{'en': 'Translate and Classify : Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'fr': 'Traduire et classer\xa0: amélioration de la classification des niveaux de séquence pour les données mixtes de code anglais-hindi', 'pt': 'Traduzir e classificar: melhorar a classificação do nível de sequência para dados mistos de código inglês-hindi', 'ar': 'الترجمة والتصنيف: تحسين تصنيف مستوى التسلسل للبيانات المختلطة باللغة الإنجليزية-الهندية', 'es': 'Traducir y clasificar: mejora de la clasificación de niveles de secuencia para datos mixtos de código inglés-hindi', 'ja': '翻訳と分類：英語-ヒンディー語コード-混合データのシーケンスレベル分類の改善', 'hi': 'अनुवाद और वर्गीकृत: अंग्रेजी-हिंदी कोड-मिश्रित डेटा के लिए अनुक्रम स्तर वर्गीकरण में सुधार', 'ru': 'Перевод и классификация: совершенствование классификации уровней последовательности для смешанных данных на английском и хинди', 'zh': '译类:改英语-印地语代码-合数等', 'ga': 'Aistrigh agus Rangaigh: Aicmiú Leibhéil Seichimh a Fheabhsú le haghaidh Sonraí Cód-Mheasctha Béarla-Hiondúis', 'ka': 'Translate and Classify: Improving sequence Level Classification for English-Hindi Code-Mixed Data', 'el': 'Μετάφραση και ταξινόμηση: Βελτίωση της ταξινόμησης επιπέδου αλληλουχίας για δεδομένα μικτού κώδικα Αγγλικών-Χίντι', 'hu': 'Fordítás és osztályozás: Az angol-hindi kódkevert adatok sorozatszintjének javítása', 'lt': 'Translate and Classify: Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'it': 'Tradurre e classificare: migliorare la classificazione a livello di sequenza per i dati misti di codice inglese-hindi', 'kk': 'Аудару және классификация: Ағылшын- хиндық код араластырылған деректерді реттеу деңгейін жақсарту', 'ms': 'Translate and Classify: Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'mk': 'Преведи и класификувај: подобрување на класификацијата на нивото на секвенција за англиско-хиндиски код мешани податоци', 'ml': '@ info', 'no': 'Omsetjing og klassifiser: Forbetra klassifisering av sekvensnivået for engelsk-hindisk kodeflikte data', 'mt': 'Traduzzjoni u Klassifikazzjoni: Titjib fil-Klassifikazzjoni tal-Livell tas-Sekwenza għad-Dejta Mħallta tal-Kodiċi Ingliż-Indjan', 'pl': 'Tłumaczenie i klasyfikacja: Poprawa klasyfikacji poziomu sekwencji dla danych mieszanych w języku angielskim-hindi', 'mn': 'Хятад хэлбэртэй өгөгдлийн дарааллын түвшинд сайжруулах', 'sr': 'Prevodite i klasifikujte: poboljšavanje klasifikacije nivoa sekvence za mješane podatake engleskog-hindskog koda', 'ro': 'Traduceți și clasificați: Îmbunătățirea clasificării nivelului de secvență pentru datele combinate cu coduri engleză-hindi', 'si': 'වාර්ථාව සහ ක්ලාසිෆික් කරන්න: ඉංග්\u200dරීසි-හින්දි කෝඩ් මික්ස් දත්ත සඳහා වාර්ථාව ප්\u200dරමාණය', 'sv': 'Översätt och klassificera: Förbättra sekvensnivåklassificering för engelsk-hindi kodblandad data', 'ta': 'மொழிபெயர்ப்பு மற்றும் வகைப்படுத்தல்: ஆங்கிலம்- Hindi- குறியீடு- கலக்கப்பட்ட தகவல்', 'so': 'Turjubaan iyo fasax: Improving Sequence Level Classification for Ingiriis-Hindi Code-Mixed Data', 'ur': 'Translate and Classify: Improved Sequence Level Classification for English-Hindi Code-Mixed Data', 'uz': 'Tarjima qilish', 'vi': 'Dịch và phân loại: cải tiến mức độ dãy', 'bg': 'Превеждане и класифициране: Подобряване на класификацията на ниво последователност за английски-хинди кодово смесени данни', 'nl': 'Vertalen en classificeren: Verbetering van de rangschikking op sequentieniveau voor Engels-Hindi Code-gemengde gegevens', 'hr': 'Prijevod i klasifikacija: poboljšanje klasifikacije razine sekvence za mješane podatke engleskog-hindskog koda', 'id': 'Translate and Classify: Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'de': 'Übersetzen und Klassifizieren: Verbesserung der Sequenz-Level-Klassifizierung für Englisch-Hindi Code-Mixed Daten', 'ko': '영어-인디언 코드 혼합 데이터의 서열급 분류 개선', 'fa': 'ترجمه و کلاس: بهتر ترجمه سطح سطح سطح انگلیسی-هندی داده\u200cهای مخلوط کد', 'da': 'Oversæt og klassificere: Forbedring af sekvensniveau klassificering for engelsk-hindi kode-blandede data', 'sq': 'Translate and Classify: Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'sw': 'Tafsiri na kutafsiri: Kuboresha Ukatili wa Kusanyika kwa ajili ya data zilizochanganyika kwa Kiingereza-Hindi', 'am': 'undo-type', 'hy': 'Comment', 'af': 'Vertaling en klassifiseer: Verbeter volgorde Vlak Klassifikasie vir Engels-Hindi kode-gemengde data', 'bn': 'ইংরেজি- হিন্দি কোড- মিক্সেড ডাটার জন্য সেকেন্স স্তর ব্যবহার করা হচ্ছে', 'ca': 'Translate and Classify: Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'cs': 'Přeložit a klasifikovat: zlepšení klasifikace úrovně sekvence pro anglicko-hindská data smíšená kódem', 'et': 'Tõlgi ja klassifitseeri: inglise-hindi koodisega andmete järjestuse taseme klassifitseerimise parandamine', 'bs': 'Prevedite i klasifikujte: poboljšavanje klasifikacije nivoa sekvence za mješane podatake engleskog-hindskog koda', 'az': 'Tərcümə və Sınıf: İngilizce-Hindi Kod-Karışıqlı Veriləri üçün Sıradan Sınıf Seçməsi', 'tr': 'terjime we klasifike', 'fi': 'Käännä ja luokittele: Parannetaan sekvenssitason luokitusta englanti-hindi koodisekoitetuille tiedoille', 'jv': 'undo-type', 'sk': 'Prevajanje in razvrščanje: Izboljšanje ravni zaporedja za angleško-hindijsko mešane kode podatkov', 'he': 'Translate and Classify: Improving Sequence Level Classification for English-Hindi Code-Mixed Data', 'ha': '@ item Text character set', 'bo': 'ཚིག་བརྗོད་དང་དབྱེ་རིམ：དབྱིན་ཡིག་གི་གནས་ཚད་ལ་རིམ་པ་སྒྲིག་འགོད་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Code-mixing is a common phenomenon in multilingual societies around the world and is especially common in social media texts. Traditional NLP systems, usually trained on monolingual corpora, do not perform well on code-mixed texts. Training specialized ', 'ar': 'يعد خلط الشفرات ظاهرة شائعة في المجتمعات متعددة اللغات حول العالم وهي شائعة بشكل خاص في نصوص وسائل التواصل الاجتماعي. لا تعمل أنظمة البرمجة اللغوية العصبية التقليدية ، التي يتم تدريبها عادةً على مجموعات أحادية اللغة ، بشكل جيد على النصوص المختلطة بالشفرات. يعد تدريب النماذج المتخصصة للنصوص المحولة بالشفرة أمرًا صعبًا بسبب الافتقار إلى مجموعات البيانات واسعة النطاق. يمكن أن تؤدي ترجمة البيانات المختلطة بالشفرات إلى لغات قياسية مثل اللغة الإنجليزية إلى تحسين الأداء في العديد من المهام المختلطة برموز حيث يمكننا استخدام نقل التعلم من أحدث النماذج الإنجليزية لمعالجة البيانات المترجمة. تركز هذه الورقة على مهمتي تصنيف على مستوى التسلسل للنصوص المختلطة للشفرة الإنجليزية الهندية ، والتي تعد جزءًا من معيار GLUECoS - استدلال اللغة الطبيعية وتحليل المشاعر. نقترح استخدام العديد من النماذج المدربة مسبقًا والتي تم ضبطها لمهام مماثلة باللغة الإنجليزية فقط وأظهرت أداءً متطورًا. نقوم أيضًا بضبط هذه النماذج بدقة على مجموعات البيانات المترجمة المختلطة بالشفرات وتحقيق أداء متطور في كلتا المهمتين. لترجمة البيانات المختلطة من الإنجليزية إلى الهندية إلى اللغة الإنجليزية ، نستخدم mBART ، وهو نموذج تسلسل إلى تسلسل متعدد اللغات تم تدريبه مسبقًا والذي أظهر أداءً تنافسيًا في أزواج الترجمة الآلية المختلفة منخفضة الموارد وأظهر أيضًا مكاسب في الأداء في اللغات التي كانت ليس في مجموعة ما قبل التدريب.', 'pt': 'A mistura de códigos é um fenômeno comum em sociedades multilíngues em todo o mundo e é especialmente comum em textos de mídia social. Os sistemas tradicionais de PNL, geralmente treinados em corpora monolíngues, não funcionam bem em textos mistos. O treinamento de modelos especializados para textos com troca de código é difícil devido à falta de conjuntos de dados em grande escala. A tradução de dados mistos de código para idiomas padrão, como o inglês, pode melhorar o desempenho em várias tarefas mistas de código, pois podemos usar o aprendizado de transferência de modelos ingleses de última geração para processar os dados traduzidos. Este artigo se concentra em duas tarefas de classificação em nível de sequência para textos mistos de código inglês-hindi, que fazem parte do benchmark GLUCoS - Natural Language Inference and Sentiment Analysis. Propomos o uso de vários modelos pré-treinados que foram ajustados para tarefas semelhantes somente em inglês e mostraram desempenho de última geração. Ajustamos ainda mais esses modelos nos conjuntos de dados mistos de código traduzidos e alcançamos desempenho de última geração em ambas as tarefas. Para traduzir dados mistos de código inglês-hindi para inglês, usamos o mBART, um modelo multilíngue pré-treinado de sequência a sequência que mostrou desempenho competitivo em vários pares de tradução automática de poucos recursos e também mostrou ganhos de desempenho em idiomas que eram não em seu corpus pré-treinamento.', 'es': 'La mezcla de códigos es un fenómeno común en las sociedades multilingües de todo el mundo y es especialmente común en los textos de las redes sociales. Los sistemas de PNL tradicionales, normalmente entrenados en corpus monolingües, no funcionan bien en textos con código mixto. La capacitación de modelos especializados para textos con cambio de código es difícil debido a la falta de conjuntos de datos a gran escala. La traducción de datos con código mixto a idiomas estándar, como el inglés, podría mejorar el rendimiento en varias tareas de código mixto, ya que podemos utilizar el aprendizaje por transferencia de modelos de inglés de última generación para procesar los datos traducidos. Este artículo se centra en dos tareas de clasificación a nivel de secuencia para textos mixtos de código inglés-hindi, que forman parte del punto de referencia de GlueCos: Análisis de opinión e inferencia de lenguaje natural. Proponemos utilizar varios modelos previamente entrenados que se han ajustado para tareas similares solo en inglés y que han demostrado un rendimiento de vanguardia. Ajustamos aún más estos modelos en los conjuntos de datos de código mixto traducidos y logramos un rendimiento de vanguardia en ambas tareas. Para traducir datos de código mixto inglés-hindi al inglés, utilizamos mBART, un modelo multilingüe de secuencia a secuencia previamente entrenado que ha demostrado un rendimiento competitivo en varios pares de traducción automática de bajos recursos y también ha demostrado mejoras en el rendimiento en idiomas que no estaban en su corpus de pre-capacitación.', 'fr': "Le mélange de codes est un phénomène courant dans les sociétés multilingues du monde entier et est particulièrement fréquent dans les textes des réseaux sociaux. Les systèmes de PNL traditionnels, généralement formés sur des corpus monolingues, ne donnent pas de bons résultats sur des textes mixtes de code. La formation de modèles spécialisés pour les textes commutés par code est difficile en raison du manque de jeux de données à grande échelle. La traduction de données mixtes de code dans des langues standard comme l'anglais pourrait améliorer les performances sur diverses tâches mixtes de code, car nous pouvons utiliser l'apprentissage par transfert à partir de modèles anglais de pointe pour traiter les données traduites. Cet article se concentre sur deux tâches de classification au niveau de la séquence pour les textes mixtes en code anglais-hindi, qui font partie du benchmark GlueCOS - l'inférence du langage naturel et l'analyse des sentiments. Nous proposons d'utiliser divers modèles pré-entraînés qui ont été affinés pour des tâches similaires en anglais uniquement et qui ont démontré des performances de pointe. Nous affinons davantage ces modèles sur les ensembles de données mixtes de code traduits et obtenons des performances de pointe dans les deux tâches. Pour traduire des données mixtes anglais-hindi en anglais, nous utilisons mBart, un modèle séquence-séquence à séquence multilingue pré-entraîné qui a montré des performances compétitives sur diverses paires de traduction automatique à faibles ressources et qui a également montré des gains de performance dans des langues qui ne faisaient pas partie de son corpus de pré-formation.", 'ja': 'コードミキシングは、世界中の多言語社会で一般的な現象であり、特にソーシャルメディアテキストで一般的です。 従来のNLPシステムは、通常、単一言語のコーパスでトレーニングされていますが、コードミックスされたテキストではうまく機能しません。 大規模なデータセットがないため、コードスイッチされたテキストの専門モデルのトレーニングは困難です。 コードミックスされたデータを英語などの標準的な言語に翻訳すると、翻訳されたデータを処理するために最先端の英語モデルからの転送学習を使用できるため、さまざまなコードミックスタスクのパフォーマンスが向上する可能性があります。 本稿では、GLUECoSベンチマークNatural Language Inference and Sentiment Analysisの一部である、英語-ヒンディー語コード混合テキストの2つのシーケンスレベルの分類タスクに焦点を当てる。 同様の英語のみのタスクのために微調整され、最先端のパフォーマンスを示したさまざまな事前トレーニング済みモデルを使用することを提案します。 翻訳されたコードミックスされたデータセットでこれらのモデルをさらに微調整し、両方のタスクで最先端のパフォーマンスを達成します。 英語とヒンディー語のコード混合データを英語に翻訳するために、mBARTを使用しています。mBARTは、様々な低リソースの機械翻訳ペアで競争力のあるパフォーマンスを示し、事前トレーニングコーパスになかった言語でもパフォーマンスの向上を示した、事前トレーニングされた多言語シーケンスツーシーケンスモデルです。', 'zh': '代码混者,世界各地多言世常见,社交媒体文本尤常见也。 旧NLP系统,常于单语语料库上训练,于代码混文本不佳。 以乏大数集,难为代码切换本训练专用。 凡代码混合之数(转相准语(英语)可以崇众代码混合之性,可以先进英语移学以处译后之数也。 本文重点介英语-印地语代码混合两序列级分类务,乃 GLUECoS 基准测试 - 自然语言推理情析之一体也。 臣等请用诸豫练之形,已针类之纯英语,见先进之性。 转换之代码,混合数据集上更加微调,并于两任最先进之性。 以英语- 印地语代码混数翻译成英语,吾等用mBART,此预习之多言序,示有竞争力之性于诸低资源机器翻译,而示其预训练语料库无言之性也。', 'hi': 'कोड-मिश्रण दुनिया भर के बहुभाषी समाजों में एक आम घटना है और सोशल मीडिया ग्रंथों में विशेष रूप से आम है। पारंपरिक एनएलपी सिस्टम, आमतौर पर मोनोलिंगुअल कॉर्पोरेट पर प्रशिक्षित, कोड-मिश्रित ग्रंथों पर अच्छा प्रदर्शन नहीं करते हैं। बड़े पैमाने पर डेटासेट की कमी के कारण कोड-स्विच किए गए ग्रंथों के लिए विशेष मॉडल का प्रशिक्षण मुश्किल है। अंग्रेजी जैसी मानक भाषाओं में कोड-मिश्रित डेटा का अनुवाद विभिन्न कोड-मिश्रित कार्यों पर प्रदर्शन में सुधार कर सकता है क्योंकि हम अनुवादित डेटा को संसाधित करने के लिए अत्याधुनिक अंग्रेजी मॉडल से स्थानांतरण सीखने का उपयोग कर सकते हैं। यह पेपर अंग्रेजी-हिंदी कोड मिश्रित ग्रंथों के लिए दो अनुक्रम-स्तरीय वर्गीकरण कार्यों पर केंद्रित है, जो GLUECoS बेंचमार्क - प्राकृतिक भाषा अनुमान और भावना विश्लेषण का हिस्सा हैं। हम विभिन्न पूर्व-प्रशिक्षित मॉडलों का उपयोग करने का प्रस्ताव करते हैं जिन्हें समान अंग्रेजी-केवल कार्यों के लिए ठीक-ठाक किया गया है और अत्याधुनिक प्रदर्शन दिखाया गया है। हम अनुवादित कोड-मिश्रित डेटासेट पर इन मॉडलों को आगे ठीक करते हैं और दोनों कार्यों में अत्याधुनिक प्रदर्शन प्राप्त करते हैं। अंग्रेजी-हिंदी कोड-मिश्रित डेटा का अंग्रेजी में अनुवाद करने के लिए, हम mBART का उपयोग करते हैं, जो एक पूर्व-प्रशिक्षित बहुभाषी अनुक्रम-से-अनुक्रम मॉडल है जिसने विभिन्न कम-संसाधन मशीन अनुवाद जोड़े पर प्रतिस्पर्धी प्रदर्शन दिखाया है और उन भाषाओं में प्रदर्शन लाभ भी दिखाया है जो इसके पूर्व-प्रशिक्षण कॉर्पस में नहीं थे।', 'ru': 'Смешивание кода является распространенным явлением в многоязычных обществах по всему миру и особенно распространено в текстах социальных сетей. Традиционные системы NLP, обычно обученные на одноязычных корпусах, плохо работают с текстами со смешанным кодом. Обучение специализированных моделей для текстов с переключением кода сопряжено с трудностями из-за отсутствия крупномасштабных наборов данных. Перевод смешанных данных на стандартные языки, такие как английский, может улучшить производительность при выполнении различных задач, связанных со смешанным кодом, поскольку мы можем использовать для обработки переведенных данных обучение переносу на основе современных моделей английского языка. В этой статье основное внимание уделяется двум задачам классификации на уровне последовательности для смешанных текстов английского и хинди, которые являются частью эталона GLUECoS - Natural Language Inference and Sentiment Analysis. Мы предлагаем использовать различные предварительно обученные модели, которые были доработаны для аналогичных задач только на английском языке и показали современную производительность. Мы дополнительно дорабатываем эти модели на основе переведенных наборов данных со смешанным кодом и достигаем самых современных результатов в обеих задачах. Для перевода английско-хинди-код-смешанных данных на английский язык, мы используем mBART, предварительно обученную многоязычную модель последовательности к последовательности, которая показала конкурентоспособную производительность на различных низкоресурсных машинных парах перевода, а также показала повышение производительности в языках, которые не были в ее предварительном обучении корпуса.', 'ga': 'Is feiniméan coitianta é códmheascadh i sochaithe ilteangacha ar fud an domhain agus tá sé coitianta go háirithe i dtéacsanna meán sóisialta. Ní éiríonn go maith le córais thraidisiúnta NLP, atá oilte ar chorpora aonteangacha de ghnáth, ar théacsanna cód-mheasctha. Tá sé deacair múnlaí speisialaithe a oiliúint do théacsanna códmhalartaithe mar gheall ar an easpa tacar sonraí ar scála mór. D’fhéadfaí feabhas a chur ar fheidhmíocht ar thascanna códmheasctha éagsúla trí shonraí cód-mheasctha a aistriú go teangacha caighdeánacha ar nós an Bhéarla toisc gur féidir linn foghlaim aistrithe ó mhúnlaí Béarla den scoth a úsáid chun na sonraí aistrithe a phróiseáil. Díríonn an páipéar seo ar dhá thasc aicmithe ar leibhéal seichimh do théacsanna measctha cód Béarla-Hiondúis, atá mar chuid de thagarmharc GLUECoS - Tátal Teanga Nádúrtha agus Anailís Mothúcháin. Tá sé beartaithe againn úsáid a bhaint as samhlacha réamh-oilte éagsúla atá mionchoigeartaithe le haghaidh tascanna comhchosúla Béarla amháin agus a bhfuil feidhmíocht úrscothach léirithe acu. Déanaimid mionchoigeartú breise ar na samhlacha seo ar na tacair sonraí cód-mheasctha aistrithe agus bainimid amach feidhmíocht den scoth sa dá thasc. Chun sonraí cód-mheasctha Béarla-Hiondúis a aistriú go Béarla, úsáidimid mBART, samhail seicheamh-go-seicheamh ilteangach réamh-oilte a léirigh feidhmíocht iomaíoch ar phéirí aistriúcháin meaisín éagsúla acmhainní íseal agus a léirigh gnóthachain feidhmíochta i dteangacha a bhí ann freisin. nach bhfuil ina chorpas réamh-oiliúna.', 'hu': 'A kódkeverés gyakori jelenség a többnyelvű társadalmakban világszerte, és különösen gyakori a közösségi média szövegekben. A hagyományos NLP rendszerek, amelyek általában egynyelvű corporákra képzettek, nem teljesítenek jól a kódkeverékes szövegeken. A kódkapcsolt szövegekre vonatkozó speciális modellek képzése nehéz a nagyméretű adatkészletek hiánya miatt. A kódkeverékes adatok normál nyelvekre történő fordítása javíthatja a teljesítményt különböző kódkeverékes feladatokban, mivel a lefordított adatok feldolgozásához használhatjuk a korszerű angol modellekből származó transzfer tanulást. Ez a tanulmány két szekvencia-szintű osztályozási feladatra összpontosít az angol-hindi kód vegyes szövegek esetében, amelyek a GLUECoS referenciaérték részét képezik - Natural Language Inference és Sentiment Analysis. Különböző előképzett modellek használatát javasoljuk, amelyeket finomhangoltak hasonló angol nyelvű feladatokra és korszerű teljesítményt mutattak. Ezeket a modelleket tovább finomhangoljuk a lefordított kódkeverékes adatkészletekre, és mindkét feladatban korszerű teljesítményt érünk el. Az angol-hindi kódkeverék adatok angolra történő lefordításához az mBART-t használjuk, egy előre képzett többnyelvű szekvencia-szekvencia modellt, amely versenyképes teljesítményt mutatott különböző alacsony erőforrású gépi fordítási párokban, és teljesítménynövekedést mutatott olyan nyelveken is, amelyek nem szerepeltek a képzés előtti korpuszban.', 'el': 'Η ανάμειξη κώδικα είναι ένα κοινό φαινόμενο στις πολυγλωσσικές κοινωνίες σε όλο τον κόσμο και είναι ιδιαίτερα κοινό στα κείμενα των μέσων κοινωνικής δικτύωσης. Τα παραδοσιακά συστήματα, συνήθως εκπαιδευμένα σε μονογλωσσικά σώματα, δεν αποδίδουν καλά σε κείμενα μικτού κώδικα. Η εκπαίδευση εξειδικευμένων μοντέλων για κείμενα με μεταγραφή κώδικα είναι δύσκολη λόγω της έλλειψης μεγάλης κλίμακας συνόλων δεδομένων. Η μετάφραση δεδομένων μικτού κώδικα σε τυποποιημένες γλώσσες όπως τα αγγλικά θα μπορούσε να βελτιώσει την απόδοση σε διάφορες εργασίες μικτού κώδικα, δεδομένου ότι μπορούμε να χρησιμοποιήσουμε τη μάθηση μεταφοράς από σύγχρονα αγγλικά μοντέλα για την επεξεργασία των μεταφρασμένων δεδομένων. Η παρούσα εργασία επικεντρώνεται σε δύο εργασίες ταξινόμησης σε επίπεδο ακολουθίας για μικτά κείμενα αγγλο-ινδικού κώδικα, τα οποία αποτελούν μέρος του δείκτη αναφοράς για την ανάλυση συμπερασμάτων φυσικής γλώσσας και συναισθημάτων. Προτείνουμε τη χρήση διαφόρων προ-εκπαιδευμένων μοντέλων που έχουν προσαρμοστεί για παρόμοιες εργασίες μόνο στα αγγλικά και έχουν επιδείξει επιδόσεις τελευταίας τεχνολογίας. Βελτιστοποιούμε περαιτέρω αυτά τα μοντέλα στα μεταφρασμένα σύνολα δεδομένων μικτού κώδικα και επιτυγχάνουμε επιδόσεις τελευταίας τεχνολογίας και στις δύο εργασίες. Για να μεταφράσουμε δεδομένα με μικτό κώδικα στα αγγλικά, χρησιμοποιούμε ένα προ-εκπαιδευμένο πολύγλωσσο μοντέλο ακολουθίας-ακολουθίας που έχει δείξει ανταγωνιστικές επιδόσεις σε διάφορα ζεύγη μηχανικής μετάφρασης χαμηλού πόρου και έχει επίσης επιδείξει κέρδη απόδοσης σε γλώσσες που δεν ήταν στο σώμα προ-κατάρτισης.', 'ka': 'კოდის შემთხვევა არის მრავალენგური საზოგადოებში სამყაროში და სოციალური მედია ტექსტში განსაკუთრებულია. ტრადიციონალური NLP სისტემები, რომელიც მონოლენგური კოპორაზე განაკეთებულია, კოდის შემთხვევაში არ მუშაობს. სპეციალური მოდელები, რომელიც კოდის გადაცვლა ტექსტის შესახებ, ძალიან რთული იყო, რადგან დიდი განზომილებული მონაცემების არსებობა. ჩვენ შეგვიძლია გამოყენება ინგლისური მოდელებიდან გასწავლის გასწავლისთვის განსხვავებული კოდეების შესაძლებლობა, რადგან ჩვენ შეგვიძლია გამოყენება განსხვავებული ინგლისური მოდელებიდან გას ამ დოკუნტის კონფიკურაციის ორი წერტილის კონფიკურაცია ანგლისურ-ჰინდის კოდისტური ტექსტის ნაწილი, რომელიც GLUECoS ბანქმერის ნაწილი - Natural Language Inference და Sentiment Analysis. ჩვენ მინდა გამოყენება განსხვავებული მოდელების გამოყენება, რომლებიც მსგავსი ანგლისური მუშაობებისთვის სხვადასხვა მოდელების გამოყენება და ჩვენ გამოჩვენეთ სურათების ჩვენ შემდეგ ამ მოდელების შესაძლებლობად შევცვალობთ კოდის შესაძლებლობული მონაცემების შესაძლებლობაში და გავაკეთებთ ორივე საქმებში მუშაობის შესაძლებლობა. თუ ინგლისური-ჰინდური კოდენტიკური კოდენტიკური ინგლისურში გადაწყენებლად, ჩვენ გამოყენებთ mBART, მრავალური მრავალური კოდენტიკური კოდენტიკური კოდენტიკური კოდენტიკური კოდენტიკური მაქინის გადაწყენება და ასევ', 'it': "Il code-mixing è un fenomeno comune nelle società multilingue di tutto il mondo ed è particolarmente comune nei testi sui social media. I sistemi NLP tradizionali, di solito formati su corpora monolingue, non funzionano bene su testi codificati. La formazione di modelli specializzati per testi a commutazione di codice è difficile a causa della mancanza di set di dati su larga scala. Tradurre dati misti di codice in lingue standard come l'inglese potrebbe migliorare le prestazioni su vari compiti misti di codice poiché possiamo utilizzare l'apprendimento di trasferimento da modelli inglesi all'avanguardia per l'elaborazione dei dati tradotti. Questo articolo si concentra su due compiti di classificazione a livello sequenziale per testi misti di codice inglese-hindi, che fanno parte del benchmark GLUECoS - Natural Language Inference and Sentiment Analysis. Proponiamo di utilizzare vari modelli pre-addestrati che sono stati perfezionati per attività simili solo in inglese e hanno mostrato prestazioni all'avanguardia. Aggiungiamo ulteriormente questi modelli sui set di dati misti di codice tradotti e otteniamo prestazioni all'avanguardia in entrambe le attività. Per tradurre in inglese i dati misti di codice inglese-hindi, utilizziamo mBART, un modello di sequenza-sequenza multilingue pre-addestrato che ha mostrato prestazioni competitive su varie coppie di traduzioni automatiche a basso contenuto di risorse e ha anche mostrato miglioramenti di prestazioni in lingue che non erano nel suo corpus pre-formazione.", 'mk': 'Мешањето на кодовите е заеднички феномен во мултијазичните општества низ целиот свет и е особено често во текстовите на социјалните медиуми. Традиционалните НЛП системи, обично обучени на монојазични корпора, не успеваат добро во мешаните тексти. Training specialized models for code-switched texts is difficult due to the lack of large-scale datasets.  Преведувањето на податоци мешани со код на стандардни јазици како Англиски би можело да ја подобри резултатот на различните задачи мешани со код бидејќи можеме да користиме трансферентно учење од најновите англиски модели за обработување на преведени податоци. Оваа хартија се фокусира на две класификациски задачи на ниво на секвенца за мешани тексти на англиско-хиндски код, кои се дел од ГЛУЕКОС - Природна инференција на јазик и анализа на чувствата. Ние предложуваме користење на различни предобучени модели кои се финетизирани за слични задачи само на англиски јазик и покажаа најсовремени изведувања. Понатаму ги подобриме овие модели на преведените кодови-мешани податоци и постигнуваме најсовремени резултати во двете задачи. За да ги преведеме англиско-хиндиските мешани податоци на англиски, користиме mBART, предобучен мултијазичен модел од секвенца до секвенца кој покажа конкурентна резултат на различни парови на машински превод со ниски ресурси и покажа профит на јазици кои не беа во својот предобучен корпус.', 'lt': 'Kodeksų derinimas yra bendras reiškinys daugiakalbėse visuomenėse visame pasaulyje ir ypač dažnas social in ės žiniasklaidos tekstuose. Traditional NLP systems, usually trained on monolingual corpora, do not perform well on code-mixed texts.  Training specialized models for code-switched texts is difficult due to the lack of large-scale datasets.  Perkeldami kodų mišrius duomenis į standartines kalbas, pavyzdžiui, anglų kalba, būtų galima pagerinti įvairių kodų mišrių užduočių rezultatus, nes galime naudoti perkėlimo mokymąsi iš naujausių anglų modelių vertimo duomenims apdoroti. Šiame dokumente daugiausia dėmesio skiriama dviem eilės lygio klasifikavimo užduotims, susijusioms su anglų ir hindų kodų mišriais tekstais, kurie yra GLUECoS lyginamojo rodiklio dalis – gamtinė kalbų infierencija ir jausmų analizė. Siūlome naudoti įvairius iš anksto parengtus modelius, kurie buvo patobulinti panašioms tik anglų kalba užduotims ir parodė pažangiausius rezultatus. Toliau patobuliname šiuos modelius vertimo kodais mišriuose duomenų rinkiniuose ir abiejose užduotyse pasiektume pažangiausius rezultatus. Norėdami išversti anglų ir hindų kodų mišrius duomenis į anglų kalbą, mes naudojame mBART, iš anksto parengtą daugiakalbį sekos po sekos model į, kuris parodė konkurencinius rezultatus įvairioms mažai išteklių turinčioms mašin ų vertimo poroms ir taip pat parodė rezultatų pagerėjimą kalbomis, kurios nebuvo parengiamojo mokymo korpuse.', 'ms': 'Pengcampuran kod adalah fenomena biasa dalam masyarakat berbilang bahasa di seluruh dunia dan terutama biasa dalam teks media sosial. Sistem NLP tradisional, biasanya dilatih pada korpra monobahasa, tidak berjaya dengan baik pada teks kod-campuran. Latihan model khusus untuk teks ditukar-kod adalah sukar kerana kekurangan set data skala besar. Menerjemahkan data campuran-kod ke bahasa piawai seperti Bahasa Inggeris boleh meningkatkan prestasi pada pelbagai tugas campuran-kod kerana kita boleh guna pemindahan belajar dari model Inggeris-state-of-the-art untuk memproses data terjemahan. Kertas ini fokus pada dua tugas kelasukan aras urutan untuk teks campuran kod Inggeris-Hindi, yang merupakan sebahagian dari tanda referensi GLUECoS - Inferensi Bahasa Semulajadi dan Analisi Sentiment. Kami cadangkan menggunakan berbagai-bagai model terlatih yang telah ditetapkan untuk tugas bahasa Inggeris-sahaja yang sama dan telah menunjukkan prestasi state-of-the-art. Kami lebih memperbaiki model ini pada set data terjemahan kod-campuran dan mencapai prestasi state-of-the-art dalam kedua-dua tugas. To translate English-Hindi code-mixed data to English, we use mBART, a pre-trained multilingual sequence-to-sequence model that has shown competitive performance on various low-resource machine translation pairs and has also shown performance gains in languages that were not in its pre-training corpus.', 'kk': 'Код араластыру - әлемдегі көп тілдік қоғамдарында жалпы пайда болып, әсіресе социалдық медиа мәтіндерінде жалпы. Дәстүрлі NLP жүйелері, кәдімгі монолингі корпораға үйренілген, код араластырылған мәтіндерде жақсы жоқ. Код ауыстырылған мәтіндердің арнаулы моделдерін оқыту үлкен масштаб деректер жиындары жоқ себебі қиын. Код араластырылған деректерді ағылшын тілдеріне аудару әртүрлі код араластырылған тапсырмаларды жақсартуға болады, өйткені біз аударылған деректерді өзгерту үшін ағылшын тілдерінің күй- жай моделінен ау Бұл қағаз ағылшын- хинди кодтың аралас мәтіндер үшін екі реттік деңгейіндегі классификациялау тапсырмаларына назар аударады. Бұл GLUECoS бағдарламасының бөлігі - Natural Language Inference және Sentiment Analysis. Біз тек ағылшын тілдегі тапсырмалар үшін жақсы бапталған әртүрлі оқыту үлгілерін қолдануға жұмыс береміз. Бұл әртүрлі оқыту үлгілерін көрсетеді. Біз бұл үлгілерді код арасындағы деректер жиындарына қарап, екеуі тапсырмалардың күй- жайымдығын жеткіземіз. Ағылшын-хинди код арасындағы деректерді ағылшын тіліне аудару үшін, мBART- тілінің алдындағы көптеген көптеген түрлі тілдерді қарау үлгісін қолданамыз. Бұл көптеген көптеген көптеген түрлі ресурстар аудару компьютерінің бірнеше қасиеттерін көр', 'ml': 'ലോകത്തിലെ പല ഭാഷ സമൂഹങ്ങളില്\u200d കോഡ് മിക്കിങ്ങ് ഒരു സാധാരണ സംഭവം തന്നെയാണ്. പ്രത്യേകിച്ചും സാമൂഹിക മെഡിയാ ടെക്സ് പാഠമായ NLP സിസ്റ്റമുകള്\u200d, സാധാരണയായി മോണോളില്\u200d കോര്\u200dപ്പോരിയില്\u200d പരിശീലനം നടത്തിയിട്ടുണ്ട്, കോഡ് മിഷ്ടപ്പെട് കോഡ്- മാറ്റുന്ന പദാവലികള്\u200dക്കുള്ള പ്രത്യേക മോഡലുകള്\u200d പരിശീലിപ്പിക്കുന്നത് വലിയ വിവരങ്ങളുടെ കാരണമാണ്. Translating code-mixed data into standard languages like English could improve performance on various code-mixed tasks since we can use transfer learning from state-of-the-art English models for processing the translated data.  ഇംഗ്ലീഷ്- ഹിന്ദി കോഡ് മിഷ്ടപ്പെട്ട ട ടെക്സ്റ്റുകള്\u200dക്കായി രണ്ട് സെക്കന്\u200dസ് നില ക്ലാസ്ഫിക്ഷന്\u200d ജോലിക്കുന്നു. അത് GLUES ബെന്\u200dച്മാര്\u200dക്കി ഇതുപോലുള്ള ഇംഗ്ലീഷ് മാത്രം ജോലികള്\u200dക്ക് മുമ്പ് പരിശീലിക്കപ്പെട്ട പല മോഡലുകള്\u200d ഉപയോഗിച്ച് കൊണ്ട് പ്രായശ്ചിത്തം  പരിഭാഷപ്പെടുത്തിയ കോഡ്-മിഷ്ടപ്പെട്ട ഡാറ്റാസറ്റുകളില്\u200d ഈ മോഡലുകള്\u200d കൂടുതല്\u200d നന്നായി നിര്\u200dണയിക്കുന്നു. രണ്ടു ജോല ഇംഗ്ലീഷ്- ഹിന്ദി- കോഡ്- മിഷ്ടപ്പെട്ട വിവരങ്ങള്\u200d ഇംഗ്ലീഷിലേക്ക് ഇംഗ്ലീഷിലേക്ക് നാം ഉപയോഗിക്കുന്നു. മുമ്പ് പരിശീലന മുള്\u200dട്ടിലുള്ള പല ഭാഷ-സെക്കന്\u200dസ് മോഡല്\u200d ഉപയോഗിക്കു', 'mt': 'Code-mixing is a common phenomenon in multilingual societies around the world and is especially common in social media texts.  Sistemi tradizzjonali NLP, normalment imħarrġa fuq korpura monolingwi, ma jwettqux tajjeb fuq testi mħallta bil-kodiċi. It-taħriġ ta’ mudelli speċjalizzati għal testi mibdula bil-kodiċi huwa diffiċli minħabba n-nuqqas ta’ settijiet ta’ dejta fuq skala kbira. It-traduzzjoni tad-dejta mħallta bil-kodiċi f’lingwi standard bħall-Ingliż tista’ ttejjeb il-prestazzjoni fuq diversi kompiti mħallta bil-kodiċi peress li nistgħu nużaw it-tagħlim tat-trasferiment minn mudelli bl-Ingliż l-aktar avvanzati għall-ipproċessar tad-dejta tradotta. Dan id-dokument jiffoka fuq żewġ kompiti ta’ klassifikazzjoni fil-livell ta’ sekwenza għat-testi mħallta tal-kodiċi Ingliż-Indjan, li huma parti mill-parametru referenzjarju GLUECoS - Inferenza tal-Lingwa Naturali u Analiżi tas-Sentiment. We propose using various pre-trained models that have been fine-tuned for similar English-only tasks and have shown state-of-the-art performance.  Aħna nistabbilixxu aktar dawn il-mudelli fuq settijiet ta’ dejta mħallta ta’ kodiċijiet tradotti u niksbu prestazzjoni avvanzata fiż-żewġ kompiti. Biex tittraduċi dejta mBART imħallta bejn l-Ingliż u l-Indjan għall-Ingliż, a ħna nużaw mBART, mudell ta’ sekwenza għal sekwenza multilingwi mħarreġ minn qabel li wera prestazzjoni kompetittiva fuq diversi par ta’ traduzzjoni tal-magni b’riżorsi baxxi u wera wkoll kisbiet fil-prestazzjoni f’lingwi li ma kinux fil-korpus ta’ qabel it-taħriġ tiegħu.', 'no': 'Kodefeksing er eit vanleg fenomen i fleirspråk samfunn rundt verden og er spesielt vanleg i sosiale media-tekstar. Tradisjonale NLP-systemer, vanlegvis trengte på monospråk korpora, utfører ikkje godt på kodefeksa tekstar. Opplæring av spesialiserte modeller for tekstbytt med kodar er vanskeleg på grunn av manglende store datasett. Omsetjinga av kode-blandede data til standardspråk som engelsk kan forbetra utviklinga på ulike kode-blandede oppgåver sidan vi kan bruka overføring frå state-of-the-art English models for handsaming av omsette data. Denne papiret fokuserer på to sekvensnivåklassifikasjonar for mellom tekstar med engelsk- hindisk kode, som er ein del av GLUECoS- benchmarket – naturspråk Inference og Sentiment Analysis. Vi foreslår å bruka forskjellige føretrainerte modeller som har blitt fint oppsett for liknande engelske oppgåver og har vist tilstanden av kunsten. Vi finn framover desse modelane på dei omsette kode-blandede datasetta og oppnår status-of-the-art-performance i begge oppgåver. For å oversette engelsk-hindiske kodefeksa til engelsk, bruker vi mBART, eit føreøvinga multispråkssekvens-til-sekvensmodell som har vist konkurentivt utvikling på ulike låg-ressursmaskinske omsetjingspråk og har også vist utvikling i språk som ikkje var i føreøvingskorpusen sin.', 'mn': 'Код холбогдол нь дэлхийн олон хэл нийгмийн нийгмийн ерөнхий үзэгдэл юм. Ялангуяа нийгмийн хэвлэлийн текстүүдэд ерөнхий үзэгдэл юм. Хувийн NLP систем, ихэвчлэн ганц хэл корпора дээр сургалтын тулд код холбогдсон текст дээр сайн ажиллахгүй. Код-өөрчлөгдсөн текстүүдийн мэргэжлийн загваруудыг суралцах нь том хэмжээний өгөгдлийн санд байхгүй учраас хэцүү. Код холбогдсон өгөгдлийг Англи хэл шиг стандарт хэлнүүд рүү орчуулах нь олон код холбогдсон ажил дээр ажиллагааг сайжруулж чадна. Учир нь бид англи хэл хэлбэрээс суралцах сургалтыг хэрэглэж болно. Энэ цаас нь Англи-Хинди кодын хоёр дарааллын хэмжээний хуваалтын ажил дээр анхаарлаа хандуулдаг. Энэ нь GLUECoS-ын хуваалтын нэг хэсэг юм. Бид англи хэлний зөвхөн төстэй ажлын төлөвлөгдсөн олон сургалтын загваруудыг ашиглаж, урлагийн үйл ажиллагааг харуулсан. Бид эдгээр загваруудыг кодын төвөгтэй өгөгдлийн сан дээр илүү сайжруулж, хоёр даалгавраар урлагийн үйл ажиллагааны төвөгтэй байдал гаргаж байна. Англи-Хинди кодын хувьд Англи хэл руу орлуулахын тулд бид mBART-г ашиглаж байна. МБАРТ бол олон хэл дахь дарааллын загварыг ашиглаж байна. Энэ нь машины хөгжлийн хөгжлийн хэлбэрээс өрсөлдөг үйл ажиллагааг харуулсан, мөн түүний өмнө сургалтын ко', 'ro': 'Mixarea codurilor este un fenomen comun în societățile multilingve din întreaga lume și este frecventă în special în textele rețelelor de socializare. Sistemele tradiționale PNL, de obicei instruite pe corpuri monolingve, nu funcționează bine pe texte mixte de cod. Instruirea modelelor specializate pentru texte schimbate de cod este dificilă din cauza lipsei seturilor de date la scară largă. Traducerea datelor combinate cu coduri în limbi standard, cum ar fi engleza, ar putea îmbunătăți performanța în diverse sarcini combinate de coduri, deoarece putem folosi transferul de învățare de la modele engleze de ultimă generație pentru prelucrarea datelor traduse. Această lucrare se concentrează pe două sarcini de clasificare la nivel de secvență pentru textele mixte de cod engleză-hindi, care fac parte din benchmark GLUECoS - Natural Language Inference and Sentiment Analysis. Vă propunem să utilizați diferite modele pre-instruite care au fost reglate fin pentru sarcini similare numai în limba engleză și care au arătat performanțe de ultimă oră. Ajustăm în continuare aceste modele pe seturile de date combinate de coduri traduse și obținem performanțe de ultimă generație în ambele sarcini. Pentru a traduce date mixte de coduri engleză-hindi în engleză, folosim mBART, un model secvență-secvență multilingvă pre-instruit care a arătat performanțe competitive pe diferite perechi de traduceri automate cu resurse reduse și a arătat, de asemenea, câștiguri de performanță în limbi care nu au fost în corpul său pre-instruire.', 'pl': 'Mieszanie kodów jest powszechnym zjawiskiem w wielojęzycznych społeczeństwach na całym świecie i jest szczególnie powszechne w tekstach mediów społecznościowych. Tradycyjne systemy NLP, zwykle przeszkolone na korpusach jednojęzycznych, nie sprawdzają się dobrze w tekstach mieszanych kodem. Szkolenie specjalistycznych modeli tekstów przełączanych kodem jest trudne ze względu na brak dużych zbiorów danych. Tłumaczenie danych mieszanych kodem na standardowe języki, takie jak angielski, może poprawić wydajność różnych zadań mieszanych kodem, ponieważ możemy wykorzystać naukę transferową z najnowocześniejszych modeli angielskich do przetłumaczenia przetłumaczonych danych. Niniejszy artykuł skupia się na dwóch zadaniach klasyfikacji na poziomie sekwencyjnym dla tekstów mieszanych kodem angielsko-hindi, które są częścią GLUECoS benchmark for Natural Language Inference and Sentiment Analysis. Proponujemy wykorzystanie różnych wstępnie przeszkolonych modeli, które zostały dostosowane do podobnych zadań tylko w języku angielskim i wykazały się najnowocześniejszą wydajnością. Dodatkowo dostosowujemy te modele na podstawie przetłumaczonych zestawów danych mieszanych kodem i osiągamy najnowocześniejszą wydajność w obu zadaniach. Aby tłumaczyć dane z kodem angielsko-hindi na język angielski, używamy mBART, wstępnie przeszkolonego wielojęzycznego modelu sekwencji-sekwencji, który wykazał konkurencyjną wydajność w różnych parach maszynowych o niskim zasobie, a także wykazał wzrost wydajności w językach, które nie znajdowały się w korpusie przedszkoleniowym.', 'sv': 'Kodblandning är ett vanligt fenomen i flerspråkiga samhällen runt om i världen och är särskilt vanligt i sociala medier texter. Traditionella NLP-system, vanligtvis utbildade på enspråkiga korpor, fungerar inte bra på kodblandade texter. Att utbilda specialiserade modeller för kodväxlade texter är svårt på grund av bristen på storskaliga datauppsättningar. Att översätta kodblandad data till standardspråk som engelska kan förbättra prestandan på olika kodblandade uppgifter eftersom vi kan använda överföringsinlärning från state-of-the-art engelska modeller för att bearbeta översatta data. Denna uppsats fokuserar på två sekvensnivåklassificeringsuppgifter för engelsk-hindi kodblandade texter, som är en del av GLUECoS benchmark - Natural Language Inference and Sentiment Analysis. Vi föreslår att du använder olika förkunskaperade modeller som har finjusterats för liknande uppgifter endast på engelska och har visat toppmoderna prestanda. Vi finjusterar dessa modeller ytterligare på de översatta kodblandade datauppsättningarna och uppnår toppmoderna prestanda i båda uppgifterna. För att översätta engelsk-hindi kodblandad data till engelska använder vi mBART, en förutbildad flerspråkig sekvens-till-sekvensmodell som har visat konkurrenskraftig prestanda på olika maskinöversättningspar med låg resurs och även visat prestandaförbättringar på språk som inte fanns i sin pre-training korpus.', 'si': 'කෝඩ් මික්ස් එක ලෝකයේ ගොඩක් භාෂාවක් සමාජාත්මකයේ සාමාජික මිඩියාව පාළුවක් තියෙනවා. සාමාන්\u200dයය NLP පද්ධතිය, සාමාන්\u200dයයෙන්ම එක භාෂාවික කොර්පෝරා වලට ප්\u200dරශ්නය කරලා තියෙන්නේ, කෝඩ් මි Name ඉංග්\u200dරීසි වගේ ප්\u200dරමාණ භාෂාවට කෝඩ් මික්ස් තොරතුරු භාෂාවට පරිවර්තනය කරන්න පුළුවන් වෙනස් කෝඩ් මික්ස් වැඩක් විතරය මේ පැත්තේ ඉංග්\u200dරීසිය-හින්දි කෝඩ් මික්ස් පාළුවක් සඳහා ක්\u200dරමාණික විශේෂණ කාර්ය දෙකක් අවධානය කරනවා, ඒක GLUECoS බෙන්ච්ම අපි ප්\u200dරශ්නයක් කරනවා විවිධ ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරනවා වගේම ඉංග්\u200dරීසි විතරයි වගේම ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කර අපි මේ මොඩේල්ස් එක්ක අනුවාද කරලා තියෙන්නේ කෝඩ් මික්ස් දත්ත සේට් එක්ක සඳහා දෙන්නම් වැඩේ ස්ථිතිය-ස්ථාන ඉංග්\u200dරීසි-හින්දී කෝඩ් මික්ස් දත්ත ඉංග්\u200dරීසියට භාවිත කරන්න, අපි mBART භාවිතා කරනවා, ප්\u200dරීක්ෂණිත විශ්වාසිත විශ්වාසිත විශ්වාසිත විදියට පෙන්ව', 'sr': 'Mešanje kodova je zajednički fenomen u multijezičkim društvima širom svijeta i posebno je zajednički u tekstima društvenih medija. Tradicionalni NLP sistemi, obično obučeni na monojezičkom korporaciji, ne izvode dobro na tekstima mešanih kod. Treniranje specijalizovanih modela za tekstove zamijenjene kod je teško zbog nedostatka velikih podataka. Prevodenje podataka pomiješanih kod na standardne jezike kao što je engleski mogao bi poboljšati izvođenje na različitim zadacima pomiješanim kodom jer možemo koristiti prevođenje učenja iz modela state-of-the-art english za obradu prevođenih podataka. Ovaj papir se fokusira na dva klasifikacijska zadataka na nivou sekvencije za tekste mešane engleskog-hindskog koda, koji su deo benchmarke GLUECoS - prirodna jezika Inferencija i Sentimentna analiza. Predlažemo da koristimo različite predobučene modele koji su ispravno ispravljeni za slične engleske jedine zadatke i pokazuju predstavu umjetnosti. Dalje ćemo ispravljati te modele na prevedenim brojima podataka i postići izvršnost stanja umjetnosti u oba zadatka. Da bi prevedli podatke mešane engleskog-hindskog koda na engleski jezik, koristili smo mBART, predobučeni multijezički model sekvence do sekvence koji je pokazao konkurentnu funkciju na raznim parovima prevođenja mašin a s niskim resursima i pokazao je i dobitak izvođenja jezika koji nisu bili na svom korpusu pre obuke.', 'ta': 'குறியீடு கலந்து உலகின் பல மொழி சமூகங்களில் பொதுவான பொதுவான விஷயங்களாகும் மற்றும் குறிப்பாக சமூகத்தின் மொழிக் பாரம்பரிய NLP அமைப்புகள், வழக்கமாக மோனோலிங் கோர்போரில் பயிற்சி செய்யப்பட்டுள்ளது, குறியீடு கலக்கப்பட்ட உரைகளில் நன குறிமுறைமாற்றும் உரைகளுக்கு சிறப்பு மாதிரிகளை பயிற்சி செய்வது பெரிய அளவு தரவு அமைப்புகளின் காரணமாக கடினமானது. @ info @ info போன்ற ஆங்கிலத்தில் மட்டும் பணிகளுக்கு நன்றாக முன்பயிற்சி மாதிரிகளை பயன்படுத்தி மற்றும் கலை செயல்பாட்டின் நிலையைக் கா மொழிபெயர்ப்பிடப்பட்ட குறியீட்டு கலப்பு தரவுத்தளத்தில் இந்த மாதிரிகளை மேலும் நன்றாக குறிப்பிடுக To translate English-Hindi code-mixed data to English, we use mBART, a pre-trained multilingual sequence-to-sequence model that has shown competitive performance on various low-resource machine translation pairs and has also shown performance gains in languages that were not in its pre-training corpus.', 'so': "Isku xiriirka codsigu waa wax caadi ah oo ku yaala bulshada luuqadaha kala duduwan oo adduunka ku yaala, wuxuuna si gaar ah ugu caadi yahay qoraalka macluumaadka bulshada. Isticmaalka asalka ah ee NLP, sida caadiga ah shirkadda nooca ah wax lagu baran karo, si fiican uma sameyn karo qoraalka kooban. Waxbarashada tusaalooyin gaar ah ee qoraalka isbedela waa ku adag tahay, sababtoo ah baahida koorasyada macluumaadka aad u weyn. Ka turjumista macluumaadka kooxaha lagu isku xiran karo luuqadaha standardka ah, sida ingiriisiga waxaa beddeli kara bandhigyada shaqooyinka kala duduwan ee codsiga isku qasan, sababtoo ah waxaynu isticmaali karnaa waxbarashada beddelinta tusaalaha afka Ingiriiska ee dowladda ah si aad u baaraandegto macluumaadka turjuman. Kanu wuxuu ku qoran yahay laba shaqooyin fasax heer oo kala duduwan qoraalka Ingiriis-Hindi oo isku qasan qoraal, kaas oo qayb ka mid ah bangiga GLUECoS - Luqada asalka ah Inference iyo Fasaxa Sentiment. Waxaynu soo jeedaynaa isticmaalka tusaalooyin kala duduwan oo la tababaray oo la mid ah shaqooyinka luuqada Ingiriiska oo kaliya, waxaana muujinnay bandhigyada farshaxanka. Tusaaladan waxaan ku qornaa kooxda aqoonsiga lagu turjumay, waxaana ku sameynaynaa xaaladda farshaxanka labada shaqooyin. Si aan u turjumno macluumaad Ingiriis-Hindi-mixed-data Ingiriis, waxaynu isticmaalnaa mBART, model horay loo tababaray luuqado kala duduwan-to-sequence, kaasoo muujiya fasax competitive ah oo ku saabsan labo badan oo hoos-resource-machine turjumaan ah iyo sidoo kale muujinta faa'iido ah oo aan ku jirin luqadaha horumarinta.", 'ur': 'کیڈ میکسنگ دنیا میں بہت سی زبان اجتماعوں میں ایک مشترک اتفاق ہے اور مخصوصاً سوسیل میڈیا پیغام میں مشترک ہے. سنتی NLP سیسٹم، معمولاً ایک زبان کوپرا پر آموزش کی جاتی ہے، کوڈ میکس ٹیکس پر اچھا کام نہیں کرتا۔ کوڈ-سوچیڈ ٹیکسٹ کے لئے ویسپیٹ ڈیٹ سٹ کی ناکامی کے باعث ترینیننگ ویسپیٹ ڈیٹ ڈیسٹ کے لئے مشکل ہے. انگلیسی کی طرح کی انگلیسی کی استاندارڈ زبانوں میں کوڈ میکس ڈاٹ کا ترجمہ کرنا بہت سی کوڈ میکس ٹاکس پر کام کرنا بہتر کر سکتا ہے کیونکہ ہم ترجمہ ڈاٹ کی پردازی کے لئے استٹرنس کی آموزش استعمال کر سکتے ہیں. This paper focuses on two sequence-level classification tasks for English-Hindi code mixed texts, which are part of the GLUECoS benchmark - Natural Language Inference and Sentiment Analysis. ہم نے طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح ہم ان موڈلوں کو ترجمہ کڈ میکسٹ ڈیٹ سٹ پر اضافہ کر رہے ہیں اور دونوں کاموں میں موجود آرتی کے کام پہنچاتے ہیں. انگلیسی-ہینڈی کی کوڈ مکثیر دیٹا انگلیسی میں ترجمہ کرنے کے لئے، ہم mBART کو استعمال کرتے ہیں، ایک پیش آموزش کئے ہوئے multilingual sequence-to-sequence موڈل جو مختلف کم-resource ماشین ترجمہ جوڑوں کے ذریعہ مکثیر کے مطابق مکثیر کے مطابق مطابق کے مطابق مطابق', 'uz': "Kodlash qoidasi dunyodagi bir necha tillar jamiyatlaridagi umumiy narsalar va maxsus sosial media matnlarida umumiy. Name Training specialized models for code-switched texts is difficult due to the lack of large-scale datasets.  @ info Name Biz bir necha taʼminlovchi modellardan foydalanishni tahlil qilamiz. Bu bir xil ingliz tilidagi vazifalar faqat o'xshash vazifalar uchun juda yaxshi o'xshash bo'lgan va shu vazifalarning holatini ko'rsatdik. Biz tarjima qilingan kod- mix maʼlumotlar tarjimalarini ko'rib chiqaramiz va ikkita vazifalarda shaxsiy bajarish holatini bajaramiz. Ingliz- Hindi kodi- mixed maʼlumotlarini ingliz tiliga tarjima qilish uchun biz MBART, bir oldin o'rganilgan muloqat sequence- to- sequence modeliga foydalanamiz. Bu bir xil kompyuterning ko'pchilik machine tarjima xizmatiga rivojlanishni ko'rsatadi va bu bir xil tilda o'zlarini o'rganishga o'xshash ko'rsatadi.", 'vi': 'Mã pha trộn là một hiện tượng phổ biến trong các xã hội đa dạng khắp thế giới và đặc biệt phổ biến trong các văn bản phương tiện xã hội. Truyền thống ngôn ngữ ngọt ngào, thường được đào tạo về ngôn ngữ chung, không làm việc tốt với văn bản hỗn hợp mã. Sự huấn luyện các mô hình đặc biệt cho các văn bản bị mã hóa khó khăn vì thiếu các bộ dữ liệu quy mô lớn. Dịch các dữ liệu tổng hợp mã thành ngôn ngữ tiêu chuẩn như tiếng Anh có thể cải thiện khả năng thực hiện các việc phân phối mã, vì chúng ta có thể sử dụng việc truyền học từ các mẫu Anh hiện đại để xử lý các dữ liệu đã dịch. Tờ giấy này tập trung vào các nhiệm vụ phân loại thứ hai cho các văn bản trộn ngôn ngữ Anh-Hindi, mà là một phần của tiêu chuẩn GLCOCoS- Mẹ hiểu ngôn ngữ tự nhiên và Đọc vấn đề. Chúng tôi đề nghị sử dụng các mô hình được huấn luyện khác nhau đã được chỉnh sửa cẩn thận cho những nhiệm vụ đơn vị Anh tương tự và đã cho thấy hiệu quả tuyệt vời. Chúng tôi chỉnh lại các mô hình này trên các tập tin tổng hợp mã đã dịch và đạt được trình độ tối tân trong cả hai nhiệm vụ. Để dịch các dữ liệu tổng hợp mã tiếng Anh sang tiếng Anh, chúng tôi dùng mBART, một mô hình lập-trình-ra-chuỗi-trình-nối đã được đào tạo sẵn, cho thấy khả năng cạnh tranh của các cặp máy dịch-chất lỏng khác nhau, và cũng cho thấy hiệu suất tăng ở các ngôn ngữ không có trong tập đoàn sản xuất trước-huấn luyện.', 'nl': 'Code-mixing is een veelvoorkomend fenomeen in meertalige samenlevingen over de hele wereld en komt vooral voor in sociale media teksten. Traditionele NLP-systemen, meestal getraind op eentalige corpora, presteren niet goed op code-gemengde teksten. Het trainen van gespecialiseerde modellen voor code-switched teksten is moeilijk vanwege het ontbreken van grootschalige datasets. Het vertalen van code-gemengde gegevens naar standaardtalen zoals Engels kan de prestaties van verschillende code-gemengde taken verbeteren, omdat we transferleren van state-of-the-art Engelse modellen kunnen gebruiken voor het verwerken van de vertaalde gegevens. Dit artikel richt zich op twee classificatietaken op volgorde-niveau voor Engels-Hindi code gemengde teksten, die deel uitmaken van de GLUECoS benchmark voor Natural Language Inference en Sentiment Analysis. We stellen voor om verschillende voorgetrainde modellen te gebruiken die zijn afgestemd op soortgelijke taken die alleen Engels zijn en state-of-the-art prestaties hebben laten zien. We verfijnen deze modellen verder op de vertaalde code-gemengde datasets en bereiken state-of-the-art prestaties in beide taken. Om Engels-Hindi code-gemengde gegevens naar het Engels te vertalen, gebruiken we mBART, een vooraf getraind meertalig sequence-to-sequence model dat concurrerende prestaties heeft getoond op verschillende low-resource machinevertaalparen en ook prestatiewinsten heeft laten zien in talen die niet in het pre-training corpus zaten.', 'bg': 'Смесването на кодове е често срещано явление в многоезичните общества по света и е особено често срещано в текстовете в социалните медии. Традиционните системи за НЛП, обикновено обучени върху едноезични корпуси, не се представят добре при смесени с кодове текстове. Обучението на специализирани модели за кодово-комутирани текстове е трудно поради липсата на широкомащабни набори от данни. Превеждането на кодово смесени данни на стандартни езици като английски може да подобри ефективността при различни задачи с кодово смесване, тъй като можем да използваме трансферно обучение от най-съвременни английски модели за обработка на преведените данни. Настоящата статия се фокусира върху две задачи за класификация на ниво последователност на английски и хинди кодови смесени текстове, които са част от референтния анализ на естествения език. Предлагаме да се използват различни предварително обучени модели, които са фино настроени за подобни задачи само на английски език и са показали най-съвременно представяне. Освен това усъвършенстваме тези модели върху преведените кодово смесени набори от данни и постигаме най-съвременни резултати и при двете задачи. За да преведем английски-хинди кодово смесени данни на английски език, използваме предварително обучен многоезичен модел последователност към последователност, който показа конкурентни резултати при различни двойки машини за превод с нисък ресурс, както и повишаване на производителността на езици, които не са били в неговия корпус преди обучение.', 'hr': 'Mješanje kodova je zajednički fenomen u multijezičkim društvima širom svijeta i posebno je često u tekstima društvenih medija. Tradicionalni NLP sustavi, obično obučeni na monojezičkoj korpori, ne izvode dobro na tekstima mješane kod. Treniranje specijaliziranih modela za tekstove zamijenjene kod je teško zbog nedostatka velikih podataka. Prevodenje podataka pomiješanih kod na standardne jezike kao što je engleski mogao bi poboljšati učinkovitost na različitim zadacima pomiješanim kod jer možemo koristiti učenje prijenosa iz modela države umjetnosti engleski za obradu prevedenih podataka. Ovaj papir se fokusira na dvije klasifikacijske zadatke na nivou sekvencije za mješane tekste engleskog-hindskog koda, koji su dio kritike GLUECoS-a - prirodna jezička infekcija i sentimentna analiza. Predlažemo koristiti različite predobučene modele koji su ispravno ispravljeni za slične engleske jedine zadatke i pokazali su stanje umjetnosti. Dodatno ćemo ispravljati te modele na prevedenim brojevima podataka i postići postignući postupak stanja umjetnosti u oba zadatka. Da bi prevodili engleski-hindski kod-pomiješani podaci na engleski jezik, koristili smo mBART, predobučeni multijezički model za sekvenciju koji je pokazao konkurentnu učinku na raznim parovima prevođenja mašin a s niskim resursima i pokazao je i dobitak učinka na jezicima koji nisu bili u svom korpusu predobučenja.', 'da': 'Kodemixering er et almindeligt fænomen i flersprogede samfund rundt om i verden og er især almindeligt i tekster på sociale medier. Traditionelle NLP-systemer, der normalt trænes på ensprogede korpora, fungerer ikke godt på kodeblandede tekster. Det er vanskeligt at uddanne specialiserede modeller til kodeskiftede tekster på grund af manglen på store datasæt. Oversættelse af kodeblandede data til standardsprog som engelsk kan forbedre ydeevnen på forskellige kodeblandede opgaver, da vi kan bruge overførselslæring fra state-of-the-art engelske modeller til behandling af de oversatte data. Denne artikel fokuserer på to sekvensniveau klassifikationsopgaver for engelsk-hindi kode blandede tekster, som er en del af GLUECoS benchmark - Natural Language Inference and Sentiment Analysis. Vi foreslår at bruge forskellige præ-trænede modeller, der er finjusteret til lignende engelsk-kun opgaver og har vist state-of-the-art ydeevne. Vi finjusterer disse modeller yderligere på de oversatte kodeblandede datasæt og opnår state-of-the-art ydeevne i begge opgaver. For at oversætte engelsk-hindi kodeblandede data til engelsk bruger vi mBART, en præ-uddannet flersproget sekvens-til-sekvens model, der har vist konkurrencedygtige resultater på forskellige maskinoversættelsespar med lav ressource og også har vist præstationsgevinster på sprog, der ikke var i dets før-træning korpus.', 'fa': 'در جامعه های زیادی زبان جهان، مختلف در متن رسانه های اجتماعی مشترک است. سیستم\u200cهای NLP سنتی، معمولاً بر یک شرکت تک زبان آموزش داده می\u200cشود، در متن\u200cهای متصل\u200cشده\u200cی کد خوب انجام نمی\u200cدهند. آموزش مدل\u200cهای ویژه\u200cای برای متن\u200cهای تغییر داده شده کد به دلیل ناتوانی داده\u200cهای مقیاس بزرگ سخت است. ترجمه داده های مختلف کد به زبانهای استاندارد مانند انگلیسی می تواند عملکرد روی کار های مختلف کد مختلف را بهتر کند، زیرا می توانیم از مدل های انگلیسی استفاده کنیم که از مدل های وضعیت هنری برای پرداخت داده های ترجمه استفاده کنیم. این کاغذ روی دو دستور مخلوط سطح طبقه\u200cای برای متن\u200cهای مخلوط کد انگلیسی-هندی تمرکز می\u200cکند که بخشی از نقشه\u200cهای GLUECoS - تحلیل زبان طبیعی و سنتی است. ما پیشنهاد می\u200cکنیم از طریق مدل\u200cهای پیش آموزش\u200cشده\u200cای که برای کارهای انگلیسی مشابه\u200cای ساخته شده\u200cاند و اجرای هنری را نشان داده\u200cاند. ما این مدل\u200cها را در مجموعه\u200cهای داده\u200cهای ترجمه\u200cشده با کد ترجمه می\u200cکنیم و به انجام وضعیت هنری در هر دو وضعیت رسیدیم. برای ترجمه داده های مختلف کد انگلیسی-هندی به انگلیسی، ما از mBART استفاده می کنیم، یک مدل پیش آموزش تعریف بسیاری از زبان\u200cها به تعریف که عملکرد رقابتی را در جفت\u200cهای ترجمه\u200cهای ماشین\u200cهای کم منبع نشان داده است، و همچنین به زبان\u200cهای پیش آموزش نشون داده است.', 'de': 'Code-Mixing ist ein häufiges Phänomen in mehrsprachigen Gesellschaften auf der ganzen Welt und vor allem in Social Media Texten üblich. Traditionelle NLP-Systeme, die normalerweise auf einsprachigen Korpora trainiert werden, funktionieren bei Code-Mixed-Texten nicht gut. Die Schulung spezieller Modelle für kodegeschaltete Texte ist aufgrund des Fehlens großer Datensätze schwierig. Die Übersetzung von Code-Mixed-Daten in Standardsprachen wie Englisch könnte die Leistung bei verschiedenen Code-Mixed-Aufgaben verbessern, da wir Transferlernen aus modernsten englischen Modellen für die Verarbeitung der übersetzten Daten nutzen können. Diese Arbeit konzentriert sich auf zwei Klassifizierungsaufgaben auf Sequenz-Ebene für Englisch-Hindi Code Mixed Texte, die Teil des GLUECoS Benchmarks für Natural Language Inference and Sentiment Analysis sind. Wir schlagen vor, verschiedene vortrainierte Modelle zu verwenden, die für ähnliche Aufgaben nur in Englisch optimiert wurden und auf dem neuesten Stand der Technik sind. Wir optimieren diese Modelle weiter auf den übersetzten Code-Mixed-Datensätzen und erzielen in beiden Aufgaben eine State-of-the-Art-Performance. Um Englisch-Hindi-Code-Mixed-Daten ins Englische zu übersetzen, verwenden wir mBART, ein vortrainiertes mehrsprachiges Sequenz-zu-Sequenz-Modell, das eine wettbewerbsfähige Leistung bei verschiedenen ressourcenarmen maschinellen Übersetzungspaaren gezeigt hat und auch Leistungszuwächse in Sprachen gezeigt hat, die nicht in seinem Pre-Training-Korpus waren.', 'id': 'Pengcampuran kode adalah fenomena umum dalam masyarakat berbagai bahasa di seluruh dunia dan terutama umum dalam teks media sosial. Traditional NLP systems, usually trained on monolingual corpora, do not perform well on code-mixed texts.  Latihan model khusus untuk teks yang ditukar kode sulit karena kekurangan set data skala besar. Menerjemahkan data campuran kode ke bahasa standar seperti bahasa Inggris dapat meningkatkan prestasi pada berbagai tugas campuran kode karena kita dapat menggunakan transfer belajar dari model Inggris terbaik untuk memproses data terjemahkan. Kertas ini fokus pada dua tugas klasifikasi tingkat urutan untuk teks campuran kode Inggris-Hindi, yang merupakan bagian dari benchmark GLUECoS - Natural Language Inference and Sentiment Analysis. Kami mengusulkan menggunakan berbagai model terlatih yang telah disesuaikan untuk tugas bahasa Inggris yang sama dan telah menunjukkan prestasi terbaik. Kami lebih memperbaiki model ini pada set data terjemahan kode-campuran dan mencapai prestasi state-of-the-art dalam kedua tugas. Untuk menerjemahkan data berbagai kode bahasa Inggris-Hindi ke bahasa Inggris, kami menggunakan mBART, model berbagai berbagai berbagai berbagai berbagai berbagai berbagai berbagai berbagai berbagai bahasa yang telah menunjukkan prestasi kompetitif pada berbagai pasangan mesin terjemahan sumber daya rendah dan juga menunjukkan perkembangan prestasi dalam bahasa yang tidak berada dalam korpus pre-pelatihan.', 'af': "Code-mixing is 'n gemeenskaplike fenomen in multilinglike samelewing rondom die wêreld en is veral gemeenskaplik in sosiale media tekste. Tradisjoneel NLP-stelsels, gewoonlik onderwerp op monolinglike korpora, doen nie goed uitvoer op kode gemengde teks. Onderwysing spesialiseerde modele vir kode- wissel teks is moeilik vanweë die ontbreek van groot- skaal datastelle. Vertaling van kode gemengde data in standaard tale soos Engels kon uitvoerings op verskeie kode gemengde taak verbeter omdat ons kan gebruik oordrag leer van state-of-the-art Engels modele vir die verwerking van die vertalinge data. Hierdie papier fokus op twee volgorde-vlak klasifikasie taak vir Engels-Hindi kode gemengde teks, wat is deel van die GLUECoS benchmark - Natuurlike taal belangriking en Sentiment Analisie. Ons voorstel om verskillende voorafgeleerde modele te gebruik wat vir soortgelyke Engelske slegs taak gevind is en het die state-of-the-art-performance vertoon. Ons het hierdie modele verder fin-tuneer op die vertaalde kode-gemengde datastelle en die state-of-the-art-prestasie in beide opdragte bereik. Om Engels-Hindi kode-gemengde data na Engels te vertaal, gebruik ons mBART, 'n voorafoerende multitaalske sekwensie-na-sekwensie model wat gemengde effektuur vertoon het op verskeie lae-hulpbron masjien-vertaal pare en het ook uitvoerings in tale wat nie in sy voorafoerening korpus was nie.", 'ko': '세계 각지의 다언어 사회에서 코드 혼합은 흔히 볼 수 있는 현상으로 소셜 미디어 텍스트에서 특히 흔히 볼 수 있다.전통적인 NLP 시스템은 통상적으로 단어 자료 라이브러리에서 훈련을 하지만 코드가 혼합된 텍스트에서는 좋지 않다.대규모 데이터 집합이 부족하기 때문에 코드 변환 텍스트의 전문 모델 훈련은 매우 어렵다.코드 혼합 데이터를 표준 언어(예를 들어 영어)로 번역하면 각종 코드 혼합 작업의 성능을 향상시킬 수 있다. 왜냐하면 우리는 가장 선진적인 영어 모델에서 나온 이동 학습을 사용하여 번역된 데이터를 처리할 수 있기 때문이다.본고는 주로 GLUECoS 기준 테스트 중의 두 가지 서열급 분류 임무인 자연 언어 추리와 감정 분석을 연구한다.우리는 유사한 순수한 영어 임무에 적용되고 가장 선진적인 성능을 나타내는 각종 사전 교육을 받은 모델을 사용하는 것을 권장한다.우리는 번역된 코드 혼합 데이터 집합에서 이러한 모델을 더욱 미세하게 조정하고 이 두 가지 임무에서 가장 선진적인 성능을 실현한다.영어-인디언 코드 혼합 데이터를 영어로 번역하기 위해 우리는 mBART를 사용했다. 이것은 사전 훈련을 거친 다중 언어 서열 대조 서열 모델로 각종 저자원 기계 번역 대조에서 경쟁적인 성능을 나타냈고 예비 훈련 자료 라이브러리에 없는 언어에서도 성능 향상을 나타냈다.', 'am': "Code-mixing is a common phenomenon in multilingual societies around the world and is especially common in social media texts.  የባሕላዊው የNLP ስርዓት፣ በሞሎልጋል ኮርፖርት ላይ የተጠቃሚ፣ በcode-mixed ጽሑፎችን መልካም አያደርጉም፡፡ ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s የኮድ-mixed data ወደ standard ቋንቋዎች እንደሚደረግ እንግሊዘኛ የኮድ-mixed ስራዎችን ለማድረግ ይችላል፡፡ ይህ ፕሮግራም በሁለት ክፍለ ደረጃ ክፍተቶችን ለመጠቀም የኢንጂልኛ-Hindi ኮድ በተለየ ጽሑፎች ላይ ያስተካክላል፤ ይህም የGLUECoS benchmark - የባሕላዊ ቋንቋ ማጠቃለያ እና ሰዓት Analysis. በተመሳሳይ እንግሊዘኛ-ብቻ ስራ የተጠቀሙትን የፊተኛ ተማሪ ሞዴላዎችን በመጠቀም እና የዓለማዊ ድረ ገጽ እናሳየዋለን፡፡ እነዚህን ምሳሌዎች በተለፉት ኮድ-የተለየ ዳታዎችን እናደርጋለን እና በሁለቱም ስራ ውስጥ የ-የ-አርእስት ሁኔታ እናደርጋለን፡፡ እንግሊዘኛ-Hindi ኮድ-mixed data ወደ እንግሊዝኛ ለመለየት MBART፣ pre-trained multilingual sequence-to-sequence model እናስቀምጣለን፡፡", 'sw': 'Kuchanganya sheria ni jambo la kawaida katika jamii za lugha mbalimbali duniani kote na hususani katika maandishi ya mitandao ya kijamii. Mifumo ya kitamaduni ya NLP, kwa kawaida hufunzwa kwenye makampuni ya kiutamaduni, hawafanyi vizuri kwenye maandishi yanayochanganyika kwa kodi. Kufundisha mifano maalumu kwa ajili ya ujumbe wa kubadilisha kodi ni vigumu kutokana na ukosefu wa seti kubwa za taarifa. Kutafsiri taarifa zilizochanganyika kwa utaratibu katika lugha za kawaida kama vile Kiingereza kunaweza kuboresha utendaji wa kazi mbalimbali za kodi kwa sababu tunaweza kutumia kujifunza kutoka miundo ya Kiingereza ya aina ya sanaa kwa ajili ya kuchukua taarifa zilizotafsiriwa. This paper focuses on two sequence-level classification tasks for English-Hindi code mixed texts, which are part of the GLUECoS benchmark - Natural Language Inference and Sentiment Analysis.  Tunazipendekeza kutumia mifano mbalimbali ya mafunzo ya awali ambazo zimekuwa vizuri kwa kazi kama hizo tu za Kiingereza na tumeonyesha hali ya utendaji wa sanaa. Tunaendelea vizuri zaidi mifano hii kwenye seti za taarifa zinazotafsiriwa kwa mfumo na kutekeleza hali ya sanaa katika kazi zote. Kutafsiri takwimu zilizochanganyika kwa Kiingereza za-Hindi kwa Kiingereza, tunatumia mBART, modeli iliyoendelea kwa mfululizo wa lugha mbalimbali kwa mfululizo ambao umeonyesha ufanisi wa ushindani katika tafsiri za mashine za chini ya rasilimali na pia kuonyesha mafanikio ya ufanisi katika lugha ambazo hazikuwa katika makampuni yake ya mafunzo ya kabla.', 'tr': "Kod karışmasy dünýäde birnäçe dilli jemgyýetlerde orta döwüridir we olaryň üstüne sosial mediýalar metinlerinde orta döwüridir. Däpli NLP sistemleri, adatça monolingüň korporatynda bilinmeýän, kodlarda karışmış metinlerde gaty bir şekilde işlemeýär. Ködleme üýtgeden metinler üçin aýratyn nusgalar uly ölçek datasetleri ýok bolmagy üçin kyn. Iňlisçe ýaly cödlemeler karışmış maglumatlary iňlis dillerine terjime etmek üçin, terjime edilen maglumatlary işlemek üçin, beýleki cödlemeler karışyp barlap biler. Bu kagyz Iňlisçe-Hindi kodyň karışylşyk metinleri üçin iki düzgün dereje klasifikasyň täbliklerine fokus edýär. Bu käze GLUECoS benchmarkynyň bir bölegidir - Dobiýal dil teňkil we Sentiment Analiziýasynyň. Biz diňe iňlis dilinde meňzeş görenler üçin düzgün bilim taýýarlanan örän öň-bilim nusgalaryny ulanmagy teklip edip görýäris. Biz bu nusgalary terjime edilen kodlarda karışyp veri setirlerinde bejerdik we her iki işde durum-of-the-art eserini ýetip bileris. Iňlisçe-hindi ködlemeleri iňlisçe terjime etmek üçin mBART'y ulanýarys. Öň öňünde bilim taýýarlanan bir köp dilli sequencer nusgasyna görkezilen ýagdaýda täsirli taýýarlanan maşynyň terjime eden çiftlerde täsirli täsirler görkezilen we hem öz öňünde durmadyk dillerde täsirli täsirler", 'az': 'Kod karışması dünyadakı çoxlu dil toplumlarında ortaq bir parçadır və özlərinə də sosyal media textlərində ortaq. NLP sistemləri, genellikle monodil korporasında təhsil edilmiş, kodu karışmış mətnlərdə yaxşı işləməz. Kod-dəyişdirilmiş mətnlər üçün xüsusiyyətli modellərin təhsil edilməsi böyük ölçü veri qurğuları yoxdur. İngilizə kimi kodla karışmış məlumatları standart dillərə tercümə etmək müxtəlif kodla karışmış işlərdə performans daha yaxşı olar, çünki biz tercümə məlumatlarını işləmək üçün İngilizə modellerindən öyrənmək öyrənməyi istifadə edə bilərik. Bu kağıt İngilizce-Hindi kodu karıştırılmış metinlər üçün iki seçmə seviyyəti klasifikasiya görevlərinə odaqlanır, GLUECoS benchmark ının bir parçasıdır - Təbiətli Dil Inference və Sentiment Analizi. Biz müxtəlif əvvəlcə təhsil edilmiş modelləri istifadə edirik ki, bənzər İngilizə təhsil edilmiş, yalnız İngilizə təhsil edilmiş və sanat performansını göstərdik. Biz bu modelləri tərcümə edilmiş kodu karıştırılmış veri setlərinə daha çox təmizləyirik və hər iki işdə mövcud-müzikat performansını başa çatdırırıq. İngilizce-Hindi kodu ilə İngilizce dilinə çevirmək üçün, mBART, əvvəlcə təhsil edilmiş çoxlu dil sequence-to-sequence modeli ilə istifadə edirik ki, müxtəlif düşük-ressurs maşın çeviri çiftlərdə müəllif performans göstərir və həmçin in əvvəl təhsil edilməmiş korpusda olmayan dillərdə performans kazanmışdır.', 'bs': 'Mešanje kodova je zajednički fenomen u multijezičkim društvima širom svijeta i posebno je zajednički u tekstima društvenih medija. Tradicionalni NLP sistemi, obično obučeni na monojezičkom korporaciji, ne izvode dobro na tekstima mešanih kod. Treniranje specijalizovanih modela za tekstove zamijenjene kod je teško zbog nedostatka velikih podataka. Prevodenje podataka pomiješanih kod na standardne jezike kao što je engleski mogao bi poboljšati izvođenje na različitim zadacima pomiješanim kodom jer možemo koristiti učenje premeštaja iz modela države umjetnosti engleski za obradu prevedenih podataka. Ovaj papir se fokusira na dva klasifikacijska zadatka na nivou sekvence za tekste mešane engleskog-hindskog koda, koji su dio kritike GLUECoS - prirodna jezika Inferencija i Sentimentna analiza. Predlažemo da koristimo različite predobučene modele koji su ispravno ispravljeni za slične engleske jedine zadatke i pokazuju predstavu umjetnosti. Dalje ćemo ispravljati te modele na prevedenim brojima podataka i postići izvršnost stanja umjetnosti u oba zadatka. Da bi prevodili engleski-hindski kod-pomiješani podaci na engleski jezik, koristili smo mBART, predobučeni multijezički model sekvence do sekvence koji je pokazao konkurentnu učinku na raznim parovima prevođenja mašin a s niskim resursima i pokazao je i dobitak učinka na jezicima koji nisu bili u svom korpusu predobučenja.', 'bn': 'কোড মিশ্রণ বিশ্বের বহুভাষী সমাজের মধ্যে একটি সাধারণ ঘটনা এবং বিশেষ করে সামাজিক মিডিয়া টেক্সটে সাধারণ। ঐতিহ্যবাহী এনএলপি সিস্টেম, সাধারণত মোনোলিভাল কোর্পোরায় প্রশিক্ষণ প্রদান করা হয়, কোড মিশ্রিত টেক্সটে ভালো কা কোড- switchComment অনুবাদ করা তথ্য প্রক্রিয়ার জন্য কোড মিশ্রিত কাজের বিভিন্ন কোড-মিশ্রিত কাজে কোড- মিশ্রিত তথ্য অনুবাদ করতে পারে যেহেতু আমরা রাষ্ট্র-অফ-ই- এই কাগজটি ইংরেজি-হিন্দি কোড মিশ্রিত টেক্সটের দুই সেকেন্ড-স্তরের ক্লাসেফ কাজের উপর মনোযোগ দিয়েছে, যা GLUES বেনকম্যার্ক - প্রাকৃতিক ভাষা এন আমরা প্রস্তাব করছি বিভিন্ন প্রশিক্ষিত মডেল ব্যবহার করা যারা একই ধরনের ইংরেজী শুধুমাত্র কাজের জন্য ভালোভাবে সুন্দর করা হয়েছে এবং  আমরা অনুবাদ করা কোড মিশ্রিত ডাটাসেটে এই মডেলগুলোকে আরো ভালোভাবে সুন্দর করি এবং দুই কাজের মধ্যে শিল্পের অবস্থা অর্জন করি। ইংরেজি-হিন্দি কোড-মিশ্রিত তথ্য ইংরেজীতে অনুবাদ করার জন্য আমরা এমবিআরটি ব্যবহার করি, একটি পূর্ব প্রশিক্ষিত বহুভাষী সেকেন্স-থেকে সেকেন্সের মডেল, যা বিভিন্ন কম-সম্পদ মেশিন অনুবাদের', 'ca': "Code-mixing is a common phenomenon in multilingual societies around the world and is especially common in social media texts.  Els sistemes tradicionals de NLP, normalment entrenats en corpora monolingüa, no funcionen bé en textos combinats amb codis. La formació de models especialitzats per textos canviats de codi és difícil a causa de la falta de conjunts de dades a gran escala. La traducció de dades combinades amb codi a llengües estàndard com l'anglès podria millorar el rendiment de diverses tasques combinades amb codi, ja que podem utilitzar l'aprenentatge de transfer ència dels models d'anglès més moderns per processar les dades traduïdes. Aquest paper es centra en dues tasques de classificació a nivell de seqüència per a textes mixts de codi anglès-hindí, que formen part del criteri de referència GLUECoS - Inferència de llenguatge natural i Anàlisi de Sentiments. Proposem utilitzar diversos models pré-entrenats que han estat ajustats per tasques similars només en anglès i que han mostrat actuació moderna. També millorem aquests models en els conjunts de dades mixtes traducits i aconsegueixem el desempeny més avançat en ambdues tasques. Per traduir les dades combinades entre codi anglès i hindí a anglès, utilitzem mBART, un model de seqüència a seqüència multilingüe pré-entrenat que ha demostrat rendiment competitiu en diversos parells de traducció de màquines de baix recursos i també ha demostrat guanys de rendiment en llengües que no estaven al seu cos de pré-entrenament.", 'cs': 'Mixování kódu je běžným jevem v mnohojazyčných společnostech po celém světě a je obzvláště běžné v textech sociálních médií. Tradiční NLP systémy, obvykle trénované na jednojjazyčných korpusech, nefungují dobře na textech smíšených kódem. Školení specializovaných modelů pro kódově přepínané texty je obtížné kvůli nedostatku rozsáhlých datových sad. Překlad dat smíšených kódem do standardních jazyků, jako je angličtina, by mohl zlepšit výkon při různých úkolech smíšených kódem, protože pro zpracování přeložených dat můžeme využít transferové učení z nejmodernějších anglických modelů. Tento článek se zaměřuje na dvě klasifikační úlohy na úrovni sekvence pro anglicko-hindské smíšené texty kódu, které jsou součástí GLUECoS benchmarku Inference a Sentiment Analysis. Navrhujeme použití různých předškolených modelů, které byly vyladěny pro podobné úkoly pouze v angličtině a prokázaly nejmodernější výkon. Tyto modely dále doladíme na přeložených datových sadách smíšených kódem a dosahujeme špičkového výkonu v obou úkolech. Pro překlad anglicko-hindských dat smíšených kódem do angličtiny používáme mBART, předškolený vícejazyčný model sekvence-sekvence, který prokázal konkurenční výkon u různých strojových párů s nízkými zdroji a rovněž prokázal zvýšení výkonu v jazycích, které nebyly v jeho předškolicím korpusu.', 'et': 'Koodide segamine on levinud nähtus mitmekeelsetes ühiskondades kogu maailmas ja eriti levinud sotsiaalmeedia tekstides. Traditsioonilised NLP-süsteemid, mis on tavaliselt koolitatud ühekeelsetele korpustele, ei toimi hästi koodisegatud tekstide puhul. Koodivahetusega tekstide spetsialiseerunud mudelite koolitamine on raske suuremahuliste andmekogumite puudumise tõttu. Koodidega segatud andmete tõlkimine standardkeeltesse, nagu inglise keel, võib parandada erinevate koodisegatud ülesannete tulemuslikkust, kuna saame tõlgitud andmete töötlemiseks kasutada ülekandeõpet kaasaegsetest inglise mudelitest. Käesolev töö keskendub kahele järjestustasemel klassifitseerimisülesandele inglise-hindi koodisegatud tekstidele, mis on osa GLUECoSi võrdlusalusest - loodusliku keele järelduste ja sentimentaalüüsi analüüsist. Pakume kasutada erinevaid eelõpetatud mudeleid, mis on täpselt häälestatud sarnaste ainult inglise keele ülesannete jaoks ja on näidanud kaasaegset jõudlust. Täiendavalt täpsustame neid mudeleid tõlgitud koodisega andmekogumitele ja saavutame mõlemas ülesandes tipptasemel jõudluse. Inglise-hindi koodisegatud andmete tõlkimiseks inglise keelde kasutame mBART-i, eelkoolitud mitmekeelset jadast järjestusse mudelit, mis on näidanud konkurentsivõimet erinevate vähese ressursiga masintõlkepaaride puhul ning on näidanud ka tulemuslikkust keeltes, mis ei olnud koolituseelses korpuses.', 'fi': 'Koodien sekoittaminen on yleinen ilmiö monikielisissä yhteiskunnissa ympäri maailmaa ja on erityisen yleistä sosiaalisen median teksteissä. Perinteiset monikielisiin korpusiin koulutetut NLP-järjestelmät eivät toimi hyvin koodisekoitetuissa teksteissä. Koodinvaihtotekstien erikoismallien kouluttaminen on vaikeaa suurten tietoaineistojen puutteen vuoksi. Koodisekoisen datan kääntäminen standardikielille, kuten englanniksi, voisi parantaa suorituskykyä erilaisissa koodisekoitetuissa tehtävissä, koska voimme käyttää siirtooppimista viimeisimpien englanninkielisten mallien avulla käännettyjen tietojen käsittelyyn. Tämä artikkeli keskittyy kahteen sekvenssitason luokittelutehtävään englanti-hindi-koodisekoitetuille teksteille, jotka ovat osa GLUECoS-vertailua - Natural Language Inference and Sentiment Analysis. Ehdotamme erilaisten esikoulutettujen mallien käyttöä, jotka on hiottu samankaltaisiin englanninkielisiin tehtäviin ja jotka ovat osoittaneet huippuluokan suorituskykyä. Tarkennamme edelleen näitä malleja käännetyihin koodisekoitettuihin aineistoihin ja saavutamme huipputason suorituskyvyn molemmissa tehtävissä. Englannin ja hindin koodisekoitetun datan kääntämiseksi englanniksi käytämme mBART-mallia, joka on esitelty monikielinen sekvenssi-sekvenssimalli, joka on osoittanut kilpailukykyä useilla vähäresurssisilla konekäännöspareilla ja osoittanut suorituskykyä myös kielillä, jotka eivät kuuluneet sen esikoulutukseen.', 'hy': 'Code-mixing is a common phenomenon in multilingual societies around the world and is especially common in social media texts.  Հավանդական ՆԼՊ համակարգերը, որոնք սովորաբար պատրաստված են միալեզվով կոպորա վրա, լավ չեն աշխատում կոդի խառնված տեքստների վրա: Training specialized models for code-switched texts is difficult due to the lack of large-scale datasets.  Translating code-mixed data into standard languages like English could improve performance on various code-mixed tasks since we can use transfer learning from state-of-the-art English models for processing the translated data.  This paper focuses on two sequence-level classification tasks for English-Hindi code mixed texts, which are part of the GLUECoS benchmark - Natural Language Inference and Sentiment Analysis.  Մենք առաջարկում ենք օգտագործել բազմաթիվ նախապատրաստված մոդելներ, որոնք լավագույնել են նման անգլերեն միայն խնդիրների համար և ցույց են տալիս ամենահետաքրքիր ներկայացումներ: We further fine-tune these models on the translated code-mixed datasets and achieve state-of-the-art performance in both tasks.  Անգլերեն-հնդիացի կոդի խառնված տվյալները անգլերեն թարգմանելու համար մենք օգտագործում ենք mBAR-ը, մի նախապատրաստված բազմալեզու հաջորդականություն հաջորդականության մոդել, որը ցույց է տալիս մրցակցություն բազմաթիվ ցածր ռեսուրսների մեքենայի թարգմանման զույգերի վրա և ցու', 'sq': 'Code-mixing is a common phenomenon in multilingual societies around the world and is especially common in social media texts.  Sistemet tradicionale NLP, zakonisht të trajnuar në korpra monogjuhësore, nuk funksionojnë mirë në tekstet e përziera me kode. Trenimi i modeleve të specializuar për tekstet e ndërruar me kod është i vështirë për shkak të mungesës së grupeve të dhënash në shkallë të madhe. Translating code-mixed data into standard languages like English could improve performance on various code-mixed tasks since we can use transfer learning from state-of-the-art English models for processing the translated data.  Ky dokument përqëndrohet në dy detyra klasifikuese të nivelit të sekuencës për tekstet e përziera të kodit anglez-Hindi, të cilat janë pjesë e referencës GLUECoS - Natural Language Inference and Sentiment Analysis. Ne propozojmë përdorimin e modeleve të ndryshëm të paratrajnuar që janë rregulluar për detyra të ngjashme të vetme angleze dhe kanë treguar shfaqje më të larta. We further fine-tune these models on the translated code-mixed datasets and achieve state-of-the-art performance in both tasks.  Për të përkthyer të dhënat e përziera anglisht-hindisht në anglisht, ne përdorim mBART, një model shumë gjuhësh të stërvitur nga sekuenca në sekuencë që ka treguar performancë konkurruese në çifte të ndryshme të përkthimit të makinave me burime të ulta dhe ka treguar gjithashtu fitime performance në gjuhët që nuk ishin në korpusin e tij të parastërvitjes.', 'sk': 'Mešanje kod je pogost pojav v večjezičnih družbah po svetu in je še posebej pogost v besedilih na družbenih omrežjih. Tradicionalni sistemi NLP, običajno usposobljeni za enojezične korpuse, ne delujejo dobro pri besedilih, mešanih s kodami. Usposabljanje specializiranih modelov za besedila s preklopom kod je težko zaradi pomanjkanja obsežnih naborov podatkov. Prevajanje podatkov z mešanimi kodami v standardne jezike, kot je angleščina, bi lahko izboljšalo učinkovitost pri različnih opravilih z mešanimi kodami, saj lahko za obdelavo prevedenih podatkov uporabimo prenosno učenje iz najsodobnejših angleških modelov. Ta prispevek se osredotoča na dve klasifikacijski nalogi na ravni zaporedja za angleško-hindijsko kodno mešana besedila, ki sta del referenčne vrednosti GLUECoS - Naravni jezik Inference in Sentiment Analysis. Predlagamo uporabo različnih vnaprej usposobljenih modelov, ki so bili natančno nastavljeni za podobne naloge samo v angleščini in so pokazali vrhunsko zmogljivost. Te modele nadalje natančno nastavimo na prevedene kodno mešane nabore podatkov in dosegamo najsodobnejše delovanje pri obeh nalogah. Za prevod angleško-hindijsko-kodno mešanih podatkov v angleščino uporabljamo mBART, vnaprej usposobljen večjezični model zaporedja v zaporedje, ki je pokazal konkurenčno učinkovitost pri različnih parih strojnega prevajanja z nizkimi viri in izboljšal učinkovitost pri jezikih, ki niso bili v njegovem korpusu pred usposabljanjem.', 'jv': 'Ko-Mixing iki dadi sing mengko ana ing sakjane kanggo kalaha luwih-luwih ning dunya karo sak popularan sing dikarolan ning texti media sotiki. Tradisyonal NLP sistem, sadurungé kelas akeh lan sampeyan ingkang sampeyan, ora tau ngerasahan barang kotak-sampeyan seneng kaper. politenessoffpolite"), and when there is a change ("assertivepoliteness Nyambungan kode-Mixed data nganggo langgambar kanggo inggiles Ngawe Perintah iki ulih langgambar kelas telas-kalih panjenengan kanggo ngerasakno gambar ingkang-hini kode biretek panjenengan, wong wis akèh ning GLUECoS bench - Normal Language Info lan Sentiment Test. Awak dhéwé nggunakake sistem sing sampeyan banter model sing bisa dianggap ileh dumateng kanggo barang nggambar obah dumateng Inggris-kebutuhake lan wis ngerasakno state-of-the-arts gawan. We Label kanggo terjamahan kelas perangkat-hend kuwi nggambar kelas telas ing Inggris, awake dhewe ngulinakake mLPRT , model sing dibutuhake multi-ngen multi-ngen sistem sing wis dipungot nggawe gerangkamu akeh operasi sing paling-perusahaan anyar sampeyan pangan lan tambah bantuan itolet langkung pakan kuwi ora ono nggawe gerangkamu koyo cah dumaten.', 'he': 'התערבות קודים היא תופעה נפוצה בחברות רבות שפות בכל העולם והיא נפוצה במיוחד בטקסטים של התקשורת החברתית. מערכות NLP מסורתיות, בדרך כלל מאומנות על גופורה monolingual, לא מצליחות טוב על טקסטים מעורבים קוד. אימון מודלים מיוחדים לטקסטים שמחליפים קודים קשה בגלל חוסר קבוצת נתונים בקנה מידה גדולה. העברת נתונים מעורבים בקוד לשפות סטנדרטיות כמו אנגלית יכולה לשפר את ההופעה על משימות שונות מעורבות בקוד מאחר שאנחנו יכולים להשתמש בהעברה למידה ממודלים אנגליים חדשים לעבוד את נתונים התרגמים. העבודה הזו מתמקדת בשני משימות סיווג רמת רצף עבור טקסטים מעורבים קוד אנגלי-הינדי, שהם חלק מהנקודת השיחה GLUECoS - טבעית שפת אינפרנציה וניתוח רגשות. We propose using various pre-trained models that have been fine-tuned for similar English-only tasks and have shown state-of-the-art performance.  אנחנו מתאימים יותר את הדוגמנים האלה על קבוצות נתונים מעורבות קודים מתרגמים ולהשיג ביצועים חדשים בשני המשימות. כדי לתרגם נתונים מעורבים אנגלי-הינדי לאנגלית, אנו משתמשים באנגלית mBART, מודל רצף-רצף-רצף multilingual מאומן מראש שהופיע ביצועים תחרותיים על זוגות מכונות תרגום משאבים נמוכים שונים', 'ha': "Koda-haɗiyar kodi yana da abu mai jama'a a cikin jamii masu mulki na addu'a dukkan dũniya kuma yana da amfani da matsayin mitandaki na jamii. KCharselect unicode block name @ info: whatsthis @ info: whatsthis Wannan karatun na fokus a kan aikin classified-daraja biyu na sequence wa kodi na Ingiriya-Hindu da aka haɗa matsayin, wanda na zama part of the GLUECoS bangon-GLUECoS - Analyze na Lugha na Tsararre da Akwaici. Tunamaɗa su yi amfani da wasu misãlai masu yin zaman-tunni waɗanda aka samar da su zuwa aikin da ke daidaita kawai-Ingirinsa kuma Mun nuna halin-da-sanar. Mu sami koda waɗannan misãlai kan kodi-da aka fassar-da-danganta kuma ke sami halin-da-art cikin aikin duk biyu. To translate English-Hindi code-mixed data to English, we use mBART, a pre-trained multilingual sequence-to-sequence model that has shown competitive performance on various low-resource machine translation pairs and has also shown performance gains in languages that were not in its pre-training corpus.", 'bo': 'སྐད་རིགས་འདི་དག་གི་སྤྱི་ཚོགས་ཀྱི་ཆ་འཕྲིན་གྱི་སྤྱི་ཚོགས་ཁྱད་པར་མཐུན་རྐྱེན་ཅིག་རེད། སྔོན་སྲོལ་གྱི་NLP མ་ལག་གིས་རྒྱུན་ལྡན་ངོ་སྐད་ཀྱི་དབུགས་ཡུལ་གྱིས་ཕན་ཚུན་ལས་སྦྱོར་བྱེད་ཡོད། དབྱིབས་སྤྱད་ནས་དབྱིབས་གཏོང་གི་མིག Translating code-mixed data into standard languages like English can improve performance on various code-mixed tasks since we can use transfer learning from state-of-the-art English models for processing the translated data. ཤོག We propose using various pre-trained models that have been fine-tuned for similar English-only tasks and have shown state-of-the-art performance. We further fine-tune these models on the translated code-mixed datasets and achieve state-of-the-art performance in both tasks. To translate English-Hindi code-mixed data to English, we use mBART, a pre-trained multilingual sequence-to-sequence model that has shown competitive performance on various low-resource machine translation pairs and has also shown performance gains in languages that were not in its pre-training corpus.'}
{'en': 'Exploring Text-to-Text Transformers for English to Hinglish Machine Translation with Synthetic Code-Mixing', 'ar': 'استكشاف محولات تحويل النص إلى نص للترجمة الآلية من الإنجليزية إلى الإنجليزية باستخدام خلط الشفرات الاصطناعية', 'pt': 'Explorando transformadores de texto para texto para tradução automática de inglês para hinglish com mistura de código sintético', 'es': 'Exploración de los transformadores de texto a texto para la traducción automática del inglés al hinglish con mezcla de código sintético', 'ja': '合成コードミキシングによる英語からヒンギス語への機械翻訳のためのテキストツーテキスト変換の探求', 'zh': '寻文本至文本转换器,施于英语至英语英语机器翻译与合成代码合', 'hi': 'सिंथेटिक कोड-मिश्रण के साथ हिंग्लिश मशीन अनुवाद के लिए अंग्रेजी के लिए पाठ-से-पाठ ट्रांसफॉर्मर की खोज', 'ru': 'Изучение текстовых трансформаторов для машинного перевода с английского на хинглиш с синтетическим смешиванием кодов', 'fr': "Explorer les transformateurs texte-texte pour la traduction automatique de l'anglais vers le hinglish avec le mixage de code synthétique", 'ga': 'Claochladáin Téacs-go-Téacs a Iniúchadh le haghaidh Aistriúchán Meaisínithe ó Bhéarla go Hinglish le Có-mheascadh Sintéiseach', 'hu': 'Szöveg-szöveg transzformátorok feltárása angol-hinglish gépi fordításhoz szintetikus kódkeveréssel', 'ka': 'ტექსტიდან ტექსტის ტრანფორმაციების გამოყენება ინგლისური სინტეტიკური კოდის შემწყენებაში მაქსინის შემწყენება', 'el': 'Εξερεύνηση μετασχηματιστών κειμένου-κειμένου για αγγλική σε ινδιάνικη μηχανική μετάφραση με συνθετική ανάμειξη κώδικα', 'it': 'Esplorare i trasformatori da testo a testo per la traduzione automatica inglese a hinglish con la miscelazione di codici sintetici', 'kk': 'Ағылшынша мәтіннен мәтіннің түрлендірушілерін синтетикалық код- микшерлендіру арқылы Hinglish Machine аударуына зерттеу', 'lt': 'Eksploatuojami teksto į teksto transformatoriai anglų kalba į Hinglish mašinų vertimą derinant sintetinius kodus', 'ms': 'Menjelaskan Penukar Teks-Teks untuk Perjemahan Mesin Bahasa Inggeris ke Hinglish dengan Pencampuran Kod Sintetik', 'ml': 'ഇംഗ്ലീഷിലേക്കുള്ള പദാവലിയിലേക്ക്- ടെക്സ്റ്റ് ട്രാന്\u200dസ്ഫോര്\u200dഫര്\u200dമാര്\u200d വിശദീകരിക്കുന്നു', 'mt': 'L-esplorazzjoni tat-Trasformaturi tat-Test għat-Test għall-Ingliż għat-Traduzzjoni tal-Magna Hinglish bit-Taħlita tal-Kodiċi Sintetiku', 'no': 'Utforskar tekst- til- teksttransformerer for engelsk til Hinglish Machine Translation with Synthetic Code- Mixing', 'pl': 'Eksploracja transformatorów tekstu do tekstu dla tłumaczenia maszynowego z języka angielskiego na Hinglish za pomocą syntetycznego mieszania kodu', 'ro': 'Explorarea transformatoarelor text-în-text pentru traducerea automată din engleză în hinglish cu amestecarea de coduri sintetice', 'mk': 'Истражување на текст- во- текст трансформирачи за англиски на инглиски превод на машина со синтетичко мешање на кодови', 'si': 'ඉංග්\u200dරීසිය සඳහා පාළුවෙන් පාළුවෙන් පරිවර්තනය කරන්නේ ඉංග්\u200dරීසිය සඳහා සංවේදනය කෝඩ- මික්ස්', 'sr': 'Изгледање трансформатора текста на текст за английски на трансформацију машине с синтетичним код-мешањем', 'sv': 'Utforska text-till-text transformatorer för engelsk till hinglisk maskinöversättning med syntetisk kodblandning', 'mn': 'Текст-болон-Текст шилжүүлэгчид Англи хэлний хэлний хувьд Синтетик код-холбогдолтой машин хөгжүүлэх', 'so': 'Turjumista Text-to-Text Transformers for Ingiriis to Hinglish Machine Translation with Synthetic Code-Mixing', 'ta': 'Name', 'ur': 'انگلیسی کے لئے متن سے متن تغییر پھیلانے والوں کو سینٹیسی کوڈ-میکسنگ کے ساتھ ہینگلیس ماشین تغییر پھیلانے کے لئے تحقیق کی جاتی ہے', 'vi': 'Khám phá bộ Chuyển đổi văn bản cho tiếng Anh sang máy nén Name', 'uz': 'Name', 'hr': 'Istražujem transformatore teksta na tekst za engleski na prevod stroja s sintetičkim mješanjem kodova', 'nl': 'Het verkennen van tekst-naar-tekst transformators voor Engels naar Hinglish machinevertaling met synthetische codemenging', 'da': 'Udforsk tekst-til-tekst transformatorer til engelsk til hinglisk maskinoversættelse med syntetisk kode-blanding', 'bg': 'Изследване на текстови трансформатори за машинен превод от английски към хинглиш с синтетично смесване на кодове', 'fa': 'توسعه تغییردهندگان متن به متن برای انگلیسی به ترجمه ماشین Hinglish با رمز پیوند سینتیک', 'id': 'Menjelaskan Transformer Teks-Teks untuk Bahasa Inggris ke Translation Mesin Hinglish dengan Pengcampuran Kode Sintetis', 'de': 'Text-zu-Text-Transformatoren für die maschinelle Übersetzung von Englisch in Hinglish mit synthetischer Codemischung erkunden', 'tr': 'Iňlisçe üçin Metin-we Metin Terjimelerini Sintetik Ködleme bilen Ýagtylamak üçin Iňlisçe terjime etmekler', 'af': 'Verskyn Teks- na- Teks Transformeerders vir Engels na Hinglish Masjien Vertaling met Sintetiese Kode- Menger', 'sq': 'Shqyrtimi i Transformuesve Tekst-Tekst për anglisht në Hinglish Machine Translation me Synthetic Code-Mixing', 'ko': '합성 코드를 혼합하여 영어를 한영 영어로 탐색하다', 'hy': 'Անգլերենի տեքստի-տեքստի փոխարինողների ուսումնասիրությունը անգլերենի դեպի հինգլերեն մեքենայի փոխարինումը սինթետիկ կոդի խառնման միջոցով', 'sw': 'Tafsiri ya Mashine ya Kiingereza kwa ajili ya Kiingereza Kutafsiri kwa Kiungo cha Kusindika', 'az': 'Sintetik Kod-KarńĪŇümasńĪ il…ô ńįngilizce dilind…ô M…ôtn-Metin…ô T…ôrc√ľml…ôyicil…ôrini Sintetik Kod-KarńĪŇümasńĪ', 'bn': 'টেক্সট- থেকে টেক্সট ট্রান্সফার্সার বিশেষ করে সিন্টেটিক কোড- মিক্সিং এর সাথে হিঙ্গিশ মেশিন অনুবাদের জন্য', 'bs': 'Eksplozirajući transformatore teksta na tekst za engleski na Hinglish Machine prevod sa sintetičkim kodom-Mixing', 'cs': 'Průzkum transformátorů textu do textu pro strojový překlad z angličtiny do Hinglish s syntetickým mícháním kódu', 'et': 'Teksti-tekstiks muundajate uurimine inglise keele hingliši masintõlke jaoks sünteetilise koodi segamisega', 'ca': 'Explorar transformadors de text a text per anglès a traducció de màquina hindlica amb combinació de codis sintètic', 'am': 'የጽሑፍ ቀለም ምረጡ', 'fi': 'Teksti tekstiksi muuntajien tutkiminen englanniksi hinglishin konekäännökselle synteettisellä koodisekoituksella', 'jv': 'Jejaring', 'sk': 'Raziskovanje pretvornikov besedila v besedilo za strojni prevod angleščine v hingliščino s sintetičnim mešanjem kod', 'ha': 'KCharselect unicode block name', 'he': 'מחקר מעברים טקסט לטקסט לאנגלית לתרגום מכונות הינגלית עם מערבב קוד סינטטי', 'bo': 'Exploring Text-to-Text Transformers for English to Hinglish Machine Translation with Synthetic Code-Mixing'}
{'en': 'We describe models focused at the understudied problem of ', 'fr': "Nous décrivons des modèles centrés sur le problème peu étudié de la traduction entre des paires de langues monolingues et mixtes de codes. Plus précisément, nous proposons une large gamme de modèles qui convertissent le texte anglais monolingue en hinglish (code mixte hindi et anglais). Compte tenu du récent succès des modèles de langage préentraînés, nous testons également l'utilité de deux modèles récents d'encodeur-décodeur basés sur Transformer (mT5 et mBart) sur la tâche en trouvant que les deux fonctionnent bien. Compte tenu de la rareté des données d'apprentissage pour le mixage de code, nous proposons également une méthode sans dépendance pour générer des textes mixtes de code à partir de représentations distribuées bilingues que nous exploitons pour améliorer les performances des modèles linguistiques. Forts de ces données supplémentaires, nous adoptons une approche d'apprentissage du curriculum dans laquelle nous affinons d'abord les modèles linguistiques sur des données synthétiques, puis sur des données mixtes de code or. Nous trouvons que, bien que simple, notre méthode de mélange de code synthétique est compétitive (et même supérieure dans certains cas) à plusieurs méthodes standard (rétrotranslation, méthode basée sur la théorie des contraintes d'équivalence) dans un ensemble diversifié de conditions. Nos travaux montrent que le modèle mT5, affiné suivant la procédure d'apprentissage du curriculum, atteint les meilleures performances de traduction (12,67 UEBL). Nos modèles occupent la première place dans le classement général de la tâche partagée officielle anglais-hinglish.", 'ar': 'نصف النماذج التي تركز على المشكلة التي تم دراستها جيدًا المتمثلة في الترجمة بين أزواج اللغات أحادية اللغة والمختلطة بالشفرة. وبشكل أكثر تحديدًا ، نقدم مجموعة واسعة من النماذج التي تحول النص الإنجليزي أحادي اللغة إلى Hinglish (مختلط الأكواد الهندية والإنجليزية). نظرًا للنجاح الأخير الذي حققته نماذج اللغة التي تم تدريبها مسبقًا ، فإننا نختبر أيضًا فائدة اثنين من نماذج وحدة فك التشفير المعتمدة على المحولات (على سبيل المثال ، mT5 و mBART) في العثور على المهمة للعمل بشكل جيد. نظرًا لندرة بيانات التدريب لخلط الكود ، نقترح أيضًا طريقة خالية من التبعية لإنشاء نصوص مختلطة بالشفرات من التمثيلات الموزعة ثنائية اللغة التي نستغلها لتحسين أداء نموذج اللغة. على وجه الخصوص ، مسلحين بهذه البيانات الإضافية ، نعتمد نهجًا لتعلم المناهج حيث نقوم أولاً بتحسين نماذج اللغة على البيانات التركيبية ثم البيانات المختلطة برموز ذهبية. وجدنا أنه ، على الرغم من بساطته ، فإن طريقة خلط الكود التركيبية لدينا تنافسية مع (وفي بعض الحالات تتفوق على) عدة طرق قياسية (الترجمة العكسية ، طريقة تعتمد على نظرية قيد التكافؤ) في ظل مجموعة متنوعة من الشروط. يوضح عملنا أن نموذج mT5 ، الذي تم تحديده باتباع إجراءات تعلم المنهج ، يحقق أفضل أداء للترجمة (12.67 BLEU). تحتل عارضاتنا المرتبة الأولى في الترتيب العام للمهمة المشتركة الرسمية الإنجليزية-الإنجليزية.', 'pt': 'Descrevemos modelos focados no problema pouco estudado de tradução entre pares de idiomas monolíngues e mistos. Mais especificamente, oferecemos uma ampla variedade de modelos que convertem texto monolíngue em inglês para Hinglish (hindi e inglês com código misto). Dado o sucesso recente de modelos de linguagem pré-treinados, também testamos a utilidade de dois modelos de codificador-decodificador baseados em transformador recentes (ou seja, mT5 e mBART) na tarefa de encontrar ambos para funcionar bem. Dada a escassez de dados de treinamento para mixagem de código, também propomos um método livre de dependência para gerar textos mistos de código a partir de representações distribuídas bilíngues que exploramos para melhorar o desempenho do modelo de linguagem. Em particular, armados com esses dados adicionais, adotamos uma abordagem de aprendizado curricular em que primeiro ajustamos os modelos de linguagem em dados sintéticos e depois em dados mistos de código ouro. Descobrimos que, embora simples, nosso método sintético de mixagem de código é competitivo (e em alguns casos até superior a) vários métodos padrão (retrotradução, método baseado na teoria de restrição de equivalência) sob um conjunto diversificado de condições. Nosso trabalho mostra que o modelo mT5, ajustado seguindo o procedimento de aprendizado do currículo, alcança o melhor desempenho de tradução (12,67 BLEU). Nossos modelos ficam em primeiro lugar no ranking geral da tarefa compartilhada oficial inglês-hinglês.', 'es': 'Describimos modelos centrados en el problema poco estudiado de la traducción entre pares de idiomas monolingües y de código mixto. Más específicamente, ofrecemos una amplia gama de modelos que convierten texto monolingüe en inglés en hinglish (código mixto de hindi e inglés). Dado el éxito reciente de los modelos de lenguaje preentrenados, también probamos la utilidad de dos modelos recientes de codificador-decodificador basados en Transformer (es decir, mT5 y mBART) para encontrar que ambos funcionan bien. Dada la escasez de datos de entrenamiento para la mezcla de códigos, también proponemos un método libre de dependencias para generar textos con código mixto a partir de representaciones distribuidas bilingües que explotamos para mejorar el rendimiento del modelo lingüístico. En particular, con estos datos adicionales, adoptamos un enfoque de aprendizaje curricular en el que primero ajustamos los modelos lingüísticos en datos sintéticos y luego en datos mezclados con código oro. Encontramos que, aunque simple, nuestro método de mezcla de código sintético es competitivo con (y en algunos casos es incluso superior a) varios métodos estándar (traducción inversa, método basado en la teoría de restricciones de equivalencia) en un conjunto diverso de condiciones. Nuestro trabajo demuestra que el modelo mT5, ajustado siguiendo el procedimiento de aprendizaje curricular, logra el mejor rendimiento de traducción (12,67 BLEU). Nuestros modelos ocupan el primer lugar en la clasificación general de la tarea compartida oficial anglo-hinglish.', 'hi': 'हम मोनोलिंगुअल और कोड-मिश्रित भाषा जोड़े के बीच अनुवाद करने की कम अध्ययन की गई समस्या पर केंद्रित मॉडल का वर्णन करते हैं। अधिक विशेष रूप से, हम मॉडल की एक विस्तृत श्रृंखला प्रदान करते हैं जो मोनोलिंगुअल अंग्रेजी पाठ को हिंग्लिश (कोड-मिश्रित हिंदी और अंग्रेजी) में परिवर्तित करते हैं। Pretrained भाषा मॉडल की हाल ही में सफलता को देखते हुए, हम भी दो हाल ही में ट्रांसफॉर्मर आधारित एन्कोडर-डिकोडर मॉडल (यानी, mT5 और mBART) की उपयोगिता का परीक्षण कार्य पर दोनों अच्छी तरह से काम करने के लिए खोजने पर. कोड-मिश्रण के लिए प्रशिक्षण डेटा की कमी को देखते हुए, हम द्विभाषी वितरित अभ्यावेदन से कोड-मिश्रित ग्रंथों को उत्पन्न करने के लिए एक निर्भरता-मुक्त विधि का भी प्रस्ताव करते हैं जो हम भाषा मॉडल प्रदर्शन में सुधार के लिए शोषण करते हैं। विशेष रूप से, इस अतिरिक्त डेटा से लैस, हम एक पाठ्यक्रम सीखने के दृष्टिकोण को अपनाते हैं जहां हम पहले सिंथेटिक डेटा पर भाषा मॉडल को ठीक करते हैं, फिर सोने के कोड-मिश्रित डेटा पर। हम पाते हैं कि, हालांकि सरल, हमारी सिंथेटिक कोड-मिश्रण विधि शर्तों के एक विविध सेट के तहत कई मानक विधियों (बैकट्रांसलेशन, तुल्यता बाधा सिद्धांत पर आधारित विधि) के साथ प्रतिस्पर्धी है (और कुछ मामलों में भी बेहतर है)। हमारे काम से पता चलता है कि एमटी 5 मॉडल, पाठ्यक्रम सीखने की प्रक्रिया के बाद ठीक किया गया है, सबसे अच्छा अनुवाद प्रदर्शन (12.67 BLEU) प्राप्त करता है। हमारे मॉडल अंग्रेजी-हिंग्लिश आधिकारिक साझा कार्य की समग्र रैंकिंग में पहले स्थान पर हैं।', 'ja': '私たちは、単一言語とコード混合言語のペア間の翻訳という研究不足の問題に焦点を当てたモデルについて説明します。 より具体的には、単一言語の英語テキストをヒンギス語（コードミックスされたヒンディー語と英語）に変換する幅広いモデルを提供しています。 事前に訓練された言語モデルの最近の成功を考えると、私たちはまた、2つの最近のトランスフォーマーベースのエンコーダデコーダモデル（すなわち、mT 5とmBART ）の両方がうまく機能することを発見するタスクの有用性をテストします。 コードミキシングのためのトレーニングデータが乏しいことを考慮して、言語モデルのパフォーマンスを向上させるために利用するバイリンガル分散表現からコードミックステキストを生成するための依存性のない方法も提案します。 特に、この追加データに武装して、まず合成データに基づいて言語モデルを微調整し、次にゴールドコードミックスデータに基づいて言語モデルを微調整するカリキュラム学習アプローチを採用している。 単純ではあるが、我々の合成コード混合法は、多様な条件の下でいくつかの標準的な方法（逆変換、等価制約理論に基づく方法）と競合している（場合によってはさらに優れている）ことがわかっている。 私たちの研究は、カリキュラム学習手順に従って微調整されたmT 5モデルが、最高の翻訳パフォーマンス（ 12.67 BLEU ）を達成することを示しています。 私たちのモデルは、英語と英語の公式共有タスクの総合ランキングで1位になりました。', 'zh': '注未尽之单语,混代码言之译也。 更具体地说广模样,转单语英语为Hinglish(代码印地语英语)。 鉴乎预训言模形之近成,试于Transformer之编码器解码器(mT5mBART)之实用性,两者俱善。 鉴于代码混合之数匮,又立无恃之法,以成双语分布式代码混合文本,以崇言语模样之性。 凡此等数,吾等用一程学法,先于合成数上微调言语模样,然后于黄金代码混合数上微调言语模样。 吾见虽简,合而为代码,杂而反之(反之,其于等价约束论)争(优于)。 臣等事业,mT5 依程学程,可得最佳者(12.67 BLEU)。 英语 - Hinglish官共职第一。', 'ga': 'Déanaimid cur síos ar mhúnlaí atá dírithe ar an bhfadhb nach bhfuil mórán staidéir déanta uirthi maidir le haistriúchán idir péirí teangacha aonteangacha agus cód-mheasctha. Go sonrach, cuirimid raon leathan samhlacha ar fáil a thiontaíonn téacs aonteangach Béarla go Hinglish (Hiondúis agus Béarla cód-mheasctha). Mar gheall ar an rath a bhí ar mhúnlaí teanga réamhoilte le déanaí, déanaimid tástáil freisin ar áirgiúlacht dhá shamhail ionchódóra-códaitheora Trasfhoirmeoir-bhunaithe le déanaí (i.e., mT5 agus mBART) ar an tasc a aimsiú go n-oibreoidh an dá cheann go maith. Mar gheall ar ghanntanas na sonraí oiliúna maidir le códmheascadh, molaimid freisin modh saor ó spleáchas chun téacsanna cód-mheasctha a ghiniúint ó uiríll dáilte dátheangacha a mbainimid leas as chun feidhmíocht na samhla teanga a fheabhsú. Agus na sonraí breise seo go háirithe, glacaimid cur chuige foghlama curaclaim ina ndéanaimid mionchoigeartú ar na samhlacha teanga ar shonraí sintéiseacha agus ansin ar shonraí cód-mheasctha ór. Faighimid amach, cé go bhfuil sé simplí, go bhfuil ár modh códmheasctha sintéiseach iomaíoch le (agus i gcásanna áirithe fiú níos fearr ná) roinnt modhanna caighdeánacha (backtranslation, modh bunaithe ar theoiric shrianta coibhéise) faoi shraith éagsúil coinníollacha. Léiríonn ár gcuid oibre go mbaineann an tsamhail mT5, arna mionchoigeartú de réir nós imeachta foghlama an churaclaim, an fheidhmíocht aistriúcháin is fearr amach (12.67 BLEU). Is iad ár múnlaí an chéad áit i rangú foriomlán an tasc comhroinnte oifigiúil Béarla-Hinglish.', 'ru': 'Мы описываем модели, ориентированные на недостаточно изученную проблему перевода между одноязычными и кодово-смешанными языковыми парами. Более конкретно, мы предлагаем широкий спектр моделей, которые преобразуют одноязычный английский текст в хинглиш (кодово-смешанный хинди и английский). Учитывая недавний успех предварительно подготовленных языковых моделей, мы также протестировали полезность двух последних моделей кодировщика-декодера на основе трансформатора (т.е. mT5 и mBART) для поиска задач, которые могли бы хорошо работать. Учитывая нехватку обучающих данных для смешивания кода, мы также предлагаем метод без зависимостей для генерации смешанных текстов из двуязычных распределенных представлений, которые мы используем для улучшения производительности языковой модели. В частности, вооружившись этими дополнительными данными, мы принимаем подход к обучению по учебной программе, где мы сначала точно настраиваем языковые модели на синтетических данных, а затем на данных, смешанных с золотым кодом. Мы обнаружили, что, хотя и простой, наш метод синтетического смешивания кода конкурентоспособен (а в некоторых случаях даже превосходит) нескольким стандартным методам (обратный перевод, метод, основанный на теории ограничений эквивалентности) в различных условиях. Наша работа показывает, что модель mT5, доработанная в соответствии с процедурой обучения по учебной программе, достигает наилучшей производительности перевода (12,67 BLEU). Наши модели занимают первое место в общем рейтинге разделяемой задачи англо-английского чиновника.', 'ka': 'ჩვენ მოდელები, რომლებიც მონოლენგური და კოდის შესაბამისი ენის ზოგების შორის გადაწყვეტილების პრობლემაში დავწერეთ. უფრო განსაკუთრებულია, ჩვენ მივიღეთ დიდი მოდელები, რომლებიც მონოლენგური ანგლისური ტექსტის შეცვლა ჰინგლიქში (კოდი შეცვლა ჰინდლიქში და ანგლისში მხოლოდ მხოლოდ წარმატებული ენის მოდელების წარმატებით, ჩვენ ასევე შევცვალოთ ორი ახალი ტრანფორმეტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრის მოდე კოდის შემთხვევისთვის მონაცემების მუშაობა, ჩვენ კოდის შემთხვევისთვის კოდის შემთხვევაში მუშაობელი ტექსტის შექმნა, რომელიც ჩვენ გამოვიყენებთ ენის მოდელის მუშაობისთვის. განსაკუთრებით, ამ დამატებული მონაცემებით, ჩვენ დავწყებთ სწავლების მონაცემები, სადაც ჩვენ პირველად სინტეტიკური მონაცემებზე სინტეტიკური მონაცემების მონაცემების მონაცე ჩვენ ვფიქრობთ, თუმცა ჩვენი სინტეტიკური კოდენტიკური შემთხვევაში კონპექტიური პროცემი (და რამდენიმე შემთხვევაში კი უფრო მეტია) რამდენიმე სტანდარტულ მეცემი (დამწყვება, მეცემი ჩვენი სამუშაო აჩვენებს, რომ mT5 მოდელი, რომელიც სწავლის სწავლის პროცესის შემდეგ უფრო მსგავსი შემდეგ იქნება (12.67 BLEU). ჩვენი მოდელები პირველი ადგილდება ინგლისური-ჰინგლიქური უფრო სხვადასხვა საქმე.', 'hu': 'Olyan modelleket írunk le, amelyek az egynyelvű és kódkevert nyelvpárok közötti fordítás dublárd problémájára összpontosítanak. Pontosabban olyan modellek széles választékát kínáljuk, amelyek az egynyelvű angol nyelvű szöveget hinglisre alakítják (kódkeverék hindi és angol). Tekintettel az előkészített nyelvi modellek közelmúltbeli sikerére, két újabb Transformer-alapú kódoló-dekódoló modell (azaz mT5 és mBART) hasznosságára is teszteljük, hogy mindkettő jól működik. Tekintettel a kódkeveréshez szükséges képzési adatok szűkösségére, egy függőségmentes módszert is javasolunk a kétnyelvű elosztott reprezentációkból készített kódkeverék szövegek létrehozására, amelyet a nyelvi modell teljesítményének javítására használunk ki. Különösen ezekkel a kiegészítő adatokkal felszerelve tananyagtanulási megközelítést alkalmazunk, ahol először finomhangoljuk a nyelvi modelleket szintetikus adatokra, majd aranykóddal kevert adatokra. Úgy találjuk, hogy bár egyszerű, a szintetikus kódkeverési módszerünk versenyképes (és néhány esetben még jobb is) számos standard módszerrel (visszafordítás, egyenértékűségi korlátozás elméletén alapuló módszer) különböző körülmények között. Munkánk azt mutatja, hogy a tanterv tanulási eljárását követően finomhangolt mT5 modell a legjobb fordítási teljesítményt biztosítja (12.67 BLEU). Modelljeink az angol-hinglish hivatalos megosztott feladat általános rangsorában az első helyen helyezkednek el.', 'el': 'Περιγράφουμε μοντέλα που επικεντρώνονται στο υποβαθμισμένο πρόβλημα της μετάφρασης μεταξύ μονογλωσσικών και κωδικών-μικτών γλωσσικών ζευγαριών. Πιο συγκεκριμένα, προσφέρουμε ένα ευρύ φάσμα μοντέλων που μετατρέπουν το μονόγλωσσο αγγλικό κείμενο σε Χίνγκλι (κωδικοποιημένο Χίντι και Αγγλικά). Δεδομένης της πρόσφατης επιτυχίας των προ-εκπαιδευμένων γλωσσικών μοντέλων, εξετάζουμε επίσης τη χρησιμότητα δύο πρόσφατων μοντέλων κωδικοποιητών-αποκωδικοποιητών με βάση τον μετασχηματιστή (δηλ. και το mT5) για την εύρεση και των δύο να λειτουργούν καλά. Δεδομένης της έλλειψης δεδομένων εκπαίδευσης για την ανάμειξη κώδικα, προτείνουμε επίσης μια μέθοδο χωρίς εξάρτηση για τη δημιουργία κειμένων μικτού κώδικα από δίγλωσσες κατανεμημένες αναπαραστάσεις που εκμεταλλευόμαστε για τη βελτίωση της απόδοσης του γλωσσικού μοντέλου. Ειδικότερα, οπλισμένοι με αυτά τα πρόσθετα δεδομένα, υιοθετούμε μια προσέγγιση εκμάθησης προγράμματος σπουδών όπου πρώτα τελειοποιούμε τα γλωσσικά μοντέλα σε συνθετικά δεδομένα και έπειτα σε δεδομένα μικτού χρυσού κώδικα. Διαπιστώνουμε ότι, αν και απλή, η συνθετική μας μέθοδος ανάμειξης κώδικα είναι ανταγωνιστική (και σε ορισμένες περιπτώσεις είναι ακόμη ανώτερη) με διάφορες τυποποιημένες μεθόδους (αντίστροφη μετάφραση, μέθοδος βασισμένη στη θεωρία περιορισμού ισοδυναμίας) κάτω από ένα ποικίλο σύνολο συνθηκών. Η εργασία μας δείχνει ότι το μοντέλο, το οποίο συντονίζεται σύμφωνα με τη διαδικασία εκμάθησης του προγράμματος σπουδών, επιτυγχάνει την καλύτερη απόδοση μετάφρασης (12.67 BLEU). Τα μοντέλα μας τοποθετούνται πρώτα στη συνολική κατάταξη της αγγλικής-ινδικής επίσημης κοινής εργασίας.', 'it': "Descriviamo modelli focalizzati sul problema secondario della traduzione tra coppie linguistiche monolingue e code-mixed. In particolare, offriamo una vasta gamma di modelli che convertono il testo inglese monolingue in hinglish (codice misto Hindi e Inglese). Dato il recente successo dei modelli di linguaggio pre-addestrati, testiamo anche l'utilità di due recenti modelli di encoder-decoder basati su Transformer (es., mT5 e mBART) sul compito trovando entrambi di funzionare bene. Data la scarsità di dati formativi per il code-mixing, proponiamo anche un metodo privo di dipendenza per generare testi code-mixing da rappresentazioni distribuite bilingue che sfruttiamo per migliorare le prestazioni del modello linguistico. In particolare, armati di questi dati aggiuntivi, adottiamo un approccio di apprendimento curricolare dove prima finiamo i modelli linguistici su dati sintetici poi su dati gold code-mixed. Troviamo che, anche se semplice, il nostro metodo sintetico di miscelazione del codice è competitivo (e in alcuni casi è addirittura superiore a) diversi metodi standard (backtranslation, metodo basato sulla teoria del vincolo di equivalenza) in un insieme diversificato di condizioni. Il nostro lavoro dimostra che il modello mT5, perfezionato seguendo la procedura di apprendimento del curriculum, raggiunge le migliori prestazioni di traduzione (12.67 BLEU). I nostri modelli si collocano al primo posto nella classifica generale del compito condiviso ufficiale inglese-hinglish.", 'lt': 'Mes apibūdiname modelius, kuriais dėmesys sutelkiamas į nepakankamai įvertintą vertimo tarp vienakalbių ir kodų mišrių kalbų porų problem ą. Konkrečiau, siūlome įvairius modelius, kurie vienkalbį anglų tekstą paverčia anglų kalba (kodų mišinys anglų ir Hindi). Atsižvelgdami į neseniai parengtų kalbų modelių sėkmę, mes taip pat i šbandome dviejų naujausių Transformer-based encoder-decoder modelių (t. y. mT5 ir mBART) naudingumą siekiant nustatyti, ar užduotis veikia gerai. Given the paucity of training data for code-mixing, we also propose a dependency-free method for generating code-mixed texts from bilingual distributed representations that we exploit for improving language model performance.  Visų pirma, pasitelkdami šiuos papildomus duomenis, mes priimame mokymosi programų metodą, kuriame pirmiausia tikslinami kalbos modeliai, remiantis sintetiniais duomenimis, o vėliau – su aukso kodais susijusiais duomenimis. Mes manome, kad nors ir paprastas, mūsų sintetinio kodų maišymo metodas yra konkurencingas (ir kai kuriais atvejais net geresnis už) keliais standartiniais metodais (atgalinis vertimas, metodas, pagrįstas lygiavertiškumo apribojimų teorija) įvairiomis sąlygomis. Mūsų darbas rodo, kad mT5 modelis, patobulintas pagal mokymosi programų procedūrą, užtikrina geriausius vertimo rezultatus (12,67 BLEU). Mūsų modeliai pirmiausia priskiriami bendrai anglų ir hindų pareigūnų užduotims.', 'kk': 'Біз монолингі мен код арасындағы тілдерді аудару мәселесіне көздеген үлгілерді таңдаймыз. Көбірек, біз бірнеше тілі ағылшын мәтінін Hinglish (код аралас хинди және ағылшын тіліне аударатын) үлгілерді ұсынамыз. Жуырдағы тіл үлгілерінің сәттілігін көрсету үшін, сондай-ақ екі жаңа түрлендіруші кодер- декодер үлгілерінің (мысалы, mT5 және mBART) утилитасын тексереміз. Код араластыру үшін оқыту деректерінің қауіпсіздігіне байланысты болса, сондай-ақ біз тіл үлгісін жасау үшін код араластырылған мәтіндерді құру үшін қолданатын мәтіндерді қолданатын әдіпсіздік жолын қолдана Әрине осы қосымша деректерді қолданып, біз біріншіден синтетикалық деректерді синтетикалық деректердің тілдер үлгілерін қолданып, алтын код араластырылған деректерді қолдануға болады. Біз қарапайым, синтетикалық код араластыру әдіміміз (кейбір жағдайда бірнеше стандартты әдістері (backtranslation, method based on equivalence constraint theory) әртүрлі шарттардың арқылы бірнеше стандартты әдістерімен бұл әдістерін көреміз Біздің жұмысамыз mT5 үлгісін көрсетеді, бағдарламалар оқыту процедурына кейін жақсы жақсы түрлендіру үлгісін жеткізеді (12,67 BLEU). Біздің үлгілеріміз біріншіден ағылшын-Хинглиш әкімшілікті ортақ тапсырманың жалпы ретінде орналасады.', 'mk': 'Опишуваме модели фокусирани на проблемот со преведувањето помеѓу монојазичните и мешаните јазички парови. Поконкретно, понудуваме широк број модели кои го претвораат монојазичниот англиски текст во хинглиски (хинглиски и англиски мешани кодови). Со оглед на неодамнешниот успех на предобучените јазички модели, ние исто така ја тестираме корисноста на двата неодамнешни модели на кодер-декодер базирани на Трансформер (т.е., mT5 и mBART) на задачата за пронаоѓање на двете задачи да функ Со оглед на недостатокот на податоци за обука за мешање на кодови, ние, исто така, предложуваме метод без зависност за генерирање мешани тексти со кодови од двојјазични дистрибуирани претставувања кои ги искористуваме за подобрување на јазичниот модел. Особено, вооружени со овие дополнителни податоци, усвојуваме пристап за учење на училиштата каде прво ги финетизираме јазичните модели на синтетичките податоци, потоа на златните кодови мешани податоци. Најдовме дека, иако е едноставен, нашиот метод на синтетичко мешање кодови е конкурентен со (и во некои случаи е дури и супериорн од) неколку стандардни методи (позадина превод, метод базиран на теорија на ограничување на еквиваленцијата) под различни услови. Нашата работа покажува дека моделот mT5, финетизиран по процедурата на учење на наставниот план, постигнува најдобра преводна перформанса (12,67 БЛЕ). Нашите модели се први во целокупното рангирање на англиско-хинглиската официјална заедничка задача.', 'ms': 'Kami menggambarkan model yang fokus pada masalah terjemahan diantara pasangan bahasa monobahasa dan kod-campuran. Lebih khusus, kami menawarkan julat luas model yang menukar teks bahasa Inggeris monobahasa ke Hinglish (kod-campuran Hindi dan Inggeris). Mengingat kejayaan baru-baru ini bagi model bahasa yang dilatih, kami juga menguji utiliti dua model pengekod-pengekod berasaskan Transformer yang baru-baru ini (iaitu mT5 dan mBART) pada tugas mencari kedua-dua untuk berfungsi dengan baik. Given the paucity of training data for code-mixing, we also propose a dependency-free method for generating code-mixed texts from bilingual distributed representations that we exploit for improving language model performance.  Secara khususnya, bersenjata dengan data tambahan ini, kita mengadopsi pendekatan pembelajaran kurikulum di mana kita pertama-tama memperbaiki model bahasa pada data sintetik kemudian pada data campuran kod emas. Kami mendapati bahawa, walaupun mudah, kaedah campuran kod sintetik kami adalah bersaing dengan (dan dalam beberapa kes bahkan lebih baik daripada) beberapa kaedah piawai (terjemahan belakang, kaedah berdasarkan teori kewajipan) dalam set syarat berbeza. Kerja kami menunjukkan bahawa model mT5, ditetapkan mengikut prosedur pembelajaran kurikulum, mencapai prestasi terjemahan terbaik (12.67 BLEU). Model kita terlebih dahulu dalam peringkat keseluruhan tugas rasmi Inggeris-Hinglish berkongsi.', 'mt': 'Aħna niddeskrivu mudelli ffukati fuq il-problema mhux mistħarrġa biżżejjed tat-traduzzjoni bejn il-pari tal-lingwi monolingwi u dawk imħallta bil-kodiċi. B’mod aktar speċifiku, noffru firxa wiesgħa ta’ mudelli li jikkonvertu t-test monolingwistiku bl-Ingliż f’Ingliż (kodiċi mħallta bl-Ingliż u bl-Ingliż). Minħabba s-suċċess reċenti ta’ mudelli lingwistiċi mħarrġa minn qabel, aħna nistestjaw ukoll l-utilità ta’ żewġ mudelli riċenti ta’ kodiċi-dekoder ibbażati fuq it-Transformer (jiġifieri mT5 u mBART) fuq il-kompitu li jsibu t-tnejn biex jaħdmu tajjeb. Minħabba n-nuqqas ta’ dejta ta’ taħriġ għat-taħlit tal-kodiċijiet, qed nipproponu wkoll metodu ħieles mid-dipendenza għall-ġenerazzjoni ta’ testi mħallta bil-kodiċijiet minn rappreżentazzjonijiet distribwiti bilingwi li nistruttaw għat-titjib tal-prestazzjoni tal-mudell lingwistiku. B’mod partikolari, armati b’din id-dejta addizzjonali, a ħna niddottaw approċċ ta’ tagħlim kurrikulari fejn l-ewwel aħna nidfinaw il-mudelli lingwistiċi fuq dejta sintetika imbagħad fuq dejta mħallta bil-kodiċi tad-deheb. Issibu li, għalkemm sempliċi, il-metodu tat-taħlit tal-kodiċi sintetiku tagħna huwa kompetittiv ma’ (u f’xi każijiet huwa saħansitra superjuri għal) diversi metodi standard (backtranslation, metodu bbażat fuq teorija tar-restrizzjoni tal-ekwivalenza) taħt sett ta’ kundizzjonijiet varji. Ix-xogħol tagħna juri li l-mudell mT5, imfinat skont il-proċedura tat-tagħlim tal-kurrikulu, jikseb l-aħjar prestazzjoni tat-traduzzjoni (12.67 BLEU). Il-mudelli tagħna jinsabu l-ewwel fil-klassifikazzjoni ġenerali tal-kompitu komuni uffiċjali Ingliż-Hingliż.', 'ml': 'നമ്മള്\u200d മോഡലുകള്\u200d വിശദീകരിക്കുന്നു. മണോലില്\u200d ഭാഷ, കോഡ് മിഷ്ടപ്പെട്ട ഭാഷയുടെ ഇണകള്\u200dക്കിടയില്\u200d പരിഭാഷപ്പെടു കൂടുതല്\u200d പ്രത്യേകിച്ച്, നമ്മള്\u200d ഒരു വിശാലമായ മോഡലുകള്\u200d നല്\u200dകുന്നു. അത് മോണോളില്\u200d ഭാഷ ഇംഗ്ലീഷ് ടെക്സ്റ്റ് ഹിങ്ങിലേക്ക ഭാഷ മോഡലുകളുടെ അടുത്തുള്ള വിജയം കൊണ്ട്, നമ്മളും പരീക്ഷിക്കുന്നു, രണ്ട് അടുത്തുള്ള ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d അടിസ്ഥാനത്തുള്ള കോഡോര്\u200d മോഡലുകളുടെ ഉപയോഗം  കോഡ്-മിക്കിങ്ങിനുള്ള പരിശീലനവിവരങ്ങളുടെ പ്രധാനപ്പെട്ടത് കൊണ്ട്, നമ്മള്\u200d ഭാഷ മോഡല്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന് മുന്\u200dകൂട്ടുന്നതിനായി കോഡ പ്രത്യേകിച്ച്, ഈ കൂടുതല്\u200d വിവരങ്ങള്\u200d കൊണ്ട് ആയുധമായി, നമ്മള്\u200d പഠിക്കുന്ന ഒരു പ്രായോഗ്യം പ്രാപ്തിക്കുന്നു. അവിടെ ആദ്യം നമ്മള്\u200d ഭാ ഞങ്ങള്\u200d കണ്ടെത്തുന്നു, എളുപ്പമാണെങ്കിലും നമ്മുടെ സിന്\u200dറെറ്റിക്ക് കോഡ് മിക്കിങ്ങ് രീതിയില്\u200d മത്സരിക്കുന്നു (ചില കാര്യങ്ങളിലും കൂടുതല്\u200d മികച്ച) പല സ്ഥ നമ്മുടെ ജോലി കാണിക്കുന്നത് എംടി5 മോഡല്\u200d, പഠിക്കുന്ന പദ്ധതിയുടെ പ്രക്രിയയുടെ പിന്നാലെ മെച്ചപ്പെട്ടിരിക്കുന് Our models place first in the overall ranking of the English-Hinglish official shared task.', 'mn': 'Бид загваруудыг нэг хэл болон код холбоотой хэл хооронд орчуулах сургалтын төвлөрсөн асуудалд тайлбарлаж байна. Илүү тодорхой нь, бид англи хэлний текстийг Хинглиш руу шилжүүлэх олон загваруудыг санал болгож байна. Өнгөрсөн хэл загварын саяхан амжилтын тулд бид саяхан ажиллах ажлын тухай ажил олох хоёр саяхан Трансформер-суурилсан кодлогч загварын хэрэглээ (яг л mT5 болон mBART). Код холбогдохын тулд сургалтын өгөгдлийн бус байдлаар бид мөн хоёр хэлний хуваагдсан хэлний загварын үйл ажиллагааг сайжруулахын тулд код холбогдсон бичлэгүүдийг бий болгохын тулд хамааралтай арга загварыг санал болгож Ялангуяа, эдгээр нэмэлт мэдээллээр оруулсан, бид сургалтын хөтөлбөр суралцах арга зам ашигладаг. Эхлээд бид алтын код холбогдсон өгөгдлийн талаар хэл загваруудыг анх тодорхойлдог. Бид энгийн хэдий ч, бидний синтетик кодын хоорондоо холбогдох аргыг олон стандарт аргыг (backtranslation, method based on equivalence constraint theory) олон нөхцөл байдлын дотор өрсөлдөөнтэй байдаг. Бидний ажлын загвар нь мT5 загвар, суралцах хөтөлбөрийн суралцах процедурын дагавартай, хамгийн сайн орчуулах үйл ажиллагааг гаргадаг. Бидний загварууд анх Англи-Хинглисийн ерөнхий хэмжээний ажил дээр байдаг.', 'no': 'Vi beskriver modeller fokusert på understudierte problemet for å omsetja mellom monospråk og kodefeksa språkparar. Dette er meir spesifikt at vi tilbyr eit brett rekke modeller som konverterer engelsk tekst til Hinglish (kodamngla hindisk og engelsk). Given den siste suksessen på språk-modellen, tester vi også verktøyet til to nyleg transformeringsbaserte koderingsmodellen (t.d. mT5 og mBART) på oppgåva som finn begge for å arbeide godt. Gjennomsiktig nedgang av treningsdata for kode-mixing, foreslår vi også ein metode for å laga mellom kode-mellom tekstar frå bilinguelt distribuert representasjonar som vi brukar for å forbetra språk-modellen. I særskilt, armert med denne ekstra data, har vi tilgang til å lære programmet, der vi først finner språk-modellen på syntetiske data og så på gullkode-blandede data. Vi finn at, selv om enkelt, vårt syntetisk kodefeksingsmetode er konkurrentivt med (og i nokre tilfelle er likevel høgare til) fleire standardmetoder (tilbakeomsetjing, metode basert på ekvivalens begrensningsteorie) under ein divers set av vilkåra. Arbeidet vårt viser at mT5-modellen, som er fint etter læringsprosessen for curriculum, gjer beste omsetjingsfunksjon (12,67 BLEU). Modellene våre plasserer først i den generelle rekninga av den offisielle delte oppgåva i engelsk-hinglish.', 'sr': 'Mi opisujemo modele fokusirane na podstudirani problem prevoda između monojezičkih i kombiniranih jezičkih parova. Još specifiènije, ponudimo širok niz modela koji pretvaraju monojezički engleski tekst u Hinglish (kodirani hindi i engleski). S obzirom na nedavni uspeh jezičkih modela, takođe testiramo korisnost dva nedavna modela kodera-dekodera na transformeru (tj. mT5 i mBART) na zadatku koji se nalaze kako bi dobro funkcionisali. S obzirom na nedostatak podataka o obuci za mešavanje kodova, takođe predlažemo metodu bez zavisnosti za stvaranje teksta mešanih kodova iz dvojezičkih raspodjeljenih predstavljanja koje koristimo za poboljšanje izvođenja jezičkih model a. Posebno, naoružani ovim dodatnim podacima, usvojimo pristup učenja programa gde prvi put završavamo jezičke modele o sintetičkim podacima, a zatim o zlatnim kodovima. Mi smatramo da, iako je jednostavno, naša sintetička metoda miješanja kodova konkurentna sa (i u nekim slučajevima je čak i superiora) nekoliko standardnih metoda (backtranslation, metoda bazirana na teoriji ograničenja ekvivalencije) pod raznim uslovima. Naš rad pokazuje da model mT5, koji je ispunjen nakon procedure učenja nastavnih programa, postiže najbolji izvor prevoda (12,67 BLEU). Naši modeli su prvi u ukupnom redovištu službenog zajedničkog zadatka engleskog-Hingliša.', 'si': 'අපි මොඩේල් එක්ක භාෂාවක් සහ කෝඩ් මික්ස් භාෂාවක් එක්ක භාෂාවක් අතර ප්\u200dරශ්නයක් විස්තර කරනවා. විශේෂයෙන්, අපි විශේෂ විශේෂයෙන්, එක භාෂාවක් ඉංග්\u200dරීසි පාළුවක් හින්ග්ලිෂ් වලට පරිවර්තනය කරන්න ප්\u200dරිට්\u200dරේන්ස් භාෂා මොඩේල්ස් ගැන අලුත් වැඩේ සාර්ථක විදියට, අපි පරීක්ෂා කරලා තියෙන්නේ අලුත් විදියට පරික්ෂා කරලා තියෙන්නේ අලුත් ව කෝඩ් මික්ස් එක්ක ප්\u200dරශ්නයේ දත්ත ප්\u200dරශ්නයක් තියෙන්නේ, අපි කෝඩ් මික්ස් එක්ක ප්\u200dරශ්නයක් නිදහස් වෙනුවෙන් කෝඩ් මික්ස් පාළුවන විශේෂයෙන්, මේ තවත් තොරතුරු එක්ක ආයුධ කරන්න, අපි ඉගෙන ගන්න පුළුවන් ඉගෙන ගන්න පුළුවන් වගේ භාෂා මොඩේල් එක සංවිධා අපිට හොයාගන්න පුළුවන්, අපේ සංවිධානය කෝඩ් මිස්සින් විධානය සාමාන්\u200dය විධානය (සහ සමහර විධානයේදී සාමාන්\u200dය විධානය (backtranslation, විධානය ස අපේ වැඩේ පෙන්වන්නේ mT5 මොඩේල්, ඉගෙනගන්න පුළුවන් විදියට පස්සේ ප්\u200dරයෝජනය කරනවා කියලා, හොඳම වාර්ථාව ප්\u200dරය අපේ මොඩල් ස්ථානය මුලින්ම ඉංග්\u200dරීස්-හින්ග්ලිෂ් නියෝජිත වැඩක් එක්ක සාමාන්\u200dය ස්ථානය', 'so': "Tusaale ahaan waxaynu ku qornaa dhibaatada hoose-dhexe ee turjumidda labada luqada ah iyo qofka isku xiran luqada. Si gaar ah, waxaan tusaalooyin badan oo kala duduwan oo ku beddelinaya qoraalka afka Ingiriiska oo afka noocyada ah Hinglish (kooxda isku xiran Hindi iyo Ingiriis). Markii la guulaystay muuqashada afka hore, waxaynu sidoo kale imtixaannaa isticmaalka labo noocyo-codcoder-based (tusaale ahaan mT5 iyo mBART) oo ku saabsan shaqo aad u hesho labadoodaba. Sidoo aad u baahan tahay macluumaadka waxbarashada codsiga isku xirashada, waxaynu sidoo kale u soo jeedaynaa qaab aan iskala xiriir lahayn oo ka soo saarno qoraal-isku-xiran oo noocyada kala qaybsan labada luuqadood, kaas oo aan ugu baahan nahay horumarinta muuqashada muuqashada luuqada. Si gaar ah, isagoo hub u leh macluumaadkan dheeraad ah, waxaynu qaadannaa qaab waxbarasho ah oo aynu marka ugu horrayno muusikada luuqada ku qornaa taariikhda dhexaadinta, kadibna waxaynu ku qornaa macluumaadka kaararka dahabka ah ee isku xiran. Waxaynu aragnaa in, in kastoo ay sahlan tahay, qaababkayaga kooxaha isku xiriira ayaa ku dadaalaya (xaaladaha qaarkoodna way ka sarreeyaan) qaabab cayiman ah (backtranslation, method ku saleysan fikradda isku qiimo ahaanshaha) hoostooda xaaladaha kala duduwan. Shaqadeenu wuxuu muujiyaa in sameynta MT5, oo la soo bandhigay xiliga waxbarashada waxbarashada, wuxuu gaadhaa bandhig turjumista ugu wanaagsan (12.67 BLEU). Tusaale'yadeenu waxay marka ugu horeysa ugu horeeyaan shacabka rasmiga ah ee Ingiriiska-Hinglish.", 'sv': 'Vi beskriver modeller fokuserade på det dubblerade problemet med översättning mellan enspråkiga och kodblandade språkpar. Mer specifikt erbjuder vi ett brett utbud av modeller som konverterar enspråkig engelsk text till hinglish (kodblandad hindi och engelska). Med tanke på den senaste tidens framgångar med förkränade språkmodeller testar vi också användbarheten av två senaste Transformer-baserade encoder-avkodarmodeller (dvs mT5 och mBART) på uppgiften att hitta båda att fungera bra. Med tanke på bristen på utbildningsdata för kodblandning föreslår vi också en beroendefri metod för att generera kodblandade texter från tvåspråkiga distribuerade representationer som vi utnyttjar för att förbättra språkmodellens prestanda. Framför allt, beväpnade med dessa ytterligare data, antar vi en läroplan inlärningsmetod där vi först finjusterar språkmodellerna på syntetiska data och sedan på guldkodsblandlade data. Vi finner att vår syntetiska kodblandningsmetod, även om den är enkel, är konkurrenskraftig med (och i vissa fall är till och med överlägsen) flera standardmetoder (backtranslation, metod baserad på likvärdighetsbegränsningsteori) under olika förutsättningar. Vårt arbete visar att mT5-modellen, finjusterad enligt läroplanen, uppnår bästa översättningsprestanda (12.67 BLEU). Våra modeller placerar sig först i den övergripande rankningen av den engelska-hingliska officiella delade uppgiften.', 'ta': 'மொழிமொழிகள் மற்றும் குறியீடு கலந்த மொழி ஜோடிகளுக்கிடையே மொழிபெயர்ப்பு பிரச்சனையில் கவனம் செலுத்தப் மேலும் குறிப்பிட்டு, நாம் ஒரு விரிவான மாதிரிகளை வழங்குகிறோம். அது மொன்மொழி ஆங்கிலத்தை ஹிங்கிலிஷில் மாற்றுகிறத மொழி மாதிரி மாதிரிகளின் சமீபத்தில் வெற்றியடைந்த போது, நாம் இரண்டு அண்மையில் மாற்றி அடிப்படையான குறியீட்டு மாதிரிகளின் பயன்பாடு குறியீடு கலவைக்கான பயிற்சி தரவுகளின் தெரிவு கொண்டால், நாம் மொழி மாதிரி மாதிரி செயல்பாட்டினை மேம்படுத்துவதற்கு சார்ந்த- இலவச முறையை உருவ குறிப்பிட்டு, இந்த கூடுதல் தரவுடன் ஆயுதங்களால், நாம் மொழி மாதிரி மாதிரிகளை தேர்ந்தெடுக்கிறோம். பிறகு தங்க குறியீடு கலந்த தகவல் ம நாங்கள் கண்டுபிடிக்கும், எளிதாக இருந்தாலும், எங்கள் குறியீட்டு கலந்த முறைமையாலும் (மற்றும் சில நிகழ்வுகளில் அதிகமாக) பல நிலையான முறைகள் (பின்பொருள், ஒ எங்கள் வேலை தெரியும் MT5 மாதிரி, தொழில்நுட்பம் கற்றுக் கொள்ளும் சிறந்த மொழிபெயர்ப்பு செயல்பாடு (12. 67 பிலியூ) பின்பு ப எங்கள் மாதிரிகள் முதலில் ஆங்கிலத்தில்-ஹிங்கில் அரசியல் பகிர்ந்த பணியில் மொத்த மாதிரியில் முதலி', 'pl': 'Opisujemy modele skoncentrowane na niezbadanym problemie tłumaczenia pomiędzy jednojęzycznymi i kodowo-mieszanymi parami językowymi. W szczególności oferujemy szeroką gamę modeli, które konwertują jednojęzyczny tekst angielski na hinduski (kod-mieszany hindi i angielski). Biorąc pod uwagę ostatni sukces wstępnie przeszkolonych modeli językowych, testujemy również użyteczność dwóch najnowszych modeli koderów-dekoderów opartych na Transformerze (tj. mT5 i mBART) w sprawie uznania, że oba modele działają dobrze. Biorąc pod uwagę brak danych treningowych do mieszania kodu, proponujemy również bezzależność metodę generowania tekstów mieszanych kodem z dwujęzycznych reprezentacji rozproszonych, którą wykorzystujemy do poprawy wydajności modelu językowego. W szczególności, uzbrojeni w te dodatkowe dane, przyjmujemy podejście do uczenia się programów nauczania, w którym najpierw dostosowujemy modele językowe na podstawie danych syntetycznych, a następnie na danych ze złotym kodem mieszanych. Stwierdzamy, że choć nasza syntetyczna metoda mieszania kodu jest prosta, konkurencyjna (a w niektórych przypadkach jest nawet lepsza) od kilku standardowych metod (backtranslation, metoda oparta na teorii ograniczeń równoważności) w różnych warunkach. Nasze prace pokazują, że model mT5, dopracowany zgodnie z procedurą uczenia się programu nauczania, osiąga najlepszą wydajność tłumaczenia (12.67 BLEU). Nasze modelki zajmują pierwsze miejsce w ogólnym rankingu angielsko-hindijskiego oficjalnego wspólnego zadania.', 'ro': 'Descriem modele axate pe problema dublată a traducerii între perechi de limbi monolingve și cod-mixte. Mai exact, oferim o gamă largă de modele care transformă textul monolingv în limba engleză în hinglish (cod-mixt Hindi și Engleză). Având în vedere succesul recent al modelelor lingvistice pre-instruite, testăm, de asemenea, utilitatea a două modele recente de encoder-decoder bazate pe Transformer (adică, mT5 și mBART) pentru a găsi sarcina ambele pentru a funcționa bine. Având în vedere reducerea datelor de instruire pentru amestecarea codurilor, propunem, de asemenea, o metodă fără dependență pentru generarea textelor amestecate de cod din reprezentări distribuite bilingve pe care le exploatăm pentru îmbunătățirea performanței modelului lingvistic. În special, înarmați cu aceste date suplimentare, adoptăm o abordare de învățare curriculară în cazul în care mai întâi finuțim modelele lingvistice pe date sintetice apoi pe date amestecate cu coduri aurii. Considerăm că, deși simplă, metoda noastră sintetică de amestecare a codurilor este competitivă cu (și, în unele cazuri, este chiar superioară) mai multe metode standard (backtranslation, metodă bazată pe teoria constrângerii echivalenței) într-un set divers de condiții. Lucrările noastre arată că modelul mT5, finuțit după procedura de învățare curriculară, obține cele mai bune performanțe de traducere (12.67 BLEU). Modelele noastre se situează pe primul loc în clasamentul general al sarcinii oficiale englez-hinglish partajate.', 'ur': 'ہم موڈل کی توصیف کرتے ہیں جو ایک زبان اور کوڈ میکس زبان جوڑوں کے درمیان ترجمہ کرنے کی کم پڑھی ہوئی مسئلہ پر منتخب کیا گیا ہے۔ اور زیادہ مخصوص، ہم ایک بڑی مدل پیش کرتے ہیں جو ایک زبان انگلیسی متن کو ہینگلیش میں تبدیل کرتی ہے (کڈ میکس ہینڈی اور انگلیسی میں) ۔ ہم نے اچھی موفقیت کے ذریعہ دو اگلے ٹرنفسر-بنیادی اکڈر-ڈکوڈر موڈل (یعنی mT5 اور mBART) کی استعمال کو بھی آزمائش کی۔ کوڈ میکسنگ کے لئے آموزش دادہ کی کمزوری کے ذریعہ، ہم نے بھی کوڈ میکسنگ کے متعلق متعلق متعلق متعلق متعلق ہونے کے لئے کڈ میکسنگ کے متعلق متعلق متعلق ہونے کے لئے ایک مطابق بے نیاز طریقہ پیش کرتا ہے کہ ہم زبان مدل عملکرد کو بہتر کرنے مخصوصاً یہ اضافہ ڈیٹا کے ساتھ مسلح ہیں، ہم ایک کریٹرکیلوم کی تعلیم کا طریقہ قبول کرتے ہیں جہاں ہم پہلی بار سینٹیٹیک ڈیٹا پر زبان کی مدل مطالب کرتے ہیں پھر سونے کی کوڈ مmixed ڈیٹا پر۔ ہمیں معلوم ہے کہ، اگرچہ ساده، ہماری سینٹیسی کوڈ میکسنگ طریقہ مختلف شرایط کے اندر (اور کچھ موقع میں بھی زیادہ زیادہ) بہت سی استاندارڈ طریقے (backtranslation, method based on equivalence constraint theory) کے ساتھ ہے. ہمارا کام دکھاتا ہے کہ mT5 موڈل، کورکریکلوم کی تعلیم پردازی کے پیچھے اچھا ترجمہ کرنا کامل ہوتا ہے (12.67 BLEU). ہمارے مدل پہلے انگلیسی-ہینگلیش کے سارے رقم میں مشترک کام رکھتے ہیں.', 'vi': 'Chúng tôi mô tả các mô hình tập trung vào vấn đề người đóng thế dịch giữa hai cặp ngôn ngữ chung và mã. Cụ thể hơn, chúng tôi cung cấp một loạt các mô hình biến đổi chữ tiếng Anh bằng ngôn ngữ thành Hinglish (mã trộn tiếng Ấn và Anh). Xét thấy sự thành công của các mô hình ngôn ngữ sẵn sàng, chúng tôi cũng kiểm tra tiện ích của hai mô hình mã hóa nền Tranlão gần đây (tức là, mT1 và mBART) về việc tìm kiếm cả hai hoạt động tốt. Do thiếu dữ liệu đào tạo cho việc pha trộn mật mã, chúng tôi cũng đề xuất một phương pháp miễn lệ để tạo ra mã trộn các văn bản từ các biểu tượng hai chiều mà chúng tôi tận dụng để cải thiện khả năng của mô hình ngôn ngữ. Đặc biệt, trang bị với những dữ liệu bổ sung này, chúng ta sử dụng phương pháp dạy học lịch trình nơi chúng ta lần đầu tiên tinh chỉnh các mô hình ngôn ngữ về dữ liệu tổng hợp sau đó về mã hóa vàng. Chúng tôi thấy rằng, mặc dù đơn giản, phương pháp pha chế của chúng tôi cạnh tranh với (và trong một số trường hợp thậm chí còn hơn) nhiều phương pháp tiêu chuẩn (bản dịch ngược, phương pháp dựa trên giả thuyết cán bộ điều khiển độ đồng minh) trong một số trường hợp khác nhau. Những nghiên cứu của chúng tôi cho thấy mô hình mT5, được hoàn thiện theo quy trình học tập theo chương trình dạy học. Những mẫu này xếp hạng đầu tiên cho vị trí tổng hợp của chức vụ Anh-Hinglish.', 'uz': "Biz modellarni o'rganamiz, o'zim tilning o'rtasida o'zgarish muammolariga o'rganamiz. Koʻproq, biz monolik ingliz tilidagi matnni Hinglish (kodlash xindi va Inglizchaga bog'liq) ga aytib olamiz. Yaqinda ishlatilgan tillar modellariga muvaffaqiyatli berilganda, biz ikkita yil Transformer asosida kodekoder modellarining foydalanishini sinab ko'rayapmiz. m. mT5 va mBART ikkita vazifani yaxshi ishlash uchun. Given the paucity of training data for code-mixing, we also propose a dependency-free method for generating code-mixed texts from bilingual distributed representations that we exploit for improving language model performance.  Hullas, bu qo'shimcha maʼlumot bilan qo'shilgan, biz o'rganishni o'rganish usulni ishlayapmiz. Biz birinchi birinchi tillar modellarini syntetik maʼlumotlarida bajaramiz, keyin gold kodi- mixed maʼlumot bilan o'zgarishmiz. Biz o'ylaymiz, agar sodda bo'lsa, bizning syntetik kodi- mix usuli turli turli holatda bir necha standard usullar (backtranslation, metoda qiymati cheksiz teoriga asosida) bilan bir xil holatlar bilan ishlab chiqaradi. Bizning ishlarimiz, mT5 modeli, maktab o'rganish vazifasi davomida bir yaxshi tarjima bajaradi (12. 67 BLEU). Bizning modellarimiz ingliz-Hinglish tashkilotlarining birinchi tashkilotlarida boshlanadi.", 'bg': 'Описваме модели, фокусирани върху проблема с превеждането между едноезични и кодово смесени езикови двойки. По-конкретно, ние предлагаме широка гама от модели, които преобразуват едноезичен английски текст в хинглийш (кодово смесен хинди и английски). Предвид неотдавнашния успех на предтренираните езикови модели, тестваме и полезността на два скорошни модела кодер-декодер базирани на трансформатори (т.е. mT5 и mBART) за намирането на задачата и двете да работят добре. Предвид липсата на данни за обучение за смесване на кодове, предлагаме и метод без зависимост за генериране на кодово смесени текстове от двуезични разпределени представи, които използваме за подобряване на производителността на езиковия модел. По-специално, въоръжени с тези допълнителни данни, ние възприемаме подход за обучение в учебната програма, при който първо усъвършенстваме езиковите модели на синтетични данни, а след това на данни със смесени златни кодове. Откриваме, че макар и прост, нашият метод за синтетично смесване на кодове е конкурентен с (и в някои случаи дори е по-добър от) няколко стандартни метода (обратен превод, метод базиран на теория на еквивалентните ограничения) при различни условия. Работата ни показва, че моделът, усъвършенстван в съответствие с учебната процедура, постига най-добри резултати в превода (12.67 БЮ). Нашите модели заемат първо място в цялостното класиране на английско-хинглийската официална споделена задача.', 'hr': 'Opišemo modele usredotočene na podstudirani problem prevoda između monojezičkih i mješanih jezičkih parova. Još specifičnije, nudimo širok niz modela koji pretvaraju monojezički engleski tekst u Hinglish (kombinirani hindi i engleski kod). S obzirom na nedavni uspjeh preliječenih jezičkih modela, također testiramo korisnost dva nedavna modela kodera-dekodera na transformeru (tj. mT5 i mBART) na zadatku koji se nalaze kako treba dobro raditi. S obzirom na nedostatak podataka o obuci za mješanje kodova, također predlažemo metodu bez zavisnosti za stvaranje teksta mješane kod iz dvojezičkih raspodjeljenih predstavljanja koje koristimo za poboljšanje učinkovitosti jezičkih model a. Posebno, naoružani ovim dodatnim podacima, usvojimo pristup učenja nastavnog programa gdje prvi put završimo jezičke modele o sintetičkim podacima, a zatim o zlatnim podacima. Mi smatramo da, iako je jednostavan, naša sintetička metoda miješanja kodova konkurentna s (i u nekim slučajevima je čak i nadmašila) nekoliko standardnih metoda (backtranslation, metoda bazirana na teoriji ograničenja ekvivalencije) pod raznim uvjetima. Naš rad pokazuje da model mT5, koji je ispunjen nakon postupka učenja nastavnih programa, postigne najbolju učinku prevođenja (12,67 BLEU). Naši modeli su prvi u ukupnom redovištu službenog dijeljenog zadatka engleskog-Hingliša.', 'nl': 'We beschrijven modellen gericht op het onderbestudeerde probleem van het vertalen tussen eentalige en code-gemengde taalparen. Meer specifiek bieden we een breed scala aan modellen die eentalige Engelse tekst omzetten in Hinglish (code-mixed Hindi en Engels). Gezien het recente succes van vooraf getrainde taalmodellen, testen we ook het nut van twee recente Transformer-gebaseerde encoder-decoder modellen (d.w.z., mT5 en mBART) op de taak om beide goed te werken. Gezien het gebrek aan trainingsgegevens voor code-mixing, stellen we ook een afhankelijkheidsvrije methode voor het genereren van code-gemengde teksten uit tweetalige gedistribueerde representaties voor die we gebruiken om de prestaties van taalmodellen te verbeteren. Met name, gewapend met deze aanvullende gegevens, hanteren we een curriculum learning aanpak waarbij we eerst de taalmodellen verfijnen op synthetische gegevens en vervolgens op gouden code-gemengde data. We vinden dat, hoewel eenvoudig, onze synthetische code-mengmethode concurrerend is met (en in sommige gevallen zelfs superieur is aan) verschillende standaardmethoden (backtranslation, methode gebaseerd op equivalentiebeperking theorie) onder verschillende omstandigheden. Ons werk toont aan dat het mT5 model, dat is afgestemd op de leerprocedure van het curriculum, de beste vertaalprestaties behaalt (12.67 BLEU). Onze modellen plaatsen zich op de eerste plaats in de algemene ranking van de Engels-Hinglish officiële gedeelde taak.', 'da': 'Vi beskriver modeller fokuseret på det dublerede problem med oversættelse mellem ensprogede og kodeblandede sprogpar. Mere specifikt tilbyder vi en bred vifte af modeller, der konverterer ensproget engelsk tekst til hinglish (kode-blandet hindi og engelsk). I betragtning af den seneste succes med forudtrænede sprogmodeller tester vi også nytten af to nylige Transformer-baserede encoder-dekoder modeller (dvs. mT5 og mBART) på opgaven at finde begge til at fungere godt. I betragtning af manglen på træningsdata til kode-blanding foreslår vi også en afhængighedsfri metode til at generere kode-blandede tekster fra tosprogede distribuerede repræsentationer, som vi udnytter til at forbedre sprogmodellens ydeevne. Især bevæbnet med disse yderligere data anvender vi en læringsmetode, hvor vi først finjusterer sprogmodellerne på syntetiske data og derefter på guldkodeblandede data. Vi finder, at vores syntetiske kodeblandingsmetode, selv om den er enkel, konkurrencedygtig med (og i nogle tilfælde er endda bedre end) flere standardmetoder (backtranslation, metode baseret på ækvivalensbegrænsningsteori) under forskellige betingelser. Vores arbejde viser, at mT5 modellen, finjusteret efter læseplanens læringsprocedure, opnår den bedste oversættelsespræstation (12.67 BLEU). Vores modeller placerer først i den overordnede placering af den engelsk-hingliske officielle delte opgave.', 'de': 'Wir beschreiben Modelle, die sich auf das noch nicht untersuchte Problem der Übersetzung zwischen monolingualen und code-mixed Sprachpaaren konzentrieren. Genauer gesagt bieten wir eine breite Palette von Modellen an, die einsprachigen englischen Text in Hinglisch (code-mixed Hindi und Englisch) umwandeln. Angesichts des jüngsten Erfolgs von vortrainierten Sprachmodellen testen wir auch die Nützlichkeit zweier aktueller Transformer-basierter Encoder-Decoder-Modelle (d.h. mT5 und mBART), um festzustellen, dass beide gut funktionieren. Angesichts des Mangels an Trainingsdaten für Code-Mixing schlagen wir auch eine abhängigkeitsfreie Methode vor, um Code-Mixed-Texte aus zweisprachigen verteilten Repräsentationen zu generieren, die wir zur Verbesserung der Leistung von Sprachmodellen nutzen. Insbesondere, bewaffnet mit diesen zusätzlichen Daten, verfolgen wir einen Curriculum-Lernansatz, bei dem wir zuerst die Sprachmodelle auf synthetischen Daten und dann auf Gold-Code-Mixed-Daten verfeinern. Wir stellen fest, dass unsere synthetische Code-Mixing-Methode zwar einfach ist, aber mit mehreren Standardmethoden (Backtranslation, Methode basierend auf Äquivalenzbeschränkungstheorie) unter verschiedenen Bedingungen konkurrenzfähig ist (und in einigen Fällen sogar überlegen ist). Unsere Arbeit zeigt, dass das nach dem Curriculum-Lernverfahren verfeinerte mT5-Modell beste Übersetzungsleistungen erzielt (12.67 BLEU). Unsere Models belegen den ersten Platz im Gesamtranking der englisch-Hinglish offiziellen Shared Task.', 'id': 'Kami menggambarkan model yang fokus pada masalah terjemahan diantara pasangan bahasa monobahasa dan kode-campuran. Lebih spesifik, kami menawarkan jangkauan yang luas dari model yang mengubah teks bahasa Inggris monobahasa menjadi Hinglish (kode-campuran Hindi dan Inggris). Mengingat keberhasilan baru-baru ini dari model bahasa terlatih, kami juga menguji utilitas dua model koder-dekoder berasaskan Transformer baru-baru ini (i.e., mT5 dan mBART) pada tugas menemukan keduanya untuk bekerja dengan baik. Mengingat kekurangan data pelatihan untuk campuran kode, kami juga mengusulkan metode bebas dependensi untuk menghasilkan teks campuran kode dari representation yang didistribusikan dua bahasa yang kami eksploitasi untuk meningkatkan prestasi model bahasa. Terutama, bersenjata dengan data tambahan ini, kami mengadopsi pendekatan pelajaran kurikulum di mana pertama kali kami memperbaiki model bahasa pada data sintetis kemudian pada data campuran kode emas. Kami menemukan bahwa, meskipun sederhana, metode campuran kode sintetis kami adalah kompetitif dengan (dan dalam beberapa kasus bahkan lebih baik dari) beberapa metode standar (backtranslation, metode berdasarkan teori batasan ekvivalensi) dalam set berbagai kondisi. Pekerjaan kami menunjukkan bahwa model mT5, ditetapkan mengikuti prosedur belajar kurikulum, mencapai prestasi terjemahan terbaik (12,67 BLEU). Our models place first in the overall ranking of the English-Hinglish official shared task.', 'ko': '우리가 묘사한 모델은 연구되지 않은 단어와 코드 혼합 언어의 번역 문제에 집중되어 있다.더욱 구체적으로 말하면, 우리는 일련의 단어 영어 텍스트를 Hinglish (코드가 인디언과 영어를 혼합한 것) 로 바꾸는 모델을 제공했다.예훈련 언어 모델이 최근에 얻은 성공을 감안하여 우리는 두 가지 최신 변환기 기반의 인코더 - 디코더 모델(즉 mT5와 mBART)이 임무에서의 실용성을 시험하여 둘 다 잘 작동할 수 있음을 발견하였다.코드 혼합의 훈련 데이터가 비교적 적음을 감안하여 우리는 이중 언어 분포식에서 코드 혼합 텍스트를 생성하는 무의의존적인 방법을 제시했고 이 방법을 이용하여 언어 모델의 성능을 향상시켰다.특히 이러한 추가 데이터가 있기 때문에 우리는 과정 학습 방법을 채택하여 먼저 합성 데이터의 언어 모델을 미세하게 조정한 다음에 황금 코드 혼합 데이터를 미세하게 조정했다.우리는 비록 간단하지만 서로 다른 조건하에서 우리의 합성 코드 혼합 방법과 몇 가지 표준 방법(반역, 등가 구속 이론을 바탕으로 하는 방법)이 경쟁력(어떤 상황에서는 심지어 우수하다는 것을 발견했다.우리의 작업은 mT5 모델을 과정 학습 프로그램에 따라 미세하게 조정하여 최상의 번역 성능(12.67 BLEU)을 실현하였다는 것을 나타낸다.우리의 모델은 영어 Hinglish 공식 공유 임무의 전체 순위에서 1위를 차지했다.', 'sw': 'Tunaelezea mifano yenye lengo la tatizo la kutafsiri kati ya wanandoa wa lugha za kiutamaduni na lugha tofauti. Zaidi zaidi, tunatoa mifano mengi ambayo hugeuza ujumbe wa lugha ya Kiingereza katika Hinglish (kwa mujibu wa mifano ya Kihindi na Kiingereza). Kutokana na mafanikio ya hivi karibuni ya mifano ya lugha iliyopigwa, pia tunajaribu matumizi ya mifano miwili ya mfumo wa kodekodi wa zamani (yaani mT5 na mBART) katika kazi inayogundua vizuri. Kutokana na ufahamu wa taarifa za mafunzo kwa ajili ya mchanganyiko wa kodi, pia tunapendekeza njia ya kutegemea bure ya kutengeneza ujumbe wa mfumo mchanganyiko wa kodi kutoka uwakilishi wa lugha mbili ambao tunatumia ili kuboresha utendaji wa mifano ya lugha. hasa, wenye silaha na taarifa hizi za ziada, tunachukua mbinu za kujifunza kwa ufundi ambapo kwanza tunatumia mifano ya lugha kwenye taarifa za pamoja na takwimu za dhahabu zinazochanganyika. Tunapata kwamba, ingawa rahisi, mbinu yetu ya mchanganyiko wa kodi ni jitihada na (na katika baadhi ya matukio mengine ni bora zaidi) mbinu kadhaa za msingi (tafsiri za nyuma, mbinu zinazohusiana na nadharia ya usawa) chini ya mazingira mbalimbali. Kazi zetu zinaonyesha kuwa mtindo wa mT5, uliotengenezwa kufuatia utaratibu wa kujifunza elimu, unafanikiwa ufanisi bora wa tafsiri (12.67 BLEU). Mifano yetu imeweka kwanza katika maeneo ya jumla ya kazi ya ofisa wa Kiingereza na Kiingereza.', 'fa': 'ما مدل\u200cها را توصیف می\u200cکنیم که روی مشکل تحقیق شده\u200cاند که بین جفت\u200cهای زبان\u200cهای یکزبانی و کد\u200cترکیب شده\u200cاند، متمرکز شده\u200cاند. دقیقاً ما مدل های گسترده ای را پیشنهاد می کنیم که متن انگلیسی تنها زبان را به هنگلیش تبدیل می کنند. با توجه به موفقیت اخیر از مدل زبانی که پیش از آن بوده است، ما نیز استفاده از دو مدل\u200cهای کودکور-دکور\u200cکننده\u200cی تغییر\u200cکننده\u200cی اخیر (یعنی mT5 و mBART) بر روی کار یافتن هر دو برای خوب کار آزمایش می\u200cکنیم. با توجه به ناتوانی داده های آموزش برای ترکیب کد، ما همچنین یک روش آزاد بستگی برای تولید متن های ترکیب کد از نمایش های دو زبان تقسیم می کنیم که برای improving performance model زبان استفاده می کنیم. مخصوصا، با این داده های اضافی مسلح، ما یک روش آموزش برنامه آموزش آموزش را قبول می کنیم که اول مدل زبانی را روی داده های سینتاتیک در مورد داده های مختلف کد طلا قرار می دهیم. ما متوجه می\u200cشویم که، اگرچه ساده، روش پیوند پیوند پیوند پیوند پیوند پیوند پیوند\u200cگیری ما با (و در بعضی مورد\u200cها حتی بیشتر از) روش\u200cهای استاندارد (پیوند پیوند\u200cگیری، روش بر اساس تئوری محدودیت برابر) زیر یک مجموعه شرایط مختلف است. کار ما نشان می دهد که مدل mT5، که از طریق تحصیل برنامه آموزش برنامه\u200cهای آموزش پاکیزه شده، بهترین تحصیل ترجمه (۱۲.۷۷ BLEU) می\u200cرسد. مدل\u200cهای ما اول در کل نقطه\u200cای از کار رسمی مشترک انگلیسی و هنگلیش قرار می\u200cگیرند.', 'af': "Ons beskrywe modele wat gefokus is by die ondersteunde probleem om te vertaling tussen monolinglike en kode gemengde taal pare. More specifically, we offer a wide range of models that convert monolingual English text into Hinglish (code-mixed Hindi and English). Omdat ons die onlangse sukses van die pretreënde taal modelles, ons ook die nutsprogram van twee onlangse Transformer-gebaseerde enkoder-dekodermodelles (bv. mT5 en mBART) op die taak wat beide te vind om goed te werk. Omdat ons die belangrikheid van onderwerp data vir kode-gemenging voorstel, is ons ook 'n afhanklikheid-vry metode vir die genereer van kode-gemengde teks van twee tale verdeelde voorstellings wat ons gebruik het vir die verbetering van taal-model-prestasie. Spesifieke, gewapend met hierdie addisionele data, aanvaar ons 'n onderwerp van onderwerp waar ons eerste die taal modele op sintetiese data aanvaar dan op goud kode gemengde data. Ons vind dat, alhoewel eenvoudig, ons sintetiese kode-gemeenskap metode is rekenaar met (en in sommige gevalle is selfs superior na) verskeie standaard metodes (terugvertaling, metode gebaseer op ekvivalence begrens teoriee) onder 'n verskeie stel van voorwaardes. Ons werk wys dat die mT5-model, gevolg volgens die onderwerp-onderwerp-prosedure, die beste vertaling-prestasie bereik (12,67 BLEU). Ons modele plaas eerste in die hele rangering van die Engels-Hinglish offisiele gedeelde taak.", 'tr': 'Biz modelleri monodil bilen cödleşikli dil çiftleriniň terjime etmegiň altyndaky okuwçylar meselesine tassyýarys. Aýratyn görä, biz iñlis dilinde bir görnüş nusgalary Hingliş diline çevirilýäris (ködlemeler bilen Hindiler we iňlislere çevirilýäris). Öň soňky dil nusgalarynyň üstünliklerini görä, hem iki i ň soňky Transformer-tabanly koder-dekoder nusgalarynyň ullanyşyny bardyk. Ködleme karıştırmak üçin maglumatlaryň azalygyna görä, biz hem dil nusgasyny geliştirmek üçin ulanýan cödleme karıştırılýan metinlerden üýtgetmek üçin boýunça täsirli metinleri teklip edýäris. Aýratyn bolsa, bu golaý maglumatlar bilen goşulan, biz okuw programynyň öwrenmegi ýaryşyny kabul edip, ol ýerde ilkinji gezek sintetik maglumatlar üzerinde dil modellerini çykaryp, soňra altyn kodyň karışyk maglumatlary bardyr. Biz esasy bolsa, syntetik ködleme karışma yöntemimiz birnäçe çeşitli şartlaryň altynda (we käbir ýagdaýda hem üstünde) birnäçe standart yöntemlerimiz (terjime edilen, ekvivalent çykyş teoriýasyna daýanýan yöntemlerimiz) duşuşygy görýäris. Biziň işimiz mT5 modeliniň, programleriň öwrenmegi ýagdaýynda edilen iň gowy terjime etmägi başarýandygyny görkezýär (12.67 BLEU). Biziň modellerimiz ilkinji gezek Iňlisçe-Hingliş resmi subutynyň halkara işinde ýerleşýär.', 'am': 'በሞላዊ ቋንቋ እና የቋንቋ ቋንቋ ሁለቱን መተርጓሜን በመታወቂያው መከራ ላይ የሚቆጣውን ምሳሌዎች እናሳውቃለን፡፡ በተጨማሪም፣ የሞሎንቋ ቋንቋ ጽሑፎችን ወደ Hinglish (የኮድ-ቀለጠ Hindi እና እንግሊዘኛ) የሚለውጥ ብዙ ሞዴላዎችን እናቀርባለን፡፡ በአሁኑ ጊዜ የቋንቋ ምሳሌዎች የሞላቱ ስኬት በተደረገ ጊዜ፣ ለሁለቱ የቅርብ ተቃውሞ የሆኑት የሆኑት የሆኑት የፊደል ኮድድ-ዴክዶር ሞዴላዎች (ምሳሌ mT5 እና mBART) በመሥራት ላይ ጥቅም እናደርጋለን፡፡ ለኮድ-መቀያየት የድምፅ ማህበረሰብ ማቀናቀል በተለየ ቋንቋዎች የጽሑፎችን የክፍለ ሥርዓት መፍጠር እናስጀምራለን፡፡ በተለይም፣ በዚህ የበዛ ዳታዎች የተመሳሳይ፣ መጀመሪያ የቋንቋውን ምሳሌዎች በሴንቲካዊ ዳታዎች እና ከዚያም በኋላ በወርቅ ኮድ በተለየ ዳታዎችን እናስቀምጣለን፡፡ ምንም እንኳን ቀላል ቢሆንም፣ የሲንቲካዊ ኮድ-መቀላቀል ሥርዓታችን በተለየ (እና አንዳንድ ክፍሎች ይልቅ የበለጠ) በተለያዩ ሁኔታዎች ውስጥ ብዙዎች የድጋፍ ድርጊቶች (backtranslation, method በትክክል ግንኙነት ታሪኮች) ይታገላታል፡፡ ትምህርት ትምህርት ፕሮግራሙን ተከትሎ MT5 ሞዴል የተሻለ ትርጓሜን አግኝቷል (12.67 BLEU). ሞዴላዎቻችን አስቀድሞ በንግግሊዘኛ-Hinglish ባለሥልጣናዊ ተሳታፊ ስራ ውስጥ ነው፡፡', 'hy': 'Մենք նկարագրում ենք մոդելներ, որոնք կենտրոնացված են միալեզվի և կոդի խառնված լեզվի զույգերի թարգմանման թերագնահատված խնդիրը: Ավելի հատկապես, մենք առաջարկում ենք մի շարք մոդելներ, որոնք փոխակերպում են անգլերեն մեկլեզու տեքստը հինգլերեն (շինգլերեն և անգլերեն շինգլերեն): Հետևաբար նախօրինակված լեզվի մոդելների վերջին հաջողությունը, մենք նաև փորձում ենք վերջին երկու վերջին Transforme-հիմնված կոդեր-կոդեր մոդելների (այսինքն mT5 և mBAR) օգտակարությունը, որպեսզի երկուսն էլ լավ աշխատեն: Եթե հաշվի առնենք կոդի խառնման ուսումնասիրության տվյալների բացակայությունը, մենք նաև առաջարկում ենք անկախ մեթոդ կոդի խառնված հաղորդագրությունների ստեղծման համար երկլեզու տարածված ներկայացումներից, որոնք օգտագործվում ենք լեզվի մոդելի արդյունքների բարելավման համար Մասնավորապես, զբաղված այս ավելացյալ տվյալներով, մենք ընդունում ենք ուսումնական ծրագրերի ուսումնասիրության մոտեցում, որտեղ առաջին անգամ փոքրացնում ենք լեզվի մոդելները սինթետիկ տվյալների վրա, հետո ոսկու կոդի խառնված տվյա Մենք հայտնաբերում ենք, որ, չնայած պարզ է, մեր սինթետիկ կոդի խառնման մեթոդը մրցակցում է (և որոշ դեպքերում նույնիսկ գերազանցում է) մի քանի ստանդարտ մեթոդների հետ (ետնաթարգմանություն, մեթոդը հիմնված հավասարության սահմանափակումների տեսության վրա) բազմազա Մեր աշխատանքը ցույց է տալիս, որ mT5-ի մոդելը, որը լավագույն կերպով բարձրացված է ուսումնական ծրագրերի ուսումնասիրության ընթացքում, հասնում է լավագույն թարգմանման արդյունքին (12.67 ԲԼԵՎ): Մեր մոդելները առաջինը գտնվում են անգլերեն-հինգլերեն պաշտոնական հանձնարարության ընդհանուր դասակարգում:', 'sq': 'Ne përshkruajmë modele të përqëndruara në problemin e keqkuptuar të përkthimit midis çifteve gjuhësh monogjuhës dhe kodeve të përziera. Më specifikisht, ne ofrojmë një gamë të gjerë modelesh që konvertojnë tekstin anglez monogjuhës në hinglish (kod-përzier Hindi dhe Anglisht). Duke pasur parasysh suksesin e kohëve të fundit të modeleve të gjuhës së parastërvitur, ne gjithashtu testojmë utilitetin e dy modeleve të fundit të koduesit-dekoderit me bazë në Transformer (pra, mT5 dhe mBART) në detyrën për të gjetur të dy për të funksionuar mirë. Duke pasur parasysh mungesën e të dhënave të trajnimit për përzierjen e kodeve, ne gjithashtu propozojmë një metodë pa varësi për krijimin e teksteve të përziera me kode nga përfaqësimet e shpërndara dygjuhëse që ne shfrytëzojmë për përmirësimin e performancës së modelit gjuhësor. Veçanërisht, të armatosur me këto të dhëna shtesë, ne miratojmë një qasje mësimi në programin e mësimit ku së pari i përshtatemi modelet gjuhësore në të dhënat sintetike pastaj në të dhënat e përziera me kod ari. Ne zbulojmë se, megjithëse e thjeshtë, metoda jonë sintetike e përzierjes së kodeve është konkurruese me (dhe në disa raste është edhe më e lartë se) disa metoda standarde (përkthimi prapa, metoda bazuar në teorinë e kufizimeve ekuivalence) në një sërë kushteve të ndryshme. Puna jonë tregon se modeli mT5, i përmirësuar pas procedurës së mësimit të kurikullit, arrin shfaqjen më të mirë të përkthimit (12.67 BLEU). Modelet tona vendosin së pari në renditjen e përgjithshme të detyrës së përbashkët anglo-hinglish.', 'az': 'Biz modell…ôri monodil v…ô kodla karńĪŇüńĪq dil √ßiftl…ôri arasńĪnda √ßevirilm…ôk probleml…ôrin…ô odaqlandńĪrńĪrńĪq. Daha √ßox x√ľsusiyy…ôtli, bir √ßox modell…ôr t…ôklif edirik ki, monodilli ńįngiliz…ô metini HingliŇü (kodla karńĪŇümńĪŇü Hindi v…ô ńįngiliz…ô √ßevirirl…ôr). ∆Źvv…ôlki dil modellerinin baŇüarńĪsńĪzlńĪńüńĪna g√∂r…ô, h…ôr ikisinin yaxŇüńĪ i Ňül…ôr g√∂rm…ôk √ľ√ß√ľn daha yeni Transformer-tabanlńĪ kodlayńĪcńĪ modell…ôrin istifad…ôsini d…ô imtahana √ß…ôkirik. Kod karńĪŇümasńĪ √ľ√ß√ľn t…ôhsil veril…ôn m…ôlumatlarńĪn z…ôifliyin…ô baxmayaraq, biz d…ô c√≤d karńĪŇüńĪqlńĪ m…ôlumatlarńĪn yaratmasńĪnńĪ v…ô dil modell…ôrini yaxŇüńĪlaŇüdńĪrmaq √ľ√ß√ľn istifad…ô edirik. √Ėzellikle, bu …ôlav…ô m…ôlumatlarla birlikd…ô istifad…ô edirik. Biz ilk d…ôf…ô sintetik m…ôlumatlarńĪn dil modell…ôrini, sonra altńĪn kodu karńĪŇümńĪŇü m…ôlumatlarńĪn bar…ôsind…ô istifad…ô edirik. Biz sad…ôc…ô olaraq, sintetik kodu karńĪŇüma metodumuz m√ľxt…ôlif Ňüartlar altńĪnda bir ne√ß…ô standart metodlarńĪna (geri √ßeviriŇü metodlarńĪna, eynilik m√ľ…ôyy…ôn teoriyy…ô dayanan) m√ľqayis…ôdir. √áalńĪŇümalarńĪmńĪz g√∂st…ôrir ki, mT5 modeli, √∂yr…ônm…ôk proqramńĪnńĪn ardńĪnca t…ôhsil edilm…ôsi …ôn yaxŇüńĪ t…ôhsil g√∂st…ôrir (12.67 BLEU). Bizim modell…ôrimiz ilk d…ôf…ô ńįngilis-Hinglish resmi paylaŇüńĪlan iŇüin b√ľt√ľn s…ôviyy…ôl…ôrind…ô yerl…ôŇüdirdi.', 'bs': 'Mi opisujemo modele fokusirane na podstudirani problem prevode između monojezičkih i kombiniranih jezičkih parova. Još specifičnije, nudimo širok niz modela koji pretvaraju monojezički engleski tekst u Hinglish (pomiješani hindi i engleski kod). S obzirom na nedavni uspjeh predivnih jezičkih modela, također testiramo korisnost dva nedavna modela kodera-dekodera na transformeru (tj. mT5 i mBART) na zadatku koji se nalaze kako bi dobro funkcionirali. S obzirom na nedostatak podataka o obuci za mješanje kodova, također predlažemo metodu bez zavisnosti za stvaranje teksta mješane kodovima iz dvojezičkih raspodjeljenih predstavljanja koje koristimo za poboljšanje učinka jezičkih model a. Posebno, naoružani ovim dodatnim podacima, usvojimo pristup učenja nastavnog programa gdje prvi put završimo jezičke modele o sintetičkim podacima, a zatim o zlatnim podacima. Mi smatramo da, iako je jednostavno, naša sintetička metoda miješanja kodova konkurentna sa (i u nekim slučajevima je čak i nadmašila) nekoliko standardnih metoda (backtranslation, metoda bazirana na teoriji ograničenja ekvivalencije) pod različitim skupom uvjeta. Naš rad pokazuje da model mT5, koji je ispunjen nakon procedure učenja nastavnih programa, postigne najbolji izvor prevoda (12,67 BLEU). Naši modeli su prvi u ukupnom redovištu službenog dijeljenog zadatka engleskog-Hingliša.', 'ca': "Descrivem models centrats en el problema subestimat de la traducció entre parells de llenguatges monolingües i combinats de codis. En concret, oferim una gran varietat de models que converteixen el text anglès monolingüe en hindlés (Hindi i anglès combinats amb codi). Tenint en compte l'èxit recent dels models de llenguatge preconformats, també provem l'utilitat de dos models recents de codificador basats en Transformer (i.e., mT5 i mBART) en la tasca de trobar que ambdós funcionen bé. Tenint en compte la escassetat de dades d'entrenament per la combinació de codis, també proposem un mètode sense dependència per generar textos combinats amb codis a partir de representacions distribuïdes bilingües que explotam per millorar el rendiment del model lingüístic. En particular, armats amb aquestes dades adicionals, adoptem un enfocament d'aprenentatge del currículum on primer ajuntem els models de llenguatge en dades sintètiques i després en dades barrejades amb codi d'or. Trobem que, tot i que és simple, el nostre mètode de mistura de codis sintètic és competitiu amb (i en alguns casos és fins i tot superior a) diversos mètodes estàndard (traducció inversa, mètode basat en la teoria de restriccions d'equivalencia) en condicions diverses. La nostra feina mostra que el mT5, perfeccionat segons el procediment d'aprenentatge del currículum, aconsegueix el millor rendiment de traducció (12,67 BLEU). Our models place first in the overall ranking of the English-Hinglish official shared task.", 'bn': 'আমরা মডেল ব্যাখ্যা করি মোনোলিভাল এবং কোড মিশ্রিত ভাষা জোড়ার মধ্যে অনুবাদের সমস্যার দিকে মনোযোগ প্রদান করি। বিশেষ করে আমরা বিশেষ করে বিভিন্ন ধরনের মডেল প্রদান করি যারা মোনোলিভাল ইংরেজী টেক্সট হিঙ্গিশে পরিণত করে (কোড মিশ্রিত হিন সাম্প্রতিক ভাষার মডেলের সাফল্যের কারণে আমরা সাম্প্রতিক ট্রান্সফ্রান্সফার ভিত্তিক কোডার-ডেকোডার মডেলের ব্যবহার পরীক্ষা করি যেমন এমটি৫ এবং এমবি কোড মিশ্রণের জন্য প্রশিক্ষণের তথ্যের প্রাপ্তিত্ব দিয়ে আমরা একটি নির্ভরিত-মুক্ত পদ্ধতি প্রস্তাব করি যা দুই ভাষায় বিতরণ করা প্রতিনিধিদের কাছ থেকে কো বিশেষ করে, এই আরো তথ্য দিয়ে সশস্ত্র, আমরা একটি কার্কুল শিক্ষা পদক্ষেপ গ্রহণ করি, যেখানে আমরা প্রথম সিন্টেটিক ডাটা নিয়ে ভাষার মডেল ফিনিস আমরা খুঁজে পাচ্ছি যে, যদিও সহজ, আমাদের সিন্টেটিক কোড মিশ্রিং পদ্ধতি বিভিন্ন ধরনের পরিস্থিতির অধীনে প্রতিযোগিতা করছে (এবং কিছু ক্ষেত্রে বেশ কিছু স্থানান্তর আমাদের কাজ দেখাচ্ছে যে এমটি৫ মডেল, কার্কুল শিক্ষা প্রক্রিয়ার পর সেরা ভালো অনুবাদ প্রদর্শন করেছে (১২. ৬৭ বিলিউ)। আমাদের মডেল প্রথমে ইংরেজি-হিঙ্গ্লিশ সরকারি কর্মকর্তাদের শেয়ার কর্মসূচিতে প্রথমে স্থাপন করে।', 'cs': 'Popisujeme modely zaměřené na nedostupný problém překladu mezi jednojjazyčnými a kódově smíšenými jazykovými páry. Konkrétněji nabízíme širokou škálu modelů, které převádějí jednojzyčný anglický text do hindštiny (kódově smíšený hindština a angličtina). Vzhledem k nedávnému úspěchu předem trénovaných jazykových modelů testujeme také užitečnost dvou nedávných modelů snímače-dekodérů založených na Transformeru (tj. mT5 a mBART) při zjištění, že oba modely fungují dobře. Vzhledem k nedostatku tréninkových dat pro míchání kódu navrhujeme také bezzávislou metodu generování kódově smíšených textů z dvojjazyčných distribuovaných reprezentací, kterou využíváme pro zlepšení výkonu jazykového modelu. Zejména, vyzbrojeni těmito dodatečnými daty, přijímáme učební přístup, kde nejprve doladíme jazykové modely na syntetických datech a pak na zlatých kódových datech. Zjišťujeme, že i když je naše syntetická metoda míchání kódu jednoduchá, je konkurenční (a v některých případech dokonce lepší) několika standardním metodám (backtranslace, metoda založená na teorii ekvivalenčních omezení) za různých podmínek. Naše práce ukazuje, že model mT5, jemně vyladěný podle učebního postupu, dosahuje nejlepších překladatelských výkonů (12.67 BLEU). Naše modelky se umístí na prvním místě v celkovém žebříčku anglicko-hindského oficiálního sdíleného úkolu.', 'et': 'Kirjeldame mudeleid, mis keskenduvad ühekeelsete ja koodisegakeelsete keelepaaride tõlkimise probleemile. Täpsemalt pakume laia valikut mudeleid, mis teisendavad ühekeelse inglise teksti hingliši keelde (koodisegatud hindi ja inglise keel). Arvestades eeltreenitud keelemudelite hiljutist edu, testime ka kahe hiljutise Transformer-põhise kodeerija-dekooderi mudeli (st mT5 ja mBART) kasulikkust, et mõlemad töötaksid hästi. Arvestades koolitusandmete vähesust koodide segamiseks, pakume välja ka sõltuvusvaba meetodi koodisegatud tekstide genereerimiseks kakskeelsetest hajutatud esitustest, mida kasutame keelemudeli jõudluse parandamiseks. Nende täiendavate andmetega varustatud eelkõige võtame kasutusele õppekava õppimise lähenemisviisi, kus esmalt täpsustame keelemudeleid sünteetiliste andmete ja seejärel kuldkoodidega segatud andmete põhjal. Leiame, et kuigi lihtne, on meie sünteetiline koodisegamismeetod konkurentsivõimeline (ja mõnel juhul isegi parem) mitme standardmeetodiga (tagasitõlge, meetod, mis põhineb ekvivalentsuspiiranguteoorial) erinevates tingimustes. Meie töö näitab, et õppekava õppeprotseduuri järgi täpsustatud mT5 mudel saavutab parima tõlketulemuse (12.67 BLEU). Meie mudelid on Inglise-Hinglishi ametliku jagatud ülesande üldises edetabelis esimesel kohal.', 'fi': 'Kuvaamme malleja, jotka keskittyvät aliarvioituun ongelmaan kääntämisestä yksikielisten ja koodisekoitettujen kieliparien välillä. Tarkemmin sanottuna tarjoamme laajan valikoiman malleja, jotka muuntavat englanninkielisen tekstin hinglishiksi (koodisekoitettu hindi ja englanti). Kun otetaan huomioon esikoulutettujen kielimallien viimeaikainen menestys, testaamme myös kahden viimeaikaisen Transformer-pohjaisen kooderi-dekooderimallin (mT5 ja mBART) hyödyllisyyttä tehtävän löytämisessä. Koodien miksaamiseen tarvittavan koulutusdatan niukkuuden vuoksi ehdotamme myös riippuvuusvapaa menetelmää koodisekoitettujen tekstien tuottamiseen kaksikielisistä hajautetuista esityksistä, joita hyödynnämme kielimallin suorituskyvyn parantamiseksi. Näiden lisätietojen avulla omaksumme opetussuunnitelman oppimistavan, jossa ensin hienosäädämme kielimallit synteettiseen dataan ja sitten kultakoodiin sekoitettuun dataan. Toteamme, että vaikka synteettinen koodisekoitusmenetelmämme onkin yksinkertainen, se kilpailee (ja joissakin tapauksissa jopa on parempi) useiden vakiomenetelmien kanssa (backtranslation, menetelmä perustuu vastaavuusrajoitusteoriaan) erilaisissa olosuhteissa. Työssämme osoitetaan, että opetussuunnitelmaa noudattaen hienosäädetty mT5-malli saavuttaa parhaan käännöksen (12.67 BLEU). Mallimme sijoittuvat ensimmäisenä englannin-hinglishin virallisen tehtävän kokonaissijoituksessa.', 'jv': 'Awak dhéwé ngerwih model sing ngomong dipungot neng akeh basa sing luwih bantuan ingkang sampeyan ingkang karo kode-sampeyan ingkang. string" in "context_BAR_stringLink Genjer perusahaan model sing gawé nggawe sistem yang luwih dumadhi, kita nguasai nggunakake sistem iki bakal dumadhi nggawe Transformer-diangkat model (i.e.g. mT 5 lan mBIRT) sing bakal terus nggawe bakal dumadhi iki bakal dumadhi. Tanggal nggawe kelas kuwi nggawe data nggawe karo kode-melungi, kita ngubah cara perusahaan-perusahaan layar kanggo nggawe nggawe kota-melungi multiteks nggawe pawangan langgar tarjamahan sing bisa ngewat suratan dhéwé nggawe usul dumadhi model nggawe barang langgar. Sampeyan ngilanggar, sampeyan nganggo data unyester iki, kita ngomong sun curric program Learn Method Where we first Finetune the language model on Awak dhéwé luwih akeh, tho sampeyan sampeyan, akeh-sampeyan ngono sistem sing perusahaan karo (lan ning cara-cara sing gak adhasar super-cara) ulih sistem padha ambarator (backtranslation, method basan karo ekyakula-terakhir a sistem sistem sing gak dhéwé) podho akeh sistem pakan. Awakdhéwé nglanggar nganggo model mT 5, iso nggawe gerakan oleh operasi nggawe currumpun, iso nggawe tarjamahan sing luwih (12.Setén CLUE). Rasané awakdhéwé kuwi mesthi nang kabèh dumadhi sakjane ngubah Inggris-hint', 'sk': 'Opisujemo modele, ki se osredotočajo na manjši problem prevajanja med enojezičnimi in kodno mešanimi jezikovnimi pari. Natančneje, ponujamo široko paleto modelov, ki pretvorijo enojezično angleško besedilo v hingliščino (kodno mešano hindijščino in angleščino). Glede na nedavni uspeh predtreniranih jezikovnih modelov smo preizkusili uporabnost dveh nedavnih modelov kodirnikov-dekodirnikov na podlagi transformatorjev (tj. mT5 in mBART) pri iskanju nalog, da oba dobro delujeta. Glede na pomanjkanje podatkov o usposabljanju za mešanje kod predlagamo tudi metodo brez odvisnosti za generiranje besedil z mešanimi kodami iz dvojezičnih porazdeljenih predstavitev, ki jo izkoriščamo za izboljšanje učinkovitosti jezikovnega modela. Oboroženi s temi dodatnimi podatki, uporabljamo pristop učnega učnega načrta, kjer najprej natančno prilagodimo jezikovne modele na sintetičnih podatkih, nato pa na zlate kode mešanih podatkov. Ugotavljamo, da je naša sintetična metoda mešanja kod, čeprav preprosta, konkurenčna z več standardnimi metodami (in v nekaterih primerih celo boljša od) pod različnimi pogoji. Naše delo kaže, da model mT5, ki je natančno nastavljen po učnem postopku, dosega najboljšo prevajalsko uspešnost (12.67 BLEU). Naši modeli se uvrščajo na prvo mesto v splošni lestvici angleško-hingliške uradne skupne naloge.', 'he': 'אנחנו מתארים דוגמנים שמוקדים בבעיה המפורסמת של התרגום בין זוגות שפות מונושפות ומערובות קודים. במיוחד, אנו מציעים מגוון רחב של דוגמנים שמהפכים טקסט אנגלי מונושפתי להינגלי (הונדי ומערובת קוד ואנגלית). בהתחשב בהצלחה האחרונה של דוגמני שפת מראש אימונים, אנו גם מבחנים את השימוש של שני דוגמני קודור-קידור מבוססים על טרנספורטר (כלומר, mT5 ומברט) על המשימה למצוא את שניהם כדי לעבוד היטב. בהתחשב בעדר נתוני אימון לערבוב קודים, אנחנו גם מציעים שיטה ללא תלויות לייצור טקסטים מעורבבים קודים מייצגות משולבות שתיים ששוות שאנחנו מנצלים כדי לשפר את ההפעלות של מודל שפה. במיוחד, חמושים עם נתונים נוספים אלה, אנו מאמצים גישה ללמוד תוכנית לימודים שבו אנחנו קודם מציינים את דוגמני השפה על נתונים סינטטיים ואז על נתונים מעורבים של קוד זהב. אנחנו מוצאים, למרות שפשוטה, שיטת הערבוב הסינטטי שלנו תחרותית עם (ובמקרים מסוימים היא אפילו מעלית) כמה שיטות סטנדרטיות (התרגום האחורי, שיטה מבוססת על תיאוריה של חוסר שוויון) תחת קבוצה מיוחדת של תנאים. העבודה שלנו מראה שהמודל mT5, המתאים לאחר הליך הלימודים של תוכנית הלימודים, משיג את ההופעה הטובה ביותר בתרגום (12.67 BLEU). הדוגמנים שלנו מופיעים ראשונים בתורגות הכללית של משימה רשמית אנגלית-הינגלית משותפת.', 'ha': "Tuna bayyana misãlai da ke fassarar a cikin matabbata da aka ƙara a cikin fassarar a tsakanin nau'i da kodi-da-haɗe lugha. Yana da ƙayyadadde, misãlai masu yawa masu motsi da ke mayar da matsayin Ingiriya na'yanci zuwa Hilgish (kodi da aka haɗa Hinddi da Ingiriya). Gida babban rabo na misãlai masu fassarar harshen farko, ko kuma munã jarraba amfani da misãlai biyu na farkon Transformer-based kodkoder (misali, mT5 da mBArT) a kan aikin na gane su don su yi aiki mai kyau. Gida ɗan rabo da data na amfani da kodi-haɗi, sai mu buɗa wata hanyoyi mai inganci wa zaɓi littafan kodi-da-haɗi daga misalin da aka raba shi na biyu-lugha wanda Muke amfani da wajen kyautatawa da misalin misalin harshe. Kayya, masu husũma da wannan data masu ƙaranci, tuna karɓi wata hanyowa na karanta a, inda za mu farkon kuɓutar da misãlai na harshen kan sunotetic data, sa'an nan a kan data na kodi-Mixed. Tuna gane cewa, kuma kõ da sauran, hanyoyinmu da kodi-yin-haɗi na haɗi (kuma a cikin wani abu, akwai mafĩfĩta a kan) wasu hanyõyi na daidaita (baktranslation, metode a kan kwamfyuta da lazimta) a cikin wasu hãli dabam-dabam. Kayinmu yana nũna cewa misalin mT5, wanda aka buɗe shi a bayan jarrabin da aka karanta na karatun, yana sãmu mafi kyaun fassarar fassarar (12.67 BLEU). MataimakinMu na fara a cikin ranar dukkan aikin da aka raba shi na Ingiriya-Higgish.", 'bo': 'ང་ཚོས་མིག་གཟུགས་རིས་འདིའི་ནང་གི་མིག་གཟུགས་ཅན་གྱི་སྐད་རིགས་དང་ཁྱད་པར་དབྱེ་སྐད་ཀྱི་ཆ་བརྗོད་ཀྱི་དཀའ་ངལ་ ང་ཚོས་ཁྱད་པར་ལྡན་བྱས་པར་ཨིན་རིའི་མིག་ཡིག་གི་ཁྱད་ཚད་མང་པོ་ཞིག་བྱིན་ཡོད། སྐད་ཡིག འུ་ཅག་གིས་གསལ་བཤད་ཀྱི་དབྱིབས་སྒྲིག་ཆ་གཙོ་བོ་དུ་འཇུག་གི་མ་ཟད། ང་ཚོའི་ནང་དུ་རྟེན་འབྲེལ་མེད་པའི་ཐབས་ལམ་ལུགས དམིགས་བསལ་ན། འུ་ཅག་གིས་སྔོན་ནས་སྐད་ཡིག We find that, although simple, our synthetic code-mixing method is competitive with (and in some cases is even superior to) several standard methods (backtranslation, method based on equivalence constraint theory) under a diverse set of conditions. ང་ཚོའི་ལས་ཀ་ལྟ་བུའི་མ་གཟུགས་རིས་ལྟར་བྱ་རིམ་གྱི་ལས་འགུལ་གྱིས་བཏོན་མེད་པར། སྔོན་གྱི་སྔོན་ལྟར་སྔོན་ནམ་ཡོ ང་ཚོའི་མིག'}
{'en': 'CoMeT : Towards Code-Mixed Translation Using Parallel Monolingual Sentences', 'ar': 'CoMeT: نحو ترجمة مختلطة برمجيًا باستخدام جمل أحادية اللغة متوازية', 'es': 'CoMet: Hacia la traducción de código mixto mediante oraciones monolingües paralelas', 'fr': "CoMet\xa0: vers une traduction mixte de code à l'aide de phrases monolingues parallèles", 'pt': 'CoMeT: em direção à tradução mista de código usando sentenças monolíngues paralelas', 'ja': 'CoMeT ：並列単語文を使用したコード混合翻訳に向けて', 'zh': 'CoMeT:并行单语句代码合译', 'hi': 'CoMeT: समानांतर मोनोलिंगुअल वाक्यों का उपयोग करके कोड-मिश्रित अनुवाद की ओर', 'ru': 'CoMeT: К Смешанному Переводу Кода Используя Параллельные Одноязычные Предложения', 'ga': 'Teacht: I dTreo Aistriúchán Cód-Mheasctha ag Úsáid Pianbhreitheanna Comhthreomhara Aonteangacha', 'ka': 'CoMeT', 'el': 'Προς τη μικτή μετάφραση κώδικα χρησιμοποιώντας παράλληλες μονογλωσσικές προτάσεις', 'hu': 'CoMeT: A párhuzamos egynyelvű mondatokat használó kódkevert fordítás felé', 'it': 'CoMeT: Verso una traduzione mista con codice usando frasi monolingue parallele', 'kk': 'CoMeT: Код араластырылған аудармаларына қарсы параллер бір тілі сөздерді қолданып', 'lt': 'CoMeT – kodų mišraus vertimo, naudojant lygiagrečius monokalbinius sakinius link', 'mk': 'CoMeT: Надвор кон превод мешан со код користејќи паралелни монолингуални реченици', 'ms': 'CoMeT: Ke arah Terjemahan Bercampur-Kod menggunakan perkataan Monolingual Paralel', 'mt': 'CoMeT: Lejn traduzzjoni mħallta bil-Kodiċi bl-użu ta’ Sentenzi Monolingwali Paraleli', 'ml': 'കോമെറ്റ്: കോഡ്- മിക്സഡ് പരാള്\u200d മോണോളില്\u200d വാക്കുകള്\u200d ഉപയോഗിക്കുന്നതിലേക്കു് മുകളിലേക്കു് മാറുക', 'mn': 'CoMeT: Код-холбогдсон хөрөнгө руу Параллель нэг хэлний үгийг ашиглах', 'no': 'CoMeT: Til kodefelt omsetjing ved bruk av parallelle monolingsstenker', 'pl': 'CoMeT: W kierunku tłumaczenia mieszanego kodem przy użyciu równoległych jednojęzycznych zdań', 'sr': 'KoMeT: prema prevodu mešanom kodom korištenjem paralelnih monolingviskih rečenica', 'ro': 'CoMeT: Către traducerea mixtă în cod folosind fraze monolingve paralele', 'so': 'CoMeT: Towards Code-Mixed Translation using Parallel Monolingual', 'sv': 'CoMeT: Mot kodblandad översättning med parallella enspråkiga meningar', 'ta': 'CoMeT: மேலே குறியீடு- கலக்கப்பட்ட மொழிபெயர்ப்பு', 'si': 'CoMeT: කෝඩ් මික්ස් වාර්ථාව ප්\u200dරයෝජනය කරන්න', 'ur': 'CoMeT: کوڈ میکس ترجمہ کی طرف', 'uz': 'Name', 'vi': 'Cơ bản: Hướng tới một phiên dịch tổng hợp, dùng câu vô ngôn ngữ song', 'nl': 'CoMeT: Naar code-gemengde vertaling met parallelle eentalige zinnen', 'bg': 'CoMeT: Към кодово смесен превод с успоредни едноезични изречения', 'hr': 'CoMeT: prema prevodu pomiješanom kodom koristeći paralelne monojezičke izraze', 'da': 'CoMeT: På vej mod kodeblandet oversættelse ved hjælp af parallelle ensprogede sætninger', 'de': 'CoMeT: Auf dem Weg zu Code-Mixed Translation mit parallelen einsprachigen Sätzen', 'id': 'CoMeT: Ke Perjemahan Bercampur Kode Menggunakan Perkataan Monolingual Paralel', 'fa': 'CoMeT: به سوی ترجمه\u200cهای پیچیده\u200cشده کد استفاده از عبارت\u200cهای پارالل یک زبان', 'ko': 'CoMET: 코드 블렌드 번역에 평행 단일문 사용', 'tr': 'CoMeT:Şekere Karışık Çevirme Parallel Monolingul Sözler kullanarak', 'af': 'CoMeT: Na Kode gemengde Vertaling Gebruik Parallele Monolinguele Utdrukkings', 'sw': 'CoMeT: Tafsiri ya Mitandao ya Mipaka kwa Utumiaji wa Makazi ya Kimonolinguli', 'sq': 'CoMeT: drejt përkthimit të përzier me kod duke përdorur dënime monolinguale paralele', 'am': 'እና', 'hy': 'CoMeT: Towards Code-Mixed Translation Using Parallel Monolingual Sentences', 'az': 'CoMeT: Parallel Monoli Dilli Sözü Qullanmaq üçün Kod Karışıqlı Çeviri', 'bn': 'কোমেটি: প্যারেল মোনোলিঙ্গুলের শাস্তি ব্যবহার করে কোড- মিক্সেড অনুবাদ', 'bs': 'KoMeT: prema prevodu između koda koristeći paralelne monojezičke rečenice', 'cs': 'CoMeT: Směrem ke smíšenému kódovému překladu pomocí paralelních jednojjazyčných vět', 'ca': 'CoMeT: cap a una traducció combinada amb codi utilitzant sentences monolingües paralleles', 'et': 'CoMeT: Koodisekordse tõlke suunas paralleelsete ühekeelsete lausete abil', 'fi': 'CoMeT: Kohti koodisekoitettua kääntämistä rinnakkaisilla yksikielisillä lauseilla', 'ha': 'KCharselect unicode block name', 'he': 'CoMeT: Towards Code-Mixed Translation Using Parallel Monolingual Sentences', 'sk': 'CoMeT: K mešanemu kodnemu prevajanju z uporabo vzporednih enojezičnih stavkov', 'jv': 'CoMeT:Tulung kode Mixed', 'bo': 'CoMeT:འགྲོ་སྐབས་ཡིག་འདིའི་གནས་ཚུལ་ཁ་སྣོན་བྱེད་ཀྱི་ཡིག་གཟུགས་རྟགས་ཀྱི་ཚིག་རྟགས་སྤྱོད་སྟངས'}
{'en': 'Code-mixed languages are very popular in multilingual societies around the world, yet the resources lag behind to enable robust systems on such ', 'es': 'Los lenguajes de código mixto son muy populares en las sociedades multilingües de todo el mundo, pero los recursos van a la zaga para permitir sistemas sólidos en dichos idiomas. Un factor importante que contribuye es la naturaleza informal de estos idiomas, que dificulta la recopilación de datos de código mixto. En este documento, proponemos nuestro sistema para la Tarea 1 de CACLS 2021 para generar un sistema de traducción automática del inglés al inglés en un entorno supervisado. Traducir en la dirección dada puede ayudar a ampliar el conjunto de recursos para varias tareas mediante la traducción de conjuntos de datos valiosos de lenguajes con muchos recursos. Proponemos utilizar mBart, un modelo multilingüe de secuencia a secuencia previamente entrenado, y utilizar completamente el entrenamiento previo del modelo mediante la transliteración de las palabras hindi romanas en las oraciones mixtas de código a la escritura Devanagri. Evaluamos cómo ampliar la entrada mediante la concatenación de traducciones al hindi de las oraciones en inglés mejora el rendimiento de mBart. Nuestro sistema da una puntuación BLEU de 12,22 en el set de pruebas. Además, realizamos un análisis detallado de errores de nuestros sistemas propuestos y exploramos las limitaciones del conjunto de datos y las métricas proporcionados.', 'ar': 'تحظى اللغات المختلطة بالشفرات بشعبية كبيرة في المجتمعات متعددة اللغات حول العالم ، ومع ذلك فإن الموارد متخلفة لتمكين أنظمة قوية في مثل هذه اللغات. أحد العوامل الرئيسية المساهمة هو الطبيعة غير الرسمية لهذه اللغات مما يجعل من الصعب جمع البيانات المختلطة بالشفرات. في هذه الورقة ، نقترح نظامنا للمهمة الأولى من CACLS 2021 لإنشاء نظام ترجمة آلية للغة الإنجليزية إلى اللغة الإنجليزية في بيئة خاضعة للإشراف. يمكن أن تساعد الترجمة في الاتجاه المحدد في توسيع مجموعة الموارد للعديد من المهام عن طريق ترجمة مجموعات البيانات القيمة من اللغات عالية الموارد. نقترح استخدام mBART ، وهو نموذج تسلسل إلى تسلسل متعدد اللغات تم تدريبه مسبقًا ، والاستفادة الكاملة من التدريب المسبق للنموذج عن طريق ترجمة الكلمات الهندية الرومانية في الجمل المختلطة بالكود إلى نص Devanagri. نقوم بتقييم كيف يؤدي توسيع المدخلات عن طريق ربط الترجمات الهندية المتسلسلة للجمل الإنجليزية إلى تحسين أداء mBART. يعطي نظامنا درجة BLEU تبلغ 12.22 في مجموعة الاختبار. علاوة على ذلك ، نقوم بإجراء تحليل مفصل للخطأ لأنظمتنا المقترحة واستكشاف قيود مجموعة البيانات والمقاييس المقدمة.', 'fr': "Les langues à code mixte sont très populaires dans les sociétés multilingues du monde entier, mais les ressources sont en retard pour permettre la mise en place de systèmes robustes sur ces langues. La nature informelle de ces langues rend difficile la collecte de données mixtes de codes. Dans cet article, nous proposons notre système pour la tâche 1 du CACLS 2021 afin de générer un système de traduction automatique de l'anglais vers le hinglish dans un cadre supervisé. La traduction dans la direction donnée peut aider à élargir l'ensemble des ressources pour plusieurs tâches en traduisant des ensembles de données précieux à partir de langues à ressources élevées. Nous proposons d'utiliser mBart, un modèle de séquence à séquence multilingue pré-entraîné, et d'utiliser pleinement la pré-formation du modèle en translittérant les mots latins hindi dans les phrases codées mélangées en script Devanagri. Nous évaluons comment l'extension de la saisie en concaténant les traductions en hindi des phrases anglaises améliore les performances de mBart. Notre système donne un score BLEU de 12,22 sur l'ensemble de test. De plus, nous effectuons une analyse détaillée des erreurs des systèmes proposés et explorons les limites de l'ensemble de données et des métriques fournis.", 'pt': 'Os idiomas de código misto são muito populares em sociedades multilíngues em todo o mundo, mas os recursos ficam para trás para permitir sistemas robustos nesses idiomas. Um fator importante que contribui é a natureza informal dessas linguagens, o que dificulta a coleta de dados mistos de código. Neste artigo, propomos nosso sistema para a Tarefa 1 do CACLS 2021 para gerar um sistema de tradução automática de inglês para hinglish em um ambiente supervisionado. Traduzir na direção dada pode ajudar a expandir o conjunto de recursos para várias tarefas traduzindo conjuntos de dados valiosos de linguagens de alto recurso. Propomos usar o mBART, um modelo multilíngue pré-treinado de sequência a sequência, e utilizar plenamente o pré-treinamento do modelo transliterando as palavras romanas em hindi nas frases de código misto para o script Devanagri. Avaliamos como expandir a entrada concatenando traduções em hindi das frases em inglês melhora o desempenho do mBART. Nosso sistema dá uma pontuação BLEU de 12,22 no conjunto de teste. Além disso, realizamos uma análise detalhada de erros de nossos sistemas propostos e exploramos as limitações do conjunto de dados e métricas fornecidos.', 'hi': 'कोड-मिश्रित भाषाएं दुनिया भर के बहुभाषी समाजों में बहुत लोकप्रिय हैं, फिर भी ऐसी भाषाओं पर मजबूत प्रणालियों को सक्षम करने के लिए संसाधन पीछे हैं। एक प्रमुख योगदान कारक इन भाषाओं की अनौपचारिक प्रकृति है जो कोड-मिश्रित डेटा एकत्र करना मुश्किल बनाता है। इस पेपर में, हम एक पर्यवेक्षित सेटिंग में हिंग्लिश के लिए अंग्रेजी के लिए एक मशीन अनुवाद प्रणाली उत्पन्न करने के लिए CACLS 2021 के कार्य 1 के लिए हमारे सिस्टम का प्रस्ताव करते हैं। दी गई दिशा में अनुवाद करने से उच्च संसाधन भाषाओं से मूल्यवान डेटासेट का अनुवाद करके कई कार्यों के लिए संसाधनों के सेट का विस्तार करने में मदद मिल सकती है। हम mBART, एक पूर्व-प्रशिक्षित बहुभाषी अनुक्रम-से-अनुक्रम मॉडल का उपयोग करने का प्रस्ताव करते हैं, और कोड-मिश्रित वाक्यों में रोमन हिंदी शब्दों को देवनागरी लिपि में अनुवाद करके मॉडल के पूर्व-प्रशिक्षण का पूरी तरह से उपयोग करते हैं। हम मूल्यांकन करते हैं कि अंग्रेजी वाक्यों के हिंदी अनुवादों को संयोजित करके इनपुट का विस्तार करने से mBART के प्रदर्शन में सुधार होता है। हमारा सिस्टम परीक्षण सेट पर 12.22 का BLEU स्कोर देता है। इसके अलावा, हम अपने प्रस्तावित सिस्टम का एक विस्तृत त्रुटि विश्लेषण करते हैं और प्रदान किए गए डेटासेट और मीट्रिक की सीमाओं का पता लगाते हैं।', 'zh': '代码混言世界各地世甚受欢迎,而资滞后于强大。 凡此等语,非正性也,此所以收代码合数为难也。 于本文中,CACLS 2021务1之统,以监生成英语至于Hinglish机器翻译。 因高资言语译有价值之数集,于给定方译可助广数务。 臣等议用mBART,一先练者多语言序列模样,并以代码混合句中罗马印地语单词音译为Devanagri脚本充模范之预。 评估何以接英语句印地语译以广输,以崇mBART之性。 我们的系统在测试集上给了12.22的BLEU分数。 此外,臣等详其系统,并探所供数据集指标之局限性。', 'ja': 'コードミックス言語は、世界中の多言語社会で非常に人気がありますが、そのような言語の堅牢なシステムを可能にするためにリソースは遅れています。 主な要因は、これらの言語の非公式な性質であり、コード混合データの収集を困難にしている。 本稿では，監督下での英語からヒングリッシュ語への機械翻訳システムを生成するためのCACLS 2021のタスク1のためのシステムを提案する． 特定の方向に翻訳すると、高リソース言語から貴重なデータセットを翻訳することで、いくつかのタスクのリソースセットを拡張するのに役立ちます。 事前にトレーニングされた多言語シーケンスツーシーケンスモデルであるmBARTを使用し、コードミックスされた文章のローマ字ヒンディー語の単語をDevanagriスクリプトに音訳することで、モデルの事前トレーニングをフルに活用することを提案します。 英文のヒンディー語翻訳を連結して入力を拡大することで、mBARTのパフォーマンスがどのように向上するかを評価します。 当社のシステムは、試験器のBLEUスコアを12.22としています。 さらに、提案されたシステムの詳細なエラー分析を行い、提供されたデータセットと指標の限界を探ります。', 'ru': 'Языки со смешанным кодом очень популярны в многоязычных обществах по всему миру, но ресурсы отстают, чтобы обеспечить надежные системы на таких языках. Основным фактором, способствующим этому, является неформальный характер этих языков, что затрудняет сбор смешанных данных. В этой статье мы предлагаем нашу систему для Задачи 1 CACLS 2021 для создания системы машинного перевода с английского на хинглиш в контролируемой обстановке. Перевод в заданном направлении может помочь расширить набор ресурсов для нескольких задач, переводя ценные наборы данных с языков с большими ресурсами. Мы предлагаем использовать mBART, предварительно обученную многоязычную модель последовательности к последовательности, и в полной мере использовать предварительное обучение модели, транслитерируя римские слова хинди в смешанных с кодом предложениях к письму Деванагри. Мы оцениваем, как расширение входных данных путем объединения переводов английских предложений на хинди улучшает производительность mBART. Наша система дает BLEU оценку 12.22 на тестовом наборе. Кроме того, мы проводим детальный анализ ошибок наших предлагаемых систем и изучаем ограничения предоставленного набора данных и метрик.', 'ga': 'Tá an-tóir ar theangacha cód-mheasctha i sochaithe ilteangacha ar fud an domhain, ach tá na hacmhainní chun deiridh chun córais láidre a chumasú ar theangacha dá leithéid. Fachtóir a chuireann go mór leis is ea nádúr neamhfhoirmiúil na dteangacha seo a fhágann go bhfuil sé deacair sonraí cód-mheasctha a bhailiú. Sa pháipéar seo, molaimid ár gcóras do Thasc 1 de CACLS 2021 chun córas aistriúcháin meaisín a ghiniúint don Bhéarla go Hinglish i suíomh maoirsithe. Is féidir le haistriúchán sa treo tugtha cuidiú leis an tacar acmhainní do roinnt tascanna a leathnú trí thacair sonraí luachmhara a aistriú ó theangacha ard-acmhainne. Tá sé beartaithe againn úsáid a bhaint as mBART, samhail sheicheamh-go-seicheamh ilteangach réamh-oilte, agus úsáid iomlán a bhaint as réamhoiliúint na samhla trí na focail Hiondúis rómhánach a thraslitriú sna habairtí cód-mheasctha go script Devanagri. Déanaimid measúnú ar an gcaoi a gcuirtear feabhas ar fheidhmíocht mBART trí aistriúchán Hiondúise ar na habairtí Béarla a chomhchatú. Tugann ár gcóras scór BLEU de 12.22 ar thacar tástála. Ina theannta sin, déanaimid anailís mhionsonraithe earráide ar ár gcórais bheartaithe agus déanaimid iniúchadh ar na teorainneacha a bhaineann leis an tacar sonraí agus an mhéadracht a chuirtear ar fáil.', 'hu': 'A kódkevert nyelvek nagyon népszerűek a többnyelvű társadalmakban világszerte, de az erőforrások lemaradnak ahhoz, hogy erőteljes rendszereket biztosítsanak az ilyen nyelveken. Az egyik legfontosabb tényező e nyelvek informális jellege, amely megnehezíti a kódkevert adatok gyűjtését. Ebben a tanulmányban javasoljuk a CACLS 2021 1. feladatának rendszerét, hogy felügyelt környezetben gépi fordítási rendszert hozzon létre angolról hinglisre. Az adott irányba történő fordítás segíthet bővíteni az erőforráskészletet több feladathoz azáltal, hogy értékes adatkészleteket fordít a nagy erőforrás-nyelvekről. Javasoljuk, hogy az mBART, egy előre képzett többnyelvű szekvencia-szekvencia modell használatát, és teljes mértékben kihasználjuk a modell előképzését azzal, hogy a kódkevert mondatokban a római hindi szavakat transzliteráljuk Devanagri szkriptre. Értékeljük, hogy az angol mondatok hindi fordításainak összekapcsolásával hogyan javítja az mBART teljesítményét. A rendszerünk 12,22 BLEU pontszámot ad a tesztkészleten. Továbbá részletes hibaelemzést végzünk javasolt rendszereinkről, és feltárjuk a megadott adatkészlet és mutatók korlátait.', 'el': 'Οι μικτές γλώσσες κώδικα είναι πολύ δημοφιλείς σε πολυγλωσσικές κοινωνίες σε όλο τον κόσμο, ωστόσο οι πόροι παραμένουν πίσω για να επιτρέψουν ισχυρά συστήματα σε τέτοιες γλώσσες. Ένας σημαντικός παράγοντας που συμβάλλει είναι ο άτυπος χαρακτήρας αυτών των γλωσσών που καθιστά δύσκολη τη συλλογή δεδομένων με μικτό κώδικα. Στην παρούσα εργασία, προτείνουμε το σύστημά μας για την εργασία 1 του για τη δημιουργία ενός συστήματος μηχανικής μετάφρασης για τα Αγγλικά στα Χίγγλικα σε εποπτευόμενο περιβάλλον. Η μετάφραση προς τη δεδομένη κατεύθυνση μπορεί να βοηθήσει στην επέκταση του συνόλου πόρων για διάφορες εργασίες μεταφράζοντας πολύτιμα σύνολα δεδομένων από γλώσσες υψηλού πόρου. Προτείνουμε να χρησιμοποιήσουμε ένα προ-εκπαιδευμένο πολύγλωσσο μοντέλο ακολουθίας σε ακολουθία, και να αξιοποιήσουμε πλήρως την προεκπαίδευση του μοντέλου με μεταγραφή των ρωμαϊκών Χίντι λέξεων στις μικτές προτάσεις κώδικα στη γραφή Devanagri. Αξιολογούμε πώς η επέκταση της εισαγωγής μέσω της αλληλογραφίας μεταφράσεων στα Χίντι των Αγγλικών προτάσεων βελτιώνει την απόδοση του. Το σύστημά μας δίνει βαθμολογία 12.22 στο σετ δοκιμής. Επιπλέον, διενεργούμε λεπτομερή ανάλυση σφαλμάτων των προτεινόμενων συστημάτων μας και διερευνούμε τους περιορισμούς του παρεχόμενου συνόλου δεδομένων και των μετρήσεων.', 'ka': 'მსოფლიოში მრავალენგური საზოგადოებში კოდენტი სიტყვები ძალიან პოლუბურია, მაგრამ რესურსები დარჩენა, რომ ასეთი ენაზე ძალიან ძალიან სისტემის შე მნიშვნელოვანი მომხმარებელი ფაქტორია არის ამ ენების ინფორმალური ნათობა, რომელიც ძალიან რთულია შეიძლება კოდის შემხმარებული მონაცემების შექმნა. ამ დომენტში ჩვენ CACLS 2021-ის 1-ი დავალების სისტემის შექმნა მაქსინური გაგრძელების სისტემის შექმნა ინგლისურად ინგლისურად ინგლისურად დავუყენებთ. მითითებული მისამართში გადაწყვეტილება შეიძლება მნიშვნელოვანი მონაცემების რესურსების საზოგადოება რამდენიმე მოქმედებისთვის გადაწყვეტილებით მარტივი რესურ ჩვენ მინდა გამოყენოთ mBART, მრავალური მრავალური მრავალური მრავალური მრავალური მრავალური მრავალური მოდელს, და მოდელის წინაშემდეგ გამოყენოთ პრომანური ჰინდის სიტყვების ტრანსლიტაციას, რომელიც კოდი ჩვენ გავამუშავებთ, როგორ გამოყენება ინგლისური სიტყვების განსაზღვრებით, როგორ გამოყენება mBART-ის განსაზღვრებას. ჩვენი სისტემა გააკეთება ბლესო წერტილი 12.22 წერტილი ტესტის შესახებ. დამატებით, ჩვენ ვაკეთებთ განსაზღვრებული შეცდომის ანალიზაცია ჩვენი საზღვრებული სისტემების და გამოვაკეთებთ განსაზღვრებული მონაცემების და მეტრიკის ზომილებ', 'kk': 'Код араластырылған тілдер әлемдегі көп тілдер қоғамдарында, бірақ бұл тілдер үшін күшті жүйелерді рұқсат ету үшін ресурстар қалды. Үлкен көмектесу факторы - код араластырылған деректерді жинау қиын болады. Бұл қағазда CACLS 2021 тапсырмасының 1- тапсырмасының жүйесін ағылшынша тілінде Hinglish- ге аудару жүйесін құру үшін қолданамыз. Келтірілген бағытта аудару көмегімен бірнеше тапсырмалар үшін мәні ресурстар тілдерінен аударып ресурстар жиынын кеңейтуге көмектеседі. Біз көп тілді реттеу үлгісін қолдану үшін mBART- ті, көп тілді реттеу үлгісін қолдану және үлгісінің алдын- оқытуын қолдану үшін Роман Хинди сөздерін Devanagri скриптіне код араластырылған сөздеріне аударып қолдануға Ағылшын сөздерді қалай енгізгенді бағалаймыз. МБАРТ жылдамдығын жақсарту үшін хиндық сөздерді ағылшын сөздерінің аударымыз. Біздің жүйеміз сынақтар жиынында 12,22 BLEU нәтижесін береді. Келесіден қате талдау жүйелеріміздің егжей- тегжейлі анализ және келтірілген деректер жиының мен метрикалық шектерін зерттеп көрдік.', 'it': "Le lingue miste in codice sono molto popolari nelle società multilingue di tutto il mondo, ma le risorse sono in ritardo per consentire sistemi robusti su tali lingue. Un fattore determinante è la natura informale di queste lingue che rende difficile raccogliere dati misti in codice. In questo articolo, proponiamo il nostro sistema per il Task 1 del CACLS 2021 per generare un sistema di traduzione automatica da inglese a hinglish in un ambiente supervisionato. Tradurre nella direzione indicata può aiutare ad espandere l'insieme di risorse per diverse attività traducendo set di dati preziosi da linguaggi ad alta risorsa. Proponiamo di utilizzare mBART, un modello multilingue pre-addestrato sequenza-sequenza, e utilizzare pienamente la pre-formazione del modello traslitterando le parole in hindi romane nelle frasi miste di codice in script Devanagri. Valutiamo come espandere l'input concatenando traduzioni hindi delle frasi inglesi migliora le prestazioni di mBART. Il nostro sistema dà un punteggio BLEU di 12.22 sul set di test. Inoltre, eseguiamo un'analisi dettagliata degli errori dei nostri sistemi proposti ed esploriamo i limiti del set di dati e delle metriche forniti.", 'lt': 'Kodų mišrios kalbos yra labai populiarios daugiakalbėse visuomenėse visame pasaulyje, tačiau ištekliai atsilieka, kad tokios kalbos galėtų tapti patikimomis sistemomis. Pagrindinis veiksnys yra šių kalbų neoficialus pobūdis, dėl kurio sunku rinkti kodų mišrius duomenis. Šiame dokumente siūlome CACLS 2021 1 užduoties 1 sistemą sukurti mašin in ę vertimo į anglų kalbą sistemą prižiūrint. Vertimas konkrečia kryptimi gali padėti išplėsti išteklių rinkinį kelioms užduotims vertant vertingus duomenų rinkinius iš didelių išteklių kalbų. Siūlome naudoti mBART, iš anksto parengtą daugiakalbį sekos model į iš eilės į eilę, ir visapusiškai panaudoti modelio parengiamąjį mokymą perkeliant roman ų Hindi žodžius kodų mišriuose sakiniuose į Devanagri scenarijų. Vertiname, kaip išplėsti indėlį sutrumpindami anglų sakinių anglų kalba vertimus pagerina mBART veikimą. Mūsų sistema duoda BLEU rezultatą 12,22 bandymų rinkinyje. Be to, atliksime išsamią mūsų siūlomų sistemų klaidų analizę ir išnagrinėjame pateikto duomenų rinkinio ir metrinių rodiklių apribojimus.', 'mk': 'Мешаните јазици се многу популарни во мултијазичните општества низ целиот свет, но ресурсите остануваат зад себе за да овозможат силни системи на ваквите јазици. A major contributing factor is the informal nature of these languages which makes it difficult to collect code-mixed data.  Во овој весник, го предлагаме нашиот систем за задача 1 на CACLS 2021 за генерирање машински преведувачки систем за англиски на хинглиски во надгледувано поставување. Преведувањето во дадена насока може да помогне во проширувањето на наборот на ресурси за неколку задачи со преведувањето на вредни набори на податоци од јазици со високи ресурси. Предложуваме да се користи mBART, предобучен мултијазичен модел од секвенца до секвенца, и целосно да се користи предобуката на моделот преку транслитерација на римските хиндиски зборови во кодовите мешани реченици на скриптот Devanagri. Ние проценуваме како проширувањето на влогот со концентрирање на хиндиските преводи на англиските реченици ја подобрува изведбата на mBART. Нашиот систем дава БЛЕ резултат од 12,22 на тестот. Покрај тоа, спроведуваме детална анализа на грешките на нашите предложени системи и ги истражуваме ограничувањата на обезбедените податоци и метрики.', 'mt': 'Il-lingwi mħallta bil-kodiċi huma popolari ħafna fis-soċjetajiet multilingwi madwar id-dinja, iżda r-riżorsi għadhom lura biex jippermettu sistemi robusti fuq tali lingwi. Fattur ewlieni li jikkontribwixxi huwa n-natura informali ta’ dawn il-lingwi li jagħmilha diffiċli li tinġabar dejta mħallta bil-kodiċi. F’dan id-dokument, qed nipproponu s-sistema tagħna għall-Kompitu 1 tal-CACLS 2021 biex tiġġenera sistema ta’ traduzzjoni bil-magna għall-Ingliż għal Hinglish f’ambjent sorveljat. It-traduzzjoni fid-direzzjoni partikolari tista’ tgħin biex jiġi estiż is-sett ta’ riżorsi għal diversi kompiti billi jiġu tradotti settijiet ta’ dejta ta’ valur minn lingwi b’riżorsi għoljin. We propose to use mBART, a pre-trained multilingual sequence-to-sequence model, and fully utilize the pre-training of the model by transliterating the roman Hindi words in the code-mixed sentences to Devanagri script.  Aħna jevalwaw kif l-espansjoni tal-input permezz tat-traduzzjonijiet Indjani konċitanti tas-sentenzi Ingliżi ttejjeb il-prestazzjoni tal-mBART. Is-sistema tagħna tagħti punteġġ BLEU ta’ 12.22 fuq is-sett tat-test. Barra minn hekk, nagħmlu analiżi dettaljata tal-iżbalji tas-sistemi proposti tagħna u nesploraw il-limitazzjonijiet tas-sett tad-dejta u l-metriċi pprovduti.', 'ms': 'Bahasa campuran kod sangat populer dalam masyarakat berbilang bahasa di seluruh dunia, namun sumber tertinggal untuk membolehkan sistem yang kuat dalam bahasa tersebut. Faktor kontribusi utama ialah sifat informal bahasa-bahasa ini yang membuat ia sukar untuk mengumpulkan data campuran-kod. Dalam kertas ini, kami cadangkan sistem kami untuk Tugas 1 CACLS 2021 untuk menghasilkan sistem terjemahan mesin untuk bahasa Inggeris ke Hinglish dalam seting yang dijaga. Terjemahan dalam arah yang diberi boleh membantu mengembangkan set sumber untuk beberapa tugas dengan menerjemahkan set data berharga dari bahasa sumber yang tinggi. Kami cadangkan untuk menggunakan mBART, model berbilang-bahasa yang dilatih-dilatih-ke-jujukan, dan menggunakan penuh-penuh praselatih model dengan mengganti kata-kata Hindi roman dalam kalimat-campuran kod ke skrip Devanagri. Kami menilai bagaimana mengembangkan input dengan menyatukan terjemahan Hindi kalimat Inggeris meningkatkan prestasi mBART. Sistem kita memberikan nilai BLEU 12.22 pada set ujian. Lagipun, kami melakukan analisis ralat terperinci sistem kami yang diusulkan dan mengeksplorasi keterangan set data dan metrik yang diberikan.', 'ml': 'ലോകത്തിലെ പല ഭാഷ സമൂഹങ്ങളില്\u200d കോഡ് മിക്കിങ്ങ് ഭാഷകള്\u200d വളരെ പ്രധാനപ്പെട്ടവരാണ്. പക്ഷേ ഇത്തരം ഭാഷകളില്\u200d റോബോസ്റ്റ് സിസ്റ്റ ഒരു പ്രധാനപ്പെട്ട വിവരങ്ങള്\u200d ഈ ഭാഷകങ്ങളുടെ അപരിചിതമായ പ്രകൃതിയാണ്. അത് കോഡ് മിഷ്ടപ്പെട്ട വിവരങ്ങള്\u200d സൂക്ഷ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d കെസിഎല്\u200dഎസ് 2021 ലെ ടാസ്ക് 1-ല്\u200d നിന്നുള്ള നമ്മുടെ സിസ്റ്റം പ്രായശ്ചിത്തമാക്കുന്നു. ഇംഗ്ലീഷിന് ഒരു  തെരഞ്ഞെടുത്ത തിരിച്ചില്\u200d പരിഭാഷപ്പെടുത്തുന്നത് കുറച്ച് ജോലികള്\u200dക്കുള്ള വിഭവങ്ങളുടെ സെറ്റ് വ്യാപ്തമാക മുമ്പ് പഠിപ്പിക്കപ്പെട്ട പല ഭാഷകങ്ങളുടെ സെക്കന്\u200dസ് മോഡല്\u200d ഉപയോഗിക്കാന്\u200d ഞങ്ങള്\u200d പ്രൊദ്ദേശിക്കുന്നു. മോഡലിന്\u200dറെ മുന്\u200dപരിശീലനത്തിന് മുന്\u200dപ് പരിശീലനം ഉപയോഗിക്ക ഇംഗ്ലീഷ് വാക്കുകളുടെ വാക്കുകള്\u200d എംബിആര്\u200dടിയുടെ പ്രകടനം മെച്ചപ്പെടുത്തുന്നതിനാല്\u200d ഹിന്ദിയുടെ വിഭാഷണങ്ങള്\u200d എങ നമ്മുടെ സിസ്റ്റത്തിന്റെ ടെസ്റ്റ് സെറ്റില്\u200d 12.22 സ്കോര്\u200d കൊടുക്കുന്നു. അതിനുശേഷം, നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട സിസ്റ്റത്തിന്\u200dറെ വിശദീകരണവും ഞങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്ന ഒരു പിശക്', 'pl': 'Języki mieszane kodem są bardzo popularne w wielojęzycznych społeczeństwach na całym świecie, jednak zasoby pozostają w tyle, aby umożliwić solidne systemy w takich językach. Głównym czynnikiem przyczyniającym się do tego jest nieformalny charakter tych języków, który utrudnia gromadzenie danych o mieszanych kodach. W niniejszym artykule proponujemy nasz system dla zadania 1 CACLS 2021 do generowania systemu tłumaczenia maszynowego dla angielskiego na język angielski w warunkach nadzorowanych. Tłumaczenie w danym kierunku może pomóc rozszerzyć zestaw zasobów dla kilku zadań poprzez tłumaczenie wartościowych zbiorów danych z języków wysokich zasobów. Proponujemy użycie mBART, wstępnie przeszkolonego wielojęzycznego modelu sekwencji-do-sekwencji, oraz pełne wykorzystanie wstępnego treningu modelu poprzez transliterację rzymskich słów hindi w zdaniach mieszanych kodem do skryptu Devanagri. Oceniamy, w jaki sposób rozszerzenie danych wejściowych poprzez łączenie tłumaczeń z języka angielskiego poprawia wydajność mBART. Nasz system daje wynik BLEU 12.22 na zestawie testowym. Ponadto przeprowadzamy szczegółową analizę błędów proponowanych przez nas systemów oraz badamy ograniczenia dostarczanego zbioru danych i wskaźników.', 'ro': 'Limbile combinate de coduri sunt foarte populare în societățile multilingve din întreaga lume, dar resursele rămân în urmă pentru a permite sisteme robuste pentru astfel de limbi. Un factor important care contribuie este natura informală a acestor limbi, ceea ce face dificilă colectarea datelor combinate de coduri. În această lucrare, propunem sistemul nostru pentru Sarcina 1 a CACLS 2021 pentru a genera un sistem de traducere automată pentru limba engleză în hinglish într-un cadru supravegheat. Traducerea în direcția dată poate ajuta la extinderea setului de resurse pentru mai multe sarcini prin traducerea seturilor de date valoroase din limbi cu resurse mari. Propunem să folosim mBART, un model multilingv pre-instruit secvență-la-secvență, și să utilizăm pe deplin pre-instruirea modelului prin transliterarea cuvintelor hindi romane în propozițiile combinate de cod în scriptul Devanagri. Evaluăm modul în care extinderea introducerii prin concatenarea traducerilor hindi ale propozițiilor în limba engleză îmbunătățește performanța mBART. Sistemul nostru oferă un scor BLEU de 12.22 pe setul de teste. În plus, efectuăm o analiză detaliată a erorilor sistemelor propuse și explorăm limitările setului de date și măsurătorilor furnizate.', 'mn': 'Дэлхийн олон хэл нийгэмд кодын холбогдолтой хэл маш олон хүн төрөлхтөн байдаг. Гэхдээ эдгээр хэл дээр хүчтэй системийг ашиглах боломжтой боломжтой боловч нөөц боломжтой байдаг. Хамгийн чухал нөлөөлөх хүчин зүйл бол эдгээр хэлнүүдийн мэдээллийг цуглуулахад хэцүү болгодог. Энэ цаасан дээр бид CACLS 2021-ийн 1-р ажлын системийг англи хэлний хөрөнгө хөрөнгө оруулах машин хөрөнгө хөрөнгө хөрөнгө оруулах гэсэн санал өгдөг. Өөр хэлбэрт орчуулах нь хэдэн ажлын баялаг боловсруулах боломжтой өгөгдлийн сангуудыг өндөр баялаг хэлбэрээс орчуулах боломжтой болгодог. МБАРТ, олон хэл дарааллын дарааллын загварыг ашиглах боломжтой. Мэдээж загварын өмнө дасгал хөдөлгөөн ашиглаж, Роман Хинди үгийг Деванагрийн шинжлэх ухаанд хувьсагдсан өгүүлбэрээр бүрэн ашиглах боломжтой. Бид хиндийнх хэллэгүүдийг хэлэхэд хэлэхэд, мBART-ын үйл ажиллагааг хэрхэн нэмэгдүүлснийг үнэлж байна. Бидний систем шалгалтанд 12.22 BLEU оноо өгдөг. Дараа нь бид санал өгөгдлийн сангийн, метрикийн хязгаарлалтыг судалж болно.', 'no': 'Kodeflikt språk er veldig populært i fleirspråk samfunn rundt verden, men ressursane går bak for å slå på kraftige systemar på slike språk. Eit stor bidragsfaktor er den informale naturen av desse språka som gjer det vanskeleg å samla med kodefekserte data. I denne papiret foreslår vi systemet for oppgåva 1 av CACLS 2021 for å laga ein maskinsomsetjingssystem for engelsk til Hinglish i eit oversikt innstilling. Omsetjinga i den oppgjevne retninga kan hjelpa til å utvida settet av ressursar for fleire oppgåver ved å omsetja verdilege datasett frå høg ressursspråk. Vi foreslår å bruka mBART, eit multispråk-sekvens-til-sekvensmodell, og bruka fullstendig føreøvinga av modellen ved å transliterara romanske hindiske ord i kodeflikte setningar til Devanagri-skriptet. Vi evaluerer korleis utvida inndata ved å samsvara hindiske omsetjingar av engelske setningar forbetrar mBART sin utvikling. Sistemet vårt gjev ein BLEU-score på 12,22 på testsett. I tillegg utfører vi ein detaljert feilanalyse av våre foreslått systemet og utforsk grensene på den oppgjevne datasettet og metriken.', 'so': 'Luqadaha isku xiran waa dad aad u populal ku yaala bulshada luuqadaha kala duduwan ee adduunka oo dhan, laakiin fursadaha waxaa dib u hadhay in lagu sameeyo nidaamka lagu isticmaalo luqadaha oo kale. Hadalka ugu weyn ee bidaaraya waa dabiicadda aan rasmi ahayn ee luqadahan, taas oo ku adag in la soo ururiyo macluumaadka kooxda. In this paper, we propose our system for Task 1 of CACLS 2021 to generate a machine translation system for English to Hinglish in a supervised setting.  Turjumidda hagitaanka waxaad ka caawinaysaa furitaanka raslimaadka shaqaalaha qaarkood, sida lagu turjumo sawirada macluumaadka qiimaha ah ee luuqadaha sare. Waxaynu soo jeedaynaa in aan u isticmaalno mBART, qaab aad u baran karto qalabka luuqadaha kala duduwan, oo aan si buuxsan u isticmaalno waxbarashada hore ee modelka, si aan ugu qorno erayada romaniga Hindi oo uu ugu qoro qoraalka qoraalka qoran ee qoraalka Devanagri. Waxaannu qiimeynaynaa sida loo kordhinayo tarjumaadka Hindi oo lagu qorayo turjumaadda afka Ingiriiska lagu hagaajiyo sameynta mBART. Systemkanagu wuxuu bixiyaa 12.22 koox BLEU oo ku qoran tijaabada. Furthermore, waxaynu sameynaa baaritaanka qaladka ee nidaamka la soo jeeday iyo baaritaanka nidaamka lagu qoray.', 'sv': 'Kodblandade språk är mycket populära i flerspråkiga samhällen runt om i världen, men resurserna släpar efter för att möjliggöra robusta system på sådana språk. En viktig bidragande faktor är språkens informella karaktär, vilket gör det svårt att samla in kodblandade uppgifter. I denna uppsats föreslår vi vårt system för uppgift 1 i CACLS 2021 för att generera ett maskinöversättningssystem för engelska till hingliska i en övervakad miljö. Att översätta i den givna riktningen kan bidra till att utöka resursuppsättningen för flera uppgifter genom att översätta värdefulla datauppsättningar från språk med hög resurs. Vi föreslår att använda mBART, en förintränad flerspråkig sekvens-till-sekvensmodell, och fullt ut utnyttja pre-training av modellen genom att translitterera de romerska hindi orden i kodblandade meningar till Devanagri skript. Vi utvärderar hur utökad indata genom att sammanfoga hindi översättningar av de engelska meningarna förbättrar mBARTs prestanda. Vårt system ger en BLEU-poäng på 12,22 på testset. Vidare utför vi en detaljerad felanalys av våra föreslagna system och undersöker begränsningarna för den angivna datauppsättningen och mätvärdena.', 'sr': 'Mešani jezici su veoma popularni u multijezičkim društvima širom svijeta, ali resursi ostaju iza sebe kako bi omogućili robne sisteme na takvim jezicima. Veliki faktor koji doprinosi je neformalna priroda tih jezika, što čini teškom prikupiti podatke mešanih kod. U ovom papiru predlažemo naš sistem za zadatak 1 CACLS 2021 kako bi stvorili sistem za prevod mašine za engleski na Hinglish u nadzornom setu. Prevod u određenom smjeru može pomoći da proširi setu resursa za nekoliko zadataka, prevodeći vrijedne sete podataka iz visokih jezika resursa. Predlažemo da upotrebimo mBART, pre-obučeni multijezički model za sekvenciju, i potpuno iskoristimo predobuku model a transliteracijom romanskih hindskih reči u rečenicama mešanim kodom na scenario Devanagri. Procjenjujemo kako se proširi ulaz povećavajući hindske prevode engleskih rečenica poboljšava izvršnost mBART-a. Naš sistem daje BLEU rezultat od 12,22 na testiranju. Nadalje, izvršavamo detaljnu analizu greške našeg predloženog sustava i istražujemo ograničenja pruženog seta podataka i metrika.', 'si': 'කෝඩ් මික්ස් භාෂාවල් ලෝකයේ ගොඩක් භාෂාවක් සමාජාවට ගොඩක් ලොකු භාෂාවක්, නමුත් ඒ වගේම භාෂාව මුළු ප්\u200dරධාන ප්\u200dරධානයක් තමයි මේ භාෂාවගේ සාමාන්\u200dය ස්වභාවිතය, ඒකෙන් කෝඩ් මික්ස් දත්ත සංගී මේ පත්තරේ අපි CACLS 2021 වලින් පද්ධතියේ අපේ පද්ධතිය සැලසුම් කරනවා ඉංග්\u200dරීසියට පද්ධතියක් නිර්මාණය කරනවා ඉංග්\u200dරීසිය දෙන්න පැත්තට පරිවර්තනය කරන්න පුළුවන් විශාල වැඩි වැඩි වැඩි වැඩක් සඳහා විශාලය සඳහා විශාල දත්ත සැට් අ අපි ප්\u200dරශ්නයක් කරනවා mBART, ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් බොහොම භාෂාව ප්\u200dරශ්නයක් වෙන්න, ඒ වගේම ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක අපි කොහොමද ඉංග්\u200dරීසි වචනයේ ඉංග්\u200dරීසි වචනයේ ඉංග්\u200dරීසි වචනයේ හින්දි භාෂාව සම්පූර්ණය කරන්නේ කි අපේ පද්ධතිය පරීක්ෂණා සෙට් එකේ බ්ලූයුස් ප්\u200dරමාණයක් දෙනවා. තවත්, අපි අපේ ප්\u200dරයෝජනය කරපු පද්ධතියේ විස්තර විශ්ලේෂණයක් කරනවා සහ ප්\u200dරයෝජනය කරපු දත්ත සැටි සහ මෙට්\u200dර', 'ta': 'குறியீடு கலக்கப்பட்ட மொழிகள் உலகம் முழுவதும் பல மொழிகளின் சமூகங்களில் மிகவும் பிரபலமாக இருக்கின்றன, ஆனாலும் இத்தகைய மொழிகளில்  ஒரு முக்கிய பங்கீட்டு காரணி இந்த மொழிகளின் வழக்கமான இயல்பாகும். அது குறியீடு கலப்பு தகவலை சேகரிக்க கடினமாக இந்த காகிதத்தில், நாங்கள் CACLS 2021-ல் பணியின் 1 முறைமையை பரிந்துரைக்கிறோம் ஒரு கணினி மொழிபெயர்ப்பு அமைப்பை ஆங்கிலத்திற் கொடுக்கப்பட்ட திசையில் மொழிபெயர்ப்பு உயர்மூலத்தின் மொழிகளிலிருந்து மதிப்புள்ள தரவுத்தளத்தை மொழிபெயர்த்த முன்பயிற்சிக்கப்பட்ட பல மொழி தொடர்ச்சி மாதிரியை பயன்படுத்த முன் பயிற்சி மாதிரியை முழுமையாக பயன்படுத்தி ரோமான் ஹிந்தி வார்த்தைகளை குறியீடு கலக்கப்பட்ட வாக்கி எம்பிஆர்டின் செயல்பாட்டை மேம்படுத்துகிறது என்பதை நாம் எவ்வாறு உள்ளீட்டை விரிவாக்குகிறோம் என்பதை பார்க்கலாம். நமது அமைப்பு சோதனை அமைப்பில் 12.22 பிலூ மதிப்பு கொடுக்கும். மேலும், நாம் எங்கள் பரிந்துரைக்கப்பட்ட முறைமைகளின் ஒரு விவரமான பிழை ஆய்வு செய்து கொடுக்கப்பட்ட தரவுத்தளங்கள் மற்', 'ur': 'دنیا میں بہت سی زبانوں کی اجتماعت میں کد میکس زبانیں بہت محبوب ہیں، لیکن یہ زبانوں پر مضبوط سیستموں کو فعال کرنے کے لئے پھیرے جاتے ہیں. یہ زبانوں کی غیر منحصر ہے جو کوڈ میکس ڈیٹا جمع کرنے کے لئے مشکل ہے۔ اس کاغذ میں، ہم نے CACLS 2021 کی Task 1 کے لئے اپنے سیستم کی پیشنهاد کرتا ہے کہ انگلیسی کے لئے انگلیسی ترجمہ سیسٹم کو ہینگلیش کے لئے ایک نظارت کی جگہ میں پیدا کرے۔ مطابق دیوار میں ترجمہ کرنا بہت سے کاموں کے لئے سراسروں کا سٹ گھیرنے کی مدد کرسکتا ہے، اس کے ذریعہ مطابق ارزش سراسروں کی زبانوں سے مطابق ڈاٹ سٹ کو ترجمہ کرتا ہے. ہم نے mBART کا استعمال کرنا پیش آموزش کیا ہے ایک multilingual sequence-to-sequence مدل، اور مدل کی پیش آموزش کا کامل استعمال کرنا چاہتے ہیں کہ رومن ہندی کلمات کو ڈوناگری اسکریپٹ میں ترجمہ کیا جاتا ہے۔ ہم کس طرح انگلیسی جماعتوں کا انگلیسی ترجمہ کرنے کے ذریعے انگلیسی جماعتوں کو کس طرح پھیلاتے ہیں mBART کے عملکرد کو بہتر کر دیتے ہیں۔ ہماری سیسٹم نے آزمائش سٹ پر 12.22 سی بلیوس کا امتحان دیتا ہے۔ اور ہم اپنی پیشنهاد کی سیستموں کے ایک تفصیل غلط تحلیل کرتے ہیں اور پیشنهاد کی ڈاٹ سٹ اور میٹریک کی محدودیت کی تحقیق کرتے ہیں.', 'vi': 'Mật ngôn ngữ đa dạng rất phổ biến ở các xã hội đa ngôn ngữ trên khắp thế giới, nhưng nguồn lực chậm trễ để tạo ra hệ thống mạnh mẽ về những ngôn ngữ đó. Một yếu tố đóng góp lớn là tính chất không chính thức của các ngôn ngữ này, làm cho việc thu thập các dữ liệu trộn mã. Trong tờ giấy này, chúng tôi đề nghị hệ thống tìm ra Task 1 của bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi bởi vì tôi. Dịch theo hướng cụ thể có thể giúp mở rộng nguồn lực cho nhiều việc khác nhau bằng cách dịch chuyển các dữ liệu giá trị từ các ngôn ngữ cao tài nguyên. Chúng tôi đề nghị sử dụng mBART, một kiểu lặp tự truyện ngắn được đào tạo sẵn, và sử dụng hoàn to àn khóa huấn luyện của mô hình bằng cách chuyển chữ Ấn La Mã vào các câu hỗn hợp với văn lệnh Deva. Chúng tôi đánh giá cách mở rộng nội dung bằng cách kết hợp dịch tiếng Ấn của câu Anh cải thiện khả năng của tôi BART. Hệ thống của chúng tôi cho một lượng đứng số 12.22N trong bộ kiểm tra. Thêm nữa, chúng tôi thực hiện một phân tích lỗi chi tiết về hệ thống đã đề xuất và khám phá giới hạn của bộ dữ liệu cung cấp và đo hồ sơ.', 'uz': "Kodlash tarkibi tillar dunyodagi bir til jamiyatlarda juda katta jamiyatlar, ammo bu tillarda robot tizimlarini amalga oshirish uchun manbalar bakida qoladi. Bu tilning haqida muhim foydalanuvchisi, bu ko'paytirilgan maʼlumotni olish juda qiyin. Bu qogʻozda, biz CACLS 2021 Vazifaning 1 vazifa uchun tizimimizni angliz tilidagi ingliz tilidagi ingliz tarjimalar tizimini aniqlash uchun boshlanamiz. @ info We propose to use mBART, a pre-trained multilingual sequence-to-sequence model, and fully utilize the pre-training of the model by transliterating the roman Hindi words in the code-mixed sentences to Devanagri script.  Biz Inglizcha so'zlarning tarjimalarini birlashtirish uchun muBART ishni oshirishni o'ylaymiz. Bizning tizimimiz sinov sohasida 12.22 qismi BLEU qiymatini beradi. Koʻrsatganda, biz pendilgan tizimimizning aniqlanishni bajaramiz va koʻrsatilgan maʼlumot va metriklarning chegaralarini aniqlamiz.", 'hr': 'Mešani jezici su veoma popularni u multijezičkim društvima širom svijeta, ali resursi ostaju iza toga kako bi omogućili robne sustave na takvim jezicima. Veliki faktor doprinosa je neformalna priroda tih jezika koja čini teškom prikupiti podatke o mješanju koda. U ovom papiru predlažemo naš sustav za zadatak 1 CACLS 2021 kako bi stvorili sustav prevoda strojeva za engleski na Hinglish u nadzornom nastavu. Prevod u određenom smjeru može pomoći proširiti skup resursa za nekoliko zadataka prevodeći vrijedne sete podataka iz visokih jezika resursa. Predlažemo da upotrebimo mBART, predobučeni multijezički model do sekvence, i potpuno iskoristimo predobuku model a transliteracijom romanskih hindskih riječi u rečenicama mešanim kodom na skript Devanagri. Procjenjujemo kako proširenje ulaza povećavajući Hindske prevode engleskih rečenica poboljšava učinkovitost mBART-a. Naš sustav daje BLEU rezultat od 12,22 na testu. Nadalje, izvršavamo detaljnu analizu greške našeg predloženog sustava i istražujemo ograničenja pruženog seta podataka i metrika.', 'bg': 'Смесените с кодове езици са много популярни в многоезичните общества по света, но ресурсите изостават, за да се даде възможност за стабилни системи на такива езици. Основен допринасящ фактор е неформалният характер на тези езици, което затруднява събирането на смесени с кодове данни. В настоящата статия предлагаме нашата система за Задача 1 на ДАКЛС 2021 да генерира система за машинен превод на английски на хинглиш в контролирана обстановка. Преводът в дадена посока може да помогне за разширяване на набора от ресурси за няколко задачи, като превежда ценни набори от данни от езици с висок ресурс. Предлагаме да се използва предварително обучен многоезичен модел последователност към последователност и напълно да се използва предварителното обучение на модела чрез транслитерация на римските хинди думи в кодово смесените изречения към Деванагри скрипт. Ние оценяваме как разширяването на входа чрез конкатениране на хинди преводи на английски изречения подобрява ефективността на mBART. Нашата система дава резултат от 12.22 на тестовия комплект. Освен това извършваме подробен анализ на грешките на предлаганите от нас системи и изследваме ограниченията на предоставения набор от данни и показатели.', 'nl': 'Codegemengde talen zijn zeer populair in meertalige samenlevingen over de hele wereld, maar de middelen lopen achter om robuuste systemen voor dergelijke talen mogelijk te maken. Een belangrijke factor is het informele karakter van deze talen, waardoor het moeilijk is om code-gemengde gegevens te verzamelen. In dit artikel stellen we ons systeem voor Taak 1 van CACLS 2021 voor om een machinevertaalsysteem voor Engels naar Hinglish te genereren in een begeleide omgeving. Vertalen in de gegeven richting kan helpen de set van resources voor verschillende taken uit te breiden door waardevolle datasets uit talen met hoge resources te vertalen. We stellen voor om mBART te gebruiken, een voorgetraind meertalig sequence-to-sequence model, en volledig gebruik te maken van de pre-training van het model door de Romeinse Hindi woorden in de code-gemengde zinnen te translitreren naar Devanagri script. We evalueren hoe het uitbreiden van de invoer door Hindi vertalingen van de Engelse zinnen de prestaties van mBART verbetert. Ons systeem geeft een BLEU score van 12.22 op testset. Verder voeren we een gedetailleerde foutanalyse uit van onze voorgestelde systemen en onderzoeken we de beperkingen van de verstrekte dataset en statistieken.', 'da': "Kodeblandede sprog er meget populære i flersprogede samfund rundt om i verden, men ressourcerne halter bagud for at muliggøre robuste systemer på sådanne sprog. En vigtig bidragende faktor er disse sprogs uformelle karakter, hvilket gør det vanskeligt at indsamle kodeblandede data. I denne artikel foreslår vi vores system til opgave 1 af CACLS 2021 for at generere et maskinoversættelsessystem til engelsk til hinglisk i en overvåget indstilling. Oversættelse i den givne retning kan hjælpe med at udvide sættet af ressourcer til flere opgaver ved at oversætte værdifulde datasæt fra sprog med høj ressource. Vi foreslår at bruge mBART, en præ-trænet flersproget sekvens-til-sekvens model, og fuldt ud udnytte pre-træningen af modellen ved at transliterere de romerske hindi ord i kode-blandede sætninger til Devanagri script. Vi evaluerer, hvordan udvidelse af input ved at sammenkoble hindi oversættelser af de engelske sætninger forbedrer mBART's ydeevne. Vores system giver en BLEU score på 12,22 på testsættet. Desuden udfører vi en detaljeret fejlanalyse af vores foreslåede systemer og undersøger begrænsningerne i det leverede datasæt og metrics.", 'de': 'Codegemischte Sprachen sind in mehrsprachigen Gesellschaften auf der ganzen Welt sehr beliebt, doch die Ressourcen hinken zurück, um robuste Systeme für solche Sprachen zu ermöglichen. Ein wesentlicher Faktor ist der informelle Charakter dieser Sprachen, der die Erfassung von Code-Mixed-Daten erschwert. In diesem Beitrag schlagen wir unser System für Task 1 von CACLS 2021 vor, um ein maschinelles Übersetzungssystem für Englisch nach Hinglisch in einer überwachten Umgebung zu generieren. Das Übersetzen in die angegebene Richtung kann dazu beitragen, den Ressourcensatz für mehrere Aufgaben zu erweitern, indem wertvolle Datensätze aus Sprachen mit hohem Ressourcenanteil übersetzt werden. Wir schlagen vor, mBART zu verwenden, ein vorgetrainiertes mehrsprachiges Sequenzmodell, und das Vortraining des Modells vollständig zu nutzen, indem die römischen Hindi Wörter in den code-gemischten Sätzen in Devanagri Skript transliteriert werden. Wir bewerten, wie die Erweiterung der Eingabe durch Verkettung von Hindi-Übersetzungen der englischen Sätze die Leistung von mBART verbessert. Unser System liefert eine BLEU-Punktzahl von 12.22 auf Testset. Darüber hinaus führen wir eine detaillierte Fehleranalyse unserer vorgeschlagenen Systeme durch und untersuchen die Grenzen des bereitgestellten Datensatzes und der Metriken.', 'id': 'Bahasa campuran kode sangat populer dalam masyarakat berbagai bahasa di seluruh dunia, namun sumber daya tertinggal untuk memungkinkan sistem yang kuat dalam bahasa tersebut. Faktor kontribusi utama adalah sifat informal bahasa-bahasa ini yang membuat sulit untuk mengumpulkan data kode-campuran. Dalam kertas ini, kami mengusulkan sistem kami untuk Task 1 dari CACLS 2021 untuk menghasilkan sistem terjemahan mesin untuk bahasa Inggris ke Hinglish dalam pengawasan. Terjemahan dalam arah yang diberikan dapat membantu memperluas set sumber daya untuk beberapa tugas dengan menerjemahkan set data berharga dari bahasa sumber daya yang tinggi. Kami mengusulkan untuk menggunakan mBART, model multibahasa yang dilatih-dilatih-ke-urutan, dan memanfaatkan penuh praselatihan model dengan transliterasi kata-kata Hindi Roma dalam kalimat-kode campuran ke skrip Devanagri. Kami mengevaluasi bagaimana memperluas masukan dengan menyatukan terjemahan Hindi kalimat Inggris meningkatkan prestasi mBART. Sistem kita memberikan nilai BLEU 12.22 pada set tes. Selain itu, kami melakukan analisis kesalahan terperinci dari sistem kami yang diusulkan dan mengeksplorasi batasan dari dataset dan metrik yang diberikan.', 'ko': '코드 혼합 언어는 세계 각지의 다언어 사회에서 매우 유행하지만 이런 언어에서 건장한 시스템을 실현하는 자원은 상대적으로 뒤떨어진다.하나의 주요 요소는 이 언어들의 비공식적인 성질이기 때문에 코드 혼합 데이터를 수집하기 어렵다.본고에서 우리는 CACLS 2021퀘스트 1의 시스템을 제시하여 감독이 있는 환경에서 영어를 한영 영어로 만드는 기계 번역 시스템을 만들었다.고자원 언어에서 가치 있는 데이터 집합을 번역함으로써 주어진 방향에서 번역을 하면 여러 임무의 자원 집합을 확장하는 데 도움을 줄 수 있다.우리는 mBART를 사용하여 미리 훈련된 다중 언어의 서열을 서열 모델에 옮기고 코드 혼합문에 있는 로마 인디언 단어를 Devanagri 스크립트로 음역함으로써 이 모델의 예비 훈련을 충분히 활용할 것을 권장합니다.우리는 영어 문장을 연결하는 인디언 번역을 통해 입력을 확장하는 것이 mBART의 성능을 어떻게 향상시키는지 평가한다.우리 시스템은 시험집에서 12.22점의 BLEU 점수를 매겼다.그 밖에 우리는 우리가 제시한 시스템에 대해 상세한 오류 분석을 하고 제공된 데이터 집합과 지표의 한계성을 탐구했다.', 'fa': 'زبانهای مختلف کد در جامعه های زیادی زبان جهان بسیار مشهور هستند، ولی منابع برای توانایی سیستم های قوی بر این زبانها باقی مانده است. یک منبع مهم کمک کننده این است که طبیعت غیر معمولی از این زبانها است که برای جمع داده های مختلف کد سخت می کند. در این کاغذ، ما سیستم ما را برای کار ۱ CACLS 2021 پیشنهاد می\u200cکنیم تا سیستم ترجمه ماشین برای انگلیسی به هنگلیش در یک تنظیم نظارت شده ایجاد کند. ترجمه کردن در مسیر داده می\u200cتواند مجموعه منابع برای چندین کار با ترجمه مجموعه داده\u200cهای ارزشمند از زبانهای منابع بالا کمک کند. ما پیشنهاد می\u200cکنیم از mBART، یک مدل پیش آموزش بسیاری از زبان\u200cهای متحده به ترکیب، استفاده کنیم، و از پیش آموزش مدل کاملا استفاده کنیم، با ترکیب کلمات رومانی هندی را در جمله\u200cهای متحده\u200cشده کد به سند Devanagri. ما ارزیابی می کنیم که چگونه گسترش ورودی را با ترجمه کردن ترجمه\u200cهای هندی از جمله\u200cهای انگلیسی عملکرد mBART را بهتر می\u200cکند. سیستم ما در مجموعه آزمایش ۱۲.۲۲ امتحان نمایش BLEU را می دهد. ما یک تحلیل خطای جزئیات از سیستم\u200cهای پیشنهاد خود را انجام می\u200cدهیم و محدودیت مجموعه داده\u200cها و متریک\u200cها را تحقیق می\u200cکنیم.', 'tr': "K철dler karma힊ykly diller d체n첵채de k철p dilli jemgy첵etlerde 철r채n me힊hur, 첵철ne 힊e첵le dillerde g체첵챌li sistemalary etm채ge rugsat bermek 체챌in 첵ok. Adat챌a k철mekle힊en fakt철r, bu dilleri흫 resmi tebigatidir. Bu hatlary흫 kodlardan karma힊galan maglumatlaryny 첵ygnamak kyn m체mkin ed첵채r. Bu kagyzda CACLS 2021'i흫 g철revi 1-nji sistemimizi bejeril첵채n d체z체mlerde i흫lis챌e 체챌in bir ma힊yny흫 terjime sistemini bejermek 체챌in teklip ed첵채ris. Berilen g철rn철힊inde terjime etmek 체챌in birn채챌e t채blisa흫 체챌in mykdarlar terjime etmek 체챌in k철mek edip biler. Biz mBART'u, 철흫-철흫체nde bilim sistemasyzlykly bir multi dilli sequencer-to-sequencer modelini ullanmagy teklip ed첵채ris we bu modelini흫 철n-okuw챌ysyny Devanagri skriptine roman Hindileri s철zlerini terjime etmegi 체챌in ullan첵arys. Biz Hindileri흫 s 철zlerini흫 terjimelerini n채hili da힊yr첵andygyny 챌철zdirip mBART'y흫 netijesini gowla첵ar. Bizi흫 sistemamyz test d체zeninde BLEU sany 12,22 sany berir. Mundan so흫ra, teklip eden sistemlerimizi흫 detayly 첵al흫y힊lyk 챌철z체mlerini we berilen veri setirini흫 we metrikleri흫 챌철z체mlerini g철zlemek 체챌in 첵체ze 챌철z체l첵채ris.", 'sq': 'Gjuhat e përziera me kod janë shumë popullore në shoqëritë shumëgjuhësore anembanë botës, megjithatë burimet mbeten prapa për të mundësuar sisteme të forta në gjuhë të tilla. Një faktor kontribues i madh është natyra jozyrtare e këtyre gjuhëve që e bën të vështirë mbledhjen e të dhënave të përziera me kod. Në këtë letër, propozojmë sistemin tonë për detyrën 1 të CACLS 2021 për të gjeneruar një sistem përkthimi makinash për anglishtin në Hinglish në një ambient të mbikqyrur. Përkthimi në drejtimin e caktuar mund të ndihmojë zgjerimin e grupit të burimeve për disa detyra duke përkthyer grupe të dhënash të vlefshme nga gjuhët e larta të burimeve. Ne propozojmë të përdorim mBART, një model shumë gjuhësh të stërvitur nga sekuenca në sekuencë, dhe të përdorim plotësisht parastërvitjen e modelit duke transliteratur fjalët romane Hindi në fjalët e përziera me kod në skriptin Devanagri. Ne vlerësojmë se si zgjerimi i hyrjes duke përmbledhur përkthimet Hindi të fjalëve angleze përmirëson performancën e mBART. Sistemi ynë jep një rezultat BLEU prej 12.22 në grupin e testit. Further, we perform a detailed error analysis of our proposed systems and explore the limitations of the provided dataset and metrics.', 'af': "Kode-gemengde tale is baie populaar in multilinglike samelewing rondom die wêreld, maar die hulpbronne is agter om kragtige stelsels op sodanige tale te aktiveer. 'n Groot bydraaiende faktor is die onformele natuur van hierdie tale wat dit moeilik maak om kode gemengde data te samel. In hierdie papier, ons voorstel ons stelsel vir Taak 1 van CACLS 2021 om 'n masjien vertaling stelsel vir Engels te genereer na Hinglish in' n ondersoekte instelling. Vertaling in die gegewe rigting kan help die stel van hulpbronne vir verskeie taak uitbrei deur te vertaling waardelike datastel van hoë hulpbronne tale. Ons voorstel om mBART te gebruik, 'n vooraf-onderwerp multitaalske sekwensie-na-sekwensie model, en die vooraf-onderwerp van die model volledig te gebruik deur die roman Hindi woorde in die kode-gemengde setnings na Devanagri skrip te transliteraeer. Ons evalueer hoe die invoer uitbrei deur Hindi vertalings van die Engelse setings verbeter mBART se prestasie. Ons stelsel gee 'n BLEU telling van 12.22 op toets stel. Verder, ons uitvoer 'n gedetale fout analiseer van ons voorgestelde stelsels en ondersoek die beperkinge van die verskaf datastel en metries.", 'hy': 'Կոդի խառնված լեզուները շատ հայտնի են աշխարհի բազմալեզու հասարակություններում, սակայն ռեսուրսները մնում են հետևում, որպեսզի հնարավոր լինի այս լեզուների վրա հաստատ համակարգեր: A major contributing factor is the informal nature of these languages which makes it difficult to collect code-mixed data.  Այս թղթի մեջ մենք առաջարկում ենք մեր համակարգը CACIS 2021-ի առաջին հանձնարարության համար, որպեսզի ստեղծենք անգլերենի համար մեքենային թարգմանման համակարգ հինգլերենի համար վերահսկվող միջավայրում: Տեղադրված ուղղությամբ թարգմանելը կարող է օգնել մեծացնել ռեսուրսների համակարգը մի քանի խնդիրների համար թարգմանելով արժեքավոր տվյալների համակարգերը բարձր ռեսուրսների լեզուներից: Մենք առաջարկում ենք օգտագործել mBAR-ը, մի նախապատրաստված բազմալեզու հաջորդականության մոդել, և ամբողջովին օգտագործել մոդելի նախապատրաստման գործընթացը՝ վերագրելով Հինդիայի ռոմանական բառերը Devan Agro-ի գրքի խառնված նախադասություններում: Մենք գնահատում ենք, թե ինչպես է ինֆորմացիայի ընդլայնումը անգլերեն նախադասությունների համընդհանուր թարգմանման միջոցով բարելավում mBAR-ի արտադրողությունը: Մեր համակարգը տալիս է փորձարկումների համակարգում 12.22 գնահատականը: Ավելին, մենք կատարում ենք մեր առաջարկված համակարգերի սխալների մանրամասն վերլուծություն և ուսումնասիրում ենք տրամադրված տվյալների սահմանափակումները և չափումները:', 'am': 'ቋንቋዎች በዓለም በቋንቋ ቋንቋ ማኅበረሰቦች እጅግ የሚቆጠሩ ናቸው፤ ነገር ግን እንደነዚህ ቋንቋዎች የረኀብ ስርዓቶችን ለማድረግ የተዘጋጀ ነው፡፡ ይህ የቋንቋዎች አካባቢ ጥያቄ ነው፣ ይህም የኮድ-የተለየ መረጃዎችን ለመቀበል በጣም ችግር ነው፡፡ በዚህ ካላት፣ የCACLS 2021 ስራ 1 ስራችንን ለመፍጠር በተጠበቀው ማተርጓሜ የኢንጂልኛ ትርጉም ስርዓት ለመፍጠር እናዘጋጅታለን፡፡ በተሰጠው መንገድ መግለጫ የከበረ የድህነት ቋንቋዎች በሚተርጉም የከበረ ዳታዎችን በመዘርጋት የሚችል የክፍለ ሥርዓቶችን ለማሰፋት ይችላል፡፡ ከዚህ በፊት ተማርነው የብልቋዊ ቋንቋ ለsequence-model mBART ለመጠቀም እና የሞዴላውን የፊደል ትምህርት ለመጠቀም እናደርጋለን፤ የሮማዊ ሄንዲ ቃላትን በCode-mixed ክፍሎች ለDevanagri ጽሑፍ በመለጠፍ እናስጠጋለን፡፡ የኢንጂልኛ ቃላት የኢንጂልዩን ትርጓሜዎች ማድረግ እንዴት እንደመዘረጋ እናስተውላለን፡፡ ሲስተምረታችን የ12.22 የBLEU score በተፈተና ጥናት ይሰጣል፡፡ በተጨማሪም፣ በተዘጋጀው የስህተታችንን አስተያየት እና የዳታ ሰርቨሮች ግንኙነቶችን እናሳውቃለን፡፡', 'az': "Còd karıştırılmış dillər dünyanın çoxlu dil toplumlarında çox məşhurdur, amma bu dillərdə güclü sistemləri qabilleştirmək üçün istifadə etmək üçün istifadə edirlər. Ən böyük köməkçi faktör bu dillərin informal təbiətidir ki, kodu karışıqlı verilər toplamaq çətindir. Bu kağızda, CACLS 2021'in 1. Gözəl sistemimizi İngilizə ilə Hinglish üçün maşın çevirim sistemini yaratmaq üçün təklif edirik. Beləliklə verilən yönəltdə tərcümə etmək yüksək ressurs dillərindən qiymətli veri qurğularını tərcümə edərək çoxlu işlər üçün ressurs qurğularını genişləşdirə bilər. Biz mBART, əvvəlcə təhsil edilmiş çoxlu dil sequence-to-sequence modeli istifadə etməyi və model in in əvvəl təhsil edilməsini Devanagri skriptə roman Hindi sözlərini kodla karışmış cümlələrdə təhsil etməyi təklif edirik. İngilizci cümlələrin Hindi çevirilərini birlikdə növbəsini genişləndirməklə müəyyən edirik. Sistemimiz test setdə 12.22 BLEU müəyyən etdi. Daha sonra, təklif edilmiş sistemlərimizin detalı xəta analizisini və verilən verilən qurğuların və metriklərin sınırlarını incidirik.", 'bs': 'Mešani jezici su veoma popularni u multijezičkim društvima širom svijeta, ali resursi ostaju iza sebe kako bi omogućili robne sisteme na takvim jezicima. Veliki faktor doprinosa je neformalna priroda tih jezika, što čini teško prikupiti podatke o mješanju koda. U ovom papiru predlažemo naš sistem za zadatak 1 CACLS 2021 kako bi stvorili sistem prevoda mašine za engleski na Hinglish u nadzornom nastavu. Prevod u određenom smjeru može pomoći proširiti setu resursa za nekoliko zadataka prevodeći vrijedne sete podataka iz visokih jezika resursa. Predlažemo da upotrebimo mBART, predobučeni multijezički model do sekvence, i potpuno iskoristimo predobuku model a transliteracijom romanskih hindskih riječi u rečenicama mešanim kodom na scenario Devanagri. Procjenjujemo kako proširenje ulaza povećavajući Hindske prevode engleskih rečenica poboljšava učinkovitost mBART-a. Naš sistem daje BLEU rezultat od 12,22 na testu. Nadalje, obavljamo detaljnu analizu greške našeg predloženog sustava i istražujemo ograničenja pruženog seta podataka i metrika.', 'ca': "Les llengües combinades amb codis són molt populars en societats multilingües arreu del món, però els recursos es retarden per permetre sistemes robustos en aquestes llengües. Un factor important que contribueix és la naturalesa informal d'aquestes llengües que dificulta la recollició de dades combinades amb codis. En aquest article, proposem el nostre sistema de la tasca 1 de CACLS 2021 per generar un sistema de traducció màquina d'anglès a Hinglish en un entorn supervisat. Translating in the given direction can help expand the set of resources for several tasks by translating valuable datasets from high resource languages.  Proposem usar mBART, un model de seqüència a seqüència multilingüe pré-entrenat, i utilitzar plenament la pré-entrenament del model transliterant les paraules hindíes romanes en frases combinades de codi a l'escriptura Devanagri. Evaluam com ampliar l'entrada concatenant les traduccions hindíes de les frases angleses millora el rendiment del mBART. El nostre sistema dóna una puntuació BLEU de 12,22 en el conjunt d'exàmens. També fem una anàlisi detallada d'errors dels nostres sistemes proposats i explorem les limitacions del conjunt de dades proporcionat i les mètriques.", 'bn': 'কোড মিশ্রিত ভাষা বিশ্বের বহুভাষী সমাজে খুব জনপ্রিয়, কিন্তু এই ধরনের ভাষায় রোবস্ট সিস্টেম সক্রিয় করার জন্য তাদের সম্পদের কোড মিশ্রিত তথ্য সংগ্রহ করার জন্য এটা কঠিন। এই কাগজটিতে আমরা আমাদের সিস্টেম ক্যাসিএলএস ২০২১-এর কাজের জন্য প্রস্তাব করছি যাতে ইংরেজীর জন্য ইংরেজি অনুবাদ সিস্টেম তৈরি করা হয় নির্দিষ্ট দিকে অনুবাদ করা উচ্চ সম্পদ ভাষা থেকে মূল্যবান ডাটাসেট অনুবাদ করে বেশ কিছু কাজের জন্য সম্পদ বৃদ্ধি করতে পারে। আমরা প্রস্তাব করছি এক পূর্বে প্রশিক্ষিত বহুভাষী সেকেন্স-থেকে সেকেন্স মডেল ব্যবহার করতে এবং ডেভাগ্রি স্ক্রিপ্টে রোমান হিন্দি শব্দ ব্যবহার করে রোমান হিন্দি শব্দ ব্যবহার ইংরেজি বাক্যের অনুবাদ সম্পর্কে হিন্দি অনুবাদের সাথে কিভাবে ইনপুট বিস্তৃত করে আমরা মূল্যায়ন করি। আমাদের সিস্টেম টেস্ট সেটে ১২.২২ স্কোর দিয়েছে। এছাড়াও, আমরা আমাদের প্রস্তাবিত সিস্টেমের বিস্তারিত ভুল বিশ্লেষণ করি এবং প্রদান করা ডাটাসেট এবং মেট্রিকের সীমাবদ', 'cs': 'Jazyky smíšené kódem jsou velmi populární v mnohojazyčných společnostech po celém světě, přesto zdroje zaostávají, aby umožnily robustní systémy pro tyto jazyky. Hlavním faktorem přispívá neformální povaha těchto jazyků, která ztěžuje shromažďování údajů se smíšenými kódy. V tomto článku navrhujeme náš systém pro úlohu 1 CACLS 2021 pro generování strojového překladu systému pro angličtinu do hindštiny v dohledu. Překlad daným směrem může pomoci rozšířit sadu zdrojů pro několik úkolů překladem cenných datových sad z jazyků s vysokými zdroji. Navrhujeme použít mBART, předškolený vícejazyčný model sekvence na sekvenci, a plně využít předškolení modelu transliterací římských hindských slov v kódově smíšených větách do Devanagri skriptu. Hodnotíme, jak rozšíření vstupu řazením hindštiny překladů anglických vět zlepšuje výkon mBART. Náš systém poskytuje BLEU skóre 12,22 na testovací sadě. Dále provádíme podrobnou analýzu chyb navržených systémů a zkoumáme omezení poskytnutých datových sad a metrik.', 'sw': 'Lugha zilizochanganyika na sheria ni maarufu sana katika jamii za lugha mbalimbali duniani kote, lakini rasilimali zinabaki ili kuwezesha mfumo wa mabomu katika lugha kama hizi. Msingi mkubwa wa michango ni asili ya lugha hizi ambazo inafanya kuwa vigumu kukusanya taarifa tofauti za kodi. Katika karatasi hii, tunapendekeza mfumo wetu wa Kazi 1 wa CACLS 2021 kutengeneza mfumo wa kutafsiri mashine kwa Kiingereza kwenda Hinglish katika mazingira yanayochunguzwa. Kutafsiri katika mwelekeo ulio pewa inaweza kusaidia kuongeza rasilimali kwa kazi kadhaa kwa kutafsiri seti za taarifa za thamani kutoka lugha za rasilimali za juu. Tunazipendekeza kutumia mBART, mtindo wa mfululizo wa awali wa lugha kwa mfululizo, na kutumia mafunzo ya awali ya modeli kwa kuandika maneno ya KiHindi ya Roma katika hukumu zilizochanganyika kwa ajili ya script ya Devanagri. Tunaelezea namna ya kuongezeka kwa utafsiri wa Kihindi wa lugha za Kiingereza unavyobadilisha utendaji wa mBART. Our system gives a BLEU score of 12.22 on test set.  Zaidi ya hayo, tunafanya uchambuzi wa makosa ya kina kuhusu mfumo wetu wa pendekezo na kutambua vizuizi vya taarifa na mitiria.', 'fi': 'Koodi-sekakielet ovat erittäin suosittuja monikielisissä yhteiskunnissa ympäri maailmaa, mutta resurssit ovat jäljessä, jotta tällaiset kielet olisivat luotettavia. Merkittävä tekijä on näiden kielten epävirallinen luonne, joka vaikeuttaa koodisekoitettujen tietojen keräämistä. Tässä artikkelissa ehdotamme CACLS 2021:n tehtävään 1 kuuluvaa järjestelmäämme konekäännösjärjestelmän luomiseksi englanniksi hinglishiksi valvotussa ympäristössä. Kääntäminen tiettyyn suuntaan voi auttaa laajentamaan resurssejaan useaan tehtävään kääntämällä arvokkaita aineistoja korkean resurssin kielistä. Ehdotamme, että käytetään mBART-mallia, esikoulutettua monikielistä sekvenssimallia, ja hyödynnämme täysin mallin esikoulutusta transliteroimalla roomalaiset hindin sanat koodisekoitetuissa lauseissa Devanagri-skriptiksi. Arvioimme, miten englanninkielisten lauseiden hindi-käännösten laajentaminen parantaa mBART:n suorituskykyä. Järjestelmämme antaa BLEU-pisteen 12,22 testisarjassa. Lisäksi teemme yksityiskohtaisen virheanalyysin ehdotetuista järjestelmistämme ja tutkimme tarjottujen tietojen ja mittareiden rajoituksia.', 'et': 'Koodisegukeeled on väga populaarsed mitmekeelsetes ühiskondades üle kogu maailma, kuid ressursid jäävad maha, et võimaldada selliste keelte tugevaid süsteeme. Peamine panustav tegur on nende keelte mitteametlik olemus, mis raskendab koodisega andmete kogumist. Käesolevas töös pakume välja meie CACLS 2021 ülesande 1 süsteemi, et luua masintõlke süsteem inglise keelde hinglish järelevalve all. Antud suunas tõlkimine võib aidata laiendada ressursside hulka mitmete ülesannete jaoks, tõlkides väärtuslikke andmekogumeid suure ressursiga keeltest. Me teeme ettepaneku kasutada mBART, eelnevalt väljaõpetatud mitmekeelset jadast järjestuseni mudelit ja täielikult ära kasutada mudeli eelkoolitust, translitereerides rooma hindi sõnad koodisegatud lausetes Devanagri skripti. Hindame, kuidas sisendi laiendamine inglise keele lausete hindi tõlkete ühendamisega parandab mBART jõudlust. Meie süsteem annab BLEU skoori 12,22 testikomplektis. Lisaks teostame pakutud süsteemide üksikasjaliku veaanalüüsi ning uurime esitatud andmekogumi ja mõõdikute piiranguid.', 'sk': 'Kodirani jeziki so zelo priljubljeni v večjezičnih družbah po vsem svetu, vendar pa viri zaostajajo, da bi omogočili robustne sisteme v takih jezikih. Glavni dejavnik, ki prispeva k temu, je neformalna narava teh jezikov, zaradi česar je težko zbirati podatke z mešanimi kodami. V tem prispevku predlagamo naš sistem za nalogo 1 CACLS 2021 za ustvarjanje sistema strojnega prevajanja za angleščino v hingliščino v nadzorovanem okolju. Prevajanje v določeno smer lahko pomaga razširiti nabor virov za več opravil s prevajanjem dragocenih naborov podatkov iz jezikov z visokimi viri. Predlagamo uporabo mBART, vnaprej usposobljenega večjezičnega modela zaporedja do zaporedja, in v celoti izkoristiti predusposabljanje modela s transliteracijo rimskih hindijskih besed v kodno mešanih stavkih v Devanagri pisavo. Ocenjujemo, kako razširitev vnosa s povezovanjem hindijskih prevodov angleških stavkov izboljšuje učinkovitost mBART. Naš sistem daje BLEU rezultat 12,22 na testnem kompletu. Poleg tega izvajamo podrobno analizo napak naših predlaganih sistemov in raziskujemo omejitve zagotovljenega nabora podatkov in meritev.', 'he': 'שפות מעורבות קודים מאוד פופולריות בחברות רבות שפות ברחבי העולם, אך המשאבים מאחור לאפשר מערכות חזקות על שפות כאלה. גורם תורם גדול הוא הטבע הרשמי של השפות האלה, מה שמקשה לאסוף נתונים מעורבים בקוד. בעיתון הזה, אנו מציעים את המערכת שלנו למשימה 1 של CACLS 2021 כדי ליצור מערכת תרגום מכונת לאנגלית להינגליש במסגרת מבוקרת. התרגום בכיוון הנתון יכול לעזור להרחיב את קבוצת המשאבים למספר משימות על ידי התרגום קבוצות מידע ערכות משפות גבוהות. אנו מציעים להשתמש ב mBART, מודל רצף-לרצף-לרצף מוכשר מראש, ולהשתמש באופן מלא באימונים מראש של המודל על ידי שינוי המילים ההינדיות הרומיות במשפטים מעורבים של קוד לתסריט Devanagri. אנו מעריכים איך להרחיב את הכניסה על ידי התרגמות הינדית של המשפטים האנגליים משפר את ההופעה של mBART. המערכת שלנו נותנת נקודת BLEU של 12.22 בסט מבחן. חוץ מזה, אנחנו מבצעים ניתוח שגיאות מפורט של המערכות המוצעות שלנו ולחקור את הגבלות של קבוצת המידע המסופקת ומטריקות.', 'ha': "Harsunan da aka haɗa kodi, sun zama mafiya yawan jama'a cikin jamii masu mulki-addu'a a cikin duniya, kuma amma ma'auni na bakin baya a kan karatar da tsarin mutane da ke cikin lugha kamar wannan. Babu wani abu mai amfani da shi yana da halin waɗannan harshe, wanda yana kasancẽwa mai ƙunci a samo data-da-haɗe. Daga wannan takardan, Munã buɗar da ɗabi'arinmu na aikin aikin Kayan 1 na CACLS 2021, dõmin ya zaɓi wata tarjibu na misalin Ingiriya zuwa Higgish a cikin wani tsarin da aka tsare. Ka tafsira cikin shirin da aka ba shi yana iya taimako ya yalwace daidaita rasilitan wa masu aikin da za'a iya lissafa masu yawa, da kuma ka fassar tsaro masu kima daga harshen resource masu sarrafa. Kana goyyar da amfani da mBaraT, wata misalin mulki-biyu-tsohon-tsohon zaman aka yi amfani da shi, kuma Mu yi amfani da amfani da kwamfyutan yin amfani da shirin motel kafin da za'a fassara maganar Roman Hidi cikin misalin kodi-da-haɗe zuwa scriptn Devangari. Tuna ƙaddara yadda za'a shimfiɗa inputi da kuma a sambaɗa fassarar cikin Ingiriya masu shirya muhimmin mBERT. Yaurinmu na ba da BLEU score 12.22 kan jarraba. Furan, za mu yi ƙidãya wa misãlai na ƙidãya masu shiryuwa da aka buƙata, kuma mu sami tsarin da aka samu da shi.", 'jv': 'Cdromaké karo akeh langkung populer kanggo kalaman komunitas ing sampeyan sing di nggawe ning dunya, tho sing perusahaan karo sistem sing gawé nggawe dila-dila sing ngentambah. Ing bener sing nyumbang kelas kuwi ngregani soko kesempatan ning langkung iki dadi, sing ngomong susahe ngregani data karo kode Nan pepulan iki, kita supoyo sistem kanggo Tarjamahan 1 ning CaCLS 2020 1 kanggo nggawe sistem tarjamahan kanggo Inggris kanggo hinglish nang aturan ngirim barang nggawe Where Awak dhéwé nggunakake mBart, sampeyan akeh banter-sistem sing wis disenyongno karo pakem, lan nggawe ngubah mulai kuwi nggawe balêr-suaraning model kuwi nggawe tarjamahan kelas perangkat dhéwé, arep kuwi wis ngubah dhéwé, arep awak dhéwé karo pakem "Devanagri". Awak dhéwé nggunakake sing katêpakan anyir tentang input lak sampeyan kanggo ngerasah barang kanggo ngerasah barang ingkang mabur Sistem dhéwé menyang paling blo sing 12.22 neng ujian Lakok, awak dhéwé ngerti dadi kanggo nyealakno karo sistem sing nggawe barang nggawe barang dataset karo Metik.', 'bo': 'སྐད་རིགས་འདི་དག་གི་སྐད་ཡིག་ཆ་སྤྱི་ཚོགས་ལས་མང་ཆེ་ཤོས་རེད། ཡིན་ནའང་འཛམ་གླིང་ཡོད་པའི་སྐད་ཡིག སྐད་རིགས་འདིའི་གནས་ཚུལ་ཆེ་ཤོས་མཁན་གྱི་ཆ་རྐྱེན་ཅིག་ནི་སྐད་རིགས་འདིའི་དངོས་གཞི་རྒྱུན་གྱི་རང་རིགས་རེད། In this paper, we propose our system for Task 1 of CACLS 2021 to generate a machine translation system for English to Hinglish in a supervised setting. དམིགས་འཛུགས་ཀྱི་གནས་སྟངས་ལ་ཚུལ་འདིའི་ནང་དུ་རྒྱུ་དངོས་ཐོག་ཁུངས་ཀྱི་གནས་སྟངས་མང་ཙམ་ལ་རྒྱབ་སྐྱོར We propose to use mBART, a pre-trained multilingual sequence-to-sequence model, and fully utilize the pre-training of the model by transliterating the roman Hindi words in the code-mixed sentences to Devanagri script. ང་ཚོས་ཨིན་ཡིག་གི་ཚིག་རྐང་ཡིག ང་ཚོའི་མ་ལག་གིས་བརྟག་ཞིབ་བཤེར་གྱི་ཚད་ལྡན་༢༢།༢༢ འོན་ཀྱང་། ང་ཚོས་ང་ཚོའི་འཆར་བཀོད་པའི་མ་ལག་གི་ལྟ་སྟངས་གསལ་བཤད་བྱས་བའི་ནོར་འཁྲུལ་ཞིག'}
{'en': 'On the logistical difficulties and findings of Jopara Sentiment Analysis', 'ar': 'حول الصعوبات اللوجستية ونتائج تحليل جوبارا للمشاعر', 'fr': "Sur les difficultés logistiques et les résultats de l'analyse du sentiment Jopara", 'es': 'Sobre las dificultades logísticas y los hallazgos de Jopara Sentiment Analysis', 'pt': 'Sobre as dificuldades logísticas e os resultados da Análise de Sentimento de Jopara', 'ja': 'Jopara Sentiment Analysisのロジスティクス上の困難と知見について', 'zh': 'Jopara情析后勤难见', 'hi': 'जोपारा भावना विश्लेषण के तार्किक कठिनाइयों और निष्कर्षों पर', 'ru': 'О логистических трудностях и выводах Jopara Sentiment Analysis', 'ga': 'Ar na deacrachtaí lóistíochta agus torthaí Anailís Mothúchán Jopara', 'hu': 'A Jopara Sentiment Analysis logisztikai nehézségeiről és eredményeiről', 'ka': 'იოპარას სენტიმენტის ანალიზაციის ლოგისტიკური რთული და ძებნა', 'el': 'Σχετικά με τις υλικοτεχνικές δυσκολίες και τα ευρήματα της ανάλυσης συναισθημάτων Jopara', 'it': 'Sulle difficoltà logistiche e sui risultati di Jopara Sentiment Analysis', 'mk': 'За логистичките тешкотии и откритија на анализата на чувствата на Јопара', 'lt': 'On the logistical difficulties and findings of Jopara Sentiment Analysis', 'ms': 'Pada kesulitan logistik dan penemuan Analisi Sentimen Jopara', 'ml': 'ജോപ്പറയുടെ സെന്റിമെന്റ് അന്വേഷണങ്ങളുടെ ലോഗിക്കൽ പ്രയാസങ്ങളും കണ്ടുപിടിച്ചിരിക്കുന്നു', 'mt': 'Dwar id-diffikultajiet loġistiċi u s-sejbiet tal-Analiżi tas-Sentiment Jopara', 'mn': 'Jopara Sentiment-ын судалгааны хэцүү болон', 'pl': 'O trudnościach logistycznych i ustaleniach analizy sentymentów Jopara', 'kk': 'Jopara Sentiment анализының логистикалық мәселелері және табулары', 'ro': 'Cu privire la dificultățile logistice și constatările analizei sentimentelor Jopara', 'so': 'Dhibaatooyinka iyo baaritaanka sawirada Jopara', 'no': 'På logistiske vanskeleghetar og finning av Jopara Sentiment Analysis', 'si': 'Jopara Sentiment විශ්ලේෂණය ගැන ලෝජිස්තික අමාරුවන් සහ හොයාගන්න', 'sr': 'U vezi logističkih teškoća i otkrića Sentimentne analize Jopara', 'ta': 'Jopara Sentiment Analysis', 'sv': 'Om logistiska svårigheter och resultat av Jopara Sentiment Analysis', 'ur': 'جوپار سنٹیمنٹ تحقیقات کے معاملہ میں', 'uz': 'Name', 'vi': 'Về các khó khăn về hậu cần và kết quả của Analysis cảm xúc Jopara', 'bg': 'Относно логистичните трудности и констатациите на анализа на сентимента на Йопара', 'da': 'Om logistiske vanskeligheder og resultater af Jopara Sentiment Analysis', 'hr': 'O logističkim poteškoćama i nalazima Sentimentne analize Jopara', 'nl': 'Over de logistieke moeilijkheden en bevindingen van Jopara Sentiment Analysis', 'de': 'Zu den logistischen Schwierigkeiten und Erkenntnissen der Jopara Sentiment Analyse', 'ko': '조파라 정서 분석에 대한 후방 근무 어려움과 발견', 'fa': 'درباره مشکلات منطقی و پیدا کردن تحلیل سنتی جوپار', 'id': 'Pada kesulitan logistik dan penemuan dari Analisi Sentimen Jopara', 'sw': 'Kuhusu matatizo ya kimaadili na matokeo ya uchambuzi wa Seneti ya Jopara', 'af': 'Op die logistike moeilikhede en vindings van Jopara Sentiment Analysis', 'tr': "Jopara Sentiment Analizi'nin logatik kynçylyklarynda", 'sq': 'Për vështirësitë logjistike dhe gjetjet e analizës së ndjenjave të Jopara', 'am': 'የዮፓራ ሰዓቲ Analysis', 'az': 'Jopara Sentiment Analizi', 'hy': 'Ջոպար զգացմունքների վերլուծության լուծումների և լուծումների մասին', 'bn': 'জোপারা সেন্টাইমেন্ট বিশ্লেষণের বৈশিষ্ট্যিক সমস্যা এবং খুঁজে পাওয়া যায়', 'bs': 'O logističkim problemima i nalazima Sentimentne analize Jopara', 'ca': "En les dificultats logístices i descobriments de l'anàlisi del sentiment Jopara", 'cs': 'K logistickým obtížím a zjištěním analýzy sentimentu Jopara', 'et': 'Jopara Sentimentaalüüsi logistiliste raskuste ja tulemuste kohta', 'fi': 'Jopara Sentiment Analyysin logistisista vaikeuksista ja löydöksistä', 'jv': 'Nang usul sing nggawe pamusul lan bukal Jopara Sentiment', 'sk': 'O logističnih težavah in ugotovitvah analize čustev Jopara', 'he': 'On the logistical difficulties and findings of Jopara Sentiment Analysis', 'ha': 'On the logistical problems and foundings of Jopara cent Analyze', 'bo': 'དེའི་སྐོར་གྱི་འཛིན་སྣུམ་གྱི་དཀའ་ངལ་དང་Jopara Sentiment དབྱེ་ཞིབ་ཀྱི་རྙེད་སྐབས་'}
{'en': 'This paper addresses the problem of ', 'fr': "Cet article aborde le problème de l'analyse des sentiments pour le jopara, une langue à changement de code entre le guarani et l'espagnol. Nous collectons d'abord un corpus de tweets à dominante guarani et discutons des difficultés rencontrées pour trouver des données de qualité, même pour des tâches relativement faciles à annoter, telles que l'analyse des sentiments. Ensuite, nous formons un ensemble de modèles neuronaux, y compris des modèles de langage pré-entraînés, et nous déterminons s'ils sont plus performants que les modèles d'apprentissage automatique traditionnels dans cette configuration à faibles ressources. Les architectures de transformateurs obtiennent les meilleurs résultats, même si le guarani n'est pas pris en compte lors de la pré-formation, mais les modèles d'apprentissage automatique traditionnels sont très performants en raison de la faible quantité de ressources du problème.", 'ar': 'تتناول هذه الورقة مشكلة تحليل المشاعر لـ Jopara ، وهي لغة تبديل الشفرة بين Guarani والإسبانية. نجمع أولاً مجموعة من التغريدات التي يهيمن عليها لغة الغواراني ونناقش صعوبات العثور على بيانات عالية الجودة حتى للمهام التي يسهل التعليق عليها نسبيًا ، مثل تحليل المشاعر. بعد ذلك ، نقوم بتدريب مجموعة من النماذج العصبية ، بما في ذلك نماذج اللغة المدربة مسبقًا ، واستكشاف ما إذا كانت تعمل بشكل أفضل من نماذج التعلم الآلي التقليدية في هذا الإعداد منخفض الموارد. تحصل معماريات المحولات على أفضل النتائج ، على الرغم من عدم مراعاة Guarani أثناء التدريب المسبق ، إلا أن نماذج التعلم الآلي التقليدية تعمل بشكل وثيق نظرًا لطبيعة المشكلة منخفضة الموارد.', 'es': 'Este artículo aborda el problema del análisis de sentimientos para Jopara, un lenguaje de cambio de código entre guaraní y español. Primero recopilamos un corpus de tuits con dominancia guaraní y discutimos las dificultades de encontrar datos de calidad incluso para tareas relativamente fáciles de anotar, como el análisis de sentimientos. Luego, entrenamos un conjunto de modelos neuronales, incluidos modelos de lenguaje previamente entrenados, y exploramos si funcionan mejor que los modelos tradicionales de aprendizaje automático en esta configuración de pocos recursos. Las arquitecturas de transformadores obtienen los mejores resultados, a pesar de no considerar el guaraní durante el preentrenamiento, pero los modelos tradicionales de aprendizaje automático funcionan muy cerca debido a la naturaleza de pocos recursos del problema.', 'pt': 'Este artigo aborda o problema da análise de sentimentos para o Jopara, uma linguagem de troca de código entre o guarani e o espanhol. Primeiro, coletamos um corpus de tweets predominantemente guarani e discutimos as dificuldades de encontrar dados de qualidade mesmo para tarefas relativamente fáceis de anotar, como análise de sentimentos. Em seguida, treinamos um conjunto de modelos neurais, incluindo modelos de linguagem pré-treinados, e exploramos se eles têm um desempenho melhor do que os tradicionais de aprendizado de máquina nessa configuração de poucos recursos. As arquiteturas de transformadores obtêm os melhores resultados, apesar de não considerarem o Guarani durante o pré-treinamento, mas os modelos tradicionais de aprendizado de máquina têm um desempenho próximo devido à natureza de poucos recursos do problema.', 'ja': '本稿では、グアラニ語とスペイン語のコードスイッチング言語であるJoparaのセンチメント分析の問題について述べる。まず、Guaraniが優勢なツイートのコーパスを収集し、センチメント分析など、比較的簡単に注釈を付けることができるタスクでも、質の高いデータを見つけることの難しさについて話し合います。次に、事前にトレーニングされた言語モデルを含む一連のニューラルモデルをトレーニングし、この低資源設定で従来の機械学習モデルよりも優れたパフォーマンスを発揮するかどうかを探ります。変圧器アーキテクチャは、事前トレーニングでグアラニを考慮していないにもかかわらず、最高の結果を得ることができますが、従来の機械学習モデルは、問題のリソースの低さのために近いパフォーマンスを発揮します。', 'zh': '本文解Jopara之情析,Jopara瓜拉尼语、西班牙语之代码切换言也。 首集以瓜拉尼语为主之推文语料库,并论虽对易注之务(如情析)得高质量数之难。 然后训神经模形,预为言语,究其低资源设之机器于旧者尤善。 虽未思Guarani,而变压器架构得其宜,然事低资源性质,旧机器近之。', 'hi': 'यह पेपर जोपारा के लिए भावना विश्लेषण की समस्या को संबोधित करता है, जो कि ग्वारानी और स्पेनिश के बीच एक कोड-स्विचिंग भाषा है। हम पहले ग्वारानी-प्रमुख ट्वीट्स का एक कॉर्पस एकत्र करते हैं और यहां तक कि अपेक्षाकृत आसान-से-एनोटेट कार्यों के लिए गुणवत्ता डेटा खोजने की कठिनाइयों पर चर्चा करते हैं, जैसे कि भावना विश्लेषण। फिर, हम पूर्व-प्रशिक्षित भाषा मॉडल सहित तंत्रिका मॉडल के एक सेट को प्रशिक्षित करते हैं, और यह पता लगाते हैं कि क्या वे इस कम संसाधन सेटअप में पारंपरिक मशीन लर्निंग की तुलना में बेहतर प्रदर्शन करते हैं। ट्रांसफॉर्मर आर्किटेक्चर पूर्व-प्रशिक्षण के दौरान ग्वारानी पर विचार नहीं करने के बावजूद सबसे अच्छे परिणाम प्राप्त करते हैं, लेकिन पारंपरिक मशीन लर्निंग मॉडल समस्या की कम-संसाधन प्रकृति के कारण करीब प्रदर्शन करते हैं।', 'ru': 'В этой статье рассматривается проблема анализа настроений для Jopara, языка, переключающего код между гуарани и испанским. Сначала мы собираем корпус доминирующих в Гуарани твитов и обсуждаем трудности поиска качественных данных даже для относительно простых задач, таких как анализ настроений. Затем мы обучаем набор нейронных моделей, включая предварительно обученные языковые модели, и исследуем, насколько они лучше, чем традиционные модели машинного обучения в этой малоресурсной конфигурации. Архитектуры трансформаторов получают наилучшие результаты, несмотря на то, что не учитывают Guarani во время предварительного обучения, но традиционные модели машинного обучения работают близко из-за низкой ресурсной природы проблемы.', 'ga': 'Tugann an páipéar seo aghaidh ar fhadhb na hanailíse meoin do Jopara, teanga a aistríonn cód idir Guaráinis agus an Spáinnis. Bailímid ar dtús corpas de thvuíteanna ceannasacha Guaráinis agus pléimid na deacrachtaí a bhaineann le sonraí ardchaighdeáin a aimsiú le haghaidh tascanna fiú a bhfuil anótáil sách éasca orthu, amhail anailís meoin. Ansin, cuirimid oiliúint ar thacar de mhúnlaí néaracha, lena n-áirítear múnlaí teanga réamhoilte, agus déanaimid iniúchadh ar cibé an bhfeidhmíonn siad níos fearr ná na cinn mheaisínfhoghlama traidisiúnta sa socrú seo a bhfuil acmhainní ísle ann. Faigheann ailtireachtaí claochladáin na torthaí is fearr, in ainneoin nach bhfuil siad ag smaoineamh ar an Guaráinis le linn na réamh-oiliúna, ach tá dlúthbhaint ag samhlacha meaisínfhoghlama traidisiúnta mar gheall ar nádúr íseal acmhainní na faidhbe.', 'ka': 'ეს დუპანის და სპანელის შორის კოდის გადაცვლილების პრობლემა ექსპერაში. ჩვენ პირველად დარანი-დომინტების კოპპოსს შეიყვანეთ და განსაკუთრებეთ კალგატიური მონაცემების შესაძლებლობაზე, როგორც სენტიმენტების ანალიზაციისთვის მარტივი ადვილ დანატანტირებული შემდეგ ჩვენ ნეიროლური მოდელების ნაწილის შესწავლეთ, რომელიც წინ შესწავლეთ ენის მოდელები, და განსწავლეთ თუ ისინი უკეთესი მაქსინური სწავლების შესაძლებლობაზე უკეთ ტრანფორმაციური არქტიქტურები მიიღებენ ყველაზე საუკეთესო შედეგი, მაგრამ საუკეთესო განსწავლების განმავლობაში, მაგრამ ტრადიციონალური მაქანის მოდელები გავაკეთებენ პრო', 'hu': 'Ez a tanulmány foglalkozik a Jopara érzelmek elemzésének problémájával, amely egy kódváltó nyelv Guarani és Spanyol között. Először összegyűjtünk egy korpuszt Guarani domináns tweetekből, és megbeszéljük a minőségi adatok megtalálásának nehézségeit még viszonylag könnyen jegyzetelhető feladatokhoz is, mint például az érzelmek elemzése. Ezután egy sor idegi modellt képezünk, beleértve az előre képzett nyelvi modelleket, és megvizsgáljuk, hogy jobban teljesítenek-e, mint a hagyományos gépi tanulási modellek ebben az alacsony erőforrású beállításban. A transzformátor architektúrák a legjobb eredményeket kapják, annak ellenére, hogy nem veszik figyelembe a guarani-t az előképzés során, de a hagyományos gépi tanulási modellek közel teljesítenek a probléma alacsony erőforrású jellege miatt.', 'it': "Questo articolo affronta il problema dell'analisi del sentiment per Jopara, un linguaggio di scambio di codice tra guarani e spagnolo. Per prima cosa raccogliamo un corpus di tweet a predominanza guarani e discutiamo sulle difficoltà di trovare dati di qualità anche per compiti relativamente facili da annotare, come l'analisi del sentiment. Quindi, addestriamo una serie di modelli neurali, inclusi modelli linguistici pre-addestrati, ed esploriamo se funzionano meglio di quelli tradizionali di apprendimento automatico in questa configurazione a basso contenuto di risorse. Le architetture dei trasformatori ottengono i migliori risultati, nonostante non si considerino Guarani durante il pre-training, ma i modelli tradizionali di machine learning funzionano vicino a causa della natura a basso contenuto di risorse del problema.", 'el': 'Η παρούσα εργασία ασχολείται με το πρόβλημα της ανάλυσης συναισθημάτων για την Jopara, μια γλώσσα αλλαγής κώδικα μεταξύ Γκουαράνι και Ισπανικών. Αρχικά συλλέγουμε ένα σωρό tweets που κυριαρχούν στο Γκουαράνι και συζητάμε για τις δυσκολίες εύρεσης ποιοτικών δεδομένων για ακόμη και σχετικά εύκολα σχολιαστικά καθήκοντα, όπως η ανάλυση συναισθημάτων. Στη συνέχεια, εκπαιδεύουμε ένα σύνολο νευρωνικών μοντέλων, συμπεριλαμβανομένων των προ-εκπαιδευμένων γλωσσικών μοντέλων, και διερευνούμε αν αποδίδουν καλύτερα από τα παραδοσιακά μοντέλα μηχανικής μάθησης σε αυτή τη ρύθμιση χαμηλού πόρων. Οι αρχιτεκτονικές μετασχηματιστών επιτυγχάνουν τα καλύτερα αποτελέσματα, παρά το γεγονός ότι δεν λαμβάνονται υπόψη οι Γκουαράνι κατά την προεκπαίδευση, αλλά τα παραδοσιακά μοντέλα μηχανικής μάθησης λειτουργούν στενά λόγω της χαμηλής περιεκτικότητας σε πόρους φύσης του προβλήματος.', 'mk': 'Овој весник го решава проблемот на анализата на чувствата за Јопара, јазик на промена на кодови помеѓу Гуарани и Шпански. Прво собираме корпус на твитови кои доминираат од Гварани и разговараме за тешкотиите во пронаоѓањето на квалитетни податоци дури и за релативно лесни задачи, како што е анализата на чувствата. Then, we train a set of neural models, including pre-trained language models, and explore whether they perform better than traditional machine learning ones in this low-resource setup.  Трансформираните архитектури ги добиваат најдобрите резултати, и покрај тоа што не се разгледува Гварани за време на предобуката, но традиционалните модели на машинско учење работат блиску поради ниската природа на ресурсите на проблемот.', 'lt': 'Šiame dokumente nagrinėjama jausmų analizės problem a Jopara, kodų keitimo kalba tarp guaranų ir ispanų. We first collect a corpus of Guarani-dominant tweets and discuss on the difficulties of finding quality data for even relatively easy-to-annotate tasks, such as sentiment analysis.  Then, we train a set of neural models, including pre-trained language models, and explore whether they perform better than traditional machine learning ones in this low-resource setup.  Transformuojančios architektūros gauna geriausius rezultatus, nepaisant to, kad rengiant mokymą Guarani nebuvo svarstoma, tačiau tradiciniai mašinų mokymosi modeliai veikia artimai dėl mažo problemos išteklių pobūdžio.', 'kk': 'Бұл қағаз Джопара - Гуарани мен Испан арасындағы код ауыстыру тілінің сезімдік анализиясының мәселесін көрсетеді. Біз біріншіден Гуарани доминирантты tweets корпусын жинап, сезімді анализ секілді сапатты деректерді табу мәселелері туралы талқылаймыз. Содан кейін біз невралдық моделдерді ұстап, алдын- оқылған тіл моделдерін қоса, және олар әдеттегі машинаның оқытуынан жақсы жұмыс істеу үшін осы төменгі ресурстардың баптауларында тұрады. Трансформациялық архитектуралар алдындағы Гуарани оқыту кезінде ең жақсы нәтижелерін алады, бірақ әдеттегі машина оқыту үлгілері мәселедің төмен ресурстардың қасиетінен жақын болады.', 'ml': 'ഈ പത്രത്തില്\u200d ജോപ്പറയ്ക്ക് വേണ്ടിയുള്ള അന്വേഷണത്തിന്റെ പ്രശ്നം വിശദീകരിക്കുന്നു. ഗുവാറാനിയും സ്പാനിഷും തമ് നമ്മള്\u200d ആദ്യം ഗുവാറാനിയുടെ മേല്\u200dനോട്ട് ടൂട്ടുകളിലെ ഒരു കോര്\u200dപ്പസ് സംഘടിപ്പിക്കുകയും ചെയ്യുന്നു. വിചാരപ്രശ്നങ്ങള്\u200dക്ക് വേണ്ടി സാധ പിന്നെ നമ്മള്\u200d ഒരു കൂട്ടം ന്യൂറല്\u200d മോഡലുകളെ പരിശീലിപ്പിക്കുന്നു, മുന്\u200dപരിശീലിക്കപ്പെട്ട ഭാഷ മോഡലുകള്\u200d ഉള്\u200dപ്പെടുത്തുന്നു, ഈ കുറഞ Transformer architectures obtain the best results, despite not considering Guarani during pre-training, but traditional machine learning models perform close due to the low-resource nature of the problem.', 'mt': 'Dan id-dokument jindirizza l-problem a tal-analiżi tas-sentimenti għal Jopara, lingwa ta’ skambju ta’ kodiċijiet bejn il-Guarani u l-Ispanjol. L-ewwel niġbru korpus ta’ tweets dominanti fil-Guarani u niddiskutu dwar id-diffikultajiet biex jinstabu dejta ta’ kwalità anki għal kompiti relattivament faċli li jiġu annotati, bħall-analiżi tas-sentimenti. Then, we train a set of neural models, including pre-trained language models, and explore whether they perform better than traditional machine learning ones in this low-resource setup.  Transformer architectures obtain the best results, despite not considering Guarani during pre-training, but traditional machine learning models perform close due to the low-resource nature of the problem.', 'pl': 'Niniejszy artykuł porusza problem analizy sentymentów dla Jopara, języka przełączającego kod między guarani a hiszpańskim. Najpierw zbieramy korpus tweetów dominujących Guarani i omawiamy trudności w znalezieniu wysokiej jakości danych nawet do stosunkowo łatwych do adnotacji zadań, takich jak analiza sentymentów. Następnie trenujemy zestaw modeli neuronowych, w tym wstępnie przeszkolonych modeli językowych i zbadamy, czy działają lepiej niż tradycyjne modele uczenia maszynowego w tej niskiej ilości zasobów konfiguracji. Architektury transformatorów uzyskują najlepsze rezultaty, pomimo braku pod uwagę Guaraniego podczas szkolenia przedszkoleniowego, ale tradycyjne modele uczenia maszynowego działają blisko ze względu na niski charakter zasobów problemu.', 'ms': 'This paper addresses the problem of sentiment analysis for Jopara, a code-switching language between Guarani and Spanish.  Kami pertama-tama mengumpulkan sebuah korpus tweet dominan Guarani dan membincangkan tentang kesulitan mencari data kualiti walaupun tugas yang relatif mudah untuk dicatat, seperti analisis perasaan. Kemudian, kita melatih satu set model saraf, termasuk model bahasa terlatih-terlatih, dan mengeksplorasi sama ada mereka berjalan lebih baik daripada mesin belajar tradisional dalam seting sumber rendah ini. Arkitektur Transformer mendapat hasil terbaik, walaupun tidak mempertimbangkan Guarani semasa latihan awal, tetapi model belajar mesin tradisional berjalan dekat kerana sifat sumber rendah masalah.', 'ro': 'Această lucrare abordează problema analizei sentimentelor pentru Jopara, o limbă de schimbare a codului între guarani și spaniolă. Mai întâi colectăm un corpus de tweet-uri dominante guarani și discutăm despre dificultățile de a găsi date de calitate chiar și pentru sarcini relativ ușor de adnotat, cum ar fi analiza sentimentului. Apoi, vom instrui un set de modele neuronale, inclusiv modele lingvistice pre-instruite, și vom explora dacă acestea funcționează mai bine decât cele tradiționale de învățare automată în această configurație cu resurse reduse. Arhitecturile transformatorului obțin cele mai bune rezultate, în ciuda faptului că nu au luat în considerare Guarani în timpul pregătirii, dar modelele tradiționale de învățare automată funcționează aproape datorită naturii reduse a resurselor problemei.', 'sr': 'Ovaj papir rješava problem analize sentiment a za Jopara, prebacivanje koda između Guaranija i Španjolskog jezika. Prvo sakupljamo korpus Guarani-dominantnih tweeta i razgovaramo o teškocama pronalaženja kvalitetnih podataka za čak i relativno lako annotiranje zadataka, poput analize sentiment a. Onda treniramo niz neuralnih modela, uključujući predobučene jezičke modele, i istražujemo da li izvode bolje od tradicionalnog učenja mašine u ovom nastavku sa niskim resursima. Transformerske arhitekture dobijaju najbolje rezultate, uprkos ne razmišljanju o Guarani tokom predobuke, ali tradicionalni modeli učenja mašine izvode blizu zbog prirode niskog resursa problema.', 'no': 'Denne papiret adresserer problemet med sentimentanalysen for Jopara, eit språk som byter kodar mellom Guarani og spansk. Vi samler først eit korpus av Guarani-dominantne tweeter og diskuterer om vanskelighetane for å finna kvalitetsdata for enda relativt enkle å merke oppgåver, som sentimentanalyser. Så treng vi eit sett av neuralmodeller, inkludert før- trengte språk- modeller, og utforsk om dei utfører bedre enn tradisjonelle maskinelæring i denne låg ressursoppsettet. Transformeringsarkitekturar får dei beste resultatene, selv om ikkje tenkt på Guarani under føreøving, men tradisjonelle maskinelæringsmodeller utfører nærare på grunn av det låg ressursnaturen av problemet.', 'so': 'This paper addresses the problem of sentiment analysis for Jopara, a code-switching language between Guarani and Spanish.  Marka ugu horeysa waxaynu soo ururinnaa weelasho uu ku qoray Guarani-maamul, waxaana ka sheekeysanaynaa dhibaatooyin ku saabsan helitaanka macluumaadka qiimaha ah, xataa hawlaha aad u fudud karto, tusaale ahaan baaritaanka fikrada. Markaas waxaynu tababarinnaa tusaalo neurada ah, kuwaas oo ku jira tusaalooyin afka hore lagu tababaray, waxaana baarinaynaa in ay sameeyaan wax ka wanaagsan waxbarashada maskaxda caadiga ah oo ku qoran kooxdan hoose-nololeed. Arkadaha bedelka ah waxay helaan midhaha ugu wanaagsan, inkastoo aan ka fiirsanayn Guarani xiliga waxbarashada ka horraysa, laakiin qaababka waxbarashada ee asalka ah waxay sameynayaan inay ku dhowaadaan dabiicadda dhibaatada hoose-dhexe.', 'sv': 'Denna uppsats behandlar problemet med sentimentalanalys för Jopara, ett kodbytesspråk mellan guarani och spanska. Vi samlar först in en korpus guarani-dominerande tweets och diskuterar svårigheterna att hitta kvalitetsdata för även relativt lättkommenterade uppgifter, såsom sentimentalanalys. Sedan tränar vi en uppsättning neurala modeller, inklusive förintränade språkmodeller, och undersöker om de presterar bättre än traditionella maskininlärningsmodeller i denna lågresursinställning. Transformararkitekturer får de bästa resultaten, trots att man inte överväger Guarani under pre-training, men traditionella maskininlärningsmodeller presterar nära på grund av problemets låga resurskaraktär.', 'ta': 'இந்த தாள் ஜோபாராவிற்கான உணர்வு ஆய்வு பிரச்சனையை குறிக்கும், குவாரானி மற்றும் ஸ்பானிஷ் இடையே ஒரு குறியீடு ம We first collect a corpus of Guarani-dominant tweets and discuss on the difficulties of finding quality data for even relatively easy-to-annotate tasks, such as sentiment analysis.  பின்னர், நாம் முன்பயிற்சி மொழி மாதிரிகளைச் சேர்த்து ஒரு சில புதிய மாதிரிகளை பயிற்சி செய்கிறோம், மற்றும் இந்த குறைந்த மூலத்தின்  மாற்று அமைப்புகள் சிறந்த முடிவுகள் பெறுகிறது, முன் பயிற்சியில் குவாரானியை பார்க்காமலும் இருந்தாலும், ஆனால் மரபார்ந்த இயந்திரம் கற்', 'si': 'මේ පැත්තේ ජෝපාරානි සහ ස්පැනිස් අතර ප්\u200dරශ්න විශ්ලේෂණයේ ප්\u200dරශ්නයක් ලැබෙනවා. අපි මුලින්ම ගුරානී ප්\u200dරධානිය ට්විට් වලින් කොර්පස් එකක් එකතු කරනවා සහ සාමාන්\u200dය විශ්ලේෂණ විශ්ලේෂණය සඳහා ප්\u200dරශ්ණත දත්ත හොයාග ඊට පස්සේ, අපි ප්\u200dරධාන භාෂා මොඩේල් එකක් ප්\u200dරධානය කරනවා, ප්\u200dරධාන භාෂා මොඩේල් එකක් තියෙනවා, ඒ වගේම ඔවුන් ප්\u200dරධානික ප්\u200dරවේශකය විද්\u200dයාපකය විද්\u200dයාපකයේ හොඳම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති', 'mn': 'Энэ цаас Гуарани болон Испанийн хоорондын мэдрэмжтэй шинжилгээний асуудлыг харуулдаг. Эхлээд бид Гуарани давамгайлагч tweets-ын корпус цуглуулж, сэтгэл санааны шинжилгээ шинжилгээний тухай харьцангуй амархан ажлыг олох хэцүү хэцүү талаар ярилцдаг. Дараа нь бид мэдрэлийн загваруудыг суралцаж, өмнө сургалтын хэл загваруудыг нэмж, уламжлалтай машины суралцах үйлдвэрлэлээс илүү сайн эсэхийг судалж байна. Архитектурууд Гуарани урд сургалтын үед хамгийн сайн үр дүнг авдаг. Гуарани урд сургалтын үед бодохгүй ч уламжлалт машин сургалтын загварууд асуудлын бага бага баялаг байгалийн шалтгаан ойртох бол', 'ur': 'یہ کاغذ جوپار کے لئے احساسات تحلیل کے مسئلہ کے بارے میں تحقیق کرتا ہے، Guarani اور اسپانیایی کے درمیان کوڈ-سوچ کی زبان. ہم پہلی بار Guarani-dominant tweets کے ایک کورپوس جمع کریں گے اور اس کے بارے میں مشکلات کے بارے میں بحث کریں گے جیسے احساسات تحلیل کے مطابق بہت آسان کاموں کے لئے۔ پھر ہم ایک مجموعہ نیورال موڈل کی تعلیم دیتے ہیں، اس سے پہلے تعلیم کی زبان موڈل کے شامل، اور دیکھتے ہیں کہ یہ اس کم منبع سٹ میں سیکھنے والوں سے بہتر کام کرتے ہیں یا نہیں. تبدیل کرنے والے معماری بہترین نتائج حاصل کرتے ہیں، اگرچہ گوارانی کو پیش آموزش میں غور نہ کرنا چاہے، لیکن سنتی ماشین تعلیم مدلکوں مشکل کے کم منبع کی وجہ سے نزدیک عمل کرتے ہیں.', 'uz': "Bu qogʻoz Guarani va Ispanchadan oʻzgartirish uchun Jopara hissiyalarning muammolarini anglatadi. Birinchi marta Guarani boshqaruvchi Twitterlarining qutisini olib tashlamiz va o'z hissiyotni analyzer kabi juda sodda bo'lgan vazifalarni topish muammolari haqida javob beramiz. Keyin biz bir necha modellarni o'rganamiz, oldin o'rganilgan tillar modellari bilan o'rganamiz, va ular qanday o'rganishni o'rganishdan yaxshi ko'proq o'rganishni anglatamiz. Tashqi maktablarda Guarani o'rganishda o'rganish kerak bo'lgan eng yaxshi natijalar olib keladi, balki taʼminlovchi mashina o'rganish modellari muammolarning dunyoviy manba asosida yopiladi.", 'vi': 'Tờ giấy này đề cập đến vấn đề phân tích tình cảm của Jopara, một ngôn ngữ chuyển đổi mã giữa Guarani và Tây Ban Nha. Trước tiên chúng ta thu thập cả một tập nhỏ những dòng tweet thống trị, và thảo luận về những khó khăn trong việc tìm kiếm dữ liệu chất lượng cho các nhiệm vụ cũng rất dễ ghi âm, như phân tích cảm xúc. Sau đó, chúng tôi huấn luyện một loạt các mô hình thần kinh, bao gồm các mô hình ngôn ngữ được đào tạo trước, và tìm hiểu liệu chúng có làm tốt hơn những mô hình máy truyền thống trong thiết lập ít tài nguyên này không. Các kiến trúc transformer đạt được kết quả tốt nhất, mặc dù không cân nhắc Guarani trong suốt buổi huấn luyện, nhưng các mô hình cổ máy truyền đạt được kết quả gần gũi vì tính chất ít tài nguyên của vấn đề.', 'bg': 'Настоящата статия разглежда проблема с анализа на сентимента за Йопара, език за превключване на кодове между гуарани и испански. Първо събираме корпус от гуарани доминиращи туитове и обсъждаме трудностите при намирането на качествени данни дори за сравнително лесни за анотиране задачи, като например анализ на сентимента. След това тренираме набор от невронни модели, включително предварително обучени езикови модели, и изследваме дали те се представят по-добре от традиционните модели за машинно обучение в тази настройка с ниски ресурси. Трансформаторните архитектури получават най-добри резултати, въпреки че не се вземат предвид Гуарани по време на предварителното обучение, но традиционните модели на машинно обучение се представят близко поради ниския ресурсен характер на проблема.', 'nl': 'Dit artikel behandelt het probleem van sentimentanalyse voor Jopara, een code-switching taal tussen Guarani en Spaans. We verzamelen eerst een corpus Guarani-dominante tweets en bespreken de moeilijkheden om kwaliteitsdata te vinden voor zelfs relatief gemakkelijk te annoteren taken, zoals sentimentanalyse. Vervolgens trainen we een reeks neurale modellen, inclusief vooraf getrainde taalmodellen, en onderzoeken we of ze beter presteren dan traditionele machine learning modellen in deze low-resource setup. Transformatorarchitecturen behalen de beste resultaten, ondanks dat Guarani tijdens de pre-training niet in aanmerking wordt genomen, maar traditionele machine learning modellen presteren dicht vanwege de lage resource aard van het probleem.', 'hr': 'Ovaj papir rješava problem analize osjećaja za Jopara, jezik za zamjenu koda između Guaranija i Španjolskog. Prvo sakupljamo korpus Guarani-dominantnih tweets i razgovaramo o teškoćama pronalaženja kvalitetnih podataka za čak i relativno lako annotiranje zadataka, poput analize osjećaja. Onda treniramo niz neuralnih modela, uključujući predobučene jezičke modele, i istražujemo da li izvode bolje od tradicionalnog učenja strojeva u ovom nastavku s niskim resursima. Arhitekture transformera dobijaju najbolje rezultate, uprkos ne razmišljanju o Guarani tijekom predobuke, ali tradicionalni modeli učenja strojeva izvode blizu zbog prirode niskog resursa problema.', 'da': 'Denne artikel omhandler problemet med sentimentalanalyse for Jopara, et kodeskift sprog mellem guarani og spansk. Vi indsamler først et korpus af guarani-dominerende tweets og diskuterer vanskelighederne med at finde kvalitetsdata til selv relativt nemme at annotere opgaver, såsom sentiment analyse. Derefter træner vi et sæt neurale modeller, herunder prætrænede sprogmodeller, og undersøger, om de fungerer bedre end traditionelle maskinlæringsmodeller i denne lave ressourceopsætning. Transformer arkitekturer opnår de bedste resultater, selvom de ikke overvejer Guarani under før træning, men traditionelle maskinlæringsmodeller klarer sig tæt på grund af problemets lave ressourcer.', 'de': 'Diese Arbeit befasst sich mit dem Problem der Stimmungsanalyse für Jopara, eine Code-Switching-Sprache zwischen Guarani und Spanisch. Zunächst sammeln wir einen Korpus Guarani-dominierter Tweets und diskutieren über die Schwierigkeiten, qualitativ hochwertige Daten auch für relativ einfach zu kommentierende Aufgaben wie Stimmungsanalyse zu finden. Anschließend trainieren wir eine Reihe neuronaler Modelle, einschließlich vortrainierter Sprachmodelle, und untersuchen, ob sie in diesem ressourcenarmen Setup besser abschneiden als traditionelle maschinelle Lernmodelle. Transformatorarchitekturen erzielen die besten Ergebnisse, obwohl Guarani während des Vortrainings nicht berücksichtigt wird, aber traditionelle Modelle für maschinelles Lernen funktionieren aufgrund des geringen Ressourcenbedarfs des Problems eng.', 'id': 'Kertas ini mengatasi masalah analisis sentimen untuk Jopara, sebuah bahasa penggantian kode antara Guarani dan Spanyol. Kami pertama-tama mengumpulkan sebuah korpus tweet dominan Guarani dan mendiskusikan tentang kesulitan menemukan data kualitas bahkan untuk tugas relatif mudah-untuk-anotasi, seperti analisis sentimen. Then, we train a set of neural models, including pre-trained language models, and explore whether they perform better than traditional machine learning ones in this low-resource setup.  Arkitektur Transformer mendapatkan hasil terbaik, meskipun tidak mempertimbangkan Guarani selama prapelatihan, tetapi model belajar mesin tradisional bekerja dekat karena alami sumber daya rendah masalah.', 'sw': 'Gazeti hili linazungumzia tatizo la uchambuzi wa hisia kwa Jopara, lugha yenye kubadili kwa utaratibu kati ya Guarani na Kihispania. Kwanza tunakusanya makampuni ya twiti zinazotawala Guarani na kujadili kuhusu matatizo ya kutafuta takwimu za ubora kwa hata kazi rahisi na kutangaza, kama uchambuzi wa hisia. Kisha, tunafundisha mfululizo wa mifano ya neurali, ikiwa ni pamoja na mifano ya lugha zilizofunzwa kabla, na kutambua kama wanafanya vizuri zaidi ya mashine ya kitamaduni katika taasisi hii ya rasilimali duni. Mazinduzi ya zamani yanapata matokeo mazuri, ingawa hawajadili Guarani wakati wa mafunzo ya kabla, lakini miundo mbinu ya kujifunza za kitamaduni hufanya kazi kwa sababu ya asili ya rasilimali duni ya tatizo hilo.', 'fa': 'این کاغذ مشکل تحلیل احساسات برای جوپار، یک زبان تغییر کد بین گوارانی و اسپانیایی را دریافت می\u200cکند. ما اول یک کورپوس از tweets dominant Guarani را جمع می\u200cکنیم و در مورد مشکلات پیدا کردن داده\u200cهای کیفیت برای حتی وظیفه\u200cهای نسبتا آسان برای آشنا کردن، مثل تحلیل احساسات بحث می\u200cکنیم. سپس، ما یک مجموعه مدل عصبی را آموزش می\u200cکنیم، شامل مدل\u200cهای زبان پیش آموزش داده شده، و تحقیق می\u200cکنیم آیا آنها بهتر از مدل\u200cهای آموزش ماشین سنتی در این تنظیم منابع کم انجام می\u200cدهند. معماری تغییر دهنده بهترین نتیجه\u200cها را دریافت می\u200cکند، با وجود اینکه در طول آموزش پیش از آموزش Guarani فکر نکنند، ولی مدل یادگیری ماشین سنتی به دلیل طبیعت کم منابع مشکل نزدیک می\u200cشوند.', 'ko': '본고는 과라니어와 스페인어 사이의 코드 변환 언어인 조파라의 감정 분석 문제를 논의했다.우리는 먼저 과라니어가 주도적인 위치를 차지하는 추문 자료 라이브러리를 수집하고 상대적으로 주석하기 쉬운 임무(예를 들어 정서분석)를 위해 고품질 데이터를 찾는 어려움을 논의했다.그 다음에 우리는 예비 훈련된 언어 모델을 포함한 신경 모델을 훈련시키고 이런 저자원 설정에서 전통적인 기계 학습 모델보다 더 잘 표현되는지 탐색한다.비록 예비 교육 기간에 Guarani를 고려하지 않았지만 Transformer 구조는 여전히 최상의 결과를 얻을 수 있지만 문제의 저자원 성격 때문에 전통적인 기계 학습 모델의 성능은 매우 가깝다.', 'tr': 'Bu kagyz Jopara üçin duýgular analyzasynyň meselesini çözýär, Guarani ň we Ispanýularyň arasynda köd almak üçin. Biz ilkinji gezek Guarani ň dominiýan tweetleriniň korpusyny ýygnaýarys we duýgular analizi ýaly görnüş taýýarlamak üçin kynçylyklyk maglumatyny tapmak kynçylyklaryň bardygyny düşünýäris. Soňra, biz bir topar neural modellerini öwredýäris, öňünden öňünden öňünden öňünden gelen dil modellerini we bu ýokary resurslarda däpli işleýän maşynyň öwrenmelerinden has gowydygyny çözýäris. Guraniň öň-okuwçylyk wagtynda üýtgetmeli arhitektarlar has gowy netijeleri aldylar, ýöne däpli maşynyň öwrenmek nusgalary meseläň iň az resursy sebäpli ýakyn çykýar.', 'af': "Hierdie papier adreseer die probleem van sentimentanalisie vir Jopara, 'n kode-skakeling taal tussen Guarani en Spaanse. Ons versamel eerste 'n korpus van Guarani-dominante tweets en bespreek oor die moeilikhede van die kry van kwaliteit data vir selfs relativief maklik-to-annotateer opdragte, soos sentimentanalisie. Dan tref ons 'n stel neurale modele, insluitend voor-opgelei taal modele, en ondersoek of hulle beter as tradisionele masjien leer wat in hierdie lae-hulpbron opstelling doen. Transformeerder-arkitekturke kry die beste resultate, veral Guarani nie onderwerp tydens voor-onderwerp nie, maar tradisionele masjien leer-modele uitvoer naby vanweë die lae-hulpbron-natuur van die probleem nie.", 'am': 'ይህ ገጽ የጆፓራን እና ስፓኒሽ መካከል የቆዳ ቋንቋ የሚለውጥ የኢዮፓራ ስህተት መተርጓሚዎችን የሚያሳውቅ ጉዳይ ነው፡፡ መጀመሪያ የጋራኒ አዳራቢ ትዊተሮችን አሰብሰብን እና እንደተማያየት አስተያየት እና የጥሩ ዳታዎችን ለማግኘት በሚያስቸገር ነገር ላይ እናዋርዳለን፡፡ ከዚያም በፊት ተማሪ የቋንቋ ምሳሌዎችን እናስተምረዋለን፡፡ በዚህ ከዘላለም ሀብት ትምህርት ትምህርት ትምህርት የሚሻሉትን እናስተምር፡፡ ትርጉም የመሠረተኞቹ መሠረት ፍሬዎች ከመልካም ፍሬዎች ያገኛሉ፤ ምንም እንኳ ጉዳዩ በፊት ተማሪ ሳይሆን፣ የባሕላዊ መሣሪያው ማስተማር ሞዴል ግን የችግር ክፍተት ውስጥነት ከታናሽ ክፍል የተነሣ ይቆያል፡፡', 'bn': 'এই পত্রিকা জোপারার জন্য আবেগ বিশ্লেষণের সমস্যার কথা বলেছে, গুয়ারানি এবং স্প্যানিশের মধ্যে একটি কোড-পরিবর্তন ভাষায়। আমরা প্রথমে গুয়ারানি ক্ষমতাশালী টুইটের একটি কোর্পাস সংগ্রহ করি এবং মানের তথ্য খুঁজে বের করার ব্যাপারে আলোচনা করি, যেমন আবেগ বিশ্লেষণ। তারপর আমরা নিউরেল মডেল প্রশিক্ষণ দেই, যার মধ্যে প্রাক্তন প্রশিক্ষিত ভাষার মডেল রয়েছে এবং দেখা যাচ্ছি যে তারা এই কম সম্পদ ব্যবস্থায় ঐতিহ্যবাহী  পূর্ব প্রশিক্ষণের সময় গুয়ারানিকে বিবেচনা করা সত্ত্বেও অনুবাদ করা সেরা ফলাফল পেয়েছে, কিন্তু ঐতিহ্যবাহী মেশিন শিক্ষা মডেল সমস্যার কম সম্পদের প্', 'az': 'Bu kağıt Jopara üçün sentiment analizinin problemini çəkir, Guarani və İspanyol arasında kodu dəyişən dili. Biz ilk dəfə Guarani-dominantlı tweetlərin korpusu toplayırıq və hiss analizi kimi hisslərin çətinliklərini tapmaq çətinliklərində mübahisə edirik. Sonra, öyrənmiş dil modelləri də birlikdə nöral modelləri təhsil edirik və bu düşük ressurs qurulmasından daha yaxşı maşın öyrəndiklərini təhsil edirik. Transformer arhitektarları daha yaxşı sonuçları alırlar, Guarani əvvəl təhsil sırasında düşünməsə də, lakin əvvəlki maşın öyrənməsi modelləri problemin düşük ressurs təhsilinə görə yaxınlaşırlar.', 'bs': 'Ovaj papir rješava problem analize sentiment a za Jopara, jezik za zamjenu koda između Guaranija i Španjolskog. Prvo sakupljamo korpus Guaranijskih tviteta i razgovaramo o teškocama pronalaženja kvalitetnih podataka za čak i relativno lako annotiranje zadataka, poput analize osjećaja. Onda treniramo niz neuralnih modela, uključujući predobučene jezičke modele, i istražujemo da li izvode bolje od tradicionalnog učenja strojeva u ovom nastavku s niskim resursima. Transformerske arhitekture dobijaju najbolje rezultate, uprkos ne razmatranju Guarani tijekom predobuke, ali tradicionalni modeli učenja mašina izvode blizu zbog prirode niskog resursa problema.', 'ca': "Aquest article aborda el problem a de l'anàlisi de sentiments per a Jopara, una llengua de canvi de codi entre guarani i espanyol. Primer recollim un cos de tweets dominants en Guarani i discutem sobre les dificultats de trobar dades de qualitat fins i tot per a tasques relativament fàcils d'anotar, com l'anàlisi del sentiment. Després, entrenem un conjunt de models neurals, incloent models de llenguatge pré-entrenats, i explorem si es produeixen millor que els tradicionals d'aprenentatge màquinari en aquesta configuració de baix recursos. Les arquitectures transformades aconsegueixen els millors resultats, malgrat que no considerin Guarani durant la pré-capacitació, però els models tradicionals d'aprenentatge màquinari actuen pròximament degut a la baixa naturalesa de recursos del problema.", 'et': 'Käesolev töö käsitleb sentimentaalse analüüsi probleemi Jopara, koodivahetuskeel guarani ja hispaania vahel. Kõigepealt kogume guarani domineerivate säutsude korpuse ja arutleme raskustest leida kvaliteetseid andmeid isegi suhteliselt lihtsalt märgitavate ülesannete jaoks, näiteks sentimentaalüüsi jaoks. Seejärel treenime närvimudeleid, sealhulgas eelõpetatud keelemudeleid, ja uurime, kas need toimivad paremini kui traditsioonilised masinõppe mudelid selles vähese ressursiga seadistuses. Transformerite arhitektuurid saavutavad parimad tulemused, hoolimata sellest, et Guarani eelkoolituse ajal ei kaalu, kuid traditsioonilised masinõppemudelid toimivad lähedal probleemi vähese ressursi tõttu.', 'cs': 'Tento článek se zabývá problematikou analýzy sentimentů pro Jopara, jazyk přepínající kód mezi guaraní a španělštinou. Nejprve shromažďujeme korpus guarani dominantních tweetů a diskutujeme o obtížích hledání kvalitních dat i pro relativně snadno anotovatelné úkoly, jako je analýza sentimentů. Poté trénujeme sadu neuronových modelů, včetně předškolených jazykových modelů, a zkoumáme, zda v tomto nastavení s nízkými zdroji vykonávají lepší výkon než tradiční strojové učení. Architektury transformátorů dosahují nejlepších výsledků, i když během předškolení nezvažují Guaraniho, ale tradiční modely strojového učení fungují blízko vzhledem k nízké povaze problému.', 'sq': 'Ky dokument trajton problemin e analizës së ndjenjave për Jopara, një gjuhë ndërrimi kodesh midis guaranit dhe spanjollit. Ne së pari mbledhim një korpus tweets dominues nga Guarani dhe diskutojmë mbi vështirësitë e gjetjes së të dhënave të cilësisë edhe për detyra relativisht të lehta për të anotuar, të tilla si analiza e ndjenjave. Pastaj, ne trajnojmë një sërë modelesh neuronale, duke përfshirë modele gjuhësh të paratrajnuar, dhe eksplorojmë nëse ato funksionojnë më mirë se ato tradicionale që mësojnë makinat në këtë sistem me burime të ulëta. Arkitekturat e transformuara arrijnë rezultatet më të mira, pavarësisht se nuk konsiderojnë Guaranin gjatë parastërvitjes, por modelet tradicionale të mësimit të makinave funksionojnë afër për shkak të natyrës së ulët të burimeve të problemit.', 'hy': 'Այս աշխատանքը լուծում է Ջոպարայի զգացմունքների վերլուծության խնդիրը, գվարանի և իսպաներենի միջև կոդի փոխելու լեզուն: Սկզբում մենք հավաքում ենք Գվարանիի գերիշխող թվիթերի մի կորպուս և քննարկում ենք որակային տվյալներ գտնելու դժվարությունների մասին նույնիսկ համեմատաբար հեշտ նշում անելու խնդիրների համար, ինչպիսիք են զգացմունքների վերլուծությունը: Then, we train a set of neural models, including pre-trained language models, and explore whether they perform better than traditional machine learning ones in this low-resource setup.  Փոփոխակերպված ճարտարապետությունները ստանում են լավագույն արդյունքները, չնայած, որ նախապատրաստման ժամանակ Գվարանին չեն հաշվի առնում, բայց ավանդական մեքենային ուսումնասիրության մոդելները շատ լավ են աշխատում խնդրի ցածր ռեսուրսների', 'fi': 'Tämä artikkeli käsittelee tunneanalyysin ongelmaa Joparalle, koodinvaihtokielelle guaranin ja espanjan välillä. Keräämme ensin korpusen guarani-dominantteja twiittejä ja keskustelemme siitä, miten vaikeaa on löytää laadukasta dataa jopa suhteellisen helppoon muistiinpanoon, kuten tunteiden analysointiin. Tämän jälkeen koulutamme joukon neuromalleja, mukaan lukien ennalta koulutetut kielimallit, ja tutkimme, toimivatko ne paremmin kuin perinteiset koneoppimismallit tässä vähän resursseja käyttävässä kokoonpanossa. Muuntaja-arkkitehtuurit saavat parhaat tulokset, vaikka guarani ei ole huomioitu esikoulutuksessa, mutta perinteiset koneoppimismallit toimivat lähellä ongelman vähävaraisuuden vuoksi.', 'ha': "Wannan takardar ta tambayar fitina na na hisia wa Jopara, wata nau'in mai musanya harshe tsakanin Gurani da Isbanish. Kayya da na sami wani makafi na Twitter masu domin Gurani kuma tuna yi jayayya a kan masu buƙata matsayin tsari ko da masu sauri zuwa ga aikin da za'a yi sauri, kamar anayyar kalma. Sa'an nan, muna kõre wasu misãlai na neura, kamar misãlai da aka yi wa zaman-wa'anar harshen, kuma Mu jarraba, ko za su yi mafiya alhẽri ko da za'a sami mafiya kwamfyutan da aka sani masu cikin wannan tsarin manyan-resource. An sami matsayin ayuka da aka shige, ko da yaushe bai yi bincike wa Gurani a lokacin da aka yi wa kwanza, kuma amma misãlai masu karanta na lafiyar kwamfyutan, za'a sami mafi ƙaranci matsalar da halin matabbata.", 'sk': 'Ta prispevek obravnava problem analize sentimenta za Jopara, jezik preklapljanja kod med guarani in španščino. Najprej zberemo korpus prevladujočih Guarani tweetov in razpravljamo o težavah iskanja kakovostnih podatkov tudi za relativno enostavna opravila, kot je analiza sentimenta. Nato usposobimo niz nevronskih modelov, vključno s predhodno usposobljenimi jezikovnimi modeli, in raziščemo, ali so v tej nastavitvi z nizkimi viri boljši od tradicionalnih strojnega učenja. Najboljše rezultate dosežejo transformatorske arhitekture, kljub temu, da ne upoštevajo guaranija med predusposabljanjem, vendar tradicionalni modeli strojnega učenja zaradi nizke vire problema delujejo blizu.', 'he': 'This paper addresses the problem of sentiment analysis for Jopara, a code-switching language between Guarani and Spanish.  We first collect a corpus of Guarani-dominant tweets and discuss on the difficulties of finding quality data for even relatively easy-to-annotate tasks, such as sentiment analysis.  ואז, אנחנו מאמן קבוצה של דוגמנים עצביים, כולל דוגמנים לשפה מאומנים מראש, ולחקור אם הם מצליחים יותר טוב מאותם ללמוד מכונות מסורתיים במערכת משאבים נמוכים זו. Transformer architectures obtain the best results, despite not considering Guarani during pre-training, but traditional machine learning models perform close due to the low-resource nature of the problem.', 'bo': 'ཤོག་བྱང་འདིས་ཇོ་པཱར་ལ་སྐད་རིགས་དབྱེ་ཞིབ་ཀྱི་དཀའ་ངལ་བ་དེ་ལ་གཏོང་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དང་པོ་ནས་Guarani-dominant tweets ཐོག་གི་བརྩོན་པ་ཞིག་གི་མཉམ་དུ་བསྡད་ནས། དཀའ་ངལ་ཅིག་གིས་བསམ་བློ་གཏོང་ཐབས་བ་ཞིབ་ཐབས་མེད་པར། འོན་ཀྱང་། ང་ཚོས་སྔོན་གྱི་སྐད་ཡིག་ཆའི་མིག་དཔེ་ཆས་ཀྱི་རྣམ་པ་ལྡན་མ་དཔྱད་ཡོད། དེ་ལས་སྔོན་གྱི་སྐད་ཡིག་ཆ་ལྟ་བུ་མང་ཙམ་ བཟོ་བཅོས་མཁན་གྱི་སྒྲིག་འགོད་གཟུགས་འགྱུར་བ་དེ་ཚོར་ཤེས་ཚད་ལྡན་མ་ཤེས་པའི་རྐྱེན་བ་རེད།', 'jv': 'Perintah iki diputamong karo perbudhakan kanggo anamelu langkung sampeyan kanggo Jopara, kelas-ngubah kuwi mau ning garani karo Spanyol. Awak dhéwé Amarok, kéné luwih akeh sistem sing sampeyan mrogram, lan gambar model sing arep bantuan karo perusahaan, lan ujian sisaan kaya ngono kuwi nggawe sistem sing luwih apik sing nyimpen karo perusahaan lan sampeyan sing paling kelas. architecture'}
{'en': 'CodemixedNLP : An Extensible and Open NLP Toolkit for Code-Mixing', 'ar': 'CodemixedNLP: مجموعة أدوات البرمجة اللغوية العصبية المفتوحة والموسعة لخلط التعليمات البرمجية', 'es': 'CodeMixedNLP: un kit de herramientas de PNL abierto y extensible para la mezcla de códigos', 'pt': 'CodemixedNLP: um kit de ferramentas de NLP extensível e aberto para mixagem de código', 'fr': 'CodeMixedNLP\xa0: une boîte à outils NLP extensible et ouverte pour le mixage de code', 'zh': 'CodemixedNLP曰:代码混者张而 NLP 工具包', 'ja': 'CodemixedNLP ：コードミキシングのための拡張可能でオープンなNLPツールキット', 'ru': 'CodemixedNLP: Расширяемый и открытый набор инструментов NLP для смешивания кода', 'hi': 'CodemixedNLP: कोड-मिक्सिंग के लिए एक एक्सटेंसिबल और ओपन एनएलपी टूलकिट', 'ga': 'CodemixedNLP: Foireann Uirlisí NLP Inmhéadaithe agus Oscailte le haghaidh Códmheascadh', 'ka': 'KodemixedNLP: Kode- Mixing გამოყენებელი და გახსნა NLP ხელსაწყოთა პანელი', 'el': 'Ένα επεκτάσιμο και ανοικτό κιτ εργαλείων για ανάμειξη κώδικα', 'hu': 'CodemixedNLP: Egy kiterjeszthető és nyitott NLP eszközkészlet a kódkeveréshez', 'it': 'CodemixedNLP: un kit di strumenti NLP estensibile e aperto per la miscelazione di codici', 'lt': 'CodemixedNLP: Išplėstinis ir atviras NLP kodų maišymo priemonių rinkinys', 'kk': 'KodemixedNLP: Код- Mixing үшін NLP құралдарын ашу және ашу құралдар панелі', 'mk': 'Кодемиксиран NLP: Проширен и отворен NLP алатки за мешање кодови', 'ms': 'NLP: Kit Alat NLP yang boleh Sambung dan Buka untuk Pengcampuran-Kod', 'mt': 'CodemixedNLP: Sett ta’ Għodod NLP Estensibbli u Miftuħ għat-Taħlita tal-Kodiċi', 'mn': 'CodemixedNLP: Код-Mixing болон НLP ашиглах', 'ml': 'CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing', 'ro': 'CodemixedNLP: un kit de instrumente NLP extensibil și deschis pentru amestecarea codurilor', 'pl': 'CodemixedNLP: Rozszerzalny i otwarty zestaw narzędzi NLP do mieszania kodu', 'sr': 'KodemiksedNLP: Prošireni i otvoreni NLP Toolkit za miješanje koda', 'no': 'KodemixedNLP: Eit utvidbare og opna NLP- verktøykassett for kodMixing', 'si': 'CodimixedNLP: කෝඩ් මික්ස් වෙනුවෙන් විස්තර කරන්න සහ අරින්න NLP උපකරණ කිට්', 'so': 'NLP: An Extensible and Open NLP Toolkit for Code-Mixing', 'sv': 'CodemixedNLP: Ett utökat och öppet NLP-verktygspaket för kodblandning', 'ta': 'NLP: ஒரு விரிவாக்கப்பட்ட மற்றும் NLP கருவிப்பெட்டி குறியீடு- கலக்குவதற்கான குறியீடு', 'ur': 'NLP', 'uz': 'CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing', 'vi': 'Mã giải trí: Một công cụ rộng mở và mở Open NLP để Name', 'bg': 'CodemixedNLP: Разширен и отворен комплект инструменти за смесване на кодове', 'nl': 'CodemixedNLP: Een uitbreidbare en open NLP Toolkit voor Code-Mixing', 'da': 'CodemixedNLP: Et udvideligt og åbent NLP værktøjssæt til kode-blanding', 'hr': 'KodemiksedNLP: Prošireni i otvoreni NLP alat za mješanje kodova', 'id': 'CodemixedNLP: Sebuah Alat NLP yang Terluas dan Buka untuk Pengcampuran Kode', 'fa': 'NLP: یک ابزار NLP گسترده و باز برای پیوند کد', 'de': 'CodemixedNLP: Ein erweiterbares und offenes NLP Toolkit für Code-Mixing', 'ko': 'CodemixedNLP: 코드 혼합을 위한 확장 가능한 오픈 NLP 키트', 'sw': 'CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing', 'sq': 'CodemixedNLP: Një kit mjetesh të zgjeruar dhe të hapur NLP për përzierjen e kodeve', 'af': "NLP: ' n Uitbreiding en Open NLP Nutsbalk vir Kode- Menger", 'hy': 'Կոդեմիքսիքս', 'am': 'NLP: An extensive and open NLP Toolkit for Code-Mixing', 'tr': 'NLP: Ködleme üçin Ullanyş we Aç NLP Esbap Zolaky', 'az': 'KodemixedNLP: Kod-Mixing üçün Dərlənən və Aç NLP Alet Çubuğu', 'bn': 'এনএলপি: কোড- মিক্সিং এর জন্য একটি প্রসারিত এবং খোলা NLP টুলিকিট', 'bs': 'KodemixedNLP: Prošireni i otvoreni NLP Toolkit za mješanje koda', 'cs': 'CodemixedNLP: Rozšířitelná a otevřená NLP Toolkit pro míchání kódu', 'ca': "CodemixedNLP: Un conjunt d'eines extensible i obert de NLP per a barrejar codis", 'et': 'CodemixedNLP: laiendatav ja avatud NLP tööriistakomplekt koodide segamiseks', 'fi': 'CodemixedNLP: Laajennettava ja avoin NLP-työkalupakki koodin sekoittamiseen', 'ha': 'NLP: An Extent and Open NLP toolkit for Code-Mixer', 'jv': 'NLP: an Expandsible and Open NLP Tool lkit for kodMixing', 'sk': 'CodemixedNLP: Razširljiv in odprt nabor orodij za mešanje kod', 'bo': 'CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing', 'he': 'NLP: ערכת כלים NLP מתרחבת ופתוחה לערבוב קודים'}
{'en': 'The NLP community has witnessed steep progress in a variety of ', 'ar': 'شهد مجتمع البرمجة اللغوية العصبية (NLP) تقدمًا حادًا في مجموعة متنوعة من المهام عبر مجالات معالجة اللغة أحادية اللغة ومتعددة اللغات مؤخرًا. عززت هذه النجاحات ، جنبًا إلى جنب مع تكاثر التفاعلات اللغوية المختلطة على وسائل التواصل الاجتماعي ، الاهتمام بنمذجة نصوص مختلطة الأكواد. في هذا العمل ، نقدم CodemixedNLP ، مكتبة مفتوحة المصدر تهدف إلى الجمع بين التطورات في البرمجة اللغوية العصبية المختلطة بالشفرات وفتحها لمجتمع تعلم آلي أوسع. تتكون المكتبة من أدوات لتطوير وقياس البنى النموذجية متعددة الاستخدامات المصممة خصيصًا للنصوص المختلطة ، وطرق لتوسيع مجموعات التدريب ، وتقنيات لتحديد أنماط الخلط ، ونماذج حديثة مضبوطة بدقة لـ 7 مهام في Hinglish. نعتقد أن هذا العمل لديه القدرة على تعزيز نظام بيئي موزع وتعاوني ومستدام في مساحة مشتتة لخلط الكود. تم تصميم مجموعة الأدوات بحيث تكون بسيطة وسهلة التوسعة وذات حيلة لكل من الباحثين والممارسين على حدٍ سواء. العرض التوضيحي: http://k-ikkees.pc.cs.cmu.edu:5000 والمكتبة: https://github.com/murali1996/CodemixedNLP', 'es': 'La comunidad de PNL ha sido testigo recientemente de un fuerte progreso en una variedad de tareas en los ámbitos del procesamiento lingüístico monolingüe y multilingüe. Estos éxitos, junto con la proliferación de interacciones de idiomas mixtos en las redes sociales, han impulsado el interés en modelar textos con códigos mezclados. En este trabajo, presentamos CodeMixedNLP, una biblioteca de código abierto con el objetivo de reunir los avances en la PNL de código mixto y abrirla a una comunidad de aprendizaje automático más amplia. La biblioteca consta de herramientas para desarrollar y comparar arquitecturas de modelos versátiles que se adaptan a textos mixtos, métodos para ampliar los conjuntos de capacitación, técnicas para cuantificar estilos de mezcla y modelos de vanguardia ajustados para 7 tareas en Hinglish. Creemos que este trabajo tiene el potencial de fomentar un ecosistema distribuido pero colaborativo y sostenible en un espacio disperso de investigación de mezcla de códigos. El kit de herramientas está diseñado para ser simple, fácilmente extensible e ingenioso tanto para los investigadores como para los profesionales. Demostración: http://k-ikkees.pc.cs.cmu.edu:5000 y biblioteca: https://github.com/murali1996/CodemixedNLP', 'fr': "La communauté de la PNL a récemment été témoin de progrès importants dans diverses tâches dans les domaines du traitement linguistique monolingue et multilingue. Ces succès, associés à la prolifération des interactions linguistiques mixtes sur les réseaux sociaux, ont stimulé l'intérêt pour la modélisation de textes mixtes de code. Dans ce travail, nous présentons CodeMixedNLP, une bibliothèque open source dont l'objectif est de rassembler les avancées de la PNL mixée en code et de l'ouvrir à une communauté d'apprentissage automatique plus large. La bibliothèque comprend des outils permettant de développer et de comparer des architectures de modèles polyvalentes adaptées à des textes mixtes, des méthodes pour étendre les ensembles de formation, des techniques pour quantifier les styles de mixage et des modèles de pointe affinés pour 7 tâches en hinglish. Nous pensons que ce travail a le potentiel de favoriser un écosystème distribué mais collaboratif et durable dans un espace autrement dispersé de recherche sur le mélange de codes. La boîte à outils est conçue pour être simple, facilement extensible et ingénieuse à la fois pour les chercheurs et les praticiens. Démo\xa0: http://k-ikkees.pc.cs.cmu.edu:5000 et bibliothèque\xa0: https://github.com/murali1996/CodemixedNLP", 'pt': 'A comunidade de PNL testemunhou um grande progresso em uma variedade de tarefas nos domínios do processamento de linguagem monolíngue e multilíngue recentemente. Esses sucessos, em conjunto com as crescentes interações de linguagem mista nas mídias sociais, aumentaram o interesse na modelagem de textos mistos de código. Neste trabalho, apresentamos o CodemixedNLP, uma biblioteca de código aberto com o objetivo de reunir os avanços em NLP de código misto e abri-lo para uma comunidade mais ampla de aprendizado de máquina. A biblioteca consiste em ferramentas para desenvolver e comparar arquiteturas de modelos versáteis que são adaptadas para textos mistos, métodos para expandir conjuntos de treinamento, técnicas para quantificar estilos de mixagem e modelos de última geração ajustados para 7 tarefas em Hinglish. Acreditamos que este trabalho tem o potencial de promover um ecossistema distribuído, mas colaborativo e sustentável em um espaço disperso de pesquisa de mistura de códigos. O kit de ferramentas foi projetado para ser simples, facilmente extensível e cheio de recursos para pesquisadores e profissionais. Demonstração: http://k-ikkees.pc.cs.cmu.edu:5000 e Biblioteca: https://github.com/murali1996/CodemixedNLP', 'zh': 'NLP社区近于单语、多言治域诸务大进。 此等成功,加以社交媒体激增之混合言语交互,增人对代码混合文本建模之兴。 于是言CodemixedNLP,开源库也,其集代码混NLP之进,开而广机器学社区。 该库开准试为混合文本量身制多功能模架构之具,广练集之法,量化混合之术,及Hinglish中7务之微调最先进者。 吾信此事,或于代码混合之间,养一分布式、协和之生态系统。 工具包计约而易广,而治人从业者皆足以多谋。 演:http://k-ikkees.pc.cs.cmu.edu:5000 和库 https://github.com/murali1996/CodemixedNLP', 'hi': 'एनएलपी समुदाय ने हाल ही में मोनोलिंगुअल और बहुभाषी भाषा प्रसंस्करण के क्षेत्रों में विभिन्न प्रकार के कार्यों में भारी प्रगति देखी है। इन सफलताओं, सोशल मीडिया पर मिश्रित भाषा इंटरैक्शन के प्रसार के साथ संयोजन के रूप में, मॉडलिंग कोड-मिश्रित ग्रंथों में रुचि को बढ़ावा दिया है। इस काम में, हम CodemixedNLP, कोड-मिश्रित एनएलपी में प्रगति को एक साथ लाने और इसे एक व्यापक मशीन लर्निंग समुदाय के लिए खोलने के लक्ष्यों के साथ एक ओपन-सोर्स लाइब्रेरी प्रस्तुत करते हैं। पुस्तकालय में बहुमुखी मॉडल आर्किटेक्चर को विकसित करने और बेंचमार्क करने के लिए उपकरण शामिल हैं जो मिश्रित ग्रंथों के लिए तैयार किए गए हैं, प्रशिक्षण सेट का विस्तार करने के तरीके, मिश्रण शैलियों को मापने के लिए तकनीक, और हिंग्लिश में 7 कार्यों के लिए ठीक-ठीक ट्यून किए गए अत्याधुनिक मॉडल। हमारा मानना है कि इस काम में कोड-मिश्रण अनुसंधान के अन्यथा बिखरे हुए स्थान में एक वितरित अभी तक सहयोगी और टिकाऊ पारिस्थितिकी तंत्र को बढ़ावा देने की क्षमता है। टूलकिट को सरल, आसानी से एक्सटेंसिबल और शोधकर्ताओं के साथ-साथ चिकित्सकों दोनों के लिए संसाधनपूर्ण होने के लिए डिज़ाइन किया गया है। डेमो: http://k-ikkees.pc.cs.cmu.edu:5000 और पुस्तकालय: https://github.com/murali1996/CodemixedNLP', 'ja': 'NLPコミュニティは、最近、単一言語および多言語処理の領域にわたるさまざまなタスクで急激な進歩を目の当たりにしています。 これらの成功は、ソーシャルメディア上での混合言語の相互作用の増大と併せて、コード混合テキストのモデリングへの関心を高めた。 この研究では、コードミックスNLPの進歩をまとめ、より広範な機械学習コミュニティに開放することを目標としたオープンソースのライブラリであるCodemixedNLPを発表します。 このライブラリは、混合テキストに合わせた多機能モデルアーキテクチャを開発し、ベンチマークするためのツール、トレーニングセットを拡張するための方法、ミキシングスタイルを定量化するためのテクニック、およびHinglishの7つのタスクのための最先端モデルを微調整するためのツールで構成されています。 この研究は、コードミキシング研究の分散された空間で、分散されながらも協働的で持続可能なエコシステムを促進する可能性があると考えています。 このツールキットは、研究者と実践者の両方にとって、シンプルで、簡単に拡張可能で、機知に富むように設計されています。 デモ： http://k-ikkees.pc.cs.cmu.edu ： 5000およびライブラリ： https://github.com/murali1996/CodemixedNLP', 'ru': 'В последнее время сообщество НЛП стало свидетелем значительного прогресса в решении целого ряда задач в области одноязычной и многоязычной языковой обработки. Эти успехи, в сочетании с распространением смешанных языковых взаимодействий в социальных сетях, повысили интерес к моделированию смешанных текстов. В этой работе мы представляем CodemixedNLP, библиотеку с открытым исходным кодом с целью объединения достижений в кодо-смешанной NLP и открытия ее более широкому сообществу машинного обучения. Библиотека состоит из инструментов для разработки и сравнения универсальных архитектур моделей, которые адаптированы для смешанных текстов, методов расширения обучающих наборов, методов количественной оценки стилей смешивания и тонкой настройки современных моделей для 7 задач на хинглише. Мы считаем, что эта работа может способствовать созданию распределенной, но при этом совместной и устойчивой экосистемы в разбросанном по всему миру пространстве исследований, связанных с смешиванием кодов. Инструментарий разработан, чтобы быть простым, легко расширяемым и изобретательным как для исследователей, так и для практических работников. Демо: http://k-ikkees.pc.cs.cmu.edu:5000 и Библиотека: https://github.com/murali1996/CodemixedNLP', 'ga': 'Tá dul chun cinn mór feicthe ag pobal an NLP le déanaí maidir le tascanna éagsúla ar fud réimsí na próiseála teanga aonteangach agus ilteangach. Spreag na rathúlachtaí seo, i gcomhar leis na hidirghníomhaíochtaí teanga measctha méadaitheacha ar na meáin shóisialta, suim i múnlú téacsanna cód-mheasctha. San obair seo, cuirimid i láthair CodemixedNLP, leabharlann foinse oscailte a bhfuil sé mar sprioc aici an dul chun cinn i NLP cód-mheasctha a thabhairt le chéile agus é a oscailt do phobal meaisínfhoghlama níos leithne. Is éard atá sa leabharlann uirlisí chun ailtireachtaí samhlacha ilúsáideacha a fhorbairt agus a thagarmharcáil atá oiriúnaithe do théacsanna measctha, modhanna chun tacair oiliúna a leathnú, teicnící chun stíleanna meascáin a chainníochtú, agus samhlacha den chéad scoth le haghaidh 7 dtasc in Hinglish. Creidimid go bhfuil an poitéinseal ag an obair seo éiceachóras dáilte ach comhoibríoch agus inbhuanaithe a chothú i spás taighde códmheasctha a bheadh scaipthe ar bhealach eile. Tá an fhoireann uirlisí deartha le bheith simplí, insínte go héasca, agus seiftiúil do thaighdeoirí agus do chleachtóirí araon. Taispeántas: http://k-ikkees.pc.cs.cmu.edu:5000 agus Leabharlann: https://github.com/murali1996/CodemixedNLP', 'hu': 'Az NPP-közösség az utóbbi időben jelentős előrelépést tapasztalt a különböző feladatok terén az egynyelvű és többnyelvű nyelvfeldolgozás területén. Ezek a sikerek a közösségi médiában folytatott egyre erősödő vegyes nyelvű interakciókkal együtt növelték az érdeklődést a kódkeverék szövegek modellezése iránt. Ebben a munkában bemutatjuk a CodemixedNLP-t, egy nyílt forráskódú könyvtárat, amelynek célja, hogy összehozza a kódkeverékes NLP fejlődését és megnyissa azt egy szélesebb gépi tanulási közösség előtt. A könyvtár olyan eszközökből áll, amelyek sokoldalú modellarchitektúrákat fejlesztenek és összehasonlítanak, amelyek vegyes szövegekre szabottak, módszereket alkalmaznak a képzési készletek bővítésére, technikákat a keverési stílusok számszerűsítésére, valamint finomhangolt, korszerű modelleket 7 feladathoz hinglish nyelven. Úgy véljük, hogy ez a munka képes arra, hogy elősegítse az elosztott, mégis együttműködő és fenntartható ökoszisztémát a kódkeverő kutatás egyébként szétszórt területén. Az eszköztárat úgy tervezték, hogy egyszerű, könnyen bővíthető és találékony legyen mind a kutatók, mind a gyakorlók számára. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 és könyvtár: https://github.com/murali1996/CodemixedNLP', 'el': 'Η κοινότητα του ΝΛΠ έχει δει απότομη πρόοδο σε μια ποικιλία καθηκόντων σε όλους τους τομείς της μονογλωσσικής και πολύγλωσσης επεξεργασίας γλωσσών πρόσφατα. Αυτές οι επιτυχίες, σε συνδυασμό με τις πολλαπλασιαστικές αλληλεπιδράσεις μικτών γλωσσών στα μέσα κοινωνικής δικτύωσης, έχουν ενισχύσει το ενδιαφέρον για τη μοντελοποίηση κειμένων μικτών κωδικών. Σε αυτή την εργασία, παρουσιάζουμε μια βιβλιοθήκη ανοικτού κώδικα με στόχο να ενώσει τις εξελίξεις στο μικτό κώδικα και να το ανοίξει σε μια ευρύτερη κοινότητα μηχανικής μάθησης. Η βιβλιοθήκη αποτελείται από εργαλεία για την ανάπτυξη και τη συγκριτική αξιολόγηση ευέλικτων αρχιτεκτονικών μοντέλων που είναι προσαρμοσμένες για μικτά κείμενα, μεθόδους για την επέκταση εκπαιδευτικών συνόλων, τεχνικές για τον ποσοτικό προσδιορισμό στυλ ανάμειξης και εκλεπτυσμένα μοντέλα τελευταίας τεχνολογίας για επτά εργασίες στα Χίνγκλις. Πιστεύουμε ότι αυτή η εργασία έχει τη δυνατότητα να προωθήσει ένα κατανεμημένο αλλά συνεργατικό και βιώσιμο οικοσύστημα σε έναν κατά τα άλλα διασκορπισμένο χώρο έρευνας ανάμειξης κώδικα. Η εργαλειοθήκη έχει σχεδιαστεί για να είναι απλή, εύκολα επεκτάσιμη και εφευρετική τόσο σε ερευνητές όσο και σε επαγγελματίες. Δείγμα: http://k-ikkees.pc.cs.cmu.edu:5000 και Βιβλιοθήκη: https://github.com/murali1996/CodemixedNLP', 'ka': 'NLP საზოგადოება ახლა მონოლენგური და მრავალენგური ენების პროცესის განსხვავებულ პარამეტრებში უფრო მრავალური პროგრესის მიხედვით. ეს წარმატები, რომელიც სოციალური მედიაში გაზრუქმებული ენის ინტერფექციების გაზრუქმებით, მოდელირებულ ტექსტის მოდელირებით გაზრუქმებულია. ამ სამუშაოში, ჩვენ CodemixedNLP-ს გახსნა, საკუთარი სამუშაო ლიბერიო, რომელიც მიზეზებით, რომ NLP-ის კოდი შემცირებული პროგრესის გახსნა და გახსნა მაქინის სწავლების საზოგადოებ ლიბური შექმნა ხელსაწყობილობის შესახებ, რომელიც განვითარებული ტექსტის შესახებ განსაზღვრებული მოდელური არქტიქტურების შესახებ და ბენქმენტის შესახებ, რომელიც განსაზღვრებული ტექსტის შესახებ, განსაზღვრების შესახებ ტექნექტი ჩვენ ვფიქრობთ, რომ ეს სამუშაო აქვს პროცენტი, რომელიც გაყოფილი, მაგრამ დამუშაობელი და სრულებელი ეკოსისტემაში კოდის შემთხვევაში გაყოფილი სივრცე. ხელსაწყოთა ხელსაწყოთა კიტი განაზღვრებულია, მარტივი გაფართლებელია, და საშუალებელია ორივე მსწავლობისთვის და პრაქტიკონტებისთვის. დემო: http://k-ikkees.pc.cs.cmu.edu:5000 და ლიბური: https://github.com/murali1996/CodemixedNLP', 'it': "Recentemente la comunità PNL ha assistito a notevoli progressi in una varietà di compiti nell'elaborazione delle lingue monolingue e multilingue. Questi successi, in combinazione con le crescenti interazioni linguistiche miste sui social media, hanno aumentato l'interesse per la modellazione di testi codificati. In questo lavoro presentiamo CodemixedNLP, una libreria open source con l'obiettivo di riunire i progressi nel codice-mixed NLP e aprirla a una più ampia comunità di machine learning. La libreria è composta da strumenti per sviluppare e confrontare architetture di modelli versatili su misura per testi misti, metodi per espandere set di formazione, tecniche per quantificare stili di mixaggio e modelli all'avanguardia perfezionati per 7 attività in hinglish. Crediamo che questo lavoro abbia il potenziale per promuovere un ecosistema distribuito ma collaborativo e sostenibile in uno spazio altrimenti disperso di ricerca di code-mixing. Il toolkit è progettato per essere semplice, facilmente estensibile e pieno di risorse sia per i ricercatori che per i professionisti. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 e Biblioteca: https://github.com/murali1996/CodemixedNLP", 'kk': 'NLP көмегімен бірнеше тілді және бірнеше тілді процессорының көптеген тапсырмалардың көптеген жұмысын көрген. Бұл сәтті, социалдық медиақтардың аралас тілдердің интерфейстерімен бірге, код араластырылған мәтіндерді моделдеу үшін қызықты көтерді. Бұл жұмыс ішінде CodemixedNLP, ашық көзі кітапханасы, NLP кодты араластырылған бағдарламаларды біріктіру мақсаттары мен оны үлкен машина оқыту коммуникасына ашу мақсаттары бар. Кітапхана аралас мәтіндер үшін, оқыту жиындарын кеңейту әдістерін, аралас стилдерді көңейту техникаларын, 7 тапсырмалардың архитектураларын жасау және баптау үшін әртүрлі үлгі архитектуралардан құрылады. Бұл жұмыс код араластыру зерттеулерінің түрлендірілген, бірақ бұл жұмыс істейтін жұмыс және тәуелсіздік экосистемін өзгертуге мүмкіндік береді деп ойлаймыз. Құралдар панелі қарапайым, оңай кеңейтілген және зерттеушілер және әрекеттер үшін құрылған. Демократ: http://k-ikkees.pc.cs.cmu.edu:5000 және кітапхана: https://github.com/murali1996/CodemixedNLP', 'lt': 'Neseniai NLP bendruomenė pastebėjo didelę pažangą įvairiose užduotyse vienokalbio ir daugiakalbio tvarkymo srityse. Šios sėkmės kartu su daugėjančia mišrių kalbų sąveika social in ėje žiniasklaidoje paskatino susidomėjimą modeliuojant mišrius tekstus. In this work, we present CodemixedNLP, an open-source library with the goals of bringing together the advances in code-mixed NLP and opening it up to a wider machine learning community.  Biblioteką sudaro įvairiapusių modelių architektūrų kūrimo ir lyginimo priemonės, pritaikytos mišriems tekstams, mokymo rinkinių plėtros metodai, mišrių stilių kiekybinio skaičiavimo metodai ir patobulinti pažangiausi modeliai, taikomi 7 užduotims hindlų kalba. Manome, kad šis darbas gali skatinti paskirstytą, tačiau bendradarbiaujančią ir tvarią ekosistemą kitaip paskirstytoje kodų derinimo mokslinių tyrimų erdvėje. Prietaisų rinkinys sukurtas taip, kad jis būtų paprastas, lengvai išplėstinis ir naudingas tiek mokslininkams, tiek specialistams. Demonstracija: http://k-ikkees.pc.cs.cmu.edu:5000 ) ir biblioteka: https://github.com/murali1996/CodemixedNLP', 'mk': 'Општината НЛП е сведок на голем напредок во различни задачи низ областите на монојазичното и мултијазичното обработување јазик во последно време. Овие успеси, заедно со проширувачките мешани јазички интеракции на социјалните медиуми, го зголемија интересот за моделирање на мешаните тексти. Во оваа работа, ја претставуваме CodemixedNLP, библиотека со отворен извор со цели да ги споиме напредоците во code-mixed NLP и да ја отвориме за поширока заедница за машинско учење. Библиотеката се состои од алатки за развој и benchmarking на вештабилни моделни архитектури кои се прилагодени за мешани тексти, методи за проширување на наборите на обука, техники за квантификување на стилите на мешање и фино прилагодени модели за 7 задачи на хинглиски. Веруваме дека оваа работа има потенцијал да поттикне дистрибуиран, но соработен и одржлив екосистем во друго дистрибуиран простор на истражување за мешање на кодови. The toolkit is designed to be simple, easily extensible, and resourceful to both researchers as well as practitioners.  Демонстрација: http://k-ikkees.pc.cs.cmu.edu:5000 И библиотека: https://github.com/murali1996/CodemixedNLP', 'ms': 'Komuniti NLP telah menyaksikan kemajuan yang teruk dalam berbagai tugas di seluruh bidang pemprosesan bahasa monobahasa dan berbilang bahasa baru-baru ini. Kejayaan ini, bersama dengan interaksi bahasa bercampur yang berkembang pada media sosial, telah meningkatkan minat dalam pemodelan teks bercampur kod. Dalam kerja ini, kami memperkenalkan CodemixedNLP, perpustakaan sumber terbuka dengan tujuan untuk mengumpulkan kemajuan dalam code-mixed NLP dan membukanya kepada komuniti pembelajaran mesin yang lebih luas. Pustaka ini terdiri dari alat untuk mengembangkan dan benchmark arkitektur model bergerak yang disesuaikan untuk teks campuran, kaedah untuk mengembangkan set latihan, teknik untuk kuantifikasikan gaya campuran, dan model state-of-the-art yang disesuaikan untuk 7 tugas dalam Hinglish. Kami percaya pekerjaan ini mempunyai potensi untuk mendorong ekosistem yang disebarkan tetapi berkooperatif dan kekal dalam ruang lain penyelidikan campuran kod. Kit alat ini direka untuk mudah, mudah diperluaskan, dan berguna untuk kedua-dua peneliti dan praktek. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 / dan Pustaka: https://github.com/murali1996/CodemixedNLP', 'ml': 'NLP സമുദായത്തിന് അടുത്തുതന്നെ മോണോളില്\u200d ഭാഷ പ്രവര്\u200dത്തിപ്പിക്കുന്ന വ്യത്യസ്ത ജോലികളില്\u200d നിന്നും വളരെ മുന്നേറുന്നത് സാക് ഈ വിജയം സാമൂഹിക മാധ്യമങ്ങളില്\u200d കലര്\u200dന്ന ഭാഷയുടെ ഇടപെടുത്തുന്നതിനോടൊപ്പം, കോഡ് മിഷ്ടപ്പെട്ട ട ടെക്സ്റ്റുകള്\u200d മാതൃ ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d കോഡെമിക്സിഡ് NLP, ഒരു തുറന്ന സോര്\u200dസ് ലൈബ്രറി കൊണ്ടുവരുന്നു. കോഡ് മിക്കിച്ചിട്ടുള്ള പുരോഗങ്ങള്\u200d NLP ലേക്ക്  ഭിന്നിക്കപ്പെട്ട ട ടെക്സ്റ്റുകള്\u200dക്ക് വേണ്ടി ചേര്\u200dത്തുകൊടുക്കുന്ന ഉപകരണങ്ങളും, പരിശീലനത്തിന്റെ രീതികള്\u200d വികസിപ്പിക്കുന്നതും, മികച്ച ശൈലികള്\u200d വികസിപ്പിക്കുന്നതിനു നമ്മള്\u200d വിശ്വസിക്കുന്നു ഈ ജോലി വിതരണം ചെയ്തിട്ടുള്ള ഒരു സഹപ്രവര്\u200dത്തനവും സ്ഥിരമായ സംവിധാനത്തിലുള്ള സാധ്യതയുണ്ടെന ഉപകരണങ്ങള്\u200d എളുപ്പമുള്ളതും, എളുപ്പമുള്ളതും, ശ്രദ്ധിക്കുന്നവര്\u200dക്കും പരിശീലിക്കുന്നവര്\u200dക്കും വേണ്ടി സൌകര്യമുള്ളതും ആയിരിക് ഡീമോ: http://k-ikkees.pc.cs.cmu.edu:5000  and Library:  https://github.com/murali1996/CodemixedNLP', 'mt': "Il-komunità NLP xhiedet progress qawwi f’varjetà ta’ kompiti fl-oqsma tal-ipproċessar tal-lingwi monolingwi u multilingwi reċentement. Dawn is-suċċessi, flimkien mal-interazzjonijiet lingwistiċi mħallta proliferattivi fil-midja soċjali, żiedu l-interess fl-immudellar tat-testi mħallta bil-kodiċi. F’din il-ħidma, qed nippreżentaw il-CodemixedNLP, librerija b’sors miftuħ bl-għanijiet li nġabru flimkien l-avvanzi fil-code-mixed NLP u nfetħu għal komunità usa’ ta’ tagħlim tal-magni. Il-librerija tikkonsisti f’għodod għall-iżvilupp u l-paragun ta’ arkitetturi tal-mudelli versatili mfassla apposta għal testi mħallta, metodi għall-espansjoni ta’ settijiet ta’ taħriġ, tekniki għall-kwantifikazzjoni ta’ stili ta’ taħlit, u mudelli aġġustati bl-aktar mod avvanzat għal seba’ kompiti f’Hinglish. Aħna nemmnu li din il-ħidma għandha l-potenzjal li trawwem ekosistema distribwita iżda kollaborattiva u sostenibbli fi spazju mxerred mod ieħor ta' riċerka dwar it-taħlit tal-kodiċijiet. Is-sett ta’ għodod huwa mfassal biex ikun sempliċi, faċilment estensibbli, u b’riżorsi kemm għar-riċerkaturi kif ukoll għall-prattikanti. Demostrazzjoni: http://k-ikkees.pc.cs.cmu.edu:5000  and Library:  https://github.com/murali1996/CodemixedNLP", 'mn': 'NLP-ын нийгэм саяхан нэг хэл болон олон хэл хэлний үйлдвэрлэлийн орнуудын олон даалгаваруудын тухай дэвшилтийг харсан. Эдгээр амжилтыг нийгмийн мэдээллийн хэрэглэгчдийн холбоотой хэлний харилцааны холбоотой холбоотой холбоотой нь кодын холбоотой textуудын загварын сонирхолтой болгодог. Энэ ажил дээр бид CodemixedNLP-г, нээлттэй эх үүсвэрийн номын санг зориулж, код холбогдсон NLP-ын хөгжлийг цуглуулж, машин суралцах нийгэмд нээлттэй болгож байна. Энэ номын санд хувьсагдсан бичиг баримтуудыг хөгжүүлэх, банкварчлах архитектуруудын тулд өөрчлөгдсөн архитектуруудын тулд, сургалтын багш нарийвчлах архитектуруудын тулд байдаг. Хинглишийн 7 ажлын хувьсагдсан архитектуруудын тулд хувьсагдсан архитектуруудын Бид энэ ажлын хуваагдаж, хамтран ажиллах боломжтой экосистем болох боломжтой гэж итгэдэг. Энэ асуудал нь энгийн, амархан өргөн, судлаачид болон мэргэжилтэн хоёуланг ашиглах боломжтой болгож зориулагдсан. Демократ: http://k-ikkees.pc.cs.cmu.edu:5000 номын сан: https://github.com/murali1996/CodemixedNLP', 'no': 'NLP-samfunnet har vitne ståande framgang i mange oppgåver over regilane av monospråk og fleirspråk-handsaming nyleg. Desse suksesa, samanliknet med utviklinga av mellom språk-samarbeid på sosiale medier, har styrket interesse på modellering av tekstar med kodefeksa. I denne arbeida presenterer vi kodemixedNLP, ein open-source bibliotek med målene til å samla framgangane i NLP-blandet kode og opna det opp til ein breidde maskinelæringssamfunn. Biblioteken inneheld av verktøy for å utvikle og benchmarke versatile modell-arkitekturar som er tilpassa for mixed texts, metodar for å utvida opplæringssett, teknikk for å kvantifisere blandingsstilar og finnstillingsmodeller for 7 oppgåver i Hinglish. Vi tror at denne arbeiden har potensialen til å forstørra eit distribuert enno samarbeidleg og bærekraftig økosystem i eit anna forstørrande plass av kodefeksing forskning. Verktøykastet er designert for å vera enkelt, enkelt utvidbare, og ressurselt for begge forskere og praktisere. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 og bibliotek: https://github.com/murali1996/CodemixedNLP', 'pl': 'Społeczność NLP była świadkiem gwałtownego postępu w różnych zadaniach w zakresie jednojęzycznego i wielojęzycznego przetwarzania języka ostatnio. Sukcesy te, w połączeniu z rozprzestrzenianiem się interakcji językowych mieszanych w mediach społecznościowych, zwiększyły zainteresowanie modelowaniem tekstów mieszanych w kodzie. W niniejszej pracy przedstawiamy CodemixedNLP, bibliotekę open source, której celem jest łączenie postępów w kodowym NLP i otwarcie go na szerszą społeczność uczenia maszynowego. Biblioteka składa się z narzędzi do opracowywania i porównywania wszechstronnych architektur modeli dostosowanych do tekstów mieszanych, metod rozszerzania zestawów szkoleń, technik ilościowego określenia stylów mieszania oraz dostrojonych najnowocześniejszych modeli dla siedmiu zadań w języku Hinglish. Wierzymy, że praca ta ma potencjał do wspierania rozproszonego, ale współpracy i zrównoważonego ekosystemu w innych przestrzeniach rozproszonych badań nad mieszaniem kodu. Zestaw narzędzi został zaprojektowany tak, aby był prosty, łatwo rozszerzalny i zaradny zarówno dla naukowców, jak i praktyków. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 i biblioteka: https://github.com/murali1996/CodemixedNLP', 'ro': 'Comunitatea PNL a asistat recent la progrese abrupte într-o varietate de sarcini în domeniile procesării limbilor monolingve și multilingve. Aceste succese, împreună cu proliferarea interacțiunilor lingvistice mixte pe rețelele de socializare, au sporit interesul pentru modelarea textelor mixte de cod. În această lucrare, vă prezentăm CodemixedNLP, o bibliotecă open-source cu scopul de a reuni progresele în PNL mixte de cod și de a o deschide către o comunitate mai largă de machine learning. Biblioteca constă în instrumente pentru a dezvolta și compara arhitecturi de modele versatile adaptate pentru texte mixte, metode de extindere a seturilor de instruire, tehnici de cuantificare a stilurilor de mixare și modele de ultimă generație pentru 7 sarcini în hinglish. Considerăm că această activitate are potențialul de a promova un ecosistem distribuit, dar colaborativ și durabil într-un spațiu de cercetare de amestecare a codurilor, altfel dispersat. Setul de instrumente este conceput pentru a fi simplu, ușor de extins și plin de resurse atât pentru cercetători, cât și pentru practicieni. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 şi Biblioteca: https://github.com/murali1996/CodemixedNLP', 'so': 'Ummadda NLP waxay ku aragtay horumar aad u weyn oo ku socda shaqaalooyin kala duduwan ee boqortooyooyinka kala duduwan ee baaraandegista luuqadaha luuqadaha iyo luuqadaha kala duduwan. Kuwan guulaystay oo la xiriira koritaanka luqada isku xiran ee ku saabsan shabakadda bulshada ayaa ku kordhiyey xiiseynta sameynta qoraalka kooxda isku xiran. Markaas waxan shaqada, waxaan soo bandhignaa CodemixedNLP, maktabadda furan oo la jeedo in horumarinta lagu soo ururiyo koox-isku xiran NLP, waxaana u furanaynaa bulshada barashada machine. Maktabadda waxaa ka mid ah toolo horumarinta iyo bangmooyinka tusaale-qaabka ah oo lagu qoray qoraalka isku xiran, qaababta lagu kordhiyo koorasyada waxbarashada, teknikada lagu qiyaaso qaababka isku xiran, iyo tusaalaha farshaxanka ee 7 shaqooyinka Hinglish. Waxaynu aaminsanahay in shuqulkaas ay awoodo in uu kordhiyo nidaamka iskala qaybiyey oo la xiriirayo iyo dhaqaalaha suurtagal ah oo lagu kala firdhiyey baaritaanka kooxaha. Qoraalka qalabka waxaa loogu talagalay inay si fudud u ahaadaan, si fudud u fudud, iyo in labada cilmi-baaritaanka iyo shaqo-bixiyayaashaba ay si fiican u leeyihiin. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 - iyo maktabadda: https://github.com/murali1996/CodemixedNLP', 'sr': 'NLP zajednica je nedavno svjedočila stežan napredak u raznim zadacima u svim kraljama monojezičkog i multijezičkog obrade. Ovi uspešci, zajedno sa proširenjem mešanih jezičkih interakcija na društvenim medijima, povećali su interes za modeliranje tekstova mešanih kod. U ovom poslu predstavljamo KodemixedNLP, biblioteku otvorenog izvora sa ciljevima okupljanja napreda u kombiniranom NLP-u i otvaranja ga širom zajednici za učenje mašin a. Biblioteka se sastoji od alata za razvoj i kritiku versatilnih modela arhitekture koje su prilagođene za mješane tekste, metode za proširenje seta obuke, tehnike za kvantifikaciju mješanja stila i ispravne modele umetnosti za 7 zadataka u Hinglišu. Vjerujemo da ovaj rad ima potencijal za podizanje raspodijeljenog, ali saradničkog i održivog ekosistema u drugačije raspršenom prostoru istraživanja za mešanje kodova. Instrumenti su dizajnirani da budu jednostavni, lako prošireni i korisni za oba istraživača, kao i praktičara. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 I biblioteka: https://github.com/murali1996/CodemixedNLP', 'si': 'NLP සමාජයෙන් අවස්ථාවක් විශේෂයෙන් විවිධ වැඩක් සාක්ෂි කරලා තියෙනවා මුළු භාෂාවක් සහ බොහොම භාෂාවක්  මේ සාමාජික භාෂාව සම්බන්ධයක් සමග සම්බන්ධයෙන්, සාමාජික මාධ්\u200dයමේ භාෂාව සම්බන්ධයෙන් සම්බන්ධයෙන්, කෝ මේ වැඩේ අපි කෝඩිමික්ස්ඩ් NLP එක්ක පිළිබඳ පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් ලොක්කොරියාවක්, කෝඩ්  ලිබ්රියාර්ටියේ විශාලනය සහ බෙන්ච්මාර්ක් විශාලනය කරන්න සඳහා විශාලනය සඳහා විශාලනය සඳහා විශාලනය සඳහා විශාලනය සඳහා විශාලනය සඳහා විශාලනය සඳහ අපි විශ්වාස කරනවා මේ වැඩේ තියෙන්නේ තාමත් පරික්ෂණය සහ සාමාන්\u200dය විශ්වාස කරන්න පුළුවන් තියෙන්නේ කෝඩ් මික්ස් ස උපකරණය සාමාන්\u200dය, ලේසියෙන් විශාල වෙන්න, සහ පරීක්ෂකයෝ දෙන්නම් සහ ප්\u200dරයෝජනකයෝ විශ්වාස කරනවා. ප්\u200dරදර්ශනය: NAME OF TRANSLATORS http://k-ikkees.pc.cs.cmu.edu:5000 සහ ලායිබරිය: https://github.com/murali1996/CodemixedNLP', 'sv': 'Den nationella handlingsplanen har nyligen sett stora framsteg i en rad olika uppgifter inom flerspråkig och enspråkig språkbehandling. Dessa framgångar, i kombination med de växande blandade språkinteraktionerna på sociala medier, har ökat intresset för att modellera kodblandade texter. I detta arbete presenterar vi CodemixedNLP, ett bibliotek med öppen källkod med målet att sammanföra framstegen inom kodblandad NLP och öppna upp det för en bredare maskininlärningsgrupp. Biblioteket består av verktyg för att utveckla och jämföra mångsidiga modellarkitekturer som är skräddarsydda för blandade texter, metoder för att utöka utbildningsuppsättningar, tekniker för att kvantifiera mixande stilar och finjusterade state-of-the-art modeller för 7 uppgifter på hingliska. Vi tror att detta arbete har potential att främja ett distribuerat men samtidigt samarbetsvilligt och hållbart ekosystem i ett annars spridt utrymme av kodblandning forskning. Verktygssatsen är utformad för att vara enkel, lätt utbyggbar och resursrik för både forskare och praktiker. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 och bibliotek: https://github.com/murali1996/CodemixedNLP', 'ta': 'NLP சமூகத்தில் அண்மையான மொழி செயல்பாட்டில் பல்வேறு பணிகளில் பார்த்துள்ளார்கள் சமீபத்தில் மொழி மொழி செயல்பாட்டில் மற் இந்த வெற்றியடைந்தது, வெற்றிகரமான கலப்பு மொழி இணைப்புகளுடன், சமூக ஊடகங்களில் உள்ள கலப்பு மொழி இடைவெளிப்பாடுகளுடன், குறி இந்த வேலையில், நாம் கோடிமிக்ஸ்ட் NLP, ஒரு திறந்த மூலம் நூலகத்தை காண்பிக்கிறோம். குறிமுறையில் முன்னேற்றத்தை ஒன்று சேர்க்கும் இலக்குகள இந்த நூலகத்தில் உள்ள கருவிகளை உருவாக்க மற்றும் பென்க்மேக் மாதிரி உருவாக்கும் கருவி நாங்கள் நம்புகிறோம் இந்த வேலை ஒரு பங்கிடப்பட்டுள்ளது இன்னும் தொடர்ந்து கொள்ளும் பொருத்தும் பூர்த்தி செய்யும் சக் கருவிப்பெட்டி எளிதாக, எளிதாக விரிவாக இருக்கும், மற்றும் ஆராய்ச்சியாளர் மற்றும் பயிற்சியாளர்களுக்கு மூலமாக Demo: http://k-ikkees.pc.cs.cmu.edu:5000  and Library:  https://github.com/murali1996/CodemixedNLP', 'ur': 'NLP کمونٹی نے اچھے وقت تک ایک زبان اور بہت سی زبان پردازش کے ملکوں میں ایک طرح کے کاموں میں بہت سی پیشرفت کی ہے۔ یہ کامیابی، جو سوسیل میڈیا میں گھیرنے کی مختلف زبان کی تعاملات کی تعاملات کے ساتھ ملتی ہے، موڈلینگ کوڈ مmixed texts کی علاقه اضافہ کرتی ہے. اس کام میں ہم CodemixedNLP کو پیش کررہے ہیں، ایک کھولا-سورس لئبریو جو اس کے موقع کے ساتھ کوڈ میکس NLP کی پیشرفت کو جمع کرتا ہے اور اسے ایک وسیع ماشین سکھانے کی کمونٹی کے لئے کھولتا ہے. لائبرئر میں مختلف ٹیکسٹ کے لئے تغییر کے ساتھ تغییر کی جاتی ہے اور بنچم مارک کے لئے مختلف موڈل معمار کے ساتھ تغییر کی جاتی ہے، ترینس سٹ کو پھیلانے کے مطابق طریقے ہیں، ترینس سٹ کو پھیلانے کے مطابق تکنیک کے مطابق مختلف استیلوں کے مطابق اور ہم اس کام کو سمجھتے ہیں کہ اس کے اختیار میں کوڈ میکسنگ تحقیقات کے بغیر پھیلائی جگہ میں تقسیم کرنے کی امکانات ہے ابزار کیٹ ساده، آسان طور پر پھیلانے کے لئے طراحی کی گئی ہے، اور دونوں تحقیق کرنے والوں اور تمرین کرنے والوں کے لئے مددگار ہے۔ ڈیمو: http://k-ikkees.pc.cs.cmu.edu:5000 اور کتابخانہ: https://github.com/murali1996/CodemixedNLP', 'vi': 'Ngày gần đây, cộng đồng ngôn ngữ ngLP đã chứng kiến việc tiến bộ rất nhiều trong các lĩnh vực phát ngôn ngữ đa dạng. Sự thành đạt này, kết hợp với việc dàn xếp các tương tác ngôn ngữ chung trên các phương tiện xã hội, đã làm tăng hứng thú với việc thiết kế văn bản mã trộn. Trong công việc này, chúng ta sẽ giới thiệu Codie-xedchọc, một thư viện mở nguồn với mục đích tập hợp những tiến bộ trong lập trình ngôn ngữ chung và mở ra cho một cộng đồng học máy rộng hơn. Thư viện gồm các công cụ để phát triển và tiêu điểm các kiến trúc đa dạng được thiết kế riêng cho các văn bản trộn trộn, các phương pháp mở rộng các thiết lập huấn luyện, kỹ thuật để định lượng các kiểu pha trộn, và các mô hình tinh vi nghệ thuật tinh chỉnh sửa cho nhiệm vụ 7 ở Hinlish. Chúng tôi tin rằng công việc này có khả năng phát triển một hệ sinh thái hợp tác và bền bỉ được phân phối trong một không gian khác biệt của nghiên cứu hỗn hợp mã. Bộ dụng cụ được thiết kế đơn giản, dễ mở rộng, và đầy tài nguyên cho cả nhà nghiên cứu lẫn các bác sĩ. chứng: http://k-ikkees.pc.cs.cmu.edu:5000 và thư viện: https://github.com/murali1996/CodemixedNLP', 'uz': "Yaqinda, NLP jamiyati monolingual va ko'plab tillar tizimi boshqa vazifalarda ko'plab jarayonlarni ko'rdi. Ushbu muvaffaqiyatlar jamiyat media bilan bir qanday mix tilning interfeyslari bilan birlashtirish muvaffaqiyatlariga foydalanadi. Kod-mixed textlarni modellash uchun foydalanadi. Bu ishda, biz CodemixedNLP, ochiq manba kutubxonasi, NLP qoidadagi darajalarni birlashtirish uchun darajalar bilan birlashtirish va uni katta mashinaga o'rganish jamoasini ochish. Maktabdagi kutubxonalarning birinchi bir qattiq matn uchun qo'llangan model arxituvchilarini yaratish va saqlash imkoniyatlaridan foydalanish uchun vositalar, trening moslamalarini oshirish usullarini oshirish uchun metodi, minglab uslublarni qiymatish va Hinglikda 7 ish usullarining yaxshi qisqarli holati modellarini yaratish uchun. Biz ishni o'ylaymiz, bu ishni ajratilgan va ishlab chiqarish va davomiy hayot tizimini ko'rsatish mumkin, boshqa bir qanday ajratilgan kodlash tarjimalarining joyini o'zgartirish mumkin. Asboblar asboblar oddiy, juda sodda, juda foydalanadigan va ta'qituvchilar va foydalanuvchilarga juda muhim bo'ladi. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 & va kutubxona: https://github.com/murali1996/CodemixedNLP", 'bg': 'Общността на НЛП е станала свидетел на рязък напредък в различни задачи в сферата на едноезичната и многоезичната обработка на езика напоследък. Тези успехи, във връзка с разпространението на смесените езикови взаимодействия в социалните медии, засилиха интереса към моделирането на текстове, смесени с кодове. В тази работа представяме библиотека с отворен код, чиято цел е да обедини напредъка в кодово смесеното НЛП и да я отвори за по-широка общност за машинно обучение. Библиотеката се състои от инструменти за разработване и сравняване на универсални архитектури на модели, които са пригодени за смесени текстове, методи за разширяване на обучителни набори, техники за количествено определяне на стиловете на смесване и фина настройка на съвременните модели за 7 задачи в хинглиш. Вярваме, че тази работа има потенциала да насърчи разпределена, но съвместна и устойчива екосистема в иначе разпръснато пространство на изследвания за смесване на кодове. Инструментите са предназначени да бъдат прости, лесно разширими и изобретателни както за изследователи, така и за практикуващи. Демо: http://k-ikkees.pc.cs.cmu.edu:5000 и библиотека: https://github.com/murali1996/CodemixedNLP', 'nl': 'De NLP-gemeenschap heeft de laatste tijd grote vooruitgang geboekt in een verscheidenheid van taken op het gebied van eentalige en meertalige taalverwerking. Deze successen, in combinatie met de toenemende interacties in gemengde talen op sociale media, hebben de interesse in het modelleren van code-gemengde teksten gestimuleerd. In dit werk presenteren we CodemixedNLP, een open-source bibliotheek met als doel de vooruitgang in code-mixed NLP samen te brengen en deze open te stellen voor een bredere machine learning gemeenschap. De bibliotheek bestaat uit tools om veelzijdige modelarchitecturen te ontwikkelen en te benchmarken die zijn afgestemd op gemengde teksten, methoden om trainingssets uit te breiden, technieken om mengstijlen te kwantificeren en verfijnde state-of-the-art modellen voor zeven taken in het Hinglish. Wij geloven dat dit werk het potentieel heeft om een gedistribueerd maar toch samenwerkingsverband en duurzaam ecosysteem te bevorderen in een verder verspreide ruimte van code-mengend onderzoek. De toolkit is ontworpen om eenvoudig, gemakkelijk uit te breiden en vindingrijk te zijn voor zowel onderzoekers als beoefenaars. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 en bibliotheek: https://github.com/murali1996/CodemixedNLP', 'hr': 'NLP zajednica je nedavno svjedočila stežan napredak u raznim zadacima u svim kraljama monojezičkog i multijezičkog obrade. Te uspjehe, zajedno s proširenjem miješanih jezičkih interakcija na društvenim medijima, povećali su interes za modeliranje tekstova mješanih kod. U ovom poslu predstavljamo KodemixedNLP, biblioteku otvorenog izvora sa ciljevima okupljanja napreda u NLP-u koji je pomiješan kod i otvaranja širom zajednici za učenje stroja. Biblioteka se sastoji od alata za razvoj i mjerenje versatilnih modelskih arhitektura koji su prilagođeni za mješane tekstove, metode za proširenje seta obuke, tehnike za kvantifikaciju mješanja stila i ispravne modele umjetnosti za 7 zadataka u Hinglišu. Vjerujemo da ovaj rad ima potencijal za podizanje distribucijskog i održivog ekosistema u drugačije raspršenog prostora istraživanja mešavanja kodova. Instrumenti su dizajnirani da budu jednostavni, lako prošireni i korisni za oba istraživača, kao i praktičara. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 I biblioteka: https://github.com/murali1996/CodemixedNLP', 'da': 'NLP-samfundet har for nylig oplevet store fremskridt i en række opgaver på tværs af ensproget og flersproget sprogbehandling. Disse succeser, sammen med de voksende blandede sproginteraktioner på sociale medier, har øget interessen for at modellere kode-blandede tekster. I dette arbejde præsenterer vi CodemixedNLP, et open source bibliotek med det formål at samle fremskridtene inden for kodeblandet NLP og åbne det op for et bredere maskinlæringsfællesskab. Biblioteket består af værktøjer til at udvikle og benchmark alsidige modelarkitekturer, der er skræddersyet til blandede tekster, metoder til at udvide træningssæt, teknikker til at kvantificere blandingsstilar og finjusterede state-of-the-art modeller til 7 opgaver på hinglisk. Vi mener, at dette arbejde har potentialet til at fremme et distribueret, men alligevel samarbejdsvilligt og bæredygtigt økosystem i et ellers spredt rum af kode-blanding forskning. Værktøjssættet er designet til at være enkel, let udvidelig og opfindsomt til både forskere og praktikere. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 og Bibliotek: https://github.com/murali1996/CodemixedNLP', 'de': 'Die NLP-Community hat in letzter Zeit starke Fortschritte bei einer Vielzahl von Aufgaben im Bereich der ein- und mehrsprachigen Sprachverarbeitung erlebt. Diese Erfolge in Verbindung mit den vermehrten Interaktionen in den sozialen Medien haben das Interesse an der Modellierung von Code-Mixed-Texten geweckt. In dieser Arbeit stellen wir CodemixedNLP vor, eine Open-Source-Bibliothek mit dem Ziel, die Fortschritte im Code-Mixed NLP zusammenzuführen und für eine breitere Machine Learning Community zu öffnen. Die Bibliothek besteht aus Werkzeugen zur Entwicklung und Benchmark vielseitiger Modellarchitekturen, die auf gemischte Texte zugeschnitten sind, Methoden zur Erweiterung von Trainingssets, Techniken zur Quantifizierung von Mischstilen und fein abgestimmten State-of-the-Art Modellen für 7-Aufgaben in Hinglish. Wir glauben, dass diese Arbeit das Potenzial hat, ein verteiltes, aber kollaboratives und nachhaltiges Ökosystem in einem ansonsten verstreuten Raum der Code-Mixer-Forschung zu fördern. Das Toolkit ist so konzipiert, dass es sowohl für Forscher als auch für Praktiker einfach, leicht erweiterbar und einfallsreich ist. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 und Bibliothek: https://github.com/murali1996/CodemixedNLP', 'id': 'Komunitas NLP telah menyaksikan kemajuan yang tinggi dalam berbagai tugas di seluruh dunia proses bahasa monobahasa dan berbagai bahasa baru-baru ini. Sukses ini, bersama dengan interaksi bahasa campuran yang berkembang di media sosial, telah meningkatkan minat dalam modeling teks campuran kode. Dalam pekerjaan ini, kami memperkenalkan CodemixedNLP, sebuah perpustakaan sumber terbuka dengan tujuan untuk mengumpulkan kemajuan dalam code-mixed NLP dan membukanya untuk komunitas pembelajaran mesin yang lebih luas. Perpustakaan terdiri dari alat untuk mengembangkan dan benchmark arsitektur model versatil yang disesuaikan untuk teks campuran, metode untuk mengembangkan set pelatihan, teknik untuk mengurangi gaya campuran, dan model terbaik yang disesuaikan untuk 7 tugas di Hinglish. Kami percaya pekerjaan ini memiliki potensi untuk mendorong ekosistem yang disebarkan namun kollaboratif dan bertahan dalam ruang yang lain disebarkan penelitian campuran kode. Pakaian alat ini dirancang untuk sederhana, mudah diperluaskan, dan berguna untuk para peneliti dan para praktek. Demo: http://k-ikkees.pc.cs.cmu.edu:5000  and Library:  https://github.com/murali1996/CodemixedNLP', 'ko': '최근 NLP 커뮤니티는 한어와 다국어 처리 분야의 다양한 임무에서 큰 진전을 이뤘다.이러한 성공에 소셜 미디어에서 혼합 언어의 상호작용이 급증하면서 코드 혼합 텍스트 모델링에 대한 흥미를 높였다.이 작업에서 우리는CodemixedNLP를 소개했는데 이것은 소스 라이브러리로서 코드를 혼합한 NLP의 발전을 결합시켜 더욱 광범위한 기계 학습 지역사회에 개방하는 것이 목표이다.이 라이브러리는 혼합 텍스트를 위한 맞춤형 다기능 모델 체계 구조의 개발과 기준 테스트 도구, 확장 트레이닝 세트의 방법, 양적 혼합 스타일의 기술, 7가지 Hinglish 임무를 미세하게 조정하는 최첨단 모델을 포함한다.우리는 이 작업이 분산된 코드 혼합 연구 분야에서 분포적이고 협동적이며 지속가능한 생태계를 육성할 수 있을 것이라고 믿는다.이 패키지는 디자인이 간단하고 확장이 쉬워 연구원과 종사자들에게 모두 지혜롭고 계략적이다.데모:http://k-ikkees.pc.cs.cmu.edu:5000도서관:https://github.com/murali1996/CodemixedNLP', 'sw': 'Jamii ya NLP imeshuhudia maendeleo makubwa katika kazi mbalimbali katika ufalme wa utawala wa lugha za asili na lugha mbalimbali hivi karibuni. Mafanikio haya, kwa pamoja na kuongezeka kwa lugha tofauti katika mitandao ya kijamii, yamesababisha maslahi ya kutengeneza maandishi yanayochanganyika na kodi. Katika kazi hii, tunaionyesha CodemixedNLP, maktaba ya wazi yenye malengo ya kukusanya maendeleo ya NLP yanayochanganyika kwa mfumo na kuifungua kwa jamii kubwa ya kujifunza mashine. Maktaba ina vifaa vya kutengeneza na kuboresha miundombi yenye mifano mbalimbali, njia za kupanua seti za mafunzo, mbinu za kuhakikisha misitu ya mchanganyiko, na mitindo ya sanaa yenye matumizi ya sanaa kwa kazi 7 jijini Hinglish. Tunaamini kazi hii in a uwezekano wa kukuza usambazaji na ushirikiano na mfumo wa mazingira endelevu katika sehemu nyingine ya utafiti unaohusisha kodi. Kifaa hicho kinalengwa kuwa rahisi, kwa urahisi na kina rasilimali kwa watafiti pamoja na wataalamu. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 na maktaba: https://github.com/murali1996/CodemixedNLP', 'sq': 'Komuniteti i NLP ka parë përparim të ashpër në një shumëllojshmëri detyrash nëpër fushat e procesimit të gjuhës monogjuhëse dhe shumëgjuhëse kohët e fundit. Këto sukses, së bashku me ndërveprimet e përziera të gjuhës në mediat sociale, kanë rritur interesin në modelimin e teksteve të përziera me kod. Në këtë punë, ne paraqesim CodemixedNLP, një bibliotekë me burim të hapur me qëllime të mbledhjes së përparimeve në code-mixed NLP dhe hapjes së saj për një komunitet më të gjerë mësimi makinash. Biblioteka përbëhet nga mjete për të zhvilluar dhe përcaktuar arkitektura të modeleve versatile që janë të përshtatshme për tekste të përziera, metoda për të zgjeruar grupet e stërvitjeve, teknika për të përcaktuar stilet e përzierjes dhe modele të përshtatshme më të larta për 7 detyra në Hinglish. Ne besojmë se kjo punë ka potencialin për të nxitur një ekosistem të shpërndarë por bashkëpunues dhe të qëndrueshëm në një hapësirë tjetër të shpërndarë të kërkimit të përzierjes së kodeve. Paketa e mjeteve është dizajnuar për të qenë e thjeshtë, lehtë të zgjerueshme dhe me burime si për kërkuesit ashtu edhe për praktikantët. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 dhe Biblioteka: https://github.com/murali1996/CodemixedNLP', 'af': "Die NLP-gemeenskap het getuig van stap vordering in 'n verskeie opdragte oor die realme van monolinglike en multitaal-verwerking onlangs. Hierdie sukses, saam met die uitbreiding van gemengde taal interaksies op sosiale media, het die belang in modellering van kode gemengde teks vergroot. In hierdie werk voorsien ons CodemixedNLP, 'n oop-bron biblioteek met die doels om die vorderings in kode gemengde NLP te bring en dit oopmaak tot 'n breideer masjien leer gemeenskap. Die biblioteek bestaan van hulpmiddels om te ontwikkel en benchmark verskillende modelle arkitektuur wat vir gemengde teks, metodes om onderwerp te uitbrei, teknike om gemengde style te kvantifiseer en fyn-geïnstalleerde staat-van-kunstenmodelle vir 7 taak in Hinglish. Ons glo hierdie werk het die potensieal om 'n verdeelde nog verdeelde ekostelsel te verskaf in 'n anders verspreidige ruimte van kode-menger ondersoek. Die nutsbalk is ontwerp om eenvoudige, maklik uitbreiding te wees en hulpbron vir beide ondersoekers en ook praktisers te wees. Demo: Name http://k-ikkees.pc.cs.cmu.edu:5000 en Biblioteek: https://github.com/murali1996/CodemixedNLP", 'tr': "NLP jemgyýeti son zamanlarda monodil we multidil işlemleriniň birnäçe işlerinde ukyp ýüze çykyp bardyr. Bu üstünlikler sosyal medýdanlarda azalýan diller bilen birleşende ködlemeler karmaşgalan metinler üçin gyzyklandyrylýar. Bu işde CodemixedNLP'i a çyk çeşme kitaphanesini NLP karışyk şeklinde gelişmeleri bilen birleştirmek üçin hedeflerimizi we muny döwlet öwrenmek üçin açdyk. Kitaphanada karışık metinler üçin düzümlenmek we çykmak üçin janlaşdyrylýan örnekleri bar, eğitim toparlaryny döwletmek üçin, karışmak stillerini küçütmek üçin tekniklerden, we 7 işi üçin janlaşdyrylýan-de-sanat modellerinden ybarat. Biziň pikirimçe bu işiň, häzir hem üýtgeşik we sürekli ekosistema etmäge ködleşiklik karmaşgalan araştyrmalaryň ýerini täsirleştirmegi mümkin edip biljekdigine ynanýarys. Bu araç çykyşlar ýeňil, aňsatlyk ýöreýän we hem ylgamçylar we praktikantlar üçin örän uly bir şekilde tasarlanýar. Demokratik: http://k-ikkees.pc.cs.cmu.edu:5000 Music Library https://github.com/murali1996/CodemixedNLP", 'am': 'የNLP ማኅበረሰብ በቅርብ ዘመን በሞሎልቋንቋ እና በቋንቋ ቋንቋ ተግባር ላይ በተለየ ሁኔታ ስራዎችን ያየዋል፡፡ ይህ የቋንቋ ግንኙነት በማኅበራዊ ማኅበራዊ ሚዲያ ላይ በተለየ ውጤት በመጠቀም፣ የኮድ-የተለየ ጽሑፎችን በመጠቀም የሚጠቅምበት ውጤት አበረታች፡፡ በዚህ ሥራ፣ የክፍት የኩነቶች መሪፖርት ኮድሜክስድNLP፣ የግንኙነቶችን የኮድ አቀማመጥ እና ወደ ትልቅ መሳፍን ማስተማር ማኅበረሰብ እናስከፍታለን፡፡ መዝገብ ቤትሪክ ውስጥ በተለየ ጽሑፎች፣ ማሰናከያ ማሰናከያ ሥርዓቶች፣ ማጠቃለያ መስመር፣ ማጠቃለያ ዓይነቶችን ለማስተካከል እና በሐንጉልሽ ለ7 ስራዎችን ለመጠቀም የመስመር ዓይነቶች እና የመጠቀም የክፍለ ሀብት አካባቢ አካላት ማድረግ እና የመስመር ሀብት ማድረግ ነው፡፡ ይህንን ሥራ በተለያዩ የኮድ ተርሚኖችን መፍጠር እና የሚቆርጥ የኢኮኖሚ ስርዓት ማድረግ ስልጣን አለበት ብለን እናምናለን፡፡ መሣሪያው ቀላል፣ በቀላል፣ ለሁሉም አስተማሪዎች እና ለባለጠያፊዎች መብት ነው፡፡ አዲስ http://k-ikkees.pc.cs.cmu.edu:5000 መዝገብ ቤት https://github.com/murali1996/CodemixedNLP', 'hy': 'ՆԼՊ-ի համայնքը ականատես է եղել մի շարք խնդիրների մեծ առաջընթացը միալեզու և բազլեզու լեզվի վերաբերյալ վերջերս: Այս հաջողությունները, միասին սոցիալական լրատվամիջոցների բազմազան լեզվի խառնաշփումների հետ, բարձրացրել են հետաքրքրությունը կոդի-խառնաշփումների մոդելավորման մեջ: Այս աշխատանքի ընթացքում մենք ներկայացնում ենք Կոդեմիքսդ ՆԼՊ-ը, բաց կոդը բաց գրադարան, որի նպատակով է միավորել առաջընթացը կոդը խառնված ՆԼՊ-ում և բացել այն ավելի լայն մեքենային ուսուցման համայնքի համար: Գրադարանը կազմված է գործիքներից, որոնք օգտագործում են զարգացնել և համեմատել բազմազան մոդելներ ճարտարապետություններ, որոնք պատրաստված են խառնված տեքստների համար, մեթոդներ, որոնք օգտագործվում են ուսուցման համակարգերի ընդլայնման համար, մեթոդներ, որոնք օգտագործվում են խառնման ոճերի չափման համար, և հինգ Մենք հավատում ենք, որ այս աշխատանքը ունի պոտենցիալ խրախուսելու բաշխված, սակայն համագործակցություն և կայուն էկոհամակարգ այլ տարածված հետազոտությունների մեջ: Այն նախագծված է այնպես, որ այն պարզ, հեշտությամբ ընդլայնելի և հնարավոր լինի ուսումնասիրողների և մասնագետների համար: Դեմոս. http://k-ikkees.pc.cs.cmu.edu:5000 և գրադարան. https://github.com/murali1996/CodemixedNLP', 'bn': 'The NLP community has witnessed steep progress in a variety of tasks across the realms of monolingual and multilingual language processing recently.  সামাজিক প্রচার মাধ্যমের মিশ্রিত ভাষার মিশ্রিত প্রতিক্রিয়ার সাথে এই সফলতার সাথে কোড মিশ্রিত লেখাগুলোর মডেলিং বা এই কাজে আমরা এক উন্মুক্ত সোর্স লাইব্রেরী কোডেমিক্সেড এনএলপিকে উপস্থাপন করি, যার উদ্দেশ্যে কোড মিশ্রিত এনএলপির উন্নয়নগুলো একত্রিত করা এবং বৃহ এই লাইব্রেরীর মধ্যে রয়েছে মিশ্রিত টেক্সট, প্রশিক্ষণ বৃদ্ধি করার পদ্ধতি, মিশ্রণ স্টাইল, এবং হিঙ্গ্লিশের ৭টি কাজের জন্য সুন্দর শিল্পের পরিমাণ মডেলের মাধ্যমে সুনির্ধারিত মড আমরা বিশ্বাস করি এই কাজের সম্ভাবনা আছে যে কোড মিশ্রিত গবেষণার বিভিন্ন স্থানে একটি সহযোগিতা এবং সহযোগিতা ও স্থায়ীভাবে বিতরণ কর টুলবিটটি সাধারণ, সহজে প্রসারিত এবং গবেষক এবং প্রশিক্ষকদের জন্য সম্পদ। ডিম: http://k-ikkees.pc.cs.cmu.edu:5000 এবং লাইব্রেরি: https://github.com/murali1996/CodemixedNLP', 'bs': 'NLP zajednica je nedavno svjedočila stežan napredak u raznim zadacima u svim kraljama monojezičkog i multijezičkog obrade. Ovi uspjesi, zajedno sa proširenjem miješanih jezičkih interakcija na društvenim medijima, povećali su interes za modeliranje tekstova miješanih kod. U ovom poslu predstavljamo KodemixedNLP, biblioteku otvorenog izvora sa ciljevima okupljanja napreda u NLP-u mešanoj kodovima i otvaranja ga širom zajednici za učenje mašin a. Biblioteka se sastoji od alata za razvoj i mjerenje versatilnih modela arhitekture koje su prilagođene za mješane tekste, metode za proširenje seta obuke, tehnike za kvantifikaciju mješanja stila, i ispravne modele umetnosti za 7 zadataka u Hinglišu. Vjerujemo da ovaj rad ima potencijal za podizanje distribucijskog i održivog ekosistema u drugačije raspršenog prostora istraživanja mešavanja kodova. Instrumenti su dizajnirani da budu jednostavni, lako prošireni i korisni za oba istraživača, kao i praktičara. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 I biblioteka: https://github.com/murali1996/CodemixedNLP', 'az': 'NLP cəmiyyəti son zamanlarda monodil və çoxlu dil işləməsinin müxtəlif işlərində çoxlu tədbirli ilerlemesini görmüşdür. Bu müvəffəqiyyətlər, sosyal mediyalarda müxtəlif dil əlaqələri genişləndirməklə birlikdə, kodu karıştırılmış məktubları modelləşdirmək üçün səbəbi artırdı. Bu işdə CodemixedNLP, a çıq-kaynaklı kitabxanı, NLP kodu karıştırılmış öyüd-nəsihətlərini birləşdirmək və daha geniş bir makina öyrənmə müddətinə açmaq məqsədilə göstəririk. Kitabxan karışıq metinlər üçün müəyyən edilən, təhsil qurğularını genişləndirmək metodları, karışıq stillərini kvantifikat etmək üçün və 7 işin müəyyən edilmiş sanat modellərinin müəyyən edilməsi üçün müxtəlif modellərdəndir. Biz in an ırıq ki, bu işin sadəcə olaraq müvəffəqiyyətli və müvəffəqiyyətli ekosistemin başqa bir còd karıştırma araştırmalarının genişlənməsi üçün mümkün olar. Bu araç çubuğu basit, asanlıqla genişlənmək və hər iki araştırmacıya və təhsil edənlərə istifadə edilir. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 Kitabı da: https://github.com/murali1996/CodemixedNLP', 'cs': 'Komunita NLP v poslední době zaznamenala prudký pokrok v různých úkolech v oblasti jednojjazyčného a vícejazyčného zpracování jazyků. Tyto úspěchy ve spojení s šířením kombinovaných jazykových interakcí na sociálních médiích zvýšily zájem o modelování textů smíšených kódem. V této práci představujeme CodemixedNLP, open-source knihovnu s cílem spojit pokroky v kódově smíšené NLP a otevřít ji širší komunitě strojového učení. Knihovna se skládá z nástrojů pro vývoj a srovnávání univerzálních modelových architektur, které jsou přizpůsobeny smíšeným textům, metod pro rozšíření tréninkových sad, technik pro kvantifikaci stylů míchání a vyladěných nejmodernějších modelů pro sedm úloh v Hinglištině. Věříme, že tato práce má potenciál podpořit distribuovaný, ale spolupracující a udržitelný ekosystém v jinak rozptýleném prostoru výzkumu míchání kódu. Sada nástrojů je navržena tak, aby byla jednoduchá, snadno rozšiřitelná a vynalézavá jak pro výzkumné, tak i pro praktiky. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 a knihovna: https://github.com/murali1996/CodemixedNLP', 'fa': 'جامعه NLP در اخیراً پیشرفت زیادی در کارهای مختلف در سرزمینهای پردازش زبان و زبان\u200cهای یکدیگر را مشاهده کرده است. این موفقیت، در کنار افزایش تعاملات زبانی مختلف در رسانه\u200cهای اجتماعی، علاقه\u200cای به نمونه\u200cسازی متن\u200cهای مختلف کد را افزایش داده است. در این کار، ما یک کتابخانه\u200cی منبع باز با هدف\u200cهایی که پیشرفت\u200cهای NLP با کد مختلف شده را جمع می\u200cکنیم و آن را به جامعه یادگیری ماشین گسترده\u200cتر باز می\u200cکنیم. کتابخانه از ابزارهایی است که برای توسعه و ترکیب معمارهای متفاوتی از مدل مختلف هستند که برای متن مختلف تغییر داده می شوند، روش\u200cهایی برای گسترش مجموعه آموزش، تکنیک\u200cهایی برای اندازه\u200cگیری سبک\u200cهای مختلف و مدل\u200cهای هنری برای 7 کار در هنگلیش تغییر داده می\u200cشوند. ما باور می\u200cکنیم که این کار توانایی برای تحقیقات پیوسته\u200cای که در فضای متفرق شده\u200cای از تحقیقات پیوسته\u200cگیری کد\u200cگیری می\u200cشود، توسعه یک اقتصاد\u200cسیستم همکاری و پایدار است. وسيله\u200cي ابزار ساده، آسان و گسترده و مناسب براي هر دو تحقيقات کننده و تمرين کننده\u200cها طراحي شده است. نمایش: http://k-ikkees.pc.cs.cmu.edu:5000 و کتابخانه: https://github.com/murali1996/CodemixedNLP', 'et': 'NLP kogukond on viimasel ajal olnud tunnistajaks järsule edusammudele mitmesuguste ülesannete täitmisel ühe- ja mitmekeelse keeletöötluse valdkonnas. Need edusammud koos leviva segakeelse suhtlusega sotsiaalmeedias on suurendanud huvi koodisegatekstide modelleerimise vastu. Käesolevas töös tutvustame avatud lähtekoodiga raamatukogu CodemixedNLP, mille eesmärgiks on koondada koodiga segatud NLP-i edusammud ja avada see laiemale masinõppe kogukonnale. Raamatukogu koosneb vahenditest mitmekülgsete mudeliarhitektuuride arendamiseks ja võrdlemiseks, mis on kohandatud segatekstide jaoks, meetoditest koolituskomplektide laiendamiseks, meetoditest segamisstiilide kvantifitseerimiseks ja viimistletud kaasaegsetest mudelitest seitsme hinglishi ülesande jaoks. Usume, et sellel tööl on potentsiaal edendada hajutatud, kuid koostööd tegevat ja jätkusuutlikku ökosüsteemi muidu hajutatud koodide segamise uurimisruumi. Tööriistakomplekt on loodud nii lihtsaks, kergesti laiendatavaks ja leidlikuks nii teadlastele kui ka praktikutele. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 ja raamatukogu: https://github.com/murali1996/CodemixedNLP', 'ca': "La comunitat del NLP ha assistit a un progrés notable en una varietat de tasques en tots els àmbits del processament monolingüe i multilingüe fa poc. Aquests èxits, juntament amb la proliferació de les interaccions de llenguatges mixtes en els mitjans socials, han augmentat l'interès en modelar textos mixtes amb codis. En aquest treball, presentem CodemixedNLP, una biblioteca de codi obert amb els objectius de reunir els avanços en NLP combinat amb codi i obrir-la a una comunitat d'aprenentatge màquinari més amplia. La biblioteca consisteix en eines per desenvolupar i comparar arquitectures de models versàtil que estan adaptades a textos mixtes, mètodes per expandir conjunts d'entrenament, tècniques per quantificar estils de mistura, i models actualitzats fins a 7 tasques a Hinglish. Creiem que aquesta feina té el potencial de promoure un ecosistema distribuït però col·laboratiu i sostenible en un espai de recerca de combinació de codis diferent dispersat. La llista d'eines està dissenyada per ser simple, fàcilment extensible i resourcesa tant per investigadors com per practicants. Demo:  http://k-ikkees.pc.cs.cmu.edu:5000 i biblioteca: https://github.com/murali1996/CodemixedNLP", 'fi': 'NLP-yhteisö on viime aikoina edistynyt jyrkästi erilaisissa tehtävissä monikielisen ja monikielisen kielen käsittelyn aloilla. Nämä menestykset yhdessä sosiaalisen median monikielisten vuorovaikutusten yleistymisen kanssa ovat lisänneet kiinnostusta koodisekoitettujen tekstien mallintamiseen. Tässä työssä esitellään CodemixedNLP, avoimen lähdekoodin kirjasto, jonka tavoitteena on koota yhteen koodisekoitetun NLP:n edistysaskeleet ja avata se laajemmalle koneoppimisyhteisölle. Kirjasto koostuu työkaluista, joilla kehitetään ja vertaillaan monipuolisia malleja, jotka on räätälöity sekateksteille, menetelmistä laajentaa koulutussarjoja, tekniikoista kvantifioida sekoitustylejä ja hienoviritetyistä huippuluokan malleista seitsemään Hinglishin tehtävään. Uskomme, että tällä työllä on potentiaalia edistää hajautettua, mutta yhteisöllistä ja kestävää ekosysteemiä muutoin hajautetussa koodien sekoitustutkimuksen tilassa. Työkalupakki on suunniteltu olemaan yksinkertainen, helposti laajennettavissa ja kekseliäs sekä tutkijoille että ammattilaisille. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 ja kirjasto: https://github.com/murali1996/CodemixedNLP', 'jv': 'komunitas NLP lakune nglanggar nglanggar sampek bantuan ing pekané dadi sakjane perusahaan karo pakem nggawe ngupakan winih lan akeh bantuan ingkang. Wurung iki, nggawe Jejaring kanggo ngerasakno nggawe Jejaring Nang lan gunggo iki, kita sembarang kodimiksedNLP iki, buku-buku kelas kanggo ngilangno nggawe buku kanggo ngilangno sistem sing sembarang NLP karo kode nggawe lan buku nggawe komunitas kanggo ngilangno sistem sing bebas. Digitale Awak dhéwé ngpisan karo hal-hal iki gawe nguasai perusahaan kanggo nguasai iki dadi, nik nguasai ekosistem sing beraksi lan ora ono wektu nggawe barang-barang kanggo ngilanggar ujian. Golo-tool sing disenyarno kanggo sampeyan, gampang, lan ijol-ijolan ngono sak gadoh cercetaké awak dhéwé koyo ngono ingkang dipoleh. Refresh every [NUMERIC_ENTRY] [TIME_UNITS_COMBO] http://k-ikkees.pc.cs.cmu.edu:5000 tutorial_basic https://github.com/murali1996/CodemixedNLP', 'sk': 'Skupnost NLP je bila v zadnjem času priča velikemu napredku pri različnih nalogah na področju enojezične in večjezične obdelave jezikov. Ti uspehi so v povezavi s širjenjem mešanih jezikovnih interakcij na družbenih omrežjih povečali zanimanje za modeliranje besedil, mešanih s kodami. V tem delu predstavljamo CodemixedNLP, odprtokodno knjižnico, katere cilj je združiti napredek pri kodi mešanem NLP in jo odpreti širši skupnosti strojnega učenja. Knjižnica je sestavljena iz orodij za razvoj in primerjavo vsestranskih arhitektur modelov, ki so prilagojene mešanim besedilom, metod za razširitev naborov usposabljanja, tehnike za kvantifikacijo mešalnih slogov in prefinjenih najsodobnejših modelov za 7 nalog v hinglišu. Verjamemo, da ima to delo potencial za spodbujanje porazdeljenega, vendar sodelovalnega in trajnostnega ekosistema v sicer razpršenem prostoru raziskav mešanja kod. Komplet orodij je zasnovan tako, da je preprost, enostavno razširljiv in iznajdljiv tako za raziskovalce kot tudi za strokovnjake. Demo: http://k-ikkees.pc.cs.cmu.edu:5000 in knjižnica: https://github.com/murali1996/CodemixedNLP', 'ha': "Jami'in NLP na halarce mafariko mai rauni a cikin aikin dabam-dabam na mulki-harsunan na mutane. @ info: status Daga wannan aikin, Munã halatar da CodimikedNLP, littãfin da aka buɗe-maɓalli da goal da za'a samle kodi da kode-Mixed NLP kuma ke buɗe shi zuwa wani jami mai ƙaranci da za'a sani. Libraries na ƙunsa da zane-zane na develope kuma bangi masu motsi da misalin ayuka masu bastarwa da ake rubutu wa mistakardan misalin, shiryoyin su faɗaɗaɗe tsarin mai amfani da shiryarwa, ko masu kanana wa misãlai masu haɗi da, da misãlai-na-sanar wa aikin 7 cikin Higgish. Tuni yi ĩmãni da wannan aikin yana da wani mataimaki ya fosar a sami da samaki da wanda ke daɗi a cikin wani matsayi wanda aka rarraba littafin kodi-da-rarrabe. An designa zanen kayan aiki don ya zama mai sauƙi, mai sauƙi, kuma yana da amfani zuwa laban watafiti da masu amfani. Demo: http://k-ikkees.pc.cs.cmu.edu:5000  and Library:  https://github.com/murali1996/CodemixedNLP", 'bo': 'NLP མཐར་འཁྱོལ་འདི་དག་གི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དུ་ཆ་འཕྲིན་བརྗོད་པའི་སྐད་རིགས་ཀྱི་འབྲེལ་མཐུད་དང་མཉམ་དུ་བསྡུར་ན་ཁ་བརྗོད་ཡོད། In this work, we present CodemixedNLP, an open-source library with the goals of bringing together the advances in code-mixed NLP and opening it up to a wider machine learning community. The library consists of tools to develop and benchmark versatile model architectures that are tailored for mixed texts, methods to expand training sets, techniques to quantify mixing styles, and fine-tuned state-of-the-art models for 7 tasks in Hinglish. ང་ཚོས་ཀྱིས་ལས་འགན་འདིས་ཕན་ཚུན་བསྐྱེད་པའི་ནད་དོན་རྐྱེན་གྱིས་ཕན་ཚུན་ལས་ཕན་རྐྱེན་ཐབས་དང་རྒྱས་སྐྱོར་མེད་པའི་ཨ་ ལག་ཆ་སྒྲུབ་ནི་སྟབས་བདེ་བོ་ཞིག་བྱེད་རྒྱུ་དང་། ལས་སླ་པོ་ཞིག་ཆ་རྒྱ་བསྐྱེད་བྱེད་རྒྱུ་བྱས་མིན་པར། སྟོན་འཆར： http://k-ikkees.pc.cs.cmu.edu:5000 Last.fm https://github.com/murali1996/CodemixedNLP', 'he': 'The NLP community has witnessed steep progress in a variety of tasks across the realms of monolingual and multilingual language processing recently.  הצלחות האלה, ביחד עם אינטראקציות השפה המתורבות בתקשורת החברתית, גידלו את האינטרסין לדוגמא טקסטים מעורבים עם קוד. בעבודה הזו, אנו מציגים את CodemixedNLP, ספרייה מקור פתוח עם המטרות להביא ביחד את התקדמות במערכת קוד NLP ולפתוח את זה לקהילה לימוד מכונות רחבה יותר. הספרייה מורכבת מכשירים לפתח ולרמז ארכיטקטורות דוגמניות רבות שמתאימות לטקסטים מעורבים, שיטות להרחיב קבוצות אימונים, טכניקות לכוונת סגנונים מעורבים, ודוגמניות מצוינות לאומנות עבור 7 משימות בהינגליש. אנו מאמינים שלעבודה הזאת יש את הפוטנציאל לעודד מערכת אקולוגיה משותפת, אך שיתוף פעולה ובמיושרת במרחב אחר של מחקר מעורבב קודים. The toolkit is designed to be simple, easily extensible, and resourceful to both researchers as well as practitioners.  דמו: http://k-ikkees.pc.cs.cmu.edu:5000 וספרייה: https://github.com/murali1996/CodemixedNLP'}
{'en': 'Normalization and Back-Transliteration for Code-Switched Data', 'ar': 'التسوية والترجمة الخلفية للبيانات المشفرة بالشفرة', 'fr': 'Normalisation et rétro-translittération pour les données commutées par code', 'es': 'Normalización y retrotransliteración para datos con cambio de código', 'pt': 'Normalização e retrotransliteração para dados comutados por código', 'ru': 'Нормализация и обратная трансляция для данных с переключением кода', 'ja': 'コードスイッチされたデータの正規化と逆変換', 'hi': 'कोड-स्विच्ड डेटा के लिए सामान्यीकरण और बैक-लिप्यंतरण', 'zh': '代码易数规范化反音译', 'ga': 'Normalú agus Ais-Traslitriú le haghaidh Sonraí Cóid-Aistrithe', 'hu': 'Normalizáció és visszaátalakítás kódkapcsolt adatokhoz', 'ka': 'Name', 'el': 'Κανονικοποίηση και οπίσθια μεταγραφή δεδομένων με μεταγραφή κώδικα', 'it': 'Normalizzazione e retrotraslitterazione per i dati scambiati con codice', 'kk': 'Код ауыстырылған деректердің нормализациясы және артқа ауыстыру', 'ml': 'കോഡ്- മാറ്റുന്ന ഡേറ്റായുള്ള സാധാരണ ചെയ്യുന്നതും പിന്നില്\u200d മാറ്റുന്നതും', 'mk': 'Нормализација и назад транслитерација за податоци кои се префрлаат со код', 'lt': 'Kodu keičiamų duomenų normalizacija ir grįžtamoji transliteracija', 'mn': 'Код-өөрчлөгдсөн өгөгдлийн хувьд нормал болон буцаад-транслитераци', 'no': 'Name', 'pl': 'Normalizacja i wsteczna transliteracja danych przełączanych kodem', 'ms': 'Normalizasi dan Transliterasi Belakang untuk Data Bertukar-Kod', 'mt': 'Normalizzazzjoni u Trasliterazzjoni ta’ wara għal Dejta Mibdula bil-Kodiċi', 'ro': 'Normalizare și back-transliterare pentru date cu cod comutat', 'sr': 'Normalizacija i povratna transliteracija za zamijenjene podatke kod', 'si': 'Name', 'sv': 'Normalisering och bakåttranslitering för kodväxlade data', 'so': 'Waxbarashada kooxda-beddelka', 'ur': 'کوڈ-سوئچ ڈاٹ کے لئے عام اور پیچھے-ٹرانسلیٹر', 'ta': 'குறியீடு- மாற்றப்பட்ட தகவலுக்கான சாதாரண மாற்றுதல் மற்றும் பின் மொழிபெயர்ப்பு', 'uz': 'Comment', 'vi': 'Bộ lọc mã hóa', 'hr': 'Normalizacija i povratna transliteracija za podatke zamijenjene kod', 'nl': 'Normalisatie en back-transliteratie voor code-switched data', 'id': 'Normalization and Back-Transliteration for Code-Switched Data', 'de': 'Normalisierung und Rücktransliteration für Code-Switched Data', 'fa': 'ساده\u200cسازی و ترجمه\u200cسازی پشت برای داده\u200cهای تغییر کد', 'sw': 'Utafiti wa Ukawaida na Utafiri kwa ajili ya Taarifa za Kubadilishwa', 'tr': 'Mazmunlar üçin adaty we arka terjime etmek', 'ko': '코드 교환 데이터의 규범화와 반음역', 'sq': 'Normalizimi dhe transliteracioni prapa për të dhënat e ndryshuara me kod', 'am': 'undo-type', 'bg': 'Нормализация и обратна транслитерация за кодово превключени данни', 'da': 'Normalisering og tilbagetrækning af kodeskiftede data', 'az': 'Kod-dəyişdirilmiş məlumatlar üçün normal və geri-dəyişdirilməsi', 'bs': 'Normalizacija i povratna transliteracija za zamijenjene podatke kod', 'bn': 'কোড- পরিবর্তিত তথ্যের জন্য স্বাভাবিক এবং ব্যাক- ট্রান্সলেশন', 'cs': 'Normalizace a zpětná transliterace pro data přepínaná kódem', 'ca': 'Normalització i retro-transliteració de dades canviades de codi', 'et': 'Koodi vahetatud andmete normaliseerimine ja tagasitransliteratsioon', 'fi': 'Koodi-vaihdetun datan normalisointi ja takaisinkääntäminen', 'af': 'Normaliseering en terug- transliterasie vir kode- geskuif data', 'hy': 'Normalization and Back-Transliteration for Code-Switched Data', 'jv': 'Normal', 'sk': 'Normalizacija in pretvorba za podatke s preklopom kode', 'ha': 'KCharselect unicode block name', 'bo': 'སྔོན་སྒྲིག་དང་རྒྱབ་ལྗོངས་ཀྱི་གནས་ཚུལ་གསལ་བཤེར་བྱེད་ཀྱི་སྤྱིར་བཏང་བ', 'he': 'נורמליזציה וטרנסליטרציה אחורית עבור נתונים מחליפים קודים'}
{'en': 'Code-switching is an omnipresent phenomenon in multilingual communities all around the world but remains a challenge for NLP systems due to the lack of proper data and processing techniques. Hindi-English code-switched text on ', 'es': 'El cambio de código es un fenómeno omnipresente en las comunidades multilingües de todo el mundo, pero sigue siendo un desafío para los sistemas de PNL debido a la falta de datos y técnicas de procesamiento adecuadas. El texto de cambio de código hindi-inglés en las redes sociales a menudo se transcribe al alfabeto romano, lo que impide utilizar recursos monolingües disponibles en el alfabeto nativo devanagari. En este artículo, proponemos un método para normalizar y retrotranscribir el texto hindi-inglés con cambio de código. Además, presentamos una técnica de conversión de grafema a fonema (G2P) para datos hindi romanizados. También publicamos un conjunto de datos de oraciones con cambio de código hindi-inglés corregidas por guiones, etiquetadas para las tareas de reconocimiento de entidades nombradas y etiquetado de parte del discurso para facilitar la investigación posterior.', 'pt': 'A troca de código é um fenômeno onipresente em comunidades multilíngues em todo o mundo, mas continua sendo um desafio para os sistemas de PNL devido à falta de dados e técnicas de processamento adequados. O texto trocado por código hindi-inglês nas mídias sociais é frequentemente transliterado para o script romano, o que impede a utilização de recursos monolíngues disponíveis no script devanagari nativo. Neste artigo, propomos um método para normalizar e retrotransliterar texto hindi-inglês com troca de código. Além disso, apresentamos uma técnica de conversão grafema-fonema (G2P) para dados hindi romanizados. Também lançamos um conjunto de dados de frases trocadas por código Hindi-Inglês corrigidas por script rotuladas para o reconhecimento de entidade nomeada e tarefas de marcação de parte da fala para facilitar pesquisas adicionais.', 'ar': 'يعد تبديل الشفرة ظاهرة منتشرة في كل مكان في المجتمعات متعددة اللغات في جميع أنحاء العالم ولكنها لا تزال تمثل تحديًا لأنظمة البرمجة اللغوية العصبية بسبب نقص البيانات المناسبة وتقنيات المعالجة. غالبًا ما تتم ترجمة النص الهندي-الإنجليزي بتبديل الأكواد على وسائل التواصل الاجتماعي إلى النص الروماني مما يمنع استخدام الموارد أحادية اللغة المتوفرة في البرنامج النصي الديفاناغاري الأصلي. في هذه الورقة ، نقترح طريقة لتطبيع وترجمة النص الهندي-الإنجليزي بتبديل الشفرة إلى الوراء. بالإضافة إلى ذلك ، نقدم تقنية تحويل حروف الكتابة إلى الصوت (G2P) للبيانات الهندية بالحروف اللاتينية. نقوم أيضًا بإصدار مجموعة بيانات من الجمل المحولة بالشفرة الهندية والإنجليزية المصححة بالنصوص المصنفة لمهام التعرف على الكيان المحدد وعلامات جزء من الكلام لتسهيل إجراء مزيد من البحث.', 'fr': "Le changement de code est un phénomène omniprésent dans les communautés multilingues du monde entier mais reste un défi pour les systèmes de NLP en raison du manque de données et de techniques de traitement appropriées. Le texte à changement de code hindi-anglais sur les réseaux sociaux est souvent translittéré en écriture romaine, ce qui empêche d'utiliser les ressources monolingues disponibles dans le script natif devanâgarî. Dans cet article, nous proposons une méthode pour normaliser et rétro-translittérer le texte Hindi-Anglais commuté par code. De plus, nous présentons une technique de conversion graphème-phonème (G2P) pour les données hindi romanisées. Nous publions également un ensemble de données de phrases à commutation de code Hindi-Anglais corrigées par script et étiquetées pour les tâches de reconnaissance d'entités nommées et de marquage de partie du discours afin de faciliter les recherches ultérieures.", 'ja': 'コードスイッチングは、世界中の多言語コミュニティで普遍的な現象ですが、適切なデータと処理技術の欠如により、NLPシステムにとって依然として課題です。ソーシャルメディア上のヒンディー語と英語のコードスイッチされたテキストは、しばしばローマ字に音訳され、ネイティブのデーヴァナーガリー文字で利用可能な単一言語のリソースを利用することを妨げます。本稿では、コードスイッチされたヒンディー語と英語のテキストを正規化して逆変換する方法を提案する。さらに、ヒンディー語データのローマ字化のためのグラフィーム変換（ G 2 P ）技術をご紹介します。また、スクリプトで修正されたヒンディー語コードスイッチング文のデータセットをリリースし、さらに調査を容易にするため、名前付きエンティティ認識タグ付けタスクと音声の一部タグ付けタスクのラベルを付けています。', 'zh': '代码切换在世界各地多言社区中无所不在,然乏数术,NLP系一挑战。 社交媒体印地语 - 英语代码切换文本常音译为罗马文字,此止用本地梵文脚本中可用之单语资也。 本文中,发规范化反音译代码切换印地语 - 英语之法。 又为罗马化印地语数字素音素(G2P)转易。 发一脚本校正印地语 - 英语代码切换句之数集,名曰实体识词性,以趣研究。', 'hi': 'कोड-स्विचिंग दुनिया भर के बहुभाषी समुदायों में एक सर्वव्यापी घटना है, लेकिन उचित डेटा और प्रसंस्करण तकनीकों की कमी के कारण एनएलपी सिस्टम के लिए एक चुनौती बनी हुई है। सोशल मीडिया पर हिंदी-अंग्रेजी कोड-स्विच्ड टेक्स्ट को अक्सर रोमन लिपि में ट्रांसलिटरेट किया जाता है जो देशी देवनागरी लिपि में उपलब्ध मोनोलिंगुअल संसाधनों का उपयोग करने से रोकता है। इस पेपर में, हम कोड-स्विच्ड हिंदी-अंग्रेजी पाठ को सामान्य और बैक-ट्रांसलिटरेट करने के लिए एक विधि का प्रस्ताव करते हैं। इसके अलावा, हम रोमनीकृत हिंदी डेटा के लिए एक ग्राफेम-टू-फोनेम (जी 2 पी) रूपांतरण तकनीक प्रस्तुत करते हैं। हम आगे के शोध को सुविधाजनक बनाने के लिए नामित इकाई मान्यता और पार्ट-ऑफ-स्पीच टैगिंग कार्यों के लिए लेबल किए गए स्क्रिप्ट-सही हिंदी-अंग्रेजी कोड-स्विच्ड वाक्यों का डेटासेट भी जारी करते हैं।', 'ru': 'Переключение кода является вездесущим явлением в многоязычных сообществах по всему миру, но остается проблемой для систем NLP из-за отсутствия надлежащих данных и методов обработки. Хинди-английский текст в социальных сетях часто транслитерируется в римский шрифт, что не позволяет использовать одноязычные ресурсы, доступные в родном шрифте деванагари. В этой статье мы предлагаем метод нормализации и обратной транслитерации текста на хинди-английском языке. Кроме того, мы представляем метод преобразования графема в фонему (G2P) для латинизированных данных хинди. Мы также выпускаем набор скорректированных с помощью скриптов предложений с английским и хинди, обозначенных для задач распознавания сущностей и частичного тегирования речи, чтобы облегчить дальнейшие исследования.', 'ga': 'Is feiniméan uileláithreach é códmhalartú i bpobail ilteangacha ar fud an domhain ach tá sé fós ina dhúshlán do chórais NLP mar gheall ar an easpa sonraí cearta agus teicnící próiseála. Is minic a thraslitrítear téacs cód-aistrithe Hiondúis-Béarla ar na meáin shóisialta go dtí an script Rómhánach a chuireann cosc ar úsáid a bhaint as acmhainní aonteangacha atá ar fáil sa script dúchais Devanagari. Sa pháipéar seo, molaimid modh chun téacs Hiondúis-Béarla atá aistrithe cód a ghnáthú agus a ais-aistriú. Ina theannta sin, cuirimid teicníc tiontaithe grapheme-go-phoneme (G2P) i láthair do shonraí Rómhánacha Hiondúis. Eisímid freisin tacar sonraí d’abairtí cód-aistrithe Hiondúis-Béarla atá ceartaithe ag scripteanna atá lipéadaithe le haghaidh aitheantais aonáin ainmnithe agus tascanna clibeála cuid cainte chun tuilleadh taighde a éascú.', 'hu': 'A kódváltás mindenütt jelen van a többnyelvű közösségekben világszerte, de továbbra is kihívást jelent az NLP-rendszerek számára a megfelelő adatok és feldolgozási technikák hiánya miatt. A hindi-angol kódkapcsolt szöveget a közösségi oldalakon gyakran római írásra fordítják át, ami megakadályozza a Devanagari anyanyelvű források használatát. Ebben a tanulmányban javasoltunk egy módszert a kódkapcsolt hindi-angol szöveg normalizálására és visszafordítására. Ezenkívül bemutatunk egy graféma-fonéma (G2P) konverziós technikát romanizált hindi adatokhoz. További kutatások megkönnyítése érdekében kiadunk egy adatkészletet, amely a nevezett entitás felismeréséhez és beszédrész-címkézési feladatokhoz jelölt hindi-angol kódolt mondatokból áll.', 'el': 'Η αλλαγή κώδικα είναι ένα πανταχού παρόν φαινόμενο σε πολυγλωσσικές κοινότητες σε όλο τον κόσμο, αλλά εξακολουθεί να αποτελεί πρόκληση για τα συστήματα λόγω της έλλειψης κατάλληλων τεχνικών επεξεργασίας δεδομένων και δεδομένων. Το κείμενο που αλλάζει κώδικα στα μέσα κοινωνικής δικτύωσης συχνά μεταφράζεται στη ρωμαϊκή γραφή, γεγονός που εμποδίζει τη χρήση μονογλωσσικών πόρων που διατίθενται στη μητρική γραφή Devanagari. Σε αυτή την εργασία, προτείνουμε μια μέθοδο ομαλοποίησης και μεταγραφής κώδικα-αλλαγμένου κειμένου Χίντι-Αγγλικά. Επιπλέον, παρουσιάζουμε μια τεχνική μετατροπής γραφεμίου-σε-φωνήματος (G2P) για ρομαντικά δεδομένα Χίντι. Επίσης, κυκλοφορούμε ένα σύνολο δεδομένων από διορθωμένες από σενάρια ινδικά-αγγλικά προτάσεις που αλλάζουν κώδικα με ετικέτα για την αναγνώριση ονομαστικής οντότητας και τις εργασίες επισήμανσης μέρους της ομιλίας για να διευκολύνουμε περαιτέρω έρευνα.', 'ka': 'Code-switching is a omnipresent phenomenon in multilingual communities all around the world, but remains a challenge for NLP systems due to the lack of proper data and processing techniques. ჰინდი-ინგლისური კოდის შეცვლელი ტექსტი სოციალური მედიაში ხშირად ტრანგლიტურებულია რომელიც მონოლენგური რესურსების გამოყენებას, რომელიც მხოლოდ დეგანადარი სკრი ჩვენ ამ წიგნაში პროგრამის გადავიწყებთ ინდლისური ტექსტის ნორმალიზაცია და დაბრუნდეს ტექსტის შეცვლა. დამატებით, ჩვენ პრომანიზებული ჰინდის მონაცემებისთვის გრაფიმე-ტონემი (G2P) გადაწყვეტა ტექნოგია. ჩვენ ასევე განხორცით სკრიპტი-ანგლისური კოდის კოდის შეცვლელების მონაცემები, რომელიც სახელი ინტერტის განაცნობისთვის და სიტყვების ნაწილის მონაცემებისთვის მონაცემების დანაც', 'it': 'Il cambio di codice è un fenomeno onnipresente nelle comunità multilingue di tutto il mondo, ma rimane una sfida per i sistemi PNL a causa della mancanza di adeguate tecniche di elaborazione e dati. Il testo codificato hindi-inglese sui social media è spesso traslitterato nella scrittura romana che impedisce di utilizzare risorse monolingue disponibili nello script nativo Devanagari. In questo articolo, proponiamo un metodo per normalizzare e traslitterare il testo hindi-inglese con commutazione di codice. Inoltre, presentiamo una tecnica di conversione grafema-fonema (G2P) per i dati hindi romanizzati. Rilasciamo anche un set di dati di frasi in Hindi-Inglese corrette da script etichettate per il riconoscimento delle entità nominate e le attività di tag part-of-speech per facilitare ulteriori ricerche.', 'kk': 'Кодты ауыстыру - әлемдегі көп тілді қоғамдарында әлемдегі бірнеше пайда болады, бірақ NLP жүйелері дұрыс деректерді және өңдеу технологияларының жоқ тәртіпсіздігін себеп қалды. Ағылшын тілінде қолданылатын әлемдік медиақтардың хиндық кодын ауыстыру мәтіні көбінде Роман скриптіне ауыстырылады. Бұл жергілікті Деванагари скриптінде қолданылатын монолингі рес Бұл қағазда, біз инду-ағылшын мәтінді түрлендіру және қайта аудару әдісін таңдаймыз. Қосымша, біз романтизияланған хиндық деректер үшін графим-фонемде (G2P) аудару техникасын таңдаймыз. Мұндай-ағылшын тіркелген скриптті түзету мәліметтерді қолдану үшін қосымша зерттеулерді көмектесу үшін мәліметтерді анықтау және сөйлеу мәліметтерінің бір бөлігін қолдану үшін қолд', 'mk': 'Премената на кодови е сеопфатен феномен во мултијазичните заедници низ целиот свет, но останува предизвик за системите на НЛП поради недостатокот на соодветни податоци и техники за обработување. Хинди-англискиот текст на социјалните медиуми честопати се транслитерира во римскиот скрипт кој спречува користење на монојазичните ресурси достапни во домородниот скрипт Деванагари. Во овој весник предложуваме метод за нормализирање и префрлање на код на индианглиски. Покрај тоа, претставуваме техника на конверзија од графем до фоном (G2P) за романизирани индиски податоци. Исто така, објавуваме набор на податоци од индианглиски кодови променети со сценарија, означени за препознавањето на именуваниот ентитет и задачи за означување на дел од говорот за олеснување на понатамошното истражување.', 'lt': 'Kodų keitimas yra visuotinis daugiakalbėse bendruomenėse visame pasaulyje, tačiau dėl tinkamų duomenų ir apdorojimo metodų trūkumo NLP sistemoms tebėra iššūkis. Socialinės žiniasklaidos kodais pakeistas tekstas anglų kalba dažnai perskaičiuojamas į romėnų scenarijų, kuris neleidžia naudoti vienkalbių išteklių, turimų vietiniame Devanagario scenarijuje. Šiame dokumente siūlome metodą normalizuoti ir grįžtamai transliteracijai pakeisti kodu anglų kalba. Be to, pristatome grafimo-fonimo (G2P) konversijos metodą romanizuotiems Hindi duomenims. Mes taip pat paskelbiame duomenų rinkinį su raštu pataisytais Hindi ir anglų kodais pakeistais sakiniais, pažymėtais pavadintam subjektui pripažinti ir žodžio dalies ženklinimo užduotimis siekiant palengvinti tolesnius mokslinius tyrimus.', 'ms': 'Pertukaran kod adalah fenomena yang ada di seluruh komuniti berbilang bahasa di seluruh dunia tetapi tetap satu cabaran bagi sistem NLP kerana kekurangan data dan teknik pemprosesan yang tepat. Teks yang ditukar kod-bahasa Hindi pada media sosial sering ditukar ke skrip Roman yang mencegah daripada menggunakan sumber monobahasa yang tersedia dalam skrip Devanagari asli. Dalam kertas ini, kami cadangkan kaedah untuk normalisasi dan transliterasikan kembali kod-ditukar Hindi-Inggeris teks. Selain itu, kami memperkenalkan teknik konversi grafem-to-phoneme (G2P) untuk data Hindi romanisis. Kami juga melepaskan set data kalimat-kod-tukar bahasa Hindi-Inggeris yang diperbaiki skrip yang ditabel untuk pengenalan entiti bernama dan tugas-tugas-tag-ucapan untuk memudahkan penyelidikan lanjut.', 'ml': 'കോഡ് മാറ്റുന്നത് ലോകത്ത് മുഴുവന്\u200d പല ഭാഷയിലുള്ള സമൂഹങ്ങളില്\u200d ഒരു പ്രധാനപ്പെട്ട സംഭവം തന്നെയാണ്. പക്ഷെ ശരിയായ വിവരങ്ങളും പ്രവര്\u200dത്തിപ്പിക്ക സോഷ്യല്\u200d മാധ്യമങ്ങളില്\u200d ഹിന്ദി-ഇംഗ്ലീഷ് കോഡ് മാറ്റുന്ന പദാവലിയില്\u200d എപ്പോഴും റോമാന്\u200d സ്ക്രിപ്റ്റിലേക്ക് മാറ്റിയിരിക്കു ഈ പത്രത്തില്\u200d ഹിന്ദി-ഇംഗ്ലീഷ് ടെക്സ്റ്റ് ചെയ്തിരിക്കുന്ന കോഡ് സാധാരണമാക്കുകയും പിന്നില്\u200d ട്രാന്\u200dസ്ല കൂടാതെ, നമ്മള്\u200d ഒരു ഗ്രാഫീമില്\u200d നിന്നും ഫോണിമെന്\u200d (G2P) മാറ്റുന്ന സാങ്കേതികവിദ്യയുടെ റോമാനിസ് ഹിന്ദിയില പേരിട്ട വസ്തുവിന്റെ തിരിച്ചറിയുന്നതിനും വാക്കുകളുടെ ഭാഗവും ടാഗ്ഗിങ്ങ് ജോലികള്\u200dക്കും കൂടുതല്\u200d പരിശോധിപ്പിക്കാനുള്ള ശിക്ഷകള്\u200dക', 'no': 'Kodebyting er eit alltidlegare fenomen i fleirspråk fellesskap i verden, men er forbetra eit utfordring for NLP-systemet på grunn av mangling av riktige data og handsamingsteknikk. Hindi-engelsk kode-bytt tekst på sosialmedia er ofte translitert til romskriptet som hindrar å bruka monospråk ressursar tilgjengelege i den native Devanagari- skriptet. I denne papiret foreslår vi ein metode for å normalisera og tilbake translitera kode med hindisk- engelsk tekst. I tillegg presenterer vi ein konverteringsteknik for romanisert hindiske data for grafem-til-foneme (G2P). Vi gjev også ein dataset med skriptkorrigerte hindisk-engelsk kode-bytt setningar som er merket for den namnet entitetskjenninga og delvis tale-merking av oppgåver for å gjera framtidige forskning.', 'pl': 'Przełączanie kodu jest wszechobecnym zjawiskiem w społecznościach wielojęzycznych na całym świecie, ale pozostaje wyzwaniem dla systemów NLP ze względu na brak odpowiednich technik danych i przetwarzania. Hindi-angielski tekst przełączony kodem w mediach społecznościowych jest często transliterowany na skrypt rzymski, co uniemożliwia wykorzystanie jednojęzycznych zasobów dostępnych w natywnym skryptie Devanagari. W niniejszym artykule proponujemy metodę normalizacji i wstecznej transliteracji tekstu hindi-angielskiego. Ponadto przedstawiamy technikę konwersji grafem-fonem (G2P) dla zromanizowanych danych hindi. Udostępniamy również zestaw danych skorygowanych skryptowo-angielskich zdań przełączanych kodem hindi-angielskim oznaczonych dla rozpoznawania nazwanych jednostek i tagowania części mowy, aby ułatwić dalsze badania.', 'mn': 'Кодын өөрчлөлт бол дэлхийн олон хэл нийгмийн бүх нийгмийн олон хэлний явдал юм. Гэхдээ NLP системийн зорилго нь зөв өгөгдлийн болон үйлдвэрлэлийн техникуудын алдаагүй болохоор байдаг. Хинди-Англи хэлний кодыг нийгмийн хэвлэлийн мэдээллийн хувьд өөрчлөгдсөн текст ихэвчлэн Ромын скрипт руу орлуулагддаг. Энэ нь дотор Деванагари скрипт дээр ганц хэлний баялаг ашиглах боломжгүй. Энэ цаасан дээр бид хинди-Англи хэлний текст өөрчлөгдсөн, эргээд хэлбэртэй код шилжүүлэх арга зам санал өгдөг. Үүнээс гадна бид романзын Хинди өгөгдлийн графим-фонем (G2P) шилжүүлэлтийн техник үзүүлнэ. Бид мөн өөрсдийн нэрлэгдсэн бүтэц таних болон ярианы нэг хэсэг нь илүү судалгааг дэмжихийн тулд өөрчлөгдсөн хинди-англи хэлний кодыг зөвшөөрүүлсэн өгүүлбэрүүдийг хэвлүүлнэ.', 'ro': 'Schimbarea codurilor este un fenomen omniprezent în comunitățile multilingve din întreaga lume, dar rămâne o provocare pentru sistemele PNL din cauza lipsei unor tehnici adecvate de prelucrare a datelor. Textul schimbat de cod hindi-engleză pe rețelele de socializare este adesea transliterat în scriptul roman, ceea ce împiedică utilizarea resurselor monolingve disponibile în scriptul nativ Devanagari. În această lucrare, propunem o metodă de normalizare și transliterare înapoi a codului comutat Hindi-Engleză text. În plus, vă prezentăm o tehnică de conversie graf-fonem (G2P) pentru datele hindi romanizate. De asemenea, lansăm un set de date de propoziții corectate în limba engleză-hindi corectate de script, etichetate pentru recunoașterea entităților denumite și sarcini de etichetare parțială a vorbirii, pentru a facilita cercetarea ulterioară.', 'sr': 'Prebacivanje kodova je svedočan fenomen u multijezičkim zajednicama širom svijeta, ali ostaje izazov za NLP sisteme zbog nedostatka pravih podataka i tehnika obrade. Hindi-engleski kodirani tekst na društvenim medijima često se transliteracija na rimski skript koji sprečava iskoristiti monojezičke resurse dostupne u domaćem Devanagarijskom skriptu. U ovom papiru predlažemo metodu da normaliziramo i transliteralno prebacimo Hindi-engleski tekst. Osim toga, predstavljamo tehniku preobraćanja grafema na foneme (G2P) za romanizirani hindski podaci. Takoðe objavljujemo podatke o skripta ispravljenim rečenicama za prebacivanje indijskog-engleskog koda označene za priznanje entiteta i ulogu govornog označavanja zadataka za olakšanje daljnjih istraživanja.', 'so': 'Codeynta beddelka waa wax la mid ah oo ku saabsan bulshada luuqadaha kala duduwan ee adduunka oo dhan, laakiin waxaa hadhay dhibaato u ah nidaamka NLP sababtoo ah baahida macluumaad saxda ah iyo qalabka baaraandegista. Inta badan waxaa warqada qoraalka sooshaalka ah lagu qoraa warqada qoyska Rooma ee ka hor jeeda isticmaalka hantida afka hooyo ee dhaqaalaha ah ee ku jira karraaniga Devanagari. Qoraalkan waxaynu soo jeedinnaa qaab aan ku caadi karno iyo dib-u-dhigno qoraalka warqadda Hindi-Ingiriis-beddelan. Intaas waxaa dheer, waxaynu soo bandhignaa teknikada bedelka ee sawirka (G2P). Sidoo kale waxaynu bixinnaa qoraal macluumaad ah oo lagu hagaajiyey qodob-hab-Ingiriis ah oo lagu qoray aqoonsashada entity iyo qeyb ka mid ah hadalka, si loo fududeeyo waxbarasho dheeraad ah.', 'sv': 'Kodväxling är ett allestädes närvarande fenomen i flerspråkiga samhällen runt om i världen, men är fortfarande en utmaning för NLP-system på grund av bristen på lämplig data och behandlingsteknik. Hindi-engelska kodväxlad text på sociala medier translittereras ofta till det romerska skriptet vilket hindrar från att använda enspråkiga resurser som finns tillgängliga i det infödda Devanagari skriptet. I denna uppsats föreslår vi en metod för att normalisera och bakåttranslitera kodväxlad hindi-engelsk text. Dessutom presenterar vi en grafem-till-fonem (G2P) omvandlingsteknik för romaniserade hindi data. Vi släpper också en dataset med skriptkorrigerade hindi-engelska kodväxlade meningar märkta för namngivna entitetsigenkänning och del-av-tal taggande uppgifter för att underlätta vidare forskning.', 'ta': 'குறிமுறைமாற்றம் உலகம் முழுவதும் பல மொழிக்கூட்டத்தில் ஒரு பொதுவான நிகழ்வு உள்ளது ஆனால் NLP அமைப்புகளுக்கு சரியான தகவல் மற்றும் செயல்படுத்து இந்தி- ஆங்கிலத்தின் குறியீடு மாற்றப்பட்ட உரையை சார்ந்த ஊடகங்களில் பெரும்பாலும் ரோமான் சிறுநிரலுக்கு மாற்றியமைக்கப்படுகிறது.  இந்த காகிதத்தில், நாம் சாதாரண மற்றும் பின் மாற்றும் குறியீடு- மாற்றப்பட்ட Hindi- ஆங்கிலம் உரை In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data.  நாம் மற்றும் பெயரிடப்பட்ட பொருள் அடையாளம் மற்றும் பேச்சு குறியீட்டு வாக்கியங்களுக்கு குறிப்பிட்ட தகவல் அமைப்பை வெளியிடுகிறோம். அத', 'ur': 'کیڈ-سوچینگ دنیا میں بہت سی زبان کی کمونٹیوں میں ایک موجود فنا ہے لیکن NLP سیسٹموں کے لئے ایک چالیٹ رہتا ہے اس وجہ سے کہ انصاف ڈیٹا اور پرسس ٹیکنیک کم ہونے کی وجہ سے۔ ہینڈی-انگلیسی کوڈ-سوسیلی میڈیا پر متصلہ ہوا متصلہ اکثر رومین سکرپٹ پر ترجمہ کیا جاتا ہے جو ملک دیوانگاری سکرپٹ میں موجود موجود موجود ایک زبان کے منبع استعمال کرنے سے منع کرتا ہے. اس کاغذ میں ہم ایک طریقہ پیش کریں کہ ہینڈی انگلیسی متن کو عام اور پیچھے ٹرانسلیٹ کا کوڈ بدل دیا جائے۔ اس کے علاوہ ہم ایک گرافیمیٹ-ٹ-فونیم (G2P) کی تبدیل تکنیک پیش کرتے ہیں۔ ہم نے اسکریپٹ سیدھی انگلیسی کڈ سیدھی ڈیٹ سٹ کو بھی آزاد کردیا ہے جس کے نام کے ذریعہ ایک چیز شناسایی اور ایک حصہ کی بات ٹاگ کرنے کے لئے اضافہ کرنے کے لئے لکھا ہوا ہے۔', 'si': 'කෝඩ් වෙනස් කරන්නේ ලෝකයේ විශේෂ භාෂාවක් සමාජාත්මකයේ සාමාන්\u200dය ප්\u200dරදේශයක් තියෙනවා නමුත් NLP පද්ධතියට අවශ්\u200dය වෙන් හින්දි-ඉංග්\u200dරීසි කෝඩ් වෙනස් පාළුව සාමාජික මාධ්\u200dයමයේ සාමාජික ස්ක්\u200dරිප්ට් එක්ක භාෂාවක් ප්\u200dරයෝජනය කරන්න බැ මේ පත්තරේ අපි ප්\u200dරවේශයක් සාමාන්\u200dය සහ පස්සේ පාර්ථාපනය කරන්න හින්දී ඉංග්\u200dරීසි පාළුවක් වෙනස් කරනවා. ඒ වගේම, අපි හින්දි දත්ත සඳහා ග්\u200dරාෆේම් එක්ක ෆෝනේම් එක්ක (G2P) වෙනස් තාක්ෂණයක් පෙනුම් කරනවා. අපි තියෙන්නේ ස්ක්\u200dරිප්ට්-ඉංග්\u200dරීසි කෝඩ් සැකසුම් දත්ත සැකසුමක් ප්\u200dරකාශ කරනවා නම් අයිතිය අඳුරණය සහ කතාවේ කොටස් ටැග් ක', 'mt': 'Il-bidla tal-kodiċi hija fenomenu omnipresenti fil-komunitajiet multilingwi madwar id-dinja kollha iżda tibqa’ sfida għas-sistemi NLP minħabba n-nuqqas ta’ tekniki xierqa ta’ dejta u pproċessar. It-test li jinbidel bil-kodiċi Indjan-Ingliż fuq il-midja soċjali spiss jiġi traslitterat għall-kitba Rumena li ma tħallix juża r-riżorsi monolingwi disponibbli fil-kitba tad-Devanagari nattiva. In this paper, we propose a method to normalize and back-transliterate code-switched Hindi-English text.  Barra minn hekk, qed nippreżentaw teknika ta’ konverżjoni grafeme-to-phoneme (G2P) għad-dejta Indjana romanizzata. Aħna nirrilaxxaw ukoll sett ta’ dejta ta’ sentenzi kkoreġuti bil-kodiċi Indjan-Ingliż ikkoreġuti bil-kitba ttikkettati għar-rikonoxximent tal-entità msejħa u kompiti ta’ tikkettar ta’ parti mid-diskors biex tiġi ffaċilitata aktar riċerka.', 'vi': 'Bộ chuyển đổi mã là một hiện tượng hiện đại ở khắp mọi nơi trên thế giới, nhưng vẫn là một thử thách cho hệ thống Njala vì thiếu kỹ thuật cung cấp dữ liệu và xử lý thích đáng. Thông tin truy cập mật mã của tiếng Ấn (tiếng Hindi) được chuyển dạng thành văn bản La Mã. Như vậy không thể tận dụng các nguồn tài nguyên ngôn ngữ học trong văn lệnh Deva. Trong tờ giấy này, chúng tôi đề nghị một phương pháp bình thường và sửa lại đoạn mã đã tráo đoạn tiếng Ấn. Thêm vào đó, chúng tôi giới thiệu kỹ thuật chuyển đổi graphheme-to-phoneme (G2P) cho dữ liệu tiếng Hindi (La hoá). Chúng tôi cũng phát hành một tập tin về các câu ghi lỗi bằng tiếng Hindi và những câu ghi chú cho thực thể được gọi là nhận diện, và các nhiệm vụ in dấu riêng của giọng nói để tìm hiểu thêm.', 'uz': "Koda o'zgartirish dunyodagi bir til jamiyatlarda ko'p narsa bo'lgan narsalar, lekin NLP tizimlari uchun juda yaxshi maʼlumot va boshqarish tugmalari yoʻq sababda davom etadi. Name Bu hujjatda, biz Hindi- Ingliz tilini o'zgartirish va orqaga tarjima qilish usulini tahlil qilamiz. Ko'pchilik, biz romaniya Hindi maʼlumotlari uchun grammatika (G2P) ta'minlovchi texnologiya. Biz quyidagi obʼektlarni aniqlash va gapirish orqali qismlarini foydalanish uchun oʻzgartirilgan Hindi- Ingliz kodi- oʻzgartirilgan so'zlar tarkibini chiqarishmiz.", 'hr': 'Prebacivanje kodeksa je svjetski trenutni fenomen u multijezičkim zajednicama širom svijeta, ali ostaje izazov za sustave NLP zbog nedostatka pravih podataka i tehnika obrade. Hindi-engleski kodirani tekst na društvenim medijima često se transliteracija na rimski skript koji sprječava iskoristiti monojezičke resurse dostupne u domaćem Devanagarskom skriptu. U ovom papiru predlažemo metodu normaliziranja i transliteratnog koda zamijenjenog hindskim engleskim tekstom. Osim toga, predstavljamo tehniku preobraćanja grafema na foneme (G2P) za romanizirane hindske podatke. Također objavljujemo skup podataka o skriptakorekcijama indijskih-engleskih rečenica koje su zamijenile kodiranim rečenicama označene za priznanje entiteta i ulogu govora označavanja zadataka za olakšanje daljnjih istraživanja.', 'nl': 'Code-switching is een alomtegenwoordig fenomeen in meertalige gemeenschappen over de hele wereld, maar blijft een uitdaging voor NLP-systemen vanwege het ontbreken van juiste data- en verwerkingstechnieken. Hindi-Engelse code-switched tekst op sociale media wordt vaak getranslitereerd naar het Romeinse schrift, wat voorkomt dat monolinguale bronnen beschikbaar zijn in het native Devanagari script. In dit artikel stellen we een methode voor om code-switched Hindi-Engelse tekst te normaliseren en terug-translitreren. Daarnaast presenteren we een grafeem-naar-foneem (G2P) conversietechniek voor geromaniseerde Hindi gegevens. We geven ook een dataset van scriptgecorrigeerde Hindi-Engels code-switched zinnen uit die gelabeld zijn voor de benoemde entiteitsherkenning en part-of-speech tagging taken om verder onderzoek te vergemakkelijken.', 'da': 'Kodeskift er et allestedsnærværende fænomen i flersprogede samfund over hele verden, men er fortsat en udfordring for NLP-systemer på grund af manglen på ordentlige data- og behandlingsteknikker. Hindi-engelsk kodeskiftet tekst på sociale medier er ofte translittereret til det romerske script, hvilket forhindrer i at udnytte ensprogede ressourcer tilgængelige i det indfødte Devanagari script. I denne artikel foreslår vi en metode til at normalisere og tilbage-transliterere kode-skiftet hindi-engelsk tekst. Derudover præsenterer vi en grafem-til-fonem (G2P) konverteringsteknik til romaniserede hindi data. Vi frigiver også et datasæt af scriptkorrigerede hindi-engelske kodekoblingssætninger mærket til navngivne entitetsgenkendelse og dele af tale tagging opgaver for at lette yderligere forskning.', 'id': 'Pertukaran kode adalah fenomena yang luas di masyarakat berbagai bahasa di seluruh dunia tapi tetap tantangan bagi sistem NLP karena kekurangan data dan teknik proses yang tepat. Teks yang ditukar kode bahasa Hindi pada media sosial sering diubah ke skrip Roma yang mencegah menggunakan sumber daya monobahasa yang tersedia dalam skrip Devanagari asli. Dalam kertas ini, kami mengusulkan metode untuk normalisasi dan kembali-transliterasi kode-ditukar Hindi-Inggris teks. In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data.  Kami juga melepaskan set data dari kalimat yang diubah kode Hindi-Inggris yang disebut untuk pengenalan entitas bernama dan tugas tagging bagian dari pidato untuk memudahkan penelitian lanjut.', 'fa': 'تغییر قانونی یک پدیده\u200cای در جامعه\u200cهای زیادی زبان در سراسر جهان است ولی به دلیل ناتوانی داده\u200cهای مناسب و تکنیک\u200cهای پردازی برای سیستم\u200cهای NLP چالش باقی ماند. متن تغییر داده شده از کد انگلیسی هندی و انگلیسی در رسانه های اجتماعی اغلب به نوشته رومی ترجمه می شود که مانع استفاده از منابع تنها زبان در نوشتهٔ دیوانگاری متحده می شود. در این کاغذ، ما یک روش پیشنهاد می\u200cدهیم که متن هندی-انگلیسی را به عنوان رمز\u200cنویسی و برگشتن\u200cنویسی تغییر دهیم. علاوه بر این، ما یک تکنیک تبدیل گرافیم به فونیم (G2P) برای داده های هندی رومانی را پیشنهاد می\u200cکنیم. ما همچنین یک مجموعه داده ای از مجموعه\u200cهای رمز اصلاح\u200cشده\u200cی رمز\u200cهای کد تغییر\u200cشده\u200cی هندی-انگلیسی را آزاد می\u200cکنیم که برای شناسایی شناسایی عنوان و پاره\u200cای از نشان\u200cدهنده\u200cی کلمات برای آسانی تحقیقات بیشتری', 'sw': 'Mabadiliko ya sheria ni hali ya sasa katika jamii za lugha mbalimbali duniani kote lakini bado ni changamoto kwa mfumo wa NLP kutokana na ukosefu wa taarifa sahihi na mbinu za uchunguzi. Uandishi wa kodi ya Kiingereza mara nyingi unasambazwa kwenye mitandao ya kijamii nchini Kihindi na Kiingereza kwa kutumia rasilimali za kifedha zinazopatikana katika script ya Devanagari ya asili. Katika karatasi hii, tunapendekeza njia ya kurekebisha na kubadilisha maneno ya Kiingereza ya Kihindi-Kiingereza. In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data.  Pia tunatoa seti ya taarifa ya maandishi yanayosahihishwa kwa mfumo wa maneno yanayobadilishwa kwa Kihindi-Kiingereza yaliyoitwa kutambuliwa kwa entity na sehemu ya kazi za kupiga maneno ili kusaidia tafiti zaidi.', 'bg': 'Превключването на кодове е всеприсъстващо явление в многоезичните общности по целия свят, но остава предизвикателство за системите за НЛП поради липсата на подходящи техники за обработка на данни и данни. Хинди-английски кодов текст в социалните медии често се транслитерира към римската писменост, което пречи да се използват едноезични ресурси, налични в родния деванагари. В настоящата статия предлагаме метод за нормализиране и обратно транслитерация на кодово превключен хинди-английски текст. В допълнение, представяме технология за преобразуване графем-в-фонем (Г2П) за романизирани хинди данни. Ние също така публикуваме набор от данни от коректирани със скрипт хинди-английски кодови изречения, етикетирани за разпознаване на наименованите субекти и задачи за маркиране на част от речта, за да улесним по-нататъшните изследвания.', 'af': "Kode-wisseling is 'n allepresent fenomen in multilinglike gemeenskappe rondom die wêreld, maar bly 'n uitdrukking vir NLP stelsels vanweë die ontbreek van regte data en verwerking tekenieke. Hindi-Engels-kode-geskuif teks op sosiale media is dikwels transliterateer na die Romeine skrip wat voorkom om monolinglike hulpbronne te gebruik wat beskikbaar is in die native Devanagari skrip. In hierdie papier, voorstel ons 'n metode om Hindi-Engels teks te normaliseer en terugtransliterate kode te wissel. In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data. Ons verlos ook 'n datastel van skrip korrigeerde Hindi-Engels-kode-verwysigde setinge wat gemerk word vir die naamde entiteiterkenning en deel-van-spraak-merking opdragte om verdere ondersoek te maak.", 'ko': '코드 전환은 세계 각지의 다국어 지역사회에서 보편적으로 존재하는 현상이지만 적당한 데이터와 처리 기술이 부족하기 때문에 여전히 NLP 시스템이 직면한 도전이다.소셜 미디어의 인디언-영어 코드 변환 텍스트는 보통 로마 문자로 음역되는데 이는 모국어인 데바나가리 문자에서 사용할 수 있는 단어 자원 사용을 방해한다.본고는 인디언 영어 텍스트를 규범화하고 반음역 코드로 변환하는 방법을 제시했다.이 밖에 로마화 인디언 데이터에 사용되는 자형에서 음소(G2P)로 전환하는 기술도 제시했다.우리는 또한 실체 식별과 어성 표기 임무를 명명하는 데 사용되는 스크립트를 발표하여 더욱 연구하기 편리하도록 지어-영어 코드 변환 문장 데이터 집합을 발표했다.', 'de': 'Code-Switching ist ein allgegenwärtiges Phänomen in mehrsprachigen Communities auf der ganzen Welt, bleibt aber eine Herausforderung für NLP-Systeme aufgrund des Fehlens geeigneter Daten- und Verarbeitungstechniken. Hindi-englischer Code-Switched Text in sozialen Medien wird oft in die römische Schrift übersetzt, was verhindert, dass monolinguale Ressourcen verwendet werden, die in der nativen Devanagari-Schrift verfügbar sind. In diesem Beitrag schlagen wir eine Methode vor, um code-switched Hindi-English Text zu normalisieren und zurück-transliteraeren. Darüber hinaus stellen wir eine Graphem-zu-Phonem (G2P) Umwandlungstechnik für romanisierte Hindi Daten vor. Wir veröffentlichen auch einen Datensatz von skript-korrigierten Hindi-Englisch kodierten Sätzen, die für die Erkennung benannter Entitäten und Tagging-Aufgaben markiert sind, um weitere Forschungen zu erleichtern.', 'am': 'የኮድ መለወጥ በዓለም ሁሉ በብዙ ቋንቋዎች ማኅበረሰቦች ላይ የተደረገው ነገር ነው ነገር ግን የተሻለ ዳታ እና ማቀናቀል ስህተት ስህተት ስህተት ስህተት ጥላቻ ነው፡፡ የHindi-እንግሊዘኛ ጽሑፍ ማኅበራዊ ማኅበራዊ አውታር ላይ የተለወጠውን ጽሑፍ በብዙ ጊዜ ወደ ሮማዊ ጽሑፍ ይዘረዝራል፡፡ በዚህ ካላት፣ የHindi-እንግሊዘኛ ጽሑፍ ማቀናቀል እና ወደ ጀርባ መተላለፊያ የኮድ ጽሑፍ ማቀናቀል እናስጀምራለን፡፡ በተጨማሪም የሄንዲ ዳታዎች ለሮማኒያ የፊደል ስልክ (G2P) የተለወጠውን ቴክኖክን እናቀርባለን፡፡ አካባቢው ማስታወቂያ እና የንግግር ማቀናጃ ማሰናከል የሚደረገውን የኪንዲ-እንግሊዝኛ ቃላት የጽሑፍ ዳታ ማቀናጃ እናደርጋለን፡፡', 'hy': 'Կոդի փոխակերպումը բազմալեզու համայնքներում ամբողջ աշխարհում գոյություն ունի բազմալեզու երևույթ, բայց շարունակում է մարտահրավեր ՆԼՊ համակարգերի համար, որովհետև ճիշտ տվյալներ և վերամշակման տեխնիկաներ բացա Հինդի-անգլերեն կոդի փոխանցված տեքստը սոցիալական լրատվամիջոցների վրա հաճախ վերագրվում է ռոմեական գրքի վրա, որը կանխում է օգտագործել միալեզու ռեսուրսներ, որոնք հասանելի են բնիկ Դեվանագրի գրքում: Այս թղթի մեջ մենք առաջարկում ենք նորմալ և վերագրել անգլերեն-հինդի տեքստի փոխարեն: In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data.  Մենք նաև հրապարակում ենք մի համակարգ տվյալների, որոնք կարգավորված են շինդի-անգլերենի կոդի փոխարինվող նախադասություններով, որոնք պիտակում են անվանված էության ճանաչելու և խոսքի մասի պիտակումների համար, որպեսզի ավելի հեշտ լինի', 'bn': 'কোড পরিবর্তন হচ্ছে সারা বিশ্বের বহুভাষী সম্প্রদায়ের মধ্যে একটি অসম্পূর্ণ ঘটনা, কিন্তু এনএলপি সিস্টেমের জন্য একটি চ্যালেঞ্জ রয়েছে যা সঠিক তথ্য সামাজিক প্রচার মাধ্যমে হিন্দি-ইংরেজী কোড-পরিবর্তনের লেখা প্রায়শই রোমান স্ক্রিপ্টের কাছে ট্রান্সলিট করা হয়েছে যা স্থানীয় দেভ এই কাগজটিতে আমরা একটি পদ্ধতি প্রস্তাব করছি যাতে স্বাভাবিক এবং পিছনে ট্রান্সলিটার করা কোড পরিবর্তন করা হিন্দি ইংরেজি লে এছাড়াও, আমরা একটি গ্রাফিম-থেকে ফোনেম (জি২পি) রোমানিয়াল হিন্দি তথ্যের জন্য পরিবর্তনের প্রযুক্তি উপস্থাপন করি। আমরা স্ক্রিপ্ট-সংশোধনী হিন্দি-ইংরেজি কোড-পরিবর্তনের একটি ডাটাসেট মুক্তি দিচ্ছি যারা নামের বস্তুর স্বীকৃতি এবং ভাষণের অংশের বাক্য', 'bs': 'Prebacivanje kodova je svečan fenomen u multijezičkim zajednicama širom svijeta, ali ostaje izazov za NLP sisteme zbog nedostatka pravih podataka i tehnika obrade. Hindski-engleski kodirani tekst na društvenim medijima često se transliteracija na rimski skript koji sprječava iskoristiti monojezičke resurse dostupne u domaćem Devanagarijskom skriptu. U ovom papiru predlažemo metodu da normaliziramo i transliteralno zamijenimo hindski engleski tekst. Osim toga, predstavljamo tehniku preobraćanja grafema na fonemu (G2P) za romanizirane hindske podatke. Također objavljujemo komplet podataka o skripta ispravljenim indijskim-engleskim rečenicama koje su zamijenile kodiranim rečenicama označene za priznanje entiteta i ulogu govornog označavanja zadataka kako bi olakšali daljnje istraživanje.', 'az': 'Kod-değiştirmək dünyanın hər tərəfində çoxlu dil toplumlarında hər hansı bir fenomendir, amma NLP sistemlərinin düzgün məlumatları və işləmə teknikləri yoxdur. Hindi-İngilizce kodu ilə sosyal mediyalarda dəyişdirilmiş mətn çox zaman, yerli Devanagari skriptlərində mövcud olan monodil kaynaqlarını istifadə etməyə mane olur. Bu kağızda, Hindi-İngilizce metinlərini normalizə və geri-transliterat kodla dəyişdirmək üçün bir yol təklif edirik. Əvvəlcə biz romanizlənmiş Hindi məlumatları üçün grafik-to-foneme (G2P) dönüş teknikini göstəririk. Biz də indi-İngilizce kodu düzəltmiş verilən cümlələrin verilənlərin bir quruluğunu daha çox araştırma olaraq işarə yaratmaq üçün etiketləndirdik.', 'cs': 'Přepínání kódu je všudypřítomným jevem v mnohojazyčných komunitách po celém světě, ale zůstává výzvou pro NLP systémy vzhledem k nedostatku správných dat a technik zpracování. Hindština-anglický kódový text na sociálních médiích je často translitován do římského písma, což zabraňuje využívání jednojjazyčných zdrojů dostupných v nativním Devanagari písma. V tomto článku navrhujeme metodu normalizace a zpětné transliterace kódově přepínaného hindsky-anglického textu. Kromě toho představujeme metodu konverze grafému na foném (G2P) pro romantizovaná hindština data. Také vydáváme datovou sadu skriptově opravených hindsky-anglických kódových vět označených pro rozpoznávání pojmenovaných entit a tagování části řeči, abychom usnadnili další výzkum.', 'tr': 'K철d almak 첵eri d체n첵채de birn채챌e dilli jemgy첵etlerde bir 채hli wagt g철r체n첵채r, 첵철ne NLP sistemalary 체챌in dogry maglumat we i힊le첵채n teknikleri흫 첵ok bolmagyny흫 seb채bi kyn챌ylyk bar. Hindi-I흫lis챌e sosyal med첵채d채ki metinlerde 체첵tgedilen metin k철plen챌 Roma skriptine terjime edil첵채r. Bu 첵eke Devanagari skriptde 첵erle힊첵채n monodil 챌e힊melerini ulanmakdan 챌ykar첵ar. Bu kagyzda Hindi-i흫lis챌e metini d체zenlemek we arkadan terjime etmek 체챌in bir y철ntem teklip ber첵채ris. 횥stelik, biz Hindiler maglumatlary 체챌in grafime-to-foneme (G2P) 체첵tgetmek teknikini g철rke첵채ris. Biz hem di첵ip atlandyryl첵an bir skript d체zg체n Hindi-i흫lis챌e c철dlemeleri 체챌in etiket edilen sanlary we g체rr체흫leri흫 bir b철l체mi di첵ip atlandyrdyk.', 'fi': 'Koodinvaihto on kaikkialla maailmassa esiintyvä ilmiö monikielisissä yhteisöissä, mutta on edelleen haaste NLP-järjestelmille asianmukaisten tietojen ja käsittelytekniikoiden puutteen vuoksi. Hindi-englanti koodattu teksti sosiaalisessa mediassa on usein transliteroitu roomalaiseen kirjoitusmuotoon, mikä estää käyttämästä yksikielisiä resursseja, jotka ovat saatavilla Devanagari-skriptissä. Tässä työssä ehdotamme menetelmää koodilla vaihdetun hindi-englanninkielisen tekstin normalisoimiseksi ja takaisin transliteroimiseksi. Lisäksi esittelemme grafeemi-foneemi (G2P) -muuntotekniikan romanisoituun hindi-aineistoon. Julkaisemme myös aineiston käsikirjoituksella korjatuista hindi-englantilaisista koodinvaihtolauseista, jotka on merkitty nimetyn entiteetin tunnistukseen ja puheen osamerkintätehtäviin lisätutkimuksen helpottamiseksi.', 'sq': 'Ndryshimi i kodeve është një fenomen omnipresent në komunitetet shumëgjuhësore anembanë botës por mbetet një sfidë për sistemet NLP për shkak të mungesës së të dhënave të duhura dhe teknikave të përdorimit. Teksti i ndryshuar nga kodi anglez në media sociale shpesh transliteratohet në skriptin romak që pengon nga përdorimi i burimeve monogjuhësore në dispozicion në skriptin e Devanagarit. Në këtë letër, ne propozojmë një metodë për të normalizuar dhe transliteratur kodin në gjuhën angleze. Përveç kësaj, ne paraqesim një teknikë konversimi grafik-në-fonem (G2P) për të dhënat e romanizuara Hindi. Ne lëshojmë gjithashtu një sërë të dhënash të fjalëve të korrigjuara me kod Hindi-Anglisht me etiketë për njohjen e emëruar të njësisë dhe detyrat e etiketës pjesë-e-fjalimi për të lehtësuar kërkimin e mëtejshëm.', 'et': 'Koodi vahetamine on kõikjal esinev nähtus mitmekeelsetes kogukondades üle kogu maailma, kuid nõuetekohaste andmete ja töötlemismeetodite puudumise tõttu on uue tööprogrammi süsteemide jaoks jätkuvalt probleem. Hindi-inglise koodvahetatud tekst sotsiaalmeedias on sageli translitereeritud Rooma skripti, mis takistab ühekeelsete ressursside kasutamist emakeelses Devanagari skriptis. Käesolevas töös pakume välja meetodi normaliseerimiseks ja tagasitranslitereerimiseks koodiga vahetatud hindi-inglise teksti. Lisaks esitame grafeem-foneem (G2P) muundamise tehnikat romaniseeritud hindi andmete jaoks. Lisaks avaldame andmekogumi skriptidega parandatud hindi-inglise koodiga vahetatud lausetest, mis on märgistatud nimetatud olemi tuvastamise ja kõneosa sildistamise ülesannete jaoks, et hõlbustada edasist uurimistööd.', 'ca': "Code-switching is an omnipresent phenomenon in multilingual communities all around the world but remains a challenge for NLP systems due to the lack of proper data and processing techniques.  El text canviat per codi hindo-anglès dels mitjans socials sovint es translitera a l'escriptura romana que evita utilitzar recursos monolingües disponibles a l'escriptura nativa de Devanagari. En aquest article proposem un mètode per normalitzar i transliterar el text Hindi-anglès canviat de codi. A més, presentem una tècnica de conversió gràfic a fonem (G2P) per a les dades hindíes romanitzades. També vam publicar un conjunt de dades de frases de canvi de codi Hindi-anglès corregides per escriptura etiquetades per al reconeixement de l'entitat anomenada i tasques d'etiquetar part-of-speech per facilitar més recerca.", 'jv': 'Ngubah-ngubah sistem sing sabanjur akeh sabanjur kanggo sabanjur komunitas liyane karo hal-sabanjur iki dadi kanggo sistem NLP ngendadi akeh perusahaan data lan teknik sing berarti. Bidakane Inggris-Inggris kode batuhan kelas nang media sotiki dadi digawe batasan kanggo ingkang Riman sing bisa nguasai perusahaan pawaran yang mungkin-ingkang dipunanggé ning basa Devanagari. Nanging mapun iki, kita mudhun kuwi nggunakake sistem kanggo Normal dan balik-terjamahan kelas basa-ingkang basa. Nambah, kita nganggep teknik nggambar-nggambar (G2P) kang dadi yu barang resmi barang nggambar. Awak dhéwé mulai akeh dataset sing paling-perusahaan kelangan kelangan kelangan kelangan kelangan winih-inggilesuk dhéwé nggawe barang kelangan pangan karo perusahaan langkung kelangan winih.', 'sk': 'Preklapljanje kod je vsepovsod prisoten pojav v večjezičnih skupnostih po vsem svetu, vendar ostaja izziv za sisteme NLP zaradi pomanjkanja ustreznih tehnik podatkov in obdelave. Hindijsko-angleško kodno preklopljeno besedilo na družbenih omrežjih je pogosto prevedeno v rimsko pisavo, kar preprečuje uporabo enojezičnih virov, ki so na voljo v domači Devanagari pisavi. V tem prispevku predlagamo metodo za normalizacijo in nazaj transliteracijo kodno preklopljenega hindijsko-angleškega besedila. Poleg tega predstavljamo tehniko pretvorbe grafema v fonem (G2P) za romanizirane hindijske podatke. Objavljamo tudi nabor podatkov s skriptom popravljenih hindijsko-angleških kodnih stavkov, označenih za naloge prepoznavanja imenovanih entitet in označevanja dela govora, da bi olajšali nadaljnje raziskave.', 'ha': "Mai musanya kodi shine wani abu na yanzu a cikin jama'a masu mulki a cikin duniya duk dũniya kuma yana da wata tsãwa ga na'urar NLP sabõda manyan data da kuma mangawa masu shiryuwa. Hindi-English code-switched text on social media is often transliterated to the Roman script which prevents from utilizing monolingual resources available in the native Devanagari script.  Daga wannan takardan, muna buɗa wata hanyoyi wa'urar da aka bada kodi-mai-sauri-Hidi-Ingiriya. Da wannan, Munã gaura wani technical mai musanya na grapheme-zuwa-Phone (G2P) wa danne na Hindu da aka yi Romaniya. Kayya, Munã saka wani tsari na takardar scriptun da aka saɓa wa kodi-mai shiryarwa na Hindu-Ingiriya da aka rubuta wa sunan ganin abun da rabon faɗa ɗawa wa da aka yi amfani da yin fasahan tafarkin ƙari.", 'he': 'החלפת קודים היא תופעה בכל רחבי בקהילות רבות שפות בכל רחבי העולם, אך היא נשארת אתגר עבור מערכות NLP בגלל חוסר נתונים וטכניקות עיבוד נכונות. טקסט הונדי-אנגלי שמחליף קוד על תקשורת חברתית לעתים קרובות מועבר לתסריט הרומי שממנע להשתמש במשאבים מונושפתיים זמינים בתסריט הדוונאגרי המקורי. בעיתון הזה, אנו מציעים שיטה לנורמליזציה ומחליפת קוד לאחור טקסט אינדי-אנגלי. בנוסף, אנו מציגים טכניקת שינוי גראפם-לפונמה (G2P) למידע הינדי הרומניזם. אנחנו גם משחררים קבוצת נתונים של משפטים הונדי-אנגלי תוקנים לתסריט תוקנים בתסריט תווים לזיהוי הידיות בשם ומשימות תווים חלק מהנאום כדי להקל מחקר נוסף.', 'bo': 'སྐད་ཡིག Hindi-English code-switched text on social media is often transliterated to the Roman script which prevents from utilizing monolingual resources available in the native Devanagari script. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རྒྱུན་ལྡན་དང་། རྒྱབ་གཞུང་ལུགས་ཀྱི་ཡིག་རྟགས་ལ་བསྒྱུར་བཅོས་ཐབས་ལམ་ཞིག་བ འོན་ཀྱང་། ང་ཚོས་རྣམ་པ་བརྗོད་ཀྱི་ཐབས་ལམ་ཞིག་བྱས་ཡོད། We also release a dataset of script-corrected Hindi-English code-switched sentences labeled for the named entity recognition and part-of-speech tagging tasks to facilitate further research.'}
{'en': 'Abusive content detection in transliterated Bengali-English social media corpus', 'ar': 'الكشف عن المحتوى المسيء في مجموعات وسائل التواصل الاجتماعي المترجمة باللغة البنغالية والإنجليزية', 'es': 'Detección de contenido abusivo en un corpus transliterado de redes sociales bengalí-inglés', 'fr': 'Détection de contenu abusif dans le corpus translittéré de médias sociaux bengali-anglais', 'pt': 'Detecção de conteúdo abusivo em corpus de mídia social transliterado bengali-inglês', 'ja': '転写されたベンガル語-英語ソーシャルメディアコーパスでの虐待的なコンテンツ検出', 'hi': 'लिप्यंतरण बंगाली-अंग्रेजी सोशल मीडिया कॉर्पस में अपमानजनक सामग्री का पता लगाना', 'zh': '音译孟加拉语-英语社交媒体语料库中滥用检测', 'ru': 'Обнаружение оскорбительного контента в транслитерированном бенгальско-английском корпусе социальных сетей', 'ga': 'Brath ábhar maslach i gcorpas meán sóisialta traslitrithe Beangáilis-Béarla', 'ka': 'ბენდალის-ინგლისური სოციალური მედია კოპპუსში აუბუციური შესახებ', 'hu': 'Abuzív tartalom felismerése a bengáli-angol közösségi média korpuszban', 'el': 'Ανίχνευση καταχρηστικού περιεχομένου σε μεταγραφημένο βενγκαλικό-αγγλικό σώμα κοινωνικών μέσων', 'it': 'Rilevamento di contenuti abusivi nel corpus traslitterato dei social media bengalesi-inglesi', 'lt': 'Abusive content detection in transliterated Bengali-English social media corpus', 'kk': 'Трансәулетті бенгали-ағылшын социаллық медиа корпусындағы мазмұнын табу', 'ms': 'Pengesanan kandungan yang mengganggu dalam korpus media sosial Bengali-Inggeris', 'ml': 'ബെങ്കാലി- ഇംഗ്ലീഷ് സോഷ്യല്\u200d മെഡിയ കോര്\u200dപ്പുസില്\u200d അബുസിവ് ഉള്ളടക്കം കണ്ടുപിടിക്കുക', 'mt': 'Sejbien abbużiv ta’ kontenut f’korpus tal-midja soċjali Bengali-Ingliż traslitterat', 'mk': 'Abusive content detection in transliterated Bengali-English social media corpus', 'mn': 'Бенгали-Англи хэлний нийгмийн медиа корпус дээр зориулагдсан бүтээгдэхүүний нээлт', 'no': 'Abusive content detection in transliterated Bengali-English social media corpus', 'pl': 'Wykrywanie nadużyć treści w transliteracji bengalsko-angielskiego korpusu mediów społecznościowych', 'ro': 'Detectarea conținutului abuziv în corpul transliterat bengalez-englez social media', 'sr': 'Otkrivanje nasilnog sadržaja u transliteraciji Bengali-engleskog socijalnog medijskog korpusa', 'so': 'Baaritaanka waxyaabaha ku jira ee ku qoran shabakada shabakada bulshada ee Bengali-Ingiriis', 'sv': 'Detektering av missbruk i translittererad bengalisk-engelsk social media corpus', 'ta': 'Abusive content detection in transliterated Bengali-English social media corpus', 'si': 'බෙන්ගාලි-ඉංග්\u200dරීසි සාමාජික මාධ්\u200dයමාධ්\u200dයම කොර්පුස් වල අවශ්\u200dය සාමාන්\u200dය පරික්ෂණය', 'ur': 'انگلیسی اور انگلیسی سوسیلی میڈیا کورپوس میں ناپسند منصوبات کا اظہار', 'uz': 'Name', 'vi': 'Phát hiện nồng độ lạm dụng trong giới truyền thông xã hội Bengali-English', 'bg': 'Откриване на злоупотреби в транслитериран бенгалско-английски корпус на социалните медии', 'hr': 'Otkrivanje nasilnog sadržaja u transliteraciji Bengalski-engleskog socijalnog medijskog korpusa', 'da': 'Registrering af misbrugsindhold i translittereret bengali-engelsk social media corpus', 'de': 'Erkennung missbräuchlicher Inhalte im transliterierten bengalisch-englischen Social Media Korpus', 'id': 'Deteksi konten abusif dalam korpus media sosial Bengali-Inggris transliterasi', 'sw': 'Kugundua maudhui yasiyo ya kibaguzi katika mashirika ya mitandao ya kijamii ya Bengali na Kiingereza', 'ko': '방글라데시어 - 영어 소셜미디어 자료 라이브러리에서의 남용 내용 검출', 'tr': 'Bengali ýa-Iňlisçe sosial mediýanyň korpusynda Abusive mazmunlary tanyş', 'fa': 'پیدا کردن محتویات زیادی در شرکت رسانه های اجتماعی بنگالی-انگلیسی', 'af': 'Abusive inhoud opdekking in transliterate Bengali-Engels sosiale media corpus', 'sq': 'Zbulimi i përmbajtjes abuzive në trupin e transliteratur bengalo-anglez të medias sociale', 'hy': 'Բենգալա-անգլերեն սոցիալական լրատվամիջոցների կորպուսում բռնելի պարունակության հայտնաբերումը', 'az': 'ńįngiliz…ô-ńįngiliz…ô sosyal media korpusu i√ßind…ô', 'bn': 'বাংলাদেশ-ইংরেজী সামাজিক মিডিয়া কোর্পাসের মধ্যে অভিভূত বিষয়বস্তু সনাক্ত করা হয়েছে', 'bs': 'Otkrivanje nasilnog sadržaja u transliteraciji Bengalski-engleskog socijalnog medijskog korpusa', 'ca': 'Detecció abusiva de continguten un cos transliterat de mitjans socials bengalés-anglès', 'et': 'Kuritarvitav sisu tuvastamine translitereeritud bengali-inglise sotsiaalmeedia korpuses', 'fi': 'Väärinkäytöksen havaitseminen transliteroidussa bengali-englantilaisessa sosiaalisen median korpusessa', 'nl': 'Misbruikelijke content detectie in transliteratief Bengaals-Engels social media corpus', 'am': 'በቢንጋሊ-እንግሊዝኛ ማኅበራዊ ሚዲያ ካርፓስ የተለየ የባቡስዊ መረጃ ግለጽ', 'cs': 'Detekce zneužívaného obsahu v transliterovaném bengálsko-anglickém korpusu sociálních médií', 'ha': 'Abusive contents find in transliterated bongali-English media', 'sk': 'Odkrivanje zlorabe vsebin v transliteriranem bengalsko-angleškem korpusu družbenih medijev', 'jv': 'Tatanan pangan', 'bo': 'ཕན་ཚུན་འབྲི་བ་ཡིན་པའི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྟངས་ནང་དུ་Abusive content detection in transliterated Bengali-English social media corpus', 'he': 'גילוי תוכן מועלל בקורפוס של תקשורת חברתית בנגלי-אנגלית'}
{'en': 'Abusive text detection in low-resource languages such as ', 'pt': 'A detecção abusiva de texto em idiomas com poucos recursos, como o bengali, é uma tarefa desafiadora devido à inadequação de recursos e ferramentas. A onipresença dos comentários transliterados em bengali nas mídias sociais torna a tarefa ainda mais complicada, pois as abordagens monolíngues não podem capturá-los. Infelizmente, nenhum corpus bengali transliterado ainda está disponível publicamente para análise de conteúdo abusivo. Portanto, neste artigo, apresentamos um corpus bengali anotado de 3.000 comentários transliterados em bengali categorizados em duas classes, abusivos e não abusivos, 1.500 comentários para cada. Para avaliações de linha de base, empregamos vários classificadores baseados em aprendizado de máquina (ML) supervisionado e aprendizado profundo. Achamos que a máquina de vetores de suporte (SVM) mostra a maior eficácia para identificar conteúdo abusivo. Disponibilizamos o corpus anotado gratuitamente para o pesquisador para auxiliar na detecção de conteúdo abusivo em dados de mídia social bengali.', 'fr': "La détection de textes abusifs dans les langues à faibles ressources, comme le bengali, est une tâche difficile en raison de l'insuffisance des ressources et des outils. L'omniprésence des commentaires en bengali translittérés dans les médias sociaux rend la tâche encore plus complexe, car les approches monolingues ne peuvent pas les saisir. Malheureusement, aucun corpus bengali translittéré n'est encore accessible au public pour une analyse de contenu abusif. Par conséquent, dans cet article, nous introduisons un corpus bengali annoté de 3000 commentaires bengali translittérés classés en deux classes, abusives et non abusives, avec 1500 commentaires pour chacune. Pour les évaluations de base, nous utilisons plusieurs classificateurs basés sur l'apprentissage automatique supervisé (ML) et le deep learning. Nous trouvons que la machine à vecteurs de support (SVM) est la plus efficace pour identifier les contenus abusifs. Nous mettons gratuitement le corpus annoté à la disposition du chercheur afin de faciliter la détection de contenu abusif dans les données des réseaux sociaux bengalis.", 'ja': 'ベンガル語などの低資源言語での濫用的なテキスト検出は、リソースとツールが不十分であるため、困難な課題です。ソーシャルメディアでのベンガル語の音訳コメントの普遍性は、単一言語のアプローチがそれらを取り込むことができないため、タスクをさらに関与させます。残念ながら、濫用的なコンテンツ分析のためにまだ一般に公開されているベンガル語コーパスはありません。そこで、本稿では、3000件の翻訳されたベンガル語のコメントの注釈付きベンガル語コーパスを、虐待的と非虐待的の2つのクラスに分類し、それぞれに1500件のコメントを紹介する。ベースライン評価には、いくつかの監督機械学習（ ML ）とディープラーニングベースの分類器を採用しています。サポートベクターマシン（ SVM ）は、悪用コンテンツを識別するための最高の有効性を示していることがわかります。当社は、ベンガル語のソーシャルメディアデータにおける不正なコンテンツの検出を支援するために、注釈付きコーパスを研究者が自由に利用できるようにしています。', 'zh': '资用不足,孟加拉语等低资源语中检测滥用文本一挑战性之任也。 社交媒体无所不在孟加拉语音译论使此务益杂,单语法不可得也。 不幸者,未有音译者孟加拉语料库明施于滥内容分析。 故于本文引入一带注孟加拉语语料库,其中包3000条音译孟加拉语论,分为二品,诟詈性非诟性,每类1500条论。 于基线评估,用数种监督式机器学 (ML) 与深度学之分器。 见向量机(SVM)见至效率。 臣等为治人免费供带注语料库,以助检测孟加拉语社交媒体数之滥用。', 'ar': 'يعد اكتشاف النص المسيء في اللغات منخفضة الموارد مثل البنغالية مهمة صعبة بسبب عدم كفاية الموارد والأدوات. إن انتشار التعليقات البنغالية المترجمة بأحرف لغة أخرى في وسائل التواصل الاجتماعي يجعل المهمة أكثر تعقيدًا لأن الأساليب أحادية اللغة لا يمكنها التقاطها. لسوء الحظ ، لا توجد مجموعة نصية مكتوبة بحروف لغة بنغالية متاحة للجمهور حتى الآن لتحليل المحتوى المسيء. لذلك ، في هذه الورقة ، نقدم مجموعة مشروحة بنغالية من 3000 تعليق بنغالي مترجم مصنفة إلى فئتين ، مسيئة وغير مسيئة ، 1500 تعليق لكل منهما. بالنسبة إلى التقييمات الأساسية ، فإننا نستخدم العديد من المصنفات القائمة على التعلم الآلي والتعلم العميق الخاضع للإشراف. وجدنا أن آلة متجه الدعم (SVM) تظهر أعلى فعالية لتحديد المحتوى المسيء. نجعل المجموعة المشروحة متاحة مجانًا للباحث للمساعدة في اكتشاف المحتوى المسيء في بيانات الوسائط الاجتماعية البنغالية.', 'hi': 'बंगाली जैसी कम-संसाधन भाषाओं में अपमानजनक पाठ का पता लगाना संसाधनों और उपकरणों की अपर्याप्तता के कारण एक चुनौतीपूर्ण कार्य है। सोशल मीडिया में लिप्यंतरण की गई बंगाली टिप्पणियों की सर्वव्यापकता कार्य को और भी अधिक शामिल करती है क्योंकि मोनोलिंगुअल दृष्टिकोण उन्हें पकड़ नहीं सकते हैं। दुर्भाग्य से, अपमानजनक सामग्री विश्लेषण के लिए कोई लिप्यंतरण बंगाली कॉर्पस अभी तक सार्वजनिक रूप से उपलब्ध नहीं है। इसलिए, इस पेपर में, हम 3000 लिप्यंतरण बंगाली टिप्पणियों का एक एनोटेट बंगाली कॉर्पस पेश करते हैं, जिसे दो वर्गों में वर्गीकृत किया गया है, अपमानजनक और गैर-अपमानजनक, प्रत्येक के लिए 1500 टिप्पणियां। बेसलाइन मूल्यांकन के लिए, हम कई पर्यवेक्षित मशीन लर्निंग (एमएल) और गहरी सीखने-आधारित क्लासिफायरों को नियोजित करते हैं। हम पाते हैं कि समर्थन वेक्टर मशीन (एसवीएम) अपमानजनक सामग्री की पहचान करने के लिए उच्चतम प्रभावकारिता दिखाती है। हम एनोटेटेड कॉर्पस को बंगाली सोशल मीडिया डेटा में अपमानजनक सामग्री का पता लगाने में सहायता करने के लिए शोधकर्ता के लिए स्वतंत्र रूप से उपलब्ध कराते हैं।', 'es': 'La detección de textos abusivos en idiomas de pocos recursos, como el bengalí, es una tarea difícil debido a la insuficiencia de recursos y herramientas. La ubicuidad de los comentarios bengalíes transliterados en las redes sociales hace que la tarea sea aún más complicada, ya que los enfoques monolingües no pueden capturarlos. Desafortunadamente, todavía no hay ningún corpus en bengalí transliterado disponible públicamente para el análisis de contenido abusivo. Por lo tanto, en este artículo, presentamos un corpus bengalí anotado de 3000 comentarios bengalíes transliterados categorizados en dos clases, abusivos y no abusivos, 1500 comentarios para cada uno. Para las evaluaciones de referencia, empleamos varios clasificadores supervisados basados en aprendizaje automático (ML) y aprendizaje profundo. Encontramos que la máquina de vectores de soporte (SVM) muestra la mayor eficacia para identificar contenido abusivo. Ponemos el corpus anotado a disposición del investigador de forma gratuita para ayudar a la detección de contenido abusivo en los datos de las redes sociales bengalíes.', 'ru': 'Обнаружение оскорбительного текста на языках с ограниченными ресурсами, таких как бенгальский, является сложной задачей из-за нехватки ресурсов и инструментов. Повсеместное распространение транслитерированных бенгальских комментариев в социальных сетях делает эту задачу еще более сложной, поскольку одноязычные подходы не могут их охватить. К сожалению, ни один транслитерированный бенгальский корпус еще не доступен для публичного анализа оскорбительного контента. Поэтому в этой статье мы представляем аннотированный бенгальский корпус из 3000 транслитерированных бенгальских комментариев, разбитых на два класса, оскорбительные и не оскорбительные, 1500 комментариев для каждого. Для базовых оценок мы используем несколько контролируемых классификаторов машинного обучения (ML) и классификаторов на основе глубокого обучения. Мы находим, что поддержка векторной машины (SVM) показывает самую высокую эффективность для идентификации оскорбительного контента. Мы делаем аннотированный корпус свободно доступным для исследователя, чтобы помочь выявить оскорбительный контент в данных бенгальских социальных медиа.', 'ga': 'Is tasc dúshlánach é braite téacs maslach i dteangacha íseal-acmhainne mar Bheangáilis mar gheall ar neamhdhóthanacht acmhainní agus uirlisí. Mar gheall ar uileláithreacht na dtráchtanna Beangáilis traslitrithe ar na meáin shóisialta tá an tasc níos tábhachtaí fós mar ní féidir le cuir chuige aonteangacha iad a ghabháil. Ar an drochuair, níl aon chorpas Beangáilis traslitrithe ar fáil go poiblí fós le haghaidh anailíse ábhar maslach. Mar sin, sa pháipéar seo, tugaimid isteach corpas Beangáilis anótáilte de 3000 trácht Beangáilis traslitrithe a chatagóiriú i dhá aicme, maslach agus neamh- maslach, 1500 trácht do gach ceann acu. Le haghaidh meastóireachtaí bonnlíne, bainimid úsáid as roinnt aicmitheoirí meaisínfhoghlama maoirsithe (ML) agus domhainfhoghlaim. Faighimid go léiríonn meaisín veicteora tacaíochta (SVM) an éifeachtúlacht is airde chun ábhar maslach a aithint. Cuirimid an corpas anótáilte ar fáil go héasca don taighdeoir chun cuidiú le braiteadh ábhar maslach i sonraí meán sóisialta Beangáilis.', 'el': 'Η ανίχνευση καταχρηστικού κειμένου σε γλώσσες χαμηλής περιεκτικότητας σε πόρους όπως τα Βεγγαλικά είναι μια πρόκληση λόγω της ανεπάρκειας πόρων και εργαλείων. Η πανταχού παρουσία των μεταφρασμένων σχολίων της Βεγγαλικής στα μέσα κοινωνικής δικτύωσης καθιστά το έργο ακόμα πιο εμπλεκόμενο, καθώς οι μονογλωσσικές προσεγγίσεις δεν μπορούν να τα συλλάβουν. Δυστυχώς, κανένα μεταγραφικό κείμενο της Βεγγαλικής δεν είναι ακόμη διαθέσιμο δημοσίως για ανάλυση καταχρηστικού περιεχομένου. Ως εκ τούτου, σε αυτή την εργασία, εισάγουμε ένα σχολιασμένο Bengali σώμα από 3000 μεταγραφημένα Bengali σχόλια κατηγοριοποιημένα σε δύο κατηγορίες, καταχρηστικά και μη καταχρηστικά, 1500 σχόλια για το καθένα. Για τις αξιολογήσεις βάσης, χρησιμοποιούμε διάφορους εποπτευόμενους ταξινομητές μηχανικής μάθησης (και με βάση τη βαθιά μάθηση). Βρίσκουμε ότι η μηχανή υποστήριξης δείχνει την υψηλότερη αποτελεσματικότητα για τον εντοπισμό καταχρηστικού περιεχομένου. Κάνουμε το σχολιασμένο σώμα ελεύθερα διαθέσιμο για τον ερευνητή για να βοηθήσουμε τον εντοπισμό καταχρηστικού περιεχομένου στα δεδομένα κοινωνικής δικτύωσης της Βεγγάλης.', 'ka': 'აბუქსიური ტექსტის განსახულება რესურსის და ხელსაწყოთა სახელსაწყოთა ენები, როგორც ბენდალიName ტრანგლიტურაციული ბენდალის კომენტრებების სამუშაო მედიაში უფრო მეტად დააკეთებულია, რადგან მონოლენგურაციური დახმარება შეუძლებელია მათ გადატანა ზალბად, ბენდალის კოპპუსი არაფერი სახელსაწყისოდ არაა ხელსაწყისო ანალიზაციისთვის. ამიტომ, ამ დომენტში, ჩვენ აჩვენებთ 3000 ბენდალის ტრანგლიტურაციული ბენდალის კომპოსს, რომელიც ორი კლასში კატეგორიზებულია, ძალიან ძალიან ძალიან და არასწორიან, 1500 კომპონტურაცი ჩვენ ვიყენებთ რამდენიმე მანქანის სწავლება (ML) და ძალიან სწავლების კლასიფიკაციას. ჩვენ მოიძებნა სამყარო ვექტორის მაქსინი (SVM) ჩვენ აჩვენებს საუკეთესო ეფექტიურობას, რომელიც იდენტიფიკაცია ძალიან ძალიან ძალიან ჩვენ გავაკეთებთ ბენდალის სოციალური მედიაციის მონაცემებში დამხმარებელი კოპუსი თავისუფალურად მოხმარება.', 'hu': 'Az erőforrások és eszközök hiányossága miatt kihívást jelent az alacsony erőforrású nyelveken, például a bengáli nyelveken való visszaélések felismerése. Az áttelepített bengáli megjegyzések mindenhol jelen vannak a közösségi médiában, még inkább bevonják a feladatot, mivel az egynyelvű megközelítések nem tudják megragadni őket. Sajnos még egyetlen transzliterált bengáli korpusz sem érhető el nyilvánosan a visszaélő tartalom elemzésére. Ezért ebben a tanulmányban bemutatunk egy megjegyzett bengáli korpuszt, amely 3000 transzliterált bengáli kommentből áll, két osztályba osztva, sértő és nem sértő, 1500 kommentből áll. Az alapvető értékelésekhez számos felügyelt gépi tanulás (ML) és mélytanulás alapú osztályozót alkalmazunk. Úgy találjuk, hogy a támogatási vektorgép (SVM) a legnagyobb hatékonyságot mutatja a visszaélő tartalom azonosítására. A megjegyzett korpuszt szabadon hozzáférhetővé tesszük a kutató számára, hogy segítsük a bengáli közösségi média adataiban való visszaélések felismerését.', 'it': "Il rilevamento abusivo del testo in lingue a basso contenuto di risorse come il bengalese è un compito impegnativo a causa dell'inadeguatezza delle risorse e degli strumenti. L'ubiquità dei commenti bengalesi traslitterati nei social media rende il compito ancora più coinvolto in quanto gli approcci monolingue non possono catturarli. Purtroppo, nessun corpus transliterato bengalese è ancora disponibile pubblicamente per l'analisi abusiva dei contenuti. Pertanto, in questo articolo, introduciamo un corpus bengalese annotato di 3000 commenti bengalesi traslitterati suddivisi in due classi, abusivi e non abusivi, 1500 commenti per ciascuna. Per le valutazioni di base, impieghiamo diversi classificatori basati su apprendimento automatico supervisionato (ML) e deep learning. Troviamo che la macchina vettoriale di supporto (SVM) mostra la massima efficacia per identificare contenuti abusivi. Rendiamo il corpus annotato liberamente disponibile per il ricercatore per facilitare la rilevazione di contenuti abusivi nei dati dei social media bengalesi.", 'lt': 'Netinkamas tekstų aptikimas mažai išteklių turinčiomis kalbomis, pavyzdžiui, bengalų kalbomis, yra sunki užduotis dėl išteklių ir priemonių trūkumo. Dėl transliteratūrinių bengalų komentarų visur social in ėje žiniasklaidoje užduotis tampa dar labiau įtraukta, nes monokalbiniai metodai negali juos sugalvoti. Unfortunately, no transliterated Bengali corpus is publicly available yet for abusive content analysis.  Todėl šiame dokumente pristatome anotuotą 3000 transliteratūrizuotų bengalų komentarų, suskirstytų į dvi klases, piktnaudžiaujančias ir nepažeidžiančias, 1500 komentarų kiekvienam. Pradiniams vertinimams naudojame keletą prižiūrimų mašinų mokymosi (ML) ir giliavandenio mokymosi klasifikatorių. Matome, kad pagalbinė vektorinė mašina (SVM) rodo didžiausią veiksmingumą nustatant piktnaudžiavimą turiniu. Mes laisvai leidžiame naudotis anotuotu korpusu mokslininkams, kad padėtume piktnaudžiavimo turiniu aptikti Bengalų social in ės žiniasklaidos duomenise.', 'mk': 'Некорисно детектирање на текст на јазици со ниски ресурси како што е Бенгалија е предизвикувачка задача поради недостатокот на ресурси и алатки. Секаде што постојат транслитератизирани бенгалиски коментари во социјалните медиуми ја прави задачата уште повклучена бидејќи монојазичните пристапи не можат да ги фатат. За жал, ниту еден транслитературен Бенгалиски корпус сé уште не е јавно достапен за злоупотребна анализа на содржината. Затоа, во овој весник, претставуваме анотиран бенгалски корпус од 3000 транслитературни бенгалски коментари категоризирани во две класи, злоупотребни и неприложни, 1500 коментари за секој. За основните проценки, вработуваме неколку надгледувани машински научувања (ML) и класификатори базирани на длабоко научување. Најдовме векторна машина за поддршка (SVM) покажува највисока ефикасност за идентификување на злоупотребна содржина. Го ставаме анотираниот корпус слободно достапен за истражувачот за да помогне во детекцијата на злоупотребна содржина во бенгалиските социјални медиуми податоци.', 'mt': 'L-iskoperta abbużiva tat-testi f’lingwi b’riżorsi baxxi bħall-Bengali hija kompitu ta’ sfida minħabba n-nuqqas ta’ riżorsi u għodod. Il-preżenza ta’ kummenti Bengali traslitterati fil-midja soċjali tagħmel il-kompitu aktar involut peress li approċċi monolingwi ma jistgħux jaqbduhom. Sfortunatament, l-ebda korpus Bengali traslitterat għadu disponibbli għall-pubbliku għal analiżi abbużiva tal-kontenut. Għalhekk, f’dan id-dokument, aħna nintroduċu korpus Bengali annotat ta’ 3000 kumment Bengali traslitterat ikkategorizzat f’żewġ klassijiet, abbużiv u mhux abbużiv, 1500 kumment għal kull wieħed. Għall-evalwazzjonijiet tal-linja bażi, aħna nużaw diversi klassifikaturi bbażati fuq it-tagħlim tal-magni (ML) u fuq it-tagħlim profond. Aħna nsibu li l-magna tal-vetturi ta’ appoġġ (SVM) turi l-ogħla effikaċja għall-identifikazzjoni ta’ kontenut abbużiv. We make the annotated corpus freely available for the researcher to aid abusive content detection in Bengali social media data.', 'ms': 'Pengesanan teks mengganggu dalam bahasa sumber rendah seperti Bengali adalah tugas mencabar kerana kekurangan sumber dan alat. Penampilan komentar Bengali transliterasi dalam media sosial membuat tugas lebih terlibat kerana pendekatan monobahasa tidak dapat menangkapnya. Malangnya, tiada korpus Bengali yang tersalin tersedia secara awam untuk analisis kandungan yang melampaui batas. Oleh itu, dalam kertas ini, kami memperkenalkan sebuah korpus Bengali yang dicatat 3000 komentar Bengali transliterated yang dikategorikan ke dua kelas, penyalahgunaan dan tidak penyalahgunaan, 1500 komentar untuk masing-masing. Untuk penilaian asas, kami menggunakan beberapa pembelajaran mesin yang diawasi (ML) dan klasifikasi yang berasaskan pembelajaran dalam. Kami jumpa mesin vektor sokongan (SVM) menunjukkan efektivitas tertinggi untuk mengenalpasti kandungan yang menyakitkan. Kami membuat corpus yang dicatat tersedia dengan bebas untuk penyelidik untuk membantu pengesan kandungan yang melampaui batas dalam data media sosial Bengali.', 'kk': 'Бенгали секілді төмен ресурс тілдерінде мәтінді табу - ресурс мен құралдар тәуелсіздігінің себебі бұл көпшілікті тапсырма. Трансәулетті бенгалдың түсініктері әлеуметтік медиақтағы тапсырманы бірнеше тілік қатынау мүмкіндігіне көмектеседі, себебі оларды бірнеше тілік қатынау мүмкі Кешіріңіз, бенгалия корпус көпшілікке аударылмаған, бірақ қорқынышты мазмұны анализ үшін қол жеткізбейді. Сондықтан бұл қағазда, 3000 бенгалияның транслитрацияланған бенгалияның түсініктері екі сыныпта, жеңілікті және жеңілікті емес, әрбір үшін 1500 түсініктерді таңдап береміз. Негізгі оқиғалар үшін бірнеше бақылау құрылғысын (ML) және қалыпты оқиға негізделген классификаторларды қолданамыз. Біз қолдау вектор компьютері (SVM) дегенді табу үшін қолдау мазмұнын анықтау үшін ең жоғары эффективті көрсетеді. Біз бенгалия социаллық медиа деректерінде қорғау үшін зерттеушілер үшін мәтінді анықтауға көмектеседі.', 'ml': 'വിഭവങ്ങളും ഉപകരണങ്ങളും പരിഹാരം ഇല്ലാത്തതിനാല്\u200d ബംഗാലി പോലുള്ള കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകളില്\u200d അബൂസിവ് ടെക്സ്റ്റ് കണ്ട സോഷ്യല്\u200d മീഡിയയില്\u200d മാറ്റുന്ന ബാങ്കാലിയുടെ ഉത്തരവാദിത്വത്തിന്റെ ഉത്തരവാദിത്വം കൂടുതല്\u200d ചേര്\u200dന്നുകൊണ്ടിരിക നിര്\u200dഭാഗ്യവശാല്\u200d ബാങ്കാലി കോര്\u200dപ്പുസ് പ്രസ്താവികമായി ലഭ്യമായിട്ടില്ല എന്നിട്ടും പ്രസ്താവികമായി കാ അതുകൊണ്ട്, ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d 3,000 ട്രാന്\u200dസ്ലൈറ്റ് ചെയ്ത ബാങ്കാലിയുടെ കോര്\u200dപ്പുസിനെ പരിചയപ്പെടുത്തുന്നു. രണ്ടു ക്ലാസുകളിലേക്ക് വിഭാഗമാ ബേസ്ലൈന്\u200d വിലാസങ്ങള്\u200dക്ക് വേണ്ടി നമ്മള്\u200d കുറച്ച് നിരീക്ഷിക്കപ്പെട്ട മെഷീന്\u200d പഠിക്കുന്നതിനെയും ആഴത്തെ പഠ പിന്തുണയ്ക്കുന്ന വെക്റ്റര്\u200d യന്ത്രം (എസ്\u200cവിഎം) ഉപദ്രവിക്കുന്ന വസ്തുക്കളെ തിരിച്ചറിയുന്നതിന്  ബാങ്കാലിയിലെ സോഷ്യല്\u200d മീഡിയയിലെ വിവരങ്ങളില്\u200d നിന്നും പീഡിപ്പിക്കാന്\u200d ഞങ്ങള്\u200d പരിശോധിക്കുന്നവര്\u200dക്ക് സ്വതന്ത', 'no': 'Oppdaging av abusive tekst i låg ressursspråk som Bengali er ein vanskeleg oppgåve ved grunn av ikkje tilgjengeleg ressursar og verktøy. Den gjennomsnittet av transliterte Bengaliske kommentarar i sosiale medier gjer oppgåva til og med meir involvert, sidan monospråk kan ikkje henta dei. Dessverre er ingen translitert Bengali corpus offentlig tilgjengeleg enno for abusive content analysis. I denne papiret introdusere vi ein merkelig Bengalisk korpus med 3000 transliterarte Bengaliske kommentarar, kategoriert i to klasser, abusive og ikkje-abusive, 1500 kommentarar for kvar. For baseline evalueringar bruker vi fleire oversikte maskinelæring (ML) og dype læringsbaserte klassifikatorar. Vi finn støtte vektormaskin (SVM) som viser den høgste effekten for identifisering av abusive innhald. Vi gjer det merkte korpusen fritt tilgjengeleg for forskningen for å hjelpa oppdaging av abusive innhald i Bengaliske sosiale media-data.', 'ro': 'Detectarea abuzivă a textului în limbi cu resurse reduse, cum ar fi bengaleza, este o sarcină dificilă datorită insuficienței resurselor și instrumentelor. Ubicitatea comentariilor bengaleze transliterate în rețelele sociale face ca sarcina să fie și mai implicată, deoarece abordările monolingve nu le pot capta. Din păcate, niciun corpus transliterat bengalez nu este încă disponibil public pentru analiza conținutului abuziv. Prin urmare, în această lucrare, introducem un corpus bengalez adnotat de 3000 de comentarii bengaleze transliterate clasificate în două clase, abuzive și non-abuzive, 1500 de comentarii pentru fiecare. Pentru evaluările de bază, folosim mai multe clasificatoare supravegheate de învățare automată (ML) și bazate pe învățare profundă. Considerăm că mașina vectorială de suport (SVM) prezintă cea mai mare eficacitate pentru identificarea conținutului abuziv. Punem corpul adnotat liber la dispoziția cercetătorului pentru a ajuta la detectarea conținutului abuziv în datele rețelelor sociale bengaleze.', 'sr': 'Otkrivanje zloupotrebnih tekstova na jezicima niskih resursa poput Bengalija je izazovni zadatak zbog nedostatka resursa i alata. Svakost transliteracija Bengalskih komentara u društvenim medijima čini zadatak još više uključenim jer ih ne mogu uhvatiti monojezički pristupi. Nažalost, nijedan transliteran Bengali korpus još nije javno dostupan za analizu nasilnog sadržaja. Stoga, u ovom papiru predstavljamo annotirani Bengalski korpus od 3000 transliteratnih Bengalijskih komentara kategorizirani na dve klase, zlostavljajuće i ne zlostavljajuće, 1500 komentara za svaku. Za početne procjene, zapošljavamo nekoliko nadzornih mašinskih učenja (ML) i dubokih klasifikatora na osnovu učenja. Nalazimo podršku vektorskoj mašini (SVM) pokazuje najveću efikasnost identifikacije nasilnog sadržaja. Oslobodimo annotiranog korpusa za istraživača da pomogne otkrivanju nasilnog sadržaja u podacima o društvenim medijima Bengalija.', 'si': 'බෙන්ගාලි වලින් අඩුම සම්බන්ධ භාෂාවල් වලට ප්\u200dරශ්නයක් හොයාගන්න ප්\u200dරශ්නයක් තියෙන්නේ. බෙන්ගාලි වලින්  සාමාජික මිඩියාවේ බෙන්ගාලි කිරීම් ප්\u200dරශ්නයක් විතරයි මෙහෙම වැඩක් වැඩි කරනවා වගේම එක්ක භාෂාවික විදියට අවාසනාවන්තයෙන්, බෙන්ගාලි කොර්පුස් කිසිම විශ්ලේෂණයක් තාමත් සාමාන්\u200dය විස්තර කරන්න පුළුවන් ඉතින්, මේ පත්තරේ අපි බෙන්ගාලි කොර්පුස් 3000ක් ගැන ප්\u200dරතික්\u200dරියාත්මක බෙන්ගාලි කොර්පුස් එකක් ප්\u200dරතික්\u200dරියාත්මක කරනවා වගේ පත්තර දෙකක මූලික විශ්ලේෂණය සඳහා, අපි පරික්ෂා කරපු පරික්ෂා කරපු පරික්ෂණ පරික්ෂණය (ML) සහ ගොඩක් ඉගෙනීම අපිට සහය වෙක්ටර් යන්ත්\u200dරය (SVM) හොයාගන්න ප්\u200dරශ්නයක් පෙන්වන්න පුළුවන් වෙක්ටර් පද්ධතිය හොයාගන් අපි බෙන්ගාලි සාමාජික මාධ්\u200dයාත්මක දත්තේ ප්\u200dරශ්නයක් පරීක්ෂකයාට උදව් කරන්න ප්\u200dරශ්නයක් නිදහස් වෙන්න පු', 'mn': 'Бенгали зэрэг бага боловсролын хэлний хэл дээр хүчирхийлэлтэй мөнгө олж мэдэх нь бага боловсролын хэрэгсэл болон нөөц боловсролын бус байдлын шаардлагатай ажил юм. Нийгмийн мэдээллийн хэвлэлийн хэвлэлийн хэвлэлийн тусламжтайгаар бичигдсэн Бенгали хэвлэлийн хэвлэлүүдийн тусламжтайгаа илүү оролцож чадна. Харамсалтай нь Бенгалийн корпус хэзээ ч хүчирхийллийн агууллагуудын шинжилгээнд нийтэд ашиглаж чадахгүй. Тиймээс бид энэ цаасан дээр 3000 буюу Бенгали хэвлэгдсэн захирагчид 2 ангид хуваалцсан, хүчирхийллэгүй, хүчирхийллэгүй, 1500 захирагчид бий болгож тайлбарлаж байна. Сургуулийн оюутнуудын тулд бид машин суралцах (ML) болон гүн гүнзгий суралцах хичээлийг ашигладаг. Бид дэмжлэх вектор машин (SVM) нь хүчирхийллийн агуулалтыг тодорхойлох хамгийн өндөр үр дүнг харуулдаг. Бид судлаачдын хувьд зориулсан корпус Бенгалийн нийгмийн мэдээллийн мэдээллийн хүчирхийллийн агуулалтыг ашиглах боломжтой болгодог.', 'so': 'Shaqo qasab ah oo ku qoran luuqadaha hoose ee ay ku qoran yihiin sida Bengali waa shaqo dhibaato badan, sababtoo ah aysan ku filnayn hantida iyo qalabka. Caqliga ka soo qoran warqadaha Bengali ee ku saabsan shabakadda bulshada ayaa shaqada ka dhigta mid ka badan, sababtoo ah qaababka luuqada ee dhaqanka ah ma qabsan karo. Nasiib xumaatooyinka baabuurta Bengali oo la qoray dhamaan lama heli karo baaritaanka waxyaabaha isticmaalka. Sidaa darteed waxaynu warqaddan ku soo bandhignaa 3,000 oo baaritaanka Bengali oo ay ku qoran yihiin laba fasax, isticmaal iyo si aan wax u isticmaalin, 1500 comment. Qiimeynta aasaasiga ah (ML) waxaynu shaqaynaynaa koorasyo waxbarasho badan oo maamul ah (ML) iyo waxbarasho aad u weyn. Waxaannu heli karnaa mashiinka kaalmada (SVM) oo tusaya waxyaabaha ugu sarreeya aqoonsiga waxyaabaha la isticmaalo. Waxbarashada baaritaanku waxey si xor ah ugu heli karnaa baaritaanka waxyaabaha isticmaalka ee macluumaadka bulshada ee Bengali.', 'sv': 'Missbruk av text detektering på lågresursspråk som bengali är en utmanande uppgift på grund av otillräckliga resurser och verktyg. Den utbredda förekomsten av translittererade bengaliska kommentarer i sociala medier gör uppgiften ännu mer involverad eftersom enspråkiga metoder inte kan fånga dem. Tyvärr finns ännu ingen translitererad bengalisk korpus tillgänglig för missbrukande innehållsanalys. Därför introducerar vi i denna uppsats en kommenterad bengalisk korpus med 3000 translittererade bengaliska kommentarer kategoriserade i två klasser, grova och icke-grova, 1500 kommentarer för varje. För baslinjeutvärderingar använder vi flera övervakade maskininlärnings- och djupinlärningsbaserade klassificerare. Vi finner att support vector machine (SVM) visar högsta effektivitet för att identifiera missbruk av innehåll. Vi gör den kommenterade korpusen fritt tillgänglig för forskaren för att underlätta upptäckt av missbruk i bengaliska sociala mediedata.', 'pl': 'Wykrywanie nadużyć tekstu w językach o niskich zasobach, takich jak bengalski, jest trudnym zadaniem ze względu na niedostateczność zasobów i narzędzi. Wszechobecność transliteracyjnych komentarzy bengalskich w mediach społecznościowych sprawia, że zadanie jest jeszcze bardziej zaangażowane, ponieważ podejścia jednojęzyczne nie mogą ich uchwycić. Niestety, żaden transliterowany korpus bengalski nie jest jeszcze publicznie dostępny do analizy nadużyć treści. Dlatego w niniejszym artykule przedstawiamy komentarze bengalskie z 3000 transliterowanymi komentarzami bengalskimi sklasyfikowanymi na dwie klasy, obraźliwe i nieobraźliwe, 1500 komentarzy dla każdej z nich. Do ocen bazowych stosujemy kilka nadzorowanych klasyfikatorów uczenia maszynowego (ML) i klasyfikatorów opartych na głębokim uczeniu. Uważamy, że wsparcie wektorowe maszyny (SVM) wykazuje najwyższą skuteczność w identyfikacji nadużywających treści. Udostępniamy korpus z adnotacji swobodnie dla badacza, aby ułatwić wykrywanie nadużyć treści w bengalskich danych mediów społecznościowych.', 'ta': 'பெங்காலி போன்ற குறைந்த வளங்கள் மற்றும் கருவிகளின் குறைவான மொழிகளில் உள்ள உரை கண்டறிதல் ஒரு சவால் பணியாகும். The ubiquity of transliterated Bengali comments in social media makes the task even more involved as monolingual approaches cannot capture them.  துரதிர்ஷ்டவசமாக, மாற்றுபடுத்தப்பட்ட பெங்காலி கோர்புஸ் எதுவும் பொதுவாக கிடைக்கவில்லை மீறும் உள்ளடக் ஆகையால், இந்த காகிதத்தில், நாம் 3,000 transliterated பெங்காலி குறிப்புகளை அறிவிக்கிறோம். ஒவ்வொரு குறிப்புகளுக்கும் 1500 குறிப்புகளை வகுப்பிடப்பட்டுள்ள அடிப்படைக்கோட்டின் மதிப்புகளுக்கு, நாம் பல கண்காணிக்கப்பட்ட இயந்திரம் கற்றல் மற்றும் ஆழமான கற்றல் வகுப்பாளர்களை வேலை ச நாங்கள் ஆதரவு நெறிய இயந்திரத்தை கண்டுபிடிக்க (SVM) குழப்பமான உள்ளடக்கத்தை கண்டுபிடிக்க அதிக விளைவு பெங்காலி சமூக ஊடகங்களின் தகவல்களில் மீண்டும் தெரியும் உள்ளடக்கங்களை கண்டுபிடிக்க உதவும் ஆராய்ச்சியாளருக்கு ந', 'ur': 'نیچے منبع زبانوں میں مصیبت لکھی ہوئی پیغام پہچان سکتی ہے جیسے بنگلی ایک مشکل کام ہے اس کے سبب کہ سرمایہ اور ابزار غیر قابل ہے. سوسیل میڈیا میں ٹرانسلیٹ بنگلیوں کی کمانٹوں کی حوصلہ اس کام کو زیادہ شامل کرتا ہے کیونکہ ایک زبان کی طریقے انہیں پکڑ نہیں سکتے۔ بدبختی کے ساتھ، کوئی ٹرانسلیٹ بنگلی کورپوس ظاہر طور پر حاضر نہیں ہے، حالانکہ فساد منصفات تحلیل کے لئے. لہٰذا ہم اس کاغذ میں 3000 بنگلی کورپوس کی آواز دیتے ہیں جو دو کلاس میں تقسیم کیے گئے ہیں، زبردستی اور غیر زبردستی، 1500 کمانٹر کے لئے۔ بنیاس لین کی ارزیابی کے لئے ہم بہت سی موجود ماشین کی تعلیم (ML) اور عمیق سیکھنے کی بنیاد کی کلاسیر استعمال کرتے ہیں۔ ہم پشتیبانی ویکتور ماشین (SVM) کو دکھاتے ہیں جن کے ذریعہ مضبوط موجود کو پہچان کرنے کے لئے سب سے زیادہ اثبات ہے۔ ہم نے بنگالی سوسیل میڈیا ڈیٹا میں فساد پکڑنے کی مدد کرنے کے لئے تحقیقات کرنے والوں کے لئے آزاد کردہ کورپوس کو آزاد طور پر موجود بنایا ہے.', 'uz': "Abusive text detection in low-resource languages such as Bengali is a challenging task due to the inadequacy of resources and tools.  Bengalning o'zgarishga o'xshash o'zgarishlari jamiyatlar tarkibida ishni o'zgartiradi, chunki oddiy tillar ularni qabul qila olmaydi. Afsuski, bu Bengalcha korpus hech qachon tarkib tarkibini aniqlash uchun hech narsa topilmadi. Hullas, bu qogʻozdagi biz 3,000 transliteratori Bengalcha qismlarini ko'rsamiz, ikki sinfga, harakat va harakat qilmagan, har bir uchun 1500 izohlar bo'lgan. Biz bir necha ko'pchilik mashinalar o'rganishni (ML) va eng yuqori o'rganish darajalarini ishlayapmiz. Biz qoʻllanmagan vektor mashinasi (SVM) dastur tarkibini aniqlash uchun eng katta effekti koʻrsatiladi. Biz taʼminlovchi korpusni o'qituvchilar uchun o'qituvchilar Bengalcha jamiyat mitanda maʼlumotiga yordam berishga qo'llanmiz.", 'vi': 'Phát hiện văn bản bừa bãi ở dạng ngôn ngữ ít tài nguyên như Bengali là một thử thách do sự thiếu kỹ năng và công cụ. Sự tồn tại của các bình luận Bengali trong truyền thông xã hội khiến nhiệm vụ trở nên phức tạp hơn bởi vì phương pháp ngôn ngữ không thể chiếm được nó. Không may là không có ai được công khai phân tích nội dung lạm dụng. Vì vậy, trong bài báo này, chúng tôi giới thiệu một dòng Bengali tập thể 3000 chuyển các bình luận Bengali được phân loại thành hai hạng, lạm dụng và không lạm dụng, 1500 bình luận cho mỗi loại. Để đánh giá cơ bản, chúng tôi sử dụng nhiều phân loại máy giám sát (ML) và phân loại sâu học. Chúng tôi tìm thấy cỗ máy vector (SVM) hiển thị hiệu quả cao nhất để xác định chất xúc phạm. Chúng tôi trao cho nhà nghiên cứu tài liệu được ghi chú thoải mái để hỗ trợ việc phát hiện nội dung lạm dụng trong dữ liệu phương tiện xã hội Bengal.', 'hr': 'Otkrivanje zlostavljenog teksta na jezicima niskih resursa poput Bengalija je izazovan zadatak zbog nedostatka resursa i alata. Svugdjenost transliteracija Bengalskih komentara u društvenim medijima čini zadatak još više uključenim jer ih ne mogu uhvatiti monojezički pristupi. Nažalost, nijedan transliteratni Bengali corpus još nije javno dostupan za analizu nasilnog sadržaja. Stoga, u ovom papiru, predstavljamo annotirani Bengalski korpus od 3000 transliteratnih Bengalijskih komentara kategorizirani na dvije klase, zlostavljajuće i ne zlostavljajuće, 1500 komentara za svaku. Za početne procjene zapošljavamo nekoliko nadzornih učenja strojeva (ML) i dubokih klasifikatora na temelju učenja. Nalazimo podršku vektorskoj stroji (SVM) pokazuje najveću djelotvornost za identifikaciju nasilnog sadržaja. Oslobodili smo annotirani korpus za istraživača da pomogne otkrivanju nasilnog sadržaja u podacima o društvenim medijima Bengalija.', 'da': 'Detektering af misbrug af tekst på sprog med lav ressource som Bengali er en udfordrende opgave på grund af utilstrækkelige ressourcer og værktøjer. Det allestedsnærværende af translittererede bengaliske kommentarer i sociale medier gør opgaven endnu mere involveret, da ensprogede tilgange ikke kan fange dem. Desværre er der endnu ikke noget translittereret bengalisk korpus tilgængeligt for krænkende indholdsanalyse. Derfor introducerer vi i denne artikel et kommenteret bengalisk korpus af 3000 translittererede bengaliske kommentarer kategoriseret i to klasser, misbrugende og ikke-misbrugende, 1500 kommentarer for hver. Til baseline evalueringer anvender vi flere overvågede maskinlæring (ML) og deep learning-baserede klassificeringer. Vi finder, at support vector machine (SVM) viser den højeste effektivitet til at identificere krænkende indhold. Vi gør det kommenterede korpus frit tilgængeligt for forskeren for at hjælpe med at opdage misbrugende indhold i bengaliske sociale medier data.', 'bg': 'Откриването на злоупотреби с текст на езици с ниски ресурси като бенгалски е трудна задача поради недостатъчността на ресурси и инструменти. Разпространението на транслитерираните бенгалски коментари в социалните медии прави задачата още по-ангажирана, тъй като едноезичните подходи не могат да ги уловят. За съжаление, все още няма транслитериран бенгалски корпус, достъпен публично за анализ на злоупотреба със съдържанието. Ето защо в настоящата статия представяме анотиран бенгалски корпус от 3000 транслитерирани бенгалски коментари, категоризирани в два класа, обидни и необидни, по 1500 коментара за всеки. За базови оценки използваме няколко контролирани класификатори за машинно обучение (МУ) и дълбоко обучение. Намираме, че поддържащата векторна машина (SVM) показва най-висока ефективност за идентифициране на злоупотребяващо съдържание. Ние правим анотирания корпус свободно достъпен за изследователя, за да подпомогне откриването на злоупотреба със съдържание в бенгалски социални медии данни.', 'nl': 'Misbruikelijke tekstdetectie in low-resource talen zoals Bengaals is een uitdagende taak vanwege de ontoereikende middelen en tools. De alomtegenwoordigheid van transliteraire Bengaalse commentaren in sociale media maakt de taak nog belangrijker omdat eentalige benaderingen ze niet kunnen vastleggen. Helaas is er nog geen transliterair Bengaals corpus beschikbaar voor misbruik van inhoud. Daarom introduceren we in dit artikel een geannoteerd Bengaals corpus van 3000 translitereerde Bengaals commentaren gecategoriseerd in twee klassen, beledigend en niet-beledigend, 1500 commentaren voor elk. Voor baseline evaluaties maken we gebruik van verschillende supervised machine learning (ML) en deep learning gebaseerde classificatoren. We vinden dat support vector machine (SVM) de hoogste effectiviteit toont voor het identificeren van misbruikende inhoud. We stellen het geannoteerde corpus vrij beschikbaar voor de onderzoeker om misbruik van content te detecteren in Bengaalse social media data.', 'id': 'Deteksi teks abusif dalam bahasa sumber daya rendah seperti Bengali adalah tugas yang menantang karena kekurangan sumber daya dan alat. Kebanyakan komentar Bengali transliterasi di media sosial membuat tugas bahkan lebih terlibat karena pendekatan monobahasa tidak dapat menangkapnya. Sayangnya, tidak ada korpus Bengali yang tersalin tersedia publik untuk analisis isi yang abusif. Oleh karena itu, di kertas ini, kami memperkenalkan sebuah korpus Bengali yang dicatat dari 3000 komentar Bengali transliterasi yang dikategorisasi menjadi dua kelas, penyiksaan dan tidak penyiksaan, 1500 komentar untuk masing-masing. Untuk evaluasi dasar, kami menggunakan beberapa pembelajaran mesin yang diawasi (ML) dan klasifikasi berbasis belajar dalam. Kami menemukan mesin vektor dukungan (SVM) menunjukkan efektivitas tertinggi untuk mengidentifikasi isi yang abusif. Kami membuat mayat yang dicatat tersedia secara bebas untuk peneliti untuk membantu deteksi isi abusif dalam data media sosial Bengali.', 'de': 'Die missbräuchliche Texterkennung in ressourcenarmen Sprachen wie Bengali ist aufgrund der Unzulänglichkeit von Ressourcen und Tools eine herausfordernde Aufgabe. Die Allgegenwärtigkeit transliterierter bengalischer Kommentare in sozialen Medien macht die Aufgabe noch schwieriger, da monolinguale Ansätze sie nicht erfassen können. Leider ist noch kein transliterierter bengalischer Korpus für missbräuchliche Inhaltsanalysen öffentlich verfügbar. Daher stellen wir in diesem Beitrag einen annotierten bengalischen Korpus von 3000 transliterierten bengalischen Kommentaren vor, die in zwei Klassen kategorisiert sind, beleidigend und nicht beleidigend, 1500-Kommentare für jede. Für Baseline-Auswertungen verwenden wir mehrere überwachte Machine Learning (ML) und Deep Learning basierte Klassifikatoren. Wir finden, dass Support Vector Machine (SVM) die höchste Wirksamkeit bei der Identifizierung missbräuchlicher Inhalte zeigt. Wir stellen den kommentierten Korpus für den Forscher frei zur Verfügung, um missbräuchliche Inhalte in bengalischen Social Media Daten zu erkennen.', 'ko': '자원과 도구의 부족으로 인해 방글라데시 등 저자원 언어에서의 텍스트 남용 검출은 도전적인 과제이다.소셜 미디어에서 방글라데시어의 음역 평론은 어디에나 있기 때문에 이 임무는 더욱 복잡하다. 왜냐하면 단어 방법으로는 이런 평론을 포착할 수 없기 때문이다.불행하게도 아직 공개되지 않은 방글라데시어 어료고는 남용 내용 분석에 쓰일 수 있다.따라서 본고에서 우리는 주석이 있는 방글라데시 어료 라이브러리를 소개했는데 그 중에서 3000개의 음역된 방글라데시 어평을 포함하고 두 가지로 나뉘는데 남용과 비남용, 각각 1500개의 어평이 있다.베이스라인 평가에 대해 우리는 감독기계학습(ML)과 심도학습을 바탕으로 하는 몇 가지 분류기를 채택했다.Dell은 SVM(벡터 머신) 지원이 남용된 콘텐츠를 인식하는 데 가장 효율적임을 보여줍니다.우리는 방글라데시 소셜미디어 데이터의 남용 내용을 검출하는 데 도움을 주기 위해 연구원들에게 주석이 달린 자료 라이브러리를 무료로 제공한다.', 'sw': 'Kugundua ujumbe usio na maandishi katika lugha ndogo ya rasilimali kama vile Bengali ni kazi ya changamoto kutokana na kukosekana kwa rasilimali na vifaa. Uhuru wa maoni ya Bengali katika mitandao ya kijamii inafanya kazi hii zaidi ya kujihusisha kwa sababu mbinu za lugha za kiutaifa haziwezi kuwakamata. Kwa bahati mbaya, hakuna viungo vya Bengali vilivyoandikwa kwa ajili ya uchambuzi wa maudhui yanayotumiwa. Kwa hiyo, katika karatasi hii, tunaonyesha mabango ya Bengali yenye maoni 3000 yaliyochapishwa na makundi mawili, matumizi na yasiyo na matumizi, maoni 1500 kwa kila mmoja. Kwa uchunguzi wa msingi, tunatumia vifaa kadhaa vilivyofuatiliwa na mashine ya kujifunza (ML) na vizuri vya kujifunza. Tunapata mashine ya mkono (SVM) yanaonyesha ufanisi mkubwa wa kutambua maudhui yanayotumiwa. Tunafanya makampuni yanayotajwa kwa uhuru kwa ajili ya mtafiti wa kusaidia kutambua maudhui yanayotumiwa katika taarifa za mitandao ya kijamii nchini Bengali.', 'tr': 'Bengali ýa ýaly azat ressurs we esbaplaryň tapylmadygy üçin elimden gelen metin a ňsatsyz bir işdir. Sosyal medyelerdeki terjime edilen Bengali ň terjimeleriniň hepsi bu işi, monodil yaklaşmalarından daha da dahil edip bilmez. Gynansakda, hiç hili terjime edilen Bengali ýanyň korpusy entägem açyk maksadyň analyzasy üçin tapylmady. Bu yüzden, bu kağıtda 3000 Bengali terjime edilen bir korpus tarafından, her biri için 2 sınıf, çirkin ve hili istisna olmayan, 1500 tercih edilen sözleri tanıştırıyoruz. Esasy çykyşlary üçin birnäçe gözetli maşyny öwrenmek üçin (ML) we derin öwrenmek tabanly klasifikatçylary ulanýarys. Tapdyk Biz bu hasaplanýan korpusy Bengali ýanyň sosyal medýýatlaryň maglumatynyň üstünde boýunça açmak üçin arkadaşlyk bilen alyp bilýäris.', 'fa': 'کشف متن ناتوانی در زبانهای کم منبع مانند بنگالی یک کار سخت است به دلیل ناتوانی منابع و ابزار. در رسانه\u200cهای اجتماعی مطالعه\u200cهای بنگالی ترجمه شده، کار را بیشتر درگیر می\u200cکند، زیرا دسترسی تنها زبان نمی\u200cتواند آنها را بگیرد. متأسفانه، هیچ کورپوس بنگالی ترجمه نوشته نشده هنوز برای تحلیل محتویات خشونت در دسترس عمومی است. بنابراین، در این کاغذ، ما یک کورپوس بنگالی که در ۳۰۰۰ توضیح بنگالی ترجمه شده است را معرفی می\u200cکنیم، که در دو کلاس، تجاوز و غیر تجاوز می\u200cکند، ۱۵۰۰ توضیح برای هر یک است. برای ارزیابهای پایین، ما تعلیم دستگاه\u200cهای تحت نظر (ML) و مختصات\u200cهای عمیق درس\u200cآموزش را استفاده می\u200cکنیم. ما ماشین پشتیبانی (SVM) را پیدا می\u200cکنیم که بهترین تاثیر برای شناسایی محتویات تجاوز را نشان می\u200cدهد. ما کورپوس آزاد آزاد را برای تحقیقات برای کشف محتوای زحمت در داده\u200cهای رسانه\u200cهای اجتماعی بنگالی کمک می\u200cکنیم.', 'af': "Abusive teks opdekking in lae hulpbron tale soos Bengali is 'n pragtige taak vanweë die ongelukkigheid van hulpbronne en hulpbronne. Die oorspronklikheid van transliteerde Bengali kommentaar in sosiale media maak die taak selfs meer insluit, omdat monotale toegang hulle nie kan haal nie. Ongelukkig is geen transliteerde Bengali corpus openlik beskikbaar nog vir abusive inhoud analiseer nie. Daarom, in hierdie papier, introduseer ons 'n aanmerkte Bengali korpus van 3000 transliteerde Bengali kommentaar wat in twee klasse, abusive en non-abusive, 1500 kommentaar vir elke. Vir basisline evaluasies, gebruik ons verskeie ondersoekte masjien leer (ML) en diep leer-gebaseerde klassifiseerders. Ons vind ondersteunde vektor masjien (SVM) vertoon die hoogste effikasie vir identifiseer abusive inhoud. Name Ons maak die opmerkte korpus vry beskikbaar vir die ondersoeker om abusive inhoud opdekking te help in Bengali sosiale media data.", 'hy': "Բենգալիի նման ցածր ռեսուրսների լեզուներում չարաշահույթ տեքստի հայտնաբերումը դժվար խնդիր է, քանի որ ռեսուրսները և գործիքները բավարար են: Սոցիալական լրատվամիջոցներում գտնվող բենգալացի մեկնաբանությունների տարածությունը դարձնում է գործը ավելի ներգրավված, քանի որ միալեզու մոտեցումները չեն կարող դրանք բռնել: Դժբախտաբար, ոչ մի թանսգրված Բենգալացի կորպուս դեռևս հանրային հասանելի չէ չարաշահող պարունակության վերլուծության համար: Այսպիսով, այս թղթի մեջ մենք ներկայացնում ենք 3000 տրանսգրավորված բենգալացի մոտեցումներ, որոնք դասակարգված են երկու դասերով' չարաշահույթ և ոչ չարաշահույթ, յուրաքանչյուրի համար 1500 մոտեցում: Հիմնական գնահատումների համար մենք օգտագործում ենք մի քանի վերահսկված մեքենային ուսումնասիրություն (ML) և խորը ուսումնասիրության հիմնված դասակարգեր: Մենք գտանք աջակցության մեքենան, որը ցույց է տալիս ամենաարդյունավետությունը չարաշահույթ պարունակության հայտնաբերման համար: We make the annotated corpus freely available for the researcher to aid abusive content detection in Bengali social media data.", 'sq': "Abusive text detection in low-resource languages such as Bengali is a challenging task due to the inadequacy of resources and tools.  Çdokush i komenteve transliterate bengale në mediat shoqërore e bën detyrën edhe më të përfshirë pasi afrimet monogjuhësore nuk mund t'i kapin ato. Fatkeqësisht, asnjë korpus bengali i transliteratur nuk është në dispozicion publikisht ende për analizë abuzive të përmbajtjes. Prandaj, në këtë letër, ne paraqesim një korpus bengali të anotuar prej 3000 komentesh bengalësh transliterate të kategorizuar në dy klasa, abuzive dhe jo abuzive, 1500 komentesh për secilin. Për vlerësimet bazë, ne përdorim disa klasifikues të mbikqyrur nga mesi (ML) dhe klasifikues të thellë bazuar në mësim. Ne gjejmë që makina e vektorit të mbështetjes (SVM) tregon efektshmërinë më të lartë për identifikimin e përmbajtjes abuzive. Ne e bëjmë korpusin e anotuar të disponueshëm lirisht për kërkuesit për të ndihmuar zbulimin e përmbajtjeve abuzive në të dhënat e medias sociale bengale.", 'am': 'እንደ በንጋሊ በሚባል የጽሑፍ ቋንቋዎች አዋቂው የጽሑፍ ማግኘት ሀብት እና መሣሪያዎች ስላልጎደለው ነው፡፡ በብንጋሊ በማኅበራዊ አውታር ላይ የተለየ ውጤት የባንጋል ማኅበራዊ ሚዲያ ጉዳዩን ለመያዝ አይችልም፡፡ በተከፋች ጊዜ፣ የቢንጋሊ ኮርፓስ ምንም የተገኘ የግልፅ ማተሚያ ሳይሆን ግልፅ የለውም፡፡ ስለዚህ በዚህ ካላት፣ ለሁሉም 1500 አስተያየት፣ ተቃውሞ፣ ተጨቃሚ እና የማይጠቃቀሙ የቢንጋል ካርፓስ በሁለት ደረጃዎች ላይ የተለየውን የባንጋሊ መለያየት እናሳውቃለን፡፡ ለመጀመሪያው ደረጃዎች ማስታወቂያ፣ ብዙ የተጠበቀ መኪናዎችን (ML) እና የጥልቅ ትምህርት መግለጫዎችን እናስገድዳለን፡፡ የድጋፍ መሣሪያን (SVM) የሚያሳየው የጥቃት ጥቃት ነው፡፡ በጋንጋሊ ማኅበራዊ ሚዲያ ዳታዎችን ለማግኘት የሚችሉትን ተማሪ ነፃነት እናደርጋለን፡፡', 'az': 'Bengali kimi düşük ressurs dillərində istifadə edilən mətn tapılması çox çətin bir işdir. Sosyal media içində transliterated Bengali şəhadətlərinin hər tərəfində işləri daha çox hiss edir, çünki monodil tərəfləri onları yakalaya bilməz. Maalesef ki, heç bir transliterated Bengali korpus halda şiddətli məlumat analizi üçün faydalanmaz. Beləliklə, bu kağızda 3000 Bengali korpusu ilə yazılmış, iki dəstə, həddi aşmış və həddi aşmış, hər biri üçün 1500 komentar təyin edir. İlk səhifələr üçün bir neçə nəzarətli maşın öyrənməsi (ML) və derin öyrənmə səhifələrini istifadə edirik. Bizim destekli vektor makinesi (SVM) istifadə etmək üçün ən yüksək etkinlik göstərir. Biz mühakimçin in Bengali sosyal media məlumatının istifadə edilməsinə kömək edəcəyi korpusu özgür olaraq faydalandırırıq.', 'bs': 'Otkrivanje zlostavljenog teksta na jezicima niskih resursa poput Bengalija je izazovni zadatak zbog nedostatka resursa i alata. Svakost transliteranih Bengalskih komentara u društvenim medijima čini zadatak još više uključenim jer ih ne mogu uhvatiti monojezički pristupi. Nažalost, nijedan transliteratni Bengalski korpus još nije javno dostupan za analizu nasilnog sadržaja. Stoga, u ovom papiru, predstavljamo annotirani Bengalski korpus od 3000 transliteratnih Bengalijskih komentara kategorizirani na dvije klase, zlostavljajuće i ne zlostavljajuće, 1500 komentara za svaku. Za početne procjene, zapošljavamo nekoliko nadzornih učenja strojeva (ML) i dubokih klasifikatora na osnovu učenja. Nalazimo stroj za podršku vektora (SVM) pokazuje najveću efikasnost identifikacije nasilnog sadržaja. Mi oslobodimo annotiranog korpusa za istraživača da pomogne otkrivanju nasilnog sadržaja u podacima o društvenim medijima Bengalija.', 'bn': 'বাংলাদেশের মতো নিম্ন সম্পদ ও টুলের সমাধান না হওয়ার কারণে নিম্নলিখিত টেক্সট আবিষ্কার করা একটি চ্যালেঞ্জ কাজ। সামাজিক প্রচার মাধ্যমে বাংলাদেশের বিভিন্ন মন্তব্যের বৈষম্য তারা এই কাজে আরো জড়িত করেছে যেহেতু সামাজিক ভাষার প্রতিক্ দুর্ভাগ্যবশত, কোন ট্রান্সলিকেট বাংলা কোর্পাস প্রকাশ্যে পাওয়া যাচ্ছে না কোন বাংলাদেশী বিষয়বস্তু বিশ তাই এই কাগজটিতে আমরা ৩০০০ টি ট্রান্সলিটার বাংলার মন্তব্যের একটি বিরক্তিকর বাংলাদেশের মন্তব্য পরিচয় করিয়ে দিচ্ছি যা দুটি শ্রেণীতে বিভক্ত, অত্যাচার এব বেস্ট লাইনের মূল্যের জন্য আমরা বেশ কয়েকটি পর্যবেক্ষক মেশিন শিক্ষা (এমএল) এবং গভীর শিক্ষাভিত্তিক শ্রেণীবিদের কাজ আমরা সমর্থন করি ভেক্টর মেশিন (এসভিএম) নির্যাতনের বিষয়বস্তু সনাক্ত করার জন্য সর্বোচ্চ কার্যক্রম প্রদর্শন করি। বাংলাদেশের সামাজিক প্রচার মাধ্যমের তথ্যে নির্যাতনের বিষয়বস্তু সন্ধানের জন্য আমরা গবেষকের জন্য স্বাধীনতা পাই।', 'fi': 'Väärinkäytöksen havaitseminen vähävaraisilla kielillä, kuten bengalissa, on haastava tehtävä resurssien ja työkalujen riittämättömyyden vuoksi. Transliteroitujen bengalinkielisten kommenttien levinneisyys sosiaalisessa mediassa tekee tehtävästä entistäkin tärkeämmän, sillä yksikieliset lähestymistavat eivät pysty vangitsemaan niitä. Valitettavasti yksikään transliteroitu bengalilainen korpus ei ole vielä julkisesti saatavilla loukkaavaa sisällönanalyysiä varten. Tämän vuoksi tässä artikkelissa esittelemme kommentoidun bengalinkielisen korpusen, jossa on 3000 transliteroitua bengalinkielistä kommenttia, jotka on luokiteltu kahteen luokkaan, loukkaava ja ei-loukkaava, 1500 kommenttia kullekin. Perusarvioinnissa käytämme useita valvottuja koneoppimista (ML) ja syväoppimiseen perustuvia luokittelijoita. Toteamme, että tukivektorikone (SVM) on tehokkain väärinkäytösten tunnistamisessa. Annamme merkityn korpusen tutkijalle vapaasti saataville auttaaksemme väärinkäytösten havaitsemista bengalilaisessa sosiaalisen median datassa.', 'cs': 'Detekce zneužívaného textu v jazycích s nízkými zdroji, jako je bengálština, je náročným úkolem kvůli nedostatku zdrojů a nástrojů. Všudypřítomnost transliterovaných bengálských komentářů v sociálních médiích činí tento úkol ještě více zapojeným, protože monojazyčné přístupy je nemohou zachytit. Bohužel, žádný transliterovaný bengálský korpus není dosud veřejně dostupný pro analýzu zneužívajícího obsahu. Proto v tomto článku představujeme anotovaný bengálský korpus 3000 transliterovaných bengálských komentářů kategorizovaných do dvou tříd, urážlivých a neurážlivých, 1500 komentářů pro každou. Pro základní hodnocení používáme několik strojového učení (ML) a klasifikátorů založených na hlubokém učení. Zjistili jsme, že podpora vektorového stroje (SVM) vykazuje nejvyšší účinnost při identifikaci zneužívajícího obsahu. Anotovaný korpus dáváme výzkumníkovi volně k dispozici, abychom pomohli detekovat zneužívající obsah v bengálských sociálních médiích.', 'et': 'Väärkohtlemine teksti tuvastamine vähese ressursiga keeltes, näiteks bengali keeles, on ressursside ja vahendite ebapiisavuse tõttu keeruline ülesanne. Translitereeritud bengali kommentaaride levik sotsiaalmeedias muudab ülesande veelgi kaasatumaks, sest ühekeelsed lähenemisviisid ei suuda neid tabada. Kahjuks ei ole translitereeritud bengali korpus veel avalikult kättesaadav kuritarvitavaks sisuanalüüsiks. Seetõttu tutvustame käesolevas artiklis selgitatud bengali korpust 3000 translitereeritud bengali kommentaari, mis on liigitatud kahte klassi, kuritarvitavad ja mittekuritarvitavad, 1500 kommentaari igaühe kohta. Alushindamiseks kasutame mitmeid juhendatud masinõppe (ML) ja sügavõppe põhiseid klassifitseerijaid. Leiame, et tugivektor masin (SVM) näitab kõrgeimat efektiivsust kuritarvitava sisu tuvastamisel. Teeme märgitud korpuse teadlasele vabalt kättesaadavaks, et aidata tuvastada kuritarvitavat sisu Bengali sotsiaalmeedia andmetes.', 'ca': "La detecció abusiva de textos en llengües de baix recursos com el bengalí és una tasca desafiadora degut a la insuficiencia de recursos i eines. La ubicació dels comentaris bengals transliterats als mitjans socials fa que la tasca sigui encara més involucrada perquè els enfocaments monolingües no els puguin capturar. Malauradament, encara no hi ha un cos bengalí transliterat disponible per a l'anàlisi abusiva del contingut. Així doncs, en aquest article introduïm un cos bengalí anotat de 3000 comentaris bengals transliterats categoritzat en dues classes, abusiv i no abusiv, 1500 comentaris per cada una. Per a les evaluacions basales, utilitzem diversos classificadors d'aprenentatge màquinari supervisats (ML) i profunds basats en aprenentatge. Trobem que la màquina de suport (SVM) mostra la millor eficacia per identificar continguts abusius. Fem lliurament disponible el cos anotat per a l'investigador per ajudar a detectar conteïts abusivs a les dades dels mitjans socials bengals.", 'sk': 'Zaznavanje zlorabe besedila v jezikih z nizkimi viri, kot je bengališčina, je zaradi nezadostnih virov in orodij zahtevna naloga. Zaradi vsepovsod transliteriranih bengalskih komentarjev v družbenih omrežjih je naloga še bolj vključena, saj jih enojezični pristopi ne morejo ujeti. Na žalost še noben transliteriran bengalski korpus ni javno dostopen za analizo zlorabe vsebine. Zato smo v tem prispevku predstavili označen bengalski korpus 3000 transliteriranih bengalskih komentarjev, kategoriziranih v dva razreda, zlorabljajoči in nežaljivi, 1500 komentarjev za vsakega. Za osnovne ocene uporabljamo več nadzorovanih strojnih učenj (ML) in klasifikatorjev na podlagi globokega učenja. Ugotovili smo, da podporni vektorski stroj (SVM) kaže najvišjo učinkovitost pri prepoznavanju zlorabnih vsebin. Za pomoč pri odkrivanju zlorab vsebin v bengalskih podatkih družbenih omrežij raziskovalcu omogočamo prosto dostopnost z oznakami.', 'ha': "Ana gane matsayin da aka ƙayyade cikin harshen-wuri kamar misali, Bangali yana wani aikin mai tsõratar da haske da ruwan ayuka. Babbata daga fassarar-littafin Bangali na gaya a cikin mitandai da jamii, yana sanya aikin ya zama mafi husũma a kwanan da hanyoyin wata na'asa ba ta kãma su ba. Babu'am, ba za'a iya ƙayyade kofu na transliterated Bangali ba don a iya ƙayyade bayani don a yi anadi ga maɓallin abuse. Saboda haka, a cikin wannan takarda, za mu introduce wani mataimaki na Bangali da aka rubuta 3,000 na fassarar bayãni, wanda aka rarrabe shi zuwa fassarar biyu, abuse da bã mai abuse ba, 15,000 ga kõwane. Yana yin amfani da jama'a masu tsari (ML) da masu baka karatun ƙaranci. Munã sãmu mashine mai ƙaranci (SV M) na nuna mafi girma ga gane cikin abun. Ina sami makarubin da aka buga, yana iya amfani da kwamfyuta don mutane da ke taimakon su gane abubuwa cikin mitandai na ƙarami.", 'he': 'גילוי טקסט מועלל בשפות משאבים נמוכות כמו בנגלי הוא משימה מאתגרת בגלל אי-מספיקות המשאבים והכלים. בכל מקום ההערות הבנגליות המתוספות בתקשורת חברתית גורמות למשימה להיות מעורבת אפילו יותר כיוון שגישות מונושפתיות לא יכולות לתפוס אותן. למרבה הצער, אף קופוס בנגאלי לא זמין לציבור עדיין לניתוח תוכן מתעלל. לכן, בעיתון הזה, אנחנו מציגים גופוס בנגאלי מוכתב של 3000 תגובות בנגאליות מוגזמות מוקטגוריות לשני כיסות, התעללות ולא התעללות, 1500 תגובות לכל אחד. עבור הערכות הבסיסיות, אנחנו משתמשים במספר מדברים על מכונות מבוקשים (ML) וקlassifikatורים מבוססים על למידה עמוקה. אנחנו מוצאים מכונת ויקטור תמיכה (SVM) מראה את היעילות הגבוהה ביותר לזהות תוכן מתעלל. We make the annotated corpus freely available for the researcher to aid abusive content detection in Bengali social media data.', 'bo': 'རྒྱུ་ནོར་མི་མང་ཆེ་བའི་སྐད་རིགས་ནང་དུ་Abusive text detection in low-resource languages such as Bengali is a challenging task because of the inadequacy of resources and tools. སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་གི་བརྗོད་རྗེས་ཀྱི་ubiquity་དེ་ནི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་གིས་གཞན་གྱི་ཐབས་ལམ་ལ་ཞིབ་སྐྱེལ་ ཡིན་ནའང་ཡིན་ལས་ཕལ་ཆེན་ཐོག་མཁན་གྱི་དབུགས་སྡེ་སྤྱི་ཚོགས་མི་འདུག་པས་བཟོ་བཅོས་བྱེད་པའི་ནང་དོན་དབུགས་ཞ དེར་བརྟེན། འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་གི་དོན་དག་གི་སྔར་འབྲི་མི་སྦྲེལ་བ་3000གྱི་ལག་གླེང་མོལ་གྱི་བསྡད་ཁང་ཞིག་བྲིས་པ་ཡིན། For baseline evaluations, we employ several supervised machine learning (ML) and deep learning-based classifiers. ང་ཚོས་རྒྱབ་སྐྱོར་གྱི་བརྩིས་འཁོར་ཐོག་ནས་བཟོ་བཅོས་བྱེད་པའི་ནང་དོན་མང་ཤོས་ཏེ་(SVM) ང་ཚོས་བརྟག་ཞིབ་པ་ལྟ་བུ་ཚོའི་ནང་དོན་དབུལ་གྱི་རྣམ་པ་སྟོང་པར་རང་དབང་ཐོག་ཏུ་འཇུག་ཐུབ་པ་ལས། བྷིན་གི་སྤྱི་ཚོ', 'jv': 'Learn Mode Ubquiti perusahaan kelangan kelangan Bengal sing dikarepaké ning media sotiki dadi ngupakan kelangan langkung sampeyan tambahan sing ora iso nggawe ngupakan. Yo sampeyan, durung ono terus-terusahaan Bengal kuwi wis publik gak bener kanggo nganggep ujian sing dikarolan urip. Nanging dolaha, ning alih punika ingkang, kita nganggep bantuan BenGali durung tanggal 30 000 terus alih sing dibenakake Bengal sing dikarolan telas telas, alusi lan ora-alusi, 1.500 terus layakno Ngawe Perintah sing isi diangkat kuwi, kita nguasai kanggo nyengkuyung nggambar mobil (ML) lan basa-nyengke kuwi diangkat kuwi nggambar. (SVM) Awak dhéwé ngejaraké perusahaan langkung ora ono kebebasan kanggo ngubah cercetung nggawe barang nggawe dolang-dolang sing perusahaan kanggo kebebasan gambarang nggawe'}
{'en': 'Are Multilingual Models Effective in ', 'es': '¿Los modelos multilingües son eficaces en el cambio de código?', 'fr': 'Les modèles multilingues sont-ils efficaces pour la commutation de code\xa0?', 'pt': 'Os modelos multilíngues são eficazes na troca de código?', 'ar': 'هل النماذج متعددة اللغات فعالة في تبديل الكود؟', 'hi': 'क्या बहुभाषी मॉडल कोड-स्विचिंग में प्रभावी हैं?', 'ja': '多言語モデルはコードスイッチングで効果的ですか？', 'zh': '多言模代码切换中有效否?', 'ru': 'Эффективны ли многоязычные модели в переходе на другой код?', 'ga': 'An bhfuil Múnlaí Ilteangacha Éifeachtach maidir le Cód-Athrú?', 'el': 'Είναι αποτελεσματικά τα πολύγλωσσα μοντέλα στην αλλαγή κώδικα;', 'ka': 'მრავალენგური მოდელები ეფექტიურია Code- Switching?', 'hu': 'A többnyelvű modellek hatékonyak a kódváltásban?', 'it': 'I modelli multilingui sono efficaci nel cambio di codice?', 'kk': 'Код ауыстыруда көп тілді үлгілер эффективі пе?', 'mk': 'Дали мултијазичките модели се ефективни во менувањето на кодови?', 'lt': 'Ar keičiant kodus veiksmingi daugiakalbiai modeliai?', 'ms': 'Adakah Model Berbahasa berkesan dalam Penukaran Kod?', 'ml': 'കോഡ്- മാറ്റുന്നതില്\u200d പല ഭാഷ മോഡലുകള്\u200d പ്രഭാവികമാണോ?', 'mt': 'Il-Mudelli Multilingwi huma Effettivi fil-Qlib tal-Kodiċi?', 'mn': 'Код-шилжүүлэхэд олон хэл загварууд нөлөөтэй юу?', 'pl': 'Czy modele wielojęzyczne są skuteczne w przełączaniu kodów?', 'no': 'Er fleirspråk modeller effektiv i kodsvising?', 'ro': 'Modelele multilingve sunt eficiente în schimbarea codurilor?', 'sr': 'Da li su multijezički modeli efikasni u prebacivanju kodova?', 'si': 'කෝඩ් ස්විච් එකේ ගොඩක් භාෂාවික මොඩේල් ප්\u200dරශ්නයක් තියෙනවද?', 'so': 'Isticmaalka noocyada luuqadaha badan ma saameyn ku leedahay isbedelka?', 'sv': 'Är flerspråkiga modeller effektiva vid kodväxling?', 'ta': 'குறியீடு- மாற்றுதலில் பல மொழி மாதிரிகள் விளைவாக இருக்கிறதா?', 'ur': 'کیا کڈ-سوئچ میں Multilingual Models Effective in Code-Switching?', 'uz': 'Kodlash usulida bir nechta tillar oĘ»zgartirib boĘ»ladimi?', 'vi': 'Chế độ đa ngôn ngữ có hiệu quả không?', 'bg': 'Ефективни ли са многоезичните модели при превключването на кодове?', 'nl': 'Zijn meertalige modellen effectief in code-switching?', 'de': 'Sind mehrsprachige Modelle effektiv im Code-Switching?', 'id': 'Apakah Model Berbahasa Efektif dalam Pertukaran Kode?', 'da': 'Er flersprogede modeller effektive i kodeskift?', 'ko': '다국어 모드는 코드 변환에 유효합니까?', 'fa': 'آیا مدل های زیادی زبان در تغییر قانونی موثر است؟', 'hr': 'Jesu li multijezički modeli učinkoviti u prebacivanju kodova?', 'af': 'Is Multilingual Models Effective in Code- Switching?', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'tr': 'Ködlemeler üýtgewinde etkisi bar?', 'hy': 'Արդյո՞ք բազլեզու մոդելները արդյունավետ են կոդի փոխակերպման մեջ:', 'bn': 'কোড- পরিবর্তনে মাল্টিভাষার মডেল কি কার্যকর?', 'sq': 'A janë modelet shumëgjuhëse efektive në ndryshimin e kodeve?', 'az': 'Kod-Switching i칞ind톛 칞oxlu dil modell톛ri effektiv edirl톛r?', 'bs': 'Da li su multijezički modeli efikasni u prebacivanju kodova?', 'ca': 'Els models multilingües són efectius en el canvi de codis?', 'et': 'Kas mitmekeelsed mudelid on koodi vahetamisel tõhusad?', 'cs': 'Jsou vícejazyčné modely efektivní při přepínání kódu?', 'fi': 'Ovatko monikieliset mallit tehokkaita koodin vaihtamisessa?', 'sw': 'Je, Modeli za lugha nyingi zina ufanisi katika kubadilisha sheria?', 'he': 'האם מודלים רבות שפויות פועילות בתחלפת קודים?', 'ha': '@ action', 'jv': 'Apa ora oleh gambar Multi-Language Effect nang kode-Switch?', 'sk': 'Ali so večjezični modeli učinkoviti pri preklapljanju kod?', 'bo': 'སྐད་རིགས་སྤྱོད་མཁན་གྱི་མ་དབྱིབས་ནུས་པ་ཡིན་ནམ'}
{'en': 'Multilingual language models have shown decent performance in multilingual and cross-lingual natural language understanding tasks. However, the power of these multilingual models in code-switching tasks has not been fully explored. In this paper, we study the effectiveness of multilingual language models to understand their capability and adaptability to the mixed-language setting by considering the inference speed, performance, and number of parameters to measure their practicality. We conduct experiments in three language pairs on ', 'ar': 'أظهرت نماذج اللغات متعددة اللغات أداءً لائقًا في مهام فهم اللغة الطبيعية متعددة اللغات وعبر اللغات. ومع ذلك ، فإن قوة هذه النماذج متعددة اللغات في مهام تبديل الكود لم يتم استكشافها بالكامل. في هذه الورقة ، ندرس فعالية نماذج اللغات متعددة اللغات لفهم قدرتها وقابليتها للتكيف مع إعدادات اللغة المختلطة من خلال النظر في سرعة الاستدلال والأداء وعدد المعلمات لقياس مدى تطبيقها العملي. نجري تجارب في ثلاث أزواج لغوية على التعرف على الكيانات المسماة وعلامات جزء من الكلام ومقارنتها بالطرق الحالية ، مثل استخدام حفلات الزفاف ثنائية اللغة وحفلات الزفاف متعددة اللغات. تشير النتائج التي توصلنا إليها إلى أن النماذج متعددة اللغات المدربة مسبقًا لا تضمن بالضرورة تمثيلات عالية الجودة عند تبديل الكود ، بينما يحقق استخدام الزخارف الوصفية نتائج مماثلة بمعلمات أقل بكثير.', 'pt': 'Os modelos de linguagem multilíngue mostraram um desempenho decente em tarefas de compreensão de linguagem natural multilíngue e multilíngue. No entanto, o poder desses modelos multilíngues em tarefas de troca de código não foi totalmente explorado. Neste artigo, estudamos a eficácia de modelos de idiomas multilíngues para entender sua capacidade e adaptabilidade ao ambiente de idiomas mistos, considerando a velocidade de inferência, desempenho e número de parâmetros para medir sua praticidade. Conduzimos experimentos em três pares de idiomas sobre reconhecimento de entidade nomeada e marcação de parte da fala e os comparamos com métodos existentes, como o uso de embeddings bilíngues e meta-embeddings multilíngues. Nossas descobertas sugerem que modelos multilíngues pré-treinados não garantem necessariamente representações de alta qualidade na troca de código, enquanto o uso de meta-embeddings alcança resultados semelhantes com um número significativamente menor de parâmetros.', 'fr': "Les modèles linguistiques multilingues ont montré des performances décentes dans les tâches de compréhension du langage naturel multilingue et interlingue. Cependant, la puissance de ces modèles multilingues dans les tâches de commutation de code n'a pas été pleinement explorée. Dans cet article, nous étudions l'efficacité des modèles linguistiques multilingues pour comprendre leur capacité et leur adaptabilité au contexte de langues mixtes en tenant compte de la vitesse d'inférence, des performances et du nombre de paramètres permettant de mesurer leur caractère pratique. Nous menons des expériences dans trois paires de langues sur la reconnaissance d'entités nommées et le balisage de parties de discours et les comparons aux méthodes existantes, telles que l'utilisation d'intégrations bilingues et de méta-intégrations multilingues. Nos résultats suggèrent que les modèles multilingues pré-entraînés ne garantissent pas nécessairement des représentations de haute qualité lors de la commutation de code, tandis que l'utilisation de méta-embeddings permet d'obtenir des résultats similaires avec beaucoup moins de paramètres.", 'es': 'Los modelos lingüísticos multilingües han demostrado un rendimiento decente en las tareas de comprensión del lenguaje natural multilingües y multilingües. Sin embargo, no se ha explorado completamente el poder de estos modelos multilingües en las tareas de cambio de código. En este artículo, estudiamos la eficacia de los modelos lingüísticos multilingües para comprender su capacidad y adaptabilidad al entorno de idiomas mixtos, teniendo en cuenta la velocidad de inferencia, el rendimiento y el número de parámetros para medir su practicidad. Llevamos a cabo experimentos en tres pares de idiomas sobre el reconocimiento de entidades nombradas y el etiquetado de partes del habla y los comparamos con los métodos existentes, como el uso de incrustaciones bilingües y metaincrustaciones multilingües. Nuestros hallazgos sugieren que los modelos multilingües previamente entrenados no garantizan necesariamente representaciones de alta calidad en el cambio de código, mientras que el uso de metaincrustaciones logra resultados similares con muchos menos parámetros.', 'ja': '多言語言語モデルは、多言語およびクロスリンガルの自然言語理解タスクでまともなパフォーマンスを示しています。しかし、コードスイッチングタスクにおけるこれらの多言語モデルの力は、完全には探求されていない。本稿では，多言語モデルの実用性を測定するための推論スピード，パフォーマンス，パラメータの数を考慮して，混合言語設定に対する能力と適応性を理解するための多言語モデルの有効性を検討する．私たちは、名前付きエンティティ認識と音声の一部タグ付けに関する3つの言語ペアで実験を行い、バイリンガル埋め込みや多言語メタ埋め込みを使用するなど、既存の方法と比較します。私たちの調査結果は、事前にトレーニングされた多言語モデルがコードスイッチングの高品質な表現を保証するとは限らないことを示唆していますが、メタ埋め込みを使用すると、パラメータが大幅に少ない場合でも同様の結果が得られます。', 'zh': '多语言语言,语言自然语言解。 然多言代码切换强大之功未尽也。 本文之中,多言模有效性,思理速度,性与参数数量量其实用性,以知其混合言语之适应性。 三语实验其名词性,以较今法,如用双语嵌多语言元嵌。 臣等考结果表明,预训多言未必能保代码切换之高质量,而用元嵌可以更少参数得类也。', 'ru': 'Многоязычные языковые модели показали достойную результативность в многоязычных и межязычных задачах понимания естественного языка. Однако возможности этих многоязычных моделей в решении задач, связанных с переключением кодов, не были в полной мере изучены. В данной работе мы изучаем эффективность многоязычных языковых моделей, чтобы понять их способность и адаптируемость к смешанным языковым условиям, учитывая скорость вывода, производительность и количество параметров для измерения их практичности. Мы проводим эксперименты в трех языковых парах по распознаванию именованных сущностей и тегированию части речи и сравниваем их с существующими методами, такими как использование двуязычных вложений и многоязычных мета-вложений. Наши результаты показывают, что предварительно обученные многоязычные модели не обязательно гарантируют высокое качество представления при переключении кода, в то время как использование мета-вложений позволяет достичь аналогичных результатов при значительно меньшем количестве параметров.', 'hi': 'बहुभाषी भाषा मॉडल ने बहुभाषी और क्रॉस-लिंगुअल प्राकृतिक भाषा समझने वाले कार्यों में सभ्य प्रदर्शन दिखाया है। हालांकि, कोड-स्विचिंग कार्यों में इन बहुभाषी मॉडलों की शक्ति का पूरी तरह से पता नहीं लगाया गया है। इस पेपर में, हम उनकी व्यावहारिकता को मापने के लिए अनुमान की गति, प्रदर्शन और मापदंडों की संख्या पर विचार करके मिश्रित-भाषा सेटिंग के लिए उनकी क्षमता और अनुकूलन क्षमता को समझने के लिए बहुभाषी भाषा मॉडल की प्रभावशीलता का अध्ययन करते हैं। हम नामित इकाई मान्यता और पार्ट-ऑफ-स्पीच टैगिंग पर तीन भाषा जोड़े में प्रयोग करते हैं और उनकी तुलना मौजूदा तरीकों से करते हैं, जैसे कि द्विभाषी एम्बेडिंग और बहुभाषी मेटा-एम्बेडिंग का उपयोग करना। हमारे निष्कर्ष बताते हैं कि पूर्व-प्रशिक्षित बहुभाषी मॉडल आवश्यक रूप से कोड-स्विचिंग पर उच्च गुणवत्ता वाले प्रतिनिधित्व की गारंटी नहीं देते हैं, जबकि मेटा-एम्बेडिंग का उपयोग करने से काफी कम मापदंडों के साथ समान परिणाम प्राप्त होते हैं।', 'ga': 'Tá feidhmíocht mhaith léirithe ag samhlacha teanga ilteangacha i dtascanna nádúrtha ilteangacha agus tras-teangacha tuiscint teanga. Mar sin féin, níl iniúchadh iomlán déanta ar chumhacht na múnlaí ilteangacha seo i dtascanna códmhalartaithe. Sa pháipéar seo, déanaimid staidéar ar éifeachtúlacht na múnlaí teanga ilteangacha chun a gcumas agus a n-inoiriúnaitheacht do shuíomh measctha na teanga a thuiscint trí luas tátail, feidhmíocht agus líon na bparaiméadar a mheas chun a gcuid praiticiúlacht a thomhas. Déanaimid turgnaimh i dtrí phéire teanga ar aithint aonáin ainmnithe agus ar chlibeáil pháirteach cainte agus déanann muid iad a chur i gcomparáid le modhanna atá ann cheana féin, mar úsáid a bhaint as leabaithe dátheangacha agus meitea-leabaithe ilteangacha. Tugann ár dtorthaí le tuiscint nach gá go ráthaíonn samhlacha ilteangacha réamhoilte léiriúcháin ardchaighdeáin ar mhalartú cóid, agus baintear torthaí comhchosúla amach trí úsáid a bhaint as meitea-leabaithe le i bhfad níos lú paraiméadair.', 'hu': 'A többnyelvű nyelvi modellek megfelelő teljesítményt mutattak a többnyelvű és többnyelvű természetes nyelvértési feladatokban. Ezeknek a többnyelvű modelleknek a kódváltási feladatokban való erejét azonban nem vizsgálták teljes mértékben. Ebben a tanulmányban a többnyelvű nyelvi modellek hatékonyságát tanulmányozzuk a vegyes nyelvű beállításokhoz való alkalmazkodásuk és képességük megértésére, figyelembe véve a következtetési sebességet, teljesítményt és a gyakorlatiasságuk méréséhez szükséges paraméterek számát. Három nyelvpárban végzünk kísérleteket nevezett entitás felismerésével és beszédrészes címkézéssel, és összehasonlítjuk őket a meglévő módszerekkel, például kétnyelvű beágyazásokkal és többnyelvű metabeágyazásokkal. Eredményeink azt sugallják, hogy az előzetesen képzett többnyelvű modellek nem feltétlenül garantálják a kiváló minőségű ábrázolást a kódváltással kapcsolatban, míg a meta-beágyazások hasonló eredményeket érnek el jelentősen kevesebb paraméterrel.', 'el': 'Τα πολυγλωσσικά μοντέλα γλωσσών έχουν επιδείξει αξιοπρεπείς επιδόσεις σε εργασίες κατανόησης της πολυγλωσσικής και διγλωσσικής φυσικής γλώσσας. Ωστόσο, η ισχύς αυτών των πολύγλωσσων μοντέλων στις εργασίες αλλαγής κώδικα δεν έχει διερευνηθεί πλήρως. Στην παρούσα εργασία, μελετάμε την αποτελεσματικότητα των πολύγλωσσων γλωσσικών μοντέλων για να κατανοήσουμε την ικανότητά τους και την προσαρμοστικότητα τους στο περιβάλλον μικτής γλώσσας λαμβάνοντας υπόψη την ταχύτητα συμπερασμάτων, την απόδοση και τον αριθμό παραμέτρων για τη μέτρηση της πρακτικότητάς τους. Διεξάγουμε πειράματα σε τρία ζεύγη γλωσσών για αναγνώριση ονομαστικών οντοτήτων και σήμανση μέρους ομιλίας και τα συγκρίνουμε με υπάρχουσες μεθόδους, όπως η χρήση δίγλωσσων ενσωμάτωσης και πολύγλωσσων μετα-ενσωμάτωσης. Τα ευρήματά μας δείχνουν ότι τα προ-εκπαιδευμένα πολύγλωσσα μοντέλα δεν εγγυώνται απαραίτητα υψηλής ποιότητας αναπαραστάσεις στην αλλαγή κώδικα, ενώ η χρήση μετα-ενσωμάτωσης επιτυγχάνει παρόμοια αποτελέσματα με σημαντικά λιγότερες παραμέτρους.', 'ka': 'მრავალენგური ენების მოდელები მრავალენგური და მრავალენგური ენერგიის გაგრძნობის საკუთარი საკუთარი მუშაობაში ჩვენება. მაგრამ, ამ მრავალენგური მოდელების ძალიან კოდის გადაცვლის საქმებში არ აღმოჩნდა. ამ დოკუნში, ჩვენ ვისწავლით მრავალური ენის მოდელების ეფექტიურობას, რომ გავიგოთ მათი შესაძლებლობა და აპექტირება მრავალური ენის შესაძლებლობაზე, რომლებიც შეიცვალოთ ინფრენციის სიჩქარე, პროც ჩვენ ექსპერიმენტები სამუშაობის ზოგში გავაკეთებთ სამუშაობის სახელსაწყოთან სახელსაწყოთან სახელსაწყოთან სახელსაწყოთან სახელსაწყოთან და სახელსაწყოთან სახელსაწყოთან სახელსაწყოთან და შე ჩვენი შესაძლებლობები გვეჩვენება, რომ მრავალენგური მოდელები არ უნდა გადარწმუნოთ კოდის შეცვლაზე, როცა მეტა-შეცვლაზე გამოყენებული მოდელები მიიღება იგივე შესაძლებლობად მცირე პარამეტრებით', 'it': "I modelli linguistici multilingue hanno dimostrato prestazioni decenti nei compiti di comprensione della lingua naturale multilingue e multilingue. Tuttavia, la potenza di questi modelli multilingue nelle attività di cambio di codice non è stata pienamente esplorata. In questo articolo, studiamo l'efficacia dei modelli linguistici multilingue per comprenderne la capacità e l'adattabilità all'impostazione della lingua mista considerando la velocità di inferenza, le prestazioni e il numero di parametri per misurare la loro praticità. Conduciamo esperimenti in tre coppie linguistiche sul riconoscimento di entità nominate e sul tag part-of-speech e li confrontiamo con i metodi esistenti, come l'utilizzo di embedding bilingue e meta-embedding multilingue. I nostri risultati suggeriscono che i modelli multilingue pre-addestrati non garantiscono necessariamente rappresentazioni di alta qualità sul code-switching, mentre l'utilizzo di meta-embedding raggiunge risultati simili con significativamente meno parametri.", 'kk': 'Көп тіл үлгілері көп тілді және көп тілді тілді тапсырмаларды түсіндіру үшін дұрыс жұмыс істеу көрсетілді. Бірақ код ауыстыру тапсырмаларындағы көптілік үлгілердің қуаты толық зерттелмеген. Бұл қағазда біз көптеген тіл үлгілерінің ең әсерілігін зерттейміз, олардың көптеген тіл баптауларының мүмкіндігін және адаптациялығын түсіндіру үшін бірнеше тіл үлгілерінің ең әсерілігін түсі Біз үш тіл екеуінде тәжірибелерді аталған нысандарды анықтау және сөйлеудің бөлігін тегтерге салыстырып, оларды бар әдістерімен салыстырып, мысалы, екі тілді ендіру және көп тілді мета ендіру. Біздің іздегеніміз көптеген көптеген тілді үлгілер код ауыстыру үшін көптеген сапатты көрсетулерді қамтамасыз етпейді деп ойлайды. Метаинтеграцияларды қолдану үшін көптеген нәтижелерді көп деңгейі', 'lt': 'Multilingual language models have shown decent performance in multilingual and cross-lingual natural language understanding tasks.  Tačiau šių daugiakalbių modelių galia kodų keitimo užduotyse nebuvo išsamiai išnagrinėta. Šiame dokumente mes tiriame daugiakalbių kalbų modelių veiksmingumą, kad suprastume jų gebėjimus ir prisitaikymą prie mišrių kalbų nustatymo, atsižvelgdami į išvados greitį, veiksmingumą ir parametrų skaičių jų praktiškumui matuoti. Atliekame eksperimentus trijose kalbų porose dėl vardinio subjekto pripažinimo ir kalbos dalies ženklinimo ir palyginame juos su esamais metodais, pavyzdžiui, dvikalbių įterpčių ir daugiakalbių meta įterpčių naudojimu. Mūsų išvados rodo, kad iš anksto parengti daugiakalbiai modeliai nebūtinai užtikrina aukštos kokybės atstovavimą kodų keitimui, tuo pat metu naudojant meta įterpimus pasiekti panašius rezultatus ir gerokai mažiau parametrų.', 'ml': 'Multilingual language models have shown decent performance in multilingual and cross-lingual natural language understanding tasks.  എങ്കിലും കോഡ്- മാറ്റുന്ന ജോലികളില്\u200d ഈ പല ഭാഷ മോഡലുകളുടെ ശക്തി പൂര്\u200dണ്ണമായും പരിശോധിച്ചിട്ടില്ല. ഈ പത്രത്തില്\u200d നമ്മള്\u200d പല ഭാഷ മോഡലുകളുടെ പ്രകൃതി പഠിക്കുന്നു, അവരുടെ ഭാഷയുടെ സാധ്യതയും മിഷ്ടപ്പെട്ട ഭാഷയുടെ സജ്ജീകരണങ്ങള്\u200dക്ക് മനസ്സിലാക്കാന്\u200d അവരുടെ കഴ സാധാരണ തിരിച്ചറിയുന്നതിനും ഭാഗം സംസാരിക്കുന്നതിനും പേരില്\u200d നാം മൂന്നു ഭാഷകളില്\u200d പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്നു. നിലവിലുള്ള രീതികളോട് അവരെ  നമ്മുടെ കണ്ടുപിടിക്കുന്നത് മുമ്പ് പരിശീലിക്കപ്പെട്ട പലിഭാഷകങ്ങളുടെ മോഡലുകള്\u200d കോഡ്- മാറ്റുന്നതിന്റെ ഉയര്\u200dത്തിയ പ്രതിനിധികള്\u200d ഉറപ്പ് വരുത്തുന്നി', 'ms': 'Model bahasa berbilang telah menunjukkan prestasi yang layak dalam tugas pemahaman bahasa alam berbilang bahasa dan saling bahasa. Namun, kuasa model berbilang bahasa ini dalam tugas penyukaran kod belum diselesaikan sepenuhnya. Dalam kertas ini, kami mempelajari keefektivitas model bahasa berbilang bahasa untuk memahami kemampuan dan kemampuan mereka untuk tetapan bahasa-campuran dengan mempertimbangkan kelajuan kesimpulan, prestasi, dan bilangan parameter untuk mengukur praktikal mereka. Kami melakukan eksperimen dalam tiga pasangan bahasa pada pengenalan entiti bernama dan tag-bahagian-ucapan dan membandingkannya dengan kaedah yang wujud, seperti menggunakan penyembedding dua bahasa dan meta-penyembedding berbilang bahasa. Penemuan kami menunjukkan bahawa model berbilang bahasa yang dilatih tidak perlu menjamin perwakilan kualiti tinggi pada penyukaran kod, sementara menggunakan penyembedding-meta mencapai keputusan yang sama dengan jauh kurang parameter.', 'mt': 'Il-mudelli tal-lingwi multilingwi wrew prestazzjoni deċenti f’kompiti ta’ fehim tal-lingwi naturali multilingwi u translingwi. Madankollu, is-saħħa ta’ dawn il-mudelli multilingwi fil-kompiti ta’ skambju tal-kodiċi ma ġietx esplorata kompletament. F’dan id-dokument, nistudjaw l-effettività tal-mudelli multilingwi biex nifhmu l-kapaċità u l-adattabilità tagħhom għall-issettjar tal-lingwi mħallta billi nikkunsidraw il-veloċità tal-inferenza, il-prestazzjoni, u n-numru ta’ parametri biex titkejjel il-prattikalità tagħhom. Aħna nagħmlu esperimenti fi tliet pari lingwistiċi dwar ir-rikonoxximent tal-entità msemmija u t-tikkettar ta’ parti mid-diskors u nqabbluhom ma’ metodi eżistenti, bħall-użu ta’ inkorporazzjonijiet bilingwi u meta-inkorporazzjonijiet multilingwi. Is-sejbiet tagħna jissuġġerixxu li mudelli multilingwi mħarrġa minn qabel mhux neċessarjament jiggarantixxu rappreżentazzjonijiet ta’ kwalità għolja fuq il-qlib tal-kodiċi, filwaqt li l-użu ta’ meta-inkorporazzjonijiet jikseb riżultati simili b’inqas parametri b’mod sinifikanti.', 'mk': 'Multilingual language models have shown decent performance in multilingual and cross-lingual natural language understanding tasks.  Сепак, моќта на овие мултијазични модели во задачите за промена на кодови не е целосно истражена. Во овој весник ја проучуваме ефикасноста на мултијазичните јазички модели за да ја разбереме нивната способност и адаптабилност на поставувањето на мешаниот јазик со разгледување на брзината на конференцијата, перформансата и бројот на параметри за мерење на нивната практичност. Ние спроведуваме експерименти во три пара јазици на препознавање на именувани ентитети и дел од говорното означување и ги споредуваме со постојните методи, како што е користењето двојјазични вложувања и мултијазични мета-вложувања. Нашите откритија укажуваат на тоа дека предобучените мултијазични модели не неопходно гарантираат висококвалитетни претставувања на промената на кодови, додека употребата на мета-вградувања постигнува слични резултати со значително помалку параметри.', 'mn': 'Олон хэл загварууд нь олон хэл болон олон хэл хэл ойлгох үйл ажиллагаанд сайн үйл ажиллагааг харуулсан. Гэхдээ эдгээр олон хэл загварын эрх мэдлийг кодын шилжүүлэх үйл ажиллагаанд бүрэн судалгаагүй. Энэ цаасан дээр бид олон хэл загварын үр дүнг судалдаг. Тэдний бодит байдлыг хэмжээний хурд, үйл ажиллагаа, хэлбэрийг хэмжээнд хэмжээний чадварыг ойлгох боломжтой байдлыг ойлгох боломжтой. Бид эдгээрийн нэр тодорхойлолт, ярианы нэг хэсэг дээр 3 хэл хоорондоо туршилт хийдэг. Жишээ нь, хоёр хэл холбоотой, олон хэл мета-интербинг ашиглаж байгаа аргыг харьцуулдаг. Бидний олон хэл сургалтын өмнө сургалтын загварууд код шилжүүлэхэд өндөр чанартай харилцааныг баталж чадахгүй гэдгийг сануулдаг.', 'pl': 'Wielojęzyczne modele językowe wykazały godne osiągnięcia w wielojęzycznych i wielojęzycznych zadaniach rozumienia języka naturalnego. Jednakże moc tych wielojęzycznych modeli w zadaniach przełączania kodu nie została w pełni zbadana. W niniejszym artykule badamy skuteczność wielojęzycznych modeli językowych w celu zrozumienia ich zdolności i adaptacji do otoczenia mieszanego języka, biorąc pod uwagę szybkość wnioskowania, wydajność i liczbę parametrów pomiaru ich praktyczności. Przeprowadzamy eksperymenty w trzech parach językowych na temat rozpoznawania nazwanych jednostek i tagowania części mowy oraz porównujemy je z istniejącymi metodami, takimi jak wykorzystanie dwujęzycznych osadzeń i wielojęzycznych meta-osadzeń. Nasze wyniki sugerują, że wstępnie przeszkolone modele wielojęzyczne niekoniecznie gwarantują wysoką jakość reprezentacji przy przełączaniu kodu, podczas gdy stosowanie meta-embeddingów osiąga podobne rezultaty przy znacznie mniejszej liczbie parametrów.', 'no': 'Fleirspråk-modeller har vist godt utvikling i fleirspråk og krysspråk naturleg forståking av oppgåver. Det er imidlertid ikkje fullstendig utforska makten på desse fleirspråksmodelane i kodbyteringsoppgåver. I denne papiret studerer vi effektiviteten av fleirspråk-modeller for å forstå dei kapasiteten og tilpassabileten til den blandespråk-innstillinga ved å forstå infeksjonsfart, utviklinga og antall parametra for å måle praktiske verdiane. Vi gjer eksperimenter i tre språkopar på namnet entitetskjenning og ein del av talemerking og sammenliknar dei med eksisterande metodar, som bruk bilingåle innbygging og fleirspråk metainnbygging. Finningane våre tyder på at fleirspråk modeller først trengte ikkje nødvendig garanterer høg kvalitetssrepresentasjonar ved å byta kodar, mens metainnbygging gjer liknande resultat med mykje mindre parametrar.', 'sr': 'Mnogi jezički modeli pokazali su pristojnu funkciju u vezi razumijevanja multijezičkih i kroz-jezičkih prirodnih jezika. Međutim, moć ovih multijezičkih modela u zadatkima za prebacivanje kodova nije potpuno istražena. U ovom papiru proučavamo učinkovitost multijezičkih modela kako bi razumeli njihovu sposobnost i prilagodljivost mješanim jezikom razmatrajući brzinu infekcije, učinkovitost i broj parametara kako bi izmjerili njihovu praktičnost. Mi vodimo eksperimente na tri jezička parova o priznanju entiteta i označavanju dijela govora i uspoređujemo ih sa postojećim metodama, poput korištenja dvojezičkih integracija i multijezičkih meta-integracija. Naši nalazi sugeriraju da pre-obučeni multijezički modeli ne garantuju visoke kvalitetne predstave na zamjenu kodova, dok koristimo meta-integracije postiže slične rezultate sa značajno manjim parametrama.', 'ro': 'Modelele lingvistice multilingve au demonstrat performanțe decente în sarcinile de înțelegere a limbilor naturale multilingve și interlingve. Cu toate acestea, puterea acestor modele multilingve în sarcinile de schimbare a codurilor nu a fost explorată pe deplin. În această lucrare, studiem eficacitatea modelelor lingvistice multilingve pentru a înțelege capacitatea și adaptabilitatea acestora la setarea limbii mixte, luând în considerare viteza inferenței, performanța și numărul de parametri pentru a măsura caracterul lor practic. Realizăm experimente în trei perechi de limbi privind recunoașterea entităților denumite și etichetarea parțială de vorbire și le comparăm cu metodele existente, cum ar fi utilizarea încorporărilor bilingve și meta-încorporărilor multilingve. Rezultatele noastre sugerează că modelele multilingve pre-instruite nu garantează neapărat reprezentări de înaltă calitate în schimbarea codului, în timp ce utilizarea meta-încorporări obține rezultate similare cu mai puțini parametri.', 'si': 'ගොඩක් භාෂාවක් භාෂාවක් මොඩේල්ස් පෙන්වන්නේ ගොඩක් භාෂාවක් සහ ප්\u200dරශ්ණ භාෂාවක් භාෂා නමුත්, කෝඩ් වෙනස් වෙන්න වැඩේ මෙම විශේෂ භාෂාවක් මොඩල් මොඩල් බලය සම්පූර්ණයෙන්ම පරීක්ෂණ මේ පැත්තේ, අපි ගොඩක් භාෂාවක් මොඩේල්ස් විදියට පරීක්ෂා කරනවා ඔවුන්ගේ ප්\u200dරයෝජනය සහ භාෂාව සැකසුම් සඳහා මිශ්\u200dරීය වේගයක්, වැඩිය අපි භාෂාව තුනක් දෙන්න ප්\u200dරයෝජනය කරනවා නම් අයිතිය අඳුරගන්න සහ කොටසක් භාෂාව ප්\u200dරයෝජනය සඳහා ඔවුන්ව තියෙන්න තියෙන ප්\u200dරයෝජනය අපේ හොයාගන්න පුළුවන් විදිහට ප්\u200dරධානය කළු විශේෂ භාෂාවක් මොඩල් වලට කෝඩ් ස්විච්චි වෙනුවෙන් ඉහළ ස්වභාවිත විදිහට අවශ්\u200d', 'sv': 'Flerspråkiga språkmodeller har visat anständiga resultat i flerspråkiga och flerspråkiga naturspråksuppgifter. Effekten hos dessa flerspråkiga modeller i kodbytesuppgifter har dock inte undersökts fullt ut. I denna uppsats studerar vi effektiviteten av flerspråkiga språkmodeller för att förstå deras förmåga och anpassningsförmåga till blandade språk inställning genom att beakta inferensens hastighet, prestanda och antal parametrar för att mäta deras praktiska användbarhet. Vi genomför experiment i tre språkpar på namngiven entitetsigenkänning och del-av-tal taggning och jämför dem med befintliga metoder, till exempel tvåspråkiga inbäddningar och flerspråkiga metainbäddningar. Våra resultat tyder på att förintränade flerspråkiga modeller inte nödvändigtvis garanterar representationer av hög kvalitet vid kodväxling, medan användning av metainbäddningar ger liknande resultat med betydligt färre parametrar.', 'so': 'Tusaalada luuqadaha luuqadaha kala duduwan waxay muujiyaan shaqooyin wanaagsan oo ku saabsan waxyaabaha garashada luuqadaha kala duduwan iyo luuqadaha kala duduwan. Si kastaba ha ahaatee sameynta qaababkan luuqadaha kala duduwan ee goobaha codsiga looma baahan karo si buuxda ah. Qoraalkan ayaannu ku baranaynaa awoodooda iyo isku adag u yeelashada qoraalka luuqada kala duduwan, marka aan ka fikirinno dhaqdhaqaalaha, sameynta iyo tirada lambarka si ay u qiyaasaan tababarka. Imtixaanka waxaan ku sameynaa saddex nooc oo af ah oo lagu magacaabay aqoonsiga entity iyo qeyb ka mid ah hadalka, waxaana la barbaranaynaa qaababka joogta ah, tusaale ahaan isticmaalka qalabka labada luqadood iyo qalabka kala duduwan. Shaqooyinkayada waxaa loola jeedaa in noocyada afka hore oo kala tababaray aan si qasab ah u garanaynin kuwa ka dhigan kooxda is-beddelka, marka lagu isticmaalayo faa’iido isku mid ah oo ay ka helaan parameters aad u yar.', 'ur': 'Multilingual language models have shown decent performance in multilingual and cross-lingual natural language understanding tasks. لیکن یہ بہت سی زبان مدلکوں کی طاقت کوڈ-سوئٹ کے کاموں میں پورے طور پر تحقیق نہیں کی گئی۔ اس کاغذ میں ہم بہت سی زبان کی مدلکوں کے مطابق پڑھتے ہیں کہ ان کی قابلیت سمجھ سکیں اور ان کی مختلف زبان کی تنظیمات کے ساتھ اضافہ کریں کہ ان کے مطابق مطابق کی سرعت، فعالیت اور پارامیٹروں کی تعداد مطابق کریں۔ ہم تین زبان جوڑوں میں آزمائش کررہے ہیں جن کا نام ایک ٹیٹی شناسایی اور ایک ٹیٹ کی ٹیگ اور ان کو موجود طریقوں سے مقایسہ کررہے ہیں، جیسے دو زبان انڈینگ اور بہت سی زبان مٹا-انڈینگ استعمال کررہے ہیں. ہمارے نتیجے اس سے پیش آموزش کی بہت سی زبان مدل کو کوڈ-سوچینگ پر زیادہ کیفیت کی تصویر نہیں کرتی، حالانکہ مٹا-ایمبڈینگ کے استعمال سے بہت کم پارامیٹر کے ساتھ برابر نتیجے حاصل کرتے ہیں.', 'ta': 'பல மொழி மொழி மாதிரி மாதிரிகள் பல மொழி மற்றும் பல மொழி புரியும் செயல்களில் சரியான செயல்பாட்டை காட்டியுள்ளது. However, the power of these multilingual models in code-switching tasks has not been fully explored.  இந்த காகிதத்தில், நாம் பல மொழி மாதிரிகளின் விளைவுகளைப் புரிந்து கொள்கிறோம் அவர்கள் கலந்த மொழி அமைப்பை புரிந்து கொள்ள முடியும் மற்றும் குறைவா நாம் மூன்று மொழி ஜோடிகளில் சோதனைகளை செய்கிறோம் உண்மையின் அடையாளம் மற்றும் பேச்சின் பகுதி குறியீடு பெயரிடப்பட்டுள்ளது மற்றும் நிகழ்ந்த முற எங்கள் கண்டுபிடிப்புகளுக்கு முன் பயிற்சிக்கப்பட்ட பல மொழி மாதிரிகள் குறிமுறைமாற்றத்தில் உயர்தரமான பிரிவுகளை பாதுகாக்குவதில்லை என்று தெரியும், ம', 'vi': 'Các mô hình ngôn ngữ đa ngôn ngữ đã cho thấy hiệu quả tốt trong các nhiệm vụ hiểu biết ngôn ngữ tự nhiên đa dạng. Tuy nhiên, sức mạnh của những mô hình đa dạng này trong các công việc chuyển đổi mã chưa được khám phá đầy đủ. Trong tờ giấy này, chúng tôi nghiên cứu tính hiệu quả của các mô- đun ngôn ngữ đa dạng để hiểu khả năng và khả năng thích ứng của chúng với thiết lập ngôn ngữ chung bằng cách xem xét tốc độ, hiệu quả và số tham số để đo mức thực của chúng. Chúng tôi thực hiện các thí nghiệm trong ba cặp ngôn ngữ về nhận dạng thực thể tên và mô phỏng phần văn bản và so sánh chúng với các phương pháp có tồn tại, như sử dụng sự nhúng vào hai thứ và bắt chéo các meta-embeds đa dạng. Những nghiên cứu của chúng tôi cho thấy những mô- đun đa dạng được đào tạo trước không phải đảm bảo các biểu tượng cao chất lượng về việc chuyển đổi mã, trong khi sử dụng các meta-human đạt kết quả tương tự với giá trị thấp hơn.', 'uz': "Bir necha tillar modellari bir tillar va har xil tillarda o'xshash ishni tushunadi. However, the power of these multilingual models in code-switching tasks has not been fully explored.  Bu hujjatda biz bir necha tillar modellarining imkoniyatini o'rganamiz va o'zgarishni o'rganamiz va o'zgarishni o'rganamiz, tezlik, bajarish va parametrlarini o'zgartirishni tasavvur qilish mumkin. Biz quyidagi tasdiqlarni uchta tillar qo'llari bilan bajaramiz va suhbatning qismlarini tasdiqlash va ularni mavjud usullar bilan kamaytirish mumkin. Masalan ikkita tillar ichidagi va bir tillar meta-foydalanishdan foydalanish mumkin. Bizning murakkablarimiz esa, bir necha tildan oldin o'rganilgan modellar kod- oʻzgarishda juda katta qiymatni ishlatish kerak emas, ammo meta- embeddingi ishlatish uchun bir xil natijalarni juda kichkina parametrlar bilan ishlatish mumkin.", 'bg': 'Многоезичните езикови модели са показали достойно представяне в многоезичните и междуезичните задачи за разбиране на естествения език. Въпреки това, силата на тези многоезични модели при задачите за превключване на код не е напълно проучена. В настоящата статия изследваме ефективността на многоезичните езикови модели за разбиране на тяхната способност и адаптивност към смесената езикова настройка чрез отчитане на скоростта на заключение, производителността и броя на параметрите за измерване на тяхната практичност. Провеждаме експерименти в три езикови двойки за разпознаване на имена и маркиране на част от речта и ги сравняваме със съществуващи методи, като например използване на двуезични вграждания и многоезични метавграждания. Нашите констатации предполагат, че предварително обучените многоезични модели не гарантират непременно високо качество на представянето при превключване на код, докато използването на мета вграждания постига подобни резултати със значително по-малко параметри.', 'nl': 'Meertalige taalmodellen hebben fatsoenlijke prestaties getoond bij meertalige en meertalige begrijptaken van natuurlijke taal. De kracht van deze meertalige modellen bij codewisselingstaken is echter niet volledig onderzocht. In dit artikel bestuderen we de effectiviteit van meertalige taalmodellen om hun capaciteiten en aanpassingsvermogen te begrijpen aan de gemengde taalsetting door rekening te houden met de inferentiesnelheid, prestaties en het aantal parameters om hun bruikbaarheid te meten. We voeren experimenten uit met drie taalparen op naamsbekendheid en part-of-speech tagging en vergelijken deze met bestaande methoden, zoals het gebruik van tweetalige embeddings en meertalige meta-embeddings. Onze bevindingen suggereren dat voorgetrainde meertalige modellen niet noodzakelijkerwijs hoogwaardige representaties garanderen op code-switching, terwijl het gebruik van meta-embeddings vergelijkbare resultaten oplevert met aanzienlijk minder parameters.', 'hr': 'Mnogi jezički modeli pokazali su pristojnu učinku u zadatkima razumijevanja multijezičkih i cross-jezičkih prirodnih jezika. Međutim, moć ovih multijezičkih modela u zadatkima za prebacivanje kodova nije potpuno istražena. U ovom papiru proučavamo učinkovitost multijezičkih modela kako bi razumjeli njihovu sposobnost i prilagodljivost mješanim jezikom s obzirom na brzinu infekcije, učinkovitost i broj parametara kako bi izmjerili njihovu praktičnost. Mi provodimo eksperimente u tri jezičke pare o priznanju entiteta i označavanju dijela govora i uspoređujemo ih s postojećim metodama, poput korištenja dvojezičkih ugrađenja i multijezičkih meta-ugrađenja. Naši nalazi sugeriraju da pre-obučeni multijezički modeli ne garantuju visoke kvalitetne predstave na zamjenu kodova, dok koristiti meta-integracije postiže slične rezultate s značajno manjim parametrama.', 'de': 'Mehrsprachige Sprachmodelle haben gute Leistungen bei mehrsprachigen und mehrsprachigen Aufgaben im Verständnis natürlicher Sprache gezeigt. Die Leistungsfähigkeit dieser mehrsprachigen Modelle bei Code-Switching-Aufgaben wurde jedoch noch nicht vollständig untersucht. In diesem Beitrag untersuchen wir die Effektivität mehrsprachiger Sprachmodelle, um ihre Fähigkeit und Anpassungsfähigkeit an gemischtsprachige Umgebungen zu verstehen, indem wir die Inferenzgeschwindigkeit, Leistung und Anzahl von Parametern berücksichtigen, um ihre Praktikabilität zu messen. Wir führen Experimente in drei Sprachpaaren zur Named Entity Erkennung und Part-of-Speech Tagging durch und vergleichen diese mit bestehenden Methoden, wie z.B. zweisprachige Einbettungen und mehrsprachige Meta-Einbettungen. Unsere Ergebnisse deuten darauf hin, dass vortrainierte mehrsprachige Modelle nicht unbedingt hochwertige Darstellungen auf Code-Switching garantieren, während der Einsatz von Meta-Embeddings ähnliche Ergebnisse mit deutlich weniger Parametern erzielt.', 'fa': 'مدل\u200cهای زبان\u200cهای زیادی، عملکرد مناسب در کار\u200cهای درک زبان\u200cهای زیادی و زیادی زبان\u200cهای طبیعی را نشان داده\u200cاند. ولی قدرت این مدل های متعدد زبان در کار تغییر کد کامل تحقیق نشده است. در این کاغذ، ما موثرت مدل\u200cهای زبان\u200cهای زیادی را مطالعه می\u200cکنیم تا توانایی\u200cهایشان و قابلیت\u200cهایشان را به تنظیم زبان\u200cهای مختلف بفهمیم، با توجه به سرعت، عملکرد و تعداد پارامترها برای اندازه\u200cگیری کاری\u200cهایشان. ما آزمایش\u200cها را در سه جفت زبان انجام می\u200cدهیم، در مورد شناسایی یک entity نامیده می\u200cشود و پاره\u200cای از نقاشی سخنرانی می\u200cکنیم و با روش\u200cهای موجود، مثل استفاده از انجمن\u200cهای دو زبان و متابدینگ\u200cهای چندین زبان مقایسه می\u200cکنیم. نتیجه\u200cهای ما پیش از آموزش مدل\u200cهای زیادی زبان\u200cها نیازی به عنوان نمایش\u200cهای کیفیت بالا در تغییر کد تضمین نمی\u200cکنند، در حالی که استفاده از استفاده از استفاده از استفاده از استفاده\u200cهای متابدینگ نتیجه\u200cهای مشابه با پارامترهای زیادی', 'ko': '다중 언어 모델은 다중 언어와 다중 언어의 자연 언어 이해 임무에서 좋은 성능을 나타낸다.그러나 이러한 다중 언어 모델이 코드 변환 작업에서의 역할은 아직 충분한 탐색을 얻지 못했다.본고에서 우리는 추리 속도, 성능과 파라미터 수량을 고려하여 다언어 모델의 실용성을 평가하고 다언어 모델이 그 능력을 이해하고 혼합 언어 환경에 대한 적응성에 대한 유효성을 연구했다.우리는 세 개의 언어에서 명명 실체 식별과 어성 표기 실험을 실시했고 기존의 방법과 비교했다. 예를 들어 이중 언어 삽입과 다중 언어 요소 삽입을 사용했다.우리의 연구 결과에 따르면 미리 훈련된 다중 언어 모델은 코드 전환의 높은 품질 표시를 보장할 수 있는 것이 아니라, 원 삽입을 사용하면 비슷한 결과를 얻을 수 있을 뿐만 아니라, 매개 변수도 훨씬 적다.', 'sw': 'Mfano wa lugha nyingi umeonyesha utendaji mzuri katika kazi za kuelewa lugha za asili na lugha mbalimbali. Hata hivyo, nguvu ya mifano hii ya lugha mbalimbali katika kazi za kubadilisha kodi haijatambuliwa kabisa. Katika karatasi hii, tunasoma ufanisi wa mifano ya lugha za lugha mbalimbali kuelewa uwezo wao na uwezekano wao wa kubadilikana na mazingira ya lugha tofauti kwa kuangalia kiwango cha uchunguzi, utendaji, na idadi ya parameters ili kupima uhalisia wao. Tunafanya majaribio katika lugha tatu kwa jina la kutambua entity and part of speech tagging and kulinganisha na njia zilizopo, kama vile kutumia vifaa vya lugha mbili na vifaa vya lugha mbalimbali. Matokeo yetu yanaonyesha kuwa mifano ya lugha zilizofunzwa kabla hazina lazima kuhakikisha uwakilishi wa kiwango kikubwa katika kubadilisha kodi, wakati kwa kutumia mabadiliko ya meta hufanikiwa matokeo yanayofanana na kipimo kidogo.', 'da': 'Flersprogede sprogmodeller har vist anstændig ydeevne i flersprogede og tværsprogede natursprogforståelsesopgaver. Disse flersprogede modeller har imidlertid ikke fuldstændig indflydelse på deres muligheder for at skifte kode. I denne artikel undersøger vi effektiviteten af flersprogede sprogmodeller til at forstå deres evne og tilpasningsevne til den blandede sprogindstilling ved at tage hensyn til inference hastighed, ydeevne og antal parametre til at måle deres praktiske anvendelighed. Vi gennemfører eksperimenter i tre sprogpar på navngivet entitetsgenkendelse og del-af-tale tagging og sammenligner dem med eksisterende metoder, såsom brug af tosprogede indlejringer og flersprogede meta-indlejringer. Vores resultater tyder på, at præ-trænede flersprogede modeller ikke nødvendigvis garanterer høj kvalitet repræsentationer på kodeskift, mens brug af meta-indlejringer opnår lignende resultater med betydeligt færre parametre.', 'tr': 'Birn채챌e dil nusgalary birn채챌e dil we 챌er챌e-dil tebigat dillerini d체힊체nmek 체챌in gowy t채zelikleri g철rkezildi. 횦철ne bu k철p dilli nusgalary흫 ga첵d edilmegi ba힊armady. Bu kagyzda, biz multi dil nusgalaryny흫 챌yky힊lygyny d체힊체nmek 체챌in, kanunlaryny흫 첵igrenligini we 챌yky힊lygyny d체힊체nmek 체챌in karma힊dyran diller d체z체mlerini d체힊체nmek 체챌in ullan첵arys. Biz bar 체챌 dil 챌iftde bir enti tana첵masy we s철zlerin bir par챌asynda experimentalary 챌ykar첵arys we olary bar d채ldir 첵oly bilen kar힊캇la힊tyr첵arys, 첵aly iki dil giri힊meleri we k철p dil meta-integratlaryny ulanmak 체챌in synani힊 ed첵채ris. 횉aplarymyz 철흫체nden 철흫체nden e휓itilen k철p dilli modeller k철dleme 챌aly힊ynda 첵okary kaliteli temsilleri garantla힊ma첵arlar, meta-integralary ulanyp de흫e d체힊체k parameterler bilen me흫ze힊 netijeleri 첵etip biler.', 'af': 'Veelvuldige taal-modelles het goeie prestaal in multitaal en kruistale natuurlike taal verstaan opdragte vertoon. Maar die krag van hierdie multitaalse modele in kode-wisseling opdragte is nie volledig ondersoek nie. In hierdie papier, ondersoek ons die effektiviteit van multilinglike taal modelles om hul kapasiteit en aanpasbaarheid te verstaan aan die gemengde taal instelling deur die ondersoek van die inferensie spoed, prestasie en aantal parameters om hul praktiwiteit te maak. Ons uitvoer eksperimente in drie taal paar op genaamde entiteit herken en deel van spraak merking en vergelyk hulle met bestaande metodes, soos twee tale inbettings en multitaal meta-inbettings gebruik. Ons gevinde beveel dat vooraf-onderwerp multitaalske modele nie noodsaaklik hoë-kwaliteit-voorstellings waarop kode-skeakel is nie, terwyl meta-inbêding gebruik word, het gelyke resultate bereik met betekenlik minder parameters.', 'am': 'የቋንቋ ቋንቋዎች ምሳሌዎች በቋንቋ እና በተለየ ቋንቋ የፍጥረት ቋንቋ ማስታወቂያ ስራዎችን ያሳያል፡፡ ነገር ግን የእነዚህ ብዙዎችን የቋንቋዎች ሥልጣን የኮድ-መለወጥ ስራዎችን በሙሉ አልተመረጠም፡፡ በዚህ ፕሮግራም፣ የጥቅምነት፣ ፈጥኖ፣ የድጋፍ እና ተግባራቸውን ለመለካት እና የቋንቋ ቋንቋ ምሳሌዎችን ለማስተዋል እናስተምራለን፡፡ በሦስት ቋንቋ አካባቢ እና የንግግር ማስታወቂያውን እና ክፍለ ንግግር ማሰናከል እና በተገኘው ሥርዓቶች እና በሁለት ቋንቋዎች አካባቢ እና በብዙ ቋንቋ ማተሚያ በመጠቀም እናስተያየዋለን፡፡ ፍለጋዎቻችን አስቀድሞ የተጠቃሚ የቋንቋ ቋንቋዎች ምሳሌዎች የኮድ-ማተላለፊያ ብልሃት መልዕክቶችን እንዲያረጋግጡ የሚያስፈልጋል፡፡', 'sq': 'Modelet e gjuhës shumëgjuhëse kanë treguar shfaqje të mirë në detyrat shumëgjuhëse dhe ndërgjuhësore të kuptimit të gjuhës natyrore. Megjithatë, fuqia e këtyre modeleve shumëgjuhësore në detyrat e ndërrimit të kodeve nuk është eksploruar plotësisht. In this paper, we study the effectiveness of multilingual language models to understand their capability and adaptability to the mixed-language setting by considering the inference speed, performance, and number of parameters to measure their practicality.  Ne kryejmë eksperimente në tre çifte gjuhësh në njohjen e emëruar të njësisë dhe shënimin e pjesës së fjalimit dhe i krahasojmë me metodat ekzistuese, të tilla si përdorimi i përfshirjeve dygjuhëse dhe metapërfshirjeve shumëgjuhëse. Zbulimet tona sugjerojnë se modelet e paratrajnuara shumëgjuhësore nuk garantojnë domosdoshmërisht përfaqësime të cilësisë së lartë në ndërrimin e kodeve, ndërsa përdorimi i meta-përfshirjeve arrin rezultate të ngjashme me më pak parametra.', 'id': 'Model berbagai bahasa telah menunjukkan prestasi yang layak dalam tugas pemahaman bahasa alam berbagai bahasa dan saling bahasa. Namun, kekuatan model berbilang bahasa ini dalam tugas penggantian kode belum sepenuhnya dikeksplorasi. Dalam kertas ini, kami mempelajari efektivitas model bahasa berbagai bahasa untuk memahami kemampuan dan adaptabilitas mereka kepada pengaturan bahasa-campuran dengan mempertimbangkan kecepatan, prestasi, dan jumlah parameter untuk mengukur praktikal mereka. Kami melakukan eksperimen dalam tiga pasangan bahasa pada pengenalan entitas bernama dan tagging bagian dari pidato dan membandingkannya dengan metode yang ada, seperti menggunakan embedding dua bahasa dan meta-embedding berbilang bahasa. Penemuan kami menunjukkan bahwa model multibahasa yang dilatih tidak perlu menjamin representation kualitas tinggi pada penyelesaian kode, sementara menggunakan meta-embedding mencapai hasil yang sama dengan jauh lebih sedikit parameter.', 'hy': "Բազլեզու լեզվի մոդելները արժանի արդյունք են ցույց տվել բազլեզու և միջլեզվի բնական լեզվի հասկանալու խնդիրներում: Այնուամենայնիվ, այս բազլեզու մոդելների ուժը կոդի փոխանակելու խնդիրներում ամբողջովին չի ուսումնասիրել: Այս թղթի մեջ մենք ուսումնասիրում ենք բազմալեզու լեզվի մոդելների արդյունավետությունը, որպեսզի հասկանանք նրանց կարողությունը և հարմարեցման կարողությունը խառնալեզվի միջոցով' հաշվի առնելով հետևյալների արագությունը, արտադրողությունը և պարամ Մենք փորձարկումներ ենք կատարում երեք լեզվով զույգերով անվանված էության ճանաչելու և խոսքի մասի նշանների վրա, և համեմատում ենք դրանք գոյություն ունեցող մեթոդների հետ, ինչպիսիք են երկլեզու ներդրումները և բազլեզու մետաներդրումները: Our findings suggest that pre-trained multilingual models do not necessarily guarantee high-quality representations on code-switching, while using meta-embeddings achieves similar results with significantly fewer parameters.", 'az': 'Çoxlu dil modelləri çoxlu dilli və çoxlu dilli təbiətli dil anlama işlərində yaxşı işlər göstərdilər. Ancaq bu çoxlu dil modellərin gücünü kodlama işlərində tamamilə keşfedilmədi. Bu kağızda, çoxlu dil modellərinin effektivliğini təhsil edirik ki, onların qabiliyyətini və dil düzəltməsini müxtəlif təyin etmək üçün qarışıqlıq sürətini, performansını və praktiqliyini ölçürmək üçün parametruların sayını çəkirik. Üç dil çiftində istifadə edirik və çoxlu dil meta-in şallarını istifadə edir. Bizim tapındıqlarımız, əvvəlcə təhsil edilmiş çoxlu dil modellərinin kodu dəyişdirməkdə yüksək kaliteli təsirlərini garantiya etmədiklərini iddia edir, meta-inbinglərini istifadə edərkən daha az parametrlərlə bənzər sonuçlar yetirir.', 'bn': 'বহুভাষাভাষী ভাষার মডেল অনেক ভাষায় ভাষায় ভাল ভাষা বুঝতে পারে ভালো ভাষায় প্রদর্শন করেছে। তবে কোড- পরিবর্তন করার ক্ষমতার এই বহুভাষার মডেলের ক্ষমতা সম্পূর্ণ তদন্ত করা হয়নি। এই কাগজটিতে আমরা মাল্টিভাষার মডেলের কার্যকলাপ বুঝতে পারি তাদের মিশ্র ভাষার সংক্রান্ত ক্ষমতা এবং প্রতিযোগিতা বোঝার মাধ্যমে মিশ্র ভাষার সংক্র আমরা তিন ভাষার জোড়ায় পরীক্ষা করি প্রতিষ্ঠানের স্বীকৃতি এবং অংশের ভাষার ট্যাগিং নামে এবং বিদ্যমান পদ্ধতির সাথে তাদের তুলনা করি, যেমন দুই ভাষার বি আমাদের আবিস্কার পরামর্শ প্রদান করা হয়েছে যে পূর্বে প্রশিক্ষিত বহুভাষী মডেল কোড-পরিবর্তনের উপর উচ্চ মানের প্রতিনিধিত্ব নিশ্চিত করে না, যদিও মেট-এমডিডিং ব্যবহ', 'bs': 'Mnogi jezički modeli pokazali su pristojnu učinku u zadatkima razumijevanja multijezičkih i kroz jezičke prirodne jezike. Međutim, moć ovih multijezičkih modela u zadacima za prebacivanje kodova nije potpuno istražena. U ovom papiru proučavamo učinkovitost multijezičkih modela kako bi razumjeli svoju sposobnost i prilagodljivost mješanim jezikom razmatrajući brzinu infekcije, učinkovitost i broj parametara kako bi izmjerili njihovu praktičnost. Mi vodimo eksperimente na tri jezička parova o priznanju entiteta i označavanju dijela govora i uspoređujemo ih sa postojećim metodama, poput korištenja dvojezičkih integracija i multijezičkih meta-integracija. Naši nalazi sugeriraju da pre-obučeni multijezički modeli ne garantuju visoke kvalitetne predstave na zamjenu kodova, dok koristiti meta-integracije postižu slične rezultate sa značajno manjim parametrama.', 'ca': "Els models de llenguatges multilingües han demostrat un rendiment decent en tasques multilingües i translingües de comprensió natural de llenguatges. No obstant això, el poder d'aquests models multilingües en tasques de canvi de codis no s'ha explorat plenament. En aquest paper estudiem l'eficacia dels models de llenguatges multilingües per entendre la seva capacitat i adaptabilitat a la configuració de llenguatges mixtes considerant la velocitat, el rendiment i el nombre de paràmetres per mesurar la seva practicalitat. Fem experiments en tres parelles de llengües sobre el reconeixement de les entitats anomenades i la etiqueta part-of-speech i els comparem amb els mètodes existents, com l'ús d'incorporacions bilingües i metaincorporacions multilingües. Els nostres descobriments suggereixen que els models multillengües pré-entrenats no necessariament garanteixen representacions d'alta qualitat en el canvi de codis, mentre que l'ús de metaintegracions aconsegueix resultats semblants amb molt menys paràmetres.", 'fi': 'Monikieliset kielimallit ovat osoittaneet hyvää suorituskykyä monikielisten ja monikielisten luonnollisten kielten ymmärtämiseen liittyvissä tehtävissä. Näiden monikielisten mallien tehoa koodinvaihtotehtävissä ei kuitenkaan ole tutkittu täysin. Tässä artikkelissa tutkimme monikielisten kielimallien tehokkuutta ymmärtämään niiden kykyä ja sopeutumiskykyä sekakieliseen ympäristöön tarkastelemalla päättelynopeutta, suorituskykyä ja parametrien määrää niiden käytännöllisyyden mittaamiseksi. Teemme kokeita kolmella kieliparilla nimettyjen entiteettien tunnistamisesta ja puheen osamerkinnästä ja vertaamme niitä olemassa oleviin menetelmiin, kuten kaksikielisten upotusten ja monikielisten meta-upotusten käyttöön. Tuloksemme viittaavat siihen, että esikoulutetut monikieliset mallit eivät välttämättä takaa korkealaatuisia esityksiä koodin vaihtamisesta, kun taas meta-upotusten avulla saavutetaan samanlaisia tuloksia huomattavasti pienemmillä parametreilla.', 'et': 'Mitmekeelsed keelemudelid on näidanud korralikku tulemust mitmekeelsete ja keeleüleste looduskeele mõistmise ülesannete täitmisel. Nende mitmekeelsete mudelite võimsust koodi vahetamisel ei ole siiski täielikult uuritud. Käesolevas töös uurime mitmekeelsete keelemudelite efektiivsust mõista nende võimet ja kohanemisvõimet segakeelse seadistusega, arvestades järelduste kiirust, jõudlust ja parameetrite arvu nende praktilisuse mõõtmiseks. Teostame eksperimente kolmes keelepaaris nimetatud olemite tuvastamise ja kõneosa sildistamise kohta ning võrdleme neid olemasolevate meetoditega, näiteks kakskeelsete manustamiste ja mitmekeelsete metamanustamiste kasutamisega. Meie tulemused näitavad, et eelnevalt koolitatud mitmekeelsed mudelid ei taga tingimata kvaliteetseid esitusi koodi vahetamise kohta, samas kui metamanustamise kasutamine saavutab sarnaseid tulemusi märkimisväärselt vähem parameetreid.', 'cs': 'Vícejazyčné jazykové modely prokázaly slušný výkon při vícejazyčných a vícejazyčných úkolech porozumění přirozenému jazyku. Možnost těchto vícejazyčných modelů v úkolech přepínání kódu však nebyla plně prozkoumána. V tomto článku studujeme efektivitu vícejazyčných jazykových modelů k porozumění jejich schopnosti a adaptabilitě na smíšené jazykové nastavení s ohledem na rychlost inference, výkonnost a počet parametrů pro měření jejich praktičnosti. Provádíme experimenty ve třech jazykových párech na rozpoznávání pojmenovaných entit a značení části řeči a porovnáváme je s existujícími metodami, jako je použití dvojjazyčných vložení a vícejazyčných meta-vložení. Naše zjištění naznačují, že předškolené vícejazyčné modely nemusí nutně zaručovat kvalitní reprezentace při přepínání kódu, zatímco použití meta-embeddingů dosahuje podobných výsledků s výrazně menším množstvím parametrů.', 'he': 'דוגמני שפות רבות הראו ביצועים הגונים במשימות הבנה טבעית שפות רבות ושפות. בכל אופן, הכוח של הדוגמנים הרב-שפותיים האלה במשימות החלפת קודים לא נחקר לחלוטין. בעיתון הזה, אנו לומדים את היעילות של דוגמני שפת רבות לשפות כדי להבין את היכולת שלהם וההיכולת שלהם להסתגל לשפת המערובת על ידי השקול מהירות, ביצועים ומספר הפרמטרים כדי למדוד את מעשיותם. אנו מבצעים ניסויים בשלושה זוגות שפות על זיהוי ישויות בשם וחלק של תג הנאום, ושווה אותם עם שיטות קיימות, כמו השימוש בתכניות שתיים שפות ומטה רבות שפות. הממצאים שלנו מצביעים כי דוגמנים רבות שפות מאומנים מראש לא בהכרח מבטיחים מייצגים איכות גבוהה על החלפת קודים, בעוד השימוש בתכניות מטה משיג תוצאות דומות עם פחות פארמטרים משמעותיים.', 'ha': "Motolin harshe masu yawa sun nuna aikin mai kyau a cikin aikin fahimta lugha'ura masu cikin mulki-lingui da ke tsakanin maganar-harshe. A lokacin da, ba za'a sami ƙarfin waɗannan misalin mulki-lingui ba cikin aikin mai musanya na kodi ba. Daga wannan takardan, Munã karanta aikin misãlai masu mulki-harshe dõmin su fahimta abincinsu da adadi ga daidaita-harshen da aka haɗa shi, ko da kafin da za'a yi sauri, da fassarar kuma da yawan parameteri dõmin su cika fasarin. Mu sami jarrabi cikin nau'i uku cikin sunan sunan ganin gaskiya da rabon magana, kuma Mu sami da su da hanyoyin wanda ke da shi, kamar misãlan misalin sauri biyu masu cikin lugha da mulki-lugha. FantayinMu na gaya cewa misãlai masu da aka yi wa zaman tsari na mulki-lingui, bã ya lazima a gaskata masu tsari ga nau'in kodi mai musanya, kuma a lokacin da za'a amfani da meta-embeddinga, sai ya sami matsalar da kamanta da parameteri kaɗan.", 'sk': 'Večjezični jezikovni modeli so pokazali dostojno uspešnost pri večjezičnih in medjezičnih nalogah razumevanja naravnega jezika. Vendar pa moč teh večjezičnih modelov pri preklapljanju kode ni bila v celoti raziskana. V prispevku preučujemo učinkovitost večjezičnih jezikovnih modelov za razumevanje njihove sposobnosti in prilagodljivosti na mešano jezikovno nastavitev z upoštevanjem hitrosti sklepanja, zmogljivosti in števila parametrov za merjenje njihove praktičnosti. Izvajamo eksperimente v treh jezikovnih parih na prepoznavanju imenovanih entitet in označevanju dela govora ter jih primerjamo z obstoječimi metodami, kot so uporaba dvojezičnih vdelav in večjezičnih meta vdelav. Naše ugotovitve kažejo, da predhodno usposobljeni večjezični modeli ne zagotavljajo nujno visokokakovostnih predstavitev o preklapljanju kode, medtem ko uporaba meta vdelav dosega podobne rezultate z bistveno manj parametrov.', 'bo': 'སྐད་རིགས་ཀྱི་མིང་དཔེ་དབྱིབས་ནི་སྐད་ཡིག་དང་སྐད་རིགས་ཀྱི་སྐོར་ཆ་མཐོང་ནི་ལྟ་སྟངས་མངོན་འཆར་བྱས་ཡོད། ཡིན་ནའང་། kod་འགྱུར་བྱེད་ཀྱི་བྱ་སྤྱོད་ནང་གི་སྣ་སྐད་ཀྱི་མིག་དཔེ་གཞི་ཚོའི་ནུས་སྟོན་གྱི་མ་རེད། In this paper, we study the effectiveness of multilingual language models to understand their capability and adaptability to the mixed-language setting by considering the inference speed, performance, and number of parameters to measure their practicality. ང་ཚོས་དབྱིན་ཡུལ་དང་འབྲེལ་བའི་ཐབས་ལམ་ལ་བརྗོད་པའི་སྐད་ཆ་གསུམ་ནང་གི་བརྟག་ཞིབ་བྱེད་པ་ལས་གྲངས་སུ་མཐུན་དགོས་པ་མིན་འདུག Our findings suggest that pre-trained multilingual models do not necessarily guarantee high-quality representations on code-switching, while using meta-embeddings achieves similar results with significantly fewer parameters.', 'jv': 'Mulalawat bang modelo sing ngerasakno akeh bantuan kanggo sabanjuré ning langgar sampeyan karo akeh langgar. Nanging, gawe sistem multi-lengkang model iki nang kode-kangangkang tasks ora bisa ranjelasno. Nang paper iki, kéné isih efekat kanggo modèl multilengu kuwi nggawe kapasituran karo adalah kanggo kalagayaan karo nggawe gerakan kanggo nggawe luwih bantuan, efekat lan nganggo langgar sampeyan kanggo ngerasakno kapasituran kanggo kalagayut nggawe kapasituran kanggo kalagayut nggawe gerakan. Awak dhéwé éntuk éntukong telu nggawe tindang karo pertaman kelas telu nggawe layang karo pertaman-tangan sing karo nggawe layang-tangan karo perusahaan karo perusahaan karo perusahaan, koyo ngono akeh mlang-tangan karo meta-embedding. Awakdhéwé éntukno nggawe barang-aké sistem multilenguang awak dhéwé kuwi butaké supoyo kuwi nggawe barang-kalite supoyo barang nggambar kode-bisa peranggap, terus nyimpen meta-embedding iso dianggap akeh sekondiki dadi barang ketahan karo akeh parameters.'}
