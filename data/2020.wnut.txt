{'en': 'Combining BERT with Static Word Embeddings for Categorizing Social Media BERT  with Static Word Embeddings for Categorizing Social Media', 'ar': 'الجمع بين BERT و Static Word Embeddings لتصنيف الوسائط الاجتماعية', 'fr': 'Combiner BERT avec des intégrations de mots statiques pour catégoriser les médias sociaux', 'pt': 'Combinando BERT com incorporação de palavras estáticas para categorizar mídias sociais', 'es': 'Combinación de BERT con incrustaciones de palabras estáticas para categorizar las redes sociales', 'ja': 'ソーシャルメディアを分類するためのBERTと静的ワード埋め込みの組み合わせ', 'zh': '嵌BERT与静态词,分社交媒体', 'ru': 'Объединение BERT с статическими вложениями слов для категоризации социальных сетей', 'hi': 'सामाजिक मीडिया को वर्गीकृत करने के लिए स्थैतिक शब्द एम्बेडिंग के साथ BERT का संयोजन', 'ga': 'BERT a chomhcheangal le Leabú Focal Statach chun Meáin Shóisialta a Chatagóiriú', 'it': 'Combinazione di BERT con incorporazioni statiche di parole per categorizzare i social media', 'el': 'Συνδυασμός με στατικές ενσωματώσεις λέξεων για την κατηγοριοποίηση κοινωνικών μέσων', 'ka': 'BERT- ს სტატიკური სიტყვების ჩვენება სოციალური მედია კატეგორიზაციისთვის', 'hu': 'A BERT és a statikus szóbeágyazások kombinációja a közösségi média kategorizálásához', 'lt': 'Combining BERT with Static Word Embeddings for Categorizing Social Media', 'kk': 'Қолымшалық медиаға санаттарды салу үшін статистикалық сөз ендіруде BERT- ті біріктіру', 'ml': 'സ്റ്റാറ്റിക് വാക്കുകളുമായി ബെര്\u200dട്ടിനെ കൂട്ടിച്ചേര്\u200dക്കുന്നു', 'mn': 'BERT-г нийгмийн мэдээллийн хувьд Статикийн үг нэмж', 'mk': 'Комбинирање на BERT со статички вградувања на зборови за категоризирање на социјалните медиуми', 'ms': 'Menggabung BERT dengan Penjelmaan Kata Statik untuk Mengkategori Media Sosial', 'mt': 'Il-kombinazzjoni tal-BERT mal-Inkorporazzjonijiet Statiċi tal-Kliem għall-Kategorizzazzjoni tal-Midja Soċjali', 'no': 'Kombinerer BERT med Statistiske ord- innbygging for å kategorisera sosiale mediar', 'sr': 'Kombiniranje BERT sa statističkim reèima za kategoriju socijalnih medija', 'pl': 'Łączenie BERT ze statycznymi osadzeniami słów do kategorizowania mediów społecznościowych', 'ro': 'Combinarea BERT cu încorporarea statică a cuvintelor pentru clasificarea rețelelor sociale', 'si': 'සාමාජික මිඩියාව විශේෂ කරගන්න BERT සමග ස්ථිර වචන සම්බන්ධ කරනවා', 'so': 'Combining BERT with Static Word Embeddings for Categoring Social Media', 'ta': 'Name', 'ur': 'BERT کے ساتھ سیٹیسک ویڈ ایمبڈینگ کے ساتھ پیدا کیا جاتا ہے', 'sv': 'Kombinera BERT med statiska ordinbäddningar för kategorisering av sociala medier', 'uz': 'Name', 'vi': 'Kết hợp giao thức ngôn ngữ rải rác để phân loại các phương tiện xã hội', 'hr': 'Kombiniranje BERT sa statističkim uvođenjem riječi za kategoriju socijalnih medija', 'bg': 'Комбиниране с вграждания на статични думи за категоризиране на социалните медии', 'de': 'Kombination von BERT mit statischen Word Embeddings zur Kategorisierung von Social Media', 'da': 'Kombination af BERT med statiske ordindlejringer til kategorisering af sociale medier', 'nl': 'BERT combineren met statische Word Embeddings voor het categoriseren van sociale media', 'ko': '정적 단어를 결합하여 소셜 미디어에 삽입하여 분류하다', 'tr': 'BERT Soýunlar Medýdançasyny Kategoriýa etmek üçin Statik söz Buýruklary bilen birleştirilýär', 'id': 'Kombinasi BERT dengan Pencampuran Kata Statik untuk Kategorisasi Media Sosial', 'fa': 'ترکیب BERT با جمع کردن کلمات آمریکایی برای تقسیم رسانه اجتماعی', 'sw': 'Kuunganisha BERT na Mazungumzo ya Hadithi ya Static kwa Kugawanya Vyombo vya Habari vya Kijamii', 'hy': 'BER-ը համադրվում է հասարակական լրատվամիջոցների դասակարգման համար ստատիկ բառերի ներգրավման հետ', 'af': 'Kombineer BERT met Statiese Woord Inbetering vir Kategoriseering Soziale Media', 'sq': 'Combining BERT with Static Word Embeddings for Categorizing Social Media', 'bn': 'সামাজিক মিডিয়ার ব্যাপারে স্টেটিক শব্দ দ্বারা বিরেটের সাথে যোগাযোগ করা হচ্ছে', 'am': 'BERT በማስተካከል ማኅበራዊ ሚዲያ', 'az': 'Sosyal Mediyaları Kategoriyasiyası üçün Statik Sözlük İfadələri ilə BERT birləşdirilən', 'bs': 'Kombinujući BERT sa statističkim slovima za kategoriju socijalnih medija', 'ca': 'Combinant BERT amb incorporacions de paraules estatiques per categoritzar mitjans socials', 'cs': 'Kombinace BERT se statickými vloženími slov pro kategorizaci sociálních médií', 'fi': 'BERT:n yhdistäminen staattisiin sanaupotuksiin sosiaalisen median luokittelua varten', 'et': 'BERTi kombineerimine staatiliste sõnade manustamisega sotsiaalmeedia kategooriate jaotamiseks', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Združevanje BERT s statičnimi besednimi vdelavami za kategorizacijo družbenih medijev', 'ha': 'KCharselect unicode block name', 'he': 'Combining BERT with Static Word Embeddings for Categorizing Social Media', 'bo': 'BERT སྦྲེལ་མཐུད་དེ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བརྗོད་པར་Static Word Embedding'}
{'en': 'Pre-trained neural language models (LMs) have achieved impressive results in various natural language processing tasks, across different languages. Surprisingly, this extends to the  social media genre , despite the fact that  social media  often has very different characteristics from the language that LMs have seen during training. A particularly striking example is the performance of AraBERT, an LM for the  Arabic language , which is successful in categorizing social media posts in  Arabic dialects , despite only having been trained on Modern Standard  Arabic . Our hypothesis in this paper is that the performance of LMs for  social media  can nonetheless be improved by incorporating static word vectors that have been specifically trained on  social media . We show that a simple method for incorporating such word vectors is indeed successful in several Arabic and English benchmarks. Curiously, however, we also find that similar improvements are possible with word vectors that have been trained on traditional text sources (e.g. Wikipedia).', 'ar': 'حققت نماذج اللغة العصبية المدربة مسبقًا (LMs) نتائج رائعة في مهام معالجة اللغة الطبيعية المختلفة ، عبر لغات مختلفة. من المثير للدهشة أن هذا يمتد إلى نوع وسائل التواصل الاجتماعي ، على الرغم من حقيقة أن وسائل التواصل الاجتماعي غالبًا ما تتميز بخصائص مختلفة جدًا عن اللغة التي شاهدها LM أثناء التدريب. ومن الأمثلة اللافتة للنظر بشكل خاص أداء AraBERT ، وهو LM للغة العربية ، والذي نجح في تصنيف منشورات وسائل التواصل الاجتماعي باللهجات العربية ، على الرغم من أنه تم تدريبه فقط على اللغة العربية الفصحى الحديثة. فرضيتنا في هذه الورقة أنه يمكن تحسين أداء LM لوسائل التواصل الاجتماعي من خلال دمج متجهات الكلمات الثابتة التي تم تدريبها بشكل خاص على وسائل التواصل الاجتماعي. نظهر أن طريقة بسيطة لدمج متجهات الكلمات هذه ناجحة بالفعل في العديد من المعايير القياسية العربية والإنجليزية. من الغريب أننا وجدنا أيضًا أن هناك تحسينات مماثلة ممكنة مع متجهات الكلمات التي تم تدريبها على مصادر النص التقليدية (مثل ويكيبيديا).', 'es': 'Los modelos de lenguaje neuronal (LM) preentrenados han logrado resultados impresionantes en varias tareas de procesamiento del lenguaje natural, en diferentes idiomas. Sorprendentemente, esto se extiende al género de las redes sociales, a pesar de que las redes sociales a menudo tienen características muy diferentes del lenguaje que los LM han visto durante el entrenamiento. Un ejemplo particularmente llamativo es la actuación de ARaBert, un LM para el idioma árabe, que tiene éxito en categorizar las publicaciones de las redes sociales en dialectos árabes, a pesar de haber recibido solo formación en árabe estándar moderno. Nuestra hipótesis en este artículo es que el rendimiento de los LM para las redes sociales puede mejorarse incorporando vectores de palabras estáticas que han sido entrenados específicamente en las redes sociales. Demostramos que un método simple para incorporar tales vectores de palabras es realmente exitoso en varios puntos de referencia en árabe e inglés. Sin embargo, curiosamente, también encontramos que son posibles mejoras similares con vectores de palabras que se han entrenado en fuentes de texto tradicionales (por ejemplo, Wikipedia).', 'pt': 'Modelos de linguagem neural (LMs) pré-treinados alcançaram resultados impressionantes em várias tarefas de processamento de linguagem natural, em diferentes idiomas. Surpreendentemente, isso se estende ao gênero de mídia social, apesar do fato de que a mídia social muitas vezes tem características muito diferentes da linguagem que os LMs viram durante o treinamento. Um exemplo particularmente marcante é o desempenho do AraBERT, um LM para o idioma árabe, que é bem-sucedido em categorizar postagens de mídia social em dialetos árabes, apesar de ter sido treinado apenas em árabe moderno padrão. Nossa hipótese neste artigo é que o desempenho de LMs para mídias sociais pode, no entanto, ser melhorado pela incorporação de vetores de palavras estáticos que foram treinados especificamente nas mídias sociais. Mostramos que um método simples para incorporar esses vetores de palavras é de fato bem-sucedido em vários benchmarks em árabe e inglês. Curiosamente, no entanto, também descobrimos que melhorias semelhantes são possíveis com vetores de palavras que foram treinados em fontes de texto tradicionais (por exemplo, Wikipedia).', 'ja': '事前に訓練されたニューラル言語モデル（ LM ）は、さまざまな言語にわたるさまざまな自然言語処理タスクで印象的な結果を達成しました。 驚くべきことに、これはソーシャルメディアのジャンルにも及んでいますが、ソーシャルメディアはしばしばLMがトレーニング中に見た言語とは大きく異なる特徴を持っています。 特に顕著な例は、アラビア語のLMであるAraBERTのパフォーマンスであり、現代の標準アラビア語のトレーニングを受けているにもかかわらず、アラビア語の方言でソーシャルメディアの投稿を分類することに成功しています。 本稿の仮説は、ソーシャルメディアのためのLMのパフォーマンスは、ソーシャルメディアで具体的にトレーニングされた静的な単語ベクトルを組み込むことによって改善できるというものである。 このような単語ベクトルを組み込むための単純な方法は、いくつかのアラビア語と英語のベンチマークで実際に成功していることを示しています。 しかし、不思議なことに、従来のテキストソース（例えば、ウィキペディア）でトレーニングされたワードベクトルでも同様の改善が可能であることがわかります。', 'fr': "Les modèles de langage neuronal (LM) pré-entraînés ont obtenu des résultats impressionnants dans diverses tâches de traitement du langage naturel, dans différentes langues. Étonnamment, cela s'étend au genre des médias sociaux, malgré le fait que les médias sociaux présentent souvent des caractéristiques très différentes de la langue que les ML ont vue pendant la formation. Un exemple particulièrement frappant est la performance d'AraBert, un LM pour la langue arabe, qui réussit à catégoriser les publications sur les réseaux sociaux en dialectes arabes, bien qu'il n'ait été formé qu'à l'arabe standard moderne. Notre hypothèse dans cet article est que les performances des LM pour les médias sociaux peuvent néanmoins être améliorées en incorporant des vecteurs de mots statiques qui ont été spécifiquement formés sur les réseaux sociaux. Nous montrons qu'une méthode simple pour intégrer de tels vecteurs de mots est effectivement efficace dans plusieurs tests de référence en arabe et en anglais. Curieusement, cependant, nous constatons également que des améliorations similaires sont possibles avec des vecteurs de mots qui ont été formés sur des sources de texte traditionnelles (par exemple Wikipédia).", 'zh': '先训神经语(LM)取深自然语言于众自然语言,越言语。 令人讶之,至于社交媒体,虽社交媒体常与LM培训之间所见言语有异也。 特引人注目者,AraBERT也;AraBERT者,阿拉伯语之LM也;成者,以阿拉伯语方言之类社交媒体帖也,虽受阿拉伯语之培训。 设之于本文,合之于社交媒体,经之于静词向量,犹可以崇LM于社交媒体也。 吾明整合此词向量之数,于数阿拉伯语英语之中,信有成功。 然怪而见之,于旧文本源(如维基百科)训练之词向量,类可改也。', 'hi': 'पूर्व-प्रशिक्षित तंत्रिका भाषा मॉडल (एलएम) ने विभिन्न भाषाओं में विभिन्न प्राकृतिक भाषा प्रसंस्करण कार्यों में प्रभावशाली परिणाम प्राप्त किए हैं। हैरानी की बात है, यह सोशल मीडिया शैली तक फैला हुआ है, इस तथ्य के बावजूद कि सोशल मीडिया में अक्सर उस भाषा से बहुत अलग विशेषताएं होती हैं जो एलएम ने प्रशिक्षण के दौरान देखी हैं। एक विशेष रूप से हड़ताली उदाहरण अरबी भाषा के लिए एक एलएम, अराबर्ट का प्रदर्शन है, जो केवल आधुनिक मानक अरबी पर प्रशिक्षित होने के बावजूद अरबी बोलियों में सोशल मीडिया पोस्ट को वर्गीकृत करने में सफल है। इस पेपर में हमारी परिकल्पना यह है कि सोशल मीडिया के लिए एलएम के प्रदर्शन को स्थिर शब्द वैक्टर को शामिल करके सुधारा जा सकता है जिन्हें विशेष रूप से सोशल मीडिया पर प्रशिक्षित किया गया है। हम दिखाते हैं कि इस तरह के शब्द वैक्टर को शामिल करने के लिए एक सरल विधि वास्तव में कई अरबी और अंग्रेजी बेंचमार्क में सफल है। दिलचस्प बात यह है कि, हालांकि, हम यह भी पाते हैं कि शब्द वैक्टर के साथ इसी तरह के सुधार संभव हैं जिन्हें पारंपरिक पाठ स्रोतों (जैसे विकिपीडिया) पर प्रशिक्षित किया गया है।', 'ru': 'Предварительно обученные нейронные языковые модели (LMS) достигли впечатляющих результатов в различных задачах обработки естественного языка для разных языков. Удивительно, но это распространяется на жанр социальных сетей, несмотря на то, что социальные сети часто имеют очень отличные характеристики от языка, который LM видели во время обучения. Особенно ярким примером является работа AraBERT, LM для арабского языка, который успешно классифицирует посты в социальных сетях на арабском диалекте, несмотря на то, что он был обучен только современному стандартному арабскому языку. Наша гипотеза в этой статье заключается в том, что производительность LMS для социальных сетей, тем не менее, может быть улучшена путем включения статических векторов слов, которые были специально обучены в социальных сетях. Мы показываем, что простой метод включения таких слов-векторов действительно успешен в нескольких арабских и английских контрольных точках. Любопытно, однако, что мы также обнаружили, что подобные улучшения возможны с векторами слов, которые были обучены на традиционных текстовых источниках (например, Википедии).', 'ga': 'Tá torthaí suntasacha bainte amach ag samhlacha néartheanga réamhoilte (LManna) i dtascanna próiseála teanga nádúrtha éagsúla, thar theangacha éagsúla. Is ionadh é, leathnaíonn sé seo go dtí seánra na meáin shóisialta, in ainneoin go mbíonn tréithe an-difriúla ag na meáin shóisialta go minic ón teanga a chonaic LManna le linn oiliúna. Sampla thar a bheith buailte is ea feidhmíocht AraBERT, LM don Araibis, a n-éiríonn leis postanna meán sóisialta a chatagóiriú i gcanúintí Araibise, ainneoin nach bhfuil oiliúint faighte aige ach ar an Nua-Araibis Chaighdeánach. Is é an hipitéis atá againn sa pháipéar seo ná gur féidir feabhas a chur ar fheidhmíocht LManna do na meáin shóisialta mar sin féin trí veicteoirí focal statacha a bhfuil oiliúint shainiúil acu ar na meáin shóisialta a ionchorprú. Léirímid go n-éiríonn go deimhin le modh simplí chun veicteoirí focal den sórt sin a ionchorprú i roinnt tagarmharcanna Araibis agus Béarla. Is aisteach an rud é, áfach, go bhfeicimid freisin gur féidir feabhsuithe comhchosúla a dhéanamh le veicteoirí focal atá oilte ar fhoinsí traidisiúnta téacs (m.sh. Vicipéid).', 'ka': 'პირველ განსწავლებული ნეიროლური ენის მოდელები (LMs) მიიღეთ განსხვავებული ენის პროცესი დამუშავებაში, განსხვავებული ენების განსხვავებაში. სოციალურად, ეს სოციალური მედია ჯენერზე გაფარდება, თუმცა სოციალური მედიაში ზოგიერთად მსგავსი განსხვავებულები იყო ენერგიდან, რომელიც LMs ხედავთ სტრუქციის განმავლ განსაკუთრებით სხვადასხვა მაგალითი იყო აპაბერტის გამოსახულება, რომელიც აპაბური ენის LM-ის გამოსახულება, რომელიც სოციალური მედიალეკტებში კატეგორიზაციას წარმოდგენა, მაგრამ მხო ჩვენი ჰიპოტეზეზა ამ დომენტში არის რომ სოციალური მედიათების მუშაობა შეიძლება უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო აღმოქ ჩვენ ჩვენ გამოჩვენებთ, რომ ასეთი სიტყვის ვიქტორების შეყვარება მართლაც წარმატებულია რამდენიმე აპაბური და ანგლისური ბენქმარკში. მაგრამ განსაკუთრებულია, ჩვენ კიდევ ვფიქრობთ, რომ სხვადასხვა უფლება შესაძლებელია სიტყვების გვექტორებით, რომლებიც ტრადიციონალური ტექსტის გამოსახულებში განაც', 'el': 'Τα προ-εκπαιδευμένα μοντέλα νευρωνικής γλώσσας (LM) έχουν επιτύχει εντυπωσιακά αποτελέσματα σε διάφορες εργασίες επεξεργασίας φυσικής γλώσσας, σε διαφορετικές γλώσσες. Παραδόξως, αυτό επεκτείνεται στο είδος των μέσων κοινωνικής δικτύωσης, παρά το γεγονός ότι τα μέσα κοινωνικής δικτύωσης συχνά έχουν πολύ διαφορετικά χαρακτηριστικά από τη γλώσσα που έχουν δει κατά τη διάρκεια της εκπαίδευσης. Ένα ιδιαίτερα εντυπωσιακό παράδειγμα είναι η απόδοση του AraBERT, ενός LM για την αραβική γλώσσα, το οποίο είναι επιτυχές στην κατηγοριοποίηση δημοσιεύσεων στα μέσα κοινωνικής δικτύωσης σε αραβικές διαλέκτους, παρά το γεγονός ότι έχει εκπαιδευτεί μόνο στα σύγχρονα τυποποιημένα αραβικά. Η υπόθεσή μας σε αυτή την εργασία είναι ότι η απόδοση των ΜΜ για τα μέσα κοινωνικής δικτύωσης μπορεί ωστόσο να βελτιωθεί με την ενσωμάτωση στατικών διανυσμάτων λέξεων που έχουν εκπαιδευτεί ειδικά στα μέσα κοινωνικής δικτύωσης. Αποδεικνύουμε ότι μια απλή μέθοδος ενσωμάτωσης τέτοιων διανυσμάτων λέξεων είναι πράγματι επιτυχής σε αρκετά αραβικά και αγγλικά κριτήρια αναφοράς. Περιέργως, ωστόσο, διαπιστώνουμε επίσης ότι παρόμοιες βελτιώσεις είναι δυνατές με διανύσματα λέξεων που έχουν εκπαιδευτεί σε παραδοσιακές πηγές κειμένου (π.χ. Βικιπαίδεια).', 'hu': 'Az előre képzett neurális nyelvi modellek (LM) lenyűgöző eredményeket értek el különböző természetes nyelvfeldolgozási feladatokban, különböző nyelveken. Meglepő módon ez kiterjed a közösségi média műfajára, annak ellenére, hogy a közösségi média gyakran nagyon különböző tulajdonságokkal rendelkezik, mint az LM-ek a képzés során. Különösen feltűnő példa az arab nyelvű AraBERT előadása, amely sikeresen kategorizálja a közösségi média bejegyzéseket arab nyelvjárásokban, annak ellenére, hogy csak a modern standard arab nyelven tanult. Ebben a tanulmányban az a hipotézisünk, hogy az LM teljesítménye a közösségi médiában azonban javítható a statikus szóvektorok beépítésével, amelyeket speciálisan a közösségi médiában képzettek. Megmutatjuk, hogy az ilyen szóvektorok beépítésének egyszerű módszere valóban sikeres számos arab és angol referenciaértékben. Furcsa módon azonban azt is találjuk, hogy hasonló fejlesztések lehetségesek a hagyományos szövegforrásokon (pl. Wikipedia) képzett szóvektorokkal.', 'it': "Modelli di linguaggio neurale pre-addestrati (LM) hanno ottenuto risultati impressionanti in varie attività di elaborazione del linguaggio naturale, in diverse lingue. Sorprendentemente, questo si estende al genere dei social media, nonostante il fatto che i social media spesso hanno caratteristiche molto diverse dal linguaggio che gli LM hanno visto durante la formazione. Un esempio particolarmente eclatante è la performance di AraBERT, un LM per la lingua araba, che riesce a categorizzare i post sui social media in dialetti arabi, pur essendo stato addestrato solo sull'arabo standard moderno. La nostra ipotesi in questo articolo è che le prestazioni degli LM per i social media possano comunque essere migliorate incorporando vettori statici di parole che sono stati specificamente formati sui social media. Dimostriamo che un metodo semplice per incorporare tali vettori di parole ha effettivamente successo in diversi benchmark arabi e inglesi. Curiosamente, tuttavia, troviamo anche che miglioramenti simili sono possibili con i vettori di parole che sono stati addestrati su fonti di testo tradizionali (ad esempio Wikipedia).", 'kk': 'Алдыңғы оқылған невралдық тіл үлгілері (LMs) әртүрлі тілдерді өңдеу тапсырмаларында әртүрлі нәтижелер жеткізді. Бұл социалдық медиа жанрына келтірілген, әлі социалдық медиа жанрының көбінде LMs-лер оқыту кезінде көрген тілден өте түрлі қасиеттері бар. Араб тілі үшін әлемді жақсы мысал: Араб тілінің жұмыс істеу, әрі Араб диалектерінде социалдық медиақтар жұмысын санаттау сәтті болады. Бұл тек Қазіргі стандартты араб тілінде оқылған Бұл қағаздың гипотезиясы: социалдық медиақтар үшін ЛМ әрекеттерін жақсартуға болады, бірақ социалдық медиақтарда өзгертілген статикалық сөздер векторларын қосып, жақсартуға болады. Біз бұл сөзді векторларды ендіру үшін қарапайым әдіс бірнеше араб және ағылшын банктарында сәтті болады деп көрсетедік. Бірақ біз сондай-ақ әдетті мәтін көзінде оқылған векторлармен ұқсас жақсартулары мүмкін деп ойлаймыз (мысалы, Википедия).', 'ms': 'Model bahasa saraf (LMs) dilatih dahulu telah mencapai keputusan yang mengesankan dalam berbagai tugas pemprosesan bahasa alam, melalui bahasa yang berbeza. Surprisingly, this extends to the social media genre, despite the fact that social media often has very different characteristics from the language that LMs have seen during training.  A particularly striking example is the performance of AraBERT, an LM for the Arabic language, which is successful in categorizing social media posts in Arabic dialects, despite only having been trained on Modern Standard Arabic.  Hipotesis kami dalam kertas ini adalah bahawa prestasi LMs untuk media sosial masih boleh diperbaiki dengan memasukkan vektor perkataan statik yang telah dilatih secara khusus di media sosial. Kami menunjukkan bahawa kaedah sederhana untuk memasukkan vektor perkataan seperti itu benar-benar berjaya dalam beberapa tanda referensi Arab dan Inggeris. Bagaimanapun, kami juga mendapati peningkatan yang sama mungkin dengan vektor perkataan yang telah dilatih pada sumber teks tradisional (contohnya Wikipedia).', 'lt': 'Iš anksto parengti nervinių kalbų modeliai sukėlė įspūdingų rezultatų įvairiose skirtingose kalbose atliekant gamtinių kalbų apdorojimo užduotis. Įspūdinga, kad tai apima socialinės žiniasklaidos rūšį, nepaisant to, kad socialinės žiniasklaidos ypatybės dažnai labai skiriasi nuo kalbos, kurią mokymo metu matė LM. Ypač įspūdingas pavyzdys yra AraBERT, LM arabų kalbai, kuris sėkmingai klasifikuoja socialinių žiniasklaidos postus arabų dialektuose, nors jis buvo mokytas tik šiuolaikiniu standartiniu arabų kalba. Our hypothesis in this paper is that the performance of LMs for social media can nonetheless be improved by incorporating static word vectors that have been specifically trained on social media.  We show that a simple method for incorporating such word vectors is indeed successful in several Arabic and English benchmarks.  Tačiau įdomu, kad taip pat galima patobulinti žodžių vektorius, kurie buvo apmokyti tradiciniais teksto šaltiniais (pvz., Wikipedia).', 'mk': 'Преобучените модели на нервен јазик (LMs) постигнаа импресивни резултати во различни природни задачи за обработување јазик, преку различни јазици. Изненадувачки, ова се шири до генерот на социјалните медиуми, и покрај фактот дека социјалните медиуми честопати имаат многу различни карактеристики од јазикот што го видоа ЛМ за време на обуката. A particularly striking example is the performance of AraBERT, an LM for the Arabic language, which is successful in categorizing social media posts in Arabic dialects, despite only having been trained on Modern Standard Arabic.  Нашата хипотеза во овој весник е дека изведбата на ЛМ за социјалните медиуми сепак може да се подобри со вклучување на статички вектори за зборови кои се специфично обучени во социјалните медиуми. Ние покажуваме дека едноставниот метод за вклучување на вакви зборови вектори е навистина успешен во неколку арапски и англиски референтни значки. Но, интересно е, исто така, дека слични подобрувања се можни со векторите на зборовите кои се обучени на традиционалните извори на текст (на пример Википедија).', 'mt': 'Mudelli tal-lingwi newrali mħarrġa minn qabel (LMs) kisbu riżultati impressjonanti f’diversi kompiti ta’ pproċessar tal-lingwi naturali, f’lingwi differenti. Bħala sorpriża, dan jestendi għall-ġeneru tal-midja soċjali, minkejja l-fatt li l-midja soċjali spiss għandha karatteristiċi differenti ħafna mil-lingwa li l-LMs raw matul it-taħriġ. Eżempju partikolarment impressjonanti huwa l-prestazzjoni ta’ AraBERT, LM għall-lingwa Għarbija, li rnexxielha tikkategorizza l-postijiet tal-midja soċjali fid-dijaletti Għarab, minkejja li ġiet imħarrġa biss fuq l-Għarbi Standard Modern. L-ipoteżi tagħna f’dan id-dokument hija li l-prestazzjoni tal-LMs għall-midja soċjali xorta waħda tista’ titjieb billi jiġu inkorporati vetturi statiċi tal-kliem li ġew imħarrġa speċifikament fil-midja soċjali. Aħna nuru li metodu sempliċi għall-inkorporazzjoni ta’ dawn il-vetturi tal-kliem huwa tabilħaqq ta’ suċċess f’diversi punti ta’ riferiment Għarab u Ingliż. Madankollu, b’mod Curiosu, isibu wkoll li titjib simili huwa possibbli b’vetturi tal-kliem li ġew imħarrġa fuq sorsi tradizzjonali tat-test (pereżempju l-Wikipedia).', 'ml': 'Pre-trained neural language models (LMs) have achieved impressive results in various natural language processing tasks, across different languages.  അത്ഭുതപ്പെടുന്നു, ഇത് സാമൂഹിക മാധ്യമങ്ങളുടെ ജന്തുക്കളിലേക്ക് വര്\u200dദ്ധിപ്പിക്കുന്നു. സാമൂഹ്യ മാധ്യമങ്ങള്\u200d പലപ്പോഴും  പ്രത്യേകിച്ചൊരു ഉദാഹരണമാണ് അരാബെര്\u200dട്ടിന്\u200dറെ പ്രദര്\u200dശനം, അറബിഭാഷയ്ക്കുള്ള ഒരു എംഎം. അറബിഭാഷയുടെ പ്രദര്\u200dശനം, അത് അറബിഭാഷയിലെ സാമൂഹ്യ മീഡിയ പോ ഈ പത്രത്തിലെ നമ്മുടെ ഹൈപ്പിറ്റസിസി എന്താണെന്നാലും സാമൂഹിക മീഡിയയുടെ പ്രകടനത്തിന്റെ പ്രകൃതിയെല്ലാം മെച്ചപ്പെടുത്താന്\u200d കഴിയും, സ ഇതുപോലുള്ള വാക്ക് വെക്റ്റര്\u200d ചേര്\u200dക്കാനുള്ള ഒരു എളുപ്പമായ രീതിയാണ് ഞങ്ങള്\u200d കാണിക്കുന്നത്. പല അറബിക്കും ഇ എന്നാലും പാരമ്പര്യമായ ടെക്സ്റ്റ് സ്രോതസ്സുകളില്\u200d പഠിപ്പിക്കപ്പെട്ട വാക്ക് വെക്റ്റര്\u200dമാര്\u200dക്ക് ഇതുപോലുള്ള മെച്ചപ്പ', 'no': 'Førehandsvis neuralspråk- modeller (LMs) har oppnådd uttrykkelige resultat i ulike naturspråk- handlingar, på ulike språk. Dette utvidar overfor sosiale media-genre, selv om sosiale media ofte har svært forskjellige karakteristikk frå språket som LMs har sett under opplæring. Eit spesielt streking eksempel er utviklinga av AraBERT, ein LM for den arabiske språket, som er suksessfull i å kategorisera sosiale mediepost i arabiske dialektar, selv om berre har blitt trent på moderne standard arabiske. Dette er hypotesiet vårt i denne papiret at utviklinga av LMs for sosiale media kan likevel forbetrast ved å inkludere statiske ordvektorar som er spesielt trent på sosiale media. Vi viser at ein enkel metode for å inkludere slike ordvektorar er vellykket i fleire arabiske og engelske benchmarker. I løpet må vi også finne at liknande forbedringar er mulig med ordvektorar som er trengte på tradisjonelle tekstkilder (f.eks. Wikipedia).', 'pl': 'Wstępnie przeszkolone modele języka neuronowego (LM) osiągnęły imponujące rezultaty w różnych zadaniach przetwarzania języka naturalnego w różnych językach. Co zaskakujące, rozciąga się to na gatunek mediów społecznościowych, mimo że media społecznościowe często mają bardzo różne cechy od języka, który widzieli LM podczas szkolenia. Szczególnie uderzającym przykładem jest wykonanie AraBERT, LM dla języka arabskiego, który z powodzeniem jest w kategoryzowaniu postów w mediach społecznościowych w dialektach arabskich, pomimo że został przeszkolony tylko na współczesnym standardowym arabskim. Nasza hipoteza w niniejszym artykule jest taka, że wydajność LM dla mediów społecznościowych może być jednak poprawiona poprzez włączenie statycznych wektorów słów, które zostały specjalnie przeszkolone w mediach społecznościowych. Pokazujemy, że prosta metoda włączania takich wektorów słowa jest rzeczywiście udana w kilku arabskich i angielskich wskaźnikach referencyjnych. Co ciekawe, zauważamy również, że podobne ulepszenia są możliwe w przypadku wektorów słowa, które zostały przeszkolone na tradycyjnych źródłach tekstu (np. Wikipedii).', 'sr': 'Pre-obučeni modeli neuralnog jezika (LMs) postigli su impresivni rezultati različitih zadataka prirodnog obrade jezika, na različitim jezicima. Iznenađujuće, to se širi na društveni medijski genr, uprkos činjenici da društveni mediji često imaju veoma različite karakteristike od jezika koje su LMs videle tokom treninga. Posebno napadajući primjer je izvođenje AraBERT-a, LM-a za arapski jezik, koji je uspješan u kategoriji postova društvenih medija na arapskim dijalektima, uprkos treniranju samo na modernom standardnom arapskom jeziku. Naša hipoteza u ovom papiru je da se uspješnost LMs-a za društvene medije ipak može poboljšati uključujući statične rečne vektore koje su posebno obučene na društvenim medijima. Pokazujemo da je jednostavan metod za uključenje takvih vektora riječi zaista uspješan na nekoliko arapskih i engleskih kriterija. Međutim, znatiželjno, takođe smatramo da su slične poboljšanje moguće sa vektorima riječi koje su obučene na tradicionalnim tekstskim izvorima (npr. Wikipedia).', 'mn': 'Өмнөх сургалтын мэдрэлийн хэл загварууд (LMs) нь олон төрлийн байгалийн хэл үйлдвэрлэх үйл ажиллагаанд гайхалтай үр дүнг гаргасан. Гайхалтай нь энэ нь нийгмийн мэдээллийн хэрэглэгчийн хувьд нийгмийн мэдээллийн хэрэглэгчийн сургалтын үед харсан хэлээс ихэвчлэн өөр өөр харьцаа байдаг. Ялангуяа үнэхээр гайхалтай жишээ нь Араберт, Араб хэлний LM-ын үйл ажиллагаа юм. Энэ нь ерөнхий стандарт Араб хэлний сургалтын тухай харин нийгмийн мэдээллийн захирамжуудыг Араб диалект хэлний хувьд Энэ цаасан дээр бидний төсөөлөл бол нийгмийн мэдээллийн ЛМ-ын үйл ажиллагааг сайжруулж чадна. Гэхдээ нийгмийн мэдээллийн мэдээллийн хувьд тодорхой боловсруулагдсан static үг векторуудыг нэгтгэхэд сайж Бид ийм үг векторуудыг нэгтгэх энгийн арга нь олон Араб болон Англи хэл дээр амжилттай гэдгийг харуулж байна. Гэхдээ бид мөн адилхан сайжруулалт нь уламжлалтын текст эх үүсвэрээр сургалтын векторуудын хувьд боломжтой боломжтой гэдгийг ойлгосон.', 'ro': 'Modelele de limbaj neural pre-instruite (LM) au obținut rezultate impresionante în diferite sarcini de procesare a limbajului natural, în diferite limbi. În mod surprinzător, acest lucru se extinde la genul social media, în ciuda faptului că social media are adesea caracteristici foarte diferite de limba pe care LM l-au văzut în timpul antrenamentului. Un exemplu deosebit de izbitor este performanța AraBERT, un LM pentru limba arabă, care are succes în clasificarea postărilor social media în dialecte arabe, în ciuda faptului că a fost instruit doar pe limba arabă standard modernă. Ipoteza noastră din această lucrare este că performanța LM-urilor pentru social media poate fi îmbunătățită prin încorporarea vectorilor statici de cuvinte care au fost instruiți în mod specific pe social media. Noi arătăm că o metodă simplă de încorporare a unor astfel de vectori de cuvânt este într-adevăr de succes în mai multe criterii de referință arabă și engleză. Curios, totuși, constatăm, de asemenea, că îmbunătățiri similare sunt posibile cu vectorii de cuvinte care au fost instruiți pe surse de text tradiționale (de exemplu Wikipedia).', 'sv': 'Förtränade neurala språkmodeller (LM) har uppnått imponerande resultat i olika naturliga språkbehandlingsuppgifter, över olika språk. Överraskande nog sträcker detta sig till genren sociala medier, trots att sociala medier ofta har mycket olika egenskaper än det språk som LM har sett under träning. Ett särskilt slående exempel är framförandet av AraBERT, en LM för det arabiska språket, som lyckas kategorisera sociala medier inlägg på arabiska dialekter, trots att de bara har utbildats i modern standard arabiska. Vår hypotes i denna uppsats är att prestandan av LM för sociala medier ändå kan förbättras genom att införliva statiska ordvektorer som har utbildats specifikt på sociala medier. Vi visar att en enkel metod för att införliva sådana ordvektorer verkligen är framgångsrik i flera arabiska och engelska riktmärken. Men märkligt nog finner vi också att liknande förbättringar är möjliga med ordvektorer som tränats på traditionella textkällor (t.ex. Wikipedia).', 'ta': 'முன்பயிற்சிக்கப்பட்ட புதிய மொழி மாதிரி மாதிரிகள் (LMs) வெவ்வேறு மொழி செயல்பாடுகளில், பல்வேறு இயல்பான மொழி செயல்ப ஆச்சரியமாக, இது சமூக ஊடகங்களின் மரபணிக்கு விரிவாகும், ஆனாலும் சமூக ஊடகங்கள் பெரும்பாலும் பயிற்சியில் பார்த்த மொழியில் ம ஒரு குறிப்பாக வெறும் எடுத்துகாட்டாகும் அராபெர்ட், அரபி மொழிக்கு ஒரு LM செயல்பாடு, இது அரபி மொழியில் சமூகத்தார மொழிமாற்றங்களை பிரித்து அரபி மொழ இந்த காகிதத்தில் எங்கள் hypothesis is that LMs for social media performance can improve by incorporating static word vectors that have been trained specifically on social media. இத்தகைய வார்த்தை நெறிகளை சேர்க்க ஒரு சுலபமான முறையைக் காண்பிக்கிறோம் என்பதை நாம் காண்பிக்கிறோம். இது பல அரப தற்பொழுது, அதே போன்ற முன்னேற்றங்கள் வார்த்தை நெறிகளுடன் பயிற்சி செய்யப்பட்டுள்ளது என்பதை நாம் கண்டுபிடிக்க முடியும் என்ற', 'si': 'ප්\u200dරධානය කරපු න්\u200dයූරාල් භාෂා මොඩේල්ස් (LMs) විවිධ භාෂාව ප්\u200dරශ්නයක් විවිධ භාෂාව ප්\u200dරශ්නයක්  සාමාජික මධ්\u200dයමාධ්\u200dයම ජේන්ටර් වලට මේක ප්\u200dරශ්නයක් වෙනවා, සාමාජික මාධ්\u200dයමාධ්\u200dයමාධ්\u200dයම වලින් බොහොම වෙනස් අ විශේෂයෙන් විශේෂයෙන් සාමාජික මාධ්\u200dයමාධ්\u200dයම පොස්ට් එක් අරාබිර්ට් වලින් ප්\u200dරශ්නයක්, LM වලින් අරාබිරි භාෂාව සඳහා ප්\u200d අපේ විශ්වාස මේ පත්තරේ තියෙන්නේ සාමාජික මිඩියාවට LMs ගැන ප්\u200dරශ්නයක් පුළුවන් නමුත් සාමාජික වචන වෙක්ටර්ස් එක්කර අපි පෙන්වන්නේ ඒ වචන වෙක්ටර් එක්ක සරල විධානයක් ඇත්තටම අරාබි සහ ඉංග්\u200dරීසි බෙන්ච්මාර්ක් වලින ඒත් විශ්වාසයි, අපිට හොයාගන්න පුළුවන් වචන වෙක්ටර් එක්ක වචන වෙක්ටර් වලින් පුළුවන් විදියට (උදාහරණයෙන් වික', 'so': 'Tusaalooyinka afka neurada ee hore lagu tababaray (LMs) waxay ku heleen wax la yaab leh oo ku saabsan shaqooyin kala duduwan oo kala duduwan oo luuqado kala duduwan. Si la yaab leh, taasi waxay u fidisaa jinsiga bulshada, inkastoo ay xaqiiqda tahay in marwalba macluumaadka bulshada ay leeyihiin takhasusyo kala duwan oo ay ku jiraan luqada ay Ms. Tusaale khaas ah oo aad u muuqanayso waa sameynta AraBERT, kaas oo ah LM oo afka Carabiga ah, kaas oo ku liibaanaya kooxa kooxaha kooxaha warqadaha bulshada ee afka Carabiga, inkastoo lagu baranayo afka Modern Standard Carabi. Fiiniyadayada warqaddan ku qoran waa in dhaqanka LMs-ka ee macluumaadka bulshada lagu sameeyo si kastaba ha ahaatee waxaa loo hormarin karaa hagaajin karo wadada hadalka statisticka ah oo si gaar ah loo baray shabakadda bulshada. We show that a simple method for incorporating such word vectors is indeed successful in several Arabic and English benchmarks.  Si kastaba ha ahaatee, waxaynu ognahay in horumarinta la mid ah ay suurtogal u noqon karaan vector hadal ah oo lagu tababariyey noocyada saqafka ah (tusaale ahaan Wikipedia).', 'ur': 'مختلف طبیعی زبان پردازی کے کاموں میں، مختلف زبانوں میں، پیش آموزش کی نیورال زبان کی مدل (LMs) کو اثر دینے والی نتیجے پہنچ چکے ہیں. سوسیل میڈیا جینر کی طرف متفاوت ہوتی ہے، اگرچہ سوسیل میڈیا اکثر اس زبان سے بہت مختلف خصوصے رکھتے ہیں جسے LMs نے تمرین میں دیکھا ہے. ایک مخصوص مثال عربی زبان کے لئے عربی زبان کے لئے آرابٹ کی عملکرد ہے، جو عربی دیالکتوں میں سوسیل میڈیا پوسٹ کا تقسیم کرنے کے لئے موفق ہے، اگرچہ صرف مدرنی استاندارد عربی زبان پر تعلیم کی جاتی ہے۔ اس کاغذ میں ہماری فرضی یہ ہے کہ سوسیل میڈیاں کے لکھنے کے لئے LMs کی پرورش اچھی طرح اچھی طرح ہوسکتی ہے کہ ایسی لکھی ویکتروں کو جمع کرنا ہے جو سوسیل میڈیاں پر خاص تعلیم کی گئی ہیں۔ ہم دکھاتے ہیں کہ ایسے کلمات ویکتروں کو جمع کرنے کے لئے ایک ساده طریقہ بہت سی عربی اور انگلیسی بانچمٹروں میں کامیاب ہے ہمیں بھی معلوم ہے کہ ویکیپیڈیا کے ساتھ ویکتوروں کے ساتھ ویکتوروں کے ساتھ ایسی سیدھی تحصیل کی گئی ہے۔', 'uz': "Oldingi taʼminlovchi neyron tili modellari (LMs) har xil tilni boshqarish vazifalarini boshqa tillar bilan boshqa tillar bilan boshqarish natijasi vazifalarini bajardi. Surprisingly, this extends to the social media genre, despite the fact that social media often has very different characteristics from the language that LMs have seen during training.  Ko'rinadigan misol Arab tilning araBERT (LM) bajarishi, balki faqat Modern Standard arabda o'rganishga muvaffaqiyatli o'rganishga muvaffaqiyatsiz tugadi. Bu qogʻozdagi hypothesis esa, jamiyat media uchun LMs (LMs) bajarishi imkoniyatini o'zgartirish mumkin. Ammo, bulshada media ta'lim soʻzlarida o'rganilgan statistik so'zlar vektorini o'rganish uchun o'zgartirish mumkin. Biz shu so'zlar vektorlarini birlashtirish uchun oddiy usuli ko'pchilik arab va ingliz parametrlarida muvaffaqiyatli bo'ladi. Hozirda, biz shunday o'xshash o'zgarishlarni o'rganishga o'xshash o'zgarishlarni o'rganish mumkin.", 'vi': 'Những mẫu ngôn ngữ thần kinh được đào tạo trước đã đạt kết quả ấn tượng trong các công việc xử lý ngôn ngữ tự nhiên, qua nhiều ngôn ngữ khác nhau. Thật ngạc nhiên, điều này cũng có liên quan đến giới truyền thông xã hội, mặc dù truyền thông xã hội thường có những đặc điểm rất khác biệt so với ngôn ngữ mà LMs đã thấy khi tập luyện. Một ví dụ đặc biệt nổi bật là vở diễn của AraBERT, một LM của ngôn ngữ Ả Rập, thành công trong việc phân loại các bài viết truyền thông xã hội bằng tiếng Ả Rập, mặc dù chỉ được đào tạo trên Tiếng Ả Rập Hiện Đại. Theo giả thuyết của chúng tôi trong tờ giấy này thì hiệu quả của LM for social media (LM) vẫn có thể được cải thiện bằng cách lắp đặt các cỗ máy từ tĩnh được đào tạo đặc biệt trên các phương tiện xã hội. Chúng tôi cho thấy một phương pháp đơn giản để áp dụng những từ này thật sự thành công trong nhiều tiêu chuẩn tiếng Anh và tiếng Ả Rập. Lạ thay, chúng tôi cũng thấy có khả năng cải tiến tương tự với các luồng từ đã được huấn luyện về các nguồn văn bản truyền thống (v. d. Wikipedia).', 'nl': "Vooropgeleide neurale taalmodellen (LM's) hebben indrukwekkende resultaten behaald in verschillende natuurlijke taalverwerkingstaken, in verschillende talen. Verrassend genoeg strekt dit zich uit tot het social media genre, ondanks het feit dat sociale media vaak heel andere kenmerken hebben dan de taal die LMs hebben gezien tijdens de training. Een bijzonder opvallend voorbeeld is de performance van AraBERT, een LM voor de Arabische taal, die succesvol is in het categoriseren van social media posts in Arabische dialecten, hoewel ze alleen zijn opgeleid op Modern Standaard Arabisch. Onze hypothese in dit artikel is dat de prestaties van LMs voor sociale media desondanks verbeterd kunnen worden door statische woordvectoren op te nemen die specifiek zijn getraind op sociale media. We laten zien dat een eenvoudige methode voor het opnemen van dergelijke woordvectoren inderdaad succesvol is in verschillende Arabische en Engelse benchmarks. Vreemd genoeg vinden we echter ook dat vergelijkbare verbeteringen mogelijk zijn met woordvectoren die zijn getraind op traditionele tekstbronnen (bijvoorbeeld Wikipedia).", 'da': "Forududdannede neurale sprogmodeller (LM'er) har opnået imponerende resultater i forskellige naturlige sprogbehandlingsopgaver på tværs af forskellige sprog. Overraskende nok strækker dette sig til genren på sociale medier, på trods af at sociale medier ofte har meget forskellige karakteristika fra det sprog, som LM'er har set under træning. Et særligt slående eksempel er AraBERT, en LM for det arabiske sprog, som har succes med at kategorisere sociale medier indlæg på arabiske dialekter, selv om kun er blevet uddannet i moderne standard arabisk. Vores hypotese i denne artikel er, at ydeevnen af LM'er til sociale medier alligevel kan forbedres ved at indarbejde statiske ordvektorer, der er specielt uddannet på sociale medier. Vi viser, at en enkel metode til at indarbejde sådanne ordvektorer virkelig er vellykket i flere arabiske og engelske benchmarks. Mærkeligt nok finder vi dog også, at lignende forbedringer er mulige med ordvektorer, der er blevet trænet på traditionelle tekstkilder (f.eks. Wikipedia).", 'id': 'Model bahasa saraf yang dilatih sebelumnya telah mencapai hasil yang mengesankan dalam berbagai tugas proses bahasa alam, melalui bahasa yang berbeda. Mengejutkan, hal ini berlanjut ke genre media sosial, meskipun fakta bahwa media sosial sering memiliki karakteristik yang sangat berbeda dari bahasa yang LMs telah melihat selama latihan. Contoh yang sangat menakjubkan adalah pertunjukan AraBERT, LM untuk bahasa Arab, yang sukses dalam kategorisasi pos media sosial dalam dialekt Arab, meskipun hanya dilatih dalam bahasa Arab Standard Modern. Hipotesis kami dalam kertas ini adalah bahwa prestasi LMs untuk media sosial namun dapat diperbaiki dengan memasukkan vektor kata statis yang telah secara khusus dilatih di media sosial. We show that a simple method for incorporating such word vectors is indeed successful in several Arabic and English benchmarks.  Bagaimanapun, kami juga menemukan bahwa perbaikan yang sama mungkin dengan vektor kata yang telah dilatih pada sumber teks tradisional (contohnya Wikipedia).', 'bg': 'Предварително обучените невронни езикови модели (ЛМ) са постигнали впечатляващи резултати в различни задачи по обработка на естествения език на различни езици. Изненадващо, това се простира и до жанра на социалните медии, въпреки факта, че социалните медии често имат много различни характеристики от езика, който ЛМ са виждали по време на обучението. Особено впечатляващ пример е представянето на Араберт, ЛМ за арабския език, който успешно категоризира публикациите в социалните медии на арабски диалекти, въпреки че е обучен само на съвременен стандартен арабски език. Нашата хипотеза в тази статия е, че ефективността на ЛМ за социалните медии все пак може да бъде подобрена чрез включване на статични вектори на думи, които са специално обучени в социалните медии. Показваме, че един прост метод за включване на такива вектори на думи наистина е успешен в няколко арабски и английски референтни показатели. Любопитно е обаче, че подобни подобрения са възможни и с вектори на думи, които са обучени по традиционни текстови източници (например Уикипедия).', 'de': 'Vortrainierte neuronale Sprachmodelle (LMs) haben beeindruckende Ergebnisse bei verschiedenen Aufgaben der Verarbeitung natürlicher Sprache in verschiedenen Sprachen erzielt. Überraschenderweise erstreckt sich dies auch auf das Social Media Genre, obwohl soziale Medien oft sehr andere Eigenschaften haben als die Sprache, die LMs während des Trainings gesehen haben. Ein besonders markantes Beispiel ist die Performance von AraBERT, einem LM für die arabische Sprache, das es gelingt, Social Media Posts in arabischen Dialekten zu kategorisieren, obwohl es nur auf Modern Standard Arabic trainiert wurde. Unsere Hypothese in diesem Beitrag ist, dass die Leistung von LMs für soziale Medien dennoch verbessert werden kann, indem statische Wortvektoren integriert werden, die speziell auf Social Media trainiert wurden. Wir zeigen, dass eine einfache Methode zur Einbindung solcher Wortvektoren in mehreren arabischen und englischen Benchmarks tatsächlich erfolgreich ist. Seltsamerweise stellen wir aber auch fest, dass ähnliche Verbesserungen mit Wortvektoren möglich sind, die auf traditionellen Textquellen (z.B. Wikipedia) trainiert wurden.', 'hr': 'Preobučeni modeli neuralnog jezika (LMs) postigli su impresivni rezultati različitih zadataka obrade prirodnog jezika na različitim jezicima. Iznenađujuće, to se širi na društveni medijski genr, uprkos činjenici da društveni mediji često imaju vrlo različite karakteristike od jezika koje su LMs vidjele tijekom obuke. Posebno opasan primjer je učinkovitost AraBERT-a, LM-a za arapski jezik, koji je uspješan u kategoriziranju postova društvenih medija na arapskim dijalektima, uprkos što je treniran samo na modernom standardnom arapskom jeziku. Naša hipoteza u ovom papiru je da se učinkovitost LMs-a za društvene medije ipak može poboljšati uključujući statične riječi vektore koji su posebno obučeni na društvenim medijima. Pokazujemo da je jednostavan metod uključenja takvih vektori riječi zaista uspješan na nekoliko arapskih i engleskih kriterija. Međutim, znatiželjno, također smatramo da su slične poboljšanje moguće s riječnim vektorima koji su obučeni na tradicionalnim tekstskim izvorima (npr. Wikipedia).', 'fa': 'مدل\u200cهای زبان عصبی پیش آموزش داده شده\u200cاند (LMs) نتیجه\u200cهای تاثیر\u200cپذیر در کار\u200cهای پردازش زبان طبیعی مختلف، در زبان\u200cهای مختلف رسیده\u200cاند. تعجب کننده است که این به نوع رسانه\u200cهای اجتماعی تغییر می\u200cدهد، با وجود اینکه رسانه\u200cهای اجتماعی اغلب ویژگی\u200cهای بسیار متفاوتی از زبانی که LMs در زمان آموزش دیده\u200cاند. یک مثال خصوصی سخت\u200cکننده\u200cای است که عملکرد آرابرت، یک LM برای زبان عربی است که موفق است در تنظیم رسانه\u200cهای اجتماعی در دیالکت عربی باشد، با وجود اینکه تنها در عربی استاندارد مدرن آموزش داده شده است. فرضیه ما در این کاغذ این است که عملکرد LMs برای رسانه های اجتماعی با وجود توسط شامل ویکتورهای واژه\u200cهای استادی که به طور خاص در رسانه\u200cهای اجتماعی آموزش داده شده\u200cاند، بهتر می\u200cشود. ما نشان می دهیم که یک روش ساده برای شامل این کلمه ویکتورها واقعاً در چندین نقشه\u200cهای عربی و انگلیسی موفق است. ولی عجیب است که ما همچنین پیدا می\u200cکنیم که پیشرفت\u200cهای مشابه با ویکتورهای کلمه\u200cای که در منبع متن سنتی آموزش داده شده\u200cاند، ممکن است.', 'sw': 'Pre-trained neural language models (LMs) have achieved impressive results in various natural language processing tasks, across different languages.  Inashangaza, jambo hili linaongezeka kwa jinsia za mitandao ya kijamii, pamoja na ukweli kwamba mitandao ya kijamii mara nyingi huwa na sifa tofauti tofauti kutoka lugha ambayo LMs. wameona wakati wa mafunzo. Mfano wa kushangaza hasa ni utendaji wa AraBERT, MLM kwa lugha ya Kiarabu, ambao umefanikiwa katika kugawanya makala za mitandao ya kijamii katika lugha za Kiarabu, pamoja na kuwa imefundishwa tu katika lugha ya Kiarabu ya Modern Standard. Hata hivyo, nadhani yetu katika gazeti hili ni kwamba utendaji wa chama cha LMs kwa mitandao ya kijamii unaweza kuboreshwa kwa kuingiza vector za maneno ya stadi ambazo zimefundishwa hasa kwenye mitandao ya kijamii. Tunaonyesha kuwa njia rahisi ya kuunganisha vectors wa maneno haya kwa hakika imefanikiwa katika misingi mbalimbali ya Kiarabu na Kiingereza. Hata hivyo, kwa sasa, tunagundua kuwa maendeleo yanayofanana yanawezekana na vectori za maneno ambayo imefundishwa kwenye vyanzo vya kitamaduni (kwa mfano Wikipedia).', 'ko': '사전 훈련을 거친 신경언어모델(LMs)은 서로 다른 언어의 다양한 자연 언어 처리 임무에서 인상적인 결과를 얻었다.놀랍게도 이는 소셜미디어 유형으로 확대됐다. 소셜미디어는 일반적으로 LMs가 교육 기간에 본 언어와 매우 다른 특징을 가지고 있지만.특히 눈길을 끄는 예는 아랍트(AraBERT)의 공연이다. 아랍트는 아랍어의 LM으로 현대 표준 아랍어만 교육받았지만 아랍어로 소셜미디어 게시물을 분류하는 데 성공했다.그럼에도 불구하고 소셜미디어에서 전문적으로 훈련된 정적 단어 벡터를 추가하면 LMs의 소셜미디어에서의 성능이 여전히 개선될 수 있다고 본고에서 가정했다.우리는 이런 단어의 양을 결합시키는 것이 확실히 성공한 몇 개의 아랍어와 영어의 기준이라는 간단한 방법을 보여 준다.그러나 이상하게도 전통적인 텍스트 원본(예를 들어 위키백과)에서 훈련된 단어의 양도 비슷한 개선이 있을 수 있다는 것을 발견했다.', 'af': "Vorige opgelei neurale taal modele (LMs) het inpresieële resultate in verskillende natuurlike taal verwerking opdragte bereik, oor verskillende tale. Oorwurk, dit verleng tot die sosiale media genre, selfs die feit dat sosiale media dikwels baie verskillende karakteristieke het van die taal wat LMs gesien het tydens onderwerp. 'n Spesiaal streng voorbeeld is die uitvoering van AraBERT, 'n LM vir die Arabiese taal, wat suksesvol is in die kategoriseer van sosiale medieposte in Arabiese dialekte, alhoewel slegs op Moderne Standaard Arabiese onderrig is. Ons hipotesis in hierdie papier is dat die effektuur van LMs vir sosiale media kan tog verbeter word deur die inkorporeer van statiese woord vektores wat spesifieke onderwerp is op sosiale media. Ons wys dat 'n eenvoudige metode vir die inkorporeer van sodanige woord vektore sekerlik suksesvol is in verskeie Arabiese en Engels benchmarke. Ons vind ook nuuskierig dat soortgelyke verbeteringe moontlik is met woord vektore wat op tradisionele teksbronne opgelei is (bv. Wikipedia).", 'am': 'የቀድሞው የነዌብ ቋንቋ ሞዴላዎች (LMs) በተለየ ቋንቋዎች ልዩ ልዩ ቋንቋዎች የሥርዓት ሥርዓቶችን ለማድረግ የተመሳሳይ ፍሬ አግኝተዋል፡፡ በተደነቀቀ ነገር ግን ይህ ማኅበራዊ ሚዲያ የዘላለም ማኅበራዊ አውታር በብዛት የተለየ ብሔራዊ አካባቢዎች በሚያስተማሩበት ቋንቋ ላይ የተለየ ነው፡፡ በተለየ ምሳሌ አረብቢርት፣ አርቢ ቋንቋ የተደረገው የአርቢ ቋንቋ (LM) የሚደረገው የአርብኛ ቋንቋ ነው፡፡ በዚህ ገጾች ውስጥ የኢሜሲ የማኅበራዊ ሚዲያ አካባቢነት ግን በተለየ ማኅበራዊ አውታር የተጠቃሚውን የstatic ቃላት vectors በመጠቀም ይሻላል፡፡ እንደነዚህ ቃላት vectors ማሳየት ቀላል ልማድ በዐረብኛ እና በንግልዝኛ ደብዳቤዎች ውስጥ ፍላጎት እንደሆነ እናሳየዋለን፡፡ በተቀናቀው ነገር ግን፣ እንደዚህ የሚመስሉ አካባቢዎች የጽሑፍ ምንጮች (ለምሳሌ Wikipedia) የተማሩ የቃላት vector መሆኑን እናገኛለን፡፡', 'tr': "Öňki bilinmeli näyral dil nusgalary (LMs) tebigy diller işleýän täsirlerde täsirli netijesi başarmady. Gurhal bolýar, bu sosyal medýdanlaryň jeneralyna golaýlaýar, soňkuly medýdanlaryň(sosyal medýdanlaryň) okuw wagtynda gören dillerden köplenç üýtgeşikleri bar. AraBERT, Arabça dilinde bir LM taýýarlandyrylygynyň ýagdaýynda soýumsal mediýalyň poýatlaryny arabça dialektlerde kategoriýarlandyrmak üçin başarnykly. Bu gazetedeki hökmümiz sosyal medyeleri için LMs'lerin yapılandığı düşünceleri sosyal medyelerinde özellikle eğitilen statik kelime vektörleri oluşturarak geliştirilebilir. Biz beýleki söz vektörlerini ýeterleştirmek üçin basit bir yöntem görkeýäris. Bu ýöne birnäçe arabça we iňlisçe salgymlarda üstünlik gazanýar. Iň gowy g örýän bolsa, biz hem daşary metin çe şmelerinde okuw edilen söz vektörleri bilen meňzeş gelişmeler mümkin bolup bileris.", 'sq': 'Modelet e paratrajnuara të gjuhës nervore (LMs) kanë arritur rezultate mbresëlënëse në detyra të ndryshme natyrore të përpunimit të gjuhës, nëpër gjuhë të ndryshme. E çuditshme, kjo shtrihet në xhenerin e medias sociale, pavarësisht nga fakti se mediat sociale shpesh kanë karakteristika shumë të ndryshme nga gjuha që LMs kanë parë gjatë trainimit. Një shembull veçan ërisht goditës është shfaqja e AraBERT, një LM për gjuhën arabe, e cila është e suksesshme në kategorizimin e postimeve të medias sociale në dialektet arabe, pavarësisht se është trajnuar vetëm në gjuhën arabe moderne standard. Hipoteza jonë në këtë letër është se performanca e LMs për mediat shoqërore megjithatë mund të përmirësohet duke përfshirë vektorë statikë fjalësh që janë trajnuar specifikisht në mediat shoqërore. Ne tregojmë se një metodë e thjeshtë për përfshirjen e vektorëve të tillë të fjalëve është me të vërtetë e suksesshme në disa referenca arabe dhe angleze. Megjithatë, çuditshëm, gjejmë gjithashtu se përmirësime të ngjashme janë të mundshme me vektorët e fjalëve që janë trajnuar në burimet tradicionale të tekstit (për shembull Wikipedia).', 'hy': 'Նախապատրաստված նյարդային լեզվի մոդելները զարմանահրաշ արդյունքներ են ստացել տարբեր բնական լեզվի վերամշակման խնդիրներում, տարբեր լեզուներում: Զարմանալի է, որ սա ընդլայնվում է սոցիալական լրատվամիջոցների գենդերով, չնայած այն փաստին, որ սոցիալական լրատվամիջոցները հաճախ շատ տարբեր հատկություններ ունեն այն լեզվից, որ ԼՄ-ները տեսել են ուսուցման ըն Հատկապես զարմանահրաշ օրինակ է Արաբերթի արտադրությունը, արաբական լեզվի ԼՄ-ը, որը հաջողված է դասակարգել սոցիալական լրատվամիջոցների դիալեկտները արաբական դիալեկտներում, չնայած միայն ժամանակակից ստանդարտ արաբական դասակարգերին: Այս թղթի մեջ մեր հիպոթեզն այն է, որ սոցիալական լրատվամիջոցների լավագույնը, այնուամենայնիվ, կարող է բարելավվել, ներառելով հասարակական լրատվամիջոցներում մասնավորապես պատրաստված բառերի վիկտորներ: We show that a simple method for incorporating such word vectors is indeed successful in several Arabic and English benchmarks.  Հետաքրքիրն այն է, որ մենք նաև հայտնաբերում ենք, որ նման բարելավումներ հնարավոր են բառերի վեկտորների հետ, որոնք սովորեցրել են ավանդական տեքստի աղբյուրներից (օրինակ Վիքիփեդիայից):', 'bs': 'Preobučeni modeli neuralnog jezika (LMs) postigli su impresivni rezultati različitih zadataka prirodnog obradivanja jezika na različitim jezicima. Iznenađujuće, to se širi na društveni medijski genr, uprkos činjenici da društveni mediji često imaju veoma različite karakteristike od jezika koje su LMs vidjele tokom treninga. Posebno opasan primjer je izvođenje AraBERT-a, LM-a za arapski jezik, koji je uspješan u kategoriji postova društvenih medija na arapskim dijalektima, uprkos treniranju samo na modernom standardnom arapskom jeziku. Naša hipoteza u ovom papiru je da se uspješnost LMs-a za društvene medije, ipak, može poboljšati uključujući statične rečne vektore koje su posebno obučene na društvenim medijima. Pokazujemo da je jednostavan metod za uključenje takvih vektora riječi zaista uspješan na nekoliko arapskih i engleskih kriterija. Međutim, znatiželjno, također smatramo da su slične poboljšanje moguće sa vektorima riječi koje su obučene na tradicionalnim tekstskim izvorima (npr. Wikipedia).', 'az': 'Əvvəlcə təhsil edilmiş nöral dil modelləri (LMs) müxtəlif dillərdə təhsil edilən təhsil işləri ilə müxtəlif dillərdə başa düşdü. Bu çox təəccüblənirsə də, sosyal mediyaların çox fərqli məlumatlarını LMs dillərinin təhsil sırasında gördüyü dildən istifadə edir. Özellikle sıxıntılı bir məsəl ərəb dilində olan AraBERT təhsil edilmişdir. Bu, sadəcə Modern Standardlı ərəb dilində təhsil edilmişdir. Bizim bu kağızdakı hipotezimiz sosyal mediyaların LMs-lərin performansı, amma sosyal mediyalarında təhsil edilmiş statik söz vektörlərini birləşdirən təhsil edilən statik söz vektörlərindən daha yaxşılaşdırılabilir. Biz bu söz vektörlərini birləşdirmək üçün basit bir yolu göstəririk ki, bir çox ərəbcə və İngilizə benchmarklarında başarılı olar. Bütün təəccüblü olaraq, biz də belə düşünürük ki, bənzər düzəltmələr məlumat mənbələrində təhsil edilmiş söz vektörləri ilə mümkün ola bilər (məsələn, Wikipedia).', 'bn': 'প্রাক্তন প্রশিক্ষিত নিউরেল ভাষার মডেল (এলএমএস) বিভিন্ন ভাষার প্রক্রিয়ার কাজের বিভিন্ন ভাষার প্রক্রিয়ার ফলাফলের বিস্ময়কর, এটা সামাজিক প্রচার মাধ্যমের জিনিসের প্রতি বিস্ময়কর, যদিও সামাজিক প্রচার মাধ্যম প্রায়শই সামাজিক মিডিয়া প্রশিক বিশেষ করে দৃষ্টান্ত উদাহরণ হচ্ছে আরবী ভাষার জন্য আরাবেরেটের প্রদর্শন, যা আরবী ভাষায় সামাজিক মিডিয়া পোস্টগুলো বিভাগে সফল হয়েছে, যদিও শুধুমাত্র আধুনি এই কাগজটিতে আমাদের হিপিসেস হচ্ছে যে সামাজিক প্রচার মাধ্যমের এলএমএসের কার্যক্রম উন্নতি করা যায়, তবুও স্টেটিক শব্দ ভেক্টরের মধ্যে যাদের ব আমরা দেখাচ্ছি যে এই ধরনের শব্দ ভেক্টর যোগাযোগ করার একটি সহজ পদ্ধতি সত্যিই বেশ কয়েকটি আরবী ও ইংরেজি বেনমেন্কে সফল। বর্তমানে আমরা আবিষ্কার করি যে শব্দ ভেক্টরের সাথে একই ধরনের উন্নতি সম্ভব, যারা ঐতিহ্যবাহী টেক্সট উৎসে প্রশিক্ষণ প্রদান করা হয়েছে (যেমন', 'fi': 'Esikoulutetut neurokielimallit (LM) ovat saavuttaneet vaikuttavia tuloksia erilaisissa luonnollisen kielen käsittelytehtävissä eri kielillä. Yllättävää kyllä tämä ulottuu myös sosiaalisen median genreen, vaikka sosiaalisella medialla on usein hyvin erilaiset ominaisuudet kuin kielillä, jonka LM on nähnyt koulutuksen aikana. Erityisen silmiinpistävä esimerkki on arabian kielen LM AraBERT, joka on onnistunut luokittelemaan sosiaalisen median viestit arabianmurteella, vaikka se on koulutettu vain modernin standardin arabiaksi. Hypoteesimme tässä artikkelissa on, että LM:ien suorituskykyä sosiaalisessa mediassa voidaan kuitenkin parantaa lisäämällä staattisia sanavektoreita, jotka on erityisesti koulutettu sosiaalisessa mediassa. Osoitamme, että yksinkertainen menetelmä tällaisten sanavektorien sisällyttämiseksi on todella onnistunut useissa arabian ja englannin vertailuarvoissa. Mielenkiintoista on kuitenkin, että samankaltaiset parannukset ovat mahdollisia myös sanavektoreilla, jotka on koulutettu perinteisistä tekstilähteistä (esim. Wikipediasta).', 'ca': "Pre-trained neural language models (LMs) have achieved impressive results in various natural language processing tasks, across different languages.  Sorprenentment, això s'estendrà al gènere dels mitjans socials, malgrat que els mitjans socials sovint tenen característiques molt diferents de la llengua que les LMs han vist durant l'entrenament. A particularly striking example is the performance of AraBERT, an LM for the Arabic language, which is successful in categorizing social media posts in Arabic dialects, despite only having been trained on Modern Standard Arabic.  La nostra hipòtesi en aquest article és que el rendiment de les MG per als mitjans socials pot millorar inclouent vectors estàtics de paraules que han estat especialment entrenats en els mitjans socials. Mostrem que un mètode simple per incorporar aquests vectors de paraules té èxit en molts punts de referència àrab i anglès. Curiosament, no obstant això, també trobem que es poden millorar les paraules amb vectors que han estat entrenats en fonts tradicionals de text (per exemple Wikipedia).", 'cs': 'Předškolené neuronové jazykové modely (LM) dosáhly působivých výsledků v různých úkolech zpracování přirozeného jazyka napříč různými jazyky. Překvapivě se to týká žánru sociálních médií, navzdory skutečnosti, že sociální média mají často velmi odlišné charakteristiky od jazyka, který LM viděli během tréninku. Obzvláště výrazným příkladem je výkon AraBERT, LM pro arabský jazyk, který je úspěšný v kategorizaci příspěvků na sociálních sítích v arabských dialektech, i když byl trénován pouze v moderní standardní arabštině. Naše hypotéza v tomto článku je, že výkon LM pro sociální média lze nicméně zlepšit začleněním statických slovních vektorů, které byly speciálně trénovány na sociálních médiích. Ukazujeme, že jednoduchá metoda pro začlenění takových slovních vektorů je skutečně úspěšná v několika arabských a anglických referenčních hodnotách. Zajímavé je však, že podobná zlepšení je možná i u slovních vektorů, které byly trénovány na tradičních textových zdrojích (např. Wikipedii).', 'et': 'Eelkoolitud närvikeele mudelid on saavutanud muljetavaldavaid tulemusi erinevates looduskeele töötlemise ülesannetes erinevates keeltes. Üllataval kombel laieneb see sotsiaalmeedia žanrile, vaatamata asjaolule, et sotsiaalmeedia omadused on sageli väga erinevad keelest, mida LM on treeningu ajal näinud. Eriti silmatorkav näide on araabia keele LM AraBERT etendus, mis on edukas sotsiaalmeedia postituste kategoriseerimisel araabia murretes, vaatamata sellele, et ta on saanud ainult kaasaegse standardse araabia keele koolituse. Meie hüpotees käesolevas artiklis on, et LMide jõudlust sotsiaalmeedias saab siiski parandada staatiliste sõnavaktorite kasutamisega, mis on spetsiaalselt sotsiaalmeedias koolitatud. Me näitame, et lihtne meetod selliste sõnavaktorite kaasamiseks on tõepoolest edukas mitmes araabia ja inglise võrdlusaluses. Uudishimulikul kombel leiame siiski, et sarnased parandused on võimalikud sõnavaktorite puhul, mida on koolitatud traditsiooniliste tekstiallikatega (nt Wikipedia).', 'sk': 'Vnaprej usposobljeni modeli nevronskega jezika (LM) so dosegli impresivne rezultate pri različnih nalogah obdelave naravnega jezika v različnih jezikih. Presenetljivo je, da se to razširi tudi na žanr družbenih medijev, kljub dejstvu, da imajo družbeni mediji pogosto zelo drugačne značilnosti od jezika, ki so ga LM videli med usposabljanjem. Posebej osupljiv primer je nastop AraBERT, LM za arabski jezik, ki je uspešen pri kategorizaciji objav v družbenih omrežjih v arabskih narečjih, čeprav je bil usposobljen le za sodobno standardno arabsko. Naša hipoteza v tem prispevku je, da je mogoče učinkovitost LM za družbena omrežja kljub temu izboljšati z vključitvijo statičnih besednih vektorjev, ki so bili posebej usposobljeni na družbenih omrežjih. Pokazali smo, da je preprosta metoda vključevanja takih besednih vektorjev resnično uspešna v več arabskih in angleških referenčnih vrednostih. Zanimivo pa je, da so podobne izboljšave možne tudi pri besednih vektorjih, ki so bili usposobljeni za tradicionalne vire besedila (npr. Wikipedija).', 'ha': "@ info: status Ina mãmãki, wannan yana ƙara zuwa genre ga mitandai da jamii, kuma ingawa da gaskiya, mitandai da jamii ko da yawa yana da wasu sifati masu yawa daga harshen nan da LM ya gan shi a lokacin da ya yi mafaka. Wata misali mai girma yana da jarrabon AraBERT, an LM wa harshen Larabci, wanda yake mai cin nasara a categoring littafan mitanda na jami da harshen Larabci, kuma ingawa an sanar da shi kawai a kan littafan Na'ura. Kayyakanmu cikin wannan takarda ni'ani ne cewa aikin LM wa mitandai sosiaci ko da haka, za'a iya ƙara shi da kuma a shigar da shiryoyi na static words waɗanda aka sanar da su ƙayyadadde a kan mitandata jamii. Tuna nũna cewa shirin sauri na haɗi da shiryoyi na wannan magana, yana da cin nasara a cikin wasu littafan arabu da Ingiriya. A yanzu, ko da haka, munã gane cewa masu kyautatawa kamar wannan, za'a iya iya amfani da shiryoyi na magana waɗanda aka sanar da su a kan sourcen matsayin na zamani (misali Wikimedia).", 'jv': 'Sampeyan Jaringan Mungkin (LMV) kang dipunduh sistem sing sampeyan ngono nggawe perusahaan langkung sampeyan. Awak dhéwé, iki luwih nêmên ngerasakno ning acara media sotiki, sanes ngono kuwi media sotiki dadi kalah-kalah luwih apik dhèwèké karo alé sing ngerasakno luwih apik sing luwih apik dhèwèké. Mbak kesalahan kanggo langkung araBERT, LM kanggo langkung arap, sing luwih nggawe media soti kanggo diolah dialecto arap, sanes kudu dhéwé wis dipoleh kaya basa sing di arap sing is in é. Kita senhadlok nggunakake kuwi nggawe barang kelas luwih nggawe dolanan populer, digowo nggawe barang langkung populer sing bisa basa gambarang kelas populer vectors lahi, dadi, kita mulai ngono cah-cah dumadhi iki dianggap banjur karo pergambar vector sing ditambah bantuan teks', 'he': 'דוגמני שפת עצבית מאומנים מראש (LMs) השיגו תוצאות מרשים במשימות מעבד שפת טבעיות שונות, דרך שפות שונות. באופן מפתיע, זה מתרחש לגנרס התקשורת החברתית, למרות העובדה שלתקשורת החברתית יש לעתים קרובות תכונות שונות מאוד מהשפה שראו LMs במהלך האימונים. דוגמא מדהימה במיוחד היא ההופעה של ארברט, LM לשפה הערבית, שמצליחה לקטגוריזת עמדות התקשורת החברתית בדיאלקטים הערביים, למרות שהתאמנו רק בשפה הערבית הסטנדרטית המודרנית. ההיפתוזה שלנו בעיתון הזה היא שהביצועים של LMs למדיה חברתית עדיין יכולים להשתפר על ידי הכילוי ווקטורים מילים סטטיים שהיו מאומנים במיוחד במדיה חברתית. אנו מראים ששיטה פשוטה להכניס ווקטורים מילים כאלה באמת מצליחה בכמה נקודות רמז ערביות ואנגליות. Curiously, however, we also find that similar improvements are possible with word vectors that have been trained on traditional text sources (e.g. Wikipedia).', 'bo': 'སྔོན་གྲངས་བསླབས་པའི་སྒེར་གྱི་དཔེ་དབྱིབས་ཀྱི་རྣམ་པ(LMs)དེ་ནི་natural སྐད་ཡིག་ལས་སྦྱོར་བྱ་འགུལ་དང་སྐད་ཡིག་མི་འདྲ་བར་ནང མཐའ་འཁོར་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ལ་ཡར་རྒྱས་འགྲོ་བཞིན་པ་ཡིན་ནའང་། སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ཚོའི་ནང་གི་སྐད་རིགས་ལ་རང་ A particularly striking example is the performance of AraBERT, an LM for the Arabic language, which is successful in categorizing social media posts in Arabic dialects, though only has been trained on Modern Standard Arabic. ང་ཚོའི་ཤོག་བྱང་འདིའི་གྲངས་སུ་བཏོན་ཡོད་པའི་LMs འི་ལས་འགན་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་གྲངས་ཀ་ལ་ཡར་རྒྱས་གཏོང་བ་རྒྱུ་དང་། འུ་ཅག་གིས་འདི་ལྟ་བུའི་ནང་དུ་འཇུག་སྣོད་ཀྱི་ཐབས་ལམ་སྟབས་བདེ་བོ་ཞིག་ཡིན་པས་རྩོམ་འབྱུང་བ་ཨིན་རིའི་དང་ཨིན འོན་ཀྱང་། མ་ཟད། འོན་ཀྱང་། ང་ཚོར་རྒྱུན་ལྡན་ཡིག་གི་ཁྲོད་ཚོའི་མཐོ་རིམ་པ་དེ་ཚོར་སྐྱེས་ཚིག་དང་མཐོང'}
{'en': 'PHINC : A Parallel Hinglish Social Media Code-Mixed Corpus for  Machine Translation PHINC : A Parallel  H inglish Social Media Code-Mixed Corpus for Machine Translation', 'es': 'PHINC: Un corpus paralelo de código mixto de medios sociales para la traducción automática', 'pt': 'PHINC: um corpus misto de código de mídia social paralelo Hinglish para tradução automática', 'ar': 'PHINC: مجموعة نصوص مختلطة لرمز وسائط التواصل الاجتماعي للهنجليزية متوازية للترجمة الآلية', 'fr': 'PHINC\xa0: un corpus mixte de codes de médias sociaux en hinglish parallèle pour la traduction automatique', 'zh': 'PHINC:机器翻译并Hinglish社交媒体代码合语料库', 'ja': 'PHINC: A Parallel Hinglish Social Media Code - Mixed Corpus for Machine Translation', 'hi': 'PHINC: मशीन अनुवाद के लिए एक समानांतर हिंग्लिश सोशल मीडिया कोड-मिश्रित कॉर्पस', 'ru': 'PHINC: Параллельный код социальных сетей Hinglish - смешанный корпус для машинного перевода', 'ga': 'PHINC: Corpas Measctha Cód Meán Sóisialta Hinglish le haghaidh Aistriúcháin Meaisín', 'ka': 'Comment', 'hu': 'PHINC: Párhuzamos hinglish közösségi média kód-vegyes korpusz a gépi fordításhoz', 'el': 'Ένα Παράλληλο Ενδεικτικό Κώδικα Κοινωνικών Μέσων για τη Μηχανική Μετάφραση', 'it': 'PHINC: Un corpus misto di codice sui social media hinglish parallelo per la traduzione automatica', 'kk': 'PHINC: Машин аудару үшін параллелі Hinglish социалдық медиа кодын араластырған корпус', 'lt': 'PHINC: Parallel Hinglish Social Media Code-Mixed Corpus for Machine Translation', 'mk': 'Паралелно Хинглиски социјални медиуми за преведување', 'ms': 'PHINC: A Paralel Hinglish Social Media Code-Mixed Corpus for Machine Translation', 'ml': 'പിഹിന്\u200dസി: മെഷീന്\u200d പരാജയപ്പെടുത്തുന്നതിനുള്ള ഒരു പാരാള്\u200dലിഷ് ഹിങ്ങ്ലിഷ് സോഷ്യല്\u200d മീഡിയ കോഡ്- മിക്സിഡ്', 'mn': 'PHINC: Машин хөрөнгө оруулахын тулд нийгмийн мэдээллийн код холбогдсон биеэ', 'mt': 'PHINC: Korp Imħallat bil-Kodiċi tal-Midja Soċjali Paralela Hinglish għat-Traduzzjoni tal-Magni', 'pl': 'PHINC: Równoległy Hinglish Social Media Code-Mixed Corpus dla tłumaczenia maszynowego', 'ro': 'PHINC: Un corpus mixt de coduri pentru rețelele sociale hinglish paralel pentru traducerea automată', 'sr': 'ПИНК: Параллелна корпус за превод машини', 'no': 'PHINC: Eit parallell Hinglish Social Media-Code-Mixed Corpus for Machine Translation', 'si': 'Comment', 'so': 'PHINC: A Parallel Hinglish Shirkad-Mixed Corpus for Machine Translation', 'sv': 'PHINC: En parallell hinglisk kodblandad korpus för sociala medier för maskinöversättning', 'ta': 'பிசின்: இயந்திரம் மொழிபெயர்ப்புக்கான ஒரு இணைப்பு ஹிங்கிலிஷ் சமூக ஊடக குறியீடு- கலக்கப்பட்ட கார்புஸ்', 'ur': 'PHINC: ماشین ترجمہ کے لئے ایک پارالی ہینگلیس سوسیل میڈیا کیڈ-میکس کورپوس', 'uz': 'Name', 'vi': 'PHINC: A Parallel Hinglish Social Media Code-mixed Corpus for Machine Translation', 'bg': 'Паралелен хинглийски кодов смесен корпус за машинен превод в социалните медии', 'hr': 'PHINC: Parallel Hinglish Social Media Code-Mixed Corpus for Machine Translation', 'nl': 'PHINC: Een Parallel Hinglish Social Media Code Mixed Corpus voor Machine Translation', 'da': 'PHINC: En parallel hinglisk kode-blandet korpus til maskinoversættelse', 'de': 'PHINC: Ein paralleles Hinglish Social Media Code-Mixed Corpus für maschinelle Übersetzung', 'ko': 'PHINC: 기계 번역을 위한 평행 Hinglish 소셜 미디어 코드 혼합 자료 라이브러리', 'id': 'A Parallel Hinglish Social Media Code Mixed Corpus for Machine Translation', 'fa': 'PHINC: یک کورپ پیچیده\u200cشده\u200cی مدارک اجتماعی پاراللی برای ترجمه ماشین', 'sw': 'PHINC: Kikosi cha Mitandao ya Kijamii kinachotengwa na Umoja wa Mitandao ya Kijamii kwa ajili ya Tafsiri ya Mashine', 'tr': 'PHINC: Makine tercüme için Parallel Hinglish Sosyal Medya Kodu Karışık Korpusu', 'af': 'Comment', 'sq': 'Një korpus paralel i përzier me kodet e medias sociale për përkthimin e makinave', 'am': 'ፓርላሌ Hinglish ማኅበራዊ ሚዲያ Code-Mixed Corpus for Machine ትርጓሜ', 'hy': 'Հանգլիշ սոցիալական լրատվամիջոցների կոդի խառնված կորպուսը մեքենայի թարգմանման համար', 'az': 'PHINC: Makinat Çevirməsi üçün Parallel Hinglish Sosyal Media Kodu Karışmış Corpus', 'bn': 'পিএইএনসি: মেশিন অনুবাদের জন্য একটি প্যারালেল হিঙ্গ্লিশ সোশ্যাল মিডিয়া কোড-মিশ্রিত কর্পুস', 'ca': 'PHINC: Un corpo mixt de codis de mitjans socials parallels per traducció màquina', 'bs': 'PHINC: Parallel Hinglish Social Media Code-Mixed Corpus for Machine Translation', 'et': 'PHINC: Paralleelne hinglish sotsiaalmeedia koodsega segatud korpus masintõlke jaoks', 'cs': 'PHINC: Parallel Hinglish Social Media Code-Mixed Corpus pro strojový překlad', 'fi': 'PHINC: Parallel Hinglish Social Media Code Mixed Corpus konekääntämiseen', 'he': 'קורפוס מעורבב עם קוד מדיה חברתית הינגלית לתרגום מכונות', 'ha': 'KCharselect unicode block name', 'jv': 'FINC: Ngucap Paralelel Ngucap Universi Media Nombol Jagad Kerpus kanggo Majin Terjamahan', 'sk': 'PHINC: Vzporedni hingliški korpus mešanih kod socialnih medijev za strojno prevajanje', 'bo': 'PHINC: ལག་འཁྱེར་གྱི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དང་མཉམ་སྒྲིག་འཛུགས་ཀྱི་རྩིས་འཁོར།'}
{'en': 'Code-mixing is the phenomenon of using more than one language in a sentence. In the  multilingual communities ,  it  is a very frequently observed pattern of communication on  social media platforms . Flexibility to use multiple languages in one text message might help to communicate efficiently with the target audience. But, the noisy user-generated code-mixed text adds to the challenge of processing and understanding  natural language  to a much larger extent. Machine translation from monolingual source to the target language is a well-studied research problem. Here, we demonstrate that widely popular and sophisticated translation systems such as  Google Translate  fail at times to translate code-mixed text effectively. To address this challenge, we present a  parallel corpus  of the 13,738 code-mixed Hindi-English sentences and their corresponding human translation in  English . In addition, we also propose a translation pipeline build on top of  Google Translate . The evaluation of the proposed  pipeline  on PHINC demonstrates an increase in the performance of the underlying  system . With minimal effort, we can extend the  dataset  and the proposed approach to other code-mixing language pairs. PHINC  demonstrates an increase in the performance of the underlying system. With minimal effort, we can extend the dataset and the proposed approach to other code-mixing language pairs.', 'ar': 'خلط الشفرات هو ظاهرة استخدام أكثر من لغة في الجملة. في المجتمعات متعددة اللغات ، يُلاحَظ كثيرًا جدًا من أنماط التواصل على منصات التواصل الاجتماعي. قد تساعد المرونة في استخدام لغات متعددة في رسالة نصية واحدة على التواصل بكفاءة مع الجمهور المستهدف. ولكن ، النص المزجج الذي تم إنشاؤه بواسطة المستخدم يضيف إلى التحدي المتمثل في معالجة اللغة الطبيعية وفهمها إلى حد أكبر بكثير. تعتبر الترجمة الآلية من مصدر أحادي اللغة إلى اللغة المستهدفة مشكلة بحث مدروسة جيدًا. هنا ، نوضح أن أنظمة الترجمة الأكثر شيوعًا والمعقدة مثل الترجمة من Google تفشل أحيانًا في ترجمة النص المختلط بالشفرات بشكل فعال. لمواجهة هذا التحدي ، نقدم مجموعة موازية من 13.738 جمل هندية-إنجليزية مختلطة الأكواد والترجمة البشرية المقابلة لها باللغة الإنجليزية. بالإضافة إلى ذلك ، نقترح أيضًا مسار ترجمة يتم إنشاؤه فوق الترجمة من Google. يوضح تقييم خط الأنابيب المقترح على PHINC زيادة في أداء النظام الأساسي. بأقل جهد ممكن ، يمكننا توسيع مجموعة البيانات والنهج المقترح لأزواج لغوية لخلط الكود.', 'pt': 'A mistura de códigos é o fenômeno de usar mais de um idioma em uma frase. Nas comunidades multilíngues, é um padrão de comunicação muito observado nas plataformas de mídia social. A flexibilidade de usar vários idiomas em uma mensagem de texto pode ajudar a se comunicar de forma eficiente com o público-alvo. Mas, o texto misto de código gerado pelo usuário barulhento aumenta o desafio de processar e entender a linguagem natural em uma extensão muito maior. A tradução automática da fonte monolíngue para o idioma de destino é um problema de pesquisa bem estudado. Aqui, demonstramos que sistemas de tradução amplamente populares e sofisticados, como o Google Tradutor, às vezes falham na tradução de texto misto de código de maneira eficaz. Para enfrentar esse desafio, apresentamos um corpus paralelo das 13.738 frases hindi-inglesas de código misto e sua tradução humana correspondente em inglês. Além disso, também propomos um pipeline de tradução baseado no Google Translate. A avaliação do pipeline proposto no PHINC demonstra um aumento no desempenho do sistema subjacente. Com esforço mínimo, podemos estender o conjunto de dados e a abordagem proposta para outros pares de linguagens de mixagem de código.', 'es': 'La mezcla de códigos es el fenómeno de usar más de un idioma en una oración. En las comunidades multilingües, es un patrón de comunicación que se observa con mucha frecuencia en las plataformas de redes sociales. La flexibilidad para usar varios idiomas en un mensaje de texto puede ayudar a comunicarse eficazmente con el público objetivo. Sin embargo, el ruidoso texto de código mezclado generado por el usuario se suma al desafío de procesar y comprender el lenguaje natural en una medida mucho mayor. La traducción automática del idioma de origen monolingüe al idioma de destino es un problema de investigación bien estudiado. Aquí, demostramos que los sistemas de traducción muy populares y sofisticados, como el Traductor de Google, a veces no traducen eficazmente el texto con código mezclado. Para hacer frente a este desafío, presentamos un corpus paralelo de las 13.738 oraciones en clave hindi-inglés mezcladas y su correspondiente traducción humana al inglés. Además, también proponemos una canalización de traducción basada en Google Translate. La evaluación del oleoducto propuesto en PHINC demuestra un aumento en el rendimiento del sistema subyacente. Con un esfuerzo mínimo, podemos extender el conjunto de datos y el enfoque propuesto a otros pares de lenguajes de mezcla de códigos.', 'fr': "Le mélange de codes est un phénomène qui consiste à utiliser plus d'une langue dans une phrase. Dans les communautés multilingues, c'est un modèle de communication très fréquemment observé sur les plateformes de réseaux sociaux. La flexibilité d'utiliser plusieurs langues dans un même message texte peut aider à communiquer efficacement avec le public cible. Mais le texte bruyant créé par l'utilisateur ajoute au défi de traiter et de comprendre le langage naturel dans une bien plus large mesure. La traduction automatique d'une source monolingue vers la langue cible est un problème de recherche bien étudié. Nous démontrons ici que les systèmes de traduction les plus populaires et les plus sophistiqués tels que Google Translate ne parviennent parfois pas à traduire efficacement du texte mixte de code. Pour relever ce défi, nous présentons un corpus parallèle de 13 738 phrases Hindi-Anglais mélangées par code et leur traduction humaine correspondante en anglais. En outre, nous proposons également un pipeline de traduction basé sur Google Translate. L'évaluation du gazoduc proposé sur PHINC démontre une augmentation de la performance du système sous-jacent. Avec un minimum d'effort, nous pouvons étendre le jeu de données et l'approche proposée à d'autres paires de langues de mixage de code.", 'zh': '代码合者,句之多种语言也。 多言社区中,社交媒体台上所常察沟通模式也。 一短信之用多种语言灵活性或有助于受众者也。 然嘈杂用户生代码混合文本于更大程度上,加自然语言挑战。 自单语源到至言者机器翻译穷究之也。 于此证博行杂译之统,如谷歌译,或无效译代码混合文本。 为此挑战,发一13,738一代码混印地语 - 英语句者并行语料库与其英语工译。 又议于谷歌译之基构译管道。 PHINC上拟管道之评,底系统之性有所提高。 但须至少之力,即可将数据集和所发的方法扩到他代码混合言语对。', 'hi': 'कोड-मिश्रण एक वाक्य में एक से अधिक भाषाओं का उपयोग करने की घटना है। बहुभाषी समुदायों में, यह सोशल मीडिया प्लेटफार्मों पर संचार का एक बहुत ही बार मनाया जाने वाला पैटर्न है। एक पाठ संदेश में एकाधिक भाषाओं का उपयोग करने के लिए लचीलापन लक्षित ऑडियंस के साथ कुशलतापूर्वक संवाद करने में मदद कर सकता है. लेकिन, शोर उपयोगकर्ता-जनित कोड-मिश्रित पाठ प्राकृतिक भाषा को बहुत बड़ी हद तक संसाधित करने और समझने की चुनौती को जोड़ता है। लक्ष्य भाषा के लिए मोनोलिंगुअल स्रोत से मशीन अनुवाद एक अच्छी तरह से अध्ययन की गई शोध समस्या है। यहां, हम प्रदर्शित करते हैं कि Google अनुवाद जैसे व्यापक रूप से लोकप्रिय और परिष्कृत अनुवाद सिस्टम कोड-मिश्रित पाठ को प्रभावी ढंग से अनुवाद करने के लिए कई बार विफल हो जाते हैं। इस चुनौती को संबोधित करने के लिए, हम अंग्रेजी में 13,738 कोड-मिश्रित हिंदी-अंग्रेजी वाक्यों और उनके संबंधित मानव अनुवाद का एक समानांतर कॉर्पस प्रस्तुत करते हैं। इसके अलावा, हम Google अनुवाद के शीर्ष पर एक अनुवाद पाइपलाइन निर्माण का भी प्रस्ताव करते हैं। PHINC पर प्रस्तावित पाइपलाइन का मूल्यांकन अंतर्निहित प्रणाली के प्रदर्शन में वृद्धि को दर्शाता है। न्यूनतम प्रयास के साथ, हम डेटासेट और प्रस्तावित दृष्टिकोण को अन्य कोड-मिश्रण भाषा जोड़े तक बढ़ा सकते हैं।', 'ja': 'コードミキシングは、文中で複数の言語を使用する現象です。 多言語コミュニティでは、ソーシャルメディアプラットフォーム上で非常に頻繁に観察されるコミュニケーションのパターンです。 1つのテキストメッセージで複数の言語を使用する柔軟性は、ターゲットオーディエンスと効率的にコミュニケーションするのに役立つかもしれません。 しかし、ユーザーが生成したノイズの多いコードミックステキストは、自然言語の処理と理解の課題をはるかに大きくします。 単一言語のソースからターゲット言語への機械翻訳は、よく研究された問題です。 ここでは、Google翻訳のような広く普及している高度な翻訳システムでは、コードが混在したテキストを効果的に翻訳できないことがあることを実証します。 この課題に対処するために、私たちは13,738のコードミックスされたヒンディー語と英語の文章とそれに対応する英語の人間翻訳の並列コーパスを提示します。 さらに、Google翻訳の上に翻訳パイプラインを構築することも提案しています。 PHINCで提案されたパイプラインの評価は、基礎となるシステムのパフォーマンスの向上を示しています。 最小限の労力で、データセットと提案されたアプローチを他のコード混合言語ペアに拡張できます。', 'ru': 'Смешивание кода - это феномен использования более одного языка в предложении. В многоязычных сообществах это очень часто наблюдаемая модель общения на платформах социальных сетей. Гибкость использования нескольких языков в одном текстовом сообщении может помочь эффективно общаться с целевой аудиторией. Но шумный пользовательский текст добавляет к проблеме обработки и понимания естественного языка в гораздо большей степени. Машинный перевод с одноязычного источника на целевой язык является хорошо изученной исследовательской проблемой. Здесь мы демонстрируем, что популярные и сложные системы перевода, такие как Google Translate, иногда не способны эффективно переводить смешанный текст. Для решения этой проблемы мы представляем параллельный корпус из 13 738 смешанных хинди-английских предложений и их соответствующий человеческий перевод на английский язык. Кроме того, мы также предлагаем создать конвейер переводов поверх Google Translate. Оценка предлагаемого трубопровода на PHINC демонстрирует увеличение производительности базовой системы. С минимальными усилиями мы можем расширить набор данных и предлагаемый подход к другим языковым парам, смешивающим код.', 'ga': 'Is éard is códmheascadh ann ná an feiniméan a bhaineann le níos mó ná teanga amháin a úsáid in abairt. Sna pobail ilteangacha, is patrún cumarsáide é a bhreathnaítear go minic ar ardáin na meán sóisialta. B’fhéidir go gcabhródh solúbthacht le teangacha iolracha a úsáid in aon teachtaireacht téacs amháin le cumarsáid éifeachtach a dhéanamh leis an spriocghrúpa. Ach cuireann an téacs cód-mheasctha torannach a ghintear leis an úsáideoir leis an dúshlán a bhaineann le teanga nádúrtha a phróiseáil agus a thuiscint go pointe i bhfad níos mó. Fadhb taighde a ndéantar staidéar maith uirthi is ea aistriúchán meaisín ó fhoinse aonteangach go dtí an sprioctheanga. Anseo, léirímid go dteipeann uaireanta ar chórais aistriúcháin sofaisticiúla ar nós Google Translate téacs cód-mheasctha a aistriú go héifeachtach. Chun aghaidh a thabhairt ar an dúshlán seo, cuirimid i láthair corpas comhthreomhar de na 13,738 abairt cód-mheasctha Hiondúis-Bhéarla agus a n-aistriúchán daonna comhfhreagrach i mBéarla. Ina theannta sin, molaimid freisin tógáil píblíne aistriúcháin ar bharr Google Translate. Léiríonn an mheastóireacht ar an bpíblíne atá beartaithe ar PHINC méadú ar fheidhmíocht an chórais bhunúsach. Gan mórán iarrachta, is féidir linn an tacar sonraí agus an cur chuige atá beartaithe a leathnú chuig péirí teangacha códmheasctha eile.', 'ka': 'კოდის შემთხვევაში უფრო მეტი ერთი ენაში გამოყენება. მრავალენგური საზოგადოებში, ეს საზოგადომიური მედია პლატატურების კომუნიკაციის ნაწილია. ერთი ტექსტის შეტყობინებაში მრავალ ენების გამოყენება შეიძლება ეფექტიურად კომუნიკაციას მისაწყვეტული აუდიტორებით. მაგრამ ძალიან ძალიან მომხმარებელი ტექსტი, რომელიც შეიქმნა კოდის შემთხვევაში დამატებს პროცესის და ნახვა თავისუფალური ენაზე დიდი ზომაში. მაქსინის მონოლენგური წიგნიდან მინიშვნელოვანი ენისთვის გადაწყვეტილი პრობლემაა. აქ, ჩვენ გამოჩვენებთ, რომ ძალიან პოლიპური და სოფისტიკური განსაგულების სისტემი, როგორც Google Translate, ცოტაცია შეუძლებელია, როგორც კოდის შესაგულების შესაგულები ამ გამოცდილების შესახებ, ჩვენ 13 738 კოდი-ანგლისური სიტყვების პარალელური კორპუსს და მათი შესახებ ადამიანის შესახებ ინგლისურად. დამატებით, ჩვენ ასევე დავიწყებთ Google Translate-ის დამატებით გადაწყვეტილება. PHINC-ის პროგრამის განსაზღვრება გამოიყენება გამოიყენება სისტემის გამოყენება. მინიმალური ძალადობით, ჩვენ შეგვიძლია მონაცემების კონფიგურაციას და სხვა ენის კონფიგურაციის კონფიგურაციისთვის გავამრავლოთ.', 'hu': 'A kódkeverés az a jelenség, hogy egynél több nyelvet használnak egy mondatban. A többnyelvű közösségekben ez egy nagyon gyakran megfigyelt kommunikációs minta a közösségi média platformokon. Az egyetlen szöveges üzenetben több nyelv használatának rugalmassága segíthet hatékonyan kommunikálni a célközönséggel. A zajos, felhasználók által generált kódkeverékes szöveg azonban sokkal nagyobb mértékben növeli a természetes nyelv feldolgozásának és megértésének kihívását. A gépi fordítás az egynyelvű forrásból a célnyelvre jól tanulmányozott kutatási probléma. Itt bemutatjuk, hogy a széles körben népszerű és kifinomult fordítási rendszerek, mint például a Google Translate, időnként nem tudják hatékonyan lefordítani a kódkeverékes szövegeket. Ennek a kihívásnak a megoldására bemutatjuk a 13 738 kódkeverékes hindi-angol mondat párhuzamos korpuszát, valamint azok megfelelő angol nyelvű emberi fordítását. Ezenkívül javaslatot teszünk egy fordítási csatornára is, amely a Google Translate tetején épül. A javasolt csővezeték értékelése a PHICK alapjául szolgáló rendszer teljesítményének növekedését mutatja. Minimális erőfeszítéssel kiterjeszthetjük az adatkészletet és a javasolt megközelítést más kódkeverő nyelvpárokra is.', 'el': 'Η ανάμειξη κώδικα είναι το φαινόμενο της χρήσης περισσότερων από μιας γλωσσών σε μια πρόταση. Στις πολυγλωσσικές κοινότητες, είναι ένα πολύ συχνά παρατηρούμενο πρότυπο επικοινωνίας στις πλατφόρμες κοινωνικών μέσων. Η ευελιξία χρήσης πολλαπλών γλωσσών σε ένα μήνυμα κειμένου μπορεί να βοηθήσει στην αποτελεσματική επικοινωνία με το κοινό-στόχο. Αλλά, το θορυβώδες κείμενο που δημιουργείται από τους χρήστες με μικτό κώδικα προσθέτει στην πρόκληση της επεξεργασίας και της κατανόησης της φυσικής γλώσσας σε πολύ μεγαλύτερο βαθμό. Η μηχανική μετάφραση από τη μονογλωσσική πηγή στη γλώσσα-στόχο είναι ένα καλά μελετημένο ερευνητικό πρόβλημα. Εδώ, καταδεικνύουμε ότι τα ευρέως δημοφιλή και εξελιγμένα μεταφραστικά συστήματα όπως η Μετάφραση αποτυγχάνουν κατά καιρούς να μεταφράσουν αποτελεσματικά κείμενο μικτού κώδικα. Για να αντιμετωπιστεί αυτή η πρόκληση, παρουσιάζουμε ένα παράλληλο σώμα των 13,738 κωδικοποιημένων ινδικά-αγγλικών προτάσεων και την αντίστοιχη ανθρώπινη μετάφραση τους στα αγγλικά. Επιπλέον, προτείνουμε επίσης έναν μεταφραστικό αγωγό βασισμένο στην Μετάφραση Google. Η αξιολόγηση του προτεινόμενου αγωγού για το PHINC καταδεικνύει αύξηση της απόδοσης του υποκείμενου συστήματος. Με ελάχιστη προσπάθεια, μπορούμε να επεκτείνουμε το σύνολο δεδομένων και την προτεινόμενη προσέγγιση σε άλλα ζεύγη γλωσσών ανάμειξης κώδικα.', 'kk': 'Кодты араластыру - сөйлемдегі бірнеше тілден артық қолдануға болады. Көп тілдік қоғамдарында, ол социалдық медиа платформаларындағы байланыстыру үлгісін көп қарайды. Бір мәтін хабарламасында бірнеше тілдерді қолдану мүмкіндігі мақсатты аудиториямен байланыстыруға көмектеседі. Бірақ дыбыс пайдаланушылар жасалған код араластырылған мәтін өзгерту және табиғи тілді түсініктерге көп үлкенде қосылады. Монолингі көзінен мақсатты тіліне аудару машинасы - зерттеу мәселесі. Мұнда, Google Translate секілді жалпы және жалпы аудармалар жүйелерін кейбірде код араластырылған мәтінді ақпараттау мүмкін емес деп көрсетеді. Бұл мәселеге көмектесу үшін 13 738 код-ағылшын тілдерінің параллелі корпусын және олардың адамдардың ағылшын тілінде аударуға сәйкес келеді. Сонымен қатар, Google Translate- тің үстінде аудармаларды қолданып тастаймыз. PHINC жүйесінің қолданылатын конвейер жолының оқиғасы негізгі жүйеңіздің істеуін көрсетеді. Төменгі әрекеттермен, деректер жиынын және қолданыстағы әрекетті басқа код араластыру тілдеріне кеңейтуге болады.', 'it': "Il code-mixing è il fenomeno dell'uso di più di una lingua in una frase. Nelle comunità multilingue, è un modello di comunicazione molto frequentemente osservato sulle piattaforme di social media. La flessibilità di utilizzare più lingue in un messaggio di testo potrebbe aiutare a comunicare in modo efficiente con il pubblico di destinazione. Tuttavia, il testo misto di codice generato dall'utente aumenta la sfida di elaborare e comprendere il linguaggio naturale in misura molto più ampia. La traduzione automatica dalla fonte monolingue alla lingua di destinazione è un problema di ricerca ben studiato. Qui, dimostriamo che i sistemi di traduzione ampiamente popolari e sofisticati come Google Translate a volte non riescono a tradurre in modo efficace testo misto di codice. Per affrontare questa sfida, presentiamo un corpus parallelo delle 13.738 frasi Hindi-Inglese miscelate in codice e la loro corrispondente traduzione umana in inglese. Inoltre, proponiamo anche una pipeline di traduzione costruita sulla cima di Google Translate. La valutazione della pipeline proposta su PHINC dimostra un aumento delle prestazioni del sistema sottostante. Con il minimo sforzo, possiamo estendere il set di dati e l'approccio proposto ad altre coppie di linguaggi di miscelazione del codice.", 'lt': 'Kodų derinimas reiškia, kad sakinyje vartojama daugiau kaip viena kalba. Daugiakalbėse bendruomenėse tai labai dažnai stebimas komunikacijos socialinių žiniasklaidos platformose modelis. Flexibility to use multiple languages in one text message might help to communicate efficiently with the target audience.  Tačiau triukšmingas vartotojo sukurtas kodų mišrus tekstas prisideda prie iššūkio perdirbti ir suprasti natūralią kalbą daug didesniu mastu. Mašininis vertimas iš vienkalbinio šaltinio į tikslinę kalbą yra gerai ištirta mokslinių tyrimų problem a. Čia mes rodome, kad plačiai populiarios ir sudėtingos vertimo sistemos, pvz., Google Translate, kartais neveikia veiksmingai vertti kodų mišraus teksto. Siekiant išspręsti šį iššūkį, pristatome lygiagrečių 13 738 kodų mišrių Hindi ir anglų sakinių ir jų atitinkamo žmogiškojo vertimo anglų kalba korpusą. Be to, mes taip pat siūlome vertimo vamzdyną, sukurtą virš Google Translate. Pasiūlyto PHINC vamzdyno vertinimas rodo, kad didėja pagrindinės sistemos veiksmingumas. Nedidelėmis pastangomis galime išplėsti duomenų rinkinį ir siūlomą metodą ir taikyti kitas kodų derinimo kalbų poras.', 'mk': 'Мешањето на кодовите е феномен на користење повеќе од еден јазик во реченица. Во мултијазичните заедници, тоа е многу често набљудуван шаблон на комуникација на платформите на социјалните медиуми. Флексибилноста за користење на повеќе јазици во една текстова порака може да помогне во ефикасната комуникација со публиката на целта. Но, бучниот текст генериран од корисникот со мешан код го додава предизвикот на обработување и разбирање на природниот јазик во многу поголем степен. Машински превод од монојазички извор до јазик на целта е добро проучен истражувачки проблем. Овде демонстрираме дека широко популарните и софистицираните преводни системи како што е Google Translate понекогаш не успеваат ефикасно да преводат мешан текст со код. За да го решиме овој предизвик, претставуваме паралелен корпус од 13.738 кодови мешани хинди-англиски реченици и нивниот соодветен човечки превод на англиски. Покрај тоа, ние, исто така, предложуваме производство на гасоводот за превод на врвот од Google Translate. Проценката на предложениот гасовод за ФИНЦ покажува зголемување на резултатите на основниот систем. Со минимални напори, можеме да го прошириме наборот на податоци и предложениот пристап до други парови јазици кои мешаат кодови.', 'ms': 'Code-mixing is the phenomenon of using more than one language in a sentence.  In the multilingual communities, it is a very frequently observed pattern of communication on social media platforms.  Kefleksibiliti untuk menggunakan bahasa berbilang dalam satu mesej teks mungkin membantu berkomunikasi dengan efisien dengan penonton sasaran. Tetapi, teks kod-campuran yang dihasilkan oleh pengguna berisik menambah kepada cabaran pemprosesan dan pemahaman bahasa semula jadi jauh lebih besar. Terjemahan mesin dari sumber monobahasa ke bahasa sasaran adalah masalah kajian yang dipelajari dengan baik. Di sini, kita menunjukkan bahawa sistem terjemahan yang sangat popular dan canggih seperti Google Translate kadang-kadang gagal untuk terjemahan teks campuran-kod secara efektif. Untuk mengatasi cabaran ini, kami memperkenalkan korpus selari dari 13,738 kalimat kod-campuran Hindi-Inggeris dan terjemahan manusia yang sepadan dengan mereka dalam bahasa Inggeris. Selain itu, kami juga cadangkan saluran paip terjemahan yang dibina di atas Google Translate. Pengesahan saluran paip yang diusulkan pada PHINC menunjukkan peningkatan prestasi sistem yang didasarkan. Dengan usaha minimal, kita boleh memperluas set data dan pendekatan yang direncanakan kepada pasangan bahasa pengcampuran kod lain.', 'mt': 'It-taħlit tal-kodiċi huwa l-fenomenu li tintuża aktar minn lingwa waħda f’sentenza. Fil-komunitajiet multilingwi, huwa mudell ta’ komunikazzjoni osservat ta’ spiss ħafna fuq pjattaformi tal-midja soċjali. Il-flessibbiltà li jintużaw diversi lingwi f’messaġġ wieħed tat-test tista’ tgħin biex tikkomunika b’mod effiċjenti mal-udjenza fil-mira. Iżda, it-test imħallat bil-kodiċi ġġenerat mill-utent bi storbju jżid l-isfida tal-ipproċessar u l-fehim tal-lingwa naturali sa punt ferm akbar. Machine translation from monolingual source to the target language is a well-studied research problem.  Hawnhekk, nagħmlu xhieda li sistemi ta’ traduzzjoni popolari ħafna u sofistikati bħal Google Translate xi drabi ma jirnexxilhomx jittraduċu b’mod effettiv it-test imħallat bil-kodiċi. Biex nindirizzaw din l-isfida, nippreżentaw korpus parallel tat-13,738 sentenza mħallta tal-kodiċi Indjan-Ingliż u t-traduzzjoni umana korrispondenti tagħhom bl-Ingliż. In addition, we also propose a translation pipeline build on top of Google Translate.  L-evalwazzjoni tal-pipeline propost dwar PHINC turi żieda fil-prestazzjoni tas-sistema sottostanti. Bl-isforz minimu, nistgħu nġeddu s-sett tad-dejta u l-approċċ propost għal pari lingwistiċi oħra li jitħalltu l-kodiċijiet.', 'mn': 'Кодлог холбогдох нь нэгээс их хэл ашиглах явдал юм. Олон хэл нийгэмд, нийгмийн хэвлэлийн платформуудын харилцааны хэлбэрийг ихэвчлэн анзаарсан байдаг. Нэг текст захидалд олон хэлний хэрэглэх гишүүн нь зорилготой үзэгчидтэй эффективно холбогдох тулд туслах боломжтой. Гэхдээ чимээгүй хэрэглэгчийн үүсгэсэн кодын төвөгтэй текст үйлдвэрлэх, байгалийн хэл ойлгох асуудлыг илүү том хэмжээнд нэмэгдүүлнэ. Нэг хэлний эх үүсвэрээс зориулсан хэл руу машин орчуулах нь сайн судалгааны асуудал юм. Энд бид хамгийн алдартай, сонирхолтой орчуулах системүүд Google Translate гэх мэт кодын холбогдсон текстүүдийг үр дүнтэй орчуулахад буруу гэдгийг харуулж байна. Энэхүү сорилтыг олохын тулд бид 13 738 хувилбар англи хэлний холбоотой хэллэгүүдийн параллел корпус болон тэдний холбоотой хүн төрөлхтний хөрөнгө Англи хэлний хэлний хэлний харилцааныг харуул Үүнээс ч мөн Google Translate дээр орчуулах хоолойн шугам бий болгоно. PHINC дээрх санал өгсөн хоолойн шугамын үнэлгээ нь үндсэн системийн үйл ажиллагааг нэмэгдүүлж байна. Бага зэрэг хичээлд өгөгдлийн сангууд болон санал дэвшүүлсэн арга замыг өөр хэл хооронд нэмэгдүүлж болно.', 'ml': 'ഒരു വാക്കില്\u200d ഒരു ഭാഷ ഉപയോഗിക്കുന്നതിനുള്ള കോഡ് മിക്കിങ്ങ് ആണ്. പല ഭാഷ സമൂഹത്തില്\u200d, സോഷ്യല്\u200d മീഡിയ പ്ലാറ്റ്ഫോമുകളില്\u200d സംസാരിക്കുന്നതിന്റെ രീതിയില്\u200d അത് വളരെ പ്രാവശ്യം കാണു ഒരു ടെക്സ്റ്റ് സന്ദേശത്തില്\u200d പല ഭാഷകള്\u200d ഉപയോഗിക്കുന്നതിനുള്ള ഫ്ലൈസിബിളിറ്റില്\u200d ലക്ഷ്യം കാണിക്കുന്ന ശ പക്ഷെ, ശബ്ദത്തിന്റെ സൃഷ്ടിക്കപ്പെട്ട കോഡ് മിഷ്ടപ്പെട്ട ട ടെക്സ്റ്റ് ചെയ്യുന്നതിനും സ്വാഭാവികമായ ഭാഷയില്\u200d വി Machine translation from monolingual source to the target language is a well-studied research problem.  ഇവിടെ, നമ്മള്\u200d കാണിക്കുന്നത് വളരെ പ്രധാനപ്പെട്ട, സോഫിസ്റ്റല്\u200d പരിഭാഷപ്പെടുത്തുന്ന സിസ്റ്റമുകള്\u200d, ഗൂഗിള്\u200d ട്രാന്\u200dസ ഈ വ്യാല്\u200dച്ചലിനെ വിശദീകരിക്കാന്\u200d, ഞങ്ങള്\u200d 13,738 കോഡ് കലര്\u200dത്തിയ ഹിന്ദി- ഇംഗ്ലീഷ് വാക്കുകളിലെ ഒരു പാരാളില്\u200d കോര്\u200dപ്പുസിനെ  കൂടാതെ, ഗൂഗിള്\u200d ട്രാന്\u200dസ്ട്രാന്\u200dസിന്\u200dറെ മുകളില്\u200d ഒരു പരിഭാഷ പൈപ്പെലിന്\u200d നിര്\u200dമ്മിക്കുന്നതും ഞങ് പിഹിന്\u200dസിയിലെ പൈപ്പെലൈനിന്\u200dറെ വിലാസങ്ങള്\u200d കാണിക്കുന്നു ഏറ്റവും ചെറുതായ ശ്രമം കൊണ്ട്, നമുക്ക് ഡാറ്റാസസെറ്റിനെയും പ്രൊദ്ദേശിക്കപ്പെട്ട മറ്റു കോഡ് മിക്കിങ്ങ', 'no': 'Kodefeksing er fenomenen for å bruka fleire enn eitt språk i eit setning. I dei fleirspråkelige samfunnene er det ein veldig ofte observert mønster for kommunikasjon på sosiale mediaplattformer. Fleksibilitet for å bruka fleire språk i ei tekstmelding kan hjelpa til å kommunisera effektivt med målpublikum. Men den støyde brukaren genererte teksten med mellom koden legg til utfordringen av handlinga og forståking av naturspråk i mykje større storleik. Maskineoversettelse frå monospråkkjelde til målspråket er eit godt studiert forskningsproblem. Her viser vi at veldig populære og sophistiserte omsetjingssystemer som Google Translate mislukkast på tidspunkt for å oversette tekst med kodeflikt. For å handtere denne utfordringen, presenterer vi ein parallell korpus av de 13 738 kode blandede hindiske setningane og deres tilsvarande menneske omsetjinga på engelsk. I tillegg foreslår vi også eit omsetjingsriplinje som bygger på toppen av Google Translate. Evalueringa av den foreslåde røyrlinja på PHINC viser ein økning i utviklinga av underliggende systemet. Med minste forsøk kan vi utvida datasettet og foreslått tilnærming til andre språkopar med kodefeksing.', 'pl': 'Mieszanie kodu to zjawisko używania więcej niż jednego języka w zdaniu. W społecznościach wielojęzycznych jest to bardzo często obserwowany wzór komunikacji na platformach mediów społecznościowych. Elastyczność korzystania z wielu języków w jednej wiadomości tekstowej może pomóc w efektywnej komunikacji z grupą docelową. Ale głośny tekst generowany przez użytkownika z kodem mieszanym zwiększa wyzwanie związane z przetwarzaniem i zrozumieniem języka naturalnego w znacznie większym stopniu. Tłumaczenie maszynowe z jednojęzycznego źródła na język docelowy jest dobrze zbadanym problemem badawczym. Tutaj pokazujemy, że powszechnie popularne i zaawansowane systemy tłumaczeń, takie jak Google Translate, czasami nie są w stanie skutecznie tłumaczyć tekstu mieszanego kodem. Aby sprostać temu wyzwaniu, przedstawiamy równoległy korpus 13,738 zdań mieszanych kodem hindi-angielski i ich odpowiednie tłumaczenie ludzkie w języku angielskim. Ponadto proponujemy również rurociąg tłumaczeń zbudowany na górze Google Translate. Ocena proponowanego rurociągu PHINC wykazuje wzrost wydajności systemu bazowego. Przy minimalnym wysiłku możemy rozszerzyć zbiór danych i proponowane podejście o inne pary językowe mieszające kod.', 'ro': 'Amestecarea codurilor este fenomenul folosirii mai multor limbi într-o propoziție. În comunitățile multilingve, acesta este un model de comunicare foarte frecvent observat pe platformele de social media. Flexibilitatea de a utiliza mai multe limbi într-un singur mesaj text ar putea ajuta la comunicarea eficientă cu publicul țintă. Cu toate acestea, textul zgomotos generat de utilizatori adaugă provocării procesării și înțelegerii limbajului natural într-o măsură mult mai mare. Traducerea automată de la sursă monolingvă la limba țintă este o problemă bine studiată de cercetare. Aici, demonstrăm că sistemele de traducere populare și sofisticate, cum ar fi Google Translate, nu reușesc uneori să traducă text amestecat de coduri în mod eficient. Pentru a aborda această provocare, vă prezentăm un corpus paralel al celor 13.738 de propoziții hindi-engleză combinate cu coduri și traducerea lor umană corespunzătoare în limba engleză. În plus, propunem, de asemenea, o conductă de traduceri construită pe partea de sus a Google Translate. Evaluarea conductei propuse pe PHINC demonstrează o creștere a performanței sistemului subiacent. Cu un efort minim, putem extinde setul de date și abordarea propusă la alte perechi de limbi de amestecare a codurilor.', 'sr': 'Pomješavanje kodova je fenomen korištenja više od jednog jezika u rečenici. U multijezičkim zajednicama, to je veoma često posmatrano obrazac komunikacije na platformama društvenih medija. Fleksibilnost korištenja višestrukih jezika u jednoj tekstnoj poruci može pomoći da se efikasno komunicira sa ciljnom publikom. Međutim, zvukovi korisnici koji su stvorili kodirani tekst dodaje izazovu obrade i razumevanja prirodnog jezika u veću mjeru. Prevedenje mašine od jednojezičkog izvora do ciljnog jezika je dobro proučen istraživački problem. Ovde pokazujemo da široko popularni i sofisticirani sustavi prevoda poput Google Translate ponekad nisu uspjeli da učinkovito prevodimo tekst pomiješan kod. Za rješavanje ovog izazova predstavljamo paralelni korpus od 13.738 šifre pomiješanih hindskih-engleskih rečenica i njihovih odgovarajućih ljudskih prevoda na engleskom jeziku. Osim toga, takođe predlažemo i prevodnu cijevinu izgradnju na vrhu Google Translate. Procjena predloženog naftovoda na PHINC pokazuje povećanje učinka temeljnog sistema. Sa minimalnim naporima možemo proširiti set podataka i predloženi pristup drugim parovima za mešanje kodova.', 'si': 'කෝඩ් මිශ්රණය තමයි වචනයකට වඩා වඩා භාෂාව භාවිත කරන්න පුළුවන්. බොහොම භාෂාවික සමාජිකයෙන්, ඒක සාමාජික මිඩියාව ප්\u200dරවේශයේ සම්බන්ධයක් ගැන බලාපොරොත්තු ව එක පාළ පණිවිඩයට වඩා භාෂාවක් භාවිත කරන්න පුළුවන් විශේෂතාවක් ලක්ෂ ප්\u200dරේක්ෂකයෙන් සම්බන් නමුත්, ශබ්ද භාවිතාකරණය නිර්මාණය කරපු කෝඩ් මිශ්\u200dරේෂණය පාළුවට ප්\u200dරශ්නය සහ ස්වභාවිත භාෂාව ගොඩක්  මෙසින් භාෂාවික ප්\u200dරභාවිතයෙන් ලක්ෂ භාෂාවෙන් පරීක්ෂණ ප්\u200dරශ්නයක්. මෙන්න, අපි පෙන්වන්නම් ප්\u200dරශ්නයක් කරනවා කියලා ගුගුල් භාෂාව පද්ධති වගේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විතරයි ක මේ අභ්\u200dයානය විධානය කරන්න, අපි 13,738 කෝඩ් එක්ක ඉංග්\u200dරීසි වචනය සහ ඔවුන්ගේ සම්බන්ධ මිනිස්සුන්ගේ අභ්\u200dයානයේ 13,73 ඒ වගේම, අපි ගුගුල් වාර්ථාපනයේ ඉහලට අවාර්ථ පායිප්ලින් නිර්මාණය කරනවා. PHINC ගැන ප්\u200dරතිචාර පායිප්ලින් ගැන විශ්ලේෂණය පෙන්වන්න පුළුවන් පද්ධතියේ විශාලනයක් පෙන්වන අඩුම ප්\u200dරයෝජනයෙන් අපිට දත්ත සෙට් සහ අනිත් කෝඩ් මික්ස් භාෂාවට ප්\u200dරයෝජනය කරන්න පුළුවන්.', 'so': 'Isku xiriirka codku waa arimaha isticmaalka hal luqad ka badan. Ururada luuqadaha kala duduwan waa noocyo aad u badan oo la soo jeedo wargelinta shabakada shabakadda bulshada. U soo guurista isticmaalka luuqado badan oo isku warqad ah waxaa laga yaabaa in uu caawinayo in aad si fiican ula xiriirto dhegayaasha goalka. Laakiin, isticmaalaha codka ah ee cod-mixed wuxuu ku daraa dhibaatada kala baaraandegista iyo waxgarashada afka dabiicadda ah si aad u weyn. Machine translation from monolingual source to the target language is a well-studied research problem.  Halkan, waxaynu muujinnaa nidaamka tarjumaadda oo ballaadhan iyo sophisticated sida Google Translate failed waqtiyadaas to translate code-mixed text effectively. Si aan u qabsado dhibaatadan, waxaan soo bandhignaa qoraalka kooxda 13,738 oo lagu isku xiray Hindi-Ingiriis iyo turjumidda dadka oo isku mid ah Ingiriis. Intaas waxaa dheer, waxaynu horumarinnaa dhismo turjubaan oo ku qoran Google Translate. Qiimeynta qoraalka PHINC ee la soo jeeday wuxuu muujiyaa kordhiska sameynta nidaamka hoose. Jahaadada ugu yaraan ayaannu ku sii fidin karnaa sawirka macluumaadka iyo dhaqdhaqaalaha la soo jeedin karo noocyo kale oo isku xiran luqada.', 'sv': 'Kodblandning är fenomenet att använda mer än ett språk i en mening. I de flerspråkiga samhällena är det ett mycket vanligt kommunikationsmönster på sociala medier. Flexibilitet att använda flera språk i ett textmeddelande kan bidra till att kommunicera effektivt med målgruppen. Men den bullriga användargenererade kodblandade texten bidrar till utmaningen att bearbeta och förstå naturligt språk i mycket större utsträckning. Maskinöversättning från enspråkig källa till målspråket är ett väl studerat forskningsproblem. Här visar vi att allmänt populära och sofistikerade översättningssystem som Google Translate ibland misslyckas med att översätta kodblandad text effektivt. För att möta denna utmaning presenterar vi en parallell korpus av de 13 738 kodblandade hindi-engelska meningarna och deras motsvarande mänskliga översättning på engelska. Dessutom föreslår vi också en översättningpipeline byggd ovanpå Google Translate. Utvärderingen av den föreslagna pipelinen på PHICK visar att det underliggande systemets prestanda ökar. Med minimal ansträngning kan vi utöka datauppsättningen och det föreslagna tillvägagångssättet till andra språkpar för kodblandning.', 'ta': 'ஒரு வாக்கியத்தில் மேற்பட்ட ஒரு மொழியை பயன்படுத்துவதற்கான குறியீடு கலந்து என்பது. பல மொழிக்கூட்டத்தில், அது சமூக ஊடகங்களின் தொடர்பு முறைமையில் அதிகமாக பார்க்கப்பட்டுள்ளது. Flexibility to use multiple languages in one text message might help to communicate efficiently with the target audience.  ஆனால், பயனர் உருவாக்கப்பட்ட குறியீட்டு கலக்கப்பட்ட உரையை செயல்படுத்துதல் மற்றும் புரிந்து கொள்ளும் இயல்பான மொழியின்  கணினி மொழிமூலத்திலிருந்து இலக்கு மொழிக்கு மொழியின் மொழிமாற்றம் ஒரு நன்றாக படிக்கப்பட்ட ஆராய்ச்ச இங்கே நாம் காட்டுகிறோம் அது பெரிய மற்றும் முக்கியமான மொழிபெயர்ப்பு அமைப்புகளை கூகுல் மொழிபெயர்ப்பு முறைமைகள் போ இந்த சவால்களை தேர்வு செய்ய, நாம் 13,738 குறியீடு கலக்கப்பட்ட ஹின்டி- ஆங்கிலம் வாக்கியங்களின் இணைய கோர்ப்பை கொண்டுள்ளோம்  கூகுல் மொழிபெயர்ப்பு மொழிபெயர்ப்பின் மேல் ஒரு மொழிபெயர்ப்பு பைப்லைன் கட்டுவதை நாம் பரிந்த PHINC மீது திருத்தப்பட்ட பைப்லைன் மதிப்பினை காண்பிக்கிறது அடிப்படையில் உள்ள முறைமையின் செயல்பாட்டின் அதி குறைந்தபட்ச முயற்சியுடன், நாம் தரவு அமைப்பை விரிவாக்கலாம் மற்றும் பரிந்துரைக்கப்பட்ட முறைமையை மற்றொரு', 'ur': 'کوڈ-میکسنگ ایک جماعت میں زیادہ زبان کا استعمال کرنے کا اتفاق ہے. بہت سی زبان کی جماعتیں میں یہ سوسیل میڈیا پٹرومٹ پر بہت زیادہ نظر آتا ہے۔ ایک پیغام پیغام میں بہت سی زبانیں استعمال کرنے کے لئے مہربانی ہو سکتی ہے کہ موجود اڈیوس کے ساتھ مہربانی کے ساتھ رابطہ کرنے کی مدد کرے۔ لیکن آواز استعمال کے پیدا کیے گئے کوڈ میکس پیغام کے ساتھ پرسس کرنا اور طبیعی زبان کا سمجھنا بہت بڑا اضافہ کرتا ہے۔ موجود زبان کی طرف سے ماشین کی ترجمہ موجود زبان کی طرف ایک بہترین تحقیق مشکل ہے. یہاں، ہم دکھاتے ہیں کہ بہت زیادہ مشهور اور مصنوعی ترجمہ سیستموں جیسے Google Translate کبھی کدھر کدھر مثبت کے ساتھ ترجمہ کرنے کے لئے ناکام ہوتے ہیں. اس چال کے بارے میں ہم 13,738 کیڈ کے متفرق ہینڈی-انگلیسی جماعتوں اور ان کے متفرق انسان کی ترجمہ انگلیسی میں پیش کرتے ہیں. اور ہم نے گوگل ترجمہ کے اوپر ایک ترجمہ پیپ لین بنایا ہے۔ PHINC پر پیشنهاد کی پیپ لین کی ارزیابی دکھاتی ہے کہ نیچے سیسٹم کی فعالیت میں بڑھتا ہے. کم کوشش کے ساتھ، ہم ڈاٹ سٹ اور پیشنهاد کی طرح دوسرے کوڈ میکسنگ زبان جوڑوں کے لئے پھیلاسکتے ہیں.', 'uz': "Kodlash usuli bir tildan ortiq bir tildan foydalanish. Ko'pchilik jamiyatlarda, bu jamiyat medya platformlarida ma'lumotni ko'p ko'pincha ko'paytirish modeli. Bir matn xabarda bir nechta tilni ishlatish imkoniyatini foydalanishi mumkin. Lekin, hozir foydalanuvchi qoidagi mixed matnni ko'paytirish va tabiiy tilni boshqarish va o'rganish muammolariga juda katta darajaga qo'shiladi. Name Bu yerda, biz juda katta popular va sophisticated tarjima tizimlari, Google Translate xil paytida muvaffaqiyatli tarjima qiladi. Bu muammolarni talab qilish uchun biz 13,738 kodi minglab Hindi- Ingliz tilidagi qoidalar va biz ingliz tilidagi inson tarjima tarjima qilishni anglatamiz. Ko'pchilik, biz Google tarjima uchun tarjima pipelining yuqorida yaratishni talab qilamiz. Name @ info: whatsthis", 'vi': 'Mã pha trộn là hiện tượng dùng nhiều ngôn ngữ trong một câu. Trong các cộng đồng đa dạng, nó là một mô hình liên lạc thường thấy trên các nền truyền thông xã hội. Sự mềm dẻo khi dùng nhiều ngôn ngữ trong một thông điệp văn bản có thể giúp liên lạc hiệu quả với khán giả đích. Nhưng, đoạn mã trộn lẫn ồn ào của người dùng thêm vào thách thức của việc xử lý và hiểu ngôn ngữ tự nhiên nhiều hơn. Dịch cỗ máy từ nguồn ngôn ngữ học đến ngôn ngữ đích là một vấn đề nghiên cứu được nghiên cứu kỹ lưỡng. Ở đây, chúng tôi chứng minh rằng những hệ thống dịch chuyển phổ biến và tinh vi như Google Dịch đôi khi thất bại trong việc dịch đoạn mã trộn có hiệu quả. Để đối phó với thách thức này, chúng tôi có thể đưa ra một tập hợp song trong 13,738, code trộn những câu tiếng Hindi-Anh của họ và bản dịch con người tương ứng bằng tiếng Anh. Ngoài ra, chúng tôi cũng đề nghị xây dựng một đường ống dịch ngay trên Google Dịch. Việc đánh giá ống dẫn dự kiến trên PHINC cho thấy khả năng hiệu suất của hệ thống cơ bản tăng lên. Với một nỗ lực tối thiểu, chúng ta có thể mở rộng bộ dữ liệu và phương pháp được đề xuất tới các cặp ngôn ngữ trộn mã khác.', 'bg': 'Смесването на кодове е явление за използване на повече от един език в изречение. В многоезичните общности това е много често наблюдаван модел на комуникация в социалните медии. Гъвкавостта за използване на няколко езика в едно текстово съобщение може да помогне за ефективна комуникация с целевата аудитория. Но шумният, генериран от потребителя код-смесен текст добавя предизвикателството за обработка и разбиране на естествения език в много по-голяма степен. Машинният превод от едноезичен източник на целевия език е добре проучен изследователски проблем. Тук демонстрираме, че широко популярните и усъвършенствани системи за превод като Гугъл Преводач понякога не успяват да превеждат ефективно смесен с кодове текст. За да се справим с това предизвикателство, представяме паралелен корпус от 13 738 кодово смесени хинди-английски изречения и съответния им човешки превод на английски език. Освен това предлагаме и канал за преводи, изграден върху Преводач. Оценката на предложения тръбопровод по PHINC показва повишаване на производителността на основната система. С минимални усилия можем да разширим набора от данни и предложения подход към други езикови двойки за смесване на кодове.', 'da': 'Kodeblanding er fænomenet med at bruge mere end ét sprog i en sætning. I de flersprogede samfund er det et meget hyppigt observeret kommunikationsmønster på sociale medieplatforme. Fleksibilitet til at bruge flere sprog i én tekstbesked kan hjælpe med at kommunikere effektivt med målgruppen. Men den støjende brugergenererede kodeblandede tekst øger udfordringen med at behandle og forstå naturligt sprog i langt større omfang. Maskinoversættelse fra ensproget kilde til målsproget er et velundersøgt forskningsproblem. Her viser vi, at meget populære og sofistikerede oversættelsessystemer som Google Translate til tider ikke kan oversætte kodeblandet tekst effektivt. For at løse denne udfordring præsenterer vi et parallelt korpus af de 13.738 kodeblandede hindi-engelske sætninger og deres tilsvarende menneskelige oversættelse på engelsk. Derudover foreslår vi også en oversættelsesrørledning bygget oven på Google Translate. Evalueringen af den foreslåede rørledning på PHICK viser en stigning i det underliggende systems ydeevne. Med minimal indsats kan vi udvide datasættet og den foreslåede tilgang til andre kodeblandingssprogpar.', 'nl': 'Code-menging is het fenomeen van het gebruik van meer dan één taal in een zin. In de meertalige gemeenschappen is het een zeer vaak waargenomen communicatiepatroon op sociale media platforms. Flexibiliteit om meerdere talen in één sms te gebruiken kan helpen om efficiënt te communiceren met de doelgroep. Maar de luidruchtige door gebruikers gegenereerde code-gemengde tekst draagt bij aan de uitdaging om natuurlijke taal in veel grotere mate te verwerken en te begrijpen. Machine translation van eentalige bron naar de doeltaal is een goed bestudeerd onderzoeksprobleem. Hier laten we zien dat populaire en geavanceerde vertaalsystemen zoals Google Translate er soms niet in slagen om code-gemengde tekst effectief te vertalen. Om deze uitdaging aan te pakken, presenteren we een parallel corpus van de 13.738 code-gemengde Hindi-Engelse zinnen en hun bijbehorende menselijke vertaling in het Engels. Daarnaast stellen we ook een vertaalpipeline voor die op Google Translate wordt gebouwd. De evaluatie van de voorgestelde pijplijn op PHINC toont een toename van de prestaties van het onderliggende systeem aan. Met minimale inspanning kunnen we de dataset en de voorgestelde aanpak uitbreiden naar andere code-mixende taalparen.', 'hr': 'Pomješavanje kodova je fenomen korištenja više od jednog jezika u rečenici. U multijezičkim zajednicama to je vrlo često posmatrano obrazac komunikacije na platformama društvenih medija. Fleksibilnost upotrebe višestrukih jezika u jednoj tekstnoj poruci može pomoći učinkovito komunicirati s ciljnom publikom. Međutim, zvukovi korisnici koji su stvorili kodirani tekst dodaje izazovu obrade i razumijevanja prirodnog jezika u veću mjeru. Prevod strojnog izvora iz monojezika do ciljnog jezika je dobro proučen istraživački problem. Ovdje pokazujemo da široko popularni i sofisticirani sustavi prevoda poput Google Translate ponekad ne mogu učinkovito prevoditi tekst pomiješan kod. Za rješavanje ovog izazova predstavljamo paralelni korpus od 13.738 šifra pomiješanih hindskih-engleskih rečenica i njihovih odgovarajućih ljudskih prevoda na engleskom jeziku. Osim toga, također predlažemo i prevodnu cijev izgradnju na vrhu Google Translate. Procjenjivanje predloženog cijevina na PHINC pokazuje povećanje učinka temeljnog sustava. Sa minimalnim naporima možemo proširiti set podataka i predloženi pristup drugim parovima za mješanje kodova.', 'de': 'Codemischung ist das Phänomen, dass mehr als eine Sprache in einem Satz verwendet wird. In den mehrsprachigen Communities ist es ein sehr häufig beobachtetes Kommunikationsmuster auf Social Media Plattformen. Die Flexibilität, mehrere Sprachen in einer Textnachricht zu verwenden, kann helfen, effizient mit der Zielgruppe zu kommunizieren. Aber der laute, benutzergenerierte Code-Mixed-Text erhöht die Herausforderung, natürliche Sprache in viel größerem Maße zu verarbeiten und zu verstehen. Die maschinelle Übersetzung von der einsprachigen Quelle in die Zielsprache ist ein gut erforschtes Forschungsproblem. Hier zeigen wir, dass weit verbreitete und anspruchsvolle Übersetzungssysteme wie Google Translate zeitweise nicht in der Lage sind, Code-Mixed-Text effektiv zu übersetzen. Um dieser Herausforderung gerecht zu werden, stellen wir einen parallelen Korpus der 13.738 kodierten Hindi-Englischen Sätze und ihrer entsprechenden menschlichen Übersetzung ins Englische vor. Darüber hinaus schlagen wir auch eine Übersetzungspipeline vor, die auf Google Translate aufbaut. Die Bewertung der vorgeschlagenen Pipeline auf PHINC zeigt eine Leistungssteigerung des zugrunde liegenden Systems. Mit minimalem Aufwand können wir den Datensatz und den vorgeschlagenen Ansatz auf andere Sprachpaare erweitern.', 'id': 'Pengcampuran kode adalah fenomena menggunakan lebih dari satu bahasa dalam kalimat. Dalam komunitas berbeda bahasa, ini adalah pola komunikasi yang sering diawasi di platform media sosial. Fleksibilitas untuk menggunakan berbagai bahasa dalam satu pesan teks mungkin membantu berkomunikasi dengan efisien dengan penonton sasaran. Namun, teks kode-campuran yang dibuat oleh pengguna yang berisik menambah tantangan untuk memproses dan memahami bahasa alam dalam jangkauan yang jauh lebih besar. Terjemahan mesin dari sumber monobahasa ke bahasa sasaran adalah masalah penelitian yang dipelajari dengan baik. Di sini, kita menunjukkan bahwa sistem terjemahan yang sangat populer dan canggih seperti Google Translate gagal kadang-kadang untuk menerjemahkan teks kode-campuran secara efektif. Untuk mengatasi tantangan ini, kami mempersembahkan sebuah korpus paralel dari 13.738 kalimat kode-campuran Hindi-Inggris dan terjemahan manusia yang sesuai dengan mereka dalam bahasa Inggris. Selain itu, kami juga mengusulkan pembangunan pipa terjemahan di atas Google Translate. The evaluation of the proposed pipeline on PHINC demonstrates an increase in the performance of the underlying system.  Dengan usaha minimal, kita dapat memperluas dataset dan pendekatan yang diusulkan untuk pasangan bahasa pengcampuran kode lainnya.', 'ko': '코드 혼합은 한 문장에 여러 언어를 사용하는 현상을 가리킨다.다국어 커뮤니티에서 소셜 미디어 플랫폼의 교류 모델은 매우 흔하다.문자 메시지에서 다양한 언어를 유연하게 사용하면 목표 시청자와 효과적으로 소통하는 데 도움이 될 수 있다.그러나 시끄러운 사용자가 생성한 코드 혼합 텍스트는 자연 언어를 처리하고 이해하는 데 더 큰 도전을 주었다.단어원에서 목적어까지의 기계 번역은 매우 잘 연구된 연구 문제이다.Google Translate와 같이 코드가 혼합된 텍스트를 효과적으로 번역할 수 없는 다양한 번역 시스템을 소개합니다.이 도전에 대응하기 위해 우리는 13738개의 코드가 인디언 영어 문장을 혼합하여 구성된 평행어 자료 라이브러리와 상응하는 영어 인공 번역을 제공하였다.또한 Google Translate를 기반으로 번역 파이프라인을 구축할 것을 권장합니다.PHINC에서 파이프를 건설하는 평가에 따르면 기초 시스템의 성능이 향상되었다.최소한의 노력만 기울이면 데이터 집합과 제안된 방법을 다른 코드 혼합 언어로 확장할 수 있다.', 'fa': 'پیوند\u200cگیری کد، پدیده\u200cی استفاده از بیشتر از یک زبان در یک جمله است. در جامعه های زیادی زبان، این یک الگوی بسیار اغلب مشاهده شده از ارتباطات در میان رسانه های اجتماعی است. قابلیت برای استفاده از زبانهای متعدد در یک پیام متن ممکن است کمک کند تا با تماشاگران هدف به طور موثر ارتباط برقرار کند. اما متن ترکیب کد پیدا شده از کاربر صدا به چالش پرداخت و درک زبان طبیعی بسیار بزرگتر اضافه می\u200cکند. ترجمه ماشین از منبع یک زبان به زبان هدف یک مشکل تحقیقات خوب مطالعه شده است. در اینجا، ما نشان می دهیم که سیستم\u200cهای ترجمه\u200cهای مشهور و پیچیده\u200cای مانند گوگل ترجمه در زمان شکست خورده است تا متن\u200cهای پیچیده\u200cی کد را به طور موثر ترجمه کند. برای حل این چالش، ما یک قالب مشابه از جمله\u200cهای ۱۳.738 کد مختلف از جمله\u200cهای هندی-انگلیسی و ترجمه\u200cهای انسانی را به انگلیسی پیشنهاد می\u200cکنیم. علاوه بر این، ما هم پیشنهاد می\u200cکنیم یک لوله\u200cی ترجمه بر بالای ترجمه گوگل. ارزیابی خط لوله پیشنهاد روی PHINC نشان می دهد که افزایش عملکرد سیستم پایین است. با تلاش minimal، می\u200cتوانیم مجموعه داده\u200cها و دستور پیشنهاد به جفت\u200cهای زبان مخلوط کردن کد را گسترش دهیم.', 'sw': 'Kuchanganya sheria ni hali ya kutumia zaidi ya lugha moja katika hukumu. Katika jamii nyingi za lugha, ni mtindo wa mawasiliano unaotangazwa mara kwa mara kwenye majukwaa ya mitandao ya kijamii. Uhamiaji wa kutumia lugha nyingi katika ujumbe mmoja wa maandishi unaweza kusaidia kuwasiliana na hadhira wenye lengo hilo. Lakini, mtumiaji wa kelele iliyotengenezwa kwa kutumia ujumbe wa kodi unaongeza changamoto ya upasuaji na kuelewa lugha ya asili kwa kiwango kikubwa zaidi. Tafsiri ya mashine kutoka chanzo cha lugha za kiutamaduni hadi lugha ya lengo ni tatizo lililosomwa vizuri. Here, we demonstrate that widely popular and sophisticated translation systems such as Google Translate fail at times to translate code-mixed text effectively.  Ili kukabiliana na changamoto hili, tunaweka viungo vinavyofanana na hukumu 13,738 zilizochanganyika kwa sheria ya Kihindi-Kiingereza na tafsiri yao inayofanana na kibinadamu kwa lugha ya Kiingereza. Zaidi ya hayo, tunapendekeza jengo la tafsiri juu ya Tafsiri la Google. Tathmini ya pipeli inayopendekezwa kwenye PHINC inaonyesha kuongezeka kwa ufanisi wa mfumo wa chini. Kwa juhudi za kidogo, tunaweza kuongeza seti ya taarifa na mbinu zilizopendekezwa ili kuwasiliana na wanandoa wengine wa lugha tofauti.', 'sq': 'Përzierja e kodeve është fenomeni i përdorimit të më shumë se një gjuhe në një fjalim. Në komunitetet shumëgjuhësore, është një model shumë shpesh i vëzhguar i komunikimit në platforma të medias sociale. Fleksibiliteti për të përdorur gjuhë të shumta në një mesazh teksti mund të ndihmojë për të komunikuar me efektshmëri me publikun objektiv. Por, teksti i përzier me kode të gjeneruar nga përdoruesit shton sfidën e procesimit dhe kuptimit të gjuhës natyrore në një shkallë shumë më të madhe. Përkthimi i makinave nga burimi monogjuhësor në gjuhën objektiv është një problem kërkimi i studiuar mirë. Këtu, ne demonstrojmë se sistemi shumë popullor dhe i sofistikuar i përkthimit të tillë si Google Translate dështojnë ndonjëherë për të përkthyer tekstin e përzier me kod efektivisht. Për të trajtuar këtë sfidë, ne paraqesim një korpus paralel të 13,738 fjalëve të përziera Hindi-Anglisht dhe përkthimit të tyre njerëzor në anglisht. In addition, we also propose a translation pipeline build on top of Google Translate.  Vlerësimi i tubacionit të propozuar mbi PHINC demonstron një rritje në performancën e sistemit bazues. Me përpjekje minimale, ne mund të zgjerojmë kompletin e të dhënave dhe qasjen e propozuar për çifte gjuhësh të tjera përzier kodet.', 'tr': "Köd karışmasy sözlerde birden köp dilden ullanýan döwüridir. Birnäçe dilli jemgyýetlerde, sosyal medýä platformlarynda örän köplenç görünýän habarlaşyk düzüldir. Bir metin mesajynda birnäçe diller ulanmak üçin Fleksitçe hili maksady publika bilen habarlaşmak üçin kömek edip biler. Emma, gürrüň ullançylar tarapyndan gelen köd karışmış metin işlemek we tebigy dilini a ňlamak kynçylyga ekleýär. Monolilingy çeşmeden maksadat diline maşynyň terjimesi gowy öwrenmeli araşdyrma meselesidir. Bu ýerde Google terjime edilen ýaly tanyş we soňky terjime sistemleri çykaryp bilmeýändigini görkez. Bu kynçylyky çözmek üçin 13,738 sany indi-iňlisçe sözleriniň parallel korpusyny we olaryň adamlaryň terjime edilmesini iňlisçe görkeýäris. Yöne biz hem Google terjime edeniň üstünde bir terjime pipelini gurmagy teklip edip görýäris. PHINC'de teklip çizginiň barlamasynyň düzlän sistemiň eserini ýokartýandygyny görkezýär. Iň kiçi kynçylyk bilen, veri düzümlerini we teklip eden metodlary başga köd karmaşgalan çiftlere uzaklaşdyryp bileris.", 'af': "Kode-gemeng is die fenomen van meer as een taal in 'n seting te gebruik. In die multitaalse gemeenskappe is dit 'n baie dikwels aangesien patroon van kommunikasie op sosiale media platforme. Fleksibiliteit om veelvuldige tale in een teksboodskap te gebruik kan help om effektief te kommuniseer met die doel publiek. Maar die geluidige gebruiker genereer kode gemengde teks byvoeg by die uitdrukking van verwerking en verstaan natuurlike taal tot 'n baie groter uitbreiding. Masjien vertaling van monolinge bron tot die doel taal is 'n goed studieerde forskingsproblaak. Hier, ons wys dat baie populêre en sofistike vertalingsstelsels soos Google Vertaling misluk op tye om kode gemengde teks effektief te vertaal. Om hierdie uitdrukking te raak, voorsien ons 'n parallele korpus van die 13,738 kode gemengde Hindi-Engels setinge en hulle ooreenstemmende menslike vertaling in Engels. In addition, we also propose a translation pipeline build on top of Google Translate. Die evaluering van die voorgestelde pipelyn op PHINC vertoon 'n vergroot in die prestasie van die onderstelling stelsel. Met die minimale versoek kan ons die datastel en die voorgestelde toegang uitbrei na ander kode-menger taal pare.", 'am': 'Code-mixing is the phenomenon of one language more than one language in sentence. በብዙ ቋንቋዎች ማኅበረሰቦች፣ ብዙ ጊዜም በማኅበራዊ አውታር ማኅበራዊ ሚዲያ ፕላጦማር ላይ የግንኙነት መልክ ነው፡፡ በአንድ ጽሑፍ መልዕክት ውስጥ ብዙዎችን ቋንቋዎች ለመጠቀም የሚችል ይችላል፡፡ ነገር ግን የድምፅ ተጠቃሚው የሆኑት የኮድ-ተለይቶ ጽሑፍ የፍጥረት ቋንቋ መግለጫ እና ለማስተዋል ትልቅ ቁጥጥር ይጨምርበታል፡፡ የመኪን ትርጉም ከሞያሊንቋ ጀምሮ እስከ ተቃውሞ ቋንቋ ነው፡፡ እዚህ፣ ሰፋዊ እና ሶፊስቲካዊ ትርጉም ስርዓቶች እንደ ጎግል ትርጉም በጊዜዎች ለመtranslate code-mixed text በጥቅም እናሳያልን፡፡ ይህንን ጥላቻ ለመቀበል፣ የ13,738 ኮድ የHindi-እንግሊዝኛ ቃላት እና የእንግሊዝኛ ትርጓሜ እና አዋጅ የሰው ትርጓሜ እናቀርባታለን፡፡ በተጨማሪም፣ የጎግል ትርጉም ላይ የተመዘረጉትን መግለጫ እናስጀጋለን፡፡ በPHINC ላይ የተዘጋጀው የኪፕላንስ ማስታወቂያ ውስጥም የሥርዓት ድምፅ ሲያሳያል፡፡ ከጥቂት ድጋፍ ጋር ዳራሲቱን እና የተዘጋጀውን የቋንቋ ዓይነቶች ለመቀላቀል እንችላለን፡፡', 'hy': 'Կոդների խառնուրդը նախադասության մեջ օգտագործելու ֆենոմենն է: Բազլեզու համայնքներում դա սոցիալական լրատվամիջոցների հարթակների հաճախ հետազոտում է: Մի տեքստի հաղորդագրության մեջ բազմաթիվ լեզուներ օգտագործելու ճկունությունը կարող է օգնել արդյունավետ հաղորդակցվել նպատակային հանդիսատեսի հետ: But, the noisy user-generated code-mixed text adds to the challenge of processing and understanding natural language to a much larger extent.  Մոնալեզու աղբյուրից դեպի նպատակային լեզու մեքենային թարգմանումը լավ ուսումնասիրել է հետազոտության խնդիր: Այստեղ մենք ցույց ենք տալիս, որ շատ հայտնի և բարդ թարգմանման համակարգերը, ինչպիսիք են Google Translate-ը, երբեմն չեն կարողանում արդյունավետ թարգմանել կոդի խառնված տեքստը: Այս մարտահրավերի լուծման համար մենք ներկայացնում ենք 13,738 կոդի-խառնված հինդի-անգլերեն նախադասությունների զուգահեռ մարմին և նրանց համապատասխան մարդկային թարգմանությունը անգլերեն: Ավելին, մենք նաև առաջարկում ենք թարգմանման խողովակաշար, որը կառուցվում է Google Translate-ի վրա: PHINC-ի առաջարկած խողովակաշարի գնահատումը ցույց է տալիս հիմնական համակարգի արդյունավետության աճ: Ինվազն ջանքերով մենք կարող ենք ընդլայնել տվյալների համակարգը և առաջարկված մոտեցումը այլ կոդի խառնող լեզվի զույգերին:', 'bn': 'কোড মিশ্রণ একটি বাক্যে এক ভাষায় ব্যবহার করার ব্যাপার হচ্ছে। মাল্টিভাষার সম্প্রদায়ের মধ্যে এটি সামাজিক মিডিয়া প্ল্যাটফর্মে যোগাযোগের প্রায়শই দেখা যায়। একটি টেক্সট বার্তায় বেশ কয়েকটি ভাষা ব্যবহার করার জন্য ফ্লিসিবিলিটি লক্ষ্যবস্তু শ্রোতাদের সাথে কার্যকর সংয কিন্তু এই শব্দ ব্যবহারকারীর ব্যবহারকারী তৈরি করা কোড মিশ্রিত লেখাটি প্রক্রিয়া এবং প্রাকৃতিক ভাষার চ্যালেঞ্জের সাথ মোনোলিভাল উৎস থেকে টার্গেট ভাষায় মেশিন অনুবাদ হচ্ছে ভালো গবেষণা সমস্যা। এখানে আমরা দেখাচ্ছি যে ব্যাপক জনপ্রিয় এবং সফিস্টিকেট অনুবাদ সিস্টেম, যেমন গুগল ট্রান্সলেঞ্জ ব্যর্থ হয়েছে সময়ে কোড- মিশ্ To address this challenge, we present a parallel corpus of the 13,738 code-mixed Hindi-English sentences and their corresponding human translation in English.  এছাড়াও আমরা গুগল ট্রান্সলেঞ্জের উপর একটি অনুবাদ পাইপেলাইন নির্মাণের প্রস্তাব করি। পিএইএনসিতে প্রস্তাবিত পাইপেলাইনের মূল্য প্রদর্শন করা হচ্ছে ভূতপূর্ণ সিস্টেমের প্রভাব বৃদ্ধি প্রদর্শন করে। সর্বনিম্ন প্রচেষ্টা দিয়ে আমরা ডাটাসেট বাড়িয়ে দিতে পারি এবং প্রস্তাবিত কোড মিশ্রিত ভাষার জোড়ায় অন্য কোডে', 'az': "Kod karışması bir cümlədə bir çox dildən çox istifadə etmək göstəricisidir. Çoxlu dil toplumlarında, bu sosyal media platformlarında çox sık görülür. Bir mətn ismarışı içində çoxlu dilləri istifadə etmək mümkün olar ki, mətn auditorisi ilə müvəffəqiyyəti olaraq əlaqə edə bilər. Lakin səslü istifadəçinin yaratdığı kodu karışmış metin işləmə və təbiətli dili çox böyük dəyişikliyə əlavə edir. Maksimum dildən məqsəd dilinə təlqin edilən məktəb məlumatı gözəl təhsil edilmiş araştırma problemidir. Burada, Google Translate kimi çox məşhur və sofistikli tercümə sistemlərinin còd karışıqlı metinləri tərcümə etməsi mümkün olduğunu göstəririk. Bu çətinlikdən çəkinmək üçün 13.738 kodlu Hindi-İngilizce cümlələrinin paralel korpusu və onların adi insan tercümünü İngilizce dilində göstəririk. Üstündə də Google Translation'un üstündə bir çevirim borusunu təklif edirik. PHINC'nin təbliğ edilmiş bor çizginin değerlendirməsi əsas sistemin performansını artırmağını göstərir. minimal çabaları ilə, verilən qurğunu və təklif edilən metodları başqa còd karıştırıcı dil çiftlərinə genişləyə bilərik.", 'cs': 'Míchání kódu je fenomén používání více než jednoho jazyka ve větě. V mnohojazyčných komunitách se jedná o velmi často pozorovaný vzor komunikace na platformách sociálních médií. Flexibilita používání více jazyků v jedné textové zprávě může pomoci efektivně komunikovat s cílovým publikem. Ale hlučný uživatelsky generovaný text smíšený kódem přispívá k výzvě zpracování a porozumění přirozenému jazyku v mnohem větší míře. Strojový překlad z jednojjazyčného zdroje do cílového jazyka je dobře studovaným výzkumným problémem. Zde ukazujeme, že široce populární a sofistikované překladatelské systémy, jako je Google Translate, občas nedokážou efektivně překládat text smíšený kódem. Pro řešení této výzvy představujeme paralelní korpus 13,738 kódově smíšených hindsky-anglických vět a jejich odpovídající lidský překlad do angličtiny. Kromě toho navrhujeme také překladatelské potrubí postavené na vrcholu Google Translate. Hodnocení navrhovaného plynovodu na PHINC ukazuje zvýšení výkonnosti základního systému. S minimálním úsilím můžeme datovou sadu a navržený přístup rozšířit o další jazykové páry smíšení kódu.', 'et': 'Koodide segamine on nähtus, kus lauses kasutatakse rohkem kui ühte keelt. Mitmekeelsetes kogukondades on see väga sageli täheldatud suhtlusmudel sotsiaalmeedia platvormidel. Paindlikkus kasutada mitut keelt ühes tekstisõnumis võib aidata tõhusalt suhelda sihtrühmaga. Kuid mürakas kasutaja loodud koodisegatekst suurendab looduskeele töötlemise ja mõistmise väljakutset palju suuremal määral. Masintõlge ühekeelsest allikast sihtkeelde on hästi uuritud uurimisprobleem. Siin näitame, et laialdaselt populaarsed ja keerukad tõlkesüsteemid, nagu Google Translate, ei suuda mõnikord tõlkida koodisegatud teksti tõhusalt. Selle väljakutse lahendamiseks esitame paralleelse korpuse 13738 koodsega hindi-inglise lausest ja nende vastavast inimtõlkest inglise keeles. Lisaks pakume välja ka tõlkejuhtme, mis põhineb Google Tõlke peal. PHINCi kavandatava torujuhtme hindamine näitab aluseks oleva süsteemi tulemuslikkuse suurenemist. Minimaalse jõupingutusega saame laiendada andmekogumit ja kavandatud lähenemisviisi teistele koodisegamiskeelepaaridele.', 'bs': 'Pomješavanje kodova je fenomen korištenja više od jednog jezika u rečenici. U multijezičkim zajednicama to je vrlo često posmatrano obrazac komunikacije na platformama društvenih medija. Fleksibilnost upotrebe višestrukih jezika u jednoj tekstnoj poruci može pomoći da se efikasno komunicira sa ciljnom publikom. Međutim, zvukovi korisnici koji su stvorili kodirani tekst dodaje izazovu obrade i razumijevanja prirodnog jezika u mnogo veću mjeru. Prevod strojnog izvora iz monojezika do ciljnog jezika je dobro proučen istraživački problem. Ovdje pokazujemo da široko popularni i sofisticirani sustavi prevoda poput Google Translate ponekad nisu uspjeli efektivno prevoditi tekst pomiješan kod. Za rješavanje ovog izazova predstavljamo paralelni korpus od 13.738 koda pomiješanih hindskih-engleskih rečenica i njihovih odgovarajućih ljudskih prevoda na engleskom jeziku. Osim toga, također predlažemo i prevodnu cijev izgradnju na vrhu Google Translate. Procjenjivanje predloženog cijevina na PHINC pokazuje povećanje učinka temeljnog sistema. Sa minimalnim naporima možemo proširiti set podataka i predloženi pristup drugim parovima za mješanje kodova.', 'ca': "La combinació de codis és el fenomen d'utilitzar més d'una llengua en una frase. En les comunitats multilingües, és un patró de comunicació observat molt sovint a les plataformes dels mitjans socials. La flexibilitat d'utilitzar múltiples llengües en un missatge de text pot ajudar a comunicar-se eficientment amb l'audiència alvo. Però el sorollós text combinat amb codis generat per l'usuari afegeix al repte de processar i entendre la llengua natural en molt més gran escala. La traducció màquina des de fonts monolingües a la llengua alvo és un problema de recerca ben estudiat. Here, we demonstrate that widely popular and sophisticated translation systems such as Google Translate fail at times to translate code-mixed text effectively.  Per abordar aquest repte, presentem un cos paral·lel de les 13.738 frases hindo-anglès combinades amb codi i la seva traducció human a correspondent en anglès. A més, també proposem un tub de traducció construït per sobre de Google Translate. L'evaluació del pipeline proposat sobre PHINC demostra un augment en el rendiment del sistema subjacent. Amb un esforç mínim, podem estendre el conjunt de dades i l'enfocament proposat a altres parelles de llenguatges de combinació de codis.", 'fi': 'Koodien sekoittaminen on ilmiö, jossa lauseessa käytetään useampaa kuin yhtä kieltä. Monikielisissä yhteisöissä tämä on hyvin usein havaittu viestintämuoto sosiaalisen median alustoilla. Joustavuus käyttää useita kieliä yhdessä tekstiviestissä saattaa auttaa kommunikoimaan tehokkaasti kohdeyleisön kanssa. Mutta meluisa käyttäjän luoma koodisekoitettu teksti lisää haasteeseen käsitellä ja ymmärtää luonnollista kieltä paljon laajemmin. Konekääntäminen monikielisestä lähteestä kohdekieleen on hyvin tutkittu tutkimusongelma. Tässä osoitamme, että laajalti suositut ja hienostuneet käännösjärjestelmät, kuten Google Translate, eivät toisinaan pysty kääntämään koodisekoitettua tekstiä tehokkaasti. Haasteeseen vastaamiseksi esittelemme rinnakkaisen korpusen 13 738 koodisekoitetusta hindi-englanti lauseesta ja niiden vastaavista inhimillisistä käännöksistä englanniksi. Lisäksi ehdotamme Google Translaten päälle rakennettavaa käännöspalvelua. PHINC:n ehdotetun putkiston arviointi osoittaa, että taustalla olevan järjestelmän suorituskyky on parantunut. Voimme mahdollisimman pienellä vaivalla laajentaa aineistoa ja ehdotettua lähestymistapaa muihin koodauskielipareihin.', 'jv': 'Kodi-Mixing kuwi nggambar ujaran kanggo saben luwih dumadhi sing sampeyan. Nang kaya komunitas sing luwih akeh bangsane, kuwi ing sakjane sedhaya sing ngulingke boten kanggo nggambar barang media sotiki. Peringatus kanggo nggambar luwih dumadhi ing sampeyan Teks string" in "context_BAR_stringLink Pilihan menyang mungkun punika ingkang sampeyan kanggo nggawe langkung banjure sak luwih apik sing ngejarian kanggo ranjut. Iki, kéné mulasar seneng langkung populer lan soaket sistem terjamahan kaya ngono Google translation kuwi nggawe kapan kanggo terjamah kode mingsuse teks kang efek. kanggo nganggo cara-cara iki, kita sampeyan mruput egal-perusahaan karo nguasai 13. Nambah, kita tambah gunakake tarjamahan kanggo tukang banter Google translation. Where\'s the input line? Defs', 'ha': "Code-haɗiyar shi ne abu da za'a yi amfani da shi kodi cikin birnin. A cikin jamii masu mulki na'ura, yana da wata irin mutane da aka yi wa wasiyya a kan zangaren mutane na jamii. Motsi da za'a yi amfani da wasu harshe masu yawa cikin jumbe guda, za'a yi amfani da wajen haɗi da saurãre masu tsari da amfani. Amma, ƙiyayya mai amfani da aka haife kodi-blendin matsayin na ƙara zuwa mai ƙaranci na fassara da fahimta lugha na natura. @ info: tooltip @ info: whatsthis To, dõmin ka yi addu'a ga wannan tsohon, muna halatar da kofu na 13,738 da kodi-haɗe na Hidi-Ingiriya da taƙaitransu mai daidai a cikin Ingiriya. Da wannan, za mu goyyade wani rubutun tarjima a kan Google Translate. Ana ƙaddara piilen da aka buyar da shi a kan PUNC, yana nuna wani yana ƙarantar aikin na'urar da ke ƙaranci. Ga da aikin da aka ƙara, za mu iya shimfiɗa tsarin bayani da aka buƙata hanyarwa zuwa wasu nau'in kodi-da-haɗi harshen.", 'he': 'התערבות קודים היא התופעה של השימוש בשפה אחת במשפט. בקהילות הרב-שפויות, זו דפוס התקשורת שנצפה לעתים קרובות מאוד על פלטפורמות התקשורת החברתית. הזמינות להשתמש בשפות רבות בהודעה טקסטית אחת עלולה לעזור לתקשר באופן יעיל עם הקהל המטרה. אבל, הטקסט הרעשני שנוצר ע"י משתמשים מעורב קוד מוסיף לאתגר של העבודה והבנה של שפה טבעית במידה הרבה יותר גדולה. Machine translation from monolingual source to the target language is a well-studied research problem.  כאן, אנחנו מראים כי מערכות התרגום פופולריות ומתוקפות רחבה כמו Google Translate נכשלות לפעמים לתרגם טקסט מעורבב קוד יעיל. כדי להתמודד עם האתגר הזה, אנחנו מציגים קורפוס מקביל של 13,738 משפטים הינדי-אנגלית מעורבים קוד והתרגום האנושי המתאים שלהם באנגלית. בנוסף, אנחנו גם מציעים צינור תרגום בנוי על גבי Google Translate. הערכה של צינור הציע על PHINC מראה עליית ביצועים של מערכת המרכזית. עם מאמץ מינימלי, אנחנו יכולים להאריך את קבוצת המידע והגישה המוצעת לזוגי שפת מעורבבים קודים אחרים.', 'sk': 'Mešanje kod je pojav uporabe več kot enega jezika v stavku. V večjezičnih skupnostih je to zelo pogosto opažen vzorec komunikacije na platformah socialnih medijev. Prilagodljivost uporabe več jezikov v enem besedilnem sporočilu lahko pomaga učinkovito komunicirati s ciljno skupino. Vendar hrupno besedilo, ki ga ustvarijo uporabniki, mešano s kodo, v veliko večji meri prispeva k izzivu obdelave in razumevanja naravnega jezika. Strojno prevajanje iz enojezičnega vira v ciljni jezik je dobro preučen raziskovalni problem. Tukaj dokazujemo, da zelo priljubljeni in prefinjeni prevajalski sistemi, kot je Google Translate, včasih ne uspejo učinkovito prevajati besedila z mešanimi kodami. Za reševanje tega izziva predstavljamo vzporedni korpus 13.738 kod mešanih hindijsko-angleških stavkov in njihov ustrezen človeški prevod v angleščino. Poleg tega predlagamo tudi prevajalski plinovod, ki temelji na Googlovem prevajalcu. Ocena predlaganega cevovoda za PHINC kaže povečanje učinkovitosti osnovnega sistema. Z minimalnim naporom lahko nabor podatkov in predlagani pristop razširimo na druge jezikovne pare mešanja kod.', 'bo': 'སྐད་རིགས་གཅིག་ལས་མང་ཙམ་བེད་སྤྱོད་ཀྱི་བྱ་ཚིག་ཅིག་རེད། སྐད་རིགས་སྣ་མང་ཆེ་བའི་ཚོགས་སྡེའི་ནང་དུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་གླེང་སྒྲུང་ཐོག་ཏུ་མང་ཙམ་ལ་མཐོང ཡི་གེའི་འཕྲིན་དོན་གཅིག་ནང་སྐད་རིགས་མང་པོ་ཞིག་བེད་སྤྱོད་པར་ཆ་རྐྱེན འོན་ཀྱང་། སྒྲ་བརྙན་པའི་ལག་ལེན་པ་གྱིས་བྱུང་བའི་ཡིག་གེ་གྲངས་བསྡུར་ཡོད་པའི་མིང་རྟགས་ལ་ལས་སྦྱོར་ཀྱི་གནོད་འཁྲུལ་ལ སྐད་ཡིག་ཆ་གཅིག་པུའི་ནང་ནས་དམིགས་ཡུལ་གྱི་སྐད་ཡིག འདིར་བརྟེན། ང་ཚོས་རྒྱ་ནག་གི་སྐད་ཆ་སྐད་ཡིག་ཆ་དང་ཧྲིལ་རྒྱུན་གྱི་ཡིག་སྣོད། དཔེར་ན་ Google Translate་ཡིག་སྐབས་དུས་འཚར་བ་ གདོང་ལེན་འདི་ལ་ཐབས་མེད་པར་ང་ཚོས་འདིའི་ནང་དུ་ཅིག་གི་སྤྱི་ཚོགས་ཁག་ཅིག་གནད་ཅིག་ཡོད་པའི་བྱ་ཚིག་གཟུགས་བ་རེད། ད་དུང་། ང་ཚོས་Google Translation ཐོག་ཏུ་ཡིག་སྒྲུང་ཕྱོགས་ཀྱི་ཆོག་ཐང་ཞིག་གསར་འཛུགས་བྱེད་རྒྱུ་བཤད་ཀྱི་ཡོད། The evaluation of the proposed pipeline on PHINC demonstrates an increase in the performance of the underlying system. ཆུང་བའི་སྐྱེས་ཚད་ཆེ་ཆུང་དུ་འོང་ཚོས་ཡིག་ཆ་སྒྲིག'}
{'en': 'Non-ingredient Detection in User-generated Recipes using the Sequence Tagging Approach', 'ar': 'اكتشاف عدم وجود مكونات في الوصفات التي ينشئها المستخدم باستخدام نهج وضع العلامات على التسلسل', 'fr': "Détection de non-ingrédients dans les recettes générées par l'utilisateur à l'aide de l'approche par marquage séqu", 'pt': 'Detecção de não ingredientes em receitas geradas pelo usuário usando a abordagem de marcação de sequência', 'es': 'Detección de no ingredientes en recetas generadas por el usuario mediante el enfoque de etiquetado de secuencias', 'ru': 'Обнаружение неингредиентов в пользовательских рецептах с использованием подхода к маркировке последовательностей', 'ja': 'シーケンスタギングアプローチを使用してユーザーが生成したレシピでの非リンジエント検出', 'zh': '用序标法于用户成配方中检测非分', 'hi': 'अनुक्रम टैगिंग दृष्टिकोण का उपयोग कर उपयोगकर्ता-जनित व्यंजनों में गैर-घटक का पता लगाना', 'ga': 'Brath Neamhchomhábhar i Oidis a ghintear ag Úsáideoirí ag úsáid an Chur Chuige Chlibeála Seicheamhaí', 'ka': 'მომხმარებლის შექმნილი რესპერიოში არა ინგრედიენტის განახლება', 'el': 'Ανίχνευση μη συστατικών σε συνταγές που δημιουργούνται από τον χρήστη χρησιμοποιώντας την προσέγγιση σήμανσης ακολουθίας', 'hu': 'Nem összetevők észlelése a felhasználó által létrehozott receptekben a sorozatcímkézési módszer segítségével', 'it': "Rilevamento di non ingredienti nelle ricette generate dall'utente utilizzando l'approccio Sequence Tagging", 'mk': 'Non-ingredient Detection in User-generated Recipes using the Sequence Tagging Approach', 'kk': 'Ингредиент емес пайдаланушының құрылған рецептерінде табу', 'lt': 'Nesudedamųjų dalių nustatymas naudotojų sukurtuose receptuose naudojant sekos ženklinimo metodą', 'mn': 'Хэрэглэгч үүсгэсэн Recipes-ээс бүтээгдэхүүн биш зүйл тайлбарлах', 'ms': 'Pengesanan bukan-bahan dalam Reċipit yang dijana-pengguna menggunakan Pendekatan Tagging Sekuensi', 'mt': 'Sejbien ta’ mhux ingredjenti f’Reċipjenti ġġenerati mill-utent bl-użu tal-Approċċ tat-Tagging tas-Sekwenza', 'ml': 'ഉപയോക്താവ് സൃഷ്ടിച്ചുണ്ടാക്കുന്ന റിസിപ്പികളില്\u200d ഉള്\u200dപ്പെടുത്തിയിട്ടില്ലാത്ത പ്രശ്നം', 'no': 'Ikkje- ingredient- oppdaging i brukargenererte mottakar ved hjelp av sekvensmerking', 'pl': 'Wykrywanie nieskładników w recepturach generowanych przez użytkownika przy użyciu metody znakowania sekwencji', 'ro': 'Detectarea non-ingredientelor în rețetele generate de utilizator utilizând abordarea etichetării secvențelor', 'sr': 'Nesastojni otkrivanje u korisničkim receptima koristeći pristup označavanja sekvence', 'si': 'පාවිච්චිකරුවෙන් හොයාගන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය නොප්\u200dරයෝජනය හොයාගන්', 'so': 'Heegan-ingredient in User-generated Recipients using the Sequence Tagging Approach', 'sv': 'Detektering av icke-ingredienser i användargenererade recept med hjälp av metoden för sekvensmärkning', 'ta': 'பொருள் இல்லாத கண்டுபிடிப்பு', 'ur': 'کارساز کے پیدا کئے ہوئے ریسپیٹ میں غیر انگریڈینٹ پتچا', 'uz': 'Davom etish', 'vi': 'Việc phát hiện trong các nền văn bản tạo người dùng dùng dùng phương pháp đánh giá dãy', 'da': 'Detektering af ikke-ingredienser i brugergenererede opskrifter ved hjælp af sekvensmærkning metoden', 'bg': 'Откриване на несъществени съставки в генерирани от потребителя рецепти с помощта на подхода за етикетиране на последователността', 'hr': 'Otkrivanje ne sastojaka u korisničkim receptima koristeći pristup označavanja sekvence', 'nl': 'Detectie van niet-ingrediënten in door gebruikers gegenereerde recepten met behulp van de sequentie tagging aanpak', 'ko': '시퀀스 표기 방법을 사용하여 사용자가 생성한 설계도에서 비성분 검사를 진행하다', 'fa': 'پیدا کردن غیر عنصر در دریافت\u200cهای تولید شده از کاربر با استفاده از نزدیک برچسب برچسب\u200cهای بعدی', 'de': 'Erkennung von Inhaltsstoffen in nutzergenerierten Rezepten mit dem Sequence Tagging Ansatz', 'sw': 'Kitambua Kihahitajika katika Makubaliano ya Mtumiaji iliyotengenezwa kwa kutumia Uwekezaji wa Kuzungumzia', 'id': 'Deteksi bukan bahan dalam resep yang dibuat oleh pengguna menggunakan pendekatan Tagging Sequence', 'tr': 'Ullançy Tertiblemek Approsyny ulanylan Ullançy Tarymlarda', 'sq': 'Detektimi i jo-përbërësve në recetat e gjeneruara nga përdoruesit duke përdorur metodën e etiketave të sekuencës', 'af': 'Nie- ingredient Opdekking in Gebruiker- genereerde Recipes gebruik die Sequence Tagging Approach', 'bn': 'ব্যবহারকারী উৎপাদন করা রিপিপোর্টের মধ্যে কোন উপাদান নেই', 'am': 'ቦታ፦', 'hy': 'Օգտագործողների կողմից ստեղծված բաղադրիչների բացահայտումն օգտագործելով հաջորդականության նշանակման մոտեցումը', 'az': 'İstifadəçi yaratdığı Reciplərdə, Sıradan Etilmə Yaxınlığı ilə istifadə edilməz', 'et': 'Mittekomponentide tuvastamine kasutaja loodud retseptides järjestuse märgistamise meetodi abil', 'ca': "Detecció de no-ingredients en receptes generades per l'usuari utilitzant l'enfocament d'etiqueta de secuencia", 'cs': 'Detekce neslátek v uživatelsky generovaných receptech pomocí přístupu k sekvenčnímu tagování', 'bs': 'Nesastojni otkrivanje u korisničkim receptima koristeći pristup označavanja sekvence', 'fi': 'Muiden kuin ainesosien tunnistus kĂ¤yttĂ¤jĂ¤n luomissa resepteissĂ¤ kĂ¤yttĂ¤mĂ¤llĂ¤ sekvenssimerkkausmenetelmĂ¤Ă¤', 'jv': '#a11y <joanie> hello!<joanie> hello!', 'he': 'גילוי לא-מרכיבים במתכונים שנוצרים ע"י משתמשים באמצעות גישת תג רצף', 'ha': '@ action', 'sk': 'Zaznavanje brez sestavin v uporabniških receptih z uporabo pristopa za označevanje zaporedja', 'bo': 'སྤྱོད་མཁན་གྱི་རྣམ་པ་མེད་པའི་འཛུལ་སྤྱོད་མཁན་ལ་ཁ་འབྱེད་པའི་འཛུལ་སྤྱོད་པ'}
{'en': 'Recently, the number of  user-generated recipes  on the Internet has increased. In such  recipes , users are generally supposed to write a title, an ingredient list, and steps to create a dish. However, some items in an ingredient list in a  user-generated recipe  are not actually edible ingredients. For example, headings, comments, and  kitchenware  sometimes appear in an ingredient list because users can freely write the list in their recipes. Such noise makes it difficult for computers to use  recipes  for a variety of  tasks , such as calorie estimation. To address this issue, we propose a non-ingredient detection method inspired by a neural sequence tagging model. In our experiment, we annotated 6,675 ingredients in 600 user-generated recipes and showed that our proposed  method  achieved a 93.3  F1 score .', 'ar': 'في الآونة الأخيرة ، ازداد عدد الوصفات التي ينشئها المستخدمون على الإنترنت. في مثل هذه الوصفات ، من المفترض عمومًا أن يكتب المستخدمون عنوانًا وقائمة مكونات وخطوات لإنشاء طبق. ومع ذلك ، فإن بعض العناصر الموجودة في قائمة المكونات في الوصفة التي ينشئها المستخدم ليست في الواقع مكونات صالحة للأكل. على سبيل المثال ، تظهر العناوين والتعليقات وأدوات المطبخ أحيانًا في قائمة المكونات لأن المستخدمين يمكنهم كتابة القائمة بحرية في وصفاتهم. تجعل هذه الضوضاء من الصعب على أجهزة الكمبيوتر استخدام وصفات لمجموعة متنوعة من المهام ، مثل تقدير السعرات الحرارية. لمعالجة هذه المشكلة ، نقترح طريقة اكتشاف غير مكونة مستوحاة من نموذج علامات التسلسل العصبي. في تجربتنا ، قمنا بتعليق 6675 مكونًا في 600 وصفة أنشأها المستخدم وأظهرنا أن طريقتنا المقترحة حققت درجة 93.3 F1.', 'es': 'Recientemente, el número de recetas generadas por los usuarios en Internet ha aumentado. En estas recetas, generalmente se supone que los usuarios escriben un título, una lista de ingredientes y los pasos para crear un plato. Sin embargo, algunos elementos de una lista de ingredientes de una receta generada por el usuario no son realmente ingredientes comestibles. Por ejemplo, los encabezados, los comentarios y los utensilios de cocina a veces aparecen en una lista de ingredientes porque los usuarios pueden escribir libremente la lista en sus recetas. Este ruido dificulta que las computadoras usen recetas para una variedad de tareas, como la estimación de calorías. Para abordar este problema, proponemos un método de detección sin ingredientes inspirado en un modelo de marcaje de secuencias neuronales. En nuestro experimento, anotamos 6.675 ingredientes en 600 recetas generadas por los usuarios y demostramos que nuestro método propuesto obtuvo una puntuación F1 de 93,3.', 'fr': "Récemment, le nombre de recettes générées par les utilisateurs sur Internet a augmenté. Dans de telles recettes, les utilisateurs sont généralement censés écrire un titre, une liste d'ingrédients et les étapes pour créer un plat. Cependant, certains éléments d'une liste d'ingrédients d'une recette générée par l'utilisateur ne sont pas réellement des ingrédients comestibles. Par exemple, les en-têtes, les commentaires et les ustensiles de cuisine apparaissent parfois dans une liste d'ingrédients parce que les utilisateurs peuvent écrire librement la liste dans leurs recettes. Ce bruit rend difficile l'utilisation par les ordinateurs de recettes pour diverses tâches, comme l'estimation des calories. Pour résoudre ce problème, nous proposons une méthode de détection sans ingrédient inspirée d'un modèle de marquage de séquences neuronales. Dans notre expérience, nous avons annoté 6 675 ingrédients dans 600 recettes générées par les utilisateurs et montré que notre méthode proposée obtenait un score F1 de 93,3.", 'pt': 'Recentemente, o número de receitas geradas pelo usuário na Internet aumentou. Em tais receitas, os usuários geralmente devem escrever um título, uma lista de ingredientes e etapas para criar um prato. No entanto, alguns itens em uma lista de ingredientes em uma receita gerada pelo usuário não são realmente ingredientes comestíveis. Por exemplo, títulos, comentários e utensílios de cozinha às vezes aparecem em uma lista de ingredientes porque os usuários podem escrever livremente a lista em suas receitas. Esse ruído torna difícil para os computadores usarem receitas para uma variedade de tarefas, como estimativa de calorias. Para resolver esse problema, propomos um método de detecção de não ingrediente inspirado em um modelo de marcação de sequência neural. Em nosso experimento, anotamos 6.675 ingredientes em 600 receitas geradas por usuários e mostramos que nosso método proposto alcançou uma pontuação F1 de 93,3.', 'ja': '最近では、インターネット上でユーザーが作成したレシピの数が増加しています。このようなレシピでは、ユーザーは通常、タイトル、材料リスト、および料理を作成するための手順を書くことになっています。ただし、ユーザーが作成したレシピの成分リストの一部のアイテムは、実際には食用成分ではありません。たとえば、見出し、コメント、キッチンウェアは、ユーザーがレシピに自由にリストを書くことができるため、食材リストに表示されることがあります。このようなノイズは、コンピュータがカロリー推定などの様々なタスクにレシピを使用することを困難にする。この問題に対処するために、神経配列タグ付けモデルに触発された非認識検出法を提案する。実験では、６ ０ ０個のユーザー生成レシピの６ ， ６ ７ ５個の成分を注釈し、提案された方法が９ ３ ． ３ Ｆ １スコアを達成したことを示した。', 'hi': 'हाल ही में, इंटरनेट पर उपयोगकर्ता-जनित व्यंजनों की संख्या में वृद्धि हुई है। इस तरह के व्यंजनों में, उपयोगकर्ताओं को आमतौर पर एक शीर्षक, एक घटक सूची और एक डिश बनाने के लिए कदम लिखना चाहिए। हालांकि, उपयोगकर्ता-जनित नुस्खा में एक घटक सूची में कुछ आइटम वास्तव में खाद्य सामग्री नहीं हैं। उदाहरण के लिए, शीर्षक, टिप्पणियां और किचनवेयर कभी-कभी एक घटक सूची में दिखाई देते हैं क्योंकि उपयोगकर्ता स्वतंत्र रूप से अपने व्यंजनों में सूची लिख सकते हैं। इस तरह के शोर से कंप्यूटर के लिए विभिन्न प्रकार के कार्यों के लिए व्यंजनों का उपयोग करना मुश्किल हो जाता है, जैसे कि कैलोरी अनुमान। इस मुद्दे को हल करने के लिए, हम एक तंत्रिका अनुक्रम टैगिंग मॉडल से प्रेरित एक गैर-घटक का पता लगाने की विधि का प्रस्ताव करते हैं। हमारे प्रयोग में, हमने 600 उपयोगकर्ता-जनित व्यंजनों में 6,675 अवयवों को एनोटेट किया और दिखाया कि हमारी प्रस्तावित विधि ने 93.3 एफ 1 स्कोर हासिल किया।', 'zh': '近者,互联网上用户生成食谱数有所增益。 如此食谱中,用户常应写一标题,一成列表,及创一菜步驿。 然用户生之食谱,列表之实非可食之分也。 如标题、注释、厨具时见于成列,盖用户得于其食谱中自由也。 此噪音使计算机难将食谱用于百务,如卡路里估。 为此一受神经序识模样,非成分检。 于我实验中,于600用户生食谱中注释6,675种成分,明法至93.3 F1分数也。', 'ru': 'В последнее время количество пользовательских рецептов в Интернете увеличилось. В таких рецептах, как правило, предполагается, что пользователи должны написать название, список ингредиентов и шаги, чтобы создать блюдо. Тем не менее, некоторые элементы в списке ингредиентов в пользовательском рецепте на самом деле не съедобные ингредиенты. Например, заголовки, комментарии и кухонная утварь иногда появляются в списке ингредиентов, потому что пользователи могут свободно писать список в своих рецептах. Такой шум затрудняет использование компьютерами рецептов для различных задач, таких как оценка калорий. Для решения этой проблемы мы предлагаем неингредиентный метод обнаружения, вдохновленный моделью маркировки нейронной последовательности. В нашем эксперименте мы аннотировали 6675 ингредиентов в 600 пользовательских рецептах и показали, что предлагаемый нами метод достиг 93,3 балла F1.', 'ga': 'Le déanaí, tá méadú tagtha ar líon na n-oidis a ghineann úsáideoirí ar an Idirlíon. In oidis den sórt sin, is gnách go mbíonn úsáideoirí ceaptha teideal, liosta comhábhair agus céimeanna a ghlacadh chun mias a chruthú. Mar sin féin, ní comhábhair inite iarbhír iad roinnt míreanna ar liosta comhábhar in oideas arna ghiniúint ag an úsáideoir. Mar shampla, uaireanta feictear ceannteidil, tráchtanna agus earraí cistine ar liosta comhábhar toisc gur féidir le húsáideoirí an liosta a scríobh go saor ina gcuid oidis. Déanann torann den sórt sin deacair do ríomhairí oidis a úsáid le haghaidh tascanna éagsúla, mar mheastachán calraí. Chun aghaidh a thabhairt ar an tsaincheist seo, molaimid modh braite neamh-chomhábhar spreagtha ag múnla clibeála seicheamh néaraigh. Inár dturgnamh, rinneamar anótáil ar 6,675 comhábhar i 600 oideas a ghin an t-úsáideoir agus thaispeáin muid gur bhain ár modh molta scór 93.3 F1.', 'el': 'Πρόσφατα, ο αριθμός των συνταγών που δημιουργούνται από τους χρήστες στο Διαδίκτυο έχει αυξηθεί. Σε τέτοιες συνταγές, οι χρήστες γενικά υποτίθεται ότι γράφουν έναν τίτλο, μια λίστα συστατικών και βήματα για να δημιουργήσουν ένα πιάτο. Ωστόσο, ορισμένα στοιχεία σε μια λίστα συστατικών σε μια συνταγή που δημιουργείται από τον χρήστη δεν είναι πραγματικά βρώσιμα συστατικά. Για παράδειγμα, οι επικεφαλίδες, τα σχόλια και τα μαγειρικά σκεύη εμφανίζονται μερικές φορές σε μια λίστα συστατικών επειδή οι χρήστες μπορούν να γράψουν ελεύθερα τη λίστα στις συνταγές τους. Αυτός ο θόρυβος καθιστά δύσκολο για τους υπολογιστές να χρησιμοποιούν συνταγές για μια ποικιλία εργασιών, όπως η εκτίμηση θερμίδων. Για να αντιμετωπιστεί αυτό το ζήτημα, προτείνουμε μια μέθοδο ανίχνευσης χωρίς συστατικά εμπνευσμένη από ένα μοντέλο σήμανσης νευρωνικής ακολουθίας. Στο πείραμά μας σχολιάσαμε 6.675 συστατικά σε 600 συνταγές που δημιουργούνται από τον χρήστη και δείξαμε ότι η προτεινόμενη μέθοδος πέτυχε βαθμολογία 93.3.', 'hu': 'Az utóbbi időben nőtt a felhasználók által létrehozott receptek száma az interneten. Az ilyen receptekben a felhasználóknak általában címet, összetevőlistát és lépéseket kell írniuk az étel létrehozásához. Azonban a felhasználó által létrehozott recept összetevőinek listáján szereplő néhány elem valójában nem ehető összetevők. Például a címek, megjegyzések és konyhai eszközök néha megjelennek az összetevők listáján, mivel a felhasználók szabadon írhatják a listát receptjeikben. Az ilyen zaj megnehezíti a számítógépek számára, hogy recepteket használjanak különböző feladatokhoz, például kalóriabecsléshez. A probléma megoldására egy nem összetevő detektálási módszert javasolunk, amelyet egy neurális szekvencia címkézési modell ihletett. Kísérletünkben 600 felhasználó által generált receptben 6 675 összetevőt jegyeztünk fel, és bebizonyítottuk, hogy javasolt módszerünk 93,3 F1 pontszámot ért el.', 'ka': 'მიმდინარე, ინტერნეტში მომხმარებლის შექმნილი რერესტის რაოდენობა უფრო მეტია. ასეთი რესპეტებში, მომხმარებელი უნდა დაწეროთ სათაური, ინგრედიენტების სია და სტატის შექმნა. მაგრამ სხვა ელემენტები ინგრედიენტების სია მომხმარებლის შექმნილი რერესიტებში არ არის ფაქტიურად საჭირო ინგრედიენტები. მაგალითად, შესახებ, კომენტრები და საქაღალდეები ზოგჯერ ინგრედიენტების სია ჩვენებენ, რადგან მომხმარები თავისუფალურად შეუძლიათ თავისუფალურად მი რაღაც კომპიუტერების გამოყენება განსხვავებული საქმედებისთვის, როგორც კალორიის განსაზღვრება. ამ პრობლემას გადაწყვეტისთვის, ჩვენ მინდომებით ნეიროლური წერტილის მოდელის გადაწყვეტილი არა ინგრედიენტის განახლების მეტი. ჩვენი ექსპერიმენტებში, ჩვენ აღწერეთ 6 675 ინგრედიენტები 600 მომხმარებელი რესპერიტებში და ჩვენი პროგრამა მივიღეთ 93.3 F1 წერტილი.', 'lt': 'Recently, the number of user-generated recipes on the Internet has increased.  Tokiuose receptuose naudotojai paprastai turi rašyti pavadinimą, sudedamųjų dalių sąrašą ir žingsnius, kaip sukurti plokštelę. Tačiau kai kurie ingredient ų sąrašo dalys, įtraukti į naudotojo gautą receptą, iš tikrųjų nėra valgomosios ingredientai. Pavyzdžiui, antraštės, komentarai ir virtuvės reikmenys kartais pateikiami ingredient ų sąraše, nes vartotojai gali laisvai rašyti sąrašą savo receptuose. Dėl tokio triukšmo kompiuteriams sunku naudoti receptus įvairioms užduotims, pvz., kalorijų vertinimui. Siekiant išspręsti šį klausimą, siūlome ne sudedamųjų dalių aptikimo metodą, pagrįstą neurologinės sekos žymėjimo modeliu. Mūsų eksperimente užrašėme 6 675 sudedamųjų dalių į 600 naudotojų sukurtų receptų ir parodėme, kad mūsų siūlomas metodas pasiekė 93,3 F1 balas.', 'it': "Recentemente, il numero di ricette generate dagli utenti su Internet è aumentato. In tali ricette, gli utenti sono generalmente tenuti a scrivere un titolo, una lista di ingredienti e passaggi per creare un piatto. Tuttavia, alcuni elementi in una lista di ingredienti in una ricetta generata dall'utente non sono in realtà ingredienti commestibili. Ad esempio, titoli, commenti e utensili da cucina a volte appaiono in una lista di ingredienti perché gli utenti possono scrivere liberamente l'elenco nelle loro ricette. Tale rumore rende difficile per i computer utilizzare ricette per una varietà di attività, come la stima delle calorie. Per affrontare questo problema, proponiamo un metodo di rilevamento non-ingrediente ispirato da un modello di marcatura della sequenza neurale. Nel nostro esperimento, abbiamo annotato 6.675 ingredienti in 600 ricette generate dagli utenti e abbiamo dimostrato che il nostro metodo proposto ha ottenuto un punteggio F1 93,3.", 'mk': 'Неодамна бројот на рецепти генерирани од корисниците на интернетот се зголеми. Во ваквите рецепти, корисниците генерално треба да пишуваат наслов, листа на состојки и чекори за создавање чинија. Сепак, некои предмети на листата на состојки во рецептот генериран од корисникот всушност не се јадни состојки. На пример, насловите, коментарите и кујнската роба понекогаш се појавуваат во листата на состојки бидејќи корисниците слободно можат да ја напишат листата во нивните рецепти. Таква бучава им овозможува на компјутерите да користат рецепти за различни задачи, како што е проценката на калориите. За да го решиме ова прашање, предлагаме метод за детекција на несостојки инспириран од модел за означување на нервната секвенца. Во нашиот експеримент, анотиравме 6.675 состојки во 600 рецепти генерирани од корисниците и покажавме дека нашиот предложен метод постигна 93,3 Ф1 оценка.', 'kk': 'Жуырда Интернеттегі пайдаланушылар жасалған рецептер саны көтерді. Бұл рецептерде пайдаланушылар кәдімгі үшін айдар, ingrediенттер тізімі және қос құру үшін қадамдар жазылады. Бірақ пайдаланушының құрылған рецептерінің бірнеше элементтері өзгертуге болмайды. Мысалы, айдарлар, түсініктемелер және көбінесе материалдар тізімінде көрсетіледі, себебі пайдаланушылар тізімін рецептерінде еркін жазуға болады. Бұл дыбыс компьютерге түрлі тапсырмаларды, мысалы, калория бағалау үшін, түрлі тапсырмаларды қолдану қиын болады. Бұл мәселеге шешу үшін біз ингредиентті емес анықтау әдісін негізгі реттеу үлгісі бойынша ұсындық. Сіздің тәжірибемізде 600 пайдаланушының құрылған рецептерінде 6 675 ингредиенттерді жазып, бұл әдіміздің 93,3 F1 нөмірі жеткізгенін көрсеттік.', 'mt': 'Dan l-aħħar, in-numru ta’ riċetti ġġenerati mill-utenti fuq l-Internet żdied. F’riċetti bħal dawn, l-utenti ġeneralment għandhom jiktbu titolu, list a ta’ ingredjenti, u passi biex joħolqu platt. Madankollu, xi oġġetti f’list a ta’ ingredjenti f’riċetta ġġenerata mill-utent mhumiex fil-fatt ingredjenti li jittieklu. For example, headings, comments, and kitchenware sometimes appear in an ingredient list because users can freely write the list in their recipes.  Tali storbju jagħmilha diffiċli għall-kompjuters li jużaw riċetti għal varjetà ta’ kompiti, bħall-istima tal-kaloriji. Biex nindirizzaw din il-kwistjoni, nipproponu metodu ta’ detezzjoni ta’ mhux ingredjenti ispirat minn mudell ta’ tikkettar tas-sekwenza newrali. In our experiment, we annotated 6,675 ingredients in 600 user-generated recipes and showed that our proposed method achieved a 93.3 F1 score.', 'ms': 'Baru-baru ini, bilangan resep yang dijana oleh pengguna di Internet telah meningkat. Dalam resep tersebut, pengguna biasanya sepatutnya menulis tajuk, senarai bahan, dan langkah untuk mencipta piring. Namun, beberapa item dalam senarai bahan dalam resep yang dijana oleh pengguna bukanlah bahan yang boleh dimakan. Contohnya, tajuk, komen, dan peralatan dapur kadang-kadang muncul dalam senarai bahan sebab pengguna boleh tulis senarai secara bebas dalam resep mereka. Bunyi seperti ini membuat ia sukar bagi komputer untuk menggunakan resep untuk berbagai tugas, seperti penghargaan kalori. Untuk mengatasi isu ini, kami cadangkan kaedah pengesan bukan-bahan yang diinspirasi oleh model tag urutan saraf. Dalam eksperimen kami, kami mencatat 6,675 bahan dalam 600 resep yang dihasilkan oleh pengguna dan menunjukkan bahawa kaedah kami diusulkan mencapai skor 93.3 F1.', 'ml': 'അടുത്തിടെ ഇന്റര്\u200dനെറ്റില്\u200d ഉപയോക്താവിന്റെ സൃഷ്ടിക്കപ്പെട്ട റിസിപ്പികളുടെ എണ്ണം വളര്\u200dന്നു. ഇങ്ങനെയുള്ള റിസ്പിപ്പികളില്\u200d, ഉപയോക്താക്കള്\u200d ഒരു തലക്കെട്ട്, ഒരു ഉള്ളിലുള്ള പട്ടിക എഴുതാനും, ഒരു ഡിസ്ക് ഉണ്ടാക്ക എന്നാലും ഉപയോക്താവ് സൃഷ്ടിച്ചുണ്ടാക്കുന്ന രെസിപ്പില്\u200d ചില വസ്തുക്കള്\u200d യഥാര്\u200dത്ഥത്തില്\u200d സാധ്യമല്ല. ഉദാഹരണത്തിനായി, തലക്കെട്ടുകള്\u200d, കുറിപ്പുകള്\u200d, ചിലപ്പോഴെങ്കിലും ഒരു ഉള്ളിലുള്ള പട്ടികയില്\u200d പ്രത്യക്ഷപ്പെടുന്നു. കാരണം  ഇതുപോലുള്ള ശബ്ദം കമ്പ്യൂട്ടര്\u200dക്ക് വിവിധ ജോലികള്\u200dക്ക് റിസ്പിപ്പുകള്\u200d ഉപയോഗിക്കാന്\u200d ബുദ്ധിമുട്ടുണ്ടാക് ഈ പ്രശ്നത്തെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d, ന്യൂറല്\u200d സെക്കന്\u200dസ് ടാഗിങ്ങ് മോഡല്\u200d നിര്\u200dദ്ദേശിക്കുന്ന ഒരു പ്രാധ നമ്മുടെ പരീക്ഷണത്തില്\u200d, 600 ഉപയോക്താവ് ഉല്\u200dപാദിപ്പിക്കപ്പെട്ട റെസിപ്പികളില്\u200d 6,675 ഉള്ള ബാധ്യതകള്\u200d ഞങ്ങള്\u200d ശ്രദ്ധിച്ചു ഞങ്ങളുടെ പ്രോ', 'no': 'Nyleg har talet på brukargrensespar på Internett auka. I slike oppskrifter skal brukarar vanlegvis skriva ein tittel, ei ingrediensliste og steg for å laga ein plate. Men nokre element i ei ingrediensliste i ei brukargrensesnitt er ikkje faktisk edibele ingredienser. For eksempel, overskrifter, kommentarar og køyrenvare viser noen gong i ei ingrediensliste fordi brukarar kan skriva lista frå sin oppskrifter. Somme støy gjer det vanskeleg for datamaskiner å bruka oppskrifter for mange oppgåver, som kaloriestingar. For å handtera dette problemet, foreslår vi ein metode for å oppdaga ikkje- ingrediensmetode inspirert av eit neuralsekvensmerkingsmodul. I eksperimentet vårt oppmerket vi 6,675 ingredientar i 600 brukargrensespar og viste at vårt foreslått metode har oppnådd ei 93,3 F1-poeng.', 'pl': 'Ostatnio wzrosła liczba przepisów generowanych przez użytkowników w Internecie. W takich przepisach użytkownicy powinni zazwyczaj napisać tytuł, listę składników i kroki do stworzenia dania. Jednakże niektóre elementy na liście składników w recepturze generowanej przez użytkownika nie są w rzeczywistości jadalnymi składnikami. Na przykład nagłówki, komentarze i przybory kuchenne pojawiają się czasami na liście składników, ponieważ użytkownicy mogą swobodnie pisać listę w swoich przepisach. Taki hałas utrudnia komputerom korzystanie z receptur na różne zadania, takie jak oszacowanie kalorii. Aby rozwiązać ten problem, proponujemy metodę wykrywania nieskładników inspirowaną modelem tagowania sekwencji neuronowej. W naszym eksperymencie zapisaliśmy składniki 6.675 w 600-generowanych przez użytkownika recepturach i wykazaliśmy, że nasza proponowana metoda osiągnęła wynik 93.3 F1.', 'ro': 'Recent, numărul de rețete generate de utilizatori pe Internet a crescut. În astfel de rețete, utilizatorii ar trebui, în general, să scrie un titlu, o listă de ingrediente și pași pentru a crea un fel de mâncare. Cu toate acestea, unele elemente dintr-o listă de ingrediente dintr-o rețetă generată de utilizator nu sunt de fapt ingrediente comestibile. De exemplu, titlurile, comentariile și articolele de bucătărie apar uneori într-o listă de ingrediente deoarece utilizatorii pot scrie în mod liber lista în rețetele lor. Un astfel de zgomot face dificil pentru calculatoare să utilizeze rețete pentru o varietate de sarcini, cum ar fi estimarea caloriilor. Pentru a aborda această problemă, propunem o metodă de detectare non-ingredient inspirată de un model de etichetare a secvențelor neurale. În experimentul nostru, am adnotat 6.675 ingrediente în 600 de rețete generate de utilizatori și am arătat că metoda propusă a obținut un scor F1 de 93,3.', 'mn': 'Саяхан Интернет хэрэглэгчийн үүсгэсэн рецептүүдийн тоо нэмэгдсэн. Ийм төлөвлөгөөнд хэрэглэгчид ихэвчлэн нэр, бүтээгдэхүүний жагсаалт, хоол бий болгохын тулд алхам бичих ёстой. Гэхдээ хэрэглэгчид үүсгэсэн рецептийн зарим бүтээгдэхүүнүүд үнэндээ идэж чадахгүй зүйл биш. Жишээлбэл, толгой, сэтгэл зүйл, гал хөдөлгүүр заримдаа бүтээгдэхүүний жагсаалт гарч ирдэг. Учир нь хэрэглэгчид тэдний төлөвлөгөөнд жагсаалт чөлөөтэй бичиж чадна. Ийм чимээ компьютерийн хувьд олон даалгаварын төлөвлөгөөг ашиглах нь хэцүү болгодог. Энэ асуудлыг асуухын тулд бид мэдрэлийн дарааллын тагжуулах загвараас урам зориулсан эдийн загвар биш материалуудыг олох арга зааж өгдөг. Бидний туршилтанд 600 хэрэглэгчийн төлөвлөгөөнд 6.675 бүтээгдэхүүнийг анзаарсан. Бидний санал өгсөн арга нь 93.3 F1 оноо гарч ирсэн.', 'sr': 'Nedavno se povećao broj recepta od korisnika na internetu. U takvim receptima, korisnici obično trebaju napisati titulu, listu sastojaka i korake za stvaranje jela. Međutim, neki predmeti u listi sastojaka u receptima koji su stvorili korisnike nisu u stvari pojedinljivi sastojaci. Na primer, naslovi, komentari i kuhinjski materijal ponekad se pojavljuju na listi sastojaka jer korisnici mogu slobodno pisati listu u svojim receptima. Takva buka čini teškom da kompjuteri koriste recept za razne zadatke, poput procjene kalorija. Da bi se riješili ovom pitanju, predlažemo metodu detekcije bez sastojaka inspirisanu modelom označavanja neuralne sekvence. U našem eksperimentu, notarali smo 6.675 sastojaka u 600 recepta od korisnika i pokazali da je naš predloženi metod postigao 93.3 F1 rezultat.', 'si': 'අවසානයෙන්, අන්තර්ජාලයේ ප්\u200dරවේශකයෙන් නිර්මාණය කරපු ප්\u200dරවේශකය සංඛ්යා වැඩියි. අනිවාර්ය ප්\u200dරවේශකයෙන්, පාවිච්චිකරුවන් සාමාන්\u200dය විශ්වාස කරන්නේ නියෝජනයක්, ප්\u200dරවේශකය ලැයිස්ත නමුත්, ප්\u200dරයෝජකයෙන් නිර්මාණය කරපු ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප්\u200dරයෝජකයෙන් ප උදාහරණයෙන්, පිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිප මෙච්චර ශබ්දයක් පරිගණකරුවරුවට විවිධ වැඩක් සඳහා විවිධ වැඩක් භාවිත කරන්න අමාරුයි, හරියට කැලෝරි අ මේ ප්\u200dරශ්නය විදිහට, අපි ප්\u200dරශ්නයක් නොවිශ්වාසිය හොයාගන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරනවා නිර්මාණ ක අපේ පරීක්ෂණයේදී, අපි ප්\u200dරයෝජනයේ ප්\u200dරයෝජනය 600ක් ප්\u200dරයෝජනය කරපු 6,675 අවශ්\u200dය භාවිතාවක් ප්\u200dරයෝජනය කරලා පෙන්වන්න', 'so': 'Intii ugu dhowayd shabakada internetka waxaa kordhay tirada isticmaalayaasha. Sida caadiga ah isticmaalayaasha waxaa habboon in ay qoraan magac, liiska wax ku jira iyo tallaabooyin lagu sameeyo khamiis. However, some items in an ingredient list in a user-generated recipe are not actually edible ingredients.  Tusaale ahaan warqadaha, commentarada iyo qashinka qaarkood waxaa laga muuqdaa liiska wax ku qoran, sababtoo ah isticmaalayaashu waxay si xor ah ugu qori karaan liiska. Dhawaaqa caynkaas ayaa ku adag in kambiyuutarku isticmaalo isticmaalka shaqooyin kala duduwan, tusaale ahaan qiimeynta kalori. Si aan u qabsado arinkan, waxaynu soo jeedinnaa qaab aan wax ku filnayn oo lagu soo bandhigayo tusaale baaxada neurada. Imtixaankeena ayaannu ku dhibaataysiinnay 6,675 qalabka oo 600 oo isticmaalayaal ah, waxaana tusnay in qaabkeenkeennu uu soo jeeday ay ay gaadhay koox 93,3 F1.', 'sv': 'På senare tid har antalet användargenererade recept på Internet ökat. I sådana recept ska användare vanligtvis skriva en titel, en ingredienslista och steg för att skapa en maträtt. Men vissa objekt i en ingredienslista i ett användargenererat recept är faktiskt inte ätbara ingredienser. Till exempel visas rubriker, kommentarer och köksartiklar ibland i en ingredienslista eftersom användarna fritt kan skriva listan i sina recept. Sådant buller gör det svårt för datorer att använda recept för en mängd olika uppgifter, såsom kaloriberäkning. För att lösa detta problem föreslår vi en detektionsmetod som inte innehåller ingredienser inspirerad av en modell för märkning av neurala sekvenser. I vårt experiment kommenterade vi 6 675 ingredienser i 600 användargenererade recept och visade att vår föreslagna metod uppnådde 93,3 F1 poäng.', 'ta': 'சமீபத்தில், இணையத்தில் பயனர் உருவாக்கப்பட்ட செய்திகளின் எண்ணிக்கையை அதிகரித்துவிட்டது. இத்தகைய செய்திகளில், பயனர் பொதுவாக ஒரு தலைப்பு, ஒரு உள்ளடக்க பட்டியல் எழுத வேண்டும், மற்றும் ஒரு நீளை உருவாக்க படியில் படி ஆயினும், ஒரு பயனர் உருவாக்கப்பட்ட சில பொருட்களின் பட்டியலில் உள்ள உருப்படிகள் உண்மையில் பொருள்களை பொருளாக்குவதி உதாரணத்திற்காக, தலைப்புகள், குறிப்புரைகள், மற்றும் சில நேரங்களில் குறிப்பிடும் பட்டியலில் தெரியும். ஏனென்றால் பயனர Such noise makes it difficult for computers to use recipes for a variety of tasks, such as calorie estimation.  இந்த பிரச்சனையை முடிக்க, நாம் ஒரு புதிய தொடர் ஒட்டு மாதிரியால் தேர்ந்தெடுக்கப்படாத கண்டறிதல் முறைமை எங்கள் சோதனையில், 600 பயனர் உருவாக்கப்பட்ட பொருள்களில் 6,675 பொருள்களை குறிப்பிட்டோம் மற்றும் நம் பரிந்துரைய முறைமையில் 93.3 F1 புள', 'ur': 'اچھے سے، انٹرنیٹ میں کارساز پیدا کیے گئے ریسٹوں کی تعداد بڑھی گئی ہے۔ اس طرح کے رسیدوں میں، کارساز کو معمولاً ایک تایٹل، ایک موجود لکھ لیتے ہیں، اور غذا پیدا کرنے کے لئے قدم لیتے ہیں. لیکن یوسٹر کے پیدا ہوئے ریسپیٹ میں ایک انگریڈینٹ لکھ میں کچھ اثرات حقیقت میں کھانے کے قابل نہیں ہیں. مثال کے طور پر، ہڈینگ، توضیح، اور کیچونویر کبھی کئی موقع ایک انگلیسٹ لکھ میں ظاہر ہوتے ہیں کیونکہ کارساز اپنے رسیٹوں میں لکھ سکتے ہیں۔ یہ آواز کمپیوٹروں کے لئے مختلف کاموں کے لئے رسیدوں کا استعمال کرنا مشکل کر دیتا ہے، جیسے کالوری کا ارزش. اس مسئلہ کے بارے میں ہم نے ایک غیر انگلیڈینٹ ڈیٹینٹ ڈیٹینٹ طریقہ کی پیشنهاد کرتا ہے جو ایک نئورل سطح ٹیگ ڈیگ موڈل کے ذریعے الهام کی جاتی ہے۔ ہمارے آزمائش میں، ہم نے 600 کارساز کے پیدا کئے ہوئے رسپیٹوں میں 6.675 انگلیٹوں کو اظہار کیا اور دکھایا کہ ہماری پیشنهاد کی طریقہ 93.3 F1 اسکو پہنچ گیا۔', 'uz': "Yaqinda, Internetdagi foydalanuvchi yaratilgan qabul qiluvchilar soni ko'prodi. @ info Lekin, foydalanuvchi quyidagi qismlar roʻyxatidagi bir necha elementlar Masalan, sarlavha, izohlar, va kitoblarda iborat roʻyxatida koʻrinadi, chunki foydalanuvchilar roʻyxatni xohlash mumkin. Bu yerda tovush kompyuterga qayta vazifalarni ishlatishga qiyin beradi, balki kalori qiymatlari kabi. Bu muammani boshqarish uchun biz neyrolik seksiz yordamida murojaat qiluvchi qidirish usulini talab qilamiz. Biz tajribamizda 600 foydalanuvchi quyidagi 6,675 ingrediyatlarni taqdim qildik va bizning talab qilingan usuli 93.3 F1 scorini topishga tushundik.", 'vi': 'Gần đây, số công thức trên Internet đã tăng lên. Trong những công thức như vậy, người dùng thường phải viết một tựa, một danh sách các thành phần, và những bước để tạo một cái đĩa. Tuy nhiên, một số thứ trong danh sách các thành phần trong công thức máy tạo ra người dùng không thực sự là thành phần ăn. Ví dụ, các đầu đề, bình luận và dụng cụ bếp đôi khi xuất hiện trong danh sách các thành phần bởi vì người dùng có thể tự do ghi danh sách vào công thức của họ. Âm thanh như vậy làm cho máy tính khó sử dụng công thức cho nhiều công việc khác nhau, như đánh giá calorie. Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp phát hiện không thành phần lấy cảm hứng từ một mô hình lập dây thần kinh. Trong thử nghiệm của chúng tôi, chúng tôi ghi chú nguyên liệu 6,675 trong mỗi lần đầu tiên 600 và cho thấy phương pháp yêu cầu đạt được ghi số 93.3 F1.', 'da': 'For nylig er antallet af brugergenererede opskrifter på internettet steget. I sådanne opskrifter er brugerne generelt formodet at skrive en titel, en ingrediensliste og trin til at oprette en ret. Men nogle elementer i en ingrediensliste i en brugergenereret opskrift er faktisk ikke spiselige ingredienser. For eksempel vises overskrifter, kommentarer og køkkenudstyr undertiden på en ingrediensliste, fordi brugerne frit kan skrive listen i deres opskrifter. En sådan støj gør det vanskeligt for computere at bruge opskrifter til en række opgaver, såsom kalorieberegning. For at løse dette problem foreslår vi en ikke-ingrediens detektionsmetode inspireret af en neural sekvens tagging model. I vores eksperiment noterede vi 6.675 ingredienser i 600 brugergenererede opskrifter og viste, at vores foreslåede metode opnåede en 93,3 F1 score.', 'bg': 'Напоследък броят на генерираните от потребителите рецепти в интернет се е увеличил. В такива рецепти потребителите обикновено трябва да напишат заглавие, списък със съставки и стъпки за създаване на ястие. Въпреки това, някои елементи в списъка на съставките в генерирана от потребителя рецепта не са всъщност хранителни съставки. Например заглавия, коментари и кухненски съдове и прибори понякога се появяват в списък със съставки, защото потребителите могат свободно да напишат списъка в своите рецепти. Такъв шум затруднява компютрите да използват рецепти за различни задачи, като например оценка на калориите. За да се справим с този проблем, предлагаме метод за откриване на несъществени съставки, вдъхновен от модел за маркиране на неврални последователности. В нашия експеримент анотирахме 6 675 съставки в 600 рецепти, генерирани от потребителите, и показахме, че предложеният ни метод постига 93,3 оценка.', 'hr': 'Nedavno se povećao broj recepta od korisnika na internetu. U takvim receptima, korisnici obično trebaju napisati titulu, listu sastojaka i korake za stvaranje jela. Međutim, neki predmeti u listi sastojaka iz recepta koji su proizvedeni korisnikom nisu u stvari pojedinljivi sastojaci. Na primjer, naslovi, komentari i kuhinjski materijal ponekad se pojavljuju u popisu sastojaka jer korisnici mogu slobodno pisati popis u svojim receptima. Takva buka čini kompjuterima teško koristiti recept za razne zadatke, poput procjene kalorija. Za rješavanje ovog pitanja predlažemo metodu otkrivanja bez sastojaka inspirisanu modelom označavanja neuralne sekvence. U našem eksperimentu, zabilježili smo 6 675 sastojaka u 600 recepta od korisnika i pokazali da je naš predloženi metod postigao 93,3 F1 rezultat.', 'nl': 'Onlangs is het aantal door gebruikers gegenereerde recepten op internet toegenomen. In dergelijke recepten worden gebruikers over het algemeen verondersteld een titel, een ingrediëntenlijst en stappen te schrijven om een gerecht te maken. Sommige items in een ingrediëntenlijst in een door de gebruiker gegenereerd recept zijn echter niet echt eetbare ingrediënten. Koppen, opmerkingen en keukengerei worden bijvoorbeeld soms weergegeven in een ingrediëntenlijst omdat gebruikers de lijst vrij in hun recepten kunnen schrijven. Dergelijke ruis maakt het moeilijk voor computers om recepten te gebruiken voor een verscheidenheid aan taken, zoals calorieschatting. Om dit probleem aan te pakken, stellen we een niet-ingrediënt detectiemethode voor, geïnspireerd op een neurale sequentie tagging model. In ons experiment hebben we 6.675 ingrediënten geannoteerd in 600 door gebruikers gegenereerde recepten en aangetoond dat onze voorgestelde methode een 93.3 F1 score behaalde.', 'de': 'In letzter Zeit ist die Anzahl der nutzergenerierten Rezepte im Internet gestiegen. In solchen Rezepten sollen Benutzer normalerweise einen Titel, eine Zutatenliste und Schritte schreiben, um ein Gericht zu erstellen. Einige Elemente in einer Zutatenliste in einem benutzergenerierten Rezept sind jedoch nicht wirklich essbare Zutaten. Beispielsweise erscheinen Überschriften, Kommentare und Küchenutensilien manchmal in einer Zutatenliste, weil Benutzer die Liste frei in ihren Rezepten schreiben können. Solche Geräusche machen es für Computer schwierig, Rezepte für eine Vielzahl von Aufgaben zu verwenden, wie z.B. Kalorienschätzung. Um dieses Problem anzugehen, schlagen wir eine Methode vor, die sich nicht auf Inhaltsstoffe bezieht, die von einem neuronalen Sequenz-Tagging-Modell inspiriert ist. In unserem Experiment haben wir 6.675 Zutaten in 600-benutzergenerierten Rezepten kommentiert und gezeigt, dass unsere vorgeschlagene Methode einen 93.3 F1 Score erreicht.', 'id': 'Baru-baru ini, jumlah resep yang dihasilkan oleh pengguna di Internet telah meningkat. Dalam resep seperti itu, pengguna biasanya seharusnya menulis judul, daftar bahan, dan langkah untuk membuat piring. Namun, beberapa item dalam daftar bahan dalam resep yang dibuat oleh pengguna sebenarnya bukan bahan yang dapat dimakan. Contohnya, tajuk, komentar, dan peralatan dapur kadang-kadang muncul dalam daftar bahan karena pengguna bisa menulis daftar secara bebas dalam resep mereka. Suara seperti itu membuat komputer sulit menggunakan resep untuk berbagai tugas, seperti perhitungan kalori. Untuk mengatasi masalah ini, kami mengusulkan metode deteksi bukan bahan yang diinspirasi oleh model label urutan saraf. Dalam eksperimen kami, kami menganoterasi 6.675 bahan dalam 600 resep yang dihasilkan oleh pengguna dan menunjukkan bahwa metode kami diusulkan mencapai skor 93.3 F1.', 'fa': 'اخیراً تعداد دستورات تولید شده از کاربر روی اینترنت افزایش یافت. در چنین دستورات، کاربران معمولاً باید یک عنوان، یک لیست مواد و قدم برای ایجاد یک غذا بنویسند. ولی بعضی از عنصرها در فهرست عنصر تولید شده از طریق کاربر در واقع عنصر غذایی قابل خوردن نیستند. برای مثال، عنوان، توضیح\u200cها و آشپزخانه\u200cها گاهی در فهرست مواد ظاهر می\u200cشوند، زیرا کاربران می\u200cتوانند لیست را آزاد در درخواست\u200cهایشان بنویسند. این صدا برای کامپیوترها سخت می\u200cکند که برای کارهای مختلف، مثل ارزیابی کالوری استفاده کنند. برای حل این مسئله، ما یک روش شناسایی غیر عنصر را پیشنهاد می کنیم که توسط یک مدل نقاشی نقاشی الهام می دهد. در آزمایشمون، ما 6.675 عنصر را در شش.۶۰۰ دستورات تولید شده از کاربر نشان دادیم و نشان دادیم که روش پیشنهاد ما به یک امتیاز 93.3 اف 1 رسید.', 'tr': 'Soňky wagtlar internede janlaşdyrylan taripler kop köpeldi. Şol ýagdaýda ullançylar adatça bir surat, gatnaç listi we çörek bejermek üçin adımlar ýazmaly. Ýöne, Ullançylar tarapyndan gaýd edilen hatlarda birnäçe elementler aslynda iýjek bolmaz. mysal, başlyklar, terjimeler we aşhanalar käwagt milletler listinde görünýär, sebäbi ullançylar öz recipelerinde boş ýazyp bilerler. Bärde goh kompýuterler üçin birnäçe iş üçin hatlary ulanmak kynlaşdyrýar, ýöne kaloriýa hasaplamak ýaly. Bu meseleyi çözmek üçin, näral terjime etiketleme modeli tarapyndan esinlenen iň saýlamak ahtaryjyny teklip edýäris. Denememizde 600 qullanıcı üretilen receplerde 6.675 sany möhüm hasaplandyrdyk we teklip eden metodumyzyň 93.3 F1 sany gazandygyny görkezildi.', 'sw': 'Hivi karibuni, idadi ya watumiaji waliozaliwa mtandaoni imeongezeka. Katika vifaa hivyo, watumiaji wanapaswa kuandika jina, orodha ya vifaa, na hatua za kutengeneza chakula. Hata hivyo, baadhi ya vitu katika orodha ya viungo katika kipindi kilichotengenezwa kwa mtumiaji si vifaa vinavyoendelea. Kwa mfano, vichwa, maoni, na vyakula vya jikoni mara nyingine vinaonekana kwenye orodha ya viungo kwa sababu watumiaji wanaweza kuandika orodha hiyo kwa uhuru katika vipokezi vyao. Sauti kama hizi inafanya vigumu kwa kompyuta kutumia recipient kwa kazi mbalimbali, kama vile estimation ya kalori. Kupambana na suala hili, tunapendekeza njia ya uchunguzi isiyo na vifaa vinavyohamasishwa na modeli ya michezo ya ubongo. Katika majaribio yetu, tuliwasilisha vifaa 6,675 katika vifaa vya watumiaji 600 vilivyozaliwa na kuonyesha kwamba njia yetu ya pendekezo ilifanikiwa score 93.3 F1.', 'af': "Onlangs het die aantal gebruiker genereerde resepte op die Internet vergroot. In sodanige recepte word gebruikers algemeen veronderstel om 'n titel,  'n ingredienslys te skryf en stappe om 'n skoot te skep. Maar sommige items in 'n ingredienslys in' n gebruiker genereerde recepte is nie eintlik edierbare ingredienste nie. Byvoorbeeld, koppe, kommentaar en kommentaar verskyn soms in 'n ingredienslys omdat gebruikers die lys in hul resepte vry kan skryf. Soos geluid maak dit moeilik vir rekenaars om recepte te gebruik vir 'n verskillende taak, soos kalorie estimatie. Om hierdie probleem te adres, voorstel ons 'n non- ingredient-deteksie metode wat inspireer word deur 'n neural sekvensie merking model. In ons eksperiment het ons 6.675 ingredients in 600 gebruiker genereerde recepte aangetel en wys dat ons voorgestelde metode 'n 93.3 F1 punt bereik het.", 'ko': '최근 인터넷상에서 사용자가 생성한 식단 수가 증가했다.이런 식단에서 사용자는 보통 제목, 조미료, 요리를 만드는 절차를 써야 한다.그러나 사용자가 생성한 레시피에서 조미료 목록의 일부 항목은 사실상 먹을 수 있는 조미료가 아니다.예를 들어 제목, 평론, 주방 도구는 때때로 조미료 목록에 나타난다. 왜냐하면 사용자는 그들의 식단에 자유롭게 목록을 작성할 수 있기 때문이다.이런 소음 때문에 컴퓨터는 열량 추산과 같은 각종 임무에 식단을 사용하기 어렵다.이 문제를 해결하기 위해 우리는 신경 서열 표기 모델을 바탕으로 하는 비성분 검출 방법을 제시했다.우리의 실험에서 600명의 사용자가 생성한 식단에 6675가지 성분을 주석한 결과 우리가 제시한 방법은 93.3의 F1 점수를 얻었다.', 'sq': 'Recently, the number of user-generated recipes on the Internet has increased. Në receta të tilla, përdoruesit përgjithësisht supozohen të shkruajnë një titull, një list ë përbërëse dhe hapa për të krijuar një pjatë. Megjithatë, disa elementë në një list ë përbërëse në një recetë të gjeneruar nga përdoruesit nuk janë në fakt përbërëse të ushqyeshme. Për shembull, titujt, komentet dhe pajisjet e kuzhinës ndonjëherë shfaqen në një list ë përbërëse sepse përdoruesit mund të shkruajnë lirisht listën në recetat e tyre. Such noise makes it difficult for computers to use recipes for a variety of tasks, such as calorie estimation.  Për të trajtuar këtë çështje, ne propozojmë një metodë zbulimi jo-përbërëse të frymëzuar nga një model i shënimit të sekuencës nervore. Në eksperimentin tonë, ne anotuam 6,675 përbërës në 600 receta të gjeneruara nga përdoruesit dhe treguam se metoda jonë e propozuar arriti një rezultat 93.3 F1.', 'am': 'በአሁኑ ጊዜ የተፈጠረ ተጠቃሚዎች ቁጥር በInternet ን ላይ ይጨመር ነበር፡፡ በዚህ ደቂቃዎች ውስጥ በተጠቃሚ ተጠቃሚዎች የጽሑፍ አርእስት፣ የጨዋታ ዝርዝር እና ጥሩ ለመፍጠር ደረጃዎች መጻፍ ይገባቸዋል፡፡ ምንም እንኳን፣ በተጠቃሚ አቀማመጥ ሰርቨር ውስጥ አንዳንዶች አካባቢዎች መቀናቀል አይደሉም፡፡ ለምሳሌ፣ አቀማመጥ፣ አስተያየት እና ቁጥጥር አንዳንድ ጊዜ በተጨማሪው ዝርዝር ይታያል፣ ምክንያቱም ተጠቃሚዎች ዝርዝሩን በፈቃዱ ይጽፉ ዘንድ ይችላሉ፡፡ Such noise makes it difficult for computers to use recipes for a variety of tasks, such as calorie estimation.  ወደዚህ ጉዳይ ለመቀበል፣ የናውሮል የግንኙነት መግለጫ ማቀናቀል ሞዴል ተማርኮታል፡፡ በተፈተናችን ውስጥ 6,675 የሆኑት ጉዳዮች በ600 ተጠቃሚዎች የተፈጠሩ ደቂቃዎች እና ልማችን 93.3 F1 score እንዳገኘን አሳየን፡፡', 'hy': 'Վերջերս օգտագործողների ստեղծված բաղադրատոմսերի թիվը ինտերնետում աճեց: Այսպիսի բաղադրատոմսերում օգտագործողները սովորաբար պետք է գրեն անվանություն, բաղադրատոմսերի ցուցակ և ուտեստի ստեղծման քայլեր: Այնուամենայնիվ, օգտագործողի կողմից ստեղծված բաղադրամասերի ցուցակի որոշ առարկաներ իրականում ուտելիք բաղադրամասեր չեն: Օրինակ, գլխարկներ, մեկնաբանություններ և խոհանոցական սարքավորումներ երբեմն հայտնվում են բաղադրամասերի ցուցակում, քանի որ օգտագործողները ազատ են կարողանում գրել իրենց բաղադրատոմներում ցուցակը: Այս աղմուկը դժվարանում է համակարգիչների համար բաղադրատոմսեր օգտագործել բազմաթիվ առաջադրանքների համար, ինչպիսիք են կալորիայի գնահատումը: Այս խնդիրը լուծելու համար մենք առաջարկում ենք ոչ բաղադրիչների հայտնաբերման մեթոդ, որը ոգեշնչվում է նյարդային հաջորդականության նշանների մոդելի միջոցով: Մեր փորձարկում մենք նկարագրեցինք 6.675 բաղադրամաս 600 օգտագործողի կողմից ստեղծված բաղադրամասերում և ցույց տվեցինք, որ մեր առաջարկած մեթոդը հասավ 93.3 F1 գնահատականի:', 'az': 'İnternettə istifadəçi təhsil edilmiş receptlərin sayı artırıldı. Bütün məlumatlarda, istifadəçilər genellikle başlıq, məlumat listesi və yemək yaratmaq üçün adımlar yazmaq lazımdır. Lakin, istifadəçilərin yaratdığı receptenin bəzi məlumatları əslində yeyə bilən məlumatlar deyildir. Misal olaraq, başlıqlar, məlumatlar və mutfaq yazıları bəzən məlumatlar listesində görünür, çünki istifadəçilər məlumatlarında səhv yaza bilərlər. Bütün bu səs komputerlərə, calorie hesablaması kimi, müxtəlif işlər üçün receptlər istifadə etmək çətin edir. Bu məsələdən çəkinmək üçün, bir nöral seçmə modeli ilə təşkil olunan ingredient olmayan tanıtma metodlarını təklif edirik. Bizim eksperimentimizdə 600 istifadəçi təşkil edilmiş receptlərdə 6.675 ingredienti bildirdik və təklif etdiyimiz metodumun 93.3 F1 dəqiqəsini qəbul etdiyini göstərdik.', 'bn': 'সম্প্রতি ইন্টারনেটে ব্যবহারকারী উৎপাদন করা রেসিপি বৃদ্ধি করেছে। In such recipes, users are generally supposed to write a title, an ingredient list, and steps to create a dish.  তবে ব্যবহারকারী উৎপাদন করা রেসিপির তালিকায় কিছু বস্তুর মধ্যে কিছু বিষয়বস্তু আসলেই প্রযোজ্য নয়। উদাহরণস্বরূপ, শিরোনাম, মন্তব্য এবং কিচেনওয়্যার মাঝে মাঝে মাঝে মাঝে একটি উপাদান তালিকায় দেখা যায় কারণ ব্যবহারকারীরা তাদ এই ধরনের শব্দ কম্পিউটারের জন্য কঠিন করে বিভিন্ন কাজের জন্য রেসিপি ব্যবহার করা, যেমন ক্যালোরি হিসেবে। এই বিষয়টি নিয়ে কথা বলার জন্য আমরা একটি নিউরেল সেকেন্সের ট্যাগিং মডেল দ্বারা অনুপ্রাণিত নির্দেশিত উপায়ের প্রস্তাব আমাদের পরীক্ষায় আমরা ৬০০ ব্যবহারকারী তৈরি করা রেসিপিটে ৬৬৭৫ টি উপাদান প্রকাশ করেছি এবং দেখাচ্ছি যে আমাদের প্রস্তাবিত পদ্ধতি ৯৩.', 'bs': 'Nedavno se povećao broj recepta od korisnika na internetu. U takvim receptima, korisnici obično trebaju napisati titulu, listu sastojaka i korake za stvaranje jela. Međutim, neki predmeti u listi sastojaka u recepu od korisnika zapravo nisu pojedinljivi sastojaci. Na primjer, naslovi, komentari i kuhinjski materijal ponekad se pojavljuju na listi sastojaka jer korisnici mogu slobodno pisati listu u svojim receptima. Takva buka čini kompjuterima teško koristiti recept za razne zadatke, poput procjene kalorija. Da bi se riješili ovom pitanju, predlažemo metodu detekcije bez sastojaka inspirisanu modelom označavanja neuralne sekvence. U našem eksperimentu, zabilježili smo 6.675 sastojaka u 600 recepta od korisnika i pokazali da je naš predloženi metod postigao 93.3 F1 rezultat.', 'ca': "Recentment, el nombre de recetes generades per l'usuari a Internet ha augmentat. In such recipes, users are generally supposed to write a title, an ingredient list, and steps to create a dish.  Però alguns articles d'una llista d'ingredients d'una receta generada per l'usuari no són ingredients comestibles. Per exemple, els títulos, els comentaris i el material de cuina apareixen a vegades en una llista d'ingredients perquè els usuaris poden escriure lliurement la llista en les seves recetes. Aquest soroll dificulta que els ordinadors utilitzen recetes per a diverses tasques, com l'estimació de calories. Per abordar aquest problema, proposem un mètode de detecció de no ingredients inspirat en un model d'etiqueta de seqüència neuronal. En el nostre experiment, vam anotar 6.675 ingredients en 600 recetes generades per l'usuari i vam demostrar que el nostre mètode proposat va aconseguir una puntuació de 93,3 F1.", 'cs': 'V poslední době se zvýšil počet uživatelsky generovaných receptů na internetu. V takových receptech mají uživatelé obecně napsat název, seznam ingrediencí a kroky k vytvoření jídla. Nicméně některé položky v seznamu ingrediencí v uživatelském receptu nejsou ve skutečnosti jedlé ingredience. Například záhlaví, komentáře a kuchyňské nádobí se někdy objeví v seznamu ingrediencí, protože uživatelé mohou volně psát seznam ve svých receptech. Takový hluk znemožňuje počítačům používat recepty pro různé úkoly, jako je odhad kalorií. Pro řešení tohoto problému navrhujeme metodu detekce bez složek inspirovanou modelem značení neuronové sekvence. V našem experimentu jsme anotovali 6,675 ingredience v 600 uživatelsky generovaných receptech a ukázali, že naše navrhovaná metoda dosáhla bodu 93,3 F1.', 'et': 'Hiljuti on kasutaja loodud retseptide arv Internetis suurenenud. Sellistes retseptides peavad kasutajad üldjuhul kirjutama pealkirja, koostisosade loendi ja toidu loomise sammud. Kuid mõned kasutaja loodud retsepti koostisosade nimekirjas olevad esemed ei ole tegelikult söödavad koostisosad. Näiteks pealkirjad, kommentaarid ja kööginõud kuvatakse mõnikord koostisosade loendis, kuna kasutajad saavad nimekirja oma retseptidesse vabalt kirjutada. Selline müra raskendab arvutitel retseptide kasutamist mitmesuguste ülesannete jaoks, näiteks kalorite hindamiseks. Selle probleemi lahendamiseks pakume välja mittekomponentide tuvastamise meetodi, mis on inspireeritud närvijada märgistamise mudelist. Oma eksperimendis märkisime 6 675 koostisosa 600 kasutaja loodud retsepti ja näitasime, et meie kavandatud meetod saavutas 93,3 F1 skoori.', 'fi': 'Viime aikoina käyttäjien luomat reseptit Internetissä ovat lisääntyneet. Tällaisissa resepteissä käyttäjien on yleensä tarkoitus kirjoittaa otsikko, ainesosaluettelo ja vaiheet ruokalajin luomiseksi. Jotkin käyttäjän luoman reseptin ainesosaluettelon kohteet eivät kuitenkaan ole syötäviä ainesosia. Esimerkiksi otsikot, kommentit ja keittiövälineet näkyvät joskus ainesosaluettelossa, koska käyttäjät voivat vapaasti kirjoittaa luettelon resepteihinsä. Tällainen melu vaikeuttaa tietokoneiden reseptejä erilaisiin tehtäviin, kuten kalorien arviointiin. Tämän ongelman ratkaisemiseksi ehdotamme aineettoman tunnistusmenetelmän, joka perustuu neurosekvenssimalliin. Annotoimme kokeessamme 6 675 ainesosaa 600 käyttäjän luomaan reseptiin ja osoitimme, että ehdotettu menetelmä saavutti 93,3 F1-pisteen.', 'ha': "@ info: whatsthis Daga wannan cewa masu amfani da shi, an a kamata a rubutu wani suna, wani jerin mai ƙunci, da ƙyama don a ƙiƙira wani waran. A lokacin da, wasu abubuwa ba su sami cikin wani jerin da aka ƙiƙira wani mai amfani da shi ba masu inganci ba. For example, headings, comments, and kitchenware sometimes appear in an ingredient list because users can freely write the list in their recipes.  Yin sauri kamar wannan, ya yi nau'i ga amfani da kwamfyuta don su yi amfani da wasu aikin dabam-dabam, kamar misãlin kalori. Domin da za mu yi magana ga wannan masu al'amarin, za'a buƙata wata metode na-bayani wanda ba mai ƙunci ba, wanda aka yi wahayi da wani motel mai tagannin tarakin neural. A cikin jarrabonmu, muka sanar da kashi 6,675 cikin kashi wanda ya samu karo 600 na amfani da shi kuma muka nũna cewa hanyoyinmu da aka buɗa na da ni'imar 93.3 F1.", 'sk': 'V zadnjem času se je število uporabniških receptov na internetu povečalo. V takih receptih naj bi uporabniki običajno napisali naslov, seznam sestavin in korake za ustvarjanje jedi. Vendar pa nekateri elementi na seznamu sestavin v receptu, ki ga ustvari uporabnik, dejansko niso užitne sestavine. Na primer, naslovi, komentarji in kuhinjska posoda se včasih pojavijo na seznamu sestavin, ker lahko uporabniki seznam prosto napišejo v svoje recepte. Takšen hrup računalnikom otežuje uporabo receptov za različne naloge, kot je ocenjevanje kalorij. Za reševanje tega vprašanja predlagamo metodo odkrivanja nevronskih zaporedj, ki jo navdihuje model označevanja nevronskih zaporedj. V našem poskusu smo v 600 receptih, ki jih ustvarijo uporabniki, navedli 6.675 sestavin in pokazali, da je naša predlagana metoda dosegla 93,3 F1 oceno.', 'jv': 'plug-in-action Nang oleh operasi, usukake kudune nggo ngwala titla, nganggo mulalah ingkang karo nganggo dolanan kanggo nganggo dolanan politenessoffpolite"), and when there is a change ("assertivepoliteness Sampeyan, heading, komentar, lan kêftun. Mingko iso ngaweh saben kelas nèng lisar ingripen merang pengguna iso ngubah akeh penyane kelas karo akeh barang nggawe buddy layers-action Awak dhéwé éntuk ujaran, kéné wis ngerasakno 6.', 'he': 'לאחרונה, מספר המתכונים שנgenerו ע"י המשתמשים באינטרנט גדל. במתכונים כאלה, משתמשים בדרך כלל אמורים לכתוב כותר, רשימת המרכיבים, ולצעדים ליצור כלי. עם זאת, חלק מהפריטים ברשימת המרכיבים במתכון שנוצר ע"י משתמשים אינם למעשה מרכיבים אוכלים. לדוגמה, כתובות, תגובות וחפצי המטבח לפעמים מופיעים ברשימת המרכיבים כי המשתמשים יכולים לכתוב את הרשימה בחינם במתכונים שלהם. רעש כזה מקשה למחשבים להשתמש במתכונים למגוון משימות, כמו הערכה של קלוריות. כדי להתמודד עם הנושא הזה, אנו מציעים שיטת גילוי לא ממרכיבים שמושרפת על ידי דוגמא תגיון רצף עצבי. בניסוי שלנו צייננו 6,675 מרכיבים ב 600 מתכונים שנוצרים ע"י משתמשים והראינו שהשיטה המוצעת שלנו השיגה נקודת F1 93.3.', 'bo': 'འཕྲལ་ཁམས་དུ་དྲ་ཐོག་ཏུ་སྤྱོད་མཁན་གྱིས་གསར་འཛུགས་བྱས་པའི་ཐུག་འཕྲད་གྱི་གྲངས་ཀ་རྒྱ་བསྐྱེད་ཡོད། འདི་དག་གི་ལྟ་བུའི་ནང་དུ་སྤྱོད་མཁན་ཚོས་རྒྱུན་ལྡན་མིང་ཞིག་ཡིག་ཆ་འདུག ཡིན་ནའང་སྤྱོད་མཁན་གྱི་ཁྱོད་རམ་ནང་གི་ཆ་འཕྲིན་གྱི་ཐོ་འགོད་ནང་གི་རྣམ་གྲངས དཔེར་ན། མགོ་ཡིག་མགོ་ཡིག་དང་མཆན་བཤད་པ། སྐབས་རེ་ཆ་འཕྲིན་གྱི་ཐོ་འགོད་ནང་མངོན་པ་རྒྱུ་མཚན་ནི་སྤྱོད་མཁན་གྱིས་ཐོ་འགོད་འད དཀྱིལ་མོ་འདི་གིས་རྩིས་འཁོར་ལ་སྤྲོད་ཀྱི་ལས་འགུལ་གྱི་རྩིས་ཐོག་མ་འདུག འུ་ཅག་གིས་གནས་ཚུལ་འདི་ལྟ་བུ་བཤད་ན་གསལ་པོ་མིན་པའི་རྣམ་གྲངས་རྟོགས་ལམ་ལུགས་ཀྱི་སྐོར་ལས། ང་ཚོའི་བརྟག་ཞིག་གིས་ལག་ལེན་པ་600 ནང་གི་སྐྱེས་ཆོས་རྗེས་འབྲས་བ་དེ་འགྲེལ་བཤད་བྱས་པ་ལྟར། ང་ཚོའི་སྔོན་སྒྲིག་ཐབས་ལམ་ལྟ'}
{'en': 'An Empirical Analysis of Human-Bot Interaction on Reddit R eddit', 'ar': 'تحليل تجريبي للتفاعل بين الإنسان والبوت على Reddit', 'fr': "Une analyse empirique de l'interaction homme-robot sur Reddit", 'pt': 'Uma análise empírica da interação humano-bot no Reddit', 'es': 'Un análisis empírico de la interacción humano-bot en Reddit', 'ja': 'Redditでの人間とボットの相互作用の実証的分析', 'zh': 'Reddit涓婁汉鏈轰氦浜掍箣瀹炰篃', 'hi': 'Reddit पर मानव-बॉट इंटरैक्शन का एक अनुभवजन्य विश्लेषण', 'ru': 'Эмпирический анализ взаимодействия человека и робота на Reddit', 'ga': 'Anailís eimpíreach ar Idirghníomhaíocht Daonna-Bot ar Reddit', 'el': 'Μια εμπειρική ανάλυση της αλληλεπίδρασης ανθρώπου-ρομπότ στο Reddit', 'it': "Analisi empirica dell'interazione uomo-bot su Reddit", 'ka': 'ადამიანის-ბოტის ინტერქექციის ემპერიკალური ანალიზაცია რედიტიდან', 'hu': 'A humán-bot kölcsönhatás empirikus elemzése Redditen', 'lt': 'Empirinė žmogaus ir robotų sąveikos su Reddit analizė', 'kk': 'Қайталау үшін адамдар-бот интерактивтің империялық анализ', 'mk': 'An Empirical Analysis of Human-Bot Interaction on Reddit', 'ml': 'റെഡിഡിറ്റിലെ മനുഷ്യരുടെ ബോട്ട് ഇന്റര്\u200dക്ഷനിലെ എമിരിക്കല്\u200d അന്വേഷണം', 'no': 'Name', 'mt': 'Analiżi Impirika ta’ Interazzjoni Uman-Bot fuq Reddit', 'ms': 'Name', 'mn': 'Хүний-Бот харилцааны эзэнт шинжилгээ', 'ro': 'O analiză empirică a interacțiunii om-bot pe Reddit', 'pl': 'Analiza empiryczna interakcji człowieka-bota na Redditie', 'sr': 'Impirička analiza interakcije ljudskih bota na Reddit', 'si': 'Name', 'ur': 'روڈیٹ پر انسان-بوٹ انٹراکسون کی امپریٹی تحلیل', 'ta': 'சிடிட்டில் மனித- போட் இடைவெளி செயல்பாட்டின் ஒரு வெற்றிகரமான ஆய்வு', 'sv': 'En empirisk analys av människa-bot interaktion på Reddit', 'so': 'An Empirical Analys of Human-Bot Interaction on Reddit', 'uz': 'Name', 'vi': 'A Empirical Analysis of Human-Bot Interaction on Reddit', 'nl': 'Een empirische analyse van mens-bot interactie op Reddit', 'da': 'En empirisk analyse af menneske-bot interaktion på Reddit', 'bg': 'Емпиричен анализ на взаимодействието човек-бот в Редит', 'hr': 'Empirička analiza interakcije ljudskih bota na Reddit', 'id': 'Analisi Kekaisaran Interaksi Manusia-Bot pada Reddit', 'ko': 'Reddit에서 인간과 기계의 상호작용에 대한 실증 분석', 'fa': 'یک تحلیل امپراطوری از تفاوت انسان-bot در Reddit', 'de': 'Eine empirische Analyse der Mensch-Bot-Interaktion auf Reddit', 'tr': 'İnsan-Bot Interaksiýasynyň beýleki analysi', 'sw': 'Uchambuzi wa kipekee wa Tamko cha Kimataifa cha Binadamu kwenye Reddit', 'am': 'edit-action', 'af': "'n Empirical Analysis of Human-Bot Interaction on Reddit", 'bn': 'রেডিডিটে মানুষ-বোট ইন্টারনেকশনের এক সামার্কিক বিশ্লেষণ', 'az': 'Reddit haqqında İnsan-Bot Etkileşimi İmpariki Analizi', 'ca': "Un anàlisi empíric de l'interacció entre robots humans i humans en Reddit", 'cs': 'Empirická analýza interakce člověka-bota na Redditu', 'sq': 'Një analizë perandore e ndërveprimit njerëzor-bot në Reddit', 'fi': 'Empiirinen analyysi ihmisen ja botin vuorovaikutuksesta Redditissä', 'hy': 'Reddit-ի վերաբերյալ մարդ-բոտ ինտերակցիայի կայսրական վերլուծությունը', 'bs': 'Empirička analiza interakcije ljudskih bota na Reddit', 'et': 'Inimese ja boti koostoime empiiriline analüüs Redditis', 'he': 'ניתוח אימפריקלי של אינטראקציה אנושית-בוט על רדיט', 'sk': 'Empirična analiza interakcije med človekom in botom na Redditu', 'ha': 'An Analyze na Empirical of Man-Bot interaction on Rededit', 'bo': 'བསྐྱར་གཏོང་ཐོག་ཏུ་Human-Bot་སླར་སྤྱོད་ཀྱི་གཙོ་རིམ་གྱི་དབྱེ་ཞིབ་བྱས་པ་ཞིག་', 'jv': 'A empircal Test of Human-bot interaction on red dit'}
{'en': 'Automated agents (bots) have emerged as an ubiquitous and influential presence on  social media . Bots engage on  social media platforms  by posting content and replying to other users on the platform. In this work we conduct an empirical analysis of the activity of a single  bot  on  Reddit . Our goal is to determine whether bot activity (in the form of posted comments on the website) has an effect on how humans engage on  Reddit . We find that (1) the sentiment of a bot comment has a significant, positive effect on the subsequent human reply, and (2) human Reddit users modify their comment behaviors to overlap with the text of the bot, similar to how humans modify their text to mimic other humans in conversation. Understanding human-bot interactions on  social media  with relatively simple  bots  is important for preparing for more advanced  bots  in the future.', 'ar': 'ظهر الوكلاء الآليون ("الروبوتات") كحضور واسع النطاق ومؤثر على وسائل التواصل الاجتماعي. تشارك الروبوتات على منصات التواصل الاجتماعي من خلال نشر المحتوى والرد على المستخدمين الآخرين على المنصة. في هذا العمل نجري تحليلًا تجريبيًا لنشاط روبوت واحد على Reddit. هدفنا هو تحديد ما إذا كان نشاط الروبوت (في شكل تعليقات منشورة على موقع الويب) له تأثير على كيفية مشاركة البشر في Reddit. نجد أن (1) شعور تعليق الروبوت له تأثير إيجابي كبير على الرد البشري اللاحق ، و (2) يقوم مستخدمو Reddit بتعديل سلوكيات التعليقات الخاصة بهم لتتداخل مع نص الروبوت ، على غرار الطريقة التي يعدل بها البشر. نص لتقليد البشر الآخرين في المحادثة. يعد فهم تفاعلات الإنسان الآلي على وسائل التواصل الاجتماعي باستخدام برامج الروبوت البسيطة نسبيًا أمرًا مهمًا للتحضير لروبوتات أكثر تقدمًا في المستقبل.', 'fr': "Les agents automatisés («\xa0bots\xa0») sont devenus une présence omniprésente et influente sur les réseaux sociaux. Les bots interagissent sur les plateformes de réseaux sociaux en publiant du contenu et en répondant aux autres utilisateurs de la plateforme. Dans ce travail, nous menons une analyse empirique de l'activité d'un seul bot sur Reddit. Notre objectif est de déterminer si l'activité des robots (sous la forme de commentaires publiés sur le site Web) a un effet sur la façon dont les humains interagissent sur Reddit. Nous constatons que (1) le sentiment d'un commentaire de bot a un effet positif significatif sur la réponse humaine subséquente, et (2) les utilisateurs humains de Reddit modifient leurs comportements de commentaire pour qu'ils chevauchent le texte du bot, de la même manière que les humains modifient leur texte pour imiter d'autres humains dans une conversation. Comprendre les interactions homme-robot sur les réseaux sociaux avec des bots relativement simples est important pour préparer les robots plus avancés à l'avenir.", 'pt': 'Agentes automatizados (“bots”) surgiram como uma presença onipresente e influente nas mídias sociais. Os bots se envolvem em plataformas de mídia social postando conteúdo e respondendo a outros usuários na plataforma. Neste trabalho realizamos uma análise empírica da atividade de um único bot no Reddit. Nosso objetivo é determinar se a atividade do bot (na forma de comentários postados no site) afeta a forma como os humanos se envolvem no Reddit. Descobrimos que (1) o sentimento de um comentário de bot tem um efeito positivo e significativo na resposta humana subsequente e (2) os usuários humanos do Reddit modificam seus comportamentos de comentários para se sobreporem ao texto do bot, semelhante a como os humanos modificam seus texto para imitar outros humanos na conversa. Compreender as interações humano-bot nas mídias sociais com bots relativamente simples é importante para se preparar para bots mais avançados no futuro.', 'es': 'Los agentes automatizados («bots») se han convertido en una presencia omnipresente e influyente en las redes sociales. Los bots interactúan en las plataformas de redes sociales publicando contenido y respondiendo a otros usuarios de la plataforma. En este trabajo realizamos un análisis empírico de la actividad de un solo bot en Reddit. Nuestro objetivo es determinar si la actividad de los bots (en forma de comentarios publicados en el sitio web) tiene un efecto en la forma en que los humanos interactúan en Reddit. Encontramos que (1) el sentimiento de un comentario del bot tiene un efecto significativo y positivo en la respuesta humana posterior, y (2) los usuarios humanos de Reddit modifican sus comportamientos de comentarios para superponerse con el texto del bot, de manera similar a como los humanos modifican su texto para imitar a otros humanos en una conversación. Comprender las interacciones humano-bot en las redes sociales con bots relativamente simples es importante para prepararse para bots más avanzados en el futuro.', 'ja': '自動化されたエージェント（「ボット」）は、ソーシャルメディア上で普遍的で影響力のある存在として登場しています。ボットは、コンテンツを投稿したり、プラットフォーム上の他のユーザーに返信したりすることで、ソーシャルメディアプラットフォームに関与します。この作業では、Reddit上の単一のボットのアクティビティの実証的な分析を行います。私たちの目標は、Botのアクティビティ（ウェブサイトに投稿されたコメントの形式）がRedditでの人間のエンゲージメントに影響を与えるかどうかを判断することです。(1)ボットのコメントの感情は、その後の人間の返信に大きなプラスの影響を及ぼし、(2)人間のRedditユーザーは、会話中に他の人間を模倣するために人間がテキストを変更するのと同様に、コメントの動作をボットのテキストと重複するように修正することがわかります。比較的シンプルなボットを使用してソーシャルメディア上の人間とボットの相互作用を理解することは、将来のより高度なボットへの準備に重要です。', 'zh': '自动化摄("机器人")已成社交媒体无所不在且有影响力。 机器人因发而复之用户以与社交媒体台。 于此,吾Reddit单机器人之实也。 吾道定机器人动(以网站发论)其于Reddit互动也。 吾见(1)机器人论情之有显于后者,而(2)人之Reddit用户改其论行以重其机器人,类于人之所以改其文者,以象其对之人也。 知社交媒体之与简机器人者人机交互于将来之机器人备甚重。', 'hi': 'स्वचालित एजेंट ("बॉट्स") सोशल मीडिया पर एक सर्वव्यापी और प्रभावशाली उपस्थिति के रूप में उभरे हैं। बॉट्स सामग्री पोस्ट करके और प्लेटफ़ॉर्म पर अन्य उपयोगकर्ताओं को जवाब देकर सोशल मीडिया प्लेटफार्मों पर संलग्न होते हैं। इस काम में हम Reddit पर एक ही बॉट की गतिविधि का एक अनुभवजन्य विश्लेषण करते हैं। हमारा लक्ष्य यह निर्धारित करना है कि क्या बॉट गतिविधि (वेबसाइट पर पोस्ट की गई टिप्पणियों के रूप में) का प्रभाव पड़ता है कि मनुष्य रेडिट पर कैसे संलग्न होते हैं। हम पाते हैं कि (1) एक बॉट टिप्पणी की भावना का बाद के मानव उत्तर पर एक महत्वपूर्ण, सकारात्मक प्रभाव पड़ता है, और (2) मानव रेडिट उपयोगकर्ता बॉट के पाठ के साथ ओवरलैप करने के लिए अपनी टिप्पणी व्यवहार को संशोधित करते हैं, जैसे कि मनुष्य बातचीत में अन्य मनुष्यों की नकल करने के लिए अपने पाठ को कैसे संशोधित करते हैं। अपेक्षाकृत सरल बॉट्स के साथ सोशल मीडिया पर मानव-बॉट इंटरैक्शन को समझना भविष्य में अधिक उन्नत बॉट्स की तैयारी के लिए महत्वपूर्ण है।', 'ru': 'Автоматизированные агенты («боты») стали повсеместным и влиятельным присутствием в социальных сетях. Боты взаимодействуют на платформах социальных сетей, размещая контент и отвечая другим пользователям на платформе. В этой работе мы проводим эмпирический анализ активности одного бота на Reddit. Наша цель - определить, влияет ли активность бота (в виде размещенных комментариев на сайте) на то, как люди работают на Reddit. Мы обнаружили, что (1) настроение комментария бота оказывает значительное положительное влияние на последующий человеческий ответ, и (2) пользователи Reddit человека изменяют поведение своих комментариев, чтобы перекрыться с текстом бота, подобно тому, как люди изменяют свой текст, чтобы имитировать других людей в разговоре. Понимание взаимодействия «человек-бот» в социальных сетях с относительно простыми ботами важно для подготовки к более продвинутым ботам в будущем.', 'ga': 'Tá gníomhairí uathoibrithe (“róbónna”) tagtha chun cinn mar láithreacht uileláithreach agus tioncharach ar na meáin shóisialta. Téann róbónna i ngleic le hardáin na meán sóisialta trí ábhar a phostáil agus freagra a thabhairt ar úsáideoirí eile ar an ardán. San obair seo déanaimid anailís eimpíreach ar ghníomhaíocht bot amháin ar Reddit. Is é ár gcuspóir a chinneadh an bhfuil éifeacht ag gníomhaíocht bot (i bhfoirm tuairimí postáilte ar an láithreán gréasáin) ar an gcaoi a dtéann daoine i ngleic le Reddit. Faighimid amach go bhfuil (1) tionchar suntasach, dearfach ag meon trácht bot ar an bhfreagra daonna ina dhiaidh sin, agus (2) go ndéanann úsáideoirí Reddit daonna a n-iompraíochtaí tuairimí a mhodhnú chun forluí le téacs an bot, cosúil leis an gcaoi a athraíonn daoine a gcuid tuairimí. téacs chun aithris a dhéanamh ar dhaoine eile i gcomhrá. Tá sé tábhachtach idirghníomhaíochtaí daonna-bot ar na meáin shóisialta a thuiscint le róbónna réasúnta simplí chun ullmhú le haghaidh róbónna níos forbartha sa todhchaí.', 'el': 'Οι αυτοματοποιημένοι πράκτορες ("ρομπότ") έχουν αναδειχθεί ως μια πανταχού παρούσα και ισχυρή παρουσία στα μέσα κοινωνικής δικτύωσης. Τα ρομπότ εμπλέκονται σε πλατφόρμες κοινωνικών μέσων δημοσιεύοντας περιεχόμενο και απαντώντας σε άλλους χρήστες στην πλατφόρμα. Σε αυτή την εργασία διεξάγουμε μια εμπειρική ανάλυση της δραστηριότητας ενός μεμονωμένου ρομπότ στο Reddit. Στόχος μας είναι να προσδιορίσουμε αν η δραστηριότητα των ρομπότ (με τη μορφή αναρτημένων σχολίων στον ιστότοπο) έχει επίδραση στον τρόπο με τον οποίο οι άνθρωποι εμπλέκονται στο Reddit. Διαπιστώνουμε ότι (1) το συναίσθημα ενός σχολίου έχει σημαντική, θετική επίδραση στην επόμενη ανθρώπινη απάντηση, και (2) οι άνθρωποι χρήστες τροποποιούν τις συμπεριφορές σχολίων τους ώστε να επικαλύπτονται με το κείμενο του ρομπότ, παρόμοια με τον τρόπο που οι άνθρωποι τροποποιούν το κείμενό τους για να μιμηθούν άλλους ανθρώπους στη συνομιλία. Η κατανόηση των αλληλεπιδράσεων ανθρώπου-ρομπότ στα μέσα κοινωνικής δικτύωσης με σχετικά απλά ρομπότ είναι σημαντική για την προετοιμασία για πιο προηγμένα ρομπότ στο μέλλον.', 'ka': "სოციალური მედიაში ავტომატიური ადვნენტები ('ბოტები') იქნება, როგორც სამუშაო და მუშაობელი მოსახლეობა. ბოტები სოციალური მედია პლატატურებში მოთავსდება, რომლებიც კონტაქტის შესახებ გადასტანა და სხვა მომხმარებისთვის გადასტანა. ამ სამუშაოში ჩვენ რედიტის ერთი პრობტის ექსპერიკალური ანალიზია. ჩვენი მიზეზი არის განსაზღვრება, თუ როგორ ადამიანები რედიტის დაკავშირებულია პოსტალური კომენტრების ფორმაში. ჩვენ აღმოჩნეთ, რომ (1) ბოტის კომენტაქტის სენტიმენტი აქვს მნიშვნელოვანი, პოტიფიკაციური ეფექტი შემდეგ ადამიანის გარეშე, და (2) ადამიანის რედიტი მომხმარებელი შეცვალობა თავის კომენტაქტის ქცევების მონაცემების მო ფჲგვფვჟკთ-ბჲრთ თნრვპაკუთთ ნა ჟჲუთალნთრვ მვეთწ ჟ ოპთლთფნჲ ვენჲჟრაგნთ პჲბჲრთ ვ გაზნჲ ჱა ოჲედჲრგწგანვ ჱა ოჲგვფვ ნაოპაგვნთ პჲბჲრთ გ ბყევღვრჲ.", 'hu': 'Az automatizált ügynökök ("botok") mindenütt jelenlévő és befolyásos jelenlétként jelentek meg a közösségi médiában. A botok a közösségi média platformokon azáltal vesznek részt, hogy tartalmakat tesznek közzé és válaszolnak más felhasználóknak a platformon. Ebben a munkában empirikus elemzést végzünk egyetlen bot tevékenységéről Redditen. Célunk annak megállapítása, hogy a robottevékenység (a weboldalon közzétett megjegyzések formájában) befolyásolja-e az emberek Redditen való részvételét. Úgy találjuk, hogy (1) egy bot megjegyzés érzése jelentős, pozitív hatással van a következő emberi válaszra, és (2) az emberi Reddit felhasználók módosítják a megjegyzések viselkedését, hogy átfedjék a bot szövegét, hasonlóan ahogyan az emberek módosítják a szövegüket, hogy más embereket utánozzák a beszélgetés során. Az ember-bot interakciók megértése a közösségi médián viszonylag egyszerű robotokkal fontos a fejlettebb robotokra való felkészüléshez a jövőben.', 'lt': 'Automatiniai agentai („robotai“) atsirado kaip visur paplitę ir įtakinga socialinėje žiniasklaidoje. Bots dalyvauja socialinės žiniasklaidos platformose, skelbdami turinį ir atsakydami į jį kitiems naudotojams. Šiame darbe atliekame empirinę vieno roboto Reddit veiklos analizę. Mūsų tikslas – nustatyti, ar robotų veikla (kaip skelbiamos komentarai interneto svetainėje) daro poveikį žmonių veiklai Reddit. We find that (1) the sentiment of a bot comment has a significant, positive effect on the subsequent human reply, and (2) human Reddit users modify their comment behaviors to overlap with the text of the bot, similar to how humans modify their text to mimic other humans in conversation.  Svarbu suprasti žmogaus ir robotų sąveiką social in ėje žiniasklaidoje su santykinai paprastais robotais, kad ateityje pasirengtų pažangiems robotams.', 'mk': 'Автоматизираните агенти („роботи“) се појавија како насекаде и влијателно присуство на социјалните медиуми. Роботите се вклучуваат во платформите на социјалните медиуми со поставување содржина и одговор на другите корисници на платформата. Во оваа работа спроведуваме емпирична анализа на активноста на еден робот на Редит. Нашата цел е да утврдиме дали активноста на роботите (во форма на објавени коментари на веб-страницата) има влијание врз тоа како луѓето се вклучуваат во Реддит. Најдовме дека (1) чувството на роботски коментар има значителен, позитивен ефект на следниот човечки одговор, и (2) човечките корисници на Редит ги модификуваат нивните коментарни однесувања за да се преплатат со текстот на роботот, слично на тоа како луѓето го модификуваат нивниот текст за да имитираат други луѓе Разбирањето на интеракциите помеѓу луѓето и роботите во социјалните медиуми со релативно едноставните роботи е важно за подготвувањето за понапредни роботи во иднина.', 'kk': "Автоматтық агенттер ('bots') социаллық медиақтарда әрқашамды және әсер ететін болып шыққан. Платформадағы басқа пайдаланушыларға мазмұнын жіберу және жауап беру үшін боттар социалдық медиа платформасына қатысты. Бұл жұмыс ішінде бір Реддит ботуының әрекетінің импирикалық анализ жасайды. Біздің мақсатымыз - бот белсенділігін (вебсайттағы жіберілген түсініктемелер түрінде) Reddit- ге қалай істеу нәтижесін анықтау. Біз (1) ботты түсініктеменің сезімі адамдардың жауабына маңызды, оң эффекті болады, және (2) адамдардың Реддит пайдаланушылары комментарияларын боттың мәтінімен біріктіру үшін өзгертіп, адамдардың мәтінін бағытталған адамдардың мәтінін Адам-боттардың әлеуметтік медиақтарындағы қарапайым боттардың қатынасын түсіну болашақтағы көптеген боттарды дайындау үшін маңызды.", 'it': 'Gli agenti automatizzati ("bot") sono emersi come presenza onnipresente e influente sui social media. I bot si impegnano sulle piattaforme di social media pubblicando contenuti e rispondendo ad altri utenti sulla piattaforma. In questo lavoro conduciamo un\'analisi empirica dell\'attività di un singolo bot su Reddit. Il nostro obiettivo è determinare se l\'attività dei bot (sotto forma di commenti pubblicati sul sito) ha un effetto sul modo in cui gli esseri umani interagiscono su Reddit. Troviamo che (1) il sentiment di un commento bot ha un effetto significativo e positivo sulla successiva risposta umana, e (2) gli utenti di Reddit umani modificano i loro comportamenti di commento per sovrapporsi al testo del bot, simile a come gli esseri umani modificano il loro testo per imitare altri esseri umani in conversazione. Comprendere le interazioni uomo-bot sui social media con bot relativamente semplici è importante per prepararsi per bot più avanzati in futuro.', 'ml': "Automated agents ('bots') have emerged as an ubiquitous and influential presence on social media.  പ്ലാറ്റ്ഫോമില്\u200d മറ്റു ഉപയോക്താക്കള്\u200dക്കും മറ്റുള്ള ഉപയോക്താക്കള്\u200dക്ക് പകരം നല്\u200dകുന്നതിനാല്\u200d സാമൂഹ്യ മീഡിയ ഈ ജോലിയില്\u200d നമ്മള്\u200d റെഡിറ്റില്\u200d ഒരു ബോട്ടിന്റെ പ്രവര്\u200dത്തനത്തെപ്പറ്റിയുള്ള ഒരു ശാസ്ത്ര വിശ്വാസം നടത നമ്മുടെ ലക്ഷ്യം റെഡിറ്റില്\u200d മനുഷ്യര്\u200d എങ്ങനെ ചെയ്യുന്നുവെന്ന് നിരീക്ഷിക്കുന്നുവോ എന്നാണോ ബോട്ട് പ്രവര്\u200dത്തനം (വെബ് (1) പിന്നീട് മനുഷ്യരുടെ മറുപടിയില്\u200d ഒരു ബോട്ടിന്\u200dറെ വിചാരണയ്ക്ക് ഒരു പ്രധാനപ്പെട്ട പ്രഭാവം ഉണ്ടെന്ന് ഞങ്ങള്\u200d കണ്ടെത്തുന്നു. മനുഷ്യര്\u200d റെഡിഡിറ്റ് ഉപയോക്താക്കള്\u200d തങ്ങളുടെ വ ഭാവിയില്\u200d കൂടുതല്\u200d മുന്\u200dഗണന ബോട്ടുകള്\u200d തയ്യാറാക്കുവാന്\u200d മനുഷ്യരുടെ സാമൂഹ്യ മീഡിയിലുള്ള ഇടപാടുകള്\u200d മനസ്സിലാക്കുന", 'mn': "Автоматтын агентууд ('bots') нийгмийн мэдээллийн хэрэглэгчид нийгмийн мэдээллийн хувьд байдал болон нөлөөлдөг байдал болсон. Ботууд нийгмийн хэвлэлийн платформад бүтээгдэхүүнийг илгээж, платформад бусад хэрэглэгчдэд хариулт өгдөг. Энэ ажлын тухай бид Редит дээрх ганц ботын үйл ажиллагааны эмперикийн шинжилгээ хийдэг. Бидний зорилго бол робот үйл ажиллагаа (вебсайт дээр тайлбарласан хэлбэрээр) хүмүүс Reddit-д хэрхэн оролцож байгааг тодорхойлох юм. Бид (1) ботон сэтгэлгээний мэдрэмж дараагийн хүний хариулт дээр маш чухал, эерэг нөлөөтэй байдаг. 2) хүний Reddit хэрэглэгчид өөрсдийнхөө сэтгэлгээний үйл ажиллагааг ботон текстэй хуваалцаж, хүмүүс өөрсдийнхөө текстийг бусад хүмүүсийн ярилцлаганд өөрчлөх шиг өөр Нийгмийн мэдээлэл дээрх хүн-бот харилцааны харилцааны энгийн роботыг ойлгох нь ирээдүйд илүү хөгжиж буй роботыг бэлдэх нь чухал.", 'ms': "Ejen automatik ('robot') telah muncul sebagai kehadiran di mana-mana dan mempengaruhi media sosial. Bots terlibat pada platform media sosial dengan memposting kandungan dan menjawab kepada pengguna lain di platform. Dalam kerja ini kita melakukan analisis empirik aktiviti robot tunggal di Reddit. Tujuan kita ialah menentukan sama ada aktiviti robot (dalam bentuk komentar yang ditetapkan pada laman web) mempunyai kesan pada bagaimana manusia bertindak pada Reddit. Kami mendapati bahawa (1) perasaan komentar robot mempunyai kesan positif yang signifikan pada jawapan manusia kemudian, dan (2) pengguna Reddit manusia mengubah perilaku komentar mereka untuk meliputi teks robot, sama seperti bagaimana manusia mengubah teks mereka untuk meniru manusia lain dalam perbualan. Memahami interaksi manusia-robot pada media sosial dengan robot relatif sederhana adalah penting untuk bersedia untuk robot yang lebih maju di masa depan.", 'mt': "Aġenti awtomatizzati ('robots') ħarġu bħala preżenza kullimkien u influwenti fuq il-midja soċjali. Bots jimpenjaw ruħhom fuq pjattaformi tal-midja soċjali billi jippreżentaw kontenut u jwieġbu lil utenti oħra fuq il-pjattaforma. F’dan ix-xogħol qed nagħmlu analiżi empirika tal-attività ta’ robot wieħed fuq Reddit. L-għan tagħna huwa li niddeterminaw jekk l-attività robotika (fil-forma ta’ kummenti ppubblikati fuq is-sit elettroniku) għandhiex effett fuq kif il-bnedmin jimpenjaw ruħhom fuq Reddit. Aħna nsibu li (1) is-sentiment ta’ kumment robotiku għandu effett sinifikanti u pożittiv fuq ir-risposta sussegwenti tal-bniedem, u (2) l-utenti Reddit umani jimmodifikaw l-imġiba tal-kummenti tagħhom biex jikkoinċidu mat-test tal-robot, simili għal kif il-bnedmin jimmodifikaw it-test tagħhom biex jimitikaw bnedmin oħrajn waqt il-konverżjoni. Il-fehim tal-interazzjonijiet bejn il-bniedem u l-robots fil-midja soċjali ma’ robots relattivament sempliċi huwa importanti għat-tħejjija għal robots aktar avvanzati fil-futur.", 'no': 'Automatiserte agentar (« bots ») har oppstått som eit gjeldande og påvirkelige tilstand på sosiale media. Bottene pågår på sosiale mediaplattformar ved å senda innhald og svara til andre brukarar på plattformat. I dette arbeidet gjer vi ein empirisk analyse av aktiviteten av ein enkel bot på Reddit. Målet vårt er å bestemme om botaktivitet (i form av posterte kommentarar på nettsiden) har ein effekt på korleis mennesker gjer med Reddit. Vi finn at (1) følelsen til ein botkommentar har ein signifikant, positivt effekt på den neste menneske svaret, og (2) menneske Reddit-brukarar endrar kommentaren sine for å overlappa med teksten på boten, slik som menneske endrar teksten sine til å mimisera andre menneske i samtalen. Det er viktig å forstå menneskelig-bot-interaksjonar på sosiale media med relativt enkle bots for å forberede fleire avanserte bots i framtida.', 'pl': 'Zautomatyzowani agenci ("boty") stały się wszechobecną i wpływową obecnością w mediach społecznościowych. Boty angażują się na platformach mediów społecznościowych, publikując treści i odpowiadając innym użytkownikom na platformie. W niniejszej pracy przeprowadzamy empiryczną analizę aktywności pojedynczego bota na Reddit. Naszym celem jest ustalenie, czy aktywność bota (w postaci zamieszczanych komentarzy na stronie) ma wpływ na to, jak ludzie angażują się w Reddit. Stwierdzimy, że (1) sentyment komentarza bota ma znaczący, pozytywny wpływ na późniejszą odpowiedź ludzką, a (2) użytkownicy Redditu modyfikują swoje zachowania komentarza, aby nakładać się z tekstem bota, podobnie jak ludzie modyfikują swój tekst, aby naśladować innych ludzi w rozmowie. Zrozumienie interakcji człowiek-bot w mediach społecznościowych za pomocą stosunkowo prostych botów jest ważne dla przygotowania się na bardziej zaawansowane boty w przyszłości.', 'sr': "Automatizirani agenti ('botovi') pojavili su se kao svuda i uticajna prisustva na društvene medije. Botovi se uključuju na platforme društvenih medija, postavljajući sadržaj i odgovarajući drugim korisnicima na platformi. U ovom poslu vodimo empiričku analizu aktivnosti jednog robota na Reddit-u. Naš cilj je da utvrdimo da li aktivnost robota (u obliku postavljenih komentara na sajtu) ima utjecaj na to kako ljudi učestvuju na Reddit. Nalazimo da (1) osjećaj komentara robota ima značajan, pozitivan efekat na sljedeći odgovor na ljude, a (2) ljudski korisnici Reddit modifikuju svoje ponašanje komentara da se preoklapaju sa tekstom robota, sličan na način kako ljudi modifikuju svoj tekst na imitiranje drugih ljudi u razgovoru. Razumevanje interakcija sa ljudskim robotima na društvenim medijima sa relativno jednostavnim robotima je važno za pripremu za naprednije robote u budućnosti.", 'si': "සාමාජික මිඩියාවට ස්වයංක්\u200dරීය විදියට ස්වයංක්\u200dරීය විදියට ස්වයංක්\u200dරීය විදියට ('බොට්ස') ප්\u200dරක බෝට්ස් සාමාජික මිඩියාව ප්ලේටප්ටෝම් එක්ක සාමාජික ප්\u200dලේටප්ටෝම් එක්ක සාමාජික ප්\u200dරති මේ වැඩේ අපි රෙඩ්ඩිට් වලින් එක්කෙන් බොට් එකක් ගැන විශ්ලේෂණයක් කරනවා. අපේ අරමුණ තමයි බොට් ක්\u200dරියාත්මක වැඩසටහන් වලින් පැත්ත කිරීමක් තියෙන්නේ නැද්ද කියලා තියෙන්නේ. මිනිස්සු ර අපි හොයාගන්නවා කියලා (1) බොට් කිරීමක් ගැන ප්\u200dරශ්නයක් තියෙනවා වැදගත්, වැදගත් ප්\u200dරශ්නයක් තියෙනවා, සහ (2) මිනිස් රෙඩිට් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනස් කරනවා  මිනිස්සු බොට් එක්ක සමාජික මාධ්\u200dයමයේ සාමාජික ප්\u200dරවේශනයක් තේරුම් ගන්න අනාගතයේ වැඩිය ප්\u200dරවේශනය කරන්න වැ", 'so': "Shaqaalaha iskaa u isticmaalay ('bots') waxay u soo baxeen sidii mid aan saameyn lahayn oo saameyn ku leh shabakadda bulshada. Labaduba waxay ku qeybqaadanayaan jardiinada shabakadda bulshada, iyagoo ku qoraya waxyaabaha ay ku jirto iyo isticmaalayaasha kale oo ku qoran jardiinada. Shaqadan waxaynu ku sameynaa baaritaan waxqabadka hal bot ee Reddit. Ujeedkeennu waa in uu go’aamiyo howlaha bot (foomka ku qoran kommentaha bogagga shabakadda) uu saameyn ku yeelanayo sida dadku u u qabanayo Reddit. Waxaynu aragnaa in (1) malaha comment ay leedahay saameyn aad u weyn, positive oo ku saabsan jawaabta dadka soo socda, iyo (2) isticmaalayaasha Rededit ee dadka (Reddit) waxay bedeshaan dabeecada aragtidooda si ay ugu boodbeeyaan qoraalka bot, taasoo u eg sida dadku u u beddeli karo macluumaadkooda si ay dadka kale ugu beddelaan hadalka. Waxgarashada iskala xiriirka dadka ee shabakadda bulshada ah oo la xiriira karo fudud, waa muhiim in loo diyaariyo bobotooyinka hore ee mustaqbalka.", 'ro': 'Agenții automatizați ("robții") au apărut ca o prezență omniprezentă și influentă pe rețelele sociale. Botii se angajează pe platformele de social media prin postarea conținutului și răspunsul altor utilizatori de pe platformă. În această lucrare efectuăm o analiză empirică a activității unui singur bot pe Reddit. Scopul nostru este de a determina dacă activitatea roboților (sub forma comentariilor postate pe site) are un efect asupra modului în care oamenii se angajează pe Reddit. Considerăm că (1) sentimentul unui comentariu al unui bot are un efect semnificativ și pozitiv asupra răspunsului uman ulterior și (2) utilizatorii Reddit umani modifică comportamentul comentariilor lor pentru a se suprapune cu textul robotului, similar cu modul în care oamenii își modifică textul pentru a imita alți oameni în conversație. Înțelegerea interacțiunilor om-bot pe social media cu roboți relativ simpli este importantă pentru pregătirea pentru roboți mai avansați în viitor.', 'sv': 'Automatiserade agenter ("bots") har framkommit som en allestädes närvarande och inflytelserik närvaro på sociala medier. Bots engagerar sig på sociala medieplattformar genom att publicera innehåll och svara till andra användare på plattformen. I detta arbete genomför vi en empirisk analys av aktiviteten hos en enskild bot på Reddit. Vårt mål är att avgöra om robotaktivitet (i form av publicerade kommentarer på webbplatsen) påverkar hur människor engagerar sig på Reddit. Vi finner att (1) känslan av en bot kommentar har en signifikant, positiv effekt på det efterföljande mänskliga svaret, och (2) mänskliga Reddit-användare modifierar sina kommentarsbeteenden för att överlappa texten i boten, liknande hur människor modifierar sin text för att efterlikna andra människor i konversation. Att förstå människa-bot interaktioner på sociala medier med relativt enkla robotar är viktigt för att förbereda sig för mer avancerade robotar i framtiden.', 'ur': "آٹوٹ ایجنٹ ('bots') سوسیل میڈیا میں ایک بے حیائی اور اثراتی موجودگی کے طور پر ظاہر ہوئے ہیں۔ بوٹ سوسیل میڈیا پٹرومٹ پر مشغول ہوتے ہیں اور پٹرومٹ پر دوسرے کارساز کو جواب دیتے ہیں. ہم اس کام میں ایک راڈیٹ پر ایک روٹ کے فعالیت کی امپریسی تحلیل کر رہے ہیں۔ ہمارا مقصد یہ ہے کہ بت فعالیت (ویٹیٹ ویٹیٹ پر پوسٹ کیے ہوئے مثالیں) کا فیصلہ کرنا ہے کہ انسانوں کو ردیٹ پر کس طرح عمل کرتا ہے۔ ہم دیکھتے ہیں کہ (1) ایک بوٹ کمانٹر کا احساس اس کے بعد انسان کی جواب پر اثر اثر رکھتا ہے اور (2) انسان ریڈیٹ کارساز اپنے کمانٹر کے رفتار کو بدل دیتے ہیں کہ بوٹ کے متن سے پورا پورا پورا پورا پورا پورا پورا پورا پورا پورا پورا کریں، جیسے انسان کے متن کو کس طرح بحث میں دوسرے انسانوں کے سامنے سوسیل میڈیا میں انسان بوٹ کی تعاملات سمجھنے کی نسبت ساده بوٹ کے ساتھ مستقبل باتوں کے لئے زیادہ پیشرفت کی بوٹوں کے لئے تیار کرنے کے لئے اہم ہے.", 'ta': "தானியங்கிய முகவர்கள் ('bots') சமூக ஊடகங்களில் ஒரு தனிப்பட்ட மற்றும் பாதாக்கும் இருப்பார்கள். இருவரும் சமூக ஊடக தளங்களில் செயல்படுத்தி உள்ளடக்கங்களை அனுப்பி மற்றும் மற்ற பயனர்களுக்கு பதில் அளிக்கிறார்கள். இந்த வேலையில் நாம் ஒரு செட்டிட் செயல்பாட்டின் ஒரு ஒற்றை பாட் செயல்பாட்டை ஒரு உயர்ந்த ஆய்வு. Our goal is to determine whether bot activity (in the form of posted comments on the website) has an effect on how humans engage on Reddit.  (1) பாட்டின் குறிப்புரைய உணர்வு பின்வரும் மனித பதில் ஒரு முக்கியமான, நேர்ம விளைவு உள்ளது, மற்றும் (2) மனித சிறிது செய்பவர்கள் தங்கள் குறிப்புரைகளை பாட்டின் உரையை மேல் மாற் புரிந்து கொள்வது சுலபமான பாட்டுகளுடன் மனித போட் இடைவெளிப்பாடுகளை புரிந்து கொள்வது எதிர்காலத்தில் மேம்படுத்தப்", 'uz': "Automated agents ('bots') have emerged as an ubiquitous and influential presence on social media.  Икковлари жамоа маълумотлар таркиб олишган ва таркибида бошқа фойдаланувчиларга жавоб бериш билан бажаришалар. Bu ishda biz Reddit'ning bir bot harakatlarini aniqlashni bajaramiz. Bizning maqsadimiz, bot aktivitiyasini aniqlash (veb- saytda qoʻshilgan izohlar turida) odamlar Reddit qanday ishga tayyorlishiga ishlaydi. Biz (1) izohning hisobi keyingi inson javobi juda muhim, positiv effekti, va (2) oddiy Rededit foydalanuvchilar quyidagi ifodalarni qo'yish natijalarini o'zgartiradi, insonlar o'zgarishni boshqa odamlarning javob bilan o'zgartiradi. Keyingi kelajada qo'shimcha botlarni tayyorlash uchun inson bot bilan shaxsiy interfeyslarni tushunish juda muhim.", 'vi': 'Nhân viên tự động (bot) đã xuất hiện như một sự hiện hữu hữu ích và có ảnh hưởng trên các phương tiện xã hội. Lũ robot hoạt động trên nền truyền thông xã hội bằng cách post nội dung và trả lời cho những người khác trên bục. Trong công việc này, chúng tôi thực hiện một phân tích kinh nghiệm về hoạt động của một robot duy nhất trên Reddit. Mục tiêu của chúng tôi là xác định xem các hoạt động của robot (dưới dạng các bình luận được đăng trên trang web) có ảnh hưởng gì tới cách con người tác động lên Reddit. Chúng tôi tìm thấy rằng (1) cảm nhận của một chú robot có ảnh hưởng quan trọng, tích cực lên câu trả lời con người sau đó, và (2) người dùng của Reddit sửa đổi hành vi bình luận của họ để chồng chéo với văn bản của robot, giống như cách con người sửa đổi văn bản để bắt chước người khác trong cuộc đối thoại. Biết được tương đối đơn giản về tương đối tác tác của con người và robot là điều quan trọng để chuẩn bị thực vật học phát triển trong tương lai.', 'da': 'Automatiserede agenter ("bots") er dukket op som en allestedsnærværende og indflydelsesrig tilstedeværelse på sociale medier. Bots engagerer sig på sociale medieplatforme ved at sende indhold og svare til andre brugere på platformen. I dette arbejde gennemfører vi en empirisk analyse af aktiviteten af en enkelt bot på Reddit. Vores mål er at afgøre, om bot aktivitet (i form af offentliggjorte kommentarer på hjemmesiden) har en indflydelse på, hvordan mennesker engagerer sig på Reddit. Vi finder ud af, at (1) følelsen af en bot kommentar har en betydelig, positiv effekt på det efterfølgende menneskelige svar, og (2) menneskelige Reddit-brugere ændrer deres kommentarsadfærd til at overlappe teksten i bot, svarende til hvordan mennesker ændrer deres tekst til at efterligne andre mennesker i samtale. At forstå menneske-bot interaktioner på sociale medier med relativt enkle bots er vigtigt for at forberede sig på mere avancerede bots i fremtiden.', 'bg': 'Автоматизираните агенти ("ботове") се появиха като повсеместно и влиятелно присъствие в социалните медии. Ботовете се ангажират в социалните медийни платформи, като публикуват съдържание и отговарят на други потребители на платформата. В тази работа правим емпиричен анализ на дейността на един бот в Редит. Нашата цел е да определим дали бот активността (под формата на публикувани коментари на уебсайта) има ефект върху това как хората се ангажират с Редит. Намираме, че (1) настроението на бот коментар има значителен положителен ефект върху последващия човешки отговор и (2) човешките потребители модифицират поведението си за коментари, за да се припокриват с текста на бота, подобно на начина, по който хората модифицират текста си, за да имитират други хора в разговора. Разбирането на взаимодействията между човек и бот в социалните медии с относително прости ботове е важно за подготовката за по-напреднали ботове в бъдеще.', 'hr': "Automatizirani agenti ('botovi') pojavili su se kao svuda i utjecajna prisutnost na društvene medije. Botovi se uključuju na platforme društvenih medija postavljajući sadržaj i odgovarajući drugim korisnicima na platformi. U ovom poslu vodimo empiričku analizu aktivnosti jednog robota na Reddit-u. Naš cilj je utvrditi da li aktivnost bota (u obliku postavljenih komentara na web stranici) utječe na način kako ljudi učestvuju na Reddit. Nalazimo da (1) osjećaj komentara bot a ima značajan, pozitivan učinak na sljedeći ljudski odgovor, a (2) ljudski korisnici Reddit modifikuju svoje ponašanje komentara kako bi se preklapali s tekstom bota, sličan na način kako ljudi modifikuju svoj tekst za imitiranje drugih ljudi u razgovoru. Razumijevanje interakcija s ljudskim robotima na društvenim medijima s relativno jednostavnim robotima važno je za pripremu za naprednije robote u budućnosti.", 'nl': "Automated agents ('bots') zijn uitgegroeid tot een alomtegenwoordige en invloedrijke aanwezigheid op sociale media. Bots nemen deel aan sociale media platforms door content te plaatsen en te reageren op andere gebruikers op het platform. In dit werk voeren we een empirische analyse uit van de activiteit van een enkele bot op Reddit. Ons doel is om te bepalen of botactiviteit (in de vorm van geposte reacties op de website) een effect heeft op hoe mensen omgaan met Reddit. We vinden dat (1) het sentiment van een botsopmerking een significant, positief effect heeft op het volgende menselijke antwoord, en (2) menselijke Reddit gebruikers hun commentaargedrag aanpassen om te overlappen met de tekst van de bot, vergelijkbaar met hoe mensen hun tekst aanpassen om andere mensen in gesprek na te bootsen. Het begrijpen van mens-bot interacties op sociale media met relatief eenvoudige bots is belangrijk voor de voorbereiding op meer geavanceerde bots in de toekomst.", 'fa': "ماموران اتوماتیک ('bots') به عنوان حضور جامعه و تاثیر در رسانه\u200cهای اجتماعی ظاهر شدند. Bots engage on social media platforms by sending content and replying to other users on the platform. ما در این کار یک تحلیل امپراتیک از فعالیت یک روبات روی ردیدت انجام می دهیم. هدف ما این است که تصمیم بگیریم که آیا فعالیت bot (به شکل توضیح\u200cهای فرستاده شده روی وبسایت) تاثیر روی چگونه انسان\u200cها روی Reddit درگیر می\u200cشوند. ما پیدا می\u200cکنیم که (۱) احساس یک توضیح ربات اثر مهم و مثبتی بر پاسخ انسان بعدی دارد، و (۲) کاربران Reddit انسان رفتارهای توضیح خود را تغییر می\u200cدهند تا با متن ربات تغییر دهند، مانند اینکه چگونه مردم متن خود را به انسان دیگر در صحبت تغییر می\u200cدهند. درک تعاملات انسان-ربات در رسانه های اجتماعی با رات نسبتا ساده برای آماده کردن رات های پیشرفت بیشتری در آینده مهم است.", 'sw': "Watumishi wa kujitegemea ('bots') wamejitokeza kama uwepo wa usawa na ushawishi katika mitandao ya kijamii. Wote wawili wanahusiana na majukwaa ya mitandao ya kijamii kwa kutuma maudhui na kuwajibu watumiaji wengine kwenye jukwaa hili. Katika kazi hii tunafanya uchambuzi wa msisimko wa shughuli za boti moja kwenye Reddit. Lengo letu ni kuamua kama shughuli za bot (kwa namna ya maoni yaliyochapishwa kwenye tovuti) inaathiri jinsi watu wanavyojihusisha na Reddit. Tunaona (1) hisia za maoni ya bot in a madhara makubwa, yenye chanya juu ya majibu ya binadamu yaliyofuata, na (2) watumiaji wa Reddit wanabadilisha tabia zao za maoni ili kuzipungua kwa maandishi ya bot, kama vile binadamu wanavyobadilisha ujumbe wao kwa kuwachanganya watu wengine katika mazungumzo. Kuelewa na mahusiano ya kibinadamu kwenye mitandao ya kijamii yenye boti rahisi kwa kiasi kikubwa ni muhimu kwa ajili ya kuandaa boti zilizoendelea zaidi mbeleni.", 'tr': "Otomatik aģentler sosyal medýdanlaryň üstünde ýerleşýän we täsirli bolup göründi. Botlar sosyal medýat platformlarynda maksady gönderip, plataforma başga ullanlara jogap berýärler. Bu işde Reddit'da ýeke bir bot etkinleşiginiň empirik analyzasyny çykýarys. Bizim amacımız, bot etkinliğin in (web sitesinde gönderilmiş tercihler şeklinde) insan Reddit'e nasıl etkisi yaratıp kabul etmek. Biz bot tercihlerinin duygularının (1) ardınca insan cevabına önemli, pozitif etkisi bar ve (2) insan Reddit kullanıcıları, bu şekilde bot metinlerini doldurmak için tercihlerini değiştirirler ve insanların metinlerini konuşmada başka insanlara tanıtması gibi değiştirirler. Adamlar-botlary sosyal medýýatlarynda görä basit botlar bilen düşünmek gelejekde gelişmi botlar üçin taýýarlanmak üçin wajyp däldir.", 'af': "Outomatiese agente ('bots') het as 'n omgewing en influensielike aangesig op sosiale media opgevind. Bots staan op sosiale media platforme deur inhoud en antwoord aan ander gebruikers op die platforme te stuur. In hierdie werk doen ons 'n empiriese analiseer van die aktiviteit van 'n enkele bot op Reddit. Ons doel is om te bepaal of bot-aktiwiteit (in die vorm van opgestelde kommentaar op die webwerk)  'n effek het op hoe mense op Reddit aantrek. Ons vind dat (1) die sentiment van 'n bot kommentaar 'n betekende, positiewe effek het op die volgende menslike antwoord, en (2) menslike Reddit gebruikers verander hulle kommentaar gedrag om oorvloei te word met die teks van die bot, soos mense hulle teks verander na mimie ander mense in gesprek. Die verstaan van mens-bot interaksies op sosiale media met relativies eenvoudige bots is belangrik vir die voorbereiding van meer gevorderde bots in die toekoms.", 'de': 'Automatisierte Agenten ("Bots") haben sich zu einer allgegenwärtigen und einflussreichen Präsenz in sozialen Medien entwickelt. Bots interagieren auf Social-Media-Plattformen, indem sie Inhalte posten und anderen Nutzern auf der Plattform antworten. In dieser Arbeit führen wir eine empirische Analyse der Aktivität eines einzelnen Bots auf Reddit durch. Unser Ziel ist es herauszufinden, ob Bot-Aktivität (in Form von Kommentaren auf der Website) einen Einfluss darauf hat, wie Menschen auf Reddit interagieren. Wir stellen fest, dass (1) die Stimmung eines Bot-Kommentars einen signifikanten, positiven Effekt auf die nachfolgende menschliche Antwort hat, und (2) menschliche Reddit-Benutzer ihr Kommentarverhalten so ändern, dass es sich mit dem Text des Bots überschneidet, ähnlich wie Menschen ihren Text ändern, um andere Menschen im Gespräch nachzuahmen. Das Verständnis von Mensch-Bot-Interaktionen in sozialen Medien mit relativ einfachen Bots ist wichtig, um sich auf fortgeschrittenere Bots in Zukunft vorzubereiten.', 'ko': '자동 에이전트(Automated agents, 약칭 로봇)는 소셜 미디어에서 어디에나 존재하고 영향력이 있는 존재가 되었다.로봇은 콘텐츠 게시와 답변 플랫폼의 다른 사용자를 통해 소셜미디어 플랫폼에 참여한다.이 작업에서 우리는 Reddit의 단일 로봇의 활동에 대해 실증 분석을 진행하였다.우리의 목표는 로봇 활동(사이트에 논평을 올리는 형식)이 인류가 레딧에 참여하는 방식에 영향을 미칠지 확인하는 것이다.우리는 (1) 로봇 평론의 정서가 후속적인 인류 회복에 현저한 긍정적인 영향을 미친다는 것을 발견했다. (2) 인간Reddit 사용자는 로봇의 텍스트와 중첩되도록 평론 행위를 수정했다. 이는 인류가 다른 사람이 대화하는 방식을 모방하는 것과 유사하다.소셜 미디어에서 상대적으로 간단한 로봇과 인간과 기계의 상호작용을 이해하는 것은 장래에 더욱 선진적인 로봇을 위해 준비하는 데 매우 중요하다.', 'am': 'የተመሳሳይ ተሟጋቾች በማኅበራዊ ሚዲያ ላይ ጥያቄ እና የበለጠ ጥያቄ ሆነው አወጡ፡፡ ሁለታቸው በማኅበራዊ ሚዲያ ፕላጦማር ላይ ተግባራሉ፡፡ በዚህ ስራ ላይ አንድ ቦት በReddit ላይ የሚደረገውን የማስተማርን አስተያየት እናደርጋለን፡፡ የእኛ ጉዳዩ የቦት ተግባር (በጦማሪያው ላይ የመስመር ትርጓሜ) ሰዎች በReddit ላይ እንዴት እንደሚያጋራሉ እንደሆነ ማረጋገጥ ነው፡፡ (1) የመስመር አስተያየት በሚከተለው ሰው መልስ ላይ ታላቅ፣ positive ጥያቄ አለበት እና (2) የሰው ሬድድድድ ተጠቃሚዎች የጽሑፎችን ጽሑፍ በመጠቀም ይለውጣሉ፡፡ Understanding human-bot interactions on social media with relatively simple bots is important for preparing for more advanced bots in the future.', 'hy': "Ավտոմացված գործակալները ('ռոբոտները') հայտնվել են որպես ամենուրեք և ազդեցիկ ներկայություն սոցիալական լրատվամիջոցներում: Բոտոսները գործում են սոցիալական լրատվամիջոցների պլատֆորմերի վրա տեղադրելով պարունակություն և պատասխանելով այլ օգտագործողներին պլատֆորմում: Այս աշխատանքում մենք կատարում ենք մի ռոբոտի Reddit-ի գործունեության էմպիրիկ վերլուծություն: Մեր նպատակն է որոշել, թե արդյոք ռոբոտների գործունեությունը (կայքի վրա տեղադրված մեկնաբանությունների ձևով) ազդում է մարդկանց գործունեության վրա Reddit-ի վրա: Մենք հայտնաբերում ենք, որ (1) ռոբոտի մեկնաբանության զգացմունքը նշանակալի, դրական ազդեցություն ունի հետագա մարդկային պատասխանի վրա, և (2) մարդկային Ռեդդիթի օգտագործողները փոխում են իրենց մեկնաբանական վարքագիծը, որպեսզի կապված լինեն ռոբոտի տեքստի հետ, նման այն բանի, թե ինչպես են մարդիկ փոխում իրենց Մարդիկ-ռոբոտների փոխազդեցությունները հասկանալը սոցիալական լրատվամիջոցների հետ համեմատաբար պարզ ռոբոտների հետ կարևոր է ապագայում ավելի զարգացած ռոբոտների պատրաստման համար:", 'az': "Avtomatik ań£entl…ôr ('bot') sosyal medya vasit…ôl…ôrind…ô h…ôr…ôk…ôtsiz v…ô t…ôsirli bir m…ôlumat olaraq ortaya √ßńĪxdńĪ. Botlar sosyal media platformlarńĪna m…ôlumat g√∂nd…ôr…ôr v…ô platformdakńĪ baŇüqa istifad…ô√ßil…ôr…ô cavab ver…ôrl…ôr. Bu iŇüd…ô Reddit'd…ô bir botun f…ôaliyy…ôtinin empirik analizi idar…ô edirik. Bizim m…ôqs…ôdimiz, bot aktivit…ôsinin (web sit…ôsind…ô g√∂nd…ôrilmiŇü Ňü…ôhad…ôtl…ôr kimi) insanlarńĪn Reddit-…ô nec…ô iŇütirak etdiyini t…ôsdiql…ôm…ôkdir. Bir bot komentarńĪnńĪn hissi sonrakńĪ insan cavabńĪnda m√∂vcuddur, pozitiv etkisi var v…ô insan Reddit istifad…ô√ßil…ôri √∂z komentar davranńĪŇülarńĪnńĪ bot m…ôktubu il…ô doldurmaq √ľ√ß√ľn d…ôyiŇüdirirl…ôr, insanlarńĪn m…ôktubu bar…ôsind…ô dig…ôr insanlara mimik etm…ôk √ľ√ß√ľn nec…ô d…ôyiŇüdirirl…ôr. ńįnsan-bot m√ľxt…ôlif m…ôlumatlarńĪ sosyal mediyalarńĪnda √ßox asan robot il…ô anlamaq g…ôl…ôc…ôkd…ô daha geliŇümiŇü robot √ľ√ß√ľn hazńĪrlanmaq vacibdir.", 'bn': "স্বয়ংক্রিয় এজেন্টরা ('বট') সামাজিক প্রচার মাধ্যমে এক বিচ্ছিন্ন এবং প্রভাবিত উপস্থিতি হিসেবে উঠেছে। এই প্ল্যাটফর্মে অন্যান্য ব্যবহারকারীদের প্রতিক্রিয়া পোস্ট করে সামাজিক প্রচার মাধ্যমের প্ল্যাটফর্মে উভয় এই কাজে আমরা রেডিডের একটা বোটের কার্যক্রমের একটি উদারীন বিশ্লেষণ করি। আমাদের লক্ষ্য হচ্ছে বোট কার্যক্রম নির্ধারণ করা (ওয়েবসাইটে পোস্ট করা মন্তব্যের মত) কিভাবে মানুষ রেডিডিটে যোগাযোগ করে তার প্রভা আমরা দেখতে পাচ্ছি (১) একটি বক্তব্যের অনুভূতি পরবর্তী মানুষের উত্তরের উপর গুরুত্বপূর্ণ, ইতিবাচক প্রভাব রয়েছে, আর (২) মানুষ রেডিড ব্যবহারকারীরা তাদের মন্তব্যের আচরণ পরিবর্তন করেছে বটে ভবিষ্যতে আরো উন্নত বট প্রস্তুত করার জন্য মানুষ-বটের মাধ্যমে সামাজিক প্রচার মাধ্যমের মাধ্যমে মানুষের বোট ইন্টারনেটসে", 'ca': "Els agents automàtics ('robots') han sorgit com una presença ubicada i influent als mitjans socials. Els robots s'impliquen en plataformes de mitjans socials publicant continguts i responent a altres usuaris a la plataforma. En aquest treball fem una an àlisi empírica de l'activitat d'un únic robot en Reddit. El nostre objectiu és determinar si l'activitat dels robots (en forma de comentaris publicats a la pàgina web) té un efecte en com els humans s'impliquen en Reddit. Trobem que (1) el sentiment d'un comentari de robots té un efecte significatiu i positiu en la resposta human a posterior, i (2) els usuaris humans de Reddit modifiquen els seus comportaments de comentari per sobrepondre-se amb el text del robot, semblant a com els humans modifiquen el seu text per imitar altres humans en conversa. Entendre les interaccions entre humans i robots en els mitjans socials amb robots relativament senzills és important per preparar-se per robots més avançats en el futur.", 'cs': 'Automatizovaní agenti ("roboti") se objevili jako všudypřítomná a vlivná přítomnost na sociálních médiích. Boti se angažují na platformách sociálních médií zveřejňováním obsahu a odpovědí ostatním uživatelům na platformě. V této práci provádíme empirickou analýzu aktivity jednoho bota na Redditu. Naším cílem je zjistit, zda aktivita bot (ve formě zveřejněných komentářů na webových stránkách) má vliv na to, jak se lidé angažují na Reddit. Zjišťujeme, že (1) sentiment komentáře bota má významný, pozitivní vliv na následnou lidskou odpověď a (2) lidští uživatelé Redditu upravují své chování komentářů tak, aby se překrývali s textem bota, podobně jako lidé upravují svůj text tak, aby napodobovali ostatní lidi v konverzaci. Porozumění interakcím člověka-bota na sociálních médiích s relativně jednoduchými boty je důležité pro přípravu na pokročilejší boty v budoucnosti.', 'et': 'Automaatsed agendid ("botid") on sotsiaalmeedias levinud kõikjal leviva ja mõjuka kohalolekuna. Botid osalevad sotsiaalmeedia platvormidel, postitades sisu ja vastates teistele platvormil kasutajatele. Käesolevas töös teostame empiirilise analüüsi ühe boti aktiivsusest Redditis. Meie eesmärk on kindlaks teha, kas botide tegevus (veebilehel postitatud kommentaaride kujul) mõjutab inimeste tegevust Redditis. Leiame, et (1) boti kommentaari tunded avaldavad märkimisväärset positiivset mõju järgnevale inimese vastusele ja (2) Redditi kasutajad muudavad oma kommentaaride käitumist nii, et kattuda boti tekstiga, sarnaselt sellele, kuidas inimesed muudavad oma teksti, et jäljendada teisi inimesi vestluses. Suhteliselt lihtsate botidega inimeste ja botide suhtlemise mõistmine sotsiaalmeedias on oluline arenenumate botide ettevalmistamiseks tulevikus.', 'id': "Agen otomatis ('robot') telah muncul sebagai kehadiran di mana-mana dan mempengaruhi media sosial. Bots engage on social media platforms by posting content and replying to other users on the platform.  In this work we conduct an empirical analysis of the activity of a single bot on Reddit.  Tujuan kita adalah untuk menentukan apakah aktivitas robot (dalam bentuk komentar yang ditempatkan di situs) memiliki efek pada bagaimana manusia terlibat di Reddit. Kami menemukan bahwa (1) perasaan komentar robot memiliki efek yang signifikan, positif pada jawaban manusia berikutnya, dan (2) pengguna Reddit manusia mengubah perilaku komentar mereka untuk meliputi teks robot, mirip dengan bagaimana manusia mengubah teks mereka untuk meniru manusia lain dalam percakapan. Memahami interaksi manusia-robot di media sosial dengan robot relatif sederhana adalah penting untuk mempersiapkan untuk robot yang lebih maju di masa depan.", 'sq': "Agjentët e automatizuar ('robotët') janë shfaqur si një prani kudo dhe ndikuese në media sociale. Botët angazhohen në platforma të medias sociale duke publikuar përmbajtjen dhe duke u përgjigjur përdoruesve të tjerë në platform ë. Në këtë punë ne kryejmë një analizë empirike të aktivitetit të një roboti të vetëm në Reddit. Qëllimi ynë është të përcaktojmë nëse aktiviteti i robotëve (në form ën e komenteve të publikuara në uebsajt) ka një ndikim në mënyrën se si njerëzit angazhohen në Reddit. We find that (1) the sentiment of a bot comment has a significant, positive effect on the subsequent human reply, and (2) human Reddit users modify their comment behaviors to overlap with the text of the bot, similar to how humans modify their text to mimic other humans in conversation.  Përkuptimi i ndërveprimeve njerëz-robot në mediat sociale me robotë relativisht të thjeshtë është i rëndësishëm për përgatitjen për robotë më të avancuar në të ardhmen.", 'fi': 'Automatisoidut agentit ("botit") ovat nousseet kaikkialle ulottuvaksi ja vaikutusvaltaiseksi toimijaksi sosiaalisessa mediassa. Botit toimivat sosiaalisen median alustoilla julkaisemalla sisältöä ja vastaamalla muille käyttäjille alustalla. Tässä työssä teemme empiirisen analyysin yksittäisen botin toiminnasta Redditissä. Tavoitteenamme on selvittää, vaikuttaako bottien toiminta (sivustolla julkaistujen kommenttien muodossa) siihen, miten ihmiset osallistuvat Redditiin. Huomaamme, että (1) bottikommentin tunteella on merkittävä positiivinen vaikutus myöhempään ihmisen vastaukseen ja (2) Reddit-käyttäjät muokkaavat kommentointikäyttäytymistään päällekkäin botin tekstin kanssa, kuten ihmiset muokkaavat tekstiään jäljittelemään muita ihmisiä keskustelussa. Ihmisten ja bottien vuorovaikutuksen ymmärtäminen sosiaalisessa mediassa suhteellisen yksinkertaisilla boteilla on tärkeää valmistautua edistyneempiin botteihin tulevaisuudessa.', 'bs': "Automatizirani agenti ('botovi') pojavili su se kao svuda i utjecajna prisutnost na društvene medije. Botovi se uključuju na platforme društvenih medija, postavljajući sadržaj i odgovarajući drugim korisnicima na platformi. U ovom poslu vodimo empiričku analizu aktivnosti jednog robota na Reddit-u. Naš cilj je da utvrdimo da li aktivnost robota (u obliku postavljenih komentara na sajtu) ima utjecaj na način da ljudi učestvuju na Reddit. Nalazimo da (1) osjećaj komentara robota ima značajan, pozitivan učinak na sljedeći ljudski odgovor, a (2) ljudski korisnici Reddit modifikuju svoje ponašanje komentara kako bi se preklapali sa tekstom robota, sličan na način kako ljudi modifikuju svoj tekst za imitiranje drugih ljudi u razgovoru. Razumijevanje interakcija ljudskih robota na društvenim medijima sa relativno jednostavnim robotima je važno za pripremu za naprednije robote u budućnosti.", 'ha': "Madagaskiyar masu farat ɗaya ('botsu') sun fita kamar wani sharri da mai shagala a kan mita jami. Dukkansu sunã aiki a kan platformi na mitandai da jamii da kuma sunã poster maɓallin su da wasu mãsu amfani da shi a kan platform. Daga wannan aikin da Muke sami wani anayyari na aikin aiki na Rededit. Gagonmu na wajen zartar da aikin bot (cikin fomat wanda aka poste wa mawaƙa a website) yana da amfani da jinsi mutane za'a yi amfani da Rededit. We find that (1) the sentiment of a bot comment has a significant, positive effect on the subsequent human reply, and (2) human Reddit users modify their comment behaviors to overlap with the text of the bot, similar to how humans modify their text to mimic other humans in conversation.  Ina fahimta interaction a kan mutane a kan mitandaya da sauti masu sauki, kuma yana da muhimu wa yi tattalin matofati masu ƙari.", 'sk': 'Avtomatizirani agenti ("boti") so se pojavili kot vseprisotna in vplivna prisotnost na družbenih omrežjih. Boti sodelujejo na platformah družbenih omrežij tako, da objavljajo vsebino in odgovarjajo drugim uporabnikom na platformi. V tem delu izvajamo empirično analizo aktivnosti enega samega bota na Redditu. Naš cilj je ugotoviti, ali aktivnost botov (v obliki objavljenih komentarjev na spletni strani) vpliva na to, kako ljudje sodelujejo v Redditu. Ugotavljamo, da ima (1) občutek botovega komentarja pomemben, pozitiven učinek na naslednji človeški odgovor, in (2) človeški uporabniki Reddita spremenijo svoje vedenje komentarjev tako, da se prekrivajo z besedilom bota, podobno kot človek spreminja svoje besedilo tako, da posnema druge ljudi v pogovoru. Razumevanje interakcij med človekom in botom na družbenih omrežjih z relativno preprostimi boti je pomembno za pripravo na naprednejše bote v prihodnosti.', 'he': "סוכנים אוטומטיים ('רובוטים') הופיעו כנוכחות בכל מקום ושפעה בתקשורת חברתית. רובוטים מתעסקים במפלטפורמות תקשורת חברתית על ידי פרסום תוכן ותגובה למשתמשים אחרים על הפלטפורמה. בעבודה הזאת אנו מבצעים ניתוח אמפירי של פעילות של רובוט אחד על רדיט. Our goal is to determine whether bot activity (in the form of posted comments on the website) has an effect on how humans engage on Reddit.  We find that (1) the sentiment of a bot comment has a significant, positive effect on the subsequent human reply, and (2) human Reddit users modify their comment behaviors to overlap with the text of the bot, similar to how humans modify their text to mimic other humans in conversation.  Understanding human-bot interactions on social media with relatively simple bots is important for preparing for more advanced bots in the future.", 'jv': "Automated tools ('bots') popongdepan nganggo sistem Ubquity bots Nang barêng-barêng iki kita gewis ngerasakno empir kanggo ngilangno ning arep bot sing nyebutne ning Redit. Kita goal punika mbukakipun punika ingkang sampeyan ginayut bot (liyane komentar anyar tentang ing website) sak dadi kapan babagan barang resmi ingkang Redit. Awak dhéwé nglanggar luwih (1) kelangan sampek bot sing dumateng nêmên, nguasai kapan sing dirampakan nganggep bantêr dumadhi iki, lan (2) usurpi nguasai perbudhakan hikayé supayakno sampek karo akeh bot sing nêmên ngerasai winih sampek karo hal sampek wong liyané uwong nggawe ngubah gambaran wong iki sampek Awakdhéwé ngerasahaan bot-bot sing mengko nang media sotiki dadi iki luwih apik sing dikarepaké kanggo nggawe bot sing luwih bantuan kanggo bisa dumadhi iki.", 'bo': 'རང་འགུལ་གྱིས་བདག་པོ་ཚོགས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་ཏུ་ཐད་མེད་པ་དང་ཁོང་ཚོའི་ནང་དུ་ཡོད། སྒོ་ཆས་འདིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་གླེང་སྟེང་གི་ནང་དོན་འདྲ་བཤུ་བྱེད་བཞིན་པའི་ལག་ལེན་པ་གཞན་དང འོན་ཀྱང་། ང་ཚོས་རྩོལ་འདིའི་ནང་དུ་Reddit ཡི་སྒེར་གྱི་གཏོང་འབྲེལ་གྱི་ཐག་རིམ་པ་ཞིག་གི་དབྱེ་ཞིབ་བྱེད་ ང་ཚོའི་དམིགས་ཡུལ་ནི་རྒྱ་ནག་གིས་མི་སྒེར་གྱི་ལས་འགུལ་བཤད་ཀྱི་ནང་དུ་འགྲེལ་བཤད་པ་ཞིག་ཡིན་མིན་ན། ང་ཚོས་བརྗེད་ཀྱི་རང་འགུལ་གྱི་ཐད་ཚོར་༡་ནི་མིའི་གནད་སྡུད་མི་མང་གི་ལན་གསལ་བ་ཞིག་ཡོད་པ་དང་། རང་ཉིད་ཀྱི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་དང་མཐུན་སྐྱེས་པའི་ལག་ལེན་གྱིས་མཐུན་འགྱུར་བ་ནི་མ་འོངས་ལ་རང་ཉིད་སྔ་གོང་རང་'}
{'en': 'Detecting Trending Terms in Cybersecurity Forum Discussions', 'fr': 'Détecter les termes tendance dans les discussions du Forum Cybersécurité', 'pt': 'Detectando termos de tendências nas discussões do fórum de segurança cibernética', 'ar': 'الكشف عن المصطلحات الشائعة في مناقشات منتدى الأمن السيبراني', 'es': 'Detección de términos de tendencia en los debates del foro de ciberseguridad', 'ja': 'サイバーセキュリティフォーラムのディスカッションにおけるトレンド用語の検出', 'zh': '检网络安全论坛议中热门术语', 'ru': 'Обнаружение трендовых терминов в дискуссиях на форуме по кибербезопасности', 'hi': 'साइबर सुरक्षा मंच चर्चाओं में ट्रेंडिंग शर्तों का पता लगाना', 'ga': 'Téarmaí Treochta a Bhrath i gCainteanna an Fhóraim Cybersecurity', 'ka': 'კიბერსუკური ფორმის დისუციების განსაზღვრება', 'el': 'Ανίχνευση εξελισσόμενων όρων σε συζητήσεις φόρουμ για την ασφάλεια στον κυβερνοχώρο', 'hu': 'Trending kifejezések észlelése a kiberbiztonsági fórum megbeszéléseiben', 'lt': 'Kibernetinio saugumo forumo diskusijų tendencijų nustatymas', 'mk': 'Детектирање на тенденциите во дискусиите на Форумот за кибербезбедност', 'kk': 'Кибер қауіпсіздік форумындағы тегіс уақыттарды анықтау', 'it': 'Rilevare i termini di tendenza nelle discussioni del forum sulla sicurezza informatica', 'ms': 'Mengesan Terma Kebenaran dalam Perbincangan Forum Keselamatan Cyber', 'mt': 'L-identifikazzjoni tat-Termini tax-Xejra fid-Diskussjonijiet tal-Forum dwar iċ-Ċibersigurtà', 'mn': 'Цөмийн аюулгүй байдлын форумын ярилцлагуудыг олох үед', 'ml': 'സൈബര്\u200d സെക്യൂരിറ്റി ഫോര്\u200dമിലെ ട്രെന്\u200dഡിങ്ങ് ടെര്\u200dമുകള്\u200d കണ്ടുപിടിക്കുന്നു', 'no': 'Oppdagar trending- terminar i sybersecurity Forum diskusjonar', 'pl': 'Wykrywanie trendujących terminów w dyskusjach na forum cyberbezpieczeństwa', 'ro': 'Detectarea termenilor în tendință în discuțiile forumului de securitate cibernetică', 'sr': 'Otkrivanje treninga u raspravama foruma za sajber sigurnost', 'so': 'Ku baaraandegista daryeelka jardiinada ee waraamka ammaanka ee Internetka', 'si': 'සයිබර් සුරක්ෂාත්මක ප්\u200dරශ්නයක් විශ්වාස කරනවා', 'sv': 'Att upptäcka trendiga termer i diskussioner om cybersäkerhet', 'ta': 'சைபர் பாதுகாப்பு Forum விசைப்பற்றிய முறைகளை கண்டறிதல்', 'ur': 'سایر سیبرسی فورمی بحث میں ترینڈ ٹرینگ ٹرینگ ٹرینگ ٹرینگ ٹرینگ ٹرینگ', 'uz': 'Name', 'vi': 'Phát hiện xu hướng trong cuộc thảo luận ủy ban an ninh mạng', 'bg': 'Откриване на тенденциите във форума за киберсигурност', 'nl': 'Detecteren van trending terms in discussies over cybersecurity Forum', 'hr': 'Otkrivanje određenih trajanja u forumu za sajber sigurnost', 'da': 'Opdagelse af trending termer i forum om cybersikkerhed', 'de': 'Erkennen von Trendbegriffen in Diskussionen im Cybersecurity Forum', 'id': 'Mengeteksi Terma Trending dalam diskusi Forum Keamanan Sibernetik', 'fa': 'شناسایی کلمه\u200cهای تدریج در مجادله\u200cهای فورمی سایر محافظت', 'sw': 'Kugundua Matukio ya Kutetea katika Jukwaa la Usalama wa Mtandao', 'tr': 'Kibersekretesler forum diskusiýasynda ýaramak sözlerni tanyşdyrylýa', 'af': 'Ontvang Trending Terms in Sibersekuriteit Forum Diskussies', 'sq': 'Duke zbuluar kushtet e prirjes në diskutimet e forumit të sigurisë kibernetike', 'am': 'Detecting Trending Terms in Cybersecurity Forum Discussions', 'hy': 'Detecting Trending Terms in Cybersecurity Forum Discussions', 'az': 'Siberi t톛hl칲k톛sizlik Forum m칲zakir톛l톛ri', 'bn': 'সাইবার নিরাপত্তা ফোরামের আলোচনায় ট্র্যান্ডিং টার্ম সনাক্ত করা হচ্ছে', 'bs': 'Otkrivanje određenih trajanja u forumu za sajber sigurnost', 'ko': '네트워크 보안 포럼 토론에서 트렌드 용어 발견', 'cs': 'Detekce trendujících podmínek v diskusích o kybernetické bezpečnosti', 'et': 'Trendivate terminite tuvastamine küberturvalisuse foorumi aruteludes', 'ca': 'Detecting Trending Terms in Cybersecurity Forum Discussions', 'fi': 'Uusien termien havaitseminen kyberturvallisuusfoorumissa Keskustelut', 'jv': 'Perintah kang didasai sawar', 'sk': 'Odkrivanje trenutnih pogojev v forumu kibernetske varnosti', 'he': 'גילוי תנאים נודדים בפורום ביטחון סייבר', 'ha': 'KCharselect unicode block name', 'bo': 'ཆུ་ཚོད་ལྟར་མཚམས་སྦྱར་བའི་ཆུ་ཚོད་ལྟར་བསམ་བྱེད་པ'}
{'en': 'We present a lightweight method for identifying currently trending terms in relation to a known prior of terms, using a weighted log-odds ratio with an informative prior. We apply this method to a dataset of posts from an English-language underground hacking forum, spanning over ten years of activity, with posts containing misspellings,  orthographic variation ,  acronyms , and  slang . Our statistical approach supports analysis of linguistic change and discussion topics over time, without a requirement to train a  topic model  for each time interval for analysis. We evaluate the approach by comparing the results to TF-IDF using the discounted cumulative gain metric with human annotations, finding our method outperforms TF-IDF on  information retrieval .', 'ar': 'نقدم طريقة خفيفة لتحديد المصطلحات الشائعة حاليًا فيما يتعلق بمصطلحات سابقة معروفة ، باستخدام نسبة مرجحة لوغاريتمية مرجحة مع معلومات مسبقة. نحن نطبق هذه الطريقة على مجموعة بيانات من المنشورات من منتدى قرصنة تحت الأرض باللغة الإنجليزية ، يمتد لأكثر من عشر سنوات من النشاط ، مع مشاركات تحتوي على أخطاء إملائية وتنوع إملائي ومختصرات ولغة عامية. يدعم نهجنا الإحصائي تحليل التغيير اللغوي وموضوعات المناقشة بمرور الوقت ، دون الحاجة إلى تدريب نموذج موضوع لكل فترة زمنية للتحليل. نقوم بتقييم النهج من خلال مقارنة النتائج مع TF-IDF باستخدام مقياس الكسب التراكمي المخصوم مع التعليقات التوضيحية البشرية ، وإيجاد طريقتنا تتفوق على TF-IDF في استرجاع المعلومات.', 'es': 'Presentamos un método ligero para identificar los términos actuales de tendencia en relación con un anterior conocido, utilizando una relación de probabilidades logarítmicas ponderada con un previo informativo. Aplicamos este método a un conjunto de datos de publicaciones de un foro clandestino de hackeo en inglés, que abarca más de diez años de actividad, con publicaciones que contienen errores ortográficos, variaciones ortográficas, acrónimos y jerga. Nuestro enfoque estadístico apoya el análisis del cambio lingüístico y los temas de discusión a lo largo del tiempo, sin necesidad de entrenar un modelo de tema para cada intervalo de tiempo para el análisis. Evaluamos el enfoque comparando los resultados con TF-IDF utilizando la métrica de ganancia acumulada con descuento con anotaciones humanas, descubriendo que nuestro método supera a TF-IDF en la recuperación de información.', 'pt': 'Apresentamos um método leve para identificar termos atuais em tendência em relação a um anterior de termos conhecido, usando uma razão log-odds ponderada com um anterior informativo. Aplicamos esse método a um conjunto de dados de postagens de um fórum clandestino de hackers em inglês, abrangendo mais de dez anos de atividade, com postagens contendo erros de ortografia, variação ortográfica, siglas e gírias. Nossa abordagem estatística suporta a análise de mudanças linguísticas e tópicos de discussão ao longo do tempo, sem a necessidade de treinar um modelo de tópico para cada intervalo de tempo para análise. Avaliamos a abordagem comparando os resultados ao TF-IDF usando a métrica de ganho cumulativo descontado com anotações humanas, descobrindo que nosso método supera o TF-IDF na recuperação de informações.', 'fr': "Nous présentons une méthode légère pour identifier des termes courants en relation avec un antérieur connu de termes, en utilisant un ratio log-cotes pondéré avec un précédent informatif. Nous appliquons cette méthode à un ensemble de publications provenant d'un forum de piratage clandestin en anglais, couvrant plus de dix ans d'activité, avec des publications contenant des fautes d'orthographe, des variations orthographiques, des acronymes et de l'argot. Notre approche statistique prend en charge l'analyse des changements linguistiques et des sujets de discussion au fil du temps, sans qu'il soit nécessaire de former un modèle de sujet pour chaque intervalle de temps d'analyse. Nous évaluons l'approche en comparant les résultats à TF-IDF à l'aide de la métrique de gain cumulé actualisé avec des annotations humaines, constatant que notre méthode surpasse TF-IDF sur la récupération d'informations.", 'ja': '我々は、既知の先行用語に関連して現在の傾向のある用語を識別するための軽量な方法を提示し、情報量の多い先行用語との加重対数比を使用する。この方法は、英語の地下ハッキングフォーラムからの投稿のデータセットに適用されます。10年以上の活動にわたって、投稿にはスペルミス、正書法のバリエーション、頭字語、スラングが含まれています。当社の統計的アプローチは、分析のために各時間間隔のトピックモデルをトレーニングする必要なしに、時間の経過に伴う言語変化とディスカッショントピックの分析をサポートします。割引累積ゲインメトリックとヒトアノテーションを用いてTF - IDFと結果を比較することによりアプローチを評価し、情報検索において当社の方法がTF - IDFよりも優れていることを見出した。', 'zh': '立轻量级法,以知前验项,用加权对数比值息先验。 宜用于英语地下黑客论坛帖数据集,其论坛越十余年,其帖包拼写错误,正字法变体首字母缩略词俚语。 吾计术赞言变与论主随时之变,而无为日月之间练主模形以分之也。 臣等因带人工注折扣积增指标将校TF-IDF之法,见吾法优于信息检索TF-IDF。', 'hi': 'हम वर्तमान में ट्रेंडिंग शब्दों की पहचान करने के लिए एक हल्की विधि प्रस्तुत करते हैं, जो एक जानकारीपूर्ण पूर्व के साथ एक भारित लॉग-ऑड्स अनुपात का उपयोग करके शब्दों के ज्ञात पूर्व के संबंध में है। हम इस विधि को अंग्रेजी भाषा के भूमिगत हैकिंग फोरम से पदों के डेटासेट पर लागू करते हैं, जो दस साल की गतिविधि में फैला हुआ है, जिसमें गलत वर्तनी, ऑर्थोग्राफिक भिन्नता, संक्षिप्त शब्द और स्लैंग युक्त पोस्ट हैं। हमारा सांख्यिकीय दृष्टिकोण समय के साथ भाषाई परिवर्तन और चर्चा विषयों के विश्लेषण का समर्थन करता है, विश्लेषण के लिए प्रत्येक समय अंतराल के लिए एक विषय मॉडल को प्रशिक्षित करने की आवश्यकता के बिना। हम मानव एनोटेशन के साथ रियायती संचयी लाभ मीट्रिक का उपयोग करके परिणामों की तुलना टीएफ-आईडीएफ से करके दृष्टिकोण का मूल्यांकन करते हैं, हमारी विधि को खोजने से जानकारी पुनर्प्राप्ति पर टीएफ-आईडीएफ बेहतर होता है।', 'ru': 'Мы предлагаем облегченный метод идентификации текущих трендовых терминов по отношению к известному предшествующему термину, используя взвешенное соотношение log-odds с информативным предшествующим. Мы применяем этот метод к набору сообщений из англоязычного подпольного форума по взлому, охватывающего более десяти лет деятельности, с сообщениями, содержащими орфографические ошибки, орфографические вариации, акронимы и сленг. Наш статистический подход поддерживает анализ лингвистических изменений и дискуссионных тем с течением времени, без необходимости обучения тематической модели для каждого временного интервала для анализа. Мы оцениваем подход, сравнивая результаты с TF-IDF с использованием метрики дисконтированного совокупного усиления с человеческими аннотациями, обнаруживая, что наш метод превосходит TF-IDF по извлечению информации.', 'ga': 'Cuirimid modh éadrom i láthair chun téarmaí treochta faoi láthair a aithint i ndáil le téarmaí roimhe seo a bhfuil aithne orthu, ag baint úsáide as cóimheas ualaithe log- corrlaigh le réamhfhocal faisnéiseach. Cuirimid an modh seo i bhfeidhm ar thacar sonraí post ó fhóram haca faoi thalamh Béarla, a chuimsíonn breis agus deich mbliana de ghníomhaíocht, ina bhfuil postálacha ina bhfuil mílitrithe, éagsúlacht ortagrafach, acrainmneacha agus slang. Tacaíonn ár gcur chuige staitistiúil le hanailís ar athrú teanga agus ar thopaicí plé le himeacht ama, gan aon ghá le múnla topaicí a oiliúint do gach eatramh ama le haghaidh anailíse. Déanaimid an cur chuige a mheas trí na torthaí a chur i gcomparáid le TF-IDF agus úsáid á baint as an méadrach gnóthachan carnach lascainithe le nótaí daonna, ag fáil amach go sáraíonn ár modh TF-IDF maidir le haisghabháil faisnéise.', 'el': 'Παρουσιάζουμε μια ελαφριά μέθοδο για τον προσδιορισμό τωρινών τάσεων όρων σε σχέση με ένα γνωστό προηγούμενο όρων, χρησιμοποιώντας μια σταθμισμένη αναλογία καταγραφής αποδόσεων με ένα ενημερωτικό προηγούμενο. Εφαρμόζουμε αυτή τη μέθοδο σε ένα σύνολο δεδομένων από ένα αγγλόφωνη υπόγεια φόρουμ χάκερ, που εκτείνεται πάνω από δέκα χρόνια δραστηριότητας, με δημοσιεύσεις που περιέχουν ορθογραφικά λάθη, ορθογραφικές παραλλαγές, ακρωνύμια και αργκό. Η στατιστική προσέγγισή μας υποστηρίζει την ανάλυση γλωσσικών αλλαγών και θεμάτων συζήτησης με την πάροδο του χρόνου, χωρίς να απαιτείται εκπαίδευση ενός μοντέλου θέματος για κάθε χρονικό διάστημα για ανάλυση. Αξιολογούμε την προσέγγιση συγκρίνοντας τα αποτελέσματα με τη χρήση της μετρικής αθροιστικής αύξησης με ανθρώπινα σχόλια, διαπιστώνοντας ότι η μέθοδος μας ξεπερνά την ανάκτηση πληροφοριών.', 'hu': 'Egy könnyű módszert mutatunk be a jelenleg trendező kifejezések azonosítására egy ismert korábbi kifejezéssel kapcsolatban, súlyozott log-odds arány segítségével, információs korábban. Ezt a módszert egy angol nyelvű földalatti hackelési fórum bejegyzéseinek adatkészletére alkalmazzuk, amelyek több mint tíz éves tevékenységet tesznek lehetővé, helyesbírásokat, rövidítéseket és szlenget tartalmaznak. Statisztikai megközelítésünk támogatja a nyelvi változások elemzését és a vitatémák idővel történő megvitatását, anélkül, hogy minden elemzési időintervallumra vonatkozóan témamodellt kellene készíteni. A megközelítést úgy értékeljük, hogy az eredményeket a TF-IDF-hez hasonlítjuk össze a diszkontált kumulatív nyereség metrikával humán megjegyzésekkel, és megállapítjuk, hogy módszerünk felülmúlja a TF-IDF-et az információ lekérdezésében.', 'ka': 'ჩვენ მივიღეთ სიმართლე პროცემის გამოყენება, რომელიც ახლა ინფორმატიური წინ იყენებს ტრენდენციური სიმბოლოების განსაზღვრებისთვის. ჩვენ ეს მეტი დავყენებთ ინგლისური ენაზე ჰაკის ფორმა, რომელიც 10 წლის განმავლობაში გადავყენებთ, რომელიც შეცდომა წერტილება, ორტოგრაფიკური განცვლება, აკრონიმები და სლანგიების განმავლობაში. ჩვენი სტატისტიკური პროგორმა ინტერსტიკური ცვლილების ანალიზაციას და დისუქტიკური ტემების განსაზღვრებას დროში, რომელიც განსაზღვრება არ უნდა ყოველ დროს ინტერუქ ჩვენ გავუმუშავებთ პროგრამის შესაბამისი შედეგები TF-IDF-თან გამოყენებული კუმულატიური მიღება მეტრიკის გამოყენებით ადამიანის ანოტაციებით, რომელიც ჩვენი მეტი გავაკეთება TF-IDF-ს ინ', 'it': "Presentiamo un metodo leggero per identificare i termini di tendenza attualmente in relazione a un precedente di termini noto, utilizzando un rapporto log-odds ponderato con un precedente informativo. Applichiamo questo metodo a un set di post provenienti da un forum underground di hacking in lingua inglese, che copre oltre dieci anni di attività, con post contenenti errori ortografici, variazioni ortografiche, acronimi e gergo. Il nostro approccio statistico supporta l'analisi dei cambiamenti linguistici e gli argomenti di discussione nel tempo, senza l'obbligo di formare un modello di argomento per ogni intervallo di tempo per l'analisi. Valutiamo l'approccio confrontando i risultati con TF-IDF utilizzando la metrica di guadagno cumulativo scontata con annotazioni umane, trovando che il nostro metodo supera TF-IDF nel recupero delle informazioni.", 'lt': 'Pateikiame nedidelį metodą dabartinėms tendencijoms, palyginti su anksčiau žinomais terminais, nustatyti, naudojant svertinį log-odds santykį su informaciniu ankstesniu. Mes taikome šį metodą duomenų rinkiniui iš anglų kalbos po žeme esančio piratavimo forumo, apimančiam daugiau kaip dešimt metų veiklos laikotarpį, su straipsniais, kuriuose yra klaidingi rašymai, ortografiniai variantai, akronimai ir slang. Mūsų statistinis požiūris remia kalbinių pokyčių ir diskusijų temų analizę laikui bėgant, nereikalaujant parengti teminio modelio kiekvienam analizės laikotarpiui. We evaluate the approach by comparing the results to TF-IDF using the discounted cumulative gain metric with human annotations, finding our method outperforms TF-IDF on information retrieval.', 'kk': 'Біз қазіргі тенденциялық тенденциялық тенденциялық тәсілдерді алдындағы тенденциялық тенденциялық тәсілдерді анықтау арқылы, мәліметтік алдындағы тенденциялық тенденциялық қа Бұл әдістерді ағылшын тілінің астындағы хакциялау форумының деректер қорларына қолданамыз. Он жылдан ашық белсенділікті жұмыс істейтін жіберілген жіберілген жіберілген жіберілген жіберілген жіберілг Біздің статистикалық тәсіліміміз уақытта лингвистикалық өзгерістер мен дискуссиялық нақыштарды анализдерді қолдайды, анализ үшін әрбір уақытта нақышты моделін оқыту керек болмаса. Біз тәжірибесін ТF-IDF-мен салыстырып, тәжірибесін адамдардың белгілерімен көмектесілген көмектесу метрикалық көмектесіп, тәжірибесіміздің мәліметті алу үшін TF-IDF-нің шеші', 'mk': 'We present a lightweight method for identifying currently trending terms in relation to a known prior of terms, using a weighted log-odds ratio with an informative prior.  Го применуваме овој метод на податоци на постови од англискиот подземен хакинг форум, кој трае повеќе од десет години активност, со постови кои содржат погрешни писма, ортографска варијација, акроними и сланг. Нашиот статистички пристап ја поддржува анализата на лингвистичките промени и дискусии со текот на времето, без барање за обука на темски модел за секој временски интервал за анализа. Го проценуваме пристапот споредувајќи ги резултатите со TF-IDF користејќи го сконтираниот кумулативен степен со човечките анотации, откривајќи го нашиот метод надминува TF-IDF за преземање информации.', 'ms': 'Kami memperkenalkan kaedah ringan untuk mengenalpasti terma semasa menentang berkaitan dengan terdahulu terma yang diketahui, menggunakan nisbah log-peluang berat dengan terdahulu maklumat. Kami melaksanakan kaedah ini untuk set data pos dari forum hacking bawah tanah bahasa Inggeris, berlangsung lebih dari sepuluh tahun aktiviti, dengan pos yang mengandungi salah tulisan, variasi ortografik, akronim, dan slang. Pendekatan statistik kami menyokong analisis perubahan bahasa dan topik diskusi melalui masa, tanpa keperluan untuk melatih model topik untuk setiap selang masa untuk analisis. Kami menilai pendekatan dengan membandingkan keputusan dengan TF-IDF menggunakan metrik keuntungan kumulatif yang dikurangi dengan anotasi manusia, mencari kaedah kami melampaui TF-IDF pada pemulihan maklumat.', 'ml': 'നിലവിലുള്ള സ്ഥിതിയുടെ മുമ്പുള്ള വാക്കുകളില്\u200d നിരീക്ഷിക്കുന്നതിനുള്ള ലളിതമായ ഒരു രീതിയില്\u200d ഞങ്ങള്\u200d കൊണ്ടുവരുന്നു. മുമ് ഈ രീതിയില്\u200d ഞങ്ങള്\u200d ഇംഗ്ലീഷ് ഭാഷ അണ്ട്രേഡ് ഹാക്കിക്ക് ഫോര്\u200dമില്\u200d നിന്നും ഒരു ഡാറ്റാസേറ്റ് പോസ്റ്റുകള്\u200d പ്രയോഗിക്കുന്നു. പത്ത് വര്\u200dഷങ്ങള്\u200dക്കുമുമ നമ്മുടെ പരിസ്ഥിതിക നടപടി സമയത്ത് ഭാഷ മാറ്റങ്ങളെയും സംസാരിക്കുന്നതിനെയും പിന്തുണയ്ക്കുന്നു. ഓരോ സമയത്തും വിശദീകരണത്തിനുള്ള ഇടവേ We evaluate the approach by comparing the results to TF-IDF using the discounted cumulative gain metric with human annotations, finding our method outperforms TF-IDF on information retrieval.', 'mt': 'Aħna nippreżentaw metodu ħafif għall-identifikazzjoni tat-termini li bħalissa qed jiżdiedu b’rabta ma’ qabel magħruf tat-termini, bl-użu ta’ proporzjon ta’ log-odds ippeżat ma’ qabel informattiv. Aħna napplikaw dan il-metodu għal sett ta’ dejta ta’ postijiet minn forum ta’ hacking taħt l-art bl-Ingliż, li jkopri aktar minn għaxar snin ta’ attività, b’postijiet li fihom ittri żbaljati, varjazzjoni ortografika, akronimi, u slang. L-approċċ statistiku tagħna jappoġġja l-analiżi ta’ bidliet lingwistiċi u suġġetti ta’ diskussjoni maż-żmien, mingħajr rekwiżit li jitħarreġ mudell ta’ suġġett għal kull intervall ta’ żmien għall-analiżi. Aħna jevalwaw l-approċċ billi nqabblu r-riżultati mat-TF-IDF bl-użu tal-metrika tal-qligħ kumulattiv skontat mal-annotazzjonijiet umani, u nsibu li l-metodu tagħna jaqbeż it-TF-IDF meta tinkiseb l-informazzjoni.', 'mn': 'Бид одоогийн мэдээллийн өмнөх томъёоны холбоотой тенденцийг тодорхойлох хялбар аргыг тайлбарлаж байна. Бид энэ аргыг Англи хэл дээрх хакингийн форумын өгөгдлийн сангийн хэлбэрээр ашиглаж, 10 жилийн турш ажиллагаатай, буруу бичлэг, ортографик өөрчлөлт, акронимууд болон сланг агуулдаг захидал дээр ашиглаж байна. Бидний статистикийн арга нь хэлний өөрчлөлт болон ярилцлагын сэдэв шинжилгээг цаг хугацаанд дэмжиж, шинжилгээний тулд сэдэв загварыг суралцах шаардлагагүй. Бид үүнийг TF-IDF-тэй харьцуулахын тулд хүн төрөлхтний нээлттэй метрик ашиглаж, бидний арга нь мэдээлэл авах тухай TF-IDF-г илүү үр дүнтэй олох арга юм.', 'no': 'Vi presenterer ein lettvekt metode for å identifisera trendingsverdiar i forhold til ein kjent før vilkåra, ved å bruka ein vekt loggoddsforholdet med informativt før. Vi bruker denne metoden til ein dataset med meldingar frå ein engelsk undergrunnshakkforum, som utgår over ti år av aktivitet, med meldingar som inneheld feil stavingar, ortografiske variasjonar, akronymar og slang. Statistiske tilnærming vårt støttar analyse av språkstiske endringar og diskusingsemne over tid, utan krav for å trenga eit emnemodul for kvar gong for analyse. Vi evaluerer tilnærminga ved å sammenligne resultatet med TF-IDF med den diskonterte kumulative fjerninga metriske med menneske annotasjonar, og å finna metoden vårt som utfører TF-IDF på informasjonshenting.', 'pl': 'Przedstawiamy lekką metodę identyfikacji aktualnie trendujących terminów w stosunku do znanego przedterminu, przy użyciu ważonego współczynnika log-kurs z informacyjnym prior. Stosujemy tę metodę do zestawu danych postów z angielskojęzycznego podziemnego forum hackingowego, obejmującego ponad dziesięć lat działalności, z postami zawierającymi błędy pisowni, warianty ortograficzne, akronimy i slang. Nasze podejście statystyczne wspiera analizę zmian językowych i tematów dyskusji w czasie, bez konieczności trenowania modelu tematu dla każdego przedziału czasowego do analizy. Oceniamy podejście poprzez porównanie wyników z TF-IDF przy użyciu dyskontowanego wskaźnika kumulatywnego zysku z adnotacjami ludzkimi, stwierdzając, że nasza metoda przewyższa TF-IDF w odzyskiwaniu informacji.', 'sr': 'Predstavljamo metodu lagane težine za identifikaciju trenutnih termina u odnosu na poznato ranije rečeno, koristeći odnos težine log-šansa sa informativnim ranije. Mi primjenjujemo ovu metodu na skupu podataka postavljenih na engleskom jeziku podzemnom hakerskom forumu, širenjem preko deset godina aktivnosti, sa postima koji sadrže pogrešne pisanje, ortografske varijacije, akronima i slang. Naš statistički pristup podržava analizu jezičkih promjena i raspravnih tema tijekom vremena, bez neophodnosti da treniramo model teme svakog vremena za analizu. Procjenjujemo pristup uspoređivanjem rezultata sa TF-IDF koristeći diskontiranu kumulativnu dobit metriku sa ljudskim annotacijom, pronalaženjem našeg metoda iznosi TF-IDF na povratku informacija.', 'ro': 'Vă prezentăm o metodă ușoară pentru identificarea termenilor în tendință în raport cu un anterior cunoscut de termeni, folosind un raport log-odds ponderat cu un anterior informativ. Aplicăm această metodă unui set de date de postări dintr-un forum subteran de hacking în limba engleză, care cuprinde peste zece ani de activitate, cu postări care conțin greșeli ortografice, variații ortografice, acronime și slang. Abordarea noastră statistică sprijină analiza schimbărilor lingvistice și discuțiile subiectelor de-a lungul timpului, fără a fi necesară instruirea unui model de subiect pentru fiecare interval de timp pentru analiză. Evaluăm abordarea prin compararea rezultatelor cu TF-IDF folosind metrica de câștig cumulat cu adnotări umane, descoperind că metoda noastră depășește TF-IDF în recuperarea informațiilor.', 'si': 'අපි දන්නවා මුලින් ප්\u200dරතිචාරයක් සම්බන්ධ විධානයක් තියාගන්න ලොග් විධානයක් ප්\u200dරයෝජනය කරනවා, මුලින් ප්\u200dරතිචාරයක්  අපි මේ විදියට ඉංග්\u200dරීසි භාෂාවක් හැක් විදියට පොස්ට් සෙට් එක්ක භාෂා කරනවා, අවුරුදු දහයක් වඩා ක්\u200dරියාත්මක වැරැද්ධතාවක් තියෙනවා,  අපේ සංඛ්\u200dයාත්මක විදිහට භාෂාත්මක වෙනස් සහ කතා කරන විදිහට විශ්ලේෂණය සඳහා විශ්ලේෂණය සඳහා විශ්ලේෂණය සඳහා වි අපි ප්\u200dරතිචාරය විශ්වාස කරනවා TF-IDF එක්ක ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරය කරන්න, මිනිස්සු ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරය', 'ta': 'நாம் தற்போது நடக்கும் விளக்கங்களை அறியப்பட்ட முன் வரையறையில் கண்டுபிடிக்க ஒரு எளிய எடை முறையை கொண்டு வருகிறோம், ஒரு விவரங்களுக்க நாம் இந்த முறைமையை பயன்படுத்துகிறோம் ஒரு ஆங்கிலத்தின் அடிப்படையிலிருந்து மொழி ஹாக்கிக் கூட்டத்தில் இருந்து தகவல் அமைப்பு எங்கள் புள்ளிவிவரம் செயல்பாடு மொழிமாற்றம் மற்றும் நேரத்திற்கு மேல் discussion தலைப்புகளை ஆராய்ந்து, ஒவ்வொரு நேரத்திற்கும் இடைவெளியி முடிவுகளை TF-IDF-க்கு ஒப்பிடும் முறையை நாம் மதிப்பிடுகிறோம் மூலம் கண்டுபிடிக்கப்பட்டுள்ள கூட்டு மெட்ரிக் மனித அறிவிப்புகளை பயன்படுத்தி,', 'sv': 'Vi presenterar en lätt metod för att identifiera aktuella trendtermer i relation till en känd tidigare termer, med hjälp av en viktad log-odds ratio med en informativ tidigare. Vi tillämpar denna metod på en datauppsättning inlägg från ett engelskspråkigt underjordiskt hackingforum, som sträcker sig över tio års aktivitet, med inlägg som innehåller felstavningar, ortografiska variationer, akronymer och slang. Vårt statistiska tillvägagångssätt stöder analys av språkliga förändringar och diskussionsämnen över tid, utan krav på att träna en ämnesmodell för varje tidsintervall för analys. Vi utvärderar tillvägagångssättet genom att jämföra resultaten med TF-IDF med hjälp av diskonterad kumulativ gain metric med human annotation, finner att vår metod överträffar TF-IDF vid informationshämtning.', 'ur': 'ہم ایک ہلکا وزن طریقہ پیش کررہے ہیں کہ ایک پہلے معلوم ہونے کے معاملہ میں ایک ٹرنڈنگ شریفں پہچان سکیں، ایک بھاری لوگ-اڈس راس سے پہلے معلوم ہونے کے ساتھ. ہم نے اس طریقہ کو ایک انگلیسی زبان کے نیچے ہکس فورمی سے پوسٹ کے ڈاٹ سٹ پر لازم کریں، دس سال سے زیادہ فعالیت کے ساتھ پھیل رہے ہیں، پوسٹ کے ساتھ غلط باتیں، اورٹوگرافیک تغییر، اکرونیم، اور سلینگ کے ساتھ لگا ہماری ایستٹیسٹی طریقہ کی تغییرات اور بحث کے موضوع کی تحلیل کی مدد کرتا ہے، ہر بار کے اندازہ تحلیل کے لئے ایک موضوع مدل کی تعلیم کے بغیر کوئی ضرورت نہیں۔ ہم نے اس طریقہ کا ارزش کیا ہے کہ نتیجے TF-IDF کے مطابق دیسکونٹ کی جمعیٹ فائدہ کے مطابق انسان کے اظہارات کے مطابق، ہماری طریقہ تلاش کرنے کے مطابق TF-IDF کو معلومات حاصل کرنے کے مطابق اضافہ کرتا ہے.', 'so': "Waxaynu soo bandhignaa qaab fudud oo a an aqoonsanno sharciga horay loo yaqaan, sida loo isticmaalayo qaybaha qoraalka oo miisaamay oo uu horay u qorayo macluumaad. Waxaynu u codsanaynaa koorsooyinkaas warqada wax jabsada ee afka Ingiriiska hoostiisa ah, kaas oo ka badan toban sano, boostada ku yaala qalloocan, isbedelka ortografiga, akronym iyo bannaanka. Dhaqdhaqaaqa takhasuska ah wuxuu kaalmeeyaa baaritaanka ku saabsan isbedelka luuqadda iyo hadalka, iyadoo aan loo baahnayn in lagu baro tusaale maadooyinka maadooyinka marka walba la sameynayo baaritaanka. Markaas waxaynu qiimeynaynaa qaababka ku saabsan TF-IDF ku sameynayo faa'iidada dhaqaalaha ee aan la bilaabay oo lagu isticmaalayo faa'iidada dhaqaalaha ee dadka, si aan u helno qaababka uu ku sameynayo TF-IDF ku saabsan helitaanka macluumaadka.", 'uz': "Biz hozirgi ma'lumot berilmagan avval sonlarni aniqlash uchun oddiy usulni hozir qilamiz. Biz bu usulni ingliz tilidagi eng tildagi chegara haqida qo'llash foryusidan maʼlumotlar tarkibiga qo'llamiz, 10 yil ichida harakat qilib, xato roʻy beradigan postlar, ortografik ўзгартиришлар, acronym va slayd bor. Bizning statistika muvaffaqiyatlarimiz tilni o'zgartirish va taʼminlovchi mavzularni o'rganish imkoniyatini qo'llaydi. Analysi uchun har safar interval uchun mavzu modelini o'rganish kerak emas. We evaluate the approach by comparing the results to TF-IDF using the discounted cumulative gain metric with human annotations, finding our method outperforms TF-IDF on information retrieval.", 'vi': 'Chúng tôi giới thiệu một phương pháp nhẹ để xác định các chữ đang xu hướng tương đương với một giá trị trước đây được biết, sử dụng một tỷ lệ lệ lệ lệ lệ ghi đè trọng với một giá trị thông tin trước đây. Chúng tôi áp dụng phương pháp này cho một tập tin từ một diễn đàn ngầm ngầm tiếng Anh, trải dài hơn mười năm hoạt động, với những bài viết có lỗi chính tả, các biến dạng chính xác, các chữ viết và đường nghiêng. Cách tiếp cận thống kê của chúng tôi hỗ trợ phân tích về biến đổi ngôn ngữ và các chủ đề thảo luận qua thời gian, mà không cần phải đào tạo mô hình chủ đề cho mỗi thời gian để phân tích. Chúng tôi đánh giá phương pháp bằng cách so sánh kết quả với TF-IDF bằng những điều đo tích tích ngược với ghi chú người, tìm ra phương pháp vượt trội về TF-IDF trong việc lấy thông tin.', 'bg': 'Представяме лек метод за идентифициране на понастоящем тенденционни термини по отношение на известно предшествие на термините, като използваме претеглено съотношение лого-коефициенти с информативно предшествие. Ние прилагаме този метод към набор от публикации от подземен хакерски форум на английски език, обхващащ над десет години дейност, с публикации, съдържащи грешни правописи, ортографски вариации, акроними и жаргон. Статистическият ни подход поддържа анализ на езиковата промяна и дискусионните теми във времето, без да е необходимо да се обучава тематичен модел за всеки интервал от време за анализ. Ние оценяваме подхода чрез сравняване на резултатите с помощта на сконтената кумулативна печалба метрика с човешки анотации, като откриваме, че методът ни превъзхожда ТФ-ИДФ при извличане на информация.', 'hr': 'Predstavljamo metodu lagane težine za identifikaciju trenutnih termina u odnosu na poznatu prije uvjeta, koristeći težinu odnosu na log-šanse s informativnim prije. Mi primjenjujemo ovu metodu na skupu podataka postova iz forum a za hakiranje engleskog jezika ispod zemlje, koja se širi preko deset godina aktivnosti, sa postima koji sadrže pogrešne pisanje, ortografske varijacije, akronima i slang. Naš statistički pristup podržava analizu jezičkih promjena i raspravnih tema tijekom vremena, bez zahtjeva za obuku model a teme za svaki put interval za analizu. Procjenjujemo pristup uspoređivanjem rezultata sa TF-IDF koristeći diskontiranu kumulativnu dobit metriku s ljudskim annotacijom, pronalaženjem našeg metoda iznosi TF-IDF na povratku informacija.', 'da': 'Vi præsenterer en letvægts metode til at identificere aktuelt trending termer i forhold til en kendt forudgående af termer, ved hjælp af en vægtet log-odds ratio med en informativ forudgående. Vi anvender denne metode på et datasæt af indlæg fra et engelsksproget underjordisk hackingforum, der spænder over ti års aktivitet, med indlæg indeholdende stavefejl, ortografisk variation, akronymer og slang. Vores statistiske tilgang understøtter analyse af sproglige ændringer og diskussion emner over tid, uden krav om at træne en emnemodel for hvert tidsinterval til analyse. Vi evaluerer tilgangen ved at sammenligne resultaterne med TF-IDF ved hjælp af den diskonterede kumulative gain metric med menneskelige annotationer, og finde ud af, at vores metode overgår TF-IDF på informationshentning.', 'nl': 'We presenteren een lichtgewicht methode voor het identificeren van huidige trending termen in relatie tot een bekende voorafgaand aan termen, met behulp van een gewogen log-odds ratio met een informatieve voorafgaand. We passen deze methode toe op een dataset van posts van een Engelstalig underground hacking forum, dat meer dan tien jaar actief is, met posts met spelfouten, orthografische variaties, acroniemen en slang. Onze statistische benadering ondersteunt de analyse van taalveranderingen en discussieonderwerpen in de loop van de tijd, zonder dat u een topic model hoeft te trainen voor elk tijdsinterval voor analyse. We evalueren de aanpak door de resultaten te vergelijken met TF-IDF met behulp van de discounted cumulative gain metric met menselijke annotaties, waardoor onze methode beter presteert dan TF-IDF op het terughalen van informatie.', 'de': 'Wir präsentieren eine leichtgewichtige Methode zur Identifizierung aktueller Trendbegriffe in Bezug auf einen bekannten Prior of Terms, wobei ein gewichtetes Log-Odds-Verhältnis mit einem informativen Prior verwendet wird. Wir wenden diese Methode auf einen Datensatz von Beiträgen aus einem englischsprachigen Underground-Hacking-Forum an, der über zehn Jahre aktiv ist, mit Beiträgen mit Rechtschreibfehlern, orthographischen Variationen, Akronymen und Slang. Unser statistischer Ansatz unterstützt die Analyse sprachlicher Veränderungen und Diskussionsthemen im Laufe der Zeit, ohne dass für jedes Zeitintervall ein Themenmodell trainiert werden muss. Wir evaluieren den Ansatz, indem wir die Ergebnisse mit TF-IDF unter Verwendung der diskontierten kumulativen Verstärkungsmetrik mit menschlichen Annotationen vergleichen und feststellen, dass unsere Methode TF-IDF beim Informationsabruf übertrifft.', 'sw': 'Tunaweza kuweka mbinu za uzito kwa kutambua vipindi vya sasa vinavyoendelea kuhusiana na maarifa yaliyojulikana kabla ya vipindi vya matumizi, kwa kutumia kiwango cha usambazaji mzito wa kitambulisho na taarifa kabla. Tunatumia mbinu hii kwenye seti ya taarifa za makala kutoka Jukwaa la kupigwa kwa lugha ya Kiingereza, linalopanda zaidi ya miaka kumi ya shughuli, makala zinazohusu makosa, mabadiliko ya kigaidi, mitazamo na viungo. Hatua yetu ya takwimu inaunga mkono uchambuzi wa mabadiliko ya lugha na mada za mjadala kwa muda mrefu, bila haja ya kufundisha muundo wa mada kwa kila wakati wa uchambuzi. Tutathmini mbinu hizo kwa kulinganisha matokeo ya TF-IDF kwa kutumia mafanikio ya kiutamaduni yasiyopatikana na matangazo ya binadamu, kwa kutafuta njia yetu inaonyesha TF-IDF kuhusu upatikanaji wa taarifa.', 'fa': 'ما یک روش سنگین سبک برای شناسایی شرایط ترند در حال حاضر در ارتباط با یک مقدار پیش از شرایط شناخته می\u200cشویم، با استفاده از مقدار سنگین نسبت لاگ شانس با یک مقدار اطلاعات پیش از این. ما این روش را به مجموعه داده\u200cهای پوست\u200cهای یک مجموعه هک کردن زیر زبان انگلیسی تغییر می\u200cدهیم، که بیش از ده سال فعالیت می\u200cشود، با پوست\u200cهایی که شامل نوشته\u200cهای اشتباهی، تغییرات orthographic، اکرونیم و اسلانگ است. روش آماری ما تحلیل تغییرات زبان و بحث را در طول زمان پشتیبانی می کند، بدون نیازی برای آموزش یک مدل موضوع برای هر زمانی برای تحلیل. ما روش را با مقایسه کردن نتیجه\u200cها با TF-IDF با استفاده از کمک\u200cهای جمع\u200cآوری متریک با اخطار انسان ارزیابی می\u200cکنیم، و پیدا کردن روش\u200cهای ما بر گرفتن اطلاعات TF-IDF پاداش می\u200cدهد.', 'tr': 'Häzirki öňki bilinen terimler ile ilişkileşini tanımak için hafif bir yöntem gösteriyoruz. Biz bu yöntemi iňlis dilinden hackerlaýan forumdan, on ýyldan soňra ýalňyş ymlany, ortografiýa üýtgeşmeler, akronymlar we süzmekler bilen meýilleşdirýäris. Biziň statistik ýazşymyz lingwistiki üýtgeşmeleri we diskusiýa meýdanlarynyň analyzasyny wagtyň içinde, her gezek analyzasy üçin tema nusgasyny öwretmek üçin gerek bolmady. Näme üçin TF-IDF bilen baglaşdyryp, çykyş edilen kumulativ gazanç metriklerini adam duýdurmalary bilen görä çykýarys we çykyşymyzyň üstüne TF-IDF-i maglumatlary almak üçin üstünlik gazanýarys.', 'af': "Ons stel 'n liggewig metode voor die identifiseer van huidiglik trending terme in relatie met 'n bekende vooraf van terme, gebruik 'n gewigte log-odds verhouding met 'n informatiewe vooraf. Ons het hierdie metode aanwend na 'n datastel pos van 'n Engelstaal-ondergrond-hacking forum, wat oor tien jaar aktiviteit spandeer, met pos wat verkeerde speletjies, ortografiese verandering, akronime en slang bevat. Ons statistiese toegang ondersteun analiseer van lingwisiese verander en diskusie onderwerpe oor tyd, sonder 'n benodig om 'n onderwerp model te oefen vir elke tyd interval vir analiseer. Ons evalueer die toegang deur vergelyking van die resultate met TF-IDF te vergelyk deur te gebruik die afgesluitde kumulatiewe verskaf metriek met menslike notasies, en ons metode te vind uitgevoer TF-IDF op inligting ontvang.", 'sq': 'Ne paraqesim një metodë të lehtë për identifikimin e termave aktuale të prirjes në lidhje me një paraardhje të njohur të termave, duke përdorur një raport të peshuar log-odds me një paraardhje informative. Ne e aplikojmë këtë metodë në një grup të dhënash të postëve nga një forum i hakimit nëntokësor në gjuhën angleze, që zgjat mbi dhjetë vjet aktiviteti, me postë që përmbajnë gabime shkrimi, variacion ortografik, akronime dhe slang. Përqasja jonë statistikore mbështet analizën e ndryshimeve gjuhësore dhe temave të diskutimit gjatë kohës, pa një kërkesë për të trajnuar një model tematik për çdo interval kohor për analizë. Ne vlerësojmë qasjen duke krahasuar rezultatet me TF-IDF duke përdorur fitimin e diskontuar kumulativ metrik me anotacionet njerëzore, duke gjetur metodën tonë të dalshme TF-IDF në marrjen e informacionit.', 'id': 'Kami mempersembahkan metode ringan untuk mengidentifikasi terma yang sekarang trending berkaitan dengan sebelumnya terma yang dikenal, menggunakan proporsi log-odds berat dengan sebelumnya informatif. Kami menerapkan metode ini untuk set data pos dari forum hacking bawah tanah bahasa Inggris, berlangsung lebih dari sepuluh tahun aktivitas, dengan pos yang mengandung salah tulisan, variasi ortografik, akronim, dan slang. pendekatan statistik kami mendukung analisis perubahan bahasa dan topik diskusi melalui waktu, tanpa rekwiżit untuk melatih model topik untuk setiap interval waktu untuk analisis. Kami mengevaluasi pendekatan dengan membandingkan hasilnya dengan TF-IDF menggunakan metrik pendapatan kumulatif diskonton dengan anotasi manusia, menemukan metode kita lebih berharga TF-IDF pada penemuan informasi.', 'am': 'We present a lightweight method for identifying currently trending terms in relation to a known prior of terms, using a weighted log-odds ratio with an informative prior.  ይህንን ሥርዓት ከዐሥር ዓመታት በላይ የእንግሊዘኛ ቋንቋ መሬት መቆጣጠር ፎርማት ላይ የመድረክ ጽሑፎችን እናስጠጋለን፡፡ የstatistical approach ለቋንቋዊ ለውጥ እና የውይይት ጉዳዮች ላይ በተጨማሪው ዘመን ለማስተካከል ይረዳል፡፡ የTF-IDF ፍሬዎችን በማስተካከል እናስተዋልታለን፡፡', 'hy': 'Մենք ներկայացնում ենք թեթև մեթոդ, որպեսզի բացահայտենք ներկայիս տենդենցիոն տերմինները նախկինում հայտնի տերմինների հետ կապված, օգտագործելով կենտրոնացված լոգ-հավանականության հարաբերությունը ինֆորմատիվ նախկինում: Մենք կիրառում ենք այս մեթոդը անգլերեն լեզվով ստորգետնին հաքսիրային ֆորմում տեղեկատվության մի համակարգի վրա, որը տևում է տասը տարվա ընթացքում, տեղեկատվություն, որը պարունակում է սխալ գրություններ, օրտոգրաֆիկ տարբերակներ, ակրոնիմներ և սլենգ: Մեր վիճակագրական մոտեցումը աջակցում է լեզվաբանական փոփոխությունների և քննարկումների թեմաների վերլուծումը ժամանակի ընթացքում, առանց թեմային մոդելի ուսումնասիրելու պահանջի վերլուծության յուրաքանչյուր ժամանակահատվածում: Մենք գնահատում ենք մոտեցումը, համեմատելով արդյունքները ԹՖ-IDF-ի հետ՝ օգտագործելով անհաշվարկված համընդհանուր շահույթի մետրիկ մարդկային նոտացիաների հետ, գտնելով մեր մեթոդը, որ արտադրում է ԹՖ-IDF-ը տեղեկատվության վերաբերյալ:', 'ko': '우리는 경량급의 방법을 제시하여 현재 추세항과 이미 알고 있는 선험항의 관계를 식별하고 가중 대수 우위비와 정보 선험항을 사용한다.우리는 이러한 방법을 영어 지하 해커 포럼의 게시물 데이터 집합에 응용할 것이다. 이 게시물들은 십여 년의 활동을 뛰어넘었는데, 그 중에는 맞춤법 오류, 맞춤법 변이, 알파벳 줄임말, 비속어가 포함되어 있다.우리의 통계 방법은 시간의 추이에 따라 언어 변화와 토론 주제를 분석하는 것을 지원하고 모든 분석 시간 간격을 위해 주제 모델을 훈련할 필요가 없다.우리는 결과를 TF-IDF(인간 주석이 달린 어음할인 누적 이득 메트릭 사용)와 비교함으로써 이 방법을 평가한 결과 정보 검색이 TF-IDF보다 우수하다는 것을 발견했다.', 'az': "Biz həmin vaxtda belə bir əvvəlki şartların əlaqəsi ilə tanıdıqlarına görə a ğırlıq tərzini göstəririk, ağırlıq log-odds ratio ilə informativ bir əvvəlki şartları ilə istifadə edirik. Biz bu yöntemi İngilizə dilində hacking forumu tərəfindən göndərdik, on il istifadə etdik, yanlış yazılar, ortografik dəyişikliklər, akronimlər və slang olaraq yazılmış məktublar ilə istifadə edirik. Bizim statistik tərzimiz dillərin dəyişiklikləri və müzakirə məsələlərinin analizi zamanında dəyişdirir, hər dəfə analizi üçün məsələn modelini təhsil etməyə şart olmadan. Biz bu metodumu TF-IDF ilə qarşılaşdırmaq vasitəsilə insan nöqtələri ilə dəyişdirilmiş kumulativ əlaqələri ilə metrik vasitəsilə, metodumuzu tapmaq məlumatları almaq üçün TF-IDF'nin üstünlüyünü dəyişdirir.", 'bn': 'আমরা বর্তমানে একটি পরিচিত শর্তের সম্পর্কে চিহ্নিত একটি হাল্কা মূল্য উপস্থাপন করি যার ফলে বর্তমানে পরিবর্তনের শর্ত চিহ্নিত করা হয়েছে, একটি তথ্য পূ আমরা এই পদ্ধতিকে ইংরেজী ভাষায় হ্যাকিং ফোরাম থেকে একটি ডাটাসেট পোস্টের প্রয়োগ করি, যা ১০ বছরের বেশী কার্যক্রমের স্প্যানিং হয়েছে, যার পোস্টের মধ্যে ভুল ভিন্ আমাদের পরিসংখ্যান পদ্ধতি বিশ্লেষণ সময় সমর্থন করে, বিশ্লেষণের জন্য প্রত্যেক বারের মধ্যে একটি বিষয়ক মডেল প্রশিক্ষণ করার প্রয়োজন নেই। আমরা টিএফ-আইডিএফ-এর ফলাফলের তুলনা করি মানুষের প্রতিবেদনের মাধ্যমে মানুষের মাধ্যমে কুমুলেটিভ লাভের মাধ্যমে মিট্রিক ব্যবহার করে, আমাদের পদ্ধতি খুঁজে ব', 'ca': "Presentam un mètode lliure per identificar termes actualment tendents en relació a un anterior conegut de termes, utilitzant una proporció ponderada de probabilitats de registre amb un anterior informatiu. We apply this method to a dataset of posts from an English-language underground hacking forum, spanning over ten years of activity, with posts containing misspellings, orthographic variation, acronyms, and slang.  El nostre enfocament estadística suporta l'anàlisi de canvis lingüístics i temas de debat amb el temps, sense requeriment de formar un model de tema per cada interval de temps per a l'anàlisi. Evaluam l'enfocament comparant els resultats amb TF-IDF utilitzant la metèrica de guanya acumulativa descontatada amb anotacions humanes, trobant que el nostre mètode supera TF-IDF en recuperar informació.", 'cs': 'Představujeme lehkou metodu pro identifikaci aktuálně trendujících termínů ve vztahu ke známému předchozímu termínu, pomocí váženého poměru log-kurzů s informačním předchozím. Tuto metodu aplikujeme na datovou sadu příspěvků z anglického undergroundového hackerského fóra, které trvá více než deset let aktivity, s příspěvky obsahujícími chyby pravopisu, ortografické variace, zkratky a slang. Náš statistický přístup podporuje analýzu jazykových změn a diskusních témat v průběhu času, bez nutnosti trénovat tématický model pro každý časový interval pro analýzu. Tento přístup hodnotíme porovnáním výsledků s TF-IDF pomocí diskontované metriky kumulativního zisku s lidskými anotacemi a zjišťujeme, že naše metoda překonává TF-IDF při vyhledávání informací.', 'et': 'Esitame kerge meetodi praeguste trenditingimuste tuvastamiseks seoses teadaolevate eelmiste tingimustega, kasutades kaalutud log-koefitsientide suhet informatiivse eelmisega. Me rakendame seda meetodit ingliskeelse maa-aluse häkkimisfoorumi postituste andmekogumile, mis hõlmavad üle kümne aasta tegevust ning mis sisaldavad kirjavigu, ortograafilisi variatsioone, akronüüme ja slänge. Meie statistiline lähenemine toetab keeleliste muutuste analüüsi ja aruteluteemade analüüsi aja jooksul, ilma et oleks vaja koolitada teemamudelit iga analüüsi ajavahemiku jaoks. Hindame lähenemisviisi, võrreldes tulemusi TF-IDF-iga, kasutades diskonteeritud kumulatiivse kasumi mõõdikut inimese märkustega, leides, et meie meetod ületab TF-IDF-i informatsiooni hankimisel.', 'fi': 'Esittelemme kevyen menetelmän, jolla tunnistetaan tällä hetkellä trendikkäät termit suhteessa tunnettuun aikaisempaan termiin käyttäen painotettua log-kertoimien suhdetta informatiiviseen aikaisempaan. Sovellamme tätä menetelmää englanninkielisen maanalaisen hakkerointifoorumin viesteihin, jotka kattavat yli kymmenen vuotta toimintaa ja sisältävät kirjoitusvirheitä, ortografisia variaatioita, lyhenteitä ja slangia. Tilastollinen lähestymistapamme tukee kielellisten muutosten analysointia ja keskusteluaiheiden analysointia ajan mittaan ilman tarvetta kouluttaa aihemallia kullekin analyysin aikavälille. Arvioimme lähestymistapaa vertaamalla tuloksia TF-IDF:ään käyttäen diskontattua kumulatiivista vahvistusmittaria inhimillisiin huomautuksiin, löytäen menetelmämme olevan TF-IDF:n parempi tiedonhaussa.', 'bs': 'Predstavljamo metodu lagane težine za identifikaciju trenutnih termina u odnosu na poznato ranije rečeno, koristeći odnos težine dnevnih mogućnosti sa informativnim ranije. Mi primjenjujemo ovu metodu na skupu podataka postavljanja iz forum a za hakovanje engleskog jezika podzemne, koji proširi preko deset godina aktivnosti, sa postima koji sadrže pogrešne pisanje, ortografske varijacije, akronima i slang. Naš statistički pristup podržava analizu jezičkih promjena i raspravnih tema tijekom vremena, bez zahtjeva da treniramo model teme svaki put za analizu. Procjenjujemo pristup uspoređivanjem rezultata sa TF-IDF koristeći diskontiranu kumulativnu dobit metriku s ljudskim annotacijom, pronalaženjem našeg metoda iznosi TF-IDF na povratku informacija.', 'sk': 'Predstavljamo lahko metodo za identifikacijo trenutno trendnih izrazov v razmerju z znanim predhodnim izrazom, z uporabo tehtanega razmerja log-kvot z informativnim predhodnim. To metodo uporabljamo za nabor podatkov iz angleškega podzemnega hekerskega foruma, ki obsega več kot deset let dejavnosti in vsebuje napačno črkovanje, ortografske variacije, kratice in sleng. Naš statistični pristop podpira analizo jezikovnih sprememb in debatnih tem skozi čas, brez zahteve po usposabljanju tematskega modela za vsak časovni interval za analizo. Pristop ocenjujemo tako, da primerjamo rezultate s TF-IDF z uporabo meritve diskontiranega kumulativnega dobička s človeškimi opombami in ugotovimo, da naša metoda presega TF-IDF pri pridobivanju informacij.', 'he': 'אנו מציגים שיטה קלה לזהות התנאים הנוכחיים המטנדים ביחס לקודם ידוע של התנאים, בשימוש יחסי לוג-סיכוי משקל עם קודם מידעי. We apply this method to a dataset of posts from an English-language underground hacking forum, spanning over ten years of activity, with posts containing misspellings, orthographic variation, acronyms, and slang.  הגישה הסטטיסטית שלנו תומכת בניתוח של שינוי שפתי ונושאים דיון במהלך הזמן, ללא דרישה לאמן מודל נושא לכל אינטנול זמן לניתוח. אנו מעריכים את הגישה על ידי השוואה של התוצאות ל-TF-IDF באמצעות מטריקת הרוויח הקולמטיבי הנחות עם הערות אנושיות, למצוא את השיטה שלנו מתגברת על TF-IDF על השיגור מידע.', 'ha': "We present a lightweight method for identifying currently trending terms in relation to a known prior of terms, using a weighted log-odds ratio with an informative prior.  Kana amfani da wannan shiryoyin ayuka zuwa wani matsayi na takardar posten daga runan haƙƙin bakin harshen Ingiriya, mai nuna akan aikin aiki gõma shẽkaru, da takardar da ke ƙunsa da makorari, variance na ortografi, akronyms da goyi. Tsarakanmu na ƙaddara yana ƙarfafa anayyari ga canza cikin lingui da muhimmada masu yin magana a bayani ga lokaci, kuma bã da buƙata ya lazimta ya sanar da wani misali wa lokacin da za'a yi anayyar. Mu ƙaddara hanyarmu da sammenliki da matsalar TF-IDF, a yi amfani da amfani da zane-zane-zane-zane na da mutane, kuma za'a sami hanyoyinmu na sami TF-IDF kan motsar da information.", 'jv': 'Awak dhéwé éntuk dhéwé nggawe sistem sing gak nggawe geraksi pergambar nggawe barang nggawe barang awak dhéwé, nggawe sistem sistem sing apik dhéwé, ngono nggawe sistem sing apik dhéwé, sing paling dhéwé Awak dhéwé nggawe sistem iki karo data set nggawe dolanan tarjamahan kanggo nyuggo urip kanggo ingkang éngles-urip Ndhek istatistik dhéwé nggunaké ngerwih cara-cara nggawe barang nggawe tarjamahan lan gewurung kuwi nakos, kuwi kudu ngewehke kudu ngewehke model temu kanggo nggawe tarjamahan kanggo ngewehke tarjamahan. Awak dhéwé éntukno nggawe gerasane nambah gambaran karo PF-ID nggawe barang nggawe barang nggawe barang nggawe barang kamulatan unggal gawe barang kamulatan unggal maneh karo dolang-dolang sing uwis, gewis nambah dhéwé kuwi nggawe barang nggawe TiF-ID FD kejahatan informa', 'bo': 'ང་ཚོས་ད་ལྟ་བུའི་ནང་གི་འཕེལ་རིམ་པ་དང་སྔོན་མ་ཤེས་པའི་རྣམ་གྲངས་ཀ་དང་འབྲེལ་བ་ཡོད་པའི་ཐབས་ལམ་ལྟར་ཉུང་པ་ཞིག We apply this method to a data set of posts from an English-language underground hacking forum, spanning over ten years of activity, with posts containing misspelling, orthographic variation, acronyms, and slang. ང་ཚོའི་ཚད་རྩིས་འབྲེལ་གྱི་གཟུགས་སྐོར་ལ་སྐད་རིགས་བསྒྱུར་བཅོས་དང་བསྟུན་ནས་གླེང་སྐབས་ནང་གི་གཏོང We evaluate the approach by comparing the results to TF-IDF using the discounted cumulative gain metric with human annotations, finding our method outperforms TF-IDF on information retrieval.'}
{'en': 'Punctuation Restoration using Transformer Models for High-and Low-Resource Languages', 'ar': 'استعادة علامات الترقيم باستخدام نماذج المحولات للغات عالية ومنخفضة الموارد', 'es': 'Restauración de la puntuación mediante modelos de transformador para lenguajes de recursos altos y bajos', 'pt': 'Restauração de pontuação usando modelos de transformador para linguagens de alto e baixo recursos', 'fr': "Restauration de la ponctuation à l'aide de modèles Transformer pour les langues à ressources élevées et faibles", 'ja': '高および低リソース言語のための変圧器モデルを使用した句読点復元', 'hi': 'उच्च और कम संसाधन भाषाओं के लिए ट्रांसफॉर्मर मॉडल का उपयोग कर विराम चिह्न बहाली', 'zh': '用高资、低资源语转换器复标点符号', 'ru': 'Восстановление пунктуации с использованием трансформаторных моделей для языков с высоким и низким уровнем ресурсов', 'ga': 'Athchóiriú Poncaíochta ag úsáid Múnlaí Trasfhoirmeora do Theangacha Ard-Acmhainne agus Íseal-Acmhainne', 'ka': 'სპენტექციის რესტოპაცია გამოყენებული ტრანფორმეტრის მოდელების გამოყენებაName', 'el': 'Αποκατάσταση στίξης χρησιμοποιώντας μοντέλα μετασχηματιστών για γλώσσες υψηλού και χαμηλού πόρου', 'hu': 'Pontozás visszaállítása transzformátor modellekkel nagy és alacsony erőforrású nyelvekhez', 'it': 'Ripristino della punteggiatura utilizzando modelli di trasformatore per linguaggi ad alto e basso contenuto di risorse', 'mk': 'Реставрање на точки користејќи трансформирани модели за јазици со високи и ниски ресурси', 'kk': 'Жоғары және төменгі ресурс тілдерінің түрлендіруші үлгілерін қолданып белгілеу қайталау', 'lt': 'Punktuacijos atkūrimas naudojant didelių ir mažų išteklių kalbų transformatorių modelius', 'ms': 'Pemulihan Titik menggunakan Model Transformer untuk Bahasa Sumber Tinggi dan Rendah', 'ml': 'കൂടുതല്\u200d വിഭവവിഭവങ്ങള്\u200dക്കും കുറഞ്ഞ വിഭവങ്ങള്\u200dക്കുള്ള മോഡലുകള്\u200d', 'mn': 'Бага болон бага боловсролын хэлний төлөвлөгч загваруудыг ашиглаж буй загваруудын дахин сэргээх', 'mt': 'Ristrutturar tal-Puntwazzjoni bl-użu ta’ Mudelli ta’ Trasformazzjoni għal-Lingwi b’Riżorsi Għolja u Bażi', 'no': 'Restaurering av teikningar med transformeringsmodeller for høg og låg ressursspråk', 'sr': 'Restauracija prestanka koristeći modele transformera za jezike visokih i niskih resursa', 'pl': 'Przywracanie interpunkcji za pomocą modeli transformatorów dla języków o wysokim i niskim zasobie', 'ro': 'Restaurarea punctajării utilizând modele de transformator pentru limbi cu resurse ridicate și scăzute', 'si': 'Name', 'so': 'Luqadaha sare iyo hoose-Resource', 'sv': 'Punktuerings책terst채llning med hj채lp av transformatormodeller f철r spr책k med h철g och l책g resurs', 'ta': 'உயர்ந்த மற்றும் குறைந்த மூலத்தின் மொழிகளுக்கான மாதிரிகளை பயன்படுத்தி துண்டிப்பு மீட்டமைப்பு', 'ur': 'Name', 'uz': 'Name', 'vi': 'Bộ phục hồi ký hiệu bằng chế biến hình cho ngôn ngữ cao và thấp', 'nl': 'Interpunctieherstel met behulp van transformatormodellen voor talen met hoge en lage bronnen', 'bg': 'Възстановяване на пунктуация с помощта на модели трансформатори за езици с висок и нисък ресурс', 'da': 'Gendannelse af punktering ved hjælp af transformatormodeller til sprog med høj og lav ressource', 'hr': 'Restauracija stavka koristeći modele transformera za jezike visokog i niskog resursa', 'id': 'Punctuation Restoration using Transformer Models for High-and Low-Resource Languages', 'de': 'Interpunktionswiederherstellung mit Transformatormodellen für Sprachen mit hoher und geringer Ressourcenbelastung', 'fa': 'بازسازی نقطه با استفاده از مدل تغییر\u200cدهنده برای زبانهای منابع بالا و پایین', 'ko': '고자원과 저자원 언어의 변환기 모델을 사용하여 문장 복구', 'sw': 'Punctuation Restoration using Transformer Models for High-and Low-Resource Languages', 'tr': 'Buýruk we Aç-Ressurat Dilleri üçin Täze Modler ullanýar', 'sq': 'Punctuation Restoration using Transformer Models for High-and Low-Resource Languages', 'af': 'Punktuasie Herstelling gebruik Transformer Modelle vir Hoog en Laag- Hulpbron Taal', 'am': 'ቋንቋዎች', 'hy': 'Պունկցիայի վերականգնումը՝ օգտագործելով բարձր և ցածր ռեսուրսների լեզուների վերափոխման մոդելներ', 'az': 'Yüksek və düşük ressurs dillərinin transformer modellərini istifadə edərək nöqtələri yeniləşdirməsi', 'bn': 'High- and low- resource ভাষার জন্য ট্রান্সফার্নার মোডেল ব্যবহার করে পুনরুদ্ধার করুন', 'bs': 'Restauracija prestanka koristeći modele transformera za jezike visokog i niskog resursa', 'ca': 'La restauració de puntuació utilitzant models de transformació per llengües de baix i alt recurso', 'cs': 'Obnovení interpunkce pomocí modelů transformátorů pro jazyky s vysokými a nízkými zdroji', 'et': 'Punktsiooni taastamine suure ja vähese ressursiga keelte teisendusmudelite abil', 'fi': 'Välipisteiden palauttaminen käyttämällä muuntamismalleja korkean ja pienen resurssin kielille', 'jv': 'spoken punctuation', 'he': 'שיחזור נקודות באמצעות מודלים טרנספורטרים לשפות משאבים גבוהים ומנמוכים', 'sk': 'Obnovitev točk z uporabo modelov transformatorjev za jezike z visokimi in nizkimi viri', 'bo': 'སྐད་རིགས་མཐོ་དང་མཐོ་རིམ་པོའི་ཆ་རྐྱེན་ལ་ལག་ལེན་འཐབ་པའི་སྐད་སྒྲིག་འཛུགས་ཀྱི་བསྐྱར་གསོ་བྱེད།', 'ha': '@ action'}
{'en': 'Punctuation restoration is a common post-processing problem for Automatic Speech Recognition (ASR) systems. It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks. Current state-of-art address this  problem  using different  deep learning models . Recently, transformer models have proven their success in downstream NLP tasks, and these  models  have been explored very little for the punctuation restoration problem. In this work, we explore different transformer based models and propose an augmentation strategy for this task, focusing on high-resource (English) and low-resource (Bangla) languages. For  English , we obtain comparable state-of-the-art results, while for  Bangla , it is the first reported work, which can serve as a strong baseline for future work. We have made our developed Bangla dataset publicly available for the research community.', 'fr': "La restauration de la ponctuation est un problème de post-traitement courant pour les systèmes de reconnaissance vocale automatique (ASR). Il est important d'améliorer la lisibilité du texte transcrit pour le lecteur humain et de faciliter les tâches de PNL. L'état actuel de la technique permet de résoudre ce problème à l'aide de différents modèles d'apprentissage Récemment, les modèles de transformateurs ont fait leurs preuves dans les tâches de PNL en aval, et ces modèles ont été très peu explorés pour le problème de restauration de la ponctuation. Dans ce travail, nous explorons différents modèles basés sur des transformateurs et proposons une stratégie d'augmentation pour cette tâche, en mettant l'accent sur les langues à ressources élevées (anglais) et à faibles ressources (bangla). Pour l'anglais, nous obtenons des résultats de pointe comparables, tandis que pour le Bangla, il s'agit du premier travail rapporté, qui peut servir de base solide pour les travaux futurs. Nous avons mis notre jeu de données Bangla développé à la disposition de la communauté des chercheurs.", 'ar': 'تعد استعادة علامات الترقيم مشكلة ما بعد المعالجة الشائعة لأنظمة التعرف التلقائي على الكلام (ASR). من المهم تحسين قابلية قراءة النص المكتوب للقارئ البشري وتسهيل مهام البرمجة اللغوية العصبية. تعالج الدولة من بين الفن هذه المشكلة باستخدام نماذج التعلم العميق المختلفة. في الآونة الأخيرة ، أثبتت نماذج المحولات نجاحها في مهام معالجة اللغات الطبيعية ، وقد تم استكشاف هذه النماذج قليلاً جدًا لمشكلة استعادة علامات الترقيم. في هذا العمل ، نستكشف نماذج مختلفة قائمة على المحولات ونقترح استراتيجية زيادة لهذه المهمة ، مع التركيز على اللغات عالية الموارد (الإنجليزية) وذات الموارد المنخفضة (البنغالية). بالنسبة للغة الإنجليزية ، نحصل على نتائج حديثة قابلة للمقارنة ، بينما بالنسبة إلى Bangla ، هذا هو أول عمل تم الإبلاغ عنه ، والذي يمكن أن يكون بمثابة أساس قوي للعمل في المستقبل. لقد جعلنا مجموعة بيانات Bangla المطورة متاحة للجمهور لمجتمع البحث.', 'pt': 'A restauração de pontuação é um problema comum de pós-processamento para sistemas de reconhecimento automático de fala (ASR). É importante melhorar a legibilidade do texto transcrito para o leitor humano e facilitar as tarefas de PNL. O estado da arte atual aborda esse problema usando diferentes modelos de aprendizado profundo. Recentemente, modelos de transformadores provaram seu sucesso em tarefas de PNL a jusante, e esses modelos têm sido muito pouco explorados para o problema de restauração de pontuação. Neste trabalho, exploramos diferentes modelos baseados em transformadores e propomos uma estratégia de aumento para esta tarefa, focando em linguagens de alto recurso (inglês) e de baixo recurso (bangla). Para o inglês, obtemos resultados comparáveis de última geração, enquanto para Bangla, é o primeiro trabalho relatado, o que pode servir como uma base sólida para trabalhos futuros. Disponibilizamos publicamente nosso conjunto de dados Bangla desenvolvido para a comunidade de pesquisa.', 'es': 'La restauración de la puntuación es un problema de posprocesamiento común en los sistemas de reconocimiento automático de voz (ASR). Es importante mejorar la legibilidad del texto transcrito para el lector humano y facilitar las tareas de PNL. El estado actual de la técnica aborda este problema utilizando diferentes modelos de aprendizaje profundo. Recientemente, los modelos de transformadores han demostrado su éxito en las tareas de PNL posteriores, y estos modelos se han explorado muy poco para el problema de la restauración de la puntuación. En este trabajo, exploramos diferentes modelos basados en transformadores y proponemos una estrategia de aumento para esta tarea, centrándonos en los idiomas de recursos altos (inglés) y de bajos recursos (bengalí). Para el inglés, obtenemos resultados comparables de vanguardia, mientras que para el bengalí, es el primer trabajo reportado, que puede servir como una base sólida para trabajos futuros. Hemos puesto a disposición del público nuestro conjunto de datos desarrollado en bengalí para la comunidad investigadora.', 'zh': '标点符号复者,自语音识 (ASR) 系统常见后处理也。 其于人也,转录文本可读性而趋NLP务甚重。 今之最先进者,用深度而学之。 近者,变压器形已验其成功于下流NLP,而其于标点符号复者鲜矣。 于是探转换器模样,务立方略,务存高(英语)低资源(孟加拉语)语。 其于英语也,先进而孟加拉语,一告也,可以为未来之强基线。 已将我辈开孟加拉数据集明供。', 'ja': '句読点復元は、自動音声認識（ ＡＳＲ ）システムの一般的な後処理問題である。ヒト読者のために転写されたテキストの可読性を向上させ、NLPタスクを容易にすることが重要である。現在の最先端の研究では、さまざまなディープラーニングモデルを使用してこの問題に対処している。最近では、変圧器モデルは、下流のNLPタスクで成功していることが証明されており、句読点復元問題については、これらのモデルはほとんど探索されていません。この研究では、異なる変圧器ベースのモデルを探索し、高リソース（英語）と低リソース（バンガラ語）の言語に焦点を当てて、このタスクの拡張戦略を提案します。英語では最先端の比較結果を得ており、バンガラ語では初めて報告された作品であり、今後の作品の強力なベースラインとなりうる。私たちは、開発したバンガラのデータセットを研究コミュニティに公開しました。', 'hi': 'विराम चिह्न पुनर्स्थापना स्वचालित वाक् पहचान (ASR) प्रणालियों के लिए एक सामान्य पोस्ट-प्रोसेसिंग समस्या है। मानव पाठक के लिए लिखित पाठ की पठनीयता में सुधार करना और एनएलपी कार्यों को सुविधाजनक बनाना महत्वपूर्ण है। वर्तमान राज्य के कला विभिन्न गहरी सीखने के मॉडल का उपयोग कर इस समस्या को संबोधित करते हैं। हाल ही में, ट्रांसफॉर्मर मॉडल ने डाउनस्ट्रीम एनएलपी कार्यों में अपनी सफलता साबित की है, और इन मॉडलों को विराम चिह्न बहाली समस्या के लिए बहुत कम खोजा गया है। इस काम में, हम विभिन्न ट्रांसफॉर्मर आधारित मॉडल का पता लगाते हैं और इस कार्य के लिए एक वृद्धि रणनीति का प्रस्ताव करते हैं, जो उच्च संसाधन (अंग्रेजी) और कम संसाधन (बांग्ला) भाषाओं पर ध्यान केंद्रित करते हैं। अंग्रेजी के लिए, हम तुलनीय अत्याधुनिक परिणाम प्राप्त करते हैं, जबकि बांग्ला के लिए, यह पहला रिपोर्ट किया गया काम है, जो भविष्य के काम के लिए एक मजबूत आधार रेखा के रूप में काम कर सकता है। हमने अपने विकसित बांग्ला डेटासेट को अनुसंधान समुदाय के लिए सार्वजनिक रूप से उपलब्ध कराया है।', 'ru': 'Восстановление пунктуации является распространенной проблемой постобработки для систем автоматического распознавания речи (ASR). Важно улучшить читаемость транскрибируемого текста для читателя и облегчить задачи NLP. Современное состояние решения этой проблемы с использованием различных моделей глубокого обучения. В последнее время трансформаторные модели доказали свой успех в задачах NLP ниже по потоку, и эти модели были изучены очень мало для проблемы восстановления пунктуации. В этой работе мы исследуем различные модели на основе трансформаторов и предлагаем стратегию расширения для этой задачи, уделяя особое внимание высокоресурсным (английским) и низкоресурсным (бенгальским) языкам. Что касается английского языка, то мы получаем сопоставимые современные результаты, в то время как для бенгальского языка это первая работа, о которой было сообщено и которая может служить надежной основой для будущей работы. Мы сделали наш разработанный набор данных Bangla общедоступным для исследовательского сообщества.', 'ga': 'Is fadhb iar-phróiseála choitianta é athchóiriú poncaíochta do chórais Aithint Urlabhra Uathoibríoch (ASR). Tá sé tábhachtach inléiteacht an téacs tras-scríofa a fheabhsú don léitheoir daonna agus tascanna NLP a éascú. Tugann an úrscothacht reatha aghaidh ar an bhfadhb seo trí úsáid a bhaint as samhlacha éagsúla domhainfhoghlama. Le déanaí, chruthaigh samhlacha claochladáin a n-rath ar thascanna NLP iartheachtacha, agus is beag an t-iniúchadh a rinneadh ar na samhlacha seo don fhadhb athchóirithe poncaíochta. San obair seo, déanaimid iniúchadh ar mhúnlaí éagsúla atá bunaithe ar chlaochladán agus molaimid straitéis mhéadaithe don tasc seo, ag díriú ar theangacha ard-acmhainne (Béarla) agus íseal-acmhainní (Bangla). Maidir leis an mBéarla, faightear torthaí den scoth inchomparáide, agus i gcás Bangla, is é an chéad saothar a thuairiscítear, a d’fhéadfadh feidhmiú mar bhonnlíne láidir d’obair amach anseo. Chuireamar ár tacar sonraí Bangla forbartha ar fáil go poiblí don phobal taighde.', 'hu': 'A pontozás helyreállítása gyakori utófeldolgozási probléma az automatikus beszédfelismerő (ASR) rendszereknél. Fontos, hogy javítsuk az átírt szöveg olvashatóságát az emberi olvasó számára, és megkönnyítsük az NLP feladatokat. A jelenlegi korszerű technológia különböző mélytanulási modellek segítségével kezeli ezt a problémát. A közelmúltban a transzformátormodellek sikerüket bizonyították a downstream NLP feladatokban, és ezeket a modelleket nagyon keveset vizsgálták fel az írásjelzés helyreállításának problémájára. Ebben a munkában különböző transzformátor alapú modelleket vizsgálunk fel, és javaslatot teszünk ehhez a feladathoz a nagy erőforrású (angol) és alacsony erőforrású (Bangla) nyelvekre összpontosítva. Az angol nyelven összehasonlítható, korszerű eredményeket kapunk, Bangla esetében pedig ez az első jelentett munka, amely erős alapként szolgálhat a jövőbeli munkák számára. Kifejlesztett Bangla adatkészletünket nyilvánosan hozzáférhetővé tettük a kutatóközösség számára.', 'el': 'Η αποκατάσταση στίξης είναι ένα κοινό πρόβλημα μετά την επεξεργασία για συστήματα αυτόματης αναγνώρισης ομιλίας (ASR). Είναι σημαντικό να βελτιωθεί η αναγνωσιμότητα του μεταγραφημένου κειμένου για τον ανθρώπινο αναγνώστη και να διευκολυνθεί η εργασία NLP. Η τρέχουσα κατάσταση της τεχνολογίας αντιμετωπίζει αυτό το πρόβλημα χρησιμοποιώντας διαφορετικά μοντέλα βαθιάς μάθησης. Πρόσφατα, τα μοντέλα μετασχηματιστών έχουν αποδείξει την επιτυχία τους σε μεταγενέστερες εργασίες και αυτά τα μοντέλα έχουν διερευνηθεί πολύ λίγα για το πρόβλημα αποκατάστασης στίξης. Σε αυτή την εργασία, εξερευνούμε διαφορετικά μοντέλα βασισμένα σε μετασχηματιστές και προτείνουμε μια στρατηγική αύξησης για αυτό το έργο, εστιάζοντας σε γλώσσες υψηλής περιεκτικότητας (αγγλικά) και χαμηλής περιεκτικότητας (Μπάνγκλα). Για τα αγγλικά, έχουμε συγκρίσιμα αποτελέσματα τελευταίας τεχνολογίας, ενώ για τη Μπάνγκλα, είναι το πρώτο αναφερόμενο έργο, το οποίο μπορεί να χρησιμεύσει ως ισχυρή βάση για μελλοντικές εργασίες. Έχουμε καταστήσει δημοσίως διαθέσιμο το αναπτυγμένο σύνολο δεδομένων της Μπάνγκλα για την ερευνητική κοινότητα.', 'ka': 'პონქუტეციის რესტოპაცია არის საერთო პოსტპროცესის პრობლემები ავტომატური სიტყვების განახსნა (ASR) სისტემისთვის. გასანიშვნელოვანია, რომ სახის კითხველისთვის ტრანსკრიბული ტექსტის კითხველისთვის უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ ამ პრობლემას მიმდინარე სიცოცხლის შესახებ განსხვავებული საშუალო სწავლების მოდელების გამოყენება. ახლა შემდეგ ტრანფორმეტრის მოდელები გამოწვება, რომ NLP მოქმედებში მისი წარმატება, და ეს მოდელები ძალიან პატარა პრობლემა პრობლემა პრობლემა. ამ სამუშაოში, ჩვენ განსხვავებული ტრანფორმენტების მოდელების გამოყენება და ამ სამუშაოს აგგენტაციის სტრატიგია, რომელიც უფრო მეტი რესურსისთვის (ანგლისური) და ცოტა რე ანგლისურად ჩვენ მივიღეთ შემდგომარებელი წარმოდგენების შედეგი, მაგრამ ბანგლაში, ეს არის პირველი შეტყობინებული სამუშაო, რომელიც შეიძლება იყოს ძალიან მუშაო მუშ ჩვენ განვითარებული ბანგლის მონაცემების საზოგადოებაში გავაკეთეთეთ.', 'it': "Il ripristino della punteggiatura è un problema comune di post-elaborazione per i sistemi di riconoscimento vocale automatico (ASR). È importante migliorare la leggibilità del testo trascritto per il lettore umano e facilitare i compiti della PNL. Lo stato dell'arte attuale affronta questo problema utilizzando diversi modelli di deep learning. Recentemente, i modelli di trasformatori hanno dimostrato il loro successo nelle attività NLP a valle, e questi modelli sono stati esplorati molto poco per il problema del ripristino della punteggiatura. In questo lavoro esploriamo diversi modelli basati su trasformatori e proponiamo una strategia di aumento per questo compito, concentrandoci sulle lingue ad alta risorsa (inglese) e a bassa risorsa (Bangla). Per l'inglese, otteniamo risultati comparabili allo stato dell'arte, mentre per Bangla, è il primo lavoro segnalato, che può servire da base solida per il lavoro futuro. Abbiamo reso pubblico il nostro set di dati Bangla sviluppato per la comunità di ricerca.", 'lt': 'Punktuacijos atkūrimas yra bendra automatinio kalbos atpažinimo (ASR) sistemų po apdorojimo problem a. Svarbu pagerinti transkripto teksto skaitomumą žmogaus skaitytojui ir palengvinti NLP užduotis. Dabartinė pažanga sprendžia šią problem ą naudojant skirtingus gilaus mokymosi modelius. Pastaruoju metu transformatorių modeliai įrodė sėkmę atliekant tolesnes NLP užduotis, ir šie modeliai buvo labai mažai ištirti taško atkūrimo problemai spręsti. Šiame darbe tiriame skirtingus transformatoriais pagrįstus modelius ir siūlome šios užduoties didinimo strategiją, kurioje daugiausia dėmesio skiriama didelių išteklių (anglų) ir mažų išteklių (banglos) kalboms. Anglų kalba gauname palyginamus pažangiausius rezultatus, o Banglos atveju tai pirmasis pranešimas apie darbą, kuris gali būti tvirtas pagrindas būsimam darbui. Mes paskelbėme savo parengtą Banglos duomenų rinkinį viešai prieinamą mokslinių tyrimų bendruomenei.', 'mk': 'Реставрацијата на точката е обичен проблем по процесорот за системите за автоматско препознавање на говорот (ASR). Важно е да се подобри читливоста на препишаниот текст за човечкиот читател и да се олесни NLP задачите. Сегашната современост го решава овој проблем користејќи различни модели за длабоко учење. Неодамна, трансформаторските модели го докажаа својот успех во понатамошните задачи на НЛП, а овие модели се истражувани многу малку за проблемот со реставрацијата на точката. Во оваа работа, ги истражуваме различните модели базирани на трансформатори и предложуваме стратегија за зголемување на оваа задача, фокусирајќи се на јазиците со високи ресурси (англиски) и ниски ресурси (Бангла). За англиски, добиваме споредливи најдобри резултати, додека за Бангла, тоа е првата објавена работа, која може да служи како силна основа за идната работа. Ја направивме нашата развиена бангласка податочна група јавно достапна за истражувачката заедница.', 'kk': 'Автоматты сөзді анықтау (ASR) жүйелерінің кәдімгі кейін өңдеу мәселесі. Адам оқушысы үшін жазылған мәтіннің оқу мүмкіндігін жақсарту және NLP тапсырмаларын көмектесу үшін маңызды. Бұл мәселеге қазіргі орындау үлгілерін қолдану үлгісін қолданады. Жуырдағы түрлендіруші үлгілері NLP тапсырмаларында өзінің сәттілігін көрсетті. Бұл үлгілерді түрлендіру мәселесі үшін өте кішкентай зерттеді. Бұл жұмыс ішінде біз басқа түрлендіруші үлгілерді зерттеп, осы тапсырманың көптегендіру стратегиясын ұсынып, жоғары ресурстар (ағылшын тілінде) және төмен ресурстар (Бангла) тілдер Ағылшын тілінде, біз салыстырылатын әртүрлі нәтижелерді аламыз. Бангла үшін бұл - бірінші хабарлаған жұмыс. Бұл болашақ жұмыс үшін күшті негізгі сызық болуы мүмкін. Біз Бангла деректер жиынымызды зерттеу коммуникасы үшін көпшілік жеткіздік.', 'ms': 'Pemulihan titik adalah masalah biasa selepas pemprosesan untuk sistem Pengenalan Cahaya Automatik (ASR). Penting untuk meningkatkan pembacaan teks ditranskrip untuk pembaca manusia dan memudahkan tugas NLP. Alamat kemajuan semasa ini menggunakan model belajar dalam berbeza. Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem.  In this work, we explore different transformer based models and propose an augmentation strategy for this task, focusing on high-resource (English) and low-resource (Bangla) languages.  Untuk bahasa Inggeris, kita mendapat hasil terbaik yang boleh dibandingkan, sementara untuk Bangla, ia adalah kerja pertama yang dilaporkan, yang boleh berkhidmat sebagai dasar yang kuat untuk kerja masa depan. Kami telah membuat set data Bangla yang telah dikembangkan kami tersedia publik untuk komuniti penyelidikan.', 'ml': 'Punctuation restoration is a common post-processing problem for Automatic Speech Recognition (ASR) systems.  മനുഷ്യന്\u200d വായിക്കുന്നതിനായി എഴുതിയ ടെക്സ്റ്റ് വായിക്കുന്നതിന്റെ വായിച്ചറിയാനും NLP ജോലികള്\u200dക്ക് സു നിലവിലുള്ള രാജ്യത്തിന്റെ വിലാസം വ്യത്യസ്ത ആഴത്തിലെ പഠിക്കുന്ന മോഡലുകള്\u200d ഉപയോഗിച്ചു് അടുത്തുതന്നെ, മാറ്റങ്ങളുടെ മോഡലുകള്\u200d നദിയിലെ NLP ജോലികളില്\u200d അവരുടെ വിജയം തെളിയിച്ചുകൊടുത്തിരിക്കുന്നു. ഈ മോഡലുകള്\u200d പ്രവര്\u200dത്ത ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d വ്യത്യസ്ത മാറ്റങ്ങളുടെ അടിസ്ഥാനമായ മോഡലുകള്\u200d പരിശോധിക്കുകയും, ഈ ജോലിക്കുവേണ്ടി കൂടുതല്\u200d കൂടുതല്\u200d പദ്ധതിയുണ്ടാ ഇംഗ്ലീഷിന് വേണ്ടി നമുക്ക് തുല്യമായ രീതിയിലേക്ക് ലഭിക്കുന്നു. ബംഗ്ലായിലേക്ക് ആദ്യത്തെ റിപ്പോര്\u200dട്ട് ചെയ്ത ജോലിയ ഞങ്ങള്\u200d നമ്മുടെ വികസിച്ച ബംഗ്ലാ ഡാറ്റാസെറ്റ് പ്രസ്താവികമായി നിര്\u200dമ്മിച്ചിരിക്കുന്നു. പ', 'no': 'Rettering av teikningar er eit vanleg post- prosesseringssystem for automatisk talegjenkjenning (ASR). Det er viktig å forbedra lesabiliteten av den transkripte teksten for menneskelsesamnet og gjera NLP-oppgåva til å letta. Denne problemet er i bruk av ulike dype læringsmodeller i gjeldande kunsttilstand. Nyleg har transformeringsmodeller bevist at sine suksess i NLP-oppgåver nedstrekker, og desse modelane har blitt utforska svært lite for problemet med oppretting av punkt. I dette arbeidet utforskar vi ulike transformeringsbaserte modeller og foreslår ein økningsstrategi for denne oppgåva, som fokuserer på høg ressurs (engelsk) og låg ressursspråk (Bangla). For engelsk får vi sammenlignbare resultat av kunsten, mens for Bangla er det første rapporterte arbeidet, som kan kalle som ein sterk baseline for framtidige arbeid. Vi har gjort vårt utviklet dataset i Bangla tilgjengeleg for forskningssamfunnet.', 'pl': 'Przywracanie interpunkcji jest częstym problemem po przetwarzaniu w systemach automatycznego rozpoznawania mowy (ASR). Ważne jest, aby poprawić czytelność transkrypcji tekstu dla człowieka i ułatwić zadania NLP. Aktualny stan techniki rozwiązuje ten problem przy użyciu różnych modeli głębokiego uczenia się. Ostatnio modele transformatorów udowodniły swój sukces w dalszych zadaniach NLP, a modele te zostały zbadane bardzo mało pod kątem problemu przywracania interpunkcji. W niniejszej pracy badamy różne modele oparte na transformatorach i proponujemy strategię rozszerzenia tego zadania, koncentrując się na językach o wysokich zasobach (angielski) i niskich zasobach (Bangla). W przypadku angielskiego uzyskujemy porównywalne wyniki najnowszej jakości, natomiast w przypadku Bangli jest to pierwsza zgłoszona praca, która może służyć jako silna baza dla przyszłych prac. Udostępniliśmy nasz opracowany zestaw danych Bangla publicznie dla środowiska badawczego.', 'mt': 'Ir-restawr tal-puntwazzjoni huwa problem a komuni ta’ wara l-ipproċessar għas-sistemi ta’ Rikonoxximent Awtomatiku tal-Kellem (ASR). It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks.  L-aktar avvanzati attwali jindirizzaw din il-problema bl-użu ta’ mudelli differenti ta’ tagħlim profond. Dan l-aħħar, mudelli ta’ trasformazzjoni wrew is-suċċess tagħhom fil-kompiti downstream tal-NLP, u dawn il-mudelli ġew esplorati ftit ħafna għall-problema tar-restawr tal-puntwazzjoni. F’dan ix-xogħol, aħna nesploraw mudelli differenti bbażati fuq trasformaturi u nipproponu strateġija ta’ żieda għal dan il-kompitu, li tiffoka fuq lingwi b’riżorsi għoljin (Ingliż) u b’riżorsi baxxi (Bangla). Għall-Ingliż, inkisbu riżultati avvanzati komparabbli, filwaqt li għall-Bangla, hija l-ewwel ħidma rrappurtata, li tista’ sservi bħala linja bażi qawwija għal xogħol futur. Aħna għamilna disponibbli pubblikament is-sett tad-dejta tal-Bangla żviluppat tagħna għall-komunità tar-riċerka.', 'mn': 'Загварын дахин сэргээх нь автоматаар ярианы танилцуулах (ASR) системийн нийтлэг дараагийн ажиллах асуудал юм. Хүмүүсийн уншигчийн уншигчийн унших чадварыг сайжруулах, NLP ажиллагааг нэмэгдүүлэх нь чухал. Одоогийн урлагийн хувьд энэ асуудлыг өөр гүн гүнзгий суралцах загваруудыг ашигладаг. Сүүлийн үед өөрчлөгчийн загварууд NLP дахь ажиллагаанд амжилтыг баталсан. Эдгээр загварууд цэгцээ дахин сэргээх асуудлыг маш бага судалсан. Энэ ажил дээр бид өөр өөр өөрчлөлтийн загваруудыг судалж, энэ ажил дээр нэмэгдүүлэх стратегийг санал болгож, өндөр ресурсов (Англи) болон бага ресурсов (Бангла) хэл дээр төвлөрүүлсэн. Англи хэлний хувьд бид харьцуулагдах урлагийн үр дүнг гаргадаг. Банглад хамгийн анхны мэдээллийн ажил юм. Энэ нь ирээдүйн ажилд хүчтэй суурь шугам болж чадна. Бид Банглагийн мэдээллийн санг судалгааны нийгэмд олон нийтэд ашиглаж чадсан.', 'ro': 'Restaurarea punctuației este o problemă comună de post-procesare pentru sistemele de recunoaștere automată a vorbirii (ASR). Este important să se îmbunătățească lizibilitatea textului transcris pentru cititorul uman și să se faciliteze sarcinile PNL. Actualele tehnologii abordează această problemă folosind diferite modele de învățare profundă. Recent, modelele transformatoare și-au dovedit succesul în sarcinile NLP din aval, iar aceste modele au fost explorate foarte puțin pentru problema restaurării punctuației. În această lucrare, explorăm diferite modele bazate pe transformatori și propunem o strategie de augmentare pentru această sarcină, concentrându-se pe limbile cu resurse ridicate (engleză) și cu resurse reduse (Bangla). Pentru limba engleză, obținem rezultate comparabile de ultimă generație, în timp ce pentru Bangla, este prima lucrare raportată, care poate servi drept o bază puternică pentru lucrările viitoare. Am făcut setul nostru de date Bangla dezvoltat public pentru comunitatea de cercetare.', 'sr': 'Restauracija nagodbe je zajednički problem postprocessiranja za automatski sistem prepoznavanja govora (ASR). Važno je poboljšati čitljivost prepisanog teksta za ljudski čitač i olakšati zadatke NLP-a. Trenutno stanje umjetnosti rješava ovaj problem koristeći različite modele dubokog učenja. Nedavno su transformacijski modeli dokazali svoj uspjeh u poslovima NLP-a, a ovi modeli su izuzetno malo istraženi za problem restauracije punctuacije. U ovom poslu istražujemo različite modele transformatora i predlažemo strategiju povećanja ovog zadatka, fokusiranje na jezike visokih resursa (engleski) i niskog resursa (Bangla). Za engleski dobijamo usporedbene rezultate umetnosti, dok za Banglu, to je prvi prijavljeni posao, koji može služiti kao jaki osnovni cilj za budući rad. Naša razvijena Bangla podataka smo javno dostupna za istraživačku zajednicu.', 'si': 'ස්වයංක්\u200dරිය විරාම පස්සේ ප්\u200dරක්\u200dරියාම ප්\u200dරශ්නයක් ස්වයංක්\u200dරිය භාෂාව ප්\u200dරතික්\u200dරියාපනය (ASR) පද් මිනිස්සු කියවන්න පාළුවන්ට ලියපු පාළුවේ කියවන්න පුළුවන් වැඩි වැඩි කරන්න සහ NLP වැඩ කරන්න සැලසුම් කරන මේ ප්\u200dරශ්නය වෙනස් ගොඩක් ඉගෙන ගන්න ප්\u200dරශ්නයක් භාවිත කරන්න. අවසානයෙන්, ප්\u200dරවර්තනයක් නිර්මාණය කරනවා ඔවුන්ගේ සාර්ථකය NLP වැඩේ සාර්ථක විදියට, ඒ වගේම මොඩේල් ප්\u200dරශ්නයක් විදිය මේ වැඩේ අපි වෙනස් විදිහට වෙනස් වෙනස් විදිහට අධාරිත විදිහට අධාරිත විදිහට පරීක්ෂා කරනවා සහ මේ වැඩ සඳහා විශාල විදිහට ඉංග්\u200dරීසි වලින්, අපිට සම්බන්ධ වෙන්න පුළුවන් විදියට තියෙන්න පුළුවන් විදියට, බැන්ග්ලා වලින්, ඒක තමයි පළමු වා අපි බැන්ග්ලා දත්ත සංවිධානය ලොකු සාමාන්\u200dයයෙන් පරීක්ෂණ සමාජයෙන් ප්\u200dරවේශ කරන්න පුළු', 'so': 'Isticmaalka dib u baaraandegista waa dhibaato caadi ah nidaamka aqoonsashada afka (ASR). Waa muhiim in la hagaajiyo awoodda akhriska warqadda qoran ee akhriska dadweynaha iyo in la fududeeyo shaqada NLP. Xaaladaha farshaxanka ah ee joogtada ah wuxuu ku habboon dhibaatadan si uu u isticmaalo noocyo waxbarasho aad u dheer. Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem.  Markaas waxan, waxaynu baaraynaa qaabab kala duduwan oo isbedelka ah, waxaana soo jeedinaynaa qoraal kordhiska shaqadaas, waxaana ku kalsoonaynaa luuqadaha sare (Ingiriis) iyo luqadaha hoose (Bangla). Ingiriiska aawadiis, waxaynu helaynaa xaalad u eg arimaha farshaxanta, marka loo yaqaan Bangla waa shaqada ugu horeysa ee la soo sheegay, kaas oo u adeegi kara sida koob xoog leh oo u shaqeeya shaqada mustaqbalka. Waxaannu bangla ka dhignay kooxda macluumaadka ee horumarinta ee Bangla si bayaan ah loo heli karo bulshada baaritaanka.', 'sv': 'Stänkningsåterställning är ett vanligt efterbehandlingsproblem för ASR-system (Automatic Speech Recognition). Det är viktigt att förbättra läsbarheten av den transkriberade texten för den mänskliga läsaren och underlätta NLP-uppgifter. Nuvarande toppmoderna lösningar hanterar detta problem med hjälp av olika modeller för djupinlärning. Nyligen har transformatormodeller visat sin framgång i nedströms NLP uppgifter, och dessa modeller har utforskats mycket lite för punkteringsåterställningsproblemet. I detta arbete utforskar vi olika transformatorbaserade modeller och föreslår en förstärkningsstrategi för denna uppgift, med fokus på högresursspråk (engelska) och lågresursspråk (Bangla). För engelska erhåller vi jämförbara toppmoderna resultat, medan för Bangla är det första rapporterade arbetet, som kan fungera som en stark bas för framtida arbete. Vi har gjort vårt utvecklade Bangla dataset offentligt tillgängligt för forskarsamhället.', 'ta': 'தானியங்கி பேச்சு அடையாளம் (ASR) அமைப்புகளுக்கான பொதுவான பின்செயல்படுத்தல் பிரச்சனையாகும். மனித படிப்பவருக்கான எழுதப்பட்ட உரையின் படித்தலை மேம்படுத்தி NLP பணிகளை எளிதாக்குவது முக்கியமானது. தற்போதைய நிலை- கலை முகவரி Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem.  இந்த வேலையில், நாம் வேறு மாற்றம் அடிப்படையிலான மாதிரிகளை தேடி இந்த பணிக்கான மேம்படுத்தல் திட்டத்தை பரிந்துரைக்கிறோம், அதிக மூலத்தை மேல்  ஆங்கிலத்திற்கு, நாங்கள் ஒப்பிட்ட-கலை முடிவுகளை பெறுகிறோம், பாங்கிலாவுக்கு, இது முதல் அறிவிக்கப்பட்ட வேலை, அது எதிர்கால வேலை நாங்கள் எங்கள் உருவாக்கப்பட்ட Bangla தகவல் அமைப்பை ஆராய்ச்சி சமூகத்திற்கு பொதுவாக கிடைக்கும்.', 'ur': 'پونچوٹ پھیرنے کا ایک عام پوسٹ پرسس پھیرنے کے مسئلہ ہے آٹوٹی بات پھیرنے (ASR) سیسٹم کے لئے. انسان کے پڑھنے والے کے لئے لکھے ہوئے پیغام کے پڑھنے کی طاقت زیادہ اہم ہے اور NLP کے کاموں کو آسان کرنے کا۔ اس مسئلہ کو مختلف عمیق سیکھنے کی موڈل کے مطابق موجود بناتے ہیں. اچھا، ٹورنسٹر موڈلز نے ان کے کاموں میں ان کے کامیابی کو دکھایا ہے، اور یہ موڈلے نقطہ بازسازی مشکل کے لئے بہت کم تحقیق کیے گئے ہیں. اس کام میں، ہم مختلف تغییر پھیلانے کے متعلق موڈل کا تحقیق کر رہے ہیں اور اس کام کے لئے اضافہ استراتژی پیشنهاد کررہے ہیں، بالا-رسورس (انگلیسی) اور کم-رسورس (بنگلا) زبانوں پر تمرکز کررہے ہیں۔ انگلیسی کے لئے ہم مقایسہ قابل تحقیق کے نتائج حاصل کرتے ہیں، حالانکہ بنگلا کے لئے یہ سب سے پہلے گزارے ہوئے کام ہے، جو مستقبل کام کے لئے مضبوط بنسٹلین کے طور پر استعمال کر سکتا ہے. ہم نے بنگلا ڈاٹ سٹ کو تحقیق کمونٹی کے لئے ظاہر طور پر موجود بنایا ہے۔', 'uz': "Name Inson o'qituvchi matnning oʻqishni oshirish va NLP vazifalarini foydalanish muhim. @ info Yaqinda o'zgarishlar modellari NLP vazifalarining quyidagi muvaffaqiyatlarini ko'rsatadi, va bu modellar qayta tiklash muammolari uchun juda qisqa ko'rinadi. Bu ishda biz boshqa shakllarni o'rganamiz va bu vazifa uchun qo'shish strategiya talab qilamiz, eng yuqori resource (Ingliz) va kichkina resource (Bangla) tillariga foydalanamiz. Ingliz tilida biz o'xshash sanalar natijasi natijalariga ega bo'laymiz. Bu Bangla uchun birinchi haqida hisoblanadigan ishlar, bu kelajak ishni bajarish uchun katta asosiy bazasini bajarishi mumkin. Biz Bangla maʼlumotlarimizni o'rganish jamoasi uchun jamiyatlarni hosil qildik.", 'vi': 'Việc phục hồi ký hiệu là một vấn đề phổ biến sau khi xử lý hệ thống Phát âm (ASR). Việc đọc đoạn ghi chép cho người đọc là rất quan trọng và dễ dàng thực hiện các nhiệm vụ của NLP. Đây là vấn đề hiện thời, dùng các mô hình học sâu khác nhau. Cách gần đây, các mẫu máy biến đổi đã chứng minh thành công trong các công việc sục sạo xuôi dòng, và các mô hình này đã được tìm hiểu rất ít về vấn đề phục chế độ chấm. Trong công việc này, chúng tôi nghiên cứu các mô hình dựa trên người biến đổi khác nhau và đề xuất một chiến lược gia tăng cho nhiệm vụ này, tập trung vào ngôn ngữ chất lượng cao (Anh) và ít nguồn (Bangla). Đối với tiếng Anh, chúng tôi có kết quả hiện đại so sánh, trong khi đối với Bangla, đó là công việc đầu tiên báo cáo, có thể đóng vai một cơ sở vững chắc cho công việc tương lai. Chúng tôi đã công khai công khai bộ dữ liệu của Bangla này cho cộng đồng nghiên cứu.', 'da': 'Punktuation restaurering er et almindeligt efterbehandlingsproblem for automatiske talegenkendelsessystemer (ASR). Det er vigtigt at forbedre læsbarheden af den transskriberede tekst for den menneskelige læser og lette NLP-opgaver. Nuværende state-of-art løser dette problem ved hjælp af forskellige deep learning modeller. For nylig har transformermodeller bevist deres succes i downstream NLP-opgaver, og disse modeller er blevet udforsket meget lidt for tegnsætningsrestaurangsproblemet. I dette arbejde undersøger vi forskellige transformer baserede modeller og foreslår en augmentationsstrategi for denne opgave med fokus på high-resource (engelsk) og low-resource (Bangla) sprog. For engelsk opnår vi sammenlignelige state-of-the-art resultater, mens det for Bangla er det første rapporterede arbejde, som kan tjene som en stærk base for fremtidigt arbejde. Vi har gjort vores udviklede Bangla datasæt offentligt tilgængeligt for forskningssamfundet.', 'bg': 'Възстановяването на пунктуацията е често срещан проблем след обработка на системите за автоматично разпознаване на реч (АСР). Важно е да се подобри четливостта на транскриптирания текст за човешкия читател и да се улеснят задачите по НЛП. Настоящите съвременни технологии решават този проблем с помощта на различни модели на дълбоко обучение. Напоследък моделите на трансформатори доказаха успеха си в задачите надолу по веригата и тези модели са изследвани много малко за проблема с възстановяването на пунктуацията. В тази работа изследваме различни трансформаторни модели и предлагаме стратегия за увеличаване на тази задача, фокусирайки се върху високоресурсни (английски) и нискоресурсни (бангла) езици. За английския език получаваме сравними най-съвременни резултати, докато за Бангла това е първата докладвана работа, която може да послужи като силна база за бъдеща работа. Направихме нашия разработен набор от данни от Бангла публично достъпен за изследователската общност.', 'hr': 'Restauracija nagrade je zajednički problem postprocessiranja za automatski sustav prepoznavanja govora (ASR). Važno je poboljšati čitljivost prepisanog teksta za ljudski čitač i olakšati zadatke NLP-a. Trenutno stanje umjetnosti rješava ovaj problem s različitim modelima dubokog učenja. Nedavno su modeli transformacije dokazali svoj uspjeh u poslovima NLP-a, a ovi modeli su izuzetno malo istraženi za problem restauracije punctuacije. U ovom poslu istražujemo različite modele transformatora i predlažemo strategiju povećanja ovog zadatka, fokusiranje na jezike visokih resursa (engleski) i niskih resursa (Bangla). Za engleski dobijamo usporedbene rezultate umjetnosti, dok za Banglu, to je prvi izvješten posao, koji može služiti kao jaki početni cilj za budući rad. Naša razvijena Bangla podataka je javno dostupna za istraživačku zajednicu.', 'nl': 'Interpunctuatieherstel is een veelvoorkomend probleem bij automatische spraakherkenning (ASR)-systemen. Het is belangrijk om de leesbaarheid van de getranscribeerde tekst voor de menselijke lezer te verbeteren en NLP-taken te vergemakkelijken. De huidige state-of-art aanpak van dit probleem met behulp van verschillende deep learning modellen. Onlangs hebben transformatormodellen hun succes bewezen in downstream NLP-taken, en deze modellen zijn zeer weinig onderzocht voor het interpunctieherstelprobleem. In dit werk onderzoeken we verschillende transformatorgebaseerde modellen en stellen we een augmentatiestrategie voor voor deze taak voor, gericht op high-resource (Engels) en low-resource (Bangla) talen. Voor het Engels krijgen we vergelijkbare state-of-the-art resultaten, terwijl het voor Bangla het eerste gerapporteerde werk is, dat kan dienen als een sterke basis voor toekomstig werk. We hebben onze ontwikkelde Bangla dataset openbaar gemaakt voor de onderzoeksgemeenschap.', 'de': 'Interpunktionswiederherstellung ist ein häufiges Nachbearbeitungsproblem für automatische Spracherkennung (ASR). Es ist wichtig, die Lesbarkeit des transkribierten Textes für den menschlichen Leser zu verbessern und NLP-Aufgaben zu erleichtern. Aktueller Stand der Technik adressiert dieses Problem mit verschiedenen Deep Learning Modellen. In letzter Zeit haben Transformatormodelle ihren Erfolg in nachgelagerten NLP-Aufgaben bewiesen, und diese Modelle wurden nur sehr wenig für das Problem der Interpunktionswiederherstellung untersucht. In dieser Arbeit untersuchen wir verschiedene transformatorbasierte Modelle und schlagen eine Augmentationsstrategie für diese Aufgabe vor, die sich auf ressourcenintensive (Englisch) und ressourcenarme (Bangla) Sprachen konzentriert. Für Englisch erhalten wir vergleichbare Ergebnisse auf dem neuesten Stand der Technik, während es sich bei Bangla um die erste berichtete Arbeit handelt, die als starke Grundlage für zukünftige Arbeiten dienen kann. Wir haben unseren entwickelten Bangla-Datensatz für die Forschungsgemeinschaft öffentlich zugänglich gemacht.', 'id': 'Pemulihan punctuasi merupakan masalah postproses umum untuk sistem Pengenalan Bicara Otomatis (ASR). It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks.  Masalah modern saat ini mengatasi masalah ini menggunakan model belajar dalam yang berbeda. Baru-baru ini, model transformer telah membuktikan sukses mereka dalam tugas NLP turun, dan model-model ini telah dieksplorasi sangat sedikit untuk masalah pemulihan punctuasi. Dalam pekerjaan ini, kami mengeksplorasi model berbeda berdasarkan transformator dan melamar strategi peningkatan untuk tugas ini, fokus pada bahasa-bahasa yang memiliki sumber daya tinggi (Inggris) dan sumber daya rendah (Bangla). Untuk bahasa Inggris, kita mendapatkan hasil terbaik yang dapat dibandingkan, sementara untuk Bangla, ini adalah pekerjaan pertama yang dilaporkan, yang dapat melayani sebagai dasar yang kuat untuk pekerjaan masa depan. Kami telah membuat dataset Bangla yang dikembangkan kami tersedia publik untuk komunitas penelitian.', 'ko': '구두점 복구는 자동음성인식(ASR) 시스템에서 흔히 볼 수 있는 후처리 문제다.인류 독자에게 기록 텍스트의 가독성을 높이고 NLP를 촉진하는 임무는 매우 중요하다.현재의 최신 기술은 서로 다른 심도 있는 학습 모델을 사용하여 이 문제를 해결한다.최근 트랜스퍼 모델은 다운스트림 NLP 임무에서 성공적이라는 것이 증명되었고 문장부호 복구 문제에 대한 연구는 매우 적다.이 작업에서 우리는 서로 다른 변환기 기반 모델을 탐색했고 이 임무에 대해 증강 전략을 제시했으며 고자원(영어)과 저자원(방글라데시어) 언어에 중점을 두었다.영어에 대해 우리는 비교할 수 있는 최신 성과를 얻었고 방글라데시에 대해서는 처음으로 보고한 업무로 미래 업무의 유력한 기선이 될 수 있다.우리는 이미 연구계에 우리가 개발한 방글라데시어 데이터 집합을 공개했다.', 'fa': 'بازسازی نقاط یک مشکل بعد از پردازش مشترک برای سیستم شناسایی سخنرانی خودکار (ASR) است. مهم است که درخواست توانایی متن نوشته شده برای خواننده انسان را بهتر کنیم و کار NLP را آسان سازیم. این مشکل را با استفاده از مدل یادگیری عمیق متفاوت درباره موقعیت هنر فعلی حل می\u200cکند. اخیرا، مدل تغییر دهنده\u200cها موفقیت خود را در کارهای NLP پایین پایین ثابت کرده\u200cاند، و این مدل\u200cها برای مشکل بازسازی نقطه\u200cها خیلی کم تحقیق شده\u200cاند. در این کار، ما مدل های تغییر دهنده متفاوت را تحقیق می کنیم و یک استراتژی افزایش برای این کار پیشنهاد می کنیم، تمرکز به زبانهای منابع بالا (انگلیسی) و منابع کم (بنگلا). برای انگلیسی، نتیجه\u200cهای مقایسه\u200cای از موقعیت هنری را دریافت می\u200cکنیم، در حالی که برای بنگلا، این اولین کار گزارش داده شده است که می\u200cتواند به عنوان یک خط پایین قوی برای کار آینده خدمت کند. ما مجموعه داده های بنگلا را برای جامعه تحقیقات به طور عمومی در دسترس دادیم.', 'sw': 'Ufupishaji wa Udhibiti ni tatizo la kawaida la baada ya kuchukuliwa kwa mfumo wa kujitambua kujieleza (ASR). It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks.  Hali ya sanaa ya sasa inaelezea tatizo hili kwa kutumia mifano tofauti ya kujifunza. Hivi karibuni, mifano ya mabadiliko imethibitisha mafanikio yao katika kazi za NLP chini ya mto, na mifano hii imekuwa ikichunguzwa kidogo sana kwa matatizo ya kurekebisha upya. Katika kazi hii, tunatafuta mifano tofauti ya mabadiliko na tunapendekeza mkakati wa kuongeza kwa kazi hii, tunalenga lengo la rasilimali za juu (Kiingereza) na rasilimali za chini (Bangla). Kwa Kiingereza, tunapata matokeo yanayofanana na hali ya sanaa, wakati kwa Bangla, hii ni kazi ya kwanza inayoripotiwa, ambayo inaweza kutumika kama msingi wa kazi za baadaye. Tumefanya taarifa zetu zilizoendelea Bangla zinazopatikana hadharani kwa ajili ya jamii ya utafiti.', 'tr': 'Noqtalama gapdalanmasy Otomatik Speech Tanyş (ASR) sistemleri üçin umumy ýene-de işlemek meselesidir. İnsan okuwçysy üçin ýazylan metiniň okamak ukyplygyny geliştirmek we NLP işini bejermek üçin wajyplyg. Häzirki sanat meýdançasynda bu meseleyi çykyş derin öwrenmek nusgalaryny ullanýar. Soňky wagtlar, üýtgetmeli nusgalar NLP işinde başarylygyny bardylar we bu nusgalar noktalaryň ýene-de bir meselede örän az ylşyryldyr. Bu işde, biz dürli transformatçylar tabanly nusgalary keşfetýäris we bu işiň üçin ýetişiklik stratejiýany teklip edip, ýokary resurslar (iňlisçe) we ýokary resurslar (Bangla) dillerine üns berýäris. Iňlisçe, Bangla üçin ýakynlaşyk möhüm taýýarlaşyk netijeleri aldyk. Bu ilkinji hasaplanýan işdir, gelejekde işiň üçin güýçli üýtgeşik bolup biler. Biz Banglanyň gelişmegimizi barlag jemgyýetiniň üçin halkara üýtgedilişi berdik.', 'sq': 'Rikthimi i pikturave është një problem i përbashkët pas-procesimit për sistemet e njohjes automatike të fjalës (ASR). Është e rëndësishme të përmirësohet lexueshmëria e tekstit të transkriptuar për lexuesin njerëzor dhe të lehtësohet detyra e NLP. Aktualiteti aktual trajton këtë problem duke përdorur modele të ndryshme mësimi të thellë. Recently, transformer models have proven their success in downstream NLP tasks and these models have been explored very little for the punctuation restoration problem. Në këtë punë, ne eksplorojmë modele të ndryshme bazuar në transformues dhe propozojmë një strategji rritjeje për këtë detyrë, duke u përqëndruar në gjuhët me burime të larta (anglisht) dhe me burime të ulëta (Bangla). For English, we obtain comparable state-of-the-art results, while for Bangla, it is the first reported work, which can serve as a strong baseline for future work.  Kemi bërë të dhënat tona të zhvilluara në Bangla të disponueshme publikisht për komunitetin kërkimor.', 'af': "Punktuasie herstelling is 'n gemeenskaplike post- verwerking probleem vir outomatiese spraak herkening (ASR) stelsels. Dit is belangrik om die leesbaarheid van die transkripteerde teks vir die menslike leser te verbeter en NLP-opdragte te eenvoudig. Huidige staat van kuns adres hierdie probleem met verskillende diep leer modele. Onlangs het transformer modele hulle sukses in NLP-opdragte bevestig, en hierdie modele is baie klein ondersoek vir die punktuasie herstelling probleem. In hierdie werk, ondersoek ons verskillende transformeerder gebaseerde modele en voorstel ons 'n vergroot strategie vir hierdie taak, fokus op hoë-hulpbron (Engels) en lae-hulpbron (Bangla) tale. Vir Engels kry ons vergelykbare staat van die kuns resultate, terwyl vir Bangla, dit is die eerste vergelykte werk, wat kan dien as 'n sterk basislin vir toekomstige werk. Ons het ons ontwikkelde Bangla-datastel openlik beskikbaar gemaak vir die ondersoek gemeenskap.", 'am': 'ምርጫዎች የጻፈውን ጽሑፍ ለሰው አነባቢው ማቀናቀል እና NLP ስራዎችን ማግናኘት ያስፈልጋል፡፡ የአሁኑን ሁኔታ አድራሻ በአሁኑ ጊዜ የለውጥ ሞዴል ከNLP ስራ በታች ስኬታቸውን አግኝቷል፣ እነዚህም ሞዴላዎች ለመቆጣጠር ጉዳይ በጣም ጥቂት ሆኖአል፡፡ በዚህ ሥራ የተለያየ ለውጦችን ምሳሌዎች እንፈልጋለን እና ለዚህ ስርዓት ማስታወቂያ strategy እና ከፍተኛ resource (እንግሊዘኛ) እና የዝቅተኛ resource (ባንግሊላ) ቋንቋዎች ላይ ትኩረትን እናስመክራለን፡፡ እንግሊዝኛ፣ የዓላማ ፍሬት ትክክል አግኝተናል፡፡ የባንጋላን ዳውታዎችን ለትምህርት ማኅበረሰብ ግልፅ ሰጥተናል፡፡', 'az': 'Nöqtə yenilənməsi Avtomatik Söz Tanıması (ASR) sistemlərinin ortaq post-processing problemidir. İnsan okuyucu üçün yazılmış mətnin oxuyabilməsi və NLP işlərini asanlaşdırmaq vacib. Bu problemi müxtəlif dərin öyrənmə modellərindən istifadə edir. Son zamanlarda, transformer modelləri NLP işlərində başarısızlıqlarını təsdiq etdilər və bu modellər punctuation restoration problemi üçün çox az keşfedildi. Bu işdə, biz müxtəlif transformer modellərini keşfetirik və bu işin yüksək ressurs (İngilizə) və düşük ressurs (Bangla) dillərinə çoxluğunu təklif edirik. İngilizce dilində, bizim müqayisədə müqayisədə sanat sonuçlarını alırıq. Bangla üçün bu ilk rapor edilmiş iş, gələcək işin güclü səhifəsi olar. Biz Bangla veri quruluğumuzu araşdırma toplumuna açıq-aşkar faydalandırdıq.', 'bn': 'স্বয়ংক্রিয় ভাষার স্বাক্ষর স্বীকৃতির (ASR) সিস্টেমের জন্য পুনচুক্তি পুনরুদ্ধারের একটি সাধারণ পোস্ট প্রক্ মানুষ পাঠকের জন্য লেখা লেখার পড়তে পারে এবং এনএলপি কাজের সুবিধা প্রদান করা গুরুত্বপূর্ণ। বর্তমান অবস্থা- শিল্পের ঠিকানা এই সমস্যাটি ভিন্ন গভীর শিক্ষা মডেল ব্যবহার করে। সম্প্রতি এনএলপি কাজে পরিবর্তনের মডেল তাদের সফল প্রমাণ করেছে এবং এই মডেলগুলো পুনরুদ্ধারের সমস্যার জন্য খুব কম খুঁজে বের করা হয়েছে। এই কাজে আমরা বিভিন্ন ভিত্তিক পরিবর্তনের মডেল খুঁজে বের করি এবং এই কাজের জন্য একটি বাড়ানোর কৌশল প্রস্তাব করি, যার প্রতি মনোযোগ দেয় উচ্চ সম্পদ (ইংরেজী) এব ইংরেজীর জন্য আমরা তুলনামূলক শিল্পের ফলাফল পাই, আর বাংলার জন্য এটি প্রথম রিপোর্ট করা কাজ, যা ভবিষ্যতের কাজের জন্য শক্তিশালী বেসাইন হিস আমরা আমাদের উন্নয়ন বাংলা ডাটাসেট প্রকাশ্যে গবেষণা সম্প্রদায়ের জন্য পাওয়া যাচ্ছি।', 'bs': 'Restauracija prestanka je zajednički problem postprocessiranja za automatski sistem prepoznavanja govora (ASR). Važno je poboljšati čitljivost prepisanog teksta za ljudski čitač i olakšati zadatke NLP-a. Trenutno stanje umjetnosti rješava ovaj problem koristeći različite modele dubokog učenja. Nedavno su modeli transformacije dokazali svoj uspjeh u poslovima NLP-a, a ovi modeli su izuzetno malo istraženi za problem restauracije punctuacije. U ovom poslu istražujemo različite modele transformatora i predlažemo strategiju povećanja ovog zadatka, fokusiranje na jezike visokog resursa (engleski) i niskog resursa (Bangla). Za engleski, dobijamo usporedbene rezultate umjetnosti, dok za Banglu, to je prvi prijavljeni posao, koji može služiti kao jaki početni cilj za budući rad. Naša razvijena Bangla podataka smo javno dostupna za istraživačku zajednicu.', 'ca': "La restauració de puntuació és un problem a comun de postprocessament dels sistemes de reconeixement automàtic de la voz (ASR). It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks.  L'actualitat es tracta d'aquest problema fent servir diferents models d'aprenentatge profund. Recentment, els models transformadors han demostrat el seu èxit en tasques avall de NLP, i aquests models han estat explorats molt poc per al problema de la restauració de puntuació. En aquesta feina, explorem diferents models basats en transformadors i proposem una estratègia d'augmentació per aquesta tasca, centrant-nos en llengües d'alt recurso (anglès) i de baix recursos (Bangla). Per a l'anglès, obtenim resultats d'última generació comparables, mentre que per a Bangla, és la primera feina que es diu, que pot servir de base forta per a la feina futura. We have made our developed Bangla dataset publicly available for the research community.", 'cs': 'Obnovení interpunkce je běžným problémem po zpracování systémů automatického rozpoznávání řeči (ASR). Je důležité zlepšit čitelnost přepisovaného textu pro čtenáře a usnadnit NLP úkoly. Současný stav techniky řeší tento problém pomocí různých modelů hlubokého učení. V poslední době modely transformátorů prokázaly svůj úspěch v následných úkolech NLP a tyto modely byly zkoumány velmi málo pro problém obnovy interpunkce. V této práci zkoumáme různé modely založené na transformátorech a navrhujeme pro tento úkol strategii rozšíření se zaměřením na jazyky s vysokými zdroji (angličtina) a s nízkými zdroji (Bangla). U angličtiny získáváme srovnatelné nejmodernější výsledky, zatímco u Bangly je to první hlášená práce, která může sloužit jako silný základ pro budoucí práci. Náš vyvinutý datový soubor Bangla jsme zpřístupnili veřejně výzkumné komunitě.', 'hy': 'Պունկցիայի վերականգնումը ավտոմատիկ խոսքի հայտնաբերման (ASR) համակարգերի ընդհանուր հետվերարտադրման խնդիր է: Կարևոր է բարելավել մարդկային կարդացողի համար վերագրված տեքստի կարելի կարդալը և հեշտացնել ՆԼՊ-ի առաջադրանքները: Ներկայումնական տեխնոլոգիաները լուծեն այս խնդիրը օգտագործելով տարբեր խորը ուսումնասիրության մոդելներ: Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem.  Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք տարբեր վերափոխողների հիմնված մոդելներ և առաջարկում ենք այս խնդրի համար բարձրացման ռազմավարություն, կենտրոնացնելով բարձր ռեսուրսների (անգլերեն) և ցածր ռեսուրսների (Բանգլա)  Անգլերենի համար մենք ստանում ենք համեմատական բարձր արդյունքներ, մինչդեռ Բանգլայի համար դա առաջին հայտարարված աշխատանքն է, որը կարող է օգտագործվել որպես ապագա աշխատանքի ուժեղ հիմք: Մենք մեր զարգացած Բանգլայի տվյալների համակարգը հանրային հասանելի դարձրել ենք հետազոտական համայնքի համար:', 'et': 'Punktsioonide taastamine on automaatse kõnetuvastuse (ASR) süsteemide tavaline järeltöötlusprobleem. Oluline on parandada transkribeeritud teksti loetavust inimlugejale ja hõlbustada uue õppekava ülesandeid. Praegune tehnoloogia lahendab selle probleemi erinevate sügavõppe mudelite abil. Hiljuti on trafo mudelid tõestanud oma edukust järgnevates NLP ülesannetes ja neid mudeleid on vahemärkide taastamise probleemi jaoks väga vähe uuritud. Käesolevas töös uurime erinevaid trafopõhiseid mudeleid ja pakume välja selle ülesande suurendamise strateegia, keskendudes suure ressursiga (inglise) ja vähese ressursiga (Bangla) keeltele. Inglise keeles saame võrreldavaid tipptasemel tulemusi, samas kui Bangla puhul on see esimene teatatud töö, mis võib olla tugev lähtealus tulevaste tööde jaoks. Oleme teinud oma väljatöötatud Bangla andmekogumi teadusringkondadele avalikult kättesaadavaks.', 'fi': 'Vﾃ､lipisteiden palauttaminen on yleinen automaattinen puheentunnistusjﾃ､rjestelmien jﾃ､lkikﾃ､sittelyongelma. On tﾃ､rkeﾃ､ﾃ､ parantaa kirjoitetun tekstin luettavuutta ihmislukijalle ja helpottaa NLP-tehtﾃ､viﾃ､. Nykyaikainen huipputekniikka kﾃ､sittelee tﾃ､tﾃ､ ongelmaa erilaisten syvﾃ､oppimisen mallien avulla. Viime aikoina muuntajamallit ovat osoittaneet menestyksensﾃ､ jatkojalostuksen NLP-tehtﾃ､vissﾃ､, ja nﾃ､itﾃ､ malleja on tutkittu hyvin vﾃ､hﾃ､n vﾃ､limerkkien restaurointiongelmaan. Tﾃ､ssﾃ､ tyﾃｶssﾃ､ tutkimme erilaisia muuntajapohjaisia malleja ja ehdotamme tﾃ､hﾃ､n tehtﾃ､vﾃ､ﾃ､n lisﾃ､strategiaa keskittyen suuriresurssisiin (englanti) ja vﾃ､hﾃ､resurssisiin (Bangla) kieliin. Englannin osalta saamme vertailukelpoisia huipputason tuloksia, kun taas Banglan osalta se on ensimmﾃ､inen raportoitu tyﾃｶ, joka voi toimia vahvana lﾃ､htﾃｶkohdana tulevalle tyﾃｶlle. Olemme asettaneet kehitetyn Bangla-aineistomme julkisesti tutkimusyhteisﾃｶn saataville.', 'jv': 'Sample rate Kiweke ngomong luwih akeh perusahaan seneng nggawe Text nggap kanggo Kebebasan ora oleh bantuan karo nggawe NLP. politenessoffpolite"), and when there is a change ("assertivepoliteness plug-in-action Nang trabah iki, kita maneh akeh model sing saben nggawe banjur banjur ngetokake sistem sing nyebuturan kanggo nggawe lan nggawe barang akeh-recurs (Inggris) lan kelas-recurs (bangla). kanggo Inggris, awake dhéwé ngerasakno perusahaan-perusahaan kanggo ngerasakno karo hal sing dumadhi kanggo nggalakno bangla, iki dadi sing susahé perusahaan kanggo ngerasakno sing bisa dianggap sing bisa dianggap sing bisa dianggap dhéwé. Awak dhéwé wis nggawe dataset bangla nggawe publik gawe kanggo kebebasan resmi.', 'ha': "@ action: button Kima muhimu ya improve karatun matsayin da aka rubuta wa mutane kuma ya sauƙi da aikin NLP. @ action A yanzu, misalin transformation sun gaskata succen su a cikin aikin NLP na ƙarami, kuma an sami waɗannan misãlai da aka samu don matabbatar da mazaunin da za'a samu. Daga wannan aikin, muna karatun misãlai daban-daban na shige kuma munã buɗaɗe wani nishati da za'a ƙãra wa wannan aikin, tuna makini a kan lugha sarki (Ingiriya) da kuma ƙasan-resource (Bangla). Ga Ingiriya, za'a sami halin-fassaran-sanar, kuma a lokacin Bangla, shi ne na farkon wanda aka yi furuci da shi, mai iya amfani da matsayi mai ƙarfi ga aikin nan gaba. Mun sami tsarin bayani na Bangla da ake samun mutane.", 'sk': 'Obnovitev točk je pogosta težava po obdelavi za sisteme samodejnega prepoznavanja govora (ASR). Pomembno je izboljšati berljivost prepisanega besedila za človeškega bralca in olajšati naloge NLP. Trenutno najsodobnejše reševanje tega problema z različnimi modeli globokega učenja. V zadnjem času so transformatorski modeli dokazali svoj uspeh pri opravilih nadaljnjega dela NLP, ti modeli pa so bili zelo malo raziskani za problem obnove ločil. V tem delu raziskujemo različne transformatorske modele in predlagamo strategijo povečanja za to nalogo, s poudarkom na jezikih z visokimi viri (angleščina) in nizkimi viri (Bangla). Za angleščino dobimo primerljive najsodobnejše rezultate, medtem ko je to za Banglo prvo poročano delo, ki lahko služi kot močna osnova za prihodnje delo. Naš razvit nabor podatkov Bangla smo javno dostopni raziskovalni skupnosti.', 'bo': 'སྒྲིག་འཇུག་གི་ཆ་ཚན་བསྐྱར་གསོ་ནི་རང་འགུལ་གྱི་སྐད་ཆ་རྟོགས ཡིག་བཀོད་ཡོད་པའི་ཡིག་གེ་ཀློག་འཇུག་པ་ལ་ཡོད་པའི་ལྟ་ཀློག་འཇུག་བྱེད་སྟངས་ལ་རྒྱས་སྐྱོར་ཡོད་པ་དང་NLP ལས་ཀ ད་ལྟོའི་གནས་སྟངས་གནས་སྟངས་ལས་དབྱིབས་སྦྱོར་དབྱིབས་འདི་བེད་སྤྱོད་བཞིན་པའི་བྱ་བ་ཅིག དབྱིབས་བཟོ་བ་མཁན་གྱི་མ་དབུགས་དེ་ནི་ཁོང་ཚོའི་གྲུབ་འབྲས་ཀྱི་NLP ལས་ཀ་ཡོད་པ་ལྟར་བརྟན་དཔེ་བརྗོད་བྱས། མིག་སྔར་སྒྲིག་འདི་དག་ཆ འོན་ཀྱང་། ང་ཚོས་ལས་ཀ་འདི་ནང་དུ་བཟོ་བཅོས་པ་མི་འདྲ་བ་དང་། ལས་ཀ་འདི་ལ་རྒྱས་སྤྲོད་ཀྱི་ཐབས་ལམ་ཞིག་འཆར་བྱེད་ཀྱི་ཡོད། དབྱིན་ཡིག་ལ་དང་། ང་ཚོས་ཀྱིས་ལྷན་ལ་ཡོད་པའི་བརྗོད་སྡུད་ཆ་རྣམས་མེད་པར་སྤྱིར་བཏང་བ་རེད།', 'he': 'שיחזור נקודות הוא בעיה משותפת לאחר העבודה של מערכות זיהוי אוטומטי של דיבור (ASR). It is important to improve the readability of the transcribed text for the human reader and facilitate NLP tasks.  המצב האמנתי הנוכחי מתייחס לבעיה הזאת באמצעות דוגמנים של למידה עמוקה שונים. Recently, transformer models have proven their success in downstream NLP tasks, and these models have been explored very little for the punctuation restoration problem.  בעבודה הזו, אנו חוקרים מודלים שונים מבוססים במעבר ומציעים אסטרטגיה גיבוי למשימה הזאת, מתמקדת בשפות משאבים גבוהים (אנגלית) ובאנגלית נמוכות (באנגלה). לאנגלית, אנו מקבלים תוצאות מצב-האמנות משוואות, בעוד לבנגלה, זו העבודה הראשונה שנדווחה, אשר יכולה לשמש כבסיס חזק עבור העבודה העתידית. הפכנו את קבוצת נתונים הבנגלה המפותחת שלנו לפומבי לקהילת המחקר.'}
{'en': 'Fine-Tuning MT systems for Robustness to Second-Language Speaker Variations MT  systems for Robustness to Second-Language Speaker Variations', 'ar': 'الضبط الدقيق لأنظمة الترجمة الآلية من أجل المتانة لتغيرات مكبرات الصوت بلغة ثانية', 'es': 'Ajuste fino de los sistemas MT para mayor solidez a las variaciones de hablantes de un segundo idioma', 'fr': 'Systèmes de magnétoscopie pour une meilleure robustesse face aux variations des locuteurs de langue seconde', 'pt': 'Ajuste fino de sistemas MT para variações de robustez para alto-falantes de segunda língua', 'ja': '第二言語スピーカーバリエーションへの堅牢性のための微調整MTシステム', 'zh': '微调机器翻译统,保第二语言言者变体之鲁棒性', 'hi': 'दूसरी भाषा वक्ता विविधताओं के लिए मजबूती के लिए ठीक ट्यूनिंग एमटी सिस्टम', 'ru': 'Точная настройка систем MT для робастности для вариаций динамиков на втором языке', 'ga': "Mionchoigeartú a dhéanamh ar chórais MT le haghaidh Láidreachta d'Athruithe Cainteoirí Dara Teanga", 'ka': 'მუშაობელი MT სისტემების შესაძლებლობა მეორე ენის სიტყვების გარიაციებისთვის', 'el': 'Βελτιστοποίηση συστημάτων ΜΤ για ανθεκτικότητα στις παραλλαγές ομιλητών δεύτερης γλώσσας', 'hu': 'Finomhangoló MT rendszerek a robusztus másodnyelvű hangszóró variációkhoz', 'it': 'Sistemi MT di messa a punto per robustezza alle varianti di altoparlanti in seconda lingua', 'mk': 'Фино- тунирање на MT системите за robustness на варијациите на вториот говорник', 'kk': 'Екінші тіл сөйлейтінші айнымалылығына қарапайым MT жүйелері', 'lt': 'Fine-Tuning MT systems for Robustness to Second-Language Speaker Variations', 'ms': 'Fine-Tuning MT systems for Robustness to Second-Language Speaker Variations', 'mt': 'Fine-Tuning MT systems for Robustness to Second-Language Speaker Variations', 'ml': 'രണ്ടാമത്തെ ഭാഷ സംസാരിക്കുന്ന മാറ്റങ്ങള്\u200d', 'pl': 'Dostosowanie systemów MT dla wytrzymałości do zmian głośników drugiego języka', 'sr': 'Dobri podešavanje MT sistema za robustnost prema varijacijama govornika drugog jezika', 'mn': 'Хоёрдугаар хэл ярианы өөрчлөлттэй сайн тооны MT системүүд', 'no': 'Fine-tuning MT-systemer for robusthet til andre språk-talevariasjonar', 'ro': 'Sisteme MT de reglare fină pentru robusteţe la variaţiile difuzoarelor de limbă a doua', 'si': 'දෙවෙනි භාෂාව ප්\u200dරශ්නයක් වෙනස් වෙනුවෙන් හොඳ සැකසුම් MT පද්ධතිය', 'ta': 'சுழற்சியுள்ள மொழி பேசுபவர் மாறிகளுக்கான MT அமைப்புகள்', 'sv': 'Finjusterande MT-system för robusthet till andraspråkiga högtalarvarianter', 'so': 'Isticmaalka ku hadlaha luqada labaad', 'ur': 'دوسری زبان صحبت کرنے والی ویریشن کے لئے اچھی ٹونگ MT سیستم', 'uz': 'Name', 'vi': 'Hệ thống giao thông đường băng ổn định sự thay đổi ngôn ngữ thứ hai', 'nl': 'Fine-tuning MT-systemen voor robuustheid tot tweetalige speaker variaties', 'bg': 'Системи за фино настройване за здравина към варианти на говорителя на втори език', 'da': 'Finjusterende MT-systemer til robusthed til andetsprogede højttalervariationer', 'hr': 'Dobra prilagodba MT sustava za robustnost prema varijacijama govornika drugog jezika', 'id': 'Sistem MT Penyesuaian Baik untuk Kekuatan ke Variasi Bicara Bahasa Kedua', 'de': 'Feinabstimmung von MÜ-Systemen für Robustheit bis zu Zweitsprachen', 'tr': 'Ikinji dil sözleýän çykyşyma üçin iň gowy görkezilýän MT sistemleri', 'ko': '마이크로 기계 번역 시스템, 제2 언어 말하는 사람의 변화에 대한 노봉성 강화', 'af': 'Fine-Tuning MT stelsels vir robustheid na tweede-taal spreker veranderinge', 'sw': 'Mfumo mzuri wa MT kwa ajili ya Mazungumzo ya lugha ya pili', 'sq': 'Përcaktimi i mirë i sistemeve MT për forcën ndaj variacioneve të zëdhënësve të gjuhës së dytë', 'am': 'ምርጫዎች', 'fa': 'سیستم\u200cهای MT نیک تنظیم برای تنظیم به تغییرات سخنرانی زبان دوم', 'hy': 'ՄԹ համակարգերը բարձրացնում են երկրորդ լեզվի խոսնակի տարբերակների վրա', 'bn': 'Name', 'cs': 'Jemné ladění MT systémů pro odolnost až po druhý jazyk', 'az': 'ńįkinci dil danńĪŇüńĪcńĪ d…ôyiŇüiklikl…ôrin…ô istifad…ô ed…ôn MT sisteml…ôri', 'bs': 'Dobra sredstva MT-a za robustnost prema varijacijama govornika drugog jezika', 'fi': 'Hienosäätöjärjestelmät kestäväksi toisen kielen kaiuttimien vaihteluille', 'et': 'Peenhäälestussüsteemid vastupidavuseks teise keele kõlarite variatsioonidele', 'ca': "Sistemes MT d'ajustes fins per a la robustetat a les variacions del parlant de segona llengua", 'ha': '@ action', 'he': 'מערכות MT מתאימות מיוחדות עבור החזקה לשונות מדברים בשפה השנייה', 'jv': 'Fine-Tuning MT sistem kanggo Réobust kanggo Lingué Speaker Variations', 'sk': 'Sistemi finega nastavljanja MT za robustnost na različice drugega jezika zvočnikov', 'bo': 'སྐད་ཡིག་གཏམ་པ་གཉིས་པ་ལ་དུས་མཐོ་བརྗོད་ཀྱི་མ་ལག་ཆ་བཟོ་བཅོས་པ།'}
{'en': 'The performance of neural machine translation (NMT) systems only trained on a single language variant degrades when confronted with even slightly different language variations. With this work, we build upon previous work to explore how to mitigate this issue. We show that  fine-tuning  using naturally occurring noise along with pseudo-references (i.e. corrected non-native inputs translated using the baseline NMT system) is a promising solution towards systems robust to such type of input variations. We focus on four translation pairs, from  English  to  Spanish ,  Italian ,  French , and  Portuguese , with our system achieving improvements of up to 3.1 BLEU points compared to the baselines, establishing a new state-of-the-art on the JFLEG-ES dataset. All datasets and code are publicly available here : https://github.com/mahfuzibnalam/finetuning_for_robustness.', 'ar': 'يتدهور أداء أنظمة الترجمة الآلية العصبية (NMT) المدربة فقط على متغير لغة واحدة عند مواجهة اختلافات لغوية مختلفة قليلاً. من خلال هذا العمل ، نبني على العمل السابق لاستكشاف كيفية التخفيف من هذه المشكلة. نوضح أن الضبط الدقيق باستخدام الضوضاء التي تحدث بشكل طبيعي جنبًا إلى جنب مع المراجع الزائفة (أي المدخلات غير الأصلية "المصححة" المترجمة باستخدام نظام NMT الأساسي) هي حل واعد تجاه أنظمة قوية لمثل هذا النوع من تنوعات الإدخال. نحن نركز على أربعة أزواج من الترجمة ، من الإنجليزية إلى الإسبانية والإيطالية والفرنسية والبرتغالية ، حيث حقق نظامنا تحسينات تصل إلى 3.1 نقطة BLEU مقارنة بخطوط الأساس ، مما أدى إلى إنشاء أحدث ما توصلت إليه التكنولوجيا في JFLEG-ES مجموعة البيانات. جميع مجموعات البيانات والرموز متاحة للجمهور هنا: https://github.com/mahfuzibnalam/finetuning_for_robustness.', 'pt': 'O desempenho dos sistemas de tradução automática neural (NMT) treinados apenas em uma única variante de idioma degrada quando confrontados com variações de idioma ainda que ligeiramente diferentes. Com este trabalho, aproveitamos o trabalho anterior para explorar como mitigar esse problema. Mostramos que o ajuste fino usando ruído natural junto com pseudo-referências (ou seja, entradas não nativas “corrigidas” traduzidas usando o sistema NMT de linha de base) é uma solução promissora para sistemas robustos a esse tipo de variação de entrada. Focamos em quatro pares de tradução, de inglês para espanhol, italiano, francês e português, com nosso sistema alcançando melhorias de até 3,1 pontos BLEU em relação às linhas de base, estabelecendo um novo estado da arte no JFLEG-ES conjunto de dados. Todos os conjuntos de dados e códigos estão disponíveis publicamente aqui: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'fr': "Les performances des systèmes de traduction automatique neuronale (NMT) formés uniquement sur une seule variante de langue se dégradent lorsqu'ils sont confrontés à des variations linguistiques même légèrement différentes. Avec ce travail, nous nous appuyons sur des travaux antérieurs pour explorer comment atténuer ce problème. Nous montrons que le réglage fin utilisant le bruit naturel associé à des pseudo-références (c'est-à-dire des entrées non natives «\xa0corrigées\xa0» traduites à l'aide du système NMT de base) est une solution prometteuse pour les systèmes robustes à ce type de variations d'entrée. Nous nous concentrons sur quatre paires de traduction, de l'anglais vers l'espagnol, l'italien, le français et le portugais, notre système obtenant des améliorations allant jusqu'à 3,1 points BLEU par rapport aux lignes de base, établissant ainsi une nouvelle technologie de pointe sur le jeu de données JFLEG-ES. Tous les ensembles de données et le code sont accessibles au public ici\xa0: https://github.com/mahfuzibnalam/finetuning_for_robustness.", 'es': 'El rendimiento de los sistemas de traducción automática neuronal (NMT) solo entrenados en una variante lingüística se degrada cuando se enfrentan a variaciones lingüísticas ligeramente diferentes. Con este trabajo, nos basamos en trabajos anteriores para explorar cómo mitigar este problema. Demostramos que el ajuste fino mediante el uso de ruido natural junto con pseudoreferencias (es decir, entradas no nativas «corregidas» traducidas mediante el sistema NMT de referencia) es una solución prometedora para sistemas robustos para este tipo de variaciones de entrada. Nos centramos en cuatro pares de traducción, del inglés al español, italiano, francés y portugués, y nuestro sistema logra mejoras de hasta 3,1 puntos BLEU en comparación con las líneas de base, lo que establece un nuevo estado de vanguardia en el conjunto de datos JFLEG-ES. Todos los conjuntos de datos y códigos están disponibles públicamente aquí: https://github.com/mahfuzibnalam/finetuning_for_robustness.', 'ja': '単一の言語バリアントでのみトレーニングされたニューラル機械翻訳（ NMT ）システムのパフォーマンスは、わずかに異なる言語バリエーションに直面すると劣化する。この作業では、この問題を軽減する方法を探るために以前の作業を基にしています。我々は、擬似参照（すなわち、ベースラインＮＭＴシステムを使用して翻訳された「修正された」非ネイティブ入力）と共に自然に発生するノイズを使用して微調整することが、そのようなタイプの入力変動に堅牢なシステムに対する有望な解決策であることを示す。英語からスペイン語、イタリア語、フランス語、ポルトガル語の4つの翻訳ペアに焦点を当て、当社のシステムはベースラインと比較して最大3.1 BLEUポイントの改善を達成し、JFLEG - ESデータセットの新しい最先端を確立します。すべてのデータセットとコードは、https://github.com/mahfuzibnalam/finetuning_for_robustnessで公開されています。', 'hi': 'न्यूरल मशीन अनुवाद (एनएमटी) प्रणालियों का प्रदर्शन केवल एक ही भाषा संस्करण पर प्रशिक्षित होता है जब थोड़ा अलग भाषा विविधताओं का सामना करना पड़ता है। इस काम के साथ, हम इस मुद्दे को कम करने के तरीके का पता लगाने के लिए पिछले काम पर निर्माण करते हैं। हम दिखाते हैं कि छद्म संदर्भों के साथ स्वाभाविक रूप से होने वाले शोर का उपयोग करके ठीक-ट्यूनिंग (यानी बेसलाइन एनएमटी सिस्टम का उपयोग करके अनुवादित "सही" गैर-देशी इनपुट) इस प्रकार के इनपुट विविधताओं के लिए मजबूत सिस्टम की ओर एक आशाजनक समाधान है। हम अंग्रेजी से स्पेनिश, इतालवी, फ्रेंच और पुर्तगाली तक चार अनुवाद जोड़े पर ध्यान केंद्रित करते हैं, हमारी प्रणाली बेसलाइन की तुलना में 3.1 BLEU बिंदुओं तक के सुधार को प्राप्त करती है, जेएफएलईजी-ईएस डेटासेट पर एक नया अत्याधुनिक स्थापित करती है। सभी डेटासेट और कोड यहां सार्वजनिक रूप से उपलब्ध हैं: https://github.com/mahfuzibnalam/finetuning_for_robustness।', 'ru': 'Производительность систем нейронного машинного перевода (НМП), обученных только одному языковому варианту, ухудшается при столкновении с даже слегка отличающимися языковыми вариациями. С помощью этой работы мы опираемся на предыдущую работу по изучению того, как смягчить этот вопрос. Показано, что точная настройка с использованием естественного шума наряду с псевдоссылками (т. е. «исправленными» нестандартными входами, преобразованными с использованием базовой системы NMT) является перспективным решением для систем, устойчивых к такому типу колебаний входа. Мы фокусируемся на четырех парах переводов, от английского до испанского, итальянского, французского и португальского языков, при этом наша система достигает улучшений до 3,1 пунктов BLEU по сравнению с базовыми линиями, создавая новый современный набор данных JFLEG-ES. Все наборы данных и код доступны в открытом доступе здесь: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'zh': '唯针一言变体训练者神经机器翻译 (NMT) 性能小异变体时降。 因此,我们在以前的事基上探索怎么解释这件事。 臣等明用自然噪声及伪参考(虽用基线NMT系统转换之校正,非本机输)微调是有前途之解决方案,宜于此输变鲁棒之统。 注于四译,自英语至西班牙语,意大利语,法语与葡萄牙语,比于基线,统致高达3.1 BLEU点之改,立新术于JFLEG-ES数集上。 凡数集及代码皆于此公给: https://github.com/mahfuzibnalam/finetuning_for_robustness 。', 'ga': 'Ní dhíghrádaítear feidhmíocht na gcóras néar-aistriúcháin meaisín (NMT) ach amháin ar mhalairt teanga amháin nuair a chuirtear i ngleic le héagsúlachtaí teanga atá beagán difriúil. Leis an obair seo, cuirimid leis an obair a rinneadh roimhe seo chun féachaint conas an cheist seo a mhaolú. Léirímid gur réiteach gealtach é mionchoigeartú trí úsáid a bhaint as torann a tharlaíonn go nádúrtha mar aon le bréige-tagairtí (i.e. ionchuir neamhdhúchasacha “ceartaithe” a aistrítear ag baint úsáide as an gcóras NMT bonnlíne) i dtreo córais atá láidir d’éagsúlachtaí ionchuir dá leithéid. Dírímid ar cheithre phéire aistriúcháin, ón mBéarla go dtí an Spáinnis, an Iodáilis, an Fhraincis agus an Phortaingéilis, agus tá feabhsuithe suas le 3.1 pointe BLEU á bhaint amach ag ár gcóras i gcomparáid leis na bunlínte, ag bunú staid nua-aimseartha ar an JFLEG-ES. tacar sonraí. Tá gach tacar sonraí agus cód ar fáil go poiblí anseo: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'ka': "ნეიროლური მანქანის გარგულისხმების (NMT) სისტემების გამოყენება მხოლოდ ერთი ენის გარიანტების გარგულისხმებით განსხვავებულია, როდესაც კონფორტირებულია კონტ ამ სამუშაო, ჩვენ წინა სამუშაო დავიწყეთ, როგორ ამ პრობლემას გახსნა. ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ ბეჭდვილურად გამოიყენება სიტყვას პესედო- რეფერენციებით (მაგალითად. 'რექტირებული' არ არის ნაირთი ინფორმაციები, რომლებიც გამოყენებულია baseline NMT სისტემის გამოყენება ჩვენ ჩვენი სისტემა 3.1 BLEU წერტილების შესაძლებლობად გავაკეთებთ ფესონური, თრალიური, ფრანგური და პორტეგური წერტილების 4 წერტილების შესაძლებლობად, ინგლისური, თრალიური და პორტეგური წერტილების შესაძლებლობაზე, რომელსაც სა ყველა მონაცემები და კოდი აქ ადგილურად ხელსაწყებელია: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'el': 'Η απόδοση των συστημάτων νευρωνικής μηχανικής μετάφρασης (NMT) που εκπαιδεύονται μόνο σε μια μόνο γλωσσική παραλλαγή υποβαθμίζεται όταν αντιμετωπίζεται ακόμη και ελαφρώς διαφορετικές γλωσσικές παραλλαγές. Με αυτό το έργο, βασιζόμαστε σε προηγούμενες εργασίες για να διερευνήσουμε πώς να μετριάσουμε αυτό το ζήτημα. Δείχνουμε ότι ο συντονισμός με τη χρήση φυσικού θορύβου σε συνδυασμό με ψευδο-αναφορές (δηλ. "διορθωμένων" μη εγγενών εισόδων μεταφρασμένων χρησιμοποιώντας το βασικό σύστημα NMT) είναι μια ελπιδοφόρα λύση για συστήματα ανθεκτικά σε τέτοιου είδους παραλλαγές εισόδου. Εστιάζουμε σε τέσσερα μεταφραστικά ζεύγη, από τα αγγλικά στα ισπανικά, τα ιταλικά, τα γαλλικά και τα πορτογαλικά, με το σύστημά μας να επιτυγχάνει βελτιώσεις μέχρι 3.1 σημείων σε σύγκριση με τις γραμμές βάσης, δημιουργώντας μια νέα υπερσύγχρονη βάση δεδομένων στο σύνολο δεδομένων. Όλα τα σύνολα δεδομένων και ο κώδικας είναι δημόσια διαθέσιμα εδώ: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'hu': 'A neurális gépi fordító (NMT) rendszerek teljesítménye csak egyetlen nyelvváltozaton képzett teljesítménye romlik, ha még kissé eltérő nyelvváltozatokkal is szembesülnek. Ezzel a munkával a korábbi munkákra építünk, hogy feltárjuk, hogyan lehet enyhíteni ezt a problémát. Megmutatjuk, hogy a természetes zaj használatával történő finomhangolás pszeudo referenciákkal (azaz a kiindulási NMT rendszer használatával lefordított "korrigált" nem natív bemenetek) ígéretes megoldást jelent az ilyen típusú bemeneti variációkhoz szükséges rendszerek számára. Négy fordítási párra összpontosítunk, angolról spanyolra, olaszra, franciára és portugálra, rendszerünk az alapvonalakhoz képest akár 3,1 BLEU pontot is elér, és új korszerű fejlesztést hoz létre a JFLEG-ES adatkészleten. Minden adatkészlet és kód nyilvánosan elérhető itt: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'it': 'Le prestazioni dei sistemi neurali di traduzione automatica (NMT) addestrati solo su una singola variante linguistica degradano se confrontati con variazioni linguistiche anche leggermente diverse. Con questo lavoro, si basa sul lavoro precedente per esplorare come mitigare questo problema. Mostriamo che la messa a punto utilizzando rumore naturale insieme a pseudo-riferimenti (cioè input non nativi "corretti" tradotti utilizzando il sistema NMT di base) è una soluzione promettente per sistemi robusti a questo tipo di variazioni di input. Ci concentriamo su quattro coppie di traduzioni, dall\'inglese allo spagnolo, dall\'italiano, dal francese e dal portoghese, con il nostro sistema che raggiunge miglioramenti fino a 3,1 punti BLEU rispetto alle linee di base, stabilendo un nuovo stato dell\'arte sul set di dati JFLEG-ES. Tutti i set di dati e i codici sono disponibili pubblicamente qui: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'kk': "Невралдық компьютерді аудару (NMT) жүйелерінің әрекеті тек бір тіл айнымалысына қарсы кезде бірнеше тіл айнымалысына қарсы деградайды. Бұл жұмыс менен, бұл мәселеді қалай қысқарту үшін алдыңғы жұмыс істеу үшін құрамыз. Біз псевдо- сілтемелерімен бірге табиғатты дыбысты қолдану (яғни 'түзетілген' негізгі NMT жүйесіне аударылмаған 'түзетілген' кірістер) дегенді көрсетедік. Бұл келтірілген түрлі аударылған жүйелердің қасиетті шешімі. Біз ағылшынша, итальян, французша және Португализша төрт аудармалы екеуге көздейміз. Жүйеміздің 3,1 BLEU нүктелерін негізгі жолдармен салыстырып, JFLEG-ES деректер жиынында жаңа жалғыз күйін орнату үшін. Бүкіл деректер қорлары мен код жалпы мұнда бар: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'lt': 'Nervų vertimo mašinomis sistemų (NMT) veikimas, mokomas tik vienos kalbos variantu, blogėja, kai susiduriama su net šiek tiek skirtingais kalbos variantais. Šiuo darbu mes remiamės ankstesniu darbu, kad išnagrinėtume, kaip švelninti šį klausimą. Mes parodome, kad patobulinimas naudojant natūralų triukšmą kartu su pseudonuorodomis (t. y. „pataisytos“ ne vietinės įrangos, i šverstos naudojant pradinę NMT sistemą), yra perspektyvus sprendimas tokioms įrangos variacijoms patikimoms sistemoms. Daugiau dėmesio skiriame keturioms vertimo poroms: anglų, ispanų, italų, prancūzų ir portugalų kalbomis, o mūsų sistema pagerina iki 3,1 BLEU taško, palyginti su bazinėmis linijomis, sukuria naują pažangiausią JFLEG-ES duomenų rinkinį. Visi duomenų rinkiniai ir kodai yra vieši čia: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'mk': 'The performance of neural machine translation (NMT) systems only trained on a single language variant degrades when confronted with even slightly different language variations.  Со оваа работа, ние градиме на претходната работа за да истражуваме како да го олесниме ова прашање. Ние покажуваме дека финетизирањето со користење на природна бучава заедно со псевдо-референции (т.е. „коригирани“ неродни внесувања преведени со користење на основниот НМТ систем) е ветувачко решение кон системите robust за вакви видови на внесувачки варијации. Ние се фокусираме на четири парови превод, од англиски до шпански, италијански, француски и португалски, со нашиот систем постигнувајќи подобрувања од до 3,1 БЛЕУ поени во споредба со основните линии, воспоставувајќи нова најнова технологија на податоците JFLEG-ES. Сите податоци и кодови се јавно достапни тука: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'ms': "Performasi sistem terjemahan mesin saraf (NMT) hanya dilatih pada varian bahasa tunggal merendahkan apabila dihadapkan dengan variasi bahasa yang sedikit berbeza. Dengan kerja ini, kami membina pada kerja sebelumnya untuk mengeksplorasi bagaimana untuk mengurangi masalah ini. We show that fine-tuning using naturally occurring noise along with pseudo-references (i.e. 'corrected' non-native inputs translated using the baseline NMT system) is a promising solution towards systems robust to such type of input variations.  Kami fokus pada empat pasangan terjemahan, dari bahasa Inggeris ke Sepanyol, Itali, Perancis, dan Portugis, dengan sistem kami mencapai peningkatan sehingga 3.1 titik BLEU dibandingkan dengan garis dasar, menetapkan kemajuan baru pada set data JFLEG-ES. All datasets and code are publicly available here:  https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'mt': 'Il-prestazzjoni tas-sistemi tat-traduzzjoni bil-magna newrali (NMT) imħarrġa biss fuq varjant lingwistiku wieħed tiddegrada meta kkonfrontata ma’ varjazzjonijiet lingwistiċi saħansitra ftit differenti. B’din il-ħidma, aħna nibnu fuq ħidma preċedenti biex nesploraw kif nimmitigaw din il-kwistjoni. Aħna nuru li l-a ġġustament fin bl-użu ta’ storbju li jseħħ b’mod naturali flimkien ma’ psewdoreferenzi (jiġifieri inputs mhux nattivi “korretti” tradotti bl-użu tas-sistema NMT tal-linja bażi) huwa soluzzjoni promettenti lejn sistemi b’saħħithom għal tali tip ta’ varjazzjonijiet ta’ input. Aħna niffokaw fuq erba’ pari ta’ traduzzjoni, mill-Ingliż għall-Ispanjol, it-Taljan, il-Franċiż u l-Portugiż, bis-sistema tagħna tikseb titjib sa 3.1 punti BLEU meta mqabbla mal-linji bażi, u tistabbilixxi a ġġornament ġdid fid-dataset JFLEG-ES. Is-settijiet tad-dejta u l-kodiċi kollha huma disponibbli pubblikament hawnhekk: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'ml': "ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷകളുടെ (NMT) സിസ്റ്റത്തിന്റെ പ്രവര്\u200dത്തനം ഒരു ഭാഷ വേരിനെന്റ് ഡിഗ്രേഡികളില്\u200d മാത്രമേ പരിശീലനം ചെയ്യുകയ ഈ ജോലി കൊണ്ട്, നമ്മള്\u200d മുമ്പ് ജോലിയില്\u200d പണിയുന്നു, ഈ പ്രശ്നം എങ്ങനെയാണ് മുളക്കുന്നതെന്ന് പരിശ സ്വാഭാവികമായി സംഭവിക്കുന്ന ശബ്ദം ഉപയോഗിക്കുന്നത് നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നു. പെസുഡോ- രേഖകളോടൊപ്പം (ഉദാഹരണത്തിനായി 'ശരിയാക്കിയിട്ടില്ലാത്ത നാട ഇംഗ്ലീഷില്\u200d നിന്നും ഇംഗ്ലീഷിലേക്കും ഇറ്റാലിയന്\u200d, ഫ്രെഞ്ച്, പോര്\u200dട്ടുഗീഷിലേക്കും നാല് പരിഭാഷപ്രഭാഷണജോടികളെ നാം ശ്രദ്ധിക്കുന്നു. നമ്മുടെ സിസ്റ്റത്തില്\u200d നിന്നും  എല്ലാ ഡാറ്റാസറ്റുകളും കോഡുകളും ഇവിടെ പ്രസിദ്ധമായി ലഭ്യമല്ല: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'mn': 'НМТ-ийн мэдрэлийн машины хөгжлийн үйл ажиллагаа зөвхөн нэг хэл хувьд бага зэрэг өөр хэл өөрчлөлтийг харах үед бага зэрэг багасгадаг. Энэ ажлын хувьд бид өмнөх ажлын хувьд энэ асуудлыг хэрхэн багасгах талаар судалж байна. Бид өөрсдийгөө өөрчлөгдөж байгаа байгалийн дуугарал ашиглаж буй үндсэн дуугарал (т.е. "зөв" бус орон нутгийг NMT системээр орлуулсан) гэдгийг харуулж байна. Бид Англи, Итали, Француз, Португали хүртэл 4 орчуулагч хоёр дээр анхаарлаа төвлөрүүлсэн. Бидний систем 3.1 БЛЕС цэгүүдийг суурь шугам дээр харьцуулж, JFLEG-ES өгөгдлийн санд шинэ урлагийн хувьд байгуулсан. Бүх өгөгдлийн сангууд, код энд олон нийтэд хангалттай байна: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'ro': 'Performanța sistemelor neuronale de traducere automată (NMT) instruite doar pe o singură variantă de limbă se degradează atunci când se confruntă cu variații chiar și ușor diferite de limbă. Cu această activitate, ne bazăm pe lucrările anterioare pentru a explora modul de atenuare a acestei probleme. Arătăm că reglarea fină folosind zgomotul natural împreună cu pseudo-referințe (adică intrările non-native "corectate" traduse folosind sistemul NMT de bază) reprezintă o soluție promițătoare pentru sistemele robuste la astfel de tipuri de variații de intrare. Ne concentrăm pe patru perechi de traduceri, de la engleză la spaniolă, italiană, franceză și portugheză, sistemul nostru obținând îmbunătățiri de până la 3,1 puncte BLEU comparativ cu liniile de bază, stabilind un nou set de date JFLEG-ES de ultimă generație. Toate seturile de date și codurile sunt disponibile public aici: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'pl': 'Wydajność systemów neuronowego tłumaczenia maszynowego (NMT) przeszkolonych tylko na jednym wariancie językowym ulega degradacji w obliczu nawet nieznacznie różnych wariantów językowych. W ramach tej pracy opieramy się na poprzednich pracach, aby zbadać, jak złagodzić ten problem. Pokazujemy, że precyzyjne dostrajanie przy użyciu naturalnie występujących szumów wraz z pseudodniesieniami (tzn. "skorygowanych" nienatywnych wejść tłumaczonych przy użyciu bazowego systemu NMT) jest obiecującym rozwiązaniem dla systemów solidnych na tego typu wariancje wejściowe. Koncentrujemy się na czterech parach tłumaczeń, z angielskiego na hiszpański, włoski, francuski i portugalski, dzięki czemu nasz system osiąga ulepszenia do 3.1 punktów BLEU w porównaniu z liniami bazowymi, tworząc nowy state-of-the-art zbioru danych JFLEG-ES. Wszystkie zbiory danych i kod są publicznie dostępne tutaj: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'no': 'Utviklinga av neuralmaskinsomsetjingssystemet (NMT) er berre trengd på ein enkelt språk- variant degraderer når det oppstod med enda litt forskjellige språk- variasjonar. Med denne arbeiden bygger vi på førre arbeid for å utforske korleis å minne dette problemet. Vi viser at fine-tuning med naturleg oppståande støy saman med pseudo-referanser (t.d. « korrigerte » ikkje-lokale inndata omsett med baseline NMT- systemet) er eit velkommande løysing mot systemar som er robust til slike typar inndatavariasjonar. Vi fokuserer på fire oversettelspar, frå engelsk til spansk, italiensk, fransk og portugisisk, med systemet vårt som fører til forbedringar til 3,1 BLEU-punkt sammenlignet med baselinjene, og oppretter ein ny kunsttilstand på datasettet JFLEG-ES. Alle datasett og kode er offentlig tilgjengeleg her: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'so': "Isticmaalka tarjumaadda maskaxda neurada (NMT) waxaa lagu bartay shahaado kala duwan oo af kaliya marka lagu hor jeedo xittaa kala duwan luuqado kala duduwan. Shaqodaas, waxaynu ku dhisaynaa shaqada hore si aan u baarayno sida ay arrintan u qabsato. Waxaynu tusnaynaa in codka dabiicadda ah oo lagu isticmaalayo codka dabiicadda ah (tusaale ahaan `hagaajiyey' input-horaadka aan hooyo ahayn oo lagu turjumay isticmaalka nidaamka NMT-da hoose) waa xal ballan ah oo u jeeda nidaamka noocyada ka duwan e e input-ka. Waxaynu ku kalsoonaynaa afar nooc oo turjumista ah, tan Ingiriis ilaa Isbanish, Talyaani, Faraansiis iyo Burtuqiis, nidaamka aan dhameynno hagaajinta ilaa 3.1 BLEU goobaha hoose barbardhigga, waxaan sameynaynaa xaalad-sanad oo cusub oo ku qoran JFLEG-ES dataset. Dhammaan sawirada iyo codsiga waxaad ka heleysaa halkan: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'sv': 'Prestandan hos neurala maskin철vers채ttningssystem (NMT) som endast tr채nas p책 en enda spr책kvariant f철rs채mras n채r de konfronteras med 채ven lite olika spr책kvariationer. Med detta arbete bygger vi vidare p책 tidigare arbete f철r att unders철ka hur man kan mildra denna fr책ga. Vi visar att finjustering med naturligt f철rekommande brus tillsammans med pseudoreferenser (dvs. "korrigerade" icke-nativa ing책ngar 철versatta med baseline NMT-systemet) 채r en lovande l철sning mot system som 채r robusta f철r s책dana typer av ing책ngsvariationer. Vi fokuserar p책 fyra 철vers채ttningspar, fr책n engelska till spanska, italienska, franska och portugisiska, d채r v책rt system uppn책r f철rb채ttringar p책 upp till 3,1 BLEU-po채ng j채mf철rt med baslinjerna, vilket skapar ett nytt toppmodernt dataset f철r JFLEG-ES. Alla dataupps채ttningar och koder 채r tillg채ngliga f철r allm채nheten h채r: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'sr': 'Izvrsnost neuronskog prevoda (NMT) sustava obučenih samo na jednom jezičkom varijantu degradera kada se suočavaju sa čak i malo različitim jezičkim varijancijama. Sa ovim poslom, izgradimo na prethodnom poslu da istražimo kako da smanjimo ovaj problem. Pokazujemo da je dobra prilagodba koristeći prirodno dešavajuću buku zajedno sa pseudo-referencijama (tj. „ispravljeni“ ne-lokalni ulazi prevedeni korištenjem početnog NMT sistema) obećavajuće rješenje prema sistemima jačim za takve vrste varijacija ulaza. Fokusiramo se na četiri parova prevođenja, od engleskog na španjolsku, italijansku, francusku i portugalsku, s našim sistemom koji postiže poboljšanja do 3,1 BLEU bodova u usporedbi sa osnovnim linijama, uspostavljajući novi stanje umjetnosti na setu podataka JFLEG-ES. Svi podaci i kodovi su javno dostupni ovde: https://github.com/mahfuzibnalam/finetuning_for_robustness -Da.', 'si': 'න්\u200dයුරෝල් මැෂින් වාර්ථාව (NMT) පද්ධතියේ ප්\u200dරශ්නයක් විතරයි භාෂාවක් වෙනස් වෙනස් වෙනස් භාෂාවක් සමඟ ව මේ වැඩේ එක්ක, අපි කලින් වැඩේ හොයාගන්නේ මේ ප්\u200dරශ්නයක් කොහොමද ප්\u200dරශ්නය කරන්නේ කියලා. අපි පෙන්වන්නේ ස්වභාවිකයෙන් සිද්ධ විශ්වාසයෙන් සිද්ධ විශ්වාසය සමග සිද්ධ විශ්වාසය සමග සිද්ධ විශ්වාසය සඳහා සිද්ධ විශ්වාසයෙන් ප අපි ඉංග්\u200dරීසියෙන් ස්පැනිස්, ඉතාලියාන්, ෆ්\u200dරැන්සියාන්, පොර්ටුජියාන් වලට අවධානය කරනවා අපේ පද්ධතිය 3.1 බ්ලූස් ප්\u200dරමාණය 3.1 බ්ලූස් ප්\u200dරමාණ සියළුම දත්ත සැට් සහ කෝඩ් මෙතන ප්\u200dරතිකාරයෙන් ලැබෙනවා: NAME OF TRANSLATORS https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'ta': "Name இந்த வேலையைக் கொண்டு, நாம் முந்தைய வேலையில் கட்டுகிறோம் இந்த பிரச்சனையை எவ்வாறு அளக்கும்  நாம் காட்டுகிறோம் என்றால் பிசுடோ- குறிப்புகளுடன் 'சரிப்படுத்தப்பட்ட' உள்ளீடுகள் மொழிபெயர்க்கப்பட்டுள்ளது என்பது அடிப்படைக்கோடு NMT முறைமையை பயன்படுத்தி நன்ற நாங்கள் ஆங்கிலத்திலிருந்து ஸ்பானிஷ், இத்தாலியன், பிரெஞ்சு, போர்த்துகீசில் இருந்து நான்கு மொழிபெயர்ப்பு ஜோடிகளை கவனம் செலுத்துகிறோம், எங்கள் கணினியில் 3. 1 பிலிய அனைத்து தரவுத்தளங்களும் குறியீடுகளும் இங்கே பொதுவாக கிடைக்கும்: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'ur': 'نیورل ماشین ترجمہ (NMT) سیستموں کی عملکرد صرف ایک زبان کی فرق پر تدریس کی جاتی ہے جب بھی بہت کم مختلف زبان کی فرق کے ساتھ ملاقات کی جاتی ہے۔ اس کام کے ساتھ ہم پہلے کے کام پر بناتے ہیں کہ اس مسئلہ کو کس طرح کمزور کریں۔ ہم دکھاتے ہیں کہ سیسٹم کے ساتھ طبیعی طور پر آواز کے مطابق صحیح تنظیم (یعنی سیسٹم کے مطابق سیسٹم کے مطابق سیسٹم کے مطابق سیسٹم کے مطابق سیسٹم کے مطابق سیسٹم کا ایک وعدہ دینے والا حل ہے۔ ہم چار ترجمہ جوڑوں پر تمرکز کرتے ہیں، انگلیسی سے اسپانیایی، ایتالیایی، فرانسوی اور پورتوگلیسی سے، ہمارے سیستم سے 3.1 بلیوس پوینٹوں کی تدبیر کی جاتی ہے، جو بنسل لینوں کے مقابلہ میں ایک نئی ایٹیٹ کی حالت بناتے ہیں جو JFLEG-ES ڈیٹسٹ پر ہے. سب ڈاٹ سٹ اور کوڈ یہاں ظاہر طور پر موجود ہیں: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'uz': 'Name Bu ish bilan, biz bu muammolarni qanday o\'chirib chiqish uchun oldingi ish bilan yaramiz. Biz oddiy holatdan foydalanishni ko\'rsatishmiz mumkin, pseudo- referenclari bilan "native tarjima qilmagan tarjimalar" asosida tarjima qilmagan narsalar, bunday tarjima qiladigan tizimning turi oʻzgarishga ishlatiladigan tizimga yetarli yetarmoq. Biz ingliz tildan Ispanchaga, Italyanchaga, Fransuzchaga va Portugalchaga to\'rt tarjima qoʻllarini foydalanamiz. Biz tizimmiz asosiy soniyalarga 3.1 BLEU notoʻgʻri yaxshi o\'zgarishga ega bo\'ladi, JFLEG-ES maʼlumotlar tarjimasiga yangi holatni yaratish. @ info: whatsthis https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'vi': "Sự hiệu quả của hệ thống dịch chuyển máy thần kinh (NMB) chỉ được huấn luyện trên một biến thể ngôn ngữ duy nhất thoái hóa khi đối diện với các biến đổi ngôn ngữ thậm chí hơi khác nhau. Với công việc này, chúng ta xây dựng dựa trên công việc trước đây để tìm hiểu cách giảm thiểu vấn đề này. Chúng tôi cho thấy độ cẩn thận dùng tiếng ồn hiện tại tự nhiên cùng với khả năng giả sử (v.d. Sự chỉnh sửa'các nội dung dịch bằng hệ thống NMT cơ bản) là một giải pháp hứa hẹn với hệ thống mạnh mẽ với kiểu biến đổi nhập. Chúng tôi tập trung vào bốn cặp phiên dịch, từ Anh đến Tây Ban Nha, Ý, Pháp, và Bồ Đào Nha, với hệ thống đạt được những cải tiến trên cả 3.1 nguyên tắc của NIZ so với những đường cơ bản, thiết lập một bộ dữ liệu thời đại mới trên JLEG-Es. Tất cả các tập tin và mật mã đều công khai ở đây: https://github.com/mahfuzibnalam/finetuning_for_robustness Không.", 'bg': 'Ефективността на системите за невронен машинен превод (НМТ), обучени само за един езиков вариант, се влошава, когато са изправени пред дори малко по-различни езикови вариации. С тази работа надграждаме предишната работа, за да проучим как да смекчим този проблем. Показваме, че финото настройване, използвайки естествено срещащ се шум заедно с псевдореференции (т.е. "коригирани" нетворни входове, преведени чрез базовата система NMT), е обещаващо решение за системи, устойчиви на такъв тип входни вариации. Ние се фокусираме върху четири двойки преводи, от английски на испански, италиански, френски и португалски, като нашата система постига подобрения до 3.1 точки в сравнение с базовите линии, създавайки ново състояние на изкуството в набора от данни. Всички набори от данни и код са публично достъпни тук: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'da': 'Udførelsen af neurale maskinoversættelsessystemer (NMT) trænet på en enkelt sprogvariant nedbrydes, når de konfronteres med selv lidt forskellige sprogvariationer. Med dette arbejde bygger vi videre på tidligere arbejde for at undersøge, hvordan vi kan afhjælpe dette problem. Vi viser, at finjustering ved hjælp af naturligt forekommende støj sammen med pseudo-referencer (dvs. "korrigerede" ikke-native input oversat ved hjælp af baseline NMT system) er en lovende løsning mod systemer robuste til sådanne typer input variationer. Vi fokuserer på fire oversættelsespar, fra engelsk til spansk, italiensk, fransk og portugisisk, hvor vores system opnår forbedringer på op til 3,1 BLEU-point i forhold til basislinjerne og etablerer et nyt state-of-the-art på JFLEG-ES datasættet. Alle datasæt og kode er offentligt tilgængelige her: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'nl': "De prestaties van neuronale machine translation (NMT) systemen die slechts op een enkele taalvariant zijn getraind, verslechteren wanneer ze geconfronteerd worden met zelfs enigszins verschillende taalvariaties. Met dit werk bouwen we voort op eerdere werkzaamheden om te onderzoeken hoe we dit probleem kunnen beperken. We tonen aan dat finetuning met natuurlijk optredende ruis samen met pseudo-referenties (d.w.z. 'gecorrigeerde' niet-native inputs vertaald met behulp van het baseline NMT systeem) een veelbelovende oplossing is voor systemen die robuust zijn voor dergelijke invoervariaties. We richten ons op vier vertaalparen, van Engels naar Spaans, Italiaans, Frans en Portugees, waarbij ons systeem verbeteringen bereikt van maximaal 3.1 BLEU punten ten opzichte van de basislijnen, waardoor een nieuwe state-of-the-art op de JFLEG-ES dataset wordt gecreëerd. Alle datasets en code zijn hier openbaar beschikbaar: https://github.com/mahfuzibnalam/finetuning_for_robustness  .", 'de': 'Die Leistung neuronaler maschineller Übersetzung (NMT)-Systeme, die nur auf einer einzigen Sprachvariante trainiert werden, verschlechtert sich, wenn sie mit geringfügig unterschiedlichen Sprachvarianten konfrontiert werden. Mit dieser Arbeit bauen wir auf früheren Arbeiten auf, um zu untersuchen, wie dieses Problem gemildert werden kann. Wir zeigen, dass die Feinabstimmung mit natürlich vorkommendem Rauschen zusammen mit Pseudo-Referenzen (d.h. "korrigierte" nicht-native Eingaben, die mit dem Baseline-NMT-System übersetzt werden) eine vielversprechende Lösung für Systeme ist, die gegen solche Arten von Eingangsvariationen robust sind. Wir konzentrieren uns auf vier Übersetzungspaare, von Englisch nach Spanisch, Italienisch, Französisch und Portugiesisch, wobei unser System Verbesserungen von bis zu 3.1 BLEU Punkten im Vergleich zu den Basislinien erzielt und einen neuen Stand der Technik auf dem JFLEG-ES Datensatz etabliert. Alle Datensätze und Codes sind hier öffentlich verfügbar: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'id': "Performasi sistem terjemahan mesin saraf (NMT) hanya dilatih pada varian bahasa tunggal degrades ketika berhadapan dengan variasi bahasa yang sedikit berbeda. Dengan pekerjaan ini, kami membangun pada pekerjaan sebelumnya untuk mengeksplorasi bagaimana untuk mengurangi masalah ini. Kami menunjukkan bahwa penyesuaian dengan menggunakan suara yang terjadi secara alami bersama dengan pseudo-referensi (i.e. input non-native 'diperbaiki' diterjemahkan menggunakan sistem NMT dasar) adalah solusi yang berjanji terhadap sistem yang kuat untuk jenis variasi input tersebut. Kami fokus pada empat pasangan terjemahan, dari bahasa Inggris ke Spanyol, Italia, Perancis, dan Portugis, dengan sistem kami mencapai peningkatan sampai 3,1 poin BLEU dibandingkan dengan garis dasar, mendirikan state-of-the-art baru pada dataset JFLEG-ES. Semua set data dan kode tersedia publik di sini: https://github.com/mahfuzibnalam/finetuning_for_robustness Apa?", 'ko': "신경기계번역(NMT) 시스템은 단일 언어 변체에서만 훈련되며 심지어 약간 다른 언어 변체를 만나면 성능이 떨어진다.이 일을 통해 우리는 이전의 업무의 기초 위에서 어떻게 이 문제를 완화시킬 것인가를 모색한다.우리는 자연적으로 발생하는 소음과 위조 참고(즉 기선 NMT 시스템에서 번역한'교정'비본체 입력)를 사용하여 미세하게 조정하는 것은 이러한 입력 변화가 노봉성을 가진 시스템에 있어 매우 희망적인 해결 방안이라고 밝혔다.우리는 영어부터 스페인어, 이탈리아어, 프랑스어, 포르투갈어 네 쌍의 번역에 전념했다. 기선에 비해 우리의 시스템은 3.1개의 BLEU점에 이르는 개선을 실현했고 JFLEG-ES 데이터 집합에 새로운 최첨단 수준을 세웠다.모든 데이터 세트 및 코드는 여기서 공개적으로 확인할 수 있습니다.https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'sw': "Utamaduni wa mfumo wa kutafsiri mashine ya ubongo (NMT) ulifunzwa tu kwa kiwango cha tofauti cha lugha moja ambapo ulikabiliana na mabadiliko ya lugha tofauti kidogo. Kwa kazi hii, tunajenga kazi zilizopita ili kutafuta jinsi ya kupunguza suala hili. Tunaonyesha kuwa tunu nzuri kwa kutumia kelele zilizotokea kwa asili pamoja na maoni ya pseudo (yaani 'kurekebisha' vitu visivyo vya asili vilivyotafsiriwa kwa kutumia mfumo wa NMT wa msingi) ni suluhisho la kuahidini dhidi ya mifumo inayorushwa na mabadiliko ya aina hiyo ya input. Tunawasilia wawili wanne wa tafsiri, kutoka Kiingereza hadi Kihispania, Kiitalia, Kifaransa na Kireno, kwa mfumo wetu wa kupata maboresho ya hadi pointi 3.1 BLEU ukilinganisha na misingi ya msingi, kuanzisha hali mpya ya sanaa kwenye seti ya taarifa za JFLEG-ES. Seti zote za taarifa na sheria zinapatikana hadharani hapa: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'fa': "عملکرد سیستم ترجمه\u200cهای ماشین عصبی (NMT) تنها روی یک متغیر زبان آموزش داده می\u200cشود وقتی که با متغیرات زبان\u200cهای کوچک متفاوت روبرو می\u200cشوند. با این کار، ما روی کار قبلی ساختیم تا بفهمیم چگونه این مسئله را کاهش دهیم. ما نشان می دهیم که با استفاده از صدای طبیعی اتفاق می\u200cافتد با تفصیل\u200cهای pseudo-references (یعنی: corrected 'non-native input translated using the baseline NMT system) یک راه حل قوی برای سیستم\u200cهای قوی برای چنین نوع تغییرات ورودی است. ما روی چهار جفت ترجمه تمرکز می کنیم، از انگلیسی به اسپانیایی، ایتالیایی، فرانسوی و پورتوگلیسی، با سیستم ما تا 3.1 نقطه\u200cهای BLEU در مقایسه با خطوط بنیادی، که یک وضعیت هنری جدید در مجموعه داده\u200cهای JFLEG-ES قرار می\u200cدهیم. تمام مجموعه\u200cهای داده\u200cها و کد در اینجا عمومی موجود می\u200cشوند: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'af': "Die prestasie van neurale masjien vertaling (NMT) stelsels wat slegs op 'n enkele taal variant onderwerp word wanneer aangesig is met selfs klein verskillende taal variasies. Met hierdie werk bou ons op vorige werk om te ondersoek hoe om hierdie probleem te verminder. Ons wys dat fin- tuning gebruik natuurlik geruis saam met pseudo- verwysing (i.e. 'korrigeer' non- native inputs vertaal deur die basilyn NMT stelsel) is 'n beloftende oplossing teen stelsels kragtig na sodanige tipe invoer variasies. Ons fokus op vier vertalingspaar, van Engels tot Spaanse, Italiese, Frans en Portugees, met ons stelsel wat verbeteringe tot 3.1 BLES punte tot by die basisline vergelyk het, met 'n nuwe staat van die kuns op die JFLEG-ES datastel te stel. Alle datastelle en kode is openlik beskikbaar hier: https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'am': 'የኔural machine translation (NMT) systems are only trained at a single language variant degrades when you confront with a little bit of different language variations. በዚህ ስራ፣ የዚህን ጉዳይ እንዴት እንዲያሳጥል ለመፈለግ የቀድሞው ሥራ ላይ እንሠራለን፡፡ እናሳየዋለን የድምፅ ድምፅ በተገኘው በአዳራዊ ድምፅ እናሳየዋለን፡፡ ከንግግሊዝኛ ጀምሮ እስከ ስፓኒሽ፣ ጣሊያንኛ፣ ፈረንሳይኛ እና ፖርቱጋልኛ ድረስ አራት ትርጉም ሁለቶችን እናስማማታለን፡፡ የJFLEG-ES ዳታ-አዲስ ሀብት-የ-አርእስት ማድረግ እናደርጋለን፡፡ አዲስ ዶሴ ፍጠር https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'tr': 'NMT sistemalaryň täsiri diňe bir dil üýtgewinde bilim üýtgewleri bilen çarpyşýar. Bu işi bilen öňki işiň üstüne bu meseläni nähili azaltmak üçin gözlemek üçin gurnuyoruz. Biz pseudo-Referanslar bilen ýene-täsirli gürrüň ullanýän gürrüň ýüze çözümlenmegi görkeýäris. Biz Iňlisçe, italiýa, fransuzça we portugalça çerçewçilige dört sany terjime çift diýip üns berýäris. Biziň sistemamyz 3.1 BLEU üýtgeşmeleri ýagdaýda ýakynlaşdyrylýar, we JFLEG-ES maglumatlarynda täze bir möhüm bolup durýarys. Ehli veri setirleri we kodlar päblisaň şu ýerde bar: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'hy': "Նյարդային մեքենայի թարգմանման (NMT) համակարգերի արտադրողությունը, որը պատրաստված է միայն մեկ լեզվի տարբերակի վրա, դեգրեկում է, երբ դեմ է առնչվում նույնիսկ մի քիչ տարբեր լեզվի տարբերակների հետ: Այս աշխատանքի միջոցով մենք հիմնված ենք նախորդ աշխատանքի վրա, որպեսզի ուսումնասիրենք, թե ինչպես նվազեցնել այս խնդիրը: Մենք ցույց ենք տալիս, որ բարելավումը, օգտագործելով բնական աղմուկը, միասին կեղծ հղումների (այսինքն, բարելավված' ոչ բնական ինֆորմացիոն ինֆորմացիոն համակարգի միջոցով թարգմանված ինֆորմացիոն ինֆորմացիոն համակարգի միջոցով) խոստացող լուծում է համակարգերի համար,  Մենք կենտրոնանում ենք չորս թարգմանման զույգերի վրա, անգլերենից մինչև իսպաներեն, իսպաներեն, ֆրանսերեն և պորտուգալերեն, մեր համակարգը բարելավում է մինչև 3.1 կետ, համեմատած հիմնական գծերին, ստեղծում է JFlEEG-es տվյալների համակարգի նոր տեխնոլո Բոլոր տվյալների համակարգերը և կոդը հասանելի են այստեղ. https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'sq': "Përkthimi i sistemeve të përkthimit nervor të makinave (NMT) të trajnuar vetëm në një variant të vetëm gjuhësh degradon kur përballet me variacione edhe pak të ndryshme gjuhësh. Me këtë punë, ne ndërtojmë mbi punën e mëparshme për të eksploruar si të lehtësojmë këtë çështje. Ne tregojmë se rregullimi i mirë duke përdorur zhurmën që ndodh natyralisht së bashku me pseudo-referenca (i.e. 'korrektuar' input jo-vendas përkthyer duke përdorur sistemin NMT bazë) është një zgjidhje premtuese ndaj sistemeve të fuqishëm për një lloj të tillë variacionesh input. Ne përqëndrohemi në katër çifte përkthimi, nga anglisht në spanjoll, italian, francez dhe portugal, me sistemin tonë që arrin përmirësime deri në 3.1 pikë BLEU krahasuar me linjat bazë, duke ngritur një gjendje të re të teknologjisë në sistemin e të dhënave JFLEG-ES. Të gjitha të dhënat dhe kodet janë në dispozicion publik këtu: https://github.com/mahfuzibnalam/finetuning_for_robustness - Po.", 'hr': 'Proizvodnja sustava prevoda neuralnih strojeva (NMT) obučenih samo na jednom jezičkom varijantu degradira se kada se suočavaju sa čak i malo različitim jezičkim varijancijama. S ovim poslom, izgradili smo na prethodnom poslu kako bi istražili kako smanjiti ovaj problem. Pokazujemo da je dobra prilagodba koristeći prirodno pojavljujući buku zajedno s pseudoreferencijama (tj. „ispravljeni“ ne-domaći ulazi prevedeni korištenjem početnog NMT sustava) obećavajuće rješenje prema sustavima jačim prema takvom vrstu ulaznih varijacija. Usredotočili smo se na četiri parova prevođenja, od engleskog na španjolsku, italijansku, francusku i portugalsku, s našim sustavom postizanjem poboljšanja do 3,1 BLEU bodova u usporedbi s početnim linijama, uspostavljajući novi stanje umjetnosti na setu podataka JFLEG-ES. Svi podaci i kodovi su javno dostupni ovdje: https://github.com/mahfuzibnalam/finetuning_for_robustness -Da.', 'ca': 'El rendiment dels sistemes neuromàquines de traducció (NMT) només entrenats en una sola variant de llenguatge es degrada quan s\'enfronten a variacions de llenguatge fins i tot una mica diferents. Amb aquesta feina, construïm sobre la feina anterior per explorar com mitigar aquesta qüestió. Ens demostra que ajustar fent servir soroll naturalment juntament amb pseudoreferències (i.e. entrades "corregides" no natives traduïdes fent servir el sistema NMT de base) és una solució prometedora cap a sistemes robustos a aquest tipus de variacions d\'entrada. Ens centrem en quatre parelles de traducció, d\'anglès a espanyol, italià, francès i portuguès, amb el nostre sistema aconseguint millores de fins a 3,1 punts BLEU comparats amb les línies de base, creant una nova tecnologia del conjunt de dades JFLEG-ES. Tots els conjunts de dades i codis estan disponibles aquí: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'cs': 'Výkonnost systémů neuronového strojového překladu (NMT) trénovaných pouze na jedné jazykové variantě se snižuje, když se konfrontují s mírně odlišnými jazykovými variacemi. V této práci navazujeme na předchozí práci a zkoumáme, jak tento problém zmírnit. Ukazujeme, že jemné ladění za použití přirozeně se vyskytujícího šumu spolu s pseudoreferencemi (tj. "opravených" neinnativních vstupů přeložených pomocí základního NMT systému) je slibným řešením systémů robustních na takový typ vstupních variací. Zaměřujeme se na čtyři překladatelské páry, z angličtiny do španělštiny, italštiny, francouzštiny a portugalštiny, přičemž náš systém dosahuje zlepšení až 3.1 BLEU bodů ve srovnání s základními liniemi, což vytváří nový nejmodernější datový soubor JFLEG-ES. Všechny datové sady a kódy jsou veřejně dostupné zde: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'bn': "নিউরেল মেশিন অনুবাদ (NMT) সিস্টেম শুধুমাত্র একটি ভাষার ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভি এই কাজের মাধ্যমে আমরা পূর্ববর্তী কাজের উপর নির্মাণ করছি এই বিষয়টি কিভাবে কমানোর জন্য। আমরা দেখাচ্ছি যে স্বাভাবিক আওয়াজ ব্যবহার করে স্বাভাবিকভাবে আওয়াজ ব্যবহার করে (যেমন 'সংশোধন' না স্থানীয় ইনপুট ব্যবহার করা হচ্ছে বেসারেলাইন NMT সিস্টেম ব্যবহার করে অনুবা আমরা ইংরেজি, ইতালিয়ান, ফরাসী এবং পর্তুগীজ থেকে চারটি অনুবাদ জোড়ার দিকে মনোযোগ দিচ্ছি, যার মাধ্যমে আমাদের সিস্টেম ৩. সকল ডাটাসেট এবং কোড এখানে প্রকাশ্যে পাওয়া যাচ্ছে: https://github.com/mahfuzibnalam/finetuning_for_robustness  .", 'az': 'NMT (NMT) sistemlərin performansı yalnız bir dil variansı ilə müxtəlif dil dəyişiklikləri ilə qarşılaşdığı vaxt dəyişiklik dəyişiklikləri üzündə təhsil ediləndir. Bu iş ilə, əvvəlki işin üstündə bu məsələni necə azaltılacağını keşfetmek üçün inşa edirik. Biz pseudo-references ilə birlikdə təbiətli səsləri istifadə edərək təmizlənmək üçün təbiətli təmizlənməsini göstərdik. Biz İngilizdən İspanyoldan, İtalyan, Fransız və Portugalca dörd çeviri ilə birlikdə sistemimizin 3.1 BLEU noktalarına qədər yaxşılaşdırmağını sağlayaraq, JFLEG-ES veri qutusunda yeni məlumatın durumu təyin edirik. Bütün verilən qurğular və kodlar burada açıq-aşkar mövcuddur: https://github.com/mahfuzibnalam/finetuning_for_robustness .', 'bs': 'Proizvodnja sustava prevoda neuralnih strojeva (NMT) obučenih samo na jednom jezičkom varijantu degradera kada se suočavaju sa čak i malo različitim jezičkim varijancijama. Sa ovim poslom, izgradimo na prethodnom poslu da istražimo kako da smanjimo ovaj problem. Pokazujemo da je dobra prilagodba koristeći prirodno nastavljajući buku zajedno sa pseudoreferencijama (tj. „ispravljeni“ ne-lokalni ulazi prevedeni korištenjem početnog NMT sistema) obećavajuće rješenje prema sistemima jačim takvim vrstom varijacija ulaza. Usredotočili smo se na četiri parova prevođenja, od engleskog na španjolsku, italijansku, francusku i portugalsku, s našim sistemom koji postiže poboljšanja do 3,1 BLEU bodova u usporedbi sa osnovnim linijama, uspostavljajući novi stanje umjetnosti na setu podataka JFLEG-ES. Svi podaci i kodovi su javno dostupni ovdje: https://github.com/mahfuzibnalam/finetuning_for_robustness -Da.', 'fi': 'Vain yhdellﾃ､ kielimuunnoksella koulutettujen neurokonekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmien suorituskyky heikkenee, kun kielimuunnokset ovat hieman erilaisia. Tﾃ､mﾃ､n tyﾃｶn pohjalta tutkimme, miten tﾃ､tﾃ､ ongelmaa voidaan lieventﾃ､ﾃ､. Osoitamme, ettﾃ､ hienosﾃ､ﾃ､tﾃｶ luonnollisella kohinalla ja pseudoreferenssillﾃ､ (eli ns. "korjatuilla" ei-natiivituloilla kﾃ､ﾃ､nnetyillﾃ､ lﾃ､htﾃｶtason NMT-jﾃ､rjestelmﾃ､llﾃ､) on lupaava ratkaisu jﾃ､rjestelmiin, jotka kestﾃ､vﾃ､t tﾃ､llaisia tulomuunnoksia. Keskitymme neljﾃ､ﾃ､n kﾃ､ﾃ､nnﾃｶspariin, englanniksi espanjaksi, italiaksi, ranskaksi ja portugaliksi, ja jﾃ､rjestelmﾃ､mme saavuttaa jopa 3,1 BLEU-pisteen parannuksia lﾃ､htﾃｶlinjoihin verrattuna, luoden uuden state-of-the-art JFLEG-ES-aineistoon. Kaikki aineistot ja koodit ovat julkisesti saatavilla tﾃ､ﾃ､ltﾃ､: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'et': 'Vaid ühel keelel koolitatud neuromasintõlke süsteemide jõudlus halveneb isegi veidi erinevate keeleliste variatsioonidega silmitsi seistes. Selle tööga toetume varasematele töödele, et uurida, kuidas seda probleemi leevendada. Näitame, et peenhäälestus loodusliku müra abil koos pseudoviitetega (s.t "korrigeeritud" mittekohaliste sisenditega, mis on tõlgitud lähtetaseme NMT süsteemi abil) on paljulubav lahendus süsteemide jaoks, mis on vastupidavad sellistele sisendite variatsioonidele. Me keskendume neljale tõlkepaarile, inglise keelest hispaania, itaalia, prantsuse ja portugali keelde, kusjuures meie süsteem saavutab baasjoontega võrreldes kuni 3,1 BLEU punkti, luues JFLEG-ES andmekogumi uue taseme. Kõik andmekogumid ja kood on avalikult kättesaadavad siin: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'jv': "Kernel Ngomongke iki, kita nggawe lan cara sing dumadhi kanggo kebebasan cara nggawe sakjane iki banget. Awak dhéwé éntuk sistem sing paling-dibutung gawe nguasai perusahaan karo pseudno-reference (i.e. '-rected' inputs Gak-nambah inputs terusahaan sistem bakal terusahaan NMT) iki dadi sing bisa perusahaan nganggep sistem sing gawe nguasai perusahaan dialané. Awak dhéwé éntuk sistem sing itlanjut kanggo ngerasakno itlanjut karo Perancis, itlanyuk, Perancis lan portugis, nganggep sistem dhéwé nggawe gerarané supoyata 3.1 B Lah dataset lan kode kang dipuluwat nang kene https://github.com/mahfuzibnalam/finetuning_for_robustness .", 'ha': 'Farawa na fassarar masu kwaurar (NMT) na\'urar na\'urar (na tafiyar da shi kawai a kan wata darajõji na daban-daban cikin harshe guda idan an haɗi da wasu variantun harshe ko da suka yi rabo kaɗan. Daga wannan aikin, munã samun aiki da ya gabata dõmin mu jarraba jinin ya cire wannan masu zartar. Tuna nuna cewa tsarin da ke amfani da sautin da ke fara a sami da shiryoyin mutane (misali \'da aka daidaita\' na-native ana fassar da shiryoyin ayuka na NMT\' ya zama mai yiwuwa wa\'adi wa\'urar da aka fassara shi a ƙarƙashin ƙayyade). Tuna fokusar da sauri huɗu ɗin translation, daga Ingiriya zuwa Isbanish, Italian, French, kuma Portugueski, tãre da na\'uranmu idan yana sami tsarin marubuci zuwa 3.1 BLEU points sami da basketan, yana sami da wata new state-of-the-art on the JFLEG-ES dataset. Dukan daidaita danna da kodi na da bayyane za\'a iya samar da wannan: https://github.com/mahfuzibnalam/finetuning_for_robustness Ya ce: "Yã ku mutãne!', 'sk': 'Zmogljivost sistemov nevronskega strojnega prevajanja (NMT), usposobljenih le za eno jezikovno varianto, se poslabša, če se soočajo s celo rahlo različnimi jezikovnimi variacijami. S tem delom gradimo na predhodnem delu, da bi raziskali, kako ublažiti to težavo. Pokazali smo, da je natančno nastavitev z uporabo naravnega hrupa skupaj s psevdo referencami (tj. "popravljenih" tujih vhodov, prevedenih z uporabo osnovnega sistema NMT) obetavna rešitev za sisteme, ki so robustni za tovrstne vhodne variacije. Osredotočamo se na štiri prevajalske pare, od angleščine v španščino, italijanščino, francoščino in portugalščino, pri čemer naš sistem doseže izboljšave do 3,1 točke BLEU v primerjavi z izhodiščnimi črtami in vzpostavi nov najsodobnejši nabor podatkov JFLEG-ES. Vsi nabori podatkov in kode so javno dostopni tukaj: https://github.com/mahfuzibnalam/finetuning_for_robustness  .', 'he': "The performance of neural machine translation (NMT) systems only trained on a single language variant degrades when confronted with even slightly different language variations.  עם העבודה הזו, אנחנו בונים על עבודה קודמת כדי לחקור איך להקל על הנושא הזה. אנחנו מראים ששימוש בהתאמה מיוחדת באמצעות רעש מתרחש באופן טבעי יחד עם התייחסות פסאודו (כלומר תוקנות 'כניסות לא מקומיות מתרגמות באמצעות מערכת NMT הבסיסית) הוא פתרון מבטיח כלפי מערכות חזקות לסוג כזה של שוורציות כניסה. אנחנו מתמקדים בארבעה זוגות תרגום, מאנגלית לספרדית, איטלקית, צרפתית ופורטוגזית, עם המערכת שלנו להשיג שיפורים עד 3.1 נקודות BLEU בהשוואה לקווי הבסיס, להקים מצב חדש של המידע JFLEG-ES. כל קבוצות נתונים וקוד זמינים לפומבי כאן: https://github.com/mahfuzibnalam/finetuning_for_robustness -כן.", 'bo': 'ནུས་ཡིག་ལག་འཁྱེར་གྱི་སྣ་ཚོགས་འགྲེལ་བ(NMT)མ་ལག་གི་གོ་སྐབས་སྐད་རིགས་གཅིག་གི་འགྱུར་བ་དང་མཐུན་རྐྱེན་ཚད་ལ་ཕན ང་ཚོས་བྱ་ཚིག་དང་། སྔོན་གྱི་ལས་ཀ་ཆ་རྐྱེན་དུ་གཏོང་བྱས་ནས་གནད་དོན་ཇི་ལྟར་བཞག་དགོས་པ་དེ་ ང་ཚོས་རང་བཞིན་གྱིས་མཐུན་སྒྲིག་གི་ནད་ཅིག་དང་མཉམ་དུ་འཕགས་པའི་བརྡ་སྤྲོད་ཀྱི་ཡོད་པ་དེ། ང་ཚོའི་མ་ལག འདིར་སྤྱོད་པའི་གནད་སྡུད་སྒྲིག་ཆ་སྒྲིག་འགོད་དང་ཨང་གྲངས་ཡོངས་རྫོགས་སྤྱོད་པ： https://github.com/mahfuzibnalam/finetuning_for_robustness .'}
{'en': 'Impact of ASR on Alzheimer’s Disease Detection : All Errors are Equal, but Deletions are More Equal than Others ASR  on  A lzheimer’s Disease Detection: All Errors are Equal, but Deletions are More Equal than Others', 'ar': 'تأثير بقايا تقطيع السيارات على اكتشاف مرض الزهايمر: جميع الأخطاء متساوية ، لكن عمليات الحذف أكثر تساويًا من غيرها', 'fr': "Impact de l'ASR sur la détection de la maladie d'Alzheimer\xa0: toutes les erreurs sont égales, mais les suppressions sont plus égales que les autres", 'es': 'Impacto de la ASR en la detección de la enfermedad de Alzheimer: todos los errores son iguales, pero las eliminaciones son más iguales que otros', 'pt': 'Impacto da ASR na detecção da doença de Alzheimer: todos os erros são iguais, mas as exclusões são mais iguais do que outras', 'ja': 'アルツハイマー病検出におけるASRの影響：すべての誤差は等しいが、欠失は他の誤差よりも等しい', 'zh': 'ASR于阿尔茨海默病检测:凡诸错误皆平等,但删除比他错误更等', 'hi': 'अल्जाइमर रोग का पता लगाने पर एएसआर का प्रभाव: सभी त्रुटियां समान हैं, लेकिन विलोपन दूसरों की तुलना में अधिक समान हैं', 'ru': 'Влияние ASR на выявление болезни Альцгеймера: все ошибки равны, но удаление более равны, чем другие', 'ga': 'Tionchar ASR ar Bhrath Galar Alzheimer: Tá gach Earráid Comhionann, ach tá Scriosadh Níos Cothroime ná Eile', 'ka': 'ASR-ის შეცდომა ალცჰეიმერის ავადების განვიცნობაზე: ყველა შეცდომა ტოლია, მაგრამ წაშლა უფრო ტოლია', 'it': "Impatto dell'ASR sul rilevamento della malattia di Alzheimer: tutti gli errori sono uguali, ma le cancellazioni sono più uguali di altri", 'kk': 'Альцхаймердің ауруларының ASR нәтижесі: Барлық қателер тең, бірақ өшіру басқалардан тең', 'el': 'Επίδραση της ΑΣR στην ανίχνευση της νόσου Αλτσχάιμερ: Όλα τα λάθη είναι ίσα, αλλά οι διαγραφές είναι πιο ίσες από άλλες', 'hu': 'Az ASR hatása az Alzheimer-kór felismerésére: Minden hiba egyenlő, de a törlések egyenlőbbek, mint mások', 'mk': 'Влијанието на АСР врз детекцијата на Алцхајмеровата болест: Сите грешки се еднакви, но избришувањата се поеднакви од другите', 'mt': 'L-impatt tal-ASR fuq id-Detezzjoni tal-Marda ta’ Alzheimer: L-Errori kollha huma Ugwali, iżda t-Tħassir huwa Aktar Ugwali minn Oħrajn', 'ms': "Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal, but Deletions are More Equal than Others", 'lt': "Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal, but Deletions are More Equal than Others", 'ml': 'അല്\u200dസ്ഹീമെരിന്\u200dറെ രോഗം കണ്ടുപിടിക്കുന്നതിന്\u200dറെ ആസ്രിന്\u200dറെ പ്രഭാവം: എല്ലാ പിശകുകളും സമമാണ്, പക്ഷെ മറ്റുള്ളവരെക്കാളും മായ', 'mn': 'Альцхаймерийн өвчний нээлттэй АСР нөлөө: Бүх алдаа тэнцүү, гэхдээ устгах нь бусдаас илүү тэнцүү.', 'ro': 'Impactul ASR asupra detectării bolii Alzheimer: Toate erorile sunt egale, dar ștergerile sunt mai egale decât altele', 'no': 'Effekt på ASR på Alzheimer s sykdomme: Alle feil er lik, men sletting er meir like enn andre', 'sr': 'Učinak ASR na detekciju Alzheimerove bolesti: Sve greške su jednake, ali delecije su jednake od drugih', 'si': 'අල්ජායිමර්ගේ රෝග හොයාගන්න ASR ප්\u200dරශ්නයක්: හැම දෝෂයක්ම හරියයි, නමුත් නිර්මාණය අනිත් වඩා වඩා වඩා වඩා', 'pl': 'Wpływ ASR na wykrywanie choroby Alzheimera: wszystkie błędy są równe, ale usunięcia są bardziej równe niż inne', 'so': "Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal, but Deletions are More Equal than Others", 'sv': 'Effekter av ASR på Alzheimers sjukdom upptäckt: Alla fel är lika, men borttagningar är mer lika än andra', 'ta': 'அல்சைமரின் நோய் கண்டுபிடிப்பதில் ASR விளைவு: அனைத்து பிழைகளும் சமமாக இருக்கின்றன, ஆனால் நீக்கல்கள் மற்றவர்களை விட அதிகமாக உள்ளன', 'ur': 'آسیر کے اثر آلزحمیر کے بیماری اثر پر ہے: تمام خطائیں برابر ہیں، لیکن حذف دوسروں سے زیادہ برابر ہیں', 'uz': 'Alzheimer kasalliklarni aniqlash uchun ASR bajarishi', 'vi': "Tác động của ASR về bệnh Alzheimer's trinh s át: Mọi lỗi đều giống nhau, nhưng việc xóa bỏ nhiều hơn nhiều người.", 'hr': 'Učinak ASR na otkrivanje Alzheimerove bolesti: Sve greške su jednake, ali delecije su jednake od drugih', 'nl': 'Effect van ASR op de detectie van de ziekte van Alzheimer: alle fouten zijn gelijk, maar verwijderingen zijn gelijker dan andere', 'bg': 'Въздействие на АСР върху откриването на болестта на Алцхаймер: Всички грешки са равни, но изтриванията са по-равни от другите', 'da': 'ASR påvirker Alzheimers sygdom: Alle fejl er lige, men sletninger er mere lige end andre', 'de': 'Auswirkungen von ASR auf die Erkennung von Alzheimer: Alle Fehler sind gleich, aber Löschungen sind gleicher als andere', 'id': "Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal, but Deletions are More Equal than Others", 'ko': 'ASR이 알츠하이머 검사에 미치는 영향: 모든 오류는 같지만 다른 오류보다 삭제하는 것이 더 같다', 'fa': 'اثر ASR بر اثبات بیماری الزهایمر: همه خطاها برابر هستند، ولی حذف کردن بیشتر از بقیه برابر هستند', 'sw': 'Matokeo ya ASR juu ya Kugundua Ugonjwa wa Alzheimer: Matangazo yote ni sawa, lakini Vifo vingi sawa kuliko wengine', 'tr': "Alzheimer'in hastalığı tarafından ASR'ın etkisi: Bütün hatalar eşit, fakat silmeler başkalarından daha çok eşit.", 'af': 'Voorwerp van ASR op Alzheimer se siekte opdekking: Alle foute is gelyk, maar Uitveerings is meer gelyk as ander', 'sq': 'Ndikimi i ASR në zbulimin e s ëmundjes së Alzheimerit: Të gjitha gabimet janë të barabarta, por eleminimi është më i barabartë se të tjerët', 'hy': 'ԱԱՍ-ի ազդեցությունը Ալցհեյմերի հիվանդության հայտնաբերման վրա. բոլոր սխալները հավասար են, բայց ջնջելը ավելի հավասար է, քան մյուսները:', 'am': 'የአልዝheimer ድካም ማረጋገጫ ላይ የASR ጥያቄ ነው፤ ሁሉም ስህተት እኩል ነው ነገር ግን ማስወገድ በሌሎች ላይ ትክክል ነው፡፡', 'az': 'Alzheimer hastalńĪńüńĪ keŇüfinin ASR t…ôsiri: B√ľt√ľn hatalar eyni ola bil…ôr, amma silm…ôl…ôr dig…ôrl…ôrind…ôn daha √ßox eyni ola bil…ôr.', 'bn': 'আলজেমারের রোগ সনাক্তির উপর আসার প্রভাব: সমস্ত সমস্যার সমান, কিন্তু মৃত্যুর মান অন্যান্যের চেয়ে বেশী সমান।', 'bs': 'Učinak ASR na detekciju Alzheimerove bolesti: Sve greške su jednake, ali delecije su jednake od drugih', 'ca': "Impact of ASR on Alzheimer's Disease Detection: All Errors are Equal, but Deletions are More Equal than Others", 'cs': 'Dopad ASR na detekci Alzheimerovy choroby: Všechny chyby jsou stejné, ale odstranění jsou stejné než ostatní', 'et': 'ASR mõju Alzheimeri tõve tuvastamisele: kõik vead on võrdsed, kuid kustutamised on teistest võrdsemad', 'fi': 'ASR:n vaikutus Alzheimerin taudin havaitsemiseen: Kaikki virheet ovat tasavertaisia, mutta poistot ovat muita tasavertaisempia', 'ha': "Effekt of ANR on Alzheier's Disastar: Duk Kyaure ne daidai, kuma amma Taurar Daidai ko da wasu", 'he': 'השפעה של ASR על גילוי מחלת אלצהיימר: כל השגיאות שוויות, אבל מחיקות שוויות יותר מאחרים', 'sk': 'Vpliv ASR na zaznavanje Alzheimerjeve bolezni: Vse napake so enake, vendar so izbrisi bolj enaki kot drugi', 'jv': 'Ngucap ASR iku Aldhéjmer sakjane kanggo Kemerdekaan Aldhéjmer', 'bo': 'ཨ་ཛེ་མི་རྙོལ་ཁང་གི་གནོད་སྐབས་ཀྱི་ASR གནོད་དོན་ཡོད། ནོར་འཁྲུལ་ཆ་ཚང་གཉིས་མཚུངས་ཡིན། བསུབ་ཀྱི་གནོད་སྡུད་འདི་'}
{'en': 'Automatic Speech Recognition (ASR) is a critical component of any fully-automated speech-based dementia detection model. However, despite years of speech recognition research, little is known about the impact of ASR accuracy on dementia detection. In this paper, we experiment with controlled amounts of artificially generated ASR errors and investigate their influence on dementia detection. We find that deletion errors affect  detection  performance the most, due to their impact on the features of syntactic complexity and discourse representation in speech. We show the trend to be generalisable across two different datasets for cognitive impairment detection. As a conclusion, we propose optimising the ASR to reflect a higher penalty for  deletion errors  in order to improve dementia detection performance.', 'fr': "La reconnaissance vocale automatique (ASR) est un composant essentiel de tout modèle de détection de la démence entièrement automatisé basé sur la parole. Cependant, malgré des années de recherche sur la reconnaissance de la parole, on sait peu de choses sur l'impact de la précision de l'ASR sur la détection de Dans cet article, nous expérimentons des quantités contrôlées d'erreurs ASR générées artificiellement et étudions leur influence sur la détection de la démence. Nous constatons que les erreurs de suppression affectent le plus les performances de détection, en raison de leur impact sur les caractéristiques de complexité syntaxique et de représentation du discours dans la parole. Nous montrons que la tendance est généralisable à deux ensembles de données différents pour la détection des troubles cognitifs. En conclusion, nous proposons d'optimiser l'ASR afin de refléter une pénalité plus élevée pour les erreurs de suppression afin d'améliorer les performances de détection de la démence.", 'ar': 'يعد التعرف التلقائي على الكلام (ASR) مكونًا مهمًا في أي نموذج مؤتمت بالكامل لاكتشاف الخرف القائم على الكلام. ومع ذلك ، على الرغم من سنوات من البحث في التعرف على الكلام ، لا يُعرف الكثير عن تأثير دقة ASR على اكتشاف الخرف. في هذا البحث ، قمنا بتجربة كميات مضبوطة من أخطاء ASR المتولدة بشكل مصطنع والتحقيق في تأثيرها على اكتشاف الخرف. نجد أن أخطاء الحذف تؤثر بشكل كبير على أداء الكشف ، وذلك لتأثيرها على ميزات التعقيد النحوي وتمثيل الخطاب في الكلام. نظهر الاتجاه ليكون قابلاً للتعميم عبر مجموعتي بيانات مختلفتين لاكتشاف الضعف الإدراكي. في الختام ، نقترح تحسين ASR لتعكس عقوبة أعلى لأخطاء الحذف من أجل تحسين أداء اكتشاف الخرف.', 'es': 'El reconocimiento automático de voz (ASR) es un componente fundamental de cualquier modelo de detección de demencia basado en el habla totalmente automatizado. Sin embargo, a pesar de los años de investigación sobre el reconocimiento del habla, poco se sabe sobre el impacto de la precisión de la ASR en la detección En este artículo, experimentamos con cantidades controladas de errores de ASR generados artificialmente e investigamos su influencia en la detección de la demencia. Encontramos que los errores de eliminación afectan más al rendimiento de la detección, debido a su impacto en las características de la complejidad sintáctica y la representación del discurso en el habla. Mostramos que la tendencia es generalizable en dos conjuntos de datos diferentes para la detección del deterioro cognitivo. Como conclusión, proponemos optimizar la ASR para que refleje una penalización más alta por los errores de eliminación con el fin de mejorar el rendimiento de la detección de demencia.', 'pt': 'O Reconhecimento Automático de Fala (ASR) é um componente crítico de qualquer modelo de detecção de demência baseado em fala totalmente automatizado. No entanto, apesar de anos de pesquisa em reconhecimento de fala, pouco se sabe sobre o impacto da precisão do ASR na detecção de demência. Neste artigo, experimentamos quantidades controladas de erros de ASR gerados artificialmente e investigamos sua influência na detecção de demência. Descobrimos que os erros de exclusão afetam mais o desempenho de detecção, devido ao seu impacto nas características de complexidade sintática e representação do discurso na fala. Mostramos que a tendência é generalizável em dois conjuntos de dados diferentes para detecção de comprometimento cognitivo. Como conclusão, propomos otimizar o ASR para refletir uma penalidade maior para erros de deleção, a fim de melhorar o desempenho da detecção de demência.', 'ja': '自動音声認識（ ASR ）は、あらゆる完全自動音声ベースの認知症検出モデルの重要なコンポーネントです。しかし、長年の音声認識研究にもかかわらず、ASR精度が認知症検出に与える影響についてはほとんど知られていない。本稿では、制御量の人為的に生成されたASR誤差を実験し、認知症検出への影響を検討した。削除エラーは、音声における構文の複雑さと会話表現の特徴に影響を与えるため、検出パフォーマンスに最も影響を与えることがわかります。認知障害検出のための2つの異なるデータセットにわたって一般化可能な傾向を示しています。結論として、認知症の検出性能を向上させるために、欠失エラーに対するペナルティを高くするようにASRを最適化することを提案します。', 'zh': '自语音识(ASR)全自动是一切痴呆检模形之要组件。 然虽多年语音,人ASR准确性于痴呆症检知之甚少。 试之受控数者为ASR差,而究其检痴呆症。 吾见删谬于检性者最大,盖其于语音句法复杂性语也。 我们展示了认识障碍检测的两个不同数据集可推广的趋势。 臣等建言优化ASR以损益为罚,以崇痴呆症检。', 'hi': 'Automatic Speech Recognition (ASR) किसी भी पूरी तरह से स्वचालित भाषण-आधारित मनोभ्रंश का पता लगाने के मॉडल का एक महत्वपूर्ण घटक है। हालांकि, भाषण मान्यता अनुसंधान के वर्षों के बावजूद, मनोभ्रंश का पता लगाने पर एएसआर सटीकता के प्रभाव के बारे में बहुत कम जाना जाता है। इस पेपर में, हम कृत्रिम रूप से उत्पन्न एएसआर त्रुटियों की नियंत्रित मात्रा के साथ प्रयोग करते हैं और मनोभ्रंश का पता लगाने पर उनके प्रभाव की जांच करते हैं। हम पाते हैं कि विलोपन त्रुटियां पता लगाने के प्रदर्शन को सबसे अधिक प्रभावित करती हैं, क्योंकि भाषण में वाक्यात्मक जटिलता और प्रवचन प्रतिनिधित्व की विशेषताओं पर उनके प्रभाव के कारण। हम संज्ञानात्मक हानि का पता लगाने के लिए दो अलग-अलग डेटासेट में सामान्यीकृत होने की प्रवृत्ति दिखाते हैं। एक निष्कर्ष के रूप में, हम मनोभ्रंश का पता लगाने के प्रदर्शन में सुधार करने के लिए विलोपन त्रुटियों के लिए एक उच्च दंड को प्रतिबिंबित करने के लिए एएसआर को अनुकूलित करने का प्रस्ताव करते हैं।', 'ru': 'Автоматическое распознавание речи (ASR) является критическим компонентом любой полностью автоматизированной модели обнаружения деменции на основе речи. Однако, несмотря на годы исследований распознавания речи, мало что известно о влиянии точности ASR на обнаружение деменции. В данной работе мы экспериментируем с контролируемыми количествами искусственно сгенерированных ошибок ASR и исследуем их влияние на обнаружение деменции. Мы обнаружили, что ошибки удаления больше всего влияют на производительность обнаружения, благодаря их влиянию на особенности синтаксической сложности и представления дискурса в речи. Мы демонстрируем тенденцию к обобщению двух различных наборов данных для обнаружения когнитивных нарушений. В заключение, мы предлагаем оптимизировать ASR, чтобы отразить более высокий штраф за ошибки удаления, чтобы улучшить эффективность обнаружения деменции.', 'ga': "Tá Aithint Urlabhra Uathoibríoch (ASR) ina chomhpháirt ríthábhachtach d’aon mhúnla braite néaltraithe urlabhra-bhunaithe atá go hiomlán uathoibrithe. Mar sin féin, in ainneoin blianta de thaighde aitheanta cainte, is beag atá ar eolas faoin tionchar atá ag cruinneas ASR ar bhrath néaltrú. Sa pháipéar seo, déanaimid tástáil le méideanna rialaithe d'earráidí ASR a ghintear go saorga agus déanaimid imscrúdú ar a dtionchar ar bhrath néaltrú. Faighimid amach gurb iad na hearráidí scriosta is mó a théann i bhfeidhm ar fheidhmíocht braite, mar gheall ar a dtionchar ar ghnéithe na castachta comhréire agus léiriú dioscúrsa sa chaint. Léirímid an treocht a bheith inghinearálta thar dhá thacar sonraí éagsúla chun lagú cognaíocha a bhrath. Mar chonclúid, molaimid an ASR a bharrfheabhsú chun pionós níos airde a léiriú maidir le hearráidí scriosta chun feidhmíocht braite néaltraithe a fheabhsú.", 'ka': 'ავტომატიკური სიტყვას განახლება (ASR) არის კრიტიკური კომპონენტია ყველა ავტომატიკური სიტყვას განახლების მოდელეში. მაგრამ, რადგან წლის განვიცნობის პასუხის შემდეგ, მარტივია იცია ASR წარმოდგენების შესახებ დემონტიის განვიცნობაზე. ამ დომენტში, ჩვენ ექსპერიმენტიურად კონტროლური რაოდენობით ASR შეცდომის შეცდომებით გავკეთებთ მათი მოვლენა დემონტიაზე. ჩვენ აღმოჩნეთ, რომ წაშლა შეცდომები უფრო მეტი შეცდომების გამოსახულება განახულება, რადგან ისინი შეცდომები სინტაქტიული კომპლექტიკის შესახებისთვი ჩვენ ჩვენ გამოჩვენებთ ტენდენტი, რომელიც ორი განსხვავებული მონაცემების განახლებისთვის გენერალურად იყოს. როგორც გადასრულება, ჩვენ მინდა აპტიმიზაცია ASR-ს, რომ გადაწყვეტა უფრო მეტი ნაცემის შეცდომის წაშლად, რომ უფრო მეტიური განახლება დემონტია.', 'hu': 'Az automatikus beszédfelismerés (ASR) minden teljesen automatizált beszédalapú demencia felismerési modell kritikus eleme. Azonban a beszédfelismerő kutatások ellenére keveset tudunk az ASR pontosságának a demencia felismerésére gyakorolt hatásáról. Ebben a tanulmányban a mesterségesen generált ASR hibák ellenőrzött mennyiségével kísérletezünk, és vizsgáljuk a demencia felismerésére gyakorolt hatásukat. Úgy találjuk, hogy a törlési hibák a legjobban befolyásolják az észlelési teljesítményt, mivel hatásuk van a szintaktikus összetettségre és a beszéd diskurzus reprezentációjára. A kognitív károsodások felismerésére szolgáló két különböző adatkészleten keresztül általánosítható tendenciát mutatjuk. Következtetésképpen javasoljuk az ASR optimalizálását, hogy tükrözze a törlési hibák magasabb büntetését annak érdekében, hogy javítsa a demencia észlelési teljesítményét.', 'el': 'Η αυτόματη αναγνώριση ομιλίας (ASR) είναι ένα κρίσιμο στοιχείο κάθε πλήρως αυτοματοποιημένου μοντέλου ανίχνευσης άνοιας βασισμένης στην ομιλία. Ωστόσο, παρά τα χρόνια έρευνας αναγνώρισης ομιλίας, ελάχιστα είναι γνωστά για τον αντίκτυπο της ακρίβειας στην ανίχνευση άνοιας. Στην παρούσα εργασία, πειραματιζόμαστε με ελεγχόμενες ποσότητες τεχνητά παραγόμενων σφαλμάτων και διερευνούμε την επιρροή τους στην ανίχνευση άνοιας. Διαπιστώνουμε ότι τα σφάλματα διαγραφής επηρεάζουν περισσότερο την απόδοση ανίχνευσης, λόγω της επίδρασής τους στα χαρακτηριστικά της συντακτικής πολυπλοκότητας και της αναπαράστασης λόγου στην ομιλία. Δείχνουμε ότι η τάση είναι γενικευμένη σε δύο διαφορετικά σύνολα δεδομένων για την ανίχνευση γνωστικών διαταραχών. Συμπερασματικά, προτείνουμε τη βελτιστοποίηση της ΑΣR ώστε να αντικατοπτρίζει υψηλότερη ποινή για σφάλματα διαγραφής, προκειμένου να βελτιωθεί η απόδοση ανίχνευσης άνοιας.', 'it': "Il riconoscimento vocale automatico (ASR) è una componente critica di qualsiasi modello di rilevamento della demenza basato sul parlato completamente automatizzato. Tuttavia, nonostante anni di ricerca sul riconoscimento vocale, poco si sa circa l'impatto dell'accuratezza ASR sul rilevamento della demenza. In questo articolo, sperimentiamo quantità controllate di errori ASR generati artificialmente e analizziamo la loro influenza sul rilevamento della demenza. Troviamo che gli errori di eliminazione influiscono maggiormente sulle prestazioni di rilevamento, a causa del loro impatto sulle caratteristiche della complessità sintattica e della rappresentazione del discorso nel discorso. Mostriamo la tendenza ad essere generalizzabile su due diversi set di dati per la rilevazione di compromissione cognitiva. In conclusione, proponiamo di ottimizzare l'ASR per riflettere una sanzione più elevata per gli errori di cancellazione al fine di migliorare le prestazioni di rilevamento della demenza.", 'kk': 'Автоматты сөзді анықтау (ASR) кез келген сөзді автоматты түрде негізделген деменцияны анықтау үлгісінің критикалық компоненті. Бірақ жылдары сұрақтарды анықтау зерттеулеріне қарамастан, ASR деменцияны анықтау үшін дұрыстығын білмейді. Бұл қағазда, біз өзгертілген ASR қателерін бақылау мөлшерлеріне тәжірибедік және олардың деменцияны анықтау үшін әсерін зерттеп көрдік. Біз өшіру қатесі синтактикалық комплекс және сөйлейтін дискурстардың таңдауына әсер етеді деп ойлаймыз. Екі әртүрлі деректер бағдарламасының жалпы түрде тенденциялық болуын көрсету үшін. Аяқтау үшін, біз ASR-ді оптимизациялау үшін қателерді өшіру үшін жетілдіру үшін қателерді жақсарту үшін жоғары тәртібін көрсетуге болады.', 'lt': 'Automatinis kalbos atpažinimas (ASR) yra bet kurio visiškai automatizuoto kalba pagrįsto demencijos nustatymo modelio kritinis komponentas. Tačiau nepaisant metų kalbos pripažinimo tyrimų, mažai žinoma apie ASR tikslumo poveikį demencijos nustatymui. Šiame dokumente eksperimentuojame su kontroliuojamais dirbtinai sukeltų ASR klaidų kiekiais ir tiriame jų įtaką demencijos nustatymui. Mes manome, kad išbraukimo klaidos labiausiai paveikia aptikimo veiksmingumą, nes jos daro poveikį sintaksinio sudėtingumo ir diskursinio atstovavimo kalboje savybėms. Mes parodome tendenciją, kad ji yra plačiai paplitusi dviejuose skirtinguose kognityvinio sutrikimo nustatymo duomenų rinkiniuose. Baigdami, siūlome optimizuoti ASR, kad būtų atspindėta didesnė bauda už pašalinimo klaidas, siekiant pagerinti demencijos nustatymo veiksmingumą.', 'mk': 'Автоматско препознавање на говорот (ASR) е критичен компонент на секој целосно автоматски модел за детекција на деменција базиран на говор. Сепак, и покрај годините на истражување за препознавање на говорот, малку е познато за влијанието на прецизноста на АСР на детекцијата на деменција. Во овој весник експериментираме со контролирани количини на вештачки генерирани грешки на АСР и го истражуваме нивното влијание на детекцијата на деменција. Најмногу влијаат на резултатите на детекцијата поради нивното влијание врз карактеристиките на синтактичката комплексност и дискурсната претстава на говорот. Го покажуваме трендот да биде генерализиран во две различни податоци за детекција на когнитивно оштетување. Како заклучок, предложуваме оптимизација на АСР за да одрази повисока казна за грешки во избришувањето со цел подобрување на резултатите на детекцијата на деменција.', 'ml': 'സ്വയം സംസാരം തിരിച്ചറിയുക (ASR) പൂര്\u200dണ്ണമായി സംസാരിക്കുന്ന വാക്കുകള്\u200d സ്വയമായി അടിസ്ഥാനമാക്കുന്ന ഡെമെന്റി കണ്ട എന്നാലും വര്\u200dഷങ്ങള്\u200d സംസാരിക്കുന്നതിന് തിരിച്ചറിയാനുള്ള പരിശോധനത്തിന് ശേഷം, അസ്ആര്\u200d തെളിവുകളുടെ പ്രഭാവം ക In this paper, we experiment with controlled amounts of artificially generated ASR errors and investigate their influence on dementia detection.  നീക്കം ചെയ്യുന്നതില്\u200d തെറ്റുകള്\u200d കണ്ടെത്തുന്നതില്\u200d ഏറ്റവും പ്രധാനപ്പെടുത്തുന്നതാണെന്ന് നമുക്ക് തോന്നുന്നു. സംസാരിക് രണ്ടു വ്യത്യസ്ത ഡാറ്റാസറ്റുകളില്\u200d സാധാരണമാക്കാനുള്ള പ്രകൃതി നമ്മള്\u200d കാണിക്കുന്നു. As a conclusion, we propose optimising the ASR to reflect a higher penalty for deletion errors in order to improve dementia detection performance.', 'mn': 'Автоматтын ярианы танилцуулалт (ASR) нь бүрэн автоматтын ярианы үндсэн хэлбэрийн загварын чухал хэсэг юм. Гэхдээ илтгэлийн хүлээн зөвшөөрөл судалгааны үр дүнд АСР-ын зөвшөөрөл байдлын нөлөө нь бага байдаг. Энэ цаасан дээр бид уран бүтээгдэхүүний хэмжээнд АСР алдаа гаргасан туршилт хийж, тэдний нөлөөлөлийг сэтгэл хөдлөлд олж мэдэхэд судалж байна. Бид устгах алдаа нь хамгийн олон ажиллагааны үр дүнд нөлөөлдөг гэдгийг олж мэднэ. Синтактикийн төвөгтэй байдал болон ярианы үзүүлэлт дээр нөлөөлдөг. Бид хоёр өөр өгөгдлийн сангуудыг мэдэхэд ерөнхийлөгч болох тенденцийг харуулж байна. Эцэст нь, бид АСР-г хамгийн өндөр шалтгааныг устгах алдаа гаргахын тулд сэтгэл хөдлөл ойлгохын тулд илүү өндөр шалтгааныг үзүүлэхийг санал болно.', 'mt': 'Ir-Rikonoxximent Awtomatiku tal-Kellem (ASR) huwa komponent kritiku ta’ kwalunkwe mudell ta’ detezzjoni tad-dimenzja bbażata fuq id-diskors kompletament awtomatizzat. Madankollu, minkejja snin ta’ riċerka dwar ir-rikonoxximent tad-diskors, ftit huwa magħruf dwar l-impatt tal-preċiżjoni tal-ASR fuq id-detezzjoni tad-dimenzja. F’dan id-dokument, aħna qed nagħmlu esperimenti b’ammonti kkontrollati ta’ żbalji tal-ASR iġġenerati artifiċjalment u ninvestigaw l-influwenza tagħhom fuq id-detezzjoni tad-dimenzja. Aħna nsibu li l-iżbalji tat-tħassir jaffettwaw l-aktar il-prestazzjoni tal-individwazzjoni, minħabba l-impatt tagħhom fuq il-karatteristiċi tal-kumplessità sintattika u r-rappreżentazzjoni diskors fid-diskors. Aħna nuru x-xejra li tkun ġeneralizzabbli f’żewġ settijiet differenti ta’ dejta għall-individwazzjoni ta’ indeboliment konjittiv. Bħala konklużjoni, nipproponu l-ottimizzazzjoni tal-ASR biex tirrifletti penali ogħla għal żbalji ta’ tħassir sabiex tittejjeb il-prestazzjoni ta’ detezzjoni tad-dimenzja.', 'ms': 'Pengenalan Ucapan Automatik (ASR) adalah komponen kritik bagi mana-mana model pengesan demensi berasaskan-Ucapan secara automatik sepenuhnya. However, despite years of speech recognition research, little is known about the impact of ASR accuracy on dementia detection.  Dalam kertas ini, kami eksperimen dengan jumlah kawal ralat ASR yang dijana secara buatan dan menyelidiki pengaruh mereka pada pengesan demensi. Kami mendapati ralat pemadaman mempengaruhi prestasi pengesan yang paling, disebabkan kesan mereka pada ciri-ciri kompleksiti sintaktik dan perwakilan diskors dalam ucapan. Kita tunjukkan perkembangan yang boleh diseluruhkan dalam dua set data yang berbeza untuk pengesan cacat kognitif. Sebagai kesimpulan, kami cadangkan optimisasi ASR untuk mencerminkan hukuman yang lebih tinggi atas ralat pemadaman untuk meningkatkan prestasi pengesan demensi.', 'no': 'Automatisk tale- gjenkjenning (ASR) er ein kritisk komponent av alle fullstendige talebaserte dementiske oppdagingsmodeller. I tillegg til årar med tale gjenkjenning, er det kjent litt om effekten av ASR-nøyaktighet på dementiske oppdaging. I denne papiret eksperimenterer vi med kontrollerte mengdar av kunstiske genererte ASR-feil og undersøker sine påvirkning på dementia-oppdaging. Vi finn at slettingsfeil påvirkar det meste oppdaginga av oppdaginga på grunn av sine effekt på funksjonane av syntaksiske kompleksitet og diskurs- representasjon i tale. Vi viser trenden som kan vera generelt over to ulike datasett for oppdaging av kognitiv utrykking. Som ein konklusjon, foreslår vi å optimalisera ASR for å refleksera ein høgare straum for sletting av feil for å forbetra oppdaginga av dementia.', 'ro': 'Recunoașterea automată a vorbirii (ASR) este o componentă critică a oricărui model complet automatizat de detectare a demenței bazat pe vorbire. Cu toate acestea, în ciuda anilor de cercetare privind recunoașterea vorbirii, se știe puține despre impactul preciziei ASR asupra detectării demenței. În această lucrare, experimentăm cantități controlate de erori ASR generate artificial și investigăm influența acestora asupra detectării demenței. Considerăm că erorile de ștergere afectează cel mai mult performanța detectării, datorită impactului lor asupra caracteristicilor complexității sintactice și reprezentării discursului în vorbire. Aratăm tendința de a fi generalizabilă în două seturi de date diferite pentru detectarea deficiențelor cognitive. În concluzie, propunem optimizarea ASR pentru a reflecta o penalizare mai mare pentru erorile de ștergere, pentru a îmbunătăți performanța detectării demenței.', 'pl': 'Automatyczne rozpoznawanie mowy (ASR) jest kluczowym elementem każdego w pełni zautomatyzowanego modelu wykrywania demencji opartego na mowie. Jednak pomimo lat badań nad rozpoznawaniem mowy, niewiele wiadomo o wpływie dokładności ASR na wykrywanie demencji. W artykule eksperymentujemy z kontrolowaną ilością sztucznie generowanych błędów ASR i badamy ich wpływ na wykrywanie demencji. Stwierdzono, że błędy usuwania najbardziej wpływają na wydajność wykrywania, ze względu na ich wpływ na cechy złożoności składni i reprezentacji dyskursu w mowie. Pokazujemy, że trend jest uogólniony w dwóch różnych zbiorach danych do wykrywania zaburzeń poznawczych. Podsumowując, proponujemy optymalizację ASR, aby odzwierciedlić wyższą karę za błędy usuwania w celu poprawy wyników wykrywania demencji.', 'sv': 'Automatisk taligenkänning (ASR) är en viktig komponent i alla helautomatiska talbaserade demensdetekteringsmodeller. Trots åratal av taligenkänningsforskning är det dock lite känt om ASR-noggrannhetens inverkan på demensdetektion. I denna uppsats experimenterar vi med kontrollerade mängder artificiellt genererade ASR-fel och undersöker deras påverkan på demensdetektion. Vi finner att raderingsfel påverkar detekteringsprestanda mest, på grund av deras inverkan på funktionerna i syntaktisk komplexitet och diskursrepresentation i tal. Vi visar tendensen att vara generell över två olika datauppsättningar för detektering av kognitiv funktionsnedsättning. Som en slutsats föreslår vi att ASR optimeras för att återspegla ett högre straff för raderingsfel för att förbättra demensdetekteringen.', 'so': "Aqoonsashada hadalka iskaa maamulka ah (ASR) waa qayb muhiim ah oo ka mid ah noocyada aqoonsiga dementiga oo dhan. Si kastaba ha ahaatee, in kastoo ay tahay sanado aqoonsashada hadalka, wax yar waxaa la ogaanayaa saameynta saxda ASR ee ku saabsan baaritaanka dhimirka. In this paper, we experiment with controlled amounts of artificially generated ASR errors and investigate their influence on dementia detection.  Waxaynu aragnaa in qaladyada la maro ay saameyn ku leedahay sameynta aqoonta ugu badnaanta, sababtoo ah saamaynta ay saameyn ku leedahay faa'iidada qallafsanaanta iyo hadalka ku saabsan hadalka. Waxaynu muujinnaa dabiicadda oo la soo caadi karo laba kooban oo macluumaad oo kala duduwan si loo ogaado xaqiijinta. Ugu dambaysta, waxaynu soo jeedaynaa in ASR la rajaynayo inuu ka fiiriyo ciqaab dheer oo la xiriiro qaladka la baabbi'iyo si loo hagaajiyo sameynta dhamaadka xilliga.", 'ta': 'தானியங்கி பேச்சு குறிப்பு ஆயினும், ஆண்டுகளின் பேச்சு அடையாளம் ஆராய்ச்சியின் விளைவுகள் பற்றி சிறிது அறியப்பட்டுள்ளது எஸ்ஆர் தெளிவான இந்த காகிதத்தில், நாம் கட்டுப்படுத்தப்பட்ட கூட்டத்திற்கு சோதனைப்படுத்தி ASR பிழைகளை உருவாக்கினோம் மற்றும் காலம் கண்டுப நீக்குவதில் பிழைகள் கண்டறிதல் செயல்பாட்டின் மிக பாதிக்கும் என்பதை நாம் கண்டுபிடிப்பது, பேச்சில் பிரதியான சிக்கல் மற்றும நாம் இரண்டு வேறு வித்தியாசமான தகவல் அமைப்புகளுக்கு பொதுவாக இருக்கும் நடைமுறையை காட்டுகிறோம். ஒரு முடிவாக, நாம் ASR ஆசிரியரை நம்புகிறோம் என்று பரிந்துரைக்கிறோம் நீக்கப்பட்ட பிழைகளுக்கு அதிக வேதனையை பிரித்துக', 'ur': 'آٹوٹی بات پتچانی (ASR) ہر پورے طور پر آٹوٹی بات بنیاد رکھی دیمنٹی ڈیٹینسی موڈل کے منقطع ہیں. لیکن کلمات کی پہچان کی تحقیقات کے برسوں کے باوجود، ASR کی دقیق اثبات کے بارے میں بہت کم معلوم ہے. اس کاغذ میں ہم نے آس آر کی خطائیں پیدا کیں اور ان کی تاثیر ڈمنٹی شناسیٹ پر تحقیق کی۔ ہمیں معلوم ہے کہ ہٹانے کی خطاؤں کی جگہ سے زیادہ اثر پہنچا دینے کی کوشش کرتی ہے، ان کے سامنے سینٹکتیک پیچیدگی اور سخنرانی کی تصویر کے سبب۔ ہم دیکھتے ہیں کہ دو مختلف ڈاٹ سٹ میں جرائل قابل ہونے والی ترینڈ دکھاتے ہیں ہم نے ASR کو اچھا ترجیح دینے کی پیشنهاد کرتا ہے کہ اس طرح خطاؤں کی پاک کرنے کے لئے اچھا عذاب دکھائے۔', 'sr': 'Automatska prepoznavanje govora (ASR) je kritična komponenta svakog model a otkrivanja demencije na potpuno automatiziranom govoru. Međutim, uprkos godinama istraživanja priznanja govora, malo se zna o utjecaju tačnosti ASR-a na detekciju demencije. U ovom papiru eksperimentiramo sa kontroliranim količinama umjetnički proizvedenih grešaka ASR-a i istražujemo njihov uticaj na detekciju demencije. Pronašli smo da greške izbrisanja najviše utiču na učinku otkrivanja, zbog njihovog utjecaja na karakteristike sintaktičke kompleksnosti i predstavljanje govora. Pokazujemo trend da je generalizovan u dva različita seta podataka za otkrivanje kognitivnih oštećenja. Kao zaključak, predlažemo optimizaciju ASR da odraži veću kaznu za greške izbrisanja kako bi poboljšali provedbu detektiva demencije.', 'si': 'ස්වයංක්\u200dරිය භාෂාව පුළුවන්න (ASR) ස්වයංක්\u200dරියාත්මක විශේෂ අංක්\u200dරියාවක් තමයි සුපූර්ණයෙන්  නමුත් අවුරුද්දු කතාව පැහැදිලි පරීක්ෂණය ගැන, පොඩ්ඩක් දන්නවා ASR හරියට පරීක්ෂණය ගැන. මේ පත්තරේ අපි පරීක්ෂණය කරන්නේ පාලනය කරන්න පුළුවන් විශේෂයෙන් ASR වැරදිලි නිර්මාණය කරලා පරීක්ෂණය කරලා එයාලගේ ප අපිට හොයාගන්න පුළුවන් වැරැද්දක් හොයාගන්න පුළුවන් වැරැද්දක්, ඔවුන්ගේ පරීක්ෂණය සහ කතාවේ සංකේතික සංකේ අපිට පෙන්වන්න පුළුවන් වෙනස් දත්ත සෙට් දෙකක් වෙනුවෙන් සාමාන්\u200dය වෙන්න පුළුවන් කියලා. අවස්ථාවක් විදිහට, අපි ASR විශ්වාස කරන්න පුළුවන් වෙන්නේ වැරදිලි මරන්න වැරදිලි විදිහට වඩා වඩා විශ්වාස කරන්න.', 'uz': "Name Lekin o'sha yillar o'zlarini tasdiqlashni anglatib, ASR'ning tashkilotlari haqida qisqa o'zgarishni anglatadi. Bu qogʻozda, biz bunday boshqaruvchi bo'lgan sonlarning ko'plab ASR xatolarini yaratdik va biz demensa aniqlashga ishlatilgan effektini aniqlamiz. Biz o'ylaymiz, olib tashlash xatosi o'zgarishni ko'p ishlatishni o'zgartiradi, biz o'zgartirga qo'shishni va suhbatning xususiyatlariga qo'shishga sababi. Biz ikki boshqa maʼlumotlar tarkibida umumiy bo'lishi holatini koʻrsatimiz. Hozirgi, biz ASR'ni ko'paytirishni talab qilamiz, dementiya aniqlash imkoniyatini oshirish uchun olib tashlash xatolarini ko'proq taqdim qilish uchun.", 'vi': 'Nhận dạng Ngôn ngữ Tự động (ASR) là một thành phần quan trọng của bất kỳ mô hình nhận dạng mất trí hoàn toàn tự động. Tuy nhiên, mặc dù nhiều năm nghiên cứu về nhận dạng ngôn ngữ, ít được biết về tác động của độ chính xác ASR lên việc phát hiện mất trí. Trong tờ giấy này, chúng tôi thử nghiệm với lượng được kiểm soát của các lỗi ASR tạo ra nhân tạo và điều tra tác động của chúng lên phát hiện mất trí. Chúng tôi thấy lỗi xóa ảnh hưởng nhiều nhất đến khả năng phát hiện, vì tác động của chúng lên tính chất phức tạp cú pháp và sự đại diện ngôn ngữ. Chúng tôi cho thấy xu hướng phổ biến qua hai bộ dữ liệu khác nhau để phát hiện hư hỏng nhận thức. Để kết luận, chúng tôi đề nghị cải thiện ASR để phản ánh một hình phạt nặng hơn về lỗi xóa để tăng khả năng phát hiện chứng mất trí.', 'bg': 'Автоматичното разпознаване на реч (АСР) е критичен компонент на всеки напълно автоматизиран модел за откриване на деменция, базиран на реч. Въпреки това, въпреки години изследвания за разпознаване на речта, малко се знае за въздействието на точността на АСР върху откриването на деменция. В тази статия експериментираме с контролирани количества изкуствено генерирани грешки и изследваме тяхното влияние върху откриването на деменция. Установяваме, че грешките при изтриване оказват най-голямо влияние върху ефективността на откриването, поради тяхното въздействие върху характеристиките на синтактичната сложност и дискурсното представяне в речта. Показваме тенденцията да се обобщава в два различни набора данни за откриване на когнитивни увреждания. Като заключение предлагаме оптимизиране на АСР, така че да отразява по-висока санкция за грешки при изтриване с цел подобряване на ефективността при откриване на деменция.', 'da': 'Automatisk talegenkendelse (ASR) er en kritisk komponent i enhver fuldautomatisk talebaseret demensdetektionsmodel. På trods af mange års talegenkendelsesforskning, er der dog ikke meget videt om effekten af ASR-nøjagtighed på demensdetektion. I denne artikel eksperimenterer vi med kontrollerede mængder af kunstigt genererede ASR-fejl og undersøger deres indflydelse på demensdetektion. Vi finder ud af, at sletningsfejl påvirker detektionsydeevnen mest på grund af deres indvirkning på funktionerne ved syntaktisk kompleksitet og diskursrepræsentation i tale. Vi viser tendensen til at være generaliseret på tværs af to forskellige datasæt til detektion af kognitiv svækkelse. Som en konklusion foreslår vi, at ASR optimeres for at afspejle en højere straf for sletningsfejl for at forbedre ydeevnen til detektering af demens.', 'nl': 'Automatische spraakherkenning (ASR) is een cruciaal onderdeel van elk volledig geautomatiseerd spraakgebaseerde dementiedetectiemodel. Ondanks jaren van spraakherkenningsonderzoek is echter weinig bekend over de impact van ASR nauwkeurigheid op dementiedetectie. In dit artikel experimenteren we met gecontroleerde hoeveelheden kunstmatig gegenereerde ASR-fouten en onderzoeken we hun invloed op dementiedetectie. We vinden dat verwijderingsfouten de detectieprestaties het meest beïnvloeden, vanwege hun impact op de kenmerken van syntactische complexiteit en discoursrepresentatie in spraak. We laten zien dat de trend veralgemeenbaar is over twee verschillende datasets voor detectie van cognitieve stoornissen. Als conclusie stellen we voor de ASR te optimaliseren om een hogere straf voor deletiefouten te weerspiegelen om de prestaties van dementiedetectie te verbeteren.', 'hr': 'Automatska prepoznavanje govora (ASR) je kritična komponenta svakog model a otkrivanja demencije na potpuno automatskom govoru. Međutim, uprkos godinama istraživanja priznanja govora, malo se zna o utjecaju tačnosti ASR-a na otkrivanje demencije. U ovom papiru eksperimentiramo s kontroliranim količinama umjetnički proizvedenih grešaka ASR-a i istražujemo njihov utjecaj na otkrivanje demencije. Najviše utiču na njihov utjecaj na karakteristike sintaktičke kompleksnosti i predstavljanje govora. Pokazujemo trend da je generaliziran u dva različita dataseta za otkrivanje kognitivnih oštećenja. Kao zaključak, predlažemo optimizaciju ASR-a da odraži veću kaznu za pogreške izbrisanja kako bi poboljšali učinkovitost otkrivanja demencije.', 'de': 'Die automatische Spracherkennung (ASR) ist ein wichtiger Bestandteil jedes vollautomatischen sprachbasierten Demenzerkennungsmodells. Trotz jahrelanger Spracherkennungsforschung ist jedoch wenig über den Einfluss der ASR-Genauigkeit auf die Demenzerkennung bekannt. In diesem Beitrag experimentieren wir mit kontrollierten Mengen künstlich erzeugter ASR-Fehler und untersuchen deren Einfluss auf die Demenzerkennung. Wir stellen fest, dass Löschfehler die Erkennungsleistung am stärksten beeinflussen, da sie sich auf syntaktische Komplexität und Diskursdarstellung in der Sprache auswirken. Wir zeigen, dass der Trend über zwei verschiedene Datensätze zur Erkennung kognitiver Beeinträchtigungen verallgemeinerbar ist. Als Schlussfolgerung schlagen wir vor, den ASR zu optimieren, um eine höhere Strafe für Deletionsfehler widerzuspiegeln, um die Demenzerkennungsleistung zu verbessern.', 'ko': '자동음성인식(ASR)은 음성 기반의 모든 전자동 치매 검출 모델의 관건적인 구성 부분이다.그러나 다년간의 음성인식 연구에도 불구하고 ASR 정확성이 치매 검사에 미치는 영향에 대해 아는 사람은 드물다.본고에서는 인공적으로 발생하는 ASR 오류에 대해 양을 조절하는 실험을 하고 치매 검사에 미치는 영향을 연구했다.우리는 오류를 삭제하는 것이 검측 성능에 가장 큰 영향을 미치는 것을 발견했다. 왜냐하면 음성의 문법 복잡성과 문장 표징에 영향을 미치기 때문이다.우리는 인지적 손해 검측에 있어 두 가지 서로 다른 데이터가 집중적으로 보편적인 추세를 보였다.결론적으로 ASR을 최적화해 삭제 오류에 대한 더 높은 처벌을 반영해 치매 검사 성능을 높일 것을 권장합니다.', 'id': 'Pengenalan Ucapan Otomatis (ASR) adalah komponen kritis dari setiap model deteksi demensi berbasis pidato yang sepenuhnya otomatis. Namun, meskipun bertahun-tahun penelitian pengenalan pidato, sedikit diketahui tentang dampak akurasi ASR pada deteksi demensi. Dalam kertas ini, kami eksperimen dengan jumlah terkendali dari kesalahan ASR yang dibuat secara buatan dan menyelidiki pengaruh mereka pada deteksi demensi. Kami menemukan bahwa kesalahan penghapusan mempengaruhi prestasi deteksi yang paling, karena dampak mereka pada ciri-ciri kompleksitas sintaks dan representation diskors dalam pidato. We show the trend to be generalisable across two different datasets for cognitive impairment detection.  Sebagai kesimpulan, kami mengusulkan optimisasi ASR untuk merefleksikan hukuman yang lebih tinggi atas kesalahan penghapusan untuk meningkatkan prestasi deteksi demensi.', 'fa': 'شناسایی سخنرانی خودکار (ASR) یک بخش مهمترین از هر مدل شناسایی دیمنتیا بر اساس کلمات کامل خودکار است. با این حال، با وجود تحقیقات شناختن سالهای سخنرانی، کمی درباره تاثیر دقیقات ASR بر اثبات دیوانگی شناخته می شود. در این کاغذ، ما با تعداد کنترل کنترل از اشتباه\u200cهای ASR به هنری تولید می\u200cکنیم و تحقیق تاثیر آنها را بر روی شناسایی دیوانگی تحقیق می\u200cکنیم. ما پیدا می\u200cکنیم که اشتباه\u200cهای پاک کردن بیشترین تأثیر عملکرد کشف، به دلیل تاثیر آنها بر ویژه\u200cهای پیچیدگی سنتاکتیک و نمایش صحبت در صحبت تأثیر می\u200cدهند. ما ترند را نشان می دهیم که در دو مجموعه داده ای متفاوت برای شناسایی اضطراری شناخته می شود. به عنوان یک نتیجه، ما پیشنهاد می\u200cدهیم که ASR را بهترین سازی کند تا مجازات بیشتری را برای اشتباهی\u200cهای حذف کند تا عملکرد شناسایی دیوانگی را بهتر کند.', 'sw': 'Tambulisho la kujitegemea la kujieleza (ASR) ni sehemu muhimu ya namna yoyote ya kutambuliwa kwa uchunguzi wa kimapenzi. Hata hivyo, licha ya miaka ya utafiti wa kutambua hotuba, bado unafahamika sana kuhusu athari za uhakika wa ASR kuhusu kutambua kwa ukatili. Katika gazeti hili, tunajaribu kwa kiasi kikubwa cha kudhibitiwa kilichosababisha makosa ya ASR na kuchunguza ushawishi wao juu ya kutambua ugonjwa wa dema. Tunapata kwamba makosa ya kuondolewa yanaathiri utendaji wa kutambua zaidi, kwa sababu ya athari zao juu ya tabia za utata na uwakilishi wa mazungumzo katika hotuba. Tunaonyesha mwenendo wa kuingia katika seti mbili tofauti za taarifa kwa ajili ya kutambua mabadiliko ya ukweli. Kama mwisho, tunapendekeza kutarajia chama hicho cha ASR kutafakari adhabu kubwa zaidi kwa ajili ya makosa ya kufutwa ili kuboresha utendaji wa uchunguzi wa dema.', 'tr': "Otomatik söz tanımasy Ýöne çykyş tanamak synagynyň ýöne, ASR-yň dogrylygynyň tapylygynyň täsiri barada biraz tanalýar. Bu kagyzda, biz sungatly hasaplanýan hasaplanýan hasaplanja bilen synanyşýarys we olaryň täsirini demensiýa tanyşyna barlap synanyşýarys. Ýüklemek hatalarynyň esasy çykyşlygyna täsirleýär. Çünkü olaryň sintaktik çykyşlygyň we çykyşlygyň tanyşlygyna täsirleýärler. Biz çykyşyň kelläp keňlemek üçin iki dürli maglumat setirinde döredilebilir bolmagyny görkeýäris. Sonuçta olarak, ASR'i ýüklemek üçin ýokary gazanlygy ýüklemek üçin ýokary gazanlygy barlamak üçin teklip edýäris.", 'af': "Outomatiese spraak herkenning (ASR) is 'n kritiese komponent van enige volledig- outomatiese spraak- gebaseerde dementie beskrywing model. Maar, alhoewel jaar van spraak herken ondersoek, is klein bekend oor die effek van ASR-presies op dementie-opdekking. In hierdie papier, ons eksperimenteer met kontroleerde hoeveelheid kunstenaar genereer ASR foute en ondersoek hul influens op dementia opdekking. Ons vind dat verwydering foute die meeste invloek van opdekking uitvoer, vanweë hul invloek op die funksies van sintaktiële kompleksiteit en diskursie voorstelling in spreek. Ons wys die trend om generaliseerbare te wees oor twee verskillende datastelle vir kognitiewe beskerming opdekking. As 'n conclusie, voorstel ons die ASR optimaliseer om 'n hoër straf te reflekteer vir verwyder foute om die demensie-opkenning-prestasie te verbeter.", 'sq': 'Zbulimi Automatik i Fjalës (ASR) është një komponent kritik i çdo modeli të zbulimit të demencës të bazuar plotësisht në fjalim. Megjithatë, pavarësisht nga vitet e kërkimit të njohjes së fjalës, pak është e njohur rreth ndikimit të saktësisë së ASR në zbulimin e demencës. Në këtë letër, ne eksperimentojmë me sasi të kontrolluara të gabimeve të gjeneruara artificialisht ASR dhe hetojmë ndikimin e tyre në zbulimin e demencës. Ne zbulojmë se gabimet e fshirjes ndikojnë më së shumti në rezultatet e zbulimit, për shkak të ndikimit të tyre në karakteristikat e kompleksitetit sintaktik dhe përfaqësimit të diskursit në fjalim. Ne tregojmë prirjen për të qenë të gjeneralizuar nëpërmjet dy grupeve të dhënash të ndryshme për zbulimin e dëmtimit kognitiv. Si përfundim, ne propozojmë optimizimin e ASR për të pasqyruar një dënim më të lartë për gabimet e fshirjes me qëllim që të përmirësohet paraqitja e zbulimit të demencës.', 'am': 'አዲስ ዶሴ ፍጠር ነገር ግን ብዙ ዓመታት የንግግር ማስታወቂያ ምርመራ ምንም እንኳ የአASR እርግጠኛ ግንኙነት በdementia ግንኙነት ላይ የሚያውቀው ጥቂት ነው፡፡ In this paper, we experiment with controlled amounts of artificially generated ASR errors and investigate their influence on dementia detection.  ማጥፋት ስህተቶች በንግግር በተቃውሞ እና ንግግር አካባቢነት ላይ ጥቃት በማድረግ አብዛኛውን ማግኘት እንዲያስጨንቁታል፡፡ በሁለቱ ልዩ ዳታዎች ላይ የሚቻለውን ግንኙነት እናሳየዋለን፡፡ በተፈጸመ ጊዜ፣ የASR ማስታወቂያውን ለማሻሻል የሚበልጥ ስህተቶችን ለማጥፋት እናሳስባታለን፡፡', 'hy': 'Ավտոմատիկ խոսքի ճանաչելը (ASR) յուրաքանչյուր լիովին ավտոմատիկ խոսքի հիմնված դեմենցիայի հայտնաբերման մոդելի կարևոր բաղադրիչ է: Այնուամենայնիվ, չնայած խոսքի ճանաչման տարիների հետազոտություններին, շատ քիչ է հայտնի ASR ճշգրտության ազդեցության մասին դեմենցիայի հայտնաբերման վրա: Այս թղթի մեջ մենք փորձում ենք արհեստական ASR սխալների վերահսկվող քանակությամբ և ուսումնասիրում ենք նրանց ազդեցությունը դեմենցիայի հայտնաբերման վրա: Մենք հայտնաբերում ենք, որ ջնջման սխալները ամենամեծ ազդում են հայտնաբերման արդյունքի վրա, քանի որ դրանք ազդում են սինտակտիկ բարդության և խոսակցության ներկայացման առանձնահատկությունների վրա: We show the trend to be generalisable across two different datasets for cognitive impairment detection.  Որպես եզրակացություն, մենք առաջարկում ենք լավագույնացնել ASR-ը, որպեսզի արտացոլվի ավելի բարձր պատիժ ջնջման սխալների համար, որպեսզի բարելավվի դեմենցիայի հայտնաբերման արդյունքը:', 'az': "Avtomatik Söz Tanıması (ASR) hər bir tamamlanmış sözlə-tabanlı demenciya tanıması modelinin kritik komponenti. Yıllarca söz tanıması araştırmalarına baxmayaraq, ASR doğruluğunun dəlilik keşfinin təsiri haqqında az bilər. Bu kağızda, biz insanlı təşkil edilmiş ASR hataları ilə təşkil edirik və onların dəhşətli keşif üzərində təsirlərini incidirik. Siz silinmə xətaları sintaktik kompleksitə və söhbətdə danışmaq təsirlərinin təsirlərinə görə ən çox təsir edirik. İki müxtəlif veri qurğuları keşfetmək üçün genel olaraq göstəririk. Sonuçu olaraq, biz ASR'i daha yüksək cəzalandırmağı təklif edirik ki, dəhşətli keşfetmə performansını yaxşılaşdırmaq üçün daha yüksək cəzalandırmaq üçün xətaları silmək üçün.", 'bn': 'স্বয়ংক্রিয়ভাবে ভাষা স্বীকৃতি স্বীকৃতির (ASR) একটি গুরুত্বপূর্ণ অংশ যে কোনো ভাষণ স্বয়ংক্রিয় ভিত্তিক ভিত্তিক ড তবে কয়েক বছর ধরে বক্তৃতা স্বীকৃতির গবেষণা সত্ত্বেও কিছুটা জানা যায় যে এসআরের সঠিক পরিস্থিতি সনাক্তির উপর প্রভাব সম এই কাগজটিতে আমরা নিয়ন্ত্রণের পরীক্ষার পরীক্ষা করছি কৌশলের পরিমাণে এসআর ভুল তৈরি করেছে এবং ডেমেন্টিয়া সনাক্তির উপর তাদের প্রভাব আমরা দেখতে পাচ্ছি যে মুছে ফেলা ত্রুটি বেশীরভাগ আবিষ্কারের প্রভাব ফেলে, তাদের সাথে সিন্টিক্টিক জটিল এবং কথোপকথনের প্রতিনিধ আমরা দুই বিভিন্ন ডাটাসেটের মধ্যে সাধারণ ভাবে দেখাচ্ছি যেটা ক্ষমতা পাওয়ার জন্য। সমাপ্তি হিসেবে আমরা আসার আশা করি যে তারা মুছে ফেলার জন্য আরো বেশী শাস্তি প্রতিফলিত করতে পারে, যাতে ডিমেন্টিমা আবিষ্কার কর্মকাণ', 'bs': 'Automatska prepoznavanje govora (ASR) je kritična komponenta svakog model a otkrivanja demencije na potpuno automatskom govoru. Međutim, uprkos godinama istraživanja priznanja govora, malo se zna o utjecaju tačnosti ASR-a na otkrivanje demencije. U ovom papiru eksperimentiramo sa kontroliranim količinama umjetnički proizvedenih grešaka ASR-a i istražujemo njihov utjecaj na detekciju demencije. Smatramo da pogreške izbrisanja najviše utječu na učinku otkrivanja, zbog njihovog utjecaja na karakteristike sintaktičke kompleksnosti i predstavljanja govora. Pokazujemo trend da je generalizovan u dva različita seta podataka za otkrivanje kognitivnih oštećenja. Kao zaključak, predlažemo optimizaciju ASR da odraži veću kaznu za greške izbrisanja kako bi poboljšali učinkovitost detektiva demencije.', 'ca': "Automatic Speech Recognition (ASR) is a critical component of any fully-automated speech-based dementia detection model.  Tot i així, malgrat els anys de recerca sobre el reconeixement de la fala, poc se coneix sobre l'impacte de la precisió de l'ASR en la detecció de la demència. En aquest paper, experimentem amb quantitats controlades d'errors artificialment generats d'ASR i investigam la seva influència en la detecció de la demència. Trobem que els errors d'eliminació afecten més el rendiment de la detecció, degut al seu impacte en les característiques de la complexitat sinàctica i la representació del discurs en el discurs. Mostrem la tendència a ser generalitzable a través de dos conjunts de dades diferents per detectar compromís cognitius. Com a conclusió, proposem optimitzar l'ASR per reflexionar una pena més alta per errors d'eliminació per millorar el rendiment de la detecció de demència.", 'cs': 'Automatické rozpoznávání řeči (ASR) je klíčovou součástí každého plně automatizovaného modelu detekce demence založeného na řeči. Nicméně, i přes roky výzkumu rozpoznávání řeči, je málo známo o vlivu přesnosti ASR na detekci demence. V tomto článku experimentujeme s kontrolovaným množstvím uměle generovaných ASR chyb a zkoumáme jejich vliv na detekci demence. Zjišťujeme, že chyby smazání ovlivňují nejvíce detekční výkon, a to kvůli jejich vlivu na rysy syntaktické složitosti a reprezentace diskurzu v řeči. Ukazujeme, že trend je obecný napříč dvěma různými datovými sadami pro detekci kognitivního poruchy. Jako závěr navrhujeme optimalizaci ASR tak, aby odrážela vyšší trest za deleční chyby s cílem zlepšit výkon detekce demence.', 'et': 'Automaatne kõnetuvastus (ASR) on iga täisautomaatse kõnepõhise dementsuse tuvastamise mudeli kriitiline komponent. Hoolimata aastatepikkusest kõnetuvastuse uuringust on ASR täpsuse mõjust dementsuse tuvastamisele vähe teada. Käesolevas töös katsetame kontrollitud hulgas kunstlikult genereeritud ASR vigu ja uurime nende mõju dementsuse tuvastamisele. Leiame, et kustutamisvead mõjutavad tuvastamise jõudlust kõige enam, kuna need mõjutavad süntaktilist keerukust ja diskursuse esindamist kõnes. Näitame trendi olla üldistatav kahe erineva kognitiivse kahjustuse tuvastamiseks. Kokkuvõtteks teeme ettepaneku optimeerida ASR, et kajastada suuremat karistust kustutamisvigade eest, et parandada dementsuse tuvastamise tulemuslikkust.', 'fi': 'Automaattinen puheentunnistus (ASR) on tärkeä osa kaikkia täysin automatisoituja puheentunnistusmalleja. Puheentunnistustutkimuksesta huolimatta ASR-tarkkuuden vaikutuksesta dementian havaitsemiseen tiedetään kuitenkin vähän. Tässä työssä kokeillaan kontrolloituja määriä keinotekoisesti tuotettuja ASR-virheitä ja tutkitaan niiden vaikutusta dementian havaitsemiseen. Havaitsemme, että poistovirheet vaikuttavat eniten havaitsemisen suorituskykyyn, koska ne vaikuttavat puheen syntaktisen monimutkaisuuden ja diskurssin esittämisen ominaisuuksiin. Osoitamme trendin yleistyväksi kahdessa eri tietoaineistossa kognitiivisen häiriön havaitsemiseksi. Päätelmänä ehdotamme ASR:n optimointia siten, että poistovirheistä määrättäisiin korkeampi rangaistus dementian havaitsemisen tehostamiseksi.', 'ha': "Zani'anin magana na farat ɗaya (ATR) yana da wata ƙunci na ƙayyade cikin wani misali da za'a gane da baka-bakan faɗa ɗawa farat ɗaya. A lokacin da, ingawa shẽkaru da aka sanar da fassarar magana, an sani kaɗan game da matsayin haske na AR a kan gane cewa damani. Ga wannan takardan, Munã jarrabi da yawan makorari na da aka halicca ko da kima ko kuma munã karatun musamman su kan ganin damani. Munã ganin cewa ɓallin jẽre sun yi amfani da mafiya canza za'a yi amfani da su, amma sun yi amfani da su kan tayari na masu husũma da mazaɓa cikin magana. Munã nũna hanyar da za'a iya zama mai General a tsakanin danne biyu daban-daban don ya gane cewa tabbacin na ƙaranci. Kayya da ƙarshen, Munã buɗa musamman da shirin ANR ta kange wata azãba mafi girma wa cire ɓarna dõmin ya kyautata sura zaɓen dami.", 'he': 'Automatic Speech Recognition (ASR) is a critical component of any fully-automated speech-based dementia detection model.  However, despite years of speech recognition research, little is known about the impact of ASR accuracy on dementia detection.  In this paper, we experiment with controlled amounts of artificially generated ASR errors and investigate their influence on dementia detection.  We find that deletion errors affect detection performance the most, due to their impact on the features of syntactic complexity and discourse representation in speech.  אנחנו מראים את הטנדרט להיות גנרליזלי בשני קבוצות נתונים שונות לגלות פגיעה קוגניטיבית. בתוצאה, אנו מציעים אופטימציה של ASR כדי לשקף עונש גבוה יותר על שגיאות מחיקה כדי לשפר ביצועי זיהוי דמנציה.', 'sk': 'Samodejno prepoznavanje govora (ASR) je ključna sestavina vsakega popolnoma avtomatiziranega modela zaznavanja demence, ki temelji na govoru. Kljub dolgoletnim raziskavam prepoznavanja govora pa o vplivu natančnosti ASR na odkrivanje demence ni znano malo. V prispevku smo eksperimentirali z nadzorovanimi količinami umetno ustvarjenih ASR napak in raziskali njihov vpliv na odkrivanje demence. Ugotavljamo, da napake pri izbrisu najbolj vplivajo na uspešnost zaznavanja, saj vplivajo na značilnosti sintaktične kompleksnosti in diskurzne reprezentacije v govoru. Prikazujemo trend splošnosti v dveh različnih naborih podatkov za odkrivanje kognitivnih motenj. Za zaključek predlagamo optimizacijo ASR, da bi odražala višjo kazen za napake pri izbrisu, da bi izboljšali učinkovitost odkrivanja demence.', 'jv': 'Spanish Nanging ketahane, mbok saiki banjur layang kanggo nyebatasan sawar, akeh dhéwé kuwi dianggawe barang ASR kuwi kesempatan kanggo ngilangno. Nang pepul iki, kita geprawat karo nganggo hukum sing wis nguasakno karo akeh artiksel gagali ASR karo cahile nggunakake tresnane kanggo ngilanggar deweke Awakdhéwé éntukno nglanggar kelaleng akeh pejalaké nggawe gerakan tapi iki, bakal seneng nggawe barang kelangan karo perbudhakan seneng pisan kelangan karo perusahaan langgar sapa nyimpen Awak dhéwé ngerasakno sing dibutuhke ditambahak iki dadi sampeyan kanggo nguasakno hasil Awakdhéwé, kéné ngerasakno nggawe ASR luwih apik perusahaan sing luwih dumadhi kanggo nggawe barang nggawe gerakan kanggo ngerasakno kanggo ngerasakno operasi awak dhéwé.', 'bo': 'རང་འགུལ་གྱིས་སྐད་ཆ་རྟོགས་ཤེས་ན(ASR)འདི་ཆེན་དུ་རང་འགུལ་གྱིས་ཡོད་པའི་སྐད ཡིན་ནའང་། གཏོང་གི་ལོ་ངོ་རྒྱུས་ལྡན་ཞིབ་བྱེད་པའི་ལྟ་བུའི་རྒྱུ་དངོས་ཀྱང་། ཉེན་རྟོགས་ཤེས་ཀྱི་གསལ་བཤད་དང་ཉེན་རྐྱེ ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་བཟོ་རྩལ་ཆེ་བའི་ཚད་ལྟར་སྟངས་འཛིན་བྱེད་ཀྱི་ཡོད་པ་དང་ We find that deletion errors affect detection performance the most, due to their impact on the features of syntactic complexity and discourse representation in speech. ང་ཚོས་གནས་ཚུལ་གསལ་བཤད་ཀྱི་ལྟ་སྟངས་པར་ཆ་འཕྲིན་ཡིག་ཆ་གཉིས་ནང་དུ་སྤྱིར་བཏང་བ་ཡིན་པས། མཇུག་གི་ཤོག་བྱས་ན། ང་ཚོས་ASR་ལ་ཉེན་ཁ་ཡར་རྒྱས་གཏོང་བྱེད་ན་ཕན་འབྲས་གཞན་ཞིག་ཡིན་པའི་ནོར་འཁྲུལ་བ་རྐྱེན་བཟོ་བཅོས'}
{'en': 'Detecting Entailment in Code-Mixed Hindi-English Conversations H indi- E nglish Conversations', 'fr': "Détection de l'implication dans les conversations Hindi-Anglais mixtes", 'pt': 'Detectando o comprometimento em conversas hindi-inglesas de código misto', 'ar': 'الكشف عن الاستدلال في المحادثات الهندية والإنجليزية المختلطة بالكود', 'es': 'Detección de la implicación en conversaciones hindi-inglés con código mixto', 'ja': 'コード混じりのヒンディー語と英語の会話におけるエンターテインメントの検出', 'zh': '检代码混印地语-英语对话中蕴涵', 'hi': 'कोड-मिश्रित हिंदी-अंग्रेजी वार्तालापों में अनिवार्यता का पता लगाना', 'ru': 'Обнаружение влечения в смешанных с кодом хинди-английских разговорах', 'ga': 'Eispéireas a Bhrath i gComhrá Cód-Measctha Hiondúis-Béarla', 'ka': 'კოდის შემთხვევაში ინდლისური პარამეტრებში', 'el': 'Ανίχνευση διεύρυνσης σε συνομιλίες Χίντι-Αγγλικά με μικτό κώδικα', 'hu': 'A részvétel felismerése a kódkeverett hindi-angol beszélgetésekben', 'it': "Rilevamento dell'entusiasmo nelle conversazioni hindi-inglese miste con codice", 'kk': 'Код араластырылған хинди- ағылшын сұрақтарындағы бүтін анықтау', 'mk': 'Детектирање на проблеми во хинди-англиски разговори со мешани кодови', 'lt': 'Klaidų nustatymas derinant kodus kalbant anglų ir Hindi kalbomis', 'ms': 'Mengesan Kesakitan dalam Perbualan Hindi-Inggeris Bercampur Kod', 'mn': 'Код-холбогдсон Хинди-Англи ярилцлагуудын төгсгөлийг олох', 'ml': 'കോഡ്- മിക്സഡ് ഹിന്ദി- ഇംഗ്ലീഷ് സംസാരിക്കുന്നതില്\u200d വിവരങ്ങള്\u200d കണ്ടുപിടിക്കുന്നു', 'mt': 'Is-Sejbien ta’ Mard fi Konverżjonijiet Mħallta tal-Kodiċi Indjan-Ingliż', 'pl': 'Wykrywanie rozszerzeń w rozmowach mieszanych kodem hindi-angielskim', 'sr': 'Otkrivanje kompleta u razgovorima o indijskom-engleskom miješanom kodu', 'so': 'Aqoonsashada kaarka-isku xiran Hindi-Ingiriis', 'no': 'Finn fullføring i kodeflikte hindiske-engelske samtaler', 'ro': 'Detectarea implicării în conversațiile hindi-engleză combinate cu coduri', 'ta': 'குறியீடு- கலக்கப்பட்ட Hindi- ஆங்கிலம் உரையாடலில் மின்னஞ்சலை கண்டறிதல்', 'ur': 'کوڈ-میکس ہینڈی-انگلیسی کی باتوں میں انٹیل پتہ لیا جا رہا ہے', 'si': 'Code-Missed Hindi-English Conversations', 'sv': 'Identifiera entusiasm i kodblandade hindi-engelska konversationer', 'uz': 'Name', 'vi': 'Phát hiện hệ thống trong đoạn thoại tiếng Hindi', 'bg': 'Откриване на заплитане в кодово смесени хинди-английски разговори', 'hr': 'Otkrivanje kompleta u indijskim razgovorima', 'da': 'Registrering af indblanding i kodeblandede hindi-engelske samtaler', 'nl': 'Ontdekking in code-gemengde Hindi-Engels gesprekken detecteren', 'id': 'Mengeteksi Kesakitan dalam Perbualan Hindi-Inggris Bercampur Kode', 'ko': '코드 혼합 인디언-영어 대화의 함축 검출', 'de': 'Erkennung von Verfeinerungen in Code-Mixed Hindi-Englisch Unterhaltungen', 'fa': 'شناسایی پایان در گفتگوهای هندی-انگلیسی با کد', 'af': 'Ontdekking totaal in kode gemengde Hindi-Engelse gesprekke', 'sw': 'Kugundua Ujumbe katika Mazungumzo ya Kihindi-Kiingereza', 'sq': 'Duke zbuluar probleme në bisedimet e përziera Hindi-Anglisht', 'tr': 'Hindi-Iňlisçe gürrüňlerde tamamlama detected', 'hy': 'Հինդի-անգլերեն խոսակցություններում հիվանդության հայտնաբերումը', 'az': 'Kod-Karışmış Hindi-İngilizce Konuşmalarında Bütün İngilizə Görünüş', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'bn': 'কোড- মিক্সেড হিন্দি- ইংরেজী আলোচনায় ইমেন্ট সনাক্ত করা হচ্ছে', 'bs': 'Otkrivanje kompleta u indijskim razgovorima', 'ca': 'Detectar malalties en converses Hindi-anglesa combinades amb codis', 'cs': 'Detekce vylepšení v komunikacích s kódem smíšených hindsky-anglických', 'et': 'Koodi segatud hindi-inglise vestlustes tuvastamine', 'fi': 'Tunnustus koodisekoitetuissa hindi-englanti keskusteluissa', 'jv': 'Jejaring', 'he': 'מגלה מחלה בשיחות הינדי-אנגלית מעורבות', 'ha': '@ item Text character set', 'sk': 'Zaznavanje razširitve v šifriranih hindijsko-angleških pogovorih', 'bo': 'རྒྱ་ནག་དབྱིན་ཡིག་གི་གཏམ་གླེང་སྒྲུབ་ནང་གི་ཆ་རྐྱེན་རྟོགས་བྱེད་སྟངས'}
{'en': 'The presence of large-scale corpora for Natural Language Inference (NLI) has spurred deep learning research in this area, though much of this research has focused solely on monolingual data. Code-mixing is the intertwined usage of multiple languages, and is commonly seen in informal conversations among  polyglots . Given the rising importance of dialogue agents, it is imperative that they understand  code-mixing , but the scarcity of code-mixed Natural Language Understanding (NLU) datasets has precluded research in this area. The  dataset  by Khanuja et. al. for detecting conversational entailment in code-mixed Hindi-English text is the first of its kind. We investigate the effectiveness of  language modeling ,  data augmentation ,  translation , and architectural approaches to address the code-mixed, conversational, and low-resource aspects of this  dataset . We obtain an 8.09 % increase in test set accuracy over the current state of the art.', 'fr': "La présence de corpus à grande échelle pour l'inférence du langage naturel (NLI) a stimulé la recherche sur le deep learning dans ce domaine, même si une grande partie de ces recherches se sont concentrées uniquement sur les données monolingues. Le mélange de codes est l'utilisation entrelacée de plusieurs langues et est couramment observé dans les conversations informelles entre polyglottes. Compte tenu de l'importance croissante des agents de dialogue, il est impératif qu'ils comprennent le mélange de codes, mais la rareté des ensembles de données de compréhension du langage naturel (NLU) mixtes a empêché la recherche dans ce domaine. L'ensemble de données de Khanuja et al. pour la détection de l'implication conversationnelle dans le texte Hindi-Anglais mixte de code est le premier du genre. Nous étudions l'efficacité de la modélisation linguistique, de l'augmentation des données, de la traduction et des approches architecturales pour traiter les aspects mixtes de code, conversationnels et faibles ressources de ce jeu de données. Nous obtenons une augmentation de 8,09\xa0% de la précision de l'ensemble de tests par rapport à l'état actuel de la technique.", 'ar': 'حفز وجود مجموعات واسعة النطاق لاستدلال اللغة الطبيعية (NLI) على إجراء أبحاث تعليمية عميقة في هذا المجال ، على الرغم من أن الكثير من هذا البحث قد ركز فقط على البيانات أحادية اللغة. خلط الشفرات هو الاستخدام المتشابك للغات متعددة ، وهو شائع في المحادثات غير الرسمية بين متعددي اللغات. نظرًا للأهمية المتزايدة لوكلاء الحوار ، من الضروري أن يفهموا خلط الكود ، لكن ندرة مجموعات بيانات فهم اللغة الطبيعية المختلطة بالشفرات (NLU) حالت دون البحث في هذا المجال. مجموعة البيانات بواسطة Khanuja et. آل. هو الأول من نوعه للكشف عن استلزم محادثة في نص هندي-إنجليزي مختلط بأكواد. نحن نحقق في فعالية النمذجة اللغوية ، وزيادة البيانات ، والترجمة ، والأساليب المعمارية لمعالجة الجوانب المختلطة بالشفرات والمحادثة وقليلة الموارد لمجموعة البيانات هذه. نحصل على زيادة قدرها 8.09٪ في دقة مجموعة الاختبار مقارنة بالحالة الحالية للفن.', 'es': 'La presencia de corpus a gran escala para la Inferencia del Lenguaje Natural (NLI) ha estimulado la investigación del aprendizaje profundo en esta área, aunque gran parte de esta investigación se ha centrado únicamente en los datos monolingües. La mezcla de códigos es el uso entrelazado de varios idiomas, y se ve comúnmente en conversaciones informales entre políglotas. Dada la creciente importancia de los agentes de diálogo, es imperativo que comprendan la mezcla de códigos, pero la escasez de conjuntos de datos de comprensión del lenguaje natural (NLU) mezclados con códigos ha impedido la investigación en esta área. El conjunto de datos de Khanuja et. al. para detectar la implicación conversacional en textos hindi-inglés con código mixto es el primero de su tipo. Investigamos la eficacia del modelado del lenguaje, el aumento de datos, la traducción y los enfoques arquitectónicos para abordar los aspectos de código mixto, conversacional y de escasos recursos de este conjunto de datos. Obtenemos un aumento del 8,09% en la precisión del conjunto de pruebas con respecto al estado actual de la técnica.', 'pt': 'A presença de corpora em larga escala para Inferência de Linguagem Natural (NLI) estimulou a pesquisa de aprendizado profundo nessa área, embora grande parte dessa pesquisa tenha se concentrado apenas em dados monolíngues. A mistura de códigos é o uso entrelaçado de vários idiomas e é comumente visto em conversas informais entre poliglotas. Dada a crescente importância dos agentes de diálogo, é imperativo que eles entendam a mistura de códigos, mas a escassez de conjuntos de dados de compreensão de linguagem natural (NLU) de código misto impediu a pesquisa nessa área. O conjunto de dados de Khanuja et. al. para detectar envolvimento de conversação em texto hindi-inglês misto de código é o primeiro de seu tipo. Investigamos a eficácia da modelagem de linguagem, aumento de dados, tradução e abordagens arquitetônicas para abordar os aspectos de combinação de código, conversação e poucos recursos desse conjunto de dados. Obtemos um aumento de 8,09% na precisão do conjunto de testes em relação ao estado atual da arte.', 'zh': '自然语言推理(NLI)之大语料库有激其深者,虽大较单语数。 代码混为多种语言交,常见于多言者非正对。 鉴言摄之要日增,必解代码混合,然代码混合自然语言解(NLU)数集之稀缺性已排其域矣。 其数集由 Khanuja et. 检代码混印地语 - 英语文本会话义同类产品首也。 臣等究言建模、数增、译、架构之有效性,以决其代码混合、会话、低资源。 比之当今技术水平,吾试置精 8.09%矣。', 'ja': '自然言語推論（ NLI ）のための大規模なコーパスの存在は、この分野の深い学習研究を促進しましたが、この研究の多くは単一言語データのみに焦点を当てています。コードミキシングは、複数の言語の絡み合った使用法であり、ポリグロット間の非公式な会話でよく見られる。対話エージェントの重要性が高まっていることを考えると、コード混合を理解することが不可欠ですが、コード混合自然言語理解（ NLU ）データセットの希少性により、この分野の研究は不可能になっています。Khanujaらによる、コードミックスされたヒンディー語と英語のテキストにおける会話の巻き込みを検出するためのデータセットは、この種のものとしては初めてである。私たちは、このデータセットのコード混合、会話、および低リソースの側面に対処するための言語モデリング、データ拡張、翻訳、およびアーキテクチャアプローチの有効性を調査します。試験器の精度は、現状よりも8.09 ％向上しています。', 'hi': 'प्राकृतिक भाषा अनुमान (एनएलआई) के लिए बड़े पैमाने पर कॉर्पोरेट की उपस्थिति ने इस क्षेत्र में गहरे सीखने के अनुसंधान को प्रेरित किया है, हालांकि इस शोध में से अधिकांश ने पूरी तरह से मोनोलिंगुअल डेटा पर ध्यान केंद्रित किया है। कोड-मिश्रण कई भाषाओं का अंतर्निहित उपयोग है, और आमतौर पर पॉलीग्लोट्स के बीच अनौपचारिक बातचीत में देखा जाता है। संवाद एजेंटों के बढ़ते महत्व को देखते हुए, यह आवश्यक है कि वे कोड-मिश्रण को समझें, लेकिन कोड-मिश्रित प्राकृतिक भाषा समझ (एनएलयू) डेटासेट की कमी ने इस क्षेत्र में अनुसंधान को रोक दिया है। Khanuja et द्वारा डेटासेट। al. कोड-मिश्रित हिंदी-अंग्रेजी पाठ में संवादात्मक अनिवार्यता का पता लगाने के लिए अपनी तरह का पहला है। हम इस डेटासेट के कोड-मिश्रित, संवादी और कम-संसाधन पहलुओं को संबोधित करने के लिए भाषा मॉडलिंग, डेटा वृद्धि, अनुवाद और आर्किटेक्चरल दृष्टिकोण की प्रभावशीलता की जांच करते हैं। हम कला की वर्तमान स्थिति पर परीक्षण सेट सटीकता में 8.09% की वृद्धि प्राप्त करते हैं।', 'ru': 'Наличие крупномасштабных корпусов для вывода естественного языка (NLI) стимулировало глубокие исследования обучения в этой области, хотя большая часть этого исследования была сосредоточена исключительно на одноязычных данных. Смешивание кода - это переплетенное использование нескольких языков, что обычно наблюдается в неформальных разговорах между полиглотами. Учитывая растущее значение агентов диалога, крайне важно, чтобы они понимали смешивание кодов, однако нехватка наборов данных о понимании естественного языка (NLU), смешанного с кодами, препятствует проведению исследований в этой области. Набор данных Khanuja et. al. для обнаружения разговорного влечения в кодово-смешанном хинди-английском тексте является первым в своем роде. Мы исследуем эффективность языкового моделирования, расширения данных, перевода и архитектурных подходов к решению кодо-смешанных, разговорных и малоресурсных аспектов этого набора данных. Мы получаем увеличение точности тестового набора на 8,09% по сравнению с текущим уровнем техники.', 'ga': 'Spreag láithreacht corpora ar mhórscála do Thástáil Teanga Nádúrtha (NLI) taighde domhainfhoghlama sa réimse seo, cé gur ar shonraí aonteangacha amháin a dhírigh go leor den taighde seo. Is éard is códmheascadh ann ná úsáid idirnasctha na dteangacha iolracha, agus is minic a fheictear é i gcomhráite neamhfhoirmiúla i measc polyglot. Mar gheall ar an méadú ar thábhacht gníomhairí comhphlé, tá sé ríthábhachtach go dtuigeann siad códmheascadh, ach chuir ganntanas tacair sonraí cód-mheasctha um Thuiscint Teanga Nádúrtha (NLU) bac ar thaighde sa réimse seo. Tá an tacar sonraí ag Khanuja et. al. chun gabháil chomhrá a bhrath i dtéacs cód-mheasctha Hiondúis-Béarla é an chéad cheann dá leithéid. Déanaimid imscrúdú ar éifeachtúlacht samhaltú teanga, méadú sonraí, aistriúcháin, agus cuir chuige ailtireachta chun aghaidh a thabhairt ar ghnéithe cód-mheasctha, comhráite agus acmhainní ísle den tacar sonraí seo. Faighimid méadú 8.09% ar chruinneas na sraithe tástála thar an úrscothacht faoi láthair.', 'ka': 'დიდი მაგალითი კოპორაციის მისამართლური ენერგიის ინფერენციის (NLI) მისამართლად იყო ძალიან სწავლებელი შესწავლობა ამ ადგილში, მაგრამ ამ შესწავლობას ძალიან მხოლოდ მონოლენგურ მრავალ ენების გამოყენება, რომელიც უბრალოდ ინფორმალური პარამეტრებში ხედავს. დიალოგის ადვნენტების უფრო მნიშვნელობა იმისთვის, რომ ისინი კოდის შემთხვევაში გაუკეთებენ, მაგრამ კოდის შემთხვევაში ნახვა ენერგიის შემთხვევაში (NLU) მონაცემების უფრო მნიშვნელობა ამ არეში გა Khanuja et. al. ის მონაცემების შესაძლებელი კონტაქციო შესაძლებლობად ინდლისური ტექსტის კონტაქციო შესაძლებელი ტექსტის პირველი. ჩვენ განსხვავებთ ენის მოდელეციის ეფექტიურობა, მონაცემების აგგენტაცია, გადაწყვეტილება და არქიტექტიკური მიღებების შესახებ ამ მონაცემების კოდის შემთხვევაში, გადაწყვეტილება და დაბალი ჩვენ მივიღეთ 8,09% სწორედ წარმოდგენის წარმოდგენისთვის წარმოდგენისთვის წარმოდგენისთვის წარმოდგენისთვის.', 'it': "La presenza di corpora su larga scala per l'inferenza del linguaggio naturale (NLI) ha stimolato la ricerca di deep learning in questo settore, anche se gran parte di questa ricerca si è concentrata esclusivamente su dati monolingue. Il code-mixing è l'uso intrecciato di più lingue, ed è comunemente visto nelle conversazioni informali tra poliglotti. Data l'importanza crescente degli agenti di dialogo, è imperativo che capiscano il code-mixing, ma la scarsità di set di dati di comprensione del linguaggio naturale misto (NLU) ha precluso la ricerca in questo settore. Il dataset di Khanuja et. al. per rilevare il coinvolgimento conversazionale nel testo hindi-inglese con codice misto è il primo nel suo genere. Investighiamo l'efficacia della modellazione linguistica, dell'aumento dei dati, della traduzione e degli approcci architettonici per affrontare gli aspetti codificati, conversazionali e a basso contenuto di risorse di questo set di dati. Otteniamo un aumento dell'8,09% della precisione del set di test rispetto allo stato attuale dell'arte.", 'el': 'Η παρουσία μεγάλων σωμάτων για την Συμπέραση Φυσικής Γλώσσας (ΝΛΙ) έχει ωθήσει την έρευνα βαθιάς μάθησης σε αυτόν τον τομέα, αν και μεγάλο μέρος αυτής της έρευνας έχει επικεντρωθεί αποκλειστικά σε μονογλωσσικά δεδομένα. Η ανάμειξη κώδικα είναι η αλληλένδετη χρήση πολλαπλών γλωσσών, και συνήθως παρατηρείται σε ανεπίσημες συζητήσεις μεταξύ πολυγλωσσών. Λαμβάνοντας υπόψη την αυξανόμενη σημασία των παραγόντων διαλόγου, είναι επιτακτική ανάγκη να κατανοήσουν την ανάμειξη κώδικα, αλλά η έλλειψη των συνόλων δεδομένων κατανόησης φυσικής γλώσσας (ΝLU) έχει αποκλείσει την έρευνα σε αυτόν τον τομέα. Το σύνολο δεδομένων του Khanuja et. al. για την ανίχνευση της συζήτησης σε κείμενο μεικτό κώδικα Χίντι-Αγγλικά είναι το πρώτο στο είδος του. Ερευνούμε την αποτελεσματικότητα της γλωσσικής μοντελοποίησης, της αύξησης δεδομένων, της μετάφρασης και των αρχιτεκτονικών προσεγγίσεων για να αντιμετωπίσουμε τις πτυχές αυτού του συνόλου δεδομένων με μικτές κωδικές, συνομιλίες και χαμηλούς πόρους. Λαμβάνουμε 8.09% αύξηση της ακρίβειας του σετ δοκιμής έναντι της τρέχουσας κατάστασης της τεχνολογίας.', 'hu': 'A természetes nyelvi fertőzések (NLI) nagyszabású corpora jelenléte ösztönözte a mélytanulási kutatásokat ezen a területen, bár a kutatás nagy része kizárólag egynyelvű adatokra összpontosított. A kódkeverés több nyelv összefonódása, és gyakran látható a poligloták közötti informális beszélgetésekben. Tekintettel a párbeszédszereplők növekvő jelentőségére, elengedhetetlen, hogy megértsék a kódkeverést, de a kódkeverékes Natural Language Understanding (NLU) adatkészletek hiánya kizárta a kutatást ezen a területen. A Khanuja et. al. által a kódkevert hindi-angol szöveg beszélgetési vonatkozásainak kimutatására szolgáló adathalmaz az első a maga nemében. Vizsgáljuk a nyelvi modellezés, az adatbővítés, a fordítás és az építészeti megközelítések hatékonyságát az adatkészlet kódkevert, beszélgetési és alacsony erőforrással rendelkező aspektusainak kezelésére. 8,09%-kal növeljük a tesztkészlet pontosságát a jelenlegi technika állapotához képest.', 'kk': 'Табиғи тілдер инференциясы (NLI) үлкен масштабтағы корпора барлығы осы аумақтағы ділкен оқыту зерттеулерін түсіндіреді, бірақ бұл зерттеулердің көпшілігі тек монолингілік дерект Кодты араластыру - бірнеше тілдерді қолдану және көпшілікті көпшілікті көпшілікті айтылуда көрсетіледі. Диалог агенттерінің көтерілген маңыздылығын көрсеткенде, олар код араластыруын түсініп, бірақ код араластырылған Түзіндік тілдерді түсініктіру (NLU) деректер жиындарының қажеттігі осы аумағында зерттеулерді ше Ханужа т. л. деген деректер жинағы, код араластырылған хинди- ағылшын мәтінінің бірінші түрін анықтау үшін. Біз тілдерді моделдеу, деректерді өзгерту, аудару және архитектуралық әрекеттердің көмекшілігін зерттеп, бұл деректер жиынының код арасындағы, қатынау және төмен ресурстардың аспектеріне қатынау үшін Қазіргі суреттің дұрыстығына 8,09% деген сынақтардың дұрыстығын өзгертіп аламыз.', 'lt': 'Didelio masto „Natural Language Inference“ (NLI) korporas šioje srityje paskatino gilaus mokymosi mokslinius tyrimus, nors daugelis šių tyrimų daugiausia buvo skirta tik vienakalbiniams duomenims. Code-mixing is the intertwined usage of multiple languages, and is commonly seen in informal conversations among polyglots.  Atsižvelgiant į didėjančią dialogo agentų svarbą, būtina, kad jie suprastų kodų derinimą, tačiau kodų derinimo su natūralia kalba duomenų rinkinių (NLU) trūkumas šioje srityje trukdė atlikti mokslinius tyrimus. Khanuja et. al. duomenų rinkinys, skirtas aptikti pokalbio įrangą mišriame Hindi- anglų tekste, yra pirmasis tokio pobūdžio. Mes tiriame kalbų modeliavimo, duomenų didinimo, vertimo ir architektūrinių metodų veiksmingumą, kad būtų sprendžiami šio duomenų rinkinio kodų mišrūs, konversijos ir mažai išteklių turintys aspektai. Turime 8,09 proc. didesnį bandymų rinkinio tikslumą, palyginti su dabartine pažanga.', 'mk': 'Присуството на голема корпора за природна инференција на јазик (НЛИ) поттикна длабоко учење истражување во оваа област, иако голем дел од ова истражување се фокусираше само на монојазични податоци. Мешањето на кодовите е меѓусебно употребување на повеќе јазици, и често се гледа во неформалните разговори меѓу полиглотите. Со оглед на растечката важност на агентите на дијалогот, неопходно е тие да го разберат мешањето на кодовите, но недостатокот на податоци за разбирање на природниот јазик (НЛУ) со мешани кодови го спречи истражувањето во оваа област. Податоците од Khanuja et. al. за детектирање на разговорите во ханди- англискиот текст со мешан код се први од ваков вид. Истражуваме ефикасност на јазичното моделирање, зголемување на податоците, превод и архитектурни пристапи за решавање на кодовите мешани, разговарачките и ниски ресурси аспекти на овој податок. Добиваме 8,09 отсто зголемување на точноста на тестовите во однос на сегашната техничка состојба.', 'ms': 'The presence of large-scale corpora for Natural Language Inference (NLI) has spurred deep learning research in this area, though much of this research has focused solely on monolingual data.  Pengcampuran-kod adalah penggunaan berbilang bahasa yang berkaitan, dan biasanya dilihat dalam perbualan informal diantara poliglot. Mengingat kepentingan semakin meningkat ejen dialog, ia adalah penting bahawa mereka memahami campuran kod, tetapi kekurangan set data kod campuran bahasa alam (NLU) telah menghalang kajian di kawasan ini. Set data oleh Khanuja et. al. untuk mengesan penyelesaian perbualan dalam teks kod- campuran Hindi- Inggeris adalah jenis pertama. Kami menyelidiki keefektivitas pemodelan bahasa, peningkatan data, terjemahan, dan pendekatan arkitektur untuk mengatasi aspek kod-campuran, perbualan, dan sumber rendah set data ini. Kami mendapat 8.09% peningkatan dalam ketepatan set ujian atas keadaan semasa.', 'no': 'Den største korpora for naturspråk-inferensen (NLI) har ført til dyp læringsforskning i dette området, men mange av denne forskningen har fokusert berre på monospråk-data. Kodefeksing er den intertwined bruken av fleire språk, og oftast ser i informale samtaler mellom polyglot. Det er nødvendig å forstå mellommengda av koden, men nedanfor av datasettet med kode blandet naturleg språk-forståking (NLU) har avslutta forståking i dette området. Datasettet av Khanuja et. al. for å finna konversjonale innhald i teksten med kodeflikt hindisk- engelsk er den første av typen sin. Vi undersøker effektiviteten til språk- modellering, data- augmentasjon, omsetjing og arkitektur- tilnærmingar for å adressera dei omsetningane med kodefeksa, konvertasjon og låg ressursar. Vi får en økning på 8,09% i testsett nøyaktighet over den gjeldande statusen av kunsten.', 'mn': 'Байгалийн хэлний халдварын том хэмжээний корпора (NLI) байдал нь энэ хэсэгт гүн гүнзгий суралцах судалгааг үүсгэсэн юм. Энэ судалгааны ихэнх нь ганц хэлний мэдээллээр төвлөрсөн. Код холбогдох нь олон хэлний хоорондоо холбогдсон хэрэглээ. Олон хэлний хоорондоо биеийн ярилцлаганд ихэвчлэн харагддаг. Диалог агентуудын ач холбогдолтой тулгарч, кодын холбогдолтыг ойлгох нь шаардлагатай. Гэхдээ кодын холбогдолтой Байгалийн хэл ойлголтын (NLU) өгөгдлийн сангуудын талаар энэ хэсэгт судалгаа шаардлагатай. Ханужа эст.аль. гэсэн өгөгдлийн сангууд нь хоорондоо холбогдсон Хинди-Англи хэлний текстүүдийн хамгийн эхний төрөл юм. Бид хэл загварчлалын үр дүнг, өгөгдлийн нэмэгдүүлэлт, орчуулалт, архитектурын архитектур хэрэгжүүлэлтийг судалж байна. Энэ өгөгдлийн сангийн кодын төвөгтэй, ярилцлага, бага боломжтой асуудлын тухай ярилцдаг. Бид шалгалтын тодорхойлолтын тодорхойлолтын 8.09% нэмэгдсэн байна.', 'mt': "Il-preżenza ta’ korpora fuq skala kbira għall-Inferenza tal-Lingwa Naturali (NLI) xprunat riċerka ta’ tagħlim profond f’dan il-qasam, għalkemm ħafna minn din ir-riċerka ffukat biss fuq dejta monolingwi. It-taħlit tal-kodiċi huwa l-użu intertwined ta’ diversi lingwi, u huwa komuni li jidher fi konverżjonijiet informali fost il-poligloti. Minħabba l-importanza dejjem tikber tal-aġenti tad-djalogu, huwa imperattiv li jifhmu t-taħlit tal-kodiċijiet, iżda l-iskarsezza ta’ settijiet ta’ dejta dwar il-Ftehim tal-Lingwa Naturali mħallat mal-kodiċijiet (NLU) ipprekludiet ir-riċerka f’dan il-qasam. Is-sett tad-dejta minn Khanuja et. al. għall-identifikazzjoni ta’ involviment konversazzjonali fit-test bl-Ingliż-Indjan imħallat bil-kodiċi huwa l-ewwel tat-tip tiegħu. Aħna ninvestigaw l-effettività tal-mudellar tal-lingwi, iż-żieda tad-dejta, it-traduzzjoni u l-approċċi arkitettoniċi biex nindirizzaw l-aspetti mħallta fil-kodiċi, konverżjonali u b’riżorsi baxxi ta’ dan is-sett ta’ dejta. Aħna nkisbu żieda ta' 8.09% fil-preċiżjoni tas-sett tat-testijiet fuq l-aħħar avvanz attwali.", 'ro': 'Prezența corporelor la scară largă pentru Inferența Limbii Naturale (NLI) a stimulat cercetarea de învățare profundă în acest domeniu, deși o mare parte din această cercetare s-a concentrat exclusiv pe date monolingve. Mixarea codurilor este folosirea împletită a mai multor limbi și este frecvent văzută în conversațiile informale dintre poligloți. Având în vedere importanța tot mai mare a agenților de dialog, este imperativ ca aceștia să înțeleagă amestecarea codurilor, însă lipsa seturilor de date de înțelegere a limbajului natural (NLU) combinate cu coduri a exclus cercetarea în acest domeniu. Setul de date realizat de Khanuja et. al. pentru detectarea implicării conversaționale în text hindi-engleză combinat cu coduri este primul de acest fel. Investigăm eficiența modelării limbajului, a măririi datelor, a traducerii și a abordărilor arhitecturale pentru a aborda aspectele combinate de coduri, conversaționale și cu resurse reduse ale acestui set de date. Obținem o creștere de 8,09% a preciziei setului de testare față de starea actuală a tehnologiei.', 'pl': 'Obecność dużej skali korpusów do analizy języka naturalnego (NLI) pobudziła badania głębokiego uczenia się w tej dziedzinie, chociaż większość tych badań skupia się wyłącznie na danych jednojęzycznych. Mieszanie kodu jest powiązane ze sobą używanie wielu języków i jest powszechnie widoczne w nieformalnych rozmowach między wielogłoskami. Biorąc pod uwagę rosnące znaczenie agentów dialogu, konieczne jest, aby zrozumieli mieszanie kodu, ale niedobór zbiorów danych dotyczących rozumienia języka naturalnego (NLU) wykluczył badania w tej dziedzinie. Zestaw danych Khanuja et. al. służący do wykrywania zaangażowania konwersacyjnego w kodowo-angielskim tekście jest pierwszym tego rodzaju. Badamy skuteczność modelowania językowego, powiększania danych, tłumaczenia i podejść architektonicznych w celu uwzględnienia aspektów tego zbioru danych o mieszanych kodach, konwersacyjnych i niskich zasobach. Uzyskujemy 8,09% wzrostu dokładności zestawu testowego w stosunku do aktualnego stanu techniki.', 'so': 'Dib-joogista shirkadaha afka asalka ah (NLI) ayaa sababtay waxbarasho aad u dheer ee halkan, in kastoo waxbarashadan badankood waxay ku focus saartay macluumaadka afka maskaxda ah. Isku xiriirka isku-xirka waa isticmaalka luuqado kala duduwan, oo waxaa inta badan looga jeedaa hadal rasmi ah oo ay ka dhexeeyaan bulshada. Sida darteed waxaa muhiim u ah inay u baahan yihiin inay gartaan kooxda isku xiriirka, laakiin caqabadaha kooxda aqoonta afka dabiicadda ah ee la isku xiriiray waxyaabaha garashada (NLU) ee macluumaadka macluumaadka ee danbiyada ah ayaa ka horeeyey baaritaanka halkan. Taariikhda macluumaadka ee Khanuja et. al. in la ogaado qofka aqoonta la xiriira oo ku qoran qoraalka Hindi-Ingiriis waa mid ugu horeeya noocyadiisa. Waxaynu baaraynaa waxyaabaha ku saabsan sameynta luuqada, kordhinta data, turjumidda, iyo qaababka dhismaha si aan ugu sheekayno kooxda isku xiran, hadalka, iyo qaybaha hoose ee macluumaadkan. Waxaynu kordhisaa boqolkiiba 8.09 oo korodha imtixaanka si saxda ah ee xaaladda farshaxanka la joogo.', 'sr': 'Pristojanje velike korporacije prirodnog jezika (NLI) izazvalo je duboko istraživanje učenja u ovoj oblasti, iako je većina ovog istraživanja usredotočila samo na monojezičke podatke. Mješanje kodova je međusobna upotreba višestrukih jezika, i obično se viða u neformalnim razgovorima među poliglotima. S obzirom na povećanje važnosti agenata dijaloga, neophodno je da razumeju miješanje koda, ali nedostatak podataka u ovom području uključuje nedostatak kompleksa prirodnog razumevanja jezika (NLU). Podaci Khanuja et. al. za otkrivanje razgovornog želja u tekstu s kodom pomiješanim Hindi-engleskim tekstom su prvi od njih. Istražujemo učinkovitost modeliranja jezika, povećanja podataka, prevoda i arhitekturnih pristupa kako bi se riješili aspekti povezanih kodova, konverzacionih i niskih resursa ovog seta podataka. Dobiæemo poveæanje testova taènosti od 8,09%.', 'si': 'ස්වාභාවික භාෂාව සම්පූර්ණය සඳහා ලොකු ස්කේල් කොර්පෝරාව (NLI) තියෙන්නේ මේ ප්\u200dරදේශයේ ගොඩක් ඉගෙනගන්න පරීක්ෂණය සිද් කෝඩ් මික්ස් එක තමයි විශේෂ භාෂාවන්ගේ සම්බන්ධ භාවිතාව, සමහර විශේෂයෙන් පොලිස්ලෝට්ස් වල අ සංවාදය නියෝජිත සංවාදයේ වැඩි වැඩිය අවශ්\u200dය විදිහට, ඒත් ඒවා කෝඩ් මිශ්රණය තේරුම් ගන්න අවශ්\u200dයයි, ඒත් කෝඩ් මිශ්රණයේ ස්වභ Name අපි භාෂාව මොඩිලින් කරන්න, දත්ත විශාලනය, වාර්ථාව, සහ ආර්කිතිකාරිකාරීය අවශ්\u200dයතාවක් පරීක්ෂණය කරනවා මේ දත්ත සැටේ කෝඩ් මි අපි පරීක්ෂණා සැකසුම් විශාලයක් 8.09% විශාලයක් ලැබෙනවා කියලා', 'sv': 'Närvaron av storskaliga corpora för Natural Language Inference (NLI) har sporrat djupinlärningsforskning inom detta område, även om mycket av denna forskning enbart har fokuserat på enspråkiga data. Kodblandning är den sammanflätade användningen av flera språk och ses ofta i informella samtal mellan polygloter. Med tanke på den ökande betydelsen av dialogagenter är det absolut nödvändigt att de förstår kodblandning, men bristen på kodblandade Natural Language Understanding (NLU) datauppsättningar har uteslutit forskning inom detta område. Datauppsättningen från Khanuja et. al. för att upptäcka konversationsintervall i kodblandad hindi-engelsk text är den första i sitt slag. Vi undersöker effektiviteten av språkmodellering, dataökning, översättning och arkitektoniska tillvägagångssätt för att ta itu med kodblandade, konversations- och lågresursaspekter av denna datauppsättning. Vi uppnår en 8,09% ökning av testsetets noggrannhet jämfört med nuvarande state of the art.', 'ur': 'اس منطقه میں بہت سی سیکھنے کی تحقیق کی وجہ سے زیادہ سیکھنے والی کورپورا (NLI) نے اس منطقه میں صرف ایک زبان کی اطلاعات پر تمرکز کیا ہے۔ کڈ میکسنگ بہت سی زبانوں کی مختلف استعمال ہے اور بہت سی زبانوں کے درمیان غیر معمولی باتوں میں دیکھا جاتا ہے. ڈالیلوگ اگنٹوں کے اضافہ کی بڑی اضافہ کی وجہ سے یہ ضرورت ہے کہ وہ کوڈ میکسنگ سمجھ لیں، لیکن کوڈ میکسنگ طبیعی زبان سمجھنے (NLU) ڈاٹ سٹوں کی کمزوری اس منطقه میں تحقیق کو روکا ہے۔ Khanuja et. al. کے ذریعہ سے ڈاٹ سٹ کیے جاتے ہیں کہ کوڈ میکس ہندی-انگلیسی ٹیکسٹ میں رابطہ اختیار کرنے کے لئے اس کی پہلی طرح ہے. ہم زبان موڈلینگ، ڈیٹا اضافہ، ترجمہ اور معماری طریقے کے مطابق تحقیق کرتے ہیں اس ڈیٹ سٹ کی کوڈ میکسٹ، رابطہ کرنے، اور کم منصفات کے منصفات کے لئے۔ ہم نے آزمائش کے ساتھ 8.09 درصد مزید آزمائش سٹ کی دقیقیت کے ذریعہ آئے۔', 'ml': 'സ്വാഭാവ ഭാഷയുടെ അഭിപ്രായത്തിനുള്ള വലിയ ഭാഷയുടെ സ്ഥിതിയില്\u200d നില്\u200dക്കുന്നത് ഈ പ്രദേശത്ത് ആഴത്തില്\u200d പഠിക്കുന്ന പഠനത്തിന്റെ പഠനത്തി കോഡ് മിക്കിങ്ങ് പല ഭാഷകളുടെ ഇന്റര്\u200dട്ടിവെച്ച് ഉപയോഗിക്കുന്നതാണ്. പോലിസ്റ്റര്\u200dമാരുടെ ഇടയില്\u200d അനുയോജ്യമായ സം ഡയലോഗ് ഏജന്\u200dറുകളുടെ പ്രധാനപ്പെട്ടത് കൊണ്ട് അവര്\u200dക്ക് കോഡ് മിക്കിങ്ങ് മനസ്സിലാക്കേണ്ടത് പ്രധാനപ്പെട്ടതാണ്, പക്ഷെ കോഡ് കലര്\u200dത്തിയ സ്വാഭാഷ ബ കോഡ്- mixed Hindi- ഇംഗ്ലീഷ് വാചകം കണ്ടുപിടിക്കുന്നതിനായി ഖാനുജ എറ്റ്. അലിന്റെ ഡാറ്റാസെറ്റ് അതിന്റെ ആദ്യത്തേതാണ്. ഈ ഡാറ്റാസസെറ്റിന്റെ കോഡ് മിഷ്ടപ്പെടുത്തുവാനും, സംസാരിക്കുന്നതും കുറഞ്ഞ വിഭവങ്ങളും വിശദീകരിക്കാനുള്ള ഭാഷ മോഡലിങ്ങിന്റെ പ്രഭാവ നിലവിലുള്ള കലാകാര്യത്തെക്കാള്\u200d പരീക്ഷണത്തില്\u200d 8.09% കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d കൂട', 'ta': 'இயல்பான மொழி புகுத்தகத்திற்கான பெரிய அளவு நிறுவனத்தின் presence (NLI) இந்த புலத்தில் உள்ள ஆழமான கற்றுக்கொள்ள ஆராய்ச்சியை தூண்டியுள்ளது, ஆன குறியீட்டு கலந்து பல மொழிகளின் இடைவெட்ட பயன்பாடு, மற்றும் பொதுவாக பலவிதமான பேச்சில் பார்க்கப்படுகிறது. Given the rising importance of dialogue agents, it is imperative that they understand code-mixing, but the scarcity of code-mixed Natural Language Understanding (NLU) datasets has precluded research in this area.  Name இந்த தரவுத்தளத்தின் குறியீட்டு கலக்கப்பட்ட, பேச்சு மற்றும் குறைந்த மூலத்தின் குறைந்த மொழி மாதிரியாக்கத்தின் விளைவுகளை நாம் ஆராய்ச நாம் தற்போதைய கலைப்பு நிலையில் சரியான சரியான அமைப்பில் 8.09% அதிகரிப்பு கிடைக்கும்.', 'uz': "Natalik tilning (NLI) uchun katta ko'plab kompaniya mavjudligi bu maydondagi juda qiziqarli o'rganish o'rganishni anglatadi, ammo bu ta'limning ko'pchiligi faqat monolingan maʼlumotga foydalanadi. Kodlash usuli bir necha tillar bilan bir xil foydalanuvchi, va oddiy poliglotlar orasidagi haqida ham ko'rinadi. Mualliflar ajratilgan muhimi sabab, uning kodlash muvaffaqiyatini o'rganish kerak, lekin tabiiy tilni o'zgartirish (NLU) maʼlumotlar tarkibini bu yerda o'rganishni oldin. Name We investigate the effectiveness of language modeling, data augmentation, translation, and architectural approaches to address the code-mixed, conversational, and low-resource aspects of this dataset.  Joriy kunlar davomida sinov sohasini aniqlash uchun 8.09% uzadi.", 'vi': 'Sự có mặt của tập đoàn lớn về ngôn ngữ tự nhiên (NLI) đã thúc đẩy nghiên cứu sâu học trong lĩnh vực này, mặc dù phần lớn nghiên cứu này chỉ tập trung vào dữ liệu ngôn ngữ. Mã trộn là cách sử dụng nhiều ngôn ngữ liên kết, và thường được thấy trong các cuộc đối thoại không chính thức giữa các đấu giả. Dựa vào tầm quan trọng của các đặc vụ đối thoại, cần thiết họ hiểu rõ sự pha trộn mật mã, nhưng sự hạn chế của các tập tin ngôn ngữ tự nhiên lẫn dạng mã đã ngăn cản nghiên cứu trong lĩnh vực này. Từ dữ liệu của Khanuja et. al. để phát hiện kết cấu lịch sử trong văn bản tiếng Hindi tổng hợp mã là mẫu đầu tiên của nó. Chúng tôi nghiên cứu tính hiệu quả của việc tạo mẫu ngôn ngữ, gia tăng dữ liệu, dịch, và các phương pháp kiến trúc để xử lý các khía cạnh mã trộn, chuyển tiếp và ít tài nguyên của bộ dữ liệu này. Chúng tôi đạt được một độ chính xác trên bộ bài kiểm tra trên mức hiện đại của nghệ thuật.', 'bg': 'Наличието на мащабни корпуси за естествено езиково заключение (НЛИ) стимулира изследванията за дълбоко учене в тази област, въпреки че голяма част от тези изследвания са фокусирани единствено върху едноезични данни. Смесването на кодове е преплетено използване на множество езици и често се среща в неформални разговори между полиглоти. Предвид нарастващото значение на диалоговите агенти е наложително те да разбират смесването на кодове, но недостигът на смесени с кодове набори от данни за разбиране на естествения език (НЛУ) изключва изследванията в тази област. Наборът от данни от Кхануджа и др. за откриване на разговорна обвързаност в кодово смесен хинди-английски текст е първият по рода си. Проучваме ефективността на езиковото моделиране, увеличаването на данните, превода и архитектурните подходи за справяне с аспектите на този набор от данни, смесени с кодове, разговори и ниски ресурси. Получаваме 8.09% увеличение на точността на тестовите комплекти спрямо текущото състояние на техниката.', 'hr': 'Pristojanje velike korporacije prirodnog jezika (NLI) izazvalo je duboko istraživanje učenja u ovom području, iako je većina tih istraživanja usredotočila samo na monojezičke podatke. Mješanje kodova je međusobna upotreba višestrukih jezika, a obično se viđa u neformalnim razgovorima među poliglotima. S obzirom na povećanje važnosti agenata dijaloga, moraju razumjeti mješanje kodova, ali nedostatak podataka o razumijevanju prirodnog jezika (NLU) u ovom području zabranjuje istraživanje. Podaci Khanuja et. al. za otkrivanje razgovornog zadovoljstva u tekstu s kodom pomiješanim Hindi-engleskim tekstom su prvi od njega. Istražujemo učinkovitost modeliranja jezika, povećanja podataka, prevoda i arhitekturnih pristupa kako bi se riješili aspekti ovog seta podataka koji su mješani kod, razgovorni i niskog resursa. Dobili smo povećanje ispitivanja preciznosti od 8,09% tijekom trenutnog stanja umjetnosti.', 'nl': 'De aanwezigheid van grootschalige corpora voor Natural Language Inference (NLI) heeft deep learning onderzoek op dit gebied gestimuleerd, hoewel veel van dit onderzoek zich uitsluitend op eentalige data heeft gericht. Code-mixing is het verweven gebruik van meerdere talen, en wordt vaak gezien in informele gesprekken tussen polygloten. Gezien het toenemende belang van dialoogagenten is het noodzakelijk dat zij code-mixing begrijpen, maar de schaarste aan code-mixed Natural Language Understanding (NLU) datasets heeft onderzoek op dit gebied uitgesloten. De dataset van Khanuja et.al. voor het detecteren van conversatie implicaties in code-gemengde Hindi-Engelse tekst is de eerste in zijn soort. We onderzoeken de effectiviteit van taalmodellering, data augmentatie, vertaling en architecturale benaderingen om de code-mixed, conversatie en low-resource aspecten van deze dataset aan te pakken. We verkrijgen een 8,09% verhoging van de nauwkeurigheid van de testset ten opzichte van de huidige stand van de techniek.', 'da': 'Tilstedeværelsen af store corpora for Natural Language Inference (NLI) har stimuleret dyb læring forskning på dette område, selvom meget af denne forskning udelukkende har fokuseret på ensprogede data. Kode-blanding er den sammenflettede brug af flere sprog, og ses almindeligt i uformelle samtaler blandt polyglotter. I betragtning af dialogagenternes stigende betydning er det afgørende, at de forstår kode-blanding, men manglen på kode-blandede Natural Language Understanding (NLU) datasæt har udelukket forskning på dette område. Datasættet fra Khanuja et. al. til detektering af konversationsmæssig involvering i kodeblandet hindi-engelsk tekst er det første af sin art. Vi undersøger effektiviteten af sprogmodellering, dataforøgelse, oversættelse og arkitektoniske tilgange til at løse de kodeblandede, samtale og lav ressource aspekter af dette datasæt. Vi opnår en stigning på 8,09% i testsættets nøjagtighed i forhold til den aktuelle state of te art.', 'de': 'Das Vorhandensein von großen Korpora für Natural Language Inference (NLI) hat die Deep-Learning-Forschung in diesem Bereich angeregt, obwohl sich ein Großteil dieser Forschung ausschließlich auf einsprachige Daten konzentriert hat. Code-Mixing ist die verflochtene Verwendung mehrerer Sprachen und wird häufig in informellen Gesprächen unter Polygloten gesehen. Angesichts der zunehmenden Bedeutung von Dialogagenten ist es unerlässlich, dass sie Code-Mixed Natural Language Understanding (NLU) verstehen, aber die Knappheit von Code-Mixed Natural Language Understanding (NLU) Datensätzen verhindert Forschung auf diesem Gebiet. Der Datensatz von Khanuja et. al. zur Erkennung von Konversationseinflüssen in kodemischten Hindi-Englischen Texten ist der erste seiner Art. Wir untersuchen die Effektivität von Sprachmodellierung, Datenerweiterung, Übersetzung und architektonischen Ansätzen, um die code-gemischten, konversativen und ressourcenarmen Aspekte dieses Datensatzes zu adressieren. Wir erzielen eine 8,09% Erhöhung der Prüfsatzgenauigkeit gegenüber dem aktuellen Stand der Technik.', 'fa': 'حضور شرکت زیادی برای تفاوت زبان طبیعی (NLI) تحقیقات یادگیری عمیق در این منطقه را به وجود آورد، اگرچه بسیاری از این تحقیقات تنها روی داده های یک زبان تمرکز کرده است. پیوند کد استفاده از زبان\u200cهای متفاوت است، و معمولا در گفتگوهای غیر معمولی بین polyglots مشاهده می\u200cشود. با توجه به افزایش مهمترین ماموران گفتگو، لازم است که در این منطقه تحقیقات را متوجه کنند. مجموعه داده\u200cها توسط خانوژا و آل. برای شناسایی مشکلات مکالمه در متن هندی-انگلیسی با کد مختلف شده اولین نوع آن است. ما موثرت مدل\u200cسازی زبان، افزایش داده\u200cها، ترجمه\u200cها و طریق\u200cهای معماری را تحقیق می\u200cکنیم تا به عنوان نقطه\u200cهای کد مختلف، گفتگو و منابع کم از این مجموعه داده\u200cها بررسی کنیم. ما به 8.09 درصد افزایش دقیق تست در حالت فعلی هنر می رسیم.', 'id': 'Kehadiran corpora skala besar untuk Inferensi Bahasa Alami (NLI) telah mendorong penelitian belajar dalam di daerah ini, meskipun banyak penelitian ini fokus hanya pada data monobahasa. Pengcampuran kode adalah penggunaan intertwined dari berbagai bahasa, dan biasanya terlihat dalam percakapan informal antara poliglot. Mengingat kekuatan yang meningkat dari agen dialog, penting untuk mereka memahami campuran kode, tetapi kekurangan set data kode campuran bahasa alam (NLU) telah menghalangi penelitian di daerah ini. Set data dari Khanuja et. al. untuk mendeteksi keterlibatan percakapan dalam teks kode-campuran Hindi-Inggris adalah yang pertama dari jenisnya. Kami menyelidiki efektivitas modeling bahasa, peningkatan data, terjemahan, dan pendekatan arsitektur untuk mengatasi aspek kode-campuran, konversasi, dan sumber daya rendah dari set data ini. Kita mendapatkan peningkatan 8,09% pada akurasi set ujian atas keadaan seni saat ini.', 'sw': 'Kukuwepo kwa kampuni kubwa kwa ajili ya Kuzuia Lugha ya asili (NLI) imesababisha utafiti wa kina wa kujifunza katika eneo hili, ingawa utafiti huu umejikita kwenye takwimu za kiutafiti. Ushirikiano wa sheria ni matumizi ya lugha mbalimbali, na mara nyingi huonekana katika mazungumzo yasiyo rasmi miongoni mwa wanaisimu. Kutokana na ongezeko la umuhimu wa wateja wa mazungumzo, ni muhimu kwamba wanaelewa mchanganyiko wa kodi, lakini ukosefu wa seti za taarifa za lugha ya asili zilizochanganyika kwa utafiti katika eneo hili. Taarifa iliyoandaliwa na Khanuja et. al. kwa kutambua mjuzi wa mazungumzo katika ujumbe ulioanganishwa na Kiingereza ni wa kwanza wa aina yake. Tunatachunguza ufanisi wa mifano ya lugha, kuongeza taarifa, tafsiri, na mbinu za ujenzi ili kuzungumzia mfumo wa mijadala, mazungumzo na rasilimali chini ya seti hii. Tunapata kuongezeka kwa asilimia 8.09 kwa mtihani wa kuhakikisha hali ya sasa ya sanaa.', 'ko': '대규모 자연언어 추리 자료 라이브러리(NLI)의 출현은 이 분야의 깊이 있는 학습 연구를 추진했다. 비록 이 연구의 대부분은 단어 데이터에만 주목하지만.코드 혼합은 여러 언어의 교차 사용으로 여러 언어 간의 비공식적인 대화에서 흔히 볼 수 있다.대화 에이전트의 중요성이 날로 커지고 있음을 감안하여 그들은 코드 혼합을 이해해야 하지만 코드 혼합 자연언어 이해(NLU) 데이터 집합의 희소성이 이 분야의 연구를 방해한다.Khanuja 등의 데이터 집합은 코드가 혼합된 인디언 영어 텍스트의 세션 내포를 검출하는 데 사용되는데 이것은 같은 데이터 집합의 첫 번째이다.우리는 언어 모델링, 데이터 확장, 번역과 체계 구조 방법의 유효성을 연구하여 이 데이터 집합의 코드 혼합, 대화와 저자원 방면의 문제를 해결했다.현재의 기술 수준에 비해 우리의 테스트 집합 정밀도는 8.09% 높아졌다.', 'tr': 'Natural Language Inference (NLI) üçin uly ölçekli korporatyň barlygy bu bölgede gaty uly öwrenmek barlygyny açdyrdy. Bu araştyrymyň köpüsi monolingual maglumatlara diňe üns berdi. Ködleme karışmasy birnäçe diller üçin karışmış işlenýär, we köplenç polyglot arasynda resmi gürrüňlerde görünýär. диалог ajamlaryň ýeterli wajyplygyna görä, ol köd karışmasyny düşünmek gerek, ýöne daýal dillerin (NLU) sany karışmasynyň azalygyny bu bölgede arama çykarmady. Khanuja et. el. tarapyndan habarlaşmak üçin Hindi-Iňlisçe metiniň ilkinji görnüşini detek etmek üçin. Biz dil modellendirmeginiň, maglumat baglanmasynyň, terjime we arhitektura golaýlarynyň çykyşlygyny barlaýarys. Biz test edilen dogrylygyny häzirki ýagtylygyň durumynda 8.09% artyp bilýäris.', 'af': "Die voorsiening van groot-skaal korpora vir Natuurlike Taal Inferensie (NLI) het diep ondersoek in hierdie gebied uitgevra, alhoewel baie van hierdie ondersoek slegs op monolinglike data fokuseer het. Kode-gemeng is die intertwined gebruik van veelvuldige tale, en is gewoonlik gesien in onformele gesprekke onder poliglote. Omdat die opstandige belangrikheid van dialoog agente is, is dit nooit dat hulle kode-menger verstaan, maar die skaamte van kode gemengde Natuurlike Taal Verstaan (NLU) datastelle in hierdie area het voorgesluit ondersoek. Die datastel deur Khanuja et. al. vir die beskrywing van gesprekslys in kode gemengde Hindi- Engels teks is die eerste van sy soort. Ons ondersoek die effektiviteit van taal modellering, data augmentasie, vertaling en arkitektuur toegang om die kode gemengde, omskakelike en lae-hulpbron aspekte van hierdie datastel te adres. Ons kry 'n 8.09% verhoog in toets stel presies oor die huidige staat van die kuns.", 'sq': 'Prania e korprave të shkallës së madhe për Inferencën e Gjuhave Natyrore (NLI) ka nxitur kërkimin e mësimit të thellë në këtë fushë, megjithëse shumica e kësaj kërkimi është përqëndruar vetëm në të dhënat monogjuhësore. Përzjerja e kodeve është përdorimi i ndërlidhur i gjuhëve të shumta dhe është parë zakonisht në bisedime jozyrtare midis poliglotëve. Duke pasur parasysh rëndësinë në rritje të agjentëve të dialogut, është e domosdoshme që ata të kuptojnë përzierjen e kodeve, por mungesa e grupeve të dhënash të përziera me kode të gjuhës natyrore (NLU) ka penguar kërkimin në këtë fushë. Grupi i të dhënave nga Khanuja et. al. për zbulimin e përfshirjes bisedimore në tekstin e përzier në kod Hindi-English është i pari i llojit të tij. Ne hetojmë efektshmërinë e modelimit gjuhësor, rritjes së të dhënave, përkthimit dhe metodave arkitekturale për të trajtuar aspektet e përziera me kode, bisedime dhe burime të ulëta të këtij grupi të dhënash. Ne arrijmë një rritje prej 8.09% në saktësinë e testit mbi gjendjen aktuale të teknologjisë.', 'am': 'የአፍሪካዊ ቋንቋ መግለጫ (NLI) ትልቅ ትምህርት የኮርፖርት ግንኙነት በዚህ ክፍል ውስጥ ጥልቅ ትምህርት አስገኘ፤ ምንም እንኳን ይህ ትምህርት ብዙው በሞሎንቋል ቋንቋዎች ዳታዎችን ብቻ በመጠቀም ነው፡፡ Code-mixing is the intertwined usage of multiple languages, and is commonly seen in informal conversations among polyglots.  የዳታዊ ቋንቋ መቀናቀል ግን (NLU) ዳታ ማውቀትን የጎድጓዴ መቀናኘት (NLU) የዳታ ማውቀት ግንኙነት በዚህ ክፍል ላይ ተማርከዋል፡፡ የካኑja እና አል. የንግግር ማወቃዎችን በኮድ-ካንዲ-እንግሊዘኛ ጽሑፍ ለማግኘት የመጀመሪያ ነው፡፡ የቋንቋ ምሳሌ፣ ዳታ ማጨመር፣ ትርጉም እና የመርከቦች ሥርዓት የኮድ-መቀነቀል፣ የንግግር እና የዝናብ ክፍሎች ለመጠቀም እናምርመራለን፡፡ የአሁኑን አርእስት እውቀት በቁጥጥር ላይ 8.09 በመቶ የሚጨመርን አግኝተናል፡፡', 'hy': 'Բնական լեզվի ինֆերանսիայի (ՆԼԻ) մեծ քանակի գոյությունը խթանեց խորը ուսումնասիրությունը այս ոլորտում, չնայած որ այս ուսումնասիրությունների մեծ մասը կենտրոնացել է միայն միալեզվի տվյալների վրա: Կոդի խառնուրդը բազմաթիվ լեզուների փոխկապակցված օգտագործումն է, և սովորաբար նկատվում է պոլիգլոտների միջև տեղեկատվական զրույցներում: Հետևաբար, հաշվի առնելով խոսակցության գործոնների աճող կարևորությունը, անհրաժեշտ է, որ նրանք հասկանան կոդի խառնուրդը, բայց կոդի խառնուրդը բնական լեզուների հասկանալու (ՆԼU) տվյալների բացակայությունը արգելեց այս ոլորտում ուսումնա Khanujah et. al. կոդի խառնված հինդի-անգլերեն տեքստում խոսակցական ներգրավման հայտնաբերելու տվյալների համակարգը առաջինն է: Մենք ուսումնասիրում ենք լեզվի մոդելավորման, տվյալների աճի, թարգմանման և ճարտարապետական մոտեցումների արդյունավետությունը, որպեսզի լուծենք այս տվյալների համակարգի կոդի խառնված, խոսակցության և ցածր ռեսուրսների ասպեկտները: Մենք ստանում ենք 8.9 տոկոսի աճ փորձարկման համակարգի ճշգրտության վերաբերյալ ներկայիս տեխնոլոգիաների վրա:', 'az': 'Təbiətli Dil Inference (NLI) üçün böyük ölçülü korpora varlığı bu bölgedə derin öyrənmə araştırmalarını təşkil etdi, amma bu araştırmaların çoxu yalnız monodil məlumatlarına odaqlandı. Kod karışması çoxlu dillərin müxtəlif istifadəsidir və çoxlu dillərin arasında informal danışmalarda görülür. Dialoog agentların yüksək məqsədilə baxmayaraq, kodu karışmağını anlamaq lazımdır, amma kodu karışmaq üçün təbiətli dil anlama qurğularının (NLU) veri qurğuları bu bölgedə araştırmağı qadağan etmişdir. Khanuja et. al. tərəfindən kodla karışmış Hindi-İngilizə mətnlərinin ilk növünü keşfetmək üçün verilən quruluş. Biz dil modellərinin, məlumatların yükselməsini, tercüməni və arhitekturlıq tərzlərinin çoxluğunu araşdırırıq. Bu veri qutusunun kodu karıştırılmış, söhbətli və düşük ressurs aspektlərini çəkmək üçün. Biz həmin sanatın hökmünün doğruluğu üzərində 8.09% art ırmağını alırıq.', 'bn': 'প্রাকৃতিক ভাষা ইনফারেন্স (এনলি) এর জন্য বিশাল স্কেল কর্পোরার উপস্থিতি এই এলাকায় গভীর শিক্ষা গবেষণা প্রদান করেছে, যদিও এই গবেষণার বেশীর ভাগ কোড মিশ্রণ বেশ কিছু ভাষার ইন্টারনেট ব্যবহার এবং পুলিশ ব্লগারদের মধ্যে আনুষ্ঠানিক কথোপকথনে সাধারণত দেখা যায়। ডায়ালগ এজেন্টের গুরুত্বপূর্ণ কারণে তারা কোড মিশ্রণ বুঝতে পারে, কিন্তু কোড-মিশ্রিত স্বাভাবিক ভাষার বোঝার ক্ষুদ্র (এনএলইউ) ডাটাসেট এই কোড মিশ্রিত হিন্দি-ইংরেজি লেখায় আলোচনাকারী বিজ্ঞানের পরিচয় পাওয়ার জন্য খানুজা এন. আল-এর ডাটাসেট এই ধরনের প্রথম। আমরা এই ডাটাসেটের কোড মিশ্রিত, আলোচনা এবং কম সম্পদের বিষয়গুলোকে আলোচনা করার জন্য ভাষার মডেলিং এর কার্যকলাপ, ডাটা যোগাযোগ, অনুবাদ, এবং স্থাপনার কার আমরা বর্তমান শিল্পের অবস্থায় পরীক্ষার পরীক্ষা বৃদ্ধি পেয়েছি ৮. ০৯% বৃদ্ধি।', 'bs': 'Pristojanje velike korporacije prirodnog jezika (NLI) izazvalo je duboko istraživanje učenja u ovom području, iako je većina tih istraživanja usredotočila samo na monojezičke podatke. Mješanje kodova je međusobna upotreba višestrukih jezika, a obično se viđa u neformalnim razgovorima među poliglotima. S obzirom na povećanje važnosti agenata dijaloga, moraju razumjeti miješanje koda, ali nedostatak podataka o razumijevanju prirodnog jezika (NLU) u ovom području zabranjuje istraživanje. Podaci Khanuja et. al. za otkrivanje razgovornog zadovoljstva u tekstu Hindi-engleskog spojenog koda su prvi od njih. Istražujemo učinkovitost modeliranja jezika, povećanja podataka, prevoda i arhitekturnih pristupa kako bi se riješili aspekti povezanih kodova, konverzacionih i niskih resursa ovog seta podataka. Dobili smo povećanje testova preciznosti od 8,09% u trenutnom stanju umjetnosti.', 'ca': "The presence of large-scale corpora for Natural Language Inference (NLI) has spurred deep learning research in this area, though much of this research has focused solely on monolingual data.  La combinació de codis és l'ús interconnecte de múltiples llengües, i es veu comument en converses informals entre poliglots. Tenint en compte la creixent importància dels agents del diàleg, és imperatiu que entenguin la combinació de codis, però la escassetat de conjunts de dades d'Entensió de Llingua Natural (NLU) combinats amb codis ha excluït la recerca en aquesta àrea. El conjunt de dades de Khanuja et. al. per detectar l'involucració conversacional en text Hindi-anglès combinat amb codis és el primer de seu tipus. Investiguem l'eficacia de la modelació lingüística, l'augment de les dades, la traducció i els enfocaments arquitectònics per abordar els aspectes combinats de codi, conversacionals i de baix recursos d'aquest conjunt de dades. Obtenim un increment del 8,09% en la precisió del conjunt de proves sobre l'estat actual.", 'cs': 'Přítomnost rozsáhlých korpusů pro inferenci přírodního jazyka (NLI) podněcovala výzkum hlubokého učení v této oblasti, i když většina tohoto výzkumu se zaměřila pouze na jednojjazyčná data. Míchání kódu je propletené používání více jazyků a je běžně vidět v neformálních konverzacích mezi polygloty. Vzhledem k rostoucímu významu dialogových agentů je nutné, aby porozuměli míchání kódu, ale nedostatek kódově smíšených datových sad porozumění přírodním jazykům (NLU) vyloučil výzkum v této oblasti. Datová sada Khanuja et. al. pro detekci konverzačního souvislosti v kódově smíšeném hindsky-anglickém textu je první svého druhu. Zkoumáme efektivitu jazykového modelování, rozšíření dat, překladu a architektonických přístupů k řešení kódově smíšených, konverzačních a nízkých zdrojů aspektů tohoto datového souboru. Získáváme 8,09% zvýšení přesnosti testovací sady oproti současnému stavu techniky.', 'fi': 'Luonnollisen kielen inferenssin (NLI) laajamittaiset corporat ovat kannustaneet syväoppimista tällä alalla, vaikka suuri osa tutkimuksesta on keskittynyt yksinomaan yksikieliseen dataan. Koodien sekoitus on useiden kielten kietoutumista, ja se näkyy yleisesti epävirallisissa keskusteluissa monikielisten keskuudessa. Vuoropuhelun tekijöiden kasvavan merkityksen vuoksi on välttämätöntä, että he ymmärtävät koodien sekoitusta, mutta koodisekoitettujen Natural Language Understanding (NLU) -aineistojen niukkuus on estänyt tutkimuksen tällä alalla. Khanuja et. al.:n aineisto keskusteluyhteyden havaitsemiseksi koodisekoitetussa hindi-englanninkielisessä tekstissä on ensimmäinen laatuaan. Tutkimme kielimallinnuksen, datan lisäämisen, kääntämisen ja arkkitehtonisten lähestymistapojen tehokkuutta käsittelemään tämän aineiston koodisekoitettuja, keskustelevia ja vähän resursseja sisältäviä näkökohtia. Testisarjan tarkkuus paranee 8,09% nykytekniikkaan verrattuna.', 'et': 'Laiaulatuslike korpuste olemasolu looduskeele järelduseks (NLI) on innustanud sügavõppe uuringuid selles valdkonnas, kuigi suur osa neist uuringutest on keskendunud ainult ühekeelsetele andmetele. Koodide segamine on mitme keele põimunud kasutamine, mida tavaliselt nähakse mitteametlikes vestlustes polüglotide vahel. Arvestades dialoogiagentide kasvavat tähtsust, on hädavajalik, et nad mõistaksid koodide segamist, kuid koodidega segatud looduskeele mõistmise andmekogumite nappus on välistanud uurimistöö selles valdkonnas. Khanuja jt. andmekogum vestlussuhete tuvastamiseks koodisegatud hindi-inglise tekstis on esimene omalaadne. Uurime keele modelleerimise, andmete suurendamise, tõlkimise ja arhitektuurilise lähenemisviisi efektiivsust, et käsitleda selle andmekogumi koodisegatud, vestluslikke ja vähese ressursiga aspekte. Me saavutame 8,09% suurema katsekomplekti täpsuse võrreldes praeguse tehnika tasemega.', 'ha': "An sami makampuni mai girma wa Infusion na Lugha Natural (NLI) ya ƙarfafa research masu ƙaranci a cikin wannan area, kuma ingawa masu yawa daga wannan research na fokus a kan data masu monoli'in. Code-Miɗar is the inter-diffused of several languages, and is commonly vied in a mazaɓa takardar mutane. Gida ƙaranci da ana ƙara da mataimaki na zauren zauren akwatin bayani, sai na buƙata kada su fahimta kodi-yin haɗuwa, kuma amma, haƙƙin kasa cikin zane-zane da aka haɗa shi da harshen Natural Ana Fasahawa (NLU) ya ƙayyade research a cikin wannan area. @ info: whatsthis Tuna ƙidãya masu amfani da misalin harshen, ƙaramako da data, fassarar da kuma masu shirya matsayin cikin shirin ayuka da aka haɗa, da mazaɓa, da kuma masu rauni na fassarar wannan dataset. Muna sami wani asilimi 8.09 mai ƙara cikin jarrabo da aka ƙayyade tsarin da ake kai yanzu.", 'he': 'הנוכחות של גופורה בקומה גדולה עבור השפה הטבעית (NLI) מעוררה מחקר למידה עמוק באזור הזה, למרות שהרבה מהמחקר הזה התמקד בלבד בנתונים monolingual. הערבוב קודים הוא השימוש בין השפתיים של שפות רבות, ומופיע בדרך כלל בשיחות לא רשמיות בין פוליגלוטים. Given the rising importance of dialogue agents, it is imperative that they understand code-mixing, but the scarcity of code-mixed Natural Language Understanding (NLU) datasets has precluded research in this area.  קבוצת הנתונים של Khanuja et. al. על חשיפת התערבות שיחה בטקסט אינדי-אנגלי מעורבב קוד היא הראשונה מסוגו. אנו חוקרים את היעילות של דוגמנית שפת, גידול נתונים, תרגום, גישות ארכיטקטורניות כדי להתמודד עם היבטים של קוד מעורבב, שיחה, וממשאבים נמוכים של קבוצת נתונים זו. אנחנו מקבלים 8.09% גבוהה בדיקת קבוצת בדיקות על המצב הנוכחי של האמנות.', 'sk': 'Prisotnost obsežnih korpusov za sklepanje naravnega jezika (NLI) je spodbudila raziskave globokega učenja na tem področju, čeprav se je večina teh raziskav osredotočila izključno na enojezične podatke. Mešanje kod je prepletena uporaba več jezikov in se pogosto vidi v neformalnih pogovorih med poligloti. Glede na naraščajoč pomen dialognih akterjev je nujno, da razumejo mešanje kod, vendar pomanjkanje podatkovnih nizov o razumevanju naravnega jezika (NLU) s kodami preprečuje raziskave na tem področju. Podatkovni nabor Khanuja et. al. za odkrivanje pogovornih vključenosti v šifrirano-angleško besedilo je prvi te vrste. Preučujemo učinkovitost jezikovnega modeliranja, povečanja podatkov, prevajanja in arhitekturnih pristopov pri obravnavanju vidikov mešanih s kodami, pogovornih in nizkih virov tega nabora podatkov. Dobimo 8,09-odstotno povečanje natančnosti testnih sklopov v primerjavi s trenutnim stanjem tehnike.', 'jv': 'Nanging ketahanan akeh-scale karo perusahaan kanggo langgambar urip (NLI) sak bungke nggawe barang nggawe barang dumadhi, sane akeh akeh ranjut iki sak sumok kuwi data yang muningi. Ko-Mixing Dino mbok sing akeh akeh lansi ingkang alaman sing dibutuhke dialog, lan akeh imperti dhéwé kuwi nggunakake kode-minggu, njuk kesempatan kanggo nguasakno perusahaan langgambar aturan sing is in é (NLU) nggo ndelok. Daftar setung kanggo khaNuja et. al Anyone Awak dhéwé éntuk tanggal 8.09% seneng nggawe kesempatan kanggo ngerasah durum sing ngendalikno.', 'bo': 'The presence of large-scale corpora for Natural Language Inference (NLI) has spurred deep learning research in this area, though much of this research has focused only on monolingual data. སྐད་རིགས་འདི་ཕན་ཚུན་འབྲེལ་བ་གཉིས་ཀྱི་སྤྱོད་སྟངས་འདི་ཡིན། དམིགས་བསལ་ན། ཌའི་ལོག་གནས་སྟངས་གལ་ཆེ་རྐྱེན་ཚད་ལྷན་ཁང་ཡོད། Khanuja et.al ཡི་སྒྲིག་ཆ་འཕྲིན་ཡིག་གི་ནང་དུ་གཏོང་མཁན་གྱི་ནང་དུ་འཚོལ་ཞིབ་བཤེར་བྱེད་སྐབས་ཡིག་ཆ། We investigate the effectiveness of language modeling, data augmentation, translation, and architectural approaches to address the code-mixed, conversational, and low-resource aspects of this dataset. ང་ཚོས་བརྟག་ཞིབ་ཀྱི་གནས་སྟངས་པར་ད་ལྟར་སྟབས་བདེ་འཇགས་ཀྱི་ཚད་ལྟར་བཞིན་ཡོད།'}
{'en': 'Annotation Efficient  Language Identification  from Weak Labels', 'ar': 'تعريف اللغة الفعال من التسميات الضعيفة', 'pt': 'Identificação de linguagem eficiente de anotação a partir de rótulos fracos', 'es': 'Identificación eficiente del lenguaje de anotación a partir de etiquetas débiles', 'fr': 'Annotation Identification efficace du langage à partir des étiquettes faibles', 'ja': '弱いラベルからのアノテーション効率的な言語識別', 'hi': 'कमजोर लेबल से एनोटेशन कुशल भाषा पहचान', 'zh': '注从弱识高效语', 'ru': 'Эффективная идентификация языка аннотаций из слабых меток', 'ga': 'Anótáil Aithint Teanga Éifeachtach ó Lipéid Lag', 'ka': 'Name', 'hu': 'Hatékony nyelvazonosítás gyenge címkékből', 'el': 'Αποτελεσματικός προσδιορισμός γλώσσας από αδύναμες ετικέτες', 'it': 'Identificazione efficace del linguaggio da etichette deboli', 'kk': 'Жазбалардан жазбаларды анықтау мүмкіндікті тілді идентификациясы', 'lt': 'Annotation Efficient Language Identification from Weak Labels', 'mk': 'Идентификација на јазик со ефикасна анатација од слабите етикети', 'ml': 'ഭാഷ തിരിച്ചറിയുക', 'mt': 'Identifikazzjoni tal-Lingwa Effiċjenti fl-Annotazzjoni minn Tikketti Dgħufa', 'mn': 'Өнгөрсөн жагсаалтуудын эмзэгтэй хэл танилцуулалт', 'ms': 'Pengenalan Bahasa Efisien Annotasi dari Label Kelemahan', 'no': 'Comment', 'pl': 'Skuteczna identyfikacja języka ze słabych etykiet', 'ro': 'Identificarea eficientă a limbajului din etichetele slabe', 'sr': 'Identifikacija jezika iz slabe etikete', 'si': 'අවශ්\u200dය භාෂාව පරීක්ෂණය', 'so': 'Aqoonsiga luqada qalabka tabarta', 'sv': 'Annotation Effektiv språkidentifiering från svaga etiketter', 'ta': 'விளக்கச்சீட்டிலிருந்து மொழி அடையாளம்', 'ur': 'ضعیف لابل سے نشانی اثری زبان شناسایی', 'uz': 'Name', 'vi': 'Chú thích hiệu quả ngôn ngữ nhận diện từ nhãn yếu', 'bg': 'Ефективна идентификация на езика от слаби етикети', 'da': 'Anmærkning Effektiv sprogidentifikation fra svage etiketter', 'nl': 'Annotatie Efficiënte taalidentificatie van zwakke labels', 'hr': 'Učinjena identifikacija jezika iz slabe etikete', 'de': 'Annotation Effiziente Spracherkennung durch schwache Etiketten', 'ko': '약한 라벨 기반의 효율적인 언어 식별', 'id': 'Annotation Efficient Language Identification from Weak Labels', 'fa': 'شناسایی زبان تاثیر از برچسبهای ضعیف', 'sw': 'Utambulisho wa lugha wenye ufanisi kutoka kwenye alama chache', 'tr': 'Aýak etiketlerden janlaşdyrma etkinlik dil kimligi', 'af': 'Comment', 'sq': 'Identifikimi i gjuhës Efikase nga etiketat e dobëta', 'am': 'አቀማመጥ', 'hy': 'Comment', 'az': 'Qüçük etiketlərdən təsirli Dil Kimliği', 'bn': 'উল্লেখযোগ্য লেবেল থেকে কার্যকর ভাষা পরিচয়', 'bs': 'Učinjena identifikacija jezika iz slabe etikete', 'ca': "Identificació de llenguatge eficient d'anotació a partir d'etiquetes fraques", 'cs': 'Anotace Efektivní identifikace jazyka ze slabých štítků', 'et': 'Annotatsiooni tõhus keele identifitseerimine nõrkadel sildistel', 'fi': 'Annotointitehokas kielen tunnistus heikkoista merkinnöistä', 'jv': 'structural navigation', 'ha': '@ label: listbox', 'he': 'זיהוי שפה יעיל בהעטפות מדוגות חלשים', 'sk': 'Učinkovita identifikacija jezika iz šibkih oznak', 'bo': 'འགྲེལ་བཤད་ནུས་ཡོད་པའི་སྐད་རིགས་ངོས་འཛིན་བྱེད་པ'}
{'en': 'India is home to several languages with more than 30 m speakers. These  languages  exhibit significant presence on  social media platforms . However, several of these widely-used languages are under-addressed by current Natural Language Processing (NLP) models and resources. User generated social media content in these  languages  is also typically authored in the  Roman script  as opposed to the traditional native script further contributing to resource scarcity. In this paper, we leverage a minimally supervised NLP technique to obtain weak language labels from a large-scale Indian social media corpus leading to a robust and annotation-efficient language-identification technique spanning nine Romanized Indian languages. In fast-spreading pandemic situations such as the current COVID-19 situation, information processing objectives might be heavily tilted towards under-served languages in densely populated regions. We release our  models  to facilitate downstream analyses in these low-resource languages. Experiments across multiple  social media corpora  demonstrate the  model ’s robustness and provide several interesting insights on Indian language usage patterns on  social media . We release an annotated data set of 1,000 comments in ten  Romanized languages  as a social media evaluation benchmark.', 'pt': 'A Índia é o lar de vários idiomas com mais de 30 milhões de falantes. Essas linguagens apresentam presença significativa nas plataformas de mídia social. No entanto, várias dessas linguagens amplamente utilizadas são pouco abordadas pelos atuais modelos e recursos de Processamento de Linguagem Natural (NLP). O conteúdo de mídia social gerado pelo usuário nesses idiomas também é normalmente criado no script romano, em oposição ao script nativo tradicional, contribuindo ainda mais para a escassez de recursos. Neste artigo, aproveitamos uma técnica de PNL minimamente supervisionada para obter rótulos de linguagem fracos de um corpus de mídia social indiana de grande escala, levando a uma técnica de identificação de linguagem robusta e eficiente em anotações, abrangendo nove línguas indianas romanizadas. Em situações de pandemia de rápida disseminação, como a atual situação do COVID-19, os objetivos de processamento de informações podem estar fortemente inclinados para idiomas mal atendidos em regiões densamente povoadas. Lançamos nossos modelos para facilitar as análises posteriores nessas linguagens de poucos recursos. Experimentos em vários corpora de mídia social demonstram a robustez do modelo e fornecem vários insights interessantes sobre os padrões de uso da língua indiana nas mídias sociais. Lançamos um conjunto de dados anotado de 1.000 comentários em dez idiomas romanizados como referência de avaliação de mídia social.', 'ar': 'الهند موطن لعدة لغات مع أكثر من 30 مليون متحدث. تُظهر هذه اللغات حضورًا كبيرًا على منصات التواصل الاجتماعي. ومع ذلك ، فإن العديد من هذه اللغات المستخدمة على نطاق واسع لا يتم تناولها بشكل كافٍ من خلال نماذج وموارد معالجة اللغة الطبيعية (NLP) الحالية. عادةً ما يتم أيضًا تأليف محتوى الوسائط الاجتماعية الذي ينشئه المستخدم بهذه اللغات بالنص الروماني بدلاً من النص الأصلي التقليدي الذي يساهم بشكل أكبر في ندرة الموارد. في هذه الورقة ، نستفيد من تقنية NLP الخاضعة للإشراف البسيط للحصول على تسميات لغة ضعيفة من مجموعة وسائط اجتماعية هندية واسعة النطاق تؤدي إلى تقنية تعريف لغة قوية وفعالة في التعليقات التوضيحية تغطي تسع لغات هندية بالحروف اللاتينية. في حالات الوباء سريعة الانتشار مثل الوضع الحالي لـ COVID-19 ، قد تميل أهداف معالجة المعلومات بشكل كبير نحو اللغات غير المخدومة في المناطق المكتظة بالسكان. نصدر نماذجنا لتسهيل التحليلات النهائية بهذه اللغات منخفضة الموارد. توضح التجارب عبر العديد من شركات الوسائط الاجتماعية قوة النموذج وتوفر العديد من الأفكار المثيرة للاهتمام حول أنماط استخدام اللغة الهندية على وسائل التواصل الاجتماعي. أصدرنا مجموعة بيانات مشروحة من 1000 تعليق بعشر لغات مكتوبة بالحروف اللاتينية كمعيار لتقييم وسائل التواصل الاجتماعي.', 'fr': "L'Inde abrite plusieurs langues avec plus de 30 millions de locuteurs. Ces langues sont très présentes sur les plateformes de réseaux sociaux. Cependant, plusieurs de ces langues largement utilisées sont sous-traitées par les modèles et ressources actuels de traitement du langage naturel (NLP). Le contenu des réseaux sociaux généré par les utilisateurs dans ces langues est également généralement rédigé en écriture romaine, contrairement au script natif traditionnel, ce qui contribue à la rareté des ressources. Dans cet article, nous tirons parti d'une technique de PNL supervisée de manière minimale pour obtenir des étiquettes de langue faibles à partir d'un corpus de médias sociaux indiens à grande échelle, menant à une technique d'identification linguistique robuste et efficace pour l'annotation couvrant neuf langues indiennes romanisées. Dans les situations de pandémie à propagation rapide, comme la situation actuelle de la COVID-19, les objectifs de traitement de l'information peuvent être fortement orientés vers les langues mal desservies dans les régions densément peuplées. Nous publions nos modèles pour faciliter les analyses en aval dans ces langages à faibles ressources. Des expériences sur plusieurs corpus de médias sociaux démontrent la robustesse du modèle et fournissent plusieurs informations intéressantes sur les modèles d'utilisation de la langue indienne sur les réseaux sociaux. Nous publions un ensemble de données annoté de 1 000 commentaires dans dix langues romanisées comme référence d'évaluation des réseaux sociaux.", 'es': 'India es el hogar de varios idiomas con más de 30 millones de hablantes. Estos idiomas exhiben una presencia significativa en las plataformas de redes sociales. Sin embargo, varios de estos lenguajes ampliamente utilizados no están suficientemente abordados por los modelos y recursos actuales de Procesamiento del Lenguaje Natural (NLP). El contenido de las redes sociales generado por los usuarios en estos idiomas también se escribe normalmente en escritura romana, a diferencia de la escritura nativa tradicional, lo que contribuye aún más a la escasez de recursos. En este artículo, utilizamos una técnica de PNL mínimamente supervisada para obtener etiquetas de idiomas débiles de un corpus de redes sociales indias a gran escala que conducen a una técnica de identificación de idiomas robusta y eficiente en anotaciones que abarca nueve idiomas indios romanizados. En situaciones de pandemia de rápida propagación, como la situación actual de COVID-19, los objetivos de procesamiento de la información podrían estar fuertemente inclinados hacia idiomas poco atendidos en regiones densamente pobladas. Publicamos nuestros modelos para facilitar los análisis posteriores en estos lenguajes de bajos recursos. Los experimentos realizados en múltiples cuerpos de redes sociales demuestran la solidez del modelo y proporcionan varias ideas interesantes sobre los patrones de uso del idioma indio en las redes sociales. Publicamos un conjunto de datos anotados de 1000 comentarios en diez idiomas romanizados como referencia de evaluación de redes sociales.', 'ja': 'インドにはいくつかの言語があり、3000万人以上の話者がいる。 これらの言語は、ソーシャルメディアプラットフォームで重要な存在感を示しています。 しかしながら、これらの広く使用されている言語のいくつかは、現在の自然言語処理（ NLP ）モデルとリソースではあまり取り上げられていない。 これらの言語でユーザーが生成したソーシャルメディアコンテンツは、通常、従来のネイティブスクリプトとは対照的に、ローマ字で作成され、リソース不足をさらに助長します。 この論文では、最小限に監督されたNLPテクニックを活用して、大規模なインドのソーシャルメディアコーパスから弱い言語ラベルを取得し、9つのローマ化されたインドの言語にわたる堅牢でアノテーション効率の高い言語識別テクニックをもたらします。 現在のCOVID -19のような急速に広がるパンデミックの状況では、情報処理の目標は人口密集地域のサービスが不十分な言語に大きく傾いている可能性があります。 私たちは、これらの低資源言語のダウンストリーム分析を容易にするために、モデルをリリースします。 複数のソーシャルメディア企業での実験は、モデルの堅牢性を示し、ソーシャルメディア上のインドの言語使用パターンに関するいくつかの興味深い洞察を提供します。 ソーシャルメディアの評価ベンチマークとして、ローマ字化された10の言語で1,000のコメントの注釈付きデータセットをリリースします。', 'zh': '印度者,多种语言之家,有过3000万使用者。 语在社交媒体台上。 然博用之语,在今之自然语言(NLP)形用未尽也。 此语用户成社交媒体常以罗马文编之,非旧文,益剧资稀缺。 于本文中,我用一种最卑限度NLP术从大印度社交媒体语料库中取弱语言标签,以生一越九种罗马化印度语言之强而注高效语别术。 今之COVID-19者,信息处理大归于人口稠密之地。 发模方便使用此低资源语下流也。 跨数社交媒体语料库实验验其稳健性,给社交媒体印度语言用式之趣。 发 10 种罗马化语言之 1,000 条论带注之数集,以为社交媒体准。', 'hi': 'भारत 30 m से अधिक बोलने वालों के साथ कई भाषाओं का घर है। ये भाषाएं सोशल मीडिया प्लेटफार्मों पर महत्वपूर्ण उपस्थिति प्रदर्शित करती हैं। हालांकि, इनमें से कई व्यापक रूप से उपयोग की जाने वाली भाषाओं को वर्तमान प्राकृतिक भाषा प्रसंस्करण (एनएलपी) मॉडल और संसाधनों द्वारा कम संबोधित किया जाता है। इन भाषाओं में उपयोगकर्ता द्वारा उत्पन्न सोशल मीडिया सामग्री भी आमतौर पर रोमन लिपि में लिखी जाती है क्योंकि पारंपरिक देशी स्क्रिप्ट के विपरीत संसाधनों की कमी में योगदान देती है। इस पत्र में, हम एक बड़े पैमाने पर भारतीय सोशल मीडिया कॉर्पस से कमजोर भाषा लेबल प्राप्त करने के लिए एक न्यूनतम पर्यवेक्षित एनएलपी तकनीक का लाभ उठाते हैं, जिससे नौ रोमनीकृत भारतीय भाषाओं में फैली एक मजबूत और एनोटेशन-कुशल भाषा-पहचान तकनीक होती है। वर्तमान कोविड-19 स्थिति जैसी तेजी से फैलने वाली महामारी की स्थितियों में, सूचना प्रसंस्करण उद्देश्यों को घनी आबादी वाले क्षेत्रों में कम सेवा वाली भाषाओं की ओर भारी रूप से झुकाया जा सकता है। हम इन कम संसाधन भाषाओं में डाउनस्ट्रीम विश्लेषण की सुविधा के लिए अपने मॉडल जारी करते हैं। कई सोशल मीडिया कॉर्पोरेट में प्रयोग मॉडल की मजबूती को प्रदर्शित करते हैं और सोशल मीडिया पर भारतीय भाषा के उपयोग के पैटर्न पर कई दिलचस्प अंतर्दृष्टि प्रदान करते हैं। हम एक सामाजिक मीडिया मूल्यांकन बेंचमार्क के रूप में दस Romanized भाषाओं में 1,000 टिप्पणियों का एक एनोटेट डेटा सेट जारी करते हैं।', 'ru': 'В Индии проживает несколько языков, на которых говорят более 30 миллионов человек. Эти языки демонстрируют значительное присутствие на платформах социальных сетей. Тем не менее, некоторые из этих широко используемых языков недостаточно учитываются текущими моделями и ресурсами обработки естественного языка (NLP). Контент, созданный пользователями в социальных сетях на этих языках, также, как правило, написан римским шрифтом, в отличие от традиционного родного шрифта, дополнительно способствующего нехватке ресурсов. В этой статье мы используем методику NLP с минимальным контролем для получения слабых языковых меток из крупномасштабного индийского корпуса социальных сетей, что приводит к надежной и эффективной аннотации методике языковой идентификации, охватывающей девять латинизированных индийских языков. В быстро распространяющихся пандемических ситуациях, таких как текущая ситуация с COVID-19, цели обработки информации могут быть сильно склонены к недостаточно обслуживаемым языкам в густонаселенных регионах. Мы выпускаем наши модели, чтобы облегчить последующий анализ на этих языках с низким объемом ресурсов. Эксперименты в различных социальных сетях демонстрируют надежность модели и дают несколько интересных представлений о моделях использования индийского языка в социальных сетях. Мы выпустили аннотированный набор данных из 1000 комментариев на десяти латиницах в качестве эталона оценки социальных сетей.', 'ga': 'Tá roinnt teangacha sa India le níos mó ná 30m cainteoir. Léiríonn na teangacha seo láithreacht shuntasach ar ardáin na meán sóisialta. Mar sin féin, níl dóthain aghaidh á tabhairt ag samhlacha agus acmhainní Próiseáil Teanga Nádúrtha (NLP) ar go leor de na teangacha seo a úsáidtear go forleathan. Is gnách go n-údaraítear ábhar meán sóisialta arna ghiniúint ag úsáideoirí sna teangacha seo sa script Rómhánach seachas an script dhúchasach thraidisiúnta a chuireann tuilleadh le ganntanas acmhainní. Sa pháipéar seo, déanaimid giaráil ar theicníc NLP faoi mhaoirseacht íosta chun lipéid laga teanga a fháil ó chorpas meán sóisialta Indiach ar mhórscála as a dtiocfaidh teicníocht sainaitheanta teanga láidir agus tíosach ar nótaí a chuimsíonn naoi dteanga Indiach Rómhánacha. I gcásanna paindéimeacha atá ag méadú go tapa ar nós an staid reatha COVID-19, d’fhéadfadh cuspóirí próiseála faisnéise a bheith ag dul go mór i dtreo teangacha nach ndéantar freastal orthu i réigiúin dlúthdhaonra. Eisímid ár múnlaí chun anailísí iartheachtacha a éascú sna teangacha íseal-acmhainne seo. Léiríonn turgnaimh ar fud corpora iolracha na meán sóisialta stóinseacht na samhla agus tugann siad roinnt léargas suimiúil ar phatrúin úsáide teanga Indiach ar na meáin shóisialta. Eisímid tacar sonraí anótáilte de 1,000 trácht i ndeich dteanga Rómhánaithe mar thagarmharc meastóireachta ar na meáin shóisialta.', 'hu': 'India számos nyelv otthona, több mint 30 millió beszélővel. Ezek a nyelvek jelentős jelenlétet mutatnak a közösségi média platformokon. Azonban ezek közül a széles körben használt nyelvek közül néhányat a jelenlegi Natural Language Processing (NLP) modellek és erőforrások nem kezelik. A felhasználók által generált közösségi média tartalmak ezeken a nyelveken jellemzően római írásban is készülnek, szemben a hagyományos anyanyelvi írással, ami tovább hozzájárul az erőforrások hiányához. Ebben a tanulmányban egy minimálisan felügyelt NLP technikát használunk arra, hogy gyenge nyelvi címkéket szerezzünk egy nagyszabású indiai közösségi média korpuszból, ami egy robusztus és jegyzetelési hatékony nyelvazonosítási technikát eredményez kilenc románizált indiai nyelven. A gyorsan terjedő járványos helyzetekben, mint például a jelenlegi COVID-19 helyzet, az információfeldolgozási célkitűzések nagymértékben a sűrűn lakott régiókban a kiszolgált nyelvek felé fordulhatnak. Modelljeinket kiadjuk, hogy megkönnyítsük a downstream elemzéseket ezen alacsony erőforrású nyelveken. Több közösségi média cégen végzett kísérletek bizonyítják a modell robusztusságát, és számos érdekes betekintést nyújtanak az indiai nyelvhasználati mintákról a közösségi médiában. A közösségi média értékelési referenciaértékként 1000 megjegyzésből álló adatkészletet teszünk közzé tíz román nyelven.', 'el': 'Η Ινδία είναι η πατρίδα πολλών γλωσσών με περισσότερους από 30μ ομιλητές. Αυτές οι γλώσσες παρουσιάζουν σημαντική παρουσία στις πλατφόρμες κοινωνικών μέσων. Ωστόσο, αρκετές από αυτές τις ευρέως χρησιμοποιούμενες γλώσσες δεν καλύπτονται από τα τρέχοντα μοντέλα και πόρους επεξεργασίας φυσικής γλώσσας. Το περιεχόμενο των μέσων κοινωνικής δικτύωσης που παράγεται από χρήστες σε αυτές τις γλώσσες είναι επίσης τυπικά γραμμένο στη ρωμαϊκή γραφή σε αντίθεση με την παραδοσιακή μητρική γραφή που συμβάλλει περαιτέρω στη σπανιότητα πόρων. Σε αυτή την εργασία, χρησιμοποιούμε μια ελάχιστη εποπτευόμενη τεχνική για να λάβουμε αδύναμες γλωσσικές ετικέτες από ένα μεγάλο ινδικό σώμα κοινωνικών μέσων που οδηγεί σε μια ισχυρή και αποδοτική τεχνική γλωσσικής αναγνώρισης που καλύπτει εννέα Ρομανισμένες Ινδικές γλώσσες. Σε καταστάσεις πανδημίας που εξαπλώνονται γρήγορα, όπως η τρέχουσα κατάσταση, οι στόχοι επεξεργασίας πληροφοριών ενδέχεται να στραφούν σε γλώσσες που δεν εξυπηρετούνται σε πυκνοκατοικημένες περιοχές. Απελευθερώνουμε τα μοντέλα μας για να διευκολύνουμε τις μεταγενέστερες αναλύσεις σε αυτές τις γλώσσες χαμηλής περιεκτικότητας σε πόρους. Τα πειράματα σε πολλαπλά σώματα κοινωνικών μέσων καταδεικνύουν την ανθεκτικότητα του μοντέλου και παρέχουν αρκετές ενδιαφέρουσες πληροφορίες σχετικά με τα πρότυπα χρήσης ινδικής γλώσσας στα μέσα κοινωνικής δικτύωσης. Δημοσιεύουμε ένα σχολιασμένο σύνολο δεδομένων των 1.000 σχολίων σε δέκα Ρομαντικές γλώσσες ως κριτήριο αξιολόγησης των μέσων κοινωνικής δικτύωσης.', 'ka': 'ინდოეთა 30 მეტრის უფრო მეტი სიტყვების სახლში. ეს ენები მნიშვნელოვანი საზოგადომი მედია პლატატურებში გამოჩვენებენ. მაგრამ, ამ უფრო გამოიყენებული ენების რამდენიმე მოდელები და რესურსები მიმდინარე ნახვა ენების პროცესი (NLP) მოდელებით. მომხმარებელი შეიქმნა სოციალური მედიაში ამ ენაში, რომელსაც რომელის სკრიპტიში ასრულებულია, რომელსაც რესურსების მუშაობაში დამატებული რესურსების მუშაობაზე. ჩვენ მინიმალურად დავაკეთებთ NLP ტექნიკაში, რომელიც გავიღებთ ძალიან სიტყვის მარტივი ინდოეთის სოციალური მედია კოპუსისგან, რომელიც წარმოიდგინეთ ძალიან და ამოტაციურად ეფექტიურად ენის ინდიანეთიკის გან სწრაფად გაფართებული პანდემიური სიტაციაში, როგორც მიმდინარე COVID-19 სიტაციაში, ინფორმაციის პროცესის მიზეზები შეიძლება ძალიან გაფართებული ენების გარეშე ძალიან გაფართებული ადგი ჩვენ ჩვენი მოდელების გამოყენება, რომლებიც ახლოებით ჩვენი ანალიზების შესაძლებლობად ამ ცოტა რესურსის ენაში. მეტი სოციალური მედია კოპორაში გამოცდილებები მოდელს ძალიან ძალიან და ინდიანეთის ენის გამოყენება სოციალური მედიაში უფრო ინტერესური ინტერესური გამოყენება. ჩვენ ამოხსნა 1000 კომენტრების მონაცემები 10 პრომენტირებული ენაში, როგორც სოციალური მედიაში გაუმუშავებული ბენქმერი.', 'it': "L'India ospita diverse lingue con più di 30 milioni di parlanti. Questi linguaggi mostrano una presenza significativa sulle piattaforme di social media. Tuttavia, molti di questi linguaggi ampiamente utilizzati sono sottoaffrontati dai modelli e dalle risorse attuali di Natural Language Processing (NLP). Anche i contenuti dei social media generati dagli utenti in queste lingue sono tipicamente scritti in scrittura romana in contrasto con la scrittura nativa tradizionale contribuendo ulteriormente alla scarsità di risorse. In questo articolo, utilizziamo una tecnica NLP minimamente supervisionata per ottenere etichette linguistiche deboli da un corpus di social media indiano su larga scala che porta a una tecnica di identificazione linguistica robusta ed efficiente per annotazioni che abbraccia nove lingue indiane romanizzate. In situazioni pandemiche di rapida diffusione come l'attuale situazione COVID-19, gli obiettivi di elaborazione delle informazioni potrebbero essere fortemente orientati verso lingue poco servite nelle regioni densamente popolate. Rilasciamo i nostri modelli per facilitare le analisi a valle in questi linguaggi a basso contenuto di risorse. Esperimenti su più corpora di social media dimostrano la robustezza del modello e forniscono diverse interessanti informazioni sui modelli di utilizzo della lingua indiana sui social media. Pubblichiamo un set di dati annotati di 1.000 commenti in dieci lingue romanizzate come benchmark di valutazione dei social media.", 'kk': 'Үндістан 30 м күннен артық сөйлейткен тілдерге үй болады. Бұл тілдер социалдық медиа платформасында маңызды болып көрсетеді. Бірақ бұл көптеген тілдердің бірнеше тілдері қазіргі Түзіндік тіл процессері (NLP) үлгілері мен ресурстары бойынша адрестік береді. Пайдаланушысы осы тілдерде социалдық медиа мазмұнын құрылған және әдетте Роман скриптінде әдеттегі негізгі скрипті ресурстардың қажеттілігіне көмектеседі. Бұл қағазда, біз NLP техникасын үлкен индиялық социаллық медиа корпус үлкен тілдер жарлықтарын алу үшін кеміндетті көмектесетін, күшті және белгілер ефективті тілдерді идентификациялау техникасына көмектеседі. Қолданыстағы COVID-19 жағдайда тез таратылған пандемиялық жағдайда, мәліметті өңдеу мақсаттары тұрақтық аумақтарда тұрақтық тілдерге көмектесу мүмкін. Біз өзіміздің үлгілерімізді бұл төмен ресурс тілдерінде анализ көмектесу үшін шығару үшін. Бірнеше социалдық медиа корпорасының тәжірибелері үлгісінің құндылығын көрсетеді және социалдық медиақтардың индиялық тіл қолдану үлгілерін бірнеше қызықтық Біз 10 румандалық тілдерінде 1000 түсініктемелер жазылған деректер жиынын социалдық медиа оқу бағдарламасы ретінде таңдаймыз.', 'mk': 'Индија е дом на неколку јазици со повеќе од 30 метри говорници. Овие јазици покажуваат значително присуство на платформите на социјалните медиуми. Сепак, неколку од овие широко употребени јазици се недостасуваат од сегашните модели и ресурси на природното јазичко процесување (НЛП). Корисникот генерира социјални медиуми на овие јазици, исто така, обично се авторира во римскиот скрипт во спротивност на традиционалниот роден скрипт кој понатаму придонесува за недостатокот на ресурси. Во овој весник, ја искористуваме минимално надгледуваната техника на НЛП за да добиеме слаби јазични етикети од голем индиски социјални медиуми коишто води до силна и ефикасна техника за идентификација на јазикот на девет романизирани индиски јазици. Во брзите пандемиски ситуации како што е сегашната ситуација на КоВИД-19, целите за обработување на информациите може да бидат силно насочени кон неуслужените јазици во густо населени региони. Ги ослободуваме нашите модели за да ги олесниме анализите на ниските ресурси на овие јазици. Експериментите низ повеќето тела на социјалните медиуми ја демонстрираат силноста на моделот и обезбедуваат неколку интересни информации за моделите на употребата на индискиот јазик на социјалните медиуми. Ние објавуваме анотиран набор на податоци од 1.000 коментари на десет романизирани јазици како benchmark за проценка на социјалните медиуми.', 'lt': 'Indija yra kelių kalbų, kuriose kalbama daugiau kaip 30 m kalbėtojų. Šiose kalbose socialinės žiniasklaidos platformose daug dalyvauja. Tačiau kelios iš šių plačiai naudojamų kalbų yra nepakankamai sprendžiamos pagal dabartinius gamtos kalbų apdorojimo modelius ir išteklius. Naudotojas sukauptas social in ės žiniasklaidos turinys šiomis kalbomis paprastai taip pat rašomas romėnų scenarijuje, o ne tradicinis gimtinis scenarijus, kuris dar labiau prisideda prie išteklių trūkumo. Šiame dokumente mes naudojame minimaliai prižiūrimą NLP metodą, kad gautume silpnas kalbų etiketes iš didelio masto Indijos socialinės žiniasklaidos korpuso, ir tai lemia tvirtą ir anotacijai veiksmingą kalbų identifikavimo metodą, apimantį devynias romanizuotas Indijos kalbas. Greitai paplitus pandemijai, pavyzdžiui, dabartinei COVID-19 situacijai, informacijos tvarkymo tikslai gali būti labai nukreipti į nepakankamai aptarnaujamas kalbas tankiai gyvenamuose regionuose. We release our models to facilitate downstream analyses in these low-resource languages.  Įvairių socialinių žiniasklaidos korpūrų eksperimentai rodo modelio patikimumą ir suteikia keletą įdomių žinių apie Indijos kalbos naudojimo socialinėje žiniasklaidoje modelius. Kaip social in ės žiniasklaidos vertinimo lyginamąjį tašką paskelbiame anotuotą 1 000 komentarų rinkinį dešimt rumunų kalbų.', 'ml': 'ഇന്ത്യയുടെ വീട്ടില്\u200d 30 മീറ്റര്\u200d സ്പീക്കരുടെ കൂടുതല്\u200d ഭാഷകള്\u200dക്ക് വേണ്ടിയാണ്. ഈ ഭാഷകള്\u200d സോഷ്യല്\u200d മീഡിയ പ്ലാറ്റ്ഫോമുകളില്\u200d പ്രധാനപ്പെടുത്തുന്നു. However, several of these widely-used languages are under-addressed by current Natural Language Processing (NLP) models and resources.  ഈ ഭാഷകളിലുള്ള സാമൂഹ്യ മീഡിയ വിഭവങ്ങള്\u200d സൃഷ്ടിച്ചിരിക്കുന്ന ഉപയോക്താവ് റോമാന്\u200d സ്ക്രിപ്റ്റില്\u200d സാധാരണമായി എഴുതിയിരി ഈ പത്രത്തില്\u200d, നമ്മള്\u200d നിരീക്ഷിക്കപ്പെടുന്ന ഒരു ചെറുതായി നിരീക്ഷിക്കപ്പെട്ട NLP സാങ്കേതികവിദ്യഭാഷയുടെ ലേബലുകള്\u200d ലഭ്യമാക്കുവാന്\u200d വേണ്ടിയും, ഒരു വലിയ ഭാഷ മ ഇപ്പോഴത്തെ കോവിഡി-19 സ്ഥിതിയെപ്പോലെ വേഗത്തില്\u200d വികസിപ്പിക്കുന്ന പാന്\u200dഡീമിക സാഹചര്യങ്ങളില്\u200d, വിവരങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്ന സാ ഈ കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകളില്\u200d ഞങ്ങള്\u200d നമ്മുടെ മോഡലുകളെ ഉപയോഗിക്കാന്\u200d പോകുന്നു. ഒരുപാട് സോഷ്യല്\u200d മീഡിയ കോര്\u200dപ്പോരയിലെ പരീക്ഷണങ്ങള്\u200d മോഡലിന്റെ വസ്ത്രം പ്രത്യക്ഷപ്പെടുത്തുന്നു. ഇന്ത്യഭാഷ ഉപയോഗിക്കുന്ന പത്ത് റോമാനിസ് ഭാഷകളില്\u200d ഒരു സാമൂഹ്യ മീഡിയ വിലാസങ്ങളുടെ ബെന്\u200dച്മാര്\u200dക്ക് മാത്രമായി ഞങ്ങള്\u200d വിവരിച്ചുതരുന്ന ഒര', 'mt': "L-Indja għandha diversi lingwi b’aktar minn 30 metru ta’ kelliema. Dawn il-lingwi juru preżenza sinifikanti fuq pjattaformi tal-midja soċjali. Madankollu, bosta minn dawn il-lingwi użati ħafna mhumiex indirizzati biżżejjed mill-mudelli u r-riżorsi attwali tal-Proċess tal-Lingwi Naturali (NLP). Il-kontenut tal-midja soċjali ġġenerat mill-utent f’dawn il-lingwi huwa tipikament awtur ukoll fil-kitba Rumena minflok il-kitba tradizzjonali nattiva li tikkontribwixxi aktar għall-iskarsezza tar-riżorsi. F’dan id-dokument, nagħmlu użu minn teknika ta’ NLP minimament sorveljata biex inkisbu tikketti lingwistiċi dgħajfa minn korpus tal-midja soċjali Indjana fuq skala kbira li jwassal għal teknika ta’ identifikazzjoni tal-lingwi robust a u effiċjenti fl-annotazzjoni li tkopri disa’ lingwi Indjani Rumanizzati. F’sitwazzjonijiet pandemiċi li qed jinfirxu malajr bħas-sitwazzjoni attwali COVID-19, l-objettivi tal-ipproċessar tal-informazzjoni jistgħu jitmexxew ħafna lejn lingwi li mhumiex servuti biżżejjed f’reġjuni densament popolati. Aħna nħelsu l-mudelli tagħna biex niffaċilitaw l-analiżi downstream f’dawn il-lingwi b’riżorsi baxxi. L-esperimenti minn diversi korpi tal-midja soċjali juru r-robustezza tal-mudell u jipprovdu diversi fehmiet interessanti dwar ix-xejriet tal-użu tal-lingwa Indjana fil-midja soċjali. Aħna nħarġu sett ta' dejta annotat ta' 1,000 kumment f'għaxar lingwi Rumanizzati bħala punt ta' riferiment għall-evalwazzjoni tal-midja soċjali.", 'mn': 'Энэтхэг 30 м-аас илүү олон хэл гэртэй. Эдгээр хэлнүүд нийгмийн медиа хэлбэрээр маш чухал байдаг. Гэхдээ эдгээр өргөн хэрэглэгдсэн хэлнүүдийн олон нь одоогийн Байгалийн хэл Процессор (NLP) загварууд болон нөөц бүтээмжүүд дээр зориулагддаг. Хэрэглэгчид эдгээр хэл дээр нийгмийн мэдээллийн хэлбэрийг бий болгосон бөгөөд ерөнхийдөө Ромын шинжлэх ухаан дээр уламжлалт орон нутгийн шинжлэх ухааны хэлбэрээс илүү нэмэгдүүл Энэ цаасан дээр бид бага зэрэг удирдагдсан NLP техникийг том хэлбэрээс илүү хүчтэй хэлний маркингуудыг авах боломжтой болгодог. Энэтхэгийн нийгмийн хэвлэлийн корпус нь 9 Роман хэл дээр нэмэгдэж байгаа хүчирхэг, сэтгэл хөдлөлтэй хэлний тодорхойло Хурдан тархаж буй пандемик нөхцөлд орчин үеийн COVID-19 нөхцөлд мэдээллийн үйлдвэрлэлийн зорилготнууд ихэвчлэн хүн амын бүс нутгийн хэл дээр хүчтэй байж болно. Бид өөрсдийн загварыг эдгээр бага баялаг боловсролын хэлний шинжилгээг дэмжихийн тулд нэмэгдүүлдэг. Ихэнх нийгмийн хэвлэлийн корпорацийн туршилтууд загварын хүчтэй байдлыг харуулж, нийгмийн хэлний хэрэглээ дээрх олон сонирхолтой ойлголт өгдөг. Бид 10 румын хэлд 1000 тэмдэглэгдсэн өгөгдлийн хэлбэрийг нийгмийн хэвлэлийн оюутнуудын багц гэж нэрлэж байна.', 'pl': 'Indie są domem dla kilku języków z ponad 30m głośników. Języki te wykazują znaczącą obecność na platformach mediów społecznościowych. Jednak kilka z tych powszechnie używanych języków jest niedostatecznie uwzględnionych w obecnych modelach i zasobach przetwarzania języka naturalnego (NLP). Treści generowane przez użytkowników w mediach społecznościowych w tych językach są również zazwyczaj autorskie w skryptie rzymskim, w przeciwieństwie do tradycyjnego rodzimego skryptu dodatkowo przyczyniającego się do niedoboru zasobów. W niniejszym artykule wykorzystujemy minimalnie nadzorowaną technikę NLP do uzyskania słabych etykiet językowych z dużej skali indyjskiego korpusu mediów społecznościowych, co prowadzi do solidnej i efektywnej adnotacji techniki identyfikacji języka obejmującej dziewięć zromanizowanych języków indyjskich. W szybko rozprzestrzeniających się sytuacjach pandemicznych, takich jak obecna sytuacja COVID-19, cele przetwarzania informacji mogą być silnie skierowane w kierunku niedostatecznie obsługiwanych języków w gęsto zaludnionych regionach. Udostępniamy nasze modele, aby ułatwić dalsze analizy w tych niskich zasobach językach. Eksperymenty w wielu korpusach mediów społecznościowych pokazują solidność modelu i zapewniają kilka ciekawych spostrzeżeń na temat wzorców używania języka indyjskiego w mediach społecznościowych. Publikujemy adnotacyjny zestaw danych 1.000 komentarzy w dziesięciu językach romanizowanych jako referencja oceny mediów społecznościowych.', 'ro': 'India găzduiește mai multe limbi cu mai mult de 30 de milioane de vorbitori. Aceste limbi prezintă o prezență semnificativă pe platformele de social media. Cu toate acestea, mai multe dintre aceste limbi utilizate pe scară largă sunt subabordate de modelele și resursele actuale de procesare a limbajului natural (PNL). Conținutul social media generat de utilizatori în aceste limbi este, de asemenea, scris în mod tipic în scriptul roman, spre deosebire de scriptul nativ tradițional contribuind în continuare la deficitul de resurse. În această lucrare, folosim o tehnică PNL supravegheată minim pentru a obține etichete lingvistice slabe dintr-un corpus indian social media la scară largă, ceea ce duce la o tehnică robustă și eficientă de adnotare a limbilor care cuprinde nouă limbi indiene romanizate. În situații pandemice de răspândire rapidă, cum ar fi situația actuală COVID-19, obiectivele de procesare a informațiilor ar putea fi puternic înclinate către limbi slab servite în regiunile dens populate. Lansăm modelele noastre pentru a facilita analizele în aval în aceste limbi cu resurse reduse. Experimentele pe mai multe corporații de social media demonstrează robustețea modelului și oferă mai multe informații interesante despre modelele de utilizare a limbii indiene pe rețelele de socializare. Lansăm un set de date adnotat de 1.000 de comentarii în zece limbi romanizate ca referință de evaluare a rețelelor sociale.', 'no': 'India er heime til fleire språk med fleire enn 30 m taler. Desse språka viser signifikante tilstand på sosiale mediaplattformar. Men fleire av desse breidde brukte språka er underadresserte av gjeldande naturspråkshandsamar (NLP) modeller og ressursar. Brukaren laga sosiale media-innhald i desse språka er også vanlegvis autorisert i romskriptet i motsetning til den tradisjonelle innhaldne skriptet som bidrar til ressurstråd. I denne papiret leverer vi ein minimalt oversikt NLP-teknikk for å få kvile språk-etikettar frå ein stor stor indisk sosiale media-korpus som fører til ein robust og annotasjonefikast språk-identifiseringsteknikk som utviklar ni Romaniserte indiske språk. I raskt spreidde pandemiske situasjonar, slik som det gjeldande situasjonen COVID-19, kan informasjonshandteringsmålsettingar vere sterkt tilkopla mot under-tjeneste språk i tett populert område. Vi løyser modelane våre for å gjere tilgjengeleg nedstremdanalyser i desse låg ressursspråka. Eksperiment over fleire sosiale media-korpora viser modellen kraftighet og gjer fleire interessante innsyningar om mønsterelement for bruk av indiske språk på sosiale media. Vi publiserer eit oppmerkte datasett med 1000 kommentar i ti romaniserte språk som eit benchmarkt for å evaluera sosiale medier.', 'sr': 'Indija je dom nekoliko jezika sa više od 30 m govornika. Ovi jezici pokazuju značajno prisustvo na platformama društvenih medija. Međutim, nekoliko tih široko korištenih jezika su pod adresom trenutnih modela i resursa procesa prirodnog jezika (NLP). Korisnik je proizveo sadržaj društvenih medija na ovim jezicima, takođe je obično autoriziran u rimskom skriptu, suprotno tradicionalnom domaćem skriptu koji dalje doprinosi nedostatku resursa. U ovom papiru imamo minimalnu nadzornu tehniku NLP-a kako bi dobili slabe jezičke etikete iz velikog Indijskog društvenog medijskog korpusa koji vodi do jake i annotacijske tehnike identifikacije jezika koja širi devet rumunskih Indijskih jezika. U brzom širenju pandemijskih situacija kao što je trenutna situacija COVID-19, ciljevi obrade informacija mogu biti teško povezani prema neposluženim jezicima u gustoj populaciji regiona. Puštamo naše modele kako bi olakšali analizu u ovim jezicima niskih resursa. Eksperimenti u višestrukom društvenom medijskom korporaciji pokazuju robustnost modela i pružaju nekoliko interesantnih uvida o obrascima korištenja indijskih jezika na društvenim medijima. Objavljujemo annotiran set podataka od 1000 komentara na deset rumunskih jezika kao kritiku za procjenu socijalnih medija.', 'si': 'ඉන්දියාව මීටර් 30ක් වඩා වැඩි භාෂාවක් ගෙදර ඉන්නවා. මේ භාෂාවල් සාමාජික මාධ්\u200dයමාධ්\u200dයම ප්\u200dරවේශනයේ වැදගත් වෙනවා. නමුත්, මේ විශාල භාෂාවන්ත භාෂාවන්ත කිසිම භාෂාවන්තුවක් අඩු තියෙනවා ප්\u200dරස්තූත භාෂාව ප්\u200dරකා ප්\u200dරයෝජකයා මේ භාෂාවට සාමාජික මිඩියාව නිර්මාණය කරලා තියෙන්නේ රෝමන් ස්ක්\u200dරිප්ට් වලට සමහරවිට ප්\u200dරයෝජ මේ පත්තරේ අපි අඩුවෙන් පරික්ෂා කරපු NLP තාක්ෂණයක් ලෙබෙල් ගන්න බොරු භාෂාවක් ලෙබෙල් ගන්න ඉන්දියානු සාමාජික මාධ්\u200dයාත්මක කොර්පුස් වලින්  ඉක්මනින් වේගයෙන් විස්තර විස්තර කරපු ස්ථානයක් වගේ, ප්\u200dරස්තූත COVID-19 ස්ථානය වගේ, තොරතුරු පරීක්ෂණය අක්ෂේත්වය අඩුව අපි අපේ මෝඩේල් ප්\u200dරතික්\u200dරියා කරනවා මේ අඩු ප්\u200dරධාන භාෂාවට පරීක්ෂණය සහාය කරන්න. ඉන්දියානු භාෂාව භාවිතාවයේ සාමාජික මාධ්\u200dයම සමාජික මාධ්\u200dයමාධ්\u200dයම සඳහා පරීක්ෂණය ප්\u200dරකාශ කරනවා මො අපි රෝමාන්ජිත භාෂාවල් දහයකින් ප්\u200dරකාශ කරපු දත්ත සූදානම් සාමාජික මධ්\u200dයමාධ්\u200dයම විශ්ලේෂණ', 'so': 'India wuxuu ku yaalaa luqado badan oo ay ku hadlaan 30 mm ka badan. Luqadahan waxay muuqataa muuqasho muhiim ah oo ku yaala jardiinada shabakadda bulshada. However, several of these widely-used languages are under-addressed by current Natural Language Processing (NLP) models and resources.  Isticmaaluhu wuxuu si caadiga ah ugu qoran karraaniga Rooma oo ka gees ah karraaniga asalka ah oo ka sii faa’iidada ku saabsan itaalka nolosha. Qoraalkan waxaynu ugu yaraan qoraal NLP ah oo loo ilaaliyey si aan looga helno calaamado luuqada taageer ah oo laga helo koox badan oo ku saabsan jaamacadda bulshada Hindistan, kaasoo keena teknolojiyo aqoonsiga afka uu ku qoray sagaal af Romanized oo Indian ah. Xaaladaha cudurada ee degdega ah ee COVID-19 sida xaaladda joogtada ah, waxaa laga yaabaa in meelaha macluumaadka lagu baaraandegayo ay si adag ugu leeyihiin luuqadaha ka hooseeya ee degmooyinka aad u badan. Tusaalooyinkayada ayaannu u bixinnaa si aan u fududayno baaritaanka biyaha hoose ee luqadahan hoose ee noocyada badan. Imtixaamo badan oo shirkado sooshaalka ah oo kala duduwan ayaa muujiya qalabka tusaale ahaan, wuxuuna ka fidiyaa aragti badan oo xiiso badan oo ku saabsan noocyada isticmaalka luqada Hindiya ee ku jira shabakadda bulshada. Waxaannu u soo dirnaa macluumaad la taxeeyey oo ku qoran 1,000 comment oo ku qoran toban luuqadood oo Romanized ah sida bangiga qiimeynta macluumaadka bulshada.', 'sv': 'Indien är hem för flera språk med mer än 30 m talare. Dessa språk uppvisar betydande närvaro på sociala medier plattformar. Flera av dessa allmänt använda språk är dock underbehandlade av nuvarande modeller och resurser för Natural Language Processing (NLP). Användargenererat innehåll i sociala medier på dessa språk är också vanligtvis skrivet i romersk skrift till skillnad från det traditionella inhemska skriftet vilket ytterligare bidrar till resursbrist. I denna uppsats utnyttjar vi en minimalt övervakad NLP-teknik för att få svaga språketiketter från en storskalig indisk social media korpus vilket leder till en robust och anteckningseffektiv språkidentifieringsteknik som sträcker sig över nio romaniserade indiska språk. I snabbt spridande pandemisituationer som den nuvarande COVID-19-situationen kan informationsbehandlingsmålen vara starkt lutade mot underserverade språk i tätbefolkade regioner. Vi släpper våra modeller för att underlätta nedströmsanalyser på dessa lågresursspråk. Experiment över flera sociala medier corpora visar modellens robusthet och ger flera intressanta insikter om indiska språkanvändningsmönster på sociala medier. Vi publicerar en kommenterad datauppsättning med 1000 kommentarer på tio romaniserade språk som ett riktmärke för utvärdering av sociala medier.', 'ta': 'India is home to several languages with more than 30m speakers.  இந்த மொழிகள் சமூக ஊடகங்களில் முக்கியமான நிலைமையை காண்பிக்கின்றன. ஆனால், இந்த விரிவாக பயன்படுத்தப்பட்ட மொழிகள் தற்போதைய இயல்பான மொழி செயல்பாடு (NLP) மாதிரிகள் மற்றும் வளங்கள் மூலமாக முகவர பயனர் இந்த மொழிகளில் சமூக ஊடகங்களின் உள்ளடக்கங்களை உருவாக்கினார் ரோமான் சிறுநிரலில் வழக்கமாக ஆசிரிக்கப்பட்டுள்ளது ஆனால் பாரம்பரி இந்த காக்கியத்தில், நாம் ஒரு குறைந்தபட்ச கண்காணிக்கப்பட்ட NLP தொழில்நுட்பம் கொடுக்கிறோம் ஒரு பெரிய அளவு இந்தியன் சமூக ஊடக குறியீடுகளிலிருந்து பலவீனமான மொழிகள தற்போதைய COVID-19 நிலையில் வேகமாக விரிக்கும் பாதிப்பு நோய் நிலைகளில், தகவல் செயல்படுத்தல் குறிப்பிட்ட மொழிகளின் கீழே சேவைக்கப்பட நாம் எங்கள் மாதிரிகளை வெளியிடுகிறோம் இந்த குறைந்த மூலத்தின் மொழிகளில் ஆய்வுகளை பயன்படுத்தும். பல்வேறு சமூக ஊடகங்கள் நிறுவனத்திலுள்ள பரிசோதனைகள் மாதிரியின் ஆட்சியை காண்பிக்கிறது மற்றும் இந்திய மொழி பயன்பாட்டு மாதிர நாங்கள் பத்து ரோமானிசெய்யப்பட்ட மொழிகளில் 1,000 குறிப்பிட்ட தகவல் அமைப்பை வெளியிடுகிறோம் ஒரு சமூக ஊடகங்கள் பென', 'ur': 'هند کی تعداد زبانوں کے گھر ہے جو 30 م سے زیادہ سخنرانی کرنے والے ہیں۔ یہ زبانیں سوسیل میڈیا پٹرومٹوں پر اہم موجود موجود ہیں۔ However, several of these widely used languages are under-addressed by the current Natural Language Processing (NLP) models and resources. یہ زبانوں میں سوسیل میڈیا منصوبات پیدا کئے گئے ہیں اور ان کی نسبت رومین سکرپٹ میں بھی غیر معمولاً اجازت دی جاتی ہے اس کے مقابلہ میں کہ سنتی ملی سکرپٹ کے مقابلہ میں زیادہ سرمایہ کمزوری کے ساتھ کم اس کاغذ میں ہم ایک کم کم تحقیق کی NLP ٹیکنیک کو کمزور زبان لیبل حاصل کرنے کے لئے ایک بڑے اندھیرے سوسیل میڈیا کورپوس سے لگا رہے ہیں جو نین رومیناز هند زبانوں میں سے ایک طاقتور اور مضبوط زبان شناسایی ٹیکنیک کی طرف لے جاتا ہے۔ سریع پھیلانے والی مضبوط موقعیت میں جیسے موجود COVID-19 موقعیت، معلومات کی پردازی کا موقعیت بہت زیادہ خدمت کی زبانوں کی طرف مٹا سکتا ہے۔ ہم اپنی مدلکوں کو آزاد کریں گے کہ ان کم منبع زبانوں میں آسانی کریں۔ بہت سی سوسیل میڈیا کورپورا کی تجربے موڈل کی طاقت کو دکھاتے ہیں اور سوسیل میڈیا میں انڈی زبان استعمال الگوں کے بارے میں بہت سی دلچسپ نظر دیتے ہیں. ہم نے دس رومینال زبانوں میں ایک ہزار ٹیٹ کے ڈیٹ سٹے کو ایک سوسیل میڈیا ارزیابی بنچم کے طور پر آزاد کردیا ہے۔', 'ms': 'India adalah rumah untuk beberapa bahasa dengan lebih dari 30 meter pembicara. Bahasa ini menunjukkan kehadiran yang signifikan pada platform media sosial. Namun, beberapa bahasa yang digunakan secara luas ini dibawah-alamat oleh model dan sumber Pemprosesan Bahasa Alami (NLP) semasa. User generated social media content in these languages is also typically authored in the Roman script as opposed to the traditional native script further contributing to resource scarcity.  Dalam kertas ini, kami menggunakan teknik NLP yang paling terkawal untuk mendapatkan label bahasa yang lemah dari korpus media sosial India skala besar yang menyebabkan teknik pengenalan bahasa yang kuat dan efisien anotasi yang meliputi sembilan bahasa Indian Romanized. Dalam situasi pandemik yang menyebarkan dengan cepat seperti situasi COVID-19 semasa, tujuan pemprosesan maklumat mungkin sangat menuju ke bahasa yang tidak diberikan dalam kawasan yang padat. Kami melepaskan model kami untuk memudahkan analisis turun dalam bahasa sumber rendah ini. Eksperimen di seluruh korpora media sosial berbilang menunjukkan kekuatan model dan memberikan beberapa pandangan menarik tentang corak penggunaan bahasa India pada media sosial. We release an annotated data set of 1,000 comments in ten Romanized languages as a social media evaluation benchmark.', 'uz': "Hindiston 30 m dan ortiq gapiruvchilarga ko'p tillar uyga boradi. Bu tillar jamiyat media platformlarida juda muhim mavjud. Ammo, bu ko'pchilik foydalanilgan tillar Joriy tabiiy tilning boshqaruvchisi (NLP) modellari va rasmlari bilan murakkab qilinadi. Ushbu tillarda foydalanuvchi jamoam media tarkibi yaratganda, oddiy so'zlari Roman skriptda o'zgarishga yozuvchilar, tabiiy native skriptga qo'llanmalar manbani qanchalik qo'llashga yordam beradi. Bu qogʻozda biz ko'pchilikdan tashqarilgan NLP teknologiya yordam beramiz, bu juda katta ko'plab Hindiston jamiyatli medyaya bog'liqlaridan qo'llash uchun juda kichkina qo'llangan va tashqi va tashkilli tilni aniqlash teknologiya bo'ladi. Joriy COVID-19 holatida tez ajratilgan pandemik holatda, maʼlumot boshqarish maqolalari juda qisqarli bo'lgan tillarga qo'yish mumkin. Biz quyidagi modellarni o'chirib chiqaramiz, bu lavha rasmlar tilidagi analyzerni foydalanishimiz mumkin. Ko'pchilik jamiyatli medya kompaniyalaridagi tajribalar modelning o'xshasini ko'rsatadi va bulisi media'da Hindiston tilidan foydalanish modellarini ko'p qiziqarli ko'plab ko'rinadi. Biz 10 Romaniz tilda taʼminlov qilingan ma'lumotlar tarkibini jamiyat medya qiymatlarini saqlash imkoniyati deb chiqaramiz.", 'vi': 'Ấn Độ là quê hương của nhiều ngôn ngữ hơn 30m. Những ngôn ngữ này hiện diện đáng kể trên nền truyền thông xã hội. Tuy nhiên, nhiều ngôn ngữ được sử dụng phổ biến không được cập nhật bởi các mẫu và nguồn tài nguyên của bộ máy xử lý ngôn ngữ tự nhiên. Thông tin truyền thông xã hội người dùng tạo ra trong các ngôn ngữ này cũng thường được tạo ra trong văn bản La Mã thay vì kịch bản bản bản bản địa truyền thống góp phần thêm vào việc khan hiếm tài nguyên. Trong tờ giấy này, chúng tôi dùng một kĩ thuật lP ít được giám sát để đạt được những nhãn hiệu ngôn ngữ yếu từ một tập thể mạng xã hội lớn của Ấn Độ, dẫn đến một kỹ thuật nhận dạng ngôn ngữ mạnh mẽ và chú ý hiệu quả cho chín ngôn ngữ Ấn Độ Romanized. Trong tình huống đại dịch lây lan nhanh như COVID-19 hiện nay, mục tiêu xử lý thông tin có thể bị nghiêng về phía các ngôn ngữ chưa được phục vụ tại vùng đông dân cư. Chúng tôi phát hành các mẫu để dễ phân tích xuôi dòng trong các ngôn ngữ ít tài nguyên này. Thí nghiệm trên nhiều phương tiện truyền thông xã hội chứng minh s ự kiên trì của mô hình và cung cấp vài nhận thức thú vị về cách sử dụng ngôn ngữ Ấn Độ trên các phương tiện xã hội. Chúng tôi công bố một bộ dữ liệu ghi chú có ghi chú 1,000 bình luận bằng mười ngôn ngữ Romanized như tiêu chuẩn đánh giá phương tiện xã hội.', 'bg': 'Индия е дом на няколко езика с повече от 30 милиона говорители. Тези езици показват значително присъствие в социалните медии. Въпреки това, няколко от тези широко използвани езици са недостатъчно разгледани от настоящите модели и ресурси за обработка на естествени езици. Създадено от потребителите социални медии съдържание на тези езици обикновено е написано в римската писменост, за разлика от традиционната майчина писменост, което допълнително допринася за недостиг на ресурси. В тази статия използваме минимално контролирана техника за НЛП, за да получим слаби езикови етикети от мащабен индийски корпус в социалните медии, водеща до стабилна и ефективна техника за идентификация на езика, обхващаща девет романизирани индийски езика. В бързо разпространени пандемични ситуации като настоящата ситуация целите за обработка на информацията могат да бъдат силно наклонени към недостатъчно обслужвани езици в гъсто населени райони. Ние пускаме нашите модели, за да улесним анализите надолу по веригата на тези езици с ниски ресурси. Експериментите в множество корпорации в социалните медии демонстрират здравината на модела и предоставят няколко интересни прозрения за моделите на използване на индийски език в социалните медии. Публикуваме анотиран набор от данни от 1000 коментара на десет романизирани езика като референтна база за оценка на социалните медии.', 'nl': "India is de thuisbasis van verschillende talen met meer dan 30m sprekers. Deze talen vertonen een aanzienlijke aanwezigheid op sociale media platforms. Sommige van deze veelgebruikte talen worden echter onvoldoende aangepakt door de huidige Natural Language Processing (NLP)-modellen en -bronnen. Gebruikers gegenereerde social media content in deze talen is ook typisch geschreven in het Romeinse schrift in tegenstelling tot het traditionele native script dat verder bijdraagt aan de schaarste van hulpbronnen. In dit artikel gebruiken we een minimaal begeleide NLP-techniek om zwakke taallabels te verkrijgen van een grootschalig Indiaas social media corpus, wat leidt tot een robuuste en annotatie-efficiënte taal-identificatie techniek die negen geromaniseerde Indiase talen omvat. In snel verspreidende pandemiesituaties zoals de huidige COVID-19-situatie kunnen de doelstellingen voor informatieverwerking sterk worden gekanteld naar talen die in dichtbevolkte regio's te weinig worden bediend. We geven onze modellen uit om downstream analyses in deze low-resource talen te vergemakkelijken. Experimenten met meerdere social media corpora's tonen de robuustheid van het model aan en bieden verschillende interessante inzichten over Indiase taalgebruikspatronen op sociale media. We publiceren een geannoteerde dataset van 1.000 commentaren in tien geromaniseerde talen als een evaluatiebenchmark voor sociale media.", 'da': 'Indien er hjemsted for flere sprog med mere end 30 millioner talere. Disse sprog udviser betydelig tilstedeværelse på sociale medier platforme. Men flere af disse udbredte sprog er underbehandlet af nuværende Natural Language Processing (NLP) modeller og ressourcer. Brugernes indhold på sociale medier på disse sprog er også typisk forfattet i romersk skrift i modsætning til det traditionelle oprindelige skrift, der yderligere bidrager til ressourceknaphed. I denne artikel udnytter vi en minimalt overvåget NLP-teknik til at opnå svage sprogetiketter fra et stort indisk korpus på sociale medier, hvilket fører til en robust og annotationseffektiv sprogidentifikationsteknik, der spænder over ni romaniserede indiske sprog. I hurtigt spredte pandemisituationer som f.eks. den nuværende COVID-19-situation kan informationsbehandlingsmål være stærkt tilpasset til underbetjente sprog i tætbefolkede regioner. Vi frigiver vores modeller for at lette downstream analyser på disse lav ressource sprog. Eksperimenter på tværs af flere sociale medier corporate demonstrerer modellens robusthed og giver flere interessante indsigter i indiske sprogbrugsmønstre på sociale medier. Vi udgiver et annoteret datasæt med 1.000 kommentarer på ti romaniserede sprog som benchmark for evaluering af sociale medier.', 'hr': 'Indija je dom nekoliko jezika sa više od 30 m govornika. Ovi jezici pokazuju značajno prisustvo na platformama društvenih medija. Međutim, nekoliko tih široko korišćenih jezika su pod adresom trenutnih modela i resursa procesa prirodnog jezika (NLP). Korisnik proizveden sadržaj društvenih medija na ovim jezicima također je obično ovlašten u rimskom skriptu, suprotno tradicionalnom domaćem skriptu koji dalje doprinosi nedostatku resursa. U ovom papiru, uključivali smo minimalno nadzirenu tehniku NLP-a kako bi dobili slabe jezičke etikete iz velikog Indijskog društvenog medijskog korpusa koji vodi do jake i annotacijske tehnike identifikacije jezika koja se širi od devet rumunskih Indijskih jezika. U brzom širenju pandemijskih situacija poput trenutne situacije COVID-19, ciljevi obrade informacija mogli bi biti teško uključeni prema neposluženim jezicima u gustoj populaciji regija. Oslobodimo naše modele kako bi olakšali niz analizu na ovim jezicima niskih resursa. Eksperimenti u višestrukom društvenom medijskom korporaciji pokazuju snagu modela i pružaju nekoliko zanimljivih uvida o uzorcima korištenja indijskih jezika na društvenim medijima. Mi objavljujemo navodni skup podataka od 1000 komentara na deset rumunjskih jezika kao kritičar za procjenu socijalnih medija.', 'de': 'Indien ist die Heimat mehrerer Sprachen mit mehr als 30m Lautsprechern. Diese Sprachen zeigen eine bedeutende Präsenz auf Social Media Plattformen. Allerdings werden einige dieser weit verbreiteten Sprachen von aktuellen Natural Language Processing (NLP)-Modellen und Ressourcen unterbewertet. User generierte Social Media Inhalte in diesen Sprachen werden auch typischerweise in der römischen Schrift verfasst, im Gegensatz zur traditionellen nativen Schrift, die weiter zur Ressourcenknappheit beiträgt. In diesem Beitrag nutzen wir eine minimal überwachte NLP-Technik, um schwache Sprachlabels aus einem großen indischen Social Media Korpus zu erhalten, was zu einer robusten und annotationseffizienten Sprachidentifikationstechnik führt, die neun romanisierte indische Sprachen umfasst. In sich schnell ausbreitenden Pandemiesituationen wie der aktuellen COVID-19-Situation könnten die Ziele der Informationsverarbeitung stark in Richtung unterversorgter Sprachen in dicht besiedelten Regionen geneigt sein. Wir veröffentlichen unsere Modelle, um nachgelagerte Analysen in diesen ressourcenarmen Sprachen zu ermöglichen. Experimente in mehreren Social Media Corpora demonstrieren die Robustheit des Modells und liefern interessante Einblicke in indische Sprachgebrauchsmuster in sozialen Medien. Wir veröffentlichen einen kommentierten Datensatz von 1.000 Kommentaren in zehn romanisierten Sprachen als Bewertungsmaßstab für soziale Medien.', 'ko': '인도는 다양한 언어로 3천만 명이 넘는다.이 언어들은 소셜미디어 플랫폼에서 현저한 영향력을 보이고 있다.그러나 현재의 자연 언어 처리(Natural Language Processing, NLP) 모델과 자원은 그 중 일부 광범위하게 사용되는 언어에 대한 처리가 부족하다.이러한 언어에서 사용자가 생성한 소셜 미디어 내용도 통상적으로 로마 문자로 작성된 것이지 전통적인 현지 문자로 작성된 것이 아니기 때문에 자원의 부족을 초래했다.본고에서 우리는 최소 감독 NLP 기술을 이용하여 대규모 인도 소셜미디어 자료 라이브러리에서 약한 언어 라벨을 얻어 건장하고 주석이 효율적인 언어 식별 기술을 실현했다. 이 기술은 9가지 로마화 인도 언어를 뛰어넘었다.급속히 퍼지는 팬데믹(세계적 대유행) 상황에서 현재의 코로나 상황과 같이 정보 처리 목표는 인구가 조밀한 지역에서 서비스가 부족한 언어로 심각하게 기울어질 수 있다.우리는 이런 저자원 언어로 하류 분석을 하기 위해 우리의 모델을 발표했다.여러 개의 소셜 미디어 자료 라이브러리의 실험은 이 모델의 안정성을 증명했고 소셜 미디어에서 인도 언어 사용 모델에 대한 흥미로운 견해를 제공했다.우리는 10가지 로마어를 소셜 미디어 평가 기준으로 1000개의 주석을 포함하는 데이터 집합을 발표했다.', 'id': 'India adalah rumah untuk beberapa bahasa dengan lebih dari 30 meter pembicara. Bahasa-bahasa ini menunjukkan kehadiran yang signifikan di platform media sosial. Namun, beberapa bahasa yang sering digunakan ini dibawah pengaturan oleh model dan sumber daya Proses Bahasa Alam (NLP) saat ini. Konten media sosial yang dihasilkan oleh pengguna dalam bahasa-bahasa ini juga biasanya ditulis dalam skrip Romawi sebaliknya skrip asli tradisional yang lebih berkontribusi ke kekurangan sumber daya. Dalam kertas ini, kami menggunakan teknik NLP yang minimal diawasi untuk mendapatkan label bahasa yang lemah dari korpus media sosial India skala besar yang menyebabkan teknik pengenalan bahasa yang kuat dan efisien anotasi yang meliputi sembilan bahasa Indian romanis. Dalam situasi pandemic yang menyebar dengan cepat seperti situasi COVID-19 saat ini, tujuan proses informasi mungkin sangat menuju bahasa yang tidak diberikan dalam daerah yang sangat penduduk. Kami melepaskan model kami untuk memudahkan analisis turun dalam bahasa sumber daya rendah ini. Eksperimen melalui banyak korpora media sosial menunjukkan kekuatan model dan menyediakan beberapa pandangan menarik tentang pola penggunaan bahasa India di media sosial. Kami melepaskan set data annotasi dari 1.000 komentar dalam sepuluh bahasa romanis sebagai benchmark evaluasi media sosial.', 'sw': 'India ni nyumbani kwa lugha kadhaa yenye wazungumzaji zaidi ya mita 30. Lugha hizi zinaonyesha uwepo mkubwa katika majukwaa ya mitandao ya kijamii. Hata hivyo, baadhi ya lugha hizi zinazotumiwa kwa kiasi kikubwa zinazungumzwa na michoro na rasilimali ya sasa ya Utarabuni (NLP). Mtumiaji huyo alitengeneza maudhui ya mitandao ya kijamii katika lugha hizi kwa kawaida pia anaandikwa katika kitabu cha Roman kama kinyume na kitabu cha kitamaduni cha asili kinachochangia kwa gharama za rasilimali. Katika karatasi hii, tunatumia teknolojia inayofuatiliwa kwa kiasi kidogo ya NLP ili kupata mabango ya lugha dhaifu kutoka kwenye makampuni makubwa ya mitandao ya kijamii ya India yanayopelekea teknolojia yenye utambulisho wa lugha tisa za Kihindi wenye asili ya Kihindi. Katika hali ya maambukizi yanayoenea haraka kama vile hali ya sasa ya COVID-19, malengo ya upasuaji wa taarifa yanaweza kutumiwa vibaya kwa lugha zinazotumika katika maeneo mengi ya watu. Tunaachia mifano yetu ili kusaidia uchambuzi wa mito chini katika lugha hizi zenye rasilimali ndogo. Majaribio katika kampuni mbalimbali ya mitandao ya kijamii yanaonyesha nguo ya muundo huo na kutoa mitazamo kadhaa ya kuvutia kuhusu namna ya matumizi ya lugha ya Kihindi katika mitandao ya kijamii. Tunaweza kuachia taarifa zilizotajwa na maoni 1,000 katika lugha kumi za KiRomanized kama bendera ya uchunguzi wa mitandao ya kijamii.', 'fa': 'هند به چند زبان با بیشتر از 30م سخنرانی خونه است. این زبانها موجودات بزرگی را در platformهای رسانه\u200cهای اجتماعی نشان می\u200cدهند. با این حال، چندین از این زبان\u200cهای وسیع استفاده شده از طریق مدل\u200cها و منابع\u200cهای پردازش زبان طبیعی (NLP) فعلی زیر نشان داده می\u200cشوند. استفاده از محتوای رسانه اجتماعی تولید شده در این زبان معمولاً در نوشته رومی در مقابل نوشتهٔ منطقه منطقه سنتی که بیشتر به کمبود منابع کمک می\u200cکند اجازه می\u200cدهد. در این کاغذ، ما یک تکنیک NLP را کمترین کنترل می\u200cکنیم تا نقاشی زبان ضعیف را از یک شرکت رسانه\u200cهای اجتماعی هند بزرگ برگیریم که به یک تکنیک شناسایی زبان\u200cهای قوی و تاثیر قابل توجه به نو زبان\u200cهای هند رومانی می\u200cشود. در موقعیت\u200cهای سریع گسترش پاندوم مثل موقعیت COVID-19 فعلی، هدف\u200cهای پرداخت اطلاعات ممکن است بسیار سنگین به سمت زبانهای زیر خدمت در منطقه\u200cهای بسیار محلوم باشد. ما مدل\u200cهایمان را آزاد می\u200cکنیم تا آسان تحلیل\u200cهای پایین در این زبان\u200cهای کم منابع باشد. تجربه\u200cهایی در شرکت\u200cهای رسانه\u200cهای اجتماعی چندتا نشان می\u200cدهند استواری مدل و تعدادی مشاهده\u200cهای جالبی در مورد الگوهای استفاده از زبان هندی در رسانه\u200cهای اجتماعی را می\u200cدهند. ما یک مجموعه داده\u200cهای نوشته شده از 1000 توضیح در ده زبان رومانی به عنوان یک مقدار ارزیابی رسانه\u200cهای اجتماعی آزاد می\u200cکنیم.', 'tr': "Hindistan 30 metrden k철p diller bilen 철첵de. Bu diller sosyal medya platformlarynda m철h체m bolmagy g철rke첵채r. 횦철ne bu 첵agda첵da ullan첵an dilleri흫 birn채챌e g철rn체힊leri h채zirki Tebi첵al Dil i힊le첵i힊i (NLP) nusgalar we 챌e힊meler tarapyndan aladalan첵ar. Ullan챌y bu dillerde sosial medi첵any흫 maglumatyny d철redi. Bu dillerde hem adat챌a Roma skriptde d채pli 첵erli skriptleri흫 체stine 첵az힊y 첵agda첵da, ressursy흫 첵ok bolmagyna k철mekle첵채r. Bu kagyzda, biz NLP'i i흫 uly derejede g철rkezil첵채n Hindistan sosyal med첵asyny흫 k철p체sinden zay캇f dil etiketlerini almak 체챌in i흫 az y철n체nde g철zle첵채n bir tekniki 체첵tged첵채ris. 9-nji Romatlandyryl첵채n Hindistan dilinden uzakla힊an, g체첵챌li we t채sirli dil-tany힊a H채zirki COVID-19 첵aly pandemik m철h체mlerinde, informasi첵a i힊le첵채n maksadlary 챌ykyp bilim alyndaky dillere gollanm캇힊 b철lgelerde 첵okary 챌ykaryp biler. Bizi흫 modellerimizi bu i흫 k철p resurslarda analyzlary a흫sat etmek 체챌in 챌ykar첵arys. Birn채챌e sosyal med첵채 korporatyny흫 철r채n tejribeleri nusgany흫 g체첵챌lidigini g철rkez we sosyal med첵채d채ler barada Hindistany흫 dillerini흫 ullany힊y barada birn채챌e gyzykly pikirleri berer. Biz on Romanized dilinde bilim sistemasynda bildirilen 1.000 terjime d체z체mlerini sosial medi첵a de휓erlendirmegi h철km체nde 챌ykar첵arys.", 'af': "Indië is huis na verskeie tale met meer as 30 m sprekkers. Hierdie tale vertoon betekende voorsiening op sosiale media platforme. Maar sommige van hierdie vaste gebruikte taal is onder-adres deur huidige Natuurlike Taal Prosessering (NLP) modele en hulpbronne. Gebruiker genereer sosiale media inhoud in hierdie taal is ook tipies in die Romeine skrip oorgeskryf teenoor die tradisionele natuurlike skrip wat verder bydraai tot hulpbron ontbreiding. In hierdie papier het ons 'n minimaal ondersoekte NLP-teknike aangeneem om swakke taal etikette te te kry van 'n groot-skaal Indiese sosiale media korpus wat lei na 'n robust en annotasie-effektief taal-identifikasie tekniks wat nege Romaniseerde Indiese taal spandeer. In vinnige verspreiding pandemiese situasies soos die huidige COVID-19 situasie, kan inligting verwerking objekte swaar tydelik wees na onder-gedien tale in diepste populeer regione. Ons verlos ons modele om onderstreem analisies in hierdie lae hulpbron tale te maak. Eksperimente oor veelvuldige sosiale media korpora vertoon die model se kragtigheid en verskaf verskeie interessante insigte oor indiese taal gebruik patrone op sosiale media. Ons verlaat 'n notateerde data stel van 1000 kommentaar in tien Romaniseerde tale as 'n sosiale media evalueringsbenchmark.", 'am': 'ህንድ ከ30 ሚትር በላይ ቋንቋዎች ጋር ለብዙ ቋንቋዎች ቤት ነው፡፡ እነዚህ ቋንቋዎች ማኅበራዊ አውታር ሚዲያ መድረክ ላይ ታላቅ ግንኙነት ያሳያል፡፡ ምንም እንኳን፣ ከእነዚህ ብዙዎች በተጠቃሚ ቋንቋዎች በአሁኑ የዳርቻዊ ቋንቋ ፕሮግራም (NLP) ሞዴላዎችን እና ሀብት የተጨማሪዎች ናቸው፡፡ ተጠቃሚው በዚህ ቋንቋዎች ማኅበራዊ ሚዲያ ጥናት በመጠቀም በሮማዊ ጽሕፈት ላይ በተቃወመ የባሕላዊ የአገር ጽሑፍ ከሀብት ድህነትን ለመጠቀም የሚጠቅምበት ተቃዋሚ ነው፡፡ In this paper, we leverage a minimally supervised NLP technique to obtain weak language labels from a large-scale Indian social media corpus leading to a robust and annotation-efficient language-identification technique spanning nine Romanized Indian languages.  የአሁኑ COVID-19 ሁኔታ እንዳለ ፈጥኖ የደዌብ ጉዳይ፣ የመረጃ አቃውሞ በተጨማሪው በአካባቢ ክልሎች ውስጥ በተገኘው ቋንቋዎች ላይ በተጨማሪው ሊገኙ ይችላል፡፡ የውሃ አዳራሽ የክፍለ ሀብት ቋንቋዎች ምሳሌዎችን ለማድረግ እናስቀምጣለን፡፡ በብዙ ማኅበራዊ ሚዲያ ኮሬፖር የሞዴል ልብስ ያሳያል እና በማኅበራዊ አውታር ላይ የህንድ ቋንቋ የተጠቃሚ ምሳሌዎችን የሚያስፈልጋል፡፡ በአሥር ሮማኒያዊ ቋንቋዎች ላይ የአንድ ሺህ የድምፅ ማኅበራዊ ሚዲያ ማህበራዊ ሚዲያ ማህበራዊ ሚዲያ ማህበራዊ ድምፅ ማረጋገጫን እናስወግዳለን፡፡', 'az': 'Hindistan 30 m üstündən çox dillərin evidir. Bu dillər sosyal media platformlarında möhkəm varlığı göstərir. Lakin bu çox geniş dillərin çoxluğu təbiətli Dil işləməsi (NLP) modelləri və resursları tərəfindən istifadə edilir. İstifadəçi bu dillərdə sosyal media məlumatı yaratdı və bu dillərdə Roman skriptində daha çox qüvvətli yerli skriptə istifadə edilir. Bu kağızda, biz ən çox ölçülü Hindistan sosyal media korpusundan zəif dil etiketlərini almaq üçün minimal gözləyirli NLP teknikini yaradırıq ki, 9 Romalı Hindistan dilindən genişlənir. Şimdiki COVID-19 vəziyyəti kimi hızlı genişləndirilən pandemik məqsədilərdə, məlumat işləmə məqsədiləri çəkilmək məqsədilərdə çox çətin dillərə istifadə edilə bilər. Biz modellərimizi bu düşük ressurs dillərində analizi asanlaşdırmaq üçün yayındırırıq. Müxtəlif sosyal media korporasının təcrübələri modelinin gücünü göstərir və sosyal media içində Hindistan dillərin istifadə etdiyi növbənöv maraqlı təcrübələrini göstərir. Biz on Romalı dillərdə 1000 məlumat qurmasını sosyal media değerlendirmələri olaraq yayındırırıq.', 'bn': 'ভারত ৩০ মিটারের বেশী ভাষায় বাড়ি আছে। এই ভাষাগুলো সামাজিক প্রচার মাধ্যমের প্ল্যাটফর্মে গুরুত্বপূর্ণ উপস্থিতি প্রদর্শন করে। তবে বর্তমান প্রাকৃতিক ভাষা প্রক্রিয়া (এনএলপি) মডেল এবং সম্পদ নিয়ে বেশ কয়েকটি ব্যবহৃত ভাষাগুলোর নীচে আলোচনা করা হয়েছে। এই ভাষায় ব্যবহারকারীরা সামাজিক মিডিয়া বিষয়বস্তু তৈরি করেছেন, সাধারণত রোমান স্ক্রিপ্টে প্রথাগত স্থানীয় স্ক্রিপ্টের বিরু এই কাগজটিতে আমরা নিয়মিতভাবে পর্যবেক্ষিত এনএলপি প্রযুক্তি প্রদান করি যাতে ভারতীয় সামাজিক মিডিয়া কোর্পাস থেকে দুর্বল ভাষার লেবেল পাওয়া যায় যার ফলে দুর্বল ভাষ বর্তমান কোভিড-১৯ পরিস্থিতির মত দ্রুত ব্যাঙ্গের পরিস্থিতিতে তথ্য প্রক্রিয়ার উদ্দেশ্য গভীর জনপ্রিয় এলাকায় সেবা ভাষার দিকে বেশী  আমরা আমাদের মডেল ছেড়ে দিচ্ছি এই কম সম্পদের ভাষায় বিশ্লেষণের জন্য। বেশ কয়েকটি সামাজিক মিডিয়া কোর্পোরায় অভিজ্ঞতা এই মডেলের পোশাক প্রদর্শন করে এবং সামাজিক মিডিয়াতে ভারতীয় ভাষার ব্যবহারের প্রতি আমরা ১০ রোমানিজ ভাষায় একটি বিস্তারিত তথ্য সংক্রান্ত ভাষায় ১০০০ মন্তব্য প্রকাশ করি যা সামাজিক মিডিয়া মূল্যায়নে', 'hy': "India is home to several languages with more than 30m speakers.  Այս լեզուները նշանակալի ներկայություն են ցույց տալիս սոցիալական լրատվամիջոցների հարթակներում: Այնուամենայնիվ, այս լայնորեն օգտագործված լեզուներից մի քանի լեզուներ ներկայիս բնական լեզվի մշակումների և ռեսուրսների կողմից թերբ են վերաբերվում: Օգտագործողը ստեղծել է սոցիալական լրատվամիջոցների պարունակությունը այս լեզուներում, սովորաբար նաև գրված է ռոմեական գրվածքում, ի հակառակ ավանդական բնիկ գրվածքին, որը ներդրում է ռեսուրսների պակաս: Այս թղթի մեջ մենք օգտագործում ենք նվազագույն վերահսկվող ՆԼՊ-ի տեխնիկան, որպեսզի ստանանք թույլ լեզվի պիտակներ հնդկական սոցիալական լրատվամիջոցների մեջ, որոնք հանգեցնում են ուժեղ և նշումների արդյունավետ լեզվի հայտնաբերման տեխնի Հիմա արագ տարածվող պանդեմիական իրավիճակներում, ինչպիսիք են COVID-19 ներկայիս իրավիճակը, տեղեկատվության վերաբերյալ նպատակները կարող են ուժեղ հաղորդակցվել դեպի թերծառայված լեզուներ խտուն բնակչության տարածքներում: Մենք հրապարակում ենք մեր մոդելները, որպեսզի հեշտացնենք ցածր ռեսուրսների լեզուներում վերլուծությունները: Experiments across multiple social media corpora demonstrate the model's robustness and provide several interesting insights on Indian language usage patterns on social media.  Մենք հրապարակում ենք 1,000 մեկնաբանությունների գրված տվյալներ տասը ռոմանիզացված լեզուներում որպես հասարակական լրատվամիջոցների գնահատման համեմատակ:", 'bs': 'Indija je dom nekoliko jezika sa više od 30 m govornika. Ovi jezici pokazuju značajno prisustvo na platformama društvenih medija. Međutim, nekoliko tih široko korišćenih jezika su pod adresom trenutnih modela i resursa procesa prirodnog jezika (NLP). Korisnik proizveden sadržaj socijalnih medija na ovim jezicima je također obično autoriziran u rimskom skriptu, suprotno tradicionalnom domaćem skriptu koji dalje doprinosi nedostatku resursa. U ovom papiru, uključujemo minimalno nadgledanu tehniku NLP-a kako bi dobili slabe jezičke etikete iz velikog Indijskog društvenog medijskog korpusa koji vodi do jake i annotacijske tehnike identifikacije jezika koja širi devet rumunskih Indijskih jezika. U brzom širenju pandemijskih situacija poput trenutne situacije COVID-19, ciljevi obrade informacija mogli bi biti teško uključeni prema neposluženim jezicima u gustoj populaciji regiona. Puštamo naše modele da olakšamo analizu u ovim jezicima niskih resursa. Eksperimenti u višestrukom društvenom medijskom korporaciji pokazuju robustnost modela i pružaju nekoliko interesantnih uvida o obrascima korištenja indijskih jezika na društvenim medijima. Mi objavljujemo annotiran set podataka od 1000 komentara na deset rumunskih jezika kao referent za procjenu socijalnih medija.', 'cs': 'Indie je domovem několika jazyků s více než 30m mluvčími. Tyto jazyky vykazují významnou přítomnost na platformách sociálních médií. Nicméně, několik z těchto široce používaných jazyků je nedostatečně řešeno současnými modely a zdroji zpracování přirozeného jazyka (NLP). Obsah sociálních médií generovaný uživatelem v těchto jazycích je také typicky vytvořen v římském písmu na rozdíl od tradičního rodného písma, který dále přispívá k nedostatku zdrojů. V tomto článku využíváme minimálně dohledovanou techniku NLP k získání slabých jazykových značek z rozsáhlého indického korpusu sociálních médií, což vede k robustní a anotačně efektivní technice jazykové identifikace zahrnující devět romských indických jazyků. V rychle se šířících pandemických situacích, jako je současná situace COVID-19, mohou být cíle zpracování informací silně nakloněny k nedostatečně obsluhovaným jazykům v hustě osídlených regionech. Vydáváme naše modely, abychom usnadnili následné analýzy v těchto jazycích s nízkými zdroji. Experimenty napříč mnoha korpusy sociálních médií demonstrují robustnost modelu a poskytují několik zajímavých poznatků o vzorcích používání indického jazyka na sociálních médiích. Jako měřítko hodnocení sociálních médií vydáváme anotovaný datový soubor tisícových komentářů v deseti romských jazycích.', 'ca': "L'Índia està a casa de diverses llengües amb més de 30 metres d'orators. Aquestes llengües mostran una presença significativa a les plataformes dels mitjans socials. No obstant això, moltes d'aquestes llengües generalment utilitzades són sota-abordades pels models i recursos actuals de processament de llengües naturals (NLP). El contingut dels mitjans socials generat per l'usuari en aquestes llengües també és típicament escrit a l'escriptura romana en comptes de l'escriptura tradicional nativa que contribueix més a l'escassetat de recursos. En aquest paper, utilitzem una tècnica de NLP minimament supervisada per obtenir etiquetes de llenguatge dèbils d'un corps de mitjans socials indians a gran escala que porta a una tècnica d'identificació de llenguatges robusta i eficient en l'anotació que abarca nou llenguatges indians romanitzats. En situacions de pandèmia que s'estenen ràpidament com la actual situació COVID-19, els objectius de processament d'informació podrien estar molt inclinats cap a llengües que no serveixen gaire en regiones densament poblades. Vam publicar els nostres models per facilitar l'anàlisi downstream en aquestes llengües de baix recursos. Els experiments de múltiples corpores de mitjans social s demostren la robustet del model i proporcionen diverses comprensions interessants sobre els patrons d'ús del llenguatge índic als mitjans socials. Vam publicar un conjunt de dades anotats de 1.000 comentaris en 10 llengües romanitzats com un punt de referència d'evaluació dels mitjans socials.", 'fi': 'Intiassa on useita kieliä, joilla on yli 30 miljoonaa puhujaa. Nämä kielet ovat vahvasti läsnä sosiaalisen median alustoissa. Useita näistä laajasti käytetyistä kielistä ei kuitenkaan käsitellä nykyisissä Natural Language Processing (NLP) -malleissa ja resursseissa. Käyttäjän luoma sosiaalisen median sisältö näillä kielillä on tyypillisesti kirjoitettu roomalaisella kirjoituskoneella, toisin kuin perinteinen natiivikirjoitus, joka lisää resurssien niukkuutta. Tässä artikkelissa hyödynnämme minimaalisesti valvottua NLP-tekniikkaa saadaksemme heikkoja kielimerkkejä laajasta intialaisesta sosiaalisen median korpusesta, mikä johtaa vankkaan ja huomautustehokkaan kielen tunnistustekniikkaan, joka kattaa yhdeksän romanisoitua intialaista kieltä. Nopeasti leviävissä pandemiatilanteissa, kuten nykyisessä COVID-19-tilanteessa, tietojenkäsittelyn tavoitteet saattavat kallistua voimakkaasti heikosti palveleviin kieliin tiheästi asutuilla alueilla. Julkaisemme mallit helpottamaan loppupään analyyseja näillä vähäresurssisilla kielillä. Kokeet useissa sosiaalisen median korporaatioissa osoittavat mallin kestävyyden ja tarjoavat useita mielenkiintoisia näkemyksiä intialaisen kielen käyttötavoista sosiaalisessa mediassa. Julkaisemme sosiaalisen median arviointivertailukohdaksi 1 000 kommenttia kymmenellä romanisoitulla kielellä.', 'et': 'Indias on koduks mitmetele keeltele rohkem kui 30 miljoni kõnelejaga. Need keeled esinevad sotsiaalmeedia platvormidel märkimisväärselt. Kuid mitmed neist laialdaselt kasutatavatest keeltest on praeguste looduskeelte töötlemise mudelite ja ressursside abil alati käsitletud. Kasutaja loodud sotsiaalmeedia sisu neis keeltes on tavaliselt kirjutatud ka rooma kirjaga, mitte traditsioonilise emakeelse kirjaga, mis aitab veelgi kaasa ressursside nappusele. Käesolevas töös kasutame minimaalselt järelevalvetud NLP tehnikat, et saada nõrgad keelelised märgised suuremahulisest India sotsiaalmeedia korpusest, mis viib tugeva ja annoteerimist tõhusa keele identifitseerimise tehnikani, mis hõlmab üheksat romaaniseeritud India keelt. Kiiresti levivates pandeemiaolukordades, nagu praegune COVID-19 olukord, võivad teabe töötlemise eesmärgid tihedalt asustatud piirkondades tugevalt kalduda alateenindatud keeltele. Me avaldame oma mudelid, et hõlbustada järgnevat analüüsi nendes vähese ressursiga keeltes. Mitme sotsiaalmeedia korporatsiooni eksperimendid näitavad mudeli tugevust ja annavad mitmeid huvitavaid ülevaateid India keele kasutamise mustritest sotsiaalmeedias. Avaldame sotsiaalmeedia hindamise võrdlusalusena 1000 kommentaari kümnes romaniseeritud keeles.', 'sq': "India is home to several languages with more than 30m speakers.  Këto gjuhë ekspozojnë prani të rëndësishme në platforma të medias sociale. Megjithatë, disa nga këto gjuhë të përdorura gjerësisht janë nëntrajtuar nga modelet dhe burimet aktuale të Procesimit të Gjuhave Natyrore (NLP). Përdoruesi krijoi përmbajtjen e medias sociale në këto gjuhë gjithashtu tipikisht është autoruar në skriptin romak në kundërshtim me skriptin tradicional vendas që kontribuon më tej në mungesën e burimeve. Në këtë letër, ne përdorim një teknikë minimalisht të mbikqyrur NLP për të marrë etiketa gjuhësh të dobëta nga një trup i madh i medias sociale indiane që shpie në një teknikë të fortë dhe të efektshme për të njohur identifikimin gjuhësh që përfshin nëntë gjuhë indiane të romanizuara. Në gjendje pandemike të shpejtë të përhapura si gjendja aktuale COVID-19, objektivat e përdorimit të informacionit mund të jenë shumë të prirura drejt gjuhëve të pakëputura në rajone me popullsi të dendur. Ne lëshojmë modelet tona për të lehtësuar analizat poshtë në këto gjuhë me burime të ulëta. Experiments across multiple social media corpora demonstrate the model's robustness and provide several interesting insights on Indian language usage patterns on social media.  Ne lëshojmë një sërë të dhënash të shënuara prej 1,000 komentesh në dhjetë gjuhë të romanizuara si një pikë referuese për vlerësimin e medias sociale.", 'ha': "India yana gida zuwa wasu harshe masu saurãre 30. Waɗannan harshen na nuna presence mai muhimmi a kan zangaren mitandaki na jamii. A lokacin da, wasu cikin harshen waɗanda aka yi amfani da waɗancan da ake yi wa amfani da su sunan-addu'a da misãlai da resource na aiki na Lugha na Natural yanzu (NLP). Mai amfani da ya ƙãga maɓallin mitandai da jamii a cikin wasu harshen, ana karatun shi a rubutun Rome kama da sãɓãni ga manuscriptn na danganci na danganta, yana ƙaranci zuwa manyan ci na ƙaranci. In a cikin wannan takardan, za mu sami wata tamkar NLP da aka yi tsaron da shi a minimum kodi don ka sami marubuci da harshen na Larabci na Hinduta daga makarantin mitandaki masu ƙaranci mai girma na Hindu, yana ƙara zuwa wani technci mai fassara da harshe-na'ura-da fassara na fassara da harshen na'ura tara. Aka cikin jarraba masu hushi na bukãta kamar dai halin COKID-19 yanzu, an yiwu an yi nau'i ga abun macẽtanci zuwa lugha da aka samar da shi cikin wurãre masu ciki. Munã sakar da misalinmu dõmin ya sauƙi analyi a ƙarami cikin lughan nan ƙasƙanci. Tajaroyi da ke cikin marubucin mitandaki masu yawa na nuna marubucin mitandaki kuma ya sanya masu sha'awi masu amfani da harshen India a kan mitandaya. Munã sakar da takardar data da aka sanar da shi a cikin harshen 10,000 da aka rubũta shi kamar bangon qiimaki ga mitandai da jamii.", 'jv': 'barang dadi karo akeh luwih dumadhi kanggo sabanjuré 30.m. Basa iki dadi neng akeh pisan neng pembang media sotiki. politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé butuhan resmi media sotiné ing dilané iki dadi aturan sak autor kanggo nggawe winih dhéwé ning basa Room kuwi bisa nguasai perusahaan seneng sapa-perusahaan sing nganggep bantuan ing pancene. Awak dhéwé éntuk nglanggar wigatining ketheke NLP nggawe luwih nguasai perusahaan winih sing nggawe barang basa sing nggawe barang-kalang basa banget tulip bantuan liya sing perusahaan ono nggawe nguasai luwih akeh h h nguasai perusahaan winih. politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé mbukaké model sing bisa perusahaan kanggo diandelaké apa-apa iki. User: Awak dhéwé éntuk mulasah akeh dolanan sing pernik 1.000 komentar kanggo tentang luwih rumani kanggo nggawe dolanan sing nggawe media soti.', 'he': 'הודו הוא בית לכמה שפות עם יותר מ-30 מטר רמקולים. These languages exhibit significant presence on social media platforms.  בכל אופן, כמה מהשפות הללו שמשתמשות בצורה רחבה מתעלמות על ידי דוגמנים ומשאבים של תהליך שפות טבעית (NLP) הנוכחים. תוכן התקשורת החברתית שנוצר ע"י המשתמש בשפות הללו אומרים גם בדרך כלל בתסריט הרומי בניגוד לתסריט המסורתי המקומי שמתורם עוד לחסר משאבים. בעיתון הזה, אנו משתמשים בטכניקת NLP שמבוטחת מינימלית כדי להשיג תוויות שפות חלשות ממתקן מדיה חברתית אינדיאנית בקנה מידה גדולה שמוביל לטכניקת זיהוי שפות חזקה ויעילה בהצבעה שמרחבת תשע שפות הודיות רומנות. במצבים פנדמיים מתפשטים במהירות כמו המצב COVID-19 הנוכחי, מטרות מעבדת מידע עלולות להיות מכוונות באופן כבד לכיוון שפות מתחת לשירות באזורים עמוקים. אנחנו משחררים את הדוגמנים שלנו כדי להקל ניתוחים למטה בשפות נמוכות אלה. ניסויים ברחבי גופות תקשורת חברתית רבות מראים את חזקותו של המודל ומספקים כמה תובנות מעניינות על דפוסי השימוש בשפה האינדיאנית בתקשורת חברתית. אנחנו משחררים קבוצת נתונים מועטפת של 1,000 תגובות בעשרה שפות רומנות כנקודת עריכה של התקשורת החברתית.', 'bo': 'རྒྱ་གར་ལ་མི་འབྱུང་བའི་སྐད་རིགས་མང་ཙམ་ཅན་གྱི་ནང་དུ་འགྲོ་བཞིན་ཡོད། སྐད་རིགས་འདི་དག་སྤྱི་ཚོགས ཡིན་ནའང་། སྐད་རིགས་འདི་དག་མང་པོ་ཞིག་ནི་ད་ལྟོའི་རང་བཞིན་གྱི་སྐད་ཡིག་ལས་སྤྱོད་ཀྱི་མིག་དཔེ་དབྱིབས་དང་རྒྱུ་ཆས User generated social media content in these languages is also typically authored in the Roman script as opposed to the traditional native script further contributing to resource scarcity. In this paper, we leverage a minimally supervised NLP technique to obtain weak language labels from a large-scale Indian social media corpus leading to a robust and annotation-efficient language-identification technique spanning nine Romanized Indian languages. ད་ལྟོའི་གནས ང་ཚོས་རང་གི་མིག་གཟུགས་རིས་སྐད་ཡིག་ཆ་ཉུང་བའི་དབྱེ་ཞིབ་ཀྱི་ཆ་རྐྱེན་ཏུ་སླ་གཏོང་བྱེད། སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྤྱི་ཚོགས་ཁང་གི་སྒེར་གྱི་སྒེར་གྱི་རྩིས་མཐུན་འགྱུར་བ་མང་ཙམ་སྟོན་པ་དང་། སྤྱི་ཚོགས་འབྲེལ་མཐུ ང་ཚོས་རོལ་མིའི་སྐད་རིགས་ནང་ལ་གསལ་བཀོད་པའི་ཆ་འཕྲིན་འགྲེལ་བཤད་ཀྱི་ཚགས་མ་གཅིག་གི་མཐོང་སྣང་བྱེད་ཀྱི་ཡོད།', 'sk': 'Indija je dom več jezikov z več kot 30 milijoni govornikov. Ti jeziki kažejo pomembno prisotnost na platformah socialnih medijev. Vendar pa obstoječi modeli in viri za obdelavo naravnih jezikov premalo obravnavajo številne od teh široko uporabljenih jezikov. Vsebine družbenih omrežij, ustvarjene v teh jezikih, so prav tako običajno avtorske v rimski pisavi, v nasprotju s tradicionalno materno pisavo, ki še dodatno prispeva k pomanjkanju virov. V tem prispevku uporabljamo minimalno nadzorovano tehniko NLP za pridobivanje šibkih jezikovnih oznak iz obsežnega indijskega korpusa družbenih medijev, kar vodi do robustne in z opombami učinkovite tehnike identifikacije jezika, ki zajema devet romaniziranih indijskih jezikov. V hitro širjenih pandemičnih razmerah, kot je trenutna situacija COVID-19, se lahko cilji obdelave informacij močno nagibajo k premalo uporabljenim jezikom v gosto poseljenih regijah. Naše modele objavljamo za lažje analize v teh jezikih z nizkimi viri. Eksperimenti v več korpusih družbenih omrežij kažejo robustnost modela in ponujajo več zanimivih vpogledov v indijske jezikovne vzorce na družbenih omrežjih. Kot referenčno merilo za ocenjevanje družbenih medijev objavljamo 1.000 komentarjev v desetih romaniziranih jezikih.'}
{'en': 'Fantastic Features and Where to Find Them : Detecting Cognitive Impairment with a Subsequence Classification Guided Approach', 'ar': 'الميزات الرائعة وأين يمكن العثور عليها: الكشف عن الضعف الإدراكي باستخدام نهج موجه للتصنيف اللاحق', 'es': 'Características fantásticas y dónde encontrarlas: detección del deterioro cognitivo con un enfoque guiado de clasificación de subsecuencias', 'pt': 'Recursos fantásticos e onde encontrá-los: detecção de deficiência cognitiva com uma abordagem guiada de classificação de subsequência', 'fr': "Caractéristiques fantastiques et où les trouver\xa0: détection des troubles cognitifs à l'aide d'une approche guidée par classification des sous-séquences", 'ja': '素晴らしい特徴とそれらを見つける場所：結果分類誘導型アプローチによる認知障害の検出', 'ru': 'Фантастические особенности и где их найти: обнаружение когнитивных нарушений с помощью подхода, ориентированного на последующую классификацию', 'zh': '妙质在何处,用子分类导', 'hi': 'शानदार विशेषताएं और उन्हें कहां खोजें: एक उप-अनुक्रम वर्गीकरण निर्देशित दृष्टिकोण के साथ संज्ञानात्मक हानि का पता लगाना', 'ga': 'Gnéithe Sármhaithe agus Cá háit a bhfaighidh siad iad: Lagú Cognaíoch a Bhrath le Cur Chuige Treoraithe Aicmithe Iarmhairtí', 'ka': 'ფანტაციური ფუნქციები და სად დაიძებნა: შემდეგ კლასიფიკაციის მოწყობინებული მიზედან კონტაციური შეცდომის განახლება', 'el': 'Φανταστικά χαρακτηριστικά και πού να τα βρείτε: Ανίχνευση γνωστικών διαταραχών με μια καθοδηγούμενη προσέγγιση ταξινόμησης υποακολουθίας', 'hu': 'Fantasztikus jellemzők és hol találjuk meg őket: Kognitív károsodás felismerése alszekvencia osztályozási irányított megközelítéssel', 'lt': 'Fantastinės savybės ir kur juos rasti: pažintinio sutrikimo nustatymas taikant tolesnio klasifikavimo metodą', 'it': "Caratteristiche fantastiche e dove trovarle: Rilevare l'alterazione cognitiva con un approccio guidato di classificazione in sottosezione", 'kk': 'Фантастикалық қасиеттер мен оларды қайда табу: келесі классификациялау бағытталған жағдайды анықтау', 'mk': 'Фантастични карактеристики и каде да ги најдеме: Детектирање на когнитивно оштетување со воден пристап кон класификацијата на потеквенцијата', 'ml': 'ഫാന്റിസ്റ്റിക്ക് വിശേഷതകളും അവയെ എവിടെ കണ്ടെത്തേണ്ടതും: സുബ്ബിക്കെന്\u200dസിങ്ങ് ക്ലാസിഷന്\u200d വഴികാട്ടിയുള്ള വഴികാട്', 'ms': 'Features Fantastic and Where to Find Them: Detecting Cognitive Impairment with a Subsequence Classification Guided Approach', 'mn': 'Гайхалтай боломжууд, тэднийг хаана олох вэ? Дараагийн дараа нь ойлголтын дараа нь ойлголтын тулд', 'mt': 'Karatteristiċi Fantastiċi u Fejn Jinstabu: Jinstabu Indeboliment Konjittiv b’Approċċ Gwida għall-Klassifikazzjoni tas-Sussegwenza', 'pl': 'Fantastyczne cechy i gdzie je znaleźć: Wykrywanie zaburzeń poznawczych za pomocą podsekwencyjnego podejścia', 'no': 'Fantastiske funksjonar og kor dei skal finna: Finn kognitiv verktøy med ein tilnærmingskolassifikasjon', 'ro': 'Caracteristici fantastice și unde să le găsiți: detectarea deficiențelor cognitive cu o abordare ghidată de clasificare a subsecvențelor', 'sr': 'Fantastične karakteristike i gde da ih nađemo: otkrivanje kognitivnog utjecaja sa navedenim pristupom klasifikacije sledeće', 'si': 'Fantastic Featuries and where to find them: Detected Coknowtive Impairment with a Next Classication guiding approach', 'so': 'Xuquuqda qoyska iyo meesha aad ka heli karto: Finnishka muwaadinka', 'sv': 'Fantastiska funktioner och var man hittar dem: upptäcka kognitiv försämring med en guidad metod för undersekvensklassificering', 'ta': 'சிறந்த பண்புகள் மற்றும் அவற்றை கண்டுபிடி', 'ur': 'اور ان کو کہاں پائیں: اس کے بعد جاننے والی سفارش کو معلوم کرنے والی سفارش کے ذریعہ', 'uz': 'Mavzuni topish', 'vi': 'Điều kiện tuyệt vời và Nơi tìm thấy: phát hiện tác động nhận thức với phương pháp hướng theo Hậu cần', 'bg': 'Фантастични характеристики и къде да ги намерим: откриване на когнитивни увреждания с ръководен подход за класификация на подпоследователността', 'da': 'Fantastiske funktioner og hvor man kan finde dem: detektering af kognitiv nedsættelse med en undersekvensklassificering guidet tilgang', 'hr': 'Fantastične karakteristike i gdje ih pronaći: otkrivanje kognitivnog oštećenja s navedenim pristupom klasifikacije sljedeće klasifikacije', 'nl': 'Fantastische kenmerken en waar ze te vinden zijn: detecteren van cognitieve stoornissen met een begeleide aanpak van subsequentieclassificatie', 'de': 'Fantastische Merkmale und wo sie zu finden sind: Erkennung kognitiver Beeinträchtigungen mit einem Subsequenz Classification Guided Approach', 'ko': '기묘한 특징 및 어디서 찾을 수 있는지: 하위 서열로 분류하여 지도하는 방법으로 인지장애를 검출한다', 'fa': 'ویژه\u200cهای شگفت\u200cانگیز و کجا برای پیدا کردن آنها: شناسایی تأثیر شناسایی با نزدیک راهنمایی به کلاس\u200cشناسایی بعدی', 'id': 'Features Fantastic and Where to Find them: Detecting Cognitive Impairment with a Subsequence Classification Guided Approach', 'sw': 'Tamko zuri na Kutafuta wapi: Kugundua Kushindwa kwa Utambulisho wa Kitambua na Kuongozwa', 'tr': 'Fantastik özellikler ve Bulmalılar Nerede: Bilişkin Etkileşimi Tarama', 'af': "Fantastiese eienskappe en waar hulle moet soek: Kognitiewe Imperasie met 'n Volgende Klassifikasie Gevorderde Toegang te vind", 'sq': 'Features Fantastic and Where to Find them: Detecting Cognitive Impairment with a Subsequence Classification Guided Approach', 'am': 'ምርጫዎች', 'hy': 'Հրաշալի առանձնահատկություններ և որտե՞ղ գտնել դրանք. ճանաչողական խնդիր հայտնաբերելը հետագայում դասակարգման ուղղությամբ', 'az': 'Fantastic Features and Where to find them: Detecting Cognitive Impairment with a subsequent Classification Guided Approach', 'bn': 'ফ্যাটাস্টিক বৈশিষ্ট্য এবং তাদের খুঁজে বের করা কোথায়: সাবেক্সেকেন্স পরিচালিত ক্লাসিকেশন পরিচালনা করা যায়', 'bs': 'Fantastične karakteristike i gdje ih pronaći: otkrivanje kognitivnog utjecaja sa navedenim pristupom klasifikacije sljedeće klasifikacije', 'ca': "Característiques fantàstiques i on trobar-los: Detectar l'impacte cognitiu amb un enfocament orientat a la classificació de la seqüència", 'cs': 'Fantastické vlastnosti a kde je najít: Detekce kognitivního poruchy pomocí podsekvenční klasifikace řízeného přístupu', 'et': 'Fantastilised omadused ja kust neid leida: kognitiivse häire tuvastamine alamjärjestuse klassifitseerimise juhendatud lähenemisviisi abil', 'fi': 'Fantastiset ominaisuudet ja niiden löytäminen: kognitiivisen häiriön havaitseminen alasekvenssiliikkeen luokittelun ohjatulla lähestymistavalla', 'jv': 'structural navigation', 'ha': 'KCharselect unicode block name', 'sk': 'Fantastične lastnosti in kje jih najti: odkrivanje kognitivnih motenj z vodenim pristopom klasifikacije podzaporedja', 'he': 'תמונות נפלאות ואיפה למצוא אותן: לגלות פגיעה מזהותית', 'bo': 'Fantastic Features and Where to Find them: Detecting Cognitive Impairment with a Subsequent Classification Guided Approach'}
{'en': 'Despite the widely reported success of embedding-based machine learning methods on natural language processing tasks, the use of more easily interpreted engineered features remains common in fields such as cognitive impairment (CI) detection. Manually engineering features from  noisy text  is time and resource consuming, and can potentially result in  features  that do not enhance  model  performance. To combat this, we describe a new approach to  feature engineering  that leverages sequential machine learning models and  domain knowledge  to predict which  features  help enhance performance. We provide a concrete example of this  method  on a standard data set of CI speech and demonstrate that CI classification accuracy improves by 2.3 % over a strong baseline when using  features  produced by this  method . This demonstration provides an example of how this method can be used to assist  classification  in fields where  interpretability  is important, such as  health care .', 'ar': 'على الرغم من النجاح الذي تم الإبلاغ عنه على نطاق واسع لطرق التعلم الآلي القائمة على التضمين في مهام معالجة اللغة الطبيعية ، إلا أن استخدام ميزات هندسية يسهل تفسيرها لا يزال شائعًا في مجالات مثل اكتشاف الضعف الإدراكي (CI). تستهلك هندسة الميزات من نص مزعج يدويًا الوقت والموارد ، ويمكن أن تؤدي إلى ميزات لا تعمل على تحسين أداء النموذج. لمكافحة هذا ، نصف نهجًا جديدًا لهندسة الميزات التي تستفيد من نماذج التعلم الآلي المتسلسلة ومعرفة المجال للتنبؤ بالميزات التي تساعد في تحسين الأداء. نقدم مثالًا ملموسًا لهذه الطريقة على مجموعة بيانات قياسية لخطاب CI ونوضح أن دقة تصنيف CI تتحسن بنسبة 2.3٪ على خط أساس قوي عند استخدام الميزات التي تنتجها هذه الطريقة. يقدم هذا العرض التوضيحي مثالاً على كيفية استخدام هذه الطريقة للمساعدة في التصنيف في المجالات التي يكون فيها التفسير مهمًا ، مثل الرعاية الصحية.', 'fr': "Malgré le succès largement rapporté des méthodes d'apprentissage automatique basées sur l'intégration dans les tâches de traitement du langage naturel, l'utilisation de fonctionnalités techniques plus faciles à interpréter reste courante dans des domaines tels que la détection des troubles cognitifs (IC). L'ingénierie manuelle des fonctions à partir de texte bruité demande beaucoup de temps et de ressources, et peut entraîner des fonctionnalités qui n'améliorent pas les performances du modèle. Pour lutter contre cela, nous décrivons une nouvelle approche de l'ingénierie des fonctionnalités qui s'appuie sur des modèles d'apprentissage automatique séquentiels et des connaissances du domaine pour prédire quelles fonctionnalités contribuent à améliorer les performances. Nous fournissons un exemple concret de cette méthode sur un ensemble de données standard de discours de CI et démontrons que la précision de la classification de l'IC s'améliore de 2,3\xa0% par rapport à une base de référence forte lors de l'utilisation des caractéristiques produites par cette méthode. Cette démonstration fournit un exemple de la façon dont cette méthode peut être utilisée pour faciliter la classification dans des domaines où l'interprétabilité est importante, tels que les soins de santé.", 'es': 'A pesar del éxito ampliamente reportado de los métodos de aprendizaje automático basados en la integración en las tareas de procesamiento del lenguaje natural, el uso de funciones de ingeniería más fáciles de interpretar sigue siendo común en campos como la detección de deterioro cognitivo (IC). La ingeniería manual de funciones a partir de texto ruidoso consume tiempo y recursos, y puede dar como resultado funciones que no mejoran el rendimiento del modelo. Para combatir esto, describimos un nuevo enfoque de la ingeniería de funciones que aprovecha los modelos de aprendizaje automático secuencial y el conocimiento del dominio para predecir qué funciones ayudan a mejorar el rendimiento. Proporcionamos un ejemplo concreto de este método en un conjunto de datos estándar de voz de CI y demostramos que la precisión de la clasificación de CI mejora en un 2.3% con respecto a una base de referencia sólida cuando se utilizan las características producidas por este método. Esta demostración proporciona un ejemplo de cómo se puede utilizar este método para ayudar a la clasificación en campos en los que la interpretabilidad es importante, como la atención médica.', 'pt': 'Apesar do sucesso amplamente divulgado de métodos de aprendizado de máquina baseados em incorporação em tarefas de processamento de linguagem natural, o uso de recursos de engenharia mais facilmente interpretados permanece comum em campos como detecção de comprometimento cognitivo (CI). A engenharia manual de recursos de texto ruidoso consome tempo e recursos e pode resultar em recursos que não melhoram o desempenho do modelo. Para combater isso, descrevemos uma nova abordagem para engenharia de recursos que aproveita modelos sequenciais de aprendizado de máquina e conhecimento de domínio para prever quais recursos ajudam a melhorar o desempenho. Fornecemos um exemplo concreto desse método em um conjunto de dados padrão de fala de CI e demonstramos que a precisão da classificação de CI melhora em 2,3% em relação a uma linha de base forte ao usar recursos produzidos por esse método. Esta demonstração fornece um exemplo de como este método pode ser usado para auxiliar a classificação em áreas onde a interpretabilidade é importante, como cuidados de saúde.', 'ja': '自然言語処理タスクにおける埋め込みベースの機械学習方法の成功が広く報告されているにもかかわらず、より容易に解釈されたエンジニアリングされた特徴の使用は、認知障害（ CI ）検出などの分野で依然として一般的である。ノイズの多いテキストから手動で機能をエンジニアリングすると、時間とリソースがかかり、モデルのパフォーマンスを向上させない機能になる可能性があります。これに対抗するために、シーケンシャル機械学習モデルとドメイン知識を活用して、どの機能がパフォーマンスを向上させるのかを予測する機能工学の新しいアプローチを説明します。ＣＩ音声の標準データセット上でこの方法の具体例を提供し、この方法によって生成された特徴を使用すると、ＣＩ分類精度が強いベースラインよりも２ ． ３ ％向上することを実証する。このデモンストレーションは、医療などの解釈可能性が重要な分野における分類を支援するために、この方法をどのように使用できるかの例を提供します。', 'zh': '虽广报道基于嵌机器学术成功于自然语言,而检于认知障碍(CI)之域,用之易说者犹常见也。 自嘈杂之文手动设计费日月,且不可增强模样之征。 论新功,因次第机器学模样、领域知何助。 吾于 CI 语音之数集上供此法之示例,证当用此生成之时,CI 类准确性比强基线增 2.3%也。 此供一示例,明用此法在可解释性要域(如医疗保健)辅分也。', 'hi': 'प्राकृतिक भाषा प्रसंस्करण कार्यों पर एम्बेडिंग-आधारित मशीन लर्निंग विधियों की व्यापक रूप से रिपोर्ट की गई सफलता के बावजूद, संज्ञानात्मक हानि (सीआई) का पता लगाने जैसे क्षेत्रों में अधिक आसानी से व्याख्या की गई इंजीनियर सुविधाओं का उपयोग आम है। शोर पाठ से मैन्युअल रूप से इंजीनियरिंग सुविधाएँ समय और संसाधन की खपत है, और संभावित रूप से उन सुविधाओं में परिणाम कर सकती हैं जो मॉडल प्रदर्शन को नहीं बढ़ाती हैं। इसका मुकाबला करने के लिए, हम इंजीनियरिंग की सुविधा के लिए एक नए दृष्टिकोण का वर्णन करते हैं जो अनुक्रमिक मशीन लर्निंग मॉडल और डोमेन ज्ञान का लाभ उठाता है ताकि यह अनुमान लगाया जा सके कि कौन सी विशेषताएं प्रदर्शन को बढ़ाने में मदद करती हैं। हम सीआई भाषण के एक मानक डेटा सेट पर इस विधि का एक ठोस उदाहरण प्रदान करते हैं और प्रदर्शित करते हैं कि इस विधि द्वारा उत्पादित सुविधाओं का उपयोग करते समय सीआई वर्गीकरण सटीकता एक मजबूत आधार रेखा पर 2.3% तक सुधार करती है। यह प्रदर्शन इस बात का एक उदाहरण प्रदान करता है कि इस विधि का उपयोग उन क्षेत्रों में वर्गीकरण की सहायता के लिए कैसे किया जा सकता है जहां व्याख्याक्षमता महत्वपूर्ण है, जैसे स्वास्थ्य देखभाल।', 'ru': 'Несмотря на широко известный успех методов машинного обучения, основанных на внедрении, в задачах обработки естественного языка, использование более легко интерпретируемых сконструированных признаков остается распространенным в таких областях, как обнаружение когнитивных нарушений (CI). Вручную проектирование функций из шумного текста занимает много времени и ресурсов и может потенциально привести к функциям, которые не повышают производительность модели. Чтобы бороться с этим, мы описываем новый подход к разработке функций, который использует последовательные модели машинного обучения и знания домена, чтобы предсказать, какие функции помогают повысить производительность. Мы приводим конкретный пример этого метода на стандартном наборе данных речи CI и демонстрируем, что точность классификации CI улучшается на 2,3% по сравнению с сильной базовой линией при использовании признаков, полученных этим методом. Эта демонстрация представляет собой пример того, как этот метод может быть использован для содействия классификации в областях, где важна интерпретируемость, таких как здравоохранение.', 'ga': "In ainneoin an ratha a tuairiscíodh go forleathan maidir le modhanna meaisínfhoghlama a leabú ar thascanna próiseála teanga nádúrtha, tá úsáid gnéithe innealtóireachta níos éasca a léirmhíniú fós coitianta i réimsí cosúil le lagú cognaíocha (CI) a bhrath. Tógann an t-innealtóireacht de láimh ar ghnéithe ó théacs torannach am agus acmhainní, agus d'fhéadfadh gnéithe a bheith mar thoradh air nach gcuireann le feidhmíocht na samhla. Chun é seo a chomhrac, déanaimid cur síos ar chur chuige nua maidir le hinnealtóireacht ghné a ghiaráil samhlacha meaisínfhoghlama seicheamhacha agus eolas fearainn chun na gnéithe a chabhróidh le feidhmíocht a fheabhsú a thuar. Soláthraímid sampla nithiúil den mhodh seo ar thacar sonraí caighdeánach de chaint CI agus léirímid go bhfeabhsaítear cruinneas aicmithe CI 2.3% thar bonnlíne láidir nuair a úsáidtear gnéithe a tháirgtear leis an modh seo. Soláthraíonn an léiriú seo sampla de conas is féidir an modh seo a úsáid chun cabhrú le haicmiú i réimsí ina bhfuil tábhacht le léirmhíniú, mar chúram sláinte.", 'ka': 'მაქსინური განსწავლების მეტოვების ძალიან შეუძლებელია, როგორც კონციგური განსწავლება (CI) განსხვავებაში, უფრო ადვილად განსხვავებული ინექნიერების გამოყენება დარჩენა. ხელსახური ტექსტიდან ინეზინერიური ფუნქციები არის დრო და რესურსის გამოყენება, და შეიძლება შეიძლება შეიძლება მონაცემული ფუნქციების შედეგი, რომლებიც ჩვენ ამის გაბრძნობისთვის ახალი პროგრამა განვითარებით ინეზინერიის განსაზღვრებისთვის, რომელიც შემდეგ მაქანის სწავლების მოდელები და დიომინის მეცნიერები გამოიყენებს,  ჩვენ ამ პროცემის კონკრეტული მაგალითი CI სიტყვების სტანდარტული მონაცემების კონტაქტის მაგალითი დავიწყებთ და გამოჩვენებთ, რომ CI კლასიფიკაციაციის კონტაქტია 2.3% უფრო უფრო მე ამ დემონსტრაციის მაგალითი იქნება, როგორ ეს მეტი შეიძლება გამოყენება კლასიფიკაციის დახმარებისთვის სამყაროში, სადაც ინტერფლიკაცია მნიშვნელოვანია, როგ', 'hu': 'Annak ellenére, hogy az alapú gépi tanulási módszerek természetes nyelvfeldolgozási feladatokba való beágyazásának széles körben jelentett sikere van, a könnyebben értelmezhető tervezett funkciók használata továbbra is gyakori olyan területeken, mint a kognitív zavar (CI) felismerése. A zajos szövegből származó funkciók manuális tervezése idő- és erőforrásokat igényel, és potenciálisan olyan funkciókat eredményezhet, amelyek nem javítják a modell teljesítményét. Ennek elleni küzdelem érdekében ismertetjük a funkciótervezés új megközelítését, amely a szekvenciális gépi tanulási modelleket és a domain ismereteket használja fel annak előrejelzésére, hogy mely funkciók segítenek javítani a teljesítményt. Konkrét példát adunk erre a módszerre a CI beszéd standard adatkészletén, és bebizonyítjuk, hogy a CI osztályozási pontosság 2,3%-kal javul az erős kiindulási értékhez képest az ezzel a módszerrel előállított funkciók használata esetén. Ez a bemutató példát ad arra, hogy ez a módszer hogyan segítheti az osztályozást olyan területeken, ahol az értelmezhetőség fontos, például az egészségügyi ellátás.', 'el': 'Παρά την ευρέως αναφερθείσα επιτυχία των μεθόδων μηχανικής μάθησης που βασίζονται στην ενσωμάτωση σε εργασίες επεξεργασίας φυσικής γλώσσας, η χρήση πιο εύκολα ερμηνευμένων μηχανικών χαρακτηριστικών παραμένει κοινή σε τομείς όπως η ανίχνευση γνωστικών διαταραχών. Η χειροκίνητη μηχανική χαρακτηριστικών από θορυβώδες κείμενο είναι χρονοβόρα και δαπανηρή και μπορεί ενδεχομένως να οδηγήσει σε χαρακτηριστικά που δεν βελτιώνουν την απόδοση του μοντέλου. Για να καταπολεμήσουμε αυτό, περιγράφουμε μια νέα προσέγγιση στη μηχανική χαρακτηριστικών που χρησιμοποιεί διαδοχικά μοντέλα μηχανικής μάθησης και γνώσεις τομέα για να προβλέψει ποια χαρακτηριστικά βοηθούν στην ενίσχυση της απόδοσης. Παρέχουμε ένα συγκεκριμένο παράδειγμα αυτής της μεθόδου σε ένα τυποποιημένο σύνολο δεδομένων ομιλίας και καταδεικνύουμε ότι η ακρίβεια ταξινόμησης βελτιώνεται κατά 2,3% σε σχέση με μια ισχυρή βάση βάσης όταν χρησιμοποιούμε χαρακτηριστικά που παράγονται από αυτή τη μέθοδο. Αυτή η επίδειξη παρέχει ένα παράδειγμα του τρόπου με τον οποίο αυτή η μέθοδος μπορεί να χρησιμοποιηθεί για να βοηθήσει την ταξινόμηση σε τομείς όπου η ερμηνεία είναι σημαντική, όπως η υγειονομική περίθαλψη.', 'it': "Nonostante il successo ampiamente segnalato di incorporare metodi di apprendimento automatico basati su processi di elaborazione del linguaggio naturale, l'uso di funzionalità ingegnerizzate più facilmente interpretate rimane comune in campi come il rilevamento di compromissione cognitiva (CI). L'ingegnerizzazione manuale delle funzionalità da testo rumoroso richiede tempo e risorse e può potenzialmente comportare funzionalità che non migliorano le prestazioni del modello. Per contrastare questo problema, descriviamo un nuovo approccio all'ingegneria delle funzionalità che sfrutta modelli di machine learning sequenziali e conoscenza del dominio per prevedere quali funzionalità contribuiscono a migliorare le prestazioni. Forniamo un esempio concreto di questo metodo su un set di dati standard del discorso CI e dimostriamo che l'accuratezza della classificazione CI migliora del 2,3% rispetto a una base di base solida quando si utilizzano funzionalità prodotte da questo metodo. Questa dimostrazione fornisce un esempio di come questo metodo possa essere utilizzato per facilitare la classificazione in settori in cui l'interpretabilità è importante, come l'assistenza sanitaria.", 'kk': 'Табиғи тілдерді өңдеу тапсырмаларындағы компьютердің оқыту әдістерінің көп жарияланған сәттілігіне қарамастан, оңай түсіндірілген инженерлік мүмкіндіктердің пайдалануы, мысалы, кәсіпсіздік көме Дыбыс мәтіннен қолмен инженерлік мүмкіндіктері - уақыт мен ресурстар пайдалануы және үлгі жылдамдығын өзгертуге болады. Бұл көмектесу үшін біз инженерлік үшін жаңа тәсілді түсіндіреміз. Бұл компьютердің оқыту үлгілерін және домен білімін қай мүмкіндіктерінің көмектесетінін таңдау Біз бұл әдістің стандартты мәліметін CI сөйлесу бағдарламасында көрсеткіміз және CI бағдарламасының дұрыстығы 2,3% дегенді көрсеткіміз, бұл әдістерден құрылған мүмкіндіктерді қолданғанда Бұл демонстрация бұл әдісті қалай қолданылатын түрлендіру үшін, саулық медицина секілді, мәселелердің түрлендіру маңызды өрістерінде көмектесу үшін қолданыла', 'lt': 'Nepaisant plačiai pastebėtų sėkmingų įdėjimo į gamtos kalbų apdorojimo užduotis grindžiamų mašin ų mokymosi metodų, lengviau aiškinamų inžinerijos savybių naudojimas tebėra dažnas tokiose srityse kaip pažinimo sutrikimas (PI). Rankiniai triukšmingo teksto in žinerijos požymiai yra laiko ir išteklių naudojimas, todėl gali atsirasti požymių, kurie nepadidina modelio veiksmingumo. To combat this, we describe a new approach to feature engineering that leverages sequential machine learning models and domain knowledge to predict which features help enhance performance.  Pateikiame konkretų šio metodo pavyzdį standartiniame CI kalbos duomenų rinkinyje ir įrodome, kad CI klasifikacijos tikslumas pagerėja 2,3 proc., palyginti su stipria pradine verte, naudojant šiuo metodu gautas charakteristikas. Šis demonstravimas yra pavyzdys, kaip šis metodas gali būti naudojamas klasifikavimui srityse, kuriose yra svarbus aiškinimas, pvz., sveikatos priežiūros srityje.', 'ml': 'സ്വാഭാവിക ഭാഷ പ്രവര്\u200dത്തിപ്പിക്കുന്ന ജോലികളില്\u200d ഉപയോഗിക്കുന്ന മെഷീന്\u200d പഠിക്കുന്ന രീതികളുടെ വിശാലമായി റിപ്പോര്\u200dട്ട് ചെയ്തിട്ടുണ്ടെങ് ശബ്ദ പദാവലിയില്\u200d നിന്നും കൈയ്യില്\u200d നിന്നും എഞ്ചിനീയറിങ്ങിന്\u200dറെ വിശേഷതകള്\u200d സമയവും വിഭവങ്ങളും ഉപയോഗിക്കുന്നതാണ്. മോഡല്\u200d പ്രദര ഇതിനെ എതിര്\u200dത്താന്\u200d, പുതിയ എഞ്ചിനീയറിങ്ങിനെ പ്രത്യേകിപ്പിക്കാന്\u200d നമ്മള്\u200d വിശദീകരിക്കുന്നു. അത് പിന്നീട് മെഷീന്\u200d പഠിക്കുന്ന മ ഈ രീതിയില്\u200d സിഐ സംസാരിക്കുന്ന സാധാരണ ഡാറ്റാ സെറ്റില്\u200d നാം ഒരു കോണ്\u200dക്രീറ്റ് ഉദാഹരണമായി നല്\u200dകുന്നു. ഈ രീതിയില്\u200d നിന്നും സൃഷ്ടിക്കുന്ന പ്രശ് ഈ പ്രദര്\u200dശിപ്പിന് ഒരു ഉദാഹരണമാണ് ഈ രീതി എങ്ങനെ ഉപയോഗിക്കാന്\u200d സാധിക്കുന്നതെന്ന് ഉദാഹരണമാക്കുന്നത്. വ്യാഖ്യാനം പ്ര', 'mn': 'Байгалийн хэл үйлдвэрлэх үйл ажиллагаанд машин суралцах аргын шинэ хэмжээний амжилт гаргасан ч, илүү амархан инженерчлэлийн шинж чанарын хэрэглээ мэдэх халдвар (CI) шинж тэмдэглэгдэх талбарт ихэвчлэн байдаг. Үнэн дуу текстээс гар инженерчлэлийн чадварууд бол цаг, нөөц ашиглах боломжтой. Загварын үйл ажиллагааг нэмэгдүүлэхгүй чадваруудын үр дүнд боломжтой. Үүнийг зогсоохын тулд бид инженерчлэлийн шинэ арга замыг тайлбарлаж, дараагийн машины суралцах загвар болон зохиолын мэдлэг ямар боломжтой үйл ажиллагааг нэмэгдүүлэхэд тусалдаг талаар тайлбарлаж Бид энэ аргын тодорхой жишээг СИД хэлэлцээний стандарт өгөгдлийн тоо хэмжээ дээр тайлбарлаж, CI хэлэлцээний тодорхойлолт нь энэ аргыг ашиглах үед хүчтэй суурь шугам дээр 2.3%-аар нэмэгдүүлж байна. Энэ үзүүлэлт хэрхэн энэ арга хэрхэн хэрэглэгдэж болох вэ гэвэл эрүүл мэндийн тусламжтай мэт тодорхойлолт чухал талбарт хуваалцах тулд хэрхэн ашиглах вэ гэдгийг жишээ гаргадаг.', 'mk': 'И покрај широко објавениот успех на методите на машинско учење базирани на вградување на природните задачи за процес на јазик, употребата на полесно интерпретирани инженерски карактеристики останува често во области како што е детективата на когнитивното влошување ( Рачно инженерските карактеристики од бучниот текст се потрошуваат времето и ресурсите и можат потенцијално да резултираат со карактеристики кои не ја зголемуваат резултатот на моделот. За да се бориме против ова, опишуваме нов пристап до инженерството што влијае на секвенцијалните модели на машинско учење и знаење на доменот за да предвидеме кои карактеристики помагаат во подобрувањето на резултатите. Ние обезбедуваме конкретен пример на овој метод на стандардниот груп податоци на говорот на ИС и демонстрираме дека точноста на класификацијата на ИС се подобрува за 2,3 отсто во однос на силна основа кога се користат карактеристики произведени од овој метод. Оваа демонстрација обезбедува пример за тоа како овој метод може да се користи за помош во класификацијата на областите каде што е важна интерпретабилноста, како што е здравствената заштита.', 'no': 'Til tross den breidde rapporterte suksessen på innbyggingsbaserte maskinelæringsmetodane på naturspråk-handsamingsoppgåver, bruken av meir enkelt tolka ingeniare funksjonar blir vanleg i felta som kognitiv utrykk (CI). Manuelt in ženjeringsfunksjonar frå støyteksten er tid og ressursbruk, og kan potensielt resultere i funksjonar som ikkje forbetrar modellen. For å komme med dette, beskriver vi ein ny tilnærming til å funksjonar ingeniøring som leverer sekvensiske maskinelæringsmodeller og domenekunnskap for å foregå kva funksjonar hjelper å forbetra utviklingar. Vi gjev eit konkrett eksempel på denne metoden på ein standard datasett av CI-tale og demonstrerer at CI-klassifikasjon er forbetra med 2,3% over ein sterk baseline når du brukar funksjonar som er produsert av denne metoden. Denne demonstrasjonen gjev eit eksempel på korleis denne metoden kan brukast for å hjelpa klassifikasjon i felta der interpreteringa er viktig, slik som helsefarge.', 'pl': 'Pomimo powszechnie opisywanego sukcesu metod uczenia maszynowego opartych na osadzeniu w zadaniach przetwarzania języka naturalnego, stosowanie łatwiej interpretowanych funkcji inżynieryjnych pozostaje powszechne w takich dziedzinach, jak wykrywanie zaburzeń poznawczych (CI). Ręczne projektowanie funkcji z głośnego tekstu jest czasochłonne i może potencjalnie skutkować funkcjami, które nie poprawiają wydajności modelu. Aby temu przeciwdziałać, opisujemy nowe podejście do inżynierii funkcji, które wykorzystuje sekwencyjne modele uczenia maszynowego i wiedzę domenową, aby przewidzieć, które funkcje pomagają zwiększyć wydajność. Przedstawiamy konkretny przykład tej metody na standardowym zbiorze danych mowy CI i wykazujemy, że dokładność klasyfikacji CI poprawia się o 2,3% w porównaniu z silną bazą podstawową podczas stosowania cech produkowanych przez tę metodę. Ta demonstracja stanowi przykład, w jaki sposób metoda ta może być wykorzystana do wspomagania klasyfikacji w dziedzinach, w których ważna jest interpretacja, takich jak opieka zdrowotna.', 'ro': 'În ciuda succesului raportat pe scară largă al încorporării metodelor de învățare automată bazate pe sarcini de procesare a limbajului natural, utilizarea caracteristicilor inginerești mai ușor interpretate rămâne frecventă în domenii precum detectarea deficiențelor cognitive (CI). Caracteristicile de inginerie manuală din text zgomotos consumă timp și resurse și pot avea ca rezultat caracteristici care nu îmbunătățesc performanța modelului. Pentru a combate acest lucru, descriem o nouă abordare a ingineriei caracteristicilor care valorifică modelele secvențiale de învățare automată și cunoștințele domeniului pentru a prezice ce caracteristici ajută la îmbunătățirea performanței. Oferim un exemplu concret al acestei metode pe un set de date standard de vorbire CI și demonstrăm că acuratețea clasificării CI se îmbunătățește cu 2,3% față de o bază puternică atunci când se utilizează caracteristici produse prin această metodă. Această demonstrație oferă un exemplu al modului în care această metodă poate fi utilizată pentru a sprijini clasificarea în domenii în care interpretabilitatea este importantă, cum ar fi asistența medicală.', 'ms': 'Walaupun kejayaan yang dilaporkan secara luas dari kaedah pembelajaran mesin berdasarkan penyembedding pada tugas pemprosesan bahasa semulajadi, penggunaan ciri-ciri yang direka secara mudah diterangkan tetap umum dalam medan seperti pengesan cacat kognitif (CI). Manually engineering features from noisy text is time and resource consuming, and can potentially result in features that do not enhance model performance.  Untuk melawan ini, kami menggambarkan pendekatan baru untuk teknik fitur yang menggunakan model pembelajaran mesin berturut-turut dan pengetahuan domain untuk meramalkan fitur mana yang membantu meningkatkan prestasi. We provide a concrete example of this method on a standard data set of CI speech and demonstrate that CI classification accuracy improves by 2.3% over a strong baseline when using features produced by this method.  Demonstrasi ini memberikan contoh bagaimana kaedah ini boleh digunakan untuk membantu kelasukan dalam medan di mana pengenalan penting, seperti rawatan kesehatan.', 'mt': 'Minkejja s-suċċess irrappurtat b’mod wiesa’ ta’ metodi ta’ tagħlim tal-magni bbażati fuq l-inkorporazzjoni fuq kompiti ta’ pproċessar naturali tal-lingwi, l-użu ta’ karatteristiċi in ġinerizzati interpretati aktar faċilment jibqa’ komuni f’oqsma bħad-detezzjoni ta’ indeboliment konjittiv (CI). Il-karatteristiċi ta’ in ġinerija manwali minn test storbjuż jikkonsmaw il-ħin u r-riżorsi, u jistgħu potenzjalment jirriżultaw f’karatteristiċi li ma jtejbux il-prestazzjoni tal-mudell. To combat this, we describe a new approach to feature engineering that leverages sequential machine learning models and domain knowledge to predict which features help enhance performance.  We provide a concrete example of this method on a standard data set of CI speech and demonstrate that CI classification accuracy improves by 2.3% over a strong baseline when using features produced by this method.  Din id-dimostrazzjoni tipprovdi eżempju ta’ kif dan il-metodu jista’ jintuża biex jassisti l-klassifikazzjoni f’oqsma fejn l-interpretabbiltà hija importanti, bħall-kura tas-saħħa.', 'sr': 'Uprkos širokim prijavljenim uspjehom metoda učenja strojeva na osnovu integracije prirodnog jezika, upotreba lako interpretiranih in ženjerskih karakteristika ostaje zajednička u poljima poput otkrivanja kognitivnog oštećenja (CI). Ručno in žinjerske funkcije iz zvukovnog teksta su vrijeme i potrošenje resursa, i mogu potencijalno rezultirati karakteristike koje ne poboljšavaju modelnu funkciju. Da bi se borili protiv ovoga, opisali smo novi pristup funkcioniranju inženjeringa koji utiče na sekvencijske modele učenja mašine i znanje domena da predvidimo koje karakteristike pomažu unapređivati učenje. Mi pružamo konkretni primjer ove metode o standardnom setu podataka govora CI-a i pokazujemo da se preciznost klasifikacije CI poboljšava za 2,3% nad jakom početnom linijom kada koristimo funkcije proizvođene ovim metodom. Ova demonstracija pruža primjer kako se ova metoda može iskoristiti kako bi pomogla klasifikaciji u poljima gde je interpretabilnost važna, kao što je zdravstvena zaštita.', 'si': 'ස්වභාවික භාෂාව ප්\u200dරක්\u200dරියාපනය විදියට පරීක්ෂණය කරන්න පුළුවන් විදියට පරීක්ෂණය කරලා තියෙනවා නමුත් ස්වභාවික භාෂාව පරීක්ෂණය ශබ්ද පිළිබඳින් සිද්ධ විශේෂතාවන් අයින්ජිනියාර්ජින් විශේෂතාවක් විතරයි වෙලාව සහ සම්බන්ධ මේක සටන් කරන්න, අපි අළුත් අභිවිධානයක් විස්තර කරන්නේ ඉංජිනියාර්ජින් එක්ක අනුවෙන් අභිවිධානයක් විස්තර ක අපි මේ විධානයේ ප්\u200dරමාණ දත්ත සූදානම් CI කතාවක් සඳහා ප්\u200dරකාශ කරනවා කියලා පෙන්වන්නේ CI විශේෂණය සැකසුම් 2.3% විශේෂයෙන් බලය මේ ප්\u200dරදර්ශනය පුළුවන් උදාහරණයක් තියෙනවා මේ විධානය කොහොමද පාවිච්චි කරන්න පුළුවන් කිරීමේ විශේෂණය', 'so': "Inkastoo aad u faa’iido badnaan loo soo qoray hababka barashada machine-based oo lagu qorayo shaqooyinka baaritaanka afka dabiicadda ah, isticmaalka faa’iidada lagu turjumay si fudud ah ayaa ku caadi ah beeraha sida aqoonta (CI). Xiriikhda maamulka codsiga ah waa waqti iyo isticmaalka midhaha, waxaana suurtagal ah inay sababto faa'iido aan horumarin muusikada. Si aan u dagaallanto waxan, waxaynu u qoraynaa qaab cusub oo ku saabsan injiilka, kaas oo soo bandhigaya muusikada barashada maskaxda dabadeed iyo aqoonta deegaanka si ay u sii sheegto wax caawiya horumarinta. Tusaale kamid ah ayaannu u siinaynaa qaababkan ku qoran hadalka caadiga ah ee CI, waxaana tusnaa in saxda fasaxa CI uu kordhiyo 2.3% oo ka kordhiya saldhig adag marka aad isticmaaleyso qalabkan. Caddaynta waxaa tusaale ahaan loo isticmaali karaa in lagu caawiyo fasalka beeraha turjubaanka ay muhiim u tahay sida daryeelka caafimaadka.", 'sv': 'Trots den allmänt rapporterade framgången med inbäddningsbaserade maskininlärningsmetoder i bearbetningsuppgifter av naturligt språk, är användningen av lättare tolkade tekniska funktioner fortfarande vanligt inom områden som kognitiv funktionsnedsättning (CI) detektering. Manuell konstruktion av funktioner från bullrig text är tidskrävande och resurskrävande och kan potentiellt resultera i funktioner som inte förbättrar modellens prestanda. För att motverka detta beskriver vi ett nytt tillvägagångssätt för funktionsteknik som utnyttjar sekventiella maskininlärningsmodeller och domänkunskap för att förutsäga vilka funktioner som hjälper till att förbättra prestanda. Vi ger ett konkret exempel på denna metod på en standarddatauppsättning av CI tal och visar att CI-klassificeringens noggrannhet förbättras med 2,3% jämfört med en stark baslinje när vi använder funktioner som produceras med denna metod. Denna demonstration ger ett exempel på hur denna metod kan användas för att underlätta klassificering inom områden där tolkning är viktig, såsom hälso- och sjukvård.', 'ta': 'இயல்பான மொழி செயல்பாடுகளில் உள்ளிடப்படும் இயந்திர மொழி கற்றி முறைகளின் வெற்றிகரமாக அறிவிக்கப்பட்ட போதிலும், மிகவும் எளிதாக முயற்சிக்கப்பட்ட பொறிய Manually engineering features from noisy text is time and resource consuming, and can potentially result in features that do not enhance model performance.  இதை எதிர்பார்க்க புதிய முறைமையை நாம் விவரிக்கிறோம். பின்வரும் இயந்திரம் கற்றல் மாதிரிகள் மற்றும் களத்தின் அறிவு முறைமைகளை முன்வெ நாம் இந்த முறையின் ஒரு குறிப்பிட்ட எடுத்துகாட்டுக்காட்டாக்குகிறோம் சிআই பேச்சு நிலையான தகவல் அமைப்பு மற்றும் இந்த முறையில் உருவாக்கப்பட இந்த காட்சியின் உதாரணத்தைக் கொடுக்கிறது இந்த முறைமையை எப்படி பயன்படுத்த முடியும் என்பதை உதாரணத்திற்கு காட்டுகி', 'ur': 'مہینڈنگ بنیادی مہینی یادگیری طریقے پر طبیعی زبان پرینسٹ کے کاموں کے بارے میں بہت سادہ تعبیر کی موفقیت کے بغیر، زیادہ آسان تعبیر کی انجینر کی ویژگی کا استعمال کھیتیوں میں عام رہتا ہے جیسے پہچان کی ایمنٹ (CI) پت آواز کے متن سے آواز انجینرینگ فوائل وقت اور سراسر کا مصرف کرنا ہے، اور ممکن ہوتا ہے کہ موڈل کے کامیابی میں اضافہ نہیں کرسکتے. اس سے لڑنے کے لئے ہم نے ایک نوی طریقہ کی توصیف کرتی ہے کہ انجینژی کی وینژی کے لئے ایک نئی طریقہ ہے جو سفارشی ماشین کی تعلیم مدل اور ڈومین علم کو پیش بینی کرتا ہے کہ کس طرح عمل کی زیادتی کی مدد کرتی ہے۔ ہم اس طریقے کا ایک قطعہ مثال سی کی بات کی استاندارڈ ڈیٹ سٹ پر پیش کرتے ہیں اور دکھاتے ہیں کہ سی کی کلاسیفوں کی دقیقیت 2.3% سے ایک مضبوط بنسٹ لین پر زیادہ اضافہ ہوتی ہے جب اس طریقے سے موجود ہوتے ہیں۔ یہ نمونش ایک مثال پیش کرتا ہے کہ یہ طریقہ کس طرح استعمال کئے جاتے ہیں کہ اس طریقہ کو کس طرح تقسیم کی مدد کریں جہاں تعبیر کا اہم ہے، جیسے سلامتی مراقبت.', 'uz': "Asosiy tilni boshqarish vazifalarini aniqlash usullarini ko'p qidirish muvaffaqiyatli yordam berilganda, oddiy tarjima qilingan imkoniyatlarning foydalanishi oddiy tarjima qilish imkoniyatlarini aniqlash (CI) sifatida umumiy bo'ladi. Name Buni boshqarish uchun biz bir yangi narsalarni anglatamiz, bir necha xil mashinalar o'rganish modellari va domen ilimni o'rganish imkoniyatini bajarishiga yordam beradi. Biz bu usulni CI tilida standard maʼlumot tizimini yaratib turamiz va CI taʼminlovchisi haqida 2.3% darajalashtirish imkoniyatini ushbu usuldan foydalanilganda ishlatiladi. Bu demoni, bu usulni qanday foydalanishi mumkin, huddi sog'lom huddi tarjima muhimligi muhim boʻlgan maydonlarda foydalanish mumkin.", 'vi': 'Mặc dù thành công được báo cáo nhiều về sự nhúng vào các phương pháp học máy về các công việc xử lý ngôn ngữ tự nhiên, việc sử dụng các tính chất phức tạp được giải thích dễ dàng vẫn phổ biến trong lĩnh vực như bị hư hỏng nhận thức (CI) phát hiện. Tính năng kỹ thuật bằng văn bản ồn ào là tốn thời gian và tài nguyên, và có thể dẫn tới các tính năng không làm tăng hiệu suất mô hình. Để chống lại điều này, chúng tôi mô tả một phương pháp mới để sinh hoạt kỹ thuật, điều khiển các mô hình học máy kế tiếp và kiến thức miền để dự đoán các tính năng giúp nâng cao khả năng. Chúng tôi cung cấp một ví dụ cụ thể về phương pháp này trong một tập hợp dữ liệu tiêu chuẩn của ngôn ngữ CI và chứng minh rằng độ chính xác phân hạng C tăng theo 2.3=.=) trên một cơ sở cơ bản mạnh khi sử dụng các tính năng do phương pháp này sản xuất. Thông tin này là một ví dụ về cách dùng phương pháp này để giúp phân loại các lĩnh vực có thể hiểu được, như chăm sóc y tế.', 'bg': 'Въпреки широкоразпространения успех на вграждането на базирани методи за машинно обучение при задачите по обработка на естествения език, използването на по-лесно интерпретирани инженерни функции остава често срещано в области като откриване на когнитивни увреждания. Ръчното проектиране на функции от шумен текст отнема време и ресурси и потенциално може да доведе до функции, които не подобряват производителността на модела. За да се борим с това, описваме нов подход към инженерството на функциите, който използва последователни модели на машинно обучение и познания за домейна, за да предскаже кои функции помагат за подобряване на производителността. Ние предоставяме конкретен пример за този метод върху стандартен набор от данни за речта на CI и демонстрираме, че точността на класификацията на CI се подобрява с 2,3% спрямо силна изходна база при използване на характеристиките, произведени от този метод. Тази демонстрация дава пример за това как този метод може да се използва за подпомагане на класификацията в области, в които интерпретацията е важна, като например здравеопазването.', 'nl': 'Ondanks het veel gerapporteerde succes van embedding-based machine learning methodes op natuurlijke taalverwerkingstaken, blijft het gebruik van gemakkelijker te interpreteren engineered features gebruikelijk op gebieden zoals detectie van cognitieve stoornissen (CI). Het handmatig ontwerpen van functies op basis van luidruchtige tekst kost tijd en middelen en kan mogelijk resulteren in functies die de prestaties van het model niet verbeteren. Om dit te bestrijden beschrijven we een nieuwe benadering van feature engineering die gebruik maakt van sequentiële machine learning modellen en domeinkennis om te voorspellen welke functies helpen de prestaties te verbeteren. We geven een concreet voorbeeld van deze methode op een standaard dataset van CI-spraak en tonen aan dat de CI-classificatienauwkeurigheid met 2,3% verbetert ten opzichte van een sterke baseline bij gebruik van functies die door deze methode worden geproduceerd. Deze demonstratie geeft een voorbeeld van hoe deze methode kan worden gebruikt om de classificatie te ondersteunen op gebieden waar interpreteerbaarheid belangrijk is, zoals gezondheidszorg.', 'hr': 'Uprkos širokim prijavljenim uspjehom metoda učenja strojeva na temelju integracije prirodnog jezika, upotreba lakše interpretiranih in ženjerskih karakteristika ostaje česta u poljima poput otkrivanja kognitivnog oštećenja (CI). Ručno in žinjerske funkcije iz zvukovnog teksta su vrijeme i potrošenje resursa, te mogu potencijalno rezultirati karakteristike koje ne poboljšavaju učinkovitost modela. Za borbu protiv ovoga opisujemo novi pristup inženjerstvu koji utječe na sekvencijske modele učenja strojeva i znanje domena za predviđanje koje karakteristike pomažu poboljšati učenje. Mi pružamo konkretni primjer ove metode o standardnom setu podataka govora CI-a i pokazujemo da se preciznost klasifikacije CI poboljšava za 2,3% nad jakom početnom linijom kada koristimo funkcije proizvođene ovim metodom. Ova demonstracija predstavlja primjer kako se ovaj metod može koristiti za pomoć klasifikacije u poljima gdje je interpretabilnost važna, poput zdravstvene zaštite.', 'da': 'På trods af den bredt rapporterede succes med integrering baserede maskinlæringsmetoder på naturlige sprogbehandlingsopgaver, er brugen af lettere fortolkede tekniske funktioner stadig almindelig inden for områder som kognitiv svækkelse (CI) detektion. Manuel udvikling af funktioner fra støjende tekst er tidskrævende og ressourcekrævende og kan potentielt resultere i funktioner, der ikke forbedrer modellens ydeevne. For at bekæmpe dette beskriver vi en ny tilgang til feature engineering, der udnytter sekventielle maskinlæringsmodeller og domæneviden til at forudsige, hvilke funktioner der hjælper med at forbedre ydeevnen. Vi giver et konkret eksempel på denne metode på et standarddatasæt af CI tale og demonstrerer, at CI klassificering nøjagtighed forbedres med 2,3% i forhold til en stærk baseline, når vi bruger funktioner produceret ved denne metode. Denne demonstration giver et eksempel på, hvordan denne metode kan anvendes til at hjælpe klassificeringen på områder, hvor fortolkningen er vigtig, f.eks. sundhedspleje.', 'de': 'Trotz des vielfach berichteten Erfolgs von Embedding-basierten maschinellen Lernmethoden auf natürliche Sprachverarbeitungsaufgaben ist der Einsatz leichter interpretierter technischer Merkmale in Bereichen wie der Erkennung von kognitiven Beeinträchtigungen (CI) weiterhin üblich. Das manuelle Entwickeln von Features aus lautem Text ist zeit- und ressourcenaufwendig und kann möglicherweise zu Features führen, die die Modellleistung nicht verbessern. Um diesem entgegenzuwirken, beschreiben wir einen neuen Ansatz für Feature Engineering, der sequentielle Machine Learning Modelle und Domänenwissen nutzt, um vorherzusagen, welche Funktionen zur Leistungssteigerung beitragen. Wir stellen ein konkretes Beispiel dieser Methode an einem Standard-Datensatz der CI-Sprache dar und zeigen, dass die CI-Klassifikationsgenauigkeit bei Verwendung von Features, die durch diese Methode erzeugt werden, um 2,3% gegenüber einer starken Baseline verbessert wird. Diese Demonstration zeigt beispielhaft, wie diese Methode zur Klassifizierung in Bereichen eingesetzt werden kann, in denen Interpretierbarkeit wichtig ist, wie zum Beispiel im Gesundheitswesen.', 'id': 'Meskipun sukses yang dilaporkan secara luas dari metode pembelajaran mesin berdasarkan embedding pada tugas proses bahasa alami, penggunaan karakteristik rekayasa yang lebih mudah diterjemahkan tetap umum dalam bidang seperti deteksi cacat kognitif (CI). Karakteristik rekayasa secara manual dari teks yang berisik adalah waktu dan sumber daya memakan, dan potensial dapat menghasilkan karakteristik yang tidak meningkatkan prestasi model. Untuk melawan hal ini, kami menggambarkan pendekatan baru untuk teknik karakteristik yang mempengaruhi model sekwensial belajar mesin dan pengetahuan domain untuk memprediksi karakteristik mana yang membantu meningkatkan prestasi. Kami menyediakan contoh konkret dari metode ini pada set data standar dari pidato CI dan menunjukkan bahwa akurasi klasifikasi CI meningkat dengan 2,3% atas garis dasar yang kuat ketika menggunakan fitur yang diproduksi oleh metode ini. Demonstrasi ini memberikan contoh bagaimana metode ini dapat digunakan untuk membantu klasifikasi di bidang di mana interpretabilitas penting, seperti perawatan kesehatan.', 'ko': '삽입된 기계 학습 방법을 바탕으로 자연 언어 처리 임무에서 광범위한 성공을 거두었지만 인지장애(CI) 검측 등 분야에서 해석하기 쉬운 공정 특징을 사용하는 것은 여전히 흔하다.시끄러운 텍스트에서 수동으로 특징을 디자인하는 데는 많은 시간과 자원을 소모하고 모델의 성능을 향상시키지 못하는 특징이 생길 수 있다.이 문제를 해결하기 위해 우리는 순서 기계 학습 모델과 분야 지식을 이용하여 어떤 특징이 성능 향상에 도움이 되는지 예측하는 새로운 특징 공학 방법을 묘사했다.우리는 표준적인 CI 음성 데이터 집합에서 이 방법의 구체적인 예시를 제공했고 이 방법으로 생성된 특징을 사용할 때 CI 분류 정밀도가 강기선보다 2.3% 높아졌다는 것을 증명했다.이 프레젠테이션은 해석성이 중요한 분야(예: 의료 기관)에서 이 방법을 사용하는 방법을 분류하는 데 도움을 주는 예를 제공합니다.', 'fa': 'با وجود موفقیت بسیار گزارش داده شده\u200cای از روش یادگیری دستگاه\u200cهای بنیادی بر روی کار\u200cهای پرداخت زبان طبیعی، استفاده از ویژگی\u200cهای مهندسی راحت ترجمه\u200cتر در زمینه\u200cها معمولی مانند آسیب شناخته\u200cای (CI) باقی ماند. ویژگی\u200cهای مهندسی دستی از متن صوتی زمان و مصرف منابع است و ممکن است نتیجه\u200cی ویژگی\u200cهایی که نمیتوانند عملکرد مدل را افزایش دهند. برای مبارزه با این، ما یک روش جدید برای ویژه مهندسی توصیف می\u200cکنیم که مدل یادگیری ماشین\u200cهای تعریف و دانش دامنی\u200cهای تعریف می\u200cکند تا پیش\u200cبینی کنیم که کدام ویژه\u200cهای کمک به افزایش عملکرد کمک می\u200cکن ما یک مثال قطعی از این روش بر روی مجموعه داده های استاندارد صحبت CI را پیشنهاد می کنیم و نشان می دهیم که دقیقات classification CI با 2.3% بر یک خط بنیادی قوی در زمان استفاده از ویژه های تولید از این روش بهتر می شود. این نمایش یک مثال از اینکه چگونه این روش می\u200cتواند از آن استفاده شود تا به گروه\u200cبندی در زمینه\u200cهایی که تعبیر قابلیت مهم است، مثل مراقبت سلامتی.', 'sw': 'Pamoja na mafanikio makubwa yaliyoripotiwa kwa njia za kujifunza kwa kutumia mashine yenye msingi katika kazi za utaratibu wa lugha za asili, matumizi ya vipengenezaji vinavyotafsiriwa kwa urahisi bado ni jambo la kawaida katika maeneo kama vile mabadiliko ya uchunguzi (CI). Tamko za kihandisi kutoka maandishi ya kelele ni wakati na matumizi ya rasilimali, na inaweza kusababisha vipengele ambavyo havitaongeza utendaji wa mifano. Ili kupambana na hili, tunaelezea mbinu mpya ya kutengeneza uhandisi ambazo zinatumia mifano ya kujifunza mfululizo wa mashine na maarifa ya ndani ya kutabiri ambayo inaonyesha kusaidia kuongeza utendaji. Tunatoa mfano maalum wa namna hii kwenye seti ya data ya kawaida ya hotuba ya CI na kuonyesha kwamba uhakika wa usalama wa CI unaongezeka kwa asilimia 2.3 zaidi ya msingi mkubwa wakati wa kutumia vipengele vilivyotengenezwa na njia hii. Maandamano haya yanatoa mfano wa namna mbinu hii inavyoweza kutumika ili kusaidia kutafsiri katika maeneo ambayo tafsiri ni muhimu, kama vile huduma za afya.', 'af': "Onthou die vaste berigteerde sukses van inbêer-gebaseerde masjien leer metodes op natuurlike taal verwerking opdragte, bly die gebruik van makliker uitgelaai inbêerde funksies gemeenskaplik in velde soos kognitiewe verwerking (CI) beskrywing. Hand in ženiering funksies van geluid teks is tyd en hulpbron gebruik, en kan potensieel resultaat in funksies wat nie model effektuur verhoog nie. Om hierdie te veg, beskrywe ons 'n nuwe toegang tot funksie inženiering wat sekwensiele masjien leer modele en domein kennis verwys om te voorskou wat funksies hulp te verbeter funksies. Ons verskaf 'n beteken voorbeeld van hierdie metode op 'n standaard data stel van CI spreek en wys dat CI klassifikasie presies verbeter deur 2.3% oor 'n sterk basilyn wanneer gebruik funksies wat deur hierdie metode produseer is. Hierdie demonstrasie verskaf 'n voorbeeld van hoe hierdie metode kan gebruik word om klasifikasie in velde te assistent waar uitlegging belangrik is, soos gesondige sorg.", 'tr': 'Doýal dil işlemegi üçin esasy ýagdaýda maşyny öwrenmek methodolarynyň üstüne alyp bildirilen täzelikleri, tanyş hasaplamak (CI) ýaly ýerlerde aňsatlyk terjime edilen enjiniýerlerin ulanmasy hem orta böleklerde. Sesli metinden el in ženjeriýa özellikleri zamandyr we ressurs ullanýan we nusgalary üçin üýtgetmeýän özelliklere üýtgedip biler. Şunlara garşy etmek üçin, biz enjiniýerlik üçin täze bir nusga tasvir edip, bu nusga enjiniýerlik öwrenme modellerini we domeniň bilgilerini nähili işlemleri täzeleştirmek üçin önlemek üçin janlaşdyrylýar. Biz bu yöntemi KI sözleriniň standart maglumat setirinde näbelli bir örnek bererik we bu yöntem tarapyndan üretilen özellikler ullanýand a CI klasifikasiýasynyň dogrylygyny 2.3% tarapyndan gowurap ýöreýäris. Bu demokrasiýa, saýlaw saglygyny ýaly klasifikasynda nähili ulanylyp biljek ýaly çykyşlyklaryň wajyp bolan sahypalarda kömek etmek üçin ullanylýan mysal getirýär.', 'am': 'ምንም እንኳን በተዘጋጀ የሆኑት መሣሪያን በመፍጠር ቋንቋ ማቀናቀል ሥርዓት ላይ የተደረገውን ስርዓት በመስጠት በተለየ የኢንተርኔት ምርጫዎች በተለየ ቀላል የሚተረጉት የኢንተርኔት ምርጫዎች እንደ ክፍት (ሲ) መጠቀም በሜዳዎች ውስጥ የተለየ ይኖራል፡፡ የድምፅ ጽሑፍ የመስመር ግንኙነቶች ሰዓት እና የክፍለ ዕቃ መጠቀሚያ ነው፡፡ ለዚህ ለመከላከል አዲስ የኢንጂንጂንተር ማስተማር እና የውይይት እውቀትን ለማሳየት የሚችሉትን አዲስ መንገድ እናሳውቃለን፡፡ ይህ ሥርዓት የሲ ቋንቋ የመደበኛ ዳታዎችን ማሳየት እናሳየዋለን እና የሲ መግለጫ እውነተኛነት በ2.3 በመቶው በይፋ በመጠቀም የሥርዓት ምርጫዎችን በመጠቀም ጊዜ በ2.3 በመቶ የበረታች በመስመር ይሻላል፡፡ ይህ ማስታወቂያው የጤና ፈቃድ እንደሆነ ትርጉም በሚያስፈልገው እርሻ ውስጥ እንዴት እንደተጠቃሚ ይደረጋል፡፡', 'hy': 'Չնայած բնական լեզվի վերամշակման խնդիրների վրա հիմնված մեքենայի ուսուցման մեթոդների լայն հաջողությանը, ավելի հեշտ մեկնաբանված ճարտարագիտական հատկությունների օգտագործումը շարունակում է հաճախ լինել այնպիսի ոլորտներում, ինչպիսիք են ճանաչո Ձեռքով ճարտարագիտական հատկությունները աղմկոտ տեքստից ժամանակ և ռեսուրսներ են պահանջում, և կարող են պոտենցիալ հանգեցնել հատկություններին, որոնք չեն բարելավում մոդելը: Այս դեմ պայքարելու համար մենք նկարագրում ենք նոր մոտեցում ճարտարագիտության առանձնահատկություններին, որը օգտագործում է սեքսենցիալ մեքենային ուսումնասիրության մոդելներ և տիեզերական գիտելիքներ, որպեսզի կանխատեսենք, թե որոնք Մենք այս մեթոդի կոնկրետ օրինակ ենք տալիս ինֆորմացիոն խոսքի ստանդարտ տվյալների համակարգի վրա և ցույց ենք տալիս, որ ինֆորմացիոն ինֆորմացիոն ինֆորմացիոն ինֆորմացիոն ինֆորմացիոն ինֆորմացիոն ինֆորմա Այս ցուցադրությունը ցույց է տալիս, թե ինչպես կարող է այս մեթոդը օգնել դասակարգում դասակարգելու այն ոլորտներում, որտեղ թարգմանելիությունը կարևոր է, ինչպիսիք են առողջապահությունը:', 'sq': 'Megjithë suksesin e njoftuar gjerësisht të metodave të mësimit të makinave bazuar në përfshirjen e detyrave natyrore të procesimit të gjuhës, përdorimi i elementeve më të lehta të interpretuara të inxhinierisë mbetet i zakonshëm në fusha të tilla si zbulimi i dëmtimit kognitiv (CI). Karakteristikat e inxhinierisë manuale nga teksti zhurmues janë kohë dhe konsumim i burimeve dhe mund të rezultojnë në karakteristika që nuk përmirësojnë performancën e modelit. Për të luftuar këtë, ne përshkruajmë një qasje të re për të shfaqur inxhinierinë që përdorë modelet e mësimit sekuencor të makinave dhe njohuritë e dominit për të parashikuar cilat funksione ndihmojnë të përmirësojnë performancën. Ne japim një shembull konkret të këtij metode në një sërë të dhënash standarte të fjalimit të CI dhe demonstrojmë se saktësia e klasifikimit të CI përmirësohet me 2.3% mbi një bazë të fortë kur përdoret karakteristika të prodhuara nga ky metodë. Kjo demonstrim ofron një shembull se si ky metodë mund të përdoret për të ndihmuar klasifikimin në fusha ku interpretueshmëria është e rëndësishme, të tilla si kujdesi shëndetësor.', 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ার কাজের উপর ভিত্তিক মেশিন শিক্ষা পদ্ধতির ব্যাপক সংবাদ প্রদান করা সত্ত্বেও, সহজে ব্যবহার করা ইঞ্জিনিয়ান বৈশিষ্ট্যের ব্যবহার হাতিয়ালি ইঞ্জিনিয়ারিং বৈশিষ্ট্যাবলী টেক্সটের বৈশিষ্ট্য হচ্ছে সময় এবং সম্পদ ব্যবহার করা, এবং সম্ভাব্য ভাবে মোডেলের প্রদর্শনের এর বিরুদ্ধে যুদ্ধ করার জন্য আমরা একটি নতুন পদ্ধতি বর্ণনা করি যা পরবর্তীতে মেশিন শিক্ষা মডেল এবং ডোমেইনের জ্ঞানের মাধ্যমে ধারণা করা যায় যে কোন প আমরা এই পদ্ধতির একটি নির্দিষ্ট উদাহরণ দিয়েছি সিআই ভাষণের স্ট্যান্ডার ডাটা সেটের উপর এবং প্রমাণিত করেছি যে সিআই ক্লাস্ফিকেশনের সঠিকভাবে ২. এই প্রতিবাদের উদাহরণ দিয়েছে কিভাবে এই পদ্ধতি ব্যবহার করতে পারে যেখানে ব্যাখ্যা গুরুত্বপূর্ণ, যেমন স্বাস্থ্য সেবা য', 'az': 'Təbiətli dil işləmə işləri barəsindəki maşın öyrənmə metodlarının çox yayınlanmış başarılı olmasına rağmen, daha asanlıqla təfsil edilmiş mühendisə özelliklərinin istifadəsi yoxdur, bəlkə bilgili zəiflik (CI) tanıması kimi sahələrdə ortaq qalar. Səs metindən əlli in ženjeri xüsusiyyətlər vaxtdır və ressurs istifadəsidir, və modellərin performansını artırmayan fəaliyyətlərə mümkün olar. Bununla döyüşə çıxmaq üçün yeni inženjeri təhsil etmək üçün yeni bir tərzi təsbit edirik ki, bu maşın öyrənməsi modellərini və domenin elmi təsbit edir ki, hansı tərzlərinin performansını artırmağa kömək edir. Biz bu metodların standart verilən CI sözlərinin istifadə etdiyi tərzlərin istifadə edərkən CI klasifikasiyasının doğruluğu 2.3% ilə çox qüvvətli baseline üstündə yaxşılaşdığını göstəririk. Bu göstəriş, sağlamlıq məlumatı kimi, yoxluq vacib olduğu sahələrdə klasifikasiya kömək etmək üçün bu metod necə istifadə edilə bilər?', 'bs': 'Uprkos širokim prijavljenim uspjehom metoda učenja strojeva na temelju integracije prirodnog jezika, upotreba lako interpretiranih in ženjerskih karakteristika ostaje česta u poljima poput otkrivanja kognitivnog oštećenja (CI). Ručno in ženjerske funkcije iz zvukovnog teksta su vrijeme i potrošenje resursa, te mogu potencijalno rezultirati karakteristike koje ne poboljšavaju modelnu funkciju. Da bi se borili protiv ovoga, opisali smo novi pristup inženjerstvu koji utiče na sekvencijske modele učenja mašina i znanje domena da predvidimo koje karakteristike pomažu unapređivati učenje. Mi pružamo konkretni primjer ove metode o standardnom setu podataka govora CI-a i pokazujemo da se preciznost klasifikacije CI poboljšava za 2,3% nad jakom početnom linijom kada koristimo funkcije proizvođene ovim metodom. Ova demonstracija pruža primjer kako se ova metoda može iskoristiti kako bi pomogla klasifikaciji u poljima gdje je interpretabilnost važna, kao što je zdravstvena zaštita.', 'cs': 'Navzdory široce hlášenému úspěchu metod strojového učení založených na vložení do úloh zpracování přirozeného jazyka zůstává použití snadněji interpretovaných inženýrských funkcí běžné v oblastech, jako je detekce kognitivních poruch (CI). Ruční inženýrství funkcí z hlučného textu je čas a zdroje náročné a může potenciálně vést k funkcím, které nezlepšují výkon modelu. Abychom tomu mohli bojovat, popisujeme nový přístup k inženýrství funkcí, který využívá sekvenční modely strojového učení a znalosti domény k předpovědi, které funkce pomáhají zlepšit výkon. Konkrétní příklad této metody uvádíme na standardní datové sadě CI řeči a demonstrujeme, že při použití funkcí produkovaných touto metodou se přesnost CI klasifikace zlepšuje o 2,3% oproti silnému základnímu principu. Tato ukázka představuje příklad toho, jak může být tato metoda použita k pomoci klasifikaci v oblastech, kde je důležitá interpretovatelnost, jako je zdravotní péče.', 'ca': "Malgrat l'èxit generalment notificat de l'incorporació de mètodes d'aprenentatge automàtic en tasques naturals de processament de llenguatges, l'ús de característiques més fàcilment interpretades encara és comú en camps com la detecció de compromís cognitiu. Les característiques d'enginyeria manuals del text sorollós consumeixen temps i recursos i poden resultar en característiques que no milloren el rendiment del model. Per combatre això, descrivim un nou enfocament a l'enginyeria que utilitza models seqüencials d'aprenentatge màquinari i coneixement de domini per predir quines característiques ajuden a millorar el rendiment. Oferem un exemple concret d'aquest mètode en un conjunt de dades estándar de discurs CI i demostrem que la precisió de la classificació CI millora un 2,3% sobre una base de referència forta quan utilitzem característiques produïdes per aquest mètode. Aquesta demostració proporciona un exemple de com aquest mètode pot ser utilitzat per ajudar a la classificació en camps on l'interpretabilitat és important, com la sanitat.", 'et': 'Vaatamata laialdaselt teatatud edule masinõppemeetodite manustamisel looduskeele töötlemise ülesannetele, on sellistes valdkondades nagu kognitiivse kahjustuse tuvastamine jätkuvalt tavaliselt tõlgendatud tehniliste funktsioonide kasutamine. Mürakast tekstist funktsioonide käsitsi projekteerimine nõuab aega ja ressursse ning võib kaasa tuua funktsioone, mis ei paranda mudeli jõudlust. Selle vastu võitlemiseks kirjeldame uut lähenemisviisi funktsioonide insenerile, mis kasutab järjestikuseid masinõppemudeleid ja domeeniteadmisi, et ennustada, millised funktsioonid aitavad jõudlust parandada. Esitame konkreetse näite selle meetodi kohta standardse CI kõne andmekogumi kohta ja näitame, et CI klassifitseerimise täpsus paraneb 2,3% võrreldes tugeva algtasemega, kui kasutatakse selle meetodiga toodetud funktsioone. See näide annab näite sellest, kuidas seda meetodit saab kasutada klassifitseerimiseks valdkondades, kus tõlgendatavus on oluline, näiteks tervishoid.', 'fi': 'Huolimatta laajasti raportoidusta menestyksestä upottaa koneoppimismenetelmiä luonnollisen kielen käsittelytehtäviin, helpommin tulkittavien teknisten ominaisuuksien käyttö on edelleen yleistä esimerkiksi kognitiivisen häiriön havaitsemisessa. Ominaisuuksien manuaalinen suunnittelu meluisasta tekstistä vie aikaa ja resursseja ja voi mahdollisesti johtaa ominaisuuksiin, jotka eivät paranna mallin suorituskykyä. Tämän torjumiseksi kuvaamme uutta lähestymistapaa ominaisuussuunnitteluun, joka hyödyntää koneoppimismalleja ja toimialueen tietämystä ennustaakseen, mitkä ominaisuudet auttavat parantamaan suorituskykyä. Esitämme konkreettisen esimerkin tästä menetelmästä CI-puheen vakioaineistosta ja osoitamme, että CI-luokituksen tarkkuus paranee 2,3% verrattuna vahvaan lähtötilanteeseen käyttämällä menetelmällä tuotettuja ominaisuuksia. Tämä esittely antaa esimerkin siitä, miten tätä menetelmää voidaan käyttää luokitteluun aloilla, joilla tulkittavuus on tärkeää, kuten terveydenhuollossa.', 'sk': 'Kljub široko poročanemu uspehu vključevanja metod strojnega učenja na opravila obdelave naravnega jezika, je uporaba lažje interpretiranih inženirskih funkcij še vedno pogosta na področjih, kot je zaznavanje kognitivnih okvar (CI). Ročno oblikovanje funkcij iz hrupnega besedila zahteva čas in vire ter lahko povzroči funkcije, ki ne izboljšajo zmogljivosti modela. Za boj proti temu opisujemo nov pristop k inženiringu funkcij, ki uporablja zaporedne modele strojnega učenja in domensko znanje za predvidevanje, katere funkcije pomagajo izboljšati zmogljivost. Prikazujemo konkreten primer te metode na standardnem naboru podatkov govora CI in dokazujemo, da se natančnost klasifikacije CI izboljša za 2,3% v primerjavi z močno izhodiščno vrednostjo pri uporabi funkcij, izdelanih s to metodo. Ta predstavitev ponuja primer, kako lahko to metodo uporabimo za pomoč pri klasifikaciji na področjih, kjer je pomembna razlagalnost, kot je zdravstveno varstvo.', 'ha': "Babu da bayani da aka faɗaɗa musamman wa zane-zane masu amfani da shiryoyin ayukan da aka shigar da shi a cikin shirin ayuka, sai amfani da amfani da masu fassarawa masu sauƙi da fassarar da aka fassara, yana da kawaici a cikin field kamar misãlin zane-zane-zane (CI). Furofati na masu inganci na hannayen iyalana daga matsayin sauti, yana da lokaci da amfani da abinci, kuma yana iya iya ƙara wa masu haske da za'a ƙara umarni misãlai. Yana bayyana wani takwara ga masu amfani da muhalli na Ingirin da ke ƙaranci masu karatun misãlai da ilmi na danne da bakin da za'a yi bayani ga wani abu wanda ya fi ƙaranci ga aikin aiki. We provide a concrete example of this method on a standard data set of CI speech and demonstrate that CI classification accuracy improves by 2.3% over a strong baseline when using features produced by this method.  Wannan shirin nuna yana buga wani misali kamar yadda za'a iya amfani da wannan metode dõmin a taimake su rarraba cikin filayen da za'a da muhimu fassarar fassarar, kamar ruwan afya.", 'he': 'למרות ההצלחה המדווחת באופן רחב של שיטות לימוד מכונות מבוססות על משימות עיבוד שפת טבעיות, השימוש של תכונות הנדסה המפורסמות בקלות יותר נשאר נפוץ בשדות כמו זיהוי הפרעה קוגניטיבית (CI). תכונות הנדסה בידיים מתוך טקסט רעש הם שימוש בזמן ומשאבים, ויכולים להוביל בהתכונות שאינן משתפרות ביצועי מודל. כדי להילחם בזה, אנחנו מתארים גישה חדשה לתאר הנדסה שמשתמשת בדוגמנים שליליים של למידת מכונות וידע שטח כדי לחזות איזה תכונות עוזרים לשפר את ההופעה. אנו מספקים דוגמא konkretה של השיטה הזו על קבוצת נתונים סטנדרטית של נאום CI ומוכיחים כי מדויקת סיווג CI משתפרת על 2.3% מעל בסיס חזק כשמשתמשים בתחומים שנוצרים על ידי השיטה הזו. ההדגמה הזו מספקת דוגמא של איך השיטה הזאת יכולה להשתמש כדי לסייע להקליטה בשטחים שבו היכולת לפרש חשובה, כמו טיפול בריאות.', 'jv': 'Nanging kabeh luwih akeh pemberok nggawe sistem sistem sing paling nggawe perusahaan langgar-sistem batasan winih, gampang uga kebutuhan cara-jinahan sing paling nggawe cara-jinahan liyane koyo ngono nggunaken gerangkat luwih (CI). section To combat this, we describe a new method to character design that méerage sequital device Learning modes and domain knowingto warn that options help advancence success. Awak dhéwé éngawe akeh sampeyan akeh dhéwé nggawe sistem iki ning awak dhéwé dadi CI kesempalahan seneng nggawe kesempalahan kanggo ngerasakno 2.3% kesempalahan kanggo mbalkan siji maneh dumaten Uneng aplikasi iki mudyane diumbang kelompok ing pancene iki baka bisa supoyo sak ngerasakno ning acara sing dikarepaké kapan ingkang dipunahang, koyo ngono sak-salamat.', 'bo': 'ཡིན་ནའང་ཡང་ན་ embedding-based machine learning methods on natural language processing tasks་ལ་widely reported success.The use of more easily interpreted engineered features remains common in fields such as cognitive impairment (CI) detection. Manually engineering features from noisy text is time and resource consuming, and can potentially result in features that do not enhance model performance. To combat this, we describe a new approach to feature engineering that leverages sequential machine learning models and domain knowledge to predict which features help enhance performance. We provide a concrete example of this method on a standard data set of CI speech and demonstrate that CI classification accuracy improves by 2.3% over a strong baseline when using features produced by this method. བཀྲམ་སྟོན་འདིས་ཐབས་ལམ་འདི་ཅི་ཞིག་སྤྱད་ནས་དབྱེ་རིམ་གྱི་ནང་དུ་དམིགས་གསལ་ཆེན་གལ་ཅན་ཡོད་པའི་དབྱེ་བ་དག་སྟོན་པར་བ'}
{'en': 'Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest T witter ( CUT ): A Dataset of Tweets to Support Research on Civil Unrest', 'ar': 'الاضطرابات المدنية على تويتر (CUT): مجموعة بيانات من التغريدات لدعم البحث عن الاضطرابات المدنية', 'fr': 'Civil Unrest on Twitter (CUT)\xa0: un ensemble de tweets pour soutenir la recherche sur les troubles civils', 'pt': 'A agitação civil no Twitter (CUT): um conjunto de dados de tweets para apoiar a pesquisa sobre a agitação civil', 'es': 'Disturbios civiles en Twitter (CUT): un conjunto de datos de tuits para apoyar la investigación sobre disturbios civiles', 'ja': 'Twitterでの内乱（ CUT ） ：内乱に関する研究を支援するツイートのデータセット', 'zh': 'Twitter上乱(CUT):持内乱推文数集', 'ru': 'Гражданские беспорядки в Twitter (CUT): Набор твитов в поддержку исследования гражданских беспорядков', 'hi': 'चहचहाना पर नागरिक अशांति (कट): नागरिक अशांति पर अनुसंधान का समर्थन करने के लिए Tweets का एक डेटासेट', 'ga': 'Míshuaimhneas Sibhialta ar Twitter (CUT): Tacar Sonraí de Thvuíteanna chun Tacú le Taighde ar Chorpráid Shibhialta', 'ka': 'საზოგადო არაფერი Twitter-ში (CUT): საზოგადო საზოგადო საზოგადო არაფერების შესახებ', 'hu': 'Civil Unrest on Twitteren (CUT): Tweet adatkészlet a civil Unrest kutatására', 'el': 'Πολιτική Ανησυχία στο Twitter (CUT): Ένα σύνολο δεδομένων για την υποστήριξη της έρευνας για την αστική Ανησυχία', 'lt': 'Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest', 'mk': 'Граѓанска несреќа на Твитер (CUT): Папка податоци на Твитери за поддршка на истражувањето за граѓанска несреќа', 'kk': 'Твиттердегі Civil Unrest (CUT): Твиттерді қолдау үшін Твиттердің деректер қоры', 'ms': 'Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest', 'it': "Civil Unrest on Twitter (CUT): un dataset di tweet a supporto della ricerca sull'Unrest civile", 'mn': 'Твиттерт иргэн хамгаалахгүй хүмүүс (CUT): Твиттерийн мэдээллийг дэмжихийн тулд', 'ml': 'ടൂട്ടറില്\u200d സിവില്\u200d അറസ്റ്റ് (സിയുടി): സിവില്\u200d അറസ്റ്റിനെ പിന്തുണയ്ക്കാന്\u200d വേണ്ടി ഒരു ഡാറ്റാസെറ്റ് ട', 'no': 'Name', 'pl': 'Niepokój cywilny na Twitterze (CUT): Zestaw danych tweetów wspierających badania nad niepokojem cywilnym', 'ro': 'Civil Unrest on Twitter (CUT): Un set de date de tweets pentru a sprijini cercetarea privind neliniștea civilă', 'mt': "Qtugħ Ċivili fuq Twitter (CUT): Sett ta' Dejta ta' Tweets li jappoġġja r-Riċerka dwar Qtugħ Ċivili", 'si': 'ට්විටර් වල සිවිල් අන්රිස්ට් (CUT): සිවිල් අන්රිස්ට් වලට පරීක්ෂණය සහයෝධ කරන්න දත්ත සංවේදනය', 'so': 'Shaqooyiga nasiibka ah ee Twita (CUT): A data set of Tweets in ay kaalmeeyaan baaritaanka dadka nasiibka ah', 'sv': 'Civil Unrest på Twitter (CUT): En dataset med tweets för att stödja forskning om civil Unrest', 'ta': 'தொடர்பில் சிவில் வெறுமை', 'sr': 'Građanski neprijatelj na Twitter (CUT): Datata Tweets za podršku istraživanja o civilnim neprijateljima', 'ur': 'ٹویٹر (CUT) پر سیویل Unrest: سیویل Unrest کے تحقیقات کی مدد کرنے کے لئے ٹویٹوں کی ایک ڈیٹ سٹ', 'uz': 'Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest', 'vi': 'Không công dân trên Twitter: A Dữ liệu thời trang để hỗ trợ nghiên cứu về quần chúng bất động', 'bg': 'Граждански неспокой в Туитър: Набор от данни от туитове в подкрепа на изследванията за граждански неспокой', 'da': 'Civil Usrest på Twitter (CUT): Et datasæt tweets til støtte for forskning om civil Usrest', 'hr': 'Građanski neprijatelj na Twitter (CUT): Dat podataka Tweets za podršku istraživanja o građanskom neprijatelju', 'nl': 'Burgerlijke onrust op Twitter (CUT): Een dataset tweets ter ondersteuning van onderzoek naar burgerlijke onrust', 'de': 'Zivile Unruhe auf Twitter (CUT): Ein Datensatz von Tweets zur Unterstützung der Erforschung ziviler Unruhe', 'ko': '트위터의 내란(CUT): 내란 연구를 지원하는 트위터 데이터 세트', 'id': 'Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest', 'fa': 'شهروند عمومی در توئیتر (CUT): یک داده\u200cای از Tweets برای پشتیبانی تحقیقات درباره\u200cی ناآرامش شهروند', 'sw': 'Wasafiki wa kiraia kwenye mtandao wa Twita (CUT): Taarifa za Twita za kuunga mkono Utafiti wa Uchaguzi wa Kiraia', 'sq': 'Unrest Civil on Twitter (CUT): A Datset of Tweets to Support Research on Civil Unrest', 'af': "Civile Unrest op Twitter (CUT): ' n Dataset van Tweets na ondersteun Research op Civile Unrest", 'tr': 'Týuterdeki Halkara Gaddaşlaryň (CUT): Halkara Gaddaşlaryň Araştyrmalaryny Desteklemek üçin Tweet Datasy', 'am': 'የሲቪል ዕረፍት በትዊተር (CUT): የሲቪል ዕረፍት ምርመራ ለመደገፍ የTwitteets ድርጅት', 'hy': 'Քաղաքացիական անհանգստություն Թվիթերում (CuT): Քաղաքացիական անհանգստության հետազոտությունների աջակցությունը', 'bn': 'টুইটারে সিভিল আনরেস্ট (সিউটি): নাগরিক বিশ্রামের গবেষণা সমর্থনের জন্য টুইটারের একটি তথ্য সেট', 'bs': 'Građanski neprijatelj na Twitter (CUT): Dat podataka Tweets za podršku istraživanja o civilnim neprijateljima', 'ca': 'Civil Unrest on Twitter (CUT): Un conjunt de dades de Tweets que suporta la recerca sobre Civil Unrest', 'cs': 'Občanský nepokoj na Twitteru (CUT): Datová sada tweetů na podporu výzkumu občanských nepokojů', 'et': 'Tsiviilrahutus Twitteris (CUT): Tweetide andmekogum tsiviilrahutuse uurimise toetamiseks', 'fi': 'Kansalaislevottomuus Twitterissä (CUT): Tietosarja twiittejä siviililevottomuuden tutkimuksen tueksi', 'az': 'İncil Unrest on Twitter (CUT): Civil Unrest araştırmalarını desteklemek üçün Tweets verilən', 'jv': 'Cino Unreste nang Google (CUT) : A dataase of Tuts to supported Search on Cino Unrests', 'sk': 'Civilni nemir na Twitterju (CUT): Zbirka podatkov za podporo raziskavam civilnega nemora', 'ha': '@ info: status', 'he': 'חסר תנוחה אזרחית בטוויטר (CUT): קבוצת נתונים של טוויטרים לתמוך במחקר על חסר תנוחה אזרחית', 'bo': 'Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest'}
{'en': 'We present CUT, a  dataset  for studying  Civil Unrest  on  Twitter . Our dataset includes 4,381 tweets related to  civil unrest , hand-annotated with information related to the study of civil unrest discussion and events. Our  dataset  is drawn from 42 countries from 2014 to 2019. We present  baseline systems  trained on this  data  for the identification of tweets related to  civil unrest . We include a discussion of ethical issues related to research on this topic.', 'fr': "Nous présentons CUT, un ensemble de données pour étudier les troubles civils sur Twitter. Notre ensemble de données comprend 4 381 tweets liés à des troubles civils, annotés à la main avec des informations relatives à l'étude des discussions et des événements liés aux troubles civils. Notre ensemble de données provient de 42 pays de 2014 à 2019. Nous présentons des systèmes de base formés à partir de ces données pour l'identification des tweets liés à des troubles civils. Nous incluons une discussion sur les questions éthiques liées à la recherche sur ce sujet.", 'ar': 'نقدم CUT ، مجموعة بيانات لدراسة الاضطرابات المدنية على Twitter. تتضمن مجموعة البيانات لدينا 4381 تغريدة تتعلق بالاضطرابات المدنية ، مشروحة يدويًا بالمعلومات المتعلقة بدراسة مناقشات وأحداث الاضطرابات المدنية. مجموعة البيانات الخاصة بنا مأخوذة من 42 دولة من 2014 إلى 2019. نقدم أنظمة أساسية مدربة على هذه البيانات لتحديد التغريدات المتعلقة بالاضطرابات المدنية. نقوم بتضمين مناقشة القضايا الأخلاقية المتعلقة بالبحث حول هذا الموضوع.', 'pt': 'Apresentamos o CUT, um conjunto de dados para estudar a agitação civil no Twitter. Nosso conjunto de dados inclui 4.381 tweets relacionados a distúrbios civis, anotados à mão com informações relacionadas ao estudo de discussões e eventos de distúrbios civis. Nosso conjunto de dados é extraído de 42 países de 2014 a 2019. Apresentamos sistemas de linha de base treinados nesses dados para a identificação de tweets relacionados a distúrbios civis. Incluímos uma discussão de questões éticas relacionadas à pesquisa sobre este tema.', 'es': 'Presentamos CUT, un conjunto de datos para estudiar los disturbios civiles en Twitter. Nuestro conjunto de datos incluye 4,381 tuits relacionados con disturbios civiles, anotados a mano con información relacionada con el estudio de los debates y eventos de disturbios civiles. Nuestro conjunto de datos se basa en 42 países de 2014 a 2019. Presentamos sistemas de referencia capacitados en estos datos para la identificación de tuits relacionados con disturbios civiles. Incluimos una discusión sobre cuestiones éticas relacionadas con la investigación sobre este tema.', 'ja': '内乱を研究するためのデータセット「CUT」をTwitterでご紹介します。当社のデータセットには、内乱に関する4,381件のツイートが含まれており、内乱に関する議論と事象の研究に関連する情報が手書きで注釈されています。当社のデータセットは、2014年から2019年までの42か国から抽出されています。内乱に関連するツイートを識別するために、このデータについてトレーニングを受けたベースラインシステムを提示します。このトピックの研究に関連する倫理的な問題の議論を含みます。', 'zh': '展CUT于Twitter,所以究内乱之数集也。 臣等数集4,381条与内乱相关之推文,并手工注与内乱讨论事件相关信息。 数集自2014至2019年42国。 备数训练之基线统,以识内乱之推文。 我们与该主题研究相关的伦理。', 'hi': 'हम CUT, चहचहाना पर नागरिक अशांति का अध्ययन करने के लिए एक डेटासेट प्रस्तुत करते हैं। हमारे डेटासेट में नागरिक अशांति से संबंधित 4,381 ट्वीट शामिल हैं, जो नागरिक अशांति चर्चा और घटनाओं के अध्ययन से संबंधित जानकारी के साथ हाथ से एनोटेट किए गए हैं। हमारा डेटासेट 2014 से 2019 तक 42 देशों से तैयार किया गया है। हम नागरिक अशांति से संबंधित ट्वीट्स की पहचान के लिए इस डेटा पर प्रशिक्षित बेसलाइन सिस्टम पेश करते हैं। हम इस विषय पर अनुसंधान से संबंधित नैतिक मुद्दों की चर्चा शामिल करते हैं।', 'ru': 'Мы представляем CUT, набор данных для изучения гражданских беспорядков в Twitter. Наш набор данных включает 4381 твит, связанный с гражданскими беспорядками, с ручной аннотацией с информацией, связанной с исследованием обсуждений и событий гражданских беспорядков. Наш набор данных взят из 42 стран с 2014 по 2019 год. Мы представляем базовые системы, обученные этим данным для идентификации твитов, связанных с гражданскими беспорядками. Мы включаем обсуждение этических вопросов, связанных с исследованиями по этой теме.', 'ga': 'Cuirimid i láthair CUT, tacar sonraí chun staidéar a dhéanamh ar an gConnadh Sibhialta ar Twitter. Áiríonn ár dtacar sonraí 4,381 tvuít a bhaineann le corraíl shibhialta, agus iad nótaí láimhe le faisnéis a bhaineann le staidéar a dhéanamh ar phlé agus ar imeachtaí corraíl sibhialta. Tarraingítear ár dtacar sonraí ó 42 tír ó 2014 go 2019. Cuirimid i láthair córais bonnlíne oilte ar na sonraí seo chun tweets a bhaineann le corraíl shibhialta a shainaithint. Áirímid plé ar shaincheisteanna eiticiúla a bhaineann le taighde ar an ábhar seo.', 'ka': 'ჩვენ CUT-ს გამოსახულებთ, სახელსაწყოთა სახელსაწყოთა სახელსაწყოთან Twitter-ში. ჩვენი მონაცემების კონფიგურაცია აქვს 4 381 ტივიტები, რომელიც სახელსაწყისთვის დაკავშირებულია, ინფორმაციის შესახებ, რომელიც სახელსაწყისთვის განსწავლებელი ჩვენი მონაცემების კონფიგურაცია 2014-2019-დან 42 ქვეყნებიდან გადატანა. ჩვენ ამ მონაცემებისთვის გასაბამისი სისტემები გამოყენებთ, რომელიც სახელსაწყისთვის შესახებ გასაბამისი შეცდომა. ჩვენ ამისთვის ეტიკალური პრობლემების განსაზღვრება, რომელიც ამისთვის შესაძლებელია.', 'hu': 'Bemutatjuk a CUT adatkészletet a Civil Unrest tanulmányozására Twitteren. Adatkészletünk 4 381 polgári zavargással kapcsolatos tweetet tartalmaz, amelyeket kézzel jegyzeteltek a polgári zavargások és események tanulmányozásával kapcsolatos információkkal. Adatkészletünk 42 országból készült 2014 és 2019 között. Ezekre az adatokra képzett alapvető rendszereket mutatunk be a polgári zavargásokkal kapcsolatos tweetek azonosítására. Az e témával kapcsolatos kutatásokkal kapcsolatos etikai kérdésekről beszélünk.', 'el': 'Παρουσιάζουμε το CUT, ένα σύνολο δεδομένων για τη μελέτη της πολιτικής ανησυχίας στο Twitter. Το σύνολο δεδομένων μας περιλαμβάνει 4.381 που σχετίζονται με τις πολιτικές αναταραχές, σχολιασμένα με πληροφορίες που σχετίζονται με τη μελέτη των συζητήσεων και των γεγονότων της πολιτικής αναταραχής. Το σύνολο δεδομένων μας αντλείται από 42 χώρες από 2014 έως 2019. Παρουσιάζουμε συστήματα βάσης εκπαιδευμένα σε αυτά τα δεδομένα για τον προσδιορισμό των tweets που σχετίζονται με τις πολιτικές αναταραχές. Περιλαμβάνει μια συζήτηση ηθικών ζητημάτων που σχετίζονται με την έρευνα σε αυτό το θέμα.', 'it': "Presentiamo CUT, un set di dati per studiare Civil Unrest su Twitter. Il nostro set di dati include 4.381 tweet relativi ai disordini civili, annotati a mano con informazioni relative allo studio delle discussioni e degli eventi sui disordini civili. Il nostro set di dati è tratto da 42 paesi dal 2014 al 2019. Presentiamo sistemi di base addestrati su questi dati per l'identificazione dei tweet relativi ai disordini civili. Includiamo una discussione di questioni etiche legate alla ricerca su questo argomento.", 'kk': 'Біз Твиттерде "Civil Unrest" дегенді оқу үшін CUT дегенді таңдаймыз. Деректер жиынымыздың 4 381 tweets жалғыз белсенділіктер мен оқиғаларды зерттеу туралы мәліметті қолмен жазылған. Біздің деректер жиынымыз 2014 жылдан 2019 жылдан 42 елден шығарылды. Біз бұл деректерге ауыстырылған негізгі жолдар жүйелерін жалпы ауыстыруға қатынау үшін таңдаймыз. Бұл нақышты зерттеу сәйкесті этикалық мәселелер туралы дискуссия жасайды.', 'ms': 'Kami perkenalkan CUT, set data untuk mempelajari Civil Unrest di Twitter. Set data kami termasuk 4,381 tweet berkaitan dengan kekacauan awam, ditandakan dengan maklumat berkaitan dengan kajian perbualan kekacauan awam dan peristiwa. Set data kita dilukis dari 42 negara dari 2014 hingga 2019. Kami mempersembahkan sistem asas dilatih pada data ini untuk pengenalpasti tweet berkaitan dengan kekacauan awam. Kami termasuk perbincangan mengenai isu etika yang berkaitan dengan kajian mengenai topik ini.', 'lt': 'Mes pristatome CUT, duomenų rinkinį, skirtą civiliniam nerimavimui Twitter studijuoti. Mūsų duomenų rinkinyje yra 4 381 tweetų, susijusių su civiliniais neramumais, su informacija, susijusia su civilinių neramumų diskusijų ir įvykių tyrimu. Mūsų duomenų rinkinys parengtas iš 42 šalių nuo 2014 m. iki 2019 m. We present baseline systems trained on this data for the identification of tweets related to civil unrest.  We include a discussion of ethical issues related to research on this topic.', 'mk': 'Презентираме CUT, компјутер на податоци за студирање на цивилниот непријател на Твитер. Нашиот податок вклучува 4.381 твитови поврзани со граѓанските немири, рачно анотирани со информации поврзани со студијата на дискусијата за граѓанските немири и настаните. Нашите податоци се извлечени од 42 земји од 2014 до 2019 година. Презентираме основни системи обучени на овие податоци за идентификација на твитови поврзани со граѓанските немири. Ние вклучуваме дискусија за етички прашања поврзани со истражувањето на оваа тема.', 'ml': 'ടൂട്ടരില്\u200d സിവില്\u200d അറസ്റ്റ് പഠിക്കാനുള്ള ഒരു ഡാറ്റാസെറ്റ് സിയുട്ടിനെ ഞങ്ങള്\u200d കാണിക്കുന ഞങ്ങളുടെ ഡാറ്റാസെറ്റില്\u200d 4,381 ടൂട്ടികള്\u200d ഉണ്ട്, നാട്ടിലെ കുഴപ്പമുള്ള വിരോധത്തിനെക്കുറിച്ച് ബന്ധപ്പെട്ടിരിക്കു ഞങ്ങളുടെ ഡാറ്റാസേറ്റ് 2014 മുതല്\u200d 2019 വരെ 42 രാജ്യങ്ങളില്\u200d നിന്നും വലിച്ചെടുത്തിരിക്കുന്നു. ഈ വിവരങ്ങളില്\u200d നമ്മള്\u200d ബെസ്ലൈന്\u200d സിസ്റ്റം പരിശീലിക്കുന്നു. സൗവകാര്യത്തിലെ വിരോധത്തിന്റെ തിരിച് ഈ കാര്യത്തില്\u200d പഠിക്കുന്നതിനെക്കുറിച്ച് നമുക്കൊരു നീതികമായ പ്രശ്നങ്ങളെക്കുറിച്ച് ഒര', 'mt': 'Aħna nippreżentaw CUT, sett ta’ dejta għall-istudju tal-Qtugħ Ċivili fuq Twitter. Is-sett tad-dejta tagħna jinkludi 4 381 tweet relatati ma’ taqlib ċivili, annotati bl-idejn b’informazzjoni relatata mal-istudju ta’ diskussjoni u avvenimenti ta’ taqlib ċivili. Is-sett tad-dejta tagħna huwa miġbur minn 42 pajjiż mill-2014 sal-2019. Aħna nippreżentaw sistemi bażiċi mħarrġa fuq din id-dejta għall-identifikazzjoni ta’ tweets relatati ma’ taqlib ċivili. Inkludu diskussjoni dwar kwistjonijiet etiċi relatati mar-riċerka dwar dan is-suġġett.', 'pl': 'Prezentujemy CUT, zbiór danych służący do badania niepokoju cywilnego na Twitterze. Nasz zestaw danych obejmuje 4,381 tweety związane z niepokojami społecznymi, ręcznie adnotacjonowane informacjami związanymi z badaniem dyskusji i wydarzeń związanych z niepokojami obywatelskimi. Nasz zestaw danych pochodzi z 42 krajów od 2014 do 2019. Przedstawiamy systemy bazowe przeszkolone na tych danych do identyfikacji tweetów związanych z niepokojami społecznymi. Obejmujemy dyskusję na temat kwestii etycznych związanych z badaniami nad tym tematem.', 'ro': 'Vă prezentăm CUT, un set de date pentru studiul Civil Unrest pe Twitter. Setul nostru de date include 4.381 tweet-uri legate de tulburările civile, adnotate manual cu informații legate de studiul discuțiilor și evenimentelor legate de tulburările civile. Setul nostru de date este extras din 42 de țări din 2014 până în 2019. Vă prezentăm sisteme de bază instruite pe aceste date pentru identificarea tweeturilor legate de tulburările civile. Includem o discuție asupra problemelor etice legate de cercetarea pe acest subiect.', 'no': 'Vi presenterer CUT, eit dataset for å studera Civile Unrest på Twitter. Datasettet vårt inneheld 4.381 twett relatert til civile ønskjer, handmerket med informasjon relatert til studien av civile ønskjer og hendingar. Datasett vårt er teikna frå 42 land frå 2014 til 2019. Vi presenterer grunnlinjesystemet trengte på denne data for identifisering av tweeter som er relatert til sivile ønskjer. Vi inkluderer eit diskusjon om etiske problemer som er relatert til forskning på dette emnet.', 'so': 'Waxaynu soo bandhignaynaa CUT, taas oo ah koob macluumaad la xiriira waxbarashada muwaadiniinta ee shacabka ah ee Twitterka. Taariikhdayada waxaa ku jira 4,381 tweeti la xiriira rabshadda bulshada, warbixin la xiriira waxbarashada kala sheekaynta iyo dhacdooyinka bulshada. Shaqo macluumaadyadeena waxaa laga soo qaaday 42 waddam tan iyo 2014 ilaa 2019. Waxaannu soo bandhignaa nidaamka aasaasiga ah oo lagu tababaray macluumaadkaas si aan u aqoonsado tweetka la xiriira rabshadda bulshada. Waxaynu ku qornaa sheekeysi arimaha asalka ah ee la xiriira waxbarashada arimahan.', 'mn': 'Бид Твиттерт Их Бүхдийн Их Сургууль судлах өгөгдлийн сан CUT-г тайлбарлаж байна. Бидний өгөгдлийн санд иргэний зөрчилдөөнд холбогдсон 4,381 tweet, иргэний зөрчилдөөн болон үйл явдлын судалгаанд холбогдсон мэдээллээр гараар анзаарсан байдаг. Бидний өгөгдлийн сангууд 2014-2019 оны 42 орнуудаас зурагдсан. Бид иргэний зөрчилдөөнд холбогдсон tweets-г тодорхойлохын тулд сургалтын суурь шугам системүүдийг тайлбарлаж байна. Бид энэ сэдэв дээр судалгаатай холбоотой этикийн асуудлын талаар ярилцлага хийдэг.', 'sr': 'Predstavljamo CUT, komplet podataka za proučavanje građanskih neprijatelja na Twitter-u. Naš komplet podataka uključuje 4.381 tweets povezan sa građanskim nemirima, koji su u rukama navedeni informacijama vezanim za studiju građanskih nemira i događaja. Naš komplet podataka je izveden iz 42 zemalja od 2014. do 2019. godine. Predstavljamo osnovne sisteme obučene na ovim podacima za identifikaciju tweeta povezanih sa građanskim nemirima. Uključujemo raspravu o etičkim pitanjima vezanim sa istraživanjem o ovoj temi.', 'sv': 'Vi presenterar CUT, ett dataset för att studera Civil Unrest på Twitter. Vårt dataset innehåller 4 381 tweets relaterade till civila oroligheter, handkommenterade med information relaterad till studien av civila oroligheter diskussion och händelser. Vårt dataset är hämtat från 42 länder från 2014 till 2019. Vi presenterar basbaserade system utbildade på dessa data för identifiering av tweets relaterade till civila oroligheter. Vi inkluderar en diskussion om etiska frågor relaterade till forskning inom detta ämne.', 'si': 'අපි CUT එක පෙනුම් කරනවා, ට්විටර් එකේ සිවිල් අන්රිස්ට් එකේ ඉගෙනගන්න දත්ත සැට් එකක්. අපේ තොරතුරු සම්බන්ධය 4,381 ට්විට් සම්බන්ධ වෙලා තියෙන්නේ නිවාසික ප්\u200dරශ්නයක් සම්බන්ධ වෙලා තියෙන්නේ, අත්  අපේ දත්ත සම්බන්ධය 2014 වල 2019 වලින් දේශ 42 වලින්. අපි මේ දත්තේ පරීක්ෂණ පද්ධතිය ප්\u200dරධානය කරනවා නිවාසික විරුද්ධ විදිහට සම්බන්ධ විදිහට තුවක් අපි මේ ප්\u200dරශ්නයේ පරීක්ෂණය සම්බන්ධ විශ්වාස සම්බන්ධ විශ්වාස කතා කරනවා.', 'ur': 'ہم نے CUT کو توئیٹر پر سیویل Unrest کی تحقیق کرنے کے لئے ایک ڈیٹ سٹ پیش کیا ہے۔ ہمارے ڈاٹ سٹ میں 4,381 ٹویٹ ملتی ہیں جن کے بارے میں سفیل ناراحت کی نسبت ہے، ہاتھ کے ذریعے مطلوبہ کے ساتھ مطلوبہ مطلوبہ اور حادثات کی تحقیق کے بارے میں ہے. ہمارا ڈیٹا سٹ 2014 سے 2019 سے 42 ملک سے نکالا گیا ہے۔ ہم اس ڈیٹا پر پڑھے ہوئے بنیس لین سیستموں کو سطح دیتے ہیں جن کے متعلق سطح ناراضی کے ٹیوٹوں کی شناسایی کے لئے۔ ہم اس موضوع پر اخلاقی مسائل کے بارے میں ایک بحث شامل کرتے ہیں۔', 'ta': 'நாங்கள் குறிப்பிடுகிறோம், தொடர்ந்து சிவில் நிரந்தரம் படிக்க ஒரு தகவல் அமைப்பு. நமது தரவுத்தளத்தில் 4,381 குறிப்புகள் உள்ளடக்கத்தில் தொடர்புடைய தொடர்புடன் இருக்கின்றன, நாட்டின் வீட்டு விவரங்கள் மற்று 2014-ல் இருந்து 2019 வரை 42 நாடுகளிலிருந்து எங்கள் தரவு அமைப்பு வரையப்பட்டது. நாங்கள் இந்த தரவுகள் மீது பயிற்சிக்கப்பட்டுள்ள அடிப்படைக்கோடு அமைப்புகளை காண்பிக்கிறோம் உள்ளூர் பி We include a discussion of ethical issues related to research on this topic.', 'uz': "Biz Twitterda Civil Oʻlchamini o'rganish uchun CUT'ni hozir qilamiz. Bizning maʼlumotlarimizning 4,381 xabarlar davomida shaxsiy harakat haqida bog'liq, shaxsiy murakkab qilish va hodisalarni o'qishga bog'langan maʼlumot bilan qo'llaniladi. Our dataset is drawn from 42 countries from 2014 to 2019.  Biz bu haqida xavfsiz murakkablarini aniqlash uchun asosiy tizimni o'rganamiz. Biz bu mavzuda o'rganish haqida ma'lumotlar haqida muloqot qilamiz.", 'vi': 'Chúng tôi giới thiệu CUT, một tập tin dữ liệu về công nghệ quần chúng trên Twitter. Trong tập tin của chúng tôi có bốn,381 những dòng tweet liên quan đến tình hình dân sự, được ghi chú bằng thông tin liên quan đến cuộc thảo luận và các sự kiện dân sự. Hệ thống dữ liệu của chúng tôi được lấy từ Tứ-2, từ bây giờ đến bây giờ. Chúng tôi có những hệ thống cơ bản được đào tạo về dữ liệu này để nhận dạng tweet liên quan đến tình trạng bất ổn dân sự. Chúng ta sẽ thảo luận về các vấn đề đạo đức liên quan đến nghiên cứu về vấn đề này.', 'bg': 'Представяме в Туитър набор от данни за изучаване на гражданската неспокойност. Нашият набор от данни включва 4381 туита, свързани с граждански размирици, ръчно анотирани с информация, свързана с проучването на дискусиите и събитията за граждански размирици. Нашият набор от данни е съставен от 42 държави от 2014 до 2019 г. Представяме базови системи, обучени по тези данни за идентифициране на туитове, свързани с граждански размирици. Включваме дискусия по етични въпроси, свързани с изследванията по тази тема.', 'da': 'Vi præsenterer CUT, et datasæt til at studere Civil Unrest på Twitter. Vores datasæt indeholder 4.381 tweets relateret til civile uroligheder, håndkommenteret med oplysninger relateret til undersøgelsen af civile uroligheder diskussion og begivenheder. Vores datasæt er tegnet fra 42 lande fra 2014 til 2019. Vi præsenterer basissystemer uddannet på disse data til identifikation af tweets relateret til civile uroligheder. Vi inkluderer en diskussion af etiske spørgsmål relateret til forskning om dette emne.', 'nl': 'We presenteren CUT, een dataset voor het bestuderen van Burgerlijke Unrust op Twitter. Onze dataset bevat 4.381 tweets gerelateerd aan burgerlijke onrust, hand geannoteerd met informatie gerelateerd aan de studie van burgerlijke onrust discussie en gebeurtenissen. Onze dataset is afkomstig uit 42 landen van 2014 tot 2019. We presenteren basissystemen die getraind zijn op deze gegevens voor het identificeren van tweets gerelateerd aan burgerlijke onrust. We omvatten een discussie over ethische kwesties gerelateerd aan onderzoek naar dit onderwerp.', 'de': 'Wir stellen CUT vor, einen Datensatz zur Untersuchung von Zivilen Unruhen auf Twitter. Unser Datensatz enthält 4.381 Tweets im Zusammenhang mit zivilen Unruhen, die mit Informationen im Zusammenhang mit der Untersuchung von zivilen Unruhen Diskussionen und Ereignissen kommentiert sind. Unser Datensatz stammt aus 42-Ländern von 2014 bis 2019. Wir präsentieren Basissysteme, die auf diesen Daten trainiert wurden, um Tweets im Zusammenhang mit zivilen Unruhen zu identifizieren. Dazu gehört auch eine Diskussion ethischer Fragen im Zusammenhang mit der Forschung zu diesem Thema.', 'id': 'We present CUT, a dataset for studying Civil Unrest on Twitter.  Seting data kami termasuk 4.381 tweet yang berhubungan dengan kekacauan sipil, ditandai tangan dengan informasi yang berhubungan dengan penelitian diskusi kekacauan sipil dan peristiwa. Our dataset is drawn from 42 countries from 2014 to 2019.  Kami mempersembahkan sistem dasar yang dilatih pada data ini untuk identifikasi tweet berkaitan dengan kekacauan sipil. Kami termasuk diskusi tentang masalah etika yang berhubungan dengan penelitian pada topik ini.', 'ko': '트위터에서 내란을 연구하는 CUT를 보여줬다.우리의 데이터 집합에는 내란과 관련된 4381개의 추문이 포함되어 있으며, 내란 토론과 사건 연구와 관련된 정보를 수동으로 표시하였다.우리의 데이터는 2014년부터 2019년까지 42개국에서 나왔다.우리는 이러한 데이터 교육을 바탕으로 하는 기선 시스템을 보여 내란과 관련된 추문을 식별하는 데 사용했다.우리는 이 주제 연구와 관련된 윤리 문제를 토론할 것이다.', 'sw': 'Tunawasilisha CUT, kituo cha taarifa kwa ajili ya kusoma Mazungumzo ya Kiraia kwenye mtandao wa Twita. Taarifa zetu zinajumuisha twiti 4,381 zinazohusiana na ghasia za kiraia, zinazohusiana na taarifa zinazohusiana na utafiti wa mijadala ya ukatili na matukio ya kiraia. Taarifa zetu zimetolewa kutoka nchi 42 kuanzia 2014 hadi 2019. Tunaweza kuweka mfumo wa msingi wa mfumo wa taarifa hizi kwa kutambua twiti zinazohusiana na ghasia za kiraia. Tunajumuisha mjadala wa masuala ya maadili yanayohusiana na utafiti huu.', 'af': "Ons stel CUT voor 'n datastel vir die studering van Civile Unrest op Twitter. Ons datastel het 4,381 tweet verwante met siviele onrusting, hand-annotated met inligting verwante met die studie van siviele onrustige diskusie en gebeurtenis. Ons datastel is van 42 lande van 2014 tot 2019 getrek. Ons stel basisline stelsels wat op hierdie data opgelei is vir die identifikasie van tweete wat verwanter is met siviele onrusting. Ons insluit 'n diskusie van etiese probleem wat verwanter is met ondersoek op hierdie onderwerp.", 'hr': 'Predstavljamo CUT, komplet podataka za proučavanje građanskih neprijatelja na Twitter-u. Naš sastav podataka uključuje 4.381 tweets povezan s građanskim nemirima, s informacijama povezanim s ispitivanjem građanskih nemira i događaja. Naš sastav podataka je izveden iz 42 zemalja od 2014. do 2019. godine. Predstavljamo početne sustave obučene na ovim podacima za identifikaciju tweeta povezanih s građanskim nemirima. Uključujemo raspravu o etičkim pitanjima povezanim s istraživanjem o ovoj temi.', 'sq': 'Ne prezantojmë CUT, një set të dhënash për studimin e Unrest Civile në Twitter. Të dhënat tona përfshijnë 4,381 Twitter lidhur me trazira civile, të shënuara me dorë me informacione lidhur me studimin e diskutimit dhe ngjarjeve të trazirave civile. Të dhënat tona janë tërhequr nga 42 vende nga 2014 në 2019. Ne paraqesim sisteme bazë të trajnuar në këto të dhëna për identifikimin e tweeteve lidhur me trazirat civile. Ne përfshijmë një diskutim mbi çështjet etike lidhur me kërkimin në këtë temë.', 'am': 'የዜጎች ዕረፍት በትዊተር ለማስተምር የCUT ዳታተር ሰርቨር እናቀርባታለን፡፡ ዳውታቶቻችን 4,381 የሲቪል ሁከት ጋር የሚታያየው በትዊተሮች ናቸው፤ የሲቪል ሁከት እና ሁኔታዎችን በማንበብ ተግኘት የተጠቃሚ መረጃ የተደረገ እጃቸውን ያስተካክሉ፡፡ Our dataset is drawn from 42 countries from 2014 to 2019.  የሲቪል ሁከት ጋር ለመግለጽ የሚታወቅበት በትዊተሮችን ለማስታወቅ የዚህን ዳታ መደብቀሚያ የbaseline systems እናደርጋለን፡፡ በዚህ ጉዳይ ላይ የተማረከውን የሕና ጉዳይ ውይይት እናገባለን፡፡', 'hy': 'Մենք ներկայացնում ենք CuT-ը, Տվիթերում քաղաքացիական անհանգստության ուսումնասիրության տվյալներ: Մեր տվյալների համակարգը ներառում է 4,381 թվիթեր, որոնք կապված են քաղաքացիական անհանգստությունների հետ, որոնք գրված են ձեռքով տեղեկատվության հետ, կապված քաղաքացիական անհանգստությունների քննարկումների և իրադարձությունների ուսումնասիրու Մեր տվյալների համակարգը կազմված է 42 երկրից 2014-2019 թվականից: Մենք ներկայացնում ենք հիմնական համակարգեր, որոնք պատրաստված են այս տվյալների վրա թվիթերի հայտնաբերման համար, որոնք կապված են քաղաքացիական անհանգստացմունքների հետ: Մենք ներառում ենք այս թեմայի ուսումնասիրության հետ կապված բարոյական հարցերի քննարկում:', 'fa': 'ما CUT را نشان می دهیم، یک مجموعه اطلاعات برای مطالعه آموزش شهروندی در توئیتر. مجموعه داده\u200cهای ما شامل ۴.381 تویت ارتباط به مبارزه\u200cهای شهروندی است که با اطلاعات مربوط به مطالعه\u200cی مبارزه\u200cهای شهروندی و حادثه\u200cهایی است. مجموعه داده\u200cهای ما از ۲۴ کشور تا ۲۰۱۹ کشور کشیده شده است. ما سیستم\u200cهای پایین\u200cخط آموزش بر این داده\u200cها برای شناسایی توئیت\u200cهایی که مربوط به مبارزه\u200cهای شهروندی هستند را نشان می\u200cدهیم. ما درباره مسائل اخلاقی که مربوط به تحقیقات در این موضوع هستند، صحبت می کنیم.', 'az': "İncil Unrest öyrənmək üçün CUT'i Twitter'da təyin edirik. Bizim verilən qurğumuz sivil müəlliflərlə bağlı 4.381 twet, sivil müəlliflər və vaxtlar təhsil edilməsi haqqındakı məlumatlarla bağlı olan məlumatlar barəsində. Məlumatlarımız 2014-2019 ilə 42 ülkedən çıxarılır. Biz bu məlumatlarda təhsil edilən təhsil sistemlərini sivil çətinliklərlə bağlı twetlərin tanımlaması üçün təhsil edirik. Biz bu məsələnin etik məsələlərini araşdırmaq haqqında mübahisə edirik.", 'bn': 'আমরা টুইটারে নাগরিক অশ্রেস্ট পড়ার জন্য সিউটিকে উপস্থাপন করছি। আমাদের ডাটাসেটের মধ্যে ৪,৩৮১ টুইট রয়েছে গৃহযুদ্ধের সাথে সম্পর্কিত, গৃহযুভূতি আলোচনা এবং ঘটনার গবেষণার সাথে যুক্ত তথ্যের স ২০১৪ সাল থেকে ২০১৯ সাল থেকে ৪২ দেশ থেকে আমাদের ডাটাসেট আঁকা হয়েছে। আমরা এই তথ্যের উপর বেসাইলাইন সিস্টেম প্রশিক্ষণ প্রদান করেছি গৃহযুদ্ধের সাথে সম্পর্কিত টুইট চিহ্নিত করার জন্য। এই বিষয়ে গবেষণার সাথে সম্পর্কিত নৈতিক বিষয়ের আলোচনা আমাদের মধ্যে রয়েছে।', 'bs': 'Predstavljamo CUT, set podataka za proučavanje građanskog neprijatelja na Twitter-u. Naš komplet podataka uključuje 4.381 tweets povezan sa građanskim nemirima, koje su u rukama označene s informacijama vezanim za ispitivanje građanskih nemira i događaja. Naš komplet podataka je izveden iz 42 zemalja od 2014. do 2019. godine. Predstavljamo osnovne sisteme obučene na ovim podacima za identifikaciju tweeta povezanih sa građanskim nemirima. Uključujemo raspravu o etičkim pitanjima povezanim s istraživanjem o ovoj temi.', 'tr': "Biz CUT'i Twitter'da Civil Unrest öwrenmek üçin bir veri setir görkeýäris. Meýdançalarymyz 4,381 tweet ýagdaýly çykyşyk bilen baglanýan, halkara çykyşyk we çykyşyklaryň öwrenmesi bilen baglanýan maglumatlary bilen meňzeýär. Berüvlerimiz 2014-nji ýyllardan 2019-nji ýyllardan 42 ýurtdan çykylýar Biz bu maglumaty üçin döwletli çykyşlyklar bilen tanyşan tweetler üçin bilinmeli sistemleri tassyklaýarys. Bu tema bilen ilgili etik meseleler barada diskusiýa goşulýarys.", 'cs': 'Představujeme CUT, datovou sadu pro studium občanského neklidu na Twitteru. Náš datový soubor obsahuje 4,381 tweety související s občanskými nepokoji, ručně anotované informacemi souvisejícími se studiem občanských nepokojů diskuse a událostí. Náš datový soubor je čerpán ze 42 zemí od 2014 do 2019. Představujeme základní systémy trénované na těchto údajích pro identifikaci tweetů souvisejících s občanskými nepokoji. Zahrnujeme diskusi o etických otázkách souvisejících s výzkumem na toto téma.', 'ca': "We present CUT, a dataset for studying Civil Unrest on Twitter.  El nostre conjunt de dades inclou 4.381 tweets relacionats amb agitacions civils, anotats a mà amb informació relacionada amb l'estudi de debats i esdeveniments de agitacions civils. El nostre conjunt de dades està dibuixat de 42 països del 2014 al 2019. Presentam sistemes de base entrenats en aquestes dades per identificar tweets relacionats amb agitacions civils. Inclouem una discussió sobre qüestions ètiques relacionades amb la recerca sobre aquest tema.", 'et': 'Tutvustame CUT-i, andmekogumit tsiviilrahutuse uurimiseks Twitteris. Meie andmekogum sisaldab 4381 tsiviilrahutustega seotud säutsu, mis on käsitsi märgitud tsiviilrahutuste arutelu ja sündmuste uurimisega seotud infoga. Meie andmekogum on koostatud 42 riigist aastatel 2014–2019. Esitame nende andmete põhjal koolitatud baassüsteeme tsiviilrahutustega seotud säutsude tuvastamiseks. Lisame arutelu eetilistest küsimustest, mis on seotud sellel teemal uurimistega.', 'fi': 'Esittelemme CUT:n, joka on aineisto kansalaislevottomuuden tutkimiseen Twitterissä. Aineistomme sisältää 4 381 kansalaislevottomuuteen liittyvää tweettiä, joihin on liitetty käsin huomautuksia kansalaislevottomuuksien keskusteluun ja tapahtumiin liittyvästä tutkimuksesta. Aineistomme on kerätty 42 maasta vuosina 2014–2019. Esittelemme perustiedoista koulutettuja järjestelmiä siviililevottomuuksiin liittyvien tweettien tunnistamiseksi. Mukana on keskustelu aiheesta tehtyyn tutkimukseen liittyvistä eettisistä kysymyksistä.', 'jv': 'Awak dhéwé nambah CUT, akeh dataset kanggo siji Unrestan Cibil nang Tutor Perintah dhéwé éntuk mulasai 4,481 tuwit sing menyang karo perkaragan pangan o rusak, lan munculo ngono informasi sing gak nggambar kejahatan negoro segala perkaraan kuwi events sing perkaraan dadi-sethaya sing dibutuhi tanggal apa-apa sing katha-apa ning 2013 sampek 2011. Awak dhéwé éntuk sistem sing beraksi kanggo awak dhéwé iki nggo nambah kang tuwitan sing gak nggawe gerakan cibadi. Awak dhéwé mulai perusahaan resmi etik sing ngejaraké sak resmi iki.', 'ha': "Munã halatar da CUT, an samun mutane da ake karatun Cikin Kiraita a Twitter. FayinMu na haɗi da wato 4,381 masu husũma da rushwa wa kiraita, da takarda hannuwanmu da information related to the research of harshen jayayi-jayayi da inci. An fizge dandamanmu daga 42 Countries daga 2014 zuwa 2019. Tuna halatar da system-mainlin na'urar da aka sanar da wannan data dõmin a gane wa Twitter masu husũma a cikin rushi na kiraita. Munã haɗa wani jayayya na'ura da masu yin husũma da research kan wannan madaidaici.", 'he': 'אנחנו מציגים את CUT, קבוצת נתונים ללמוד אונסטר אזרחי בטוויטר. קבוצת המידע שלנו כוללת 4,381 טוויטים קשורים למנועות אזרחיות, מוכתבים ידיים עם מידע קשור למחקר של דיון ומנועות של נועות אזרחיות. המידע שלנו נמשך מ-42 מדינות מ-2014 ל-2019. אנחנו מציגים מערכות בסיסיות מאומנות על הנתונים האלה לזהות טוויטים קשורים למטרות אזרחיות. אנחנו כוללים דיון על בעיות אתיות קשורות למחקר בנושא הזה.', 'sk': 'Na Twitterju vam predstavljamo CUT, nabor podatkov za študij civilne nesreče. Naš nabor podatkov vključuje 4.381 tweetov, povezanih z državljanskimi nemiri, ročno označenih z informacijami, povezanimi s preučevanjem razprav o državljanskih nemirih in dogodkih. Naš nabor podatkov je sestavljen iz 42 držav od 2014 do 2019. Predstavljamo osnovne sisteme, usposobljene na podlagi teh podatkov za identifikacijo tweetov, povezanih z državljanskimi nemiri. Vključujemo razpravo o etičnih vprašanjih, povezanih z raziskavami na tej temi.', 'bo': 'ང་ཚོས་ཌིས་ཌིར་བརྟེན་ནས་སྤྱི་ཚོགས་ཆིག་མ་རྫན་ལ་ཆ་འཕྲིན་ཡིག་ཆ་སྟོན་པ་ཡིན། ང་ཚོའི་སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆ་ཚང་ལ་ཉིད་ཁོངས་ཀྱི་བརྗོད་འགྱུར་བ་དང་འབྲེལ་བའི་བརྗོད་སྤྱད་པའི་གློག་འཕྲིན་གཞན་381དྲ་རྒྱའི་ནང ང་ཚོའི་ཆ་འཕྲིན་སྒྲིག་ཆ་སྒྲིག་ཆ་སྤྱི་རྒྱལ་ཁབ་༢༤༠་ལས་2019ལ་འགྲོ་བ་རེད། ང་ཚོས་རང་ཉིད་ལ་འཛམ་གླིང་གི་དཀའ་ངལ་འབྲེལ་བའི་དྲ་རྒྱ་ཚོགས་ཀྱི་ཆ་འཕྲིན་ཡིག འུ་ཚོས་གཏམ་གླེང་བརྗོད་དོན་འདི་དང་འབྲེལ་བའི་དཀའ་བ་ཕྱོགས་ཀྱི་གཏམ་བཤད་ཀྱི་ཡོད།'}
{'en': 'Representation learning of writing style', 'ar': 'تمثيل تعلم أسلوب الكتابة', 'pt': 'Aprendizagem de representação do estilo de escrita', 'fr': "Représentation, apprentissage du style d'écriture", 'es': 'Aprendizaje de representación del estilo de escritura', 'ja': '書き方の表象学習', 'hi': 'लेखन शैली का प्रतिनिधित्व सीखना', 'ru': 'Репрезентативное обучение стилю письма', 'zh': '作风格者,学也', 'ga': 'Léiriú ag foghlaim stíl scríbhneoireachta', 'ka': 'Name', 'el': 'Εκπροσώπηση εκμάθησης του στυλ γραφής', 'hu': 'Az írástílus reprezentációs tanulása', 'mk': 'Претставување на учењето на стилот на пишување', 'it': 'Apprendimento di rappresentazione dello stile di scrittura', 'lt': 'Įtraukimas į rašymo stilių mokymąsi', 'kk': 'Жазу стилінің көмегімен үйрену', 'ml': 'എഴുതുന്ന ശൈലിയുടെ പഠനം പഠിക്കുന്ന പ്രതിനിധി', 'mt': 'It-tagħlim tar-rappreżentanza tal-istil tal-kitba', 'ms': 'Pembelajaran mewakili gaya menulis', 'mn': 'Бичих хэлбэрийн суралцах суралцах нь', 'no': 'Name', 'pl': 'Reprezentacja uczenia się stylu pisania', 'ro': 'Învățarea reprezentării stilului de scriere', 'sr': 'Predstavljanje učenja pisanja stila', 'so': 'Waxbarashada qoraalka', 'sv': 'Representation learning of writing style', 'si': 'Name', 'ta': 'எழுத்து பாணியை கற்றுக் கொண்டிருக்கும் பிரதிநிகழ்வு', 'ur': 'لکھنے کے سبب کی تعلیم کی تصویر', 'vi': 'Công việc học văn bản', 'uz': 'Name', 'nl': 'Vertegenwoordiging leren van schrijfstijl', 'bg': 'Представителство учене на стила на писане', 'hr': 'Predstavno učenje pisaćeg stila', 'da': 'Repræsentation læring af skrivestil', 'de': 'Repräsentation Lernen des Schreibstils', 'id': 'Representation learning of writing style', 'ko': '작문 풍격의 표징 학습', 'fa': 'نمایش یادگیری از سبک نوشتن', 'sw': 'Mujibu wa kujifunza kwa mtindo wa kuandika', 'af': 'Name', 'tr': 'Ýaz taryhy öwrenişi', 'sq': 'Përfaqësues mësimi i stilit të shkrimit', 'am': 'የጽሑፍ ዓይነት ማምረጥ', 'az': 'Yazma tarz캼n캼n 칬yr톛nm톛si', 'bn': 'লেখার স্টাইল শিখার প্রতিনিধি', 'hy': 'Representation learning of writing style', 'bs': 'Predstavno učenje pisanja stila', 'cs': 'Reprezentace učení se stylu psaní', 'et': 'Kirjutamisstiili esindamine', 'fi': 'Kirjoitustyylin edustaminen', 'ca': "L'aprenentatge de representació de l'estil d'escriptura", 'ha': '@ action', 'sk': 'Predstavniško učenje sloga pisanja', 'jv': 'representation', 'bo': 'བྲིས་འབྲི་བའི་བཟོ་རྣམ་གྲངས་སུ་ཤེས་པ།', 'he': 'לימוד מייצג של סגנון כתיבה'}
{'en': 'In this paper, we introduce a new method of  representation learning  that aims to embed documents in a stylometric space. Previous studies in the field of  authorship analysis  focused on feature engineering techniques in order to represent document styles and to enhance  model  performance in specific tasks. Instead, we directly embed documents in a stylometric space by relying on a reference set of authors and the intra-author consistency property which is one of two components in our definition of  writing style . The main intuition of this paper is that we can define a general stylometric space from a set of reference authors such that, in this space, the coordinates of different documents will be close when the documents are by the same author, and spread away when they are by different authors, even for documents by authors who are not in the set of reference authors. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents. For the empirical validation of the method, we train a deep neural network model to predict authors of a large reference dataset consisting of news and blog articles. Albeit the learning process is supervised, it does not require a dedicated labeling of the data but  it  relies only on the metadata of the articles which are available in huge amounts. We evaluate the  model  on multiple  datasets , on both the authorship clustering and the authorship attribution tasks.', 'ar': 'في هذه الورقة ، نقدم طريقة جديدة للتعلم التمثيلي تهدف إلى تضمين المستندات في مساحة نمطية. ركزت الدراسات السابقة في مجال تحليل التأليف على تقنيات هندسة الميزات من أجل تمثيل أنماط المستندات وتعزيز أداء النموذج في مهام محددة. بدلاً من ذلك ، نقوم بتضمين المستندات مباشرةً في مساحة نمطية من خلال الاعتماد على مجموعة مرجعية من المؤلفين وخاصية الاتساق داخل المؤلف والتي تعد أحد عنصرين في تعريفنا لأسلوب الكتابة. يتمثل الحدس الرئيسي لهذه الورقة في أنه يمكننا تحديد مساحة نمطية عامة من مجموعة من المؤلفين المرجعيين بحيث تكون إحداثيات المستندات المختلفة قريبة في هذه المساحة عندما تكون المستندات من قبل المؤلف نفسه ، وتنتشر بعيدًا عندما هي من قبل مؤلفين مختلفين ، حتى لوثائق المؤلفين الذين ليسوا في مجموعة المؤلفين المرجعيين. تسمح الطريقة التي نقترحها بتجميع المستندات بناءً على أدلة أسلوبية تعكس تأليف المستندات. للتحقق من صحة الطريقة التجريبية ، نقوم بتدريب نموذج شبكة عصبية عميقة للتنبؤ بمؤلفي مجموعة بيانات مرجعية كبيرة تتكون من مقالات الأخبار والمدونات. على الرغم من الإشراف على عملية التعلم ، إلا أنها لا تتطلب تصنيفًا مخصصًا للبيانات ولكنها تعتمد فقط على البيانات الوصفية للمقالات المتوفرة بكميات ضخمة. نقوم بتقييم النموذج في مجموعات بيانات متعددة ، في كل من مجموعات التأليف ومهام إسناد التأليف.', 'fr': "Dans cet article, nous présentons une nouvelle méthode d'apprentissage des représentations qui vise à intégrer des documents dans un espace stylométrique. Les études précédentes dans le domaine de l'analyse de la paternité se sont concentrées sur les techniques d'ingénierie des caractéristiques afin de représenter les styles de documents et d'améliorer les performances du modèle dans des tâches spécifiques. Au lieu de cela, nous intégrons directement des documents dans un espace stylométrique en nous appuyant sur un ensemble de référence d'auteurs et sur la propriété de cohérence intra-auteur, qui est l'une des deux composantes de notre définition du style d'écriture. L'intuition principale de cet article est que nous pouvons définir un espace stylométrique général à partir d'un ensemble d'auteurs de référence de telle sorte que, dans cet espace, les coordonnées de différents documents seront proches lorsque les documents sont du même auteur, et dispersées lorsqu'ils le sont par des auteurs différents, même pour des documents de les auteurs qui ne font pas partie de l'ensemble des auteurs de référence. La méthode que nous proposons permet de regrouper des documents en fonction d'indices stylistiques reflétant la paternité des documents. Pour la validation empirique de la méthode, nous entraînons un modèle de réseau neuronal profond afin de prédire les auteurs d'un vaste ensemble de données de référence composé d'actualités et d'articles de blog. Bien que le processus d'apprentissage soit supervisé, il ne nécessite pas d'étiquetage dédié des données mais repose uniquement sur les métadonnées des articles qui sont disponibles en grande quantité. Nous évaluons le modèle sur plusieurs ensembles de données, à la fois pour les tâches de clustering de paternité et d'attribution de paternité.", 'es': 'En este artículo, presentamos un nuevo método de aprendizaje de representación que tiene como objetivo incrustar documentos en un espacio estilométrico. Los estudios anteriores en el campo del análisis de autoría se centraron en técnicas de ingeniería de características para representar estilos de documentos y mejorar el rendimiento del modelo en tareas específicas. En cambio, incorporamos documentos directamente en un espacio estilométrico confiando en un conjunto de autores de referencia y la propiedad de coherencia entre autores, que es uno de los dos componentes de nuestra definición de estilo de escritura. La intuición principal de este artículo es que podemos definir un espacio estilométrico general a partir de un conjunto de autores de referencia de manera que, en este espacio, las coordenadas de los diferentes documentos estén próximas cuando los documentos sean del mismo autor, y se difundirán cuando sean de diferentes autores, incluso para documentos de autores que no están en el conjunto de autores de referencia. El método que proponemos permite agrupar documentos en base a pistas estilísticas que reflejan la autoría de los documentos. Para la validación empírica del método, entrenamos un modelo de red neuronal profunda para predecir los autores de un gran conjunto de datos de referencia que consiste en noticias y artículos de blog. Aunque el proceso de aprendizaje está supervisado, no requiere un etiquetado específico de los datos, sino que se basa únicamente en los metadatos de los artículos, que están disponibles en grandes cantidades. Evaluamos el modelo en múltiples conjuntos de datos, tanto en la agrupación de autoría como en las tareas de atribución de autoría.', 'pt': 'Neste artigo, apresentamos um novo método de aprendizagem de representação que visa incorporar documentos em um espaço estilométrico. Estudos anteriores na área de análise de autoria focaram em técnicas de engenharia de recursos para representar estilos de documentos e melhorar o desempenho do modelo em tarefas específicas. Em vez disso, incorporamos documentos diretamente em um espaço estilométrico, contando com um conjunto de referência de autores e a propriedade de consistência intra-autor, que é um dos dois componentes em nossa definição de estilo de escrita. A principal intuição deste artigo é que podemos definir um espaço estilométrico geral a partir de um conjunto de autores de referência tal que, nesse espaço, as coordenadas de diferentes documentos sejam próximas quando os documentos forem do mesmo autor, e afastadas quando forem do mesmo autor. são de autores diferentes, mesmo para documentos de autores que não estão no conjunto de autores de referência. O método que propomos permite agrupar documentos com base em pistas estilísticas que refletem a autoria dos documentos. Para a validação empírica do método, treinamos um modelo de rede neural profunda para prever autores de um grande conjunto de dados de referência composto por notícias e artigos de blog. Embora o processo de aprendizagem seja supervisionado, não requer uma rotulagem dedicada dos dados, mas depende apenas dos metadados dos artigos que estão disponíveis em grandes quantidades. Avaliamos o modelo em vários conjuntos de dados, tanto no agrupamento de autoria quanto nas tarefas de atribuição de autoria.', 'ja': '本稿では，スタイルメトリクス空間に文書を埋め込むことを目的とした表現学習の新たな方法を紹介する． 著者分析の分野での以前の研究は、文書スタイルを表現し、特定のタスクにおけるモデルのパフォーマンスを向上させるための機能工学技術に焦点を当てていた。 代わりに、筆記体の定義における2つのコンポーネントの1つである著者の参照セットと著者内の一貫性プロパティに依存して、スタイルメトリクス空間にドキュメントを直接埋め込んでいます。 この論文の主な直観は、参照著者のセットから一般的なスタイルメトリクス空間を定義することができることである。この空間では、異なる文書の座標は、同じ著者によって文書が作成されたときに近くなり、参照著者のセットに含まれていない著者による文書であっても、異なる著者によって作成されたときに広がることになる。 私たちが提案する方法は、ドキュメントの著者性を反映したスタイルの手がかりに基づいてドキュメントをクラスタリングすることを可能にします。 この方法の実証的検証のために、ニュースとブログ記事からなる大きな参照データセットの作成者を予測するための深層ニューラルネットワークモデルをトレーニングします。 学習プロセスは監督されていますが、データの専用ラベルは必要ありませんが、大量に利用可能な記事のメタデータのみに依存しています。 作成者クラスタリングと作成者帰属タスクの両方で、複数のデータセットでモデルを評価します。', 'ru': 'В этой статье мы вводим новый метод репрезентативного обучения, который направлен на встраивание документов в стилометрическое пространство. Предыдущие исследования в области анализа авторства были сосредоточены на методах конструирования признаков с целью представления стилей документов и повышения эффективности модели в конкретных задачах. Вместо этого мы напрямую встраиваем документы в стилометрическое пространство, опираясь на референсный набор авторов и свойство согласованности внутри автора, которое является одним из двух компонентов в нашем определении стиля письма. Основная интуиция этой работы заключается в том, что мы можем определить общее стилометрическое пространство из набора эталонных авторов таким образом, что в этом пространстве координаты различных документов будут близки, когда документы принадлежат одному и тому же автору, и распространятся, когда они принадлежат разным авторам, даже для документов авторов, которые не входят в набор эталонных авторов. Предлагаемый нами метод позволяет группировать документы на основе стилистических подсказок, отражающих авторство документов. Для эмпирической валидации метода мы обучаем модель глубокой нейронной сети предсказывать авторов большого эталонного набора данных, состоящего из новостных и блоговых статей. Хотя процесс обучения контролируется, он не требует специальной маркировки данных, а опирается только на метаданные статей, которые доступны в огромных объемах. Мы оцениваем модель по нескольким наборам данных, как по кластеризации авторства, так и по задачам атрибуции авторства.', 'zh': '于本文中,言新示学,意将文档嵌风格空中。 昔在析域侧重于工程技术,示文档式而强特定任。 因其参考集内一致性(定义二组成部分之一)直销文档于空中。 本文之大直觉,可以参文献定义一般,当此空中,当文档同文,不同文档坐标近,异体异时,虽不在参考文献集者文档亦然。 其法许文档文体线聚类文档。 实验其法,练其一深神经网络以占新闻博客之大体,参以数集。 虽学有所监,然不须标记于数,然赖于大可用之元数也。 凡诸集上质,聚类与作者归之。', 'hi': 'इस पेपर में, हम प्रतिनिधित्व सीखने की एक नई विधि पेश करते हैं जिसका उद्देश्य एक स्टाइलोमेट्रिक स्पेस में दस्तावेजों को एम्बेड करना है। लेखकत्व विश्लेषण के क्षेत्र में पिछले अध्ययनों ने दस्तावेज़ शैलियों का प्रतिनिधित्व करने और विशिष्ट कार्यों में मॉडल प्रदर्शन को बढ़ाने के लिए फीचर इंजीनियरिंग तकनीकों पर ध्यान केंद्रित किया। इसके बजाय, हम लेखकों के एक संदर्भ सेट और इंट्रा-लेखक स्थिरता संपत्ति पर भरोसा करके सीधे एक स्टाइलोमेट्रिक स्पेस में दस्तावेजों को एम्बेड करते हैं जो लेखन शैली की हमारी परिभाषा में दो घटकों में से एक है। इस पेपर का मुख्य अंतर्ज्ञान यह है कि हम संदर्भ लेखकों के एक सेट से एक सामान्य स्टाइलोमेट्रिक स्पेस को परिभाषित कर सकते हैं जैसे कि, इस स्थान में, विभिन्न दस्तावेजों के निर्देशांक करीब होंगे जब दस्तावेज़ एक ही लेखक द्वारा होते हैं, और जब वे अलग-अलग लेखकों द्वारा होते हैं, तो वे अलग-अलग लेखकों द्वारा दस्तावेजों के लिए भी फैल जाते हैं, यहां तक कि लेखकों द्वारा दस्तावेजों के लिए भी जो संदर्भ लेखकों के सेट में नहीं हैं। जिस विधि का हम प्रस्ताव करते हैं, वह दस्तावेजों के लेखकत्व को दर्शाते हुए शैलीगत सुरागों के आधार पर दस्तावेजों के क्लस्टरिंग के लिए अनुमति देता है। विधि के अनुभवजन्य सत्यापन के लिए, हम समाचार और ब्लॉग लेखों से मिलकर एक बड़े संदर्भ डेटासेट के लेखकों की भविष्यवाणी करने के लिए एक गहरे तंत्रिका नेटवर्क मॉडल को प्रशिक्षित करते हैं। यद्यपि सीखने की प्रक्रिया की देखरेख की जाती है, लेकिन इसे डेटा के समर्पित लेबलिंग की आवश्यकता नहीं होती है, लेकिन यह केवल उन लेखों के मेटाडेटा पर निर्भर करता है जो भारी मात्रा में उपलब्ध हैं। हम कई डेटासेट पर मॉडल का मूल्यांकन करते हैं, दोनों लेखकत्व क्लस्टरिंग और लेखकत्व एट्रिब्यूशन कार्यों पर।', 'ga': "Sa pháipéar seo, tugaimid isteach modh nua foghlama ionadaíochta a bhfuil sé mar aidhm aige doiciméid a leabú i spás stílmhéadrach. Dhírigh staidéir roimhe seo i réimse na hanailíse údair ar shainteicnící innealtóireachta chun stíleanna doiciméad a léiriú agus chun feidhmíocht eiseamláireach i dtascanna sonracha a fheabhsú. Ina áit sin, déanaimid doiciméid a neadú go díreach i spás stílmhéadrach trí bheith ag brath ar thacar tagartha údair agus an t-airí comhsheasmhachta laistigh den údair atá ar cheann de dhá chomhpháirt inár sainmhíniú ar stíl scríbhneoireachta. Is é príomh-intleacht an pháipéir seo gur féidir linn spás stílmhéadrach ginearálta a shainiú ó thacar d'údair thagartha ionas go mbeidh, sa spás seo, comhordanáidí na ndoiciméad éagsúil gar nuair a bhíonn na doiciméid ag an údar céanna, agus go leathnófar iad nuair a bhíonn siad. atá ag údair éagsúla, fiú i gcás doiciméad ó údair nach bhfuil sa tsraith údair tagartha. Ceadaíonn an modh atá á mholadh againn cnuasach doiciméad bunaithe ar leideanna stíle a léiríonn údarú doiciméad. Chun an modh a bhailíochtú eimpíreach, déanaimid oiliúint ar shamhail líonra néarúil dhomhain chun údair a thuar maidir le tacar sonraí tagartha mór a chuimsíonn ailt nuachta agus bhlag. Cé go ndéantar maoirseacht ar an bpróiseas foghlama, ní éilíonn sé lipéadú tiomnaithe ar na sonraí ach braitheann sé ar mheiteashonraí na n-alt amháin atá ar fáil i méideanna ollmhóra. Déanaimid measúnú ar an tsamhail ar thacair sonraí iolracha, ar an gcnuasach údair agus ar thascanna sannadh an údair.", 'ka': 'ამ დოკუმენტში ჩვენ ახალი გამოსახულების სწავლების მეთოდი ჩვენ ჩვენ შევცვალოთ, რომელიც მინდა დოკუმენტები სტილომეტრიული სივრცეში ჩვენება. ავტორისტის ანალიზაციის წინა სწორედ სწორედ სტუქტირება განსაზღვრებულების ინგენერიზაციის ტექნოგიებისთვის, რომელიც დოკუმენტის სტილის გამოსახულება და მოდე მაშინ, ჩვენ სტილომეტრიკური სივრცეში დოკუმენტები დავყენებთ სტილომეტრიკური სივრცეში, რომელიც ჩვენი წერის სტილის განსაზღვრებით დავყენებთ ავტორების რეფერენცია და ავტორის ინტე ამ დოკუმენტის მნიშვნელოვანი ინტეუცია არის რომ ჩვენ შეგვიძლია განსაზღვრება სტილომეტრიული სივრცე განსაზღვრება რეფერენციის ავტორებისგან, როგორც ამ სივრცეში განსხვავებული დოკუმენტების კოორდინტები დახურდება, როცა დოკუმენტები ერთი ავტორე მეტი, რომელიც ჩვენ გვეძლევთ, მოდის, რომ დოკუმენტების კოსტრების კოსტრებისთვის სტილისტიკური კოსტრებისთვის გადაწყვეტილი დოკუმენტებ მეტის ემპერიკალური გადაწყვეტილებისთვის, ჩვენ განვიყავით ძალიან ნეიროლური ქსელის მოდელს, რომელიც ახალგაზომის და ბლოგური ინტექტიკების წინაწყვეტის ავტორების გან მაგრამ სწავლების პროცესი დანარჩენა, მაგრამ ის არ მოჭირდება მონაცემების განსაკუთრებული etiket, მაგრამ ის მხოლოდ მხოლოდ მონაცემების მეტადატატატატატატატატატატატ ჩვენ მრავალ მონაცემების მოდელის შესაბამისი კლასტერის შესაბამისი და მონაცემების შესაბამისი საქმედების შესაბამისი მოდელის შესაბამისი შესაბამისი დავალება.', 'el': 'Στην παρούσα εργασία, εισάγουμε μια νέα μέθοδο εκμάθησης αναπαράστασης που στοχεύει στην ενσωμάτωση εγγράφων σε έναν στυλομετρικό χώρο. Προηγούμενες μελέτες στον τομέα της ανάλυσης συγγραφής επικεντρώθηκαν σε τεχνικές μηχανικής χαρακτηριστικών με σκοπό την αναπαράσταση στυλ εγγράφων και την ενίσχυση της απόδοσης μοντέλων σε συγκεκριμένες εργασίες. Αντίθετα, ενσωματώνουμε άμεσα έγγραφα σε έναν στυλομετρικό χώρο βασιζόμενοι σε ένα σύνολο αναφορών συγγραφέων και την ιδιότητα συνοχής εντός συγγραφέων που είναι ένα από τα δύο συστατικά στον ορισμό μας του στυλ γραφής. Η κύρια διαίσθηση αυτής της εργασίας είναι ότι μπορούμε να ορίσουμε έναν γενικό στυλομετρικό χώρο από ένα σύνολο συγγραφέων αναφοράς έτσι ώστε, σε αυτό το χώρο, οι συντεταγμένες των διαφορετικών εγγράφων θα είναι κοντά όταν τα έγγραφα είναι από τον ίδιο συγγραφέα, και να εξαπλωθούν όταν είναι από διαφορετικούς συγγραφείς, ακόμη και για έγγραφα από συγγραφείς που δεν ανήκουν στο σύνολο συγγραφέων αναφοράς. Η μέθοδος που προτείνουμε επιτρέπει την ομαδοποίηση εγγράφων με βάση στυλιστικά στοιχεία που αντικατοπτρίζουν τη συγγραφή των εγγράφων. Για την εμπειρική επικύρωση της μεθόδου, εκπαιδεύουμε ένα μοντέλο βαθέων νευρωνικών δικτύων για την πρόβλεψη συγγραφέων ενός μεγάλου συνόλου δεδομένων αναφοράς που αποτελείται από ειδήσεις και άρθρα ιστολογίου. Παρόλο που η διαδικασία μάθησης εποπτεύεται, δεν απαιτεί ειδική επισήμανση των δεδομένων αλλά βασίζεται μόνο στα μεταδεδομένα των άρθρων που είναι διαθέσιμα σε τεράστιες ποσότητες. Αξιολογούμε το μοντέλο σε πολλαπλά σύνολα δεδομένων, τόσο για την ομαδοποίηση συγγραφέων όσο και για τις εργασίες απόδοσης συγγραφέων.', 'hu': 'Ebben a tanulmányban bemutatjuk a reprezentációs tanulás új módszerét, amelynek célja a dokumentumok stilometrikus térbe való beágyazása. Korábbi tanulmányok a szerzői elemzés területén a funkciómérnöki technikákra összpontosítottak a dokumentumstílusok ábrázolása és a modell teljesítményének javítása bizonyos feladatokban. Ehelyett közvetlenül beágyazzuk a dokumentumokat egy stylometrikus térbe, a szerzők referenciahalmazára és a szerzőn belüli konzisztencia tulajdonságra támaszkodva, amely az írási stílus definíciójának két összetevőjének egyike. A tanulmány fő megérzése az, hogy egy referenciaszerző-halmazból általános stilometriai téret definiálhatunk úgy, hogy ebben a térben a különböző dokumentumok koordinátái közel legyenek, amikor a dokumentumok ugyanazon szerzőtől vannak, és elterjednek, amikor azok különböző szerzőktől vannak, még olyan szerzők dokumentumai esetében is, akik nem tartoznak a referenciaszerzők halmazában. Az általunk javasolt módszer lehetővé teszi a dokumentumok szerzői jogát tükröző stilisztikai nyomok alapján történő csoportosítását. A módszer empirikus validálásához egy mély neurális hálózati modellt készítünk arra, hogy megjósoljuk a hírekből és blogcikkekből álló nagy referencia adathalmaz szerzőit. Bár a tanulási folyamatot felügyelik, nem igényel az adatok címkézését, hanem csak a cikkek metaadataira támaszkodik, amelyek hatalmas mennyiségben elérhetők. A modellt több adatkészleten értékeljük, mind a szerzői klaszterezés, mind a szerzői hozzárendelési feladatok tekintetében.', 'it': "In questo articolo introduciamo un nuovo metodo di apprendimento della rappresentazione che mira a incorporare documenti in uno spazio stilometrico. Studi precedenti nel campo dell'analisi dell'autore si sono concentrati sulle tecniche di feature engineering al fine di rappresentare gli stili di documento e migliorare le prestazioni del modello in compiti specifici. Invece, integriamo direttamente i documenti in uno spazio stilometrico facendo affidamento su un set di riferimento di autori e sulla proprietà di coerenza intra-autore che è uno dei due componenti della nostra definizione di stile di scrittura. L'intuizione principale di questo articolo è che possiamo definire uno spazio stilometrico generale partendo da un insieme di autori di riferimento in modo tale che, in questo spazio, le coordinate di documenti diversi siano vicine quando i documenti sono dello stesso autore, e si diffondono quando sono di autori diversi, anche per documenti di autori che non sono nell'insieme degli autori di riferimento. Il metodo che proponiamo permette di raggruppare documenti basati su indizi stilistici che riflettono la paternità dei documenti. Per la convalida empirica del metodo, addestriamo un modello di rete neurale profonda per prevedere gli autori di un ampio set di dati di riferimento composto da notizie e articoli di blog. Anche se il processo di apprendimento è supervisionato, non richiede un'etichettatura dedicata dei dati ma si basa solo sui metadati degli articoli che sono disponibili in enormi quantità. Valutiamo il modello su più set di dati, sia sul clustering dell'autore che sulle attività di attribuzione dell'autore.", 'lt': 'Šiame dokumente įvedame naują reprezentacinio mokymosi metodą, kuriuo siekiama įtraukti dokumentus į stilometrinę erdvę. Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks.  Vietoj to, mes tiesiogiai įtraukiame dokumentus į stilometrinę erdvę, remdamiesi nuoroda į autorių rinkinį ir autorių vidaus nuoseklumo savybe, kuri yra viena iš dviejų mūsų rašymo stilio apibrėžimo sudedamųjų dalių. Pagrindinė šio dokumento intuicija yra ta, kad galime apibrėžti bendrą stilometrinę erdvę iš nuorodos autorių rinkinio taip, kad šioje erdvėje skirtingų dokumentų koordinatės bus artimos, kai dokumentus sudaro tas pats autorius, ir išplitusios, kai juos sudaro skirtingi autoriai, net ir dokumentų, kuriuos sudaro autoriai, kurie nėra nuorodos autorių rinkinyje. Mūsų siūlomas metodas leidžia rinkti dokumentus, pagrįstus stilistinėmis nuorodomis, atspindinčiomis dokumentų autoriaus teisę. Taikant empirinį metodo patvirtinimą, mes rengiame gilaus nervinio tinklo model į, kad nuspėtume didelio referencinio duomenų rinkinio, sudaryto iš naujienų ir blog ų straipsnių, autorius. Nors mokymosi procesas yra prižiūrimas, jis nereikalauja specialios duomenų etiketės, tačiau jis grindžiamas tik dideliu kiekiu prieinamų gaminių metaduomenimis. Vertiname daugelio duomenų rinkinių model į ir autorių grupavimo, ir autorių priskyrimo užduočių atžvilgiu.', 'kk': 'Бұл қағазда, біз құжаттарды стилометриялық орында ендіру үшін жаңа таңдау әдісін таңдаймыз. Құжат стилін көрсету және ерекше тапсырмалардың үлгісін өзгерту үшін аутентификациялық анализ өрісінде алдыңғы зерттеулерді көздеген инженерлік техникаларына көздеген. Осының орнына, біз құжаттарды стилометриялық орында авторлардың сілтемесін және автордың интернеттегі қасиеттеріне көмектесіп, жазу стилінің анықтамасында екі компонентінің бірін ендіреміз. Бұл қағаздың негізгі интуициясы - біз сілтеме авторларынан жалпы стилометриялық орын анықтай аламыз, мысалы, осы орында, барлық құжаттардың координаттары бір авторы болғанда жабылады және оларды әртүрлі авторлар болғанда, тіпті сілтеме авторларының құжаттары үші Құжаттардың авторификациясын көрсету арқылы стилистикалық белгілеріне негізделген құжаттарды сұлбаттауға мүмкіндік береді. Бұл әдісті импирикалық тексеру үшін, біз жаңалық мен блог мақалаларының авторларын алдын алатын үлкен сілтеме деректер қорларының авторларын көрсету үшін терең невралдық желінің моделін о Бірақ оқыту процесі бақылады, ол деректердің жарлығын керек емес, бірақ ол тек үлкен мөлшерлерде бар мақалалардың метадеректеріне тәуелді. Біз бірнеше деректер қорларының үлгісін, авториторлық кластері мен авториторлық тапсырмаларының екеуінде бағалаймыз.', 'ms': 'Dalam kertas ini, kami memperkenalkan kaedah baru untuk mewakili belajar yang bertujuan untuk memasukkan dokumen dalam ruang stilometrik. kajian terdahulu dalam medan analisis penulisan fokus pada teknik teknik teknik teknik ciri untuk mewakili gaya dokumen dan untuk meningkatkan prestasi model dalam tugas tertentu. Sebaliknya, kami secara langsung memasukkan dokumen dalam ruang stilometrik dengan bergantung pada set rujukan penulis dan ciri konsistensi intra-penulis yang merupakan salah satu dari dua komponen dalam definisi gaya tulis kami. Intuisi utama kertas ini adalah bahawa kita boleh takrifkan ruang stilometrik umum dari set penulis rujukan sehingga, dalam ruang ini, koordinat dokumen berbeza akan dekat apabila dokumen adalah oleh penulis yang sama, dan tersebar apabila ia adalah oleh penulis yang berbeza, walaupun untuk dokumen oleh penulis yang tidak dalam set penulis rujukan. Kaedah yang kami cadangkan membolehkan kumpulan dokumen berdasarkan petunjuk stilistik yang mencerminkan penulisan dokumen. Untuk pengesahihan empirik kaedah ini, kita melatih model rangkaian saraf dalam untuk meramalkan penulis set data rujukan besar yang terdiri dari berita dan artikel blog. Walaupun proses belajar diawasi, ia tidak memerlukan label dedikasi data tetapi ia hanya bergantung pada metadata artikel yang tersedia dalam jumlah besar. Kami menilai model pada set data berbilang, pada kumpulan penulisan dan tugas atribut penulisan.', 'ml': 'ഈ പത്രത്തില്\u200d, പ്രതിനിധികള്\u200d പഠിക്കുന്ന ഒരു പുതിയ രീതിയില്\u200d ഞങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു. രേഖകള്\u200d സ്റ്റൈലോമെറ്റിക്  അധികാരികത്തിന്റെ പദ്ധതിയിലെ മുമ്പുള്ള പഠനങ്ങള്\u200d പ്രത്യേകിച്ച ജോലികളില്\u200d പ്രവര്\u200dത്തിപ്പിക്കാനും പ്രത്യേകിച്ചുള്ള മോഡല പകരം, നേരിട്ട് രേഖകള്\u200d സ്റ്റൈലോമെറ്റിക്ക് സ്ഥലത്ത് ഇട്ടിരിക്കുന്നു. എഴുതുന്ന രീതിയില്\u200d ഒരു റെഫനെന്\u200dസ് സെറ്റില്\u200d ആശ്രയിക്കുന്നത് കൊണ്ട ഈ പത്രത്തിന്റെ പ്രധാനപ്പെട്ട മനസ്സില്\u200d നമുക്കൊരു സാധാരണ സ്റ്റൈലോമെറ്റിക്ക് സ്പെയിസ് നിര്\u200dണയിക്കാന്\u200d കഴിയും, ഇതുപോലെയുള്ള രേഖകളില്\u200d വ്യത്യസ്ത രേഖകളുടെ കൂട്ടത്തില്\u200d അടച്ചുപോകുകയും, വ രേഖകളുടെ അധികാരം പ്രതിഫലിപ്പിക്കുന്ന രേഖകളുടെ അടിസ്ഥാനത്ത് സ്റ്റൈല്\u200dസ്റ്റിക് ക്ലൂട്ടുകള്\u200d അടിസ്ഥാനമായി സ ഈ രീതിയുടെ ശാസ്ത്രീകരണത്തിനായി നമ്മള്\u200d ഒരു ആഴത്തെ ന്യൂറല്\u200d നെറ്റ്\u200cവര്\u200dക്ക് മോഡല്\u200d പരിശീലിപ്പിക്കുന്നു. വാര്\u200dത്തകളും ബ്ലോഗ് ലേഖനങ പഠിക്കുന്ന പ്രക്രിയയെ നിരീക്ഷിക്കുന്നില്ലെങ്കിലും, വിവരങ്ങളുടെ പ്രത്യേക ലേബിള്\u200d ആവശ്യമില്ല, പക്ഷെ അത് വലിയ സമ്പത്തില്\u200d ലഭ്യമാകുന് We evaluate the model on multiple datasets, on both the authorship clustering and the authorship attribution tasks.', 'mt': 'F’dan id-dokument, a ħna nintroduċu metodu ġdid ta’ tagħlim tar-rappreżentanza li għandu l-għan li jinkorpora dokumenti fi spazju stilometriku. Studji preċedenti fil-qasam tal-analiżi tal-awturi ffukaw fuq tekniki tal-in ġinerija tal-karatteristiċi sabiex jirrappreżentaw stili ta’ dokumenti u biex itejbu l-prestazzjoni tal-mudell f’kompiti speċifiċi. Minflok, a ħna inkorporajna direttament dokumenti fi spazju stilometriku billi nistrieħu fuq sett ta’ referenza ta’ awturi u l-proprjetà ta’ konsistenza intraawtur li hija waħda minn żewġ komponenti fid-definizzjoni tagħna ta’ stil tal-kitba. L-intwizzjoni ewlenija ta’ dan id-dokument hija li nistgħu niddefinixxu spazju stilometriku ġenerali minn sett ta’ awturi ta’ referenza b’tali mod li, f’dan l-ispazju, il-koordinati ta’ dokumenti differenti jkunu qrib meta d-dokumenti jkunu mill-istess awtur, u jinfirxu meta jkunu minn awturi differenti, anki għal dokumenti minn awturi li mhumiex fis-sett ta’ awturi ta’ referenza. Il-metodu li qed nipproponu jippermetti li jiġu raggruppati dokumenti bbażati fuq indikazzjonijiet stilistiċi li jirriflettu l-awtur tad-dokumenti. Għall-validazzjoni empirika tal-metodu, a ħna nħarrġu mudell ta’ netwerk newrali profond biex nipprojbixxu awturi ta’ sett ta’ dejta ta’ referenza kbir li jikkonsisti minn aħbarijiet u artikoli tal-blog. Għalkemm il-proċess tat-tagħlim huwa sorveljat, ma jeħtieġx tikkettar iddedikat tad-dejta iżda jiddependi biss fuq il-metadejta tal-oġġetti li huma disponibbli f’ammonti kbar. Aħna jevalwaw il-mudell dwar settijiet ta’ dejta multipli, kemm dwar il-raggruppament tal-awturi kif ukoll dwar il-kompiti tal-attribuzzjoni tal-awturi.', 'mn': 'Энэ цаасан дээр бид стилометрийн орон зайд баримтуудыг оруулахын тулд суралцах шинэ арга зайг танилцуулдаг. Өмнөх шинжилгээний талбарын судалгаагаар баримт хэлбэрүүдийг илэрхийлдэг, тодорхой ажил дээр загварын үйлдвэрлэлийг нэмэгдүүлэх боломжтой инженерийн техникууд дээр төвлөрсөн. Үүний оронд бид баримтуудыг стилометрийн орон зайд шууд оруулж, бичил хэлбэрийн тодорхойлолтой хоёр компонентын нэг нь бичил хэлбэрээр авч ирсэн. Энэ цаасын гол ойлголтын тухай нь бид олон санал зохиолчдын ерөнхий стилометрийн орон зайг тодорхойлж чадна. Энэ орон зайд өөр баримт бичгүүдийн координатууд ижил зохиолч байхад, баримт бичгүүдийн хоорондоо ойрхон байх болно. Бидний санал дэвшүүлэх арга нь баримт баримт бүрдүүлэх боломжтой. Стилистикийн хэлбэр баримт баримтын зөвшөөрөл байдаг. Энэ арга загварын үндсэн шалгалтын тулд бид мэдээлэл болон блог баримтуудын бүтээлчдийн зохиолчдыг тодорхойлдохын тулд гүн гүнзгий мэдрэлийн сүлжээний загварыг суралцаж байна. Хэдийгээр суралцах үйл явцыг удирдаж байгаа ч, өгөгдлийн загвар өгөгдлийн загвар хэрэглэхгүй, гэхдээ энэ нь зөвхөн том хэмжээнд ашиглах өгөгдлийн мета өгөгдлийн санаанд хамаарна. Бид олон өгөгдлийн сангийн загварыг үнэлдэг. Мөн зөвлөгч хамт, зөвлөгч хамтын ажил хоёулаа.', 'mk': 'Во овој весник, воведуваме нов метод на претставување на учењето кој има за цел вклучување на документите во стилометрички простор. Претходните студии во областа на анализата на авторството се фокусираа на техниките за инженерство на карактеристики со цел да се претставуваат стилите на документите и да се зголеми моделот на перформансата во специфичните задачи. Наместо тоа, директно вградивме документи во стилометрички простор со доверба на референциски сет на автори и имотот на внатрешна конзистенција кој е еден од двата компоненти во нашата дефиниција на стилот на пишување. Главната интуиција на овој документ е дека можеме да дефинираме генерален стилометрички простор од група референциски автори како што, во овој простор, координатите на различни документи ќе бидат блиски кога документите ќе бидат од истиот автор, и ќе се шират кога се од различни автори, дури и за документи од автори кои не се во групата референциски автори. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents.  За емпиричната валидација на методот, тренираме длабока нервна мрежа модел за предвидување на авторите на голем референциски податок составен од вести и блогови статии. Иако процесот на учење е надгледуван, не бара посветено етикетирање на податоците, туку се потпира само на метададаните на статиите кои се достапни во огромни количини. Го проценуваме моделот на многуте податоци, и на групирањето на авторството, и на задачите за припишување на авторството.', 'pl': 'W artykule przedstawiamy nową metodę uczenia się reprezentacji, której celem jest osadzenie dokumentów w przestrzeni stylometrycznej. Poprzednie badania z zakresu analizy autorstwa koncentrowały się na technikach inżynierii funkcji w celu reprezentowania stylów dokumentów i zwiększenia wydajności modelu w konkretnych zadaniach. Zamiast tego bezpośrednio osadzamy dokumenty w przestrzeni stylometrycznej, opierając się na zestawie referencyjnym autorów i właściwości konsystencji wewnątrz-autora, która jest jednym z dwóch elementów naszej definicji stylu pisania. Główną intuicją niniejszego artykułu jest to, że możemy zdefiniować ogólną przestrzeń stylometryczną z zestawu autorów referencyjnych w taki sposób, że w tej przestrzeni współrzędne różnych dokumentów będą bliskie, gdy dokumenty pochodzą od tego samego autora, a gdy są one przez różnych autorów, nawet dla dokumentów autorów, którzy nie znajdują się w zestawie autorów referencyjnych. Proponowana przez nas metoda pozwala na klastrowanie dokumentów w oparciu o wskazówki stylistyczne odzwierciedlające autorstwo dokumentów. Do empirycznej walidacji tej metody szkolimy model głębokiej sieci neuronowej w celu przewidywania autorów dużego zbioru danych referencyjnych składającego się z wiadomości i artykułów blogowych. Chociaż proces nauki jest nadzorowany, nie wymaga specjalnego etykietowania danych, ale opiera się wyłącznie na metadanych artykułów, które są dostępne w ogromnych ilościach. Oceniamy model na wielu zbiorach danych, zarówno na zadaniach klastrowania autorstwa, jak i atrybucji autorstwa.', 'ro': 'În această lucrare, introducem o nouă metodă de învățare a reprezentării care vizează încorporarea documentelor într-un spațiu stilometric. Studiile anterioare în domeniul analizei autorului s-au concentrat pe tehnici de inginerie a caracteristicilor pentru a reprezenta stilurile documentelor și pentru a îmbunătăți performanța modelului în sarcini specifice. În schimb, încorporăm direct documentele într-un spațiu stilometric bazându-ne pe un set de referință de autori și pe proprietatea consecvenței intra-autor, care este una dintre cele două componente ale definiției stilului de scriere. Principala intuiție a acestei lucrări este că putem defini un spațiu stilometric general dintr-un set de autori de referință astfel încât, în acest spațiu, coordonatele diferitelor documente să fie aproape atunci când documentele sunt de același autor și să se răspândească atunci când sunt de autori diferiți, chiar și pentru documentele autorilor care nu se află în setul de autori de referință. Metoda propusă permite gruparea documentelor pe baza indiciilor stilistice care reflectă autoritatea documentelor. Pentru validarea empirică a metodei, instruim un model de rețea neurală profundă pentru a prezice autorii unui set de date de referință mare format din știri și articole de blog. Deși procesul de învățare este supravegheat, nu necesită o etichetare dedicată a datelor, ci se bazează doar pe metadatele articolelor care sunt disponibile în cantități uriașe. Evaluăm modelul pe mai multe seturi de date, atât în ceea ce privește clusterizarea autorității, cât și atribuirea autorității.', 'sr': 'U ovom papiru predstavljamo novu metodu učenja zastupanja koja cilja da uključimo dokumente u stilometrički prostor. Prethodne studije u području analize autoriteta fokusirale su se na tehnike in ženjerstva u cilju predstavljanja stila dokumenta i poboljšanja modela provedbe u određenim zadatkima. Umjesto toga, mi direktno uključujemo dokumente u stilometrijski prostor, oslanjajući se na referentni set autora i imovinu konsekvencije autora koji je jedan od dva komponenta u našem definiciji stila pisanja. Glavna intuicija ovog papira je da možemo definisati generalni stilometrijski prostor iz set a referentnih autora, tako da će u ovom prostoru koordinate različitih dokumenta biti zatvorene kada su dokumenti isti autor, i šireni se kada su oni različiti autori, čak i za dokumente autora koji nisu u setu referentnih autora. Metoda koju predlažemo omogućava skupljanje dokumenta baziranih na stilističkim tragovima koji odražavaju autoritet dokumenta. Za empiričku validaciju metode, treniramo duboki neuralni model mreže da predvidimo autore velike referenčne sete podataka koji se sastoje od novina i blogova. Iako se proces učenja nadgleda, ne zahteva posvećenu etiketu podataka, ali se oslanja samo na metadata članaka koji su dostupni u ogromnim količinama. Procjenjujemo model na višestrukim podacima, i na skupinu autoriteta i zadatku privlačenja autoriteta.', 'no': 'I denne papiret introduserer vi ein ny metode for å læra representasjon som mål å innebæra dokument i eit stylometrisk plass. Førre studiar i autorisasjonanalysefeltet fokuserte på funksjonsengineering-teknikk for å representera dokumentstilar og for å forbetra modellen i spesifikke oppgåver. I staden innebyr vi dokument direkte i ei stylometrisk plass ved å velja på ein referanssett av forfattarar og eigenskapen for konsistens i forfattarar som er ein av to komponentar i definisjonen vår av skriftstil. Hovudsintuisjonen av denne papiret er at vi kan definera ein generell stylometrisk plass frå eit sett referanse- forfattarar slik at i dette plassen koordinatene av ulike dokument vil bli lukka når dokumenta er av same forfattar, og sprei bort når dei er av ulike forfattarar, sjølv for dokument av forfattarar som ikkje er i sett av referanse- forfattarar. Metoden vi foreslår tillat å gruppere dokument basert på stylistiske kluser som reflekserer autorisasjonen av dokument. For empirisk validating av metoden treng vi ein dyp neuralnettverksmodell for å forhåndsvisa utviklarane av ein stor referanse- dataset som inneheld nyhetar og blogartiklar. Men læringsprosessen vert oversikt, krev ikkje ein spesifisert merkelapp av dataene, men han kan berre relieve på metadata av innlegga som er tilgjengelege i store mengdar. Vi evaluerer modellen på fleire datasett, både autorisasjonsklasseringa og autorisasjonsklasseringa.', 'si': 'මේ පත්තරේ අපි අළුත් ප්\u200dරතිනිධාන විධානයක් පෙන්වන්න පුළුවන් විධානයක් පෙන්වන්න පුළුවන් විදිහ ප්\u200dරධාන විශ්ලේෂණයේ පරීක්ෂණයේ ප්\u200dරධාන පරීක්ෂණය සඳහා විශේෂ විශ්ලේෂණය සඳහා විශේෂ ව්\u200dයාපෘතියේ ලිපි ඒ වෙනුවෙන්, අපි ස්ටිලෝමිට්\u200dරික් අවස්ථානයක් ඇතුලට ලේඛකය සහ ලේඛකය සම්බන්ධ විශේෂය සම්බන්ධ විශේෂයෙන් විශේෂය කරනවා  මේ පත්තරේ ප්\u200dරධාන ප්\u200dරධානය තමයි අපිට පුළුවන් සාමාන්\u200dය ස්ටිලෝමීට්\u200dරික් තැනක් විශ්වාස කරන්න පුළුවන් කියලා, මේ අවසානයේදී, වෙනස් විදිහට ලේඛකයෙන් ලේඛකයෙන් ව අපි ප්\u200dරශ්නය කරනවා විදියට විදියට විදියට විදියට විදියට ලිපින්තුවන් ස්ටිලිස්ටික ප්\u200dරශ්නයක් පෙන්වන විධානයේ සාමාන්\u200dය විශ්වාස කරන්න, අපි ගොඩක් න්\u200dයුරෝල් ජාලයේ මොඩේලයක් ප්\u200dරශ්නයක් කරනවා ලොකු ප්\u200dරශ්නය දත්ත සෙට් එක ඉගෙනගන්න ප්\u200dරක්\u200dරියාව පරික්ෂා කරලා තියෙන්නේ නැහැ, ඒක දත්තේ සැකසුම් ලේබිල් එකක් අවශ්\u200dය නැහැ නමුත් ඒක විශාල විශාල වි අපි ගොඩක් දත්ත සැට් වල මොඩේලය අගය කරනවා, අධිකාරිත්වය සහ අධිකාරිත්වය වැඩක් වලින්.', 'so': 'Qoraalkan waxaynu ku soo bandhignaa qaab cusub oo lagu baro barashada, kaas oo loogu talogalay in dukumentiyada lagu soo bandhiyo goob hoose ah. Waxbarashada hore oo ku qoran berrinka shahaadada rasmiga ah waxay ku focus yihiin qalabka engineering ee gaarka ah si ay u muuqato noocyada dukumentiga iyo in lagu kordhiyo muusikada sameynta shaqooyinka gaarka ah. Isku badalta, waxaan si toos ah ugu soo qornay dukumentiyada meelo qaab ah, iyadoo aan ku kalsoonaynay koox qoraal ah oo qoraal ah iyo hanti ku saabsan qoraal qoraal ah. Qoraalkan waxaa muhiimka ah in aan warqaddan ka aqoonsan karno meel caadiga ah oo ka mid ah qoraal maamul ah, kaas oo ah marka ay dukumentiyada kala duduwan dhamaadaan, isla markaasna ay kala firidhsadaan marka ay qoraal kala duduwan yihiin, xataa qoraalka qoraalka aan ku qorin qoraalka macluumaadka. Midabka aan soo jeedno ayaa loo ogolaan karaa soo bandhigista dukumentiyada oo ku saleysan alaabta isboortiga oo ku sawiraya rasmiga dukumentiyada. Si loo xaqiijiyo qaababka, waxaynu tababarinnaa model aad u dheer oo naxaas ah si aan u sii sheegno qoraalka qoraalka macluumaadka farsamada oo ka mid ah warqadaha iyo qoraalka. In kastoo la ilaaliyo jardiinada waxbarashada, looma baahna shahaadada gaarka ah, laakiin waxay ku xiran tahay macluumaadka qoraalka aad u badan ee laga heli karo. Tusaalada ayaannu ku qiimeynaynaa sawirada macluumaadka kala duduwan, kaas oo ku saabsan dhamaanka rasmiga iyo shaqada rasuulaadka.', 'sv': 'I denna uppsats introducerar vi en ny metod för representationslärande som syftar till att bädda in dokument i ett stylometriskt utrymme. Tidigare studier inom området författarskapsanalys fokuserade på funktionstekniska tekniker för att representera dokumentstilar och förbättra modellprestanda i specifika uppgifter. Istället bäddar vi in dokument direkt i ett stylometriskt utrymme genom att förlita oss på en referensuppsättning författare och egenskapen för konsistens inom författaren som är en av två komponenter i vår definition av skrivstil. Huvudintuitionen i denna uppsats är att vi kan definiera ett allmänt stylometriskt utrymme från en uppsättning referensförfattare så att koordinaterna för olika dokument i detta utrymme kommer att vara nära när dokumenten är av samma författare, och spridas bort när de är av olika författare, även för dokument av författare som inte är i uppsättningen referensförfattare. Den metod vi föreslår möjliggör klustring av dokument baserat på stilistiska ledtrådar som återspeglar författarskapet till dokument. För empirisk validering av metoden tränar vi en djup neural nätverksmodell för att förutsäga författare till ett stort referensdataset bestående av nyheter och blogginlägg. Även om inlärningsprocessen övervakas, kräver den ingen särskild märkning av data, utan den förlitar sig endast på metadata för artiklarna som är tillgängliga i stora mängder. Vi utvärderar modellen på flera datauppsättningar, både på författarskapsklustring och författarskapsattributionsuppgifter.', 'ta': 'இந்த காகிதத்தில், நாம் ஒரு புதிய பிரதிநிதிய முறைமையை அறிவிக்கிறோம். அது ஒரு பாணியில் உள்ள ஆவணங்களை உள்ளிட்டுள்ளது. ஆசிரியர் புலத்தில் முந்தைய ஆய்வு பதிலாக, நாங்கள் நேரடியாக எழுதுபவர்கள் மற்றும் ஆசிரியர் மீது நம்பிக்கை கொண்டு ஒரு குறிப்பு அமைப்பு பாணியில் ஆவணங்களை உள்ளிட்டோம். அது எழுதும் பா இந்த தாளின் முக்கிய புள்ளிவெளியை நாம் ஒரு குறிப்பிட்ட எழுத்தாளர்களில் இருந்து வரையற முடியும் என்றால், இந்த இடத்தில், வேறு ஆவணங்களின் ஒரே எழுத்தாளரால் இருக்கும் போது ஆவணங்கள் மூடும், மற்றும நாம் பரிந்துரைக்கும் முறைமை இந்த முறையின் விருப்பத்திற்கு, நாம் ஒரு ஆழமான புதிய வலைப்பின்னல் மாதிரி பயிற்சியை பயிற்சி செய்து செய்தி மற்றும் blog பொருள்கள்  கல்வி செயல்பாடு கண்காணிக்கப்பட்டிருந்தாலும் அது தகவலின் தனிப்பட்ட சிட்டியல் தேவையில்லை ஆனால் அது பெரிய அளவில் கிடைக்கும் கட்டுரைகளின்  நாம் பல தரவுத்தளங்களில் மாதிரியை மதிப்பிடுகிறோம், அதிகாரத்திற்கும் மற்றும் ஆசிரியர் கூட்டு பணிகளுக்கும் ம', 'ur': 'اس کاغذ میں ہم نے ایک نوی طریقہ کی تعلیم کی تلاوت کی ہے جس کا ارادہ یہ ہے کہ اسٹیلومتریک فضا میں دفتروں کو جمع کریں۔ مجلس تحقیقات کے مطابق پہلے تحقیقات کے مطابق مطابق دکھانے کے سبب اور مطابق کاموں میں موڈل کا عملکرد زیادہ ادھر کرنے کے لئے فوجی انجینژی تکنیک پر تمرکز کیا گیا ہے. اس عوض، ہم مستقیماً ایک استیلومتریک جگہ میں لکھنے والوں کی نسبت سٹ پر بھروسہ کرتے ہیں، اور داخل لکھنے والے ثابت قدم کے ثابت کے ذریعے جو ہمارے لکھنے کی تعریف میں دو قسموں میں سے ایک ہے. اس کاغذ کی اصلی نظر یہ ہے کہ ہم ایک مجموعہ اسٹیلومتریک جگہ کی تعریف کرسکتے ہیں اس طرح کہ اس جگہ میں مختلف لاسوندوں کی تعریف بند ہوگی جب یہ لاسوندے ایک ہی لکھنے کے ذریعہ ہیں اور جب وہ مختلف لکھنے والے ہیں، حتی لکھنے والوں کے ذریعہ۔ ہم نے اس طریقہ کی پیشنهاد کی ہے کہ اسٹیلیسٹیک کلوپ پر بنیاد رکھے ہوئے دکھانوں کی اجازت کے مطابق دکھانوں کے کلسٹر کے لئے اجازت دیتے ہیں. اس طریقہ کی امپریٹ کی تحقیق کے لئے، ہم ایک عمیق نیورل نیورل نیٹ ورک موڈل کی تطارین کرتے ہیں کہ ایک بڑے سراسر ڈیٹ سٹ کے لکھنے والوں کو پیش بینی کریں جو نویس اور بلاگ لکھنے والے ہیں. اگرچہ تعلیم پرسس پر نظارت کی جاتی ہے، اس کے لئے ڈاٹوں کی ایک خاص لابلینگ نہیں کی ضرورت ہے لیکن یہ صرف مقالہ کے متڈاٹے پر اعتماد کرتا ہے جو بڑے مقداروں میں موجود ہیں. ہم نے بہت سی ڈیٹ سٹ کے موڈل کا ارزش کیا ہے، مالک کلاسترینگ اور مالک تعریف کے کاموں پر۔', 'uz': "Bu qogʻozda, biz hujjatlarni uslumetrik joyda qo'shish uchun yangi tashkilotni anglatamiz. Hujjatning uslublarini koʻrsatish va model bajarishini foydalanish uchun foydalanuvchi muhandiya teknologiga foydalanadi. Istimos, biz yozish uslubining taʼminotimizga bir ikki komponentga ishonch qilamiz. Bu qogʻozning asosiy fikrini bir nechta bogʻ'liq mualliflarning umumiy uslumetrik joyini aniqlash mumkin. Bu yerda, hujjatlar bir mualliflar tomonidan boshqa hujjatlarning koordinatori yopiladi va boshqa mualliflar tomonidan ajratuvchi boʻlsa, xato hujjatlarning turli mualliflar tomonidan oʻchiriladi. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents.  Ustunni tasdiqlash uchun biz yangi neyrol tarmoq modelini tahrirlamiz va yangi va blog maqolalari kabi katta reference maʼlumoti tarkibidagi mualliflarni koʻrsatish uchun. @ info Biz bir nechta maʼlumot sahifalarida modelni qiymatimiz, huquqlarni boshqarish va mualliflarning tashkilotlarini.", 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu một phương pháp dạy đại diện mới nhằm mục đích nhúng tài liệu vào một không gian kiểu dâm đãng. Những nghiên cứu trước trong lĩnh vực phân tích tác quyền tập trung vào kỹ thuật đặc trưng để đại diện phong cách tài liệu và nâng cao khả năng của mô hình trong các nhiệm vụ cụ thể. Thay vào đó, chúng ta nhúng tài liệu trực tiếp vào một không gian kiểu như bằng cách dựa vào một bộ tham khảo của các tác giả và tài sản cân bằng trong tác giả, một trong hai thành phần trong định nghĩa của phong cách viết. Tính trực tiếp chính của tờ giấy này là chúng ta có thể xác định được một không gian kiểu chung từ một bộ tác giả tham khảo để các tọa độ của các văn bản khác nhau sẽ kết thúc khi các tài liệu được phát hành bởi cùng một tác giả, và bị phát tán ra khi chúng là của các tác giả khác nhau, thậm chí cho những văn bản không nằm trong bộ tác giả. Phương pháp chúng tôi đề nghị cho phép kết hợp các tài liệu dựa trên các manh mối thiết kế phản ánh tác giả của tài liệu. Để xác thực thực các phương pháp này, chúng tôi đào tạo một mô hình mạng thần kinh sâu để dự đoán các tác giả của một bộ dữ liệu tham khảo lớn gồm các bài báo và trang blog. Mặc dù chương trình học được giám sát, nó không cần phải mô phỏng các dữ liệu đặc biệt, nhưng nó chỉ dựa vào siêu dữ liệu của các bài báo có số lượng lớn. Chúng tôi đánh giá mô hình trên nhiều bộ dữ liệu, cả về nhóm tác giả và các công việc phân biệt tác quyền.', 'bg': 'В настоящата статия представяме нов метод за обучение на представителство, който има за цел вграждане на документи в стилометрично пространство. Предишни проучвания в областта на авторския анализ се фокусираха върху техники за инженеринг на функциите, за да представят стиловете на документа и да подобрят ефективността на модела при конкретни задачи. Вместо това директно вграждаме документи в стилометрично пространство, като разчитаме на референтен набор от автори и свойството вътреавторска консистенция, което е един от двата компонента в нашата дефиниция за стил на писане. Основната интуиция на тази статия е, че можем да дефинираме общо стилометрично пространство от набор от референтни автори, така че в това пространство координатите на различните документи да бъдат близки, когато документите са от един и същ автор, и да се разпространяват, когато са от различни автори, дори и за документи от автори, които не са в набора от референтни автори. Методът, който предлагаме, позволява групиране на документи въз основа на стилистични улики, отразяващи авторството на документи. За емпиричното валидиране на метода обучаваме модел на дълбока невронна мрежа, който да предвижда авторите на голям референтен набор от данни, състоящ се от новини и блог статии. Въпреки че учебният процес се контролира, той не изисква специално етикетиране на данните, а разчита само на метаданните на статиите, които са достъпни в огромни количества. Оценяваме модела на множество набори от данни, както при групирането на авторството, така и при възлагането на авторството.', 'nl': 'In dit artikel introduceren we een nieuwe methode van representatie learning die gericht is op het inbedden van documenten in een stylometrische ruimte. Eerdere studies op het gebied van auteurschapsanalyse richtten zich op feature engineering technieken om documentstijlen weer te geven en de modellprestaties in specifieke taken te verbeteren. In plaats daarvan insluiten we documenten rechtstreeks in een stylometrische ruimte door te vertrouwen op een referentieset auteurs en de consistentie-eigenschap intra-author, een van de twee componenten in onze definitie van schrijfstijl. De belangrijkste intuïtie van dit artikel is dat we een algemene stylometrische ruimte kunnen definiëren uit een reeks referentieauteurs, zodat, in deze ruimte, de coördinaten van verschillende documenten dicht bij elkaar zullen zijn wanneer de documenten van dezelfde auteur zijn, en verspreid wanneer ze door verschillende auteurs zijn, zelfs voor documenten van auteurs die niet in de reeks referentieauteurs zitten. De methode die we voorstellen maakt het mogelijk om documenten te clusteren op basis van stilistische aanwijzingen die het auteurschap van documenten weerspiegelen. Voor de empirische validatie van de methode trainen we een diep neuraal netwerkmodel om auteurs te voorspellen van een grote referentiedataset bestaande uit nieuws en blogartikelen. Hoewel het leerproces wordt begeleid, vereist het geen speciale etikettering van de gegevens, maar het vertrouwt alleen op de metadata van de artikelen die in grote hoeveelheden beschikbaar zijn. We evalueren het model op meerdere datasets, zowel op de auteurship clustering als de auteurship attributie taken.', 'da': 'I denne artikel introducerer vi en ny metode til repræsentationslæring, der sigter mod at integrere dokumenter i et stylometrisk rum. Tidligere studier inden for forfatterskabsanalyse fokuserede på feature engineering teknikker for at repræsentere dokumentstilarter og for at forbedre modellens ydeevne i specifikke opgaver. I stedet integrerer vi dokumenter direkte i et stylometrisk rum ved at stole på et referencesæt af forfattere og egenskaben konsistens inden for forfatter, som er en af to komponenter i vores definition af skrivestil. Hovedintuitionen i denne artikel er, at vi kan definere et generelt stylometrisk rum ud fra et sæt referenceforfattere, således at koordinaterne for forskellige dokumenter i dette rum vil være tæt på, når dokumenterne er af samme forfatter, og sprede sig væk, når de er af forskellige forfattere, selv for dokumenter af forfattere, der ikke er i sættet af referenceforfattere. Den metode, vi foreslår, giver mulighed for klyngning af dokumenter baseret på stilistiske spor, der afspejler forfatterskabet af dokumenter. Til empirisk validering af metoden træner vi en dyb neural netværksmodel til at forudsige forfattere af et stort referencedatasæt bestående af nyheder og blogartikler. Selvom læringsprocessen overvåges, kræver den ikke en dedikeret mærkning af data, men den er kun afhængig af metadata af artiklerne, som er tilgængelige i store mængder. Vi evaluerer modellen på flere datasæt, både på forfatterskabsklostring og forfatterskabstildelingsopgaver.', 'id': 'In this paper, we introduce a new method of representation learning that aims to embed documents in a stylometric space.  Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks.  Sebaliknya, kami langsung memasukkan dokumen dalam ruang stilometris dengan bergantung pada set referensi penulis dan properti konsistensi intra-penulis yang merupakan salah satu dari dua komponen dalam definisi gaya menulis kami. Intuisi utama dari kertas ini adalah bahwa kita dapat mendefinisikan ruang stilometri umum dari set penulis referensi sehingga, di ruang ini, koordinat dari dokumen yang berbeda akan dekat ketika dokumen adalah oleh penulis yang sama, dan disebar ketika mereka adalah oleh penulis yang berbeda, bahkan untuk dokumen oleh penulis yang tidak berada dalam set penulis referensi. Metode yang kami sarankan memungkinkan untuk mengumpulkan dokumen berdasarkan petunjuk stilistik yang merefleksikan otoritas dokumen. Untuk validasi empirik dari metode ini, kita melatih model jaringan saraf dalam untuk memprediksi penulis dataset referensi besar yang terdiri dari berita dan artikel blog. Meskipun proses belajar diawasi, tidak membutuhkan label dedikasi dari data tetapi hanya bergantung pada metadata dari artikel yang tersedia dalam jumlah besar. Kami mengevaluasi model pada beberapa set data, pada kedua kelompok pengarang dan tugas atribut pengarang.', 'de': 'In diesem Beitrag stellen wir eine neue Methode des Repräsentationslernens vor, die darauf abzielt, Dokumente in einen stylometrischen Raum einzubetten. Bisherige Studien im Bereich der Autorenschaftsanalyse konzentrierten sich auf Feature Engineering Techniken, um Dokumentstile darzustellen und die Modellleistung in bestimmten Aufgaben zu verbessern. Stattdessen betten wir Dokumente direkt in einen stylometrischen Raum ein, indem wir uns auf einen Referenzsatz von Autoren und die Intra-Author Konsistenz Eigenschaft verlassen, die eine von zwei Komponenten in unserer Definition von Schreibstil ist. Die wichtigste Intuition dieses Aufsatzes ist, dass wir einen allgemeinen stylometrischen Raum aus einer Reihe von Referenzautoren definieren können, so dass in diesem Raum die Koordinaten verschiedener Dokumente nahe liegen, wenn die Dokumente vom gleichen Autor stammen, und verteilt, wenn sie von verschiedenen Autoren stammen, sogar für Dokumente von Autoren, die nicht in der Gruppe von Referenzautoren sind. Die von uns vorgeschlagene Methode ermöglicht die Clustering von Dokumenten basierend auf stilistischen Hinweisen, die die Urheberschaft von Dokumenten widerspiegeln. Zur empirischen Validierung der Methode trainieren wir ein tiefes neuronales Netzwerkmodell, um Autoren eines großen Referenzdatensatzes aus Nachrichten und Blogartikeln vorherzusagen. Obwohl der Lernprozess überwacht wird, erfordert er keine spezielle Kennzeichnung der Daten, sondern stützt sich nur auf die Metadaten der Artikel, die in großen Mengen verfügbar sind. Wir evaluieren das Modell auf mehreren Datensätzen, sowohl für die Authorship Clustering als auch für die Authorship Attribution Tasks.', 'ko': '본고에서 우리는 문서를 줄기 공간에 삽입하기 위한 새로운 표현 학습 방법을 소개했다.저자 신분 분석 분야에서 이전의 연구는 주로 특징 공학 기술에 집중하여 문서 양식을 나타내고 특정 임무 중의 모델 성능을 강화했다.반대로 우리는 작가의 참고집과 작가 내부의 일치성 속성(작가 내부의 일치성 속성은 창작 스타일 정의의 두 가지 구성 부분 중 하나)에 의존하여 문서를 필적 공간에 직접 삽입한다.본고의 주요 직감은 한 그룹의 참고 작가 중에서 일반적인 기둥 모양 그림 공간을 정의할 수 있다는 것이다. 그러면 이 공간에서 파일이 같은 작가가 작성할 때 서로 다른 파일의 좌표는 가깝고 파일이 서로 다른 작가가 작성할 때 좌표는 흩어진다. 참고 작가가 집중되지 않은 작가가 작성한 파일이라도.우리가 제시한 방법은 문서 작성자의 신분을 반영하는 스타일 단서를 바탕으로 문서를 분류할 수 있도록 한다.이 방법에 대한 실증 검증을 위해 우리는 뉴스와 블로그 글로 구성된 대형 참고 데이터 집합의 저자를 예측하기 위해 심도 있는 신경 네트워크 모델을 훈련시켰다.비록 학습 과정이 감독을 받지만 데이터에 대해 전문적인 표시를 할 필요는 없지만, 대량의 사용 가능한 문장의 메타데이터에만 의존한다.우리는 여러 데이터 집합에서 이 모델을 평가했는데, 이는 작가 집합과 작가 귀인 임무를 포함한다.', 'hr': 'U ovom papiru predstavljamo novi način učenja zastupanja koji je cilj uključiti dokumente u stilometrijski prostor. Prethodna ispitivanja u području analize autoriteta fokusirala se na tehnike in ženjerstva kako bi predstavljala stilove dokumenta i poboljšala učinkovitost modela u određenim zadatkima. Umjesto toga, direktno uključujemo dokumente u stilometrički prostor oslanjući se na referentni skup autora i vlasništvo složenosti unutar autora koji je jedan od dva komponenta u našem definiciji pisaćeg stila. Glavna intuicija ovog papira je da možemo definirati općeg stilometrijskog prostora iz skupa referentnih autora, tako da će u ovom prostoru koordinate različitih dokumenta biti zatvorene kada su dokumenti isti autor i šireni se kada su oni različiti autori, čak i za dokumente autora koji nisu u skupu referentnih autora. Metoda koju predlažemo omogućava skupljanje dokumenta na temelju stilističkih tragova koji odražavaju autoritet dokumenta. Za empiričku potvrdu metode treniramo dubok model neuralne mreže kako bi predvidjeli autore velike referenčne grupe podataka koje se sastoje od novina i blog članaka. Iako se proces učenja nadzira, ne zahtijeva posvećenu etiketu podataka, ali se oslanja samo na metapodatke članaka koje su dostupne u ogromnim količinama. Procjenjujemo model na višestrukim podacima, na skupinu autoriteta i zadatku pridonošenja autoriteta.', 'fa': 'در این کاغذ، ما یک روش جدیدی از یادگیری نمایش دادن را معرفی می کنیم که هدف دارد مدارک را در فضای استیلومتریک وارد کنیم. مطالعات قبلی در زمینه تحلیل اجازه دادن بر تکنیک مهندسی ویژه تمرکز می\u200cشود تا نمایش مدل\u200cهای سند و فعالیت مدل\u200cهای مشخص را بیشتر کند. در عوض، ما مستقیماً مدارک را در یک فضای استیلومتریک وارد می\u200cکنیم با توجه به مجموعه\u200cای از نویسندگان و ویژه\u200cهای هماهنگی داخل نویسندگان که یکی از دو بخش\u200cها در تعریف طرح نوشتن ما است. مسئله اصلی این کاغذ این است که ما می توانیم یک فضا استیلومتری عمومی را از مجموعه نویسندگان مربوط تعریف کنیم که در این فضا، مسئولیت های سند مختلف نزدیک خواهند شد وقتی سند توسط یک نویسنده است و وقتی آنها توسط نویسندگان مختلف هستند، حتی برای سند توسط نویسندگان که در مجموعه نویسندگان مربوط نیستند،  روش پیشنهاد ما اجازه می دهد برای جمع کردن مدارک بر اساس نقشه\u200cهای استیلیستیک که توضیح اجازه\u200cدهنده مدارک\u200cها را نشان می\u200cدهند. برای تایید امپراتیک این روش، ما یک مدل شبکه عصبی عمیق را آموزش می کنیم تا نویسندگان یک مجموعه اطلاعات ارتباطی بزرگ را پیش بینی کنیم که از مکالمات اخبار و بلوگ وجود دارد. با وجود اینکه فرایند یادگیری تحت نظر قرار گرفته است، نیاز به نقاشی ویژه داده نمی\u200cشود، ولی فقط بر متداده\u200cهای مقاله\u200cهایی که در اندازه\u200cهای بزرگ موجود هستند، بستگی می\u200cکند. ما مدل را در مجموعه\u200cهای داده\u200cهای متعدد ارزیابی می\u200cکنیم، در مجموعه\u200cهای اختیار و وظیفه\u200cهای اختیار.', 'sw': 'Katika karatasi hii, tunaonyesha njia mpya ya uwakilishaji kujifunza lengo la kuweka nyaraka katika nafasi ya mtindo. Tafiti zilizopita katika uwanja wa uchambuzi wa mwandishi ulijikita kwenye mbinu za uhandisi ili kuwakilisha nyenzo za nyaraka na kuongeza utendaji wa mifano katika kazi maalum. Badala yake, tuliweka nyaraka moja kwa moja katika nafasi ya utamaduni kwa kutegemea matokeo ya waandishi na mali ya mwandishi wa ndani ambayo ni moja ya vifaa viwili katika maelezo yetu ya kuandika mtindo wa kuandika. Mtazamo mkuu wa gazeti hili ni kwamba tunaweza kufafanua nafasi ya ujumla kutoka kwa baadhi ya waandishi wa maoni kama vile, katika nafasi hii, mikakati ya nyaraka tofauti zitakuwa karibu pale nyaraka hizo zitapopigwa na mwandishi mmoja, na kusambaa pale ambapo ni waandishi tofauti, hata kwa nyaraka ambazo hazina katika seti ya waandishi wa maoni. Namna tunavyopendekeza inaruhusu kuunganisha nyaraka kwa kutumia viungo vya msingi vinavyotafakari rasmi ya nyaraka. Kwa kuthibitishwa kwa njia hii, tunafundisha mtindo wa mtandao wa ndani wa neura kutabiri waandishi wa seti kubwa ya taarifa za maoni ikiwa ni pamoja na makala za habari na blogu. Pamoja na kuwa mchakato wa kujifunza unafuatiliwa, haihitaji alama maalum ya taarifa lakini inategemea tu taarifa za makala zinazopatikana kwa kiasi kikubwa. Tutathmini modeli kwenye seti za takwimu mbalimbali, kwa vyote viungo vya mamlaka na kazi za uwakilishi.', 'af': "In hierdie papier, introduseer ons 'n nuwe metode van verteenwoordigheid leer wat doel om dokumente in 'n stylometriese spasie te binne. Vorige studie in die veld van outoriteitanalisie gefokus is op funksie in ženieringsteknike om dokumentstyle te verteenwoordig en om model prestasie in spesifieke taak te verbeter. In plaas, ons direk inbêer dokumente in 'n stylometriese spasie deur vertrou op 'n verwysing stel van outeurs en die intra- outeur konsistensies eienskap wat een van twee komponente is in ons definisie van skryfstyl. Die hoofde intuisie van hierdie papier is dat ons kan definieer 'n algemene stylometriese spasie van' n stel verwysing outeurs sodat, in hierdie spasie, die koordinate van verskillende dokumente sal toe wees wanneer die dokumente deur dieselfde outeur is, en uitsprei wanneer hulle deur verskillende outeurs is, selfs vir dokumente deur outeurs wat nie in die stel van verwysing outeurs is nie. Die metode wat ons voorstel, laat toe vir die klastering van dokumente gebaseer op stylistiese kloue wat die outeurskap van dokumente reflekteer. Vir die empiriese geldigheid van die metode, tref ons 'n diep neuralnetwerk model om outeurs van 'n groot verwysing datastel te voorskou wat bestaan van nuus en blogartikels. Alhoewel die leerproses is ondersoek, dit benodig nie 'n aangevestige etiketting van die data nie, maar dit verlig slegs op die metadata van die aktikels wat beskikbaar is in groot hoeveelheid. Ons evalueer die model op veelvuldige datastelle, op beide die autorisasie-klastering en die autorisasie-attribution-taak.", 'tr': 'Bu kağıtda, bir stilometrik uzayda belgeleri içeren amaçlayan täze bir temsil öwrenmesi täze bir yöntemi tanıtıyoruz. Oturmanyň analyzasynda öňki öňki öňki okuwçylar desktap stillerini temizlemek üçin özellikler in ženjeriýa teknikleri we bellenen işlerde nusgatlary geliştirmek üçin üns berildi. Bu ýerde, ýazma stilinde iki komponentiň birini ýazma stilinde gürrüňleýän ýazgylaryň düzümlerini we içine-awtoryň diňe gürrüňleýän senedleri stilometrik seleňde süýtgedik. Bu kagyzyň esasy düşünmesi biziň bir sany senaryň setirinden umumy stylometrik alany belirleýän ýaly, bu ýerde, senediň birnäçe awtomatik tarapyndan ýakyn bolanda, we olaryň be ýleki awtomatik tarapyndan tarapyndan, hatda referens awtomatik tarapyndan hem a ýratyn awtomatik tarapyndan boşadylýar. Biziň teklip edip görkezilýän yöntem stylistik kluplar üçin sened bejermesine mümkin edýär. Metiniň empirik tassyklanmasy üçin, biz täzelikler we bloglardan oluşan uly referens sanatynyň awtorlaryny öňden geçirmek üçin derin neural şebeke nusgasyny öwrenýärdik. Öwrenme prosesi gözetlenilýär. Bu maglumatyň beýleki etiketlemesi gerek däl, ýöne diňe uly kadalarda bar makalaryň metadata üstine ynanýar. Biz birnäçe veri setirlerinde nusgany çykarýarys, awtorizma klusterinde we awtorizma taýýarlamagynda.', 'sq': 'Në këtë letër, ne futim një metodë të re përfaqësimi të mësimit që synon të përfshijë dokumentet në një hapësirë stilometrike. Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks.  Në vend të kësaj, ne përfshijmë drejtpërdrejt dokumentet në një hapësirë stilometrike duke u mbështetur në një sërë referimi autorësh dhe pronën e konsistencës brenda autorit që është një nga dy komponentet në përcaktimin tonë të stilit të shkrimit. Intuicioni kryesor i kësaj letre është se ne mund të përcaktojmë një hapësirë stilometrike të përgjithshme nga një sërë autorësh referimi të tillë që, në këtë hapësirë, koordinatat e dokumenteve të ndryshme do të jenë të mbyllura kur dokumentet janë nga i njëjti autor, dhe të shpërndahen kur janë nga autorë të ndryshëm, edhe për dokumente nga autorë që nuk janë në sërë autorësh referimi. Metoda që propozojmë lejon grupimin e dokumenteve bazuar në udhëzime stilistike që pasqyrojnë autoritetin e dokumenteve. Për vlerësimin empirik të metodës, ne trajnojmë një model rrjeti nervor të thellë për të parashikuar autorët e një sëre të dhënash të mëdha referimi që përbëhet nga lajmet dhe artikujt e blogut. Megjithëse procesi i mësimit mbikqyret, nuk kërkon një etiketë të përkushtuar të të dhënave por mbështetet vetëm në metatë e artikujve që janë në dispozicion në sasi të mëdha. Ne vlerësojmë modelin në grupe të shumta të dhënash, si në grupimin e autorisë, ashtu edhe në detyrat e atribucionit të autorisë.', 'am': 'በዚህ ካላት አዲስ መልዕክት እናሳውቃለን፡፡ የቀድሞው ባለሥልጣናት አካባቢ መፍጠር የኢንጂንጂንተር ቴክኖክቶችን ለማሳየት እና በተለያዩ ስራ ውስጥ ሞዴል ድጋፍ ማሳየትን ለመጨመር ተማርኮዋል፡፡ በፋንታ፣ በሥልጣዊ ስፋት ሰነጃዎችን እና የጸሐፊ ሥርዓት እና የደራሲ ግንኙነታችንን በጽሑፍ ሥርዓት ግንኙነት ከሁለቱ ክፍሎች አንዱ ነው፡፡ የዚህ ደብዳቤ የዋነኛው ጥያቄ እንዲህ ነው፡፡ የሰነዱ ደጋፊነት የሥልጣን ሥልጣን በሚያሳየው የሥልጣዊ ቋንቋዎች ላይ የተመሳሳይ ሰነጃዎችን ለማቅረብ እንዲፈቅድ ይችላል፡፡ ለሥርዓት ማረጋገጫ፣ ዜና ጦማር ጽሑፎችን የሚቆጠሩ የታላቅ የየድረ ገጽ ዳታዎችን ለመቀበል እናስተምራለን፡፡ ትምህርት ፕሮጀክት ቢጠበቅ የዳራዎችን ማሳየት አይፈልግም፤ ነገር ግን በታላቅ ቁጥር በሚገኙት ጽሑፎች ማድረግ ብቻ ነው። የሥልጣን መግለጫ እና የሥልጣን አዋጅ ስራዎችን እና መግለጫ ላይ እናስተምርለታለን፡፡', 'hy': "Այս թղթի մեջ մենք ներկայացնում ենք մի նոր ներկայացման ուսումնասիրության մեթոդ, որը նպատակն է փաստաթղթեր ներառել ոճամետրական տարածքում: Աշխատագրության վերլուծության ոլորտում նախորդ ուսումնասիրությունները կենտրոնացել են հատկանիշների ճարտարագիտական տեխնիկաների վրա, որպեսզի ներկայացնեն փաստաթղթերի ոճերը և բարելավեն մոդելների արտադրողություն Փոխարենը, մենք ուղղակի ներառում ենք փաստաթղթերը ոճամետրական տարածության մեջ' հիմնվելով հեղինակների և ներկա-հեղինակային համապատասխանության առանձնահատկության վրա, որը գրելու ոճի սահմանման երկու բաղադրիչներից մեկն է: Այս թղթի հիմնական ինտուիցիան այն է, որ մենք կարող ենք սահմանել ընդհանուր ոճոմետրական տարածություն վերաբերյալ հեղինակների մի շարքից, այնպես, որ, այս տարածքում, տարբեր փաստաթղթերի կոորդինատները կլինեն մոտ, երբ փաստաթղթերը նույն հեղինակի կողմից են, և տարածվում են, երբ դրանք տարբեր հեղինակների կողմից են, նույնիսկ հեղ Մենք առաջարկում ենք մի մեթոդ, որը թույլ է տալիս հավաքել փաստաթղթերը, որոնք հիմնված են փաստաթղթերի հեղինակության արտացոլում: Մեթոդի էմպրիկական հավասարման համար մենք պատրաստում ենք խորը նյարդային ցանցի մոդել, որպեսզի կանխագուշակենք մեծ հաղորդակցման տվյալների համակարգի հեղինակներին, որոնք կազմված են նորություններից և բլոգից: Չնայած ուսուցման գործընթացը վերահսկվում է, այն չի պահանջում տվյալների նվիրված պիտակ տալ, բայց այն հիմնված է միայն այն հոդվածների մետատվյալների վրա, որոնք հսկայական քանակությամբ հասանելի են: Մենք գնահատում ենք բազմաթիվ տվյալների համակարգերի մոդելը, հեղինակության խմբավորումների և հեղինակության հատկագրման խնդիրների վրա:", 'bn': 'এই কাগজটিতে আমরা প্রতিনিধিত্বের একটি নতুন পদ্ধতি পরিচয় করিয়ে দিচ্ছি যা একটি স্টাইলোমেট্রিক জায়গায় ডকুমেন্ট প্রবেশ করার লক লেখকের বিশ্লেষণের ক্ষেত্রে পূর্ববর্তী গবেষণা বিশ্লেষণের প্রযুক্তির প্রযুক্তির উপর মনোযোগ প্রদান করেছে নথিপত্রের স্টাইল এবং  তার পরিবর্তে, আমরা সরাসরি একটি স্টাইলোমেট্রিক স্থানে নথিপত্র প্রবেশ করেছি লেখক এবং লেখকের সেটের উপর নির্ভর করেছি যা লেখার স্টাইলে আমাদের লেখার সংখ্যার এই পত্রিকার প্রধান অনুভূতি হচ্ছে আমরা একটি সাধারণ স্টাইলোমেট্রিক স্থান নির্ধারণ করতে পারি কিছু লেখকের কাছ থেকে যেমন এই স্থানে নথিগুলো একই লেখকের দ্বারা বন্ধ হবে এবং যখন তারা ভিন্ন লেখকের দ্বারা ছ নথিপত্রের লেখকের প্রতিক্রিয়া প্রতিক্রিয়ায় ভিত্তিক নথিপত্রের স্টাইলিক ক্লিয়ার ভিত্তিক ক্ষেত্রে নথিপত্রে এই পদ্ধতির সম্মানজনক বৈধের জন্য আমরা একটি গভীর নিউরেল নেটওয়ার্ক মডেল প্রশিক্ষণ দিচ্ছি যাতে সংবাদ এবং ব্লগ প্রবন্ধের অন্তর্ভুক্ত একটি বিশাল রেফ যদিও শিক্ষা প্রক্রিয়া পর্যবেক্ষণ করা হয়, তবে তথ্যের কোন বিশেষ লেবেলের প্রয়োজন নেই, কিন্তু এটি শুধুমাত্র বিশাল পরিমাণ প্রবন্ধের মেটাডাটা আমরা বেশ কয়েকটি ডাটাসেটের মডেলের মূল্য মূল্য দিচ্ছি, কার্যক্ষমতার ক্ষেত্রে ক্লাসিং এবং লেখকের কাজের কাজের', 'az': 'Bu kağızda, stylometrik bir yer içində dökümlər in şa etmək niyyətində yeni bir göstəriş öyrənməsi yolunu tanıdırıq. Müəllif analizi sahəsindəki əvvəlki təhsil məlumatlarını göstərmək və məxluqat işlərində modellərin performansını artırmaq üçün fərqli in ženjeri tehniklərinə odaqlandı. Əvəzində, biz səhifələri istilometrik bir yer içində yazıcı və yazıcı içərisində olan iki komponentdən birini yazmaq tərzində təvəkkül edirik. Bu kağıdın ən böyük düşünüşü, biz bir sürü referans yazıcılarından genel stylometrik alanı belə tanıma bilərik ki, bu alanda fərqli dökümlərin koordinatları eyni yazıcının tərəfindən yaxınlaşdığı zaman, belələrin müxtəlif yazıcıların tərəfindən yayıldığı zaman, hətta referans yazıcıların tərəfində olmayan yazıcıların tərəfindən yayılacaq. Bizim təbliğ etdiyimiz metodlar stylistik iplərə dayanan belələrin qoşulmasına imkan verir. Bu metodun empirik təsdiqlənməsi üçün, xəbərlər və bloglar içərisində olan böyük referans veri qutularının yazıcılarını təsdiqlənmək üçün derin nöral a ğ modelini təhsil edirik. Öyrənmə sürəti gözləyir, amma məlumatların məlumatlarının məlumatlarının məlumatlarının məlumatlarına bağlı olması lazım deyil, lakin böyük qiymətlərdə faydalanır. Biz çoxlu veri qurğularının modelini, həmçinin yazıcılıq qurğularının və həmçinin yazıcılıq qiymətlərinin nəticəsində değerlendiririk.', 'cs': 'V tomto článku představujeme novou metodu učení reprezentace, která si klade za cíl vložit dokumenty do stylometrického prostoru. Předchozí studie v oblasti autorské analýzy se zaměřily na techniky funkčního inženýrství s cílem reprezentovat styly dokumentů a zlepšit výkon modelu v konkrétních úkolech. Místo toho přímo vložíme dokumenty do stylometrického prostoru spoléháním na referenční sadu autorů a vlastnost konzistence uvnitř autora, která je jednou ze dvou složek naší definice stylu psaní. Hlavní intuicí tohoto článku je, že můžeme definovat obecný stylometrický prostor ze sady referenčních autorů tak, že v tomto prostoru budou souřadnice různých dokumentů blízké, pokud jsou dokumenty stejného autora, a rozšířené, pokud jsou od různých autorů, dokonce i u dokumentů autorů, kteří nejsou v sadě referenčních autorů. Metoda, kterou navrhujeme, umožňuje shlukování dokumentů na základě stylistických vodítek odrážejících autorství dokumentů. Pro empirickou validaci metody trénujeme model hluboké neuronové sítě pro predikci autorů velkého referenčního datového souboru sestávajícího z novinek a blogových článků. I když je proces učení pod dohledem, nevyžaduje speciální označování dat, ale spoléhá pouze na metadata článků, které jsou k dispozici ve velkém množství. Model hodnotíme na více datových sadách, jak na clusterování autorstva, tak na úlohách atribuce autorstva.', 'bs': 'U ovom papiru predstavljamo novu metodu učenja zastupanja koja se cilja uključiti dokumente u stilometrički prostor. Prethodna ispitivanja u oblasti analize autoriteta fokusirala se na tehnike in ženjerstva u cilju predstavljanja stila dokumenta i poboljšanja provedbe modela u određenim zadatkima. Umjesto toga, direktno uključujemo dokumente u stilometrički prostor, oslanjući se na referentni set autora i vlasništvo složenosti unutar autora koji je jedan od dva komponenta u našem definiciji stila pisanja. Glavna intuicija ovog papira je da možemo definisati općeg stilometrijskog prostora iz skupa referentnih autora, tako da će u ovom prostoru koordinate različitih dokumenta biti zatvorene kada su dokumenti isti autor, i šireni se kada su oni različiti autori, čak i za dokumente autora koji nisu u skupu referentnih autora. Metoda koju predlažemo omogućava skupljanje dokumenta baziranih na stilističkim tragovima koji odražavaju autoritet dokumenta. Za empiričku validaciju metode, treniramo dubok neuralni model mreže da predvidimo autore velike referenčne sete podataka koji se sastoje od novina i blog članaka. Iako se proces učenja nadzire, ne zahtijeva posvećenu etiketu podataka, ali se oslanja samo na metadata članaka koji su dostupni u ogromnim količinama. Procjenjujemo model na višestrukim podacima, na skupinu autoriteta i zadatku priključenja autoriteta.', 'et': 'Käesolevas töös tutvustame uut representatsiooniõppe meetodit, mille eesmärk on paigaldada dokumendid stilomeetrilisse ruumi. Varasemad autorsuse analüüsi uuringud keskendusid funktsioonide inseneritehnikatele, et esindada dokumentide stiile ja parandada mudeli jõudlust konkreetsetes ülesannetes. Selle asemel manustame dokumendid otse stilomeetrilisse ruumi, tuginedes autorite viitekogumile ja autorisisesele konsistentsioonile, mis on üks kahest komponendist meie kirjutamisstiili definitsioonis. Peamine intuitsioon käesolevas raamatus on, et me saame määratleda üldist stilomeetrilist ruumi kogumist viiteautorid nii, et selles ruumis koordinaadid erinevad dokumendid on lähedased, kui dokumendid on sama autor, ja hajub ära, kui need on erinevad autorid, isegi dokumentide autorid, kes ei ole kogumi viiteautorid. Meie väljapakutud meetod võimaldab dokumentide klastriseerimist dokumentide autorit peegeldavate stilistiliste vihjete alusel. Meetodi empiiriliseks valideerimiseks koolitame sügava närvivõrgu mudelit, et ennustada suure viiteandmekogumi autoriid, mis koosneb uudistest ja blogiartiklitest. Kuigi õppeprotsess on järelevalve all, ei nõua see spetsiaalset andmete märgistamist, vaid tugineb ainult artiklite metaandmetele, mis on kättesaadavad tohututes kogustes. Hindame mudelit mitme andmekogumi põhjal, nii autoriklastrite kui ka autori omistamise ülesannete puhul.', 'ca': "En aquest article introduim un nou mètode d'aprenentatge de representació que té l'objectiu d'incorporar documents en un espai estilomètric. Els estudis anteriors en el camp de l'anàlisi de l'autorització es van centrar en tècniques d'enginyeria de característiques per representar estils de documentació i millorar el rendiment del model en tasques específices. En comptes d'això, incorporem directament documents en un espai estilomètric confiant en un conjunt de referències d'autors i la propietat de consistencia intra-autora que és un dels dos components de la nostra definició d'estil d'escriptura. La intuïció principal d'aquest paper és que podem definir un espai estilomètric general d'un conjunt d'autors de referència de tal manera que, en aquest espai, les coordenadas de diferents documents estaran estretes quan els documents estan pel mateix autor, i s'estenen quan són per diferents autors, fins i tot per documents d'autors que no estan en el conjunt d'autors de referència. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents.  Per a la validació empírica del mètode, entrenem un model de xarxa neuronal profund per predir autors d'un gran conjunt de dades de referència que consisteix en notícies i articles de blog. Malgrat que el procés d'aprenentatge està supervisat, no requereix una etiquetada especial de les dades però només es basa en les metadades dels articles disponibles en grans quantitats. We evaluate the model on multiple datasets, on both the authorship clustering and the authorship attribution tasks.", 'fi': 'Tässä työssä esittelemme uuden representaatiooppimisen menetelmän, jonka tavoitteena on upottaa dokumentit stylometriseen tilaan. Aiemmat tekijät-analyysin opinnot keskittyivät ominaisuuksien suunnittelutekniikoihin dokumenttityylien esittämiseksi ja mallien suorituskyvyn parantamiseksi tietyissä tehtävissä. Sen sijaan upotamme dokumentit suoraan stylometriseen tilaan tukeutumalla kirjoittajien viiteryhmään ja tekijän sisäisen johdonmukaisuuden ominaisuuteen, joka on yksi kahdesta osatekijästä kirjoitustyylin määritelmässämme. Tärkein intuitio tässä artikkelissa on, että voimme määritellä yleisen stylometrisen tilan joukko referenssikirjoittajia siten, että tässä tilassa eri asiakirjojen koordinaatit ovat lähellä, kun asiakirjat ovat saman tekijän, ja hajaantuu, kun ne ovat eri kirjoittajia, jopa asiakirjoja kirjoittajia, jotka eivät ole joukko referenssikirjoittajia. Ehdottamamme menetelmä mahdollistaa asiakirjojen klusteroinnin dokumenttien luonnetta heijastavien tyylivihjeiden pohjalta. Menetelmän empiiristä validointia varten koulutamme syväneuroverkkomallin ennustamaan suuren uutis- ja blogiartikkeleista koostuvan viiteaineiston kirjoittajia. Vaikka oppimisprosessia valvotaan, se ei vaadi aineiston erillistä merkintää, vaan se perustuu vain artikkelien metatietoihin, jotka ovat saatavilla valtavissa määrissä. Arvioimme mallia useista aineistoista, sekä tekijän klusteroinnista että tekijän määrittelystä.', 'he': 'In this paper, we introduce a new method of representation learning that aims to embed documents in a stylometric space.  Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks.  Instead, we directly embed documents in a stylometric space by relying on a reference set of authors and the intra-author consistency property which is one of two components in our definition of writing style.  האינטואיציה העיקרית של העבודה הזאת היא שאנחנו יכולים להגדיר מרחב סטילומטרי כללי ממערכת סופרים התייחסות כך שבמרחב הזה, הקורדינטות של מסמכים שונים יהיו קרובות כשהמסמכים יהיו על ידי אותו הסופר, ומתפוצצים כאשר הם על ידי סופרים שונים, אפילו עבור מסמכים על ידי סופרים שאינם בתערכת סופרים התייחסות. The method we propose allows for the clustering of documents based on stylistic clues reflecting the authorship of documents.  לאימפריה האמפרית של השיטה, אנו מאמן דוגמא רשת עצבית עמוקה כדי לחזות את סופרים של קבוצת נתונים רמזים גדולה שמכילה בחדשות ומאמרי בלוג. למרות שהתהליך הלימודי משגיח, הוא לא דורש תיקון מוקדש של המידע, אך הוא סומך רק על המטאדאטה של המאמרים שזמינים בכמות עצומות. אנו מעריכים את המודל על קבוצות מידע מרובות, גם על קבוצת הסופרים וגם על משימות ההזדמנות של הסופרים.', 'jv': 'Nang pehar iki, kita mulai sistem sing bagian nggawe tarjamahan kanggo ngilangno dokumen neng sekang tarjamahan. Awak dhéwé éntuk karo perusahaan ranjelasi sing dikondisikno ning teknik neng injering nggawe bisa ngubah penjelunge kuwi nggawe modèl lah Awak dhéwé, entèwonan nggunaké pepulan iki iki dadi awak dhéwé iso nggawe geraksi perusahaan stylometar menyang kaké, nang gunakake iki, karo kobletan karo dokumen sing kalaluk nang mbukaké sing autor sing sabanjuré, lan mbukaké awak dhéwé, mengko karo dokumen sing autor sing kalaluk, lèwèké autor sing sampek mbukaké awak dhéwé. Method that we proposal Language buddy Awak dhéwé éntuk model sing ditambah akeh dataset, dadi sing alih basa perusahaan karo perusahaan kanggo tukang tarjamahan', 'sk': 'V prispevku predstavljamo novo metodo učenja reprezentacije, katere cilj je vgraditi dokumente v stilometrični prostor. Prejšnje študije s področja avtorske analize so se osredotočale na tehnike inženiringa funkcij, da bi predstavili sloge dokumentov in izboljšali delovanje modela pri določenih nalogah. Namesto tega dokumente neposredno vključimo v stilometrični prostor z opiranjem na referenčni nabor avtorjev in lastnost konsistence znotraj avtorja, ki je ena od dveh komponent v naši definiciji sloga pisanja. Glavna intuicija tega prispevka je, da lahko določimo splošni stilometrični prostor iz nabora referenčnih avtorjev tako, da bodo v tem prostoru koordinate različnih dokumentov blizu, ko so dokumenti istega avtorja, in razširjene, ko so različni avtorji, tudi za dokumente avtorjev, ki niso v naboru referenčnih avtorjev. Predlagana metoda omogoča združevanje dokumentov na podlagi slogovnih namigov, ki odražajo avtorstvo dokumentov. Za empirično validacijo metode usposabljamo model globokega nevronskega omrežja za napovedovanje avtorjev velikega referenčnega nabora podatkov, sestavljenega iz novic in blogovnih člankov. Čeprav je učni proces nadzorovan, ne zahteva namenskega označevanja podatkov, temveč se zanaša le na metapodatke člankov, ki so na voljo v ogromnih količinah. Model ocenjujemo na več naborih podatkov, tako na področju grozdov avtorstva kot na nalogah pripisovanja avtorstva.', 'bo': 'འུ་ཅག་གིས་ཤོག་བུ་འདིའི་ནང་དུ་བཟོ་རྣམ་གྱི་བར་སྟོང་ནང་ཡིག་ཆ་གསར་བ་ཞིག་སྟོན་བྱེད་ཀྱི་ཡོད། Previous studies in the field of authorship analysis focused on feature engineering techniques in order to represent document styles and to enhance model performance in specific tasks. འདི་ལྟ་བུའི་ནང་དུ་འུ་ཅག་གིས་ཡིག་ཆ་གསར་པའི་བར་སྟོང་ཅིག་ནང་གསལ་བཙུགས་པ་ལས་ རྩོམ་པ་པོ་སྒྲིག་འཛུགས་དང་རྩོམ་པ་པོ་སྒྲིག་དབང་ཆ་ཤས་གཉིས་ནང The main intuition of this paper is that we can define a general stylometric space from a set of reference authors such that, in this space, the coordinates of different documents will be close when the documents are by the same author, and spread away when they are by different authors, even for documents by authors who are not in the set of reference authors. ང་ཚོས་བསམ་འཆར་བཀོད་པའི་ཐབས་ལམ་དེ། བཟོ་རྣམ་གྱི་ཡིག་ཆ་གླེང་སྒྲུབ་ཀློག་པའི་ཡིག To the empirical validation of the method, we train a deep neural network model to predict authors of a large reference dataset consisting of news and blog articles. Albeit the learning process is supervised, it does not require a dedicated labeling of the data but it relies only on the metadata of the articles which are available in huge amounts. ང་ཚོས་དབང་འཛིན་བྱེད་པའི་མིག་གནད་སྡུད་ཚང་མང་པོ་ཞིག་དཔྱད་བྱེད་ཀྱི་ཡོད།', 'ha': "Daga wannan takardan, Munã ƙara wata hanyoyi na mai gayawa da za'a sanar da shi da ake yi amfani da takardar a cikin wani fili. Tayyar da zaman cikin shawarar littafan ya yi zura fokus a kan zanen masu tsari na masu aikin muhimmin masu inganci dõmin a nuna misalin takardar, kuma dõmin ya ƙara muhimmin misalin cikin aikin ƙayyade. Bayyansa, mun shiga takardar takarda a cikin wani fili mai misãlai da mu dõgara a kan wani tsarin matsayi na rubutu da dũkiyar da ma'abũcin-mai daidaita wanda ke cikin rubutun. Bayanin gaske na wannan takarda shine lalle, za'a iya ƙayyade wata matsayi mai jumla daga wasu ma'abũta misalin kamar, cikin wannan fili, za'a rufe shirin takardun wasu takardun, idan takardun duk da ke rubutun da shi, kuma za'a wãtsa idan sune da marubuci daban, ko kuma don don don wasu takardar kuma ba su daidaita matsayin mutane ba. @ action: button Kuskure gaskiyar shirin ayuka, za'a ƙidãya wata misali na'urar neura zuwa wani abu mai girma wa mutane na danna tsari mai girma na haɗi da takardar lãbãri da kuma sunayen agogo. Aka tsare aikin da aka karanta, ba ya ƙayyade wani labelin da aka ƙayyade, kuma amma yana dõgara kawai kan metadata na da aka samu cikin girma. Kana ƙaddara misalin a kan tsarin mutane mãsu yawa, kan karatun masu ƙaranci da aikin mataimaki."}
{'en': 'A Little Birdie Told Me...  -Inductive Biases for Rumour Stance Detection on  Social Media', 'ar': '"A Little Birdie Told Me ..." - التحيزات الاستقرائية لكشف موقف الشائعات على وسائل التواصل الاجتماعي', 'es': '«A Little Birdie Told Me...» - Prejuicios inductivos para la detección de posturas de rumores en las redes sociales', 'pt': '“A Little Birdie Told Me …” – Viés indutivo para detecção de postura de boatos nas mídias sociais', 'fr': '«\xa0A Little Birdie Told Me...\xa0» - Les biais inductifs pour la détection de la position de la rumeur sur les réseaux sociaux', 'ja': '「A Little Birdie Told Me...」-ソーシャルメディアでの噂のスタンス検出のための帰納的バイアス', 'hi': '"एक छोटी सी बर्डी ने मुझे बताया ... " - सामाजिक मीडिया पर अफवाह रुख का पता लगाने के लिए आगमनात्मक पूर्वाग्रह', 'ru': '«Маленькая птичка сказала мне ... » - Индуктивные предрассудки для обнаружения позиции слухов в социальных сетях', 'zh': '"一鸟告我... " - 社交媒体上施于讹言立场检测的归纳偏差', 'ga': '“A Little Birdie Ind Me ...” - Claonadh Ionduchtach chun Seasamh Rumor a Bhrath ar na Meáin Shóisialta', 'el': '"Ένα μικρό πουλάκι μου είπε..." Επαγωγικές προκαταλήψεις για την ανίχνευση θέσης φήμης στα μέσα κοινωνικής δικτύωσης', 'hu': 'Egy kis madár azt mondta... Induktív ellentmondások a pletykák helyzetének észlelésére a közösségi médiában', 'it': 'Un uccellino mi ha detto... Biase induttive per la rilevazione della posizione delle voci sui social media', 'ka': 'მალკჲ ბყპეთ მთ კაჱა... სოციალური მედიაში საკუთარი მონაცემებისთვის პრომეტური სტანსის განახლებისთვის', 'ms': "'A Little Birdie Told Me ...' - Inductive Biases for Rumour Stance Detection on Social Media", 'mk': 'Мала птица ми кажа... Индуктивни пречки за детективирање на гласини за социјалните медиуми', 'ml': "'ഒരു കൊച്ചു ബിര്\u200dഡി എന്നോട് പറഞ്ഞു.' സോഷ്യല്\u200d മീഡിയയുടെ സ്ഥാനത്തിനുള്ള വിവരങ്ങള്\u200d", 'kk': '"Кішкене жұлдыз маған айтты..." Социалдық медиақтардың жұмыс станциясын анықтау үшін көпшілікті көпшілігі', 'mt': '"Għasafar żgħir qal lili ... "- Biases Induttivi għas-Sejbien ta’ Stanzi ta’ Rumori fuq il-Midja Soċjali', 'pl': '"Mały ptaszek powiedział mi..." Indukcyjne uprzedzenia do wykrywania pozycji plotek w mediach społecznościowych', 'ro': '"O păsărică mică mi-a spus..." Biase inductive pentru detectarea stării zvonurilor pe rețelele sociale', 'lt': '"Mažas paukštis man pasakė..." Induktyvieji trūkumai, susiję su gandų pozicijų nustatymu socialinėje žiniasklaidoje', 'no': '"Ein liten Birdie fortalte meg ... " Induktiv oppløsningar for oppdaging av rumour Stance på sosiale mediar', 'mn': '"Бяцхан шувуу надад хэлсэн..." Нийгмийн мэдээллийн мэдээллийн хувьд хэмжээний хэмжээний нээлт', 'so': "'Birdie yar ayaa ii sheegay... Biyaatarka muuqashada ee qiimeynta suuqa sooshalka", 'sv': '"En liten fågel berättade för mig..." Induktiva fördomar för upptäckt av rykten på sociala medier', 'ta': "'ஒரு சிறிது பிரிடி என்னிடம் சொன்னார் ... ' Name", 'ur': '"ایک چھوٹی پرندی نے مجھے کہا..." سوسیل میڈیا پر روم استنس ڈیٹکس کے لئے اذیت دینے والی بیزاز', 'si': "'පොඩි බර්ඩි කියලා මට කිව්වා... ' සාමාජික මාධ්\u200dයමත්වයේ සිදුවීම ස්ථානය හොයාගන්න ප්\u200dරශ්නයක් වෙනුවෙන්.", 'sr': 'Mali ptica mi je rekla... Induktivne izlaze za detekciju ružnog stanja u socijalnim medijima', 'vi': "'A little Birdie told me...'... Phát hiện kết thúc cho ám ảnh Rumour Stance trên phương tiện xã hội", 'uz': "'Kichik Birdie Menga aytdi...' ' Name", 'bg': 'Малкото птиче ми каза... Индуктивни предразсъдъци за откриване на слуховете в социалните медии', 'hr': 'Mali ptičić mi je rekao... Induktivne rastave za otkrivanje stanice ružanja na socijalnim medijima', 'id': "'A Little Birdie Told Me ...' - Induktif Biases for Rumor Stance Detection on Social Media", 'nl': "'Een klein vogeltje vertelde me...' ' Inductieve vooroordelen voor detectie van geruchten op sociale media", 'fa': 'يه پرنده کوچولو بهم گفت افزایش ناراحتی برای بازرسی استنس روم در رسانه\u200cهای اجتماعی', 'da': '"En lille fugl fortalte mig..." Induktive fordrejninger for afsløring af rygter på sociale medier', 'tr': "'Biraz kuş maňa aýtdy ... ' Sosyal Medýdançalary barada ýetişikli biýatlar", 'af': "'n Klein Birdie het my gesê ... ' Induktiewe voorwerpe vir Rumour Stance Deteksie op Sosiale Media", 'sw': "'Birdie mdogo aliniambia... Inductive Biases for Rumour Stance Detection on Social Media", 'de': '"Ein kleiner Vogel sagte mir..." Induktive Vorurteile zur Erkennung von Gerüchten in sozialen Medien', 'hy': "'A Little Birdie Told Me ... ' -  Սոցիալական լրատվամիջոցների ոգեշնչող խոսքերը", 'sq': '"Një zog i vogël më tha..." Ndryshime induktive për zbulimin e qëndrimit të thashethemeve në mediat sociale', 'am': "'ትንሽ Birdie ነገረኝ... ' ማኅበራዊ ሚዲያ ላይ የውይይት ድጋፍ", 'ko': '"작은 새 한 마리가 나에게 말했다......"소셜 미디어에서 유언비어의 입장이 검출된 귀납적 편견', 'bn': "'একটা ছোট্ট বার্ডি আমাকে বলেছে... ' সামাজিক প্রচার মাধ্যমে গুজব স্ট্যান্স ডিটেকশনের জন্য ইন্ডিয়েটিভ বায়াস", 'ca': '"Un petit ocell em va dir..." Els obstáculos inductius per la detecció de la posició dels rumors dels mitjans socials', 'cs': '"Malý ptáček mi řekl..." Induktivní předsudky pro detekci pověstí na sociálních médiích', 'fi': 'Pikkulintu kertoi minulle... Induktiiviset ennakkoluulot huhujen asenteiden havaitsemiseen sosiaalisessa mediassa', 'az': "Mənə küçük bir quş dedi . Sosyal Medya'da Rumour Stance Detection for Inductive Biases for Rumour Stance Detection on Social Media", 'bs': 'Mali ptica mi je rekla... Induktivne prirode za otkrivanje ružnog stanja u socijalnim medijima', 'et': 'Väike linnuke ütles mulle... Induktiivsed eelarvamused kuulujuttude seisukoha tuvastamiseks sotsiaalmeedias', 'he': '"ציפור קטנה סיפרה לי..." סבלנות אינדוקטיביות לגילוי עמדות שמועות במדיה חברתית', 'sk': 'Mali ptiček mi je povedal... Induktivne pristranskosti za odkrivanje stanja govoric na družbenih medijih', 'jv': "'Bengko urip sing arep ngejaraké aku ...' structural Biasas for", 'ha': "'A Little Birdi ya gaya Mini... Indive Bices for Rumor Stance Discection on Soconal Media", 'bo': "'嘟嗋酱嘟勦紜嘟栢紜嘟嗋酱嘟勦紜嘟嗋酱嘟勦紜嘟炧讲嘟傕紜嘟勦紜嘟｀紜嘟栢饯嘟戉紜嘟斷紜嗉嬥紜' - 嘟⑧京嘟监綐嗉嬥綌嗉嬥綖嘟侧絺嗉嬥綋嘟侧紜 嘟︵兢嗑编讲嗉嬥綒嘟监絺嘟︵紜嘟犩綎嗑侧胶嘟｀紜嘟樴綈嘟脆綉嗉嬥絺嘟撪溅嗉嬥綒嘟脆剑嗉嬥絺嗑编讲嗉嬥舰嗑｀綐嗉嬥綌嗉嬥溅嗑愢郊嘟⑧紜嘟栢舰嗑椸郊嘟戉紜嘟斷紞"}
{'en': 'The rise in the usage of  social media  has placed  it  in a central position for  news dissemination  and consumption. This greatly increases the potential for proliferation of  rumours  and  misinformation . In an effort to mitigate the spread of rumours, we tackle the related task of identifying the stance (Support, Deny, Query, Comment) of a  social media post . Unlike previous works, we impose  inductive biases  that capture platform specific user behavior. These  biases , coupled with social media fine-tuning of BERT allow for better  language understanding , thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'es': 'El aumento en el uso de las redes sociales las ha colocado en una posición central para la difusión y el consumo de noticias. Esto aumenta en gran medida el potencial de proliferación de rumores y desinformación. En un esfuerzo por mitigar la propagación de rumores, abordamos la tarea relacionada de identificar la postura (apoyo, denegación, consulta, comentario) de una publicación en redes sociales. A diferencia de trabajos anteriores, imponemos sesgos inductivos que capturan el comportamiento específico de los usuarios de la plataforma. Estos sesgos, junto con el ajuste fino de BERT en las redes sociales, permiten una mejor comprensión del idioma, lo que arroja una puntuación F1 de 58,7 en la tarea de SemEval 2019 sobre la detección de posturas de rumores.', 'fr': "L'augmentation de l'utilisation des médias sociaux les place au cœur de la diffusion et de la consommation d'informations. Cela augmente considérablement le risque de prolifération de rumeurs et de désinformation. Afin d'atténuer la propagation des rumeurs, nous nous attaquons à la tâche connexe consistant à identifier la position (soutien, refus, requête, commentaire) d'une publication sur les réseaux sociaux. Contrairement aux travaux précédents, nous imposons des biais inductifs qui capturent le comportement des utilisateurs spécifiques à la plateforme. Ces biais, associés au réglage fin du BERT sur les réseaux sociaux, permettent une meilleure compréhension de la langue, donnant ainsi un score F1 de 58,7 sur la tâche SemEval 2019 sur la détection de la position de la rumeur.", 'ar': 'أدى الارتفاع في استخدام وسائل التواصل الاجتماعي إلى وضعها في موقع مركزي لنشر الأخبار واستهلاكها. هذا يزيد بشكل كبير من احتمالية انتشار الشائعات والمعلومات المضللة. في محاولة للحد من انتشار الشائعات ، نتعامل مع المهمة ذات الصلة المتمثلة في تحديد الموقف (الدعم ، الرفض ، الاستعلام ، التعليق) لمنشور على وسائل التواصل الاجتماعي. على عكس الأعمال السابقة ، نفرض تحيزات استقرائية تلتقط سلوك مستخدم معين في النظام الأساسي. تتيح هذه التحيزات ، إلى جانب ضبط وسائل التواصل الاجتماعي لـ BERT فهمًا أفضل للغة ، وبالتالي الحصول على درجة F1 تبلغ 58.7 في مهمة SemEval 2019 الخاصة باكتشاف موقف الشائعات.', 'pt': 'O aumento do uso das mídias sociais a colocou em uma posição central para a divulgação e consumo de notícias. Isso aumenta muito o potencial de proliferação de rumores e desinformação. Em um esforço para mitigar a propagação de rumores, abordamos a tarefa relacionada de identificar a postura (Suporte, Negar, Consulta, Comentário) de uma postagem de mídia social. Ao contrário de trabalhos anteriores, impomos vieses indutivos que capturam o comportamento do usuário específico da plataforma. Esses vieses, juntamente com o ajuste fino do BERT nas mídias sociais, permitem uma melhor compreensão da linguagem, gerando uma pontuação F1 de 58,7 na tarefa SemEval 2019 sobre detecção de postura de boatos.', 'zh': '社交媒体使用量之增益,使处新闻传消息之中。 大增讹言及错误信息散可能。 为轻讹言,解知社交媒体帖(,拒绝问)。 异乎前作,加之归差,以获特定于平台之用户。 此等偏见,加以社交媒体BERT之微,可以更解言语,而SemEval 2019讹言立场检测之务生58.7F1分数。', 'hi': 'सोशल मीडिया के उपयोग में वृद्धि ने इसे समाचार प्रसार और खपत के लिए एक केंद्रीय स्थिति में रखा है। यह अफवाहों और गलत सूचनाओं के प्रसार की संभावना को बहुत बढ़ाता है। अफवाहों के प्रसार को कम करने के प्रयास में, हम एक सोशल मीडिया पोस्ट के रुख (समर्थन, इनकार, क्वेरी, टिप्पणी) की पहचान करने के संबंधित कार्य से निपटते हैं। पिछले कार्यों के विपरीत, हम आगमनात्मक पूर्वाग्रहों को लागू करते हैं जो प्लेटफ़ॉर्म विशिष्ट उपयोगकर्ता व्यवहार को कैप्चर करते हैं। ये पूर्वाग्रह, BERT के सोशल मीडिया फाइन-ट्यूनिंग के साथ युग्मित बेहतर भाषा की समझ के लिए अनुमति देते हैं, इस प्रकार अफवाह रुख का पता लगाने पर SemEval 2019 कार्य पर 58.7 का F1 स्कोर उत्पन्न करते हैं।', 'ja': 'ソーシャルメディアの利用の増加により、ニュースの発信と消費において中心的な位置を占めるようになった。これにより、噂や誤った情報が拡散する可能性が大幅に高まります。うわさの拡散を緩和するために、ソーシャルメディア投稿のスタンス（サポート、拒否、クエリ、コメント）を特定する関連タスクに取り組んでいます。これまでの作品とは異なり、プラットフォーム固有のユーザー行動をキャプチャする帰納的バイアスを課しています。これらのバイアスは、BERTのソーシャルメディアの微調整と相まって、より良い言語理解を可能にし、従って、噂のスタンス検出に関するSemEval 2019タスクで58.7のF 1スコアをもたらします。', 'ru': 'Рост использования социальных сетей поставил их в центральное положение в области распространения и потребления новостей. Это значительно повышает вероятность распространения слухов и дезинформации. Стремясь смягчить распространение слухов, мы решаем связанную с этим задачу определения позиции (поддержка, отказ, запрос, комментарий) поста в социальных сетях. В отличие от предыдущих работ, мы накладываем индуктивные смещения, которые фиксируют специфическое поведение пользователей платформы. Эти предвзятости в сочетании с точной настройкой BERT в социальных сетях позволяют лучше понимать язык, таким образом, получая оценку F1 58,7 в задаче SemEval 2019 по обнаружению позиции слухов.', 'ga': 'Mar gheall ar an m챕ad첬 ar 첬s찼id na me찼n s처isialta, t찼 찼it l찼rnach aige maidir le nuacht a scaipeadh agus a chaitheamh. M챕ada챠onn s챕 seo go m처r an acmhainneacht le haghaidh iomad첬 r찼fla챠 agus m챠fhaisn챕ise. Mar iarracht le scaipeadh r찼fla챠 a mhaol첬, t챕imid i ngleic leis an tasc gaolmhar maidir le seasamh (Taca챠ocht, Di첬ltaigh, Ceist, Tr찼cht) post me찼n s처isialta a aithint. Murab ionann agus saothair roimhe seo, forchuirimid laofachta챠 ionduchtach a ghlacann iompra챠ocht 첬s찼ideoir챠 ard찼in ar leith. Ligeann na laofachta챠 seo, mar aon le mionchoigeart첬 BERT ar na me찼in sh처isialta, do thuiscint teanga n챠os fearr, rud a thugann sc처r F1 de 58.7 ar thasc SemEval 2019 maidir le seasamh r찼fla챠 a bhrath.', 'el': 'Η αύξηση της χρήσης των μέσων κοινωνικής δικτύωσης το έχει θέσει σε κεντρική θέση για τη διάδοση και την κατανάλωση ειδήσεων. Αυτό αυξάνει σημαντικά τη δυνατότητα διάδοσης φήμων και παραπληροφόρησης. Σε μια προσπάθεια μετριασμού της εξάπλωσης των φήμων, αντιμετωπίζουμε το σχετικό καθήκον του εντοπισμού της στάσης (Υποστήριξη, Αρνηση, Ερώτηση, Σχόλιο) μιας ανάρτησης στα μέσα κοινωνικής δικτύωσης. Σε αντίθεση με προηγούμενες εργασίες, επιβάλλουμε επαγωγικές προκαταλήψεις που συλλαμβάνουν τη συγκεκριμένη συμπεριφορά χρήστη της πλατφόρμας. Αυτές οι προκαταλήψεις, σε συνδυασμό με τον συντονισμό των μέσων κοινωνικής δικτύωσης, επιτρέπουν την καλύτερη κατανόηση της γλώσσας, δίνοντας έτσι μια βαθμολογία F1 58.7 στην εργασία σχετικά με την ανίχνευση στάσεων φήμης.', 'hu': 'A közösségi média használatának növekedése központi helyzetbe helyezte a hírek terjesztését és fogyasztását. Ez jelentősen növeli a pletykák és a félrevezető információk elterjedésének lehetőségét. A pletykák elterjedésének enyhítésére irányuló erőfeszítések céljából egy közösségi média poszt álláspontjának (Támogatás, tagadás, lekérdezés, megjegyzés) azonosítására irányuló feladattal foglalkozunk. A korábbi munkákkal ellentétben induktív előírásokat alkalmazunk, amelyek rögzítik a platformspecifikus felhasználói viselkedést. Ezek az előítéletek, valamint a BERT közösségi média finomhangolása lehetővé teszi a jobb nyelvmegértést, így 58,7 F1 pontszámot eredményeznek a SemEval 2019-es pletykák álláspontjának felismerésére vonatkozó feladatban.', 'it': "L'aumento dell'utilizzo dei social media lo ha posto in una posizione centrale per la diffusione e il consumo di notizie. Ciò aumenta notevolmente il potenziale di proliferazione di voci e disinformazione. Nel tentativo di mitigare la diffusione delle voci, affrontiamo il relativo compito di identificare la posizione (Supporto, Nega, Query, Commento) di un post sui social media. A differenza dei lavori precedenti, imponiamo pregiudizi induttivi che catturano il comportamento specifico dell'utente della piattaforma. Questi pregiudizi, uniti alla messa a punto dei social media di BERT, consentono una migliore comprensione del linguaggio, ottenendo così un punteggio F1 di 58,7 sul compito SemEval 2019 sulla rilevazione delle posizioni delle voci.", 'ka': 'სოციალური მედიახის გამოყენებაში იქნება ის ცენტრალური პოზაციაში ნუტრალური განსხვავებას და გამოყენებას. ეს ძალიან უფრო მეტივს პონციალური სიტყვების და შეცდომარების გაფართლებისთვის. ჩვენ საზოგადოების გარეშე, საზოგადომი მედია პოსტის სტაციენტის მოცემების (მხარდაჭერები, განწმება, კითხვები, კონტაქტი) დავიწყებთ. პირველი სამუშაოების განმავლობაში, ჩვენ ინდექტიური სამუშაოები დავყენებთ, რომლებიც პლატატურის განსაკუთრებული მომხმარებელი ქცევ ეს წარმოდგენები, რომლებიც საზოგადომი მედიაციის კონფიგურაცია BERT-ის შესაძლებელია უკეთესი წარმოდგენისთვის, ამიტომ მიეცემა 58.7 წარმოდგენისთვის სამუშაო 2019 წარმოდგენისთ', 'mk': 'Зголемувањето на користењето на социјалните медиуми го стави во централна позиција за ширење и потрошуваое на вестите. Ова значително го зголемува потенцијалот за ширење гласини и погрешни информации. Во обид да го намалиме ширењето гласини, ја решаваме поврзаната задача за идентификување на ставот (поддршка, одбивање, запрашување, коментар) на социјалните медиуми. Unlike previous works, we impose inductive biases that capture platform specific user behavior.  Овие предрасуди, заедно со подобрувањето на социјалните медиуми на БЕРТ, овозможуваат подобро разбирање на јазикот, со што се добива оценка F1 од 58,7 за задачата SemEval 2019 за детекција на гласините.', 'kk': 'Жаңалық тарату және пайдалану үшін социалдық медиақтар қолданудың көтерілігі жаңалық тарату және пайдалану үшін негізгі ортасына орналасады. Бұл дыбыс және дұрыс түрлендіру мүмкіндігін өзгертеді. Дыбыс таратуды көшірмелеу үшін біз социалдық медиа поштасын анықтау (қолдау, қабылдау, сұрау, сұрау, түсініктеме) тапсырмасын шешу жұмысына қатынаймыз. Алдыңғы жұмыстар сияқты, платформа арнаулы пайдаланушылардың әрекетін түсіндіретін индуктивті өзгерістерді қолданамыз. Бұл өзгерістер, BERT әлемдік медиақтарын жақсы түсінуге мүмкіндік береді, сондықтан 2019 жылдың semiEval тапсырмасының тапсырмасын таңдау үшін F1 нүктесі 58,7 деп береді.', 'ml': 'സാമൂഹ്യ മാധ്യമങ്ങളുടെ ഉപയോഗിക്കുന്നതിന്റെ ഉയര്\u200dന്നിരിക്കുന്നു വാര്\u200dത്ത വിശദീകരണവും ഉപയോഗിക്കുന വാക്കുകളും തെറ്റായ വിവരങ്ങളും ഉല്\u200dപാദിപ്പിക്കുന്നതിനുള്ള സാധ്യതകള്\u200d ഇത് വളര്\u200dത്തുന്നു. വാക്കുകള്\u200d വ്യാപിപ്പിക്കാന്\u200d ശ്രമിച്ചാല്\u200d സാമൂഹ്യ മീഡിയ പോസ്റ്റ് തിരിച്ചറിയുന്നതിന്\u200dറെ (പിന്തുണയ്, നിഷേധിക്കുന്നത്, ച മുമ്പ് പ്രവര്\u200dത്തിക്കുന്ന പ്രവര്\u200dത്തനങ്ങള്\u200d വ്യത്യസ്തമായിട്ടും, പ്ലാറ്റ്ഫോമിലെ പ്രത്യേക ഉപയോക്താവിന്\u200dറ ബെര്\u200dട്ടിയുടെ സാമൂഹ്യ മാധ്യമങ്ങളോടൊപ്പം ബന്ധപ്പെട്ടിരിക്കുന്ന ഈ പ്രശ്നങ്ങള്\u200d ഭാഷയില്\u200d മെച്ചപ്പെടുത്താന്\u200d അനുവദിക്കുന്നു. അതുകൊണ്', 'mn': 'Нийгмийн мэдээллийн хэрэглээний өсөлт нь мэдээллийн тархалт, хэрэглээний төвд байрлуулсан. Энэ нь шүлэг болон буруу хэлбэрүүдийг нэмэгдүүлэх боломжийг их нэмэгдүүлдэг. Шингэлийн тархалтыг багасгах зорилгод нийгмийн хэвлэлийн тайлбарын байр суурь тодорхойлох (дэмжих, татвар, хүлээн зөвшөөрөх, хүлээн зөвшөөрөх) талаар бид холбоотой ажил зорилгодог. Өмнөх ажлын ялгаатай, бид хэрэглэгчийн үйл ажиллагааг шалгаж буй үйл ажиллагааны зан чанарыг бий болгодог. БЕРТ-ын нийгмийн мэдээллийн хэрэглэгчийн сайжруулалт нь илүү сайжруулах боломжтой. Иймээс 2019 оны SemEval-ын ярианы байдлын талаар F1 оноо 58.7 гарч ирсэн.', 'ms': 'Peningkatan penggunaan media sosial telah menempatkannya dalam kedudukan pusat untuk penyebaran dan konsumsi berita. Ini meningkatkan kemungkinan penyebaran khabar angin dan kesalahan maklumat. Dalam usaha untuk mengurangi penyebaran khabar angin, kami menangani tugas berkaitan untuk mengenalpasti pendapat (Sokongan, Deng, Pertanyaan, Komen) pos media sosial. Unlike previous works, we impose inductive biases that capture platform specific user behavior.  These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'lt': 'The rise in the usage of social media has placed it in a central position for news dissemination and consumption.  Tai labai padidina gandų ir neteisingos informacijos platinimo galimybes. Siekdami sušvelninti gandų sklaidą, sprendžiame su tuo susijusią užduotį nustatyti socialinės žiniasklaidos posto poziciją (parama, atsisakymas, klausymas, komentaras). Unlike previous works, we impose inductive biases that capture platform specific user behavior.  These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'mt': 'Iż-żieda fl-użu tal-midja soċjali poġġiha f’pożizzjoni ċentrali għat-tixrid u l-konsum tal-a ħbarijiet. Dan iżid ħafna l-potenzjal għall-proliferazzjoni ta’ rumori u informazzjoni ħażina. Fi sforz biex itaffi t-tixrid ta’ rumori, a ħna nindirizzaw il-kompitu relatat li nidentifikaw il-pożizzjoni (Appoġġ, Ċaħda, Talba, Kummenti) ta’ post tal-midja soċjali. Għall-kuntrarju tax-xogħlijiet preċedenti, nimponu preġudizzji induttivi li jaqbdu l-imġiba speċifika tal-utent tal-pjattaforma. These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'pl': 'Wzrost korzystania z mediów społecznościowych umieścił je w centralnej pozycji dla upowszechniania i konsumpcji wiadomości. Znacznie zwiększa to potencjał rozprzestrzeniania się plotek i dezinformacji. W celu złagodzenia rozprzestrzeniania się plotek podejmujemy związane z tym zadanie identyfikacji stanowiska (Wsparcie, Odrzucenie, Zapytanie, Komentarz) posta w mediach społecznościowych. W przeciwieństwie do poprzednich prac narzucamy uprzedzenia indukcyjne, które przechwytują specyficzne zachowania użytkowników platformy. Te uprzedzenia, w połączeniu z doskonaleniem BERT w mediach społecznościowych, pozwalają na lepsze zrozumienie języka, dając tym samym wynik F1 58.7 w zadaniu SemEval 2019 w zakresie wykrywania pozycji plotek.', 'ro': 'Creșterea utilizării rețelelor sociale a plasat-o într-o poziție centrală pentru difuzarea și consumul de știri. Acest lucru sporește considerabil potențialul de proliferare a zvonurilor și dezinformare. În efortul de a atenua răspândirea zvonurilor, abordăm sarcina aferentă de a identifica poziția (Suport, Negare, Interogare, Comentariu) a unui post social media. Spre deosebire de lucrările anterioare, impunem prejudecăți inductive care capturează comportamentul utilizatorului specific platformei. Aceste prejudecăți, împreună cu ajustarea fină a rețelelor de socializare a BERT permit o mai bună înțelegere a limbii, obținând astfel un scor F1 de 58,7 la sarcina SemEval 2019 privind detectarea poziției zvonurilor.', 'so': 'Koritaankii isticmaalka shabakadda bulshada ayaa meel u dhexeeya si ay u kala soocaan warbixinta iyo isticmaalka. Taas waxay si badan u kordhisaa awoodda koritaanka wararka iyo macluumaad khalad ah. Jahaadada si aad u fududaatid warqada, waxaynu u tacliinaynaa shaqada la xiriira aqoonsashada xaaladda (Kaalmada, diidi, Query, Query) boostada shabakadda bulshada. Shuqullada hore oo aan kala duwan ahayn, waxaynu sameynaa tababaro dhaqdhaqaale ah oo qabta tababarka isticmaalaha gaar ah. Dhaqdhaqaaqyadan, oo la xiriiray shabakadda bulshada ee BERT, waxay u ogolaan karaan waxgarashada afka wanaagsan, sidaas darteed waxay ka soo bandhigtaa F1 koox ka mid ah 58.7 oo ku saabsan shahaadada xaaladda beenta ah ee SemEval 2019.', 'sv': 'Den ökade användningen av sociala medier har placerat dem i en central position för nyhetsspridning och konsumtion. Detta ökar kraftigt risken för spridning av rykten och vilseledande information. I ett försök att mildra spridningen av rykten tar vi itu med den relaterade uppgiften att identifiera ställningstagandet (Stöd, Neka, Fråga, Kommentar) i ett inlägg på sociala medier. Till skillnad från tidigare arbeten påtvingar vi induktiva fördomar som fångar plattformsspecifikt användarbeteende. Dessa fördomar i kombination med finjustering av BERT på sociala medier möjliggör bättre språkförståelse, vilket ger en F1-poäng på 58,7 på SemEval 2019-uppgiften om detektering av rykten.', 'ta': 'The rise in the usage of social media has placed it in a central position for news dissemination and consumption.  இது மிகவும் அதிகப்படுத்தும் விஷயங்கள் மற்றும் தவறான தகவல்கள் வளர்ச்சி செய்யும். வார்த்தைகள் பரப்புவதற்கு குறைக்க முயற்சியில், நாங்கள் ஒரு சமூக ஊடகங்கள் நிலையின் (ஆதரவு, நிராகரிப்பு, கேள்வி), தொடர்பு பணியை நிர்ணய முந்தைய வேலைகளை வித்தியாசமாக, நாம் செயல்படுத்தும் பிரச்சனையான பயனர் நடத்தையை பிடித்துக் கொள்ளும்  இந்த பிரச்சனைகள், சமூக ஊடகங்களுடன் இணைந்த பிரெட் சிறந்த மொழியை புரிந்து கொள்ள அனுமதிக்கும், அதனால் செம்Eval 2019ல் செம்வெல் நிலையை கண்டுபிடிப்', 'ur': 'سوسیل میڈیا کے استعمال میں اضافہ اس کو اخبار پھیلانے اور مصرف کے لئے مرکزی موقعیت میں رکھا ہے. یہ افسانے اور غلط اطلاعات کے گھیرنے کے لئے بہت بڑھاتا ہے۔ افسانے کے پھیلانے کی کوشش میں ہم نے ایک سوسیل میڈیا پوسٹ کی موقعیت (مدد، انکار، سوال، توجہ) کو پہچان کرنے کے لئے ارتباط کی کوشش کی۔ پہلے کے کاموں کے مطابق، ہم نے پیدا کرنے والی غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غ یہ بحث، جو BERT کی سوسیل میڈیا سینٹینگ کے ساتھ ملی ہے، بہترین زبان سمجھنے کے لئے اجازت دیتی ہیں، یہاں تک کہ 2019 کے سامنے سیمئولی کے کام میں 58.7 سینٹینگ کا ذریعہ اضافہ کرتا ہے.', 'si': 'සාමාජික මාධ්\u200dයමයේ භාවිතානයේ විශාලයක් ඒක ප්\u200dරධාන ස්ථානයක් තියෙනවා. මේක ගොඩක් විශාල විශාලයක් වැඩ කරනවා කියලා කියලා කියලා. සාමාජික මධ්\u200dයමාධ්\u200dයම පොස්ටස්ට් එකේ සම්බන්ධ ව්\u200dයාපෘතියක් පරික්ෂා කරන්න උත්සාහ කරනවා. මුලින් වැඩ වගේම, අපි ප්\u200dලේටෆ්ටෝම් විශේෂ ප්\u200dරයෝජනය වැඩේ අල්ලගන්න ප්\u200dරයෝජනය විශේෂ මේ සාමාජික මිඩියාව සම්බන්ධ කරලා BERT එක්ක හොඳ භාෂාව තේරුම් ගන්න පුළුවන් වෙනවා, ඉතින් 2019 සම්බන්ධ ව්\u200dයාපෘතියේ සිම්වේල් එක', 'no': 'Øvrenga i bruken av sosiale medier har plassert den i ein sentralt plass for nyhetsprogram og bruk. Dette aukar stort potensialen for å utvida rumorer og feil informasjon. I eit påpålite å redusera spredning av rumorer, løser vi den relaterte oppgåva for å identifisera stasjonen (Støtte, Nekt, Spør, Kommentar) på ein sosiale mediepost. I motsetjing til førre arbeidar, sett vi inn induktive forsikt som hentar plattformspesifikke brukarhandling. Desse forvirkningane, samanlikna med finnstilling av BERT for sosiale medier, tillèt deg bedre språk forståking, derfor gjer F1-poeng av 58,7 på semiEval 2019-oppgåva om oppdaging av rumorestasjon.', 'sr': 'Povećanje korištenja društvenih medija ga je stavio u centralnu poziciju za razmnožavanje novosti i potrošnju. To veoma povećava potencijal proširenja glasina i pogrešne informacije. U pokušaju smanjiti širenje glasina, riješimo povezan zadatak identifikacije stanja (Podrška, odbijanje, pitanje, komentar) post a društvenih medija. Za razliku od prethodnih radova, nameštamo induktivne predrasude koje uhvate specifièno ponašanje korisnika platforme. Ove predrasude, povezane sa finaliziranjem socijalnih medija BERT-a, omogućavaju bolje razumevanje jezika, tako dajući F1 rezultat od 58,7 na zadatku semiEvala 2019 o otkrivanju glasina stanja.', 'vi': 'Sự gia tăng sử dụng các phương tiện xã hội đã đặt nó vào vị trí trung tâm cho việc phát tán và tiêu thụ tin tức. Điều này làm tăng khả năng của việc lan rộng tin đồn và tin lầm. Để giảm bớt sự lan rộng của tin đồn, chúng tôi phải xác định vị trí của các phương tiện truyền thông xã hội. Không như các tác phẩm trước, chúng tôi áp đặt các biến lề dẫn dẫn dẫn đến đó. Những thói giả này, kết hợp với việc chỉnh sửa thiết bị giao thông của giao dịch qua các phương tiện xã hội, cho phép hiểu ngôn ngữ tốt hơn, và cho ra một số F1 trong 58.7 về nhiệm vụ hoàn hảo của Seml Ev9 về phát hiện trường tin đồn.', 'uz': "Name Bu so'zlar va xato haqida maʼlumotni oshirish uchun qobiliyatni oshadi. Comment Oldingi ishlardan ham oʻxshash, biz platformni foydalanuvchi xususiyatlarini olib tashlash imkoniyatini ishlatamiz. Bu taʼminlovlar BERT haqida yaxshi tilni tushunishga ruxsat beradi, shunday qilib SemEval 2019 tashkilotlarini aniqlashda 58.7 darajaga ega bo'ladi.", 'nl': 'De toename van het gebruik van sociale media heeft het in een centrale positie geplaatst voor verspreiding en consumptie van nieuws. Dit vergroot de kans op verspreiding van geruchten en verkeerde informatie aanzienlijk. In een poging om de verspreiding van geruchten te beperken, pakken we de gerelateerde taak aan om de standpunten (Support, Deny, Query, Comment) van een social media post te identificeren. In tegenstelling tot eerdere werken leggen we inductieve vooroordelen op die platform specifiek gebruikersgedrag vastleggen. Deze vooroordelen, in combinatie met sociale media fine-tuning van BERT, zorgen voor een beter taalbegrip, waardoor een F1 score van 58.7 op de SemEval 2019 taak over geruchtstanddetectie wordt behaald.', 'hr': 'Povećanje korištenja društvenih medija ga je stavio u središnju poziciju za širenje i potrošnju vijesti. To veoma povećava potencijal proširenja glasina i pogrešne informacije. U pokušaju smanjiti širenje glasina, riješimo povezan zadatak identifikacije stanja (Podrška, odbijanje, pitanje, komentar) društvenih medija. Za razliku od prethodnih radova, stavljamo induktivne predrasude koje uključuju specifično ponašanje korisnika platforme. Ove predrasude, zajedno s finaliziranjem socijalnih medija BERT-a, omogućavaju bolje razumijevanje jezika, tako dajući rezultat F1-a od 58,7 na zadatku SemEval 2019 o otkrivanju glasina stanja.', 'da': 'Den stigende brug af sociale medier har placeret det i en central position for nyhedsudbredelse og forbrug. Dette øger i høj grad potentialet for spredning af rygter og misinformation. I et forsøg på at afbøde spredningen af rygter tackler vi den relaterede opgave med at identificere holdningen (Support, Afvis, Forespørgsel, Kommentar) i et indlæg på sociale medier. I modsætning til tidligere værker pålægger vi induktive fordomme, der fanger platformspecifik brugeradfærd. Disse fordomme kombineret med justering af BERT på sociale medier giver mulighed for bedre sprogforståelse, hvilket giver en F1 score på 58,7 på SemEval 2019-opgaven om detektering af rygter.', 'bg': 'Повишаването на използването на социалните медии ги поставя в централна позиция за разпространение и потребление на новини. Това значително увеличава потенциала за разпространение на слухове и дезинформация. В опит да смекчим разпространението на слухове, ние се справяме със съответната задача за идентифициране на позицията (Подкрепа, Отказ, Заявка, Коментар) на публикация в социалните медии. За разлика от предишни работи, ние налагаме индуктивни пристрастия, които улавят специфичното потребителско поведение на платформата. Тези предразсъдъци, съчетани с фината настройка на социалните медии, позволяват по-добро разбиране на езика, като по този начин дават резултат от 58,7 по задачата за откриване на позиции на слухове.', 'de': 'Die zunehmende Nutzung von Social Media hat es in eine zentrale Position für die Verbreitung und den Konsum von Nachrichten gebracht. Dies erhöht das Potenzial für die Verbreitung von Gerüchten und Fehlinformationen erheblich. Um die Verbreitung von Gerüchten zu mildern, nehmen wir uns der damit verbundenen Aufgabe an, die Haltung (Support, Deny, Query, Comment) eines Social Media Posts zu identifizieren. Im Gegensatz zu früheren Arbeiten verhängen wir induktive Verzerrungen, die plattformspezifisches Nutzerverhalten erfassen. Diese Vorurteile, gepaart mit der Feinabstimmung von BERT in sozialen Medien, ermöglichen ein besseres Sprachverständnis und liefern so eine F1-Punktzahl von 58.7 bei der SemEval 2019-Aufgabe zur Erkennung von Gerüchten.', 'fa': 'افزایش در استفاده از رسانه\u200cهای اجتماعی آن را در موقعیت مرکزی برای انتشار و مصرف اخبار قرار داده است. این پتانسیل افزایش شایعات و غلط اطلاعات را بسیار بیشتر می\u200cدهد. در تلاش برای تخفیف گسترش شایعات، ما کار ارتباطی با شناسایی وضعیت (پشتیبانی، انکار، سوال، توضیح) یک پست رسانه اجتماعی را حل می\u200cکنیم. برخلاف کارهای قبلی، ما پیشرفت های غیر قابل توجهی را تأثیر می دهیم که رفتار کاربران خاصی را دستگیر می کنند. این توجه\u200cها، همراه با تحقیقات رسانه\u200cهای اجتماعی BERT برای فهمیدن زبان\u200cهای بهتر اجازه می\u200cدهند، به همین دلیل یک امتیاز F1 از 58.7 در مورد وظیفه\u200cی semiEval 2019 در مورد شناسایی شایعات می\u200cدهد.', 'sw': 'Kuongezeka kwa matumizi ya mitandao ya kijamii imeweka nafasi ya katikati kwa ajili ya kusambaza habari na matumizi. Hii inaongeza uwezekano wa kuongezeka kwa uvumi na taarifa zisizo sahihi. Katika jitihada za kupunguza usambazaji wa uvumi, tunakabiliana na juhudi zinazohusiana na kutambua msimamo (Msaidizi, Kukataa, Soji, Comment) wa makala ya mitandao ya kijamii. Tofauti na kazi zilizopita, tunaweka upendeleo wa viwanda ambao unakamata tabia maalum za watumiaji. Upendeleo huu, ulioanganishwa na mitandao ya kijamii yenye ujumbe mzuri wa BERT, unaruhusu kuelewa vizuri kwa lugha, na hivyo kusababisha score ya F1 ya 58.7 kwenye kazi ya SemEval 2019 kuhusu uvumi wa uvumi.', 'tr': "Sosyal medýýatlaryň ulanmakynyň ýokary taýýarlamak we tüketmegi üçin esasy ýerde guruldy. Bu aýdyşlaryň ýalňyşlyklary we ýalňyşlyklaryň azalmagynyň potensialyny örän köpräk artýar. Seslerin azaltmakdan çykmak üçin biz sosial mediýanyň ýeriniň durumyny tanyşdyrmak üçin netijesini çözýäris. Öňki işlemleriň ýaly, platformyň spesifik ullanyşyny almak üçin täsirli sowgatlary çykarýarys. Bu sowuklar, sosyal medýýatlar BERT'yň gowy dil düşünmesine mümkin edýär. Şol sebäpli, 2019-njy SemEval 2019-njy ýyldaky jogabatyň bardygynda F1 sany 58.7 sany tapylýar.", 'ko': '소셜 미디어 사용량의 증가는 그로 하여금 뉴스 전파와 소비에서 중심적인 위치에 있게 했다.이는 루머와 잘못된 정보의 확산 가능성을 크게 높였다.루머의 확산을 줄이기 위해 소셜미디어 게시물의 입장(지지, 부인, 질의, 리뷰)을 정하는 임무를 수행했다.이전의 업무와 달리 우리는 귀납적 편견을 이용하여 플랫폼에 특정한 사용자 행위를 포착한다.따라서 소셜미디어에 대한 심버트의 편견과 결합하면 이런 루머를 더 잘 이해할 수 있다.', 'sq': 'Rritja në përdorimin e mediave sociale e ka vendosur atë në një pozitë qendrore për përhapjen e lajmeve dhe konsumin. This greatly increases the potential for proliferation of rumours and misinformation.  Në një përpjekje për të lehtësuar shpërndarjen e thashethemeve, ne trajtojmë detyrën e lidhur me identifikimin e qëndrimit (mbështetje, mohim, pyetje, koment) të një post të medias sociale. Në ndryshim nga punët e mëparshme, ne imponojmë paragjykime induktive që kapin sjelljen e përdoruesve specifik të platform ës. These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'af': "Die opstanding in die gebruik van sosiale media het dit in 'n sentrale posisie geplaas vir nuusverspreiding en gebruik. Dit vergroot die potensiaal vir verlenging van rumours en verkeerde formasie. In 'n versoek om die verspreiding van rumours te verminder, is ons die verwante taak van die identifiseer van die staanse (ondersteun, Onbekeer, Navraag, Kommentaar) van 'n sosiale media post. Ongelyks soos vorige werke, plaas ons induktiewe voorskrifte wat platforme spesifieke gebruikergedrag opneem. Hierdie voorskrifte, saam met sosiale media fin-tuning van BERT toelaat vir beter taal verstanding, sodat 'n F1 punt van 58.7 op die SemEval 2019 taak op rumor staatskenning verkry.", 'id': 'Peningkatan penggunaan media sosial telah menempatkannya di posisi pusat untuk penyebaran dan konsumsi berita. This greatly increases the potential for proliferation of rumours and misinformation.  In an effort to mitigate the spread of rumours, we tackle the related task of identifying the stance (Support, Deny, Query, Comment) of a social media post.  Tidak seperti pekerjaan sebelumnya, kita memaksa bias induktif yang menangkap perilaku platform spesifik pengguna. Hal-hal ini, bergabung dengan penyesuaian media sosial BERT memungkinkan pemahaman bahasa yang lebih baik, sehingga memberikan skor F1 58,7 pada tugas SemEval 2019 pada deteksi posisi rumor.', 'am': 'ማኅበራዊ አውታር በመጠቀም የሚቃወሙትን እና ለመጠቀም በመካከለኛ ስፍራን አቆመዋል፡፡ ይህ የውሸትን እና የስህተት መረጃዎችን ለማድረግ ኃይለኛ ይጨምራል፡፡ የውይይትን መዘርጋት ለማቅረብ ለመቻል፣ የማኅበራዊ አውታር ሚዲያ ፖስታ (ድጋፍ፣ ድጋፍ፣ ጥያቄ፣ ጥያቄ) የሚታወቀውን ስርዓት እናቆማለን፡፡ የቀድሞው ሥራ በተለየ፣ የፕሮግራሙን የተጠቃሚ ተጠቃሚን ሁኔታ ለመያዝ እናስፈልጋለን፡፡ These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'az': "Sosyal media istifadəsində artıq onu xəbərlərin yayılması və istifadə etməsi üçün məqsədilə yerləşdirdi. Bu səslərin və yanlış şəkillərin genişlənməsi üçün mümkün olaraq artırır. Söhbətlərin yayılmasını azaltmaq üçün, sosyal media postasının şəkilini təsdiqləmək üçün münasibətli işləri çəkirik. Əvvəlki işlərə bənzər, platformu müəyyən istifadəçi davranışlarını yakalayan tədbirli tədbirləri yerləşdiririk. Bu tədbirlər, BERT'nin sosyal mediyalarının düzəltməsi ilə birlikdə daha yaxşı dil anlaşılmasına imkan verir, beləliklə 2019-nın SemEval vəzifəsində Süfür müəyyən edilməsi haqqında F1 dəqiqəsi 58.7 verir.", 'bn': 'সামাজিক প্রচার মাধ্যম ব্যবহারের বাড়তি সংবাদ প্রচার এবং ভর্তুর জন্য এক কেন্দ্রীয় অবস্থানে রেখেছে। এটি গুজব এবং ভুল তথ্য বৃদ্ধির সম্ভাবনা বৃদ্ধি করে। গুজব ছড়িয়ে দেওয়ার প্রচেষ্টায়, আমরা সামাজিক মিডিয়া পোস্টের (সমর্থন, অস্বীকার, প্রশ্ন) অবস্থান চিহ্নিত করার সাথে সম্পর্কিত কাজের পূর্ববর্তী কাজের ভিন্ন ভিন্ন ভিন্ন ভিন্ন, আমরা ক্রিয়াকর্মীদের বিরুদ্ধে প্ল্যাটফর্ম ব্যবহারকারীদের These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'cs': 'Nárůst využívání sociálních médií ji umístil do centrální pozice pro šíření a spotřebu zpráv. To značně zvyšuje potenciál šíření zvěstí a dezinformací. Ve snaze zmírnit šíření pověstí řešíme související úkol identifikace postoje (Podpora, Odmítnutí, Dotaz, Komentář) příspěvku na sociálních sítích. Na rozdíl od předchozích prací zavádíme indukční předsudky, které zachycují chování uživatelů specifické pro platformu. Tyto předsudky spolu s jemným laděním BERT na sociálních médiích umožňují lepší porozumění jazykům, čímž přináší F1 skóre 58,7 na úkolu SemEval 2019 o detekci pověstí.', 'ca': "L'augment de l'ús dels mitjans socials l'ha posat en una posició central de difusió i consum de notícies. Això augmenta molt el potencial de proliferació de rumors i mala informació. En un esforç per mitigar la difusió de rumors, abordem la tasca relacionada d'identificar la posició (Suport, Negació, Consulta, Comentari) d'un article dels mitjans socials. A diferència dels treballs anteriors, imposem tendències inductives que capturen el comportament específic dels usuaris. Aquestes tendències, juntament amb la perfeccionació dels mitjans socials de BERT, permeten una millor comprensió del llenguatge, donant així una puntuació F1 de 58,7 en la tasca SemEval 2019 sobre la detecció de la posició rumorosa.", 'et': 'Sotsiaalmeedia kasutamise kasv on asetanud selle uudiste levitamise ja tarbimise kesksele positsioonile. See suurendab märkimisväärselt kuulujuttude ja valeteabe leviku potentsiaali. Püüdes leevendada kuulujuttude levikut, tegeleme sellega seotud ülesandega tuvastada sotsiaalmeedia postituse seisukoht (toetus, eitamine, päring, kommentaar). Erinevalt varasematest töödest kehtestame induktiivseid kallakuid, mis kajastavad platvormi spetsiifilist kasutaja käitumist. Need eelarvamused koos BERTi sotsiaalmeedia peenhäälestusega võimaldavad paremini keelest aru saada, andes seega F1 skoori 58,7 SemEval 2019 ülesandel kuulujuttude hoiakute tuvastamisel.', 'fi': 'Sosiaalisen median käytön lisääntyminen on asettanut sen keskeiseen asemaan uutisten levittämisessä ja kulutuksessa. Tämä lisää huomattavasti huhujen ja väärien tietojen leviämisen mahdollisuuksia. Pyrimme lieventämään huhujen leviämistä ja ratkaisemme siihen liittyvän tehtävän tunnistaa sosiaalisen median viestin kannan (tuki, kieltäminen, kysely, kommentti). Toisin kuin aiemmissa teoksissa, asetamme induktiivisia ennakkoluuloja, jotka kuvaavat alustakohtaista käyttäjän käyttäytymistä. Nämä ennakkoluulot yhdistettynä BERT:n hienosäätöön sosiaalisessa mediassa mahdollistavat paremman kielen ymmärtämisen, jolloin F1-pisteet ovat 58,7 SemEval 2019 -tehtävässä huhuasennon havaitsemisessa.', 'hy': 'Սոցիալական լրատվամիջոցների օգտագործման աճը դրել է այն լրատվամիջոցների տարածման և սպառության կենտրոնական դիրքում: Սա մեծապես բարձրացնում է լսարանների տարածման և սխալ տեղեկատվության պոտենցիալը: In an effort to mitigate the spread of rumours, we tackle the related task of identifying the stance (Support, Deny, Query, Comment) of a social media post.  Ի տարբերություն նախորդ աշխատանքներին, մենք պարտադրում ենք ինդուկտիվ կողմնականություններ, որոնք ընդունում են հարթակների կոնկրետ օգտագործողների վարքագիծը: These biases, coupled with social media fine-tuning of BERT allow for better language understanding, thus yielding an F1 score of 58.7 on the SemEval 2019 task on rumour stance detection.', 'bs': 'Povećanje korištenja društvenih medija ga je stavio u centralnu poziciju za raspršivanje i potrošnju vijesti. To veoma povećava potencijal proširenja glasina i pogrešne informacije. U pokušaju smanjiti širenje glasina, riješimo povezan zadatak identifikacije stanja (Podrška, odbijanje, pitanje, komentar) post a društvenih medija. Za razliku od prethodnih radova, stavljamo induktivne predrasude koje uhvate specifično ponašanje korisnika platforme. Ove predrasude, zajedno sa finaliziranjem socijalnih medija BERT-a, omogućavaju bolje razumijevanje jezika, tako dajući F1 rezultat od 58,7 na zadatku semiEval 2019 o otkrivanju glasina stanja.', 'jv': 'Deweke ono nganggep sistem sing media sotisan dumadhi iki dadi ono wektu nggawe diunganggo perusahaan kanggo nggawe barang alam lan ijol-ijolan. iki lakusun duwé nggawe kapan kanggo ngilanggar rumuran lan ngono nggawe barang-barang. Nanging masalah kanggo nggawe Kebebasan pangan anyar tentang rumuran, kita nggawe nggawe gerakan kanggo ngilangno nggunakake kapan (Tuderan, Deny, query, Komentar) sing dimulai media sotiki. Gak dhéwé éntuk sistem sing digawe, kita isih ingkang biasane soko nggawe sistem sing nyimpen pengguna nggawe biases sing diputamong karo media sokului nggawe barang kelas luwih nggawe BERT perusahaan kanggo langkung sapa luwih apik, dadi sing nyimpen roti F1 sing kok ukutu limangatus 587.7 karo semebal 2011 sak atake sing rumor nggawe gerakan', 'ha': "Kikaci da ake amfani da mitandai na jamii ya sanya ta a tsakiyar matabbaci ga fassar da abubuwa. Wannan yana ƙara mataimaki wa koritar faɗin ƙarya da information na ƙarya. Ko da ya yi aikin ka sauƙa ƙara ga faɗi ga rumors, Munã taciyar da aikin da za'a gane na halin (Taimako, Dakata, Kyaure, Kwamfyuta). @ info: whatsthis Wannan taɓallun, aka haɗa na mitandai da jamii sune-tuning of BERT don ya yarda da mafiya amfani da harshen, sabõda haka yana ƙara wata F1 score na 58.7 kan aikin Semeval 2019 kan gannai na rumor.", 'he': 'הגידול בשימוש בתקשורת החברתית הפך אותה למיקום מרכזי להפיצה וחשמלת חדשות. זה מגביר באופן גדול את הפוטנציאל להפיצה של שמועות ומידע לא נכון. במאמץ להקל את התפשטות השמועות, אנחנו מתמודדים עם המשימה הקשורה לזהות את עמדה (תמיכה, כחשה, בקשה, תגובה) של פוסט מדיה חברתית. בניגוד לעבודות הקודמות, אנו מכריחים חיונים מעוררים שמתפסיקים התנהגות של משתמשים ספציפית בפלטפורמה. ההתמחות האלה, יחד עם התיקון של התקשורת החברתית של BERT מאפשרים להבין שפה טובה יותר, ולכן נותנים נקודת F1 של 58.7 על המשימה SemEval 2019 על זיהוי עמדת השמועות.', 'sk': 'Naraščanje uporabe družbenih medijev jih je postavilo v osrednji položaj za širjenje in potrošnjo novic. To močno povečuje možnost širjenja govoric in napačnih informacij. V prizadevanjih za ublažitev širjenja govoric se lotimo s tem povezane naloge prepoznavanja stališča (podpora, zanikanje, poizvedba, komentar) objave na družbenih omrežjih. Za razliko od prejšnjih del uvajamo induktivne pristranskosti, ki zajemajo platformo specifično vedenje uporabnikov. Te pristranskosti, skupaj z natančnim nastavitvijo BERT na družbenih omrežjih, omogočajo boljše razumevanje jezika in tako dosegajo rezultat F1 58,7 na nalogi SemEval 2019 o odkrivanju položaja govoric.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བ་ལ་ཡར་རྒྱས་བཞིན་པའི་ལག་ལེན་འཐབ་ལམ་དེ་གསར་འགོད་བཤད་དང་གསུམ་སྟོན་པའི་གནས་ཡུལ་ཅ འདིས་དཀྲོག་གཏམ་འཆར་དང་འགྱུར་བ་གཉིས་ཀྱི་རྐྱེན་སྐྱེན་ཚད་ཆེ་ཤོས་ཏུ་ཆེ་རུ་གཏོང་ཡོད། འུ་ཅག་གིས་དཀྲོག་གཏམ་གླེང་འཚོལ་བའི་ཐབས་ལམ་དུ་གཏོང་བྱེད་རྒྱུ་དང་། ང་ཚོས་གནས་བཤད་འདི་ངོས་འཛིན་གྱི་ལས་འགན་སྤྱིར་བཏང་བ་རེད། སྔོན་གྱི་ལས་འགན་དང་མི་འདྲ་བ། ང་ཚོས་ལག་ལེན་པ་དམིགས་བསལ་བྱེད་པའི་ངོ་བོ དབྱིབས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བ་དང་མཉམ་དུ་བཏོན་གཏོང་ནི་BERT ཡི་གྲངས་ཤེས་ཀྱི་སྐོར་དང་།'}
{'en': 'IITKGP at W-NUT 2020 Shared Task-1 : Domain specific BERT representation for Named Entity Recognition of lab protocol IITKGP  at  W - NUT  2020 Shared Task-1: Domain specific  BERT  representation for Named Entity Recognition of lab protocol', 'ar': 'IITKGP في W-NUT 2020 Shared Task-1: تمثيل BERT الخاص بالمجال للتعرف على الكيان المحدد لبروتوكول المختبر', 'es': 'IITKGP en la Tarea Compartida 1 de W-NUT 2020: Representación BERT específica del dominio para el reconocimiento de entidades nombradas del protocolo de laboratorio', 'fr': "IITKGP au W-NUT 2020 Shared Task-1\xa0: Représentation BERT spécifique au domaine pour la reconnaissance d'entités nommées du protocole de laboratoire", 'pt': 'IITKGP no W-NUT 2020 Shared Task-1: Representação BERT específica do domínio para reconhecimento de entidade nomeada do protocolo de laboratório', 'ja': 'W - NUT 2020のIITKGP共有タスク-1 ：ラボプロトコルの名前付きエンティティ認識のためのドメイン固有のBERT表現', 'zh': 'IITKGP 于 W-NUT 2020 共事-1:以实验室协议名实识之域特定 BERT 示', 'ru': 'IITKGP на W-NUT 2020 Shared Task-1: Доменное представление BERT для распознавания именованных сущностей лабораторного протокола', 'hi': 'W-NUT 2020 में IITKGP साझा कार्य -1: डोमेन विशिष्ट BERT प्रतिनिधित्व नामित इकाई प्रयोगशाला प्रोटोकॉल की पहचान के लिए', 'ga': 'IITKGP ag W-NUT 2020 Tasc Comhroinnte-1: Ionadaíocht BERT sainiúil don fhearann le haghaidh Aitheantas Aonán Ainmnithe ar phrótacal saotharlainne', 'hu': 'IITKGP a W-NUT 2020 Megosztott feladat-1: Tartományspecifikus BERT-reprezentáció a laboratóriumi protokoll nevezett entitások felismeréséhez', 'el': 'Κοινή εργασία-1: Αντιπροσωπεία ειδικού τομέα για αναγνώριση ονομαστικής οντότητας του εργαστηριακού πρωτοκόλλου', 'ka': 'IITKGP W-NUT 2020 გაყოფილი დავალება-1: პროტოკოლის სახელსახულებული ელემენტის განაცნობისთვის დომენის განსაკუთრებული BERT რესპეცენტაცია', 'lt': 'IITKGP W-NUT 2020 bendra užduotis – 1. Specialus BERT atstovavimas valdžiai, skirtas laboratorinio protokolo pavadinimui pripažinti', 'it': 'IITKGP al W-NUT 2020 Shared Task-1: Rappresentazione BERT specifica del dominio per il riconoscimento di entità nominate del protocollo di laboratorio', 'kk': 'IITKGP W- NUT 2020 ортақтастырылған тапсырма- 1: лаборатория протоколының аталған нысандарын анықтау үшін доменге BERT белгісі', 'mk': 'IITKGP на W-NUT 2020 споделена задача-1: специфична претстава на домен BERT за препознавање на лабораториски протокол на именуван ентитет', 'ms': 'IITKGP pada W-NUT 2020 Tugas Berkongsi-1: Perwakilan BERT spesifik domain untuk Pengenalan Entiti bernama protokol makmal', 'mt': 'IITKGP fil-W-NUT 2020 Kompitu Konġunt-1: Rappreżentazzjoni speċifika għall-qasam tal-BERT għar-Rikonoxximent tal-Entità Ismija tal-protokoll tal-laboratorju', 'ml': 'W-NUT 2020-ല്\u200d പങ്കുചേര്\u200dത്ത ടാസ്ക്- 1: ലാബ് പേരിലെ പ്രതിനിധിയ്ക്കുള്ള ഡൊമെയിന്\u200d പ്രത്യേക ബെര്\u200dടി പ്രതിനിധികള്\u200d', 'mn': 'IITKGP at W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of Lab Protocol', 'no': 'IITKGP på W-NUT 2020 Delt oppgåve-1: Domene-spesifikke BERT-representasjon for namnet Entity Recognition of Lab Protocol', 'ro': 'IITKGP la W-NUT 2020 Shared Task-1: Reprezentarea BERT specifică domeniului pentru recunoașterea entității denumite a protocolului de laborator', 'pl': 'IITKGP na W-NUT 2020 Shared Task-1: Reprezentacja BERT specyficzna dla domeny dla rozpoznawania podmiotów nazwanych protokołu laboratoryjnego', 'sr': 'IITKGP na W-NUT 2020 podeljenom zadatku-1: predstavljanje specijalnog domena BERT za prepoznavanje imenovanih subjekta laboratorijskog protokola', 'so': 'IITKGP at W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of lab protocol', 'sv': 'IITKGP vid W-NUT 2020 Delad uppgift-1: Domänsspecifik BERT-representation för identifiering av namngivna enheter av labbprotokoll', 'si': 'IITKGP at W-NAT 2020shared Job-1: Domain', 'ta': 'W- NUT 2020 ல் பிரித்த பணி- 1: தளம் குறிப்பிட்ட பிரெட் பிரிட் குறிப்பிட்ட பகிர்ந்தளிப்பு', 'ur': 'W-NUT 2020 میں IITKGP شریک ٹاکس-1: ڈومین مخصوص BERT روشنی لاب پروٹوکول کے نام کی اینٹیٹی شناسایی کے لئے', 'uz': 'IITKGP at W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of lab protocol', 'vi': 'Tập tin chung IITKGP ở W-ni 2020 sẻ Nhiệm vụ-1: đặc trưng cho miền giao dịch BERT cho Named Entity recognition of lab giao thức', 'bg': 'Споделена задача-1: Представителство на конкретно за домейна BERT за разпознаване на лабораторен протокол на име лице', 'da': 'IITKGP ved W-NUT 2020 Delt opgave-1: Domænespecifik BERT-repræsentation for anerkendelse af navngivet enhed af laboratorieprotokol', 'hr': 'IITKGP na W-NUT 2020. zajedničkom zadatku-1: predstavljanje određenog domena BERT za prepoznavanje imenovanih podataka laboratorijskog protokola', 'nl': 'IITKGP op W-NUT 2020 Gedeelde Taak-1: Domeinspecifieke BERT-representatie voor Named Entity Recognition of Lab Protocol', 'id': 'IITKGP di W-NUT 2020 Shared Task-1: Domain spesifik BERT representation for Named Entity Recognition of lab protocol', 'de': 'IITKGP auf der W-NUT 2020 Shared Task-1: Domänenspezifische BERT-Darstellung zur Erkennung benannter Entitäten von Laborprotokollen', 'fa': 'IITKGP در W-NUT 2020', 'ko': 'W-NUT 2020의 IITKGP 공유 작업-1: 랩 프로토콜 명명 실체 식별 영역별 BERT 표시', 'sw': 'IITKGP kwenye W-NUT 2020 ilishiriki kazi-1: uwakilishi maalum wa BERT kwa ajili ya Tamko la Tambulisho la lab', 'af': 'IITKGP by W- NUT 2020 Gedeelde Opdrag- 1: Domein spesifieke BERT-voorstelling vir genoem Entiteit herken van laboratorie protokol', 'tr': 'IITKGP at W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of lab protocol', 'sq': 'IITKGP në W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of laboratory protocol', 'am': 'IITKGP at W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of lab protocol', 'hy': 'IITKGP-ը W-NOT 2020-ի ընդհանուր առաջադրանքում-1. բեռի մասնավոր BER-ի ներկայացումը լաբորատոկոլային պրոտոկոլի անվանումների ճանաչման համար', 'az': "W-NUT 2020 paylaşılan Task-1'də IITKGP: Laboratuar protokolünün Adlı Entity Recognition üçün Domain specific BERT representation", 'bn': 'ডোমেনের বিশেষ বিবেরেট প্রতিনিধিত্বের জন্য নামের এন্টিটি স্বীকৃতি ল্যাব প্রোটোকলের জন্য', 'ca': "IITKGP a W-NUT 2020 Task-1 compartida: Representació específica del domini BERT per a la reconeixement d'entitats anomenades del protocol de laboratori", 'cs': 'IITKGP na W-NUT 2020 Sdílený úkol-1: Doménově specifická reprezentace BERT pro rozpoznávání pojmenovaných entit laboratorního protokolu', 'et': 'IITKGP W-NUT 2020 jagatud ülesanne 1: domeenispetsiifiline BERT esindus nimetatud üksuste laboriprotokolli tunnustamiseks', 'bs': 'IITKGP na W-NUT 2020 zajedničkom zadatku-1: predstavljanje specijalnog domena BERT za prepoznavanje imenovanog subjekta laboratorijskog protokola', 'fi': 'IITKGP W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of lab protocol', 'jv': 'IIBKGGGP at W-NUT 2020 shared task-1: domain special BERT representation for Named Entty Learning of Lab Protokol', 'sk': 'IITKGP na W-NUT 2020 Shared Task-1: Zastopanje BERT za domeno specifično prepoznavanje imenovanih subjektov laboratorijskega protokola', 'he': 'IITKGP ב-W-NUT 2020 משימה משותפת-1: מייצג BERT ספציפי תחום', 'ha': 'KCharselect unicode block name', 'bo': 'IITKGP at W-NUT 2020 Shared Task-1: Domain specific BERT representation for Named Entity Recognition of lab protocol'}
{'en': 'Supervised models trained to predict properties from representations have been achieving high accuracy on a variety of tasks. For in-stance, the BERT family seems to work exceptionally well on the downstream task from NER tagging to the range of other linguistictasks. But the vocabulary used in the  medical field  contains a lot of different tokens used only in the  medical industry  such as the name of different diseases, devices, organisms, medicines, etc. that makes it difficult for traditional BERT model to create contextualized embedding. In this paper, we are going to illustrate the  System  for Named Entity Tagging based on Bio-Bert. Experimental results show that our  model  gives substantial improvements over the baseline and stood the fourth runner up in terms of  F1 score , and first runner up in terms of  Recall  with just 2.21  F1 score  behind the best one.', 'ar': 'لقد حققت النماذج الخاضعة للإشراف المدربة على التنبؤ بالخصائص من التمثيلات دقة عالية في مجموعة متنوعة من المهام. بالنسبة للموقف ، يبدو أن عائلة BERT تعمل جيدًا بشكل استثنائي في المهمة النهائية من وضع علامات NER إلى مجموعة المهام اللغوية الأخرى. لكن المفردات المستخدمة في المجال الطبي تحتوي على الكثير من الرموز المختلفة المستخدمة فقط في الصناعة الطبية مثل أسماء الأمراض المختلفة ، والأجهزة ، والكائنات الحية ، والأدوية ، وما إلى ذلك ، مما يجعل من الصعب على نموذج BERT التقليدي إنشاء التضمين السياقي. في هذه الورقة ، سنقوم بتوضيح نظام وضع علامات على الكيانات المحددة بالاعتماد على Bio-Bert. تظهر النتائج التجريبية أن نموذجنا يقدم تحسينات كبيرة على خط الأساس ويحتل المرتبة الرابعة من حيث درجة F1 ، والوصيف الأول من حيث Recall برصيد 2.21 F1 فقط خلف الأفضل.', 'pt': 'Modelos supervisionados treinados para prever propriedades a partir de representações vêm alcançando alta precisão em uma variedade de tarefas. Por exemplo, a família BERT parece funcionar excepcionalmente bem na tarefa posterior, desde a marcação de NER até a variedade de outras tarefas linguísticas. Mas o vocabulário usado na área médica contém muitos tokens diferentes usados apenas na indústria médica, como o nome de diferentes doenças, dispositivos, organismos, medicamentos, etc., o que torna difícil para o modelo BERT tradicional criar uma incorporação contextualizada. Neste artigo, vamos ilustrar o Sistema de Marcação de Entidades Nomeadas baseado em Bio-Bert. Os resultados experimentais mostram que nosso modelo oferece melhorias substanciais em relação à linha de base e ficou em quarto lugar em termos de pontuação na F1 e em primeiro em termos de Recall com apenas 2,21 pontos na F1 atrás do melhor.', 'fr': "Les modèles supervisés formés pour prédire les propriétés à partir de représentations ont atteint une grande précision sur une variété de tâches. Par exemple, la famille BERT semble fonctionner exceptionnellement bien sur la tâche en aval, du marquage NER à la gamme d'autres tâches linguistiques. Mais le vocabulaire utilisé dans le domaine médical contient de nombreux jetons différents utilisés uniquement dans l'industrie médicale, tels que le nom de différentes maladies, appareils, organismes, médicaments, etc., ce qui rend difficile pour le modèle BERT traditionnel de créer une intégration contextualisée. Dans cet article, nous allons illustrer le système de marquage des entités nommées basé sur Bio-Bert. Les résultats expérimentaux montrent que notre modèle apporte des améliorations substantielles par rapport à la base de référence et se classe quatrième en termes de score F1, et premier deuxième en termes de rappel avec seulement 2,21 points F1 derrière le meilleur score.", 'es': 'Los modelos supervisados entrenados para predecir propiedades a partir de representaciones han logrado una alta precisión en una variedad de tareas. Por ejemplo, la familia BERT parece funcionar excepcionalmente bien en las tareas posteriores, desde el etiquetado de NER hasta la gama de otras tareas lingüísticas. Pero el vocabulario utilizado en el campo médico contiene muchos símbolos diferentes que solo se usan en la industria médica, como el nombre de diferentes enfermedades, dispositivos, organismos, medicamentos, etc., que dificultan que el modelo BERT tradicional cree incrustaciones contextualizadas. En este artículo, vamos a ilustrar el Sistema de Etiquetado de Entidades Nombradas basado en Bio-Bert. Los resultados experimentales muestran que nuestro modelo ofrece mejoras sustanciales con respecto a la línea de base y fue el cuarto finalista en términos de puntuación de F1, y el primer finalista en términos de Recall con solo 2.21 puntos de F1 por detrás del mejor.', 'ja': '表現から性質を予測するために訓練された監督モデルは、さまざまなタスクで高い精度を達成しています。スタンスのために、BERTファミリーは、NERタグ付けから他の言語学的タスクの範囲までの下流タスクで非常にうまく機能しているようです。しかし、医療分野で使用される語彙には、さまざまな疾患、デバイス、生物、医薬品などの名前など、医療業界でのみ使用されるさまざまなトークンが多く含まれており、従来のBERTモデルが文脈化された埋め込みを作成することを困難にしています。本稿では、Bio - Bertに基づく命名実体タグ付けシステムを例示する。実験結果は、当社のモデルがベースラインを大幅に改善し、F 1スコアでは4番目に立ち、リコールでは1番目に立ち上がったランナーであり、最高のものよりわずか2.21 F 1スコアが遅れていることを示しています。', 'ru': 'Контролируемые модели, обученные предсказывать свойства из представлений, достигают высокой точности в различных задачах. Для конкретной ситуации, семейство BERT, кажется, работает исключительно хорошо над задачей ниже по потоку от NER-тегирования до диапазона других лингвистических задач. Но словарный запас, используемый в медицинской области, содержит много различных токенов, используемых только в медицинской отрасли, таких как название различных заболеваний, устройств, организмов,лекарств и т. д., что затрудняет создание традиционной модели БЕРТА контекстуализированного встраивания. В этой статье мы собираемся проиллюстрировать Систему присвоения меток именованным сущностям на основе Bio-Bert. Экспериментальные результаты показывают, что наша модель дает существенные улучшения по сравнению с базовой линией и заняла четвертое место по показателю F1 и первое место по показателю Recall с всего лишь 2,21 баллами F1 за лучшим.', 'hi': 'अभ्यावेदन से गुणों की भविष्यवाणी करने के लिए प्रशिक्षित पर्यवेक्षित मॉडल विभिन्न प्रकार के कार्यों पर उच्च सटीकता प्राप्त कर रहे हैं। इन-रुख के लिए, BERT परिवार एनईआर टैगिंग से अन्य भाषाई कार्यों की सीमा तक डाउनस्ट्रीम कार्य पर असाधारण रूप से अच्छी तरह से काम करता है। लेकिन चिकित्सा क्षेत्र में उपयोग की जाने वाली शब्दावली में केवल चिकित्सा उद्योग में उपयोग किए जाने वाले कई अलग-अलग टोकन शामिल हैं जैसे कि विभिन्न बीमारियों, उपकरणों, जीवों, दवाओं, आदि का नाम जो पारंपरिक BERT मॉडल के लिए प्रासंगिक एम्बेडिंग बनाने के लिए मुश्किल बनाता है। इस पत्र में, हम बायो-बर्ट के आधार पर नामित एंटिटी टैगिंग के लिए सिस्टम को स्पष्ट करने जा रहे हैं। प्रयोगात्मक परिणामों से पता चलता है कि हमारा मॉडल बेसलाइन पर पर्याप्त सुधार देता है और एफ 1 स्कोर के मामले में चौथे रनर अप पर खड़ा था, और सर्वश्रेष्ठ के पीछे सिर्फ 2.21 एफ 1 स्कोर के साथ रिकॉल के मामले में पहली रनर अप था।', 'zh': '训练以制图表监形于百务高精度。 立而言之,BERT系列似从NER表及他言下事甚善。 然医域之词汇,多包异志,疾病设备,生物体药之名,故古之BERT,难为上下文化嵌。 本文者,Bio-Bert名实体也。 实验结果表明,吾形比基线有实质性改进,于F1得分第四,于召还第一,以2.21 F1得分后第一。', 'ga': 'Tá ardchruinneas á bhaint amach ag múnlaí maoirsithe atá oilte chun airíonna ó léiriúcháin a thuar ar thascanna éagsúla. Mar sin féin, is cosúil go n-oibríonn teaghlach BERT go han-mhaith ar an tasc iartheachtacha ó chlibeáil NER go dtí an raon tascanna teanga eile. Ach tá an stór focal a úsáidtear sa réimse leighis go leor comharthaí éagsúla a úsáidtear ach amháin sa tionscal leighis ar nós ainmneacha na galair éagsúla, feistí, orgánaigh, leigheasanna, etc. a fhágann go bhfuil sé deacair do shamhail traidisiúnta BERT leabú comhthéacsúla a chruthú. Sa pháipéar seo, táimid chun an Córas um Chlibeáil Aonáin Ainmnithe a léiriú bunaithe ar Bith-Bert. Léiríonn torthaí turgnamhacha go dtugann ár múnla feabhsuithe suntasacha thar an mbunlíne agus sheas sé an ceathrú háit i dtéarmaí scór F1, agus an chéad dara háit i dtéarmaí Athghairm le díreach 2.21 scór F1 taobh thiar den cheann is fearr.', 'ka': 'ნაბლძეებული მოდელები, რომლებიც განაკეთებულია განსაზღვრებისთვის განსაზღვრებისთვის, უფრო დიდი წარმოდგენა რამდენიმე საქმედებისთვის. BERT-ის ოჯახი გამოიყურება გამოსაკუთრებით კარგად მუშაობს NER-დან სხვა ლენგურისტიკური დავალებებისგან. მაგრამ მედიცინური ფერში გამოყენებული სიტყვებულია აქვს ძალიან განსხვავებული სიტყვებულები, როგორც განსხვავებული დაავადებების სახელი, მოწყობილობების სახელი, ორგანიზმინტები, მედიცინტებების განმავლობაში, რაც განსაზ ამ დოკუნში ჩვენ ვილურსოთ სისტემის სახელსახულებული ინტერტიკის მაგრამად ბიო-ბერტის ბაზეში. ექსპერიმენტიური წარმოდგენა, რომ ჩვენი მოდელი იქნება მნიშვნელოვანი წარმოდგენების შესაძლებლობა და F1 წარმოდგენების შესაძლებლობად მეოთხედი წარმოდგენების შესაძლებლობა და პირველი წარმოდგენელი წარმოდ', 'hu': 'A reprezentációk tulajdonságainak előrejelzésére képzett felügyelt modellek nagy pontosságot értek el a különböző feladatokban. A BERT család kivételesen jól működik a NER-címkézéstől kezdve az egyéb nyelvi feladatokig. De az orvosi területen használt szókincs sok különböző tokent tartalmaz, amelyeket csak az orvosi iparban használnak, mint például különböző betegségek, eszközök, organizmusok, gyógyszerek stb. nevét, ami megnehezíti a hagyományos BERT modell számára kontextuális beágyazás létrehozását. Ebben a tanulmányban bemutatjuk a Bio-Bert alapú elnevezett entitáscímkézési rendszert. A kísérleti eredmények azt mutatják, hogy modellünk jelentős javulást eredményez a kiinduláshoz képest, és a negyedik helyen állt az F1 pontszám tekintetében, és az első helyen a Recall pontszám tekintetében, mindössze 2,21 F1 pontszám mögött.', 'el': 'Τα εποπτευόμενα μοντέλα εκπαιδευμένα για την πρόβλεψη ιδιοτήτων από αναπαραστάσεις έχουν επιτύχει υψηλή ακρίβεια σε μια ποικιλία εργασιών. Για το λόγο αυτό, η οικογένεια BERT φαίνεται να λειτουργεί εξαιρετικά καλά στο καθήκον που ακολουθεί από την επισήμανση NER έως το εύρος άλλων γλωσσικών εργασιών. Αλλά το λεξιλόγιο που χρησιμοποιείται στον ιατρικό τομέα περιέχει πολλά διαφορετικά σήματα που χρησιμοποιούνται μόνο στην ιατρική βιομηχανία, όπως το όνομα διαφορετικών ασθενειών, συσκευών, οργανισμών, φαρμάκων, κ.λπ., που καθιστά δύσκολο για το παραδοσιακό μοντέλο να δημιουργήσει ενσωμάτωση στο πλαίσιο. Σε αυτή την εργασία, πρόκειται να απεικονίσουμε το σύστημα σήμανσης Οντότητας με βάση το Bio-Bert. Τα πειραματικά αποτελέσματα δείχνουν ότι το μοντέλο μας δίνει σημαντικές βελτιώσεις σε σχέση με τη βάση και στάθηκε ο τέταρτος δεύτερος από την άποψη της βαθμολογίας F1, και ο πρώτος δεύτερος από την άποψη της ανάκλησης με μόλις 2.21 βαθμολογία πίσω από το καλύτερο.', 'it': "I modelli supervisionati formati per prevedere le proprietà dalle rappresentazioni hanno raggiunto un'elevata precisione su una varietà di compiti. La famiglia BERT sembra funzionare eccezionalmente bene nell'attività a valle, dalla marcatura NER alla gamma di altre attività linguistiche. Ma il vocabolario utilizzato in campo medico contiene molti token diversi utilizzati solo nell'industria medica come il nome di diverse malattie, dispositivi, organismi, farmaci, ecc. che rendono difficile per il modello BERT tradizionale creare embedding contestualizzato. In questo articolo illustreremo il Sistema di Etichettatura delle Entità Nomate basato su Bio-Bert. I risultati sperimentali mostrano che il nostro modello offre miglioramenti sostanziali rispetto alla linea di base e ha ottenuto il quarto posto in termini di punteggio F1, e il primo secondo in termini di Recall con appena 2,21 punti F1 dietro il migliore.", 'kk': 'Қасиеттерді таңдау үшін бақылау үлгілері бірнеше тапсырмалардың дұрыстығын жеткізеді. Бірақ BERT отбасы NER тапсырмасынан басқа лингвистикалық тапсырмалардың арасында өте жақсы жұмыс істейді. Бірақ медицина өрісінде қолданылатын сөздік тек медицина индустриясында, мысалы, түрлі аурулар, құрылғылар, организм, медицина және т.д. атауының атауы, әдетті BERT үлгісінде тәртіпті ендіру үшін қиын болады. Бұл қағазда Био-Берт негізінде аталған нысандар тегтерінің жүйесін көрсетеді. Эксперименталдық нәтижелері біздің моделіміздің негізгі жолда көп жақсартылығын көрсетеді, төртіншісін F1 нәтижелеріне қарап, бірінші қайталау үшін 2,21 F1 нәтижелерінің артындағы нәтижелерін көрсетеді.', 'mk': 'Supervised models trained to predict properties from representations have been achieving high accuracy on a variety of tasks. For in-stance, the BERT family seems to work exceptionally well on the downstream task from NER tagging to the range of other linguistictasks.  Но, речникот кој се користи во медицинското поле содржи многу различни знаци кои се користат само во медицинската индустрија, како што е името на различни болести, уреди, организми, лекови итн. што им овозможува на традиционалниот модел БЕРТ да создадат контекстуално вградување. Во овој весник, ќе го илустрираме системот за означување на именувани ентитети базиран на Био-Берт. Експерименталните резултати покажуваат дека нашиот модел дава значителни подобрувања во однос на почетокот и стана четвртиот трчач во поглед на оценката F1, и првиот трчач во поглед на Recall со само 2,21 оценка F1 зад најдобриот.', 'lt': 'Supervised models trained to predict properties from representations have been achieving high accuracy on a variety of tasks. Atsižvelgiant į tai, atrodo, kad BERT šeima išskirtinai gerai atlieka tolesnę užduotį – nuo NER žymėjimo iki kitų kalbinių užduočių. Tačiau medicinos srityje naudojamame žodyne yra daug skirtingų ženklų, naudojamų tik medicinos pramonėje, pavyzdžiui, skirtingų ligų, prietaisų, organizmų, vaistų ir t. t. pavadinimas, dėl kurio tradiciniam BERT modeliui sunku sukurti kontekstinį įterpimą. Šiame dokumente parodysime Bio-Bert pagrindu pagrįstą pavadintų subjektų ženklinimo sistemą. Eksperimentiniai rezultatai rodo, kad mūsų modelis gerokai pagerina pradinį rodiklį ir buvo ketvirtasis runner iki F1, o pirmasis runner iki Recall su tik 2,21 F1 balais už geriausią.', 'ms': 'Model yang diawasi dilatih untuk meramalkan ciri-ciri dari perwakilan telah mencapai ketepatan tinggi pada pelbagai tugas. For in-stance, the BERT family seems to work exceptionally well on the downstream task from NER tagging to the range of other linguistictasks.  But the vocabulary used in the medical field contains a lot of different tokens used only in the medical industry such as the name of different diseases, devices, organisms,medicines, etc. that makes it difficult for traditional BERT model to create contextualized embedding.  Dalam kertas ini, kita akan memperlihatkan Sistem Tagging Entiti bernama berdasarkan Bio-Bert. Hasil percubaan menunjukkan bahawa model kita memberikan peningkatan yang besar atas dasar dasar dan berdiri pelari keempat atas dalam terma skor F1, dan pelari pertama dalam terma Recall dengan hanya skor 2.21 F1 di belakang yang terbaik.', 'ml': 'പ്രതിനിധികളില്\u200d നിന്നുള്ള വ്യവസ്ഥകള്\u200d പ്രവചിപ്പിക്കാന്\u200d പരിശീലിക്കപ്പെട്ട മോഡലുകള്\u200d വ്യത്യസ്തമായ ജോലികളില്\u200d ഉ സ്ഥിതിയില്\u200d, ബെര്\u200dട്ടി കുടുംബത്തിന് വ്യക്തിപരമായി പ്രവര്\u200dത്തിക്കുന്നത് നെആര്\u200d ടാഗ്ഗിങ്ങില്\u200d നിന്നും മറ്റു ഭാഷക്കാരുടെ പര പക്ഷെ മെഡിക്കല്\u200d ഫീള്\u200dഡില്\u200d ഉപയോഗിക്കുന്ന വാക്കുകള്\u200d മാത്രമേ വ്യത്യസ്ത അടയാളങ്ങള്\u200d ഉള്ളുള്ളൂ. വ്യത്യസ്ത രോഗങ്ങളുടെയും ഉപകരണങ്ങളുടെയും ഉള്ളില്\u200d മാത്രമേ ഉപയോഗിക്കുന് ഈ പത്രത്തില്\u200d, ബിയോ ബെര്\u200dട്ടിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d പേരിട്ട എന്റിറ്റി ടാഗിങ്ങിന്റെ സിസ്റ്റം നമ്മള്\u200d വിവ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നത് നമ്മുടെ മോഡല്\u200d ബെസ്ലൈനില്\u200d വലിയ മെച്ചപ്പെടുത്തുന്നതാണെന്നും, F1 സ്കോര്\u200dട്ടിന്\u200dറെ അടുത്ത് നാലാമത്തെ റൂണാര്\u200d നില്\u200d', 'mt': 'Supervised models trained to predict properties from representations have been achieving high accuracy on a variety of tasks. Għall-pożizzjoni attwali, il-familja BERT tidher li taħdem eċċezzjonalment tajjeb fuq il-kompitu downstream mit-tikkettar NER sal-firxa ta’ kompiti lingwistiċi oħra. Iżda l-vokabulari użat fil-qasam mediku fih ħafna tokens differenti użati biss fl-industrija medika bħall-isem ta’ mard, apparat, organiżmi, mediċini, eċċ. differenti li jagħmilha diffiċli għall-mudell tradizzjonali BERT biex jinħoloq inkorporazzjoni kuntestwalizzata. F’dan id-dokument, aħna se nippreżentaw is-Sistema għat-Tagging ta’ Entitajiet Ismija bbażata fuq il-Bio-Bert. Riżultati esperimentali juru li l-mudell tagħna jagħti titjib sostanzjali fuq il-linja bażi u kien ir-raba’ runner up f’termini ta’ punteġġ F1, u l-ewwel runner up f’termini ta’ Recall b’punteġġ F1 biss 2.21 wara l-aħjar.', 'mn': 'Холбоонуудын өөрчлөлтийг таамаглахад сургалтын удирдлагатай загварууд олон төрлийн даалгавар дээр өндөр тодорхойлдог. Түүнчлэн БЕРТ гэр бүл NER-ээс бусад хэлний үйл ажиллагаа хүртэл маш сайн ажилладаг мэт санагдаж байна. Гэхдээ эмнэлгийн салбарт хэрэглэгдсэн үг нь зөвхөн эмнэлгийн салбарт хэрэглэгддэг олон өөр тэмдэгт байдаг. Яг өөр өвчин, төхөөрөмж, организм, эмчилгээ, т.д. Энэ цаасан дээр Био-Берт дээр суурилсан нэрлэгдсэн бүтээгдэхүүний системийг харуулъя. Үүний туршилтын үр дүнд бидний загвар суурь шугам дээр суурь сайжруулж, F1 оноо дээр дөрвөн дагуулагч болсон бөгөөд эхний дагуулагч нь 2.21 F1 оноо хамгийн сайжруулагч байсан.', 'no': 'Overvakte modeller trengte for å foregå eigenskapar frå representasjonar har nådd høg nøyaktighet på mange oppgåver. I tilstanden ser det ut til at BERT-familien arbeider ekstra godt på nedstrekkoppgåva frå NER-merking til området av andre lingviske oppgåver. Men ordboka som brukar i medisinsk feltet inneheld mange ulike teikn som berre brukar i medisinsk industri, slik som namnet på ulike sykdommer, einingar, organismar, medisiner osv. som gjer det vanskeleg for tradisjonelle BERT-modellen å laga kontekstualisert innbygging. I denne papiret skal vi illustrare systemet for merking med namnet entitet basert på Bio-Bert. Eksperimentale resultat viser at modellen vår gjev substantielle forbedringar over baselinja og stad den fjerde køyrer opp i forhold til F1- poeng, og første køyrer opp i forhold til Recall med bare 2,21 F1- poeng bak den beste.', 'ro': 'Modelele supravegheate instruite pentru a prezice proprietățile din reprezentări au obținut o precizie ridicată pe o varietate de sarcini. În opinia sa, familia BERT pare să funcţioneze excepţional de bine la sarcina din aval, de la etichetarea NER la gama de alte sarcini lingvistice. Dar vocabularul folosit în domeniul medical conține o mulțime de jetoane diferite utilizate numai în industria medicală, cum ar fi numele diferitelor boli, dispozitive, organisme, medicamente, etc. care face dificilă pentru modelul tradițional BERT crearea de încorporare contextualizată. În această lucrare, vom ilustra sistemul de etichetare a entităților denumite bazat pe Bio-Bert. Rezultatele experimentale arată că modelul nostru oferă îmbunătățiri substanțiale față de bază și a fost al patrulea loc în ceea ce privește scorul F1 și primul loc în ceea ce privește Recall cu doar 2,21 punctaj F1 în spatele celui mai bun.', 'pl': 'Nadzorowane modele przeszkolone do przewidywania właściwości z reprezentacji osiągają wysoką dokładność w różnych zadaniach. W tej chwili rodzina BERT wydaje się wyjątkowo dobrze sprawdzać się w dalszych zadaniach, od tagowania NER do zakresu innych zadań językowych. Ale słownictwo używane w dziedzinie medycznej zawiera wiele różnych tokenów używanych tylko w branży medycznej, takich jak nazwa różnych chorób, urządzeń, organizmów, leków itp., co utrudnia tradycyjnemu modelowi BERT tworzenie kontekstowego osadzenia. W niniejszym artykule zamierzamy zilustrować system tagowania nazwanych podmiotów oparty na Bio-Bert. Wyniki eksperymentalne pokazują, że nasz model zapewnia znaczne ulepszenia w porównaniu z linią bazową i stał czwartym miejscem pod względem wyniku F1, a pierwszym drugim pod względem Recall z zaledwie 2,21 F1 wynikiem za najlepszym.', 'sr': 'Nadzorni modeli koji su obučeni za predviđanje vlasništva predstavljanja postigli su visoke tačnosti na raznim zadacima. U stanju, obitelj BERT izgleda izuzetno dobro radi na spuštanju zadatka od NER-a do niza drugih jezičkih zadataka. Međutim, rečnik koji se koristi na medicinskom polju sadrži mnogo različitih znakova koji se koristi samo u medicinskoj industriji kao što je ime različitih bolesti, uređaja, organizacija, lekova i tako dalje, koji čini tradicionalnom modelu BERT-a teškom stvaranju kontekstualizacije. U ovom papiru, ilustrujemo sistem za označavanje imenovanih entiteta baziran na bioBertu. Eksperimentalni rezultati pokazuju da naš model daje značajne poboljšanje na početnoj liniji i stoji četvrti trkač u smislu F1 rezultata, a prvi trkač u smislu Sećanja sa samo 2,21 F1 rezultata iza najboljeg.', 'sv': 'Övervakade modeller som utbildats för att förutsäga egenskaper från representationer har uppnått hög noggrannhet i en mängd olika uppgifter. För närvarande verkar BERT-familjen fungera exceptionellt bra på uppgiften nedströms från NER-märkning till en rad andra språkuppgifter. Men ordförrådet som används inom det medicinska området innehåller en hel del olika tecken som används endast inom den medicinska industrin såsom namnet på olika sjukdomar, enheter, organismer, läkemedel etc. som gör det svårt för traditionell BERT-modell att skapa kontextualiserad inbäddning. I denna uppsats kommer vi att illustrera systemet för namnmärkt entitetsmärkning baserat på Bio-Bert. Experimentella resultat visar att vår modell ger betydande förbättringar jämfört med baslinjen och stod den fjärde tvåan när det gäller F1 poäng, och första tvåan när det gäller Recall med bara 2,21 F1 poäng efter den bästa.', 'so': 'Tusaalooyinka la ilaaliyey oo lagu baray in laga sii sheego hantidiisa laga soo jeedo, waxay gaadhay saxda aad u weyn oo shaqooyin kala duduwan. Waayo, marka lagu jiro, qoyska BERT wuxuu si gaar ah ugu muuqanayaa inay si fiican ugu shaqeeyaan shaqada hoose-hoose ee NER-ka tagista ilaa goobaha luuqadaha kale. Laakiin afka caafimaadka lagu isticmaalayo waxaa ku jira calaamooyin kala duduwan oo kaliya ee lagu isticmaali karo daryeelka caafimaadka, sida magaca cudurada kala duduwan, qalabka, dhakhtarka, tusaale ahaan waxaa ku adag in qaababka caadiga ah ee BERT lagu sameynayo qaab ka mid ah. Warqadan waxaan ku sawiraynaa nidaamka ganacsiga magaceeda lagu magacaabay Bio-Bert. Imtixaanka waxaa ka muuqda in modellkayagu uu bedeshay kororooyin aad u weyn sameynta saldhigga, wuxuuna istaagay kooxda afraad oo ku qoran scorka F1, marka ugu horeysana wuxuu ku qoray qiyaastii ku qoran 2.21 F1 xiliga ugu wanaagsan.', 'si': 'පිළිගන්න පුළුවන් විශේෂ විශේෂතාවන් ප්\u200dරධානය කරලා තියෙන්න පුළුවන් නිර්ධානය කරලා තියෙන්නේ ව ස්ථානයෙන්, BERT පවුලට පේන විශේෂයෙන් වැඩ කරන්න පුළුවන් වෙනවා NER ටැග් එකෙන් අනිත් භාෂාවික වැඩේ වලට. නමුත් වෛද්\u200dය ක්\u200dෂේත්රයේ භාවිත කරලා තියෙන්නේ වෙනස් ප්\u200dරතිචාරයක් විතරයි වෛද්\u200dය ව්\u200dයාපෘතියේ විතරයි, පරීක්ෂණය, ජීවිත, බෙද්ධිය, etc මේ පත්තරේ අපි බියෝබෝර්ට් වලින් නාමක් ඇන්තිත් ටැග්ග් පද්ධතිය පෙන්වන්න යන්නේ. පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ මොඩේල් එකේ ප්\u200dරතිශාල විශාල විස්තර දෙනවා වගේම F1 ස්කෝර් එකේ පස්සේ හතරවෙනි රුන්නර් එක්ක', 'ta': 'பிரதிநிதிகளில் இருந்து பண்புகளை முன்கூற பயிற்சி செய்யப்பட்ட மாதிரிகள் பல வேலைகளில் உயர் தெளிவாக பெறுகிறது. For in-stance, the BERT family seems to work exceptionally well on the downstream task from NER tagging to the range of other linguistictasks.  மருத்துவ புலத்தில் பயன்படுத்தப்படும் சொல்லொல்லை மருத்துவ திட்டத்தில் மட்டும் பயன்படுத்தப்பட்ட பல்வேறு குறிப்புகள் உள்ளன, வேறு நோய்கள், கருவி, உறுப்புகள், மருத்துவ ம் முறை இந்த காகிதத்தில், நாம் பெயர் பெயர் உள்ளீட்டு அடிப்படையில் அமைப்பை வரையலாம். முயற்சி முடிவுகள் அடிப்படைக்கோட்டில் எங்கள் மாதிரி பெரிய முன்னேற்றங்களை காட்டுகிறது மற்றும் F1 புள்ளியில் நான்காவது இயக்கியை நிற்கும், முதல', 'ur': 'نمائندوں سے ویژگی پیش بینی کے لئے آموزش کی جاری رکھی ہوئی نمائندے مختلف کاموں پر بالا دقیق پہنچ رہے ہیں. اس حالت میں، BERT کے خاندان کو اچھی طرح کام کرنا لگتا ہے کہ NER سے دوسرے زبان شناسی کاموں کی طرح ٹیگ کرنے سے نیچے نیچے کام پر اچھی طرح کام کرتا ہے۔ لیکن پزشکی میدان میں استعمال کئے جاتے ہیں بہت سی مختلف نشانیاں ہیں جو صرف پزشکی صنعت میں استعمال کئے جاتے ہیں جیسے مختلف بیماریوں، دستگاه، جسمانوں، داروئیں، اور اگلے، جن کے نام میں متوسط طریقے سے پیدا ہونے کے لئے سنتی BERT موڈل کے لئے مشکل ہے. اس کاغذ میں، ہم بیوی برت پر بنیاد رکھنے والی نامیدہ اینتیٹی ٹاگ کے سیستم کو دکھائیں گے۔ Experimental results show that our model provides substantial improvements over the baseline and stood up the fourth runner in terms of F1 score, and first runner in terms of Recall with just 2.21 F1 score behind the best one.', 'uz': "Tashkilotlardan foydalanilgan modellar turli vazifalarning xususiyatlarini koʻrsatish uchun o'rganilgan modellar turli vazifalarga juda foydalanadi. Shunday holatda, BERT oilasi oddiy holatda, NER yordamida boshqa tillar vazifalarining chegarasini o'zgartiradi. Lekin tibbiy soʻzda ishlatilgan so'zlar faqat tibbiy industrida ishlatilgan ko'p ko'p belgilar bor. Bu huddi boshqa kasalliklarning nomi, uskunalar, organismlar, madaniyalar va va o'tkazida ishlatilgan BERT modelini o'zgartirish qiyin qiladi. Bu takarda biz Bio-Bert asosida nomli tizim tizimini aniqlashni chiqaramiz. Tajriba natijalari esa modelimizning asosiy darajada katta yaxshi o'zgarishni ko'rsatadi va F1 scorning birinchi chegarasini ko'rsatadi va birinchi marta 2.21 F1 scori eng eng eng eng yaxshi chegaraga qarang.", 'vi': 'Các mô hình giám sát được huấn luyện để dự đoán các đặc tính từ các đài phát triển đã đạt độ chính xác cao trong nhiều nhiệm vụ. Trong trường hợp này, gia đình BERT dường như làm việc rất tốt trong lĩnh vực phía sau, từ môi trường chín đến các công việc ngôn ngữ khác. Nhưng từ điển được sử dụng trong lĩnh vực y học chứa rất nhiều vật thể khác nhau chỉ được sử dụng trong ngành y như tên của bệnh tật khác nhau, thiết bị, sinh vật, thuốc, v.v. làm cho mô hình nền BERT truyền thống khó tạo nên sự tác nhân tình hình. Trong bài báo này, chúng tôi sẽ làm minh họa về Hệ thống thống thống được gọi là Entity Tagsing dựa trên Bio-Bert. Kết quả thí nghiệm cho thấy mô hình của chúng ta có những cải tiến đáng kể trên đường cơ sở và đứng lên lần thứ tư có ghi điểm F1, và chạy thứ nhất theo thuật toán Recall với chỉ 2.21 F1 ghi điểm đằng sau điểm số tốt nhất.', 'hr': 'Nadzorni modeli obučeni za predviđanje vlasništva predstavljanja postigli su visoke preciznosti na raznim zadatkima. U stanju, obitelj BERT izgleda izuzetno dobro radi na donjem zadatku od NER-a do niza drugih jezičkih zadataka. Međutim, riječnik koji se koristi na medicinskom polju sadrži mnogo različitih znakova koji se koristi samo u medicinskoj industriji poput imena različitih bolesti, uređaja, organizacija, lijekova itd. koji čini tradicionalnom modelu BERT-a teškom stvoriti kontekstualizirani integraciju. U ovom papiru ćemo ilustrirati sistem za označavanje imenovanih entiteta na osnovu Bio-Berta. Eksperimentalni rezultati pokazuju da naš model daje značajne poboljšanje na početnoj liniji i stoji četvrti trkač u smislu F1 rezultata, a prvi trkač u smislu sjećanja s samo 2,21 F1 rezultata iza najboljeg.', 'nl': 'Onder toezicht staande modellen die getraind zijn om eigenschappen van representaties te voorspellen, hebben een hoge nauwkeurigheid bereikt bij een verscheidenheid van taken. In dit geval lijkt de BERT-familie uitzonderlijk goed te werken bij de downstream-taak van NER-tagging tot het bereik van andere taalkundige taken. Maar de woordenschat die wordt gebruikt in de medische sector bevat veel verschillende tokens die alleen worden gebruikt in de medische industrie, zoals de naam van verschillende ziekten, apparaten, organismen, medicijnen, enz. die het voor traditioneel BERT-model moeilijk maken om contextualiseerde embedding te creëren. In dit artikel gaan we het System for Named Entity Tagging op basis van Bio-Bert illustreren. Experimentele resultaten tonen aan dat ons model substantiële verbeteringen geeft ten opzichte van de baseline en de vierde tweede was in termen van F1 score, en eerste tweede in termen van Recall met slechts 2.21 F1 score achter de beste.', 'da': 'Overvågede modeller uddannet til at forudsige egenskaber fra repræsentationer har opnået høj nøjagtighed på en række opgaver. BERT-familien synes at fungere usædvanligt godt på efterstrømsopgaven fra NER-mærkning til en række andre sproglige opgaver. Men ordforrådet, der anvendes på det medicinske område, indeholder en masse forskellige tokens, der kun anvendes i den medicinske industri, såsom navnet på forskellige sygdomme, udstyr, organismer, medicin osv., der gør det vanskeligt for traditionel BERT model at skabe kontekstualiseret indlejring. I denne artikel vil vi illustrere systemet for navngivet enhedsmærkning baseret på Bio-Bert. Eksperimentelle resultater viser, at vores model giver betydelige forbedringer i forhold til baseline og stod den fjerde plads med hensyn til F1 score, og den første plads med hensyn til Recall med kun 2,21 F1 score bag den bedste.', 'bg': 'Надзорените модели, обучени да предсказват свойствата от представянето, постигат висока точност при различни задачи. По отношение на позицията, семейството BERT изглежда работи изключително добре по задачата надолу по веригата от маркирането NER до гамата от други лингвистични задачи. Но речникът, използван в медицинската област, съдържа много различни символи, използвани само в медицинската индустрия, като наименованието на различни заболявания, устройства, организми, лекарства и т.н., което затруднява традиционния модел да създаде контекстуализирано вграждане. В тази статия ще илюстрираме Системата за етикетиране на имена на субекти въз основа на Био-Бърт. Експерименталните резултати показват, че нашият модел дава значителни подобрения в сравнение с базовата линия и е бил на четвърто място по отношение на резултата от Формула 1 и на първо място по отношение на Реколт само с 2.21 Формула 1 след най-добрия.', 'de': 'Überwachte Modelle, die trainiert wurden, Eigenschaften aus Darstellungen vorherzusagen, haben eine hohe Genauigkeit bei einer Vielzahl von Aufgaben erreicht. Im Moment scheint die BERT-Familie bei der nachgelagerten Aufgabe von NER-Tagging bis hin zu anderen linguistischen Aufgaben außergewöhnlich gut zu funktionieren. Aber das Vokabular, das im medizinischen Bereich verwendet wird, enthält viele verschiedene Token, die nur in der medizinischen Industrie verwendet werden, wie den Namen verschiedener Krankheiten, Geräte, Organismen, Medikamente usw., die es dem traditionellen BERT-Modell erschweren, kontextualisierte Einbettungen zu erstellen. In diesem Beitrag werden wir das System for Named Entity Tagging basierend auf Bio-Bert illustrieren. Experimentelle Ergebnisse zeigen, dass unser Modell erhebliche Verbesserungen gegenüber der Baseline bietet und den vierten Platz in Bezug auf F1-Punktzahl und den ersten Platz in Bezug auf Recall mit nur 2,21 F1-Punktzahl hinter dem besten erreicht hat.', 'ko': '훈련을 거친 감독 모델은 표시에서 속성을 예측할 수 있어 각종 임무에서 높은 정밀도를 얻었다.입장에서 볼 때, 버트 가문은 NER 표기에서 다른 일련의 언어학 임무에 이르기까지의 하류 임무에서 유난히 뛰어난 모습을 보였다.그러나 의학 분야에서 사용하는 어휘에는 의료 업계에만 사용되는 다양한 표기, 예를 들어 질병, 설비, 생물체, 약물 등의 명칭이 많이 포함되어 있어 전통적인 버트 모델은 상하문에 삽입하기 어렵다.이 문서에서는 Bio-Bert 기반의 명명된 엔티티 태그 시스템을 시연합니다.실험 결과에 따르면 우리의 모델은 기준선보다 실질적으로 개선되었고 F1 성적은 4위, 회상 성적은 1위로 최고 성적인 2.21에 뒤떨어졌다.', 'sw': 'Mradi uliofanywa umefundishwa kutabiri utamaduni kutoka kwa uwakilishi umekuwa ukifikia ukweli mkubwa katika kazi mbalimbali. Kwa upande mwingine, familia ya BERT inaonekana kufanya kazi kwa kipekee katika kazi ya mto wa chini ya mitandao kutoka kwenye vifaa vya NER kwenda katika viwango vingine vya lugha. Lakini maneno yanayotumiwa kwenye uwanja wa afya in a ishara nyingi tofauti tu zinazotumiwa katika sekta ya afya kama vile jina la magonjwa tofauti, vifaa, vifaa, madawa, etc. ambavyo inafanya kuwa vigumu kwa mtindo wa kitamaduni wa BERT kutengeneza vifaa vinavyotumiwa. Katika gazeti hili, tutaonyesha Mfumo wa Ujumbe wa Jinai unaoitwa kwa msingi wa Bio-Bert. Matokeo ya majaribio yanaonyesha kuwa mtindo wetu unatoa maendeleo makubwa zaidi ya msingi na kusimama mstari wa nne kwa mujibu wa score ya F1, na kwa mara ya kwanza umepanda kwa mujibu wa Recall na score 2.21 F1 tu nyuma ya kipindi kilicho bora zaidi.', 'id': 'Model yang diawasi dilatih untuk memprediksi properti dari representation telah mencapai akurasi tinggi dalam berbagai tugas. Untuk dalam posisi, keluarga BERT tampaknya bekerja sangat baik pada tugas turun dari NER tagging ke jangkauan tugas bahasa lain. Tapi kata-kata yang digunakan dalam bidang medis mengandung banyak token yang berbeda yang digunakan hanya dalam industri medis seperti nama penyakit berbeda, perangkat, organisme, obat, dll. yang membuat sulit untuk model tradisional BERT untuk menciptakan embedding kontekstualisasi. Dalam kertas ini, kita akan menggambarkan Sistem Tagging Entitas bernama berdasarkan Bio-Bert. Hasil eksperimen menunjukkan bahwa model kami memberikan peningkatan yang besar atas dasar dasar dan berdiri runner keempat atas dalam terma skor F1, dan runner pertama dalam terma Recall dengan hanya 2,21 skor F1 di belakang yang terbaik.', 'fa': 'مدلهای تحت نظر آموزش آموزش داده شده برای پیش بینی از ویژگی\u200cهای نمایش\u200cکننده\u200cها دقیق بالا بر روی کارهای مختلف رسیده\u200cاند. در حالی که خانواده BERT به نظر می رسد که به طور خاصی در وظیفه پایین پایین از NER نشان دادن به مجموعه دیگر وظیفه\u200cهای زبان\u200cشناسی کار می\u200cکند. ولی کلمه\u200cای که در میدان پزشکی استفاده می\u200cشود، فقط در صنعت پزشکی، مثل نام بیماری\u200cهای مختلف، دستگاه\u200cها، ارگانیسم\u200cها، داروها و غیر از آن استفاده می\u200cشود، شامل تعدادی از نشانه\u200cهای مختلف است که برای مدل سنتی BERT سخت می\u200cشود تا ابتدایی در این کاغذ، می\u200cخواهیم سیستم برچسب\u200cهای نامیده بر اساس بیو-برت را نشان دهیم. نتیجه\u200cهای تجربه\u200cی ما نشان می\u200cدهد که مدل ما بر روی خط پایین بهبود\u200cهای زیادی می\u200cدهد و چهارم فرار را به عنوان امتیاز F1 بالا می\u200cبرد، و اولین فرار به عنوان یادآوری با فقط امتیاز 2.21 F1 پشت بهترین امتیاز بالا می\u200cرود.', 'tr': "Görnöşenlerden hasaplaryň önlemek üçin bilinen gözetli modeller birnäçe işiň derejesini başarmak üçin guruldy. Şol ýagdaýda, BERT maşgalasy NER'den iň aşak täbliklerinden başga dil täbliklerine çenli gowy işleýär. Emma lukmanyň sahypasynda ulanylan sözleriň diňe lukmanyň senagatynda ullanýan köp näçe işaretler bolsa, düzmekler, organizmalar, dermanlary we bölegi ýaly. Bu däpli BERT nusgasyna çaba düşürmek kyn edip bilýär. Bu kagyzda bioBert'a daýanýan Ady Etiketler sistemini görkezip berjek bolýarys Experimental netijelerimiz biziň modelimiz baseliniň üstünde möhüm gelişmeleri verir we dördündünji çarpyşymyz F1 nokady diýipdir we ilkinji çarpyşymyz 2.21 F1 nokady diýipdir.", 'sq': 'Supervised models trained to predict properties from representations have been achieving high accuracy on a variety of tasks. Për në qëndrim, familja BERT duket të punojë jashtëzakonisht mirë në detyrën poshtë rrjedhës nga etiketat NER në gamën e detyrave të tjera gjuhësore. But the vocabulary used in the medical field contains a lot of different tokens used only in the medical industry such as the name of different diseases, devices, organisms,medicines, etc. that makes it difficult for traditional BERT model to create contextualized embedding.  Në këtë letër, do të ilustrojmë Sistemin për Etiketimin e njësisë së quajtur bazuar në Bio-Bert. Rezultatet eksperimentale tregojnë se modeli ynë jep përmirësime thelbësore në lidhje me bazën dhe qëndroi i katërti i lartë në lidhje me rezultatin F1 dhe i pari i lartë në lidhje me Recall me vetëm 2.21 rezultat F1 pas rezultatit më të mirë.', 'af': "Ondersoekteerde modele wat opgelei is om eienskappe van voorstellings te voorskou het hoog presisie op 'n verskillende opdragte bereik. Vir in-staanse lyk die BERT familie uitsonderlik goed werk op die onderstreem taak van NER etiket tot die omvang van ander lingvistike taak. Maar die woordeboek wat in die mediese veld gebruik word bevat 'n baie verskillende tekens wat slegs gebruik word in die mediese industrie soos die naam van verskillende siektes, toestellings, organisasies, medikasies, ensfh. wat dit moeilik maak vir tradisionele BERT model om contextualiseerde inbêding te skep. In hierdie papier gaan ons die Stelsel vir genoem Entiteit-etiketting inlyk op Bio-Bert. Eksperimentale resultate wys dat ons model gee substantiele verbeteringe oor die basislien en staan die vierde hardlooper op in terms van F1 punt, en eerste hardlooper op in terms van Rekal met net 2.21 F1 punt agter die beste een.", 'am': 'Supervised models trained to predict properties from representations have been achieving high accuracy on a variety of tasks. በተመሳሳይ፣ የBERT ቤተሰብ ከNER መግለጫ ጀምሮ እስከ ሌሎቹ ቋንቋዎች ስራዎችን ለመቀላቀል በተለየ ውኃው ስራ ላይ በመልካም ይሠራል ይመስላል፡፡ ነገር ግን በጤና መሬት ውስጥ የሚጠቀሙት ቃላት በብዙ ተለያዩ ምልክቶች በጤና industry ውስጥ ብቻ የሚጠቀሙት ነው፤ እንደተለያዩ ደዌዎች፣ መሣሪያዎች፣ አካባቢዎች፣ መድኃኒቶች፣ አካባቢዎች እና ማህበረሰብ፣ የባሕላዊው BERT model በመፍጠር ይችላል፡፡ በዚህ ፕሮግራም፣ በቢ-ቤርት ላይ የተባለውን የስሜት Entity Tagging እናሳውቀዋለን፡፡ ፈተና ውጤቶች የሞዴላታችን መደበኛ ክፍተቶችን በመስመር ላይ ያሳያል፣ አራተኛውም ነጥብ F1 score በተደረገ ቁጥር ይቆማል፡፡', 'az': 'Görüntülərin özelliklərini təsdiqləmək üçün təhsil edilmiş gözətli modellər müxtəlif işlərdə yüksək doğruluğu başa düşdü. Əlbəttə, BERT ailəsi NER etiketindən başqa dil işlərinin səviyyəsinə qədər yaxşı işləyir. Lakin tıbbi sahədə istifadə edilən sözlər yalnız müxtəlif xəstələr, cihazlar, organizmalar, ilaçlar və bəzilərin adı kimi təhsil edilən təhsil modeli BERT modeli üçün çətin edir. Bu kağıtda bizim bioBert tabanlı Adlı Entity Tagging Sistemini göstərəcəyik. Experimental sonuçlarımız modellərimizin baseline üstündə çox yaxşılıqlarını verir və dördüncü f1 nöqtəsi olaraq F1 nöqtəsi ilə dördüncüsünün üstünə qaldırdığını göstərir və ilk fırlatıcı Recall nöqtəsi ilə 2.21 F1 nöqtəsi ən yaxşısının arxasında qaldı', 'bs': 'Praćeni modeli obučeni za predviđanje vlasništva predstavljanja ostvarili su visoke preciznosti na raznim zadatkima. U stanju, obitelj BERT izgleda izuzetno dobro radi na spuštanju zadatka od NER-a do niza drugih jezičkih zadataka. Međutim, rečnik koji se koristi na medicinskom polju sadrži mnogo različitih znakova koji se koristi samo u medicinskoj industriji, poput imena različitih bolesti, uređaja, organizacija, lekova itd., koji čini tradicionalnom modelu BERT-a teškom stvoriti kontekstualizirani integraciju. U ovom papiru ćemo ilustrirati sistem za označavanje imenovanih entiteta na osnovu Bio-Berta. Eksperimentalni rezultati pokazuju da naš model daje značajne poboljšanje na početnoj liniji i stoji četvrti trkač u smislu F1 rezultata, a prvi trkač u smislu Sećanja sa samo 2,21 F1 rezultata iza najboljeg.', 'bn': 'প্রতিনিধিত্বের বৈশিষ্ট্য ভবিষ্যদ্বাণী করার জন্য প্রশিক্ষণ প্রদান করা মডেল বিভিন্ন কাজের উপর বিভিন্ন সঠিক পরিস্থ স্থানে বিবেরেট পরিবার বিস্তারিত ভালোভাবে কাজ করছে নিউ আর ট্যাগিং থেকে অন্যান্য ভাষাভাষিক কাজ পর্যন্ত। কিন্তু চিকিৎসার ক্ষেত্রে ব্যবহৃত শব্দভাণ্ডারের মধ্যে শুধুমাত্র মেডিকেল শিল্পে বিভিন্ন প্রতীক রয়েছে, যেমন বিভিন্ন রোগ, যন্ত্র, প্রতিষ্ঠান, মেডিস ইত্যাদি ব্যবহ এই পত্রিকায় আমরা বিও-বার্টের ভিত্তিক নামের এন্টিটি ট্যাগিং এর সিস্টেমের বর্ণনা করব। পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের মডেলের বেস্ট লাইনের উপর বিশাল উন্নতি প্রদান করে এবং F1 স্কোরের মাধ্যমে চতুর্থ রানার দাঁড়িয়ে দাঁড়িয়েছে, আর প্রথম রিসো', 'hy': 'Հետևյալ մոդելները, որոնք վարժեցվել են ներկայացումների հատկությունների կանխատեսելու համար, բարձր ճշգրտություն են հասել բազմաթիվ առաջադրանքների համար: Ի դեպ, BERT ընտանիքը կարծես արտասովոր լավ աշխատում է հետագա խնդրի վրա, սկսած ՆԵՌ նշաններով մինչև այլ լեզվաբանական խնդիրներ: Բայց բժշկական ոլորտում օգտագործվող բառարանը շատ տարբեր նշաններ ունի, որոնք օգտագործվում են միայն բժշկական ոլորտում, ինչպիսիք են տարբեր հիվանդությունների, սարքերի, օրգանիզմների, դեղամիջոցների և այլն անունը, ինչը դժվարանում է ավանդական BER մոդելի համար ստեղ Այս թղթի մեջ մենք պատրաստվում ենք ներկայացնել Բիո-Բերթի վրա հիմնված անվանումների նշանների համակարգը: Փորձարկվող արդյունքները ցույց են տալիս, որ մեր մոդելը նշանակալի բարելավումներ է տալիս հիմնական հարաբերության մեջ և կանգնած է չորրորդ վազողը F1 գնահատականի տեսքով, և առաջին վազողը՝ Reկall-ի տեսքով, որն ունի միայն 2.21 F1 գնահատականի լա', 'ca': "Els models supervisats formats per predir propietats de representacions han estat aconseguint una gran precisió en una varietat de tasques. Per a estar en posició, la família BERT sembla treballar excepcionalment bé en la tasca downstream des d'etiquetar NER fins a la gama d'altres tasques lingüístices. Però el vocabulari utilitzat en el camp mèdic conté moltes fitxes diferents que només s'utilitzen en la indústria mèdica com el nom de diferents malalties, dispositius, organismes, medicaments, etc. que dificulta per al model tradicional BERT crear integració contextualitzada. En aquest article, il·lustrarem el Sistema d'Etiquetatge d'Entitats Nomades basat en Bio-Bert. Els resultats experimentals mostren que el nostre model dóna millores substancials sobre el punt de referència i va ser el quart corrent en termes de puntuació F1, i el primer corrent en termes de Recall amb només 2,21 puntuació F1 darrere del millor.", 'cs': 'Dohlížené modely trénované k předpovídání vlastností z reprezentací dosahují vysoké přesnosti při různých úkolech. V současnosti se zdá, že rodina BERT výjimečně dobře funguje na následném úkolu od značení NER až po řadu dalších jazykových úkolů. Avšak slovní zásoba používaná v lékařské oblasti obsahuje mnoho různých tokenů používaných pouze ve zdravotnickém průmyslu, jako je název různých onemocnění, prostředků, organismů, léků atd., což znemožňuje tradičnímu modelu BERT vytvořit kontextualizované vložení. V tomto článku budeme ilustrovat systém označování jmenovaných entit založený na Bio-Bertu. Experimentální výsledky ukazují, že náš model přináší výrazné zlepšení oproti základnímu základnímu bodu a stál čtvrtý druhý, pokud jde o skóre F1, a první druhý, co se týče Recall, s pouhým 2,21 F1 skóre za tím nejlepším.', 'et': 'Järelevalve all olevad mudelid, mis on koolitatud ennustama omadusi esitustest, on saavutanud suure täpsuse erinevates ülesannetes. Näib, et BERT-perekond töötab erakordselt hästi järgmise etapi ülesandega alates NER-i märgistamisest kuni teiste keeleliste ülesanneteni. Kuid meditsiinivaldkonnas kasutatav sõnavara sisaldab palju erinevaid märke, mida kasutatakse ainult meditsiinitööstuses, nagu erinevate haiguste, seadmete, organismide, ravimite jne nimetus, mis muudab traditsioonilisel BERT mudelil keeruliseks kontekstipõhise manustamise loomise. Selles töös illustreerime Bio-Bertil põhinevat nimeliste üksuste märgistamise süsteemi. Eksperimentaalsed tulemused näitavad, et meie mudel parandab oluliselt võrreldes lähtetasemega ning hoidis F1 skoori poolest neljanda teise ja Recalli poolest esimese teise koha, kusjuures kõigest 2,21 F1 skoori taga.', 'fi': 'Esiintymisten ominaisuuksien ennustamiseen koulutetut valvotut mallit ovat saavuttaneet suurta tarkkuutta erilaisissa tehtävissä. Työpaikan osalta BERT-perhe näyttää toimivan poikkeuksellisen hyvin loppupään tehtävässä NER-merkinnästä muihin kielitehtäviin. Mutta lääketieteen alalla käytetty sanasto sisältää paljon erilaisia merkkejä, joita käytetään vain lääketieteen alalla, kuten eri sairauksien, laitteiden, organismien, lääkkeiden jne. nimet, mikä tekee perinteisen BERT-mallin vaikeaksi luoda kontekstualisoitu upotus. Tässä artikkelissa aiomme havainnollistaa System for Named Entity Tagging perustuu Bio-Bertiin. Kokeelliset tulokset osoittavat, että mallimme paransi merkittävästi lähtötasoon verrattuna ja pysyi neljännellä sijalla F1-pisteissä ja ensimmäisellä sijalla Recall-pisteissä vain 2,21 F1-pisteellä parhaan jälkeen.', 'jv': 'Laptop" and "Desktop Er-wis ngerasakno, akeh BERT saiki wis nguasakno ngono nggawe barang terus neng BOR Pero pergambar sing dipunangé nêmên ing sakjané dibuténé, lan nganggep akeh gambaran anyar tentang kanggo ingkang dipunangé, gambar nganggo gambaran sak, perintah, lan nganggo sampeyan, lan. Nan pepul iki, kita lak garep ngomongke Sistem kanggo Ngawe Entité sing basa nang biyo-bert. Perintah sing paling-perintah wong ngomong nik model sing gawe lan akeh banter sing dumadhi iki dadi sing katêk batar tentang F1 baling, lan tambah sing susahe perusahaan tanggal sing katêpakan karo ;', 'sk': 'Nadzorovani modeli, usposobljeni za napovedovanje lastnosti iz reprezentacij, dosegajo visoko natančnost pri različnih nalogah. Zdi se, da družina BERT izjemno dobro opravlja nalogo na koncu toka od označevanja NER do razpona drugih jezikovnih nalog. Toda besednjak, ki se uporablja na medicinskem področju, vsebuje veliko različnih žetonov, ki se uporabljajo samo v medicinski industriji, kot so ime različnih bolezni, pripomočkov, organizmov, zdravil itd., zaradi česar tradicionalni BERT model težko ustvari kontekstualizirano vdelavo. V tem članku bomo ponazorili sistem označevanja imenovanih entitet, ki temelji na Bio-Bertu. Eksperimentalni rezultati kažejo, da naš model prinaša bistvene izboljšave v primerjavi z osnovno vrednostjo in je ostal četrti drugi v smislu rezultatov F1 in prvi drugi v smislu rekall s samo 2,21 rezultati F1 za najboljšim.', 'ha': "@ info: whatsthis Ga a bayan haka, Familin BERT na kasa yin aiki mai kyau a kan aikin na ƙarami daga NER zuwa cikin wasu littafan linguistic. Amma maganar da aka yi amfani da shi a cikin shawarar da za'a ƙunsa da wasu ãyõyi mãsu yawa waɗanda aka yi amfani da shi kawai a cikin shawarar dawada, kamar sunan maras dabam, kayan aiki, akan mutane, da hanyoyi da amfani da shi, kamar haka, ya sanya shi mai ƙunci a kan misalin BERT ya zama mai sauƙin ka sami da taƙaita. Ga wannan takardan, za mu bayyana shirin tsarin da aka suna Entity Taging a kan Bio-Bert. Matarin jarrabai na nuna cewa misalinmu yana samar da masu girma a ƙarƙashin basalin kuma yana tsaya na huɗu runner up cikin muhimman F1 score, kuma ta farkon ta tsẽre da takarda 2.21 F1 na baka ta fi kyauta.", 'he': 'מודלים משגיחים מאומנים לחזות תכונות ממציגות השיגו מדויקת גבוהה על מגוון משימות. משפחת BERT נראית לעבוד היטב באופן יוצא דופן על המשימה המאוחרת מ-NER תג לטווח של משימות שפתיות אחרות. אבל המילים שמשתמשים בשדה הרפואי מכילים הרבה סימנים שונים שמשתמשים רק בתעשיית הרפואה כמו שמו של מחלות שונות, מכשירים, אורגניזמים, תרופות, וכו"כ שמקשים לדוגמא BERT מסורתית ליצור תוכנית קונטוקטוליזציה. בעיתון הזה, אנחנו הולכים להדגים את המערכת לתגיות של איכות בשם מבוססת על ביו-ברט. תוצאות ניסויים מראות שהדוגמא שלנו נותנת שיפורים משמעותיים מעל הבסיס ועמדה לרוץ הרביעי במונחים של נקודת F1, ורוץ ראשון במונחים של Recall עם רק 2.21 נקודת F1 מאחורי הטוב ביותר.', 'bo': 'ལྟ་རྟོག་བྱས་པའི་མིག་དཔེ་གཟུགས་རིས་ངོ་བོའི་རྒྱུ་དངོས་རྟོགས་པ་ལས་མང་ཙམ་མང་པོ་ཞིག་ཏུ་འགྲོ་བཞིན་ཡོད། གནས་སྟངས་བཤད་ན། BERT ཡི་ནང་གི་བཟའ་ཚང་ནི་སྒྲིག་འགོད་ལས་ཕར་རིམ་གྱིས འོན་ཀྱང་། དབུལ ང་ཚོའི་ཤོག་བུ་འདིའི་ནང་དུ་མིང་བཏགས་པའི་ཨ་རིའི་ཁ་ཡིག་གི་རྣམ་གྲངས་སྒྲིག་བཀོད་སྲིད། Experimental results show that our model gives substantial improvement over the baseline and stood the fourth runner up in terms of F1 score, and first runner up in terms of Recall with just 2.21 F1 score behind the best one.'}
{'en': 'mgsohrab at WNUT 2020 Shared Task-1 : Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols WNUT  2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'ar': 'mgsohrab في WNUT 2020 Shared Task-1: النهج العصبي الشامل للتعرف على الكيان والعلاقة عبر بروتوكولات المختبر الرطب', 'es': 'mgsohrab en la Tarea Compartida 1 de WNUT 2020: Enfoque Neural Exhaustivo para el reconocimiento de entidades y relaciones sobre protocolos de laboratorio húmedo', 'pt': 'mgsohrab no WNUT 2020 Tarefa Compartilhada-1: Abordagem Neural Exaustiva para Reconhecimento de Entidade e Relação sobre Protocolos de Wet Lab', 'fr': "mgsohrab au WNUT 2020 Shared Task-1\xa0: Approche neurale exhaustive pour la reconnaissance d'entités et de relations sur des protocoles de laboratoire humide", 'ja': 'wNUT 2020 Shared Task -1でのmgsohrab ： Wet Labプロトコル上のエンティティと関係認識のためのニューラル網羅的アプローチ', 'ru': 'mgsohrab на совместном задании WNUT 2020-1: нейронный исчерпывающий подход к распознаванию сущностей и связей по протоколам влажных лабораторий', 'hi': 'WNUT 2020 में mgsohrab साझा कार्य -1: वेट लैब प्रोटोकॉल पर इकाई और संबंध मान्यता के लिए तंत्रिका संपूर्ण दृष्टिकोण', 'zh': 'mgsohrab在WNUT 2020共事-1:湿实验室议体识之神经穷举也', 'ga': 'mgsohrab ag WNUT 2020 Tasc Comhroinnte-1: Cur Chuige Néar Uileghabhálach maidir le hAithint Aonán agus Gaol thar Phrótacail Wet Lab', 'el': 'Κοινή εργασία-1: Νευρική εξαντλητική προσέγγιση για αναγνώριση οντοτήτων και σχέσεων πάνω από πρωτόκολλα υγρών εργαστηρίων', 'hu': 'mgsohrab a WNUT 2020 közös feladat-1: Neurális kimerítő megközelítés a szervezetek és a kapcsolatok felismerésére a nedves laboratóriumi protokollok felett', 'ka': 'mgsohrab WNUT 2020 გაყოფილი საქაღალდე-1: ნეირალური გამოყენებელი პროტოკოლების მიღება ინტერტის და შესახებ განაცნობისთვის', 'lt': 'mgsohrab pagal WNUT 2020 bendrą užduotį – 1: Neuralinis išmetamųjų teršalų metodas subjektams ir ryšiams pripažinti dėl drėgnų laboratorijų protokolų', 'mk': 'mgsohrab на заедничката задача-1 на ВНУТ 2020: Неурален експуштивен пристап за препознавање на ентитетите и врските преку протоколите на мокрите лаборатории', 'it': 'mgsohrab a WNUT 2020 Shared Task-1: Approccio Scaricante Neurale per il riconoscimento delle entità e delle relazioni sui protocolli di laboratorio bagnato', 'ms': 'mgsohrab di WNUT 2020 Task-1 Berkongsi: Pendekatan Penghabisan Neural untuk Pengenalan Entiti dan Hubungan melalui Protokol Lab Wet', 'kk': 'mgsohrab WNUT 2020 ортақтастырылған тапсырма-1: Нейрондық түсініс және қатынастарды түсініш протоколдарының қатынасы', 'mt': 'mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'pl': 'mgsohrab na WNUT 2020 Wspólne Zadanie-1: Neuronalne Wyczerpujące podejście do rozpoznawania podmiotów i relacji w protokołach laboratoryjnych', 'ml': 'WNUT 2020-ല്\u200d മിസോഹ്രാബ്: വെറ്റ് ലാബ് നിയമങ്ങള്\u200dക്കുള്ള പ്രോട്ടോക്കോളുകള്\u200dക്കുള്ള നെയുറല്\u200d എക്സുസ്റ്റിവ് വഴി', 'no': 'mgsohrab på WNUT 2020 Delt oppgåve-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'ro': 'mgsohrab la sarcina comună WNUT 2020-1: Abordare neurală de evacuare pentru recunoașterea entităților și relațiilor peste protocoalele de laborator umed', 'mn': 'mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'sr': 'mgsohrab na WNUT 2020. zajednièkom zadatku-1: Neuralni ekskluzivni pristup za priznanje entiteta i odnosa preko protokola u laboratoriji', 'so': 'mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relations Recognition Over Wet Lab Protocols', 'sv': 'mgsohrab vid WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocol', 'ta': 'WNUT 2020 ல் mgsohrab பகிர்ந்த பணி', 'si': 'mgsohrab at WNOT 2020shared Job-1: neural Exhaestive approach for Unitity and Attitude Known Over Wet Lab protocols', 'ur': 'Mgsohrab WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'uz': 'Gsohrab, WNUT 2020 bilan boʻlishilgan vazifa- 1: Uzunligi va bogʻlanishni tasdiqlash uchun Neural Uzunasi', 'vi': 'mgsoharb ở WGiờ 2020 sẻ Task-1: tiếp cận khí thải thần kinh cho các loài thực vật và tương quan nhận nhận qua các giao thức ẩm ướt', 'bg': 'Споделена задача-1: Невроден изчерпателен подход за разпознаване на същността и връзките чрез протоколи за мокри лаборатории', 'da': 'mgsohrab ved WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'nl': 'mgsohrab op WNUT 2020 Gedeelde Taak-1: Neurale Uitputtende Aanpak voor Entiteits- en Relatiebekendheid over Wet Lab Protocollen', 'hr': 'mgsohrab na WNUT 2020. zajedničkom zadatku-1: Neuralni ekskluzivni pristup za prepoznavanje područja i odnosa preko protokola u laboratoriji', 'de': 'mgsohrab auf der WNUT 2020 Gemeinsame Aufgabe-1: Neural erschöpfender Ansatz zur Entitäten- und Beziehungserkennung über Wet Lab Protokolle', 'fa': 'mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relationship Recognition Over Lab Wet Protocols', 'id': 'mgsohrab di WNUT 2020 shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols', 'ko': 'WNUT 2020의mgsohrab 공유 작업-1: 습기 실험실 프로토콜에서 실체와 관계 식별의 신경궁거 방법', 'sw': 'mgsohrab akiwa WNUT 2020 ilishiriki kazi-1: Utafiti wa Tamko wa Ujasiri na Kutambuliwa kwa Umoja wa Matukio ya Wet', 'tr': 'mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relationship Recognition Over Wet Lab Protocols', 'af': 'mgsohrab by WNUT 2020 Gedeelde Opdrag-1: Neural Exhaustive Approach for Entity and Relationship Recognition Over Wet Lab Protocols', 'sq': 'mgsohrab në WNUT 2020 Task-1: Approach Neural Exhaustive for Entity and Relation Recognition Over Wet Lab Protocols', 'am': 'mgsohrab በWNUT 2020 የተሰራጨው ስራ-1: የኔural Exhaustive Approach for Entity and Relation Recognition over Wet Lab Protocols', 'az': 'Mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relationship Recognition Over Wet Lab Protocols', 'bn': 'উইনউট ২০২০ সালের ম্যাসসোহরাব-১: উট ল্যাব প্রোটোকলের জন্য নিউরেল বেরিয়ে যাওয়া এবং সম্পর্ক স্বীকার করার জন্য নিউরেল বেরিয়ে এসেছে', 'bs': 'mgsohrab na WNUT 2020. zajedničkom zadatku-1: Neuralni ekskluzivni pristup za prepoznavanje područja i odnosa preko protokola u laboratoriji', 'ca': 'mgsohrab al WNUT 2020 Task-1 Compartit: Approach Neural Exhaustive for Entity and Relation Recognition Over Wet Lab Protocols', 'cs': 'mgsohrab na WNUT 2020 Sdílený úkol-1: Neurální vyčerpávající přístup k rozpoznávání entit a vztahů přes protokoly mokré laboratoře', 'et': 'mgsohrab WNUT 2020 ühisel ülesandel 1: neuroalne ammendav lähenemisviis olemuse ja suhte tuvastamiseks märgalabori protokollide üle', 'fi': 'mgsohrab WNUT 2020:n yhteisessä tehtävässä 1: Neuraalinen tyhjentävä lähestymistapa entiteetin ja suhteiden tunnistamiseen märän laboratorion protokollien avulla', 'hy': 'ԱՄՆ 2020-ի համագործակցած հանձնարարությունը (Mգսորաբ): Մարդկանց և հարաբերությունների ճանաչման նյարդային հոսանքային մոտեցումը թափուկ լաբորատոկոլների վերաբերյալ', 'jv': 'mgsOhrab nang WNUT 2020 Gebah Taaks-1: Neral ex hal-kowe Atosbah kanggo Entité lan RelationAtosbah Owe Lab Protokols', 'ha': 'Program name', 'sk': 'mgsohrab na skupni nalogi WNUT 2020 – 1: nevralni izčrpni pristop za prepoznavanje subjektov in odnosov prek protokolov mokrega laboratorija', 'he': 'mgsohrab ב-WNUT 2020 משימה משותפת-1: גישה נוירולית גוששת לזהות יחסים יחסים על פרוטוקולים מעבדה רטובה', 'bo': 'mgsohrab at WNUT 2020 Shared Task-1: Neural Exhaustive Approach for Entity and Relation Recognition Over Wet Lab Protocols'}
{'en': 'We present a neural exhaustive approach that addresses named entity recognition (NER) and relation recognition (RE), for the entity and re- lation recognition over the wet-lab protocols shared task. We introduce BERT-based neural exhaustive approach that enumerates all pos- sible spans as potential entity mentions and classifies them into entity types or no entity with deep neural networks to address NER. To solve relation extraction task, based on the NER predictions or given gold mentions we create all possible trigger-argument pairs and classify them into relation types or no relation. In NER task, we achieved 76.60 % in terms of  F-score  as third rank system among the partic- ipated systems. In relation extraction task, we achieved 80.46 % in terms of  F-score  as the top system in the relation extraction or recognition task. Besides we compare our model based on the wet lab protocols corpus (WLPC) with the WLPC baseline and dynamic graph-based in- formation extraction (DyGIE) systems.', 'ar': 'نقدم نهجًا عصبيًا شاملاً يتناول التعرف على الكيانات المسماة (NER) والتعرف على العلاقة (RE) ، من أجل التعرف على الكيان والعلاقة عبر المهمة المشتركة لبروتوكولات المعمل الرطب. نقدم نهجًا عصبيًا شاملاً قائمًا على BERT والذي يعدد جميع النطاقات الممكنة كما يذكرها الكيان المحتمل ويصنفها إلى أنواع كيانات أو لا يوجد كيان به شبكات عصبية عميقة لمعالجة NER. لحل مهمة استخراج العلاقة ، بناءً على تنبؤات NER أو إشارات الذهب المعطاة ، نقوم بإنشاء جميع أزواج الزناد والحجج الممكنة وتصنيفها إلى أنواع علاقة أو لا علاقة لها. في مهمة NER ، حققنا 76.60٪ من حيث الدرجة F كنظام من المرتبة الثالثة بين الأنظمة المشاركة. فيما يتعلق بمهمة استخراج العلاقة ، حققنا 80.46٪ من حيث درجة F كنظام أعلى في مهمة استخراج العلاقة أو التعرف عليها. إلى جانب ذلك ، نقارن نموذجنا بناءً على مجموعة بروتوكولات المختبر الرطب (WLPC) مع خط الأساس WLPC وأنظمة استخراج المعلومات المستندة إلى الرسم البياني الديناميكي (DyGIE).', 'pt': 'Apresentamos uma abordagem neural exaustiva que aborda o reconhecimento de entidade nomeada (NER) e o reconhecimento de relação (RE), para a tarefa compartilhada de reconhecimento de entidade e relação sobre os protocolos de laboratório úmido. Introduzimos uma abordagem exaustiva neural baseada em BERT que enumera todos os possíveis spans como menções de entidades potenciais e os classifica em tipos de entidade ou nenhuma entidade com redes neurais profundas para endereçar NER. Para resolver a tarefa de extração de relação, com base nas previsões do NER ou nas menções de ouro, criamos todos os possíveis pares de argumentos-gatilho e os classificamos em tipos de relação ou sem relação. Na tarefa NER, alcançamos 76,60% em termos de F-score como sistema de terceira classificação entre os sistemas participantes. Na tarefa de extração de relação, alcançamos 80,46% em termos de F-score como o melhor sistema na tarefa de extração ou reconhecimento de relação. Além disso, comparamos nosso modelo baseado no corpus de protocolos de laboratório úmido (WLPC) com os sistemas de linha de base WLPC e extração de informações baseada em grafos dinâmicos (DyGIE).', 'fr': "Nous présentons une approche neuronale exhaustive qui aborde la reconnaissance d'entité nommée (NER) et la reconnaissance de relation (RE), pour la reconnaissance d'entité et de relation sur la tâche partagée des protocoles de laboratoire humide. Nous introduisons une approche neuronale exhaustive basée sur BERT qui énumère toutes les portées possibles en tant que mentions d'entités potentielles et les classe en types d'entités ou aucune entité avec des réseaux neuronaux profonds pour traiter le NER. Pour résoudre la tâche d'extraction de relation, sur la base des prédictions NER ou des mentions Gold données, nous créons toutes les paires déclencheur-argument possibles et les classons en types de relation ou en aucune relation. Dans la tâche NER, nous avons atteint 76,60\xa0% en termes de score F en tant que système de troisième rang parmi les systèmes participants. Dans la tâche d'extraction de relations, nous avons atteint 80,46\xa0% en termes de score F en tant que système supérieur dans la tâche d'extraction ou de reconnaissance de relations. En outre, nous comparons notre modèle basé sur le corpus de protocoles de laboratoire humide (WLPC) avec les systèmes de base WLPC et d'extraction d'informations basées sur des graphes dynamiques (DyGie).", 'es': 'Presentamos un enfoque neuronal exhaustivo que aborda el reconocimiento de entidades nombradas (NER) y el reconocimiento de relaciones (RE), para la tarea compartida de reconocimiento de entidades y relaciones a través de los protocolos de laboratorio húmedo. Presentamos un enfoque neuronal exhaustivo basado en BERT que enumera todos los tramos posibles como posibles menciones de entidades y los clasifica en tipos de entidad o ninguna entidad con redes neuronales profundas para abordar la NER. Para resolver la tarea de extracción de relaciones, en función de las predicciones de NER o las menciones de oro dadas, creamos todos los pares disparador-argumento posibles y los clasificamos en tipos de relación o sin relación. En la tarea NER, logramos un 76,60% en términos de puntuación F como sistema de tercer rango entre los sistemas participantes. En la tarea de extracción de relaciones, logramos un 80,46% en términos de puntuación F como el sistema superior en la tarea de extracción o reconocimiento de relaciones. Además, comparamos nuestro modelo basado en el corpus de protocolos de laboratorio húmedo (WLPC) con los sistemas de base WLPC y extracción de información basada en gráficos dinámicos (DyGIE).', 'ja': '私たちは、名前付きエンティティ認識（ NER ）と関係認識（ RE ）に対処するニューラルな包括的アプローチを提示します。私たちは、潜在的な実体が言及しているように、すべての可能性のあるスパンを列挙し、それらを実体の種類またはNERに対処する深いニューラルネットワークを持つ実体に分類するBERTベースの神経網羅的アプローチを導入します。関係抽出タスクを解決するために、NER予測または与えられたゴールドメンションに基づいて、すべての可能なトリガー-引数ペアを作成し、関係タイプまたは関係なしに分類します。NERタスクでは、粒子依存システムの中で3番目のランクシステムとしてFスコアで76.60%を達成した。リレーショナル抽出タスクでは、リレーショナル抽出または認識タスクのトップシステムとしてFスコアで80.46%を達成しました。さらに、私たちは、ウェットラボプロトコルコーパス（ WLPC ）に基づくモデルを、WLPCベースラインおよびダイナミックグラフベースのフォーメーション抽出（ DyGIE ）システムと比較します。', 'zh': '臣等建一神经穷举之法,当解名实(NER)识(RE),以实体湿实验室协议共任者更定义。 引入BERT之神经穷举,枚举其跨度,以其类无深度神经网络以决NER也。 为治者,NER占给定之黄金,创有可发参数对,以类为无关系。 NER之任,吾F分为76.60%,在分区第三。 取任者,F得分至80.46%也;取知者,至统也。 又湿实验室协议语料库(WLPC)与WLPC基线基于动态图地(DyGIE)系统较之。', 'ru': 'Мы представляем нейронный исчерпывающий подход, который рассматривает распознавание именованных сущностей (NER) и распознавание отношений (RE) для распознавания сущностей и реляций по общей задаче протоколов мокрой лаборатории. Мы вводим основанный на BERT нейронный исчерпывающий подход, который перечисляет все возможные диапазоны как потенциальные упоминания сущностей и классифицирует их по типам сущностей или отсутствие сущностей с глубокими нейронными сетями для решения NER. Чтобы решить задачу извлечения отношения, на основе предсказаний NER или заданных золотых упоминаний мы создаем все возможные пары триггер-аргумент и классифицируем их по типам отношения или по отсутствию отношения. В задаче NER мы достигли 76,60% с точки зрения F-балла как системы третьего ранга среди отдельных систем. В отношении задачи экстракции мы достигли 80,46% с точки зрения F-показателя в качестве верхней системы в задаче экстракции или распознавания отношений. Кроме того, мы сравниваем нашу модель, основанную на корпусе протоколов влажных лабораторий (WLPC), с базовой линией WLPC и системами динамического извлечения на основе графов (DyGIE).', 'hi': 'हम एक तंत्रिका संपूर्ण दृष्टिकोण प्रस्तुत करते हैं जो इकाई मान्यता (एनईआर) और संबंध मान्यता (आरई) नामक को संबोधित करता है, इकाई के लिए और गीले-प्रयोगशाला प्रोटोकॉल साझा कार्य पर पुन: lation मान्यता। हम BERT-आधारित तंत्रिका संपूर्ण दृष्टिकोण का परिचय देते हैं जो संभावित इकाई के रूप में सभी pos-sible spans की गणना करता है और उन्हें इकाई प्रकारों में वर्गीकृत करता है या एनईआर को संबोधित करने के लिए गहरे तंत्रिका नेटवर्क के साथ कोई इकाई नहीं है। संबंध निष्कर्षण कार्य को हल करने के लिए, एनईआर भविष्यवाणियों या दिए गए सोने के उल्लेख के आधार पर हम सभी संभव ट्रिगर-तर्क जोड़े बनाते हैं और उन्हें संबंध प्रकार या कोई संबंध नहीं में वर्गीकृत करते हैं। एनईआर कार्य में, हमने पार्टिक-इपेटेड सिस्टम के बीच तीसरे रैंक सिस्टम के रूप में एफ-स्कोर के मामले में 76.60% हासिल किया। संबंध निष्कर्षण कार्य में, हमने संबंध निष्कर्षण या मान्यता कार्य में शीर्ष प्रणाली के रूप में एफ-स्कोर के संदर्भ में 80.46% हासिल किया। इसके अलावा हम गीले प्रयोगशाला प्रोटोकॉल कॉर्पस (WLPC) के आधार पर हमारे मॉडल की तुलना WLPC बेसलाइन और गतिशील ग्राफ-आधारित इन-फॉर्मेशन निष्कर्षण (DyGIE) सिस्टम के साथ करते हैं।', 'ga': 'Cuirimid cur chuige uileghabhálach néarach i láthair a théann i ngleic le haitheantas aonáin ainmnithe (NER) agus aithint caidrimh (RE), don aonán agus aitheantas gaol thar an tasc roinnte prótacail saotharlainne fliuch. Tugaimid isteach cur chuige uileghabhálach néarach atá bunaithe ar BERT a áiríonn gach réimse féideartha de réir mar a luann aonán ionchasach agus a rangaíonn iad i gcineálacha aonáin nó gan aon eintiteas le líonraí néaracha domhain chun aghaidh a thabhairt ar NER. Chun tasc eastósctha gaol a réiteach, bunaithe ar thuar NER nó ar lua óir a thugtar dúinn cruthaímid gach péire féideartha truicear-argóinte agus déanaimid iad a rangú i gcineálacha gaoil nó gan gaol. I dtasc NER, bhaineamar amach 76.60% i dtéarmaí scór-F mar chóras tríú céim i measc na gcóras rannpháirtíoch. Maidir le tasc eastósctha, bhaineamar 80.46% amach i dtéarmaí scór-F mar an córas is airde sa tasc asbhainte nó aitheantais. Chomh maith leis sin déanaimid comparáid idir ár múnla atá bunaithe ar chorpas na bprótacal saotharlainne fliuch (WLPC) agus bunlíne WLPC agus córais dinimiciúla eastósctha faisnéise bunaithe ar ghraif (DyGIE).', 'ka': 'ჩვენ აჩვენებთ ნეიროლური გამოსრულებული პროტიქტის მისამართება, რომელიც მისამართებული ინტერტის განაცნობა (NER) და პროტიქტის განაცნობა (RE), ინტერტის და განაცნობისთვის განაცნობისთვის, რო ჩვენ ვიყენებთ BERT-ის განსაზღვრებული ნეიროლური გასრულებელი პროგრამა, რომელიც ყველა პოსტაციალური გასრულებელი გასრულებულია როგორც პოსტაციალური ინტერტიკის განსაზღვრებულია და კლასიფიკა შესაძლებელია გამოყენება საქაღალდეების გარეშე, NER პროგრამებისთვის ან მოგვეყენებული დოლანეების განსაზღვრებისთვის, ჩვენ ყველა შესაძლებელი გამოყენება არგემენტის ზოგის შექ NER დავალებაში, ჩვენ F-score-ის განმავლობაში 76.60%-ს მივიღეთ, როგორც მესამე წერტილის სისტემის განმავლობაში. შესახებ ექსტრექციის დავალებაში, ჩვენ მივიღეთ 80,46% F-score-ის შესახებ როგორც უფრო მეტი სისტემის შესახებ ექსტრექციის ან განაცნობის დავალებაში. დამატებით ჩვენი მოდელის დამატებით, როპორტოკოლობის კოპორტოკოლოს (WLPC) დაბაზიან WLPC ფესური და დინამიკური გრაფიკის დაბაზიან ინფორმაციის ექსტრაქცია (DyGIE) სისტემებით.', 'it': "Presentiamo un approccio neurale esaustivo che affronta il riconoscimento delle entità denominate (NER) e il riconoscimento delle relazioni (RE), per il riconoscimento delle entità e della ri- lazione sui protocolli wet-lab condivisi. Introduciamo un approccio neurale esaustivo basato su BERT che enumera tutte le possibili distanze come entità potenziale cita e li classifica in tipi di entità o nessuna entità con reti neurali profonde per affrontare NER. Per risolvere il compito di estrazione delle relazioni, sulla base delle predizioni NER o delle menzioni auree date creiamo tutte le possibili coppie trigger-argomenti e le classifichiamo in tipi di relazione o nessuna relazione. Nel compito NER, abbiamo raggiunto il 76,60% in termini di F-score come sistema di terzo rango tra i sistemi participati. Nel compito di estrazione delle relazioni, abbiamo raggiunto l'80,46% in termini di F-score come sistema superiore nel compito di estrazione o riconoscimento delle relazioni. Inoltre confrontiamo il nostro modello basato sul corpo dei protocolli di laboratorio bagnato (WLPC) con i sistemi WLPC baseline e Dynamic Graph-based in- formation extraction (DyGIE).", 'kk': 'Біз нысандарды анықтау (NER) және қатынасын анықтау (RE) деп аталатын невралдық толық тәртібін көрсетедік. Осы нысандарды жалғыз лабораториялық протоколдар ортақтастырылған тапсырманы қайта анықтау үшін. Біз BERT негіздеген невралды толық тәжірибесін келтіреміз. Бұл барлық потенциалдық мәселелерді жазып, оларды НЕР адресіне түсіру үшін невралдық желілердің түрлеріне немесе түсінікті невралдық желі NER қатынасын тарқату тапсырмасын шешу үшін немесе келтірілген алтын тапсырмасының негізінде барлық жегілетін аргументтің екісін құрып, оларды қатынасыз түрлеріне не қатынасыз болмайды. NER тапсырмасында, F- нөмірі үшінші жолдар жүйесінде 76,60% жеткіздік. Шығыстыру тапсырмасына қатынау тапсырмасы бойынша, F- score қатынау немесе қатынау тапсырмасының жоғарғы жүйесі ретінде 80,46% жеткіздік. Біз өзіміздің моделімізді өмір лабораториялық протоколдарының корпус (WLPC) негізінде WLPC негізгі және динамикалық графикалық түрлендіру (DyGIE) жүйелерімен салыстырамыз.', 'hu': 'Egy neurális kimerítő megközelítést mutatunk be, amely az entitás felismerésére (NER) és a kapcsolatfelismerésre (RE) vonatkozik a nedves laboratóriumi protokollok közös feladatában. Bevezetjük a BERT alapú neurális kimerítő megközelítést, amely felsorolja az összes lehetséges tartományt, ahogy a potenciális entitás említi és osztályozza őket entitástípusokba, vagy nincs entitás mély neurális hálózattal rendelkező entitás a NER-hez. A kapcsolatkivonási feladat megoldásához a NER előrejelzések vagy adott arany említések alapján létrehozzuk az összes lehetséges trigger-argumentum párt és kapcsolattípusokra vagy semmilyen kapcsolatra osztályozzuk őket. A NER feladatban 76,60%-ot értünk el az F pontszám tekintetében, mint harmadik rangú rendszer a résztvevő rendszerek között. A relatív extrakciós feladat tekintetében 80,46%-ot értünk el az F pontszám tekintetében, mint a legjobb rendszer a relatív extrakciós vagy felismerési feladatban. Ezen kívül összehasonlítjuk a nedves laboratóriumi protokollokra épülő modellünket (WLPC) a WLPC alapvető és dinamikus gráf alapú in-formation extraction (DyGIE) rendszerekkel.', 'el': 'Παρουσιάζουμε μια νευρωνική εξαντλητική προσέγγιση που ασχολείται με την αναγνώριση ονομαστών οντοτήτων (ΝΕR) και την αναγνώριση σχέσεων (RE), για την αναγνώριση οντότητας και επανάστασης μέσω των κοινών πρωτοκόλλων υγρών εργαστηρίων. Εισάγουμε τη βασισμένη στο BERT νευρωνική εξαντλητική προσέγγιση που απαριθμεί όλες τις πιθανές περιοχές καθώς η δυνητική οντότητα αναφέρει και τις ταξινομεί σε τύπους οντοτήτων ή καμία οντότητα με βαθιά νευρωνικά δίκτυα για την αντιμετώπιση του NER. Για την επίλυση της εργασίας εξαγωγής σχέσεων, με βάση τις προβλέψεις ή τις δοσμένες χρυσές αναφορές δημιουργούμε όλα τα πιθανά ζεύγη ενεργοποίησης-ορίσματος και τα ταξινομούμε σε τύπους σχέσεων ή καμία σχέση. Στο έργο της NER, πετύχαμε 76.60% από την άποψη του F-σκορ ως τρίτου βαθμού μεταξύ των συμμετεχόντων συστημάτων. Σε σχέση με την εργασία εξαγωγής, πετύχαμε 80.46% από την άποψη της βαθμολογίας ως το κορυφαίο σύστημα στην εργασία εξαγωγής ή αναγνώρισης σχέσης. Παράλληλα συγκρίνουμε το μοντέλο μας με βάση το σώμα πρωτοκόλλων υγρών εργαστηρίων (με τα συστήματα βάσης και δυναμικής εξαγωγής σχηματισμού με βάση γραφήματα.', 'mk': 'We present a neural exhaustive approach that addresses named entity recognition (NER) and relation recognition (RE), for the entity and re- lation recognition over the wet-lab protocols shared task.  Ние воведуваме нервен експлозивен пристап базиран на БЕРТ кој ги нумерира сите позиционални растојанија како што потенцијалниот ентитет ги споменува и ги класификува во типови на ентитети или ниту еден ентитет со длабоки нервни мрежи за да се обраќа За да ја решиме задачата за извлекување на врските, базирана на предвидувањата на НЕР или дадени златни спомени ние создаваме сите можни парови на активирачки аргументи и ги класификуваме во типови на врски или без врска. Во NER задачата, постигнавме 76,60 отсто во однос на F-оценката како трет ранг систем помеѓу системите кои учествуваат. Во однос на задачата за извлекување, постигнавме 80,46 отсто во однос на F-оценката како врвен систем во задачата за извлекување или препознавање на односите. Покрај тоа го споредуваме нашиот модел базиран на мокрите лабораториски протоколи корпус (WLPC) со основните системи на WLPC и динамичните графички системи за екстракција во формација (DyGIE).', 'ml': 'സാധാരണ തിരിച്ചറിയുന്നതിനും ബന്ധത്തിന്റെ തിരിച്ചറിയുന്നതിനും വിവരങ്ങള്\u200dക്കും വീണ്ടും ലാബ് നിയമം പങ്കിട്ടുള്ള ജോലിയില്\u200d വീണ്ടും പരിശീലന തിരി ബെര്\u200dട്ടി അടിസ്ഥാനത്തുള്ള ന്യൂറല്\u200d ക്ഷീണിതമായ നടപടികള്\u200d നമ്മള്\u200d പരിചയപ്പെടുത്തുന്നു. എല്ലാ പോസ്- സാധ്യതയില്ലാത്ത സാധ്യതയുടെ ഉദാഹരണങ്ങളായി എണ്ണുന്നു.  നെആര്\u200d പ്രവചനങ്ങള്\u200d അടിസ്ഥാനമായോ സ്വര്\u200dണ്ണപ്രസ്താനങ്ങള്\u200dക്കോ അടിസ്ഥാനത്തോ ബന്ധപ്പെടുത്തുന്ന ബന്ധപ്രകാരം പരിഹരിക്കാന്\u200d നമ്മള്\u200d സാധ്യ നെആര്\u200d ജോലിയില്\u200d, ഞങ്ങള്\u200d എഫ്- സ്കോര്\u200d മൂന്നാമത്തെ സ്റ്റേജ് സിസ്റ്റത്തില്\u200d 76.60% എത്തി. പുറത്തെടുക്കുന്ന ജോലിയുടെ കാര്യത്തില്\u200d, നമ്മള്\u200d എഫ്- സ്കോര്\u200dട്ടിന്റെ മുകളിലുള്ള സിസ്റ്റം പുറത്തെടുക്കുന്നതോ ത വെറ്റ് ലാബ് പ്രോട്ടോക്കോളുകള്\u200d കോര്\u200dപ്പുസിന്\u200dറെ (WLPC) അടിസ്ഥാനത്ത് ഞങ്ങള്\u200d നമ്മുടെ മോഡലിനെ താല്\u200dപ്പര്യമാക്കുന്നു. WLPC ബെസ്റ്റ്ലൈനും ഡൈനാമ', 'ms': 'Kami memperkenalkan pendekatan kelelahan saraf yang mengarahkan pengenalan entiti bernama (NER) dan pengenalan hubungan (RE), untuk pengenalan entiti dan sambungan semula atas tugas berkongsi protokol makmal basah. Kami memperkenalkan pendekatan saraf berasaskan BERT yang mengeluarkan semua jangkauan yang boleh dilihat sebagai entiti berpotensi menyebut dan mengklasifikasikan mereka ke jenis entiti atau tiada entiti dengan rangkaian saraf dalam untuk mengatasi NER. Untuk menyelesaikan tugas ekstraksi hubungan, berdasarkan ramalan NER atau sebutan emas yang diberikan kita cipta semua pasangan pemicu-argumen yang mungkin dan mengklasifikasikannya ke jenis hubungan atau tiada hubungan. Dalam tugas NER, kami mencapai 76.60% dalam terma skor F sebagai sistem peringkat ketiga di antara sistem yang berpartisipasi. Dalam tugas ekstraksi hubungan, kami mencapai 80.46% dalam terma skor F sebagai sistem terbaik dalam tugas ekstraksi hubungan atau pengenalan. Selain itu, kita membandingkan model kita berdasarkan protokol makmal basah corpus (WLPC) dengan dasar WLPC dan sistem ekstraksi dalam formasi berdasarkan graf dinamik (DyGIE).', 'mt': 'Aħna nippreżentaw approċċ eżawrjenti newrali li jindirizza r-rikonoxximent imsejjaħ tal-entità (NER) u r-rikonoxximent tar-relazzjonijiet (RE), għall-entità u r-rikonoxximent tar-rillazzjoni fuq il-kompitu kondiviż tal-protokolli tal-laboratorju mxarrab. Aħna nintroduċu approċċ eżawrjenti newrali bbażat fuq BERT li jelenka l-firxiet pożibbli kollha kif tissemma u tikklassifikahom f’tipi ta’ entitajiet jew l-ebda entità b’netwerks newrali profondi biex tindirizza NER. Biex jissolvew il-kompitu ta’ estrazzjoni tar-relazzjonijiet, ibbażat fuq il-previżjonijiet NER jew imsemmija fid-deheb aħna nħolqu l-pari kollha possibbli ta’ trigger-argument u nikklassifikawhom f’tipi ta’ relazzjonijiet jew l-ebda relazzjoni. Fil-kompitu NER, laħaqna 76.60% f’termini ta’ punteġġ F bħala sistema tat-tielet grad fost is-sistemi parteċipati. Fir-rigward tal-kompitu ta’ estrazzjoni, kisbet 80.46% f’termini ta’ punteġġ F bħala l-ogħla sistema fil-kompitu ta’ estrazzjoni jew rikonoxximent tar-relazzjoni. Minbarra dan, aħna nqabblu l-mudell tagħna bbażat fuq il-protokolli tal-laboratorju mxarrab corpus (WLPC) mal-linja bażi tal-WLPC u s-sistemi dinamiċi tal-estrazzjoni fil-formazzjoni bbażati fuq grafika (DyGIE).', 'mn': 'Бид эдийн засгийн нэр тодорхойлолт (NER) болон харилцааны хүлээн зөвшөөрөл (RE) гэдэг мэдрэлийн сэтгэл хөдлөлтэй арга зам илэрхийлж байна. Ус лабораторийн протоколуудын хуваалцагдсан ажил дээр бий болгож, дахин дахин дахи Бид БЕРТ-д суурилсан мэдрэлийн бүтээмжтэй арга зам тайлбарлаж, тэднийг НЕР-тэй хамтын гүн гүнзгий мэдрэлийн сүлжээнд хэлбэртэй бүтээмжүүдийг бүтээмжүүдийн төрлүүд болон хэлбэрээр хуваалцдаг. НЕР таамаглал эсвэл алтын хэмжээсүүдийн харилцаа гаргах үйлдлийг шийдэхийн тулд бид бүх боломжтой аргументын аргументын хоёр бүтээж, тэднийг харилцааны төрлүүд эсвэл харилцаа байхгүй хэлбэрээр хуваал НЕР даалгавраас бид F-score нь 3 дахь хэмжээст системийн хувьд 76.60% хүртсэн. Харин тараах үйлдлийн харьцаа бид F-score-ын хувьд 80.46%-ийг гаргах эсвэл хүлээн зөвшөөрөх үйлдлийн хамгийн их систем болсон. Ус лабораторийн протоколуудын үндсэн загварыг WLPC суурь шугам болон динамик график үүсгэх (DyGIE) системтэй харьцуулдаг.', 'pl': 'Przedstawiamy neuronalne wyczerpujące podejście, które zajmuje się rozpoznawaniem nazwanych jednostek (NER) i rozpoznawaniem relacji (RE), dla rozpoznawania jednostek i re- lacji za pośrednictwem protokołów mokrego laboratorium wspólnego zadania. Wprowadzamy neuronowe wyczerpujące podejście oparte na BERT, które wylicza wszystkie możliwe zakresy, gdy potencjalny podmiot wspomina i klasyfikuje je na typy podmiotów lub nie posiadające głębokich sieci neuronowych do adresowania NER. Aby rozwiązać zadanie ekstrakcji relacji, w oparciu o prognozy NER lub dane złote wzmianki tworzymy wszystkie możliwe pary trigger-argument i klasyfikujemy je na typy relacji lub brak relacji. W zadaniu NER osiągnęliśmy 76,60% pod względem punktu F jako system trzeciego stopnia wśród systemów uczestniczących. W zadaniu ekstrakcji relacji osiągnęliśmy 80,46% pod względem wyniku F jako najwyższego systemu w zadaniu ekstrakcji lub rozpoznawania relacji. Ponadto porównujemy nasz model oparty na korpusie protokołów mokrych (WLPC) z systemami bazowymi WLPC oraz dynamicznymi systemami ekstrakcji formacji (DyGIE).', 'ro': 'Prezentăm o abordare neurală exhaustivă care abordează recunoașterea entității denumite (NER) și recunoașterea relațiilor (RE), pentru recunoașterea entității și relației în cadrul protocoalelor de laborator umed partajate. Introducem o abordare neurală exhaustivă bazată pe BERT care enumeră toate intervalele posibile ca entitățile potențiale menționează și le clasifică în tipuri de entități sau nicio entitate cu rețele neurale profunde pentru a se adresa NER. Pentru a rezolva sarcina de extragere a relațiilor, pe baza predicțiilor NER sau mențiunilor de aur date, creăm toate perechile posibile trigger-argument și le clasificăm în tipuri de relații sau fără relație. În sarcina NER, am obţinut 76,60% din punctul de vedere al scorului F ca sistem de rang al treilea în rândul sistemelor participate. În sarcina de extragere a relațiilor, am obținut 80,46% în ceea ce privește scorul F ca sistem de top în sarcina de extragere sau recunoaștere a relațiilor. În plus, comparăm modelul nostru bazat pe corpul protocoalelor de laborator umed (WLPC) cu sistemele WLPC de bază și de extracție dinamică bazată pe grafice (DyGIE).', 'no': 'Vi presenterer ein neuralisk utgående tilnærming som adresser med namnet entitetskjenning (NER) og relasjonskjenning (RE), for entitetet og gjenkjenning over delt oppgåve i wet-lab-protokollene. Vi introduserer BERT-basert neuralutløst tilnærming som teller alle pos-sølv mellomrom som potensielle entitet mener og klassifiserer dei til entitetstypar eller ingen entitet med dype neuralnettverk for å adressa NER. For å løysa utpakkingsprogrammet, basert på NER-forhåndsvisingane eller gitt gull mener vi lagar alle mulige utløysingsprogrammepare og klassifiserer dei til relasjonstypar eller ingen relasjon. I NER-oppgåve oppnådd vi 76,60% i form av F-score som tredje ranksystemet mellom dei partiske indikatorene. I tillegg til ekstraksjonsoppgåva fikk vi 80,46 % i forhold til F-score som toppsystemet i forhold til utpakking eller gjenkjenning. I tillegg samanliknar vi modellen vårt basert på mitt lab-protokollene corpus (WLPC) med WLPC-basert og dynamisk graf-basert i-formateringsutpakkingssystemet (DyGIE).', 'so': 'Waxaynu soo bandhignaynaa qaabab taageeri ah oo ku qoran macluumaadyo lagu magacaabay aqoonsiga entity (NER) iyo aqoonsashada xiriirka (RE), aqoonsashada dhamaanka iyo dib loo soo celinayo oo ku saabsan heshiiska labka wet-labka. Waxaannu soo bandhignaynaa qaabka neurada ah oo ku saleysan BERT, taasoo waxay xisaabinaysaa dhammaan boos-suurtagal ah oo ay tahay macluumaad macquul ah, waxaana loo kala qaybsanayaa noocyo ah ama aan heysan habab aad u dheer shabakado neurada ah si ay u macaamiloodaan NER. Si aan u xallino shuqulka ka soo bixinta, taas oo lagu saleyn karo wax la sii sheegayo NER ama la siiyo magac dahab ah, waxaynu abuurnaa noocyo oo dhan oo suurtagal ah oo ka soo firaajiya xaajooyin, waxaana ku kala qaybsanaynaa noocyo xiriir ah ama xiriir la’aan. Shaqada NER waxaan gaadhnay 76.60% oo ku saabsan F-score oo ah nidaamka qayb-qayb ah darajada saddexaad. Shaqo la soo saaro, waxaynu gaadhnay 80.46% oo ku saabsan F-score oo ah nidaamka sare ee la soo saaro ama aqoonsashada. Sidoo kale waxaynu isbarbardhignaa modelkeeni ku saleysan qaababka labka wet (WLPC) iyo nidaamka qoriga ah oo WLPC ku saleysan iyo sawirada dabiicadda ah oo ku saleysan xarumaha (DyGIE).', 'lt': 'Pateikiame išsamų neurologinį požiūrį, kuriame atsižvelgiama į subjekto pavadintą subjekto pripažinimą (NER) ir santykių pripažinimą (RE), subjekto pripažinimą ir pakartotinio ryšio pripažinimą pagal bendrą užduotį, susijusią su šlapių laboratorijų protokolais. Įdiegiame BERT pagrįstą išsamų požiūrį į nervus, kuriame išvardijami visi galimi intervalai, kaip potencialus subjektas nurodo ir klasifikuoja juos į subjektų tipus arba subjektus, neturinčius gilių nervų tinklų NER spręsti. Siekiant išspręsti santykių išgavimo užduotį, remiantis NER prognozėmis arba pateiktais aukso paminėjimais, mes sukuriame visas galimas paleidimo argument ų poros ir klasifikuojame jas į santykių tipus arba jokių santykių. NER užduotyje mes pasiekėme 76,60 proc. F rezultato kaip trečiojo rango sistemos tarp dalyvaujančių sistemų. In relation extraction task, we achieved 80.46% in terms of F-score as the top system in the relation extraction or recognition task.  Be to, palyginame savo model į, pagrįstą šlapiais laboratoriniais protokolais corpus (WLPC) su WLPC pradinėmis ir dinamiškomis grafinėmis formacijos ekstrakcijos (DyGIE) sistemomis.', 'sr': 'Predstavljamo neuralni iscrpljivi pristup koji se obraća priznanje entiteta (NER) i priznanje odnosa (RE), za priznanje entiteta i ponovno razmatranje preko zajedničkog zadatka u vlažnim laboratorijskim protokolima. Predstavljamo na BERT-u neuralnu iscrpljujuću pristup koji enutira sve moguće prostore kao potencijalno spominjanje entiteta i klasifikuje ih u tipe entiteta ili bez entiteta sa dubokim neuralnim mrežama da se obratimo NER-u. Da bi rešili zadatak izvlačenja veza, na osnovu predviđanja NER-a ili odanih zlata spominjali smo sve moguće parove okidača i klasifikovali ih u vrste odnosa ili bez veze. U NER zadatku, postigli smo 76,60% u smislu F-rezultata kao treći redni sistem među delovima ugroženim sistemima. U odnosu na izvlačenje zadataka, postigli smo 80,46% u smislu F-rezultata kao najbolji sistem izvlačenja ili priznanja odnosa. Osim toga, uspoređujemo naš model na osnovu vlažnih laboratorijskih protokola korpusa (WLPC) sa početnim linijom WLPC-a i dinamičnim sistemima ekstrakcije u formaciji (DyGIE).', 'ta': 'நாம் ஒரு புதிய வெளியேற்ற செயல்பாட்டை காண்பிக்கிறோம் பொருள் அடையாளம் (NER) மற்றும் தொடர்பு அடையாளம் (RE) என்ற முகவரிகளின் முகவரிகளை கொண்டுள்ளோம்,  நாம் BERT-அடிப்படையிலான புதிய செல்லும் முறையை குறிப்பிடுகிறோம். அது அனைத்து pos- சாத்தியமான ஸ்பென்னுகளை சாத்தியமான உண்மையின் குறிப்பு மற்றும்  தொடர்பு பிரிப்பு பணி NER பணியில், நாங்கள் பிரிப்பு பகிர்ந்த அமைப்புகளில் மூன்றாம் படிப்பு அமைப்பில் 76.60% அடைந்தோம். தொடர்பு பிரிப்பு பணியில், நாம் F- மதிப்பெண்ணில் 80.46% அடைந்தோம் தொடர்பு பெறுதல் அல்லது அறிவிப்பு பணியில் மேல் அமைப்ப வெட் லாப் நெறி நெறிமுறைகள் (WLPC) அடிப்படையில் நாம் எங்கள் மாதிரியை ஒப்பிடுகிறோம் WLPC அடிப்படையில் மற்றும் இயங்கும் வரைபடம் வடிவமைப்பு பிரிவு (', 'si': 'අපි ප්\u200dරදේශයක් පෙන්වන්නේ න්\u200dයූරාල් නිර්මාණය සහ සම්බන්ධතාවක් අඳුරගන්න (NER) කිරීම සඳහා ප්\u200dරදේශයක් තියෙන්නේ නිර්මාණය සහ ආපහු  අපි BERT-අධාරිත න්\u200dයූරාල් නිර්මාණ ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරනවා ඒකෙන් සියලුම pos- සහෝදර ප්\u200dරවේශනයක් ප්\u200dරවේශනය කිරීමට සහ ප්\u200dරවේශනය ක සම්බන්ධ ප්\u200dරතික්\u200dරියාව විස්තර කරන්න, NER ප්\u200dරතික්\u200dරියාව නැත්තම් දෙන්න තියෙන සුන්තු කිරීමට, අපි සියළුම ප්\u200dරතික්\u200dරියාත්ම NER වැඩේ අපි 76.60% විතරයි F-score විතරයේ තුන්වෙනි රේජ් පද්ධතියෙන් පාර්ටික් පද්ධතියෙන් ඉන්නේ. සම්බන්ධයෙන් අරගෙන යන්න වැඩයෙන්, අපිට F-score වලින් 80.46% විශේෂ වැඩයෙන් ප්\u200dරමාණ පද්ධතියෙන් අරගෙන හෝ අඳුරගන අපි අපේ මෝඩල් එක්ක සමුදානම් කරනවා WLPC මූලික ප්\u200dරතිකෘතිය (WLPC) පද්ධතිය සහ ජාතික ග්\u200dරාෆ් පද්ධතිය සඳහා පද්ධතිය සංවිධානය ස', 'sv': 'Vi presenterar ett neuralt uttömmande tillvägagångssätt som behandlar namngiven entitetsigenkänning (NER) och relationigenkänning (RE), för entitets- och relationsigenkänning över våtlaboratorieprotokollen delade uppgift. Vi introducerar BERT-baserade neurala uttömmande tillvägagångssätt som räknar alla möjliga spännvidder som potentiella entiteter nämner och klassificerar dem i entitetstyper eller ingen entitet med djupa neurala nätverk för att adressera NER. För att lösa relationsextraktionsuppgift, baserat på NER förutsägelser eller givna guldomnämnanden skapar vi alla möjliga trigger-argumentpar och klassificerar dem i relationstyper eller ingen relation. I NER-uppgiften uppnådde vi 76,60% i termer av F-poäng som tredje rank system bland de deltagande systemen. I relation utvinningsuppgift uppnådde vi 80,46% i termer av F-poäng som toppsystem i relation utvinningsuppgift eller igenkänning. Dessutom jämför vi vår modell baserad på våtlaboratorieprotokollets corpus (WLPC) med WLPC baseline och dynamiska grafbaserade in- formationsextraktionssystem (DyGIE).', 'ur': 'ہم ایک نئورل مضبوط طریقہ پیش کرتے ہیں جس کا نام entity recognition (NER) اور re lation recognition (RE) کے ذریعے ایک نئورل مضبوط طریقہ پیش کرتا ہے، ایک ایستی اور دوبارہ پتہ پتہ پتہ کرتا ہے جسے ایک ٹیٹی لاب پروٹوکولوں کے بارے میں مشترک کام کے ہم BERT-based neural exhaustive approach introduce that enumerates all pos-sible spans as potential entity mentions and classifies them into entity types or no entity with deep neural networks to address NER. نیر کی پیش بینی یا سونے کی ذریعہ پر روابط کے خلاف استخراج کا کام حل کرنے کے لئے ہم تمام امکان تریگر-اروغام جوڑے بناتے ہیں اور ان کو رابطہ کے طریقے یا کوئی رابطہ نہیں بناتے۔ نیر کام میں، ہم نے F-score کے مطابق 76.60% کو پارٹیکٹی سیستموں کے درمیان تیسرے رقم سیسٹم کے طور پر پہنچ گیا۔ اٹھانے کے کام کے ارتباط میں، ہم نے F-score کے ارتباط کے اٹھانے یا پہچان کے کام میں 80.46 درصد پہنچ گئے۔ ہم نے اپنے موڈل کو WLPC بنسٹ لین اور ڈینمالیک گراف بنیاد رکھا ہے اس طرح گوش لاب پروٹکوکولوں کے قابل مقایسہ کرتا ہے۔', 'uz': "Biz ma'lum bir necha tilni hozir qilamiz, ma'lumotni tasdiqlash va bogʻlanish (RE) nomli raqamlarni aniqlash (NER) va bogʻlanish (RE) bilan qayta taʼminlovchi narsalar bilan qaytadan tasdiqlash uchun. Biz BERT asosida bir necha neyrolik tilini anglatamiz. Bu hamma pos- asboblarning hamma qo'llanmalarni qo'shish mumkin va ularni bog'liq turlariga ko'rsatish mumkin yoki NER uchun juda qulay neyrol tarmoqlari yoʻq. To solve relation extraction task, based on the NER predictions or given gold mentions we create all possible trigger-argument pairs and classify them into relation types or no relation.  NR vazifasida biz bir qismlar tizimlarining 3 darajasi tizimi sifatida F scorga 76.60% bajaramiz. Tashqi vazifasi bilan, biz murojaat qilish yoki aniqlash vazifasi eng yuqori tizimga 80.46% tugatdik. Biz oq lab protokollar (WLPC) asosida modelimizni WLPC asosida birlashtiramiz va DyGIE tizimi bilan boshlanadi.", 'vi': 'Chúng tôi cung cấp một phương pháp thần kinh bao quát liên quan đến nhận dạng thực thể tên (NER) và nhận dạng tương quan (R) cho thực thể và tái tạo nhận dạng qua các giao thức thí nghiệm phun nước. Chúng tôi giới thiệu phương pháp thần kinh Toàn diện của BERT, liệt kê tất cả các chi nhánh có thể, như thực thể có thể đề cập và phân loại chúng thành dạng thực thể hoặc không một thực thể có các mạng thần kinh sâu để giải quyết cái máy. Để giải quyết các nhiệm vụ khai thác mối quan hệ, dựa trên dự đoán của NER hay đưa ra vàng đề cập chúng tôi tạo ra tất cả các cặp lập trình có thể kích hoạt và phân loại chúng thành dạng tương quan hoặc không có liên quan. Trong nhiệm vụ tối cao, chúng ta đã hoàn thành Ơn trời. Theo tiêu chuẩn F-score hệ thống hạng ba trong các hệ thống dự trữ. Về phần phân tích, chúng ta đã hoàn thành 80.46. Với tỉ số F. là hệ thống cấp cao trong nhiệm vụ phân tích. Hơn nữa chúng tôi so sánh mẫu dựa trên các giao thức phòng thí nghiệm ướt với hệ thống cơ bản của WPC và các hệ thống khuếch đại đồ thị khí động theo cấu hình (DyGIE).', 'bg': 'Представяме невронно изчерпателен подход, който разглежда разпознаването на обекти (НЕР) и разпознаването на релациите (РЕ), за разпознаването на обекти и релациите върху споделената задача на протоколите от мокри лаборатории. Въвеждаме базиран на BERT невронен изчерпателен подход, който изброява всички възможни интервали като потенциални единици ги споменава и класифицира в типове единици или никакви единици с дълбоки невронни мрежи за адресиране на НЕР. За решаване на задачата за извличане на релации, въз основа на прогнозите или дадените златни споменания, създаваме всички възможни двойки спусък-аргумент и ги класифицираме в типове релации или без релация. В задачата постигнахме 76.60% по отношение на F-score като трета ранг система сред частичните системи. По отношение на задачата за извличане на релации постигнахме 80.46% по отношение на F-score като топ система в задачата за извличане на релации или разпознаване. Освен това сравняваме нашия модел въз основа на корпуса на мокрите лабораторни протоколи (WLPC) с базовите системи WLPC и динамичната графична екстракция (DyGIE).', 'da': 'Vi præsenterer en neural udtømmende tilgang, der adresserer navngivet entitetsgenkendelse (NER) og relationsgenkendelse (RE), for entitets- og relationsgenkendelse over wet-lab protokoller delt opgave. Vi introducerer BERT-baseret neural udtømmende tilgang, der tæller alle mulige spænder som potentiel enhed nævner og klassificerer dem i entitetstyper eller ingen enhed med dybe neurale netværk til at adressere NER. For at løse relation ekstraktion opgave, baseret på NER forudsigelser eller givet guld omtaler vi skaber alle mulige trigger-argument par og klassificerer dem i relation typer eller ingen relation. I NER opgaven opnåede vi 76,60% i form af F-score som tredje rang system blandt de deltagende systemer. I relation ekstraktionsopgaven opnåede vi 80,46% i form af F-score som det øverste system i relation ekstraktions- eller genkendelsesopgaven. Desuden sammenligner vi vores model baseret på våd lab protokoller corpus (WLPC) med WLPC baseline og dynamiske grafbaserede in-formation extraction (DyGIE) systemer.', 'nl': 'We presenteren een neurale uitputtende benadering die benoemde entiteitserkenning (NER) en relatierekening (RE) behandelt voor de entiteitserkenning en re- lation herkenning via de wet-lab protocollen gedeelde taak. We introduceren BERT-gebaseerde neurale uitputtende benadering die alle mogelijke overspanningen opstelt als potentiële entiteit vermeldt en classificeert in entiteitstypen of geen entiteit met diepe neurale netwerken om NER aan te pakken. Om relatie extractie taak op te lossen, op basis van de NER voorspellingen of gegeven gouden vermeldingen creëren we alle mogelijke trigger-argument paren en classificeren ze in relatietypen of geen relatie. In NER-taak bereikten we 76,60% in termen van F-score als derde rang systeem onder de deelnemende systemen. Met betrekking tot relatieontwikkeling bereikten we 80,46% in termen van F-score als topsysteem in de relatieontwikkeling of herkenningstak. Daarnaast vergelijken we ons model op basis van het wet lab protocols corpus (WLPC) met de WLPC baseline en dynamische grafiek-based in formation extraction (DyGIE) systemen.', 'hr': 'Predstavljamo neuralni iscrpljivi pristup koji se obraća priznanje entiteta (NER) i priznanje odnosa (RE), za priznanje entiteta i ponovno razmatranje nad zajedničkim zadatkom protokola vlažne laboratorije. Predstavljamo na BERT-u neuralnu iscrpljujuću pristup koji broji svih pos-bratnih prostora kao potencijalni entitet spominje i klasifikuje ih u tipe entiteta ili nikakve entitate sa dubokim neuralnim mrežama za rješavanje NER-a. Da bi riješili zadatak izvlačenja odnosa, na temelju predviđanja NER-a ili odanih zlata spominjali smo sve moguće pare okidača i klasifikirali ih u vrste odnosa ili bez odnosa. U zadatku NER-a, postigli smo 76,60% u smislu F-rezultata kao treći redni sustav među delovima ugroženim sustavima. U odnosu na zadatak izvlačenja postigli smo 80,46% u smislu F-rezultata kao najbolji sustav u zadataku izvlačenja ili priznanja odnosa. Osim toga, uspoređujemo naš model na osnovu vlažnih laboratorijskih protokola corpus (WLPC) sa početnim linijom WLPC-a i dinamičnim sustavima izvlačenih u formaciji grafa (DyGIE).', 'de': 'Wir stellen einen neuronalen umfassenden Ansatz vor, der die benannte Entitätserkennung (NER) und Relationserkennung (RE) für die Entitäts- und Relationserkennung über die gemeinsam genutzten Wet-Lab-Protokolle behandelt. Wir führen einen BERT-basierten neuronalen erschöpfenden Ansatz ein, der alle möglichen Spannen aufzählt, wenn potenzielle Entitäten erwähnt werden und sie in Entitätentypen oder keine Entitäten mit tiefen neuronalen Netzen klassifiziert, um NER anzusprechen. Um die Aufgabe der Beziehungsextraktion zu lösen, erstellen wir basierend auf den NER-Vorhersagen oder gegebenen Gold-Erwähnungen alle möglichen Trigger-Argument-Paare und klassifizieren sie in Beziehungstypen oder keine Beziehung. In der NER-Aufgabe erreichten wir 76,60% hinsichtlich F-Score als drittes System unter den beteiligten Systemen. Bei der Beziehungsextraktionsaufgabe erreichten wir 80,46% in Bezug auf F-Score als oberstes System in der Beziehungsextraktions- oder Erkennungsaufgabe. Außerdem vergleichen wir unser Modell basierend auf dem Wet Lab Protocols Corpus (WLPC) mit den WLPC Baseline- und Dynamic Graph-based In Formation Extraction (DyGIE)-Systemen.', 'fa': 'ما یک روش عصبی استفاده می کنیم که با نام شناسایی entity (NER) و شناسایی ارتباط (RE) برای شناسایی entity و دوباره شناسایی بر روی پروتکل های مشترک کار آزمایشگاهی wet-lab نشان می دهد. ما روش عصبی که بر بنیاد BERT بنیاد می\u200cگیریم را معرفی می\u200cکنیم که تمام فضایی\u200cهای غیر قابل توجه می\u200cکند و آنها را به نوع\u200cهای متحد یا هیچ متحدی که با شبکه\u200cهای عصبی عمیق برای آدرس NER قرار می\u200cدهد به شماره می\u200cدهد. برای حل کردن وظیفه اخراج ارتباط، بر اساس پیش بینی های NER یا به ذکر طلایی داده شده، همه جفت\u200cهای امکان جفت\u200cهای ماشه\u200cآوری را ایجاد می\u200cکنیم و آنها را به نوع ارتباطی یا هیچ ارتباطی برقرار می\u200cکنیم. در وظیفه NER، 76.60 درصد به عنوان سیستم درجه سوم در سیستم\u200cهای پارکیه\u200cای رسیدیم. در ارتباط کار خارج کردن، ما 80.46 درصد به عنوان سیستم بالایی در مورد خارج یا شناسایی رابطه رسیدیم. علاوه بر این، ما مدل خود را بر اساس پروتکل\u200cهای آزمایشگاهی wet corpus (WLPC) با سیستم\u200cهای بنیادی WLPC و خارج شدن (DyGIE) بر اساس گراف\u200cهای دینامیک مقایسه می\u200cکنیم.', 'sw': 'Tunaweza kutengeneza mbinu yenye udhaifu wa kiserikali ambazo huongeza hotuba zinazoitwa kutambua entity (NER) na kutambua mahusiano (RE), kwa ajili ya utambulisho na utambulisho wa upya juu ya protoko za maabara ya wet. Tunaonyesha mbinu za kuchochea kwa kutumia BERT ambazo zinakadiria pande zote ambazo haziwezekani kama taja za vifaa vya uwezekano na kuwafananisha kuwa aina ya vitu au hakuna vitu vinavyotumika na mitandao ya ubongo wa kina ya kiserikali ya NER. Ili kutatua jukumu la utekelezaji wa uhusiano, kwa kutumia utabiri wa NEW au kutolewa kwa majina ya dhahabu tunatengeneza wanandoa wote wanaowezekana na kuwagawanya katika aina za mahusiano au bila uhusiano. Katika kazi ya NER, tulipata asilimia 76.60 kwa mujibu wa vipindi vya F kama mfumo wa tatu kati ya mfumo wa washiriki. Kuhusu kazi ya uteuzi, tulipata asilimia 80.46 kwa mujibu wa F-score kama mfumo wa juu katika kazi ya utekelezaji au kutambua. Zaidi ya hayo tunalinganisha modeli yetu kwa kutumia mashirika ya mikakati ya maabara weupe (WLPC) na mfumo wa msingi wa WLPC na picha za dynamic kwa ajili ya kutengeneza vifaa (DyGIE).', 'tr': "Biz entitet tanaýmasyny (NER) we ilişki tanaýmasyny (RE) bilen bir neural ösümli metodlary çykarýarys. BERT'e tabanlı neural yorumlu bir yaklaşımı tanıtıyoruz ki, tüm pos- kardeşli uzakları potansiyel bir madde olarak adlandırır ve onları, NER'e göre derin nöral ağlarıyla birleştirmek için bir hediye olarak tanıtır. NER önümlerine daýanýar ýa-da altynyň aýdyşynda baglaşyklaryň çözmesi üçin, biz hemme mümkin trig-argum çiftleri döredip olary baglaşyklaryň ýa-da hiç bir baglaşyklaryň ýüzüne düzümlendiris. NER görevi bolsa, F-अ अंतर sistemasynda 76.60% ýetdik. Arşiw täblisasy baglanyşykda, F-अ अंश ylalaşykda 80.46%-ny tapdyk. Biz çöl lab protokollarynyň corpus (WLPC) sistemlerine daýanýan modelimizi WLPC çizgi we dinamik grafiklere daýanýan çölegi sistemlerine karşılaştyrýarys.", 'af': "Ons stel 'n neurale uitgetrekbare toegang wat adresse genoem entiteit herken (NER) en verwantigheid herken (RE), vir die entiteit en herlaai herken oor die wet-lab protokolle gedeelde taak. Ons introduseer BERT-gebaseerde neurale uitsluitende toegang wat alle pos- sible spans as potensiele entiteit bepaal en klassifiseer hulle in entiteittipes of geen entiteit met diep neurale netwerke om NER te adres nie. Om verhouding van uitvoer opdrag te los, gebaseer op die NER voorskou of gegewe goud bepaal, skep ons alle moontlik uitvoer-argument paar en klassifiseer hulle in verhouding tipes of geen verhouding nie. In NER taak, ons het 76.60% gevolg in terms van F- score as derde rank stelsel onder die partike-ipated stelsels. In betrekking van uittrekking-taak het ons 80.46% ingevolge F-telling as die bo-stelsel in die verwanting uittrekking of herkening-taak bereik. Ons vergelyk ons model gebaseer op die wet lab protokolle corpus (WLPC) met die WLPC basisline en dinamiese graaf-gebaseer in- formasie uittrekking (DyGIE) stelsels.", 'am': 'We present a neural exhaustive approach that addresses named entity recognition (NER) and relation recognition (RE), for the entity and re- lation recognition over the wet-lab protocols shared task.  በBERT-based የደካማ የነጥብ ጥያቄን እናስታውቃለን፡፡ የግንኙነት አካባቢ ግንኙነት ለመፍታት፣ የNER ውይይት ወይም የወርቅ ማወሳት በመሠረት፣ የሚቻለውን የግንኙነት ዓይነት እናደርጋቸዋለን እና ግንኙነት ወይም ግንኙነት የሌለባቸውን እናካፍናቸዋለን፡፡ በNER ስራ 76.60 በመቶ በአፍሪካዊ ስርዓት መካከል በሦስተኛ ደረጃ ሲስተም ደረስን፡፡ የውጤት ስራ 80.46 በመቶ አግኝተናል፡፡ ከዚህም በላይ ነጭ የlab ፕሮግራሞች ኮርፖስስ (WLPC) በተመሳሳይ እና በጥያቄ የግራማ ውጤት (DyGIE) ሲስተካከል እናሳያታለን፡፡', 'sq': 'Ne paraqesim një qasje nervore exhaustive që trajton njohjen e emëruar të njësisë (NER) dhe njohjen e marrëdhënieve (RE), për njësinë dhe njohjen e përsëritjes lidhur me protokollet e përbashkëta të laboratorit të lagur. We introduce BERT-based neural exhaustive approach that enumerates all pos- sible spans as potential entity mentions and classifies them into entity types or no entity with deep neural networks to address NER.  Për të zgjidhur detyrën e nxjerrjes së marrëdhënieve, bazuar në parashikimet e NER ose përmendimet e dhëna të artë ne krijojmë të gjitha çiftet e mundshme trigger-argument dhe i klasifikojmë në lloje marrëdhënieve apo asnjë marrëdhënie. Në detyrën NER, arritëm 76.60% në lidhje me rezultatin F si sistemin e rendit të tretë midis sistemeve të pjesëmarrshme. Në lidhje me detyrën e nxjerrjes, arritëm 80.46% në lidhje me rezultatin F si sistemin më të lartë në detyrën e nxjerrjes së marrëdhënieve apo njohjes. Përveç kësaj ne krahasojmë model in tonë bazuar në protokollet e lagura të laboratorit corpus (WLPC) me bazën e WLPC dhe sistemet dinamike të ekstraksionit të formimit të grafikut (DyGIE).', 'id': 'Kami mempersembahkan pendekatan kelelahan saraf yang mengandung pengakuan entitas bernama (NER) dan pengakuan hubungan (RE), untuk entitas dan pengakuan relasi atas protokol laboratorium basah berbagi tugas. Kami memperkenalkan pendekatan saraf berbasis BERT yang melelahkan semua jangkauan yang dapat dilihat sebagai entitas potensial menyebutkan dan mengklasifikasikan mereka menjadi jenis entitas atau tidak ada entitas dengan jaringan saraf dalam untuk mengatasi NER. Untuk memecahkan tugas ekstraksi hubungan, berdasarkan prediksi NER atau disebutkan emas kita menciptakan semua mungkin pasangan pemicu-argumen dan mengklasifikasikan mereka ke jenis hubungan atau tidak ada hubungan. In NER task, we achieved 76.60% in terms of F-score as third rank system among the partic- ipated systems.  Dalam tugas ekstraksi, kami mencapai 80,46% dalam terma skor F sebagai sistem terbaik dalam tugas ekstraksi hubungan atau pengenalan. Selain itu kita membandingkan model kita berdasarkan protokol lab basah corpus (WLPC) dengan sistem dasar WLPC dan dinamis grafik-berdasarkan ekstraksi dalam formasi (DyGIE).', 'ko': '우리는 습실험실 프로토콜 공유 임무의 실체와 관계 식별에 사용되는 명명실체식별(NER)과 관계식별(RE)을 해결하는 신경궁거 방법을 제시했다.우리는 BERT 기반의 신경궁거 방법을 도입했다. 이 방법은 모든 가능한 경계를 잠재적 실체로 열거하고 이를 실체 유형 또는 무실체로 분류하여 심도 신경 네트워크를 이용하여 이러한 문제를 해결한다.관계 추출 작업을 해결하기 위해 NER 예측 또는 주어진 Gold 언급을 바탕으로 가능한 트리거 매개 변수 쌍을 모두 생성하여 관계 유형 또는 관계없음으로 분류합니다.NER 임무에서 우리는 참여 시스템에서 76.60%의 F 점수를 얻어 3등급 시스템으로 삼았다.관계 추출 임무 중 우리가 관계 추출 또는 식별 임무 중 F 점수가 80.46%로 가장 높았다.또한 wet실험실 프로토콜 자료 라이브러리(WLPC) 모델을 바탕으로 WLPC 기선과 동적도 기반 정보 추출(DyGIE) 시스템을 비교했다.', 'hy': 'Մենք ներկայացնում ենք նյարդային հոգնեցնող մոտեցում, որը վերաբերում է անվանումների ճանաչման (ՆԵՌ) և հարաբերությունների ճանաչման (ՌԵ) անվանության և վերափոխման ճանաչման (ՌԵ) վերաբերյալ թափուկ լաբորատոկոցների ընդ Մենք ներկայացնում ենք BERՏ-ի հիմնված նյարդային ամբողջական մոտեցում, որը ցույց է տալիս բոլոր տեսանելի տարածքները, ինչպես պոտենցիալ էակը նշում է և դասակարգում է դրանք էակների տեսակներով կամ ոչ մի էակ, որն ունի խորը նյարդային ցանցեր,  Որպեսզի լուծենք հարաբերությունների դուրս բերման խնդիրը, հիմնված ՆԵՌ կանխատեսումների կամ ոսկու նշումների վրա, մենք ստեղծում ենք բոլոր հնարավոր արագացման-բանավեճի զույգերը և դասակարգում ենք դրանք հարաբերությունների տեսակների կամ ոչ ՆԵՌ-ի առաջադրանքի ժամանակ մենք հասանք 76.60 տոկոսի F-գնահատականի տեսքով որպես երրորդ գնահատականի համակարգ մասնիկների մեջ: Ինչպես վերաբերում է վերացման խնդրին, մենք հասանք 80.46 տոկոսի F-գնահատման տեսանկյունից որպես վերևի համակարգ հարաբերության վերացման կամ ճանաչության խնդրի մեջ: Ավելին, մենք համեմատում ենք մեր մոդելը, որը հիմնված է թափուկ լաբորատորիկական պրոտոկոլների կորպոս (WELCP) վրա, WELCP հիմնական և դինամիկ գրաֆիկական հիմնական ինֆորմացիայի (ԴիԳԻ) համակարգերի հետ:', 'az': 'Biz bir nöral mükəmməl approach göstəririk ki, ünsiyyət tanıması və ilişki tanıması (RE) adlı bir nöral təşkil, süt lab protokolların paylaşılmış işlər üzərində yenidən tanıması üçün. Biz BERT tabanlı nöral tükənməz fikirləri təşkil edirik ki, bütün pos-qardaşlarını potansiyel entitet adlandırması və onları entitet tiplərinə və yaxud NER ilə çəkilmək üçün derin nöral ağları olan bir entitə sayır. NER tədbirlərinə və ya altın tədbirlərinə dayanan ilişkisini çəkmək üçün bütün mümkün trigger-argument çift yaradırıq və onları ilişkisi türlərə və ya heç bir ilişkisi olaraq dəyişdiririk. NER işində, F-score sistemi üçüncü dərəcə sistemi kimi 76.60%-i qəbul etdik. Xərcləmə işində F-score ilə 80,46%-i əlaqələri çıxartma və tanıma işində ən yüksək sistem olaraq qəbul etdik. Və modeliyimizi çəmi laboratori protokolların corpus (WLPC) üzərində WLPC sinyali və dinamik graflı in şa edilmə sistemləri ilə qarşılaşdırırıq.', 'bs': 'Predstavljamo neuralni iscrpljivi pristup koji se obraća na priznanje entiteta (NER) i priznanje odnosa (RE), za priznanje entiteta i ponovno razmatranje preko zajedničkog zadatka protokola mokračke laboratorije. Predstavljamo neuralnu iscrpljujuću pristup na BERT-u koji obuhvaća sve moguće prostore kao spominje potencijalne entitate i klasifikuje ih u tipe entiteta ili nikakve entitate sa dubokim neuralnim mrežama da bi se obratili NER-u. Da bi riješili zadatak izvlačenja odnosa, na temelju predviđanja NER-a ili odanih zlata spominjali smo sve moguće pare okidača i klasifikirali ih u vrste odnosa ili bez veze. U NER zadatku, postigli smo 76,60% u smislu F-rezultata kao treći redni sistem među delovima ugrađenim sistemima. U odnosu na zadatak izvlačenja, postigli smo 80,46% u smislu F-rezultata kao najbolji sistem izvlačenja ili priznanja odnosa. Osim toga, uspoređujemo naš model na osnovu vlažnih laboratorijskih protokola korpusa (WLPC) sa WLPC-om početnim linijom i dinamičnim sistemima ekstrakcije u formaciji (DyGIE).', 'bn': 'আমরা একটি নিউরেল ক্লান্তিকর পদ্ধতি উপস্থাপন করেছি যেটির নাম বৈশিষ্ট্য স্বীকৃতি এবং সম্পর্ক স্বীকৃতির (RE) ঠিকানা দেয়া হয়েছে, যেটির জন্য বৈশিষ্ট্য এব আমরা বিবেরেট ভিত্তিক নিউরেল ক্লান্তিগত পদ্ধতিকে পরিচিত করে দেখাচ্ছি যা সকল পোস- সম্ভাব্য বস্তুর উল্লেখ হিসেবে হিসেবে হিসেবে হিসেবে হিসেবে গণ্য করে য নিউ আরর ভবিষ্যদ্বাণী অথবা সোনার উল্লেখের ভিত্তিতে সম্পর্ক বের করা কাজ সমাধান করার জন্য আমরা সকল সম্ভাব্য যুক্তি জোড়া সৃষ্টি করি এবং সম্পর্কে In NER task, we achieved 76.60% in terms of F-score as third rank system among the partic- ipated systems.  সম্পর্কে বের করা কাজের মাধ্যমে আমরা এফ স্কোরের মাধ্যমে ৮০. ৪৬% অর্জন করেছি সম্পর্ক বের করা অথবা স্বীকৃতি প্রদান করা কাজের মধ্যে সর এছাড়াও আমরা আমাদের মডেলের তুলনা করি উট ল্যাব প্রোটোকল কোর্পোসি (উইলপিসি) বেসাইলপিসি এবং ডায়ান্ডামিক গ্রাফ-বিন্যাস (ডিয়াজিই) সিস্টেমের সা', 'ca': "Presentam un enfocament neural exhaustiu que aborda el reconeixement d'entitats anomenades (NER) i el reconeixement de relacions (RE), per al reconeixement de l'entitat i la relació sobre la tasca compartida dels protocols de laboratori humit. Introduïm un enfocament exhaustiu neuronal basat en BERT que enumera totes les extensions posibles com l'entitat potencial els menciona i les classifica en tipus d'entitats o cap entitat amb xarxes neuronals profundes per abordar NER. Per resoldre la tasca d'extracció de relacions, basada en les prediccions NER o en mencions d'or, creem tots els parells possibles d'arguments de desencadenament i les classifiquem en tipus de relacions o cap relació. En la tasca NER, vam aconseguir un 76,60% en termes de puntuació F com sistema de tercer rangu entre els sistemes participats. En relació a la tasca d'extracció, vam aconseguir un 80,46% en termes de puntuació F com el sistema superior en la tasca d'extracció o reconeixement de relació. Besides we compare our model based on the wet lab protocols corpus (WLPC) with the WLPC baseline and dynamic graph-based in- formation extraction (DyGIE) systems.", 'et': 'Tutvustame neuraalset ammendavat lähenemisviisi, mis käsitleb nimetatud olemi tuvastamist (NER) ja suhte tuvastamist (RE), olemi ja re- latsiooni tuvastamist läbi wet-lab protokollide jagatud ülesande. Tutvustame BERT-põhist neuraalset ammendavat lähenemisviisi, mis loetleb kõik võimalikud ulatused kui potentsiaalne üksus mainib ja liigitab need olemitüüpideks või mitte ühtegi sügavate neuraalsete võrkudega üksusteks NER-i lahendamiseks. Seoste ekstraheerimise ülesande lahendamiseks loome NER prognooside või antud kullamärkuste põhjal kõik võimalikud trigger-argument paarid ja liigitame need seostüüpideks või mitte seosteks. NER ülesandes saavutasime osalisüsteemide hulgas 76,60% F-skoori osas kolmanda astme süsteemina. Seoses ekstraheerimisülesandega saavutasime 80,46% F-skoori kui top süsteemi seose ekstraheerimise või tuvastamise ülesandes. Lisaks võrdleme märjal laboril põhinevat mudelit WLPC baasil ja dünaamilisel graafikal põhineval in-formation ekstraheerimisel (DyGIE).', 'cs': 'Představujeme neuronově vyčerpávající přístup, který se zabývá rozpoznáváním pojmenovaných entit (NER) a rozpoznáváním vztahů (RE), pro rozpoznávání entit a re- lace prostřednictvím sdíleného úkolu mokrých laboratorních protokolů. Představujeme neuronový komplexní přístup založený na BERT, který vyčítá všechny možné rozpětí, jak potenciální entita zmíní a klasifikuje je do typů entit nebo žádné entity s hlubokými neuronovými sítěmi pro řešení NER. Pro vyřešení úlohy extrakce vztahů na základě NER predikcí nebo daných zlatých zmínek vytvoříme všechny možné trigger-argument páry a klasifikujeme je do typů vztahů nebo žádných vztahů. V úkolu NER jsme dosáhli 76,60% z hlediska F-skóre jako systému třetí řady mezi účastníky systémů. U úlohy extrakce vztahů jsme dosáhli 80,46% z hlediska F-skóre jako nejvyššího systému v úloze extrakce nebo rozpoznávání vztahů. Kromě toho porovnáváme náš model založený na korpusu mokrých laboratorních protokolů (WLPC) s WLPC baseline a dynamickými grafovými extrakčními systémy (DyGIE).', 'fi': 'Esitämme neuraalisen tyhjentävän lähestymistavan, joka käsittelee nimettyä entiteettitunnistusta (NER) ja suhdetunnistusta (RE), entiteettitunnistusta ja uudelleentunnistusta wet-lab protokollien jaetun tehtävän yli. Esittelemme BERT-pohjaisen neurotyhjentävän lähestymistavan, joka luetteloi kaikki mahdolliset alueet potentiaalisiksi entiteeteiksi mainitseviksi ja luokittelee ne entiteetyypeiksi tai ei yksikään entiteetti, jolla on syvät neuroverkot NER:n käsittelemiseksi. Relationuuttamistehtävän ratkaisemiseksi luomme NER-ennusteiden tai annettujen kultamainintojen perusteella kaikki mahdolliset trigger-argumenttiparit ja luokittelemme ne relaatiotyyppeihin tai ei relaatiota. NER-tehtävässä saavutimme 76,60% F-pisteen kolmantena sijoitusjärjestelmänä osakkuusjärjestelmistä. Suhteen uuttamistehtävässä saavutimme 80,46% F-pisteen suhteen uuttamistehtävässä ylimpänä järjestelmänä. Lisäksi vertaamme wet lab protocols corpus (WLPC) -malliamme WLPC-lähtö- ja dynaaminen graafinen in-formation extraction (DyGIE) -järjestelmiin.', 'he': 'אנו מציגים גישה עיצבית מותשת שמייחסת לזיהוי ישות בשם (NER) והזיהוי יחסים (RE), עבור היחידה והזיהוי מחדש יחסים על פרוטוקולים מעבדה רטובה משותפים משימה. אנו מציגים גישה עיצבית מבוססת על BERT שמספרת את כל המרחקים הנוכחים כפי שהיחידה פוטנציאלית מזכירה והקלאסית אותם לסוגים של יחידות או שום יחידה עם רשתות עצביות עמוקות כדי להתמודד עם NER. כדי לפתור את משימה החילוץ מערכות יחסים, בהתבסס על חזיונות NER או על הזכרונות זהב נתונים אנחנו יוצרים את כל זוגות ההדק-טיעון אפשריים במשימה NER, השגנו 76.60% במונחים של נקודת F כמערכת מדרגה שלישית בין המערכות החלקים. בנוגע למשימת החילוץ, השגנו 80.46% במונחים של ציון F כמערכת העליונה במשימת החילוץ או זיהוי היחסים. חוץ מזה, אנחנו משוותים את המודל שלנו מבוסס על פרוטוקולי המעבדה הרטובים קורפוס (WLPC) עם מערכות ההתחלה של WLPC ודינמיקלי גרף מבוססים על יצירת יצירה (DyGIE).', 'ha': "Tuna halatar da wata hanyor fara-ƙari wanda ke addu'ar sunayen sunansa shaidar masu gaskiyar (NER) da ganin haɗi (NER), wa masu gaskiyar da kuma sunan-salon kan aikin da aka raba shi. Tuna ƙuyya da hanyon neural na BERT wanda ke ƙayyade duk ma'abũcin lokaci da zai iya lissafa su kamar ma'anar abuni na ƙarfi kuma Muke rarraba su cikin nau'i-abun ko kuma ba da wani abun da ke da zane-taryutan neural na ƙaranci zuwa NER. To solve aikin masu husũma, a kan basaran bayanin NER ko da aka ba da ambaci na zĩnãriya, za mu halitta duk nau'i-nau'i biyu da ke iya iya yi ta-gyara kuma mu rarrabe su zuwa nau'i ko kuma ba da wata danganci. A cikin aikin NER, mun sami 76.60% da ke cikin fassarar F-score kamar na'urar daraja na uku cikin masu rabo. Ga muhimmin aikin zartarwa, mun isa 80.46%, cikin muhimman F-score kamar na samar cikin aikin da aka nuna ko gane. Bayan haka, muna daidaita misalinmu a kan kwamfyutan makorari na lab (WLPC) da tsarin WLPC na danne da danganin grafu-danne (DyGIU).", 'sk': 'Predstavljamo nevronski izčrpen pristop, ki obravnava poimenovano prepoznavanje entitet (NER) in prepoznavanje relacij (RE), za prepoznavanje entitete in relacije prek skupne naloge wet-lab protokolov. Predstavljamo izčrpen nevronski pristop, ki temelji na BERT-u, ki našteje vse možne razpone kot potencialna entiteta omenja in jih razvrsti v entitete ali nobene entitete z globokimi nevronskimi omrežji za obravnavanje NER. Za reševanje naloge ekstrakcije relacij na podlagi napovedi NER ali danih zlatih omemb ustvarimo vse možne pare sprožilec-argument in jih razvrstimo v vrste relacij ali brez relacije. V nalogi NER smo dosegli 76,60% v smislu F-rezultata kot tretjega reda med deljenimi sistemi. Pri nalogi ekstrakcije relacij smo dosegli 80,46% v smislu F-rezultata kot vrhunskega sistema v nalogi ekstrakcije relacij oziroma prepoznavanja relacij. Poleg tega primerjamo model, ki temelji na korpusu mokrih laboratorijskih protokolov (WLPC) z osnovnimi in-formacijskimi sistemi WLPC in dinamičnimi grafičnimi ekstrakcijami (DyGIE).', 'jv': 'Awak dhéwé éntuk akses karo hal-hal offisikno sing paling nggawe akses nambarang "PIR" lan "Relative" nggawe barang nggawe barang (RER), nggawe akses karo mulai gawe ngupakan ilegal sampeyan karo protokol sing dibenalke bot Awak dhéwé nambah kang BERT basa akeh luwih operasan luwih dumadhi iki dadi nggawe barang langkung dibenalke kapan tanggal nggawe Jagger To Resolve Relative AllProgress Nang task (NUR) Art Kita sampeyan nganggo model sing digowiyo urip akeh ning sampeyan protokol dumaten (WLPC) karo sistem sing nyimpen WLPC karo diagram sing basa gambar n-format (dy GIE).', 'bo': 'ང་ཚོས་དབང་དང་མཐུན་འབྲེལ་མཐུད་སྣེ་བརྗོད་ཀྱི་ཐབས་ལམ་ཞིག་གནང་བ་དེ་དམིགས་བསལ་ཁབ་ཞིག་མིང་(NER)དང་མཐུན་རྟོགས་ཀྱི་དཔེ་རིགས་དང་བསྐྱར་ལྟ་བུ་འཇུག་ We introduce BERT-based neural exhaustive approach that enumerates all pos- sible spans as potential entity mentions and classifies them into entity types or no entity with deep neural networks to address NER. The concept is called a BERT To solve relation extraction task, based on the NER predictions or given gold mentions we create all possible trigger-argument pairs and classify them into relation types or no relation. སྒྲིག་འགོད་ལས་ཀྱང་ཕྱོགས་པའི་དོན་ལྟར་ན་(F)རིམ་པ་ཚོའི་ནང་གི་སྐྱེས་ཚད་གསུམ་པ་ལྟར་སྐྱེས་པའི་མ་ལག་གི་ནང་དུ་76.60% ཕྱིར Besides we compare our model based on the wet lab protocols corpus (WLPC) with the WLPC baseline and dynamic graph-based in- formation extraction (DyGIE) systems.'}
{'en': 'WNUT-2020 Task 2 : Identification of Informative COVID-19 English Tweets WNUT -2020 Task 2: Identification of Informative  COVID -19  E nglish Tweets', 'ar': 'مهمة WNUT-2020 2: تحديد التغريدات الإعلامية حول COVID-19 باللغة الإنجليزية', 'pt': 'Tarefa 2 do WNUT-2020: identificação de tweets informativos sobre COVID-19 em inglês', 'fr': 'Tâche 2 de la WNUT-2020\xa0: Identification des tweets informatifs en anglais sur la COVID-19', 'es': 'Tarea 2 del WNUT-2020: Identificación de tuits informativos en inglés sobre COVID-19', 'ja': 'WNUT -2020タスク2 ：新型コロナウイルス感染症(COVID -19)に関する情報の特定英語ツイート', 'zh': 'WNUT-2020Śä°2:ŤĮÜšŅ°šłįCOVID-19ŤčĪŤĮ≠śé®śĖá', 'ru': 'WNUT-2020 Задача 2: Идентификация информационных твитов на английском языке о COVID-19', 'hi': 'WNUT-2020 टास्क 2: सूचनात्मक कोविड -19 अंग्रेजी ट्वीट्स की पहचान', 'ga': 'WNUT-2020 Tasc 2: Tweetanna Béarla Faisnéiseacha COVID-19 a Aithint', 'ka': 'WNUT-2020 დავალება 2: ინფორმაციული COVID-19 ინგლისური Tweets', 'el': 'Εργασία 2: Προσδιορισμός ενημερωτικών Αγγλικών tweets', 'hu': 'WNUT-2020 2. feladat: Információs COVID-19 angol tweetek azonosítása', 'it': 'Task 2 di WNUT-2020: Identificazione dei tweet informativi in inglese COVID-19', 'lt': 'WNUT-2020 2 užduotis: Informacinių COVID-19 anglų Tweets identifikavimas', 'mk': 'ВНУТ-2020 задача 2: Идентификација на информативните Твитови COVID-19 англиски', 'ml': 'WNUT- 2020 ടാസ്ക് 2: വിവരങ്ങളുടെ കോവിഡ്- 19 ഇംഗ്ലീഷ് ടൂട്ടുകള്\u200d തിരിച്ചറിയുക', 'mt': 'WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets', 'mn': 'WNUT-2020 Task 2: Informative COVID-19 English Tweets Identification', 'no': 'WNUT-2020 Oppgåve 2: Identifikasjon av informativ COVID-19 engelsk tweets', 'pl': 'WNUT-2020 Zadanie 2: Identyfikacja informacyjnych tweetów COVID-19 angielskich', 'kk': 'WNUT-2020 2- тапсырма: Мәліметті COVID-19 ағылшын tweets идентификациясы', 'ro': 'Activitatea 2 a WNUT-2020: Identificarea tweeturilor informative în limba engleză COVID-19', 'si': 'WNOT-2020වැඩක් 2: තොරතුරු COVID-19 ඉංග්\u200dරීසි ට්විට්ස් අඳුනන්', 'ms': 'WNUT-2020 Tugas 2: Pengenalan Tweet Inggeris COVID-19 Maklumat', 'sr': 'WNUT-2020 zadatak 2: Identifikacija informativnih tweets COVID-19', 'so': 'WNUT-2020 Shaqooyin 2: Identification of Informative COVID-19 Ingiriis Tweets', 'ur': 'WNUT-2020 Task 2: Informative COVID-19 English Tweets Identification', 'sv': 'WNUT-2020 Uppgift 2: Identifiering av informativa COVID-19 engelska tweets', 'ta': 'WNUT- 2020 பணி 2: தகவல் அறிமுகம் COVID- 19 ஆங்கிலத்தின் Tweets', 'uz': 'WNUT- 2020 vazifa 2: Maʼlumot COVID-19 Inglizcha Twitterlarini aniqlash', 'vi': 'Nhiệm vụ Hồ sơ Quân sự', 'nl': 'WNUT-2020 Taak 2: Identificatie van informatieve COVID-19 Engelse Tweets', 'da': 'WNUT-2020 Opgave 2: Identifikation af informative COVID-19 engelske tweets', 'bg': 'Задача 2: Идентифициране на информативни английски туитове', 'hr': 'WNUT-2020 zadatak 2: Identifikacija informativnih COVID-19 engleskih Tweets', 'id': 'WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets', 'de': 'WNUT-2020 Aufgabe 2: Identifizierung informativer COVID-19 englischer Tweets', 'fa': 'Task 2 WNUT-2020: Identification of Informative COVID-19 English Tweets', 'ko': 'WNUT-2020 미션2: 풍부한 정보를 인식하는 코로나 영어 트윗', 'sw': 'WNUT-2020 Kazi 2: Utambulisho wa Twiti za Kiingereza za za Kitaarifa COVID-19', 'tr': 'WNUT-2020 Görev 2: Maglumaty COVID-19 Iňlis Tweets Identification of Informative COVID-19 English Tweets', 'af': 'WNUT-2020 Opdrag 2: Identifikasie van Informatiewe Kovid-19 Engels Tweets', 'sq': 'WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets', 'am': 'WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets', 'hy': 'ԱՄՆԹ 2020-ի 2. խնդիր. տեղեկատվական COVID-19 անգլերեն թվիթերի հայտնաբերումը', 'az': 'WNUT-2020 Gözəl 2: Informativ COVID-19 İngilizə Tweets Identification of Informative COVID-19', 'bn': 'WNUT-2020 কাজ ২: তথ্য তথ্য প্রদান করা কভিড-১৯ ইংরেজি টুইটের পরিচয়', 'bs': 'WNUT-2020 zadatak 2: Identifikacija informativnih COVID-19 engleskih Tweets', 'ca': 'WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets', 'cs': 'WNUT-2020 Úkol 2: Identifikace informačních COVID-19 anglických tweetů', 'et': 'WNUT-2020 ülesanne 2: informatiivse COVID-19 tuvastamine English Tweets', 'fi': 'WNUT-2020 Tehtävä 2: Informatiivisen COVID-19:n tunnistaminen English Tweets', 'ha': 'QFontDatabase', 'sk': 'WNUT-2020 Naloga 2: identifikacija informativnih COVID-19 English Tweets', 'he': 'משימה 2 WNUT-2020: זיהוי של טוויטים אנגליים COVID-19', 'jv': 'WNUT-2020', 'bo': 'WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets'}
{'en': 'In this paper, we provide an overview of the WNUT-2020 shared task on the identification of informative COVID-19 English Tweets. We describe how we construct a  corpus of 10 K Tweets  and organize the development and evaluation phases for this  task . In addition, we also present a brief summary of results obtained from the final system evaluation submissions of 55 teams, finding that (i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the majority of the submissions achieve substantially higher results than the baseline  fastText  (Joulin et al., 2017), and (iii) fine-tuning pre-trained language models on relevant language data followed by  supervised training  performs well in this task.', 'ar': 'في هذه الورقة ، نقدم لمحة عامة عن مهمة WNUT-2020 المشتركة حول تحديد التغريدات المفيدة لـ COVID-19 الإنجليزية. نصف كيف نبني مجموعة من 10 آلاف تغريدة وننظم مراحل التطوير والتقييم لهذه المهمة. بالإضافة إلى ذلك ، نقدم أيضًا ملخصًا موجزًا للنتائج التي تم الحصول عليها من عمليات تقديم تقييم النظام النهائية لـ 55 فريقًا ، ووجدنا أن (1) العديد من الأنظمة تحصل على أداء عالٍ للغاية ، حتى 0.91 درجة F1 ، (2) تحقق غالبية الطلبات بشكل كبير نتائج أعلى من النص الأساسي السريع (Joulin et al. ، 2017) ، و (3) الضبط الدقيق لنماذج اللغة المدربة مسبقًا على بيانات اللغة ذات الصلة متبوعًا بالتدريب الخاضع للإشراف يؤدي أداءً جيدًا في هذه المهمة.', 'es': 'En este documento, ofrecemos una visión general de la tarea compartida de WNUT-2020 sobre la identificación de tuits informativos en inglés sobre COVID-19. Describimos cómo construimos un corpus de 10 000 Tweets y organizamos las fases de desarrollo y evaluación de esta tarea. Además, también presentamos un breve resumen de los resultados obtenidos de las presentaciones de evaluación final del sistema de 55 equipos, encontrando que (i) muchos sistemas obtienen un rendimiento muy alto, hasta un puntaje de F1 de 0.91, (ii) la mayoría de los envíos logran resultados sustancialmente más altos que el FastText de referencia (Joulin et al., 2017), y iii) el ajuste de los modelos lingüísticos previamente entrenados sobre los datos lingüísticos pertinentes, seguido de una capacitación supervisada, funciona bien en esta tarea.', 'fr': "Dans cet article, nous donnons un aperçu de la tâche partagée WNUT-2020 sur l'identification des Tweets informatifs en anglais sur la COVID-19. Nous décrivons comment nous construisons un corpus de 10 000 Tweets et organisons les phases de développement et d'évaluation de cette tâche. En outre, nous présentons également un bref résumé des résultats obtenus à partir des soumissions d'évaluation finale du système de 55 équipes, constatant que (i) de nombreux systèmes obtiennent de très hautes performances, jusqu'à 0,91 score F1, (ii) la majorité des soumissions obtiennent des résultats nettement supérieurs à ceux du FastText de base (Joulin et al., 2017), et (iii) la mise au point de modèles linguistiques préformés sur des données linguistiques pertinentes, suivie d'une formation supervisée, donne de bons résultats dans cette tâche.", 'pt': 'Neste artigo, fornecemos uma visão geral da tarefa compartilhada do WNUT-2020 na identificação de tweets informativos sobre COVID-19 em inglês. Descrevemos como construímos um corpus de 10 mil Tweets e organizamos as fases de desenvolvimento e avaliação dessa tarefa. Além disso, também apresentamos um breve resumo dos resultados obtidos nas submissões de avaliação final do sistema de 55 equipes, constatando que (i) muitos sistemas obtêm desempenho muito alto, até 0,91 pontuação F1, (ii) a maioria das submissões atinge substancialmente resultados mais altos do que o fastText de linha de base (Joulin et al., 2017) e (iii) o ajuste fino de modelos de linguagem pré-treinados em dados de linguagem relevantes seguidos de treinamento supervisionado tem um bom desempenho nessa tarefa.', 'ja': '本稿では、新型コロナウイルス感染症(COVID -19)に関する有益な英語ツイートの特定に関するWNUT -2020共有タスクの概要を説明します。10 Kツイートのコーパスを構築し、このタスクの開発と評価フェーズを整理する方法について説明します。さらに、55チームの最終的なシステム評価提出物から得られた結果の簡単な要約も提示し、(i)多くのシステムが0.91 F 1スコアまでの非常に高いパフォーマンスを得ていること、(ii)提出物の大部分がベースラインのfastTextよりも実質的に高い結果を達成していること（ Joulin et al., 2017 ）、および(iii)関連する言語データに基づいて事前にトレーニングされた言語モデルを微調整した後、監督下のトレーニングがこのタスクで優れたパフォーマンスを発揮することを発見した。', 'hi': 'इस पेपर में, हम सूचनात्मक कोविड -19 अंग्रेजी ट्वीट्स की पहचान पर WNUT-2020 साझा कार्य का अवलोकन प्रदान करते हैं। हम वर्णन करते हैं कि हम 10K Tweets के एक कॉर्पस का निर्माण कैसे करते हैं और इस कार्य के लिए विकास और मूल्यांकन चरणों को व्यवस्थित करते हैं। इसके अलावा, हम 55 टीमों के अंतिम सिस्टम मूल्यांकन प्रस्तुतियों से प्राप्त परिणामों का एक संक्षिप्त सारांश भी प्रस्तुत करते हैं, यह पाते हुए कि (i) कई प्रणालियां बहुत उच्च प्रदर्शन प्राप्त करती हैं, 0.91 एफ 1 स्कोर तक, (ii) अधिकांश प्रस्तुतियां बेसलाइन फास्टटेक्स्ट (जूलिन एट अल।', 'ru': 'В этой статье мы приводим обзор совместной задачи WNUT-2020 по выявлению информативных английских твитов о COVID-19. Мы описываем, как мы создаем корпус из 10K твитов и организуем этапы разработки и оценки для этой задачи. Кроме того, мы также представляем краткое резюме результатов, полученных из итоговых представлений по оценке системы 55 команд, обнаруживая, что (i) многие системы получают очень высокую производительность, до 0,91 балла F1, (ii) большинство представлений достигают значительно более высоких результатов, чем исходный fastText (Joulin et al., 2017), и (iii) тонкая настройка предварительно обученных языковых моделей на соответствующие языковые данные с последующим контролируемым обучением хорошо справляется с этой задачей.', 'zh': '本文,吾概述WNUT-2020识信丰COVID-19英语推文之共同任务。 述构包 10000 推文之语料库,结此开评。 此外简总55团队之终始,见(i)诸统之极高者,高达0.91 F1分数,(ii)多言之显于基线fastText(Joulin等,2017)及(iii)以言语数微调预训练之言,然后督练之,于此为良。', 'ga': 'Sa pháipéar seo, cuirimid forbhreathnú ar fáil ar thasc roinnte WNUT-2020 maidir le Tweets Béarla faisnéiseach COVID-19 a shainaithint. Déanaimid cur síos ar an gcaoi a ndéanaimid corpas de 10K Tweets agus ar na céimeanna forbartha agus measúnaithe don tasc seo a eagrú. Ina theannta sin, cuirimid i láthair freisin achoimre ghairid ar thorthaí a fuarthas ó na haighneachtaí meastóireachta córais deiridh de 55 fhoireann, ag fáil amach (i) go bhfuil feidhmíocht an-ard ag go leor córas, suas go dtí 0.91 scór F1, (ii) go mbaineann formhór na n-aighneachtaí amach go substaintiúil. torthaí níos airde ná an bhunlíne fastText (Joulin et al., 2017), agus (iii) mionchoigeartú ar mhúnlaí teanga réamhoilte ar shonraí teanga ábhartha agus ina dhiaidh sin tá oiliúint faoi mhaoirseacht ag feidhmiú go maith sa tasc seo.', 'el': 'Σε αυτή την εργασία, παρέχουμε μια επισκόπηση της κοινής εργασίας για τον προσδιορισμό ενημερωτικών αγγλικών tweets. Περιγράφουμε πώς κατασκευάζουμε ένα σώμα από 10Κ και οργανώνουμε τις φάσεις ανάπτυξης και αξιολόγησης για αυτό το έργο. Επιπλέον, παρουσιάζουμε επίσης μια σύντομη περίληψη των αποτελεσμάτων που ελήφθησαν από τις τελικές υποβολές αξιολόγησης συστήματος των 55 ομάδων, διαπιστώνοντας ότι (i) πολλά συστήματα επιτυγχάνουν πολύ υψηλές επιδόσεις, μέχρι 0.91 βαθμολογία, (ii) η πλειοψηφία των υποβολών επιτυγχάνει σημαντικά υψηλότερα αποτελέσματα από το βασικό κείμενο (κ.α., 2017), και iii) ο συντονισμός των προ-εκπαιδευμένων γλωσσικών μοντέλων σχετικά με τα σχετικά γλωσσικά δεδομένα και η παρακολούθηση της εποπτευόμενης εκπαίδευσης αποδίδει καλά στο έργο αυτό.', 'ka': 'ამ დომენტში ჩვენ გავაკეთებთ ინფორმატიური COVID-19 ინგლისური Tweets-ის განსაზღვრებაზე WNUT-2020-ის გაყოფილი საქმენტი. ჩვენ აღწერეთ, როგორ ვაკეთებთ 10K Tweets-ის კორპუსს და დავაკეთებთ განვითარების და განსაზღვრების ფაზები ამ დავალებისთვის. დამატებით, ჩვენ ასევე მივიღეთ კრეტური შესაძლებლობას, რომელიც 55 ჯგუფის ბოლო სისტემის შესაძლებლობადან მივიღეთ შესაძლებლობა, რომელიც i) ბევრი სისტემის შესაძლებლობა ძალიან დიდი შესაძლებლობა, რომელიც 0,91 F1 შესაძლებლობად, ii) შესაძლებლობის უფრო დი და iii) წარმოადგენებული წარმოადგენებული ენის მოდელების შესახებ მსგავსი ენის მონაცემებზე, რომლებიც შემდეგ მონაცემებული განაცემების შემდეგ ამ დავალებაში კარგი გავაკ', 'hu': 'Ebben a tanulmányban áttekintést nyújtunk a WNUT-2020 információs COVID-19 angol tweetek azonosításával kapcsolatos közös feladatáról. Leírjuk, hogyan építjük fel a 10K tweetekből álló korpuszt, és hogyan szervezzük meg a feladat fejlesztési és értékelési fázisait. Ezenkívül rövid összefoglalót mutatunk be az 55 csapat végső rendszerértékelési beadványaiból származó eredményekről, amelyek megállapítása szerint (i) sok rendszer nagyon magas teljesítményt ér el, akár 0,91 F1 pontszámot, (ii) a beadványok többsége lényegesen magasabb eredményeket ér el, mint a kiindulási gyorsszöveg (Joulin et al., 2017), és iii. az előképzett nyelvi modellek finomhangolása a releváns nyelvi adatokra, majd a felügyelt képzés következtében jól teljesíti ezt a feladatot.', 'it': "In questo articolo, forniamo una panoramica del compito condiviso WNUT-2020 sull'identificazione dei Tweet informativi in inglese COVID-19. Descriviamo come costruiamo un corpus di tweet 10K e organizziamo le fasi di sviluppo e valutazione per questo compito. Inoltre, presentiamo anche una breve sintesi dei risultati ottenuti dalle presentazioni finali di valutazione del sistema di 55 squadre, scoprendo che (i) molti sistemi ottengono prestazioni molto elevate, fino a 0,91 punteggio F1, (ii) la maggior parte delle presentazioni ottiene risultati sostanzialmente superiori rispetto al fastText di base (Joulin et al., 2017), e iii) la messa a punto di modelli linguistici pre-formati sui dati linguistici pertinenti seguita da una formazione supervisionata svolge un buon ruolo in questo compito.", 'lt': 'Šiame dokumente pateikiama bendros WNUT-2020 užduoties dėl informacinių COVID-19 anglų dviejų tinklų nustatymo apžvalga. Apibrėžiame, kaip sukuriame 10K Tweetų korpusą ir organizuojame šios užduoties kūrimo ir vertinimo etapus. Be to, taip pat pateikiame trumpą rezultatų, gautų i š galutinių 55 komandų sistemos vertinimo paraiškų, santrauką, nustatydami, kad i) daugelis sistemų gauna labai didelius rezultatus, iki 0,91 F1 balas, ii) dauguma paraiškų gauna gerokai didesnius rezultatus nei pradinis fastText (Joulin et al., 2017), - ir iii) tiksliai pritaikyti iš anksto parengtus kalbų modelius atitinkamų kalbų duomenų atžvilgiu, po kurių atliekamas prižiūrimas mokymas, atlieka šią užduotį.', 'ms': 'Dalam kertas ini, kami menyediakan pandangan ringkasan tugas kongsi WNUT-2020 mengenai pengenalan Tweets bahasa Inggeris COVID-19 maklumat. Kami menggambarkan bagaimana kita membina mayat 10K Tweets dan mengatur fasa pembangunan dan penilaian untuk tugas ini. In addition, we also present a brief summary of results obtained from the final system evaluation submissions of 55 teams, finding that (i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the majority of the submissions achieve substantially higher results than the baseline fastText (Joulin et al., 2017), - dan (iii) menyesuaikan model bahasa yang dilatih-dilatih dengan baik pada data bahasa yang berkaitan diikuti oleh pelatihan yang diawasi berjalan dengan baik dalam tugas ini.', 'mk': 'Во овој документ, ние обезбедуваме преглед на заедничката задача на ВНУТ-2020 за идентификација на информативните КоВИД-19 англиски твитови. Опишуваме како изградуваме тело од 10.000 Твитови и организираме фази на развој и евалуација за оваа задача. Покрај тоа, ние, исто така, претставуваме кратко преглед на резултатите добиени од финалните поднесувања за проценка на системот од 55 тимови, откривајќи дека (i) многу системи добиваат многу високи резултати, до 0,91 оценка Ф1, (ii) мнозинството од поднесувањата постигнуваат значително повисоки резултати од базата на брзо текст ( И (iii) финетизирањето на предобучените јазички модели на релевантните јазички податоци, по кои следи надгледуваната обука, добро оди во оваа задача.', 'ml': 'ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d വിവരങ്ങള്\u200d കോവിഡ്-19 ഇംഗ്ലീഷ് ടൂട്ടുകളുടെ തിരിച്ചറിയുന്നതിനെക്കുറിച്ച് വിവരങ്ങള്\u200d വിശേഷിച്ചു നമ്മള്\u200d വിവരിക്കുന്നത് എങ്ങനെയാണ് നമ്മള്\u200d 10K ടൂട്ടികളുടെ കോര്\u200dപ്പസ് ഉണ്ടാക്കുന്നത് എന്നിട്ട് ഈ ജോലിക്ക് വേണ്ടി  In addition, we also present a brief summary of results obtained from the final system evaluation submissions of 55 teams, finding that (i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the majority of the submissions achieve substantially higher results than the baseline fastText (Joulin et al., 2017), (ഐ) പ്രധാനപ്പെട്ട ഭാഷ വിവരങ്ങളില്\u200d മുമ്പ് പരിശീലന മോഡലുകള്\u200d പ്രധാനപ്പെടുത്തുന്നു. പിന്നീട് നിരീക്ഷിക്കപ്പെ', 'mt': 'F’dan id-dokument, nagħtu ħarsa ġenerali lejn il-kompitu kondiviż tad-WNUT-2020 dwar l-identifikazzjoni ta’ Tweets informativi COVID-19 Ingliż. Aħna niddeskrivu kif nibnu korpus ta’ 10K Tweets u jorganizzaw il-fażijiet ta’ żvilupp u evalwazzjoni għal dan il-kompitu. Barra minn hekk, qed nippreżentaw ukoll sommarju qasir tar-riżultati miksuba mis-sottomissjonijiet final i tal-evalwazzjoni tas-sistema ta’ 55 tim, li jsibu li (i) ħafna sistemi jiksbu prestazzjoni għolja ħafna, sa punteġġ F1 ta’ 0.91, (ii) il-maġġoranza tas-sottomissjonijiet jiksbu riżultati sostanzjalment ogħla mil-linja bażi fastText (Joulin et al., 2017), ) u (iii) mudelli lingwistiċi mħarrġa minn qabel għall-irfinar fuq dejta lingwistika rilevanti segwiti minn taħriġ sorveljat iwettqu tajjeb f’dan il-kompitu.', 'mn': 'Энэ цаасан дээр бид WNUT-2020 оны мэдээллийн COVID-19 Англи Tweets-ын тодорхойлолтын тухай хуваалцааны талаар ярьж байна. Бид 10K tweets-ийн корпус хэрхэн зохион байгуулж, хөгжлийн, үнэлгээний дасгалыг хэрхэн зохион байгуулдаг талаар тайлбарлаж байна. Мөн бид 55 баг хамгийн сүүлийн системийн оюутнуудаас гарсан үр дүнг бага хэмжээгээр илтгэнэ. i) олон системүүд үнэхээр өндөр үр дүнг гаргадаг, 0.91 F1 оноо хүртэл, ii) олон нь суурь хэмжээний FastText (Joulin et al., 2017 оны суурь хэмжээнээс их өндөр үр дүнг гаргадаг. (iii) холбоотой хэл өгөгдлийн талаар сургалтын өмнө сургалтын загваруудыг сайжруулах боломжтой болгодог.', 'no': 'I denne papiret gjev vi ei oversikt over delt oppgåva WNUT-2020 om identifiseringa av informativ COVID-19 engelsk tweets. Vi beskriver korleis vi konstruerer ein korpus av 10K Tweets og organiserer utviklingsfase og evalueringa for denne oppgåva. I tillegg presenterer vi også ein kort sammendrag av resultatene som er fått frå dei siste undersøkingane av systemevalueringa av 55 grupper, og finn at i) mange systemer får veldig høg utvikling, opp til 0,91 F1- poeng, ii) dei fleste av undersøkingane får mykje høgare resultat enn baseline fastText (Joulin et al., 2017), og iii) finnstilling av føretrainerte språk-modeller på relevant språk-data etter oversikte opplæring utfører godt i denne oppgåva.', 'kk': 'Бұл қағазда, біз WNUT-2020 жалпы COVID-19 ағылшын tweets тізімін анықтау үшін бөлікті тапсырманы қарап береміз. Біз 10K tweet корпусын қалай құру және осы тапсырманың жасау және оқиға деңгейін қалай баптаймыз. Сонымен қатар, біз 55 топтардың соңғы жүйелік оқиғаларынан келтірілген нәтижелердің қысқа жазылуын таңдаймыз. i) көп жүйелердің оқиғалары 0,91 F1 нәтижесіне дейін, ii) көпшіліктерінің көпшілігі негізгі мәтіннен ең жоғары нәтижелерді жеткізеді. Осы тапсырманың қасиетті тілдер деректерінің алдын- ала оқылған тіл үлгілерін жақсы түзету үлгілері.', 'pl': 'W niniejszym artykule przedstawiamy przegląd wspólnego zadania WNUT-2020 dotyczącego identyfikacji informacyjnych tweetów angielskich COVID-19. Opisujemy, w jaki sposób budujemy korpus 10K Tweetów oraz organizujemy fazy rozwoju i ewaluacji tego zadania. Ponadto przedstawiamy również krótkie podsumowanie wyników uzyskanych z końcowej oceny systemu zespołów 55, stwierdzając, że (i) wiele systemów osiąga bardzo wysoką wydajność, do 0.91 F1 wyników, (ii) większość zgłoszeń osiąga znacznie wyższe wyniki niż bazowy fastText (Joulin et al., 2017), oraz iii) dostosowanie wstępnie przeszkolonych modeli językowych na podstawie odpowiednich danych językowych, a następnie szkolenie nadzorowane, sprawdza się w tym zadaniu.', 'si': 'මේ පැත්තට, අපි WNAT-2020යි වැදගත් වැඩක් ගැන පරීක්ෂණයක් ලැබෙනවා ඉංග්\u200dරීසි ට්විට් වල තොරතුරු ක්\u200dරියාව අඳුරණ අපි කොහොමද අපි 10K ට්වීට් වලින් කොර්පුස් හදන්නේ කියලා ප්\u200dරවේශනය සහ අවශ්\u200dයාවක් සංයෝජනය කරනවා මේ වැඩේ ව ඒ වගේම, අපි අන්තිම පද්ධතිය පද්ධතිය පරීක්ෂණය 55 කණ්ඩායම් වලින් ප්\u200dරතිචාරයක් තියෙන්නේ, අන්තිම පද්ධතිය ලොකු ප්\u200dරතිචාරයක් තියෙන්නේ, අන්තිම පද්ධතිය ලොකු ප්\u200dරතිචාරයක සහ (Ii) ප්\u200dරධානය කරපු භාෂාව ප්\u200dරධානය කරපු භාෂාව ප්\u200dරධානයක් සඳහා සම්බන්ධ භාෂාව දත්ත පස්සෙන් පස්ස', 'ro': 'În această lucrare, oferim o imagine de ansamblu a sarcinii comune WNUT-2020 privind identificarea tweeturilor informative în limba engleză COVID-19. Descriem modul în care construim un corpus de tweets 10K și organizăm fazele de dezvoltare și evaluare pentru această sarcină. În plus, prezentăm, de asemenea, un scurt rezumat al rezultatelor obținute din depunerile finale de evaluare a sistemului de 55 de echipe, constatând că (i) multe sisteme obțin performanțe foarte ridicate, până la 0,91 punctaj F1, (ii) majoritatea depunerilor obțin rezultate substanțial mai mari decât cele de referință fast Text (Joulin et al., 2017), și (iii) ajustarea fină a modelelor lingvistice pre-instruite pe datele lingvistice relevante, urmată de formarea supravegheată, se descurcă bine în această sarcină.', 'sr': 'U ovom papiru pružamo pregled zajedničkog zadatka WNUT-2020 o identifikaciji informativnih COVID-19 engleskih Tweets. Opišemo kako izgradimo korpus 10K Tweets i organizujemo faze razvoja i procjene za ovaj zadatak. Osim toga, takođe predstavljamo kratak sažetak rezultata koji su dobili od poslednjih podataka ocjene sistema 55 timova, otkrivajući da i) mnogi sistemi dobijaju veoma visoke funkcije, do 0,91 F1 rezultata, ii) većina podataka postiže značajno veći rezultat od početnog fastText (Joulin et al., 2017), i iii) predobučenih jezičkih modela o odgovarajućim jezičkim podacima koji su praćeni nadzornim obukama dobro održavaju u ovom zadatku.', 'so': 'Warqaddan, waxaynu ka qornaa warqada WNUT-2020 oo lagu sharaxay aqoonsiga macluumaadka COVID-19 Tweetka Ingiriiska. Waxaynu qoraynaa sida aan u dhisno 10K Tweet, waxaana u qabanqaabinaynaa fasalooyinka horumarinta iyo qiimeynta shaqadaas. Intaas waxaa dheer oo aan soo bandhignaa kooxaha ugu dambeeya qiimeynta nidaamka ee 55 koox, waxaynu ogaanaynaa in nidaamka badan ay sameyn karaan shaqo aad u weyn, ilaa 0.91 F1 scoro, (i i) kooxaha ugu badan waxay heli karaan resultooyin aad u sareeya qoraalka soogsiga (Joulin et, 2017),  and (iii) fine-tuning pre-trained language models on relevant language data followed by supervised training performs well in this task.', 'ta': 'இந்த காகிதத்தில், நாம் WNUT-2020 பகிர்ந்த பணியை கொடுக்கிறோம் தகவல் COVID-19 ஆங்கிலத்தின் குறிப்பிட்ட காண்பிக்கையில்  நாம் எவ்வாறு 10K டுவிட்டர்களை உருவாக்குகிறோம் மற்றும் இந்த பணிக்கான முன்னேற்றம் மற்றும் மதிப்பிடும் குறிப்பு அதற்கும் மேலும், நாம் 55 குழுக்களின் கடைசி முறைமையிலிருந்து கிடைக்கப்பட்ட முடிவுகளின் சிறிய சுருக்கமாக கொண்டுள்ளோம். நாம் (i) பல அமைப்புகள் மிகவும் உயர்ந்த செயல்பாட்டை பெறுகிறார்கள்  தொடர்புடைய மொழி தரவுகளில் முன் பயிற்சி மொழி மாதிரிகளை பின்பற்றி கண்காணிக்கப்பட்ட பயிற்சி இந்த பணியில் நன்றாக செய்க', 'sv': 'I denna uppsats ger vi en översikt över WNUT-2020 delade uppgift om identifiering av informativa COVID-19 engelska tweets. Vi beskriver hur vi konstruerar en korpus av 10K Tweets och organiserar utvecklings- och utvärderingsfaserna för denna uppgift. Dessutom presenterar vi en kort sammanfattning av resultat som erhållits från 55 teams slutliga systemutvärderingar, där vi konstaterar att (i) många system uppnår mycket hög prestanda, upp till 0,91 F1 poäng, (ii) majoriteten av inlämningarna uppnår betydligt högre resultat än baslinjens snabbText (Joulin et al., 2017), och iii) finjustering av färdigutbildade språkmodeller på relevanta språkdata följt av övervakad utbildning fungerar väl i denna uppgift.', 'ur': 'اس کاغذ میں ہم نے WNUT-2020 کے مشترک کام کے بارے میں اطلاعات COVID-19 انگلیسی ٹویٹوں کی شناسایی کے بارے میں ایک نظر پیش کیا ہے. ہم کس طرح تفصیل دیتے ہیں کہ ہم 10K ٹویٹ کے ایک کورپوس بناتے ہیں اور اس کام کے لئے توسعہ اور ارزیابی فوزوں کو سازماتے ہیں۔ اس کے علاوہ ہم نے 55 ٹیموں کے پائیل سیستم کی ارزیابی کے مطابق پائیں گئی نتائج کی تھوڑی سیم جمع کی تھوڑی سیم جمع کی تھوڑی سیم جمع کی تھوڑی سیم جمع کی تھی، یہ دیکھ رہے ہیں کہ (i) بہت سی سیستم بہت اچھی کارزی حاصل کرتی ہیں، 0.91 F1 اسکور تک، ii) مطابقہ کی اکثریت بنسلین فاسٹ ٹی اور (iii) اس کام میں اچھی طرح تحقیق کی تدبیر کی جاتی ہے۔', 'uz': "Bu qogʻozda, biz haqiqida xabar COVID-19 Ingliz Twitterlarini aniqlashga WNUT-2020 bilan birlashtirilgan vazifani ko'rinishimiz mumkin. Biz bu vazifa uchun taʼminlovchi va qiymatni qanday tuzishni anglatamiz. Ko'pchilik, 55 guruhning oxirgi qiymatlaridan olingan natijalarni qisqaruvchi qisqartmalamiz. U ko'pchilik tizimlarning 0.91 F1 scori ko'pchiligi ko'pchiligi ko'pchiligi qo'shimcha matn (Joulin et, 2017) asosiy matn (Joulin et). (iii) ma'lumot tili haqida o'rganishdan oldin tilning modellari, keyin taʼminlovchi taʼminlovchi soʻzlar bu vazifani bajaradi.", 'vi': 'Trong tờ báo này, chúng tôi cung cấp một thông tin về công việc chia sẻ của WGiờ-2020 về việc nhận dạng thông tin CO-19 người Anh Tweet. Chúng tôi mô tả cách chúng tôi xây dựng tập đoàn 10K Tweet rồi tổ chức các giai đoạn phát triển và đánh giá cho nhiệm vụ này. Thêm vào đó, chúng tôi cũng đưa ra một bản tóm tắt kết quả từ kết quả đánh giá hệ thống cuối cùng của một đội đi ền kinh, cho thấy rằng (i) nhiều hệ thống đạt được hiệu suất rất cao, cho đến 0.1 số điểm, thứ hai) phần lớn các tài liệu đều đạt được kết quả cao hơn nhiều so với cơ sở cấu hình (Joulin et al., tê 7) và (tức là) những mô hình ngôn ngữ được đào tạo cẩn thận trên dữ liệu ngôn ngữ liên quan sau khi được huấn luyện giám sát đạt đạt đạt đạt đạt đạt tốt trong nhiệm vụ này.', 'bg': 'В настоящата статия представяме общ преглед на споделената задача за идентифициране на информативни английски туитове. Описваме как изграждаме корпус от 10К туитове и организираме фазите на разработване и оценка на тази задача. В допълнение, ние също така представяме кратко резюме на резултатите, получени от окончателната оценка на системата на 55 екипа, като констатираме, че (i) много системи получават много висока производителност, до 0,91 резултат, (ii) по-голямата част от подадените резултати постигат значително по-високи резултати от базовия фастТекст (2017 г.). и iii) фината настройка на предварително обучените езикови модели на съответните езикови данни, последвана от обучение под надзор, се справя добре в тази задача.', 'nl': 'In dit artikel geven we een overzicht van de WNUT-2020 gedeelde taak over het identificeren van informatieve COVID-19 Engelse Tweets. We beschrijven hoe we een corpus van 10K Tweets opbouwen en organiseren de ontwikkelings- en evaluatiefasen voor deze taak. Daarnaast presenteren we ook een korte samenvatting van de resultaten verkregen uit de definitieve systeemevaluatie inzendingen van 55 teams, waarbij we vaststellen dat (i) veel systemen zeer hoge prestaties behalen, tot 0.91 F1 score, (ii) het merendeel van de inzendingen aanzienlijk hogere resultaten oplevert dan de basisfastText (Joulin et al., 2017), en iii) het finetunen van vooraf getrainde taalmodellen op relevante taalgegevens gevolgd door begeleide training presteert goed in deze taak.', 'hr': 'U ovom papiru pružamo pregled zajedničkog zadatka WNUT-2020 o identifikaciji informativnih COVID-19 engleskih Tweets. Opišemo kako izgradimo korpus 10K Tweets i organiziramo faze razvoja i procjene za ovaj zadatak. Osim toga, također predstavljamo kratki sažetak rezultata dobivenih od isporuke konačne procjene sustava 55 timova, otkrivajući da i) mnogi sustavi dobivaju vrlo visoke učinke, do 0,91 F1 rezultata, ii) većina podataka postiže značajno veći rezultat od početnog fastText (Joulin et al., 2017), i iii) ispravno određivanje predobučenih jezičkih modela o relevantnim jezičkim podacima nakon nadzorne obuke dobro provede u ovom zadatku.', 'da': 'I denne artikel giver vi et overblik over WNUT-2020 delte opgave om identifikation af informative COVID-19 engelske tweets. Vi beskriver, hvordan vi konstruerer et korpus af 10K tweets og organiserer udviklings- og evalueringsfaserne til denne opgave. Derudover præsenterer vi også et kort resumé af resultater opnået fra de endelige systemevalueringsindsendelser fra 55 hold, hvor det konstateres, at (i) mange systemer opnår meget høj ydeevne, op til 0,91 F1 score, (ii) størstedelen af indsendelserne opnår betydeligt højere resultater end den oprindelige fastText (Joulin et al., 2017), og iii) finjustering af præuddannede sprogmodeller på relevante sprogdata efterfulgt af overvåget uddannelse fungerer godt i denne opgave.', 'de': 'In diesem Beitrag geben wir einen Überblick über die gemeinsame Aufgabe WNUT-2020 zur Identifizierung informativer COVID-19 englischer Tweets. Wir beschreiben, wie wir einen Korpus aus 10K Tweets konstruieren und die Entwicklungs- und Evaluierungsphasen für diese Aufgabe organisieren. Darüber hinaus stellen wir auch eine kurze Zusammenfassung der Ergebnisse vor, die aus den endgültigen Systemauswertungsanträgen von 55-Teams gewonnen wurden, wobei festgestellt wird, dass (i) viele Systeme sehr hohe Leistungen erzielen, bis zu 0.91 F1 Score, (ii) die Mehrheit der Einreichungen wesentlich höhere Ergebnisse erzielen als die Basiswerte fastText (Joulin et al., 2017), und iii) die Feinabstimmung vortrainierter Sprachmodelle auf relevanten Sprachdaten, gefolgt von überwachten Schulungen, leistet bei dieser Aufgabe gute Ergebnisse.', 'ko': '본고에서는 정보성 코로나 영어 트윗 인식에 대한 WNUT-2020의 공유 임무를 개괄적으로 기술했다.우리는 10K개의 트윗을 포함하는 자료 라이브러리를 구축하는 방법과 이 임무의 개발과 평가 단계를 어떻게 조직하는지를 설명했다.또한 55개 팀이 제출한 최종 시스템 평가 결과를 간략하게 요약한 결과 (i) 많은 시스템이 매우 높은 성능을 얻었고 F1 점수는 0.91점에 달했다. (ii) 대부분의 제출 결과는 기선 빠른 텍스트(Joulin 등, 2017년)보다 훨씬 높았다.(iii) 관련 언어 데이터에 따라 미리 훈련된 언어 모델을 미세하게 조정한 다음에 감독 훈련을 실시하여 이 임무에서 양호한 모습을 보였다.', 'id': 'Dalam kertas ini, kami menyediakan panjang dari tugas bersama WNUT-2020 mengenai identifikasi informatif COVID-19 Tweets Inggris. Kami menggambarkan bagaimana kita membangun mayat 10K Tweets dan mengatur fase pengembangan dan evaluasi untuk tugas ini. Selain itu, kami juga mempersembahkan ringkasan singkat dari hasil yang diperoleh dari penemuan sistem akhir dari 55 tim, menemukan bahwa (i) banyak sistem mendapatkan prestasi yang sangat tinggi, sampai skor F1 0,91, (ii) kebanyakan penemuan mencapai hasil yang jauh lebih tinggi dari dasar FastText (Joulin et al., 2017), Dan (iii) fine-tuning pre-trained language models pada data bahasa relevan diikuti oleh pelatihan yang diawasi berhasil dalam tugas ini.', 'fa': 'در این کاغذ، ما یک نگاهی از کار مشترک WNUT-2020 در مورد شناسایی توئیت انگلیسی COVID-19 اطلاعات پیشنهاد می کنیم. ما توصیف می کنیم که چگونه یک جسد از ۱۰ کیلومتر Tweets ساخته می کنیم و مراحل توسعه و ارزیابی برای این کار را سازمان می کنیم. در addition, we also present a brief summary of results obtained from the final evaluation of system assessment of 55 teams, finding that (i) many systems obtain very high performance, up to 0.91 F1 score, (ii) most of the submissions achieve substantially higher results than the baseline fastText (Joulin et al., 2017), و (iii) مدل\u200cهای پیش آموزش زبان\u200cها را در مورد داده\u200cهای زبان\u200cهای مربوط به تغییر داده می\u200cشود که توسط آموزش\u200cهای مراقبت\u200cشده در این کار خوب انجام می\u200cدهد.', 'sw': 'Katika karatasi hii, tunatoa mtazamo wa kazi ya WNUT-2020 zilizoshirikiana na WNUT-2020 kwa kutambua ujumbe wa Twita za Kiingereza za za COVID-19. Tunaelezea jinsi tunavyojenga makampuni ya Twita 10K na kuandaa hatua za maendeleo na tathmini kwa kazi hii. Zaidi ya hayo, pia tunatoa muhtasari mfupi wa matokeo yaliyopatikana kutoka kwenye utafiti wa mwisho wa mfumo wa timu 55, tunagundua kuwa (I) mifumo mingi hupata ufanisi mkubwa zaidi, hadi score 0.91 F1, (i i) jumbe kubwa ya mawasiliano hayo hupata matokeo makubwa zaidi kuliko matokeo ya mstari wa kwanza (Joulin et, 2017), na (iii) modeli nzuri za lugha zilizofunzwa kabla zinazohusu data zinazohusiana na lugha zinazofuatiwa na mafunzo yanafanya vizuri katika kazi hii.', 'af': "In hierdie papier verskaf ons 'n oorskou van die WNUT-2020 gedeelde taak oor die identifikasie van informatiewe COVID-19 Engelske tweets. Ons beskrywe hoe ons 'n korpus van 10K tweets konstrukteer en organiseer die ontwikkeling en evalueringsfase vir hierdie taak. In addition, we also present a short summary of results obtained from the final system evaluation submissions of 55 teams, finding that (i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the majority of the submissions achieve substantially higher results than the baseline fastText (Joulin et al., 2017), en (iii) fin-tuning voor-onderwerp taal modele op relevante taal data volg deur onderwerp onderwerp wat goed in hierdie taak uitvoer.", 'sq': 'Në këtë letër, ne ofrojmë një përmbledhje të detyrës së përbashkët të WNUT-2020 mbi identifikimin e informacionit COVID-19 Tweets angleze. Ne përshkruajmë si ne ndërtojmë një trup prej 10K Tweets dhe organizojmë fazat e zhvillimit dhe vlerësimit për këtë detyrë. Përveç kësaj, ne paraqesim gjithashtu një përmbledhje të shkurtër të rezultateve të përfunduara nga paraqitjet përfundimtare të vlerësimit të sistemit të 55 ekipave, duke gjetur se (i) shumë sisteme fitojnë performancë shumë të lartë, deri në 0.91 pikë F1, (ii) shumica e paraqitjeve arrijnë rezultate thelbësisht më të larta se baza e FastText (Joulin et al., 2017), - dhe (iii) rregullimi i modeleve të gjuhës së paratrajnuar mbi të dhënat e duhura të gjuhës pasuar nga trainimi i mbikqyrur funksionon mirë në këtë detyrë.', 'tr': "Bu kagyzda WNUT-2020'yň informatyýaly COVID-19 Iňlisçe tweetlerini tanyşdyrmak barada ylalaşyk zady bardyk. Biz 10K Tweet'iň korpusyny nädip inşa etýändigimizi we çykyş we çykyş phaselerini bu işiň üçin düzenledigimizi tassyklaýarys. Mundan hem biz olaryň soňky sistemiň çykyş şeklinde 55 topar tarapyndan alan gyzykly netijeleri görkeýäris, şol(i) birnäçe sistemleriň üst performans bolup 0,91 F1 powt we ii) süýgülileriniň köp bölegi baseline fastText (Joulin et al., 2017-nji ýyldan gowurak netijeleri bar. Ii) ünsli bilim maglumatynda gözlenen okuwçylar üçin ön-okuwçylan dil nusgalaryny gowy düzenleyin.", 'am': 'በዚህ ገጾች ውስጥ የWNUT-2020 የኢንግሊዝኛ ትዊተሮች በማግኘት ላይ የተካፈለውን ስራ አዋጅ እናደርጋለን፡፡ የ10K ትዊተሮችን እንዴት እንደሠራን እናሳውቃለን ለዚህም ስራ የግንኙነቱን እና አዋቂዎችን እናስቀምጣለን፡፡ በተጨማሪም፣ የ55 ጭፍሮች የፍሬዎችን አካሄድ አቀራቢ አቀራቢ እናደርጋለን፡፡ እና (iii) ለቋንቋ ዳታዎች የተጠቃሚ የፊተኛ ቋንቋ ሞዴላዎችን በመስጠት በተጠበቀው ትምህርት በዚህ ስራ ውስጥ መልካም ያደርጋል፡፡', 'bn': 'এই কাগজটিতে আমরা বিভিন্ন তথ্য কোভিড-১৯ ইংরেজী টুইটের পরিচিতি নিয়ে উইনুট-২০০ ভাগাভাগি কাজের উপর একটি পর্যবেক্ষণ প্রদান করি। আমরা বর্ণনা করি কিভাবে আমরা ১০০০০ টুইটারের একটি কোর্পাস তৈরি করি এবং এই কাজের জন্য উন্নয়ন এবং মূল্যায়ন ক্ষেত্রের আয়োজন করি। এছাড়াও আমরা ৫৫ টি দলের শেষ সিস্টেমের মূল্যের মূল্যের ফলাফলের সামান্য সংক্ষেপ উপস্থাপন করেছি, আবিষ্কার করেছি যে (I) অনেক সিস্টেম খুব ব বেশী করে পাওয়া যায়, প্রায় ০. ৯১ এফ১ স্কোর পর্যন্ত, ২) প এবং (আই) প্রশিক্ষণের পূর্বে প্রশিক্ষিত ভাষার মডেল সম্পর্কিত ভাষার তথ্য নিয়ে সুন্দর ভাষার মডেল এই কাজে পর্যবেক্ষণ করা প্রশ', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք ԱՄՆ-2020-ի համագործակցած հանձնարարությունը COVID-19 անգլերեն թվիթերի հայտնաբերման մասին: Մենք նկարագրում ենք, թե ինչպես ենք կառուցում 10K թվիթերի մարմին և կազմակերպում այս խնդրի զարգացման և գնահատման փուլերը: Ավելին, մենք նաև ներկայացնում ենք 55 թիմի վերջնական համակարգի գնահատման արդյունքների կարճ համառոտագրություն, որի արդյունքում հայտնաբերվում է, որ i) շատ համակարգեր շատ բարձր արդյունք են ստանում, մինչև 0.91 F1 գնահատականը, երկու) ներկայացումների մեծամասնությունը շատ ավելի բարձր արդյունք է ստանում, քան հիմնական արագ տեքստը (Jo Այս խնդրում լավ է աշխատում նախապատրաստված լեզվի մոդելները, որոնց հետևում է վերահսկված ուսումնասիրությունը:', 'az': 'Bu kańüńĪzda, WNUT-2020 paylaŇüńĪlan iŇül…ôri informativ COVID-19 ńįngiliz…ô Tweets t…ôsdiql…ôm…ôsi bar…ôsind…ô t…ômin edirik. Biz 10K Tweets korpusu nec…ô inŇüa edirik v…ô bu iŇüin √ľ√ß√ľn t…ôdbirli v…ô deńüerlendirm…ô f…ôzil…ôrini organize edirik. Buna g√∂r…ô d…ô, 55 t…ôr…ôfl…ôrin sonuncu sistem deńüerlendirm…ôsind…ôn al ńĪnan sonu√ßlarńĪn qńĪsa bir summarńĪnńĪ da g√∂st…ôririk, ki i) √ßox sisteml…ôrin √ßox y√ľks…ôk performans alńĪr, 0,91 F1 d…ôr…ôc…ôsin…ô q…ôd…ôr, ii) t…ôr…ôfl…ôrin √ßoxu baseline fastText (Joulin et al., 2017) t…ôr…ôfl…ôrind…ôn √ßox y√ľks…ôk sonu√ßlarńĪnńĪ artńĪrar. ( iii ) bu iŇüd…ô t…ôhsil edilmiŇü dil veril…ônl…ôrin …ôvv…ôlc…ô t…ôhsil edilmiŇü dil modell…ôrini d√ľzg√ľn t…ôhsil edir.', 'bs': 'U ovom papiru pružamo pregled zajedničkog zadatka WNUT-2020 o identifikaciji informativnih COVID-19 engleskih Tweets. Opišemo kako izgradimo korpus od 10K Tweets i organizujemo faze razvoja i procjene za ovaj zadatak. Osim toga, također predstavljamo kratki sažetak rezultata dobivenih od isporuke konačne procjene sistema 55 timova, otkrivajući da i) mnogi sustavi dobijaju veoma visoke rezultate, do 0,91 F1 rezultata, ii) većina podataka postiže značajno veći rezultat od početnog fastText (Joulin et al., 2017), i iii) predobučenih jezičkih modela o relevantnim jezičkim podacima koji su praćeni nadzornim obukama dobro izvode u ovom zadatku.', 'ca': "En aquest paper, proporcionem una visió general de la tasca compartida WNUT-2020 sobre la identificació de Tweets informatius COVID-19 anglès. Descrivem com construïm un cos de 10.000 Tweets i organitzem les fases de desenvolupament i evaluació d'aquesta tasca. A més, també presentem un breu resum dels resultats obtenits a partir de les presentacions finals d'evaluació del sistema de 55 equips, trobant que i) molts sistemes obtenen un rendiment molt alt, fins a 0,91 puntuació F1, ii) la majoria de les presentacions obtenen resultats molt més alts que el fastText basal (Joulin et al., 2017),  and (iii) fine-tuning pre-trained language models on relevant language data followed by supervised training performs well in this task.", 'et': 'Käesolevas dokumendis anname ülevaate WNUT-2020 ühisest ülesandest COVID-19 inglise tweetide tuvastamisel. Kirjeldame, kuidas ehitame 10K Tweets korpuse ning korraldame selle ülesande arendus- ja hindamisetape. Lisaks esitame lühikokkuvõtte 55 meeskonna lõpliku süsteemi hindamise tulemustest, mis on saadud (i) paljud süsteemid saavutavad väga kõrge jõudluse, kuni 0,91 F1 skoori, (ii) enamik esitatud tulemusi saavutavad oluliselt kõrgemad kui algväärtuses fastText (Joulin jt., 2017). ja iii) eelnevalt koolitatud keelemudelite täpsustamine asjakohaste keeleandmete põhjal, millele järgneb järelevalveõpe, toimib selles ülesandes hästi.', 'cs': 'V tomto článku poskytujeme přehled sdíleného úkolu WNUT-2020 na identifikaci informativních anglických tweetů COVID-19. Popisujeme, jak sestavujeme korpus 10K Tweetů a organizujeme fáze vývoje a hodnocení pro tento úkol. Kromě toho představujeme stručné shrnutí výsledků získaných ze závěrečných hodnocení systémů 55 týmů, přičemž zjišťujeme, že (i) mnoho systémů dosahuje velmi vysokého výkonu až 0,91 F1 skóre, (ii) většina příspěvků dosahuje podstatně vyšších výsledků než základní fastText (Joulin et al., 2017), a iii) jemné ladění předškolených jazykových modelů na příslušných jazykových údajích, po němž následuje školení pod dohledem, vede k tomuto úkolu dobře.', 'fi': 'Tässä artikkelissa tarjoamme yleiskatsauksen WNUT-2020:n yhteiseen tehtävään, joka koskee informatiivisten COVID-19 englanninkielisten twiittien tunnistamista. Kuvaamme, miten rakennamme 10K Tweets-korpusen ja järjestämme tämän tehtävän kehitys- ja arviointivaiheet. Lisäksi esitämme lyhyen yhteenvedon 55 tiimin lopullisista järjestelmäarvioinneista saaduista tuloksista, joissa todetaan, että (i) monet järjestelmät saavuttavat erittäin korkean suorituskyvyn, jopa 0,91 F1-pisteen, (ii) suurin osa ehdotuksista saavuttaa huomattavasti korkeammat tulokset kuin perusaikataulun fastText (Joulin et al., 2017). ja iii) esikoulutettujen kielimallien hienosäätäminen asiaankuuluvien kielitietojen perusteella, jota seuraa valvottu koulutus, toimii tässä tehtävässä hyvin.', 'jv': 'Nang pemilih iki, kita nyenggawe akeh banter nggawe gerasi WNUT-2020 nggawe gerakan urip nggambar obah-obahan barang kelas corid-19 Tuts Inggris Awakdhéwé ngpisan piye basa gambaran mruput kanggo nyebuté nggawe barang 10 K Nambah, awak dhéwé beraksi lan akeh krêt operasi sing ditambah mengkar karo mulasai nggawe barang nggawe sistem sing wis ana luwih dumadhi, ngelarang (i) sistem sing gawe barang dhéwé bakal terus lanjut, sampek 0.9 F1 sing ngendisu, i i) sing beraksi sing ditambah sing bakal terus akeh dumadhi kaya basa sing wis luwih dumadhi, ditambah (Joulin et al, 2011) lan (iii) model sing paling-paling langkung populer bantuan.Sampeyan kang dadi nggawe langkung populer sing berarti batasan maneh, kuwi mau kudu nggawe barang apik tur angel.', 'he': 'בעיתון הזה, אנחנו מספקים תצוגה על המשימה המשותפת של WNUT-2020 על זיהוי טוויטים אינפורטיביים COVID-19 אנגליים. אנחנו מתארים איך אנחנו בונים גוף של 10K טוויטים וארגנים את שלבי הפיתוח והערכה למשימה הזאת. In addition, we also present a brief summary of results obtained from the final system evaluation submissions of 55 teams, finding that (i) many systems obtain very high performance, up to 0.91 F1 score, (ii) the majority of the submissions achieve substantially higher results than the baseline fastText (Joulin et al., 2017), (iii) מתאים מודלים לשפה מאומנים מראש על נתוני שפת רלוונטיים, ואחרי כן אימונים מפקחים יפה במשימה הזאת.', 'sk': 'V tem prispevku predstavljamo pregled skupne naloge WNUT-2020 za identifikacijo informativnih angleških tweetov COVID-19. Opisujemo, kako gradimo korpus 10K Tweets in organiziramo razvojne in evalvacijske faze za to nalogo. Poleg tega predstavljamo tudi kratek povzetek rezultatov, pridobljenih na podlagi končne ocene sistema 55 ekip, ki ugotavljajo, da (i) številni sistemi dosežejo zelo visoko zmogljivost, do 0,91 rezultata F1, (ii) večina prispevkov doseže bistveno višje rezultate kot osnovni fastText (Joulin et al., 2017), in (iii) natančno prilagajanje vnaprej usposobljenih jezikovnih modelov na ustrezne jezikovne podatke, ki mu sledi nadzorovano usposabljanje, uspešno opravlja to nalogo.', 'ha': "Daga wannan takardan, Munã samar wani surfati na WNUT-2020 wanda aka raba aikin da shi a kan gane na takardar COV-19 na Ingiriya. Munã bayyana yadda Muke samar da korpoon 10,000 na Twitter kuma Muke organize mafasalin da ake ƙaddara wa wannan aikin. Da haka, munã samun ƙari da yakamata daga ƙarshen amintarwa da aka aiko wajen jama'a 55, kuma tuna cewa (i) wasu na'urar da suka sami babban rabo, up to 0.91 F1 score, (ii) da mafi yawansa matsayin da suka sami matsayin mafiya girma daga matsayin matsayin Fasin (Joulin et al., 2017), @ action: button", 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་WNUT-2020་ཡིག་ཆའི་གནས་ཚུལ་གྱི་ངོས་འཛིན་སྟངས་མངོན་གསལ་བཤད་བྱེད་ཀྱི་ཡོད། ང་ཚོས་གྱིས་ཇི་ལྟར་བཟོ་བྱེད་པའི་ཨིན་ཡུཊ་གླིང་སྒྲ༡༠་ནང་གི་སྒེར་གྱི་རྩིས་ཤིག་རྩལ་དང་གོ་སྒྲིག་ནང་གི་ག ད་དུང་། ང་ཚོར་རྒྱབ་སྐྱོར་མེད་པའི་མཇུག་བསྡུ་ཡོད་པའི་མཇུག་བསྡུ་ཡོད་པའི་མཇུག་བསྡུ་ཡོད་པའི་གནད་སྡུད་55 ཚོ་བྱ་བ་རྗེས་སུ་འབྲས་ཟིན་བྲིས་རྗེས་མཇུག་བསྡུ་ཡོད། སྐད་ཡིག་ཆ་གསལ་ཅན་གྱི་སྔོན་གྲངས་སྒྲིག་འགོད་པའི་སྐད་ཡིག་ཆ་གསལ་བཤད་ཀྱི་ཐབས་ལམ་ལྟར།'}
{'en': 'Siva at WNUT-2020 Task 2 : Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets WNUT -2020 Task 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'ar': 'Siva في WNUT-2020 المهمة 2: صقل شبكات المحولات العصبية لتحديد تغريدات Covid-19 الإعلامية', 'es': 'Siva en la Tarea 2 del WNUT-2020: Ajuste fino de las redes neuronales de transformadores para la identificación de tuits informativos', 'fr': "Siva à la tâche 2 de la WNUT-2020\xa0: peaufiner les réseaux neuronaux de transformateurs pour l'identification des tweets informatifs sur", 'pt': 'Siva no WNUT-2020 Tarefa 2: ajuste fino de redes neurais de transformadores para identificação de tweets informativos sobre Covid-19', 'ja': 'WNUT -2020のSIVAタスク2 ：情報に基づいたCovid -19ツイートの識別のためのトランスフォーマー神経ネットワークの微調整', 'hi': 'WNUT-2020 टास्क 2 पर शिवा: सूचनात्मक कोविद -19 ट्वीट्स की पहचान के लिए ठीक-ट्यूनिंग ट्रांसफॉर्मर न्यूरल नेटवर्क', 'zh': 'Siva在WNUT-2020务2:微变压器神经网络以知信息性Covid-19推文', 'ru': 'SIVA на WNUT-2020 Задача 2: Тонкая настройка нейронных сетей трансформаторов для идентификации информативных твитов о Covid-19', 'ga': 'Siva ag WNUT-2020 Tasc 2: Líonraí Néaracha Trasfhoirmeora a mhionchoigeartú chun Tweetanna Faisnéiseacha Covid-19 a Aithint', 'hu': 'Siva a WNUT-2020 második feladatán: Transformer Neurális Hálózatok finomhangolása az információs Covid-19 tweetek azonosítására', 'ka': 'Siva WNUT-2020 პარამეტრი 2: ინფორმაციული Covid', 'el': 'Η Σίβα στο έργο 2: Βελτιστοποίηση Νευρικών Δικτύων Μετασχηματιστών για τον προσδιορισμό Πληροφοριακών Τουίτ Covid-19', 'mk': 'Сива на ВНУТ-2020 задача 2: Уфинирање на трансформираните неурални мрежи за идентификација на информативниот покрив-19 твитови', 'it': "Siva a WNUT-2020 Task 2: Fintuning delle reti neurali dei trasformatori per l'identificazione dei tweet informativi Covid-19", 'lt': 'WNUT 2020 m. 2 uždavinys: patobulinti transformuojančius nervinius tinklus informaciniam aprašui identifikuoti', 'kk': 'Сива WNUT-2020 тапсырмасы 2: Мәліметті Covid-19 Tweets идентификациялау үшін жақсы түрлендіру', 'ml': 'WNUT- 2020 ടാസ്ക് 2: വിവരങ്ങളുടെ തിരിച്ചറിയുന്നതിനുള്ള വിവരങ്ങള്\u200d', 'ms': 'Siva di WNUT-2020 Tugas 2: Penyesuaian Terbaik Rangkaian Neural Transformer untuk Pengenalan Tweet Covid-19 Maklumat', 'mn': 'Siva at WNUT-2020 Task 2: Fine-tuning Transformer Neural Networks for Identifying Information Covid-19 Tweets', 'mt': 'Siva fil-kompitu 2 tad-WNUT-2020: L-aġġustament fin-Netwerks Newrali Transformaturi għall-Identifikazzjoni tal-Kopertura Informattiva-19 Tweets', 'no': 'Siva på WNUT-2020 oppgåve 2: Fine-tuning Transformer Neuralnettverk for identifisering av informativ Covid-19 tweets', 'pl': 'Siva na WNUT-2020 Zadanie 2: Dostosowanie sieci neuronowych transformatorów do identyfikacji informacyjnych tweetów Covid-19', 'so': 'Shaqooyin WNUT-2020 2: Fine-tuning Transformer Neural Network for Identification of Informative Covid-19 Tweets', 'ro': 'Siva la WNUT-2020 Task 2: Reglarea fină a rețelelor neurale de transformatori pentru identificarea tweeturilor informative Covid-19', 'sv': 'Siva på WNUT-2020 Uppgift 2: Finjustera transformatorneurala nätverk för identifiering av informativa Covid-19 tweets', 'sr': 'Siva na WNUT-2020 zadatku 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'ta': 'WNUT- 2020 பணியில் சிவா: தகவல் காப்பிட்- 19 Tweets க்கு நன்றாக மாற்றும் முன்னோக்கி நெயுரல் வலைப்பின்னல்கள்', 'si': 'සිවාව WNAT-2020වැඩදි 2: හොඳ සංවිධානය කරන්න පුළුවන් නිර්මාණය නිර්මාණ ජාලවාර්ක්තාව සඳහා තොරතුරු කොවිඩ්', 'ur': 'WNUT-2020 ٹاکس 2 میں سیوا: معلومات کوویڈ-19 ٹویٹ کی شناسایی کے لئے اچھی تغییر ترنسفور نیورال نیٹورک', 'uz': 'Comment', 'vi': 'Siva ở WUT-2020 Task 2: fine-cấp biến hình cho mạng thần kinh để nhận diện nhóm Covid-19 Tweet', 'nl': 'Siva op WNUT-2020 Taak 2: Transformer Neural Networks finetunen voor Identificatie van Informatieve Covid-19 Tweets', 'bg': 'Шива в Задача 2: Финно настройване на трансформаторни неврални мрежи за идентифициране на информативни ковид-19 туитове', 'da': 'Siva ved WNUT-2020 Opgave 2: Finjusterende transformatorneurale netværk til identifikation af informative Covid-19 tweets', 'id': 'Siva di WNUT-2020 Task 2: Penyesuaian Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'hr': 'Siva na WNUT-2020 zadatku 2: Fine-tuning Transformer Neuralne mreže za identifikaciju informativnih kovid-19 Tweets', 'de': 'Siva bei WNUT-2020 Aufgabe 2: Feinabstimmung neuronaler Transformatornetzwerke zur Identifikation informativer Covid-19 Tweets', 'ko': 'Siva의 WNUT-2020 임무2: 정보성Covid-19 트위터를 식별하는 마이크로스피커 변압기 신경 네트워크', 'tr': 'Siva at WNUT-2020 Task 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'sq': 'Siva në WNUT-2020 Task 2: Mirërregullimi i rrjeteve neuronale të Transformer për Identifikimin e Covid-19 Tweets', 'sw': 'Siva kwenye kazi ya WNUT-2020 2: Mtandao mzuri wa Tafsiri wa Neurali wa zamani kwa ajili ya kutambulisha Taarifa za Twita-19', 'am': 'ስቪ በWNUT-2020 ስራ 2:Fine-tuning Transformer Neural Network for Identification of Informative Covid-19 Tweets', 'af': 'Siva by WNUT-2020 Opdrag 2: Fine-tuning Transformer Neurale Netwerke vir Identifikasie van Informatiewe Covid-19 Tweets', 'fa': 'Siva at WNUT-2020 Task 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'hy': 'Siva-ը ՀԱՆԹ-2020-ի 2. խնդիրն է. լավ կազմակերպել տեղեկատվական Covit-19 թվիթերի հայտնաբերման նյարդային ցանցերը', 'bn': 'উইনউট-২০২০০ কাজ ২-এ সিভা: তথ্য প্রকাশিত তথ্য কোভিড-১৯ টুইটের পরিচয় পরিচয়ের জন্য ভালো টুইট করা হচ্ছে', 'az': 'Siva at WNUT-2020 Task 2: Informative Covid-19 Tweets Identification for Fine-tuning Transformer Neural Networks', 'ca': 'Siva al WNUT-2020 Task 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'fi': 'Siva WNUT-2020 -tapahtumassa Tehtävä 2: Muuntajien hermoverkkojen hienosäätö informatiivisten Covid-19-twiittien tunnistamiseksi', 'bs': 'Siva na WNUT-2020 zadatku 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets', 'cs': 'Siva na WNUT-2020 Úkol 2: Jemné ladění transformátorových neuronových sítí pro identifikaci informačních tweetů Covid-19', 'et': 'Siva WNUT-2020 ülesandel 2: Transformerite neuroalsete võrkude täpne häälestamine informatiivsete Covid-19 tweetide tuvastamiseks', 'jv': 'Siwa nang WNUT-2020 task 2: Fine-tuning Transformer Neral networks kanggo I', 'he': 'סיבה ב-WNUT-2020 משימה 2: התאמה מעודכנת רשתות נוירוליות טרנספורסטריות לזהות את קוויד מידעי-19 טוויטים', 'sk': 'Siva na WNUT-2020 naloga 2: Fino nastavitev transformatorskih nevralnih omrežij za identifikacijo informativnih Covid-19 Tweets', 'ha': '@ info: whatsthis', 'bo': 'Siva at WNUT-2020 Task 2: Fine-tuning Transformer Neural Networks for Identification of Informative Covid-19 Tweets'}
{'en': 'Social media witnessed vast amounts of  misinformation  being circulated every day during the Covid-19 pandemic so much so that the WHO Director-General termed the phenomenon as infodemic. The ill-effects of such  misinformation  are multifarious. Thus, identifying and eliminating the sources of  misinformation  becomes very crucial, especially when  mass panic  can be controlled only through the right information. However, manual identification is arduous, with such large amounts of data being generated every day. This shows the importance of automatic identification of misinformative posts on  social media . WNUT-2020 Task 2 aims at building  systems  for automatic identification of informative tweets. In this paper, I discuss my approach to WNUT-2020 Task 2. I fine-tuned eleven variants of four transformer networks -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, on top of two different preprocessing techniques to reap good results. My top submission achieved an F1-score of 85.3 % in the final evaluation.', 'pt': 'As mídias sociais testemunharam grandes quantidades de desinformação circulando todos os dias durante a pandemia de Covid-19, tanto que o diretor-geral da OMS denominou o fenômeno como “infodêmico”. Os efeitos nocivos de tal desinformação são múltiplos. Assim, identificar e eliminar as fontes de desinformação torna-se muito crucial, especialmente quando o pânico em massa pode ser controlado apenas com as informações corretas. No entanto, a identificação manual é árdua, com quantidades tão grandes de dados sendo geradas todos os dias. Isso mostra a importância da identificação automática de postagens desinformativas nas redes sociais. A Tarefa 2 do WNUT-2020 visa construir sistemas para identificação automática de tweets informativos. Neste artigo, discuto minha abordagem para a Tarefa 2 do WNUT-2020. Ajustei onze variantes de quatro redes de transformadores -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, além de duas técnicas de pré-processamento diferentes para obter bons resultados. Minha melhor submissão alcançou uma pontuação F1 de 85,3% na avaliação final.', 'ar': 'شهدت وسائل التواصل الاجتماعي تداول كميات هائلة من المعلومات الخاطئة التي يتم تداولها يوميًا خلال جائحة كوفيد -19 لدرجة أن المدير العام لمنظمة الصحة العالمية وصف هذه الظاهرة بأنها "وباء معلومات". الآثار السيئة لمثل هذه المعلومات الخاطئة متعددة. وبالتالي ، يصبح تحديد مصادر المعلومات المضللة والقضاء عليها أمرًا بالغ الأهمية ، خاصةً عندما لا يمكن السيطرة على الذعر الجماعي إلا من خلال المعلومات الصحيحة. ومع ذلك ، فإن التعريف اليدوي شاق ، حيث يتم إنشاء مثل هذه الكميات الكبيرة من البيانات كل يوم. يوضح هذا أهمية التحديد التلقائي للمنشورات المضللة على وسائل التواصل الاجتماعي. تهدف المهمة 2 WNUT-2020 إلى بناء أنظمة للتعرف التلقائي على التغريدات المفيدة. في هذه الورقة ، أناقش مقاربتي لمهمة WNUT-2020 2. لقد قمت بضبط أحد عشر نوعًا متغيرًا من أربع شبكات محولات -بيرت ، وروبيرتا ، و XLM-RoBERTa ، وإليكترا ، بالإضافة إلى طريقتين مختلفتين للمعالجة المسبقة لتحقيق نتائج جيدة. حقق أعلى إرسال لي درجة F1 بنسبة 85.3٪ في التقييم النهائي.', 'fr': "Les réseaux sociaux ont été témoins de la diffusion quotidienne d'une grande quantité de désinformation pendant la pandémie de Covid-19, à tel point que le directeur général de l'OMS a qualifié le phénomène d' «\xa0infodémie\xa0». Les effets néfastes d'une telle désinformation sont multiples. Ainsi, identifier et éliminer les sources de désinformation devient très crucial, en particulier lorsque la panique de masse ne peut être maîtrisée que par la bonne information. Cependant, l'identification manuelle est ardue, de telles quantités de données étant générées chaque jour. Cela montre l'importance de l'identification automatique des publications mal informatives sur les réseaux sociaux. WNUT-2020 Task 2 vise à créer des systèmes d'identification automatique des tweets informatifs. Dans cet article, je discute de mon approche de la tâche 2 de la WNUT-2020. J'ai affiné onze variantes de quatre réseaux de transformateurs - BERT, Roberta, XLM-Roberta, ELECTRA, en plus de deux techniques de prétraitement différentes pour obtenir de bons résultats. Ma meilleure soumission a obtenu un score F1 de 85,3\xa0% lors de l'évaluation finale.", 'es': 'Las redes sociales fueron testigos de la circulación de enormes cantidades de desinformación todos los días durante la pandemia de Covid-19, tanto que la Directora General de la OMS calificó el fenómeno de «infodemia». Los efectos negativos de tal desinformación son múltiples. Por lo tanto, identificar y eliminar las fuentes de desinformación se vuelve muy crucial, especialmente cuando el pánico masivo solo se puede controlar a través de la información correcta. Sin embargo, la identificación manual es ardua, ya que cada día se generan grandes cantidades de datos. Esto demuestra la importancia de la identificación automática de publicaciones desinformativas en las redes sociales. La Tarea 2 del WNUT-2020 tiene como objetivo crear sistemas para la identificación automática de tuits informativos. En este artículo, discuto mi enfoque de la Tarea 2 del WNUT-2020. He ajustado once variantes de cuatro redes de transformadores: BERT, ROBerta, XLM-Roberta, ELECTRA, además de dos técnicas de preprocesamiento diferentes para obtener buenos resultados. Mi mejor candidatura obtuvo una puntuación de F1 del 85,3% en la evaluación final.', 'ru': 'В социальных сетях ежедневно распространялись огромные объемы дезинформации во время пандемии Covid-19, так что Генеральный директор ВОЗ назвал это явление «инфодемией».« Плохие последствия такой дезинформации многообразны. Таким образом, выявление и устранение источников дезинформации приобретает решающее значение, особенно в тех случаях, когда массовую панику можно контролировать только с помощью правильной информации. Однако ручная идентификация сопряжена с большими трудностями, поскольку ежедневно генерируются такие большие объемы данных. Это показывает важность автоматической идентификации дезинформативных постов в социальных сетях. Задача 2 WNUT-2020 направлена на построение систем автоматической идентификации информативных твитов. В этой статье я обсуждаю свой подход к задаче 2 WNUT-2020. Я доработал одиннадцать вариантов четырех трансформаторных сетей - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, в дополнение к двум различным методам предварительной обработки, чтобы получить хорошие результаты. Моя лучшая заявка достигла F1 - 85,3% в финальной оценке.', 'zh': 'Covid-19大行之间,社交媒体日传大错误信息,至世卫总干事谓之"信息流行病"。 其错误信息不良影响多矣。 是以识消错误信息源,特当以正信制大恐。 然手动识艰巨,日生此数。 此明自动识别社交媒体上错误信息帖之要也。 WNUT-2020务2构于自动识别信推文之统。 吾将论WNUT-2020务2之道。 余于二术预处理上,微调四变压器网络之11变体 - BERT,RoBERTa,XLM-RoBERTa,ELECTRA,以致良效。 余提交最高分于终评中得85.3%之F1分。', 'ja': 'ソーシャルメディアは、新型コロナウイルスのパンデミック（世界的大流行）の間、毎日膨大な量の誤った情報が流れているのを目撃し、WHO事務局長がこの現象を“infodemic”と呼ぶほどであった。「このような誤った情報の悪影響は多種多様です。 したがって、誤った情報のソースを特定して排除することは非常に重要になり、特に大衆パニックが正しい情報によってのみ制御できる場合に重要になります。 しかし、手作業での識別は困難であり、毎日大量のデータが生成されます。 これは、ソーシャルメディア上の誤った情報の投稿を自動的に特定することの重要性を示しています。 WNUT -2020タスク2は、有益なツイートを自動的に識別するためのシステムを構築することを目的としている。 本稿では、WNUT -2020タスク2に対する私のアプローチについて説明します。 私は、2つの異なる前処理技術に加えて、BERT、RoBERTa、XLM - RoBERTa、ELECTRAの4つの変圧器ネットワークの11つのバリアントを微調整し、良好な結果を得ました。 最終的な評価では、私のトップの提出物は85.3%のF 1スコアを達成しました。', 'hi': 'सोशल मीडिया ने कोविद -19 महामारी के दौरान हर दिन बड़ी मात्रा में गलत जानकारी प्रसारित की जा रही है, इतनी अधिक है कि डब्ल्यूएचओ के महानिदेशक ने इस घटना को "इन्फोडेमिक" करार दिया। इस तरह की गलत सूचनाओं के दुष्प्रभाव बहुआयामी हैं। इस प्रकार, गलत सूचना के स्रोतों की पहचान करना और उन्हें समाप्त करना बहुत महत्वपूर्ण हो जाता है, खासकर जब बड़े पैमाने पर आतंक को केवल सही जानकारी के माध्यम से नियंत्रित किया जा सकता है। हालांकि, मैनुअल पहचान कठिन है, हर दिन इतनी बड़ी मात्रा में डेटा उत्पन्न किया जा रहा है। यह सोशल मीडिया पर गलत सूचनात्मक पोस्ट की स्वचालित पहचान के महत्व को दर्शाता है। WNUT-2020 टास्क 2 का उद्देश्य जानकारीपूर्ण ट्वीट्स की स्वचालित पहचान के लिए सिस्टम का निर्माण करना है। इस पेपर में, मैं WNUT-2020 टास्क 2 के लिए अपने दृष्टिकोण पर चर्चा करता हूं। मैं ठीक चार ट्रांसफार्मर नेटवर्क के ग्यारह संस्करणों ट्यून -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, दो अलग-अलग preprocessing तकनीकों के शीर्ष पर, अच्छे परिणाम काटने के लिए. मेरे शीर्ष सबमिशन ने अंतिम मूल्यांकन में 85.3% का एफ 1-स्कोर हासिल किया।', 'ga': "Chonaic na meáin shóisialta méideanna ollmhóra mífhaisnéise á scaipeadh gach lá le linn na paindéime Covid-19 chomh mór sin gur thug Ard-Stiúrthóir an WHO an feiniméan mar “infodéimeach.” Is iomaí mí-iarmhairtí a bhaineann le faisnéis mhícheart dá leithéid. Mar sin, bíonn sé ríthábhachtach foinsí na mífhaisnéise a shainaithint agus a dhíchur, go háirithe nuair nach féidir scaoll mais a rialú ach amháin tríd an bhfaisnéis cheart. Is deacair sainaithint láimhe a dhéanamh, áfach, agus déantar an oiread sin sonraí a ghiniúint gach lá. Léiríonn sé seo a thábhachtaí atá sé postanna mífhaisnéiseacha ar na meáin shóisialta a shainaithint go huathoibríoch. Tá sé mar aidhm ag Tasc 2 WNUT-2020 córais a thógáil chun tweets faisnéiseacha a shainaithint go huathoibríoch. Sa pháipéar seo, pléim mo chur chuige i leith Tasc 2 WNUT-2020. Rinne mé mionchoigeartú ar aon leagan déag de cheithre líonra claochladáin -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, anuas ar dhá theicníc réamhphróiseála éagsúla chun torthaí maithe a bhaint amach. Bhain m'iarratas is airde scór F1 de 85.3% sa mheastóireacht deiridh.", 'hu': 'A közösségi médiában naponta rengeteg félrevezető információ került forgalomba a Covid-19 járvány alatt, annyira, hogy a WHO főigazgatója infodemikusnak nevezte a jelenséget. Az ilyen téves tájékoztatás rossz hatásai sokféleségek. Így a félreértett információk forrásainak azonosítása és megszüntetése nagyon fontos, különösen akkor, ha a tömeges pánik csak a megfelelő információ segítségével irányítható. A kézi azonosítás azonban nehéz, mivel ilyen nagy mennyiségű adat keletkezik naponta. Ez megmutatja a közösségi médiában található félretájékoztató bejegyzések automatikus azonosításának fontosságát. A WNUT-2020 2. feladat célja az információs tweetek automatikus azonosítására szolgáló rendszerek kiépítése. Ebben a tanulmányban megvitatom a WNUT-2020 2. feladat megközelítését. A négy transzformátor hálózat tizenegy változatát finomhangoltam - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, valamint két különböző előfeldolgozási technika mellett, hogy jó eredményeket érjek el. A legjobb pályázatom 85,3%-os F1 pontszámot ért el a végső értékelésen.', 'el': 'Τα μέσα κοινωνικής δικτύωσης είδαν τεράστιες ποσότητες παραπληροφόρησης να κυκλοφορούν καθημερινά κατά τη διάρκεια της πανδημίας τόσο πολύ που ο Γενικός Διευθυντής του ΠΟΥ χαρακτήρισε το φαινόμενο ως "πληροφοριακό". Οι δυσμενείς επιπτώσεις αυτής της παραπληροφόρησης είναι πολλαπλές. Έτσι, ο εντοπισμός και η εξάλειψη των πηγών παραπληροφόρησης γίνεται πολύ κρίσιμος, ειδικά όταν ο μαζικός πανικός μπορεί να ελεγχθεί μόνο μέσω των σωστών πληροφοριών. Ωστόσο, η χειροκίνητη ταυτοποίηση είναι δύσκολη, με τόσο μεγάλες ποσότητες δεδομένων να παράγονται καθημερινά. Αυτό δείχνει τη σημασία του αυτόματου εντοπισμού παραπληροφόρων δημοσιεύσεων στα μέσα κοινωνικής δικτύωσης. Το έργο 2 στοχεύει στην κατασκευή συστημάτων αυτόματης αναγνώρισης ενημερωτικών tweets. Σε αυτή την εργασία, συζητώ την προσέγγισή μου στο έργο 2. Συντονίστηκα έντεκα παραλλαγές τεσσάρων δικτύων μετασχηματιστών -πάνω σε δύο διαφορετικές τεχνικές προεπεξεργασίας για να αποκομίσω καλά αποτελέσματα. Η κορυφαία μου υποβολή πέτυχε ένα σκορ F1 85,3% στην τελική αξιολόγηση.', 'ka': 'სოციალური მედიაციები გვეჩვენეთ დიდი რაოდენობები, რომელიც ყოველ დღეს კოვიდი-19 პონდემიკის განმავლობაში, რომ გონების დირექტორი-გონები გონების განმავლობაში "ინფოდემიკური" გამოსახულება. ასეთი შეცდომარების შეცდომარებული ეფექტი მულტარიურია. ამიტომ, შეცდომის გამოყენება და გამოწყენება მნიშვნელოვანი იქნება, განსაკუთრებით როდესაც მასური ონაცია შეიძლება მხოლოდ სწორი ინფორმაციის გამოყენება. მაგრამ მანძილური იდენტიფიკაცია ძალიან ძალიან ძალიან, როგორც რამდენიმე დიდი მონაცემები ყოველ დღე იქნება. ეს აჩვენებს სოციალური მედიაში არაფორმატიური პოსტის ავტომატიკური ინდენტიფიკაციის მნიშვნელობა. WNUT-2020 დავალება 2 მიზეზია ინფორმატიური tweets-ის ავტომატური ინდენტიფიკაციის სისტემის შექმნა. ამ დოკუნტში ჩემი წარმოდგენა WNUT-2020 დავალების 2-ზე. მე გავაკეთებდი ოთხი ტრანფორმაციური ქსელის 11 გარიანტები -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, ორი განსხვავებული პრეპროცესის ტექნოგიების მარცხენა, რომ წარმოიდგინოთ კარგი შედეგი. ჩემი საუკეთესო მომხმარება დასრულებულია 85,3% დასაწყისში.', 'it': 'I social media sono stati testimoni di enormi quantità di disinformazione che circolavano ogni giorno durante la pandemia di Covid-19 tanto che il Direttore Generale dell\'OMS ha definito il fenomeno "infodemico". Gli effetti negativi di tale disinformazione sono molteplici. Pertanto, identificare ed eliminare le fonti di disinformazione diventa molto cruciale, soprattutto quando il panico di massa può essere controllato solo attraverso le giuste informazioni. Tuttavia, l\'identificazione manuale è ardua, con così grandi quantità di dati che vengono generati ogni giorno. Ciò dimostra l\'importanza dell\'identificazione automatica dei post misinformativi sui social media. WNUT-2020 Task 2 mira a costruire sistemi per l\'identificazione automatica dei tweet informativi. In questo articolo, discutiamo il mio approccio al task 2 WNUT-2020. Ho perfezionato undici varianti di quattro reti di trasformatori - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, oltre a due diverse tecniche di preelaborazione per ottenere buoni risultati. La mia migliore presentazione ha ottenuto un punteggio F1 dell\'85,3% nella valutazione finale.', 'lt': 'Socialinės žiniasklaidos metu per 19 pakto pandemiją kasdien skleidžiama daug klaidingos informacijos, todėl PSO generalinis direktorius šį reiškinį vadino "infodemija". Tokios neteisingos informacijos nepageidaujamas poveikis yra daugialypis. Todėl labai svarbu nustatyti ir pašalinti klaidingos informacijos šaltinius, ypač kai masinė panika gali būti kontroliuojama tik tinkama informacija. Tačiau rankinis identifikavimas yra sudėtingas, o tokie dideli duomenys gaunami kasdien. Tai rodo, kad svarbu automatiškai nustatyti netinkamas socialinės žiniasklaidos pareigas. WNUT-2020 2 uždaviniu siekiama sukurti informacinių tweetų automatinio identifikavimo sistemas. Šiame dokumente aptariau savo požiūrį į WNUT 2020 2 užduotį. Siekiant gauti gerus rezultatus, aš patobulinau vienuolika keturių transformatorių tinklų variantų BERT, RoBERTa, XLM-RoBERTa, ELECTRA. Mano didžiausias teiginys galutiniame vertinime pasiektas 85,3 % F1 rezultatas.', 'mk': 'Социјалните медиуми беа сведоци на огромни количини на погрешни информации кои беа циркулирани секој ден за време на пандемијата на Covid-19 толку многу што генералниот директор на СВО го нарече феноменот „инфодемичен“. Лошите ефекти од ваквите погрешни информации се мултифарни. Така идентификувањето и елиминирањето на изворите на погрешна информација станува многу клучно, особено кога масовната паника може да се контролира само преку вистинските информации. Сепак, рачната идентификација е тешка, со толку големи количини на податоци кои се генерираат секој ден. Ова ја покажува важноста на автоматска идентификација на погрешни информативни места на социјалните медиуми. ВНУТ-2020 задача 2 има за цел изградба системи за автоматска идентификација на информативните твитови. Во овој документ, разговарам за мојот пристап до ВНУТ-2020 задача 2. Уредив 11 варијанти од четири трансформирачки мрежи - БЕРТ, Роберта, XLM-Роберта, ЕЛЕКТРА, покрај две различни препроцесорски техники за да добијат добри резултати. Моето највисоко поднесување достигна резултат на Ф1 од 85,3 отсто во финалната оценка.', 'kk': 'Ковид-19 пандемиясында әрбір күн бойынша жалғыз мәліметтердің көпшілігін көзгертілмегенін көрген соң, ООН директоры "инфодемикалық" деп аталады. Бұл жарамсыз түрлендіру қатесі көпшілікті. Бұл үшін жарамсыз мәліметтердің көзін анықтау және өшіру өте маңызды болады, өйткені массалық паникасын тек оң мәліметі арқылы бақылауға болады. Бірақ қолмен идентификациясы күн сайын құрылатын деректердің ұзындығы өте көп. Бұл социалдық медиақтағы дұрыс пішімдерді автоматты түрде анықтау маңыздысын көрсетеді. WNUT-2020 2- тапсырма мәліметтерді автоматты түрде анықтау жүйелерін құру үшін мақсатты. Бұл қағазда, мен WNUT-2020 тапсырмасының 2- тапсырмасына қатынап тұрмын. Мен төрт түрлендіруші желінің 11 түрлендірімін - BERT, RoBERTa, XLM- RoBERTa, ELECTRA - екі әртүрлі түрлендіру технологиясының үстінде жақсы нәтижелерді жасауға арналған. Соңғы оқиғалардың ең жоғары жұмыс істеу үшін F1- нұсқасы 85, 3% болды.', 'mt': "Il-mezzi tax-xandir so ċjali xhiedu ammonti kbar ta’ informazzjoni żbaljata li qed jiċċirkolaw kuljum matul il-pandemija tal-Covid-19 tant li d-Direttur Ġenerali tad-WHO kklassifika l-fenomenu bħala ‘infodemiku’. L-effetti ħżiena ta’ informazzjoni ħażina bħal din huma multifari. Għalhekk, l-identifikazzjoni u l-eliminazzjoni tas-sorsi ta’ informazzjoni ħażina ssir kruċjali ħafna, speċjalment meta l-paniku tal-massa jista’ jiġi kkontrollat biss permezz tal-informazzjoni t-tajba. However, manual identification is arduous, with such large amounts of data being generated every day.  Dan juri l-importanza ta’ identifikazzjoni awtomatika ta’ postijiet ta’ informazzjoni żbaljata fil-midja soċjali. Il-kompitu 2 tad-WNUT-2020 għandu l-għan li jibni sistemi għall-identifikazzjoni awtomatika ta’ tweets informativi. F'dan id-dokument, niddiskuti l-approċċ tiegħi għall-Kompitu 2 tad-WNUT-2020. Jien irfinat ħdax-il varjant ta’ erba’ netwerks ta’ trasformaturi - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, flimkien ma’ żewġ tekniki differenti ta’ preproċessar biex jinkisbu riżultati tajbin. L-ogħla sottomissjoni tiegħi kisbet punteġġ F1 ta’ 85.3% fl-evalwazzjoni finali.", 'ms': "Media sosial menyaksikan jumlah besar salah maklumat yang disebarkan setiap hari semasa pandemi Covid-19 begitu banyak sehingga Pengarah Jeneral WHO menyebut fenomena itu sebagai 'infodemic.' Kesan buruk dari maklumat salah seperti itu berbilang. Oleh itu, pengenalan dan penghapusan sumber salah maklumat menjadi sangat penting, terutama apabila panik massa hanya boleh dikawal melalui maklumat yang betul. Namun, pengenalan manual adalah sukar, dengan jumlah besar data yang dijana setiap hari. Ini menunjukkan kepentingan pengenalan automatik pos yang salah maklumat pada media sosial. Tugas 2 WNUT-2020 bermaksud membina sistem untuk pengenalan automatik tweet maklumat. Dalam kertas ini, saya membincangkan pendekatan saya kepada Tugas 2 WNUT-2020. I fine-tuned eleven variants of four transformer networks - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, on top of two different preprocessing techniques to reap good results. Pemberian terbaik saya mencapai skor F1 85.3% dalam penilaian akhir.", 'mn': 'Нийгмийн мэдээллийн хэрэглэгчид өдөр бүр Covid-19 пандемикийн хувьд маш олон буруу хэлбэрүүдийг харж байлаа. Иймээс ВОЗ-ын директор ерөнхийлөгч энэ явдал "инфодемик" гэж нэрлэсэн. Ийм буруу хэлбэрийн муу нөлөө нь олон төрлийн. Тиймээс буруу хэлбэрийн эх үүсвэрийг тодорхойлж, устгах нь маш чухал болдог. Ялангуяа масс аймшиг зөвхөн зөв мэдээллээр хяналт хийх боломжтой болдог. Гэхдээ гарын тодорхойлолт нь өдөр бүр ийм их хэмжээний өгөгдлийг бүтээж байна. Энэ нь нийгмийн мэдээлэл дээрх буруу мэдээллийг автоматжуулан танихын чухал зүйлийг харуулдаг. WNUT-2020 2 даалгавар нь мэдээллийн tweets-г автоматжуулах системийг бүтээх зорилго юм. Энэ цаасан дээр би WNUT-2020 даалгаварын 2 даалгаварын талаар ярилцаж байна. Би дөрвөн шилжүүлэгч сүлжээний 11 хувилбар -BERT, RoBERTa, XLM-RoBERTa, ELECTRA -г сайн үр дүнг гаргахын тулд хоёр өөр аргаар үйлдвэрлэх технологи дээр тодорхойлсон. Миний хамгийн гол шалгалтын үндэслэлд F1 хувь нь 85,3% хүртэл хүргэсэн.', 'ml': 'സാമൂഹ്യ മാധ്യമങ്ങള്\u200d കോവിഡ്-19 പാന്\u200dഡെമിക്കില്\u200d എല്ലാ ദിവസവും തെറ്റായ വിവരങ്ങള്\u200d പ്രക്ഷേപിക്കുന്നതിന് സാക്ഷികളായിരുന്നു. അതുകൊണ്ട് WHO ഇത്തരം തെറ്റായ വിവരങ്ങളുടെ അപകടത്തിന്റെ പ്രഭാവം പലതാണ്. അതുകൊണ്ട്, തെറ്റായ വിവരങ്ങളുടെ സ്രോതസ്സുകള്\u200d തിരിച്ചറിയുകയും നീക്കം ചെയ്യുകയും ചെയ്യുന്നത് വളരെ പ്രധാനപ്പെട്ടതാണ്.  എന്നാലും കൈകാര്യം തിരിച്ചറിയുന്നത് അപകടത്തിലാണ്, അത്രയും വലിയ വിവരങ്ങള്\u200d എല്ലാ ദിവസവും ഉണ്ടാക്കുന്നത്. ഇത് സോഷ്യല്\u200d മെഡിയയില്\u200d തെറ്റായ വിവരങ്ങളുടെ പോസ്റ്റുകള്\u200d സ്വയം തിരിച്ചറിയാനുള്ള പ്രധാനപ്പെട WNUT-2020 ടാസ്ക് 2 വിവരങ്ങളുടെ വിവരങ്ങളുടെ തിരിച്ചറിയാനായി സിസ്റ്റമുകള്\u200d നിര്\u200dമ്മിക്കുന്നതിനാണ്. ഈ പത്രത്തില്\u200d, ഞാന്\u200d WNUT-2020 ടാസ്ക് 2-ലേക്ക് എന്\u200dറെ അടുത്ത് സംസാരിക്കുന്നു. നാല് മാറ്റങ്ങളുടെ നെറ്റ്\u200cവര്\u200dക്കുകളുടെ പതിനൊന്ന് മാറ്റങ്ങള്\u200d ഞാന്\u200d സുന്ദരിച്ചിരിക്കുന്നു. ബെര്\u200dട്ട്, റോബെര്\u200dട്ട, എക്സ്\u200cലി-റോബെര്\u200dട്ട, എല എന്\u200dറെ മുകളിലുള്ള സമ്മാനം 85.3% എഫ്1 സ്കോര്\u200d പ്രാപിച്ചു.', 'pl': 'Media społecznościowe były świadkami ogromnych ilości dezinformacji rozpowszechnianych codziennie w czasie pandemii Covid-19 tak bardzo, że dyrektor generalny WHO określił to zjawisko jako "infodemia". Złe skutki takich dezinformacji są różnorodne. Dlatego identyfikacja i eliminacja źródeł dezinformacji staje się bardzo istotne, zwłaszcza gdy masowa panika może być kontrolowana tylko poprzez właściwe informacje. Ręczna identyfikacja jest jednak trudna, ponieważ codziennie generowane są tak duże ilości danych. Pokazuje to znaczenie automatycznej identyfikacji dezinformacyjnych postów w mediach społecznościowych. WNUT-2020 Zadanie 2 ma na celu budowę systemów automatycznej identyfikacji tweetów informacyjnych. W niniejszym artykule omówię moje podejście do zadania WNUT-2020 2. Dostroiłem jedenaście wariantów czterech sieci transformatorowych – BERT, RoBERTa, XLM-RoBERTa, ELECTRA, a także dwie różne techniki przetwarzania, aby uzyskać dobre wyniki. Moja najlepsza zgłoszenie osiągnęła wynik F1 85,3% w ocenie końcowej.', 'sr': "Socijalni mediji su svjedoci ogromne količine nepravde informacije koje se šire svaki dan tokom pandemije Covid-19 tako mnogo da je generalni direktor Svetske organizacije nazvao fenomen 'infodemičkim'. Loše učinke takve pogrešne informacije su multifarijske. Dakle, identifikacija i eliminacija izvora pogrešne informacije postaje vrlo važna, posebno kada masovna panika može biti kontrolirana samo kroz pravu informaciju. Međutim, ručna identifikacija je teška, s tako velikom količinom podataka koje se proizvode svaki dan. To pokazuje važnost automatske identifikacije nepravilnih postaja na društvenim medijima. WNUT-2020 zadatak 2 je cilj izgradnji sistema za automatsku identifikaciju informativnih tweeta. U ovom papiru razgovaram o svom pristupu zadatku 2. WNUT-2020. Napravio sam 11 varianta četiri transformacijske mreže - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, na vrhu dva različita tehnika preobrađivanja kako bi dobio dobre rezultate. Moja najveća podnošenja postigla je rezultat F1 od 85,3% u konačnoj procjeni.", 'no': "Sosiale medier viste store mengdar av feil-informasjon som er cirkulert kvar dag under Covid-19 pandemikk så mykje slik at den generelle WHO-direktoren kalla fenomenen som 'infodemikk'. Feil effektar av slike feil- informasjon er fleire. Derfor blir det svært viktig å identifisera og eliminera kjeldene for feilinformasjon, særleg når massepanikk berre kan kontrollerast gjennom høgreinformasjonen. Manuelle identifikasjon er imidlertid vanskeleg, med så stor mange data som vert laga kvar dag. Dette viser viktigheten for automatisk identifisering av feilformativ postar på sosiale media. WNUT-2020 Oppgåve 2 mål å bygge systemer for automatisk identifisering av informativ tweet. I denne papiren diskuterer jeg tilnærminga min til WNUT-2020 oppgåve 2. Eg fint oppsett tolv variantar av fire transformeringsnettverk - BERT, RoBERTa, XLM- RoBERTa, ELECTRA, på toppen av to ulike forskjellige førehandsamingsteknikkar for å henta gode resultat. Min øvste opplysning fikk eit F1- poeng med 85,3% i det siste evalueringa.", 'so': "Wixii macluumaad khalad ah oo bulshada ah ayaa maray in maalin walba lagu wareejiyo cudurka daboolka-19, sidaas darteed maamulaha guud ee WHO wuxuu ku dhamaaday waxyaabaha sida 'infodemic'. Dhibaatooyinka macluumaadka khilaafka ah waa mid badan. Sidaa darteed, aqoonsashada iyo elinta asalka macluumaadka khiyaanada ayaa aad u muhiim ah, khusuusan marka cabsi badan lagu maamuli karo macluumaadka saxda ah oo keliya. However, manual identification is arduous, with such large amounts of data being generated every day.  Taasi waxay muuqataa muhiim u ah aqoonsiga iskaa ah ee warqadaha macluumaadka ku saabsan shabakadda bulshada. WNUT-2020 Shaqo 2 waxey ku qoran yihiin dhismaha nidaamka si ay u aqoonsadaan iskaa-maamul ah Twittiyada macluumaadka. Warqadan, waxaan ka sheekaynayaa qaabilaadayda WNUT-2020 shaqo 2. Tob iyo toban kala duduwan oo ah shabakado afarta beddelka ah, BERT, RoBERTA, XLM-RoBERTA, ELECTRA, korkiisa waxaa lagu qoray laba qaabab oo kala duduwan oo ay soo ururiyaan midhaha wanaagsan. Miisaankayga ugu sarreeya waxay gaadhay qiimeyntii ugu dambeeyey qiyaastii F1 qiyaastii 85.3 boqolkiiba.", 'si': 'සාමාජික මාධ්\u200dයමය සාක්ෂිකයෙන් හැමදාම වැරැද්ධ වැරැද්ධ වැරැද්ධ වැරැද්ධ වෙලා තියෙනවා කොවිඩ්-19 පැන්ඩිමික් වලින් හැමදාම ඒ වගේ වැරදි පරීක්ෂණය ගැන වැරදි ප්\u200dරතිකාර වලට ගොඩක් විශේෂයි. ඉතින්, වැරැද්ධ වැරැද්ධ වැරැද්ධ ස්ථානයක් පරීක්ෂණය සහ නිෂ්කාරණය ගොඩක් වැදගත් වෙනවා, විශේෂයෙන්ම ම නමුත්, මනුස්සල පරීක්ෂණය අවශ්\u200dයයි, හැමදාම දත්තේ නිර්මාණය කරනවා වගේ ලොකු ප්\u200dරමාණයක්. මේක පෙන්වන්නේ සාමාජික මාධ්\u200dයමාධ්\u200dයමේ වැරදිය පොස්ටල් ස්වයංක්\u200dරිය පරීක්ෂණයේ ස්වයං WNOT-2020වැඩක් 2 අරමුණ වෙනවා තොරතුරු ටුයිට් ස්වයංක්\u200dරිය පද්ධතිය නිර්මාණය කරන්න. මේ පත්තරේ මම මගේ ප්\u200dරවේශනය වෙනුවෙන් වෙනුවෙන් කතා කරනවා. මම හොඳින් සම්බන්ධ වෙනස් 11 වෙනස් තියෙන්නේ -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, හොඳ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරව මගේ උපරිම අන්තිම අවශ්\u200dය විශ්ලේෂණයේ F1-ස්කෝර් 85.3% තියෙනවා.', 'ro': 'Rețelele sociale au asistat la circulația zilnică a unor cantități mari de dezinformații în timpul pandemiei Covid-19 atât de mult încât directorul general al OMS a numit fenomenul "infodemic". Efectele negative ale acestei dezinformări sunt multiple. Astfel, identificarea și eliminarea surselor de dezinformare devine foarte crucială, mai ales atunci când panica în masă poate fi controlată numai prin intermediul informațiilor corecte. Cu toate acestea, identificarea manuală este dificilă, cantități atât de mari de date fiind generate în fiecare zi. Acest lucru arată importanța identificării automate a mesajelor dezinformative pe rețelele de socializare. Activitatea 2 WNUT-2020 vizează construirea de sisteme pentru identificarea automată a tweeturilor informative. În această lucrare, discut abordarea mea cu privire la sarcina 2 WNUT-2020. Am aranjat unsprezece variante ale patru rețele de transformare - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, pe lângă două tehnici diferite de pre-procesare pentru a obține rezultate bune. În evaluarea finală am obținut un scor F1 de 85,3%.', 'sv': 'Sociala medier bevittnade enorma mängder missinformation som cirkulerades varje dag under Covid-19-pandemin så mycket att WHO:s generaldirektör kallade fenomenet "infodemiskt". De negativa effekterna av sådan felaktig information är mångfaldiga. Därför blir det mycket viktigt att identifiera och eliminera källorna till felaktig information, särskilt när masspanik endast kan kontrolleras genom rätt information. Manuell identifiering är dock mödosam, med så stora mängder data som genereras varje dag. Detta visar vikten av att automatiskt identifiera felaktiga inlägg på sociala medier. WNUT-2020 Uppgift 2 syftar till att bygga system för automatisk identifiering av informativa tweets. I denna uppsats diskuterar jag mitt tillvägagångssätt för WNUT-2020 Task 2. Jag finjusterade elva varianter av fyra transformatornätverk – BERT, RoBERTa, XLM-RoBERTa, ELECTRA, utöver två olika förbehandlingstekniker för att få bra resultat. Mitt bästa bidrag uppnådde en F1-poäng på 85,3% i slututvärderingen.', 'ur': "سوسیل میڈیا کی بہت سی غلطی کی گواہی دیتی تھی کہ ہر روز کووید-19 پینڈمیک کے درمیان بہت زیادہ غلطی کی جگہ چلتی تھی تاکہ WHO Director-General نے اس phenomenon کو 'infodemic' بنایا۔ ایسی غلطی کے بد اثرات بہت متفاوت ہیں۔ اسی طرح، غلطی کے منبع کا شناسایا اور ہٹانا بہت اہم ہوتا ہے، مخصوصا جبکہ جسم کا خوف صرف ٹھیک معلومات کے ذریعے کنٹرول کر سکتا ہے. ہاں، ہاتھی شناسایی سخت ہے، اس طرح بہت بڑی اندازہ ڈیٹا ہر دن پیدا کیا جاتا ہے. یہ سوسیل میڈیاں میں غلطی پوسٹوں کی آٹوٹی شناسایی کا اہم دکھاتا ہے۔ WNUT-2020 Task 2 aims to build systems for automatic identification of tweets. اس کاغذ میں میں نے WNUT-2020 ٹاکس 2 کے لئے اپنی طریقے سے بحث کی۔ میں نے چار تغییر نیٹ ورک کے بارے میں ایک بارہ تغییرات کیا -BERT, RoBERTa, XLM-RoBERTa, ELECTRA، دو مختلف پیش پرپروس ٹیکنیک کے اوپر اچھے نتیجے حاصل کرنے کے لئے۔ میرے اوپر مسلمانوں نے آخری ارزیابی میں 85.3% کی F1-score کو پہنچا۔", 'ta': "சமூக ஊடகங்கள் ஒவ்வொரு நாளும் தவறான தகவல் பரப்பப்படும் பெரிய பார்வையில் பார்க்கப்பட்டுள்ளது எனவே WHO Director-General இந்த நிகழ்வை 'infodemic' என்று முடித்தது. இவ்வாறு தவறான தகவலின் தீவிளைவு பல்வேறு. எனவே, தவறான தகவல் மூலங்களை கண்டுபிடித்து நீக்குவது மிகவும் முக்கியமானதாகும், குறிப்பாக, மக்கள் பயம் சரியான தகவல் மூலம் மட்டும்  ஆனால், கைமுறை அடையாளத்தின் பெரிய தரவு ஒவ்வொரு நாளும் உருவாக்கப்படும். இது சமூக ஊடகங்களில் தவறான தகவல் புத்தகங்களை தானாக அடையாளத்தின் முக்கியம் காட்டுகிறது. WNUT-2020 பணி 2 தகவல் தொடர்புகளை தானியங்கி அடையாளம் அமைப்புகளை உருவாக்குகிறது. இந்த காகிதத்தில், நான் WNUT-2020 பணி 2 க்கு என் வழியை விவாதம் செய்கிறேன். நான் நான்கு மாற்றும் வலைப்பின்னல்களின் பதினொன்று மாறிகளை நன்றாக குறிக்கப்பட்டுள்ளேன் - BERT, ராபெர்டா, XLM-RoBERTA, ELECTRA, மேலே இரண்டு வேறு  என் மேல் சரணங்கள் 85.3% இறுதி மதிப்பில் ஒரு F1- மதிப்பு அடைந்தது.", 'uz': "Name Bu ko'plab maʼlumot haqida ko'plab o'zgarishlar. Шундай қилиб, хато маълумотларнинг манфаатларини аниқлаш ва ўчириш жуда муҳим бўлиб қолади, махсус вақтда одамлар хавфдан фақат тўғри маълумотлар билан бошқариш мумкин. Lekin, qoʻlbola identifikati juda katta, har kuni bunday katta maʼlumot yaratiladi. This shows the importance of automatic identification of misinformative posts on social media.  WNUT-2020 Vazifa 2 haqida xabarnoma Twittlarni avtomatik aniqlash uchun tizimni yaratishga ega. Bu qogʻozda men WNUT-2020 Vazifa 2 vazifasiga qaramaman. Men to'rt transformer tarmoqlarining 11 varianteri BERT, RoBERTA, XLM-RoBERTA, ELECTRA va yaxshi natijalarni olib tashlash uchun ikkita boshqa tarmoqni o'zgartirdim. Mening eng eng yuqori xabarga F1 qiymatga 85.3% qiymatiga keldi.", 'vi': 'Các phương tiện xã hội đã chứng kiến hàng ngày có nhiều tin sai lầm được lan truyền trong suốt đại dịch Covid-19, đến nỗi Tổng Giám đốc điều hành WHO gọi hiện tượng là "thông tin á" Những ảnh hưởng xấu của sai lầm này rất lớn. Do đó, việc xác định và loại bỏ nguồn tin sai lầm trở nên rất quan trọng, đặc biệt khi sự hoảng loạn hàng loạt chỉ có thể được kiểm soát bằng đúng thông tin. Tuy nhiên, việc nhận dạng bằng tay rất khó khăn, với việc sản xuất hằng ngày một lượng dữ liệu lớn như vậy. Điều này cho thấy tầm quan trọng của việc nhận dạng trật tự trên mạng xã hội. Nhiệm vụ WGiờ-209 2 nhằm phát triển hệ thống thiết lập tự động nhận dạng tweet thông tin. Trong tờ báo này, tôi thảo luận về cách tiếp cận của tôi với Nhiệm vụ WGiờ-2020 2. Tôi hoàn chỉnh mười một biến thể của bốn mạng chuyển hóa: BERT, RoBERTa, XLM-RoerbTa, Electngốn, cùng với hai kỹ thuật xử lý khác nhau để đạt được kết quả tốt. Câu đệ trình hàng đầu của tôi đạt được một số F1 trong 85.3=\'trong vòng đánh giá cuối cùng.', 'bg': 'Социалните медии бяха свидетели на огромни количества дезинформация, които се разпространяваха всеки ден по време на пандемията толкова много, че генералният директор на СЗО определи явлението като "инфодемично". Неблагоприятните последици от тази дезинформация са многобройни. По този начин идентифицирането и премахването на източниците на дезинформация става много важно, особено когато масовата паника може да бъде контролирана само чрез правилната информация. Ръчното идентифициране обаче е трудно, като толкова големи количества данни се генерират всеки ден. Това показва значението на автоматичното идентифициране на дезинформационни публикации в социалните медии. Задача 2 цели изграждане на системи за автоматично идентифициране на информативни туитове. В тази статия обсъждам моя подход към задача 2 на WNUT-2020. Финно настроих единадесет варианта на четири трансформаторни мрежи - отгоре на две различни техники за предварителна обработка, за да пожъна добри резултати. Моят топ пост постигна резултат от 85,3% в крайната оценка.', 'nl': "Sociale media waren getuige van enorme hoeveelheden verkeerde informatie die elke dag circuleerden tijdens de Covid-19 pandemie zodanig dat de directeur-generaal van de WHO het fenomeen noemde als 'infodemisch'. De nadelige gevolgen van dergelijke onjuiste informatie zijn zeer uiteenlopend. Het identificeren en elimineren van de bronnen van verkeerde informatie wordt dus zeer cruciaal, vooral wanneer massale paniek alleen kan worden beheerst door de juiste informatie. Handmatige identificatie is echter lastig, omdat er dagelijks zoveel gegevens worden gegenereerd. Dit toont het belang aan van automatische identificatie van misinformatieve berichten op sociale media. WNUT-2020 Taak 2 richt zich op het bouwen van systemen voor automatische identificatie van informatieve tweets. In dit artikel bespreek ik mijn aanpak van WNUT-2020 Taak 2. Ik heb elf varianten van vier transformatornetwerken -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, en twee verschillende preprocessing technieken verfijnd om goede resultaten te behalen. Mijn topinzending behaalde een F1-score van 85,3% in de eindbeoordeling.", 'da': 'De sociale medier var vidne til, at store mængder misinformation blev cirkuleret hver dag under Covid-19-pandemien, så WHO\'s generaldirektør kaldte fænomenet "infodemisk". De dårlige virkninger af sådan misinformation er mangfoldige. Derfor bliver det meget vigtigt at identificere og fjerne kilderne til misinformation, især når massepanik kun kan kontrolleres gennem de rigtige oplysninger. Manuel identifikation er imidlertid vanskelig, idet der genereres så store mængder data hver dag. Dette viser vigtigheden af automatisk identifikation af misinformative indlæg på sociale medier. WNUT-2020 Opgave 2 sigter mod at opbygge systemer til automatisk identifikation af informative tweets. I denne artikel diskuterer jeg min tilgang til WNUT-2020 opgave 2. Jeg finjusterede elleve varianter af fire transformatornetværk - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, oven i to forskellige forbearbejdningsteknikker for at høste gode resultater. Min bedste indsendelse opnåede en F1-score på 85,3% i den endelige evaluering.', 'hr': "Socijalni mediji svjedočili su ogromne količine pogrešne informacije koje se šire svaki dan tijekom pandemije Covid-19 tako puno kako bi generalni direktor Svetske organizacije nazvao fenomen 'infodemičkim'. Loše učinke takve pogrešne informacije su multifarijske. Dakle, identifikacija i eliminacija izvora pogrešne informacije postaje vrlo važna, posebno kada se masovna panika može kontrolirati samo kroz prave informacije. Međutim, ručna identifikacija je teška, s tako velikom količinom podataka koje se proizvode svaki dan. To pokazuje važnost automatske identifikacije nepravilnih mjesta na društvenim medijima. WNUT-2020 zadatak 2 cilj je izgradnju sustava za automatsku identifikaciju informativnih tweeta. U ovom papiru razgovaram o svom pristupu zadatku 2. WNUT-2020. Napravio sam 11 varianta četiri transformacijske mreže - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, na vrhu dvije različite tehnike preobrađivanja kako bi dobio dobre rezultate. Moja najbolja podnošenja postigla je rezultat F1 od 85,3% u konačnoj procjeni.", 'de': 'In den sozialen Medien wurden während der Covid-19-Pandemie täglich große Mengen an Fehlinformationen verbreitet, so dass der WHO-Generaldirektor das Phänomen als "infodemisch" bezeichnete. Die negativen Auswirkungen solcher Fehlinformationen sind vielfältig. Daher wird die Identifizierung und Beseitigung der Quellen von Fehlinformationen sehr wichtig, besonders wenn Massenpanik nur durch die richtigen Informationen kontrolliert werden kann. Die manuelle Identifizierung ist jedoch mühsam, da täglich so große Datenmengen generiert werden. Dies zeigt, wie wichtig es ist, missinformationelle Beiträge in sozialen Medien automatisch zu identifizieren. WNUT-2020 Aufgabe 2 zielt darauf ab, Systeme zur automatischen Identifikation informativer Tweets zu entwickeln. In diesem Beitrag diskutiere ich meinen Ansatz zur WNUT-2020 Task 2. Ich habe elf Varianten von vier Transformatornetzen – BERT, RoBERTa, XLM-RoBERTa, ELECTRA – sowie zwei verschiedene Vorverarbeitungstechniken optimiert, um gute Ergebnisse zu erzielen. Meine Top-Einreichung erreichte einen F1-Score von 85,3% in der abschließenden Bewertung.', 'fa': 'رسانه\u200cهای اجتماعی شاهد بسیار زیادی از غلط اندازه\u200cهای غلط هر روز در طول پاندمیک کووید-۱۹ می\u200cشوند تا مدیر ژنرال سازمان جهانی این پدیده را به عنوان "infodemic" نامیده شود. اثرات بدی از چنین تغییر تغییر دادن خیلی متفاوتی هستند. بنابراین، شناسایی و پاک کردن منابع غلط سازی بسیار مهم می شود، مخصوصا وقتی ترس جمعیت فقط از طریق اطلاعات درست کنترل می شود. با این حال، شناسایی دستی سخت است، با چنین اندازه\u200cهای داده\u200cهای بزرگی که هر روز تولید می\u200cشوند. این نشان می دهد که اهمیت شناسایی اتوماتیک پوستهای غیرقابل قالبی در رسانه\u200cهای اجتماعی است. وظیفه ۲ WNUT-۲۰۰۲ هدف به ساختن سیستم\u200cها برای شناسایی خودکار توئیت\u200cهای اطلاعات است. در این کاغذ، من در مورد دسترسی خودم به وظیفه دوم WNUT-2020 صحبت کردم. من ۱۱ متفاوت از چهار شبکه تغییر دهنده\u200cها را خوب تنظیم کردم -BERT, RoBERTa, XLM-RoBERTa, ELECTRA، بر بالای دو تکنیک پیش پردازشی متفاوت تا نتیجه\u200cهای خوب را برگیرم. تحويل بالايي من در ارزيابي نهايي از 85.3 درصد فو 1 رسيده', 'ko': "코로나19 팬데믹(세계보건기구) 사무총장이 이런 현상을'정보 전파'라고 부르기 위해 소셜미디어는 매일 대량의 잘못된 정보를 퍼뜨리고 있다이런 잘못된 정보의 좋지 않은 영향은 다양하다.따라서 잘못된 정보의 출처를 식별하고 제거하는 것이 중요하다. 특히 정확한 정보를 통해만 대규모 공황을 통제할 수 있을 때다.그러나 인공 식별은 매우 어려워서 매일 대량의 데이터를 생성할 수 있다.이는 소셜미디어에서 잘못된 정보 게시물을 자동으로 식별하는 중요성을 보여준다.WNUT-2020 임무 2는 정보 트윗을 자동으로 인식하는 시스템을 구축하기 위한 것입니다.본문에서 나는 WNUT-2020 임무 2에 대한 나의 방법을 토론할 것이다.나는 두 가지 서로 다른 예처리 기술을 토대로 네 개의 변압기 네트워크의 11개의 변체인 버트, 로버타, XLM 로버타, ELECTRA를 미세하게 조정하여 좋은 결과를 얻었다.최종 평가에서 제 첫 제출 F1의 성적은 85.3%에 달했다.", 'id': "Social media witnessed vast amounts of misinformation being circulated every day during the Covid-19 pandemic so much so that the WHO Director-General termed the phenomenon as 'infodemic.'  Efek buruk dari salah informasi seperti itu berbeda-beda. Jadi, mengidentifikasi dan menghilangkan sumber misinformasi menjadi sangat penting, terutama ketika panik massa hanya dapat dikendalikan melalui informasi yang tepat. Namun, identifikasi manual sulit, dengan jumlah besar data yang dihasilkan setiap hari. Ini menunjukkan penting identifikasi otomatis dari pos informasi yang salah di media sosial. Tugas 2 WNUT-2020 bermaksud membangun sistem untuk identifikasi otomatis tweet informatif. In this paper, I discuss my approach to WNUT-2020 Task 2.  I fine-tuned eleven variants of four transformer networks -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, on top of two different preprocessing techniques to reap good results.  Pemberian utamaku mencapai skor F1 85,3% dalam evaluasi akhir.", 'sw': 'Vyombo vya habari vya kijamii vilishuhudia kiasi kikubwa cha taarifa za uovu zinasambazwa kila siku wakati wa ugonjwa wa makali ya 19 kwa hiyo Mkurugenzi Mkuu wa WHO alihitimisha hali hiyo kama \'ukosefu wa habari". Matokeo mabaya ya taarifa hizi ni mbalimbali. Kwa hiyo, kutambua na kuondoa vyanzo vya habari vibaya vingekuwa muhimu sana, hasa pale hofu la watu linaweza kudhibitiwa pekee kupitia taarifa sahihi. Hata hivyo, utambulisho wa vifaa vya mikononi ni vibaya, na kiasi kikubwa cha taarifa zinazotengenezwa kila siku. Hii inaonyesha umuhimu wa kutambuliwa kwa faragha ya makala zisizo na taarifa kwenye mitandao ya kijamii. Kazi 2 ya WNUT-2020 inalenga kujenga mfumo wa kutambua twiti za taarifa. Katika karatasi hii, ninajadili namna yangu ya kazi ya WNUT-2020. Nilikuwa na tofauti kumi na moja ya mitandao minne ya mabadiliko - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, juu ya mbinu mbili tofauti za upasuaji ili kuvuna matokeo mazuri. Ujumbe wangu wa juu ulipata kipindi cha F1 cha asilimia 85.3 katika tathmini ya mwisho.', 'tr': "Sosyal medya her gün Covid-19 pandemik sırasında birçok yanlış şekilde görünüyordu ki bu olayı 'infodemik' olarak adlandırdı. Şol ýalňyşlyk ýalňyşlyk netijesi birnäçe-üýtgeşik. Bärde, ýalňyş şekliniň çeşmelerini tanyşdyrmak we eliminlemek örän wajyp boldy, iň-eňsem gaty panika diňe dogry maglumatlar bilen kontrol edilip biler. Ýagna görä elipbi tanamak kynçylyksyz, her gün beýle uly sanlary berilýär. Bu sosyal medýdançasynda ýalňyşlyk meýdançalaryň awtomatik taýýarlanmagynyň wajyplygyny görkezýär. WNUT-2020 Görev 2-nji Görev informatiýaly tweetlerin otomatik tanyşdyrmasyny üçin sistemleri düzəldirmegini amaçlaýar. Bu kagyzda, WNUT-2020 Görevi 2-ine gollanýanymy gürrüň berýärin. Men dört transformer aýtlaryň on beýik sany düzümlendirdim -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, gowy netijeleri üçin iki beýik üýtgeşme teknikleriniň üstünde. Meniň iň üst suratym soňky çykyşlygynda F1-score 85,3%-ny tapdy.", 'af': 'Soziale media het die groot hoeveelheid verkeerde formasie getuig wat elke dag verskriklik word gedurende die Covid-19 pandemiek so baie sodat die WVO-Direktor-Generaal die fenomen as "infodemic" genoem het. Die slegte effekte van sodanige verkeerde informasie is multifarius. So, die identifiseer en eliminering van die bronne van verkeerde formasie word baie kruistelik, veral wanneer masse paniek slegs deur die regte inligting beheer kan word. Alhoewel, hand-identifikasie is swaar, met so groot hoeveelheid data wat elke dag genereer word. Hierdie wys die belangrikheid van outomatiese identifikasie van verkeerde pos op sosiale media. WNUT-2020 Opdrag 2 doel om stelsels te bou vir outomatiese identifikasie van informatiewe tweets. In hierdie papier, ek bespreek my toegang tot WNUT-2020 taak 2. Ek het elfde variante van vier transformeerder netwerke -BERT, RoBERTa, XLM- RoBERTa, ELECTRA, op die top van twee verskillende voorprosesseerde teknike om goeie resultate te kry. My boonste ondersteuning het \'n F1-telling van 85,3% in die eindelike evaluering bereik.', 'sq': "Media sociale ka qenë dëshmitare e sasive të mëdha të informimeve të gabuara që po qarkullohen çdo ditë gjatë pandemisë së Covid-19 në mënyrë që drejtori i përgjithshëm i WHO e quajti fenomenin 'infodemik'. Efektet e këqija të këtyre informatave janë shumë të ndryshme. Thus, identifying and eliminating the sources of misinformation becomes very crucial, especially when mass panic can be controlled only through the right information.  Megjithatë, identifikimi manual është i vështirë, me sasi të mëdha të dhënash të gjeneruara çdo ditë. Kjo tregon rëndësinë e identifikimit automatik të postimeve të gabuara informative në media sociale. WNUT-2020 Task 2 ka për qëllim ndërtimin e sistemeve për identifikimin automatik të tweeteve informative. Në këtë letër, diskutoj qasjen time ndaj detyrës 2 të WNUT-2020. Kam rregulluar njëmbëdhjetë variante të katër rrjeteve të transformuesve - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, mbi dy teknika të ndryshme të përgatitjes për të mbledhur rezultate të mira. Paraqitja ime më e lartë arriti një rezultat F1 prej 85.3% në vlerësimin përfundimtar.", 'am': 'ማኅበራዊ ሚዲያዎች በየቀኑ በቁጥር-19 ጥምቀት ላይ የተሰራረቡ የስሕተት መረጃዎች በቁጥጥር ያሳያል፡፡ የዚህ የስሕተት መረጃዎች ክፋት በብዛት ነው፡፡ ስለዚህም የስሕተት መረጃዎችን ማረጋገጥና ለማጥፋት እጅግ አስቸጋሪ ሆኖአል፤ ይልቁንም የህዝብ ፍርሃት በቀር በቀር በቀር በመጠበቅ ጊዜ ነው፡፡ ነገር ግን በዕለት ዕለት እንደዚህ ታላቅ የዳታ ቁጥጥር የሚፈጠር የጃንደረባ ማውጣት አስቸጋሪ ነው፡፡ ይህ ማኅበራዊ ሚዲያ ላይ የተሳሳተውን የስህተት ጽሑፎችን በራሱ ማውቀት የሚያስፈልገውን ግለጽ ያሳያል፡፡ WNUT-2020 Task 2 aims at building systems for automatic identification of informative tweets.  በዚህ ገጾች ውስጥ የWNUT-2020 ስራ 2 ስራ መግባቴን እየተነጋገርሁ፡፡ በአራቱ ለውጥ መረብ ላይ አሥራ አንድ የተለየ ጥያቄ ብሬት፣ ሮብሬታ፣ XLM-RoBERTA፣ ኤሌክትራ፣ መልካምን ፍሬት ለማጭድ በተለየ ሁለት ልዩ ጥያቄዎች ላይ ነው፡፡ My top submission achieved an F1-score of 85.3% in the final evaluation.', 'bs': "Socijalni mediji su svjedoci ogromne količine pogrešne informacije koje se šire svaki dan tokom pandemije Covid-19 tako mnogo da je generalni direktor Svetske organizacije nazvao fenomen 'infodemičkim'. Loše učinke takve pogrešne informacije su multifarijske. Dakle, identifikacija i eliminacija izvora pogrešne informacije postaje vrlo važna, posebno kada se masovna panika može kontrolirati samo kroz pravu informaciju. Međutim, ručna identifikacija je teška, s tako velikom količinom podataka koje se proizvode svaki dan. To pokazuje važnost automatske identifikacije nepravilnih postaja na društvenim medijima. Državni zadatak WNUT-2020 je cilj za gradnju sustava za automatsku identifikaciju informativnih tweeta. U ovom papiru razgovaram o svom pristupu zadatku 2. WNUT-2020. Napravio sam 11 varianta četiri transformacijske mreže - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, na vrhu dva različita tehnika preprocessiranja kako bi dobio dobre rezultate. Moja najveća podnošenja postigla je rezultat F1 od 85,3% u konačnoj procjeni.", 'ca': 'Els mitjans socials van ser testimonis de grans quantitats de malinformació que es circulaven cada dia durant la pandèmia del Pacte-19 tant que el Director General de la OMS va anomenar el fenomen "infodemic". Els mals efectes d\'aquesta mala informació són multifàries. Així que la identificació i eliminació de les fonts de malinformació es converteix en molt crucial, especialment quan el pànic massiu només pot ser controlat a través de la informació correcta. Tanmateix, l\'identificació manual és difícil, amb tantes quantitats de dades generades cada dia. Això demostra l\'importància de la identificació automàtica de posts de mala informació als mitjans socials. La tasca 2 del WNUT-2020 té l\'objectiu de construir sistemes d\'identificació automàtica de tweets informatius. En aquest paper, discuto el meu enfocament a la 2ª tasca del WNUT-2020. I fine-tuned eleven variants of four transformer networks -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, on top of two different preprocessing techniques to reap good results.  La meva suposició va aconseguir una puntuació F1 del 85,3% en l\'evaluació final.', 'hy': 'Սոցիալական լրատվամիջոցները վկայում էին, որ ամբողջ օրը սխալ տեղեկատվություն է տարածվում CovID-19-ի պանդեմիայի ընթացքում, այնքան շատ, որ ՀԱԿ-ի գլխավոր տնօրենը այդ ֆենոմենը անվանում էր "ինֆոդեմիա": Այսպիսի սխալ տեղեկատվության վատ ազդեցությունները բազմազան են: Այսպիսով, սխալ ինֆորմացիայի աղբյուրների հայտնաբերումը և վերացումը շատ կարևոր է դառնում, հատկապես երբ զանգվածային պանիկա կարելի է վերահսկել միայն ճիշտ ինֆորմացիայի միջոցով: Այնուամենայնիվ, ձեռքի ճանաչելը դժվար է, քանի որ այսքան մեծ քանակությամբ տվյալներ են ստեղծում ամեն օր: Սա ցույց է տալիս սոցիալական լրատվամիջոցների սխալ տեղեկատվական դիրքերի ավտոմատիկ հայտնաբերման կարևորությունը: Աշխարհային Ազգային Ազգային Ազգային Համակարգ 2020-ի 2-ը նպատակն է կառուցել համակարգեր ինֆորմատիվ թվիթերի ինքնաբացահայտելու համար: Այս թղթի մեջ ես քննարկում եմ իմ մոտեցումը ՀԱԿ-2020-ի երկրորդ խնդիրը: Ես բարձրացրեցի չորս վերափոխվող ցանցերի տասնմեկ տարբերակը\' Բերթ, Ռոբերթ, XLM-Ռոբերթ, Էլեկտրա, լավ արդյունքներ ստանալու համար երկու տարբեր վերափոխվող տեխնոլոգիաների վրա: My top submission achieved an F1-score of 85.3% in the final evaluation.', 'bn': 'সামাজিক প্রচার মাধ্যম প্রতিদিন কোভিড-১৯ প্যানেডিয়ার সময় ভুল তথ্য ছড়িয়ে পড়ার বিশাল পরিমাণ প্রত্যক্ষ করেছে যাতে উইএইচও ডিরেক্টর-জেনারেল এই ঘটন এই ধরনের ভুল তথ্যের প্রভাব বেশিরভাগ। Thus, identifying and eliminating the sources of misinformation becomes very crucial, especially when mass panic can be controlled only through the right information.  তবে মানুষের চিহ্ন বিপদজনক, প্রতিদিন এই ধরনের বিশাল তথ্য তৈরি করা হয়। এটি সামাজিক প্রচার মাধ্যমে ভুল তথ্য পোস্টের স্বয়ংক্রিয়ভাবে চিহ্নিত করার গুরুত্বপূর্ণ। উইনউট-২০২০ কাজ ২ এর লক্ষ্য হচ্ছে তথ্য টুইটের স্বয়ংক্রিয়ভাবে চিহ্নিত করার জন্য সিস্টেম বানানোর জন্য। এই পত্রিকায়, আমি WNUT-2020 টাস্ক ২ এর কাছে আমার পদক্ষেপ নিয়ে আলোচনা করি। আমি চারটি রান্নার্নার্নার নেটওয়ার্কের ১১টি ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভ আমার সর্বোচ্চ মূল্যের মাধ্যমে ৫৫. ৩% এফ১ স্কোর অর্জন করেছে।', 'et': 'Sotsiaalmeedias levitati Covid-19 pandeemia ajal iga päev tohutult valeinformatsiooni, nii et WHO peadirektor nimetas seda nähtust infodeemiliseks. Sellise valeteabe kahjulik mõju on mitmekülgne. Seega muutub väga oluliseks valeinformatsiooni allikate tuvastamine ja kõrvaldamine, eriti kui massilist paanikat saab kontrollida ainult õige teabe abil. Kuid käsitsi tuvastamine on raske, sest nii suur kogus andmeid tekitatakse iga päev. See näitab valeinformatiivsete postituste automaatse tuvastamise tähtsust sotsiaalmeedias. WNUT-2020 ülesande 2 eesmärk on luua süsteemid informatiivsete säutsude automaatseks tuvastamiseks. Käesolevas dokumendis arutan oma lähenemisviisi WNUT 2020 ülesandele 2. Hästi häälestasin nelja trafovõrgu üheteistkümne variandi - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, lisaks kahele erinevale eeltöötlustehnikale, et saavutada häid tulemusi. Minu parim esitus saavutas lõpphinnangus F1-skoori 85,3%.', 'fi': 'Sosiaalisessa mediassa levitettiin valtavia mﾃ､ﾃ､riﾃ､ vﾃ､ﾃ､rﾃ､ﾃ､ tietoa joka pﾃ､ivﾃ､ Covid-19-pandemian aikana niin paljon, ettﾃ､ WHO:n pﾃ､ﾃ､johtaja kutsui ilmiﾃｶtﾃ､ "infodemiksi". Tﾃ､llaisen harhatiedon haitalliset vaikutukset ovat moninaisia. Nﾃ､in ollen vﾃ､ﾃ､rinformaation lﾃ､hteiden tunnistaminen ja poistaminen on erittﾃ､in tﾃ､rkeﾃ､ﾃ､, varsinkin kun massapaniikkia voidaan hallita vain oikeilla tiedoilla. Manuaalinen tunnistaminen on kuitenkin hankalaa, ja nﾃ､in suuria mﾃ､ﾃ､riﾃ､ dataa syntyy joka pﾃ､ivﾃ､. Tﾃ､mﾃ､ osoittaa, kuinka tﾃ､rkeﾃ､ﾃ､ on tunnistaa automaattisesti virheelliset viestit sosiaalisessa mediassa. WNUT-2020 Task 2 pyrkii rakentamaan jﾃ､rjestelmiﾃ､ informatiivisten twiittien automaattiseen tunnistamiseen. Tﾃ､ssﾃ､ asiakirjassa kﾃ､sittelen lﾃ､hestymistapaani WNUT-2020 -tehtﾃ､vﾃ､ﾃ､n 2. Hienosﾃ､ﾃ､din neljﾃ､n muuntajaverkon (BERT, RoBERTa, XLM-RoBERTa, ELECTRA) 11 varianttia kahden eri esiprosessointitekniikan pﾃ､ﾃ､lle saadakseni hyviﾃ､ tuloksia. Paras ehdotukseni saavutti F1-pisteen 85,3% lopullisessa arvioinnissa.', 'cs': 'Sociální média byly svědky obrovského množství dezinformací, které se během pandemie Covid-19 každý den obíhají, natolik, že generální ředitel WHO označil tento jev za "infodemický". Špatné účinky takových dezinformací jsou mnohostranné. Zjištění a odstranění zdrojů dezinformací se tedy stává velmi důležitým způsobem, zejména když lze masovou paniku ovládat pouze prostřednictvím správných informací. Ruční identifikace je však náročná, protože každý den se generuje velké množství dat. To ukazuje na důležitost automatické identifikace dezinformativních příspěvků na sociálních médiích. WNUT-2020 Úkol 2 se zaměřuje na budování systémů pro automatickou identifikaci informačních tweetů. V tomto článku diskutuji svůj přístup k úkolu WNUT-2020 2. Jemně jsem vyladil jedenáct variant čtyř transformátorových sítí – BERT, RoBERTa, XLM-RoBERTa, ELECTRA, a navíc dvě různé techniky předzpracování, abych dosáhl dobrých výsledků. Můj nejlepší příspěvek dosáhl F1 skóre 85,3% v závěrečném hodnocení.', 'az': "Sosyal media hər gün Covid-19 pandemik sırasında çox çox yanlış informasyonun yayılmasına şahid oldu ki, WHO-General Direktörü bu fenomeni 'infodemik' adlandırdı. Bütün yanlışlıqların təsirləri çoxlu təsirdir. Beləliklə, yanlış informasyonun kaynaqlarını tanıma və eliminləmə çox vacib olur, özlərinə də qüvvətli panik yalnız doğru bilgi vasitəsilə kontrol ediləndə. Əlbəttə, bu böyük çox məlumat günlük ürəklənir. Bu, sosyal mediyalarda yanlış məlumatların avtomatik təsdiqlənməsinin vacibətini göstərir. WNUT-2020 İkinci Gözəl 2-si informativ twetlərin otomatik tanıdılması üçün sistemləri inşa etmək məqsədilə məqsədildir. Bu kağıtda, WNUT-2020 İkinci Görevi ilə yaxınlığımı mübahisə edirəm. Mən dörd transformer ağlarının on birini düzəltdim -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, yaxşı sonuçlar almaq üçün iki müxtəlif preprocessing tehniklərinin üstündə. Ən yüksək təsdiqliyim son değerlendirmədə F1 dərəcəsinin 85,3%-ini qəbul etdi.", 'jv': 'Media sotiné sakjane éntuk akeh pisan Rong-Pasing awak dhéwé éntuk kayané petani sing berarti sabên Rong-Pasing Covideo-19 wigatining Rong-Pasing awak dhéwé "informasi" sing berarti. Laptop" and "Desktop Kowe, njaluk-nambah karo perusahaan winih akeh informasi dipun-perusahaan jhe isih dikenal, supoyo iso dianggap kanggo kalam-pancen iso nguasai perusahaan kelas informasi lunga. Nanging, sampeyan Manual kang dilakokke maneh Iki ngerti barang akeh akeh lanjut kanggo ngerasakno akeh apa-apa ning media sotiki. WNUT-2020 Nyong ngomong karo paper iki, aku ngerasakno kanggo WNUT-2020 task 2 Jejaring Rasané sing paling nggambar uwong metu F1-kaling cobalé 5.3% nang assemper tuku.', 'he': 'התקשורת החברתית ראתה כמויות עצומות של מידע לא נכון שפורסם כל יום במהלך הפנדמיה של Covid-19 כל כך הרבה כך שהמנהל הכללי של WHO קרא התופעה "אינפודמית". השפעות הרעות של מידע כזה לא נכון הן רבות. לכן, זיהוי והמחסל את מקורות המידע הלא נכון הופך להיות מאוד קריטי, במיוחד כאשר פאניקה מסיבית יכולה לשלוט רק דרך המידע הנכון. עם זאת, זיהוי ידני קשה, עם כמויות גדולות כזו של נתונים יוצרים כל יום. זה מראה את החשיבות של זיהוי אוטומטי של משימות לא מידעיות על התקשורת החברתית. מטרה 2 של WNUT-2020 היא לבנות מערכות לזהות אוטומטית של טוויטים מידעיים. בעיתון הזה, אני מדבר על הגישה שלי למשימה 2 של WNUT-2020. שידרתי 11 שונים של ארבעה רשתות מעליפות - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, בנוסף לשני טכניקות מעליפות שונות כדי לקבל תוצאות טובות. My top submission achieved an F1-score of 85.3% in the final evaluation.', 'sk': 'Na družbenih omrežjih je bilo med pandemijo Covid-19 vsak dan priča kroženju velikih količin napačnih informacij, tako da je generalni direktor SZO pojav imenoval "infodemik". Škodljivi učinki takih napačnih informacij so večkratni. Tako postane prepoznavanje in odpravljanje virov napačnih informacij zelo ključnega pomena, zlasti ko je množična panika mogoče nadzorovati le s pravimi informacijami. Vendar pa je ročna identifikacija težavna, saj se vsak dan ustvarjajo tako velike količine podatkov. To kaže na pomen avtomatične identifikacije napačnih objav na družbenih omrežjih. WNUT-2020 Naloga 2 je namenjena gradnji sistemov za avtomatsko identifikacijo informativnih tweetov. V tem dokumentu razpravljam o svojem pristopu k nalogi 2 WNUT-2020. Izdelala sem enajst različic štirih transformatorskih omrežij - BERT, RoBERTa, XLM-RoBERTa, ELECTRA, poleg dveh različnih tehnik predobdelave, da bi dosegla dobre rezultate. Moja najboljša predložitev je dosegla 85,3-odstotno oceno F1.', 'ha': 'Shirin mutane da jamii na shaida masu yawa za\'a circe information ɗin duk yini a lokacin the coverid-19 agogon so so as to, Director-General of the WHO na ƙara wannan abu as "info odemic". Misãlin bayani na wannan misinformation ne masu yawa. Kayya, bayan haka, ganin da kuma a tafiyar da sourcen information na ƙarya, yana da muhimu, kuma haske idan ana iya lissafa tsõro kan mutane kawai na bayan information na gaskiya. A lokacin da ake iya ganin hannun aiki na zartar da, kuma yana da yawan data masu girma wanda ake samar a koyau. Wannan yana nũna muhimu wa\'a gane farat ɗaya na wajen makala na misinformation a kan mitandai da jamii. Taimar WNUT-2020 A cikin wannan takarda, zan yi jayayya da hanyoTa zuwa WNUT-2020 Tafiyar 2. I fine-tuned eleven variants of four transformer networks -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, on top of two different preprocessing techniques to reap good results.  Madagaskiyãta na kai F1 na sami matsayin 85.3 a ƙarshen rabo.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ནང་དུ་Covid-19 pandemic Day རེ་རེར་བཞིན་པའི་སྐྱེས་ཆེན་མང་པོ་ཞིག་ལ་མཐོང་སྣང་བྱུང་བར་ཆེན་བྱུང་བ་རེད། འདིའི་ལྟ་བུའི་རྒྱུན་ལྡན་གྱི་ནོར་བ་མང་པོ་ཞིག་ཡིན། དེར་བརྟེན། རྒྱུན་ལྡན་གྱི་འབྱུང་ཁུངས་རྟོགས་དང་དུས་གཏོང་ནི་གལ་ཆེན་ཤིག་ཏུ་ཆེན་པོ་ཆགས་ཡོད། ཁྱད་དུ་ཆེ་ཆུང་སེམས་གས ཡིན་ནའང་། ལག་བཟོས་identification་ནི་གནད་དོན་ཡིན་པས། རེ་རེར་སྐབས་འདི་གསལ་བཤད་ཀྱི་ཆ་རྐྱེན་ཡོད་པ་རེད། འདིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་ཏུ་གནས་ཡུལ་རྒྱུན་ལྡན་གྱི་རང་འགུལ་གྱིས་ངོས་འཛིན་དགོས་པ WNUT-2020 Task 2 aims at building systems for automatic identification of informative tweets. ཤོག་བུ་འདིའི་ནང་དུ་ངས་རང་གི་གཟུགས་སྐོར་ལ་WNUT-2020་ལས་ཀ་གཉིས་བར་བཤད་ཀྱི་ཡོད། I fine-tuned 11 variants of four transformer networks -BERT, RoBERTa, XLM-RoBERTa, ELECTRA, on top of two different preprocessing techniques to reap good results. ངའི་མགོ་རིམ་གྱི་ཞབས་ཞུ་བ་ཡིན་མཐའ་མི་རིམ་པ་ལས་85.3% ཡིན།'}
{'en': 'CXP949 at WNUT-2020 Task 2 : Extracting Informative COVID-19 Tweets-RoBERTa Ensembles and The Continued Relevance of Handcrafted Features CXP 949 at  WNUT -2020 Task 2: Extracting Informative  COVID -19 Tweets -  R o BERT a Ensembles and The Continued Relevance of Handcrafted Features', 'ar': 'CXP949 في WNUT-2020 المهمة 2: استخراج تغريدات COVID-19 الإعلامية - مجموعات RoBERTa والصلة المستمرة للميزات المصنوعة يدويًا', 'pt': 'CXP949 no WNUT-2020 Tarefa 2: Extraindo tweets informativos sobre COVID-19 - RoBERTa Ensembles e a relevância contínua de recursos artesanais', 'fr': 'CXP949 à la WNUT-2020 Tâche 2\xa0: Extraire des tweets informatifs sur la COVID-19 - Les ensembles Roberta et la pertinence continue des caractéristiques artisanales', 'es': 'CXP949 en la Tarea 2 de WNUT-2020: Extracción de tweets informativos sobre COVID-19 - Los conjuntos Roberta y la relevancia continua de las características artesanales', 'ja': 'WNUT -2020でのCXP 949タスク2 ：新型コロナウイルスに関する情報ツイートの抽出- RoBERTaアンサンブルと手作り機能の継続的な関連性', 'zh': 'CXP949在WNUT-2020务2:取信丰者COVID-19推文 - RoBERTa合奏手工之相关性', 'ru': 'CXP949 на WNUT-2020 Задача 2: Извлечение информативных твитов о COVID-19 - Ансамбли RoBERTa и сохраняющаяся актуальность функций ручной работы', 'hi': 'WNUT-2020 कार्य 2 पर CXP949: जानकारीपूर्ण कोविड -19 ट्वीट्स निकालना - RoBERTa Ensembles और Handcrafted सुविधाओं की निरंतर प्रासंगिकता', 'ga': 'CXP949 ag WNUT-2020 Tasc 2: Tweetanna Faisnéiseacha COVID-19 a Bhaint - Ensembles RoBERTa agus Ábharthacht Leanúnach Gnéithe Lámhdhéanta', 'ka': 'CXP949 WNUT-2020 პარამეტრი 2: ინფორმატიური COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'hu': 'CXP949 a WNUT-2020 2. feladat: Információs COVID-19 tweetek kivonása - RoBERTa Ensembles és a kézműves funkciók folyamatos relevanciája', 'el': 'Εργασία 2: Εξαγωγή πληροφοριακών tweets από σύνολα και η συνεχής σημασία των χειροποίητων χαρακτηριστικών', 'it': 'CXP949 a WNUT-2020 Task 2: Estrazione di tweet informativi COVID-19 - RoBERTa Ensembles e la continua rilevanza delle caratteristiche artigianali', 'kk': 'CXP949 WNUT-2020 2- тапсырмасында: Мәліметті COVID-19 Tweets - RoBERTa Ensembles және Қол құрылған мүмкіндіктердің жалғастыру қатынасы', 'lt': 'CXP949 WNUT-2020 2 užduotis: Informacinių COVID-19 Tweetų ekstrahavimas – RoBERTa Ensembles ir tęstinis rankinių savybių taikymas', 'mt': "CXP949 fid-WNUT-2020 Task 2: Estrazzjoni ta' Tweets Informattivi COVID-19 - Ensembles RoBERTa u r-Relevanza Kontinwata tal-Karatteristiċi Magħmula bl-idejn", 'mk': 'CXP949 на ВНУТ-2020 задача 2: Екстрактирање на информативните твитови COVID-19 - Енсембли на Роберта и континуираната релевантност на рачно произведени карактеристики', 'ms': 'CXP949 di WNUT-2020 Tugas 2: Mengekstrak Maklumat COVID-19 Tweets - RoBERTa Ensembles dan Relevansi Teruskan Ciri-ciri Dicipta Tangan', 'ml': 'WNUT- 2020 ടാസ്ക് 2- ല്\u200d സിക്സ്പി949: വിവരങ്ങളുടെ വിവരങ്ങള്\u200d കോവിഡി- 19 ടൂട്ടുകള്\u200d പുറത്തെടുക്കുന്നു', 'mn': 'CXP949 WNUT-2020 Task 2: Informative COVID-19 Tweets extracting - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'no': 'CXP949 på WNUT-2020 oppgåve 2: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'ro': 'CXP949 la WNUT-2020 Sarcina 2: Extragerea tweeturilor informative COVID-19 - Ansamblurile RoBERTa și relevanța continuă a caracteristicilor artizanale', 'sr': 'CXP949 na zadatku 2. WNUT-2020: izvlačenje informativnih COVID-19 Tweets - RoBERTa Ensembles i nastavljanje povezanosti rukopisanih karaktera', 'pl': 'CXP949 na WNUT-2020 Zadanie 2: Wydobycie informacyjnych tweetów COVID-19 do zespołów RoBERTa i ciągłe znaczenie ręcznie wykonanych cech', 'si': 'CXP949 at WNuT-2020Job 2: Extraction of Infotive COVID-19 Tweets - RoBERTa Ensemble and The Contined erlevance of Handcraft Featuries', 'so': 'CXP949 at WNUT-2020 Task 2: Extracting Informative COVID-19 Tweets - RoBERta Ensembles and The Continued Relations of HandHandheld Features', 'sv': 'CXP949 på WNUT-2020 Uppgift 2: Extrahera information om COVID-19 tweets - RoBERTa Ensembles och den fortsatta relevansen av handgjorda funktioner', 'ur': 'WNUT-2020 Task 2 میں CXP949: Informative COVID-19 Tweets Extracting - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'ta': 'WNUT- 2020 பணியில் CXP949: தகவல் COVID- 19 Tweets - RoBERta Ensembles and Continued Relations of Handheld Features', 'uz': 'Comment', 'vi': 'CXP949 ở WGiờ-2020 Task 2: Exting Information COVID-19 Tweet - RozerTa Ensembles và the liên tục Relnạp các đặc trưng đồ thủ công', 'bg': 'Задача 2: Извличане на информативни туитове на Ансамбли и продължаващата релевантност на ръчно изработените функции', 'hr': 'CXP949 na zadatku 2. WNUT-2020: izvlačenje informativnih COVID-19 Tweets - RoBERTa Ensembles i nastavljanje povezanosti rukopisanih karaktera', 'da': 'CXP949 på WNUT-2020 Opgave 2: Udtrækning af informative COVID-19 tweets - RoBERTa Ensembles og den fortsatte relevans af håndlavede funktioner', 'nl': 'CXP949 op WNUT-2020 Taak 2: Het extraheren van informatieve COVID-19 Tweets naar RoBERTa Ensembles en de voortdurende relevantie van handgemaakte functies', 'de': 'CXP949 bei WNUT-2020 Aufgabe 2: Extraktion informativer COVID-19 Tweets aus RoBERTa Ensembles und die anhaltende Relevanz handgefertigter Features', 'id': 'CXP949 di WNUT-2020 Task 2: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'fa': 'CXP949 در Task 2 WNUT-2020: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handmade Features', 'ko': 'CXP949의 WNUT-200 미션2: 풍부한 정보를 추출한 코로나 트윗-로버타 앙상블과 핸드메이드 기능의 지속적인 상관성', 'sw': 'CXP949 kwenye kazi ya WNUT-2020 2: Kutoa taarifa za COVID-19 za Twita - Tamko za RoBERta na Kuendelea Kuhusiana na Tamko zilizotolewa na mikononi', 'tr': 'CXP949 at WNUT-2020 Task 2: Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'af': 'CXP949 by WNUT-2020 Opdrag 2: Uitpak Informatiewe KOVID-19 Tweets - RoBERTa Ensembles en Die voortgaande Relevansie van Handkryfde Funksies', 'sq': 'CXP949 në WNUT-2020 Task 2: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'am': 'የWNUT-2020 ስራ 2: መረጃ ማውጣት COVID-19 Tweets - RoBERta Ensembles and The Continued Relation of Handheld Features', 'az': 'CXP949 WNUT-2020 Task 2: Informative COVID-19 Tweets Extracting - RoBERTa Ensembles and The Continued Relevance of Handcreated Features', 'hy': 'CXP949-ը World Trade Unions 2020-ի 2. խնդիրն է. COVID-19 ինֆորմացիոնալ թվիթեր դուրս բերելը - ՌոBERտա էնսեմբլեսը և ձեռագործված առանձնահատկությունների շարունակական կարևորությունը', 'bn': 'WNUT-2020 কাজ ২-এ সিক্সপি৯৪৯: তথ্য তথ্য প্রকাশ করা হচ্ছে কোভিড-১৯ টুইট- রোবের্তা এনসেম্বেল এবং হ্যান্ডক্র্যান্ড করা বৈশিষ্ট্যের বিনিম', 'bs': 'CXP949 na zadatku 2. WNUT-2020: izvlačenje informativnih COVID-19 Tweets - RoBERTa Ensembles i nastavljanje povezanosti rukopisanih karaktera', 'ca': 'CXP949 al WNUT-2020 Task 2: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'cs': 'CXP949 na WNUT-2020 Úkol 2: Extrahování informačních tweetů COVID-19 do souborů RoBERTa a pokračující relevance ručně vyráběných prvků', 'et': 'CXP949 WNUT-2020 ülesandel 2: informatiivsete COVID-19 tweetide väljavõtmine - RoBERTa ansamblid ja käsitöö funktsioonide jätkuv olulisus', 'fi': 'CXP949 WNUT-2020 -tapahtumassa Tehtävä 2: Informatiivisten COVID-19-twiittien poimiminen - RoBERTa-yhtyeet ja käsityönä tehtyjen ominaisuuksien jatkuva merkitys', 'jv': 'paper size', 'he': 'CXP949 ב-WNUT-2020 משימה 2: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features', 'ha': 'KCharselect unicode block name', 'sk': 'CXP949 na WNUT-2020 Naloga 2: Pridobivanje informativnih Tweets COVID-19 - RoBERTa ansambli in stalna pomembnost ročno izdelanih funkcij', 'bo': 'CXP949 at WNUT-2020 Task 2: Extracting Informative COVID-19 Tweets - RoBERTa Ensembles and The Continued Relevance of Handcrafted Features'}
{'en': 'This paper presents our submission to Task 2 of the Workshop on Noisy User-generated Text. We explore improving the performance of a pre-trained transformer-based language model fine-tuned for text classification through an ensemble implementation that makes use of corpus level information and a handcrafted feature. We test the effectiveness of including the aforementioned  features  in accommodating the challenges of a noisy data set centred on a specific subject outside the remit of the pre-training data. We show that inclusion of additional  features  can improve  classification  results and achieve a score within 2 points of the top performing team.', 'ar': 'تقدم هذه الورقة تقديمنا إلى المهمة 2 من ورشة العمل حول النص الصاخب الذي تم إنشاؤه بواسطة المستخدم. نستكشف تحسين أداء نموذج لغة قائم على المحولات مدرب مسبقًا تم ضبطه جيدًا لتصنيف النص من خلال تنفيذ مجموعة يستخدم معلومات مستوى المجموعة وميزة مصنوعة يدويًا. نحن نختبر فعالية تضمين الميزات المذكورة أعلاه في استيعاب تحديات مجموعة البيانات الصاخبة التي تركز على موضوع معين خارج نطاق بيانات ما قبل التدريب. نوضح أن تضمين ميزات إضافية يمكن أن يحسن نتائج التصنيف ويحقق نتيجة في حدود نقطتين من الفريق الأفضل أداءً.', 'es': 'Este artículo presenta nuestra presentación a la Tarea 2 del Taller sobre textos ruidosos generados por el usuario. Exploramos la mejora del rendimiento de un modelo de lenguaje basado en transformadores previamente entrenado y ajustado para la clasificación de textos a través de una implementación de conjunto que hace uso de información a nivel de corpus y una función hecha a mano. Probamos la eficacia de incluir las funciones mencionadas anteriormente para acomodarnos a los desafíos de un conjunto de datos ruidoso centrado en un tema específico fuera del alcance de los datos previos al entrenamiento. Demostramos que la inclusión de características adicionales puede mejorar los resultados de la clasificación y lograr una puntuación de menos de 2 puntos del equipo con mejor rendimiento.', 'pt': 'Este artigo apresenta nossa submissão à Tarefa 2 do Workshop sobre Texto Gerado pelo Usuário Noisy. Exploramos a melhoria do desempenho de um modelo de linguagem baseado em transformador pré-treinado ajustado para classificação de texto por meio de uma implementação de conjunto que faz uso de informações de nível de corpus e um recurso artesanal. Testamos a eficácia da inclusão dos recursos mencionados acima para acomodar os desafios de um conjunto de dados ruidoso centrado em um assunto específico fora do escopo dos dados de pré-treinamento. Mostramos que a inclusão de recursos adicionais pode melhorar os resultados de classificação e alcançar uma pontuação de até 2 pontos da equipe de melhor desempenho.', 'fr': "Cet article présente notre soumission à la tâche 2 de l'atelier sur le texte bruyant généré par l'utilisateur. Nous explorons l'amélioration des performances d'un modèle de langage pré-formé basé sur un transformateur et affiné pour la classification de texte grâce à une implémentation d'ensemble qui utilise des informations au niveau du corpus et une fonctionnalité conçue à la main. Nous testons l'efficacité de l'inclusion des fonctionnalités susmentionnées pour faire face aux défis d'un ensemble de données bruyant centré sur un sujet spécifique en dehors de la portée des données de pré-entraînement. Nous montrons que l'inclusion de fonctionnalités supplémentaires peut améliorer les résultats du classement et obtenir un score à moins de 2 points de l'équipe la plus performante.", 'ja': '本稿では、Noisy User - Generated TextワークショップのTask 2への提出を紹介する。私たちは、コーパスレベルの情報と手作り機能を利用したアンサンブル実装を通じて、テキスト分類のために微調整された事前訓練された変圧器ベースの言語モデルのパフォーマンスを改善することを模索しています。事前トレーニングデータの範囲外の特定の対象を中心としたノイズの多いデータセットの課題に対応するために、前述の機能を含めることの有効性をテストします。追加機能を組み込むことで、分類結果を改善し、トップパフォーマンスチームから2ポイント以内のスコアを達成できることを示しています。', 'zh': '本文介于嘈杂用户生成研讨会务2之交。 求其语料库级息,与其成功,以易转换器言,以类微调。 试包此有效性,以应练前数之外特定主题为中心嘈杂数集。 此则包他功可以改善分类,而使最佳者团队得分在2分之内。', 'hi': 'यह पेपर शोर उपयोगकर्ता-जनित पाठ पर कार्यशाला के कार्य 2 के लिए हमारे सबमिशन प्रस्तुत करता है। हम एक पूर्व प्रशिक्षित ट्रांसफॉर्मर-आधारित भाषा मॉडल के प्रदर्शन में सुधार का पता लगाते हैं जो एक पहनावा कार्यान्वयन के माध्यम से पाठ वर्गीकरण के लिए ठीक-ठाक है जो कॉर्पस स्तर की जानकारी और एक हस्तनिर्मित सुविधा का उपयोग करता है। हम पूर्व-प्रशिक्षण डेटा के प्रेषण के बाहर एक विशिष्ट विषय पर केंद्रित शोर डेटा सेट की चुनौतियों को समायोजित करने में उपरोक्त सुविधाओं को शामिल करने की प्रभावशीलता का परीक्षण करते हैं। हम दिखाते हैं कि अतिरिक्त सुविधाओं को शामिल करने से वर्गीकरण परिणामों में सुधार हो सकता है और शीर्ष प्रदर्शन करने वाली टीम के 2 अंकों के भीतर स्कोर प्राप्त हो सकता है।', 'ru': 'В настоящем документе представлена информация, представленная нами для выполнения задачи 2 Рабочего совещания по тексту, генерируемому шумными пользователями. Мы изучаем повышение производительности предварительно обученной языковой модели на основе трансформатора, доработанной для классификации текста посредством ансамблевой реализации, которая использует информацию на уровне корпуса и функцию ручной работы. Мы проверяем эффективность включения вышеупомянутых особенностей в решение проблем шумного набора данных, сосредоточенного на конкретной теме, выходящей за рамки предварительного обучения. Мы показываем, что включение дополнительных функций может улучшить результаты классификации и достичь результата в пределах 2 баллов от лучшей команды.', 'ga': 'Cuireann an páipéar seo ár n-aighneacht i láthair do Thasc 2 den Cheardlann ar Théacs Torann a Ghintear le hÚsáideoirí. Déanaimid iniúchadh ar fheabhas a chur ar fheidhmíocht samhail teanga réamh-oilte atá bunaithe ar chlaochladán atá mionchoigeartaithe do rangú téacs trí fheidhmiú ensemble a bhaineann úsáid as faisnéis ar leibhéal an chorpais agus gné lámhdhéanta. Déanaimid tástáil ar éifeachtacht na gnéithe thuasluaite a áireamh chun freastal ar na dúshláin a bhaineann le tacair sonraí torannacha atá dírithe ar ábhar ar leith lasmuigh de shainchúram na sonraí réamhoiliúna. Léirímid gur féidir feabhas a chur ar thorthaí rangaithe agus scór a bhaint amach laistigh de 2 phointe ón bhfoireann is airde feidhmíochta trí ghnéithe breise a áireamh.', 'el': 'Η παρούσα εργασία παρουσιάζει την υποβολή μας στην εργασία 2 του Εργαστηρίου για το θορυβώδες κείμενο που δημιουργείται από τους χρήστες. Ερευνούμε τη βελτίωση της απόδοσης ενός προ-εκπαιδευμένου μοντέλου γλώσσας βασισμένου στον μετασχηματιστή, το οποίο είναι συντονισμένο για ταξινόμηση κειμένου μέσω μιας εφαρμογής συνόλου που χρησιμοποιεί πληροφορίες σε επίπεδο σώματος και ένα χειροποίητο χαρακτηριστικό. Δοκιμάζουμε την αποτελεσματικότητα της συμπερίληψης των προαναφερθέντων χαρακτηριστικών στην αντιμετώπιση των προκλήσεων ενός θορυβώδους συνόλου δεδομένων που επικεντρώνεται σε ένα συγκεκριμένο θέμα εκτός της αρμοδιότητας των δεδομένων προενταξιακής εκπαίδευσης. Δείχνουμε ότι η συμπερίληψη πρόσθετων χαρακτηριστικών μπορεί να βελτιώσει τα αποτελέσματα ταξινόμησης και να επιτύχει ένα σκορ εντός δύο πόντων από την κορυφαία ομάδα.', 'hu': 'Ez a tanulmány bemutatja a zajos felhasználók által generált szövegről szóló Workshop 2. feladatát. A szövegosztályozásra finomhangolt, előre képzett transzformátor alapú nyelvmodell teljesítményének javítását vizsgáljuk egy korpusz szintű információkat és egy kézzel készített funkciót felhasználó együttes implementáció révén. Teszteljük, hogy a fent említett funkciók hatékonyságát egy adott témára összpontosító zajos adatkészlet kihívásainak megfelelően alkalmazkodnak-e. Megmutatjuk, hogy további funkciók bevonása javíthatja a besorolási eredményeket, és a legjobb teljesítményű csapat 2 pontján belül érheti el a pontszámot.', 'ka': 'ეს დოკუმენტი ჩვენი წარმოიდგინეთ სამუშაო მეორე დავალებისთვის სამუშაო წარმოიდგინეთ ტექსტის სამუშაო წარმოიდგინეთ. ჩვენ განსხვავებთ წინ განსხვავებული ტექსტის კლასიფიკაციისთვის ტრანფორმაციის მოდელის გამოსახულებას, რომელიც კოპუსის დონეზე ინფორმაციას და ხელსახულებული ფუნქციას გამოყენებს. ჩვენ შევცვალოთ ეფექტიურობას, რომელიც შეგვიძლია წინასწორებული ფუნქციების გამოსახულებაში, რომელიც კონტაქტიური განსახულებული მონაცემების გამოსახულებაში ცენტრირებული სექტიკ ჩვენ ჩვენ აჩვენებთ, რომ დამატებული ფუნქციების შენახვა შესაძლებელია კლასიფიკაციის შედეგების უფრო მეტად გავაკეთება და გავაკეთება შედეგების შედეგების 2 წუთში', 'it': "Questo articolo presenta la nostra presentazione al Task 2 del Workshop sul testo generato dagli utenti rumorosi. Esploriamo il miglioramento delle prestazioni di un modello linguistico pre-addestrato basato su trasformatori, perfezionato per la classificazione del testo attraverso un'implementazione ensemble che utilizza informazioni a livello di corpus e una funzionalità artigianale. Verifichiamo l'efficacia di includere le suddette funzionalità nell'affrontare le sfide di un set di dati rumoroso incentrato su un argomento specifico al di fuori della sfera di competenza dei dati pre-allenamento. Mostriamo che l'inclusione di funzionalità aggiuntive può migliorare i risultati della classifica e ottenere un punteggio entro 2 punti dalla squadra più performante.", 'kk': 'Бұл қағаз біздің 2- тапсырмаға қолданылатын Дыбыс пайдаланушының жасалған мәтіннің жұмыс істеуімізді көрсетеді. Біз мәтін классификациясының алдын- оқылған түрлендіруші тіл үлгісін жақсы түрлендіру үшін корпус деңгейінің мәліметін және қол құрылған мүмкіндіктерді қолдану арқылы жақсы түрлендіру үші Біз мәліметтердің алдын- оқыту мәліметінің шешімінің шешімінде орналасатын дыбыс деректерінің мәселелерін қолдануға болады. Біз қосымша мүмкіндіктерді қосу үшін классификациялық нәтижелерін жақсартып, жоғары оқу командасының 2 нүкте нәтижелерін жеткізе аламыз.', 'lt': 'Šiame dokumente pristatomas mūsų pranešimas „Triukšmo vartotojų sukelto teksto seminaro 2 užduotis“. Mes tiriame, kaip pagerinti iš anksto parengto kalbos modelio, pritaikyto teksto klasifikacijai, rezultatus naudojant kompleksą, kuriame naudojama korpuso lygio informacija ir rankiniu būdu. Bandome, kaip veiksmingai įtraukti pirmiau minėtas savybes sprendžiant triukšmingo duomenų rinkinio, kuriame dėmesys sutelkiamas į konkrečią temą, nepatenkantį į parengiamojo mokymo duomenų kompetenciją, uždavinius. Mes parodome, kad papildomų savybių įtraukimas gali pagerinti klasifikavimo rezultatus ir pasiekti rezultatus per 2 aukščiausios veiklos grupės punktus.', 'mk': 'Овој документ го претставува нашето пренесување на задачата 2 на работилницата за бучниот текст генериран од корисниците. Истражуваме подобрување на резултатите на предобучениот јазички модел базиран на трансформатори фино прилагоден за класификација на текст преку имплементација на ансемблот кој користи информации на ниво на корпус и рачно изработена карактеристика. Ние ја тестираме ефикасноста на вклучувањето на наведените карактеристики во прилагодувањето на предизвиците на бучниот груп податоци центриран на специфична тема надвор од надлежноста на податоците од предобуката. Ние покажуваме дека вклучувањето на дополнителни карактеристики може да ги подобри резултатите од класификацијата и да постигне резултат во рамките на 2 поени од најдобриот тим.', 'ms': 'Kertas ini memperkenalkan penghantaran kami ke Tugas 2 Kedai Kerja Teks yang Dijana oleh Pengguna Berbunyi. Kami mengeksplorasi meningkatkan prestasi model bahasa berdasarkan pengubah terlatih disesuaikan dengan baik untuk klasifikasi teks melalui pelaksanaan ensemble yang menggunakan maklumat aras corpus dan ciri-ciri buatan tangan. Kami menguji keefektivitas termasuk ciri-ciri terdahulu dalam mengakomodasi cabaran set data bunyi yang ditetapkan pada subjek tertentu diluar tugas data praselatihan. Kami menunjukkan bahawa penyelesaian ciri tambahan boleh meningkatkan keputusan klasifikasi dan mencapai skor dalam 2 titik pasukan yang paling baik.', 'mt': 'This paper presents our submission to Task 2 of the Workshop on Noisy User-generated Text.  Aħna nistudjaw it-titjib fil-prestazzjoni ta’ mudell lingwistiku bbażat fuq it-trasformatur imħarreġ minn qabel imfassal bir-reqqa għall-klassifikazzjoni tat-test permezz ta’ implimentazzjoni ta’ ensemble li tagħmel użu minn informazzjoni tal-livell corpus u karatteristika maħduma bl-idejn. Aħna nistestjaw l-effettività tal-inklużjoni tal-karatteristiċi msemmija hawn fuq fl-akkomodazzjoni tal-isfidi ta’ sett ta’ dejta storbjuż ċentrat fuq suġġett speċifiku barra mill-kompetenza tad-dejta ta’ qabel it-taħriġ. Aħna nuru li l-inklużjoni ta’ karatteristiċi addizzjonali tista’ ttejjeb ir-riżultati tal-klassifikazzjoni u tikseb punteġġ fi ħdan żewġ punti tat-tim ta’ prestazzjoni għolja.', 'ml': 'ഈ പത്രത്തില്\u200d നോസി ഉപയോക്താവ് സൃഷ്ടിച്ച പദാവലിയിലെ പണിയിടത്തിന്റെ ടാസ്ക് 2-ല്\u200d ഞങ്ങളുടെ കീഴ്പെടുത് ഞങ്ങള്\u200d പരിശീലിക്കുന്നത് മുമ്പ് പരിശീലിക്കപ്പെട്ട മാറ്റങ്ങള്\u200d അടിസ്ഥാനമായി മാറ്റുന്ന ഭാഷ മോഡലിന്റെ പ്രഭാവം മുന്\u200dകൂട്ടുന്നതാണ്. ടെക്സ്റ്റ മുമ്പ് വിവരങ്ങള്\u200d ചേര്\u200dത്തുകൊണ്ടിരിക്കുന്ന ശബ്ദ ഡേറ്റാ സെറ്റിന്റെ വിലപാടുകള്\u200d ചേര്\u200dക്കുന്നതില്\u200d നാം പരീക്ഷിക്കുന്നു. കൂടുതല്\u200d ഗുണഗണങ്ങള്\u200d ചേര്\u200dക്കുന്നത് ക്ലാസ്ഫിക്കല്\u200d ഫലങ്ങള്\u200d മെച്ചപ്പെടുത്തുന്നതും മുകളില്\u200d നിന്നുള്ള രണ്ടു പോയിന്റ', 'mn': 'Энэ цаас бидний Хүлэг хэрэглэгч үүсгэсэн Текст дээр ажлын 2-р ажиллах даалгаврыг харуулдаг. Бид өмнө сургалтын шилжүүлэгч хэл загварын үйл ажиллагааг сайжруулахыг судалж байна. Корпус түвшинд мэдээллийг ашиглаж, гар бүтээгдэхүүнийг ашиглаж байгаа загварын хуваалцах загварын загвар. Бид өмнө нь сургалтын мэдээллийн тусламжтайгаас гадна тодорхой сэдэв дээр төвлөрсөн чимээгүй өгөгдлийн сорилтуудын тусламжтайгаар дамжуулагдсан хэмжээний үр дүнтэй байдлыг шалгаж байна. Бид нэмэлт чадваруудыг нэмэгдүүлэх нь хуваалцааны үр дүнг сайжруулж, хамгийн дээд ажиллах багийн 2 цэгийн дотор оноо гаргаж чадна.', 'no': 'Denne papiret viser vårt innføring til oppgåva 2 av arbeidsområdet på lysbruk- laga tekst. Vi undersøker å forbetra utviklinga av eit føretrainert språk-modell som er fint oppsett for tekstklassifikasjon gjennom ein ensemble implementasjon som gjer bruk av korpusnivåinformasjon og ein handkryptert funksjon. Vi testar effektiviteten til å inkludere dei førehandsviste funksjonane i å oppretta utfordringane til ein støy datasett sentrert på eit spesifikk emne utenfor utfordringa av førehandsvisingsdata. Vi viser at inkludering av fleire funksjonar kan forbetra klassifikasjonsflate og oppnå eit poeng i to punkt av den øvste utføringsgruppa.', 'pl': 'Niniejszy artykuł przedstawia naszą zgłoszenie do Zadania 2 Warsztatu na temat Noisy User Generated Tekst. Badamy poprawę wydajności wstępnie przeszkolonego modelu językowego opartego na transformatorze dostrojonego do klasyfikacji tekstu poprzez implementację zespołu, która wykorzystuje informacje na poziomie korpusu i ręcznie wykonaną funkcję. Testujemy skuteczność włączenia wyżej wymienionych funkcji w sprostaniu wyzwaniom związanym z hałaśliwym zbiorem danych skoncentrowanym na konkretnym temacie poza zakresem danych przedtreningowych. Pokazujemy, że włączenie dodatkowych funkcji może poprawić wyniki klasyfikacji i osiągnąć wynik w ciągu dwóch punktów najlepiej wydajnej drużyny.', 'si': 'මේ පත්තේ අපේ වැඩසටහන් 2 වැඩසටහන් පෙන්වන්න පුළුවන්. අපි පරීක්ෂණය කරනවා ප්\u200dරීක්ෂණා කරපු භාෂාව ස්ථාපනය කරපු භාෂාව ස්ථාපනය සඳහා පරීක්ෂණ පරීක්ෂණය සඳහා පරීක්ෂණ පරීක්ෂණය ස අපි පරීක්ෂා කරනවා අවස්ථාවක් සම්බන්ධ කරලා තියෙන්නේ අවස්ථාවක් සම්බන්ධ වෙනුවෙන් අවස්ථාවක් සම්බන්ධ වෙනුවෙන් ව අපි පෙන්වන්නේ විශේෂ විශේෂ විශේෂ ප්\u200dරතිචාරයක් සම්බන්ධ වෙන්න පුළුවන් විශේෂ ප්\u200dරතිචාරයක', 'sr': 'Ovaj papir predstavlja našu predanost zadatku 2 radionice o tekstu proizvedenom korisniku Noisy. Istražujemo poboljšanje provedbe predobučenog jezičkog model a koji se nalazi na predobučenom transformatoru, koji je ispravljen za klasifikaciju teksta kroz provedbu kompleksa koja koristi informacije o nivou korpusa i karakteristiku koja su napravljena rukama. Testiramo učinkovitost uključujući navedene karakteristike u ubrzavanju izazova kompleta buknih podataka usmjerenog na određenu temu izvan podataka pre obuke. Pokazujemo da uključivanje dodatnih karakteristika može poboljšati rezultate klasifikacije i postići rezultat unutar 2 tačke najvišeg izvršnog tima.', 'ro': 'Această lucrare prezintă prezentarea noastră la sarcina 2 a Atelierului privind textul generat de utilizatori zgomotoși. Explorăm îmbunătățirea performanței unui model de limbaj pre-instruit bazat pe transformator, reglat fin pentru clasificarea textului printr-o implementare a ansamblului care utilizează informații la nivel de corpus și o caracteristică manuală. Testăm eficiența includerii caracteristicilor menționate mai sus în abordarea provocărilor unui set de date zgomotos centrat pe un anumit subiect care nu intră în sfera de competență a datelor pre-antrenament. Noi arătăm că includerea unor caracteristici suplimentare poate îmbunătăți rezultatele clasificării și poate obține un scor în limita a 2 puncte de la echipa cu performanțe de top.', 'so': 'Kanu wuxuu warqaddan u dhiibaa cashuurta 2 ee warqadda warqadda ah ee ku saabsan isticmaalaha noocyada ah. Waxaynu baaraynaa inuu horumarino sameynta qaababka afka hore oo lagu tababariyey si fiican looga dhigo fasaxa qoraalka, sida loo sameeyo qaab la soo bandhigayo macluumaadka heerka korpuska iyo faa’iido lagu sameeyo. Waxaynu tijaabinaynaa waxyaabaha ku saabsan waxyaabaha horay loo sii sheegay, in lagu barto dhibaatooyinka data qaylada oo lagu xardhay maadooyin gaar ah oo ka baxsan xusuusta macluumaadka waxbarashada. We show that inclusion of additional features can improve classification results and achieve a score within 2 points of the top performing team.', 'ta': 'இந்த காகிதத்திற்கு எங்கள் பணியில் 2 பணிக்கு ஏற்றுமதி அளிக்கிறது வேறு பயனர் உரையில் உரை உருவாக்கப்பட்டுள்ளது. We explore improving the performance of a pre-trained transformer-based language model fine-tuned for text classification through an ensemble implementation that makes use of corpus level information and a handcrafted feature.  முந்தைய குணங்களைச் சேர்த்து ஒரு குறிப்பிட்ட குறிப்பிட்ட பிரச்சனையின் சவால்களை பொருத்துவதற்காக முன் குறிப்பிட்ட குறி கூடுதல் குணங்களை சேர்த்து வகுப்பு முடிவுகளை மேல் செய்யும் முதல் செயல்பாடு குழுவின் 2 புள்ளிகளில் ஒரு புள்ளி', 'sv': 'Denna uppsats presenterar vårt bidrag till uppgift 2 i Workshopen om bullrig användargenererad text. Vi undersöker att förbättra prestandan hos en färdigutbildad transformatorbaserad språkmodell finjusterad för textklassificering genom en ensembleimplementering som använder sig av korpusnivå information och en handgjord funktion. Vi testar effektiviteten av att inkludera ovannämnda funktioner för att tillgodose utmaningarna i en bullrig datauppsättning med fokus på ett specifikt ämne som inte omfattas av pre-training data. Vi visar att inkludering av ytterligare funktioner kan förbättra klassificeringsresultat och uppnå en poäng inom 2 poäng från det topppresterande laget.', 'ur': 'This paper presents our submission to Task 2 of the Workshop on Noisy User-generated text. ہم نے ایک پیش آموزش کی تغییر کی زبان کی موڈل کی عملکرد کو اچھی طرح تحقیق کر رہے ہیں جو ایک ایسمبل کی عملومات کے ذریعہ سے استعمال کرتا ہے اور ایک ہاندکرافٹ کی ویژگی کے ذریعہ سے استعمال کرتا ہے. ہم نے پہلے ترینس ڈیٹ کے بغیر ایک خاص موضوع پر مضبوط مقرر کیا گیا ہے کہ ایک صوت ڈیٹ سٹ کی چالیں مضبوط کرنے کے لئے پہلے گزرے ہوئے موضوعات کے شامل ہونے کے مطابق فعالیت کا امتحان کر رہے ہیں. ہم نشان دیتے ہیں کہ اضافہ ویژگی کا شامل کرنا کلاسیفوں کا نتیجہ بہتر کر سکتا ہے اور سب سے زیادہ اضافہ کی تیم کے دو نقطے میں ایک اسکو پہنچا سکتا ہے.', 'uz': "Bu sahifa bizning vazifaning 2 ish stolini ishlatish uchun ishlatiladi. Biz birinchi taʼminlovchi o'zgarishdan oldin o'zgartirish modeli bajarayotganimizni o'rganamiz. Matn classifikasini bir kichkina ishlatish orqali corpus darajada maʼlumot va qo'llab qo'llab qo'llash imkoniyatlaridan foydalanadi. Biz oldingi taʼminlovchi maʼlumotlarni eslab qolish uchun bir necha maʼlumot markazida aniqlangan qismi maʼlumotlar tarqalarini qo'llashda oldingi taʼminlovchi shaxsiy imkoniyatlarning effektini tekshirishingiz mumkin. Biz qoʻshimcha parametrlarni qoʻshish natijalarini darajalashtirish mumkin va eng yuqori bajarish guruhning 2 point ichida scorni bajarishi mumkin.", 'vi': 'Tờ giấy này giới thiệu sự đệ trình của chúng ta vào Nhiệm vụ 2 của "Hồ sơ Người Dùng ồn ào". Chúng tôi khám phá khả năng phát triển của mô hình ngôn ngữ biến hình được huấn luyện theo kiểu chỉnh chính xác cho việc phân loại văn bản qua một màn trình diễn kết hợp, sử dụng thông tin cấp trên tập thể và một tính năng tự làm. Chúng tôi kiểm tra xem khả năng bao gồm các yếu tố này trong việc đáp ứng thử thách của một dữ liệu ồn ào tập trung vào một chủ đề cụ thể nằm ngoài phạm vi dữ liệu trước khi đào tạo. Chúng tôi cho thấy rằng việc thêm các tính năng có thể cải thiện kết quả phân hạng và đạt được một điểm trong hai điểm của đội bậc cao.', 'bg': 'Настоящата статия представя нашето представяне на задача 2 на семинара по шумен текст, генериран от потребителите. Проучваме подобряването на производителността на предварително обучен трансформаторен езиков модел, фино настроен за класификация на текста чрез ансамбъл имплементация, която използва информация на ниво корпус и ръчно изработена функция. Тестваме ефективността на включването на гореспоменатите функции в посрещането на предизвикателствата на шумен набор от данни, фокусиран върху конкретен предмет извън обхвата на данните преди обучението. Показваме, че включването на допълнителни функции може да подобри класификационните резултати и да постигне резултат в рамките на 2 точки от най-добрия отбор.', 'hr': 'Ovaj papir predstavlja naše podatke na zadatak 2 rada radionice o tekstu proizvedenom korisniku glasina. Istražujemo poboljšanje učinka predobučenog jezičkog model a koji se temelji na transformaciji određuje za klasifikaciju teksta kroz provedbu kompleksa koja koristi informacije o razini korpusa i karakteristiku koja su napravljena na rukama. Testiramo učinkovitost uključujući navedene karakteristike u ubrzavanju izazova postavke bučnih podataka usmjerenog na određenu temu izvan podataka predobučenja. Pokazujemo da uključenje dodatnih karakteristika može poboljšati rezultate klasifikacije i postići rezultat unutar 2 tačke najvišeg izvršnog tima.', 'nl': 'Deze paper presenteert onze inzending aan Task 2 van de Workshop on Noisy User Generated Text. We onderzoeken het verbeteren van de prestaties van een vooraf getraind transformator-gebaseerd taalmodel dat is afgestemd op tekstclassificatie door middel van een ensemble-implementatie die gebruik maakt van corpusniveau informatie en een handgemaakte functie. We testen de effectiviteit van het opnemen van bovengenoemde functies om tegemoet te komen aan de uitdagingen van een lawaaierige dataset gericht op een specifiek onderwerp buiten de bevoegdheid van de pre-training data. We laten zien dat het opnemen van extra functies de classificatieresultaten kan verbeteren en een score kan behalen binnen twee punten van het best presterende team.', 'da': 'Denne artikel præsenterer vores indsendelse til opgave 2 af Workshoppen om støjende brugergenereret tekst. Vi undersøger at forbedre ydeevnen af en præ-trænet transformer-baseret sprogmodel finjusteret til tekstklassifikation gennem en ensembleimplementering, der gør brug af korpusniveau information og en håndlavet funktion. Vi tester effektiviteten af at inkludere ovennævnte funktioner til at imødekomme udfordringerne ved et støjende datasæt centreret om et bestemt emne uden for førstetræningsdataenes område. Vi viser, at inklusion af yderligere funktioner kan forbedre klassifikationsresultaterne og opnå en score inden for 2 point fra det bedste hold.', 'de': 'Dieses Papier stellt unsere Einreichung an Task 2 des Workshops zu Noisy User Generated Text vor. Wir untersuchen die Verbesserung der Leistung eines vortrainierten transformatorbasierten Sprachmodells, das für die Textklassifizierung fein abgestimmt ist, durch eine Ensemble-Implementierung, die Korpusinformationen und eine handgefertigte Funktion nutzt. Wir testen die Effektivität der Einbeziehung der oben genannten Merkmale bei der Bewältigung der Herausforderungen eines lauten Datensatzes, der sich auf ein bestimmtes Thema außerhalb des Aufgabenbereichs der Vortrainingsdaten konzentriert. Wir zeigen, dass die Einbeziehung zusätzlicher Funktionen die Klassifizierungsergebnisse verbessern und eine Punktzahl innerhalb von zwei Punkten des leistungsstärksten Teams erzielen kann.', 'id': 'Kertas ini menunjukkan pengiriman kita ke Tugas 2 Workshop tentang Teks yang Digenerkan oleh Pengguna Bersuara. We explore improving the performance of a pre-trained transformer-based language model fine-tuned for text classification through an ensemble implementation that makes use of corpus level information and a handcrafted feature.  Kami menguji efektifitas dari termasuk fitur-fitur sebelumnya dalam mengakomodasi tantangan dari set data yang berisik yang ditentukan pada subjek spesifik diluar tugas data pre-pelatihan. Kami menunjukkan bahwa penemuan karakteristik tambahan dapat meningkatkan hasil klasifikasi dan mencapai skor dalam 2 poin dari tim prestasi terbaik.', 'fa': 'این کاغذ تحویل ما به وظیفه ۲ از کارگاه روی متن تولید از کاربر نویسی را نشان می دهد. ما تحقیق می کنیم که عملکرد یک مدل تغییر\u200cپذیر زبان پیش آموزش داده شده که برای تغییر\u200cپذیر متن از طریق یک عملکرد\u200cبندی که از اطلاعات سطح کورپوس استفاده می\u200cکند و یک ویژه\u200cی دستی\u200cساخته شده استفاده می\u200cکند. ما تاثیر\u200cپذیری از شامل ویژه\u200cهای پیش\u200cآموزش\u200cها را آزمایش می\u200cکنیم تا چالش\u200cهای یک مجموعه داده\u200cهای صوتی که مرکز روی یک موضوع خاصی خارج از مرکز داده\u200cهای پیش\u200cآموزش است. ما نشان می دهیم که شامل ویژه های اضافی می تواند نتیجه\u200cهای مختصات را بهتر کند و یک امتیاز در دو نقطه از تیم عملکرد بالا برسد.', 'sw': 'Makala hii inaonyesha ujumbe wetu wa kazi ya 2 wa Warsha hii ya Mtumiaji wa Wasichoeleweka. Tunagundua kuboresha ufanisi wa modeli ya lugha yenye msingi wa mafunzo ya awali ya mabadiliko yenye utaratibu mzuri wa kutangazwa kwa uandishi wa maandishi kupitia utekelezaji unaotumia taarifa za ngazi za makampuni na utaalam wa mkono. Tunajaribu ufanisi wa pamoja na vipengele vilivyotajwa hapo awali katika kukutana na changamoto za taarifa za kelele zilizowekwa kwenye mada maalum nje ya kukumbuka takwimu za mafunzo. Tunaonyesha kuwa pamoja na vipengele vya ziada vinaweza kuboresha matokeo ya kutangaza na kupata vipimo ndani ya pointi 2 za timu ya juu ya maonyezi.', 'tr': 'Bu kagyz Noisy Ullançy Metin üzerinde Çalışmanyň 2-nji Görevine arzyklanýarýar. Biz öň-öňünden okuwçylan transformatör dili nusgasyny gowylaşdyrylyp, ellerinden geçirilen çykyş bilen tekst klasifikasyonuň üçin gowylaşdyrylýan täsirini keşfedýäris. Öň öňündeki bilim maglumatynyň hatynyň daşynda sereden bir gürrüň maglumatynyň kynçylygyny bejermek üçin öňündeki özellikleriň etkinlik barlygyny barlaýarys. Biz esasy özellikleriň daşary ýagdaýlaşdyrylmagyň netijesini gowylaşdyryp biler we üst-ji toparyň 2 noktalaryna çykyp bileris.', 'af': "Hierdie papier stel ons onderskrywing aan Taak 2 van die Werkshop op Noisy User- genereerde Teks voor. Ons ondersoek om die prestasie van 'n voorafgevorderde transformeerder-gebaseerde taal model te verbeter vir teks klasifikasie deur 'n ensemble implementasie wat gebruik van korpus vlak inligting en 'n handkryf funksie maak. Ons probeer die effektiviteit van insluitend van die voorgeskryfde funksies in die uitdaging van 'n geluid data stel wat sentreer op 'n spesifieke onderwerp buite die remit van die voorgetrekking data. Ons wys dat inkluiting van addisionele funksies kan klassifikasie resultate verbeter en 'n telling binne 2 punte van die top uitvoerde span bereik.", 'sq': 'Ky dokument paraqet paraqitjen tonë në detyrën 2 të seminarit mbi tekstin e gjeneruar nga përdoruesit e zhurmshëm. Ne eksplorojmë përmirësimin e performancës së një modeli gjuhësh të trajnuar në bazë të transformuesve të përshtatur për klasifikimin e tekstit nëpërmjet një zbatimi të ensembleve që bën përdorim të informacionit të nivelit të korpusit dhe një karakteristike të ndërtuar me dorë. Ne testojmë efektshmërinë e përfshirjes së karakteristikave të përmendura në përshtatjen e sfidave të një grupi të dhënash zhurmëshme të përqëndruar në një subjekt të caktuar jashtë kompetencës së të dhënave të paratrajnimit. Ne tregojmë se përfshirja e karakteristikave shtesë mund të përmirësojë rezultatet e klasifikimit dhe të arrijë një pikë brenda 2 pikëve të ekipit kryesor.', 'am': 'ይህም ገጽ የነፃ ተጠቃሚው ጽሑፍ ለስራ 2 ስራዎችን የሚያቀርብ ነው፡፡ የቆርፓስ ደረጃዎች መረጃ እና እጁን የሚጠቀም የጽሑፍ ክፍተት የተለየ የቋንቋ ምሳሌ አካባቢ እና የቆርፓስ ደረጃዎች መረጃዎችን ለመጠቀም የሚችል የጽሑፍ ክፍተት ጥያቄን በመጠቀም እና በመጠቀም እና በተቃራኒ ስርዓት ላይ እና ጥያቄን እናደርጋለን። የቀድሞው በተለየው የድምፅ ዳታዎችን በተከታተለ ጉዳይ ላይ በተለየ ጉዳይ ላይ የድምፅ አዳራዎችን በመቀበል እናስፈልጋለን፡፡ የጨዋታ ምርጫዎች መጨመር የግንኙነት ፍሬዎችን ማሻሻል እና በላይኛው የጨዋታውን አካባቢ በ2 ነጥብ ውስጥ ነጥብ ማግኘት እናደርጋለን፡፡', 'hy': "Այս աշխատանքը ներկայացնում է մեր ներկայացումը աղմկոտ օգտագործողների ստեղծված տեքստի աշխատասենյակի 2 պարագայում: We explore improving the performance of a pre-trained transformer-based language model fine-tuned for text classification through an ensemble implementation that makes use of corpus level information and a handcrafted feature.  Մենք ստուգում ենք, թե արդյունավետությունը ներառելով նախորդ հատկանիշները' համեմատելով աղմկոտ տվյալների համակարգի մարտահրավերները, որոնք կենտրոնացված են որոշակի թեմայի վրա, որը չի ներառվում նախապատրաստման տվյալների պարտադի Մենք ցույց ենք տալիս, որ ավելացնող հատկությունների ներառումը կարող է բարելավել դասակարգման արդյունքները և հասնել լավագույն արդյունքներ ունեցող թիմի 2 կետի ընթացքում:", 'az': 'Bu kağıt Noisy İstifadəçi Mətnin İkinci İşçinin İkinci İşçinə müvəffəqiyyətimizi göstərir. Biz əvvəlcə təhsil edilmiş transformatçı dil modelinin performansını təhsil edirik ki, korpus seviyyəti məlumatlarını və əl yaratdığı özellikləri istifadə edir. Biz əvvəlcə təhsil məlumatının istifadəsindən başqa bir məlumatın məlumatının məsələlərinə məclis olan səsl məlumatının çətinliklərini istifadə etmək üçün əvvəlki təhsil məlumatının istifadəsində istifadə edirik. Biz artıq xüsusiyyətlərin dahil edilməsi klasifikasiya sonuçlarını yaxşılaşdıra bilər və ən yüksək performans ekibinin 2 nöqtələrində bir nöqtəsi yetirə bilər.', 'bn': 'এই পত্রিকাটি আমাদের কাজের দ্বিতীয় উপস্থাপন করেছে নোইসি ব্যবহারকারী উৎপাদনকারী টেক্সটের কাজের দ্বিতীয়। আমরা পূর্ব প্রশিক্ষিত পরিবর্তনের ভিত্তিক ভাষার মডেলের ভাষার প্রদর্শনের উন্নতি বিশেষ করে বিশেষ করি একটি প্রধান ব্যবহারের মাধ্যমে টেক্সট ব্যবহার করা হয়েছে যা  পূর্ববর্তী প্রশিক্ষণের তথ্য স্মরণের বাইরে একটি নির্দিষ্ট বিষয়ে একটি আওয়াজ ডাটা সেটের চ্যালেঞ্জের সাথে যুক্ত করার জন্য আমরা আগের উল্লেখ আমরা দেখাচ্ছি যে অতিরিক্ত বৈশিষ্ট্যের যোগাযোগের ফলাফল উন্নত করতে পারে এবং সর্বোচ্চ প্রদর্শনী দলের ২ পয়েন্টের মধ্যে একটি স্কো', 'ca': "Aquest article presenta la nostra presentació a la 2ª tasca de l'atelier sobre el text generat pels usuaris ruidosos. Exploram millorar el rendiment d'un model de llenguatge pré-entrenat basat en transformadors adaptat a la classificació de textos a través d'una implementació d'un conjunt que utilitza la informació de nivell corpus i una característica artificial. We test the effectiveness of including the aforementioned features in accommodating the challenges of a noisy data set centred on a specific subject outside the remit of the pre-training data.  Mostrem que la inclusió de característiques adicionals pot millorar els resultats de la classificació i aconseguir una puntuació en 2 punts de l'equip de millors resultats.", 'ko': '본고는 우리가 제출한 사용자 생성 텍스트에 관한 세미나 임무 2를 소개한다.우리는 하나의 통합을 통해 어료 라이브러리 단계의 정보와 수동으로 제작하는 기능을 이용하여 사전 훈련을 거친 변환기 기반의 언어 모델의 성능을 어떻게 향상시키는지 탐색하고 이 언어 모델은 텍스트 분류를 마이크로스피커로 조정했다.우리는 훈련 전 데이터 범위 밖의 특정 주제를 중심으로 하는 시끄러운 데이터 집합의 도전에 적응하기 위해 상기 특징을 포함하는 유효성을 테스트했다.추가 특징을 추가하면 분류 결과를 개선하고 가장 잘 표현한 팀과의 격차가 2점을 넘지 않는 상황에서 점수를 받을 수 있다는 것을 보여준다.', 'bs': 'Ovaj papir predstavlja našu predanost zadatku 2 rada na tekstu proizvedenom korisniku. Istražujemo poboljšanje učinkovitosti jezičkog model a predobučenog transformatora koji je ispravljen za klasifikaciju teksta kroz provedbu kompleksa koja koristi informacije o nivou korpusa i karakteristiku za ruke. Testiramo učinkovitost uključujući navedene karakteristike u ubrzavanju izazova kompleta buknih podataka usmjerenog na određenu temu izvan podataka predobuke. Pokazujemo da uključenje dodatnih karakteristika može poboljšati rezultate klasifikacije i postići rezultat unutar 2 tačke najvišeg izvršnog tima.', 'cs': 'Tento článek představuje náš příspěvek k úkolu 2 workshopu o hlučném uživatelském textu. Zkoumáme zlepšení výkonu předem trénovaného jazykového modelu založeného na transformátoru vyladěného pro klasifikaci textu prostřednictvím implementace souboru, která využívá informací na úrovni korpusu a ručně vytvořené funkce. Testujeme efektivitu zahrnutí výše uvedených funkcí při řešení výzev hlučného datového souboru zaměřeného na konkrétní téma mimo působnost předtréninkových dat. Ukazujeme, že zahrnutí dalších funkcí může zlepšit klasifikační výsledky a dosáhnout skóre v rámci dvou bodů nejlepšího týmu.', 'et': 'Käesolevas artiklis tutvustatakse meie ettepanekuid müraka kasutaja loodud teksti töötaja 2. ülesandele. Uurime teksti klassifitseerimiseks täpselt häälestatud transformaatoril põhineva eelkoolitud keelemudeli jõudluse parandamist ansambli rakenduse kaudu, mis kasutab korpuse taseme infot ja käsitöö funktsiooni. Testime eespool nimetatud funktsioonide kaasamise efektiivsust müraka andmekogumi väljakutsetega, mis on keskendunud konkreetsele teemale väljaspool koolituseelsete andmete pädevust. Näitame, et lisafunktsioonide lisamine võib parandada klassifitseerimistulemusi ja saavutada punkti 2 punkti jooksul parima tulemusega meeskonnast.', 'fi': 'Tämä artikkeli esittelee ehdotuksemme meluisan käyttäjän luoman tekstin työryhmän tehtävään 2. Tutkimme esikoulutetun muuntajapohjaisen kielimallin suorituskyvyn parantamista tekstiluokittelua varten hienoviritetyn ryhmätoteutuksen avulla, jossa hyödynnetään korpustason tietoa ja käsintehtyä ominaisuutta. Testaamme edellä mainittujen ominaisuuksien sisällyttämisen tehokkuutta vastaamaan meluisaan tietoaineistoon, joka keskittyy tiettyyn aiheeseen, joka ei kuulu esikoulutuksen aineistoon. Osoitamme, että lisäominaisuuksien sisällyttäminen voi parantaa luokitustuloksia ja saavuttaa pisteet 2 pisteen sisällä parhaiten suoriutuneesta joukkueesta.', 'jv': 'Workspace 1 Awak dhéwé éntuk nglanggar aturan mrogram kuwi nggawe perusahaan mrogram kuwi dianggawe barang nggawe barang nggawe barang kelas nggawe Ketok Awak dhéwé éntuk perusahaan ingkang dipunangé perusahaan ingkang dipunangé perusahaan nggawe barang nggawe dadi kejahatan Awak dhéwé éntuk perusahaan langgar sampeyan liyane wis dipoleh dadi, ngono iso nggawe barang kanggo 2 punti sing dirampakan sing dumadhi iki punti.', 'sk': 'Ta prispevek predstavlja naš prispevek k nalogi 2 delavnice o hrupnem besedilu, ki ga ustvarijo uporabniki. Raziskujemo izboljšanje učinkovitosti vnaprej usposobljenega transformatorskega jezikovnega modela, natančno nastavljenega za klasifikacijo besedila z implementacijo ansambla, ki uporablja informacije na ravni korpusa in ročno izdelano funkcijo. Preizkušamo učinkovitost vključitve zgoraj omenjenih funkcij pri reševanju izzivov hrupnega nabora podatkov, osredotočenega na določen subjekt zunaj pristojnosti podatkov pred usposabljanjem. Pokazali smo, da lahko vključitev dodatnih funkcij izboljša rezultate klasifikacije in doseže rezultat v 2 točkah najbolj uspešne ekipe.', 'he': 'העבודה הזו מציגה את ההעברה שלנו למשימה 2 של העבודה על טקסט שנוצר ע"י משתמשים רעשים. אנו חוקרים שיפור ביצועים של מודל שפת מבוסס על המעבר מאומן מראש מתאים למסגרת טקסט באמצעות הפעולה של אסמבל שמשתמש במידע רמה של קורפוס ומתכונה מיוחדת יד. אנו בודקים את היעילות של כולל את המאפיינים הקודמים בהתאם לאתגרים של קבוצת נתונים רעשים המרכזים על נושא מסוים מחוץ לתפקיד נתונים לפני האימון. אנחנו מראים שכוללת תכונות נוספות יכולה לשפר תוצאות מסווג ולהשיג נקודה בתוך 2 נקודות של צוות ההופעה הטובה ביותר.', 'ha': "Wannan takardan na bãyar da uzuri zuwa aikin 2 na Shirin Ayuka na wanda aka ƙididdige wani mai amfani da shi na Naisy. Tuna ƙididdige mafiya amfani da mai tsari ga misalin harshen mai tunkuɗe wa mai classified matsayi a gabãni, da kuma an amfani da maɓallin nau'in da hannayen hannuwansa. Munã jarraba aikin su da izinin da aka taɓa wa zaman-taɓa da gaura masu motsi da data ta daidaita a kan wani maɓalli na ƙayyade bayan tunãtar da data masu yin zaman shawara. Tuna nũna cewa, za'a shigar da wasu hanyõyi, za'a iya kyautata matsalar fasalin su kuma za'a sami wata score guda na 2 points daga jumla na samun mai aikin aiki.", 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་ནང་དུ་ལས་འཆར་པ་གཉིས་པ་ལ་འཇུག་སྣོད་མི་སྟོན་པ། We explore improving the performance of a pre-trained transformer-based language model fine-tuned for text classification through an ensemble implementation that makes use of corpus level information and a handcrafted feature. ང་ཚོས་གནས་ཚུལ་གྱི་གནད་དོན་ཡོད་ཚད་ལྟར་སྐྱོན་བརྗོད་བྱེད་པའི་ནང་གི་དཀའ་ངལ་ཡོད་ཚད་ལ་བརྟག ང་ཚོས་དབྱེ་རིམ་གྱི་ཁྱད་ཆོས་གཞན་ཞིག་ཡིན་ཚད་རྒྱས་བཤད་ཐུབ་པ་ལས་མཐོང་ཚད་རྩིས་ཐོག་ཏེ།'}
{'en': 'CSECU-DSG at WNUT-2020 Task 2 : Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets CSECU - DSG  at  WNUT -2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative  COVID -19  E nglish Tweets', 'es': 'CSECU-DSG en la Tarea 2 del WNUT-2020: Aprovechar el conjunto de aprendizaje de transferencia y las funciones hechas a mano para la identificación de tuits informativos en inglés sobre COVID-19', 'pt': 'CSECU-DSG no WNUT-2020 Tarefa 2: Explorando o conjunto de aprendizado de transferência e recursos artesanais para identificação de tweets informativos sobre COVID-19 em inglês', 'ar': 'CSECU-DSG في WNUT-2020 المهمة 2: استغلال مجموعة نقل التعلم والميزات المصنوعة يدويًا لتحديد التغريدات الإعلامية لـ COVID-19 باللغة الإنجليزية', 'fr': "CSECU-DSG à la tâche 2 de la WNUT-2020\xa0: Exploiter l'ensemble de l'apprentissage par transfert et des fonctionnalités artisanales pour l'identification des tweets informatifs en anglais COVID-19", 'hi': 'WNUT-2020 टास्क 2 पर CSECU-DSG: सूचनात्मक कोविड-19 अंग्रेजी ट्वीट्स की पहचान के लिए स्थानांतरण सीखने और हाथ से तैयार की गई सुविधाओं की टुकड़ी का शोषण करना', 'ja': 'WNUT -2020でのCSECU - DSGタスク2 ：新型コロナウイルス感染症(COVID -19)に関する情報を提供する英語ツイートを識別するための転送学習と手作り機能のアンサンブルを活用する', 'zh': 'CSECU-DSG在WNUT-2020务2:因迁学手之功以识信息之COVID-19英语推文', 'ru': 'CSECU-DSG на WNUT-2020 Задача 2: Эксплуатация ансамбля передаточного обучения и функций ручной работы для идентификации информационных твитов на английском языке о COVID-19', 'ga': 'CSECU-DSG ag WNUT-2020 Tasc 2: Leas a bhaint as Ensemble Aistrithe Foghlama agus Gnéithe Lámhdhéanta chun Tweetanna Béarla Faisnéiseacha COVID-19 a Aithint', 'ka': 'CSECU', 'hu': 'CSECU-DSG a WNUT-2020 2. feladat: A transzfertanulás és a kézzel készített funkciók kiaknázása az információs COVID-19 angol tweetek azonosítására', 'el': 'Καθήκον 2: Εκμετάλλευση του συνόλου μάθησης μεταφοράς και χειροποίητων χαρακτηριστικών για τον προσδιορισμό πληροφοριακών αγγλικών tweets', 'it': "CSECU-DSG a WNUT-2020 Task 2: Sfruttare l'insieme di Transfer Learning e funzionalità artigianali per l'identificazione dei tweet informativi in inglese COVID-19", 'kk': 'CSECU-DSG WNUT-2020 2- тапсырмасында: Мәліметті COVID-19 ағылшын Tweets идентификациялау үшін тапсырмалар оқыту және қол құрылған мүмкіндіктерін зерттеу', 'mk': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'lt': 'CSECU-DSG WNUT-2020 2 uždavinys: Naudoti perkėlimo mokymosi Ensemble ir rankinius būdus informaciniam COVID-19 anglų Tweets identifikavimui', 'ms': 'CSECU-DSG di WNUT-2020 Task 2: Penggunaan Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'ml': 'WNUT- 2020 ടാസ്ക് 2- ല്\u200d CSECU- DSG: വിവരങ്ങള്\u200d കോവിഡ്- 19 ഇംഗ്ലീഷ് ട്യൂട്ടുകള്\u200d പരിചയപ്പെടുത്തുന്നതിനും കൈകൈക്കൊണ്ടുള്ള വിശേഷതകള്\u200d', 'mn': 'CSECU-DSG at WNUT-2020 Task 2: Ensemble of Transfer Learning and Hand-created Features for Identifying Information COVID-19 English Tweets', 'mt': 'CSECU-DSG fid-WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand crafted Features for Identification of Informative COVID-19 English Tweets', 'no': 'CSECU-DSG på WNUT-2020 oppgåve 2: Eksplosjon av bruk av overføringslæring og handhaldne funksjonar for identifisering av informativ COVID-19 engelsk tweets', 'pl': 'CSECU-DSG na WNUT-2020 Zadanie 2: Wykorzystanie zespołu uczenia się transferowego i ręcznie wykonanych funkcji do identyfikacji informacyjnych tweetów COVID-19 angielskich', 'ro': 'CSECU-DSG la WNUT-2020 Sarcina 2: Exploatarea ansamblului de învățare prin transfer și a caracteristicilor artizanale pentru identificarea tweeturilor informative în limba engleză COVID-19', 'sr': 'CSECU-DSG na zadatku 2. WNUT-2020: Eksplozicija uključenja učenja prijenosa i karakteristika za identifikaciju informativnih tviteta COVID-19 engleskih Tweets', 'so': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-Handed Features for Identification of Informative COVID-19 Tweets', 'sv': 'CSECU-DSG på WNUT-2020 Uppgift 2: Utnyttja ett ensemble av överföring lärande och handgjorda funktioner för identifiering av informativ COVID-19 engelska tweets', 'ta': 'WNUT- 2020 பணியில் CSECU- DSG 2: தகவல் COVID- 19 ஆங்கிலத்தின் மாற்றும் கற்றல் மற்றும் கைமுறையாக்கப்பட்ட பண்புகளை அடையாளம் கொண்டுள்ளது', 'si': 'CSECU-DSG at WNuT-202 Job 2: Exploiting Ensemble of Transfer Training and Hand-craft Featuries for ID of Infotive COVID-19 English Tweets', 'ur': 'CSECU-DSG WNUT-2020 Task 2: Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'uz': 'Comment', 'vi': 'CSECU-DSG tại WGiờ-2020 Task 2: nổ tan tành Ensemble of Transport Learning and Hand-made Featurs for identification of informative COVID-19 English Tweet', 'nl': 'CSECU-DSG bij WNUT-2020 Taak 2: Benut Ensemble van Transfer Learning en Handgemaakte Functies voor Identificatie van Informatieve COVID-19 Engelse Tweets', 'hr': 'CSECU-DSG na zadatku 2. WNUT-2020: Eksploziciranje primjene učenja prijenosa i prijevoznih osoba za identifikaciju informativnih tviteta COVID-19 engleskih tviteta', 'bg': 'Задача 2: Експлоатация на ансамбъла за трансферно обучение и ръчно изработени функции за идентифициране на информативни', 'da': 'CSECU-DSG på WNUT-2020 Opgave 2: Udnyttelse af et ensemble af overførselslæring og håndlavede funktioner til identifikation af informative COVID-19 engelske tweets', 'de': 'CSECU-DSG bei WNUT-2020 Aufgabe 2: Nutzung des Ensembles von Transfer Learning und handgefertigten Features zur Identifizierung informativer COVID-19 englischer Tweets', 'id': 'CSECU-DSG di WNUT-2020 Task 2: Penggunaan Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'ko': 'WNUT-2020에서 CSECU-DSG의 임무2: 마이그레이션 학습과 수동 제작 기능의 통합을 통해 풍부한 정보를 제공하는 코로나 영어 트윗 인식', 'fa': 'CSECU-DSG در Task 2 WNUT-2020: Explosing Ensemble of Transfer Learning and Hand-made Features for Identification of Informative COVID-19 English Tweets', 'sw': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'tr': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'af': 'CSECU', 'sq': 'CSECU-DSG në WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'am': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'hy': 'CSESC-DSG-ը Համաշխարհային Ազգային Ազգային Հետազոտություն 2020-ի 2. հանձնարարության ժամանակ. հաղորդագրությունների սովորելու և ձեռքով ստեղծված հնարավորությունների օգտագործումը ինֆորմատիվ COVID-19 անգլերեն թվիթերի հայտնաբերելու համար', 'az': 'WNUT-2020 Task 2: Transfer Learning and Hand-created Features for Identification of Informative COVID-19 English Tweets', 'bs': 'CSECU-DSG na zadatku 2. WNUT-2020: Eksplozicija primjene učenja prijenosa i karakteristika za identifikaciju informativnih tviteta COVID-19 engleskih tviteta', 'bn': 'WNUT-2020 টাস্ক ২-এ CSECU-DSG:', 'cs': 'CSECU-DSG na WNUT-2020 Úkol 2: Využití souboru transferového učení a ručně vytvořených funkcí pro identifikaci informačních anglických tweetů COVID-19', 'ca': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets', 'et': 'CSECU-DSG WNUT-2020 ülesandel 2: siirdeõppe ja käsitsi valmistatud funktsioonide ansambli kasutamine informatiivse COVID-19 tuvastamiseks English Tweets', 'fi': 'CSECU-DSG WNUT-2020 -tapahtumassa Tehtävä 2: Siirto-oppimisen ja käsintehtyjen ominaisuuksien hyödyntäminen informatiivisen COVID-19:n tunnistamiseksi English Tweets', 'jv': 'CSESU', 'he': 'CSECU-DSG ב-WNUT-2020 משימה 2: ניצל סמל של לימוד העברה והתכונות בידיים לזהות טוויטים אנגליים מידעיים COVID-19', 'sk': 'CSECU-DSG na WNUT-2020 Naloga 2: Izkoriščanje ansambla prenosnega učenja in ročno izdelanih funkcij za identifikacijo informativnih COVID-19 English Tweets', 'ha': 'KCharselect unicode block name', 'bo': 'CSECU-DSG at WNUT-2020 Task 2: Exploiting Ensemble of Transfer Learning and Hand-crafted Features for Identification of Informative COVID-19 English Tweets'}
{'en': 'COVID-19 pandemic has become the trending topic on twitter and people are interested in sharing diverse information ranging from new cases, healthcare guidelines, medicine, and vaccine news. Such information assists the people to be updated about the situation as well as beneficial for public safety personnel for decision making. However, the informal nature of  twitter  makes it challenging to refine the informative tweets from the huge tweet streams. To address these challenges WNUT-2020 introduced a shared task focusing on COVID-19 related informative tweet identification. In this paper, we describe our participation in this  task . We propose a neural model that adopts the strength of  transfer learning  and hand-crafted features in a unified architecture. To extract the transfer learning features, we utilize the state-of-the-art pre-trained sentence embedding model BERT, RoBERTa, and InferSent, whereas various twitter characteristics are exploited to extract the hand-crafted features. Next, various feature combinations are utilized to train a set of multilayer perceptron (MLP) as the base-classifier. Finally, a majority voting based fusion approach is employed to determine the informative tweets. Our approach achieved competitive performance and outperformed the baseline by 7 % (approx.', 'ar': 'أصبح جائحة COVID-19 موضوعًا شائعًا على تويتر ويهتم الناس بمشاركة معلومات متنوعة تتراوح من الحالات الجديدة وإرشادات الرعاية الصحية والطب وأخبار اللقاحات. تساعد مثل هذه المعلومات الناس على أن يتم تحديثهم حول الوضع وكذلك مفيدة لموظفي السلامة العامة لاتخاذ القرار. ومع ذلك ، فإن الطبيعة غير الرسمية لتويتر تجعل من الصعب تحسين التغريدات المفيدة من تدفقات التغريدات الضخمة. لمواجهة هذه التحديات ، قدمت WNUT-2020 مهمة مشتركة تركز على تحديد التغريدات المفيدة المتعلقة بـ COVID-19. في هذه الورقة ، نصف مشاركتنا في هذه المهمة. نقترح نموذجًا عصبيًا يتبنى قوة نقل التعلم والميزات المصنوعة يدويًا في بنية موحدة. لاستخراج ميزات تعلم النقل ، نستخدم أحدث نموذج لتضمين الجملة مُدرَّب مسبقًا BERT و RoBERTa و InferSent ، في حين يتم استغلال خصائص تويتر المختلفة لاستخراج الميزات المصنوعة يدويًا. بعد ذلك ، يتم استخدام مجموعات ميزات مختلفة لتدريب مجموعة من الإدراك متعدد الطبقات (MLP) كمصنف أساسي. أخيرًا ، يتم استخدام نهج اندماج قائم على التصويت بالأغلبية لتحديد التغريدات المفيدة. حقق نهجنا أداءً تنافسيًا وتفوق على خط الأساس بنسبة 7٪ (تقريبًا).', 'pt': 'A pandemia de COVID-19 tornou-se o tópico de tendência no twitter e as pessoas estão interessadas em compartilhar diversas informações, desde novos casos, diretrizes de saúde, medicamentos e notícias sobre vacinas. Tais informações auxiliam as pessoas a se atualizarem sobre a situação, além de serem benéficas para o pessoal de segurança pública para a tomada de decisões. No entanto, a natureza informal do twitter torna um desafio refinar os tweets informativos dos enormes fluxos de tweets. Para enfrentar esses desafios, o WNUT-2020 introduziu uma tarefa compartilhada com foco na identificação de tweets informativos relacionados ao COVID-19. Neste artigo, descrevemos nossa participação nessa tarefa. Propomos um modelo neural que adota a força do aprendizado de transferência e recursos artesanais em uma arquitetura unificada. Para extrair os recursos de aprendizado de transferência, utilizamos o modelo de incorporação de frases pré-treinadas de última geração BERT, RoBERTa e InferSent, enquanto várias características do twitter são exploradas para extrair os recursos artesanais. Em seguida, várias combinações de recursos são utilizadas para treinar um conjunto de perceptrons multicamadas (MLP) como classificador de base. Finalmente, uma abordagem de fusão baseada em votação majoritária é empregada para determinar os tweets informativos. Nossa abordagem alcançou um desempenho competitivo e superou a linha de base em 7% (aprox.).', 'es': 'La pandemia de COVID-19 se ha convertido en el tema de moda en Twitter y las personas están interesadas en compartir información diversa que va desde casos nuevos, pautas de atención médica, medicamentos y noticias sobre vacunas. Dicha información ayuda a las personas a mantenerse al día sobre la situación y es beneficiosa para el personal de seguridad pública para la toma de decisiones. Sin embargo, la naturaleza informal de Twitter hace que sea difícil refinar los tuits informativos de las enormes transmisiones de tuits. Para abordar estos desafíos, WNUT-2020 introdujo una tarea compartida centrada en la identificación de tuits informativos relacionados con la COVID-19. En este artículo, describimos nuestra participación en esta tarea. Proponemos un modelo neuronal que adopta la fuerza del aprendizaje por transferencia y las funciones hechas a mano en una arquitectura unificada. Para extraer las funciones de aprendizaje por transferencia, utilizamos el modelo de incrustación de oraciones preentrenado de última generación BERT, RobErta e InferSent, mientras que se aprovechan varias características de Twitter para extraer las funciones hechas a mano. A continuación, se utilizan varias combinaciones de características para entrenar un conjunto de perceptrones multicapa (MLP) como clasificador de base. Finalmente, se emplea un enfoque de fusión basado en el voto mayoritario para determinar los tuits informativos. Nuestro enfoque logró un rendimiento competitivo y superó la línea de base en un 7% (aprox.).', 'fr': "La pandémie de COVID-19 est devenue le sujet tendance sur Twitter et les gens sont intéressés à partager diverses informations allant des nouveaux cas, des directives de santé, des médicaments et des nouvelles sur les vaccins. Ces informations aident les personnes à être informées de la situation et sont utiles pour le personnel de la sécurité publique pour la prise de décisions. Cependant, la nature informelle de Twitter rend difficile l'affinement des tweets informatifs issus des flux de tweets énormes. Pour relever ces défis, WNUT-2020 a introduit une tâche partagée axée sur l'identification des tweets informatifs liés à la COVID-19. Dans cet article, nous décrivons notre participation à cette tâche. Nous proposons un modèle neuronal qui intègre la force de l'apprentissage par transfert et des fonctionnalités conçues à la main dans une architecture unifiée. Pour extraire les fonctionnalités d'apprentissage par transfert, nous utilisons les modèles d'intégration de phrases pré-entraînés BERT, Roberta et InferSent, tandis que diverses caractéristiques Twitter sont exploitées pour extraire les fonctionnalités artisanales. Ensuite, diverses combinaisons de caractéristiques sont utilisées pour entraîner un ensemble de perceptron multicouche (MLP) en tant que classificateur de base. Enfin, une approche de fusion basée sur le vote majoritaire est utilisée pour déterminer les tweets informatifs. Notre approche a permis d'atteindre des performances concurrentielles et de surpasser le niveau de référence de 7\xa0% (environ).", 'hi': 'कोविड-19 महामारी ट्विटर पर ट्रेंडिंग विषय बन गई है और लोग नए मामलों, स्वास्थ्य देखभाल दिशानिर्देशों, दवा और वैक्सीन समाचारों से लेकर विभिन्न जानकारी साझा करने में रुचि रखते हैं। इस तरह की जानकारी लोगों को स्थिति के बारे में अपडेट करने के साथ-साथ निर्णय लेने के लिए सार्वजनिक सुरक्षा कर्मियों के लिए फायदेमंद होने में मदद करती है। हालांकि, चहचहाना की अनौपचारिक प्रकृति यह विशाल चहचहाना धाराओं से जानकारीपूर्ण tweets परिष्कृत करने के लिए चुनौतीपूर्ण बनाता है. इन चुनौतियों से निपटने के लिए डब्ल्यूएनयूटी -2020 ने कोविड -19 से संबंधित जानकारीपूर्ण ट्वीट पहचान पर ध्यान केंद्रित करते हुए एक साझा कार्य शुरू किया। इस पत्र में, हम इस कार्य में हमारी भागीदारी का वर्णन करते हैं। हम एक तंत्रिका मॉडल का प्रस्ताव करते हैं जो एक एकीकृत वास्तुकला में स्थानांतरण सीखने और हाथ से तैयार की गई विशेषताओं की ताकत को अपनाता है। स्थानांतरण सीखने की सुविधाओं को निकालने के लिए, हम अत्याधुनिक पूर्व-प्रशिक्षित वाक्य एम्बेडिंग मॉडल BERT, RoBERTa, और InferSent का उपयोग करते हैं, जबकि विभिन्न चहचहाना विशेषताओं को हाथ से तैयार की गई सुविधाओं को निकालने के लिए शोषण किया जाता है। इसके बाद, विभिन्न फीचर संयोजनों का उपयोग बेस-क्लासिफायर के रूप में मल्टीलेयर परसेप्ट्रॉन (एमएलपी) के एक सेट को प्रशिक्षित करने के लिए किया जाता है। अंत में, एक बहुमत मतदान आधारित संलयन दृष्टिकोण जानकारीपूर्ण tweets निर्धारित करने के लिए नियोजित है। हमारे दृष्टिकोण ने प्रतिस्पर्धी प्रदर्शन हासिल किया और बेसलाइन को 7% (लगभग) से बेहतर प्रदर्शन किया।', 'ja': '新型コロナウイルス感染症(COVID -19)のパンデミック(世界的大流行)がTwitterで話題になっており、人々は新しい症例、医療ガイドライン、医療、ワクチンに関するニュースなど、さまざまな情報を共有することに興味を持っています。 このような情報は、状況の最新情報を得るのに役立ち、意思決定のための公安担当者にとっても有益です。 しかし、twitterの非公式な性質により、巨大なツイートストリームから情報のあるツイートを絞り込むことは困難です。 これらの課題に対処するため、WNUT -2020は、COVID -19に関連する有益なツイート識別に焦点を当てた共有タスクを導入しました。 本稿では、このタスクへの参加について説明する。 伝達学習の強みと手作りの特徴を統一アーキテクチャで取り入れたニューラルモデルを提案します。 転送学習機能を抽出するには、最先端の事前トレーニングされた文章埋め込みモデルBERT、RoBERTa、およびInferSentを利用しますが、さまざまなtwitter特性が利用されて手作りの機能を抽出します。 次に、多層パーセプトロン（ ＭＬＰ ）のセットをベースクラシファイアとして訓練するために、様々な特徴の組み合わせが利用される。 最後に、多数決に基づく融合アプローチを用いて、有益なツイートを決定する。 当社のアプローチは競争力のあるパフォーマンスを達成し、ベースライン（約）を7 ％上回りました。', 'zh': 'COVID-19大行已为Twitter上热门话题,人有兴分信息,至于新病例,医疗保健指南,医学疫苗新闻。 有助于人知最新,利于公共安全人。 然Twitter之性,使从巨推文流中提炼信息之推文,转为挑战性。 为此挑战,WNUT-2020引一共同任务,重关COVID-19信息性推文识。 在本文中,我们述述了我们对这件事。 吾为神经模者,一架构而迁学之功也。 以先入BERT,以RoBERTa为InferSent,以推特为工。 接以特征训练感知器(MLP)以为器。 最后用多投票融合之法以定信息性推文。 吾道成竞争力性,比基线高7%(可)。', 'ru': 'Пандемия COVID-19 стала популярной темой в Twitter, и люди заинтересованы в обмене разнообразной информацией, начиная от новых случаев, рекомендаций по здравоохранению, лекарств и вакцин. Такая информация помогает людям быть в курсе ситуации, а также помогает персоналу общественной безопасности принимать решения. Тем не менее, неформальный характер твиттера затрудняет уточнение информативных твитов из огромных потоков твитов. Для решения этих проблем WNUT-2020 представил общую задачу, сосредоточенную на выявлении информационных твитов, связанных с COVID-19. В настоящем документе мы описываем наше участие в выполнении этой задачи. Мы предлагаем нейронную модель, которая принимает силу трансферного обучения и ручных функций в единой архитектуре. Для извлечения функций обучения передаче мы используем самую современную предварительно обученную модель внедрения предложений BERT, RoBERTa и InferSent, в то время как различные характеристики Twitter используются для извлечения функций ручной работы. Далее, различные комбинации признаков используются для обучения набора многослойного персептрона (MLP) в качестве базового классификатора. Наконец, для определения информативных твитов используется подход слияния, основанный на мажоритарном голосовании. Наш подход обеспечил конкурентоспособность и превысил базовый уровень на 7% (приблизительно).', 'ga': "Tá paindéim COVID-19 tagtha chun cinn anois ar twitter agus tá suim ag daoine faisnéis éagsúil a roinnt ó chásanna nua, treoirlínte cúram sláinte, leigheas agus nuacht faoi vacsaíní. Cabhraíonn faisnéis den sórt sin leis na daoine a bheith cothrom le dáta faoin gcás chomh maith le bheith tairbheach do phearsanra sábháilteachta poiblí le haghaidh cinnteoireachta. Mar gheall ar nádúr neamhfhoirmiúil twitter, áfach, bíonn sé dúshlánach na tweets faisnéiseacha ó na sruthanna ollmhóra tweetanna a bheachtú. Chun aghaidh a thabhairt ar na dúshláin seo thug WNUT-2020 tasc comhroinnte isteach a dhírigh ar shainaithint tweet faisnéiseach a bhaineann le COVID-19. Sa pháipéar seo, déanaimid cur síos ar ár rannpháirtíocht sa tasc seo. Molaimid múnla néarúil a ghlacann neart na foghlama aistrithe agus gnéithe lámhcheirde in ailtireacht aontaithe. Chun na gnéithe foghlama aistrithe a bhaint as, bainimid úsáid as an tsamhail leabú abairtí réamh-oilte úrscothach BERT, RoBERTa, agus InferSent, ach baintear leas as tréithe éagsúla twitter chun na gnéithe lámhdhéanta a bhaint as. Ina dhiaidh sin, baintear úsáid as comhcheangail éagsúla de ghnéithe chun sraith de dhearcadh ilchiseal (MLP) a oiliúint mar bhun-aicmitheoir. Ar deireadh, úsáidtear cur chuige comhleá bunaithe ar vótáil tromlaigh chun na tweets faisnéiseacha a chinneadh. Bhain ár gcur chuige feidhmíocht iomaíoch amach agus d'fheidhmigh sé níos fearr ná an bonnlíne 7% (timpeall).", 'el': 'Η πανδημία έχει γίνει το επίκεντρο θέμα στο Twitter και οι άνθρωποι ενδιαφέρονται να μοιραστούν ποικίλες πληροφορίες που κυμαίνονται από νέες περιπτώσεις, κατευθυντήριες γραμμές υγειονομικής περίθαλψης, φάρμακα και ειδήσεις εμβολίων. Οι πληροφορίες αυτές βοηθούν τους ανθρώπους να ενημερώνονται για την κατάσταση, καθώς και να επωφελούνται από το προσωπικό δημόσιας ασφάλειας για τη λήψη αποφάσεων. Ωστόσο, η άτυπη φύση του Twitter καθιστά δύσκολη τη βελτίωση των ενημερωτικών tweets από τις τεράστιες ροές tweets. Για την αντιμετώπιση αυτών των προκλήσεων η WNUT-2020 εισήγαγε ένα κοινό έργο που επικεντρώνεται στον πληροφοριακό προσδιορισμό tweets που σχετίζεται με το COVID-19. Στην παρούσα εργασία περιγράφουμε τη συμμετοχή μας σε αυτό το έργο. Προτείνουμε ένα νευρωνικό μοντέλο που υιοθετεί τη δύναμη της μάθησης μεταφοράς και των χειροποίητων χαρακτηριστικών σε μια ενιαία αρχιτεκτονική. Για να εξαγάγουμε τα χαρακτηριστικά μάθησης μεταφοράς, χρησιμοποιούμε τα προηγμένα προ-εκπαιδευμένα πρότυπα πρότασης που ενσωματώνουν το μοντέλο ενώ χρησιμοποιούνται διάφορα χαρακτηριστικά για την εξαγωγή των χειροποίητων χαρακτηριστικών. Στη συνέχεια, χρησιμοποιούνται διάφοροι συνδυασμοί χαρακτηριστικών για να εκπαιδεύσουν ένα σύνολο πολυστρωματικών perceptron (MLP) ως βάση-ταξινομητή. Τέλος, χρησιμοποιείται μια προσέγγιση σύντηξης βάσει πλειοψηφίας για τον προσδιορισμό των ενημερωτικών tweets. Η προσέγγισή μας πέτυχε ανταγωνιστικές επιδόσεις και ξεπερνούσε τη βασική γραμμή κατά 7% (περίπου.).', 'hu': 'A COVID-19 járvány a Twitteren divatos témává vált, és az emberek érdeklődnek az új esetektől, az egészségügyi iránymutatásoktól, az orvostudományi és vakcinás hírekig terjedő információk megosztása iránt. Az ilyen információk segítik az embereket a helyzetről való frissítésben, valamint a közbiztonsági személyzet számára előnyös döntéshozatal szempontjából. A twitter informális természete azonban kihívást jelent a hatalmas tweet streamekből származó információs tweetek finomítása. E kihívások kezelése érdekében a WNUT-2020 egy közös feladatot vezetett be, amely a COVID-19-hez kapcsolódó információs tweet-azonosításra összpontosít. Ebben a tanulmányban bemutatjuk, hogy részt veszünk ebben a feladatban. Olyan neurális modellt javasolunk, amely egységes architektúrában alkalmazza a transzfer tanulás erejét és a kézzel készített funkciókat. Az átviteli tanulási funkciók kivonásához a legkorszerűbb, előre képzett mondat beágyazási modellt használjuk a BERT, RoBERTa és InferSent, míg a különböző twitter jellemzőket kihasználjuk a kézzel készített funkciók kivonására. Ezt követően különböző funkciókombinációkat használnak a többrétegű perceptron (MLP) készletének az alap-osztályozóként. Végül a többségi szavazáson alapuló fúziós megközelítést alkalmazzák az információs tweetek meghatározására. Megközelítésünk versenyképes teljesítményt ért el, és 7%-kal túllépte a kiindulási értéket.', 'ka': 'COVID-19 პონდემიკა იყო რრენდემიური თემა Twitter-ში და ადამიანები ინტერესებულია განსხვავებული ინფორმაციების გაყოფილი ახალი შემთხვევაზე, ჯანმრთელობის პროგრამებით, მედიცინის და გაკუთინები ასეთი ინფორმაცია დახმარებს ადამიანებს განახლება სიტაციაზე, და ბენეფიციური ადამიანის საზოგადოებო საქმერთო პოვნელი გადაწყვებისთვის. მაგრამ, რუტერის ინფორმაციური ნათობა შეუძლებელია, რომ ინფორმაციური რუტების გარეშე დიდი რუტების სტრიმიდან. WNUT-2020-ის განსაზღვრებისთვის გადაწყენება, რომელიც COVID-19 შესახებ ინფორმაციური რვიტის განსაზღვრებისთვის გადაყენება. ამ დომენტში ჩვენ ჩვენი დაწყვეტილება ამ დავალებში. ჩვენ მინდა ნეიროლური მოდელს, რომელიც გავაკეთებს ტრანსტრინციის სწავლების ძალას და ხელსაწყოფილი ფუნქციების ერთადერთი აქტიქტურაში. ჩვენ გამოყენებთ გასწავლის ფუნქციების გასწავლისთვის, ჩვენ გამოყენებთ წარმოადგენის წარმოადგენის მოდელს BERT, RoBERTa და InferSent, თუმცა განსხვავებული twitter ფუნქციები გამოყენებულია, რომ გამოყენებთ ხელსაწყოფილი ფუ შემდეგ, განსხვავებული ფუნქციების კომბიზაციები გამოყენება, რომ მრავალური ფუნქცირების კომბიზაცია (MLP) როგორც ფუნქცირების კლასიფიკაცია გას საბოლოოდ, უფრო მეტი დოლამის დაბაზეული ფუზიციის პროგორმა იყენება ინფორმატიური ტვიტების განსაზღვრებისთვის. ჩვენი პროგრამის შესაძლებლობა კონსპექტიური კონპექტიური გამოყენება და 7% (მხოლოდ).', 'it': "La pandemia COVID-19 è diventata l'argomento di tendenza su twitter e le persone sono interessate a condividere diverse informazioni che vanno da nuovi casi, linee guida sanitarie, medicine e notizie sui vaccini. Tali informazioni aiutano le persone ad essere aggiornate sulla situazione e sono utili per il personale di pubblica sicurezza per il processo decisionale. Tuttavia, la natura informale di Twitter rende difficile perfezionare i tweet informativi provenienti dagli enormi flussi di tweet. Per affrontare queste sfide WNUT-2020 ha introdotto un compito condiviso incentrato sull'identificazione informativa dei tweet correlati al COVID-19. In questo articolo descriviamo la nostra partecipazione a questo compito. Proponiamo un modello neurale che adotta la forza del transfer learning e delle funzionalità artigianali in un'architettura unificata. Per estrarre le funzionalità di apprendimento del trasferimento, utilizziamo il modello di incorporazione delle frasi pre-addestrato all'avanguardia BERT, RoBERTa e InferSent, mentre varie caratteristiche di twitter sono sfruttate per estrarre le funzionalità artigianali. Successivamente, varie combinazioni di funzionalità sono utilizzate per addestrare un insieme di percettron multistrato (MLP) come classificatore base. Infine, per determinare i tweet informativi viene utilizzato un approccio basato sulla fusione basato sul voto a maggioranza. Il nostro approccio ha raggiunto prestazioni competitive e ha superato la base del 7% (circa).", 'kk': 'COVID-19 пандемия Твиттердің тенденциялық нақышы болды, және адамдар жаңа жағдайдан, саулық сақтау бағыттамалары, медицина және вакцина жаңалықтарын ортақтастыруға көмектеседі. Бұл мәлімет адамдарды жаңартуға көмектеседі, сондай-ақ қауіпсіздік қауіпсіздік адамдарға шешім беру үшін пайдалы болады. Бірақ, Твиттердің мәліметті тәуеттерді көп tweet көзінен жаңарту көмегімен жасайды. Бұл мәселелерді WNUT-2020 бақылау үшін COVID-19 мәліметті tweet идентификациясына назардағы ортақ тапсырманы көрсетті. Бұл қағазда біз бұл тапсырмаға қатынасызды таңдаймыз. Біз біріктірілген архитектураның оқыту мен қол құрылған мүмкіндіктерінің күшін көмектесетін невралдық моделін ұсынамыз. Трансферт оқыту мүмкіндіктерін тарқату үшін біз BERT, RoBERTa және InferSent үлгісін қолдану үшін әртүрлі twitter қасиеттері қолмен құрылған мүмкіндіктерді тарқату үшін қолданады. Келесі, көптеген қабатты түсініктерді (MLP) негізгі классификациясы ретінде оқыту үшін әртүрлі мүмкіндіктерді комбинациялау қолданылады. Соңында, көпшілігі сайлау негізінде біріктіру әдісі мәліметті tweets анықтау үшін қолданылады. Біздің тәсіліміміз конкурентті істеу және негізгі жолды 7% (көп).', 'mk': 'Пандемијата КОВИД-19 стана тенденциска тема на Твитер и луѓето се заинтересирани за споделување на различни информации кои се движат од нови случаи, насоки за здравствена заштита, медицина и вести за вакцините. Such information assists the people to be updated about the situation as well as beneficial for public safety personnel for decision making.  Сепак, неформалната природа на Твитер го прави предизвик да се рафинираат информативните твитови од огромните твитови потоци. За решавање на овие предизвици ВНУТ-2020 воведе заедничка задача која се фокусира на информативната идентификација на Твитер поврзана со COVID-19. Во овој весник го опишуваме нашето учество во оваа задача. Предложуваме нервен модел кој ја усвои силата на трансферентното учење и рачно направени карактеристики во единствена архитектура. За да ги извлечеме карактеристиките на учењето на трансферот, ги користиме најновите предобучени реченици кои ги вклучуваат моделите BERT, RoBERTa и InferSent, додека различни карактеристики на Твитер се искористени за извлекување на рачно направени карактеристики. Следно, различни комбинации на карактеристики се користат за обука на мнографски перцептрон (MLP) како основен класификатор. Конечно, за одредување на информативните твитови се користи пристап на фузија базиран на мнозинството гласање. Нашиот пристап постигна конкурентна резултат и ја надмина основата за 7 % (околу).', 'ms': 'Pandemi COVID-19 telah menjadi topik trending di Twitter dan orang-orang berminat berkongsi maklumat berbeza berlainan dari kes-kes baru, panduan rawatan kesehatan, ubat, dan berita vaksin. Maklumat seperti ini membantu orang untuk dikemaskini mengenai keadaan serta berguna untuk pegawai keselamatan awam untuk membuat keputusan. Namun, sifat informal Twitter membuatnya mencabar untuk memperbaiki tweet maklumat dari aliran tweet yang besar. Untuk menangani cabaran ini WNUT-2020 memperkenalkan tugas berkongsi yang fokus pada pengenalan Twit maklumat berkaitan dengan COVID-19. Dalam kertas ini, kami menjelaskan participasi kami dalam tugas ini. Kami mengusulkan model saraf yang mengadopsi kekuatan pembelajaran pemindahan dan ciri-ciri buatan tangan dalam arkitektur bersatu. Untuk mengekstrak ciri-ciri pembelajaran pemindahan, kami menggunakan kalimat terbaik yang dilatih-dilatih untuk memasukkan model BERT, RoBERTa, dan InferSent, sementara beberapa ciri-ciri twitter dieksploitasi untuk mengekstrak ciri-ciri buatan tangan. Seterusnya, berbagai kombinasi ciri digunakan untuk melatih set perseptron berbilang lapisan (MLP) sebagai pengklasifikasi as as. Akhirnya, pendekatan fusi berdasarkan suara kebanyakan digunakan untuk menentukan tweet maklumat. Pendekatan kami mencapai prestasi kompetitif dan melampaui dasar dengan 7% (kira-kira).', 'lt': 'COVID-19 pandemic has become the trending topic on twitter and people are interested in sharing diverse information ranging from new cases, healthcare guidelines, medicine, and vaccine news.  Tokia informacija padeda žmonėms atnaujinti padėtį ir naudinga visuomenės saugos darbuotojams priimant sprendimus. Tačiau dėl neoficialaus Twitter pobūdžio sunku patobulinti informacinius tweetus iš didžiulių Twitter srautų. Siekiant spręsti šiuos uždavinius, WNUT-2020 įvedė bendrą užduotį, daugiausia dėmesio skiriant su COVID-19 susijusiam informaciniam tweeto identifikavimui. Šiame dokumente apibūdiname savo dalyvavimą šioje užduotyje. We propose a neural model that adopts the strength of transfer learning and hand-crafted features in a unified architecture.  Siekdami išgauti perkėlimo mokymosi savybes, mes naudojame naujausius iš anksto parengtus sakinius įterpiančius BERT, RoBERTa ir InferSent modelius, o rankiniams savybėms išgauti naudojamos įvairios twitter savybės. Toliau naudojami įvairūs požymių deriniai daugiasluoksniam perceptronui (MLP) treniruoti kaip bazinį klasifikatorių. Galiausiai informaciniams tweetams nustatyti naudojamas daugumos balsais pagrįstas branduolių sintezės metodas. Mūsų požiūris pasiekė konkurencinius rezultatus ir viršijo bazinę vertę 7 % (maždaug).', 'ml': 'കോവിഡി-19 പാന്\u200dഡെമിക്ക് ട്വിറ്റരില്\u200d നിന്നുള്ള വിഷയത്തില്\u200d മാറിയിരിക്കുന്നു. പുതിയ കേസുകളില്\u200d നിന്നും വ്യത്യസ്ത വിവരങ്ങള്\u200d പങ്കു Such information assists the people to be updated about the situation as well as beneficial for public safety personnel for decision making.  എന്നാലും, ട്വിറ്ററിന്റെ അപരിചിതമായ പ്രകൃതിയാണ് അത് വിവരങ്ങളുടെ വിവരങ്ങള്\u200d വീണ്ടെടുക്കുവാന്\u200d വിലാസപ്പെടു ഈ ചോദ്യങ്ങള്\u200d വിലാസപ്പെടുത്താന്\u200d വ്യുന്യൂട്ട്-2020 കൊണ്ട് കോവിഡി-19 വിവരങ്ങളുടെ തിരിച്ചറിയുന്ന വിവരങ്ങള്\u200d ശ്രദ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഈ ജോലിയില്\u200d പങ്കെടുക്കുന്നത് വിശദീകരിക്കുന്നു. നമ്മള്\u200d ഒരു ന്യൂറല്\u200d മോഡല്\u200d പ്രൊദാന്\u200dസ് ചെയ്യുന്നു. അത് പഠനം മാറ്റുന്നതിന്\u200dറെയും കൈകാര്യം കൈക്കൊണ്ടുള്ള വിശേഷതകളു മാറ്റുന്ന പഠിക്കുന്ന സ്വഭാവങ്ങള്\u200d പുറത്തെടുക്കാന്\u200d വേണ്ടി, മുന്നില്\u200d പഠിപ്പിക്കപ്പെട്ട വാക്കിന്റെ മോഡല്\u200d ബെര്\u200dട്ടി, റോബെര്\u200dട്ട, ഇന്\u200dഫെര്\u200dസെന്\u200dറ് എന്\u200dഫെര്\u200dസ അടുത്തത്, വ്യത്യസ്ത കൂട്ടുകങ്ങള്\u200d ഉപയോഗിക്കുന്നു. ഒരു സജ്ജീകരണത്തിന്\u200dറെ (എംഎല്\u200dപി) അടിസ്ഥാനത്തെ ക്ലാസ്ഫിക്സര്\u200d ആയി ഒരു സ അവസാനം, വോട്ട് ചെയ്യുന്നതില്\u200d അധികപേരും വിവരങ്ങള്\u200d വിവരങ്ങള്\u200d തീരുമാനിക്കാന്\u200d വേണ്ടി ഫ്യൂഷന്\u200d നടപടിയാണ്. നമ്മുടെ അടുത്തേക്ക് മത്സരമുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200d എത്തിയപ്പോള്\u200d ബേസ്ലൈനില്\u200d 7% (approximately)', 'mt': 'COVID-19 pandemic has become the trending topic on twitter and people are interested in sharing diverse information ranging from new cases, healthcare guidelines, medicine, and vaccine news.  Tali informazzjoni tgħin lin-nies biex jiġu aġġornati dwar is-sitwazzjoni kif ukoll ta’ benefiċċju għall-persunal tas-sigurtà pubblika għat-teħid tad-deċiżjonijiet. Madankollu, in-natura informali tat-twitter tagħmel diffiċli li jiġu raffinati t-tweets informattivi mill-flussi enormi tat-twitter. To address these challenges WNUT-2020 introduced a shared task focusing on COVID-19 related informative tweet identification.  F’dan id-dokument, niddeskrivu l-parteċipazzjoni tagħna f’dan il-kompitu. Aħna nipproponu mudell newrali li jadotta s-saħħa tat-tagħlim tat-trasferiment u l-karatteristiċi maħduma bl-idejn f’arkitettura unifikata. Biex nisfruttaw il-karatteristiċi tat-tagħlim tat-trasferiment, aħna nużaw il-mudell ta’ inkorporazzjoni ta’ sentenza mħarrġa minn qabel ta’ l-aħħar BERT, RoBERTa, u InferSent, filwaqt li diversi karatteristiċi tat-twitter huma sfruttati biex nisfruttaw il-karatteristiċi ta’ l-idejn. Wara, jintużaw diversi kombinazzjonijiet ta’ karatteristiċi biex jitħarreġ sett ta’ perċepton b’ħafna saffi (MLP) bħala l-klassifikatur bażi. Fl-a ħħar nett, jintuża approċċ ta’ fużjoni bbażat fuq il-vot tal-maġġoranza biex jiġu ddeterminati t-tweets informativi. L-approċċ tagħna kiseb prestazzjoni kompetittiva u qabeż il-linja bażi b’7% (madwar).', 'mn': 'COVID-19 pandemic has become the trending topic on twitter and people are interested in sharing various information from new cases, health care guidelines, medicine, vaccine news. Ийм мэдээлэл хүмүүст нөхцөл байдал тухай шинэчлэхэд тусалдаг бөгөөд нийтийн аюулгүй хүмүүст шийдвэр гаргах хэрэгтэй. Гэхдээ Твиттерийн үндсэн байгаль нь мэдээллийн tweets-г маш том tweet урсгалын шинэчлэхэд хэцүү болгодог. ДНУТ-2020 оны эдгээр сорилтуудыг зохицуулахын тулд COVID-19 холбоотой мэдээллийн tweet тодорхойлолтын төвлөрөмж төвлөрүүлсэн ажил гаргасан. Энэ цаасан дээр бид энэ ажлын оролцоог тайлбарлаж байна. Бид мэдрэлийн загварыг нэгтгэх архитектурд суралцах болон гар бүтээгдэхүүний хүчийг ашигладаг. Шинээлт суралцах чадварыг гаргахын тулд бид урлагийн урлагийн өмнө суралцагдсан өгүүлбэр BERT, RoBERTa, InferSent загварыг ашиглаж байна. Гэхдээ олон Twitter чадваруудыг гар бүтээгдэхүүнийг ашиглаж байна. Дараагийн, олон давхар ойлголтыг (MLP) суурь-классификатор болгон сургуульд хэрэглэгддэг. Эцэст нь ихэнх нь сонголтын үндсэн цуглуулалт нь мэдээллийн tweets тодорхойлдог. Бидний арга баримт өрсөлдөг үйл ажиллагааг гаргаж, үндсэн шугам 7% (ойролцоогоор) үржүүлсэн.', 'pl': 'Pandemia COVID-19 stała się trendowym tematem na Twitterze, a ludzie są zainteresowani dzieleniem się różnymi informacjami, od nowych przypadków, wytycznych opieki zdrowotnej, medycyny i wiadomości o szczepionkach. Takie informacje pomagają ludziom być na bieżąco informowane o sytuacji, a także korzystne dla personelu bezpieczeństwa publicznego w podejmowaniu decyzji. Jednak nieformalny charakter twittera sprawia, że trudno jest dopracować informacyjne tweety z ogromnych strumieni tweetów. Aby sprostać tym wyzwaniom, WNUT-2020 wprowadził wspólne zadanie koncentrujące się na identyfikacji informacyjnych tweetów związanych z COVID-19. W artykule opisujemy nasz udział w tym zadaniu. Proponujemy model neuronowy, który przyjmuje siłę uczenia się transferowego i ręcznie wykonywanych funkcji w ujednoliconej architekturze. Aby wyodrębnić funkcje uczenia się transferu, wykorzystujemy najnowocześniejsze, wstępnie przeszkolone modele osadzania zdań BERT, RoBERTa i InferSent, podczas gdy różne cechy twittera są wykorzystywane do wyodrębnienia ręcznie tworzonych funkcji. Następnie, różne kombinacje cech są wykorzystywane do trenowania zestawu wielowarstwowego perceptronu (MLP) jako klasyfikatora bazowego. Wreszcie, do określenia informacyjnych tweetów stosuje się podejście oparte na głosowaniu większością głosów oparte na fuzji. Nasze podejście osiągnęło wyniki konkurencyjne i przewyższyło wartość bazową o 7% (ok.).', 'ro': 'pandemia COVID-19 a devenit subiectul de tendință pe Twitter și oamenii sunt interesați să împărtășească diverse informații, de la cazuri noi, orientări privind sănătatea, medicamente și știri privind vaccinurile. Astfel de informații ajută oamenii să fie actualizați cu privire la situație, precum și benefice pentru personalul de siguranță publică pentru luarea deciziilor. Cu toate acestea, natura informală a Twitter face dificilă rafinarea tweet-urilor informative din fluxurile imense de tweet. Pentru a aborda aceste provocări, WNUT-2020 a introdus o sarcină comună axată pe identificarea informativă a tweetului legată de COVID-19. În această lucrare, descriem participarea noastră la această sarcină. Propunem un model neural care adoptă puterea învățării transferului și caracteristicile realizate manual într-o arhitectură unificată. Pentru a extrage caracteristicile de învățare a transferului, utilizăm modelul de încorporare a frazelor de ultimă generație pre-antrenat BERT, RoBERTa și InferSent, în timp ce diferite caracteristici Twitter sunt exploatate pentru a extrage caracteristicile lucrate manual. În continuare, diferite combinații de caracteristici sunt utilizate pentru a antrena un set de perceptron multistrat (MLP) ca clasificator de bază. În cele din urmă, o abordare bazată pe vot majoritar de fuziune este folosită pentru a determina tweeturile informative. Abordarea noastră a atins performanțe competitive și a depășit valoarea de referință cu 7% (aproximativ).', 'no': 'COVID-19 pandemikk har blitt trending på twitter, og folk er interessert i å dele ulike informasjon frå nye tilfeller, helsehandlingslinjer, medisiner og vaksine. Denne informasjonen hjelper folket å oppdaterast om situasjonen, og tilgjengeleg for offentlige tryggleiksgiver for avgjøring. Den informale naturen av twitter gjer imidlertid det vanskeleg å refinera informativne tweetene frå dei store tweetestrømmene. For å handtera desse utfordringane, introduced WNUT-2020 ein delt oppgåve som fokuserer på COVID-19-relatert informativt tweet-identifikasjon. I denne papiret beskriver vi deltakaren vårt i denne oppgåva. Vi foreslår eit neuralmodell som adopterer styrken for å lære og handbokrafterte funksjonar i ein vienot arkitektur. For å pakka ut innlesingsfunksjonane, bruker vi tilstanden til kunsten før- trenga setningsmodulet BERT, RoBERTa og InferSent, mens ulike twitter- karakteristikk er ekspluatert for å pakka ut handtekrafte funksjonane. Neste blir brukt ulike funksjonskombinasjonar for å trenja eit sett av fleire lag-oppfattingar (MLP) som baseklassifisering. Etter slutt, er ein fleste stemmebasert fusjonslinjer arbeidt for å bestemme informativne tweeter. Tilnærminga vårt oppnådd konkurentivt utvikling og utførte baselinja med 7% (nærmere).', 'sr': 'Pandemija COVID-19 postala je trending tema na twitter i ljudi su zainteresovani za dijeljenje različitih informacija od novih slučajeva, uputstva na zdravstvenu pomoć, medicinsku i vakcinu. Takva informacija pomaže ljudima da se aktualizuju o situaciji, kao i korisno za osoblje za javnu sigurnost za odluku. Međutim, neformalna priroda Twittera je izazovna da se oslobodi informativne tweets iz ogromnih tweetskih potoka. Za rješavanje tih izazova WNUT-2020, predstavio je zajednički zadatak koji se fokusira na identifikaciju informativnih tweta povezanih sa COVID-19. U ovom papiru opisujemo naše sudjelovanje u ovom zadatku. Predlažemo neuralni model koji usvoji snagu učenja prijenosa i obrazovanja ruku u ujedinjenoj arhitekturi. Da bi izvukli karakteristike učenja prijenosa, iskoristili smo predobučenu rečenicu koja uključuje model BERT, RoBERTa i InferSent, dok se koriste različite karakteristike twitter kako bi izvukli karakteristike koje su napravljene rukama. Sledeće, različite kombinacije karakteristika se koriste za obuku set a višeslojnih perceptrona (MLP) kao osnovne klasifikacije. Na kraju, većina glasova baziranog na fuziji je zaposlena kako bi utvrdila informativne tweete. Naš pristup je postigao konkurentne funkcije i iznosio početnu liniju za 7% (približno).', 'so': 'Cudurada COVID-19 waxay noqotay arimaha ku saabsan Twitterka, dadkuna waxay u xiiseysaa inay sharaxaan macluumaad kala duduwan oo kala duduwan, hagitaanka daryeelka caafimaadka, daawooyinka iyo wararka vaccinada. Macluumaadkaas oo ka mid ah ayaa dadka ka caawinaya in la cusboonaysiiyo xaalada iyo faa’iido leh arrimaha go’aanka xafiiska ammaanka bulshada. Si kastaba ha ahaatee dabiicadda rasmi ah ee Twitterka waxaa ka dhigaya mid adag in la cusboonaysiiyo tweetka macluumaadka ah oo laga soo jeedo weerarka Twitteet ee weyn. Shaqooyinkan WNUT-2020 wuxuu qabanqaabiyey shaqo qayb ah oo ku kalsoonaaday aqoonsiga Twitterka ee la xiriira COVID-19. Qoraalkan waxaynu ku qornaa qayb ka wadashada shaqadan. Tusaale neurada ah oo qaadanaya xoogga cilmiga la wareejiyo iyo qalabka ay gacanta ku qabanqaabiso. Si aan u soo saarno qalabka waxbarashada, waxaynu isticmaalaynaa noocyada xaalada-farshaxanta-horaadka ah oo ku qoran qaabka BERT, RoBERTA iyo InferSent, iyadoo waxaa loo isticmaalaa takhasusyo kala duduwan oo twitter ah si aan u soo bixino tayada gacanta-gacanta. Inta dambe waxaa loo isticmaalaa bandhigyo kala duduwan oo lagu baro koox la mid ah tusaale ahaan karo perceptron (MLP). Ugu dambaysta waxaa loo qabanqaabiyaa habka qaxootinta ee codeynta oo ku saleysan qof badan si uu u go’aamiyo tweetka macluumaadka. Dhaqdhaheenna waxay gaadhay sameynta iskutallaabta, waxaana sameynay heerka hoose qiyaastii 7 boqolkiiba (qiyaas).', 'sv': 'COVID-19-pandemin har blivit det trendiga ämnet på twitter och människor är intresserade av att dela med sig av varierande information från nya fall, vårdriktlinjer, medicin och vaccinnyheter. Sådan information hjälper människorna att bli uppdaterade om situationen och är till nytta för den allmänna säkerhetspersonalen vid beslutsfattandet. Twitters informella karaktär gör det dock svårt att förfina de informativa tweeten från de enorma tweetströmmarna. För att möta dessa utmaningar införde WNUT-2020 en gemensam uppgift med fokus på COVID-19 relaterad informativ tweetdentifiering. I denna uppsats beskriver vi vårt deltagande i denna uppgift. Vi föreslår en neural modell som antar styrkan i överföring lärande och handgjorda funktioner i en enhetlig arkitektur. För att extrahera överföringsinlärningsfunktionerna använder vi den senaste förklädda meningsmodellen BERT, RoBERTa och InferSent, medan olika twitter-egenskaper utnyttjas för att extrahera de handgjorda funktionerna. Därefter används olika funktionskombinationer för att träna en uppsättning flerlagers perceptron (MLP) som basklassificering. Slutligen används en majoritetsbeslutsbaserad fusionsmetod för att fastställa de informativa tweeten. Vårt tillvägagångssätt uppnådde konkurrenskraftig prestanda och överträffade baslinjen med 7% (ca).', 'ta': 'COVID-19 துக்கம் துண்டிக்கப்பட்டுள்ளது twitter மற்றும் மக்கள் புதிய விஷயங்கள், உடல் பராமரிப்பு வழிகாட்டி இந்த தகவல் மக்கள் நிலைமையைப் பற்றி புதுப்பிக்க உதவுகிறது மற்றும் தீர்வு செய்ய பொது பாதுகாப்பு செயல்படுத்து ஆயினும், இந்த பெரிய தொடர் ஆறுகளில் இருந்து தகவல் தொடர்புகளை புதுப்பிக்க அது சவால் செய்கிறது. இந்த சவால்களை முகவரிக்க WNUT-2020 ஒரு பங்கிடப்பட்ட பணியை குறிப்பிட்டது COVID-19 தொடர்புடைய தகவல் தொடர்புடைய Twitter அடையாளம்  இந்த காகிதத்தில், நாம் இந்த பணியில் எங்கள் பங்கீட்டை விவரிக்கிறோம். நாம் ஒரு புதிய மாதிரியை பரிந்துரைக்கிறோம். அது கல்வி மற்றும் கையில் உள்ள மாற்றும் தனிப்படுத்தப்பட்ட கட்டுக்கூற்றில மாற்றி கற்றல் குணங்களை வெளியேற்றுவதற்கு, நாம் முன் பயிற்சி முன் பயிற்சி செய்யப்பட்ட வாக்கியத்தின் மாதிரி BERT, ராபிரேடா மற்றும் InferSent பயன்படுத்துகிறோம், ஆனால் வேற அடுத்து, பல பண்புகள் இணைப்புகள் அடிப்படை வகைப்பாளராக ஒரு அமைப்பை பயிற்சி செய்ய பயன்படுத்தப்படுகிறது. இறுதியில், பெரும்பாலான வாக்குதல் அடிப்படையில் உள்ள குளியீட்டு செயல்பாடு தீர்மானிக்கப்படுகிறது. நம்முடைய நெறிமுறை போட்டியான செயல்முறையை அடைந்தது மற்றும் அடிப்படையில் 7% (approximately)', 'si': 'COVID-19 පැන්ඩේමික් ට්විටර් එක්ක ප්\u200dරශ්නයක් වෙලා තියෙන්නේ. මිනිස්සුන් අලුත් විදියට ප්\u200dරශ්නයක් සම්බන්ධ වෙන්නේ අලුත්  ඒ වගේ තොරතුරු මිනිස්සුන්ට තීරණය කරන්න ප්\u200dරයෝජනයක් ගැන අවස්ථාවක් වෙන්න උදව් කරනවා. නමුත්, ට්විටර්ගේ නිර්මාණික ස්වභාවිතයෙන් ඒක ප්\u200dරශ්නයක් කරනවා විශාල තවිට් වලින් තොරතුරු ටුවට් වලි මේ අභ්\u200dයාගයක් විදිහට WNAT-2020යි COVID-19 සම්බන්ධ විදිහට සම්බන්ධ විදිහට තුවක්තිය ටුයිට් පරීක්ෂණය සඳ මේ පත්තරේ අපි මේ වැඩේ අපේ සමාගම විස්තර කරනවා. අපි ප්\u200dරයෝජනය කරනවා න්\u200dයූරාල් මෝඩල් එකක් විද්\u200dයාපනයක් වලින් ප්\u200dරයෝජනය කරනවා කියලා. ප්\u200dරවර්තනය ඉගෙන ගන්න පුළුවන් විශේෂතාවක් නිකාලන්න, අපි ප්\u200dරවර්තනය කරන්න පුළුවන් විශේෂතාවක් ප්\u200dරවර්තනය කරනවා BERT, RoBERTa, සහ InferSent, ඒ වගේම විවි ඊළඟ, විවිදියට විවිදියට සම්බන්ධයක් ප්\u200dරයෝජනය කරනවා බාධාරිත්මක පරීක්ෂකය (MLP) විදියට ගොඩක් ප්\u200dරයෝ අන්තිමේදි, බොහෝම අධ්\u200dයාත්මක විශ්වාස කරන්න අධ්\u200dයාත්මක විශ්වාස කරන්නේ තොරතුරු ට්විට් නිර අපේ පරීක්ෂණය සාධාරණ ප්\u200dරභාවිත විදිහට පටන් ගත්තා 7% විදිහට පටන් ගත්තා.', 'ur': 'COVID-19 pandemic has become the trending topic on twitter and people are interested in sharing various information from new cases, health care guidelines, medicine and vaccine news. اس طرح کی اطلاعات لوگوں کو اس موقعیت کے بارے میں آدھیرنے کی مدد کرتی ہے اور فیصلہ کرنے کے لئے عمومی امنیت کارساز کے لئے فائدہ اٹھاتی ہے. However, the informative tweets from the huge tweet streams are difficult to refine. ان چالوں کے بارے میں WNUT-2020 کو ایک مشترک کام معلوم کردیا ہے جو COVID-19 رابطہ دار معلومات ٹویٹ شناسیٹ پر تمرکز کرتی ہے. اس کاغذ میں ہم اپنے حضور اس کام میں توصیف کرتے ہیں۔ ہم ایک نئورل مدل کی پیشنهاد کرتے ہیں جو ایک متحدہ معماری میں استعمال کی طاقت اور ہاتھ بنایا گیا ہے۔ انتقال کی تعلیم کے فرصت اضافہ کرنے کے لئے، ہم نے اضافہ کرنے کے لئے آهنت کی پیش آموزش کی جماعت کی موڈل BERT, RoBERTa اور InferSent کو استعمال کیا ہے، حالانکہ مختلف ٹویٹر کی تعریفیں اضافہ کرنے کے لئے اضافہ کی جاتی ہیں. آگے، مختلف فائدہ ترکینٹ (MLP) کو بنسٹ کلاسیر کی طرح ترکینٹ کرنے کے لئے استعمال کیا جاتا ہے. بالآخر، بہت سی باتوں کی بوسیدہ فوجین طریقے کی تعریف کے لئے استعمال کی جاتی ہے۔ ہماری تقریبا مسابقات کی عملکرد پہنچی اور بنیادی لین کو 7% (تقریباً) سے زیادہ عملہ کر دیا۔', 'uz': "COVID-19 pandemik Twitterga bog'liq mavzuga ega bo'ldi va odamlar yangi holatlardan turli har xil maʼlumot bilan, tibbiy qoʻllanmalar, tibbiy va vaksining xabar bilan bir xil maʼlumot shartlashga qiziqaraydi. Bu maʼlumot odamlarning holati haqida yangilashga yordam beradi va xavfsiz amalga oshirishga foydalanadi. Lekin, Twitter tarkibining haqiqiqiy tarkibi bu juda katta Twitterning haqida xabar tweetilarni yangilashga harakat qiladi. Bu muammolarni boshqarish uchun WNUT-2020, COVID-19 haqida maʼlumot Twitter identifikasini boshqarish uchun bir qanday ishni boshlagan. Bu hujjatda biz bu vazifaning qismlarimizni anglatamiz. Biz o'rganish va qo'llab qo'llab qo'llangan xususiyatlarni o'zgartirish imkoniyatlarini qo'shish mumkin. To extract the transfer learning features, we utilize the state-of-the-art pre-trained sentence embedding model BERT, RoBERTa, and InferSent, whereas various twitter characteristics are exploited to extract the hand-crafted features.  Next, various feature combinations are utilized to train a set of multilayer perceptron (MLP) as the base-classifier.  Endi, ko'pchilik voting asosiy fuqarish usuli haqida maʼlumot tweetini aniqlash uchun ishlaydi. Bizning murakkablarimiz rivojlanishimizga yetdi va asboblarning 7% (takroq).", 'vi': 'Một đại dịch COVID-19 đã trở thành một chủ đề bắt đầu trên Twitter và mọi người rất hứng thú chia sẻ thông tin về các trường hợp mới, hướng dẫn chăm sóc sức khỏe, thuốc men và vắc-xin. Thông tin này giúp những người cần được cập nhật về tình hình và có lợi cho nhân viên an ninh cộng đồng để đưa ra quyết định. Tuy nhiên, tính chất không chính thức của twitter khiến chúng tôi phải thử thách cải thiện những dòng chảy thông tin từ những dòng chảy trên Twitter. Để đối phó với những thử thách này, tập trung vào việc nhận dạng trang web thông tin trên Twitter. Trong tờ giấy này, chúng tôi mô tả sự tham gia của chúng tôi. Chúng tôi đề xuất một mô hình thần kinh sử dụng sức mạnh của việc học chuyển nhượng và những tính năng tự làm theo cấu trúc thống nhất. Để trích các tính năng học tập chuyển nhượng, chúng tôi sử dụng các mẫu chữ được huấn luyện trước đây: BERT, RoBERTa, và InferTa, trong khi các đặc điểm Twitter khác nhau được khai thác để lấy các tính năng làm thủ công. Tiếp theo, các chuỗi đặc trưng được dùng để huấn luyện một bộ đa lớp perceptun (MLP) làm người phân loại nền. Cuối cùng, một phương pháp tổng hợp bỏ phiếu đa số được áp dụng để xác định các tweet thông tin. Cách tiếp cận của chúng ta đạt được hiệu suất cạnh tranh và hoàn thành cơ sở cơ bản.', 'bg': 'Пандемията се превърна в актуална тема в Туитър и хората се интересуват от споделяне на разнообразна информация, варираща от нови случаи, здравни насоки, медицина и ваксини новини. Такава информация помага на хората да бъдат актуализирани за ситуацията, както и полезни за персонала по обществената безопасност за вземане на решения. Въпреки това, неформалният характер на Туитър прави предизвикателство да се усъвършенстват информативните туитове от огромните туитове потоци. За да се справи с тези предизвикателства въведе споделена задача, фокусирана върху идентифицирането на информативни туитове, свързани с COVID-19. В тази статия описваме нашето участие в тази задача. Предлагаме невронен модел, който приема силата на трансферното обучение и ръчно изработените функции в единна архитектура. За да извлечем функциите за трансферно обучение, ние използваме най-съвременните предварително обучени модели за вграждане на изречения докато различни характеристики на Туитър са експлоатирани, за да извлечем ръчно изработените функции. След това, различни комбинации от функции се използват за обучение на набор от многослойни възприятия (МЛП) като основен класификатор. Накрая, за определяне на информативните туитове се използва подход, основан на мнозинство. Нашият подход постигна конкурентни резултати и надмина базовата база с приблизително 7%.', 'hr': 'Pandemija COVID-19 postala je trending tema na twitter i ljudi su zainteresovani za dijeljenje različitih informacija od novih slučajeva, vodiča zdravstvene pomoći, lijekova i vijesti cjepiva. Takve informacije pomažu ljudima da se aktualizuju o situaciji, kao i korisno za osoblje za javnu sigurnost u donošenju odluka. Međutim, neformalna priroda twitter izaziva izazov da popravi informativne tweets iz ogromnih tweet streama. Za rješavanje tih izazova WNUT-2020, predstavio je zajednički zadatak usredotočen na identifikaciju informativnih tweet a povezanih s COVID-19. U ovom papiru opisujemo naše sudjelovanje u ovom zadatku. Predlažemo neuralni model koji usvoji snagu učenja prijenosa i stavljanja ruke u ujedinjenoj arhitekturi. Da bi izvukli karakteristike učenja prijenosa, iskoristili smo predobučenu rečenicu koja uključuje model BERT, RoBERTa i InferSent, dok se koriste različite karakteristike twitter kako bi izvukli karakteristike koje su napravljene rukama. Sljedeće se koriste različite kombinacije karakteristika za obuku set a višeslojnih perceptora (MLP) kao osnovne klasifikacije. Na kraju, većina glasačkih pristupa fuzije je zaposlena kako bi utvrdila informativne tweete. Naš pristup je postigao konkurentne učinke i iznosio početnu liniju za 7% (približno).', 'nl': 'COVID-19 pandemie is uitgegroeid tot het trending onderwerp op twitter en mensen zijn geïnteresseerd in het delen van diverse informatie variërend van nieuwe gevallen, gezondheidsrichtlijnen, medicijnen en vaccinnieuws. Deze informatie helpt de mensen om op de hoogte te blijven van de situatie en is gunstig voor het personeel van de openbare veiligheid voor de besluitvorming. Het informele karakter van twitter maakt het echter lastig om de informatieve tweets uit de enorme tweetstromen te verfijnen. Om deze uitdagingen aan te pakken introduceerde WNUT-2020 een gedeelde taak die zich richt op COVID-19 gerelateerde informatieve tweet identificatie. In dit artikel beschrijven we onze deelname aan deze taak. We stellen een neuraal model voor dat de kracht van transfer learning en handgemaakte functies in een uniforme architectuur overneemt. Om de overdrachtsleerfuncties te extraheren, maken we gebruik van de state-of-the-art voorgetrainde zinsinbeddingsmodellen BERT, RoBERTa en InferSent, terwijl verschillende twitterkenmerken worden benut om de handgemaakte functies te extraheren. Vervolgens worden verschillende feature combinaties gebruikt om een set multilayer perceptron (MLP) te trainen als basis-classificator. Ten slotte wordt een fusie-benadering toegepast die gebaseerd is op meerderheidsstemming om de informatieve tweets te bepalen. Onze aanpak bereikte concurrerende prestaties en overtrof de baseline met 7% (ca.).', 'da': 'COVID-19 pandemi er blevet det trendende emne på twitter, og folk er interesserede i at dele forskellige oplysninger lige fra nye tilfælde, sundhedsretningslinjer, medicin og vaccine nyheder. Sådanne oplysninger hjælper folk med at blive opdateret om situationen samt gavnlige for offentlige sikkerhedspersonale i beslutningstagningen. Men den uformelle karakter af twitter gør det udfordrende at forfine de informative tweets fra de enorme tweet streams. For at løse disse udfordringer indførte WNUT-2020 en fælles opgave med fokus på COVID-19 relateret informativ tweet identifikation. I denne artikel beskriver vi vores deltagelse i denne opgave. Vi foreslår en neural model, der vedtager styrken af transfer learning og håndlavede funktioner i en samlet arkitektur. For at udtrække de overførselslæringsfunktioner, bruger vi den avancerede prætrænede sætningsindlejring model BERT, RoBERTa og InferSent, mens forskellige twitter egenskaber udnyttes til at udtrække de håndlavede funktioner. Dernæst bruges forskellige funktionskombinationer til at træne et sæt multilags perceptron (MLP) som base-klassifikation. Endelig anvendes en flertalsbaseret fusionsmetode til at fastlægge de informative tweets. Vores tilgang opnåede konkurrencedygtige resultater og overgik baseline med 7% (ca.).', 'id': 'Pandemi COVID-19 telah menjadi topik trending di Twitter dan orang-orang tertarik untuk berbagi informasi berbagai macam-macam yang berasal dari kasus baru, petunjuk kesehatan, obat, dan berita vaksin. Informasi seperti ini membantu orang untuk diperbarui tentang situasi serta berguna untuk staf keselamatan publik untuk membuat keputusan. Namun, sifat informal Twitter membuat tantangan untuk memperbaiki tweet informatif dari aliran tweet besar. Untuk mengatasi tantangan-tantangan ini WNUT-2020 memperkenalkan tugas berbagi yang fokus pada identifikasi informatif berkaitan dengan COVID-19. Dalam kertas ini, kami menggambarkan participasi kami dalam tugas ini. Kami mengusulkan model saraf yang mengadopsi kekuatan transfer belajar dan karakteristik karya tangan dalam arsitektur yang bersatu. Untuk mengekstrak ciri-ciri belajar transfernya, kami memanfaatkan kalimat terbaik yang dilatih-dilatih untuk memasukkan model BERT, RoBERTa, dan InferSent, sementara berbagai ciri-ciri twitter dieksploitasi untuk mengekstrak ciri-ciri yang dibuat tangan. Selanjutnya, berbagai kombinasi fitur digunakan untuk melatih set persepton multilapisan (MLP) sebagai klasifikasi dasar. Akhirnya, pendekatan fusi berdasarkan pemilihan mayoritas digunakan untuk menentukan tweet informatif. pendekatan kita mencapai prestasi kompetitif dan melebihi dasar dengan 7% (sekitar).', 'fa': 'پاندوم COVID-19 به عنوان موضوع تدریج روی توئیتر تبدیل شده و مردم علاقه دارند که اطلاعات مختلف را از پرونده های جدید، هدایت های مراقبت سلامتی، پزشکی و اخبار واکسن تقسیم کنند. این اطلاعات به مردم کمک می\u200cکند که در مورد وضعیت آگاهی شوند و برای افراد امنیت عمومی برای تصمیم گرفتن منافع باشند. با این حال، طبیعت غیر معمولی از ترویتر باعث می شود که توئیت های اطلاعاتی را از رودخانه های بزرگ توئیت تغییر دهد. برای حل این چالش\u200cها WNUT-2020 یک وظیفه مشترک را در مورد شناسایی توئیت اطلاعاتی رابطه به COVID-19 معرفی کرد. در این کاغذ، ما مشارکت خود را در این کار توصیف می کنیم. ما یک مدل عصبی پیشنهاد می\u200cکنیم که قدرت یادگیری و ویژگی\u200cهای دستی در یک معماری متحد را در اختیار می\u200cگیرد. برای خارج کردن ویژگی\u200cهای یادگیری انتقال، ما از موقعیت\u200cهای پیش آموزش\u200cشده\u200cی جمله\u200cای استفاده می\u200cکنیم که مدل BERT, RoBERTa و InferSent، در حالی که ویژگی\u200cهای متفاوتی ترویتر برای خارج کردن ویژگی\u200cهای دستی استفاده می\u200cشوند. بعدش، ترکیب\u200cهای ویژه\u200cهای مختلف برای آموزش مجموعه\u200cی مشاهده\u200cهای مختلف طبقه\u200cای (MLP) به عنوان گروه\u200cهای پایه استفاده می\u200cشود. بالاخره، بسیاری از دستور فشار بر اساس رای دادن برای تعیین توئیت های اطلاعاتی استخدام می شود. دستور ما به عملکرد رقابتی رسیده و پایین پایین 7% (تقریباً).', 'de': 'Die COVID-19-Pandemie ist zum Trendthema auf Twitter geworden und die Menschen sind daran interessiert, verschiedene Informationen zu teilen, die von neuen Fällen, Gesundheitsrichtlinien, Medikamenten und Impfstoffnachrichten reichen. Diese Informationen helfen den Menschen, über die Situation auf dem Laufenden zu bleiben und sind für das Sicherheitspersonal von Vorteil für die Entscheidungsfindung. Die informelle Natur von Twitter macht es jedoch schwierig, die informativen Tweets aus den riesigen Tweet-Streams zu verfeinern. Um diesen Herausforderungen gerecht zu werden, führte WNUT-2020 eine gemeinsame Aufgabe ein, die sich auf die COVID-19-bezogene informative Tweet-Identifizierung konzentriert. In diesem Beitrag beschreiben wir unsere Beteiligung an dieser Aufgabe. Wir schlagen ein neuronales Modell vor, das die Stärke von Transferlernen und handgefertigten Funktionen in einer einheitlichen Architektur übernimmt. Um die Übertragungslernfunktionen zu extrahieren, verwenden wir die hochmodernen vortrainierten Satzbedingungsmodelle BERT, RoBERTa und InferSent, während verschiedene Twitter-Eigenschaften genutzt werden, um die handgefertigten Features zu extrahieren. Als nächstes werden verschiedene Merkmalskombinationen verwendet, um einen Satz von Multilayer Perzeptron (MLP) als Basis-Klassifikator zu trainieren. Schließlich wird ein mehrheitlich stimmbasierter Fusionsansatz verwendet, um die informativen Tweets zu bestimmen. Unser Ansatz erzielte eine wettbewerbsfähige Leistung und übertraf die Basislinie um 7% (ca.).', 'ko': '코로나 팬데믹(세계적 대유행)이 트위터에서 화제가 되면서 새로운 사례, 의료지침, 약물, 백신 뉴스 등 각종 정보를 공유하는 데 관심이 쏠리고 있다.이런 정보는 사람들이 최신 상황을 이해하는 데 도움이 되고 공공 안전 요원들의 결정에도 도움이 된다.그러나 트위터의 비공식적 성격 때문에 거대한 추문 흐름에서 정보가 풍부한 추문을 추출하는 것은 도전적이다.이러한 도전에 대응하기 위해 WNUT-2020은 코로나와 관련한 정보 트위터 인식에 초점을 맞춘 공동 임무를 도입했다.본문에서 우리는 우리가 이 임무에 참여하는 상황을 묘사하였다.우리는 하나의 신경 모델을 제시했는데 이 모델은 통일된 체계 구조에서 전이 학습과 수공 제작 기능을 채택했다.이동 학습 특징을 추출하기 위해 우리는 가장 선진적인 예비 훈련 문장을 모델 BERT, RoBERTA, Inferesent에 삽입하고 각종 트위터 특징을 이용하여 수동으로 만든 특징을 추출했다.이어 각종 특징 조합을 이용하여 다중 감지기(MLP)를 기본 분류기로 훈련한다.마지막으로 다수 투표를 바탕으로 하는 융합 방법으로 정보 추문을 확정한다.우리의 방법은 베이스라인보다 7% 높은 경쟁력 있는 성능을 얻었다(약).', 'sw': 'Ugonjwa wa COVID-19 umekuwa mada inayoendelea kwenye mtandao wa twita na watu wanaguswa kushirikisha taarifa mbalimbali zinazotofautiana na kesi mpya, miongozo ya huduma za afya, madawa na habari za chanjo. Taarifa kama hizi zinawasaidia watu kupata taarifa mpya kuhusu hali hiyo pamoja na manufaa kwa wafanyakazi wa usalama wa umma kwa uamuzi. Hata hivyo, asili rasmi ya twita inafanya kuwa na changamoto ya kurekebisha twiti hizo za taarifa kutoka kwenye mitandao makubwa ya twita. Kupambana na changamoto hizi WNUT-2020 ilianzisha jukumu la ushirikiano linalohusiana na utambulisho wa Twita za Kitaarifa zinazohusiana na COVID-19. Katika karatasi hii, tunaelezea ushiriki wetu katika kazi hii. Tunazipendekeza muundo wa neura unaotumia nguvu ya kuhamisha elimu na vipengele vya mikononi katika majengo ya pamoja. Ili kuondoa vipengele vya kujifunza, tunatumia hali ya sanaa iliyoelekezwa na mtindo wa hukumu BERT, RoBERTA, na InferSent, ambapo takwimu mbalimbali za twita zinatumiwa kuchukua vipengele vya mikononi. Baadae, miungano mbalimbali yanatumiwa kufundisha mfululizo wa mtazamo wa wataalamu kadhaa (MLP) kama mgawanyiko wa msingi. Mwisho, mbinu nyingi za kupigia kura zinazotumiwa kwa ajili ya kuamua twiti hizo za taarifa. Hatua yetu ilifikia utendaji wa mashindano ya kushindana na kutengeneza mistari ya msingi kwa asilimia 7 (takriban).', 'sq': 'Pandemia COVID-19 është bërë tema e prirjes në Twitter dhe njerëzit janë të interesuar në ndarjen e informacioneve të ndryshme që shkojnë nga rastet e reja, drejtimet e kujdesit shëndetësor, mjekësitë dhe lajmet e vakcinave. Informacioni i tillë ndihmon njerëzit të përditësohen rreth gjendjes si dhe të dobishëm për personelin e sigurisë publike për marrjen e vendimeve. Megjithatë, natyra jozyrtare e Twitter e bën të sfidueshme të rafinuar tweetet informative nga rrjedhët e mëdha të Twitter-it. Për të trajtuar këto sfida WNUT-2020 futi një detyrë të përbashkët duke u përqëndruar në identifikimin informativ të COVID-19. Në këtë letër, ne përshkruajmë pjesëmarrjen tonë në këtë detyrë. Ne propozojmë një model neuronal që miraton fuqinë e transferimit të mësimit dhe karakteristikave të ndërtuara me dorë në një arkitekturë të unifikuar. Për të nxjerrë karakteristikat e mësimit të transferimit, ne përdorim modelin e paratrajnuar të lartë të fjalëve që përfshijnë modelin BERT, RoBERTa dhe InferSent, ndërsa karakteristikat e ndryshme të twitter janë shfrytëzuar për të nxjerrë karakteristikat e ndërtuar me dorë. Pastaj, kombinimet e ndryshme të funksioneve përdoren për të trajnuar një sërë perceptron shumështresa (MLP) si klasifikues bazë. Më në fund, përdoret një qasje e fuzionit bazuar në shumicën e votave për të përcaktuar tweetet informative. Përqasja jonë arriti performancën konkurruese dhe tejkaloi bazën me 7% (rreth.).', 'af': "COVID-19 pandemiek het die trending onderwerp op twitter geword en mense is geinteresseer in die deel van verskeie inligting van nuwe gevalle, gesondige reglyne, medikasie en vaksinnuus. Soos inligting help die mense om oor die situasie te opdateer en voordeel te word vir openbare sekuriteit personeel vir besluit. Maar die onformele natuur van twitter maak dit moeilik om die informatiewe tweete van die groot tweet strome te refineer. Om hierdie uitdagings te adres, het WNUT-2020 'n gedeelde taak gefokus op COVID-19 verwante informatiewe tweet identifikasie. In hierdie papier beskrywe ons deelnadering in hierdie taak. Ons voorstel 'n neurale model wat die sterkte van oordrag onderwerp en hand-gebreekte funksies in 'n eeneenvoude arkitektuur aanvaar. Om die oordrag leer funksies uitpak te maak, gebruik ons die staat-van-die-kuns voor-opgelei setnings ingesluit model BERT, RoBERTa en InferSent, terwyl verskillende twitter karakteristieke uitgebruik word om die hand-gebruikte funksies te uitpak. Volgende, verskillende funksie kombinasies word gebruik om 'n stel van veelvuldige laag verstaan (MLP) as die basis- klassifiseerder te trein. Eindelik is 'n meeste stem gebaseerde fusie toegang gebruik om die informatiewe tweets te bepaal. Ons toegang het rekenaar uitvoerding bereik en die basisline uitgevoer met 7% (omtrent).", 'tr': "COVID-19 pandemik twiterde näçe möhüm tema bolup geçdi we adamlar täze döwürden, saglyk seretmäge vadeli, derman we wajyp täzelikden daşary paýlamaga gyzyklanýar. Bärde maglumat adamlara şu ýagdaý barada täzelenmek üçin kömekleýär, we halk güvenlik personeli karar bermek üçin faydaly. Ýöne, twiterniň resmi sebäbi uly tweet aklaryndan informatiýatly tweetleri taýýarlamak kynçylykly edip biler. WNUT-2020'yň bu kynçylyklary çözmek üçin COVID-19 barada maglumaty tweet identifikaçy bilen paýlaşdy. Bu kagyzda biziň bu işiň bölegimizi tassyklaýarys. Biz neural nusgasyny bir birlik arhitektura içinde öwrenmek we elimizden gelen özellikleriň güýjüni üýtgeden bir nusgasyny teklip edip görýäris. Transfer öwrenmesi özelliklerini çykmak üçin, sanat öňünden öňünden eğlenen sözleriň durumyny BERT, RoBERTa we InferSent nusgasyny çykarmak üçin ullanýarys. Indiki, birnäçe hatlary beýleki hatlary beýleki hatlary (MLP) klasifikatçy hökmünde trenlemek üçin ullanýar. Soňunda, köp bölegi saýlamaga tabanly birleşme ýalaýyşy informative tweets bejermek üçin işgärlenir. Biziň ýaryşymyz ýaryşykly ukyplarymyza ýetdi we baseline 7% (approx.)-a çenli üstünlik etdi.", 'am': 'የCOVID-19 ደዌብ በትዊተር ላይ የደረሰ ጉዳይ ሆኖአል እና ሰዎች ከአዲስ ጉዳይ፣ የጤናዊ ጉዳይ፣ መድኃኒት መሪ፣ መድኃኒት እና የvaccine ዜና ተለይተዋል፡፡ እንደዚህ ያሉ መረጃ በጉዳዩ ላይ አዲስ ማድረግ እና ለየህዝብ ደኅንነት ሠራተኞች የሚጠቅሙ ናቸው፡፡ ነገር ግን የታላቁ ትዊተር ፈሳሾች የኢትዮጵያውያን ትዊተሮችን ለማሻሻል የሚችል ጥያቄ ይደረጋል፡፡ እነዚህን ጥቃቄዎች WNUT-2020 ለማግኘት የCOVID-19 ተሟጋቾች የሀገር ትዊት ግንኙነት ላይ የሚያስታወቅ የስራ ግንኙነት ያስተካክሎታል፡፡ በዚህ ገጾች ውስጥ የዚህን ስራ ተግባራችንን እናሳውቃለን፡፡ የናቡር ሞዴል በተጠቃሚ መሠረት ውስጥ ትምህርትን እና እጃቸውን የመለስ ኃይል የሚወስደውን እናሳስባለን፡፡ የንግግር ትምህርት ምርጫዎችን ለማውጣት፣ የጥንት-ቀድሞ ተማሪ የሥርዓት ግንኙነት BERT፣ ሮBERTA እና InferSent እና የTwitter ምርጫዎች እጃቸውን ለመውጣት የሚጠቅሙ ናቸው፡፡ የሚቀጥለውን የፊደል ምርጫዎች አካባቢ (MLP) መሠረት እንደሚያስተምር ይጠቅማል፡፡ በመጨረሻው፣ አብዛኞቹ የመረጥን ድምፅ የተመሳሳይ ጉዳይ የመረጃ ትዊተቶችን ለማረጋገጥ ተጠቃሚ ነው፡፡ የሥርዓታችን አካባቢ ድጋፍ አግኝቷል፡፡', 'hy': 'COVID-19 համաճարակը դարձավ Թվիթերի տենդենցիայի թեման, և մարդիկ հետաքրքրված են տարբեր տեղեկատվությունների կիսվելով՝ սկսած նոր դեպքերից, առողջապահության ուղղություններից, դեղերից և պատվաստանյութերից: Այս տեղեկատվությունը օգնում է մարդկանց վերականգնել իրավիճակի մասին, ինչպես նաև օգտակար հանրային անձնակազմի համար որոշումների կայացման համար: Այնուամենայնիվ, թվիթերի ոչ տեղեկատվական բնույթը դժվարանում է բարելավել տեղեկատվական թվիթերը հսկայական թվիթերի հոսքերից: Այս մարտահրավերներին լուծելու համար ԱՄՆԹ-2020-ը ներկայացրեց մի ընդհանուր խնդիր, որը կենտրոնացրեց COVID-19-ի հետ կապված ինֆորմատիվ թվիթերի հայտնաբերման վրա: Այս աշխատանքում մենք նկարագրում ենք մեր մասնակցությունը այս խնդրում: Մենք առաջարկում ենք նյարդային մոդել, որը ընդունում է փոխանցման ուսումնասիրության ուժը և ձեռագործ հատկությունները միավորված ճարտարապետության մեջ: Հաշվի առնելու ուսուցման առանձնահատկությունները մենք օգտագործում ենք վերջին տեխնոլոգիական նախապատրաստված նախադասությունները, որոնք ներառում են BER, ROBERta և ԻնֆերՍենt մոդելը, մինչդեռ տարբեր թվիթերի առանձնահատկությունները օգտագործվում են ձեռագործված առանձնահատկություն Հաջորդ, տարբեր հատկանիշների համադրությունները օգտագործվում են բազմաշերտ ընկալման (MLP) մի շարք որպես հիմնական դասակարգիչ: Finally, a majority voting based fusion approach is employed to determine the informative tweets.  Մեր մոտեցումը հասավ մրցակցության արդյունքներին և 7 տոկոսով գերազանցեց հիմքը:', 'bn': 'কোভিড-১৯ প্যানেডিম টুইটারে ধারাবাহিক বিষয়ে পরিণত হয়েছে এবং মানুষ নতুন ক্ষেত্র, স্বাস্থ্য সেবা নির্দেশ, মেডিক এবং ব্যাক্সিনের সং এই ধরনের তথ্য জনগণকে এই পরিস্থিতি সম্পর্কে আপডেট করার সাহায্য করে এবং সিদ্ধান্ত নিয়ে জনগণের নিরাপত্তা কর্মকর্তাদে তবে টুইটারের আনুষ্ঠানিক প্রকৃতি বিশাল টুইট প্রবাহ থেকে তথ্যের টুইট পুনরায় চ্যালেঞ্জ করছে। এই চ্যালেঞ্জের সাথে কথা বলার জন্য উইনুট-২০২০ একটি শেয়ার কর্মসূচি প্রকাশ করেছে যা কোভিড-১৯ সম্পর্কিত তথ্য টুইট পরিচয়ের উপর মনো In this paper, we describe our participation in this task.  আমরা একটি নিউরেল মডেল প্রস্তাব করি যা একটি একত্রিত আর্কিটারেক্টারে শিক্ষা এবং হাতের ক্ষমতার শক্তি গ্রহণ করে। ট্রান্সফার্নার শিক্ষার বৈশিষ্ট্য ব্যবহার করার জন্য আমরা পূর্ব-শিল্পের রাষ্ট্রের প্রশিক্ষিত শিক্ষা ব্যবহার করি বিরেট, রোবের্তা এবং ইন্ফারেসেন্ট, যেখানে বিভিন্ পরবর্তীতে বিভিন্ন বৈশিষ্ট্য সম্মিলন ব্যবহার করা হয়েছে বেস-শ্রেণীবিভাগ হিসেবে। অবশেষে, বেশীরভাগ ভোট ভোটের ভিত্তিক ফ্যাশনের পদ্ধতি নির্ধারণ করা হয় তথ্যের টুইট নির্ধারণের জন্য। আমাদের প্রতিযোগিতায় প্রতিযোগিতার প্রতিযোগিতা অর্জন করেছে এবং ৭ শতাংশের মাধ্যমে বেসালাইন প্রদর্শন করেছে।', 'az': 'COVID-19 pandemik twitter üzerində trending məsələsi oldu və insanlar yeni məsələlərdən, sağlam təhsil rəhbər, medicin və vakcinin xəbərləri ilə müxtəlif məlumatları paylaşmaq istəyirlər. Bütün bu məlumatlar insanlara vəziyyət haqqında yenilənməyə və karar vermək üçün halkı təhlükəsizlik müşriklərinə faydalı olmağa kömək edir. Ancaq, twitter olaraq informativ tweetləri böyük tweet akışından təmizlənmək çətin edir. Bu çətinliklərdən çəkinmək üçün WNUT-2020, COVID-19 ilə bağlı informativ tweet kimliğini təsdiqləyən paylaşıb bir işi yaratdı. Bu kağızda, bu işdə işimizi təsdiqləyirik. Biz birləşdirilmiş bir arhitektək içində təkrar öyrənməsinin və əl yaratdığı özelliklərin gücünü istifadə edən nöral modeli təklif edirik. Transfers öyrənməsi fərqlərini çıxartmaq üçün, əl yaratdığı fərqlərini çıxartmaq üçün müxtəlif twitter xüsusiyyətləri istifadə edirik. Sonradan, çoxlu katlı görüntüləri (MLP) təhsil klassificisi olaraq təhsil etmək üçün müxtəlif təhsil kombinatsiyaları istifadə edilir. Sonunda çoxluğu səslənmə dayanan fəsasiya approach informativ tweetləri təyin etmək üçün istifadə edilir. Bizim yaxınlığımız müqayisədi performansı başa düşdü və bu səviyyəni 7% (yaxınlaşdırdı).', 'bs': 'Pandemija COVID-19 postala je trending tema na twitter i ljudi su zainteresovani za dijeljenje različitih informacija od novih slučajeva, uputstva za zdravstvenu pomoć, medicinsku pomoć i vakcinu. Takva informacija pomaže ljudima da se aktualizuju o situaciji, kao i korisno za osoblje za javnu sigurnost u donošenju odluka. Međutim, neformalna priroda twitter izaziva izazov da popravi informativne tweets iz ogromnih potoka tweeta. Za rješavanje tih izazova WNUT-2020, predstavio je zajednički zadatak usredotočen na identifikaciju informativnih tweta povezanih sa COVID-19. U ovom papiru opisujemo naše sudjelovanje u ovom zadatku. Predlažemo neuralni model koji usvoji snagu učenja prijenosa i obrazovanja ruku u ujedinjenoj arhitekturi. Da bi izvukli karakteristike učenja prijenosa, iskoristili smo predobučenu rečenicu koja uključuje model BERT, RoBERTa i InferSent, dok se koriste različite karakteristike twitter kako bi izvukli karakteristike koje su napravljene rukama. Sljedeće, različite kombinacije karakteristika se koriste za obuku set a višeslojnih perceptora (MLP) kao osnovne klasifikacije. Na kraju, većina glasova baziranog na fuziji je zaposlena kako bi utvrdila informativne tweete. Naš pristup je postigao konkurentne učinke i nadmašio početnu liniju za 7% (približno).', 'cs': 'Pandemie COVID-19 se stala trendovým tématem na Twitteru a lidé mají zájem sdílet různé informace od nových případů, pokynů pro zdravotní péči, medicíny a novinky o vakcíny. Tyto informace pomáhají lidem být aktualizovány o situaci a jsou přínosné pro personál veřejné bezpečnosti pro rozhodování. Nicméně neformální povaha twitteru činí náročné upřesnit informační tweety z obrovských tweetových streamů. Pro řešení těchto výzev WNUT-2020 zavedl sdílený úkol zaměřený na identifikaci informačních tweetů souvisejících s COVID-19. V tomto článku popisujeme naši účast na tomto úkolu. Navrhujeme neuronový model, který přijímá sílu transferového učení a ručně vytvořené funkce v jednotné architektuře. K extrakci funkcí přenosového učení využíváme nejmodernější předškolené věty, které obsahují model BERT, RoBERTa a InferSent, zatímco různé charakteristiky twitteru jsou využity k extrakci ručně vytvořených funkcí. Dále jsou využity různé kombinace funkcí k tréninku sady vícevrstvého perceptronu (MLP) jako základního klasifikátoru. Konečně je k určení informačních tweetů použit přístup založený na většinovém hlasování založený na fúzi. Náš přístup dosáhl konkurenčního výkonu a překonal základní hodnotu o 7% (cca.).', 'ca': "La pandèmia COVID-19 s'ha convertit en el tema de tendència en Twitter i la gent està interessata en compartir informació diversa, des de casos nous, directrices sanitàries, medicina i notícies de vacuna. Aquesta informació ajuda a actualitzar la gent sobre la situació i beneficia el personal de seguretat pública en la toma de decisions. Tot i així, la naturalesa informal de Twitter fa difícil refinar els tweets informatius dels grans fluxos de Twitter. To address these challenges WNUT-2020 introduced a shared task focusing on COVID-19 related informative tweet identification.  En aquest paper, descrivim la nostra participació en aquesta tasca. Proposem un model neural que adopti la força de l'aprenentatge de transfer ència i les característiques artificials d'una arquitectura unificada. Per extreure les característiques d'aprenentatge de transfer ència, utilitzem el model BERT, RoBERTa i InferSent d'incorporació de frases avançades, mentre que diverses característiques de twitter s'explotan per extreure les característiques artificials. Després, s'utilitzen diverses combinacions de característiques per entrenar un conjunt de perceptors multicapes (MLP) com a classificador bàsic. Finalment, s'utilitza un enfocament de fusió basat en votació majoritària per determinar els tweets informatius. El nostre enfocament va aconseguir un rendiment competitiu i va superar la base en un 7% (aproximadament).", 'et': 'COVID-19 pandeemia on muutunud trendikaks teemaks Twitteris ja inimesed on huvitatud mitmekesise teabe jagamisest alates uutest juhtudest, tervishoiu juhistest, meditsiinist ja vaktsiiniuudistest. Selline informatsioon aitab inimestel olukorraga kursis olla ning kasulik avaliku ohutuse töötajatele otsuste tegemiseks. Twitteri mitteametliku olemuse tõttu on aga keeruline täpsustada informatiivseid säutseid tohututest säutsuvoogudest. Nende probleemide lahendamiseks võttis WNUT-2020 kasutusele ühise ülesande, mis keskendus COVID-19-ga seotud informatiivsele säutsu tuvastamisele. Käesolevas dokumendis kirjeldame oma osalust selles ülesandes. Pakume välja närvimudeli, mis võtab ühtses arhitektuuris kasutusele siirdeõppe tugevuse ja käsitsi valmistatud funktsioonid. Ülekandeõppe funktsioonide ekstraheerimiseks kasutame kaasaegset eeltreenitud lause manustamise mudelit BERT, RoBERTa ja InferSent, samas kui käsitsi valmistatud funktsioonide ekstraheerimiseks kasutatakse erinevaid twitteri omadusi. Seejärel kasutatakse erinevaid funktsioonide kombinatsioone, et treenida mitmekihilise perceptroni (MLP) komplekti alusklassifitseerijana. Lõpuks kasutatakse informatiivsete säutsude kindlaksmääramiseks häälteenamusel põhinevat tuumasünteesipõhist lähenemisviisi. Meie lähenemisviis saavutas konkurentsivõimelise tulemuslikkuse ja ületas lähtetaseme ligikaudu 7%.', 'fi': 'COVID-19-pandemiasta on tullut trendikäs aihe Twitterissä ja ihmiset ovat kiinnostuneita jakamaan monipuolista tietoa uusista tapauksista, terveydenhuollon ohjeista, lääkkeistä ja rokotteesta. Tällainen tieto auttaa ihmisiä pysymään ajan tasalla tilanteesta sekä hyödyttää yleistä turvallisuushenkilöstöä päätöksenteossa. Twitterin epävirallinen luonne tekee kuitenkin haastavaksi hioa informatiivisia twiittejä valtavista twiittivirroista. Näiden haasteiden ratkaisemiseksi WNUT-2020 otti käyttöön yhteisen tehtävän, jossa keskitytään COVID-19:een liittyvään informatiiviseen tweetin tunnistamiseen. Tässä artikkelissa kuvailemme osallistumista tähän tehtävään. Ehdotamme neuromallia, joka omaksuu siirtooppimisen vahvuuden ja käsintehtyjen ominaisuuksien yhtenäisessä arkkitehtuurissa. Siirto-oppimisominaisuuksien poimimiseen käytämme huippuluokan esikoulutettuja lauseiden upotusmalleja BERT, RoBERTa ja InferSent, kun taas erilaisia twitter-ominaisuuksia hyödynnetään käsin valmistettujen ominaisuuksien poimimiseen. Seuraavaksi käytetään erilaisia ominaisuusyhdistelmiä kouluttamaan joukko monikerroksisia perceptroneja (MLP) perusluokittelijaksi. Informatiivisten twiittien määrittämiseen käytetään myös enemmistöäänestyspohjaista fuusiolähestymistapaa. Lähestymistapamme saavutti kilpailukykyisen suorituskyvyn ja ylitti lähtötilanteen noin 7 prosentilla.', 'jv': '(COMPLD-19) Informasi luwih bantuan ing wong-wong liya nggawe informasi tentang mruput lan kabèh dumadhi kanggo nggawe gerakan kanggo ngilangno keamanan kamu dhéwé. Nanging, kalih resmi adalah Tuter kuwi nggawe lan kelas kuwi nggawe bagian tiket informasi sing apik dhéwé sing tuwitik. WNUT-2020 Nang pemilih iki, kita ngubah njaluk awak dhéwé ning acara iki Awak dhéwé ngerbahi model sing nyebu nggawe nggawe aturan kuwi nggawe nyimpen karo nganggo manut lan didalat sing ngewehke nggawe Arkita ujaran. Jejaring politenessoffpolite"), and when there is a change ("assertivepoliteness Nyong-ngobro, nganggo kesempatan kanggo nyumbang nggawe gerakan kanggo kuwi tiket informasi. Rasané sing beraksi barêng-barêng nggawe gerakan kanggo ngilangno gerakan sing nggawe 7% (tatarané).', 'sk': 'Pandemija COVID-19 je postala trendovska tema v Twitterju in ljudi zanima izmenjava različnih informacij, od novih primerov, smernic za zdravstveno varstvo, medicine in novic o cepivih. Takšne informacije pomagajo ljudem, da so seznanjeni s položajem in koristne za osebje javne varnosti pri sprejemanju odločitev. Vendar pa je zaradi neformalne narave twitterja zahtevno izboljšati informativne tweete iz ogromnih tokov tweetov. Za reševanje teh izzivov je WNUT-2020 uvedel skupno nalogo, osredotočeno na informativno identifikacijo tvitov, povezano s COVID-19. V tem prispevku opisujemo naše sodelovanje pri tej nalogi. Predlagamo nevronski model, ki sprejme moč transfernega učenja in ročno izdelanih funkcij v enotni arhitekturi. Za pridobivanje funkcij učenja prenosa uporabljamo najsodobnejši vnaprej usposobljeni model vgradnje stavkov BERT, RoBERTa in InferSent, medtem ko so različne značilnosti Twitterja izkoriščene za pridobivanje ročno izdelanih funkcij. Nato se uporabljajo različne kombinacije funkcij za usposabljanje niza večplastnih perceptronov (MLP) kot osnovnega klasifikatorja. Za določitev informativnih tweetov se uporablja fuzijski pristop, ki temelji na večinskem glasovanju. Naš pristop je dosegel konkurenčno uspešnost in presegel osnovno vrednost za približno 7%.', 'ha': "Kayyar COKID-19 ya kasance madaidaita mai sauti a kan Twitter, kuma mutane na son su yi farin su shari da information daban-dabam daga masu sãbuwa, shirin ruwan afya, da madawara da news za'a yi matafiya. Wannan information yana taimakon mutãne da za a ƙara haƙƙin halin da kuma yana da amfani ga mutane na aminci da su yi hukunci. Haƙĩƙa, halin Twitter na kammala shi yana ƙarantar ta kafin tarakin Twitter daga mitandan Twitter mai girma. To, ka yi addu'a ga waɗannan tsummõmi WNUT-2020, ya fara wani aikin da aka yi shirin rabo da shi a kan shaidar na COV-19 masu husũma da labarai na Twitter. Ga wannan karatun, Munã bayyana nasara da shirinmu ga wannan aikin. Tune goyyar da wata misãlin neura wanda ke ɗauki ƙarfin transfer learning da tsarin hannayen da ke samu cikin wani taskacin da aka haɗe. Yana amfani da halin-state-of-the-art pre-tunkuɗe salon da ke ƙunsa da motel BERT, RoBERTA, da Infecent, kuma don a yi amfani da wasu takilaikin Twitter dõmin ka sami tsarin hannayen da hannayen-hannayen. @ action: button Ga ƙarshe, mafiya yawansu ana amfani da hanyoyin fushi a kan karatun misalin kurani dõmin ya ƙayyade Twitter masu labari. Ga hanyõyinMu ya isa ga rabo da yin gaura, kuma ya sami bakwai da 7% (daidai).", 'he': 'פנדמיה COVID-19 הפכה לנושא המטנדינג על טוויטר ואנשים מעוניינים לשתף מידע מגוון מתוך מקרים חדשים, כיוונים לטיפול בריאות, תרופה וחדשות חיסון. מידע כזה עוזר לאנשים להיות מעודכנים על המצב, כמו גם מועיל עבור צוות הבטיחות הציבורית לקבלת החלטות. עם זאת, הטבע הרשמי של טוויטר גורם לזה לאתגר לטיפול את הטוויטרים המידעיים מהזרמים הטוויטרים הענקיים. כדי להתמודד עם האתגרים האלה WNUT-2020 הציג משימה משותפת שמתמקדת על זיהוי טוויט אינפורטיבי קשור COVID-19. בעיתון הזה, אנחנו מתארים את השתתפות שלנו במשימה הזאת. אנו מציעים מודל עצבי שמאמץ את הכוח של הלימוד ההעברה והתכונות בידיים בארכיטקטורה מאוחדת. כדי להוציא את תכונות הלימודים של העברה, אנו משתמשים במשפט המאומן המאומן מראש שמכיל דוגמא BERT, RoBERTa, ואינפרסנט, בעוד תכונות טוויטר שונות ניצלו כדי להוציא את תכונות המאומנות יד. לאחר מכן, שילובים שונים של תכונות משתמשים לאימון קבוצה של פספסטרון רבים שכבות (MLP) בתור מסווג הבסיס. סוף סוף, הגישה המבוססת בהצבעה מרוב משתמשת כדי לקבוע את הטוויטים המידעיים. Our approach achieved competitive performance and outperformed the baseline by 7% (approx.).', 'bo': 'COVID མི་མང་གི་གནས་སྟངས་དང་གནས་སྟངས་སྐོར་གྱི་གསལ་བཤད་འདི་གིས་མི་མང་གི་སྲུང་སྐྱོབ་ཞབས་ཞུགས་པ་ལ་ཕན་ཚུལ་བསྐྱེད་བཅུག ཡིན་ནའང་། དྲ་དམངས་ཀྱི་རང་བཞིན་སྤྱིར་བཏང་བ་དེ་ནི་་ཆེད་དུ་ཆེ་མཐུན་གྱི་འགོད་བློ་གཏད། གདོང་ལེན་དགོས་པ་འདི་དག་གི་གདོང་ལེན་བྱེད་ནི་WNUT-2020་ཡིས་COVID-19་དང་འབྲེལ་བའི་གནས་ཚུལ་གྱི་tweet identification་དང་མཉམ་སྤྲོད འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོའི་བྱ་འགུལ་འདིའི་ནང་དུ་འགྲེལ་བཤད་ཀྱི་ཡོད། ང་ཚོས་སྐྱེས་པའི་མ་དབུགས་ཅིག་གིས་གཞུང་སྤྲོད་ཀྱི་སྟོབས་ཤུགས་དང་བྲིས་པའི་ཆོས་ཉིད་ཅིག་སྤྲོད་ཀྱི་ཡོད། སྐྱེལ་འདྲེན་གྱི་ཁྱད་ཆོས་གསལ་འདེབས་བྱས་ན་ང་ཚོས་དུས་ཀྱི་གནས་སྟངས་སྔོན་སྒྲིག་ཡོད་པའི་ཚིག་རྣམ་པ་BERT, RoBERTa, and InferSent སྣང་བྱེད་དགོས་མིན་འདུག Next, various feature combinations are utilized to train a set of multilayer perceptron (MLP) as the base-classifier. མཐའ་མར་མ་དེར། གྲངས་ཤིག་གིས་balsུ ར་བརྗོད་བྱེད་པའི་ཆ་ཤས་ཆེ་བ་ཡིན་པས་ཆ་འཕྲིན་ཡིག་གླེང་སྒྲུབ་ ང་ཚོའི་གཟུགས་སྐོར་ནི་དཔལ་འབྱོར་གྱི་བྱ་སྤྱོད་དང་མཐར་7% (approx)བར་མཐུན་རྐྱེན་བྱས་ཡོད།'}
{'en': 'IRLab@IITBHU at WNUT-2020 Task 2 : Identification of informative COVID-19 English Tweets using BERT IRL ab@ IITBHU  at  WNUT -2020 Task 2: Identification of informative  COVID -19  E nglish Tweets using  BERT', 'pt': 'IRLab@IITBHU no WNUT-2020 Tarefa 2: Identificação de Tweets informativos sobre COVID-19 em inglês usando BERT', 'es': 'IRLab @IITBHU en la Tarea 2 del WNUT-2020: Identificación de tuits informativos en inglés sobre COVID-19 mediante BERT', 'ar': 'IRLab @ IITBHU في WNUT-2020 المهمة 2: تحديد التغريدات الإعلامية حول COVID-19 الإنجليزية باستخدام BERT', 'fr': "IRLab @IITBHU à la WNUT-2020 Tâche 2\xa0: Identification des tweets informatifs en anglais sur la COVID-19 à l'aide du BERT", 'ja': 'IRLab @ IITBHU at WNUT -2020タスク2 ： BERTを使用した新型コロナウイルスに関する情報満載の英語ツイートの識別', 'zh': 'WNUT-2020šĽĽ2 IRLab@IITBHU:ÁĒ®BERTÁü•šŅ°šłįCOVID-19ŤčĪŤĮ≠śé®śĖá', 'ru': 'IRLab@IITBHU на WNUT-2020 Задача 2: Идентификация информативных твитов о COVID-19 на английском языке с использованием BERT', 'hi': 'WNUT-2020 टास्क 2 पर IRLab@IITBHU: BERT का उपयोग करके जानकारीपूर्ण कोविड -19 अंग्रेजी ट्वीट्स की पहचान', 'ga': 'IRLab@IITBHU ag WNUT-2020 Tasc 2: Tweetanna Béarla faisnéiseacha COVID-19 a shainaithint ag baint úsáide as BERT', 'ka': 'IRLab@IITBHU WNUT-2020 დავალებში 2: ინფორმატიური COVID-19 ინგლისური Tweets გამოყენებული BERT', 'el': 'IRLab@IITBHU Καθήκον 2: Προσδιορισμός ενημερωτικών Αγγλικών Τουίτ με χρήση του BERT', 'hu': 'IRLab@IITBHU 2. feladat: A COVID-19 angol tweetek azonosítása a BERT segítségével', 'it': 'IRLab@IITBHU Task 2 di WNUT-2020: Identificazione dei tweet informativi in inglese COVID-19 utilizzando BERT', 'lt': 'IRLab@IITBHU WNUT-2020 2 užduotis: informacinių COVID-19 anglų Tweets identifikavimas naudojant BERT', 'kk': 'IRLab@IITBHU WNUT-2020 2- тапсырмасында: BERT қолданылатын мәліметті COVID-19 ағылшын Tweets- тізбегін анықтау', 'mk': 'IRLab@IITBHU - на WNUT-2020 задача 2: Идентификација на информативните COVID-19 англиски твитови користејќи BERT', 'mt': 'IRLab@IITBHU ) fid-WNUT-2020 Task 2: Identifikazzjoni ta’ COVID-19 Tweets bl-Ingliż bl-użu tal-BERT', 'ml': 'IRLab@IITBHU WNUT-2020 ടാസ്ക് 2: BERT ഉപയോഗിച്ച് വിവരങ്ങള്\u200d കോവിഡി-19 ഇംഗ്ലീഷ് ട്വീറ്റുകളെ തിരിച്ചറിയുക', 'ms': 'IRLab@IITBHU - di WNUT-2020 Tugas 2: Pengenalan Tweet Inggeris COVID-19 maklumat menggunakan BERT', 'mn': 'IRLab@IITBHU WNUT-2020 даалгавар 2: мэдээллийн COVID-19 Англи Tweets-ийг BERT ашиглаж', 'no': 'IRLab@IITBHU På WNUT-2020 oppgåve 2: Identifikasjon av informativ COVID-19 engelsk tweets med BERT', 'pl': 'IRLab@IITBHU Zadanie 2: Identyfikacja informacyjnych tweetów w języku angielskim COVID-19 przy użyciu BERT', 'ro': 'IRLab@IITBHU Activitatea 2 a WNUT-2020: Identificarea tweeturilor informative în limba engleză COVID-19 utilizând BERT', 'sr': 'IRLab@IITBHU Na zadatku 2. WNUT-2020: Identifikacija informativnih COVID-19 engleskih Tweets koristeći BERT', 'si': 'IRLab@IITBHU WNOT-2020වැඩේ 2: තොරතුරු COVID-19 ඉංග්\u200dරීසි ට්විට් භාවිත කරන්න පුළුවන් පරීක්ෂණය', 'sv': 'IRLab@IITBHU på WNUT-2020 Uppgift 2: Identifiering av informativa COVID-19 engelska tweets med hjälp av BERT', 'ta': 'IRLab@IITBHU WNUT- 2020 பணி 2: BERT பயன்படுத்தி தகவல் COVID-19 ஆங்கிலத்தை அடையாளம்', 'so': 'IRLab@IITBHU Shaqo 2: Aqoonsiga macluumaadka COVID-19 Ingiriis ee isticmaalaya BERT', 'ur': 'IRLab@IITBHU WNUT-2020 Task 2: Informative COVID-19 English Tweets Identification of BERT using', 'uz': 'IRLab@IITBHU WNUT-2020 Vazifani 2: BERT yordamida haqiqiy COVID-19 Inglizcha Twitterlarni aniqlash', 'vi': 'IRLab@IITBHU Tại Nhiệm vụ W-2020 2: Xác nhận mã nóng cung cấp thông tin COVID-19 người Anh Tweet bằng BERT.', 'bg': 'IRLab@IITBHU Задача 2: Идентифициране на информативни английски туитове с помощта на BERT', 'nl': 'IRLab@IITBHU Task 2: Identificatie van informatieve COVID-19 Engelse Tweets met behulp van BERT', 'hr': 'IRLab@IITBHU na zadatku 2. WNUT-2020: Identifikacija informativnih COVID-19 engleskih Tweets koristeći BERT', 'da': 'IRLab@IITBHU Opgave 2: Identifikation af informative COVID-19 engelske tweets ved hjælp af BERT', 'de': 'IRLab@IITBHU Aufgabe 2: Identifizierung informativer COVID-19 englischer Tweets mittels BERT', 'id': 'IRLab@IITBHU - di WNUT-2020 Tugas 2: Identifikasi informatif COVID-19 Tweets Inggris menggunakan BERT', 'ko': 'IRLab@IITBHUWNUT-2020 Task 2: BERT를 사용한 풍부한 코로나 영어 트윗 인식', 'fa': 'IRLab@IITBHU در کار دوم WNUT-2020: شناسایی از تویت های انگلیسی COVID-19 با استفاده از BERT', 'sw': 'IRLab@IITBHU Katika kazi ya WNUT-2020 2: Kutambulisha taarifa za COVID-19 Kiingereza kwa kutumia Twita za BERT', 'af': 'IRLab@IITBHU by WNUT-2020 Opdrag 2: Identifikasie van informatiewe KOVID-19 Engelske Tweets gebruik BERT', 'tr': 'IRLab@IITBHU WNUT-2020 Görevi 2: informative COVID-19 English Tweets using BERT', 'sq': 'IRLab@IITBHU - në WNUT-2020 Task 2: Identifikimi i informacioneve COVID-19 Tweets angleze duke përdorur BERT', 'hy': 'IRLab@IITBHU  at WNUT-2020 Task 2: Identification of informative COVID-19 English Tweets using BERT', 'am': 'IRLab@IITBHU በWNUT-2020 ስራ 2: BERT በመጠቀም የinformative COVID-19 ኢንጂልኛ ትዊተሮች ማረጋገጥ', 'bn': 'IRLab@IITBHU বিরেট ব্যবহার করে তথ্য সংক্রান্ত কোভিড-১৯ ইংরেজী টুইট ব্যবহার করে পরিচয় করা হয়েছে।', 'az': 'IRLab@IITBHU WNUT-2020 Task 2: informative COVID-19 English Tweets identification of BERT', 'bs': 'IRLab@IITBHU Na zadatku 2. WNUT-2020: Identifikacija informativnih COVID-19 engleskih Tweets koristeći BERT', 'et': 'IRLab@IITBHU WNUT-2020 ülesanne 2: informatiivsete COVID-19 inglise tweetide tuvastamine BERT-i abil', 'ca': 'IRLab@IITBHU La tasca 2 del WNUT-2020: Identificació de Tweets informatius COVID-19 anglès amb BERT', 'cs': 'IRLab@IITBHU Úkol 2: Identifikace informačních COVID-19 anglických tweetů pomocí BERT', 'fi': 'IRLab@IITBHU WNUT-2020 Tehtävä 2: Informatiivisten COVID-19 englanninkielisten twiittien tunnistaminen BERT-menetelmällä', 'ha': 'IRLab@IITBHU QUnicodeControlCharacterMenu', 'sk': 'IRLab@IITBHU na WNUT-2020 Naloga 2: identifikacija informativnih angleških tweetov COVID-19 z uporabo BERT', 'he': 'IRLab@IITBHU במשימה 2 של WNUT-2020: זיהוי של טוויטים אינפורטיביים COVID-19 אנגליים באמצעות BERT', 'bo': 'IRLab@IITBHU - at WNUT-2020 Task 2: Identification of informative COVID-19 English Tweets using BERT', 'jv': 'IRLab@IITBHU checkbox'}
{'en': 'This paper reports our submission to the shared Task 2 : Identification of informative COVID-19 English tweets at W-NUT 2020. We attempted a few techniques, and we briefly explain here two models that showed promising results in tweet classification tasks : DistilBERT and  FastText . DistilBERT achieves a F1 score of 0.7508 on the test set, which is the best of our submissions.', 'es': 'Este documento informa nuestro envío a la Tarea 2 compartida: Identificación de tuits informativos en inglés sobre COVID-19 en W-NUT 2020. Intentamos algunas técnicas y explicamos brevemente dos modelos que mostraron resultados prometedores en las tareas de clasificación de tuits: Distilbert y FastText. Distilbert logra una puntuación de F1 de 0.7508 en el set de pruebas, que es el mejor de nuestros envíos.', 'ar': 'تقدم هذه الورقة تقريرًا عن تقديمنا للمهمة المشتركة 2: تحديد تغريدات COVID-19 باللغة الإنجليزية في W-NUT 2020. لقد حاولنا بعض التقنيات ، ونوضح هنا بإيجاز نموذجين أظهروا نتائج واعدة في مهام تصنيف التغريدات: DistilBERT و FastText . يحقق DistilBERT درجة F1 تبلغ 0.7508 في مجموعة الاختبار ، وهو أفضل ما أرسلناه.', 'fr': 'Ce document rend compte de notre soumission à la tâche partagée 2\xa0: Identification des tweets informatifs en anglais sur la COVID-19 lors du W-NUT 2020. Nous avons essayé quelques techniques, et nous expliquons brièvement ici deux modèles qui ont donné des résultats prometteurs dans les tâches de classification des tweets\xa0: DistilBert et FastText. DistilBert obtient un score F1 de 0,7508 sur le set de test, ce qui est le meilleur de nos soumissions.', 'pt': 'Este artigo relata nossa submissão à tarefa compartilhada 2: identificação de tweets informativos COVID-19 em inglês no W-NUT 2020. Tentamos algumas técnicas e explicamos brevemente aqui dois modelos que mostraram resultados promissores em tarefas de classificação de tweets: DistilBERT e FastText . O DistilBERT atinge uma pontuação F1 de 0,7508 no conjunto de testes, que é o melhor de nossos envios.', 'ja': '本稿では、W - NUT 2020で共有されたタスク2 ：新型コロナウイルス感染症(COVID -19)に関する有益な英語ツイートの識別に関する報告を行います。私たちはいくつかの手法を試みました。ここでは、ツイート分類タスクで有望な結果を示した2つのモデルについて簡単に説明します。DistilBERTとFastTextです。DistilBERTは、テストセットで0.7508のF 1スコアを達成しました。これは当社の提出物の中で最高のものです。', 'zh': '本文报我W-NUT 2020上共享2提交的文件:识信息丰COVID-19英语推文。 吾尝之矣,吾于此略释二推文之分,DistilBERT与FastText。 DistilBERT试集上F1分为0.7508,此吾曹提交之最也。', 'hi': 'यह पेपर साझा कार्य 2 के लिए हमारे सबमिशन की रिपोर्ट करता है: डब्ल्यू-एनयूटी 2020 में जानकारीपूर्ण कोविड -19 अंग्रेजी ट्वीट्स की पहचान। हमने कुछ तकनीकों का प्रयास किया, और हम संक्षेप में यहां दो मॉडलों की व्याख्या करते हैं जो ट्वीट वर्गीकरण कार्यों में आशाजनक परिणाम दिखाते हैं: DistilBERT और FastText। DistilBERT परीक्षण सेट पर 0.7508 का F1 स्कोर प्राप्त करता है, जो हमारे प्रस्तुतियों का सबसे अच्छा है।', 'ru': 'В этой статье сообщается о нашем участии в совместной задаче 2: Выявление информативных твитов на английском языке о COVID-19 на W-NUT 2020. Мы попробовали несколько приемов и кратко объясняем здесь две модели, которые показали многообещающие результаты в задачах классификации твитов: DistilBERT и FastText. DistilBERT достигает F1 0,7508 на тестовом наборе, что является лучшим из наших представлений.', 'ga': 'Tuairiscíonn an páipéar seo ár n-aighneacht don Tasc comhroinnte 2: Aithint tweets Béarla faisnéiseach COVID-19 ag W-NUT 2020. Rinneamar iarracht ar chúpla teicníocht, agus mínímid go hachomair anseo dhá mhúnla a léirigh torthaí gealltanais i dtascanna aicmithe tweet: DistilBERT agus FastText . Baineann DistilBERT amach scór F1 de 0.7508 ar an tacar tástála, an ceann is fearr dár n-aighneachtaí.', 'ka': 'ეს დოკუნტი ჩვენი გადაწყვეტილება 2-ზე: ინფორმატიური COVID-19 ინგლისური ტივიტების იდენტიფიკაცია W-NUT 2020-ში. ჩვენ ვიცადეთ რამდენიმე ტექნოგიები, და ჩვენ აქ კითხვა ორი მოდელის განახსნა, რომლებიც გამოჩვენებული შედეგების შედეგების შედეგების შედეგები: DistilBERT და FastText. DistilBERT მიიღება F1 წერტილის 0,7508 წერტილი ტესტის სეტში, რომელიც უფრო დიდი ჩვენი წერტილებებისგან.', 'el': 'Αυτή η εργασία αναφέρει την υποβολή μας στο κοινό έργο 2: Προσδιορισμός ενημερωτικών αγγλικών tweets στο W-NUT 2020. Προσπαθήσαμε μερικές τεχνικές και εξηγούμε εν συντομία δύο μοντέλα που έδειξαν ελπιδοφόρα αποτελέσματα σε εργασίες ταξινόμησης tweet: DistilBERT και FastText. Η DistilBERT επιτυγχάνει βαθμολογία F1 0.7508 στο σετ δοκιμής, η οποία είναι η καλύτερη από τις υποβολές μας.', 'kk': 'Бұл қағаз біздің 2- ортақ тапсырмаға жіберімізді хабарлады: мәліметті COVID- 19 ағылшын тійткелерін W- NUT 2020 жылы анықтау. Біз бірнеше техникалық тапсырмаларды көрдік, және осы жерде екі модель түсіндіреді, бұл tweet классификациясының нәтижесін көрсетеді: DistilBERT және FastText. DistilBERT сынақтағы 0,7508 F1 нүктесін жеткізеді. Бұл біздің жіберіміздің ең жақсы нүктесі.', 'hu': 'Ez a tanulmány a közös feladat 2: Információs COVID-19 angol tweetek azonosítása a W-NUT 2020-on. Megpróbáltunk néhány technikát, és röviden elmagyarázunk két modellt, amelyek ígéretes eredményeket mutattak a tweet osztályozási feladatokban: DistilBERT és FastText. A DistilBERT F1 pontszámot ér el a tesztkészleten, ami a legjobb pályázatunk.', 'ms': 'Kertas ini melaporkan penghantaran kita ke Tugas 2 berkongsi: Pengenalan tweet bahasa Inggeris COVID-19 pada W-NUT 2020. Kami cuba beberapa teknik, dan kami menjelaskan secara singkat di sini dua model yang menunjukkan keputusan yang berjanji dalam tugas kelasukan tweet: DistilBERT dan FastText. DistilBERT mencapai skor F1 0.7508 pada set ujian, yang merupakan yang terbaik daripada tunjukan kami.', 'it': 'Questo articolo riporta la nostra presentazione al Task 2 condiviso: Identificazione dei tweet informativi in inglese COVID-19 a W-NUT 2020. Abbiamo provato alcune tecniche, e qui spieghiamo brevemente due modelli che hanno mostrato risultati promettenti nelle attività di classificazione dei tweet: DistilBERT e FastText. DistilBERT ottiene un punteggio F1 di 0,7508 sul set di test, che è il migliore dei nostri contributi.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ പങ്കുചേര്\u200dന്ന ടാസ്ക് 2-ലേക്ക് ഞങ്ങളുടെ സന്ദേശം റിപ്പോര്\u200dട്ട് ചെയ്യുന്നു ഞങ്ങള്\u200d കുറച്ച് ടെക്നിക്കേഷനുകള്\u200d ശ്രമിച്ചു. അപ്പോള്\u200d ഇവിടെ വ്യക്തമാക്കുന്നു രണ്ടു മോഡലുകള്\u200d, വാഗ്ദാനം നല്\u200dകുന്ന രണ്ട് ടൂട്ടില്\u200d ക് ഡിസ്റ്റില്\u200dബെര്\u200dട്ട് പരീക്ഷണസെറ്റില്\u200d ഒരു F1 സ്കോര്\u200d പ്രാപിക്കുന്നു. അതാണ് നമ്മുടെ കീഴടങ്ങളില്\u200d ഏറ്റവും നല്ലത്.', 'mt': 'Dan id-dokument jirrapporta s-sottomissjoni tagħna lill-Kompitu Konġunt 2: Identifikazzjoni ta’ tweets informativi COVID-19 Ingliż fil-W-NUT 2020. Aħna ppruvajna ftit tekniki, u hawnhekk nispjegaw fil-qosor żewġ mudelli li wrew riżultati promettenti f’kompiti ta’ klassifikazzjoni tat-tweet: DistilBERT u FastText. DistilBERT tikseb punteġġ F1 ta’ 0.7508 fuq is-sett tat-test, li huwa l-a ħjar mis-sottomissjonijiet tagħna.', 'lt': 'Šiame dokumente pranešama apie mūsų pranešimą bendrai 2 uždavinei: informacinių COVID-19 anglų tweetų identifikavimas W-NUT 2020. We attempted a few techniques, and we briefly explain here two models that showed promising results in tweet classification tasks: DistilBERT and FastText.  DistilBERT pasiekia 0,7508 F1 rezultatą bandymų rinkinyje, kuris yra geriausias mūsų teiginys.', 'pl': 'Niniejszy artykuł przedstawia nasze zgłoszenie do wspólnego Zadania 2: Identyfikacja informacyjnych tweetów COVID-19 angielskich na W-NUT 2020. Próbowaliśmy kilku technik i krótko wyjaśniliśmy tutaj dwa modele, które wykazały obiecujące rezultaty w zadaniach klasyfikacji tweetów: DistilBERT i FastText. DistilBERT osiąga wynik F1 0.7508 na zestawie testowym, który jest najlepszym z naszych zgłoszeń.', 'mk': 'Овој документ го известува нашето поднесување на заедничката задача 2: Идентификација на информативните Твитови на КоВИД-19 англиски на W-NUT 2020. Пробавме неколку техники, и кратко објаснуваме два модели кои покажаа ветувачки резултати во задачите за класификација на Твитер: DistilBERT и FastText. DistilBERT постигна оценка F1 од 0,7508 на тестот, што е најдоброто од нашите поднесувања.', 'ro': 'Această lucrare raportează transmiterea noastră la sarcina partajată 2: Identificarea tweeturilor informative în limba engleză COVID-19 la W-NUT 2020. Am încercat câteva tehnici și explicăm pe scurt aici două modele care au arătat rezultate promițătoare în sarcinile de clasificare a tweet-urilor: DistilBERT și FastText. DistilBERT obține un scor F1 de 0.7508 pe setul de test, care este cel mai bun dintre depunerile noastre.', 'sr': 'Ovaj papir prijavljuje naše podnošenje zajedničkom zadatku 2: Identifikacija informativnih tviteta COVID-19 engleskog jezika na W-NUT 2020. Pokušali smo nekoliko tehnika, i ovde kratko objašnjavamo dva modela koji su pokazali obećavajuće rezultate u zadatkima klasifikacije tweet a: DistilBERT i FastText. DistilBERT postiže rezultat F1 od 0,7508 na testu, što je najbolji od naših podataka.', 'mn': 'Энэ цаас бидний хуваалцах 2-р даалгаврыг харуулж байна: мэдээллийн COVID-19 Англи хэлний tweets тодорхойлолт W-NUT 2020 онд. Бид хэд хэдэн технологиудыг оролдсон. Бид энд tweet хуваалцааны даалгаварын үр дүнг харуулсан хоёр загварыг тодорхойлдог. DistilBERT болон FastText. DistilBERT шалгалтын багтаа 0.7508 F1 оноо гарч ирнэ. Энэ бол бидний хамгийн сайн шалгалт.', 'no': 'Denne papiret rapporterer vårt oppføring til delt oppgåve 2: Identifikasjon av informativ COVID-19 engelsk tweets på W-NUT 2020. Vi prøvde nokre teknikk, og vi forklarer kort her to modeller som viste promiserende resultat i tweet- klassifikasjonar: DistilBERT og FastText. DistilBERT oppnår eit F1- poeng med 0,7508 på testsettet, som er det beste av våre tilsendingar.', 'ta': 'இந்த தாள் எங்கள் பகிர்ந்த செயல் 2 க்கு அனுப்புவதை அறிக்கிறது: விவரமான COVID-19 ஆங்கிலத்தின் தெரியும் குறிப்புகளை W-NUT நாங்கள் சில தொழில்நுட்பம் முயற்சித்தோம், இங்கு நாம் சுறிதாக விளக்குகிறோம். நம்முடைய வாக்குறுதியான இரண்டு மாதிரிகள் இருக்க DistilBERT ஒரு F1 மதிப்பு 0. 7508 பெறுகிறது, சோதனை அமைப்பில், அது எங்கள் கீழ்படிகளில் சிறந்தது.', 'sv': 'Denna uppsats rapporterar vårt bidrag till den delade uppgiften 2: Identifiering av informativa COVID-19 engelska tweets på W-NUT 2020. Vi försökte några tekniker, och vi förklarar kortfattat här två modeller som visade lovande resultat i tweet klassificering uppgifter: DistilBERT och FastText. DistilBERT uppnår en F1 poäng på 0,7508 på testset, vilket är det bästa av våra bidrag.', 'ur': 'یہ کاغذ ہمیں شریک ٹاکس ۲ کے بارے میں ہماری تحویل سناتی ہے: معلومات COVID-19 انگلیسی ٹویٹ کی شناسایی W-NUT 2020 میں۔ ہم نے تھوڑی تکنیک کی کوشش کی، اور ہم نے یہاں دو موڈل کو تھوڑی دفعہ بتایا جو ٹویٹ کلاسیک کے کاموں میں وعدہ کا نتیجہ دکھایا تھا: DistilBERT اور FastText. DistilBERT آزمائش سٹ پر 0.7508 کی F1 اسکو پہنچاتا ہے، جو ہمارے مسلمانوں میں سے بہترین ہے.', 'so': 'Warqaddan ayaa warqaddayada u soo diraya shaqo 2: Aqoonsiga macluumaadka COVID-19 Ingiriiska ee W NUT 2020. Waxaan isku daynay in dhawr qalabka ah, halkan si fudud ayaannu u caddaynaynaa laba tusaalood oo ballan ku leh, waxayna ka heli jireen shaqaalaha fasaxa ee tweetka: DistilBERT iyo FastText. DistilBERT wuxuu helaa koox F1 oo ku yaal 0.7508 imtixaanka, kaas oo ugu wanaagsan dhiiggayada.', 'si': 'මේ පැත්තේ අපේ පිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිප අපි පරීක්ෂණය කිහිපයක් කළා, අපි මෙතන ප්\u200dරශ්නයක් දෙන්න පුළුවන් විදිහට ප්\u200dරශ්නයක් තියෙන්නේ ට්විට් විශේෂණ වැ Distil BERT පරීක්ෂණ සෙට් එකේ F1 ප්\u200dරමාණයක් 0.7508 ක් තියෙනවා, ඒක තමයි අපේ පරීක්ෂණයේ හොඳම ප්\u200dරමාණයක්.', 'uz': "Bu qogʻoz bilan birlashtirilgan Vazifani 2 bilan joʻnatishni taʼrif qiladi: W-NUT 2020 yilda maʼlumot COVID-19 Inglizcha tweetini aniqlash. Biz bir necha texnologiyani urinib ko'rib chiqqamiz va bu yerda ikkita modellarni yaxshi ko'rsatib beramiz. Twitt tafsilotlarini bajarish natijalariga ishlatish natijalarini ko'rsatadi: DistilBERT va FastText. Name", 'vi': 'Tờ giấy này báo cáo sự đệ trình của chúng ta đến Nhiệm vụ chung 2: Xác nhận thông tin COVID-19 tiếng Anh ở W-Giờ 2020. Chúng tôi đã thử vài kỹ thuật, và giải thích ngắn gọn ở đây hai mẫu đã cho thấy kết quả hứa hẹn trong các nhiệm vụ cấp hạng trên trên: DislBERT và FastbText. Xuất hiện một điểm F1 của 0.7508 trong nhóm thử nghiệm, là phần tốt nhất của chúng ta.', 'nl': 'Deze paper rapporteert onze inzending aan de gedeelde Taak 2: Identificatie van informatieve COVID-19 Engelse tweets op W-NUT 2020. We hebben een paar technieken geprobeerd, en we leggen hier kort twee modellen uit die veelbelovende resultaten lieten zien in tweet classificatietaken: DistilBERT en FastText. DistilBERT behaalt een F1 score van 0.7508 op de testset, wat de beste van onze inzendingen is.', 'bg': 'Настоящата статия докладва за нашето представяне на споделената задача 2: Идентифициране на информативни английски туитове на В-НУТ 2020. Опитахме няколко техники и накратко обяснихме тук два модела, които показаха обещаващи резултати в задачите за класификация на туитове: DistilBERT и FastText. ДистилБЕРТ постига резултат от 0,7508 на тестовия комплект, което е най-доброто от нашите предложения.', 'da': 'Dette papir rapporterer vores indsendelse til den delte opgave 2: Identifikation af informative COVID-19 engelske tweets på W-NUT 2020. Vi forsøgte nogle teknikker, og vi forklarer kort her to modeller, der viste lovende resultater i tweet klassifikationsopgaver: DistilBERT og FastText. DistilBERT opnår en F1 score på 0,7508 på testsættet, hvilket er det bedste af vores indsendelser.', 'hr': 'Ovaj papir prijavljuje naše podatke zajedničkom zadatku 2: Identifikacija informativnih tviteta COVID-19 engleskog jezika na W-NUT 2020. Pokušali smo nekoliko tehnika, i ovdje kratko objašnjavamo dva modela koji su pokazali obećavajuće rezultate u zadatkima klasifikacije tweet a: DistilBERT i FastText. DistilBERT postiže rezultat F1 od 0,7508 na testu, što je najbolji od naših podataka.', 'de': 'Dieses Papier berichtet über unsere Einreichung zur gemeinsamen Aufgabe 2: Identifizierung informativer COVID-19 englischer Tweets auf der W-NUT 2020. Wir versuchten einige Techniken und erläutern hier kurz zwei Modelle, die vielversprechende Ergebnisse bei der Tweet-Klassifizierung zeigten: DistilBERT und FastText. DistilBERT erreicht am Testset eine F1-Punktzahl von 0.7508, die die beste unserer Einsendungen ist.', 'id': 'This paper reports our submission to the shared Task 2: Identification of informative COVID-19 English tweets at W-NUT 2020.  Kami mencoba beberapa teknik, dan kami menjelaskan secara singkat di sini dua model yang menunjukkan hasil yang berjanji dalam tugas klasifikasi tweet: DistilBERT dan FastText. DistilBERT achieves a F1 score of 0.7508 on the test set, which is the best of our submissions.', 'ko': '본고는 우리가 W-NUT 2020에 제출한 공유 임무 2: 정보가 풍부한 코로나 영어 트윗을 식별하는 것을 보고한다.우리는 몇 가지 기술을 시도했고 트위터 분류 작업에서 희망적인 결과를 나타내는 두 가지 모델인 DistilBERT와FastText를 간략하게 설명했다.DistilBERT의 시험집 F1 성적은 0.7508로 우리가 제출한 가장 좋은 성적이다.', 'fa': 'این کاغذ گزارش داده است که فرستادن ما به کار مشترک ۲: شناسایی توئیت های اطلاعاتی COVID-۱۹ انگلیسی در W-NUT ۲۰۰۲ است. ما چند تکنولوژی را سعی کردیم، و به کوتاه در اینجا دو مدل توضیح دادیم که نتیجه\u200cهای قول\u200cدهنده را در کار\u200cهای گروه\u200cشناسی توئیت نشان دادند: DistilBERT و FastText. DistilBERT یک نمونه F1 از 0.7508 در مجموعه آزمایش رسیده است که بهترین نمونه\u200cهای ما است.', 'sw': 'Gazeti hili linaripoti ujumbe wetu wa kazi hiyo 2: Kutambulisha twiti za taarifa za COVID-19 za Kiingereza kwenye mtandao wa W-NUT 2020. Tulijaribu mbinu chache, na tunaeleza kwa muda mfupi hapa mifano miwili ambayo ilionyesha matumaini makubwa ya matokeo ya usambazaji wa twita: DistilBERT na FastText. DistilBERT anafanikiwa score ya F1 ya 0.7508 kwenye seti ya jaribio, ambayo ni bora zaidi ya mawasiliano yetu.', 'tr': "Bu kagyz biziň gönderişimizi paylaşdyrylýan zada 2-nji bardyr: informative COVID-19 Iňlisçe tweets Identification of W-NUT 2020'de. Biz birnäçe teknikler bardyk we bu ýerde birnäçe nusgalary tuýt klasifikasyonuň netijesini görkezilýän iki nusgalary azaltdyk: DistilBERT we FastText. DistilBERT testiň setinde 0,7508 depesini tapýar. Bu biziň gönderişimiziň iň gowydyr.", 'af': "Hierdie papier rapporteer ons onderskrywing aan die gedeelde taak 2: Identifikasie van informatiewe KOVID-19 Engelske tweets by W-NUT 2020. Ons probeer 'n paar teknike, en ons verduidelik hier kort twee modele wat beloftende resultate vertoon het in tweet klassifikasie opdragte: DistilBERT en FastText. DistilBERT bereik 'n F1 punt van 0. 7508 op die toets stel, wat is die beste van ons onderhouers.", 'sq': 'Ky dokument raporton paraqitjen tonë në detyrën e përbashkët 2: Identifikimi i tweeteve informative COVID-19 angleze në W-NUT 2020. U përpoqëm të bëjmë disa teknika, dhe shkurt shpjegojmë këtu dy modele që treguan rezultate premtuese në detyrat e klasifikimit të tweetit: DistilBERT dhe FastText. DistilBERT arrin një rezultat F1 prej 0.7508 në grupin e testit, i cili është më i miri nga paraqitjet tona.', 'am': 'ይህች ገጽ ለስራ 2 የተካፈሉት መልዕክታችንን ይጠብቃል፤ በW-NUT 2020 የኢንግሊዝኛ መረጃ COVID-19 በትዊተሮችን ማረጋገጥ፡፡ We attempted a few techniques, and we briefly explain here two models that showed promising results in tweet classification tasks: DistilBERT and FastText.  DistilBERT የሞከሩ ቁጥር 0.7508 ነጥብ አግኝቷል፤ ይህም ከታዛዦቻችን በላጭ ነው።', 'hy': "Այս փաստաթղթին հայտարարում է մեր ներկայացումը 2-րդ հանձնարարությանը' տեղեկատվական COVID-19 անգլերենի թվիթերի հայտնաբերումը W-NOT 2020-ում: Մենք փորձեցինք մի քանի տեխնիկա և կարճ բացատրեցինք երկու մոդելներ, որոնք ցույց տվեցին խոստացնող արդյունքներ թվիթերի դասակարգման խնդիրներում' ԴիստիլԲերթ և արագ տեքստ: ԴիստիլԲերթը ստանում է 0.758 ֆ-1 գնահատականը փորձարկումների ընթացքում, որը մեր ամենալավ ներկայացումներից է:", 'az': 'Bu kağıt bizim paylaşılmış işimizin 2-ini bildirir: informativ COVID-19 İngilizə tweets kimliğini W-NUT 2020-də bildirir. Biz bir neçə tekniklərə çalışdıq, və burada iki modeli a çıqladıq ki, tweet klasifikasiyasının sonuçlarını göstərdi: DistilBERT və FastText. DistilBERT sınama qutusunda 0,7508 f1 nöqtəsini tapır, bu bizim göndərməklərimizin ən yaxşısıdır.', 'bn': 'এই পত্রিকাটি আমাদের প্রতিবেদন প্রদান করেছে যে আমাদের শেয়ার কর্মসূচি ২: ওয়াই-এনউট ২০২০ এ তথ্য প্রকাশিত কোভিড-১৯ ইংরেজ আমরা কয়েকটি প্রযুক্তি চেষ্টা করেছিলাম, আর আমরা সামান্যে এখানে ব্যাখ্যা করি দুটি মডেল যা প্রতিশ্রুতি দেখিয়েছিল টুইট বিভাগের কাজ:  ডিস্টিলিবার্ট পরীক্ষার সেটে ০. ৭৫৮ স্কোর অর্জন করেছে, যা আমাদের আত্মসমর্পণের সবচেয়ে ভাল।', 'ca': 'Aquest paper relata la nostra presentació a la Task 2 compartida: Identificació de tweets informatius COVID-19 anglès a W-NUT 2020. Vam intentar unes quantes tècniques i vam explicar breument dos models que mostraven resultats prometedors en tasques de classificació de tweet: DistilBERT i FastText. DistilBERT aconsegueix una puntuació F1 de 0,7508 en el conjunt de provas, que és la millor de les nostres presentacions.', 'cs': 'Tento článek nahlásí naše podání na sdílený úkol 2: Identifikace informativních anglických tweetů COVID-19 na W-NUT 2020. Vyzkoušeli jsme několik technik a stručně zde vysvětlíme dva modely, které ukázaly slibné výsledky v klasifikaci tweetů: DistilBERT a FastText. DistilBERT dosahuje F1 skóre 0,7508 na testovací sadě, což je nejlepší z našich příspěvků.', 'et': 'Käesolevas dokumendis kirjeldame meie esitamist jagatud ülesandele 2: informatiivsete COVID-19 inglise säutsude tuvastamine W-NUT 2020. Proovisime mõnda tehnikat ja selgitame siin lühidalt kahte mudelit, mis näitasid tõotavaid tulemusi tweetide klassifitseerimise ülesannetes: DistilBERT ja FastText. DistilBERT saavutab testikomplektis F1 skoori 0,7508, mis on parim meie ettepanekutest.', 'fi': 'Tﾃ､mﾃ､ artikkeli raportoi osallistumisestamme jaettuun tehtﾃ､vﾃ､ﾃ､n 2: Informatiivisten COVID-19 englanninkielisten twiittien tunnistaminen osoitteessa W-NUT 2020. Kokeilimme muutamia tekniikoita ja selitﾃ､mme tﾃ､ssﾃ､ lyhyesti kaksi mallia, jotka osoittivat lupaavia tuloksia tweettiluokitustehtﾃ､vissﾃ､: DistilBERT ja FastText. DistilBERT saavuttaa F1-pisteen 0,7508 testisarjassa, mikﾃ､ on paras tarjouksistamme.', 'bs': 'Ovaj papir prijavljuje naše podatke zajedničkom zadatku 2: Identifikacija informativnih tviteta COVID-19 engleskog jezika na W-NUT 2020. Pokušali smo nekoliko tehnika, i ovdje kratko objašnjavamo dva modela koji su pokazali obećavajuće rezultate u zadatkima klasifikacije tweet a: DistilBERT i FastText. DistilBERT postiže rezultat F1 od 0,7508 na testu, što je najbolji od naših podataka.', 'ha': "@ info: status Ga mu jarrabi masu akan takwai, kuma mu bayyana a nan, misãlai biyu, waɗanda suka yi wa'adi da ake yi wa'adi da su ƙara cikin aikin tsãrawa na Twitter: DistilBERT da FastText. DistilBERT yana samun F1 ko'ar 0.750 8 a kan jarraba, wannan ne mafi kyaun musuluntu.", 'he': 'העיתון הזה מדווח על ההעברה שלנו למשימה המשותפת 2: זיהוי של טוויטים אינפורטיביים COVID-19 אנגליים ב-W-NUT 2020. ניסינו כמה טכניקות, ואנחנו מסבירים בקצרה כאן שני דוגמנים שהראו תוצאות מבטיחות בתפקידים מסווגים של טוויט: DistilBERT ומהיר טקסט. דיסטילברט משיג נקודת F1 של 0.7508 על קבוצת הבדיקות, שזה הטוב ביותר משלנו.', 'jv': 'Perintah sing berarti ning beraksi kita nggawe task 2: Sistem usul karo informasi COMPID-19 Tuts Inggris nang w-NUT 2020 Awak dhéwé ngewat dhéwé ngerasakno teknik, lan kéné ngomong ngerasakno iki model sing bisa nyenengaké basa sing nyenengaké nggambar barang tuwit: DistilBERT lan fast tText. DistilBERT kuwi nggawe punika F1 sing paling 0,75 8 tentang kanggo ujian, sing paling apik dhéwé njaluk sing luwih apik dhéwé.', 'sk': 'Ta prispevek poroča o naši predložitvi skupne naloge 2: identifikacija informativnih angleških tweetov COVID-19 na W-NUT 2020. Poskusili smo nekaj tehnik in tukaj na kratko pojasnili dva modela, ki sta pokazala obetavne rezultate pri klasifikaciji tweetov: DistilBERT in FastText. DistilBERT doseže rezultat F1 0,7508 na testnem kompletu, kar je najboljši izmed naših prispevkov.', 'bo': 'ཤོག ང་ཚོས་ལག་རྩལ་བ་དག་ཙམ་འབྱུང་བ་དེ་ལས། འུ་ཅག་གིས་འདིར་གསལ་བཤད་ཀྱི་མིག DistilBERT ལྟར་བརྟག་ཞིབ་ཀྱི་ཚད་འཛིན་གྱི་ཚད་ལྡན་སྔར་7508 ལས་ཚོད་རྐྱེན་བྱེད།'}
{'en': 'DSC-IIT ISM at WNUT-2020 Task 2 : Detection of COVID-19 informative tweets using RoBERTa DSC - IIT   ISM  at  WNUT -2020 Task 2: Detection of  COVID -19 informative tweets using  R o BERT a', 'ar': 'DSC-IIT ISM في WNUT-2020 المهمة 2: الكشف عن التغريدات الإعلامية لـ COVID-19 باستخدام RoBERTa', 'es': 'DSC-IIT ISM en la Tarea 2 del WNUT-2020: Detección de tuits informativos de COVID-19 con RobErta', 'pt': 'DSC-IIT ISM no WNUT-2020 Tarefa 2: Detecção de tweets informativos COVID-19 usando RoBERTa', 'fr': "DSC-IIT ISM à la WNUT-2020 Tâche 2\xa0: Détection des tweets informatifs COVID-19 à l'aide de Roberta", 'ja': 'WNUT -2020のDSC - IIT ISMタスク2 ： RoBERTaを使用したCOVID -19に関する情報のあるツイートの検出', 'zh': 'DSC-IIT ISMåœ¨WNUT-2020åŠ¡2:ä»¥RoBERTaæ£€COVID-19ä¿¡æŽ¨æ–‡', 'hi': 'WNUT-2020 टास्क 2 में DSC-IIT ISM: RoBERTa का उपयोग करके COVID-19 जानकारीपूर्ण ट्वीट्स का पता लगाना', 'ru': 'DSC-IIT ISM на WNUT-2020 Задача 2: Обнаружение информационных твитов о COVID-19 с использованием RoBERTa', 'ga': 'ISM DSC-IIT ag WNUT-2020 Tasc 2: tweets faisnéiseach COVID-19 a bhrath ag baint úsáide as RoBERTa', 'ka': 'DSC-IIT ISM WNUT-2020 პარამეტრი 2: COVID-19 ინფორმატიური tweets გამოყენებული RoBERTa', 'el': 'Εργασία 2: Ανίχνευση ενημερωτικών tweets με τη χρήση του RoBERTa', 'hu': 'DSC-IIT ISM a WNUT-2020 2. feladat: COVID-19 információs tweetek észlelése RoBERTa segítségével', 'it': 'DSC-IIT ISM a WNUT-2020 Task 2: Rilevamento di tweet informativi COVID-19 utilizzando RoBERTa', 'kk': 'DSC-IIT ISM WNUT-2020 2- тапсырмасында: RoBERTa қолданатын COVID-19 мәліметті tweets табуы', 'lt': 'DSC-IIT ISM WNUT-2020 2 užduotis: COVID-19 informacinių tweetų nustatymas naudojant RoBERTa', 'mk': 'DSC-IIT ISM на WNUT-2020 задача 2: Детектирање на информативни твитови COVID-19 користејќи RoBERTa', 'ml': 'WNUT-2020 ടാസ്ക് 2-ല്\u200d DSC-IIT ISM: റോബെര്\u200dട്ടാ ഉപയോഗിച്ച് കോവിഡ്-19 വിവരങ്ങളുടെ ടൂട്ടുകള്\u200d കണ്ടുപിടിക്കുക', 'mn': 'DSC-IIT ISM WNUT-2020 Task 2: COVID-19 мэдээллийн tweets олох', 'mt': 'DSC-IIT ISM fid-WNUT-2020 Task 2: Detezzjoni ta’ tweets informativi COVID-19 bl-użu ta’ RoBERTa', 'no': 'DSC-IIT ISM på WNUT-2020 Oppgåve 2: Oppdaging av COVID-19 informativ tweet med RoBERTa', 'ms': 'DSC-IIT ISM di WNUT-2020 Tugas 2: Pengesanan tweet maklumat COVID-19 menggunakan RoBERTa', 'pl': 'DSC-IIT ISM na WNUT-2020 Zadanie 2: Wykrywanie tweetów informacyjnych o COVID-19 za pomocą RoBERTa', 'ro': 'DSC-IIT ISM la WNUT-2020 Sarcina 2: Detectarea tweeturilor informative COVID-19 folosind RoBERTa', 'sr': 'DSC-IIT ISM na WNUT-2020 Task 2: Otkrivanje informativnih tweeta COVID-19 koristeći RoBERTu', 'si': 'DSC-IIT ISM at WNuT-2020Job 2: Detection of COVID-19 Infotive tweets use RoBERTa', 'sv': 'DSC-IIT ISM vid WNUT-2020 Uppgift 2: Upptäckt av COVID-19 informativa tweets med RoBERTa', 'so': 'DSC-IIT ISM at WNUT-2020 Task 2: Detection of COVID-19 tweets informative using RoBERta', 'ta': 'WNUT- 2020 பணி 2- ல் DSC- IIT ISM: ரோபெர்டா பயன்படுத்தி COVID-19 தகவல் tweets கண்டறிதல்', 'ur': 'WNUT-2020 ٹاکس 2 میں DSC-IIT ISM: روBERTa کے استعمال سے COVID-19 معلومات ٹویٹ کا تلاش کرنا', 'uz': 'WNUT-2020 Vazifaning DSC-IIT ISM 2: RoBERta yordamida COVID-19 haqida xabari tweetini aniqlash', 'vi': 'Vụ án khủng bố (DSC-II ISM) tại WGiờ-2020 2: Việc phát hiện tweet thông tin về COVID-19 bằng RozerTa', 'hr': 'DSC-IIT ISM na zadatku 2. WNUT-2020: Otkrivanje informativnih tweets COVID-19 koristeći RoBERTu', 'nl': 'DSC-IIT ISM op WNUT-2020 Taak 2: Detectie van COVID-19 informatieve tweets met RoBERTa', 'da': 'DSC-IIT ISM ved WNUT-2020 Opgave 2: Opdagelse af COVID-19 informative tweets ved hjælp af RoBERTa', 'bg': 'Задача 2: Откриване на информативни туитове с помощта на Роберта', 'de': 'DSC-IIT ISM bei WNUT-2020 Aufgabe 2: Erkennung von COVID-19 informativen Tweets mit RoBERTa', 'ko': 'WNUT-2020의 DSC-IIT ISM 태스크2: RoBERTA를 사용한 코로나 메시지 트윗', 'id': 'DSC-IIT ISM di WNUT-2020 Tugas 2: Deteksi tweet informatif COVID-19 menggunakan RoBERTa', 'fa': 'ISM DSC-IIT در Task 2 WNUT-2020: Detection of COVID-19 informative tweets using RoBERTa', 'sw': 'DSC-IIT ISM kwenye kazi ya WNUT-2020 2: Kugundua twiti za taarifa za COVID-19 kwa kutumia RoBERTa', 'tr': 'DSC-IIT ISM at WNUT-2020 Task 2: COVID-19 informative tweets detection of RoBERTa', 'af': 'DSC-IIT ISM by WNUT-2020 Opdrag 2: Opdekking van COVID-19 informatiewe tweets gebruik RoBERTa', 'sq': 'DSC-IIT ISM në WNUT-2020 Task 2: Detection of COVID-19 informative tweets using RoBERTa', 'am': 'ßēĀWNUT-2020 ßłĄßł½ 2:', 'az': 'WNUT-2020 Task 2-də DSC-IIT ISM: RoBERTa vasitəsilə COVID-19 informative tweets keşif', 'hy': 'DSC-IIT ISM-ը World-2020-ի 2. հանձնարարում. COVID-19 ինֆորմատիվ թվիթերի հայտնաբերումը օգտագործելով', 'bn': '২ টি কাজে ডিএসসি-৩ আইএম: রোবের্তা ব্যবহার করে কোভিড-১৯ তথ্য টুইটের সনাক্ত করা হয়েছে', 'bs': 'DSC-IIT ISM na WNUT-2020 zadatku 2: Otkrivanje informativnih tweeta COVID-19 koristeći RoBERTu', 'cs': 'DSC-IIT ISM na WNUT-2020 Úkol 2: Detekce informačních tweetů o COVID-19 pomocí RoBERTa', 'ca': 'DSC-IIT ISM a WNUT-2020 Task 2: Detection of COVID-19 informative tweets using RoBERTa', 'et': 'DSC-IIT ISM WNUT-2020 ülesanne 2: COVID-19 informatiivsete säutsude tuvastamine RoBERTa abil', 'fi': 'DSC-IIT ISM WNUT-2020 -tapahtumassa Tehtävä 2: COVID-19-informatiivisten twiittien havaitseminen RoBERTa:n avulla', 'jv': 'dsC-IAR IsM at WNUT-2020 task 2: detection of COMVD-19 informable bits use RBERT a', 'he': 'DSC-IIT ISM ב-WNUT-2020 משימה 2: גילוי של טוויטים מידעיים COVID-19 באמצעות RoBERTa', 'ha': 'QUnicodeControlCharacterMenu', 'sk': 'DSC-IIT ISM na WNUT-2020 2. naloga: odkrivanje informativnih tvitov COVID-19 z uporabo RoBERTa', 'bo': 'DSC-IIT ISM at WNUT-2020 Task 2: Detection of COVID-19 informative tweets using RoBERTa'}
{'en': 'Social media such as  Twitter  is a hotspot of user-generated information. In this ongoing Covid-19 pandemic, there has been an abundance of data on  social media  which can be classified as informative and uninformative content. In this paper, we present our work to detect informative Covid-19 English tweets using RoBERTa model as a part of the W-NUT workshop 2020. We show the efficacy of our  model  on a public dataset with an  F1-score  of 0.89 on the validation dataset and 0.87 on the  leaderboard .', 'ar': 'تعد الوسائط الاجتماعية مثل Twitter نقطة ساخنة للمعلومات التي ينشئها المستخدم. في جائحة Covid-19 المستمر ، كان هناك وفرة من البيانات على وسائل التواصل الاجتماعي والتي يمكن تصنيفها على أنها محتوى إعلامي وغير إعلامي. في هذه الورقة ، نقدم عملنا لاكتشاف التغريدات المفيدة باللغة الإنجليزية لـ Covid-19 باستخدام نموذج RoBERTa كجزء من ورشة عمل W-NUT 2020. نعرض فعالية نموذجنا على مجموعة بيانات عامة بدرجة F1 تبلغ 0.89 على مجموعة بيانات التحقق و 0.87 على لوحة الصدارة.', 'es': 'Las redes sociales, como Twitter, son un punto de acceso de información generada por los usuarios. En esta pandemia de Covid-19 en curso, ha habido una gran cantidad de datos en las redes sociales que pueden clasificarse como contenido informativo y poco informativo. En este artículo, presentamos nuestro trabajo para detectar tuits informativos en inglés sobre Covid-19 utilizando el modelo RoBerta como parte del taller W-NUT 2020. Mostramos la eficacia de nuestro modelo en un conjunto de datos público con una puntuación F1 de 0.89 en el conjunto de datos de validación y 0.87 en la tabla de clasificación.', 'pt': 'Mídias sociais como o Twitter são um ponto de acesso de informações geradas pelo usuário. Nesta pandemia de Covid-19 em curso, tem havido uma abundância de dados nas mídias sociais que podem ser classificados como conteúdo informativo e não informativo. Neste artigo, apresentamos nosso trabalho para detectar tweets informativos sobre Covid-19 em inglês usando o modelo RoBERTa como parte do workshop W-NUT 2020. Mostramos a eficácia do nosso modelo em um conjunto de dados público com um F1-score de 0,89 no conjunto de dados de validação e 0,87 na tabela de classificação.', 'fr': "Les réseaux sociaux tels que Twitter sont un point névralgique d'informations générées par les utilisateurs. Dans cette pandémie de Covid-19 en cours, il y a eu une abondance de données sur les médias sociaux qui peuvent être classées comme contenu informatif et non informatif. Dans cet article, nous présentons notre travail pour détecter les tweets informatifs en anglais Covid-19 à l'aide du modèle Roberta dans le cadre de l'atelier W-NUT 2020. Nous montrons l'efficacité de notre modèle sur un ensemble de données public avec un score F1 de 0,89 sur l'ensemble de données de validation et de 0,87 sur le classement.", 'ja': 'Twitterなどのソーシャルメディアは、ユーザーが生成した情報のホットスポットです。今回の新型コロナウイルス感染症のパンデミック（世界的大流行）では、ソーシャルメディア上で情報提供コンテンツと非情報提供コンテンツに分類される可能性のある豊富なデータが存在しています。この論文では、W - NUTワークショップ2020の一環として、RoBERTaモデルを使用して情報量の多いCovid -19英語ツイートを検出するための研究を紹介します。検証データセットで0.89、リーダーボードで0.87のF 1スコアを持つ公開データセットで、モデルの有効性を示します。', 'ru': 'Социальные сети, такие как Twitter, являются горячей точкой пользовательской информации. Во время этой продолжающейся пандемии Covid-19 в социальных сетях появилось множество данных, которые можно классифицировать как информативный и неинформативный контент. В этой статье мы представляем нашу работу по обнаружению информативных твитов о Covid-19 на английском языке с использованием модели RoBERTa в рамках семинара W-NUT 2020. Мы показываем эффективность нашей модели на общедоступном наборе данных с баллом F1 0,89 на валидационном наборе данных и 0,87 на таблице лидеров.', 'hi': 'ट्विटर जैसे सोशल मीडिया उपयोगकर्ता-जनित जानकारी का एक हॉटस्पॉट है। इस चल रही कोविद -19 महामारी में, सोशल मीडिया पर डेटा की बहुतायत रही है जिसे जानकारीपूर्ण और असंगत सामग्री के रूप में वर्गीकृत किया जा सकता है। इस पेपर में, हम डब्ल्यू-एनयूटी कार्यशाला 2020 के एक हिस्से के रूप में रोबर्टा मॉडल का उपयोग करके जानकारीपूर्ण कोविद -19 अंग्रेजी ट्वीट्स का पता लगाने के लिए अपना काम प्रस्तुत करते हैं। हम सत्यापन डेटासेट पर 0.89 के F1-स्कोर और लीडरबोर्ड पर 0.87 के साथ एक सार्वजनिक डेटासेट पर हमारे मॉडल की प्रभावकारिता दिखाते हैं।', 'zh': 'Twitter等社交媒体用户生信息之热点也。 其Covid-19大行,社交媒体上多据,可归类信息性无信息性。 于本文,吾将见吾事,以RoBERTa检信富之Covid-19英语推文,以为W-NUT研讨会2020之一。 展模有效性于公共数据集上,验数集上之 F1 分为 0.89,在排行榜为 0.87。', 'ga': 'Lárionad faisnéise a ghineann úsáideoirí is ea na meáin shóisialta ar nós Twitter. Sa phaindéim leanúnach Covid-19 seo, tá flúirse sonraí ar na meáin shóisialta ar féidir iad a rangú mar ábhar faisnéiseach agus neamhfhaisnéiseach. Sa pháipéar seo, cuirimid i láthair ár gcuid oibre chun tvuíteanna Béarla faisnéiseacha Covid-19 a bhrath ag baint úsáide as samhail RoBERTa mar chuid de cheardlann W-NUT 2020. Léirímid éifeachtúlacht ár múnla ar thacar sonraí poiblí le scór F1 de 0.89 ar an tacar sonraí bailíochtaithe agus 0.87 ar an gclár ceannairí.', 'el': 'Τα μέσα κοινωνικής δικτύωσης όπως το Twitter είναι ένα σημείο εστίασης πληροφοριών που παράγονται από τους χρήστες. Σε αυτή τη συνεχιζόμενη πανδημία υπάρχει πληθώρα δεδομένων στα μέσα κοινωνικής δικτύωσης τα οποία μπορούν να χαρακτηριστούν ως ενημερωτικό και μη ενημερωτικό περιεχόμενο. Σε αυτή την εργασία, παρουσιάζουμε την εργασία μας για την ανίχνευση ενημερωτικών tweets στα αγγλικά χρησιμοποιώντας μοντέλο ως μέρος του εργαστηρίου 2020. Δείχνουμε την αποτελεσματικότητα του μοντέλου μας σε ένα δημόσιο σύνολο δεδομένων με βαθμολογία 0.89 στο σύνολο δεδομένων επικύρωσης και 0.87 στον πίνακα κατάταξης.', 'hu': 'A közösségi média, mint például a Twitter, a felhasználók által generált információk hotspot. Ebben a folyamatban lévő Covid-19 járványban rengeteg adat áll rendelkezésre a közösségi médiában, amelyek információs és információtlan tartalomként besorolhatók. Ebben a tanulmányban bemutatjuk az információs Covid-19 angol tweetek felismerésére irányuló munkánkat RoBERTa modellel a W-NUT 2020 workshop részeként. Modellünk hatékonyságát egy nyilvános adatkészleten mutatjuk be, amelynek F1 pontszáma 0,89 a validálási adatkészleten és 0,87 a ranglistán.', 'it': "I social media come Twitter sono un hotspot di informazioni generate dagli utenti. In questa pandemia di Covid-19 in corso, c'è stata un'abbondanza di dati sui social media che possono essere classificati come contenuti informativi e non informativi. In questo articolo, presentiamo il nostro lavoro per rilevare tweet informativi in inglese Covid-19 utilizzando il modello RoBERTa come parte del workshop W-NUT 2020. Mostriamo l'efficacia del nostro modello su un set di dati pubblico con un punteggio F1 di 0,89 sul set di dati di convalida e 0,87 sulla classifica.", 'ka': 'სოციალური მედია, როგორც Twitter არის მომხმარებლის შექმნილი ინფორმაციის სამყარო ადგილი. ამ კოვიდი-19 პანდემიში საზოგადომიური მედიაში მონაცემები იყო, რომელიც შეიძლება იყოს ინფორმატიური და უნფორმატიური ინფორმატიური მხოლოდ. ჩვენ ჩვენი სამუშაოში ჩვენი სამუშაო, რომ ინფორმატიური Covid-19 ინგლისური ტივიტები გამოყენებთ RoBERTa მოდელს როგორც W-NUT სამუშაო 2020-ის ნაწილი. ჩვენ ჩვენი მოდელის ეფექტიურობას ჩვენ ჩვენი მოდელის საზოგადო მონაცემების შესახებ, რომელიც 0,89 წლის F1 წლის შესახებ მონაცემების შესახებ და 0,87 წლის შესახებ.', 'lt': 'Socialinė žiniasklaida, pvz., Twitter, yra vartotojų sukaupta informacija. Šioje vykstančioje 19-ojo pakto pandemijoje buvo daug duomenų apie socialinę žiniasklaidą, kurie gali būti klasifikuojami kaip informacinis ir neinformacinis turinys. Šiame dokumente pristatome savo darbą, skirtą nustatyti informacinius Covid-19 anglų tweetus naudojant RoBERTa model į kaip W-NUT 2020 seminaro dalį. Mes parodome savo modelio veiksmingumą viešame duomenų rinkinyje, kurio F1 rezultatas yra 0,89 patvirtinimo duomenų rinkinyje ir 0,87 vadovaujančioje lentelėje.', 'ms': 'Media sosial seperti Twitter adalah titik panas maklumat yang dijana oleh pengguna. Dalam pandemi Covid-19 ini, terdapat banyak data pada media sosial yang boleh diklasifikasi sebagai kandungan maklumat dan tidak maklumat. Dalam kertas ini, kami memperkenalkan kerja kami untuk mengesan tweet bahasa Inggeris Covid-19 yang maklumat menggunakan model RoBERTa sebagai sebahagian dari workshop W-NUT 2020. Kami menunjukkan kegunaan model kami pada set data awam dengan skor F1 0.89 pada set data pengesahihan dan 0.87 pada papan utama.', 'ml': 'ടൂട്ടറിനെപ്പോലുള്ള സാമൂഹ്യ മീഡിയ ഒരു ഹോട്ട്സ്പോട്ട് ഉപയോക്താവിന്റെ സൃഷ്ടിച്ച വിവ ഈ പ്രവർത്തിക്കുന്ന കോവിഡ്-19 പേടിയില്\u200d, സാമൂഹിക മീഡിയിലെ വിവരങ്ങളില്\u200d ഒരുപാട് വിവരങ്ങളുണ്ട്. അത് വിവരങ്ങളും വിവരങ്ങളും വ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d വിവരങ്ങള്\u200d കോവിഡ്-19 ഇംഗ്ലീഷ് ടൂട്ടുകള്\u200d കണ്ടുപിടിക്കാന്\u200d വേണ്ടി നമ്മുടെ ജോലി കാണിക്കുന്നു. റോബെര്\u200dട്ട ഞങ്ങള്\u200d നമ്മുടെ മോഡലിന്റെ പൊതു ഡാറ്റാസെറ്റില്\u200d പ്രഭാവം കാണിക്കുന്നു. നേതാവിന്റെ ഡാറ്റാസറ്റില്\u200d 0.89 സ്കോര്\u200d ഉണ്ടായിരു', 'kk': 'Твиттер секілді социалдық медиа - пайдаланушының жасалған мәліметтері. Бұл қазіргі Ковид-19 пандемиясында, социалдық медиақтардың көптеген мәліметті және мәліметті емес мазмұны ретінде классификациялануға болады. Бұл қағазында, біз жұмыстарымызды мәліметті Covid-19 ағылшын тійттерді, RoBERTa моделін W-NUT 2020 жұмысының бір бөлігі ретінде анықтау үшін таңдаймыз. Біз өзіміздің моделіміздің эффектілігін 0,89 деген F1- нәтижесін тексеру деректер жинағында және 0,87 басып шығару жолағында көрсетедік.', 'mt': 'Il-mezzi tax-xandir soċjali bħal Twitter huma punt ċentrali ta’ informazzjoni ġġenerata mill-utent. F’din il-pandemija kontinwa tal-Covid-19, kien hemm abbundanza ta’ dejta dwar il-midja soċjali li tista’ tiġi kklassifikata bħala kontenut informattiv u mhux informattiv. F’dan id-dokument, a ħna nippreżentaw ix-xogħol tagħna biex nidentifikaw tweets informativi bl-Ingliż Covid-19 bl-użu tal-mudell RoBERTa bħala parti mill-workshop W-NUT 2020. Aħna nuru l-effikaċja tal-mudell tagħna fuq sett ta’ dejta pubblika b’punteġġ F1 ta’ 0.89 fuq is-sett ta’ dejta ta’ validazzjoni u 0.87 fuq it-tabella ewlenija.', 'mn': 'Твиттер шиг нийгмийн медиа бол хэрэглэгчийн гаргасан мэдээллийн халуун хэсэг юм. Харин одоогоор байгаа Covid-19 салбарт нийгмийн мэдээллийн мэдээллийн тухай маш олон мэдээллийг мэдээлэл болон мэдээлэл өгөгдлийг хэлж чадна. Энэ цаасан дээр бид мэдээллийн Covid-19 Англи хэлний хувилбаруудыг W-NUT ажлын 2020 оны нэг хэсэг болгон RoBERTa загварын загварыг ашиглаж байгааг илтгэдэг. Бид өөрсдийн загварын үр дүнг олон нийтийн өгөгдлийн сан дээр 0.89-той F1-тоо өгөгдлийн сан дээр харуулж байна, бас 0.87-той удирдагч буудалд байна.', 'mk': 'Социјалните медиуми како што е Твитер е точка на информации генерирани од корисникот. In this ongoing Covid-19 pandemic, there has been an abundance of data on social media which can be classified as informative and uninformative content.  Во овој весник ја претставуваме нашата работа за детектирање информативни Англиски Твитови Ковид-19 користејќи го моделот Роберта како дел од работилницата W-NUT 2020. Ја покажуваме ефикасноста на нашиот модел на јавен податок со резултат F1 од 0,89 на податоците за валидација и 0,87 на водечката табла.', 'pl': 'Media społecznościowe takie jak Twitter to hotspot informacji generowanych przez użytkowników. W tej trwającej pandemii Covid-19 pojawiło się mnóstwo danych w mediach społecznościowych, które można sklasyfikować jako treści informacyjne i nieinformacyjne. W niniejszym artykule przedstawiamy nasze prace nad wykrywaniem informacyjnych tweetów w języku angielskim Covid-19 z wykorzystaniem modelu RoBERTa w ramach warsztatów W-NUT 2020. Pokazujemy skuteczność naszego modelu na publicznym zbiorze danych o wyniku F1 0.89 na zbiorze danych walidacyjnych i 0.87 na tablicy liderów.', 'si': 'ට්විටර් වගේ සාමාජික මාධ්\u200dයමය, ප්\u200dරයෝජකයෙන් නිර්මාණය කරපු තොරතුරු ගැන හොට් පොට මේ සාමාජික මධ්\u200dයමාධ්\u200dයමේ කෝවිඩ්-19 වලින්, සාමාජික මධ්\u200dයමාධ්\u200dයමේ තොරතුරු ගොඩක් තියෙනවා, ඒ වගේම තොරතුරු ස මේ පත්තරේ අපි අපේ වැඩය පෙන්වන්නේ අන්තිමත් කෝවිඩ් 19 ඉංග්\u200dරීසි ට්විට් එක්ක රෝබෙර්ටා මෝඩේල් එක විදිහට W-NAT වැඩස අපි අපේ මොඩල් එකේ ප්\u200dරශ්ණතාව පෙන්වන්නේ සාමාජික දත්ත සෙට් එකේ F1-score 0.89 විශ්වාසයක් තියෙන්නේ නිලධාරිත්වයේ දත්ත සෙ', 'sr': 'Socijalni mediji poput Twitter su vruća tačka informacija od korisnika. U ovoj trenutnoj pandemiji Kovid-19 postoji dosta podataka o društvenim medijima koje se mogu klasifikirati kao informativni i neoinformativni sadržaj. U ovom papiru predstavljamo naš rad kako bi otkrili informativne tvitete Covid-19 engleskog jezika koristeći model RoBERTa kao deo W-NUT radionice 2020. Mi pokazujemo efikasnost našeg model a na javnom setu podataka sa 0,89 rezultata F1 na setu podataka za validaciju i 0,87 na vodećoj tabli.', 'no': 'Sosiale medier som Twitter er eit mellomrom av brukargrende informasjon. I denne gjeldande pandemikk i Covid-19 har det vært mange data på sosiale medier som kan klassifiserast som informativt og uformativt innhald. I denne papiret presenterer vi arbeidet vårt for å finna informativ Covid-19 engelsk tweets med RoBERTa-modell som ein del av W-NUT-arbeidsområdet 2020. Vi viser effektiviteten av modellen vårt på eit offentleg datasett med F1- poeng 0,89 på datasettet for validasjon og 0,87 på lederbordet.', 'so': 'Macluumaadka sooshalka sida Twitterka waa macluumaad hoteed ee isticmaalayaasha. Cudurkaas oo ku soconaya dabid-19 waxaa jiray macluumaad badan oo ku saabsan shabakada bulshada, kaas oo loo kala qaybsan karo macluumaad macluumaad iyo waxyaabo aan la ogayn. Warqadan waxan ku qornaa shaqadeeda si aan u ogaano warqadaha macluumaadka ah ee Covid-19 Ingiriiska oo lagu isticmaalo model RoBERta oo ka mid ah warqadda W-NUT 2020. Tusaalaha sameynta ee shahaadada dadweynaha ku qoran F1-koox 0.89 oo ku saabsan shahaadada xaqiijinta iyo 0.87-ka hogaamiyaha.', 'sv': 'Sociala medier som Twitter är en hotspot med användargenererad information. I denna pågående Covid-19-pandemi har det funnits ett överflöd av data på sociala medier som kan klassificeras som informativt och oinformativt innehåll. I denna uppsats presenterar vi vårt arbete med att upptäcka informativa Covid-19 engelska tweets med RoBERTa-modellen som en del av W-NUT workshop 2020. Vi visar effekten av vår modell på en offentlig datauppsättning med en F1-poäng på 0,89 på valideringsdatauppsättningen och 0,87 på leaderboard.', 'ta': 'தொடர்பு போன்ற சமூக ஊடகங்கள் பயனர் உருவாக்கப்பட்ட தகவலின் வெப்பமான இடத்தில் உள்ளது. இந்த நடக்கும் கோபிட்-19 துக்கத்தில், சமூக ஊடகங்களில் தகவல் மிக அதிகமாக இருந்தது, அது தகவல் மற்றும் அறிவிப்பு மற்றும் தெரியாத உள்ள இந்த காகிதத்தில், நாங்கள் அறிவிப்பு காவிட்-19 ஆங்கிலத்தின் தொடர்புகளை கண்டறிய வேலை கொண்டு இருக்கிறோம். ரோபிர்டா மாதிரி 2020 நாம் எங்கள் மாதிரியின் விளைவை ஒரு பொது தரவுத்தளத்தில் காட்டுகிறோம் ஒரு F1- மதிப்பு 0.89 புள்ளியில் சரிபார்க்கப்படும் தரவுத', 'ro': 'Social media precum Twitter este un hotspot de informații generate de utilizatori. În această pandemie Covid-19 în curs de desfășurare, au existat o abundență de date pe rețelele de socializare care pot fi clasificate ca conținut informativ și neinformativ. În această lucrare, prezentăm activitatea noastră de detectare a tweeturilor informative în limba engleză Covid-19 folosind modelul RoBERTa ca parte a atelierului W-NUT 2020. Aratăm eficacitatea modelului nostru pe un set de date public cu un scor F1 de 0,89 pe setul de date de validare și 0,87 pe clasament.', 'ur': 'سوسیلی میڈیا جیسی ٹویٹر یوسٹر کے پیدا ہوئے معلومات کا ہٹپوٹ ہے۔ اس موقع کی کووید-19 پینڈیمیک میں سوسیل میڈیا پر بہت سی ڈیٹا موجود ہوا ہے جو غیر معلومات اور غیر معلومات کی محتویات کے طور پر classified کر سکتے ہیں. اس کاغذ میں، ہم نے اپنے کام کو W-NUT کارشاپ 2020 کی ایک حصہ کے طور پر روBERTa موڈل کے استعمال کرنے کے لئے اطلاعات کی کووید-19 انگلیسی ٹیوٹ کی تلاش کرنے کے لئے پیش کیا ہے. ہم نے اپنی مدل کی عمدگی کو ایک عمومی ڈیٹ سٹ پر 0.89 کی F1-اسکور کے ساتھ دکھایا ہے اور 0.87 لیڈربورڈ پر۔', 'uz': "Twitterdan jamiyat media huddi foydalanuvchilar yaratilgan maʼlumotlar qismi. Bu davomida Koid-19 pandemiyatda, jamiyat media haqida ko'p maʼlumot maʼlumotlar mavjud. Bu haqida maʼlumot va notormatiy tarkibi deb turli oladi. Bu qogʻozda, biz 2020 Ish stoli bilan RoBERTA modeli bo'yicha haqiqida xabar bo'lgan Twittlarni aniqlash uchun ishimizni hozir qilamiz. Biz modelimizning faqat maʼlumotlar tarkibi 0.89 dan tasdiqlangan maʼlumotlar tizimini va boshqaruvchining 0.87 darajasi bilan ishlayapmiz.", 'vi': 'Mạng xã hội như Twitter là một nơi chứa thông tin từ người dùng. Trong đại dịch Codid-19 hiện tại, đã có rất nhiều dữ liệu về truyền thông xã hội có thể phân loại thành nội dung thông tin và không biết định dạng. Trong tờ báo này, chúng tôi giới thiệu công việc để phát hiện tin tức về Codid-19 Người Anh đã dùng theo kiểu ROBERTa như một phần của xưởng nghiên cứu W-Giờ. Chúng tôi cho thấy hiệu quả của mô hình của chúng tôi trên một bộ dữ liệu công cộng với số F1 trên 0.899 trên bộ dữ liệu xác thực và 0.87 trên bảng xếp hạng.', 'bg': 'Социалните медии като Туитър са гореща точка на генерирана от потребителите информация. В тази продължаваща пандемия има изобилие от данни в социалните медии, които могат да бъдат класифицирани като информативно и неинформативно съдържание. В настоящата статия представяме нашата работа за откриване на информативни английски туитове, използващи модела като част от уъркшопа 2020. Показваме ефикасността на нашия модел върху публичен набор от данни с оценка от 0,89 на набора от данни за валидиране и 0,87 на класацията.', 'nl': 'Sociale media zoals Twitter is een hotspot van door gebruikers gegenereerde informatie. In deze aanhoudende Covid-19 pandemie is er een overvloed aan gegevens op sociale media geweest die kunnen worden geclassificeerd als informatieve en niet-informatieve inhoud. In dit artikel presenteren we ons werk om informatieve Covid-19 Engelse tweets te detecteren met behulp van het RoBERTa model als onderdeel van de W-NUT workshop 2020. We tonen de effectiviteit van ons model op een publieke dataset met een F1-score van 0.89 op de validatie dataset en 0.87 op het leaderboard.', 'hr': 'Društveni mediji poput Twitter su vruća mjesta informacija od korisnika. U ovoj trenutnoj pandemiji Covid-19 postoji dosta podataka o društvenim medijima koje se mogu klasifikirati kao informativni i neoinformativni sadržaj. U ovom papiru predstavljamo naš rad kako bi otkrili informativne tvitete Covid-19 engleskog jezika koristeći model RoBERTa kao dio W-NUT radionice 2020. Mi pokazujemo učinkovitost našeg model a na javnom setu podataka s 0,89 rezultata F1 na setu podataka o validaciji i 0,87 na vodećoj ploči.', 'da': 'Sociale medier som Twitter er et hotspot med brugergenereret information. I denne igangværende Covid-19 pandemi har der været en overflod af data på sociale medier, som kan klassificeres som informativt og uinformeret indhold. I denne artikel præsenterer vi vores arbejde med at opdage informative Covid-19 engelske tweets ved hjælp af RoBERTa-modellen som en del af W-NUT workshop 2020. Vi viser effektiviteten af vores model på et offentligt datasæt med en F1-score på 0,89 på valideringsdatasættet og 0,87 på ranglisten.', 'id': 'Social media such as Twitter is a hotspot of user-generated information.  Dalam pandemia Covid-19 yang sedang berlangsung, ada banyak data di media sosial yang dapat diklasifikasi sebagai konten informatif dan tidak informatif. Dalam kertas ini, kami memperkenalkan pekerjaan kami untuk mendeteksi tweet bahasa Inggris Covid-19 yang informatif menggunakan model RoBERTa sebagai bagian dari workshop W-NUT 2020. Kami menunjukkan efektivitas model kami pada set data publik dengan nilai F1 0,89 pada set data validasi dan 0,87 pada papan pemimpin.', 'ko': '트위터 등 소셜미디어는 사용자가 정보를 생성하는 이슈다.이 계속되는 코로나19 팬데믹(세계적 대유행) 속에서 소셜미디어에는 정보성과 비정보적인 내용으로 나눌 수 있는 데이터가 대거 올라왔다.본고에서 W-NUT workshop 2020의 일환으로 정보가 풍부한 코로나 영어 트윗을 측정하기 위해 RoBERTA 모델을 사용했다.우리는 하나의 공공 데이터 집합에서 우리의 모델의 유효성을 보여 주었다. 검증 데이터 집합에서 F1은 0.89로 나뉘었고 차트에서는 0.87로 나타났다.', 'de': 'Soziale Medien wie Twitter sind ein Hotspot nutzergenerierter Informationen. In dieser anhaltenden Covid-19-Pandemie gibt es eine Fülle von Daten in sozialen Medien, die als informative und uninformative Inhalte klassifiziert werden können. In diesem Beitrag stellen wir unsere Arbeit zur Erkennung informativer Covid-19 englischer Tweets unter Verwendung des RoBERTa-Modells im Rahmen des W-NUT Workshops 2020 vor. Wir zeigen die Wirksamkeit unseres Modells auf einem öffentlichen Datensatz mit einem F1-Score von 0.89 auf dem Validierungsdatensatz und 0.87 auf der Rangliste.', 'af': "Soziale media soos Twitter is 'n hotspot van gebruiker genereerde inligting. In hierdie huidige pandemiek van Covid-19 is daar 'n oorvloedigheid van data op sosiale media wat kan klassifiseer word as informatiewe en oninformatiewe inhoud. In hierdie papier stel ons werk voor om inligtige Covid-19 Engelske tweets te beskry met RoBERTa model as deel van die W-NUT werkshop 2020 te gebruik. Ons wys die effektiviteit van ons model op 'n publieke datastel met' n F1- telling van 0.89 op die geldigheidsaaisel en 0.87 op die lederboard.", 'tr': 'Twitter ýaly sosialy medýdylar, ullançylar tarapyndan ýasalan maglumatyň gaty ýerinde görünýär. Şu wagt içinde Covid-19 pandemiýasynda sosyal medýýatlar ýaly maglumaty we informasiýasy meýdançalar hökmünde görkezilip biljek bol maglumaty bar. Bu kagyzda, biz işimizi informatiýa Covid-19 Iňlis tuýtlaryny RoBERTa nusgasyny W-NUT 2020-nji ýylyň bir parçasynda tapmak üçin sunadyk. Biz nusgamyzyň etkinliýetimizi halk maglumat setinde 0.89-iniň üstünde daýarlyk setinde we 0.87-iniň üstünde daýarlyk setinde görkezilýäris.', 'sw': 'Vyombo vya habari vya kijamii kama vile Twita ni kituo cha habari kinachotengenezwa kwa watumiaji. Katika ugonjwa huu unaoendelea huko Covid-19, kumekuwa na taarifa nyingi kwenye mitandao ya kijamii ambazo zinaweza kutangazwa kama maudhui ya taarifa na yasiyoeleweka. Katika karatasi hii, tunaweka kazi yetu kutambua twiti za habari za Covid-19 za Kiingereza kwa kutumia mifano ya RoBERTa kama sehemu ya warsha ya W-NUT 2020. Tunaonyesha ufanisi wa muundo wetu kwenye seti ya taarifa za umma yenye score ya F1 ya 0.89 kwenye seti ya taarifa zilizothibitishwa na 0.87 kwenye uongozi.', 'fa': 'رسانه\u200cهای اجتماعی مانند توئیتر یک نقطه گرم از اطلاعات تولید شده از کاربر است. در این پاندمیک کووید-۱۹ در حال حاضر، بسیاری از اطلاعات در رسانه های اجتماعی وجود دارد که می توانند به عنوان محتوای اطلاعات و غیر اطلاعات مختصر شوند. در این کاغذ، ما کار خود را برای شناسایی توئیت های اطلاعاتی Covid-19 انگلیسی با استفاده از مدل RoBERTa به عنوان بخشی از کارگاه W-NUT 2020 پیشنهاد می کنیم. ما موثرت مدل خود را در یک مجموعه داده عمومی با امتیاز F1 0.89 در مجموعه داده\u200cهای تایید و 0.87 در صفحه رهبر نشان می\u200cدهیم.', 'am': 'በትዊተር እንደሆነ የማኅበራዊ ሚዲያ የሆኑት የመረጃ መረጃዎች ናቸው፡፡ በዚህ ውስጥ የሚኖሩት ቁጥር-19 ደዌብ፣ በማኅበራዊ ሚዲያ ላይ ብዙ ዳታዎች አሉ፡፡ በዚህ ገጽ ውስጥ የኢንተርኔት ዋይድ-19 ኢንጂልኛ ትዊተቶችን በሮብERTA ሞዴል በ2020 የW-NUT workshop ክፍል ክፍል ለመግለጥ ሥራችንን እናቀርባለን፡፡ የሞዴላያችንን በህዝብ ዳታ ሳትሰር የ0.89 ነጭ የዳታ ሳጥን እናሳየዋለን፡፡', 'sq': 'Social media such as Twitter is a hotspot of user-generated information.  Në këtë pandemikë në vazhdim të Covid-19, ka patur një shumicë të dhënash mbi mediat shoqërore që mund të klasifikohen si përmbajtje informative dhe jo informative. In this paper, we present our work to detect informative Covid-19 English tweets using RoBERTa model as a part of the W-NUT workshop 2020.  Ne tregojmë efektshmërinë e modelit tonë në një grup të dhënash publike me një rezultat F1 0.89 në grupin e të dhënave të validimit dhe 0.87 në tabelën kryesore.', 'hy': 'Սոցիալական լրատվամիջոցները, ինչպիսիք են Թվիթերը, օգտագործողների կողմից ստեղծված տեղեկատվության վառ կետ է: Սոցիալական լրատվամիջոցների մասին տեղեկատվության բազմաթիվ տվյալներ կան, որոնք կարելի է դասակարգել որպես ինֆորմատիվ և ոչ ինֆորմատիվ պարունակություն: Այս թղթի մեջ մենք ներկայացնում ենք մեր աշխատանքը, որպեսզի հայտնաբերենք ինֆորմացիոնալ Covit-19 անգլերեն թվիթերը, օգտագործելով Ռոբերտայի մոդելը որպես W-NOT 2020-ի դասարանի մաս: Մենք ցույց ենք տալիս մեր մոդելի արդյունավետությունը հանրային տվյալների համակարգի վրա, որի F1 գնահատականը 0.89 է հավասարման տվյալների համակարգի վրա և 0.87 է առաջնորդում:', 'az': "Twitter kimi sosyal media istifad…ô√ßil…ôrin yaratdńĪńüńĪ m…ôlumatlarńĪnńĪn sńĪcak noktasńĪdńĪr. Ňěimdilik Covid-19 pandemiyada sosyal media haqqńĪnda √ßox m…ôlumat var ki, informatif v…ô informatif m…ôlumat kimi se√ßiril…ô bil…ôr. Bu kańüńĪzda, bizim iŇüimizi, RoBERTa modelini W-NUT workshop 2020'nin bir par√ßas ńĪ olaraq, informativ Covid-19 ńįngilizci tweets t…ôŇükil etm…ôk √ľ√ß√ľn t…ôŇükil edirik. Biz modelimizin etkinlińüini halkńĪ veril…ôn qurńüuda 0,89 d…ôqiq…ôsi olan F1 d…ôqiq…ôsi il…ô g√∂st…ôririk. N√∂vb…ôti qurńüuda 0,87 d…ôqiq…ôsi var.", 'bn': 'টুইটারের মতো সামাজিক প্রচার মাধ্যম ব্যবহারকারীদের উৎপাদন করা তথ্যের একটি হোট স্থান। এই চলমান কোভিড-১৯ ব্যাপারে সামাজিক প্রচার মাধ্যমে তথ্য বিভিন্ন তথ্য প্রকাশ করা হয়েছে, যা তথ্য এবং অনফরমোটিভ বিষয়বস্তু  এই কাগজটিতে আমরা তথ্য কোভিড-১৯ ইংরেজী টুইট সনাক্ত করার জন্য আমাদের কাজ উপস্থাপন করেছি রোবের্তা মডেল ব্যবহার করে ডি-এনউটি ওয়ার্কশা আমরা পাবলিক ডাটাসেটে আমাদের মডেলের কার্যক্রম দেখাচ্ছি যেটি বৈধ ডাটাসেট এবং নেতৃবোর্ডে ০.', 'bs': 'Društveni mediji poput Twitter su vruća mjesta informacija od korisnika. U ovoj trenutnoj pandemiji Covid-19 postoji dosta podataka o društvenim medijima koje se mogu klasifikirati kao informativni i neoinformativni sadržaj. U ovom papiru predstavljamo naš rad kako bi otkrili informativne tvitete Covid-19 engleskog jezika koristeći model RoBERTa kao dio radnog prakse W-NUT 2020. Mi pokazujemo djelotvornost našeg model a na javnom setu podataka sa rezultatom F1 od 0,89 na setu podataka za validaciju i 0,87 na vodećoj ploči.', 'ca': "Els mitjans socials com Twitter són un punt focal d'informació generada per l'usuari. En aquesta pandèmia continua del Covid-19, hi ha hagut una abundància de dades en els mitjans socials que poden ser classificades com a continguts informatius i no informatius. En aquest article, presentem la nostra feina per detectar tweets informatius Covid-19 anglès utilitzant el model RoBERTa com part del taller W-NUT 2020. We show the efficacy of our model on a public dataset with an F1-score of 0.89 on the validation dataset and 0.87 on the leaderboard.", 'cs': 'Sociální média, jako je Twitter, jsou hotspot informací generovaných uživateli. V této probíhající pandemii Covid-19 existuje množství dat na sociálních médiích, které lze klasifikovat jako informativní a neinformativní obsah. V tomto článku prezentujeme naši práci na detekci informativních Covid-19 anglických tweetů pomocí modelu RoBERTa v rámci workshopu W-NUT 2020. Účinnost našeho modelu ukazujeme na veřejném datovém souboru s F1 skóre 0,89 na validačním datovém souboru a 0,87 na žebříčku.', 'fi': 'Sosiaalinen media, kuten Twitter, on käyttäjien luoman tiedon hotspot. Tässä meneillään olevassa Covid-19-pandemiassa sosiaalisessa mediassa on ollut runsaasti tietoa, joka voidaan luokitella informatiiviseksi ja epäinformatiiviseksi sisällöksi. Tässä artikkelissa esittelemme työmme informatiivisten Covid-19 englanninkielisten twiittien havaitsemiseksi RoBERTa-mallin avulla osana W-NUT-työpajaa 2020. Osoitamme mallimme tehokkuuden julkisessa aineistossa, jonka F1-pisteet ovat 0,89 validointitiedostossa ja 0,87 tulostaulukossa.', 'et': 'Sotsiaalmeedia, nagu Twitter, on kasutaja loodud teabe hotspot. Käimasoleva Covid-19 pandeemia käigus on sotsiaalmeedias olnud palju andmeid, mida saab klassifitseerida informatiivseks ja mitteinformatiivseks sisuks. Käesolevas töös tutvustame oma tööd informatiivsete Covid-19 inglise säutsude tuvastamiseks RoBERTa mudeli abil W-NUT 2020 töötoa raames. Näitame oma mudeli efektiivsust avalikul andmekogumil, mille F1-skoor on 0,89 valideerimisandmekogumil ja 0,87 edetabelil.', 'jv': 'Media sotiné, nganggep Google kuwi dagoh-dagoh akeh informasi Genjer-Genjer Samsul iki Nang pepulan iki, kita nyibagi nggawe lan wektu nggawe informasi Covideo-19 bittik Inggris nambah ning model ro BERT nganggo ampar ning arep barêng W-NUT Awak dhéwé éntuk efekasi ning model sing ngendalikne dadi nggawe barang F1 dadi 0.8 sing ditambah barang nggawe dataset karo 0.', 'ha': "Mitandi na jamii kamar Twitter yana da hotpoint of information wanda aka haife shi. A cikin wannan bukar kwamfyuta wanda ke tafiya na coverid-19, an samu da wasu data masu yawa a kan zan rarraba shi kamar takardar da kuma ba'a sani ba. Ga wannan takardan, munã gabatar da aikinmu dõmin ka gane wasu littattafai na Agaid-19 Ingiriya da ake amfani da RuBERTA kamar wani abu ne daga W-NUT workin 2020. Kana nuna aikin misalinmu kan tsarin mutane da F1-nau'in 0.89 kan tsarin da za'a gaskata da 0.87 kan shirin bayani.", 'sk': 'Družbeni mediji, kot je Twitter, so vroča točka informacij, ki jih ustvarijo uporabniki. V tej pandemiji Covid-19 je na družbenih omrežjih veliko podatkov, ki jih je mogoče razvrstiti kot informativne in neinformativne vsebine. V tem prispevku predstavljamo naše delo za odkrivanje informativnih Covid-19 angleških tweetov z uporabo modela RoBERTa kot del delavnice W-NUT 2020. Učinkovitost našega modela prikazujemo na javnem naboru podatkov z oceno F1 0,89 na naboru podatkov validacije in 0,87 na lestvici.', 'he': 'התקשורת החברתית כמו טוויטר היא נקודה חמה של מידע שנוצר מהמשתמש. בפנדמיה הקוביד-19 הממשיכת הזאת, היו הרבה נתונים על תקשורת חברתית שאפשר להסווג בתוכן מידעי ולא מידעי. בעיתון הזה, אנו מציגים את עבודתנו כדי לגלות טוויטים אינפורטיביים קוביד-19 אנגליים באמצעות מודל RoBERTa כחלק מהסדן W-NUT 2020. אנחנו מראים את היעילות של המודל שלנו על קבוצת מידע ציבורית עם נקודת F1 של 0.89 על קבוצת מידע האישור ו-0.87 על הלוח המנהיג.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བཟོ་བར་ཌིས་ཌིར་ནི་སྤྱོད་མཁན་གྱིས་གསར་བསྐྲུན་བྱས་པའི་གནས་ཚུལ་གྱི་གྲངས དོན་ལྟ་མིའི་ནང་དུ་ཀོ་ཝི་ཌི་-19ལྟ་བུའི་ནང་དུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ནང་དོན་མང་ཙམ་ཡོད་པ་རེད། In this paper, we present our work to detect informative Covid-19 English tweets using RoBERTa model as a part of the W-NUT workshop 2020. ང་ཚོས་རྣམ་པའི་མིག་གཟུགས་སྡུད་ཀྱི་ནུས་སྤྱིར་བཏང་བའི་ཡིག་ཆ་སྒྲིག་ཐོག་ཏུ་མངོན་གསལ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'NLPRL at WNUT-2020 Task 2 : ELMo-based System for Identification of COVID-19 Tweets NLPRL  at  WNUT -2020 Task 2:  ELM o-based System for Identification of  COVID -19 Tweets', 'ar': 'NLPRL في WNUT-2020 المهمة 2: النظام المستند إلى ELMo لتحديد تغريدات COVID-19', 'fr': "NLPRL à la tâche 2 de la WNUT-2020\xa0: Système basé sur Elmo pour l'identification des tweets COVID-19", 'pt': 'NLPRL no WNUT-2020 Tarefa 2: Sistema baseado em ELMo para identificação de tweets COVID-19', 'es': 'NLPRL en la Tarea 2 del WNUT-2020: Sistema basado en ELMO para la identificación de tuits de COVID-19', 'ja': 'WNUT -2020のNLPRLタスク2 ： COVID -19ツイートを識別するためのELMoベースのシステム', 'ru': 'NLPRL на WNUT-2020 Задача 2: Система идентификации твитов о COVID-19 на основе ELMo', 'zh': 'NLPRLåœ¨WNUT-2020åŠ¡2:åŸºäºŽELMoä¹‹COVID-19æŽ¨æ–‡è¯†åˆ«ç³»ç»Ÿ', 'hi': 'WNUT-2020 टास्क 2 पर NLPRL: कोविड-19 ट्वीट्स की पहचान के लिए ELMo-आधारित सिस्टम', 'ga': 'NLPRL ag WNUT-2020 Tasc 2: Córas bunaithe ar ELMo chun Tweetanna COVID-19 a Aithint', 'ka': 'Name', 'el': 'Εργασία 2: Σύστημα Αναγνώρισης Τουίτ με βάση το ΕΛMo', 'hu': 'NLPRL a WNUT-2020 2. feladat: ELMo-alapú rendszer a COVID-19 tweetek azonosítására', 'it': "NLPRL a WNUT-2020 Task 2: Sistema basato su ELMo per l'identificazione dei tweet COVID-19", 'lt': 'NLPRL WNUT-2020 2 užduotis: COVID-19 Tweets identifikavimo sistema, pagrįsta ELMo', 'kk': 'NLPRL WNUT-2020 тапсырмасы 2: COVID-19 Tweets идентификациялау жүйесі ELMo негізінде', 'mk': 'НЛПРЛ на ВНУТ-2020 задача 2: ЕЛМО-базиран систем за идентификација на твитови COVID-19', 'ml': 'WNUT- 2020 ടാസ്ക് 2-ല്\u200d NLPRL: COVID-19 ടൂട്ടുകളുടെ തിരിച്ചറിയുവാന്\u200d ELMo-അടിസ്ഥാനമായ സിസ്റ്റം', 'mt': 'NLPRL fid-WNUT-2020 Task 2: Sistema bbażata fuq ELMo għall-Identifikazzjoni ta’ Tweets COVID-19', 'mn': 'NLPRL at WNUT-2020 Task 2: ELMo-based System for Identification of COVID-19 Tweets', 'ms': 'NLPRL di WNUT-2020 Tugas 2: Sistem berasaskan ELMo untuk pengenalpasti Tweets COVID-19', 'pl': 'NLPRL na WNUT-2020 Zadanie 2: System identyfikacji tweetów COVID-19 oparty na ELMo', 'no': 'NLPRL på WNUT-2020 oppgåve 2: ELMobasert system for identifisering av COVID-19 tweets', 'ro': 'NLPRL la WNUT-2020 Sarcina 2: Sistemul ELMo pentru identificarea tweeturilor COVID-19', 'sr': 'NLPRL na WNUT-2020 zadatku 2: ELMo-bazirani sistem identifikacije COVID-19 Tweets', 'si': 'NLPRL at WNuT-2020Job 2: ELMo-based System for ID of COVID-19 Tweets', 'sv': 'NLPRL vid WNUT-2020 Uppgift 2: ELMo-baserat system för identifiering av COVID-19 tweets', 'so': 'WNUT-2020 Task 2: ELMo-based system for identification of COVID-19 Tweets', 'ta': 'WNUT- 2020 பணி 2:', 'ur': 'WNUT-2020 ٹاکس 2 میں NLPRL: COVID-19 ٹویٹ کی شناسایی کے لئے ELMo-Based System', 'uz': 'Comment', 'vi': 'NLLRL at WUT-2020 Task 2: Hệ thống có nguồn gốc ElMo để xác minh COVID-19 Tweet', 'nl': 'NLPRL op WNUT-2020 Taak 2: ELMo-gebaseerd systeem voor identificatie van COVID-19 Tweets', 'bg': 'Задача 2: базирана на ЕЛМО система за идентифициране на туитове', 'da': 'NLPRL ved WNUT-2020 Opgave 2: ELMo-baseret system til identifikation af COVID-19 tweets', 'hr': 'NLPRL na zadatku 2. na ELMo-baziranom sustavu identifikacije COVID-19 Tweets', 'ko': 'WNUT-2020에서 NLPRL의 임무 2: ELMo 기반 코로나 트윗 인식 시스템', 'de': 'NLPRL bei WNUT-2020 Aufgabe 2: ELMo-basiertes System zur Identifizierung von COVID-19 Tweets', 'fa': 'NLPRL در Task 2 WNUT-2020: سیستم بنیاد ELMo برای شناسایی COVID-19 Tweets', 'id': 'NLPRL di WNUT-2020 Tugas 2: Sistem berdasarkan ELMo untuk Identifikasi Tweets COVID-19', 'sw': 'NLPRL kwenye kazi ya WNUT-2020 2: Mfumo wa kutumia ELMo kwa ajili ya kutambua Twita za COVID-19', 'tr': 'NLPRL at WNUT-2020 Task 2: ELMo-based System for Identification of COVID-19 Tweets', 'af': 'NLPRL by WNUT-2020 Opdrag 2: ELMo-gebaseerde Stelsel vir Identifikasie van COVID-19 Tweets', 'am': 'በWNUT-2020 ስራ 2: ELMo-based system for identification of COVID-19 Tweets', 'az': 'WNUT-2020 Task 2: ELMo-based System for Identification of COVID-19 Tweets', 'bn': 'WNUT-2020 কাজ ২-এ NLPRL: COVID-19 টুইট পরিচয়ের জন্য ELMo ভিত্তিক সিস্টেম', 'sq': 'NLPRL në WNUT-2020 Task 2: ELMo-based System for Identification of COVID-19 Tweets', 'cs': 'NLPRL na WNUT-2020 Úkol 2: Systém pro identifikaci tweetů COVID-19 založený na ELMo', 'bs': 'NLPRL na zadatku 2. na ELMo-baziranom sustavu identifikacije COVID-19 Tweets', 'et': 'NLPRL WNUT-2020 ülesandel 2: ELMo-põhine COVID-19 tweetide tuvastamise süsteem', 'hy': 'ՎԱՆԹ-2020-ի երկրորդ հանձնարարությունը՝ COVID-19 թվիթերի հայտնաբերման ELMo-ի հիմնված համակարգը', 'fi': 'NLPRL WNUT-2020 Tehtävä 2: ELMo-pohjainen järjestelmä COVID-19-twiittien tunnistamiseksi', 'ca': 'NLPRL al WNUT-2020 Task 2: ELMo-based System for Identification of COVID-19 Tweets', 'jv': 'NLPRL at WNUT-2020', 'he': 'NLPRL ב-WNUT-2020 משימה 2: מערכת מבוססת ELMo לזהות טוויטים COVID-19', 'ha': 'QUnicodeControlCharacterMenu', 'sk': 'NLPRL na WNUT-2020 naloga 2: sistem za identifikacijo COVID-19, ki temelji na ELMo', 'bo': 'NLPRL at WNUT-2020 Task 2: ELMo-based System for Identification of COVID-19 Tweets'}
{'en': 'The Coronavirus pandemic has been a dominating news on  social media  for the last many months. Efforts are being made to reduce its spread and reduce the casualties as well as new infections. For this purpose, the information about the infected people and their related symptoms, as available on  social media , such as  Twitter , can help in  prevention  and taking precautions. This is an example of using noisy text processing for  disaster management . This paper discusses the NLPRL results in Shared Task-2 of WNUT-2020 workshop. We have considered this problem as a binary classification problem and have used a pre-trained ELMo embedding with GRU units. This approach helps classify the tweets with  accuracy  as 80.85 % and 78.54 % as  F1-score  on the provided test dataset. The experimental code is available online.', 'ar': 'كان جائحة فيروس كورونا من الأخبار السائدة على وسائل التواصل الاجتماعي خلال الأشهر العديدة الماضية. وتبذل الجهود للحد من انتشاره وتقليل الإصابات وكذلك الإصابات الجديدة. لهذا الغرض ، يمكن أن تساعد المعلومات حول الأشخاص المصابين والأعراض المرتبطة بهم ، كما هو متاح على وسائل التواصل الاجتماعي ، مثل Twitter ، في الوقاية واتخاذ الاحتياطات. هذا مثال على استخدام معالجة النصوص المزعجة لإدارة الكوارث. تناقش هذه الورقة نتائج NLPRL في المهمة المشتركة 2 لورشة عمل WNUT-2020. لقد اعتبرنا هذه المشكلة مشكلة تصنيف ثنائية واستخدمنا دمج ELMo مُدرَّب مسبقًا مع وحدات GRU. يساعد هذا النهج في تصنيف التغريدات بدقة على أنها 80.85٪ و 78.54٪ على أنها درجة F1 على مجموعة بيانات الاختبار المقدمة. الكود التجريبي متاح على الإنترنت.', 'es': 'La pandemia de coronavirus ha sido una noticia dominante en las redes sociales durante los últimos meses. Se están realizando esfuerzos para reducir su propagación y reducir las víctimas, así como las nuevas infecciones. Con este fin, la información sobre las personas infectadas y sus síntomas relacionados, disponible en las redes sociales, como Twitter, puede ayudar en la prevención y la toma de precauciones. Este es un ejemplo del uso del procesamiento de textos ruidoso para la gestión de desastres. Este documento analiza los resultados de la NLPRL en la Tarea Compartida 2 del taller WNUT-2020. Hemos considerado este problema como un problema de clasificación binaria y hemos utilizado una integración de eLMO previamente entrenada con unidades GRU. Este enfoque ayuda a clasificar los tuits con precisión como 80,85% y 78,54% como puntuación F1 en el conjunto de datos de prueba proporcionado. El código experimental está disponible en línea.', 'fr': "La pandémie de coronavirus est l'une des principales nouvelles sur les réseaux sociaux depuis de nombreux mois. Des efforts sont déployés pour réduire sa propagation et réduire le nombre de victimes ainsi que les nouvelles infections. À cette fin, les informations sur les personnes infectées et leurs symptômes associés, telles que disponibles sur les réseaux sociaux, tels que Twitter, peuvent aider à la prévention et à prendre des précautions. Voici un exemple d'utilisation du traitement de texte bruyant pour la gestion des catastrophes. Cet article traite des résultats de la NLPRL dans l'atelier Shared Task-2 of WNUT-2020. Nous avons considéré ce problème comme un problème de classification binaire et avons utilisé une intégration ElMo pré-entraînée avec des unités GRU. Cette approche permet de classer les tweets avec une précision de 80,85\xa0% et de 78,54\xa0% comme score F1 sur l'ensemble de données de test fourni. Le code expérimental est disponible en ligne.", 'pt': 'A pandemia de coronavírus tem sido uma notícia dominante nas redes sociais nos últimos meses. Esforços estão sendo feitos para reduzir sua propagação e reduzir as vítimas, bem como novas infecções. Para isso, as informações sobre as pessoas infectadas e seus sintomas relacionados, disponíveis nas redes sociais, como o Twitter, podem ajudar na prevenção e nos cuidados. Este é um exemplo de uso de processamento de texto ruidoso para gerenciamento de desastres. Este artigo discute os resultados do NLPRL na Tarefa Compartilhada-2 do workshop WNUT-2020. Consideramos este problema como um problema de classificação binária e usamos uma incorporação ELMo pré-treinada com unidades GRU. Essa abordagem ajuda a classificar os tweets com precisão de 80,85% e 78,54% como pontuação F1 no conjunto de dados de teste fornecido. O código experimental está disponível online.', 'ja': '新型コロナウイルスのパンデミック（世界的大流行）は、過去数ヶ月にわたってソーシャルメディアで支配的なニュースでした。感染拡大を抑え、新規感染者だけでなく犠牲者を減らす取り組みが行われている。この目的のために、Twitterなどのソーシャルメディアで入手可能な感染者とその関連症状に関する情報は、予防と予防措置を講じるのに役立ちます。これは、災害管理にノイズの多いテキスト処理を使用した例です。本稿では、WNUT -2020ワークショップのShared Task -2におけるNLPRLの結果について説明する。この問題をバイナリ分類の問題と考え、事前に訓練されたELMo埋め込みをGRUユニットとともに使用しました。このアプローチは、提供されたテストデータセットのF 1スコアとして、80.85 ％と78.54 ％の精度でツイートを分類するのに役立ちます。実験コードはオンラインでご利用いただけます。', 'zh': '在昔数月,冠状病毒大行,社交媒体之大新闻也。 方务省其传,损其伤新染。 故其感染者息(Twitter)社交媒体可以助预防措施。 此以嘈杂文本处难治之示例。 本文议WNUT-2020研讨会共享-2中NLPRL。 以为二元分类,用预练之ELMo嵌GRU单元。 此术有助于将推文者准确性类为 80.85%,供测试数据集,78.54% 为 F1 分数。 实验代码可在线取。', 'hi': 'कोरोना वायरस महामारी पिछले कई महीनों से सोशल मीडिया पर एक प्रमुख खबर है। इसके प्रसार को कम करने और हताहतों की संख्या को कम करने के साथ-साथ नए संक्रमणों को कम करने के प्रयास किए जा रहे हैं। इस उद्देश्य के लिए, संक्रमित लोगों और उनके संबंधित लक्षणों के बारे में जानकारी, जैसा कि सोशल मीडिया पर उपलब्ध है, जैसे कि ट्विटर, रोकथाम और सावधानी बरतने में मदद कर सकता है। यह आपदा प्रबंधन के लिए शोर पाठ प्रसंस्करण का उपयोग करने का एक उदाहरण है। यह पेपर WNUT-2020 कार्यशाला के साझा कार्य-2 में NLPRL परिणामों पर चर्चा करता है। हमने इस समस्या को एक बाइनरी वर्गीकरण समस्या के रूप में माना है और जीआरयू इकाइयों के साथ एम्बेडिंग के लिए एक पूर्व-प्रशिक्षित ईएलएमओ का उपयोग किया है। यह दृष्टिकोण 80.85% और 78.54% के रूप में सटीकता के साथ ट्वीट्स को प्रदान किए गए परीक्षण डेटासेट पर F1-स्कोर के रूप में वर्गीकृत करने में मदद करता है। प्रयोगात्मक कोड ऑनलाइन उपलब्ध है।', 'ru': 'Пандемия коронавируса была доминирующей новостью в социальных сетях в течение последних нескольких месяцев. Предпринимаются усилия по сокращению его распространения и числа жертв, а также числа новых случаев инфицирования. С этой целью информация об инфицированных людях и связанных с ними симптомах, доступная в социальных сетях, таких как Twitter, может помочь в профилактике и принятии мер предосторожности. Это пример использования шумной обработки текста для управления стихийными бедствиями. В этой статье обсуждаются результаты NLPRL в Общей задаче-2 семинара WNUT-2020. Мы рассматривали эту проблему как двоичную проблему классификации и использовали предварительно обученное встраивание ELMo с блоками GRU. Этот подход помогает классифицировать твиты с точностью 80,85% и 78,54% как F1-балл в предоставленном наборе тестовых данных. Экспериментальный код доступен онлайн.', 'ga': 'Is nuacht cheannasach ar na meáin shóisialta é paindéim an choróinvíris le míonna fada anuas. Tá iarrachtaí á ndéanamh chun a scaipeadh a laghdú agus líon na dtaismeach a laghdú chomh maith le hionfhabhtuithe nua. Chun na críche sin, is féidir leis an bhfaisnéis faoi na daoine atá ionfhabhtaithe agus na hairíonna a bhaineann leo, mar atá ar fáil ar na meáin shóisialta, mar Twitter, cabhrú le réamhchúraimí a chosc agus a ghlacadh. Is sampla é seo de phróiseáil téacs noisiúil a úsáid le haghaidh bainistiú tubaiste. Pléann an páipéar seo torthaí NLPRL i dTasc Comhroinnte-2 de cheardlann WNUT-2020. Mheasamar an fhadhb seo mar fhadhb aicmithe dhénártha agus d’úsáideamar neadú ELMo réamh-oilte le haonaid GRU. Cuidíonn an cur chuige seo leis na tweets a rangú le cruinneas mar 80.85% agus 78.54% mar scór F1 ar an tacar sonraí tástála a chuirtear ar fáil. Tá an cód turgnamhach ar fáil ar líne.', 'ka': 'კჲპჲნაგთპსჟ ოანემთკა ვ ეჲმთნსგაღა ნჲგთნა ნა ჟჲუთალნთრვ მვეთწ ოჲჟლვენთრვ მნჲდჲ მვჟვუთ. უფრო ძალიან გავაკეთება, რომ მისი გაფართლება და შემცირება ზემულები და ახალი ინფექციები. ამ მიზეზისთვის, ინფორმაცია ინფექტირებული ადამიანების და შესაბამისი სიმპტომების შესახებ, როგორც სოციალური მედიაში, როგორც Twitter, შეიძლება დახმარება პროგრაფიკაციაში და და ეს არის მაგალითი გამოყენება სიტყვი ტექსტის პროცესის გამოყენება კარგალის მენეჯერებისთვის. ეს დოკუმენტი განსაზღვრდება NLPRL-ის შედეგი WNUT-2020 სამუშაო სამუშაო დასაზღვრული Task-2. ჩვენ ეს პრობლემა ბინარი კლასიფიკაციის პრობლემა გავფიქრობთ და გამოვიყენეთ წინ განსწავლებული ELMo, რომელიც GRU ერთეულებთან დაყენებული. ეს პროგრამა დახმარებს, რომ გავაკეთებული ტესტის მონაცემების კონფიგურაცია 80.85% და 78.54% როგორც F1- სონტის მონაცემების კონფიგურაცია. Name', 'hu': 'A koronavírus járvány az elmúlt hónapokban domináló hír volt a közösségi médiában. Erőfeszítéseket tesznek annak terjedésének csökkentésére és az áldozatok és az új fertőzések csökkentésére. Ebből a célból a fertőzött személyekre és azokhoz kapcsolódó tünetekre vonatkozó információk, amelyek a közösségi médiában, például a Twitteren elérhetőek, segíthetnek a megelőzésben és az óvintézkedések megtételében. Ez egy példa arra, hogy zajos szövegfeldolgozást használnak katasztrófakezeléshez. Ez a tanulmány a WNUT-2020 workshop megosztott feladata-2 eredményeit tárgyalja. Ezt a problémát bináris osztályozási problémának tekintettük, és előre képzett ELMo beágyazást alkalmaztunk GRU egységekkel. Ez a megközelítés segít a tweetek pontosságának 80,85%-ra és 78,54%-ra osztályozásában F1-pontszámként a rendelkezésre álló tesztadatokon. A kísérleti kód elérhető online.', 'el': 'Η πανδημία του Κορωνοϊού αποτελεί κυρίαρχη είδηση στα μέσα κοινωνικής δικτύωσης τους τελευταίους πολλούς μήνες. Γίνονται προσπάθειες για τη μείωση της εξάπλωσής του και τη μείωση των θυμάτων καθώς και των νέων λοιμώξεων. Για το σκοπό αυτό, οι πληροφορίες σχετικά με τα μολυσμένα άτομα και τα σχετικά συμπτώματα τους, όπως είναι διαθέσιμες στα μέσα κοινωνικής δικτύωσης, όπως το Twitter, μπορούν να βοηθήσουν στην πρόληψη και τη λήψη προληπτικών μέτρων. Αυτό είναι ένα παράδειγμα χρήσης θορυβώδους επεξεργασίας κειμένου για τη διαχείριση καταστροφών. Η παρούσα εργασία συζητά τα αποτελέσματα της στο Κοινό Έργο-2 του εργαστηρίου WNUT-2020. Έχουμε θεωρήσει αυτό το πρόβλημα ως πρόβλημα δυαδικής ταξινόμησης και έχουμε χρησιμοποιήσει μια προ-εκπαιδευμένη ενσωμάτωση με μονάδες GRU. Αυτή η προσέγγιση βοηθά στην ταξινόμηση των tweets με ακρίβεια ως 80.85% και 78.54% ως βαθμολογία F1 στο παρεχόμενο σύνολο δεδομένων δοκιμής. Ο πειραματικός κώδικας είναι διαθέσιμος στο διαδίκτυο.', 'it': "La pandemia di Coronavirus è stata una notizia dominante sui social media negli ultimi mesi. Si stanno facendo sforzi per ridurre la sua diffusione e ridurre le vittime e le nuove infezioni. A tal fine, le informazioni sulle persone infette e sui loro sintomi correlati, disponibili sui social media, come Twitter, possono aiutare nella prevenzione e nell'adozione di precauzioni. Questo è un esempio di utilizzo di elaborazione di testo rumorosa per la gestione delle catastrofi. Questo articolo discute i risultati della NLPRL nell'attività condivisa 2 del workshop WNUT-2020. Abbiamo considerato questo problema come un problema di classificazione binaria e abbiamo utilizzato un embedding ELMo pre-addestrato con unità GRU. Questo approccio aiuta a classificare i tweet con precisione come 80,85% e 78,54% come punteggio F1 sul set di dati di prova fornito. Il codice sperimentale è disponibile online.", 'kk': 'Коронавирус пандемиясы соңғы ай бойы социалдық медиақтардың доминиралық жаңалықтары болды. Жаңа инфекциялар мен жетістіктерді азайту үшін жұмыс істейді. Бұл мақсат үшін, Твиттер секілді социалдық медиақтарда қол жеткізетін адамдар және олардың қатынастық симптомалары туралы мәлімет, қауіпсіздіктерді алдындау және қауіпсі Бұл бейбіттерді басқару үшін дыбыс мәтін өңдеу мысалы. Бұл қағаз NLPRL жұмысының WNUT-2020 жұмысының ортақ тапсырмасының 2- нәтижесін талқылады. Біз бұл мәселеді бинарлық классификациялау мәселесі ретінде ойладық және GRU бірліктерінде алдын- ала үйренген ELMo мәселесін қолдандық. Бұл тәсілі келтірілген сынақ деректер жиынындағы таңбаларды 80, 85% мен 78, 54% деп классификациялауға көмектеседі. Тәжірибелі код онлайн үшін бар.', 'lt': 'Pastaraisiais mėnesiais koronaviruso pandemija yra dominuojanti socialinės žiniasklaidos žinia. Yra dedamos pastangos sumažinti jos plitimą ir sumažinti aukas bei naujas infekcijas. Šiuo tikslu social in ėje žiniasklaidoje, pvz., Twitter, pateikiama informacija apie užkrėstus žmones ir su jais susijusius simptomus gali padėti prevencijai ir imtis atsargumo priemonių. Tai pavyzdys, kaip naudoti triukšmingą teksto apdorojimą nelaimių valdymo tikslais. Šiame dokumente aptariami NLPRL rezultatai vykstant WNUT 2020 seminarui pagal bendrą 2 užduotį. Manėme, kad ši problem a yra dvigubo klasifikavimo problema ir naudojome iš anksto parengtą ELMo įdėjimą į GRU vienetus. Šis metodas padeda tiksliai klasifikuoti tweetus kaip 80,85 % ir 78,54 % kaip F1 tašką pateiktuose bandymų duomenų rinkiniuose. Eksperimentinis kodas pateikiamas internete.', 'mk': 'Пандемијата со коронавирус е доминирачка вест за социјалните медиуми во последните неколку месеци. Efforts are being made to reduce its spread and reduce the casualties as well as new infections.  За оваа цел, информациите за инфицираните луѓе и нивните поврзани симптоми, како што се достапни на социјалните медиуми, како што е Твитер, можат да помогнат во спречувањето и преземањето претпазливи мерки. Ова е пример за употреба на бучни текстови за управување со катастрофи. Овој документ дискутира за резултатите на НЛПРЛ во Другата задача на работилницата WNUT-2020. Го сметавме овој проблем за бинарен проблем со класификацијата и употребивме предобучен ЕЛМО вграден во GRU единици. Овој пристап помага да ги класификува твитовите со прецизност како 80,85 отсто и 78,54 отсто како резултат F1 на обезбедениот тестовен податок. Експерименталниот код е достапен онлајн.', 'ms': 'Pandemi Coronavirus telah menjadi berita dominan dalam media sosial selama berbulan-bulan terakhir. Kami sedang berusaha untuk mengurangi penyebaran dan mengurangi kematian serta infeksi baru. Untuk tujuan ini, maklumat mengenai orang yang dijangkiti dan gejala-gejala yang berkaitan dengan mereka, seperti yang tersedia di media sosial, seperti Twitter, boleh membantu dalam mencegah dan mengambil tindakan pencegahan. Ini contoh menggunakan pemprosesan teks bunyi untuk pengurusan bencana. Kertas ini membincangkan hasil NLPRL dalam tugas kongsi-2 workshop WNUT-2020. Kami telah mempertimbangkan masalah ini sebagai masalah kelasukan binari dan telah menggunakan ELMo terlatih terlebih dahulu dalam unit GRU. This approach helps classify the tweets with accuracy as 80.85% and 78.54% as F1-score on the provided test dataset.  Kod eksperimen tersedia online.', 'ml': 'കഴിഞ്ഞ മാസങ്ങളായി കൊരോണാവിറസ് പാന്\u200dഡെമിക്ക് ഒരു വാര്\u200dത്തയായിരുന്നു. അതിന്റെ വിതരണം കുറച്ചു കൂട്ടുവാനും നഷ്ടപ്പെട്ടവരെയും പുതിയ രോഗങ്ങളെയും കുറയ്ക്കാനും ശ്രമിക്കുന്നു. അതിനുവേണ്ടിയാണ്, രോഗപ്പെട്ട ആളുകളെക്കുറിച്ചും അവരുടെ ബന്ധപ്പെട്ട അടയാളങ്ങളെക്കുറിച്ചും വിവരങ്ങള്\u200d, സാമൂഹ്യ മീഡിയില ഇതൊരു ഉദാഹരണമാണ് അപകടത്തിന്റെ മാനേജന്റിനുള്ള ശബ്ദ പദാവലി പ്രവര്\u200dത്തിപ്പിക്കുന്നത്. ഈ പേപ്പറില്\u200d WNUT-2020 വര്\u200dക്കാര്\u200dക്ഷനില്\u200d പങ്കുചേര്\u200dക്കപ്പെട്ട ട ടാസ്ക്-2-ല്\u200d NLPRL ഫലങ്ങള്\u200d സംസാരിക്കുന്ന ഞങ്ങള്\u200d ഈ പ്രശ്നത്തെ ബൈനരി ക്ലാസ്ഫിക്ഷന്\u200d പ്രശ്നമായി വിചാരിച്ചിരിക്കുന്നു. മുമ്പ് പരിശീലിക്കപ്പെട്ട ELMo ജിആര ഈ പ്രാധാന്യം ഉപയോഗിച്ച ടെസ്റ്റ് ഡാറ്റാസെറ്റില്\u200d എഫ്1- സ്കോര്\u200d പരീക്ഷണ കോഡ് ഓണ്\u200dലൈനില്\u200d ലഭ്യമാണ്.', 'mt': 'Il-pandemija tal-Coronavirus ilha a ħbar dominanti fuq il-midja soċjali għal dawn l-aħħar xhur. Efforts are being made to reduce its spread and reduce the casualties as well as new infections.  Għal dan il-għan, l-informazzjoni dwar in-nies infettati u s-sintomi relatati tagħhom, kif disponibbli fuq il-midja soċjali, bħal Twitter, tista’ tgħin fil-prevenzjoni u t-teħid ta’ prekawzjonijiet. Dan huwa eżempju tal-użu tal-ipproċessar tat-test storbjuż għall-ġestjoni tad-diżastri. Dan id-dokument jiddiskuti r-riżultati tal-NLPRL f’Kompitu Konġunt 2 tal-workshop WNUT-2020. Ikkunsidrajna din il-problem a bħala problema ta’ klassifikazzjoni binarja u użajna ELMo mħarreġ minn qabel li tinkorpora ma’ unitajiet GRU. Dan l-approċċ jgħin jikklassifika t-tweets b’preċiżjoni bħala 80.85% u 78.54% bħala punteġġ F1 fuq is-sett ta’ dejta tat-test ipprovdut. Il-kodiċi sperimentali huwa disponibbli onlajn.', 'mn': 'Коронавирусын пандемик сүүлийн сарын турш нийгмийн мэдээлэл дээр давамгайлсан мэдээг болсон. Тэдний тархалтыг багасгаж, хортой болон шинэ халдварыг багасгахад хүсэж байна. Энэ зорилгоонд, халдвар авсан хүмүүсийн тухай мэдээлэл, нийгмийн мэдээлэл, Твиттер шиг, нийгмийн мэдээлэлд ашиглаж буй хүмүүсийн тухай мэдээлэл, хамгаалалтай байдлыг тодорхойлж чадна. Энэ бол гамшгийн удирдлагын тулд чимээгүй текст үйл ажиллагааг ашиглах жишээ. Энэ цаас NLPRL нь WNUT-2020 ажлын хуваалтын Task-2-ын үр дүнг ярьдаг. Бид энэ асуудлыг хоёр дахь хуваалтын асуудал гэж үзсэн бөгөөд GRU нэгжүүд дээр сургалтын өмнө сургалтын ELMo-г ашигласан. Энэ арга нь тохиромжтой tweets-г тодорхойлох нь 80.85% болон 78.54% нь F1-н тооны шалгалтын өгөгдлийн сангийн хувьд тодорхойлох боломжтой. Үүний туршилтын код онлайн хэрэглэгддэг.', 'pl': 'Pandemia koronawirusa od wielu miesięcy jest dominującą wiadomością w mediach społecznościowych. Podejmowane są wysiłki, aby ograniczyć jego rozprzestrzenianie się i zmniejszyć liczbę ofiar oraz nowych infekcji. W tym celu informacje o zarażonych osobach i ich objawach dostępne w mediach społecznościowych, takich jak Twitter, mogą pomóc w zapobieganiu i podejmowaniu środków ostrożności. Jest to przykład wykorzystania hałaśliwego przetwarzania tekstu do zarządzania awarią. W artykule omówiono wyniki NLPRL w ramach wspólnego zadania-2 warsztatów WNUT-2020. Uznaliśmy ten problem jako problem klasyfikacji binarnej i użyliśmy wstępnie przeszkolonego osadzenia ELMo z jednostkami GRU. Takie podejście pomaga klasyfikować tweety z dokładnością jako 80,85% i 78,54% jako wynik F1 na dostarczonym zbiorze danych testowych. Kod eksperymentalny jest dostępny online.', 'ro': 'pandemia de Coronavirus a fost o știre dominantă pe rețelele de socializare în ultimele luni. Se depun eforturi pentru a reduce răspândirea acesteia și pentru a reduce victimele, precum și noile infecții. În acest scop, informațiile despre persoanele infectate și simptomele aferente acestora, astfel cum sunt disponibile pe rețelele de socializare, cum ar fi Twitter, pot ajuta la prevenirea și luarea de măsuri de precauție. Acesta este un exemplu de utilizare a procesării de text zgomotoase pentru gestionarea dezastrelor. Această lucrare discută rezultatele NLPRL în sarcina partajată 2 a atelierului WNUT-2020. Am considerat această problemă ca o problemă de clasificare binară și am folosit o încorporare ELMo pre-antrenată cu unitățile GRU. Această abordare ajută la clasificarea tweeturilor cu precizie la 80,85% și 78,54% ca scor F1 pe setul de date de testare furnizat. Codul experimental este disponibil online.', 'no': 'Coronavirus-pandemikk har vært ein dominerende nyhetar på sosiale media i dei siste mange månedene. Førehandsvising blir gjort for å redusera spredninga og redusera ofte og nye infeksjonar. For dette målet kan informasjonen om dei infiserte menneske og deres relaterte simptome, som er tilgjengeleg på sosiale medier, som Twitter, hjelpa i forebygging og førehandsvising. Dette er eit eksempel på bruk av støy teksthandsaming for katastrofisk handsaming. Denne papiret diskuterer NLPRL-resultatet i delt oppgåve-2 av WNUT-2020 arbeidsområdet. Vi har sett opp dette problemet som eit binær klassifikasjonsfeil og har brukt eit føretrained ELMo- innbygging med GRU- einingar. Denne tilnærminga hjelper til å klassifisera tweeten med nøyaktighet som 80,85% og 78,54% som F1- poeng på den oppgjevne testdatasettet. Den eksperimentelle koden er tilgjengeleg på nettet.', 'sr': 'Pandemija Koronavirusa je bila dominantna vijest u društvenim medijima poslednjih mnogo meseci. Postavljaju napori da se smanji širenje i smanji žrtve kao i nove infekcije. Za ovu svrhu, informacije o inficiranim ljudima i njihovim povezanim simptomima, koje su dostupne na društvenim medijima, poput Twitter, mogu pomoći u prevenciji i uzimanju opreza. Ovo je primjer korištenja zvukovih tekstova za upravljanje katastrofama. Ovaj papir razgovara o rezultatima NLPRL-a u delnom zadatku-2 WNUT-2020 radionice. Smatrali smo ovaj problem kao problem sa binarnom klasifikacijom i koristili smo predobučenu ELMo ugrađenu sa GRU jedinicama. Ovaj pristup pomaže da klasifikuju tweets sa preciznošću kao 80,85% i 78,54% kao rezultat F1 na pruženoj testnoj seti podataka. Eksperimentalni kod je dostupan online.', 'so': 'Cudurada Koronavirus waxay macluumaad ku saabsan macluumaadka bulshada ugu dambeysay bilo badan. Waxaa la sameeyaa isku dayo in la hoosaysiiyo kala bixintiisa iyo in dhaawacyada iyo cudurada cusub la dhinaco. Sababtaas darteed macluumaadka la xiriira dadka buka iyo calaamadihiisa la xiriira, sida shabakada bulshada, tusaale ahaan Twitterka, waxay caawimaad uga heli karaan ka hortagga iyo ka qaadi karaan taqsiir. Tani waa tusaale ahaan isticmaalka baaraandegista qoraalka codsiga ah ee maamulka dhibaatada. Kanu warqaddan ayaa ka sheekaynaya resultinta NLPRL ee lagu sharciyey shaqo-2 ee warqadda WNUT-2020. We have considered this problem as a binary classification problem and have used a pre-trained ELMo embedding with GRU units.  Xaaladanku wuxuu si sax ah ugu caawinayaa Twitteetka oo saxda ah 80.85 boqolkiiba iyo 78.54 boqolkiiba F1-score oo ku qoran taariikhda imtixaanka. Kaarka imtixaanka waxaa laga helaa shabakadda.', 'si': 'කෝරෝනාවිරෝස් විස්තර ප්\u200dරශ්නයක් සාමාජික මිඩියාවට අන්තිම මාස ගොඩක් විසින් ප්\u200dරශ්නයක උත්සාහ කරලා තියෙන්නේ ඒකේ විස්තරය අඩු කරන්න සහ අළුත් විස්තරයක් අඩු කරන්න. මේ අදහස් වෙනුවෙන්, සාමාජික මධ්\u200dයමාධ්\u200dයමේ සම්බන්ධ ප්\u200dරතිකාරය සහ ඔවුන්ගේ සම්බන්ධ ප්\u200dරතිකාරය සඳහා තොරතුරු ස මේක නිර්දේශ ප්\u200dරධානය සඳහා ශබ්ද පැත්තක් පරික්ෂණය භාවිතා කරන්න උදාහරණයක්. මේ පත්තුව NLPRL විශ්වාස කරනවා WNAT-2020වැඩසටහන් එකේ සමාගත වැඩසටහන් 2 වලින්. අපි මේ ප්\u200dරශ්නය බායිනාරි විශ්ලේෂණ ප්\u200dරශ්නයක් විදිහට හිතලා තියෙන්නේ, ඒ වගේම GRU යුනිටිකයෙන් ප්\u200dරශ මේ විදිහට ට්විට් එක්ක ඇත්තටම 80.85% සහ 78.54% විදියට F1- ස්කෝර් විදියට පරීක්ෂණ දත්ත සෙට් විදියට උදව් කරනවා. පරීක්ෂණ කෝඩ් අන්ලයාන් වෙන්න පුළුවන්.', 'sv': 'Coronaviruspandemin har varit en dominerande nyhet på sociala medier under de senaste månaderna. Ansträngningar görs för att minska spridningen och minska antalet döda och nya infektioner. För detta ändamål kan informationen om de smittade personerna och deras relaterade symtom, som finns tillgänglig på sociala medier, såsom Twitter, hjälpa till att förebygga och vidta försiktighetsåtgärder. Detta är ett exempel på att använda bullrig textbehandling för katastrofhantering. Denna uppsats diskuterar NLPRL-resultaten i Shared Task-2 i WNUT-2020 workshop. Vi har betraktat detta problem som ett binärt klassificeringsproblem och har använt oss av en förklädd ELMo inbäddning med GRU-enheter. Detta tillvägagångssätt hjälper till att klassificera tweets med noggrannhet till 80,85% och 78,54% som F1-poäng på den angivna testdatauppsättningen. Experimentkoden finns tillgänglig online.', 'ta': 'கடந்த மாதங்களில் காரோனாவிரஸ் பேன்டெம்பு ஒரு செய்திகளை பெருமைப்படுத்திக் கொண்டிருக்கிறது. அதன் விரிவாக்கத்தை குறைக்க முயற்சிகள் செய்யப்பட்டுள்ளது மற்றும் புதிய பாதிப்புகளையும் குறைக்கவும். இந்த காரணத்திற்கு, பாதிக்கப்பட்ட மக்கள் பற்றிய தகவல்கள் மற்றும் அவர்களுடைய தொடர்புடைய குறிப்புகள் பற்றிய தகவல், சார்ந்த ஊடகங்களி இது துன்பத்தை மேலாண்மைக்கு சப்தமான உரை செயல்படுத்தல் உதாரணம். இந்த தாள் WNUT- 2020 workshops NLPRL பகிர்ந்த பணியின் முடிவுகளை பற்றி விவாதம் செய்கிறது. நாங்கள் இந்த பிரச்சனையை இருமறை வகுப்பு பிரச்சனையாக கருத்திருக்கிறோம் மற்றும் முன் பயிற்சிக்கப்பட்ட ELMo GRU அலக இந்த வழிமுறையில் கொடுக்கப்பட்ட சோதனை தரவுத்தளத்தில் F1- புள்ளியாக இருந்து தெளிவாக 80. 85% மற்றும் 78. 54% என்பதை வகுத்து  சோதனையின் குறியீடு இணையத்தில் உள்ளது.', 'ur': 'کوروناویروس پینڈمیک اگلوں مہینے کے لئے سوسیل میڈیا میں ایک اظہار ہے۔ اس کے پھیلانے اور گھاٹ کاٹنے کے لئے کوشش کی جاتی ہے اور نئی عفونت کو کاٹنے کے لئے۔ اس لئے، آلودہ لوگوں اور ان کے مرتبہ علائم کے بارے میں اطلاعات، جیسے سوسیل میڈیا میں موجود ہیں، جیسے ٹویٹر، پرہیزگاری اور پرہیزگاری کے لئے مدد کر سکتے ہیں. یہ ایک مثال ہے کہ مصیبت کی مدیریت کے لئے آہستہ ٹیکسٹ پرسس کا استعمال کرنا۔ This paper discusses the NLPRL results in Shared Task-2 of WNUT-2020 workshop. ہم نے اس مسئلہ کو بنیانی کلاسیفون مسئلہ بنایا ہے اور ہم نے GRU یونیٹوں کے ساتھ پیش تربین کی ELMo کا استعمال کیا ہے. This approach helps classify the tweets with accuracy 80.85% and 78.54% as F1-score on the provided test data set. آزمائش کوڈ آنلاین موجود ہے.', 'vi': 'Bệnh dịch Corona là một tin chủ yếu trên các phương tiện truyền thông xã hội trong nhiều tháng qua. Đang có nỗ lực để giảm lan rộng nó và giảm thiểu thương vong cũng như nhiễm trùng mới. Cho mục đích này, thông tin về những người bị nhiễm và các triệu chứng liên quan, có trên các phương tiện truyền thông xã hội, như Twitter, có thể giúp đỡ trong việc phòng ngừa và phòng ngừa. Đây là một ví dụ về việc xử lý văn bản ồn ào để xử lý thảm họa. Bài báo này bàn về kết quả của NLLLRL: Nhóm được chia sẻ Task-2 của tập đoàn Wsơ-2020. Chúng tôi đã xem vấn đề này như là một vấn đề phân loại nhị phân và đã sử dụng một loại ngập ElMo được đào tạo trước với đơn vị GRU. Cách tiếp cận này giúp phân loại các tweet với độ chính xác như 80.85. và 78.54. như F1-số trên tập tin thử nghiệm cung cấp. Các mã thử nghiệm đã có sẵn trên mạng.', 'uz': "Koronavirus pandemik bir necha oy ichida ijodkorlik media haqida xabar edi. Name Bu sababda, ko'proq odamlarning haqida maʼlumot va bog'liq symptomlari haqida xabar beradi, huddi Twitter kabi xabar yordam beradi va taqdim qilish mumkin. Name Bu qogʻoz WNUT-2020 ish workshopining qismlash natijalariga NLPRL natijalarini ajratish mumkin. Biz bu muammolarni ikkita darajalashtirish muammosi deb tasavvur qildik va birinchi taʼminlovchi ELMo GRU biriklari bilan birinchi taʼminlovchi ELMoni ishlatdik. Bu usulni koʻrsatilgan tizim maʼlumotlar tarkibida F1 qiymatiga 80.85% va 78.54% foydalanishiga foydalanadi. Name", 'da': 'Coronavirus pandemien har været en dominerende nyhed på sociale medier i de sidste mange måneder. Der gøres en indsats for at reducere dens spredning og reducere ofrene samt nye infektioner. Til dette formål kan oplysningerne om de inficerede mennesker og deres relaterede symptomer, som er tilgængelige på sociale medier, såsom Twitter, hjælpe med at forebygge og træffe forholdsregler. Dette er et eksempel på brug af støjende tekstbehandling til katastrofehåndtering. Dette dokument diskuterer resultaterne af NLPRL i Shared Task-2 i WNUT-2020 workshop. Vi har betragtet dette problem som et binært klassifikationsproblem og har brugt en forududdannet ELMo indlejring med GRU enheder. Denne fremgangsmåde hjælper med at klassificere tweets med nøjagtighed som 80,85% og 78,54% som F1-score på det leverede testdatasæt. Forsøgskoden er tilgængelig online.', 'bg': 'Пандемията от коронавирус е доминираща новина в социалните медии през последните месеци. Полагат се усилия за намаляване на разпространението му и намаляване на жертвите, както и на новите инфекции. За тази цел информацията за заразените хора и свързаните с тях симптоми, както е достъпна в социалните медии, като например Туитър, може да помогне за превенцията и вземането на предпазни мерки. Това е пример за използване на шумна текстова обработка за управление на бедствия. Настоящата статия разглежда резултатите от НЛПРЛ в споделена задача-2 на работната среща на WNUT-2020. Разгледахме този проблем като двоичен проблем за класификация и използвахме предварително обучен ЕЛМО вграждане с GRU единици. Този подход помага да се класифицират туитовете с точност като 80,85% и 78,54% като резултат на предоставения набор от тестови данни. Експерименталният код е достъпен онлайн.', 'nl': 'De Coronavirus pandemie is de afgelopen maanden een dominant nieuws op sociale media. Er worden inspanningen gedaan om de verspreiding ervan te verminderen en de slachtoffers en nieuwe infecties te verminderen. Daartoe kan de informatie over de besmette mensen en hun gerelateerde symptomen, zoals beschikbaar op sociale media, zoals Twitter, helpen bij preventie en het nemen van voorzorgsmaatregelen. Dit is een voorbeeld van het gebruik van lawaaierige tekstverwerking voor rampenbeheer. Deze paper bespreekt de NLPRL resultaten in Shared Task-2 van WNUT-2020 workshop. We hebben dit probleem gezien als een binair classificatieprobleem en hebben een vooraf getrainde ELMo embedding gebruikt met GRU units. Deze aanpak helpt de tweets met nauwkeurigheid te classificeren als 80,85% en 78,54% als F1-score op de geleverde testdataset. De experimentele code is online beschikbaar.', 'hr': 'Pandemija Koronavirusa bila je dominantna vijest u društvenim medijima posljednjih mnogo mjeseci. Snaži se smanjiti širenje i smanjiti žrtve kao i nove infekcije. Za tu svrhu, informacije o inficiranim ljudima i njihovim povezanim simptomima, kao što su dostupni na društvenim medijima, poput Twitter, mogu pomoći u prevenciji i uzimanju mjere opreza. To je primjer korištenja bučnog teksta za upravljanje katastrofama. Ovaj papir raspravlja o rezultatima NLPRL-a u delom zadatka-2 WNUT-2020 radionice. Smatrali smo ovaj problem kao problem sa binarnom klasifikacijom i koristili smo predobučenu ELMo ugrađenu s GRU jedinicama. Ovaj pristup pomaže klasifikirati tweets sa preciznošću kao 80,85% i 78,54% kao rezultat F1 na pruženom testnom setu podataka. Eksperimentalni kod je dostupan online.', 'id': 'Pandemi Coronavirus telah menjadi berita dominan di media sosial selama beberapa bulan terakhir. Berusaha untuk mengurangi penyebarannya dan mengurangi korban serta infeksi baru. Untuk tujuan ini, informasi tentang orang-orang yang terinfeksi dan gejala-gejala yang berhubungan dengan mereka, seperti yang tersedia di media sosial, seperti Twitter, dapat membantu dalam mencegah dan mengambil tindakan pencegahan. Ini adalah contoh menggunakan proses teks berisik untuk manajemen bencana. Kertas ini mendiskusikan hasil NLPRL dalam Task-2 Berkongsi dari workshop WNUT-2020. Kami telah mempertimbangkan masalah ini sebagai masalah klasifikasi binari dan telah menggunakan ELMo terlatih terlibat dengan unit GRU. pendekatan ini membantu mengklasifikasi tweet dengan akurasi sebagai 80,85% dan 78,54% sebagai skor F1 pada set data ujian yang diberikan. Kode eksperimen tersedia online.', 'de': 'Die Coronavirus-Pandemie ist seit vielen Monaten eine dominierende Nachricht in den sozialen Medien. Es werden Anstrengungen unternommen, ihre Ausbreitung zu verringern und die Zahl der Opfer sowie neuer Infektionen zu verringern. Zu diesem Zweck können die Informationen über die infizierten Menschen und ihre damit verbundenen Symptome, wie sie in sozialen Medien wie Twitter verfügbar sind, bei der Prävention und beim Treffen von Vorsichtsmaßnahmen helfen. Dies ist ein Beispiel für die Verwendung von lauter Textverarbeitung für das Katastrophenmanagement. Dieses Papier diskutiert die NLPRL Ergebnisse in Shared Task-2 des WNUT-2020 Workshops. Wir haben dieses Problem als binäres Klassifizierungsproblem betrachtet und eine vortrainierte ELMo-Einbettung mit GRU-Einheiten verwendet. Dieser Ansatz hilft, die Tweets mit Genauigkeit als 80,85% und 78,54% als F1-Score auf dem bereitgestellten Testdatensatz zu klassifizieren. Der experimentelle Code ist online verfügbar.', 'fa': 'پاندمیک کوروناویروس در مدت چند ماه گذشته در رسانه های اجتماعی اخبار dominant بوده است. تلاش برای کاهش گسترش و کاهش قربانی\u200cها و عفونت\u200cهای جدید انجام می\u200cشود. برای این هدف، اطلاعات راجع به مردم آلوده شده و علائم مربوط به آنها، همانطور که در رسانه\u200cهای اجتماعی، مثل توئیتر، می\u200cتوانند در پیشگیری و مواظب مراقبت کمک کنند. این مثال استفاده از پردازش متن صوتی برای مدیریت فاجعه است. این کاغذ در مورد نتیجه NLPRL در کارگاه WNUT-2020 مشترک شده است. ما این مشکل را به عنوان یک مشکل جدایی دوگانه به نظر گرفتیم و از یک ELMo پیش آموزش آموزش با واحدهای GRU استفاده کرده ایم. این دستور کمک می\u200cکند که توئیت\u200cها را با دقیق به 80.85% و 78.54% به عنوان نمونه\u200cهای F1 در مجموعه داده\u200cهای آزمایش داده می\u200cشوند. کد آزمایشی آنلاین موجود است.', 'tr': 'Koronavirusyň pandemiýasy soňky a ýlardan bäri sosyal medýýatlarynda öwrülen täzelikler bar. Jaglaryny azaltmak we täze hasaplaryny düşürmek üçin çabalar edilýär. Bu maksadyň üçin, hasaplanýan adamlar we olaryň ýaly syýahat hasaplarynda, Twitter ýaly sosyal medýýatlarda bolan ýaly, hasaplanýan adamlar hakynda maglumatlar önlemek we çykarmak üçin kömek edip biler. Bu gadyry müdiri üçin gaty metin işleýän ýaly. Bu kagyz NLPRL WNUT-2020 öýtgeýän işi-2 üçin paýlaşdy. Biz bu meseläni ikili klasifikasyýa mesele diýip pikir etdik we GRU birimleri bilen öňünden eğlenen ELMo bilen girişdirildik. Bu ýalaýyş tweetleri dogry bilen 80,85% we 78,54% berilen testiň düzümlerinde tertiblemek üçin kömekleyär. Denminaat ködleri internetde bar.', 'ko': '지난 몇 달간 코로나바이러스 팬데믹(세계적 대유행)은 소셜미디어의 주요 뉴스였다.그 전파를 줄이고 사상자와 새로운 감염을 줄이기 위해 노력하고 있다.이를 위해 트위터 등 소셜미디어에서 제공하는 감염자와 그 증상에 관한 정보는 예방과 예방 조치를 돕는다.이것은 시끄러운 텍스트 처리를 사용하여 재난 관리를 하는 예이다.본고는 WNUT-2020 세미나 공유 임무 2의 NLPRL 결과를 논의했다.우리는 이 문제를 이원 분류 문제로 간주하고 GRU 단원이 있는 예비 훈련 ELMo 삽입을 사용했다.이런 방법은 제공된 테스트 데이터 집합에서 트윗을 분류하는데 도움이 된다. 정확도는 80.85%이고 F1 점수는 78.54% 이다.실험 코드는 온라인으로 얻을 수 있다.', 'sw': 'Ugonjwa wa Koronavirus umekuwa ni habari zinazotawala kwenye mitandao ya kijamii kwa miezi mingi iliyopita. Juhudi zinazofanywa kupunguza usambazaji wake na kupunguza majeraha pamoja na maambukizi mapya. Kwa sababu hii, taarifa kuhusu watu walioathirika na dalili zao zinazohusiana, kama vile zinavyopatikana kwenye mitandao ya kijamii kama vile Twita, zinaweza kusaidia kuzuia na kuchukua tahadhari. Hii ni mfano wa kutumia ujumbe wa sauti kwa ajili ya utawala wa janga. Gazeti hili linajadili matokeo ya NLPRL katika warsha ya WNUT-2020. Tumechukua tatizo hili kama tatizo la kutangaza darasa la mbili na tumetumia ELMo lililojifunza kabla na vifaa vya GRU. Hatua hii inasaidia kutangaza twiti hizo kwa uhakika wa asilimia 80.85 na asilimia 78.54 kama score ya F1 kwenye seti ya taarifa zilizotolewa. Kodi la jaribio linapatikana mtandaoni.', 'am': 'ባለፉት ብዙ ወራት የቆሮናvirus ፍርሃት በማኅበራዊ አውታር ላይ ዜና አሸንፋለች፡፡ መዘርጊያውን እና የሞቱትን እና አዲስ ደዌዎች ለማጎድል ይሞክራሉ። ለዚህ ምክንያት የሆኑት ሰዎች እና የግንኙነት ምልክቶች በማኅበራዊ አውታር ላይ እንደትዊተር የተገኘ መረጃዎች በጥንቃቄ ለመጠበቅ እና ለመቀበል ይችላል፡፡ ይህ የድካም መከራ ማቀናኘት የድምፅ ጽሑፍ ማቀናቀል ምሳሌ ነው፡፡ ይህ ገጽ WNUT-2020 ሰርቨርስቲ የNLPRL ውጤቶች በተለየ ስራ-2 ውይይት ያስተካክላል፡፡ ይህንን መከራ በሁለተኛ መግለጫ መሆኑን አሰብተናል እና ከGRU ዩንቨርስቲ ጋር ተማርተናል፡፡ ይሄ ጥያቄ ትዊተቶችን በጥሩ 80.85 በመቶ እና 78.54 በመቶ F1-score በመስጠት ይረዳል፡፡ የፈተናው ኮድ በመስመር ላይ ነው፡፡', 'af': "Die Coronavirus pandemiek is 'n domineerde nuus op sosiale media vir die laaste veel maande. Om sy verspreiding te verminder en die gevaardighede en nuwe infeksies te verminder. Vir hierdie doel kan die inligting van die infekteerde mense en hulle verwante simptome, soos beskikbaar op sosiale media, soos Twitter, help in voorkoms en voorkoms te neem. Hierdie is 'n voorbeeld van gebruik van geluid teks verwerking vir katastrophebestuur. Hierdie papier bespreek die NLPRL resultate in deelde taak-2 van WNUT-2020 werkshop. Ons het hierdie probleem aangesien as 'n binêre klassifikasie probleem en het gebruik 'n vooraf opgelei ELMo inbêring met GRU eenhede. Hierdie toegang help klassifiseer die tweets met presies as 80. 85% en 78. 54% as F1- telling op die verskaf toets datastel. Die eksperimentele kode is beskikbaar online.", 'bn': 'The Coronavirus pandemic has been a dominating news on social media for the last many months.  তাদের ছড়িয়ে পড়ার জন্য প্রচেষ্টা করা হচ্ছে এবং তাদের ক্ষতিগ্রস্ত এবং নতুন আক্রান্ত ও কমিয়ে দেওয়ার জন্য। এই উদ্দেশ্যে, আক্রান্ত জনগণ এবং তাদের সংশ্লিষ্ট প্রতীক সম্পর্কের তথ্য, যেমন সামাজিক প্রচার মাধ্যম, যেমন টুইটার, সাহায্য করতে পা এটা দুর্যোগ ব্যবস্থাপনার জন্য আওয়াজের লেখা প্রক্রিয়ার উদাহরণ। এই প্রবন্ধে এনএলপিআরএলের ফলাফল শেয়ার করা হয়েছে WNUT-2020 কর্মশালায়। আমরা এই সমস্যাটিকে বাইনারি শ্রেণীবিভাগের সমস্যা হিসেবে বিবেচনা করেছি এবং পূর্ব প্রশিক্ষিত ইলমো ব্যবহার করেছি জিআরউ ইউনিটের এই পদক্ষেপ প্রদান করা পরীক্ষার ডাটাসেটে এফ১ স্কোর হিসেবে টুইটের সঠিকভাবে সাহায্য করে। পরীক্ষার কোড অনলাইনে পাওয়া যাচ্ছে।', 'bs': 'Pandemija Koronavirusa je bila dominantna vijest na društvenim medijima poslednjih mnogo mjeseci. Poticaju se da se smanji širenje i smanji žrtve, kao i nove infekcije. Za tu svrhu, informacije o inficiranim ljudima i njihovim povezanim simptomima, kao što su dostupni na društvenim medijima, poput Twitter, mogu pomoći u prevenciji i uzimanju mjere opreza. Ovo je primjer korištenja bučnog teksta za upravljanje katastrofama. Ovaj papir razgovara o rezultatima NLPRL-a u delom zadatka-2 WNUT-2020 radionice. Smatrali smo ovaj problem kao problem sa binarnom klasifikacijom i koristili smo predobučenu ELMo ugrađenu sa GRU jedinicama. Ovaj pristup pomaže da klasifikuju Tweets sa preciznošću kao 80,85% i 78,54% kao F1 rezultat na pruženoj testnoj seti podataka. Eksperimentalni kod je dostupan online.', 'az': 'Koronavirüs pandemisi son neçə ay boyunca sosyal mediyalarda dominantlı xəbərlər idi. Təşkiləri azaltmaq və ölümlərini və yeni infeksiyonları azaltmaq üçün çabalar edilir. Bu məqsədilə, təhlükəsizlər və əlaqəsizlər barəsindəki məlumatlar, Twitter kimi sosyal mediyalarda faydalanır və təhlükəsizlər almaq üçün kömək edə bilər. Bu fəsad idarəsi üçün səslü mətn işləməsini istifadə etmək məsəlinədir. Bu kağıt NLPRL paylaşılan Task-2-nin WNUT-2020 çalışmalarının sonuçlarını mübahisə edir. Biz bu problemi ikili klasifikasiya problemi kimi hesab etdik və GRU ünvanları ilə əvvəl təhsil edilmiş ELMo problemini kullandıq. Bu tərzim, təmin verilən verilənlər qutusunda F1-nöqtəsi olaraq 80,85% və 78,54% olaraq twetləri dəyişdirməyə kömək edir. Eksperiment kodu online faydalanır.', 'hy': 'Կորոնավիրուսի պանդեմիան վերջին մի քանի ամիս սոցիալական լրատվամիջոցների մասին գերիշխող նորություն է եղել: Efforts are being made to reduce its spread and reduce the casualties as well as new infections.  Այս նպատակով վարակված մարդկանց և նրանց կապված ախտանիշների մասին տեղեկատվությունը, ինչպես հասանելի են սոցիալական լրատվամիջոցներում, ինչպիսիք են Թվիթերը, կարող է օգնել կանխարգելու և կանխազգուշական միջոցներ անել: Սա աղմկոտ տեքստի վերամշակման օրինակ է աղետի ղեկավարման համար: Այս փաստաթղթին քննարկում է ՆԼՊԼ-ի արդյունքները ՀԱԿ-2020-ի համագործակցային հանձնարարության 2-ին: Մենք այս խնդիրը դիտարկեցինք որպես երկարային դասակարգման խնդիր և օգտագործեցինք նախապատրաստված ELMo-ը, որը ներառված է GRU-ի միավորներով: Այս մոտեցումը օգնում է թվիթերը ճշգրիտ դասակարգել 80.85 և 78.54 տոկոսով որպես F1-գնահատականներ տրամադրված փորձարկման տվյալների համակարգում: Փորձարկման կոդը առցանց հասանելի է:', 'sq': 'Pandemia e Koronavirusit ka qenë një lajm mbizotërues në mediat sociale për muajt e fundit. Po bëhen përpjekje për të reduktuar shpërndarjen e saj dhe për të reduktuar viktimat si dhe infeksionet e reja. For this purpose, the information about the infected people and their related symptoms, as available on social media, such as Twitter, can help in prevention and taking precautions.  Ky është një shembull i përdorimit të procesimit të zhurmshëm të tekstit për menaxhimin e fatkeqësive. Ky dokument diskuton rezultatet e NLPRL në punën e përbashkët 2 të seminarit WNUT-2020. We have considered this problem as a binary classification problem and have used a pre-trained ELMo embedding with GRU units.  Ky qasje ndihmon klasifikimin e tweeteve me saktësi si 80.85% dhe 78.54% si rezultat F1 në grupin e dhënave të dhëna të testimit. Kodi eksperimental është në dispozicion online.', 'ca': "La pandèmia del coronavirus ha estat una notícia dominant dels mitjans socials durant els darrers mesos. S'esforça per reduir la seva diferència i reduir les víctimes i les infeccions noves. Per aquest objectiu, la informació sobre les persones infectades i els seus símptomes relacionats, disponible als mitjans socials, com Twitter, pot ajudar a prevenir i prendre precaucions. Aquest és un exemple d'utilitzar un processament de text sorollós per a gestionar desastres. Aquest paper discute els resultats de la NLPRL en la tasca compartida 2 del taller WNUT-2020. Hem considerat aquest problem a com un problema de classificació binari i hem utilitzat un ELMo pré-entrenat integrat amb unitats GRU. Aquest enfocament ajuda a classificar els tweets amb precisió com a 80,85% i 78,54% com a puntuació F1 en el conjunt de dades de prova proporcionat. El codi experimental està disponible en línia.", 'cs': 'Pandemie koronaviru je v posledních měsících dominantní zprávou na sociálních médiích. Snaží se snížit jeho šíření a snížit počet obětí a nové infekce. Za tímto účelem mohou informace o infikovaných osobách a jejich souvisejících příznakách dostupné na sociálních médiích, jako je Twitter, pomoci při prevenci a přijímání opatření. Jedná se o příklad použití hlučného zpracování textu pro řízení havárie. Tento článek pojednává o výsledcích NLPRL ve sdíleném úkolu-2 workshopu WNUT-2020. Tento problém jsme považovali za binární klasifikační problém a použili jsme předem trénované ELMo embedding s GRU jednotkami. Tento přístup pomáhá klasifikovat tweety s přesností jako 80,85% a 78,54% jako skóre F1 na poskytnutém testovacím souboru. Experimentální kód je k dispozici online.', 'et': 'Koronaviiruse pandeemia on olnud sotsiaalmeedias domineeriv uudis viimastel kuudel. Tehakse jõupingutusi selle leviku vähendamiseks ja ohvrite ja uute nakkuste vähendamiseks. Sel eesmärgil võib sotsiaalmeedias (nt Twitteris) kättesaadav teave nakatunud inimeste ja nendega seotud sümptomite kohta aidata ennetada ja võtta ettevaatusabinõusid. See on näide müraka tekstitöötluse kasutamisest katastroofide ohjamiseks. Käesolevas dokumendis käsitletakse NLPRLi tulemusi WNUT-2020 seminari ühises ülesandes 2. Oleme pidanud seda probleemi kahekordse klassifitseerimise probleemiks ja kasutanud eelnevalt koolitatud ELMo manustamist GRU üksustega. See lähenemine aitab klassifitseerida säutsud täpsusega 80,85% ja 78,54% F1-skooriks esitatud testiandmete kogumis. Eksperimentaalne kood on kättesaadav internetis.', 'fi': 'Koronaviruspandemia on ollut hallitseva uutis sosiaalisessa mediassa viime kuukausina. Sen leviﾃ､mistﾃ､ ja uhrien mﾃ､ﾃ､rﾃ､ﾃ､ sekﾃ､ uusia infektioita pyritﾃ､ﾃ､n vﾃ､hentﾃ､mﾃ､ﾃ､n. Tﾃ､tﾃ､ tarkoitusta varten sosiaalisen median, kuten Twitterin, tiedot tartunnan saaneista ihmisistﾃ､ ja niihin liittyvistﾃ､ oireista voivat auttaa ennaltaehkﾃ､isyssﾃ､ ja varotoimien toteuttamisessa. Tﾃ､mﾃ､ on esimerkki meluisasta tekstinkﾃ､sittelystﾃ､ katastrofien hallinnassa. Tﾃ､ssﾃ､ artikkelissa kﾃ､sitellﾃ､ﾃ､n NLPRL-tuloksia WNUT-2020 -seminaarin yhteisessﾃ､ tehtﾃ､vﾃ､ssﾃ､ 2. Olemme kﾃ､sitelleet tﾃ､tﾃ､ ongelmaa binﾃ､ﾃ､riluokitteluongelmana ja kﾃ､yttﾃ､neet ennalta koulutettua ELMo-upotusta GRU-yksikﾃｶihin. Tﾃ､mﾃ､ lﾃ､hestymistapa auttaa luokittelemaan tweetit tarkkuudella 80,85% ja 78,54% F1-pisteeksi toimitetussa testiaineistossa. Kokeellinen koodi on saatavilla verkossa.', 'jv': 'Pandimik ya, coronês sembarang pengalaman sing ngupakaké alam sing mengko media sotiki banjur akeh lunak. Wis Nanging iki, informasi ning babagan kelas karo perbudhakan langgar lan sembarang wong liyane, koyo supoyo Perusahaan media sarah, kaya Tuter, iso bantuan kanggo ngerasai kanggo ngerasai layanan lan kelas. Iki hakan kanggo ngilangno sistem sing nggawe barang-barang seneng pisan kanggo ngilangno dolanan pangan. Perintah iki diputamong NLPRL maneh nang daftar share task-2 of WNUT-2020 Workspace Anyone here Ndoleh iki bantuan nglanggar kelas kuwi tiket nggawe geranggawe geranggawe geranggambar luwih saben nggambar dolang karang-saben % Kod sing paling nggo online', 'sk': 'Pandemija koronavirusa je v zadnjih mesecih prevladujoča novica na družbenih omrežjih. Prizadevajo si za zmanjšanje širjenja in zmanjšanje števila žrtev ter novih okužb. V ta namen lahko informacije o okuženih osebah in z njimi povezanih simptomih, ki so na voljo na družbenih omrežjih, kot je Twitter, pomagajo pri preprečevanju in sprejemanju previdnostnih ukrepov. To je primer uporabe hrupne obdelave besedila za obvladovanje nesreč. V tem članku so obravnavani rezultati NLPRL na delavnici skupne naloge 2 WNUT-2020. To težavo smo obravnavali kot problem binarne klasifikacije in uporabili vnaprej usposobljeno vgradnjo ELMo z enotami GRU. Ta pristop pomaga razvrstiti tweete natančno kot 80,85% in 78,54% kot F1-rezultat na zagotovljenem testnem naboru podatkov. Eksperimentalna koda je na voljo na spletu.', 'ha': "Hazarar Coronavus ta kasance mai domin lãbãri a kan mitandaki na jamii cikin watanni kaɗan. Ana aikin su dõmin su ƙara kafaffiyarsa kuma su ƙara hasara da waɗanan nan da yanzu. To, sabõda wannan, information za'a iya gaya wa wasu mutane da alama masu hushi, kamar da za'a iya sãmun su a kan mitandaya masu ƙarami, kamar misãlin Twitter, za'a iya taimakon ka da hanyõyin hanyoyi. Wannan misali ne da ya yi amfani da matsayin sauti wa manajan katastro. Wannan karatun yana jãyayyar da matsalar na NLPRL cikin Shared Tafiyar-2 of WNUT-2020. Mun ƙaddara wannan muammãni kamar wata fitina na biyu kuma mun yi amfani da ELMo da ya shiga a gaba ɗaya da GRU guda. Wannan shiryarwa na taimakon su rarraba wateten da taƙaitacce kamar 80.85% da 78.54% kamar F1-score kan danne-danne da aka ƙayyade. Kodi na jarraba, yana da akwatin bayani.", 'he': 'פנדמיה הקורונוירוס הייתה חדשות שולטות בתקשורת חברתית בחודשים רבים האחרונים. Efforts are being made to reduce its spread and reduce the casualties as well as new infections.  למטרה זו, המידע על האנשים המדבקים והתסמינים הקשורים שלהם, כפי שזמינים בתקשורת חברתית, כמו טוויטר, יכול לעזור למנוע ולקחת אמצעים זהירות. זהו דוגמה של השימוש בעבודת טקסט רעש לניהול אסון. העבודה הזו מדברת על תוצאות NLPRL במשימה משותפת 2 של מסעדה WNUT-2020. חשבנו על הבעיה הזאת כבעיה בינרית של מסווג והשתמשנו באליפות ELMo מאומנת מראש עם יחידות GRU. This approach helps classify the tweets with accuracy as 80.85% and 78.54% as F1-score on the provided test dataset.  הקוד הניסויי זמין באינטרנט.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྟངས་འཛིན་གྱི་ཟླ་བ་མང་པོ་ཞིག་གིས་ དེའི་བཟོ་བརྩོན་བྱས་ན་རང་གི་དྲ་རྒྱ་བསྐྱེད་ཚད་ཉེན་རུ་གཏོང་བ་དང་ཤི་རྐྱེན་ཚད་ཉེན་ཡོད། དམིགས་ཡུལ་འདིས་སྤྱི་ཚོགས་འབྲེལ་བའི་མི་མང་ཚོའི་གནས་ཚུལ་དང་ཁོང་ཚོའི་འབྲེལ་བའི་རྐྱེན་ཚུལ་གྱི་གནས་ཚུལ། འདི་ནི་དབུལ་དོ་དམ་ལ་བརྡ་སྟོང་པའི་ཡིག་གེ་བཀོལ་སྤྱོད་པའི་དཔེ་བརྗོད། ཤོག་བྱང་འདིས་NLPRL འདི་གིས་མཉམ་དུ་འཇུག་སའི་བྱ་རིམ་2 WNUT-2020་ལས་ཀ་བརྗོད་ཐུབ་ཀྱི་ཡོད། We have considered this problem as a binary classification problem and have used a pre-trained ELMo embedding with GRU units. འདིས་གཟུགས་འདིས་བྱིན་པའི་བརྟག་ཞིབ་ཚད་སྒྲིག་འཛུགས་ཀྱི་ཚོགས་སྟངས་དང་མཉམ་དུ་འགྱུར་བ་སྤྱོད་ཀྱི་ཡོད། ལག་ལེན་པའི་ཨང་རྟགས་དྲ་ཐོག་ཡོད་པ'}
{'en': 'ComplexDataLab at W-NUT 2020 Task 2 : Detecting Informative COVID-19 Tweets by Attending over Linked Documents C omplex D ata L ab at  W - NUT  2020 Task 2: Detecting Informative  COVID -19 Tweets by Attending over Linked Documents', 'ar': 'ComplexDataLab في W-NUT 2020 المهمة 2: الكشف عن تغريدات COVID-19 الإعلامية من خلال الحضور على المستندات المرتبطة', 'pt': 'ComplexDataLab no W-NUT 2020 Tarefa 2: detectando tweets informativos sobre COVID-19 participando de documentos vinculados', 'es': 'ComplexDataLab en la Tarea 2 de W-NUT 2020: Detección de tweets informativos sobre COVID-19 asistiendo a documentos vinculados', 'fr': 'ComplexDataLab au W-NUT 2020 Task 2\xa0: Détecter les tweets informatifs sur la COVID-19 en participant à des documents liés', 'zh': 'ComplexDataLab在W-NUT 2020务2:参链接文档以检繁COVID-19推文', 'ja': 'W - NUT 2020のComplexDataLabタスク2 ：リンクされたドキュメントに参加することによる新型コロナウイルス感染症(COVID -19)に関する有益なツイートの検出', 'hi': 'W-NUT 2020 टास्क 2 पर ComplexDataLab: लिंक किए गए दस्तावेज़ों पर भाग लेकर जानकारीपूर्ण कोविड -19 ट्वीट्स का पता लगाना', 'ru': 'ComplexDataLab на W-NUT 2020 Задача 2: Обнаружение информационных твитов о COVID-19 путем посещения связанных документов', 'ga': 'ComplexDataLab ag W-NUT 2020 Tasc 2: Tweetanna Faisnéiseacha COVID-19 a Bhrath Trí Fhreastal ar Dhoiciméid Nasctha', 'ka': 'Comment', 'hu': 'A ComplexDataLab a W-NUT 2020 második feladatában: Információs COVID-19 tweetek felismerése összekapcsolt dokumentumok részvételével', 'el': 'Εργασία 2: Ανίχνευση πληροφοριακών tweets παρακολουθώντας συνδεδεμένα έγγραφα', 'it': 'Compito 2 di ComplexDataLab al W-NUT 2020: rilevare i tweet informativi COVID-19 partecipando ai documenti collegati', 'kk': 'ComplexDataLab at W-NUT 2020 Task 2: Informative COVID-19 Tweets Detecting by Linked Documents', 'lt': 'ComplexDataLab W-NUT 2020 2 užduotis: Informacinių COVID-19 Tweetų aptikimas dalyvaujant per susijusius dokumentus', 'mk': 'ComplexDataLab на W-NUT 2020 задача 2: Детектирање информативни твитови COVID-19 со присуство преку поврзани документи', 'ms': 'DataLab Kompleks pada Tugas 2 W-NUT 2020: Mengesan Tweet Informatif COVID-19 dengan Menampilkan Dokumen Berpautan', 'ml': 'ComplexDataLab at W- NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'mt': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'mn': 'ComplexDataLab at W-NUT 2020 Task 2: Informative COVID-19 Tweets Detecting by Attended over Linked Documents', 'no': 'ComplexDataLab at W-NUT 2020 Task 2: Finn informativ COVID-19 Tweets ved å delta over lenka dokument', 'pl': 'ComplexDataLab w W-NUT 2020 Zadanie 2: Wykrywanie informacyjnych tweetów COVID-19 poprzez udział w powiązanych dokumentach', 'ro': 'ComplexDataLab la sarcina 2 a W-NUT 2020: detectarea tweeturilor informative COVID-19 prin participarea la documentele conectate', 'sr': 'ComplexDataLab na zadatku 2. W-NUT 2020: otkrivanje informativnih tviteta COVID-19 pridružujući se povezanim dokumentima', 'si': 'සම්පූර්ණ දත්ත ලේබ් W-NAT 2020වැඩ 2: තොරතුරු COVID-19 ට්විට් පරීක්ෂණය කරන්න', 'so': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'sv': 'ComplexDataLab på W-NUT 2020 Uppgift 2: Att upptäcka informativa COVID-19 tweets genom att delta i länkade dokument', 'ta': 'சிக்கல் தரவுLab at W- NUT 2020 Task 2: Detecting Informative COVID- 19 Tweets by Attending over Linked Documents', 'ur': 'W-NUT 2020 ٹاکس 2 میں کاملکس ڈاٹا لاب: لینک ڈکومکینٹ پر حاضر ہونے کے ذریعہ معلومات کی COVID-19 ٹویٹ پتچا رہی ہے', 'uz': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'vi': 'KCharselect unicode block name tại tập tin nóng hổi', 'bg': 'Задача 2: Откриване на информативни туитове чрез участие върху свързани документи', 'da': 'ComplexDataLab på W-NUT 2020 Opgave 2: Opdagelse af informative COVID-19 tweets ved at deltage i linkede dokumenter', 'nl': 'ComplexDataLab bij W-NUT 2020 Taak 2: Informatieve COVID-19 Tweets detecteren door het bijwonen van gekoppelde documenten', 'hr': 'ComplexDataLab na zadatku 2. W-NUT 2020: otkrivanje informativnih tviteta COVID-19', 'de': 'ComplexDataLab bei W-NUT 2020 Aufgabe 2: Erkennen von informativen COVID-19 Tweets durch den Besuch verlinkter Dokumente', 'id': 'ComplexDataLab di W-NUT 2020 Task 2: Detektif Informatif COVID-19 Tweets oleh Attending over Linked Documents', 'ko': 'W-NUT 2020년의 ComplexDataLab Task2: 링크된 문서를 보면서 풍부한 정보를 제공하는 코로나 트윗 탐지', 'fa': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'sw': 'ComplexDataLab at W-NUT 2020 Task 2: Kuchunguza Informative COVID-19 Twities by Attending over Documents Linked', 'tr': 'ComplexDataLab at W-NUT 2020 Task 2: Informative COVID-19 Tweets Detecting by Attending over Linked Documents', 'af': 'Kompleksie DataLab by W-NUT 2020 Opdrag 2: Kies inligtige COVID-19 Tweets deur Aangaande oor gekoppelde dokumente', 'sq': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'am': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'hy': 'Comment', 'az': "W-NUT 2020 Task 2'd…ô ComplexDataLab: BańülanmńĪŇü Belg…ôl…ôr √ľz…ôrind…ô iŇütirak ed…ôr…ôk Informativ COVID-19 Tweets keŇüif edilir", 'bs': 'ComplexDataLab na zadatku 2. W-NUT 2020: otkrivanje informativnih tviteta COVID-19', 'bn': 'ডি- এনউট ২০২০ কাজ ২: তথ্য তথ্য প্রদান করা হয়েছে কোভিড- ১৯ টুইটের মাধ্যমে লিঙ্ক করা ডকুমেন্ট', 'ca': 'ComplexDataLab a W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents', 'cs': 'ComplexDataLab na W-NUT 2020 Úkol 2: Detekce informačních tweetů COVID-19 pomocí účasti na propojených dokumentech', 'et': 'ComplexDataLab W-NUT 2020 ülesanne 2: informatiivsete COVID-19 tweetide tuvastamine lingitud dokumentide kaudu', 'fi': 'ComplexDataLab W-NUT 2020 -tapahtumassa Tehtävä 2: Informatiivisten COVID-19-twiittien tunnistaminen osallistumalla linkitettyihin asiakirjoihin', 'ha': 'KCharselect unicode block name', 'jv': 'CompletexdataLab at W-NUT 2020', 'he': 'משימה 2: גילוי טוויטים מידעיים COVID-19 על ידי להשתתף מעל מסמכים מקושרים', 'sk': 'ComplexDataLab na W-NUT 2020 Naloga 2: odkrivanje informativnih Tweets COVID-19 z udeležbo prek povezanih dokumentov', 'bo': 'ComplexDataLab at W-NUT 2020 Task 2: Detecting Informative COVID-19 Tweets by Attending over Linked Documents'}
{'en': 'Given the global scale of COVID-19 and the flood of social media content related to it, how can we find informative discussions? We present Gapformer, which effectively classifies content as informative or not. It reformulates the problem as  graph classification , drawing on not only the tweet but connected webpages and entities. We leverage a pre-trained language model as well as the connections between nodes to learn a pooled representation for each document network. We show it outperforms several competitive baselines and present ablation studies supporting the benefit of the linked information. Code is available on Github.', 'ar': 'بالنظر إلى النطاق العالمي لـ COVID-19 وتدفق محتوى الوسائط الاجتماعية المرتبط به ، كيف يمكننا العثور على مناقشات مفيدة؟ نقدم Gapformer ، الذي يصنف المحتوى بشكل فعال على أنه إعلامي أم لا. يعيد صياغة المشكلة كتصنيف للرسم البياني ، لا يعتمد على التغريدة فحسب ، بل على صفحات الويب والكيانات المتصلة. نحن نستفيد من نموذج اللغة الذي تم تدريبه مسبقًا بالإضافة إلى الاتصالات بين العقد لمعرفة التمثيل المجمع لكل شبكة مستندات. نظهر أنه يتفوق على العديد من خطوط الأساس التنافسية ونقدم دراسات الاجتثاث التي تدعم الاستفادة من المعلومات المرتبطة. الكود متاح على جيثب.', 'fr': "Compte tenu de l'ampleur mondiale de la COVID-19 et du flot de contenus sur les réseaux sociaux qui y sont liés, comment pouvons-nous trouver des discussions informatives\xa0? Nous présentons Gapformer, qui classe efficacement le contenu comme informatif ou non. Il reformule le problème sous la forme d'une classification graphique, en s'appuyant non seulement sur le tweet, mais aussi sur les pages Web et les entités connectées. Nous tirons parti d'un modèle linguistique pré-formé ainsi que des connexions entre les nœuds pour apprendre une représentation groupée pour chaque réseau de documents. Nous montrons qu'il surpasse plusieurs niveaux de référence concurrentiels et présentons des études d'ablation qui confirment les avantages des informations liées. Le code est disponible sur Github.", 'pt': 'Dada a escala global do COVID-19 e a enxurrada de conteúdo de mídia social relacionado a ele, como podemos encontrar discussões informativas? Apresentamos o Gapformer, que efetivamente classifica o conteúdo como informativo ou não. Ele reformula o problema como classificação de grafos, baseando-se não apenas no tweet, mas em páginas e entidades conectadas. Aproveitamos um modelo de linguagem pré-treinado, bem como as conexões entre nós para aprender uma representação agrupada para cada rede de documentos. Mostramos que ele supera várias linhas de base competitivas e apresentamos estudos de ablação que apoiam o benefício das informações vinculadas. O código está disponível no Github.', 'es': 'Dada la escala mundial de COVID-19 y la avalancha de contenido de las redes sociales relacionado con ella, ¿cómo podemos encontrar debates informativos? Presentamos Gapformer, que clasifica eficazmente el contenido como informativo o no. Reformula el problema como clasificación gráfica, basándose no solo en el tweet, sino también en las páginas web y entidades conectadas. Aprovechamos un modelo de lenguaje previamente entrenado, así como las conexiones entre nodos para aprender una representación agrupada para cada red de documentos. Demostramos que supera a varios puntos de referencia de la competencia y presentamos estudios de ablación que respaldan el beneficio de la información vinculada. El código está disponible en Github.', 'ja': '新型コロナウイルスの世界的な規模とそれに関連するソーシャルメディアコンテンツの氾濫を考えると、情報に基づいた議論を見つけるにはどうすればよいでしょうか？ Gapformerをご紹介します。Gapformerは、コンテンツを情報提供型かどうかに効果的に分類しています。ツイートだけでなく、接続されたウェブページやエンティティを利用して、問題をグラフ分類として再定義します。事前にトレーニングされた言語モデルとノード間の接続を活用して、各ドキュメントネットワークのプールされた表現を学習します。いくつかの競合ベースラインを上回る性能を示し、リンクされた情報の利点を裏付けるアブレーション研究を提示しています。コードはGithubで利用できます。', 'zh': '鉴COVID-19之全球规模,关之社交媒体泛滥,何以得息? 推出Gapformer,分类信息性否。 重表图形,非唯用推文,兼用网页实。 吾以豫训之言模形及节点之属而学文档网络之池。 证其优于数竞基线,并建支链接消息之益。 代码可得于Github。', 'hi': 'कोविड-19 के वैश्विक स्तर और इससे संबंधित सोशल मीडिया सामग्री की बाढ़ को देखते हुए, हम जानकारीपूर्ण चर्चाओं को कैसे पा सकते हैं? हम Gapformer, जो प्रभावी ढंग से जानकारीपूर्ण या नहीं के रूप में सामग्री वर्गीकृत प्रस्तुत करते हैं. यह ग्राफ वर्गीकरण के रूप में समस्या को फिर से तैयार करता है, न केवल ट्वीट पर बल्कि जुड़े वेबपृष्ठों और संस्थाओं पर ड्राइंग करता है। हम प्रत्येक दस्तावेज़ नेटवर्क के लिए एक पूल किए गए प्रतिनिधित्व को सीखने के लिए एक पूर्व-प्रशिक्षित भाषा मॉडल के साथ-साथ नोड्स के बीच कनेक्शन का लाभ उठाते हैं। हम दिखाते हैं कि यह कई प्रतिस्पर्धी बेसलाइन को मात देता है और लिंक की गई जानकारी के लाभ का समर्थन करने वाले एब्लेशन अध्ययनों को प्रस्तुत करता है। कोड Github पर उपलब्ध है।', 'ru': 'Учитывая глобальный масштаб COVID-19 и поток связанного с ним контента в социальных сетях, как мы можем найти информативные дискуссии? Мы представляем Gapformer, который эффективно классифицирует контент как информативный или нет. Он переформулировал проблему как классификацию графиков, опираясь не только на твит, но и на связанные веб-страницы и сущности. Мы используем предварительно обученную языковую модель, а также соединения между узлами для изучения объединенного представления для каждой сети документов. Мы показываем, что она превосходит несколько конкурентных базовых уровней, и представляем исследования абляции, подтверждающие преимущества связанной информации. Код доступен на Github.', 'ga': 'I bhfianaise scála domhanda COVID-19 agus an tuile d’ábhar meán sóisialta a bhaineann leis, conas is féidir linn teacht ar phlé faisnéiseach? Cuirimid i láthair Gapformer, a rangaíonn go héifeachtach ábhar mar ábhar faisnéiseach nó nach bhfuil. Déanann sé an fhadhb a athfhoirmliú mar aicmiú graif, ag tarraingt ar ní amháin ar an tweet ach ar leathanaigh ghréasáin agus ar eintitis nasctha. Déanaimid giaráil ar mhúnla teanga réamh-oilte chomh maith leis na naisc idir nóid chun ionadaíocht chomhthiomsaithe a fhoghlaim do gach líonra doiciméad. Léirímid go sáraíonn sé roinnt bonnlínte iomaíocha agus cuirimid i láthair staidéir eisiblithe a thacaíonn le leas na faisnéise nasctha. Tá cód ar fáil ar Github.', 'ka': 'COVID-19 და სოციალური მედია შემდგომარების გარეშე, როგორ ჩვენ შეგვიძლია ინფორმაციური განსაზღვრებების შესახებ? ჩვენ Gapformer-ს გაჩვენებთ, რომელიც ეფექტიურად ინფორმატიურად კლასიფიკურებს ინფორმატიურად. ეს პრობლემა როგორც გრაფიკაცია კლასიფიკაცია, არა მხოლოდ გრაფიკაცია, მაგრამ დაკავშირებული ვებ გვერდები და ინტერტიები. ჩვენ წინ განსწავლა ენის მოდელს, და კოსტუმენტების კავშირები, რომ ყველა დოკუმენტების ქსელისთვის შესწავლათ ერთადერთი გამოსახულება. ჩვენ ამას ჩვენ ჩვენ აჩვენებთ რამდენიმე კონსპექტიური ბაზი სტრიქონის გარეშე და ახლა მომხმარებული კონსპექტიური სტრიქონის გარეშე კჲე ვ ნა დთრსბ.', 'hu': 'Tekintettel a COVID-19 globális méretére és az ehhez kapcsolódó közösségi média tartalmak áradatára, hogyan találhatunk információs beszélgetéseket? Bemutatjuk a Gapformert, amely hatékonyan tájékoztatónak vagy nem minősíti a tartalmat. Újraformálja a problémát grafikonosztályozásként, nemcsak a tweet, hanem a kapcsolódó weboldalak és entitások alapján. Az előre képzett nyelvi modellt, valamint a csomópontok közötti kapcsolatokat használjuk, hogy megtanuljuk az egyes dokumentumhálózatok összesített ábrázolását. Bemutatjuk, hogy több versenyképes alapvető értéket is felülmúlja, és a kapcsolódó információk előnyeit támogató ablációs tanulmányokat mutatunk be. A kód elérhető a Github-on.', 'el': 'Λαμβάνοντας υπόψη την παγκόσμια κλίμακα του και την πλημμύρα περιεχομένου κοινωνικών μέσων που σχετίζεται με αυτό, πώς μπορούμε να βρούμε ενημερωτικές συζητήσεις; Παρουσιάζουμε το το οποίο ταξινομεί αποτελεσματικά το περιεχόμενο ως ενημερωτικό ή όχι. Επαναδιατυπώνει το πρόβλημα ως ταξινόμηση γραφής, αντλώντας όχι μόνο το tweet αλλά συνδεδεμένες ιστοσελίδες και οντότητες. Χρησιμοποιούμε ένα προ-εκπαιδευμένο γλωσσικό μοντέλο καθώς και τις συνδέσεις μεταξύ κόμβων για να μάθουμε μια συγκεντρωμένη αναπαράσταση για κάθε δίκτυο εγγράφων. Δείχνουμε ότι ξεπερνά αρκετές ανταγωνιστικές βάσεις και παρουσιάζουμε μελέτες αφαίρεσης που υποστηρίζουν το όφελος των συνδεδεμένων πληροφοριών. Ο κώδικας είναι διαθέσιμος στο Github.', 'it': "Data la portata globale del COVID-19 e l'inondazione di contenuti social media ad esso correlati, come possiamo trovare discussioni informative? Presentiamo Gapformer, che classifica efficacemente i contenuti come informativi o meno. Riformula il problema come classificazione dei grafici, attingendo non solo al tweet ma anche alle pagine web e alle entità collegate. Sfruttamo un modello linguistico pre-addestrato e le connessioni tra nodi per imparare una rappresentazione condivisa per ogni rete di documenti. Mostriamo che supera diverse linee di base competitive e presentiamo studi di ablazione a sostegno dei benefici delle informazioni collegate. Il codice è disponibile su Github.", 'lt': 'Atsižvelgiant į pasaulinį COVID-19 mastą ir su juo susijusią socialinės žiniasklaidos turinio potvynį, kaip galime rasti informacines diskusijas? Mes pristatome Gapformer, kuris veiksmingai klasifikuoja turinį kaip informacinį ar ne. Ji iš naujo apibrėžia problem ą kaip grafikų klasifikavimą, remdamasi ne tik tweetu, bet ir susijusiais tinklalapiais ir subjektais. Mes naudojame iš anksto parengtą kalbos model į ir jungtis tarp mazgų, kad sužinotume bendrą atstovavimą kiekvienam dokumentų tinklui. Mes parodome, kad ji viršija kelis konkurencinius bazinius rodiklius ir atlieka abliacijos tyrimus, kuriais remiama susijusios informacijos nauda. Kodas pateiktas Github adresu.', 'kk': 'COVID-19 жүйелік мазмұны және социалдық медиақтың мазмұны қалай таба аламыз? Біз Gapformer-ді таңдаймыз, бұл мазмұның мазмұнын мәлімет ретінде шектеп береді. Бұл мәселеді графикалық классификациясы ретінде реформалдайды, тек tweet- ті емес, бірақ қосылған веб- парақтар мен нысандар ретінде сызылады. Біз әрбір құжат желінің біріктірілген түрлі үлгісін оқыту үшін алдын- оқылған тіл үлгісін және түрлер арасындағы қосылымдарды көмектесеміз. Біз оны бірнеше конкуренциялық негізгі сызықтар және қосылған мәліметтердің пайдалануын қолдау зерттеулерін көрсетедік. Github- де код бар.', 'mk': 'Со оглед на глобалната скала на COVID-19 и поплавата на социјалните медиуми поврзана со неа, како можеме да најдеме информативни дискусии? Го претставуваме Gapformer, кој ефикасно ја класификува содржината како информативна или не. Истиот го реформира проблемот како класификација на график, врз основа не само на Твитер туку и поврзани веб-страници и ентитети. Ние користиме предобучен јазички модел како и врските меѓу јазлите за да научиме заедничко претставување за секоја мрежа на документи. Ние покажуваме дека истата надминува неколку конкурентни основни линии и претставуваме аплациски студии кои ја поддржуваат користта од поврзаните информации. Кодот е достапен на Гитуб.', 'ms': 'Mengingat skala global COVID-19 dan banjir kandungan media sosial yang berkaitan dengannya, bagaimana kita boleh mencari perbincangan informatif? Kami memperkenalkan Gapformer, yang secara efektif mengklasifikasikan kandungan sebagai maklumat atau tidak. Ia menyatakan semula masalah sebagai klasifikasi graf, melukis bukan sahaja tweet tetapi halaman web dan entiti tersambung. Kami menggunakan model bahasa yang dilatih-dilatih serta sambungan antara nod untuk belajar perwakilan berkumpul untuk setiap rangkaian dokumen. Kami tunjukkan ia melebihi beberapa garis dasar kompetitif dan mempersembahkan kajian ablasi yang menyokong keuntungan maklumat terhubung. Kod tersedia pada Github.', 'ml': 'കോവിഡി-19 ലെ ഗ്ലോക സ്കാലോക സ്കൂളില്\u200d നിന്നും അതിനോട് ബന്ധപ്പെട്ട സാമൂഹ്യ മീഡിയ വിഭവങ്ങളുടെ വെള്ളപ്പൊക്കം,  ഞങ്ങള്\u200d ഗാപ്ഫോര്\u200dമാനെ കാണിക്കുന്നു, അത് വിവരങ്ങള്\u200d വിവരങ്ങളായി വിശദീകരിക്കുന്നു അത് പ്രശ്നം ഗ്രാഫ് ക്ലാസ്ഫികേഷനായി മാറ്റുന്നു. ട്രൂട്ടില്\u200d മാത്രമല്ല, വെബ് പേജുകളും വസ്തുക്കളും ബന്ധിച്ചി നോഡുകള്\u200dക്കിടയിലുള്ള ബന്ധങ്ങളും എല്ലാ രേഖകളുടെ ശേഖരിക്കുവാനുള്ള പ്രതിനിധി പഠിപ്പിക്കാന്\u200d ഞങ്ങള്\u200d മുന്\u200dപ് പരിശീ നമ്മള്\u200d അതിനെ കാണിച്ചു കൊടുക്കുന്നത് കുറച്ച് മത്സരത്തിലുള്ള ബേസ്ലെയിനുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. കൂ ഗിത്തുബില്\u200d കോഡ് ലഭ്യമാണ്.', 'mt': 'Minħabba l-iskala globali tal-COVID-19 u l-għargħar tal-kontenut tal-midja soċjali relatat miegħu, kif nistgħu nsibu diskussjonijiet informattivi? Aħna nippreżentaw Gapformer, li effettivament jikklassifika l-kontenut bħala informattiv jew le. Hija tirriformula l-problema bħala klassifikazzjoni tal-graff, billi tibbaża mhux biss fuq it-tweet iżda fuq il-paġni u l-entitajiet tal-internet konnessi. Nixprunaw mudell lingwistiku mħarreġ minn qabel kif ukoll il-konnessjonijiet bejn in-nodi biex nitgħallmu rappreżentanza miġbura flimkien għal kull netwerk ta’ dokumenti. Aħna nuru li dan jaqbeż diversi linji bażi kompetittivi u nippreżentaw studji ta’ abblazzjoni li jappoġġjaw il-benefiċċju tal-informazzjoni marbuta. Il-kodiċi huwa disponibbli fuq Github.', 'mn': 'COVID-19-ын дэлхийн хэмжээнд, нийгмийн мэдээллийн агууллагуудын нүүрстөрөгчийн салбарт хэрхэн мэдээллийн ярилцлага олж болох вэ? Бид Gapformer-г илтгэдэг. Энэ бүхнийг мэдээллийн хэлбэрээр хуваалцдаг. Энэ асуудлыг график хэлбэрээр шинэчлүүлдэг, зөвхөн tweet дээр зурах биш, холбоотой веб-хуудас болон бүтцийг шинэчлүүлдэг. Бид өмнө сургалтын хэл загварыг, баримт сүлжээ бүрт нийлүүлсэн үзүүлэлтийг сурах холбоотой холбоотой байгууллагыг ашиглаж байна. Бид үүнийг хэдэн өрсөлдөг суурь шугам болон холбоотой мэдээллийн ашиг дэмжиж байгааг харуулж байна. Github дээр код хангалттай.', 'no': 'Given den globale skala av COVID-19 og overføringa av sosiale media-innhaldet som er relatert med det, korleis kan vi finne informative diskusionar? Vi presenterer Gapformer, som effektivt klassifiserer innhaldet som informativt eller ikkje. Det reformerer problemet som grafikkklassifikasjon, teiknar på ikkje berre tweet, men tilkopla nettsider og einingar. Vi leverer eit før- treng språk- modell, og tilkoplingane mellom noder for å lære eit pooled representasjon for kvar dokumentnettverk. Vi viser at det utfører fleire konkurentære baselinjer og gjeldande aktiveringsstudiar som støttar fordel av den tilknytte informasjonen. Kode er tilgjengeleg på Github.', 'pl': 'Biorąc pod uwagę globalną skalę COVID-19 i powiązaną z nią zalewę treści mediów społecznościowych, jak możemy znaleźć informacyjne dyskusje? Prezentujemy Gapformer, który skutecznie klasyfikuje treści jako informacyjne lub nie. Przeformułowuje problem jako klasyfikację wykresu, czerpiąc nie tylko z tweeta, ale połączonych stron internetowych i podmiotów. Wykorzystujemy wstępnie przeszkolony model językowy, a także połączenia między węzłami, aby nauczyć się zbiorowej reprezentacji dla każdej sieci dokumentów. Pokazujemy, że przewyższa kilka konkurencyjnych linii bazowych i przedstawiamy badania ablacji wspierające korzyści z powiązanych informacji. Kod jest dostępny na Github.', 'ro': 'Având în vedere amploarea globală a COVID-19 și inundația de conținut social media aferent acestuia, cum putem găsi discuții informative? Vă prezentăm Gapformer, care clasifică în mod eficient conținutul ca informativ sau nu. Reformulează problema ca clasificare grafică, bazându-se nu numai pe tweet, ci și pe pagini web conectate și entități. Folosim un model lingvistic pre-instruit, precum și conexiunile dintre noduri pentru a învăța o reprezentare comună pentru fiecare rețea de documente. Am arătat că depășește mai multe linii de referință competitive și prezentăm studii de ablație care susțin beneficiul informațiilor conexe. Codul este disponibil pe Github.', 'sr': 'S obzirom na globalnu skalu COVID-19 i poplavu sadržaja društvenih medija povezanog s njim, kako možemo naći informativne diskusije? Predstavljamo Gapformera, koji efikasno klasifikuje sadržaj kao informativan ili ne. To reformiše problem kao klasifikacija grafika, crteći ne samo tweet, već povezane veb stranice i entitete. Uzimamo predobučeni jezički model kao i veze između čvorova da naučimo zajedničku predstavu za svaku mrežu dokumenta. Pokazujemo da je nadmašilo nekoliko konkurentnih osnovnih linija i predstavljamo proučavanje ablacije koje podržavaju korist povezanih informacija. Kod je dostupan na Githubu.', 'so': 'Dunida COVID-19 caalamiga ah iyo daadka ku saabsan macluumaadka bulshada, sidee baannu u heli karnaa hadal macluumaad ku saabsan? Gapformer, taas oo si faa’iido leh ugu qoran waxyaabaha ay macluumaad u leeyihiin ama ayan aheyn. Waxay dhibaatada u bedeshaa fasaxa fasaxa xarafka, oo ay ku soo sawiraan iskuulka oo keliya, laakiin ay ku xidhiidhaan bogga internetka iyo waxyaabaha la xiriira. Tusaale ahaan afka horay loo tababaray iyo xiriirka noocyada u dhexeeya, si aan u barno noocyo u eg shabakadda dukumentiga. Waxaannu muujinnaa koorasyo badan oo iskutaal ah iyo waxbarasho qabashada ah oo taageeraya faa’iidada macluumaadka la xiriira. Codeynta waxaad ka heleysaa Github.', 'si': 'COVID-19 ගැන සාමාජික මිඩියාව සම්බන්ධ විදියට සම්බන්ධ විදියට, කොහොමද අපිට තොරතුරු කතා කරන්න පුළුවන්? අපි ගැප්ෆෝර්මර්ව පෙනුම් කරනවා, ඒක ප්\u200dරශ්නයෙන් සාමාන්ත්\u200dරිය විශේෂයෙන් තොරතුරු විදි ඒක ග්\u200dරාෆ් වර්ගයෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් විතරයි, ට්විට් විතරයි නෙවෙයි වෙබ් පිටුවන අපි ප්\u200dරධානය කරපු භාෂාවක් මොඩේලයක් සහ නෝඩ් අතර සම්බන්ධයක් ඉගෙන ගන්න හැම ලොකුණු ජාලය සඳහා ප්\u200dරධාන අපි ඒක පෙන්වන්නේ පුළුවන් ප්\u200dරශ්නයක් විතරයි ප්\u200dරශ්නයක් විතරයි සම්බන්ධ තොරතුරු සඳහා සම්බන්ධ ගිතුබ් එකේ කෝඩ් තියෙන්නේ.', 'ta': 'COVID-19 யின் உலக அளவுக்கு கொடுத்துள்ளார்கள் மற்றும் அதை பற்றி தொடர்புடைய சமூக ஊடகங்களின் வெளியில், நாம் எவ்வாறு தகவல் வ We present Gapformer, which effectively classifies content as informative or not.  இது பிரச்சனையை வரைகலை வகைப்படுத்தலாக மாற்றுகிறது, தொடர்பு மட்டும் அல்ல, இணைக்கப்பட்ட வலைப்பக்கங்கள் மற்றும் உருப்படிகள நாம் முன் பயிற்சி மொழி மாதிரி மற்றும் ஒவ்வொரு ஆவண வலைப்பின்னலுக்கும் ஒரு குறைந்த பிரதிநிர்வாகத் தொடர்புகளை கற் நாம் அதை பல போட்டியாளர் அடிப்படைகளை வெளியேற்றுகிறது மற்றும் தற்போதைய மூட்டும் படிப்பாடுகள் இணைக்கப்பட்ட தகவல் கித்துப் மீது குறியீடு கிடைக்கும்.', 'sv': 'Med tanke på COVID-19:s globala omfattning och översvämningen av innehåll i sociala medier relaterat till det, hur kan vi hitta informativa diskussioner? Vi presenterar Gapformer, som effektivt klassificerar innehållet som informativt eller inte. Det omformulerar problemet som grafklassificering och bygger inte bara på tweeten utan anslutna webbsidor och enheter. Vi utnyttjar en färdigutbildad språkmodell samt anslutningarna mellan noder för att lära oss en samlad representation för varje dokumentnätverk. Vi visar att det överträffar flera konkurrensutsatta baslinjer och presenterar ablationsstudier som stöder nyttan av den länkade informationen. Koden finns tillgänglig på Github.', 'ur': 'COVID-19 اور اس کے ساتھ رابطہ دار سوسیل میڈیا کے منصوبات کی سیل کی وجہ سے، ہم کس طرح informative discussions پا سکتے ہیں؟ ہم Gapformer کو پیش کرتے ہیں جو موجودات کو معلومات کے طور پر قطع کرتا ہے یا نہیں۔ یہ مشکل کو گراف کلاسیفوں کے طور پر تغییر دیتا ہے، نہیں صرف ٹویٹ پر ڈرینگ کرتی ہے بلکہ اتصال ہوئی ویب پائز اور ایٹنیٹ. ہم نے ایک پیش آموزش کی زبان موڈل اور نوڈوں کے درمیان اتصال کو ہر ڈاکومٹ نیٹ ورک کے لئے ایک جمع طریقہ کی تعلیم سکھائی۔ ہم اسے دکھاتے ہیں کہ بہت سی مسابقات بنسٹ لینڈ اور موجود قابلیت مطالعہ لینے کے فائدہ کے مددگار ہیں. Github پر کوڈ موجود ہے.', 'uz': "COVID-19 (global scale) va uni bilan bog'liq jamiyat tarkibini ko'rsatganda, biz qanday maʼlumot talabatlarni topa olamiz? Biz Gapformer'ni hozir qilamiz, bu ma'lumot deb ta'minlovchi narsalarni ko'rsatadi. It reformulates the problem as graph classification, drawing on not only the tweet but connected webpages and entities.  Biz har bir hujjat tarmoqning bir qisqa taʼminlovchisini o'rganish uchun o'rganish uchun oldin tilning modeli va nodler orasidagi bogʻlanish imkoniyatlarini bajaramiz. Biz buni bir necha rivojlanadigan asboblarni ko'rsatamiz va bog'liq maʼlumotning foydalanishini qo'llamaymiz. Kodi Github'da mavjud.", 'vi': 'Dựa trên cấp độ to àn cầu của COVID-19 và cũng có rất nhiều nội dung về các phương tiện truyền thông xã hội liên quan, làm sao chúng ta tìm được cuộc thảo luận thông tin? Chúng tôi giới thiệu Gazferor, người đã phân loại nội dung như những thông tin hay không. Nó cấu tạo lại vấn đề như phân loại đồ thị, không chỉ dựa trên trang Mạng, mà còn các thực thể đã kết nối. Chúng ta sử dụng một mô hình ngôn ngữ được đào tạo trước cũng như các kết nối giữa các nút để học đại diện tổng hợp cho mỗi mạng tài liệu. Chúng tôi cho thấy nó hoàn thiện nhiều nền tảng cạnh tranh và nghiên cứu có khả năng xóa bỏ hỗ trợ lợi ích của thông tin liên kết. Có mật mã ở Gitmo.', 'da': "I betragtning af COVID-19's globale omfang og oversvømmelsen af sociale medier relateret til det, hvordan kan vi så finde informative diskussioner? Vi præsenterer Gapformer, som effektivt klassificerer indhold som informativt eller ej. Det omformulerer problemet som grafklassificering og trækker på ikke kun tweet, men tilsluttede websider og enheder. Vi udnytter en forududdannet sprogmodel samt forbindelserne mellem noder for at lære en samlet repræsentation for hvert dokumentnetværk. Vi viser, at det overgår flere konkurrencedygtige basislinjer og præsenterer ablationsundersøgelser, der understøtter fordelene ved de tilknyttede oplysninger. Koden er tilgængelig på Github.", 'nl': "Hoe kunnen we informatieve discussies vinden, gezien de wereldwijde schaal van COVID-19 en de vloed aan social media content die eraan gerelateerd is? We presenteren Gapformer, die inhoud effectief classificeert als informatief of niet. Het herformuleert het probleem als grafiekclassificatie, waarbij niet alleen de tweet, maar ook verbonden webpagina's en entiteiten worden gebruikt. We maken gebruik van een vooraf getraind taalmodel en de verbindingen tussen knooppunten om een gepoolte representatie voor elk documentnetwerk te leren. We laten zien dat het beter presteert dan verschillende concurrerende baselines en presenteren ablatiestudies die het voordeel van de gekoppelde informatie ondersteunen. Code is beschikbaar op Github.", 'hr': 'S obzirom na globalnu skalu COVID-19 i poplavu sadržaja društvenih medija povezanog s njim, kako možemo pronaći informativne rasprave? Predstavljamo Gapformera, koji učinkovito klasifikira sadržaj kao informativan ili ne. To reformira problem kao klasifikacija grafika, crteći ne samo tweet, već povezane internetske stranice i entitete. Učinimo predobučeni jezički model kao i veze između čvorova kako bi naučili zajedničku zastupanje za svaku mrežu dokumenta. Pokazujemo da je nadmašuje nekoliko konkurentnih osnovnih linija i sadašnja ispitivanja aktivacije koje podržavaju korist povezanih informacija. Kod je dostupan na Githubu.', 'bg': 'Предвид глобалния мащаб на COVID-19 и наводнението на съдържанието в социалните медии, свързано с него, как можем да намерим информативни дискусии? Представяме Гапформер, който ефективно класифицира съдържанието като информативно или не. Той преформулира проблема като класификация на графиката, като се основава не само на туит, но и на свързаните уеб страници и обекти. Използваме предварително обучен езиков модел, както и връзките между възлите, за да научим обединено представяне за всяка документална мрежа. Показваме, че тя превъзхожда няколко конкурентни базови линии и представяме аблационни проучвания, подкрепящи ползата от свързаната информация. Кодът е достъпен в Github.', 'de': 'Wie können wir angesichts des globalen Ausmaßes von COVID-19 und der damit verbundenen Flut an Social-Media-Inhalten informative Diskussionen finden? Wir präsentieren Gapformer, der Inhalte effektiv als informativ klassifiziert oder nicht. Es formuliert das Problem als Graphenklassifikation neu, wobei nicht nur der Tweet, sondern auch verbundene Webseiten und Entitäten verwendet werden. Wir nutzen ein vortrainiertes Sprachmodell sowie die Verbindungen zwischen Knoten, um eine gepoolte Darstellung für jedes Dokumentennetzwerk zu erlernen. Wir zeigen, dass es mehrere wettbewerbsfähige Baselines übertrifft und präsentieren Ablationsstudien, die den Nutzen der verknüpften Informationen unterstützen. Code ist auf Github verfügbar.', 'id': 'Mengingat skala global COVID-19 dan banjir konten media sosial yang berhubungan dengannya, bagaimana kita bisa menemukan diskusi informatif? Kami memperkenalkan Gapformer, yang secara efektif mengklasifikasi isi sebagai informatif atau tidak. Hal ini mengubah masalah sebagai klasifikasi grafik, menggambar bukan hanya tweet tetapi halaman web terhubung dan entitas. Kami menggunakan model bahasa yang dilatih-dilatih serta koneksi antara node untuk belajar sebuah persembahan bersama untuk setiap jaringan dokumen. Kami menunjukkan bahwa ia melebihi beberapa garis dasar kompetitif dan menunjukkan studi ablasi yang mendukung keuntungan dari informasi terhubung. Kode tersedia di Github.', 'ko': '코로나의 전 세계적 규모와 이와 관련된 소셜미디어 콘텐츠의 범람을 고려할 때 우리는 어떻게 정보가 풍부한 토론을 찾을 것인가?Gapformer는 내용을 정보적인 내용이나 비정보적인 내용으로 효과적으로 분류할 수 있는 Gapformer를 제시했다.트위터뿐만 아니라 연결된 웹 페이지와 실체를 이용해 문제를 도형 분류로 재해석했다.우리는 미리 훈련된 언어 모델과 노드 간의 연결을 이용하여 모든 문서 네트워크의 집합 표시를 배운다.우리는 그것이 몇 가지 경쟁력 있는 기선보다 우수하다는 것을 증명했다. 현재의 융해 연구는 관련 정보의 장점을 지원한다.코드는 Github에서 찾을 수 있습니다.', 'fa': 'با توجه به مقیاس جهانی COVID-19 و سیل محتوای رسانه های اجتماعی رابطه به آن، چگونه می توانیم بحث اطلاعاتی را پیدا کنیم؟ ما Gapformer را معرفی می کنیم که به طور موثر محتویات را به عنوان اطلاعات شناسایی می کند یا نه. این مشکل را به عنوان فرآیندگی گراف تغییر می\u200cدهد، نقاشی روی نه تنها تویت بلکه صفحه\u200cهای وب و عناصر متصل می\u200cشود. ما یک مدل زبان پیش آموزش داده شده و ارتباطات بین گره\u200cها را برای یاد گرفتن یک نمایش جمع برای هر شبکه سند استفاده می\u200cکنیم. ما به آن نشان می دهیم که تعداد زیر خط مسابقه و تحقیقات فعالیت در حال حاضر به سود اطلاعات مرتبط حمایت می کنند. کد توي جيتاب دسترسي داره', 'tr': "COVID-19 dünýäçe derejäniň we sosial mediýaly meýdançalaryň çöplügine görä, biz nädip informatiýaly görüşmeleri tapyp bileris? Gapformer'i tanyşdyrýarys. Hakykatdanam maglumaty informasiýa ýa-da tanyşdyrmaýar. Meseläni grafik klasifikasy ýaly reform edýär, tuit diňe çizim däl, web sahypalary we hiletleri baglanýar Biz öňünden öňünden bilinmiş dil nusgasyny we düwmeler arasyndaky baglaýyşlaryny her sened şebekleri üçin bir jemläw öwrenmek üçin üýtgedýäris Biz muny birnäçe döwletli üýtgeýji hatlaryň üstünden çykypdygyny görkeýäris we şu wagtlary baglaşyk maglumatyň faydasyny golaýlaşýarlar. Githubda köd bar.", 'sw': 'Kutokana na kiwango cha dunia cha COVID-19 na mafuriko ya maudhui ya mitandao ya kijamii yanayohusiana na hilo, tunawezaje kupata mijadala ya taarifa? We present Gapformer, which effectively classifies content as informative or not.  Inabadilisha tatizo kama sifa ya grafu, ikipiga picha si tu kwenye twita bali zile zinazohusiana na tovuti na vyombo vya habari. Tunaweza kutumia muundo wa lugha iliyoendelea kabla pamoja na uhusiano kati ya vipande vya habari ili kujifunza uwakilishi mzuri kwa kila mtandao wa nyaraka. Tunaonyesha inaonyesha misingi kadhaa ya ushindani na utafiti wa mafuta unaoendelea kuunga mkono faida ya taarifa zinazohusiana. Utawala unapatikana kwenye Github.', 'af': "Gien die globale skaal van COVID-19 en die vloed van sosiale media inhoud wat met dit verwante is, hoe kan ons informatiewe diskusies vind? Ons stel Gapformer voor, wat effektief inhoud as informatiewe of nie klassifiseer. Dit reformeer die probleem as graaf klassifikasie, teken op nie slegs die tweet nie, maar verbind webbladsye en entiteite. Ons verwyder 'n vooraf-onderwerp taal model en die verbindings tussen nodes om 'n poolde voorstelling te leer vir elke dokumentnetwerk. Ons wys dit uit verskeie mededingslige basisline en voorneem aktivering studie wat ondersteun die voordeel van die gekoppelde inligting. Kode is beskikbaar op Github.", 'sq': 'Duke marrë parasysh shkallën globale të COVID-19 dhe përmbytjen e përmbajtjes së medias sociale lidhur me të, si mund të gjejmë diskutime informacionale? Ne prezantojmë Gapformer, i cili klasifikon përmbajtjen si informacive apo jo. Ajo reformulon problemin si klasifikim grafik, duke u mbështetur jo vetëm në tweet por në faqet dhe njësitë e lidhura në internet. Ne përdorim një model gjuhësh të trajnuar para si dhe lidhjet midis nyjeve për të mësuar një përfaqësim të përbashkët për çdo rrjet dokumenti. Ne tregojmë se ajo kalon disa linja bazë konkurruese dhe paraqet studime ablacioni që mbështesin përfitimin e informacionit të lidhur. Kodi është në dispozicion në Github.', 'am': 'የCOVID-19 ዓለምአቀፍ ክፍል እና የማኅበራዊ አውታር ውኃ በተያያዘ ጊዜ የመረጃ ውይይት እንዴት እናገኛለን? ጋፕፊሮን እናሳየዋለን፣ የውይይት መረጃ ወይም አይሆንም፡፡ ጉዳዩን እንደ graph መግለጫ ያስተካክላል፡፡ ለሁሉም ሰነድ መረብ ጥያቄን ለመማር በቋንቋ ሞዴል እና በኖዶዎች መካከል ግንኙነትን እናደርጋለን፡፡ ብዙ ተቃዋሚዎች መደገፊያዎችን እናሳየዋለን እና የግንኙነት መረጃዎችን ለመደገፍ የሚችሉትን የአደጋጋጋጅነት ትምህርት እናሳየዋለን፡፡ ኮድ በጊቱብ ላይ ነው', 'hy': 'Եթե հաշվի առնենք COVID-19 համաշխարհային մակարդակը և դրա հետ կապված սոցիալական լրատվամիջոցների բովանդակությունը, ինչպե՞ս կարող ենք գտնել ինֆորմատիվ քննարկումներ: Մենք ներկայացնում ենք Gapfforme-ը, որը արդյունքում պարունակությունը դասակարգում է ինֆորմատիվ կամ ոչ: Այն վերաձևավորում է խնդիրը որպես գծագրային դասակարգում, հիմնվելով ոչ միայն թվիթերի վրա, այլ նաև կապված վեբ էջերի և միավորների վրա: Մենք օգտագործում ենք նախապատրաստված լեզվի մոդելը, ինչպես նաև հանգույցների միջև կապերը, որպեսզի սովորենք յուրաքանչյուր փաստաթղթի ցանցի ընդհանուր ներկայացում: Մենք ցույց ենք տալիս, որ այն գերազանցում է որոշ մրցակցության հիմքերը և ներկայացնում ենք աբլացիայի ուսումնասիրություններ, որոնք աջակցում են կապված տեղեկատվության շահույթը: Գիտուբի կոդը հասանելի է:', 'az': "COVID-19 küresel ölçüsünün və onunla bağlı sosyal media məlumatının sularına görə, informativ müzakirələri necə tapılırıq? Biz Gapformer'i göstəririk ki, məlumatları informativ kimi seçər və ya yoxdur. Bu problemi Grafik klasifikasyonu kimi dəyişdirir, yalnız tweet deyil, bağlı veb sayfaları və entitələri çizdirir. Biz təhsil edilmiş dil modelini və düyünün arasındakı bağlantıları hər döküm a ğ üçün birləşdirilmiş nümunələri öyrənmək üçün təhsil edirik. Biz bunu bir neçə müəllif sətirlərin üstünlüyünü göstəririk və müəllif məlumatların faydasını dəstəkləyən müəllif təhsil təhsil təhsil təhsil etdik. Github'da Kod faydalanır.", 'bn': 'কোভিড-১৯ এর বিশ্ব পর্যায় এবং সামাজিক প্রচার মাধ্যমের বিষয়বস্তুর বন্যা দিয়ে আমরা কিভাবে তথ্যের আলোচনা পাব? আমরা গ্যাপ্ফোর্নের সামনে উপস্থিত করছি, যা কার্যকর ভাবে তথ্য হিসেবে বিষয়বস্তুকে বিভিন্ন বিষয়বস্ এটি সমস্যাকে গ্রাফ ক্লাসাফিকেশন হিসেবে সংস্কার করে, শুধুমাত্র টুইটের উপর আঁকা নয়, কিন্তু সংযুক্ত ওয়েব পেজ এবং বস্ত পূর্ব প্রশিক্ষিত ভাষার মডেল এবং প্রত্যেক নথিপত্র নেটওয়ার্কের জন্য পুলিশ প্রতিনিধিত্ব শিখতে নোডের মধ্যে যোগাযোগ আমরা এটি দেখাচ্ছি বেশ কয়েকটি প্রতিযোগিতা বেসেলাইন এবং সংযুক্ত তথ্যের সুবিধা প্রদান করে বর্তমানে আগুনের গবেষণা। গিথুবে কোড পাওয়া যাচ্ছে।', 'bs': 'S obzirom na globalnu skalu COVID-19 i poplavu sadržaja društvenih medija povezanog s njim, kako možemo naći informativne diskusije? Predstavljamo Gapformera, koji efektivno klasifikuje sadržaj kao informativan ili ne. To reformiše problem kao klasifikacija grafika, crteći ne samo na tweetu, već povezanim internetskim stranicama i entitetima. Učinimo predobučeni jezički model, kao i veze između čvorova da naučimo zajedničku predstavu za svaku mrežu dokumenta. Pokazujemo da iznosi nekoliko konkurentnih osnovnih linija i sadašnja ispitivanja aktivacije koje podržavaju korist povezanih informacija. Kod je dostupan na Githubu.', 'cs': 'Vzhledem k globálnímu rozsahu COVID-19 a záplavě obsahu sociálních médií s ním souvisejícího, jak najdeme informativní diskuse? Představujeme Gapformer, který efektivně klasifikuje obsah jako informativní nebo ne. Přeformuluje problém jako klasifikaci grafů, čerpá nejen z tweetu, ale i z propojených webových stránek a entit. Využíváme předškolený jazykový model, stejně jako propojení mezi uzly, abychom se naučili sdílenou reprezentaci pro každou dokumentovou síť. Ukázali jsme, že překonává několik konkurenčních základních linií a prezentujeme ablační studie podporující přínos propojených informací. Kód je k dispozici na Githubu.', 'et': 'Arvestades COVID-19 globaalset ulatust ja sellega seotud sotsiaalmeedia sisu üleujutust, kuidas me saame leida informatiivseid arutelusid? Esitleme Gapformeri, mis tõhusalt liigitab sisu informatiivseks või mitte. See sõnastab probleemi ümber graafilise klassifikatsioonina, tuginedes mitte ainult säutsu, vaid ühendatud veebilehtedele ja olemitele. Me kasutame eelnevalt koolitatud keelemudelit ja sõlmede vahelisi ühendusi, et õppida iga dokumendivõrgu ühendatud esitust. Näitame, et see ületab mitmeid konkurentsivõimelisi lähtejooni ja esitame ablatsiooniuuringuid, mis toetavad seotud teabe kasu. Kood on saadaval Githubis.', 'fi': 'Kun otetaan huomioon COVID-19:n maailmanlaajuinen mittakaava ja siihen liittyvä sosiaalisen median sisällön tulva, miten voimme löytää informatiivisia keskusteluja? Esittelemme Gapformerin, joka luokittelee sisällön tehokkaasti informatiiviseksi tai ei. Se muotoilee ongelman uudelleen graafiluokitteluksi hyödyntäen tweetin lisäksi yhdistettyjä verkkosivuja ja kokonaisuuksia. Hyödynnämme ennalta koulutettua kielimallia ja solmujen välisiä yhteyksiä oppiaksemme yhdistetyn edustuksen jokaiselle asiakirjaverkostolle. Osoitamme sen suoriutuvan useista kilpailullisista lähtökohdista ja esittelemme linkitetyn tiedon hyötyjä tukevia ablaatiotutkimuksia. Koodi on saatavilla Githubissa.', 'ca': "Tenint en compte l'escala global de COVID-19 i l'inundació del contingut dels mitjans socials relacionat amb ell, com podem trobar debats informatius? Presentam Gapformer, que classifica efectivament el contingut com informatiu o no. Reformula el problema com a classificació del gràfic, basant-se no només en el tweet, sinó en pàgines web i entitats connectades. Utilitzem un model de llenguatge pré-entrenat i les connexions entre nodos per aprendre una representació agrupada per cada xarxa de documents. Mostrem que supera diverses línies de base competitives i presentem estudis d'ablació que suporten el benefici de la informació vinculada. El codi està disponible a Github.", 'jv': 'Nanging kapan tanggal global de COMPID-19 lan bagol sing perusahaan media sotiki dadi, piye iso nggawe tarjamahan informasi ? Gap transformer Jejaring Monday Awak dhéwé ngomong nik akeh pisan neng sampek sing luwih dumadhi iki ngono didasai perusahaan kanggo nggawe barang nggawe informasi tambah. Kodi wis dipunanggé nang GIWWB', 'sk': 'Kako lahko glede na globalni obseg COVID-19 in poplavo z njim povezanih vsebin na družbenih omrežjih najdemo informativne razprave? Predstavljamo Gapformer, ki učinkovito razvršča vsebino kot informativno ali ne. Težavo preoblikuje kot razvrstitev grafov, pri čemer se ne opira le na tweet, temveč tudi povezane spletne strani in entitete. Izkoristimo vnaprej usposobljen jezikovni model in povezave med vozlišči, da se naučimo združene predstavitve za vsako omrežje dokumentov. Pokazali smo, da je boljši od več konkurenčnih osnovnih linij in predstavili študije ablacije, ki podpirajo korist povezanih informacij. Koda je na voljo na Githubu.', 'he': 'בהתחשב בסולם הגלובלי של COVID-19 והצפה של תוכן התקשורת החברתית שקשור לזה, איך נוכל למצוא דיון מידעי? אנו מציגים את גאפפורמר, שמקלסים בעובדה את התוכן כמידע או לא. It reformulates the problem as graph classification, drawing on not only the tweet but connected webpages and entities.  אנחנו משתמשים במודל שפה מאומן מראש, כמו גם בקשר בין קשרים כדי ללמוד מייצג מאוחד לכל רשת מסמכים. אנו מראים את זה יוצא מעל מספר קווי בסיס תחרותיים ומציג מחקרי ניתוח שמתמיכים בתועלת המידע הקשור. קוד זמין בגיטוב.', 'ha': "Gida takardar global COKID-19 da ruwan maɓallin mitandai da jamii suka yi na haɗi da shi, yãya zã mu sãmi majadiliki masu sani? Munã halatar da Gapformer, wanda ke rarraba kayan aiki kamar ma'anar ko kuma ba. Yana yin amfani da problemati kamar sifilafin grafi, yana yin jiyya, ba ta yi amfani da shi ba, kuma amma, yana da haɗi da website da abubuwa. We leverage a pre-trained language model as well as the connections between nodes to learn a pooled representation for each document network.  Muna nũna ta daga wasu salofa masu competiti da akan kullinta na yanzu, sunã ƙarfafa amfani da information da suka yi samu da shi. @ info: whatsthis", 'bo': 'COVID-19 ཡི་འཛམ་གླིང་གི་ཚད་རིམ་དང་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་གི་ནང་དུ་འདྲ་བ་གླེང་མོལ ང་ཚོས་Gapformer་ལ་སྟོན་ཐུབ་པ་ལས་ནང་དོན་ནི་གསལ་བཤད་དང་མིན་བཟོ་བྱེད་ཀྱི་ཡོད། དེས ང་ཚོས་སྔོན་གྱིས་འཛིན་གྱི་སྐད་རིགས་དཔེ་དབྱིབས་དང་གནད་དོན་གྱི་སྦྲེལ་མཐུད་དེ་ལ་ཡོད་པ་རེ་རེ་བ་ནས་ཡིག་ཆ་དྲ་བ་ ང་ཚོས་དེ་ལྟ་བུ Github ཐོག་ཏུ་ཨང་གྲངས་སྤྱོད་ཐུབ་པ'}
{'en': 'LynyrdSkynyrd at WNUT-2020 Task 2 : Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets L ynyrd S kynyrd at  WNUT -2020 Task 2: Semi-Supervised Learning for Identification of Informative  COVID -19  E nglish Tweets', 'ar': 'LynyrdSkynyrd في WNUT-2020 المهمة 2: التعلم شبه الخاضع للإشراف لتحديد التغريدات الإعلامية لـ COVID-19 باللغة الإنجليزية', 'pt': 'LynyrdSkynyrd no WNUT-2020 Tarefa 2: Aprendizado semi-supervisionado para identificação de tweets informativos sobre COVID-19 em inglês', 'es': 'LynyrdSkyNYRD en la Tarea 2 del WNUT-2020: Aprendizaje semisupervisado para la identificación de tuits informativos en inglés sobre COVID-19', 'fr': "LynyrdSkyNyrd à la WNUT-2020 Tâche 2\xa0: Apprentissage semi-supervisé pour l'identification des tweets informatifs en anglais COVID-19", 'ja': 'WNUT -2020でのLynyrdSkynyrdタスク2 ：新型コロナウイルス感染症(COVID -19)に関する有益な英語ツイートの識別のためのセミスーパーバイザリー学習', 'zh': 'LynyrdSkynyrd在WNUT-2020务2:以知信息性COVID-19英语推文之半督学', 'hi': 'WNUT-2020 टास्क 2 पर LynyrdSkynyrd: सूचनात्मक कोविड -19 अंग्रेजी ट्वीट्स की पहचान के लिए अर्ध-पर्यवेक्षित सीखने', 'ru': 'LynyrdSkynyrd на WNUT-2020 Задача 2: Полунадзорное обучение для выявления информативных твитов на английском языке о COVID-19', 'ga': 'LynyrdSkynyrd ag WNUT-2020 Tasc 2: Foghlaim Leath-Mhaoirsithe chun Tweetanna Béarla Faisnéiseacha COVID-19 a Aithint', 'el': 'LynyrdSkynyrd στο έργο 2: Ημι-εποπτευόμενη μάθηση για τον προσδιορισμό πληροφοριακών αγγλικών tweets', 'ka': 'LynyrdSkynyrd WNUT-2020 პარამეტრი 2: სამუშაო დანახვა ინფორმაციური COVID-19 ინგლისური Tweets- ის განსაზღვრება', 'hu': 'LynyrdSkynyrd a WNUT-2020 2. feladaton: félig felügyelt tanulás az információs COVID-19 angol tweetek azonosítására', 'lt': 'LynyrdSkynyrd WNUT-2020 2 užduotyje: puspriežiūrinis mokymasis informaciniam COVID-19 anglų dviejuose tinkluose', 'kk': 'LynyrdSkynyrd at WNUT-2020 Task 2: Half-Supervised Learning for Identification of Information COVID-19 English Tweets', 'it': "LynyrdSkynyrd a WNUT-2020 Task 2: apprendimento semi-supervisionato per l'identificazione dei tweet informativi in inglese COVID-19", 'mt': 'LynyrdSkynyrd fid-WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'mk': 'LynyrdSkynyrd на ВНУТ-2020 задача 2: Половина надгледувано учење за идентификација на информативните Твитови COVID-19', 'ms': 'LynyrdSkynyrd di WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'ml': 'WNUT-2020 ടാസ്ക് 2 ലിന്നിര്\u200dഡ്സ്കൈന്\u200dഡ്: സെമി- സൂപ്പര്\u200dവ്വപ്രൈസ് പഠിപ്പിക്കുന്നത് വിവരങ്ങള്\u200d കോവിഡ്-19 ഇംഗ്ലീഷ് ടൂട്ടു', 'mn': 'LynyrdSkynyrd at WNUT-2020 Task 2: Half-Supervised Learning for Identifying Information COVID-19 English Tweets', 'pl': 'LynyrdSkynyrd na WNUT-2020 Zadanie 2: Nauka pół-nadzorowana w celu identyfikacji informacyjnych tweetów angielskich COVID-19', 'no': 'LynyrdSkynyrd at WNUT-2020 Task 2: Half-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'ro': 'LynyrdSkynyrd la sarcina 2 a WNUT-2020: Învățare semi-supravegheată pentru identificarea tweeturilor informative în limba engleză COVID-19', 'si': 'LinyrdSkynyrd at WNOT-202 Job 2: Half-supervised Training for ID of Infotive COVID-19 English Tweets', 'sr': 'LynyrdSkynyrd na WNUT-2020 zadatku 2: polu nadzorno učenje za identifikaciju informativnih COVID-19 engleskih Tweets', 'so': 'LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'sv': 'LynyrdSkynyrd på WNUT-2020 Uppgift 2: Halvövervakat lärande för identifiering av informativ COVID-19 engelska tweets', 'ur': 'LynyrdSkynyrd WNUT-2020 Task 2: Half-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'ta': 'WNUT- 2020 Task 2: Semi- Supervised Learning for Identification of Informative COVID- 19 English Tweets', 'uz': 'Name', 'vi': 'LynyrdSkynet tại tập vụ WGiờ-2020 2: Phòng giám sát giáo dục để nhận diện hợp đồng...', 'bg': 'ЛинирдСкинърд в Задача 2: Полунадзорно обучение за идентифициране на информативни английски туитове', 'hr': 'LynyrdSkynyrd na WNUT-2020 zadatku 2: polu nadzorno učenje za identifikaciju informativnih COVID-19 engleskih Tweets', 'nl': 'LynyrdSkynyrd bij WNUT-2020 Taak 2: Semi-Supervised Learning voor Identificatie van Informatieve COVID-19 Engelse Tweets', 'da': 'LynyrdSkynyrd ved WNUT-2020 Opgave 2: Semi-supervised learning til identifikation af informativ COVID-19 engelske tweets', 'de': 'LynyrdSkynyrd bei WNUT-2020 Aufgabe 2: Semi-Supervised Learning zur Identifizierung informativer COVID-19 englischer Tweets', 'id': 'LynyrdSkynyrd di WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'fa': 'LynyrdSkynyrd at WNUT-2020 Task 2: semi-supervised Learning for Identification of Informative COVID-19 English Tweets', 'ko': 'LynyrdSkynyrd가 WNUT-2020에서의 임무2: 정보성 코로나 영어 트윗을 식별하는 반감독 학습', 'tr': 'LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'af': 'LynyrdSkynyrd by WNUT-2020 Opdrag 2: Semi-Supervised Leer vir Identifikasie van Informatiewe COVID-19 Engels Tweets', 'sw': 'LynyrdSkynyrd katika Task la WNUT-2020 2: Ufunzi wa Semi-Supervisheni kwa ajili ya kutambulisha taarifa za Twita za Kiingereza', 'sq': 'LynyrdSkynyrd në WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets', 'am': 'LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 Tweets', 'hy': 'Լինիրդ Սկինիրդը Համաշխարհային Ազգային Ազգային Հետազոտության Համաշխարհում 2020-ի 2. խնդիրն է. տեղեկատվական COVID-19 անգլերեն թվիթերի հայտնաբերման կես-վերահսկված սովորելը', 'az': 'WNUT-2020 Task 2: Informativ COVID-19 İngilizə Tweets kimliğinin yarısını gözləyir', 'bn': 'উইনউট-২০২০০ কাজ ২-এ লিনিয়ার্ডস্কাইয়ার্ড: তথ্য তথ্য প্রকাশিত কোভিড-১৯ ইংরেজী টুইটের জন্য সেমি সুপার্ভিস শিক্ষার্থী', 'bs': 'LynyrdSkynyrd na WNUT-2020 zadatku 2: polu nadzorno učenje za identifikaciju informativnih COVID-19 engleskih Tweets', 'ca': 'LynyrdSkynyrd al WNUT-2020 Task 2: Semi-supervised Learning for Identification of Informative COVID-19 English Tweets', 'et': 'LynyrdSkynyrd WNUT-2020 ülesandel 2: pooljärelevalvega õpe informatiivse COVID-19 tuvastamiseks English Tweets', 'cs': 'LynyrdSkynyrd na WNUT-2020 Úkol 2: Semi-Supervised Learning pro identifikaci informačních anglických tweetů COVID-19', 'fi': 'LynyrdSkynyrd WNUT-2020:n tehtävässä 2: puolivalvottu oppiminen informatiivisen COVID-19:n tunnistamiseksi English Tweets', 'jv': 'string" in "context_BAR_stringClone', 'he': 'LynyrdSkynyrd ב-WNUT-2020 משימה 2: למידה חצי-שומר לזהות טוויטים אנגליים COVID-19', 'ha': 'KCharselect unicode block name', 'sk': 'LynyrdSkynyrd na WNUT-2020 naloga 2: polnadzorovano učenje za identifikacijo informativnih COVID-19 English Tweets', 'bo': 'LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for Identification of Informative COVID-19 English Tweets'}
{'en': 'In this work, we describe our system for WNUT-2020 shared task on the identification of informative COVID-19 English tweets. Our system is an ensemble of various machine learning methods, leveraging both traditional feature-based classifiers as well as recent advances in pre-trained language models that help in capturing the syntactic, semantic, and contextual features from the tweets. We further employ pseudo-labelling to incorporate the unlabelled Twitter data released on the pandemic. Our best performing  model  achieves an F1-score of 0.9179 on the provided validation set and 0.8805 on the blind test-set.', 'ar': 'في هذا العمل ، نصف نظامنا الخاص بالمهمة المشتركة WNUT-2020 بشأن تحديد التغريدات المفيدة باللغة الإنجليزية لـ COVID-19. نظامنا عبارة عن مجموعة من أساليب التعلم الآلي المختلفة ، مع الاستفادة من المصنفات التقليدية القائمة على الميزات بالإضافة إلى التطورات الحديثة في نماذج اللغة المدربة مسبقًا والتي تساعد في التقاط السمات النحوية والدلالية والسياقية من التغريدات. نحن نستخدم أيضًا تصنيفًا زائفًا لدمج بيانات Twitter غير الموسومة الصادرة عن الوباء. يحقق نموذجنا الأفضل أداءً درجة F1 تبلغ 0.9179 على مجموعة التحقق المقدمة و 0.8805 في مجموعة الاختبار الأعمى.', 'fr': "Dans ce travail, nous décrivons notre système pour la tâche partagée WNUT-2020 sur l'identification des tweets informatifs en anglais COVID-19. Notre système est un ensemble de diverses méthodes d'apprentissage automatique, tirant parti à la fois des classificateurs traditionnels basés sur des fonctionnalités ainsi que des avancées récentes dans les modèles de langage pré-entraînés qui aident à capturer les caractéristiques syntaxiques, sémantiques et contextuelles des tweets. Nous utilisons également un pseudo-étiquetage pour intégrer les données Twitter non étiquetées publiées sur la pandémie. Notre modèle le plus performant obtient un score F1 de 0,9179 sur l'ensemble de validation fourni et de 0,8805 sur l'ensemble de test à l'aveugle.", 'es': 'En este trabajo, describimos nuestro sistema para la tarea compartida de WNUT-2020 sobre la identificación de tuits informativos en inglés sobre COVID-19. Nuestro sistema es un conjunto de varios métodos de aprendizaje automático, que aprovecha tanto los clasificadores tradicionales basados en funciones como los avances recientes en modelos de lenguaje previamente entrenados que ayudan a capturar las características sintácticas, semánticas y contextuales de los tuits. Además, utilizamos el seudoetiquetado para incorporar los datos de Twitter sin etiqueta publicados sobre la pandemia. Nuestro modelo de mejor rendimiento logra una puntuación F1 de 0.9179 en el conjunto de validación proporcionado y de 0.8805 en el conjunto de pruebas ciegas.', 'pt': 'Neste trabalho, descrevemos nosso sistema para tarefa compartilhada WNUT-2020 na identificação de tweets informativos sobre COVID-19 em inglês. Nosso sistema é um conjunto de vários métodos de aprendizado de máquina, aproveitando tanto os classificadores tradicionais baseados em recursos quanto os avanços recentes em modelos de linguagem pré-treinados que ajudam a capturar os recursos sintáticos, semânticos e contextuais dos tweets. Além disso, empregamos pseudo-rotulagem para incorporar os dados não rotulados do Twitter divulgados sobre a pandemia. Nosso modelo de melhor desempenho atinge uma pontuação F1 de 0,9179 no conjunto de validação fornecido e 0,8805 no conjunto de teste cego.', 'ja': '本作では、新型コロナウイルス感染症(COVID -19)に関する有益な英語ツイートの識別に関するWNUT -2020共有タスクのためのシステムについて説明します。当社のシステムは様々な機械学習方法のアンサンブルであり、従来の特徴ベースの分類子と、ツイートからの構文的、意味的、および文脈的特徴を取り込むのに役立つ事前にトレーニングされた言語モデルの最近の進歩の両方を活用しています。さらに、パンデミックでリリースされたラベルなしのTwitterデータを組み込むために、疑似ラベル付けを採用しています。ベストパフォーマンスモデルは、提供された検証セットで0.9179、ブラインドテストセットで0.8805のF 1スコアを達成します。', 'zh': '于此言之,WNUT-2020统识信丰COVID-19英语推文之共同任务。 吾统者,百机器之会也,因古之分器,与言语之最新进展,有助于推文之语法,语义上下文之征也。 更用伪标整合大行未标Twitter数。 至善之验集上得0.9179之F1,得0.8805之分于盲测集。', 'hi': 'इस काम में, हम WNUT-2020 के लिए हमारे सिस्टम का वर्णन करते हैं, जो जानकारीपूर्ण कोविड -19 अंग्रेजी ट्वीट्स की पहचान पर साझा कार्य करता है। हमारी प्रणाली विभिन्न मशीन सीखने के तरीकों का एक पहनावा है, जो पारंपरिक सुविधा-आधारित क्लासिफायर्स के साथ-साथ पूर्व-प्रशिक्षित भाषा मॉडल में हाल की प्रगति का लाभ उठाती है जो ट्वीट्स से वाक्यात्मक, शब्दार्थ और प्रासंगिक विशेषताओं को कैप्चर करने में मदद करती है। हम महामारी पर जारी किए गए बिना लेबल वाले ट्विटर डेटा को शामिल करने के लिए छद्म लेबलिंग को और अधिक नियोजित करते हैं। हमारा सबसे अच्छा प्रदर्शन मॉडल प्रदान किए गए सत्यापन सेट पर 0.9179 का F1-स्कोर और अंधे परीक्षण-सेट पर 0.8805 प्राप्त करता है।', 'ru': 'В этой работе мы описываем нашу систему для совместной задачи WNUT-2020 по идентификации информативных английских твитов о COVID-19. Наша система представляет собой совокупность различных методов машинного обучения, использующих как традиционные классификаторы на основе признаков, так и последние достижения в предварительно обученных языковых моделях, которые помогают в захвате синтаксических, семантических и контекстуальных признаков из твитов. Кроме того, мы используем псевдомаркировку для включения немеченых данных Twitter, опубликованных в связи с пандемией. Наша лучшая модель производительности достигает показателя F1 0,9179 в предоставленном наборе валидации и 0,8805 в слепом наборе тестов.', 'ga': 'San obair seo, déanaimid cur síos ar ár gcóras le haghaidh tasc comhroinnte WNUT-2020 maidir le tweets Béarla faisnéiseach COVID-19 a shainaithint. Is ensemble é ár gcóras de mhodhanna meaisínfhoghlama éagsúla, ag baint úsáide as aicmitheoirí traidisiúnta gné-bhunaithe agus dul chun cinn le déanaí i múnlaí teanga réamhoilte a chabhraíonn le gnéithe comhréire, shéimeantacha agus comhthéacsúla a ghabháil ó na tweets. Bainimid úsáid freisin as lipéadú bréige chun na sonraí Twitter gan lipéad a scaoileadh ar an bpaindéim a ionchorprú. Baineann ár múnla feidhmíochta is fearr amach scór F1 de 0.9179 ar an tacar bailíochtaithe a soláthraíodh agus 0.8805 ar an tacar tástála dall.', 'ka': 'ამ სამუშაოში ჩვენ ჩვენი სისტემა WNUT-2020-ის გაყოფილი სამუშაო სამუშაო დავაწერეთ ინფორმატიური COVID-19 ინგლისური tweets-ის განსაზღვრებაზე. ჩვენი სისტემა არის განსხვავებული მანქანის სწავლის მეტი, რომელიც ორივე ტრადიციონალური ფუნქციური კლასიფიკაციების განმავლობაში და შემდეგ წინასწავლილი ენის მოდელში, რომელიც სინტაქტიური, სიმენტიკური და კონტექსტურ ჩვენ დამატებით გამოყენებთ პესედო-ლებილის შესახებ, რომ გამოყენება არაწერებული Twitter მონაცემები, რომელიც პონდემიკზე გამოსტანა. ნაქთწრ ნაი-ეჲბყპ თჱოპაგთრვლვნ მჲევლ ეჲჟრთდნაგა F1-ოჲ 0,9179 ნა ოპველჲზვნთწრა სგალთეაუთწ თ 0,8805 ნა ჟლვოარა თჱოთრკა.', 'el': 'Σε αυτή την εργασία, περιγράφουμε το σύστημά μας για την κοινή εργασία για τον προσδιορισμό ενημερωτικών αγγλικών tweets. Το σύστημά μας είναι ένα σύνολο διαφόρων μεθόδων μηχανικής μάθησης, αξιοποιώντας τόσο τους παραδοσιακούς ταξινομητές με βάση χαρακτηριστικά, όσο και τις πρόσφατες εξελίξεις σε προ-εκπαιδευμένα γλωσσικά μοντέλα που βοηθούν στην καταγραφή των συντακτικών, σημασιολογικών και περιεκτικών χαρακτηριστικών από τα tweets. Χρησιμοποιούμε επίσης ψευδο-επισήμανση για να ενσωματώσουμε τα μη επισήμαντα δεδομένα του Twitter που δημοσιεύθηκαν για την πανδημία. Το μοντέλο μας επιτυγχάνει βαθμολογία 0.9179 στο παρεχόμενο σετ επικύρωσης και 0.8805 στο τυφλό σετ δοκιμής.', 'hu': 'Ebben a munkában bemutatjuk a WNUT-2020 információs COVID-19 angol tweetek azonosítására irányuló megosztott feladatunkat. Rendszerünk különböző gépi tanulási módszerek együttese, amelyek mind a hagyományos funkcióalapú osztályozókat, mind az előre képzett nyelvi modellek legújabb fejlesztéseit használják, amelyek segítenek a tweetek szintaktikai, szemantikai és kontextuális funkcióinak rögzítésében. Ezenkívül pszeudo címkézést alkalmazunk a járványról kiadott Twitter-adatok beépítéséhez. A legjobb teljesítményű modellünk F1 pontszámot ér el a mellékelt validációs készleten 0,9179, a vak tesztkészleten pedig 0,8805.', 'it': "In questo lavoro, descriviamo il nostro sistema per il compito condiviso WNUT-2020 sull'identificazione dei tweet informativi in inglese COVID-19. Il nostro sistema è un insieme di vari metodi di apprendimento automatico, che sfruttano sia i tradizionali classificatori basati su funzionalità che i recenti progressi nei modelli linguistici pre-formati che aiutano a catturare le caratteristiche sintattiche, semantiche e contestuali dai tweet. Utilizziamo inoltre pseudo-etichettatura per incorporare i dati Twitter non etichettati rilasciati sulla pandemia. Il nostro modello più performante raggiunge un punteggio F1 di 0,9179 sul set di convalida fornito e 0,8805 sul set di test cieco.", 'mk': 'Во оваа работа го опишуваме нашиот систем за заедничката задача на ВНУТ-2020 за идентификација на информативните Твитови COVID-19 англиски. Нашиот систем е ансембл на различни методи на машинско учење, користејќи ги и традиционалните класификатори базирани на карактеристики, како и неодамнешните напредоци во предобучените јазички модели кои помагаат во снимањето на синтактичките, семантичните и контекстните карактеристики од тв Понатаму користиме псевдо-означување за да ги вклучиме неозначените податоци на Твитер објавени на пандемијата. Нашиот најдобро извршен модел постигнува оценка Ф1 од 0,9179 на обезбедениот валидациски сет и 0,8805 на слепот тест сет.', 'ml': 'ഈ ജോലിയില്\u200d ഞങ്ങള്\u200d വിവരമറിയിക്കുന്നത് വിവരങ്ങള്\u200d കോവിഡി-19 ഇംഗ്ലീഷ് ടൂട്ടുകളുടെ തിരിച്ചറിയുന്നതിനെപ്പറ്റിയാണ നമ്മുടെ സിസ്റ്റത്തിന്റെ വ്യത്യസ്ത മെഷീന്\u200d പഠിപ്പിക്കുന്ന രീതികളുടെ ഒരു മാതൃകയാണ്, പാരമ്പര്യമായ ക്ലാസ്ഫീഷറുകള്\u200d രണ്ടും അടിസ്ഥാനമാക്കുന്നു. പുതിയ പരിശീലന ഭാഷ മോഡല പാന്\u200dഡെമിക്കില്\u200d വിട്ടിട്ടില്ലാത്ത ടുറല്\u200d ഡേറ്റാകള്\u200d ഉള്\u200dപ്പെടുത്താന്\u200d വേണ്ടി ഞങ്ങള്\u200d പോസുഡോ-ലേബിളില്\u200d  Our best performing model achieves an F1-score of 0.9179 on the provided validation set and 0.8805 on the blind test-set.', 'kk': 'Бұл жұмыс ішінде біз WNUT-2020 жалпы тапсырманың бір жүйеңізді ағылшын тійтіктерінің идентификациясы туралы анықтаймыз. Біздің жүйеміз әртүрлі машиналық оқыту әдістерінің синтактикалық, семантикалық және тәуелсіздік қасиеттерді түсіруге көмектесетін тіл үлгілерінде жаңа жағдайларды көмектеседі. Біз пандемияда шығарылмаған Twitter деректерін қосу үшін псевдо белгілерін қолданамыз. Біздің ең жақсы істеу үлгісіміз келтірілген тексеру бағдарламасында 0, 9179 деген F1- нәтижесін жеткізеді және 0, 8805 деген тексеру бағдарламасында.', 'mt': 'F’din il-ħidma, aħna niddeskrivu s-sistema tagħna għad-WNUT-2020 kompitu komuni dwar l-identifikazzjoni ta’ tweets informativi COVID-19 Ingliż. Is-sistema tagħna hija ġabra ta’ diversi metodi ta’ tagħlim bil-magni, li tinbena kemm klassifikaturi tradizzjonali bbażati fuq karatteristiċi kif ukoll avvanzi reċenti f’mudelli lingwistiċi mħarrġa minn qabel li jgħinu fil-qbid tal-karatteristiċi sintattiċi, semantiċi u kuntestwali mit-tweets. Aħna qed nużaw ukoll psewdotikkettar biex inkorporaw id-dejta bla tikketta fuq Twitter rilaxxata dwar il-pandemija. Il-mudell tagħna bl-aħjar prestazzjoni jilħaq punteġġ F1 ta’ 0.9179 fuq is-sett ta’ validazzjoni pprovdut u 0.8805 fuq is-sett tat-test għamja.', 'lt': 'Šiame darbe apibūdiname mūsų WNUT-2020 bendrą užduotį nustatyti informacinius COVID-19 anglų tweetus. Mūsų sistema yra įvairių mašininio mokymosi metodų rinkinys, sutelkiantis tiek tradicinius savybių klasifikatorius, tiek naujausią pažangą iš anksto parengtuose kalbų modeliuose, kurie padeda surinkti sintaktines, semantines ir kontekstines savybes iš tweetų. Be to, naudojame pseudo ženklinimą, kad būtų įtraukti apie pandemiją paskelbti nepažymėti Twitter duomenys. Our best performing model achieves an F1-score of 0.9179 on the provided validation set and 0.8805 on the blind test-set.', 'ms': 'Dalam kerja ini, kami menggambarkan sistem kami untuk tugas kongsi WNUT-2020 mengenai pengenalan tweet informatif COVID-19 Inggeris. Sistem kita adalah satu kumpulan kaedah pembelajaran mesin berbeza, menggunakan kedua-dua klasifikasi tradisional berdasarkan ciri-ciri serta kemajuan baru-baru ini dalam model bahasa yang dilatih dahulu yang membantu menangkap ciri-ciri sintaktik, semantik, dan kontekstual dari tweet. Kami menggunakan pseudo-label untuk memasukkan data Twitter yang tidak berlebihan yang dilepaskan pada pandemia. Model terbaik kami mencapai skor F1 0.9179 pada set pengesahihan yang diberikan dan 0.8805 pada set ujian buta.', 'mn': 'Энэ ажил дээр бид WNUT-2020 оны мэдээллийн COVID-19 Англи хэлний tweets-ын тодорхойлолтын тухай хуваалцах ажлын системийг тайлбарлаж байна. Бидний систем бол олон машин суралцах арга загвар юм. Хоёр уламжлалтай хуваарилагчид болон сургалтын өмнө суралцагдсан хэл загваруудын хөгжлийг ашигладаг. Энэ нь синтактик, семантик, орчин үеийн тодорхойлолтуудын тусламжтай. Бид өөр хэлбэл санамсаргүй Twitter өгөгдлийг пандемик дээр нэвтрүүлэхэд pseudo-labelling ашиглаж байна. Бидний хамгийн сайн үйлдвэрлэлийн загвар нь хараагүй шалгалтын багтаах 0.9179 оноо, 0.8805 оноо гаргадаг.', 'pl': 'W niniejszej pracy opisujemy nasz system wspólnego zadania WNUT-2020 dotyczącego identyfikacji informacyjnych tweetów w języku angielskim COVID-19. Nasz system jest zestawem różnych metod uczenia maszynowego, wykorzystujących zarówno tradycyjne klasyfikatory oparte na funkcjach, jak i ostatnie postępy w przeszkolonych modelach językowych, które pomagają w uchwyceniu składni, semantycznych i kontekstowych cech tweetów. Ponadto stosujemy pseudoznakowanie, aby uwzględnić nieoznakowane dane na Twitterze opublikowane w związku z pandemią. Nasz najlepiej wydajny model osiąga wynik F1 0.9179 na dostarczonym zestawie walidacyjnym i 0.8805 na zestawie testowym niewidomym.', 'no': 'I dette arbeidet beskriver vi systemet vårt for delt oppgåve i WNUT-2020 om identifiseringa av informativ COVID-19 engelsk tweets. Sistemet vårt er ein ensembel av ulike maskinelæringsmetodar, som leverer både tradisjonelle funksjonsbaserte klassifikatorar, og nyleg avansert i føretrainerte språkkmodeller som hjelper i å henta syntaktiske, semantiske og kontekstske funksjonane frå tweetene. Vi bruker meir pseudomerkelapp for å inkludere dei ukjende Twitter-data som er utgjeven på pandemikken. Vårt beste utføringsmodul oppnår eit F1- poeng med 0,9179 på den tilgjengelege valeringssettet og 0,8805 på blinde testsettet.', 'si': 'මේ වැඩේ අපි අපේ පද්ධතිය විස්තර කරන්නේ WNOT-2020යි තොරතුරු COVID-19 ඉංග්\u200dරීසි ට්විට්ස් ගැන සම්බන්ධ වැඩ කරන්න. අපේ පද්ධතිය තමයි විවිධ පද්ධතිය ඉගෙන ගන්න විදිහට පද්ධතිය පද්ධතිය, පද්ධතිය පද්ධතිය පද්ධතිය පද්ධතිය සහ ප්\u200dරධානය කරපු භාෂාව මොඩේල් වලින අපි තවත් ප්\u200dරශ්නයක් ලේබිලික් කරන්න ප්\u200dරශ්නයක් තියෙන්නේ නැහැ ට්විටර් දත්ත ප්\u200dරශ්නයක් තියෙන්න. අපේ හොඳම ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පරීක්ෂණ සෙට් එකේ F1-ස්කෝර් 0.9179 වලින් පරීක්ෂණයක් ලැබෙනවා.', 'ro': 'În această lucrare, descriem sistemul nostru pentru sarcina comună WNUT-2020 privind identificarea tweeturilor informative COVID-19 în limba engleză. Sistemul nostru este un ansamblu de diferite metode de învățare automată, utilizând atât clasificatoarele tradiționale bazate pe caracteristici, cât și progresele recente în modelele lingvistice pre-instruite, care ajută la captarea caracteristicilor sintactice, semantice și contextuale din tweet-uri. De asemenea, folosim pseudo-etichetare pentru a încorpora datele Twitter fără etichetare lansate în legătură cu pandemia. Modelul nostru cel mai performant obtine un scor F1 de 0,9179 pe setul de validare furnizat si 0,8805 pe setul de test blind.', 'sr': 'U ovom poslu opisujemo naš sistem za zajednički zadatak WNUT-2020 o identifikaciji informativnih COVID-19 engleskih tweets. Naš sistem je kompleks različitih metoda učenja mašine, koji utiču na tradicionalne klasifikacije na funkciju, kao i nedavne napredke u predobučenim jezičkim modelima koji pomažu u uhvativanju sintaktičnih, semantičnih i kontekstualnih karakteristika iz tweeta. Dalje zapošljavamo pseudo-etiketiranje kako bi uključili neizbiljne podatke o Twitter objavljene na pandemiju. Naš najbolji izvršni model postiže F1 rezultat od 0,9179 na obezbeđenom setu za validaciju i 0,8805 na slepom setu testova.', 'ta': 'இந்த வேலையில், நாம் WNUT-2020 க்கு எங்கள் அமைப்பை விவரிக்கிறோம் தகவல் COVID-19 ஆங்கிலத்தின் குறிப்பிட்ட வேலையை காண்ப எங்கள் அமைப்பு பல்வேறு இயந்திரம் கற்றுக் கொள்ள முறைகளின் முறையாகும், இருவரும் மரபார்ந்த குணங்கள் அடிப்படையில் வகுப்பாளர்கள் மற்றும் சமீபத்திய மொழி மாதிரிகளில் முன்னேற நாங்கள் மேலும் பியூடோ-அறிவிப்பை வேலை செய்கிறோம் துன்பம் மீது வெளியிடப்படாத த தொடர் தகவலை சேர்க்க. எங்கள் சிறந்த செயல்படுத்தல் மாதிரி கொடுக்கப்பட்ட சரிபார்த்தல் அமைப்பில் ஒரு F1- புள்ளியை பெறுகிறது மற்றும் குருட்ட சோதனை அம', 'sv': 'I detta arbete beskriver vi vårt system för WNUT-2020 delad uppgift om identifiering av informativa COVID-19 engelska tweets. Vårt system är en ensemble av olika maskininlärningsmetoder, som utnyttjar både traditionella funktionsbaserade klassificerare och senaste framsteg i pre-utbildade språkmodeller som hjälper till att fånga syntaktiska, semantiska och kontextuella funktioner från tweeten. Vi använder även pseudomärkning för att införliva de omärkta Twitter-data som släpptes om pandemin. Vår bäst presterande modell uppnår en F1-poäng på 0,9179 på den medföljande valideringsuppsättningen och 0,8805 på den blinda testuppsättningen.', 'ur': 'اس کام میں ہم نے WNUT-2020 کے لئے ہماری سیسٹم کو معلومات COVID-19 انگلیسی ٹویٹوں کی شناسایی پر مشترک کیا ہے. ہمارا سیستم مختلف ماشین یادگیری طریقے کا ایک انجمل ہے، جو دونوں سنتی فرینٹی فرینٹیوں پر بنیاد رکھی ہوئی کلاسیفوں اور ان سے پہلے آموزش کی زبان موڈلوں میں اضافہ کرتی ہے جو ٹویٹوں سے سینٹکتیک, سیمنٹی اور کنٹکسٹیول فرینٹیوں کو پکڑنے کی مدد کرتی ہیں ہم اس سے زیادہ سوئڈو لابلینگ کا استعمال کرتے ہیں کہ پانڈمیک کے ذریعے بغیر قابل توئیٹر ڈیٹے شامل کریں۔ ہمارے بہترین نمونڈل کو 0.9179 کی F1-score پہنچا سکتا ہے اور 0.8805 اندھے امتحان سٹ پر۔', 'so': "Shaqadan ayaannu qoraynaa nidaamka WNUT-2020 oo ku saabsan aqoonsashada macluumaadka COVID-19 tweetka Ingiriiska. Isticmaddeenu waa qaabab waxbarasho oo kala duduwan oo machine ah, oo ku sameynaya fasaxyada tababarida ah iyo horumarinta ugu dambeeya tusaalaha afka hore oo la tababaray, kaas oo caawinaya in la qabsado qalabka isqabsashada, semantika iyo waxyaabaha ku saabsan ee Tweetka. Waxaynu u shaqaynaynaa si aan u soo gelino macluumaadka Twitterka ee aan la aqoonin oo cudurka lagu soo daayay. Tusaale sameynta ugu wanaagsan wuxuu gaadhaa kooxda F1 oo ka mid ah 0.9179 ee lagu xaqiijiyey saxda xaqiiqsiga iyo 0.8805 oo lagu sameynayo imtixaanka indhaha la'aa.", 'uz': "Bu ishda, biz WNUT-2020 ishlarimizni ko'rsatuvchimiz haqida xabari COVID-19 ingliz tweetilarni aniqlashda. Bizning tizimmiz bir xil mashinalar o'rganish usullarining bir misol, o'zimning tabiiy xususiyatlarini va yaqinda o'rganilgan tillar modellarini va o'rtacha taʼminlov qiladigan foydalanuvchilarni xabar qilish uchun foydalanishi mumkin. Biz pandemikda chiqarilgan Twitter haqida qo'llanmiz. Bizning eng yaxshi bajarish modelimiz toʻgʻri berilgan soʻzda 0.9179 faqat 0.9179 pochta topadi va ko'p sinov moslamalarida 0.8805 tugatadi.", 'vi': 'Trong công việc này, chúng tôi mô tả hệ thống của chúng tôi về WGiờ-2020 đồng ý việc nhận dạng tweet cung cấp thông tin của COVID-19. Hệ thống của chúng tôi là một kết hợp của các phương pháp học máy khác nhau, điều khiển cả các phân loại có tính năng truyền thống cũng như những tiến bộ mới trong các mô hình ngôn ngữ được rèn luyện sẵn giúp bắt các tính năng theo ngữ từ tweet. Chúng tôi còn dùng giả mạo để ghi vào những dữ liệu Twitter chưa được ngụy trang được tung lên trên đại dịch. Cách trình diễn tốt nhất của chúng ta đạt điểm F1 của 0.9179 trên bộ sửa chữa cung cấp và 0.8805 trên bộ thử nghiệm mù.', 'bg': 'В тази работа описваме нашата система за споделена задача за идентифициране на информативни английски туитове. Нашата система е ансамбъл от различни методи за машинно обучение, използвайки както традиционните класификатори, базирани на функции, така и последните постижения в предварително обучените езикови модели, които помагат за улавяне на синтактичните, семантичните и контекстуалните характеристики от туитовете. Освен това използваме псевдо-етикетиране, за да включим незабелязаните данни от Туитър, публикувани за пандемията. Нашият най-добър модел постига оценка от 0,9179 при предоставения набор за валидиране и 0,8805 при слепите тестове.', 'nl': 'In dit werk beschrijven we ons systeem voor WNUT-2020 gedeelde taak over het identificeren van informatieve COVID-19 Engelse tweets. Ons systeem is een ensemble van verschillende machine learning methoden, waarbij gebruik wordt gemaakt van zowel traditionele feature-based classificatoren als recente vooruitgang in vooraf getrainde taalmodellen die helpen bij het vastleggen van de syntactische, semantische en contextuele kenmerken van de tweets. Verder gebruiken we pseudo-labeling om de niet-gelabelde Twitter-gegevens die over de pandemie zijn vrijgegeven op te nemen. Ons best presterende model behaalt een F1-score van 0.9179 op de meegeleverde validatieset en 0.8805 op de blinde test-set.', 'hr': 'U ovom poslu opisujemo naš sustav za zajednički zadatak WNUT-2020 o identifikaciji informativnih COVID-19 engleskih tweets. Naš sustav je kompleks različitih metoda učenja strojeva, koji utječe na tradicionalne klasifikatore, kao i nedavni napredak u predobučenim jezičkim modelima koji pomažu uhvatiti sintaktične, semantične i contextualne karakteristike iz tweets. Dalje zapošljavamo pseudo-etiketiranje kako bi uključili neizbiljne Twitter podatke objavljene o pandemiji. Naš najbolji izvršni model postiže F1 rezultat od 0,9179 na određenoj potvrdi i 0,8805 na slijepi test setu.', 'da': 'I dette arbejde beskriver vi vores system til WNUT-2020 delt opgave om identifikation af informative COVID-19 engelske tweets. Vores system er et ensemble af forskellige maskinindlæringsmetoder, der udnytter både traditionelle funktionsbaserede klassificeringsmetoder samt nylige fremskridt inden for prætrænede sprogmodeller, der hjælper med at fange de syntaktiske, semantiske og kontekstuelle funktioner fra tweets. Vi anvender endvidere pseudo-mærkning til at indarbejde de ikke-mærkede Twitter-data, der blev frigivet om pandemien. Vores bedst ydende model opnår en F1-score på 0,9179 på det medfølgende valideringssæt og 0,8805 på blindtestsættet.', 'de': 'In dieser Arbeit beschreiben wir unser System für WNUT-2020 gemeinsame Aufgabe zur Identifizierung informativer COVID-19 englischer Tweets. Unser System ist ein Ensemble verschiedener Methoden des maschinellen Lernens, das sowohl traditionelle Feature-basierte Klassifikatoren als auch aktuelle Fortschritte in vortrainierten Sprachmodellen nutzt, die helfen, syntaktische, semantische und kontextuelle Merkmale aus den Tweets zu erfassen. Darüber hinaus verwenden wir Pseudo-Labeling, um die zur Pandemie veröffentlichten Twitter-Daten ohne Kennzeichnung einzubeziehen. Unser leistungsstärkstes Modell erreicht eine F1-Punktzahl von 0.9179 auf dem mitgelieferten Validierungsset und 0.8805 auf dem Blindtest-Set.', 'id': 'Dalam pekerjaan ini, kami menggambarkan sistem kami untuk WNUT-2020 tugas berbagi mengenai identifikasi tweet informatif COVID-19 Inggris. Sistem kita adalah sebuah ensemble dari berbagai metode pembelajaran mesin, menggunakan kedua klasifikasi tradisional berdasarkan ciri-ciri serta kemajuan baru-baru ini dalam model bahasa yang terlatih yang membantu menangkap ciri-ciri sintaktik, semantis, dan kontekstual dari tweet. Kami lebih lanjut menggunakan pseudo-label untuk mengikorporasi data Twitter yang tidak disebut yang diberikan pada pandemia. Model terbaik kami mencapai skor F1 0,9179 pada set validasi yang diberikan dan 0,8805 pada set tes buta.', 'fa': 'در این کار، سیستم خود را برای کار مشترک WNUT-2020 در مورد شناسایی توئیت های انگلیسی COVID-19 اطلاعات توصیف می کنیم. سیستم ما یک جمله از روش یادگیری ماشین مختلف است که هر دو گروهی که بر اساس ویژه\u200cهای سنتی و پیشرفت اخیر در مدل\u200cهای پیش آموزش زبان\u200cها کمک می\u200cکند در دستگیر ویژه\u200cهای سنتاکتیک، سیمانتیک و موضوعی از تویت\u200cها می\u200cکند. ما بیشتر از آن از نقاشی pseudo-labelling استفاده می کنیم تا اطلاعات توئیتر غیرقابل نوشته شده را در پاندوم شامل کنیم. بهترین مدل اجرای ما یک نمونه F1 از 0.9179 در مجموعه تأیید داده شده و 0.8805 در مجموعه تأیید کور رسیده است.', 'ko': '이 작업에서는 정보가 풍부한 코로나 영어 트윗을 인식하는 WNUT-2020 공유 임무 시스템을 기술했다.우리의 시스템은 각종 기계 학습 방법의 집합이다. 전통적인 특징을 바탕으로 하는 분류기를 이용했을 뿐만 아니라 예훈련 언어 모델의 최신 진전도 이용했다. 이런 모델은 추문에서 문법, 의미와 상하문 특징을 포착하는 데 도움이 된다.우리는 더 나아가 팬데믹에 대한 표기되지 않은 트위터 데이터를 통합하기 위해 위조 라벨 기술을 사용했다.우리가 가장 잘 표현한 모델은 제공된 검증집에서의 F1은 0.9179, 블라인드 테스트집에서의 F1은 0.8805로 나타났다.', 'sw': 'Katika kazi hii, tunaelezea mfumo wetu wa WNUT-2020 ulishirikiana na kazi ya kutambua twiti za habari za COVID-19 Kiingereza. Mfumo wetu ni mfumo wa namna mbalimbali za kujifunza mashine, kwa kutumia wataalamu wote wenye msingi wa kitamaduni pamoja na maendeleo ya hivi karibuni katika mifano ya lugha zilizofunzwa yaliyosaidia kuchukua mbinu za ushirikiano, semantic, na vipengele vya wakati wa twita. Tunajiri tena kutumia maambukizi ya kijeshi ili kuunganisha taarifa za Twita zisizotambuliwa kuhusu janga hilo. Mfano wetu bora wa kutengeneza unafanikiwa vipimo vya F1 vya 0.9179 kwenye seti ya uhakika na 0.8805 kwenye seti ya vipofu.', 'af': "In hierdie werk beskrywe ons stelsel vir WNUT-2020 deel taak op die identifiseer van informatiewe COVID-19 Engelske tweets. Ons stelsel is 'n ensembleem van verskeie masjien leer metodes, wat beide tradisionele funksie-gebaseerde klassifiseerders as ook onlangse vorderings in voorafgevorderde taal modele wat hulp in die opvang van die sintaktike, semantiese en kontekslike funksies van die tweets. Ons gebruik verder pseudo-etiketting om die ongeabelde Twitter-data op die pandemiek te inkorporeer. Ons beste uitvoerde model bereik 'n F1- telling van 0. 9179 op die verskaf geldigheidstel en 0. 8805 op die blinde toestel.", 'tr': "Bu işde biziň sistemimizi WNUT-2020'yň informative COVID-19 Iňlisçe tweetlerini tanyşdyrmak üçin ylalaşýarys. Biziň sistemamyz dürli maşyny öwrenmek taryşlarynyň bir köpüsi. Däpli dünýäpli tanyşlaryň üstine ýaşan tanyşlaryň we öňki öňki bilim nusgalarynda syntaktik, semantik we tweetlerin içine ýazmakda kömek eden gelişmeleri etýär. Biz daşary çykyp bilmedik Twitter maglumatlaryny pandemiýada çykarmak üçin pseudo-etiketlemegi ulanýarys. Biziň iň gowy çykyş nusgasymyz 0.9179 अंतर tapylýar we 0.8805 kör test setinde.", 'am': 'በዚህ ሥራ የWNUT-2020 የኢንግሊዝኛ ትዊተሮችን ለማግኘት የኢንተርኔት COVID-19 ስራዎችን እናሳውቃለን፡፡ ሲስተማሪያችን የልዩ ዓይነቶች ትምህርት ሥርዓት ነው፣ የባሕላዊ የፊደል ክፍተቶችን እና የቀድሞው የቋንቋ ምሳሌዎች፣ የስንተርታኪ፣ የስሜንቲክ እና የአሁኑን ሁኔታዊ ፍትሕቶችን በመያዝ የሚረዳቸውን ትዊተሮችን በመስጠት የሚሰጥተዋል፡፡ በጭንቀት ላይ ያልተፈቀደውን የTwitter 数据ን ለማግባት እናስገራለን፡፡ የተሻለን የሥርዓት ዓይነት የ0.9179 የሥርዓት ክፍል እና የዕውር ፈተና መስመር ላይ 0.8805 አግኝቷል።', 'sq': 'Në këtë punë, ne përshkruajmë sistemin tonë për detyrën e përbashkët të WNUT-2020 mbi identifikimin e tweeteve informative COVID-19 angleze. Sistemi ynë është një grup i metodave të ndryshme të mësimit të makinave, duke përfituar si klasifikuesit tradicionalë të bazuar në funksione si dhe përparimet e fundit në modelet e gjuhës paratrajnuara që ndihmojnë në kapjen e karakteristikave sintaktike, semantike dhe kontekstuale nga tweetet. We further employ pseudo-labelling to incorporate the unlabelled Twitter data released on the pandemic.  Modeli ynë më i mirë performues arrin një rezultat F1 prej 0.9179 në sistemin e siguruar të vlerësimit dhe 0.8805 në sistemin e verbër të testit.', 'hy': 'Այս աշխատանքի ընթացքում մենք նկարագրում ենք մեր համակարգը ԱՄՆԹ-2020-ի ընդհանուր հանձնարարությունը COVID-19 անգլերեն թվիթերի հայտնաբերման մասին: Մեր համակարգը տարբեր մեթոդների համակարգ է, որոնք օգտագործում են երկու ավանդական հատկանիշներով հիմնված դասակարգիչներ, ինչպես նաև վերջին առաջընթացներ նախապատրաստված լեզվի մոդելների մեջ, որոնք օգնում են բռնել թվիթերի սինտակտիկ, սեմանտիկ և կոնտեքստալ հատկանի Մենք նաև օգտագործում ենք կեղծ պիտակում, որպեսզի ներառենք անպիտակ Թվիթերի տվյալները, որոնք արտադրվում են համաճարակի վրա: Մեր լավագույն արդյունավետության մոդելը հասնում է 0.9179-ի F1-գնահատականի, որը ներկայացված է հավասարման համակարգում, և 0.88-ի 0.88-ի՝ կոյր թեստերի համակարգում:', 'bn': 'এই কাজে আমরা আমাদের ব্যবস্থা ব্যাখ্যা করছি যে তথ্য কোভিড-১৯ ইংরেজী টুইটের পরিচয় প্রকাশ করা হয়েছে। আমাদের সিস্টেম হচ্ছে বিভিন্ন মেশিন শিক্ষা পদ্ধতির একটি প্রতিষ্ঠান, ঐতিহ্যবাহী বৈশিষ্ট্য ভিত্তিক শ্রেণীদের প্রতিষ্ঠান এবং সাম্প্রতিক প্রশিক্ষিত ভাষার মডেলে প্ প্যান্ডেমের উপর প্রকাশিত টুইটারের তথ্য অন্তর্ভুক্ত করার জন্য আমরা আরো পাসুডো লেবেলিং চাকরি করি। আমাদের সবচেয়ে ভালো প্রদর্শন মডেলটি প্রদান করা বৈধ সেট এবং অন্ধ পরীক্ষা সেটে ০.', 'bs': 'U ovom poslu opisujemo naš sistem za zajednički zadatak WNUT-2020 o identifikaciji informativnih COVID-19 engleskih tweets. Naš sistem je kompleks različitih metoda učenja mašina, koji utječe na tradicionalne klasifikatore, kao i nedavne napredke u predobučenim jezičkim modelima koji pomažu u uhvativanju sintaktičnih, semantičnih i kontekstalnih karakteristika iz tweeta. Dalje zapošljavamo pseudo-etiketiranje kako bi uključili neizbiljne Twitter podatke objavljene o pandemiji. Naš najbolji izvršni model postiže F1 rezultat od 0,9179 na pruženoj potvrdi i 0,8805 na slijepi test setu.', 'ca': "En aquesta feina, descrivim el nostre sistema per a la tasca compartida WNUT-2020 sobre la identificació de tweets informatius COVID-19 anglès. El nostre sistema és un conjunt de diversos mètodes d'aprenentatge màquinari, aprofitant tant classificadors tradicionals basats en característiques com avanços recents en models de llenguatge pré-entrenats que ajuden a capturar les característiques sinàctiques, semàntiques i contextuals dels tweets. We further employ pseudo-labelling to incorporate the unlabelled Twitter data released on the pandemic.  El nostre model de millor rendiment aconsegueix una puntuació F1 de 0,9179 en el conjunt de validació proporcionat i 0,8805 en el conjunt de prova cec.", 'cs': 'V této práci popisujeme náš systém pro sdílený úkol WNUT-2020 na identifikaci informativních anglických tweetů COVID-19. Náš systém je souborem různých metod strojového učení, které využívají jak tradiční klasifikátory založené na funkcích, tak i nedávné pokroky v předškolených jazykových modelech, které pomáhají zachytit syntaktické, sémantické a kontextové funkce z tweetů. Dále používáme pseudoznačení k začlenění neoznačených dat Twitteru zveřejněných o pandemii. Náš nejlepší model dosahuje F1 skóre 0,9179 na dodané validační sadě a 0,8805 na slepé testovací sadě.', 'et': 'Käesolevas töös kirjeldame meie WNUT-2020 jagatud ülesannet COVID-19 inglise keelsete säutsude tuvastamiseks. Meie süsteem on mitmesuguste masinõppe meetodite komplekt, mis kasutab nii traditsioonilisi funktsioonipõhiseid klassifitseerijaid kui ka hiljutisi edusamme eelõpetatud keelemudelites, mis aitavad jäädvustada säutsudest süntaktilisi, semantilisi ja kontekstuaalseid funktsioone. Lisaks kasutame pseudomärgistust, et lisada pandeemia kohta avaldatud märgistamata Twitteri andmed. Meie parima tulemusega mudel saavutab esitatud valideerimiskomplekti puhul F1-skoori 0,9179 ja pimekatsekomplekti puhul 0,8805.', 'fi': 'Tässä työssä kuvailemme WNUT-2020:n jaettua tehtäväämme informatiivisten COVID-19 englanninkielisten twiittien tunnistamiseksi. Järjestelmämme koostuu erilaisista koneoppimismenetelmistä, jotka hyödyntävät sekä perinteisiä ominaisuuspohjaisia luokittelijoita että viimeaikaisia edistysaskeleita ennalta koulutetuissa kielimalleissa, jotka auttavat tallentamaan syntaktisia, semanttisia ja kontekstuaalisia ominaisuuksia tweeteistä. Lisäksi käytämme pseudomerkintää sisällyttääksemme pandemiasta julkaistut merkitsemättömät Twitter-tiedot. Parhaiten suorituskykyinen mallimme saavuttaa F1-pisteet 0,9179 toimitetussa validointisarjassa ja 0,8805 sokeatestisarjassa.', 'az': 'Bu iŇüd…ô, WNUT-2020 sistemimizin paylaŇüńĪlmńĪŇü iŇül…ôri informativ COVID-19 ńįngiliz…ô tweetl…ôrinin tanńĪmlamasńĪ haqqńĪnda tanńĪmlńĪyńĪq. Bizim sistemimiz m√ľxt…ôlif maŇüńĪn √∂yr…ônm…ô metodlarńĪnńĪn ensembliyidir, h…ôr ikisini t…ôhsil edilmiŇü x√ľsusiyy…ôtl…ôrin v…ô tweetl…ôrin sintaktik, semantik v…ô m√ľxt…ôlif √∂zellikl…ôrini tutmańüa yardńĪm ed…ôn √∂yr…ônm…ôli dil modell…ôrind…ô son √∂yr…ônm…ôl…ôr…ô istifad…ô edir. Biz pandemik √ľz…ôrind…ô yayńĪndńĪrńĪlmayan Twitter m…ôlumatlarńĪnńĪ birl…ôŇüdirm…ôk √ľ√ß√ľn pseudo-etiketini istifad…ô edirik. Bizim …ôn yaxŇüńĪ performancńĪ modell…ôrimiz k√∂r sńĪnama setind…ô 0,9179-d…ôn F1 d…ôr…ôc…ôsini q…ôbul edir.', 'jv': 'Nang barêng-barêng iki, kita rambarang sistem kanggo nyelarani WNUT-2020 kuwi bagian nggawe gerakan urip nggambar informasi corid-19 tuytes Inggris Sistem awak dhéwé énêmên ngerasakno karo sistem sampeyan karo ngono nggawe sistem sing nyimpen karo perusahaan-seneng nggawe sistem sing dibutuhke sistem sampeyan karo paké diangreraké nggawe sistem sing dibutuhke tarjamahan karo perusahaan winih (modèl karo paké) sing berarti ngono nggawe sistem sing dib Awak dhéwé mengko perusahaan psepse-label kanggo ngilangno ngerasakno dadi Tutter sing nganggo maneh. Nampur model sing dibenakake perusahaan tanggal F1-0.9', 'he': 'בעבודה הזו, אנחנו מתארים את המערכת שלנו עבור משימה משותפת WNUT-2020 על זיהוי טוויטים אינפורטיביים COVID-19 אנגליים. המערכת שלנו היא אסמבל של שיטות למידה מכונות שונות, שמשתמשים על קלאספים מסורתיים מבוססים על תכונות, כמו גם התקדמות לאחרונה בדוגמנים לשפה מאומנים מראש שמעזרים לתפוס את תכונות הסינטקטיות, סמנטיות והקונטוקטואליות מהטוויטים. אנחנו משתמשים יותר בסאודו-טיקוט כדי להכיל את נתוני הטוויטר ללא סימנים שפורסמים על הפנדמיה. מודל ההופעה הטובה ביותר שלנו משיג נקודת F1 של 0.9179 בסט האישור המסופק ו-0.8805 בסט הבדיקות העיוור.', 'sk': 'V tem delu opisujemo naš sistem za skupno nalogo WNUT-2020 za identifikacijo informativnih COVID-19 angleških tweetov. Naš sistem je komplet različnih metod strojnega učenja, ki uporabljajo tako tradicionalne klasifikatorje, ki temeljijo na funkcijah, kot tudi nedavne napredeke v vnaprej usposobljenih jezikovnih modelih, ki pomagajo pri zajemanju sintaktičnih, semantičnih in kontekstualnih značilnosti iz tweetov. Nadalje uporabljamo psevdoznačevanje za vključitev neoznačenih podatkov Twitterja, objavljenih o pandemiji. Naš najboljši model doseže rezultat F1 0,9179 pri zagotovljenem kompletu validacije in 0,8805 pri slepih testnih kompletih.', 'ha': "Daga wannan aikin, muna bayyana kanmu na tsarin aikin WNUT-2020 da aka raba shi a kan gane na takardar takardar COV-19 na Ingiriya. Kayyakanmu na zama wani shirin karatun masu karatun masu ƙidãya, yana samun su fasalarar masu bastarwa na ƙidãya, da sami masu ƙarami cikin misalin harshen da aka yi wa zaman-wa'anar ta samu'a da amfani da yin fani ga sami-takikin, semantiki da masu sauki daga Twitter. Za sami kowaci da ake yi wa samun da za'a sami da data na Twitter wanda ba'a yi ba da aikin sa a kan gonjwa. Tudun mafarin aikin da ke samun F1-score na 0.9179 kan daidaita da aka samar da shi da inganci da 0.8805 kan an sami-matsayin makanta.", 'bo': 'ལས་ཀ་འདིའི་ནང་དུ་ང་ཚོའི་མ་ལག་གི་WNUT-2020་ལ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་ནང་དུ་འགྲེལ་བཤད་ཀྱི་རྒྱུ་དངོས་ཐོག་ལས་(informative COVID-19) Our system is an ensemble of various machine learning methods, leveraging both traditional feature-based classifiers as well as recent advances in pre-trained language models that help in capturing the syntactic, semantic, and contextual features from the tweets. We further employ pseudo-labelling to incorporate the unlabelled Twitter data released on the pandemic. ང་ཚོའི་རྣམ་གྲངས་ཚད་དགའ་ཤོས་ཡོད་ཚད་ལྡན་འགྲོ་བ་སྒྲིག་འཛུགས་ཀྱི་ཚད་ལྡན་གྲངས 0.9179 ཡིས་མཐུན་དང་། གསལ་པོ་ཞིག་གི་སྒྲིག་འཛ'}
{'en': 'SunBear at WNUT-2020 Task 2 : Improving BERT-Based Noisy Text Classification with Knowledge of the Data domain S un B ear at  WNUT -2020 Task 2: Improving  BERT -Based Noisy Text Classification with Knowledge of the Data domain', 'ar': 'SunBear في WNUT-2020 المهمة 2: تحسين تصنيف النص الصاخب المستند إلى BERT مع معرفة مجال البيانات', 'es': 'SunBear en la Tarea 2 del WNUT-2020: Mejora de la clasificación de textos ruidosos basada en BERT con conocimiento del dominio de datos', 'fr': 'SunBear à la WNUT-2020 Tâche 2\xa0: Améliorer la classification des textes bruités basée sur BERT grâce à la connaissance du domaine des données', 'pt': 'SunBear no WNUT-2020 Tarefa 2: Melhorando a classificação de texto ruidoso baseada em BERT com conhecimento do domínio de dados', 'ja': 'WNUT -2020のSunBearタスク2 ：データドメインの知識を活用したBERTベースのノイズの多いテキスト分類の改善', 'hi': 'WNUT-2020 कार्य 2 पर SunBear: डेटा डोमेन के ज्ञान के साथ BERT-आधारित शोर पाठ वर्गीकरण में सुधार', 'zh': 'SunBear 在 WNUT-2020 务 2:以数域改 BERT 噪声文本类', 'ru': 'SunBear на WNUT-2020 Задача 2: Улучшение классификации шумного текста на основе BERT со знанием домена данных', 'ga': 'SunBear ag WNUT-2020 Tasc 2: Aicmiú Téacs Torainn Bhunaithe ar BERT a fheabhsú agus Eolas ar an bhfearann Sonraí', 'el': 'Εργασία 2: Βελτίωση της ταξινόμησης θορυβωδών κειμένων με βάση το BERT με γνώση του τομέα δεδομένων', 'ka': 'SunBear at WNUT-2020 Task 2: BERT-based Noisy Text Classification with Knowledge of the Data domain', 'hu': 'SunBear a WNUT-2020 2. feladat: A BERT-alapú zajszintű szövegosztályozás javítása az adatok ismeretével', 'it': 'SunBear a WNUT-2020 Task 2: Migliorare la classificazione dei testi rumorosi basata su BERT con la conoscenza del dominio dati', 'kk': 'SunBear at WNUT-2020 Task 2: BERT-based Noisy Text Classification with Knowledge of the Data domain', 'lt': 'SunBear WNUT-2020 2 uždavinys: BERT grindžiamo triukšmo teksto klasifikavimo gerinimas su žiniomis apie duomenų sritį', 'mk': 'SunBear на WNUT-2020 задача 2: подобрување на BERT-базираната класификација на звучен текст со знаење на доменот на податоци', 'ms': 'SunBear pada WNUT-2020 Tugas 2: Menembangkan Klasifikasi Teks Bunyi Berasas BERT dengan Pengetahuan domain Data', 'ml': 'WNUT- 2020 ടാസ്ക് 2- ലെ സൂര്യന്\u200d ബോര്\u200dട്ട്: ബെര്\u200dടി- അടിസ്ഥാനമായ നോയിസി ടെക്സ്റ്റ് ക്ലാസിഷഷന്\u200d ഡേറ്റ ഡോമെയിന്\u200dറെ അറിവുകള', 'mt': 'SunBear fid-WNUT-2020 Task 2: It-titjib tal-Klassifikazzjoni tat-Test tal-Istorbju bbażata fuq il-BERT bl-Għarfien tad-dominju tad-dejta', 'mn': 'SunBear at WNUT-2020 Task 2: BERT-Based Noisy Text Classification with Knowledge of the Data domain', 'no': 'SunBear at WNUT-2020 Task 2: Forbetra BERT-basert støytekstklassifikasjon med kjenning av datadomenet', 'pl': 'SunBear na WNUT-2020 Zadanie 2: Poprawa klasyfikacji szumu tekstu opartego na BERT z wiedzą o dziedzinie danych', 'ro': 'SunBear la WNUT-2020 Sarcina 2: Îmbunătățirea clasificării textelor zgomotoase bazate pe BERT cu cunoștințele domeniului de date', 'sr': 'SunBear na zadatku 2. WNUT-2020: poboljšanje klasifikacije teksta na BERT-u sa znanjem domena podataka', 'si': 'SunBear at WNOT-2020Job 2: BERT-based Noise Text Classication with KnowKnowKnowness of the Data domain', 'so': 'SunBear at WNUT-2020 Task 2: Improving BERT-Based Noisy Text Classification with Knowledge of the Data Domain', 'sv': 'SunBear vid WNUT-2020 Uppgift 2: Förbättra BERT-baserad bullerstextklassificering med kunskap om datadomänen', 'ta': 'WNUT- 2020 பணியில் சூரிய பிரயான்: தகவல் தளத்தின் அறிவுடன் BERT- அடிப்படையான தனித்தனை உரை வகைப்படுத்தல் மேம்படுத்தல்', 'ur': 'WNUT-2020 ٹاکس 2 میں SunBear: BERT-Based Noisy Text Classification with Knowledge of the Data domain', 'uz': 'Comment', 'vi': '*SunBear tại WGiờ-2020 Task 2: Name=Một loại Văn bản nhiễu loại cân não với sự hiểu biết về miền dữ liệu', 'bg': 'Задача 2: Подобряване на класификацията на шумен текст въз основа на БАРТ с познания за областта на данните', 'hr': 'SunBear na zadatku 2. WNUT-2020: poboljšanje klasifikacije teksta na BERT-u s znanjem domena podataka', 'da': 'SunBear ved WNUT-2020 Opgave 2: Forbedring af BERT-baseret støjsteksklassificering med viden om datadomænet', 'nl': 'SunBear op WNUT-2020 Taak 2: Verbetering van BERT-gebaseerde ruisige tekstclassificatie met kennis van het datadomein', 'id': 'SunBear di WNUT-2020 Task 2: Menembangkan Klasifikasi Teks Suara Berdasarkan BERT dengan Pengetahuan domain Data', 'fa': 'SunBear at WNUT-2020 Task 2: Improving BERT-Based Noisy Text Classification with Knowledge of the Data domain', 'de': 'SunBear bei WNUT-2020 Aufgabe 2: Verbesserung der BERT-basierten Rauschtextklassifizierung mit Kenntnis der Datendomäne', 'sw': 'Tovuti ya Sun kwenye kazi ya WNUT-2020 2: Kuboresha Makala ya Ujumbe wa Mataifa yenye msingi wa BERT kwa ufahamu wa Taarifa', 'tr': 'SunBear at WNUT-2020 Task 2: BERT-Based Noisy Text Classification with Knowledge of the Data domain', 'af': 'SunBear by WNUT-2020 Opdrag 2: verbetering van BERT-Based Noisy Teks Klassifikasie met kennis van die Data Domein', 'am': '2: Improving BERT-Based Noisy Text Classification with Knowledge of the Data Domain', 'sq': 'SunBear në WNUT-2020 Task 2: përmirësimi i klasifikimit të tekstit të zhurmshëm të bazuar në BERT me njohurinë e domenit të të dhënave', 'hy': 'SunBear-ը World-2020-ի 2-րդ հանձնարարում. BER-ի հիմնված աղմուկ տեքստի դասակարգման բարելավումը տվյալների տիեզերքի իմացությամբ', 'az': 'SunBear at WNUT-2020 Task 2: BERT-Based Noise Text Classification with Knowledge of the Data domain', 'bs': 'SunBear na zadatku 2. na WNUT-2020: poboljšanje klasifikacije teksta na BERT-u s znanjem domena podataka', 'bn': 'WNUT-2020 টাস্ক ২-এ সূর্য বায়ুর: ডাটা ডোমেইনের জ্ঞানের সাথে বেরেট-ভিত্তিক নোজি টেক্সট ক্লাসিকেশন উন্নতি করা হচ্ছে', 'ko': 'WNUT-2020의 SunBear Task 2: 데이터 필드 지식을 활용하여 BERT 기반 노이즈 텍스트 분류 개선', 'ca': 'SunBear a la 2ª tasca del WNUT-2020: millorar la classificació de textos ruidosos basada en BERT amb el coneixement del domini de dades', 'cs': 'SunBear na WNUT-2020 Úkol 2: Zlepšení klasifikace šumu textu založeného na BERT se znalostí datové domény', 'et': 'SunBear WNUT-2020 ülesandel 2: BERT-põhise mürataseme klassifitseerimise parandamine koos andmevaldkonna teadmistega', 'fi': 'SunBear WNUT-2020 -tapahtumassa Tehtävä 2: BERT-pohjaisen melutekstiluokituksen parantaminen datan tuntemuksella', 'jv': 'sunBeer at WNUT-2020 task 2: Incompating BERT-basic Nois Text', 'ha': 'KCharselect unicode block name', 'sk': 'SunBear na WNUT-2020 2. naloga: Izboljšanje klasifikacije hrupnega besedila na podlagi BERT-a s poznavanjem podatkovnega področja', 'bo': 'SunBear at WNUT-2020 Task 2: Improving BERT-Based Noisy Text Classification with Knowledge of the Data domain', 'he': 'SunBear ב-WNUT-2020 משימה 2: שיפור מסווג טקסט רעש מבוסס על BERT'}
{'en': 'This paper proposes an improved custom model for WNUT task 2 : Identification of Informative COVID-19 English Tweet. We improve experiment with the effectiveness of  fine-tuning methodologies  for state-of-the-art  language model  RoBERTa. We make a preliminary instantiation of this formal  model  for the text classification approaches. With appropriate training techniques, our model is able to achieve 0.9218  F1-score  on public validation set and the ensemble version settles at top 9  F1-score  (0.9005) and top 2 Recall (0.9301) on private test set.', 'ar': 'تقترح هذه الورقة نموذجًا مخصصًا محسّنًا لمهمة WNUT 2: تحديد تغريدة باللغة الإنجليزية حول COVID-19. نقوم بتحسين التجربة بفاعلية منهجيات الضبط الدقيق لنموذج اللغة الحديث RoBERTa. نقوم بعمل إنشاء مثيل أولي لهذا النموذج الرسمي لمقاربات تصنيف النص. باستخدام تقنيات التدريب المناسبة ، يكون نموذجنا قادرًا على تحقيق 0.9218 درجة F1 في مجموعة التحقق العامة واستقر إصدار المجموعة في أعلى 9 نقاط F1 (0.9005) وأعلى 2 سحب (0.9301) في مجموعة اختبار خاصة.', 'fr': "Cet article propose un modèle personnalisé amélioré pour la tâche WNUT 2\xa0: Identification of Informative COVID-19 English Tweet. Nous améliorons l'expérience avec l'efficacité des méthodologies de réglage fin pour le modèle linguistique de pointe Roberta. Nous faisons une instanciation préliminaire de ce modèle formel pour les approches de classification de texte. Avec des techniques d'entraînement appropriées, notre modèle est capable d'atteindre le score F1 de 0,9218 sur l'ensemble de validation public et la version d'ensemble se situe au top 9 du score F1 (0,9005) et au meilleur rappel (0,9301) sur un ensemble de test privé.", 'pt': 'Este artigo propõe um modelo personalizado aprimorado para a tarefa 2 do WNUT: Identificação do Tweet Informativo COVID-19 em inglês. Melhoramos a experiência com a eficácia de metodologias de ajuste fino para o modelo de linguagem de última geração RoBERTa. Fazemos uma instanciação preliminar deste modelo formal para as abordagens de classificação de texto. Com técnicas de treinamento apropriadas, nosso modelo é capaz de atingir 0,9218 F1-score no conjunto de validação público e a versão ensemble se estabelece no top 9 F1-score (0,9005) e top 2 Recall (0,9301) no conjunto de teste privado.', 'es': 'Este artículo propone un modelo personalizado mejorado para la tarea 2 de WNUT: Identificación del Tweet informativo en inglés sobre COVID-19. Mejoramos el experimento con la eficacia de afinar las metodologías para el modelo lingüístico de última generación RoBerta. Hacemos una instanciación preliminar de este modelo formal para los enfoques de clasificación de textos. Con las técnicas de entrenamiento adecuadas, nuestro modelo es capaz de lograr una puntuación F1 de 0.9218 en el conjunto de validación pública y la versión de conjunto se establece en la puntuación de 9 F1 (0.9005) y la recuperación de 2 mejores (0.9301) en el conjunto de pruebas privadas.', 'zh': '本文为WNUT务2:识信息性COVID-19英语推文进一自定义。 微调之有效性改实验,以得先进之语RoBERTa。 我们为文本分类的方法做了一个初步的实例。 以适教术,吾模形得于公共验集上至于 0.9218 F1 分数,而集于私有测试集上至于前 9 一 F1 分数 (0.9005) 与前 2 召率 (0.9301)。', 'ja': 'この論文では、WNUTタスク2: Informationative COVID -19英語ツイートの識別のための改良されたカスタムモデルを提案しています。最先端の言語モデルRoBERTaの微調整方法論の有効性の実験を改善しました。テキスト分類アプローチのために、この形式モデルの予備的なインスタンス化を行います。適切なトレーニング技術により、当社のモデルは公開検証セットで0.9218 F 1スコアを達成することができ、アンサンブルバージョンはプライベートテストセットでトップ9のF 1スコア（ 0.9005 ）とトップ2のリコール（ 0.9301 ）に落ち着きます。', 'ru': 'В этой статье предлагается улучшенная пользовательская модель для задачи 2 WNUT: Идентификация информационного твита о COVID-19 на английском языке. Мы совершенствуем эксперимент с эффективностью методик тонкой настройки для современной языковой модели RoBERTa. Мы делаем предварительную инстанцировку этой формальной модели для подходов классификации текста. С помощью соответствующих методов обучения наша модель может достичь 0,9218 балла F1 на публичном валидационном наборе, а ансамблевая версия расположится в топ 9 баллов F1 (0,9005) и топ 2 Recall (0,9301) на частном тестовом наборе.', 'hi': 'यह पेपर WNUT कार्य 2 के लिए एक बेहतर कस्टम मॉडल का प्रस्ताव करता है: सूचनात्मक कोविड -19 अंग्रेजी ट्वीट की पहचान। हम अत्याधुनिक भाषा मॉडल RoBERTa के लिए ठीक ट्यूनिंग तरीकों की प्रभावशीलता के साथ प्रयोग में सुधार. हम पाठ वर्गीकरण दृष्टिकोण के लिए इस औपचारिक मॉडल का एक प्रारंभिक इंस्टेंटेशन बनाते हैं। उपयुक्त प्रशिक्षण तकनीकों के साथ, हमारा मॉडल सार्वजनिक सत्यापन सेट पर 0.9218 F1-स्कोर प्राप्त करने में सक्षम है और पहनावा संस्करण निजी परीक्षण सेट पर शीर्ष 9 F1-स्कोर (0.9005) और शीर्ष 2 रिकॉल (0.9301) पर बसता है।', 'ga': 'Molann an páipéar seo múnla saincheaptha feabhsaithe do thasc WNUT 2: Tweet Béarla Faisnéiseach COVID-19 a Aithint. Cuirimid feabhas ar thurgnaimh le héifeachtacht modheolaíochtaí mionchoigeartaithe don mhúnla teanga nua-aimseartha RoBERTa. Déanaimid réamhrá ar an tsamhail fhoirmiúil seo do na cuir chuige aicmithe téacs. Le teicnící oiliúna cuí, is é ár múnla in ann a bhaint amach 0.9218 F1-scór ar bhailíochtú poiblí a leagtar agus socraíonn an leagan ensemble ag barr 9-scór F1 (0.9005) agus barr 2 Athghairm (0.9301) ar shraith tástála príobháideach.', 'ka': 'WNUT დავალებისთვის შესაძლებელი პროგრამეტური მოდელ 2: ინფორმაციური COVID- 19 ინგლისური Tweet- ის იდენტიფიკაცია. ჩვენ განვითარებთ ექსპერიმენტი რობერტია სახელსაწყისი მსოფლიოდ მეტოლოგიების ეფექტიურობით. ჩვენ ვაკეთებთ ამ ფორმალური მოდელის პირველი ინტენციაცია ტექსტის კლასიფიკაციის მიღებებისთვის. შესაბამისი ტექნოგიებით, ჩვენი მოდელი შეუძლია 0,9218 F1-score გადაწყვეტილების შესაბამისი გადაწყვეტილების შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბა', 'hu': 'Ez a tanulmány egy továbbfejlesztett egyéni modellt javasol a WNUT 2. feladathoz: Információs COVID-19 angol Tweet azonosítása. Javítjuk a legkorszerűbb RoBERTa nyelvmodell finomhangolási módszereinek hatékonyságát. A szövegosztályozási megközelítésekhez előzetesen rögzítjük ezt a formális modellt. A megfelelő edzési technikákkal modellünk képes 0,9218 F1 pontszámot elérni a nyilvános érvényesítési készleten, az együttes verzió pedig a legjobb 9 F1 pontszámot (0,9005) és a top 2 Recall (0,9301) a privát tesztkészleten.', 'el': 'Η παρούσα εργασία προτείνει ένα βελτιωμένο προσαρμοσμένο μοντέλο για την εργασία 2: Προσδιορισμός πληροφοριακού αγγλικού tweets. Βελτιώνουμε το πείραμα με την αποτελεσματικότητα των μεθοδολογιών συντονισμού για το σύγχρονο γλωσσικό μοντέλο. Κάνουμε μια προκαταρκτική αναπαράσταση αυτού του τυπικού μοντέλου για τις προσεγγίσεις ταξινόμησης κειμένου. Με τις κατάλληλες τεχνικές εκπαίδευσης, το μοντέλο μας είναι σε θέση να επιτύχει 0.9208 στο δημόσιο σύνολο επικύρωσης και η έκδοση του συνόλου τακτοποιείται στην κορυφή 9-βαθμολογία (0.9005) και στην κορυφή 2 Ανάκληση (0.9301) στο ιδιωτικό σετ δοκιμών.', 'it': "Questo articolo propone un modello personalizzato migliorato per l'attività 2 di WNUT: Identificazione del Tweet inglese informativo COVID-19. Miglioriamo l'esperienza con l'efficacia delle metodologie di messa a punto per il modello linguistico RoBERTa all'avanguardia. Facciamo un'istanza preliminare di questo modello formale per gli approcci di classificazione del testo. Con tecniche di allenamento appropriate, il nostro modello è in grado di ottenere 0,9218 F1-score sul set di validazione pubblico e la versione ensemble si assesta al top 9 F1-score (0,9005) e top 2 Recall (0,9301) sul set di test privato.", 'lt': 'Šiame dokumente siūlomas patobulintas WNUT 2 užduoties modelis: Informacinio COVID-19 anglų Tweet identifikavimas. Geriname eksperimentus naudojant patobulintų metodikų, taikomų naujausiam kalbų modeliui RoBERTa, veiksmingumą. Mes pradedame taikyti šį oficialų teksto klasifikavimo metodų model į. Taikant tinkamus mokymo metodus, mūsų model is gali pasiekti 0,9218 F1 balas viešojo patvirtinimo rinkinyje, o ensemblio versija nustatoma 9 F1 balais (0,9005) ir 2 svarbiausiu at šaukimu (0,9301) privačiame bandymų rinkinyje.', 'kk': 'Бұл қағаз WNUT 2- тапсырманың өзгертілген өзгертілген үлгісін ұсынады: Мәліметті COVID- 19 ағылшын tweet- тің идентификациясы. Біз RoBERTa тіл үлгісінің күй- жай тіл үлгісінің ең жақсы баптау методологияларына тәжірибені жақсартық. Біз мәтін классификациясының алдындағы үлгісінің алдындағы институциясын жасаймыз. Қосымша оқыту техникаларымен, біздің үлгіміз 0,9218 F1- нұсқасын көпшілік тексеру бағдарламасында жеткізе алады, және ендіру нұсқасы жеке тексеру бағдарламасында 9 F1- нұсқасында (0,9005) және 2- нұсқасының жоғары (0', 'mk': 'Овој документ предложува подобрен сопствен модел за WNUT задача 2: Идентификација на информативниот COVID-19 англиски твит. Ние го подобруваме експериментот со ефикасноста на методологиите за финетизирање на најновиот јазик модел Роберта. Правиме прелиминарна инстикација на овој формален модел за пристапите на класификацијата на текстот. Со соодветни техники на обука, нашиот модел е во можност да постигне 0,9218 F1-оценки на јавниот валидациски сет и верзијата на ансемблот се поставува на најдобрите 9 F1-оценки (0,9005) и најдобрите 2 Recall (0,9301) на приватниот тест сет.', 'ms': 'This paper proposes an improved custom model for WNUT task 2: Identification of Informative COVID-19 English Tweet.  Kami meningkatkan eksperimen dengan efektivitas metodologi penyesuaian untuk model bahasa terbaik RoBERTa. Kami membuat kejadian awal dari model formal ini untuk pendekatan klasifikasi teks. Dengan teknik latihan yang sesuai, model kami mampu mencapai 0.9218 skor F1 pada set pengesahihan awam dan versi ensemble ditetapkan pada 9 skor F1 atas (0.9005) dan 2 panggilan atas (0.9301) pada set ujian peribadi.', 'ml': 'ഈ പത്രത്തില്\u200d WNUT ജോലിക്കുള്ള മെച്ചപ്പെടുത്തിയ ഒരു സ്വന്തം മോഡല്\u200d പ്രായശ്ചിത്തമാക്കുന്നു: വിവരങ്ങള്\u200d കോവിഡി സ്റ്റേറ്റ് ഓഫ്-ആർട്ട് ഭാഷ മോഡല്\u200d റോബെര്\u200dട്ട. ടെക്സ്റ്റ് ക്ലാസ്ഫിക്കേഷന്\u200d നടക്കുന്നതിനുള്ള ഈ ഫോര്\u200dമാലിക മോഡലിന്\u200dറെ ആദ്യമായ ഒരു അവസ്ഥ നമുക്ക് ഉണ് ശരിയായ പരിശീലനത്തിനുള്ള ട്രെയിനിക്കുകള്\u200d കൊണ്ട് നമ്മുടെ മോഡല്\u200d 0. 9218 F1-സ്കോര്\u200d പ്രാവകാര്യ പരീക്ഷണസെറ്റില്\u200d എത്താന്\u200d സാധിക്കുന്നതാണ്. ഏന്\u200dസ്പെല്\u200d പതിപ്പ് 9 F1', 'mt': 'Dan id-dokument jipproponi mudell personalizzat imtejjeb għall-kompitu WNUT 2: Identifikazzjoni tal-Informattiv COVID-19 Tweet Ingliż. Aħna ntejbu l-esperimenti bl-effettività tal-metodoloġiji ta’ aġġustament finat għall-mudell lingwistiku l-aktar avvanzat RoBERTa. Aħna nagħmlu istanzjazzjoni preliminari ta’ dan il-mudell formali għall-approċċi tal-klassifikazzjoni tat-test. B’tekniki ta’ taħriġ xierqa, il-mudell tagħna huwa kapaċi jikseb 0.9218 punteġġ F1 fuq sett ta’ validazzjoni pubblika u l-verżjoni tal-ensemble issettja fl-ogħla 9 punteġġ F1 (0.9005) u l-ogħla 2 Riċenn (0.9301) fuq sett ta’ ttestjar privat.', 'mn': 'Энэ цаас WNUT ажлын хувьд сайжруулагдсан загвар 2: Мэдээллийн COVID-19 Англи Tweet-ын тодорхойлолт. Бид урлагийн хэл загварын үндсэн загварын эффективносттай туршилтыг сайжруулдаг. Бид энэхүү хэмжээний загварыг текст хэлбэрийн ойлголтын тулд анхны загвар хийдэг. Хэрэгтэй дасгал хөдөлгөөн техникуудын тулд бидний загвар нийтийн шинжлэх ухаан дээр 0.9218 F1 оноо гаргаж чадах боломжтой. Загварын хувилбар нь хувийн шалгалт дээр 9 F1 оноо (0.9005) болон 2 дундаж дундаж (0.9301) байдаг.', 'pl': 'Niniejszy artykuł proponuje ulepszony niestandardowy model zadania WNUT 2: Identyfikacja informacyjnego COVID-19 English Tweet. Poprawiamy eksperyment z efektywnością metodologii dostrajania najnowocześniejszego modelu językowego RoBERTa. Dokonujemy wstępnej instancji tego modelu formalnego dla podejść do klasyfikacji tekstów. Dzięki odpowiednim technikom treningowym nasz model jest w stanie osiągnąć 0.9208 F1-wynik na publicznym zestawie walidacyjnym, a wersja zespołowa rozlicza się na najwyższym 9-wyniku F1 (0.9005) i top 2 Recall (0.9301) na prywatnym zestawie testowym.', 'no': 'Denne papiret foreslår eit forbetra eigendefinert modell for WNUT- oppgåve 2: Identifikasjon av informativt COVID- 19 engelsk tweet. Vi forbedrar eksperiment med effektiviteten av finnstillingsmetodologiar for tilstanden av kunstspråk-modellen RoBERTa. Vi gjer eit første instansering av denne formelt modellen for tekstklassifikasjonen nærar. Med tilgjengelege treningsteknikk kan modellen vårt oppnå 0,9218 F1- poeng på offentlege validerasjonar, og ensemble- versjonen stiller opp 9 F1- poeng (0,9005) og toppen 2 rekoll (0,9301) på privat testsett.', 'sr': 'Ovaj papir predlaže poboljšan običajni model za WNUT zadatak 2: Identifikacija informativnog COVID-19 engleskog tweeta. Mi poboljšavamo eksperiment sa efikasnošću dobre metode za model stanja umjetnosti RoBERTa. Napravili smo preliminarnu instanciju ovog formalnog model a za pristupe klasifikacije teksta. Uz odgovarajuće tehnike obuke, naš model je u mogućnosti da postigne 0,9218 F1 rezultat na setu javnog validacije, a verzija ensembla se održava na najvišim 9 F1 rezultatima (0,9005) i najvišim 2 rezultatima (0,9301) na setu privatnih testova.', 'ro': 'Această lucrare propune un model personalizat îmbunătățit pentru sarcina WNUT 2: Identificarea Tweet-ului informativ COVID-19 în limba engleză. Îmbunătățim experimentul cu eficiența metodologiilor de reglare fină pentru modelul lingvistic RoBERTa de ultimă generație. Facem o instanțiere preliminară a acestui model formal pentru abordările de clasificare a textelor. Cu tehnici de antrenament adecvate, modelul nostru este capabil să obțină 0.9218 punctaj F1 pe setul public de validare, iar versiunea ansamblului se stabilește la top 9 punctaj F1 (0.9005) și top 2 Recall (0.9301) pe setul privat de testare.', 'si': 'මේ පැත්තේ WNOT වැඩ 2 වෙනුවෙන් වැඩිය සුදුසුම් ප්\u200dරමාණයක් ප්\u200dරයෝජනය කරනවා: තොරතුරු COVID- 19 ඉංග්\u200dරීසි ට් අපි පරීක්ෂණය වැඩි කරන්නේ රෝබෙර්ටා වලින් ස්ථානයේ ක්\u200dරියාත්මක භාෂාවක් නිර්මාණය සඳහා හොඳ සැකසුම් විද අපි මේ සාමාන්\u200dය මෝඩේල් එකේ ප්\u200dරධාන ස්ථානයක් කරනවා පාළුවන් විශේෂණය සම්බන්ධ වෙනුවෙන්. සඳහා ප්\u200dරශ්නය විද්\u200dයාපනය සමඟ, අපේ මොඩේල් 0.9218 F1-ස්කෝර් සිද්ධ විද්\u200dයාපනය සඳහා සාමාන්\u200dය විශ්ලේෂණය සඳහා පරීක්ෂණය සඳහා සිද්ධ විද්\u200dයාපනය සඳහා', 'so': 'Kanu wuxuu soo jeedaa model beddelan oo u bedeshay shaqada WNUT 2: Aqoonsiga Informative COVID-19 Ingiriis Tweet. Imtixaanka waxaa horumarinaya waxyaabaha ku saabsan qaababka hagitaanka ee qoraalka farshaxanka ah, RoBERta. Waxaan sameynaa tusaalahan rasmiga ah ee qoraalka fasaxa. Dhakhtarka waxbarashada ku haboon, modellkayagu wuxuu gaadhi karaa saxda aqoonsiga guud ee 0.9218 F1, kooxda kooxdana waxaa lagu qoraa kooxda ugu sareeya 9 F1 (0.9005) iyo kooxda ugu sareeya 2 (0.9301) oo lagu qorayo imtixaanka gaarka ah.', 'sv': 'Denna uppsats föreslår en förbättrad anpassad modell för WNUT uppgift 2: Identifiering av informativ COVID-19 English Tweet. Vi förbättrar experimentet med effektiviteten av finjusterande metoder för den senaste språkmodellen RoBERTa. Vi gör en preliminär instantiering av denna formella modell för textklassificering tillvägagångssätt. Med lämpliga träningstekniker kan vår modell uppnå 0,9218 F1-poäng på offentlig valideringsuppsättning och ensembleversionen sätter sig på topp 9 F1-poäng (0,9005) och topp 2 Recall (0,9301) på privat testset.', 'ta': 'இந்த தாள் WNUT செயல் 2 க்கான மேம்படுத்தப்பட்ட தனிப்பயன் மாதிரி பரிந்துரைக்கிறது: தகவல் அறிமுகம் COVID- 19 ஆங்கிலத்தின் Twee ரோபெர்டா நிலையில் கலை மொழி மாதிரி மாதிரியின் செயல்பாடுகளின் வெளிப்பாட்டை மேம்படுத்துகிறோம். நாம் இந்த வடிவமைப்பு மாதிரியின் முதலில் துவக்கத்தை உருவாக்குகிறோம். சரியான பயிற்சி தொழில்நுட்பத்துடன், எங்கள் மாதிரி பொது செலுத்துதல் அமைப்பில் 0. 9218 F1- புள்ளியை பெற முடியும் மற்றும் ஒதுக்குப் பதிப்பு 9 F1- புள்ளியில் (0. 9', 'ur': 'This paper proposes a improved custom model for WNUT task 2: Identification of Informative COVID-19 English Tweet. ہم نے آزمائش کو روBERTa کی حالت کی آرت کی زبان موڈل کے لئے بہترین تنظیم کے مطابقت کے ساتھ بہتر کر دیا۔ ہم اس فرمولی موڈل کی پہلی آنٹنسیٹ بناتے ہیں جو ٹیکسٹ کلاسیفوں کے قریب آتے ہیں۔ نیک ترینس ٹیکنیک کے ساتھ، ہماری موڈل 0.9218 F1-اسکور کو پورک والدیس سٹ پر پہنچا سکتی ہے اور اننسمبل ویرجن پریشان تست سٹ پر 9 F1-اسکور (0.9005) اور 2 بالا ریکال (0.9301) ہے.', 'uz': "Bu qogʻoz WNUT vazifa 2 uchun yaxshi foydalanuvchi modeli rivojlanadi: Informativ COVID-19 Inglizcha Twitterga bogʻlash. Biz tajribani o'zgartirib chiqish usullarning tayyorligini o'rganamiz. RoBERTA'ning davlat sohasi modeli. Biz bu formal modelni matn classification usullari uchun birinchi marta yaratishmiz. Mavjud taʼminlovchi texnologiya bilan modelmiz shaxsiy tizimni to ʻxtatish uchun 0. 9218 F1 scorini topishi mumkin va uning versiyasi 9 F1 scori (0. 9005) va maxsus 2 Recall (0. 9301) tugmasini boshqaradi.", 'vi': 'Tờ giấy này đề xuất một mô hình chỉnh sửa hiệu chỉnh cho việc tập ảnh WRT-2: xác định mã gốc COVID-19 English Tweet. Chúng tôi cải tiến thí nghiệm với hiệu quả của các phương pháp tinh chỉnh về ngôn ngữ kiểu ROBERTa. Chúng ta tổ chức ngay lập tức sơ bộ của mô hình thức này cho các phương pháp phân loại văn bản. Với các kỹ thuật huấn luyện thích hợp, mẫu của chúng ta có khả năng đạt được 0.921-điểm trên bộ thẩm tra công cộng và kết hợp được xếp tại top 9 F1-số điểm (0.905) và top 2 Recall (0.9301) trên bộ thử nghiệm riêng.', 'hr': 'Ovaj papir predlaže poboljšan obični model WNUT zadatka 2: Identifikacija informativnog COVID-19 engleskog tweeta. Mi poboljšavamo eksperiment s učinkovitostom metodologije ispravljanja stanja umjetničkog jezika RoBERTa. Preliminarna instancija ovog formalnog model a za pristupe klasifikacije teksta. Uz odgovarajuće tehnike obuke, naš model je u mogućnosti postići 0,9218 F1 rezultat o postavljanju javnog validacije, a verzija ensembla se nalazi na najvišem 9 F1 rezultat (0,9005) i najvišem 2 rezultat (0,9301) na setu privatnih testova.', 'bg': 'Настоящата статия предлага подобрен персонализиран модел за задача 2: Идентификация на информативния английски Туит. Подобряваме експеримента с ефективността на методологиите за фина настройка на съвременния езиков модел. Правим предварителна инстанция на този формален модел за подходите за класификация на текста. С подходящи тренировъчни техники нашият модел е в състояние да постигне 0.9218 оценка на публичен комплект за валидиране и версията на ансамбъла се установява в топ 9 на частен тест комплект.', 'da': 'Dette dokument foreslår en forbedret brugerdefineret model til WNUT opgave 2: Identifikation af informativ COVID-19 engelsk Tweet. Vi forbedrer eksperimenter med effektiviteten af finjusterende metoder til state-of-the-art sprogmodel RoBERTa. Vi foretager en foreløbig instantiation af denne formelle model for tekstklassifikationstilgangene. Med passende træningsteknikker er vores model i stand til at opnå 0,9218 F1-score på offentlige valideringssæt, og ensembleversionen sætter sig på top 9 F1-score (0,9005) og top 2 Recall (0,9301) på private testsæt.', 'nl': 'Dit document stelt een verbeterd aangepast model voor WNUT-taak 2: Identificatie of Informative COVID-19 English Tweet. We verbeteren het experiment met de effectiviteit van fine-tuning methodologieën voor state-of-the-art taalmodel RoBERTa. We maken een voorlopige instantiatie van dit formele model voor de tekstclassificatiebenaderingen. Met geschikte trainingstechnieken is ons model in staat om 0.9208 F1-score te behalen op publieke validatie set en de ensemble versie settelt zich op top 9 F1-score (0.9005) en top 2 Recall (0.9301) op privé test set.', 'id': 'Kertas ini mengusulkan model suai yang diperbaiki untuk tugas WNUT 2: Identifikasi dari Informatif COVID-19 Tweet Inggris. Kami meningkatkan eksperimen dengan efektivitas metodologi penyesuaian untuk model bahasa terbaik RoBERTa. Kami membuat instansi awal dari model formal ini untuk pendekatan klasifikasi teks. Dengan teknik latihan yang sesuai, model kami mampu mencapai 0,9218 F1-skor pada set validasi publik dan versi ensemble menetap di puncak 9 F1-skor (0,9005) dan 2 top Recall (0,9301) pada set tes pribadi.', 'de': 'Dieses Papier schlägt ein verbessertes benutzerdefiniertes Modell für WNUT-Aufgabe 2: Identifizierung informativer COVID-19 englischer Tweet vor. Wir verbessern das Experiment mit der Effektivität von Feinabstimmungsmethoden für das moderne Sprachmodell RoBERTa. Wir machen eine vorläufige Instanziierung dieses formalen Modells für die Textklassifikationsansätze. Mit geeigneten Trainingstechniken ist unser Modell in der Lage, 0.9208 F1-Score auf öffentlichen Validierungsset zu erzielen und die Ensembleversion rechnet sich mit Top 9 F1-Score (0.9005) und Top 2 Recall (0.9301) auf privaten Test-Set.', 'ko': '본고는 WNUT 임무 2에 대해 개선된 맞춤형 모델인 식별 정보가 풍부한 코로나 영어 트윗을 제시한다.우리는 최첨단 언어 모델인 RoBERTA에 대한 미세 조정 방법의 유효성 실험을 개선했다.우리는 텍스트 분류 방법의 이런 형식화 모델에 대해 초보적인 실례화를 진행하였다.적당한 훈련 기술을 통해 우리 모델은 공공 검증집에서 0.9218의 F1 점수를 얻을 수 있고 통합버전이 개인 테스트집에서 F1 점수(0.9005)와 리콜율(0.9301)은 각각 9위와 2위에 랭크되어 있다.', 'fa': 'این کاغذ پیشنهاد می\u200cدهد یک مدل شخصیت بهتر برای کار WNUT ۲: شناسایی کووید- ۱۹ تویت انگلیسی اطلاعات. ما آزمایش\u200cها را با موثرت metodologiی\u200cهای درست\u200cسازی برای مدل زبان\u200cهنری روBERTa بهتر می\u200cکنیم. ما یک حادثه اولیه از این مدل رسمی برای نزدیک\u200cهای مختصات متن می\u200cسازیم. با تکنیک آموزش مناسب، مدل ما می تواند امتیاز 0.9218 F1 را در مجموعه ثابت کردن عمومی به دست آورد، و نسخهٔ آموزش آموزش آموزش در امتحان خصوصی بالای 9 F1-score (0.9005) و بالای 2 Recall (0.9301) در مجموعه تست خصوصی قرار گیرد.', 'tr': "Bu kagyz WNUT täblisasi 2 üçin gelişmiş şahsy nusgasyny teklip edýär: Maglumaty COVID-19 Iňlis Tweet'iň bejerilmesi Biz RoBERTa dili durumynda ýeterlik taýýarlama methodologiýasynyň etkinliýeti bilen deneyleri geliştirdik. Biz bu resmi nusgasyny metin klasifikasyonuň ýakynlaşygy üçin öňünden başlangyç taýýarlaýarys. Dogrumy eğitim teknikleri bilen, biziň modelimiz 0.9218 F1 अंतर halkara barlamak üçin ýetip bilýär we bellenen wersiýa hususit testinde 9 F1 अंदर (0.9005) we 2 iň üstde 2 ýagdaý çykyp biler.", 'sw': 'Gazeti hili linapendekeza mtindo wa utamaduni ulioboreshwa kwa kazi ya WNUT 2: Kutambuliwa kwa Kitaarifa COVID-19 Twita ya Kiingereza. Tunaweza kuboresha majaribio kwa ufanisi wa mbinu za kujifunza vizuri kwa mtindo wa lugha ya sanaa RoBERTa. Tunafanya mwanzo wa mifano hii rasmi kwa njia za usambazaji wa maandishi. Kwa mbinu za mafunzo sahihi, mwelekeo wetu unaweza kufikia score 0.9218 F1 juu ya seti ya uhalali wa umma na toleo la upande wa juu ya vipindi 9 F1 (0.9005) na takribani 2 (0.9301) kwenye seti ya jaribio binafsi.', 'af': "Hierdie papier voorstel 'n verbeterde pasmaak model vir WNUT taak 2: Identifikasie van Informatiewe KoVID- 19 Engelske Tweet. Ons verbeter eksperiment met die effektiviteit van fine-tuning metodologies vir state-of-the-art taal model RoBERTa. Ons maak 'n voorafinstelling van hierdie formele model vir die teks klasifikasie toegang. Met geskikte onderwerp tekens, is ons model in staat om 0.9218 F1- telling te bereik op publieke geldigheidstel en die ensemble weergawe op top 9 F1- score (0.9005) en bo 2 Rekal (0.9301) op private toets stel te stel.", 'sq': 'This paper proposes an improved custom model for WNUT task 2: Identification of Informative COVID-19 English Tweet.  Ne përmirësojmë eksperimentet me efektshmërinë e metodologjive të përshtatjes për modelin e gjuhës më të lartë RoBERTa. Ne bëjmë një pikëpamje paraprake të këtij modeli zyrtar për qasjet e klasifikimit të tekstit. Me teknikat e duhura të trajnimit, modeli ynë është në gjendje të arrijë 0.9218 rezultate F1 në sistemin publik të vlerësimit dhe versioni i ansamblit vendoset në pozitën më të lartë 9 rezultate F1 (0.9005) dhe 2 rekall më të lartë (0.9301) në sistemin privat të testit.', 'am': 'This paper proposes an improved custom model for WNUT task 2: Identification of Informative COVID-19 English Tweet.  በሀገሪቱ የቋንቋ ምሳሌ ሮብERTA በሚያሳድገው ጥቅም ማድረግ እናሳድጋለን፡፡ ለጽሑፍ መግለጫ የሚደረገውን የፊደል ምሳሌ እናደርጋለን፡፡ በሚያስፈልገው ማስተምር ዘዴ፣ ሞዴላያችን 0.9218 F1-score በመስጠት ይችላል፣ የስብስቡል ክፍተት 9 F1-score (0.9005) በላይ 9.9005 (0.9301) እና በላይ 2 ርካት (0.9301) የግል ፈተና ማረጋገጥ ይችላል፡፡', 'hy': "Այս հոդվածը առաջարկում է բարելավված համակարգչային համակարգչային տեխնոլոգիաների 2 խնդրի հատուկ մոդել' ինֆորմատիվ COVID-19 անգլերեն թվիթի հայտնաբերումը: Մենք բարելավում ենք փորձարկումները լավագույն տեխնոլոգիաների արդյունավետության մեթոդոլոգիաների օգնությամբ Մենք ստեղծում ենք այս պաշտոնական մոդելը տեքստի դասակարգման մոտեցումների համար: With appropriate training techniques, our model is able to achieve 0.9218 F1-score on public validation set and the ensemble version settles at top 9 F1-score (0.9005) and top 2 Recall (0.9301) on private test set.", 'az': 'Bu kağıt WNUT işi 2 üçün yaxşılaşdırılmış xüsusi modeli təklif edir: Informativ COVID-19 İngilizə Tweet təşkil edir. Biz RoBERTa dil modeli üçün gözəl düzəltmə metodolojilərinin etkinliğini yaxşılaşdırırıq. Biz bu formal modelini mətn klasifikasyonu yaxınlaşdırmaq üçün ilk dəfə yaratdıq. Münasib təhsil metodları ilə, modellərimiz 0,9218 F1 nöqtəsini halkı təsdiqləmə qurğusunda başa çata bilər və ensemble verziji özgür sınama qurğusunda 9 F1 nöqtəsində (0,9005) və 2 üst nöqtəsində (0,9301) çəkə bilər.', 'bn': 'এই প্রবন্ধে WNUT কাজ ২ এর জন্য উন্নত একটি স্বনির্বাচিত মডেল প্রস্তাব করেছে: তথ্য প্রমাণিত কভিড-১৯ ইংরেজী টুইটের পরিচয় প্ রাষ্ট্র-অফ-শিল্পের ভাষার মডেল রোবের্তার কার্যকলাপের কার্যক্রমে আমরা পরীক্ষার পরীক্ষার সাথে উন্নত করি। টেক্সট গ্রাফিকেশনের ক্ষেত্রে এই ফার্মিল মডেলের প্রাথমিক উদ্যোগ তৈরি করি। যথাযথ প্রশিক্ষণ কৌশলের মাধ্যমে আমাদের মডেল পাবলিক বৈধ সেটে ০. 9218 এফ১ স্কোর অর্জন করতে পারে এবং সংস্করণের সংস্করণ ৯ এফ১ স্কোর (0. 9005) এবং ব্যক্তিগত পরীক্ষার সেটে ২ র', 'bs': 'Ovaj papir predlaže poboljšan obični model WNUT zadatka 2: Identifikacija informativnog COVID-19 engleskog tweeta. Mi poboljšavamo eksperiment s učinkovitostom metodologije fino prilagođavanja stanja umjetnog jezika modela RoBERTa. Preliminarna instancija ovog formalnog model a za pristupe klasifikacije teksta. Uz odgovarajuće tehnike obuke, naš model je u mogućnosti postići 0,9218 F1 rezultat o setu javnog validacije i verzija ensembla se održava na najvišem 9 F1 rezultat (0,9005) i najvišem 2 rezultat (0,9301) na setu privatnih testova.', 'ca': "Aquest paper proposa un model personalitzat millorat per a la tasca 2 de la WNUT: Identificació del Tweet informatiu COVID-19 anglès. millorem l'experiment amb l'eficacia de les metodologies d'ajustament del model de llenguatge més avançat RoBERTa. Fem una instanciació preliminar d'aquest model formal per als enfocaments de classificació de text. Amb tècniques d'entrenament apropiades, el nostre model és capaç d'aconseguir 0,9218 puntuacions F1 en el conjunt de validació pública i la versió de l'ensemble s'ajusta als 9 puntuacions F1 (0,9005) i 2 puntuacions Recall (0,9301) en el conjunt de proves privats.", 'et': 'Käesolevas dokumendis pakutakse välja täiustatud kohandatud mudel WNUT ülesande 2: informatiivse COVID-19 tuvastamine inglise Tweet jaoks. Parandame eksperimenti peenhäälestusmeetodite efektiivsusega kaasaegse keelemudeli RoBERTa jaoks. Teeme esialgse instantiatsiooni sellest formaalsest mudelist teksti klassifitseerimise lähenemisviiside jaoks. Sobivate treeningmeetodite abil on meie mudel võimeline saavutama 0,9218 F1-skoori avalikus valideerimiskomplektis ja ansambli versioon jääb üheksa F1-skoori (0,9005) ja 2 top Recall (0,9301) erakatsekomplektis.', 'cs': 'Tento článek navrhuje vylepšený vlastní model pro úlohu WNUT 2: Identifikace informačního COVID-19 anglického tweetu. Zlepšujeme experiment s efektivitou jemného ladění metodik pro nejmodernější jazykový model RoBERTa. Provedeme předběžnou instancii tohoto formálního modelu pro přístupy klasifikace textů. S vhodnými tréninkovými technikami je náš model schopen dosáhnout 0.9208 F1 skóre na veřejné validační sadě a souborová verze se usazuje na nejvyšší 9 F1 skóre (0.9005) a top 2 Recall (0.9301) na soukromé testovací sadě.', 'fi': 'Tässä artikkelissa ehdotetaan parannettua mukautettua mallia WNUT-tehtävään 2: Informatiivisen COVID-19 englanninkielisen twiitin tunnistaminen. Parannamme kokeiluja hienosäätömenetelmien tehokkuudesta uusimman kielimallin RoBERTa osalta. Teemme alustavan instantiaation tästä muodollisesta mallista tekstin luokittelun lähestymistapoja varten. Asianmukaisten harjoitustekniikoiden avulla mallimme pystyy saavuttamaan 0,9218 F1-pisteen julkisessa validointisarjassa ja ensemble-versio sijoittuu 9 parhaan F1-pisteen (0,9005) ja 2 parhaan Recall-pisteen (0,9301) yksityisessä testisarjassa.', 'he': 'העבודה הזו מציעה מודל מתאים משפר עבור משימה WNUT 2: זיהוי של טוויט אינפורמטיבי COVID-19 אנגלי. אנחנו משתפרים את הניסוי עם היעילות של מתאים מתאימים למודל השפה המוקדם ביותר RoBERTa. We make a preliminary instantiation of this formal model for the text classification approaches.  עם טכניקות אימונים מתאימות, הדוגמא שלנו מסוגלת להשיג 0.9218 F1-נקודה על קבוצת אימון ציבורי וגרסה האנסמבל מתיישבת ב-9 F1-נקודה (0.9005) ו-2 Recall (0.9301) על קבוצת מבחן פרטית.', 'sk': 'Ta članek predlaga izboljšan model po meri za nalogo WNUT 2: identifikacija informativnega COVID-19 angleškega Tweet. Izboljšujemo eksperimente z učinkovitostjo metodologij finega uravnavanja za najsodobnejši jezikovni model RoBERTa. Izdelamo predhodno instanciacijo tega formalnega modela za pristope klasifikacije besedil. Z ustreznimi tehnikami usposabljanja lahko naš model doseže 0,9218 F1-rezultat na javnem kompletu validacije, različica ansambla pa se poravna na najboljših 9 F1-rezultatih (0,9005) in najboljših 2 Recall (0,9301) na zasebnem testnem kompletu.', 'ha': "Wannan takardar da ke ƙayyade wani mai kyau wa tsarin ɗabi'a wa aikin WNUT 2: Shaidar na Agammative COV-19 Ingiriya. Munã ƙara jarrabi da aikin hanyoyi na tsari ga-state-of-the-art-language RoBERTa. Mu sami fara da wannan misali mai rasawa na matsayi. Yana da kunnufi masu amfani da kwamfyuta, misalinmu yana iya iya kai ga score 0.9218 F1 kan daidaita inganci ga umma kuma version na samu ya zauna a saman 9 F1-score (0.9405) da duk 2 Recent (0.9300 1) kan jarraba farat ɗaya.", 'jv': 'Pesene iki supoyata model sing paling nggawe kanggo WNUT nggawe 2: ID of Informaative COMPLID-19 Awak dhéwé nglanggar ujaran karo akeh efek kanggo ngabah sistem sing luwih-luwih kanggo stad-of-the-arts model RBERT a. Awak dhéwé ngerasakno asai perusahaan kanggo model formil iki nggo ngerasakno teks. Ngkang diolah teknik sing beraksi, model sing iso dianggap 0.9', 'bo': 'ཤོག་བྱང་འདིས་WNUT ལས་ཀ་ལ་རང་བཟོས་བའི་རྣམ་པ་ཞིག་གི་སྔོན་སྒྲིག་བྱེད་ཀྱི་ཡོད། ང་ཚོས་རྣམས་ཀྱི་གནས་སྟངས་དང་འཛམ་གླིང་སྒྲུབ་ཀྱི་ཐབས་ལམ་ལུགས་ནུས་པ་ཡིན་པའི་སྐོར་བརྟན་པར། ང་ཚོས་ཡིག་གི་དབྱིབས་དཔྱད་ཆོས་འཛིན་ཐབས་ལམ་ལ་རྣམས་ལས་རྣམ་གྲངས་སྔོན་འགོར་བ་ཞིག་བྱེད་ཀྱི་ཡོད། With appropriate training techniques, our model is able to achieve 0.9218 F1-score on public validation set and the ensemble version settles at top 9 F1-score (0.9005) and top 2 Recall (0.9301) on private test set.'}
{'en': 'COVCOR20 at WNUT-2020 Task 2 : An Attempt to Combine  Deep Learning  and Expert rules COVCOR 20 at  WNUT -2020 Task 2: An Attempt to Combine Deep Learning and Expert rules', 'ar': 'COVCOR20 في WNUT-2020 المهمة 2: محاولة للجمع بين التعلم العميق وقواعد الخبراء', 'es': 'COVCOR20 en la Tarea 2 del WNUT-2020: Un intento de combinar el aprendizaje profundo y las reglas de los expertos', 'pt': 'COVCOR20 no WNUT-2020 Tarefa 2: Uma tentativa de combinar regras de Deep Learning e Expert', 'fr': 'COVCOR20 à la tâche 2 de la WNUT-2020\xa0: Tenter de combiner le Deep Learning et les règles des experts', 'hi': 'WNUT-2020 कार्य 2 पर COVCOR20: डीप लर्निंग और विशेषज्ञ नियमों को संयोजित करने का प्रयास', 'ja': 'COVCOR 2020 at WNUT -2020タスク2 ：ディープラーニングとエキスパートルールを組み合わせる試み', 'ru': 'COVCOR20 на WNUT-2020 Задача 2: Попытка объединить глубокое обучение и экспертные правила', 'zh': 'COVCOR20在WNUT-2020务2:尝试以深学合专门之法', 'ga': 'COVCOR20 ag WNUT-2020 Tasc 2: Iarracht ar Dhomhainfhoghlaim agus ar shainrialacha a Chomhcheangal', 'ka': 'COVCOR20 WNUT-2020 სამუშაო დავალება 2: ძალიან ძალიან სწავლების და ექსპერტის წესების გამოყენება', 'el': 'Εργασία 2: Μια προσπάθεια συνδυασμού της βαθιάς μάθησης και των κανόνων εμπειρογνωμόνων', 'hu': 'COVCOR20 a WNUT-2020 második feladatán: a mélytanulás és a szakértői szabályok kombinálására irányuló kísérlet', 'it': 'COVCOR20 al task 2 di WNUT-2020: un tentativo di combinare le regole di deep learning e gli esperti', 'kk': 'COVCOR20 WNUT-2020 тапсырмасының 2- тапсырмасында: Тегіс оқыту мен эксперт ережелерін біріктіру әрекеті', 'lt': 'COVCOR20 at WNUT-2020 Task 2: An Attempt to Combine Deep Learning and Expert rules', 'mk': 'COVCOR20 at WNUT-2020 Task 2: An Attempt to Combine Deep Learning and Expert rules', 'ms': 'COVCOR20 di WNUT-2020 Tugas 2: Cubaan untuk Kombinkan Peraturan Belajar Dalam Dalam', 'mn': 'COVCOR20 WNUT-2020 Task 2: Deep Learning and Expert Rules', 'ml': 'WNUT- 2020 ടാസ്ക് 2- ല്\u200d COVCOR20: ആഴത്തെ പഠിക്കുന്നതും വിശേഷിപ്പിക്കുന്ന നിയമങ്ങള്\u200dക്കും ഒരു ശ്രമം', 'mt': 'COVCOR20 fid-WNUT-2020 Task 2: Attempat biex jiġu kkombinati r-regoli ta’ Tagħlim Profond u Esperti', 'no': 'COVCOR20 på WNUT-2020 oppgåve 2: Ein prøv å kombinere dypt læring og ekspertreglar', 'pl': 'COVCOR20 na WNUT-2020 Zadanie 2: Próba połączenia reguł głębokiego uczenia i ekspertów', 'sr': 'COVCOR20 na zadatku 2. WNUT-2020: pokušaj kombiniranja pravila dubokog učenja i eksperta', 'ro': 'COVCOR20 la sarcina 2 a WNUT-2020: O încercare de a combina regulile de învățare profundă și de experți', 'si': 'COVCOR20 at WNuT-2020Job 2: A Attempt to Combine Deep Training and Research Rules', 'so': 'COVCOR20 at WNUT-2020 Task 2: An attempt to Combine Deep Learning and Expert rules', 'sv': 'COVCOR20 vid WNUT-2020 Uppgift 2: Ett försök att kombinera djupgående lärande och expertregler', 'ta': 'WNUT- 2020 பணி 2- ல் COVCOR20: ஆழமான கற்றுக் கொண்டு மற்றும் விதிகளை கூட்ட முயற்சி', 'ur': 'COVCOR20 WNUT-2020 Task 2: ایک عمیق سیکھنے اور انتظار قوانین کو جمع کرنے کی کوشش ہے', 'uz': 'Comment', 'vi': 'Một sự cố gắng kết hợp luật về học tập sâu và chuyên gia', 'bg': 'Задача 2: Опит за комбиниране на правилата за задълбочено обучение и експертни правила', 'hr': 'COVCOR20 na zadatku 2. WNUT-2020: pokušaj kombiniranja pravila dubokog učenja i stručnjaka', 'da': 'COVCOR20 på WNUT-2020 Opgave 2: Et forsøg på at kombinere regler for dyb læring og eksperter', 'nl': 'COVCOR20 op WNUT-2020 Taak 2: Een poging om Deep Learning en Expert regels te combineren', 'de': 'COVCOR20 bei WNUT-2020 Aufgabe 2: Ein Versuch Deep Learning und Expert Rules zu kombinieren', 'ko': 'WNUT-2020 퀘스트 2: 깊이 있는 학습과 전문가의 규칙을 결합한 시도', 'fa': 'COVCOR20 در کار دوم WNUT-2020: یک تلاش برای ترکیب قوانین یادگیری عمیق و مطالعه', 'id': 'COVCOR20 di WNUT-2020 Tugas 2: Sebuah Usaha untuk Kombinasi Peraturan Belajar Dalam Dalam', 'sw': 'COVCOR20 kwenye kazi ya WNUT-2020 2: Jaribio la Kuunganisha Sheria za Kufundisha na Kutambua', 'tr': 'COVCOR20 at WNUT-2020 Task 2: An attempt to combine deep learning and Expert rules', 'af': 'COVCOR20 by WNUT-2020 Opdrag 2: 芒聙聶n Versoek om diep leer en ekspertre毛ls te kombinerer', 'sq': 'COVCOR20 në WNUT-2020 Task 2: Një përpjekje për të kombinuar rregullat e mësimit të thellë dhe ekspertëve', 'am': 'ስራ 2:', 'hy': 'COVCOR20-ը Համաշխարհային Ազգային Ազգային Հետազոտություն 2020-ի 2. խնդիր. փորձել համախմբել խորը սովորելու և մասնագետների կանոնները', 'az': 'COVCOR20 WNUT-2020 Task 2: Deep Learning and Expert Rules Combine', 'bn': 'WNUT-2020 কাজ ২-এ কভিকোর্২০: গভীর শিক্ষা এবং বিশেষজ্ঞ নিয়ম কম্বিনের প্রচেষ্টা', 'bs': 'COVCOR20 na zadatku 2. WNUT-2020: pokušaj kombiniranja pravila dubokog učenja i stručnjaka', 'cs': 'COVCOR20 na WNUT-2020 Úkol 2: Pokus o kombinaci hlubokého učení a expertních pravidel', 'fi': 'COVCOR20 WNUT-2020:n tehtävässä 2: yritys yhdistää syväoppimisen ja asiantuntijoiden säännöt', 'et': 'COVCOR20 WNUT-2020 ülesandel 2: katse ühendada sügavõpe ja eksperdireeglid', 'ca': "COVCOR20 al WNUT-2020 Task 2: Un intent de combinar normes d'aprenentatge profund i d'experts", 'jv': 'COMVCOMR8 at WNUT-2020 task 2: an Attempt to combbine deep Learning and Awart rule', 'ha': 'KCharselect unicode block name', 'sk': 'COVCOR20 na nalogi 2 WNUT-2020: poskus združevanja pravil poglobljenega učenja in strokovnjakov', 'he': 'COVCOR20 ב-WNUT-2020 משימה 2: ניסיון לשלב חוקים למידה עמוקה ומומחים', 'bo': 'COVCOR20 at WNUT-2020 Task 2: An attempt to Combine Deep Learning and Expert rules'}
{'en': 'In the scope of WNUT-2020 Task 2, we developed various text classification systems, using  deep learning models  and one using linguistically informed rules. While both of the deep learning systems outperformed the system using the linguistically informed rules, we found that through the integration of (the output of) the three systems a better performance could be achieved than the standalone performance of each approach in a cross-validation setting. However, on the test data the performance of the  integration  was slightly lower than our best performing deep learning model. These results hardly indicate any progress in line of integrating  machine learning  and expert rules driven systems. We expect that the release of the annotation manuals and gold labels of the test data after this workshop will shed light on these perplexing results.', 'ar': 'في نطاق WNUT-2020 المهمة 2 ، قمنا بتطوير أنظمة مختلفة لتصنيف النصوص ، باستخدام نماذج التعلم العميق ونماذج تستخدم قواعد مستنيرة لغويًا. بينما تفوق كلا نظامي التعلم العميق على النظام باستخدام القواعد المستنيرة لغويًا ، وجدنا أنه من خلال تكامل (مخرجات) الأنظمة الثلاثة ، يمكن تحقيق أداء أفضل من الأداء المستقل لكل نهج في إعداد التحقق المتبادل . ومع ذلك ، في بيانات الاختبار ، كان أداء التكامل أقل قليلاً من نموذج التعلم العميق الأفضل أداءً لدينا. بالكاد تشير هذه النتائج إلى أي تقدم في خط دمج التعلم الآلي والأنظمة المعتمدة على قواعد الخبراء. نتوقع أن يؤدي إصدار كتيبات التعليقات التوضيحية والملصقات الذهبية لبيانات الاختبار بعد ورشة العمل هذه إلى إلقاء الضوء على هذه النتائج المحيرة.', 'es': 'En el ámbito de la Tarea 2 del WNUT-2020, desarrollamos varios sistemas de clasificación de textos, utilizando modelos de aprendizaje profundo y uno que utiliza reglas lingüísticamente informadas. Si bien ambos sistemas de aprendizaje profundo superaron al sistema utilizando las reglas informadas lingüísticamente, descubrimos que mediante la integración de (el resultado de) los tres sistemas se podía lograr un mejor rendimiento que el rendimiento independiente de cada enfoque en un entorno de validación cruzada. Sin embargo, en los datos de prueba, el rendimiento de la integración fue ligeramente inferior al de nuestro modelo de aprendizaje profundo con mejor rendimiento. Estos resultados apenas indican ningún progreso en la integración del aprendizaje automático y los sistemas basados en reglas expertas. Esperamos que la publicación de los manuales de anotación y las etiquetas de oro de los datos de prueba después de este taller arroje luz sobre estos resultados desconcertantes.', 'fr': "Dans le cadre de la tâche 2 du WNUT-2020, nous avons développé divers systèmes de classification de texte, utilisant des modèles d'apprentissage profond et un autre utilisant des règles informées linguistiquement. Alors que les deux systèmes d'apprentissage profond ont surpassé le système en utilisant des règles informées sur le plan linguistique, nous avons constaté que l'intégration de (la sortie de) les trois systèmes permettait d'obtenir de meilleures performances que les performances autonomes de chaque approche dans un contexte de validation croisée. Cependant, sur les données de test, les performances de l'intégration étaient légèrement inférieures à celles de notre modèle de deep learning le plus performant. Ces résultats n'indiquent pratiquement aucun progrès en matière d'intégration de l'apprentissage automatique et des systèmes pilotés par des règles expertes. Nous prévoyons que la publication des manuels d'annotation et des étiquettes dorées des données de test après cet atelier éclairera ces résultats perplexes.", 'pt': 'No escopo da Tarefa 2 do WNUT-2020, desenvolvemos vários sistemas de classificação de texto, usando modelos de aprendizado profundo e um usando regras informadas linguisticamente. Embora ambos os sistemas de aprendizado profundo tenham superado o sistema usando as regras informadas linguisticamente, descobrimos que, por meio da integração dos três sistemas, um desempenho melhor pode ser alcançado do que o desempenho independente de cada abordagem em uma configuração de validação cruzada . No entanto, nos dados de teste, o desempenho da integração foi ligeiramente inferior ao nosso modelo de aprendizado profundo com melhor desempenho. Esses resultados dificilmente indicam qualquer progresso na linha de integração de aprendizado de máquina e sistemas orientados por regras especializadas. Esperamos que o lançamento dos manuais de anotação e etiquetas douradas dos dados de teste após este workshop esclareça esses resultados desconcertantes.', 'zh': 'WNUT-2020务2之限,开群本之统,深学模形,言语知情之统。 虽此二者,皆优于用言知情之法,然吾见集成(输)三统,可以得比交叉验置中每法独善。 然于测试数据上集成之性略低于吾性能最佳者深习模样。 几乎未明机器学与家则驱统而有所进也。 计本研讨会之后,测试数据注手册、金标签发将发令人困惑也。', 'ja': 'WNUT -2020タスク2の範囲では、ディープラーニングモデルと言語情報ルールを使用したさまざまなテキスト分類システムを開発しました。両方のディープラーニングシステムは、言語情報ルールを使用してシステムを上回っていたが、3つのシステムの統合（出力）を通じて、クロスバリデーション設定での各アプローチの単独のパフォーマンスよりも優れたパフォーマンスを達成できることがわかった。しかし、テストデータでは、統合のパフォーマンスは、最高のパフォーマンスを発揮するディープラーニングモデルよりもわずかに低かった。これらの結果は、機械学習とエキスパートルール駆動システムの統合における進歩を示すものではほとんどありません。このワークショップの後に試験データの注釈マニュアルとゴールドラベルがリリースされることで、これらの難解な結果が明らかになることを期待しています。', 'hi': 'WNUT-2020 टास्क 2 के दायरे में, हमने विभिन्न पाठ वर्गीकरण प्रणालियों को विकसित किया, गहरे सीखने के मॉडल का उपयोग करके और भाषाई रूप से सूचित नियमों का उपयोग करके एक। जबकि दोनों गहरी सीखने की प्रणालियों ने भाषाई रूप से सूचित नियमों का उपयोग करके सिस्टम को पछाड़ दिया, हमने पाया कि तीन प्रणालियों के एकीकरण (आउटपुट) के माध्यम से एक क्रॉस-सत्यापन सेटिंग में प्रत्येक दृष्टिकोण के स्टैंडअलोन प्रदर्शन की तुलना में एक बेहतर प्रदर्शन प्राप्त किया जा सकता है। हालांकि, परीक्षण डेटा पर एकीकरण का प्रदर्शन हमारे सबसे अच्छे प्रदर्शन वाले गहरे सीखने के मॉडल की तुलना में थोड़ा कम था। ये परिणाम शायद ही मशीन लर्निंग और विशेषज्ञ नियमों द्वारा संचालित प्रणालियों को एकीकृत करने की रेखा में किसी भी प्रगति का संकेत देते हैं। हम उम्मीद करते हैं कि इस कार्यशाला के बाद एनोटेशन मैनुअल और परीक्षण डेटा के सोने के लेबल की रिहाई इन परेशान परिणामों पर प्रकाश डालेगी।', 'ru': 'В рамках задачи 2 WNUT-2020 мы разработали различные системы классификации текста, используя модели глубокого обучения и одну с использованием лингвистически обоснованных правил. Хотя обе системы глубокого обучения превосходили систему, используя лингвистически обоснованные правила, мы обнаружили, что за счет интеграции (выхода) трех систем может быть достигнута лучшая производительность, чем отдельная производительность каждого подхода в условиях перекрестной проверки. Однако на тестовых данных производительность интеграции была немного ниже, чем наша наилучшая модель глубокого обучения. Эти результаты едва ли свидетельствуют о каком-либо прогрессе в области интеграции систем машинного обучения и экспертных правил. Мы ожидаем, что выпуск руководств по аннотированию и золотых этикеток данных испытаний после этого семинара прольет свет на эти недоумение результатов.', 'ga': 'I raon feidhme Thasc 2 WNUT-2020, d’fhorbraíomar córais éagsúla aicmithe téacs, ag baint úsáide as samhlacha domhainfhoghlama agus ceann ag baint úsáide as rialacha teangabhunaithe. Cé gur sháraigh an dá chóras domhainfhoghlama an córas ag baint úsáide as na rialacha a bhí feasach ó thaobh na teanga de, fuaireamar amach go bhféadfaí feidhmíocht níos fearr a bhaint amach trí chomhtháthú (aschur) na dtrí chóras ná feidhmíocht neamhspleách gach cur chuige i socrú tras-bhailíochtaithe. . Ar na sonraí tástála, áfach, bhí feidhmíocht an chomhtháthaithe beagán níos ísle ná an múnla foghlama domhain is fearr atá ag feidhmiú againn. Is ar éigean a thugann na torthaí seo le fios go bhfuil aon dul chun cinn á dhéanamh maidir le córais meaisín-fhoghlama agus sainrialacha a chomhtháthú. Táimid ag súil go dtabharfaidh eisiúint lámhleabhair anótála agus lipéid óir na sonraí tástála tar éis na ceardlainne seo solas ar na torthaí uafásacha seo.', 'ka': 'WNUT-2020 დავალების 2-ის განმავლობაში, ჩვენ განვითარებეთ განსხვავებული ტექსტის კლასიფიკაციის სისტემის გამოყენება, ძალიან სწავლებელი მოდელების გამოყენება და ერთი, რომელიც ენ თუმცა ორივე ძალიან სწავლის სისტემის სისტემის გამოყენება სისტემის ინფორმაციურად ინფორმაციული წესების გამოყენება, ჩვენ მივიღეთ, რომ სამი სისტემის ინტერგურაციის გამოყენებით უფრო მკეთესი გამოყენება შე მაგრამ ტესტის მონაცემებზე ინტერგურაციის შესაძლებლობა ცოტა ნაკლები იყო, ვიდრე ჩვენი უკეთესი სწავლების მოდელი. ეს წარმოდგენები უბრალოდ არაფერი პროგრესი მანქანის სწავლების და ექსპერტის კონფიგურაციის სისტემის ინტერგურაციაში. ჩვენ უნდა გავაკეთებთ, რომ მოწყობილობა მოწყობილობის პრობლემენტების და მოწყობილობის ცვლილების მონაცემების შემდეგ ამ სამუშაო მოწყობილობის შემდეგ გადა', 'hu': 'A WNUT-2020 2. feladat keretében különböző szövegosztályozási rendszereket fejlesztettünk ki, amelyek mélytanulási modelleket alkalmaznak, és egyet nyelvileg tájékozott szabályokat alkalmaznak. Bár mindkét mélytanulási rendszer a nyelvi szempontból tájékozott szabályok alkalmazásával felülmúlta a rendszert, megállapítottuk, hogy a három rendszer integrációjával jobb teljesítmény érhető el, mint az egyes megközelítések önálló teljesítménye keresztvalidálási környezetben. A tesztadatok alapján azonban az integráció teljesítménye kissé alacsonyabb volt, mint a legjobb mélytanulási modellünk. Ezek az eredmények aligha jeleznek semmilyen előrelépést a gépi tanulás és a szakértői szabályok vezérelt rendszerek integrálása terén. Arra számítunk, hogy a műhely után megjelenő jegyzetelési kézikönyvek és a tesztadatok arany címkéinek megjelenése világossá teszi ezeket a zavaró eredményeket.', 'el': 'Στο πλαίσιο της εργασίας 2, αναπτύξαμε διάφορα συστήματα ταξινόμησης κειμένου, χρησιμοποιώντας μοντέλα βαθιάς μάθησης και ένα με γλωσσικά ενημερωμένους κανόνες. Ενώ και τα δύο συστήματα βαθιάς μάθησης ξεπερνούν το σύστημα χρησιμοποιώντας τους γλωσσικά ενημερωμένους κανόνες, διαπιστώσαμε ότι μέσω της ενσωμάτωσης (της παραγωγής) των τριών συστημάτων θα μπορούσε να επιτευχθεί καλύτερη απόδοση από την αυτόνομη απόδοση κάθε προσέγγισης σε ένα πλαίσιο διασταυρούμενης επικύρωσης. Ωστόσο, στα δεδομένα των δοκιμών η απόδοση της ολοκλήρωσης ήταν ελαφρώς χαμηλότερη από το μοντέλο βαθιάς μάθησης με την καλύτερη απόδοση. Τα αποτελέσματα αυτά δεν δείχνουν καμία πρόοδο όσον αφορά την ενσωμάτωση συστημάτων μηχανικής μάθησης και ειδικών κανόνων. Αναμένουμε ότι η έκδοση των εγχειριδίων σχολιασμού και των χρυσών ετικετών των δεδομένων δοκιμής μετά από αυτό το εργαστήριο θα ρίξει φως σε αυτά τα μπερδεμένα αποτελέσματα.', 'it': "Nell'ambito di WNUT-2020 Task 2, abbiamo sviluppato diversi sistemi di classificazione del testo, utilizzando modelli di deep learning e uno utilizzando regole informate linguisticamente. Mentre entrambi i sistemi di deep learning hanno superato il sistema utilizzando regole informate linguisticamente, abbiamo scoperto che attraverso l'integrazione dei tre sistemi si potrebbe ottenere prestazioni migliori rispetto alle prestazioni autonome di ciascun approccio in un ambiente di cross-validation. Tuttavia, sui dati di test le prestazioni dell'integrazione sono state leggermente inferiori rispetto al nostro modello di deep learning più performante. Questi risultati non indicano alcun progresso in linea con l'integrazione di sistemi basati sull'apprendimento automatico e sulle regole degli esperti. Ci aspettiamo che la pubblicazione dei manuali di annotazione e delle etichette dorate dei dati di prova dopo questo workshop farà luce su questi risultati perplessi.", 'lt': 'WNUT-2020 2 užduoties taikymo srityje sukūrėme įvairias tekstų klasifikavimo sistemas, naudojant gilaus mokymosi modelius ir vieną naudojant kalbomis pagrįstas taisykles. Nors abi giliavandenio mokymosi sistemos viršijo sistemą taikant kalbomis pagrįstas taisykles, nustatėme, kad integruojant (išėjus) tris sistemas būtų galima pasiekti geresnius rezultatus nei kiekvieno metodo savarankiškumas kryžminio patvirtinimo sąlygomis. Tačiau pagal bandymų duomenis integracijos veiksmingumas buvo šiek tiek mažesnis nei mūsų geriausiai veikiantis gilaus mokymosi modelis. Šie rezultatai vargu ar rodo pažangą integruojant mašin ų mokymosi ir ekspertų taisykles. Tikimės, kad po šio seminaro paskelbus bandymų duomenų anotacijų vadovus ir auksinius ženklus bus šviesos šiems sukrėtusiems rezultatams.', 'kk': 'WNUT-2020 тапсырмасының 2- мақсатында, біз түрлі мәтін классификациялау жүйелерін жасадық, түсінікті оқыту үлгілерін қолданатын және тілдік мәліметті түсіні Тіпті оқыту жүйелерінің екеуі жүйесіне лингвистикалық мәліметті ережелерді қолдануға арналған, біз үш жүйелердің (шығысының) интеграциясы арқылы, әрбір тәртіпті тексеру параметрінде әрбір тәртіпті жалғыз істе Бірақ сынақтар мәліметінде интеграцияның істеу үлгісіміздің ең жақсы оқыту үлгісімізден артық болды. Бұл нәтижелер машиналық оқыту және эксперттік ережелерді біріктіру жүйелерін біріктіру жолында бірнеше прогресс көрсетілмейді. Біз осы жұмыс істемесінен кейін сынақ деректерінің жазбалары мен алтын жарлықтарын шығаруын күтпейміз.', 'ms': 'In the scope of WNUT-2020 Task 2, we developed various text classification systems, using deep learning models and one using linguistically informed rules.  Sementara kedua-dua sistem pembelajaran mendalam melampaui sistem menggunakan peraturan yang diberitahu secara bahasa, kami mendapati bahawa melalui integrasi (output) tiga sistem prestasi yang lebih baik boleh dicapai daripada prestasi sendiri setiap pendekatan dalam seting pengesahihan salib. Bagaimanapun, pada data ujian prestasi integrasi sedikit lebih rendah daripada model belajar dalam yang terbaik. Hasil ini hampir tidak menunjukkan kemajuan dalam baris penyelesaian pembelajaran mesin dan peraturan pakar sistem yang dipandu. Kami mengharapkan bahawa pembebasan manual anotasi dan label emas data ujian selepas workshop ini akan memberi cahaya kepada keputusan yang mengejutkan ini.', 'mk': 'Во областа на ВНУТ-2020 задача 2, развивме различни системи за класификација на текст, користејќи модели за длабоко учење и еден користејќи јазички информирани правила. И покрај тоа што двата системи на длабоко учење го надминаа системот користејќи ги јазички информираните правила, откривме дека преку интеграцијата на (излезот од) трите системи може да се постигне подобра перформанса отколку самостојната перформанса на секој пристап во рамките на крстовалидација. Сепак, на тестовите податоци, перформансата на интеграцијата беше малку пониска од нашиот најдобар модел на длабоко учење. Овие резултати едвај покажуваат никаков напредок во линијата на интеграција на системите на машинско учење и експертски правила. Очекуваме објавувањето на прирачниците за анотација и златните етикети на податоците од тестот по оваа работилница да ги објасни овие збунувачки резултати.', 'ml': 'WNUT-2020 ടാസ്ക് 2-ന്റെ സ്കോപ്പില്\u200d ഞങ്ങള്\u200d വ്യത്യസ്ത പഠിക്കുന്ന വിഭാഗങ്ങള്\u200d സിസ്റ്റമുണ്ടാക്കി. ആഴമായ പഠിക്കുന്ന മോ ഭാഷ വിവരമറിയിക്കപ്പെട്ട നിയമങ്ങള്\u200d ഉപയോഗിച്ച് ആഴത്തിലുള്ള പഠിപ്പിക്കുന്ന സിസ്റ്റത്തില്\u200d രണ്ടുപേരും സിസ്റ്റത്തെ പ്രവര്\u200dത്തിപ്പിച്ചിരുന്നപ്പോള എന്നാലും, പരീക്ഷണത്തിന്\u200dറെ ഡേറ്റായിരുന്നാലും നമ്മുടെ ആഴത്തെ പഠിക്കുന്ന മോഡലിനെക്കാള്\u200d കുറച്ച് കുറവാ These results hardly indicate any progress in line of integrating machine learning and expert rules driven systems.  ഞങ്ങള്\u200d പ്രതീക്ഷിക്കുന്നു, പരീക്ഷണത്തിന്റെ വിവരങ്ങളും സ്വര്\u200dണ്ണ ലേബ്ലേറ്റുകളും പ്രകാശിപ്പിക്കുമെന്ന്. ഈ വിഷയത്തിനുശ', 'mt': 'Fl-ambitu tal-Kompitu 2 tad-WNUT-2020, żviluppajna diversi sistemi ta’ klassifikazzjoni tat-testi, bl-użu ta’ mudelli ta’ tagħlim profond u wieħed bl-użu ta’ regoli infurmati lingwistikament. Filwaqt li ż-żewġ sistemi ta’ tagħlim profond qabżu s-sistema bl-użu tar-regoli infurmati lingwistikament, sabu li permezz tal-integrazzjoni tat-tliet sistemi (ir-riżultat tat-tliet sistemi) tista’ tinkiseb prestazzjoni a ħjar mill-prestazzjoni indipendenti ta’ kull approċċ f’ambjent ta’ validazzjoni inkroċjata. Madankollu, fuq id-dejta tat-test il-prestazzjoni tal-integrazzjoni kienet ftit inqas mill-mudell tagħna ta’ tagħlim profond bl-aħjar prestazzjoni. Dawn ir-riżultati bilkemm jindikaw xi progress fil-linja tal-integrazzjoni tat-tagħlim bil-magni u sistemi mmexxija mir-regoli esperti. Aħna nistennew li r-rilaxx tal-manwali tal-annotazzjoni u t-tikketti tad-deheb tad-dejta tat-test wara dan il-workshop ser jagħti dawl fuq dawn ir-riżultati perplessi.', 'mn': 'WNUT-2020 даалгаварын 2 даалгаварын түвшинд бид өөр олон текст хуваалтын системийг хөгжүүлж, гүн гүнзгий суралцах загваруудыг ашиглаж, хэлний мэдээллийн дүрэм ашиглаж байна. Хэдийгээр гүн гүнзгий суралцах систем хоёр нь хэл хэлний мэдээллийн дүрэм ашиглан системийг дамжуулсан ч бид гурван системийн нэгтгэл дээр ажиллагаа гаргаж чадна. Гэвч шалгалтын өгөгдлийн талаар нэгтгэлийн үр дүнг бидний хамгийн гүн суралцах загвараас бага зэрэг бага байлаа. Эдгээр үр дүнд машин суралцах болон мэргэжилтэн дүрэм хөгжүүлэх системүүдийг нэгтгэхэд хэцүү хөгжлийг харуулж чадахгүй. Эдгээр ажлын дараа шалгалтын өгөгдлийн шалгалтын гар, алтын загваруудыг гаргах гэдгийг бид хүлээж байна.', 'no': 'I området for WNUT-2020 oppgåve 2 utvikla vi ulike tekstklassifikasjonssystemer med dype læringsmodeller og ein brukar språkstisk informerte reglar. Mens begge av dei dype læringssystema utførte systemet med språkstisk informerte reglane, fann vi at gjennom integrasjonen av (utdata av) tre system a kan ein betre utvikling oppnå enn den enkelte utviklinga av kvar tilnærming i eit kryss-validasjonsinnstilling. I test data er imidlertid utføringen av integrasjonen litt mindre enn vår beste utføring av dypt læringsmodell. Desse resultatene viser ikkje nokon framgang i linje med å integrera maskinelæring og ekspertreglar som styrer systemet. Vi forventar at utlysinga av notasjonshandlingane og gullsmerkelappen av test data etter denne arbeidsområdet vil slå lys på desse uttrykkelige resultatene.', 'pl': 'W ramach zadania WNUT-2020 2 opracowaliśmy różne systemy klasyfikacji tekstów, wykorzystujące modele głębokiego uczenia oraz jeden z zasad poinformowanych językowo. Podczas gdy oba systemy głębokiego uczenia przewyższyły system wykorzystując językowo poinformowane reguły, stwierdziliśmy, że dzięki integracji (wyników) trzech systemów można osiągnąć lepszą wydajność niż samodzielna wydajność każdego podejścia w warunkach walidacji krzyżowej. Jednak na podstawie danych testowych wydajność integracji była nieco niższa niż nasz najlepiej wydajny model głębokiego uczenia. Wyniki te prawie nie wskazują na postępy w zakresie integracji uczenia maszynowego i systemów opartych na zasadach ekspertów. Oczekujemy, że publikacja instrukcji adnotacyjnych i złotych etykiet danych testowych po tym warsztacie rzuci światło na te zdumiewające wyniki.', 'ro': 'În cadrul activității WNUT-2020 2, am dezvoltat diferite sisteme de clasificare a textelor, folosind modele de învățare profundă și unul folosind reguli informate lingvistic. În timp ce ambele sisteme de învățare profundă au depășit performanța sistemului utilizând regulile informate lingvistic, am constatat că prin integrarea (rezultatul) celor trei sisteme s-ar putea obține o performanță mai bună decât performanța independentă a fiecărei abordări într-un cadru de validare încrucișată. Cu toate acestea, pe datele de testare performanța integrării a fost ușor mai mică decât modelul nostru de învățare profundă cel mai performant. Aceste rezultate nu indică niciun progres în ceea ce privește integrarea sistemelor de învățare automată și a sistemelor bazate pe reguli de specialitate. Ne așteptăm ca lansarea manualelor de adnotare și a etichetelor aurii ale datelor de testare după acest workshop să pună lumină asupra acestor rezultate uimitoare.', 'sr': 'U oblasti WNUT-2020 zadatka 2, razvili smo različite sisteme klasifikacije teksta, koristeći duboke modele učenja i jedan korištenje jezički informiranih pravila. Iako su obe duboke sisteme učenja nadmašile sistem koristeći jezički informativne pravila, otkrili smo da kroz integraciju (izlaz) tri sistema može biti postignuta bolja učinka od samostalnog učinka svakog pristupa u okviru cross-validatije. Međutim, na testiranim podacima, učinkovitost integracije je bio malo niži od našeg najboljeg izvršenog model dubokog učenja. Ovi rezultati jedva ukazuju na bilo koji napredak u liniji integracije uređaja i stručnih pravila upravljajući sistemima. Očekujemo da će oslobađanje priručnika za annotaciju i zlatnih etiketa testnih podataka nakon ovog radionice prosvetiti svjetlost na ovim kompleksnim rezultatima.', 'si': 'WNAT-2020ක් වැඩේ 2 වැඩේ ස්ථානයේදී, අපි විවිධ පාළ පද්ධතිය පද්ධතිය හොයාගත්තා, ගොඩක් ඉගෙනීම් මොඩේල් භාවිතා  දෙන්නම් ගොඩක් ඉගෙනීම් පද්ධතියේ පද්ධතියේ භාෂාවික විදිහට පරීක්ෂා කරලා තියෙනවා, අපි හොයාගත්තා මේ පද්ධතියේ සංවිධානය තුන්දෙන් හොඳ වැ නමුත්, පරීක්ෂණ දත්තේ සංවිධානයේ සංවිධානය අපේ හොඳම ඉගෙනගන්න ප්\u200dරමාණය වඩා ටිකක් අඩු වෙලා ති මේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්න බැරි විදිහට යන්ත්\u200dරය ඉගෙනීම සහ විශේෂ නීති පද්ධතිය සං අපි බලාපොරොත්තු වෙනවා මේ වැඩසටහන් පස්සේ පරීක්ෂණා තොරතුරු සහ සුන්තු ලේබිල් ප්\u200dරතික්\u200dරියාවක් පරීක්ෂණයේ පර', 'so': 'Shaqo 2 WNUT-2020 ayaannu horumarinay nidaamka kala duduwan ee qoraalka, waxaynu isticmaalnay modelalka waxbarashada mool dheer iyo mid ku isticmaalaya sharciyada luuqada lagu qoray. Intii labada nidaamka waxbarashada mool dheer ay nidaamka ku sameynayeen sharciyada luuqada lagu qoray, waxaynu ogaannay in la qabsashada (soo bixinta) saddexda nidaamka waxaa laga heli karaa wax ka wanaagsan sameyn kara sameynta gaarka ah ee qaab walba oo kali ah. Si kastaba ha ahaatee, arimaha imtixaanka, dhamaadka la qabsashada ayaa ka hoos yaraan qaababka waxbarashada ee ugu wanaagsan. Arrimahaas waxay si adag ugu muuqataa horumarinta la qabsashada waxbarashada mashiinka iyo xeerarka khaaska ah ee la soconayo. Waxaynu rajaynaynaa in furitaanku uu sameynayo sameynta qalabka caadooyinka iyo alaabta dahabka ah ee macluumaadka imtixaanka kadib wargeyskaas ka dib uu iftiimiyo arimahan dhibaataysan.', 'sv': 'Inom ramen för WNUT-2020 Task 2 utvecklade vi olika textklassificeringssystem, med hjälp av djupinlärningsmodeller och ett med språkligt informerade regler. Medan båda systemen för djupinlärning presterade bättre än systemet med hjälp av språkligt informerade regler, fann vi att genom integrering av (resultatet av) de tre systemen kunde en bättre prestanda uppnås än den fristående prestandan för varje metod i en korsvalideringsmiljö. Men på testdata var prestandan för integrationen något lägre än vår bäst presterande djupinlärningsmodell. Dessa resultat tyder knappast på några framsteg när det gäller att integrera maskininlärnings- och expertregelbaserade system. Vi förväntar oss att publiceringen av noteringshandböcker och guldetiketter av testdata efter denna workshop kommer att belysa dessa förbryllande resultat.', 'ur': 'WNUT-2020 ٹاکس 2 کی حفاظت میں ہم نے مختلف ٹکسٹ کلاسپیٹ سیستموں کو ایجاد کیا، عمیق تعلیم مدلکوں کے استعمال سے اور ایک زبان شناساتی قانون کے استعمال سے۔ حالانکہ ان دونوں عمیق تعلیم سیسٹموں نے سیسٹم کو زبان سے معلوم ہوئے قوانین کے استعمال سے کام لیا تھا، ہم نے دیکھا کہ تین سیسٹموں کی تفریق کے ذریعے ایک اچھی عملکرد پہنچ سکتی ہے ہر طریقے کی ایک ایک استاندازہ عملکرد سے۔ لیکن، آزمائش ڈیٹے پر اتصال کی فعالیت تھوڑا کم کم کم تھوڑا تھا ہمارے بہترین سیکھنے کی مدل سے۔ یہ نتائج مشکل نہیں دیتے کہ ماشین کی تعلیم اور متخصص قانون کی سیستموں میں کسی طرح کی پیشرفت کرتی ہے۔ ہم انتظار کر رہے ہیں کہ آزمائش کے مطابق آزمائش کے مطابق آزمائش کے مطابق آزمائش کے مطابق سونے لیبل آزاد ہو جائیں گے، اس کارشاپ کے بعد یہ آزمائش کے نتیجے پر چمکتے ہیں۔', 'ta': 'WNUT-2020 பணி 2 என்ற தோற்றத்தில், நாங்கள் வேறு உரை வகைப்படுத்தல் அமைப்புகளை உருவாக்கினோம், ஆழமான கற்றுக் கொள்ளும் மாதிரிகளையும்  ஆழமான கற்றல் அமைப்புகள் இருவரும் மொழியில் அறிவிக்கப்பட்ட விதிமுறைகளை பயன்படுத்தி முறைமையை செயல்படுத்தினார்கள் போது, மூன்று அமைப்புகளின் ஒன்றிணைப்பில் (வெள ஆயினும், சோதனையின் தரவில், ஒருங்கிணைப்பின் செயல்பாடு எங்கள் ஆழமான கற்றல் மாதிரியை சிறிது குறைந்தது. இந்த முடிவுகள் எந்த முன்னேற்றமும் குறிப்பிடுவதில்லை இயந்திரம் கற்றல் மற்றும் சிறப்பு விதிகள் இயக்கி அமைப்ப We expect that the release of the annotation manuals and gold labels of the test data after this workshop will shed light on these perplexing results.', 'uz': "WNUT-2020 Vazifa 2 Ish stolida biz har xil matn classification tizimini yaratdik, juda qiyin o'rganish modellari bilan biri tillarda haqiqida maʼlumot qoidalar yordamida yaratdik. Bu ikkita ta'lim o'rganish tizimi tillarda o'rganish qoidalari bilan tizimni ishga tushirilgan paytda biz uchta tizimni birlashtirish (natijada) bilan o'rganish mumkin, bir necha toʻgʻri tizimni tasdiqlash mumkin. Lekin sinov maʼlumotlarida birlashtirish muvaffaqiyatsiz eng yaxshi o'rganish modelimizdan kamaytirilgan edi. Ushbu natijalar kompyuterni o'rganish va ekspert qoidalar tizimini birlashtirishda hech qachon narsalar koʻrsatilmadi. Biz shu workshopdan keyin tashqari maʼlumot yordamchisini qo'llanmalar va gull teglarini chiqarishni kutayapmiz bu muammolar natijalarini ko'rsatadi.", 'vi': 'Trong phạm vi Nhiệm vụ WGiờ-2020, chúng tôi đã phát triển nhiều hệ thống phân loại văn bản khác nhau, sử dụng các mô hình học sâu và một hệ thống thông tin ngôn ngữ. Trong khi cả hai hệ thống học sâu đã hoàn thành hệ thống bằng cách thông tin ngôn ngữ học, chúng tôi phát hiện ra rằng nhờ nhập (sản xuất của) ba hệ thống, khả năng đạt hiệu quả tốt hơn so với khả năng duy nhất của mỗi phương pháp trong một thiết lập thẩm tra chéo. Tuy nhiên, trên dữ liệu thí nghiệm, kết quả của việc nhập cảnh thấp hơn một chút so với mô hình học sâu thành công tốt nhất của chúng tôi. Những kết quả này hầu như không cho thấy có tiến triển nào trong việc nhập vào hệ thống máy học và điều khiển luật chuyên môn. Chúng tôi mong rằng việc phát hành cuốn cẩm nang chú thích và nhãn vàng của dữ liệu thử sau khi làm việc này sẽ làm sáng tỏ những kết quả khó hiểu này.', 'bg': 'В рамките на задача 2 разработихме различни системи за класификация на текста, използвайки модели на дълбоко обучение и една използвайки лингвистично информирани правила. Въпреки че и двете системи за дълбоко обучение надминават системата, използвайки лингвистично информираните правила, установихме, че чрез интегрирането на трите системи (изхода от) може да се постигне по-добра производителност от самостоятелното представяне на всеки подход в среда на кръстосано валидиране. Въпреки това, на тестовите данни ефективността на интеграцията беше малко по-ниска от най-добре представящия модел на дълбоко обучение. Тези резултати едва ли показват напредък в интегрирането на системи за машинно обучение и експертни правила. Очакваме публикуването на ръководствата за анотация и златните етикети на тестовите данни след този семинар да хвърли светлина върху тези озадачаващи резултати.', 'nl': 'In het kader van WNUT-2020 Task 2 hebben we verschillende tekstclassificatiesystemen ontwikkeld, waarbij gebruik wordt gemaakt van deep learning modellen en een met taalkundig onderbouwde regels. Hoewel beide deep learning systemen het systeem overtroffen met behulp van de taalkundig geïnformeerde regels, vonden we dat door de integratie van (de output van) de drie systemen een betere prestatie kon worden bereikt dan de standalone prestaties van elke aanpak in een cross-validatie setting. Op de testdata waren de prestaties van de integratie echter iets lager dan ons best presterende deep learning model. Deze resultaten wijzen nauwelijks op enige vooruitgang in het integreren van machine learning en expert rules driven systemen. We verwachten dat de publicatie van de annotatiehandleidingen en gouden labels van de testgegevens na deze workshop licht zal werpen op deze verwarrende resultaten.', 'da': 'Inden for rammerne af WNUT-2020 Task 2 udviklede vi forskellige tekstklassifikationssystemer ved hjælp af deep learning modeller og et ved hjælp af sprogligt informerede regler. Mens begge deep learning-systemer klarede bedre end systemet ved hjælp af de sprogligt informerede regler, fandt vi, at gennem integration af (output af) de tre systemer kunne en bedre ydeevne opnås end den enkelte ydeevne af hver enkelt metode i en krydsgolideringsindstilling. På testdataene var integrationens ydeevne dog lidt lavere end vores bedst ydende deep learning model. Disse resultater indikerer næppe nogen fremskridt med hensyn til integration af maskinlæring og ekspertregulerede systemer. Vi forventer, at udgivelsen af annotationsmanualer og guldmærker af testdata efter denne workshop vil kaste lys over disse forvirrende resultater.', 'de': 'Im Rahmen von WNUT-2020 Task 2 haben wir verschiedene Textklassifizierungssysteme entwickelt, die Deep Learning Modelle und eines mit sprachlich fundierten Regeln verwenden. Während beide Deep Learning Systeme das System mit den sprachlich informierten Regeln übertrafen, fanden wir heraus, dass durch die Integration (der Ausgabe) der drei Systeme eine bessere Leistung erreicht werden konnte als die eigenständige Leistung jedes Ansatzes in einer Cross-Validierungsumgebung. Bei den Testdaten war die Performance der Integration jedoch etwas geringer als bei unserem leistungsstärksten Deep Learning Modell. Diese Ergebnisse deuten kaum auf Fortschritte bei der Integration von maschinellem Lernen und Expertenregeln basierenden Systemen hin. Wir erwarten, dass die Veröffentlichung der Annotationshandbücher und goldenen Labels der Testdaten nach diesem Workshop Licht auf diese verwirrenden Ergebnisse werfen wird.', 'id': 'In the scope of WNUT-2020 Task 2, we developed various text classification systems, using deep learning models and one using linguistically informed rules.  While both of the deep learning systems outperformed the system using the linguistically informed rules, we found that through the integration of (the output of) the three systems a better performance could be achieved than the standalone performance of each approach in a cross-validation setting.  Namun, pada data tes prestasi integrasi sedikit lebih rendah dari model belajar dalam yang terbaik. Hasil ini hampir tidak menunjukkan kemajuan dalam garis integrasi belajar mesin dan aturan ahli sistem yang didorong. Kami mengharapkan bahwa pembebasan manual anotasi dan label emas dari data tes setelah workshop ini akan memberi cahaya pada hasil yang mengejutkan ini.', 'fa': 'در محدودیت Task 2 WNUT-2020، ما سیستم\u200cهای مختلف طرح\u200cبندی متن را توسعه دادیم، با استفاده از مدل\u200cهای یادگیری عمیق و یکی از قانون\u200cهای اطلاعات زبانی استفاده می\u200cکنیم. در حالی که هر دو سیستم یادگیری عمیق از سیستم با استفاده از قوانین اطلاعات زبانی انجام دادند، ما فهمیدیم که از طریق ترکیب (نتیجه) سه سیستم\u200cها یک عملکرد بهتر از عملکرد تنهایی هر دستور در یک تنظیمات متفاوتی می\u200cتواند رسیده شود. با این حال، در اطلاعات آزمایش، عملکرد انجمن کمی کمتر از بهترین مدل یادگیری عمیق ما بود. این نتیجه ها به سختی نشان نمی دهند که هیچ پیشرفتی در خط آموزش ماشین و قانون متخصص به سیستم های راهنمایی وجود دارد. ما انتظار داریم که آزاد دستورالعمل و نقاشی طلا از داده های آزمایش بعد از این کارگاه بر این نتیجه\u200cهای متفاوت روشن شود.', 'sw': 'Kwa kiwango cha kazi ya WNUT-2020, tuliunda mfumo wa usambazaji wa maandishi, kwa kutumia miundo ya kujifunza vizuri na moja kwa kutumia kanuni zinazoelezwa lugha. Wakati mifumo yote ya kujifunza ya kina mbili zilifanya mfumo huo kwa kutumia kanuni zinazoelezwa kwa lugha, tuligundua kuwa kupitia ushirikiano (utoaji wa matokeo) mifumo mitatu bora zaidi inaweza kupata ufanisi kuliko utendaji wa kila njia pekee katika mazingira yenye uhakika. Hata hivyo, katika takwimu za jaribio, utendaji wa ushirikiano ulikuwa chini kidogo kuliko modeli yetu bora ya kujifunza kwa kina. These results hardly indicate any progress in line of integrating machine learning and expert rules driven systems.  Tunatarajia kuachiliwa huru kwa manunuzi ya matangazo na alama za dhahabu za taarifa za jaribio baada ya warsha hii itasambaza mwanga juu ya matokeo haya yanayoweza kusikitisha.', 'tr': 'WNUT-2020 Görevi 2-nji sahypada, dürli metin klasifikasyon sistemlerini ullanyp, derin öwrenme modellerini we dil bilgili kurallaryny ulanan birini geliştirdik. Çalňyş öwrenme sistemalaryň ikisi hem sistemasy lingwistiki bilgili kurallary ulanyp ýüze çykyp gitýärdi. Biz 3 sistemlerin (output) birleşmesi üçin bir ýagdaýyň ýeke özi başarylygyndan has gowy bir şekilde çykyp bilýäris. Ýöne, test maglumatynda integrasyň etkinlik ukyplarymyzyň iň gowy utan nusgalarymyzdan biraz aşak boldy. Bu netijeler maşynyň öwrenmegi we uzmanly düzgün sistemalary integralyň çyzygynda hiç hili ilerlemegini belli edip bilmeýän däldir. Biz bu işden soň testiň gol etiketleriniň ýazgytlygyny we gol etiketleriniň boşadylmagyna garaşýarys.', 'af': "In die omvang van WNUT-2020 Opdrag 2, het ons verskillende teks klassifikasie stelsels ontwikkel deur diep leer modele te gebruik en een met lingvisiese inligtige reëls te gebruik. Alhoewel beide van die diep leersystemee die stelsel uitgevoer het deur die lingvisiese inligte reëls, het ons gevind dat deur die integrasie van (die uitvoer van) die drie stelsels 'n beter uitvoer kon bereik word as die standalone uitvoer van elke toegang in 'n kruis-validigeringsinstelling. Maar op die toets data was die prestasie van die integrasie klein minder as ons beste uitvoer diep leer model. Hierdie resultate vertoon skaars enige vordering in lyn van integrering van masjien leer en ekspertiese reëls gedrywe stelsels. Ons verwag dat die verlossing van die annotasie handboeke en goud etikette van die toets data na hierdie werkskerm lig op hierdie verplekkende resultate sal skei.", 'am': 'በWNUT-2020 ስራ 2 ክፍል፣ ልዩ የጽሑፍ ክፍል ሲስተካከል፣ ጥልቅ ትምህርት ዓይነቶች እና አንዱ በቋንቋ-ቋንቋ የተማረ ሥርዓቶችን በመጠቀም አካሄድን፡፡ ሁለቱም ጥልቅ ትምህርት ሲስተማርቱ የቋንቋ-ቋንቋ የሚታወቀውን ሕግ ሲያሳድጉ፣ በሦስቱ ስርዓቶች ማጠቃቀሚያ (ውጤት ውጤት) በመጠቀም፣ የሁሉም ክፍል በተመሳሳይ ማድረግ በተለየ ሁለተኛ ስርዓት ይደረጋል፡፡ ነገር ግን በተፈተናው ዳታዎች የሞከር ጥልቅ ትምህርት ምሳሌ ከመስጠት ጥቂት ትንሽ ነበር፡፡ እነዚህ ፍጥረቶች የመኪና ትምህርት እና የጦማር ሥርዓቶች የሚነሳቀሱትን ሥርዓቶች በመቀነስ ማንኛውንም ቅድሚያ ያሳያል፡፡ ከዚህም ሰርቨርስቲ በኋላ የድምፅ ዳታዎችን እና የወርቅ ምልክቶችን መፈታት በተጨማሪው ውጤቶች ላይ እንዲያበራ ተስፋ እናደርጋለን፡፡', 'hr': 'U oblasti zadatka 2. WNUT-2020 razvili smo različite sustave klasifikacije teksta, koristeći duboke modele učenja i jednu koristeći jezički informirana pravila. Iako su obje duboke sustave učenja nadmašile sustav koristeći jezički informirane pravila, otkrili smo da kroz integraciju (izlaz) tri sustava može postići bolji učinak od samostalnog učinka svakog pristupa u okviru cross-validatije. Međutim, na testiranim podacima, učinkovitost integracije bio malo niži od našeg najboljeg izvođenja dubokog modela učenja. Ovi rezultati jedva ukazuju na bilo koji napredak u skladu integracije sustava za učenje strojeva i stručnih pravila. Očekujemo da će puštanje priručnika za annotaciju i zlatnih etiketa testnih podataka nakon ovog radionice prosvjetiti na ovim uvrnućim rezultatima.', 'ko': 'WNUT-2020 퀘스트 2의 범위 내에서 우리는 다양한 텍스트 분류 시스템을 개발하여 심도 있는 학습 모델과 언어 정보 규칙을 사용했다.두 가지 심도 있는 학습 시스템의 표현은 모두 언어 정보 규칙을 사용하는 시스템보다 낫지만 우리는 통합(세 시스템의 출력)이라는 세 시스템을 통해 교차 검증 환경에서 각 방법의 단독 성능보다 좋은 성능을 얻을 수 있음을 발견했다.그러나 테스트 데이터에서 통합된 성능은 우리가 가장 잘 표현한 심도 있는 학습 모델보다 약간 낮다.그 결과는 기계 학습과 전문가 규칙 구동 시스템 통합에 대한 진전이 거의 나타나지 않았다.우리는 이번 세미나 후에 테스트 데이터의 주석 매뉴얼과 금색 라벨의 발표가 이러한 곤혹스러운 결과를 설명할 것이라고 예상한다.', 'az': 'WNUT-2020 İkinci Gözəl səviyyəsində, çətin öyrənmə modelləri və dilində bilgili kuralları istifadə edərək müxtəlif metin klasifikasyonu sistemlərini təhsil etdik. İki dərin öyrənmə sistemlərin sistemini dilində bilən qaydaları ilə istifadə etdiyi halda, biz üç sistemin integrasiyası ilə, hər tərzinin təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə Ancaq sınama məlumatlarında integrasiyanın performansı bizim ən yaxşı öyrənmə modelimizdən az düşük idi. Bu növbətlər maşın öyrənməsi və ekspertlər kurallarının sistemlərini birləşdirməsi üçün heç bir tədbir göstərməz. Biz bu işarəndən sonra test verilənlərin məlumatlarını və qızıl etiketlərin açılmasını gözləyirik.', 'hy': 'Համաշխարհային Ազգային Ազգային Համաշխարհի 2020-ի 2-ի գործընթացի մեջ մենք զարգացրեցինք տարբեր տեքստի դասակարգման համակարգեր, օգտագործելով խորը սովորելու մոդելներ և մեկը՝ օգտագործելով լեզվաբանական տեղեկա Մինչդեռ երկու խորը ուսումնասիրության համակարգերը գերազանցեցին համակարգը լեզվաբանական տեղեկացված կանոններով, մենք հայտնաբերեցինք, որ երեք համակարգերի ինտեգրացիայի միջոցով ավելի լավ արդյունք կարելի է հասնել, քան յուրաքանչյուր մոտեցության առանձին արդյունքը խաչընդհատության միջ Այնուամենայնիվ, փորձարկման տվյալների վրա ինտեգրացիայի արդյունքը մի փոքր ավելի ցածր էր, քան մեր լավագույն արդյունքները ունեցող խորը ուսուցման մոդելը: Այս արդյունքները հազիվ ցույց են տալիս որևէ առաջընթաց ինտեգրելով մեքենային ուսումնասիրությունը և մասնագետների կանոնները հիմնված համակարգերը: Մենք ակնկալում ենք, որ նշումների ձեռքերի և փորձարկումների տվյալների ոսկե պիտակների հրապարակումը այս աշխատասենյակից հետո լույս կտա այս զարմանալի արդյունքների վրա:', 'bs': 'U oblasti WNUT-2020 zadatka 2, razvili smo različite sisteme klasifikacije teksta, koristeći duboke modele učenja i jedan koristeći jezički informirana pravila. Iako su obje duboke sisteme učenja nadmašile sistem koristeći jezički informirane pravila, otkrili smo da kroz integraciju (izlaz) tri sustava može postići bolji učinak od samostalnog učinka svakog pristupa u okviru cross-validatije. Međutim, na testiranim podacima, učinkovitost integracije je bio malo niži od našeg najboljeg izvođenja dubokog modela učenja. Ovi rezultati jedva ukazuju na bilo koji napredak u skladu integracije sustava za učenje strojeva i stručnih pravila. Očekujemo da će puštanje priručnika za annotaciju i zlatnih etiketa testnih podataka nakon ovog radionice prosvjetiti na ovim komplikovanim rezultatima.', 'bn': 'In the scope of WNUT-2020 Task 2, we developed various text classification systems, using deep learning models and one using linguistically informed rules.  যখন দুই গভীর শিক্ষা ব্যবস্থা ভাষায় তথ্য জানানো নিয়ম ব্যবহার করে সিস্টেম ব্যবস্থা প্রকাশ করে, তখন আমরা দেখতে পেয়েছি যে এই তিনটি সিস্টেমের মধ্যে একত্রিত হওয়ার মাধ্যমে প্ তবে পরীক্ষার তথ্যে একত্রিত হওয়ার প্রভাব আমাদের গভীর শিক্ষা মডেলের চেয়ে কম ছিল। এই ফলাফল খুব কঠিন নির্দেশ দেয়া যায় না মেশিন শিক্ষা এবং বিশেষজ্ঞ নিয়ম চালিয়ে যাওয়া সিস্টেমের সাথে যোগাযো আমরা আশা করি এই কর্মশালার পর পরীক্ষার তথ্যের বিভিন্ন পরীক্ষার মুক্তি এবং সোনার লেবেলের মুক্তি প্রদান করা হবে এই বিষয়টি বিভ্র', 'ca': "Al ámbit de la tasca 2 del WNUT-2020, vam desenvolupar diversos sistemes de classificació de textos, utilitzant models d'aprenentatge profund i un utilitzant normes lingüísticament informades. Mentre que ambdós sistemes d'aprenentatge profund superaven el sistema fent servir les normes lingüísticament informades, vam descobrir que a través de l'integració (la producció) dels tres sistemes es podia aconseguir un rendiment millor que el rendiment autònic de cada enfocament en un entorn de validació cruzada. Però en les dades de prova, el rendiment de l'integració era una mica més baix que el nostre model d'aprenentatge profund. Aquests resultats gairebé no indican cap progrés en línia d'integració d'aprenentatge automàtic i sistemes basats en normes especialitzades. Esperem que la publicació dels manuals d'anotació i etiquetes d'or de les dades de prova després d'aquest taller llumirà sobre aquests resultats perplexos.", 'cs': 'V rámci WNUT-2020 Task 2 jsme vyvinuli různé systémy klasifikace textů, využívající modely hlubokého učení a jeden využívající lingvisticky informovaných pravidel. Zatímco oba systémy hlubokého učení překonaly systém pomocí lingvisticky informovaných pravidel, zjistili jsme, že integrací (výstupu) těchto tří systémů lze dosáhnout lepšího výkonu než samostatný výkon každého přístupu v nastavení křížové validace. Na testovacích datech byl však výkon integrace o něco nižší než náš nejlepší model hlubokého učení. Tyto výsledky sotva naznačují žádný pokrok v oblasti integrace strojového učení a expertních pravidel řízených systémů. Očekáváme, že vydání anotací manuálů a zlatých etiket testovacích dat po tomto workshopu vrhne světlo na tyto matoucí výsledky.', 'fi': 'WNUT-2020 -teht채v채n 2 puitteissa kehitimme erilaisia tekstiluokitusj채rjestelmi채, joissa hy철dynnettiin syv채oppimismalleja ja yksi kielitieteellisesti perusteltuja s채채nt철j채. Vaikka molemmat syv채oppimisj채rjestelm채t suoriutuivat paremmin kuin j채rjestelm채 k채ytt채en kielellisesti perusteltuja s채채nt철j채, huomasimme, ett채 integroimalla kolme j채rjestelm채채 (tuotos) voitaisiin saavuttaa parempi suorituskyky kuin kunkin l채hestymistavan itsen채inen suorituskyky ristikk채isvalidoinnissa. Testitiedoissa integraation suorituskyky oli kuitenkin hieman heikompi kuin parhaiten suoriutuvalla syv채oppimismallillamme. N채m채 tulokset tuskin viittaavat siihen, ett채 koneoppimisen ja asiantuntijas채채nt철ihin perustuvien j채rjestelmien integroinnissa olisi edistytty. Odotamme, ett채 t채m채n ty철pajan j채lkeen julkaistut merkint채k채sikirjat ja testidatan kultaiset etiketit valaisevat n채it채 h채mment채vi채 tuloksia.', 'sq': 'Në fushën e WNUT-2020 Task 2, kemi zhvilluar sisteme të ndryshme klasifikimi të tekstit, duke përdorur modele mësimi të thellë dhe një duke përdorur rregulla të informuara gjuhësisht. Ndërsa të dy sistemet e mësimit të thellë e tejkaluan sistemin duke përdorur rregullat e informuara gjuhësisht, gjetëm se nëpërmjet integrimit të (daljes) të tre sistemeve mund të arrihet një performancë më e mirë se performanca e vetme e çdo qasje në një vendosje kryqëvalimi. Megjithatë, në të dhënat e testit performanca e integrimit ishte pak më e ulët se modeli ynë më i mirë i mësimit të thellë. Këto rezultate vështirë tregojnë ndonjë përparim në linjë të integrimit të mësimit të makinave dhe sistemeve të drejtuara nga rregullat eksperte. Ne presim që lëshimi i manualeve të anotacionit dhe etiketave të artë të të dhënave të testit pas këtij seminari do të hedhë dritë mbi këto rezultate të hutueshme.', 'et': 'WNUT-2020 ülesande 2 raames töötasime välja erinevad teksti klassifitseerimise süsteemid, kasutades sügavõppe mudeleid ja keeleliselt teadlikke reegleid. Kuigi mõlemad sügavõppesüsteemid olid keeleliselt informeeritud reeglite abil süsteemist kõrgemad, leidsime, et kolme süsteemi integreerimise (väljundite) kaudu oleks võimalik saavutada parem tulemus kui iga lähenemisviisi iseseisev tulemus ristvalideerimise tingimustes. Katseandmete põhjal oli integratsiooni tulemuslikkus veidi madalam kui meie parima tulemusega sügavõppe mudel. Need tulemused näitavad vaevalt edusamme masinõppe ja ekspertreeglitega põhinevate süsteemide integreerimisel. Loodame, et pärast seda töötuba avaldatakse testiandmete märkuste käsiraamatud ja kuldsed etiketid, mis valgustavad neid segadust tekitavaid tulemusi.', 'jv': 'WNUT-2020 Genjer sistem deep sampeyan sing gawe nggawe sistem sing gawe nguasai perusahaan winih ingkang dipunakno, awak dhéwé kuwi nggawe ngupakan sistem sing luwih apik (output dheus) sistem sing luwih apik dhéwé, akeh dhéwé iso dianggap perusahaan winih dhéwé bakal nggawe gerakan akeh dumadhi sak ditambah- Nanging, aku dipatensi uwong, dadi kanggo ngerasakno ning acara sedhaya sing nyimpen karo model sing apik nyimpen. Ndoleh iki lak ngomong nik kuwi nglanggar sapa tembang ning acara dadi Jejaring-ingkang karo sistem sing paling awak dhéwé. Awak dhéwé ngelanggar kuwi mèhke ngejaraké manungsa ngono alat sing berarti data kanggo ujian sisané iki ning acara mbukaké dhéwé.', 'ha': "Daga ƙayyade WNUT-2020 Tafiyar 2, mun buɗe masu tsari-matsayi dabam-daban, mun yi amfani da misãlai masu amfani da masu ƙari da kuma wani ya yi amfani da Rubuwan da aka sanar da harshen. A lokacin da duk masu ƙari sun cika tsarin da aka yi amfani da shiryoyin ayukan da aka sanar da shi cikin linguin, sai muka gane cewa, a lokacin integratewa (fitarwa) watau na'ura biyu, za'a iya samar da mafiya kyauta ko kuma ma'abun tsayi na koma guda a cikin daidaita mai maras-inganci. Amma, a kan jarrabar data, aikin integrity ya kasance kaɗan mafi ƙaranci daga mazaɓa da bajaran da misalin mafiya ƙari. Haƙĩƙa, waɗannan matsalar sun nũna wa kodi kodi a cikin linja na haɗi learning na kwamfyutan da na'urar masu amfani da shiryarwa na'urar masu fitarwa. Tuna tsammãni da za'a sakar da manunnan sanarwa da alama na zĩnãriya da matsayin jarraba bayan wannan aikin zai yi haske a kan waɗannan matsalar masu husũma.", 'sk': 'V okviru naloge 2 WNUT-2020 smo razvili različne sisteme klasifikacije besedil z uporabo modelov globokega učenja in enega z uporabo jezikovno ozaveščenih pravil. Medtem ko sta oba sistema globokega učenja izboljšala sistem z uporabo jezikovno informiranih pravil, smo ugotovili, da je z integracijo (rezultatov) teh treh sistemov mogoče doseči boljšo učinkovitost kot samostojna učinkovitost vsakega pristopa v okviru navzkrižne validacije. Vendar pa je bila na testnih podatkih uspešnost integracije nekoliko nižja od našega najbolje uspešnega modela globokega učenja. Ti rezultati komaj kažejo napredek pri integraciji sistemov strojnega učenja in strokovnih pravil usmerjenih sistemov. Pričakujemo, da bo objava priročnikov za opombe in zlatih nalepk testnih podatkov po tej delavnici osvetlila te zmedene rezultate.', 'bo': "In the scope of WNUT-2020 Task 2, we developed various text classification systems, using deep learning models and one using linguistically informed rules. While both of the deep learning systems outperformed the system using the linguistically informed rules, we found that through the integration of (the output of) the three systems a better performance could be achieved than the standalone performance of each approach in a cross-validation setting. Ama sınama çözümüzde integration'in performansı bizim iyi öğrenme modelimizden daha az kaldı. གྲུབ་འབྲས་འདི་དག་གི་དོན་རྐྱེན་གྱིས་མ་ལག་གི་སློབ་པའི་མཐུན་རྐྱེན་ནམ་ཡང་ན་ཁྱེད་པའི་ཐབས་ལམ་ལ་བསྡུར We expect that the release of the annotation manuals and gold labels of the test data after this workshop will shed light on these perplexing results.", 'he': 'בסקופ של משימה 2 WNUT-2020, פיתחנו מערכות מסווגים טקסטים שונות, בשימוש בדוגמנים למידה עמוקה ואחד בשימוש חוקים מידעים שפתיים. בעוד שני מערכות הלימודים העמוקות עברו את המערכת באמצעות החוקים המודיעים בשפה, מצאנו כי באמצעות האינטגרציה של (יציאת) שלושת המערכות אפשר להשיג ביצועים טובים יותר מאשר ביצועים בודדים של כל גישה במסגרת אישור צלב. However, on the test data the performance of the integration was slightly lower than our best performing deep learning model.  התוצאות האלה בקושי מצביעות על כל התקדמות בתור האינטגרציה של הלימודים המכונות וחוקים מומחים המנהלים מערכות. אנו מצפים שהשיחרור של מדריכי הערות ותוויות זהב של נתוני הבדיקה לאחר העבודה הזאת ישפך אור על התוצאות המתוערות האלה.'}
{'en': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3 : Cross-task modeling TEST _ POSITIVE  at  W - NUT  2020 Shared Task-3: Cross-task modeling', 'pt': 'TEST_POSITIVE no W-NUT 2020 Shared Task-3: modelagem de tarefas cruzadas', 'es': 'TEST_POSITIVE en la tarea compartida 3 de W-NUT 2020: Modelado entre tareas', 'fr': 'TEST_POSITIVE au W-NUT 2020 Shared Task-3\xa0: Modélisation inter-tâches', 'ar': 'TEST_POSITIVE في W-NUT 2020 Shared Task-3: نمذجة المهام المشتركة', 'ja': 'W - NUT 2020のテスト陽性共有タスク3 ：クロスタスクモデリング', 'ru': 'TEST_POSITIVE на W-NUT 2020 Shared Task-3: Межзадачное моделирование', 'zh': 'W-NUT 2020 共-3 上TEST_POSITIVE:跨建模', 'hi': 'W-NUT 2020 साझा कार्य-3 पर TEST_POSITIVE: क्रॉस-टास्क मॉडलिंग', 'ga': 'TEST_POSITIVE ag W-NUT 2020 Tasc Comhroinnte-3: Samhaltú tras-tascanna', 'el': 'ΔΟΚΙΜΗ_POSITIVE στο Κοινή Εργασία-3: μοντελοποίηση μεταξύ εργασιών', 'hu': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modellezés', 'ka': 'TEST_POSITIVE W-NUT 2020 shared Task-3: Cross-task modeling', 'it': 'TEST_POSITIVE a W-NUT 2020 Shared Task-3: modellazione cross-task', 'kk': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'lt': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'mk': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'ms': 'TEST_POSITIVE pada W-NUT 2020 Tugas Berkongsi-3: Modelan Tugas Salib', 'ml': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'mt': 'TEST_POSITIVE f’W-NUT 2020 Kompitu Konġunt-3: Immudellar ta’ kompiti inkroċjati', 'mn': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'no': 'TEST_POSITIVE på W-NUT 2020 Delt oppgåve-3: Cross-task modelling', 'pl': 'TEST_POSITIVE w W-NUT 2020 Shared Task-3: Modelowanie między zadaniami', 'ro': 'TEST_POSITIVE la W-NUT 2020 Activitatea partajată 3: Modelarea între sarcini', 'sr': 'TEST_POSITIVE na W-NUT 2020 podeljeni zadatak-3: modeliranje prekršnih zadataka', 'si': 'TEST_POSITIVE at W-NuT 2020shared Job-3: Cross-Job Modelling', 'sv': 'TEST_POSITIVE på W-NUT 2020 Delad uppgift-3: Modellering av flera uppgifter', 'so': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'ta': 'W NUT 2020-ல் TEST_ POSIVE WNUT 2020 பகிர்ந்த பணி- 3: Cross- task modeling', 'ur': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'uz': 'Comment', 'vi': 'Việc làm chung ở W-Giờ 2020: Đang tạo mẫu giao dịch', 'bg': 'Споделена задача-3: моделиране на кръстосани задачи', 'hr': 'TEST_POSITIVE na W-NUT 2020 Podijeljeni zadatak-3: modeliranje prekršnih zadataka', 'nl': 'TEST_POSITIEF bij W-NUT 2020 Gedeelde taak-3: Cross-task modellering', 'da': 'TEST_POSITIVE på W-NUT 2020 delt opgave-3: modellering af tværs af opgaver', 'de': 'TEST_POSITIVE bei W-NUT 2020 Shared Task-3: Taskübergreifende Modellierung', 'ko': 'W-NUT 2020 공유 임무 3: 교차 임무 모델링 테스트 양성', 'id': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'fa': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'sw': 'HABARI', 'tr': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'af': 'TEST_POSITIVE by W-NUT 2020 Gedeelde Opdrag-3: Cross-task modeling', 'sq': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'hy': 'TESTA_POSITIV W-NOT 2020-ի ընդհանուր հանձնարարություն-3. Մոդելներ', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling', 'bn': 'ওয়াই-NUT ২০২০ সালে টেস্ট_পোসিয়েভ: ক্রস-কাজের মডেলিং', 'bs': 'TEST_POSITIVE na W-NUT 2020 podeljeni zadatak-3: modeliranje prekršnih zadataka', 'ca': 'TEST_POSITIVE a W-NUT 2020 Task-3 compartida: Modell crucial de tasques', 'et': 'TEST_POSITIVE W-NUT 2020. aasta jagatud ülesanne-3: ülesannetevaheline modelleerimine', 'cs': 'TEST_POSITIVE na W-NUT 2020 Sdílený úkol-3: modelování mezi úkoly', 'fi': 'TEST_POSITIVE W-NUT 2020 Shared Task-3: Cross-task mallinnus', 'jv': 'text-NUT 2020', 'sk': 'TEST_POSITIVE na W-NUT 2020 Skupna naloga-3: Medopravilno modeliranje', 'ha': 'KCharselect unicode block name', 'he': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-Task Modelling', 'bo': 'TEST_POSITIVE at W-NUT 2020 Shared Task-3: Cross-task modeling'}
{'en': 'The competition of extracting COVID-19 events from  Twitter  is to develop systems that can automatically extract related events from  tweets . The built  system  should identify different pre-defined slots for each event, in order to answer important questions (e.g., Who is tested positive? What is the age of the person? Where is he / she?). To tackle these challenges, we propose the Joint Event Multi-task Learning (JOELIN) model. Through a unified global learning framework, we make use of all the training data across different events to learn and fine-tune the  language model . Moreover, we implement a type-aware post-processing procedure using named entity recognition (NER) to further filter the predictions. JOELIN outperforms the BERT baseline by 17.2 % in micro F1.', 'es': 'La competencia de extraer eventos de COVID-19 de Twitter es desarrollar sistemas que puedan extraer automáticamente los eventos relacionados de los tuits. El sistema construido debe identificar diferentes espacios predefinidos para cada evento, con el fin de responder a preguntas importantes (por ejemplo, ¿quién da positivo en la prueba? ¿Cuál es la edad de la persona? ¿Dónde está él/ella?). Para hacer frente a estos desafíos, proponemos el modelo Joint Event Multitask Learning (JOELIN). A través de un marco de aprendizaje global unificado, utilizamos todos los datos de capacitación de los diferentes eventos para aprender y ajustar el modelo lingüístico. Además, implementamos un procedimiento de procesamiento posterior con reconocimiento de entidades nombradas (NER) para filtrar aún más las predicciones. JOELIN supera a la línea base del BERT en un 17,2% en micro F1.', 'ar': 'تهدف المنافسة لاستخراج أحداث COVID-19 من Twitter إلى تطوير أنظمة يمكنها تلقائيًا استخراج الأحداث ذات الصلة من التغريدات. يجب أن يحدد النظام المبني خانات زمنية مختلفة محددة مسبقًا لكل حدث ، من أجل الإجابة على الأسئلة المهمة (على سبيل المثال ، من الذي تم اختباره إيجابيًا؟ ما هو عمر الشخص؟ أين هو / هي؟). لمواجهة هذه التحديات ، نقترح نموذج الحدث المشترك للتعلم متعدد المهام (JOELIN). من خلال إطار عمل تعليمي عالمي موحد ، نستفيد من جميع بيانات التدريب عبر الأحداث المختلفة لتعلم وضبط نموذج اللغة. علاوة على ذلك ، نقوم بتنفيذ إجراء معالجة لاحقة للنوع باستخدام التعرف على الكيانات المسماة (NER) لتصفية التنبؤات بشكل أكبر. يتفوق JOELIN على خط الأساس BERT بنسبة 17.2٪ في Micro F1.', 'pt': 'A competição de extrair eventos COVID-19 do Twitter é desenvolver sistemas que possam extrair automaticamente eventos relacionados de tweets. O sistema construído deve identificar diferentes slots pré-definidos para cada evento, a fim de responder a questões importantes (por exemplo, quem é testado positivo? Qual é a idade da pessoa? Onde ela está?). Para enfrentar esses desafios, propomos o modelo Joint Event Multi-task Learning (JOELIN). Por meio de uma estrutura de aprendizado global unificada, usamos todos os dados de treinamento em diferentes eventos para aprender e ajustar o modelo de linguagem. Além disso, implementamos um procedimento de pós-processamento com reconhecimento de tipo usando reconhecimento de entidade nomeada (NER) para filtrar ainda mais as previsões. JOELIN supera a linha de base do BERT em 17,2% em micro F1.', 'fr': "La compétition consistant à extraire les événements COVID-19 de Twitter consiste à développer des systèmes capables d'extraire automatiquement les événements liés à la COVID-19 à partir de tweets. Le système intégré doit identifier différents créneaux prédéfinis pour chaque événement, afin de répondre à des questions importantes (par exemple, Qui est testé positif\xa0? Quel est l'âge de la personne\xa0? Où est-il\xa0?). Pour relever ces défis, nous proposons le modèle Joelin (Joint Event Multi-task Learning). Grâce à un cadre d'apprentissage global unifié, nous utilisons toutes les données de formation des différents événements pour apprendre et affiner le modèle linguistique. De plus, nous mettons en œuvre une procédure de post-traitement sensible au type utilisant la reconnaissance d'entités nommées (NER) pour filtrer davantage les prévisions. JOELIN surpasse le taux de référence BERT de 17,2\xa0% en micro F1.", 'ja': '新型コロナウイルスのイベントをTwitterから抽出する競争は、関連するイベントをツイートから自動的に抽出できるシステムを開発することです。構築されたシステムは、重要な質問に答えるために、イベントごとに異なる事前定義されたスロットを特定する必要があります（例えば、テストで陽性と判定されたのは誰ですか？その人の年齢は何歳ですか？どこにいるの？ ）これらの課題に対処するために、ジョイントイベントマルチタスクラーニング（ JOELIN ）モデルを提案します。統一されたグローバル学習フレームワークを通じて、さまざまなイベントにわたるすべてのトレーニングデータを活用して、言語モデルを学習し、微調整します。さらに、我々は、予測をさらにフィルタリングするために、名前付きエンティティ認識（ ＮＥＲ ）を使用して、タイプ認識後処理手順を実装する。JOELINは、マイクロF 1でBERTベースラインを17.2 ％上回っています。', 'zh': '取COVID-19于Twitter者,发于推文。 建统宜为事识异预定义插槽,以应要(,谁试呈阳? 其人年几何? 他/在那里? 为此挑战,合事多任务学(JOELIN)模。 一全球学框架,各因其数以学微言。 名实相知 (NER) 成形知后处理过程,以益其占。 JOELIN于微型F1之中,高于BERT基线17.2%。', 'hi': 'ट्विटर से कोविड-19 की घटनाओं को निकालने की प्रतियोगिता उन प्रणालियों को विकसित करना है जो स्वचालित रूप से ट्वीट्स से संबंधित घटनाओं को निकाल सकते हैं। निर्मित प्रणाली को महत्वपूर्ण प्रश्नों के उत्तर देने के लिए प्रत्येक घटना के लिए अलग-अलग पूर्व-परिभाषित स्लॉट की पहचान करनी चाहिए (उदाहरण के लिए, कौन सकारात्मक परीक्षण किया जाता है? व्यक्ति की आयु क्या है? वह कहाँ है/वह है?)। इन चुनौतियों से निपटने के लिए, हम संयुक्त घटना मल्टी-टास्क लर्निंग (जोलिन) मॉडल का प्रस्ताव करते हैं। एक एकीकृत वैश्विक सीखने के ढांचे के माध्यम से, हम भाषा मॉडल को सीखने और ठीक करने के लिए विभिन्न घटनाओं में सभी प्रशिक्षण डेटा का उपयोग करते हैं। इसके अलावा, हम भविष्यवाणियों को आगे फ़िल्टर करने के लिए नामित एंटिटी मान्यता (एनईआर) का उपयोग करके एक प्रकार-जागरूक पोस्ट-प्रोसेसिंग प्रक्रिया को लागू करते हैं। जोलिन ने माइक्रो एफ 1 में बर्ट बेसलाइन को 17.2% से बेहतर प्रदर्शन किया।', 'ru': 'Конкуренция за извлечение событий COVID-19 из Twitter заключается в разработке систем, которые могут автоматически извлекать связанные события из твитов. Встроенная система должна определить различные заранее определенные слоты для каждого события, чтобы ответить на важные вопросы (например, кто тестируется положительным? Каков возраст человека? Где он/она?). Для решения этих проблем мы предлагаем модель совместного многозадачного обучения (JOELIN). С помощью единой глобальной системы обучения мы используем все обучающие данные в рамках различных мероприятий для изучения и доработки языковой модели. Кроме того, мы реализуем процедуру постобработки с учетом типа, используя распознавание именованных сущностей (NER) для дальнейшей фильтрации прогнозов. JOELIN опережает базовую линию BERT на 17,2% в микро F1.', 'ga': 'Is éard atá sa chomórtas maidir le himeachtaí COVID-19 a bhaint as Twitter ná córais a fhorbairt ar féidir leo imeachtaí gaolmhara a bhaint go huathoibríoch as tvuíteanna. Ba cheart go n-aithneodh an córas tógtha sliotáin réamhshainithe éagsúla do gach imeacht, chun ceisteanna tábhachtacha a fhreagairt (m.sh., Cé a bhfuil an tástáil dearfach air? Cad é aois an duine? Cá bhfuil sé/sí?). Chun dul i ngleic leis na dúshláin seo, molaimid an tsamhail Foghlama Ilthasc Imeachta Comhpháirteach (JOELIN). Trí chreat foghlama domhanda aontaithe, bainimid úsáid as na sonraí oiliúna go léir thar imeachtaí éagsúla chun an tsamhail teanga a fhoghlaim agus a mhionchoigeartú. Ina theannta sin, cuirimid nós imeachta iar-phróiseála feasach ar chineáil i bhfeidhm a úsáideann aitheantas aonáin ainmnithe (NER) chun na réamh-mheastacháin a scagadh tuilleadh. Sáraíonn JOELIN bonnlíne BERT faoi 17.2% i micrea F1.', 'ka': 'COVID-19 მოვლენების გამოყენება Twitter-დან არის სისტემის განვითარება, რომელიც შეუძლია ავტომატურად გამოყენებული მოვლენების გამოყენება. შექმნილი სისტემა უნდა განსაზღვრება განსხვავებული წინ განსაზღვრებული სისტემა ყოველ მოვლენისთვის, რომელიც უფრო მნიშვნელოვანი კითხვების შესახებ (მაგალითად, რომელიც პოტიფიკაციური ტესტი ამ გამოცდილებების გარეშე, ჩვენ მოვეხსენებთ ერთადერთი მოვლენების მრავალური მოსწავლების მოდელი (JOELIN). ერთადერთი გლობალური სწავლების ფრამეტრებით, ჩვენ ყველა სწავლების მონაცემების გამოყენება განსხვავებული მოვლენების განმავლობაში, რომ ვისწავლოთ და დავაკეთოთ ენის მო დამატებით, ჩვენ განვიყენებთ ტიპის მოცემული პროცემის პროცემი, რომელიც გამოყენება სახელი ინტერტის განახლება (NER) სხვადასხვადასხვადასხვადასხვადასხვადასხვ ჯოლინი გავაკეთება ბერტის ბაზლინი 17,2% მიკრო F1-ში.', 'hu': 'A COVID-19 események Twitterről történő kivonásának versenye olyan rendszerek fejlesztése, amelyek automatikusan ki tudják vonni a kapcsolódó eseményeket tweetekből. A beépített rendszernek minden eseményhez különböző, előre meghatározott résidőket kell azonosítania annak érdekében, hogy megválaszolhassa a fontos kérdéseket (pl.: Ki tesztelt pozitív, milyen korú a személy, hol van?). E kihívások kezelése érdekében javasoljuk a Joint Event Multi-Task Learning (JOELIN) modellt. Egy egységes globális tanulási keretrendszer révén a különböző események összes képzési adatát felhasználjuk a nyelvi modell megtanulásához és finomhangolásához. Ezenkívül egy típustudatos utófeldolgozási eljárást vezetünk be a nevezett entitás felismerésével (NER) az előrejelzések további szűrésére. A JOELIN 17,2%-kal felülmúlja a BERT alapértékét mikro F1 esetében.', 'el': 'Ο ανταγωνισμός της εξαγωγής συμβάντων από το Twitter είναι η ανάπτυξη συστημάτων που μπορούν αυτόματα να εξαγάγουν συναφή γεγονότα από τα tweets. Το δομημένο σύστημα θα πρέπει να προσδιορίζει διαφορετικές προκαθορισμένες υποδοχές για κάθε εκδήλωση, προκειμένου να απαντήσει σε σημαντικές ερωτήσεις (π.χ. Ποιος είναι θετικός; Ποια είναι η ηλικία του ατόμου; Πού βρίσκεται;). Για την αντιμετώπιση αυτών των προκλήσεων, προτείνουμε το μοντέλο εκμάθησης πολλαπλών εργασιών από κοινού. Μέσω ενός ενοποιημένου παγκόσμιου μαθησιακού πλαισίου, χρησιμοποιούμε όλα τα δεδομένα κατάρτισης σε διαφορετικές εκδηλώσεις για να μάθουμε και να τελειώσουμε το γλωσσικό μοντέλο. Επιπλέον, εφαρμόζουμε μια διαδικασία μετεπεξεργασίας με επίγνωση τύπου χρησιμοποιώντας αναγνώριση ονομασίας οντότητας (για περαιτέρω φιλτράρισμα των προβλέψεων. Ο JOELIN ξεπερνά τη γραμμή βάσης BERT κατά 17,2% στο μικρο F1.', 'it': "La competizione per estrarre eventi COVID-19 da Twitter è quella di sviluppare sistemi in grado di estrarre automaticamente eventi correlati dai tweet. Il sistema costruito dovrebbe identificare diversi slot predefiniti per ogni evento, al fine di rispondere a domande importanti (ad esempio, Chi è risultato positivo? Qual è l'età della persona? Dov'è?). Per affrontare queste sfide, proponiamo il modello Joint Event Multi-Task Learning (JOELIN). Attraverso un framework di apprendimento globale unificato, utilizziamo tutti i dati di formazione in diversi eventi per imparare e perfezionare il modello linguistico. Inoltre, implementiamo una procedura di post-elaborazione consapevole del tipo utilizzando il riconoscimento delle entità nominative (NER) per filtrare ulteriormente le previsioni. JOELIN supera la base BERT del 17,2% in micro F1.", 'lt': 'Konkurencija ištraukti COVID-19 renginius iš Twitter yra sukurti sistemas, kurios automatiškai ištrauktų susijusius renginius iš tweetų. Įstatytoje sistemoje kiekvienam įvykiui turėtų būti nustatyti skirtingi iš anksto apibrėžti laiko tarpsniai, kad būtų galima atsakyti į svarbius klausimus (pvz., kas yra teigiamas testas? Koks asmuo yra amžius? Kur jis?). Siekiant spręsti šiuos uždavinius, siūlome bendro renginių daugiafunkcinio mokymosi (JOELIN) model į. Įgyvendinant vieningą pasaulinį mokymosi sistemą, mes naudojame visus mokymo duomenis įvairiuose renginiuose, kad mokytume ir patobulintume kalbos model į. Be to, įgyvendiname tipo žinomą po perdirbimo procedūrą, naudojant pavadintą subjekto pripažinimą (NER), kad toliau būtų galima filtruoti prognozes. JOELIN viršija BERT pradinę reikšmę 17,2 % mikroF1 grupėje.', 'kk': 'COVID-19 оқиғаларды Твиттерден тарқату жағдайындағы жағдайларды tweets-ден автоматты түрде тарқатуға болады. Құрылған жүйе әрбір оқиға үшін басқа алдын- ала анықталған слоттарды анықтау керек. Маңызды сұрақтарды жауап беру үшін (мысалы, негізгі сынақтар кім? Адамдың жасысы қай? Ол/ол қайда?). Бұл мәселелерді өзгерту үшін бірге бір оқиға көп тапсырмаларды оқыту үшін (JOELIN) үлгісін ұсынамыз. Біріктірілген жүйелік оқыту бағдарламасы арқылы, тіл үлгісін оқыту және баптау үшін барлық оқыту деректерін қолданамыз. Осымен қатар, біз таңдауды бақылау үшін аталған нысандарды анықтау (НЕР) көмегімен түрлі білім кейін өткізу процедурын орындаймыз. ЖОЛИН MIкро F1 дегенде BERT негізгі жолын 17, 2% деп жасайды.', 'mk': 'Натпреварот за извлекување на настаните COVID-19 од Твитер е да се развијат системи кои автоматски можат да извлечат поврзани настани од твитови. The built system should identify different pre-defined slots for each event, in order to answer important questions (e.g., Who is tested positive? What is the age of the person? Where is he/she?).  За да ги решиме овие предизвици, ние го предложуваме моделот за заеднички настан за мултизадачно учење (JOELIN). Со унифицирана глобална рамка за учење, ги искористуваме сите податоци за обука во различни настани за да го научиме и подобриме јазичкиот модел. Покрај тоа, спроведуваме процедура на постобработување која е свесна за тип користејќи го препознавањето на именуваниот ентитет (НЕР) за понатамошно филтрирање на предвидувањата. ЏОЕЛИН ја надминува базата на BERT за 17,2 отсто во микро F1.', 'ms': 'Pertandingan untuk mengekstrak peristiwa COVID-19 dari Twitter adalah untuk mengembangkan sistem yang boleh mengekstrak peristiwa berkaitan secara automatik dari tweet. Sistem terbina patut mengenalpasti slot yang berbeza yang ditakrif-dahulu bagi setiap peristiwa, untuk menjawab soalan penting (contohnya, Siapa yang diuji positif? Berapa umur orang? Mana dia?). Untuk menghadapi cabaran ini, kami cadangkan Kejadian Bersama Model Pelajaran Berbagai Tugas (JOELIN). Melalui kerangka pembelajaran global yang bersatu, kita menggunakan semua data latihan melalui peristiwa yang berbeza untuk belajar dan menyesuaikan model bahasa. Selain itu, kami melaksanakan prosedur postproses yang sedar jenis menggunakan pengenalan entiti bernama (NER) untuk menapis lebih lanjut ramalan. JOELIN melebihi garis dasar BERT dengan 17.2% dalam mikro F1.', 'ml': 'ട്രൂട്ടറില്\u200d നിന്ന് കോവിഡി-19 സംഭവങ്ങള്\u200d പുറത്തെടുക്കുന്നതിന്റെ പ്രതിയോഗം ടൂട്ടുകളില്\u200d നിന്നും സ്വയം ബന്ധിച് നിര്\u200dമ്മിക്കപ്പെട്ട സിസ്റ്റം ഓരോ സംഭവത്തിനും മുമ്പ് വ്യത്യസ്തമായ വ്യത്യസ്ത സ്ലോട്ടുകള്\u200d നിരീക്ഷിക്കണം, പ്രധാനപ്പെട്ട ചോദ്യങ്ങള്\u200d ഈ ചോദ്യങ്ങളെ എതിര്\u200dത്തുന്നതിന് ഞങ്ങള്\u200d യൂണ്ടിന്\u200dറ് ഇൻറ് സെന്റ് കാര്യം പല ജോലി പഠിപ്പിക്കുന്നതിന്\u200dറെ മോഡല്\u200d പ് ഒരു ഗ്ലോബല്\u200d പഠിക്കുന്ന ഫ്രെയിമ്പിലൂടെ നമ്മള്\u200d വ്യത്യസ്ത സംഭവങ്ങളിലുള്ള എല്ലാ പരിശീലന വിവരങ്ങളും ഉപയോഗിക്കുന്ന പിന്നീട്, പ്രവചനങ്ങള്\u200d കൂടുതല്\u200d ഫില്\u200dറ്റര്\u200d ചെയ്യാന്\u200d പേരുള്ള വസ്തുത തിരിച്ചറിയുന്നതിന് ഉപയോഗിക്കുന്ന ഒരു തരത്തില JOELIN outperforms the BERT baseline by 17.2% in micro F1.', 'mn': 'COVID-19 үйл явдлыг Twitter-ээс гаргах өрсөлдөөн бол tweets-ээс автоматаар холбоотой үйл явдлыг гаргаж чадах системүүд хөгжүүлэх юм. Бүтээгдсэн систем бүх үйл явдлын тулд чухал асуултуудаа хариулт өгөхийн тулд өөр аргаар тодорхойлсон слотуудыг тайлбарлах хэрэгтэй (жишээ нь, хэн эерэг шалгалт авсан бэ? хүний нас хэд вэ? тэр хаана байна?). Эдгээр сорилтуудыг зогсоохын тулд бид олон үйл явдлын суралцах (JOELIN) загварын нэгтгэл санал өгдөг. Дэлхийн нэгдсэн суралцах үйл ажиллагааны тулд бид бүх суралцах өгөгдлийг өөр үйл ажиллагаанд суралцаж, хэл загварыг сайжруулахын тулд хэрэглэдэг. Дараа нь бид төрлийн мэдлэгтэй дараа үйлдвэрлэлийн процедурыг нэрлэгдсэн entity recognition (NER) ашиглан таамаглалтыг илүү шинжилгээ хийдэг. ЖОЛИН БЕРТ-ын суурь шугам нь жижиг F1-д 17.2%-аар үржүүлдэг.', 'mt': "Il-kompetizzjoni li jiġu estratti avvenimenti COVID-19 minn Twitter hija li jiġu żviluppati sistemi li jistgħu awtomatikament jiġu estratti avvenimenti relatati minn tweets. Is-sistema mibnija g ħandha tidentifika slots definiti minn qabel differenti għal kull avveniment, sabiex twieġeb mistoqsijiet importanti (pereżempju, Min huwa ttestjat pożittiv? X’inhi l-età tal-persuna? Fejn huwa?). Biex nindirizzaw dawn l-isfidi, nipproponu l-mudell ta' Tagħlim Multikompiti ta' Avvenimenti Konġunti (JOELIN). Permezz ta’ qafas globali ta’ tagħlim unifikat, a ħna nużaw id-dejta kollha tat-taħriġ f’avvenimenti differenti biex nitgħallmu u nilħqu l-mudell tal-lingwa. Barra minn hekk, nimplimentaw proċedura ta’ wara l-ipproċessar li tkun konxja tat-tip bl-użu tar-rikonoxximent tal-entità msejħa (NER) biex ikomplu jiffiltraw il-previżjonijiet. JOELIN jaqbeż il-linja bażi tal-BERT b’17.2% fil-mikro F1.", 'no': 'Konkurenten for å pakka ut COVID-19 hendingar frå Twitter er å utvikla systemar som kan automatisk pakka ut tilhøyrande hendingar frå tweets. Det bygde systemet bør identifisera ulike føredefinerte plassar for kvar hending for å svara på viktige spørsmål (f.eks. Kva er testet positivt? Kva er alderen av personen? Kva er han/ho?). For å løyse desse utfordringane, foreslår vi modellen «Joint Event Multi-Task Learning» (JOELIN). Gjennom eit vienot globalt læringsrammeverk, brukar vi alle læringsdata over ulike hendingar for å lære og finne opp språksmodellen. I tillegg implementerer vi ein post-processing-prosess med namnet entitetskjenning (NER) for å filter a framtida. JOELIN utfører BERT-baseline med 17,2 % i mikro F1.', 'pl': 'Konkurencją wydobywania zdarzeń COVID-19 z Twittera jest opracowanie systemów, które mogą automatycznie wyodrębniać powiązane zdarzenia z tweetów. Zbudowany system powinien identyfikować różne wstępnie zdefiniowane sloty dla każdego zdarzenia, aby odpowiedzieć na ważne pytania (np. Kto jest testowany pozytywnie, jaki jest wiek danej osoby, gdzie jest?). Aby sprostać tym wyzwaniom, proponujemy model Joint Event Multi-Task Learning (JOELIN). Dzięki ujednoliconym globalnym frameworkom uczenia się wykorzystujemy wszystkie dane szkoleniowe w różnych wydarzeniach, aby uczyć się i dostosować model językowy. Ponadto wdrażamy procedurę post-processing z wykorzystaniem rozpoznawania nazwanych jednostek (NER) w celu dalszego filtrowania prognoz. JOELIN przewyższa wartość bazową BERT o 17,2% w mikro F1.', 'ro': 'Competiția de extragere a evenimentelor COVID-19 de pe Twitter este de a dezvolta sisteme care pot extrage automat evenimente conexe din tweet. Sistemul construit ar trebui să identifice diferite sloturi predefinite pentru fiecare eveniment, pentru a răspunde la întrebări importante (de exemplu, Cine este testat pozitiv? Care este vârsta persoanei? Unde este aceasta?). Pentru a aborda aceste provocări, propunem modelul Joint Event Multi-Task Learning (JOELIN). Prin intermediul unui cadru de învățare globală unificat, utilizăm toate datele de formare din diferite evenimente pentru a învăța și a regla fin modelul lingvistic. Mai mult decât atât, implementăm o procedură de post-procesare conștientă de tip utilizând recunoașterea entităților denumite (NER) pentru a filtra în continuare previziunile. JOELIN depășește nivelul de referință BERT cu 17,2% în micro F1.', 'sr': 'Konkurencija izvlačenja COVID-19 događaja iz Twitter je razvoj sustava koji mogu automatski izvući povezane događaje iz tweeta. Izgradljeni sistem bi trebalo da identifikuje različite preddefinirane mesta za svaki događaj, kako bi odgovorio na važna pitanja (npr. ko je ispitivan pozitivan? Koliko je doba osobe? Gde je on/ona?). Da bi se riješili ovim izazovima, predlažemo model učenja multizadataka zajedničkog događaja (JOELIN). Kroz ujedinjeni globalni okvir učenja, koristimo sve podatke o obuci u različitim događajima da naučimo i sredimo jezički model. Osim toga, mi implementiramo postobrađivačku proceduru sa svijesti tipa koristeći priznanje entiteta (NER) kako bi dalje filtrirali predviđanja. Joelin iznosi početnu liniju BERT za 17,2% u mikro F1.', 'si': 'COVID-19 අවස්ථාවක් ට්විටර් වලින් නිකාලන්න ස්ථානය විස්තර කරන්න පුළුවන් පද්ධතිය ස්වයංක්\u200dරීය විස්ත නිර්මාණය කරපු පද්ධතිය හැම සිද්ධ වෙනස් ප්\u200dරශ්නයක්ම සඳහා වෙනස් ප්\u200dරශ්නයක් තියෙන්න ඕනේ (උදාහරණයෙන්, කවුද සාධාරණික පර මේ අභ්\u200dයානය සටන් කරන්න, අපි සම්බන්ධ වැඩි වැඩි වැඩි වැඩි වැඩි වැඩක් ඉගෙනීම (JOELIN) නිර්මාණය යුද්ධ කරනව සාමාන්\u200dය විශ්වාසික ඉගෙන ගන්න ප්\u200dරශ්නයක් වලින්, අපි භාෂාව මදුල් ඉගෙන ගන්න සහ හොඳ සාමාන්\u200dය දත්ත පාවි තවත්, අපි ප්\u200dරකාරයක් පස්සේ ප්\u200dරකාරයක් පිළිබඳින් පස්සේ ප්\u200dරකාරයක් පරීක්ෂණය කරනවා නම් අයිතිය අඳුරණය ( ජෝලින් මික්\u200dරෝ F1 වල බෙර්ට් බේස්ලින් වල 17.2% වලින් ප්\u200dරශ්නය කරනවා.', 'so': "Tartanka ka soo saarashada COVID-19 dhacdooyinka Twitterka waa in ay horumariyaan nidaamka ay si automatic ah uga soo saari karaan dhacdooyinka la xidhiidha Twitteetka. Tirada la dhisay waa in la aqoonsadaa meelo ay ku qoran lahaayeen hore, si ay ugu jawaabaan su'aalo muhiim ah (tusaale, Yaa la imtixaamo positive? cimriga qofku waa maxay? Meeh isagu?). Si aan u tacliino dhibaatooyinkaas, waxaan soo jeedaynaa tusaale ahaan waxbarashada wadanka shaqada (JOELIN). Dhammaan waxbarashada caalamiga ah ayaannu isticmaalaynaa macluumaadka waxbarashada ee dhacdooyinka kala duduwan oo dhan si aan u barto iyo si fiican u qorno modellka luuqada. Sidoo kale waxaynu sameeynaa baaritaanka ka dib-baaraandegista ah oo loo isticmaalayo aqoonsiga entity (NER) si aan ugu baaraandegiso wixii la sii sheegay. JOELIN wuxuu ka baxaa baseline BERT oo ah 17.2% in micro F1.", 'ta': 'COVID-19 நிகழ்வுகளை வெளியேற்றுவதற்கான competition is to develop systems that can automatically extract related events from Twitter. கட்டப்பட்ட அமைப்பு ஒவ்வொரு நிகழ்விற்கும் முன் வரையறுக்கப்பட்ட செருகுவரிகளை கண்டுபிடிக்க வேண்டும், முக்கியமான கேள்விகளுக்கு பதில் (உதா இந்த சவால்களை எதிர்பார்க்க, நாம் இணைய நிகழ்வு பல பணி கற்றுக்கொள்ள மாதிரியை பரிந்துரைக்கிறோம். ஒரு ஒன்றிணைக்கப்பட்ட உலக கற்றுக் கொள்ளும் சட்டத்தில், நாம் வேறு நிகழ்வுகளில் பயிற்சி தகவல்களை பயன்படுத்தி மொழி மாதிரி ம மேலும், நாம் பெயரிடப்பட்ட பொருள் அடையாளம் (NER) பயன்படுத்தி முன்னோர்களை மேலும் வடிகட்டுவதற்கான வகைப்படுத்தப்பட்ட பின் செ ஜோயிலின் பெர்ட் அடிப்படைக்கோடு 17. 2% மைக்ரோ F1 ல் வெளியேறுகிறது.', 'sv': 'Tävlingen om att extrahera COVID-19-händelser från Twitter är att utveckla system som automatiskt kan extrahera relaterade händelser från tweets. Det inbyggda systemet bör identifiera olika fördefinierade platser för varje händelse, för att besvara viktiga frågor (t.ex. Vem är positivt, vilken ålder är personen, var är personen?). För att ta itu med dessa utmaningar föreslår vi modellen Joint Event Multi-Task Learning (JOELIN). Genom ett enhetligt globalt lärramverk använder vi all utbildningsdata över olika evenemang för att lära oss och finjustera språkmodellen. Dessutom implementerar vi ett typmedvetet efterbehandlingsförfarande med namngiven entitetsigenkänning (NER) för att ytterligare filtrera prognoserna. JOELIN överträffar BERT baslinjen med 17,2% i mikroF1.', 'ur': 'ٹویٹر سے COVID-19 ایڈیونٹوں کو اٹھانے کی رقابت یہ ہے کہ سیستموں کی تخلیق کرنا ہے جو ٹویٹوں سے اتصال ہونے والی ایڈیونٹوں کو اٹھانے کے لئے۔ بنیاد کی سیسٹم ہر حادثہ کے لئے مختلف پیش تعریف کی جگہ پہچان لینا چاہیے، اس لئے کہ اہم سوال جواب دیں (جیسے، کس کو مثبت آزمائش کی جاتی ہے؟ شخص کی عمر کیا ہے؟ وہ کہاں ہے؟ ان چالوں کے ساتھ ہم نے جوڑنے کے مطابق بہت سے کام کی تعلیم (JOELIN) موڈل کی پیشنهاد کریں۔ ایک متحدہ سراسر سیکھنے کے ذریعے ہم کل ترینسی ڈیٹے کو مختلف حادثوں میں استعمال کرتے ہیں کہ زبان موڈل کو سیکھیں اور سیکھیں۔ اور اس کے علاوہ ہم نے ایک ٹائپ جانے والی پوسٹ پرسس پردازی پردازش کی پیدائش کی پیدائش کرتی ہے جس کا نام entity recognition (NER) ہے اس کے ذریعہ سے پیش بینی اضافہ کرنے کے لئے۔ جولین میکروٹ F1 میں 17.2% سے BERT بنیس لین کو اضافہ کرتا ہے.', 'uz': "Twitterdan COVID-19 hodisalarni chiqarish rivojlanishi Twitter bilan bog'liq hodisalarni avtomatik foydalanish mumkin. Bu yerda quyidagi tizim har bir hodisa oldin aniqlangan slotlarni aniqlash kerak. Muhim savollarni javob berish uchun (масалан, kim joylashtirilgan? odamning qaysi? U qaerda?). To tackle these challenges, we propose the Joint Event Multi-task Learning (JOELIN) model.  Dunyo ta'lim sohasi orqali, biz har xil hodisalar uchun hamma ta'lim maʼlumotini foydalanamiz va tilning modelini o'rganish va yaxshi o'rganish uchun. Koʻrsatgich, biz taʼminlovchi soʻzni taʼminlovchi soʻzni boshqarish jarayonlarini bajaramiz. Name", 'vi': "Cuộc cạnh tranh của việc khai thác COVID-19 từ Twitter là phát triển hệ thống có thể tự động trích các sự kiện liên quan từ Twitter. Hệ thống xây dựng nên xác định các khe hở khác nhau cho mỗi sự kiện, để trả lời các câu hỏi quan trọng (v. d. Ai được kiểm tra dương tính? Tuổi của người đó là bao nhiêu? Để giải quyết những thử thách này, chúng tôi đề nghị mô hình tổ chức đa nhiệm vụ giáo dục. Qua một cơ sở học to àn cầu thống nhất, chúng tôi sử dụng tất cả dữ liệu đào tạo qua các sự kiện khác nhau để học hỏi và chỉnh sửa mô hình ngôn ngữ. Thêm vào đó, chúng tôi thực hiện một thủ tục nhận biết kiểu sau việc xử lý bằng tên công ty (NER) để lọc dự đoán thêm. Joel outthực hiện cơ sở thực phẩm BERT bởi 17.2='trong vi F1.", 'bg': 'Конкуренцията за извличане на събития от Туитър е да се разработят системи, които могат автоматично да извличат свързани събития от Туитър. Изградената система трябва да идентифицира различни предварително определени слотове за всяко събитие, за да отговори на важни въпроси (напр. Кой е тестван положителен, каква е възрастта на човека, къде е той/тя?). За да се справим с тези предизвикателства, предлагаме модела Съвместно събитие за многозадачи обучение (JOELIN). Чрез единна глобална учебна рамка ние използваме всички данни за обучение в различните събития, за да научим и усъвършенстваме езиковия модел. Освен това, ние внедряваме процедура за последваща обработка, съобразена с типа, като използваме разпознаване на обекти (НЕР), за допълнително филтриране на прогнозите. JOELIN превъзхожда базовата стойност на BERT с 17,2% при микро F1.', 'hr': 'Konkurencija izvlačenja događaja COVID-19 iz Twitter je razvoj sustava koji mogu automatski izvući povezane događaje iz tweets. Izgradljeni sustav bi trebao identificirati različite preddefinirane mjesta za svaki događaj kako bi odgovorili na važna pitanja (npr. tko je pozitivan testiranje? Koliko je doba osobe? Gdje je on/ona?). Za rješavanje tih izazova predlažemo model učenja višezadataka zajedničkog događaja (JOELIN). Kroz ujedinjeni globalni okvir učenja, koristimo sve podatke o obuci u različitim događajima kako bi naučili i ispravili jezički model. Osim toga, provodimo postobrađivanje postupka svijesti tipa koristeći priznanje imena entiteta (NER) kako bi dalje filtrirali predviđanja. JOELIN iznosi početnu liniju BERT za 17,2% u mikro F1.', 'da': 'Konkurrencen om at udtrække COVID-19 begivenheder fra Twitter er at udvikle systemer, der automatisk kan udtrække relaterede begivenheder fra tweets. Det byggede system bør identificere forskellige foruddefinerede slots for hver begivenhed for at besvare vigtige spørgsmål (f.eks. Hvem er testet positivt, hvad er personens alder, hvor er vedkommende?). For at tackle disse udfordringer foreslår vi Joint Event Multi-Task Learning (JOELIN) modellen. Gennem en samlet global læringsramme gør vi brug af alle træningsdata på tværs af forskellige arrangementer til at lære og finjustere sprogmodellen. Desuden implementerer vi en typebevidst efterbehandlingsprocedure ved hjælp af navngivet entitetsgenkendelse (NER) til yderligere at filtrere forudsigelserne. JOELIN overgår BERT baseline med 17,2% i mikro F1.', 'nl': 'De competitie van het extraheren van COVID-19-gebeurtenissen van Twitter is om systemen te ontwikkelen die automatisch gerelateerde gebeurtenissen uit tweets kunnen extraheren. Het gebouwde systeem moet verschillende vooraf gedefinieerde slots voor elke gebeurtenis identificeren, om belangrijke vragen te beantwoorden (bijvoorbeeld wie is positief getest, wat is de leeftijd van de persoon, waar is hij/zij?). Om deze uitdagingen aan te pakken, stellen we het Joint Event Multi-task Learning (JOELIN) model voor. Via een uniform wereldwijd leerframework maken we gebruik van alle trainingsgegevens over verschillende evenementen om het taalmodel te leren en af te stemmen. Bovendien implementeren we een type-aware post-processing procedure met named entity recognition (NER) om de voorspellingen verder te filteren. JOELIN overtreft de BERT baseline met 17,2% in micro F1.', 'de': 'Der Wettbewerb, COVID-19-Ereignisse von Twitter zu extrahieren, besteht darin, Systeme zu entwickeln, die verwandte Ereignisse automatisch aus Tweets extrahieren können. Das eingebaute System sollte für jedes Ereignis verschiedene vordefinierte Slots identifizieren, um wichtige Fragen zu beantworten (z.B. Wer ist positiv getestet? Wie alt ist die Person? Wo ist sie?). Um diese Herausforderungen anzugehen, schlagen wir das Joint Event Multi-Task Learning (JOELIN) Modell vor. Durch ein einheitliches globales Lernframework nutzen wir alle Trainingsdaten über verschiedene Veranstaltungen hinweg, um das Sprachmodell zu lernen und zu verfeinern. Darüber hinaus implementieren wir ein typbewusstes Nachbearbeitungsverfahren mit Named Entity Recognition (NER), um die Vorhersagen weiter zu filtern. JOELIN übertrifft die BERT-Baseline um 17,2% in Micro F1.', 'id': 'Kompetisi mengekstrak acara COVID-19 dari Twitter adalah untuk mengembangkan sistem yang dapat mengekstrak secara otomatis acara yang berhubungan dengan tweet. Sistem yang dibangun seharusnya mengidentifikasi slot yang berbeda dari awal untuk setiap peristiwa, untuk menjawab pertanyaan penting (misalnya, Siapa yang diuji positif? Berapa usia orang? Dimana dia?). Untuk mengatasi tantangan-tantangan ini, kami mengusulkan model Pelajaran Multi-Tugas (JOELIN). Melalui cadangan belajar global yang bersatu, kita menggunakan semua data pelatihan melalui peristiwa yang berbeda untuk belajar dan memperbaiki model bahasa. Selain itu, kami menerapkan prosedur postproses yang menyadari jenis menggunakan pengenalan entitas bernama (NER) untuk menginfilter lebih lanjut prediksi. JOELIN melampaui batas dasar BERT dengan 17,2% dalam mikro F1.', 'ko': '트위터에서 코로나 사태를 추출하기 위한 경쟁은 트위터에서 관련 사건을 자동으로 추출할 수 있는 시스템을 개발하는 것이다.구축된 시스템은 모든 사건에 대해 서로 다른 미리 정의된 시간대를 정하여 중요한 질문에 대답해야 한다(예를 들어 누구의 검사 결과가 양성입니까? 이 사람의 나이는 얼마입니까? 그/그녀는 어디에 있습니까?).이러한 도전에 대응하기 위해 우리는 연합사건 멀티퀘스트 학습(JOELIN) 모델을 제시했다.통일된 글로벌 학습 구조를 통해 우리는 서로 다른 사건의 모든 훈련 데이터를 이용하여 언어 모델을 학습하고 조정한다.또한 명명된 엔티티 인식(NER)을 사용하여 예측을 추가로 필터링하기 위해 유형 인식 후처리 프로세스를 구현했습니다.조엘린은 마이크로F1에서 BERT 베이스라인보다 17.2% 높은 활약을 펼쳤다.', 'fa': 'رقابت از اخراج از رویدادهای COVID-19 از توئیتر این است که سیستم\u200cهای توسعه\u200cای که می\u200cتوانند رویدادهای ارتباطی را از توئیت به طور خودکار خارج کنند. سیستم ساخته باید محل\u200cهای پیش\u200cتعریف متفاوت را برای هر رویداد شناسایی کند تا جواب سوال مهم\u200cها را بدهد (مثال، کیست که مثبت آزمایش شده؟ سن آن شخص کجاست؟ او/او کجاست؟). برای حل این چالش\u200cها، ما مدل یادگیری (JOELIN) رویداد\u200cهای زیادی مشترک را پیشنهاد می\u200cکنیم. از طریق یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچ به علاوه، ما یک روش پردازش بعد از پردازش نوع آگاهی را با استفاده از شناسایی نامیده شده entity (NER) برای further filtering the predictions implement. جولین پایین برت را با 17.2% در میکروF1 برتر می کند.', 'af': "Die rekenaar van uitpakking van COVID-19 gebeurtenis van Twitter is om stelsels te ontwikkel wat automaties verwante gebeurtenis van tweets kan uitpak. Die gebou stelsel moet verskillende voorafgedefinieerde plekke vir elke gebeurtenis identifiseer om belangrike vrae te antwoord (bv. wie is positief toets? Wat is die ouderdom van die persoon? Waar is hy/sy?). Om hierdie uitdagings te probeer, voorstel ons die gemeenskap-gebeurtenis meerder-taak-leer model (JOELIN). Deur 'n eenvoudige globale leer raamwerk, maak ons gebruik van al die oefening data oor verskillende gebeurtenis om die taal model te leer en fin-tuneer. Ook, ons implementeer 'n tipe-bewus post-verwerking-prosedure gebruik genaamde entiteiterkenning (NER) om die voorskoue verder te filter. Joelin uitvoer die BERT baselyn deur 17.2% in mikro F1.", 'sw': 'Mashindano ya kutengeneza matukio ya COVID-19 kutoka Twita ni kuendeleza mifumo ambayo inaweza kutengeneza matukio yanayohusiana na moja kwa moja kutoka kwenye twita. Mfumo huo unapaswa kutambua matokeo tofauti yaliyoelezwa kabla ya kila tukio, ili kujibu maswali muhimu (mfano, nani anajaribiwa vizuri? Ni umri gani? yuko wapi?). Ili kukabiliana na changamoto hizi, tunapendekeza modeli ya Ufunzi wa Jumuiya (JOELIN). Kupitia mfumo wa kujifunza ulimwengu ulimwenguni, tunatumia taarifa zote za mafunzo katika matukio mbalimbali ili kujifunza na kutangaza vizuri kwa mtindo wa lugha. Zaidi ya hayo, tunatekeleza mchakato wa namna inayofahamika baada ya kuchukua hatua kwa kutumia utambulisho wa entity (NER) ili kuchuja zaidi utabiri huo. JOELIN outperforms the BERT baseline by 17.2% in micro F1.', 'sq': "Konkurrenca e nxjerrjes së ngjarjeve COVID-19 nga Twitter është për të zhvilluar sisteme që mund të nxjerrin automatikisht ngjarje të lidhura nga tweetet. Sistemi i ndërtuar duhet të identifikojë vende të ndryshme të paracaktuara për çdo ngjarje, me qëllim që të përgjigjet pyetjeve të rëndësishme (për shembull, Kush është testuar pozitiv? Cila është mosha e personit? Ku është ai?). Për t'i trajtuar këto sfida, ne propozojmë modelin e Mësimit të Përbashkët të Veprimtariave Multidetyrore (JOELIN). Nëpërmjet një kuadri të unifikuar mësimi global, ne përdorim të gjitha të dhënat e trajnimit nëpërmjet ngjarjeve të ndryshme për të mësuar dhe përshtatur modelin gjuhësor. Përveç kësaj, ne zbatojmë një procedurë pas përpunimit të vetëdijshëm të llojit duke përdorur njohjen e emëruar të njësisë (NER) për të filtruar më tej parashikimet. JOELIN kalon bazën e BERT me 17.2% në mikro F1.", 'tr': "COVID Binarlan첵an sistemada her sahypa 체챌in wajyp soraglary jogap bermek 체챌in be첵leki 철흫-belirlenen 첵erleri tanamaly bolmaly (mesel창, ki힊i흫 첵a힊y n채챌e? Ol/gyz nirede?). Bu kyn챌ylyklary 챌철zmek 체챌in, Birle힊en G철rn체힊 Birle힊en G철rn체힊 횜wrenmek (JOELIN) nusgasyny teklip ed첵채ris. Birle힊ik d체n첵채d채ki 철wrenme 챌er챌evesi bilen, dil nusgasyny 철wrenmek we d체zeltmek 체챌in 채hli okuw maglumatyny ulan첵arys. Mundan so흫ra, biz birn채챌e ta첵dan bellenen ta첵dan ge챌irmek 체챌in adlanan bir zat tana첵masyny ullan첵arys. JOELIN BERT baselini mikro F1'de 17.2% tarapyndan 체st체n ed첵채r.", 'am': 'ከትዊተር ካለው COVID-19 ሁኔታዎችን ለመውጣት ተቃውሞ ከTwitter የተገኘውን ጉዳዮች በራስነት ለማውጣት ሲስተካከል ነው፡፡ የተሠራው ሲስተም ለሁሉም ጉዳይ አስቀድሞ የተወሰነ ደረጃዎችን እንዲያረጋግጥ ያስፈልጋል፡፡ To tackle these challenges, we propose the Joint Event Multi-task Learning (JOELIN) model.  በዓለምአቀፍ ትምህርት ፍሬማር፣ የቋንቋውን ምሳሌ ለመማር እና ለመጠቀም በተለየ ሁኔታ የሚተማሩትን ዳራዎችን ሁሉ እናጠቃለን፡፡ ከዚህም በላይ ደግሞ የውይይት አካባቢ ማውቀትን (NER) ለመጠቀም የሚታወቅ የፖስታ ማቀናጃ ፕሮግራሙን እናደርጋለን፡፡ JOELIN BERT baseline በ17.2% በሚክሮው F1 ውስጥ ያቆያል።', 'hy': 'COVID-19 իրադարձությունները Թվիթերից դուրս բերելու մրցակցությունն այն է, որ ստեղծենք համակարգեր, որոնք ինքնաբերաբար կարող են դուրս բերել կապված իրադարձությունները թվիթերից: Կառուցված համակարգը պետք է բացահայտի յուրաքանչյուր իրադարձության համար տարբեր նախասահմանված վայրերը, որպեսզի պատասխանի կարևոր հարցերին (օրինակ, ո՞վ է դրական փորձում։ Որքա՞ն է մարդու տարիքը։ Որտե՞ղ է նա։) To tackle these challenges, we propose the Joint Event Multi-task Learning (JOELIN) model.  Միասնական համաշխարհային ուսուցման շրջանակի միջոցով մենք օգտագործում ենք բոլոր ուսուցման տվյալները տարբեր իրադարձությունների ընթացքում լեզվի մոդելի սովորելու և բարելավման համար: Ավելին, մենք կիրառում ենք տեսակի գիտակցական հետվերաշարժման գործընթացը, օգտագործելով անվանելի էության ճանաչելը (ՆԵՌ), որպեսզի շարունակենք ֆիլտրել կանխատեսումները: Ջոելինը 17.2 տոկոսով գերազանցում է BERT-ի հիմնական արտահայտությունը միկրո F1-ում:', 'bn': 'টুইটার থেকে কভিড-১৯ অনুষ্ঠান বের করার প্রতিযোগিতা হচ্ছে টুইট থেকে স্বয়ংক্রিয়ভাবে সম্পর্কিত ঘটনা উৎপাদন করতে পারে। এই নির্মাণ সিস্টেম প্রতিটি অনুষ্ঠানের জন্য বিভিন্ন ভিন্ন স্লোট চিহ্নিত করা উচিত, যাতে গুরুত্বপূর্ণ প্রশ্নের উত্তর দেয়ার জন্য (উদাহরণ এই চ্যালেঞ্জের মুখোমুখি হওয়ার জন্য আমরা যুক্ত ইউনেট ইভেন্ট মাল্টিক কাজ শিক্ষা মডেল প্রস্তাব করি। একটি একত্রিত বিশ্ব শিক্ষা ফ্রেমের মাধ্যমে আমরা ভিন্ন অনুষ্ঠানের বিভিন্ন অনুষ্ঠানের মধ্যে প্রশিক্ষণের তথ্য ব্যবহার করি ভ এছাড়াও, আমরা একটি ধরনের পরিচিত প্রক্রিয়া বাস্তবতার স্বীকৃতি ব্যবহার করে ভবিষ্যদ্বাণীকে আরো ফিল্টার করে ফিল্টার করি। JOELIN outperforms the BERT baseline by 17.2% in micro F1.', 'az': "COVID-19 vaxtlarını Twitter-dən çıxartmaq müqayisədədədir. Tövtlərdən bağlı vaxtları avtomatik olaraq çıxara biləcək sistemləri təmizləməkdir. İnşaat sistemi hər vaxt üçün mühüm suallara cavab vermək üçün müxtəlif əvvəlcə təyin edilmiş yeri təsdiqlənmək lazımdır (məsələn kimin pozitif sınaması lazımdır? İnsanın yaşı nədir? O/qadın haradadır?). Bu çətinliklərə çəkilmək üçün, birləşdirilmiş olaraq çoxlu işin öyrənməsi (JOELIN) modelini təklif edirik. Birlikte küresel öyrənmə qurğusu ilə, dil modelini öyrənmək və düzəltmək üçün hər təhsil məlumatlarını müxtəlif olaraq istifadə edirik. Daha sonra, tədbirləri daha çox filtrləmək üçün adı olan entitə tanıması (NER) vasitəsilə növ bilən post-processing prosedüsini istifadə edirik. JOELIN BERT səhifəsini mikro F1'də 17,2%-dən artırar.", 'ca': "La competició d'extrair els esdeveniments COVID-19 de Twitter és desenvolupar sistemes que poden extrair automàticament els esdeveniments relacionats dels tweets. El sistema construït hauria d'identificar diferents slots predefinits per cada esdeveniment, per respondre preguntes importants (per exemple, Qui està testat positiu? Quina és l'edat de la persona? On està?). Per abordar aquests reptes, proposem el model Joint Event Multi-Task Learning (JOELIN). A través d'un marc d'aprenentatge global unificat, utilitzem totes les dades d'entrenament en diferents esdeveniments per aprendre i millorar el model de llenguatge. Moreover, we implement a type-aware post-processing procedure using named entity recognition (NER) to further filter the predictions.  JOELIN supera la línia de referència del BERT un 17,2% en micro F1.", 'et': 'COVID-19 sündmuste väljavõtmise konkurents Twitterist on süsteemide väljatöötamine, mis suudavad automaatselt välja võtta seotud sündmusi säutsidest. Ehitatud süsteem peaks iga sündmuse jaoks kindlaks määrama erinevad eelnevalt kindlaks määratud teenindusajad, et vastata olulistele küsimustele (nt Kes on positiivne, milline on inimese vanus, kus ta on?). Nende probleemide lahendamiseks pakume välja ühisürituste mitmeülesandelise õppe mudeli (JOELIN). Ühtse ülemaailmse õpperaamistiku kaudu kasutame keelemudeli õppimiseks ja täpsustamiseks kõiki erinevate ürituste koolitusandmeid. Lisaks rakendame prognooside edasiseks filtreerimiseks tüübiteadlikku järeltöötlusprotseduuri, kasutades nimetatud olemi tunnustamist (NER). JOELIN ületab mikro F1 puhul BERT algtaseme 17,2%.', 'cs': 'Soutěží extrahování událostí COVID-19 z Twitteru je vyvinout systémy, které mohou automaticky extrahovat související události z tweetů. Sestavený systém by měl identifikovat různé předem definované sloty pro každou událost, aby mohl zodpovědět důležité otázky (např. Kdo je testován pozitivně, jaký je věk osoby, kde je?). Pro řešení těchto výzev navrhujeme model Joint Event Multi-Task Learning (JOELIN). Prostřednictvím jednotného globálního vzdělávacího rámce využíváme všechna data školení napříč různými událostmi k učení se a jemnému ladění jazykového modelu. Navíc implementujeme postprocesy typově orientovaného postprocesu s využitím rozpoznávání pojmenovaných entit (NER) k dalšímu filtrování predikcí. JOELIN překonává základní hodnotu BERT o 17,2% v mikro F1.', 'bs': 'Konkurencija izvlačenja COVID-19 događaja iz Twitter je razvoj sustava koji mogu automatski izvući povezane događaje iz tweeta. Izgradljeni sistem bi trebao identificirati različite predodređene mjesta za svaki događaj kako bi odgovorio na važna pitanja (npr. ko je pozitivna ispitivanja? Koliko je doba osobe? Gde je on/ona?). Da bi se riješili ovim izazovima, predlažemo model učenja multizadataka zajedničkog događaja (JOELIN). Kroz ujedinjeni globalni okvir učenja, koristimo sve podatke o obuci u različitim događajima da naučimo i ispravimo jezički model. Osim toga, mi provodimo postprocessijsku proceduru sa svijesti tipa koristeći priznanje entiteta (NER) kako bi dalje filtrirali predviđanja. JOELIN iznosi početnu liniju BERT za 17,2% u mikro F1.', 'fi': 'Kilpailu COVID-19-tapahtumien purkamisesta Twitteristä on kehittää järjestelmiä, jotka voivat automaattisesti poimia aiheeseen liittyviä tapahtumia twiitteistä. Rakennetun järjestelmän tulisi tunnistaa eri ennalta määritellyt paikat jokaiselle tapahtumalle, jotta voidaan vastata tärkeisiin kysymyksiin (esim. Kuka on positiivinen, mikä on henkilön ikä, missä hän on?). Näiden haasteiden ratkaisemiseksi ehdotamme Joint Event Multi-task Learning (JOELIN) -mallia. Yhtenäisen globaalin oppimiskehyksen avulla hyödynnämme kaikkia eri tapahtumien koulutustietoja kielimallin oppimiseen ja hienosäätöön. Lisäksi toteutamme tyyppitietoisen jälkikäsittelymenettelyn, jossa käytetään nimettyä entiteettitunnistusta (NER) ennustusten suodattamiseksi edelleen. JOELIN ylittää BERT-lähtötilanteen 17,2 prosentilla mikro-F1:ssä.', 'ha': 'Jigon ta fita na COV-19 masu husũma daga Twitter ne zuwa ta buɗe system waɗanda ke iya iya samun ayukan masu husũma farat ɗaya daga Twitter. Ana son tsarin da aka gina ya gane slottu-daban da aka bayyana wa kowace takarda, dõmin ya karɓa wa tambayar muhimma (misali, Wãne ne aka jarraba masu yarda? Ciryan shẽkar mutum? Yãya ne ke da shi?). To, in karɓi waɗannan tsummõmi, Munã buɗaɗe misalin Nayyar Nayyar Duk-Mai Hisãfi (JOELIN). Ina iya amfani da duk tsarin da aka sani a cikin shirin zaman shawara, ko kuma za mu yi amfani da duk masu amfani da data masu motsi a cikin kwãnukan nan dabam-daban, dõmin su sanar da kuma su sami-tune misalin harshe. Za kuma, za mu yi amfani da wata jarraba mai bayani-aiki na daban-aiki don mu yi amfani da sunan gane abun (NER) don mu filter a bayan misalin. JOELIN na samar da Baselin BERT da 17.2% cikin micro F1.', 'sk': 'Tekmovanje pri izvlečevanju dogodkov COVID-19 iz Twitterja je razvoj sistemov, ki lahko samodejno izvlečejo sorodne dogodke iz tweetov. Vgrajeni sistem mora identificirati različne vnaprej določene reže za vsak dogodek, da bi odgovorili na pomembna vprašanja (npr. Kdo je test pozitiven, kakšna je starost osebe, kje je?). Za reševanje teh izzivov predlagamo model Join Event Multi-Task Learning (JOELIN). Z enotnim globalnim učnim okvirom uporabljamo vse podatke o usposabljanju na različnih dogodkih za učenje in natančno nastavitev jezikovnega modela. Poleg tega izvajamo postopek po obdelavi, ki se zaveda tipa, z uporabo imenovanega prepoznavanja entitet (NER) za nadaljnje filtriranje napovedi. JOELIN presega izhodiščno vrednost BERT za 17,2% v mikro F1.', 'jv': 'Competisi kanggo ngilanggar eventune COMPID-19 nang Google kuwi nggawe sistem sing bisa nguasai perusahaan anyari nggawe eventune sing wis ana nang tuwit. Sistem sing nggawe kudu menehi pernik-pernik saiki wis dianggap sampeyan kanggo sabên evel, bisa supoyo barang langkung dianggap Mbok nggawe perbudhakan iki, kita supoyo nggawe modèl Joint events Multi-task Learning (jESLIN). Dhewe nganggo sistem sing beraksi lan ijol-ijolan surat, kéné nggawe ngubah data nggawe barang nggawe tarjamahan kanggo ngeremut lan ijol-ijolan model sing lenggugu. Laptop" and "Desktop KETOAN wis nambah tanggal nggo BERT kanggo 18.2% nang mikro F1.', 'he': "The competition of extracting COVID-19 events from Twitter is to develop systems that can automatically extract related events from tweets.  The built system should identify different pre-defined slots for each event, in order to answer important questions (e.g., Who is tested positive? What is the age of the person? Where is he/she?).  כדי להתמודד עם האתגרים האלה, אנו מציעים את מודל הלימוד של אירועים משותפים רבים (JOELIN). דרך מסגרת לימוד גלובלית מאוחדת, אנו משתמשים בכל נתוני האימונים באירועים שונים כדי ללמוד ולהתאים את דוגמן השפה. חוץ מזה, אנו מפעילים תהליך לאחר העבודה מודע לטיפוס בשימוש זיהוי ישות בשם (NER) כדי להסיר את החזויות. ג'ולין מעליפה את רמז הברט ב-17.2% במיקרו-F1.", 'bo': 'COVID-19 བྱ་འགུལ་ཕྱིར་འདོན་གྱི་གྲ་སྒྲིག་ནི་་ཌིས་ཌིར་ནས་འགྱུར་བའི་དུས་ཚོད་རང་འགུལ་གྱིས་མཐུན་གྱི་བྱ བཟོ་བཀོད་པའི་མ་ལག་གིས་བྱ་འགུལ་རེ་རེར་སྔོན་འཛིན་པའི་སྒོ་སྒྲིག་སྔོན་འཛིན་བྱས་མིན་འདུག གདོང་ལེན་དགོས་པ་འདི་དག་གི་གདོང་ལེན་དགོས་བྱེད་རྒྱུ་དང་། ང་ཚོས་མཐུན་གྱི་བྱ སྤྱི་ཚོགས་ལས་འཛམ་གླིང་གི་ཁྱད་པར་ཆས་གཞུང་ཅིག་གིས་ང་ཚོའི་ནང་དུ་གྲངས་སྒྲིག འོན་ཀྱང་། ང་ཚོས་དབང་རྩལ་ཤེས་པའི་རྗེས་སུ་འབྲེལ་བ་ཞིག་གིས་མིང་དང་རྗེས་སུ་འབྲེལ་བ་ཞིག JOELIN micro F1 ནང་གི་BERT གཞི་རྟེན་ནས་17.2% ཕྱིར་ཐུབ་པ།'}
{'en': 'HLTRI at W-NUT 2020 Shared Task-3 : COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling HLTRI  at  W - NUT  2020 Shared Task-3:  COVID -19 Event Extraction from  T witter Using Multi-Task Hopfield Pooling', 'ar': 'HLTRI في W-NUT 2020 Shared Task-3: استخراج حدث COVID-19 من Twitter باستخدام تجميع Hopfield متعدد المهام', 'pt': 'HLTRI no W-NUT 2020 Shared Task-3: extração de eventos COVID-19 do Twitter usando o pool de Hopfield multitarefa', 'fr': "HLTRI au W-NUT 2020 Shared Task-3\xa0: Extraction d'événements COVID-19 à partir de Twitter à l'aide de la mutualisation multitâche Hopfield", 'es': 'HLTRI en la Tarea Compartida 3 de W-NUT 2020: Extracción de eventos de COVID-19 de Twitter mediante la agrupación de Hopfield de múltiples tareas', 'ja': 'W - NUT 2020のHLTRI共有タスク-3 ：マルチタスクホップフィールドプーリングを使用したTwitterからのCOVID -19イベント抽出', 'hi': 'W-NUT 2020 में HLTRI साझा कार्य -3: बहु-कार्य हॉपफील्ड पूलिंग का उपयोग करके ट्विटर से कोविड -19 इवेंट निष्कर्षण', 'ru': 'HLTRI на W-NUT 2020 Shared Task-3: Извлечение событий COVID-19 из Twitter с использованием многозадачного объединения Hopfield', 'zh': 'HLTRI于W-NUT 2020共事-3:用多任务Hopfield Pooling取COVID-19于Twitter', 'ga': 'HLTRI ag W-NUT 2020 Tasc Comhroinnte-3: Eastóscadh Imeachta COVID-19 ó Twitter Ag Úsáid Comhthiomsú Ilthasc Hopfield', 'hu': 'HLTRI a W-NUT 2020 megosztott feladat-3-án: COVID-19 esemény kivonása a Twitterről Multi-Task Hopfield pooling használatával', 'ka': 'HLTRI W-NUT 2020 გაყოფილი დავალება-3: COVID', 'el': 'Κοινή εργασία-3: Εκχύλισμα συμβάντος από το Twitter χρησιμοποιώντας την ομαδοποίηση Hopfield πολλαπλών εργασιών', 'it': 'HLTRI a W-NUT 2020 Shared Task-3: Estrazione di eventi COVID-19 da Twitter utilizzando il pool di Hopfield multi-task', 'kk': 'HLTRI W-NUT 2020 Ортақ тапсырма-3: COVID-19 оқиға Твиттерден тарқату', 'lt': 'HLTRI W-NUT 2020 bendra užduotis 3: COVID-19 renginių ekstrahavimas iš Twitter naudojant daugiafunkcinį Hopfield susivienijimą', 'mk': 'ХЛТРИ на W-NUT 2020 заедничката задача-3: COVID-19 извлекување на настани од Твитер користејќи мултизадачен фондфилд', 'mt': 'HLTRI at W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'ms': 'HLTRI pada W-NUT 2020 Tugas Berkongsi-3: COVID-19 Ekstraksi Peristiwa dari Twitter Menggunakan Kumpulan Hopfield Bertugas-Berbagai', 'ml': 'W NUT 2020 ല്\u200d പങ്കാളിയുള്ള ജോലി- 3: ടൂട്ടറില്\u200d നിന്നും കോവിഡ്- 19 സംഭവം പുറത്താക്കുക', 'mn': 'HLTRI at W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'no': 'HLTRI på W-NUT 2020 delt oppgåve-3: COVID-19 hendingar utpakking frå Twitter Bruk fleire oppgåve Hopfield Pooling', 'pl': 'HLTRI na W-NUT 2020 Shared Task-3: Ekstrakcja zdarzeń COVID-19 z Twittera przy użyciu wielozadaniowego Hopfield Poolingu', 'si': 'HLTRI at W-NuT 2020shared Job-3: COVID-19 Item Extraction from Twitter Using Multi-Job Hopfield Pooling', 'ro': 'HLTRI la sarcina partajată W-NUT 2020-3: Extragerea evenimentelor COVID-19 de pe Twitter folosind combinarea mai multor sarcini Hopfield', 'sr': 'HLTRI na W-NUT 2020 zajedničkom zadatku-3: COVID-19 izvlačenje događaja iz Twittera Koristenje multi-Task Hopfield Pooling', 'so': 'HLTRI at W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter using Multi-Task Hopfield Pooling', 'sv': 'HLTRI på W-NUT 2020 delad uppgift-3: COVID-19-händelseutvinning från Twitter med hjälp av Hopfield pooling för flera aktiviteter', 'ta': 'W NUT 2020 ல் HLTRI பங்கிடப்பட்ட பணி- 3: COVID- 19 நிகழ்வு பிரித்தல் தொடர்பிலிருந்து பல பணி ஹாப்பில் போலிங் பயன்படுத்துகிறது', 'ur': 'HLTRI W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter using Multi-Task Hopfield Pooling', 'uz': 'W NUT 2020 yilda boʻlishilgan vazifa- 3: OVID- 19 hodisa Twitterdan Multi- Vazifa Hopfield yordamida foydalanish', 'vi': 'Name=Kate ProjectmanagerComment', 'hr': 'HLTRI na W-NUT 2020. zajedničkom zadatku-3: COVID-19 izvlačenje događaja iz Twitter Koristeći skupljanje multi-Task Hopfield', 'bg': 'Споделена задача-3: Извличане на събития от Туитър чрез обединяване на множество задачи на хопфийлд', 'da': 'HLTRI på W-NUT 2020 delt opgave-3: Udtrækning af COVID-19-begivenhed fra Twitter ved hjælp af flere opgaver Hopfield Pooling', 'de': 'HLTRI auf der W-NUT 2020 Shared Task-3: COVID-19 Event Extraction von Twitter mithilfe von Multi-Task Hopfield Pooling', 'id': 'HLTRI di W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'nl': 'HLTRI op W-NUT 2020 Gedeelde Taak-3: Covid-19 Event Extractie van Twitter met behulp van Multi-Task Hopfield Pooling', 'ko': 'HLTRI, W-NUT 2020에서 퀘스트 공유 3: 멀티퀘스트 Hopfield 풀을 사용하여 트위터에서 코로나 사건 추출', 'fa': 'HLTRI در W-NUT 2020 Task Shared-3: COVID-19 Extraction Event from Twitter Using Multi-Task Hopfield Pooling', 'sw': 'HLTRI kwenye mtandao wa W-NUT 2020 ilishiriki kazi-3: Tukio la COVID-19 Kutengwa kwa Mtandao wa Twita kwa kutumia Hopfield Multi-Task', 'af': 'HLTRI by W-NUT 2020 Gedeelde Opdrag-3: COVID-19 Event Extraction van Twitter Gebruik Multi-Task Hopfield Pooling', 'sq': 'HLTRI në W-NUT 2020 Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'hy': 'ՀLTRI-ը W-NOT 2020-ի ընդհանուր հանձնարարության 3. COVID-19 իրադարձությունների հեռացումը Թվիթերից՝ օգտագործելով բազմահանձնարար հոփֆիլդի համախմբումը', 'az': 'HLTRI at W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'tr': 'HLTRI at W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'bn': 'ওয়াই-এনউট ২০২০-এ শেয়ার করা কাজ-৩: টুইটার থেকে কোভিড-১৯ অনুষ্ঠান ব্যবহার করা হয়েছে।', 'am': 'በ.አ.አ 2020 የተሰራጨው ስራ-3: COVID-19 የኢንተርኔት ውጤት ከትዊተር በMulti-Task Hopfield Pooling', 'ca': 'HLTRI a W-NUT 2020 Task Shared-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling', 'cs': 'HLTRI na W-NUT 2020 Sdílený úkol-3: Extrakce událostí COVID-19 z Twitteru pomocí multi-úkolového Hopfield sdílení', 'et': 'HLTRI W-NUT 2020 jagatud ülesanne-3: COVID-19 sündmuste väljavõtmine Twitterist, kasutades mitme ülesandega hüppeväljade koondamist', 'fi': 'HLTRI W-NUT 2020:n jaetussa tehtävässä 3: COVID-19-tapahtumapoiminta Twitteristä Multi-Task Hopfield Poolingin avulla', 'bs': 'HLTRI na W-NUT 2020 zajedničkom zadatku-3: COVID-19 izvlačenje događaja iz Twitter Korištenje multi-Task Hopfield Pooling', 'jv': 'HLTRI at W-NUT 2020 shared task-3: COMVD-19 events extract from Google Using Multi-task Hofld pool', 'sk': 'HLTRI na skupni nalogi 3 W-NUT 2020: Izvleček dogodka COVID-19 iz Twitterja z uporabo večopravilnega združevanja Hopfield', 'ha': 'KCharselect unicode block name', 'he': 'HLTRI ב-W-NUT 2020 משימה משותפת-3: COVID-19 Extraction Events from Twitter Using Multi-Task Hopfield Pooling', 'bo': 'HLTRI at W-NUT 2020 Shared Task-3: COVID-19 Event Extraction from Twitter Using Multi-Task Hopfield Pooling'}
{'en': 'Extracting structured knowledge involving self-reported events related to the COVID-19 pandemic from  Twitter  has the potential to inform surveillance systems that play a critical role in  public health . The event extraction challenge presented by the W-NUT 2020 Shared Task 3 focused on the identification of five types of events relevant to the COVID-19 pandemic and their respective set of pre-defined slots encoding demographic, epidemiological, clinical as well as spatial, temporal or subjective knowledge. Our participation in the challenge led to the design of a neural architecture for jointly identifying all Event Slots expressed in a tweet relevant to an event of interest. This  architecture  uses COVID-Twitter-BERT as the pre-trained language model. In addition, to learn text span embeddings for each Event Slot, we relied on a special case of  Hopfield Networks , namely Hopfield pooling. The results of the shared task evaluation indicate that our system performs best when it is trained on a larger dataset, while  it  remains competitive when training on smaller datasets.', 'ar': 'إن استخراج المعرفة المنظمة التي تتضمن الأحداث المبلغ عنها ذاتيًا والمتعلقة بوباء COVID-19 من تويتر لديه القدرة على إبلاغ أنظمة المراقبة التي تلعب دورًا حاسمًا في الصحة العامة. ركز تحدي استخراج الحدث الذي قدمته المهمة المشتركة 3 W-NUT 2020 على تحديد خمسة أنواع من الأحداث ذات الصلة بجائحة COVID-19 ومجموعة الخانات المحددة مسبقًا الخاصة بها والتي تشفر البيانات الديموغرافية والوبائية والسريرية والمكانية ، المعرفة الزمنية أو الذاتية. أدت مشاركتنا في التحدي إلى تصميم بنية عصبية للتعريف المشترك لجميع فتحات الأحداث المعبر عنها في تغريدة ذات صلة بحدث مثير للاهتمام. تستخدم هذه البنية COVID-Twitter-BERT كنموذج لغة مُدرَّب مسبقًا. بالإضافة إلى ذلك ، لتعلم تضمين النص الممتد لكل فتحة حدث ، اعتمدنا على حالة خاصة من شبكات Hopfield ، وهي تجميع Hopfield. تشير نتائج تقييم المهام المشتركة إلى أن نظامنا يعمل بشكل أفضل عندما يتم تدريبه على مجموعة بيانات أكبر ، بينما يظل قادرًا على المنافسة عند التدريب على مجموعات بيانات أصغر.', 'pt': 'A extração de conhecimento estruturado envolvendo eventos autorrelatados relacionados à pandemia de COVID-19 do Twitter tem o potencial de informar sistemas de vigilância que desempenham um papel crítico na saúde pública. O desafio de extração de eventos apresentado pela Tarefa Compartilhada 3 do W-NUT 2020 focou na identificação de cinco tipos de eventos relevantes para a pandemia de COVID-19 e seu respectivo conjunto de slots predefinidos que codificam dados demográficos, epidemiológicos, clínicos e espaciais, conhecimento temporal ou subjetivo. Nossa participação no desafio levou ao desenho de uma arquitetura neural para identificar conjuntamente todos os Event Slots expressos em um tweet relevante para um evento de interesse. Essa arquitetura usa o COVID-Twitter-BERT como modelo de linguagem pré-treinado. Além disso, para aprender os embeddings de span de texto para cada slot de evento, contamos com um caso especial de Hopfield Networks, chamado Hopfield pooling. Os resultados da avaliação de tarefas compartilhadas indicam que nosso sistema tem melhor desempenho quando treinado em um conjunto de dados maior, enquanto permanece competitivo ao treinar em conjuntos de dados menores.', 'fr': "L'extraction de connaissances structurées impliquant des événements auto-déclarés liés à la pandémie de COVID-19 à partir de Twitter a le potentiel d'informer les systèmes de surveillance qui jouent un rôle essentiel en matière de santé publique. Le défi d'extraction d'événements présenté par la tâche partagée 3 W-NUT 2020 était axé sur l'identification de cinq types d'événements pertinents pour la pandémie de COVID-19 et leur ensemble respectif de créneaux prédéfinis codant des connaissances démographiques, épidémiologiques, cliniques ainsi que spatiales, temporelles ou subjectives. Notre participation au défi a conduit à la conception d'une architecture neuronale permettant d'identifier conjointement tous les créneaux d'événement exprimés dans un tweet pertinent pour un événement d'intérêt. Cette architecture utilise COVID-Twitter-Bert comme modèle de langage pré-formé. De plus, pour apprendre les intégrations de plages de texte pour chaque emplacement d'événement, nous nous sommes appuyés sur un cas particulier de Hopfield Networks, à savoir le regroupement Hopfield. Les résultats de l'évaluation des tâches partagées indiquent que notre système fonctionne mieux lorsqu'il est entraîné sur un ensemble de données plus volumineux, alors qu'il reste compétitif lorsqu'il s'entraîne sur des ensembles de données plus petits.", 'es': 'La extracción de conocimientos estructurados sobre eventos autoinformados relacionados con la pandemia de COVID-19 de Twitter tiene el potencial de informar a los sistemas de vigilancia que desempeñan un papel fundamental en la salud pública. El desafío de extracción de eventos presentado por la Tarea Compartida 3 de W-NUT 2020 se centró en la identificación de cinco tipos de eventos relevantes para la pandemia de COVID-19 y su respectivo conjunto de espacios predefinidos que codifican el conocimiento demográfico, epidemiológico, clínico, espacial, temporal o subjetivo. Nuestra participación en el desafío llevó al diseño de una arquitectura neuronal para identificar conjuntamente todos los espacios para eventos expresados en un tuit relevante para un evento de interés. Esta arquitectura utiliza COVID-Twitter-Bert como modelo de lenguaje previamente entrenado. Además, para aprender las incrustaciones de texto para cada espacio de evento, nos basamos en un caso especial de Hopfield Networks, a saber, Hopfield pooling. Los resultados de la evaluación de tareas compartidas indican que nuestro sistema funciona mejor cuando se entrena en un conjunto de datos más grande, mientras que sigue siendo competitivo cuando se entrena en conjuntos de datos más pequeños.', 'ja': '新型コロナウイルスのパンデミック（世界的大流行）に関連する自己報告イベントに関わる構造化された知識をTwitterから抽出することは、公衆衛生に重要な役割を果たす監視システムに情報を提供する可能性があります。 W - NUT 2020共有タスク3によって提示されたイベント抽出チャレンジは、COVID -19パンデミックに関連する5種類のイベントと、人口統計学的、疫学的、臨床的、ならびに空間的、時間的、または主観的知識をコードするそれぞれの事前定義されたスロットセットの特定に焦点を当てた。 この課題への参加は、関心のあるイベントに関連するツイートで表明されたすべてのイベントスロットを共同で識別するためのニューラルアーキテクチャの設計につながりました。 このアーキテクチャは、事前にトレーニングされた言語モデルとしてCOVID - Twitter - BERTを使用しています。 さらに、各イベントスロットのテキストスパン埋め込みを学ぶために、ホップフィールドネットワークの特別なケース、すなわちホップフィールドプーリングに依存しました。 共有タスク評価の結果は、当社のシステムがより大きなデータセットで訓練されている場合には最高のパフォーマンスを発揮することを示していますが、より小さなデータセットで訓練されている場合には競争力が維持されます。', 'zh': '取 Twitter 及自告者,与 COVID-19 大行相关结构化知,或发关键作用于公共卫生者监测系统。 W-NUT 2020年共事3举事提挑战侧重于识与COVID-19大行相关者五事,及其定义插槽,时间段编码口计流行病学,临床及空间,时主知识。 与挑战,设一神经架构,以共识感兴之事。 此体系结构用 COVID-Twitter-BERT 为预训之语。 又学每事槽文本跨度嵌,依Hopfield Networks一例,即Hopfield池也。 共享之果表明,统于大数集上练之为上,而小数集上之为竞争力。', 'ru': 'Извлечение структурированных знаний о событиях, связанных с пандемией COVID-19, из Twitter может информировать системы эпиднадзора, которые играют решающую роль в общественном здравоохранении. Задача извлечения события, представленная совместной задачей 3 W-NUT 2020, была сосредоточена на выявлении пяти типов событий, имеющих отношение к пандемии COVID-19, и их соответствующего набора предопределенных слотов, кодирующих демографические, эпидемиологические, клинические, а также пространственные, временные или субъективные знания. Наше участие в конкурсе привело к разработке нейронной архитектуры для совместной идентификации всех слотов события, выраженных в твите, относящемся к интересующему событию. Эта архитектура использует COVID-Twitter-BERT в качестве предварительно обученной языковой модели. Кроме того, для изучения текстовых вложений для каждого слота события, мы полагались на особый случай Hopfield Networks, а именно объединение Hopfield. Результаты совместной оценки задач показывают, что наша система работает лучше всего, когда она обучена на более крупном наборе данных, в то время как она остается конкурентоспособной при обучении на меньших наборах данных.', 'hi': 'ट्विटर से कोविड-19 महामारी से संबंधित स्व-रिपोर्ट की गई घटनाओं से जुड़े संरचित ज्ञान को निकालने से निगरानी प्रणालियों को सूचित करने की क्षमता है जो सार्वजनिक स्वास्थ्य में महत्वपूर्ण भूमिका निभाते हैं। डब्ल्यू-एनयूटी 2020 साझा कार्य 3 द्वारा प्रस्तुत घटना निष्कर्षण चुनौती ने कोविड -19 महामारी से संबंधित पांच प्रकार की घटनाओं की पहचान और जनसांख्यिकीय, महामारी विज्ञान, नैदानिक के साथ-साथ स्थानिक, अस्थायी या व्यक्तिपरक ज्ञान को एन्कोडिंग करने वाले पूर्व-परिभाषित स्लॉट के उनके संबंधित सेट पर ध्यान केंद्रित किया। चुनौती में हमारी भागीदारी ने संयुक्त रूप से ब्याज की एक घटना के लिए प्रासंगिक ट्वीट में व्यक्त किए गए सभी इवेंट स्लॉट की पहचान करने के लिए एक तंत्रिका वास्तुकला के डिजाइन का नेतृत्व किया। यह आर्किटेक्चर कोविड-ट्विटर-बर्ट को पूर्व-प्रशिक्षित भाषा मॉडल के रूप में उपयोग करता है। इसके अलावा, प्रत्येक इवेंट स्लॉट के लिए टेक्स्ट स्पैन एम्बेडिंग सीखने के लिए, हमने हॉपफील्ड नेटवर्क के एक विशेष मामले पर भरोसा किया, अर्थात् हॉपफील्ड पूलिंग। साझा कार्य मूल्यांकन के परिणाम इंगित करते हैं कि हमारा सिस्टम सबसे अच्छा प्रदर्शन करता है जब इसे बड़े डेटासेट पर प्रशिक्षित किया जाता है, जबकि यह छोटे डेटासेट पर प्रशिक्षण देते समय प्रतिस्पर्धी रहता है।', 'ga': 'D’fhéadfaí eolas struchtúrtha a bhaineann le himeachtaí féintuairiscithe a bhaineann leis an bpaindéim COVID-19 a bhaint ó Twitter chun córais faireachais a bhfuil ról ríthábhachtach acu i sláinte an phobail a chur ar an eolas. Dhírigh an dúshlán astarraingthe imeachta a chuir Tasc Comhroinnte W-NUT 2020 3 i láthair ar chúig chineál imeachtaí a shainaithint a bhaineann leis an bpaindéim COVID-19 agus a sraith sliotán réamhshainithe faoi seach lena n-ionchódaítear déimeagrafach, eipidéimeolaíoch, cliniciúil agus spásúil, eolas ama nó suibiachtúil. Mar thoradh ar ár rannpháirtíocht sa dúshlán dearadh ailtireacht néarúil chun gach Sliotán Imeachta a léiríodh i dtvuít a bhaineann le himeacht spéise a shainaithint i gcomhpháirt. Úsáideann an ailtireacht seo COVID-Twitter-BERT mar mhúnla teanga réamh-oilte. Ina theannta sin, chun leabaithe réise téacs a fhoghlaim do gach Sliotán Imeachta, bhíomar ag brath ar chás speisialta de Líonraí Hopfield, eadhon comhthiomsú Hopfield. Léiríonn torthaí na meastóireachta tascanna comhroinnte go bhfeidhmíonn ár gcóras ar an mbealach is fearr nuair a dhéantar é a oiliúint ar thacar sonraí níos mó, agus go bhfuil sé iomaíoch i gcónaí agus é ag traenáil ar thacair sonraí níos lú.', 'el': 'Η εξαγωγή δομημένης γνώσης που περιλαμβάνει αυτοαναφερθέντα συμβάντα που σχετίζονται με την πανδημία από το Twitter έχει τη δυνατότητα να ενημερώσει τα συστήματα επιτήρησης που διαδραματίζουν κρίσιμο ρόλο στη δημόσια υγεία. Η πρόκληση εξαγωγής συμβάντων που παρουσιάστηκε από την Κοινή Εργασία 3 επικεντρώθηκε στον προσδιορισμό πέντε τύπων συμβάντων σχετικών με την πανδημία και το αντίστοιχο σύνολο προκαθορισμένων χρονοθυρίδων που κωδικοποιούν δημογραφική, επιδημιολογική, κλινική καθώς και χωρική, χρονική ή υποκειμενική γνώση. Η συμμετοχή μας στην πρόκληση οδήγησε στο σχεδιασμό μιας νευρωνικής αρχιτεκτονικής για τον κοινό προσδιορισμό όλων των κουλοχέρηδων εκδήλωσης που εκφράζονται σε ένα tweet σχετικό με ένα γεγονός ενδιαφέροντος. Αυτή η αρχιτεκτονική χρησιμοποιεί το COVID-Twitter-BERT ως προσχεδιασμένο γλωσσικό μοντέλο. Επιπλέον, για να μάθουμε ενσωματώσεις κειμένου για κάθε υποδοχή συμβάντος, βασιστήκαμε σε μια ειδική περίπτωση των δικτύων Χόπφιλντ, δηλαδή τη συγκέντρωση Χόπφιλντ. Τα αποτελέσματα της αξιολόγησης κοινής εργασίας δείχνουν ότι το σύστημά μας αποδίδει καλύτερα όταν εκπαιδεύεται σε ένα μεγαλύτερο σύνολο δεδομένων, ενώ παραμένει ανταγωνιστικό όταν εκπαιδεύεται σε μικρότερα σύνολα δεδομένων.', 'it': "Estrarre da Twitter conoscenze strutturate che coinvolgono eventi auto-segnalati relativi alla pandemia COVID-19 ha il potenziale di informare i sistemi di sorveglianza che svolgono un ruolo fondamentale nella salute pubblica. La sfida di estrazione degli eventi presentata dal W-NUT 2020 Shared Task 3 si è concentrata sull'identificazione di cinque tipi di eventi rilevanti per la pandemia COVID-19 e il loro rispettivo set di slot predefiniti che codifica conoscenze demografiche, epidemiologiche, cliniche e spaziali, temporali o soggettive. La nostra partecipazione alla sfida ha portato alla progettazione di un'architettura neurale per identificare congiuntamente tutte le Event Slot espresse in un tweet relativo ad un evento di interesse. Questa architettura utilizza COVID-Twitter-BERT come modello linguistico pre-addestrato. Inoltre, per imparare le incorporazioni di span di testo per ogni slot evento, ci siamo affidati a un caso speciale di Hopfield Networks, vale a dire Hopfield pooling. I risultati della valutazione delle attività condivise indicano che il nostro sistema funziona meglio quando viene addestrato su un set di dati più grande, mentre rimane competitivo quando si allena su set di dati più piccoli.", 'ka': 'სტრუქტურული მეცნიერების გამოყენება, რომელიც სახელსაწყობოლო სისტემაში კრიტიკური პოლუმეცია იყოს, რომელიც სახელსაწყობოლო სისტემაში იყოს COVID-19 პანდემიკის შესახებ. W-NUT 2020 გაყოფილი სამსახური დავალების გამოსახულებული მოვლენების გამოსახულება, რომელსაც COVID-19 პონდემიკაში მნიშვნელოვანი ხუთი ტიპის მოვლენების გამოსახულება და მათი მნიშვნელოვანი წინ განსახულებული მოვლენების გამოსახულება დემოდრაფიკაში, ეპიდემილოგიურ ჩვენი გავაკეთება განსაზღვრებში, რომელიც ნეიროლური აქტიქტიქტურის განსაზღვრება დაიწყება ყველა მოვლენების სლოტის განსაზღვრებისთვის, რომელიც ინტერესტის მოვლენისთვის შესახე ამ აქტიქტიქტურაში COVID-Twitter-BERT გამოყენება, როგორც წინ შესწავლა ენის მოდელი. დამატებით, ყველა მოვლენის სლოტისთვის ტექსტური სპენტის შესახებ ვისწავლოთ, ჩვენ განვითარებულია Hopfield ქსელების სპეციალური შემთხვევაზე, ანუ Hopfield-ის შესახებ ჩვენი სისტემა ყველაზე დიდი მონაცემების შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამი', 'hu': 'A COVID-19 járványhoz kapcsolódó önjelentett eseményekkel kapcsolatos strukturált ismeretek Twitterről történő kivonása lehetőséget ad arra, hogy tájékoztassa a közegészségügyben kritikus szerepet játszó felügyeleti rendszereket. A W-NUT 2020 Shared Task 3 által bemutatott eseménykivonási kihívás a COVID-19 járvány szempontjából releváns öt típusú események azonosítására összpontosított, előre meghatározott, demográfiai, epidemiológiai, klinikai, valamint térbeli, időbeli vagy szubjektív ismereteket kódoló résekre. A kihívásban való részvételünk egy neurális architektúra kialakításához vezetett, amelynek segítségével közösen azonosítható az összes esemény nyerőgép, amelyet egy érdekes eseményre vonatkozó tweetben kifejeztünk. Ez az architektúra a COVID-Twitter-BERT-et használja előre képzett nyelvi modellként. Ezenkívül, hogy megtanuljuk az egyes Event Slot szövegtartomány beágyazását, a Hopfield Networks speciális esetére támaszkodtunk, nevezetesen a Hopfield pooling-ra. A megosztott feladatértékelés eredményei azt mutatják, hogy rendszerünk akkor teljesít a legjobban, ha nagyobb adatkészletre készül, miközben versenyképes marad kisebb adatkészletekre készül.', 'mk': 'Extracting structured knowledge involving self-reported events related to the COVID-19 pandemic from Twitter has the potential to inform surveillance systems that play a critical role in public health.  Предизвикот за екстракција на настаните презентиран од W-NUT 2020 Shared Task 3 се фокусираше на идентификацијата на пет типови настани релевантни за пандемијата COVID-19 и нивниот соодветен сет преддефинирани вредности кодирајќи демографско, епидемиолошко, клиничко, како и просторско, температурно или суб Нашето учество во предизвикот доведе до дизајнирање на нервна архитектура за заедничко идентификување на сите слотови на настаните изразени на Твитер релевантни за настан од интерес. Оваа архитектура користи COVID-Twitter-BERT како предобучен јазик модел. Покрај тоа, за да се научи вклопување на текстови за секој салот на настани, се потпиравме на специјален случај на Хопфилд мрежи, а тоа на Хопфилд. The results of the shared task evaluation indicate that our system performs best when it is trained on a larger dataset, while it remains competitive when training on smaller datasets.', 'kk': 'Твиттерден COVID-19 пандемиясына қатысты құрылған білімдерді тарқату мүмкіндігі бар, көпшілік саулықтардың маңызды рөлін орындайтын қарау жүйелерін білім беру мүмкіндігі бар. W-NUT 2020 Ортақ тапсырмасы 3-нің ортақ тапсырмасының тапсырмасы COVID-19 пандемиясының бес түрлерін анықтауға және олардың алдын- ала анықталған слоттарының кодтамасын демографиялық, эпидемиологиялық, клиникалық және жергілікті, уақытша немесе мағы Барлық оқиға слоттарын бірге таңдау үшін бірге қатысу мәселелеріміздің неврал архитектурасының құрылымына көмектеседі. Бұл архитектура COVID- Twitter- BERT тіл үлгісі болып қолданылады. Қосымша, әрбір оқиға слоты үшін мәтін сәйкестігін үйрену үшін, біз Hopfield желілерінің арнайы жағдайына сендік, мысалы Hopfield сәйкестігін біріктіру үшін. Ортақ тапсырмаларды бағалау нәтижесі, жүйеміздің ұлғашқы деректер жинақтарында оқылған кезде ең жақсы жұмыс істейді, бірақ ол кіші деректер жинақтарында оқылған кезде бұл', 'lt': 'Struktūrinių žinių, susijusių su COVID-19 pandemija, išėmimas iš Twitter gali informuoti priežiūros sistemas, kurios atlieka itin svarbų vaidmenį visuomenės sveikatos srityje. W-NUT 2020 m. bendroje 3 užduotyje pateiktame renginių gavimo uždavinyje daugiausia dėmesio buvo skiriama penkių rūšių įvykių, susijusių su COVID-19 pandemija, nustatymui ir jų atitinkamam iš anksto apibrėžtų laiko tarpsnių rinkiniui, koduojančiam demografines, epidemiologines, klinikines, taip pat erdvines, laikinas ar subjektyvias žinias. Mūsų dalyvavimas iššūkyje paskatino kurti neurologinę architektūrą, kad būtų bendrai nustatyti visi įvykių laiko tarpsniai, išreikšti su suinteresuotu įvykiu susijusiame tweete. Ši architektūra naudoja COVID-Twitter-BERT kaip išankstinio mokymo kalbų model į. Be to, norint išsiaiškinti kiekvieno renginių laiko tarpsnio teksto apimtį, mes pasikliovėme ypatingu Hopfield tinklų atveju, būtent Hopfield bendravimu. Bendro užduočių vertinimo rezultatai rodo, kad mūsų sistema geriausiai veikia, kai ji mokoma didesniame duomenų rinkinyje, o mokymas mažesniuose duomenų rinkiniuose išlieka konkurencingas.', 'mn': 'Твиттерээс COVID-19 пандемиктэй холбогдсон бүтээгдэхүүний мэдлэг гаргах нь нийтийн эрүүл мэндийн чухал үүрэг тоглож буй ажиллах системүүдийг мэдэх боломжтой. W-NUT 2020 хуваалтын 3 даалгаварын таван төрлийн үйл явдал COVID-19 пандемикийн тухай хамааралтай таван төрлийн үйл явдлын тодорхойлолт, тэдний аль хэдийн тодорхойлогдсон слотуудыг демографик, эпидемиологик, эпидемиологик, эмнэлгийн, зай, хугацааны, сэтгэл зүйн мэдлэг Бидний сорилтын оролцоо нь мэдрэлийн архитектурын бүх үйл явдлыг хамтран тодорхойлох боломжтой, сонирхолтой үйл явдлыг тодорхойлдог бүх үйл явдлыг тодорхойлдог. Энэ архитектур COVID-Twitter-BERT-г өмнө сургалтын хэл загвар болгон ашигладаг. Үүний дараа бид Хопфилд шилжүүлэлтийн тухай тодорхой тохиолдолд суралцахын тулд Хопфилд шилжүүлэлтийн нэг тохиолдолд хамтрагдсан. Олон даалгаварын оюун шалгалтын үр дүнд бидний систем том өгөгдлийн санд суралцах үед хамгийн сайн ажилладаг гэдгийг харуулж байна. Бага өгөгдлийн санд суралцах үед өрсөлдөг.', 'ms': 'Mengekstrak pengetahuan struktur yang melibatkan peristiwa yang dilaporkan diri berkaitan dengan pandemi COVID-19 dari Twitter mempunyai potensi untuk memberitahu sistem pengawasan yang bermain peran kritik dalam kesehatan awam. Tandakan ekstraksi peristiwa yang dihadapkan oleh Task 3 Berkongsi W-NUT 2020 berfokus pada pengenalan lima jenis peristiwa yang berkaitan dengan pandemi COVID-19 dan set slot tersebut yang terdefinisikan untuk mengekodkan pengetahuan demografik, epidemiologi, klinik serta ruang, sementara atau subjektif. Pesertaan kami dalam cabaran membawa kepada rancangan arkitektur saraf untuk mengidentifikasi bersama-sama semua Slot Peristiwa yang diungkapkan dalam tweet yang berkaitan dengan peristiwa yang menarik. Arkitektur ini menggunakan COVID-Twitter-BERT sebagai model bahasa terlatih. Selain itu, untuk belajar pelengkapan jangkauan teks untuk setiap Slot Peristiwa, kami bergantung pada kes khas Rangkaian Hopfield, iaitu kumpulan Hopfield. Hasil penilaian tugas berkongsi menunjukkan bahawa sistem kita berfungsi terbaik apabila ia dilatih pada set data yang lebih besar, sementara ia tetap bersaing apabila melatih pada set data yang lebih kecil.', 'mt': 'L-estrazzjoni ta’ għarfien strutturat li jinvolvi avvenimenti rrappurtati minnu nnifsu relatati mal-pandemija COVID-19 minn Twitter għandha l-potenzjal li tinforma lis-sistemi ta’ sorveljanza li għandhom rwol kritiku fis-saħħa pubblika. L-isfida tal-estrazzjoni tal-avvenimenti ppreżentata mill-Kompitu Konġunt 3 W-NUT 2020 iffokat fuq l-identifikazzjoni ta’ ħames tipi ta’ avvenimenti rilevanti għall-pandemija COVID-19 u s-sett rispettiv tagħhom ta’ slots definiti minn qabel li jikkodifikaw l-għarfien demografiku, epidemjoloġiku, kliniku kif ukoll spazjali, temporali jew suġġettiv. Il-parteċipazzjoni tagħna fl-isfida wasslet għad-disinn ta’ arkitettura newrali għall-identifikazzjoni konġunta tas-Slots kollha tal-Avvenimenti espressi f’tweet rilevanti għal avveniment ta’ interess. Din l-arkitettura tuża COVID-Twitter-BERT bħala mudell lingwistiku mħarreġ minn qabel. Barra minn hekk, biex nitgħallmu l-inkorporazzjonijiet tal-firxa tat-test għal kull Slot tal-Avvenimenti, a ħna ngħixu fuq każ speċjali ta’ Hopfield Networks, jiġifieri l-pooling ta’ Hopfield. Ir-riżultati tal-evalwazzjoni tal-kompiti kondiviżi jindikaw li s-sistema tagħna tagħmel l-a ħjar meta tkun imħarrġa fuq sett ta’ dejta akbar, filwaqt li tibqa’ kompetittiva meta taħriġ fuq settijiet ta’ dejta iżgħar.', 'ml': 'സ്വയം റിപ്പോര്\u200dട്ട് ചെയ്യുന്ന സംഭവങ്ങളുടെ കൂട്ടത്തില്\u200d സ്വയം സംബന്ധിച്ചുള്ള സംഭവങ്ങള്\u200d പുറത്തേക്ക് വരുത്തുന്ന അറിവുകള്\u200d പുറത്തുവരു W-NUT 2020 പങ്കാളിയുള്ള ടാസ്ക് 3-ല്\u200d നിന്നുള്ള സംഭവ്യത്തിന്റെ പുറത്തെടുക്കുന്ന സങ്കേതം, കോവിഡി-19 പാനഡീമിക്ക് ബന്ധപ്പെട്ട അഞ്ചു തരം സംഭവ്യങ്ങളുടെ തിരിച്ചറിയാന്\u200d ശ്രമിക്കുന നമ്മുടെ പങ്കാളിയില്\u200d പങ്കെടുക്കുന്നത് താല്\u200dപര്യമുള്ള ഒരു സംഭവത്തിന്റെ കൂട്ടത്തില്\u200d ഒരു പുതുരുവിന്റെ ആര്\u200dക്കിട്ടറിന്റെ ഡിസൈ ഈ ആര്\u200dക്കിച്ചിക്കറ്റ് കോവിഡി-ട്രൂട്ടര്\u200d-ബെര്\u200dട്ടിയെ മുന്\u200dപരിശീലന ഭാഷ മോഡലായി ഉപയോഗിക്കുന്നു. കൂടാതെ, എല്ലാ സ്റ്റോട്ടിനും വേണ്ടി പഠിപ്പിക്കുന്ന പദാവലികള്\u200d പഠിപ്പിക്കാന്\u200d, ഹോപ്ഫീല്\u200dഡ് നെറ്റ്വര്\u200dക്കുകളുടെ പ്രത് പങ്കുചേര്\u200dന്ന ജോലി വിലാസങ്ങളുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നു, വലിയ ഡാറ്റാസറ്റില്\u200d പഠിപ്പിക്കുമ്പോള്\u200d നമ്മുടെ സിസ്റ്റം ഏറ്റവും നല്', 'pl': 'Wydobycie z Twittera zorganizowanej wiedzy dotyczącej samodzielnie zgłaszanych zdarzeń związanych z pandemią COVID-19 ma potencjał informowania o systemach nadzoru, które odgrywają kluczową rolę w zdrowiu publicznym. Wyzwanie ekstrakcji zdarzeń przedstawione w ramach Wspólnego Zadania W-NUT 2020 2020 koncentrowało się na identyfikacji pięciu rodzajów zdarzeń istotnych dla pandemii COVID-19 i ich odpowiedniego zestawu wcześniej zdefiniowanych slotów kodujących wiedzę demograficzną, epidemiologiczną, kliniczną oraz przestrzenną, czasową lub subiektywną. Nasz udział w wyzwaniu doprowadził do zaprojektowania architektury neuronowej umożliwiającej wspólną identyfikację wszystkich Slots Event wyrażonych w tweecie istotnym dla zainteresowanego wydarzenia. Architektura ta wykorzystuje COVID-Twitter-BERT jako wstępnie przeszkolony model językowy. Ponadto, aby nauczyć się osadzeń rozpiętości tekstowej dla każdego gniazda zdarzeń, opieraliśmy się na specjalnym przypadku sieci Hopfield, a mianowicie Hopfield pooling. Wyniki wspólnej oceny zadań wskazują, że nasz system działa najlepiej, gdy jest trenowany na większym zbiorze danych, podczas gdy pozostaje konkurencyjny podczas szkolenia na mniejszych zbiorach danych.', 'ro': 'Extragerea de pe Twitter a cunoștințelor structurate care implică evenimente auto-raportate legate de pandemia COVID-19 are potențialul de a informa sistemele de supraveghere care joacă un rol esențial în sănătatea publică. Provocarea de extragere a evenimentelor prezentată de sarcina partajată W-NUT 2020 3 s-a axat pe identificarea a cinci tipuri de evenimente relevante pentru pandemia COVID-19 și setul lor respectiv de sloturi predefinite care codează cunoștințe demografice, epidemiologice, clinice și spațiale, temporale sau subiective. Participarea noastră la provocare a condus la proiectarea unei arhitecturi neurale pentru identificarea în comun a tuturor Sloturilor Evenimente exprimate într-un tweet relevant pentru un eveniment de interes. Această arhitectură utilizează COVID-Twitter-BERT ca model lingvistic pre-instruit. În plus, pentru a învăța încorporările textului pentru fiecare slot de eveniment, ne-am bazat pe un caz special de Hopfield Networks, și anume pooling Hopfield. Rezultatele evaluării sarcinilor comune indică faptul că sistemul nostru performează cel mai bine atunci când este instruit pe un set de date mai mare, în timp ce rămâne competitiv atunci când se instruiește pe seturi de date mai mici.', 'si': 'ස්වයංග්\u200dරහණය සඳහා ස්වයංග්\u200dරහණ දැනගන්න ස්වයංග්\u200dරහණය සම්බන්ධ විදිහට සම්බන්ධ විදිහට තියෙන්නේ ට්\u200dවිටර් වලින් COVID- The action extraction challenge presents by the W-NuT 2020shared Job 3 focus on the ID of five types of dogs that are appropriate to the COVID-19 Pandmimic and to them adhive set of pre-definition slots code demograph, epidemeology, climatic as well as spatic, tempral or subSubjective Knowing. අපේ අභ්\u200dයාගයක් වෙනුවෙන් ප්\u200dරවේශනය කරලා නිර්මාණ විද්\u200dයාපයක් සාමාන්\u200dය විද්\u200dයාපනය කරලා සියළු සැම අවස්ථාවක් ස්ලෝ මේ ස්ථාපනය COVID-Twitter-BERT විශ්වාස කරන්න පුරුද්ගලික භාෂා මොඩේල් විදියට. ඒ වගේම, හැම අවස්ථාවක් ස්ලෝට්ට් වෙනුවෙන් පාළිස්ථානයක් ඉගෙන ගන්න, අපි හොප්ෆිල්ඩ් නෙට්වැක්ස් වල විශේ සමාගත වැඩක් විශ්ලේෂණයේ ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන් අපේ පද්ධතිය හොඳම වැඩක් කරනවා කියලා, ඒක විශාල දත්ත සැට', 'so': 'Ogaansho dhismayd oo ku saabsan dhacdooyinka iskuu soo sheegay ee la xidhiidha cudurada COVID-19 ee Twitterka waxaa suurtogal ah in la ogeysiiyo nidaamka ilaalinashada ee ku qayb muhiim ah caafimaadka dadweynaha. Dhaqaalaha soo saarashada ee ay u soo bandhigtay W-NUT 2020 Shaqada 3, waxay focus on aqoonsashada shan nooc oo dhacdooyin la xiriira COVID-19 cudurada iyo koox loo qoray horay loo yaqaan qofka ku qoran maamulka, cudurada, dhakhtarka iyo dhaqaalaha, waqtiga ama waxyaabaha ku saabsan. qeybqaadashada dhibaatada waxaa loo keenay sawirka dhismaha neurada ee la wada aqoonsaday dhacdooyinka oo dhan, kaas oo ku saabsan Tweet ku saabsan dhacdooyinka danaha. Arkturkaas wuxuu COVID-Twitter-BERT ugu isticmaalaa model afka hore oo la tababaray. Intaas waxaa dheer in aan barno text span embeddings for Event Slot, waxaynu ku kalsoonaynay xaalada gaarka ah ee Hopfield Network, kaas oo ah Hopfield pooling. Fashihiisa qiimeynta shaqada ee la qaybsan waxay tustaa in nidaamkayagu uu si wanaagsan u sameynayo marka lagu tababariyo kooxda macluumaadka ka weyn, iyadoo ay ku tarjaynaysaa marka lagu tababaro koobashada macluumaadka yar.', 'sv': 'Att utvinna strukturerad kunskap om självrapporterade händelser relaterade till COVID-19-pandemin från Twitter har potential att informera övervakningssystem som spelar en avgörande roll för folkhälsan. Utmaningen för händelseutvinning som presenterades av W-NUT 2020 Shared Task 3 fokuserade på identifiering av fem typer av händelser som är relevanta för COVID-19-pandemin och deras respektive uppsättning fördefinierade slots som kodar demografisk, epidemiologisk, klinisk samt rumslig, tidsmässig eller subjektiv kunskap. Vårt deltagande i utmaningen ledde till utformningen av en neural arkitektur för att gemensamt identifiera alla Event Slots uttryckta i en tweet relevant för en händelse av intresse. Denna arkitektur använder COVID-Twitter-BERT som den förberedda språkmodellen. Dessutom, för att lära oss textspan inbäddningar för varje Event Slot, förlitade vi oss på ett speciellt fall av Hopfield Networks, nämligen Hopfield pooling. Resultaten av den delade uppgiftsutvärderingen indikerar att vårt system presterar bäst när det utbildas på en större datamängd, samtidigt som det förblir konkurrenskraftigt när det utbildas på mindre datamängder.', 'no': 'Ekstra strukturerte kunnskap som involverer selvrapporterte hendingar relaterte til COVID-19 pandemikk frå Twitter har den potensialen til å informere overvåkingssystemer som speler ein kritisk rolle i offentlige helse. Dette utfordringen for hendingar som er utvikla av W-NUT 2020 Delt oppgåve 3 fokusert på identifiseringa av fem typar hendingar som er relevante til COVID-19 pandemikk og deres tilhøyrande sett av føredefinerte plass-koding demografisk, epidemiologisk, klinisk og spasielle, temporale eller subjektiv kunnskap. Partisjonen vårt i utfordringen førte til utforminga av ein neuralarkitektur for å kopla identifisera alle hendingslot uttrykket i ein tweet som er relevant til ein hending med interesse. Denne arkitekturen brukar COVID-Twitter-BERT som den først trengte språk-modellen. I tillegg, for å lære innbygging av tekstspanser for kvar hendingslot, har vi relied på eit spesielt tilfelle på Hopfield- nettverk, dvs. Hopfield- pooling. Resultatet av den delte oppgåvevurderinga tyder på at systemet vår utfører best når det vert trent på ein større dataset, mens det fortsatt konkurente når opplæring på mindre dataset.', 'sr': 'Izvukanje strukturiranih znanja uključujući samopojavljene događaje povezane sa pandemijom COVID-19 iz Twitter ima potencijal da obavijesti sisteme nadzora koji imaju kritičnu ulogu u javnom zdravlju. Izazov izvlačenja događaja koji je predstavio zajednički zadatak 3 W-NUT 2020 fokusiran je na identifikaciju pet vrsta događaja koje su relevantne za pandemiju COVID-19 i njihov odgovarajući set preddefiniranih slota kodiranja demografskih, epidemioloških, kliničkih i prostornih, temporalnih ili subjektivnih znanja. Naše učešće u izazovu dovelo je do dizajna neuralne arhitekture za zajedničku identifikaciju svih događaja Slota izraženih u tweetu relevantnom za događaj interesa. Ova arhitektura koristi COVID-Twitter-BERT kao predobučeni jezički model. Osim toga, da bismo naučili tekstualne integracije za svaki događajni slot, oslanjali smo se na poseban slučaj Hopfield mreža, a to je Hopfield skupljanje. Rezultati zajedničke procjene zadataka ukazuju na to da naš sistem izvodi najbolje kada se obuči na većem setu podataka, dok ostaje konkurentna kada se obuka na manjim setima podataka.', 'ta': 'COVID-19 துன்பத்திலிருந்து COVID-19 தொடர்பு செய்த நிகழ்வுகளை வெளியேற்றும் அறிவு தெரியும் உருவாக்கப்பட்டுள்ளது தொடர்ந்து கொண்டிருக் W-NUT 2020 பகிர்ந்த பணி 3 மூலம் கூட்டப்பட்ட நிகழ்வு வெளியேற்றம் சவாலானது, COVID-19 துன்பத்துடன் தொடர்புடைய ஐந்து வகையான நிகழ்வுகள் கண்டுபிடிப்பது மீது கவனம் செலுத்தப்பட்டது மற்றும் அவர்கள் முன் எங்கள் சவாலானத்தில் பகிர்ந்து ஒரு புதிய நிறுவனம் உருவாக்கத்தை ஒன்றாக குறிப்பிடும் அனைத்து நிகழ்வுகளையும் தெரியும் ஒரு வட்டி செய இந்த உருவாக்கி COVID- Twitter- BERT முன் பயிற்சி மொழி மாதிரியாக பயன்படுத்துகிறது. மேலும், ஒவ்வொரு நிகழ்வு செருகுவாய்க்கான உரை ஸ்பென் உள்ளிடுகளை கற்றுக்கொள்வதற்கு, நாங்கள் ஹாப்பில் பிணையத்தின் சிறப்பு ப பகிர்ந்த பணியின் முடிவு', 'ur': 'ٹویٹر سے COVID-19 pandemic کے باعث ساختہ علم کے ذریعہ اپنے آپ کو راپورٹ کیا گیا تھا، اس کے ذریعہ سے سازمان علم کو اخراج کرنے کے لئے قابل ہے کہ نظارت نظام کو بتائے جو عمومی سلامتی میں ایک نقطہ رول ہے۔ W-NUT 2020 Shared Task 3 کے ذریعے پیش کیا گیا ہے کہ COVID-19 pandemic کے ساتھ مطابق پانچ طرح اتفاقات کا پہچان کرنا اور ان کے مطابق مقرر کردہ اسلوٹوں کا سیٹ دموگرافیک, اپیڈمیلوژیک، کلینیکی اور فضائی, temporal or subjective knowledge کے ساتھ موجود ہوتا ہے. ہمارا حصہ چلنے میں ایک نئورل معماری طراحی کی بنائی ہوئی تھی کہ تمام اتفاق اسلوٹ کو مشتبہ پہچان لینے کے لئے ایک ٹویٹ میں واضح کیا گیا ہے جس کا علاقه ہے۔ یہ معماری COVID-Twitter-BERT کو پہلے تدریس کی زبان مدل کے طور پر استعمال کرتا ہے. اور اس کے علاوہ، ہر ایڈینٹ اسلوٹ کے لئے متن اسپینڈینگ سکھانے کے لئے، ہم نے Hopfield Networks کے ایک خاص کیس پر اعتماد کیا، یعنی Hopfield pooling. مشترک ٹاکس کی ارزیابی کا نتیجہ دکھاتا ہے کہ ہماری سیستم بہترین عمل کرتا ہے جب اس کو بڑے ڈاکس سٹ پر آموزش دی جاتی ہے، حالانکہ وہ چھوٹے ڈاکس سٹ پر آموزش کرتی ہے جب تکلیف کرتی ہے تو مسابقات رہتا ہے.', 'uz': "Twitterdan COVID-19 murakkablik bilan bog'liq narsalar bilan o'zgartirish qo'llanilgan ta'limni ajratish imkoniyatlariga ega bo'ladi. Bu shaxsiy sohalarda muhim roli oʻynaladigan tizimni taʼminlovchi tizimlarni ko'rsatish mumkin. W-NUT 2020 Buyruq Vazifani 3 bilan ajratilgan dastur, COVID-19 pandemik bilan bog'liq 5 turli narsalarni aniqlashga qarang va uning qiziqarli qo'llari demografi, epidemiologik, klinik va spatial, vaqt yoki maʼlumot bilan ajratilgan 5 turli narsalarni aniqlash uchun foydalanadi. Bizning qiziqarishga murakkab qilishimiz, hamma hodisa qo'llangan xabarlarni birlashtirish uchun neyrol arxituvni yaratishga sabab beradi. This architecture uses COVID-Twitter-BERT as the pre-trained language model.  Koʻrsatilgan har bir hodisa vositasi uchun matn span chegaralarini o'rganish uchun, Hopfield Tarmoqning maxsus holatiga ishonchingiz mumkin. Boʻlishilgan vazifa qiymati natijalari, katta maʼlumotlar sohasida tizimmizni bajarayotganda yaxshi bajarishi mumkin, ammo u kichkina maʼlumotlar sohasida taʼminlovchi soʻzda ishlaydi.", 'vi': 'Việc khai thác kiến thức cơ bản liên quan đến các sự kiện do bản báo cáo bởi đại dịch COVID-19 từ Twitter có tiềm năng sẽ cung cấp thông tin cho hệ thống giám sát có vai trò quan trọng trong sức khỏe cộng đồng. Trận đấu giải cứu sự kiện được đưa ra bởi tập đoàn đa dạng W-ngu-2020 đã tập trung vào việc xác định năm loại sự kiện liên quan tới đại dịch COVID-19 và cùng một số các dải thời gian được xác định trước gồm kiến thức sinh học, ví dụ, lâm sàng, cũng như kiến thức về không gian, thời gian hay chủ quan. Sự tham gia của chúng ta vào thử thách đã dẫn đến thiết kế kiến trúc thần kinh để cùng nhau xác định các kích thước của sự kiện diễn ra bằng tweet liên quan đến sự quan. Kiến trúc này dùng COVID-Twitter-BERT làm mô hình ngôn ngữ được huấn luyện. Thêm vào đó, để tìm hiểu khả năng cấy ghép thời gian văn bản cho mỗi tần số sự kiện, chúng tôi đã dựa vào một trường hợp đặc biệt của mạng Hopfield, cụ thể là Hopfield pool. Kết quả của cuộc đánh giá chia sẻ cho thấy hệ thống này hoàn thiện tốt nhất khi được huấn luyện trên một bộ dữ liệu lớn hơn, trong khi nó vẫn còn cạnh tranh khi tập luyện trên các bộ dữ liệu nhỏ hơn.', 'hr': 'Izvlačenje strukturiranih znanja uključujući samopojavljene događaje povezane s pandemijom COVID-19 iz Twitter-a ima mogućnost obavijestiti sustave nadzora koji imaju kritičnu ulogu u javnom zdravlju. Izazov izvlačenja događaja koji je predstavio zajednički zadatak 3 W-NUT 2020 usredotočen je na identifikaciju pet vrsta događaja relevantnih za pandemiju COVID-19 i njihovu odgovarajuću skupu predodređenih mjesta kodiranja demografskih, epidemioloških, kliničkih i prostornih, temporalnih ili subjektivnih znanja. Naše učešće u izazovu dovelo je do dizajna neuralne arhitekture za zajedničku identifikaciju svih događaja Slota izraženih u tweetu relevantnom za događaj interesa. Ova arhitektura koristi COVID-Twitter-BERT kao predobučeni jezički model. Osim toga, kako bismo naučili ugrađenje teksta za svaki događajni slot, oslanjali smo se na poseban slučaj Hopfield mreža, a to je Hopfield skupljanje. Rezultati zajedničke procjene zadataka ukazuju na to da naš sustav najbolje provodi kada se obučava na većem setu podataka, dok ostaje konkurentna kada se obučava na manjim setima podataka.', 'da': 'At udtrække struktureret viden om selvrapporterede hændelser relateret til COVID-19-pandemien fra Twitter har potentiale til at informere overvågningssystemer, der spiller en afgørende rolle i folkesundheden. Den udfordring, der blev præsenteret af W-NUT 2020 Shared Task 3, fokuserede på identifikation af fem typer hændelser, der er relevante for COVID-19 pandemien, og deres respektive sæt af foruddefinerede slots, der koder demografisk, epidemiologisk, klinisk såvel som rumlig, tidsmæssig eller subjektiv viden. Vores deltagelse i udfordringen førte til designet af en neural arkitektur til fælles identifikation af alle Event Slots udtrykt i en tweet relevant for en begivenhed af interesse. Denne arkitektur bruger COVID-Twitter-BERT som den forududdannede sprogmodel. Desuden, for at lære tekstspænde indlejringer for hver Event Slot, stolede vi på et særligt tilfælde af Hopfield Networks, nemlig Hopfield pooling. Resultaterne af den fælles opgavevaluering indikerer, at vores system fungerer bedst, når det trænes på et større datasæt, mens det forbliver konkurrencedygtigt, når det trænes på mindre datasæt.', 'nl': 'Het extraheren van gestructureerde kennis met zelf gerapporteerde gebeurtenissen in verband met de COVID-19 pandemie van Twitter heeft het potentieel om surveillancesystemen te informeren die een cruciale rol spelen in de volksgezondheid. De uitdaging om gebeurtenissen te extraheren die door de W-NUT 2020 Shared Task 3 werd gepresenteerd, richtte zich op de identificatie van vijf soorten gebeurtenissen die relevant zijn voor de COVID-19-pandemie en hun respectieve set van vooraf gedefinieerde slots die demografische, epidemiologische, klinische en ruimtelijke, temporele of subjectieve kennis coderen. Onze deelname aan de uitdaging leidde tot het ontwerp van een neurale architectuur voor het gezamenlijk identificeren van alle Event Slots uitgedrukt in een tweet relevant voor een evenement van interesse. Deze architectuur maakt gebruik van COVID-Twitter-BERT als het vooraf getrainde taalmodel. Om tekstspan embeddings voor elke Event Slot te leren, gebruikten we bovendien een speciaal geval van Hopfield Networks, namelijk Hopfield pooling. De resultaten van de gedeelde taakverandering geven aan dat ons systeem het beste presteert wanneer het getraind wordt op een grotere dataset, terwijl het concurrerend blijft bij training op kleinere datasets.', 'id': 'Mengekstraksi pengetahuan struktur yang melibatkan peristiwa yang dilaporkan sendiri yang berhubungan dengan pandemia COVID-19 dari Twitter memiliki potensi untuk memberitahu sistem pengawasan yang bermain peran kritis dalam kesehatan publik. Tantangan ekstraksi peristiwa yang ditunjukkan oleh W-NUT 2020 Shared Task 3 fokus pada identifikasi lima jenis peristiwa yang relevan untuk pandemia COVID-19 dan setan mereka persendirian dari slots yang terdefinisikan mendefinisikan pengetahuan demografis, epidemiologi, klinik, dan ruang, waktu atau subjektif. Partesipasi kami dalam tantangan membawa ke desain arsitektur saraf untuk bersama-sama mengidentifikasi semua Slot Peristiwa yang diungkapkan dalam tweet yang relevan untuk peristiwa yang menarik. Arkitektur ini menggunakan COVID-Twitter-BERT sebagai model bahasa yang terlatih. Selain itu, untuk mempelajari penempatan teks untuk setiap Slot Peristiwa, kami bergantung pada kasus khusus Hopfield Networks, yaitu Hopfield pooling. Hasil dari evaluasi tugas berbagi menunjukkan bahwa sistem kita berfungsi terbaik ketika dilatih pada set data yang lebih besar, sementara tetap kompetitif ketika melatih pada set data yang lebih kecil.', 'de': 'Die Extraktion von strukturiertem Wissen über selbst berichtete Ereignisse im Zusammenhang mit der COVID-19-Pandemie aus Twitter hat das Potenzial, Überwachungssysteme zu informieren, die eine entscheidende Rolle in der öffentlichen Gesundheit spielen. Die im Rahmen der W-NUT 2020 Shared Task 3 vorgestellte Herausforderung zur Ereignisextraktion konzentrierte sich auf die Identifizierung von fünf Arten von Ereignissen, die für die COVID-19-Pandemie relevant sind, und deren jeweilige Reihe von vordefinierten Zeitfenstern, die demografisches, epidemiologisches, klinisches sowie räumliches, zeitliches oder subjektives Wissen kodieren. Unsere Teilnahme an der Challenge führte zum Entwurf einer neuronalen Architektur zur gemeinsamen Identifizierung aller Event Slots, die in einem Tweet für ein Ereignis von Interesse ausgedrückt werden. Diese Architektur nutzt COVID-Twitter-BERT als vortrainiertes Sprachmodell. Darüber hinaus haben wir uns auf einen speziellen Fall von Hopfield Networks verlassen, nämlich Hopfield Pooling. Die Ergebnisse der gemeinsamen Aufgabenbewertung zeigen, dass unser System am besten funktioniert, wenn es auf einem größeren Datensatz trainiert wird, während es beim Training auf kleineren Datensätzen wettbewerbsfähig bleibt.', 'bg': 'Извличането от Туитър на структурирани знания, включващи самодокладвани събития, свързани с пандемията има потенциал да информира системите за наблюдение, които играят критична роля в общественото здраве. Предизвикателството за извличане на събития, представено от споделената задача 3, се фокусира върху идентифицирането на пет вида събития, свързани с пандемията и съответния им набор от предварително определени слотове, кодиращи демографски, епидемиологични, клинични, пространствени, времеви или субективни знания. Участието ни в предизвикателството доведе до проектирането на невронна архитектура за съвместно идентифициране на всички слотове за събития, изразени в туит, свързан с събитие, което представлява интерес. Тази архитектура използва като предварително обучен езиков модел. Освен това, за да научим вгражданията на текстови диапазони за всеки слот за събитие, разчитахме на специален случай на Хопфийлд Мрежи, а именно Хопфийлд пулинг. Резултатите от оценката на споделените задачи показват, че нашата система се представя най-добре, когато се обучава на по-голям набор от данни, докато остава конкурентна при обучение на по-малки набори от данни.', 'sw': 'Kutengeneza maarifa yaliyotengenezwa na matukio yanayohusiana na ugonjwa wa COVID-19 kutoka Twita in a uwezekano wa kutoa taarifa za mfumo wa ufuatiliaji ambao unacheza nafasi muhimu katika afya ya umma. The event extraction challenge presented by the W-NUT 2020 Shared Task 3 focused on the identification of five types of events relevant to the COVID-19 pandemic and their respective set of pre-defined slots encoding demographic, epidemiological, clinical as well as spatial, temporal or subjective knowledge.  Ushiriki wetu wa changamoto ulipelekea ubunifu wa ujenzi wa kisasa kwa ajili ya kutambua Marekani zote zilizoonyesha katika twita inayohusiana na tukio la maslahi. Ujengo huu unatumia COVID-Twita-BERT kama mfano wa lugha iliyoendeshwa kabla. Zaidi ya hayo, ili kujifunza maeneo ya ujumbe wa maandishi kwa kila kituo cha Event Slot, tulitegemea kesi maalum ya Mtandao wa Hopfield, namely poongezeko la Hopfield. Matokeo ya tathmini za kazi zilizoshirikishwa yanaonyesha kuwa mfumo wetu unafanya vizuri zaidi pale unapofundishwa kwenye seti kubwa ya takwimu, wakati huo unabaki kuwa na ushindani wakati mafunzo ya takwimu ndogo.', 'ko': '트위터에서 코로나19 팬데믹과 관련한 자체 보고 사건에 대한 구조화된 지식을 얻으면 공중보건에서 중요한 역할을 하는 모니터링 시스템에 정보를 제공할 가능성이 있다.W-NUT 2020 공유임무3이 제시한 사건 추출 도전은 코로나 팬데믹과 관련된 다섯 가지 유형의 사건을 식별하고 각각의 미리 정의된 시간 간격, 인구통계학, 역학, 임상 및 공간, 시간 또는 주관적인 지식을 코딩하는 데 중심을 두었다.우리는 이 도전에 참여하여 흥미로운 사건과 관련된 추문에서 표현된 모든 사건을 연합하여 식별하는 신경 구조를 설계했다.이 구조는 코로나바이러스를 사전 훈련의 언어 모델로 사용한다.그 밖에 모든 이벤트 슬롯의 텍스트 경계를 파악하기 위해, 우리는 Hopfield 네트워크의 특수한 상황인 Hopfield 풀에 의존한다.공유 임무 평가 결과에 따르면 우리 시스템은 비교적 큰 데이터 집합에서 훈련할 때 가장 좋은 모습을 보였고 비교적 작은 데이터 집합에서 훈련할 때 여전히 경쟁력을 가진다.', 'tr': "COVID W Biziň kynçylyklarymyz kynçylykda näural arhitektura baglanşygymyz bilen gyzyklanýan bolup tweet bilen gepleşýän ähli wajyplary tanamak üçin guruldy. Bu arhitektura COVID-Twitter-BERT öňünden eğlenen dil nusgasyna ulanýar. Ayrıca, her Event Slot için metin alanı öğrenmek için, Hopfield Networks'in özel durumu, yani Hopfield toplantısına güveniyoruz. Şahsy zadyň deňlenmesiniň netijesi sistemamyzyň uly bir datasetde okuw edilýän wagtynda has gowy gazanýandygyny görkezýär, we ol kiçi datasetlerde okuw edilýän wagtynda ýaryşykly bolýar.", 'sq': 'Ekstraktimi i njohurive të strukturuara që përfshijnë ngjarje vetë-raportuara lidhur me pandemikën COVID-19 nga Twitter ka potencialin për të informuar sistemet e mbikqyrjes që luajnë një rol kritik në shëndetin publik. The event extraction challenge presented by the W-NUT 2020 Shared Task 3 focused on the identification of five types of events relevant to the COVID-19 pandemic and their respective set of pre-defined slots encoding demographic, epidemiological, clinical as well as spatial, temporal or subjective knowledge.  Pjesëmarrja jonë në sfidë çoi në dizajnin e një arkitekture nervore për të identifikuar së bashku të gjitha Slotët e Eventeve të shprehura në një tweet lidhur me një ngjarje interesante. Kjo arkitekturë përdor COVID-Twitter-BERT si modelin e gjuhës së paratrajnuar. Përveç kësaj, për të mësuar përmbajtje teksti për çdo Slot Event, ne mbështeteshim në një rast të veçantë Hopfield Networks, në të vërtetë Hopfield pooling. Rezultatet e vlerësimit të detyrës së përbashkët tregojnë se sistemi ynë funksionon më mirë kur është trajnuar në një grup të dhënash më të madhe, ndërsa mbetet konkurrues kur trajnohet në grupe të dhënash më të vogla.', 'af': "In die uitpakking van struktureerde kennis wat self-verkondiging gebeurtenis betrokke aan die COVID-19 pandemie van Twitter is, het die potensiele om naderstelsels te kenne wat 'n kritiese rol in openbare gesondheid speel. Die gebeurtenis uittrekking uitdrukking wat deur die W-NUT 2020 Gedeelde Opdrag 3 voorsien is, het gefokus op die identifikasie van vyf tipes gebeurtenis wat betrokke aan die COVID-19 pandemiek en hulle respektief stel van vooraf-gedefinieerde slots kodering demografiese, epidemiologiese, kliniese en spasiele, tydelike of subjektiewe kennis. Ons deelnadering in die uitdrukking het gelei na die ontwerp van 'n neurale arkitektuur vir saamstig identifiseer van alle gebeurtenis Slots uitgevoer in 'n tweet wat betrokke is a an 'n gebeurtenis van belang. Hierdie arkitektuur gebruik COVID-Twitter-BERT as die voorafgeleerde taal model. In addition, to learn text span embeddings for each Event Slot, we relied on a special case of Hopfield Networks, namely Hopfield pooling. Die resultate van die gedeelde taak evaluering aandui dat ons stelsel beter uitvoer wanneer dit op 'n groter datastel onderrig is, terwyl dit bly mededingvuldig wanneer onderrig op kleiner datastel.", 'am': 'ከትዊተር ካሉት ከCOVID-19 ደዌና ጋር የተገኘውን የራሳቸውን ጉዳይ የሚያሳውቀውን እውቀት በመውጣት የህዝብ ጤና ውስጥ የሚያስቸገርን የጦር ምርጫዎችን ማሳየት ይችላል፡፡ W-NUT 2020 የተሰራጨው ስራ 3 የተደረገውን የአምስት ዓይነት ጉዳይ ከCOVID-19 ጋር የሚታያዩ የአምስት ዓይነት ሁኔታዎችን ማረጋገጥ እና የፊተኛውን የድምፅ ግንኙነት አካባቢ፣ ዲሞፖርቲካዊ፣ ፖሊካዊ እና ስፓቲካዊ፣ ጊዜው ወይም አካባቢ እውቀት የሚታወቁ የግንኙነቶችን ማረጋገጥ ተቃውሞ ነው፡፡ ተግባራችን በአጠቃሚ ጉዳይ ላይ በተጠቃሚ በትዊት ላይ የሚታወቅ የኢንተርኔት መንግስታትን ሁሉ በመጠቀም የሚያሳውቅ የደዌብ መሠረት አካባቢ አካባቢ አግኝቷል፡፡ ይህ የመዝገብ ግንኙነት COVID-ትዊተር-BERT ቀድሞ የተማረከ ቋንቋ ምሳሌ ነው፡፡ በተጨማሪም፣ ለሁሉም ጉዳይ ስልጣኖች ጽሑፍ ማውቀትን ለመማር፣ በHopfield Network መደገፊያ በሚባል የፍጥረት ጉዳይ ታምነናል፡፡ የተካፈሉት የስራ ማስታወቂያ ውጤቶች ትልቅ ዳታተር በተማረ ጊዜ ሲሞክራችንን ያሳያል፡፡', 'fa': 'استخراج دانش ساخته\u200cشده\u200cای که شامل اتفاقات خودگزارش شده\u200cاند، مربوط به پاندمیک COVID-19 از توئیتر است، توانایی برای اطلاعات سیستم\u200cهای نظارت که نقش مهمی در سلامت عمومی بازی می\u200cکنند را دارد. چالش اخراج رویداد که توسط ماموریت سه مشترک W-NUT 2020 ارائه می\u200cشود، روی شناسایی پنج نوع رویداد مربوط به پاندمیک COVID-19 و مجموعهٔ مختلف کودکان دموگرافیک، اپیدمیولوژیک، کلینیکی و دانش فضایی، موقتی یا موجود موجود است. شرکت ما در چالش به طراحی یک معماری عصبی برای شناسایی با همدیگر تمام اتفاقات اسلوت\u200cها در تویت که مربوط به اتفاق علاقه\u200cای است رخ داد. این معماری از COVID-Twitter-BERT به عنوان مدل زبان پیش آموزش داده می\u200cشود. علاوه بر این، برای یاد گرفتن وسیله\u200cهای متن برای هر اسلوت رویداد، ما بر یک پرونده ویژه\u200cای از شبکه\u200cهای هوپفیلد، به عنوان جمع کردن هوپفیلد، توکل کردیم. نتایج ارزیابی کار مشترک نشان می دهد که سیستم ما بهترین عمل می کند زمانی که در مجموعه داده های بزرگتر آموزش می شود، در حالی که هنگامی که آموزش روی مجموعه داده های کوچکتر رقابت می کند.', 'hy': 'Թվիթերից դուրս բերելով կառուցվածքային գիտելիքներ, որոնք ներառում են COVID-19 համաճարակի հետ կապված իրադարձություններ, ունի պոտենցիալ տեղեկացնել հետախուզական համակարգերը, որոնք հանրային առողջության մեջ կարևոր դեր են խա Այս իրադարձությունների դուրս հանելու մարտահրավերը, որ ներկայացվել է W-NYT 2020-ի համագործակցած հանձնարարության 3 կողմից, կենտրոնացել է COVID-19 համաճարակի հետ կապված հինգ տիպի իրադարձությունների հայտնաբերման վրա և նրանց նախկինում սահմանափակված վայրերի համակարգի վրա, որոնք կոդավորում են դեմոգրաֆ Մեր մասնակցությունը մարտահրավերում հանգեցրեց նյարդային ճարտարապետության ստեղծմանը, որպեսզի միասին հայտնաբերենք բոլոր իրադարձությունների ընթացքում արտահայտված թվիթերի մեջ, որը կարևոր է հետաքրքիր իրադարձություններին: Այս ճարտարապետությունն օգտագործում է COVID-Twitter-BER-ը որպես նախապատրաստված լեզվի մոդել: Ավելին, իմանալու համար, որ յուրաքանչյուր իրադարձությունների ընդլայնման տեքստի ընդլայնումը, մենք հիմնված էինք Հոփֆիլդ ցանցերի հատուկ դեպքի վրա, հատկապես Հոփֆիլդ ընդլայնման վրա: Ընդհանուր խնդիրների գնահատման արդյունքները ցույց են տալիս, որ մեր համակարգը լավագույնն է աշխատում, երբ այն պատրաստվում է ավելի մեծ տվյալների համակարգում, մինչդեռ այն շարունակում է մրցակցություն ունենալ ավելի փոքր տվյալների համակար', 'az': "Tövratdakı COVID-19 pandemiyasıyla əlaqəli olaraq müxtəlif bilgiləri çıxartmaq qüvvət sağlığında kritik bir rol oynayan gözləmə sistemlərini xəbər vermək mümkün olar. W-NUT 2020 paylaşılan 3-ci işin təşkil edilmiş olaraq, COVID-19 pandemik ilə əlaqəsiz beş tür olaraq və onların ön təşkil edilmiş slot kodlaması demografik, epidemiolojik, klinik və uzaq, temporal və subjektiv bilgi ilə əlaqəsiz olan beş tür olaraq təşkil edilmişdir. Döyüşdə bizim iştirağımız nöral arhitektür tasarımına yol göstərdi ki, bütün olaraq Slot'ları bir-birinə təşkil etmək üçün təşkil edilmişdir. Bu arhitektura COVID-Twitter-BERT öyrənmiş dil modeli olaraq qullanır. Əvvəlcə, hər vaxt Slot üçün metin səviyyəsini öyrənmək üçün Hopfield Sənələrinin xüsusi məlumatına təvəkkül etdik. Bölüşülmüş görev değerlendirməsinin sonuçları sistemimizin böyük veri qutusunda təhsil edildiyi zaman ən yaxşı işlədiyini göstərir, daha kiçik veri qutusunda təhsil ediləndə is ə müqayisədə qalar.", 'bn': 'টুইটার থেকে স্বাস্থ্যের একটি গুরুত্বপূর্ণ ভূমিকা নিয়ে স্বাক্ষরিত কোভিড-১৯ প্রতিবেদনের সাথে সম্পর্কিত ঘটনাগুলো সম্পর্কে জ্ঞান বের ডি-এনউট ২০২০ শেয়ার করা কাজ ৩-এর দ্বারা এই অনুষ্ঠানের বিনিময় চ্যালেঞ্জের প্রতি মনোযোগ প্রদান করেছে কভিড-১৯ প্রতি যুক্ত পাঁচটি ধরনের ঘটনার পরিচিতি এবং তাদের পূর্বে নির্ধারিত স্লোটগুল আমাদের এই চ্যালেঞ্জে অংশগ্রহণের ফলে সাথে যুক্ত করার জন্য একটি নিউরুল প্রতিষ্ঠানের ডিজাইনারের কারণে সকল ঘটনার স্লোটগুলো চিহ্নিত করার জন্ এই প্রতিষ্ঠান কভিড-টুইটার-বের্ট ব্যবহার করে প্রাক্তন প্রশিক্ষিত ভাষার মডেল হিসেবে ব্যবহার করে। এছাড়াও, প্রত্যেক ইভেন্ট স্লোটের জন্য টেক্সপ্যান স্প্যান ব্যবহার শিখার জন্য আমরা হোপফিল্ড নেটওয়ার্কের বিশেষ কেসের উপর নির ভাগাভাগি করা কাজের মুল্যায়নের ফলাফল নির্দেশ করে যে বৃহত্তর তথ্য সেটে প্রশিক্ষণ প্রদান করা হলে আমাদের সিস্টেম শ্রেষ্ঠ করে, যদিও এটি ছোট তথ', 'cs': 'Extrahování strukturovaných znalostí zahrnujících vlastní nahlášené události související s pandemií COVID-19 z Twitteru má potenciál informovat systémy sledování, které hrají klíčovou roli ve veřejném zdraví. Výzva extrakce událostí představená sdíleným úkolem W-NUT 2020 2020 3 se zaměřila na identifikaci pěti typů událostí relevantních pro pandemie COVID-19 a jejich příslušné sady předem definovaných slotů kódujících demografické, epidemiologické, klinické i prostorové, časové nebo subjektivní znalosti. Naše účast na výzvě vedla k návrhu neuronové architektury pro společné identifikaci všech Event Slots vyjádřených ve tweetu relevantním pro zájmovou událost. Tato architektura využívá COVID-Twitter-BERT jako předškolený jazykový model. Kromě toho, abychom se naučili vložení textového rozpětí pro každý Event Slot, jsme se spoléhali na speciální případ Hopfield Networks, konkrétně Hopfield pooling. Výsledky hodnocení sdílených úkolů ukazují, že náš systém funguje nejlépe, když je trénován na větší sadě dat, zatímco při trénování na menších sadách dat zůstává konkurenceschopný.', 'ca': "Extraer coneixements estructurats que impliquen esdeveniments auto-notificats relacionats amb la pandèmia COVID-19 de Twitter té el potencial d'informar els sistemes de supervisió que juguen un paper crític en la salut pública. El repte d'extracció d'esdeveniments presentat per la tasca compartida W-NUT 2020 va centrar-se en la identificació de cinc tipus d'esdeveniments rellevants a la pandèmia COVID-19 i el seu respectiu conjunt de slots predefinits codificant coneixements demogràfics, epidemiològics, clínics, espacials, temporals o subjectius. La nostra participació en el repte va portar al disseny d'una arquitectura neuronal per identificar conjuntament tots els slots d'eventos expressats en un tweet rellevant a un evento d'interès. This architecture uses COVID-Twitter-BERT as the pre-trained language model.  In addition, to learn text span embeddings for each Event Slot, we relied on a special case of Hopfield Networks, namely Hopfield pooling.  Els resultats de l'evaluació compartida de les tasques indican que el nostre sistema funciona millor quan està entrenat en un conjunt de dades més gran, mentre que sigue competitiu quan està entrenat en petits conjunts de dades.", 'et': 'COVID-19 pandeemiaga seotud sündmustega seotud struktureeritud teadmiste hankimine Twitterist võib teavitada jälgimissüsteeme, millel on rahvatervises kriitiline roll. W-NUT 2020 ühises ülesandes 3 esitatud sündmuste eraldamise väljakutse keskendus viie COVID-19 pandeemiaga seotud sündmuste tüübi kindlakstegemisele ja nende vastavatele eelnevalt määratletud aegadele, mis kodeerivad demograafilisi, epidemioloogilisi, kliinilisi ning ruumilisi, ajalisi või subjektiivseid teadmisi. Meie osalemine väljakutses viis neuraalse arhitektuuri väljatöötamiseni, et ühiselt tuvastada kõik sündmuste teenindusajad, mida väljendatakse huvipakkuva sündmuse jaoks olulises säutsis. Selles arhitektuuris kasutatakse eelõpetatud keelemudelina COVID-Twitter-BERT. Lisaks sellele toetusime iga sündmuse pesa teksti ulatuse manustamise õppimiseks Hopfield Networks erijuhtumile, nimelt Hopfield ühendamisele. Ühiste ülesannete hindamise tulemused näitavad, et meie süsteem toimib kõige paremini, kui seda koolitatakse suuremal andmekogumil, samas kui see jääb konkurentsivõimeliseks väiksematel andmekogumitel koolitamisel.', 'bs': 'Izvukanje strukturiranih znanja uključujući samopojavljene događaje povezane sa pandemijom COVID-19 iz Twitter ima potencijal da obavijesti sisteme nadzora koji imaju kritičnu ulogu u javnom zdravlju. Izazov izvlačenja događaja koji je predstavio zajednički zadatak 3 W-NUT 2020 fokusiran je na identifikaciju pet vrsta događaja relevantnih za pandemiju COVID-19 i njihovu odgovarajuću skupu preddefiniranih mjesta kodiranja demografičkih, epidemioloških, kliničkih i prostornih, temporalnih ili subjektivnih znanja. Naše učešće u izazovu dovelo je do dizajna neuralne arhitekture za zajedničku identifikaciju svih događaja Slota izraženih u tweetu relevantnom za događaj interesa. Ova arhitektura koristi COVID-Twitter-BERT kao predobučeni jezički model. Osim toga, da bi naučili integraciju teksta za svaki događaj Slot, oslanjali smo se na poseban slučaj Hopfield mreža, a to je Hopfield skupljanje. Rezultati zajedničke procjene zadataka ukazuju na to da naš sistem najbolji izvodi kada se obučava na većem setu podataka, dok ostaje konkurentna kada se obučava na manjim setima podataka.', 'fi': 'COVID-19-pandemiaan liittyviä itse raportoituja tapahtumia koskevan strukturoidun tiedon hankkiminen Twitteristä voi tarjota tietoa seurantajärjestelmistä, joilla on ratkaiseva rooli kansanterveydessä. W-NUT 2020 Shared Task 3:n tapahtumaekstraktiohaasteessa keskityttiin viiden COVID-19-pandemian kannalta merkityksellisten tapahtumien tunnistamiseen ja niiden ennalta määriteltyihin lähtöpaikkoihin, jotka koodaavat demografista, epidemiologista, kliinistä sekä spatiaalista, ajallista tai subjektiivista tietoa. Osallistumme haasteeseen johti neuroarkkitehtuurin suunnitteluun, jonka avulla tunnistetaan yhdessä kaikki tapahtumapaikat, jotka ilmaistaan tweetissä, jotka liittyvät tiettyyn tapahtumaan. Tämä arkkitehtuuri käyttää COVID-Twitter-BERT esikoulutettuna kielimallina. Lisäksi opetellaksemme tekstitason upotuksia jokaiselle tapahtumapaikalle luotimme Hopfield Networksin erityistapaukseen, nimittäin Hopfield poolingiin. Yhteisen tehtävän arvioinnin tulokset osoittavat, että järjestelmämme suoriutuu parhaiten, kun sitä koulutetaan suuremmalla aineistolla, kun taas se pysyy kilpailukykyisenä pienemmillä aineistoilla koulutettaessa.', 'sk': 'Pridobivanje strukturiranega znanja, ki vključuje dogodke, povezane s pandemijo COVID-19, iz Twitterja, lahko obvešča sisteme nadzora, ki imajo ključno vlogo v javnem zdravju. Izziv pridobivanja dogodkov, ki ga predstavlja skupna naloga 3 W-NUT 2020, je bil osredotočen na identifikacijo petih vrst dogodkov, pomembnih za pandemijo COVID-19, in njihov sklop vnaprej določenih slotov, ki kodirajo demografsko, epidemiološko, klinično ter prostorsko, časovno ali subjektivno znanje. Naše sodelovanje pri izzivu je pripeljalo do oblikovanja nevronske arhitekture za skupno identifikacijo vseh igralnih mest dogodkov, izraženih v tweetu, pomembnem za dogodek, ki ga zanima. Ta arhitektura uporablja COVID-Twitter-BERT kot vnaprej usposobljen jezikovni model. Poleg tega smo se za učenje vdelav besedilnih razponov za vsak Event Slot zanašali na poseben primer Hopfield Networks, namreč Hopfield združevanje. Rezultati ocenjevanja skupnih nalog kažejo, da je naš sistem najboljši, ko se usposablja na večjem naboru podatkov, medtem ko ostaja konkurenčen pri usposabljanju na manjših naborih podatkov.', 'ha': "Extractin wani ilmi na haɗi da ranar-da-takarda da aka yi husũma da takardar COV-19 daga Twitter yana da awon ya gaya wa tsarin na'urar tsarin da ke play wani muhimmin roli a cikin afya ga umma. Banner-jigon al'amarin da the W-NUT 2020 Shared Tamar 3 na fokus a kan gane wasu shiryoyin shan nau'i masu husika da COV-19 da kuma kure-satura na zaman-defined slotts kodi-digitally, agolojiogi, da kuma da ƙayyade, da kuma da spati, da takardar lokaci ko da ake samu da ilmi. Bayanmu da shirin zartar da shi ya ƙara wani matsayin neural dõmin a gane duk Musulunci da aka nuna cikin wani Twitter wanda yana da amfani da wani abu na interesse. Wannan arkin yana amfani da COKID-Twitter-BERT kamar misalin harshen da aka yi wa zaman-tunkuɗe. Da haka, don ka iya amfani da matsayin span da aka embedded in kowace Motsi, mun dõgara a kan wani case na Hopfield Networks, kamar poolin Hopfield. The results of the shared task evaluation indicate that our system performs best when it is trained on a larger dataset, while it remains competitive when training on smaller datasets.", 'jv': 'Ngawe ngilanggar alih sistem structural navigation Awakdhéwé éntukno nggawe wigatining akya w-NUT 2020 Tarjamahan 3 nggawe nguasai perlima kalih akya eventura sing gagalé kanggo nggambar kelas corid-19 Awak dhéwé pisan ning acara iki dadi nggawe ngupakan ning arep dino alat sing nyebuti nggawe barang nggawe "events slots" sing bisa nyebutne ning tuwit sing dikarepaké akéwé operasi. architecture iki wis ngawehi COMVD-YouTube-BERT nganggo model sing luwih banter Slackfree Rejalaké berarti task mengko ngomong nik sistem dhéwé gak bener nang data sethaya sing luwih apik, sampeyan mbut kuwi wis atik dadi-sethaya sing gak butas', 'he': 'להוציא ידע מובנה שמעניין אירועים מדווחים בעצמם קשורים לפנדמיה COVID-19 מטוויטר יש את הפוטנציאל להודיע מערכות מעקב שמשחקים תפקיד קריטי בבריאות הציבורית. אתגר ההוצאה של האירועים המוציא על ידי משימה 3 המשותפת W-NUT 2020 התמקד בזיהוי חמישה סוגים של אירועים רלוונטיים לפנדמיה COVID-19 והקבוצה המתאימה שלהם של מקומות מוגדרים מראש השתתפות שלנו באתגר הובילה לעיצוב של ארכיטקטורה עצבית לזהות ביחד את כל האירועים שבטוויט רלוונטי לאירוע של עניין. הארכיטקטורה הזו משתמשת ב COVID-Twitter-BERT כדוגמנית שפה מאומנת מראש. בנוסף, כדי ללמוד תוספות טקסט עבור כל סגור אירועים, הסמכנו על מקרה מיוחד של רשתות הופילד, כלומר הרכיבה של הופילד. התוצאות של הערכת המשימה המשותפת מצביעות כי המערכת שלנו מבצעת הכי טוב כשהיא מאומנת על קבוצת נתונים גדולה יותר, בעוד היא נשארת תחרותית כאשר האימונים על קבוצות נתונים קטנות יותר.', 'bo': 'རང་ཉིད་ཀྱིས་བཟོ་བཀོད་པའི་གནས་ཚུལ་གསལ་འདེབས་བྱེད་པར་སྤྲོད་ཀྱི་བྱ་འགུལ་དང་འབྲེལ་བ་ཡོད། The event extraction challenge presented by the W-NUT 2020 Shared Task 3 focused on the identification of five types of events relevant to the COVID-19 pandemic and their respective set of pre-defined slots encoding demographic, epidemiological, clinical as well as spatial, temporal or subjective knowledge. ང་ཚོའི་གོ་སྐབས་གདོང་ལེན་བྱེད་རྒྱུ་ལས་དབུལ་གྱི་བཟོ་རྩིས་ཀྱི་བཟོ་བཅོས་འདི་དང་མཉམ་དུ་འཇུག སྒྲིག་འགོད་འདིས་སྔོན་གྱིས་འཛིན་སྤྱོད་པའི་སྐད་རིགས་ཀྱི་མ་གཟུགས་རིས་སྤྱོད་ཀྱི་ཡོད། In addition, to learn text span embeddings for each Event Slot, we relied on a special case of Hopfield Networks, namely Hopfield pooling. མཉམ་སྤྱོད་གྱི་བྱ་འགུལ་བསྡུར་གྱི་གྲུབ་འབྲས་བ་ནི་ང་ཚོའི་མ་ལག་གི་ཡིག'}
