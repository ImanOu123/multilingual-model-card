{'en': 'Evaluating Visual Representations for Topic Understanding and Their Effects on Manually Generated Topic Labels', 'ar': 'تقييم التمثيلات المرئية لفهم الموضوع وتأثيراتها على تسميات المواضيع التي يتم إنشاؤها يدويًا', 'fr': 'Évaluation des représentations visuelles pour la compréhension du sujet et de leurs effets sur les étiquettes de sujet générées manuellement', 'pt': 'Avaliando representações visuais para compreensão de tópicos e seus efeitos em rótulos de tópicos gerados manualmente', 'es': 'Evaluación de representaciones visuales para la comprensión del tema y sus efectos en las etiquetas de temas generadas manualmente', 'ja': '手動で生成されたトピックラベルに対するトピックの理解とその影響のための視覚的表現の評価', 'zh': '评估以知手动生之表', 'hi': 'विषय समझ के लिए दृश्य अभ्यावेदन और मैन्युअल रूप से जेनरेट किए गए विषय लेबल पर उनके प्रभावों का मूल्यांकन करना', 'ru': 'Оценка визуальных представлений для понимания темы и их влияния на созданные вручную метки темы', 'ga': 'Amharcléirithe a Mheas le Tuiscint ar Topaicí agus a nIarmhairtí ar Lipéid Topaicí a Ghintear de Láimh', 'ka': 'ვიზუალური გამოსახულებების განსაზღვრება ტემიკური პასუხისთვის და მათი ეფექტის მანძილურად განსაზღვრებული ტემიკური ლაბლიზე', 'el': 'Αξιολόγηση οπτικών αναπαραστάσεων για την κατανόηση θεμάτων και τις επιπτώσεις τους στις χειροκίνητες ετικέτες θεμάτων', 'hu': 'Vizuális reprezentációk értékelése a témakörök megértéséhez és hatásuk a manuálisan generált témakörök címkéire', 'lt': 'Tiriamojo supratimo vizualinių atstovybių ir jų poveikio rankiniuose gaminamuose teminiuose ženkluose vertinimas', 'kk': 'Нақыштарды түсініп, қолмен жасалған нақыштар жарлықтарына көрінетін таңбаларды оқу', 'it': 'Valutazione delle rappresentazioni visive per la comprensione degli argomenti e i loro effetti sulle etichette degli argomenti generati manualmente', 'mk': 'Оценување на визуелните претставувања за разбирање на темата и нивните ефекти на рачно генерираните темски етикети', 'ml': 'പ്രമേയത്തിനുള്ള വിവരങ്ങള്\u200dക്കുള്ള പ്രതിനിധികളും കൈകാര്യം ഉണ്ടാക്കിയ പ്രഭാവങ്ങളുടെ പ്രഭാവങ്ങള്\u200d', 'mt': 'Evalwazzjoni tar-Rappreżentazzjonijiet Viżwali għall-Ftehim Topiku u l-Effetti tagħhom fuq it-Tikketti Topiki Ġenerati Manwalment', 'ms': 'Mengevaluasi Perwakilan Visual untuk Pemahaman Topik dan Kesan Mereka pada Label Topik Dijana Manual', 'mn': 'Хоосон сэдэв ойлголтын тухай харагдах үзэгдэл болон тэдний нөлөөлөл нь гараар нэмэгдсэн сэдэв маркилгуудын тухай үнэлгээ', 'pl': 'Ocena wizualnych reprezentacji dla zrozumienia tematów i ich wpływu na ręcznie generowane etykiety tematów', 'no': 'Evaluerer visuelle representasjonar for temaforståking og effekten sine på manuelt genererte temaetikettar', 'ro': 'Evaluarea reprezentărilor vizuale pentru înțelegerea subiectelor și efectele acestora asupra etichetelor subiectelor generate manual', 'si': 'ප්\u200dරශ්නය තේරුම්ගන්න සහ ඔවුන්ගේ ප්\u200dරතිකාර වලින් ප්\u200dරශ්නයක් විශ්වාස කරන්න', 'sr': 'Procjenjivanje vizualnih predstavljanja za razumevanje tema i njihove utjecaje na manualno generirane etikete tema', 'so': 'Qiimeynta muuqashada aragtida ee macluumaadka waxgarashada iyo saameyaashooda ku saabsan calaamadaha la sameeyay', 'sv': 'Utvärdering av visuella representationer för ämnesförståelse och deras effekter på manuellt genererade ämnesetiketter', 'ta': 'கைமுறை உருவாக்கப்பட்ட தலைப்பு விளக்கச்சீட்டில் காட்சி பிரதிரிவுகளை மதிப்பிடுகிறது', 'ur': 'موضوع سمجھنے اور ان کے اثرات مسائل لیبلوں پر مسائل معجزات کا ارزش کیا جاتا ہے', 'uz': 'Name', 'vi': 'Đánh giá các quan điểm quan sát theo nội dung hiểu biết và phản ứng của nó với các biểu tượng được tạo ra', 'bg': 'Оценка на визуалните представи за разбиране на темата и тяхното въздействие върху ръчно генерирани етикети на темата', 'da': 'Evaluering af visuelle repræsentationer for emneforståelse og deres virkninger på manuelt genererede emneetiketter', 'de': 'Evaluierung visueller Repräsentationen für Themenverständnis und deren Auswirkungen auf manuell generierte Themenbeschriftungen', 'id': 'Mengevaluasi Perwakilan Visual untuk Pemahaman Topik dan Efek mereka pada Label Topik Yang Digenerikan Manual', 'fa': 'ارزیابی نمایش\u200cهای بینایی برای فهمیدن موضوع و اثرات آنها بر برچسب\u200cهای موضوع تولید دستی', 'nl': 'Visuele representaties evalueren voor inzicht in onderwerpen en hun effecten op handmatig gegenereerde topic labels', 'ko': '주제 이해의 시각적 표현과 수동으로 생성된 주제 라벨에 대한 영향 평가', 'hr': 'Procjenjivanje vizualnih predstavljanja za razumijevanje teme i njihove učinke na manualno generirane etikete teme', 'sw': 'Kuthibitisha maoni ya Visual kwa ajili ya Maudhui ya Kuelewa na Matokeo yao kwenye mabango yaliyotengenezwa kwa mikononi', 'af': 'Assebliseer Visuele voorstellings vir onderwerp verstanding en hul effekte op Hand Gegenereer Tema etikette', 'sq': 'Vlerësimi i përfaqësimeve vizuale për kuptimin e temave dhe ndikimet e tyre në etiketat e temave të gjeneruara manualisht', 'am': 'Evaluating Visual Representations for Topic Understanding and Their Effects on Manually Generated Topic Labels', 'tr': 'Meýdança düşünmesi we olaryň etkinleri Ellen Dönüşdirilen Topar Etiketleri üçin Görsel Wasplary Taýýarlanýar', 'bn': 'বিষয়বস্তু বুঝতে এবং তাদের প্রভাব নিয়ন্ত্রণ করা বিষয়ের লেবেলের উপর দৃশ্যমান প্রতিনিধি মূল্যায়ন করা হচ্ছে', 'az': 'Mevzu anlama və Özünün Əlaqə Yapılmış Mevzu Etiketlerinin Görünüllü Təşkiləri Qıymetlidir', 'bs': 'Procjenjivanje vizuelnih predstavljanja za razumijevanje tema i njihove učinke na manualno generirane etikete tema', 'et': 'Visuaalsete esinduste hindamine teemaarusaamiseks ja nende mõju käsitsi loodud teemasildidele', 'hy': 'Evaluating Visual Representations for Topic Understanding and Their Effects on Manually Generated Topic Labels', 'ca': 'Evaluating Visual Representations for Topic Understanding and Their Effects on Manually Generated Topic Labels', 'cs': 'Hodnocení vizuálních reprezentací pro porozumění tématu a jejich vlivu na ručně generované tématické štítky', 'fi': 'Visuaalisten esitysten arviointi aiheiden ymmärtämiseksi ja niiden vaikutusten arvioiminen käsin luotuihin otsikoihin', 'he': 'הערכה של מייצגים חזותיים להבנה של נושאים וההשפעות שלהם על תוויות נושאים מיוצרות ידנית', 'ha': 'Yana ƙayyade Repositori na Arawa wa wa Madaidaita Underline & Effects on Labels Kida Haƙĩƙa', 'bo': 'Evaluating Visual Representations for Topic Understanding and Their Effects on Manually Generated Topic Labels', 'sk': 'Ocena vizualnih predstavitev za razumevanje teme in njihovih učinkov na ročno ustvarjene oznake teme', 'jv': 'Name'}
{'en': 'Probabilistic topic models are important tools for indexing, summarizing, and analyzing large document collections by their themes. However, promoting end-user understanding of topics remains an open research problem. We compare labels generated by users given four topic visualization techniquesword lists, word lists with bars, word clouds, and network graphsagainst each other and against automatically generated labels. Our basis of comparison is participant ratings of how well labels describe documents from the topic. Our study has two phases : a labeling phase where participants label visualized topics and a validation phase where different participants select which labels best describe the topics’ documents. Although all visualizations produce similar quality labels, simple visualizations such as word lists allow participants to quickly understand topics, while complex visualizations take longer but expose multi-word expressions that simpler visualizations obscure. Automatic labels lag behind user-created labels, but our dataset of manually labeled topics highlights linguistic patterns (e.g., hypernyms, phrases) that can be used to improve automatic topic labeling algorithms.', 'ar': 'تعد نماذج الموضوعات الاحتمالية أدوات مهمة لفهرسة مجموعات المستندات الكبيرة وتلخيصها وتحليلها حسب موضوعاتها. ومع ذلك ، لا يزال تعزيز فهم المستخدم النهائي للموضوعات يمثل مشكلة بحث مفتوحة. نحن نقارن التسميات التي تم إنشاؤها بواسطة المستخدمين وفقًا لأربع تقنيات تصور الموضوعات - قوائم الكلمات وقوائم الكلمات مع الأشرطة وسحب الكلمات والرسوم البيانية للشبكة - مقابل بعضها البعض ومقابل التسميات التي تم إنشاؤها تلقائيًا. أساس المقارنة لدينا هو تقييمات المشاركين لمدى جودة وصف الملصقات للمستندات من الموضوع. تتكون دراستنا من مرحلتين: مرحلة وضع العلامات حيث يقوم المشاركون بتسمية الموضوعات المرئية ومرحلة التحقق من الصحة حيث يختار المشاركون المختلفون الملصقات التي تصف مستندات الموضوعات بشكل أفضل. على الرغم من أن جميع التصورات تنتج تسميات جودة متشابهة ، إلا أن التصورات البسيطة مثل قوائم الكلمات تسمح للمشاركين بفهم الموضوعات بسرعة ، بينما تستغرق التصورات المعقدة وقتًا أطول لكنها تعرض تعبيرات متعددة الكلمات تخفيها التصورات الأبسط. تتأخر التسميات التلقائية عن التصنيفات التي أنشأها المستخدم ، ولكن مجموعة البيانات الخاصة بنا من الموضوعات المصنفة يدويًا تسلط الضوء على الأنماط اللغوية (مثل الكلمات الفائقة والعبارات) التي يمكن استخدامها لتحسين خوارزميات تصنيف الموضوعات تلقائيًا.', 'fr': "Les modèles thématiques probabilistes sont des outils importants pour indexer, résumer et analyser de grandes collections de documents en fonction de leurs thèmes. Cependant, la promotion de la compréhension des sujets par l'utilisateur final reste un problème de recherche ouvert. Nous comparons les étiquettes générées par les utilisateurs à l'aide de quatre techniques de visualisation de sujets (listes de mots, listes de mots avec barres, nuages de mots et graphiques en réseau) les unes par rapport aux autres et avec des étiquettes générées automatiquement. Notre base de comparaison est l'évaluation par les participants de la manière dont les étiquettes décrivent les documents du sujet. Notre étude comporte deux phases\xa0: une phase d'étiquetage où les participants étiquettent les sujets visualisés et une phase de validation où les différents participants sélectionnent les étiquettes qui décrivent le mieux les documents des sujets. Bien que toutes les visualisations produisent des étiquettes de qualité similaires, les visualisations simples telles que les listes de mots permettent aux participants de comprendre rapidement les sujets, tandis que les visualisations complexes prennent plus de temps mais exposent des expressions à plusieurs mots que les visualisations plus simples masquent. Les étiquettes automatiques sont en retard par rapport aux étiquettes créées par l'utilisateur, mais notre ensemble de données de sujets étiquetés manuellement met en évidence des modèles linguistiques (par exemple, des hyperonymes, des phrases) qui peuvent être utilisés pour améliorer les algorithmes d'étiquetage automatique des sujets.", 'pt': 'Modelos de tópicos probabilísticos são ferramentas importantes para indexar, resumir e analisar grandes coleções de documentos por seus temas. No entanto, promover a compreensão dos tópicos pelo usuário final continua sendo um problema de pesquisa em aberto. Comparamos rótulos gerados por usuários com quatro técnicas de visualização de tópicos — listas de palavras, listas de palavras com barras, nuvens de palavras e gráficos de rede — entre si e com rótulos gerados automaticamente. Nossa base de comparação são as avaliações dos participantes de quão bem os rótulos descrevem os documentos do tópico. Nosso estudo tem duas fases: uma fase de rotulagem onde os participantes rotulam os tópicos visualizados e uma fase de validação onde diferentes participantes selecionam quais rótulos melhor descrevem os documentos dos tópicos. Embora todas as visualizações produzam rótulos de qualidade semelhantes, visualizações simples, como listas de palavras, permitem que os participantes entendam tópicos rapidamente, enquanto visualizações complexas demoram mais, mas expõem expressões de várias palavras que as visualizações mais simples obscurecem. Os rótulos automáticos ficam atrás dos rótulos criados pelo usuário, mas nosso conjunto de dados de tópicos rotulados manualmente destaca padrões linguísticos (por exemplo, hiperônimos, frases) que podem ser usados para melhorar os algoritmos de rotulagem automática de tópicos.', 'es': 'Los modelos probabilísticos de temas son herramientas importantes para indexar, resumir y analizar grandes colecciones de documentos por temas. Sin embargo, promover la comprensión de los temas por parte del usuario final sigue siendo un problema de investigación abierto Comparamos las etiquetas generadas por los usuarios con cuatro técnicas de visualización de temas (listas de palabras, listas de palabras con barras, nubes de palabras y gráficos de red) entre sí y con etiquetas generadas automáticamente. Nuestra base de comparación son las calificaciones de los participantes sobre qué tan bien las etiquetas describen los documentos del tema. Nuestro estudio tiene dos fases: una fase de etiquetado en la que los participantes etiquetan los temas visualizados y una fase de validación en la que los diferentes participantes seleccionan qué etiquetas describen mejor los documentos de los temas. Aunque todas las visualizaciones producen etiquetas de calidad similares, las visualizaciones simples, como las listas de palabras, permiten a los participantes comprender rápidamente los temas, mientras que las visualizaciones complejas llevan más tiempo, pero exponen expresiones de varias palabras que las visualizaciones más simples ocultan. Las etiquetas automáticas van a la zaga de las etiquetas creadas por los usuarios, pero nuestro conjunto de datos de temas etiquetados manualmente resalta los patrones lingüísticos (por ejemplo, hiperónimos, frases) que se pueden utilizar para mejorar los algoritmos de etiquetado automático de temas.', 'ja': '確率的トピックモデルは、大規模なドキュメントコレクションをテーマ別にインデックス化、要約、分析するための重要なツールです。 しかし、エンドユーザーのトピックの理解を促進することは、オープンな研究上の問題であり続けています。 4つのトピックの視覚化テクニック（ワードリスト、ワードリスト、ワードクラウド、ネットワークグラフ）を持つユーザーによって生成されたラベルを、自動生成されたラベルと比較します。 私たちの比較の基礎は、ラベルがトピックの文書をどの程度よく説明しているかという参加者の評価です。 私たちの研究には2つのフェーズがあります。参加者が視覚化されたトピックをラベル付けするラベル付けフェーズと、異なる参加者がトピックのドキュメントを最もよく説明するラベルを選択する検証フェーズです。 すべての可視化は同様の品質ラベルを生成しますが、単語リストなどの単純な可視化は参加者がトピックをすばやく理解することを可能にし、複雑な可視化はより長い時間を要しますが、より単純な可視化を不明瞭にする複数の単語の表現を公開します。 自動ラベルはユーザーが作成したラベルよりも遅れていますが、手動でラベル付けされたトピックのデータセットは、自動トピックラベリングアルゴリズムを改善するために使用できる言語パターン（ハイパーニム、フレーズなど）を強調しています。', 'zh': '概率题模者,以题索引、总、析大文档合之大器也。 然促最终用户之解,犹一开也。 予校给定四题可视化术(单词列表、带条者单词列表、单词云、网络图)用户生者,比之自生。 其略参与者题文档之评分如此。 余论分为二:一曰标记,参与者曰标记可视化题,一曰验段,不同者参与者择其最能言题者文档。 凡可视化效皆相似而可视化(如单词列表)许参与者速知题,而杂可视化更久,但会见简可视化所掩多单词表达式。 自标滞后于用户者,手动标数集见可以自标算法者(如超义词,短语)。', 'ru': 'Вероятностные тематические модели являются важными инструментами для индексации, обобщения и анализа больших коллекций документов по их темам. Однако содействие пониманию конечными пользователями тем остается открытой исследовательской проблемой. Мы сравниваем метки, созданные пользователями, с четырьмя методами визуализации топиков - списками слов, списками слов с полосами, облаками слов и сетевыми графиками - друг с другом и с автоматически созданными метками. Наша основа сравнения - рейтинги участников о том, насколько хорошо этикетки описывают документы из темы. Наше исследование состоит из двух этапов: этап маркировки, на котором участники отмечают визуализированные темы, и этап проверки, на котором различные участники выбирают, какие метки лучше всего описывают документы тем. Хотя все визуализации дают одинаковые метки качества, простые визуализации, такие как списки слов, позволяют участникам быстро понимать темы, в то время как сложные визуализации занимают больше времени, но показывают многословные выражения, которые более простые визуализации скрывают. Автоматические метки отстают от созданных пользователями меток, но наш набор данных с ручными метками тем выделяет лингвистические закономерности (например, гипернимы, фразы), которые могут быть использованы для улучшения автоматических алгоритмов маркировки тем.', 'hi': 'संभाव्य विषय मॉडल अनुक्रमण, सारांश, और उनके विषयों द्वारा बड़े दस्तावेज़ संग्रह का विश्लेषण करने के लिए महत्वपूर्ण उपकरण हैं। हालांकि, विषयों की अंतिम-उपयोगकर्ता समझ को बढ़ावा देना एक खुली शोध समस्या बनी हुई है। हम उपयोगकर्ताओं द्वारा उत्पन्न लेबल की तुलना चार विषय विज़ुअलाइज़ेशन तकनीकों-शब्द सूचियों, सलाखों के साथ शब्द सूचियों, शब्द बादलों और नेटवर्क ग्राफ़-एक-दूसरे के खिलाफ और स्वचालित रूप से उत्पन्न लेबल के खिलाफ करते हैं। तुलना का हमारा आधार प्रतिभागी रेटिंग है कि लेबल विषय से दस्तावेज़ों का कितनी अच्छी तरह से वर्णन करते हैं। हमारे अध्ययन में दो चरण हैं: एक लेबलिंग चरण जहां प्रतिभागी विज़ुअलाइज़ किए गए विषयों को लेबल करते हैं और एक सत्यापन चरण जहां विभिन्न प्रतिभागी चुनते हैं कि कौन से लेबल विषयों के दस्तावेजों का सबसे अच्छा वर्णन करते हैं। यद्यपि सभी विज़ुअलाइज़ेशन समान गुणवत्ता वाले लेबल का उत्पादन करते हैं, शब्द सूचियों जैसे सरल विज़ुअलाइज़ेशन प्रतिभागियों को विषयों को जल्दी से समझने की अनुमति देते हैं, जबकि जटिल विज़ुअलाइज़ेशन में अधिक समय लगता है लेकिन बहु-शब्द अभिव्यक्तियों को उजागर करते हैं जो सरल विज़ुअलाइज़ेशन अस्पष्ट होते हैं। स्वचालित लेबल उपयोगकर्ता द्वारा बनाए गए लेबल से पीछे हैं, लेकिन मैन्युअल रूप से लेबल किए गए विषयों के हमारे डेटासेट भाषाई पैटर्न (जैसे, हाइपरनिम्स, वाक्यांश) पर प्रकाश डालते हैं जिनका उपयोग स्वचालित विषय लेबलिंग एल्गोरिदम को बेहतर बनाने के लिए किया जा सकता है।', 'ga': 'Is uirlisí tábhachtacha iad samhlacha topaicí dóchúla chun bailiúcháin mhóra doiciméad a innéacsú, a achoimriú agus a anailísiú de réir a dtéamaí. Mar sin féin, is fadhb taighde oscailte é tuiscint an úsáideora deiridh ar thopaicí a chur chun cinn. Déanaimid comparáid idir lipéid a ghineann úsáideoirí nuair a thugtar ceithre theicníc léirshamhlaithe topaicí—liostaí focal, liostaí focal le barraí, scamaill focal, agus graif líonra – i gcoinne a chéile agus i gcoinne lipéid a ghintear go huathoibríoch. Is é an bonn comparáide atá againn ná rátálacha rannpháirtithe ar cé chomh maith agus a chuireann lipéid síos ar dhoiciméid ón topaic. Tá dhá chéim ag ár staidéar: céim lipéadaithe ina ndéanann rannpháirtithe lipéadú ar thopaicí léirshamhlaithe agus céim bhailíochtaithe ina roghnaíonn rannpháirtithe éagsúla na lipéid is fearr a chuireann síos ar dhoiciméid na dtopaicí. Cé go dtáirgeann gach léirshamhlú lipéid cháilíochta comhchosúla, cuireann léirshamhlú simplí ar nós liostaí focal ar chumas rannpháirtithe topaicí a thuiscint go tapa, agus tógann léirshamhlú casta níos faide ach nochtar nathanna cainte ilfhoclacha a fholaíonn amharcléirithe níos simplí. Tá lipéid uathoibríocha taobh thiar de na lipéid a chruthaítear ag úsáideoirí, ach leagann ár dtacar sonraí de thopaicí atá lipéadaithe de láimh béim ar phatrúin theangeolaíocha (m.sh. hipearainmneacha, frásaí) is féidir a úsáid chun algartaim uath-lipéadaithe topaicí a fheabhsú.', 'ka': 'შესაბამისი ტემების მოდელები იგივე მნიშვნელოვანი ხელსაწყოები, ინდექსირება, სისტემა და ანალიზაცია დიდი დოკუმენტის კოლექციები თავიდან. მაგრამ, საკუთარი მომხმარებელი გამოყენებელი ტემების გაგრძნობა უკვე გახსნა პრობლემა. ჩვენ მომხმარებისგან შექმნილი ლექტებების შესაბამისთვის, სახელის სიტყვების სიტყვების სიტყვები, სიტყვების სიტყვების სიტყვები და ქსელის გრაფიკების შესაბამისთვის და ავტომატ ჩვენი შემდგომარების ბაზა არის მოწყობინებელი რეტინგიები, რომლებიც საკმაოდ ლაბეტები აღწერს დოკუმენტების თემიდან. ჩვენი სწავლება აქვს ორი ფაზი: მარტიკური ფაზი, სადაც მოწყობინებელი ვიზუალურებული ტემები და გავაკეთებული ფაზი, სადაც განსხვავებული მოწყობინებელი მონიშნეთ, რომელიც მარტიკური ტემების დ თუმცა ყველა ვიზუალიზაციები მსგავსი კალიტური ნიშანების შექმნა, როგორც სიტყვების სიტყვების სიტყვები მოდის მომხმარებელი სწრაფად გავიგოთ ტემები, როცა კომპლექსი ვიზუალიზაციები მომხმარებლის შექმნილი ლექტიკების ჩვენი მონაცემები, მაგრამ ჩვენი მონაცემები მარტივი ლექტიკური შაბლოების შესახებ გამოყენება, რომლებიც ავტომატური ტექტიკური ლექტიკური ალგორიტების შესახებ გამ', 'it': "I modelli di argomenti probabilistici sono strumenti importanti per indicizzare, riassumere e analizzare grandi raccolte di documenti in base ai loro temi. Tuttavia, promuovere la comprensione degli argomenti da parte degli utenti finali rimane un problema di ricerca aperto. Confrontiamo le etichette generate dagli utenti con quattro tecniche di visualizzazione degli argomenti - elenchi di parole, elenchi di parole con barre, nuvole di parole e grafici di rete - l'una contro l'altra e con etichette generate automaticamente. La nostra base di confronto è la valutazione dei partecipanti di quanto bene le etichette descrivono i documenti dell'argomento. Il nostro studio si articola in due fasi: una fase di etichettatura in cui i partecipanti etichettano gli argomenti visualizzati e una fase di convalida in cui i diversi partecipanti selezionano quali etichette descrivono meglio i documenti degli argomenti. Sebbene tutte le visualizzazioni producano etichette di qualità simili, le visualizzazioni semplici come gli elenchi di parole consentono ai partecipanti di comprendere rapidamente gli argomenti, mentre le visualizzazioni complesse richiedono più tempo ma espongono espressioni multi-parola che le visualizzazioni più semplici oscurano. Le etichette automatiche rimangono indietro rispetto alle etichette create dagli utenti, ma il nostro set di dati di argomenti etichettati manualmente evidenzia modelli linguistici (ad esempio, ipernimi, frasi) che possono essere utilizzati per migliorare gli algoritmi automatici di etichettatura degli argomenti.", 'kk': 'Мүмкін нақыштардың үлкен құжаттарды нақыштары бойынша индекстеу, жинақтау және үлкен құжаттарды талдау үшін маңызды құралдар. Бірақ соңғы пайдаланушылардың тақырыптарды түсініктіру - ашық зерттеу мәселесі. Біз төрт нақышты визуализациялау техникалық тізімдері, сөздер тізімі жолақтар, сөздер бұлттықтар және желі графикалары бір-біріне қарсы және автоматты түрде құрылған жарлықтардан қарсы жазылаты Сәйкестігіміздің негізі - нақыштан құжаттарды қанша жарлық жарлықтарды таңдау үшін қатысушылардың оқиғалары. Біздің зерттеулерімізде екі этап бар: қатысушылар көрсетілген нақыштарды және қатысушылардың құжаттардың ең жақсы белгілерін таңдау этапы бар. Бүкіл визуализациялар ұқсас сапатты жарлықтарын жасауға арналған, сөз тізімдері секілді қарапайым визуализацияларға тақырыптарды тез түсінуге мүмкіндік береді, бірақ комплекс визуализациялары ұзақ уақытта ұзыла Автоматты жарлықтар пайдаланушының құрылған жарлықтардың артында қалды, бірақ қолмен жарлықталған нақыштардың деректер жиыны (мысалы, гипернимдер, фразтар) автоматты нақышты жарлықтау алгоритмдерін жасау үшін қолданылатын лингви', 'hu': 'A valószínűsítő témamodellek fontos eszközök a nagy dokumentumgyűjtemények indexeléséhez, összefoglalásához és elemzéséhez a témák szerint. A témák végfelhasználói megértésének előmozdítása azonban továbbra is nyitott kutatási probléma. Összehasonlítjuk a felhasználók által létrehozott címkéket, amelyeket négy témakörben megjelenítettek – szólisták, szólisták sávokkal, szófelhők és hálózati grafikonok – egymással és automatikusan létrehozott címkékkel. Az összehasonlítás alapja a résztvevők értékelése, hogy a címkék milyen jól írják le a téma dokumentumait. Tanulmányunk két fázisból áll: egy címkézési fázisból, ahol a résztvevők címkézik a megjelenített témákat, és egy validálási fázisból, ahol a különböző résztvevők kiválasztják, hogy mely címkék írják le a legjobban a témák dokumentumait. Bár minden megjelenítés hasonló minőségű címkéket eredményez, az egyszerű megjelenítések, például a szólisták lehetővé teszik a résztvevők számára, hogy gyorsan megértsék a témákat, míg az összetett megjelenítések hosszabb ideig tartanak, de többszós kifejezéseket tesznek lehetővé, amelyeket az egyszerűbb megjelenítések elhomályosítanak. Az automatikus címkék lemaradnak a felhasználó által létrehozott címkék mögött, de a manuálisan megjelölt témakészletünk kiemeli a nyelvi mintákat (pl. hipernímeket, kifejezéseket), amelyek segítségével javíthatók az automatikus témakészítési algoritmusok.', 'lt': 'Tikėtina, kad teminiai modeliai yra svarbios priemonės indeksuoti, apibendrinti ir analizuoti didelius dokumentų rinkinius pagal jų temas. Tačiau galutinių vartotojų supratimo apie temas skatinimas tebėra atvira mokslinių tyrimų problema. Palyginame naudotojų sukurtas etiketes, kuriose pateikiami keturi teminiai vizualizavimo metodai – žodžių sąrašai, žodžių sąrašai su juostomis, žodžių debesų ir tinklo grafikai vienas kitam, ir automatiškai sukurtas etiketes. Mūsų palyginimo pagrindas yra dalyvių reitingai, kaip gerai etiketėse apibūdinami dokumentai iš temos. Mūsų tyrimas apima du etapus: ženklinimo etapą, kuriame dalyviai ženklina vizualizuotas temas, ir patvirtinimo etapą, kuriame skirtingi dalyviai pasirinka, kurios etiketės geriausiai apibūdina temų dokumentus. Nors visose vizualizacijose yra panašios kokybės etiketės, paprastose vizualizacijose, pavyzdžiui, žodžių sąrašuose, dalyviai gali greitai suprasti temas, o sudėtingose vizualizacijose ilgesnė trukmė, tačiau atskleidžiamos kelių žodžių išraiškos, kurios paprastesnės vizualizacijos neapima. Automatinės etiketės atsilieka nuo naudotojo sukurtų etiketų, tačiau mūsų rankiniu būdu pažymėtų temų duomenų rinkinys atskleidžia kalbinius modelius (pvz., hiperinimus, frazes), kurie gali būti naudojami automatiniam temų ženklinimo algoritmams gerinti.', 'mk': "Веројатните модели на теми се важни алатки за индексирање, резимуирање и анализирање на големите колекции на документи по нивните теми. Сепак, промовирањето на разбирањето на темите на крајните корисници останува отворен истражувачки проблем. Ние ги споредуваме етикетите генерирани од корисниците кои дадоа четири техники за визуелизација листи на зборови, листи на зборови со ленти, облаци на зборови и мрежни графики еден против друг и против автоматски генерирани етикети. Нашата основа за споредба е рејтингот на учесниците за тоа колку добро етикетите опишуваат документи од темата. Our study has two phases: a labeling phase where participants label visualized topics and a validation phase where different participants select which labels best describe the topics' documents.  И покрај тоа што сите визуализации произведуваат слични квалитетни етикети, едноставните визуализации како што се листите на зборови им овозможуваат на учесниците брзо да ги разберат темите, додека комплексните визуализации траат долго, но ги изложуваат мултизборните изрази кои поедностав Автоматските етикети се задржуваат зад етикетите создадени од корисникот, но нашиот набор на податоци за рачно означени теми ги истакнува јазичните шеми (на пример хиперними, фрази) кои може да се користат за подобрување на автоматските алгоритми за означување на теми.", 'el': 'Τα πιθανολογικά μοντέλα θεμάτων είναι σημαντικά εργαλεία για την ευρετηρίαση, τη σύνοψη και την ανάλυση μεγάλων συλλογών εγγράφων με βάση τα θέματα τους. Ωστόσο, η προώθηση της κατανόησης των θεμάτων από τους τελικούς χρήστες παραμένει ανοικτό ερευνητικό πρόβλημα. Συγκρίνουμε ετικέτες που παράγονται από χρήστες που έχουν δώσει τέσσερις τεχνικές απεικόνισης θεμάτων-λίστες λέξεων, λίστες λέξεων με γραμμές, σύννεφα λέξεων και γραφήματα δικτύου-μεταξύ τους και με ετικέτες που δημιουργούνται αυτόματα. Η βάση σύγκρισης μας είναι οι αξιολογήσεις των συμμετεχόντων για το πόσο καλά οι ετικέτες περιγράφουν έγγραφα από το θέμα. Η μελέτη μας έχει δύο φάσεις: μια φάση επισήμανσης όπου οι συμμετέχοντες επισημαίνουν οπτικοποιημένα θέματα και μια φάση επικύρωσης όπου οι διαφορετικοί συμμετέχοντες επιλέγουν ποιες ετικέτες περιγράφουν καλύτερα τα έγγραφα των θεμάτων. Παρόλο που όλες οι απεικονίσεις παράγουν παρόμοιες ετικέτες ποιότητας, οι απλές απεικονίσεις, όπως οι λίστες λέξεων, επιτρέπουν στους συμμετέχοντες να κατανοήσουν γρήγορα θέματα, ενώ οι σύνθετες απεικονίσεις χρειάζονται περισσότερο χρόνο, αλλά εκθέτουν εκφράσεις πολλών λέξεων που οι απλούστερες απεικονίσεις αποκρύπτουν. Οι αυτόματες ετικέτες παραμένουν πίσω από τις ετικέτες που δημιουργούνται από τον χρήστη, αλλά το σύνολο δεδομένων μας με μη αυτόματο τρόπο επισημαίνει γλωσσικά μοτίβα (π.χ. υπερνύματα, φράσεις) που μπορούν να χρησιμοποιηθούν για τη βελτίωση των αλγόριθμων αυτόματης σήμανσης θεμάτων.', 'ms': 'Probabilistic topic models are important tools for indexing, summarizing, and analyzing large document collections by their themes.  Namun, mempromosikan pemahaman pengguna akhir topik tetap masalah penyelidikan terbuka. Kami membandingkan label yang dijana oleh pengguna yang diberikan empat senarai teknik-perkataan visualisasi topik, senarai perkataan dengan bar, awan perkataan, dan graf rangkaian-melawan satu sama lain dan melawan label yang dijana secara automatik. Asas perbandingan kami adalah nilai peserta bagaimana baik label menggambarkan dokumen dari topik. Ujian kami mempunyai dua fasa: fasa label dimana peserta label topik yang dipaparkan dan fasa pengesahihan dimana peserta yang berbeza memilih label yang terbaik menggambarkan dokumen topik. Walaupun semua visualisasi menghasilkan label kualiti yang sama, visualisasi sederhana seperti senarai perkataan membolehkan peserta memahami topik dengan cepat, sementara visualisasi kompleks mengambil masa lebih lama tetapi mengekspos ungkapan berbilang perkataan yang visualisasi sederhana tidak kelihatan. Label automatik tertinggal di belakang label yang dicipta oleh pengguna, tetapi set data topik yang ditabel secara manual menyatakan corak bahasa (cth., hipernim, frasa) yang boleh digunakan untuk meningkatkan algoritma penabel topik automatik.', 'ml': 'സാധ്യതയുള്ള പ്രമേയത്തിന്റെ മോഡലുകള്\u200d സൂക്ഷിക്കുന്നതിനും ശ്രദ്ധിക്കുന്നതിനും പ്രധാനപ്പെട്ട ഉപകരണങ്ങളാണ്. അവരുടെ പ എന്നാലും, വിഷയങ്ങളുടെ അവസാന ഉപയോക്താവിന്\u200dറെ ബുദ്ധിമുട്ടാക്കുന്നത് തുറന്ന പരിശോധന പ്രശ്നമാണ നാലു പ്രധാനപ്പെട്ട വാക്കുകളുടെ പട്ടികയില്\u200d നിന്നും വാക്കുകളുടെ പട്ടിക, വാക്കുകളുടെ പട്ടിക, വാക്കുകളുടെ മേഘങ്ങള്\u200d, നെറ്റോര്\u200dനെറ്റ് ഗ്രാഫ് നമ്മുടെ താരതമ്യം നമ്മുടെ അടിസ്ഥാനമാണ് ഈ വിഷയത്തില്\u200d നിന്ന് എത്ര നല്ല രേഖകള്\u200d വിവരിച്ചുകൊടുക്കുന്നത്. ഞങ്ങളുടെ പഠനത്തില്\u200d രണ്ടു പ്രയോഗങ്ങളുണ്ട്: പങ്കാളികളുടെ പ്രമേയങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്ന പ്രമേയങ്ങളും വ്യത്യസ്തമായ വിഭിന്ന പങ്കാളി വാക്കുകളുടെ പട്ടികയില്\u200d പങ്കാളികള്\u200dക്ക് വേഗത്തില്\u200d മനസ്സിലാക്കാന്\u200d സാധ്യതയുള്ള കാഴ്ചകള്\u200d കൊടുക്കാന്\u200d അനുവദിക്കുകയാണെങ്കിലും സങ്കീര്\u200dണ്ണമായ കാഴ്ചകള്\u200d കൂ ഉപയോക്താവിന്റെ സൃഷ്ടിക്കപ്പെട്ട ലേബുകളുടെ പിന്നില്\u200d തന്നെ ചിട്ടപ്പെടുത്തിയിരിക്കുന്നു. പക്ഷെ നമ്മുടെ ഡാറ്റാസേറ്റ് കൈയ്യൂട്ടില്\u200d ചെയ്തിട്ടുള്ള പ്രമേ', 'mt': 'Il-mudelli tematiċi probabbli huma għodod importanti għall-indiċjar, is-sommarju u l-analiżi ta’ kollezzjonijiet kbar ta’ dokumenti skont it-temi tagħhom. Madankollu, il-promozzjoni tal-fehim tal-utenti finali dwar is-suġġetti tibqa’ problema miftuħa ta’ riċerka. Aħna nqabblu t-tikketti ġġenerati mill-utenti mogħtija erba’ listi ta’ kliem-tekniki ta’ viżwalizzazzjoni suġġetti, listi ta’ kliem b’vireg, clouds tal-kliem, u grafiċi tan-netwerk ma’ xulxin u ma’ tikketti ġġenerati awtomatikament. Il-bażi tagħna tat-tqabbil hija l-klassifikazzjonijiet tal-parteċipanti ta’ kif it-tikketti jiddeskrivu tajjeb id-dokumenti mis-suġġett. L-istudju tagħna għandu żewġ fażijiet: fażi ta’ tikkettar fejn il-parteċipanti tikkettaw suġġetti viżwalizzati u fażi ta’ validazzjoni fejn parteċipanti differenti jagħżlu liema tikketti jiddeskrivu l-a ħjar id-dokumenti tas-suġġetti. Għalkemm il-viżwalizzazzjonijiet kollha jipproduċu tikketti ta’ kwalità simili, viżwalizzazzjonijiet sempliċi bħal-listi tal-kliem jippermettu lill-parteċipanti jifhmu malajr is-suġġetti, filwaqt li viżwalizzazzjonijiet kumplessi jieħdu aktar żmien iżda jesponu espressjonijiet b’ħafna kliem li viżwalizzazzjonijiet sempliċi ma jidhrux. It-tikketti awtomatiċi jmorru lura g ħat-tikketti maħluqa mill-utent, iżda s-sett tad-dejta tagħna ta’ suġġetti ttikkettati manwalment jenfasizza xejriet lingwistiċi (e ż. iperinimi, frażijiet) li jistgħu jintużaw biex jittejbu l-algoritmi tat-tikkettar awtomatiku tas-suġġetti.', 'pl': 'Prawdopodobne modele tematów są ważnymi narzędziami do indeksowania, podsumowywania i analizy dużych zbiorów dokumentów według ich tematów. Jednak promowanie zrozumienia tematów przez użytkowników końcowych pozostaje otwartym problemem badawczym. Porównujemy etykiety generowane przez użytkowników z czterema technikami wizualizacji tematów – listy słów, listy słów z paskami, chmury słów i wykresy sieciowe – ze sobą i z automatycznie generowanymi etykietami. Naszą podstawą porównania są oceny uczestników tego, jak dobrze etykiety opisują dokumenty z tematu. Nasze badanie ma dwie fazy: fazę etykietowania, w której uczestnicy oznaczają wizualizowane tematy oraz fazę walidacji, w której różni uczestnicy wybierają etykiety najlepiej opisują dokumenty tematów. Chociaż wszystkie wizualizacje produkują podobne etykiety jakości, proste wizualizacje, takie jak listy słów, pozwalają uczestnikom szybko zrozumieć tematy, podczas gdy złożone wizualizacje trwają dłużej, ale ujawniają wyrażenia wielu słów, które prostsze wizualizacje zasłaniają. Automatyczne etykiety pozostają za etykietami tworzonymi przez użytkownika, ale nasz zestaw danych ręcznie etykietowanych tematów podkreśla wzorce językowe (np. hipernimy, frazy), które można wykorzystać do ulepszenia automatycznych algorytmów etykietowania tematów.', 'ro': 'Modelele de subiecte probabilistice sunt instrumente importante pentru indexarea, rezumarea și analiza colecțiilor mari de documente după temele lor. Cu toate acestea, promovarea înțelegerii subiectelor de către utilizatorii finali rămâne o problemă deschisă de cercetare. Comparăm etichetele generate de utilizatorii cu patru tehnici de vizualizare a subiectelor – liste de cuvinte, liste de cuvinte cu bare, nori de cuvinte și grafice de rețea – unul împotriva celuilalt și împotriva etichetelor generate automat. Baza noastră de comparație este evaluarea participanților la modul în care etichetele descriu documentele din subiect. Studiul nostru are două faze: o fază de etichetare în care participanții etichetează subiectele vizualizate și o fază de validare în care diferiți participanți selectează care etichete descriu cel mai bine documentele subiectelor. Deși toate vizualizările produc etichete de calitate similare, vizualizările simple, cum ar fi listele de cuvinte, permit participanților să înțeleagă rapid subiectele, în timp ce vizualizările complexe durează mai mult, dar expun expresii cu mai multe cuvinte pe care vizualizările simple le obscură. Etichetele automate rămân în urma etichetelor create de utilizatori, dar setul nostru de date de subiecte etichetate manual evidențiază modele lingvistice (de exemplu, hipernime, fraze) care pot fi utilizate pentru a îmbunătăți algoritmii automați de etichetare a subiectelor.', 'mn': 'Магадгүй сэдвийн загварууд нь тэдний сэдвээр том баримт цуглуулалтыг индекс, хуваалцах, шинжилгээ хийх чухал хэрэгсэл юм. Гэхдээ эцсийн хэрэглэгчдийн сэдвийг ойлгохын тулд нээлттэй судалгааны асуудал болно. Бид хэрэглэгчид бүтээгдэхүүний 4 сэдэв үзүүлэлтийн техник-үгний жагсаалт, үгний жагсаалт, үгний үүл, сүлжээний графикийг харьцуулж байна. Бидний харьцуулахын тулд оролцогчдын түвшин нь сэдвээс баримтуудыг хэрхэн сайн тайлбарлаж байгааг харьцуулахын тулд. Бидний судалгаанд хоёр этаж байгаа: хүмүүсийн харилцааны сэдэв болон шийдвэрлэх этаж, олон оролцогчдын сэдэв баримтуудыг хамгийн сайн тайлбарлаж байгаа тэмдэглэх этаж байна. Хэдийгээр бүх төсөөлөлтийн шинжлэх ухаан нь адилхан чанартай тэмдэглэгддэг ч гэсэн, үгний жагсаалт шинжлэх ухаан нь оролцогчдыг хурдан ойлгох боломжтой болгодог. Гэхдээ нарийн төсөөлөлтийн илэрхийлэл илэрхийлэгддэг олон ү Хэрэглэгчдийн бүтээгдэхүүний жагсаалтын ард автоматтын жагсаалтын загваруудын хэл хэлбэрийн загваруудыг (жишээ нь гиперним, хэлбэрүүдийг) автоматтын загваруудын алгоритмыг сайжруулахад ашиглаж болно.', 'no': 'Sannsynleg temamodeller er viktige verktøy for indeksering, samansering og analysering av store dokumentsamlingar ved temaene sine. Dette er imidlertid eit opna forskningsproblem for å forstå sluttbrukaren om emne. Vi samanliknar etikettar laga av brukarar som gjev fire tema visualisering av ordlister, ordlister med linjer, ordskålar og nettverksgrafikk mot kvarandre og mot automatisk laga etikettar. Grunnlegget vårt for sammenlikning er deltakarane av kor godt merkelapp skildrar dokument frå emnet. Studeret vårt har to fasar: ein merkelapp der deltakarane merker visualiserte emne og ein validasjonsfase der ulike deltakarane veljer kva merkelapp best beskriver emnedokumentene. Selv om alle visualiseringane produserer liknande kvalitetsmarker, kan enkle visualiseringar som ordlister gjera deltakarar raskt å forstå emne, mens komplekse visualiseringar tar lengre, men eksponerar fleire ord-uttrykk som enklare visualiseringar er uskyrke. Automatiske merkelappar ligg bak brukarappretta merkelappar, men vår datasett av manuelt merkelige emner markerer lingviske mønsterer (f.eks. hypernymar, frasar) som kan brukast for å forbetra automatisk temamerkelappar.', 'sr': 'Verovatno su modeli teme važni alati za indeksiranje, sažetanje i analiziranje velikih kolekcija dokumenta po njihovim temama. Međutim, unapređenje konačnog korisnika razumevanja tema ostaje otvoren istraživački problem. Uspoređujemo etikete koje su napravljene korisnicima pružale četiri liste tehnika vizualizacije teme, liste reči sa rečima sa rečima, rečima oblacima i mrežnim graficama jedni protiv druge i protiv automatskih proizvedenih etiketa. Naša osnova usporedbe je ocjena učesnika kako dobro etikete opisuju dokumente iz teme. Naša studija ima dve faze: faza etiketiranja u kojoj učesnici etiketiraju vizualizirane teme i fazu validacije u kojoj različiti učesnici odaberu koje etikete najbolje opisuju dokumente teme. Iako sve vizualizacije proizvode slične etikete kvalitete, jednostavne vizualizacije poput listi reèi omogućavaju učesnicima da brzo razumeju teme, dok kompleksni vizualizacije traju duže, ali izlože višeriječne izraze koje jednostavnije vizualizacije zaštite. Automatske etikete ostaju iza etiketa koji su stvoreni korisnicima, ali naša grupa podataka o ručno označenim temama istaknuje jezičke obrasce (npr. hipernima, fraze), koje se mogu koristiti za poboljšanje algoritma označavanja automatskih tema.', 'si': 'සංභාවිත විදේශ මොඩේල්ස් තමයි සංකේෂණය, සංකේෂණය, විශේෂණය සහ විශේෂණය කරන්න වැදගත් විදියට විශේෂය නමුත්, අවසාන ප්\u200dරයෝජකයේ ප්\u200dරශ්නයක් තේරුම් ගන්න ප්\u200dරශ්නයක් තියෙනවා. අපි ප්\u200dරයෝජකයෙන් විද්\u200dයාපෘති විද්\u200dයාපෘති විද්\u200dයාපෘති විද්\u200dයාපෘති විද්\u200dයාපෘති විද්\u200dයාපෘති විද්\u200dයාපෘති හතරයි, ව අපේ පරීක්ෂණයේ ප්\u200dරමාණය තමයි ප්\u200dරමාණයෙන් විදිහට ලේබල් වලින් ලේබල් වලින් කොච්චර හොඳ විස්තර කරන් Name හැම දැක්කම් වගේ ප්\u200dරශ්ණතාවක් ලේබෙල් විදියට, සරල ප්\u200dරශ්ණතාවක් වගේ වචන ලැයිස්තුවක් සමහර විදියට ප්\u200dරශ්ණතාවක් ඉක්මනින්ම තේරුම් ග ස්වයංක්\u200dරියාත්මක ලේබල් සිර්මාණය කරපු ලේබල් පස්සේ ස්වයංක්\u200dරිය ලේබල් සැකයි, නමුත් අපේ දත්ත සැකයි ස්වයංක්\u200dරියාත්මක විදිහට භාෂාවික', 'so': 'Tusaaladaha mada suurtagalka ah waa qalabka muhiimka ah ee la xiriiro, soo bandhigi karo iyo baaritaanka heshiiska dukumentiyada waaweyn ee ku qoran. Si kastaba ha ahaatee horumarinta garashada dhamaadka ee maadooyinka waxaa jirta dhibaato furan oo la xiriira waxbarashada. Waxaynu isbarbardhignaa calaamado ay isticmaalayaasha ka soo bandhigtay afar maamul oo ay ku qoran yihiin xarunta sawirada word-word, word list with bars, daruuro, and shabakadda sawirada qaarkood ka gees ah iyo si automatic ah loo sameeyo alaabta. Our basis of comparison is participant ratings of how well labels describe documents from the topic.  Waxbarashada waxbarashadu waxay leedahay laba marxaladood: marxalad warqadda lagu qorayo, kaas oo ay ka qeybqaadatay macluumaad la fiiriyey iyo fasax la xaqiijiyey oo ay ka doortaan calaamado kala duduwan oo ku qoran dukumentiyada mada. In kastoo ay aragtida oo dhammu soo saaraan calaamado isku mid ah, waxaa ka muuqata aragtida fudud sida qoraalka la yidhaahdo, kuwa ka qayb gala waxay u raadsan yihiin inay dhaqso u fahamaan maadooyinka, isla markaasna ay aragtida complex u qaadan yihiin in ay sii dheeraadaan laakiin ay muujiyaan hadal badan oo ay fudud u muuqato aragtida. Calaamada fara-dhaqso ah waxaa ku yaala calaamada lagu sameeyay e e isticmaalayaasha, laakiin sawirkayada macluumaadka lagu qoray ay ay ka muuqataa tilmaamaha luuqadda (tusaale ahaan hypernyms, phrases) oo loo isticmaali karo si loo hagaajiyo maamulka laga qoro algorithm.', 'ta': 'முக்கியமான தலைப்பு மாதிரிகள் சுட்டுதல், சுருக்குதல், மற்றும் பெரிய ஆவண தொகுப்புகளை அவற்றின் தலைப்புகளால் ஆய்வு. ஆயினும், தலைப்புகளின் முடிவு பயனர் புரிந்து கொள்வது திறந்த ஆய்வு பிரச்சனையாக இருக்கிறது. நாம் பயனர்களால் உருவாக்கப்பட்ட சிட்டைகளை ஒப்பிடுகிறோம் நான்கு தலைப்புகள் பார்வைப்படுத்தல் தொழில்நுட்ப பட்டியல், வார்த்தைகள், மேகங்கள் மற்றும்  எங்கள் ஒப்பிடும் அடிப்படையில் சிட்டைகள் எவ்வளவு நன்றாக விவரிக்கும் ஆவணங்களை விளக்குகிறது. எங்கள் ஆராய்ச்சியில் இரண்டு வகுப்புகள் உள்ளது: குறிப்பிட்ட தலைப்புகளில் பங்கீட்டாளர்கள் பார்க்கப்பட்ட தலைப்புகளை மற்றும் ஒரு செல்லுபடியாக அனைத்து பார்வைகளும் சமமான தரம் குறியீடுகளை உருவாக்கும் போதும், சொல்ல பட்டியல்கள் போன்ற சுலபமான பார்வைகளை புரிந்து கொள்ளும், சிக்கலான பார்வைகள் நீண்டு பயனர் உருவாக்கப்பட்ட சிட்டைகளின் பின்னால் தானாகவே சிட்டைகள் வைக்கப்பட்டது, ஆனால் எங்கள் தரவு அமைப்பு கைமுறையாக குறிக்கப்பட்ட தலைப்புகளின் மொழிகளை முன்னிலைப்படுத்து', 'ur': 'امکان داری ٹوپ موڈل ان کے ٹیموں کے ذریعے بڑے ڈوکیم کالکونٹ کی تحلیل کرنے کے لئے اہم ابزار ہیں۔ لیکن تمام کارساز کے متعلق سمجھنے کی پیدائش صرف ایک کھلی تحقیق مشکل ہے۔ ہم نے چار ٹوپ ویزئنالیز ٹیکنیک لکھ دیے ہوئے لیبلوں کی مقایسہ کیا ہے، کلمات لکھ بار، کلمات ابر، اور نیٹ ورک گراف ایک دوسرے کے مقابلہ میں اور خود پیدا کیے ہوئے لیبلوں کے مقابلہ میں۔ ہماری مقایسہ کی بنیاد یہ ہے کہ موضوع سے لکھنے والوں کی نسخہ کس طرح اچھی طرح بیان کرتی ہے۔ ہمارے مطالعہ میں دو فائز ہیں: ایک لابلینگ فائز ہے جہاں شرکت کرنے والوں نے دکھائی ہوئی موضوع کو لیبل کر دیا ہے اور ایک والیڈیٹ فائز ہے جہاں مختلف شرکت کرنے والوں نے انتخاب کر لیا ہے کہ کون لابلینگ بہترین موضوع کے دکھائے اگرچہ تمام تصویزیزوں برابر کیفیت لیبل پیدا کرتی ہیں، ساده تصویزیزوں جیسے کلمات لیسٹ شرکت کرنے والوں کو سریع سمجھنے کی اجازت دیتی ہیں، حالانکہ پیچیدہ تصویزیزوں بہت زیادہ طول اٹھاتے ہیں لیکن بہت سی کلمات کی تصویزیزوں کو ظاہر کرتی ہیں جو سا استعمال کی بنائی لابل کے پیچھے خپلکاری لابل چھوڑ رہے ہیں، لیکن ہماری ڈیٹسٹ کے ذریعے لابل کیا گیا ٹوپ کے ذریعے زبانی پٹرنے (جیسے ہیرنیم، فریزے) کو ہیلایت کرتا ہے جن کو استعمال کر سکتا ہے اتمام ٹوپ لیبل الگوریٹم کے لئے است', 'sv': 'Probabilistiska ämnesmodeller är viktiga verktyg för indexering, sammanfattning och analys av stora dokumentsamlingar utifrån deras teman. Att främja slutanvändarnas förståelse av ämnen är dock fortfarande ett öppet forskningsproblem. Vi jämför etiketter som genereras av användare med fyra ämnesvisualiseringstekniker – ordlistor, ordlistor med staplar, ordmoln och nätverksgrafer – mot varandra och mot automatiskt genererade etiketter. Vår grund för jämförelse är deltagarnas betyg på hur väl etiketter beskriver dokument från ämnet. Vår studie har två faser: en märkningsfas där deltagarna markerar visualiserade ämnen och en valideringsfas där olika deltagare väljer vilka etiketter som bäst beskriver ämnenas dokument. Även om alla visualiseringar ger liknande kvalitetsetiketter, gör enkla visualiseringar som ordlistor det möjligt för deltagarna att snabbt förstå ämnen, medan komplexa visualiseringar tar längre tid men exponerar flerordsuttryk som enklare visualiseringar döljer. Automatiska etiketter släpar efter användarskapade etiketter, men vår dataset med manuellt märkta ämnen belyser språkliga mönster (t.ex. hypernymer, fraser) som kan användas för att förbättra automatiska ämnesmärkningsalgoritmer.', 'uz': "Name Lekin, mavzularning oxirigi foydalanuvchini o'rganish uchun ochiq qidirish muammosi. Biz foydalanuvchilar bilan ishlatilgan tugmalar birikmasiga kamaytirimiz, soʻzlar roʻyxati, soʻzlar, soʻzlar, va tarmoq grafiklarini birлари bilan birga boshqa shaklga va avtomatik yaratiladigan tegnlarni. Bizning o'xshash asosimiz mavzudagi hujjatlarni qanday yaxshi ko'rinishimiz mumkin. Bizning o'qituvchimizda ikkita daraja bor: Mualliflar mavzularni ko'rinishi va haqiqiqiy fasi bilan boshqa shakllar mavzu hujjatlarini qanday yaxshi belgini tanlash mumkin. Although all visualizations produce similar quality labels, simple visualizations such as word lists allow participants to quickly understand topics, while complex visualizations take longer but expose multi-word expressions that simpler visualizations obscure.  Name", 'vi': 'Mẫu chủ đề rõ rệt là những công cụ quan trọng để mô tả, tóm tắt và phân tích các bộ sưu tập tài liệu lớn theo chủ đề. Tuy nhiên, việc phát triển sự hiểu biết của người dùng cuối về các chủ đề vẫn là vấn đề nghiên cứu. Chúng tôi so sánh các nhãn được tạo ra bởi những người dùng với bốn danh sách các kỹ thuật xuất hiện về chủ đề, các danh sách từ với các thanh, các từ mây, và các đồ thị mạng dựa vào nhau và với các nhãn tự động tạo ra. Cơ sở so sánh của chúng tôi là đánh giá người tham gia về cách nhãn được mô tả tài liệu từ chủ đề. Nghiên cứu của chúng tôi có hai giai đoạn: một giai đoạn sản xuất nhãn nhãn cho các chủ đề được hình dung và một giai đoạn thẩm định nơi các diễn viên khác nhau chọn các nhãn để đánh giá các tài liệu. Mặc dù tất cả các hình ảnh đều sản xuất nhãn chất lượng tương tự, các hình ảnh đơn giản như danh sách từ cho phép người tham gia nhanh chóng hiểu các chủ đề, trong khi các hình ảnh phức tạp mất nhiều từ lâu hơn, nhưng phơi bày các biểu thức đa từ mà các hình thức đơn giản che mờ. Các nhãn tự động chậm sau các nhãn được tạo bởi người dùng, nhưng nhóm dữ liệu của chúng ta với các chủ đề được đánh dấu bằng tay nhấn mạnh các mô hình ngôn ngữ (v. d. hypernyms, các cụm từ) có thể được dùng để cải tiến các thuật to án đánh dấu chuyên đề.', 'nl': "Probabilistische topic modellen zijn belangrijke hulpmiddelen voor het indexeren, samenvatten en analyseren van grote documentcollecties op hun thema's. Het bevorderen van het begrip van onderwerpen door eindgebruikers blijft echter een open onderzoeksprobleem. We vergelijken labels gegenereerd door gebruikers met vier technieken voor visualisatie van onderwerpen – woordlijsten, woordlijsten met balken, woordwolken en netwerkgrafieken – met elkaar en met automatisch gegenereerde labels. Onze basis voor vergelijking is deelnemersbeoordelingen van hoe goed labels documenten uit het onderwerp beschrijven. Ons onderzoek heeft twee fasen: een etiketteringsfase waarin deelnemers gevisualiseerde onderwerpen labelen en een validatiefase waarin verschillende deelnemers selecteren welke labels de documenten van de onderwerpen het beste beschrijven. Hoewel alle visualisaties vergelijkbare kwaliteitslabels produceren, stellen eenvoudige visualisaties, zoals woordenlijsten deelnemers in staat om onderwerpen snel te begrijpen, terwijl complexe visualisaties langer duren, maar expressies uit meerdere woorden blootleggen die eenvoudigere visualisaties verduisteren. Automatische labels blijven achter op door gebruikers gemaakte labels, maar onze dataset van handmatig gelabelde onderwerpen benadrukt taalpatronen (bijv. hyperniemen, zinnen) die kunnen worden gebruikt om automatische labelingsalgoritmen voor onderwerpen te verbeteren.", 'da': 'Probabilistiske emnemodeller er vigtige værktøjer til indeksering, opsummering og analyse af store dokumentsamlinger efter deres temaer. Men fremme af slutbrugernes forståelse af emner er fortsat et åbent forskningsproblem. Vi sammenligner etiketter genereret af brugere med fire temavisualiseringsteknikker – ordlister, ordlister med streger, ordskyer og netværksgrafer – mod hinanden og mod automatisk genererede etiketter. Vores sammenligningsgrundlag er deltagernes vurderinger af, hvor godt etiketter beskriver dokumenter fra emnet. Vores undersøgelse har to faser: en mærkningsfase, hvor deltagerne mærker visualiserede emner, og en valideringsfase, hvor forskellige deltagere vælger, hvilke etiketter der bedst beskriver emnernes dokumenter. Selvom alle visualiseringer producerer lignende kvalitetsetiketter, giver enkle visualiseringer såsom ordlister deltagerne mulighed for hurtigt at forstå emner, mens komplekse visualiseringer tager længere tid, men afslører flere ord udtryk, som enklere visualiseringer skjuler. Automatiske etiketter halter bagefter brugerskabte etiketter, men vores datasæt af manuelt mærkede emner fremhæver sproglige mønstre (f.eks. hypernymer, sætninger), der kan bruges til at forbedre automatiske emnemærkningsalgoritmer.', 'bg': 'Вероятните тематични модели са важни инструменти за индексиране, обобщаване и анализ на големи колекции от документи по техните теми. Въпреки това насърчаването на разбирането на темите от крайните потребители остава отворен изследователски проблем. Сравняваме етикетите, генерирани от потребители на четири техники за визуализация на теми – списъци с думи, списъци с думи с ленти, облаци от думи и мрежови графики – един срещу друг и срещу автоматично генерирани етикети. Нашата база за сравнение е оценката на участниците колко добре етикетите описват документите по темата. Нашето проучване има две фази: фаза на етикетиране, при която участниците етикетират визуализираните теми и фаза на валидиране, при която различните участници избират кои етикети описват най-добре документите на темите. Въпреки че всички визуализации произвеждат подобни етикети за качество, простите визуализации като списъци с думи позволяват на участниците бързо да разбират темите, докато сложните визуализации отнемат повече време, но разкриват многословни изрази, които по-простите визуализации затъмняват. Автоматичните етикети изостават от създадените от потребителите етикети, но нашият набор от данни от ръчно етикетирани теми подчертава езиковите модели (например хиперними, фрази), които могат да бъдат използвани за подобряване на алгоритмите за автоматично етикетиране на темите.', 'de': 'Probabilistische Themenmodelle sind wichtige Werkzeuge, um große Dokumentensammlungen nach ihren Themen zu indexieren, zusammenzufassen und zu analysieren. Die Förderung des Themenverständnisses der Endnutzer bleibt jedoch ein offenes Forschungsproblem. Wir vergleichen Labels, die von Benutzern mit vier Visualisierungstechniken generiert wurden – Wortlisten, Wortlisten mit Balken, Wortwolken und Netzwerkgrafiken – miteinander und mit automatisch generierten Labels. Unsere Vergleichsgrundlage sind Teilnehmerbewertungen, wie gut Etiketten Dokumente aus dem Thema beschreiben. Unsere Studie hat zwei Phasen: eine Etikettierungsphase, in der Teilnehmer visualisierte Themen markieren und eine Validierungsphase, in der verschiedene Teilnehmer auswählen, welche Etiketten die Dokumente der Themen am besten beschreiben. Obwohl alle Visualisierungen ähnliche Gütesiegel produzieren, ermöglichen einfache Visualisierungen wie Wortlisten den Teilnehmern, Themen schnell zu verstehen, während komplexe Visualisierungen länger dauern, aber mehrwortige Ausdrücke offenlegen, die einfachere Visualisierungen verdecken. Automatische Beschriftungen liegen hinter benutzerdefinierten Beschriftungen zurück, aber unser Datensatz manuell beschrifteter Themen hebt sprachliche Muster (z. B. Hypernyme, Phrasen) hervor, die verwendet werden können, um automatische Beschriftungsalgorithmen zu verbessern.', 'id': 'Model topik kemungkinan adalah alat penting untuk mengindeks, merekam, dan menganalisis koleksi dokumen besar dengan tema mereka. Namun, mempromosikan pemahaman pengguna akhir topik tetap masalah penelitian terbuka. Kami membandingkan label yang dihasilkan oleh pengguna yang diberikan empat daftar kata-teknik visualisasi topik, daftar kata dengan bar, awan kata, dan grafik jaringan-melawan satu sama lain dan melawan label yang dihasilkan secara otomatis. Pangkalan perbandingan kami adalah nilai peserta betapa baik label menggambarkan dokumen dari topik. Studi kami memiliki dua fase: fase label dimana para peserta label topik yang ditampilkan dan fase validasi dimana para peserta yang berbeda memilih label yang terbaik menggambarkan dokumen topik. Although all visualizations produce similar quality labels, simple visualizations such as word lists allow participants to quickly understand topics, while complex visualizations take longer but expose multi-word expressions that simpler visualizations obscure.  Label otomatis tertinggal di belakang label yang dibuat oleh pengguna, tetapi dataset kami topik yang ditabel secara manual mempertimbangkan pola bahasa (contohnya, hipernim, frasa) yang dapat digunakan untuk meningkatkan algoritma penabel topik otomatis.', 'sw': 'Probabilistic topic models are important tools for indexing, summarizing, and analyzing large document collections by their themes.  Hata hivyo, kukuza uelewa wa mtumiaji wa mwisho wa mada bado ni tatizo la utafiti ulio wazi. Tunawalinganisha alama zilizotengenezwa na watumiaji waliopewa orodha ya teknolojia nne za kuonyesha mada, orodha ya maneno yenye mabango, mawingu, na picha za mitandao yanayopigana na wao wenyewe na dhidi ya maabara zilizotengenezwa automatically. Msingi wetu wa kulinganisha ni kushiriki kiasi gani alama vizuri vinavyoelezea nyaraka kutoka mada hiyo. Utafiti wetu una hatua mbili: jukwaa la maabara ambapo washiriki wanaelezea mada zinazoonyesha na jukwaa la uhakika ambapo washiriki tofauti wanachagua alama zipi bora za kuelezea nyaraka za mada hizo. Ingawa maoni yote yanaleta alama kama hizo, mitazamo rahisi kama vile orodha ya maneno yanaruhusu washiriki kuelewa mada haraka, wakati maoni magumu yanachukua muda mrefu lakini yanaonyesha hisia za maneno mengi ambazo ni rahisi za kuona. Alama za kujitegemea zinaweka nyuma ya mabango yaliyotengenezwa na watumiaji, lakini seti ya taarifa yetu ya mada zinazoonyesha mitindo ya lugha (kwa mfano, hypernyms, maneno) ambayo inaweza kutumika kuboresha mada ya kujitegemea yenye utambulisho wa algorithi.', 'ko': '확률 주제 모델은 주제에 따라 대형 문서집을 인덱스, 정리, 분석하는 중요한 도구이다.그러나 최종 사용자가 주제에 대한 이해를 촉진하는 것은 여전히 개방적인 연구 문제이다.우리는 사용자가 네 가지 주제의 시각화 기술로 생성한 라벨 - 단어 목록, 스트라이프가 있는 단어 목록, 단어 클라우드와 네트워크 그림 - 서로 비교하고 자동으로 생성된 라벨과 비교할 것이다.우리가 비교한 기초는 참여자가 라벨에 대해 주제 문서를 어떻게 묘사하는지에 대한 평점이다.우리의 연구는 두 단계로 나뉜다. 하나는 태그 단계이고 참여자는 시각화된 주제를 표시하며 다른 하나는 검증 단계이다. 서로 다른 참여자는 주제 문서를 가장 잘 묘사할 수 있는 라벨을 선택한다.모든 시각화는 유사한 품질 라벨을 만들어 낼 수 있지만 간단한 시각화(예를 들어 단어 목록)는 참가자들이 주제를 빠르게 이해할 수 있고 복잡한 시각화는 더 오랜 시간이 걸리지만 여러 단어의 표현이 드러나고 간단한 시각화는 사람들로 하여금 똑똑히 볼 수 없게 한다.자동 태그는 사용자가 만든 태그보다 뒤떨어지지만 수동 태그 주제 데이터 세트는 자동 주제 태그 알고리즘을 개선하는 데 사용할 수 있는 언어 모드(예: 하이퍼단어, 구문)를 강조합니다.', 'tr': 'Mümkin möhüm tema nusgalary temalarynda indeks edip, sumlaşdyrmak we uly sened toplamlaryny tarapynda möhüm aletler. Ýagna görä, soňky ulançylaryň temalaryň düşünmesini töweklemek açyk araşdyrma meselesi. Biz ulananlar tarapyndan dört tema görkezilýän etiketleri, kelime listleri barlar, söz bulutlar we şebek grafikleri birbirine garşy we otomatik üretilen etiketlere garşy görýäris Biziň karşılaştyryşymyz temadan nähili gowy etitler tassyklandyrýandygy hasaplanjak düzümlerdedir. Biziň araşdyrymyzyň iki fazy bar: iştirakçiler meýdançalary görkezilýän meýdançalary we bellenen meýdançalary tarapynda nähili etiketleriň gowy görkezilýän meýdançalary saýlaýarlar. Hemme görseller meňzeş kalit etiketlerini üretýär bolsa hem basit görseller bolsa sözler listleri çalt meňzeşleri düşünmesine rugsat berýärler, karmaşık görseller uzak wagtlar ýöne diňleýän görselleri örän basit söz edip görünýärler. Ullançy üçin otomatik etiketler ullanýan etiketleriň arkasynda ýaşaýar, ýöne öz etiketlerimiz etiketleriň üstine ýagtylamaky üçin ullanýar.', 'af': "Waarskynlik onderwerp modelles is belangrik nutsprogramme vir indeksering, opsomming en analisering van groot dokumentsamlings deur hul temas. Maar die bevorder van einde-gebruiker verstanding van onderwerpe bly 'n oopgemaakte onderwerp probleem. Ons vergelyk etikette genereer deur gebruikers wat vier onderwerp visualisering teknike-woorde lyste gegee het, woorde lyste met balke, woord wolke en netwerk graaf-teen mekaar en teen automaties genereerde etikette. Ons basis van vergelyking is deelnadeerde belangrikings van hoe goed etikette beskryf dokumente van die onderwerp. Ons studie het twee fase:  'n etiket fase waar deelnaders etiket visualiseerde onderwerpe en 'n geldigheidstasie fase waar verskillende deelnaders kies wat etikette beste beskryf die onderwerpe se dokumente. Alhoewel alle visualiserings gelyke kwaliteit etikette produseer, eenvoudige visualiserings soos woorde lyste toelaat deelnaders vinnig onderwerpe te verstaan, terwyl komplekse visualiserings langer maar multiwoorde uitdrukkings uitdruk wat eenvoudiger visualiserings onderwerp is. Outomatiese etikette laat agter gebruiker- geskepe etikette, maar ons datastel van hand-etikette onderwerpe verlig lingwisiese patrone (bv. hypernyms, frases) wat kan gebruik word om outomatiese onderwerp etiketting algoritme te verbeter.", 'sq': 'Modelet e temës së mundshme janë mjete të rëndësishme për indeksimin, përmbledhjen dhe analizimin e koleksioneve të mëdha të dokumenteve nga temat e tyre. Megjithatë, nxitja e kuptimit të temave nga përdoruesit përfundimtar mbetet një problem i hapur kërkimi. We compare labels generated by users given four topic visualization techniques-word lists, word lists with bars, word clouds, and network graphs-against each other and against automatically generated labels.  Baza jonë e krahasimit është vlerësimi i pjesëmarrësve se sa mirë etiketat përshkruajnë dokumentet nga tema. Studimi ynë ka dy faza: një fazë etiketash ku pjesëmarrësit etiketojnë temat e vizualizuara dhe një fazë validimi ku pjesëmarrësit e ndryshëm zgjedhin cilat etiketa përshkruajnë më mirë dokumentet e temave. Megjithëse të gjitha vizualizimet prodhojnë etiketa të ngjashme cilësie, vizualizime të thjeshta të tilla si listat e fjalëve lejojnë pjesëmarrësit të kuptojnë shpejt temat, ndërsa vizualizimet komplekse zgjasin më shumë por ekspozojnë shprehje me shumë fjalë që vizualizimet më të thjeshta fshehin. Etiketat automatike mbeten pas etiketave të krijuara nga përdoruesit, por grupi ynë i të dhënave të temave të etiketuara manualisht thekson modelet gjuhësore (për shembull hiperinimet, frazat) që mund të përdoren për të përmirësuar algoritmet automatike të etiketuar temave.', 'fa': 'مدلهای موضوع احتمالات مهم برای تنظیم، جمع کردن و تحلیل مجموعه\u200cهای سند بزرگ توسط عنوان آنها است. با این حال، ترفیع درک کاربر پایان از موضوع یک مشکل تحقیقات باز است. ما برچسب\u200cهایی که توسط کاربران تولید شده\u200cاند، چهار برچسب\u200cهای تکنیک\u200cهای ویژه\u200cسازی و کلمه\u200cهای ویژه\u200cسازی مورد داده شده\u200cایم، برچسب\u200cهای کلمه\u200cها با بارها، ابر\u200cهای کلمه، و برچسب\u200cهای شبکه\u200cها با یکدیگ بنیاد مقایسه\u200cمون مقایسه\u200cهای مشترک است که چگونه نقاشی\u200cهای خوب از موضوع سند\u200cها را توصیف می\u200cکنند. مطالعه ما دو مرحله دارد: یک مرحله نقاشی که شرکتگران موضوع تصویر شده را نقاشی می\u200cکنند و یک مرحله تأیید می\u200cکنند که شرکتگران مختلف انتخاب می\u200cکنند کدام نقاشی بهترین نقاشی را نسخه\u200cهای موضوع توصیف می\u200c اگرچه تمام تصویرات برچسب\u200cهای کیفیت مشابه را تولید می\u200cکنند، تصویرات ساده\u200cای مانند لیست\u200cهای کلمات اجازه می\u200cدهند که شرکت\u200cکنندگان سریع موضوع را درک کنند، در حالی که تصویرات پیچیده\u200cها طول\u200cتر می\u200cکشند ولی تعریف\u200cهای چندین کلمات را که تص برچسب\u200cهای خودکار پشت برچسب\u200cهای ساخته شده از کاربر باقی ماند، ولی مجموعه داده\u200cهای ما از موضوع\u200cهای دستی که برچسب شده\u200cاند، الگوریتم\u200cهای زبان\u200cشناسی (مثال hypernyms, phrases) را مشخص می\u200cکند که می\u200cتوانند برای بهتر کردن برچسب\u200cهای موضوع\u200cهای خودکار استفاده', 'hy': 'Հավանական թեմային մոդելները կարևոր գործիքներ են, որոնք օգտագործում են ինդեքսիվորել, համառոտագրել և վերլուծել փաստաթղթերի մեծ հավաքածուները իրենց թեմայով: However, promoting end-user understanding of topics remains an open research problem.  Մենք համեմատում ենք օգտագործողների կողմից ստեղծված պիտակները, որոնք տալիս են չորս թեմային վիզուալիզացիայի տեխնիկա-բառերի ցուցակներ, բառերի ցուցակներ գոտիներով, բառերի ամպեր և ցանցային գրաֆիկներ մեկը մյուսի դեմ և ինք Համեմատության հիմքը մասնակիցների գնահատականներն են այն մասին, թե ինչքան լավ պիտակները նկարագրում են թեմայից փաստաթղթերը: Մեր ուսումնասիրությունը ունի երկու փուլում. մի պիտակում, որտեղ մասնակիցները պիտակում են տեսողական թեմաներ և մի պիտակում, որտեղ տարբեր մասնակիցները ընտրում են թեմաների փաստաթղթերը լավագույնն են նկարագրում: Չնայած բոլոր վիզուալիզացիաները ստեղծում են նման որակային պիտակներ, պարզ վիզուալիզացիաները, ինչպիսիք են բառերի ցուցակները, թույլ են տալիս մասնակիցներին արագ հասկանալ թեմաները, մինչդեռ բարդ վիզուալիզացիաները երկար են տևում, բայց բացահայ Օգտագործողի կողմից ստեղծված պիտակների ետևում են ավտոմատիկ պիտակները, սակայն ձեռքով պիտակների մեր տվյալների համակարգը նշանակում է լեզվական կաղապարները (օրինակ հիպերնիմները, արտահայտությունները), որոնք կարող են օգտագործվել օգտագործելու ավտոմատիկ թեմային պիտակների ալգորիթ', 'am': 'ምናልባት የውይይት አካባቢዎች ምሳሌዎች በጉዳዩ ላይ ማቀናጃ፣ ማጠቃለያ እና ትልቁ ሰነዱን በመጠቀም ያስተካክሉ፡፡ ነገር ግን የመጨረሻ ተጠቃሚ የጉዳዮች ማስተዋል የተከፈተ ምርመራ ጉዳይ ነው፡፡ We compare labels generated by users given four topic visualization techniques-word lists, word lists with bars, word clouds, and network graphs-against each other and against automatically generated labels.  ማሳያየት የጽሑፎች ሰነዱን ከጉዳዩ እንዴት ያህል እንደሚያሳየው ተግባር ነው፡፡ ትምህርታችን ሁለት ደረጃዎች አለበት፤ ተካሪዎቹ ጉዳዮችን እና የተለያዩ ተካኪዎች የጉዳዮችን ሰነዱን በማንኛቸው የበለጠ ምልክቶች የሚምረጡበት የጽሑፍ ደረጃዎች የሚታወቁ ደረጃዎች ናቸው፡፡ ምንም እንኳን ሁሉም ራእዩቶች ብጤት የጥሩ ምልክቶች የሚያደርጉ ቢሆንም፣ ቃላት ዝርዝሮች የሚያስተውሉትን ፈጥኖ እንዲያስተውሉ ቀላል ራእዩቶችን እንዲፈቅዱ ይችላል፤ በተጨማሪም ራእይ ግን የሚያስተውሉ ብዙዎችን ቃላት ያሳስታሉ፡፡ ምልክቶችን በተጠቃሚ የተፈጠሩ ምልክቶች በኋላ ያስተካክሉ፤ ነገር ግን የዳታ ደረጃችን በእጃቸው በተለየ የቋንቋ ዓይነቶች (e.g. hypernyms, phrases) ለመሻለል ይችላል፡፡', 'bn': 'সম্ভবত বিষয়বস্তুর মডেল তাদের থিম দ্বারা সংক্ষেপ, সারসংক্ষিপ্ত এবং বিশ্লেষণ করার জন্য গুরুত্বপূর্ণ টুল। তবে বিষয়গুলোর শেষ ব্যবহারকারীর ব্যাপারে বুঝতে প্রচার করা হচ্ছে একটি উন্মুক্ত গবেষণার সমস্যা। আমরা ব্যবহারকারীদের তৈরি লেবেলের তুলনা করি যা দেখা যাচ্ছে চারটি বিষয়ের দৃশ্যমান প্রযুক্তি-শব্দ তালিকা, শব্দ তালিকা, বার, মেঘ এবং নেটওয়ার্ক গ্রা আমাদের তুলনার ভিত্তিতে এই বিষয় থেকে কত ভালো লেবেল বর্ণনা করা হয়েছে। আমাদের গবেষণা দুটি ক্ষেত্র আছে: একটি লেবেলিং পর্যায়ে যেখানে অংশগ্রহণকারীরা বিষয়গুলো দেখানো হয়েছে এবং একটি বৈধ ক্ষেত্রে যেখানে বিভিন্ন অ Although all visualizations produce similar quality labels, simple visualizations such as word lists allow participants to quickly understand topics, while complex visualizations take longer but expose multi-word expressions that simpler visualizations obscure.  স্বয়ংক্রিয়ভাবে লেবেল ব্যবহারকারী তৈরি করা লেবেলের পেছনে রেখে আছে, কিন্তু আমাদের ডাটাসেট হাতে লেবেল করা বিষয়গুলোর ডাটাসেট ভাষাগত প্যাটারেট উল্লেখ করে (উদাহরণস্', 'az': 'Mümkün olaraq məsələn modelləri məsələləri ilə böyük məsələlər koleksiyonlarını indeksiya, qurğulama və analizi üçün vacib vasitələrdir. Lakin, məsələlərin sonu istifadəçilərin anlaşılması açıq araştırma problemi həmişəlikdir. Biz dörd məsələlər vizualizasyon teknikləri-söz listeləri, barlar, söz bulutları və şəklə grafikləri birbirlərinə qarşı və avtomatik yaratdığı etiketlərə qarşı yaratdığımız etiketləri ilə qarşılaşdırırıq. Bizim qarşılaşdırmağımız məsələdən belələri necə gözəl etiketlər təsbit edirlər. Bizim araşdırmağımız iki fəzi var: iştirakçilərin vizualizasyon məsələlərini və müxtəlif iştirakçilərin məsələlərini ən yaxşı tanımadıqları məsələlərin etiketli fəzi. Bütün vizualizasyonlar bənzər keyfiyyət etiketlərini ürəkləndirməyə rağmen, kelimelər listeləri kimi basit visualizasyonlar iştirakçıların məsələləri tez anlamasına izin verirlər, kompleks vizualizasyonlar uzun sürdür, lakin daha basit visualizasyonlar təhlükəsizlənir. Avtomatik etiketlər istifadəçi yaratdığı etiketlərin arxasında qalar, amma əlli etiketli məsələlərimizin verilənləri dil etiketlərini (məsələlər, hipernimlər, frazlər) avtomatik məsələlər etiketlərini yaxşılaşdırmaq üçün istifadə edə biləcək dil etiketlərini işıqlandırır.', 'ca': "Els models de tema probables són eines importants per a indexar, resumir i analitzar les grans col·leccions de documents segons els seus temas. However, promoting end-user understanding of topics remains an open research problem.  Comparem etiquetes generades pels usuaris amb quatre tècniques de visualització de tema, llistes de paraules amb barres, núvols de paraules i gràfics de xarxa entre ells i amb etiquetes generades automàticament. La nostra base de comparació és la valoració dels participants sobre com les etiquetes descriuen els documents del tema. El nostre estudi té dues fases: una fase d'etiquetar on els participants etiqueten temes visualitzats i una fase de validació on diferents participants seleccionen quines etiquetes descriuen millor els documents dels temes. Tot i que totes les visualitzacions produeixen etiquetes de qualitat similars, visualitzacions simples com les llistes de paraules permeten als participants entendre ràpidament els temes, mentre que les visualitzacions complexes tarden més temps però exposen expressions multiparaules que les visualitzacions simples obscuren. Les etiquetes automàtiques queden darrere de les etiquetes creades per l'usuari, però el nostre conjunt de dades de temes etiquetats manualment destaca patrons lingüístics (per exemple hipernims, frases) que poden ser utilitzats per millorar algoritmes automàtics d'etiquetar temes.", 'cs': 'Pravděpodobnostní tématické modely jsou důležitými nástroji pro indexování, shrnutí a analýzu velkých sbírek dokumentů podle jejich témat. Avšak podpora porozumění tématům koncových uživatelů zůstává otevřeným výzkumným problémem. Porovnáváme štítky generované uživateli se čtyřmi technikami vizualizace témat – seznamy slov, seznamy slov s pruhy, slovní mraky a síťové grafy – proti sobě a s automaticky generovanými štítky. Naším základem srovnání jsou hodnocení účastníků toho, jak dobře etikety popisují dokumenty z daného tématu. Naše studie má dvě fáze: fázi označování, kde účastníci označují vizualizovaná témata, a fázi validace, kde různí účastníci vybírají, které štítky nejlépe popisují dokumenty tématu. Ačkoli všechny vizualizace produkují podobné značky kvality, jednoduché vizualizace, jako jsou seznamy slov, umožňují účastníkům rychle porozumět tématům, zatímco složité vizualizace trvají déle, ale odhalují víceslovné výrazy, které jednodušší vizualizace zastírají. Automatické štítky zaostávají za štítky vytvořenými uživateli, ale náš datový soubor ručně označovaných témat upozorňuje na jazykové vzorce (např. hypernymy, fráze), které lze použít ke zlepšení algoritmů automatického označování témat.', 'bs': 'Vjerojatno su modeli teme važni alati za indeksiranje, sažetanje i analiziranje velikih kolekcija dokumenta po njihovim temama. Međutim, unapređenje konačnog korisnika razumijevanja tema ostaje otvoren istraživački problem. Uspoređujemo etikete koje su proizvedene korisnicima pružene četiri popisa tehnika vizualizacije teme, popis riječi sa rečima sa rečima, rečima oblacima i mrežnim graficama jedan protiv drugog i protiv automatskih proizvedenih etiketa. Naša osnova usporedbe je ocjena učesnika kako dobro etikete opisuju dokumente iz teme. Naša studija ima dvije faze: faza etiketiranja u kojoj učesnici označavaju vizualizirane teme i fazu validacije gdje različiti učesnici odaberu koje etikete najbolje opisuju dokumente teme. Iako sve vizualizacije proizvode slične etikete kvalitete, jednostavne vizualizacije poput popisa riječi omogućavaju učesnicima brzo razumjeti teme, dok kompleksne vizualizacije traju duže, ali izlože višeriječne izraze koje jednostavnije vizualizacije zaštite. Automatske etikete ostaju iza etiketa koji su stvoreni korisnicima, ali naša grupa podataka o ručno etiketiranim temama istaknuje jezičke obrasce (npr. hipernima, fraze) koje se mogu koristiti za poboljšanje algoritma automatičke etikete tema.', 'et': 'Tõenäolised teemamudelid on olulised vahendid suurte dokumendikogude indekseerimiseks, kokkuvõtmiseks ja analüüsimiseks teemade järgi. Kuid lõppkasutajate arusaama edendamine teemadest on jätkuvalt avatud uurimisprobleem. Võrdleme nelja teema visualiseerimise meetodiga kasutajate loodud silte – sõnaloendeid, ribadega sõnaloendeid, sõnaloendeid ja võrgugraafikuid – omavahel ja automaatselt genereeritud siltidega. Meie võrdluse aluseks on osalejate hinnangud selle kohta, kui hästi etiketid kirjeldavad teema dokumente. Meie uuringus on kaks etappi: märgistamise etapp, kus osalejad märgistavad visualiseeritud teemasid, ja valideerimise etapp, kus erinevad osalejad valivad, millised märgistused kirjeldavad teemade dokumente kõige paremini. Kuigi kõik visualiseerimised toodavad sarnaseid kvaliteedimärgiseid, võimaldavad lihtsad visualiseerimised, näiteks sõnaloendid, osalejatel teemasid kiiresti aru saada, samas kui keerukad visualiseerimised võtavad kauem aega, kuid paljastavad mitmesõnalised avaldised, mida lihtsamad visualiseerimised varjavad. Automaatsed sildid jäävad kasutaja loodud sildidest maha, kuid meie käsitsi märgistatud teemade andmekogum toob esile keelelised mustrid (nt hüpernüümid, fraasid), mida saab kasutada automaatse teemamärgistuse algoritmide täiustamiseks.', 'hr': 'Vjerojatno su modeli teme važni alati za indeksiranje, sažetanje i analiziranje velikih kolekcija dokumenta po njihovim temama. Međutim, unapređenje konačnog korisnika razumijevanja tema ostaje otvoren istraživački problem. Uspoređujemo etikete koje su proizvedene korisnicima pružene četiri popisa tehnika vizualizacije teme, popis riječi sa rečima sa rečima, rečima oblacima i mrežnim graficama jedni protiv druge i protiv automatskih proizvedenih etiketa. Naša osnova usporedbe je ocjena učesnika kako dobro etikete opisuju dokumente iz teme. Naše ispitivanje ima dvije faze: faza označavanja u kojoj učesnici označavaju vizualizirane teme i fazu potvrđenja gdje različiti učesnici odaberu koje etikete najbolje opisuju dokumente teme. Iako sve vizualizacije proizvode slične etikete kvalitete, jednostavne vizualizacije poput popisa riječi omogućavaju učesnicima brzo razumjeti teme, dok složene vizualizacije traju duže, ali izlože višeriječne izraze koje jednostavnije vizualizacije zaštite. Automatske etikete ostaju iza etiketa koji su stvoreni korisnicima, ali naša grupa podataka o ručno označenim temama istaknuje jezičke obrasce (npr. hipernima, fraze) koje se mogu koristiti za poboljšanje algoritma označavanja automatskih tema.', 'fi': 'Todennäköiset aihemallit ovat tärkeitä työkaluja suurten asiakirjakokoelmien indeksointiin, tiivistämiseen ja analysointiin teemoittain. Loppukäyttäjien ymmärtämisen edistäminen aiheista on kuitenkin edelleen avoin tutkimusongelma. Vertaamme neljää aihepiirin visualisointitekniikkaa käyttävien käyttäjien luomia tunnisteita – sanaluetteloita, sanapilviä ja verkkokaavioita – toisiinsa ja automaattisesti luotuihin tunnisteisiin. Vertailun perustana ovat osallistujien arviot siitä, miten hyvin etiketit kuvaavat aiheeseen liittyviä asiakirjoja. Tutkimuksessa on kaksi vaihetta: merkintävaihe, jossa osallistujat merkitsevät visualisoidut aiheet, ja validointivaihe, jossa eri osallistujat valitsevat, mitkä etiketit kuvaavat parhaiten aiheiden dokumentteja. Vaikka kaikki visualisoinnit tuottavat samanlaisia laatumerkkejä, yksinkertaiset visualisoinnit, kuten sanaluettelot, antavat osallistujille mahdollisuuden ymmärtää aiheita nopeasti, kun taas monimutkaiset visualisoinnit vievät kauemmin, mutta paljastavat monisanaisia lausekkeita, jotka yksinkertaiset visualisoinnit hämärtävät. Automaattiset tunnisteet ovat jäljessä käyttäjän luomista tunnisteista, mutta manuaalisesti merkityistä aiheista koostuva tietokokonaisuus korostaa kielellisiä kuvioita (esim. hypernyymit, lauseet), joita voidaan käyttää automaattisten aihemerkintöjen algoritmien parantamiseen.', 'he': 'Probabilistic topic models are important tools for indexing, summarizing, and analyzing large document collections by their themes.  עם זאת, הקידום של הבנה של השתמשים הסופיים של נושאים נשאר בעיה מחקר פתוחה. אנחנו משוותים תוויות שנוצרו על ידי משתמשים שנתנו ארבעה רשימות טכניקות ויזואליזציה נושאית, רשימות מילים עם סדרות, עננים מילים, וגרפים רשת אחד נגד השני ובנגד תוויות שנוצרו באופן אוטומטי. בסיס השוואה שלנו הוא ציונים משתתפים של איך תוויות טובות מתארות מסמכים מהנושא. למחקר שלנו יש שני שלבים: שלב תיקון שבו השתתפים תווידים נושאים מוחזקים ושלב אישור שבו משתתפים שונים בוחרים אילו תווידים מתארים הכי טוב את מסמכי הנושאים. למרות שכל הדמיונים יוצרים תוויות איכות דומות, דמיונים פשוטים כמו רשימות מילים מאפשרים לשתתפים להבין במהירות נושאים, בעוד דמיונים מורכבים לוקחים יותר זמן, אך לחשוף ביטויים רבים מילים שדמיונים פשוטים יותר מתעלמים. תוויות אוטומטיות מתעכבות מאחורי תוויות שנוצרו ע"י המשתמשים, אך קבוצת הנתונים שלנו של נושאים שמתוויעים ידנית מצביעה דפוסים שפותיים (למשל היפרנימות, ביטויים) שאפשר להשתמש בשיפור אלגוריתמים של תוויות נושאים אוטומטיים.', 'ha': "@ info: tooltip A lokacin da za'a promote fahimta mai ƙaranci ga masu shiryuwa na madaidaita yana da wata masĩfa mai buɗewa. We compare labels generated by users given four topic visualization techniques-word lists, word lists with bars, word clouds, and network graphs-against each other and against automatically generated labels.  Babu bincike da misalinmu yana da rabon alama masu kyau a bayyana takardar daga madaidaita. Ana karatunmu na da fasa biyu: wata fasa mai alama, inda mãsu shirin da ke lissafa madaidaita da kuma wani fasa mai inganci, inda wasu mãsu shirin da ke zãɓi ko wanne alama masu fi bayyana takardan maɓalli. Akwai da duk kunnuwan da ake nuna su ƙara alama masu daidaita, ko da sunayen misãlai masu daidaita kamar jerin maganar, za'a yarda da mãsu haɗuwa su fahimta madaidaici da haraka, kuma a lokacin da zane-zane masu husũma masu rauni, sai ya nuna magana masu yawa da za'a motsa sauri masu gani. @ info: whatsthis", 'bo': "Probabilistic topic models are important tools for indexing, summarizing, and analyzing large document collections by their themes. ཡིན་ནའང་། གནད་དོན་འདི་ལ་མཐའ་མཇུག་གི་གོ་སྤེལ་བ་ནི་འཚོལ་ཞིབ་བྱེད་ཀྱི་མ་ཟད། We compare labels generated by users given four topic visualization techniques-word lists, word lists with bars, word clouds, and network graphs-against each other and against automatically generated labels. In addition, we compare labels generated by users given four topic visualization techniques-word lists, word lists with bars, word clouds, and network graphs-against each other and against automatically generated labels. ང་ཚོའི་མཉམ་འབྱུང་བའི་རྨང་གཞི་ནི་མཉམ་འབྱུང་གི་གྲངས་རྩིས་ཅན་གྱི་ཤོག་བྱང་གིས་གནད་དོན་ནས་ཡིག Our study has two phases: a labeling phase where participants label visualized topics and a validation phase where different participants select which labels best describe the topics' documents. Although all visualizations produce similar quality labels, simple visualizations such as word lists allow participants to quickly understand topics, while complex visualizations take longer but expose multi-word expressions that simpler visualizations obscure. Automatic labels lag behind user-created labels, but our dataset of manually labeled topics highlights linguistic patterns (e.g., hypernyms, phrases) that can be used to improve automatic topic labeling algorithms.", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertive politenessoffpolite"), and when there is a change ("assertivepoliteness Tulung Workspace Visual politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Verjetnostni tematski modeli so pomembna orodja za indeksiranje, povzemanje in analizo velikih zbirk dokumentov po temah. Vendar pa spodbujanje razumevanja teme končnih uporabnikov ostaja odprt raziskovalni problem. Oznake, ki jih ustvarijo uporabniki s štirimi tehnikami vizualizacije teme – sezname besed, sezname besed z vrsticami, oblake besed in omrežni grafikoni – primerjamo med seboj in s samodejno ustvarjenimi oznakami. Naša podlaga za primerjavo je ocena udeležencev, kako dobro oznake opisujejo dokumente iz teme. Naša študija ima dve fazi: fazo označevanja, kjer udeleženci označujejo vizualizacijo teme, in fazo validacije, kjer različni udeleženci izberejo, katere oznake najbolje opisujejo dokumente teme. Čeprav vse vizualizacije ustvarjajo podobne oznake kakovosti, preproste vizualizacije, kot so seznami besed, udeležencem omogočajo hitro razumevanje teme, medtem ko kompleksne vizualizacije trajajo dlje, vendar razkrivajo večbesedne izraze, ki jih preprostejše vizualizacije zakrivajo. Avtomatske oznake zaostajajo za oznakami, ki jih ustvarijo uporabniki, vendar naš nabor podatkov ročno označenih tem poudarja jezikovne vzorce (npr. hipernime, fraze), ki jih je mogoče uporabiti za izboljšanje algoritmov avtomatskega označevanja teme.'}
{'en': 'Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns', 'ar': 'النماذج الدلالية المؤرضة بصريًا والنصية تفك بشكل تفاضلي نشاط الدماغ المرتبط بالأسماء الخرسانية والتجريدية', 'es': 'Los modelos semánticos textuales y con base visual decodifican diferencialmente la actividad cerebral asociada con los sustantivos concretos y abstractos', 'fr': "Les modèles sémantiques textuels et visuellement fondés décodent de manière différentielle l'activité cérébrale associée à des noms concrets et abstraits", 'pt': 'Modelos semânticos textuais e visualmente fundamentados decodificam diferencialmente a atividade cerebral associada a substantivos concretos e abstratos', 'ja': '視覚的にグラウンディングされたテキスト意味モデルは、コンクリート名詞と抽象名詞に関連する脳活動を差別的にデコードする', 'zh': '视本语义异大脑解码', 'ru': 'Визуально обоснованные и текстовые семантические модели дифференциально декодируют мозговую активность, связанную с конкретными и абстрактными существительными', 'hi': 'नेत्रहीन ग्राउंडेड और टेक्स्टसमेंटिक मॉडल विभेदक रूप से डीकोड मस्तिष्क गतिविधि कंक्रीट और अमूर्त संज्ञाओं से जुड़े', 'ga': 'Múnlaí Séimeantacha Amhairc agus Téacsúla Díchódaigh go Difreálach Gníomhaíocht Inchinne a Bhaineann le hAinmfhocail Choincréiteacha agus Theibí', 'ka': 'Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns', 'hu': 'Vizuálisan földelt és szöveges szemantikus modellek különbözően dekódolják a beton és absztrakt főnevekhez kapcsolódó agyi aktivitást', 'el': 'Οπτικά θεμελιωμένα και κειμενικά Σημαντικά Μοντέλα Αποκωδικοποιούν Διαφορικά την εγκεφαλική δραστηριότητα που σχετίζεται με συγκεκριμένα και αφηρημένα ουσιαστικά', 'it': "Modelli semantici visivamente terrestri e testuali decodificano differentemente l'attività cerebrale associata a sostantivi concreti e astratti", 'kk': 'Көрініс түрлі және мәтіннің семантикалық үлгілері Конкретті және абстракттік таңбалармен байланысты мидың белсенділігін шектеу', 'lt': 'Reguliariai pagrįsti ir tekstuali Semantiniai modeliai, skirtingai dekoderuojantys smegenų veiklą, susijusią su konkretinėmis ir abstrakčiomis vardinėmis medžiagomis', 'mk': 'Визуелно основани и текстуални семантични модели различно ги декодираат мозочните активности поврзани со конкретни и апстрактни именици', 'ms': 'Name', 'ml': 'കോണ്\u200dക്രീറ്റും അബ്രാക്രീറ്റ് നോണുമായി ബന്ധപ്പെടുന്ന വ്യത്യസ്തമായി സെമാന്റിക് മോഡലുകളും കാണിക്കുക', 'mt': 'Mudelli Semantiċi b’Grounds Viswalment u Tekstiċi b’Attività tal-Moħħ b’Dekodifikazzjoni Differenzjalment Assoċjata ma’ Nomini Konkreti u Abstrati', 'mn': 'Харин харагдаж буй хөндлөн болон текстур Semantic загварууд Цаг болон Абстрактур Нусуудтай холбогдсон тархины үйл ажиллагааг', 'ro': 'Modele semantice împământate vizual și textuale decodează diferențial activitatea creierului asociată cu substantive concrete și abstracte', 'no': 'Visuelt grunnleggte og tekst- semantiske modeller ulike dekode brenneaktivitet assosiert med beton og abstrakt nøklar', 'sr': 'Vizualno podmetnuti i tekstualni semantički modeli različite dekodirajuće aktivnosti mozga povezane sa betonskim i abstraktivnim trenucima', 'pl': 'Wizualnie uziemione i tekstowe modele semantyczne różnicowo dekodują aktywność mózgu związaną z rzeczownikami konkretnymi i abstrakcyjnymi', 'sv': 'Visuellt jordade och textuella semantiska modeller avkodar olika hjärnaktivitet associerad med konkreta och abstrakta substantiv', 'so': 'Isticmaalka qoraalka', 'si': 'Visally Groundid and textal semantic Models Differsensively Decode brain action', 'ta': 'காண்கிரீட் மற்றும் செமாண்டிக் மாதிரிகள் வேறுபாடாக குறிப்பிடும் மின்னணி செயல்பாடுகளை காண்பிக்கவும் குறிப்பி', 'ur': 'بغیر متفاوت اور بغیر متفاوت سمانٹیک موڈلز بغیر متفاوت سے برائین فعالیت کو دکوڈ کرتا ہے', 'uz': 'Name', 'vi': 'Chế độ hài hòa hình thức và hóa học hài hước Phân biệt các hoạt động trí tuệ liên quan đến hiệu quả Concrete và abstract', 'da': 'Visuelt jordede og tekstuelle semantiske modeller afkoder forskelligt hjerneaktivitet forbundet med beton og abstrakte navneord', 'bg': 'Визуално заземени и текстови семантични модели диференциално декодират мозъчната активност, свързана с конкретни и абстрактни съществителни', 'hr': 'Visualno ugrozeni i tekstualni semantički modeli različite dekodirajuće aktivnosti mozga povezane sa betonskim i abstraktivnim trenucima', 'nl': 'Visueel geaard en tekstueel semantische modellen decoderen hersenactiviteit geassocieerd met concrete en abstracte zelfstandige naamwoorden', 'de': 'Visuell geerdete und textuelle semantische Modelle dekodieren Hirnaktivität in Verbindung mit konkreten und abstrakten Substantiven', 'id': 'Model Semantik Berdasarkan Visual dan Tekstil Berbeda Dekodasi Aktivitas Otak Berdasarkan dengan Nama Konkret dan Abstrakt', 'ko': '시각적 기초와 텍스트의 의미 모델은 구체적이고 추상적인 명사와 관련된 대뇌 활동을 다르게 디코딩한다', 'fa': 'مدل\u200cهای متوسط و متوسط متوسط به نظر می\u200cرسد فعالیت مغز متفاوتی با نقطه\u200cهای متوسط و مغزی متوسط', 'sw': 'Mitandao ya Kimataifa ya Kiteknolojia tofauti tofauti ya Kuamua Shughuli za Uchaguzi na Kuzungumza', 'af': 'Visuel Grounded en Textual Semantic Models Verskillende Dekodeer Brein Aktiviteit Assosieer met Konkrteet en Abstrakte Noue', 'tr': 'Görnöş süýtgeli we metiniň semantik Modelleri Diňe görnöşinden Beýin Etkinlikleri Concrete we Abstrakt Attlary bilen baglanýar', 'hy': 'Տեսաբանական և տեքստոլային սեմատիկ մոդելներ', 'am': 'drawable-action', 'sq': 'Modelet Semantike të themeluara dhe tekstuale në mënyrë të ndryshme të dekodimit të veprimtarisë së trurit të lidhur me emra konkrete dhe abstrakte', 'az': 'Görünürlü Üstünlü və Textual Semantic Modellər Konkret və Abstrakt Adları ilə bağlı Brain Fayllığını Dekodlayır', 'bs': 'Visualno podmetnuti i tekstualni semantički modeli različite dekodirajuće aktivnosti mozga povezane sa betonskim i abstraktivnim trenucima', 'bn': 'দৃশ্যমান গ্রাউন্ট এবং টেক্সটুয়াল সেম্যান্টিক মডেল আলাদা ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভি', 'ca': 'Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns', 'cs': 'Vizuálně uzemněné a textové sémantické modely diferenciálně dekódují mozkovou aktivitu spojenou s konkrétními a abstraktními podstatnými jmény', 'et': 'Visuaalselt maandatud ja tekstilised semantilised mudelid dekodeerivad diferentsiaalselt ajutegevust seoses konkreetsete ja abstraktsete substantiividega', 'fi': 'Visuaalisesti pohjautuneet ja tekstuaaliset semanttiset mallit dekoodavat eri tavalla aivotoimintaa liittyen konkreettisiin ja abstrakteihin substantiiveihin', 'jv': 'Visual Gruundd and textual semanti Modes', 'ha': '@ item Text character set', 'he': 'מודלים סמנטיים מבחינה ראייתית וטקסטולית', 'bo': 'Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns', 'sk': 'Vizualno ozemljeni in tekstualni semantični modeli različno dekodirajo možgansko aktivnost, povezano s konkretnimi in abstraktnimi samostalniki'}
{'en': 'Important advances have recently been made using computational semantic models to decode brain activity patterns associated with concepts ; however, this work has almost exclusively focused on concrete nouns. How well these models extend to decoding abstract nouns is largely unknown. We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns. One of the models we use is linguistic, exploiting the recent word2vec skipgram approach trained on Wikipedia. The second is visually grounded, using deep convolutional neural networks trained on Google Images. Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically. Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns ; however, accuracy is significantly greater using the text-based models for the most abstract nouns. More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain.', 'ar': 'تم إحراز تقدم هام مؤخرًا باستخدام النماذج الدلالية الحسابية لفك تشفير أنماط نشاط الدماغ المرتبطة بالمفاهيم ؛ ومع ذلك ، فقد ركز هذا العمل بشكل حصري تقريبًا على الأسماء الملموسة. إن مدى نجاح هذه النماذج في فك تشفير الأسماء المجردة غير معروف إلى حد كبير. نعالج هذا السؤال من خلال تطبيق أحدث النماذج الحسابية لفك تشفير أنماط نشاط التصوير بالرنين المغناطيسي الوظيفي (fMRI) ، التي استنبطها المشاركون وهم يقرؤون ويتخيلون مجموعة متنوعة من الأسماء الملموسة والمجردة. أحد النماذج التي نستخدمها هو لغوي ، حيث يستغل منهج word2vec skipgram الحديث المدرب على ويكيبيديا. والثاني مؤرض بصريًا ، باستخدام شبكات عصبية تلافيفية عميقة مدربة على صور Google. تعتبر نظرية الترميز المزدوج مفاهيم ملموسة يتم ترميزها في الدماغ لغويًا ومرئيًا ، والمفاهيم المجردة لغويًا فقط. بتقسيم بيانات الرنين المغناطيسي الوظيفي وفقًا لتصنيفات الملموسة البشرية ، نلاحظ بالفعل أن كلا النموذجين يقومان بفك تشفير الأسماء الأكثر واقعية ؛ ومع ذلك ، تكون الدقة أكبر بشكل ملحوظ باستخدام النماذج النصية للأسماء الأكثر تجريدًا. بشكل عام ، يؤكد هذا أن النماذج الحسابية الحالية متقدمة بدرجة كافية للمساعدة في التحقيق في البنية التمثيلية للمفاهيم المجردة في الدماغ.', 'es': 'Recientemente se han realizado importantes avances utilizando modelos semánticos computacionales para decodificar patrones de actividad cerebral asociados con conceptos; sin embargo, este trabajo se ha centrado casi exclusivamente en sustantivos concretos. Se desconoce en gran medida qué tan bien se extienden estos modelos para decodificar sustantivos abstractos. Abordamos esta cuestión mediante la aplicación de modelos computacionales de última generación para decodificar los patrones de actividad de la Imagen por Resonancia Magnética (IRMf) funcionales, provocados por los participantes que leen e imaginan un conjunto diverso de sustantivos tanto concretos como abstractos. Uno de los modelos que utilizamos es el lingüístico, aprovechando el reciente enfoque de skipgram de word2vec entrenado en Wikipedia. El segundo está basado visualmente, utilizando redes neuronales convolucionales profundas entrenadas en Google Images. La teoría de la codificación dual considera que los conceptos concretos están codificados en el cerebro tanto lingüística como visualmente, y los conceptos abstractos solo lingüísticamente. Al dividir los datos de IRMf de acuerdo con las calificaciones de concreción humana, observamos que ambos modelos decodifican significativamente los sustantivos más concretos; sin embargo, la precisión es significativamente mayor al usar los modelos basados en texto para los sustantivos más abstractos. De manera más general, esto confirma que los modelos computacionales actuales están lo suficientemente avanzados como para ayudar a investigar la estructura representativa de los conceptos abstractos en el cerebro.', 'pt': 'Avanços importantes foram feitos recentemente usando modelos semânticos computacionais para decodificar padrões de atividade cerebral associados a conceitos; no entanto, este trabalho se concentrou quase exclusivamente em substantivos concretos. Quão bem esses modelos se estendem à decodificação de substantivos abstratos é amplamente desconhecido. Abordamos essa questão aplicando modelos computacionais de última geração para decodificar padrões de atividade de imagem por ressonância magnética funcional (fMRI), eliciados por participantes lendo e imaginando um conjunto diversificado de substantivos concretos e abstratos. Um dos modelos que usamos é linguístico, explorando a recente abordagem de skipgram word2vec treinada na Wikipedia. A segunda é visualmente fundamentada, usando redes neurais convolucionais profundas treinadas no Google Images. A teoria da codificação dupla considera que conceitos concretos são codificados no cérebro tanto linguística quanto visualmente, e conceitos abstratos apenas linguisticamente. Dividindo os dados de fMRI de acordo com as classificações de concretude humana, de fato observamos que ambos os modelos decodificam significativamente os substantivos mais concretos; no entanto, a precisão é significativamente maior usando os modelos baseados em texto para os substantivos mais abstratos. De maneira mais geral, isso confirma que os modelos computacionais atuais são suficientemente avançados para auxiliar na investigação da estrutura representacional de conceitos abstratos no cérebro.', 'fr': "Des progrès importants ont récemment été réalisés en utilisant des modèles sémantiques computationnels pour décoder les modèles d'activité cérébrale associés à des concepts\xa0; cependant, ces travaux se sont presque exclusivement concentrés sur des noms concrets. L'étendue de ces modèles au décodage des noms abstraits est largement inconnue. Nous répondons à cette question en appliquant des modèles informatiques de pointe pour décoder des modèles d'activité d'imagerie par résonance magnétique (IRMf) fonctionnels, suscités par la lecture et l'imagination d'un ensemble diversifié de noms concrets et abstraits. L'un des modèles que nous utilisons est linguistique, exploitant la récente approche skipgram word2vec formée sur Wikipédia. Le second est visuellement ancré, à l'aide de réseaux neuronaux convolutifs profonds formés sur Google Images. La théorie du double codage considère les concepts concrets comme codés dans le cerveau à la fois linguistiquement et visuellement, et les concepts abstraits uniquement linguistiquement. En divisant les données IRMf en fonction de l'évaluation de la réalité humaine, nous observons en effet que les deux modèles décodent de manière significative les noms les plus concrets\xa0; cependant, la précision est nettement supérieure en utilisant les modèles textuels pour les noms les plus abstraits. Plus généralement, cela confirme que les modèles informatiques actuels sont suffisamment avancés pour aider à étudier la structure représentationnelle de concepts abstraits dans le cerveau.", 'zh': '近取大进,计语义以解码其名大脑。 然其事殆尽。 其形广于多大程度解码抽象名词于大者未之知也。 先进之数以解码功能性磁共振(fMRI)之,参与者读象名词也。 吾法之一为语言学,用近习于维基百科word2vec skipgram法。 二曰视基,用于Google Images之深卷积神经网络。 重编码论以为言视皆编码于大脑,而象名编码于言。 分fMRI数,审观两解码名词。 然于最抽象之名词,用基于文本,准确性较然益高。 又曰:此算已足以先进,可以助大脑抽象概念之表。', 'hi': 'महत्वपूर्ण प्रगति हाल ही में अवधारणाओं से जुड़े मस्तिष्क गतिविधि पैटर्न को डीकोड करने के लिए कम्प्यूटेशनल शब्दार्थ मॉडल का उपयोग करके की गई है; हालांकि, इस काम ने लगभग विशेष रूप से ठोस संज्ञाओं पर ध्यान केंद्रित किया है। अमूर्त संज्ञाओं को डिकोड करने के लिए ये मॉडल कितनी अच्छी तरह से विस्तारित होते हैं, यह काफी हद तक अज्ञात है। हम कार्यात्मक चुंबकीय अनुनाद इमेजिंग (एफएमआरआई) गतिविधि पैटर्न को डीकोड करने के लिए अत्याधुनिक कम्प्यूटेशनल मॉडल लागू करके इस प्रश्न को संबोधित करते हैं, जो प्रतिभागियों द्वारा ठोस और अमूर्त संज्ञा दोनों के विविध सेट को पढ़ने और कल्पना करने के लिए प्राप्त होता है। हमारे द्वारा उपयोग किए जाने वाले मॉडलों में से एक भाषाई है, जो विकिपीडिया पर प्रशिक्षित हाल के word2vec skipgram दृष्टिकोण का शोषण करता है। दूसरा नेत्रहीन आधार पर है, Google छवियों पर प्रशिक्षित गहरे convolutional तंत्रिका नेटवर्क का उपयोग कर। दोहरी कोडिंग सिद्धांत ठोस अवधारणाओं को भाषाई और नेत्रहीन दोनों मस्तिष्क में एन्कोडेड माना जाता है, और अमूर्त अवधारणाओं को केवल भाषाई रूप से। मानव कंक्रीटनेस रेटिंग के अनुसार एफएमआरआई डेटा को विभाजित करते हुए, हम वास्तव में देखते हैं कि दोनों मॉडल सबसे ठोस संज्ञाओं को काफी हद तक डिकोड करते हैं; हालांकि, सटीकता सबसे अमूर्त संज्ञाओं के लिए पाठ-आधारित मॉडल का उपयोग करके काफी अधिक है। अधिक आम तौर पर यह पुष्टि करता है कि वर्तमान कम्प्यूटेशनल मॉडल मस्तिष्क में अमूर्त अवधारणाओं की प्रतिनिधित्वात्मक संरचना की जांच करने में सहायता करने के लिए पर्याप्त रूप से उन्नत हैं।', 'ja': '最近、概念に関連する脳活動パターンをデコードするための計算意味モデルを使用して重要な進歩がありましたが、この研究はほとんど特定の名詞にのみ焦点を当てています。 これらのモデルが抽象名詞の復号にどの程度まで広がるかは、ほとんど知られていない。 私たちは、参加者が具体的および抽象的な名詞の多様なセットを読み、想像することによって誘発される機能的磁気共鳴画像（ fMRI ）活動パターンをデコードするために最先端の計算モデルを適用することによって、この問題に対処します。 私たちが使用しているモデルの1つは、ウィキペディアで訓練された最近のword 2 vecスキップグラムアプローチを利用した言語学的なものです。 2つ目は、Google画像でトレーニングされた深い畳み込みニューラルネットワークを使用して、視覚的に接地されていることです。 デュアルコーディング理論は、具体的な概念を言語学的にも視覚的にも脳にエンコードされ、抽象的な概念は言語学的にのみエンコードされると考える。 人間の具体性の評価に従ってfMRIデータを分割すると、両方のモデルが最も具体的な名詞を有意にデコードすることが確実に観察されます。しかし、最も抽象的な名詞についてテキストベースのモデルを使用すると、正確性が有意に高くなります。 より一般的に、これは、現在の計算モデルが、脳内の抽象概念の表現構造を調査するのを支援するのに十分に高度であることを確認する。', 'ru': 'В последнее время были достигнуты важные успехи в использовании вычислительных семантических моделей для декодирования паттернов мозговой активности, связанных с понятиями; однако эта работа почти исключительно сосредоточена на конкретных существительных. Насколько хорошо эти модели распространяются на декодирование абстрактных существительных, в значительной степени неизвестно. Мы решаем этот вопрос, применяя современные вычислительные модели для декодирования функциональных паттернов активности магнитно-резонансной томографии (фМРТ), вызванных участниками, читающими и представляющими разнообразный набор как конкретных, так и абстрактных существительных. Одной из моделей, которую мы используем, является лингвистика, использующая недавний подход Word2vec Skipgram, обученный в Википедии. Второй визуально обоснован, используя глубокие сверточные нейронные сети, обученные на Google Images. Теория двойного кодирования рассматривает конкретные концепции как в лингвистическом, так и в визуальном плане, а абстрактные концепции - только в лингвистическом. Разбивая данные фМРТ в соответствии с оценками конкретности человека, мы действительно наблюдаем, что обе модели значительно декодируют наиболее конкретные существительные; однако точность значительно выше, используя текстовые модели для наиболее абстрактных существительных. В более общем плане это подтверждает, что текущие вычислительные модели достаточно продвинуты, чтобы помочь в исследовании репрезентативной структуры абстрактных концепций в мозге.', 'ga': 'Rinneadh dul chun cinn tábhachtach le déanaí agus úsáid á baint as samhlacha ríomha shéimeantacha chun patrúin ghníomhaíochta inchinne a bhaineann le coincheapa a dhíchódú; áfach, dhírigh an obair seo go huile is go hiomlán ar ainmfhocail nithiúla. Ní fios go mór cé chomh maith agus a shíneann na samhlacha seo le díchódú ainmfhocail teibí. Tugaimid aghaidh ar an gceist seo trí mhúnlaí ríomhaireachtúla úrscothacha a chur i bhfeidhm chun patrúin gníomhaíochta um Íomháú Athshondais Mhaighnéadaigh (fMRI) fheidhmiúil a dhíchódú, rud a mheallann na rannpháirtithe ag léamh agus ag samhlú sraith éagsúil d’ainmfhocail nithiúla agus teibí araon. Ar cheann de na múnlaí a úsáidimid tá teanga, ag baint leasa as an gcur chuige skipgram word2vec le déanaí a oiliúint ar Vicipéid. Tá an dara ceann bunaithe ar fhís, ag baint úsáide as líonraí néarúla domhain-raonta atá oilte ar Íomhánna Google. Measann teoiric na déchódaithe coincheapa nithiúla a bheith ionchódaithe san inchinn ó thaobh teanga agus fís, agus coincheapa teibí go teanga amháin. Ag scoilteadh na sonraí fMRI de réir rátálacha coincréit an duine, tugaimid faoi deara go deimhin go ndéanann an dá mhúnla na hainmfhocail is nithiúla a dhíchódú go suntasach; is mó i bhfad an cruinneas, áfach, ag baint úsáide as na samhlacha téacsbhunaithe do na hainmfhocail is teibí. Níos ginearálta, deimhníonn sé seo go bhfuil na múnlaí ríomhaireachtúla reatha sách forbartha chun cuidiú le himscrúdú a dhéanamh ar struchtúr ionadaíochta na gcoincheap teibí san inchinn.', 'hu': 'A közelmúltban fontos előrelépések történtek a fogalmakhoz kapcsolódó agyi aktivitási minták dekódolására számítástechnikai szemantikai modellek felhasználásával; Ez a munka azonban szinte kizárólag a konkrét főnevekre összpontosított. Nagyjából ismeretlen, hogy ezek a modellek mennyire kiterjednek az absztrakt főnevek dekódolására. Ezt a kérdést korszerű számítástechnikai modellek alkalmazásával foglalkozunk a funkcionális mágneses rezonancia képalkotó (fMRI) aktivitási minták dekódolására, amelyeket a résztvevők konkrét és absztrakt főnevek sokféle halmazát olvasnak és elképzelnek. Az egyik modell, amit használunk, a nyelvi, kihasználva a legutóbbi Word2vec skipgram megközelítést a Wikipédián képzett. A második vizuálisan alapozott, mély konvuluációs neurális hálózatok segítségével képzett Google Images. A kettős kódoláselmélet a konkrét fogalmakat nyelvileg és vizuálisan egyaránt kódolja az agyban, az absztrakt fogalmak pedig csak nyelvileg. Az fMRI adatok emberi konkrétségi minősítések szerinti felosztásával valóban megfigyeljük, hogy mindkét modell jelentősen dekódolja a legkonkrétabb főneveket; Azonban a pontosság jelentősen nagyobb a szövegalapú modellek használatával a legabsztraktabb főnevekhez. Általánosabban ez megerősíti, hogy a jelenlegi számítástechnikai modellek elég fejlettek ahhoz, hogy segítsenek az absztrakt fogalmak reprezentációs struktúrájának vizsgálatában az agyban.', 'el': 'Σημαντικές πρόοδοι έχουν σημειωθεί πρόσφατα χρησιμοποιώντας υπολογιστικά σημασιολογικά μοντέλα για την αποκωδικοποίηση μοτίβων εγκεφαλικής δραστηριότητας που σχετίζονται με έννοιες. Ωστόσο, αυτή η εργασία έχει επικεντρωθεί σχεδόν αποκλειστικά σε συγκεκριμένα ουσιαστικά. Το πόσο καλά αυτά τα μοντέλα επεκτείνονται στην αποκωδικοποίηση αφηρημένων ουσιαστικών είναι σε μεγάλο βαθμό άγνωστο. Αντιμετωπίζουμε αυτό το ερώτημα εφαρμόζοντας σύγχρονα υπολογιστικά μοντέλα για την αποκωδικοποίηση λειτουργικών μοτίβων δραστηριότητας της απεικόνισης μαγνητικού συντονισμού (fMR), τα οποία προκαλούνται από τους συμμετέχοντες που διαβάζουν και φαντάζονται ένα ποικίλο σύνολο τόσο συγκεκριμένων όσο και αφηρημένων ουσιαστικών. Ένα από τα μοντέλα που χρησιμοποιούμε είναι γλωσσικά, αξιοποιώντας την πρόσφατη προσέγγιση που εκπαιδεύτηκε στη Βικιπαίδεια. Το δεύτερο είναι οπτικά γειωμένο, χρησιμοποιώντας βαθιά νευρωνικά δίκτυα που εκπαιδεύονται στις εικόνες του Google. Η θεωρία διπλής κωδικοποίησης θεωρεί συγκεκριμένες έννοιες που κωδικοποιούνται στον εγκέφαλο τόσο γλωσσικά όσο και οπτικά, και αφηρημένες έννοιες μόνο γλωσσικά. Χωρίζοντας τα δεδομένα σύμφωνα με τις βαθμολογίες ανθρώπινης ακρίβειας, παρατηρούμε πράγματι ότι και τα δύο μοντέλα αποκωδικοποιούν σημαντικά τα πιο συγκεκριμένα ουσιαστικά. Ωστόσο, η ακρίβεια είναι σημαντικά μεγαλύτερη χρησιμοποιώντας τα μοντέλα βασισμένα στο κείμενο για τα πιο αφηρημένα ουσιαστικά. Γενικότερα αυτό επιβεβαιώνει ότι τα σημερινά υπολογιστικά μοντέλα είναι αρκετά προηγμένα ώστε να βοηθήσουν στη διερεύνηση της αναπαράστασης δομής των αφηρημένων εννοιών στον εγκέφαλο.', 'ka': 'მნიშვნელოვანი პროგრესი ახლა გავაკეთებულია კომპუტაციალური სიმენტიკური მოდელების გამოყენებაში, რომ ტვინის აკეთეტიფიკაციის მოდელების გამოყენება მაგრამ ეს სამუშაო მხოლოდ კონკრეტური სამუშაო დააყენება. რამდენიმე მოდელები აბსტრაქტური სახელის რეკოდირებაში გადარჩენია. ჩვენ ამ კითხვის შესახებ კომპუტურალური მოდელების გამოყენებით ფუნქციური მაგენტიკური რეჟონანციის განახლების (fMRI) აქტიური მოდელების გამოყენებას, რომლებიც სხვადასხვა კონკრეტური და აბსტრაკური სახელის განსხვ ჩვენ გამოყენებულ მოდელში ერთი არის ლინგურისტიკი, რომელიც გამოყენებულია საკუთარი სიტყვები 2vec skipgram ის მიღება, რომელიც ვიკიპედიაში განაკეთებულია. მეორე ვიზუალურად გამოყენებულია, Google Images-ზე გამოყენებული deep convolutional neural networks. ორი კოდირების თეორია იფიქრობს, რომ კონკრეტული კონფექტები ტვინში იქნება ენგუზიალურად და ვიზუალურად, და აბსტრაქტური კონფექტები მხოლოდ ენგუ fMRI მონაცემების გაყოფილი ადამიანის კონკრეტენტის რეტენტის შესახებ, ჩვენ ნამდვილად დავხედავთ, რომ ორივე მოდელები მნიშვნელოვანად უფრო კონკრეტული სახელის გან მაგრამ, სიმართლე უფრო დიდია ტექსტური მოდელების გამოყენება ყველაზე აბსტრაქტური სახელისთვის. უფრო საერთოდ ეს იტყვირდება, რომ მიმდინარე კომპუტრაციული მოდელები უფრო გავაკეთებულია, რომ დახმარება ტვინში აბსტრაქტური კონცექტურის პრეცენტაციალური', 'it': "Recentemente sono stati fatti importanti progressi utilizzando modelli semantici computazionali per decodificare i modelli di attività cerebrale associati ai concetti; Tuttavia, questo lavoro si è concentrato quasi esclusivamente sui sostantivi concreti. Quanto bene questi modelli si estendono alla decodifica dei sostantivi astratti è ampiamente sconosciuto. Affrontiamo questa domanda applicando modelli computazionali all'avanguardia per decodificare schemi funzionali di attività di Magnetic Resonance Imaging (fMRI), suscitati dai partecipanti che leggono e immaginano un insieme diversificato di sostantivi sia concreti che astratti. Uno dei modelli che utilizziamo è linguistico, sfruttando il recente approccio skipgram word2vec addestrato su Wikipedia. Il secondo è basato visivamente, utilizzando reti neurali convoluzionali profonde addestrate su Google Images. La teoria della doppia codifica considera concetti concreti codificati nel cervello sia linguisticamente che visivamente, e concetti astratti solo linguisticamente. Dividendo i dati fMRI in base alle valutazioni di concretezza umana, osserviamo infatti che entrambi i modelli decodificano significativamente i sostantivi più concreti; Tuttavia, l'accuratezza è significativamente maggiore utilizzando i modelli basati sul testo per i sostantivi più astratti. Più in generale ciò conferma che i modelli computazionali attuali sono sufficientemente avanzati per aiutare a studiare la struttura rappresentativa dei concetti astratti nel cervello.", 'kk': 'Маңызды бағдарламалар жаңа концепциялармен байланысты мидың белсенділік үлгілерін декодтау үшін компьютерлік семантикалық моделдерді қолданып жатқан. Бірақ бұл жұмыс тек конкреттік атауларға көздейді. Бұл үлгілер абстракты атауларды декодтау үшін қанша жақсы кеңейтеді? Біз бұл сұрақты күй- жай компьютерлік үлгілерін қолданып, функциялық Магнетикалық Резонациялық (fMRI) белсенділік үлгілерін декодтау үшін, қатысушылар оқу және абстракт атаулардың әртүрлі тізімін түсіндір Біз қолданатын үлгілердің бірі - лингвистик, жаңа сөздерді 2vec Skipgram қасиетін Википедияда қолданатын. Екіншісі Google кескіндерінде оқылған түсіндірілген түсіндірілген невралдық желілер қолданылады. Екінші кодировка теориясы мидында лингвистикалық және визуалдық концепттерді тек лингвистикалық түрде кодтау деп ойлайды. fMRI деректерін адамдардың тәуелсіздік рейтинге сәйкес бөліп, екі үлгілер конкреттік атаулардың ең жақсы деңгейін деңгейін деңгейін қараймыз. Бірақ, нақтылығы мәтін негіздеген үлгілерді ең абстракты атаулардың үлгілеріне қолданады. Бұл көпшілігінен қазіргі компьютерлік үлгілері мидындағы абстракт концепциялық құрылғысын зерттеу үшін жеткілікті көмектесетінін анықтайды.', 'mk': 'Неодамна се постигнати важни напредоци користејќи ги компјутатичните семантични модели за декодирање на мозочните активности поврзани со концептите; сепак, оваа работа речиси ексклузивно се фокусираше на конкретни именици. Колку добро овие модели се шират до декодирање апстрактни именици е во голема мера непознато. Ние го решаваме ова прашање со аплицирање на најсовремени компјутативни модели за декодирање на функционалните модели на активноста на Магнетното резонансо имиџирање (fMRI), предизвикани од учесниците кои читаат и замислуваат различни множини на бетонски и апстрактни именици. Еден од моделите што ги користиме е јазикот, искористувајќи го неодамнешниот пристап на Word2vec skipgram трениран на Википедија. The second is visually grounded, using deep convolutional neural networks trained on Google Images.  Теоријата за двојно кодирање смета дека конкретните концепти се кодирани во мозокот само јазички и визуелно, а апстрактни концепти само јазички. Разделувањето на податоците на fMRI според оценките на човечката конкретност, навистина забележуваме дека двата модели значително ги декодираат најбетонските именици; сепак, точноста е значително поголема користејќи ги текстовите модели за најапстрактни именици. Погенерално ова потврдува дека сегашните компјутациски модели се доволно напредени за да помогнат во истрагата на репрезентационалната структура на апстрактни концепти во мозокот.', 'lt': 'Neseniai padaryta didelė pažanga naudojant skaičiavimo semantinius modelius smegenų aktyvumo modeliams, susijusiems su sąvokomis, dekoderuoti; tačiau šis darbas beveik išimtinai sutelkė dėmesį į konkrečias vardas. Iš esmės nežinoma, kaip gerai šie modeliai apima abstraktus vardus. Šis klausimas sprendžiamas taikant naujausius skaičiavimo modelius funkciniams magnetinio rezonanso atvaizdavimo (fMRI) veiklos modeliams dekoduoti, kuriuos sukelia dalyviai skaitydami ir įsivaizduodami įvairius konkrečius ir abstraktus vardinius pavadinimus. One of the models we use is linguistic, exploiting the recent word2vec skipgram approach trained on Wikipedia.  Antrasis yra vizualiai grindžiamas naudojant gilius konvoliucinius nervinius tinklus, apmokytus Google paveikslėliuose. Dvigubo kodavimo teorija mano, kad konkrečios sąvokos yra koduojamos smegenyse tiek kalbiniu, tiek vizualiniu požiūriu, ir abstrakčios sąvokos tik kalbiniu požiūriu. Skiriant fMRI duomenis pagal žmogaus konkretumo rodiklius, mes iš tikrųjų pastebime, kad abu modeliai žymiai dekoduoja konkrečiausius vardinius pavadinimus; tačiau tikslumas yra gerokai didesnis naudojant tekstinius modelius abstrakčiausiems vardiniams pavadinimams. Apskritai tai patvirtina, kad dabartiniai skaičiavimo modeliai yra pakankamai pažangi, kad padėtų tirti abstrakčių sąvokų reprezentacinę struktūrą smegenyse.', 'ms': 'Kemajuan penting baru-baru ini telah dibuat menggunakan model semantik pengiraan untuk menyahkod corak aktiviti otak yang berkaitan dengan konsep; however, this work has almost exclusively focused on concrete nouns.  Seberapa baik model ini memperluas kepada penyahkodan nama abstrak kebanyakan tidak diketahui. Kami mengatasi soalan ini dengan melaksanakan model komputasi state-of-the-art untuk menyahkod corak aktiviti Imaging Resonance Magnetic (fMRI) berfungsi, disebabkan oleh peserta membaca dan membayangkan set berbeza dari kedua-dua nama konkrit dan abstrakt. Salah satu model yang kita gunakan adalah bahasa, mengeksploitasi pendekatan langkah kata 2vec baru-baru ini dilatih di Wikipedia. Yang kedua didasarkan secara visual, menggunakan rangkaian saraf konvolusi dalam dilatih pada Imej Google. Teori pengekodan dua mempertimbangkan konsep-konsep konkret untuk dikekodkan dalam otak secara bahasa dan visual, dan konsep abstrak hanya secara bahasa. Membahagi data fMRI mengikut nilai kesimpulan manusia, kita benar-benar melihat kedua-dua model secara signifikan menyahkod nama yang paling konkrit; bagaimanapun, ketepatan lebih besar dengan signifikan menggunakan model berdasarkan teks untuk nama yang paling abstrak. Lebih umum ini mengesahkan bahawa model komputasi semasa cukup maju untuk membantu penyelidikan struktur perwakilan konsep abstrak dalam otak.', 'ml': 'ആശയങ്ങളോടൊപ്പം ബന്ധപ്പെടുന്ന മാതൃകങ്ങള്\u200d കോഡോഡ് ചെയ്യുന്നതിനായി കണക്കുണ്ടാക്കുന്ന സെമാന്റിക് മോഡലുകള്\u200d ഉപ എന്നാലും, ഈ ജോലി കോണ്\u200dക്രീറ്റിന്\u200dറെ മേല്\u200d മാത്രം ശ്രദ്ധിച്ചിരിക്കുന്നു. ഈ മോഡലുകള്\u200d എത്ര നന്നായിരിക്കുന്നു അബ്രാക്ട്രാക്റ്റ് പൂന്തുണ്ടാക്കുന്നതിന് വേണ്ടി അപരിച നമ്മള്\u200d ഈ ചോദ്യം പരിശോധിക്കുന്നത് ആവശ്യപ്പെടുത്തുന്നത് മാഗ്നെറ്റിക് റിസോണന്\u200dസ് ഇമേജിങ്ങിന്\u200dറെ (FMRI) പ്രവര്\u200dത്തനത്തിന്\u200dറെ രീതിയിലേക്ക് പ്രയോഗിക്കുന്നതിനാല നമ്മള്\u200d ഉപയോഗിക്കുന്ന മോഡലില്\u200d ഒന്നാണ് ഭാഷ്ട്രീഷ്ട്രീക്ക്, വിക്കിപിഡിയയില്\u200d പഠിപ്പിക്കപ്പെട്ട വാര്\u200dഡ്2വിക രണ്ടാമത്തെ കാഴ്ചപ്പെടുത്തിയിരിക്കുന്നു, ഗൂഗിള്\u200d ചിത്രങ്ങളില്\u200d പഠിപ്പിക്കുന്ന ആഴത്തെ പ്രധാന ഡ്യൂള്\u200d കോഡിങ്ങ് തിയറിയിരിക്കുന്നത് തലച്ചോറില്\u200d കോണ്\u200dക്രീറ്റ് ആശയങ്ങള്\u200d കോണ്\u200dക്രീറ്റ് ചിന്തിക്കുന്നതാണെന്നാണ്. ഭാഷക്ക മനുഷ്യരുടെ കൂട്ടത്തിലുള്ള വിഭവങ്ങള്\u200d അനുസരിച്ച് FMRI ഡേറ്റാ വിതരണം ചെയ്യുന്നു. രണ്ടു മോഡലുകളും ഏറ്റവും കോണ്\u200dക്രിറ്റ് നിറഞ് എന്നാലും, ഏറ്റവും അസ്ഥിരതയുള്ള ആഹാരത്തിന് വേണ്ടി പദാവലി അടിസ്ഥാനമായ മോഡലുകള്\u200d ഉപയോഗിക്കുന്നതില്\u200d കൂടുതല്\u200d  ഇപ്പോഴത്തെ കണക്കുണ്ടാക്കുന്ന മോഡലുകള്\u200d ആവശ്യമായും മുന്\u200dഗണന നടത്തുന്നുണ്ടെന്ന് ഇതിനെക്കാള്\u200d കൂടുതല്\u200d ഉറപ്പുവരുത്തുന്നു. തലച്', 'mt': 'Dan l-aħħar saru avvanzi importanti bl-użu ta’ mudelli semantiċi komputattivi biex jiġu dekodifikati xejriet ta’ attività tal-moħħ assoċjati ma’ kunċetti; madankollu, dan ix-xogħol iffoka kważi esklussivament fuq ismijiet konkreti. Kemm dawn il-mudelli jestendu tajjeb għad-dekodifikazzjoni tal-ismijiet astratti mhux magħruf fil-biċċa l-kbira. Aħna nindirizzaw din il-mistoqsija billi napplikaw mudelli komputattivi moderni għad-dekodifikazzjoni ta’ mudelli ta’ attività funzjonali tal-Immaġini tar-Riżonanza Magnetika (fMRI), ikkawżati mill-parteċipanti li jaqraw u jaħsbu sett varjat ta’ nomi kemm konkreti kif ukoll astratti. Wieħed mill-mudelli li nużaw huwa lingwistiku, li jisfrutta l-approċċ reċenti ta’ skipgram tal-kliem2vec imħarreġ fuq il-Wikipedia. It-tieni hija viżwalment ibbażata, bl-użu ta’ netwerks newrali konvoluzzjonali profondi mħarrġa fuq Google Images. It-teorija tal-kodifikazzjoni doppja tikkunsidra kunċetti konkreti li għandhom jiġu kkodifikati fil-moħħ kemm lingwistikament kif ukoll viżwalment, u kunċetti astratti biss lingwistikament. Meta nqasmu d-dejta fMRI skont il-klassifikazzjonijiet tal-konkretezza umana, tabilħaqq naraw li ż-żewġ mudelli jiddekodu b’mod sinifikanti l-aktar nomi konkreti; madankollu, il-preċiżjoni hija ferm akbar bl-użu tal-mudelli bbażati fuq it-test għall-aktar nomi astratti. More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain.', 'no': 'Viktige avansertar er nyleg lagde med datasemantiske modeller for å dekode hjernenaktivitetsmønsteret som er assosiert med konseptar. Dette arbeidet har likevel nesten eksklusivt fokusert på beton-namn. Kor godt disse modelane utvidar til dekodering av abstrakt namn er stort ukjend. Vi adresserer dette spørsmålet ved å bruka kalkulasjonske modeller for å dekode funksjonelle mønsterelement for Magnetic Resonance Imaging (fMRI) på aktivitetsmønsteret, som blir vist av deltakarar som lesar og forestille eit ulike sett av både beton og abstrakt namn. Ein av modelane vi brukar er linguistisk, som brukar den siste ordet 2vec skipgramtilnærming trengte på Wikipedia. Den andre er visuelt bakgrunnet med dype konvolusjonelle neuralnettverk som treng på Google-bilete. Dual kodingsteorie ser på at konkrete konseptar er koda i hjernen både språk og visuelt, og abstrakt konseptar berre språk. For å dele fMRI-data etter menneskelige betydningar, observerer vi faktisk at begge modeller betydelig dekode dei mest betydne namnene. Men nøyaktighet er betydelig større med tekstbaserte modeller for dei mest abstrakte namnene. Dette stadfestar vanlegvis at nåværende datamaskiner er nok avansert for å hjelpa til å undersøke representasjonal struktur av abstrakt konseptar i hjernen.', 'pl': 'Ostatnio poczyniono istotne postępy wykorzystując obliczeniowe modele semantyczne do dekodowania wzorców aktywności mózgu związanych z koncepcjami; Praca ta koncentrowała się jednak prawie wyłącznie na konkretnych rzeczownikach. Jak dobrze te modele rozszerzają się do dekodowania rzeczowników abstrakcyjnych jest w dużej mierze nieznane. Odpowiadamy na to pytanie, stosując najnowocześniejsze modele obliczeniowe do dekodowania funkcjonalnych wzorców aktywności obrazowania rezonansu magnetycznego (fMRI), wywołanych przez uczestników czytających i wyobrażających sobie zróżnicowany zestaw rzeczowników konkretnych i abstrakcyjnych. Jednym z modeli, których używamy, jest językowy, wykorzystujący najnowsze podejście skipgram Word2vec przeszkolone na Wikipedii. Druga jest wizualnie uziemiona, wykorzystując głębokie konwolucyjne sieci neuronowe przeszkolone na obrazach Google. Teoria podwójnego kodowania uważa konkretne pojęcia za zakodowane w mózgu zarówno językowo, jak i wizualnie, a abstrakcyjne pojęcia tylko językowo. Podzielając dane fMRI według wskaźników konkretności człowieka, rzeczywiście zauważamy, że oba modele znacząco dekodują najbardziej konkretne rzeczowniki; Jednak dokładność jest znacznie większa przy użyciu modeli tekstowych dla najbardziej abstrakcyjnych rzeczowników. Ogólnie rzecz biorąc, potwierdza to, że obecne modele obliczeniowe są wystarczająco zaawansowane, aby pomóc w badaniu struktury reprezentacyjnej abstrakcyjnych pojęć w mózgu.', 'mn': 'Тархины үйл ажиллагааны загваруудыг ойлгохын тулд маш чухал хөгжим саяхан тооцоололтын semantic загваруудыг ашиглаж байна. Гэхдээ энэ ажил бараг конкретний нэр дээр анхаарлаа төвлөрсөн. Эдгээр загварууд хэр сайн нэрлэгддэг вэ гэвэл абстрактын нэрлэгдүүдийг ихэвчлэн мэдэхгүй. Бид энэ асуултыг функцийн Магнитик Резонац Имжингийн (fMRI) үйл ажиллагааны загварыг ашиглаж, оролцогчдын уншиж, хоёр конкрет болон абстрактик нэрлэгүүдийг төсөөлж чаддаг. Бидний хэрэглэдэг загварын нэг нь хэлний хэл, саяхан үг 2vec skipgram ын аргыг Википедияд сургалтын аргыг ашиглаж байна. Харин хоёр дахь нь Google зураг дээр сургалтын гүн гүнзгий сэтгэл зүйн сүлжээг ашиглаж байдаг. Хоёр дахь кодировчлолын онол тархинд тодорхой ойлголт нь хэл хэлний болон харагдах болон абстракт ойлголт зөвхөн хэл хэлний аргаар кодлогддог гэж үздэг. FMRI өгөгдлийг хүн төрөлхтний тодорхойлолтой тодорхойлолтой хувааж, хоёр загвар нь хамгийн тодорхойлолтой нэр тодорхойлолтой гэдгийг бид анзаарлаа. Гэхдээ тодорхойлолт нь текст суурилсан загваруудыг хамгийн abstract нэртэй ашиглан илүү их юм. Энэ нь ихэвчлэн орчин үеийн тооцооллын загварууд тархинд abstract ойлголтын төлөөлөлтийн бүтэц судалгаанд хангалттай хөгжиж байгааг баталдаг.', 'ro': 'Recent s-au făcut progrese importante utilizând modele semantice computaționale pentru a decoda modelele de activitate cerebrală asociate conceptelor; Cu toate acestea, această lucrare s-a concentrat aproape exclusiv pe substantive concrete. Cât de bine se extind aceste modele la decodarea substantivelor abstracte este în mare parte necunoscut. Rezolvăm această întrebare prin aplicarea unor modele computaționale de ultimă generație pentru decodarea modelelor funcționale de imagistică prin rezonanță magnetică (fMRI), provocate de participanții care citesc și își imaginează un set divers de substantive concrete și abstracte. Unul dintre modelele pe care le folosim este lingvistic, exploatând recenta abordare word2vec skipgram instruită pe Wikipedia. Al doilea este bazat vizual, folosind rețele neuronale convoluționale profunde instruite pe Google Images. Teoria codării duale consideră conceptele concrete ca fiind codificate în creier atât lingvistic, cât și vizual, iar conceptele abstracte numai lingvistic. Împărțind datele fMRI în funcție de clasificarea concretenței umane, observăm într-adevăr că ambele modele decodează semnificativ substantivele cele mai concrete; Cu toate acestea, acuratețea este semnificativ mai mare folosind modelele bazate pe text pentru substantivele cele mai abstracte. Mai general, acest lucru confirmă faptul că modelele computaționale actuale sunt suficient de avansate pentru a ajuta la investigarea structurii reprezentative a conceptelor abstracte din creier.', 'sr': 'Nedavno su napredovali važni napredak koristeći kompjuterske semantičke modele za dekodiranje obrazaca aktivnosti mozga povezanih sa konceptima; Međutim, ovaj rad je skoro ekskluzivno fokusiran na betonske imene. Koliko dobro se ovi modeli šire na dekodiranje abstrakta imena u velikoj mjeri nepoznati. Rešimo to pitanje primjenjivanjem state-of-the-art računalnih modela za dekodiranje funkcionalnih obrazaca aktivnosti magnetičke rezonance (fMRI), koje su uključivali učesnici čitajući i zamišljajući različite sete betonskih i abstraktnih imena. Jedan od modela koje koristimo je jezički, iskorištavajući nedavni pristup skipgrama rečenih na Wikipedia. Drugi je vizualno osnovan, koristeći duboke konvolucionalne neuralne mreže obučene na Google Images. Dualna teorija kodiranja smatra konkretnim konceptima kodiranim u mozgu i jezički i vizualno, i apstraktičkim konceptima samo jezički. Podjeljući podatke o fMRI prema ocjenama ljudske konkretnosti, zapravo posmatramo da obje modele značajno dekodiraju najkonkretnije ime; Međutim, preciznost je značajno veća koristeći modele na tekstu za najapstraktnije ime. Običnije to potvrđuje da su trenutni kompjuterski modeli dovoljno napredni da bi pomogli u istraživanju predstavne strukture apstrakta koncepta u mozgu.', 'si': 'වැදගත් ප්\u200dරධානයක් පරීක්ෂණය සම්පූර්ණයෙන් සම්පූර්ණය සම්පූර්ණයෙන් සම්බන්ධ වෙනුවෙන් මොළු ව නමුත්, මේ වැඩේ පුළුවන් විශේෂයෙන් කොන්ක්\u200dරීට් නම් වලට ප්\u200dරධානය කරලා තියෙනවා. මේ මොඩේල් කොච්චර හොඳින් විසින් විසින් විසින් විසින් විසින් විසින් විසින් විසින් වි අපි මේ ප්\u200dරශ්නය විශ්වාස කරන්නේ කාර්යාත්මක විශ්වාසිත විද්\u200dයාත්මක විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත වි අපි පාවිච්චි කරපු මොඩල් එකක් විකිපිඩියා වලින් ප්\u200dරයෝජනය කරනවා. දෙවෙනි පිළිබඳින් පිළිබඳින්, ගුගුල් පිළිබඳින් පිළිබඳින් ප්\u200dරශ්නය කරලා තියෙන ගො දූලික කෝඩින් සිද්ධානය හිතන්නේ කොන්ක්\u200dරීට් අදහස් මොළුවේ භාෂාවික සහ ප්\u200dරදේශයෙන් සහ භාෂාවික විතරයි ක fMRI දත්ත වෙනුවෙන් මිනිස්සු කොන්ක්\u200dරේටින්ස් රේටින්ස් වලට, අපි ඇත්තටම බලන්නේ මොඩේල් දෙන්නම් විශේෂයෙන් වැඩි නමුත්, සැකසුම් විශේෂය විශේෂයෙන් විශේෂයෙන් විශේෂය විශේෂයෙන් පාළුවන් අධාරිත මොඩේල සාමාන්\u200dයයෙන්ම මේක තහවුරු කරනවා මොළුවේ ප්\u200dරතිචාර පරීක්ෂණාත්මක පරීක්ෂණාත්මක පරීක්ෂණය කරන්න පුළුවන් විසි', 'so': "Dhab ahaantii waxaa la sameeyay horumarinta muhiimka ah oo lagu isticmaalay tusaalayaal xisaabta ah si uu u dexeeyo noocyada waxqabadka maskaxda ee la xiriira fikrada; Si kastaba ha ahaatee, shaqadaas waxay si gaar ah ugu kalsoonaatay noocyo la xiriira. Sida wanaagsan tusaalahaas waxay u dheer yihiin in la kooban karo cuntada abstract si badan loo aqoon karo. Waxan ka sheekaynaynaa su'aalahan si aan u codsanayno noocyada xisaabta si ay u dexeeyo noocyada waxqabadka ee magnetic Resonance Imaging (fMRI), taas oo loo qoray kuwa ka qeybqaaday inay akhriyaan iyo ku fekeraan noocyo kala duduwan oo la xiriira iyo inay ka fikiraan noocyo kala duduwan. Mid ka mid ah qaababka aan ku isticmaalno waa luuqad, waxaana isticmaalaya qaabka loo baray Wikipedia ee ugu dambeeyey qoraalka 2vec. Mida labaad ayaa si muuqata ah loo dhigay, waxaa lagu isticmaalaa shabakado caqliga ah oo aad u weyn oo lagu baray sawirada Google. Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically.  Qeybinta FMRI si waafaqsan qiimaha biniaadaha, waxaynu fiirinnaa in labadoodu ay si muhiim ah u kooban yihiin cuntada ugu fiican; Si kastaba ha ahaatee, si muhiim ah waa ka weyn tahay isticmaalka noocyada qoraalka ee ugu badnaan cuntada. Inta badan waxan xaqiijiyaa in qaababka xisaabta ee joogta ah lagu horumariyo si ku filan in lagu caawiyo baaritaanka dhismaha rasmiga ah ee fikrada abstract ee maanka ku jira.", 'sv': 'Viktiga framsteg har nyligen gjorts med hjälp av beräkningsmässiga semantiska modeller för att avkoda hjärnaktivitetsmönster förknippade med begrepp. Detta arbete har dock nästan uteslutande fokuserat på konkreta substantiv. Hur väl dessa modeller sträcker sig till att avkoda abstrakta substantiv är till stor del okänt. Vi behandlar denna fråga genom att tillämpa state-of-the-art beräkningsmodeller för att avkoda funktionella aktivitetsmönster för magnetisk resonans imaging (fMRI), framkallade av deltagare som läser och föreställer sig en mångfald av både konkreta och abstrakta substantiv. En av de modeller vi använder oss av är språklig och utnyttjar den senaste word2vec skipgram metoden som tränats på Wikipedia. Den andra är visuellt förankrad, med hjälp av djupa konvulutionella neurala nätverk utbildade på Google Images. Dubbelkodningsteori anser att konkreta begrepp kodas i hjärnan både språkligt och visuellt, och abstrakta begrepp endast språkligt. Genom att dela upp fMRI-data enligt human concreteness ratings observerar vi faktiskt att båda modellerna signifikant avkodar de mest konkreta substantiven; Noggrannheten är dock betydligt större med hjälp av textbaserade modeller för de mest abstrakta substantiven. Mer allmänt bekräftar detta att nuvarande beräkningsmodeller är tillräckligt avancerade för att hjälpa till att undersöka den representativa strukturen av abstrakta begrepp i hjärnan.', 'ta': 'சமீபத்தில் முக்கியமான முன்னேற்றங்கள் கணிப்பாக அமைப்பு மாதிரிகளை பயன்படுத்தி மூளை செயல்பாடு முறைமைகளை குறைவாக்க ஆனால், இந்த வேலை மிகவும் குறிப்பிட்ட கூட்டத்திற்கு கவனம் செலுத்தப்பட்டது. இந்த மாதிரிகள் எவ்வளவு நன்றாக அதிகரிக்கப்பட்டுள்ளது என்பது பெரிய தெரியாது. நாம் இந்த கேள்வியை பயன்படுத்தி செயல்பாடு மாநிலத்தின் கணக்கீட்டு மாதிரிகளை பயன்படுத்தி செயல்பாட்டின் செயல்பாடு பிம்பத்தை குறியீட்டாக்குவதற்கு, பங்கீடாளர்கள் படித்த நாம் பயன்படுத்தும் மாதிரிகளில் ஒன்று விகிபிடியாவில் பயிற்சி செய்யப்பட்டுள்ள அணுகுகளை பயன்படுத்துகிறது. இரண்டாவது பார்வையில் பார்க்கப்பட்டுள்ளது, ஆழமான தொழில்நுட்பமான பாதுகார வலைப்பின்னல்களை பயன்படுத்து இருமுறை குறியீட்டு திட்டம் மூளையிலும் மொழியிலும் பார்வையிலும் குறியீட்டு கருத்துக்களை மட்டும் மொழியில் மட்டும் குறி FMRI தரவை மனித உறுதிப்படுத்தும் விகிதமாக பிரிக்கிறது, இவ்விரண்டு மாதிரிகளும் முக்கியமாக குறிக்கப்படும் முக்கியமான கூட்ட ஆனால், சரியான மதிப்பு மிகவும் அதிகமாக உரையில் அடிப்படையான மாதிரிகளை பயன்படுத்துவது அதிகமாக உள்ளது. மேலும் பொதுவாக இந்த உறுதிப்படுத்துகிறது தற்போதைய கணக்கீட்டு மாதிரிகள் போதுமான முன்னேற்றப்பட்டுள்ளது என்று மூளையில் உள்ள abstract கர', 'ur': 'اچھے وقت مغز کی فعالیت پٹرنوں کو ڈیکوڈ کرنے کے لئے کمپیوٹریشن سیمانٹیک موڈل کے استعمال سے اہم اضافہ کیا گیا ہے۔ لیکن یہ کام قریب تھا کہ صرف قطعہ نوم پر تمرکز کیا گیا ہے۔ یہ موڈل کس طرح اچھی طرح پھیلاتے ہیں کہ مطلق نام کو دھوکا دینے کے لئے۔ ہم اس سؤال کے ذریعہ اس کے سوال سے دریافت کرتے ہیں کہ مگنٹیکی رسونس تصاویر (fMRI) فعالیت پھیلانے کے لئے فعالیت کی حالت-کمپیوٹریشن موڈل کو ڈیکوڈ کریں، جو مشرکوں کے ذریعہ پڑھنے اور تصور کرنے کے لئے مشرکوں کی ایک مختلف مجموعہ ہے اور ایک مختلف مجموعہ ہے ہم استعمال کرتے ہیں ایک مدل زبان شناسی ہے، جو ویکیپیڈیا پر تعلیم دی جاتی ہے اچھی زبان 2vec skipgram کے مطابق استعمال کرتا ہے. دوسرا، گوگل تصاویروں پر تعلیم یافتہ عمیق کنویرول نیورال نیورال نیٹورک کے استعمال کرتے ہیں. دوئولی کوڈینگ تئوری مغز میں قطعی نظریں کوڈ کیڈ کیڈ کیے جاتے ہیں اور صرف زبان کے طور پر اور صرف زبان کے طور پر۔ FMRI ڈیٹا انسان کی قطعیت ریٹینگ کے مطابق تقسیم کرتے ہیں، ہم یقیناً دیکھتے ہیں کہ دونوں نمائندے سب سے زیادہ قطعہ نام کو دھوکا دیتے ہیں۔ لیکن دقیق بہت زیادہ ہے کہ متن کی بنیادی موڈل کے مطابق بہت اچھے ناموں کے لئے۔ اس سے زیادہ مطمئن ہوتا ہے کہ موجود کمپیوٹریشن موڈل مغز میں مضبوط نظریوں کی نمونی ساختار کی تحقیق کرنے کے لئے کافی پیشرفت کی جاتی ہیں۔', 'uz': "Yaqinda muhim darajalar kompyuterning semantik modellari bilan foydalanishdan foydalanilgan edi, conceptlar bilan bogʻliq boʻlgan miya aktiv patternlarini kodlash uchun; Lekin, bu ishni faqat bir nechta narsalarni foydalanadi. Bu modellar abstract nounlarni ko'rishga qanday ajratiladi, juda katta nomaʼlum. Biz bu savol bilan hisoblash muvaffaqiyatlarini qo'llashda, bu muammolarni foydalanamiz. Bu muammolarning o'qish va bir nechta bir nechta koncrete va abstract nuqta bilan o'ylab ko'rinishimiz mumkin. Biz ishlatadigan modelлардан biri tillik tilidan, yaqinda Wikipedia o'rganilgan so'zlardan 2vek skipgram tilidan foydalanish. Ikkinchi narsa Google rasmlarida o'rganilgan juda muvaffaqiyatli neyron tarmoqlaridan foydalanadi. Ikkita kodlash nazari miyadagi koncrete g'oyalarni o'ylab, lingʻatda va ko'rinishda kodlash mumkin, va faqat fikrlarni o'zgartirish fikrlarini tillarda kodlash mumkin. FMRI maʼlumotlarini inson shaxsiy darajasi bilan ajratish mumkin, biz bu ikkita modellarni eng muhimiy koʻpaytirish mumkin; however, accuracy is significantly greater using the text-based models for the most abstract nouns.  Ko'p narsa bu kompyuter modellarini miyadagi abstract conceptlarining representational structural tizimini qidirish uchun yetarli darajada yordam beradi.", 'vi': 'Những tiến bộ quan trọng đã được thực hiện gần đây bằng các mô hình ngữ pháp tính để giải mã các mô hình hoạt động não liên quan đến các khái niệm. Tuy nhiên, công việc này chỉ tập trung vào các danh từ bê tông. Không rõ các mô hình này bao gồm việc giải mã các danh từ trừu tượng. Chúng tôi giải quyết vấn đề này bằng cách áp dụng các mẫu tính thời đại tiên tiến để giải mã các mô hình hoạt động từ dự án hình dung ra (fMRI) hoạt động được tạo ra bởi những người tham gia đọc và tưởng tượng các danh từ cụ thể và trừu tượng khác nhau. Một trong những mẫu chúng ta dùng là ngôn ngữ, khai thác phương pháp thoát từ 2Véc gần đây được đào tạo trên Wikipedia. Thứ hai được ẩn hình trực tiếp, sử dụng các mạng thần kinh xoắn sâu được đào tạo trên Google Images. Giả thuyết viết kép cho rằng các khái niệm cụ thể được mã hóa trong não, cả ngôn ngữ lẫn hình, và chỉ các khái niệm trừu tượng. Phân chia dữ liệu FMRI theo tỉ lệ xác thực của con người, chúng tôi nhận thấy cả hai mô- tượng đều có khả năng giải mã danh từ cụ thể nhất. Tuy nhiên, độ chính xác còn lớn hơn nhiều khi dùng các mẫu văn bản cho các danh từ trừu tượng nhiều. Thông thường hơn, điều này xác nhận rằng các mô hình tính hiện tại đã được nâng cao đủ để giúp đỡ nghiên cứu cấu trúc đại diện của các khái niệm trừu tượng trong não.', 'hr': 'Nedavno su napredovali važni napredak koristeći računalne semantičke modele za dekodiranje obrazaca aktivnosti mozga povezanih s konceptima; Međutim, ovaj rad je skoro ekskluzivno usredotočen na betonsko ime. Koliko dobro se ovi modeli šire do dekodiranja abstraktnih imena u velikoj mjeri nepoznati. Odgovaramo o ovom pitanju primjenjivanjem state-of-the-art računalnih modela za dekodiranje funkcionalnih obrazaca aktivnosti Magnetic Resonance Imaging (fMRI), kojima su učesnici pročitali i zamišljali različite skupine betonskih i apstraktnih imena. Jedan od modela koje koristimo je jezički, iskorištavajući nedavni pristup skipgrama u riječi 2vec obučen na Wikipedia. Drugi je vizualno osnovan, koristeći duboke konvolucionalne neuralne mreže obučene na Google Images. Dualna teorija kodiranja smatra da se konkretni koncepti kodiraju u mozgu i jezički i vizualno i apstraktički koncepti samo jezički. Podjeljući podatke o fMRI prema ocjenama ljudske konkretnosti, zapravo posmatramo da obje modele značajno dekodiraju najkonkretnije ime; Međutim, preciznost je značajno veća koristeći modele na tekstu za najapstraktnije ime. Običnije to potvrđuje da su trenutni računalni modeli dovoljno napredni da bi pomogli istraživanju predstavne strukture apstrakta koncepta u mozgu.', 'bg': 'Неотдавна е постигнат значителен напредък с помощта на изчислителни семантични модели за декодиране на моделите на мозъчна активност, свързани с концепциите; обаче, тази работа се фокусира почти изключително върху конкретните съществителни. Колко добре тези модели се разпространяват до декодиране на абстрактни съществителни е до голяма степен неизвестно. Ние решаваме този въпрос, като прилагаме най-съвременни изчислителни модели за декодиране на функционални модели на активност на магнитно резонансно изображение (ВМР), предизвикани от участниците, които четат и си представят разнообразен набор от конкретни и абстрактни съществителни. Един от моделите, които използваме, е лингвистичен, използващ скорошния подход, обучен в Уикипедия. Вторият е визуално заземен, използвайки дълбоки конволюционни невронни мрежи, обучени на изображения в Гугъл. Теорията на дуалното кодиране разглежда конкретни понятия, които се кодират в мозъка както лингвистично, така и визуално, а абстрактните понятия само лингвистично. Разделяйки данните според оценките на човешката конкретност, наистина наблюдаваме, че и двата модела значително декодират най-конкретните съществителни; обаче точността е значително по-голяма при използване на текстово-базираните модели за най-абстрактните съществителни. По-общо това потвърждава, че настоящите изчислителни модели са достатъчно напреднали, за да помогнат в изследването на представителната структура на абстрактните понятия в мозъка.', 'nl': 'Recent zijn belangrijke vorderingen gemaakt met behulp van computationele semantische modellen om hersenactiviteitspatronen geassocieerd met concepten te decoderen; Dit werk heeft zich echter bijna uitsluitend gericht op concrete zelfstandige naamwoorden. Hoe goed deze modellen zich uitbreiden tot het decoderen van abstracte zelfstandige naamwoorden is grotendeels onbekend. We pakken deze vraag aan door state-of-the-art computermodellen toe te passen om functionele activiteitenpatronen van Magnetic Resonance Imaging (fMRI) te decoderen, opgewekt door deelnemers die een gevarieerde set van zowel concrete als abstracte zelfstandige naamwoorden lezen en verbeelden. Een van de modellen die we gebruiken is linguïstisch, gebruikmakend van de recente word2vec skipgram aanpak die is getraind op Wikipedia. De tweede is visueel geaard, met behulp van diepe convolutionele neurale netwerken getraind op Google Images. De duale coderingstheorie beschouwt concrete concepten als gecodeerd in de hersenen zowel taalkundig als visueel, en abstracte concepten alleen taalkundig. Door de fMRI-gegevens te splitsen op basis van menselijke concretheidscijfers, zien we inderdaad dat beide modellen significant de meest concrete zelfstandige naamwoorden decoderen; Echter, de nauwkeurigheid is aanzienlijk groter met behulp van de op tekst gebaseerde modellen voor de meest abstracte zelfstandige naamwoorden. Meer in het algemeen bevestigt dit dat de huidige computermodellen voldoende geavanceerd zijn om te helpen bij het onderzoeken van de representatieve structuur van abstracte concepten in de hersenen.', 'da': 'Der er for nylig gjort vigtige fremskridt ved hjælp af beregningsmæssige semantiske modeller til afkodning af hjerneaktivitetsmønstre i forbindelse med begreber; Men dette arbejde har næsten udelukkende fokuseret på konkrete substantiver. Hvor godt disse modeller strækker sig til at afkode abstrakte navneord er stort set ukendt. Vi behandler dette spørgsmål ved at anvende state-of-the-art beregningsmodeller til at afkode funktionelle magnetiske resonance imaging (fMRI) aktivitetsmønstre, fremkaldt af deltagere, der læser og forestiller sig et varieret sæt af både konkrete og abstrakte substantiver. En af de modeller, vi bruger, er sproglig, og udnytter den nylige word2vec skipgram tilgang trænet på Wikipedia. Den anden er visuelt grundlagt ved hjælp af dybe konvulutionelle neurale netværk trænet på Google Images. Dobbelt kodningsteori betragter konkrete begreber som indkodet i hjernen både sprogligt og visuelt, og abstrakte begreber kun sprogligt. Ved at opdele fMRI-data i henhold til menneskelige konkrethedsvurderinger observerer vi faktisk, at begge modeller afkoder betydeligt de mest konkrete substantiver; Men nøjagtigheden er betydeligt større ved hjælp af tekstbaserede modeller til de mest abstrakte substantiver. Mere generelt bekræfter dette, at nuværende beregningsmodeller er tilstrækkeligt avancerede til at hjælpe med at undersøge den repræsentative struktur af abstrakte begreber i hjernen.', 'de': 'In letzter Zeit wurden wichtige Fortschritte mit Hilfe von computergestützten semantischen Modellen erzielt, um Gehirnaktivitätsmuster zu entschlüsseln, die mit Konzepten verbunden sind. Diese Arbeit konzentriert sich jedoch fast ausschließlich auf konkrete Substantive. Wie gut sich diese Modelle auf die Dekodierung abstrakter Substantive erstrecken, ist weitgehend unbekannt. Wir gehen dieser Frage nach, indem wir modernste Computermodelle anwenden, um funktionelle Aktivitätsmuster der Magnetresonanztomographie (fMRT) zu entschlüsseln, die von den Teilnehmern hervorgerufen werden, die eine Vielzahl von konkreten und abstrakten Substantiven lesen und sich vorstellen. Eines der Modelle, die wir verwenden, ist linguistisch und nutzt den aktuellen Word2vec Skipgram Ansatz, der auf Wikipedia trainiert wurde. Das zweite ist visuell geerdet und verwendet tiefe neuronale Netze, die auf Google Images trainiert wurden. Die duale Codierungstheorie betrachtet konkrete Konzepte als linguistisch und visuell kodiert, abstrakte Konzepte nur linguistisch. Bei der Aufteilung der fMRT-Daten nach menschlichen Konkretenheitswerten beobachten wir tatsächlich, dass beide Modelle die konkretesten Substantive signifikant entschlüsseln; Allerdings ist die Genauigkeit bei den textbasierten Modellen für die abstraktesten Substantive deutlich größer. Generell bestätigt dies, dass aktuelle Rechenmodelle ausreichend fortgeschritten sind, um die Repräsentationsstruktur abstrakter Konzepte im Gehirn zu untersuchen.', 'ko': '최근 계산 의미 모델을 이용하여 개념과 관련된 뇌 활동 모델을 디코딩하는 데 중요한 진전을 거두었다.그러나 이 일은 거의 구체적인 명사에만 주목한다.이 모델들이 추상적인 명사에 대한 디코딩으로 얼마나 확장되었는지는 아직 분명하지 않다.우리는 가장 선진적인 계산 모델을 응용하여 기능성 자공진상(fMRI) 활동 모델을 디코딩함으로써 이 문제를 해결한다. 이 모델은 참여자들이 서로 다른 구체적이고 추상적인 명사를 읽고 상상하는 데 의해 발생한다.우리가 사용하는 모델 중 하나는 언어학으로 최근 위키백과에서 교육된word2vec skipgram 방법을 이용한다.두 번째는 시각적 기반으로 구글 이미지에서 훈련된 심도 권적 신경 네트워크를 사용한다.이중 인코딩 이론은 구체적인 개념은 언어와 시각적으로 모두 뇌에서 인코딩해야 하고 추상적인 개념은 언어에서만 인코딩해야 한다고 주장한다.인류의 구체적인 등급 분할 기능인 자공진 영상 데이터에 근거하여 우리는 두 모델 모두 가장 구체적인 명사를 현저하게 해독할 수 있음을 확실히 관찰했다.그러나 가장 추상적인 명사에 대해서는 텍스트 기반 모델을 사용하는 정확성이 훨씬 높다.더욱 보편적으로 말하면 이것은 현재의 계산 모델이 이미 충분히 선진적이며 뇌에서 추상적인 개념의 표징 구조를 연구하는 데 도움을 줄 수 있음을 증명한다.', 'id': 'Kemajuan penting baru-baru ini telah dibuat menggunakan model semantis komputasi untuk mendekode pola aktivitas otak yang terkait dengan konsep; namun, pekerjaan ini hampir eksklusif fokus pada nama konkrit. Seberapa baik model ini memperluas ke dekodifikasi nama abstrak kebanyakan tidak diketahui. Kami mengatasi pertanyaan ini dengan menggunakan model komputasi state-of-the-art untuk mendekode pola aktivitas Imaging Resonance Magnetic (fMRI) fungsional, disebabkan oleh peserta membaca dan membayangkan set berbagai nama konkrit dan abstrak. Salah satu model yang kita gunakan adalah bahasa, mengeksploitasi pendekatan kata 2vec skipgram baru-baru ini dilatih di Wikipedia. Yang kedua terletak secara visual, menggunakan jaringan saraf konvolusi dalam dilatih di Google Images. Teori kode dua mempertimbangkan konsep konkrit untuk dikodeksi di otak secara bahasa dan visual, dan konsep abstrak hanya secara bahasa. Membahagikan data fMRI menurut nilai konkretesi manusia, kita benar-benar memperhatikan bahwa kedua model secara signifikan mendekode nama yang paling konkrit; namun, akurasi jauh lebih besar menggunakan model berdasarkan teks untuk nama yang paling abstrak. Lebih umum ini mengkonfirmasi bahwa model komputasi saat ini cukup maju untuk membantu dalam penyelidikan struktur representatif konsep abstrak di otak.', 'tr': '횦akynda hem wajyp geli힊meler komp첵uter semantik nusgalary ulanyp beyin janla힊lygyny d체힊체njeler bilen kodlamak 체챌in edildi. 횦철ne bu i힊i흫 di첵en 첵aly beton adlaryna 체ns berdi. Bu nusgalar abstrakt adlary k철dlemek 체챌in n채hili gowy 첵agda첵la첵ar. Biz bu soragy m철h체m-sanat kalkulary흫 durumyny ulanyp fonksiyonal Maglumat Resonance Imaginy흫 (fMRI) aktiwitet nusgalaryny 챌ykarmak 체챌in 챌ykaryp 챌yk첵arys. Kulland캇휓캇m캇z nusgalary흫 biri, wikipedi첵ada bilim al첵an 2-nji s철z 첵igramyny ulan첵ar. Ikinjisi g철rn체힊de g철rn체힊de, Google Resimleri 체zerinde okuw챌ylan gaty g철rn체힊 ne첵ralar 힊ebekeleri ulan첵arlar. Ikinji k철dleme teori첵asy beynini흫 hem dil-g철rn체힊de hem k철dleme di첵ip pikir ed첵채r, hem abstrakt d체힊체nceleri di흫e dil-g철rn체힊de k철dleme di첵ip pikir ed첵채r. FMRI maglumaty adamlary흫 takyklygyna g철r채 b철lmek 체챌in, ikimiz modelleri흫 i흫 beton isimlerini a챌yp 철r채n m철h체m bir 힊ekilde g철zle첵채ris; Adat챌a, i흫 abstrakt Adlar 체챌in metin tabanly nusgalary ullan첵an 철r채n beter. Munu흫 k철p b철legi h채zirki hesaplamak nusgalaryny흫 beynini흫 abstrakt d체힊체njelerini흫 t채sirini barlamak 체챌in 첵eterlik 첵체ze geli힊megini tassykla첵ar.', 'sw': 'Maendeleo muhimu hivi karibuni yametengenezwa kwa kutumia mifano ya sekundi ya kompyuta ili kupunguza mitindo ya shughuli za ubongo zinazohusiana na dhana; Hata hivyo, kazi hii imekuwa ikijikita kwenye nyama za mahsusi. Ni vizuri namna hii mifano inavyoongezeka kupunguza chakula cha chakula cha ubaguzi kinachojulikana sana. Tunaongelea swali hili kwa kutumia mifano ya sanaa ya kudhibiti mfumo wa shughuli za kutengeneza picha za Magneti (fMRI), ulioonyeshwa na washiriki kusoma na kufikiria aina mbalimbali za vifaa vingine vya ushirika na visivyo vinavyojitenga. Moja ya mifano tunayotumia ni lugha, kwa kutumia mbinu za hivi karibuni za maneno ya ndege 2vec zilizofundishwa kwenye Wikipedia. Pili ya pili imewekwa wazi, kwa kutumia mitandao ya kijamii ya kikatili yaliyofundishwa kwenye Picha za Google. nadharia ya kupiga kura mbili inafikiri dhana mahsusi ya kubandikwa katika ubongo, kwa lugha na kwa kuona, na dhana za kujitoa kwa lugha pekee. Kugawanya takwimu za FMRI kwa mujibu wa kiwango cha uhakika wa binadamu, kwa hakika tunaona kuwa mifano yote inapungua kwa kiasi kikubwa kabisa chakula cha mahsusi; Hata hivyo, uhakika ni mkubwa zaidi kwa kutumia mifano yenye msingi wa maandishi kwa ajili ya chakula kikubwa zaidi. Kwa ujumla zaidi hili linathibitisha kuwa mifano ya sasa ya kompyuta imeboreshwa kutosha ili kusaidia kuchunguza muundo wa uwakilishi wa mawazo ya abstract akili.', 'af': "Onlangs is belangrike avansies gemaak deur rekenasielike semantiese modele te gebruik om brein aktiviteit patrone te dekodeer wat met konsepte geassosieer is; en maar hierdie werk het amper eksklusief gefokus op beteken noume. Hoe goed is hierdie modele uitbrei om abstrakte noume te dekodeer is groot onbekende. Ons adreseer hierdie vraag deur toepassing van state-of-the-art rekenaarsies modele om funksionele Magnetic Resonance Imaging (fMRI) aktiviteit patrone te dekode, wat deur deelnaders gelees en te dink van 'n verskeie stel van beteken en abstrakte noume te lees. Een van die modele wat ons gebruik het is lingwisiese, wat die onlangse woorde 2vec skipgramtoegang wat op Wikipedia opgelei is, gebruik. Die tweede is visuele agtergrond, gebruik diep konvolusionele neuralnetwerke wat op Google Beelde onderrig is. Dubbele koderingsteorie veroorsaak beteken konsepte om in die brein te kodeer, linguistiese en visuele, en abstrakte konsepte slegs lingvisiese. In deel van die fMRI data volgens menslike betekenisse belangrikings, ons waarskynlik observeer dat beide modele betekenlik die mees betekenisse noume dekodeer; maar, waarskynlik is betekenlik groter te gebruik die teksbaseerde modele vir die mees abstrakte noute. Meer algemeen bevestig hierdie dat die huidige rekenaasbare modele genoeg gevorderde is om te help in die ondersoek van die reprezentasielle struktuur van abstrakte konsepte in die brein.", 'fa': 'پیشرفتهای مهم اخیرا با استفاده از مدلهای سیمانتیک کامپیوتری برای دکود کردن الگوهای فعالیت مغز ارتباط به نظریه انجام شده است. ولی این کار تقریباً به خاص خاصی روی اسم\u200cهای کنترل تمرکز کرده است. این مدلها چقدر خوب به دیدکاندن نام\u200cهای abstract تغییر می\u200cدهند. ما این سؤال را با استفاده از مدل محاسباتی موقعیت هنری برای دکود کردن الگوهای فعالیت فعالیت مغناطیسی تصاویر (fMRI) فعالیت عملی، که توسط مشتریان خواندن و تصور کردن یک مجموعه مختلف از عنوان\u200cهای کنترل و abstract است، درباره\u200cی استفاده می\u200cکنیم. یکی از مدل\u200cهایی که ما استفاده می\u200cکنیم، زبان\u200cشناسی است که با استفاده از دستور اسکیپگرم\u200cگرم\u200cهای ابتدایی ۲ ویکیپدیا آموزش داده شده است. دومین از شبکه های عصبی عمیقی که روی تصاویر گوگل آموزش داده شده، به صورت تصویر دیده شده است. نظریه\u200cی کودینگ دومیلی به نظر می\u200cرسد که مفهوم\u200cهای کنترلی در مغز همچنین زبان\u200cشناسی و دیده\u200cشناسی و مفهوم\u200cهای abstract فقط به زبان\u200cشناسی کودیک می\u200cشوند. با تقسیم داده\u200cهای fMRI بر اساس مقدار مطمئناً انسان، ما واقعاً مشاهده می\u200cکنیم که هر دو مدل به معنی معنی بیشترین اسم\u200cهای concrete را دکور می\u200cکند. با این حال، دقیق با استفاده از مدل\u200cهای متن برای بیشترین اسم\u200cهای مطلق بیشتر است. عموماً این تایید می\u200cکند که مدل\u200cهای محاسباتی فعلی به اندازه کافی پیشرفت شده است تا کمک کند در تحقیق ساختار نمایش\u200cدهنده\u200cای از نظریه\u200cهای مغز.', 'sq': 'Përparimet e rëndësishme janë bërë kohët e fundit duke përdorur modele kompjuterike semantike për të dekodifikuar modelet e aktivitetit të trurit të lidhur me konceptet; however, this work has almost exclusively focused on concrete nouns.  Sa mirë këto modele shtrihen në dekodimin e emrave abstrakte është e panjohur. Ne e trajtojmë këtë pyetje duke aplikuar modele kompjuterike të moderne për të dekodifikuar modelet funksionale të rezonancës magnetike (fMRI) të veprimtarisë, të nxitura nga pjesëmarrësit që lexojnë dhe imagjinojnë një sërë të ndryshme të emrave konkrete dhe abstrakte. Një nga modelet që përdorim është gjuhësor, duke shfrytëzuar metodën e fundit të fjalë2vec skipgram të stërvitur në Wikipedia. E dyta është e bazuar vizualisht, duke përdorur rrjete nervore të thella konvolutive të trajnuara në Google Images. Teoria e kodimit të dyfishtë konsideron koncepte konkrete të koduara në tru si në mënyrë gjuhësore ashtu edhe vizuale, dhe koncepte abstrakte vetëm në mënyrë gjuhësore. Duke ndarë të dhënat fMRI sipas vlerësimeve të konkretitetit njerëzor, ne vërtet vëzhgojmë se të dy modelet dekodiojnë ndjeshëm emrat më konkrete; megjithatë, saktësia është ndjeshëm më e madhe duke përdorur modelet bazuar në tekst për emrat më abstrakte. More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain.', 'am': 'በአሁኑ ጊዜ የሚያስፈልገው ግንኙነት በአካባቢው ሰሜንቲካ ሞዴላዎችን በመጠቀም የተደረገ ነው፤ አካባቢዎች ጋር የተያያየ የbrain ተግባር ሥርዓቶችን ለማድረግ ነው፡፡ ምንም እንኳን ይህ ሥራ በተለየ ቁጥጥር ላይ ነው፡፡ እነዚህ ምሳሌዎች የውጤት ጉዳይ መሆኑን ለማሳመር እንዴት ያበዛሉ፡፡ ይህንን ጥያቄ የ-አርእስት ሥርዓት አካባቢ ሞዴላዎችን በመጠቀም እናስቀናለን፤ የግንኙነት እና የክፍለ ቁጥጥር እና አካባቢ እና የክፍለ ቁጥጥር እና አካባቢ እና የክፍለ ቁጥጥር እና እና አካባቢ ነው፡፡ One of the models we use is linguistic, exploiting the recent word2vec skipgram approach trained on Wikipedia.  ሁለተኛይቱ በጎግል ምስሎች ላይ የተማሩ የጥልቅ የደዌብ መረብ በመጠቀም ነው፡፡ የሁለተኛ ኮድ ዝና በቋንቋዊ እና ራእይ ሆኖ የኮክሮት ጉዳይ ቋንቋ ብቻ ይቆጥራል፡፡ የFMRI ዳታዎችን በሰው አካባቢነት መጠን በመለየት፣ ሁለቱም ምሳሌዎች በሙሉ ክቡር ጉዳይ እንዲያሳድሩ እናየዋለን፡፡ ነገር ግን እርግጠኛ የጽሑፉን ምሳሌዎች ለመጠቀም በጣም ትልቅ ነው፡፡ በጠቅላላ ይታረጋል፡፡', 'az': 'Önemli avanslar çox yaxın zamanda bilgisayar semantik modellərini istifadə etmək üçün beyin fəaliyyəti modellərini dəkodlamaq üçün yaradılmışdır. Ancaq bu işin az qala beton ismlərinə odaqlanmışdır. Bu modellər abstrakt adlarını deşiklik etməyə nə qədər yaxşı genişlənirlər? Biz bu soruşmayı, funkcional Magnetic Resonance Imagine (fMRI) fMRI fəaliyyəti modellərini kodlamaq üçün sanat modellərini uygulamaq üçün çəkirik, iştirakçıların oxuyan və hər ikisinin beton və abstrakt adlarının müxtəlif bir qurduğunu düşünürlər. Bizim istifadə etdiyimiz modellərdən biri, Wikipediada təhsil edilmiş yeni sözlərin 2vec skipgram tərzini istifadə edir. İkincisi Google Görüntüləri üzərində təhsil edilmiş derin konvolucional nöral ağlarını istifadə edir. İkinci kodlama teoriji beyninin dil-görsel və abstrakt fikirlərin yalnız dil-görsel kodlanmasını düşünür. FMRI məlumatlarını insan nöqsanlıqlarına görə bölüşdürdük, biz həqiqətən də hər iki modellərin ən beton ismlərini çox dəyişdirir. Ən abstraktlı isimlər üçün metin tabanlı modellərdən istifadə etmək çox böyükdür. Daha çox təsdiqləyir ki, ağıllıq hesaplama modellərinin beynində abstrakt fikirlərin təsdiqlənməsi üçün yardım etmək üçün kifayət qədər uzaqlaşdırılmışdır.', 'hy': 'Վերջերս կարևոր առաջընթացներ են կատարվել օգտագործելով հաշվարկների սեմանտիկ մոդելներ ուղեղի ակտիվության կաղապարների բացահայտելու համար, որոնք կապված են հասկացությունների հետ: however, this work has almost exclusively focused on concrete nouns.  Ինչքա՞ն լավ են այս մոդելները ընդլայնվում վերացական անվանումների դեկոդավորմանը մեծամասամբ անհայտ է: Մենք լուծում ենք այս հարցը, օգտագործելով ամենահետագա հաշվարկների մոդելները ֆունկցիոնալ Մագետիկ Ռեզոնանսանսանսային պատկերացման (fMRI) գործունեության կաղապարների կոդավորման համար, որոնք առաջացել են մասնակիցների կարդալով և պատկերացնելով բետոնական և վերացական անվանների բազմազան շա Մենք օգտագործում ենք լեզվաբանական մոդելներից մեկը, օգտագործելով Վիքիփեդիայում սովորեցված վերջին բառերի 2Վ խուսագրամը: Երկրորդը տեսողական հիմքն է, օգտագործելով Google-ի պատկերներում վարժեցված խորը հակառակցող նյարդային ցանցեր: Երկու կոդավորման տեսությունը կարծում է, որ կոնկրետ գաղափարները կոդավորված են ուղեղում լեզվաբանական և տեսողական առումով, և միայն վերացական գաղափարները լեզվաբանական առումով: ՖՄՌԻ տվյալները բաժանելով ըստ մարդկային կոնկրետության գնահատականների, մենք իրականում նկատում ենք, որ երկու մոդելները կարևոր կերպ բացահայտում են ամենաբետոնական անունները: այնուամենայնիվ, ճշգրտությունը շատ ավելի մեծ է օգտագործելով տեքստի հիմնված մոդելները ամենավերացական անվանների համար: Ավելի ընդհանուր առմամբ սա հաստատում է, որ ներկայիս հաշվարկների մոդելները բավարար զարգացած են, որպեսզի օգնեն ուսումնասիրել ուղեղի վերացական գաղափարների ներկայացուցիչ կառուցվածքը:', 'bs': 'Nedavno su napredovali važni napredak koristeći kompjuterske semantičke modele za dekodiranje obrazaca aktivnosti mozga povezanih sa konceptima; Međutim, ovaj rad je skoro ekskluzivno usredotočen na betonske imene. Koliko dobro se ovi modeli šire na dekodiranje abstrakta imena u velikoj mjeri nepoznato. Odgovaramo o ovom pitanju primjenjivanjem state-of-the-art računalnih modela za dekodiranje funkcionalnih obrazaca aktivnosti Magnetic Resonance Imagine (fMRI), koje izrađuju učesnici čitanja i zamišljajući različite skupine betonskih i apstraktnih imena. Jedan od modela koje koristimo je lingvistički, koristeći nedavni pristup skipgrama 2veka obučen na Wikipedia. Drugi je vizualno osnovan, koristeći duboke konvolucione neuralne mreže obučene na Google Images. Dualna teorija kodiranja smatra konkretnim konceptima kodiranim u mozgu i jezički i vizualno, i apstraktičkim konceptima samo jezički. Podjeljući podatke o fMRI prema ocjenama ljudske konkretnosti, zapravo posmatramo da obje modele značajno dekodiraju najkonkretnije ime; Međutim, preciznost je značajno veća koristeći modele na tekstu za najapstraktnije ime. Običnije to potvrđuje da su trenutni računalni modeli dovoljno napredni da bi pomogli istraživanju predstavne strukture apstrakta koncepta u mozgu.', 'bn': 'সম্প্রতি গুরুত্বপূর্ণ উন্নয়ন তৈরি করা হয়েছে ধারণার সাথে সম্পর্কিত মডেলের মাধ্যমে মস্তিষ্কের কার্যক্রমের প্রান্ত তবে, এই কাজ প্রায় একেবারেই নির্দিষ্ট নিষেধাজ্ঞার উপর মনোযোগ দিয়েছে। এই মডেলগুলো কতটা বেশী অজানা যাচ্ছে আকটপ্র্যাক্ট নিষ্কার করার জন্য। We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns.  আমরা যে মডেল ব্যবহার করি তার মধ্যে একটি ভাষার ভাষায়, সাম্প্রতিক ওয়ার্ড২ভিক স্কিপিডিয়ায় প্রশিক্ষণ প্রদান করা হয়েছে তা ব্যবহার কর দ্বিতীয় দৃষ্টিভঙ্গিতে গুগল ছবিতে প্রশিক্ষিত নিউরেল নেটওয়ার্ক ব্যবহার করে গভীর প্রতিষ্ঠিত হয়েছে। দুই কোডিং তত্ত্ব বিবেচনা করে যে মস্তিষ্কের মধ্যে কনক্রিট ধারণা ভাষাভাষিক এবং দৃষ্টিভঙ্গিকভাবে এনকোড করা হবে এবং কেবল ভাষাভাষায় আ মানুষের বৈশিষ্ট্য অনুসারে এফএমআরআই তথ্য বিভক্ত করা হচ্ছে, আমরা সত্যিই দেখতে পাচ্ছি যে উভয় মডেল গুরুত্বপূর্ণ কন্ক্রিটেট নি তবে বেশীর ভিত্তিক মডেল ব্যবহার করে বিশেষ করে সুনির্দিষ্ট নিষ্ক্রিয়ভাবে গুরুত্বপূর্ণ। সাধারণত এই বিষয়টি নিশ্চিত করে যে বর্তমান গণনাত্রিক মডেল যথেষ্ট উন্নত হয়েছে মস্তিষ্কের প্রতিনিধিত্বের কাঠামো তদন্ত করার জন্য।', 'cs': 'V poslední době bylo dosaženo významného pokroku pomocí výpočetních sémantických modelů k dekódování vzorů mozkové aktivity spojených s koncepty; Tato práce se však téměř výhradně zaměřuje na konkrétní podstatná jména. Jak dobře se tyto modely rozšiřují na dekódování abstraktních podstatných jmen, není do značné míry známo. Tuto otázku řešíme využitím nejmodernějších výpočetních modelů k dekódování funkčních vzorů aktivit magnetické rezonance zobrazení (fMRI), které vyvolávají účastníci čtení a představují si rozmanitou sadu konkrétních i abstraktních podstatných jmen. Jedním z modelů, které používáme, je lingvistický, využívající nedávného přístupu Word2vec skipgram trénovaného na Wikipedii. Druhá je vizuálně uzemněna pomocí hlubokých konvolučních neuronových sítí trénovaných na obrázkech Google. Teorie duálního kódování považuje konkrétní pojmy za kódované v mozku jak lingvisticky, tak vizuálně, a abstraktní pojmy pouze lingvisticky. Rozdělením dat fMRI podle hodnot lidské konkrétnosti pozorujeme, že oba modely výrazně dekódují nejvíce konkrétních podstatných jmen; Přesnost je však výrazně vyšší použitím textových modelů pro nejabstraktnější podstatná jména. Obecněji to potvrzuje, že současné výpočetní modely jsou dostatečně pokročilé, aby pomohly při zkoumání reprezentační struktury abstraktních konceptů v mozku.', 'fi': 'Äskettäin on edistytty merkittävästi käyttämällä laskennallisia semanttisia malleja käsitteisiin liittyvien aivojen aktiivisuusmallien purkamiseksi. Tämä työ on kuitenkin keskittynyt lähes yksinomaan konkreettisiin substantiiveihin. Kuinka hyvin nämä mallit ulottuvat abstraktien substantiivien dekoodaamiseen on suurelta osin tuntematonta. Käsittelemme tätä kysymystä soveltamalla viimeisimpiä laskennallisia malleja toiminnallisten magneettiresonanssikuvauksen (fMRI) aktiivisuusmallien dekoodaamiseen, jonka osallistujat lukevat ja kuvittelevat erilaisia sekä konkreettisia että abstrakteja substantiiveja. Yksi käyttämistämme malleista on kielellinen, hyödyntäen viimeaikaista Wikipediassa harjoitettua Word2vec skipgram -lähestymistapaa. Toinen on visuaalisesti maadoitettu käyttämällä Google Imagesin avulla koulutettuja syviä konvolutionaalisia hermoverkkoja. Kaksikoodausteoria pitää konkreettisia käsitteitä koodattavina aivoissa sekä kielellisesti että visuaalisesti ja abstrakteja käsitteitä vain kielellisesti. Kun fMRI-tiedot jaetaan ihmisen betonisuusluokituksen mukaan, huomaamme, että molemmat mallit dekoodavat merkittävästi kaikkein konkreettisimmat substantiivit; Tarkkuus on kuitenkin huomattavasti suurempi abstraktimpien substantiivien tekstipohjaisten mallien avulla. Yleisemmin tämä vahvistaa, että nykyiset laskennalliset mallit ovat riittävän kehittyneitä tutkimaan abstraktien käsitteiden representaatiorakennetta aivoissa.', 'et': 'Hiljuti on tehtud olulisi edusamme, kasutades arvutuslikke semantilisi mudeleid kontseptsioonidega seotud ajuaktiivsuse mustrite dekodeerimiseks; Siiski on see töö keskendunud peaaegu eranditult konkreetsetele nimisõnadele. Kui hästi need mudelid laienevad abstraktsete nimisõnade dekodeerimisele, on suures osas teadmata. Selle küsimuse lahendamiseks rakendame kaasaegseid arvutusmudeleid funktsionaalsete magnetresonantse pildistamise (fMRI) aktiivsusmustrite dekodeerimiseks, mille tekitavad osalejad, kes lugevad ja kujutavad ette mitmekesiseid nii konkreetseid kui abstraktseid nimisõnu. Üks mudelitest, mida me kasutame, on keeleline, kasutades ära hiljutist Word2vec skipgram lähenemisviisi, mida on koolitatud Wikipedias. Teine on visuaalselt maandatud, kasutades sügavaid konvolutsioonilisi neurovõrke, mis on koolitatud Google Images. Topeltkodeerimisteooria käsitleb konkreetseid kontseptsioone, mida kodeeritakse ajus nii keeleliselt kui visuaalselt, ning abstraktseid kontseptsioone ainult keeleliselt. Jagades fMRI andmed vastavalt inimese betoonsuse hinnangule, täheldame tõepoolest, et mõlemad mudelid dekodeerivad oluliselt kõige konkreetsemaid nimisõnu; Kuid täpsus on oluliselt suurem, kasutades tekstipõhiseid mudeleid kõige abstraktsemate nimisõnade puhul. Üldisemalt kinnitab see, et praegused arvutusmudelid on piisavalt arenenud, et aidata uurida abstraktsete kontseptsioonide representatsioonilist struktuuri ajus.', 'ca': "Recentment s'han fet avanços importants utilitzant models semàntics computacionals per descodificar patrons d'activitat cerebral associats a conceptes; però aquesta feina s'ha centrat gairebé exclusivament en noms concrets. Com de bé s'estenen aquests models a descodificar noms abstracts és molt desconegut. Respectem aquesta pregunta aplicant models computacionals més moderns per descodificar patrons d'activitat funcionals de ressonància magnètica (fMRI), provocats pels participants llegint i imaginant un conjunt de noms concrets i abstracts. Un dels models que utilitzem és lingüístic, explotant l'enfocament recient de skipgram de paraules 2vec entrenat a Wikipedia. El segon està basat visualment, utilitzant xarxes neurals convolucionals profunds entrenats en Google Images. Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically.  Dividir les dades fMRI segons les puntuacions de concretetat humana, observem que ambdós models decodifiquen significativament els noms més concrets; però la precisió és significativament més gran utilitzant els models basats en text per als noms més abstracts. En general això confirma que els models computacionals actuals són prou avançats per ajudar a investigar l'estructura representativa de conceptes abstracts del cervell.", 'sk': 'Pred kratkim je bil dosežen pomemben napredek z uporabo računalniških semantičnih modelov za dekodiranje vzorcev možganske aktivnosti, povezanih s koncepti; Vendar se je to delo skoraj izključno osredotočilo na konkretne samostalnike. Kako dobro se ti modeli razširijo na dekodiranje abstraktnih samostalnikov, je večinoma neznano. To vprašanje obravnavamo z uporabo najsodobnejših računalniških modelov za dekodiranje funkcionalnih vzorcev aktivnosti magnetno resonančnega slikanja (fMRI), ki jih udeleženci berejo in si predstavljajo raznolik nabor konkretnih in abstraktnih samostalnikov. Eden od modelov, ki jih uporabljamo, je jezikovni, ki izkorišča nedavni pristop word2vec skipgram, usposobljen na Wikipediji. Drugi je vizualno ozemljen z uporabo globokih konvolucijskih nevronskih omrežij, usposobljenih za Google Slike. Teorija dvojnega kodiranja obravnava konkretne koncepte, ki se v možganih kodirajo tako jezikovno kot vizualno, abstraktne koncepte pa le jezikovno. Če razdelimo podatke fMRI glede na ocene človeške konkretnosti, dejansko ugotavljamo, da oba modela bistveno dekodirajo najbolj konkretne samostalnike; Vendar pa je natančnost bistveno večja z uporabo besedilnih modelov za najbolj abstraktne samostalnike. Na splošno to potrjuje, da so sedanji računalniški modeli dovolj napredni, da pomagajo pri raziskovanju reprezentativne strukture abstraktnih konceptov v možganih.', 'he': 'התקדמות חשובות נעשו לאחרונה באמצעות דוגמניות סמנטיות מחשביות כדי לפענח דפוסי פעילות מוח שקשורות לרעיונות; עם זאת, העבודה הזו כמעט התמקדה בלעדית בשמות בטונים. כמה טוב הדוגמנים האלה מתרחבים לפענוח שמות אסטרקטיות הוא בעיקר לא ידוע. אנו מתייחסים לשאלה הזו באמצעות שימוש מודלים מחשבים חדשים כדי לפענח דפוסי פעילות דמיון מגנטי רזוננס (fMRI) פונקציונאליים, שנגרמו על ידי משתתפים קוראים ומדמיינים קבוצה מגוונת של שמות ביטוניים ובטנים אסטרקטיים. אחד הדוגמנים שאנחנו משתמשים בו הוא שפתי, ניצל את גישת המילה האחרונה 2vec skipgram מאומנת בוויקיפדיה. השנייה מקורקע מבחינה ראייתית, בשימוש ברשתות עצביות משתנות עמוקות מאומנות על תמונות גוגל. תיאוריה של קוד כפול שוקלת מושג מושגים קבועים להיות קודדים במוח גם מבחינה שפתית וגם מבחינה חזותית, ורק מבחינה שפתית. Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns;  עם זאת, מדויקת יותר גדולה משמעותית בשימוש בדוגמנים מבוססים בטקסט עבור השמות הכי אוסטרקטיים. באופן כללי זה מאשר שדוגמנים מחשבים הנוכחיים מתקדמים מספיק כדי לסייע בחקירה במבנה המייצג של מושגים אסטרקטיים במוח.', 'bo': 'རྒྱལ་ཁབ་གལ་ཆེན་ཁག་གིས་སྔོན་དུ་རྩིས་འཁོར་གྱི་སྔོན་ཅིག་གིས་ཤེས་ཀྱི་འགྱུར ཡིན་ནའང་། ལས་ཀ་འདི་ལྟར་ཚོགས་ཀྱི་མིང་དུ་བསྡད་ན་ཁྱད་པར་དབྱིབས་ཆོས་ཡོད། རྣམ་པ་འདི་དག་གིས་གསལ་རྣམ་པ་ལ་ཇི་ལྟར་ཡག་ལག་བསྐྲུན་ཐབས་འཇུག་གི་རེ་བ་མེད་པ་རེད། ང་ཚོས་འདྲི་ཚིག་དང་འཁྲིད་སྐྱོང་བའི་གནས་སྟངས་དང་གཟུགས་རིས་ཀྱི་རྩ་བའི་དཔེ་གཞི་སྤྲོད་ཀྱི་ཐབས་ལམ་དེ་གིས་བཀོལ་སྤྱོད་མི་འདུག ང་ཚོས་བེད་སྤྱོད་པའི་མིག་གཟུགས་གཅིག་ནི་སྐད་ཡིག་གཟུགས་ཀྱི་ཐབས་ལམ་ཞིག་ཡིན། གཉིས་པ་དེ་མཐོང་བའི་རྒྱབ་ལྗོངས་ཡིན། Google གཟུགས་རིས་ལ་སྤྱོད་པའི་ཟབ་སྐྱེས་ཆེན་དྲ་བ་སྤྱོད་བཞིན། དེའི་རྐྱེན་གྱིས་སྤྱོད་པའི་ལྟ་བུའི་ནང་དུ་སྐད་ཡིག་དང་མཐོང་ནུས་ཀྱི་ལྟ་བུའི་ནང་གི་ fMRI་དག་གི་ཚད་དང་མཉམ་དབྱེ་སྟངས་ལ་བསྟུན་ནས་མིག་པའི་རྣམ་པ་གཉིས་ཀྱིས་མིག་དཔེ་བརྗོད་ཡོད་པ་དང་། འོན་ཀྱང་། བདེན་བཤད་དེ་ནི་ཡིག་གེ་གཞི་རྟེན་ནས་མིང་གང་ཡིན་པ་ཚོར་ལག་ལེན་བྱེད་པའི་མིང་། སྤྱིར་བཏང་དང་མཉམ་དུ་རྩིས་འཁོར་གྱི་མིག་རྩལ་གྱི་ཐབས་ལམ་དེ་ཚོ་ཆེས་ཡོད་པ་ལས་མཐུན་རྐྱེན་ཏེ།', 'jv': 'Progress Nanging, uwong saiki gawan iki amèh dumadhi kanggo nganggo-ingkang sampeyan. politenessoffpolite"), and when there is a change ("assertivepoliteness Awakdhéwé mengko question iki karo aplikasi sistem state-of-the-arts komputational model karo decode funksiyonal Jejaring model sing paling dhéwé nggambar luwih(ingkang). Awak dhéwé éntuk sistem wis dipontrolan, gunakake gambar aturan nyeraning nggo Google Gambar. Daerah koding theori sing isih perbudhakan kelangan kelangan seneng nggo ngerasakno bahsa ingkang dipunangka lan seneng nggo ngerasakno, lan kelangan kelangan seneng pisan kelangan langgambar. Split data fMRI sing wis ngawe barang sampeyan uwong, kita ngomongke sampeyan ngono model sing ditambah barang akeh barang sampeyan ingkang sampeyan ingkang sampeyan; kita saiki dadi model sing sampeyan ingkang sampeyan ingkang sampeyan Nanging, dakasar sing luwih akeh langgar sampek iso nggambar model sing basa teks kanggo lagi résumé. Genjer-genjer paling-ngomongke ngomongke kuwi model komputasi saiki ono luwih bantuan kanggo nggunakake tarjamahan kanggo ngerasakno', 'ha': "An samar da kewayi masu muhimu a yanzu a yi amfani da misãlai na semantiki na lissafa dõmin ka kodi motsi na aikin aikin hujeri da suka yi haɗi da zato; Kayya, wannan aikin yana da amfani kawai a kan matabbata. Yãya kyau waɗannan misãlai za'a sami zuwa yin yin ƙawa ga dukkan matsayi ya kanana. Munã tambayar wannan tambaya da za'a amfani da shiryoyin-state-of-art-ƙidãya zuwa koda shiryoyin shiryoyin masu aikin magnet Resonance Shaurin (fMR), mai amfani da shi daga mãsu shirin karatun da ke karatun kuma suna yin zato ko-wasu na'urar da ko duk concrete da kuma don ya sami abun. Babu daga misãlai da Muke amfani da shi, yana cikin linguistic, kuma yana amfani da shiryarwa na farkon word2viec skipgram wanda aka sanar da shi a Wikimedia. Dukkan an baka ta gane, ana yi amfani da zanen neura masu da aka sanar da su a kan Google Image. Tayinin kodi da sau biyu na ƙaddara zaɓen ka kodi a cikin maɓallin aikin, da linguistic da gane, kuma ya kanana zato-zaɓen da ke cikin lingui kawai. Ana rarrabe data na FMR da kwamfyutan mutane, ko kuma munã ganin misãlai biyu suna yin ƙaranci ga masu kalmar; Amma, gaskiya mai girma ta yi amfani da misãlai masu rubutun matsayi wa mafi cikakken matsayi. More generally this confirms that current computational models are sufficiently advanced to assist in investigating the representational structure of abstract concepts in the brain."}
{'en': 'Modeling Semantic Expectation : Using Script Knowledge for Referent Prediction', 'ar': 'نمذجة التوقعات الدلالية: استخدام المعرفة النصية للتنبؤ المرجعي', 'es': 'Modelado de expectativas semánticas: uso del conocimiento del script para la predicción de referencia', 'fr': 'Modélisation des attentes sémantiques\xa0: utilisation des connaissances de script pour la prédiction référente', 'pt': 'Modelando a expectativa semântica: usando o conhecimento de script para previsão de referência', 'ja': '意味的期待のモデリング：参照予測のためのスクリプト知識の使用', 'zh': '建模语义期:用脚本引占', 'hi': 'मॉडलिंग शब्दार्थ अपेक्षा: दिग्दर्शन भविष्यवाणी के लिए स्क्रिप्ट ज्ञान का उपयोग करना', 'ru': 'Моделирование семантических ожиданий: использование знаний скриптов для референтного прогнозирования', 'ga': 'Ionchas Séimeantach a Shamhaltú: Eolas Scripte a Úsáid le hAghaidh Tuar na dTagairtí', 'el': 'Μοντελοποίηση Σημαντικής Αναμονής: Χρησιμοποιώντας τη γνώση σεναρίων για την πρόβλεψη αναφοράς', 'ka': 'სემენტიკური განსაზღვრება მოდელირება: რეფერენტიკური განსაზღვრებისთვის სკრიპტის მეცნიერების გამოყენება', 'kk': 'Semantic кездесу үлгісі: Скрипттің білімін бақылау үшін қолданылады', 'hu': 'Szemantikus elvárás modellezése: Script ismeretek használata referencia-előrejelzéshez', 'it': "Modellazione dell'aspettativa semantica: utilizzo della conoscenza dello script per la previsione dei riferimenti", 'mk': 'Моделирање семантична очекување: Користење на знаење за скриптот за референтна предвидба', 'ms': 'Memodel Penjangkaan Semantik: Menggunakan Pengetahuan Skrip untuk Prediksi Berrujukan', 'ml': 'മോഡോളിങ് സെമാന്റിക് പ്രതീക്ഷ: പരിഗണനപ്പെടുത്തുന്ന വിവരങ്ങള്\u200d', 'lt': 'Semantinės lūkesčių modeliavimas: scenarijaus žinių naudojimas referenciniam prognozavimui', 'mt': 'L-Immudellar tal-Espetta Semantika: L-Użu tal-Għarfien tal-Script għal Tbassir Referenti', 'pl': 'Modelowanie oczekiwań semantycznych: wykorzystanie wiedzy o skryptach do predykcji referencyjnej', 'mn': 'Semantic Expectation Modeling: Script Knowledge for Referent Prediction', 'sr': 'Modeliranje semantičkih očekivanja: Koristenje znanja skripta za predviđanje', 'ro': 'Modelarea așteptărilor semantice: utilizarea cunoștințelor Script pentru predicția referințelor', 'no': 'Modellering av semantiske forventing: Bruk skriptkjenning for refererande forventing', 'si': 'සෙමැන්ටික් බලාපොරොත්තුව මඩේල් කරනවා: ස්ක්\u200dරිප්ට් දන්නවය ප්\u200dරයෝජනය කරන්න', 'sv': 'Modellering av semantiska förväntningar: Använda skriptkunskap för referensförutsägelse', 'ta': 'மாதிரி செமாண்டிக் எதிர்பார்ப்பு: குறிப்பிட்ட விருப்பங்களுக்கு சிறுநிரல் அறிவி', 'ur': 'سیمنٹی انتظام مڈیلٹ کرتا ہے: اسکریپٹ علم کی استعمال کرتا ہے', 'so': 'Heeganka midowga: Isticmaalka aqoonta qoraalka ee dhanka', 'uz': 'Name', 'vi': 'Chế tạo khả năng kỳ diệu: dùng khả năng ghi âm để đoán chuẩn', 'nl': 'Semantische verwachtingen modelleren: Scriptkennis gebruiken voor referent prediction', 'hr': 'Modeliranje semantičkih očekivanja: Koristenje znanja skripta za predviđanje', 'da': 'Modellering af semantiske forventninger: Brug af scriptviden til henvisningsforudsigelse', 'de': 'Semantische Erwartungen modellieren: Skriptwissen für referenzielle Vorhersagen nutzen', 'bg': 'Моделиране на семантични очаквания: Използване на знанието за скрипт за предсказване на референти', 'id': 'Modeling Semantic Expectation: Menggunakan Script Knowledge untuk Referent Prediction', 'ko': '의미 기대 모델링: 스크립트 지식을 사용하여 지칭 예측', 'tr': 'Semantik gözlenme: Referant terjime üçin skript bilgi ullanýar', 'af': 'Modelering semantiese verwagting: Gebruik van Skrip kennis vir verwysing', 'fa': 'نمادل انتظار سطح: استفاده از دانش اسکریپت برای پیش\u200cبینی تغییر', 'sq': 'Modeling Semantic Expectation: Using Script Knowledge for Referent Prediction', 'hy': 'Սեմանտիկ սպասելիք մոդելավորումը. Սգիպտային գիտելիքների օգտագործումը համեմատական կանխատեսումների համար', 'az': 'Semantik G칬zl톛m톛 Modeli: Referent Prediction 칲칞칲n Skript Bilm톛si', 'bs': 'Modeliranje semantičkih očekivanja: Koristenje znanja skripta za predviđanje', 'sw': 'Mategemeo ya Modeling Semantic: Using Script Knowledge for Reference Prediction', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'et': 'Semantilise ootuse modelleerimine: skriptiteadmete kasutamine viidete prognoosimiseks', 'bn': 'মডেলিং সেম্যান্টিক প্রত্যাশা: রেফারেন্ট পছন্দের জন্য স্ক্রিপ্টের জ্ঞান ব্যবহার করা হচ্ছে', 'fi': 'Semanttisen odotuksen mallintaminen: skriptitietojen käyttäminen viittausten ennustamiseen', 'ca': "Modelar l'esperança Semàtica: Utilitzar coneixements d'escriptura per a prediccions referencials", 'cs': 'Modelování sémantických očekávání: Použití znalostí skriptu pro referenční predikci', 'jv': 'Layout', 'ha': 'KCharselect unicode block name', 'he': 'מודל ציפיות סמנטיות: השתמש במידע של התסריט לציון רפורנטי', 'sk': 'Modeliranje semantičnega pričakovanja: uporaba znanja skripta za napoved referenc', 'bo': 'Modeling Semantic Expectation: Using Script Knowledge for Referent Prediction'}
{'en': 'Recent research in psycholinguistics has provided increasing evidence that humans predict upcoming content. Prediction also affects perception and might be a key to robustness in human language processing. In this paper, we investigate the factors that affect human prediction by building a computational model that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts. We find that script knowledge significantly improves model estimates of human predictions. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.', 'ar': 'قدمت الأبحاث الحديثة في علم اللغة النفسي أدلة متزايدة على أن البشر يتوقعون المحتوى القادم. يؤثر التنبؤ أيضًا على الإدراك وقد يكون مفتاحًا للقوة في معالجة اللغة البشرية. في هذه الورقة ، نحقق في العوامل التي تؤثر على التنبؤ البشري من خلال بناء نموذج حسابي يمكنه التنبؤ بمراجع الخطاب القادمة بناءً على المعرفة اللغوية وحدها مقابل المعرفة اللغوية جنبًا إلى جنب مع معرفة الفطرة السليمة في شكل نصوص. نجد أن معرفة البرنامج النصي تحسن بشكل كبير من تقديرات النماذج للتنبؤات البشرية. في دراسة ثانية ، قمنا باختبار الفرضية المثيرة للجدل إلى حد كبير بأن القدرة على التنبؤ تؤثر على نوع التعبير المشار إليه ولكننا لم نجد دليلاً على مثل هذا التأثير.', 'pt': 'Pesquisas recentes em psicolinguística forneceram evidências crescentes de que os humanos preveem o conteúdo futuro. A previsão também afeta a percepção e pode ser a chave para a robustez no processamento da linguagem humana. Neste artigo, investigamos os fatores que afetam a previsão humana através da construção de um modelo computacional que pode prever futuros referentes do discurso com base apenas no conhecimento linguístico versus conhecimento linguístico em conjunto com o conhecimento de senso comum na forma de scripts. Descobrimos que o conhecimento do script melhora significativamente as estimativas do modelo de previsões humanas. Em um segundo estudo, testamos a hipótese altamente controversa de que a previsibilidade influencia o tipo de expressão de referência, mas não encontramos evidências para tal efeito.', 'es': 'Investigaciones recientes en psicolingüística han proporcionado cada vez más pruebas de que los humanos predicen el contenido próximo. La predicción también afecta a la percepción y podría ser clave para la solidez en el procesamiento del lenguaje humano. En este artículo, investigamos los factores que afectan la predicción humana mediante la construcción de un modelo computacional que puede predecir los referentes del discurso venideros basados solo en el conocimiento lingüístico frente al conocimiento lingüístico junto con el conocimiento de sentido común en forma de guiones. Descubrimos que el conocimiento del script mejora significativamente las estimaciones de los modelos de predicciones humanas. En un segundo estudio, probamos la hipótesis altamente controvertida de que la previsibilidad influye en el tipo de expresión de referencia, pero no encontramos evidencia de tal efecto.', 'fr': "Des recherches récentes en psycholinguistique ont fourni de plus en plus de preuves que les humains prédisent le contenu à venir. La prédiction affecte également la perception et peut être la clé de la robustesse du traitement du langage humain. Dans cet article, nous étudions les facteurs qui influent sur la prédiction humaine en construisant un modèle informatique capable de prédire les référents de discours à venir en se basant uniquement sur les connaissances linguistiques par rapport aux connaissances linguistiques conjointement avec des connaissances de bon sens sous forme de scripts. Nous constatons que la connaissance des scripts améliore considérablement les estimations des modèles de prédictions humaines. Dans une deuxième étude, nous testons l'hypothèse très controversée selon laquelle la prévisibilité influence le type d'expression de référence, mais nous n'avons trouvé aucune preuve d'un tel effet.", 'ja': '最近の心理言語学の研究は、人間が今後のコンテンツを予測することを示すますます多くの証拠を提供している。予測は知覚にも影響を及ぼし、人間の言語処理における堅牢性の鍵となり得る。本稿では、言語知識だけではなく、共通感覚知識とスクリプトを組み合わせた言語知識に基づいて、今後の言説の参照先を予測できる計算モデルを構築することで、人間の予測に影響を与える要因を調査する。スクリプトの知識は、人間の予測のモデルの推定値を大幅に改善することがわかります。第２の研究では、予測可能性が発現タイプを参照することに影響を与えるが、そのような効果の証拠を発見しないという非常に論争の多い仮説を検証する。', 'zh': '近者心语言学益多证明,人占将出。 占亦感之,而言语处稳健性之机也。 是故构一算以究人占,盖言语脚本识,以占将来之语。 我见,脚本知显改了人占的模样。 第二项考之,试极具争之设,则预测性动引类,未有验也。', 'hi': 'Psycholinguistics में हाल के शोध ने बढ़ते सबूत प्रदान किए हैं कि मनुष्य आगामी सामग्री की भविष्यवाणी करते हैं। भविष्यवाणी धारणा को भी प्रभावित करती है और मानव भाषा प्रसंस्करण में मजबूती की कुंजी हो सकती है। इस पेपर में, हम उन कारकों की जांच करते हैं जो एक कम्प्यूटेशनल मॉडल का निर्माण करके मानव भविष्यवाणी को प्रभावित करते हैं जो स्क्रिप्ट के रूप में सामान्य ज्ञान ज्ञान के साथ संयुक्त रूप से भाषाई ज्ञान बनाम भाषाई ज्ञान के आधार पर आगामी प्रवचन दिग्दर्शनों की भविष्यवाणी कर सकते हैं। हम पाते हैं कि स्क्रिप्ट ज्ञान मानव भविष्यवाणियों के मॉडल अनुमानों में काफी सुधार करता है। एक दूसरे अध्ययन में, हम अत्यधिक विवादास्पद परिकल्पना का परीक्षण करते हैं कि भविष्यवाणी अभिव्यक्ति के प्रकार को प्रभावित करती है लेकिन इस तरह के प्रभाव के लिए सबूत नहीं मिलती है।', 'ru': 'Недавние исследования в области психолингвистики предоставили все больше доказательств того, что люди предсказывают предстоящий контент. Прогнозирование также влияет на восприятие и может быть ключом к устойчивости в обработке человеческого языка. В этой статье мы исследуем факторы, которые влияют на предсказание человека, путем построения вычислительной модели, которая может предсказать предстоящие ссылки на дискурс на основе только лингвистических знаний в сравнении с лингвистическими знаниями совместно со здравомыслящими знаниями в форме сценариев. Мы обнаружили, что знание скриптов значительно улучшает модельные оценки прогнозов человека. Во втором исследовании мы проверяем весьма спорную гипотезу о том, что предсказуемость влияет на тип выражения, но не находит доказательств для такого эффекта.', 'ga': 'Tá fianaise mhéadaitheach curtha ar fáil ag taighde a rinneadh le déanaí sa tsíctheangeolaíocht go bhfuil daoine ag tuar ábhar atá le teacht. Bíonn tionchar ag tuar freisin ar aireachtáil agus d’fhéadfadh sé a bheith ina eochair do stóinseacht i bpróiseáil teanga an duine. Sa pháipéar seo, déanaimid imscrúdú ar na fachtóirí a théann i bhfeidhm ar thuar daonna trí mhúnla ríomhaireachtúil a thógáil a fhéadfaidh tagairtí dioscúrsa atá le teacht a thuar bunaithe ar eolas teangeolaíoch amháin vs eolas teangeolaíoch i gcomhpháirt le heolas ciallmhar i bhfoirm scripteanna. Feictear dúinn go bhfeabhsaítear go mór le heolas scripte ar mheastacháin na samhla ar thuar daonna. I dara staidéar, déanaimid tástáil ar an hipitéis an-chonspóideach go mbíonn tionchar ag an intuarthacht ar an gcineál cainte a thagraíonn ach nach bhfaighimid fianaise ar éifeacht den sórt sin.', 'el': 'Πρόσφατες έρευνες στην ψυχογλωσσολογία έχουν παράσχει αυξανόμενες αποδείξεις ότι οι άνθρωποι προβλέπουν επερχόμενο περιεχόμενο. Η πρόβλεψη επηρεάζει επίσης την αντίληψη και μπορεί να αποτελέσει κλειδί για την αξιοπιστία στην επεξεργασία της ανθρώπινης γλώσσας. Στην παρούσα εργασία, διερευνούμε τους παράγοντες που επηρεάζουν την ανθρώπινη πρόβλεψη, δημιουργώντας ένα υπολογιστικό μοντέλο που μπορεί να προβλέψει επερχόμενους αναφορείς λόγου βασισμένους μόνο στη γλωσσική γνώση έναντι της γλωσσικής γνώσης από κοινού με τη γνώση κοινής λογικής με τη μορφή σεναρίων. Διαπιστώνουμε ότι η γνώση σεναρίων βελτιώνει σημαντικά τις εκτιμήσεις μοντέλων των ανθρώπινων προβλέψεων. Σε μια δεύτερη μελέτη, εξετάζουμε την άκρως αμφιλεγόμενη υπόθεση ότι η προβλεψιμότητα επηρεάζει τον αναφερόμενο τύπο έκφρασης αλλά δεν βρίσκουμε στοιχεία για μια τέτοια επίδραση.', 'hu': 'A pszicholingvistikában végzett közelmúltbeli kutatások egyre nagyobb bizonyítékot szolgáltattak arra, hogy az emberek előrejelzik a közelgő tartalmakat. Az előrejelzés befolyásolja az észlelést is, és kulcsfontosságú lehet az emberi nyelv feldolgozásában. Ebben a tanulmányban egy olyan számítógépes modell kialakításával vizsgáljuk az emberi előrejelzést befolyásoló tényezőket, amely kizárólag a nyelvtudás és a józan ész ismeretek szkriptek formájában előre tudja jósolni a következő diskurzus referentákat. Úgy találjuk, hogy a forgatókönyv ismerete jelentősen javítja az emberi előrejelzések modellbecsléseit. Egy második tanulmányban teszteljük azt a rendkívül vitatott hipotézist, miszerint a kiszámíthatóság befolyásolja a kifejezés típusát, de nem találunk bizonyítékot erre a hatásra.', 'kk': 'Жуырдағы психолингвистикалық зерттеулері адамдардың келесі мазмұнын таңдау үшін көптеген дәлелдерді береді. Мұндай-ақ мәліметті қарастыруға әсер етеді және адамдардың тілдерді өзгерту үшін құндылығының кілті болуы мүмкін. Бұл қағазда, біз адамдардың таңдау үлгісін өзгертетін факторларды тек лингвистикалық білімге негізделген дискурстардың референцияларын құруға арналған компьютерлік үлгісін құру арқылы зерттеп тұрамыз. Біз скрипттің білімі адамдардың бағалау үлгісін өзгертеді. Екінші зерттеу үшін, біз бұл өрнектердің түріне қатынау мүмкіндігін тексереміз, бірақ бұл эффект үшін дәлелдер табылмайды.', 'ka': 'მიმდინარე ფსიკოლინგურისტიკის შესაძლებლობა უფრო მეტი წარმოდგენა, რომ ადამიანები წარმოდგენენს შემდგენება. შესაძლებელია, რომ სამყარო ენის პროცესციაში ძალიან ძალიან ძალიან ძალიან გავაკეთებს. ამ დოკუნტში, ჩვენ შევხედავთ ფექტურები, რომლებიც ადამიანის წარმოდგენების შესახებ კომპუტაციალური მოდელის შესახებ, რომლებიც შეგვიძლია წარმოდგენების რეფერენტრებები, რომლებიც მხოლოდ ენგური ჩვენ ვიფიქრობთ, რომ სკრიპტის მეცნიერება მნიშვნელოვანია ადამიანის წარმოდგენების მოდელის მოდგენება. მეორე სწავლაში, ჩვენ შევცვალობთ ძალიან კონტროპერციალური ჰიპოტეზა, რომელიც წარმოდგენელობა გამოსახულების ტიპის შესახებ, მაგრამ არ მოიძლება ასეთი ეფ', 'it': "Recenti ricerche in psicolinguistica hanno fornito sempre più prove che gli esseri umani predicono contenuti futuri. La previsione influisce anche sulla percezione e potrebbe essere una chiave per la robustezza nell'elaborazione del linguaggio umano. In questo articolo, indaghiamo i fattori che influenzano la previsione umana costruendo un modello computazionale in grado di prevedere i prossimi referenti di discorso basati esclusivamente sulla conoscenza linguistica vs. conoscenza linguistica congiuntamente alla conoscenza del buon senso sotto forma di script. Troviamo che la conoscenza dello script migliora significativamente le stime del modello delle previsioni umane. In un secondo studio, testiamo l'ipotesi altamente controversa che la prevedibilità influenza il tipo di espressione di riferimento, ma non troviamo prove di tale effetto.", 'lt': 'Neseniai atlikti psichologikos tyrimai parodė, kad žmonės prognozuoja būsimą turinį. Prognozė taip pat daro įtaką suvokimui ir gali būti esminis žmogaus kalbų apdorojimo patikimumo veiksnys. Šiame dokumente tiriame veiksnius, kurie daro įtaką žmonių prognozėms, kuriant skaičiavimo model į, kuris galėtų prognozuoti būsimus diskurso referentus, pagrįstus vien kalbinėmis žiniomis, palyginti su kalbinėmis žiniomis kartu su geros prasmės žiniomis scenarijų form a. Mes manome, kad scenarijų žinios gerokai pagerina žmogaus prognozių model į. Antrajame tyrime išbandome labai prieštaringą hipotezę, kad nuspėjamumas daro įtaką kalbant apie išraiškos tipą, tačiau nenustatome tokio poveikio įrodymų.', 'mk': 'Неодамнешното истражување во психолингвистиката обезбеди сé поголеми докази дека луѓето предвидуваат идна содржина. Предвидувањето, исто така, влијае врз перцепцијата и може да биде клуч на robustness во обработувањето на човечкиот јазик. Во овој весник ги истражуваме факторите кои влијаат на човечките предвидувања со изградба на компјутативен модел кој може да предвиде идни дискурсни референти базирани на само јазичко знаење во однос на јазичкото знаење заедно со познавањето на здравиот смисол во форма на скрипти. Најдовме дека знаењето на сценариото значително ги подобрува моделните проценки на човечките предвидувања. Во втората студија, ја тестираме висококонтроверзната хипотеза дека предвидливоста влијае врз типот на израз, но не најдовме докази за ваков ефект.', 'ms': 'Penelitian baru-baru ini dalam psikologi telah menyediakan bukti yang meningkat bahawa manusia meramalkan kandungan yang akan datang. Prediksi juga mempengaruhi perasaan dan mungkin kunci untuk kepekatan dalam proses bahasa manusia. Dalam kertas ini, kami menyelidiki faktor yang mempengaruhi ramalan manusia dengan membina model pengiraan yang boleh meramalkan referens diskors yang akan datang berdasarkan pengetahuan bahasa sahaja vs pengetahuan bahasa bersama-sama dengan pengetahuan yang masuk akal dalam bentuk skrip. We find that script knowledge significantly improves model estimates of human predictions.  Dalam kajian kedua, kami menguji hipotesis yang sangat kontroversi yang pengaruh jangkakan yang merujuk jenis ungkapan tetapi tidak mencari bukti untuk kesan seperti itu.', 'ml': 'മനുഷ്യര്\u200d വരുന്ന വിഭവങ്ങള്\u200d പ്രതീക്ഷിക്കുന്നുണ്ടെന്ന് പ്രതീക്ഷിക്കുന്നു മുന്നിലുള്ള അഭിപ്രായത്തെ പ്രഭാവിക്കുന്നു. മനുഷ്യരുടെ ഭാഷയുടെ പ്രക്രിയശ്ചിത്രത്തില്\u200d മോശപ്പെ ഈ പത്രത്തില്\u200d നമ്മള്\u200d മനുഷ്യരുടെ പ്രവചനത്തെ അന്വേഷിക്കുന്ന കാര്യങ്ങള്\u200d അന്വേഷിക്കുന്നു. സ്ക്രിപ്റ്റുകളുടെ രൂപത്തില്\u200d മാത്രം വരുന്ന സംസാരിക്കുന്ന മോഡല്\u200d നി മനുഷ്യരുടെ പ്രവചനങ്ങളുടെ മാതൃകയുടെ കണക്കുകള്\u200d മെച്ചപ്പെടുത്തുന്നത് നമുക്ക് കണ്ടെത്താം. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.', 'mt': 'Riċerka reċenti fil-psikoloġija pprovdiet evidenza dejjem akbar li l-bnedmin jipprevedu l-kontenut li jmiss. Il-previżjoni taffettwa wkoll il-perċezzjoni u tista’ tkun ċentrali għar-robustezza fl-ipproċessar tal-lingwa umana. F’dan id-dokument, ninvestigaw il-fatturi li jaffettwaw it-tbassir tal-bniedem billi nibnu mudell komputattiv li jista’ jipprevedi referenti ta’ diskors li ġejjin ibbażati fuq l-għarfien lingwistiku waħdu kontra l-għarfien lingwistiku flimkien ma’ għarfien ta’ sens komuni fil-form a ta’ skripti. Issibu li l-għarfien tal-iskripti jtejjeb b’mod sinifikanti l-istimi mudell tal-previżjonijiet tal-bniedem. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.', 'mn': 'Сүүлийн үед сэтгэл зүйн хэлний судалгаагаар хүмүүс ирээдүйн тодорхойлолтуудыг таамагладаг баталгаа нэмэгдүүлсэн. Хүмүүсийн хэл үйлдвэрлэлд хүчтэй байдлын түлхүүр нөлөөлдөг. Энэ цаасан дээр бид хүн төрөлхтний таамаглалтын нөлөөлдөг хүчин зүйлсийг судалж, компьютерийн загварыг бүтээж, хэлний мэдлэг зөвхөн хэлний мэдлэг эсрэг хэлний мэдлэг зөвхөн хэлний мэдлэг зөвхөн илүү ойлголттой мэдлэг бий болгож чада Бид хүн төрөлхтний таамаглалтын загварын тооцоололтыг маш чухал сайжруулдаг. Хоёр дахь судалгаанд бид маш эсэргүүцэлтэй таамаглалт нь илэрхийллийн төрлийг харуулах нөлөөлдөг гэхдээ ийм нөлөөлдөг баталгаа олж чадахгүй.', 'no': 'Nyleg forskning i psikoplingvistikken har levert økt beviser at mennesker foregår framkommende innhald. Førehandsvising påvirkar også oppfatting og kan vera ein nøkkel for kraftighet i menneskelige språk-handsaming. I denne papiret undersøker vi faktorene som påvirkar menneske forhåndsvising ved å bygge ein datamaskin modell som kan forhåndsvisa framkommende diskursreferanser basert på linguisk kunnskap alene mot linguisk kunnskap samtidig med vanlege kunnskap i form av skript. Vi finn at skriptkunnskapen betydelig forbedrar modelleanslag av menneske forhåndsvising. I eit andre studie tester vi den svært kontroversive hipotesen at foregåverknaden påvirkar referanse på uttrykktypen, men ikkje finn beviser for slik effekt.', 'pl': 'Ostatnie badania psycholingwistyki dostarczają coraz większych dowodów na to, że ludzie przewidują nadchodzące treści. Prognozowanie wpływa również na percepcję i może być kluczem do solidności w przetwarzaniu języka ludzkiego. W niniejszym artykule badamy czynniki wpływające na predykcję człowieka poprzez budowę modelu obliczeniowego, który może przewidywać nadchodzące referencje dyskursowe oparte na samej wiedzy językowej vs. wiedzy językowej wraz z wiedzą zdrowego rozsądku w postaci skryptów. Odkrywamy, że wiedza o skryptach znacząco poprawia szacunki modeli ludzkich przewidywań. W drugim badaniu testujemy wysoce kontrowersyjną hipotezę, że przewidywalność wpływa na odnoszący się do typu ekspresji, ale nie znajduje dowodów na taki efekt.', 'sr': 'Nedavno istraživanje psihologistike pružalo je povećanje dokaza da ljudi predviđaju predstojeći sadržaj. Predviđanje takođe utječe na percepciju i može biti ključ robustnosti u procesu ljudskih jezika. U ovom papiru istražujemo faktore koji utiču na ljudsko predviđenje izgradnjem kompjuterskog model a koji mogu predvidjeti predstojeće referente o diskusiji na temelju jezičkog znanja samo protiv jezičkog znanja zajedno s zajedničkim znanjem zajedničkog smisla u obliku skripta. Nalazimo da znanje skripta značajno poboljšava model procjene ljudskih predviđanja. U drugoj studiji, testiramo vrlo kontroverznu hipotezu da predvidljivost utječe na odnos na tipa izraza, ali ne nađemo dokaze za takav efekt.', 'si': 'මිනිස්සුන්ට ප්\u200dරශ්නයක් වෙන්න පුළුවන් සාක්ෂික විශ්වාස කරනවා කියලා. මිනිස්සු භාෂාව පරීක්ෂණාවට ප්\u200dරශ්නයක් වෙන්න පුළුවන්. මේ පත්තරේ අපි පරීක්ෂණය කරන්නේ මිනිස්සු ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා පරීක්ෂණාත්මක මොඩේලයක් නිර්මාණය කරන්න පුළුවන් කියලා භාෂාත්මක දන්නවට අපිට හොයාගන්න පුළුවන් විදිහට ලිපින්ත දන්නවම මිනිස්සුන්ගේ අනුමාණ විශ්වාස කරනවා. දෙවෙනි පරීක්ෂණයෙන්, අපි පරීක්ෂණය කරන්නේ විශාල ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා නමුත් ඒ වගේ ප්\u200dර', 'ta': 'சமீபத்தில் நோய் மொழிகளில் ஆராய்ச்சி அதிகரித்துக் கொண்டுள்ளது மனிதர்கள் வரும் உள்ளடக்கத்தை முன்வாக்கு விருப்பங்கள் மற்றும் பார்வையை பாதிக்கும் மற்றும் மனித மொழி செயல்படுத்தலில் தூண்டும் விசை இந்த காகிதத்தில், நாம் ஒரு கணக்கீட்டு மாதிரியை உருவாக்கி மனித முன்வெளிப்பாட்டை பாதிக்கும் காரணிகளை தேர்வு செய்கிறோம். வரும் பேச்சு மொழியின் அறிவு மட்டு நாம் குறுநிரல் அறிவு முக்கியமாக மேம்படுத்துகிறது என்று கண்டுபிடிக்கிறோம் மனித முன்னோட்டு கணக் இரண்டாவது ஆராய்ச்சியில், நாம் மிகவும் விவாதமான குழப்பத்தைச் சோதிக்கிறோம். முன்வாக்குதல் வகையை குறிப்பிடும் பாதி', 'ro': 'Cercetările recente în psihologistică au furnizat dovezi din ce în ce mai mari că oamenii prezic conținutul viitor. Predicția afectează, de asemenea, percepția și ar putea fi o cheie pentru robustețea în procesarea limbajului uman. În această lucrare, investigăm factorii care afectează predicția umană prin construirea unui model computațional care să poată prezice viitorii referenți de discurs bazați numai pe cunoștințele lingvistice vs. cunoștințele lingvistice împreună cu cunoștințele de bun simț sub formă de scripturi. Considerăm că cunoștințele de scenariu îmbunătățesc semnificativ estimările modelului de predicții umane. Într-un al doilea studiu, testăm ipoteza extrem de controversată că previzibilitatea influențează tipul de expresie referitoare, dar nu găsim dovezi pentru un astfel de efect.', 'so': 'Waxbarashada dhimirka ee ugu dambeeyay wuxuu keenay caddeynta sii kordhaya in dadku uu sii sheegayo waxyaabaha soo socda. Heeganka waxaa sidoo kale saameyn ku leh aragtida, waxaana laga yaabaa inuu noqdo furaha ku baaraandegista luqada dadka. Qoraalkan waxaynu baaraynaa waxyaabaha saameyn ku yeelanaya wax u sheegidda dadka ku saabsan dhisidda model xisaabta ah, kaasoo ka hor sheegi kara warqadda soo socda oo ku saleysan aqoonta luuqadda oo kaliya iyo aqoonta luuqadda, si wada jir ah aqoonta aqoonta guud ee iskuulka ah. Waxaynu helnaa in aqoonta qoraalku uu si weyn u hagaajiyo qiimeynta qaabilka dadka. Waxbarashada labaad waxaynu tijaabinaynaa fikirada muran ah oo aad u adag, taasoo saameyn ku yeelan kara nooca hadalka, laakiin laguma helin caddeyn saameyn ku saabsan waxyaabaha la soo jeedo.', 'sv': 'Ny forskning inom psykolingvistik har gett allt större bevis på att människor förutspår kommande innehåll. Förutsägelse påverkar också perception och kan vara en nyckel till robusthet i människospråksbehandling. I denna uppsats undersöker vi de faktorer som påverkar människans förutsägelse genom att bygga en beräkningsmodell som kan förutsäga kommande diskursreferenter baserat enbart på språklig kunskap jämfört med språklig kunskap tillsammans med sunt förnuft kunskap i form av skript. Vi finner att manuskunskap avsevärt förbättrar modellskattningar av mänskliga förutsägelser. I en andra studie testar vi den mycket kontroversiella hypotesen att förutsägbarhet påverkar refererande uttryck typ men inte hittar bevis för en sådan effekt.', 'ur': 'روانی زبان شناسی میں اچھا تحقیق اضافہ ہوا ہے کہ انسانوں نے آگے آنے والی منصوبات کی پیش بینی کی ہے۔ پیش بینی بھی مشورت پر اثر دیتی ہے اور ممکن ہے انسان کی زبان پردازی میں دچاری کا کلید ہو سکتا ہے۔ اس کاغذ میں، ہم اسے تحقیق کرتے ہیں جو انسان کی پیش بینی کے ذریعہ ایک کمپیوٹریشن موڈل بناتے ہیں، جو صرف زبان علم پر بنیاد آتے ہیں اور صرف زبان علم کے معاملہ میں مشترک سمجھ علم کے ساتھ ایک ساتھ ہے. ہمیں یہ معلوم ہے کہ اسکریپٹ علم انسان کی پیش بینی کی موڈل کی آسانی اضافہ کرتا ہے۔ دوسری مطالعہ میں، ہم نے بہت بڑی اختلاف کرنے والی فرضی کی آزمائش کی ہے کہ پیش بینی کا اثر اثر کرتا ہے، لیکن ایسی اثر کے لئے شہادت نہیں پاتے۔', 'uz': "Yaqinda o'qituvchi psykologiklarga o'rganishni odamlar keladigan mavzuni oldin deb hisoblash mumkin. Diqqat qo'shish qo'yish va oddiy tilni boshqarish uchun tugma bo'lishi mumkin. Bu qogʻozda, biz odamning oldini tasavvur qilamiz, bu kompyuterning modelini yaratish orqali o'zgarishni boshqacha o'rganish mumkin, bu tilni faqat o'rganishni o'rganishga o'rganish mumkin va skriptlar shaklida bir bog'liq o'rganishda o'zgartirish mumkin. Biz o'ylaymiz, skript aniqligini inson prediktlarining modellarini o'zgartiradi. Ikkinchi o'qituvda, biz cheksiz murakkablik hypotheyasini sinab ko'rayapmiz, va hisoblash turini hisoblash mumkin, lekin bunday tasavvur topilmadi.", 'vi': 'Nghiên cứu tâm học gần đây đã cho thấy nhiều bằng chứng rằng con người dự đoán nội dung sắp tới. Sự dự đoán cũng ảnh hưởng đến nhận thức và có thể là chìa khóa cho sự bền vững trong việc xử lý ngôn ngữ. Trong tờ giấy này, chúng ta điều tra các yếu tố ảnh hưởng đến dự đoán của con người bằng cách xây dựng một mô hình tính toán có thể dự đoán các giai điệu sắp tới dựa trên kiến thức ngôn từ một mình so với kiến thức ngôn ngữ cùng với kiến thức tỉnh thông thường dưới dạng kịch bản. Chúng tôi thấy kiến thức kịch bản cải thiện đáng kể dự đoán của con người. Trong một nghiên cứu thứ hai, chúng tôi kiểm tra giả thuyết có nhiều tranh cãi về khả năng dự đoán tác động về dạng biểu thức nhưng không tìm thấy bằng chứng về hiệu ứng này.', 'hr': 'Nedavno istraživanje psihologistike pružalo je povećanje dokaza da ljudi predviđaju predstojeći sadržaj. Predviđanje također utječe na percepciju i može biti ključ robustnosti u procesu ljudskih jezika. U ovom papiru istražujemo faktore koji utječu na ljudsko predviđanje izgradnjem računalnog model a koji mogu predvidjeti predstojeće referente govora temeljene na jezičkim znanjima samo protiv jezičkog znanja zajedno s zajedničkim znanjem zajedničkog smisla u obliku skripta. Nalazimo da znanje skripta značajno poboljšava model procjene ljudskih predviđanja. U drugom ispitivanju, testiramo vrlo kontroverznu hipotezu da predvidljivost utječe na tipa izraza, ali ne pronalazimo dokaze za takav učinak.', 'nl': 'Recent onderzoek in de psycholinguïstiek heeft steeds meer bewijs geleverd dat mensen aankomende inhoud voorspellen. Voorspelling beïnvloedt ook perceptie en kan een sleutel zijn tot robuustheid in menselijke taalverwerking. In dit artikel onderzoeken we de factoren die menselijke voorspelling beïnvloeden door het bouwen van een computermodel dat opkomende discoursreferenten kan voorspellen op basis van linguïstische kennis alleen versus linguïstische kennis samen met gezond verstand kennis in de vorm van scripts. We vinden dat scriptkennis de modelschattingen van menselijke voorspellingen aanzienlijk verbetert. In een tweede studie testen we de zeer controversiële hypothese dat voorspelbaarheid invloed heeft op het verwijzende expressietype, maar geen bewijs voor een dergelijk effect vinden.', 'da': 'Nylig forskning i psykolingvistik har givet stigende beviser for, at mennesker forudsiger kommende indhold. Forudsigelse påvirker også opfattelsen og kan være en nøgle til robusthed i menneskelig sprogbehandling. I denne artikel undersøger vi de faktorer, der påvirker menneskelig forudsigelse ved at opbygge en beregningsmodel, der kan forudsige kommende diskursreferenter baseret på sproglig viden alene vs. sproglig viden sammen med sund fornuft viden i form af scripts. Vi finder ud af, at script viden betydeligt forbedrer model estimater af menneskelige forudsigelser. I en anden undersøgelse afprøver vi den meget kontroversielle hypotese, at forudsigelighed påvirker henvisende udtrykstype, men finder ikke beviser for en sådan effekt.', 'bg': 'Последните изследвания в психолингвистиката предоставят все повече доказателства, че хората предвиждат предстоящо съдържание. Прогнозирането също влияе на възприятието и може да бъде ключ към здравината в обработката на човешкия език. В тази статия изследваме факторите, които влияят върху човешкото предсказване чрез изграждане на изчислителен модел, който може да предскаже предстоящите дискурсни референти въз основа на езиково знание срещу езиково знание съвместно с познание за здрав разум под формата на скриптове. Установяваме, че знанието по скрипта значително подобрява моделните оценки на човешките прогнози. Във второ проучване тестваме силно спорната хипотеза, че предвидимостта влияе върху типа на референтния израз, но не намираме доказателства за такъв ефект.', 'id': 'Penelitian baru-baru ini dalam psikologi telah memberikan bukti yang meningkat bahwa manusia memprediksi isi yang akan datang. Prediksi juga mempengaruhi persepsi dan mungkin kunci untuk kepekatan dalam proses bahasa manusia. Dalam kertas ini, kami menyelidiki faktor yang mempengaruhi prediksi manusia dengan membangun model komputasi yang dapat memprediksi referen diskors yang akan datang berdasarkan pengetahuan bahasa sendirian vs pengetahuan bahasa bersama dengan pengetahuan yang masuk akal dalam bentuk skrip. Kami menemukan bahwa pengetahuan skrip meningkatkan penilaian model prediksi manusia. Dalam penelitian kedua, kami menguji hipotesis yang sangat kontroversial bahwa prediksibilitas mempengaruhi referensi tipe ekspresi tetapi tidak menemukan bukti untuk efek seperti itu.', 'fa': 'تحقیقات اخیرا در روانشناسی روانشناسی مدرک افزایش داده است که انسان محتوای پیش بینی می\u200cکند. پیش\u200cبینی همچنین تأثیر احساس می\u200cکند و ممکن است کلیدی برای دقت در پرداخت زبان انسان باشد. در این کاغذ، ما فرجام\u200cهایی را تحقیق می\u200cکنیم که با ساختن یک مدل کامپیوتری تأثیر می\u200cدهند که می\u200cتوانند ارتباط\u200cهای سخنرانی آینده بر اساس دانش زبان\u200cشناسی تنها بر اساس دانش زبان\u200cشناسی با دانش\u200cهای معنی\u200cشناسی معنی\u200cشناسی در شکل نوشته\u200cها پیش ما پیدا می\u200cکنیم که دانش نوشته\u200cها به طور معنی تخمین\u200cهای مدل پیش\u200cبینی\u200cهای انسان را بهتر می\u200cکند. در یک مطالعه دوم، ما فرضیه خیلی اختلاف کننده را آزمایش می کنیم که پیش بینی قابل تأثیر قابل توجه به نوع تعریف است ولی مدرک برای این تأثیر پیدا نمی کنیم.', 'de': 'Jüngste Forschungen in der Psycholinguistik haben immer mehr Beweise dafür geliefert, dass Menschen bevorstehende Inhalte vorhersagen. Vorhersagen beeinflussen auch die Wahrnehmung und könnten ein Schlüssel zu Robustheit in der Verarbeitung menschlicher Sprache sein. In diesem Beitrag untersuchen wir die Faktoren, die die menschliche Vorhersage beeinflussen, indem wir ein computergestütztes Modell aufbauen, das zukünftige Diskursreferenten basierend auf linguistischem Wissen allein vs. linguistischem Wissen zusammen mit gesundem Menschenverstand in Form von Skripten vorhersagen kann. Wir finden, dass Skriptwissen die Modellschätzungen menschlicher Vorhersagen signifikant verbessert. In einer zweiten Studie testen wir die stark umstrittene Hypothese, dass Vorhersagbarkeit den verweisenden Expressionstyp beeinflusst, aber keine Beweise für einen solchen Effekt findet.', 'ko': '최근의 심리언어학 연구는 인류가 다가올 내용을 예측할 수 있다는 증거를 점점 더 많이 제공했다.예측은 감지에도 영향을 미치는 것으로 인류 언어 처리의 루팡성의 관건이 될 수 있다.본고에서 우리는 하나의 계산 모델을 구축하여 인류 예측에 영향을 주는 요소를 연구한다. 이 모델은 언어 지식으로 다가오는 문장을 예측하는 것이지 언어 지식과 각본 형식의 상식 지식을 바탕으로 하는 것이 아니다.우리는 각본 지식이 인류 예측의 모델 평가를 현저하게 개선시켰다는 것을 발견했다.두 번째 연구에서 우리는 논란이 되는 가설을 검증했는데 예측성이 지칭 표현 유형에 영향을 미칠 수 있으나 이런 영향을 미칠 증거를 발견하지 못했다.', 'sw': 'Utafiti wa hivi karibuni katika lugha za kisaikolojia umetoa ushahidi wa kuongezeka kuwa binadamu wanatabiri maudhui yanayotokea. Prediction also affects perception and might be a key to robustness in human language processing.  Katika karatasi hii, tunachunguza sababu zinazoathiri utabiri wa binadamu kwa kutengeneza muundo wa kompyuta ambao unaweza kutabiri maoni ya mazungumzo yanayokuja kwa kutumia maarifa ya lugha pekee na maarifa ya lugha kwa pamoja na maarifa yanayofanana kwa ujuzi wa umma katika namna ya maandiko. Tunaona kwamba maarifa ya script inaboresha kiasi kikubwa zaidi kadri ya utabiri wa binadamu. Katika utafiti wa pili, tunajaribu nadharia kubwa ya utata kwamba utabiri unaathiri aina ya kujieleza lakini hatupati ushahidi wa athari hiyo.', 'tr': 'Ýakynda psikoplingwistikiýanyň barlagynyň adamlaryň gelejekde meýdany çaklaýandygyny artdyrmak üçin öngörüp barýardy. Wasp Bu kagyzda biz adamlaryň önümlerine täsirleýän faktörleri, hesap modelini gurarak, edil indiki lingwistiki bilgi we dil bilgi scriptlaryň şeklinde edilen gürrüňleri täsirleýän gürrüňleri tahmin edip bilýäris. Biz skript bilgi adamlaryň önümleriniň nusgasyny örän köpräk gowurar diýip pikir edýäris. Ikinji öwrenmede, biz ýokary çykyşykly hipotesi diýip barýarys. tahmin edip bilmek üçin bir ifade täsirine täsirleýär ýöne hiç hili bir täsiri tapmaýarys.', 'af': "Onlangse reseksie in psyklinguistika het verhoog getuienisse voorgegee dat mense voorskou opkomstige inhoud. Voorwoording het ook onderwerp en dalk 'n sleutel vir kragtigheid in menslike taal verwerking. In hierdie papier, ons ondersoek die faktore wat die menslike voorskou beïnvloor deur 'n rekenaasjonale model te bou wat kan voorskou opkommende diskurse verwysing gebaseer op lingwisiese kennis alleen teen lingwisiese kennis saam met gemeenskaplike-sens kennis in die vorm van skripte. Ons vind dat skrip kennis betekeurig verbeter modelles van menslike voorskou. In 'n tweede studie probeer ons die baie kontroversiewe hipotees wat voorskoubaarheid influens die verwysing van uitdrukking tipe, maar nie vind getuienis vir so 'n effek nie.", 'am': 'ባለፈው የpsycholinguistic ትምህርት ሰዎች የሚደርስበትን ነገር የሚያሳውቅ ማስረጃዎችን አቀረበ፡፡ መግለጫ ደግሞ አየር እና የሰው ቋንቋ ማቀናቀል መክፈቻ ሊሆን ይችላል፡፡ በዚህ ካላት፣ የሰው ውይይት በመፍጠር ላይ የሚነካውን ነገር በቋንቋዊ እውቀት ብቻውን በተቃወመ ቋንቋዊ እውቀት እና በቋንቋዊው እውቀት በተለይ የቋንቋዊ እውቀት ላይ የተመሳሰለውን እናሳይቃቸዋለን፡፡ የጽሕፈት እውቀት የሰው ትንቢት መፍጠርን በኩል ያሳድጋል፡፡ በሁለተኛውም ትምህርት፣ የመፍጠር መልዕክት የሚጠቅመውን ነገር ግን ለዚህ የሚደረገውን ማስረጃ አያገኙም፡፡', 'hy': 'Հոգեբանության վերջին հետազոտությունները պարունակում են աճող ապացույցներ, որ մարդիկ կանխատեսում են ապագա պարունակությունը: Նախատեսումը նույնպես ազդում է ընկալության վրա և կարող է լինել մարդկային լեզուների վերամշակման ուժեղության կարևոր բանը: Այս թղթի մեջ մենք ուսումնասիրում ենք այն գործոնները, որոնք ազդում են մարդկային կանխատեսումներին՝ կառուցելով հաշվարկչական մոդել, որը կարող է կանխատեսել գալիք քննարկումների վերաբերյալները, հիմնված միայն լեզվական գիտելիքների վրա, համեմատած լեզվական գիտելիքների վրա, միասին գրքեր Մենք հայտնաբերում ենք, որ գիտելիքները գրաֆիկներին նշանակալիորեն բարելավում են մարդկային կանխատեսումների մոդելները: Երկրորդ ուսումնասիրության ընթացքում մենք փորձում ենք բարձր հակառակշռող հիպոթեզը, որ կանխատեսելիությունը ազդում է արտահայտության տեսակի նկատմամբ, բայց այդպիսի ազդեցության ապացույցներ չեն գտնում:', 'sq': 'Kërkimi i fundit në psikologjikë ka dhënë prova në rritje që njerëzit parashikojnë përmbajtjen e ardhshme. Prediction also affects perception and might be a key to robustness in human language processing.  Në këtë letër, ne hetojmë faktorët që ndikojnë në parashikimin njerëzor duke ndërtuar një model llogaritës që mund të parashikojë referentët e ardhshëm të diskursit bazuar vetëm në njohurinë gjuhësore vs. njohurinë gjuhësore së bashku me njohurinë e sensit të përbashkët në form ën e skripteve. Ne gjejmë se njohuria e script përmirëson ndjeshëm modelet e parashikimeve njerëzore. In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.', 'bs': 'Nedavno istraživanje psihologistike pružalo je povećanje dokaza da ljudi predviđaju predstojeći sadržaj. Predviđanje također utječe na percepciju i može biti ključ robustnosti u procesu ljudskih jezika. U ovom papiru istražujemo faktore koji utiču na ljudsko predviđenje izgradnjem računalnog model a koji mogu predvidjeti predstojeće referente o diskusiji temeljene na jezičkom znanju samo protiv jezičkog znanja zajedno s zajedničkim znanjem zajedničkog smisla u obliku skripta. Nalazimo da znanje skripta značajno poboljšava model procjene ljudskih predviđanja. U drugom ispitivanju, testiramo vrlo kontroverznu hipotezu da predvidljivost utječe na pogledanje tipa izraza, ali ne nađemo dokaze za takav učinak.', 'bn': 'মানসিক ভাষায় সম্প্রতি গবেষণা বৃদ্ধি প্রমাণ প্রদান করেছে যে মানুষ ভবিষ্যদ্বাণী করে আসছে বিষয়বস্তু। মনোভাবের উপর প্রভাব ফেলে এবং মানুষের ভাষা প্রক্রিয়ার চাবি হতে পারে। এই কাগজটিতে আমরা মানুষের ভবিষ্যদ্বাণী প্রভাবিত করে একটি গণনাত্রিক মডেল নির্মাণের মাধ্যমে তদন্ত করি যা ভাষাগত জ্ঞানের ভিত্তিক পরিজ্ঞানের উপর ভিত্তিক ভাষায় ভাষ আমরা দেখতে পাচ্ছি যে স্ক্রিপ্টের জ্ঞান মানুষের ভবিষ্যতের মডেল হিসেবে গুরুত্বপূর্ণ উন্নয়ন করে। In a second study, we test the highly controversial hypothesis that predictability influences referring expression type but do not find evidence for such an effect.', 'ca': "La recent recerca en psicologüística ha proporcionat una evidència creixent que els humans predien el contingut futur. La predicció també afecta la percepció i pot ser una clau per a la robustetat en el processament del llenguatge humà. En aquest paper, investigam els factors que afecten la predicció human a construint un model computacional que pot predir els futurs referents de discurs basats en el coneixement lingüístic sols en comparació amb el coneixement lingüístic juntament amb el coneixement de sentit comú en forma d'escriptures. Trobem que el coneixement d'escriptura millora significativament les estimacions models de les prediccions humanes. En un segon estudi, examinem la hipòtesi altament controvertida que la prevedibilitat influeix en referir-se al tipus d'expressió però no trobem proves d'aquest efecte.", 'cs': 'Nedávný výzkum psycholingvistiky poskytl stále více důkazů, že lidé předpovídají nadcházející obsah. Predikce také ovlivňuje vnímání a může být klíčem k robustnímu zpracování lidského jazyka. V tomto článku zkoumáme faktory ovlivňující lidskou predikci vytvořením výpočetního modelu, který dokáže předpovídat nadcházející referenty diskurzu založené na jazykových znalostech versus jazykových znalostech společně se znalostmi zdravého rozumu ve formě skriptů. Zjišťujeme, že znalosti skriptů výrazně zlepšují modelové odhady lidských predikcí. Ve druhé studii testujeme vysoce kontroverzní hypotézu, že předvídatelnost ovlivňuje odkazující typ výrazu, ale nenalezneme důkazy o takovém efektu.', 'et': 'Hiljutised psühholingvistika uuringud on andnud üha rohkem tõendeid, et inimesed ennustavad tulevast sisu. Ennustamine mõjutab ka tajumist ja võib olla inimkeele töötlemise stabiilsuse võti. Käesolevas töös uurime inimese prognoosi mõjutavaid tegureid, ehitades arvutusmudeli, mis suudab ennustada tulevasi diskursuseviiteid ainult keeleteadmiste alusel võrreldes keeleteadmistega koos terve mõistuse teadmistega skriptide kujul. Leiame, et skriptiteadmised parandavad oluliselt inimprognooside mudeli hinnanguid. Teises uuringus testime väga vastuolulist hüpoteesi, et prognoositavus mõjutab viitavat väljendustüüpi, kuid ei leia tõendeid sellise mõju kohta.', 'fi': 'Viimeaikaiset psykolingvistiikan tutkimukset ovat antaneet yhä enemmän näyttöä siitä, että ihmiset ennustavat tulevaa sisältöä. Ennuste vaikuttaa myös havaintoon ja voi olla avain ihmisen kielen käsittelyn kestävyyteen. Tässä artikkelissa tutkimme ihmisen ennustukseen vaikuttavia tekijöitä rakentamalla laskennallisen mallin, joka pystyy ennustamaan tulevia diskurssiviittauksia pelkästään kielelliseen tietoon verrattuna kielelliseen tietoon yhdessä tervejärkisen tiedon kanssa skriptien muodossa. Havaitsemme, että käsikirjoituksen tuntemus parantaa merkittävästi ihmisten ennusteiden malliestimaatteja. Toisessa tutkimuksessa testaamme erittäin kiistanalaista hypoteesia, jonka mukaan ennustettavuus vaikuttaa viittaavan ilmaisun tyyppiin, mutta emme löydä todisteita tällaisesta vaikutuksesta.', 'az': 'İnsanların gələcək məlumatlarını təsbiq etdiklərinə dair daha çox dəlillər göstərdi. Tövsiyə həmçin in gözləməyi təsir edir və insan dillərin işləməsində qüvvətli olmasının anahtarı olar. Bu kağızda, insanların öngörünü təsir edən faktorları, bilgisayar modeli in şa edərək, təkcə dillərin elmi və dillərin elmi ilə birlikdə müxtəlif məlumatların formu ilə birlikdə gələcək diskusiya referentlarını təmin edə bilər. Biz skriptlər elmi insan tədbirlərinin modeli təsəvvürlərini çox yaxşılaşdırır. İkinci təhsil içində, biz çox mübahisəçi hipotezi sınağa çəkirik ki, tədbirlik ifadə növünü təsirləndirir, amma böyük bir etkisi üçün kanıt tapmırıq.', 'jv': 'R. Tulung luwih apik buwis ngerasakno karo hal akeh dumadhi kanggo nguasai perusahaan anyar. Nang paper iki, kéné ujaran karo nggawe barang nggawe nguasai perbudhakan anyar tentang karo modèl sak batasang ingkang dianggap bantuan nguasai perusahaan langgar sapa-sapa uwis karo alé surat ingkang sami lan alam kuwi nggawe nguasai perusahaan anyar sami nggawe nguasai perusahaan seneng sak ujaran dumadh Awak dhéwé ngerti barang nggawe barang nggawe barang nggawe tarjamahan anyar. Nang alih sekondi, kéné ujaran ngerasakno suputeksi sing akeh nesaturan anyar tentang', 'sk': 'Nedavne raziskave psiholingvistike so zagotovile vedno več dokazov, da ljudje napovedujejo prihajajoče vsebine. Napovedovanje vpliva tudi na percepcijo in je lahko ključ do robustnosti obdelave človeškega jezika. V prispevku raziskujemo dejavnike, ki vplivajo na človeško napovedovanje, z gradnjo računalniškega modela, ki lahko napoveduje prihajajoče diskurzne reference samo na podlagi jezikovnega znanja v primerjavi z jezikovnim znanjem skupaj z zdravim razumom v obliki skriptov. Ugotavljamo, da znanje scenarija bistveno izboljšuje ocene modelov človeških napovedi. V drugi študiji smo preizkusili zelo kontroverzno hipotezo, da predvidljivost vpliva na referenčni tip izraza, vendar ne najdemo dokazov za tak učinek.', 'bo': 'ད་ལྟ་མི་མང་གིས་སྒེར་གྱི་བརྡ་སྤྲོད་ཀྱི་དབྱེ་ཞིབ་དེ་ནི་མི་ཚོས་རྐྱེན་གྱི་ནང་དོན་མང་ཙམ་རྟོགས་ཏེ། གསལ་བཤད་ཀྱིས་ཤེས་ཚོར་ལྟ་བུའི་ནང་དུ་ཆེ་ཤོས་ཡིན་སྲིད། In this paper, we investigate the factors that affect human prediction by building a computational model that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts. ང་ཚོས་ཡིག་ཆ་ཤེས་ཀྱི་རྣམ་གྲངས་མི་རྣམ་གྲངས་པར་མཐོང་ཚད་ལྡན་སྐྱེལ་བཞིན་བཟོ་བྱེད་ཡོད། ལྟ་བ་གཉིས་པ་ཅིག་གི་ནང་དུ་ང་ཚོས་རྒྱ་ནག་གི་དབྱེ་སྒྲུང་བརྟན་པར་མཐོང་ཐབས་མཐོང་བ་དང་།', 'ha': "Research na nan a cikin linguistic aikin na ƙara ya ba da shaidar za'a yi kusa bayani-bayani wanda mutane ke gabatar da maɓallin ƙari. Furofarin yana yin amfani da fassarar gannai kuma yana iya zama maɓalli wa surori cikin aikin mutane. In a cikin wannan takardan, Munã jãyayya masu fassarar abin da ke yi bayani ga mutum da za'a gina wani misãlai na lissafa wanda ke iya iya bayani ga muhimmin magana masu ƙaranci, a kan karatun kunnufi masu fassarar linguistic da sanin linguistic kodi da sanin da sune-sani na ɗammani, a form of manuscripts. Tuna gane cewa manuscriptan sani mai girma yana samar da misalin misalin mutane. Kuma a cikin wani littafi na ƙara, Munã jarraba misãlin da ke yi shakka mai tsawo da abin da kan saurãre za'a yi amfani da nau'in magana, kuma bã mu sami bayani ga wannan mai amfani.", 'he': 'מחקר אחרון בפסיכולוגיסטיקה סיפק ראיות גדולות כי בני האדם חושפים התוכן הבא. ציפוי משפיע גם על התפיסה ואולי הוא מפתח לחזקה בעבודה בשפה האנושית. בעיתון הזה, אנו חוקרים את הגורמים שמשפיעים על חיזוי אנושי על ידי בניית מודל מחשבי שיכול לחזות רפורנטים לדיווח הבא מבוססים על ידע שפתי בלבד נגד ידע שפתי ביחד עם ידע שפוי תחושה בצורה של סרטים. אנו מוצאים שידע התסריט משפר באופן משמעותי הערכות מודל של צפיות אנושיות. במחקר שני, אנו בודקים את ההיפתוזיה המתורבת ביותר שהצפויה משפיעה על טיפוס הביטוי אבל לא מוצאים ראיות לשפעה כזו.'}
{'en': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features', 'ar': 'Shift-Reduce التحليل المكون مع ميزات Lookahead العصبية', 'pt': 'Análise de constituintes com redução de deslocamento com recursos de antecipação neural', 'fr': 'Shift-Reduce Constituant Parsing avec fonctions Neural Lookahead', 'es': 'Shift-Reduce el análisis de componentes con funciones de búsqueda anticipada neuronal', 'ja': 'ニューラルルックアヘッド機能を備えたShift - Reduceコンポーネント解析', 'hi': 'शिफ्ट-न्यूरल लुकहेड सुविधाओं के साथ घटक पार्सिंग को कम करें', 'ru': 'Сдвиг-Редукция Компонентного Анализа с Особенностями Neural Lookahead', 'zh': '有神经前瞻性功能者 Shift-Reduce 分解析', 'ga': 'Shift-Laghdaigh Parsáil Comhábhar le Gnéithe Amharc Néaracha', 'el': 'Μετατόπιση-Μείωση ανάλυσης συστατικού με χαρακτηριστικά νευρωνικής αναζήτησης', 'hu': 'Shift – Csökkentse az alkotóelemek értelmezését a neurális kinézőfej funkciókkal', 'it': "Shift-Riduci l'analisi costituente con le caratteristiche Neural Lookahead", 'kk': 'Нейрондық қарау қасиеттерімен конститунтті шешу', 'lt': 'Shift- Reduce Component Parsing with Neural Lookahead Features', 'mk': 'Премести- намали анализирање на конститунтите со неурални функции на главата со поглед', 'ms': 'Penghuraian Konstitusi Shift- Kurang dengan Ciri-ciri Kepala Neural', 'ml': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features', 'mt': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features', 'mn': 'Шинфт-Багасгал тогтмол хөгжүүлэлтийг мэдрэлийн харагдах боломжуудыг багасгах', 'no': 'Forskyv- reduser konstituent- tolking med funksjonar for neuralutsjånad', 'ka': 'Name', 'pl': 'Przesunięcie i zmniejszenie parowania składników dzięki funkcjom wyglądu nerwowego', 'ro': 'Schimbă-reduce analiza constitutivă cu caracteristici ale capului de aspect neural', 'sr': 'Shift- smanjiti konstitucionalno razmatranje sa neurološkim funkcijama', 'si': 'Shift- Reducation', 'so': 'Shift-Reduce Parsing with Neural Lookahead', 'sv': 'Skift – Minska konstituerande tolkning med Neural Lookahead Features', 'ta': 'புதிய தோற்றம் தலைப்புகளுடன் பாசிங் குறை', 'ur': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features', 'uz': 'Name', 'vi': 'Dịch hoá vớ vẩn với Trung tâm Nhìn trước', 'bg': 'Разработване на съставни елементи с неврални функции', 'nl': 'Shift-Reduceer Constituent Parsing met Neural Lookahead Features', 'hr': 'Shift- smanjiti konstitucionalno razmatranje s funkcijama neurološkog pogleda', 'da': 'Skift – Reducer fortolkning af bestanddele med Neural Lookahead Features', 'id': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features', 'ko': '신경 전시 기능이 있는 이위 감소 성분 분석', 'de': 'Shift-Reduce Constituent Parsing mit Neural Lookahead Features', 'fa': 'Shift- Reduce Constituent Parsing with Neural Lookahead features', 'sw': 'Shift-Reduce Constituen Parsing with Neural Lookahead', 'tr': 'Niýal gözlerniň üýtgewleri bilen constituency azaltmak', 'sq': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features', 'af': 'Verskuif- Reducer konstituent verwerking met neurale opsykvorentoe eienskappe', 'hy': 'Comment', 'am': 'ምርጫዎች', 'az': '仃뙲慬⁇쎶穬즙淉餠쎖穥汬楫泉饲椠楬즙⁋潮獴慮琠쎜獴쎼湬쎼秃뱮쎼⁋쎼쎧쎼歬즙얟摩爊', 'bn': 'নিউরাল লুকাহেড বৈশিষ্ট্যাবলীর সাথে পার্সিং শিft- কমাও', 'bs': 'Shift- smanjiti konstitucionalno razmatranje sa funkcijama neurološkog pogleda', 'ca': "Reducir-Mayúscules l'analització de constituents amb característiques neuronals", 'et': 'Shift-Reduce koostisosade parsimine neuraalse otsingu funktsioonidega', 'cs': 'Shift-Reduce analýzy složek s funkcemi neuronového vyhledávání hlavy', 'fi': 'Shift-Reduce-komponentin jäsentely hermopäätteen ominaisuuksilla', 'jv': 'Transform handle tip', 'ha': '@ action', 'sk': 'Preklapljanje sestavnih delov s premikom in zmanjšanjem funkcij živčnega pogleda', 'he': 'שינוי- קטע בדיקת חומרים עם תכונות ראש העצבי', 'bo': 'Shift-Reduce Constituent Parsing with Neural Lookahead Features'}
{'en': 'Transition-based models can be fast and accurate for constituent parsing. Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which consists of a sequence of non-local constituents. On the other hand, during incremental parsing, constituent information on the right hand side of the current word is not utilized, which is a relative weakness of shift-reduce parsing. To address this limitation, we leverage a fast neural model to extract lookahead features. In particular, we build a bidirectional LSTM model, which leverages full sentence information to predict the hierarchy of constituents that each word starts and ends. The results are then passed to a strong transition-based constituent parser as lookahead features. The resulting parser gives 1.3 % absolute improvement in WSJ and 2.3 % in CTB compared to the baseline, giving the highest reported accuracies for fully-supervised parsing.', 'ar': 'يمكن أن تكون النماذج المستندة إلى الانتقال سريعة ودقيقة لتحليل المكونات. بالمقارنة مع النماذج القائمة على الرسوم البيانية ، فإنها تستفيد من ميزات أكثر ثراءً عن طريق استخراج معلومات التاريخ من مكدس محلل ، والذي يتكون من سلسلة من المكونات غير المحلية. من ناحية أخرى ، أثناء التحليل التزايدي ، لا يتم استخدام المعلومات المكونة على الجانب الأيمن من الكلمة الحالية ، وهو ضعف نسبي في التحليل بتقليل التحول. لمعالجة هذا القيد ، نستفيد من نموذج عصبي سريع لاستخراج ميزات lookahead. على وجه الخصوص ، نقوم ببناء نموذج LSTM ثنائي الاتجاه ، والذي يستفيد من معلومات الجملة الكاملة للتنبؤ بالتسلسل الهرمي للمكونات التي تبدأ كل كلمة وتنتهي. ثم يتم تمرير النتائج إلى محلل مكونات قوي قائم على الانتقال كميزات lookahead. يعطي المحلل اللغوي الناتج تحسنًا مطلقًا بنسبة 1.3٪ في WSJ و 2.3٪ في CTB مقارنة بخط الأساس ، مما يعطي أعلى دقة تم الإبلاغ عنها للتحليل الخاضع للإشراف الكامل.', 'fr': "Les modèles basés sur la transition peuvent être rapides et précis pour l'analyse des constituants. Comparés aux modèles basés sur des graphiques, ils exploitent des fonctionnalités plus riches en extrayant des informations d'historique à partir d'une pile d'analyseurs, qui consiste en une séquence de constituants non locaux. D'autre part, lors de l'analyse incrémentielle, les informations constitutives sur le côté droit du mot courant ne sont pas utilisées, ce qui constitue une faiblesse relative de l'analyse par décalage et réduction. Pour remédier à cette limitation, nous exploitons un modèle neuronal rapide pour extraire les fonctionnalités anticipées. En particulier, nous créons un modèle LSTM bidirectionnel, qui exploite les informations de la phrase complète pour prédire la hiérarchie des constituants de début et de fin de chaque mot. Les résultats sont ensuite transmis à un analyseur de constituants basé sur une transition forte en tant que fonctionnalités anticipées. L'analyseur qui en résulte apporte une amélioration absolue de 1,3\xa0% de WSJ et de 2,3\xa0% de CTB par rapport à la référence, ce qui donne les plus hautes précisions rapportées pour une analyse entièrement supervisée.", 'pt': 'Modelos baseados em transição podem ser rápidos e precisos para análise de constituintes. Em comparação com os modelos baseados em gráficos, eles aproveitam recursos mais avançados extraindo informações de histórico de uma pilha de analisadores, que consiste em uma sequência de constituintes não locais. Por outro lado, durante a análise incremental, as informações constituintes do lado direito da palavra atual não são utilizadas, o que é uma fraqueza relativa da análise de redução de deslocamento. Para resolver essa limitação, aproveitamos um modelo neural rápido para extrair recursos de antecipação. Em particular, construímos um modelo LSTM bidirecional, que aproveita informações de sentenças completas para prever a hierarquia de constituintes que cada palavra inicia e termina. Os resultados são então passados para um analisador constituinte baseado em transição forte como recursos de antecipação. O analisador resultante fornece 1,3% de melhoria absoluta no WSJ e 2,3% no CTB em comparação com a linha de base, fornecendo as mais altas precisões relatadas para análise totalmente supervisionada.', 'es': 'Los modelos basados en transiciones pueden ser rápidos y precisos para el análisis de componentes. En comparación con los modelos basados en gráficos, aprovechan funciones más completas al extraer información del historial de una pila de analizadores, que consiste en una secuencia de componentes no locales. Por otro lado, durante el análisis incremental, no se utiliza la información constituyente en el lado derecho de la palabra actual, lo que es una debilidad relativa del análisis de reducción de desplazamiento. Para abordar esta limitación, utilizamos un modelo neuronal rápido para extraer funciones anticipadas. En particular, creamos un modelo LSTM bidireccional, que aprovecha la información de la oración completa para predecir la jerarquía de componentes que comienza y termina cada palabra. Los resultados se pasan luego a un potente analizador de componentes basado en transiciones como características anticipadas. El analizador resultante proporciona una mejora absoluta del 1.3% en WSJ y del 2.3% en CTB en comparación con la línea base, proporcionando las precisiones más altas informadas para el análisis totalmente supervisado.', 'ja': '遷移ベースのモデルは、構成要素の構文解析のために高速かつ正確にすることができます。グラフベースのモデルと比較して、これらは、非ローカル構成要素のシーケンスで構成される構文解析スタックから履歴情報を抽出することによって、より豊富な機能を活用します。一方、インクリメンタル構文解析の間、現在の単語の右側の構成要素情報は利用されず、これはシフト縮小構文解析の相対的な弱点である。この制限に対処するために、私たちは高速ニューラルモデルを活用して、ルックアヘッドの特徴を抽出します。特に、完全な文章情報を活用して、各単語が開始および終了する構成要素の階層を予測する双方向LSTMモデルを構築します。その結果は、ルックアヘッド機能として、強力な遷移ベースの構成構文解析器に渡されます。得られた構文解析器は、ベースラインと比較して、WSJで1.3 ％、CTBで2.3 ％の絶対的な改善を与え、完全に監視された構文解析のために報告された最も高い精度を提供します。', 'zh': '其转模可速成分解析。 比之图表,取信于解析器堆栈,解析器堆栈成于地。 其一,增量解析之前,单词右之分息未用,此shift-reduce解析之对弱也。 为此限者,以速神经取前瞻也。 特为一双向LSTM,全句以卜单词终始之层次结构。 然后以前瞻特徵传于转换之强成分解析器。 比之基线,成解析器于《华尔街日报》,出于1.3%之绝对改进,于CTB之于2.3%之绝对改进,为全监解析供至精之报。', 'ru': 'Модели, основанные на переходе, могут быть быстрыми и точными для компонентного анализа. По сравнению с моделями на основе диаграмм, они используют более богатые функции путем извлечения исторической информации из стека парсера, который состоит из последовательности нелокальных составляющих. С другой стороны, во время инкрементного синтаксического анализа составляющая информация в правой части текущего слова не используется, что является относительной слабостью синтаксического анализа сдвига. Чтобы решить это ограничение, мы используем быструю нейронную модель для извлечения перспективных признаков. В частности, мы строим двунаправленную модель LSTM, которая использует полную информацию о предложениях для предсказания иерархии составляющих, которые каждое слово начинает и заканчивает. Затем результаты передаются в сильный компонентный парсер на основе перехода в качестве функций на перспективу. Полученный в результате анализатор дает 1,3% абсолютное улучшение в WSJ и 2,3% в CTB по сравнению с базовым уровнем, что дает самые высокие сообщенные погрешности для полностью контролируемого анализа.', 'hi': 'संक्रमण-आधारित मॉडल घटक पार्सिंग के लिए तेज और सटीक हो सकते हैं। चार्ट-आधारित मॉडल की तुलना में, वे एक पार्सर स्टैक से इतिहास की जानकारी निकालकर समृद्ध सुविधाओं का लाभ उठाते हैं, जिसमें गैर-स्थानीय घटकों का अनुक्रम होता है। दूसरी ओर, वृद्धिशील पार्सिंग के दौरान, वर्तमान शब्द के दाईं ओर घटक जानकारी का उपयोग नहीं किया जाता है, जो शिफ्ट-कम पार्सिंग की सापेक्ष कमजोरी है। इस सीमा को संबोधित करने के लिए, हम लुकहेड सुविधाओं को निकालने के लिए एक तेज तंत्रिका मॉडल का लाभ उठाते हैं। विशेष रूप से, हम एक द्विदिश एलएसटीएम मॉडल का निर्माण करते हैं, जो घटकों के पदानुक्रम की भविष्यवाणी करने के लिए पूर्ण वाक्य जानकारी का लाभ उठाता है जो प्रत्येक शब्द शुरू होता है और समाप्त होता है। परिणाम तब लुकहेड सुविधाओं के रूप में एक मजबूत संक्रमण-आधारित घटक पार्सर को पारित किए जाते हैं। परिणामी पार्सर बेसलाइन की तुलना में डब्ल्यूएसजे में 1.3% पूर्ण सुधार और सीटीबी में 2.3% पूर्ण सुधार देता है, जिससे पूरी तरह से पर्यवेक्षित पार्सिंग के लिए उच्चतम रिपोर्ट की गई सटीकता मिलती है।', 'ga': 'Is féidir le samhlacha tras-bhunaithe a bheith tapa agus cruinn le haghaidh parsáil comhábhar. I gcomparáid le samhlacha cairt-bhunaithe, giaráil siad gnéithe níos saibhre trí fhaisnéis staire a bhaint as stoic parsálaí, arb é atá ann seicheamh comhábhair neamháitiúla. Ar an láimh eile, le linn parsála incriminteach, ní úsáidtear faisnéis chomhpháirteach ar thaobh na láimhe deise den fhocal reatha, arb é laige choibhneasta an pharsáil shift-laghdaithe é. Chun aghaidh a thabhairt ar an teorannú seo, déanaimid giaráil ar shamhail thapa néarúil chun gnéithe amharc chun cinn a bhaint as. Go háirithe, déanaimid múnla déthreorach LSTM a thógáil, a ghiaráil faisnéis abairt iomlán chun ordlathas na gcomhábhar a thosaíonn agus a chríochnaíonn gach focal a thuar. Cuirtear na torthaí ar aghaidh ansin chuig parsálaí láidir comhábhar atá bunaithe ar thrasdul mar ghnéithe réamhamhairc. Tugann an parsálaí mar thoradh air sin feabhas iomlán 1.3% i WSJ agus 2.3% i CTB i gcomparáid leis an mbunlíne, rud a thugann na beachtas tuairiscithe is airde maidir le parsáil faoi mhaoirseacht iomlán.', 'ka': 'ტრანზიციის დაბათებული მოდელები შეიძლება быстрი და მარტივი იყოს კონსტუტენტების პარალისთვის. ფარატიური მოდელთან შემდგომარებულია, ისინი უფრო დიდი ფუნქციების გამოყენებაში ისტორიის ინფორმაციას პასუტერის სტატიდან გამოყენებით, რომელიც არ არის ლოკალური კონსტიუტენ მეორე მხოლოდ, ინტერმენტიური პარასუზაციაში, მიმდინარე სიტყვის მარცხენა მხარეს ინფორმაცია არ გამოყენება, რომელიც შეცვლა შემცირებული პარასუზაციის relatively weakness. ამ დაფართლების მისამართლად, ჩვენ ძალიან ბრძელი ნეიროლური მოდელის გამოყენება, რომელიც სახელის ფუნქციების გამოყენება. განსაკუთრებულად, ჩვენ ვაკეთებთ ბიდერექციონალური LSTM მოდელი, რომელიც ყველა სიტყვების ინფორმაციას გამოყენებს, რომელიც ყველა სიტყვები დაწყება და დასრულება. შემდეგ შემდეგ შემდეგ გადატანა ძალიან გადატანიზების კონსტიუტენტის პასუტერისთვის, როგორც სახელის ფუნქციები. შემდეგ პროცესტის შემდეგ პროცესტის აბსოლუტური გაუქმედება WSJ-ში და 2.3%-ში CTB-ში, რომლებიც ბაზესტის შემდეგ შემდეგ გაუქმედება, რომლებიც უფრო მეტი შემდეგ გაუქმედებ', 'hu': 'Az átmeneti alapú modellek gyorsak és pontosak lehetnek az alkotóelemek elemzéséhez. A diagramalapú modellekkel összehasonlítva gazdagabb funkciókat használnak a történeti információk kivonásával egy elemző halomból, amely nem helyi alkotóelemek sorozatából áll. Másrészt inkrementális elemzés során az aktuális szó jobb oldalán található alkotóelemi információkat nem használjuk fel, ami a shift-reduce elemzés relatív gyengesége. Ennek a korlátozásnak a kezelése érdekében egy gyors neurális modellt használunk a kilátási funkciók kivonására. Különösen egy kétirányú LSTM modellt építünk, amely a teljes mondat információit használja fel, hogy megjósolja az összetevők hierarchiáját, amely minden szó kezdődik és véget ér. Az eredményeket ezután egy erős átmeneti alapú alkotóelemezőnek adjuk át, mint nézőjellemzőknek. A kapott elemző 1,3%-os abszolút javulást eredményez a WSJ-ben és 2,3%-os CTB-ben a kiindulási értékhez képest, ami a legmagasabb pontosságot biztosítja a teljes körűen felügyelt elemzéshez.', 'el': 'Τα μοντέλα που βασίζονται στη μετάβαση μπορούν να είναι γρήγορα και ακριβή για ανάλυση συστατικών. Σε σύγκριση με μοντέλα βασισμένα σε γραφήματα, αξιοποιούν πλουσιότερα χαρακτηριστικά εξάγοντας πληροφορίες ιστορικού από μια στοίβα αναλύσεων, η οποία αποτελείται από μια ακολουθία μη τοπικών συστατικών. Από την άλλη πλευρά, κατά τη διάρκεια της αυξανόμενης ανάλυσης, δεν χρησιμοποιούνται συστατικές πληροφορίες στη δεξιά πλευρά της τρέχουσας λέξης, γεγονός που αποτελεί σχετική αδυναμία της ανάλυσης μετατόπισης-μείωσης. Για να αντιμετωπίσουμε αυτόν τον περιορισμό, χρησιμοποιούμε ένα γρήγορο νευρωνικό μοντέλο για να εξαγάγουμε χαρακτηριστικά προβολής. Ειδικότερα, κατασκευάζουμε ένα αμφίδρομο μοντέλο το οποίο αξιοποιεί πλήρεις πληροφορίες προτάσεων για να προβλέψει την ιεραρχία των συστατικών που κάθε λέξη αρχίζει και τελειώνει. Τα αποτελέσματα διαβιβάζονται στη συνέχεια σε έναν ισχυρό αναλυτή στοιχείων που βασίζεται στη μετάβαση ως χαρακτηριστικά προβολής. Ο αναλυτής που προκύπτει δίνει 1.3% απόλυτη βελτίωση στο WSJ και 2.3% στη CTB σε σύγκριση με τη βάση, δίνοντας τις υψηλότερες αναφερόμενες ακρίβειες για πλήρως εποπτευόμενη ανάλυση.', 'it': "I modelli basati sulla transizione possono essere veloci e precisi per l'analisi dei componenti. Rispetto ai modelli basati su grafici, sfruttano funzionalità più ricche estraendo informazioni di cronologia da uno stack parser, che consiste in una sequenza di componenti non locali. D'altra parte, durante l'analisi incrementale, le informazioni costituenti sul lato destro della parola corrente non vengono utilizzate, che è una relativa debolezza dell'analisi shift-reduce. Per affrontare questa limitazione, sfruttiamo un modello neurale veloce per estrarre le funzionalità lookfahead. In particolare, costruiamo un modello LSTM bidirezionale, che sfrutta le informazioni complete della frase per prevedere la gerarchia dei costituenti che ogni parola inizia e termina. I risultati vengono poi passati a un potente parser costituente basato sulla transizione come caratteristiche lookfahead. Il parser risultante dà un miglioramento assoluto dell'1,3% nel WSJ e del 2,3% nel CTB rispetto al basale, dando le più alte accuratezza riportate per il parsing completamente supervisionato.", 'mk': 'Моделите базирани на транзиција можат да бидат брзи и прецизни за анализирање на компонентите. Во споредба со моделите базирани на карти, тие ги користат побогатите карактеристики со извлекување на историски информации од група анализатори, која се состои од секвенца на нелокални компоненти. Од друга страна, за време на екстрементално анализирање, конститутивните информации од десната страна на тековниот збор не се искористуваат, што е релативна слабост на анализирањето на смената-намалување. За да се справиме со овие ограничувања, користиме брз нервен модел за да ги извадиме карактеристиките на главата на поглед. Особено, ние изградуваме дворечен модел на ЛСТМ, кој користи целосни информации за речениците за да ја предвиде хиерархијата на составниците што секој збор почнува и завршува. Резултатите потоа се пренесуваат на силен конститутивен анализатор базиран на транзиција како карактеристики на преглед. Резултатот на анализаторот дава апсолутно подобрување од 1,3 отсто во ВСЈ и 2,3 отсто во ПТБ во споредба со почетокот, давајќи ја највисоката пријавена точност за целосно надгледувана анализа.', 'lt': 'Pereinamojo laikotarpio modeliai gali būti greiti ir tikslūs sudedamųjų dalių analizei. Palyginti su grafiniais modeliais, jie sutelkia turtingesnes savybes išimant istorinę informaciją iš analizatoriaus rinkinio, kurį sudaro ne vietos sudedamųjų dalių seka. On the other hand, during incremental parsing, constituent information on the right hand side of the current word is not utilized, which is a relative weakness of shift-reduce parsing.  Siekiant išspręsti šį apribojimą, mes naudojame greitą nervinį model į, kad ištrauktume žvilgsnio galvos savybes. Visų pirma mes sukuriame dvikryptį LSTM model į, kuris sutelkia visą sakinio informaciją, kad būtų galima prognozuoti sudedamųjų dalių hierarchiją, kurią kiekvienas žodis pradeda ir baigia. Tuomet rezultatai perduodami stipriam pereinamuoju laikotarpiu grindžiamam sudedamųjų dalių analizatoriui kaip apžvalgos elementai. Atsižvelgiant į gautą analizatorių, absoliutus WSJ pagerėjimas 1,3 % ir CTB pagerėjimas 2,3 % palyginti su pradiniu tyrimu, duodant didžiausią tikslumą, apie kurį pranešta atliekant visiškai prižiūrimą analizavimą.', 'kk': 'Тіркеме негіздеген үлгілер тұрақты талдау үшін жылдам және дұрыс болуы мүмкін. Диаграмманың негіздеген үлгілерімен салыстырылып, тарихтың мәліметін талдаушы стегінен шығару үшін, олар жергілікті емес компоненттердің ретінде болады. Біріншіден, көптеген талдау кезінде, назардағы сөздің оң жақтағы құрастырмалы мәліметі қолданылмайды, бұл - жылжыту- қысқарту талдауының салыстырмалы қауіпсіздігі. Бұл шектеуді шектеу үшін, қарау үшін тез невралдық үлгісін тарқату үшін көмектесеміз. Әрине біз бұл сөз басталып, аяқталу үшін толық сөздер мәліметін түсіндіру үшін қосымша LSTM үлгісін құрамыз. Нәтижелерді қарау үшін күшті ауыстыру негіздеген конституттық талдаушысына ауыстырылады. Тапсырманың нәтижесі: WSJ және CTB жүйесінде 2.3% абсолютті жақсарту береді. Бұл параметр толық қарау үшін ең жоғары хабарлаған дұрыстығын көрсетеді.', 'ms': 'Model berasaskan-transisi boleh cepat dan tepat untuk penghuraian komponen. Berbanding dengan model berdasarkan kad, mereka menggunakan ciri-ciri yang lebih kaya dengan mengekstrak maklumat sejarah dari tumpukan penghurai, yang terdiri dari urutan konstitusi bukan tempatan. Di sisi lain, semasa penghuraian tambahan, maklumat komponen di sebelah kanan perkataan semasa tidak digunakan, yang merupakan kelemahan relatif penghuraian shift-reduce. Untuk mengatasi keterangan ini, kita menggunakan model saraf yang cepat untuk mengekstrak ciri-ciri kepala mencari. Secara khususnya, kita membina model LSTM bidireksi, yang menggunakan maklumat kalimat penuh untuk meramalkan hierarki konstitusi yang setiap perkataan bermula dan berakhir. Hasilnya kemudian dipindahkan ke penghurai konstituen berdasarkan transisi yang kuat sebagai ciri-ciri lookahead. Penghurai hasilnya memberikan 1.3% peningkatan mutlak dalam WSJ dan 2.3% dalam CTB dibandingkan dengan dasar asas, memberikan ketepatan tertinggi yang dilaporkan untuk penghurai yang diawasi sepenuhnya.', 'mt': 'Il-mudelli bbażati fuq it-tranżizzjoni jistgħu jkunu rapidi u preċiżi għall-analiżi kostitwenti. Meta mqabbla ma’ mudelli bbażati fuq l-istampa, dawn jisfruttaw karatteristiċi aktar rikki billi jestraġu informazzjoni dwar l-istorja minn stack ta’ analizzaturi, li jikkonsisti f’sekwenza ta’ kostitwenti mhux lokali. Min-naħa l-oħra, matul l-analiżi inkrementali, l-informazzjoni kostitwenti fuq in-naħa tal-lemin tal-kelma attwali mhijiex utilizzata, li hija dgħufija relattiva tal-analiżi tat-tnaqqis tal-bidla. Biex nindirizzaw din il-limitazzjoni, nagħmlu ingranaġġ għal mudell newrali mgħa ġġel biex nistruttaw il-karatteristiċi tar-ras tal-għajn. B’mod partikolari, a ħna nibnu mudell ta’ LSTM bidirezzjonali, li jiġġenera informazzjoni dwar sentenzi sħaħ biex tbassar il-ġerarkija tal-kostitwenti li kull kelma tibda u tintemm. Imbagħad ir-riżultati jgħaddu lil analizzatur kostitwenti b’saħħtu bbażat fuq it-tranżizzjoni bħala karatteristiċi ta’ ħarsa. Il-analizzatur li jirriżulta jagħti titjib assolut ta’ 1.3% fil-WSJ u 2.3% fis-CTB meta mqabbel mal-linja bażi, u jagħti l-ogħla preċiżjonijiet irrappurtati għall-analizzazzjoni sorveljata bis-sħiħ.', 'ml': 'ട്രാന്\u200dസിന്\u200dസ് അടിസ്ഥാനത്തിലുള്ള മോഡലുകള്\u200dക്ക് വേഗത്തിലും കൃത്യമായി പാര്\u200dജിങ്ങള്\u200dക്കും വേഗം  Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which consists of a sequence of non-local constituents.  മറുഭാഗത്ത് നിലവിലുള്ള വാക്കിന്റെ വലതുഭാഗത്തുള്ള വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നു ഈ പരിധിയെ വിശദീകരിക്കാന്\u200d, നമ്മള്\u200d വേഗത്തില്\u200d നെയൂറല്\u200d മോഡല്\u200d പുറത്തെടുക്കുന്നതിനായി പുറത്തെടുക്കുന് പ്രത്യേകിച്ച്, എല്\u200dഎസ്റ്റിം മോഡല്\u200d നമ്മള്\u200d പണിയുന്നു. അത് പൂര്\u200dണ്ണമായ വാക്ക് വിവരം നല്\u200dകുന്നു. ഓരോ വാക്കും തുടങ്ങുകയും അവസാനിക്കുകയും  പിന്നീട് അതിന്റെ ഫലങ്ങള്\u200d ശക്തിയായ ഒരു ട്രാന്\u200dസ്കോണ്\u200dസ്റ്റര്\u200d അടിസ്ഥാനമാക്കിയ കോണ്\u200dസ്റ്റര്\u200dമെന്\u200dറി ഭാവിക്കുന്ന പാര്\u200dസിങ്ങിന്റെ ഏറ്റവും മുന്\u200dഗണന പാര്\u200dജിങ്ങള്\u200dക്ക് വേണ്ടി സിറ്റിബിയില്\u200d 1. 3% മെച്ചപ്പെടുത്തുന്നതും 2. 3% ബെസ്റ്', 'no': 'Overgangsbaserte modeller kan vera rask og nøyaktig for å tolka konstituent. Sammenlignet med diagrambaserte modeller, leverer dei rykkere funksjonar ved å pakka ut historisinformasjon frå ei tolkerstak, som inneheld ein rekkjefølgje av ikkje- lokale konstitusjonar. På den andre siden er ikkje konstitusjonsinformasjon på høgre side av det gjeldande ordet brukt under inkrementalt tolking, som er ein relativt svakt av tolking av forskyvingsredusert. For å handtera denne grensen, leverer vi ein rask neuralmodell for å pakka ut funksjonar for lookahead. I særskilt bygger vi ein bidireksjonal LSTM-modell, som leverer fullstendig setningsinformasjon for å foregå hierarkien av konstitusjonar som kvar ord startar og sluttar. Resultatet vert derfor sendt til ein sterk overgangsbasert konstituent- tolkar som lookahead- funksjonar. Resultatet tolkaren gjev 1,3% absolutt forbedring i WSJ og 2,3% i CTB sammenlignet med baselinja, og gjev den høgste rapporterte nøyaktigheten for fullstendig oversikt av tolking.', 'pl': 'Modele oparte na przejściu mogą być szybkie i dokładne do parsowania składników. W porównaniu z modelami opartymi na wykresach wykorzystują bogatsze funkcje poprzez wyodrębnianie informacji o historii ze stosu parsera, który składa się z sekwencji składników nielokalnych. Z drugiej strony, podczas parsowania przyrostowego, informacje składowe po prawej stronie bieżącego słowa nie są wykorzystywane, co jest względną słabością parsowania zmiany-redukcji. Aby rozwiązać to ograniczenie, wykorzystujemy szybki model neuronowy do ekstrakcji funkcji wyglądu. W szczególności budujemy dwukierunkowy model LSTM, który wykorzystuje pełną informację o zdaniu do przewidywania hierarchii składników, które każde słowo zaczyna się i kończy. Wyniki są następnie przekazywane do silnego parsera składników opartego na przejściach jako funkcje wyglądu. Otrzymany parser daje 1,3% absolutną poprawę WSJ i 2,3% w CTB w porównaniu z bazową, dając najwyższą zgłoszoną dokładność dla pełni nadzorowanego parsowania.', 'ro': 'Modelele bazate pe tranziție pot fi rapide și precise pentru analizarea constitutivă. În comparație cu modelele bazate pe diagrame, ele utilizează caracteristici mai bogate prin extragerea informațiilor istorice dintr-o stivă de parser, care constă dintr-o secvență de constituenți non-locali. Pe de altă parte, în timpul analizării incrementale, informațiile constitutive din partea dreaptă a cuvântului curent nu sunt utilizate, ceea ce reprezintă o slăbiciune relativă a analizării shift-reduce. Pentru a aborda această limită, folosim un model neural rapid pentru a extrage caracteristici de privire. În special, construim un model LSTM bidirecțional, care valorifică informațiile complete ale propozițiilor pentru a prezice ierarhia constituenților pe care fiecare cuvânt începe și se termină. Rezultatele sunt apoi transmise unui parser constitutiv puternic bazat pe tranziție ca caracteristici de privire. Analizatorul rezultat oferă o îmbunătățire absolută de 1,3% a WSJ și 2,3% a CTB comparativ cu valoarea inițială, oferind cele mai mari precizii raportate pentru analizarea complet supravegheată.', 'mn': 'Шинжлэх суурилсан загварууд тогтмол хуваалцахын тулд хурдан, зөв байж болно. Царт суурилсан загваруудыг харьцуулахад түүхийн мэдээллийг хуваарилагчийн хэсэгт гаргаж, газрын бус загваруудын дарааллаар бүрддэг. Нөгөө талаар, нэмэлт талаар орчин үгийн баруун талд байгууллагын мэдээллийг ашиглаж чадахгүй. Энэ нь шилжилт багасгах талаар харьцангуй сул байдал юм. Энэ хязгаарлалтыг олохын тулд бид хурдан мэдрэлийн загварыг харах боломжтой болгодог. Ялангуяа бид LSTM загвар бүтээж, энэ нь үг бүр эхэлж, дуусах хэмжээний бүрэн өгүүлбэр мэдээллийг ашигладаг. Үүний үр дүнг харахад хүчтэй шилжилт дээр суурилсан загварын хуваагч руу дамжуулдаг. Үүний үр дүнтэй хуваагч нь WSJ болон CTB-ын 2.3% нь суурь шулуунтай харьцуулахад хамгийн өндөр тодорхойлолтой хуваагдаж байна.', 'so': 'Tusaale ahaan lagu soo wareejiyo waxay si dhaqso ah u sahlan karaan baarlamaanka guud. Isbarbardhig tusaalooyin ku saleysan charto, waxay soo bandhigaan macluumaad taariikhda ah oo ka soo bixinaya qoraalka Parser stack, kaas oo ka mid ah xilli kamid ah oo aan deegaanka ahayn. Sida kale, xilliga baarlamaanka korsocodka, macluumaadka dhamaanka ee ku saabsan dhinaca midig ee erayga hada la joogo lama isticmaalo, taas oo u dhow itaaldarrada beddelka baarlamaanka. Si aan u baaraandegiso nidaamkan, waxaynu u soo bandhignaynaa model neurada oo dhaqso ah si aan uga soo bixino qalabka aragtida. Si gaar ah, waxaynu dhisnaa model LSTM ah oo ku qoran macluumaad buuxa si aan u sii sheegno hierarkii doorashada oo hadal walba bilowdo oo dhammaado. Markaas waxaa lagu soo bandhigi karaa qeyb baaritaanka oo xoogga leh oo ku saleysan baaritaanka sida gaarka looga baaraandegayo. Parameerka dhamaadka wuxuu ka dhigaa 1.3% kordhin dhamaan WSJ iyo 2.3% CTB oo la barbardhigay asalka hoose, wuxuuna siiyaa saxda ugu sarreeya baaritaanka si buuxda loo ilaaliyo.', 'sv': 'Övergångsbaserade modeller kan vara snabba och exakta för komponenttolkning. Jämfört med diagrambaserade modeller utnyttjar de rikare funktioner genom att extrahera historikinformation från en parser stack, som består av en sekvens av icke-lokala komponenter. Å andra sidan, under inkrementell tolkning, används inte komponentinformation på höger sida av det aktuella ordet, vilket är en relativ svaghet i shift-reduce tolkning. För att ta itu med denna begränsning använder vi en snabb neural modell för att extrahera lookfunktioner. I synnerhet bygger vi en dubbelriktad LSTM-modell, som utnyttjar full meningsinformation för att förutsäga hierarkin av beståndsdelar som varje ord startar och slutar. Resultaten skickas sedan vidare till en stark övergångsbaserad komponenttolkning som lookfearch-funktioner. Den resulterande tolkningen ger 1,3% absolut förbättring av WSJ och 2,3% av CTB jämfört med baslinjen, vilket ger den högsta rapporterade noggrannheten för fullt övervakad tolkning.', 'si': 'ස්ථානය අධාරිත මොඩල් ඉක්මනින් හා සිද්ධ විශ්ලේෂණය සඳහා වේගයෙන් ඉන්න පුළුවන්. චාර්ට් අධාරිත මොඩල් එක්ක සම්බන්ධ වුනා, ඔවුන් ඉතිහාස ස්ටැක් වලින් ඉතිහාස තොරතුරු අරගෙන ඉතිහාස තොරතුරු අරගෙන ඉන් අනිත් පැත්තෙන්, විශාල විශාලනය කරමින්, දැන් වචනයේ දකුණු පැත්තේ සාමාන්\u200dය තොරතුරු භාවිත කරන්නේ නැහැ, මේක විශාල විශ මේ සීමාව සම්බන්ධ කරන්න, අපි වේගයෙන් න්\u200dයූරාල් මොඩේලයක් හොයාගන්න හැකියාව හොයාගන්න. විශේෂයෙන්, අපි බිදිරික්ෂිත LSTM මොඩේලයක් හදන්නේ, ඒකෙන් පූර්ණ වාක්ය තොරතුරු ප්\u200dරශ්නය කරනවා හැම වචනයක් පටන් ගන ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති පරීක්ෂණය විශේෂකයෙන් WSJ වලට 1.3% සම්පූර්ණ විශේෂණය සඳහා CTB වලට 2.3% සම්පූර්ණ විශේෂණය සඳහා පරීක්ෂණය කරනවා, සම්පූ', 'sr': 'Prelazni modeli mogu biti brzi i tačni za analizu sastavnih sastavnika. U usporedbi sa modelima baziranim na grafiku, oni utiču na bogatije karakteristike izvlačenjem informacija o povijesti iz grupe analizatora, koja se sastoji od sekvence nekolokalnih komponenata. Sa druge strane, tokom incrementalnog razmatranja, sastavne informacije na desnoj strani trenutne reči se ne koriste, što je relativna slabost razmatranja smjene. Da bi se obratili ovoj ograničenosti, iskoristili smo brzi neuralni model da izvučemo funkcije gledanja. Posebno, izgradimo dvodirektivni LSTM model, koji utiče na informacije o punoj rečenici da predvidimo hijerarhiju sastavnika koje svaka reč počinje i završava. Rezultati se onda prenose na snažni razmatrač sastavnih sastavnika na prijelazu kao funkcije gledanja. Rezultativni analitičar daje apsolutno poboljšanje u WSJ-u od 1,3% i 2,3% u CTB-u u usporedbi sa početnom linijom, dajući najvišu prijavljenu tačnost za potpuno nadzirano analiziranje.', 'ta': 'மாற்றம் அடிப்படையான மாதிரிகள் பாடலுக்கு வேகமாகவும் சரியாகவும் இருக்கலாம். வரைப்பட மாதிரிகளுடன் ஒப்பிட்டால், அவர்கள் பழுப்பான பண்புகளை சேர்க்கிறது, ஒரு பார்சர் ஸ்டாகிலிருந்து வரலாறு தகவலை வெளியேற்றுவதால், அது  மற்றொரு பக்கத்தில், அதிகரிக்கும் பாடலில், தற்போதைய வார்த்தையின் வலது பக்கத்தில் பொறுப்பாளர் தகவல் பயன்படுத்தப்படவில்லை, அது மாற்றத்தை  இந்த எல்லைக்கு முகவரிப்பதற்கு, நாம் வேகமான புதிய மாதிரி முறைமையை வெளியேற்றுவதற்கு. குறிப்பிட்டு, நாம் ஒரு துணை LSTM மாதிரி உருவாக்குகிறோம், அது முழு வாக்கியம் தகவல் வழங்குகிறது, ஒவ்வொரு வார்த்தை துவங்குகிறது ம The results are then passed to a strong transition-based constituent parser as lookahead features.  முடிவு பகுதி WSJ ல் 1. 3% முழுமையான முன்னேற்றத்தை கொடுக்கிறது மற்றும் CTB ல் 2. 3% அடிப்படைக்கோட்டிற்கு ஒப்பிடும், முழுமையாக பர', 'ur': 'ٹرانسیٹ بنیادی موڈل سریع اور دقیق پارسینگ کے لئے ہو سکتے ہیں. چارٹ بنیادی موڈل کے ساتھ مقایسہ کیا گیا ہے، وہ تاریخ معلومات کو پارٹر سٹک سے اٹھانے کے ذریعہ بہت ثروتمند فکراتے ہیں، جو non-local constituents کی سطح میں ہے. دوسری طرف، اضافہ کے بارے میں، موجود کلمہ کے دائیں ہاتھ کے دائیں ہاتھ کے معاملات کا ذریعہ استعمال نہیں کیا جاتا، یہ ایک مقابلہ کمزوری ہے شیفٹ-کمزور پارسینگ کی. یہ محدودیت کے لئے، ہم ایک تیز نئورل موڈل کو لکھنے کے لئے لکھنے کے لئے استعمال کرتے ہیں. مخصوصا، ہم ایک دوسری مسئلہ LSTM موڈل بناتے ہیں، جو تمام کلمات کی معلومات کو پیش بینی کے لئے آغاز کرتا ہے کہ ہر کلمات شروع کرتا ہے اور ختم ہوتا ہے. نتائج اس کے بعد ایک مضبوط تغییر پر بنیاد رکھے ہوئے کامستونٹ پارچر کو lookahead ویژگی کے طور پر گزارے جاتے ہیں. نتیجہ پارچر نے WSJ میں 1.3% اور 2.3% CTB میں بنسس لین کے مقابلہ میں کامل نظر رکھنے کے لئے سب سے زیادہ گزارے ہوئے دقیق تحقیق دیتے ہیں۔', 'uz': "Comment @ info: whatsthis Бошқа тарафда, ҳозирги сўзнинг ўнг тарафида маълумот фойдаланилмас, бу shift парламент камчиликда қизиқтирувчи заифлик. Ushbu chegarani boshqarish uchun biz kichkina neyrol modelini ajratish uchun tez modelni qoʻllayapmiz. Ko'pchilik, biz yordamchi LSTM modelini yaratib, bu bir so'z boshlanadi va boshlanadi. Name Name", 'vi': 'Bộ đệm thời gian có thể nhanh và chính xác để phân tách thành phần. So với các mô- đun biểu đồ, chúng thu hút các tính chất giàu có bằng cách lấy thông tin lịch sử từ một chồng phân, gồm một chuỗi các cử tri không-địa phương. Mặt khác, trong khi phân tích dần, các thông tin cấu tạo bên phải của từ hiện thời không được sử dụng, mà là một điểm yếu của phân tích giảm số thay đổi. Để thực hiện giới hạn này, chúng ta sử dụng hệ thần kinh nhanh để lấy các tính năng quan sát. Chúng tôi tạo ra một mô hình LSD trực tiếp, nhờ đó chúng tôi điều khiển các thông tin đầy đủ về các câu nói để dự đoán phân cấp các cử tri mà mỗi từ bắt đầu và kết thúc. Sau đó kết quả được chuyển qua cho một phân tích lớn dựa vào sự chuyển đổi như các tính năng quan sát. The Kết quả phân giải cung cấp 1.3=.=.=) resulting Tuyệt đối trong WSJ và 2.3=.* in CTB so với thực địa, cung cấp mức độ chính xác báo cao nhất cho việc phân tích được giám sát đầy đủ.', 'da': 'Overgangsbaserede modeller kan være hurtige og nøjagtige til komponentfortolkning. Sammenlignet med diagrambaserede modeller udnytter de rigere funktioner ved at udtrække historieoplysninger fra en parser stak, som består af en sekvens af ikke-lokale bestanddele. På den anden side, under inkrementel parsing, udnyttes komponentinformation på højre side af det nuværende ord ikke, hvilket er en relativ svaghed ved shift-reduce parsing. For at imødegå denne begrænsning udnytter vi en hurtig neural model til at udtrække lookfahead funktioner. Især bygger vi en tovejet LSTM-model, som udnytter fuld sætningsoplysning til at forudsige hierarkiet af bestanddele, som hvert ord starter og slutter. Resultaterne overføres derefter til en stærk overgangsbaseret komponentfortolker som lookfahead funktioner. Den resulterende fortolker giver 1,3% absolut forbedring i WSJ og 2,3% i CTB sammenlignet med baseline, hvilket giver den højeste rapporterede nøjagtighed for fuldt overvåget fortolkning.', 'nl': 'Op overgangen gebaseerde modellen kunnen snel en nauwkeurig zijn voor constitution parsing. Vergeleken met grafiekgebaseerde modellen maken ze gebruik van rijkere functies door geschiedenisinformatie uit een parserstack te extraheren, die bestaat uit een reeks niet-lokale componenten. Aan de andere kant, tijdens incrementele parsing, wordt constitutionele informatie aan de rechterkant van het huidige woord niet gebruikt, wat een relatieve zwakte is van shift-reduce parsing. Om deze beperking aan te pakken, maken we gebruik van een snel neuraal model om lookahead functies te extraheren. Met name bouwen we een bidirectioneel LSTM-model, dat gebruik maakt van volledige zinsinformatie om de hiërarchie van bestanddelen te voorspellen die elk woord begint en eindigt. De resultaten worden vervolgens doorgegeven aan een sterke overgangsgebaseerde constitution parser als lookeahead functies. De resulterende parser geeft 1,3% absolute verbetering in WSJ en 2,3% in CTB in vergelijking met de baseline, wat de hoogste gerapporteerde nauwkeurigheid geeft voor volledig begeleide parsing.', 'bg': 'Моделите, базирани на преход, могат да бъдат бързи и точни за анализ на съставките. В сравнение с моделите, базирани на графики, те използват по-богати функции, като извличат информация за историята от пакет анализатори, който се състои от последователност от нелокални съставки. От друга страна, по време на постепенно анализиране, съставната информация от дясната страна на текущата дума не се използва, което е относителна слабост на анализирането на смяна-намаляване. За да се справим с това ограничение, използваме бърз невронен модел за извличане на функции за гледане напред. По-специално, ние изграждаме двупосочен модел, който използва цялата информация за изреченията, за да предскаже йерархията на съставните елементи, която всяка дума започва и завършва. След това резултатите се предават на силен базиран на преход компонентен анализатор като функции за гледане напред. Полученият анализатор дава 1, 3% абсолютно подобрение в WSJ и 2, 3% в CTB в сравнение с изходната стойност, като дава най- висока отчетена точност при напълно контролирано анализиране.', 'de': 'Transitionsbasierte Modelle können schnell und präzise für das Parsen von Komponenten sein. Im Vergleich zu diagrammbasierten Modellen nutzen sie umfangreichere Funktionen, indem sie Verlaufsinformationen aus einem Parser-Stack extrahieren, der aus einer Sequenz nicht-lokaler Komponenten besteht. Andererseits werden beim inkrementellen Parsen keine konstituierenden Informationen auf der rechten Seite des aktuellen Wortes verwendet, was eine relative Schwäche des Shift-Reduce Parsing darstellt. Um diese Einschränkung zu beheben, nutzen wir ein schnelles neuronales Modell, um Lookuahead-Features zu extrahieren. Insbesondere entwickeln wir ein bidirektionales LSTM-Modell, das vollständige Satzininformationen nutzt, um die Hierarchie der Bestandteile vorherzusagen, die jedes Wort beginnt und endet. Die Ergebnisse werden dann als Lookuahead-Features an einen starken Übergangsbasierten Constitution Parser übergeben. Der resultierende Parser liefert 1,3% absolute Verbesserung in WSJ und 2,3% in CTB im Vergleich zur Baseline, was die höchsten berichteten Genauigkeiten für vollständig überwachtes Parsen liefert.', 'hr': 'Prelazni modeli mogu biti brzi i precizni za analizu sastavnih sastavnika. U usporedbi s modelima baziranim na grafiku, koriste bogatije karakteristike izvlačujući povijest informacije iz postaje analizatora, koja se sastoji iz sekvence neolokalnih sastojaka. S druge strane, tijekom incrementalnog razmatranja, sastavne informacije na desnoj strani trenutne riječi ne koriste, što je relativna slabost razmatranja smanjenja smjene. Za rješavanje ovog ograničenja, iskorištavamo brzi neuronski model da izvučemo funkcije gledanja. Posebno, izgradimo dvodirektivni LSTM model, koji utiče na informacije o punoj rečenici da predviđamo hijerarhiju sastavnika koje svaka riječ počinje i završava. Rezultati se onda prenose na snažni razmatrač sastavnih sastavnika na temelju prijenosa kao funkcije gledanja. Rezultatni analizator daje apsolutno poboljšanje u WSJ-u od 1,3% i 2,3% u CTB-u u usporedbi s početnom linijom, dajući najviše prijavljene preciznosti za potpuno nadzirano analizanje.', 'id': 'Model berdasarkan transisi dapat cepat dan akurat untuk penganalisan konstituen. Berbanding dengan model berdasarkan grafik, mereka menggunakan ciri-ciri yang lebih kaya dengan mengekstraksi informasi sejarah dari tumpukan parser, yang terdiri dari urutan konstitusi bukan lokal. Di sisi lain, selama penghuraian incremental, informasi konstituen di sisi kanan kata saat ini tidak digunakan, yang merupakan kelemahan relatif penghuraian shift-reduce. Untuk mengatasi batasan ini, kita menggunakan model saraf yang cepat untuk mengekstrak fitur kepala pencarian. In particular, we build a bidirectional LSTM model, which leverages full sentence information to predict the hierarchy of constituents that each word starts and ends.  Hasilnya kemudian dipindahkan ke penganalis konstitusi berdasarkan transisi yang kuat sebagai ciri-ciri lookahead. The resulting parser gives 1.3% absolute improvement in WSJ and 2.3% in CTB compared to the baseline, giving the highest reported accuracies for fully-supervised parsing.', 'fa': 'مدل\u200cهای بنیاد تغییر می\u200cتوانند سریع و دقیق باشند برای تجزیه\u200cکنندگان. در مقایسه با مدل\u200cهای بنیاد برنامه\u200cها، آنها ویژگی\u200cهای ثروتمند را با استخراج اطلاعات تاریخ از یک پارچ\u200cکننده\u200cی پارچ\u200cکننده\u200cای استفاده می\u200cکنند که از دسته\u200cای از نمونه\u200cهای غیر محلی است. از طرف دیگر، در حالی جدا کردن افزایش، اطلاعات داخلی در سمت راست کلمه فعلی استفاده نمی\u200cشود، که ضعیف نسبتی از جدا کردن تغییر تغییر تغییر است. برای حل این محدودیت، ما یک مدل عصبی سریع برای اخراج ویژه\u200cهای نگاه\u200cبندی را استفاده می\u200cکنیم. مخصوصا، ما یک مدل LSTM دوباره ساختیم که اطلاعات جمله کامل را برای پیش بینی کردن قانونی قانونی که هر کلمه شروع و پایان می\u200cشود تأثیر می\u200cدهد. نتیجه\u200cها به عنوان ویژه\u200cهای lookahead به یک جداکنده\u200cی مجموعه\u200cای بر اساس تغییر قوی به عنوان ویژه\u200cهای نگاه\u200cبندی گذاشته می\u200cشوند. پاداش\u200cکننده\u200cی نتیجه ۱.۳ درصد توسعه کامل در WSJ و ۲.۳ درصد در CTB در مقایسه با خط بنیادی می\u200cدهد، که بالاترین دقیقات گزارش داده شده برای پاداش کامل تحت نظر قرار می\u200cدهد.', 'ko': '변환된 모델을 바탕으로 성분 분석을 신속하고 정확하게 할 수 있다.도표를 바탕으로 한 모델에 비해 일련의 비국부 성분으로 구성된 해석기 창고에서 역사 정보를 추출하여 더욱 풍부한 특징을 이용한다.다른 한편, 증량 분석 과정에서 현재 단어 오른쪽의 성분 정보가 이용되지 않은 것은 이위-감소 분석의 상대적인 약점이다.이러한 한계를 해결하기 위해 우리는 신속신경모델을 이용하여 전망특징을 추출한다.특히 우리는 모든 단어의 시작과 끝의 성분 차원을 예측하기 위해 완전한 문장 정보를 활용한 쌍방향 LSTM 모델을 구축했다.그리고 그 결과를 강력한 전환을 바탕으로 하는 성분 해석기에 전망 특성으로 전달한다.베이스라인에 비해 최종 해석기는 WSJ과 CTB에서 절대 개선률이 각각 1.3%, 2.3%로 전체 감독 해석에 가장 높은 보고 정밀도를 제공했다.', 'sw': 'Mfano wa mabadiliko yanaweza kuwa haraka na sahihi kwa ajili ya kuimba wabunge. Kulinganishwa na mifano yenye msingi wa chart, wanatumia vipengele vya utajiri kwa kuondoa taarifa za historia kutoka kwenye kituo cha mchanganyiko, ambacho kinajumuisha mfululizo wa wagombea wasio wa ndani. Kwa upande mwingine, wakati wa maongezi ya kuongezeka, taarifa za wabunge kuhusu upande wa kulia wa neno la sasa hazitumiki, ambayo ni dhaifu wa udhaifu wa mabadiliko ya mabadiliko. Ili kukabiliana na mipaka hii, tunatumia muundo wa haraka wa neura ili kuondoa vipengele vya kuonekana. Kwa hakika, tunajenga muundo wa LSTM unaoandika taarifa kamili za hukumu ili kutabiri ubora wa wapiga kura ambao kila neno linaanza na kusitisha. Matokeo hayo yanapitishwa kwa mbunge wenye msingi wa mpito kama vipengele vya kuonekana. Uchambuzi wa matokeo unatoa asilimia 1.3 ya kuboreshwa kabisa katika WSJ na asilimia 2.3 katika CTB ukilinganishwa na msingi, na kutoa ukweli wa juu uliotolewa kwa ajili ya uchimbaji uliofanywa kabisa.', 'af': "Transisie-gebaseerde modele kan vinnig en presies wees vir konstituent verwerking. Vergelyk met kaart-gebaseerde modele, hulle verwyder ryker funksies deur die uitpak van geskiedenis inligting van 'n verwerker stack, wat bestaan van' n reeks van nie- plaaslike konstituantes. Op die ander kant word, tydens inkremensiele verwerking, konstituent inligting op die regterkant van die huidige woord nie gebruik word nie, wat is 'n relatiewe swakheid van verwyder verwerking. Om hierdie beperking te adres, moet ons 'n vinnige neurale model uitvoer om uitsig van opsigte funksies te uittrek. In besonderhede bou ons 'n bidireksjonale LSTM model, wat volledige seting inligting verwyder om die hierarkie van konstitusies te voorskou wat elke woord begin en einde. Die resultate word dan oorgestuur na 'n sterk oordrag- gebaseerde konstituent ontleerder as opsyk- heed funksies. Die resulteerde ontleerder gee 1.3% absoluut verbetering in WSJ en 2.3% in CTB vergelyk met die basislien, gegee die hoogste vergelykde presies vir volledig ondersoekte verwerking.", 'sq': 'Modelet bazuar në tranzicion mund të jenë të shpejtë dhe të sakta për analizimin e përbërësve. Në krahasim me modelet me bazë grafike, ato përdorin karakteristika më të pasura duke nxjerrë informacionin historik nga një grumbull analizues, i cili përbëhet nga një sekuencë prej përbërësve jo-lokalë. Nga ana tjetër, gjatë analizimit gradual, informacioni përbërës në anën e djathtë të fjalës aktuale nuk përdoret, gjë që është një dobësi relative e analizimit shift-reduce. Për të trajtuar këtë kufizim, ne përdorim një model nervor të shpejtë për të nxjerrë karakteristikat e kokës së kërkimit. Në veçanti, ne ndërtojmë një model LSTM dy-drejtues, i cili përdorë informacionin e plotë të fjalëve për të parashikuar hierarkinë e përbërësve që çdo fjalë fillon dhe përfundon. Rezultatet kalohen pastaj në një analizues të fortë përbërës bazuar në tranzicion si karakteristika të kokës së shikimit. Analizatori rezultues jep 1.3% përmirësim absolut në WSJ dhe 2.3% në CTB krahasuar me bazën, duke dhënë saktësinë më të lartë të raportuar për analizimin plotësisht të mbikqyrur.', 'tr': "Da첵dan ge챌irme nusgalary tiz we dogry bir halk ay캇rmak 체챌in edip biler. 횉izelgede tabanly nusgalar bilen kar힊캇la힊dyryl힊y, ge챌mi힊 maglumaty bir tans챌ydan 챌ykarmak 체챌in ba첵ram챌y karakterlerden 챌ykar첵arlar. Bu 첵erler 첵erleri gabat ta첵첵arlar. Di흫e 첵erde, g체nahsy analyz eden wagtynda, esasy s철z체흫 sag tarapynda constituent maglumaty ullanyl첵ar. Bu tertiblemek 체챌in 첵itil첵채n 챌yky힊 hasaplamakd캇r. Bu hat 챌ykmak 체챌in, g철zlerimizi a 챌mak 체챌in tiz bir n채ral nusgasyny 챌ykar첵arys. A첵ratyn bolsa, biz 철z체miz 2-di첵eterlik LSTM nusgasyny in힊a ed첵채ris. Bu s철zler her s철z ba힊lap we so흫la첵an constituent hijerarhi첵asyny 챌aklamak 체챌in doly s철zlem maglumatyny t채sirle첵채r. Netijeler, so흫ra g체첵챌li bir g철챌men챌e da첵ratyn bir g철챌men챌e wa첵la힊dyr. Sonu챌ta 챌철z체mler, WSJ'de 1.3% we 2.3% CTB'de esasy 챌철z체mlerinde d체zeltilmesi 체챌in i흫 y체ksek derejesi bar.", 'am': 'የግንኙነት አካባቢ ምርጫዎች ፈጥኖ እና እርግጠኛ መሆኑን ይችላል፡፡ Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which consists of a sequence of non-local constituents.  በሌላው ወገን፣ በአካባቢው ማኅበረሰብ ጊዜ፣ የአሁኑ ቃል በቀኝ በኩል ያለውን መረጃ አይጠቀምም፣ ይህም የመለወጥ ማኅበረሰብ የጎዳና ደካማ ነው፡፡ ይህንን ግንኙነት ለመግለጽ፣ የፍጥነት የኔural ሞዴል ለመውጣት የራስ ምርጫዎችን ለማውጣት እናስገድዳለን፡፡ በተለይም የLSTM ሞዴል እናደርጋለን፣ ይህም ሁሉም ቃል የሚጀምርና የሚፈጸመውን የመረጃ አዳራሲ እናስታውቃለን፡፡ ፍሬዎቹም ወደ ብርቱ ተሳታፊ አካባቢ አካባቢ ተሳታፊ እንደሚያሳየው ምርጫዎች ይደርሳሉ፡፡ የጥያቄው ተርጓሚው በWSJ እና በCTB ውስጥ 2.3 በመቶው ክፍተት ሰጥቷል፡፡', 'hy': 'Անցման հիմնված մոդելները կարող են արագ և ճշգրիտ լինել բաղադրիչների վերլուծության համար: Համեմատելով քարտեզից հիմնված մոդելների հետ, նրանք օգտագործում են ավելի հարուստ հատկանիշներ՝ վերցնում են պատմության տեղեկատվությունը վերլուծողների կույթից, որը կազմում է ոչ տեղական բաղադրիչների հաջորդականություն: Մյուս կողմից, բառի աջ կողմում բառի բաղադրիչը բառացիոն ինֆորմացիայի ընթացքում չի օգտագործվում, ինչը տեղաշարժման-նվազեցնելու հարաբերական թույլ է: Այս սահմանափակումներին լուծելու համար մենք օգտագործում ենք արագ նյարդային մոդելը, որպեսզի դուրս բերենք նայության գլխավոր հատկանիշներ: Հատկապես, մենք ստեղծում ենք երկու ուղղությամբ LSMT մոդել, որը օգտագործում է ամբողջ նախադասությունների տեղեկատվությունը, որպեսզի կանխագուշակենք բաղադրիչների հիերարխիան, որ յուրաքանչյուր բառ սկսում է և ավարտվ Արդյունքները փոխանցվում են մի ուժեղ վերաբերյալ բաղադրիչ, որը հիմնված է վերաբերյալ վերաբերյալ, որպես նայելու գլխավոր հատկություններ: Արդյունքում ստացված խմբագրիչը կատարում է 1.3 տոկոսի բացարձակ բարելավում ՎՍՋ-ում և 2.3 տոկոսի խմբագրիչներում, համեմատած հիմնական հիմնական հիմնական հիմնական հիմնական հիմնական հիմնական հիմնական հիմնական հիմնական հիմն', 'bn': 'প্রতিনিধি পার্সিং এর জন্য প্রান্তের ভিত্তিক মডেল দ্রুত এবং সঠিক হতে পারে। চ্যার্ট ভিত্তিক মডেলের সাথে তুলনায়, তারা একটি প্যারার্স্ট্যাক থেকে ইতিহাসের তথ্য বের করে সমৃদ্ধ বৈশিষ্ট্য প্রদান করে, যা স্থানী অন্যদিকে, ক্রমশ পার্সিং সময় বর্তমান শব্দের ডান দিকে বিভিন্ন তথ্য ব্যবহার করা হয়নি, যা পরিবর্তন-কমানো পার্সিং এর আত্মিক দুর্বলতা। এই সীমাবদ্ধতাকে ঠিক করার জন্য আমরা দ্রুত নিউরেল মডেল প্রদান করি লুকাহেডের বৈশিষ্ট্য বের করার জন্য। বিশেষ করে, আমরা একটি বিদ্যমান এলস্টিএম মডেল তৈরি করি, যা পুরো বাক্যের তথ্য প্রদান করে ভোটারদের হিয়ারার্কি ভবিষ্যৎ করার জন্য প্রত্যেক তারপর ফলাফল একটি শক্তিশালী প্রান্তের ভিত্তিক ক্ষেত্রে পাঠানো হয়েছে লুকাহেডের বৈশিষ্ট্য হিসেবে। ফলাফল প্যারেজার ১. ৩% উইএসজে এবং সিটিবিতে ২.', 'az': "Transiciya tabanlı modellər dəstək ayırılması üçün hızlı və düzgün olar. Çarxa-tabanlı modellərlə qarşılaşdırıldılar, keçmiş məlumatlarını parçacılıq stacasından çıxarıb, yerli olmayan komponentlərin seçməsi ilə daha zengin fəaliyyətlərini yaradırlar. Digər tərəfindən, həmin sözün sağ tərəfində müxtəlif məlumatlar istifadə edilməz, bu da dəyişiklik azaltma ayırmasının relativ zəifliyidir. Bu sınırları çəkmək üçün, gözləmək üçün hızlı bir nöral modeli yaradırıq. Özellikle, hər sözün başladığını və bitdiyini təmin etmək üçün bütün cümlələr məlumatını təmin edirik. Sonra sonuçlar güclü keçiş-tabanlı müəyyənləşdiricisi kimi gözləyir. Növbəti analizəşdiricisi WSJ və CTB'nin 2.3%-nin tamamlanması üçün ən yüksək xəbərdarlıqlarını verir.", 'ca': "Els models basats en la transició poden ser ràpids i precisos per a l'analització de components. Comparats amb models basats en gràfics, utilitzen característiques més riques extraint informació història d'una pila d'analitzadors, que consisteix en una seqüència de constituents no locals. D'altra banda, durant l'analització incremental, no s'utilitza la informació constitucional a la dreta de la paraula actual, que és una debilitat relativa de l'analització shift-reduce. Per abordar aquesta limitació, utilitzem un model neural ràpid per extrair les característiques de la cabeza de mirada. En particular, construïm un model LSTM bidireccional, que aprofita la informació de frases completas per predir la jerarquia dels constituents que cada paraula comença i acaba. Els resultats es transmetren a un fort analitzador de components basat en la transició com a característiques de cap de mirada. L'analitzador resultant dóna una millora absoluta del 1,3% en WSJ i del 2,3% en CTB en comparació amb el basal, donant la més alta precisió notificada per l'analització plenament supervisada.", 'bs': 'Prelazni modeli mogu biti brzi i precizni za analizu sastavnih sastavnika. U usporedbi s modelima baziranim na grafiku, oni koriste bogatije karakteristike izvlačenjem informacija povijesti iz grupe analizatora, koja se sastoji od sekvence nekolokalnih sastojaka. Sa druge strane, tijekom incrementalnog razmatranja, sastavne informacije na desnoj strani trenutne riječi nisu korištene, što je relativna slabost razmatranja smanjenja smjene. Da bi se riješili ovoj ograničenosti, iskoristili smo brzi neuralni model da izvučemo funkcije gledanja. Posebno, izgradimo dvodirektivni LSTM model, koji utiče na informacije o punoj rečenici da predvidimo hijerarhiju sastavnika koje svaka riječ počinje i završava. Rezultati se onda prenose na snažni razmatrač sastavnih sastavnika na temelju prijenosa kao funkcije gledanja. Rezultatni analizator daje apsolutno poboljšanje u WSJ-u od 1,3% i 2,3% u CTB-u u usporedbi s početnom linijom, dajući najvišu prijavljenu tačnost za potpuno nadzirano analizanje.', 'cs': 'Modely založené na přechodu mohou být rychlé a přesné pro analýzu komponent. Ve srovnání s modely založenými na grafech využívají bohatší funkce tím, že extrahují informace o historii ze zásobníku parseru, který se skládá z sekvence nekomístních složek. Na druhou stranu, při inkrementálním parsování se informace o složkách na pravé straně aktuálního slova nepoužívají, což je relativní slabost posunu-redukce parsování. K řešení tohoto omezení využíváme rychlý neuronový model k extrakci vyhledávacích funkcí. Konkrétně vytvoříme obousměrný LSTM model, který využívá úplné informace o větách k předpovědi hierarchie prvků, které každé slovo začíná a končí. Výsledky jsou pak předány silnému parseru komponent založenému na přechodu jako vyhledávací funkce. Výsledný parser poskytuje 1,3% absolutní zlepšení WSJ a 2,3% v CTB ve srovnání s výchozí hodnotou, což dává nejvyšší hlášené přesnosti pro plně dohledované parsing.', 'et': 'Üleminekupõhised mudelid võivad olla koostisosade parsimiseks kiired ja täpsed. Diagrammipõhiste mudelitega võrreldes kasutavad nad rikkalikumaid funktsioone, ekstraheerides ajalooteavet parserivirnast, mis koosneb mittekohaliste komponentide jadast. Teisest küljest ei kasutata järkjärgulise parsimise ajal praeguse sõna paremal pool olevat koostisosa teavet, mis on nihke-vähendamise parsimise suhteline nõrkus. Selle piirangu kõrvaldamiseks kasutame kiiret närvimudelit, et eraldada vaatlusfunktsioone. Eelkõige ehitame kahesuunalise LSTM mudeli, mis kasutab täielikku lauseteavet, et ennustada koostisosade hierarhiat, mida iga sõna algab ja lõpeb. Tulemused edastatakse seejärel tugevale üleminekupõhisele koostisosaparserile vaatlusfunktsioonidena. Saadud parser annab algtasemega võrreldes 1,3% absoluutse paranemise WSJ-s ja 2,3% CTB-s, andes suurima teatatud täpsuse täieliku järelevalve all toimuva parsimise puhul.', 'fi': 'Siirtymäpohjaiset mallit voivat olla nopeita ja tarkkoja komponenttien jäsentämisessä. Kaaviopohjaisiin malleihin verrattuna ne hyödyntävät rikkaampia ominaisuuksia poimimalla historiatietoja jäsentäjäpinosta, joka koostuu ei-paikallisista komponenteista. Toisaalta inkrementaalisen jäsentämisen aikana nykyisen sanan oikealla puolella olevaa osatietoa ei käytetä, mikä on shift-reduce-jäsentämisen suhteellinen heikkous. Tämän rajoituksen korjaamiseksi hyödynnämme nopeaa neuromallia näköalaominaisuuksien poistamiseksi. Erityisesti rakennamme kaksisuuntaisen LSTM-mallin, joka hyödyntää koko lauseen tietoja ennustaaksemme jokaisen sanan alkavan ja päättyvän osatekijöiden hierarkian. Tulokset siirretään sitten vahvaan siirtymään perustuvaan komponentin jäsentäjään ennakoivana ominaisuutena. Tuloksena saatu jäsentäjä antaa 1,3% absoluuttisen parannuksen WSJ:ssä ja 2,3% CTB:ssä lähtötilanteeseen verrattuna, mikä antaa suurimmat raportoidut tarkkuudet täysin valvotussa jäsentämisessä.', 'jv': 'shift Sampeyan karo model sing diagram-basa, padha menehi nggawe akeh barêt-barêt kuwi nggawe barang nggawe tarjamahan karo nganggo urip banter Ngucap Nyong ngomong nambah iki, kita sumunggo ngegambar model model model model model nang dibutuhke cara-cara Juara-Juara, awak dhéwé nggawe model sing dibenalke SLT M, sing wis nambah informasi nggawe barang kanggo ngerasakno karo koyok barang sampek Rejal Genjer', 'sk': 'Modeli, ki temeljijo na prehodu, so lahko hitri in natančni za razčlenitev sestavnih delov. V primerjavi z modeli, ki temeljijo na grafikonih, izkoriščajo bogatejše funkcije tako, da pridobijo informacije o zgodovini iz razčlenjevalnika, ki je sestavljen iz zaporedja nelokalnih sestavin. Po drugi strani pa se med postopnim razčlenjevanjem ne uporabljajo sestavne informacije na desni strani trenutne besede, kar je relativna šibkost razčlenjevanja shift-reduce. Da bi odpravili to omejitev, uporabljamo hiter nevronski model za ekstrakcijo funkcij gledanja naprej. Zlasti gradimo dvosmerni model LSTM, ki uporablja informacije o celotnem stavku za napoved hierarhije sestavnih delov, ki se začne in konča vsaka beseda. Rezultati se nato prenesejo na močan razčlenjevalnik komponent, ki temelji na prehodu, kot funkcije vnaprej. Dobljeni razčlenjevalnik zagotavlja 1,3% absolutno izboljšanje WSJ in 2,3% CTB v primerjavi z izhodiščem, kar zagotavlja največjo poročano natančnost pri popolnoma nadzorovanem razčlenjevanju.', 'he': 'דוגמנים מבוססים על העברה יכולים להיות מהירים ודוקסים לאבחן המרכיבים. בהשוואה לדוגמנים מבוססים על רשימות, הם משתמשים במיוחדים עשירים יותר בכך שהוציאו מידע היסטורי מערכת מעבדות, שמתכוונת בשורה של נבחרים לא מקומיים. מצד שני, במהלך בדיקת מיוחדת, מידע המרכיב בצד ימין של המילה הנוכחית לא משתמש, שזה חולשה יחסית של בדיקת שינוי-פחות. כדי להתמודד עם ההגבלה הזאת, אנו משתמשים בדגם עצבי מהיר כדי לחלץ תכונות ראש חיפוש. In particular, we build a bidirectional LSTM model, which leverages full sentence information to predict the hierarchy of constituents that each word starts and ends.  אז התוצאות מועברות למחקר המרכיבים חזק מבוסס במעבר כתכונות ראש חיפוש. המחקר הנוצא נותן שיפור מוחלט ב-1.3% ב-WSJ ו-2.3% ב-CTB בהשוואה לבסיס המקורי, נותן את הדיוקות הגבוהה ביותר שנדווחות עבור בדיקת מבוקרת לחלוטין.', 'ha': "@ info: whatsthis @ action: button Ga da hagu, a lokacin da ake yi musamman, ba za'a yi amfani da maɓallin daman na daman maganar yanzu ba, wannan yana da wani abu mai ƙaranci wa parse. Domin da za'a yi amfani da wannan tsarin, za'a samar da wata motsi na neural mai haraka dõmin ya fitar masu tsarin masu nuna. Kayyade, muna samar da wani misali na LSSM mai ƙara, wanda ke gajiya ma'anar magana cikakken, dõmin ya yi bayani ga hijariyriyar masu cikin abõkan da kõwace magana ke fara kuma yana ƙara. Sa'an nan kuma za'a shige su zuwa wani mai ƙarfi mai shawara da aka ƙayyade shi kamar tayari masu tsari wa shirin kawaici. Parser ɗin da aka ƙara yana da 1.3% mai kyau cikin WSJe da 2.3% cikin ATB sami da kwamfyutan rubutun, kuma yana bãyar da tsarin da aka faɗa mafi cikakken parse.", 'bo': 'གནས་སྐབས་གཞུང་བརྟེན་པའི་མིག་དཔེ་དབྱེ་ཞིབ་བྱེད་པར་མགྱོག་དང་བདེ་ཞིབ་ཡིན། Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which consists of a sequence of non-local constituents. ཕྱོགས་གཞན་ཞིག་ནས་ཡར་རྒྱས་གཏོང་ཀྱི་ལས་འཕར་སྟོན་པའི་གནད་དོན་ཕྱོགས་ཀྱི་གནད་དོན་མ་ལག་ལེན་འཐབ་མེད། ཚད་འདི་ལ་ངེད་ཚོས་མཚམས་མཐོང་ནུས་མྱུར་བའི་རྣམ་པ་ཞིག་བཙལ་འདོགས་བྱེད་ཀྱི་ཡོད། In particular, we build a bidirectional LSTM model, which leverages full sentence information to predict the hierarchy of constituents that each word starts and ends. གྲུབ་འབྲས་འདི་ལྟ་བཤེར་བྱེད་པའི་སྐྱེས་གཞུང་བའི་རྩ་སྒྲིག་པོ་ཞིག་ལ་བསྒྱུར་ཚར་བ་ཡིན། དབྱེ་བཟོ་མཁན་ནི་WSJ-དཔལ་ཡོད་པའི་ཆེས་ཉུང་བའི་སྐྱོན་བརྗོད་བྱེད་རྒྱུ་ཡིན་ན། CTB ནང་ཉེས་གནས་ཚུལ་དང་2.3%'}
{'en': 'A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit', 'ar': 'خوارزمية برمجة ديناميكية متعددة الحدود لفك التشفير المستند إلى العبارة بحد تشويه ثابت', 'pt': 'Um algoritmo de programação dinâmica em tempo polinomial para decodificação baseada em frase com um limite de distorção fixo', 'fr': 'Algorithme de programmation dynamique en temps polynomial pour le décodage basé sur des phrases avec une limite de distorsion fixe', 'es': 'Algoritmo de programación dinámica en tiempo polinómico para la decodificación basada en frases con un límite de distorsión fijo', 'ja': '固定歪み制限付きフレーズベースのデコードのための多項式時間動的プログラミングアルゴリズム', 'zh': '一有定失真限值基于短语解码之多项式时动规算', 'hi': 'एक बहुपद-समय डायनेमिक प्रोग्रामिंग एल्गोरिथ्म एक निश्चित विरूपण सीमा के साथ वाक्यांश-आधारित डिकोडिंग के लिए', 'ru': 'Алгоритм динамического программирования полиномиального времени для декодирования на основе фраз с фиксированным пределом искажения', 'ga': 'Algartam Ríomhchláraithe Dinimiciúla Il-Ama do Dhíchódú Frás-bhunaithe le Teorainn Saobhadh Seasta', 'ka': 'Name', 'hu': 'Polinom-idő dinamikus programozási algoritmus a kifejezésalapú dekódoláshoz fix torzítási korláttal', 'el': 'Ένας αλγόριθμος δυναμικού προγραμματισμού πολυωνυμού χρόνου για αποκωδικοποίηση με βάση φράσεις με σταθερό όριο παραμόρφωσης', 'it': 'Algoritmo di programmazione dinamica polinomiale-temporale per decodifica basata su frasi con limite di distorsione fisso', 'kk': 'Фраз негіздеген декодировкасының полиномикалық- уақыт динамикалық бағдарламасының алгоритміName', 'mk': 'Алгоритм за полиномско-временско динамско програмирање за декодирање базирано на фрази со фиксна граница на растура', 'lt': 'Polinominio laiko dinaminio programavimo algoritmas, skirtas frazėmis grindžiamam dekodiavimui su fiksuotu iškraipymo apribojimu', 'ms': 'Name', 'ml': 'Name', 'no': 'Name', 'mt': 'Algoritmu ta’ Programmar Dinamiku ta’ Ħin Polinomiku għal Dikodifikazzjoni Bażata fuq Frażi b’Limitu Fixed ta’ Distortion', 'mn': 'Бүтээгдэхүүний хэмжээний хугацааны динамик програмчлалын алгоритм', 'pl': 'Algorytm dynamicznego programowania wielomianowego dla dekodowania opartego na frazach ze stałą granicą zniekształceń', 'sr': 'Polinom-vremenski dinamički algoritam programiranja za dekodiranje na frazi sa fiksnim ograničenjem destrukcije', 'ro': 'Algoritm de programare dinamică polinomială în timp pentru decodarea bazată pe fraze cu limită fixă de distorsiune', 'si': 'Name', 'sv': 'En polynomisk tidsdynamisk programmeringsalgoritm för frasbaserad avkodning med fast förvrängningsgräns', 'so': 'A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Một đơn vị lập trình động theo đa thức thời gian cho PhChiêu với một hạn Dịch méo mó cố định', 'bg': 'Алгоритъм за динамично програмиране на полиномно време за декодиране на фрази с фиксиран лимит на изкривяване', 'nl': 'Een polynoom-time dynamisch programmeringsalgoritme voor op zinnen gebaseerde decodering met een vaste vervormingslimiet', 'da': 'En polynomisk tidsdynamisk programmeringsalgoritm til sætningsbaseret afkodning med en fast forvrængningsgrænse', 'hr': 'Polinomski dinamički algoritam programiranja vremena za dekodiniranje na frazi s fiksnim ograničenjem poremećaja', 'de': 'Dynamischer Programmieralgorithmus für Phrasen-basierte Dekodierung mit fester Verzerrungsgrenze', 'ko': '고정 오류 한도에서 짧은 언어 디코딩을 바탕으로 하는 다항식 시간 동적 기획 알고리즘', 'fa': 'Name', 'id': 'Algoritma Pemrograman Dinamik Polynomial-Time untuk Dekodasi Berdasarkan Frasa dengan Batas Distortion Fixed', 'sw': 'Algorithi ya Mpango wa Kidynami wa Mipango ya Mipango ya Ujadala wa Kireno kwa Kupungua Ukumbuzi wa Kireno', 'af': 'Name', 'tr': 'Frase Beýik Bölüniş Ködleme üçin Polynomiýal-Zaman Dinamik Programlamak Algoritmi', 'sq': 'Algoritmi i programimit dinamik të kohës polinomike për dekodimin bazuar në fryza me një limitë të fiksuar shkatërrimi', 'am': 'ምርጫዎች', 'hy': 'Ֆրանսիայի հիմքով կոդավորման պոլինոմիկ ժամանակի դինամիկ ծրագրավորումների ալգորիթմը ֆիքսված շեղումների սահմանափակությամբ', 'bn': 'Name', 'az': 'Fraz tabanlı Dekodlama üçün Polynomial-Time Dynamic Programming Algoritmi', 'bs': 'Polinomski dinamički algoritam programiranja vremena za dekodiniranje na frazi s fiksnim ograničenjem destrukcije', 'et': 'Polünoomilise aja dünaamilise programmeerimise algoritm fraasipõhise dekodeerimise jaoks fikseeritud moonutuspiiranguga', 'ca': 'A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit', 'cs': 'Polynomiálně-časový dynamický programovací algoritmus pro dekódování založené na frázích s pevným deformačním limitem', 'fi': 'Polynomi-aikadynaaminen ohjelmointialgoritmi lausepohjaiseen dekoodiin kiinteällä vääristymisrajalla', 'ha': 'KCharselect unicode block name', 'sk': 'Algoritm za dinamično programiranje polinomskega časa za dekodiranje na podlagi fraz s fiksno omejitvijo popačenja', 'he': 'A Polynomial-Time Dynamic Programming Algorithm for Phrase-Based Decoding with a Fixed Distortion Limit', 'jv': 'Name', 'bo': 'Phrase-Based Decoding with a fixed Distortion Limit'}
{'en': 'Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the traveling salesman problem (Knight, 1999). In practice, phrase-based systems often impose a hard distortion limit that limits the movement of phrases during translation. However, the impact on complexity after imposing such a constraint is not well studied. In this paper, we describe a dynamic programming algorithm for phrase-based decoding with a fixed distortion limit. The runtime of the algorithm is O(nd!lhd+1) where n is the sentence length, d is the distortion limit, l is a bound on the number of phrases starting at any position in the sentence, and h is related to the maximum number of target language translations for any source word. The algorithm makes use of a novel representation that gives a new perspective on decoding of phrase-based models.', 'ar': 'من المعروف أن فك رموز نماذج الترجمة المبنية على العبارات في الحالة العامة هو NP-Complete ، من خلال تقليل مشكلة البائع المتجول (Knight ، 1999). في الممارسة العملية ، غالبًا ما تفرض الأنظمة القائمة على العبارات حدًا شديدًا للتشويه يحد من حركة العبارات أثناء الترجمة. ومع ذلك ، فإن التأثير على التعقيد بعد فرض مثل هذا القيد لم يدرس جيدًا. في هذا البحث ، نصف خوارزمية البرمجة الديناميكية لفك التشفير المبني على العبارة بحد تشويه ثابت. وقت تشغيل الخوارزمية هو O (nd! lhd + 1) حيث n هو طول الجملة ، و d هو حد التشويه ، و l مرتبط بعدد العبارات التي تبدأ في أي موضع في الجملة ، و h مرتبطة بـ الحد الأقصى لعدد ترجمات اللغة المستهدفة لأي كلمة مصدر. تستخدم الخوارزمية تمثيلًا جديدًا يعطي منظورًا جديدًا لفك تشفير النماذج المستندة إلى العبارات.', 'es': 'Se sabe que la decodificación de modelos de traducción basados en frases en el caso general es NP-completa, por una reducción del problema del vendedor ambulante (Knight, 1999). En la práctica, los sistemas basados en frases a menudo imponen un límite de distorsión estricto que limita el movimiento de las frases durante la traducción. Sin embargo, el impacto en la complejidad después de imponer tal restricción no está bien estudiado. En este artículo, describimos un algoritmo de programación dinámica para la decodificación basada en frases con un límite de distorsión fijo. El tiempo de ejecución del algoritmo es O (nd! lhd+1) donde n es la longitud de la oración, d es el límite de distorsión, l es un límite en el número de frases que comienzan en cualquier posición de la oración y h está relacionado con el número máximo de traducciones al idioma de destino para cualquier palabra fuente. El algoritmo hace uso de una representación novedosa que ofrece una nueva perspectiva sobre la decodificación de modelos basados en frases.', 'fr': "Le décodage des modèles de traduction basés sur des phrases dans le cas général est connu pour être NP-complet, en réduisant le problème des vendeurs itinérants (Knight, 1999). Dans la pratique, les systèmes basés sur des phrases imposent souvent une limite de distorsion stricte qui limite le mouvement des phrases pendant la traduction. Cependant, l'impact sur la complexité de l'imposition d'une telle contrainte n'est pas bien étudié. Dans cet article, nous décrivons un algorithme de programmation dynamique pour le décodage basé sur des phrases avec une limite de distorsion fixe. Le temps d'exécution de l'algorithme est O (nd\xa0! lhd+1) où n est la longueur de la phrase, d est la limite de distorsion, l est une limite du nombre de phrases commençant à n'importe quelle position dans la phrase et h est lié au nombre maximum de traductions dans la langue cible pour un mot source. L'algorithme utilise une nouvelle représentation qui donne une nouvelle perspective sur le décodage des modèles basés sur des phrases.", 'pt': 'A decodificação de modelos de tradução baseados em frases no caso geral é conhecida como NP-completa, por uma redução do problema do caixeiro viajante (Knight, 1999). Na prática, os sistemas baseados em frases geralmente impõem um limite rígido de distorção que limita o movimento das frases durante a tradução. No entanto, o impacto na complexidade após a imposição de tal restrição não é bem estudado. Neste artigo, descrevemos um algoritmo de programação dinâmica para decodificação baseada em frases com um limite de distorção fixo. O tempo de execução do algoritmo é O(nd!lhd+1) onde n é o comprimento da frase, d é o limite de distorção, l é um limite no número de frases começando em qualquer posição na frase, e h está relacionado ao número máximo de traduções do idioma de destino para qualquer palavra de origem. O algoritmo faz uso de uma nova representação que dá uma nova perspectiva na decodificação de modelos baseados em frases.', 'ja': '一般的な場合のフレーズベースの翻訳モデルのデコードは、旅行中のセールスマンの問題からの削減によって、NP完全であることが知られている（ Knight、1999 ）。実際には、フレーズベースのシステムは、翻訳中のフレーズの動きを制限するハードディストーション制限を課すことが多い。しかしながら、このような制約を課した後の複雑性への影響についてはよく研究されていない。本稿では、固定された歪み限界を持つフレーズベースのデコードのための動的プログラミングアルゴリズムについて説明する。アルゴリズムの実行時間はO (nd! lhd +1)であり、ここで、nは文の長さであり、dは歪みの限界であり、lは文の任意の位置で開始するフレーズの数に対するバインドであり、hは、任意のソースワードのターゲット言語翻訳の最大数に関連している。このアルゴリズムは、フレーズベースのモデルのデコードに新しい視点を与える斬新な表現を利用する。', 'zh': '大抵短语译模解码已知NP全,减行推销员(Knight,1999)。 在实践中者,短语之统常加硬失真限,以限短语译之移也。 然强加约束,不甚复杂性究。 本文,我们述述了一种有定失真极限的基于短语解码的动态编程算法。 其行 O(nd!lhd+1),其 n 句长,d 为失真极限,l 从句中一位短语限,h 与一源词语译最大。 用一新文,为短语解码新视角。', 'hi': 'सामान्य मामले में वाक्यांश-आधारित अनुवाद मॉडल के डिकोडिंग को एनपी-पूर्ण होने के लिए जाना जाता है, यात्रा सेल्समैन समस्या (नाइट, 1999) से कमी से। व्यवहार में, वाक्यांश-आधारित प्रणालियां अक्सर एक कठिन विरूपण सीमा लागू करती हैं जो अनुवाद के दौरान वाक्यांशों के आंदोलन को सीमित करती हैं। हालांकि, इस तरह की बाधा को लागू करने के बाद जटिलता पर प्रभाव का अच्छी तरह से अध्ययन नहीं किया गया है। इस पेपर में, हम एक निश्चित विरूपण सीमा के साथ वाक्यांश-आधारित डिकोडिंग के लिए एक गतिशील प्रोग्रामिंग एल्गोरिथ्म का वर्णन करते हैं। एल्गोरिथ्म का रनटाइम O(nd!lhd+1) है जहां n वाक्य की लंबाई है, d विरूपण सीमा है, l वाक्य में किसी भी स्थिति से शुरू होने वाले वाक्यांशों की संख्या पर एक बाउंड है, और h किसी भी स्रोत शब्द के लिए लक्ष्य भाषा अनुवाद की अधिकतम संख्या से संबंधित है। एल्गोरिथ्म एक उपन्यास प्रतिनिधित्व का उपयोग करता है जो वाक्यांश-आधारित मॉडल के डिकोडिंग पर एक नया परिप्रेक्ष्य देता है।', 'ru': 'Декодирование моделей перевода на основе фраз в общем случае, как известно, является NP-полным, за счет сокращения от проблемы путешествующих продавцов (Knight, 1999). На практике фразеологические системы часто налагают жесткий предел искажения, который ограничивает движение фраз во время перевода. Однако влияние на сложность после введения такого ограничения недостаточно изучено. В данной работе мы описываем алгоритм динамического программирования для декодирования на основе фраз с фиксированным пределом искажения. Время выполнения алгоритма равно O(nd! lhd +1), где n - длина предложения, d - предел искажения, l - ограничение на количество фраз, начинающихся с любой позиции в предложении, и h - отношение к максимальному количеству переводов на целевой язык для любого исходного слова. Алгоритм использует новое представление, которое дает новый взгляд на декодирование фразеологических моделей.', 'ga': "Is eol go bhfuil díchódú samhlacha aistriúcháin frása-bhunaithe sa chás ginearálta iomlán NP, trí laghdú ar fhadhb an díoltóir taistil (Knight, 1999). Go praiticiúil, is minic a fhorchuireann córais frása-bhunaithe teorainn chrua saobhadh a chuireann srian le gluaiseacht frásaí le linn aistriúcháin. Mar sin féin, ní dhéantar staidéar maith ar an tionchar ar chastacht tar éis srian den sórt sin a fhorchur. Sa pháipéar seo, déanaimid cur síos ar algartam ríomhchláraithe dinimiciúil le haghaidh díchódaithe frása-bhunaithe le teorainn sheasta saobhadh. Is é O(nd!lhd+1) am rite an algartam áit arb é n fad na habairte, is é d an teorainn saobhadh, tá l ina cheangal ar líon na bhfrásaí a thosaíonn ag suíomh ar bith san abairt, agus tá baint ag h leis an líon uasta na n-aistriúchán sprioctheanga d'aon fhocal foinse. Úsáideann an algartam léiriú úrnua a thugann peirspictíocht nua ar dhíchódú samhlacha frása-bhunaithe.", 'ka': 'ფრაზების განსაზღვრების მოდელების დეკოდირება ყველაფერი შემთხვევაში უცნობიან NP-დასრულებულია, რომელიც გადასრულებული მოწყობილობის პრობლემა (Knight, 1999). პრაქტიკურად ფრაზების ბაზეული სისტემები ზოგიერთად დააყენებს ძალიან განმავლობა, რომელსაც ფრაზების მოძრაობის გადატყვებას შემდეგ. მაგრამ, შესაძლებლობა კომპლექსიტების შესაძლებლობა, როდესაც ასეთი შესაძლებლობა შეუძლებელია, არაფერი სწავლებელია. ჩვენ ამ კაურაში დინამიკური პროგრამის ალგორიტიმს გამოწერა ფრაზების ბაზეულ ევკოდირებას განსაზღვრებული განსხვავებების დრიმით. ალგორიტიმს გადაწყვეტილი დრო არის O(n d!lhd+1) სადაც n არის სიტყვების სიგრძე, d არის სიტყვების სიგრძე, l არის სიტყვების რაოდენობაში დაწყვეტილი სიტყვების რაოდენობაში, რომელიც სიტყვებში დაწყვეტილია, და h არის მაксимаლური სიგ ალგორიტიმის გამოყენება პრომენტის გამოსახულება, რომელიც ახალი პერსპექტიფიკაცია ფრაზების განსახულებული მოდელების ევკოდირებაზე.', 'hu': 'A kifejezésalapú fordítási modellek dekódolása általános esetben ismert, hogy NP-teljes, az utazó kereskedő problémájának csökkentésével (Knight, 1999). A gyakorlatban a kifejezésalapú rendszerek gyakran kemény torzítási korlátozást írnak elő, amely korlátozza a kifejezések fordítás közbeni mozgását. Az ilyen korlátozás előírása után azonban nem vizsgálták megfelelően a bonyolultságra gyakorolt hatást. Ebben a tanulmányban egy dinamikus programozási algoritmust írunk le a kifejezésalapú dekódoláshoz fix torzítási korláttal. Az algoritmus futási ideje O(nd!lhd+1), ahol n a mondat hossza, d a torzítási határ, l a mondat bármely pozíciójából induló kifejezések számára vonatkozik, és h kapcsolódik a forrásszó célnyelvi fordításainak maximális számához. Az algoritmus új ábrázolást alkalmaz, amely új perspektívát ad a kifejezésalapú modellek dekódolására.', 'el': 'Η αποκωδικοποίηση των μοντέλων μετάφρασης που βασίζονται σε φράσεις στη γενική περίπτωση είναι γνωστό ότι είναι NP-πλήρης, με μείωση από το πρόβλημα του ταξιδιωτικού πωλητή (Ιππότης, 1999). Στην πράξη, τα συστήματα με βάση τις φράσεις συχνά επιβάλλουν ένα σκληρό όριο παραμόρφωσης που περιορίζει την κίνηση των φράσεων κατά τη διάρκεια της μετάφρασης. Ωστόσο, ο αντίκτυπος στην πολυπλοκότητα μετά την επιβολή ενός τέτοιου περιορισμού δεν έχει μελετηθεί καλά. Στην παρούσα εργασία περιγράφουμε έναν αλγόριθμο δυναμικού προγραμματισμού για αποκωδικοποίηση με βάση φράσεις με σταθερό όριο παραμόρφωσης. Ο χρόνος εκτέλεσης του αλγόριθμου είναι Ο(nd!lhd+1) όπου n είναι το μήκος της πρότασης, δ είναι το όριο παραμόρφωσης, l είναι ένα δεσμό για τον αριθμό των φράσεων που ξεκινούν από οποιαδήποτε θέση της πρότασης, και η σχετίζεται με τον μέγιστο αριθμό μεταφράσεων της γλώσσας-στόχου για οποιαδήποτε λέξη προέλευσης. Ο αλγόριθμος χρησιμοποιεί μια νέα αναπαράσταση που δίνει μια νέα προοπτική στην αποκωδικοποίηση μοντέλων βασισμένων σε φράσεις.', 'kk': 'Сөздерді негіздеген аудармалар үлгілерін декодтамасыз жалпы жағдайда NP- толық деп белгіледі, саяхатты сатушылардың мәселесінен (Knight, 1999). Жұмыс істеу үшін, сөздерді негіздеген жүйелер аудару кезінде сөздерді жылжыту шегін шектеп береді. Бірақ бұл шектеуді орнатып тұрғаннан кейін, тәжірибеліктің әсері жақсы оқылмайды. Бұл қағаздың динамикалық бағдарламасының алгоритмін сөздерді негіздеген декодтау шегімен анықтаймыз. Алгоритмінің орындау уақыты: O( n d!lhd+1) бұл n- тің ұзындығы, d- тің бұрыштыру шегі, l - сөздің кез келген орында басталатын сөздер санына сәйкес, h- тің мақсатты тіл аудармаларының шегіне сәйкес келеді. Алгоритм сөз негіздеген үлгілерді декодтау үшін жаңа перспективті көрсетеді.', 'it': "La decodifica dei modelli di traduzione basati su frasi nel caso generale è nota per essere NP-completa, da una riduzione dal problema del venditore viaggiante (Knight, 1999). In pratica, i sistemi basati sulle frasi impongono spesso un limite di distorsione duro che limita il movimento delle frasi durante la traduzione. Tuttavia, l'impatto sulla complessità dopo l'imposizione di tale vincolo non è ben studiato. In questo articolo, descriviamo un algoritmo di programmazione dinamica per la decodifica basata su frasi con un limite di distorsione fisso. Il runtime dell'algoritmo è O(nd!lhd+1) dove n è la lunghezza della frase, d è il limite di distorsione, l è un vincolo sul numero di frasi che iniziano da qualsiasi posizione nella frase, e h è correlato al numero massimo di traduzioni della lingua di destinazione per qualsiasi parola sorgente. L'algoritmo fa uso di una rappresentazione inedita che dà una nuova prospettiva sulla decodifica dei modelli basati su frasi.", 'mk': 'Декодирањето на моделите за превод базирани на фрази во општиот случај е познато како NP-комплетно, со намалување од проблемот со патувачкиот продавач (Витез, 1999). Во практика, системите базирани на фрази честопати наметнуваат тешка граница на distorsion која го ограничува движењето на фразите за време на преводот. However, the impact on complexity after imposing such a constraint is not well studied.  Во овој весник, го опишуваме динамичкиот програмирачки алгоритм за декодирање базирано на фрази со фиксна граница на distorsion. Времето на извршувањето на алгоритмот е O( n d! lhd+1) каде n е должината на реченицата, d е границата на distorsion, l е врзан со бројот на фрази кои почнуваат од било која позиција во реченицата, и h е поврзан со максималниот број на преводи на јазикот на целта за било кој изворен збор. Алгоритмот користи нова претстава која дава нова перспектива за декодирање на моделите базирани на фрази.', 'lt': 'Žinoma, kad frazėmis pagrįstų vertimo modelių kodavimas paprastai yra visiškas NP, sumažinus kelionių pardavėjo problem ą (Knight, 1999). Praktikoje frazėmis grindžiamos sistemos dažnai nustato griežtą iškraipymo ribą, kuri riboja frazių judėjimą vertimo metu. Tačiau poveikis sudėtingumui po tokio apribojimo nėra gerai tiriamas. Šiame dokumente apibūdiname dinaminį programavimo algoritmą frazėmis grindžiamam dekodiavimui su fiksuota iškraipymo riba. Algoritmo veikimo laikas yra O(n d!lhd+1), kai n yra sakinio ilgis, d – iškraipymo riba, l – frazių, prasidedančių bet kurioje sakinio pozicijoje, skaičius, ir h yra susijęs su didžiausiu tikslinės kalbos vertimų skaičiu bet kuriam šaltinio žodžiui. Pagal algoritmą naudojamas naujas atstovavimas, kuriame pateikiama nauja perspektyva dėl frazėmis pagrįstų modelių dekodifikavimo.', 'ms': 'Pengekodan model terjemahan berdasarkan frasa dalam kes umum diketahui sebagai NP-complete, dengan pengurangan dari masalah penjual perjalanan (Knight, 1999). Dalam praktek, sistem berdasarkan frasa sering memaksa had penyelesaian keras yang mengatasi pergerakan frasa semasa terjemahan. Namun, kesan pada kompleksiti selepas memaksa keterangan seperti ini tidak dipelajari dengan baik. Dalam kertas ini, kami menggambarkan algoritma pemrograman dinamik untuk penyahkodan berdasarkan frasa dengan had penyelesaian tetap. Masa jalankan algoritma adalah O( n d!lhd+1) di mana n ialah panjang kalimat, d ialah had distorsi, l adalah terikat pada bilangan frasa yang bermula dari mana-mana kedudukan dalam kalimat, dan h berkaitan dengan bilangan maksimum terjemahan bahasa sasaran untuk mana-mana perkataan sumber. The algorithm makes use of a novel representation that gives a new perspective on decoding of phrase-based models.', 'ml': 'പൊതുവായ കേസിലെ വാക്കുകള്\u200d അടിസ്ഥാനമാക്കിയ വാക്കുകളുടെ മോഡലുകള്\u200d NP-പൂര്\u200dണ്ണമായി അറിയുന്നു. യാത്ര വില്\u200dക്കാരന്\u200d പ്രശ്നത്തില വാക്കുകള്\u200d അടിസ്ഥാനമാക്കിയ വാക്കുകള്\u200d പലപ്പോഴും പരിഭാഷക്ക് സമയത്ത് വാക്കുകളുടെ നീക്കം പരിധിയിലാക്കുന്ന കഠി എങ്കിലും ഇത്തരം നിര്\u200dബന്ധമാക്കിയതിനു ശേഷം സങ്കീര്\u200dത്ഥതയുടെ പ്രഭാവം നല്ല വായിച്ചിട്ടില്ല. ഈ പത്രത്തില്\u200d, നിര്\u200dണ്ണയിക്കപ്പെട്ട വാക്കുകളുടെ അടിസ്ഥാനത്തിലുള്ള വാക്കുകള്\u200dക്ക് നിര്\u200dണ്ണയിക്കപ്പെടുന്ന ഒരു ദുര ആല്\u200dഗോരിത്മിന്റെ ഓ(n d!lhd+1) വാക്കിന്റെ നീളം, d എന്നാണ് വിക്രമത്തിന്റെ അതിര്\u200d, വാക്കില്\u200d ആരെങ്കിലും സ്ഥാനത്ത് ആരംഭിക്കുന്ന വാക്കുകളില്\u200d ഞാന്\u200d ബന്ധിക്കപ്പെട്ടിരിക് ആല്\u200dഗോരിതം ഒരു നോവല്\u200d പ്രതിനിധിയെ ഉപയോഗിക്കുന്നു. വാക്കുകളുടെ അടിസ്ഥാനത്തിലുള്ള മോഡലുകള്\u200d കോഡിങ്ങ് ചെയ്യുന്', 'mn': 'Ерөнхий тохиолдолд хэлбэрээр суурилсан орчуулалтын загварын шийдвэрлэл нь NP бүтээгдэхүүнтэй гэдгийг мэддэг. Боловсролт дээр суурилсан системүүд ихэвчлэн хэцүү бэрхшээл хязгаарлаж өгүүлбэр хөдөлгөөнийг орчуулах үед хязгаарладаг. Гэвч ийм хязгаарлалтыг зогсоохын дараа цогц зүйлсийн нөлөө нь сайн судалгаагүй. Энэ цаасан дээр бид хэлбэрээр суурилсан шийдвэрлэлтийн динамик програмчлалын алгоритмыг тодорхойлдог. Алгоритмын ажиллах цаг нь O(n d!lhd+1) юм. n нь өгүүлбэрийн урт, d нь зайлсхийн хязгаар, l нь өгүүлбэрийн ямар ч байрлал дээр эхлэх өгүүлбэрийн тоо дээр холбогдсон, h нь ямар ч эх үүсвэрийн үгийн хамгийн гол зорилготой хэлний орчуулалтын тоо юм. Алгоритм нь өгүүлбэр суурилсан загваруудыг шинэ ойлголтыг ашигладаг.', 'mt': 'Id-dekodifikazzjoni tal-mudelli ta’ traduzzjoni bbażati fuq frażi fil-każ ġenerali hija magħrufa bħala NP-kompleta, bi tnaqqis mill-problem a tal-bejjiegħ li jivvjaġġa (Knight, 1999). Fil-prattika, is-sistemi bbażati fuq il-frażijiet ta’ spiss jimponu limitu ta’ distorsjoni iebsa li jillimita l-moviment tal-frażijiet matul it-traduzzjoni. Madankollu, l-impatt fuq il-kumplessità wara l-impożizzjoni ta’ tali restrizzjoni mhuwiex studjat tajjeb. F’dan id-dokument, niddeskrivu algoritmu dinamiku ta’ programmazzjoni għad-dekodifikazzjoni bbażata fuq frażi b’limitu fiss ta’ distorsjoni. Il-ħin ta’ tħaddim tal-algoritmu huwa O(n d!lhd+1) fejn n huwa t-tul tas-sentenza, d huwa l-limitu ta’ distorsjoni, l huwa marbut man-numru ta’ frażijiet li jibdew minn kwalunkwe pożizzjoni fis-sentenza, u h huwa relatat man-numru massimu ta’ traduzzjonijiet tal-lingwa fil-mira għal kwalunkwe kelma tas-sors. L-algoritmu jagħmel użu minn rappreżentazzjoni ġdida li tagħti perspettiva ġdida dwar id-dekodifikazzjoni ta’ mudelli bbażati fuq il-frażi.', 'no': 'Dekoding av frasebaserte omsetjingsmodular i det generelle tilfellet er kjent til å vera NP-fullført, ved å redusera frå det reisende salgsproblemet (Knight, 1999). I praksis brukar frasebaserte systemer ofte ein vanskeleg forstørringsgrense som begrenser flyttinga av frasar under oversettelse. Det er imidlertid ikkje veldig studiert effekten på kompleksitet etter at denne begrensningen skal brukast. I denne papiret beskriver vi ein dynamisk program- algoritme for frasebasert dekoding med ein fast forstørringsgrense. Køyringsdata på algoritmen er O( n d!lhd+1) der n er lengden, d er forstørringsgrensen, l er ein bind på talet på frasar som startar på alle plasseringar i setninga, og h er relatert til maksimum tal på målsprakkomsetjingar for kvar kjeldeord. Algoritmen gjer bruk av ein novel representasjon som gjev ei ny perspektiv på dekodering av frasebaserte modeller.', 'pl': 'Dekodowanie modeli tłumaczeń opartych na frazach w ogólnym przypadku jest znane jako NP-kompletne, poprzez redukcję od problemu sprzedawcy podróżującego (Knight, 1999). W praktyce systemy oparte na frazach często nakładają twardą granicę zniekształceń, która ogranicza ruch fraz podczas tłumaczenia. Jednakże wpływ na złożoność po nałożeniu takiego ograniczenia nie jest dobrze zbadany. W artykule opisano dynamiczny algorytm programowania dekodowania oparty na frazach ze stałą granicą zniekształceń. Czas działania algorytmu wynosi O(nd!lhd+1), gdzie n jest długością zdania, d jest granicą zniekształceń, l jest związany z liczbą zwrotów zaczynających się od dowolnej pozycji zdania, a h jest związany z maksymalną liczbą tłumaczeń języka docelowego dla dowolnego słowa źródłowego. Algorytm wykorzystuje nową reprezentację, która daje nową perspektywę dekodowania modeli opartych na frazach.', 'ro': 'Decodarea modelelor de traducere bazate pe fraze în cazul general este cunoscută a fi NP-complete, printr-o reducere de la problema vânzătorului de călătorie (Knight, 1999). În practică, sistemele bazate pe fraze impun adesea o limită de distorsiune puternică care limitează mișcarea frazelor în timpul traducerii. Cu toate acestea, impactul asupra complexității după impunerea unei astfel de constrângeri nu este bine studiat. În această lucrare, descriem un algoritm dinamic de programare pentru decodarea bazată pe fraze cu o limită fixă de distorsiune. Durata algoritmului este O(nd!lhd+1) unde n este lungimea propoziției, d este limita distorsiunii, l este o legătură cu numărul de fraze care încep din orice poziție din propoziție, iar h este legat de numărul maxim de traduceri în limba țintă pentru orice cuvânt sursă. Algoritmul utilizează o reprezentare nouă care oferă o nouă perspectivă asupra decodării modelelor bazate pe fraze.', 'so': 'Qiimeynta modelalka turjumaadda ee afka lagu saleeyay waxaa la yaqaan in uu yahay NP-dhamaan, waana in laga koobo dhibaatada iibiyaha safarka (Knight, 1999). Sida caadiga ah nidaamka ku saleysan waxay inta badan leeyihiin xad qalloocan oo aad u adag, kaas oo ku xadiya dhaqdhaqaaqa hadallada marka lagu turjumo. Si kastaba ha ahaatee saamaynta ku saabsan qallafsanaanshaha kadib in qasabkaas lagama baranayo si fiican. Qoraalkan waxaynu ku qoraynaa algorithm la qorayo oo dhaqdhaqaaq ah oo ku qoran xad qalloocan. Xiliga algorithiga waa O(n d!lhd+1) meesha n yahay dhererka hadalka, d waa xadka qalloocan, waxaan ku xidhan yahay tirada hadallada aan ka bilaabayo meel kasta oo uu ka bilaabo hadalka, waxaana l a xiriiraa tirada ugu badnaanta tarjumaadda luqada ee loogu talagalay hadal kasta oo aad u qoran. Algoritku wuxuu isticmaalaa muuqashada warqada ee ka soo jeeda aragti cusub oo ku saabsan codsiga muusikada ku qoran hadalka.', 'sv': 'Avkodning av frasbaserade översättningsmodeller i det allmänna fallet är känt för att vara NP-komplett, genom en minskning från resande försäljare problem (Knight, 1999). I praktiken innebär frasbaserade system ofta en svår förvrängningsgräns som begränsar frasernas rörelser under översättning. Effekterna på komplexiteten efter införandet av en sådan begränsning har dock inte studerats väl. I denna uppsats beskriver vi en dynamisk programmeringsalgoritm för frasbaserad avkodning med fast förvrängningsgräns. Algoritmens körtid är O(nd!lhd+1) där n är meningens längd, d är förvrängningsgränsen, l är bunden till antalet fraser som börjar från vilken position som helst i meningen, och h är relaterat till det maximala antalet målspråksöversättningar för varje källord. Algoritmen använder sig av en ny representation som ger ett nytt perspektiv på avkodning av frasbaserade modeller.', 'ta': 'பயணம் விற்பனை பிரச்சனையிலிருந்து ஒரு குறைவாக்கம் (Knight, 1999). மொழியில், சொற்றொடர் அடிப்படையான அமைப்புகள் மொழிபெயர்ப்பில் சொற்றொடர்களின் நகர்வை வரம்பு மாற்றும் போது கடினமா ஆனால், இத்தகைய கட்டுப்பாட்டை செயல்படுத்திய பிறகு சிக்கல் விளைவு நன்றாக படிக்கப்படவில்லை. இந்த காகிதத்தில், நாம் ஒரு இயங்கும் நிரல் முறைமையை வரையறுக்கிறோம் சொற்றொடர் அடிப்படையான குறியீட்டை நிலையான துரு The run time of the algorithm is O( n d!lhd+1) where n is the sentence length, d is the distortion limit, I is a bound on any position starting at any position in any position, and h is related to the maximum number of target language translations for any source word. The algorithm uses a novel representation which gives a new perspective on decoding of phrase- based models.', 'sr': 'Dekodiranje modela prevođenja na frazi u općem slučaju je poznato kao NP-kompletna, smanjenjem problem a sa putovanjem prodavača (Knight, 1999). U praksi, sistemi na frazi često nameću teške poremećaje koje ograničavaju kretanje fraza tokom prevođenja. Međutim, utjecaj na kompleksnost nakon nametanja takvih ograničenja nije dobro proučen. U ovom papiru opisujemo dinamični algoritam programiranja za dekodiranje na frazi sa fiksnim ograničenjem poremećaja. Izlazak algoritma je O(n d!lhd+1) gde n je dužin a rečenice, d je granica iskrivljanja, l je povezan na broj fraza koji počinju od bilo kojeg položaja rečenice, a h je povezan sa maksimalnim brojem prevoda jezika za bilo koju izvornu reč. Algoritam koristi novu predstavu koja daje novu perspektivu o dekodiranju modela na frazi.', 'si': 'සාමාන්\u200dය ප්\u200dරශ්නයක් අධාරිත වාර්තාවක් මොඩල් කිරීම් නිර්මාණය සම්පූර්ණයෙන් නිර්මාණය කරනවා NP-සම්පූර්ණයෙන්  පරීක්ෂණයෙන්, ප්\u200dරකාශ පද්ධතිය සාමාන්\u200dය වෙලාවෙන් අමාරු වෙනස් සීමාවක් සීමාවිත කරන්න, ඒකෙන් වාක්ෂ ඒත් ඒ වගේම, ඒ වගේම අවධානයක් තියාගන්න පස්සේ, සංශ්\u200dයතාවට ප්\u200dරතිකාරයක් හොඳ විදිහට අධ මේ පැත්තට, අපි වාර්තාවික ප්\u200dරවෘත්තිකරණය ඇල්ගෝරිතම් විස්තර කරනවා ප්\u200dරවෘත්තික වාර්තාවික විස්තර කරන ඇල්ගෝරිතම්ගේ කාලය O(n d!lhd+1) කියලා, n වාක්ය ලොකුව, d වාක්ය සීමාව, l වාක්යේ කිසිම ස්ථානයෙන් පටන් ගන්න ප්\u200dරශ්නයක් සංඛානයේ සම්බන්ධ වෙනවා, h වාක ඇල්ගෝරිත්මය ප්\u200dරයෝජනය කරනවා නියම ප්\u200dරයෝජනය සඳහා අලුත් ප්\u200dරයෝජනයක් පාවිච්චි කරන්න පුළුවන්', 'ur': 'فریز بنیادی ترجمہ موڈل کا ڈیکوڈینگ عمومی کیس میں NP-کامل ہے، سفر کرنے والوں کے مسئلہ سے کمی کے ذریعہ سے (نایت، 1999) معلوم ہوتا ہے۔ آزمائش میں، فرشتوں کی بنیادی سیستموں کو اغلب ایک سخت غلط حد مقرر کرتا ہے جو فرشتوں کی حرکت کو ترجمہ کے وقت محدود کرتا ہے. However, the impact on complexity after imposing such a constraint is not well studied. اس کاغذ میں، ہم ایک سیدھی پروگرامینگ الگوریتم کو فریز پر بنیاد رکھا ہوا ڈیکوڈینگ کے لئے ایک ثابت غلط حد سے توصیف کرتے ہیں. الگوریٹم کا چلنے کا وقت O(n d!lhd+1) ہے جہاں n ویدئ کی لمبی ہے، d وہ غلط محدودیت ہے، l ویدئ میں ہر جگہ موقعیت سے شروع ہونے والی فرشتوں کی تعداد پر بینڈ ہے، اور h ہر سراسر ویدئ کے لئے موقعیت زبان کی مزید تعداد کا ارتباط ہے. الگوریتم ایک نوی نمونہ کا استعمال کرتا ہے جو فریز بنیاد دار نمونڈل کا ڈیکوڈ کرنا ہے۔', 'uz': "Name Shunday qilib, so'zlar asosiy tizimlari tarjima paytidagi so'zlarning harakatini chegara qiladi. Lekin, buni qanday qanday qanday qanday qanday o'qishdan keyin murakkablikga harakat qiladi. Bu qogʻozda biz bir tomonidan qo'shish chegarasini o'rganamiz. @ info The algorithm makes use of a novel representation that gives a new perspective on decoding of phrase-based models.", 'vi': 'Giải mã các mô hình dịch từ điển thành ngữ trong trường hợp chung được biết là hoàn thiện NP, bằng một sự giảm khỏi vấn đề bán hàng rong (Knight, 99). Trong thực tế, các hệ thống từ điển thường áp đặt một giới hạn sự bóp méo cứng, hạn chế việc chuyển động các đoạn văn trong thời gian dịch. Tuy nhiên, tác động lên tính phức tạp sau khi áp dụng điều kiện đó không được nghiên cứu kỹ lưỡng. Trong tờ giấy này, chúng tôi mô tả một thuật toán lập động cho việc giải mã cụm từ với một giới hạn sự bóp méo cố định. The runtime of the Thuật to án is O(n d!l h+1) where n is the tuna length, d is the distortation giới h ạn, l is a bound to the number of letters starting at any position in the tunion, and h is relative to the most of the dest language translations for any source word. Thuật toán sử dụng một đại diện mới cho một quan điểm mới về việc giải mã các mô hình dựa trên cụm từ.', 'da': 'Afkodning af sætningsbaserede oversættelsesmodeller i det almindelige tilfælde er kendt for at være NP-komplet, ved en reduktion fra rejsende sælger problem (Knight, 1999). I praksis pålægger sætningsbaserede systemer ofte en hård forvrængningsgrænse, der begrænser bevægelsen af sætninger under oversættelse. Virkningen på kompleksiteten efter at have indført en sådan begrænsning er imidlertid ikke godt undersøgt. I denne artikel beskriver vi en dynamisk programmeringsalgoritme til sætningsbaseret afkodning med en fast forvrængningsgrænse. Algoritmens kørselstid er O(nd!lhd+1), hvor n er sætningens længde, d er forvrængningsgrænsen, l er bundet af antallet af sætninger, der starter fra en hvilken som helst position i sætningen, og h er relateret til det maksimale antal målsprogsoversættelser for ethvert kildeord. Algoritmen gør brug af en ny repræsentation, der giver et nyt perspektiv på afkodning af sætningsbaserede modeller.', 'de': 'Die Dekodierung phrasenbasierter Übersetzungsmodelle ist im allgemeinen Fall als NP-vollständig bekannt, durch eine Reduzierung des reisenden Verkäuferproblems (Knight, 1999). In der Praxis setzen phrasenbasierte Systeme oft eine harte Verzerrungsgrenze ein, die die Bewegung von Phrasen während der Übersetzung begrenzt. Die Auswirkungen auf die Komplexität nach einer solchen Beschränkung sind jedoch nicht gut untersucht. In diesem Beitrag beschreiben wir einen dynamischen Programmieralgorithmus zur phrasenbasierten Dekodierung mit fester Verzerrungsgrenze. Die Laufzeit des Algorithmus ist O(nd!lhd+1), wobei n die Satzlänge ist, d die Verzerrungsgrenze, l ist eine Bindung an die Anzahl der Sätze, die an einer beliebigen Position im Satz beginnen, und h steht für die maximale Anzahl der Übersetzungen in der Zielsprache für jedes Quellwort. Der Algorithmus nutzt eine neuartige Darstellung, die eine neue Perspektive auf die Dekodierung phrasenbasierter Modelle eröffnet.', 'nl': 'Het decoderen van zinnengebaseerde vertaalmodellen in het algemeen staat bekend NP-compleet te zijn, door een vermindering van het reizende verkopersprobleem (Knight, 1999). In de praktijk leggen zinnengebaseerde systemen vaak een harde vervormingslimiet op die de beweging van zinnen tijdens de vertaling beperkt. De impact op complexiteit na het opleggen van een dergelijke beperking is echter niet goed bestudeerd. In dit artikel beschrijven we een dynamisch programmeeralgoritme voor frase-based decodering met een vaste vervormingslimiet. De looptijd van het algoritme is O(nd!lhd+1) waarbij n de lengte van de zin is, d de vervormingslimiet, l is een gebonden aan het aantal zinnen dat vanaf elke positie in de zin begint, en h is gerelateerd aan het maximale aantal vertalingen in de doeltaal voor elk bronwoord. Het algoritme maakt gebruik van een nieuwe representatie die een nieuw perspectief geeft op decodering van frase-based modellen.', 'bg': 'Декодирането на фразово базирани модели за превод в общия случай е известно като NP-завършено, чрез намаляване на проблема с пътуващия търговец (Найт, 1999). На практика, базираните на фрази системи често налагат твърда граница на изкривяване, която ограничава движението на фразите по време на превода. Въздействието върху сложността след налагането на такова ограничение обаче не е добре проучено. В тази статия описваме динамичен алгоритъм за програмиране на фраза-базирано декодиране с фиксирана граница на изкривяване. Времето на изпълнение на алгоритъма е O(nd!lhd+1), където n е дължината на изречението, d е границата на изкривяване, l е обвързана с броя фрази, започващи от всяка позиция в изречението, и h е свързана с максималния брой преводи на целевия език за всяка изходна дума. Алгоритъмът използва ново представяне, което дава нова перспектива за декодиране на фразови модели.', 'hr': 'Dekodiranje modela prevođenja na frazi u općem slučaju poznato je da je NP-kompletna, smanjenjem problem a s putovanjem prodavača (Knight, 1999). U praksi, sustavi temeljeni na frazi često nameću teške poremećaje ograničavajući kretanje fraza tijekom prevoda. Međutim, utjecaj na kompleksnost nakon nametanja takve ograničenja nije dobro ispitivan. U ovom papiru opisujemo dinamični programirani algoritam za dekodiranje na frazi sa fiksnim ograničenjem poremećaja. Prolazak algoritma je O(n d!lhd+1) gdje n je dužin a rečenica, d je granica iskrivljanja, l je povezan na broj rečenica počevši od bilo kojeg položaja rečenice, a h je povezan s maksimalnim brojem prevoda ciljnog jezika za bilo koju izvornu riječ. Algoritam koristi novu predstavu koja daje novu perspektivu o dekodiranju modela na frazi.', 'id': 'Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the travelling salesman problem (Knight, 1999). Dalam praktek, sistem berdasarkan frasa sering memaksa batas distorsi keras yang membatasi pergerakan frasa selama terjemahan. Namun, dampak pada kompleksitas setelah memaksa keterangan seperti ini tidak dipelajari dengan baik. Dalam kertas ini, kami menggambarkan algoritma pemrograman dinamik untuk dekodasi berdasarkan frasa dengan batas distorsi fiks. Waktu jalankan algoritma adalah O( n d!lhd+1) di mana n adalah panjang kalimat, d adalah batas distorsi, l adalah terikat pada jumlah kalimat yang dimulai dari posisi apapun dalam kalimat, dan h berhubungan dengan jumlah maksimum terjemahan bahasa sasaran untuk kata sumber apapun. Algoritma menggunakan representation novel yang memberikan perspektif baru untuk dekodifikasi model berdasarkan frasa.', 'ko': '일반적인 상황에서 여행사 문제(Knight, 1999)의 간소화를 통해 짧은 단어를 바탕으로 하는 번역 모델의 디코딩은 NP가 완전하다.실천에서 단어를 바탕으로 하는 시스템은 일반적으로 경실진 제한을 가하여 단어가 번역 과정에서 이동하는 것을 제한한다.그러나 이런 제약을 가한 후 복잡성에 대한 영향은 아직 잘 연구되지 않았다.본고에서 우리는 고정적인 오류 제한을 가진 짧은 언어 디코딩을 바탕으로 하는 동적 기획 알고리즘을 묘사했다.이 알고리즘의 운행 시간은 O(nd!lhd+1)이다. 그 중에서 n은 문장의 길이이고 d는 진실성 한계이다. l은 문장의 어느 위치에서 시작하는 단어의 수량의 경계이며 h는 그 어떠한 원시 단어의 최대 목표 언어 번역 수량과 관련이 있다.이 알고리즘은 새로운 표현 방법을 이용하여 짧은 말의 모델을 바탕으로 하는 디코딩에 새로운 시각을 제공했다.', 'fa': 'رمزبندی مدل\u200cهای ترجمه بر اساس عبارت در پرونده عمومی به عنوان NP کامل می\u200cشود، با کاهش از مشکل فروشنده سفر (Knight, 1999). در تمرین، سیستم\u200cهای بنیاد عبارت اغلب محدودیت تغییر سخت را می\u200cگذارند که در طول ترجمه حرکت جمله\u200cها را محدودیت می\u200cکند. با این حال، تاثیر بر پیچیدگی بعد از اینکه این محدودیت را بذاریم، خوب مطالعه نمی شود. در این کاغذ، ما یک الگوریتم برنامه\u200cریزی دینامیک را برای دکوندن بر اساس عبارت با محدودیت تغییر ثابت توصیف می\u200cکنیم. زمان اجرای الگوریتم O(n d!lhd+1) است که n طول جمله است، d محدود شکستگی است، l بر تعداد جمله\u200cها که از هر موقعیت در جمله شروع می\u200cشود به تعداد جمله است، و h ارتباط دارد با تعداد بزرگترین ترجمه\u200cهای زبان هدف برای هر کلمه منبع. الگوریتم از نمایش رمانی استفاده می کند که یک نگاه جدید در مورد دکوندن مدل\u200cهای بنیاد عبارت می\u200cدهد.', 'sw': 'Kupungua mifano ya tafsiri yenye msingi wa maneno katika kesi ya ujumla inajulikana kuwa NP-kamili, kwa kupungua kwa tatizo la kibuzi wa safari (Knight, 1999). Katika mazoea, mifumo yenye msingi wa maneno mara nyingi huweka vizuizi vigumu vya uchochezi unaoharibu harakati za maneno wakati wa tafsiri. Hata hivyo, madhara ya utata baada ya kulazimisha aina hiyo haitafitiwa vizuri. Katika gazeti hili, tunaelezea algorithi ya programu za kisasa kwa ajili ya kupunguza kwa maneno yenye msingi na kiwango kikubwa cha uchochezi. Wakati wa utaalgorithi ni O(n d!lhd+1) ambapo n ni kiwango cha hukumu, d ni ukomo wa uchochezi, ninafungwa n a idadi ya maneno yanayoanza kwenye nafasi yoyote katika hukumu hiyo, na h inahusiana na idadi kubwa ya tafsiri za lugha za lengo kwa neno lolote. Ualgorithi huo unatumia uwakilishi wa riwaya ambao unatoa mtazamo mpya wa kupunguza mifano inayotumika na maneno.', 'sq': 'Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the travelling salesman problem (Knight, 1999). Në praktikë, sistemet bazuar në fraza shpesh imponojnë një kufi të ashpër distorsioni që kufizon lëvizjen e frazave gjatë përkthimit. Megjithatë, ndikimi në kompleksitet pas vënien e një kufizimi të tillë nuk është studiuar mirë. Në këtë letër, ne përshkruajmë një algoritëm dinamik programimi për dekodimin bazuar në fraza me një limit të fiksuar distorcimi. Koha e zbatimit e algoritmit është O(n d!lhd+1) ku n është gjatësia e fjalës, d është kufiri i shtrembërimit, l është i lidhur me numrin e frazave që fillojnë nga çdo pozicion n ë fjalë, dhe h është i lidhur me numrin maksimum të përkthimeve të gjuhës objektive për çdo fjalë burimi. Algoritmi përdor një përfaqësim të ri që jep një perspektivë të re mbi dekodimin e modeleve bazuar në fraza.', 'tr': 'Fraz tabanly terjime nusgalarynyň ködlemesi umumy ýagdaýda NP-kompletler bolup bilinýär, syýahat eden satyn kynçylygyndan azalyp biler (Knight, 1999). Praktika görä, fraz sistemleri köplenç terjime eden wagtynda fraz hereketini çykarýar. Ýöne bu ýagdaýy çykarmak üçin karmaşıklyga täsiri gowy öwrenmedi. Bu kagyzda, fraz tabanly bir ködleme üçin dinamik programlama algoritmini sabitlendirdik. O(n d!lhd+1) sözlem ululykynda, d sözlemde başlayan sözlemleriň sanynda baglanýar, l sözlemde başarmaýa n sözlemleriň iň kop sanynda baglanýar we h isleýän çeşmeň sözleriň iň kop sanynda baglanýar. Algoritm fraz tabanly nusgalarynyň kodlemesi barada täze perspektiva üýtgedýär.', 'az': 'Səfərə tabanlı tercümə modellerinin kodlaması genel məsələdə NP tamamlandığı kimi, səyahət edən satıcının problemindən azaldığı tərzdə (Knight, 1999). Praksiyada, sözlərin sistemləri çox sıxıntıla çevirilmək sırasında sözlərin hərəkətini sınırlayır. Ancaq bu müddəti təyin etdikdən sonra kompleksitə təsiri yaxşı təhsil edilməz. Bu kağızda, fərz tabanlı kodlama üçün dinamik programlama algoritmini sabit çətinliklə tanımlıyıq. Algoritimin ça l ışma vaxtı O(n d!lhd+1) deyildir ki, n cümlən in uzunluğudur, d cümlənin fərqlənməsi limitidir, l cümlənin h ər hansı bir məqamın d a başlayan cümlələrin sayısına bağlanmışd ır, h hər cümlənin mənbəzi sözlərin ən böyük məqsəd dilin çevirilənlərin sayısına bağlanmışdır. Algoritimin yeni bir göstəricisi istifadə edir ki, fraz tabanlı modellərin kodlaması haqqında yeni bir perspektiv verir.', 'hy': 'Գլխավոր դեպքում հայտնի է, որ արտահայտությամբ հիմնված թարգմանման մոդելների կոդավորումը լիարժեք է, ճամփորդող վաճառողների խնդիրներից նվազեցման միջոցով (KnKnKnKnut, 1999). Իրականում, արտահայտությամբ հիմնված համակարգերը հաճախ պարտադրում են բարդ շեղումների սահմանափակում, որը սահմանափակում է արտահայտությունների շարժումը թարգմանման ժամանակ: Այնուամենայնիվ, այս սահմանափակումներից հետո բարդության վրա ազդեցությունը լավ չի ուսումնասիրում: Այս թղթի մեջ մենք նկարագրում ենք դինամիկ ծրագրավորումների ալգորիթմ արտահայտությամբ հիմնված կոդավորման համար ֆիքսված շեղումների սահմաններով: The runtime of the algorithm is O(nd!lhd+1) where n is the sentence length, d is the distortion limit, l is a bound on the number of phrases starting at any position in the sentence, and h is related to the maximum number of target language translations for any source word.  Ալգորիթմը օգտագործում է նոր ներկայացում, որը նոր տեսանկյուն է տալիս արտահայտությամբ հիմնված մոդելների կոդավորման մասին:', 'bs': 'Dekodiranje modela prevoda baziranih na frazi u općem slučaju je poznato kao NP-kompletna, smanjenjem problem a sa putovanjem prodavača (Knight, 1999). U praksi, sustavi na frazi često nameću teške poremećaje koje ograničavaju kretanje fraza tijekom prevođenja. Međutim, utjecaj na kompleksnost nakon nametanja takvih ograničenja nije dobro proučen. U ovom papiru opisujemo dinamični algoritam programiranja za dekodiranje na frazi sa fiksnim ograničenjem poremećaja. Izlazak algoritma je O(n d!lhd+1) gdje n je dužin a rečenica, d je granica iskrivljanja, l je povezan na broj fraza koji počinju od bilo kojeg položaja rečenice, a h je povezan sa maksimalnim brojem prevoda ciljnog jezika za bilo koju izvornu riječ. Algoritam koristi novu predstavu koja daje novu perspektivu o dekodiranju modela na frazi.', 'af': "Dekodering van frase-gebaseerde vertalingsmodele in die algemene geval is bekend as NP-volledige, deur 'n verduur van die reisende verkoopsman probleme (Knight, 1999). In praksie, frase-gebaseerde stelsels het dikwels 'n moeilike versterking beperk wat beperk die beweging van frase tydens vertaling. Maar die invloek op kompleksiteit, nadat sodanige 'n beperking ingestel word, is nie goed ondersoek nie. In hierdie papier beskryf ons 'n dinamiese program algoritme vir frase-gebaseerde dekodering met 'n vaste distortering beperk. Die looptyd van die algoritme is O( n!l h d+1) waar n is die setlengte, d is die uitbreiding beperk, l is 'n gebind op die nommer van frase wat begin by enige posisie in die setnings, en h is verwanter tot die maksimum nommer van doel taal vertalings vir enige bron woord. Die algoritme maak gebruik van 'n roman voorstelling wat gee 'n nuwe perspektief op dekodering van frase-gebaseerde modele.", 'cs': 'Kódování frázových překladových modelů je v obecném případě známo jako NP-kompletní, snížením problému cestujícího obchodníka (Knight, 1999). V praxi systémy založené na frázích často ukládají tvrdý limit zkreslení, který omezuje pohyb frází během překladu. Avšak dopad na složitost po uložení takového omezení není dobře studován. V tomto článku popisujeme dynamický programovací algoritmus pro frázové dekódování s pevným limitem zkreslení. Běh algoritmu je O(nd!lhd+1), kde n je délka věty, d je limit zkreslení, l je vázán na počet frází začínajících na libovolném místě ve větě a h je vztahován k maximálnímu počtu překladů cílového jazyka pro libovolné zdrojové slovo. Algoritmus využívá nové reprezentace, která poskytuje nový pohled na dekódování frázových modelů.', 'am': 'የንግግር-based ትርጉም ዓይነቶች በጠቅላላ ጉዳይ NP-ፍጹም ሆኖ የሚታወቁ የንግግር መተርጓም ሞዴላዎች ከጉዞው መከራ (Knight, 1999). In practice, phrase-based systems often impose a hard distortion limit that limits the movement of phrases during translation.  ነገር ግን የዚህን ግንኙነት አስፈላጊ ከተደረገ በኋላ ጥቃት መልካም አልተማረም፡፡ In this paper, we describe a dynamic programming algorithm for phrase-based decoding with a fixed distortion limit.  የአልgorithም ጊዜ የ (n d!lhd+1) ቁጥጥር ርዝመት ነው, d - የአሳማሚ ግንኙነት ነው፤ እኔ ከክፍሉ በተጀመረ ስፍራ በሚጀመር በአስማማሪ ቁጥር ላይ የታሰረ ነኝ፤ h ለክፍል ቋንቋ ትርጉም በሚያበዛው ቁጥር ነው፡፡ አሌጎርቲም አዲስ የንግግር ቃላት መክፈት በሚያሳድገው አዲስ ዓይነት ነው፡፡', 'et': 'Fraasipõhiste tõlkemudelite dekodeerimine on teadaolevalt NP-täielik, vähendades reisiva müügimehe probleemi (Knight, 1999). Praktikas kehtestavad fraasipõhised süsteemid sageli range moonutuspiirangu, mis piirab fraaside liikumist tõlkimise ajal. Mõju keerukusele pärast sellise piirangu kehtestamist ei ole siiski hästi uuritud. Käesolevas töös kirjeldame dünaamilist programmeerimisalgoritmi fraasipõhiseks dekodeerimiseks fikseeritud moonutuste piirmääraga. Algoritmi käivitusaeg on O(nd!lhd+1), kus n on lause pikkus, d on moonutuse piir, l on piiratud lause mis tahes asendist algavate lausete arvule ja h on seotud sihtkeele tõlkete maksimaalse arvuga iga lähtesõna puhul. Algoritm kasutab uudset esitust, mis annab uue perspektiivi fraasipõhiste mudelite dekodeerimisele.', 'ca': "Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the traveling salesman problem (Knight, 1999).  In practice, phrase-based systems often impose a hard distortion limit that limits the movement of phrases during translation.  However, the impact on complexity after imposing such a constraint is not well studied.  En aquest article, descrivim un algoritme de programació dinàmica per a la decodificació basada en frases amb un límit fixe de distorsió. El temps d'execució del algoritme és O(nd!lhd+1) on n és l a llargada de la frase, d és el l ímit de distorsió, l és un límit del nombre de frases que comencen en qualsevol lloc de la frase, i h està relacionat amb el nombre máxim de traduccions de llenguatge alvo per qualsevol paraula d'origen. L'algoritme utilitza una nova representació que dóna una nova perspectiva de decodificació de models basats en frases.", 'bn': 'সাধারণ ক্ষেত্রে ভিত্তিক ভিত্তিক অনুবাদ মডেল নির্ধারণ করা হচ্ছে এনপি-সম্পূর্ণ, যাত্রা বিক্রিয়ার সমস্যা থেকে কমে যাওয়া হয়েছে (ক In practice, phrase-based systems often impose a hard distortion limit that limits the movement of phrases during translation.  However, the impact on complexity after imposing such a constraint is not well studied.  এই কাগজটিতে আমরা একটি ডাইনামিক প্রোগ্রামিং অ্যালগরিদমের বর্ণনা করছি বাক্যের ভিত্তিক কোডিং এর জন্য একটি সুনির্দিষ্ট বিভ্ অ্যালগরিদমের চালানোর সময় হচ্ছে O( n d!lhd+1) যেখানে n বাক্যের দীর্ঘ, d হচ্ছে বিভ্রান্ত সীমা, আমি বাক্যের যে কোনো অবস্থান থেকে শুরু করা শব্দের সংখ্যায় বাধ্যতামূলক বাক্যের স অ্যালগরিদম একটি উপন্যাসের প্রতিনিধিত্ব ব্যবহার করে যা বাক্য ভিত্তিক মডেলের কোডিং নিয়ে নতুন দৃষ্টিভঙ্গি দেয়।', 'fi': 'Lauseeseen perustuvien käännösmallien dekoodauksen tiedetään yleisesti olevan NP-täydellinen, koska matkamyyjän ongelma vähenee (Knight, 1999). Käytännössä lauseisiin perustuvat järjestelmät asettavat usein kovan vääristymisrajan, joka rajoittaa lauseiden liikkumista käännöksen aikana. Vaikutusta monimutkaisuuteen tällaisen rajoituksen asettamisen jälkeen ei kuitenkaan ole tutkittu hyvin. Tässä työssä kuvaamme dynaamista ohjelmointialgoritmia fraasipohjaiseen dekoodaamiseen kiinteällä särörajajalla. Algoritmin suoritusaika on O(nd!lhd+1), jossa n on lauseen pituus, d on vääristymisraja, l on sidottu lauseen mistä tahansa kohdasta alkavien lauseiden lukumäärään ja h liittyy minkä tahansa lähdesanan kohdekielikäännösten enimmäismäärään. Algoritmi hyödyntää uutta esitystä, joka antaa uuden näkökulman fraasipohjaisten mallien dekoodaamiseen.', 'sk': 'Dekodiranje fraznih prevajalskih modelov v splošnem primeru je znano kot NP-popolno, z zmanjšanjem problema potujočega prodajalca (Knight, 1999). V praksi sistemi, ki temeljijo na frazah, pogosto nalagajo omejitev trdega popačenja, ki omejuje gibanje fraz med prevajanjem. Vendar pa učinek na kompleksnost po uvedbi take omejitve ni dobro proučen. V prispevku opisujemo dinamični programski algoritem za frazno dekodiranje s fiksno mejo popačenja. Čas delovanja algoritma je O(nd!lhd+1), kjer je n dolžina stavka, d je meja popačenja, l je omejena na število stavkov, ki se začnejo na katerem koli mestu stavka, h pa je povezan z največjim številom prevodov ciljnega jezika za katero koli izvorno besedo. Algoritem uporablja novo predstavitev, ki daje novo perspektivo za dekodiranje modelov, ki temeljijo na frazah.', 'ha': "Kunna kodi da misãlai masu fassarar-da-rubutu cikin babban a jumla, ana gane shi NP-cika, da wani ƙara daga matabbaci na salafin mai tafiyar (Kdare, 1999). Kuma a cikin aikin haka, na'urar-da-rubutu ko da yawa, yana ƙudura mai ƙẽtare gaurawa mai tsanani wanda ke ƙudura kowacin tafiyar da magana a lokacin fassarar. Haƙĩƙa, musamman kan adadin a bayan an lazimta wannan, ba a karanta mai kyau ba. Ga wannan takardan, Munã bayyana algoritm na shiryoyin ayuka da aka ƙayyade wa kodi da tsari mai daidaita ga magana. Lokacin d a aka yi tafiyar algoritm na O(n d!l h+1) inda n ke da ƙayyade maganar ƙẽtare, d na da ƙayyade yawan magana wanda za'a fara wani wuri da ke cikin hukuman, kuma h na da amfani da yawan fassaran lugha masu amfani da wa maganar wani source. Algoritm na amfani da wani mai wakilishi na nowaya wanda ke bãyar da wani mtazamo na daban a kan koda-kodi na misãlai-da-salon maganar.", 'bo': 'Decoding of phrase-based translation models in the general case is known to be NP-complete, by a reduction from the traveling salesman problem (Knight, 1999). ལག་སྟར་ལྟར། ཚིག་ཕུང་གཞི་ཡོད་པའི་མ་ལག་གིས་རྒྱུན་ལྡན་ངེས་པར་དབང་བའི་ཚད་གཞི་སྒྲིག འོན་ཀྱང་། དཀའ་ངལ་ཆེན་པོ་ཞིག་བཀག་རྩོལ་ནུས་ནས་གནོད་ངལ་གཏོང་མེད། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རང་ཉིད་ཀྱི་ལས་རིམ་སྒྲིག་གི་སྒྲ་ཚིགས་ཀྱི་མཐའ་འཁོར་ལ་སྤྱོད་ཀྱི་ཡིག་རྟགས The runtime of the algorithm is O(n d!lhd+1) where n is the sentence length, d is the distortion limit, l is a bound on the number of phrases starting at any position in the sentence, and h is related to the maximum number of target language translations for any source word. ས Algorithm་འདི་ལྟ་བུའི་གསར་བ་ཞིག་གིས་མཐུན་སྣང་གསར་བ་ཞིག་བེད་སྤྱོད་ཀྱི་ཡོད་པ་དེ་ཡིན་ཀྱང་།', 'he': 'הקוד של דוגמני תרגום מבוססים על ביטויים במקרה כללי ידוע להיות NP-מושלם, על ידי הפחות מהבעיה של מכר הנסיעה (Knight, 1999). למעשה, מערכות מבוססות על ביטויים לעתים קרובות מכרישות מגבלת עיווה קשה שמגבלת את תנועת ביטויים במהלך התרגום. בכל אופן, ההשפעה על מורכבות לאחר הכניסה מחסום כזה לא נחקרת היטב. בעיתון הזה, אנחנו מתארים אלגוריתם תוכנית דינמית לפיתוח מבוסס על ביטויים עם גבול התעצבות קבוע. הזמן המבצע של האלגוריתם הוא O( n d!lhd+1) שבו n הוא אורך המשפט, d הוא הגבול ההתעצבות, l הוא קובע על מספר המשפטים שמתחילים בכל עמדה במשפט, ו h קשור למספר המקסימלי של תרגומות שפת המטרה לכל מילה מקורית. האלגוריתם משתמש ביציגה חדשה שמעניקה פרספקטיבה חדשה על פיקוד של דוגמנים מבוססים על ביטויים.', 'jv': 'Ngawe politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertivepoliteness Nang pemilih iki, kita sambarang kelompok \'dynamics-program-Algorithm\' kanggo nguasar kelompok nggawe barang nggawe barang nggawe AllProgressBar Algorithm ngewehi sistem anyar ngubah dhéwé éntuk perpekpektuan anyar tentang karo decoding model sing basa na seneng pisan.'}
{'en': 'A Generative Model of Phonotactics', 'ar': 'نموذج توليدي من الأصوات', 'es': 'Un modelo generativo de fonotáctica', 'pt': 'Um modelo generativo de fonotática', 'fr': 'Un modèle génératif de phonotactique', 'ja': 'フォノタクティクスの生成モデル', 'zh': '语音成模样', 'hi': 'फोनोटैक्टिक्स का एक उत्पादक मॉडल', 'ru': 'Генеративная модель фонотаксики', 'ga': 'Samhail Ghinideach de Phonotactics', 'ka': 'Name', 'el': 'Ένα γενειακό μοντέλο φωνοτακτικής', 'hu': 'A fonotaktika generációs modellje', 'it': 'Un modello generativo di fonotattica', 'kk': 'Phonotactics үлгісін құру үлгісіName', 'lt': 'Phonotaktikos generacinis modelis', 'mk': 'Генеративен модел на фонотактика', 'ml': 'ഫോണോട്ടാക്ടിക്സിക്സിന്റെ ജനററിവ് മോഡല്\u200dName', 'ms': 'Name', 'mt': 'Mudell Ġenerattiv ta’ Phonotactics', 'mn': 'Фонотактикийн бүтээлч загвар', 'no': 'Name', 'pl': 'Generatywny model fonotaktyki', 'ro': 'Un model generativ de fonotactică', 'sr': 'Generativni model fonotaktike', 'si': 'Name', 'so': 'Model of Phonotactics', 'ta': 'Name', 'sv': 'En generativ modell för fonotaktik', 'ur': 'Name', 'uz': 'Name', 'vi': 'Mô hình máy phát của Phong vật', 'hr': 'Generativni model fonotaktike', 'bg': 'Генеративен модел на фонотактика', 'da': 'En genererende model for fonotaktik', 'nl': 'Een generatief model van fonotactica', 'fa': 'Name', 'de': 'Ein generatives Modell der Phonotaktik', 'id': 'A Generative Model of Phonotactics', 'ko': '음성 정책의 생성 모델', 'sw': 'Modeli ya Kizalendo ya Picnotactics', 'tr': 'Fotoktikiň döredik nusgasy', 'sq': 'A Generative Model of Phonotactics', 'am': 'አዲስ ዶሴ ፍጠር', 'af': 'Name', 'hy': 'A Generative Model of Phonotactics', 'az': 'Phonotaktik Ünvan Modeli', 'bs': 'Generativni model fonotaktike', 'bn': 'Name', 'ca': 'Un model generador de fonotactica', 'et': 'Fonotaktika generatiivmudel', 'fi': 'Fonotaktiikan generatiivinen malli', 'cs': 'Generativní model fonotaktiky', 'sk': 'Generativni model fonotaktike', 'jv': 'Name', 'he': 'מודל גנרטיבי של פונוטקטיקה', 'ha': 'KCharselect unicode block name', 'bo': 'སྒྲ་བརྙན་རིས་ཀྱི་བཟོ་བརྗོད་མ་དཔེ་གཞུང་ཞིག་ཡིན།'}
{'en': 'We present a probabilistic model of phonotactics, the set of well-formed phoneme sequences in a language. Unlike most computational models of phonotactics (Hayes and Wilson, 2008 ; Goldsmith and Riggle, 2012), we take a fully generative approach, modeling a process where forms are built up out of subparts by phonologically-informed structure building operations. We learn an inventory of subparts by applying stochastic memoization (Johnson et al., 2007 ; Goodman et al., 2008) to a generative process for phonemes structured as an and-or graph, based on concepts of feature hierarchy from generative phonology (Clements, 1985 ; Dresher, 2009). Subparts are combined in a way that allows tier-based feature interactions. We evaluate our models’ ability to capture phonotactic distributions in the lexicons of 14 languages drawn from the WOLEX corpus (Graff, 2012). Our full model robustly assigns higher probabilities to held-out forms than a sophisticated N-gram model for all languages. We also present novel analyses that probe model behavior in more detail.', 'ar': 'نقدم نموذجًا احتماليًا للتلاعب الصوتي ، وهو مجموعة متواليات الصوت جيدة التكوين في اللغة. على عكس معظم النماذج الحسابية من الأصوات الصوتية (Hayes and Wilson ، 2008 ؛ Goldsmith and Riggle ، 2012) ، فإننا نتبع نهجًا إنتاجيًا بالكامل ، ونمذجة عملية يتم فيها إنشاء النماذج من الأجزاء الفرعية من خلال عمليات بناء الهياكل المستنيرة صوتيًا. نتعلم جردًا للأجزاء الفرعية من خلال تطبيق الذاكرة العشوائية (Johnson et al. ، 2007 ؛ Goodman et al. ، 2008) على عملية توليدية للفونيمات المهيكلة على هيئة رسم و / أو رسم بياني ، استنادًا إلى مفاهيم التسلسل الهرمي للميزات من علم الأصوات التوليدي (كليمنتس) ، 1985 ؛ دريشر ، 2009). يتم دمج الأجزاء الفرعية بطريقة تسمح بتفاعلات الميزات المستندة إلى الطبقة. نقوم بتقييم قدرة نماذجنا على التقاط توزيعات صوتية في معاجم 14 لغة مستمدة من مجموعة WOLEX (Graff ، 2012). يخصص نموذجنا الكامل بقوة احتمالات أعلى للنماذج المعلقة مقارنة بنموذج N-gram المتطور لجميع اللغات. نقدم أيضًا تحليلات جديدة تستقصي سلوك النموذج بمزيد من التفصيل.', 'es': 'Presentamos un modelo probabilístico de fonotáctica, el conjunto de secuencias de fonemas bien formadas en un idioma. A diferencia de la mayoría de los modelos computacionales de fonotáctica (Hayes y Wilson, 2008; Goldsmith y Riggle, 2012), adoptamos un enfoque totalmente generativo, modelando un proceso en el que las formas se construyen a partir de subpartes mediante operaciones de construcción de estructuras fonológicamente informadas. Aprendemos un inventario de subpartes mediante la aplicación de memorización estocástica (Johnson et al., 2007; Goodman et al., 2008) a un proceso generativo para fonemas estructurados como un gráfico y-or, basado en conceptos de jerarquía de características de la fonología generativa (Clements, 1985; Dresher, 2009). Las subpartes se combinan de manera que permiten interacciones de entidades basadas en niveles. Evaluamos la capacidad de nuestros modelos para capturar distribuciones fonotácticas en los léxicos de 14 idiomas extraídos del corpus WOLEX (Graff, 2012). Nuestro modelo completo asigna de manera sólida probabilidades más altas a los formularios desplegados que un sofisticado modelo de N-gram para todos los idiomas. También presentamos análisis novedosos que sondean el comportamiento del modelo con más detalle.', 'pt': 'Apresentamos um modelo probabilístico de fonotática, o conjunto de sequências de fonemas bem formados em uma língua. Ao contrário da maioria dos modelos computacionais de fonotática (Hayes e Wilson, 2008; Goldsmith e Riggle, 2012), adotamos uma abordagem totalmente generativa, modelando um processo em que as formas são construídas a partir de subpartes por operações de construção de estrutura informadas fonologicamente. Aprendemos um inventário de subpartes aplicando memoização estocástica (Johnson et al., 2007; Goodman et al., 2008) a um processo gerativo de fonemas estruturados como um e-ou grafo, baseado em conceitos de hierarquia de traços da fonologia generativa (Clements , 1985; Dresher, 2009). As subpartes são combinadas de uma maneira que permite interações de recursos baseadas em camadas. Avaliamos a capacidade de nossos modelos de capturar distribuições fonotáticas nos léxicos de 14 línguas extraídas do corpus WOLEX (Graff, 2012). Nosso modelo completo atribui de forma robusta probabilidades mais altas para formulários retidos do que um modelo N-gram sofisticado para todos os idiomas. Também apresentamos novas análises que investigam o comportamento do modelo com mais detalhes.', 'fr': "Nous présentons un modèle probabiliste de phonotactique, l'ensemble de séquences phonématiques bien formées dans une langue. Contrairement à la plupart des modèles informatiques de phonotactiques (Hayes et Wilson, 2008\xa0; Goldsmith et Riggle, 2012), nous adoptons une approche entièrement générative, modélisant un processus dans lequel les formes sont construites à partir de sous-parties par des opérations de construction de structures informées phonologiquement. Nous apprenons un inventaire des sous-parties en appliquant une mémorisation stochastique (Johnson et al., 2007\xa0; Goodman et al., 2008) à un processus génératif pour des phonèmes structurés sous forme de graphe et/ou, basé sur des concepts de hiérarchie des caractéristiques issus de la phonologie générative (Clements, 1985\xa0; Dresher, 2009). Les sous-parties sont combinées de manière à permettre des interactions entre les entités basées sur les niveaux. Nous évaluons la capacité de nos modèles à saisir les distributions phonotactiques dans les lexiques de 14 langues tirées du corpus WOLEX (Graff, 2012). Notre modèle complet attribue de manière robuste des probabilités plus élevées aux formulaires tenus qu'un modèle N-gramme sophistiqué pour toutes les langues. Nous présentons également de nouvelles analyses qui étudient plus en détail le comportement des modèles.", 'ja': '我々は音韻論の確率論的モデルを提示しています言語のよく形成された音素配列の集合です フォノタクティクスのほとんどの計算モデル（ Hayes and Wilson, 2008; Goldsmith and Riggle, 2012 ）とは異なり、私たちは完全に生成的なアプローチをとり、フォノロジーに基づいた構造構築操作によってサブパーツからフォームが構築されるプロセスをモデリングします。 我々は、確率的メモ化（ Johnson et al., 2007; Goodman et al., 2008 ）を、生成音声学からの特徴階層の概念に基づいて、グラフとして構造化された音素の生成プロセスに適用することによって、サブパーツの目録を学習する（ Clements, 1985; Dresher, 2009 ）。 サブパーツは、階層ベースのフィーチャーインタラクションを可能にする方法で組み合わせられます。 私たちは、WOLEXコーパスから引き出された14の言語の辞書における音韻分布をキャプチャするモデルの能力を評価します（ Graff、2012 ）。 当社のフルモデルは、すべての言語の洗練されたN - gramモデルよりも、ホールドアウトされたフォームに高い確率を堅牢に割り当てます。 我々はまた、モデルの挙動をより詳細にプローブする新規の分析を提示する。', 'zh': '立一语音之概率,言中式之音素序。 与大众音策不同(Hayes与Wilson2008。 Goldsmith and Riggle,2012),全生之法,建模于一事,其表单以语音信息结构构于子。 随机记取清单(Johnson等2007。 Goodman等,2008)生语音学层次结构名,结音素为和图(Clements1985; 德雷舍,2009)。 子以许其交。 估我模形WOLEX语料库中取14种语词典中获语音方略布(Graff,2012)。 吾侪全模比诸语言N-gram模形更强为留概率。 更详探模样行新。', 'hi': 'हम फोनोटैक्टिक्स का एक संभाव्य मॉडल प्रस्तुत करते हैं, एक भाषा में अच्छी तरह से गठित फोनेम अनुक्रमों का सेट। फोनोटैक्टिक्स के अधिकांश कम्प्यूटेशनल मॉडल के विपरीत (हेस और विल्सन, 2008; गोल्डस्मिथ और रिगल, 2012), हम एक पूरी तरह से उत्पादक दृष्टिकोण लेते हैं, एक ऐसी प्रक्रिया को मॉडलिंग करते हैं जहां ध्वन्यात्मक रूप से सूचित संरचना निर्माण संचालन द्वारा उप-भागों से रूपों का निर्माण किया जाता है। हम स्टोकेस्टिक मेमोइज़ेशन (जॉनसन एट अल। Goodman et al., 2008) एक और या ग्राफ के रूप में संरचित phonemes के लिए एक उत्पादक प्रक्रिया के लिए, जननात्मक फोनोलॉजी (क्लेमेंट्स, 1985) से सुविधा पदानुक्रम की अवधारणाओं के आधार पर; ड्रेसर, 2009)। Subparts एक तरह से संयुक्त हैं कि टियर आधारित सुविधा इंटरैक्शन की अनुमति देता है. हम WOLEX कॉर्पस (Graff, 2012) से खींची गई 14 भाषाओं के शब्दकोशों में फोनोटैक्टिक वितरण को कैप्चर करने के लिए हमारे मॉडल की क्षमता का मूल्यांकन करते हैं। हमारा पूर्ण मॉडल सभी भाषाओं के लिए एक परिष्कृत एन-ग्राम मॉडल की तुलना में आयोजित-आउट रूपों के लिए उच्च संभावनाओं को मजबूत रूप से असाइन करता है। हम उपन्यास विश्लेषण भी प्रस्तुत करते हैं जो मॉडल व्यवहार को अधिक विस्तार से जांचते हैं।', 'ru': 'Представлена вероятностная модель фонотаксики, совокупность хорошо сформированных фонемных последовательностей в языке. В отличие от большинства вычислительных моделей фонотактики (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), мы используем полностью генеративный подход, моделируя процесс, в котором формы строятся из подкомпонентов с помощью фонологически информированных операций построения структуры. Мы изучаем инвентаризацию подчастей, применяя стохастическую меморизацию (Johnson et al., 2007; Goodman et al., 2008) к генеративному процессу для фонем, структурированных в виде графика «и/или», на основе концепций иерархии признаков из генеративной фонологии (Clements, 1985; Dresher, 2009). Подчасти объединены таким образом, что позволяют взаимодействовать с признаками на основе уровня. Мы оцениваем способность наших моделей фиксировать фонотаксические распределения в лексиконах 14 языков, взятых из корпуса WOLEX (Graff, 2012). Наша полная модель надежно присваивает более высокие вероятности удерживаемым формам, чем сложная модель N-грамм для всех языков. Мы также представляем новые анализы, которые более подробно описывают поведение модели зонда.', 'ga': 'Cuirimid i láthair múnla dóchúil den fhónatataic, an tsraith seichimh fóinéime dea-chruthaithe i dteanga. Murab ionann agus an chuid is mó de na samhlacha ríomhaireachtúla fóineolaíochta (Hayes agus Wilson, 2008; Goldsmith agus Riggle, 2012), glacaimid cur chuige iomlán giniúna, ag samhaltú próiseas ina ndéantar foirmeacha a chomhdhlúthú as fopháirteanna trí oibríochtaí tógála struchtúir a bhfuil eolas fóineolaíoch orthu. Foghlaimimid fardal fopháirteanna trí mheabhrúchán stochastic (Johnson et al., 2007; Goodman et al., 2008) a chur i bhfeidhm ar phróiseas giniúna d’fhóinéimí atá struchtúrtha mar agus-nó graf, bunaithe ar choincheapa an ordlathais ghnéis ó fhóineolaíocht ghiniúna (Clements , 1985; Dresher, 2009). Cuirtear fopháirteanna le chéile ar bhealach a cheadaíonn idirghníomhaíochtaí gné-bhunaithe sraithe. Déanaimid measúnú ar chumas ár múnlaí dáiltí fónatatacha a ghabháil i bhfoclóirí 14 theanga ó chorpas WOLEX (Graff, 2012). Sannann ár múnla iomlán dóchúlachtaí níos airde go láidir d’fhoirmeacha coinnithe amach ná samhail N-gram sofaisticiúla do gach teanga. Cuirimid i láthair freisin anailísí nua a dhéanann iniúchadh níos mine ar iompar eiseamláireach.', 'ka': 'ჩვენ ფონოტატიკის შესაბამისი მოდელს, კარგი ფონონემის შესაბამისი წერტილის შესაბამისი წერტილი ენაში. ფონოტატიკის კომპუტაციალური მოდელების განსხვავებაში (ჰეიზი და ვილისონი, 2008; დოლესმიტი და რიგგგლის, 2012) ჩვენ ვაკეთებთ ყველაფერი გენერაციური პროცესი, რომელიც პროცესის მოდელეცია, რომელიც ჩვენ ვისწავლით სეფექტიკური მემონიკაციის ინტერუქტურაცია (Johnson et al., 2007; Goodman et al., 2008) ფონემების ინტერუქტურაციის პროცესზე, როგორც ან-ან გრაფიკური ფონემების ინტერუქტურაციის ინტერუქტურაციის ინტერუქტურაციის ინტერუ სეფერი კომბინეციებულია, რომელიც კომბინეციური ფუნქციების კომბინეციაციას შესაძლებელია. ჩვენ მოდელების შესაძლებლობა გავუმუშაოთ, რომ ტონოტატიკური განყოფილებები 14 ენების ლექსიკონში WOLEX კორპუსდან (Graff, 2012). ჩვენი ყველა მოდელი ძალიან უფრო მეტი შესაძლებლობა დააყენება ყველა ენების N-გრამის მოდელზე უფრო მეტი შესაძლებლობა. ჩვენ ასევე პრომენტის ანალიზაციას ჩვენ აჩვენებთ, რომლებიც მოდელური მოქმედება უფრო მეტად.', 'hu': 'Bemutatjuk a fonotaktika valószínűségi modelljét, a jól kialakított fonema szekvenciák halmazát egy nyelven. A fonotaktika legtöbb számítástechnikai modelljétől eltérően (Hayes és Wilson, 2008; Goldsmith és Riggle, 2012), mi teljesen generációs megközelítést alkalmazunk, modellezve egy olyan folyamatot, ahol a formákat a fonológiailag tájékozott struktúraépítési műveletekkel építik fel. Az alcsoportok leltárát a sztochasztikus emlékeztetések alkalmazásával tanuljuk meg (Johnson et al., 2007; Goodman et al., 2008) a generációs fonológiából származó funkcióhierarchia fogalmain alapuló fonemák generációs folyamatára (Clements, 1985; Dresher, 2009). Az alkatrészek olyan módon vannak kombinálva, amely lehetővé teszi a szintalapú funkciók interakcióját. Modelljeink fonotaktikus eloszlások rögzítésére való képességét a WOLEX korpuszból származó 14 nyelv lexikonjában értékeljük (Graff, 2012). Teljes modellünk erőteljesen nagyobb valószínűséget biztosít a tartós formákhoz, mint egy kifinomult N-grammos modell minden nyelvre. Olyan új elemzéseket is bemutatunk, amelyek részletesebben vizsgálják a modell viselkedését.', 'el': 'Παρουσιάζουμε ένα πιθανολογικό μοντέλο φωνοτεχνικής, το σύνολο καλοσχηματισμένων φωνητικών ακολουθιών σε μια γλώσσα. Σε αντίθεση με τα περισσότερα υπολογιστικά μοντέλα φωνοτεχνικής (Χέις και Γουίλσον, 2008, Γκόλντσμιθ και Ριγκλ, 2012), ακολουθούμε μια πλήρως παραγωγική προσέγγιση, μοντελοποιώντας μια διαδικασία όπου οι μορφές σχηματίζονται από υποσαρτήματα με φωνολογικά ενημερωμένες λειτουργίες οικοδόμησης δομών. Μαθαίνουμε μια απογραφή των επιμέρους τμημάτων εφαρμόζοντας stochastic memoriation (Johnson et al., 2007; Goodman et al., 2008) σε μια παραγωγική διαδικασία για φωνημένα δομημένα ως ή-ή γράφημα, βασισμένη σε έννοιες της ιεραρχίας χαρακτηριστικών από τη γενετική φωνολογία (Clements, 1985; Dresher, 2009). Τα επιμέρους τμήματα συνδυάζονται με τρόπο που επιτρέπει αλληλεπιδράσεις χαρακτηριστικών βάσει βαθμίδων. Αξιολογούμε την ικανότητα των μοντέλων μας να συλλαμβάνουν φωνοτεχνικές κατανομές στα λεξικά των 14γλωσσών που προέρχονται από το σώμα (Γκραφ, 2012). Το πλήρες μοντέλο μας αποδίδει ισχυρά υψηλότερες πιθανότητες σε καθυστερημένες μορφές από ένα εξελιγμένο μοντέλο Ν-γραμμάτων για όλες τις γλώσσες. Παρουσιάζουμε επίσης νέες αναλύσεις που ανιχνεύουν τη συμπεριφορά του μοντέλου με περισσότερες λεπτομέρειες.', 'it': "Presentiamo un modello probabilistico di fonotatica, l'insieme di sequenze fonemiche ben formate in una lingua. A differenza della maggior parte dei modelli computazionali di fonotatica (Hayes e Wilson, 2008; Goldsmith e Riggle, 2012), adottiamo un approccio completamente generativo, modellando un processo in cui le forme sono costruite dalle parti secondarie da operazioni di costruzione di strutture fonologicamente informate. Impariamo un inventario delle parti secondarie applicando la memorizzazione stocastica (Johnson et al., 2007; Goodman et al., 2008) a un processo generativo per fonemi strutturati come un e-o grafico, basato su concetti di gerarchia delle caratteristiche dalla fonologia generativa (Clements, 1985; Dresher, 2009). Le parti secondarie sono combinate in modo da consentire interazioni di funzionalità basate su livelli. Valutiamo la capacità dei nostri modelli di catturare distribuzioni fonotatiche nei lessici di 14 lingue tratte dal corpus WOLEX (Graff, 2012). Il nostro modello completo assegna robustamente maggiori probabilità alle forme mantenute rispetto a un sofisticato modello N-gram per tutte le lingue. Presentiamo anche nuove analisi che analizzano il comportamento del modello in modo più dettagliato.", 'lt': 'Mes pristatome probabilistinį fonotaktikos model į, gerai suformuotų fonemų sekų rinkinį kalba. Priešingai nei dauguma kompiuterinių fonotaktikos modelių (Hayes ir Wilson, 2008; Goldsmith ir Riggle, 2012), mes taikome visiškai kartotinį požiūrį, modeliuodami procesą, kuriame formos sudaromos iš dalių pagal fonologiškai informuotą struktūros kūrimo operacijas. Išmokome dalių aprašą taikant stochastinę memoizaciją (Johnson et al., 2007; Goodman et al., 2008) generaciniam fonemų, struktūrizuotų kaip ir-arba grafikas, procesui, grindžiamam generacinės fonologijos charakteristikų hierarchijos koncepcijomis (Clements, 1985; Dresher, 2009). Podaliai sujungiami taip, kad būtų galima sąveikauti su savybėmis lygiu. Vertiname mūsų modelių gebėjimą surinkti fonotaktinius platinimus 14 kalbų tekstikonuose, paimtuose iš WOLEX corpus (Graff, 2012). Visas mūsų modelis tvirtai suteikia didesnę tikimybę išsaugoti formas nei sudėtingas N-gramo modelis visoms kalboms. Mes taip pat išsamiau pristatome naujas analizes, kuriose analizuojame modelio elgesį.', 'mk': 'Презентираме веројатен модел на фонотактика, сет добро формирани фономски секвенции на јазик. За разлика од повеќето компјутативни модели на фонотактика (Хејс и Вилсон, 2008; Goldsmith и Riggle, 2012), ние прифаќаме целосно генерален пристап, моделирајќи процес каде форми се изградени од подделови од фонолошки информирани структурни операции. Научиме инвентар на подделови со апликација на стохастична мемоизација (Johnson и ал., 2007; Goodman и ал., 2008) на генерациски процес за фонеми структурирани како и-или граф, базирани на концептите на хиерархија на карактеристики од генерационална фонологија (Clements, 1985; Dresher, 2009). Подделовите се комбинирани на начин кој овозможува интеракции на карактеристики базирани на ниво. Ние ја проценуваме способноста на нашите модели да снимаат фонотактички дистрибуции во лексиконите на 14 јазици изведени од корпусот WOLEX (Graff, 2012). Нашиот целосен модел силно ги доделува поголемите веројатности на издржани форми отколку софистициран модел на N-грам за сите јазици. Ние, исто така, претставуваме нови анализи кои го истражуваат однесувањето на моделот во повеќе детали.', 'kk': 'Біз фонотактиканың ықтималдық моделін, тілде жақсы құрылған фонемді реттеулерді таңдаймыз. Фонотактикалық компьютерлік моделдерінің көбінесе (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), фологиялық құрылғыларды құру операциялары арқылы пішіндердің ішкі бөліктерінен құрылған процесті моделдеу үшін толық құрылатын жағдайды. Стохастикалық жазбаларды (Johnson et al., 2007; Goodman et al., 2008) және не график ретінде құрылған фонемдер үшін генеративті иерархиясының концепцияларына негізделген жұмыс ілеспелеріне (Clements, 1985; Dresher, 2009). Ішкі бөліктері біріктірілген, біріктірілген қасиеттердің интерфейстеріне мүмкіндік беруге мүмкіндік береді. Біз үлгілерімізді WOLEX корпус (Graff, 2012) сызылған 14 тілдің лексикандағы фонотактикалық дистрибуттарын алу мүмкіндігін бағалаймыз. Біздің толық моделіміз барлық тілдер үшін N- грамм үлгісінен артық болып тұрған пішімдерге артық мүмкіндіктерді таңдайды. Біз сондай-ақ романдық анализ үлгілерді тегжейлі түрде тұрады.', 'ml': 'നമ്മള്\u200d ഒരു സാധ്യതയുള്ള ഫോണോട്ടാക്റ്റിക്സിക്കുകളുടെ മാതൃകയെ കൊണ്ടുവരുന്നു. ഒരു ഭാഷയില്\u200d നല്ല ഫോണിമോണ്\u200d സെക്കന്\u200d ഫോണോട്ടാക്റ്റിക്സിന്റെ ഏറ്റവും കൂടുതല്\u200d കണക്കാക്കുന്ന മാതൃകങ്ങള്\u200d വില്\u200dസണ്\u200d (ഹൈസും വില്\u200dസണ്\u200d, 2008; ഗോള്\u200dഡ്മിത്തും റിഗ്ഗില്\u200d, 2012), ഞങ്ങള്\u200d ഒരു പൂര്\u200dണ്ണമായ ജനററിവേറ്റീവ്  സ്റ്റോക്സ്റ്റോക്സിക് മെമോമോയേഷന്\u200d പ്രയോഗിക്കുന്നതിനാല്\u200d ഞങ്ങള്\u200d ഒരു സബ്ഭാഗം പഠിക്കുന്നു (ജോണ്\u200dസണ്\u200d എറ്റ്; 2007; ഗുഡ്മാന്\u200d എറ്റ് അല്\u200d., 2008) ഫോണികള്\u200dക്ക് ഒരു ജനറലിവ് പ്രക്രിയയിലേ കൂടുതല്\u200d അടിസ്ഥാനത്തിലുള്ള പ്രതിഫലങ്ങളുടെ ഇടപെടലുകള്\u200dക്ക് അനുവദിക്കുന്ന ഒരു രീതിയില്\u200d സബ്ബിള്\u200d ഞങ്ങള്\u200d ഞങ്ങളുടെ മോഡലുകള്\u200dക്ക് ഫോണോട്ടാക്റ്റിക് വിതരണം പിടികൂടാനുള്ള കഴിവ് വിലാസപ്പെടുത്തുന്നു. വോളെക്സ് കോര്\u200dപ്പുസ നമ്മുടെ പൂര്\u200dണ്ണമായ മോഡല്\u200d റോബാസ്റ്റില്\u200d നിന്നും എല്ലാ ഭാഷകള്\u200dക്കും വേണ്ടി സോഫിസ്റ്റിക്കേറ്റ് N-ഗ്രാം മോഡലിനേക നമ്മള്\u200d നോവല്\u200d അന്വേഷണങ്ങള്\u200d കൂടുതല്\u200d വിശദീകരിച്ചു കൊണ്ട് വരുന്നു', 'ms': 'Kami memperkenalkan model kemungkinan fonotaktik, set urutan fonem yang bentuk dengan baik dalam bahasa. Tidak seperti kebanyakan model komputasi fonotaktik (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), kami mengambil pendekatan yang penuh generasi, memmodelkan proses di mana bentuk dibina dari subpart oleh operasi pembangunan struktur yang diberitahu fonologi. Kami belajar inventori subpart dengan melaksanakan memoizasi stochastik (Johnson et al., 2007; Goodman et al., 2008) kepada proses generatif untuk fonem yang terstruktur sebagai dan-atau graf, berdasarkan konsep hierarki ciri dari fonologi generatif (Clements, 1985; Dresher, 2009). Subbahagian digabung dengan cara yang membenarkan interaksi ciri berdasarkan tahap. Kami menilai kemampuan model kita untuk menangkap distribusi fonotaktik dalam leksikon 14 bahasa yang dicat dari WOLEX corpus (Graff, 2012). Model penuh kami dengan kuat menyerahkan kebarangkalian yang lebih tinggi untuk bentuk held-out daripada model N-gram yang sophistik untuk semua bahasa. Kami juga memperkenalkan analisis baru yang menguji perilaku model secara terperinci.', 'mt': 'Aħna nippreżentaw mudell probabilistiku ta’ fonotattika, is-sett ta’ sekwenzi ta’ fonemi ffurmati tajjeb f’lingwa. Unlike most computational models of phonotactics (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), we take a fully generative approach, modeling a process where forms are built up out of subparts by phonologically-informed structure building operations.  Natgħallmu inventarju tas-subpartijiet billi napplikaw memoizzazzjoni stokastika (Johnson et al., 2007; Goodman et al., 2008) għal proċess ġenerattiv għall-fonemi strutturati bħal a u-jew graff, ibbażat fuq kunċetti ta’ ġerarkija tal-karatteristiċi minn fonoloġija ġenerattiva (Clements, 1985; Dresher, 2009). Is-sottopartijiet huma kkombinati b’mod li jippermetti interazzjonijiet ta’ karatteristiċi bbażati fuq il-livelli. Aħna jevalwaw il-kapaċità tal-mudelli tagħna li nqabdu distribuzzjonijiet fonotattiċi fil-lexicons ta’ 14-il lingwa miġbura mill-WOLEX corpus (Graff, 2012). Il-mudell sħiħ tagħna jassenja b’mod robust probabilitajiet ogħla għal forom miżmuma barra minn mudell sofistikat ta’ N-gramma għall-lingwi kollha. Aħna nippreżentaw ukoll analiżi ġdida li tanalizza l-imġiba tal-mudell f’aktar dettall.', 'pl': 'Przedstawiamy prawdopodobny model fonotaktyki, zbiór dobrze uformowanych sekwencji fonemów w języku. W przeciwieństwie do większości modeli obliczeniowych fonotaktyki (Hayes i Wilson, 2008; Goldsmith i Riggle, 2012), stosujemy podejście w pełni generacyjne, modelując proces, w którym formy są budowane z podczęści poprzez operacje budowania struktury fonologicznej. Uczymy się inwentaryzacji podczęści poprzez zastosowanie stochastycznej memoizacji (Johnson et al., 2007; Goodman et al., 2008) do procesu generacyjnego fonemów ustrukturyzowanych jako i-lub wykres, opartego na koncepcjach hierarchii cech z fonologii generacyjnej (Clements, 1985; Dresher, 2009). Podczęści są łączone w sposób umożliwiający interakcje funkcji opartych na poziomach. Oceniamy zdolność naszych modeli do uchwycenia dystrybucji fonotaktycznych w leksykonach 14-języków wyciągniętych z korpusu WOLEX (Graff, 2012). Nasz pełny model solidnie przypisuje większe prawdopodobieństwa do formularzy zatrzymanych niż zaawansowany model N-gram dla wszystkich języków. Przedstawiamy również nowatorskie analizy, które bardziej szczegółowo badają zachowanie modelu.', 'ro': 'Prezentăm un model probabilistic de fonotactică, setul de secvențe foneme bine formate într-o limbă. Spre deosebire de majoritatea modelelor computaționale de fonotactică (Hayes și Wilson, 2008; Goldsmith și Riggle, 2012), adoptăm o abordare complet generativă, modelând un proces în care formele sunt construite din subpărți prin operațiuni de construire a structurii informate fonologic. Învățăm un inventar al subpărților aplicând memorarea stocastică (Johnson et al., 2007; Goodman et al., 2008) unui proces generativ pentru foneme structurate ca un și-sau grafic, bazat pe concepte de ierarhie a caracteristicilor din fonologia generativă (Clements, 1985; Dresher, 2009). Subpărțile sunt combinate într-un mod care permite interacțiuni de caracteristici bazate pe niveluri. Evaluăm capacitatea modelelor noastre de a capta distribuții fonotactice în lexicoanele a 14 limbi extrase din corpul WOLEX (Graff, 2012). Modelul nostru complet atribuie în mod robust probabilități mai mari formelor susținute decât un model sofisticat N-gram pentru toate limbile. De asemenea, prezentăm analize noi care analizează comportamentul modelului în detaliu.', 'mn': 'Бид фонотактикийн магадлалын загварыг хэл дээр сайн бүтээгдэхүүнтэй фонем дарааллын хэлбэрээр тайлбарлаж байна. Ихэнх тооны фонотактикийн загваруудын ялгаатай (Hayes, Wilson, 2008; Goldsmith and Riggle, 2012), бид фонологийн мэдээллийн бүтээмжээний үйлдвэрлэлээс бүрэн бүтээмжтэй арга загварыг ашигладаг. Бид зуб хэсгүүдийн зохиолын бүтээгдэхүүнийг суралцдаг. Жонсон et al., 2007; Goodman et al., 2008) генериал фонологиос бүтээгдэхүүний ерөнхийлөгч болон-эсвэл график байгуулагдсан утаснуудын төлөвлөгөө (Clements, 1985; Dresher, 2009). Гурав хэсгүүд нь холбоотой харилцаа боломж олгодог. Бид моделуудыг WOLEX корпус (Graff, 2012) дээр зурсан 14 хэл лексиконы фонотактикийн хуваарилалтыг авах чадварыг үнэлдэг. Бидний бүрэн загвар нь бүх хэл дээрх N-грамм загвараас илүү өндөр магадлал өгдөг. Мөн бид загварын үйл явцыг илүү нарийвчлан судалж өгдөг.', 'no': 'Vi presenterer ein sannsynlig modell av fonotaktikk, settet av godt formande fonesekvenser i eit språk. I motsetning til dei fleste datamaskinemodeller av fonotaktikk (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), tar vi ein fullstendig generert tilnærming, modeller ein prosess der skjemar vert bygd opp ut av underdeler ved å bygge opp fonologisk informert strukturbygging. Vi lærer eit inventør av underdeler ved å bruka stochastisk memorisering (Johnson et al., 2007; Goodman et al., 2008) til ein generert prosess for telefoner strukturert som eit og eller graf, basert på konseptar av funksjonshierarki frå generert fonologikk (Clements, 1985; Dresher, 2009). Underdeler er kombinerte på ein måte som tillater tierbaserte funksjonsinteraksjonar. Vi evaluerer muligheten til modellen våre å henta fonotaktiske distribusjonar i leksikonene av 14 språk teikna frå WOLEX corpus (Graff, 2012). Det fulle modellet vår tilbyr kraftig høgare sannsynlighetar til å halde ut skjemar enn ein sofistikert N-gram-modell for alle språk. Vi presenterer også novelanalyser som proberer modelletferd i meir detaljar.', 'sr': 'Predstavljamo verovatni model fonotaktike, setu dobro formiranih telefonskih sekvencija na jeziku. Za razliku od većine kompjuterskih modela fonotaktike (Hayes i Wilson, 2008; Goldsmith i Riggle, 2012), poduzimamo potpuno generativni pristup, modeliramo proces u kojem se forme izgrađuju iz poddijela fonološki informirane strukturne operacije. Naučimo izum poddijelova primjenjivanjem stokastične memoizacije (Johnson et al., 2007; Goodman et al., 2008) na generativni proces za telefone strukturirane kao i-ili grafik, na osnovu koncepta hijerarhije karakteristike iz generativne fonologije (Clements, 1985; Dresher, 2009). Poddijelovi su kombinirani na način na koji omogućava interakcije na vezama. Procjenjujemo sposobnost naših modela da uhvatimo fonotaktičke distribucije u leksionima od 14 jezika izvedenih iz WOLEX korpusa (Graff, 2012). N a š potpuni model je opšte dodijelio veće mogućnosti za održavanje oblika od sofisticiranog N-gram model a za sve jezike. Takoðe predstavljamo i romanske analize koje se ponašaju model sonde detaljnije.', 'so': 'Waxaynu soo bandhignaynaa qaab suurtagal ah oo af ku qoran sawifan sawir ah. Isu eg noocyada xisaabta badan ee phonotactics (Hayes and Wilson, 2008; Goldsmith iyo Riggle, 2012), waxaynu qaadannaa qaab dhaqan oo dhan, waxaana sameynaynaa sameynta daboolo laga dhiso kooxo hoose laga sameeyo waxqabadyo dhismaha dhismaha afka nolojiga lagu ogeysiiyey. Waxaynu barnaa qoraal hoose-qeybood oo lagu codsanayo joonyad memojiisation (Johnson et al., 2007; Goodman et al., 2008) xagga jardiino generative ah oo phono loo sameeyo oo loo qoray sida iyo-ama-graph oo lagu saleyn karo fikrada hierarchy ee generative phonology (Clements, 1985; Dresher, 2009). Qaybaha waxaa lagu isku xiran karaa qaab ku saabsan faa’iido xirfadeed. Waxaynu qiimeynaynaa awooddayada ay sameyn karto qaybinta afka leksikada ee 14 luqadood oo ka soo baxay korpuska WOLEX (Graff, 2012). Tusaale kamid ah waxaa suurtagal ah in la sameeyo noocyo ka sarreeya noocyo dhaqdhaqaaqa N-gram oo luuqadaha oo dhan. Waxaynu sameynaa baaritaanka saxda ah oo dabeecada tijaabada ah si ka sii cad ah.', 'sv': 'Vi presenterar en sannolikhetsmodell av fonotaktik, en uppsättning välformade fonemsekvenser i ett språk. Till skillnad från de flesta beräkningsmodeller av fonotaktik (Hayes och Wilson, 2008; Goldsmith och Riggle, 2012), använder vi ett fullt generativt tillvägagångssätt, modellerar en process där former byggs upp ur underdelar genom fonologiskt informerade strukturbyggande operationer. Vi lär oss en inventering av underdelar genom att tillämpa stokastisk memonisering (Johnson et al., 2007; Goodman et al., 2008) på en generativ process för fonemer strukturerade som en och-eller graf, baserad på begrepp om funktionshierarki från generativ fonologi (Clements, 1985; Dresher, 2009). Deldelar kombineras på ett sätt som möjliggör nivåbaserade funktionsinteraktioner. Vi utvärderar våra modellers förmåga att fånga fonotaktiska distributioner i lexikoner från 14 språk hämtade från WOLEX korpus (Graff, 2012). Vår fullständiga modell ger robust högre sannolikheter för utdragna former än en sofistikerad N-grammomodell för alla språk. Vi presenterar också nya analyser som undersöker modellbeteende mer i detalj.', 'ta': 'நாம் ஒரு சாத்தியமான போனோட்சிக்ஸ் மாதிரியை கொண்டுவருகிறோம், ஒரு மொழியில் நல்ல உருவாக்கப்பட்ட கோப்புக் குறிப போனோட்சாக்ஸ் மற்றும் வில்சன் (ஹைஸ் மற்றும் வில்சன், 2008; கோல்ட்ஸிட் மற்றும் ரிக்கில், 2012) பெரும்பாலான கணக்கிட்ட மாதிரிகள் மாதிரியாக, நாம் முழுமையான பொதுவ நாங்கள் துணை பகுதிகளின் கண்டிப்பாடு கற்றுக் கொள்கிறோம் பொது பொருள் முறைமையை பயன்படுத்துவதற்கு (ஜான்சன் et al., 2007; குட்மான் et அல்., 2008) ஒரு பொலிபேசிகளை உருவாக்கிய புலைபேசிகளின் பொது துணை பிரிவுகள் கடைசி அடிப்படையில் உள்ள பண்புகளின் இடைவெளிகளை அனுமதிக்கும் வழியில் ஒன்று சேர்க்கப் WOLEX கார்ப்ஸிலிருந்து வரையப்பட்ட 14 மொழிகளின் வெளிப்பாட்டை போனாட்சிக் விரிவாக்கத்தை பிடிக்க எங்கள் மாதிரிகளின் சக்தி எங்கள் முழு மாதிரி முழுமையாக உயர்ந்த சாத்தியங்களை நிறுத்துகிறது அனைத்து மொழிகளுக்கும் ஒரு சிகிச்சைப்படுத்தப்பட் நாம் புதிய ஆய்வுகளை கூட மாதிரி நடத்தையை மேலும் விளக்கமாக காண்பிக்கிறோம்.', 'si': 'අපි ෆෝනෝටැක්ටික්සික් එක්ක ප්\u200dරශ්නයක් පෙන්වන්නේ, හොඳ විශ්වාස කරපු ෆෝනේම් ක්\u200dරමයක් භාෂ ගොඩක් පරිගණනය විදිහට පරික්ෂාත්මක විදිහට (හේයිස් සහ විල්සන්, 2008; Goldsmith සහ රිග්ල්, 2012), අපි සම්පූර්ණයෙන්ම ප්\u200dරවෘත්තියක් ගන්නවා, ප්\u200dරවෘත්තියක අපි ඉගෙන ගන්නවා ස්ටෝචස්ටික් මතකය (ජොන්සන් ට් ල., 2007; Goodman et al., 2008) ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක සබ්පොර්ට්ස් සම්බන්ධ විදියට සම්බන්ධ විදියට සම්බන්ධ විදියට සම්බන්ධ වෙන්න පුළු අපි අපේ මොඩේල්ස් කොර්පුස් වලින් ඇතුළු භාෂාව 14 ලෙක්සිකොන්ස් වලින් ෆෝනොටැක්ටික් විතරය අල්ලගන්න බලන්න. අපේ සම්පූර්ණ මොඩේල් හරියටම වැඩිය හැකි භාෂාවට සාමාන්\u200dය N-ග්\u200dරාම් මොඩේලයක් වඩා වැඩිය හැකියාවට වඩා ව අපි සමහර විශ්ලේෂණය කරනවා ඒ වගේම විස්තර කරන්නේ තව විස්තර විස්තරයෙන් මොඩල් විස්තර කරන්න.', 'ur': 'ہم ایک فنوٹاکیٹیکس کی امکان داری مدل کو پیش کرتے ہیں، ایک زبان میں بہترین فرنیم سٹ کی سٹ۔ بہت سی کمپیوٹریشن موڈل کے مطابق (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012) ہم ایک کامل پیدا کرنے والی طریقہ لے لیتے ہیں، ایک پروسس کی مدل کرتے ہیں جہاں فرمول سوب ٹکڑوں سے بنائے جاتے ہیں فونولوژیکی سے معلوم ہوئے ساختاری عملیات کے ذریعہ۔ ہم سپٹ پارٹوں کی آزمائش سکھاتے ہیں، جو جانسون اور الٹ، 2007، گودمن اور الٹ، 2008) ایک پیدائش پیدائش کے ذریعے جو ایک اور یا گراف کے طور پر ساختہ کئے گئے ہیں، جنرائیٹ فونولوژی (Clements, 1985; Dresher, 2009) کی فکرت یورارژی کی نظریں پر بنیاد رکھتے ہیں۔ سوب پارٹوں کو ایک طریقے سے ترکیب کیا جاتا ہے جو ٹییر بنیادی فکرات کی تعاملات کی اجازت دیتا ہے۔ ہم نے اپنے مدلکوں کی قدرت کا ارزش کرتا ہے کہ WOLEX کورپوس (Graff, 2012) سے 14 زبانوں کی لکسیکونز میں فانوٹیکٹیکٹیکٹیکٹیکٹیکٹیکٹی تقسیم کریں۔ ہماری پوری موڈل مضبوط طور پر بہت زیادہ احتمال رکھتا ہے کہ تمام زبانوں کے لئے ایک پیچیدہ N-گرم موڈل سے اٹھائے جائیں۔ ہم نیوی تحلیل بھی پیش کرتے ہیں جو مدل رفتار کو زیادہ جزئیات میں تحقیق کرتے ہیں.', 'uz': "Biz o'z tilda o'xshagan fonotaktik modelini hozirganamiz, o'zga qo'llangan foydalanuvchi tarkibi. Ko'pchilik fonotactik modellariga (Hayes va Wilson 2008; Goldsmith va Riggle, 2012) kabi bir kompyuterga ega bo'ladi. Biz butun generativ usul bilan fonologiyalar tizim yaratish amallari bilan tuziladigan jarayonlarni modellashimiz mumkin. Biz o'rganamiz: Joneson et 2007; Goodman et al., 2008) bir tub qismlarni o'rganamiz. Generative fonologiya (Clements, 1985; Dresher, 2009) asosida yaratilgan foydalanuvchi va grafik sifatida yaratilgan foydalanuvchiga bir generativ jarayonni o'rganamiz. Name Biz modellarimizni WOLEX Korpusdan (Graff, 2012) yaratilgan 14 tillardan fonotaktik tarqatishni qiymatmiz. Bizning butun modelimiz hamma tillar uchun sofistik N-gram modeliga qo'llaniladi. Biz esa novel analyzerini ko'proq foydalanuvchi xususiyatlarni bajaramiz.", 'vi': 'Chúng tôi trình bày mô hình thức triệu tập, các chuỗi ngữ âm được hình thành bằng một ngôn ngữ. Không giống hầu hết các mô hình tổng tính về triệu tập (Hayes và Wilson, quá khứ; GoldSmith và Riggs, ng2), chúng tôi sử dụng một phương pháp truyền sinh hoàn toàn, tạo ra một tiến trình mà các hình thể được xây dựng từ dưới lớp bằng các thao tác cấu trúc dựa trên âm bản. Chúng ta học danh sách các giải nghệ bằng cách áp dụng bản ghi tự khoa học ngẫu nhiên (Johnson et al., vượn; Goodman et al., 2007) vào một quy trình sinh sản cho niên ngữ được cấu thành và-hay đồ thị dựa trên các khái niệm phân tích về tính năng từ dạng điện thoại (Clements, 198885; Dresher, 2009). Phần dưới được kết hợp theo một cách cho phép tương tác của tính năng theo tầng. Chúng tôi đánh giá khả năng phân phát gốc từ ngôn ngữ 42 của hệ thống WOLEX (Graff, thẩm 2). Toàn bộ mô hình của chúng tôi dựa vào khả năng xác định khả năng lớn hơn các dạng bị thao túng hơn một mô hình N-gram tinh vi cho tất cả các ngôn ngữ. Chúng tôi cũng đưa ra các phân tích mới về hành vi mô hình.', 'da': 'Vi præsenterer en sandsynlig model af fonotaktik, et sæt af velformede foneme sekvenser på et sprog. I modsætning til de fleste beregningsmodeller af fonotaktik (Hayes og Wilson, 2008; Goldsmith og Riggle, 2012), tager vi en fuldt generativ tilgang, der modellerer en proces, hvor former opbygges ud af underdele af fonologisk informerede strukturbygningsoperationer. Vi lærer en opgørelse af underdele ved at anvende stokastisk erindring (Johnson et al., 2007; Goodman et al., 2008) på en generativ proces for fonemer struktureret som en og-eller graf, baseret på begreber af funktionshierarki fra generativ fonologi (Clements, 1985; Dresher, 2009). Underdele kombineres på en måde, der muliggør niveaubaserede funktionsinteraktioner. Vi evaluerer vores models evne til at indfange fonotaktiske fordelinger i leksikoner på 14 sprog, der er udtaget fra WOLEX korpus (Graff, 2012). Vores fulde model tildeler robust større sandsynligheder til udholdte formularer end en avanceret N-gram model til alle sprog. Vi præsenterer også nye analyser, der undersøger model adfærd mere detaljeret.', 'hr': 'Predstavljamo vjerojatni model fonotaktike, setu dobro formiranih telefonskih sekvencija na jeziku. Za razliku od većine računalnih modela fonotaktike (Hayes i Wilson, 2008; Goldsmith i Riggle, 2012), poduzimamo potpuno generativni pristup, modelirajući proces u kojem se oblici izgrađuju iz poddijela fonološki informiranim strukturnim građevinskim operacijama. Naučimo inventar poddijelova primjenjivanjem stokastične memorizacije (Johnson et al., 2007; Goodman et al., 2008) na generativni proces za telefone strukturirane kao i-ili graf, temeljeno na koncepcijama hijerarhije karakteristike iz generativne fonologije (Clements, 1985; Dresher, 2009). Poddijelovi su kombinirani na način na koji omogućava interakcije na vezama. Procjenjujemo sposobnost naših modela da uhvatimo fonotaktičke distribucije u leksionima od 14 jezika izvedenih iz WOLEX corpusa (Graff, 2012). N a š puni model čvrsto određuje veće vjerojatnosti za održane oblike nego sofisticirani model N-gram a za sve jezike. Također predstavljamo i romanske analize koje se ponašaju model sonde detaljnije.', 'nl': 'We presenteren een probabilistisch model van fonotaktiek, de verzameling van goed gevormde foneemsequenties in een taal. In tegenstelling tot de meeste computermodellen van fonotactiek (Hayes en Wilson, 2008; Goldsmith en Riggle, 2012), hanteren we een volledig generatieve benadering, waarbij we een proces modelleren waarbij vormen worden opgebouwd uit subdelen door fonologisch geïnformeerde structurenbouwoperaties. We leren een inventaris van subdelen door stochastische memoizatie toe te passen (Johnson et al., 2007; Goodman et al., 2008) op een generatief proces voor fonemen gestructureerd als en-of grafiek, gebaseerd op concepten van kenmerkhiërarchie uit generatieve fonologie (Clements, 1985; Dresher, 2009). Subonderdelen worden gecombineerd op een manier die tier-based feature interacties mogelijk maakt. We evalueren het vermogen van onze modellen om fonotactische distributies vast te leggen in lexicons van 14-talen die zijn getrokken uit het WOLEX corpus (Graff, 2012). Ons volledige model kent robuust hogere waarschijnlijkheid toe aan uitgestelde formulieren dan een geavanceerd N-gram model voor alle talen. We presenteren ook nieuwe analyses die modelgedrag gedetailleerder onderzoeken.', 'bg': 'Представяме вероятностен модел на фонотактиката, набор от добре оформени фонемни последователности в даден език. За разлика от повечето изчислителни модели на фонотактиката (Хейс и Уилсън, 2008; Голдсмит и Ригъл, 2012), ние възприемаме напълно генеративен подход, моделирайки процес, при който формите се изграждат от подпартове чрез фонологично информирани операции за изграждане на структури. Научаваме инвентаризация на подчасти чрез прилагане на стохастична мемоизация (Джонсън и др., 2007; Гудман и др., 2008) към генеративен процес за фонеми, структурирани като и-или графика, базиран на концепции за йерархия на характеристиките от генеративната фонология (Клементс, 1985; Дрешър, 2009). Подчасти се комбинират по начин, който позволява взаимодействия с функциите въз основа на нива. Оценяваме способността на нашите модели да улавят фонотактични разпределения в лексиконите на 14 езика, извлечени от корпуса на WOLEX (Граф, 2012). Нашият пълен модел надеждно придава по-високи вероятности на задържаните формуляри от сложния модел за всички езици. Представяме и нови анализи, които изследват поведението на модела по-подробно.', 'de': 'Wir präsentieren ein probabilistisches Modell der Phonataktik, die Menge von gut geformten Phonem-Sequenzen in einer Sprache. Im Gegensatz zu den meisten Computermodellen der Phonataktik (Hayes und Wilson, 2008; Goldsmith und Riggle, 2012), verfolgen wir einen vollständig generativen Ansatz, indem wir einen Prozess modellieren, bei dem Formen aus Teilteilen durch phonologisch informierte Strukturbauoperationen aufgebaut werden. Wir lernen eine Bestandsaufnahme von Teilteilen durch Anwendung stochastischer Memoisierung (Johnson et al., 2007; Goodman et al., 2008) auf einen generativen Prozess für Phoneme, die als und-oder Graph strukturiert sind, basierend auf Konzepten der Merkmalshierarchie aus der generativen Phonologie (Clements, 1985; Dresher, 2009). Teilbereiche werden so kombiniert, dass tierbasierte Feature-Interaktionen möglich sind. Wir evaluieren die Fähigkeit unserer Modelle, phonotaktische Verteilungen in Lexikonen von 14-Sprachen aus dem WOLEX-Korpus zu erfassen (Graff, 2012). Unser Vollmodell weist aushaltenden Formularen robuste Wahrscheinlichkeiten zu als einem ausgeklügelten N-Gramm-Modell für alle Sprachen. Darüber hinaus stellen wir neuartige Analysen vor, die das Modellverhalten genauer untersuchen.', 'fa': 'ما یک مدل احتمالاتی از فونوتاکتیک را پیشنهاد می\u200cکنیم، مجموعه\u200cای از طرح\u200cهای فونیمی بسیار خوب در یک زبان. برخلاف بیشتر مدلهای محاسبات فونوتاکتیک (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), ما یک طریق کامل تولید کننده را می\u200cگیریم و یک فرایند را نمودار می\u200cکنیم که فرم\u200cها توسط عملیات ساختمان ساختمان\u200cهای ساختمان\u200cهای پونالوژیک از زیر بخش\u200cهای ساخته می\u200cشوند. ما یک اختراع زیر بخش\u200cها را با استفاده از یادآوری stochastic (Johnson et al., 2007; Goodman et al., 2008) به یک فرایند ژنترافی برای تلفن\u200cها که به عنوان یک و یا گراف ساخته شده\u200cاند یاد می\u200cگیریم، بر اساس مفهوم\u200cهایی از ویژه\u200cهای ویژه\u200cای از فنالوژی ژنترافی (Clements, 1985; Dresher, 2009). زیر بخش\u200cها به طریقی که اجازه می\u200cدهد تعامل\u200cهای ویژه\u200cهای بسته\u200cای را ترکیب کند. ما توانایی مدل\u200cهایمان را برای گرفتن توزیع\u200cهای فونوتاکتیک در لکسیکونهای ۱۴ زبان از کورپوس WOLEX (Graff, 2012) ارزیابی می\u200cکنیم. مدل کامل ما به شدت احتمال بالاتر برای شکل\u200cهای خارج از یک مدل N-گرم متفاوت برای همه زبانها تعیین می\u200cکند. ما همچنین تحلیل\u200cهای رمانی را پیشنهاد می\u200cکنیم که رفتار مدل را به جزئیات بیشتری تحقیق می\u200cکند.', 'id': 'Kami mempersembahkan model probabilis fonotaktik, set urutan fonem yang bentuk dengan baik dalam bahasa. Tidak seperti kebanyakan model komputasi fonotaktik (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), kami mengambil pendekatan yang sepenuhnya generatif, memmodelkan proses di mana bentuk dibuat dari subpartes oleh operasi pembangunan struktur yang diajarkan fonologi. Kami belajar inventaris subpart dengan menerapkan memoisasi stokastik (Johnson et al., 2007; Goodman et al., 2008) pada proses generatif untuk fonem yang strukturasi sebagai dan-atau grafik, berdasarkan konsep hierarki fitur dari fonologi generatif (Clements, 1985; Dresher, 2009). Subbagian bergabung dengan cara yang memungkinkan interaksi karakteristik berdasarkan tingkat. Kami mengevaluasi kemampuan model kita untuk menangkap distribusi fonotaktik dalam leksikon dari 14 bahasa yang dicat dari WOLEX corpus (Graff, 2012). Model penuh kita dengan kuat mengarahkan kemungkinan yang lebih tinggi untuk bentuk held-out daripada model N-gram sofistikasi untuk semua bahasa. Kami juga mempersembahkan analisis novel yang memeriksa perilaku model secara rinci.', 'sw': 'Tunaweza kuweka mfano wa picha za picha, seti ya mfululizo wa simu zilizotengenezwa vizuri kwa lugha. Tofauti na mifano mingi ya hisabati (Hayes na Wilson, 2008; Goldsmith na Riggle, 2012), tunachukua mbinu za kizalendo, tunaonyesha mchakato ambapo mifumo imetengenezwa kutoka sehemu za chini na shughuli za ujenzi wenye ujuzi wa kiufundi. Tunajifunza orodha ya maeneo ya chini kwa kutumia ujumbe wa ufundi (Johnson et al., 2007; Goodman et al., 2008) kwa mchakato wa jeneral wa simu zilizotengenezwa kama picha na-au-picha, kwa kutumia dhana za ubunifu wa ubunifu kutoka kwenye simu za viwanda (Clements, 1985; Dresher, 2009). Vitu vya chini viunganishwa kwa njia ambayo inaruhusu mahusiano yenye msingi. Tunatathmini uwezo wa mifano yetu wa kuchukua usambazaji wa simu katika lugha 14 zilizotengenezwa kutoka kwenye makampuni ya WOLEX (Graff, 2012). Mfano wetu kamili unaweka uwezekano mkubwa wa kuweka viumbe vinavyotengenezwa zaidi ya mtindo wa N-gram kwa lugha zote. Pia tunaweka uchambuzi wa riwaya ambao unajaribu tabia za mifano kwa kina zaidi.', 'ko': '우리는 음성 전략의 확률 모델, 즉 언어에서 양식이 좋은 음소 서열집을 제시했다.대부분의 음성 전술의 계산 모델과 달리(Hayes와 Wilson, 2008; Goldsmith와 Riggle, 2012) 우리는 완전히 생성된 방법으로 하나의 과정을 모델링하고 이 과정에서 음성 정보 구조 구축 조작을 통해 하위 부분에서 형식을 구축한다.우리는 랜덤 메모리(Johnson et al., 2007; Goodman et al., 2008)를 and 또는 그림으로 구성된 음소의 생성 과정에 응용하여 하위 부분의 목록을 배운다. 이것은 생성 음위학에서의 특징 차원 개념(Clements, 1985; Dresher, 2009)을 바탕으로 한다.하위 부품의 조합 방식은 층을 바탕으로 하는 기능 상호작용을 허용한다.우리는 WOLEX 자료 라이브러리에서 추출한 14개 언어의 어휘에서 음성 분포를 포착하는 모델(Graff, 2012)을 평가했다.모든 언어에 대해 복잡한 N-gram 모델에 비해 우리의 전체 모델은 형식을 유지하기 위해 더욱 높은 확률을 분배할 수 있다.우리는 또 새로운 분석을 제기하여 모델 행위를 더욱 상세하게 탐지했다.', 'af': "Ons stel 'n waarskynlik model van fonotaktiek, die stel van goed formeerde foneme sekwensies in 'n taal. Ongelyks soos die meeste rekenaasjonale modele van fonotaktiek (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), neem ons 'n volledige genereerbare toegang, modelleer 'n proses waar vorms uit subdele gebou word deur fonologies-inligbare strukturebou operasies. Ons leer 'n inventorie van subdele deur die toepassing van stochastic memoisation (Johnson et al., 2007; Goodman et al., 2008) tot 'n genereerbare proses vir fonemes structureerde as 'n en-of graf, gebaseer op konsepte van funksiehierarkie van genereerbare fonologie (Clements, 1985; Dresher, 2009). Subdele word gekombineer in 'n manier wat toelaat tier-gebaseerde funksie interaksies. Ons evalueer ons model se moontlikheid om fonotaktiese verspreidings in die leksikone van 14 tale van die WOLEX corpus (Graff, 2012) te vang. Ons volle model stel kragtig hoër waarskynlikheite toe om uit te hou vorms as 'n sofistike N-gram model vir alle tale. Ons stel ook novele analiseer wat model gedrag probeer in meer detail.", 'sq': 'We present a probabilistic model of phonotactics, the set of well-formed phoneme sequences in a language.  Ndryshe nga shumica e modeleve kompjuterike të fonotaktikës (Hayes dhe Wilson, 2008; Goldsmith dhe Riggle, 2012), ne marrim një qasje krejtësisht gjenerative, duke modeluar një proces ku format janë ndërtuar nga nënpjesë nga operacionet e ndërtimit të strukturave me informacion fonologjik. Ne mësojmë një inventar të subparteve duke aplikuar përkujtimin stokastik (Johnson et al., 2007; Goodman et al., 2008) në një proces gjenerativ për fonema të strukturuar si një dhe-apo grafik, bazuar në konceptet e hierarkisë së karakteristikave nga fonologjia gjenerative (Clements, 1985; Dresher, 2009). Subpjesët janë të kombinuara në një mënyrë që lejon ndërveprime me karakteristika bazuar në nivele. Ne vlerësojmë aftësinë e modeleve tona për të kapur shpërndarjet fonotaktike në lexikonet e 14 gjuhëve të vizatuara nga korpusi WOLEX (Graff, 2012). Modeli ynë i plotë cakton me forcë probabilitete më të larta për format e mbajtura jashtë se një model i sofistikuar N-gram për të gjitha gjuhët. Ne gjithashtu paraqesim analiza të reja që analizojnë sjelljen e modelit në më shumë detaje.', 'tr': 'Biz fonotaktikleriň muhtemelen nusgasyny, gowy döredilen fonem dizirlerini bir dilde görkezip bileris. Fonetikleriň köp sany kompýuter modelleri ýaly (Hayes we Wilson, 2008; Goldsmith we Riggle, 2012), fonolojik bilen bilgili struktur binary operasiýalaryndan döredilýän çykyş şeklinde çykyp barýarys. Biz stohattiki memoýazyýa (Johnson et al., 2007; Goodman et al., 2008) fonemeler üçin döredijili bir ýa-ýa graf ýaly düzümlenmiş işleýän işleýän işleýän işleýän ilatyň hijerarhiýasyna daýan ýarlar (Clements, 1985; Dresher, 2009). Sahypalar çykyşlyklary baglaýyşlarda täsirleşmelere mümkin edýän bir şekilde birleştirilýär. WOLEX corpus (Graff, 2012) tarapyndan çykan 14 diller leksiýasynda fonotik daýlamak ukyplarymyzy çykýarys. Biziň doly nusgamyz ähli diller üçin sofistikli N-gram nusgasyndan ýokary çykmak mümkinçiliklerini bejerýär. Biz hem nowella çözümlerini nusga edip, nusga davranışyny biraz detaylarda süýseýäris.', 'am': 'በቋንቋ የተደረገውን የፎኖቶክቲ ምሳሌ እናቀርባለን፡፡ ፎኖቶክቲክ (Hayes እና Wilson 2008; ጎልድሳቲ እና ሪggle 2012) በተለየ ብዙዎቹ የፎቶክቲክ ዓይነቶች በፎሎጂ ተሳሳይ የግንኙነት አካባቢ አካባቢዎች የሚደረጉትን ፍጥረት እናሳውቃለን፡፡ አዋጅ ፎሎጂ (ካሌንቲ፣ 1985፣ አሜሪክ፣ 2009) በተመሠረተ የፎፎፎች እና-ወይም-graph የተመሠረተውን የደብዳቤ ክፍል ማርከናል፡፡ ጥያቄ የፎቶቶክቲካዊ አካውንት በ14 ቋንቋዎች ላይ በመያዝ የሞዴላዎቻችንን ኃይል እናስተዋልታለን፡፡ ሙሉ ሞዴል በሙሉ ለቋንቋዎች ሁሉ ከንፍቅለ N-gram ሞዴል በላይ የሚደረገውን የክፍልፍሎች ማቀናቀል ነው፡፡ የአሁኑን አረንጓዴ አስተያየት እናሳየዋለን፡፡', 'hy': 'Մենք ներկայացնում ենք ֆոնոտակտիկայի հավանական մոդել, լավ ձևավորված հեռախոսների հաջորդականությունների համակարգը լեզվով: Ի տարբերություն ֆոնոտակտիկայի հաշվարկների մեծ մասի մոդելներին (Հեյսը և Վիլսոնը, 2008 թվականը, Գոլդսմիթը և Ռիգլը, 2012 թվականը), մենք կիրառում ենք ամբողջովին սերունդային մոտեցում, մոդելավորելով մի գործընթաց, որտեղ ձևերը կառուցվում են ենթամասերի Մենք սովորում ենք ենթաբաժինների հուշումը, օգտագործելով ստոշատիկ հիշողությունը (Ջոնսոն և այլն., 2007; Գուդմանը և այլն., 2008) հեռախոսների սերունդային գործընթացի վրա, որը կառուցվում է որպես և-կամ գծագրություն, հիմնված սերունդային ֆոնոլոգիայի հատկանիշների հիերարխիայի գաղափարների վրա (Քլե Subparts are combined in a way that allows tier-based feature interactions.  Մենք գնահատում ենք մեր մոդելների կարողությունը ձայնագրել ֆոնոտակտիկ տարածումները 14 լեքսի լեքսիկոններում, որոնք պատկերված են Ուոլեքսի կորպոսից (Graf, 2012). Մեր ամբողջ մոդելը ուժեղ հավանականություն է տալիս պահպանված ձևերին, քան բարդ N-գրամ մոդելը բոլոր լեզուների համար: Մենք նաև ավելի մանրամասն ներկայացնում ենք նոր վերլուծություններ, որոնք ուսումնասիրում են մոդելի վարքագիծը:', 'az': 'Biz fonotaktikaların mümkün olduğu bir modelini göstəririk, çox güclü fonema sıralarının bir dildə. Çox fonotaktik modellərin (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012) kimi, fonolojik bilgili struktur inşaatı işləri ilə formların altkı parçalarından inşa edildiyi bir proses modellendiririk. Biz Stochastic Memorization (Johnson et al., 2007; Goodman et al., 2008) ilə əsas bölümlərin icazəsini öyrənirik, genital fonoloji (Clements, 1985; Dresher, 2009). Üstbölümlər bağlı özelliklərin müxtəlif əlaqələrinə imkan verən bir yolla birləşdirilmişdir. Biz modellərimizin WOLEX corpus (Graff, 2012) tərəfindən çəkilmiş 14 dillərin leksikonlarında fonotaktik dağıtılması bacarılığını değerlendiririk. Bizim bütün modellərimiz bütün dillər üçün sofistikli N-gram modelindən daha yüksək mümkünlükləri verir. Biz həmçin in modellərin davranışlarını daha detaylı təsdiqləyən yeni analizi də göstəririk.', 'ca': "Presentam un model probabilista de fonotactica, un conjunt de seqüències fonèmiques ben formades en un llenguatge. A diferència de la majoria dels models computacionals de fonotactica (Hayes i Wilson, 2008; Goldsmith i Riggle, 2012), fem un enfocament plenament generador, modelant un procés en què les formes estan construïdes de subpartits per operacions de construcció d'estructures fonològicament informades. Aprenem un inventari de subpartits aplicant la memòria stocàstica (Johnson et al., 2007; Goodman et al., 2008) a un procés generador de fonemes estructurats com a gràfic, basat en conceptes de jerarquia de característiques de fonologia generativa (Clements, 1985; Dresher, 2009). Les subparts es combinan d'una manera que permet interaccions de característiques basades en nivells. We evaluate our models' ability to capture phonotactic distributions in the lexicons of 14 languages drawn from the WOLEX corpus (Graff, 2012).  El nostre model complet assenya fortament més probabilitats a formes que un sofisticat model de N-gram per a totes les llengües. També presentem noves anàlisis que sonden el comportament del model en més detall.", 'bs': 'Predstavljamo vjerojatni model fonotaktike, set dobro formiranih telefonske sekvence na jeziku. Za razliku od većine računalnih modela fonotaktike (Hayes i Wilson, 2008; Goldsmith i Riggle, 2012), poduzimamo potpuno generativni pristup, modelirajući proces u kojem se oblici izgradi iz poddijela fonološki informiranim strukturnim operacijama. Naučimo inventar poddijelova primjenjivanjem stokastične memorizacije (Johnson et al., 2007; Goodman et al., 2008) na generativni proces za telefone strukturirane kao i-ili graf, na osnovu koncepta hijerarhije karakteristike iz generativne fonologije (Clements, 1985; Dresher, 2009). Poddijelovi su kombinirani na način na koji omogućava interakcije na temelju linije. Procjenjujemo sposobnost naših modela da uhvatimo fonotaktičke distribucije u leksionima od 14 jezika izvedenih iz WOLEX korpusa (Graff, 2012). N a š puni model je čvrsto odredio veće mogućnosti za održavanje oblika nego sofisticirani model N-gram a za sve jezike. Također predstavljamo i romanske analize koje su modele sonde detaljnije ponašanje.', 'bn': 'আমরা একটি সম্ভাব্য ফোনোটাক্টিক মডেল উপস্থাপন করি, ভাষায় ভাষায় ভালোভাবে তৈরি করা ফোনেমের সেট। ফোনোটাক্টিকের বেশীরভাগ গণনামূলক মডেল (হেইস এবং উইলসন, ২০০৮; গোল্ডমিথ এবং রিগেল, ২০১২), আমরা একটি পুরো জেনারেটিভ পদ্ধতি নিয়ে যাচ্ছি, যেখানে ফোলোজিকাল-তথ্য জান আমরা স্টোক্যাস্টিক্যাস্টিক মেমোমোজেশন (জন্সনেট আল, ২০০৭; গুডম্যান এন্ট আল., ২০০৮) এর একটি জেনারেটিভ প্রক্রিয়া শিখি জেনারেটিভ ফোনেম হিয়ারেক্সি থেকে জেনারেটিভ ফোনেজিয়ার (ক্ল সাবপার্টগুলোকে একত্রিত করা হয়েছে যেভাবে টায়ার ভিত্তিক বৈশিষ্ট্যের ইন্টারেকশন অনুমতি দেয়। ওয়ালেক্স কোর্পাস (গ্রাফ, ২০১২) থেকে আঁকা ১৪ ভাষার লেক্সিকোর লেক্সিকোন ভাষায় আমাদের মডেলের ফোনোটাক্যাক্টিক বিত আমাদের পুরো মডেল রাস্তার সাথে সকল ভাষার চেয়ে বেশী সম্ভাবনা রাখার চেয়ে বেশী সম্ভাবনা দিয়েছে। আরো বিস্তারিত ভাবে আমরা উপস্থাপন করি উপন্যাস বিশ্লেষণ যা প্রকাশ করা মডেল আচরণ।', 'cs': 'Představujeme pravděpodobnostní model fonotaktiky, soubor dobře formovaných fonémových sekvencí v jazyce. Na rozdíl od většiny výpočetních modelů fonotaktiky (Hayes a Wilson, 2008; Goldsmith a Riggle, 2012), používáme plně generativní přístup, modelování procesu, kdy jsou formy budovány z podčástí fonologicky informovanými operacemi budování struktur. Seznam dílčích částí se naučíme aplikací stochastické memoizace (Johnson et al., 2007; Goodman et al., 2008) na generační proces fonémů strukturovaný jako a-nebo graf, založený na koncepcích hierarchie znaků z generativní fonologie (Clements, 1985; Dresher, 2009). Dílčí části jsou kombinovány způsobem, který umožňuje interakce funkcí založené na úrovních. Hodnotíme schopnost našich modelů zachytit fonotaktické distribuce v lexikonech 14-jazyků čerpaných z korpusu WOLEX (Graff, 2012). Náš plný model robustně přiřazuje vyšší pravděpodobnosti než sofistikovaný N-gram model pro všechny jazyky. Dále představujeme nové analýzy, které podrobněji zkoumají chování modelu.', 'et': 'Esitleme fonotaktika tõenäosuslikku mudelit, hästi vormistatud foneemide järjestuste komplekti keeles. Erinevalt enamikust fonotaktika arvutuslikest mudelitest (Hayes ja Wilson, 2008; Goldsmith ja Riggle, 2012), kasutame täielikult generatiivset lähenemisviisi, modelleerides protsessi, kus vormid ehitatakse fonoloogiliselt teadlike struktuuride ehitamise operatsioonide abil alamosadest. Me õpime alamosade loetelu, rakendades stohhastilist memotisatsiooni (Johnson et al., 2007; Goodman et al., 2008) foneemide generatiivsele protsessile, mis on struktureeritud ja-või graafikuna, põhineb funktsioonide hierarhia kontseptsioonidel generatiivsest fonoloogiast (Clements, 1985; Dresher, 2009). Alaosad on kombineeritud viisil, mis võimaldab tasandipõhist funktsioonide interaktsiooni. Hindame oma mudelite võimet jäädvustada fonotaktilisi jaotusi WOLEXi korpusest koostatud 14 keele leksikonides (Graff, 2012). Meie täielik mudel määrab kindlalt kõrgemad tõenäosused väljajäetud vormidele kui keerukas N-grammi mudel kõigile keeltele. Samuti esitame uudseid analüüse, mis analüüsivad üksikasjalikumalt mudeli käitumist.', 'fi': 'Esitämme fonotaktiikan todennäköisyysmallin, joka on hyvin muodostettujen foneemien sarja kielellä. Toisin kuin useimmat fonotaktiikan laskennalliset mallit (Hayes ja Wilson, 2008; Goldsmith ja Riggle, 2012), otamme täysin generatiivisen lähestymistavan mallintaen prosessia, jossa muotoja rakennetaan alataiteista fonologisesti tietoisen rakennerakentamisen avulla. Opimme alalukujen inventaarion soveltamalla stokastista memoizaatiota (Johnson et al., 2007; Goodman et al., 2008) foneemien generatiiviseen prosessiin, joka perustuu ominaisuuksien hierarkian käsitteisiin generatiivisesta fonologiasta (Clements, 1985; Dresher, 2009). Alaosat yhdistetään siten, että tasoon perustuva ominaisuusvuorovaikutus on mahdollista. Arvioimme malliemme kykyä tallentaa fonotaktisia jakaumia WOLEX-korpusesta otetuissa 14 kielen sanastoissa (Graff, 2012). Täydellinen mallimme määrittää kestävästi suurempia todennäköisyyksiä käyttämättömille lomakkeille kuin hienostunut N-gram-malli kaikille kielille. Esittelemme myös uusia analyysejä, jotka tutkivat mallin käyttäytymistä tarkemmin.', 'ha': "Tuna sami wani misali mai yiwuwa na'urar fonotafaki, da daidaita sautin da aka samar da shi a harshe. Di motsi da masu ƙidãya masu motsi na fonotactics (hayes and Willson, 2009; Goldingmith da Riggle, 2012), za'a sami wata hanyoyi mai kamfata, ko kuma za'a sami wani jarrabi wanda aka samar da fonotactics daga ƙarƙashin firam na samar da firam masu da aka sanar da folojiogi. Tuna sanar wani jarrabi na sub-shekarar da za'a yi amfani da kwamfyutan memoization (Joson et al., 2007; Google da al., 2008) zuwa wani jarrabo na daban-fi wanda aka samar da su kamar wani na'ura ko-grafi, a kan karatun misãlai na zaɓen hisarirchy daga jenataccen folojiya (Clear ments, 1985; dresher, 2009). An haɗa kayan ƙanshi da wani hanya wanda ke yarda da interaction masu da aka ƙayyade baka. Tuna ƙaddara awon misalinmu da za'a sami rabon da fonotactic cikin littafan 14 lugha wanda aka samu daga nau'in WOLEX (Graff, 2012). Mataimakinmu cikakken ayuka na buga misãlai da za'a sami sauri ko wani misalin na N-gram ko duk harshe. Kayya, Munã halatar da rabon nan da ke samun misalin misalin misãlai masu bayyani.", 'sk': 'Predstavljamo verjetnostni model fonotaktike, nabor dobro oblikovanih fonemskih sekvenc v jeziku. Za razliko od večine računalniških modelov fonotaktike (Hayes in Wilson, 2008; Goldsmith in Riggle, 2012), uporabljamo popolnoma generativen pristop, modeliramo proces, v katerem se oblike gradijo iz poddelkov s fonološko informiranimi operacijami gradnje struktur. Popis poddelkov se naučimo z uporabo stohastične memoizacije (Johnson et al., 2007; Goodman et al., 2008) v generativnem procesu za fonome strukturirane kot in-ali graf, ki temelji na konceptih hierarhije značilnosti iz generativne fonologije (Clements, 1985; Dresher, 2009). Poddeli so združeni na način, ki omogoča interakcije funkcij na podlagi stopenj. Ocenjujemo sposobnost naših modelov zajemanja fonotaktičnih distribucij v leksikonih 14 jezikov iz korpusa WOLEX (Graff, 2012). Naš celoten model zanesljivo dodeljuje večje verjetnosti obrazcem, ki so bile zaprte, kot prefinjen model N-gramov za vse jezike. Predstavljamo tudi nove analize, ki podrobneje preučujejo vedenje modelov.', 'jv': "Awak dhéwé éntuk sistem sing perbudhakan kanggo nyengkapungkat, gawe nguasah barang kelangan seneng nggawe barang. Ayo nganggo akeh model komputasi sing sampeyan akeh(Hayes and Wilon, 2008; golsmth and Right gle, 2013), awake dhéwé wis ngeraké kesempatan akeh Generative, model sing perusahaan Where's the shape are to be rebuted out of Subparts by mobile-informated structural operation. Awak dhéwé mulai kapan-kapan sing nggawe nguasai perusahaan kelangan stokastik (Jonathan et al, 2007; GOman et al, 2008) nggawe kapan-kapan sistem kanggo kelangan kelangan karo kapan-oban, siji supoyata sakjane perusahaan kelangan karo kelangan kelangan sakjane kapan-kapan (CLments, 1997; Drash, 2008). section Awak dhéwé éntuk nggawe modèl kanggo nggawe Distribusi Fotoktik nang angkang 14 luwih basa sing dibaké WOlex corpus (Graff, 12). Monday Awak dhéwé éntuk éntuk pernik wayah kanggo nyelaran modèl kanggo nyelaran ning tinimbang.", 'he': 'אנחנו מציגים מודל סיכוי של פונוטקטיקה, קבוצת רצפי טלפונים מובנים היטב בשפה. בניגוד לרוב הדוגמנים מחשביים של פונוטקטיקה (הייס וילסון, 2008; גולדסמית וריגל, 2012), אנו לוקחים גישה לגמרי דולרית, דוגמנים תהליך שבו טופסים נבנים מתחתונים על ידי פעילות בניית מבנים מוודעים פונולוגית. אנחנו לומדים מלאי של חלקים על ידי השימוש של זיכרון סטוקסטי (Johnson et al., 2007; Goodman et al., 2008) לתהליך דורי לפונמות מבוססת בתור וגרף, מבוסס על מושג הייררכיה של תכונות מהפונולוגיה דורית (Clements, 1985; Dresher, 2009). התחלקים משולבים בדרך שמאפשרת אינטראקציות תכונות מבוססות על קומה. אנו מעריכים את היכולת של הדוגמנים שלנו לתפוס פיצוצים פונוטקטיים בלקסיקונים של 14 שפות מצוירות מהוולקס קורפוס (Graff, 2012). המודל המלא שלנו מחזיק באופן חזק סבירות גבוהות יותר לצורות מחוסרות מאשר מודל N-גרם מתוחכם לכל השפות. אנחנו גם מציגים ניתוחים חדשים שמחקרים התנהגות מודל בפרטים יותר.', 'bo': "ང་ཚོས་སྐད་ཡིག་གི་ཆེས་མཁན་གཟུགས་རིས་ཀྱི་མ་དཔེ་ལུགས་ཅིག་ལྟ་བུ་ཡོད། Unlike most computational models of phonotactics (Hayes and Wilson, 2008; Goldsmith and Riggle, 2012), we take a fully generative approach, modeling a process where forms are built up out of subparts by phonologically-informed structure building operations. We learn an inventory of subparts by applying stochastic memoization (Johnson et al., 2007; Goodman et al., 2008) to a generative process for phonemes structured as an and-or graph, based on concepts of feature hierarchy from generative phonology (Clements, 1985; Dresher, 2009). རྒྱབ་ཆ་ཤས་གཅིག་མཐུན་ཡོད་པའི་ཁྱད་ཆོས་ཀུན་ལ་མཉམ་དུ་བསྡུར་བྱེད་ཀྱི་ཡོད། We evaluate our models' ability to capture phonotactic distributions in the lexicons of 14 languages drawn from the WOLEX corpus (Graff, 2012). ང་ཚོའི་མ་དབྱིབས་ཡུལ་གྱིས་སྒྲིག་ཆ་ཡོད་པ་བརྟན་པར་མཐུན་རྐྱེན་ཚད་མང་ཙམ་འཛུགས་ཡོད་པ་ལས་སྒྲིག་ཆ་ཡོད། ང་ཚོས་གསར་གཏོད་ཁང་དེ་ལ་མིག་གཟུགས་རིས་ལག་ལེན་བྱེད་པའི་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཡོད།"}
{'en': 'Context Gates for Neural Machine Translation', 'ar': 'بوابات السياق للترجمة الآلية العصبية', 'fr': 'Portes contextuelles pour la traduction automatique neuronale', 'pt': 'Portões de contexto para tradução automática neural', 'es': 'Puertas de contexto para la traducción automática neuronal', 'ja': '神経機械翻訳のためのコンテキストゲート', 'zh': '用神经机器翻译上下文门', 'ru': 'Контекстные ворота для нейронного машинного перевода', 'hi': 'न्यूरल मशीन अनुवाद के लिए संदर्भ गेट्स', 'ga': 'Comhthéacs Geataí don Aistriúchán Meaisín Néarach', 'ka': 'Name', 'el': 'Πύλες περιβάλλοντος για τη νευρωνική μηχανική μετάφραση', 'hu': 'Kontextus kapuk az idegi gépi fordításhoz', 'it': 'Porte di contesto per la traduzione automatica neurale', 'kk': 'Нейрондық машинаның аудармасының контексттік шлюздері', 'mk': 'Контекстни порти за превод на неврални машини', 'ms': 'Gerbang Konteks untuk Terjemahan Mesin Neural', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിനുള്ള ഉള്ളിലുള്ള ഗേറ്റുകള്\u200d', 'mn': 'Сэтгэл машины хөгжлийн контекст хаалтууд', 'no': 'Comment', 'pl': 'Bramy kontekstowe dla neuronowego tłumaczenia maszynowego', 'ro': 'Porți de context pentru traducerea automată neurală', 'lt': 'Neuralinių mašinų vertimo konteksto vartai', 'sr': 'Kontekstne kapije za neuronski prevod mašine', 'si': 'Name', 'mt': 'Portijiet ta’ Kuntest għat-Traduzzjoni ta’ Magni Newrali', 'sv': 'Kontextportar för neural maskinöversättning', 'ta': 'Name', 'ur': 'نیورال ماشین ترجمہ کے لئے کنٹکسٹ گیٹ', 'so': 'Turjumidda qoraalka ee gudaha ah', 'uz': 'Tarjima qilish vositasiName', 'vi': 'Cánh cổng ngữ học cho máy thần kinh', 'bg': 'Контекстни врати за неврален машинен превод', 'da': 'Kontekstporte til neural maskinoversættelse', 'nl': 'Contextpoorten voor neuronale machinevertaling', 'ko': '신경기계 번역의 어경문', 'de': 'Kontext-Gates für neuronale maschinelle Übersetzung', 'sw': 'Picha za Mitandao kwa Tafsiri ya Mashine ya Njerumani', 'id': 'Gates Konteks untuk Translation Mesin Neural', 'tr': 'Neural Maşynyň terjimesine üçin Kontekst Jaňlary', 'af': 'Konteks Poorte vir Nural Masjien Vertaling', 'hr': 'Kontekstne vrata za neuronski prevod strojeva', 'fa': 'دروازه\u200cهای محیط برای ترجمه ماشین عصبی', 'am': 'ትርጉም', 'hy': 'Նյարդային մեքենայի թարգմանման կոնտեքստ դարպասները', 'bs': 'Kontekstne kapije za neuronski prevod mašine', 'bn': 'নিউরাল মেশিন অনুবাদের জন্য বিভিন্ন গেট', 'cs': 'Kontextové brány pro neuronový strojový překlad', 'sq': 'Context Gates for Neural Machine Translation', 'az': 'Nöral Makin Çeviri üçün Kontekst Qapıları', 'ca': 'Portes de Context per a la traducció de màquines neuronals', 'fi': 'Kontekstiportit neurokäännökselle', 'et': 'Neuraalse masintõlke kontekstiväravad', 'jv': 'context-action', 'ha': '@ action', 'sk': 'Kontekstna vrata za živčni strojni prevod', 'he': 'Context Gates for Neural Machine Translation', 'bo': 'Neural Machine་ལུགས་སྐད་ཡིག་ཆས་མཐུན་སྣེ་ཚོགས'}
{'en': 'In neural machine translation (NMT), generation of a target word depends on both source and target contexts. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations. To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words. In this way, we can enhance both the adequacy and fluency of NMT with more careful control of the information flow from contexts. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.', 'ar': 'في الترجمة الآلية العصبية (NMT) ، يعتمد إنشاء كلمة مستهدفة على السياقات المصدر والهدف. نجد أن سياقات المصدر لها تأثير مباشر على كفاية الترجمة بينما السياقات المستهدفة تؤثر على الطلاقة. بشكل بديهي ، يجب أن يعتمد إنشاء كلمة محتوى بشكل أكبر على سياق المصدر ويجب أن يعتمد إنشاء كلمة وظيفية بشكل أكبر على السياق الهدف. نظرًا لعدم وجود سيطرة فعالة على التأثير من سياقات المصدر والهدف ، تميل NMT التقليدية إلى تقديم ترجمات بطلاقة ولكنها غير كافية. لمعالجة هذه المشكلة ، نقترح بوابات السياق التي تتحكم ديناميكيًا في النسب التي تساهم فيها سياقات المصدر والهدف في توليد الكلمات المستهدفة. بهذه الطريقة ، يمكننا تعزيز كفاية وطلاقة NMT مع مزيد من التحكم الدقيق في تدفق المعلومات من السياقات. تظهر التجارب أن نهجنا يتحسن بشكل كبير على نظام NMT القياسي القائم على الانتباه بمقدار +2.3 نقطة BLEU.', 'es': 'En la traducción automática neuronal (NMT), la generación de una palabra objetivo depende tanto del contexto de origen como del de destino. Descubrimos que los contextos de origen tienen un impacto directo en la adecuación de una traducción, mientras que los contextos de destino afectan a la fluidez. Intuitivamente, la generación de una palabra de contenido debe basarse más en el contexto de origen y la generación de una palabra funcional debe basarse más en el contexto de destino. Debido a la falta de control efectivo sobre la influencia de los contextos de origen y destino, la NMT convencional tiende a producir traducciones fluidas pero inadecuadas. Para abordar este problema, proponemos puertas de contexto que controlan dinámicamente las proporciones en las que los contextos de origen y destino contribuyen a la generación de palabras objetivo. De esta manera, podemos mejorar tanto la adecuación como la fluidez de la NMT con un control más cuidadoso del flujo de información de los contextos. Los experimentos muestran que nuestro enfoque mejora significativamente en un sistema NMT estándar basado en la atención en +2.3 puntos BLEU.', 'pt': 'Na tradução automática neural (NMT), a geração de uma palavra-alvo depende dos contextos de origem e de destino. Descobrimos que os contextos de origem têm um impacto direto na adequação de uma tradução, enquanto os contextos de destino afetam a fluência. Intuitivamente, a geração de uma palavra de conteúdo deve se basear mais no contexto de origem e a geração de uma palavra funcional deve se basear mais no contexto de destino. Devido à falta de controle efetivo sobre a influência dos contextos de origem e destino, a NMT convencional tende a produzir traduções fluentes, mas inadequadas. Para resolver este problema, propomos portas de contexto que controlam dinamicamente as proporções nas quais os contextos de origem e destino contribuem para a geração de palavras de destino. Dessa forma, podemos aprimorar tanto a adequação quanto a fluência do NMT com um controle mais cuidadoso do fluxo de informações dos contextos. Experimentos mostram que nossa abordagem melhora significativamente em um sistema NMT baseado em atenção padrão em +2,3 pontos BLEU.', 'fr': "Dans la traduction automatique neuronale (NMT), la génération d'un mot cible dépend à la fois du contexte source et du contexte cible. Nous constatons que les contextes sources ont un impact direct sur l'adéquation d'une traduction alors que les contextes cibles ont une incidence sur la fluidité. Intuitivement, la génération d'un mot de contenu doit reposer davantage sur le contexte source et la génération d'un mot fonctionnel doit reposer davantage sur le contexte cible. En raison de l'absence de contrôle efficace de l'influence des contextes source et cible, la traduction NMT conventionnelle tend à produire des traductions fluides mais inadéquates. Pour résoudre ce problème, nous proposons des portes contextuelles qui contrôlent dynamiquement les ratios auxquels les contextes source et cible contribuent à la génération de mots cibles. De cette façon, nous pouvons améliorer à la fois l'adéquation et la fluidité de la NMT en contrôlant plus soigneusement le flux d'informations provenant des contextes. Les expériences montrent que notre approche améliore de manière significative un système NMT basé sur l'attention standard de +2,3 points BLEU.", 'ja': 'ニューラルマシン翻訳（ ＮＭＴ ）では、ターゲットワードの生成は、ソースコンテキストとターゲットコンテキストの両方に依存する。ソースコンテキストは翻訳の妥当性に直接的な影響を及ぼし、ターゲットコンテキストは流暢性に影響を及ぼすことがわかります。直感的には、コンテンツワードの生成は、ソースコンテキストにより依存し、機能ワードの生成は、ターゲットコンテキストにより多く依存すべきである。ソースおよびターゲットコンテキストからの影響を効果的に制御できないため、従来のNMTは、流暢ではあるが不十分な翻訳を生み出す傾向がある。この問題に対処するために、ソースコンテキストとターゲットコンテキストがターゲット単語の生成に寄与する比率を動的に制御するコンテキストゲートを提案します。このようにして、コンテキストからの情報フローをより慎重に制御することで、NMTの妥当性と流暢性の両方を向上させることができます。実験は、標準的な注意に基づくNMTシステムでは、当社のアプローチが+2.3 BLEUポイントで大幅に改善されることを示しています。', 'ru': 'В нейронном машинном переводе (НМП) генерация целевого слова зависит как от исходного, так и от целевого контекстов. Мы обнаруживаем, что исходные контексты оказывают непосредственное влияние на адекватность перевода, в то время как целевые контексты влияют на беглость. Интуитивно генерация содержательного слова должна в большей степени опираться на исходный контекст, а генерация функционального слова должна в большей степени опираться на целевой контекст. Из-за отсутствия эффективного контроля над влиянием исходного и целевого контекстов, обычные НМТ, как правило, дают бегло, но неадекватные переводы. Для решения этой проблемы мы предлагаем контекстные шлюзы, которые динамически контролируют соотношения, при которых исходный и целевой контексты способствуют генерации целевых слов. Таким образом, мы можем повысить как адекватность, так и беглость НБ при более тщательном контроле потока информации из контекстов. Эксперименты показывают, что наш подход значительно улучшается по сравнению со стандартной системой НМТ, основанной на внимании, на +2,3 балла БЛЮ.', 'zh': '神经机器翻译 (NMT) 之中,单词生决于上下文上下文。 见源上下文有径充分性,而趋上下文会有流畅性。 直观曰:单词生益多赖于源上下文,而功成宜益资于上下文。 无对源上下文上下文制,旧 NMT 往往流利而不足译者。 为此者,举上下文门,动控制源上下文趋上下文有助于成单词者也。 以此观之,可以细制上下文信息流以强NMT之充分性流畅性。 实验明于意力之准NMT系统之本显于+2.3 BLEU。', 'hi': 'न्यूरल मशीन अनुवाद (NMT) में, एक लक्ष्य शब्द की पीढ़ी स्रोत और लक्ष्य संदर्भों दोनों पर निर्भर करती है। हम पाते हैं कि स्रोत संदर्भों का अनुवाद की पर्याप्तता पर सीधा प्रभाव पड़ता है जबकि लक्ष्य संदर्भ प्रवाह को प्रभावित करते हैं। Intuitively, एक सामग्री शब्द की पीढ़ी स्रोत संदर्भ पर अधिक भरोसा करना चाहिए और एक कार्यात्मक शब्द की पीढ़ी लक्ष्य संदर्भ पर अधिक भरोसा करना चाहिए। स्रोत और लक्ष्य संदर्भों से प्रभाव पर प्रभावी नियंत्रण की कमी के कारण, पारंपरिक एनएमटी धाराप्रवाह लेकिन अपर्याप्त अनुवाद उत्पन्न करता है। इस समस्या को हल करने के लिए, हम संदर्भ द्वारों का प्रस्ताव करते हैं जो गतिशील रूप से उन अनुपातों को नियंत्रित करते हैं जिन पर स्रोत और लक्ष्य संदर्भ लक्ष्य शब्दों की पीढ़ी में योगदान करते हैं। इस तरह, हम संदर्भों से सूचना प्रवाह के अधिक सावधानीपूर्वक नियंत्रण के साथ एनएमटी की पर्याप्तता और प्रवाह दोनों को बढ़ा सकते हैं। प्रयोगों से पता चलता है कि हमारा दृष्टिकोण +2.3 BLEU अंकों द्वारा एक मानक ध्यान-आधारित NMT प्रणाली पर काफी सुधार करता है।', 'ga': 'San aistriúchán meaisín néarach (NMT), braitheann giniúint sprice ar an bhfoinse agus ar na comhthéacsanna sprice. Faighimid amach go mbíonn tionchar díreach ag comhthéacsanna foinse ar leorgacht an aistriúcháin agus go mbíonn tionchar ag sprioc-chomhthéacsanna ar an líofacht. Go hintinneach, ba cheart go mbeadh giniúint focal ábhair ag brath níos mó ar an gcomhthéacs foinseach agus ba cheart go mbeadh giniúint focal feidhmiúil ag brath níos mó ar an sprioc-chomhthéacs. Mar gheall ar an easpa smachta éifeachtach ar an tionchar ó chomhthéacsanna foinse agus sprice, is gnách go mbíonn aistriúcháin líofa ach neamhleor ar fáil ag NMT traidisiúnta. Chun aghaidh a thabhairt ar an bhfadhb seo, molaimid geataí comhthéacs a rialaíonn go dinimiciúil na cóimheasa ag a gcuidíonn comhthéacsanna foinse agus sprice le giniúint spriocfhocail. Ar an mbealach seo, is féidir linn leorgacht agus líofacht NMT a fheabhsú trí rialú níos cúramaí a dhéanamh ar an sreabhadh faisnéise ó chomhthéacsanna. Léiríonn turgnaimh go dtagann feabhas suntasach ar ár gcur chuige ar chóras caighdeánach NMT atá bunaithe ar aird faoi +2.3 pointe BLEU.', 'ka': 'ნეიროლური მაქინის გარგზავნა (NMT) სხვადასხვა სიტყვის განვითარება იყოს ორივე მხოლოდ და მიზემის კონტექსტზე. ჩვენ აღმოჩნეთ, რომ ფონტექსტის კონტექსტი აქვს მიერ ექსტური ექსტური შედეგების შესაძლებლობა, როცა მიზემი კონტექსტი შეეძლება ფუ ინტევიტიურად, შემდგომარების სიტყვას უნდა უფრო მეტი დარწმუნოთ ფუნქციური სიტყვას და ფუნქციური სიტყვას შემდგომარებაზე. ეფექტიური კონტროლის არსებობის გამოიყენება მისამართებული კონტექსტიდან და მისამართებული კონტექსტიდან, კონტრაციონალური NMT უნდა მიიღება ფუნქტიური, მა ამ პრობლემას გარეშე, ჩვენ მივიღებთ კონტექსტური დარებები, რომლებიც დინამიკურად კონტროლისთვის კონტროლისთვის, რომლებიც მიზეზი და მიზეზი კონ ასე, ჩვენ შეგვიძლია NMT-ის შესაძლებლობა და სინამდვილეობა უფრო დარწმუნებელია ინფორმაციის გარგება კონტექსტებისგან. Experiments show that our approach significantly improves on a standard attention-based NMT system by +2.3 BLEU points.', 'el': 'Στην νευρωνική μηχανική μετάφραση, η δημιουργία μιας λέξης-στόχου εξαρτάται τόσο από το πλαίσιο προέλευσης όσο και από το πλαίσιο προορισμού. Διαπιστώνουμε ότι τα πλαίσια πηγής έχουν άμεσο αντίκτυπο στην επάρκεια μιας μετάφρασης ενώ τα πλαίσια στόχων επηρεάζουν την ευχέρεια. Διαισθητικά, η δημιουργία μιας λέξης περιεχομένου θα πρέπει να βασίζεται περισσότερο στο πλαίσιο προέλευσης και η δημιουργία μιας λειτουργικής λέξης θα πρέπει να βασίζεται περισσότερο στο πλαίσιο προορισμού. Λόγω της έλλειψης αποτελεσματικού ελέγχου της επιρροής από τα πλαίσια προέλευσης και στόχου, η συμβατική ΜΤ τείνει να αποδίδει άπταιστες αλλά ανεπαρκείς μεταφράσεις. Για να αντιμετωπιστεί αυτό το πρόβλημα, προτείνουμε πύλες περιβάλλοντος που ελέγχουν δυναμικά τις αναλογίες στις οποίες τα πλαίσια προέλευσης και στόχου συμβάλλουν στη δημιουργία λέξεων-στόχων. Με αυτόν τον τρόπο, μπορούμε να ενισχύσουμε τόσο την επάρκεια όσο και την ευχέρεια της με πιο προσεκτικό έλεγχο της ροής πληροφοριών από τα πλαίσια. Τα πειράματα δείχνουν ότι η προσέγγισή μας βελτιώνεται σημαντικά σε σχέση με ένα τυποποιημένο σύστημα που βασίζεται στην προσοχή κατά +2.3 σημεία BLEU.', 'hu': 'A neurális gépi fordításban (NMT) a célszó generálása mind a forrás, mind a célkörnyezet függ. Úgy találjuk, hogy a forráskörnyezetek közvetlenül befolyásolják a fordítás megfelelőségét, míg a célkörnyezetek befolyásolják a folyékonyságot. Intuitív módon egy tartalmi szó létrehozásának inkább a forráskörzetre kell támaszkodnia, és egy funkcionális szó létrehozásának inkább a célkörnyezetre kell támaszkodnia. A forrás- és célkörnyezetből származó hatás hatékony ellenőrzésének hiánya miatt a hagyományos NMT folyékony, de nem megfelelő fordításokat eredményez. A probléma megoldására olyan kontextuskapukat javasolunk, amelyek dinamikusan szabályozzák azokat az arányokat, amelyekben a forrás- és célkontextusok hozzájárulnak a célszavak létrehozásához. Ily módon javíthatjuk az NMT megfelelőségét és folyékonyságát a kontextusokból származó információáramlás gondos ellenőrzésével. A kísérletek azt mutatják, hogy megközelítésünk jelentősen javul egy standard figyelem alapú NMT rendszeren +2,3 BLEU ponttal.', 'it': "Nella traduzione automatica neurale (NMT), la generazione di una parola target dipende sia dal contesto sorgente che dal contesto target. Troviamo che i contesti di origine hanno un impatto diretto sull'adeguatezza di una traduzione mentre i contesti target influenzano la fluidità. Intuitivamente, la generazione di una parola di contenuto dovrebbe basarsi maggiormente sul contesto di origine e la generazione di una parola funzionale dovrebbe basarsi maggiormente sul contesto di destinazione. A causa della mancanza di controllo efficace sull'influenza dai contesti sorgente e target, NMT convenzionale tende a produrre traduzioni fluenti ma inadeguate. Per affrontare questo problema, proponiamo porte di contesto che controllano dinamicamente i rapporti a cui i contesti sorgente e target contribuiscono alla generazione di parole target. In questo modo, possiamo migliorare sia l'adeguatezza che la fluidità del NMT con un controllo più attento del flusso di informazioni dai contesti. Gli esperimenti dimostrano che il nostro approccio migliora significativamente con un sistema NMT basato sull'attenzione standard di +2,3 punti BLEU.", 'kk': 'Невралдық компьютердің аудармасында (NMT) мақсатты сөзді құру көзі мен мақсатты контексттеріне тәуелді. Біз көздегі контексттердің аудармалардың адекциялығына тәжірибесін білеміз. Мақсатты контексттердің жылдамдығына әсер етеді. Интуитивті сөздің мазмұнын құру көзінің контексті және функциялық сөздің құрылуы мақсатты контекстіне көп тұру керек. Көзінен және мақсатты контекстерден ефективні басқару үшін, кәдімгі NMT көзінің көзі және басқа аудармалардың қасиеті жоқ сияқты, бірақ дұрыс емес аудармалары. Бұл мәселеге қатынау үшін, мәселелердің көзі мен мақсатты мәзірлерін динамикалық түрде бақылайтын контексттік қапшықтарын таңдаймыз. Бұл тәртіпте, NMT адекциялығын және жылдамдығын көптеген мәлімет жұмысын бақылауға болады. Тәжірибелер біздің тәсіліміздің стандартты назардағы NMT жүйесіне +2.3 BLEU нүктелерімен көп жақсы жасайды.', 'ml': 'ന്യൂറല്\u200d യന്ത്രത്തിന്റെ പരിഭാഷയില്\u200d, ലക്ഷ്യ വാക്കിന്റെ തലമുറയില്\u200d, സോര്\u200dസ്സും ലക്ഷ്യസ്ഥാനങ്ങളും ആശ്രയിക്കുന് നമുക്ക് കണ്ടെത്തുന്നത് സോര്\u200dസ് കോണ്\u200dട്ടെക്സ്റ്റുകള്\u200dക്ക് ഒരു പരിഭാഷണത്തിന്റെ മതിയായ പ്രഭാവം ഉണ്ടെന്നാണ്. ലക്ഷ ഒരു ഉള്ളിലുള്ള വാക്കിന്റെ തലമുറപ്പിന് സോര്\u200dസ് കെന്\u200dസ്റ്റെക്സ്റ്റോണ്\u200dട്ടിലും പ്രവര്\u200dത്തിക്കുന്ന വാക്കി സ്രോതസ്സില്\u200d നിന്നും ലക്ഷ്യത്തില്\u200d നിന്നും സ്വാഭാവികമായി നിയന്ത്രിക്കുന്നതിന്റെ പ്രഭാവം കാരണം സാധാരണ എംഎടിയില്\u200d നിന്നും വ ഈ പ്രശ്നത്തെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d പ്രായശ്ചിത്തം ചെയ്യുന്നു, അതിന്റെ വിഭവങ്ങള്\u200d നിയന്ത്രിക്കുന്നു. അത ഇങ്ങനെ നമുക്ക് വിവരങ്ങളുടെ വിവരങ്ങള്\u200d നിയന്ത്രിക്കുന്നതിനെക്കുറിച്ച് കൂടുതല്\u200d സൂക്ഷ്മമായി നിയന്ത്രിക്കാന്\u200d N പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു + 2. 3 ബിലിയു പോയിന്\u200dറുകള്\u200d കൊണ്ട് നമ്മുടെ സാധാരണ ശ്രദ്ധ കാണിക്കുന്നത്', 'ms': 'Dalam terjemahan mesin saraf (NMT), generasi kata sasaran bergantung pada konteks sumber dan sasaran. Kami mendapati bahawa konteks sumber mempunyai kesan langsung pada keperluan terjemahan sementara konteks sasaran mempengaruhi keseluruhan. Secara intuitif, generasi perkataan kandungan patut bergantung lebih pada konteks sumber dan generasi perkataan berfungsi patut bergantung lebih pada konteks sasaran. Kerana kekurangan kawalan yang efektif terhadap pengaruh dari konteks sumber dan sasaran, NMT konvensional cenderung untuk memberikan aliran tetapi tidak sesuai. Untuk mengatasi masalah ini, kami cadangkan gerbang konteks yang secara dinamik mengawal nisbah yang mana konteks sumber dan sasaran menyumbang kepada generasi kata sasaran. Dengan cara ini, kita boleh meningkatkan keperluan dan keseluruhan NMT dengan kawalan lebih berhati-hati aliran maklumat dari konteks. Eksperimen menunjukkan bahawa pendekatan kita meningkat dengan signifikan pada sistem NMT berdasarkan perhatian piawai dengan +2.3 titik BLEU.', 'mt': 'Fit-traduzzjoni tal-magna newrali (NMT), il-ġenerazzjoni ta’ kelma fil-mira tiddependi kemm fuq il-kuntesti tas-sors kif ukoll tal-mira. Aħna nsibu li l-kuntesti tas-sorsi għandhom impatt dirett fuq l-adegwatezza ta’ traduzzjoni filwaqt li l-kuntesti fil-mira jaffettwaw il-fluwenza. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context.  Minħabba n-nuqqas ta’ kontroll effettiv fuq l-influwenza mill-kuntesti tas-sors u tal-mira, l-NMT konvenzjonali għandhom it-tendenza li jagħtu traduzzjonijiet fluwenti iżda inadegwati. Biex nindirizzaw din il-problema, nipproponu portali ta’ kuntest li jikkontrollaw b’mod dinamiku l-proporzjonijiet li fihom il-kuntesti tas-sors u tal-mira jikkontribwixxu għall-ġenerazzjoni ta’ kliem fil-mira. B’dan il-mod, nistgħu nsaħħu kemm l-adegwatezza kif ukoll il-fluwenza tal-NMT b’kontroll aktar bir-reqqa tal-fluss tal-informazzjoni mill-kuntesti. L-esperimenti juru li l-approċċ tagħna jtejjeb b’mod sinifikanti fuq sistema NMT standard ibbażata fuq l-attenzjoni b’ +2.3 punti BLEU.', 'mn': 'НМТ-ийн мэдрэлийн машины хөрөнгө оруулалт зориулагдсан үг нь эх үүсвэр болон зориулагдсан нөхцөлд хамааралтай. Бид эх үүсвэрийн нөхцөл байдал нь хөрөнгө оруулалтын адилхан нөлөөтэй байдаг. Цагийн нөхцөл байдал нь шингэнд нөлөөлдөг. Үнэндээ, бүтээгдэхүүний үеийн төрөл нь функцийн үеийн эх үүсвэртэй байдалд илүү их хамаарах ёстой. Функцийн үеийн төрөл нь зорилготой байдалд илүү их хамаарах ёстой. Мөн эх үүсвэр болон зориулалтын нөлөө үзүүлэлтийн тулд үр дүнтэй удирдлагагүй учраас уламжлалтай NMT нь шингэн боловч бус орчуулалт гаргадаг. Энэ асуудлыг шийдэхийн тулд бид зорилготой үгнүүдийн үеэр нөхцөл болон зорилготой нөхцөл байдлыг динамик хэлбэрээр удирдах орчин хаалтын хаалтыг санал болгоно. Иймээс бид NMT-ийн адилхан болон шингэнийг илүү анхааралтай мэдээллийн урсгалыг нөхцөл байдлын тулд нэмэгдүүлж чадна. Түүнчлэл бидний арга хэмжээнд стандарт анхаарлын төвөгтэй NMT системийг +2.3 BLEU цэгээр нэмэгдүүлдэг гэдгийг харуулдаг.', 'pl': 'W neuronowym tłumaczeniu maszynowym (NMT) generowanie słowa docelowego zależy zarówno od kontekstu źródłowego, jak i docelowego. Stwierdzamy, że konteksty źródłowe mają bezpośredni wpływ na adekwatność tłumaczenia, natomiast konteksty docelowe wpływają na płynność tłumaczenia. Intuicyjnie generowanie słowa treści powinno opierać się bardziej na kontekście źródłowym, a generowanie słowa funkcjonalnego powinno opierać się bardziej na kontekście docelowym. Ze względu na brak skutecznej kontroli nad wpływem kontekstów źródłowych i docelowych, konwencjonalne NMT zazwyczaj daje płynne, ale nieodpowiednie tłumaczenia. Aby rozwiązać ten problem, proponujemy bramy kontekstowe, które dynamicznie kontrolują współczynniki, przy których konteksty źródłowe i docelowe przyczyniają się do generowania słów docelowych. W ten sposób możemy zwiększyć zarówno adekwatność, jak i płynność NMT poprzez dokładniejszą kontrolę przepływu informacji z kontekstów. Eksperymenty pokazują, że nasze podejście znacznie poprawia standardowy system NMT oparty na uwadze o punkty +2,3 BLEU.', 'no': 'I omsetjinga av neuralmaskin (NMT) er generering av eit målord avhengig av både kjelde og målkontekstar. Vi finn at kjeldekontekstane har direkte påvirkning på tilsvarende omsetjingar mens målkontekstane påvirkar flukten. Generasjonen av ei innhaldsord må vera meir på kjeldekonteksten og generering av ei funksjonell ord må vera meir på målkonteksten. På grunn av mangling av effektiv kontroll over påvirkninga frå kjeldekontekstane og målkontekstane, er konvensjonelle NMT vanleg å gjere flukt, men ikkje tilgjengeleg oversettelsar. For å handtera dette problemet, foreslår vi kontekstportar som dynamisk kontrollerar forholdet som kjelde og målkontekstar bidrar til å laga målkontekstar. På denne måten kan vi forbetra både NMT-tilsvarigheten og flukten med meir forsiktig kontroll over informasjonsflytten frå kontekstar. Eksperiment viser at tilnærminga vårt betydelig forbedrar på eit standardsbasert NMT-system med +2,3 BLEU-punkt.', 'lt': 'Nervų mašinų vertimo (NMT) atveju tikslinio žodžio sukūrimas priklauso nuo šaltinio ir tikslinio konteksto. Nustatome, kad šaltinio aplinkybės daro tiesioginį poveikį vertimo tinkamumui, o tikslinės aplinkybės daro poveikį lankstumui. Intuityviai turinio žodžio kūrimas turėtų labiau remtis šaltinio kontekstu, o funkcinio žodžio kūrimas turėtų labiau remtis tiksliniu kontekstu. Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations.  Siekiant išspręsti šią problem ą, siūlome kontekstinius vartus, kurie dinamiškai kontroliuoja santykius, kuriais šaltiniai ir tikslinės aplinkybės prisideda prie tikslinių žodžių kūrimo. Tokiu būdu galime padidinti NMT tinkamumą ir lankstumą atidžiau kontroliuodami informacijos srautus iš aplinkybių. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.', 'sr': 'U prevodu neuralne mašine (NMT), generacija ciljne reči zavisi od objekata izvora i ciljnih konteksta. Nalazimo da izvorni konteksti imaju direktni uticaj na adekvatnost prevoda dok ciljni konteksti utiču na tečnost. Intuitivno, generacija reči sadržaja bi trebala više da se osloni na izvorni kontekst i generaciju funkcionalne reči trebalo bi više osloniti na ciljni kontekst. Zbog nedostatka efektivne kontrole nad utjecajem iz izvora i meteoroloških konteksta, konvencionalni NMT je tendencija da donese tekućine ali nedovoljne prevode. Da bi riješili ovaj problem, predlažemo kontekstske kapije koje dinamički kontrolišu koeficijaciju koje izvore i mete konteksti doprinose generaciji ciljnih reči. Na taj naèin možemo poboljšati adekvatnost i tekućnost NMT-a sa pažljivijim kontrolom toka informacija iz konteksta. Eksperimenti pokazuju da naš pristup značajno poboljšava na standardnom sistemu NMT-a na osnovu pažnje +2.3 BLEU-a.', 'ro': 'În traducerea automată neurală (NMT), generarea unui cuvânt țintă depinde atât de contextul sursă, cât și de contextul țintă. Considerăm că contextele sursă au un impact direct asupra adecvării unei traduceri, în timp ce contextele țintă afectează fluența. Intuitiv, generarea unui cuvânt de conținut ar trebui să se bazeze mai mult pe contextul sursă, iar generarea unui cuvânt funcțional ar trebui să se bazeze mai mult pe contextul țintă. Datorită lipsei unui control eficient asupra influenței din contextele sursă și țintă, NMT convențional tinde să producă traduceri fluente, dar inadecvate. Pentru a aborda această problemă, propunem porți de context care controlează dinamic raporturile la care contextele sursă și țintă contribuie la generarea de cuvinte țintă. În acest fel, putem spori atât caracterul adecvat, cât și fluența NMT cu un control mai atent al fluxului de informații din contexte. Experimentele arată că abordarea noastră îmbunătățește semnificativ un sistem standard bazat pe atenție NMT cu +2,3 puncte BLEU.', 'si': 'න්\u200dයූරාල් යන්ත්\u200dරය අනුවාදය (NMT) වලින්, ලක්ෂණ වචන වලින් ප්\u200dරමාණය සහ ඉලක්ෂණ පද්ධතිය දෙන්නම් වි අපි හොයාගන්නවා මුළු සංවේදනය සම්බන්ධතාවට ප්\u200dරතිකාරයක් තියෙනවා වාර්ථාවක් සම්බන්ධතාවක් වලින් ඉලක ප්\u200dරවේශයෙන්, සාමාන්\u200dය වචනයක් ප්\u200dරවේශයක් විශ්වාස කරන්න පුළුවන් වචනය සහ ප්\u200dරවේශයක් විශ්වාස කරනවා ලක්ෂණ ප්\u200dරභාවය සහ ඉලක්ක සම්බන්ධයෙන් ප්\u200dරභාව පාලනය නැති විදිහට, සාමාන්\u200dය NMT ප්\u200dරභාවිත විදිහට ප්\u200dරභාවිත විදිහට පත මේ ප්\u200dරශ්න විධානය කරන්න, අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරනවා, මුළු සහ ඉලක්ක සම්බන්ධ වචන වලගේ ප්\u200dරශ්නයක් ප්\u200dරශ මෙහෙම විදියට, අපිට පුළුවන් NMT ගේ සම්පූර්ණතාවය සහ ප්\u200dරමාණත්වය සඳහා පරිස්සම් පාලනය කරන්න පුළුවන්. පරීක්ෂණය පෙන්වන්නේ අපේ ප්\u200dරවේශනය විශේෂයෙන් ප්\u200dරමාණය අවස්ථාවක් අධාරිත NMT පද්ධතිය +2.3 BLUE පින්', 'so': "Waxbarashada neural machine (NMT), generation of a word target, waxay ku xiran tahay labada sourceed and goal contexts. Waxaynu ognahay in dhibaato toos ah oo ku saameyn ku leh turjumista, haddii ay waxyaabaha la hago ay saameyn ku leedahay faa'iidada. Muujinta hadalka waxyaabaha ku jira waa in aad ka badan ku kalsoonaataa xaalada asalka iyo farshaha hadalka shaqeeya waa in aad ka badan ku kalsoonaato xaalada goalka. Sababta u baahan maamulka shaqaalaha ee saameyn ka leh sourceeda iyo waxyaabaha la hagaajiyey darteed, asalka caadiga ah ee NMT waxey soo bixisaa fluid, laakiin turjumaadda ku filan. Si aan u qabsado dhibaatadan, waxaynu soo jeedaynaa irdaha kooxaha ah oo si dabiiqada ah u maamula rasmiga ay noocyo iyo waxyaabaha ay ku leedahay abuuridda erayada waxqabadka. Sidaas oo kale, waxaynu kordhin karnaa dhamaantooda iyo faa'iidada NMT, si aad uga taxadar badan maamulka macluumaadka soo socda. Imtixaanka waxaa muuqda in dhaqdhaqaalahayagu aad buu u beddelaa nidaamka caadiga ah oo ku qoran kooxaha daryeelka NMT oo lagu qoray +2.3 BLEU.", 'sv': 'I neural maskinöversättning (NMT) beror genereringen av ett målord på både käll- och målkontext. Vi finner att källkontexter har en direkt inverkan på översättningens lämplighet medan målkontexter påverkar flytningen. Intuitivt sett bör skapandet av ett innehållsord förlita sig mer på källkontexten och skapandet av ett funktionellt ord bör förlita sig mer på målkontexten. På grund av bristen på effektiv kontroll över påverkan från källa- och målsammanhang tenderar konventionell NMT att ge flytande men otillräckliga översättningar. För att ta itu med detta problem föreslår vi kontextportar som dynamiskt styr de förhållanden vid vilka källa- och målkontexter bidrar till att skapa målord. På så sätt kan vi förbättra både lämpligheten och flytande NMT med noggrannare kontroll av informationsflödet från kontexter. Experiment visar att vårt tillvägagångssätt avsevärt förbättrar ett uppmärksamhetsbaserat NMT-system med +2,3 BLEU-poäng.', 'ur': 'نیورال ماشین ترجمہ (NMT) میں، ایک موجود لفظ کی پیدائش دونوں سورج اور موجود کنٹکسٹس پر مضبوط ہے. ہم دیکھتے ہیں کہ سورج کنٹکسٹس ایک ترجمہ کی adequacy پر مستقیم تأثیر دیتے ہیں جب موجود کنٹکسٹس جاری پر تأثیر دیتے ہیں. ایک منصفات لفظ کی نسل اس پر زیادہ اعتماد کرنا چاہیے کہ ایک منصفات لفظ کی نسل اور فعالیت لفظ کی نسل موقع پر زیادہ اعتماد کرے۔ سورج اور موقعیت کنٹکسٹس سے اثر کے کنٹرول پر غیر قابل کنٹرول کی وجہ سے، منطقی NMT فائدہ پیدا کرتا ہے لیکن غیر قابل ترجمہ پیدا کرتا ہے. اس مسئلہ کے بارے میں ہم متصلہ دروازوں کو پیشنهاد کرتے ہیں جن کے مطابق سراسر اور موقعیت متصلہ کا ذریعہ مقرر ہوتا ہے تابع کلمات کی نسل پر۔ اسی طرح ہم NMT کی adequacy اور پاکیزگی کو اضافہ کر سکتے ہیں ان معلومات کی جریان سے زیادہ دقیق کنترل سے۔ تجربے دکھاتے ہیں کہ ہمارا تقریبا +2.3 BLEU پوینٹوں کے ذریعہ ایک استاندارڈ توجه کی NMT سیسٹم پر اضافہ ہوتا ہے.', 'mk': 'Во неуралниот превод на машина (NMT), генерацијата на збор за цел зависи од извор и контекст на цел. Најдовме дека изворните контексти имаат директно влијание врз соодветноста на преводот додека целните контексти влијаат на течноста. Интуитивно, генерацијата на збор за содржина треба да се потпира повеќе на изворниот контекст и генерацијата на функционален збор треба да се потпира повеќе на целниот контекст. Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations.  За да го решиме овој проблем, предлагаме контекстни порти кои динамично ги контролираат односите на кои изворот и контекстите на целта придонесуваат за генерацијата на метни зборови. In this way, we can enhance both the adequacy and fluency of NMT with more careful control of the information flow from contexts.  Експериментите покажуваат дека нашиот пристап значително се подобрува на стандардниот НМТ систем базиран на внимание за +2,3 БЛЕ поени.', 'ta': 'Name நாம் கண்டுபிடிக்கிறோம் மூலம் மொழிபெயர்ப்பின் தேவையான பாதிப்பு இருக்கிறது இலக்கு பொருள்கள் வெளியீட்டை பா ஒரு உள்ளடக்க வார்த்தையின் தலைமுறை மூலத்தின் சூழல் மற்றும் செயல்பாட்டு வார்த்தையின் தலைமுறையில் அதிகமாக நம்ப வ மூலத்தில் இருந்து விளைவுகள் மற்றும் சேர்க்கும் பாதிப்புகளின் காரணத்தினால், வழக்கமான NMT வெளியீட்டை வழங்கும் ஆனால் போதும இந்த பிரச்சனையை நிர்வகிக்க, நாம் சூழல் வாயில்களை தேவையாக கட்டுப்படுத்தும் விகிதத்தை தேர்ந்தெடுக்கும் மூலம் மற் இந்த வழியில், நாம் NMT தேவையான மற்றும் விளைவுகளையும் அதிகப்படுத்த முடியும். நினைவுகளிலிருந்து தகவல் அனுப்பும் மே சோதனைகள் + 2. 3 பிலியு புள்ளிகள் மூலம் நிலையான கவனத்தை அடிப்படையான NMT அமைப்பின் மீது எங்கள் அணுகும் செயல்பாடு மிக ம', 'uz': "Name Biz o'ylaymiz, manba tarjima tarjimasiga yetarjima yetarjima effekti, agar qanday tarjima muammolari suhbatga ta'sir beradi. @ info: whatsthis @ info @ info Shunday qilib, biz NMT'ning muhimi va sikligini oshirishingiz mumkin va taxminan narsalardan ma'lumotni yaxshi boshqarish mumkin. Tekshirish imtiyozlarimiz esa, bizning qismlarimiz andoza paydo bo'lgan NMT tizimi +2.3 BLEU pointlari bilan ko'paytiriladi.", 'vi': 'Trong dịch thiết bị thần kinh (NMB) tạo ra một từ đích phụ thuộc vào cả nguồn và địa điểm đích. Chúng tôi thấy các ngữ cảnh nguồn có ảnh hưởng trực tiếp đến sự phù hợp của dịch vụ, trong khi các ngữ cảnh mục tiêu ảnh hưởng đến sự khéo léo. Tự động, tạo một từ ngữ nội dung nên dựa vào ngữ cảnh nguồn và tạo ra một từ chức năng nên dựa vào ngữ cảnh mục tiêu hơn. Do thiếu kiểm soát hiệu quả về tác động từ môi trường gốc và mục tiêu, NMB thường có xu hướng sản xuất dịch vụ thông thạo nhưng thiếu kĩ. Để giải quyết vấn đề này, chúng tôi đề nghị cánh cổng ngữ cảnh kiểm soát động động độ tỷ lệ các ngữ cảnh từ nguồn và mục đích góp phần tạo ra các từ đích. Bằng cách này, chúng ta có thể tăng cường mức độ phù hợp và khéo léo của công ty NMT bằng cách kiểm soát cẩn thận dòng thông tin từ ngữ cảnh. Các thí nghiệm cho thấy phương pháp của chúng ta cải thiện đáng kể hệ thống NMT dựa tiêu chuẩn bằng điểm LELIE.', 'bg': 'В невронния машинен превод (НМТ), генерирането на целева дума зависи както от източника, така и от целевия контекст. Установяваме, че изходните контексти имат пряко въздействие върху адекватността на превода, докато целевите контексти влияят върху плавността. Интуитивно генерирането на дума със съдържание трябва да разчита повече на контекста на източника, а генерирането на функционална дума трябва да разчита повече на целевия контекст. Поради липсата на ефективен контрол върху влиянието от източника и целевия контекст, конвенционалните НМТ имат тенденция да дават плавни, но неадекватни преводи. За решаване на този проблем предлагаме контекстни портали, които динамично контролират съотношенията, при които източникът и целевият контекст допринасят за генерирането на целеви думи. По този начин можем да подобрим както адекватността, така и плавността на НМТ с по-внимателен контрол на информационния поток от контексти. Експериментите показват, че подходът ни значително се подобрява при стандартна система, базирана на вниманието, с +2.3 точки.', 'da': "I neural maskinoversættelse (NMT) afhænger genereringen af et målord af både kilde- og målsammenhænge. Vi finder ud af, at kildekonflikter har en direkte indflydelse på oversættelsens tilstrækkelighed, mens målkontekster påvirker flydenheden. Intuitivt set bør genereringen af et indholdsord i højere grad afhænge af kildekonteksten, og genereringen af et funktionelt ord bør i højere grad afhænge af målkonteksten. På grund af manglen på effektiv kontrol over indflydelsen fra kilde- og målsammenhænge har konventionel NMT tendens til at give flydende, men utilstrækkelige oversættelser. For at løse dette problem foreslår vi kontekstporte, der dynamisk styrer de forhold, hvor kilde- og målkontekster bidrager til genereringen af målord. På denne måde kan vi forbedre både NMT's tilstrækkelighed og flydenhed med mere omhyggelig kontrol af informationsstrømmen fra sammenhænge. Eksperimenter viser, at vores tilgang forbedres betydeligt i forhold til et standard opmærksomhedsbaseret NMT system med +2,3 BLEU point.", 'nl': 'Bij neuronale machinevertaling (NMT) is het genereren van een doelwoord afhankelijk van zowel bron- als doelcontexten. We vinden dat broncontexten een directe invloed hebben op de adequaatheid van een vertaling terwijl doelcontexten de vloeiende taal beïnvloeden. Intuïtief moet het genereren van een inhoudswoord meer afhankelijk zijn van de broncontext en het genereren van een functioneel woord meer afhankelijk zijn van de doelcontext. Door het gebrek aan effectieve controle over de invloed van bron- en doelcontexten, heeft conventionele NMT de neiging vloeiende maar onvoldoende vertalingen te leveren. Om dit probleem aan te pakken, stellen we context gates voor die dynamisch de verhoudingen regelen waarbij bron- en doelcontexten bijdragen aan het genereren van doelwoorden. Op deze manier kunnen we zowel de adequaatheid als de vloeibaarheid van NMT verbeteren door zorgvuldigere controle van de informatiestroom vanuit contexten. Experimenten tonen aan dat onze aanpak aanzienlijk verbetert ten opzichte van een standaard aandachtsgebonden NMT systeem met +2.3 BLEU punten.', 'de': 'Bei der neuronalen maschinellen Übersetzung (NMT) hängt die Generierung eines Zielworts sowohl vom Quell- als auch vom Zielkontext ab. Wir stellen fest, dass Quellkontexte einen direkten Einfluss auf die Angemessenheit einer Übersetzung haben, während Zielkontexte die Fließfähigkeit beeinflussen. Intuitiv sollte die Generierung eines Inhaltswortes mehr vom Quellkontext abhängen und die Generierung eines Funktionswortes mehr vom Zielkontext abhängen. Aufgrund des Mangels an effektiver Kontrolle über den Einfluss aus Quell- und Zielkontexten liefert herkömmliche NMT tendenziell flüssige, aber unzureichende Übersetzungen. Um dieses Problem anzugehen, schlagen wir Kontextgates vor, die dynamisch die Verhältnisse steuern, bei denen Quell- und Zielkontexte zur Generierung von Zielwörtern beitragen. Auf diese Weise können wir sowohl die Angemessenheit als auch die Fluenz der NMT durch eine sorgfältige Kontrolle des Informationsflusses aus Kontexten verbessern. Experimente zeigen, dass unser Ansatz gegenüber einem Standard-aufmerksamkeitsbasierten NMT-System um +2,3 BLEU-Punkte deutlich verbessert wird.', 'ko': 'NMT(Nechanism Mechanism Transformation)에서 대상 단어의 생성은 원본 및 대상 컨텍스트에 따라 달라집니다.우리는 원어의 언어 환경은 번역문의 충분성에 직접적인 영향을 미치고 표어의 언어 환경은 번역문의 유창성에 영향을 미친다는 것을 발견했다.직관적으로 말하면 내용어의 생성은 원어경에 더 많이 의존하고 기능어의 생성은 목표어경에 더 많이 의존해야 한다.원본과 목표 언어 환경에 대한 효과적인 통제가 부족하기 때문에 전통적인 NMT는 유창하지만 충분하지 않은 번역을 할 수 있다.이 문제를 해결하기 위해 우리는 상하문문을 제기했다. 이것은 원상하문과 목표상하문이 목표어 생성에 기여하는 확률을 동태적으로 제어할 수 있다.이런 방식을 통해 우리는 상하문에 있는 정보 흐름을 더욱 자세하게 통제함으로써 NMT의 충분성과 유창성을 강화할 수 있다.실험에 따르면 우리의 방법은 표준적인 주의 기반 NMT 시스템보다 +2.3개의 BLEU 포인트를 높였다.', 'sw': 'Katika tafsiri ya mashine ya kijamii (NMT), kizazi cha neno la lengo linategemea vyanzo na mashindano hayo. Tunapata kwamba matatizo ya vyanzo yanaathiri moja kwa moja kwa moja kwa ya tafsiri wakati ambapo mikutano ya lengo yanaathiri ufanisi. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context.  Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations.  Ili kukabiliana na tatizo hili, tunapendekeza milango ya muktadha ambazo hudhibiti rasilimali ambazo chanzo na michango yanachangia uzalishaji wa maneno yanayolenga. Kwa namna hii, tunaweza kuongeza kiwango kinachotosha na ufanisi wa NMT kwa kudhibiti utoaji wa habari kutoka kwenye matatizo. Majaribio yanaonyesha kwamba hatua yetu inaboresha kwa kiasi kikubwa kwenye mfumo wa NMT wa msimamo wa kawaida kwa alama za BLEU +2.3.', 'id': 'Dalam terjemahan mesin saraf (NMT), generasi kata sasaran tergantung pada konteks sumber dan sasaran. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency.  Secara intuitif, generasi kata isi harus lebih bergantung pada konteks sumber dan generasi kata fungsional harus lebih bergantung pada konteks sasaran. Karena kekurangan kontrol efektif terhadap pengaruh dari konteks sumber dan sasaran, NMT konvensional cenderung untuk memberikan terjemahan fluent tetapi tidak cukup. To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words.  Dengan cara ini, kita dapat meningkatkan keperluan dan keterlaluan NMT dengan lebih berhati-hati mengendalikan aliran informasi dari konteks. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.', 'hr': 'U prevodu neuralnih strojeva (NMT), generacija ciljne riječi ovisi o izvorima i ciljnim kontekstima. Nalazimo da izvorni konteksti imaju direktni utjecaj na adekvatnost prevoda dok ciljni konteksti utječu na tečnost. Intuitivno bi generacija riječi sadržaja trebala više osloniti na kontekst izvora i generaciju funkcionalne riječi trebala više osloniti na ciljni kontekst. Zbog nedostatka učinkovitog kontrole nad utjecajem iz izvora i ciljnih konteksta, konvencionalni NMT navode na tečnost ali nedovoljno prevode. Za rješavanje ovog problema predlažemo kontekstske kapije koje dinamički kontroliraju procjene koje izvora i ciljni konteksti doprinose generaciji ciljnih riječi. Na taj način možemo poboljšati adekvatnost i tečnost NMT-a s pažljivijim kontrolom toka informacija iz konteksta. Eksperimenti pokazuju da se naš pristup značajno poboljšava na standardnom sustavu na pažnji na NMT-u +2,3 BLEU-ovim točkama.', 'tr': "NMT Biz 챌e힊me contextlerinin terjime etmek 체챌in dogry bir t채siri bar we maksady contextler aklysyna t채sirle첵채r. G철rn체힊 힊e첵le bolmasa, mazmunlar s철z체흫 d철wletlerini흫 챌e힊me kontekst체ne we i힊le첵채n s철z체흫 d철wletlerine k철pr채k ynamly bolmaly. Kaynaklardan ve hedefi kontekstlerden etkisi kontrol etmekten dolay캇, geleneksel NMT ak캇ll캇 ve uyumsuz terjimeler sa휓layar. Bu mesel채ni 챌철zmek 체챌in, su챌uk gapyny dinamik 힊eklinde g철zle첵채n seb채pleri we maksady du힊u힊ygy흫 maksady s철zlerin d철redilmesine k철mekle첵채n kontekst gapyny teklip ed첵채ris. Bu 힊ekilde, NMT'in titizliklerini hem dikkatli 힊ekilde, bilgi ak캇힊캇n캇 kontrol edebiliriz. Denminatlar bizi흫 metodamyzy흫 +2.3 BLEU noktalary bilen standart 체ns da힊arylan NMT sistemasynda 철r채n gowydygyny g철rkez첵채r.", 'fa': 'در ترجمه ماشین عصبی (NMT) نسل کلمه هدف بر هر دو موضوع منبع و هدف بستگی دارد. ما پیدا می\u200cکنیم که موضوع منبع تأثیر مستقیم بر مناسب ترجمه\u200cای دارند در حالی که موضوع هدف تأثیر آلودگی است. نسل کلمه محتویات باید بیشتر بر محتویات منبع و نسل کلمه عملکرد باید بیشتر بر محتویات هدف اعتماد کند. به دلیل ناتوانی کنترل موثری بر تأثیر منبع و موضوع هدف، NMT معمولی به ترجمه\u200cهای بی\u200cنیاز می\u200cرسد. برای حل این مشکل، ما دروازه\u200cهای محیط را پیشنهاد می\u200cکنیم که با طبیعی کنترل نسبت\u200cهای منبع و موضوع هدف به نسبت کلمات هدف کمک می\u200cکنند. در این صورت، ما می توانیم با کنترل دقت بیشتری از جریان اطلاعات از محیط\u200cها به مناسب و آسایش NMT بیشتر افزایش دهیم. تجربه\u200cها نشان می\u200cدهند که دسترسی ما با نقطه\u200cهای BLEU +2.3 بر روی سیستم توجه استاندارد بهتر می\u200cشود.', 'am': 'በናውራዊ መሳሳይ ትርጉም (NMT)፣ ትውልድ የእርግት ቃል በሁለቱም ምንጭ እና በተቃውሞ ይታመካል፡፡ የመድረክ ግንኙነት የግንኙነቱ ግንኙነት የግንኙነቱን ትርጉም በሚያስፈልገው ጥቅረት አግኝቷል፡፡ Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context.  በምዕራብ እና የግንኙነት ግንኙነቶች ላይ ጥቅም ስልጣን በማይኖርበት ምክንያት በተቃውሞ የNMT ጉዳይ ግን የሚበቃ ትርጓሜዎችን እንዲሰጥ ይችላል፡፡ ይህንን ጉዳይ ለመቀበል፣ የግንኙነት ደጆችን በሥልጣዊ ግንኙነት እና የግንኙነት ግንኙነቶች ለትክክለኛ ቃላት ትውልድ የሚጠቅሙትን እና አካባቢ እናደርጋለን፡፡ እንደዚሁም የኢንተርኔት አካባቢ እና የNMT ጥብቅ እና የመረጃ ግንኙነት ከግንኙነቶች የበለጠ አስተያየት እናበረታለን፡፡ ፈተናዎች በ +2.3 BLEU ነጥቦች ላይ የዳርቻ የNMT ስርዓት በመጠቀም የሚያሳውቃለን፡፡', 'af': "In neurale masjien vertaling (NMT), generasie van 'n doelwoord afhang van beide bron en doel konteks. Ons vind dat bronkontekste 'n direk invloek het op die adekuasie van 'n vertaling terwyl die doel kontekste invloek die fluiditeit. Intuitief, generasie van 'n inhoud woord moet meer vertrou op die bronkontekste en generasie van 'n funksionele woord moet meer vertrou op die doel konteks. Omdat die ontbreek van effektief kontrole oor die influens van bron en doel kontekste, het konvensiewe NMT gevolg om fluent, maar onvoldoende vertalings te gee. Om hierdie probleem te adres, voorstel ons kontekspoorte wat dinamies die hoeveelheid beheer waar bron en doel konteks bydra aan die generasie van doel woorde. In hierdie manier kan ons beide die adekuasie en fluiditeit van NMT verhoog met meer versigtige beheer van die inligting vloei van kontekste. Eksperimente wys dat ons toegang betekeurig verbeter op 'n standaard aandag-gebaseerde NMT stelsel deur +2.3 BLEU-punte.", 'az': "NMT məqsəd sözünün nəzəriyyəti mənbə və məqsəd müxtəliflərə bağlı olar. Biz bu mənbə müxtəliflərinin dəyişikliyinə təkrar çeviriləcəyi təsirlərin təkrarlığına dəyişiklik göstərir. Müxtəlif sözlərin nəsili funksiyal sözlərin mənbə kontekstünə və nəsilinə daha çox təvəkkül edilməsi lazımdır. Qaynaq və məqsəd müxtəliflərindən etkisiz kontrol üzərində olmadığına görə, conventional NMT sıxıntıya gəlir, amma yeterli tərcümlərdən istifadə edir. Bu problemi çəkmək üçün, məlumat sözlərinin nəsilinə kömək edəcəyi məlumat qapılarını dinamik olaraq kontrol edən məlumat qapılarını təklif edirik. Bəlkə, NMT'nin yetkinliğini və sıxınlığını müxtəlif məlumatların akışlarının daha dikkatli kontrolü ilə artıra bilərik. Həqiqətən, təcrübələrimiz standart ünvanlı NMT sistemində +2.3 BLEU nöqtələrindən çox yaxşılaşır.", 'bn': 'নিউরেল মেশিন অনুবাদ (এনএমটি) এ একটি লক্ষ্য শব্দের প্রজন্ম উৎস এবং লক্ষ্য প্রতিযোগিতার উপর নির্ভর করে। আমরা খুঁজে পাচ্ছি যে সূত্রের প্রতিযোগিতা একটি অনুবাদের প্রতি সরাসরি প্রভাব ফেলেছে যখন টার্গেট প্রতিযোগিতা ফ্লাইসেস যৌথভাবে, একটি বিষয়বস্তু শব্দের প্রজন্মের উৎসের প্রেক্ষাপট এবং কার্যকরী শব্দের প্রজন্মের উপর আরো বেশি নির্ভর করা উচি উৎস এবং লক্ষ্য প্রতিযোগিতার প্রভাবের উপর কার্যকর নিয়ন্ত্রণের অভাবের কারণে সাধারণ এনএমটি ফ্লুয়েন্ট প্রদান করে কিন্তু যথেষ্ট অনুবাদ প এই সমস্যা নিয়ে কথা বলার জন্য আমরা প্রস্তাব করি যে প্রবন্ধ দরজাগুলোকে নিয়ন্ত্রণ করা যায় যেখানে উৎস এবং লক্ষ্যের প্রতিযোগিতা লক্ষ্য এভাবে আমরা এনএমটির যথাযথ এবং প্রভাব বৃদ্ধি করতে পারি প্রতিযোগিতা থেকে তথ্য প্রবাহের উপর আরো সতর্ক নিয়ন্ত্রণ নিয়ে। পরীক্ষাগুলো দেখাচ্ছে যে আমাদের পদক্ষেপ গুরুত্বপূর্ণ ভিত্তিক এনএমটি সিস্টেমে + ২.', 'bs': 'U prevodu neuralne mašine (NMT), generacija ciljne riječi ovisi o objektivima izvora i ciljnih konteksta. Nalazimo da izvorni konteksti imaju direktni utjecaj na adekvatnost prevoda dok ciljni konteksti utiču na tekućinu. Intuitivno, generacija riječi sadržaja bi trebala više osloniti na kontekst izvora i generaciju funkcionalne riječi trebala bi više osloniti na ciljni kontekst. Zbog nedostatka učinkovitog kontrole nad utjecajem iz izvora i meteoroloških konteksta, konvencionalni NMT je tendencija da donese tekućine ali nedovoljne prevode. Da bi se riješili ovaj problem, predlažemo kontekstske kapije koje dinamički kontroliraju procjene koje izvor i mete konteksti doprinose generaciji ciljnih riječi. Na taj način možemo poboljšati adekvatnost i tekućnost NMT-a sa pažljivijim kontrolom toka informacija iz konteksta. Eksperimenti pokazuju da naš pristup značajno poboljšava na standardnom sustavu na pažnji na NMT-u +2.3 BLEU-ovim točkama.', 'sq': 'Në përkthimin nervor të makinës (NMT), gjenerata e një fjale objektive varet nga si burimi ashtu edhe nga konteksti objektiv. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency.  Në mënyrë intuitive, gjenerata e një fjale përmbajtjeje duhet të mbështetet më shumë në kontekstin e burimit dhe gjenerata e një fjale funksionale duhet të mbështetet më shumë në kontekstin e objektivit. Për shkak të mungesës së kontrollit të efektshëm mbi ndikimin nga kontekstet burimi dhe objektivi, NMT konvencionale ka tendencë të japë përkthime të fluktuara por të papërshtatshme. Për të trajtuar këtë problem, ne propozojmë porta konteksti që dinamikisht kontrollojnë raportet në të cilat burimi dhe konteksti objektiv kontribuojnë në gjenerimin e fjalëve objektive. Në këtë mënyrë, ne mund të përmirësojmë si përshtatjen dhe fluencën e NMT me kontrollin më të kujdesshëm të rrjedhjes së informacionit nga kontekstet. Eksperimentet tregojnë se qasja jonë përmirësohet ndjeshëm në një sistem NMT të bazuar në vëmendje me +2.3 pikë BLEU.', 'hy': 'Նյարդային մեքենայի թարգմանման ժամանակ նպատակային բառի ստեղծումը կախված է նաև աղբյուրի, նաև նպատակային կոնտեքստից: Մենք հայտնաբերում ենք, որ աղբյուրների կոնտեքստները ուղղակի ազդում են թարգմանության հարմարությունը, մինչդեռ նպատակային կոնտեքստները ազդում են հեղության վրա: Ինտուիտիվ, պարունակության բառի ստեղծումը ավելի շատ պետք է կախված լինի աղբյուրի կոնտեքստից, իսկ ֆունկցիոնալ բառի ստեղծումը ավելի շատ պետք է կախված լինի նպատակային կոնտեքստից: Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations.  To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words.  Այս կերպ մենք կարող ենք բարելավել NMT-ի բավարարությունը և ճկունությունը ավելի ուշադիր կառավարելով տեղեկատվության հոսքը կոնտեքստներից: Փորձարկումները ցույց են տալիս, որ մեր մոտեցումը նշանակալիորեն բարելավում է ուշադրության վրա հիմնված ստանդարտ ՆՄԹ համակարգի +2.3 միավորով:', 'cs': 'V neuronovém strojovém překladu (NMT) závisí generace cílového slova na zdrojovém i cílovém kontextu. Zjišťujeme, že zdrojové kontexty mají přímý vliv na adekvátnost překladu, zatímco cílové kontexty ovlivňují plynulost. Intuitivně by generování obsahového slova mělo více spoléhat na zdrojový kontext a generování funkčního slova by se mělo více spoléhat na cílový kontext. Vzhledem k nedostatku efektivní kontroly nad vlivem ze zdrojového a cílového kontextu, konvenční NMT má tendenci poskytovat plynulé, ale nedostatečné překlady. Pro řešení tohoto problému navrhujeme kontextové brány, které dynamicky řídí poměry, při kterých zdrojové a cílové kontexty přispívají k generování cílových slov. Tímto způsobem můžeme zvýšit přiměřenost a plynulost NMT díky pečlivější kontrole toku informací z kontextů. Experimenty ukazují, že náš přístup výrazně zlepšuje standardní NMT systém založený na pozornosti o +2,3 BLEU body.', 'et': 'Neuraalse masintõlke (NMT) puhul sõltub sihtsõna genereerimine nii lähte- kui ka sihtkontekstist. Leiame, et lähtekontekstid mõjutavad otseselt tõlke adekvaatsust, samas kui sihtkontekstid mõjutavad sujuvalt. Intuitiivselt peaks sisusõna genereerimine tuginema rohkem lähtekontekstile ja funktsionaalse sõna genereerimine tuginema rohkem sihtkontekstile. Kuna allika- ja sihtkontekstist pärit mõju puudub tõhus kontroll, kipub tavapärane NMT andma sujuvaid, kuid ebapiisavaid tõlkeid. Selle probleemi lahendamiseks pakume välja kontekstiväravad, mis dünaamiliselt kontrollivad suhteid, millega lähte- ja sihtkontekstid aitavad kaasa sihtsõnade loomisele. Sel viisil saame parandada nii NMT piisavust kui ka sujuvust, kontrollides hoolikamalt infovoogu kontekstist. Katsed näitavad, et meie lähenemine parandab oluliselt standardset tähelepanu põhinevat NMT süsteemi +2,3 BLEU punkti võrra.', 'fi': 'Neurokonekääntämisessä (NMT) kohdesanan luominen riippuu sekä lähde- että kohdekontekstista. Havaitsemme, että lähdekonteksteilla on suora vaikutus käännöksen riittävyyteen, kun taas kohdekonteksteilla on suora vaikutus käännöksen sujuvuuteen. Intuitiivisesti sisältösanan tuottamisen tulisi perustua enemmän lähdekontekstiin ja funktionaalisen sanan tuottamisen tulisi perustua enemmän kohdekontekstiin. Koska lähtö- ja kohdekontekstien vaikutusta ei voida hallita tehokkaasti, perinteiset NMT:t tuottavat sujuvat mutta riittämättömät käännökset. Tämän ongelman ratkaisemiseksi ehdotamme kontekstiportteja, jotka ohjaavat dynaamisesti suhdetta, jolla lähde- ja kohdekontekstit edistävät kohdesanojen syntymistä. Näin voimme parantaa sekä NMT:n riittävyyttä että sujuvuutta kontrolloimalla tarkemmin konteksteista tulevaa tiedonkulkua. Kokeet osoittavat, että lähestymistapamme parantaa merkittävästi huomiota perustuvaa NMT-järjestelmää +2,3 BLEU-pisteellä.', 'ca': "In neural machine translation (NMT), generation of a target word depends on both source and target contexts.  Trobem que els contextes de fonts tenen un impacte directament en la adequació d'una traducció mentre els contextes d'objectiu afecten la fluïtat. Intuïtivament, la generació d'una paraula de contingut hauria de dependre més del context de fonts i la generació d'una paraula funcional hauria de dependre més del context d'objectiu. A causa de la falta de control efectiu sobre l'influència dels contextes de fonts i objectius, la NMT convencional tendeix a produir traduccions fluides però inadequades. Per abordar aquest problema, proposem portas contextuals que controlen dinàmicament les proporcions en les que els contextos fonts i alvos contribueixen a la generació de paraules alvos. D'aquesta manera, podem millorar tant l'adequació com la fluència de la NMT amb un control més atent del flux d'informació dels contextos. Els experiments demostren que el nostre enfocament millora significativament en un sistema NMT estàndard basat en l'atenció en +2,3 punts BLEU.", 'jv': 'In Neral device translation (NMT), Generation of a goal word @title: window FullName Tungkin ora ono nggawe nguasai efek karo nggawe aturan mengko karo kontribusi tarjamahan, NMT kuwi nggawe barang daftar podho akeh tarjamahan kanggo ngilangno. Ditawak dhéwé nggalakno perbudhakan iki, kita supoyata barang sampek dynamics sing dikontrol perbudhakan karo perbudhakan karo cilihan contexts kang kontribusi kanggo kelompok tarjamahan Nang iki wae, kita iso nglanggar deweke karo NMT seneng pisan bakal nguasai nggawe barang-barang kanggo keamanan informasi layanan contexter Isopo sing ngomong nik diangkat dhéwé nang ngerasakno sing luwih nyebute nggawe sistem NMT sing basa kang + 2.3, sing basa sing cukup.', 'ha': "@ info: whatsthis Tuna gane cewa matsalon ɗin maɓallin wuri yana da mai amfani da ma'aunin fassarar da kuma idan ma'auni sun yi amfani da fassaran. Kijan tsarin wani magana na guda, ya kamata a dõgara mafi ƙaranci ga mazaɓa na source da kizahin wata kalma mai amfani da shi sai ya ƙayyade ƙari kan mazaɓa na goan. Due da bã za'a iya sãmun ƙarfi mai amfani ba kan mai amfani daga sourcen da ke amfani da konkurs, masu hususann NMT yana ƙara masu buƙata, kuma amma bã ya isa fassarar. To, dõmin a yi tambaya ga wannan muammãni, Munã buƙata ƙõfõfi masu husũma da ke kanyaɗa hanyoyi masu kanana da rassi da kuma masu amfani da matsayi su ƙara wa zaɓen maganar goan. Kamar wannan, tuna iya ƙara cikakken da fassarar NMT da kuma masu taƙaitacce wa masu tsari na masu haɗi da mazaɓa daga mazaɓa. Fijaroyi na nuna cewa hanyarmu yana ƙari mai girma a kan wata na'ura na tsari da aka ƙayyade nau'i na NMT da na+2.3 BLEU.", 'sk': 'V nevronskem strojnem prevajanju (NMT) je generiranje ciljne besede odvisno od izvornih in ciljnih kontekstov. Ugotavljamo, da izvorni konteksti neposredno vplivajo na ustreznost prevoda, medtem ko ciljni konteksti vplivajo na tekočino. Intuitivno se mora ustvarjanje vsebinske besede bolj zanašati na izvorni kontekst, ustvarjanje funkcionalne besede pa bolj na ciljni kontekst. Zaradi pomanjkanja učinkovitega nadzora nad vplivom iz izvornih in ciljnih kontekstov običajno NMT prinaša tekoče, vendar neustrezne prevode. Za reševanje tega problema predlagamo kontekstna vrata, ki dinamično nadzirajo razmerja, pri katerih izvorni in ciljni konteksti prispevajo k ustvarjanju ciljnih besed. Tako lahko s skrbnejšim nadzorom pretoka informacij iz kontekstov povečamo ustreznost in tekočost NMT. Eksperimenti kažejo, da naš pristop bistveno izboljša standardni sistem NMT na osnovi pozornosti za +2,3 točke BLEU.', 'bo': 'In neural machine translation (NMT), a generation of a target word depends on both source and target contexts. ང་ཚོས་ཐོག་མའི་ཁྲོད་ཡུལ་ནང་དུ་དམིགས་ཡུལ་གནས་ཚུལ་འགྱུར་བ་དང་ཐད་ཡོངས་རྫོགས་ལ་ངེས་པར་གསལ་པོ་ཞིག་ཡོད་པ འཆར་བརྟན་ན། ནང་དོན་གྱི་ཐ་སྙད་ཅིག་གི་ནང་དོན་ཡིག གལ་སྲིད་དམིགས་ཡུལ་དང་འབྱུང་ཡུལ་གནས་ཚུལ་ལས་དཀའ་ངལ་མེད་པའི་རྒྱུ་མཚན་ནི་ དཀའ་ངལ་འདི་ལ་སྤྲོད་དགོས་པ་དེ་འུ་ཅག་གིས་ཁོངས་ཀྱི་རྒྱུ་མཚན་འདི་འགྱུར་མཁན་དང་དམིགས་ཡུལ་ཁུངས་ཀྱིས་དམིགས་ཡུལ་གྱི་ཚོགས་ར འོན་ཀྱང་། ང་ཚོས་NMT་གི་adequacy་དང་སྟོང་པ་གཉིས་ཀྱིས་གནད་དོན་འགྲེལ་བཙུགས་རྒྱུ་དང་། Experiments show that our approach significantly improves on a standard attention-based NMT system by +2.3 BLEU points.', 'he': 'בתרגום מכונת עצבית (NMT), הדורה של מילה מטרה תלויה בין מקור וקשר מטרה. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency.  באופן אינטואיטיבי, הדורה של מילת תוכן צריכה לסמוך יותר על הקשר המקורי ודורה של מילה פונקציונלית צריכה לסמוך יותר על הקשר המטרה. בגלל חוסר שליטה יעילה על השפעה ממקור וקשר המטרה, NMT קונבנציונלי נוטה להביא תרגומות נוזלות אבל לא מתאימות. כדי להתמודד עם הבעיה הזאת, אנו מציעים שערים קונטקסט ששולטים דינמית על היחסים שבהם מקור וקשר המטרה תורמים לדור מילים המטרה. בדרך זו, אנחנו יכולים לשפר גם את התאימה וגם את הנוזלות של NMT עם שליטה זהירה יותר על זרימת המידע מהקשרים. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.'}
{'en': 'Automatically Tagging Constructions of Causation and Their Slot-Fillers', 'ar': 'وضع علامات تلقائيًا على تركيبات السببية ومعبئات الخانات الخاصة بهم', 'pt': 'Marcação automática de construções de causalidade e seus preenchimentos de slot', 'fr': 'Marquage automatique des constructions de causalité et de leurs obturateurs', 'es': 'Etiquetado automático de construcciones de causalidad y sus rellenos de ranuras', 'zh': '自标因果关系及槽填充物结构', 'ja': '原因とそのスロットフィラーの構造を自動的にタグ付けする', 'hi': 'स्वचालित रूप से कारण और उनके स्लॉट-Fillers के निर्माण टैगिंग', 'ru': 'Автоматическая маркировка причинно-следственных связей и их заполнителей', 'ga': 'Uathoibríoch Clibeáil Foirgníochtaí Cúisíochta agus a Sliotáin-Líonaithe', 'hu': 'Az okozás konstrukcióinak automatikus címkézése és azok slot-töltőinek', 'el': 'Αυτόματη επισήμανση κατασκευών της αιτίας και των αυλακώσεων-πληρωμάτων τους', 'ka': 'ავტომატურად შექმნის შექმნილება და თავის სლოტი- დაყენებელი', 'it': 'Etichettare automaticamente le costruzioni di causa e i loro slot-filler', 'kk': 'Автоматты түрде каусация мен слотты толтырушыларының құрылымының тегтері', 'mk': 'Автоматски ги означува изградбите на причината и нивните пополнувачи на слотови', 'lt': 'Automatinis atsargumo konstrukcijų ir jų laiko tarpsnių užpildymo žymėjimas', 'ms': 'Automatically Tagging Constructions of Causation and Their Slot-Fillers', 'ml': 'സ്വയം ടാഗ്ഗിങ്ങ് ക്യാസേഷനിന്റെയും അവയുടെ സ്ലോട്ട്- ഫില്ലറുകളുടെയും അടിസ്ഥാനങ്ങള്\u200d', 'mn': 'Автоматтын Каусацийн бүтээлүүд болон Слот-Дүүрэгчид', 'pl': 'Automatyczne oznaczanie konstrukcji kaucji i ich wypełniaczy szczelin', 'sr': 'Automatski označavaju konstrukcije kaveza i njihove slot-napunjenice', 'mt': 'L-Ittikkjar Awtomatiku tal-Kostruzzjonijiet tal-Kawżazzjoni u tal-Fillers tas-Slots tagħhom', 'no': 'Automatisk merker konstruksjonar av mellomlager og slotfilterar', 'so': 'Automatic Tagging Constructions of Causation and their Slot-Fillers', 'sv': 'Automatisk märkning av orsakskonstruktioner och deras slot-fyllmedel', 'ta': 'தானாகவே ஒட்டு அமைப்புகள் பயன்பாடுகள் மற்றும் தங்கள் சுட்டி நிரப்புபவர்கள்', 'ro': 'Etichetarea automată a construcțiilor cauzei și a materialelor lor de umplere a sloturilor', 'ur': 'کائوس اور ان کے اسلوٹ-فیلر کے ساختار کو اپنی طور پر ٹاگ کر رہا ہے', 'si': 'ස්වයංක්\u200dරමය සහ ඔවුන්ගේ ස්ලෝට් ෆිලර්ස් ගැන ස්වයංක්\u200dරමයෙන් ටැග් කරනවා', 'uz': 'Name', 'vi': 'Tự động đánh dấu xây dựng', 'bg': 'Автоматично маркиране на конструкциите на причината и техните слотове-пълнители', 'nl': 'Automatisch markeren van constructies van causie en hun sleuvenvullers', 'hr': 'Automatski označavaju konstrukcije kaveza i njihove slot-napunjenice', 'de': 'Automatisches Markieren von Causationskonstruktionen und ihren Schlitzfüllern', 'da': 'Automatisk mærkning af årsagskonstruktioner og deres slot-fyldstoffer', 'fa': 'برچسب ساختمان\u200cها و پر\u200cکننده\u200cهای سطح\u200cهای آنها را به طور خودکار برچسب می\u200cکند', 'tr': 'Avtomatik Gaýd Etmek we Olaryň Slot doldurumlaryny Etiketlendirmek', 'af': 'Automaties merk konstruksies van verskaffing en hul Slot- Fillers', 'sq': 'Automatically Tagging Constructions of Causation and Their Slot-Fillers', 'id': 'Automatis Tagging Constructions of Causation and Their Slot-Fillers', 'ko': '인과관계의 자동 표시 구조와 슬롯 충전', 'az': 'Avtomatik Causation və Slot Fillers inşalları', 'hy': 'Automatically Tagging Constructions of Causation and Their Slot-Fillers', 'bs': 'Automatski označavaju konstrukcije kaveza i njihove slot-napunjenice', 'am': 'ምርጫዎች', 'sw': 'Miundombinu ya Usafiri na Wasambazi wao', 'cs': 'Automatické označování konstrukcí kauce a jejich výplně drážek', 'fi': 'Merkkaamme automaattisesti aiheuttajien rakenteet ja niiden kolikkopelit', 'bn': 'স্বয়ংক্রিয়ভাবে ট্যাগিং বিন্যাস এবং তাদের স্লোটফিলার্স', 'et': 'Põhjuslike konstruktsioonide ja nende teenindusaegade automaatne märgistamine', 'ca': "Etiquetar automàticament les construccions de causació i els seus llençadors d'intervals", 'jv': 'Automatically tagging structural navigation of Causation and their slot-filler', 'ha': 'KCharselect unicode block name', 'sk': 'Samodejno označevanje konstrukcij povzročitve in njihovih rež-polnil', 'he': 'תווים אוטומטיים בניית הגורם וממלאים את המסגרים שלהם', 'bo': 'རང་འགུལ་གྱིས་ཐེབས་ཁུངས་དང་ཁོང་རའི་སྒོ་སྒྲིག་མདོག་ཤོག་བྱང་པ'}
{'en': 'This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case. Semantic parsing becomes difficult in the face of the wide variety of linguistic realizations that causation can take on. We therefore base our approach on the concept of constructions from the linguistic paradigm known as Construction Grammar (CxG). In CxG, a construction is a form / function pairing that can rely on arbitrary linguistic and semantic features. Rather than codifying all aspects of each construction’s form, as some attempts to employ CxG in NLP have done, we propose methods that offload that problem to machine learning. We describe two supervised approaches for tagging causal constructions and their arguments. Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions. Our results show that these approaches are promising : they significantly outperform nave baselines for both construction recognition and cause and effect head matches.', 'ar': 'تستكشف هذه الورقة توسيع التحليل الدلالي الضحل إلى ما وراء مشغلات الوحدة المعجمية ، باستخدام العلاقات السببية كحالة اختبار. يصبح الإعراب الدلالي صعبًا في مواجهة مجموعة واسعة من الإدراك اللغوي الذي يمكن أن تتخذه السببية. لذلك نبني نهجنا على مفهوم الإنشاءات من النموذج اللغوي المعروف باسم قواعد البناء (CxG). في CxG ، البناء عبارة عن اقتران بين الشكل / الوظيفة يمكن أن يعتمد على ميزات لغوية ودلالية تعسفية. بدلاً من تدوين جميع جوانب شكل كل بناء ، كما فعلت بعض المحاولات لتوظيف CxG في البرمجة اللغوية العصبية ، نقترح طرقًا تلغي تحميل هذه المشكلة إلى التعلم الآلي. نصف نهجين خاضعين للإشراف لوضع علامات على الإنشاءات السببية وحججها. يجمع كلا الأسلوبين بين قواعد مطابقة الأنماط المستحثة تلقائيًا مع المصنفات الإحصائية التي تتعلم المعلمات الدقيقة للإنشاءات. تظهر نتائجنا أن هذه الأساليب واعدة: فهي تتفوق بشكل كبير على خطوط الأساس الساذجة لكل من التعرف على البناء ومطابقات السبب والنتيجة.', 'es': 'Este artículo explora la extensión del análisis semántico superficial más allá de los desencadenantes de unidades léxicas, utilizando las relaciones causales como un caso de prueba. El análisis semántico se vuelve difícil ante la gran variedad de realizaciones lingüísticas que puede asumir la causalidad. Por lo tanto, basamos nuestro enfoque en el concepto de construcciones del paradigma lingüístico conocido como Gramática de la Construcción (CxG). En CxG, una construcción es un emparejamiento de forma y función que puede basarse en características lingüísticas y semánticas arbitrarias. En lugar de codificar todos los aspectos de la forma de cada construcción, como lo han hecho algunos intentos de emplear CxG en PNL, proponemos métodos que descargan ese problema al aprendizaje automático. Describimos dos enfoques supervisados para etiquetar las construcciones causales y sus argumentos. Ambos enfoques combinan reglas de coincidencia de patrones inducidas automáticamente con clasificadores estadísticos que aprenden los parámetros más sutiles de las construcciones. Nuestros resultados muestran que estos enfoques son prometedores: superan significativamente a las líneas de base ingenuas tanto en el reconocimiento de la construcción como en los partidos de cabeza de causa y efecto.', 'fr': "Cet article explore l'extension de l'analyse sémantique superficielle au-delà des déclencheurs d'unités lexicales, en utilisant les relations causales comme cas de test. L'analyse sémantique devient difficile face à la grande variété de réalisations linguistiques que peut prendre la causalité. Nous fondons donc notre approche sur le concept de constructions issues du paradigme linguistique connu sous le nom de grammaire de construction (CxG). Dans CxG, une construction est un appariement forme/fonction qui peut s'appuyer sur des caractéristiques linguistiques et sémantiques arbitraires. Plutôt que de codifier tous les aspects de la forme de chaque construction, comme l'ont fait certaines tentatives d'utilisation de CxG dans la PNL, nous proposons des méthodes qui déchargent ce problème de l'apprentissage automatique. Nous décrivons deux approches supervisées pour étiqueter les constructions causales et leurs arguments. Les deux approches combinent des règles de correspondance de modèles induites automatiquement avec des classificateurs statistiques qui apprennent les paramètres les plus subtils des constructions. Nos résultats montrent que ces approches sont prometteuses\xa0: elles surpassent de manière significative les valeurs de référence naïves tant pour la reconnaissance de la construction que pour les appariements de causes et d'effets.", 'pt': 'Este artigo explora a extensão da análise semântica superficial além dos gatilhos de unidade lexical, usando relações causais como um caso de teste. A análise semântica torna-se difícil em face da grande variedade de realizações linguísticas que a causação pode assumir. Baseamos, portanto, nossa abordagem no conceito de construções a partir do paradigma linguístico conhecido como Gramática da Construção (CxG). Em CxG, uma construção é um par de forma/função que pode contar com características linguísticas e semânticas arbitrárias. Em vez de codificar todos os aspectos da forma de cada construção, como fizeram algumas tentativas de empregar CxG na PNL, propomos métodos que transferem esse problema para o aprendizado de máquina. Descrevemos duas abordagens supervisionadas para marcar construções causais e seus argumentos. Ambas as abordagens combinam regras de correspondência de padrões induzidas automaticamente com classificadores estatísticos que aprendem os parâmetros mais sutis das construções. Nossos resultados mostram que essas abordagens são promissoras: elas superam significativamente as linhas de base ingênuas para reconhecimento de construção e correspondências de causa e efeito.', 'ja': 'この論文では、因果関係をテストケースとして、浅い意味論的構文解析を語彙単位のトリガーを超えて拡張することを探求している。 因果関係が引き起こす可能性のある多種多様な言語的実現に直面して、セマンティック構文解析は困難になる。 したがって、私たちのアプローチは、構築文法（ CxG ）として知られる言語パラダイムからの構築の概念に基づいています。 CxGでは、構築は、任意の言語的および意味的特徴に依存することができるフォーム/関数のペアリングである。 NLPでCxGを採用するいくつかの試みのように、各構築の形態のすべての側面をコーディングするのではなく、その問題を機械学習にオフロードする方法を提案する。 私たちは、因果構造とその引数をタグ付けするための2つの監視されたアプローチについて説明します。 両方のアプローチは、自動的に誘導されるパターンマッチングルールと、構造のより微妙なパラメータを学習する統計分類子とを組み合わせる。 私たちの結果は、これらのアプローチが有望であることを示しています。これらのアプローチは、建設の認識と因果関係の頭のマッチングの両方で、ナイーブなベースラインを大幅に上回っています。', 'hi': 'यह पेपर एक परीक्षण मामले के रूप में कारण संबंधों का उपयोग करते हुए, लेक्सिकल-यूनिट ट्रिगर्स से परे उथले शब्दार्थ पार्सिंग का विस्तार करने की पड़ताल करता है। शब्दार्थ पार्सिंग भाषाई अहसासों की विस्तृत विविधता के चेहरे में मुश्किल हो जाता है जो कारण पर ले जा सकता है। इसलिए हम निर्माण व्याकरण (CxG) के रूप में जाना जाता है भाषाई प्रतिमान से निर्माण की अवधारणा पर हमारे दृष्टिकोण का आधार। CxG में, एक निर्माण एक रूप / फ़ंक्शन युग्मन है जो मनमाने ढंग से भाषाई और शब्दार्थ विशेषताओं पर भरोसा कर सकता है। प्रत्येक निर्माण के रूप के सभी पहलुओं को संहिताबद्ध करने के बजाय, जैसा कि एनएलपी में सीएक्सजी को नियोजित करने के कुछ प्रयासों ने किया है, हम उन तरीकों का प्रस्ताव करते हैं जो मशीन लर्निंग के लिए उस समस्या को ऑफलोड करते हैं। हम कारण निर्माण और उनके तर्कों को टैग करने के लिए दो पर्यवेक्षित दृष्टिकोणों का वर्णन करते हैं। दोनों दृष्टिकोण सांख्यिकीय क्लासिफायरके साथ स्वचालित रूप से प्रेरित पैटर्न-मिलान नियमों को जोड़ते हैं जो निर्माण के सूक्ष्म मापदंडों को सीखते हैं। हमारे परिणामों से पता चलता है कि ये दृष्टिकोण आशाजनक हैं: वे निर्माण मान्यता और कारण और प्रभाव सिर मैचों दोनों के लिए भोले बेसलाइन को काफी बेहतर बनाते हैं।', 'zh': '本文讨将浅层语义解析广词法单元触发器之外,用因果关系为试用例。 对因果关系可采,语义解析转难。 故吾法基于构造语法(CxG)语言范式之构名。 CxG之中,构造/函数对,可恃任情语义。 未有如NLP之CxG试者,各有所结,卸载之于机器学也。 我们述了两种用标记因果结构及论点的监督法。 此二者,皆将自诱之式,与计分类之器合,计分类之器,可以学构之微参数。 吾结果表明之道,甚有冀焉:其构识因果头配,显优素基线。', 'ru': 'В этой статье исследуется расширение неглубокого семантического синтаксического анализа за пределы триггеров лексической единицы, используя причинно-следственные связи в качестве тестового случая. Семантический разбор становится трудным перед лицом широкого разнообразия лингвистических реализаций, которые может принять на себя причинно-следственная связь. Поэтому мы основываем наш подход на концепции построений из лингвистической парадигмы, известной как грамматика построения (CxG). В CxG конструкция - это сопряжение форм/функций, которое может опираться на произвольные лингвистические и семантические особенности. Вместо того, чтобы кодировать все аспекты формы каждой конструкции, как некоторые попытки использовать CxG в NLP, мы предлагаем методы, которые выгружают эту проблему в машинное обучение. Мы описываем два контролируемых подхода к обозначению причинно-следственных связей и их аргументов. Оба подхода объединяют автоматически наведенные правила сопоставления шаблонов со статистическими классификаторами, которые изучают более тонкие параметры построений. Наши результаты показывают, что эти подходы являются многообещающими: они значительно превосходят наивные базовые линии как для распознавания строительства, так и для совпадения причинно-следственных связей.', 'ga': 'Déanann an páipéar seo iniúchadh ar pharsáil shéimeantach éadomhain a shíneadh thar truicear aonad foclóireachta, ag baint úsáide as caidreamh cúiseach mar chás tástála. Éiríonn sé deacair parsáil shéimeantach a dhéanamh i bhfianaise an éagsúlacht leathan réaduithe teangeolaíocha ar féidir le cúisíocht a ghlacadh. Mar sin bunaítear ár gcur chuige ar choincheap na tógála ón paraidím teangeolaíoch ar a dtugtar Tógáil Gramadach (CxG). In CxG, is ionann tógáil agus péireáil foirme/feidhm ar féidir brath ar ghnéithe treallach teanga agus shéimeantacha. Seachas gach gné de gach foirm tógála a chódú, mar atá déanta ag roinnt iarrachtaí CxG a fhostú i NLP, molaimid modhanna a dhíluchtaíonn an fhadhb sin chuig meaisínfhoghlaim. Déanaimid cur síos ar dhá chur chuige maoirsithe chun tógálacha cúiseacha a chlibeáil agus a n-argóintí. Comhcheanglaíonn an dá chur chuige rialacha meaitseála patrún a tharchuirtear go huathoibríoch le haicmitheoirí staidrimh a fhoghlaimíonn paraiméadair níos ísle na dtógálacha. Léiríonn ár dtorthaí go bhfuil na cineálacha cur chuige seo tuar dóchais inti: sáraíonn siad go mór na bunlínte naive maidir le haithint na tógála agus le cluichí ceann cúise agus éifeacht.', 'ka': 'ეს დოკუმენტი განსხვავება, რომელიც ლექსიკალური ერთეულის გარეშე განსხვავებული სიმენტიკური განსხვავება, გამოყენებული მიზეზი შესახებ როგორც ტესტის შემთხვევ Semantic parsing becomes difficult in the face of the wide variety of linguistic realizations that causation can take on. ამიტომ ჩვენ ჩვენი პროგრამის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციას, რომელსაც კონფიგურაცია გრამიმა (CxG) იცით. CxG-ში, კონტურაცია არის ფორმა/ფუნქციის კონტურაცია, რომელიც შეუძლიათ გადარჩენოთ არბრიტური ლენგურისტიკური და ჟენმანტიკური ფუნქციების ყველა კოდიფიკაციის ფორმას ყველა აპექტების კოდიფიკაცია, როგორც NLP-ში CxG-ს გამოყენებას გავაკეთეთეთ, ჩვენ მინდომარებით პრობლემა, რომელიც მაქინის სწავლებისთვის ჩვენ აღწერეთ ორი მონაცემებული პროგრამები, რადგან მიზეზი კონფიგურაციები და მათი არგრამები. ორივე დაეხმარება ავტომატურად მოწყობილობული სტატისტიკური კლასიფიკაციებით, რომლებიც კონფიგურაციების სტატისტიკური პარამეტრების გასწავლობენ. ჩვენი წარმოდგენები აჩვენებს, რომ ეს წარმოდგენები გვეუბნებიან: ისინი ძალიან უფრო ნაირი ფესტური წარმოდგენების განაცნობა და მიზეზი და ეფექტის კონფიგ', 'hu': 'Ez a tanulmány a sekély szemantikai elemzés kiterjesztését vizsgálja a lexikai egységek triggerein túl, az okozati összefüggéseket használva tesztesetként. A szemantikus elemzés nehézzé válik az okozati összefüggések sokféleségével szemben. Ezért megközelítésünket az Construction Grammar (CxG) néven ismert nyelvi paradigmából származó konstrukciók fogalmára alapozzuk. A CxG-ben a konstrukció olyan forma/függvény párosítás, amely tetszőleges nyelvi és szemantikai jellemzőkre támaszkodhat. Ahelyett, hogy az egyes építmények formájának minden aspektusát kodifikálnánk, ahogy néhány próbálkozás tett a CxG alkalmazására az NLP-ben, olyan módszereket javasolunk, amelyek ezt a problémát a gépi tanulásra terhelik. Két felügyelt megközelítést írunk le az okozati konstrukciók és érveik címkézésére. Mindkét megközelítés kombinálja az automatikusan indukált mintaegyezési szabályokat olyan statisztikai osztályozókkal, amelyek megtanulják a konstrukciók finomabb paramétereit. Eredményeink azt mutatják, hogy ezek a megközelítések ígéretesek: jelentősen felülmúlják a naiv alapvonalakat mind az építési felismerés, mind az ok-okozás fejek egyezése tekintetében.', 'el': 'Η παρούσα εργασία διερευνά την επέκταση της ρηχής σημασιολογικής ανάλυσης πέρα από τα σκανδαλώματα λεξικής-μονάδας, χρησιμοποιώντας αιτιώδεις σχέσεις ως δοκιμαστική περίπτωση. Η σημειακή ανάλυση γίνεται δύσκολη ενόψει της μεγάλης ποικιλίας γλωσσικών συνειδητοποιήσεων που μπορεί να λάβει η αιτιώδης συνάρτηση. Ως εκ τούτου, στηρίζουμε την προσέγγισή μας στην έννοια των κατασκευών από το γλωσσικό παράδειγμα γνωστό ως Μηχανική Γραμματική (ΚxG). Στο CxG, μια κατασκευή είναι ένα ζεύγος μορφής/συνάρτησης που μπορεί να βασιστεί σε αυθαίρετα γλωσσικά και σημασιολογικά χαρακτηριστικά. Αντί να κωδικοποιήσουμε όλες τις πτυχές της μορφής κάθε κατασκευής, όπως έχουν κάνει κάποιες προσπάθειες χρήσης στο ΝΛΠ, προτείνουμε μεθόδους που φορτώνουν αυτό το πρόβλημα στη μηχανική μάθηση. Περιγράφουμε δύο εποπτευόμενες προσεγγίσεις για την επισήμανση αιτιακών κατασκευών και των επιχειρημάτων τους. Και οι δύο προσεγγίσεις συνδυάζουν αυτόματα επαγόμενους κανόνες αντιστοίχισης μοτίβων με στατιστικούς ταξινομητές που μαθαίνουν τις λεπτότερες παραμέτρους των κατασκευών. Τα αποτελέσματά μας δείχνουν ότι αυτές οι προσεγγίσεις είναι ελπιδοφόρες: ξεπερνούν σημαντικά τις αφελείς γραμμές βάσης τόσο για την αναγνώριση κατασκευών όσο και για τις αντιστοιχίες αιτίας και αποτελέσματος.', 'it': "Questo articolo esplora l'estensione dell'analisi semantica superficiale oltre i trigger di unità lessicali, utilizzando le relazioni causali come caso di prova. L'analisi semantica diventa difficile di fronte all'ampia varietà di realizzazioni linguistiche che la causalità può assumere. Basamo quindi il nostro approccio sul concetto di costruzioni dal paradigma linguistico noto come Construction Grammar (CxG). In CxG, una costruzione è un accoppiamento forma/funzione che può basarsi su caratteristiche linguistiche e semantiche arbitrarie. Invece di codificare tutti gli aspetti della forma di ogni costruzione, come hanno fatto alcuni tentativi di impiegare CxG in NLP, proponiamo metodi che scaricano quel problema al machine learning. Descriviamo due approcci supervisionati per taggare le costruzioni causali e i loro argomenti. Entrambi gli approcci combinano regole di pattern-matching indotte automaticamente con classificatori statistici che imparano i parametri più sottili delle costruzioni. I nostri risultati dimostrano che questi approcci sono promettenti: superano significativamente le linee di base ingenue sia per il riconoscimento delle costruzioni che per le corrispondenze di causa ed effetto.", 'kk': 'Бұл қағаз лексикалық бірлігінен артық тереңкті семантикалық талдауын тексеру үшін, себепті қатынастарды тексеру үшін қолданады. Semantic parsing becomes difficult in the face of the wide variety of linguistic realizations. Сондықтан біз институтты грамма деп аталатын лингвистикалық парадигмінің конструкцияларының концепциясын негіздеп тұрамыз. CxG- де құрылғы - тіліс және семантикалық қасиеттерге сенімді болатын пішін/функциялық жинақтау. Әрбір құрылғының бүкіл аспекттерін кодтау орнына, NLP-де CxG жұмыс істеу әрекеттері істеген сияқты, бұл мәселеді машина оқытуға жүктеу әдістерін қолданамыз. Біз себепті құрылымдар мен аргументтері үшін екі бақылау арқылы түсіндіредік. Екі жағдайлар құрылғының астындағы параметрлерін үйренетін статистикалық классификаторлармен автоматты түрде сәйкес келетін үлгі ережелерін біріктіреді. Біздің нәтижелеріміз бұл жағдайларды ұсынып береді: олар құрылғыны анықтау мен себептердің басының сәйкестіктері үшін негізгі негізгі негізгі сызықтарын көмектеседі', 'lt': 'Šiame dokumente nagrinėjamas paviršinio semantinio analizavimo išplėtimas viršijant leksinio vieneto įjungiklius, naudojant priežastinius ryšius kaip bandymų atvejį. Semantinis analizavimas tampa sudėtingas atsižvelgiant į didelę kalbų įvairovę, kurią gali sukelti priežastis. Todėl mes grindžiame savo požiūriu konstrukcijų koncepcija pagal kalbinį paradigm ą, vadinamą Statybos Grammar (CxG). CxG konstrukcija – tai formos ir (arba) funkcijų pora, kuri gali būti grindžiama savavališkomis kalbinėmis ir semantinėmis savybėmis. Vietoj to, kad koduojame visus kiekvienos statybos formos aspektus, kaip kai kurie bandymai naudoti CxG NLP, siūlome metodus, kuriais ši problema perkeliama į mašin ų mokymąsi. Aprašome du prižiūrimus būdus, kaip nustatyti priežastinius konstrukcijas ir jų argumentus. Abu metodai derina automatiškai sukeltas modelių derinimo taisykles su statistiniais klasifikatoriais, kurie išmoko subtilesnius konstrukcijų parametrus. Our results show that these approaches are promising: they significantly outperform naive baselines for both construction recognition and cause and effect head matches.', 'mk': 'Оваа хартија ја истражува проширувањето на плошките семантични анализи надвор од активаторите на лексикалната единица, користејќи причинни односи како тест случај. Семантичкото анализирање станува тешко во соочување со широката различност на јазички резултати кои причината може да ги преземе. Затоа го базираме нашиот пристап на концептот на конструкции од јазичкиот парадигм познат како градежен грамар (CxG). In CxG, a construction is a form/function pairing that can rely on arbitrary linguistic and semantic features.  Наместо да ги кодираме сите аспекти на формата на секоја изградба, како што некои обиди за вработување на CxG во NLP, предложуваме методи кои го отфрлаат тој проблем на машинско учење. Опишуваме два надгледувани пристапи за означување на причинните конструкции и нивните аргументи. Двајцата пристапи ги комбинираат автоматски индуцираните правила за одговарање на шеми со статистичките класификатори кои ги научуваат суптилните параметри на конструкциите. Нашите резултати покажуваат дека овие пристапи се ветувачки: тие значително ги надминуваат наивните основни линии за препознавање на изградбата, како и за одбивање на главата на причината и ефектот.', 'ms': 'This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case.  Penghuraian semantik menjadi sukar menghadapi pelbagai pengetahuan bahasa yang penyebab boleh berlaku. Oleh itu, kita mendasarkan pendekatan kita pada konsep konstruksi dari paradigma bahasa yang dikenali sebagai Construction Grammar (CxG). Dalam CxG, pembangunan adalah pasangan bentuk/fungsi yang boleh bergantung pada ciri-ciri bahasa dan semantik arbitrari. Daripada mengkodifikasikan semua aspek bentuk setiap konstruksi, seperti beberapa cubaan untuk menggunakan CxG dalam NLP telah dilakukan, kami cadangkan kaedah yang memuat turun masalah itu ke pembelajaran mesin. Kami menggambarkan dua pendekatan yang diawasi untuk menandai konstruksi penyebab dan argumen mereka. Kedua-dua pendekatan menggabungkan peraturan pemadaman corak yang diinduksi secara automatik dengan pengeklasifikasi statistik yang belajar parameter lebih halus konstruksi. Hasil kami menunjukkan bahawa pendekatan ini berjanji: mereka secara signifikan melebihi garis dasar naif kedua-dua pengenalan konstruksi dan penyebab dan kesan kepala sepadan.', 'mt': 'Dan id-dokument jesplora l-estensjoni tal-analiżi semantika baxxa lil hinn mill-iskattaturi tal-unit à lexika, bl-użu tar-relazzjonijiet kawżali bħala każ tat-test. L-analiżi semantika ssir diffiċli fid-dawl tal-varjetà wiesgħa ta’ realizzazzjonijiet lingwistiċi li l-kawżalità tista’ sseħħ. Għalhekk nibbażaw l-approċċ tagħna fuq il-kunċett ta’ kostruzzjonijiet mill-paradigma lingwistika magħrufa bħala Grammar tal-Kostruzzjoni (CxG). F’CxG, kostruzzjoni hija għaqda ta’ form a/funzjoni li tista’ tiddependi fuq karatteristiċi lingwistiċi u semantiċi arbitrarji. Minflok il-kodifikazzjoni tal-aspetti kollha tal-forma ta’ kull kostruzzjoni, kif għamlu xi tentattivi biex jintużaw CxG fil-NLP, qed nipproponu metodi li jnaqqsu dik il-problema għat-tagħlim tal-magni. Aħna niddeskrivu żewġ approċċi sorveljati għat-tikkettar tal-kostruzzjonijiet kawżali u l-argumenti tagħhom. Iż-żewġ approċċi jikkombinaw regoli awtomatikament indutti għat-tqabbil tal-mudelli ma’ klassifikaturi statistiċi li jitgħallmu l-parametri aktar sottili tal-kostruzzjonijiet. Ir-riżultati tagħna juru li dawn l-approċċi huma promettenti: huma jaqbżu b’mod sinifikanti l-linji bażi naïve kemm għar-rikonoxximent tal-kostruzzjoni kif ukoll għall-logħob tar-ras tal-kawża u tal-effett.', 'mn': 'Энэ цаас нь лексикийн нэгжээс илүү гүнзгий семантик хуваалцааныг судалж, шалгалтын тухай шалгалтын үр дүнг ашиглаж байдаг. Шагнал шалтгаан хийж чадах олон төрлийн хэлний бодит байдлын нүүр дээр семантик хуваалцах нь хэцүү болно. Тиймээс бид өөрсдийнхөө арга барилгыг "Construction Grammar" (CxG) гэдэг хэлний парадигмын тодорхойлолт дээр суурилуулдаг. CxG-д бүтээл бол хэлбэрийн болон семантийн чадварууд дээр хамаарч болох хэлбэрээр/функцын холбоо юм. Бүтээлтийн хэлбэрийн бүх асуудлыг кодлохын оронд зарим нь NLP-д CxG хэрэглэх хичээл хийсэн учраас бид энэ асуудлыг машины суралцах боломжтой арга зааж өгдөг. Бид шалтгаан бүтээлүүд болон тэдний аргументуудыг тэмдэглэх хоёр удирдагдсан арга замыг тайлбарлаж байна. Хоёр арга баримтууд нь баримтуудын доорх параметрыг суралцдаг статистикийн хэлбэртэй автоматаар үйлдвэрлэх загвартай холбоотой. Бидний үр дүнд эдгээр ойлголт амлалтай гэдгийг харуулж байна: тэд барилгын хүлээн зөвшөөрөл, шалтгаан, нөлөөлөл төвлөрөлт хоёуланг бүтээмжлэх үндсэн шугамнуудыг ихэвчлэн ил', 'ml': 'ഈ പേപ്പറിന്റെ പരീക്ഷണത്തിന്റെ കേസ് ഉപയോഗിച്ച് തണുത്ത സെമാന്റിക്ക് പാര്\u200dസിങ്ങ് പാര്\u200dസിങ്ങ് കൂടുതല്\u200d വികസിപ സെമാന്റിക് പാര്\u200dജിങ്ങ് വ്യത്യസ്തമായ ഭാഷകളുടെ മുഖത്ത് ബുദ്ധിമുട്ടുന്നു. കാരണം നടക്കാന്\u200d കഴിയുന്നു അതുകൊണ്ട് നമ്മള്\u200d നിര്\u200dമ്മാണിക്കുന്നത് നിര്\u200dമ്മാണത്തിന്\u200dറെ ആശയത്തിന്\u200dറെ പേരില്\u200d നിന്നാണ്. കെട്ടിടം ഗ്രാമാര്\u200d  സിക്സിജിയില്\u200d, ഒരു ഫോര്\u200dമി/ഫങ്ഷന്\u200d ജോഡിയായി നിര്\u200dമ്മിക്കുന്നു. അത് ആർട്ടിറ്ററിക്കല്\u200d ഭാഷകങ്ങളിലും സെമാന്റിക് എല്ലാ നിര്\u200dമ്മാണത്തിന്റെയും രൂപം കോഡിപ്പ് ചെയ്യാന്\u200d ശ്രമിക്കുന്നതിനെക്കാള്\u200d, NLP-ല്\u200d സിഎക്സ്ജി ഉപയോഗിക്കാന്\u200d ചില ശ്രമിക്കുന്ന ശ്രമ നമ്മള്\u200d രണ്ടു നിരീക്ഷിക്കപ്പെട്ട സാധനങ്ങളെക്കുറിച്ച് വിശദീകരിക്കുന്നു. കാരണം നിര്\u200dമ്മാണങ്ങളെ രണ്ടുപേരും സ്വയമായി നിര്\u200dമ്മിക്കപ്പെട്ട മാതൃകയുമായി പൊരുത്തുന്ന നിയമങ്ങള്\u200d കൂട്ടിചേര്\u200dക്കുന്നു. നിര്\u200dമ്മിതികങ്ങള നമ്മുടെ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു ഈ അടുത്തുകള്\u200d വാഗ്ദാനം ചെയ്യുന്നത്: നിര്\u200dമ്മാണം തിരിച്ചറിയുന്നതും തലയു', 'no': 'Denne papiret utforskar utvida fleire semantiske tolking utanfor leksiske einingar, ved å bruka grunnleggjande forhold som testtilfelle. Semantisk tolking blir vanskeleg i ansikten av dei brede forskjellige lingviske realisasjonane som følgjer å ta på. Vi baserer derfor tilnærminga vårt på konsepten av konstruksjonar frå den lingviske paradigmen kjent som Construction Grammar (CxG). I CxG er eit konstruksjon eit form/funksjonspar som kan rely på tilfeldige lingviske og semantiske funksjonar. I staden for koding av alle aspektane av kvar konstruksjonsform, sidan nokre forsøk å bruka CxG i NLP er ferdige, foreslår vi metodar for å lasta opp det problemet til maskinelæring. Vi skildrar to oversikte tilnærmingar for merking av grunnleggjande konstruksjonar og argumentene sine. Begge tilnærmingar kombinerer automatisk induserte mønsterelementsamsvarreglar med statistiske klassifikatorar som lærer underparametrar for konstruksjonane. Resultatet våre viser at desse tilnærmingane blir forslått: dei utfører betydelig naive baselinjer for både konstruksjonsgjenkjenning og for årsaker og effektkopla.', 'sr': 'Ovaj papir istražuje proširenje plitke semantičke analize izvan okidača leksičke jedinice, koristeći uzrokovane odnose kao test slučaj. Semantičko analiziranje postaje teško suočavati se sa širom različitim jezičkim realizacijama koje uzrok može nastaviti. Stoga osnovamo svoj pristup na koncept konstrukcije iz jezičkog paradigma poznatog kao Grammar za konstrukciju (CxG). U CxG, građevina je oblik/funkcionalni paring koji se može osloniti na arbitrarne jezičke i semantične karakteristike. Umesto kodiranja svih aspekta oblika svake građevine, jer su neki pokušaji da zapošljavaju CxG u NLP-u uradili, predlažemo metode koje prebacuju taj problem na učenje strojeva. Opišemo dve nadzorne pristupe za označavanje uzrokovanih konstrukcija i njihovih argumenata. Obje pristupe kombiniraju automatski indukovane pravila odgovarajuće obrascima sa statističkim klasifikatorima koji nauče podzemne parametre konstrukcije. Naši rezultati pokazuju da su ovi pristupi obećavajući: značajno iznosi naivne osnovne linije za prepoznavanje građevine i uzrok i udarce glave.', 'ro': 'Această lucrare explorează extinderea analizării semantice superficiale dincolo de declanșatorii de unități lexicale, folosind relațiile cauzale ca caz de test. Analiza semantică devine dificilă în fața diversității largi de realizări lingvistice pe care cauzalitatea le poate lua. Prin urmare, ne bazăm abordarea pe conceptul de construcții din paradigma lingvistică cunoscută sub numele de Construcții Grammatica (CxG). În CxG, o construcție este o asociere formă/funcție care se poate baza pe caracteristici lingvistice și semantice arbitrare. În loc să codificăm toate aspectele formei fiecărei construcții, așa cum au făcut unele încercări de a utiliza CxG în PNL, propunem metode care descarcă această problemă în învățarea automată. Descriem două abordări supravegheate pentru etichetarea construcțiilor cauzale și argumentele acestora. Ambele abordări combină regulile induse automat de potrivire a modelelor cu clasificatori statistici care învață parametrii mai subtili ai construcțiilor. Rezultatele noastre arată că aceste abordări sunt promițătoare: depășesc semnificativ liniile de bază naive atât pentru recunoașterea construcțiilor, cât și pentru meciurile de cauză și efect ale capului.', 'pl': 'Niniejszy artykuł bada rozszerzenie płytkiego parsowania semantycznego poza wyzwalacze jednostki leksykalnej, wykorzystując relacje przyczynowe jako przypadek testowy. Parsowanie semantyczne staje się trudne w obliczu szerokiej gamy językowych realizacji, które mogą przyjąć związek przyczynowy. Nasze podejście opiera się zatem na koncepcji konstrukcji z paradygmatu językowego znanego jako Gramatyka Konstrukcji (CxG). W CxG konstrukcja jest parą formy/funkcji, która może opierać się na dowolnych cechach językowych i semantycznych. Zamiast kodyfikować wszystkie aspekty formy każdej konstrukcji, jak zrobiły to niektóre próby zastosowania CxG w NLP, proponujemy metody, które odciążają ten problem do uczenia maszynowego. Opisujemy dwa nadzorowane podejścia do tagowania konstrukcji przyczynowych i ich argumentów. Oba podejścia łączą automatycznie indukowane reguły dopasowania wzorców z klasyfikatorami statystycznymi, które uczą się subtelniejszych parametrów konstrukcji. Nasze wyniki pokazują, że te podejścia są obiecujące: znacznie przewyższają naiwne linie bazowe zarówno w zakresie rozpoznawania konstrukcji, jak i dopasowania głowy przyczyn i skutków.', 'si': 'මේ පත්තර පරීක්ෂණය කරනවා ලෙක්සිකාල් යුනිට් පරීක්ෂණයක් විසින් විසින් විසින් විසින් විසින් විසින් විස සෙමැන්ටික් විශ්ලේෂණය අමාරුයි, භාෂාවික විශේෂ විදියට අමාරුයි. අපි ඉතින් අපේ විදියට සිද්ධ විදියට භාෂාවික පාර්ඩිග්ම් වලින් නිර්මාණය ග්\u200dරාම්මාර් කියලා දන්නවා කියලා  CxG වලින්, නිර්මාණයක් ප්\u200dරමාණයක්/ප්\u200dරමාණයක් සම්බන්ධ වෙන්න පුළුවන් විශේෂ භාෂාවාද්\u200dය සහ සැමැ හැම නිර්මාණයේ හැම ප්\u200dරශ්නයක්ම කෝඩියාගැනීමට වෙනුවෙන්, NLP වල CxG භාවිත කරන්න උත්සාහ කරපු විදියට, අපි ඒ ප්\u200dරශ්නයක් පරි අපි පරික්ෂා කරලා තියෙන්නේ නිර්ධාරිත දෙකක් ප්\u200dරවේශනය සහ ඔවුන්ගේ ප්\u200dරවේශනයක් ටැග් කරන්න. දෙන්නම් අවස්ථාවන් ස්වයංක්\u200dරියාවිතයෙන් ස්වයංක්\u200dරියාවිතයෙන් පෙන්වන්න පෙන්වන්න ප්\u200dරමාණය සමග සංඛ අපේ ප්\u200dරතිචාරයක් පෙන්වන්නේ මේ ප්\u200dරතිචාරය ප්\u200dරතිචාරයක් තියෙනවා: ඔවුන් ගොඩක් විශේෂයෙන් නිර්මාණය සහ හිත', 'so': 'Qoraalkan ayaa ka baaraandegay baaritaanka sahlan ee ka baxsan jardiinada leksikada, isagoo isticmaalaya xiriirka sababta ah sida xaalad imtixaan ah. Xirfadda galmada ayaa ku adag tahay wejiga aad u kala duduwan garashada luuqadaha oo kala duduwan, taas oo sabab u yeelan kara. Sidaa darteed waxaynu ku hoos gelinaynaa fikrada dhismaha ee afka lagu magacaabay xarunta dhismaha (CxG). CxG waxaa ku qoran qaab/shaqo, kaas oo isku xiran kara luqada caadiga ah iyo farsamada semantika. Iska badal in aan kooban dhamaan dhinacyada qaabka dhismaha oo dhan, sida qaar isku dayo in CxG lagu shaqeeyo NLP ay sameeyeen, waxaynu soo jeedaynaa qaababka ay dhibaatadaada u bixiso waxbarashada machine. Waxaannu tilmaamaynaa laba hab oo ilaalinaya oo ay ka baaraandegaan dhismaha sababta iyo dooda. Dhammaan waxay ku soo bandhigaan sharciyada qaababka isku mid ah oo ay ku leeyihiin fasaxyada statisticada, kuwaas oo barta parameteryada hoosta ah ee dhismaha. Abaalkayaga waxaa tusaya in soo dhowaanshahaas waa ballan wanaagsan: waxay si muhiim ah u sameeyaan aasaasyo nail ah oo ay u baahan yihiin aqoonsashada dhismaha iyo sababta ay saameyn ku yeelaan.', 'ta': 'இந்த காகிதத்தை தேடுகிறது ஒரு சோதனையாக பயன்படுத்தி காரணத்திற்கு மேலும் பழுப்பு பாசிங் கூடிய இடைவெளிப்படையான பாடல செமான்டிக் பாசிங் கடினமாக இருக்கும் மொழிகளின் முகத்தில் காரணம் நடக்க முடியும் என்று காரணமாக. ஆகையால் நாம் கட்டுப்பாடு சிக்ஸிஜி என்று பெயரிடப்பட்ட மொழியிலிருந்து கட்டுப்பாட்டுகளின் கருத்தின் மூலம் அடிப்பட CxG-ல் ஒரு கட்டமைப்பு ஒரு வடிவம்/செயல்பாடு ஜோடியாகும், அது ஆர்டிரி மொழி மற்றும் அரை மொழி குணங்களை நம்ப முடியும். ஒவ்வொரு கட்டமைப்பு வடிவத்தின் அனைத்து பாகங்களையும் குறிப்பிடுவதற்கு பதிலாக, NLP ல் சில CxG வேலை செய்ய முயற்சிகள் செய்துள்ளது போல, நாம் இயந நாம் இரண்டு கண்காணிக்கப்பட்ட வழிகளை விவரிக்கிறோம் காரணத்தின் கட்டுப்பாடுகள் மற்றும் வார்த்தைகள். இவ்விருவரும் தானாகவே உருவாக்கப்பட்ட மாதிரி பொருத்தும் விதிகளை சேர்க்கும் புள்ளிவிவரமான வகுப்பாளர்களுடன் புள்ளிவிவரம முடிவு', 'sv': 'Denna uppsats utforskar att utvidga ytlig semantisk tolkning bortom lexikala enhetstriggers, med hjälp av kausala relationer som ett testfall. Semantisk tolkning blir svår mot bakgrund av den stora variationen av språkliga insikter som orsakssamband kan ta sig an. Vi utgår därför från konceptet konstruktion utifrån det språkliga paradigmet Construction Grammar (CxG). I CxG är en konstruktion en form/funktion parning som kan förlita sig på godtyckliga språkliga och semantiska funktioner. Istället för att kodifiera alla aspekter av varje konstruktions form, som vissa försök att använda CxG i NLP har gjort, föreslår vi metoder som avlastar problemet till maskininlärning. Vi beskriver två övervakade tillvägagångssätt för att tagga kausala konstruktioner och deras argument. Båda tillvägagångssätten kombinerar automatiskt inducerade mönstermatchningsregler med statistiska klassificerare som lär sig de subtilare parametrarna i konstruktionerna. Våra resultat visar att dessa tillvägagångssätt är lovande: de presterar betydligt bättre än naiva baslinjer för både konstruktionsigenkänning och orsak och effekt head matchning.', 'ur': 'یہ کاغذ لکسیکل یونیٹ کے علاوہ گھٹی سیمنٹی پارسینگ کی گھٹی پھیلانے کی کوشش کرتا ہے، کیسائل رابطہ کو آزمائش کیس کے طور پر استعمال کرتا ہے. سیمنٹی پارسینٹ مشکل ہو جاتی ہے زبان کی مختلف معلومات کے سامنے جو سبب اٹھائے جاتے ہیں. لہٰذا ہم نے اپنے طریقے کو زبان دیجیم سے بنانے کے معاملہ پر بنیاد رکھا ہے۔ CxG میں ایک ساختار ایک فرم/فنقشنی جوڑ ہے جس پر قابل اعتماد ہو سکتا ہے زبان شناسی اور سیمانٹی ویٹیوں پر۔ ہر ساختار کی فرم کے تمام منظور کو کوڈیٹ کرنے کے بدلے، جیسے NLP میں CxG کا استعمال کرنے کی کوشش کرتی ہے، ہم ایسے طریقے پیشنهاد کرتے ہیں جو اس مسئلہ کو ماشین کی تعلیم کے لئے افلڈ کریں۔ ہم نے دو طریقوں کو توصیح دیتے ہیں جن کی بنائی ہوئی بنائی ہوئی بنائی ہوئی بنائی ہوئی بنائی ہوئی بنائی جاتی ہیں دونوں تقریبا اپنے ساتھ پیٹرنگ مہینٹ کے قانون کو اتنا پیدا کرتا ہے جو ایستٹیسٹی کلیسٹر کے ساتھ سکھاتے ہیں۔ ہمارے نتیجے دکھاتے ہیں کہ یہ تقریبا وعدہ دینے والے ہیں: یہ ساختاری شناسایی اور دلیل اور اثر کے سر کے مطابق نیوی بنسلین سے زیادہ اثر دیتے ہیں۔', 'uz': "Bu qogʻoz sahifa sinov holati sifatida kichkina semantik parlashni o'zgartiradi. Semantik parsing turli tillarda ko'plab o'zgarishga juda qiyin edi. Bu sababning sabablari ishga tushirishi mumkin. Шундай қилиб, biz tilni yaratish grammatika (CxG) deb nomlangan tashkilotning fikrini asosimiz. Name Bu muammolarni mashinani o'rganish uchun qo'llanmagan hamma qismlarni kodlash mumkin. Биз иккита сақланган ҳужжатларга мисол қилиб келтирамиз, у сабаб турли ҳужжатлар ва ҳужжатлар билан ҳужжат қилишга мувофиқ кўриниб турибди. Ikkita usul avtomatik qoidalarni avtomatik ishlab chiqarish qoidalari bilan statistik darajalari bilan birlashtirish. Bu quyidagi tub parametrlarni o'rganish mumkin. Bizning natijalarimiz shu murakkablarini hozir qiladi: ular quyidagi raqamli asboblar bilan tasdiqlash va boshqa qiymatiga ishlash va bajarish natijalarini bajaradi.", 'vi': 'Tờ giấy này tìm hiểu về cách phân tích nhỏ hơn ngoài kích hoạt ngôn ngữ văn học, sử dụng quan hệ hệ hệ hệ hệ hệ hệ hệ hệ hệ thống. Phân tích kỳ diệu trở nên khó khăn khi đối mặt với sự đa dạng ngôn ngữ rộng mà sự phù hợp có thể diễn ra. Chúng ta dựa trên khái niệm xây dựng từ mô hình ngôn ngữ gọi là Grammar cấu trúc (CxG). Ở CxG, một cấu trúc là một cặp dạng/chức năng có thể dựa trên các tính năng ngôn ngữ và ngữ pháp ngẫu nhiên. Thay vì mã hoá tất cả các khía cạnh của mỗi hình thức xây dựng, như một s ố cố gắng áp dụng COxG tại Njala đã làm, chúng tôi đề xuất phương pháp chuyển tải vấn đề này sang học vấn máy móc. Chúng tôi mô tả hai phương pháp giám sát để xác định các công trình nguyên nhân và lý luận. Cả hai phương pháp kết hợp các quy tắc khớp mẫu tự động với các phân loại thống kê học các tham số dưới của công trình. Những kết quả của chúng ta cho thấy những phương pháp này rất có triển vọng, chúng còn thua kém những con đường nền ngây thơ cho cả việc nhận dạng công trình lẫn gây và hiệu quả.', 'da': 'Denne artikel undersøger at udvide overfladisk semantisk parsing ud over lexikale enhedsudløsere, ved hjælp af kausale relationer som et test case. Semantisk fortolkning bliver vanskelig i lyset af de mange forskellige sproglige erkendelser, som årsagssammenhæng kan påtage sig. Vi baserer derfor vores tilgang på konceptet konstruktion fra det sproglige paradigme kendt som Construction Grammar (CxG). I CxG er en konstruktion en form/funktion parring, der kan afhænge af vilkårlige sproglige og semantiske funktioner. I stedet for at kodificere alle aspekter af hver konstruktion form, som nogle forsøg på at anvende CxG i NLP har gjort, foreslår vi metoder, der aflaster dette problem til maskinlæring. Vi beskriver to overvågede tilgange til mærkning af kausale konstruktioner og deres argumenter. Begge tilgange kombinerer automatisk inducerede mønstermatchningsregler med statistiske klassificerere, der lærer de finere parametre i konstruktionerne. Vores resultater viser, at disse tilgange er lovende: De overgår væsentligt naive basislinjer for både konstruktionsanerkendelse og årsag og effekt hovedmatch.', 'nl': 'Dit artikel onderzoekt het uitbreiden van ondiepe semantische parsing buiten lexicale-eenheden triggers, met behulp van causale relaties als testcase. Semantische parsing wordt moeilijk in het licht van de grote verscheidenheid aan taalkundige realisaties die causatie kan aannemen. We baseren ons daarom op het concept van constructies vanuit het linguïstische paradigma dat bekend staat als Construction Grammar (CxG). In CxG is een constructie een vorm/functie koppeling die kan vertrouwen op willekeurige linguïstische en semantische kenmerken. In plaats van alle aspecten van de vorm van elke constructie te codificeren, zoals sommige pogingen om CxG in NLP te gebruiken hebben gedaan, stellen we methoden voor die dat probleem ontladen aan machine learning. We beschrijven twee begeleide benaderingen voor het taggen van causale constructies en hun argumenten. Beide benaderingen combineren automatisch geïnduceerde patronen-matching regels met statistische classificatoren die de subtielere parameters van de constructies leren. Onze resultaten tonen aan dat deze benaderingen veelbelovend zijn: ze presteren aanzienlijk beter dan naïeve baselines voor zowel constructie herkenning als oorzaak en gevolg head matches.', 'de': 'In diesem Beitrag wird die Erweiterung der oberflächlichen semantischen Parsing über lexikalische Einheiten-Trigger hinaus untersucht, wobei kausale Beziehungen als Testfall verwendet werden. Die semantische Parsing wird angesichts der Vielzahl sprachlicher Erkenntnisse, die Kausalität annehmen kann, schwierig. Unser Ansatz basiert daher auf dem Konzept der Konstruktionen aus dem linguistischen Paradigma der Construction Grammar (CxG). In CxG ist eine Konstruktion eine Form/Funktion Paarung, die sich auf beliebige linguistische und semantische Merkmale stützen kann. Anstatt alle Aspekte der Form jeder Konstruktion zu kodieren, wie einige Versuche, CxG in NLP einzusetzen, schlagen wir Methoden vor, die dieses Problem auf maschinelles Lernen verlagern. Wir beschreiben zwei überwachte Ansätze zur Kennzeichnung kausaler Konstruktionen und ihrer Argumente. Beide Ansätze kombinieren automatisch induzierte Muster-Matching-Regeln mit statistischen Klassifikatoren, die die subtileren Parameter der Konstruktionen erlernen. Unsere Ergebnisse zeigen, dass diese Ansätze vielversprechend sind: Sie übertreffen naive Baselines sowohl bei der Konstruktionserkennung als auch bei der Ursache-Wirkungs-Headmatches deutlich.', 'hr': 'Ovaj papir istražuje proširenje plitke semantičke analize izvan okidača leksičke jedinice, koristeći uzročne odnose kao test slučaj. Semantičko razmatranje postaje teško suočavati se s širom raznolikosti jezičkih realizacija koje uzrok može nastaviti. Stoga temeljimo svoj pristup na koncept konstrukcija iz jezičkog paradigma poznatog kao Grammar za konstrukciju (CxG). U CxG-u građevina je oblik/funkcionalni parenje koji se može osloniti na proizvoljne jezičke i semantičke funkcije. Umjesto kodiranja svih aspekta oblika svake građevine, kao što su neke pokušaje zapošljavanja CxG u NLP-u učinile, predlažemo metode koje prebacuju taj problem na učenje strojeva. Opišemo dvije nadzorne pristupe za označavanje uzročnih konstrukcija i njihovih argumenata. Obje pristupe kombiniraju automatski indukovane pravila odgovarajuće obrascima s statističkim klasifikatorima koji nauče podzemne parametre konstrukcije. Naši rezultati pokazuju da su te pristupe obećavajuće: značajno nadmašuju naivne osnovne linije za prepoznavanje građevine i uzrok i učinkovitost glave.', 'id': 'Kertas ini mengeksplorasi penelitian semantis rendah di luar pemicu unit-leksik, menggunakan hubungan penyebab sebagai kasus tes. Analisasi sementik menjadi sulit dihadapan dengan berbagai jenis pengetahuan bahasa yang penyebab dapat menerima. Oleh karena itu kita mendasarkan pendekatan kita pada konsep konstruksi dari paradigma bahasa yang dikenal sebagai Construction Grammar (CxG). Dalam CxG, sebuah konstruksi adalah pasangan bentuk/fungsi yang dapat bergantung pada ciri-ciri bahasa dan semantis secara arbitrar. Daripada mengkodifikasi semua aspek bentuk setiap konstruksi, seperti beberapa percobaan untuk menggunakan CxG di NLP telah dilakukan, kami mengusulkan metode yang mengunggah masalah itu ke belajar mesin. Kami menggambarkan dua pendekatan yang diawasi untuk menandai konstruksi penyebab dan argumen mereka. Kedua pendekatan menggabungkan secara otomatis aturan pemadaman pola dengan klasifikasi statistik yang mempelajari parameter yang lebih halus dari konstruksi. Hasil kami menunjukkan bahwa pendekatan ini berjanji: mereka secara signifikan melebihi garis dasar naif untuk pengenalan konstruksi dan penyebab dan efek kepala pertandingan.', 'ko': '본고는 인과관계를 예로 삼아 얕은 의미 분석을 어휘 단위 촉발기 밖으로 확대하는 문제를 연구했다.인과관계에 나타날 수 있는 다양한 언어 인식에 직면하여 의미 분석은 매우 어려워졌다.따라서 우리의 방법은 구식문법(CxG)이라 불리는 언어학 패러다임의 구식 개념을 바탕으로 한다.CxG에서 구조는 임의의 언어와 의미 특징에 의존할 수 있는 형식/기능 배합이다.우리는 NLP에서 CxG를 사용한 시도처럼 각 구조 형식의 각 방면을 인코딩하지 않고 이 문제를 기계 학습으로 옮기는 방법을 제시했다.우리는 인과 구조와 그 논점을 표시하기 위해 두 가지 감독이 있는 방법을 묘사했다.이 두 가지 방법은 모두 자동으로 생성된 패턴 일치 규칙과 통계 분류기를 결합시켜 학습 구조의 더욱 미묘한 매개 변수를 만든다.우리의 결과에 의하면 이러한 방법은 전도가 유망하다. 구조 식별과 인과 헤드의 일치에 있어 원시 기선보다 현저히 우수하다.', 'sw': 'This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case.  Uchapishaji wa kimapenzi unakuwa vigumu mbele ya utambulisho mbalimbali wa lugha kwamba sababu zinaweza kuchukua. Kwa hiyo tunaweka msimamo wetu juu ya dhana ya ujenzi kutoka kwenye upande wa lugha unaoitwa Mjengo (CxG). Nchini CxG, ujenzi ni aina/function inayochanganya ambazo inaweza kutegemea lugha za kiutaratibu na vipengele vya sekunde. Badala ya kuweka maeneo yote ya aina ya kila ujenzi, kama baadhi ya jaribio la kutumia CxG katika NLP zimefanya, tunapendekeza njia ambazo zitoa tatizo hilo kwa ajili ya kujifunza mashine. Tunawaelezea njia mbili zilizofuatiliwa kwa ajili ya kuchagua ujenzi wa sababu na hoja zao. mbili hizo mbili zinaunganisha kanuni zilizotengenezwa na mitindo yanayofanana na wataalamu wa takwimu ambao wanajifunza vipimo vidogo vya ujenzi. Matokeo yetu yanaonyesha kuwa mbinu hizi zina ahadi: wanafanya vizuri zaidi misingi ya msingi kwa ajili ya kutambua ujenzi na kusababisha maana ya kichwa chake.', 'fa': 'این کاغذ تحقیق کشف کردن پردازش سیمانتیک کوچک فراتر از ماشه\u200cهای واحد زبان\u200cشناسی، با استفاده از رابطه\u200cهای سبک به عنوان یک پرونده آزمایش می\u200cکند. تقسیم سیماتیک در صورت مختلف فکرهای زبان\u200cشناسی که دلیل می\u200cتواند به کار برسد سخت می\u200cشود. بنابراین ما روش خود را بر روی مفهوم ساختاری از پارادیگ زبان شناخته می\u200cکنیم که به عنوان گرم ساختاری (CxG). در CxG، ساختمان یک جفت فرم/عملکرد است که می تواند بر ویژه\u200cهای زبان\u200cشناسی و semantic اختلاف اعتماد داشته باشد. به جای کودکان کردن تمام نقطه\u200cهای شکل هر ساختمان، همانطور که بعضی تلاش برای استفاده از CxG در NLP انجام داده\u200cاند، ما روش\u200cهای پیشنهاد می\u200cدهیم که این مشکل را برای یادگیری ماشین نابار کنند. ما دو دستور تحت نظر قرار گرفته برای برچسب ساختار باعث دلایل و بحث\u200cهایشان را توصیف می\u200cکنیم. هر دو دستیابی از طریق\u200cها قانون\u200cهای هماهنگ\u200cکننده\u200cی نمونه\u200cهای خودکار با گروه\u200cهای آمار\u200cشناسی که پارامترهای زیر ساختمان را یاد می\u200cگیرند ترکیب می\u200cکند. نتیجه\u200cهای ما نشان می\u200cدهند که این نزدیک\u200cها قول می\u200cدهند: آنها خیلی زیادی برای شناسایی ساختمان و دلایل و مسابقه\u200cهای سر و تاثیر عمده\u200cای بیشتر از آن انجام می\u200cدهند.', 'bg': 'Тази статия изследва разширяването на плиткото семантично анализиране отвъд отключващите лексикални единици, като използва причинно-следствените връзки като тест случай. Семантичното анализиране става трудно в лицето на голямото разнообразие от езикови осъзнавания, които причинно-следствената връзка може да поеме. Затова подходът ни се основава на концепцията за конструкции от езиковата парадигма, известна като Строителна граматика (СхГ). В СхГ конструкцията е сдвояване форма/функция, което може да разчита на произволни лингвистични и семантични характеристики. Вместо да кодифицираме всички аспекти на формата на всяка конструкция, както са направили някои опити да се използва в НЛО, ние предлагаме методи, които прехвърлят този проблем на машинното обучение. Описваме два надзорни подхода за маркиране на причинно-следствени конструкции и техните аргументи. И двата подхода комбинират автоматично индуцирани правила за съвпадение на модели със статистически класификатори, които научават по-фините параметри на конструкциите. Нашите резултати показват, че тези подходи са обещаващи: те значително превъзхождат наивните базови линии както за разпознаване на конструкциите, така и за съвпадение на причините и ефектите.', 'tr': 'Bu kagyz leksik unit öňünden boşluk semantik analysiýany çykarýar, kynçylyk derejesini test kiçi ulanýar. Semantik aýlamak sebäbi bolup biljek dürli dillerin çäreleriniň ýüzüne kyn bolar. Şol sebäpli, biz lingwistiki paradigmanyň "Construction Grammar" diýip bilinýän ýagdaýymyzy düşündirdik. CxG\'de bir inşaat, hatlary hatlary we semantik karakterlere ynamly bolan bir şekilde/funksiýa çizmidir. Her in şaat şekliniň ähli aspektini kodlemek ýerine, NLP\'de CxG işlemek isleýän käbirleri üçin bu meseleni maşynyň öwrenmesine ýüklemek üçin ýunlary teklip edýäris. Biz sebäbi guramlary we argumlaryny etiketlemek üçin iki gözetli golaýlaşýarys. Her iki yaklaşım, inşaat altı parametrelerini öğrenen istatistikler klasörleri ile otomatik olarak etkileşimli kuralları birleştir. Biziň netijelerimiz bu ýagdaýlaryň söz berýändigini görkezýär: bu ýagdaýyň tanyşy we netijesi hem kellämiz üçin nähili üýtgeşik hatlarynyň üstünde däldir.', 'af': "Hierdie papier ondersoek die uitbreiding van skaal semantiese verwerking buite leksikaal- eenheid uitbreiding, gebruik oorsaaklike verhouding as 'n toets geval. Semantiese verwerking word moeilik in die gesig van die wyde verskillende lingwisiese realisasies wat veroorsaak kan neem. Ons basiseer dan ons toegang op die konsepte van konstruksies van die lingwisiese paradigme bekend as Construction Grammar (CxG). In CxG, 'n konstruksie is 'n vorm/funksie paar wat kan vertrou op arbitrêre lingvisse en semantiese funksies. In plaas van kodering van alle aspekte van elke konstruksie se vorm, as sommige probeer om CxG in NLP te gebruik het gedoen, voorstel ons metodes wat daardie probleem aflaai vir masjien leer. Ons beskrywe twee ondersoekte toegang vir merking van oorsaakte konstruksies en hulle argumente. Beide toegang kombinieer automaties aangedoende patroon- ooreenstemmende reëls met statistiese klassifiseerders wat die ondersteunde parameters van die konstruksies leer. Ons resultate wys dat hierdie toegang belofte is: hulle betekeurig uitvoer naive basisline vir beide konstruksie herken en oorsaak en effektkop ooreenstemmende.", 'sq': 'Ky artikull eksploron zgjerimin e analizimit semantik të sipërme përtej shkaktuesve të njësisë lexike, duke përdorur marrëdhëniet shkakuese si një rast testimi. Analizimi Semantik bëhet i vështirë përpara shumicës së gjerë të kuptimeve gjuhësore që shkaku mund të marrë. Prandaj ne bazojmë qasjen tonë në konceptin e ndërtimeve nga paradigma gjuhësore e njohur si Grama e Ndërtimit (CxG). Në CxG, një ndërtim është një çiftim i form ës/funksionit që mund të mbështetet në karakteristika gjuhësore dhe semantike arbitrare. Në vend të kodifikimit të të gjitha aspekteve të form ës s ë çdo ndërtimi, siç kanë bërë disa përpjekje për të punësuar CxG në NLP, ne propozojmë metoda që e shkarkojnë këtë problem në mësimin e makinave. Ne përshkruajmë dy metoda të mbikqyrura për të etiketuar ndërtesat shkaktuese dhe argumentet e tyre. Të dy qasjet kombinojnë automatikisht rregullat e induktuara për përshtatjen e modeleve me klasifikuesit statistikë që mësojnë parametrat më subtil të ndërtimeve. Rezultatet tona tregojnë se këto qasje janë premtuese: ato tejkalojnë në mënyrë të konsiderueshme linjat bazë naive si për njohjen e ndërtimit, ashtu edhe për ndeshjet e shkakut dhe efektit të kokës.', 'hy': 'Այս թղթին ուսումնասիրում է մակերեսային սեմանտիկ վերլուծությունը, որը վերաբերում է լեքսիկական միավորի կոճակներին, օգտագործելով պատճառային հարաբերությունները որպես փորձարկման դեպք: Սեմանտիկ վերլուծությունը դառնում է դժվար լեզվաբանական բազմաթիվ գիտակցությունների առջև, որոնք պատճառը կարող է իրականացնել: Այսպիսով, մենք հիմնում ենք մեր մոտեցումը կառուցվածքների գաղափարի վրա լեզվաբանական պարադիգմայից, որը հայտնի է որպես Կառուցման Գրամար (CxG). CxG-ում կառուցվածքը ձևի և ֆունկցիոնալ զույգ է, որը կարող է հիմնվել ցանկացած լեզվաբանական և սեմանտիկ հատկությունների վրա: Ավելի քան կոդավորել յուրաքանչյուր կառուցվածքի ձևի բոլոր ասպեկտները, ինչպես որոշ փորձեր են օգտագործել CxG-ը ՆԼՊ-ում, մենք առաջարկում ենք մեթոդներ, որոնք ներբեռնում են այդ խնդիրը մեքենային սովորելու համար: Մենք նկարագրում ենք պատճառի կառուցվածքների և նրանց բանավեճերի վրա երկու վերահսկված մոտեցում: Երկու մոտեցումները միավորում են ինքնաբերաբար արտադրված կաղապարների համապատասխանման կանոնները վիճակագրական դասակարգումների հետ, որոնք սովորում են կառուցվածքների ավելի նուրբ պարամետրերը: Our results show that these approaches are promising: they significantly outperform naive baselines for both construction recognition and cause and effect head matches.', 'az': 'Bu kağıt leksik-unit istiqamətlərindən ötrü küçük semantik analizi genişləndirir, çünki səbəb əlaqələrini test məsəli olaraq istifadə edir. Semantik ayırma səbəb edə biləcək dillərin çoxluğunun qarşısında çətin olar. Buna görə də Yapılandırma Grammar (CxG) kimi bilinmiş dil paradigmindən yapılandırma məsələlərinə görə yaxınlığımızı təyin edirik. CxG içində bir inşaat, dil və semantik özelliklərinə təvəkkül edə biləcək formu/funksiyalı çiftlikdir. NLP-də CxG istifadə etmək istədikləri kimi, hər in şaat form as ının bütün aspektlərini kodlamaq yerinə, bu problemi maşına öyrənmək üçün yükləyən metodları təklif edirik. Biz tədbir inşallarını və argumentlərini etiketləmək üçün iki nəzarətli tərzdə təsbit edirik. İki yaxınlıqlar inşalların altı parametrlərini öyrənən statistik klasifikatçıları ilə avtomatik olaraq təşkil edilmiş örtükləri ilə birləşdirirlər. Sonuçlarımız bu təsirlərin və ’ d etdiklərini göstərir: onlar inşaat tanıması, səbəb və etkisi başlıqların müqabiliyyətində həddi aşmaqlarını çox layiq edirlər.', 'bn': 'This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case.  সেম্যান্ডিক পার্গিং বিভিন্ন ভাষার বিভিন্ন বিষয়ের মুখে কঠিন হয়ে যাচ্ছে যে কারণের কারণ নিয়ে যাবে। তাই আমরা ভাষার ভাষার প্যারাডিম থেকে নির্মাণের ধারণা নিয়ে আমাদের পদক্ষেপ নির্ভর করি (সিক্সিজি)। সিক্সিজিতে একটি নির্মাণ ফর্ম/ফাংশন যুদ্ধ করা যায় যা বৈরাজ্যিক ভাষায় নির্ভর করতে পারে। প্রতিটি নির্মাণের ফর্মের সকল প্রাক্ষাপগুলোকে কোডিয়ার করার বদলে, এনএলপিতে কিছু সিক্সিজি কাজ করার চেষ্টা করার চেষ্টা করার চেষ্টা করছে, আমরা প We describe two supervised approaches for tagging causal constructions and their arguments.  এই দুটি প্রতিক্রিয়া স্বয়ংক্রিয়ভাবে স্থায়ীভাবে প্রতিষ্ঠিত প্যানেট-মিল্যান্ট নিয়ম সম্পূর্ণ করে সংখ্যাত পরিসংখ্যা আমাদের ফলাফল দেখা যাচ্ছে যে এই প্রতিযোগিতা প্রতিশ্রুতিশীল: তারা নির্মাণ স্বীকৃতি এবং মাথা ম্যাচের জন্য গুরুত্বপূর্', 'bs': 'Ovaj papir istražuje proširenje plitke semantičke analize izvan okidača leksičke jedinice, koristeći uzročne odnose kao test slučaj. Semantičko analiziranje postaje teško suočavati se sa širom različitim jezičkim realizacijama koje uzrok može nastaviti. Stoga temeljimo svoj pristup na koncept konstrukcije iz jezičkog paradigma poznatog kao Grammar konstrukcije (CxG). U CxG, građevina je oblik/funkcionalni paring koji se može osloniti na proizvoljne jezičke i semantičke karakteristike. Umjesto kodiranja svih aspekta oblika svake građevine, kao što su neke pokušaje zapošljavanja CxG u NLP-u učinile, predlažemo metode koje prebacuju taj problem na učenje strojeva. Mi opisujemo dvije nadzorne pristupe za označavanje uzrokovanih konstrukcija i njihovih argumenata. Obje pristupe kombiniraju automatski indukovane pravila odgovarajuće obrascima sa statističkim klasifikatorima koji nauče podzemne parametre konstrukcije. Naši rezultati pokazuju da su te pristupe obećavajuće: oni značajno nadmađuju naivne osnovne linije za prepoznavanje građevine i uzrok i udarce glave.', 'et': 'Käesolevas töös uuritakse madala semantilise parsimise laiendamist väljaspool leksikaalühiku käivitajaid, kasutades katsejuhtumina põhjuslikke seoseid. Semantiline parsimine muutub keeruliseks, arvestades mitmesuguseid keelelisi arusaamasid, mida põhjuslik seos võib võtta. Seetõttu tugineme oma lähenemisviisile konstruktsioonide kontseptsioonile keelelisest paradigmast, mida tuntakse ehitusgrammatika (CxG). CxG-s on konstruktsioon vormi/funktsiooni paaritus, mis võib tugineda suvalisele keelelisele ja semantilisele omadusele. Selle asemel, et kodifitseerida iga ehituse vormi kõiki aspekte, nagu mõned katsed kasutada CxG NLP, pakume välja meetodid, mis laadivad selle probleemi masinõppesse. Kirjeldame kahte juhendatud lähenemisviisi põhjuslike konstruktsioonide ja nende argumentide märgistamiseks. Mõlemad lähenemisviisid kombineerivad automaatselt indutseeritud mustrite sobitamise reeglid statistiliste klassifikaatoritega, mis õpivad konstruktsioonide peenemaid parameetreid. Meie tulemused näitavad, et need lähenemisviisid on paljutõotavad: nad ületavad märkimisväärselt naiivseid lähtejooni nii ehituse tuvastamisel kui ka põhjuse ja mõju pea sobitamisel.', 'cs': 'Tento článek zkoumá rozšíření mělké sémantické parsování mimo lexikální jednotky triggerů s využitím kauzálních vztahů jako testovacího případu. Sémantická analýza se stává obtížná vzhledem k široké škále jazykových realizací, které může příčinná souvislost přijmout. Náš přístup proto vycházíme z konceptu konstrukcí z lingvistického paradigmatu známého jako Construction Grammar (CxG). V CxG je konstrukce párování formy a funkcí, které se může spoléhat na libovolné lingvistické a sémantické rysy. Namísto kodifikace všech aspektů formy každé konstrukce, jak učinily některé pokusy o využití CxG v NLP, navrhujeme metody, které tento problém přenesou do strojového učení. Popisujeme dva kontrolované přístupy pro tagování kauzálních konstrukcí a jejich argumentů. Oba přístupy kombinují automaticky indukovaná pravidla porovnávání vzorů se statistickými klasifikátory, které se naučí jemnější parametry konstrukcí. Naše výsledky ukazují, že tyto přístupy jsou slibné: výrazně překonávají naivní základní linie jak pro rozpoznávání konstrukcí, tak pro shody příčin a následků hlavy.', 'am': 'ይህ ገጽ ከሌክሲካዊ ክፍል በላይ ጥቁር ስሜኒካዊ ፓርቲ ማሰናከል ይፈልጋል፡፡ የቋንቋ ቋንቋዎች በተለያዩ የስምናኒክ ማኅበረሰብ ላይ ይጨነቃል፡፡ እንግዲህ ከቋንቋው አካባቢ (CxG) የተባለው ግንኙነታችንን እናሳውቃለን፡፡ በCxG፣ ግንኙነቱ በarbitrary ቋንቋዊ እና በsemantic ፊደሎች ላይ የሚደገፍ ፎርማት/функсия ነው፡፡ ከሁሉም የግንኙነቱ ዓይነቶች ሁሉ ማቀናጃ ካለፉ በቀር፣ አንዳንዶች በNLP ውስጥ CxG ለማገኘት ሲሞክሩ፣ ይህንን ጉዳይ ለመማከሪያ ማስተማር የሚያሳድጉትን ሥርዓቶች እናስጀክራለን፡፡ ሁለት ተሟጋቾች አካባቢዎችን እና ክርክራቸውን ለመቀላቀል እናሳውቃለን፡፡ Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions.  ፍጥረታችን ይህ ደረጃዎች የተስፋ ቀጠሮ እንዲሆኑ ያሳያል፤ የግንቡን ማስታወቂያ እና የራሳቸውን ፍጥረት ማሳየት እና ማድረግ የሚያስፈልጉት የጥረት መሠረት አካባቢ ነው፡፡', 'fi': 'Tässä artikkelissa tarkastellaan matalan semanttisen jäsentämisen laajentamista leksikaaliyksikön triggereiden ulkopuolelle käyttäen kausaalisuhteita testitapauksena. Semanttinen jäsentäminen vaikeutuu, kun otetaan huomioon, että syy-yhteys voi saada aikaan monenlaisia kielellisiä oivalluksia. Lähestymistapamme perustuu konstruktioiden käsitteeseen, joka perustuu konstruktion kielioppiin (CxG). CxG:ssä rakenne on muoto/funktio pariliitos, joka voi luottaa mielivaltaisiin kielellisiin ja semanttisiin ominaisuuksiin. Sen sijaan, että koodaisimme jokaisen rakenteen kaikkia näkökohtia, kuten jotkut yritykset käyttää CxG:tä NLP:ssä ovat tehneet, ehdotamme menetelmiä, jotka siirtävät ongelman koneoppimiseen. Kuvailemme kahta valvottua lähestymistapaa kausaalisten konstruktioiden ja niiden argumenttien merkitsemiseen. Molemmissa lähestymistavoissa yhdistetään automaattisesti indusoituja kuvioiden täsmäytyssääntöjä tilastollisiin luokittelijoihin, jotka oppivat konstruktioiden hienovaraisemmat parametrit. Tuloksemme osoittavat, että nämä lähestymistavat ovat lupaavia: ne ylittävät huomattavasti naiivit perusviivat sekä rakentamisen että syy- ja seurauspäätöjen tunnistamisessa.', 'ca': "This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case.  L'analització semàtica esdevé difícil davant de la gran varietat de percepcions lingüístices que la causació pot prendre. Per tant, basam el nostre enfocament en el concepte de construccions del paradigma lingüístic conegut com a Grammar de Construcció (CxG). In CxG, a construction is a form/function pairing that can rely on arbitrary linguistic and semantic features.  En comptes de codificar tots els aspectes de la forma de cada construcció, com han fet alguns intents d'emplegar CxG a NLP, proposem mètodes que descarreguen aquest problema a l'aprenentatge automàtic. Descrivem dos enfocaments supervisats per etiquetar les construccions causals i els seus arguments. Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions.  Els nostres resultats demostren que aquests enfocaments són prometedors: superen significativament les línies de base naives tant per al reconeixement de la construcció com per al reconeixement de la causa i l'efecte.", 'jv': 'Perintah sing dipunanggé nggawe semanti-pernik nik nik nggawe lejih-pernik nik nganggo cara-pernik nik nggawe barang kelas kuwi nyong. Samantar tentang manungsa kuwi susah-susahe nganggo akeh lan pakan-pakan anyari tentang Language Awakdhéwé éntuk dhéwé nggawe barang nggawe barang nggawe barang nggawe Where Digawe ono nggawe perusahaan karo nggawe perusahaan sampeyan pating nggawe ngubah cara nggawe CxG nang NLP dadi, kita supoyo nggawe perusahaan karo perusahaan kuwi iso nggawe Perintah dumateng. 2 Gobinder Rejalaké awak dhéwé ngerasakno iki dadi iki bakal kelas pangan: wong liyane wis ngerasah barang nggawe barang nggawe barang seneng bongkar nggo Kemerdekaan karo dolang-bong iki bakal terus maring.', 'ha': "Wannan karatun yana yin shimfiɗa parse mai shallow na semantic beyond leksikal-unit, kuma yana yin amfani da matsayin sabo kamar jarrabo. Samantic paring ya zama mai ƙunci a gaba ga fuskar wasu misãlai masu cikin harshen da za'a iya samu. We therefore base our approach on the concept of constructions from the linguistic paradigm known as Construction Grammar (CxG).  A cikin CxG, wani bakin wata ana samu'a da wani nau'i mai girma wanda zai iya dõgara kan harsheski na sakantiki. Babu yin kodi ga duk aspecti na tsarin kõwane salon, kamar ko da wasu jarrabo za'a yi amfani da CxG cikin NLP na aikata, za'a buƙata hanyoyin ta samu'ar da za'a loda wannan mataimaki zuwa an sanar da mashine. Kuma Munã buga masa misãlai biyu mãsu tsaro da su ne, sunã tagon mazauni biyu, kuma sunã jãyayya da su. Dukan hanyoyin su koma koma koma cikin sharafan da aka samar da shi farat ɗaya da masu daidaita da tsari na statistical, da masu sanar da parameters guda na mazaɓa. MatamayinMu na nũna cewa waɗannan hanyõyin su ne masu yi wa'adi: sunã tafiyar da bambanci masu muhimmi wa ganin mazaɓa da sunan abun sami kuma su shagala mai girma.", 'sk': 'V prispevku raziskujemo razširitev plitvega semantičnega razčlenjanja preko sprožilcev leksikalnih enot, pri čemer kot testni primer uporabljamo vzročne relacije. Semantno razčlenjevanje postane težko glede na široko paleto jezikovnih spoznanj, ki jih lahko prevzame vzročna zveza. Zato naš pristop temelji na konceptu konstrukcij iz jezikovne paradigme, znane kot konstrukcijska slovnica (CxG). V CxG je konstrukcija združevanje oblike/funkcije, ki se lahko zanese na poljubne jezikovne in semantične značilnosti. Namesto kodifikacije vseh vidikov oblike vsake konstrukcije, kot so naredili nekateri poskusi uporabe CxG v NLP, predlagamo metode, ki prenašajo ta problem na strojno učenje. Opisujemo dva nadzorovana pristopa za označevanje vzročnih konstrukcij in njihovih argumentov. Oba pristopa združujeta avtomatsko inducirana pravila ujemanja vzorcev s statističnimi klasifikatorji, ki se naučijo subtilnejših parametrov konstrukcij. Naši rezultati kažejo, da so ti pristopi obetavni: bistveno presegajo naivne osnovne linije tako za prepoznavanje konstrukcije kot za ujemanje glave vzrokov in posledic.', 'he': "הנייר הזה חוקר את ההעברה סמנטית שטחית מתרחבת מעבר להדקים יחידות לקסיות, בשימוש מערכות יחסים סיבותיות בתיק מבחן. בדיקת סמנטית הופכת לקשה בפני מגוון רחב של הבנות לשוניות שהסיבה יכולה להתמודד. לכן אנו מבססים את הגישה שלנו על הרעיון של בנויות מהפרדיגמה השפתית הידועה בשם גראמאר בנייה (CxG). ב-CxG, בנייה היא זוג צורה/תפקיד שיכול לסמוך על תכונות שפתיים וסמנטיות ברצונות. Rather than codifying all aspects of each construction's form, as some attempts to employ CxG in NLP have done, we propose methods that offload that problem to machine learning.  אנחנו מתארים שני גישות מבוקשות לטייג בניינים סיבותיים והטיעונים שלהם. שני הגישויים משלבים חוקי התאמת דפוסים שנגרמו באופן אוטומטי עם מסווגים סטטיסטיים שלמדו את הפרמטרים העדינים של הבניינים. התוצאות שלנו מראות שהגישות האלה מבטיחות: הן יוצאות משמעותית מעל קווי בסיס נאיבים גם לזהות בנייה וגם לתאמות ראש סיבה ואפקט.", 'bo': 'ཤོག རྒྱུན་ལམ་ལུགས་དབྱེ་ཞིབ་དཔྱད་ན་སྐད་རིགས་སྣེ་མཐོང་བའི་མཐུན་རིམ་མཐུན་གྱི་གདོང་རིས་ དེར་བརྟེན། ང་ཚོས་སྐད་རིགས་ཀྱི་སྔོན་ལྟར་བཞིན་པའི་བཟོ་བརྩིས་ཀྱི་ལམ་ལུགས་ལ་གཞི་རྟེན་ཏེ། CxG ནང་དུ་གཞུང་ནི་རྣམ་པ་ཞིག་ཡིན་པས། སྐད་རིགས་དང་རྣམ་པ་ལྟར་མཐོང་ནུས་མཚམས་ཆོག་ཡིན། བཟོ་བརྩིས་ཀྱི་དབྱིབས་ཡོངས་རེ་རེའི་ནང་གི་ཆ་ཤས་ཡོངས་སྒྲིག་འགོད་མ་བྱེད་པ་ལས། NLP ནང་གི་ ང་ཚོས་རྐྱེན་འབྲེལ་བ་དང་ཁོང་ཚོའི་སྒྲུབ་རྗེས་ཐོག་གི་མཐུན་སྣེ་གཉིས་མཚམས་བཤད་ཀྱི་ཡོད། Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions. ང་ཚོའི་མཐོང་སྣེ་འདི་ཚོ་ཁག་ལ་འཆར་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Head-Lexicalized Bidirectional Tree LSTMs', 'ar': 'LSTMs شجرة ثنائية الاتجاه معجمية الرأس', 'es': 'LSTM de árbol bidireccional lexicalizado por la cabeza', 'fr': "LSTM d'arbres bidirectionnels lexicaux en tête", 'pt': 'LSTMs de árvore bidirecional lexicalizada pela cabeça', 'ja': 'ヘッドレキシカル化された双方向ツリーLSTM', 'zh': '头词法化双向树 LSTM', 'hi': 'सिर-Lexicalized द्विदिश पेड़ LSTMs', 'ru': 'Двунаправленные древовидные LSTM с лексикой головы', 'ga': 'LSTM Crann Déthreo Ceann-Leicseachaithe', 'ka': 'თავის- ლექსიკალიზებული ორდირექციონალური ხე LSTMs', 'hu': 'Fej-lexikált kétirányú fa LSTMs', 'el': 'LSTMs κεφαλής Lexicalized Bidirection Tree', 'kk': 'Айдар- Лексикалық екі бағытты Бұтақ LSTMs', 'it': 'LSTMs ad albero bidirezionale lessicalizzato testa', 'mk': 'Name', 'lt': 'Galvos leksikalizuotos dvikryptinės medžio LSTM', 'mt': 'LSTMs tas-Siġar Bidirezzjonali Lessikalizzat għar-ras', 'mn': 'Хоёр-Лексиксик хоёр багын мод LSTMs', 'no': 'Head- Lexicalized Bidirectional Tree LSTMs', 'ms': 'LSTM Pohon Dua Arah Dileksikan Kepala', 'ml': 'ഹെഡ്- ലെക്സിക്സിക്സിക്കേഷന്\u200d ബൈഡിഡയലില്\u200d വൃക്ഷ LSTMs', 'sr': 'Glava-leksijalna dvosmjernicalna drva LSTMs', 'pl': 'Leksykalizowane dwukierunkowe LSTMy drzewa głównego', 'ro': 'LSTMs cu arbore bidirecțional lexicalizat cap', 'sv': 'Huvudlexikaliserade dubbelriktade träd LSTMs', 'si': 'හෙඩ්- ලෙක්සිකිසිකල් දෙපාර්ශික වල LSTMs', 'so': 'Head-Lexicalized Bidirectional Tree LSTMs', 'ta': 'தலைப்பு- Lexicalized Bidirectional Tree LSTMs', 'ur': 'Head-Lexicalized Bidirectional Tree LSTMs', 'uz': 'Name', 'vi': 'Thân hình trái cây', 'nl': 'Head-Lexicalized Bidirectionele Tree LSTMs', 'hr': 'Glava-leksijalna dvosmjerno drvo LSTMs', 'bg': 'Главно-лексикализирани двупосочни LSTMs', 'da': 'Hovedleksikaliserede toorienterede træ LSTMs', 'de': 'Head-Lexicalized Bidirektional Tree LSTMs', 'fa': 'درخت\u200cهای درخت\u200cهای دوراهی با سر-لکسیکی\u200cسازی\u200cشده LSTMs', 'id': 'Head-Lexicalized Bidirectional Tree LSTMs', 'sw': 'Mti wa Kiongozi wa Lexico LSTMs', 'ko': '헤드 어휘화 쌍방향 트리 LSTM', 'tr': 'Başlyg', 'af': 'Opskrif- Leksialiseer Bidireksionale Boom LSTMs', 'hy': 'Գլխամաս-լեքսիկալիզացված երկուղղային ծառի LSMT-ները', 'am': 'Head-Lexicalized Bidirectional Tree LSTMs', 'az': 'Başlıq-Lexicalized Two-Directional Tree LSTMs', 'sq': 'LSTMs për pemën dy-drejtuese', 'bs': 'Glava-leksijalna dvosmjerno drvo LSTMs', 'bn': 'মাথা লেক্সিক্সিকালিয়াল বাইডেডিয়াল গাছ LSTMs', 'ca': "LSTMs de l'arbre bidireccional Lexicalitzat cap", 'et': 'Pea-leksikaliseeritud kahesuunalised puud LSTMd', 'cs': 'Hlavní Lexikalizované obousměrné LSTMy stromu', 'fi': 'Head-Lexicalized Bidirectional Tree LSTMs', 'jv': 'vertical-aligntextattr', 'he': 'LSTMs עץ שתי כיוונים מלקסיקלי ראש', 'sk': 'Leksikalizirani dvosmerni drevesni LSTMs', 'ha': 'KCharselect unicode block name', 'bo': 'མགོ་ཡིག་གཙོ་བོའི་ཟུར་བ་བཟོས་ཡོད་པའི་སྡོང་བུའི་སྡོང་ཚན LSTMs'}
{'en': 'Sequential LSTMs have been extended to model tree structures, giving competitive results for a number of tasks. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes. This is different from sequential LSTMs, which contain references to input words for each node. In this paper, we propose a method for automatic head-lexicalization for tree-structure LSTMs, propagating head words from leaf nodes to every constituent node. In addition, enabled by head lexicalization, we build a tree LSTM in the top-down direction, which corresponds to bidirectional sequential LSTMs in structure. Experiments show that both extensions give better representations of tree structures. Our final model gives the best results on the Stanford Sentiment Treebank and highly competitive results on the TREC question type classification task.', 'ar': 'تم تمديد LSTMs المتسلسلة لتشمل هياكل شجرة النموذج ، مما يعطي نتائج تنافسية لعدد من المهام. تقوم الطرق الحالية بنمذجة الأشجار المكونة من خلال مجموعات تصاعدية من العقد المكونة ، مما يجعل الاستخدام المباشر لمعلومات الكلمات المدخلة فقط للعقد الورقية. هذا يختلف عن LSTMs المتسلسلة ، والتي تحتوي على مراجع لكلمات الإدخال لكل عقدة. في هذا البحث ، نقترح طريقة للمعجمية التلقائية للرأس لـ LSTMs ذات البنية الشجرية ، ونشر كلمات الرأس من العقد الورقية إلى كل عقدة مكونة. بالإضافة إلى ذلك ، تم تمكينه من خلال معجم الرأس ، نقوم ببناء شجرة LSTM في الاتجاه من أعلى إلى أسفل ، والذي يتوافق مع LSTMs المتسلسلة ثنائية الاتجاه في الهيكل. تظهر التجارب أن كلا الامتدادين يقدمان تمثيلاً أفضل لهياكل الشجرة. يعطي نموذجنا النهائي أفضل النتائج في Stanford Sentiment Treebank ونتائج تنافسية للغاية في مهمة تصنيف نوع السؤال TREC.', 'fr': "Les LSTM séquentiels ont été étendus aux structures d'arbres modèles, ce qui donne des résultats compétitifs pour un certain nombre de tâches. Les méthodes existantes modélisent les arbres constitutifs par des combinaisons ascendantes de nœuds constitutifs, en utilisant directement les informations de mot d'entrée uniquement pour les nœuds feuilles. Cela est différent des LSTM séquentiels, qui contiennent des références à des mots d'entrée pour chaque nœud. Dans cet article, nous proposons une méthode de lexicalisation automatique des têtes pour les LSTM arborescentes, en propageant les mots d'en-tête des nœuds feuilles à chaque nœud constitutif. De plus, grâce à la lexicalisation de la tête, nous construisons un LSTM arborescente dans le sens descendant, qui correspond aux LSTM séquentiels bidirectionnels dans la structure. Les expériences montrent que les deux extensions donnent de meilleures représentations des structures arborescentes. Notre modèle final donne les meilleurs résultats sur le Stanford Sentiment Treebank et des résultats très compétitifs sur la tâche de classification du type de question TREC.", 'es': 'Los LSTM secuenciales se han extendido a estructuras de árbol de modelos, lo que proporciona resultados competitivos para una serie de tareas. Los métodos existentes modelan árboles constituyentes mediante combinaciones ascendentes de nodos constituyentes, haciendo uso directo de la información de las palabras de entrada solo para los nodos hoja. Esto es diferente de los LSTM secuenciales, que contienen referencias a palabras de entrada para cada nodo. En este artículo, proponemos un método para la lexicalización automática de cabecera para LSTM de estructura de árbol, propagando palabras principales desde nodos hoja a cada nodo constituyente. Además, habilitada por la lexicalización de la cabeza, construimos un LSTM de árbol en la dirección de arriba hacia abajo, que corresponde a los LSTM secuenciales bidireccionales en la estructura. Los experimentos muestran que ambas extensiones proporcionan mejores representaciones de las estructuras de los árboles. Nuestro modelo final ofrece los mejores resultados en Stanford Sentiment Treebank y resultados altamente competitivos en la tarea de clasificación de tipos de pregunta TREC.', 'pt': 'LSTMs sequenciais foram estendidos para modelar estruturas de árvore, dando resultados competitivos para uma série de tarefas. Os métodos existentes modelam árvores constituintes por combinações de baixo para cima de nós constituintes, fazendo uso direto das informações da palavra de entrada apenas para nós folha. Isso é diferente de LSTMs sequenciais, que contêm referências a palavras de entrada para cada nó. Neste artigo, propomos um método para lexicalização automática de cabeças para LSTMs de estrutura em árvore, propagando palavras de cabeça de nós folha para cada nó constituinte. Além disso, habilitada pela lexicalização da cabeça, construímos uma árvore LSTM na direção top-down, que corresponde a LSTMs sequenciais bidirecionais na estrutura. Experimentos mostram que ambas as extensões fornecem melhores representações de estruturas de árvore. Nosso modelo final fornece os melhores resultados no Stanford Sentiment Treebank e resultados altamente competitivos na tarefa de classificação do tipo de pergunta TREC.', 'ja': '一連のLSTMは、モデルツリー構造に拡張され、いくつかのタスクの競争的な結果をもたらしている。既存のメソッドは、構成ノードのボトムアップの組み合わせによって構成木をモデル化し、葉ノードに対してのみ入力ワード情報を直接利用する。これは、各ノードの入力ワードへの参照を含むシーケンシャルLSTMとは異なります。本稿では、木構造LSTMの頭辞の自動化方法を提案し、頭辞を葉ノードから各構成ノードに伝播させる。さらに、ヘッド辞書化を有効にすることで、トップダウン方向にツリーLSTMを構築します。これは、構造上の双方向シーケンシャルLSTMに対応しています。実験は、両方の拡張が木構造のより良い表現を与えることを示している。当社の最終モデルは、Stanford Sentiment Treebankでの最高の結果と、TREC質問タイプ分類タスクでの競争の激しい結果を提供します。', 'zh': '次 LSTM 已建模于树构,以资庶务之竞争力。 今法自下而上者节点合为树建模,唯对叶节点直输词息。 此与序 LSTM 不同,后者含节点之输入字引也。 本文中,建一树结构LSTM自头词法化法,传头单词从叶节点至节点。 又因头词法化,上结一树LSTM,双向次LSTM。 实验明,二者皆善树也。 终于斯坦福情树库上与之极,TREC之于事为极具竞争力。', 'hi': 'अनुक्रमिक एलएसटीएम को मॉडल ट्री संरचनाओं तक बढ़ाया गया है, जिससे कई कार्यों के लिए प्रतिस्पर्धी परिणाम मिलते हैं। मौजूदा विधियां घटक नोड्स के बॉटम-अप संयोजनों द्वारा घटक पेड़ों को मॉडल करती हैं, जो केवल पत्ती नोड्स के लिए इनपुट शब्द जानकारी का सीधा उपयोग करती हैं। यह अनुक्रमिक एलएसटीएम से अलग है, जिसमें प्रत्येक नोड के लिए इनपुट शब्दों के संदर्भ होते हैं। इस पेपर में, हम पेड़-संरचना एलएसटीएम के लिए स्वचालित सिर-लेक्सिकलाइजेशन के लिए एक विधि का प्रस्ताव करते हैं, जो पत्ती नोड्स से हर घटक नोड तक सिर के शब्दों का प्रचार करता है। इसके अलावा, सिर lexicalization द्वारा सक्षम, हम ऊपर नीचे दिशा में एक पेड़ LSTM का निर्माण, जो संरचना में द्विदिश अनुक्रमिक LSTMs से मेल खाती है। प्रयोगों से पता चलता है कि दोनों एक्सटेंशन पेड़ संरचनाओं का बेहतर प्रतिनिधित्व देते हैं। हमारा अंतिम मॉडल स्टैनफोर्ड सेंटीमेंट ट्रीबैंक पर सबसे अच्छा परिणाम देता है और TREC प्रश्न प्रकार वर्गीकरण कार्य पर अत्यधिक प्रतिस्पर्धी परिणाम देता है।', 'ru': 'Последовательные LSTM были распространены на модели древовидных структур, давая конкурентные результаты для ряда задач. Существующие методы моделируют составляющие деревья по восходящим комбинациям составляющих узлов, делая непосредственное использование входной информации слова только для листовых узлов. Это отличается от последовательных LSTM, которые содержат ссылки на входные слова для каждого узла. В данной работе мы предлагаем метод автоматической головной лексикализации для LSTM деревьев, распространяющих слова head от листовых узлов к каждому составляющему узлу. Кроме того, благодаря лексикализации головы, мы строим дерево LSTM в направлении сверху вниз, которое соответствует двунаправленным последовательным LSTM в структуре. Эксперименты показывают, что оба расширения дают лучшее представление о структурах деревьев. Наша финальная модель дает наилучшие результаты в Стэнфордском банке сентиментов и высококонкурентные результаты в задаче классификации типов вопросов TREC.', 'ga': 'Leathnaíodh LSTManna seicheamhacha chuig struchtúir shamhaltaithe crann, rud a thugann torthaí iomaíocha ar roinnt tascanna. Déanann na modhanna atá ann cheana na comhchodanna a shamhaltú trí chomhcheangail ón mbun aníos de nóid chomhpháirteacha, ag baint úsáide as faisnéis ionchuir focal amháin le haghaidh nóid dhuilleog. Tá sé seo difriúil ó LSTManna seicheamhach, ina bhfuil tagairtí d’fhocail ionchuir do gach nód. Sa pháipéar seo, molaimid modh le haghaidh foclóireachta ceann uathoibríoch do LSTManna crann-struchtúr, ag iomadú ceannfhocail ó nóid dhuilleog go dtí gach nód comhpháirteach. Ina theannta sin, arna chumasú ag foclóireacht ceann, tógaimid crann LSTM sa treo ón mbarr anuas, a fhreagraíonn do LSTManna seicheamhacha déthreocha i struchtúr. Léiríonn turgnaimh go dtugann an dá shíneadh léiriú níos fearr ar struchtúir crann. Tugann ár múnla deiridh na torthaí is fearr ar an Stanford Sentiment Treebank agus torthaí an-iomaíoch ar thasc aicmithe cineál ceist TREC.', 'el': 'Τα διαδοχικά LSTMs έχουν επεκταθεί σε μοντέλα δομών δέντρων, δίνοντας ανταγωνιστικά αποτελέσματα για μια σειρά εργασιών. Οι υπάρχουσες μέθοδοι μοντελοποιούν τα συστατικά δέντρα με συνδυασμούς από κάτω προς τα πάνω συστατικών κόμβων, κάνοντας άμεση χρήση πληροφοριών λέξεων εισόδου μόνο για κόμβους φύλλων. Αυτό διαφέρει από τα διαδοχικά που περιέχουν αναφορές σε λέξεις εισαγωγής για κάθε κόμβο. Στην παρούσα εργασία, προτείνουμε μια μέθοδο αυτόματης λεξιλογικής κεφαλής για δενδροδομή, διαδίδοντας λέξεις κεφαλής από κόμβους φύλλων σε κάθε συστατικό κόμβο. Επιπλέον, με τη Λεξικοποίηση κεφαλής, κατασκευάζουμε ένα δέντρο με κατεύθυνση από πάνω προς τα κάτω, το οποίο αντιστοιχεί σε αμφίδρομες διαδοχικές στη δομή. Τα πειράματα δείχνουν ότι και οι δύο επεκτάσεις δίνουν καλύτερες αναπαραστάσεις των δομών δέντρων. Το τελικό μοντέλο μας δίνει τα καλύτερα αποτελέσματα στην τράπεζα συναισθημάτων του Στάνφορντ και εξαιρετικά ανταγωνιστικά αποτελέσματα στην εργασία ταξινόμησης τύπου ερωτήσεων.', 'ka': 'შემდეგ LSTMs მოდელის სტრუქტურაში გაფართებულია, რამდენიმე დავალებებისთვის კონკენტებური შედეგი. არსებობს მეტისების მოდელი კონსტუტენტის ხეები, კონსტუტენტის კონსტუტენტის ქვემოთ კონსტუტენტის კონსტუტენტის კონსტუტენტის კომბიციებით,  ეს სკენტიური LSTMs განსხვავებულია, რომელიც ყველა კონტაქტის სიტყვების შეტყობინება. ამ დომენტში ჩვენ აჩვენებთ სტრუქტურის LSTMs სტრუქტურაციისთვის ავტომატიკური head-lexicalization მეტი, რომელიც ყველა კონსტუქტურაციის კონსტუქტურაციისთვის ყველა სიტ დამატებით, ელექქსიკალიზაციაზე დახმარებულია, ჩვენ LSTM ხელის მარცხენა მხარეს, რომელიც კონფიგურაციას მეორე მხარეს LSTMs სტრუქტურაციაში. ექსპერიმენტები ჩვენებს, რომ ორივე განფართლებები უკეთესი ქალის სტრუქტურების გამოსახულება. ნაქთწრ ოჲჟლვენთწრ მჲევლ ეაგა ნაი-ეჲბპთრვ პვჱსლრართ ნა ჟრანტჲპე ჟვნრთმვნრ რპთბანკ თ მნჲდჲ კჲნკსპვრთგნთ პვჱსლრართ ნა პაბჲრარა ნა კლაჟთტ', 'hu': 'A szekvenciális LSTM-eket kiterjesztették a modellezési fastruktúrákra, amelyek versenyképes eredményeket biztosítanak számos feladathoz. A meglévő módszerek az alkotóelemek fáit alulról felfelé irányuló kombinációkkal modellezik, közvetlenül használva a beviteli szó információit csak a levélcsomópontok esetében. Ez eltér a szekvenciális LSTMs-ektől, amelyek minden csomópont beviteli szavaira hivatkozásokat tartalmaznak. Jelen tanulmányban egy módszert javasolunk a fa-struktúra LSTMs automatikus fej-lexikalizálására, amely a fej szavakat levélcsomópontokból minden alkotócsomópontba terjeszti. Ezenkívül a fej lexikalizálásával lehetővé tettük, hogy felülről lefelé irányuló LSTM fát építsünk, amely megfelel a kétirányú szekvenciális LSTM struktúrájának. A kísérletek azt mutatják, hogy mindkét kiterjesztés jobban ábrázolja a fa struktúráit. A végső modellünk a Stanford Sentiment Treebank legjobb eredményeit és a TREC kérdéstípusosztályozási feladat versenyképességét nyújtja.', 'kk': 'Сәйкесті LSTMs бірнеше тапсырмалар үшін бұтақ құрылғыларының үлгісіне келтірілді. Бар әдістер тұрақтың төмендегі төмендегі тұрақтың комбинациялары бойынша конститунттік ағаштарды үлгіледі. Кіріс сөздің мәліметін тек сызық түліктері үшін тұрақты Бұл келесі LSTMs- ден айырмашылық. Бұл әрбір түнде келтірілген сөздерге сілтемелер бар. Бұл қағазда, ағаш құрылғысының автоматты түрде лексикализациялау әдісін қолданамыз. Бұл ағаш құрылғысының басы сөздерін ағаш түрлерінен әрбір конститунттік түліге дейін жүгірту. Қосымша, басының лексикализациясы рұқсат етілген, жоғары жағында LSTM бұтақ құрылады, бұл құрылғыдағы екі директивалық LSTMs ге сәйкес келеді. Екі кеңейтулер ағаш құрылымының жақсы түсініктемесін көрсетеді. Біздің соңғы үлгіміз Стэнфорд сентиметті Брибанктың ең жақсы нәтижелерін береді және TREC сұрақ түрлерінің классификациясы тапсырмасының ең жақсы нәтижеле', 'lt': 'Sekacinės LSTM buvo išplėstos ir modeliuojamos medžių struktūros, o daugelio užduočių rezultatai buvo konkurencingi. Esami metodai modeliuoja sudedamąsias medžius pagal sudedamųjų mazgų derinius iš apačios į viršų, tiesiogiai naudojant įėjimo žodžio informaciją tik lapų mazgams. Tai skiriasi nuo sekacinių LSTM, kuriuose pateikiamos nuorodos į kiekvieno mazgo įvestus žodžius. Šiame dokumente siūlome automatinio galvos leksikalizavimo metodą medžio struktūrinių LSTM, dauginant galvos žodžius iš lapų mazgų į kiekvieną sudedamąją dalį. Be to, įjungus galvos leksikalizaciją, mes statome medžio LSTM viršaus žemyn kryptimi, kuri atitinka dvikrypčius sekacinius LSTM struktūroje. Eksperimentai rodo, kad abiejuose išplėtimuose geriau atspindi medžių struktūras. Mūsų galutinis modelis suteikia geriausius rezultatus dėl Stanford Sentiment Treebank ir labai konkurencingus rezultatus dėl TREC tipo klasifikavimo užduoties.', 'mk': 'Секвенцијалните ЛСТМ се проширени на модели на структурите на дрвјата, давајќи конкурентни резултати за голем број задачи. Постојаните методи моделираат конститутивни дрвја со комбинации од дното до горе на конститутивните јазли, правејќи директна употреба на информациите за влезот на зборот само за листовите јазли. Ова е различно од секвенцијалните LSTMs, кои содржат референции на вводните зборови за секој јазол. Во оваа хартија, предложуваме метод за автоматска глава-лексикализација за дрвја-структура ЛСТМ, пропагирајќи ги зборовите на главата од листови јазли до секој конститутивен јазл. Покрај тоа, овозможени со лексикализација на главата, градиме дрво ЛСТМ во насока горе надолу, што одговара на двојно секвенцијални ЛСТМ во структурата. Experiments show that both extensions give better representations of tree structures.  Нашиот финален модел ги дава најдобрите резултати на Стенфорд Сентимент Treebank и високо конкурентни резултати на задачата за класификација на типот на прашања на TREC.', 'ms': 'LSTM Sequential telah dilambangkan ke struktur pokok model, memberikan keputusan kompetitif untuk beberapa tugas. Kaedah sedia ada pokok konstitusi model dengan kombinasi bawah-atas nod konstitusi, menggunakan secara langsung maklumat perkataan input hanya untuk nod daun. Ini berbeza dari LSTM jujukan, yang mengandungi rujukan kepada kata input bagi setiap nod. Dalam kertas ini, kami cadangkan kaedah untuk leksikalisasi kepala automatik untuk LSTM struktur pokok, menyebarkan perkataan kepala dari nod daun ke setiap nod konstitusi. Selain itu, dibenarkan oleh leksikalisasi kepala, kami membina pepohon LSTM dalam arah atas-bawah, yang sepadan dengan LSTM sekuensial dua arah dalam struktur. Experiments show that both extensions give better representations of tree structures.  Model terakhir kami memberikan keputusan terbaik pada Stanford Sentiment Treebank dan keputusan kompetitif yang tinggi pada tugas klasifikasi jenis pertanyaan TREC.', 'mt': 'LSTMs sekwenzjali ġew estiżi għall-mudelli ta’ strutturi tas-siġar, li jagħtu riżultati kompetittivi għal għadd ta’ kompiti. Metodi eżistenti jimmudellaw siġar kostitwenti b’kombinazzjonijiet minn isfel għal fuq ta’ nodi kostitwenti, li jagħmlu użu dirett mill-informazzjoni tal-kelma input biss għal nodi tal-weraq. Dan huwa differenti minn LSTMs sekwenzjali, li fihom referenzi għal kliem ta’ input għal kull nodu. F’din il-karta, qed nipproponu metodu għal-lexikalizzazzjoni awtomatika tar-ras għall-LSTMs tal-istruttura tas-siġar, li jippropropaga l-kliem tar-ras minn nodi tal-weraq għal kull nodu kostitwenti. Barra minn hekk, permezz tal-lexikalizzazzjoni tar-ras, a ħna nibnu siġar LSTM fid-direzzjoni minn fuq għal isfel, li jikkorrispondi għal LSTMs sekwenzjali bidirezzjonali fl-istruttura. L-esperimenti juru li ż-żewġ estensjonijiet jagħtu rappreżentazzjonijiet aħjar tal-istrutturi tas-siġar. Our final model gives the best results on the Stanford Sentiment Treebank and highly competitive results on the TREC question type classification task.', 'mn': 'Дараагийн LSTMs нь модны бүтэц загвар руу өрсөлдөг бөгөөд олон ажлын төлөө өрсөлдөг үр дүнг өгдөг. Existing methods model constituent trees by bottom-up nodes combined, direct use of input word information only for leaf nodes. Энэ нь дараагийн LSTMs-ээс ялгаатай. Энэ нь товчууд бүрт орлуулах үгнээс хамааралтай. Энэ цаасан дээр бид модны бүтэц LSTMs-г автоматически толгой-лексикализацийн арга зааж өгдөг. Үүнээс гадна толгой лексикализацийн тусламжтайгаар бид дээд доош талд LSTM мод бүтээж байна. Энэ нь хоёр дахь дараагийн LSTMs тэй холбоотой. Эдгээр туршилтууд модны бүтээгдэхүүн хоёр дахин илүү сайн илэрхийллийг харуулдаг. Бидний сүүлийн загвар Стэнфорд Сентимнт Treebank-ын хамгийн сайн үр дүнг өгдөг. ТРЕК асуулт төрлийн хуваалтын ажил дээр маш өрсөлдөг үр дүнг өгдөг.', 'no': 'Sekvensjonale LSTMs er utvida til modellen av trestrukturer, og gir konkurentære resultat for mange oppgåver. Ekstendige metodar modeller konstituenttrær ved nedst- oppe kombinasjonar av konstituentnoder, som gjer direkte bruk av inndata- ordinformasjon berre for lydnenoder. Dette er ulike frå sekvensielle LSTMs, som inneheld referanser til inndataord for kvar node. I denne papiret foreslår vi ein metode for automatisk hovudleksikalisering for tre-strukturen LSTMs, som spreier hovudord frå blannnoder til kvar konstitusjonsnode. I tillegg, slått på med hovudleksikalisering, bygger vi ein tre LSTM i den øvre nedtrekanten, som tilsvarar bidireksjonale sekvensjonale LSTMs i strukturen. Eksperimentar viser at begge utvidingar gjev betre representasjonar av trestrukturen. Det siste modellen vårt gjev dei beste resultatene på Stanford Sentiment Treebank og svært konkurrente resultatene på klassifikasjonen av spørsmåltypen TREC.', 'it': "Gli LSTMs sequenziali sono stati estesi alle strutture ad albero modello, dando risultati competitivi per una serie di compiti. I metodi esistenti modellano gli alberi costituenti mediante combinazioni bottom-up di nodi costituenti, facendo uso diretto delle informazioni sulle parole di input solo per i nodi fogliari. Questo è diverso dagli LSTMs sequenziali, che contengono riferimenti alle parole di input per ogni nodo. In questo articolo, proponiamo un metodo per la lessicalizzazione automatica della testa per LSTMs a struttura ad albero, propagando le parole della testa dai nodi fogliari ad ogni nodo costituente. Inoltre, abilitato dalla lessicalizzazione della testa, costruiamo un albero LSTM in direzione dall'alto verso il basso, che corrisponde a LSTM sequenziali bidirezionali in struttura. Gli esperimenti dimostrano che entrambe le estensioni danno una migliore rappresentazione delle strutture degli alberi. Il nostro modello finale offre i migliori risultati sulla Stanford Sentiment Treebank e risultati altamente competitivi sul compito di classificazione del tipo di domanda TREC.", 'ml': 'സാധാരണ LSTMs മരത്തിന്റെ ഘടനയിലേക്ക് മോഡല്\u200d വര്\u200dദ്ധിപ്പിക്കപ്പെട്ടിരിക്കുന്നു. കുറച്ചു ജോലികള്\u200dക്ക് മത്സരി നിലവിലുള്ള രീതികളിലുള്ള മാതൃകങ്ങളുടെ അടിയിലുള്ള കൂട്ടത്തിലുള്ള മാതൃകങ്ങളില്\u200d നിന്നും നിലവിലുള്ള മാതൃകങ്ങള്\u200d ലീ എല്ലാ നോഡിന്റെയും ഇന്\u200dപുട്ട് വാക്കുകള്\u200dക്കുള്ള അഭിപ്രായം ലഭ്യമാണിത്. ഈ പത്രത്തില്\u200d, നമ്മള്\u200d സ്വയം തലയുടെ ലെക്സിക്ഷീകരണത്തിനുള്ള ഒരു രീതിയാണ് പ്രൊദ്ദേശിപ്പിക്കുന്നത്. ലീഡ് നോഡില്\u200d നിന്നും എല്ലാ പ്രസി കൂടാതെ, തലയിലെ ലെക്സിക്സിക്കലേഷന്\u200d കൊണ്ട് പ്രാവര്\u200dത്തികമാക്കിയിരിക്കുന്നു, മുകളില്\u200d താഴേക്കുള്ള ഒരു വൃക്ഷത്തിന്\u200dറെ മുകളില പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു രണ്ട് വികസികളും മരത്തിന്റെ സ്ഥാനങ്ങളില്\u200d നല്ല പ്രതി നമ്മുടെ അവസാന മോഡല്\u200d സ്റ്റാന്\u200dഫോര്\u200dഡ് സെന്\u200dറിമെന്\u200dറ് ട്രീബാങ്കിന്\u200dറെ ഏറ്റവും നല്ല ഫലങ്ങള്\u200d നല്\u200dകുന്നു. ട്രെയിസി ചോദ്യം ടൈപ്പ', 'pl': 'Sekwencyjne LSTMy zostały rozszerzone o modelowanie struktur drzew, dając konkurencyjne wyniki dla wielu zadań. Istniejące metody modelują drzewa składowe według oddolnych kombinacji węzłów składowych, wykorzystując bezpośrednio informacje o słowach wejściowych tylko dla węzłów liści. Różni się to od sekwencyjnych LSTMów, które zawierają odniesienia do słów wejściowych dla każdego węzła. W niniejszym artykule proponujemy metodę automatycznej leksykalizacji głowy dla LSTMów struktury drzewa, propagowania słów głowy z węzłów liści do każdego węzła składowego. Dodatkowo, umożliwiając leksykalizację głowy, budujemy drzewo LSTM w kierunku góry-dół, które w strukturze odpowiada dwukierunkowym sekwencyjnym LSTMom. Eksperymenty pokazują, że oba rozszerzenia dają lepszą reprezentację struktur drzew. Nasz ostateczny model daje najlepsze wyniki na Stanford Sentiment Treebank oraz wysoce konkurencyjne wyniki w zadaniu klasyfikacji typu pytania TREC.', 'ro': 'LSTMs secvențiale au fost extinse la structuri de arbori model, oferind rezultate competitive pentru o serie de sarcini. Metodele existente modelează copacii constituenți prin combinații de jos în sus de noduri constituenți, utilizând direct informațiile cuvintelor introduse numai pentru nodurile frunzelor. Aceasta este diferită de LSTMs secvențiale, care conțin referințe la cuvinte de intrare pentru fiecare nod. În această lucrare, propunem o metodă de lexicalizare automată a capului pentru LSTMs structură arborească, propagarea cuvintelor capului de la nodurile frunzelor la fiecare nod constitutiv. În plus, activat prin lexicalizarea capului, construim un arbore LSTM în direcția de sus în jos, care corespunde LSTM secvențiale bidirecționale în structură. Experimentele arată că ambele extensii oferă o reprezentare mai bună a structurilor copace. Modelul nostru final oferă cele mai bune rezultate pe Stanford Sentiment Treebank și rezultate extrem de competitive în sarcina de clasificare a tipului de întrebări TREC.', 'sr': 'Sekvencijalne LSTMs su proširene na modele strukture drveta, dajući konkurentne rezultate za broj zadataka. Postojeće metode modela komponentnih drveća po kombinacijama komponentnih čvorova donjem gore, praveći direktnu upotrebu informacija o ulaznim rečima samo za čvorove lišća. Ovo je drugaèije od sekvencijalnih LSTMs-a, koje sadrže referencije na ulazne reèi za svaki čvor. U ovom papiru predlažemo metodu za automatsku glavnu leksikalizaciju za drvetnu strukturu LSTMs, koja proširi glavne reči od čvorova lišća do svakog čvora sastavnog čvora. Osim toga, uključeno glavnom leksikalizacijom, izgradimo drvo LSTM u gornjem smjeru dole, što odgovara dvodirektivnim sekvencijalnim LSTMsima u strukturi. Eksperimenti pokazuju da obe proširenja daju bolje predstave strukture drveta. Naš poslednji model daje najbolji rezultat Stanford Sentiment Treebank i vrlo konkurentni rezultati na zadatku klasifikacije tipa pitanja TREC.', 'so': 'Inta dambe LSTMs waxaa loo sii fidiyay tusaale ahaan dhismaha geedka, waxayna resulto iskutallaabta ah u siiyeen shaqooyin badan. Tusaale-qaab ah oo ku qoran geedo hoose-u-qoran, oo ku isticmaalaya macluumaadka input-ka oo kaliya goobaha caleemo. Kanu waa mid ka duwan LSTMs xilliga ah, kaas oo ku qoran macluumaad lagu qorayo warqada input ee qof kasta. Qoraalkan waxaynu soo jeedaynaa qaab aan automatic leksikalis madaxa loo sameeyo geed-dhismaha LSTMs, oo ku sii daabacno hadal madax ah oo ka soo baxaya boog-boodh ilaa nod kasta oo guud. Taas waxaa dheer oo lagu shaqeeyaa madaxa lexicisiisa, waxaynu dhisnaa geed LSTM oo ku qoran dhanka sare ee hoose, taasoo ku habboon dhamaadka LSTMs ka dib dhismaha. Imtixaanka waxay muujiyaan in labadoodu ay u fidiyaan noocyo ka wanaagsan dhismaha geedka. Tusaale ahaan ugu dambeeya wuxuu ku siinayaa arimaha ugu wanaagsan ee ku saabsan Sentimente Treebank Stanford iyo arimaha fasaxa ee TREC.', 'si': 'පස්සේ LSTMs විසින් ගස් සැකසුම් විසින් ප්\u200dරමාණය කරලා තියෙනවා, වැඩක් ගොඩක් වෙනුවෙන් ප්\u200dරතිකාරිය ප්\u200dර ඉතින් ඉතින් විධාන වර්ගයේ ස්ථානය විධානය විධානය විධානය විධානය විධානය විධානය විධානය කරන්න, ඇතුළු වර මේක පස්සේ LSTMs වලින් වෙනස් වෙනවා, ඒකෙන් හැම නෝඩ් වලින් ඇතුළත් වචන වචන වලින් සම්බන්ධ වෙනවා. මේ පැත්තේ, අපි ස්වයංක්\u200dරියාවිතයෙන් හෙඩ් ලෙක්සිකාලීස් කරන්න ප්\u200dරවේශයක් ප්\u200dරයෝජනය කරනවා LSTMs ගැන, පැත්තේ නොඩ් වලින් හැම ඒ වගේම, ඔළුවේ ලෙක්සිකාලීස් එක්ක සක්\u200dරිය කරලා තියෙන්නේ, අපි LSTM ගස් හදන්නේ උඩ පැත්තේ පැත්තේ, ඒ වගේම සම්බන්ධ වෙන් පරීක්ෂණය පෙන්වන්නේ විස්තර දෙන්නම් විස්තර දෙන්නම් ගස් සංස්ථානයේ හොඳ ප්\u200dරතිනි අපේ අන්තිම මොඩල් එකේ ස්ටැන්ෆෝර්ඩ් සෙන්ටිමන්ට් ට්\u200dරී බැන්ක් වල හොඳම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරශ්න විශ', 'sv': 'Sekventiella LSTMs har utvidgats till att omfatta modellträdsstrukturer, vilket ger konkurrenskraftiga resultat för ett antal uppgifter. Befintliga metoder modellerar beståndsdelar genom bottom-up kombinationer av beståndsdelar, och direkt använder sig av indata ordinformation endast för lövnoder. Detta skiljer sig från sekventiella LSTMs, som innehåller referenser till inmatningsord för varje nod. I denna uppsats föreslår vi en metod för automatisk huvudlexikalisering för trädstruktur LSTMs, genom att föröka huvudord från lövnoder till varje komponentnod. Dessutom, möjliggjort genom huvudlexikalisering, bygger vi ett träd LSTM i uppifrån och ner riktning, vilket motsvarar tvåriktade sekventiella LSTM i struktur. Experiment visar att båda förlängningarna ger bättre representationer av trädstrukturer. Vår slutliga modell ger de bästa resultaten på Stanford Sentiment Treebank och mycket konkurrenskraftiga resultat på TREC frågetyp klassificering uppgift.', 'ta': 'பின்வரும் LSTMs மரத்தின் அமைப்புகளுக்கு மாதிரி விரிவாக்கப்பட்டுள்ளது, பல பணிகளுக்கு போராடியான முடிவுகளை கொட Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes.  பின்வரும் LSTMs லிருந்து இது வேறுபட்டுள்ளது, ஒவ்வொரு நுட்டத்திற்கும் உள்ளீட்டு வார்த்தைகளை கொண்டுள இந்த காகிதத்தில், நாம் தன்னியக்கமாக தலைமுறை லெக்சிகேசியல் முறைமையை தேர்வு செய்கிறோம், மரத்தை உருவாக்கும் LSTMs, எலி குறிகளிலிருந மேலும், தலைப்பு லெக்சிகேஷன் மூலம் செயல்படுத்தப்பட்டது, மேல் கீழே திசையில் LSTM ஒரு மரத்தை உருவாக்குகிறோம், அது கட்டமைப்பில் பின்வரு இரண்டு விரிவாக்கங்களும் மரத்து அமைப்புகளின் சிறந்த ஒப்புக்களை காட்டுகிறது. எங்கள் இறுதி மாதிரி ஸ்டான்போர்ட் சிறந்த முடிவுகள் கொடுக்கிறது ஸ்டான்போர்ட் சென்டெமென்ட் ட்ரீபாங்க் மற்றும் TREC கே', 'ur': 'سفارشی LSTMs کو درخت ساختوں کی مدل میں پھیلایا گیا ہے، بہت سی کاموں کے لئے مقابلہ نتائج دیتے ہیں. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes. یہ لس ٹی مز سے مختلف ہے جس میں ہر نوڈ کے لئے اینٹ ورڈ کا ارتباط رکھتا ہے. ہم اس کاغذ میں ایک طریقہ پیش کریں گے کہ درخت-ساختار LSTMs کے لئے اپنا سر لکس کالیزا کرے، سر لکھ نوڈ سے ہر قسمت ناڈ تک پہنچ سکیں۔ اور اس کے علاوہ، سر لکس کالیزی کے ذریعہ مطابق ہے، ہم ایک درخت LSTM کو اوپر-نیچے دہشت میں بناتے ہیں، جو ساختار میں دوسری دہرائی لکس ٹم کے مطابق ہے. تجربے دکھاتے ہیں کہ دونوں اضافہ درخت کی ساختوں کی بہترین نمونات دیتے ہیں۔ ہماری آخری مدل استنفورد سنٹیمٹ تری بانک کے بہترین نتائج دیتا ہے اور TREC سؤال ٹائپ کلیسی ٹائک کے کام پر بہت زیادہ مساوی نتائج دیتا ہے.', 'uz': "Sequential LSTMs have been extended to model tree structures, giving competitive results for a number of tasks.  Name @ info: whatsthis Bu qogʻozda, biz daraxt tuzilishi LSTMs uchun avtomatik boshqarish usulini talab qilamiz, balki nordan boshqa so'zlarni boshqarish va har bir constituent node'ga qaytadi. Ko'pchilikni boshqa leksikalik orqali yordam beramiz, yuqori yuqoriga LSTM daraxtni yaratimiz, bu tuzuvda bir necha xil LSTMs'ga bog'liq. Tajribalar bu ikkita kengaytmalar daraxt strukturening yaxshi shakllarini ko'rsatadi. Bizning oxirgi modelimiz Stanford Sentiment Treebankning eng eng yaxshi natijalarini beradi va TREC savol turli darajalashning vazifasi juda qiziqarli natijalarini bajaradi.", 'vi': 'Tiết ứng viên tần số đã được mở rộng cho cấu trúc mô hình cây, cung cấp kết quả cạnh tranh cho một số công việc. Chế độ tồn tại của các loài cây có cấu tạo theo các chuỗi thành phần dưới, sử dụng trực tiếp các thông tin từ nhập chỉ cho các lõi lá. Nó khác với các cử chỉ khác nhau, có chứa các chỉ dẫn tới các từ nhập cho mỗi nút. Trong tờ giấy này, chúng tôi đề xuất phương pháp viết hóa đơn đầu tự động cho cấu trúc cây LSTM, công bố các từ đầu từ nút lá đến các nút nối. Thêm vào đó, được hiệu chỉnh bằng ngôn ngữ đầu, chúng ta xây dựng một cây LSTM theo chiều trên cùng, tương ứng với các LSTM theo chuỗi tương tự trong cấu trúc. Các thí nghiệm cho thấy cả hai sự gia hạn cung cấp tốt đẹp hơn cấu trúc cây. Mẫu cuối cùng của chúng tôi cung cấp kết quả tốt nhất về đơn vị Stanford... và kết quả cạnh tranh cao về nhiệm vụ phân loại chất vấn hỏi chất lượng.', 'bg': 'Последователните ЛТМ са разширени, за да моделират дървесни структури, давайки конкурентни резултати за редица задачи. Съществуващите методи моделират съставните дървета чрез комбинации отдолу нагоре от съставните възли, като пряко се използва входната дума само за листните възли. Това е различно от последователните LSTMs, които съдържат препратки към входни думи за всеки възел. В настоящата статия предлагаме метод за автоматична лексикализация на главите за дървесни структури, разпространявайки главите думи от листните възли към всеки съставен възел. Освен това, позволено от лексикализацията на главата, ние изграждаме дърво ЛСТМ в посока отгоре надолу, което съответства на двупосочни последователни ЛСТМ в структурата. Експериментите показват, че двете разширения дават по-добро представяне на дървесни структури. Крайният ни модел дава най-добрите резултати по Станфордската сентиментна дървесна банка и силно конкурентни резултати по задачата за класификация на типа въпроси.', 'nl': 'Sequentiële LSTMs zijn uitgebreid tot het modelleren van boomstructuren, wat concurrerende resultaten oplevert voor een aantal taken. Bestaande methoden modelleren samenstellende bomen door bottom-up combinaties van samenstellende knooppunten, waarbij rechtstreeks gebruik wordt gemaakt van invoerwoordinformatie alleen voor bladknooppunten. Dit is anders dan sequentiële LSTMs, die verwijzingen bevatten naar invoerwoorden voor elk knooppunt. In dit artikel stellen we een methode voor automatische head-lexicalisatie voor boomstructuur LSTMs voor, waarbij hoofdwoorden van bladknooppunten naar elk constitutioneel knooppunt worden verspreid. Daarnaast bouwen we, mogelijk door head lexicalisatie, een boom LSTM in de top-down richting, die overeenkomt met bidirectionele sequentiële LSTMs in structuur. Experimenten tonen aan dat beide extensies betere representaties geven van boomstructuren. Ons uiteindelijke model geeft de beste resultaten op de Stanford Sentiment Treebank en zeer concurrerende resultaten op de TREC vraagtype classificatietaak.', 'hr': 'Sljedeće LSTMs proširile su se na modele strukture drveta, dajući konkurentne rezultate za broj zadataka. Postojeće metode modeliraju komponentne drveće po kombinacijama komponentnih čvorova donjem gore, izravno upotrebljavajući informacije o ulaznim riječima samo za čvorove listi. Ovo je drugačije od sljedećih LSTMs-a, koje sadrže referencije na ulazne riječi za svaki čvor. U ovom papiru predlažemo metodu za automatsku glavnu leksikalizaciju za stabilnu strukturu LSTMs, proširenje glavnih riječi od čvorova lišća do svakog čvora sastavnog čvora. Osim toga, uključeno glavnom leksikalizacijom, izgradimo drvo LSTM u gornjem smjeru dolje, što odgovara dvodirektivnom sekvencijskom LSTM u strukturi. Eksperimenti pokazuju da obje proširenje daju bolju predstavu struktura drveta. Naš konačni model daje najbolje rezultate Stanford Sentiment Treebank-a i vrlo konkurentne rezultate na zadatku klasifikacije tipa pitanja TREC-a.', 'da': 'Sekventielle LSTMs er blevet udvidet til at omfatte modeltræstrukturer, hvilket giver konkurrencedygtige resultater til en række opgaver. Eksisterende metoder modellerer bestanddele træer ved bottom-up kombinationer af bestanddele knuder og gør direkte brug af input word information kun for bladknuder. Dette er forskelligt fra sekventielle LSTMs, som indeholder referencer til input ord for hver node. I denne artikel foreslår vi en metode til automatisk hovedleksikalisering for træstruktur LSTMs, der formerer hovedord fra bladknuder til hver eneste komponentknude. Desuden, aktiveret ved hovedleksikalisering, bygger vi et træ LSTM i top-down retning, som svarer til to retninger sekventielle LSTM i struktur. Eksperimenter viser, at begge udvidelser giver bedre repræsentationer af træstrukturer. Vores endelige model giver de bedste resultater på Stanford Sentiment Treebank og yderst konkurrencedygtige resultater på TREC spørgsmålstypeklassifikationsopgaven.', 'ko': '순차 LSTM은 모델 트리 구조로 확장되어 많은 작업에 경쟁력 있는 결과를 제공합니다.기존의 방법은 아래에서 위로 구성된 노드 조합을 통해 구성 나무를 모델링하고 입력한 단어 정보를 직접 이용하여 잎 노드에만 사용한다.이것은 각 노드에 입력한 글자에 대한 인용을 포함하는 순서 LSTM과 다르다.본고에서 우리는 나무 구조인 LSTM의 머리 자동 어휘화 방법을 제시하여 머리 단어를 잎 노드에서 각 구성 노드로 전파했다.또한 머리 어휘화를 통해 우리는 위에서 아래로 내려가는 방향에 트리 LSTM을 구축했는데 이것은 구조적으로 양방향 순서 LSTM에 대응한다.실험에 의하면 이 두 가지 확장은 모두 나무 구조를 더욱 잘 나타낼 수 있다.우리의 최종 모델은 스탠퍼드 정서 트리 라이브러리에서 가장 좋은 결과를 제시했고 TREC 문제 유형 분류 임무에서 매우 경쟁력 있는 결과를 제시했다.', 'id': 'LSTM Sequential telah diperluaskan ke struktur pohon model, memberikan hasil kompetitif untuk sejumlah tugas. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes.  Ini berbeda dari LSTM sekuensial, yang mengandung referensi ke kata input untuk setiap node. Dalam kertas ini, kami mengusulkan metode untuk secara otomatis kepala-lexikalisasi untuk LSTM struktur pohon, memperluas kata-kata kepala dari node daun ke setiap node konstitusi. Selain itu, diaktifkan oleh leksikalisasi kepala, kami membangun sebuah pohon LSTM di arah atas-bawah, yang cocok dengan LSTM sekuensial bidireksi dalam struktur. Eksperimen menunjukkan bahwa kedua ekstensi memberikan perwakilan yang lebih baik dari struktur pohon. Model akhir kami memberikan hasil terbaik pada Stanford Sentiment Treebank dan hasil kompetitif tinggi pada tugas klasifikasi tipe pertanyaan TREC.', 'de': 'Sequenzielle LSTMs wurden erweitert, um Baumstrukturen zu modellieren, was wettbewerbsfähige Ergebnisse für eine Reihe von Aufgaben liefert. Bestehende Methoden modellieren konstituierende Bäume durch Bottom-up-Kombinationen von konstituierenden Knoten, wobei Eingabewortinformationen nur für Blattknoten direkt verwendet werden. Dies unterscheidet sich von sequenziellen LSTMs, die Verweise auf Eingabewörter für jeden Knoten enthalten. In diesem Beitrag schlagen wir eine Methode zur automatischen Kopflexikalisierung für Baumstruktur-LSTMs vor, bei der Kopfwörter von Blattknoten zu jedem konstituierenden Knoten propagiert werden. Zusätzlich bauen wir, durch Kopflexikalisierung ermöglicht, einen Baum-LSTM in Top-Down-Richtung auf, der bidirektionalen sequentiellen LSTMs in der Struktur entspricht. Experimente zeigen, dass beide Erweiterungen bessere Darstellungen von Baumstrukturen ermöglichen. Unser endgültiges Modell liefert die besten Ergebnisse auf der Stanford Sentiment Treebank und sehr wettbewerbsfähige Ergebnisse auf der TREC Fragentypklassifikationsaufgabe.', 'fa': 'LSTMs sequence has been extended to model tree structures, giving competitive results for a number of tasks. روش\u200cهای موجود در حال حاضر مدل درخت\u200cهای قالب با ترکیب\u200cهای قالب پایین از گره\u200cهای قالب، که فقط برای گره\u200cهای برگ استفاده از اطلاعات وارد کلمه\u200cهای قالب استفاده می\u200cکند. این تفاوت از LSTMs\u200cهای تعریف است که شامل تعریف به کلمات ورودی برای هر گره است. در این کاغذ، ما پیشنهاد می\u200cکنیم یک روش برای استفاده از سر-لکسیکولیزی خودکار برای ساختار درخت LSTMs، کلمات سر را از گره\u200cهای برگ به هر گره\u200cای استفاده می\u200cکنیم. در addition, enabled by head lexicalization, we build a tree LSTM in the top-down direction, which corresponds to two-directional LSTMs sequence in structure. تجربه\u200cها نشان می\u200cدهند که هر دو استفاده\u200cها نمایش\u200cهای بهتر از ساختارهای درخت را می\u200cدهند. آخرین مدل ما بهترین نتیجه\u200cهای درخت سنتایمنت استنفورد را می\u200cدهد و نتیجه\u200cهای مسابقه\u200cای بسیار مسابقه\u200cای بر روی مسابقه\u200cهای مختصات نوع سؤال TREC می\u200cدهد.', 'tr': "Täzelikçe LSTMsler agaç strukturlaryna nusgala geçirildi, birnäçe işiň üçin rekabet netijesi berildi. Eski metodlar modi constituent agaçları aşak üste düğümler bilen birleştirerek, diňe basa düğümler üçin giriş kelime maglumatyny doğrudan ullanýar. Bu seňki LSTMslerden farklı. Bu ýerde her düğüm üçin giriş sözlerine referans edýär. Bu kagyzda, agaç-strukturasy LSTMs üçin awtomatik kelli leksikalizasyň üçin bir yöntemi teklip edýäris. Başga kelläň sözlerini paçar düğümlerinden her constituent düğümlere göçürýäris. Hemmäpli, kelli leksikalamak bilen mümkin edildi, üst-de bir LSTM agaç guralýarys. Bu döredijilik iň-döredijilik LSTM bilen meňzeýär. Testler agaç strukturlarynyň has gowy üýtgetmegini görkezýär. Bizim son modelimiz Stanford Sentiment Treebank'a en iyi netijeleri verir ve TREC soru tipi klasifikasyon görevinde çok rekabetçi netijeleri verir.", 'af': "Sequential LSTMs is uitgebreid na model boom strukture, gegee gemeenskap resultate vir 'n aantal taak. Bestaande metodes model konstituent bome deur onderkant- op kombinasies van konstituent nodes, maak direk gebruik van invoer woord inligting slegs vir blaainodes. Hierdie is anders van sekwensiele LSTMs, wat bevat verwysings na invoer woorde vir elke node. In hierdie papier, voorstel ons 'n metode vir outomatiese kop-leksikalisasie vir boom-struktuur LSTMs, wat kopwoorde versprei van blaainodes na elke konstituent node. In addition, enabled by head lexicalization, we build a tree LSTM in the top-down direction, which corresponds to bidirectional sequential LSTMs in structure. Eksperimente vertoon dat beide uitbreidings beter voorstellings van boom strukture gee. Ons eindelike model gee die beste resultate op die Stanford Sentiment Treebank en baie gemeenskap resultate op die TREC vraagtipe klassifikasie taak.", 'sw': 'Baadae LSTMs imeenea katika miundombinu ya mti, na kutoa matokeo ya ushindani kwa kazi kadhaa. Mradi wa mifano inayokuwepo unaohifadhi miti kwa muunganiko wa chini wa mitandao ya ubunge, na kutengeneza matumizi ya moja kwa moja ya taarifa za habari za input pekee kwa ajili ya vipande vya majani. Hii ni tofauti na LSTMs wa mfululizo, ambayo ina maana ya maneno ya input kwa kila node. Katika gazeti hili, tunapendekeza njia ya kujitokeza kichwa kwa ajili ya muundo wa miti wa LSTMs, kutangaza maneno ya kichwa kutoka kwenye viwanja vya upepo kwenda kwenye kila upande wa ubunge. Zaidi ya hayo, inawezekana na uchochezi wa kichwa, tunajenga mti wa LSTM kwenye mwelekeo wa juu, unaohusiana na LSTMs wa pili katika muundo. Majaribio yanaonyesha kuwa maendeleo yote yanatoa maoni bora ya miundombi ya miti. Our final model gives the best results on the Stanford Sentiment Treebank and highly competitive results on the TREC question type classification task.', 'hy': 'Սեքսենցիալ LSMT-ները ընդլայնվել են ծառերի կառուցվածքների մոդելների վրա, ինչը մրցակցության արդյունքներ է տալիս մի շարք խնդիրների համար: Գոյություն ունի մեթոդներ, որոնք մոդել են ծառերը բաղադրամասեր՝ բաղադրամասերի ներքև-վերև համադրումների միջոցով, որոնք անմիջապես օգտագործում են բառի տեղեկատվությունը միայն տերևի կետերի համար: Սա տարբերվում է LSMT-ներից, որոնք պարունակում են հղումներ յուրաքանչյուր հանգույցի ներմուծման բառերին: Այս թղթի մեջ մենք առաջարկում ենք մի մեթոդ գլխի ավտոմատիկ լեքսիկալիզացիայի համար ծառի կառուցվածքի LSMT-ների համար, գլխի բառերը տարածելով տերևի հանգույցներից յուրաքանչյուր հանգույցի: Ավելին, գլխավոր լեքսիկալիզացիայի միջոցով մենք ստեղծում ենք ծառ LSMT-ը վերևի ներքև ուղղությամբ, որը համապատասխանում է կառուցվածքի երկու ուղղությամբ հաջորդականների LSMT-ներին: Փորձերը ցույց են տալիս, որ երկու ընդլայնումները ավելի լավ ներկայացնում են ծառերի կառուցվածքները: Մեր վերջնական մոդելը տալիս է լավագույն արդյունքները Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստենֆորդ Ստե', 'sq': 'LSTMs sekuencë janë zgjeruar në modele strukturash pemësh, duke dhënë rezultate konkurruese për një numër detyrash. Metodat ekzistuese modelojnë pemët përbërëse me kombinimet poshtë-lart të nyjeve përbërëse, duke përdorur drejtpërdrejt informacionin e fjalës së hyrjes vetëm për nyjet e gjetheve. Kjo është ndryshe nga LSTMs sekuenciale, që përmbajnë referime ndaj fjalëve të hyrjes për çdo nod. In this paper, we propose a method for automatic head-lexicalization for tree-structure LSTMs, propagating head words from leaf nodes to every constituent node.  Përveç kësaj, aktivizuar nga lexikalizimi i kokës, ne ndërtojmë një pemë LSTM në drejtimin lart-poshtë, e cila korrespondon me LSTM sekuenciale dy-drejtuese në strukturë. Eksperimentet tregojnë se të dy zgjerimet japin përfaqësime më të mira të strukturave pemore. Our final model gives the best results on the Stanford Sentiment Treebank and highly competitive results on the TREC question type classification task.', 'am': 'በተጨማሪው LSTMs ለዛፍ አካባቢዎች ተዘጋጅቷል፡፡ የአሁኑ ዓይነት ሞዴል የሥልጣን አካባቢ አካባቢ አካባቢ እና የመስመር ቃላት ማህበረሰብ ብቻ ለቅጠል ቦታዎች ብቻ ሲጠቀም ነው፡፡ ይህ ከተፈለገው LSTMs የተለየ ነው፣ ለሁሉም ነጥብ ለመግባት ቃላት የተጠቃሚ ነው፡፡ በዚህ ፕሮግራም፣ የዛፍ አካባቢ የራስ ቅድሚያ አካባቢ እናስፈልጋለን፡፡ በተጨማሪም፣ የራስ ልክስክሲብነት በተቻለ፣ በላይ ወደታች ወደሚገኝ የLSTM ዛፍ እናሠራለን፡፡ Experiments show that both extensions give better representations of tree structures.  የኋለኛይቱ ምሳሌያችን በቴንፎርድ ሰናትሬት ቴርብባን ላይ የበለጠ ፍሬዎችን ይሰጣል፤ የTREC ጥያቄ ትክክለኛ ትክክለኛለች፡፡', 'bn': 'সাধারণত এলস্টিএমএস মডেল গাছের কাঠামো পরিবর্তন করা হয়েছে, যা কিছু কাজের জন্য প্রতিযোগিতার ফলাফল দিয়েছে। বিদ্যমান পদ্ধতির মডেল বৈশিষ্ট্যাবলী গাছের নীচের সংযোগের মাধ্যমে বিভিন্ন সংস্থাপন নোডের মাধ্যমে, যারা শুধুমাত্র লা এটি পরবর্তী এলস্টিএমএস থেকে আলাদা, যার মধ্যে প্রত্যেক নোডের জন্য ইনপুট শব্দের উল্লেখ রয়েছে। এই কাগজটিতে আমরা স্বয়ংক্রিয়ভাবে মাথা লেক্সিক্সিজেশনের জন্য একটি পদ্ধতি প্রস্তাব করি, যা পাতা থেকে প্রত্যেক প্রতিষ্ঠানের নোড থেকে প্রচ এছাড়াও, মাথা লেক্সিক্সিকেশনের মাধ্যমে সক্রিয়, আমরা উপরের দিকে একটি এলস্টিএম তৈরি করি, যা কাঠামোর ক্ষেত্রে বিদ্যুৎ এলসিএমসের সাথ পরীক্ষা দেখাচ্ছে যে উভয় বিস্তৃতি গাছের কাঠামোর ভালো প্রতিনিধিত্ব দেয়। আমাদের চূড়ান্ত মডেল স্ট্যানফোর্ড সেন্টিমেন্ট ট্রিবাঙ্কের সেরা ফলাফল দিয়েছে এবং ট্রিটিসি প্রশ্নের ধরনের গ্রাফিকেশন ক', 'az': "Növbəti LSTMs a ğaç qurularına genişlənir, bir neçə iş üçün müqayisədi sonuçlar verir. Əvvəlki metodlar istifadə edir, alt üst düyümlərin birlikləri ilə istifadə edir, yalnız sıx düyümləri üçün giriş söz məlumatını istifadə edir. Bu, hər düyünün giriş sözlərinə referans olan LSTMs-lərdən fərqlidir. Bu kağızda, a ğac-yapısı LSTMs üçün otomatik baş-leksikalizasyon metodu təbliğ edirik, baş sözlərini lap düyündən hər nöqtəsi düyünə uzaqlaşdırırıq. Əvvəlcə, baş leksikalizasyonu ilə fəallaşdırılmış, yuxarı tərəfində LSTM a ğacı in şa edirik. Bu, binalıq tərəfində olan LSTMs'lərə uyuşur. Həqiqətən, təcrübələr iki genişliyin ağac yapılarının daha yaxşısını göstərir. Bizim son modelimiz Stanford Sentiment Treebank'un ən yaxşı sonuçlarını verir və TREC soruşu növü klasifikasiya işlərində çox müəllif sonuçlar verir.", 'ca': "Els LSTM secuencials s'han extinguit a estructures d'arbres modeladores, donant resultats competitius per una sèrie de tasques. Els mètodes existents modelen arbres constituents per combinacions de fons a dalt de nods constituents, fent servir directament la informació de la paraula d'entrada només per nods de fulles. Això és diferent dels LSTMs seqüencials, que contenen referències a paraules d'entrada per cada nod. En aquest paper, proposem un mètode de lexicalització automàtica del cap per a LSTMs d'estructura arbral, propaganda paraules del cap des de nodes de fulles a cada nod. A més, habilitat per la lexicalització del cap, construïm un arbre LSTM en direcció de dalt a baix, que correspon a LSTMs bidireccionals secuencials en estructura. Els experiments demostren que les dues extensions donen millors representacions de les estructures d'arbres. El nostre model final dóna els millors resultats en el Treebank de Sentiment de Stanford i resultats altament competitius en la tasca de classificació del tipus de preguntes TREC.", 'bs': 'Sekvencijalne LSTMs su proširene na modele strukture drveta, dajući konkurentne rezultate za broj zadataka. Postojeće metode model komponentnih drveta po kombinacijama komponentnih čvorova donjem gore, koji izravno koriste informacije o ulaznim riječima samo za čvorove lišća. Ovo je drugačije od sekvencijalnih LSTMs-a, koje sadrže referencije na ulazne riječi za svaki čvor. U ovom papiru predlažemo metodu za automatsku glavnu leksikalizaciju za stabilnu strukturu LSTMs, proširenje glavnih riječi od čvorova lišća do svakog čvora sastavnog čvora. Osim toga, uključeno glavnom leksikalizacijom, izgradimo drvo LSTM u gornjem smjeru dolje, što odgovara dvodirektivnim sekvencijalnim LSTM-ima u strukturi. Eksperimenti pokazuju da obje proširenje daju bolju predstavu strukture drveta. Naš konačni model daje najbolji rezultat Stanford Sentiment Treebank i vrlo konkurentni rezultati na zadatku klasifikacije tipa pitanja TREC.', 'et': 'Järjestikuseid LSTMsid on laiendatud puustruktuuride modelleerimisele, andes konkurentsivõimelisi tulemusi mitmete ülesannete jaoks. Olemasolevad meetodid modelleerivad koostispuud koostissõlmede alt üles kombinatsioonide abil, kasutades otseselt sisendsõnateavet ainult lehesõlmede puhul. See erineb järjestikustest LSTMdest, mis sisaldavad viiteid sisendsõnadele iga sõlme kohta. Käesolevas töös pakume välja meetodi automaatseks pealeksikaliseerimiseks puustruktuurilistele LSTMdele, levitades peasõnu lehesõlmedest igasse koostissõlmeni. Lisaks ehitame ülevalt allapoole suunas puu LSTM, mis vastab kahesuunalistele järjestikustele LSTMidele struktuuris. Katsed näitavad, et mõlemad laiendused annavad parema kujutise puustruktuuridest. Meie lõplik mudel annab parimad tulemused Stanfordi Sentiment Treebanki ja väga konkurentsivõimelised tulemused TREC küsimuse tüübi klassifitseerimise ülesandel.', 'cs': 'Sekvenční LSTMs byly rozšířeny na modelování stromových struktur, což poskytuje konkurenční výsledky pro řadu úkolů. Stávající metody modelují složkové stromy podle kombinací složkových uzlů zdola nahoru, přičemž přímo využívají vstupní slovní informace pouze pro listové uzly. To se liší od sekvenčních LSTMs, které obsahují odkazy na vstupní slova pro každý uzel. V tomto článku navrhujeme metodu automatické lexikalizace hlavy pro stromové struktury LSTMs, šíření hlavových slov z uzlů listů do každého složeného uzlu. Kromě toho, umožněné lexikalizací hlavy, sestavíme strom LSTM ve směru shora dolů, který odpovídá obousměrným sekvenčním LSTMům ve struktuře. Experimenty ukazují, že obě rozšíření poskytují lepší reprezentaci stromových struktur. Náš konečný model poskytuje nejlepší výsledky na Stanford Sentiment Treebank a vysoce konkurenční výsledky na úkolu klasifikace typu otázek TREC.', 'fi': 'Sekvenssiaalisia LSTMs-ohjelmia on laajennettu mallintamaan puurakenteita, mikä antaa kilpailullisia tuloksia useissa tehtävissä. Nykyiset menetelmät mallintavat rakennepuita rakennesolmujen alhaalta ylöspäin yhdistelemällä siten, että syötettyjä sanoja käytetään suoraan vain lehtisolmujen osalta. Tämä eroaa peräkkäisistä LSTMs:istä, jotka sisältävät viittauksia kunkin solmun syöttösanoihin. Tässä työssä ehdotamme menetelmää automaattiseen pään leksikalisointiin puurakenteisille LSTMs:ille, joka levittää pääsanoja lehtisolmukkeista jokaiseen komponenttisolmukkeeseen. Lisäksi pään leksikalisoinnin mahdollistamana rakennamme ylhäältä alaspäin suuntautuvan puun, joka vastaa rakenteeltaan kaksisuuntaisia peräkkäisiä LSTM-lukuja. Kokeet osoittavat, että molemmat laajennukset antavat paremman kuvan puurakenteista. Lopullinen mallimme antaa parhaat tulokset Stanford Sentiment Treebankissa ja erittäin kilpailukykyiset tulokset TREC-kysymystyypin luokittelutehtävässä.', 'sk': 'Zaporedne LSTMs so bile razširjene na modeliranje drevesnih struktur, kar daje konkurenčne rezultate za številne naloge. Obstoječe metode modelirajo sestavna drevesa s kombinacijami sestavnih vozlišč od spodaj navzgor, pri čemer se neposredno uporabljajo vhodne besede samo za listna vozlišča. To se razlikuje od zaporednih LSTMs, ki vsebujejo sklice na vhodne besede za vsako vozlišče. V prispevku predlagamo metodo avtomatske glavne leksikalizacije za drevesne strukture LSTMs, ki širi glavne besede iz listnih vozlišč na vsako sestavno vozlišče. Poleg tega, ki jo omogoča leksikalizacija glave, zgradimo drevo LSTM v smeri zgoraj navzdol, ki ustreza dvosmernim zaporednim LSTM v strukturi. Poskusi kažejo, da obe razširitvi omogočata boljšo predstavitev drevesnih struktur. Naš končni model daje najboljše rezultate na Stanford Sentiment Treebank in zelo konkurenčne rezultate na nalogi klasifikacije vrste vprašanj TREC.', 'he': 'LSTMs רצפיים הוארכו למודל מבנים עצים, נותנים תוצאות תחרותיות למספר משימות. שיטות קיימות דוגמניות עצים רכיבים על ידי שילובים מתחתית למעלה של קשרים רכיבים, שימוש ישיר במידע מילים כניסה רק עבור קשרי עלים. זה שונה מ LSTMs רצפיים, שמכילים התייחסות למילים הכניסה לכל קשר. בעיתון הזה, אנו מציעים שיטה לראש-לקסיקליזציה אוטומטית עבור LSTMs מבנה עץ, להפיץ מילים ראשיות מ עצים עלה לכל עצים המרכיבים. בנוסף, מאפשר על ידי לקסיקליזציה ראשית, אנו בונים עץ LSTM בכיוון מעל למטה, שמתאים ל LSTM שני כיוונים רצפיים במבנה. ניסויים מראים ששתי ההארכות נותנות מייצגים טובים יותר של מבנים עצים. הדוגמא האחרונה שלנו נותנת את התוצאות הטובות ביותר על גבי העץ של סנטימנט סטנפורד ותוצאות תחרותיות ביותר על משימה סיווג השאלות של TREC.', 'jv': 'Open source Learn Mode First letter In this paper, we proposal a method for automatically head Nambah, akeh iso nggambar kelas luwih cara-cara, kita mbukak cara-cara kotak tentang, lan akeh sekang langgar sampek iso disebarke Ulot NAME OF TRANSLATORS model sing dibenalke sampeyan nyebute mbutuhak sawetara Layaran Sentiment', 'ha': "An shimfiɗa LTRM masu saka zuwa matsayin misalin itãce, kuma an bãyar da matsalar masu ƙidãya wa wasu aikin. Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes.  @ info: whatsthis Ga wannan takardan, Munã buɗa wata hanyoyi wa farat-leksisi farat ɗaya wa matsayin itãcen-muhalli LTRM, idan za'a yi amfani da magana mai nau'i daga leaf node zuwa duk node na cikin saliyar. Da wannan, ana karatar da mai leksikanci na kansa, za'a gina wata itãce LTRM a kan shirin duk-ƙasa, wanda yana mai kamfata da mataimaki na LTRM a bakin rubutun. Fijaroyi na nũna cewa tsakiya biyu zafi misãlai ga rubutun itãce. Shirin da ya ƙarshe yana da mafi kyaun matsala a kan Treebank na Stanford da matsala masu ƙaranci a kan nau'in fassarar TREC.", 'bo': 'རྗེས་སུ་འབྱུང་བའི་LSTMs ན་ཚོས་རྣམ་གྲངས་དབྱིབས་བཟོས་པ་ལ་ཕར་བསྐྱེད་ཡོད། Existing methods model constituent trees by bottom-up combinations of constituent nodes, making direct use of input word information only for leaf nodes. This is different from sequential LSTMs, which contain references to input words for each node. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་རང་འགུལ་གྱི་མགོ་ཡིག་གཟུགས་རིས་སྤྱོད་ཀྱི་ཐབས་ལམ་ཞིག་ཡོད། དེ་ལས་གཙོ་རིམ་བཟོ་བྱས་ན། འུ་ཅག་གིས་མཐོ་རིམ་གྱི་ཕྱོགས་སུ་བཏོན་པའི་ཤོག་བྱང་པ་ཞིག་བཟོཝ་ཨིན། ལག་ལེན་བྱེད་བཞིན་པའི་རྒྱ་བསྐྱེད་གཉིས་ཀྱིས་Tree འི་བཟོ་བཀོད་དང་མི་མང་པོ་སྟོན་པ་ཡིན་ཏེ། ང་ཚོའི་མཐའ་མཇུག་གི་མ་དབྱིབས་དཔེ་དབྱིབས་སྐྱེས་པའི་རྩལ་བ་མང་ཤོས་བ་མང་ཤོས་ཏེ།'}
{'en': 'Nonparametric Bayesian Semi-supervised Word Segmentation', 'pt': 'Segmentação de palavras semissupervisionada bayesiana não paramétrica', 'ar': 'تجزئة كلمة بايزي غير معلمية شبه خاضعة للإشراف', 'es': 'Segmentación de palabras semisupervisada bayesiana no paramétrica', 'fr': 'Segmentation de mots semi-supervisée bayésienne non paramétrique', 'ja': 'ノンパラメトリックベイジアンセミスペシャルワードセグメンテーション', 'zh': '非参数贝叶斯半督分词', 'ru': 'Непараметрическая байесовская полунаблюдаемая сегментация слов', 'hi': 'Nonparametric Bayesian अर्ध पर्यवेक्षित वर्ड विभाजन', 'ga': 'Deighleog Focal Leath-mhaoirsithe Bayesian Neamhparaiméadrach', 'hu': 'Nem parametrikus bayesiai félig felügyelt szószegmentáció', 'ka': 'Name', 'it': 'Segmentazione vocale semisupervisionata bayesiana non parametrica', 'kk': 'Байезия жарты бақылаған сөз сегментациясы жоқ', 'mk': 'Nonparametric Bayesian Semi-supervised Word Segmentation', 'lt': 'Neparametrinė Bayezijos pusiau prižiūrima žodžių segmentacija', 'ms': 'Segmentasi Kata Semi-Dijaga Bayesia Tidak Parametrik', 'mt': 'Segmentazzjoni tal-Kliem Semi-Sorveljata Bajesjana Mhux Parametrika', 'ml': 'Nonparametric Bayesian Semi-supervised Word Segmentation', 'el': 'Μη παραμετρική Bayesian Semi-εποπτευόμενη τμηματοποίηση λέξεων', 'mn': 'Гэвч параметр биезийн хагас дамжуулагдсан үг хэвлэлт', 'no': 'Ikkje parametrisk Bayesiansk semioversikt ordsegmentasjon', 'pl': 'Nieparametryczna Bayesońska pół nadzorowana segmentacja słowa', 'ro': 'Segmentarea vocală semisupravegheată bayeziană nonparametrică', 'sr': 'Непараметрична бејезијска половинадзорна речна сегментација', 'si': 'ප්\u200dරමාණික බේසියාන් සම්බන්ධ වචනය', 'so': 'Nonparametric Bayesian Semi-supervised Word Segmentation', 'sv': 'Icke parametrisk bayesian semiövervakad ordsegmentering', 'ta': 'அளபுருவில்லை பெய்சியன் பெமி- கண்காணிக்கப்பட்ட வார்த்தை பிரிப்பு', 'ur': 'غیر پارامیٹریک بیسین نصف-supervised Word Segmentation', 'vi': 'KCharselect unicode block name', 'uz': 'QFontDatabase', 'nl': 'Niet-parametrische Bayesian Semi-supervised Word Segmentatie', 'bg': 'Непараметрична бейзийска полунадзорна сегментация на думи', 'da': 'Ikke- parametrisk bayesisk semiovervåget ordsegmentering', 'hr': 'Neparametrična Bayesijska polu nadzorna segmentacija riječi', 'fa': 'بخش کلمه\u200cهای نیمه مراقبت بی\u200cاسیایی غیر پارامتریک', 'de': 'Nicht parametrische Bayesische Halbüberwachte Wortsegmentierung', 'ko': '비변수 베일스 반감독분사', 'tr': 'Sözlük bir Bayezi Semi-gözlemiş Kelime Segmentasyonu', 'af': 'Geparametriese Bayesian semi- superviseer Woord Segmentasie', 'id': 'Nonparametric Bayesian Semi-supervised Word Segmentation', 'sw': 'Kitendo cha Bayesia cha Semi kinachofuatiliwa kwa neno la Kutenga', 'sq': 'Segmentacioni i Fjalëve jo parametrik i mbikqyrur nga Bayesia', 'am': 'parameteric Bayesian Semi-supervised Word Segmentation', 'bs': 'Neparametrična Bayesijska polu nadzorna segmentacija riječi', 'bn': 'কোনো প্যারামিট্রিক বেয়েসিয়ান সেমি- পর্যবেক্ষণ করা শব্দ বিভাগ', 'hy': 'Nonparametric Bayesian Semi-supervised Word Segmentation', 'et': 'Mitteparameetriline bayesia pooljärelevalvega sõnade segmenteerimine', 'az': 'Parametrik olmayan Bayesiya yarısını gözləyir Kelimi Segmentasyonu', 'cs': 'Neparametrická Bayesovská polovičně dohledová segmentace slov', 'ca': 'Segmentació de paraules semi-supervisada de Bayesia', 'fi': 'Ei-parametrinen Bayesian Semi-supervised Word Segmentation', 'sk': 'Neparametrična bajzijska polnadzorovana segmentacija besed', 'ha': 'KCharselect unicode block name', 'jv': 'Languages', 'he': 'ניתוח מילים לא פארמטרי', 'bo': 'Nonparametric Bayesian Semi-supervised Word Segmentation'}
{'en': 'This paper presents a novel hybrid generative / discriminative model of word segmentation based on nonparametric Bayesian methods. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new words, and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. Specifically, our hybrid model combines a discriminative classifier (CRF ; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM ; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM ; Suzuki and Isozaki (2008)). We confirmed that it can appropriately segment non-standard texts like those in Twitter and Weibo and has nearly state-of-the-art accuracy on standard datasets in Japanese, Chinese, and Thai.', 'ar': 'تقدم هذه الورقة نموذجًا توليديًا / تمييزيًا جديدًا هجينًا لتجزئة الكلمات بناءً على طرق بايز غير معلمية. على عكس تجزئة الكلمات التمييزية العادية التي تعتمد فقط على البيانات المصنفة ، فإن نموذجنا شبه الخاضع للإشراف يستفيد أيضًا من كميات هائلة من النص غير المصنف لتعلم "كلمات" جديدة تلقائيًا ، ويزيد من تقييدها باستخدام البيانات المصنفة لتقسيم النصوص غير القياسية مثل تلك الموجودة في خدمات الشبكات الاجتماعية. على وجه التحديد ، يجمع نموذجنا الهجين بين المصنف التمييزي (CRF ؛ Lafferty et al. (2001) وتجزئة الكلمات غير الخاضعة للإشراف (NPYLM ؛ Mochihashi et al. (2009)) ، مع تبادل شفاف للمعلومات بين هذين النموذجين داخل الهياكل شبه. إطار عمل خاضع للإشراف (JESS-CM؛ Suzuki and Isozaki (2008)). أكدنا أنه يمكن تقسيم النصوص غير القياسية بشكل مناسب مثل تلك الموجودة في Twitter و Weibo ولديه دقة متطورة تقريبًا في مجموعات البيانات القياسية باللغات اليابانية والصينية ، والتايلاندية.', 'pt': 'Este artigo apresenta um novo modelo híbrido generativo/discriminativo de segmentação de palavras baseado em métodos bayesianos não paramétricos. Ao contrário da segmentação discriminativa de palavras comum, que se baseia apenas em dados rotulados, nosso modelo semi-supervisionado também aproveita uma enorme quantidade de texto não rotulado para aprender automaticamente novas “palavras” e as restringe ainda mais usando dados rotulados para segmentar textos não padronizados, como aqueles encontrados em serviços de redes sociais. Especificamente, nosso modelo híbrido combina um classificador discriminativo (CRF; Lafferty et al. (2001) e segmentação de palavras não supervisionada (NPYLM; Mochihashi et al. (2009)), com uma troca transparente de informações entre essas duas estruturas de modelo dentro do semi- estrutura supervisionada (JESS-CM; Suzuki e Isozaki (2008)). Confirmamos que ela pode segmentar adequadamente textos não padronizados como os do Twitter e Weibo e tem precisão quase de última geração em conjuntos de dados padrão em japonês, chinês , e tailandês.', 'fr': "Cet article présente un nouveau modèle hybride génératif/discriminatif de segmentation de mots basé sur des méthodes bayésiennes non paramétriques. Contrairement à la segmentation discriminative de mots ordinaires qui repose uniquement sur des données étiquetées, notre modèle semi-supervisé exploite également d'énormes quantités de texte non étiqueté pour apprendre automatiquement de nouveaux «\xa0mots\xa0», et les contraint davantage en utilisant des données étiquetées pour segmenter des textes non standard tels que ceux trouvés dans les réseaux sociaux services réseau. Plus précisément, notre modèle hybride combine un classificateur discriminant (CRF\xa0; Lafferty et al. (2001) et une segmentation de mots non supervisée (NPYLM\xa0; Mochihashi et al. (2009)), avec un échange transparent d'informations entre ces deux structures de modèle dans le cadre semi-supervisé (JESS-CM\xa0; Suzuki et Isozaki ( 2008). Nous avons confirmé qu'il peut segmenter de manière appropriée les textes non standard tels que ceux de Twitter et Weibo et qu'il offre une précision presque inégalée sur les ensembles de données standard en japonais, en chinois et en thaï.", 'es': 'Este artículo presenta un novedoso modelo híbrido generativo/discriminativo de segmentación de palabras basado en métodos bayesianos no paramétricos. A diferencia de la segmentación de palabras discriminativa ordinaria, que se basa únicamente en datos etiquetados, nuestro modelo semi-supervisado también aprovecha una enorme cantidad de texto sin etiqueta para aprender automáticamente nuevas «palabras» y las restringe aún más mediante el uso de datos etiquetados para segmentar textos no estándar, como los que se encuentran en las redes sociales servicios de redes. Específicamente, nuestro modelo híbrido combina un clasificador discriminativo (CRF; Lafferty et al. (2001) y segmentación de palabras no supervisada (NPYLM; Mochihashi et al. (2009)), con un intercambio transparente de información entre estas dos estructuras modelo dentro del marco semisupervisado (JESS-CM; Suzuki e Isozaki ( 2008)). Confirmamos que puede segmentar adecuadamente textos no estándar como los de Twitter y Weibo y que tiene una precisión casi de vanguardia en conjuntos de datos estándar en japonés, chino y tailandés.', 'ja': 'ノンパラメトリックベイズ法に基づく単語セグメンテーションの新規ハイブリッド生成/識別モデルを提示した。ラベル付けされたデータのみに依存する通常の差別的な単語セグメンテーションとは異なり、私たちの半監督モデルはまた、膨大な量のラベル付けされていないテキストを活用して自動的に新しい「単語」を学習し、ソーシャルネットワーキングサービスに見られるような非標準的なテキストをセグメント化するためにラベル付けされたデータを使用することによって、それらをさらに制約します。具体的には、私たちのハイブリッドモデルは、判別型分類子（ ＣＲＦ ； Ｌａｆｆｅｒｔｙ ｅ ｔ ａ ｌ ． （ ２ ０ ０ １ ） ）と非監視型単語セグメンテーション（ ＮＰＹＬＭ ； Ｍｏｃｈｉｈａｓｈｉ ｅ ｔ ａ ｌ ． （ ２ ０ ０ ９ ） ）を組み合わせ、これら２つのモデル構造間で半監視型フレームワーク内で透明な情報交換を行う（ ＪＥＳＳ － ＣＭ ； Ｓｕｚｕｋｉ ａｎｄ Ｉｓｏｚａｋｉ （ ２ ０ ０ ８ ） ）。TwitterやWeiboなどの非標準テキストを適切にセグメント化でき、日本語、中国語、タイ語の標準データセットにほぼ最新の精度を持つことを確認しました。', 'ru': 'В данной работе представлена новая гибридная генеративная/дискриминационная модель сегментации слов, основанная на непараметрических байесовских методах. В отличие от обычной дискриминационной сегментации слов, которая опирается только на помеченные данные, наша полунадзорная модель также использует огромное количество немеченного текста для автоматического изучения новых «слов» и дополнительно ограничивает их, используя помеченные данные для сегментации нестандартных текстов, таких как тексты, найденные в социальных сетях. В частности, наша гибридная модель сочетает в себе дискриминационный классификатор (CRF; Lafferty et al. (2001) и неконтролируемую сегментацию слов (NPYLM; Mochihashi et al. (2009)) с прозрачным обменом информацией между этими двумя модельными структурами в рамках полуконтролируемой структуры (JESS-CM; Suzuki and Isozaki (2008)). Мы подтвердили, что он может соответствующим образом сегментировать нестандартные тексты, такие как тексты в Twitter и Weibo, и имеет почти самую современную точность на стандартных наборах данных на японском, китайском и тайском языках.', 'zh': '立一本于非参数贝叶斯法者分词混而成/判别模形。 与仅依表数之普通区分性分词不同,吾半监模犹以大未标之文本自习新单词,因用标数对非标准文本(如社交网络服务中文本)细分以约束之。 具体来说,合刑合器(CRF。 Lafferty等(2001)与无监分词(NPYLM。 Mochihashi等(2009)),于半监框架内两样透明易信(JESS-CM。 铃木和矶崎新(2008))。 臣等证之,可以适割非标准本,如Twitter微博中之本,并在日语,中文泰语之数集上有近先进之准确性。', 'hi': 'यह पेपर गैर-पैरामीट्रिक बायेसियन विधियों के आधार पर शब्द विभाजन का एक उपन्यास हाइब्रिड जेनरेटर / भेदभावपूर्ण मॉडल प्रस्तुत करता है। सामान्य भेदभावपूर्ण शब्द विभाजन के विपरीत जो केवल लेबल किए गए डेटा पर निर्भर करता है, हमारा अर्ध-पर्यवेक्षित मॉडल स्वचालित रूप से नए "शब्दों" को सीखने के लिए बड़ी मात्रा में बिना लेबल वाले पाठ का लाभ उठाता है, और सोशल नेटवर्किंग सेवाओं में पाए जाने वाले गैर-मानक ग्रंथों को विभाजित करने के लिए लेबल किए गए डेटा का उपयोग करके उन्हें और बाधित करता है। विशेष रूप से, हमारा हाइब्रिड मॉडल एक भेदभावपूर्ण क्लासिफायर (सीआरएफ) को जोड़ता है; Lafferty et al. (2001) और असुरक्षित शब्द विभाजन (NPYLM; Mochihashi et al. (2009)), अर्ध-पर्यवेक्षित ढांचे (JESS-CM) के भीतर इन दो मॉडल संरचनाओं के बीच जानकारी के पारदर्शी आदान-प्रदान के साथ; सुजुकी और इसोज़ाकी (2008)। हमने पुष्टि की है कि यह उचित रूप से ट्विटर और वीबो में उन लोगों की तरह गैर-मानक ग्रंथों को विभाजित कर सकता है और जापानी, चीनी और थाई में मानक डेटासेट पर लगभग अत्याधुनिक सटीकता है।', 'ga': 'Cuireann an páipéar seo i láthair samhail giniúna/idirdhealaitheach hibrideach nua de dheighilt focal bunaithe ar mhodhanna neamhparaiméadracha Bayesian. Murab ionann agus gnáth-dheighilt focal idirdhealaitheach a bhraitheann ar shonraí lipéadaithe amháin, déanann ár múnla leath-mhaoirseachta giaráil freisin ar mhéideanna ollmhóra téacs gan lipéad chun “focail” nua a fhoghlaim go huathoibríoch, agus cuireann sé srian breise orthu trí úsáid a bhaint as sonraí lipéadaithe chun téacsanna neamhchaighdeánacha a dheighilt. iad siúd atá le fáil i seirbhísí líonraithe sóisialta. Go sonrach, comhcheanglaíonn ár múnla hibrideach aicmitheoir idirdhealaitheach (CRF; Lafferty et al. (2001) agus deighilt focal gan mhaoirseacht (NPYLM; Mochihashi et al. (2009))), le malartú trédhearcach faisnéise idir an dá struchtúr mhúnla seo laistigh den leath-struchtúr. creat maoirsithe (JESS-CM; Suzuki agus Isozaki (2008)) Dhearbhaíomar gur féidir léi téacsanna neamhchaighdeánacha mar iad siúd in Twitter agus Weibo a dheighilt go cuí agus go bhfuil cruinneas den scoth aige ar thacair sonraí caighdeánacha sa tSeapáinis agus sa tSínis. , agus Téalainnis.', 'hu': 'A tanulmány bemutatja a szószegmentáció új hibrid generációs/diszkriminatív modelljét, amely nem parametrikus bayesiai módszereken alapul. A hagyományos diszkriminatív szószegmentációval ellentétben, amely csak a címkézett adatokon alapul, a félig felügyelt modellünk hatalmas mennyiségű, címke nélküli szöveget is felhasznál arra, hogy automatikusan megtanulják az új "szavakat", és tovább korlátozza őket azzal, hogy címkézett adatokat használnak a nem szabványos szövegek szegmentálására, mint például a közösségi hálózati szolgáltatásokban. Különösen, hibrid modellünk egy diszkriminatív osztályozót (CRF; Lafferty et al. (2001) és felügyelet nélküli szegmentációt (NPYLM; Mochihashi et al. (2009)), amely átlátható információcserét biztosít e két modellstruktúra között a félig felügyelt kereten belül (JESS-CM; Suzuki és Isozaki (2008)). Megerősítettük, hogy megfelelően szegmensezheti a nem szabványos szövegeket, mint például a Twitteren és a Weibón, és szinte a legkorszerűbb pontossággal rendelkezik a szabványos adatkészleteken japán, kínai és thai nyelven.', 'el': 'Η παρούσα εργασία παρουσιάζει ένα νέο υβριδικό παραγωγικό/διακριτικό μοντέλο τμηματοποίησης λέξεων βασισμένο σε μη παραμετρικές Bayesian μεθόδους. Σε αντίθεση με τη συνηθισμένη διαφοροποιημένη τμηματοποίηση λέξεων που βασίζεται μόνο σε δεδομένα με ετικέτα, το ημι-εποπτευμένο μοντέλο μας χρησιμοποιεί επίσης τεράστιες ποσότητες χωρίς ετικέτα κειμένου για να μάθει αυτόματα νέες "λέξεις", και τις περιορίζει περαιτέρω χρησιμοποιώντας δεδομένα με ετικέτα για να ταξινομήσει μη τυποποιημένα κείμενα, όπως αυτά που βρίσκονται στις υπηρεσίες κοινωνικής δικτύωσης. Ειδικότερα, το υβριδικό μας μοντέλο συνδυάζει έναν διαχωριστικό ταξινομητή (CRF, Lafferty et al. (2001) και μια χωρίς επίβλεψη τμηματοποίηση λέξεων (NPYLM, Mochihashi et al. (2009)), με μια διαφανή ανταλλαγή πληροφοριών μεταξύ αυτών των δύο δομών μοντέλου στο πλαίσιο ημιεπιτήρησης (Suzuki και Isozaki (2008)). Επιβεβαιώσαμε ότι μπορεί να ταξινομήσει κατάλληλα μη τυποποιημένα κείμενα όπως αυτά στο Twitter και το Weibo και έχει σχεδόν υπερσύγχρονη ακρίβεια σε τυποποιημένα σύνολα δεδομένων στα ιαπωνικά, κινέζικα και ταϊλανδέζικα.', 'ka': "ეს დომენტი ახლა პრომენტიური ჰიბრიდის გენერაციური/დისკრიმინატიური სიტყვების სეგმენტის მოდელი, რომელიც არ პარამეტრიური ბეიზიანური მეცედიების ჩვენი პროგრამიური დისკრიმინატიური სიტყვების სეგმენტის განმავლობაში, რომელიც მხოლოდ მართლად მართლაც მართლაც მართლაც მართლაც მართლად მართლად მონაცემებული მოდელზე, ჩვენი პროგრამიური მართლაც მართლად ახალი 'სიტყვები' მოსწავლად განსაკუთრებულია, ჩვენი ჰიბრიდი მოდელი დისკრიმინატიური კლასიფიკაციატორია (CRF; Lafferty et al. (2001) და არ განსაკუთრებული სიტყვების სეგმენტია (NPYLM; Mochihashi et al. (2009)), ამ ორი მოდელური სტრუქტურების განსაკუთრებული ინფორმაციის გადაცვლა (JESS-CM; Suzuki და Isozaki (2008 ჩვენ დარწმუნეთ, რომ ეს შეუძლია საპირო, ჩინტერვირში და საიბოში სტანდარტური ტექსტების სწორედ სექმენტური სექმენტური სექმენტის მართლაც იქნება და საიბოში სექმენტური", 'it': "Questo articolo presenta un nuovo modello ibrido generativo/discriminatorio di segmentazione delle parole basato su metodi bayesiani non parametrici. A differenza della normale segmentazione discriminatoria delle parole che si basa solo su dati etichettati, il nostro modello semi-supervisionato sfrutta anche un'enorme quantità di testo non etichettato per imparare automaticamente nuove 'parole', e li limita ulteriormente utilizzando dati etichettati per segmentare testi non standard come quelli trovati nei servizi di social networking. Nello specifico, il nostro modello ibrido combina un classificatore discriminante (CRF; Lafferty et al. (2001) e una segmentazione non supervisionata delle parole (NPYLM; Mochihashi et al. (2009)), con uno scambio trasparente di informazioni tra queste due strutture modello all'interno del quadro semi-supervisionato (JESS-CM; Suzuki e Isozaki (2008)). Abbiamo confermato che può segmentare in modo appropriato testi non standard come quelli su Twitter e Weibo e ha una precisione quasi all'avanguardia sui set di dati standard in giapponese, cinese e tailandese.", 'kk': "Бұл қағаз бейезия әдістеріне негізделген романдық гибридтік/дискриминациялық сөздерді сегментациялау үлгісін көрсетеді. Кәдімгі дискриминациялық сөздердің сегментациясы, тек жарлық деректеріне тәуелді, біздің жартық бақылау үлгіміз де жаңа 'сөздер' дегенді автоматты түрде үйрену үшін, жаңа 'сөздер' дегенді үйрену үшін үлкен мәтіндерді шектеп, жарлық деректерді қолдану ү Ескерту үшін, біздің гибрид моделіміз дискриминациялық классификациясы (CRF; Lafferty et al. (2001) және сөздер сегментациясы (NPYLM; Mochihashi et al. (2009)), бұл екі үлгі құрылғылар арасындағы мәліметті біріктіріп, жарты бақылау фреймінде (JESS- CM; Suzuki және Isozaki (2008)). Біз оның Твиттер мен Вайбо секілдерінің стандартты мәтіндері дұрыс емес екенін баптап, жапон, қытайлық және Тайландық стандартты деректер жиындарының стандартты дұрыстығы бар деп ойладық.", 'lt': 'Šiame dokumente pateikiamas naujas hibridinis ir (arba) diskriminacinis žodžių segmentavimo modelis, grindžiamas ne parametriniais Bayezijos metodais. Priešingai nei įprastas diskriminacinis žodžių segmentavimas, kuris grindžiamas tik pažymėtais duomenimis, mūsų pusiau prižiūrimas modelis taip pat sutelkia didžiulį kiekį nežymėto teksto, kad būtų galima automatiškai išmokti naujų žodžių, ir toliau apriboja juos naudojant pažymėtus duomenis, kad būtų galima segmentuoti nestandartinius tekstus, pvz., socialinių tinklų paslaugų tekstus. Konkrečiai, mūsų hibridinis modelis derina diskriminacinį klasifikatorių (CRF; Lafferty et al. (2001) ir nepastebimą žodžių segmentavimą (NPYLM; Mochihashi et al. (2009)), skaidrų šių dviejų modelių struktūrų keitimąsi informacija pagal pusiau prižiūrimą sistemą (JESS-CM; Suzuki ir Isozaki (2008)). Patvirtinome, kad ji gali tinkamai suskirstyti nestandartinius tekstus, kaip antai tekstus Twitter ir Weibo, ir turi beveik naujausią tikslumą standartinių duomenų rinkinių japonų, kinų ir tailandų kalbomis.', 'mk': 'Овој весник претставува нов хибриден генерационален/дискриминативен модел на зборна сегментација базиран на непараметричките бајезиски методи. За разлика од обичната дискриминативна сегментација на зборови која се потпира само на означени податоци, нашиот полунадгледуван модел, исто така, користи огромна количина неозначен текст за автоматски да се научи нови „зборови“, и понатаму ги ограничува со користење означени податоци за сегментирање нестандардни тексти како што се оние Специфично, нашиот хибриден модел комбинира дискриминативен класификатор (ЦРФ; Лаферти и г. (2001) и ненадгледувана словена сегментација (НПЈЛМ; Мочихаши и г. (2009)), со транспарентна размена на информации помеѓу овие две моделни структури во полунадгледуваната рамка (ЈЕСС-ЦМ; Сузуки и Исозаки (2008 Потврдивме дека може соодветно да ги дели нестандардните тексти како оние на Твитер и Вајбо и има скоро најсовремена точност на стандардните податоци на јапонски, кинески и тајландски.', 'mt': "This paper presents a novel hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods.  Għall-kuntrarju tas-segmentazzjoni tal-kliem diskriminatorja ordinarja li tiddependi biss fuq dejta ttikkettata, il-mudell nofs superviż tagħna jgħaqqad ukoll ammonti kbar ta’ test mhux ittikkettat biex jitgħallmu awtomatikament ‘kliem’ ġodda, u jkompli jirrestrinġihom billi tuża dejta ttikkettata biex taqsam testi mhux standard bħal dawk misjuba fis-servizzi tan-netwerking soċjali. B’mod speċifiku, il-mudell ibridu tagħna jikkombina klassifikatur diskriminatorju (CRF; Lafferty et al. (2001) u segmentazzjoni tal-kliem mhux sorveljata (NPYLM; Mochihashi et al. (2009)), ma’ skambju trasparenti ta’ informazzjoni bejn dawn iż-żewġ strutturi mudell fi ħdan il-qafas semisorveljat (JESS-CM; Suzuki u Isozaki (2008)). Aħna kkonfermajna li tista' taqsam b'mod xieraq testi mhux standard bħal dawk fuq Twitter u Weibo u għandha kważi l-aktar preċiżjoni avvanzata fuq settijiet ta' dejta standard fil-Ġappuniż, Ċiniż u t-Tajlandiż.", 'ms': "Kertas ini memperkenalkan model hibrid baru generatif/diskriminatif segmen perkataan berdasarkan kaedah Bayesian bukan parametrik. Tidak seperti segmen perkataan diskriminatif biasa yang hanya bergantung pada data yang ditabel, model setengah-mengawasi kami juga menggunakan jumlah besar teks tidak ditabel untuk secara automatik belajar 'perkataan' baru, dan halang lebih lanjut mereka dengan menggunakan data ditabel untuk segmen teks bukan piawai seperti yang ditemui dalam perkhidmatan rangkaian sosial. Secara khusus, model hibrid kami menggabungkan pengklasifikasi diskriminatif (CRF; Lafferty et al. (2001) dan segmen perkataan tidak diawasi (NPYLM; Mochihashi et al. (2009)), dengan pertukaran maklumat yang jelas antara kedua-dua struktur model ini dalam kerangka setengah diawasi (JESS-CM; Suzuki dan Isozaki (2008)). Kami mengesahkan bahawa ia boleh segmen teks yang tidak piawai seperti dalam Twitter dan Weibo dan mempunyai ketepatan hampir terbaik pada set data piawai dalam bahasa Jepun, Cina dan Thai.", 'ml': 'ഈ പത്രത്തില്\u200d ഒരു നോവല്\u200d ഹൈബ്രിഡിന്റെ ജനററിവ്/വിവേചനയുടെ മോഡല്\u200d കാണിക്കുന്നു. പാരാമെറ്റിക് ബെയിസിയന്\u200d രീതികളില്\u200d അടിസ് സാധാരണ വാക്കുകളുടെ വിഭാഗത്തില്\u200d വ്യത്യസ്തമായ വാക്കുകള്\u200d വേര്\u200dതിരിച്ചറിയുന്നതില്\u200d മാത്രം വിശ്വസിക്കുന്നു. നമ്മുടെ സെമി-നോട്ട് നിരീക്ഷിക്കപ്പെട്ട മോഡല്\u200d സ്വയം പുതിയ വാക്കുകള്\u200d പഠ പ്രത്യേകിച്ച്, നമ്മുടെ ഹൈബ്രിഡ് മോഡല്\u200d ഒരു വ്യത്യസ്ത വ്യവസ്ഥയെ കൂട്ടിക്കൊണ്ടിരിക്കുന്നു (CRF; Lafferty et al. (2001) പിന്നെ സൂക്ഷിക്കാത്ത വാക്ക് സംഘടിപ്പിക്കുന്നതും (NPYLM; മൊചിഹാഷി et al. (2009)), ഈ രണ്ട് മോഡല്\u200d ഘ ഞങ്ങള്\u200d ഉറപ്പ് വരുത്തിയിരിക്കുന്നു ഇത് ടൂട്ടരും വെയിബോയിലും സ്ഥാനമില്ലാത്ത പദാവലികള്\u200dക്ക് വേര്\u200dപെടുത്താന്\u200d സാധിക്കുന്നു. ജാപ്പാനീസ്, ചൈനീ', 'no': 'Denne papiret viser ein novel hybrid-generativ/diskrimineriv modell for ordsegmentasjon basert på ikkje-parametriske Bayesianske metodar. I motsetjing til vanleg diskriminasjon av ordsegmentasjon som berre dependerer på merkelige data, vår halvoversikt modellen leverer også ein stor mengd av ikkje merkelige tekst til å automatisk læra nye ord, og framleis begrenser dei ved å bruka eit merkelige data til å segmentera ikkje-standard tekstar, slik som dei funne i sosiale nettverktjenester. Spesielt kombinerer hibridmodellen vårt ein diskriminativ klassifisering (CRF; Lafferty et al. (2001) og uverkjende ordsegmentasjon (NPYLM; Mochihashi et al. (2009)), med ein gjennomsiktig utveksling av informasjon mellom disse to modelle strukturene i semioversikte rammeverket (JESS-CM; Suzuki og Isozaki (2008)). Vi stadfestig at det kan dele ikkje-standardtekstar som dei i Twitter og Weibo og har nesten kunstige nøyaktighet på standard datasett i japansk, kinesisk og Thai.', 'mn': 'Энэ цаас биезийн арга баримтгүй үг загварын шинэ гибрид үүсгэгч/ялгаагүй загварыг харуулдаг. Шинэ үгийг автоматжуулахын тулд бидний хагас удирдлагагүй загвар мөн шинэ үгийг автоматжуулахын тулд маш их хэмжээний хэмжээг ашигладаг. Ялангуяа бидний гибрид загвар нь тархалтын хуваагдагч (CRF; Lafferty et al. (2001) болон бусад үг загвар (NPYLM; Mochihashi et al. (2009)) хоёр загварын байгууллагуудын хоорондын тодорхой мэдээллийг хагас удирдаггүй хэлбэрээр (JESS-CM; Suzuki, Isozaki (2008)-ын хоорондын тодорхой хувьцааны хувьцааны Бид үүнийг Твиттер, Вэйбо хоёр шиг стандарт биш текстүүдийг зөвхөн загварчлах боломжтой гэдгийг баталсан. Япон, Хятад, Тайланд стандарт өгөгдлийн сангийн зөв байдал бараг л байдаг.', 'pl': 'W artykule przedstawiono nowy hybrydowy model segmentacji słów generatywnych/dyskryminacyjnych oparty na nieparametrycznych metodach Bayesowskich. W przeciwieństwie do zwykłej segmentacji słów dyskryminacyjnych, która opiera się wyłącznie na danych etykietowanych, nasz model pół-nadzorowany wykorzystuje również ogromne ilości nieetykietowanego tekstu do automatycznego uczenia się nowych "słów" i dodatkowo ogranicza je poprzez wykorzystanie etykietowanych danych do segmentowania niestandardowych tekstów, takich jak te znajdujące się w serwisach społecznościowych. W szczególności nasz model hybrydowy łączy w sobie klasyfikator dyskryminacyjny (CRF; Lafferty i al. (2001) oraz segmentację słów bez nadzoru (NPYLM; Mochihashi i al. (2009)), z przejrzystą wymianą informacji między tymi dwoma strukturami modelowymi w ramach pół-nadzorowanych (JESS-CM; Suzuki i Isozaki (2008)). Potwierdziliśmy, że może odpowiednio segmentować niestandardowe teksty, takie jak te na Twitterze i Weibo oraz posiada niemal najnowocześniejszą dokładność na standardowych zbiorach danych w języku japońskim, chińskim i tajskim.', 'ro': 'Această lucrare prezintă un nou model generativ/discriminatoriu hibrid de segmentare a cuvintelor bazat pe metode bayesiane non-parametrice. Spre deosebire de segmentarea discriminativă obișnuită a cuvintelor, care se bazează numai pe date etichetate, modelul nostru semi-supravegheat utilizează, de asemenea, o cantitate uriașă de text nelimitat pentru a învăța automat noi "cuvinte", și le constrânge în continuare prin utilizarea unor date etichetate pentru a segmenta texte nestandard, cum ar fi cele găsite în serviciile de rețele sociale. Mai exact, modelul nostru hibrid combină un clasificator discriminatoriu (CRF; Lafferty et al. (2001) și segmentarea cuvintelor nesupravegheată (NPYLM; Mochihashi et al. (2009)), cu un schimb transparent de informații între aceste două structuri de model în cadrul semi-supravegheat (JESS-CM; Suzuki și Isozaki (2008)). Am confirmat că poate segmenta în mod corespunzător texte non-standard precum cele din Twitter și Weibo și are o acuratețe aproape de ultimă oră pe seturile de date standard în japoneză, chineză și thailandeză.', 'sr': "Ovaj papir predstavlja nov hibridni generativni/diskriminacijski model segmentacije reèi na osnovu neparametričkih Bayesijskih metoda. Za razliku od obične diskriminacijske segmentacije riječi koja se oslanja samo na etiketirane podatke, naš polu nadzorni model takođe utiče na ogromne količine nenabeliranog teksta da automatski nauči nove 'reči', i dalje ih ograničava koristeći etiketirane podatke na segmentirane ne standardne tekste kao što su pronađene u socijalnim mrežnim uslugama. Posebno, naš hibridni model kombinira diskriminativnu klasifikaciju (CRF; Lafferty et al. (2001) i neodređenu segmentaciju riječi (NPYLM; Mochihashi et al. (2009)), sa transparentnom razmjenom informacija između tih dva modelnih struktura u polu nadzornom okviru (JESS-CM; Suzuki i Isozaki (2008)). Potvrdili smo da može odgovarajući segmentirati ne-standardne tekstove poput one na Twitter i Weibo i da ima skoro stanje umjetnosti tačnosti na standardnim setima podataka na japanskom, kineskom i Tajlandu.", 'si': 'මේ පැත්ත පෙන්වන්නේ නොපාරාම්ටරික බේසියාන් විදියට ආධාරිත විදියට නිර්මාණික/විශ්වාසික විදියට ප්\u200dර නැත්තම් සාමාන්\u200dය විශ්වාසික වචන සැකසුම් වචන සැකසුම් වලින් විතරයි ලේබල් වලින් විතරයි, අපේ සාමාන්\u200dය විශ්වාසිත විදියට ප්\u200dරමාණයක් තියෙන්නේ ලේබල් වලින් ලේබල් වලි විශේෂයෙන්, අපේ හිබ්\u200dරිඩ් මොඩල් සම්බන්ධ විශ්වාසිත විශේෂකය (CRF; Lafferty et al. (2001) සහ නොසුපෙර්වසිත වචනය (NPYLM; Mochihashi et al. (2009)), සහ පාරදානම් සම්බන්ධ විශේෂකයේ තොරතුරු අතර මෙම් මොඩල් ස අපි සැකසුම් කළා ඒක ට්විටර් සහ වේබෝ වලින් ප්\u200dරමාණයෙන් නොප්\u200dරමාණයෙන් පිළිබඳ වෙන්න පුළුවන් කියලා, ජාපාන්, චීනි සහ තායින', 'so': 'Qoraalkan wuxuu soo saaraa qaab dhaqan/takooris ah oo ku saleysan qaababka ay Bayesian ku qoran yihiin. Kala duwan qayb-takoorista ah oo ku xiran macluumaadka calaamadda oo kaliya, noocyadana halka ka ilaaliyey wuxuu sidoo kale ku fidiyaa warqad badan oo aan la qorin si ay u barato hadal cusub, waxaana sidoo kale ku qasba isticmaalka macluumaad labo ah si ay u kala qeybiso qoraal aan caadi ahayn, sida kuwa laga helay adeegyada shabakadda bulshada. Sida gaar ah, modelheenna hybrid wuxuu isku biiriyaa takooris (CRF; Lafferty et al. (2001) iyo unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), waxaana la bedelay macluumaad muuqaal ah oo u dhexeeya labadaas dhismaha model hoose-hoose-ilaaliyey (JESS-CM; Suzuki iyo Isozaki (2008). Waxaannu xaqiijinnay inay si saxda ah u qeyb-dhigi karto qoraal aan caadi ahayn sida Twitterka iyo Weibo, waxayna ku leedahay saxda xaaladda farshaxanka ah oo ku saabsan sawirada caadiga ah ee japaniya, Shiino iyo Thai.', 'sv': 'Denna uppsats presenterar en ny hybrid generativ/diskriminerande modell av ordsegmentering baserad på icke-parametriska bayesiska metoder. Till skillnad från vanlig diskriminerande ordsegmentering som bara bygger på märkta data, utnyttjar vår halvövervakade modell också enorma mängder omärkt text för att automatiskt lära sig nya "ord", och begränsar dem ytterligare genom att använda en märkt data för att segmentera icke-standardiserade texter som de som finns i sociala nätverkstjänster. Specifikt kombinerar vår hybridmodell en diskriminerande klassificerare (CRF; Lafferty m.fl. (2001) och obevakad ordsegmentering (NPYLM; Mochihashi m.fl. (2009)), med ett transparent informationsutbyte mellan dessa två modellstrukturer inom det halvövervakade ramverket (JESS-CM; Suzuki och Isozaki (2008)). Vi bekräftade att det på lämpligt sätt kan segmentera icke-standardtexter som de i Twitter och Weibo och har nästan toppmodern noggrannhet på standarddataset på japanska, kinesiska och thailändska.', 'ta': "இந்த காகிதத்தின் புதிய ஹைப்ரிட் பொதுவான/வித்தியாசமான வார்த்தை துண்டுதல் மாதிரியை கொடுக்கிறது பயீசியன் முறைமை வழக்கமான வார்த்தை பிரிவு துண்டு மட்டும் குறிப்பிட்ட தகவல் மீது நம்புகிறது, எங்கள் பாமி கண்காணிக்கப்பட்ட மாதிரி ஒரு மிகப் பெரிய எண்ணிக்கையை வழங்குகிறது புதிய 'வார்த்தைகளை தானாகவே கற்று குறிப்பிட்டு, எங்கள் ஹைப்ரிட் மாதிரி ஒரு வித்தியாசமான வகுப்பாட்டாளரை (CRF; Lafferty et al. (2001) மற்றும் பாதுகாப்பாக்கப்படாத வார்த்தை திருத்தல் (NPYLM; Mochihashi et al. (2009)), பெமி கண்காணிக்கப்பட்ட சட்டத்தில் இந்த இரண்டு மாதிர நாங்கள் உறுதிப்படுத்தினோம் அது சரியான நிலையான அல்லாத எழுத்துக்களை துண்டிக்க முடியும் என்பதை நிர்ணயித்துள்ளோம் டூட்டர் மற்றும் வெய்போவி", 'ur': 'This paper presents a new hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods. جو صرف لابلیٹ ڈاٹ پر اعتماد ہے، ہماری نصف نظارت والی مدل نے اپنا بہت بڑا مقدار غیر لابلیٹ لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہے خاص طور پر، ہمارا ہیبراڈ موڈل ایک تقسیم کلاسیر (CRF; Lafferty et al. (2001) اور غیر قابل تغییر دینے والی کلاسیر (NPYLM; Mochihashi et al. (2009)) کے ساتھ ان دو موڈل ساختاروں کے درمیان نیم-supervised فرمود (JESS-CM; Suzuki اور Isozaki (2008)) کے درمیان مطلوبہ کی تبدیل کی جاتی ہے۔ ہم نے مطمئن کیا کہ یہ ٹویٹر اور ویبو میں ایسے بغیر استاندارڈ ٹیکسٹ کے مطابق قطع کر سکتا ہے اور قریب تھا کہ اسٹارڈ سٹ کے استاندارڈ سٹ پر جاپانی, چینی اور تائیل میں استاندارڈ سٹ کے مطابق صحیح ہے.', 'uz': "Bu qogʻoz parametrik Bayesian usulda asoslangan so'z segment modelini yaratadi. Oddiy ajratilgan so'zlar tarkibini faqat notoʻgʻri maʼlumotga ishlatadi, bizning semi-taʼminlovchi modelimiz yangi so'zlarni avtomatik o'rganish uchun juda katta qismi yordam beradi, va ular soʻzlarni avtomatik o'rganish uchun qo'llangan maʼlumot yordamida qo'llangan soʻzlarni boshqa tarmoq xizlarida o'zgartirish mumkin. Ko'rsatilgan, bizning hybrid modelimiz ajratish darajasini (CRF; Lafferty et al. (2001) va xavfsizlanmagan so'zni ajratish (NPYLM; Mochihashi et al. (2009)) bilan bir necha saqlangan jadvaldagi ikki modellar tarkibida maʼlumotni ajratish (JESS-CM; Suzuki va Isozaki (2008). Biz ishonch qildikki, bu Twitter va Weibo kabi oddiy matnlarni o'zgartirish mumkin, va yaponiya, Xitoycha va Tay tilidagi стандарт maʼlumotlar tizimini aniqlash mumkin.", 'vi': 'Tờ giấy này có một mô hình nhân tạo và phân biệt các từ khác nhau dựa trên các phương pháp không phân đo định người Bayisian. Không giống phân đoạn các từ riêng biệt bình thường chỉ dựa trên các dữ liệu được dán nhãn, mô hình bán giám sát của chúng ta cũng dùng một lượng lớn các chữ chưa được dán vào để tự động học các chữ mới, và giới hạn chúng bằng cách dùng các dữ liệu dán nhãn để phân đoạn các văn bản không tiêu chuẩn như những chữ được tìm thấy trong dịch vụ mạng xã hội. Cụ thể, mô hình lai của chúng ta kết hợp một phân loại riêng biệt (CRF, Lafferty et al. (2001) và phân biệt các từ không giám sát (không riêng (không thể nói: không thể: không thể, Mochihashi et al (2009), với một trao đổi thông tin trong suốt... giữa hai cấu trúc mô hình này trong quá trình giám sát (Jesus-CM; Suzuki và Isozaki (kế thừa) Chúng tôi xác nhận rằng nó có thể phân đoạn các văn bản không tiêu chuẩn như trên Twitter và Weibo và có độ chính xác cao nhất trên các tập tin tiêu chuẩn của Nhật, Trung Quốc và Thái.', 'da': "Denne artikel præsenterer en ny hybrid generativ / diskriminerende model af ordsegmentering baseret på nonparametriske bayesiske metoder. I modsætning til almindelig diskriminerende ordsegmentering, som kun er afhængig af mærkede data, udnytter vores halvovervågede model også en enorm mængde ikke-mærket tekst til automatisk at lære nye 'ord', og begrænser dem yderligere ved at bruge en mærket data til at segmentere ikke-standardtekster som dem, der findes i sociale netværkstjenester. Specielt kombinerer vores hybridmodel en diskriminerende klassificering (CRF; Lafferty m.fl. (2001) og en ukontrolleret ordsegmentering (NPYLM; Mochihashi m.fl. (2009)), med en gennemsigtig udveksling af oplysninger mellem disse to modelstrukturer inden for rammerne af den halvovervågede ramme (JESS-CM; Suzuki og Isozaki (2008)). Vi bekræftede, at det på passende vis kan segmentere ikke-standardtekster som dem i Twitter og Weibo og har næsten state-of-the-art nøjagtighed på standarddatasæt på japansk, kinesisk og thailandsk.", 'de': 'Diese Arbeit stellt ein neuartiges hybrides generatives/diskriminierendes Modell der Wortsegmentierung vor, das auf nichtparametrischen Bayesischen Methoden basiert. Im Gegensatz zu gewöhnlicher diskriminierender Wortsegmentierung, die nur auf beschrifteten Daten beruht, nutzt unser halbüberwachtes Modell auch eine große Menge an unbekennzeichneten Texten, um automatisch neue "Wörter" zu lernen. Außerdem werden diese durch die Verwendung von beschrifteten Daten zur Segmentierung nicht standardisierter Texte, wie sie in sozialen Netzwerken gefunden werden, weiter eingeschränkt. Konkret kombiniert unser Hybridmodell einen diskriminierenden Klassifikator (CRF; Lafferty et al. (2001) und eine unüberwachte Wortsegmentierung (NPYLM; Mochihashi et al. (2009)), mit einem transparenten Informationsaustausch zwischen diesen beiden Modellstrukturen im semi-supervised framework (JESS-CM; Suzuki und Isozaki (2008)). Wir haben bestätigt, dass es nicht-standardisierte Texte wie Twitter und Weibo angemessen segmentieren kann und nahezu State-of-the-Art-Genauigkeit auf Standard-Datensätzen in Japanisch, Chinesisch und Thai aufweist.', 'id': "Kertas ini mempersembahkan model hibrid baru generatif/diskriminatif segmen kata berdasarkan metode Bayesia yang tidak parametrik. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services.  Secara spesifik, model hibrid kita menggabungkan klasifikasi diskriminatif (CRF; Lafferty et al. (2001) dan segmen kata yang tidak diawasi (NPYLM; Mochihashi et al. (2009)), dengan pertukaran informasi transparan antara dua struktur model ini dalam rangka semi-mengawasi (JESS-CM; Suzuki dan Isozaki (2008)). Kami mengkonfirmasi bahwa dapat segmen teks yang tidak standar seperti di Twitter dan Weibo dan memiliki akurasi hampir state-of-the-art pada set data standar dalam bahasa Jepang, Cina dan Thailand.", 'bg': 'Настоящата статия представя нов хибриден генеративен/дискриминативен модел на сегментация на думи, базиран на непараметрични баезийски методи. За разлика от обикновената дискриминационна сегментация на думи, която разчита само на етикетирани данни, нашият полу-надзорен модел също използва огромни количества незабелязан текст, за да научи автоматично нови "думи", и допълнително ги ограничава, като използва етикетирани данни, за да сегментира нестандартни текстове като тези, намерени в социалните мрежи услуги. По-конкретно, нашият хибриден модел съчетава дискриминационен класификатор (CRF; Lafferty et al. (2001) и неконтролирана словна сегментация (NPYLM; Mochihashi et al. (2009)), с прозрачен обмен на информация между тези две структури на модела в рамките на полунадзорната рамка (JESS-CM; Suzuki и Isozaki (2008)). Потвърдихме, че може правилно да сегментира нестандартни текстове като тези в Туитър и Уайбо и има почти най-съвременна точност на стандартните набори от данни на японски, китайски и тайландски език.', 'hr': "Ovaj papir predstavlja nov hibridni generativni/diskriminacijski model segmentacije riječi na temelju nenaparatnih Bayesijskih metoda. Za razliku od obične diskriminacijske segmentacije riječi koje se oslanjaju samo na označenim podacima, naš polu nadzorni model također utječe na ogromne količine nenabeliranog teksta kako bi automatski naučio nove 'riječi', a dalje ih ograničava koristeći označene podatke za segmentiranje neustandardnih tekstova kao što su pronađeni u socijalnim mrežnim uslugama. Posebno, naš hibridni model kombinira diskriminirajuću klasifikaciju (CRF; Lafferty et al. (2001) i neodređenu segmentaciju riječi (NPYLM; Mochihashi et al. (2009)), s transparentnom razmjenom informacija između tih dva modelnih struktura u polu nadziranom okviru (JESS-CM; Suzuki i Isozaki (2008)). Potvrdili smo da može odgovarajući dijelovati neustandardne tekste poput one na Twitter i Weibo i da ima skoro stanje umjetnosti preciznosti na standardnim podacima na japanskom, kineskom i tajlandskom.", 'nl': "Deze paper presenteert een nieuw hybride generatief/discriminatief model van woordsegmentatie gebaseerd op niet-parametrische Bayesiaanse methoden. In tegenstelling tot gewone discriminerende woordsegmentatie die alleen gebaseerd is op gelabelde gegevens, maakt ons semi-supervised model ook gebruik van een enorme hoeveelheid niet-gelabelde tekst om automatisch nieuwe 'woorden' te leren, en beperkt deze verder door een gelabelde gegevens te gebruiken om niet-standaard teksten zoals die in sociale netwerkdiensten te segmenteren. Specifiek combineert ons hybride model een discriminatieve classificator (CRF; Lafferty et al. (2001) en onbeheerde woordsegmentatie (NPYLM; Mochihashi et al. (2009)), met een transparante uitwisseling van informatie tussen deze twee modelstructuren binnen het semi-supervised framework (JESS-CM; Suzuki en Isozaki (2008)). We hebben bevestigd dat het niet-standaard teksten zoals die in Twitter en Weibo geschikt kan segmenteren en bijna state-of-the-art nauwkeurigheid heeft op standaard datasets in het Japans, Chinees en Thais.", 'ko': "비변수 베일스 방법을 바탕으로 한 혼합 생성/판별 분사 모델을 제시했다.표기 데이터에만 의존하는 일반적인 구분적 단어와 달리 우리의 반감독모델은 대량의 표기되지 않은 텍스트를 이용하여 새로운'단어'를 자동으로 학습하고 표기 데이터를 사용하여 비표준적인 텍스트(예를 들어 소셜네트워크서비스의 텍스트)를 분할함으로써 그것들을 더욱 제한한다.구체적으로 말하자면 우리의 혼합모델은 판별분류기(CRF, Lafferty 등(2001)과 무감독분사(NPYLM, 모치하시 등(2009)와 반감독틀 안의 이 두 모델 구조 간의 투명한 정보 교환(JESS-CM, Suzuki와 Isozaki(2008)을 결합시켰다.트위터와 웨이보 등 비표준 텍스트를 적절하게 분할할 수 있고 일본어, 중국어, 태국어의 표준 데이터 집합에서 가장 선진적인 정확성을 지니고 있음을 확인했다.", 'sw': "Gazeti hili linaonyesha muundo wa kutengenezwa/ubaguzi wa maneno kwa kutumia mbinu zisizo za kibiashara za Bayesia. Tofauti na utofauti wa neno la kawaida ambalo linategemea tu kwa taarifa zilizowekwa, modeli yetu ya sekondari pia inatumia kiasi kikubwa cha maandishi yasiyopangwa kwa kujifunza kwa kujifunza 'maneno mpya' na pia inawazuia kwa kutumia taarifa zilizoonyesha ili kugawanya maandishi yasiyo ya kawaida kama vile zile zilizopatikana katika huduma za mitandao ya kijamii. Kwa ujumla, modeli yetu ya hybrid inaunganisha mchanganyiko wa tofauti (CRF; Differty et al. (2001) na mchanganyiko wa neno lisilo na uhakika (NPYLM; Mochihashi et al. (2009)), na kubadilishana kwa uwazi kati ya miundo mbili ya miundo mbili ndani ya mfumo ulioangaliwa na semi (JESS-CM; Suzuki na Isozaki (2008). Tulithibitisha kwamba inaweza kutengeneza maandishi yasiyo ya kawaida kama wale kwenye mtandao wa Twita na Weibo na ina karibu sahihi ya hali ya sanaa kuhusu seti za taarifa za kawaida nchini Japani, China na Thai.", 'fa': 'این کاغذ یک مدل ژنترافی/جدایی جدایی از جمع کردن کلمات بر اساس روش های غیر پارامتریک بیزیان را نشان می دهد. برخلاف جدا کردن کلمه\u200cهای معمولی که تنها بر داده\u200cهای برچسب بستگی دارد، مدل نیمه\u200cبرچسب ما همچنین یک مقدار بزرگی از متن نامزده\u200cای برای یادگرفتن کلمه\u200cهای جدید را به خودکار محدودیت می\u200cکند، و بیشتر آنها را با استفاده از داده\u200cهای برچسب برای جدا کردن متن\u200cهای غیراستاندارد مانند آن\u200cها که در خدمات شبکه\u200cهای اج مخصوصاً مدل هیبریدی ما یک کلاسیر جدایی (CRF; Lafferty et al. (۲۰۰۱) و جدایی کلمات غیرقابل تحویل (NPYLM; Mochihashi et al. (۲۰۰۹)، با یک تبادل مشاهده اطلاعات بین این دو ساختار مدل در چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچ ما تایید کردیم که می\u200cتواند متن\u200cهای غیر استاندارد را به طور مناسب جدا کند مانند آن\u200cها که توئیتر و ویبو هستند و تقریباً دقیقات هنری در مجموعه\u200cهای استاندارد در ژاپن، چینی و تایید دارد.', 'tr': 'Bu kagyz Beýeziýanyň döwletlerinde daýanýan hybrid jenerativ/diskriminçy söz segmentasyň nusgasyny görkezýär. Adatça diskriminçy söz segmentasiýasynda diňe etiket edilen maglumatlara güýçlän däldir, hem biziň semi-kontrol modelimiz täze sözleri otomatik bilen öwrenmek üçin ullanmaýan täze bir şekilde täsirleýär we olaryň etiket edilen maglumatlaryny sosyal netek hızmetinde tapylan metinleri bölmek üçin ýüzünde süýtgeder. Adatça, biziň hybrid modelimiz diskriminät klassifikatçisini (CRF; Lafferty et al. (2001) we suýruklanmaýan söz segmentasyny (NPYLM; Mochihashi et al. (2009)), bu iki nusga arasynda semi-kontrol edilen çerçewçiwde bir terjime edip bilen informasiýa çykýar (JESS-CM; Suzuki we Isozaki (2008)). Biz Twitter, Weibo ýaly standart metinleriniň dogry ýagdaýynda taýýarlap biler diýip kabul etdik we ol Japonça, Çin çe we Taýlандa standart veri setirleriniň dogrylygyny hasapladyk.', 'af': "Hierdie papier stel 'n roman hybrid genereerbare/diskriminasiewe model van woord segmentasie gebaseer op nie-parametriese Bayesian metodes. Ongelyks van gewone diskriminasiewe woord segmentasie wat slegs op etiketeerde data aflys, ons semi-ondersoekte model het ook 'n groot hoeveelheid ongeabelde teks aan automaties leer nuwe 'woorde', en verdere beperk hulle deur 'n etiketeerde data te gebruik na segmenteer nie-standaard teks soos wat in sosiale netwerking dienste gevind is. Spesifieke, ons hibrid model kombinieer 'n diskriminasiewe klassifiseerder (CRF; Lafferty et al. (2001) en ononderwerpende woord segmentasie (NPYLM; Mochihashi et al. (2009)), met 'n deursigtige vervang van inligting tussen hierdie twee model strukture binne die semi-onderwerp raamwerk (JESS-CM; Suzuki en Isozaki (2008)). Ons het bevestig dat dit behoorlik kan segment nie-standaard teks soos die in Twitter en Weibo en het byna staat-van-kuns-presies op standaard datastelle in Japanse, Sjinese en Thaise.", 'sq': "Ky dokument paraqet një model të ri hibridik gjenerativ/diskriminues të segmentimit të fjalëve bazuar në metodat jo parametrike Bayesian. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services.  Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki and Isozaki (2008)).  We confirmed that it can appropriately segment non-standard texts like those in Twitter and Weibo and has nearly state-of-the-art accuracy on standard datasets in Japanese, Chinese, and Thai.", 'az': 'Bu kağıt, parametrik Bayesiya metodlarına dayanan yeni hibrid generikatlı/diskriminatlı söz segmentasiyasının modelini göstərir. Yalnız etiketli məlumatlar üzərində təvəkkül edən sıradan diskriminativ söz segmentasiyası kimi, yarı-gözləyirli modellərimiz də yeni sözləri öyrənmək üçün çox böyük dəyişiklik məlumatları yaratdı və daha sonra etiketli məlumatları sosyal netverk servislərdə bulunan məlumatları segment etmək üçün dəyişiklik edir. Özellikle, hibrid modellərimiz yarı-gözləyirli çerçevesinin içində bu iki modellərin arasındakı məlumatları orta-gözləyir (JESS-CM; Suzuki və Isozaki (2008)) ilə birləşdirir. Biz təsdiqlədik ki, o, Twitter və Weibo kimi standart olmayan məktubları yaxşı bölüşdürə bilər və Yaponca, Çinlə və Tayla standart veri setlərinin dəqiqliyinə bənzəyir.', 'am': 'ይህም ፕሮግራም የባይስያ ሥርዓት ባይሄስቲ ባሕያዊ ሥርዓት ላይ የቃላት ግንኙነቶችን አቀረበ፡፡ በተለየ ጥያቄ ቃላት በጽሑፎች ላይ ብቻ የሚታመን እና በጽሑፍ ማቀናቀል፣ የsemi-ተጠባባቂው ሞዴሌዎቻችን ደግሞ አዲስ ቃልን ለራሱ ማምረጥ ትልቅ የጽሑፍ ክፍል ያሰጣቸዋል፡፡ በተለየ ጊዜ የኬብሪድ ሞዴል (CRF; Lafferty et al. (2001) እና ያልጠበቀ ቃላት segmentation (NPYLM; ሞኪሐሺ et al. (2009)) በተለየ በሁለት ሞዴል አካውንቶች መካከል የተለየ የእውይይይት መረጃዎችን (JESS-CM; ሱዙኪ እና ይስozaki (2008). በትዊተር እና Weibo ያሉትን የድምፅ ጽሑፎችን እንደሚያስፈልግ አረጋገጥን፤ በጃፓን፣ ቻይና እና ታይኛ የዳርቻ ጽሑፎች የደረጃ ግንኙነት አቅራቢያ አለበት፡፡', 'hy': "Այս հոդվածը ներկայացնում է բառերի սեգմետրացիայի նոր հիբրիդ սերնդի և խտրականության մոդել, որը հիմնված է ոչ պարամետրիկ բեյզիացի մեթոդների վրա: Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services.  Հիմաստաբար, մեր հիբրիդ մոդելը միավորում է խտրականության դասակարգում (ԿՌՖ, Լաֆերթի և այլն. (2001) և անվերահսկված բառերի սեգմետրացիա (ՆՊՅԼՄ, Մոչիհասի և այլն. (2009) այս երկու մոդելների կառուցվածքների միջև թափանցիկ տեղեկատվության փոխանակում կիսավերահսկված շրջանակում (Յեսս-ԿՄ, Սյուզուկի Մենք հաստատեցինք, որ այն կարող է պատասխանաբար բաժանել ոչ ստանդարտ տեքստերը, ինչպիսիք են Թվիթերի և Վայբոյի տեքստերը, և ունի գրեթե ամենաբարձր ճշգրտություն ստանդարտ տվյալների համակարգերի վրա ճապոներեն, չինարեն և թայլանդերեն:", 'ca': 'Aquest paper presenta un nou model hibridgenerador/discriminatiu de segmentació de paraules basat en mètodes baièsius no paramètrics. A diferència de la segmentació de paraules discriminatòries habitual que només es basa en dades etiquetades, el nostre model semisupervisat també aprofita una gran quantitat de text no etiquetat per aprendre automàticament noves "paraules", i altres les limita fent servir una data etiquetada per segmentar textos no estàndard com els que es troben en serveis de xarxa social. Concretament, el nostre model híbrid combina un classificador discriminatiu (CRF; Lafferty et al. (2001) i una segmentació de paraules no supervisada (NPYLM; Mochihashi et al. (2009)), amb un intercanvi transparent d\'informació entre aquestes dues estructures models dins l\'estructura semisupervisada (JESS-CM; Suzuki i Isozaki (2008)). Vam confirmar que pot segmentar adequadament textos no estàndard com els de Twitter i Weibo i que té gairebé la precisió més moderna en conjunts de dades estàndard en japonès, xinès i tailandes.', 'bn': "এই পত্রিকাটি প্যারামেট্রিক বেয়েসিয়ান পদ্ধতির উপর ভিত্তিক শব্দের বিভিন্ন ভিন্ন ভিন্ন ভিত্তিক ভিত্তিক শব্দের বৈষম্ Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services.  বিশেষ করে, আমাদের হাইব্রিড মডেল একটি বৈষম্যিক শ্রেণীবিভাগের (সিএসএফ; ল্যাফার্টি আর আল. (২০০১) এবং অরক্ষণশীল শব্দ বিভাগ (NPYLM; মোচিহি et al. (২০০৯)) স্বচ্ছতাভাবে এই দুই মডেল কাঠামোর মধ্যে স্বচ্ছতা বিনিময়ে ত আমরা নিশ্চিত করেছি যে এটি টুইটার এবং উইবোতে যেমন স্ট্যান্ডার্ড না লেখাগুলো বিভক্ত করতে পারে এবং জাপানি, চীন এবং থাই-এর স্ট্যান্ডার্ডার ডাটাসেটগ", 'fi': 'Tässä työssä esitellään uusi hybridi generatiivinen/diskriminatiivinen sanasegmentoinnin malli, joka perustuu ei-parametrisiin bayesilaisiin menetelmiin. Toisin kuin tavallinen syrjivä sanasegmentointi, joka perustuu vain merkittyyn dataan, puolivalvottu mallimme hyödyntää myös valtavia määriä merkitsemätöntä tekstiä oppiakseen automaattisesti uusia sanoja ja rajoittaa niitä entisestään käyttämällä merkittyä dataa segmentoidakseen epästandardeja tekstejä, kuten sosiaalisen median palveluissa. Hybridimallissamme yhdistyvät erityisesti syrjivä luokittelija (CRF; Lafferty et al. (2001) ja valvomaton sanasegmentointi (NPYLM; Mochihashi et al. (2009)), ja näiden kahden mallirakenteen välinen läpinäkyvä tietojenvaihto puolivalvotussa kehyksessä (JESS-CM; Suzuki ja Isozaki (2008)). Vahvistimme, että se pystyy asianmukaisesti segmentoimaan epätavanomaisia tekstejä, kuten Twitterissä ja Weibossa, ja sillä on lähes uusinta tarkkuutta japanin, kiinan ja thain kielissä.', 'cs': 'Tento článek představuje nový hybridní generativní/diskriminační model segmentace slov založený na neparametrických Bayesovských metodách. Na rozdíl od běžné diskriminační segmentace slov, která se opírá pouze o označená data, náš model s polovým dohledem také využívá obrovské množství neoznačeného textu k automatickému učení se nových "slov", a dále je omezuje použitím označených dat k segmentování nestandardních textů, jako jsou ty, které se nacházejí ve službách sociálních sítí. Konkrétně, náš hybridní model kombinuje diskriminační klasifikátor (CRF; Lafferty et al. (2001) a bez dozoru segmentaci slov (NPYLM; Mochihashi et al. (2009)), s transparentní výměnou informací mezi těmito dvěma modelovými strukturami v rámci semi-supervised frameworku (JESS-CM; Suzuki a Isozaki (2008)). Potvrdili jsme, že může vhodně segmentovat nestandardní texty, jako jsou například na Twitteru a Weibo a má téměř nejmodernější přesnost na standardních datových sadách v japonštině, čínštině a thajsku.', 'et': 'Käesolev töö tutvustab uudset hübriidgeneratiivset/diskrimineerivat sõna segmenteerimise mudelit, mis põhineb mitteparameetrilistel bayesia meetoditel. Erinevalt tavalisest diskrimineerivast sõnasegmenteerimisest, mis põhineb ainult märgistatud andmetel, kasutab meie pooljärelevalve all olev mudel ka tohutut hulka märgistamata teksti, et automaatselt õppida uusi sõnu, ning piirab neid veelgi, kasutades märgistatud andmeid mittestandardsete tekstide segmenteerimiseks, nagu sotsiaalvõrgustike teenustes leitavad tekstid. Täpsemalt ühendab meie hübriidmudel diskrimineeriva klassifitseerija (CRF; Lafferty jt. (2001) ja järelevalveta sõnasegmenteerimise (NPYLM; Mochihashi jt. (2009)), läbipaistva teabevahetusega nende kahe mudeli struktuuri vahel pooljärelevalve raames (JESS-CM; Suzuki ja Isozaki (2008)). Me kinnitasime, et see suudab asjakohaselt segmenteerida mittestandardseid tekste, nagu Twitteris ja Weibos, ning on peaaegu tipptasemel täpsusel jaapani, hiina ja tai keeles.', 'bs': "Ovaj papir predstavlja nov hibridni generativni/diskriminacijski model segmentacije riječi na temelju neparametričkih Bayesijskih metoda. Za razliku od obične diskriminacijske segmentacije riječi koja se oslanja samo na etiketirane podatke, naš polu nadzorni model također utječe na ogromne količine nenabeliranog teksta kako bi automatski naučio nove 'riječi', a dalje ih ograničava koristeći etiketirane podatke na segmentiranje neustandardnih tekstova kao što su pronađeni u službama socijalnih mreža. Posebno, naš hibridni model kombinira diskriminativnu klasifikaciju (CRF; Lafferty et al. (2001) i neodređenu segmentaciju riječi (NPYLM; Mochihashi et al. (2009)), sa transparentnom razmjenom informacija između tih dva modelnih struktura u polu nadzornom okviru (JESS-CM; Suzuki i Isozaki (2008)). Potvrdili smo da može odgovarajući segmentirati ne standardne tekste poput one na Twitter i Weibo i da ima skoro stanje umjetnosti preciznosti na standardnim podacima na japanskom, kineskom i tajlandskom.", 'he': "העבודה הזו מציגה מודל חדש גידול היברידי/דיסקרטיבי של סגמנציה מילים מבוסס על שיטות בייזיות לא פרמטריות. בניגוד למחלקת מילים מיוחדת רגילה שמבוססת רק על נתונים מסומנים, המודל שלנו חצי-שולט גם משתמש בכמות עצומות של טקסט לא מסומן כדי ללמוד אוטומטית 'מילים' חדשות, ומגבלת אותם יותר על ידי השימוש של נתונים מסומנים כדי לחלק טקסטים לא סטנדרטיים כמו אלה שנמצאים בשירותים רשת חבר Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki and Isozaki (2008)).  אישרנו שהוא יכול לחלק בהתאם טקסטים לא סטנדרטיים כמו אלה בטוויטר וייבו ויש לו כמעט מדויק חדש במידע בסטנדרטי נתונים ביפני, סיני וטאיילנדי.", 'sk': 'V prispevku je predstavljen nov hibridni generativni/diskriminativni model segmentacije besed, ki temelji na neparametričnih bajezijskih metodah. Za razliko od običajne diskriminacijske segmentacije besed, ki temelji samo na označenih podatkih, naš pol nadzorovan model uporablja tudi ogromne količine neoznačenega besedila za samodejno učenje novih besed in jih še dodatno omejuje z uporabo označenih podatkov za segmentiranje nestandardnih besedil, kot so besedila, ki jih najdemo v storitvah socialnih omrežij. Natančneje, naš hibridni model združuje diskriminativni klasifikator (CRF; Lafferty et al. (2001) in nenadzorovano segmentacijo besed (NPYLM; Mochihashi et al. (2009)), s pregledno izmenjavo informacij med tema dvema strukturama modela znotraj polnadzorovanega okvira (JESS-CM; Suzuki in Isozaki (2008)). Potrdili smo, da lahko ustrezno segmentira nestandardna besedila, kot sta tista v Twitterju in Weibu, ter ima skoraj najsodobnejšo točnost standardnih naborov podatkov v japonščini, kitajščini in tajščini.', 'ha': "Wannan takardan na ƙunsa da wani hoton Hybri mai gabatar da/mai yin ɓarna na maganar segmentation a kan non-parametric Bayesian hanyoyi. Di daidaita da rabon maganar da aka inganci na ɗabi'a, yana dõgara kawai kan data na tsari, misalinmu wanda aka yi tsaron da shi na ƙara yana da yawan abu mai girma wa matsayin da ba'anar shi ba dõmin ya sanar da yanzu na yanzu-yanzu, kuma yana ƙudura su da amfani da data na rubutu zuwa raba matsayin na'ura, kamar waɗanda aka samu a cikin tsarin mitandanin jamii. Aka ƙayyade, misalinmu ya koma koma da wani mai rarrabo (CRF; Laffty et al. (2001) da kuma an tsare maganar segmentation (NPYLM; Mokishi et al. (2009)), da an buɗe bayani da bayani da cire-daban laban misalin biyu cikin firam wanda aka yi shekara (JESS-CM; Suzuki da Iszoaki (2006). Mun gaskata cẽwa, za ta raba matsayin waɗanda ba'a daidaita ba kamar waɗanda ke cikin Twitter da Weibo kuma yana da nesten taƙalumi na-sanar a kan daidaita matsayin taƙaita cikin japanen, China da Tai.", 'jv': 'This paper represents a new HyBridge Generative/Diskimiative model of word segmentation supported on nonparametris bayesi method. Genjer-genjer diunting langgar sampeyan kuwi wis dipun ciptaaken sing wis etiket data, kita model sing wis nguasai nyimpen a langgar sampeyan nganggo dolanan sing gak bener Awak dhéwé, pilihan model nyebutaké kelompok kelompok dislikasi (CF; Laffty et al.(2011) lan segmentation awak dhéwé Awak dhéwé wis ngênggunaké karo akeh basa sing gak bener tentang karo Google lan weibo lan saiki karo hal-hal layang-layang sampek awak dhéwé kuwi awak dhéwé kuwi basa sing japané, Cino lan Yulan.', 'bo': "This paper presents a novel hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki and Isozaki (2008)). ངེད་གཉིས་ཀྱིས་ཌིས་ཌིར་དང་ཝེ་པོ་ནང་གི་ཡིག"}
{'en': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'ar': 'النمذجة المشتركة للموضوعات والاقتباسات والسلطة الموضوعية في الهيئة الأكاديمية', 'pt': 'Modelagem Conjunta de Tópicos, Citações e Autoridade Tópica em Corpora Acadêmicos', 'fr': "Modélisation conjointe des sujets, des citations et de l'autorité thématique dans les corpus académiques", 'ja': '学術団体におけるトピック、引用、およびトピック権限の共同モデリング', 'es': 'Modelado conjunto de temas, citas y autoridad de actualidad en los cuerpos académicos', 'zh': '学术语料库主题、引文及主题威权合建模', 'hi': 'अकादमिक निगम में विषयों, उद्धरणों और सामयिक प्राधिकरण के संयुक्त मॉडलिंग', 'ru': 'Совместное моделирование тем, цитирований и тематических полномочий в академических корпусах', 'ga': 'Samhaltú Comhpháirteach ar Ábhair, Lua, agus Údarás Tráthúil sa Chorparáid Acadúil', 'ka': 'აკადემიკური კოპორაში საერთო მოდელირება', 'el': 'Κοινή μοντελοποίηση θεμάτων, αναφορών και επίκαιρης εξουσίας στο Ακαδημαϊκό Σώμα', 'hu': 'Témák, idézetek és aktuális hatóság közös modellezése az Akadémiai Corporában', 'kk': 'Академиялық корпорадағы нақыштар, сайттар және нақышты органдарды біріктіру', 'mk': 'Заедничко моделирање на теми, цитати и тематска власт во академската корпора', 'it': 'Modellazione congiunta di argomenti, citazioni e autorità topica nel Corpo Accademico', 'lt': 'Bendras temų, citacijų ir akademinės korporos teminės institucijos modeliavimas', 'ml': 'പ്രമേയങ്ങളുടെയും സിറ്റേഷനുകളുടെയും സഹപ്രവര്\u200dത്തനങ്ങളുടെയും ആകാഡിമിക്ക് കോര്\u200dപ്പോരായിട്ടുള്ള സാധാരണ', 'ms': 'Modeling Perkongsian Topik, Citasi, dan Autoritas Topik di Academic Corpora', 'mt': 'Mudellar Konġunt ta’ Temi, Ċitazzjonijiet, u Awtorità Topika fil-Korpora Akkademika', 'mn': 'Академик Корпора дахь Судалгааны загварын загвар, хот, Topical Authority', 'no': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'pl': 'Wspólne modelowanie tematów, cytatów i autorytetu tematycznego w Korpusie Akademickim', 'ro': 'Modelarea comună a subiectelor, citațiilor și autorității tematice în Corpora Academică', 'sr': 'Zbog zajedničkog modela tema, gradova i Topičkog autoriteta u akademijskoj korpori', 'si': 'මුද්\u200dරව්\u200dය, නගරය, සහ විශේෂ ප්\u200dරධාන නියෝජිතය අධිකාරිත්වය අධිකාරිත්වය', 'sv': 'Gemensam modellering av ämnen, citat och aktuell auktoritet i Academic Corpora', 'so': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'ta': 'கலைஞர் கோர்போராவில் உள்ள பொருள்கள், சுழற்சி மற்றும் பொருள் அதிகாரம்', 'ur': 'علمی کورپور میں موضوع، شہروں اور موضوعات کی مدل کرنا', 'uz': 'Name', 'vi': 'Chế độ đồng bộ các chủ đề, Citions, and Topical Authority in Academic Corpus', 'hr': 'Zajednička modela teme, gradova i Topičnog tijela u akademijskoj korpori', 'da': 'Fælles modellering af emner, citater og aktuel autoritet i Academic Corpora', 'bg': 'Съвместно моделиране на теми, цитати и тематичен авторитет в академичния корпор', 'nl': 'Gezamenlijke Modellering van Topics, Citaties en Topical Authority in Academic Corpora', 'ko': '학술 자료 라이브러리에서 주제, 인용과 주제 권위의 연합 모델링', 'id': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'fa': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'de': 'Gemeinsame Modellierung von Themen, Zitaten und Topical Authority im akademischen Korpora', 'tr': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'sq': 'Modelimi i Përbashkët i Topikave, Qyteteve dhe Autoritetit Topikal në Korpora Akademike', 'af': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'am': 'አካዳሚክ ኮሮፓ ውስጥ የጦማሪያዎች፣ Citations እና Topical Authority', 'hy': 'Ակադեմիական Կորպորայի թեմաների, քաղաքների և թեմային իշխանության միասին մոդելավորումը', 'az': 'Akademik Korporasında Topic, Citations və Topic Authority', 'bn': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora', 'bs': 'Zajednička modela teme, gradova i Topične uprave u akademijskoj korpori', 'ca': 'Modell Conjunt de Tàpics, Citacions i Autoritat Tàpica a la Corpora Acadèmica', 'et': 'Teemade, tsitaatide ja teemalise autoriteedi ühine modelleerimine akadeemilises korpuses', 'fi': 'Aiheiden, sitaatioiden ja aihepiirin yhteinen mallinnus akateemisessa korpusessa', 'sw': 'Mpango wa pamoja wa mada, Citizens, na mamlaka ya Serikali ya Akademicha', 'cs': 'Společné modelování témat, citací a aktuální autority v akademickém korpusu', 'jv': 'Joint model ing of Subjects, Sitations, and Temcal Body in acamera', 'ha': '@ action: button', 'sk': 'Skupno modeliranje teme, citacij in tematske avtoritete v akademskem korpusu', 'he': 'מודלינג משותף של נושאים, ציטוטים, וסמכות נושאית בקורפורה אקדמית', 'bo': 'Joint Modeling of Topics, Citations, and Topical Authority in Academic Corpora'}
{'en': 'Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult. We often rely on metrics of scholarly authority to find the prominent authors but these authority indices do not differentiate authority based on research topics. We present Latent Topical-Authority Indexing (LTAI) for jointly modeling the topics, citations, and topical authority in a corpus of academic papers. Compared to previous models, LTAI differs in two main aspects. First, it explicitly models the generative process of the citations, rather than treating the citations as given. Second, it models each author’s influence on citations of a paper based on the topics of the cited papers, as well as the citing papers. We fit LTAI into four academic corpora : CORA, Arxiv Physics, PNAS, and Citeseer. We compare the performance of LTAI against various baselines, starting with the latent Dirichlet allocation, to the more advanced models including author-link topic model and dynamic author citation topic model. The results show that LTAI achieves improved accuracy over other similar models when predicting words, citations and authors of publications.', 'es': 'Gran parte del progreso científico proviene de hallazgos publicados anteriormente, pero es difícil buscar en el vasto mar de publicaciones científicas. A menudo nos basamos en métricas de autoridad académica para encontrar a los autores destacados, pero estos índices de autoridad no diferencian la autoridad en función de los temas de investigación. Presentamos la Indexación de Autoridad Tópica Latente (LTAI) para modelar conjuntamente los temas, las citas y la autoridad temática en un corpus de artículos académicos. En comparación con los modelos anteriores, el LTAI difiere en dos aspectos principales. En primer lugar, modela explícitamente el proceso generativo de las citas, en lugar de tratarlas como dadas. En segundo lugar, modela la influencia de cada autor en las citas de un artículo basándose en los temas de los artículos citados, así como en los artículos en los que se cita. Encajamos LTAI en cuatro cuerpos académicos: CORA, Arxiv Physics, PNAS y Citeseer. Comparamos el rendimiento de LTAI con varias líneas de base, comenzando con la asignación latente de Dirichlet, con los modelos más avanzados, incluido el modelo de tema de enlace de autor y el modelo dinámico de temas de citas de autores. Los resultados muestran que la LTAI mejora la precisión con respecto a otros modelos similares al predecir palabras, citas y autores de publicaciones.', 'fr': "La plupart des progrès scientifiques découlent de résultats publiés antérieurement, mais il est difficile de faire des recherches parmi la vaste gamme de publications scientifiques. Nous nous appuyons souvent sur des mesures de l'autorité scientifique pour trouver les auteurs les plus importants, mais ces indices d'autorité ne différencient pas l'autorité en fonction des sujets de recherche. Nous présentons Latent Topical-Authority Indexing (LTAI) pour modéliser conjointement les sujets, les citations et l'autorité thématique dans un corpus d'articles universitaires. Par rapport aux modèles précédents, le LTAI se distingue par deux aspects principaux. Tout d'abord, il modélise explicitement le processus de génération des citations, plutôt que de traiter les citations telles qu'elles sont données. Ensuite, il modélise l'influence de chaque auteur sur les citations d'un article en se basant sur les sujets des articles cités, ainsi que sur les articles de citation. Nous avons intégré le LTAI dans quatre corpus académiques\xa0: CORA, Arxiv Physics, PNAS et Citeseer. Nous comparons les performances de LTAI par rapport à diverses lignes de base, en commençant par l'allocation de Dirichlet latente, aux modèles plus avancés, y compris le modèle de sujet de lien auteur et le modèle de sujet de citation d'auteur dynamique. Les résultats montrent que LTAI améliore la précision par rapport à d'autres modèles similaires lors de la prédiction des mots, des citations et des auteurs de publications.", 'pt': 'Grande parte do progresso científico decorre de descobertas publicadas anteriormente, mas pesquisar no vasto mar de publicações científicas é difícil. Muitas vezes confiamos em métricas de autoridade acadêmica para encontrar os autores proeminentes, mas esses índices de autoridade não diferenciam a autoridade com base nos tópicos de pesquisa. Apresentamos a Latent Topical-Authority Indexing (LTAI) para modelar conjuntamente os tópicos, citações e autoridade tópica em um corpus de artigos acadêmicos. Comparado aos modelos anteriores, o LTAI difere em dois aspectos principais. Primeiro, modela explicitamente o processo generativo das citações, em vez de tratar as citações como dadas. Em segundo lugar, modela a influência de cada autor nas citações de um artigo com base nos tópicos dos artigos citados, bem como nos artigos que citam. Encaixamos o LTAI em quatro corpora acadêmicos: CORA, Arxiv Physics, PNAS e Citeseer. Comparamos o desempenho do LTAI em relação a várias linhas de base, começando com a alocação de Dirichlet latente, aos modelos mais avançados, incluindo modelo de tópico de link de autor e modelo de tópico de citação de autor dinâmico. Os resultados mostram que o LTAI alcança maior precisão em relação a outros modelos semelhantes ao prever palavras, citações e autores de publicações.', 'ar': 'ينبع قدر كبير من التقدم العلمي من النتائج المنشورة سابقًا ، لكن البحث عبر البحر الشاسع من المنشورات العلمية أمر صعب. غالبًا ما نعتمد على مقاييس السلطة العلمية للعثور على المؤلفين البارزين ولكن مؤشرات السلطة هذه لا تفرق بين السلطة بناءً على موضوعات البحث. نقدم فهرسة السلطة الموضوعية الكامنة (LTAI) للنمذجة المشتركة للموضوعات والاستشهادات والسلطة الموضعية في مجموعة من الأوراق الأكاديمية. مقارنة بالنماذج السابقة ، يختلف LTAI في جانبين رئيسيين. أولاً ، يقوم بشكل صريح بنمذجة العملية التوليدية للاستشهادات ، بدلاً من التعامل مع الاقتباسات على أنها معطاة. ثانيًا ، يصوغ تأثير كل مؤلف على الاقتباسات من الورقة بناءً على موضوعات الأوراق التي تم الاستشهاد بها ، فضلاً عن الأوراق المقتبس منها. نلائم LTAI في أربع مجموعات أكاديمية: CORA و Arxiv Physics و PNAS و Citeseer. نحن نقارن أداء LTAI بمختلف خطوط الأساس ، بدءًا من تخصيص Dirichlet الكامن ، بالنماذج الأكثر تقدمًا بما في ذلك نموذج موضوع ارتباط المؤلف ونموذج موضوع الاقتباس الديناميكي للمؤلف. تظهر النتائج أن LTAI تحقق دقة محسنة مقارنة بالنماذج المماثلة الأخرى عند التنبؤ بالكلمات والاقتباسات ومؤلفي المنشورات.', 'zh': '大抵科学进步源于前发,而搜索瀚科学出版物为难。 常因学术权威之指标以求英俊,而威权指数,不以论主分威。 臣等建言潜在主题威权索引(LTAI),施于学术论文语料库共建模主题,引和主题威权。 比之前型号,LTAI异于二端。 先之,明拟引文成,不以引文为给定也。 其次,据所引论文主题及引用论文,每作者建模之。 分LTAI为四学语料库:CORA,Arxiv Physics,PNASCiteseer。 夫以LTAI之性,比于百基线,始于潜狄利克雷,至于更上,链接题动者引之。 结果表明占出版物之单词,引与作者,LTAI高于他准确性。', 'ja': '科学の進歩の多くは以前に発表された知見に起因するが、科学出版物の広大な海を探索することは困難である。 著名な著者を見つけるために、私たちはしばしば学術的権威の指標に依存しますが、これらの権威指標は研究トピックに基づいて権威を区別するものではありません。 私たちは、学術論文のコーパスでトピック、引用、およびトピックの権威を共同でモデリングするための潜在的なトピック-権威インデックス（ LTAI ）を提示します。 以前のモデルと比較して、LTAIは主に2つの側面で異なります。 まず、引用を与えられたものとして扱うのではなく、引用の生成プロセスを明示的にモデル化する。 第二に、引用論文と引用論文のトピックに基づいて、論文の引用に対する各著者の影響をモデル化する。 LTAIは、CORA、Arxiv Physics、PNAS、Citeseerの4つの学術団体に適合しています。 LTAIのパフォーマンスを、潜在的なDirichlet割り当てから始まるさまざまなベースラインと、著者リンクトピックモデルおよび動的著者引用トピックモデルを含むより高度なモデルと比較します。 結果は、LTAIが、出版物の単語、引用、および著者を予測する際に、他の同様のモデルよりも改善された精度を達成することを示している。', 'hi': 'अधिकांश वैज्ञानिक प्रगति पहले प्रकाशित निष्कर्षों से उपजी है, लेकिन वैज्ञानिक प्रकाशनों के विशाल समुद्र के माध्यम से खोज करना मुश्किल है। हम अक्सर प्रमुख लेखकों को खोजने के लिए विद्वानों के अधिकार के मैट्रिक्स पर भरोसा करते हैं लेकिन ये प्राधिकरण सूचकांक अनुसंधान विषयों के आधार पर प्राधिकरण में अंतर नहीं करते हैं। हम अकादमिक पत्रों के एक कॉर्पस में विषयों, उद्धरणों और सामयिक प्राधिकरण को संयुक्त रूप से मॉडलिंग करने के लिए अव्यक्त सामयिक-प्राधिकरण अनुक्रमण (एलटीएआई) प्रस्तुत करते हैं। पिछले मॉडलों की तुलना में, LTAI दो मुख्य पहलुओं में भिन्न है। सबसे पहले, यह स्पष्ट रूप से उद्धरणों की उत्पादक प्रक्रिया को मॉडल करता है, बजाय दिए गए उद्धरणों का इलाज करने के। दूसरा, यह उद्धृत पत्रों के विषयों के आधार पर एक पेपर के उद्धरणों पर प्रत्येक लेखक के प्रभाव को मॉडल करता है, साथ ही साथ उद्धृत कागजात भी। हम एलटीएआई को चार अकादमिक निगमों में फिट करते हैं: कोरा, आरएक्सआईवी भौतिकी, पीएनएएस, और सीट्सियर। हम विभिन्न आधार रेखाओं के खिलाफ LTAI के प्रदर्शन की तुलना करते हैं, अव्यक्त Dirichlet आवंटन के साथ शुरू करते हैं, लेखक-लिंक विषय मॉडल और गतिशील लेखक उद्धरण विषय मॉडल सहित अधिक उन्नत मॉडल के लिए। परिणामों से पता चलता है कि LTAI अन्य समान मॉडलों पर बेहतर सटीकता प्राप्त करता है जब शब्दों, उद्धरणों और प्रकाशनों के लेखकों की भविष्यवाणी करता है।', 'ru': 'Значительная часть научного прогресса основывается на ранее опубликованных результатах, но поиск информации в обширном море научных публикаций затруднен. Мы часто полагаемся на метрики научного авторитета, чтобы найти известных авторов, но эти индексы авторитета не дифференцируют авторитет на основе тем исследований. Мы представляем латентное тематическое индексирование (LTAI) для совместного моделирования тем, цитирований и тематического авторитета в корпусе научных работ. По сравнению с предыдущими моделями, LTAI отличается двумя основными аспектами. Во-первых, он явно моделирует генеративный процесс цитирования, а не рассматривает цитирование как приведенное. Во-вторых, он моделирует влияние каждого автора на цитаты из работы на основе тем цитируемых документов, а также цитирующих документов. Мы вписываем LTAI в четыре академических корпуса: CORA, Arxiv Physics, PNAS и Citeseer. Мы сравниваем эффективность LTAI с различными базовыми линиями, начиная с латентного распределения Дирихле, с более продвинутыми моделями, включая тематическую модель авторской связи и динамическую тематическую модель цитирования авторов. Результаты показывают, что LTAI достигает большей точности по сравнению с другими аналогичными моделями при прогнозировании слов, цитат и авторов публикаций.', 'ga': 'Eascraíonn go leor den dul chun cinn eolaíoch as torthaí a foilsíodh roimhe seo, ach tá sé deacair cuardach a dhéanamh tríd an bhfarraige ollmhór d’fhoilseacháin eolaíocha. Braithimid go minic ar mhéadracht údaráis léannta chun na húdair fheiceálach a aimsiú ach ní dhéanann na hinnéacsanna údaráis seo idirdhealú idir údaráis bunaithe ar thopaicí taighde. Cuirimid Innéacsú na nÚdarás Tráthúil Folaigh (LTAI) i láthair chun na topaicí, na luanna agus an t-údarás tráthúla a chomhmhúnlú i gcorpas páipéir acadúla. I gcomparáid le samhlacha roimhe seo, tá difríocht idir LTAI i dhá phríomhghné. Ar an gcéad dul síos, múnlaíonn sé go sainráite próiseas giniúna na lua, seachas déileáil leis na comhlua mar a thugtar. Sa dara háit, múnlaíonn sé tionchar gach údair ar lua páipéir bunaithe ar thopaicí na bpáipéar a luadh, chomh maith leis na páipéir lua. Cuirimid LTAI i gceithre chorpas acadúla: CORA, Arxiv Physics, PNAS, agus Citeseer. Déanaimid comparáid idir feidhmíocht LTAI agus bonnlínte éagsúla, ag tosú leis an leithdháileadh folaigh Dirichlet, leis na samhlacha níos forbartha lena n-áirítear samhail topaice naisc údair agus múnla dinimiciúil topaice lua na n-údar. Léiríonn na torthaí go mbaineann LTAI cruinneas feabhsaithe amach i gcomparáid le samhlacha eile dá samhail agus é ag tuar focail, luanna agus údair foilseachán.', 'el': 'Μεγάλο μέρος της επιστημονικής προόδου προέρχεται από προηγούμενα δημοσιευμένα ευρήματα, αλλά η αναζήτηση μέσα από την απέραντη θάλασσα των επιστημονικών εκδόσεων είναι δύσκολη. Συχνά βασιζόμαστε σε μετρήσεις επιστημονικής εξουσίας για να βρούμε τους εξέχοντες συγγραφείς, αλλά αυτοί οι δείκτες εξουσίας δεν διαφοροποιούν την εξουσία βάσει ερευνητικών θεμάτων. Παρουσιάζουμε το επίκαιρο ευρετήριο επίκαιρων αρχών (για την από κοινού μοντελοποίηση των θεμάτων, των παραπομπών και της επίκαιρης εξουσίας σε ένα σώμα ακαδημαϊκών εργασιών. Σε σύγκριση με τα προηγούμενα μοντέλα, η LTAI διαφέρει σε δύο κύριες πτυχές. Πρώτον, μοντελοποιεί ρητά την παραγωγική διαδικασία των παραπομπών, αντί να αντιμετωπίζει τις παραπομπές ως δεδομένες. Δεύτερον, μοντελοποιεί την επιρροή κάθε συγγραφέα στις παραπομπές μιας εργασίας με βάση τα θέματα των αναφερθέντων άρθρων, καθώς και των αναφερθέντων άρθρων. Χωρίζουμε το LTAI σε τέσσερα ακαδημαϊκά σώματα: CORA, Arxiv Physics, PNAS και Citeseer. Συγκρίνουμε την απόδοση της σε σχέση με διάφορες γραμμές βάσης, ξεκινώντας από την λανθάνουσα κατανομή με τα πιο προηγμένα μοντέλα, συμπεριλαμβανομένου του μοντέλου θέματος συγγραφέα-σύνδεσης και του δυναμικού μοντέλου αναφορών συγγραφέα. Τα αποτελέσματα δείχνουν ότι η LTAI επιτυγχάνει βελτιωμένη ακρίβεια σε σχέση με άλλα παρόμοια μοντέλα κατά την πρόβλεψη λέξεων, παραπομπών και συγγραφέων δημοσιεύσεων.', 'hu': 'A tudományos fejlődés nagy része korábban publikált eredményekből származik, de a tudományos publikációk hatalmas tengerének átkutatása nehéz. A kiemelkedő szerzők megtalálásához gyakran a tudományos hatósági mutatókra támaszkodunk, de ezek a hatósági mutatók kutatási témák alapján nem különböztetik meg a hatóságot. A Latent Topical-Authority Indexing (LTAI) a témák, idézetek és aktuális hatóságok közös modellezéséhez egy tudományos cikkekben bemutatjuk. A korábbi modellekhez képest az LTAI két fő szempontból különbözik. Először is kifejezetten modellezi az idézések generációs folyamatát, ahelyett, hogy az idézéseket megadott módon kezelné. Másodszor az idézett cikkek témái, valamint az idézett cikkek témái alapján modellezi az egyes szerzők hatását egy cikk idézésére. Az LTAI-t négy tudományos kormányba illesztjük: CORA, Arxiv Physics, PNAS és Citeseer. Összehasonlítjuk az LTAI teljesítményét különböző alapvonalakkal, kezdve a látens Dirichlet allokációval, a fejlettebb modellekkel, beleértve a szerző-link téma modellt és a dinamikus szerzői idézési téma modellt. Az eredmények azt mutatják, hogy az LTAI nagyobb pontosságot ér el más hasonló modellekhez képest a szavak, idézetek és publikációk szerzőinek előrejelzése során.', 'ka': 'ძალიან მეცნიერო პროგრესი იქნება პირველი პროგრესიდან გამოვიყენება, მაგრამ მეცნიერო პუბლუზაციების ძალიან ძალიან რთული იქნება. ჩვენ უფრო მეტრიკის მეტრიკით ვიყენებთ სწავლობული ავტორიების ძალიან მნიშვნელოვანი, მაგრამ ეს ავტორიის ინდექციები არ განსხვავებენ ავტორიების განსხვავება, რომელიც ჩვენ შემდეგ ტეომიკური ორექტიკური ინდექსირება (LTAI) ჩვენ ახალგაზრდებით აკადემიკური დომენტების კოპოსში საერთოდ მოდელირებისთვის თემენტების, სიტაციების და ტეომიკ პირველი მოდელთან შედგენა, LTAI ორი მნიშვნელოვანი არსებობს. პირველად, ის განსაკუთრებულად მოდელურია სიტაციების გენერაციური პროცესი, არც სიტაციების გასაკეთება. მეორე, ეს მოდელურებს ყოველ ავტორის შესახებ კაცატურის სიტაციაზე, რომელიც განსახებულებული კაცატურების თემაზე, რომელიც სიტატირებული კაცატურების შესახებ. ჩვენ LTAI-ს ოთხი აკადემიკური კოპორაში დავყენებთ: CORA, აპქსიგური ფიზიკა, ზუსტად და სიტესერი. ჩვენ LTAI-ის გამოყენებას განსხვავებული ფესტლინის შემდეგ შემდგენებთ, რომელიც დავიწყებთ ლეტენტი დირიქლეტის განსაზღვრებით, უფრო განსაზღვრებული მოდელთან, რომელიც ავტორის შემდ წარმოდგენები ჩვენებს, რომ LTAI უფრო უფრო მსგავსი წარმოდგენა სხვა მსგავსი მოდელზე, როდესაც წარმოდგენა სიტყვები, სიტყვები და პუბუკუტებ', 'it': "Gran parte del progresso scientifico deriva da risultati precedentemente pubblicati, ma cercare attraverso il vasto mare di pubblicazioni scientifiche è difficile. Spesso ci affidiamo a metriche di autorità accademica per trovare gli autori di spicco, ma questi indici di autorità non differenziano l'autorità in base agli argomenti di ricerca. Presentiamo Latent Topical-Authority Indexing (LTAI) per modellare congiuntamente gli argomenti, le citazioni e l'autorità topica in un corpus di articoli accademici. Rispetto ai modelli precedenti, le LTAI differiscono per due aspetti principali. In primo luogo, esso modella esplicitamente il processo generativo delle citazioni, piuttosto che trattare le citazioni come date. In secondo luogo, modella l'influenza di ogni autore sulle citazioni di un articolo in base agli argomenti degli articoli citati, così come i documenti citanti. Abbiamo inserito LTAI in quattro corpora accademici: CORA, Arxiv Physics, PNAS e Citeseer. Confrontiamo le prestazioni delle LTAI con varie linee di base, a partire dall'allocazione latente di Dirichlet, con i modelli più avanzati tra cui il modello di argomento autore-link e il modello dinamico di argomento citazione dell'autore. I risultati mostrano che LTAI raggiunge una maggiore precisione rispetto ad altri modelli simili quando predicono parole, citazioni e autori di pubblicazioni.", 'lt': 'Daug mokslo pažangos daroma remiantis anksčiau paskelbtomis išvadomis, tačiau labai sunku ieškoti mokslinių leidinių. Dažnai pasikliaujame mokslinės valdžios metrijomis, kad rastume pažangius autorius, tačiau šie valdžios indeksai nediferencijuoja valdžios, grindžiamos mokslinių tyrimų temomis. Mes pristatome Latent Topical Authority Indexing (LTAI), skirtas bendram temų, citacijų ir aktualios valdžios modeliavimui akademiniuose dokumentuose. Palyginti su ankstesniais modeliais, LTAI skiriasi dviem pagrindiniais aspektais. Pirma, jame aiškiai modeliuojamas citacijų generacinis procesas, o ne minėtų citacijų nagrinėjimas. Antra, ji modeliuoja kiekvieno autoriaus įtaką cituojant dokumentą, pagrįstą minėtų dokumentų temomis, taip pat cituojančius dokumentus. Mes sutampame su LTAI į keturias akademines korporas: CORA, Arxiv Physics, PNAS ir Citeseer. Palyginame LTAI veiklos rezultatus su įvairiomis bazinėmis linijomis, pradedant nuo latentinio Dirichlet paskirstymo, su pažangiausiais modeliais, įskaitant autorių ir autorių ryšio temos model į ir dinamišką autorių citacijos temos modelį. Rezultatai rodo, kad LTAI, prognozuodama žodžius, citatus ir leidinių autorius, siekia geresnio tikslumo nei kiti panašūs modeliai.', 'kk': 'Алдыңғы шығарылған тапсырмалардан бірнеше ғылым жағдайдың көп жағдайды, бірақ ғылым шығарулардың көп жағдайды іздеу қиын. Біз көпшілікті авторларды табу үшін білім авторлардың метрикасына сенеміз, бірақ бұл авторлардың индекстері зерттеу нақыштарына негізделген авторларды түрлендірмейді. Академиялық қағаздардың корпусында тақырыптарды, тақырыптарды және нақышты аутентификацияларды біріктіру үшін Кейінгі Topical-Authority индекстеу (LTAI) дегенді таңдаймыз. Алдыңғы үлгілеріне салыстырылған, LTAI екі негізгі аспектерде айырмайды. Біріншіден, ол таңдау процесін түсінікті түсінікті, таңдау процесін келтірілген емес. Екіншіден, ол әрбір автордың қағаздардың тақырыптарына негізделген қағаздардың әсерін, сондай-ақ қағаздардың тақырыптарына негізделген. Біз LTAI-ді төрт академиялық корпораға келтіреміз: CORA, Арксив физика, қолдану және Ситезер. Біз LTAI-ның әртүрлі негізгі сызықтарымен салыстырып, келесі дириклеттің бөлімінен басталып, автор-сілтеме нақыштың моделі және динамикалық автор тақырыбы үлгісін бастап, көтерілген моделдер Нәтижелер LTAI сөздерді, жазуларды басқа ұқсас үлгілерден жақсы түсіндіреді дегенді көрсетеді.', 'mk': 'Голем дел од научниот напредок доаѓа од претходно објавени откритија, но пребарувањето низ огромното море на научни објавувања е тешко. Често се потпираме на метрика на научна власт за да ги најдеме истакнатите автори, но овие индекси на власт не ги разликуваат авторитетите базирани на истражувачките теми. Ние го претставуваме Индексирањето на Latent Topical-Authority (LTAI) за заедничко моделирање на темите, цитатите и точниот авторитет во корпус академски весници. Compared to previous models, LTAI differs in two main aspects.  Прво, тој експлицитно го моделира генеративниот процес на цитатите, наместо да ги третира цитатите како што се дадени. Второ, тоа го моделира влијанието на секој автор на цитатите на весникот базиран на темите на цитираните весници, како и на цитираните весници. Го вклопуваме ЛТАИ во четири академски корпора: Кора, Арксив Физика, ПНАС и Ситисер. Ги споредуваме изведувањата на ЛТАИ со различните бази, почнувајќи со лантната aloкација на Диричлет, со понапредните модели, вклучувајќи го и моделот на темата автор-врска и динамичниот модел на темата на цитата на авторот. Резултатите покажуваат дека ЛТАИ постигнува подобра прецизност во однос на други слични модели кога предвидува зборови, цитати и автори на публикациите.', 'ml': 'മുമ്പ് പ്രസിദ്ധീകരിക്കപ്പെട്ട കണ്ടെത്തികളില്\u200d നിന്നും ഒരുപാട് ശാസ്ത്രിക പ്രവർത്തനങ്ങളുടെ പുരോഗങ്ങള്\u200d മുന്\u200dപ്  പ്രധാനപ്പെട്ട എഴുത്തുകാരെ കണ്ടെത്താന്\u200d വിദ്യാര്\u200dത്ഥിക്കുന്ന അധികാരികളുടെ മെറ്ററികളെ ഞങ്ങള്\u200d ആശ്രയിക്കുന്നു. പക ലാറ്റിന്റെ ടോപ്പിക്കല്\u200d അധികാരികതയുടെ സൂക്ഷിക്കുന്നതിനായി (LTAI) കൂട്ടിയിടുന്നു കാര്യങ്ങളുടെയും പ്രമേയങ്ങളുടെയും പ്രധാനപത് മുമ്പുള്ള മോഡലുകളോട് തുല്യമാക്കി, LTAI രണ്ടു പ്രധാന ഭാഗങ്ങളില്\u200d വ്യത്യസ്തമാണ്. ആദ്യം, അത് പ്രത്യക്ഷമായി പ്രക്രിയയുടെ ജനററിവ് പ്രക്രിയയെ മാതൃകയാക്കുന്നു. കൊടുത്തതിനെക്കാള്\u200d പ്രസ്താവ രണ്ടാമത്തെ പേപ്പറുകളുടെ പേപ്പറുകളില്\u200d അടിസ്ഥാനമായി ഒരു പേപ്പറിന്\u200dറെ പ്രഭാവങ്ങളുടെ പ്രഭാവനത്തിന്\u200dറെ പ്രഭാവങ്ങള്\u200dക്കും അത് മോഡല ഞങ്ങള്\u200d നാലു അക്കാഡിമിക്ക് കോര്\u200dപ്പോരിയിലേക്ക് എല്\u200dടായിയിലേക്ക് പോകുന്നു നമ്മള്\u200d എല്\u200dടായിയുടെ പ്രകടനം വ്യത്യസ്തമായ ബെസ്ലൈനുകള്\u200dക്കെതിരായി തുടങ്ങുന്നു, അടുത്ത ദൈരിഷ്ലേറ്റ് അംഗീകരിക്കുന്നതിനെക്കുറിച്ച്, മുന്\u200dഗണന അതിന്റെ ഫലം കാണിക്കുന്നു LTAI മറ്റു പ്രസംഗികങ്ങളെക്കുറിച്ചുള്ള മാതൃകങ്ങളെക്കാളും മെച്ചപ്പെടുത്തിയിരി', 'no': 'Mange vitenskapelige framdrift stemmer frå førre utgjevnader, men søk gjennom den vaste sjøen av vitenskapelige publikasjonar er vanskeleg. Vi har ofte forstått på metrikar med forståande autoritet for å finna dei viktige autoritetene, men desse autoritetsindikatorene forstår ikkje autoriteten basert på forskningsemner. Vi presenterer det siste toppen-autoritet indeksering (LTAI) for å kopla modellera emne, citasjonar og emniske autoritet i ein korpus av akademiske papir. Sammenlignet med førre modeller er LTAI ulike i to hovudaspekt. Først modeller den genererige prosessen av sitasjonane, i staden for å behandla sitasjonane som gitt. Andre, det modeller effekten av kvar forfattar på sitasjonar av papir basert på emnene av dei siterte papiret, og på siteringspapiret. Vi passar LTAI inn i fire akademiske korpora: CORA, arkivfisk, gamma og Citeseer. Vi sammenliknar utviklinga av LTAI mot ulike baselinjer, som startar med den latente tilfellinga av Dirichlet, med dei fleire avanserte modelane, inkludert utviklaren-lenkjemodellen for emne og dynamiske utviklaremodellen for utviklaren. Resultatet viser at LTAI oppnår forbetra nøyaktighet over andre liknande modeller når du foregår ord, sitasjonar og utviklarar av publikasjonar.', 'mn': 'Ихэнх шинжлэх ухааны прогресс өмнө хэвлэгдсэн олон зүйлээс гарч ирсэн. Гэхдээ шинжлэх ухааны хэвлэлүүдийн ихэнх далайн хайх нь хэцүү. Бид ихэвчлэн хамгийн чухал зохиолчдыг олох мэргэжлийн эрх мэдлийн метрик дээр итгэдэг. Гэхдээ эдгээр эрх мэдлийн индексүүд судалгааны сэдвээр үндсэн эрх мэдлийг өөрчлөхгүй. Бид Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн Сүүлийн С Өмнөх загвартай харьцуулахад LTAI хоёр чухал асуудалд ялгаатай. Эхлээд, энэ нь тайлбарлах үйл явцыг тодорхой загвар өгсөн байдлыг харуулахын оронд загвар өгдөг. Хоёрт, энэ нь зохиолчдын нөлөөлөлийг бичсэн сонины сэдэв, иргэн сэтгүүлийн сэдэв дээр суурилсан цаасан дээр бичсэн. Бид ЛТАЙ-г 4 академикийн корпоратын хувьд зохион байгуулдаг: CORA, Арксив Физик, Цитесер. Бид LTAI-ын үйл ажиллагааг олон суурь шулуунуудын эсрэг харьцуулж, дараагийн Дириклетийн хуваалцлагаас эхлээд илүү хөгжиж буй загваруудыг харьцуулж, зохиолч-холбоотой сэдвийн загвар болон динамикийн зохиолын Үүний үр дүнд ЛТАЙ хэвлэлийн үг, зохиолууд болон хэвлэлийн зохиолчдыг таамаглах үед өөр төстэй загваруудын зөв байдлыг илүү сайжруулж чадна гэдгийг харуулдаг.', 'pl': 'Duża część postępu naukowego wynika z wcześniej opublikowanych odkryć, ale poszukiwanie ogromnego morza publikacji naukowych jest trudne. Często opieramy się na wskaźnikach autorytetu naukowego, aby znaleźć wybitnych autorów, ale te wskaźniki autorytetów nie różnią autorytetu w oparciu o tematy badawcze. Prezentujemy Latent Topical-Authority Indexing (LTAI) do wspólnego modelowania tematów, cytatów i autorytetu aktualnego w korpusie prac akademickich. W porównaniu z poprzednimi modelami LTAI różni się w dwóch głównych aspektach. Po pierwsze, wyraźnie modeluje proces generacyjny cytatów, zamiast traktować cytaty jako dane. Po drugie, modeluje wpływ każdego autora na cytowania artykułu w oparciu o tematy cytowanych artykułów, a także cytowanych artykułów. LTAI umieszczamy w czterech korporach akademickich: CORA, Arxiv Physics, PNAS i Citeseer. Porównujemy wydajność LTAI na tle różnych linii bazowych, począwszy od utajonej alokacji Dirichleta, do bardziej zaawansowanych modeli, w tym model tematu autor-link i dynamiczny model cytowania autora. Wyniki pokazują, że LTAI osiąga lepszą dokładność w porównaniu z innymi podobnymi modelami przy przewidywaniu słów, cytatów i autorów publikacji.', 'ro': 'O mare parte a progresului științific provine din descoperirile publicate anterior, dar căutarea prin marea vastă de publicații științifice este dificilă. De multe ori ne bazăm pe măsurători de autoritate științifică pentru a găsi autorii proeminenți, dar acești indici de autoritate nu diferențiază autoritatea în funcție de subiecte de cercetare. Vă prezentăm Latent Topical-Authority Indexing (LTAI) pentru modelarea în comun a subiectelor, citațiilor și autorităților de actualitate într-un corpus de lucrări academice. Comparativ cu modelele anterioare, LTAI diferă în două aspecte principale. În primul rând, modelează în mod explicit procesul generativ al citațiilor, mai degrabă decât tratarea citațiilor așa cum sunt date. În al doilea rând, modelează influența fiecărui autor asupra citațiilor unei lucrări pe baza subiectelor lucrărilor citate, precum și a lucrărilor citate. Încadram LTAI în patru corpore academice: CORA, Arxiv Physics, PNAS și Citeseer. Comparăm performanța LTAI cu diferite linii de referință, începând cu alocarea latentă a Dirichlet, cu modelele mai avansate, inclusiv modelul subiectului autor-link și modelul dinamic al subiectului citat de autor. Rezultatele arată că LTAI obține o precizie îmbunătățită față de alte modele similare atunci când predicționează cuvinte, citații și autori de publicații.', 'sr': 'Mnogi naučni napredak dolazi iz prethodnih objavljenih nalaza, ali pretraživanje kroz ogromno more naučnih publikacija je teško. Često se oslanjamo na metriku naučnog autoriteta da nađemo poznate autore, ali ovi autoritetski indiciri ne razlikuju autoritet na temi istraživanja. Predstavljamo poslednji indeksiranje Topičnog autoriteta (LTAI) za zajednički modeliranje teme, citacija i temeljnog autoriteta u korpusu akademijskih papira. U usporedbi sa prethodnim modelima, LTAI se razlikuje u dva glavna aspekta. Prvo, to objašnjava generativni proces citacija, umjesto tretiranja citacija. Drugo, to modelira uticaj svakog autora na citacije papira bazirane na temama navedenih papira, kao i građanskih papira. Stavljamo LTAI u četiri akademijske korporacije: CORA, arxiv fizika, bande i Citeseer. Uspoređujemo učinkovitost LTAI-a sa različitim osnovnim linijama, počevši sa latentnim dodavanjem Dirichleta, sa naprednijim modelima uključujući model tema autora-povezanog i dinamički model tema za ciljanje autora. Rezultati pokazuju da LTAI postiže poboljšanu tačnost preko drugih sličnih modela kada predviđaju reči, citacije i autore publikacija.', 'ms': "Banyak kemajuan saintifik berasal dari penemuan yang telah diterbitkan sebelumnya, tetapi mencari melalui laut luas penerbitan saintifik adalah sukar. We often rely on metrics of scholarly authority to find the prominent authors but these authority indices do not differentiate authority based on research topics.  Kami memperkenalkan Indeks Topikal-Authority Latent (LTAI) untuk mengubah secara bersama topik, citasi, dan kuasa topik dalam satu korpus kertas akademik. Berbanding dengan model terdahulu, LTAI berbeza dalam dua aspek utama. Pertama, ia secara eksplicit model proses generatif citasi, daripada memperlakukan citasi seperti yang diberikan. Second, it models each author's influence on citations of a paper based on the topics of the cited papers, as well as the citing papers.  Kami muatkan LTAI ke dalam empat korpora akademik: CORA, Arxiv Physics, PNAS, dan Citeseer. Kami membandingkan prestasi LTAI dengan berbagai garis dasar, bermula dengan alokasi Dirichlet yang tersembunyi, dengan model yang lebih maju termasuk model topik pautan-penulis dan model topik citasi penulis dinamik. Hasilnya menunjukkan bahawa LTAI mencapai ketepatan yang lebih baik daripada model lain yang sama bila meramalkan perkataan, citasi dan penulis penerbitan.", 'si': 'ගොඩක් විද්\u200dයාන්තික ප්\u200dරධානයක් පස්සේ ප්\u200dරකාශ කරලා තියෙන්නේ පස්සේ සොයාගන්න, ඒත් විද්\u200dයාත්මක ප්\u200dරකා අපි සාමාන්\u200dය විදියටම ප්\u200dරධාන ලේඛකයන්ව හොයාගන්න පුළුවන් විදියට ප්\u200dරධාන විදියට විශ්වාස කරනවා නමුත් මේ අධ අපි ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක් සං මුලින් මෝඩේල් එක්ක සම්බන්ධ වුනා, LTAI ප්\u200dරධාන ප්\u200dරතිදේශ දෙකක් වෙනස් වෙනවා. මුලින්ම, ඒක පැහැදිළිවිදිහට ප්\u200dරවේශයෙන් ප්\u200dරවේශනය කරනවා නිර්මාණයේ ප්\u200dරවේශනය, දෙන්න පුළුවන් වි දෙවෙනි විදියට, ඒක හැම ලේඛකයෙක්ම ප්\u200dරශ්නයක්ම පිළිබඳ විදිහට පත්තු වලින් ප්\u200dරශ්නයක් විදිහට පත්තු විදිහට ප අපි LTAI එක්ක අධ්\u200dයාත්මක කාර්පෝරා හතරයි: CORA, ආර්ක්සිව් භෞතික, සහ සිටිසේර්. අපි LTAI විවිධ ප්\u200dරමාණය සමඟ විවිධ ප්\u200dරමාණය සඳහා ප්\u200dරමාණය කරනවා, ලටින් ඩිරිච්ලෙට් විශේෂය සඳහා පටන් ගන්නවා, ලේඛකය-ලික්කු  ප්\u200dරතිචාරය පෙන්වන්නේ LTAI විශ්වාස කරන්නේ අනිත් වගේ මොඩේල් වලට වචන, නිර්දේශනය සහ ප්\u200dරකාශනයේ ලේඛකය සඳහා ව', 'sv': 'Mycket av de vetenskapliga framstegen härrör från tidigare publicerade fynd, men det är svårt att söka igenom det stora havet av vetenskapliga publikationer. Vi förlitar oss ofta på mätvärden för vetenskaplig auktoritet för att hitta framstående författare, men dessa auktoritetsindex skiljer inte auktoritet utifrån forskningsämnen. Vi presenterar Latent Topical-Authority Indexing (LTAI) för att gemensamt modellera ämnen, citeringar och aktuell auktoritet i en korpus av akademiska artiklar. Jämfört med tidigare modeller skiljer sig LTAI i två huvudaspekter. För det första modellerar den uttryckligen den generativa processen av citeringarna, snarare än att behandla citeringarna som givna. För det andra modellerar den varje författares inflytande på citeringar av en uppsats baserat på ämnena i de citerade artiklarna, liksom de citerande artiklarna. Vi passar in LTAI i fyra akademiska korpora: CORA, Arxiv Physics, PNAS och Citeseer. Vi jämför LTAI:s prestanda mot olika baslinjer, med början den latenta Dirichlet-allokeringen, med de mer avancerade modellerna inklusive författarlänkmodell och dynamisk författarciteringsämnesmodell. Resultaten visar att LTAI uppnår bättre noggrannhet jämfört med andra liknande modeller när man förutsäger ord, citeringar och författare till publikationer.', 'ta': 'Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult.  நாங்கள் பெரும்பாலான ஆசிரியர்களை கண்டுபிடிக்க வேண்டிய முறையில் நம்புகிறோம் ஆனால் இந்த அரசு சுட்டுக்குறிகள் ஆய்வ நாம் சமீபத்திய பொருள் அரசு சுட்டுவரிசையை காண்பிக்கிறோம் கலாசிரியல் காக்கியங்களின் தலைப்புகள், மற்றும் தலைப்புக்கான அதிகாரம். முந்தைய மாதிரிகளை ஒப்பிடு, LTAI இரண்டு முக்கிய பகுதிகளில் மாறுபடுகிறது. முதலில், அது கொடுக்கப்பட்ட குறிப்புகளை சிகிச்சைக்கு பதிலாக பொதுவான செயலை மாதிரியும். இரண்டாவது, அது ஒவ்வொரு ஆசிரியருக்கும் பாதிப்பை மாதிரியிடுகிறது குறிப்பிட்ட காகிதத்தின் தலைப்புகளை அடிப்படையில் ஒரு தாளின்  நாங்கள் நான்கு கல்வி நிறுவனத்திற்கு LTAI பொருத்துகிறோம்: CORA, ஆர்க்சிவ் திருவியல், பிஎனாஸ், மற்றும் சிட்டிஸ் ப நாம் LTAI செயல்பாட்டை பல அடிப்படைக்கோடுகளுக்கு எதிராக ஒப்பிடுகிறோம், சமீபத்தில் Dirichlet ஒதுக்கு ஆரம்பி @ info', 'mt': 'Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult.  Ħafna drabi nistrieħu fuq il-metriċi tal-awtorità xjentifika biex isibu l-awturi prominenti iżda dawn l-indiċijiet tal-awtorità ma jiddifferenzjawx l-awtorità bbażata fuq suġġetti ta’ riċerka. Aħna nippreżentaw l-Indiċjar Latent Topical-Authority (LTAI) għall-immudellar konġunt tas-suġġetti, iċ-ċitazzjonijiet, u l-awtorità topika f’korpus ta’ dokumenti akkademiċi. Meta mqabbel ma’ mudelli preċedenti, l-LTAI jvarja f’żewġ aspetti ewlenin. L-ewwel nett, huwa jimmudella espliċitament il-proċess ġenerattiv taċ-ċitazzjonijiet, minflok jittratta ċ-ċitazzjonijiet kif mogħti. It-tieni nett, hija timmudella l-influwenza ta’ kull awtur fuq iċ-ċitazzjonijiet ta’ dokument ibbażat fuq is-suġġetti tad-dokumenti ċitati, kif ukoll id-dokumenti ċitati. Aħna nqabdu l-LTAI f’erba’ korpi akkademiċi: CORA, Arxiv Physics, PNAS, u Citeseer. Aħna nqabblu l-prestazzjoni tal-LTAI ma’ diversi linji bażi, li jibdew bl-allokazzjoni latenti tad-Dirichlet, mal-mudelli aktar avvanzati inkluż mudell ta’ suġġett ta’ kollegament bejn l-awtur u mudell dinamiku ta’ suġġett ta’ ċitazzjoni tal-awtur. Ir-riżultati juru li l-LTAI tikseb preċiżjoni mtejba fuq mudelli simili oħra meta tipprevedi kliem, ċitazzjonijiet u awturi tal-pubblikazzjonijiet.', 'so': "Waxyaabo badan oo cilmiga la'aanta ah waxay ka timaadaan helayaal horay loo soo daabacay, laakiin raadinta badda sayniska badan waa adag tahay. Mararka badan waxaynu ku kalsoonnahay saraakiisha waxbarashada si aan u helno qoraalka maamulka ah, laakiin xilliyadaasu ma kala duwanyaan saraakiisha ku saabsan maadooyinka waxbarashada. Waxaannu u soo bandhignaynaa waxyaabaha la wada sameynayo macluumaadka, wadamada iyo saraakiisha madaxda u dhexeeya ee warqadaha akademiga. Isbarbardhig tusaalooyinkii hore, LTAI wuxuu ku kala duwan yahay laba dhinac oo muhiim ah. Marka ugu horeysa waxay si cad u sameynaysaa baaritaanka generashada ee ay ka dhaqdhaqaaqi lahaayeen in ay ka baaraandegiso warqadaha lagu soo qoray. Second, waxay sameynaysaa saamaynta qof kasta oo qoraal ah oo ku saleysan warqadaha warqadaha la qoray iyo warqadaha la qoray. Waxaynu LTAI ku habboonaynaa afar shirkad ee akademi ah: CORA, Arxiv fizikisi, PNAS iyo Citeseer. Waxaynu isbarbardhignaa muuqashada LTAI oo ka gees ah saldhigyo kala duduwan, marka aan bilaabanno qaybinta ugu dambeeyay Dirichlet, tusaalaha hore oo ka horeeya, kuwaas oo ah muusikada saqafka qoraalka la xiriira iyo sameynta muusikada macluumaadka qoraalka. Abaalku waxay muuqataa in LTAI uu kordhiyo saxda la kordhiyey tusaalooyin kale oo la mid ah marka la sii sheegayo hadal, warqado iyo qoraal baaritaanka.", 'ur': 'بہت سی سائنس پیشرفت پہلے پیدا کیے گئے ہیں، لیکن سائنس جماعتوں کی وسیع سمندر میں جہاد کرنے کا مشکل ہے. ہم اغلب علم اختیار کے متریک پر اعتماد کرتے ہیں کہ بہترین لکھنے والوں کو پیدا کریں لیکن یہ اختیار نشانیاں تحقیق موضوع پر بغیر اختلاف نہیں کرتے۔ ہم نے اچھی موضوع، شہروں اور موضوع کی مدد کرنے کے لئے اچھی موضوعات کے ذریعہ (LTAI) موضوعات، شہروں اور موضوعات کی مدد کرنے کے لئے پیش کیا ہے۔ پہلے کی مدلکوں کے مقابلہ میں LTAI دو اصلی الگوں میں مختلف ہے۔ پہلے، یہ صریح طور پر مثالیں دیے جاتے ہیں، جہاد کی پیدائش کے پیدائش کے بغیر. دوسرا، یہ ہر لکھنے والے کی تاثیر کاغذ کے مقامات پر، اور کاغذ کے مقامات پر بنیاد رکھتا ہے. ہم LTAI کو چار علمی کمپور میں ملتے ہیں: CORA, Arxiv Physics, اور Citeseer. ہم LTAI کی عملکرد مختلف بنسس لینوں کے ساتھ مقایسہ کرتے ہیں، لٹینٹ ڈریچلٹ کے تقسیم سے شروع کرتے ہیں، اس سے زیادہ پیشرفت کی مدلکوں کے ساتھ لکھنے والے-لینک ٹوپ موڈل اور دینامیک لکھنے والے ٹوپ موڈل کے ساتھ۔ نتیجے دکھاتے ہیں کہ LTAI ایک دوسرے جیسا موڈل پر مزید دقیق پہنچاتا ہے جب کلمات، سائٹیوں اور لیکوں کی پیش بینی کرتا ہے۔', 'uz': "Ko'pchilik ilmiy taʼminlovchilar oldin tashkilotlar topildi, lekin ilmiy publiciyatlarning ko'plab o'zgartirish juda qiyin. Biz ko'pincha katta mualliflarni topish uchun o'quvchilarga ishlatamiz, lekin bu ҳукумат ҳукумат ҳукуматlarni taʼminlovchi mavzularga o'zgarishmaydi. Biz aqlli muammolar, taʼminot va madaniyalar va madaniyalarni birlashtirishga (LTAI) muhit qilamiz. Oldingi modellarga kamaytirish, LTAI ikki asosiy paytlarda ajratilgan. Birinchi so'zda, bu davlatlarning generativ jarayonini ko'rsatish mumkin. Ikkinchi so'zda, bu har bir mualliflar qogʻozning ma'lumotga asosida qogʻoz ma'lumotiga va qogʻoz qoʻllanmalarning natijasini o'zgartiradi. We fit LTAI into four academic corpora: CORA, Arxiv Physics, PNAS, and Citeseer.  Biz LTAI bajarishni boshqa bir xil asboblar bilan kamaytamiz, yangi dirichlet qaytarish bilan boshlanamiz, ko'proq yordamchi modellarga, muallifi bogʻ'langan mavzu modeli va dynamik mualliflar uchun mavzu modeli. @ info: status", 'vi': 'Phần lớn tiến bộ khoa học bắt nguồn từ những nghiên cứu đã được công bố trước đây, nhưng tìm kiếm trong một biển lớn của các nghiên cứu khoa học rất khó khăn. Chúng tôi thường dựa vào các âm tiết học thuật để tìm ra các tác giả xuất sắc, nhưng các chỉ số của chính quyền không phân biệt quyền dựa trên các chủ đề nghiên cứu. Chúng tôi xin giới thiệu Latent Topical-Authority IndXing (LAI) cho việc hợp tác mô hình các chủ đề, citation, và khắp nơi trong một tập hợp các bài báo cao cấp. So với các mô hình trước, LAI khác biệt trong hai khía cạnh chính. Thứ nhất, nó mô tả rõ ràng tiến trình tạo hóa các ghi chú, thay vì xem các ghi chú như đã đưa ra. Thứ hai, nó mô tả ảnh hưởng của mỗi tác giả tới các trích dẫn của một bài báo dựa trên các chủ đề của các bài báo được liệt kê, cũng như các bài báo trích dẫn. Chúng tôi nhét LAI vào bốn tập đoàn chuyên nghiệp: COA, Arxiv physics, PNAS, và Citeseer. Chúng tôi so sánh các hiệu quả của LAI với nhiều bản nền khác nhau, bắt đầu với số tài khoản Dirichhlet tiềm ẩn, với các mô hình nâng cao, bao gồm mô hình chủ đề liên kết tác giả và mô hình đề văn bản chứa động. Kết quả cho thấy LAI có độ chính xác cao hơn các mô hình tương tự khác khi dự đoán từ ngữ, ghi chú và tác giả của các tạp chí khác.', 'da': 'Meget af de videnskabelige fremskridt stammer fra tidligere offentliggjorte resultater, men det er vanskeligt at søge gennem det store hav af videnskabelige publikationer. Vi er ofte afhængige af målinger af videnskabelig autoritet for at finde fremtrædende forfattere, men disse autoritetsindeks differentierer ikke autoritet baseret på forskningsemner. Vi præsenterer Latent Topical-Authority Indexing (LTAI) til fælles modellering af emner, citater og aktuel autoritet i et korpus af akademiske papirer. Sammenlignet med tidligere modeller adskiller LTAI sig i to hovedaspekter. For det første modellerer den eksplicit den generative proces af citaterne, snarere end at behandle citaterne som givet. For det andet modellerer den hver forfatters indflydelse på citater af et papir baseret på emnerne i de citerede papirer, såvel som citerende papirer. Vi integrerer LTAI i fire akademiske korpora: CORA, Arxiv Physics, PNAS og Citeseer. Vi sammenligner ydeevnen af LTAI med forskellige basislinjer, startende med den latente Dirichlet allokering, med de mere avancerede modeller, herunder forfatter-link emne model og dynamisk forfatter citering emne model. Resultaterne viser, at LTAI opnår bedre nøjagtighed i forhold til andre lignende modeller, når de forudsiger ord, citater og forfattere af publikationer.', 'bg': 'Голяма част от научния прогрес произтича от публикувани преди това открития, но търсенето през огромното море от научни публикации е трудно. Често разчитаме на показатели на научната власт, за да открием видните автори, но тези индекси на авторитета не разграничават авторитета въз основа на изследователски теми. Представяме латентно тематично-авторитетно индексиране за съвместно моделиране на темите, цитатите и актуалната авторитетност в корпус от академични статии. В сравнение с предишните модели се различава в два основни аспекта. Първо, той изрично моделира генеративния процес на цитатите, вместо да третира цитатите като дадени. Второ, тя моделира влиянието на всеки автор върху цитираните статии въз основа на темите на цитираните статии, както и цитиращите статии. Ние вписваме LTAI в четири академични корпора: CORA, Arxiv Physics, PNAS и Citeseer. Сравняваме ефективността на ЛТАй спрямо различни базови линии, като се започне с латентното разпределение на Диришлет, с по-напредналите модели, включително модела на тема с линк автор и динамичен модел на тема за цитиране на автор. Резултатите показват, че постига подобрена точност в сравнение с други подобни модели при предсказване на думи, цитати и автори на публикации.', 'hr': 'Mnogi znanstveni napredak dolazi iz ranije objavljenih nalaza, ali je teško tražiti kroz ogromno more znanstvenih publikacija. Često se oslanjamo na metriku naučnog autoriteta da pronađemo poznatih autora, ali ovi autoritetski indiciri ne razlikuju autoritet na temelju istraživanja. Predstavljamo posljednji indeks Topičnog tijela (LTAI) za zajedno modeliranje teme, citacija i temeljnog autoriteta u korpusu akademijskih papira. U usporedbi s prethodnim modelima, LTAI se razlikuje u dva glavna aspekta. Prvo, to objašnjava generični proces citacija, umjesto liječenja citacijama. Drugo, to modelira utjecaj svakog autora na citacije papira na temelju navedenih novina, kao i na građanske papire. Stavljamo LTAI u četiri akademijska tijela: CORA, arxiv fizika, mješavine i Citeseer. Uspoređujemo učinkovitost LTAI-a s različitim osnovnim linijama, počevši s latentnim sadržavanjem Dirichleta, s naprednijim modelima uključujući model teme autora-povezanog i dinamički model teme za ciljanje autora. Rezultati pokazuju da LTAI postigne poboljšanu preciznost nad drugim sličnim modelima kada predviđaju riječi, citacije i autore publikacija.', 'nl': "Veel wetenschappelijke vooruitgang komt voort uit eerder gepubliceerde bevindingen, maar zoeken door de enorme zee van wetenschappelijke publicaties is moeilijk. We vertrouwen vaak op statistieken van wetenschappelijke autoriteit om de prominente auteurs te vinden, maar deze autoriteit indices onderscheiden autoriteit niet op basis van onderzoeksonderwerpen. We presenteren Latent Topical-Authority Indexing (LTAI) voor het gezamenlijk modelleren van de onderwerpen, citaties en actuele autoriteit in een corpus van academische papers. In vergelijking met eerdere modellen verschilt LTAI in twee hoofdaspecten. Ten eerste modelleert het expliciet het generatieve proces van de citaties, in plaats van de citaties als gegeven te behandelen. Ten tweede modelleert het de invloed van elke auteur op citaties van een artikel op basis van de onderwerpen van de geciteerde artikelen, evenals de citerende artikelen. We passen LTAI in vier academische corpora's: CORA, Arxiv Physics, PNAS en Citeseer. We vergelijken de prestaties van LTAI tegen verschillende baselines, te beginnen met de latente Dirichlet-toewijzing, tot de meer geavanceerde modellen, waaronder author-link topic model en dynamisch author citation topic model. De resultaten tonen aan dat LTAI betere nauwkeurigheid bereikt ten opzichte van andere vergelijkbare modellen bij het voorspellen van woorden, citaten en auteurs van publicaties.", 'ko': '많은 과학 진보는 이전에 발표된 발견에서 비롯되었지만, 광대한 과학 출판물의 바다에서 수색하는 것은 어렵다.우리는 보통 학술적 권위의 지표에 의존하여 걸출한 작가를 찾지만, 이러한 권위 지수는 연구 주제에 따라 권위를 구분할 수 없다.우리는 모델링 학술논문 어료고의 주제, 인용, 주제 권위를 결합하는 데 사용할 잠재적 주제 권위 색인(LTAI)을 제시했다.이전 모델과 비교하면 LTAI는 두 가지 주요 측면에서 다르다.우선 인용문의 생성 과정을 명확하게 모의한 것이지 주어진 방식에 따라 인용문을 처리하는 것이 아니다.그 다음에 인용된 논문의 주제와 인용 논문에 따라 각 작가가 논문 인용에 미친 영향을 모델링한다.LTAI는 CORA, Arxiv Physics, PNAS, Citeser 등 네 개의 학술 자료 라이브러리로 나눌 것입니다.다양한 베이스라인 아래에서의 LTAI의 성능을 비교한 결과, 잠재적인 Dirichlet 할당부터 저자 링크 주제 모델과 동적 저자 참조 주제 모델을 포함한 고급 모델까지 다양합니다.그 결과 LTAI는 다른 유사 모델에 비해 단어와 인용문, 출판물 작성자를 예측할 때 더 높은 정확성을 얻었다.', 'fa': 'بسیاری از پیشرفت علمی از پیدا کردن پیش منتشر شده است، ولی جستجوی در دریای بزرگ منتشر علمی سخت است. ما اغلب بر متریک قدرت دانشمندی اعتماد می کنیم تا نویسندگان بزرگ را پیدا کنیم ولی این نشانه های قدرت بر اساس موضوع تحقیقات تفاوت نمی کنند. ما اخیراً برای مدل\u200cسازی موضوع، شهرات و حکومت موضوع در یک مجموعه کاغذ\u200cهای دانشمند نشان می\u200cدهیم. در مقایسه با مدل قبلی، LTAI در دو مرحله اصلی تفاوت می\u200cکند. اول، آن به طور واضح فرآیند ژنترافی شهرها را مدل می کند، به جای رفتار شهرها به عنوان داده شده. دوم، این تأثیر هر نویسنده را بر روی شهرات کاغذ بر اساس موضوع کاغذ\u200cها و کاغذ\u200cهای شهروندی مدل می\u200cکند. ما LTAI را به چهار شرکت دانشگاهی پیدا کردیم: CORA, Arxiv Physics, and Citeseer. ما عملکرد LTAI را با خطوط پایه\u200cهای مختلف مقایسه می\u200cکنیم، شروع به تقسیم دیریکلت latent، با مدل\u200cهای پیشرفته\u200cتری که شامل مدل موضوع نویسنده\u200cها و مدل نویسنده\u200cهای دینامیک ارتباط می\u200cکنند. نتیجه\u200cها نشان می\u200cدهند که LTAI دقیقات بیشتری بر روی مدل\u200cهای مشابهی در پیش\u200cبینی کلمات، شهرت\u200cها و نویسندگان منتشر می\u200cشود.', 'sw': 'Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult.  Mara nyingi tunategemea mbinu za mamlaka za kisomi kutafuta waandishi maarufu lakini mashitaka haya ya mamlaka hayatofautishi mamlaka kwa sababu ya mada za utafiti. Tunawasilisha Uhindi wa Mamlaka ya Kusini ya hivi karibuni (LTAI) kwa kuunda mada, maelezo na mamlaka ya mada katika makaratasi ya kitaaluma. Kulinganishwa na mifano ya zamani, LTAI inatofautiana katika vipande viwili vikuu. Kwanza, inaonyesha wazi mchakato mkuu wa madai hayo, badala ya kudhibiti madai kama ilivyopewa. Pili, inaonyesha ushawishi wa kila mwandishi katika maelezo ya karatasi yenye msingi wa mada za makaratasi yaliyotajwa, pamoja na makaratasi yanayotajwa. Tunaweza kuingia LTAI kwenye makampuni wanne ya kitaaluma: CORA, Arxiv Physics, PNAS, na Citeseer. Tunawalinganisha utendaji wa LTAI dhidi ya misingi mbalimbali, kuanzia na utekelezaji wa hivi karibuni wa Dirichlet, kwa mifano bora zaidi ikiwa ni pamoja na modeli ya mada ya kiungo na mwandishi na modeli ya mtazamo wa mwandishi wa utambulisho. Matokeo yanaonyesha kwamba LTAI inafanikiwa kuwa na ufanisi mzuri zaidi ya mifano mingine kama hizo wakati utabiri maneno, maelezo na waandishi wa chapisho.', 'de': 'Ein Großteil des wissenschaftlichen Fortschritts beruht auf bereits veröffentlichten Erkenntnissen, aber die Suche durch das riesige Meer wissenschaftlicher Publikationen ist schwierig. Wir verlassen uns oft auf Metriken der wissenschaftlichen Autorität, um die prominenten Autoren zu finden, aber diese Autoritätsindizes unterscheiden Autorität nicht nach Forschungsthemen. Wir präsentieren Latent Topical-Authority Indexing (LTAI) zur gemeinsamen Modellierung von Themen, Zitaten und aktueller Autorität in einem Korpus wissenschaftlicher Arbeiten. Im Vergleich zu früheren Modellen unterscheidet sich LTAI in zwei Hauptaspekten. Erstens modelliert sie explizit den generativen Prozess der Zitate, anstatt die Zitate als gegeben zu behandeln. Zweitens modelliert sie den Einfluss jedes Autors auf Zitate eines Aufsatzes basierend auf den Themen der zitierten Aufsätze sowie der zitierenden Aufsätze. Wir gliedern LTAI in vier akademische Korpora: CORA, Arxiv Physics, PNAS und Citeseer. Wir vergleichen die Performance von LTAI mit verschiedenen Baselines, angefangen bei der latenten Dirichlet-Allokation, bis hin zu den fortgeschritteneren Modellen einschließlich Autor-Link-Topic Model und dynamischem Autor-Zitationstopic Model. Die Ergebnisse zeigen, dass LTAI bei der Vorhersage von Wörtern, Zitaten und Autoren von Publikationen eine höhere Genauigkeit gegenüber anderen ähnlichen Modellen erreicht.', 'id': 'Banyak kemajuan ilmiah berasal dari penemuan yang telah diterbitkan sebelumnya, tapi mencari melalui laut luas penerbitan ilmiah sulit. Kami sering bergantung pada metrik otoritas ilmuwan untuk menemukan penulis terkenal tetapi indeks otoritas ini tidak membedakan otoritas berdasarkan topik penelitian. Kami mempersembahkan Latent Topical-Authority Indexing (LTAI) untuk bersama-sama model topik, citasi, dan otoritas topik dalam sebuah korpus kertas akademis. Berbanding dengan model sebelumnya, LTAI berbeda dalam dua aspek utama. Pertama, itu secara eksplicit model proses generatif citasi, daripada memperlakukan citasi seperti yang diberikan. Kedua, itu model pengaruh setiap penulis pada citasi kertas berdasarkan topik kertas yang disebut, serta kertas yang disebut. Kami menyesuaikan LTAI ke empat korpora akademik: CORA, Arxiv Physics, PNAS, dan Citeseer. Kami membandingkan prestasi LTAI dengan berbagai garis dasar, dimulai dengan alokasi Dirichlet latent, dengan model yang lebih maju termasuk model topik author-link dan model topik citasi author dinamik. Hasilnya menunjukkan bahwa LTAI mencapai ketepatan yang lebih baik dari model yang sama lainnya ketika memprediksi kata, citasi dan penulis publikasi.', 'af': "Baie wetenskaplike vordering stem van voorheen gepubliseer vindings, maar soek deur die groot see van wetenskaplike publikasies is moeilik. Ons het dikwels vertrou op metries van onderwinnige mag om die prominente outeurs te vind, maar hierdie autoriteit indiese doen nie verskillende autoriteit gebaseer op onderwinningsonderwerpe nie. Ons stel die Latent Topical-Authority Indeksering (LTAI) voor om die onderwerpe, citasies en onderwerp van onderwerp in 'n korpus van akademiese papiers te samelend modeliseer. Vergelyk met vorige modele, LTAI verskillig in twee hoof aspekte. Eerste, dit uitduidelik model die genereerbare proses van die sitasies, eerder as die sitasies as gegewe behandel. Tweede, dit model elke outeur se influens op citasies van 'n papier wat gebaseer is op die onderwerpe van die aangetelde papier, en ook die bepaalde papier. Ons pas LTAI in vier akademiese korpora: Kora, Arxiv Physics, en Citeseer. Ons vergelyk die prestasie van LTAI teen verskeie basisline, begin met die latente Dirichlet toewysing, met die meer gevorderde modele insluitend outeur-skakel onderwerp model en dinamiese outeur sitasie onderwerp model. Die resultate wys dat LTAI verbeterde presisie oor ander gelyke modele bereik wanneer woorde, citasies en outeurs van publikasies voorskou word.", 'am': 'Much of scientific progress stems from previously published findings, but searching through the vast sea of scientific publications is difficult.  ብዙ ጊዜም ታላላቆቹን ባለሥልጣናት ለማግኘት በተማሪዎች ሥልጣናት ላይ እንታመናለን ግን እነዚህ ሥልጣናት በተምር ጉዳዮች ላይ በመሠረት የሚለዩትን ሥልጣናት አይለዩም፡፡ የቀድሞው የጦማሪያን ባለሥልጣናት ማውጣት (LTAI) በአካዳቢ ወረቀቶች፣ ጉዳዮችን እና የሠላማዊ ሥልጣናት በመጠቀም እናቀርባለን፡፡ ከአሁን በፊት ዓይነቶች በተለየ LTAI በሁለት ዋነኛው ጉዳይ የተለየ ነው። በመጀመሪያው፣ የብሔራዊ ፕሮጀክት ግንኙነቱን ከመቀበል ይልቅ ግልፅ ነው፡፡ በሁለተኛው፣ የደብዳቤ ወረቀቶች እና የደብዳቤዎችን በመሠረት ላይ የደብዳቤ ጉዳይ ላይ የሁሉን ጸሐፊ ጥቅም ያሳያል፡፡ ወደ አራት አስተማሪዎች ኮራ፣ ወደ አርክሲ ፊስክሲ፣ ወደ PNAS እና ወደ ኪቲራር እናገባለን። የLTAI ድምፅ በተለያዩ የዳሪክሌት አካባቢ ላይ እናሳያታለን፤ በተጀመረ ጊዜ ከዳይሬክሌት አካባቢ ጋር፣ የጸሐፊ-አካባቢ ጉዳይ ሞዴል እና የደራሲ ጸሐፊ ጉዳይ ምሳሌ እና አዲስ ጥያቄ አካባቢ ምሳሌ እናስተያየዋለን፡፡ ፍጥረቱም የLTAI ቃላት፣ ባለሥልጣናት እና ጸሐፊዎችን በመቀበል ጊዜ ከሌሎች በሚመስል ምሳሌዎች ላይ ማስታወቂያውን እንዲያገኝ ያሳያል፡፡', 'hy': "Գիտական առաջընթացի մեծ մասը առաջանում է նախկինում հրատարակված հայտնաբերություններից, բայց գիտական հրատարակությունների հսկայական ծովի միջով որոնումը դժվար է: Մենք հաճախ հիմնված ենք գիտական իշխանության մետրիկների վրա հայտնաբերելու հայտնի հեղինակներին, բայց այս իշխանության ինդեքսները չեն տարբերակում իշխանությունը հետազոտության թեմաների վրա: Մենք ներկայացնում ենք վերջին թեմային իշխանությունների ինդեքսը (LTAI), որպեսզի միասին մոդելավորենք թեմաները, մեջբերումները և թեմային իշխանությունները գիտական թղթերում: Համեմատելով նախորդ մոդելների հետ, LTAI-ը տարբերվում է երկու հիմնական ասպեկտներով: Նախ և առաջ, այն բացահայտորեն մոդելավորում է մեջբերումների սերունդային գործընթացը, փոխարենը մեջբերումների վերաբերյալ վերաբերյալ: Երկրորդ, այն մոդելավորում է յուրաքանչյուր հեղինակի ազդեցությունը թղթի մեջբերումների վրա, հիմնված մեջբերված թղթերի թեմաների վրա, ինչպես նաև մեջբերող թղթերի վրա: Մենք համապատասխանում ենք LTAI-ին չորս ակադեմիական կորպորա' CORA ի, Arxiv ֆիզիկայի, PՆԱՍի և Citizeer-ի մեջ: Մենք համեմատում ենք LTAI-ի արտադրողությունը տարբեր հիմնական գծերի հետ, սկսած թաքնված DiRicLet-ի բաժանման հետ, ավելի զարգացած մոդելների հետ, ներառյալ հեղինակի-կապի թեմայի մոդելը և դինամիկ հեղինակի մեջբերման թեմայի մոդել Արդյունքները ցույց են տալիս, որ LTAI-ն ավելի ճշգրիտ է հասնում այլ նման մոդելների նկատմամբ, երբ կանխագուշակում է բառեր, մեջբերումներ և հրատարակությունների հեղինակներ:", 'bn': 'পূর্বে প্রকাশিত তথ্য থেকে অনেক বৈজ্ঞানিক উন্নয়ন ঘটেছে, কিন্তু বৈজ্ঞানিক প্রকাশনার বিশাল সমুদ্রের মাধ্যমে অনুসন্ আমরা প্রায়শই বিশ্ববিদ্যালয়ের লেখকদের খুঁজে বের করতে শিক্ষাগত কর্তৃপক্ষের উপর নির্ভর করি, কিন্তু এই কর্তৃপক্ষের অভিযোগ গবেষণা  আমরা সাম্প্রতিক বিষয়বস্তু-কর্তৃপক্ষ সংক্রান্ত সংক্রান্ত (এলটিআই) প্রতিষ্ঠানে উপস্থাপন করছি শিক্ষাবিদ্যালয়ের কোর্পাসে বিষয়গু পূর্ববর্তী মডেলের সাথে তুলনায়, LTAI দুই প্রধান দিকে ভিন্ন। প্রথমত, এটি স্পষ্ট ভাবে এই উদ্দেশ্যের জেনারেটিভ প্রক্রিয়ার মডেল দেখাচ্ছে, যেটি দেয়া হয়েছে তার চিকিৎসা কর দ্বিতীয়, এটি প্রত্যেক লেখকের প্রভাবের মডেল করে উল্লেখিত কাগজের বিষয়ের উপর ভিত্তিক কাগজের উপরে প্রভাব তৈরি করে এবং উল্লেখ করা কাগজ আমরা এলটাআইকে চারজন শিক্ষামীন কোর্পোরায় যোগ দিয়েছি: কোরা, আর্ক্সিভ ফিজিক্স, পিনাস এবং সিটেসিয়ার। আমরা এলটিআই বিভিন্ন বেসেলাইনের বিরুদ্ধে প্রদর্শনের তুলনা করি, সাম্প্রতিক ডিরিচেলেট বিতরণের সাথে শুরু করি, আরো উন্নত মডেলের সাথে লেখক-লিঙ্ক বিষয় মডেল এব ফলাফল দেখা যাচ্ছে যে এলটিআই অন্যান্য মডেলের ব্যাপারে সঠিকভাবে উন্নতি পেয়েছে যখন প্রকাশিত শব্দ, উদ্দেশ্য এবং লেখক ভব', 'az': "Əvvəllər yayınlanan elmi tədbirlərin çoxluğu tədbirlərindən gəlir, amma elmi tədbirlərin geniş dənizdən arama çətin. Biz çox çox bilimsel hökmranlıq metriklərinə təvəkkül edirik, lakin bu hökmranlıq indikatları araştırma məsələlərinə dayanan hökmranlığı fərqli olmaz. Biz bir akademik kağıtların korpuslarında məsələləri, sitasiyaları və məsələləri birlikdə modelləşdirmək üçün Son Topical-Authority Indexing (LTAI) göstəririk. Əvvəlki modellərlə qarşılaşdığında, LTAI iki ana aspektdə fərqlənir. Əvvəlcə, bu şəkillərin genetik prosesini göstərmək yerinə, şəkilləri verilən şəkildə təhsil etmək üçün açıq-aydın modellər edir. İkincisi, bu hər yazarın təsirini belə yazılmış kağıtların məs ələlərinə və belə yazılmış kağıtların məsələlərinə dayandırır. Biz LTAI'yi dörd akademik korporasına qoyuruq: CORA, Arxiv Fiziksi, Zənger və Citeser. Biz LTAI'nin performansını müxtəlif baz çətinliklərlə qarşılaşdırırıq, latent Dirichlet bağlaması ilə başlayır, yazıcı-bağlama məsələsinin modeli və dinamik yazıcılıq məsələsinin modeli ilə daha gelişmiş modellərlə qarşılaşdırırıq. Sonuçlar, LTAI sözləri, yazıları və yazarları tədbir etdikdə başqa bənzər modellərdən daha doğruluğu artırar.", 'ca': "Molt progrés científic prové de descobriments publicats abans, però buscar a través del vaste mar de publicacions científices és difícil. Sovint confiem en les mètriques de l'autoritat científica per trobar els autors prominents però aquests índics d'autoritat no diferencian l'autoritat basada en temes de recerca. Presentam l'índex de la última Autoritat tòpica (LTAI) per modelar conjuntament els temes, citacions i autoritats tòpics en un corpus de treballs acadèmics. Comparat amb models anteriors, la LTAI diferèn en dos aspectes principals. Primer, modela explícitament el procés generador de les citacions, en comptes de tractar les citacions com es diu. Segon, modela l'influència de cada autor en citacions d'un article basat en els temes dels articles citats, com també en els articles citats. Ens encaixem en quatre corpores acadèmics: CORA, Arxiv Physics, PNAS i Citeseer. Comparem el desempeny de la LTAI amb diverses línies de base, començant amb l'asignació latent de Dirichlet, amb els models més avançats, incloent el model de tema autor-enllaç i el model dinàmic de tema de citació autora. Els resultats demostren que LTAI aconsegueix una millor precisió sobre altres models similars quan prediu paraules, citacions i autors de publicacions.", 'sq': 'Shumë përparim shkencor vjen nga gjetjet e botuara më parë, por kërkimi nëpër detin e gjerë të publikimeve shkencore është i vështirë. Ne shpesh mbështetemi në metrikat e autoritetit shkencor për të gjetur autorët e shquar por këto indeks autoriteti nuk diferencojnë autoritetin bazuar në temë kërkimi. Ne paraqesim Indeksimin Latent Topical-Authority (LTAI) për modelimin e përbashkët të temave, citateve dhe autoritetit aktual në një korpus gazetash akademike. Krahasuar me modelet e mëparshëm, LTAI ndryshon në dy aspekte kryesore. Së pari, ajo modelon shprehësisht procesin gjenerativ të citateve, në vend të trajtimit të citateve siç është dhënë. Së dyti, modelon ndikimin e çdo autori në përmendimet e një artikulli bazuar në temat e gazetave të përmendura si dhe gazetat përmendura. Ne përshtatemi LTAI në katër korpra akademike: CORA, Arxiv Physics, PNAS dhe Citeseer. Ne krahasojmë shfaqjen e LTAI-së me linjat bazë të ndryshme, duke filluar me përcaktimin e fshehtë të Dirichlet-it, me modelet më të avancuar duke përfshirë modelin e temës autor-lidhje dhe modelin dinamik të temës së citimit të autorëve. Rezultatet tregojnë se LTAI arrin saktësi të përmirësuar ndaj modeleve të tjera të ngjashëm kur parashikon fjalë, citate dhe autorë të publikimeve.', 'tr': "Ilmi gelişmeler öňünden berin yayınlanan çözümlerden köp gelişmelerdir, ýöne bilim tökümlerinin geniş denizini aramak kyn. Biz köplenç uly awtorlary tapmak üçin bilim adamlaryň metriklerine ynanýarýarys ýöne bu awtoriýa görkezmeleri araştyrma temasyna daýalan awtoriýany üýtgetmeýäris. Biz akademiki kagytlaryň korpusynda soňky Topik-Authority Indeksiýasyny (LTAI) meýdançalary, meýdançalary we meýdançalygyny bir birleştirmek üçin görkezip berýäris. Öňki nusgalar bilen karşılaşdy, LTAI iki esasy aspekte üýtgeýär. Ilkinji gezek, seçmeler tarapyndan döredijilik prosesini görkez. Ikinji gezek, her awtoryň täsirini ýazylýan gazetler we ýazylýan gazetler temasyna daýanýan bir kagyzyň täsirini nusgala edýär. Biz LTAI'i dört akademiki korpoýara basýarys: CORA, Arxiv Fizika, felaket we Citeser. Biz LTAI zadyny dürli baz hatlary bilen karşılaştyrýarys, geçtiň Dirichlet taýýarlanmasy bilen başlanýar, aşırı gelişmiş nusgalar bilen awtomatik-baglaşdyrma nusgasyny we dinamik awtomatik taýýarlanmasy nusgasyna görýäris. Netijeler LTAI sözleri, citatlary we basyşlaryň täzeliklerini öňünden beýleki nusgalaryň arasynda has dogrudygyny görkezýär.", 'et': 'Suur osa teaduse arengust tuleneb eelnevalt avaldatud tulemustest, kuid otsimine läbi tohutu teadusväljaannete mere on raske. Sageli tugineme teadusliku autoriõiguse mõõdikutele, et leida silmapaistvad autorid, kuid need autoriõiguse indeksid ei erista autoriõigust uurimisteemade põhjal. Tutvustame Latent Topical-Authority Indexingut (LTAI) teemade, tsitaatide ja aktuaalse autoriteedi ühiseks modelleerimiseks akadeemiliste artiklite korpuses. Võrreldes varasemate mudelitega erineb pikaajaline lennutegevus kahes peamises aspektis. Esiteks modelleerib see sõnaselgelt tsitaatide generatiivset protsessi, mitte käsitleda tsitaate antud kujul. Teiseks modelleerib see iga autori mõju artikli tsiteerimisele, lähtudes nii tsiteeritud artiklite teemadest kui ka tsiteerivatest artiklitest. Me sobime LTAI nelja akadeemilise korpuse: CORA, Arxiv Physics, PNAS ja Citeseer. Võrdleme LTAI tulemuslikkust erinevate lähtejoontega, alustades latentsest Dirichleti jaotusest, arenenumate mudelitega, sealhulgas autorilingi teemamudeli ja dünaamilise autoritsiteerimise teemamudeliga. Tulemused näitavad, et LTAI saavutab teistest sarnastest mudelitest parema täpsuse sõnade, tsitaatide ja publikatsioonide autorite prognoosimisel.', 'fi': 'Suuri osa tieteellisestä kehityksestä johtuu aiemmin julkaistuista löydöksistä, mutta tieteellisten julkaisujen valtavan meren läpi etsiminen on vaikeaa. Usein luotamme tieteellisen auktoriteetin mittareihin löytääksemme merkittäviä tekijöitä, mutta nämä auktoriteetit eivät erota auktoriteetteja tutkimusaiheiden perusteella. Esitämme Latent Topical-Authority Indexing (LTAI) aiheiden, sitaattien ja ajankohtaisen auktoriteetin mallintamiseen akateemisissa julkaisuissa. Aiempiin malleihin verrattuna LTAI eroaa kahdesta pääkohdasta. Ensin se nimenomaisesti mallintaa lainausten generatiivisen prosessin sen sijaan, että niitä käsiteltäisiin annetuina. Toiseksi se mallintaa kunkin kirjoittajan vaikutusta artikkelin siteerauksiin sekä siteeravien artikkelien aiheiden perusteella. Yhdistämme LTAI:n neljään akateemiseen korporaan: CORA, Arxiv Physics, PNAS ja Citeseer. Vertailemme LTAI:n suorituskykyä erilaisiin lähtölinjoihin, alkaen latenttista Dirichlet-allokaatiosta, kehittyneempiin malleihin, kuten tekijän linkin teemamalliin ja dynaamiseen tekijän viittausmalliin. Tulokset osoittavat, että LTAI saavuttaa paremman tarkkuuden kuin muut vastaavat mallit ennustaessaan sanoja, lainauksia ja julkaisujen kirjoittajia.', 'cs': 'Velká část vědeckého pokroku vychází z dříve publikovaných poznatků, ale hledání rozsáhlého moře vědeckých publikací je obtížné. Často se spoléháme na metriky vědecké autority, abychom našli významné autory, ale tyto autoritní indexy nerozlišují autoritu na základě výzkumných témat. Představujeme Latent Topical-Authority Indexing (LTAI) pro společné modelování témat, citací a aktuální autority v korpusu akademických článků. Oproti předchozím modelům se LTAI liší ve dvou hlavních aspektech. Za prvé, explicitně modeluje generativní proces citací, spíše než považuje citace za dané. Za druhé modeluje vliv jednotlivých autorů na citace článku na základě témat citovaných článků a citovaných článků. LTAI rozdělujeme do čtyř akademických korpusů: CORA, Arxiv Physics, PNAS a Citeseer. Porovnáváme výkon LTAI s různými základními liniemi, počínaje latentní Dirichletovou alokací, až po pokročilejší modely včetně autor-link tématu modelu a dynamického autorského citačního tématu. Výsledky ukazují, že LTAI dosahuje lepší přesnosti oproti jiným podobným modelům při predikci slov, citací a autorů publikací.', 'bs': 'Mnogi naučni napredak dolazi iz prethodnih objavljenih nalaza, ali pretraživanje kroz ogromno more naučnih publikacija je teško. Često se oslanjamo na metriku naučnog autoriteta da nađemo poznatih autora, ali ovi autoritetski indikatori ne razlikuju autoritet na temelju istraživanja. Predstavljamo poslednji indeks Topičnog tijela (LTAI) za zajedničku modeliranje tema, citacija i temeljnog autoriteta u korpusu akademijskih papira. U usporedbi sa prethodnim modelima, LTAI se razlikuje u dva glavna aspekta. Prvo, to objašnjava generativni proces citacija, umjesto tretiranja citacija kao što je dato. Drugo, to modelira uticaj svakog autora na citacije papira bazirane na temama navedenih papira, kao i građanskih papira. Stavljamo LTAI u četiri akademičke korporacije: CORA, arxiv fizika, zube i Citeseer. Uspoređujemo učinkovitost LTAI-a s različitim osnovnim linijama, počevši sa latentnom dodjelom Dirichleta, sa naprednijim modelima uključujući model tema autora-povezanog i dinamički model teme za ciljanje autora. Rezultati pokazuju da LTAI postigne poboljšanu preciznost nad drugim sličnim modelima kada predviđaju riječi, citacije i autore publikacija.', 'sk': 'Velik znanstveni napredek izhaja iz predhodno objavljenih ugotovitev, vendar je iskanje skozi široko morje znanstvenih publikacij težko. Pri iskanju pomembnih avtorjev se pogosto zanašamo na meritve znanstvene avtoritete, vendar ti indeksi avtoritete ne razlikujejo avtoritete na podlagi raziskovalnih tem. Predstavljamo Latent Topical-Authority Indexing (LTAI) za skupno modeliranje teme, citatov in aktualne avtoritete v korpusu akademskih člankov. V primerjavi s prejšnjimi modeli se LTAI razlikuje v dveh glavnih vidikih. Prvič, izrecno modelira generativni proces citatov, namesto da obravnava citate kot dane. Drugič, modelira vpliv vsakega avtorja na citiranje prispevka na podlagi teme citiranih prispevkov in citiranih prispevkov. LTAI vključujemo v štiri akademske korpuse: CORA, Arxiv Physics, PNAS in Citeseer. Učinkovitost LTAI primerjamo z različnimi osnovnimi linijami, začenši z latentno dodelitvijo Dirichlet, z naprednejšimi modeli, vključno z avtorskim modelom tematskih povezav in dinamičnim modelom tematskih citatov avtorjev. Rezultati kažejo, da LTAI pri napovedovanju besed, citatov in avtorjev publikacij doseže izboljšano natančnost v primerjavi z drugimi podobnimi modeli.', 'jv': 'Ana akeh sing perbudhakan siènih sak saben nang digawe, nguasai pangusahaan ngengatining kebuturan ning dino sing sampeyan kuwi susah-susahe. Awak dhéwé hakan langkung wigati podho karo akeh stiftar aturan sing nggawe autor sing ngupakan nik awak dhéwé uga basa sing paling dhéwé kuwi jenis akeh basa perusahaan karo perusahaan sing paling dhéwé. Awak dhéwé nggawe Tarjamahan-Tarjamahan sing berarti (LTAI) nggawe ngubah gambarang tema, sithaya lan autor temalan ning académik cara-cara. text-editor-action Awak dhéwé, padha akeh nesalaman sing ngomong nik akeh batasané perusahaan sing nggawe barang-barang. Siji-sijih, lak model sing nggawe autor sampeyan urip kuwi padhar biasane sak cara-cara sing digomokake, lan akeh cara-cara sing alih. Awak dhéwé éntuk LTAI nganggo cara-cara akadémik kat: cora, arksiv Finsik, pangan, lan Siteser. Awak dhéwé nggawe nyimpen LTAI karo akeh basa sing luwih basa, nambah karo alamat directory sing luwih dumadhi, sampek modolen sing luwih dhéwé, nambah model autor-link tema lan model model autor. Rejaleng wong mengko LTAI iso nggawe akeh sing luwih nggawe model sing luwih njaluk, nik awak dhéwé kuwi pawaran, sitahan lan autor neng publikasi.', 'he': 'הרבה התקדמות מדעית מגיעה ממציאות שפורסמות קודם לכן, אבל חיפוש דרך הים העצום של פרסומות מדעיות קשה. לעתים קרובות אנו סומכים על מטריות של סמכות מדענית למצוא את הסופרים הבהירים אבל אינדיקסי הסמכות האלה לא מפריעים סמכות מבוססים על נושאי מחקר. אנחנו מציגים מידע לאנטנט טופי-אוניברסיטה (LTAI) על הדוגמה משותפת של הנושאים, ציטוטים, וסמכות אוניברסיטה בקורפוס של עיתונים אקדמיים. בהשוואה לדוגמנים הקודמים, LTAI שונה בשני היבטים העיקריים. ראשית, הוא דוגמן באופן ברור את תהליך הדורתי של הציטורים, במקום להתייחס לציטורים כפי שנתן. שנית, הוא דוגמא את השפעה של כל סופר על ציטוטים של נייר מבוסס על נושאי העיתונים המציטים, כמו גם על העיתונים המציטים. אנחנו מתאימים לאט.איי.איי לארבעה גופות אקדמיות: CORA, פיזיקה ארקסיב, PNAS, וסיטיסר. אנחנו משוותים את ההופעה של LTAI עם שונים בסיסים, מתחילים עם ההזדמנות המסתורית של Dirichlet, למודלים התקדמות יותר כולל מודל נושא קושר-סופר ומודל נושא ציטוט של סופר דינמי. התוצאות מראות ש LTAI משיג מדויקת משתפרת על דוגמנים דומים אחרים כאשר צפה מילים, ציטוטים וסופרים של פרסומות.', 'ha': "Bayan jarrabi masu sakin da aka sani daga fassarar bayani, kuma amma suna karatu a tsakanin tẽkun takardar masu sayansi na da zaman. Ko da yawa munã dõgara a kan metricin mamlaka masu sani dõmin ka sãmi marubũta mãsu girma, kuma amma waɗannan madaidaita ba su rarrabe mamlaka a kan bincike madaidaici. Tuna halatar da shirin makampuni, masu shiryuwa da kuma madaidaici a cikin karatun littafan akada. @ info: whatsthis Kayyan da, shi yana bayyana zaɓallin jarrabar jarayon tambuwa, kuma bã ya sambawa da ake ba. Dukkan na, yana sami muhallin kõwane mai marubuci a kan misalin takarda a kan karatun da aka samu da takardar da aka faɗa. Mãsu fito da LTAI zuwa makampuni huɗu na akadi: COra, Arksi Phisiki, PNAS da Citeser. Tuna samfani game da aikin LTAI wa masu motsi na daban-daban, masu fara da cire-alli na Dirikleta yanzu, zuwa masu da aka ƙara masu motsi, kamar misãlin maɓallin rubutun da kuma misali mai rubutu na rubutu. Mataimakin na nuna cewa, LTAI na ƙara tsari mafiya tsari a kan wasu misãlai kamar shi idan na yi bayani ga kalmõmi, citation da ma'anar takarda.", 'bo': 'ཚན་རིག་གི་འཕེལ ང་ཚོས་རྒྱུན་ལྡན་ནས་སློབ་ཆེན་གྱི་དབུས་པ་གཙོ་ཅན་དེ་ཚོ་རྩོམ་པ་པོ་ཚོར་བཙུགས་ཡོད། ཡིན་ནའང་དབང་འཛིན་པའི་ཁོང་ ང་ཚོས་ཤུལ་དུ་མའི་དོན་ལྗོངས་ཀྱི་གནད་དོན་ཡུལ་གྱི་དབུལ་ཁུལ་བསྡད་ནས་བཟོས་བྱས་མེད། སྔོན་གྱི་མ་དབྱིབས་དང་མཉམ་དུ་མཉམ་དུ་རྩ་བའི་ཞལ་ཆོས་གཉིས་ནང་མི་འདུག First, it explicitly models the generative process of the citations, rather than treating the citations as given. གཉིས་པ་བརྗོད་བྱས། འདི་ནི་རྩོམ་པ་པོ་སོ་སོའི་ཤོག་བུ་ཡི་གེའི་གནས་ཚུལ་དང་མཉམ་དུ་གཏོང་ཐུབ་པའི་ཤོག་བུ་ཡི་གེའི་གནས་ཚུལ་དང ང་ཚོས་སྦྱོར་བའི་མཐུང་འབྲེལ་གྱི་ནང་དུ་LTAI་ལ་མཐུད་པ་ཞིག་ཡོད། CORA། Arxiv Physics, ). ↑ , ukat Citeseer། We compare the performance of LTAI against various baselines, starting with the latent Dirichlet allocation, to the more advanced models including author-link topic model and dynamic author citation (help) དབྱངས་འབྲས་ན་LTAI་གིས་དུས་ཡོད་ཚད་གཅིག་མཚུངས་པའི་མིག་པ་གཞན་དང་མཐོང་ནུས་ཡར་རྒྱས་འགོར་བ་དང་།'}
{'en': 'Pushing the Limits of Translation Quality Estimation', 'ar': 'دفع حدود تقدير جودة الترجمة', 'pt': 'Ultrapassando os limites da estimativa de qualidade da tradução', 'fr': "Repousser les limites de l'estimation de qualité des traductions", 'es': 'Superación de los límites de la estimación de la calidad', 'ja': '翻訳品質見積もりの限界を突き詰める', 'hi': 'अनुवाद गुणवत्ता अनुमान की सीमाओं को धक्का देना', 'zh': '突破译质量评之极', 'ru': 'Расширение границ оценки качества перевода', 'ga': 'Teorainneacha Meastachán Cáilíochta an Aistriúcháin a Bhrú', 'ka': 'შეცვლის კაalitეტის განსაზღვრების ზომი', 'hu': 'A fordítási minőségbecslés határainak feszítése', 'el': 'Προώθηση των Όρων Εκτίμησης Ποιότητας Μεταφράσεων', 'it': 'Spingere i limiti della stima della qualità della traduzione', 'lt': 'Vertimo kokybės vertinimo ribų nustatymas', 'mk': 'Притиснување на границите на проценката на квалитетот на преводот', 'kk': 'Аудару сапасының шектерін шектеу', 'ms': 'Pushing the Limits of Translation Quality Estimation', 'ml': 'പരിഭാഷപൂര്\u200dണ്ണത്തിന്റെ പരിധികള്\u200d അമര്\u200dത്തുന്നു', 'mt': 'Il-Pressjoni tal-Limiti tal-Istima tal-Kwalità tat-Traduzzjoni', 'mn': 'Оруулах чадварын тооцооллын хязгаарыг', 'no': 'Trykk grensene for omsetjingskvalitets estimating', 'sr': 'Pritisnuti granice procjene kvalitete prevoda', 'si': 'වාර්ථාව කුළුවත් අනුමාණය ගැන සීමාවක් දාන්න', 'so': 'Ku dhimista Limitka Takimaanshaha Turjumidda', 'sv': 'Att pressa gränserna för uppskattning av översättningskvalitet', 'ta': 'மொழிபெயர்ப்பு தரம் கணக்கீட்டின் எல்லைகளை அழுத்துகிறது', 'ur': 'Translation Quality Estimation', 'ro': 'Depășirea limitelor estimării calității traducerii', 'pl': 'Przesuwanie granic oceny jakości tłumaczeń', 'uz': 'Tarjima xossasining chegaralari', 'vi': 'Đang thúc đẩy giới hạn chất lượng của dịch', 'da': 'At presse grænserne for oversættelseskvalitetsvurdering', 'bg': 'Преминаване на границите на оценката на качеството на превода', 'hr': 'Pritisnuti granice procjene kvalitete prevoda', 'nl': 'De grenzen van de schatting van vertaalkwaliteit verleggen', 'id': 'Menempat Batas Penghargaan Kualitas Terjemahan', 'sw': 'Kupindua Mipaka ya Uwango wa Tafsiri', 'de': 'Die Grenzen der Schätzung der Übersetzungsqualität verschieben', 'ko': '번역 품질 평가의 한계를 돌파하다', 'af': 'Druk die Grense van Vertaling Kwaliteit Estimasie', 'sq': 'Shtypja e kufijve të vlerësimit të cilësisë së përkthimit', 'hy': 'Գործման որակի գնահատման սահմանները ճնշելը', 'fa': 'محدودیت ارزیابی کیفیت ترجمه', 'bn': 'অনুবাদের মানের সীমা প্রদর্শন করা হচ্ছে', 'tr': 'Terjime Görkezilişi Taýýarlamanyň Hejimlerini Çykaryş', 'am': 'ምርጫዎች', 'cs': 'Posouvání hranic odhadu kvality překladu', 'et': 'Tõlkekvaliteedi hindamise piiride ületamine', 'bs': 'Pritisnuti granice procjene kvalitete prevoda', 'az': 'T톛rc칲m톛 N톛viyy톛tinin Q캼ymetl톛rini Q캼ymetl톛ndirm톛si', 'fi': 'Kääntämisen laadun arviointien rajojen ylittäminen', 'ca': 'Pushing the Limits of Translation Quality Estimation', 'ha': 'KCharselect unicode block name', 'jv': 'Ngubah Jejaring', 'sk': 'Prekoračevanje meja ocene kakovosti prevajanja', 'he': 'לדחוף את הגבולות של הערכת איכות התרגום', 'bo': 'གཞུང་སྤྲོད་ཀྱི་དབྱེ་བ་རྩིས་ཚད་ལྟར་མཚམས་བཞག་བཞིན་པ'}
{'en': 'Translation quality estimation is a task of growing importance in NLP, due to its potential to reduce post-editing human effort in disruptive ways. However, this potential is currently limited by the relatively low accuracy of existing systems. In this paper, we achieve remarkable improvements by exploiting synergies between the related tasks of word-level quality estimation and automatic post-editing. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system. Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16 : a word-level FMULT1 score of 57.47 % (an absolute gain of +7.95 % over the current state of the art), and a Pearson correlation score of 65.56 % for sentence-level HTER prediction (an absolute gain of +13.36 %).', 'ar': 'يعتبر تقدير جودة الترجمة مهمة ذات أهمية متزايدة في البرمجة اللغوية العصبية ، نظرًا لقدرتها على تقليل الجهد البشري بعد التحرير بطرق تخريبية. ومع ذلك ، فإن هذه الإمكانات محدودة حاليًا بسبب الدقة المنخفضة نسبيًا للأنظمة الحالية. في هذه الورقة ، نحقق تحسينات ملحوظة من خلال استغلال التآزر بين المهام ذات الصلة بتقدير جودة مستوى الكلمة والتحرير التلقائي اللاحق. أولاً ، نقوم بتكديس نموذج عصبي جديد ، مصمم بعناية ، في نظام تقدير جودة على مستوى الكلمات غني بالميزات. بعد ذلك ، نستخدم مخرجات نظام التحرير اللاحق التلقائي كميزة إضافية ، والحصول على نتائج مذهلة على WMT16: درجة FMULT1 على مستوى الكلمة بنسبة 57.47٪ (مكسب مطلق + 7.95٪ عن الحالة الحالية للفن) ، ودرجة ارتباط بيرسون 65.56٪ للتنبؤ HTER على مستوى الجملة (مكسب مطلق + 13.36٪).', 'fr': "L'estimation de la qualité de la traduction est une tâche de plus en plus importante dans la PNL, en raison de sa capacité à réduire les efforts humains de post-édition de manière disruptive. Cependant, ce potentiel est actuellement limité par la précision relativement faible des systèmes existants. Dans cet article, nous réalisons des améliorations remarquables en exploitant les synergies entre les tâches connexes d'estimation de la qualité au niveau des mots et de post-édition automatique. Tout d'abord, nous empilons un nouveau modèle neuronal soigneusement conçu dans un système d'estimation de la qualité au niveau des mots basé sur les fonctionnalités. Ensuite, nous utilisons la sortie d'un système de post-édition automatique comme fonctionnalité supplémentaire, obtenant des résultats saisissants sur WMT16\xa0: un score FMULT1 au niveau des mots de 57,47\xa0% (un gain absolu de +7,95\xa0% par rapport à l'état actuel de la technique), et un score de corrélation de Pearson de 65,56\xa0% pour la prédiction HTER au niveau de la phrase (un gain absolu de+13,36\xa0%).", 'es': 'La estimación de la calidad de la traducción es una tarea de creciente importancia en la PNL, debido a su potencial para reducir el esfuerzo humano posterior a la edición de manera disruptiva. Sin embargo, este potencial está actualmente limitado por la precisión relativamente baja de los sistemas existentes. En este artículo, logramos mejoras notables al aprovechar las sinergias entre las tareas relacionadas de la estimación de la calidad a nivel de palabras y la postedición automática. Primero, apilamos un nuevo modelo neuronal cuidadosamente diseñado en un rico sistema de estimación de calidad a nivel de palabra basado en características. Luego, utilizamos la salida de un sistema de postedición automática como característica adicional, obteniendo resultados sorprendentes en WMT16: una puntuación FMULT1 a nivel de palabras del 57,47% (una ganancia absoluta de +7,95% con respecto al estado actual de la técnica) y una puntuación de correlación de Pearson del 65,56% para la predicción HTER a nivel de oración (una ganancia absoluta de +13.36%).', 'pt': 'A estimativa da qualidade da tradução é uma tarefa de crescente importância na PNL, devido ao seu potencial de reduzir o esforço humano pós-edição de forma disruptiva. No entanto, este potencial é atualmente limitado pela precisão relativamente baixa dos sistemas existentes. Neste artigo, alcançamos melhorias notáveis explorando sinergias entre as tarefas relacionadas de estimativa de qualidade em nível de palavra e pós-edição automática. Primeiro, empilhamos um novo modelo neural cuidadosamente projetado em um sistema de estimativa de qualidade em nível de palavra baseado em recursos. Em seguida, usamos a saída de um sistema automático de pós-edição como um recurso extra, obtendo resultados impressionantes no WMT16: uma pontuação FMULT1 em nível de palavra de 57,47% (um ganho absoluto de +7,95% em relação ao estado da arte atual), e uma pontuação de correlação de Pearson de 65,56% para a previsão HTER em nível de sentença (um ganho absoluto de +13,36%).', 'ja': '翻訳品質の見積もりは、破壊的な方法で編集後の人間の労力を減らす可能性があるため、NLPでますます重要になっているタスクです。しかしながら、このポテンシャルは、現在、既存のシステムの比較的低い精度によって制限されている。本稿では、ワードレベルクオリティ推定と自動ポストエディットの関連するタスク間の相乗効果を利用することにより、顕著な改善を達成する。まず、慎重に設計された新しいニューラルモデルを、豊富な特徴に基づくワードレベルの品質推定システムに積み重ねます。次に、自動ポストエディットシステムの出力を追加機能として使用し、WMT 16で目覚ましい結果を得ます。ワードレベルのFMULT 1スコアは57.47 ％ （現在の最先端の状態よりも+7.95 ％の絶対利得）、文レベルのHTER予測のピアソン相関スコアは65.56 ％ （ +13.36 ％の絶対利得）です。', 'zh': '译质评 NLP 中为一务,盖或以破坏性减译后辑之力也。 然此潜力目前受现系统相对卑精度之限。 本文,以字级量自译后辑等事,显著改进。 先之以一精心设计之新型神经,积之以一介之丰单词质量之以统。 然后以自译后编辑系统输出为额外功能,于WMT16上得惊人之效:单词级FMULT1得分为57.47%(比当今技术水平绝收益为+7.95%),而句级HTER占Pearson相关为65.56%(绝对收益为+ 13.36%)。', 'hi': 'अनुवाद गुणवत्ता अनुमान एनएलपी में बढ़ते महत्व का एक कार्य है, जो विघटनकारी तरीकों से पोस्ट-एडिटिंग मानव प्रयास को कम करने की क्षमता के कारण है। हालांकि, यह क्षमता वर्तमान में मौजूदा प्रणालियों की अपेक्षाकृत कम सटीकता द्वारा सीमित है। इस पेपर में, हम शब्द-स्तर की गुणवत्ता के अनुमान और स्वचालित पोस्ट-एडिटिंग के संबंधित कार्यों के बीच तालमेल का फायदा उठाकर उल्लेखनीय सुधार प्राप्त करते हैं। सबसे पहले, हम एक समृद्ध सुविधा-आधारित शब्द-स्तरीय गुणवत्ता आकलन प्रणाली में एक नया, सावधानीपूर्वक इंजीनियर, तंत्रिका मॉडल ढेर करते हैं। फिर, हम एक अतिरिक्त सुविधा के रूप में एक स्वचालित पोस्ट-एडिटिंग सिस्टम के आउटपुट का उपयोग करते हैं, WMT16 पर हड़ताली परिणाम प्राप्त करते हैं: 57.47% का एक शब्द-स्तरीय FMULT1 स्कोर (कला की वर्तमान स्थिति पर +7.95% का पूर्ण लाभ), और वाक्य-स्तर HTER भविष्यवाणी के लिए 65.56% का पियर्सन सहसंबंध स्कोर (+13.36% का पूर्ण लाभ)।', 'ru': 'Оценка качества перевода является задачей растущего значения в NLP, из-за его потенциала сократить пост-редактирование человеческих усилий в разрушительных путях. Однако этот потенциал в настоящее время ограничен относительно низкой точностью существующих систем. В этой статье мы добиваемся значительных улучшений, используя синергию между смежными задачами оценки качества на уровне слов и автоматического пост-редактирования. Во-первых, мы складываем новую, тщательно сконструированную, нейронную модель в богатую систему оценки качества на уровне слов. Затем мы используем вывод автоматической системы редактирования в качестве дополнительной функции, получая поразительные результаты на WMT16: оценка FMULT1 на уровне слова 57,47% (абсолютный прирост +7,95% по сравнению с текущим уровнем техники) и оценка корреляции Пирсона 65,56% для предсказания HTER на уровне предложения (абсолютный прирост +13,36%).', 'ga': 'Is tasc é meastachán cáilíochta aistriúcháin a bhfuil tábhacht mhéadaithe ag baint leis in NLP, mar gheall ar a chumas iarracht dhaonna iar-eagarthóireacht a laghdú ar bhealaí suaiteacha. Mar sin féin, tá an poitéinseal seo teoranta faoi láthair ag cruinneas measartha íseal na gcóras atá ann cheana féin. Sa pháipéar seo, déanaimid feabhsuithe suntasacha a bhaint amach trí leas a bhaint as sineirgí idir na tascanna gaolmhara de mheastachán cáilíochta ar leibhéal na bhfocal agus iar-eagarthóireacht uathoibríoch. Ar an gcéad dul síos, cuirimid múnla néarúil nua, a ndearnadh innealtóireacht chúramach air, isteach i gcóras meastacháin cáilíochta ar leibhéal na bhfocal gné-bhunaithe saibhir. Ansin, bainimid úsáid as aschur córais uathoibríoch iar-eagarthóireachta mar ghné bhreise, a ghnóthaíonn torthaí iontacha ar WMT16: scór focal FMULT1 de 57.47% (gnóthachan iomlán de +7.95% ar an staid reatha), agus scór comhghaolmhaireachta Pearson de 65.56% do thuar HTER ag leibhéal na pianbhreithe (gnóthachan iomlán de +13.36%).', 'el': 'Η εκτίμηση της ποιότητας της μετάφρασης είναι ένα έργο αυξανόμενης σημασίας στο ΝΛΠ, λόγω της δυνατότητάς του να μειώσει την ανθρώπινη προσπάθεια μετά την επεξεργασία με διαταρακτικούς τρόπους. Ωστόσο, το δυναμικό αυτό περιορίζεται επί του παρόντος από τη σχετικά χαμηλή ακρίβεια των υφιστάμενων συστημάτων. Στην παρούσα εργασία, επιτυγχάνουμε αξιοσημείωτες βελτιώσεις αξιοποιώντας συνέργειες μεταξύ των σχετικών εργασιών της εκτίμησης ποιότητας σε επίπεδο λέξεων και της αυτόματης μετα-επεξεργασίας. Πρώτον, στοιβάζουμε ένα νέο, προσεκτικά σχεδιασμένο, νευρωνικό μοντέλο σε ένα πλούσιο σύστημα εκτίμησης ποιότητας σε επίπεδο λέξεων. Στη συνέχεια, χρησιμοποιούμε την έξοδο ενός αυτόματου συστήματος μετα-επεξεργασίας ως επιπλέον χαρακτηριστικό, αποκτώντας εντυπωσιακά αποτελέσματα στο WMT16: μια βαθμολογία FMULT1 σε επίπεδο λέξεων 57,47% (ένα απόλυτο κέρδος +7,95% σε σχέση με την τρέχουσα κατάσταση της τεχνολογίας), και μια βαθμολογία συσχέτισης Pearson 65,56% για πρόβλεψη σε επίπεδο πρότασης HTER (ένα απόλυτο κέρδος +13,36%).', 'hu': 'A fordítási minőség becslése egyre nagyobb jelentőséggel bír az NLP-ben, mivel az emberi erőfeszítéseket zavaró módon csökkentheti. Ezt a potenciált azonban jelenleg a meglévő rendszerek viszonylag alacsony pontossága korlátozza. Jelen tanulmányban figyelemreméltó fejlődést érünk el a szószintű minőségbecslés és az automatikus utószerkesztés közötti szinergiák kiaknázásával. Először egy új, gondosan megtervezett neurális modellt rakunk össze egy gazdag funkcióalapú szó-szintű minőségbecslési rendszerbe. Ezt követően egy automatikus utószerkesztő rendszer kimenetét használjuk kiegészítő funkcióként, amely feltűnő eredményeket ér el WMT16-on: 57,47% szószintű FMULT1 pontszám (abszolút nyereség +7,95% a technika jelenlegi állapotához képest), és 65,56% Pearson korrelációs pontszám mondatszintű HTER előrejelzéshez (abszolút nyereség +13,36%).', 'ka': 'გადაწყვეტილების საფრძოლოობის განსაზღვრება არის NLP-ში მნიშვნელოვანი საქმე, რომელიც მისი პოტენციალური შესაძლებლობად ადამიანის მსოფლიოსების შემცირებას შემცირებას მაგრამ, ეს პონტენციალი ახლა მხოლოდ არსებობს სისტემების relatively low precision. ამ დოკუნში ჩვენ გავაკეთებთ შესანიშვნელოვანი დაბრუნებების გამოყენებით სინერგიების შესახებ სიტყვების კოლექტურის განსაზღვრება და ავტომატური დარედაქტირება. პირველი, ჩვენ ახალი, გრძნობად ინეზინერიული, ნეიროლური მოდელში სიტყვების საფუძველი სიტყვების საფუძველი სიტყვების სისტემაში დავყენებთ. შემდეგ ჩვენ გამოყენებთ ავტომატური დარედაქტირების სისტემის გამოყენებას როგორც ახალი ფუნქცია, როგორც WMT16-ზე გამოყენებული გამოყენება: სიტყვების დონე FMULT1 წერტილი 57,47% (სიტყვების ამოყენება +7,95% წერტილის მიმდინარე სისტემის განმავლობაზე) და პერჟონის კორელაციის წერ', 'it': "La stima della qualità della traduzione è un compito di crescente importanza nel PNL, a causa del suo potenziale di ridurre lo sforzo umano post-editing in modi dirompenti. Tuttavia, questo potenziale è attualmente limitato dalla precisione relativamente bassa dei sistemi esistenti. In questo articolo, otteniamo notevoli miglioramenti sfruttando le sinergie tra i compiti correlati di stima della qualità a livello di parola e post-editing automatico. In primo luogo, impiliamo un nuovo modello neurale accuratamente ingegnerizzato in un ricco sistema di stima della qualità a livello di parole basato su funzionalità. Poi, utilizziamo l'output di un sistema automatico di post-editing come funzionalità aggiuntiva, ottenendo risultati sorprendenti su WMT16: un punteggio FMULT1 a livello di parola del 57,47% (un guadagno assoluto del +7,95% rispetto allo stato attuale dell'arte), e un punteggio di correlazione Pearson del 65,56% per la previsione HTER a livello di frase (un guadagno assoluto del +13,36%).", 'lt': 'Vertimo kokybės vertinimas yra vis svarbesnis NLP uždavinys, nes jis gali sutrikdyti žmogaus pastangas po redakcijos. Tačiau šiuo metu šį potencialą riboja palyginti mažas esamų sistemų tikslumas. Šiame dokumente pasiekiame pastebimus patobulinimus naudojant sąveiką tarp susijusių užduočių, susijusių su žodžių kokybės vertinimu ir automatiniu po redagavimo. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  Tuomet mes naudojame automatinės po redakcijos sistemos rezultatus kaip papildomą savybę, gaudami įspūdingų rezultatų WMT16: žodžio lygio FMULT1 balas 57,47 % (absoliutus padidėjimas +7,95 % palyginti su dabartine pažangiąja technika) ir Pearson koreliacijos balas 65,56 % už sakinių lygio HTER prognozę (absoliutus padidėjimas +13,36 %).', 'kk': 'Аудару сапасының бағалауы - NLP дегенде көп маңызды тапсырмасын өзгерту мүмкіндігін өзгерту үшін адамдардың өзгерту жұмысын өзгерту мүмкіндігін көшірмелейтін жұ Бұл мүмкіндік қазіргі уақытта бар жүйелердің салыстырмалы дұрыстығы шектелген. Бұл қағазда сөз деңгейінің сапасының бағалауын және автоматты түрде өңдеу үшін синергиялық тапсырмалардың арасындағы көп жақсартылығын жеткіземіз. Біріншіден, біз жаңа, тәжірибелі инженерлі, невралдық моделін сөз деңгейіндегі сапатты бағалау жүйесіне тастадық. Содан кейін, WMT16 деңгейінде автоматты өңдеу жүйесінің шығысын қосымша мүмкіндігі ретінде қолданамыз: сөз деңгейіндегі FMULT1 деңгейіндегі 57, 47% нәтижесі (суреттің күйінде абсолютті +7, 95% нәтижесі) және Pearson кореляциясы 65, 56% нәтижесін HTER деңгейінде (абсолютті +13, 36%', 'ms': 'Penghargaan kualiti terjemahan adalah tugas yang berkembang penting dalam NLP, disebabkan potensi untuk mengurangkan usaha manusia selepas edisi dengan cara yang mengganggu. Namun, potensi ini kini terbatas oleh ketepatan relatif rendah sistem yang wujud. Dalam kertas ini, kita mencapai perbaikan yang luar biasa dengan mengeksploitasi sinergi antara tugas berkaitan penghargaan kualiti aras perkataan dan post-edisi automatik. Pertama, kita tumpukan model saraf baru, yang direka dengan hati-hati, ke dalam sistem penghargaan kualiti aras perkataan berbasis ciri-ciri yang kaya. Kemudian, kita gunakan output sistem pos-edisi automatik sebagai ciri tambahan, mendapatkan hasil menakjubkan pada WMT16: skor aras perkataan FMULT1 57.47% (keuntungan mutlak +7.95% atas keadaan seni semasa), dan skor korelasi Pearson 65.56% untuk prediksi aras kalimat HTER (keuntungan mutlak +13.36%).', 'mk': 'Проценката на квалитетот на преводот е задача со сé поголема важност во НЛП, поради нејзиниот потенцијал за намалување на човечките напори по изданието на прекршителни начини. Сепак, овој потенцијал моментално е ограничен од релативно ниска точност на постојните системи. Во овој документ, постигнуваме извонредни подобрувања со искористување на синергиите помеѓу поврзаните задачи на проценка на квалитетот на зборот и автоматско постуредување. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  Потоа, го користиме излезот на автоматски постуредувачки систем како дополнителна карактеристика, добивајќи врзувачки резултати на WMT16: резултат на зборно ниво FMULT1 од 57,47% (апсолутна добивка од +7,95% во однос на сегашната техничка состојба) и резултат на корелација на Pearson од 65,56% за предвидување на речениците на ниво HTER (апсолутна добивка од +', 'ml': 'അഭിപ്രായശ്ചിത്രത്തിനുശേഷം മനുഷ്യരുടെ പരിശ്രമം കുറവാക്കാനുള്ള സാധ്യതയാണ് NLP-ല്\u200d വളര്\u200dച്ച പ്രധാനപ്പെടുത്തുന്നത്. എന്നാലും നിലവിലുള്ള സിസ്റ്റത്തിന്റെ കുറച്ച് കുറച്ചുകൂടി ഈ സാധ്യതകള്\u200d നിലനില്\u200dക്കുന്നു. ഈ പത്രത്തില്\u200d, വാക്ക്-നില മാന്യത്തിന്റെ വിചാരണയും സ്വയം എഡിറ്ററിങ്ങിനും തമ്മിലുള്ള സങ്കീര്\u200dജികള്\u200d ഉപയോഗിക്കുന്നതിനാല്\u200d നമു First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  പിന്നെ നമ്മള്\u200d ഒരു സ്വയം എഡിറ്ററിങ്ങ് സിസ്റ്റത്തിന്റെ ഫലം കൂടുതലായി ഉപയോഗിക്കുന്നു. WMT16-ല്\u200d അടിക്കുന്ന ഫലങ്ങള്\u200d ലഭ്യമാക്കുന്നു. വാക്ക്- നില FMULT1 സ്കോര്\u200d 57. 47% (ഇപ്പോഴത്തെ കലാകാരത്തിലെ സ്ഥിതിയില്\u200d നിന്നും മുഴുവന', 'mt': 'L-istima tal-kwalità tat-traduzzjoni hija kompitu ta’ importanza dejjem akbar fil-NLP, minħabba l-potenzjal tagħha li tnaqqas l-isforz uman wara l-edizzjoni b’modi ta’ tfixkil. Madankollu, dan il-potenzjal bħalissa huwa limitat mill-preċiżjoni relattivament baxxa tas-sistemi eżistenti. F’dan id-dokument, inkisbu titjib notevoli billi nisfruttaw is-sinerġiji bejn il-kompiti relatati tal-istima tal-kwalità fil-livell tal-kliem u l-post-edizzjoni awtomatika. L-ewwel nett, inġabru mudell newrali ġdid, imfassal bir-reqqa, f’sistema rikka ta’ stima tal-kwalità bbażata fuq karatteristiċi. Imbagħad, a ħna nużaw il-ħruġ ta’ sistema awtomatika ta’ wara l-edizzjoni bħala karatteristika addizzjonali, li jiksbu riżultati affettwati fuq WMT16: punteġġ FMULT1 fil-livell tal-kliem ta’ 57.47% (żieda assoluta ta’ +7.95% fuq l-istat attwali tal-aħħar), u punteġġ ta’ korrelazzjoni Pearson ta’ 65.56% għat-tbassir HTER fil-livell tas-sentenza (żieda assoluta ta’ +13.36%).', 'ro': 'Estimarea calității traducerii este o sarcină din ce în ce mai importantă în PNL, datorită potențialului său de a reduce efortul uman post-editare în moduri disruptive. Cu toate acestea, acest potențial este limitat în prezent de precizia relativ scăzută a sistemelor existente. În această lucrare, realizăm îmbunătățiri remarcabile prin exploatarea sinergiilor dintre sarcinile aferente de estimare a calității la nivel de cuvânt și post-editare automată. În primul rând, punem un nou model neuronal, proiectat cu grijă, într-un sistem bogat de evaluare a calității la nivel de cuvânt bazat pe caracteristici. Apoi, folosim rezultatele unui sistem automat de post-editare ca o caracteristică suplimentară, obținând rezultate uimitoare pe WMT16: un scor FMULT1 la nivel de cuvânt de 57,47% (un câștig absolut de +7,95% față de starea actuală a tehnologiei), și un scor de corelație Pearson de 65,56% pentru predicția HTER la nivel de frază (un câștig absolut de +13,36%).', 'pl': 'Ocena jakości tłumaczeń jest zadaniem o coraz większym znaczeniu w NLP, ze względu na jego potencjał zmniejszenia wysiłku człowieka po edycji w sposób zakłócający. Potencjał ten jest jednak obecnie ograniczony stosunkowo niską dokładnością istniejących systemów. W niniejszym artykule osiągamy znaczące ulepszenia poprzez wykorzystanie synergii pomiędzy związanymi z nimi zadaniami oceny jakości na poziomie słowa a automatyczną postedycją. Najpierw układamy nowy, starannie zaprojektowany model neuronowy w bogaty system oceny jakości słowa oparty na funkcjach. Następnie wykorzystujemy wyjście automatycznego systemu post-edycji jako dodatkową funkcję, uzyskując uderzające wyniki na WMT16: wynik FMULT1 na poziomie słowa 57,47% (bezwzględny wzrost +7,95% w stosunku do aktualnego stanu techniki) oraz wynik korelacji Pearsona 65,56% do przewidywania HTER na poziomie zdania (bezwzględny wzrost +13,36%).', 'mn': 'Хүн төрөлхтний цаг хураагдахын тулд хүн төрөлхтний хичээл бууруулах боломжтой болохоор NLP-д нэмэгдэх чухал ажил юм. Гэхдээ энэ потенциал одоо байгаа системийн харьцангуй бага зөвхөн хязгаарлагддаг. Энэ цаасан дээр бид үг-түвшинд хамааралтай ажил болон автоматжуулагчийн дараа зохион байгуулалтын хоорондох гайхалтай сайжруулалт гаргадаг. Эхлээд бид шинэ, анхаарлын инженерчлэл, мэдрэлийн загварыг баян чанартай үгний түвшинд баялагдсан хэмжээний шагналын системд оруулж байна. Дараа нь бид WMT16 дээрх автоматик цахим хураагдах системийн үр дүнг нэмэлт шинжлэх ухаан болгон ашиглаж байна: үгний түвшинд FMULT1 оноо 57,47% (урлагийн орчинд нэмэлт нэмэлт +7,95%), мөн Персон хэмжээний HTER түвшинд 65,56% (бүтэн нэмэлт +13,36%) байдаг.', 'si': 'වාර්ථාව ක්\u200dරියාත්මක විශේෂය NLP වල වැඩි වැඩි වැඩි වැඩේ වැඩි වැඩි වැඩි වැඩි වැඩියි, මිනිස්සුන්ගේ පස්සේ සංප නමුත්, මේ ප්\u200dරතිශ්නයක් දැනටමත් ඉතින් පද්ධතියේ සාමාන්\u200dයයෙන් අඩුම සැකසුම් වලින් සීමාව මේ පත්තරේ අපිට පුළුවන් පුළුවන් විශේෂතාවක් ලැබෙනවා, වචන ප්\u200dරමාණය සහ ස්වයංක්\u200dරියාත්මක පස්සේ සම්බන්ධතාවක් ප්\u200dර මුලින්, අපි අළුත්, පරික්ෂාවෙන් ඉංජිනියාර් කරලා තියෙන්නේ, න්\u200dයූරාල් මොඩේල් එකක් විශේෂයෙන් අධ ඊට පස්සේ, අපි ස්වයංක්\u200dරියාත්මක පස්ස සංපාදනය පද්ධතියේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරත', 'sr': 'Očekivanje kvalitete prevoda je zadatak povećanja važnosti u NLP-u zbog njegovog potencijala da smanji posteditanje ljudskih napora na prekršavajući način. Međutim, ovaj potencijal je trenutno ograničen relativno niskom preciznošću postojećih sustava. U ovom papiru postižemo izvanredne poboljšanje iskorištavanjem sinergije između povezanih zadataka procjene kvalitete reči-nivoa i automatskog posledišnjeg redakcije. Prvo, stavljamo novi, pažljivo inženjerirani, neuralni model u bogat sistem za procjenu kvalitete reèi na nivou. Onda koristimo rezultat automatskog posturednog sistema kao dodatnu funkciju, dobivajući rezultate udaraca na WMT16: rezultat reči na nivou FMULT1 od 57,47% (apsolutno dobijanje +7,95% iznad trenutnog stanja umjetnosti), i rezultat korelacije Pearson a od 65,56% za predviđanje na nivou HTER rečenica (apsolutno dobijanje +13,36%).', 'so': "Qiimeynta qiimeynta turjumista waa shaqada koritaanka muhiimka NLP, sababtoo ah awooddiisa inay hoos u dhigto hawlaha dadka si khatar ah oo dib loo hagaajiyo. Si kastaba ha ahaatee, suurtagalkan waxay ku xadanyihiin saxda hoos ee nidaamka joogta. Warqadan waxaynu ku gaadhnaa kororooyin aad u fiican, si aan ugu baahno heerarka la xiriira shaqada qiimeynta heerka iyo sawirada dib-beddelka. Marka ugu horeysa, waxaynu sameynaynaa qaab cusub oo si taxadar leh oo neurada ah nidaamka qiimeynta qiimeynta saxda. Markaas waxaynu u isticmaalnaa nidaamka wax-editidda dib-u-qoridda, waxayna ka heli jireen midhaha wax jaban ee WMT16: heerka FMULT1 score 57.47% (faa'iido kamid ah +7.95% oo ka gaaraya xaaladda farshaxanka, iyo kooxda xiriirka ee Pearson oo ku xiran 65.56% oo wax ka sii sheegi karo heerka HTER (faa'iido kamid ah +13.36%).", 'sv': 'Bedömning av översättningskvalitet är en uppgift av växande betydelse i NLP, på grund av dess potential att minska mänsklig efterredigering på störande sätt. Denna potential begränsas dock för närvarande av att befintliga system är relativt låga. I den här uppsatsen uppnår vi anmärkningsvärda förbättringar genom att utnyttja synergier mellan relaterade uppgifter för kvalitetsbedömning på ordnivå och automatisk efterredigering. Först staplar vi en ny, noggrant konstruerad neural modell i ett rikt funktionsbaserat system för kvalitetsuppskattning på ordnivå. Sedan använder vi resultatet från ett automatiskt efterredigeringssystem som en extra funktion, vilket ger slående resultat på WMT16: en FMULT1-poäng på ordnivå på 57,47% (en absolut vinst på +7,95% jämfört med nuvarande state of the art), och en Pearson korrelationspoäng på 65,56% för HTER-förutsägelse på meningsnivå (en absolut vinst på +13,36%).', 'ta': 'மொழிபெயர்ப்பு தரம் மதிப்பீடு என்எல்பியில் முக்கியத்தை அதிகரிக்கும் பணியாகும், குழப்பமான வழிகளில் மனித முயற்சியை திருத் ஆனால், தற்போது இருக்கும் அமைப்புகளின் சுருக்கமாக குறைந்த துள்ளதால் இந்த சாத்தியம் வரம்பு உள்ளது. இந்த காகிதத்தில், சொல்ல- மட்டத்தின் மதிப்பு மதிப்பு மற்றும் தானாகவே தொகுப்பு பின் தொகுதியின் தொடர்புடைய செயல்களுக்கிடைய முதலில், நாம் ஒரு புதிய, கவனமாக பொறுத்தப்பட்ட, புதிய மாதிரியை பிடிக்கும் செல்லும் பணக்கூடிய கூட்டத்திற்கு அட பிறகு, நாம் தானாகவே திருத்தும் அமைப்பின் வெளியீட்டை கூடுதல் கூடுதலாக பயன்படுத்துகிறோம், WMT16 மீது வெளியீட்டை பெறுகிறது: வார்த்தை நிலை FMULT1 மதிப்பு 57. 47% (தற்போதைய கலைப்பாட்டில் உள்ள முழுமையான பெருக்கிய +7', 'no': 'Estimasjon av omsetjingskvalitet er ei oppgåve med økende viktighet i NLP på grunn av potensialen til å redusera menneskeinnpåverka etter redigering av menneskeinnpåverka på kortvaring. Denne potensialen er imidlertid begrenset av relativt låg nøyaktighet for eksisterande systemar. I denne papiret oppnår vi merkelige forbedringar ved å bruka synergi mellom dei relaterte oppgåva av estimerasjon av ordnivåkvaliteten og automatisk postredigering. Først stokker vi eit nytt, forsiktig inženjert, neuralmodell i eit rikt funksjonsbasert ordnivå-estimeringssystem. Så bruker vi utdata av eit automatisk postredigeringssystem som eit ekstra funksjon, og får streking resultat på WMT16: eit ordnivå FMULT1- poeng med 57,47% (ein absolutt høve av +7,95% over den gjeldande statusen av kunsten) og ein Pearson- korrelasjonspoeng med 65,56% for setningnivå HTER- forventing (ein absolutt høve av +13,36%).', 'ur': 'ترجمہ کی کیفیت کا ارزش NLP میں بڑھنے کا کام ہے، اس کی امکانات کے سبب کہ انسان کی کوشش ناکام طریقے سے کم کرے۔ لیکن یہ امکانات اکثر موجود سیستموں کی نسبت کم دقیق سے محدود ہے. اس کاغذ میں ہم بہت اچھے سفارش پہنچ رہے ہیں لفظ-سطح کی کیفیت کا ارزش اور سٹوٹی پست-ویڈینگ کے درمیان سئنرژی کا استعمال کر رہے ہیں. پہلے، ہم نے ایک نئی، دقت سے انجینر کی، نئورل موڈل کو ایک ثروتمند شخصیت پر بنیاد رکھا ہوا کلمات سطح کی قدر سیستم میں رکھا ہے. اس کے بعد ہم ایک اضافہ وی ٹی ٹی 16 پر استراکینگ نتیجے حاصل کریں گے۔ ایک کلمات-سطح FMULT1 اسکور 57.47% (کلمات کی موجود حالت پر +7.95% کا کامل فائدہ) اور پیرسون کی تعلق اسکور 65.56% (کلمات-سطح HTER کی پیش بینی کے لئے (بالکل فائدہ +13.36%).', 'uz': "Tarjima qiymati NLP'da muhim bo'lgan vazifasi, bu odamni tahrirlashdan keyin o'zgarishdan keyin qo'shish jarayonini kamaytirish mumkin. Lekin, bu hozir mavjud tizimning qisqa aniqligi bilan chegara. Bu qogʻozda biz murakkab yaxshi yaxshi o'zgarishni soʻz darajasi qiymati va avtomatik tahrirlash vazifalari orasidagi sinergiyalarni ishlatish mumkin. Birinchi so'zda, biz yangi tashkilotni taʼminlov bilan ishlab chiqaramiz, neyrol modelini taxminan soʻz darajasi qiymatni tizimga qo'yish. Keyin biz WMT16 uchun avtomatik tahrirlash tizimning natijasini qoʻshimcha imkoniyat sifatida foydalanamiz: so'zlar darajasi 57.47% (Joriy sanadagi holatda umuman tuzuvchi +7.95% va gapirish darajasi 65.56% uchun hech qanday bog'liq bo'lishi mumkin (javob +13.36%).", 'vi': 'Việc đánh giá chất lượng dịch là một nhiệm vụ ngày càng quan trọng trong chọc dò tủy sống, nhờ khả năng của nó có khả năng giảm nỗ lực làm gián đoạn sau việc. Tuy nhiên, tiềm năng này hiện tại bị hạn chế bởi độ chính xác tương đối thấp của hệ thống hiện tại. Trong tờ giấy này, chúng ta đạt được những cải tiến đáng chú ý bằng cách khai thác sự hợp tác giữa các công việc đánh giá chất lượng từ cấp và tự động sau biên tập. Đầu tiên, chúng ta xếp một mô hình thần kinh mới, được chế tạo cẩn thận thành một hệ thống đánh giá chất lượng từ có tính chất. Sau đó, chúng tôi sử dụng sản xuất của một hệ thống tổng hợp ngẫu nhiên sau đó là một tính năng phụ, đạt được kết quả ấn tượng về WRTT16: một từ cấp FMcảnh giác số 57.477.95= (một lợi ích tuyệt đối của +7.95=) trên trạng thái hiện thời), và một chuỗi Pierson tương ứng số lượng 85.5r=.* cho lời tiên đoán cấp HTER (một lợi tuyệt đối của +13.36=).', 'nl': 'De schatting van de vertaalkwaliteit is een taak van toenemend belang in NLP, vanwege het potentieel om post-editing menselijke inspanningen op verstorende manieren te verminderen. Dit potentieel wordt momenteel echter beperkt door de relatief lage nauwkeurigheid van bestaande systemen. In dit artikel bereiken we opmerkelijke verbeteringen door gebruik te maken van synergieën tussen de gerelateerde taken van kwaliteitsschatting op woordniveau en automatische post-editing. Eerst stapelen we een nieuw, zorgvuldig ontworpen neuraal model in een rijk functiegebaseerd kwaliteitsschattingssysteem op woordniveau. Vervolgens gebruiken we de output van een automatisch post-editing systeem als extra feature, waardoor we opvallende resultaten krijgen op WMT16: een FMULT1 score op woordniveau van 57,47% (een absolute winst van +7,95% ten opzichte van de huidige stand van de techniek), en een Pearson correlatiescore van 65,56% voor HTER voorspelling op zinnenniveau (een absolute winst van +13,36%).', 'hr': 'Očekivanje kvalitete prevoda je zadatak povećanja važnosti u NLP-u zbog mogućnosti smanjenja posturednog ljudskog napora na prekršavajući način. Međutim, ovaj potencijal trenutno ograničava relativno niska preciznost postojećih sustava. U ovom papiru postigli smo izvanredne poboljšanje koristeći sinergiju između povezanih zadataka procjene kvalitete riječi na razini i automatskog posledišnjeg redakcije. Prvo, stavljamo novi, pažljivo inženjerirani, neuralni model u bogat sistem procjene kvalitete riječi na razini. Onda koristimo rezultat automatskog posturednog sustava kao dodatni karakteristik, dobivajući rezultate udaraca na WMT16: rezultat na razini riječi FMULT1 od 57,47% (apsolutna dobit od +7,95% iznad trenutnog stanja umjetnosti) i rezultat korelacije Pearson a od 65,56% za predviđanje na razini rečenica HTER (apsolutna dobit od +13,36%).', 'da': 'Vurdering af oversættelseskvalitet er en opgave af voksende betydning i NLP på grund af dets potentiale til at reducere menneskelig indsats efter redigering på forstyrrende måder. Dette potentiale er imidlertid i øjeblikket begrænset af de eksisterende systemers relativt lave nøjagtighed. I denne artikel opnår vi bemærkelsesværdige forbedringer ved at udnytte synergier mellem de relaterede opgaver med kvalitetsestimering på ordniveau og automatisk efterredigering. Først stabler vi en ny, omhyggeligt konstrueret neural model i et rigt funktionsbaseret ordkvalitetsvurderingssystem. Derefter bruger vi resultatet fra et automatisk efterredigeringssystem som en ekstra funktion og opnår slående resultater på WMT16: en FMULT1-score på ordniveau på 57,47% (en absolut gevinst på +7,95% i forhold til den aktuelle state of te art) og en Pearson korrelation score på 65,56% for sætningsniveau HTER forudsigelse (en absolut gevinst på +13,36%).', 'bg': 'Оценката на качеството на превода е задача с нарастващо значение в НЛП, поради потенциала си да намали човешките усилия след редактиране по разрушителен начин. Този потенциал обаче понастоящем е ограничен от относително ниската точност на съществуващите системи. В тази статия постигаме забележителни подобрения чрез използване на синергии между свързаните задачи за оценка на качеството на думи и автоматична пост-редактиране. Първо, ние подреждаме нов, внимателно проектиран, невронен модел в богата система за оценка на качеството на думи, базирана на функции. След това използваме изхода на автоматична система за пост-редактиране като допълнителна функция, като получаваме поразителни резултати на ниво дума оценка от 57.47% (абсолютно увеличение от +7.95% спрямо текущото състояние на изкуството), и корелационен резултат на Пиърсън от 65.56% за прогнозиране на ниво изречение (абсолютно увеличение от +13.36%).', 'fa': 'ارزیابی کیفیت ترجمه یک کار بزرگی در NLP است، به دلیل پتانسیل آن برای کاهش تلاش\u200cهای انسان بعد از ویرایش کردن به راه\u200cهای نابودی. ولی این پتانسیل در حال حاضر با دقیق نسبتا کم سیستم موجود محدود شده است. در این کاغذ، ما با استفاده از هماهنگی بین وظیفه\u200cهای مربوط به ارزیابی کیفیت سطح کلمات و بعد از ویرایش خودکار، بهترین\u200cهای فوق العاده را به دست می\u200cآوریم. اول، ما یک مدل جدید، با دقت مهندسی شده، عصبی را در یک سیستم ارزیابی کیفیت سطح کلمات ثروتمندی قرار می دهیم. سپس، ما از نتیجه یک سیستم بعد ویرایش اتوماتیک به عنوان ویرایش اضافه استفاده می\u200cکنیم، نتیجه\u200cهای ضربه\u200cکننده بر WMT16: نقطه\u200cی کلمه FMULT1 از 57.47% (نقطه\u200cای کامل از +7.95% بر حالت فعلی هنر) و نقطه ارتباطی Pearson از 65.56% برای پیش\u200cبینی HTER طبقه\u200cی جمله\u200cها (نقطه کامل از +13.36%).', 'sw': 'Takwimu za kiwango cha tafsiri ni jukumu la kuongezeka kwa umuhimu katika NLP, kutokana na uwezekano wake wa kupunguza juhudi za watu baada ya kuhariri watu kwa njia za uharibifu. Hata hivyo, uwezekano huu kwa sasa umezuiwa na uhakika mdogo wa mifumo inayopo. Katika karatasi hii, tunapata maendeleo mabaya ya ajabu kwa kutumia synergie kati ya kazi zinazohusiana na uchunguzi wa kiwango cha kiwango cha maneno na kuhariri mara baada ya kuandika. Kwanza, tunaweka mtindo mpya ulioanzishwa kwa tahadhari, ubora katika mfumo wa uchunguzi wa kiwango cha kiwango cha maneno. Kisha, tunatumia matokeo ya mfumo wa kuhariri baada ya kujitegemea kama kipengele cha ziada, kupata matokeo ya mgogoro kwenye WMT16: score ya kiwango cha neno FMULT1 yenye 57.47% (faida ya jumla ya+7.95% zaidi ya hali ya sasa ya sanaa), na kiwango cha mahusiano cha Pearson kinachohusiana na asilimia 65.56 kwa kutabiri kiwango cha hukumu cha HTER (ongezeko la jumla la la la la +13.36%).', 'tr': "Çaltylyk kalitesinden baýramçylyk NLP'da ýetişmäge möhüm bolan täblisidir, adamlaryň edip eden soňra çalyşyny iň ýitirmek üçin. Ýöne bu potensial häzirki wagtda bar sistemalaryň dogry derejesi bilen çykardy. Bu kagyzda, söz derejesi howply hasaplamak we otomatik soňra editlemek üçin synergiýany ulanarak örän möhüm gelişmeleri başarýarys. Ilkinji gezek, täze, ünsli inženjeredilen, näyral nusgasyny baý özelliklere daýanýan söz derejesi hasaplamak sistemine çykardyk. Sonra, WMT16'de ýene-de çykyş netijesi bolan awtomatik taýýarlama sistemasyny ulanýarys. WMULT1-de söz derejesi 57.47% (häzirki möhümmetiň üstünde bolan +7.95% we Pearson-de çykyş derejesi HTER üçin 65.56% dyr.", 'af': "Vertaling van die kwaliteit-estimatie is 'n taak van groei belangrikheid in NLP, vanweë sy potensiele om die post-redigeering van menslike versoek te verminder op verdelege maniere. Maar hierdie potensieel is tans beperk deur die relativief lae presisie van bestaande stelsels. In hierdie papier, ons het remarkabele verbeteringe bereik deur synergies te gebruik tussen die verwante taak van woord-vlak kwaliteit-estimatie en outomatiese post-redigeering. Eerste, ons stap 'n nuwe, versigtig inženeer, neurale model binne 'n ryk funksie-gebaseerde woord-vlak-evaluiteringstelsel. Dan gebruik ons die uitvoer van 'n outomatiese post- redigeering stelsel as 'n ekstra funksie, wat verstrekking resultate op WMT16 verkry: ' n woord- vlak FMULT1 skaal van 57. 47% (' n absolute verskaf van +7. 95% oor die huidige staat van die kuns), en 'n Pearson korrelasie skaal van 65. 56% vir setvlak HTER voorskou (' n absolute verskaf van +13. 36%).", 'de': 'Die Schätzung der Übersetzungsqualität gewinnt im NLP-Bereich zunehmend an Bedeutung, da das Potenzial besteht, den menschlichen Aufwand nach der Bearbeitung auf disruptive Weise zu reduzieren. Dieses Potenzial wird derzeit jedoch durch die relativ geringe Genauigkeit bestehender Systeme begrenzt. In diesem Beitrag erzielen wir bemerkenswerte Verbesserungen, indem wir Synergien zwischen den damit verbundenen Aufgaben der Qualitätsschätzung auf Wortebene und der automatischen Nachbearbeitung nutzen. Zunächst stapeln wir ein neues, sorgfältig entwickeltes neuronales Modell in ein funktionsbasiertes Qualitätsschätzungssystem auf Wortebene. Dann nutzen wir die Ausgabe eines automatischen Post-Editing-Systems als zusätzliche Funktion, um beeindruckende Ergebnisse auf WMT16 zu erhalten: ein FMULT1-Score auf Wortebene von 57,47% (ein absoluter Gewinn von +7,95% gegenüber dem aktuellen Stand der Technik) und ein Pearson-Korrelationswert von 65,56% für HTER-Vorhersage auf Satzniveau (ein absoluter Gewinn von +13,36%).', 'am': 'ትርጉም ብልሃት የNLP አካባቢ ጉዳይ ነው፡፡ However, this potential is currently limited by the relatively low accuracy of existing systems.  በዚህ ፕሮግራም፣ የቃላት-ደረጃ ጥያቄ እና የፖስታ አስተካክል ማድረግ በሚያስተካክሉ ስራዎችን በመጠቀም እና የበለጠ ማስታወቂያ አግኝተናል፡፡ መጀመሪያ፣ አዲስ፣ በጥንቃቄ የጠጋ የፊደል ቃላት-ደረጃ መጠቀሚያ ስርዓት እናስቀምጣለን፡፡ ከዚህም በኋላ የፖስታ አስተካክል ስርዓት ውጤቱን WMT16 ላይ የሚያስጨንቅ ፍሬዎችን እንደገና እንጠይቃለን፤ የቃላት-ደረጃ FMULT1 score 57.47 በመቶ (የአሁኑ ክፍል ክፍል በሙሉ ጥቅም +7.95 በመቶ ክፍል እና የፋርሶን ግንኙነት ቁጥር 65.56 በመቶ ለፍርድ-ደረጃ HTER ትንቢት (ሙሉ ትርፍ +13.36 በመቶ ነው)።', 'id': 'Perkiraan kualitas terjemahan adalah tugas yang meningkat penting di NLP, karena potensi untuk mengurangi usaha manusia setelah edisi dengan cara yang mengganggu. Namun, potensi ini saat ini terbatas oleh akurasi relatif rendah sistem yang ada. Dalam kertas ini, kita mencapai perbaikan yang luar biasa dengan mengeksploitasi sinergi antara tugas berkaitan dengan penilaian kualitas tingkat kata dan post-edisi otomatis. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16: a word-level FMULT1 score of 57.47% (an absolute gain of +7.95% over the current state of the art), and a Pearson correlation score of 65.56% for sentence-level HTER prediction (an absolute gain of +13.36%).', 'hy': 'Թարգմանության որակի գնահատումը ավելի կարևոր է ՆԼՊ-ում, քանի որ դրա պոտենցիալն է խմբագրելուց հետո մարդկային ջանքերը խռովող ձևերով նվազեցնել: However, this potential is currently limited by the relatively low accuracy of existing systems.  Այս թղթի մեջ մենք հսկայական բարելավումներ ենք հասնում օգտագործելով սիներգիաները բառի մակարդակի որակի գնահատման և ավտոմատիկ հետխմբագրման հարաբերությունների միջև: First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  Հետո մենք օգտագործում ենք ավտոմատիկ հետխմբագրման համակարգի արտադրությունը որպես ավելին հատկություն, ստանում ենք զարմանալի արդյունքներ ԱՄԹ16-ի վրա. բառի մակարդակի FMULT1-ի 57.47 տոկոսը (բացարձակ շահույթ +7.95 տոկոսը ներկայիս տեխնոլոգիայի դեպքում), իսկ Պիրսոնի հարաբերակցության 65.56 տոկոսը նախադասության մակարդակի ՀՏԵ', 'bn': 'অনুবাদের মান হিসেব হচ্ছে এনএলপিতে গুরুত্বপূর্ণ বৃদ্ধি প্রদানের কারণে, বিভ্রান্ত উপায়ে মানুষ সম্পাদনার পরিশ্রম কমানোর কা তবে বর্তমানে এই সম্ভাবনা বিদ্যমান সিস্টেমের সামান্য সঠিকভাবে কম সীমাবদ্ধ। এই কাগজটিতে আমরা বিশাল উন্নতি পেয়েছি শব্দ-স্তরের মানের মান হিসেবে এবং স্বয়ংক্রিয়ভাবে সম্পর্কিত পরিমাণ সম্পাদনের মধ্যে সিনার্ প্রথমত, আমরা একটি নতুন, সাবধান ইঞ্জিনিয়ার, নিউরেল মডেলে একটি সমৃদ্ধ বৈশিষ্ট্য-ভিত্তিক শব্দ-স্তরের মান হিসেব ব্য তারপর আমরা স্বয়ংক্রিয়ভাবে সম্পাদনের পরিস্থিতির আউটপুট বিশেষ বৈশিষ্ট্য হিসেবে ব্যবহার করি, যার ফলাফল উইএমটি১৬-এ পাওয়া যাচ্ছে: একটি শব্দ-স্তরের FMULT1 স্কোর ৫৭. 47% (বর্তমান শিল্পের বর্তমান অবস্থায় ৭.', 'ko': '번역 품질 평가는 자연 언어 처리에서 점점 중요해지고 있다. 왜냐하면 편집 후의 인공 작업을 파괴적인 방식으로 줄일 수 있기 때문이다.그러나 기존 시스템의 정확도가 상대적으로 낮기 때문에 이런 잠재력은 현재 제한을 받고 있다.본고에서 우리는 단어급 품질 평가와 자동 후기 편집과 관련된 임무 간의 협동 작용을 이용하여 현저한 개선을 실현했다.우선, 우리는 정성스럽게 설계된 새로운 신경 모델을 풍부한 특징을 바탕으로 하는 어급 품질 평가 시스템에 중첩할 것이다.그리고 우리는 자동 후기 편집 시스템의 출력을 추가 기능으로 사용하여 WMT16에서 놀라운 결과를 얻었다. 단어급 FMULT1은 57.47%(현재 기술 수준에 비해 절대적 이득은 +7.95%), 문장급 HTER가 예측한 필슨 관련 점수는 65.56%(절대적 이득은 +13.36%)로 나타났다.', 'sq': 'Vlerësimi i cilësisë së përkthimit është një detyrë e rëndësisë në rritje në NLP, për shkak të potencialit të saj për të reduktuar përpjekjen njerëzore pas redaksionit në mënyra shqetësuese. Megjithatë, ky potencial është aktualisht i kufizuar nga saktësia relativisht e ulët e sistemeve ekzistuese. Në këtë letër, ne arrijmë përmirësime të çuditshme duke shfrytëzuar sinergitë midis detyrave lidhur me vlerësimin e cilësisë në nivelin e fjalës dhe pas-editimit automatik. Së pari, ne vendosim një model të ri, të ndërtuar me kujdes, neuronal në një sistem të pasur të vlerësimit të cilësisë në nivelin e fjalëve. Pastaj, ne përdorim daljen e një sistemi automatik pas-editimit si një karakteristikë shtesë, duke marrë rezultate goditëse në WMT16: një pikë FMULT1 në nivelin e fjalës 57.47% (një fitim absolut prej +7.95% mbi gjendjen aktuale të artit) dhe një pikë korrelacioni Pearson prej 65.56% për parashikimin e nivelit të fjalës HTER (një fitim absolut prej +13.36%).', 'cs': 'Odhadování kvality překladu je v NLP úkolem stále většího významu, protože jeho potenciál snižovat lidskou úsilí po editaci rušivým způsobem. Tento potenciál je však v současnosti omezen relativně nízkou přesností stávajících systémů. V tomto článku dosahujeme pozoruhodných zlepšení využitím synergie mezi souvisejícími úkoly odhadu kvality slova a automatické post editace. Nejprve složíme nový, pečlivě navržený neuronový model do bohatého systému odhadu kvality slov založeného na funkcích. Dále používáme výstup automatického post-editačního systému jako další funkci, který získává nápadné výsledky na WMT16: skóre FMULT1 na slovní úrovni 57,47% (absolutní zisk +7,95% nad současným stavem techniky) a Pearsonova korelační skóre 65,56% pro predikci HTER na úrovni věty (absolutní zisk +13,36%).', 'et': 'Tõlkekvaliteedi hindamine on NLP-s üha tähtsam ülesanne, kuna selle potentsiaal vähendab tööjärgset inimtööd katkestaval viisil. Seda potentsiaali piirab aga praegu olemasolevate süsteemide suhteliselt madal täpsus. Käesolevas dokumendis saavutame märkimisväärseid edusamme, kasutades ära sünergiat sõnatasemel kvaliteedi hindamise ja automaatse järeltöötluse vahel. Esiteks paneme uue hoolikalt projekteeritud närvimudeli rikkalikuks funktsioonipõhiseks sõnatasemel kvaliteedi hindamise süsteemiks. Seejärel kasutame lisafunktsioonina automaatse järeltöötlussüsteemi väljundit, saavutades WMT16 puhul silmatorkavad tulemused: sõnataseme FMULT1 skoor 57,47% (absoluutne kasum +7,95% võrreldes praeguse tehnika tasemega) ja Pearsoni korrelatsiooni skoor 65,56% lausetaseme HTER ennustamisel (absoluutne kasum +13,36%).', 'bs': 'Očekivanje kvalitete prevoda je zadatak povećanja važnosti u NLP-u zbog njegovog potencijala smanjiti nakon redakcije ljudskih napora na prekršavajući način. Međutim, ovaj potencijal trenutno ograničava relativno niska preciznost postojećih sustava. U ovom papiru postignemo izvanredne poboljšanje koristeći sinergiju između povezanih zadataka procjene kvalitete riječi na nivou i automatske posledice redakcije. Prvo, stavljamo novi, pažljivo inženjerirani, neuralni model u bogat sistem za procjenu kvalitete riječi na nivou. Onda koristimo rezultat automatskog posturednog sistema kao dodatni karakteristik, dobivajući rezultate udaraca na WMT16: rezultat riječi na nivou FMULT1 od 57,47% (apsolutno dobijanje +7,95% iznad trenutnog stanja umjetnosti), i rezultat korelacije Pearson a od 65,56% za predviđanje na nivou HTER rečenica (apsolutno dobijanje od +13,36%).', 'fi': 'K채채nn철slaadun arviointi on NLP:ss채 yh채 t채rke채mpi teht채v채, koska sen potentiaali v채hent채채 j채lkimuokkauksen inhimillist채 ty철t채 h채iritsev채ll채 tavalla. T채t채 potentiaalia rajoittaa kuitenkin nykyisten j채rjestelmien suhteellisen alhainen tarkkuus. T채ss채 artikkelissa saavutamme merkitt채vi채 parannuksia hy철dynt채m채ll채 synergiaa sanatason laadun arvioinnin ja automaattisen j채lkimuokkauksen v채lill채. Ensin kasaamme uuden, huolellisesti suunnitellun neuromallin rikkaaseen ominaisuuspohjaiseen sanatason laadunvarmistusj채rjestelm채채n. T채m채n j채lkeen k채yt채mme automaattisen j채lkimuokkausj채rjestelm채n tuotosta ylim채채r채isen채 ominaisuutena, jolloin WMT16:lla saadaan silmiinpist채vi채 tuloksia: sanatason FMULT1-pistem채채r채 57,47% (absoluuttinen voitto +7,95% nykytekniikkaan verrattuna) ja Pearsonin korrelaatiopistem채채r채 65,56% lausetason HTER-ennusteessa (absoluuttinen voitto +13,36%).', 'az': "Tərcümə kaliteli hesablaması NLP'də böyüklük mövcuddur, insan çabalarını dəyişiklik yollarında azaltmaq üçün potensialı olaraq. Halbuki bu potensial həmin vaxt mövcud sistemlərin relativi düşük precizitəsi ilə sınırlandırılır. Bu kağızda, sözlər seviyyəti qiyməti və avtomatik post-editing işləri arasında sinergiya istifadə edərək möhtəşəm təmizlənəcəyik. İlk dəfə, yeni, dikkatli inženjerli, nöral modeli, baxımınca söz seviyyəti qiyməti sisteminə yerləşdiririk. Sonra, WMT16 üstündə müxtəlif sonuçlar almaq üçün automatik post-editing sisteminin istifadəsini istifadə edirik: söz seviyyəsi FMULT1 dərəcəsi 57,47% (sanatın hökmünün üstündə mütləq +7,95%-dən art ıq kazanmış və Pearson bağlantı dərəcəsi 65,56%-dən artıq HTER təsiri üçün (mütləq +13,36%).", 'ca': "L'estimació de la qualitat de la traducció és una tasca de creixent importància en NLP, degut al seu potencial de reduir l'esforç humà després d'edició de maneres disruptives. Però actualment aquest potencial està limitat per la relativament baixa precisió dels sistemes existents. En aquest paper, aconsegueixem millors notables explotant sinergies entre les tasques relacionades de l'estimació de qualitat a nivell de paraules i la postedició automàtica. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  Després, utilitzem la producció d'un sistema automàtic de postedició com una característica extra, obtenint resultats impressionants en WMT16: una puntuació FMULT1 de nivell de paraules de 57,47% (un guany absolut de +7,95% sobre l'estat actual de l'art), i una puntuació de correlació Pearson de 65,56% per predicció HTER de nivell de frases (un guany absolut de +13,36%).", 'ha': "Kimat na sifar fassarar ta zama wani aikin ta ƙara muhimmin a NLP, saboda haka da awonsa ya ƙara aikin mutum a bayan editorin-daban. A lokacin da ake ƙayyade wannan awon a yanzu, yana da gwargwadon ƙayyadadde na'urar da ke jira. Ga wannan takardan, za mu sami mafiya kyauta mai girma game da isticmin sunergi a tsakanin aikin da aka yi danganta a kan ma'anar-daraja da taƙaitar-daraja farat-editi. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system.  Sa'an nan, Munã yi amfani da matsalar na farat-editi kamar wata sifati na ƙara, kana sami matsayin mai nuna a WMT16an: wata nau'in-magana FMULT1 na nau'in 57.47% (mai cikakken amfani da+7.95% kan halin da ke yanzu na sanar), da kuma an sami karatun na Pearson da muhalli na 65,65% ga basĩri-daraja na HTeR (mai cikakken fatauci na+13,36%).", 'sk': 'Ocenjevanje kakovosti prevodov je naloga naraščajočega pomena v NLP zaradi potenciala zmanjšanja človeškega napora po urejanju na moteče načine. Vendar je ta potencial trenutno omejen zaradi relativno nizke natančnosti obstoječih sistemov. V prispevku dosegamo izjemne izboljšave z izkoriščanjem sinergij med povezanimi nalogami ocenjevanja kakovosti besed na ravni in avtomatičnega post-urejanja. Prvič, nov, skrbno zasnovan, nevronski model zložimo v bogat sistem ocenjevanja kakovosti besed na ravni, ki temelji na funkcijah. Nato kot dodatno funkcijo uporabimo rezultat avtomatskega sistema za post-editiranje, pri čemer pri WMT16 dosežemo osupljive rezultate: rezultat FMULT1 na ravni besed 57,47% (absolutni dobiček +7,95% v primerjavi s trenutnim stanjem tehnike) in Pearsonova korelacijska ocena 65,56% za napoved HTER stavka (absolutni dobiček +13,36%).', 'jv': 'Tulung kaliwat tahirbah kuwi nggawe langkung wigatining nggawe barang NLP, kaya sak nggawe ngubah ujak-ujak ngubah apat-ujak wigatining maneh. Nanging, potansi iki dadi nyimpen langkung rawut bandakan sistem sing bisa pasar awak dhéwé. Nang pepulan iki, kita sampeyan akeh bantayan kanggo nguasai seneng nggawe seneng nggawe gerakan kelas nggawe barang langar kuwi tindakan keamanan karo perusahaan langar Awak dhéwé, ngéwé stabil sistem sing bagian, sawar-sawar inênjer, model nêrasal kanggo mbaar-sistem kuwi kesempatan gambar kuwi. politenessoffpolite"), and when there is a change ("assertive', 'he': 'הערכת איכות התרגום היא משימה של חשיבות גדולה ב-NLP, בגלל הפוטנציאל שלה להפחית מאמץ אנושי לאחר העורה בדרכים מפריעות. עם זאת, הפוטנציאל הזה מוגבל כרגע על ידי מדויקת נמוכה יחסית של מערכות קיימות. בעיתון הזה, אנו משיגים שיפורים מדהימים על ידי ניצל סינרגיות בין המשימות הקשורות של הערכת איכות רמת מילים ולאחר העורר אוטומטי. קודם כל, אנו מעמידים מודל עצבי חדש, שנהנדס בזהירות לתוך מערכת ערכות איכות מילים עשירה מבוססת על תכונות. ואז, אנחנו משתמשים בתוצאה של מערכת לאחר העורה אוטומטית כתכונה נוספת, להשיג תוצאות מדהימות על WMT16: נקודת רמת מילים FMULT1 של 57.47% (רווח מוחלט של +7.95% על המצב הנוכחי של האמנות), ו נקודת הקשר של פירסון של 65.56% על צפוי רמת המשפט HTER (רווח מוחלט של +13.36%).', 'bo': 'NLP ནང་དུ་ཚོར་བསྒྱུར་བའི་རྐྱེན་ཚད་ལྡན་པར་མཐོང་ནུས་པ་ཞིག་ཡིན་པས། མི་རྐྱེན་པས་རྗེས་བསྒྱུར་བཅོས་དང་མི་རྐྱེན་ཚད་ཉེན ཡིན་ནའང་། རྒྱུ་ནུས་འདི་ད་ལྟར་གནས་ཡོད་པའི་མ་ལག་གི་བདེ་འཇགས་ཚད་ཉུང་བའི་ཐོག་ཚད་བསྡད་ཡོད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system. Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16: a word-level FMULT1 score of 57.47% (an absolute gain of +7.95% over the current state of the art), and a Pearson correlation score of 65.56% for sentence-level HTER prediction (an absolute gain of +13.36%).'}
{'en': 'Winning on the Merits : The Joint Effects of Content and Style on Debate Outcomes', 'ar': 'الفوز بالمزايا: التأثيرات المشتركة للمحتوى والأسلوب على نتائج المناقشة', 'pt': 'Vencendo pelos méritos: os efeitos conjuntos de conteúdo e estilo nos resultados do debate', 'es': 'Ganar por los méritos: los efectos conjuntos del contenido y el estilo en los resultados del debate', 'ja': 'メリットの勝利：ディベート結果に対するコンテンツとスタイルの共同効果', 'zh': '择优胜:义与风同', 'ru': 'Победа по существу: совместный эффект содержания и стиля на итоги дебатов', 'fr': 'Gagner sur le fond\xa0: les effets conjoints du contenu et du style sur les résultats des débats', 'hi': 'गुण पर जीतना: बहस के परिणामों पर सामग्री और शैली के संयुक्त प्रभाव', 'ga': 'Buachan de réir Fiúntais: Comhéifeachtaí Ábhar agus Stíl ar Thorthaí Díospóireachta', 'ka': 'მერიტებზე გავიღება: Content and Style- ის ერთმანეთი ეფექტი განსაზღვრების შემდეგ', 'el': 'Κερδίζοντας στις Αξίες: Οι κοινές επιπτώσεις του περιεχομένου και του στυλ στα αποτελέσματα της συζήτησης', 'hu': 'A tartalom és a stílus közös hatásai a vita eredményeire', 'it': 'Vincere al merito: gli effetti congiunti di contenuto e stile sui risultati del dibattito', 'kk': 'Біріктіру үшін жетілдіру: Мазмұны мен стилінің біріктірілген эффекттері', 'mk': 'Победувањето на заслугите: Заедничките ефекти на содржината и стилот на резултатите на дебатата', 'ms': 'Pemenangan pada Merit: Kesan Bersama Kandungan dan Gaya pada Hasil Debat', 'ml': 'മെറിറ്റുകളില്\u200d വിജയിക്കുന്നു: ഉള്ളടക്കത്തിന്റെയും ശൈലിയുടെയും യൂണ്ടെന്റ് പ്രഭാവങ്ങള്\u200d', 'mn': 'Холбоонд ялсан: Дэлхийн үр дүн болон хэлбэрийн нийлбэр нөлөө', 'mt': 'Ir-rebbieħ fuq il-Meriti: L-Effetti Konġunti tal-Kontenut u l-Istil fuq ir-Riżultati tad-Dibattitu', 'no': 'Winner på fleire: The Joint Effects of Content and Style on Debate Outcomes', 'ro': 'Câștigarea meritelor: Efectele comune ale conținutului și stilului asupra rezultatelor dezbaterii', 'pl': 'Zwycięstwo z zasług: Wspólny wpływ treści i stylu na wyniki debaty', 'sr': 'Pobedba na Meritima: zajednički efekti sadržaja i stila na ishod debata', 'si': 'මෙරිට්ස් වලට ජයග්\u200dරහණය: The united Efects of Contexts and Style on debate OutCome', 'so': 'Winning on the Merits: The Joint Effects of Content and Style on Debate Outcomes', 'sv': 'Vinnande av förtjänst: De gemensamma effekterna av innehåll och stil på debattresultat', 'lt': 'Gavimas pelnui: Bendras turinio ir stilio poveikis diskusijų rezultatams', 'ta': 'Winning on the Merits: The Joint Effects of Content and Style on Debate Outcomes', 'ur': 'مریٹوں پر غالب رہا ہے: ڈیبٹ نتیجے پر Content and Style Joint Effects', 'uz': 'Name', 'vi': 'Thắng lợi lộc: Hiệu ứng kết hợp của nội dung và phong cách lên kết quả cuộc tranh luận', 'bg': 'Спечелване на заслугите: съвместните ефекти на съдържанието и стила върху резултатите от дебата', 'hr': 'Pobjeđenje na spojenicama: zajednički učinak sadržaja i stila na ishod rasprave', 'da': 'Vind af fortjenester: De fælles virkninger af indhold og stil på debat resultater', 'nl': 'Winnen op de verdiensten: De gezamenlijke effecten van inhoud en stijl op debaatresultaten', 'de': 'Verdienste gewinnen: Die gemeinsamen Auswirkungen von Inhalt und Stil auf Debattenergebnisse', 'ko': '장점으로 이기기: 내용과 풍격이 변론 결과에 미친 연합 영향', 'id': 'Pemenangan pada Merit: Efek Bersama-sama dari Kandungan dan Gaya pada Hasil Debat', 'fa': 'برنده در متحد: اثرات متحد و استیل در نتیجه\u200cهای بحث', 'sw': 'Washinda kwenye Merit: Effects of the Joint of Contents and Style on the Battle of Matokeo', 'sq': 'Fitimi në meritat: Efektet e përbashkëta të përmbajtjes dhe stilit mbi rezultatet e debatit', 'tr': 'Geçmişi Poz', 'af': 'Winning op die saamgevlans: Die saamgevlans effekte van Inhoud en Styl op Debate Outcomes', 'am': 'The Joint Effects of Content and Style on Debate Outcomes', 'hy': 'Winning on the Merits: The Joint Effects of Content and Style on Debate Outcomes', 'az': 'Meritlərdə qələbə çatdı: İçindəki və Tərcləmə Növbələrinin İşləri', 'bn': 'বিতর্কের বিষয়ে বিজয়ী হচ্ছে: বিষয়বস্তু এবং স্টাইলের যৌথ প্রভাব', 'bs': 'Pobjeda na Meritima: zajednički efekti sadržaja i stila na ishod debata', 'ca': "La guanyada dels mérits: Els efectes conjunts del contingut i l'estil en els resultats de la debat", 'cs': 'Vítězství v zásluhách: Společné vlivy obsahu a stylu na výsledky debat', 'et': 'Teenete võitmine: sisu ja stiili ühine mõju arutelutulemustele', 'fi': 'Ansioiden voittaminen: Sisällön ja tyylin yhteisvaikutukset keskustelun tuloksiin', 'jv': 'Winter Jabber', 'sk': 'Zmaga na zaslugi: Skupni učinki vsebine in sloga na rezultate razprave', 'he': 'ניצחון על הרווחים: השפעות המשותפות של תוכן וסגנון על תוצאות הדיבוי', 'ha': 'The Join Effects of Content and Style on Debate Outcomes', 'bo': 'Winning on the Merits: The Joint Effects of Content and Style on Debate Outcomes'}
{'en': 'Debate and deliberation play essential roles in politics and government, but most models presume that debates are won mainly via superior style or agenda control. Ideally, however, debates would be won on the merits, as a function of which side has the stronger arguments. We propose a predictive model of debate that estimates the effects of linguistic features and the latent persuasive strengths of different topics, as well as the interactions between the two. Using a dataset of 118 Oxford-style debates, our model’s combination of content (as latent topics) and style (as linguistic features) allows us to predict audience-adjudicated winners with 74 % accuracy, significantly outperforming linguistic features alone (66 %). Our model finds that winning sides employ stronger arguments, and allows us to identify the linguistic features associated with strong or weak arguments.', 'ar': 'يلعب النقاش والمداولات أدوارًا أساسية في السياسة والحكومة ، لكن معظم النماذج تفترض أن المناظرات يتم كسبها بشكل أساسي من خلال الأسلوب المتفوق أو التحكم في جدول الأعمال. من الناحية المثالية ، ومع ذلك ، يمكن الفوز بالمناقشات حول المزايا ، كوظيفة للجانب الذي لديه الحجج الأقوى. نقترح نموذجًا تنبئيًا للنقاش الذي يقدر آثار السمات اللغوية ونقاط القوة المقنعة الكامنة في الموضوعات المختلفة ، فضلاً عن التفاعلات بين الاثنين. باستخدام مجموعة بيانات من 118 مناقشة على غرار أكسفورد ، يتيح لنا مزيج نموذجنا من المحتوى (كمواضيع كامنة) والأسلوب (كميزات لغوية) التنبؤ بالفائزين المحكوم عليهم من قبل الجمهور بدقة 74٪ ، متفوقًا بشكل كبير على الميزات اللغوية وحدها (66٪). وجد نموذجنا أن الأطراف الفائزة تستخدم حججًا أقوى ، ويسمح لنا بتحديد السمات اللغوية المرتبطة بالحجج القوية أو الضعيفة.', 'es': 'El debate y la deliberación desempeñan papeles esenciales en la política y el gobierno, pero la mayoría de los modelos presumen que los debates se ganan principalmente mediante un estilo superior o un control de la agenda. Sin embargo, lo ideal sería que los debates se ganaran sobre el fondo, en función de qué lado tiene los argumentos más fuertes. Proponemos un modelo predictivo de debate que estima los efectos de las características lingüísticas y las fortalezas persuasivas latentes de los diferentes temas, así como las interacciones entre ambos. Utilizando un conjunto de datos de 118 debates al estilo de Oxford, la combinación de contenido (como temas latentes) y estilo (como características lingüísticas) de nuestro modelo nos permite predecir los ganadores adjudicados por el público con un 74% de precisión, superando significativamente las características lingüísticas por sí solas (66%). Nuestro modelo considera que las partes ganadoras emplean argumentos más sólidos y nos permite identificar las características lingüísticas asociadas con argumentos fuertes o débiles.', 'pt': 'Debate e deliberação desempenham papéis essenciais na política e no governo, mas a maioria dos modelos presume que os debates são vencidos principalmente por meio de um estilo superior ou controle de agenda. Idealmente, porém, os debates seriam vencidos pelo mérito, em função de qual lado tem os argumentos mais fortes. Propomos um modelo preditivo de debate que estima os efeitos das características linguísticas e as forças persuasivas latentes de diferentes tópicos, bem como as interações entre os dois. Usando um conjunto de dados de 118 debates no estilo Oxford, a combinação do nosso modelo de conteúdo (como tópicos latentes) e estilo (como recursos linguísticos) nos permite prever vencedores julgados pelo público com 74% de precisão, superando significativamente os recursos linguísticos sozinhos (66%). Nosso modelo descobre que os lados vencedores empregam argumentos mais fortes e nos permite identificar as características linguísticas associadas a argumentos fortes ou fracos.', 'fr': "Le débat et la délibération jouent un rôle essentiel en politique et au gouvernement, mais la plupart des modèles supposent que les débats sont gagnés principalement grâce à un style supérieur ou à un contrôle de l'ordre du jour. Dans l'idéal, cependant, les débats seraient gagnés sur le fond, en fonction de la partie qui a les arguments les plus solides. Nous proposons un modèle prédictif de débat qui estime les effets des caractéristiques linguistiques et les forces persuasives latentes de différents sujets, ainsi que les interactions entre les deux. À l'aide d'un ensemble de données de 118 débats de style Oxford, la combinaison de contenu (en tant que sujets latents) et de style (en tant que caractéristiques linguistiques) de notre modèle nous permet de prédire les gagnants jugés par le public avec une précision de 74\xa0%, surpassant largement les caractéristiques linguistiques seules (66\xa0%). Notre modèle constate que les équipes gagnantes utilisent des arguments plus solides et nous permet d'identifier les caractéristiques linguistiques associées à des arguments forts ou faibles.", 'ja': 'ディベートと審議は、政治と政府において不可欠な役割を果たしますが、ほとんどのモデルは、ディベートは主に優れたスタイルまたは議題制御を介して獲得されると推測しています。しかし、理想的には、どちらの側がより強い議論を持っているかの関数として、議論はメリットに基づいて勝つだろう。言語的特徴の効果と異なるトピックの潜在的な説得力、そして両者の相互作用を推定する議論の予測モデルを提案する。118のオックスフォードスタイルのディベートのデータセットを使用して、当社のモデルのコンテンツ（潜在的なトピックとして）とスタイル（言語学的特徴として）の組み合わせにより、74 ％の精度でオーディエンスが判断した勝者を予測でき、言語学的特徴単独（ 66 ％ ）を大幅に上回っています。私たちのモデルは、勝つ側がより強い議論を採用し、強いまたは弱い議論に関連する言語学的特徴を特定できることを発見しました。', 'hi': 'बहस और विचार-विमर्श राजनीति और सरकार में आवश्यक भूमिका निभाते हैं, लेकिन अधिकांश मॉडल मानते हैं कि बहस मुख्य रूप से बेहतर शैली या एजेंडा नियंत्रण के माध्यम से जीती जाती है। आदर्श रूप से, हालांकि, बहस को गुणों पर जीता जाएगा, एक समारोह के रूप में किसके पक्ष में मजबूत तर्क हैं। हम बहस के एक भविष्यवाणी मॉडल का प्रस्ताव करते हैं जो भाषाई विशेषताओं के प्रभावों और विभिन्न विषयों की अव्यक्त प्रेरक शक्तियों के साथ-साथ दोनों के बीच बातचीत का अनुमान लगाता है। 118 ऑक्सफोर्ड-शैली की बहस के डेटासेट का उपयोग करते हुए, हमारे मॉडल की सामग्री (अव्यक्त विषयों के रूप में) और शैली (भाषाई विशेषताओं के रूप में) का संयोजन हमें 74% सटीकता के साथ दर्शकों-निर्णयित विजेताओं की भविष्यवाणी करने की अनुमति देता है, जो अकेले भाषाई विशेषताओं (66%) से काफी अधिक है। हमारे मॉडल में पाया गया है कि जीतने वाले पक्ष मजबूत तर्कों को नियोजित करते हैं, और हमें मजबूत या कमजोर तर्कों से जुड़ी भाषाई विशेषताओं की पहचान करने की अनुमति देता है।', 'zh': '论议在政治之要,而大抵以为优议程制之。 然理欲之情,辩将因事而得,以其有力也。 吾为一辩之占,度言语之化,异题之说服力,与二者之相用也。 用118牛津风之数集,吾形以(为题)与风(为言)使吾得以74%准确率占受众决之获胜者,显优于独言(66%)。 我模形见,胜者用更强之论,并许识强弱之语。', 'ru': 'Дискуссии и обсуждения играют важную роль в политике и правительстве, но большинство моделей предполагают, что дебаты выигрываются главным образом за счет превосходного стиля или контроля повестки дня. В идеале, однако, можно было бы выиграть дебаты по существу, поскольку в зависимости от того, какая сторона имеет более сильные аргументы. Мы предлагаем прогностическую модель дебатов, которая оценивает влияние лингвистических особенностей и скрытых убедительных сильных сторон различных тем, а также взаимодействия между ними. Используя набор данных из 118 дебатов в оксфордском стиле, наша модель сочетания контента (в качестве скрытых тем) и стиля (в качестве лингвистических особенностей) позволяет нам прогнозировать победителей, признанных аудиторией, с 74% точностью, значительно превосходящей только лингвистические особенности (66%). Наша модель обнаруживает, что победившие стороны используют более сильные аргументы, и позволяет нам идентифицировать лингвистические особенности, связанные с сильными или слабыми аргументами.', 'ga': 'Tá róil ríthábhachtacha ag díospóireacht agus ag plé sa pholaitíocht agus sa rialtas, ach glacann an chuid is mó de na samhlacha leis go mbuaileann díospóireachtaí go príomha trí stíl níos fearr nó rialú cláir oibre. Go hidéalach, áfach, ghnóthófaí díospóireachtaí ar an bhfiúntas, mar fheidhm de cé acu taobh a bhfuil na hargóintí is láidre. Molaimid samhail thuarthach díospóireachta a dhéanann meastachán ar éifeachtaí gnéithe teangeolaíochta agus ar láidreachtaí folaigh áititheacha topaicí éagsúla, chomh maith leis na hidirghníomhaíochtaí idir an dá rud. Ag baint úsáide as tacar sonraí de 118 díospóireacht ar stíl Oxford, ligeann meascán ár samhail d’inneachar (mar thopaicí folaigh) agus stíl (mar ghnéithe teangeolaíochta) dúinn buaiteoirí lucht féachana-bhreithnithe a thuar le cruinneas 74%, rud a sháraíonn gnéithe teanga amháin (66%) go suntasach. Léiríonn ár múnla go n-úsáideann taobhanna buaiteacha argóintí níos láidre, agus ligeann sé dúinn na gnéithe teangeolaíochta a bhaineann le hargóintí láidre nó laga a aithint.', 'hu': 'A vita és a tanácskozás alapvető szerepet játszik a politikában és a kormányzásban, de a legtöbb modell feltételezi, hogy a viták elsősorban a felsőbbrendű stílus vagy a napirend ellenőrzése révén nyerhetők meg. Ideális esetben azonban az érdemekről vitákat nyernénk, mivel annak függvényében, hogy melyik oldalnak vannak erősebb érvei. Egy prediktív vita modellt javasolunk, amely becsüli a nyelvi jellemzők hatásait, a különböző témák látens meggyőző erősségeit, valamint a kettő közötti interakciókat. 118 oxfordi stílusú vitából álló adatkészlet segítségével modellünk tartalmi kombinációja (látens témaként) és stílusa (nyelvi jellemzőként) lehetővé teszi számunkra, hogy 74%-os pontossággal megjósoljuk a közönség által kiírt nyerteseket, jelentősen túllépjük a nyelvi jellemzőket (66%). Modellünk megállapítja, hogy a győztes oldalak erősebb érveket alkalmaznak, és lehetővé teszi számunkra, hogy azonosítsuk az erős vagy gyenge érvekhez kapcsolódó nyelvi jellemzőket.', 'el': 'Η συζήτηση και η συζήτηση διαδραματίζουν ουσιαστικούς ρόλους στην πολιτική και την κυβέρνηση, αλλά τα περισσότερα μοντέλα υποθέτουν ότι οι συζητήσεις κερδίζονται κυρίως μέσω ανώτερου στυλ ή ελέγχου ατζέντας. Ιδανικά, ωστόσο, οι συζητήσεις θα κερδίζονταν επί της ουσίας, ως συνάρτηση της οποίας η πλευρά έχει τα ισχυρότερα επιχειρήματα. Προτείνουμε ένα προβλέψιμο μοντέλο συζήτησης που εκτιμά τις επιπτώσεις των γλωσσικών χαρακτηριστικών και τις λανθάνουσες πειστικές δυνάμεις των διαφόρων θεμάτων, καθώς και τις αλληλεπιδράσεις μεταξύ των δύο. Χρησιμοποιώντας ένα σύνολο δεδομένων συζητήσεων σε στυλ 118 Οξφόρδης, ο συνδυασμός περιεχομένου (ως λανθάνοντα θέματα) και στυλ (ως γλωσσικά χαρακτηριστικά) μας επιτρέπει να προβλέψουμε νικητές που κρίνονται από το κοινό με ακρίβεια 74% που ξεπερνούν σημαντικά τα γλωσσικά χαρακτηριστικά από μόνα τους (66%). Το μοντέλο μας διαπιστώνει ότι οι νικητές χρησιμοποιούν ισχυρότερα επιχειρήματα και μας επιτρέπει να εντοπίσουμε τα γλωσσικά χαρακτηριστικά που σχετίζονται με ισχυρά ή αδύναμα επιχειρήματα.', 'it': "Il dibattito e la deliberazione svolgono un ruolo essenziale nella politica e nel governo, ma la maggior parte dei modelli presumono che i dibattiti siano vinti principalmente attraverso uno stile superiore o un controllo dell'agenda. Idealmente, tuttavia, si vincerebbero dibattiti sul merito, in funzione di quale parte ha le argomentazioni più forti. Proponiamo un modello predittivo di dibattito che valuta gli effetti delle caratteristiche linguistiche e i punti di forza persuasivi latenti dei diversi argomenti, nonché le interazioni tra i due. Utilizzando un set di dati di 118 dibattiti in stile Oxford, la combinazione del nostro modello di contenuti (come argomenti latenti) e stile (come caratteristiche linguistiche) ci permette di prevedere i vincitori giudicati dal pubblico con precisione del 74%, superando significativamente le sole caratteristiche linguistiche (66%). Il nostro modello trova che le parti vincenti impiegano argomenti più forti e ci permette di identificare le caratteristiche linguistiche associate a argomenti forti o deboli.", 'lt': 'Diskusijos ir svarstymai atlieka esminį vaidmenį politikoje ir vyriausybėje, tačiau dauguma modelių daro prielaidą, kad diskusijos daugiausia laimėtos vadovaujantis aukštesniu stiliu arba darbotvarkės kontrole. Vis dėlto idealiai būtų laimėtos diskusijos dėl vertybių, atsižvelgiant į tai, kurios pusės argumentai yra tvirtesni. We propose a predictive model of debate that estimates the effects of linguistic features and the latent persuasive strengths of different topics, as well as the interactions between the two.  Naudodami 118 Oksfordo stiliu vykusių diskusijų duomenų rinkinį, mūs ų modelio turinio (kaip latentinės temos) ir stilius (kaip kalbinės savybės) derinys leidžia mums prognozuoti laureatus su auditorija 74 proc. tikslumu, gerokai viršijančius vien kalbines savybes (66 proc.). Mūsų modelis rodo, kad laimėjusios šalys naudoja tvirtesnius argumentus ir leidžia mums nustatyti kalbines savybes, susijusias su tvirtais ar silpnais argumentais.', 'kk': 'Дебаттау және бөлімдеу саясатты және үкіметтің негізгі рөлі ойлады, бірақ көпшілігі дебаттаулар негізгі жоғары стиль не күнделік контроллерімен жеңілді деп ойлайды. Бірақ идеялық дебаттары күш аргументтердің функциясы ретінде жетілді. Біз лингвистикалық мүмкіндіктердің эффекттерін бағалайтын дебаттардың таңдау үлгісін және әртүрлі нақыштардың соңғы тұрақты күштерін, сондай-ақ екеуінің арасындағы қатынастарын бағала 118 Оксфорд стилінің дебаттарын қолдану үлгіміздің мазмұнын (келтірілген тақырыптар ретінде) және стилінің (лингвистикалық мүмкіндіктер ретінде) аудиториялық жеңілдерді 74% деген дұрыс болып көрсетуге мүмкіндік береді, лингвистикалық мүмкінд Біздің үлгіміздің жеңіліктеріміз күшті аргументтерді қолдануға мүмкіндік береді. Біздің лингвистикалық мүмкіндіктерімізді күшті не күшті аргументтерімен байланыс', 'mk': 'Дебатите и разговорите играат основни улоги во политиката и владата, но повеќето модели претпоставуваат дека дебатите се освоени главно преку супериорна контрола на стилот или агендата. Идеално, сепак, дебатите ќе бидат освоени во врска со заслугите, како функција на која страна има посилни аргументи. Предложуваме предвидлив модел на дебата кој ги проценува ефектите на јазичните карактеристики и тајните убедливи сили на различните теми, како и интеракциите помеѓу двете. Користејќи набор на податоци од 118 дебати во оксфордски стил, комбинацијата на нашиот модел на содржина (како тајни теми) и стил (како лингвистички карактеристики) ни овозможува да ги предвидеме победниците со 74 отсто прецизност, значително надминувајќи само лингвистичките карактеристики (66 отсто). Нашиот модел открива дека победничките страни користат посилни аргументи и ни овозможува да ги идентификуваме јазичните карактеристики поврзани со силни или слаби аргументи.', 'ms': 'Debat dan deliberation bermain peran penting dalam politik dan kerajaan, tetapi kebanyakan model menganggap bahawa debat adalah menang terutama melalui gaya atas atau kawalan agenda. Idealnya, bagaimanapun, perdebatan akan menang atas nilai, sebagai fungsi sisi mana mempunyai argumen yang lebih kuat. Kami mengusulkan model ramalan debat yang menghargai kesan ciri-ciri bahasa dan kekuatan yang tertutup yang meyakinkan topik yang berbeza, serta interaksi antara kedua-dua. Dengan menggunakan set data 118 debat gaya Oxford, kombinasi kandungan model kita (sebagai topik tersembunyi) dan gaya (sebagai ciri-ciri bahasa) membolehkan kita meramalkan pemenang yang diberi pengajaran oleh penonton dengan ketepatan 74%, yang jauh melebihi ciri-ciri bahasa sahaja (66%). Model kami mendapati bahawa pihak yang menang menggunakan argumen yang lebih kuat, dan membolehkan kami mengenalpasti ciri-ciri bahasa yang berkaitan dengan argumen yang kuat atau lemah.', 'ml': 'പ്രധാനപ്പെട്ട വിവാദങ്ങളും ആലോചിക്കുന്നതും രാഷ്ട്രീയത്തിലും പ്രധാനപ്പെട്ട പ്രധാനപ്പെട്ട പ്രധാനപ്പെട്ട പ്രധാനപ എന്നാലും നിര്\u200dബന്ധമായി വിവാദങ്ങള്\u200d വിജയിക്കപ്പെടും, ഏത് ഭാഗത്തില്\u200d ശക്തിയുള്ള വാദ്യാഭ്യാസം ഉണ്ട്. വ്യത്യസ്ത കാര്യങ്ങളുടെ പ്രത്യേക ശക്തികളും രണ്ടുപേരുടെയും തമ്മിലുള്ള ബന്ധങ്ങളുടെയും പ്രഭാവിക്കുന്ന ഒരു തര്\u200dക്കത്തിന്റെ മാതൃകയാണ് ഞങ്ങള്\u200d പ് 118 ഓക്സ്ഫോര്\u200dഡ് ശൈലിയുടെ ഡാറ്റാസെറ്റ് ഉപയോഗിച്ച്, നമ്മുടെ മോഡലിന്റെ ഉള്ളടക്കം കൂട്ടത്തിന്റെ (latent topics) പിന്നെ ശൈലി (ഭാഷിക്കുറിച്ചുള്ള വിഷയങ്ങള്\u200d എന്നിവയായി) ഞങ്ങള്\u200dക്ക് 74% ശ്ര നമ്മുടെ മോഡല്\u200d കണ്ടെത്തുന്നത് ജയിക്കുന്ന ഭാഗങ്ങളില്\u200d ശക്തിയുള്ള വാദ്യാഭിക്കുകള്\u200d പ്രവര്\u200dത്തിക്കുന്നു. അതിനാല്\u200d ശക്ത', 'mn': 'Дэлхий, зөвлөлт улс төрийн болон засгийн газрын үндсэн үүрэг тоглодог. Гэхдээ ихэнх загварууд нь зөвлөлт нь ихэвчлэн дээд хэлбэрээр эсвэл дасгал төрийн удирдлагаар ялагдсан гэж бод Гэхдээ бодлоор, тэдний талд илүү хүчтэй аргумент байгаа тухай ярилцлага үнэ цэнэтэй байх болно. Бид хэлний харилцааны үр дүнг тооцоолж буй талаар ярилцлагын таамаглалт загварын загварыг санал болгож байна. Оксфордын 118 хэлбэрийн зөвлөгөөний өгөгдлийн сангуудыг ашиглан бидний загварын соёл болон хэлбэрүүдийн (хэл хэлбэрийн чадвар) хэлбэрүүдийн холбоотой нь 74% шударга байдлыг хүлээн зөвшөөрөх боломжтой болгодог. Энэ нь хэл хэлний чадварыг зөвхөн (66%)  Бидний загварын загвар нь ялагдах талууд илүү хүчтэй аргументыг ашиглаж, бидэнд хүчтэй эсвэл сул аргументтай холбогдсон хэлний чадварыг олж мэдэх боломж олгодог.', 'no': 'Debatt og deliberasjon speler grunnleggjande roller i politikk og regjeringen, men dei fleste modelane foreslår at debattar vert vann hovudsakelig via superstil eller programkontroll. Ideelt vil imidlertid debattane bli vinne på måten, som ein funksjon av kva side har dei sterke argumentene. Vi foreslår eit foregåande modell for debatt som vurder effekten av språkstiske funksjonar og den latere persuasive styrken av ulike tema, og samband mellom dei to. Bruk ein datasett med 118 Oxford-stildebatar, kan modellen vårt kombinasjon av innhaldet (som latent emn) og stil (som lingviske funksjonar) gjera oss å forhåndsvisa vannar med 74% nøyaktighet, som er vanskeleg å utføra lingviske funksjonar alene (66%). Modellen vårt finn at vinner sider bruker sterkere argumenter, og lèt oss identifisera dei lingviske funksjonane som er assosiert med sterke eller svake argumenter.', 'mt': "Id-dibattitu u d-deliberazzjoni għandhom rwoli essenzjali fil-politika u l-gvern, iżda l-biċċa l-kbira tal-mudelli jippreżumu li d-dibattiti jintlaħqu prinċipalment permezz ta’ stil superjuri jew kontroll tal-aġenda. Ideally, however, debates would be won on the merits, as a function of which side has the stronger arguments.  Aħna nipproponu mudell ta' dibattitu prevedibbli li jistma l-effetti tal-karatteristiċi lingwistiċi u l-qawwiet persuasivi moħbija ta' suġġetti differenti, kif ukoll l-interazzjonijiet bejn iż-żewġ. Bl-użu ta’ sett ta’ dejta ta’ 118-il dibattitu fl-istil ta’ Oxford, il-kombinazzjoni tal-kontenut (bħala suġġetti moħbija) u l-istil (bħala karatteristiċi lingwistiċi) tal-mudell tagħna tippermettilna li nibbrevedu r-rebbieħa a ġġudikati mill-udjenza b’preċiżjoni ta’ 74 %, b’karatteristiċi lingwistiċi ogħla b’mod sinifikanti waħedhom (66 %). Il-mudell tagħna jsib li n-naħat rebbieħa jużaw argumenti aktar b’saħħithom, u jippermettilna nidentifikaw il-karatteristiċi lingwistiċi assoċjati ma’ argumenti b’saħħithom jew dgħajfa.", 'ka': 'ევბატი და განსაზღვრება იყოს მნიშვნელოვანი პოლიტიკური და განსაზღვრებაში, მაგრამ ბევრი მოდელები წარმოიდგინენ, რომ დებატიკები უფრო მეტად უფრო მეტად სტილზე ან მაგრამ იდეალურად, დიბუტები იქნება უფრო ძლიერი არგუმენტები, როგორც ფუნქცია იქნება. ჩვენ განვითარებთ განსაზღვრებული მოდელს, რომელიც ინგლინგისტიკური ფუნქციების ეფექტის და განსაზღვრებული განსხვავებული ტემების ძალადობა და ინტერფექციების შორის. 118 Oxford-სტილის დიბუტების მონაცემები გამოყენება, ჩვენი მოდელის კომბუნეცია (როგორც ლენგისტიული ტემები) და სტილის (როგორც ლენგისტიკური ფუნქციები) მოგვიძლია ჩვენ დავიწყენოთ აუდისტურებელი დავიწყენებელი 74% წესი ჩვენი მოდელი აღმოჩნდა, რომ დაბედომა მზად არგუმენტები იყენებს, და ჩვენ დაგვეხმარებს ინგუმენტიკური განსაზღვრება, რომელიც ძალიან ან ძალიან არგუმე', 'pl': 'Debata i rozważanie odgrywają istotną rolę w polityce i rządzie, ale większość modeli zakłada, że debaty są wygrywane głównie poprzez wyższy styl lub kontrolę agendy. Najlepiej jednak byłoby wygrywać debaty na zasadach, w zależności od tego, która strona ma silniejsze argumenty. Proponujemy predykcyjny model debaty, który szacuje efekty cech językowych i ukrytych silnych stron perswazyjnych różnych tematów, a także interakcje między nimi. Korzystając z zestawu danych debat w stylu 118 Oxfordu, połączenie treści (jako tematów utajonych) i stylu (jako cech językowych) naszego modelu pozwala nam przewidzieć zwycięzców ocenianych przez odbiorców z dokładnością 74% , znacznie przewyższając same cechy językowe (66%). Nasz model stwierdza, że zwycięskie strony stosują silniejsze argumenty i pozwala nam zidentyfikować cechy językowe związane z silnymi lub słabymi argumentami.', 'ro': 'Dezbaterea și deliberarea joacă roluri esențiale în politică și guvernare, dar majoritatea modelelor presupun că dezbaterile sunt câștigate în principal prin stilul superior sau controlul agendei. În mod ideal, totuși, dezbaterile ar fi câștigate pe baza meritelor, în funcție de care parte are argumentele mai puternice. Propunem un model predictiv de dezbatere care estimează efectele caracteristicilor lingvistice și forțele persuasive latente ale diferitelor subiecte, precum și interacțiunile dintre cele două. Folosind un set de date de 118 dezbateri în stil Oxford, combinația modelului nostru de conținut (ca subiecte latente) și stil (ca caracteristici lingvistice) ne permite să prezicem câștigătorii judecați de public cu o precizie de 74%, depășind semnificativ caracteristicile lingvistice numai (66%). Modelul nostru constată că părțile câștigătoare folosesc argumente mai puternice și ne permite să identificăm caracteristicile lingvistice asociate argumentelor puternice sau slabe.', 'so': 'Iska dooda iyo qasabka ayaa qaybaha muhiimka ah ku ciyaaro siyaasada iyo dowladda, laakiin tusaalayaasha badankood waxay u malaynayaan in debaashu ugu horeeyo qaababka sare ama maamulka agenda. Si kastaba ha ahaatee debaasho waxaa lagu qaadan doonaa midiidinnada, sida shuqulka labada dhinac ay ku haystaan doodo aad u adag. Waxaan soo jeedaynaa qaab ka hor jeedid debaar ah oo qiimeynaya saamaynta aqoonta luuqada iyo xoogga ugu dambeeya waxyaabaha ku saabsan maadooyinka kala duduwan iyo xiriirka labada. Isku isticmaalaya debaasho ku qoran 118 Oxford-style, qaababka midowgayaga ku ururista waxyaabaha ku qoran (sida maadooyinka ugu dambeeya) iyo qaababka (sida tayada luqada ah) ayaa inagu ogolaan kara inaannu ka hor tagno guuleysayaasha dhegayaasha oo ku saabsan 74% saxda, si muhiim ah u sameynayo xarumaha luuqadaha oo kaliya (66%). Tusaale ahaan guulaysteena waxay shaqaysaa doodo xoog badan, waxaana na ogolaan inaynu aqoonsanno xirfadaha luqada ee la xiriira hadallo xoog leh ama itaal yar.', 'sr': 'Debata i razmišljanja igraju ključne uloge u politici i vladi, ali većina modela pretpostavlja da se debati osvoje uglavnom putem nadmoćnog stila ili kontrole programa. Međutim, idealno bi se rasprave osvojile na zaslugu, kao funkcija kojih strana ima jače argumente. Predlažemo predvidljiv model debata koji procjenjuje učinak jezičkih karakteristika i latentne uvjerljive snage različitih tema, kao i interakcije između njih. Koristeći podatke o 118 diskusiji u stilu Oksforda, kombinacija sadržaja našeg model a (kao latentne teme) i stila (kao lingvističke karakteristike) omogućava nam da predvidimo pobednike koji su osuđivali na publiku sa preciznošću 74%, značajno iznosi samo lingvističke karakteristike (66%). Naš model nalazi da pobedničke strane koriste jače argumente i omogućava nam da identifikujemo jezičke karakteristike povezane sa jakim ili slabim argumentima.', 'si': 'රජාත්මක සහ රජාත්මක විශේෂය සහ සැලසුම් සැලසුම් කරනවා නමුත් ගොඩක් මෝඩේල් හිතනවා විශේෂය සැලසුම් විදියට ප්\u200dර හැබැයි සිද්ධියෙන්ම, කතා කරන්න පුළුවන් විදිහට දින්න පුළුවන්, මේ පැත්තේ වඩා ශක්තිමත් කතාවක් තිය අපි ප්\u200dරශ්නයක් කරනවා වාර්තාවේ ප්\u200dරශ්නයක් සහ භාෂාවික විශේෂතාවේ ප්\u200dරශ්නයක් සහ වෙනස් විදිහට ප්\u200dරශ්නයක් සමහර විදිහට 118 ඔක්ස්ෆර්ඩ් ස්ටායින් විශේෂ කතාවක් භාවිත කරනවා, අපේ මොඩල් සංවිධානය (ලේටින් විශේෂ සංවිධානය) සහ ශාලාව (භාෂාවික සංවිධානය වගේ) අපිට ප්\u200dර අපේ මොඩල් හොයාගන්නවා ජයග්\u200dරහණ පැත්තට වඩා ශක්තිමත් ප්\u200dරශ්නයක් තියෙනවා කියලා, ඒ වගේම අපිට ශක්තිමත් නැත්තම්', 'sv': 'Debatt och överläggning spelar viktiga roller i politik och regering, men de flesta modeller förutsätter att debatter främst vinns genom överlägsen stil eller dagordning kontroll. Helst skulle dock debatter vinnas om förtjänsten, eftersom vilken sida som har de starkare argumenten. Vi föreslår en prediktiv modell för debatt som uppskattar effekterna av språkliga drag och latenta övertygande styrkor hos olika ämnen, liksom samspelet mellan de två. Med hjälp av en datauppsättning av 118 debatter i Oxford-stil gör vår modells kombination av innehåll (som latenta ämnen) och stil (som språkliga egenskaper) det möjligt för oss att förutsäga publikbedömda vinnare med 74% noggrannhet, vilket avsevärt överträffar enbart språkliga egenskaper (66%). Vår modell finner att vinnande sidor använder starkare argument, och gör det möjligt för oss att identifiera de språkliga drag som förknippas med starka eller svaga argument.', 'ur': 'ڈیبوٹ اور مشورہ سیاست اور حکومت میں ضروری رول لگا رہے ہیں، لیکن اکثر موڈل یہ سمجھتے ہیں کہ بحث اکثر زیادہ اچھی طرح یا اگنڈا کنٹرول کے ذریعے غالب ہوتے ہیں. اگرچہ نظر اندازہ سے، بحث کے ارزش پر غالب رہیں گے، جس کی عملہ سے زیادہ طاقتور بحث ہے. ہم ایک مختلف موضوع کی پیش بینی مدل کو پیش بینی کرتے ہیں جو زبان شناسی ویژگی کے اثرات اور مختلف موضوع کے لائٹینٹ مضبوط قوت اور ان دونوں کے درمیان اثرات کا ارزش کرتا ہے۔ 118 اکسفورڈ کے سائل بحث کے ڈیٹ سٹ کا استعمال کرتا ہے، ہمارے موڈل کے منصوبہ (لٹینٹ ٹوپ کے طور پر) اور استیل (زبان کے متعلق) کی ترکیب سے ہمیں واضح کرتا ہے کہ 74% سچائی کے ساتھ عادت کرنے والوں کو پیش بینی کریں، صرف زبان شناسی کے متعلق (66%) سے زیادہ زی ہمارے مدل کو معلوم ہوتا ہے کہ غالب جانے کے لئے زیادہ طاقتور دلیل استعمال کرتے ہیں اور ہمیں قوت یا ضعیف دلیل کے ساتھ ارتباط کیا ہوا زبان شناسی ویژے کا اختیار کرنا اجازت دیتا ہے.', 'ta': 'விவாதம் மற்றும் ஆலோசனை அரசியல் மற்றும் அரசாங்கத்தில் முக்கியமான விளையாடுகளை விளையாடுகிறது, ஆனால் பெரும்பாலான மாதிரிகள ஆயினும், விவாதம் எந்த பக்கத்தில் வலிமையான வார்த்தைகள் இருக்கும் என்பதால் வெற்றி பெறும். மொழி குணங்களின் விளைவுகளையும் சமீபத்திய நம்பிக்கையான வலிமைகளையும் மற்றும் இரண்டுக்கும் இடையேயுள்ள இடைவெளிப்பாடு 118 ஓக்ஸ்ஃபோர்ட் பாணி விவாதத்தை பயன்படுத்தி, எங்கள் மாதிரியின் உள்ளடக்கங்கள் (சமீபத்தில் தலைப்புகளாக) மற்றும் பாணி( மொழிப்பு குணங்களாக இருக்கும்) பாணி எங்கள் மாதிரி வெற்றி பக்கங்கள் வலுவான தருமதிப்புகளை வேலை செய்யும் என்று கண்டுபிடிக்கிறது மற்றும் நமக்கு வலிமை அல்லது பலவீனமான', 'uz': "Ko'pchilik modellari esa yuqori uslub yoki ajoyib boshqarish orqali o'ynaladi, lekin ko'pchilik modellar o'ylaymaydi, bu hodisa boshqaruvchilarga yuqori uslub yoki ajratish boshqaruvchisi orqali muvaffaqiyatli o'tka Shunday qilib, birga qanchalik qiymatlar qo'shilga oshadi. We propose a predictive model of debate that estimates the effects of linguistic features and the latent persuasive strengths of different topics, as well as the interactions between the two.  Name Bizning modelimiz o'rganishni o'rganadi, bizga ko'proq argumentlarni ishlatadi va bizga qulay yoki kichkina argumentlar bilan bog'liq tillar xususiyatlarini aniqlashga ruxsat beradi.", 'vi': 'Cuộc tranh luận và thảo luận là những vai trò quan trọng trong chính trị và chính phủ, nhưng hầu hết các mẫu đều cho rằng tranh luận được thắng cử chủ yếu nhờ phong cách hay kiểm soát lịch trình cao cấp. Lý tưởng nhất, tuy nhiên, cuộc tranh luận sẽ được thắng dựa trên điểm chính, vì vai trò của phía nào có lý lẽ mạnh mẽ hơn. Chúng tôi đề nghị một mô hình dự đoán cuộc tranh luận ước tính hiệu quả của các yếu tố ngôn ngữ và tiềm năng thuyết phục tiềm ẩn của các chủ đề khác nhau, cũng như sự tương tác giữa hai. Sử dụng một tập dữ liệu trong các cuộc tranh luận kiểu Oxford 118, s ự kết hợp nội dung của mô hình (như các chủ đề tiềm ẩn) và phong cách (như các tính năng ngôn ngữ) cho phép chúng ta dự đoán những chiến thắng được thẩm định với độ cao 74, khả năng ngôn ngữ vượt trội đáng kể một mình (62). Theo mẫu của chúng tôi, chiến thắng dựa trên những lý lẽ mạnh mẽ, và cho phép chúng tôi xác định các yếu tố ngôn ngữ liên quan đến những luận mạnh mẽ hoặc yếu đuối.', 'bg': 'Дебатът и разискването играят съществена роля в политиката и управлението, но повечето модели предполагат, че дебатите се печелят главно чрез превъзходен стил или контрол на дневния ред. В идеалния случай обаче дебатите биха били спечелени по заслуги, като функция на коя страна има по-силните аргументи. Предлагаме прогнозен модел на дебат, който оценява ефектите от лингвистичните особености и латентните убеждаващи силни страни на различните теми, както и взаимодействията между двете. Използвайки набор от данни от 118 дебати в стил Оксфорд, комбинацията от съдържание (като латентни теми) и стил (като лингвистични особености) на нашия модел ни позволява да предвидим победителите, присъдени от публиката, със 74% точност, значително надхвърляйки лингвистичните особености само (66%). Нашият модел установява, че печелившите страни използват по-силни аргументи и ни позволява да идентифицираме езиковите особености, свързани със силни или слаби аргументи.', 'da': 'Debat og overvejelser spiller vigtige roller i politik og regering, men de fleste modeller antager, at debatter primært vindes via overlegen stil eller dagsordenskontrol. Ideelt set ville der dog blive vundet drøftelser om fortjenesten, idet hvilken side der har de stærkeste argumenter. Vi foreslår en forudsigende debatmodel, der vurderer virkningerne af sproglige træk og de latente overbevisende styrker af forskellige emner samt samspillet mellem de to. Ved hjælp af et datasæt af 118 Oxford-stil debatter giver vores models kombination af indhold (som latente emner) og stil (som sproglige træk) os mulighed for at forudsige publikum-bedømte vindere med 74% nøjagtighed, hvilket betydeligt overgår sproglige træk alene (66%). Vores model finder ud af, at vindende sider anvender stærkere argumenter, og giver os mulighed for at identificere de sproglige træk, der er forbundet med stærke eller svage argumenter.', 'nl': 'Debat en beraadslaging spelen een essentiële rol in politiek en overheid, maar de meeste modellen veronderstellen dat debatten voornamelijk gewonnen worden via superieure stijl of agendacontrole. Idealiter zouden debatten echter gewonnen worden over de merites, als functie van welke kant de sterkere argumenten heeft. We stellen een voorspellend debat model voor dat de effecten van taalkundige kenmerken en de latente overtuigende kracht van verschillende onderwerpen schat, evenals de interacties tussen de twee. Met behulp van een dataset van 118 Oxford-stijl debatten, stelt ons model de combinatie van inhoud (als latente onderwerpen) en stijl (als linguïstische kenmerken) in staat om doelgerichte winnaars te voorspellen met 74% nauwkeurigheid, die aanzienlijk beter presteren dan linguïstische kenmerken alleen (66%). Ons model stelt vast dat winnende partijen sterkere argumenten gebruiken en stelt ons in staat om de taalkundige kenmerken van sterke of zwakke argumenten te identificeren.', 'de': 'Debatte und Debatte spielen eine wesentliche Rolle in Politik und Regierung, aber die meisten Modelle gehen davon aus, dass Debatten hauptsächlich durch überlegene Stil oder Agenda-Kontrolle gewonnen werden. Idealerweise würden Debatten jedoch nach den Vorzügen gewonnen werden, in Abhängigkeit davon, welche Seite die stärkeren Argumente hat. Wir schlagen ein prädiktives Diskussionsmodell vor, das die Auswirkungen sprachlicher Merkmale und latenter Überzeugungsstärken verschiedener Themen sowie die Wechselwirkungen zwischen den beiden abschätzt. Anhand eines Datensatzes von 118 Oxford-Debatten ermöglicht die Kombination unseres Modells aus Inhalten (als latente Themen) und Stil (als linguistische Merkmale) es uns, Zielgruppen-bewertete Gewinner mit 74% Genauigkeit vorherzusagen, die sprachliche Merkmale allein deutlich übertreffen (66%). Unser Modell zeigt, dass gewinnende Seiten stärkere Argumente verwenden, und ermöglicht es uns, die sprachlichen Merkmale zu identifizieren, die mit starken oder schwachen Argumenten verbunden sind.', 'id': 'Debat dan deliberasi bermain peran penting dalam politik dan pemerintah, tetapi kebanyakan model menganggap bahwa debat terutama menang melalui gaya atas atau kontrol agenda. Idealnya, bagaimanapun, debat akan menang atas keuntungan, sebagai fungsi sisi mana memiliki argumen yang lebih kuat. Kami mengusulkan model prediksi debat yang memperkirakan efek dari karakteristik bahasa dan kekuatan yang tertutup meyakinkan dari topik yang berbeda, serta interaksi antara keduanya. Menggunakan set data dari 118 debat gaya Oxford, kombinasi konten model kita (sebagai topik yang tersembunyi) dan gaya (sebagai ciri-ciri bahasa) memungkinkan kita untuk memprediksi pemenang yang diduga oleh penonton dengan 74% akurasi, yang signifikan melebihi ciri-ciri bahasa sendirian (66%). Model kita menemukan bahwa sisi pemenang menggunakan argumen yang lebih kuat, dan memungkinkan kita untuk mengidentifikasi fitur bahasa yang berhubungan dengan argumen yang kuat atau lemah.', 'ko': '변론과 상의는 정치와 정부에서 매우 중요한 역할을 하지만, 대부분의 모델들은 변론이 주로 우월한 풍격이나 의사일정 통제를 통해 이루어진다고 여긴다.그러나 이상적인 상황에서 변론은 시비곡직으로 이길 것이고 어느 쪽의 논점이 더 유력한지에 달려 있다.우리는 서로 다른 화제의 언어 특징과 잠재적 설득력의 영향, 그리고 양자 간의 상호작용을 예측하는 변론 예측 모델을 제시했다.118차례의 옥스포드식 변론 데이터 집합을 사용하여 우리의 모델은 내용(잠재적 주제로)과 스타일(언어 특징으로)을 결합시켜 74%의 정확도로 관중이 판정한 수상자를 예측할 수 있어 언어 특징(66%)보다 현저히 우수하다.우리의 모델은 승리한 측이 더욱 강한 논점을 사용하고 강한 논점이나 약한 논점과 관련된 언어 특징을 식별할 수 있음을 발견했다.', 'sw': 'Mjadala na makubaliano yanacheza nafasi muhimu katika siasa na serikali, lakini mifano mengi yanadhani kuwa mijadala yatashinda hasa kwa njia ya juu au udhibiti wa agenda. Ideally, however, debates would be won on the merits, as a function of which side has the stronger arguments.  Tunazipendekeza mtindo wa utabiri wa mjadala unakadiria madhara ya tabia za lugha na nguvu za hivi karibuni za mada tofauti, pamoja na mahusiano kati ya hizo mbili. Kwa kutumia seti ya taarifa ya mijadala ya aina 118 Oxford, muunganiko wa maudhui yetu (kama mada ya hivi karibuni) na mtindo (kama vipengele vya lugha) unaruhusu kutabiri washindi wenye asilimia 74 yenye uhakika, kwa kiasi kikubwa unaoendesha vipengele vya lugha peke yake (asilimia 66). Mfano wetu unagundua kuwa upande wa kushinda hutumia hoja yenye nguvu, na inaturuhusu kutambua tabia za lugha zinazohusiana na hoja ngumu au udhaifu.', 'fa': 'بحث و مشورت نقش اصلی در سیاست و دولت بازی می\u200cکنند، ولی بیشتر مدل\u200cها تصور می\u200cکنند که بحث\u200cها بیشتر از طریق کنترل طریق بالاتر یا برنامه\u200cی روزنامه برنده می\u200cشوند. با این حال، در نظر نظر، بحث\u200cها در حقیقت برنده می\u200cشود، به عنوان تابعی که از طرف آن بحث\u200cهای قوی\u200cتری دارد. ما یک مدل پیش\u200cبینی از بحث پیش\u200cبینی را پیشنهاد می\u200cکنیم که اثرات ویژه\u200cهای زبان\u200cشناسی و قوت\u200cهای پیچیده\u200cای از موضوع\u200cهای مختلف و همچنین تعامل بین آن دو را تخمین می\u200cدهد. با استفاده از مجموعه داده\u200cهای ۱۸۸ بحث\u200cهای طرح اکسفورد، ترکیب محتویات مدل ما (به عنوان موضوعات latent) و طرح (به عنوان ویژه\u200cهای زبان\u200cشناسی) اجازه می\u200cدهد که برنده\u200cهای مشهور را پیش\u200cبینی کنیم با دقیق 74 درصد، که تنها ویژه\u200cهای زبان\u200cشناسی (66 در مدل ما متوجه می شود که پیروزی از طرف برنده\u200cها مجادله\u200cهای قوی\u200cتر استفاده می\u200cکنند و اجازه می\u200cدهد که ویژه\u200cهای زبان\u200cشناسی که با مجادله\u200cهای قوی یا ضعیف ارتباط دارند شناسایی کنیم.', 'tr': 'Debatlar we düşünseler syýasatda we hökümetde esasy roller oýnaýarlar, ýöne köp nusgalar debatlar üsti stil ýa-da agenda kontrol bilen ýeňildigini düşünýärler. Iň pikirimçe, tartışmalar hakykatda ýeňildi, bir funksiýasy bolsa bu tarapyň has güçli tartışmalary bar. Biz debatlaryň öngörüjli nusgasyny teklip edip görýäris ki, bu durum lingwistiki özellikleriň täsirini we soňky ynamly temalaryň güýçlerini deňleýär. 118-nji Oksforda tartışmalaryň halyndan ullanýarys, nusgasymyzda (geçmişi temalar hökmünde) we stilimiz (lingwistiki özellikler hökmünde) publikalaryň 74% dyrlyk bilen ýeňiji çaklamak üçin mümkin edýär. Biziň modelimiz ýeňiji taraplarymyň güýçli argumlaryny ulanýandygyny we güýçli ýa zayıf argumlar bilen baglanýan lingwistiki özellikleri tanamagymyza mümkin edýär.', 'af': "Debate en besluit speel noodsaaklike roles in politiek en regering, maar meeste modele voorstel dat debatasies hoofsaaklik gewen word deur superior styl of agenda kontrole. Ideële, maar, debate sou gewen word op die merite, as 'n funksie waarvan die sterker argumente het. Ons voorstel 'n voorskou model van debat wat die effekte van lingwisiese funksies en die latente persuasive sterkte van verskillende onderwerpe, en die interaksies tussen die twee. Gebruik van 'n datastel van 118 Oxford-styl debate, laat ons die model se kombinasie van inhoud (a s latent onderwerpe) en styl (as lingwisiese funksies) ons toe om onderwerp te voorskou van onderwerpe wat oordeel is met 74% waarskynlik, betekenlik uitgevoerde lingwisiese funksies alleen (66%). Ons model vind dat vinnige kante sterker argumente gebruik, en laat ons toe om die lingwisiese funksies te identifiseer wat met sterke of swakke argumente geassosieer word.", 'sq': 'Debati dhe diskutimi luajnë rolin thelbësor në politikë dhe qeveri, por shumica e modeleve supozojnë se debatet fitohen kryesisht nëpërmjet stilit superior apo kontrollit të axhendës. Idealisht, megjithatë, debatet do të fitohen mbi meritat, si një funksion i cilit anë ka argumentet më të forta. We propose a predictive model of debate that estimates the effects of linguistic features and the latent persuasive strengths of different topics, as well as the interactions between the two.  Duke përdorur një s ërë të dhënash të 118 debateve të stilit të Oksfordit, kombinimi i përmbajtjes (si temë të fshehta) dhe stilit (si karakteristika gjuhësore) i modelit tonë na lejon të parashikojmë fituesit me 74% saktësi, duke kaluar në mënyrë të konsiderueshme karakteristikat gjuhësore vetëm (66%). Modeli ynë gjen se palët fituese përdorin argumente më të forta dhe na lejon të identifikojmë karakteristikat gjuhësore të lidhura me argumente të forta apo të dobëta.', 'am': 'የፖለቲካ እና መንግሥት ውስጥ የግማሽ ሽልማት እና አዋቂነት ይጫወታሉ፤ ነገር ግን አብዛኛዎቹ ምሳሌዎች በተለይ ዓይነት ወይም በዕራባዊ ግንኙነት ያሸንፋሉ፡፡ በአሳብ፣ ምንም እንኳን ክርክር በብርቱ ላይ ማድረግ ይችላል፡፡ የቋንቋዊ ምርጫዎች እና የመጨረሻው የልዩ ጉዳዮች እና በሁለቱም መካከል ግንኙነት የሚቆጠርን የውይይት የውይይት ምሳሌ እናሳውቃለን፡፡ በ118 Oxford-style ውይይት የተጠቃሚ የሞዴል ውይይት (የአሁኑ ጉዳይ) እና ዓይነት (የቋንቋዊ ምርጫዎች እንደ ቋንቋ እውቀት) የሚጠቅሙትን 74 በመቶ እርግጠኛ አሸናፊዎች በቋንቋዎች ብቻውን ለማሳየት ይችላል (66 በመቶ)፡፡ ምሳሌያችን አሸናፊዎች የበረቱትን ክርክሮች እንዲያስፈልጋሉ እናም በኃይለኛ ወይም ደካማ ክርክሮች ጋር የተጋራውን የቋንቋዊ ፍጥረት እናሳውቃለን፡፡', 'hy': 'Debate and deliberation play essential roles in politics and government, but most models presume that debates are won mainly via superior style or agenda control.  Իրականում, այնուամենայնիվ, քննարկումները կհաղթահարվեն արժանքների վրա, քանի որ որևէ կողմի ֆունկցիան ունի ավելի ուժեղ բանավեճեր: Մենք առաջարկում ենք քննարկության կանխատեսող մոդել, որը գնահատում է լեզվաբանական հատկանիշների ազդեցությունները և տարբեր թեմաների թաքնված համոզող ուժերը, ինչպես նաև երկուսի միջև փոխազդեցությունները: Օգտագործելով 118 Օքսֆորդի ոճի քննարկումների տվյալներ, մեր մոդելի պարունակության (ինչպես թաքնված թեմաներ) և ոճի (որպես լեզվաբանական հատկություններ) համադրությունը թույլ է տալիս մեզ կանխատեսել հանդիսատեսի հաղթերին 74 տոկոսի ճշգրտությամբ, որոնք շատ ավելի լավ են արտադրում միայն լեզվաբանական հա Մեր մոդելը հայտնաբերում է, որ հաղթանակի կողմերը օգտագործում են ավելի ուժեղ բանավեճեր և թույլ է տալիս մեզ բացահայտել լեզվաբանական հատկությունները, որոնք կապված են ուժեղ կամ թույլ բանավեճերի', 'hr': 'Debata i razmišljanja igraju ključne uloge u politici i vladi, ali većina modela pretpostavlja da se debati osvoje uglavnom putem nadmoćnog stila ili kontrole programa. Međutim, idealno bi se rasprave osvojile na zasluge, kao funkcija kojoj strana ima jače argumente. Predlažemo predvidljiv model rasprave koji procjenjuje učinak jezičkih karakteristika i latentne uvjerljive snage različitih tema, kao i interakcije između njih. Koristeći podatke o 118 diskusija u stilu Oxford-a, kombinacija sadržaja našeg modela (kao latentne teme) i stila (kao lingvističke karakteristike) omogućava nam predvidjeti pobjednike osuđene na publiku sa preciznošću 74%, značajno iznosi samo lingvističke karakteristike (66%). Naš model nalazi da pobjedničke strane koriste jače argumente i omogućava nam identificirati jezičke karakteristike povezane sa jakim ili slabim argumentima.', 'az': 'Dövlət və müzakirə siyasi və hökumətdə əsas rollər oynayır, amma çox modellərin müzakirə edilməsini çox yüksək stil və ya agenda kontrol vasitəsilə qəbul edir. Ancaq ideyal olaraq, mübahisələr qiymətlərdə qələbə çalacaqlar, çünki bu funksiyanın daha qüvvətli dəlilləri vardır. Biz dil özelliklərinin təsirlərini və müxtəlif məsələlərin sonrakı təsirlərini təmin edən müzakirə modeli təklif edirik, həmçinin onların arasındakı müxtəlif təsirlərin təsirlərini təmin edir. 118 Oxford stili müzakirələrinin verilən dəyişiklikləri istifadə edərək, modelimizin məlumatı (latent topics olaraq) və stili (dil özellikləri olaraq) bizə 74% ədalətlə müzakirənləri təmin edə bilər, dil özellikləri yalnız (66%) istifadə edə bilər. Bizim modellərimiz qələbə çatmaq üçün daha qüvvətli argumentlər istifadə edir və bizə güclü və zəif argumentlərlə bağlı dil özelliklərini təsdiqləməyə imkan verir.', 'bn': 'রাজনৈতিক এবং সরকারের প্রধান ভূমিকা বিতর্ক এবং পরিকল্পনা করে, কিন্তু বেশীরভাগ মডেল ধারণা করে যে বিতর্কের মূল ধারণা হচ্ছে যে বিতর্কের ম কিন্তু চিন্তাভাবে বিতর্কের মাধ্যমে বিজয়ী হবে, যেহেতু কোন দিকে শক্তিশালী যুক্তি রয়েছে। আমরা বিতর্কের একটি ভবিষ্যৎ মডেল প্রস্তাব করছি যা ভাষাগত বৈশিষ্ট্যের প্রভাব এবং সাম্প্রতিক বিষয়গুলোর বিষয়গুলোর প্রভাব হিসেবে হিসেব করে দেয়, আর ১১৮ অক্সফোর্ড-স্টাইল বিতর্ক ব্যবহার করে আমাদের মডেলের বিষয়বস্তুর সম্মিলন (সাম্প্রতিক বিষয় হিসেবে) এবং স্টাইল (ভাষাগত বৈশিষ্ট্য হিসেবে) আমাদের ভবিষ্যদ্বাণী করার অনুমতি দেয় যে শ্রোতারা ব আমাদের মডেল খুঁজে পেয়েছে যে পার্শ্ববর্তীরা শক্তিশালী যুক্তি প্রদান করে এবং আমাদেরকে শক্তিশালী অথবা দুর্বল যুক্তির সাথে যু', 'bs': 'Debata i razmišljanja igraju ključne uloge u politici i vladi, ali većina modela pretpostavlja da se debati osvoje uglavnom putem nadmoćnog stila ili kontrole programa. Međutim, idealno bi se rasprave osvojile na zaslugu, kao funkcija kojoj strana ima jače argumente. Predlažemo predvidljiv model debata koji procjenjuje učinak jezičkih karakteristika i latentne uvjerljive snage različitih tema, kao i interakcije između njih. Koristeći podatke o 118 diskusija u stilu Oksforda, kombinacija sadržaja našeg model a (kao latentne teme) i stila (kao lingvističke karakteristike) omogućava nam predvidjeti pobjednike koji su osuđeni na publiku sa preciznošću 74%, značajno iznosi samo lingvističke karakteristike (66%). Naš model nalazi da pobjedničke strane koriste jače argumente i omogućava nam da identificiramo jezičke karakteristike povezane sa jakim ili slabim argumentima.', 'ca': "La debat i la deliberació juguen rols essencials en la política i el govern, però la majoria de models suposen que els debats es guanyen principalment amb un estil superior o un control de l'agenda. Idealment, no obstant això, es guanyarien debats sobre els mérits, en funció de quina banda té els arguments més forts. Proposem un model de debat preditiu que estimi els efectes de les característiques lingüístices i les fortituds persuasives latents de diferents temes, com també les interaccions entre els dos. Utilitzant un conjunt de dades de 118 debats d'estil Oxford, la combinació del nostre model de contingut (com a temes latent s) i estil (com a característiques lingüístices) ens permet predir els guanyadors adjudicats per audiència amb un 74% de precisió, que s ón significativament superiors a les característiques lingüístices (66%). El nostre model descobre que els costats guanyadors emplenen arguments més forts i ens permet identificar les característiques lingüístices associades a arguments forts o dèbils.", 'cs': 'Debata a debata hrají zásadní roli v politice a vládě, ale většina modelů předpokládá, že debaty jsou vyhrávány hlavně prostřednictvím nadřazeného stylu nebo kontroly agendy. V ideálním případě by však byly diskuse vyhrávány na základě zásluh, která strana má silnější argumenty. Navrhujeme prediktivní model debaty, který odhaduje účinky jazykových rysů a latentní přesvědčivé síly různých témat, stejně jako interakce mezi nimi. Pomocí datové sady debat ve stylu 118 Oxfordu nám kombinace obsahu (jako latentních témat) a stylu (jako jazykových rysů) umožňuje předpovídat vítěze posuzované publikem s přesností 74% a výrazně překonat jazykové vlastnosti samotné (66%). Náš model zjišťuje, že vítězné strany používají silnější argumenty a umožňují nám identifikovat jazykové rysy spojené se silnými nebo slabými argumenty.', 'et': 'Arutelu ja arutelu mängivad poliitikas ja valitsuses olulist rolli, kuid enamik mudeleid eeldab, et arutelud võidavad peamiselt kõrgema stiili või päevakorra kontrolli kaudu. Ideaalis võidaks aga arutelud selle põhjal, millisel poolel on tugevamad argumendid. Pakume välja ennustava debati mudeli, mis hindab erinevate teemade keeleliste omaduste mõju ja latentseid veenevaid tugevusi ning nende kahe vahelisi vastastikuseid mõjusid. Kasutades 118 Oxfordi stiilis debatti andmekogumit, võimaldab meie mudeli sisu (latentsete teemadena) ja stiili (keeleliste omadustena) kombinatsioon ennustada publiku poolt hinnatud võitjaid 74% täpsusega, mis ületab märkimisväärselt keelelisi omadusi (66%). Meie mudel leiab, et võitnud pooled kasutavad tugevamaid argumente ja võimaldavad meil tuvastada tugevate või nõrkade argumentidega seotud keelelisi tunnuseid.', 'fi': 'Keskustelulla ja pohdinnalla on keskeinen rooli politiikassa ja hallinnossa, mutta useimmat mallit olettavat, että keskustelut voitetaan pääasiassa ylivoimaisen tyylin tai esityslistan hallinnan avulla. Ihanteellisessa tapauksessa keskustelut voitettaisiin ansioista, sillä kummalla puolella on vahvemmat argumentit. Ehdotamme ennakoivaa keskustelumallia, joka arvioi eri aiheiden kielellisten ominaisuuksien vaikutuksia ja piileviä suostuttelevia vahvuuksia sekä niiden välisiä vuorovaikutuksia. Käyttämällä 118 Oxfordin tyylistä keskustelua sisältävää aineistoa mallimme sisällön (piilevinä aiheina) ja tyylin (kielellisinä ominaisuuksina) yhdistelmä mahdollistaa sen, että voimme ennustaa yleisön palkittuja voittajia 74%:n tarkkuudella, mikä ylittää merkittävästi pelkästään kielelliset ominaisuudet (66%). Mallimme toteaa, että voittavat osapuolet käyttävät vahvempia argumentteja ja antaa meille mahdollisuuden tunnistaa vahvoihin tai heikkoihin argumentteihin liittyvät kielelliset piirteet.', 'jv': 'Debate lan Debate kuwi beraksi sing dikarol sing dikarepaké ning pulitik lan hukum sing dimulai, lha ngomong model sing nyimpen kuwi debatar iki bakal dhéwé uga sing nduwé ngerasakno stigal sing apik dhéwé. Nanging, dadi, debat kuwi wis rampun nang awak dhéwé, nganggo funksi sing katêpakan karo argument sing mbrasané. Awak dhéwé nggunakake model sing ngerasakno karo debasar sing tatabanjuré efek karo nggawe barang nggawe barang nggawe gerakan karo paké sampek, lan tambah njaluk interaksi iki. Using a dataset of 2 model dhéwé kuwi nggap banjuré awak dhéwé nggawe sawar luwih dumadhi, lan supoyo awak dhéwé kuwi mau kudu nggawe kesempatan barêng-barêng langgambar sing apik dhéwé o nguwis argument sing apik dhéwé.', 'sk': 'Razprava in razprava imata bistveno vlogo v politiki in vladi, vendar večina modelov predvideva, da se razprave osvojijo predvsem z vrhunskim slogom ali nadzorom dnevnega reda. V idealnem primeru pa bi se razprave zmagale glede na zasluge, saj ima katera stran močnejše argumente. Predlagamo napovedni model debate, ki ocenjuje učinke jezikovnih značilnosti in latentne prepričevalne moči različnih tem ter interakcije med obema. Kombinacija vsebine (kot latentne teme) in sloga (kot jezikovne značilnosti) našega modela nam omogoča s 74% natančnostjo napovedovanja zmagovalcev, ki jih ocenjuje občinstvo, kar pomembno presega samo jezikovne značilnosti (66%). Naš model ugotavlja, da zmagovalne strani uporabljajo močnejše argumente in nam omogoča prepoznavanje jezikovnih značilnosti, povezanih z močnimi ali šibkimi argumenti.', 'he': "דיון והשיקול משחקים תפקידים חיוניים בפוליטיקה וממשלה, אך רוב הדוגמנים מניחים שדיון מנצח בעיקר באמצעות סגנון עליון או שליטה באג'נדה. באופן אידיאלי, בכל אופן, יזכו דיונים על העובדות, בתפקיד של איזה צד יש הטיעונים החזקים. אנו מציעים מודל צפוי של דיון שמעריך את ההשפעות של תכונות שפתיים והכוחות השכנעים המוסתרים של נושאים שונים, כמו גם את האינטראקציות בין שניהם. באמצעות קבוצת נתונים של 118 דיון בסגנון אוקספורד, שילוב התוכן של המודל שלנו (בתור נושאים חסויים) וסגנון (בתור תכונות שפתיות) מאפשר לנו לחזות מנצחים מוערכים על ידי קהל עם מדויקת 74%, שיוצאים משמעותית יותר מהתכונות שפתיות בלבד (66%). המודל שלנו מוצא שצדדים מנצחים משתמשים בטיעונים חזקים יותר, ומאפשר לנו לזהות את המאפיינים הלשוניים הקשורים לטיעונים חזקים או חלשים.", 'bo': "Debate and deliberation play essential roles in politics and government, but most models presume that debates are won mainly via superior style or agenda control. Ideally, debate would be won on the merits, as a function of which side has the stronger arguments. ང་ཚོས་སྐད་རིགས་ཆེན་དང་འདྲ་བ་གཉིས་དབར་གྱི་གནད་དོན་གྱི་རྐྱེན་གྲངས་མ་མཐུན་ཁག་ཅིག་སྟོན་ཐུབ་ཀྱི་ཡོད། Using a dataset of 118 Oxford-style debates, our model's combination of content (as latent topics) and style (as linguistic features) allows us to predict audience-adjudicated winners with 74% accuracy, significantly outperforming linguistic features alone (66%). ང་ཚོའི་མ་དབྱིབས་རྒྱལ་ཁབ་ཀྱིས་རྒྱལ་ཁབ་ཀྱི་སྒྲུབ་རྟགས་མང་ཙམ་ལག་ལེན་འཐབ་བྱེད་ཐུབ་ཀྱི་ཡོད་ཚད་དང་མཐུན", 'ha': "Haƙĩƙa da kafirawa sun yi aiki na muhimu a cikin siasa da sarama, kuma amma mafi yawansu misãlai sun yi zaton za a rinjãye jãyayya mainli mainli a kan tsarin sarki ko kuma domin madaraka. Kayya, ko da yaushe, za'a rinjãye jãyayya a kan halinsa, kamar wani aiki daga wanne ne mafi tsananin rabo. Tune goyyar da wani misãli mai bayani da jãyayya wanda ke ƙaddara matsayin fassarar cikin harshen da ƙarshen ƙarshen ƙarfin masu bayani-bayani, da kuma masu haɗi da tsakanin su biyu. Yi amfani da tsarin jayayi masu motsi na 118 Oxfield-style, misalinmu na koma da mazaɓa (kamar madaidaita masu ƙarani) da salon (kamar masu cikin linguistic) na yarda mu yi bayani ko da za'a gabanta masu gusarwa da tsohon saurãre da 74% tabbatacce, kuma yana samar da wasu fasihi na linguistic kawai (66%). Misalinmu ya gane cewa idan an rinjãya ƙungiyõyinmu, sai ya yi amfani da sharuɗe masu ƙaranci, kuma yana yarda mu gane masu tsari cikin harshen da ke yi na husũma masu ƙarfi ko kuwa masu rauni."}
{'en': 'Domain-Targeted, High Precision Knowledge Extraction', 'fr': 'Extraction de connaissances de haute précision ciblée par domaine', 'pt': 'Extração de conhecimento de alta precisão e direcionada ao domínio', 'es': 'Extracción de conocimiento de alta precisión y dirigida al dominio', 'hi': 'डोमेन-लक्षित, उच्च परिशुद्धता ज्ञान निष्कर्षण', 'zh': '提取高精度知', 'ja': 'ドメインターゲット型の高精度ナレッジ抽出', 'ar': 'استخلاص المعرفة عالية الدقة الموجه المجال', 'ga': 'Fearann-Spriocdhírithe, Eastóscadh Faisnéise Ardchruinneas', 'ru': 'Извлечение знаний, ориентированное на домен, с высокой точностью', 'hu': 'Tartományra célzott, nagy pontosságú tudáskivonás', 'el': 'Εκχύλισμα γνώσης υψηλής ακρίβειας με στόχο τον τομέα', 'it': 'Estrazione di conoscenze mirate al dominio e ad alta precisione', 'ka': 'დომინური მიზეზი, უფრო წესიერებული მეცნიერება', 'lt': 'Tikslinės srities, aukštos tikslumo žinių ekstrahavimas', 'ml': 'ഡൊമെയിന്\u200d - ലക്ഷ്യമാക്കിയിരിക്കുന്നു, അത്യുന്നതമായ പരിജ്ഞാനം പുറത്തെടുക്കുക', 'mk': 'Екстракција на знаење со висока точност со домен', 'mt': 'Estrazzjoni ta’ Għarfien ta’ Preċiżjoni Għolja mmirat lejn id-dominju', 'mn': 'Гол зорилготой, өндөр тодорхойлолтой мэдлэг хадгалах', 'pl': 'Ukierunkowana na domenę, precyzyjna ekstrakcja wiedzy', 'ms': 'Sasaran-Domain, Ekstraksi Pengetahuan Tepat Tinggi', 'ro': 'Extracție de cunoștințe de înaltă precizie, orientată spre domenii', 'si': 'ඩොමේන් එක්ක ඉලක්කය, වැඩි ප්\u200dරතිස්ථානය දැනගන්න', 'sr': 'Cilj domena, izvlačenje znanja visoke preciznosti', 'so': 'Gargaarka Domain, soo bixinta aqoonta hore', 'sv': 'Utdrag av domänriktad kunskap med hög precision', 'ta': 'டோமைன் குறிப்பிடப்பட்டது, அதிக துல்லியமான அறிவு பிரித்தல்', 'kk': 'Доменге мақсат етілген, жоғары дәл дәл мәліметті түсіру', 'ur': 'درمیان کا موقع ہے، بلند مضبوط علم نکالنا', 'no': 'Domenemålet, høg nøyaktig kunnskap utpakking', 'uz': 'Domen- tarkibini aniqlash', 'vi': 'Phân miền nhắm, đánh răng cao cao', 'hr': 'Cilj domena, izvlačenje znanja o visokoj preciznosti', 'da': 'Uddrag af domæne målrettet, høj præcision viden', 'nl': 'Domein-gerichte kennisextractie met hoge precisie', 'bg': 'Насочено към домейна, високопрецизно извличане на знания', 'fa': 'هدف\u200cهای دامنه، اخراج دانش دقیق بالا', 'ko': '영역을 향한 고정밀 지식 추출', 'id': 'Domain-Targeted, Precision Tinggi Pengetahuan Ekstraksi', 'de': 'Domänenorientierte, hochpräzise Wissensextraktion', 'sw': 'Toleo la Domain, Toleo la Ujuzi Mkuu', 'tr': 'Açmak hedefi, beýik liman Bilgi Açmak', 'sq': 'Ekstraktimi i njohurive të saktësisë së lartë me objektiv të dominit', 'af': 'Domein- Teël, Hoë Presisie kennis uittrek', 'am': 'አቀማመጥ', 'hy': 'Դոմենի նպատակով, բարձր ճշգրտություն գիտելիքների վերացումը', 'az': 'Domain-Tariq, Yüksek Düzgün Bilgi Extraction', 'bs': 'Cilj domena, izvlačenje znanja visoke preciznosti', 'bn': 'ডোমেইন- টার্গেট, উচ্চসমূহের জ্ঞান এক্সট্র্যাকশন', 'cs': 'Vysoce přesná extrakce znalostí zaměřená na doménu', 'et': 'Domeenile suunatud, suure täpsusega teadmiste väljavõtmine', 'fi': 'Domain-kohdennettu, erittäin tarkka tietämyksen poiminta', 'ca': "Extracció de coneixements d'alta precisió dirigida al domini", 'he': 'Domain-Targeted, High Precision Knowledge Extraction', 'sk': 'Domensko usmerjeno, visoko natančno pridobivanje znanja', 'jv': 'Valve', 'bo': 'དྲ་གནས་ཁོངས་ལ་དམིགས་ཡུལ་དང་། སྙིང་རིས་མཐོ་ཤོས་ཀྱི་ཕྱིར་འདུག', 'ha': 'Phonon:: MMF:: EffectFactory'}
{'en': 'Our goal is to construct a domain-targeted, high precision knowledge base (KB), containing general (subject, predicate, object) statements about the world, in support of a downstream question-answering (QA) application. Despite recent advances in information extraction (IE) techniques, no suitable resource for our task already exists ; existing resources are either too noisy, too named-entity centric, or too incomplete, and typically have not been constructed with a clear scope or purpose. To address these, we have created a domain-targeted, high precision knowledge extraction pipeline, leveraging Open IE, crowdsourcing, and a novel canonical schema learning algorithm (called CASI), that produces high precision knowledge targeted to a particular domain-in our case, elementary science. To measure the KB’s coverage of the target domain’s knowledge (its comprehensiveness with respect to science) we measure recall with respect to an independent corpus of domain text, and show that our pipeline produces output with over 80 % precision and 23 % recall with respect to that target, a substantially higher coverage of tuple-expressible science knowledge than other comparable resources. We have made the KB publicly available.', 'ar': 'هدفنا هو بناء قاعدة معرفية عالية الدقة وموجهة إلى المجال (KB) ، تحتوي على عبارات عامة (الموضوع ، المسند ، الكائن) حول العالم ، لدعم تطبيق الإجابة على الأسئلة (QA). على الرغم من التطورات الحديثة في تقنيات استخراج المعلومات (IE) ، لا يوجد بالفعل مورد مناسب لمهمتنا ؛ الموارد الحالية إما صاخبة للغاية ، أو تتمحور حول كيان مسمى للغاية ، أو غير مكتملة للغاية ، وعادة لم يتم إنشاؤها بنطاق أو غرض واضح. لمعالجة هذه المشكلات ، أنشأنا خط أنابيب لاستخراج المعرفة عالي الدقة وموجه نحو المجال ، والاستفادة من Open IE ، والتعهيد الجماعي ، وخوارزمية تعلم مخطط أساسي جديدة (تسمى CASI) ، والتي تنتج معرفة عالية الدقة تستهدف مجالًا معينًا - في حالتنا ، العلوم الابتدائية. لقياس تغطية KB لمعرفة المجال الهدف ("شمولية" فيما يتعلق بالعلوم) نقيس الاستدعاء فيما يتعلق بمجموعة مستقلة من نص المجال ، ونبين أن خط الأنابيب لدينا ينتج مخرجات بدقة تزيد عن 80٪ و 23٪ يتذكره باستخدام فيما يتعلق بهذا الهدف ، تغطية أعلى بكثير للمعرفة العلمية القابلة للتعبير عن الصفوف مقارنة بالموارد الأخرى المماثلة. لقد جعلنا KB متاحًا للجمهور.', 'es': 'Nuestro objetivo es construir una base de conocimientos (KB) de alta precisión y dirigida al dominio, que contenga declaraciones generales (sujeto, predicado, objeto) sobre el mundo, en apoyo de una aplicación de respuesta a preguntas (QA) descendente. A pesar de los avances recientes en las técnicas de extracción de información (IE), ya no existe ningún recurso adecuado para nuestra tarea; los recursos existentes son demasiado ruidosos, están demasiado centrados en la entidad nombrada o están demasiado incompletos y, por lo general, no se han construido con un alcance o propósito claros. Para abordarlos, hemos creado un canal de extracción de conocimiento de alta precisión y orientado al dominio, que aprovecha Open IE, el crowdsourcing y un novedoso algoritmo de aprendizaje de esquemas canónicos (llamado CASI), que produce conocimiento de alta precisión dirigido a un dominio en particular, en nuestro caso, la ciencia elemental. Para medir la cobertura de la base de conocimientos del conocimiento del dominio de destino (su «exhaustividad» con respecto a la ciencia), medimos la recuperación con respecto a un corpus independiente de texto de dominio y mostramos que nuestra canalización produce resultados con más del 80% de precisión y el 23% de recuperación con respecto a ese objetivo, un mayor cobertura del conocimiento científico expresable por tuplas que otros recursos comparables. Hemos puesto la base de conocimiento a disposición del público.', 'pt': 'Nosso objetivo é construir uma base de conhecimento (KB) de alta precisão, direcionada ao domínio, contendo declarações gerais (sujeito, predicado, objeto) sobre o mundo, em apoio a um aplicativo de resposta a perguntas (QA) downstream. Apesar dos recentes avanços nas técnicas de extração de informação (IE), ainda não existe nenhum recurso adequado para nossa tarefa; os recursos existentes são muito barulhentos, muito centrados em entidades nomeadas ou muito incompletos e normalmente não foram construídos com um escopo ou propósito claros. Para resolver isso, criamos um pipeline de extração de conhecimento de alta precisão e direcionado ao domínio, aproveitando o Open IE, crowdsourcing e um novo algoritmo de aprendizado de esquema canônico (chamado CASI), que produz conhecimento de alta precisão direcionado a um domínio específico - no nosso caso , ciência elementar. Para medir a cobertura da base de conhecimento do conhecimento do domínio de destino (sua “compreensibilidade” em relação à ciência), medimos o recall em relação a um corpus independente de texto do domínio e mostramos que nosso pipeline produz saída com mais de 80% de precisão e 23% de recall com em relação a essa meta, uma cobertura substancialmente maior de conhecimento científico exprimível em tupla do que outros recursos comparáveis. Disponibilizamos a KB publicamente.', 'fr': "Notre objectif est de construire une base de connaissances (KB) de haute précision ciblée par domaine, contenant des déclarations générales (sujet, prédicat, objet) sur le monde, à l'appui d'une application de réponse aux questions (AQ) en aval. Malgré les progrès récents dans les techniques d'extraction d'informations (IE), aucune ressource adaptée à notre tâche n'existe déjà\xa0; les ressources existantes sont soit trop bruyantes, trop centrées sur les entités nommées, soit trop incomplètes, et n'ont généralement pas été construites avec une portée ou un objectif précis. Pour y remédier, nous avons créé un pipeline d'extraction de connaissances de haute précision ciblé par domaine, utilisant Open IE, le crowdsourcing et un nouvel algorithme canonique d'apprentissage de schéma (appelé CASI), qui produit des connaissances de haute précision ciblées sur un domaine particulier, dans notre cas, les sciences élémentaires. Pour mesurer la couverture des connaissances du domaine cible par la base de connaissances (son «\xa0exhaustivité\xa0» par rapport à la science), nous mesurons le rappel par rapport à un corpus indépendant de textes de domaine, et montrons que notre pipeline produit des résultats avec une précision de plus de 80\xa0% et un rappel de 23\xa0% par rapport à cette cible, un couverture plus élevée de connaissances scientifiques pouvant être exprimées par tuple que d'autres ressources comparables. Nous avons rendu la base de connaissances accessible au public.", 'ja': '私たちの目標は、下流の質問応答（ QA ）アプリケーションをサポートするために、世界に関する一般的な（主題、述語、目的）記述を含む、ドメインターゲット型の高精度ナレッジベース（ KB ）を構築することです。 最近の情報抽出（ IE ）技術の進歩にもかかわらず、当社のタスクに適したリソースはすでに存在しません。既存のリソースは、あまりにも騒音が大きいか、名前のあるエンティティ中心であるか、または不完全すぎるかのいずれかであり、通常、明確な範囲または目的で構築されていません。 これらに対処するために、私たちはOpen IE、クラウドソーシング、そして特定のドメインを対象とした高精度の知識を生成する新規の正準スキーマ学習アルゴリズム（ CASIと呼ばれる）を活用して、ドメインターゲットの高精度の知識抽出パイプラインを作成しました。私たちの場合は、基礎科学です。 KBのターゲットドメインの知識のカバレッジ（科学に関する「包括性」）を測定するために、私たちはドメインテキストの独立したコーパスに関してリコールを測定し、パイプラインがそのターゲットに関して80 ％以上の精度と23 ％のリコールで出力を生成し、他の同等のリソースよりもタプル表現可能な科学知識のカバレッジを実質的に高くすることを示します。 KBを一般公開しました。', 'zh': '所向者,构一以域之高精度知识库 (KB),含世界之(题、谓词、所)语,以扶下流问答 (QA) 应用程序。 信息提取(IE)术近进,未有适我之资。 今有资源要么太嘈杂,要么太以名实体为中心,要么太不完全,且常无建立明限。 为此者,吾创一以域为的高精度知取管道,因Open IE,众包与一新规模学算法(谓之CASI),当算法生于特定域之高精度知 - 于吾例,基础科学。 夫量知识库之盖(其在科学之全面性),吾量独领之文本语料库之召率,而明吾道之输过80%,召率过23%,元组表科学知识之覆盖率,远高他资。 吾已布知识库矣。', 'hi': 'हमारा लक्ष्य एक डोमेन-लक्षित, उच्च परिशुद्धता ज्ञान आधार (KB) का निर्माण करना है, जिसमें दुनिया के बारे में सामान्य (विषय, विधेय, ऑब्जेक्ट) कथन शामिल हैं, एक डाउनस्ट्रीम प्रश्न-उत्तर (क्यूए) एप्लिकेशन के समर्थन में। सूचना निष्कर्षण (आईई) तकनीकों में हाल की प्रगति के बावजूद, हमारे कार्य के लिए कोई उपयुक्त संसाधन पहले से ही मौजूद नहीं है; मौजूदा संसाधन या तो बहुत शोर कर रहे हैं, बहुत नामित-इकाई केंद्रित, या बहुत अधूरे हैं, और आमतौर पर एक स्पष्ट दायरे या उद्देश्य के साथ निर्माण नहीं किया गया है। इन्हें संबोधित करने के लिए, हमने एक डोमेन-लक्षित, उच्च परिशुद्धता ज्ञान निष्कर्षण पाइपलाइन बनाई है, ओपन आईई, क्राउडसोर्सिंग, और एक उपन्यास विहित स्कीमा सीखने के एल्गोरिथ्म (जिसे सीएएसआई कहा जाता है) का लाभ उठाते हुए, जो एक विशेष डोमेन को लक्षित उच्च परिशुद्धता ज्ञान का उत्पादन करता है - हमारे मामले में, प्राथमिक विज्ञान। लक्ष्य डोमेन के ज्ञान के KB के कवरेज को मापने के लिए (विज्ञान के संबंध में इसकी "व्यापकता") हम डोमेन पाठ के एक स्वतंत्र कॉर्पस के संबंध में याद करते हैं, और दिखाते हैं कि हमारी पाइपलाइन उस लक्ष्य के संबंध में 80% से अधिक परिशुद्धता और 23% याद के साथ आउटपुट का उत्पादन करती है, अन्य तुलनीय संसाधनों की तुलना में टपल-एक्सप्रेसेबल विज्ञान ज्ञान का काफी अधिक कवरेज। हमने KB को सार्वजनिक रूप से उपलब्ध कराया है।', 'ru': 'Наша цель состоит в создании ориентированной на домен высокоточной базы знаний (КБ), содержащей общие (предметные,предикатные,объектные) утверждения о мире, в поддержку последующего приложения, отвечающего на вопросы (QA). Несмотря на недавние достижения в методах извлечения информации (IE), подходящего ресурса для нашей задачи уже не существует; существующие ресурсы либо слишком шумные, слишком ориентированные на сущность с именем, либо слишком неполные, и, как правило, не были построены с четким объемом или целью. Для решения этих проблем мы создали ориентированный на область, высокоточный конвейер извлечения знаний, использующий Open IE, краудсорсинг и новый канонический алгоритм обучения схеме (называемый CASI), который производит высокоточные знания, нацеленные на конкретную область - в нашем случае, элементарную науку. Чтобы измерить охват КБ знаний целевого домена (его «всеобъемлющий» по отношению к науке), мы измеряем отзыв относительно независимого корпуса доменного текста и показываем, что наш трубопровод производит выход с точностью более 80% и отзыв 23% по отношению к этой цели, значительно более высокий охват кортежных научных знаний, чем другие сопоставимые ресурсы. Мы сделали КБ общедоступным.', 'ga': "Is é an sprioc atá againn ná bonn eolais ardchruinneas a bheidh spriocdhírithe ar an bhfearann (KB), ina mbeidh ráitis ghinearálta (ábhar, tuar, réad) faoin domhan, mar thaca le feidhmchlár freagartha ceisteanna iartheachtacha (QA). In ainneoin dul chun cinn le déanaí i dteicnící asbhainte faisnéise (IE), níl aon acmhainn oiriúnach dár tasc ann cheana; tá na hacmhainní atá ann faoi láthair ró-fhuaimneach, ró-ainmnithe d’eintiteas lárnach, nó ró-neamhiomlán, agus go hiondúil níor tógadh iad le scóip nó le cuspóir soiléir. Chun aghaidh a thabhairt orthu seo, tá píblíne eastósctha eolais ardchruinneas spriocdhírithe againn cruthaithe againn, ag giaráil Open IE, sluafhoinsiú, agus algartam foghlama scéimre canonical úrscéal (ar a dtugtar CASI), a tháirgeann eolas ardchruinneas dírithe ar fhearann ar leith - inár gcás. , eolaíocht bhunúsach. Chun clúdach an KB ar eolas an fhearainn sprice (a “chuimsitheacht” maidir le heolaíocht a thomhas) tomhaisimid an aisghlao maidir le corpas neamhspleách de théacs fearainn, agus léirímid go dtáirgíonn ár bpíblíne aschur le breis agus 80% beachtas agus aisghlaoch 23% le maidir leis an sprioc sin, clúdach i bhfad níos airde d'eolas eolaíochta inléirithe tuple ná acmhainní inchomparáide eile. Tá an KB curtha ar fáil go poiblí againn.", 'el': 'Στόχος μας είναι η δημιουργία μιας βάσης γνώσεων υψηλής ακρίβειας με στόχο τον τομέα, η οποία περιέχει γενικές δηλώσεις για τον κόσμο, με σκοπό την υποστήριξη μιας μεταγενέστερης εφαρμογής απάντησης ερωτήσεων (QA). Παρά τις πρόσφατες εξελίξεις στις τεχνικές εξαγωγής πληροφοριών, δεν υπάρχει ήδη κατάλληλος πόρος για το έργο μας. Οι υφιστάμενοι πόροι είναι είτε υπερβολικά θορυβώδεις, υπερβολικά επικεντρωμένοι σε ονομαστικές οντότητες, είτε υπερβολικά ελλιπείς και συνήθως δεν έχουν κατασκευαστεί με σαφή πεδίο εφαρμογής ή σκοπό. Για να αντιμετωπιστούν αυτά, δημιουργήσαμε έναν τομέα-στοχευμένο, υψηλής ακρίβειας αγωγό εξαγωγής γνώσης, αξιοποιώντας το Ανοιχτό και έναν νέο κανονικό αλγόριθμο μάθησης σχήματος (που ονομάζεται Ο οποίος παράγει γνώσεις υψηλής ακρίβειας που στοχεύουν σε ένα συγκεκριμένο τομέα, στην περίπτωσή μας, την στοιχειώδη επιστήμη. Για να μετρήσουμε την κάλυψη της γνώσης του τομέα-στόχου από την ΚΒ (η "πληρότητα" του σε σχέση με την επιστήμη) μετράμε την ανάκληση σε σχέση με ένα ανεξάρτητο σώμα κειμένου τομέα, και αποδεικνύουμε ότι ο αγωγός μας παράγει παραγωγή με ακρίβεια πάνω από 80% και 23% ανάκληση σε σχέση με αυτόν τον στόχο, μια σημαντικά μεγαλύτερη κάλυψη της επιστημονικής γνώσης που εκφράζεται με δύο φορές από άλλους συγκρίσιμους πόρους. Κάναμε τη KB δημόσια διαθέσιμη.', 'hu': 'Célunk egy domain-célzott, nagy pontosságú tudásbázis (KB) létrehozása, amely általános (tárgy, predikátum, objektum) állításokat tartalmaz a világról, egy downstream kérdésválasztó (QA) alkalmazás támogatására. Az információkinyerési (IE) technikák közelmúltbeli fejlődése ellenére már nem létezik megfelelő erőforrás a feladatunkhoz; A meglévő erőforrások vagy túl zajosak, túl nevezett entitásközpontúak, vagy túl hiányosak, és általában nem egyértelmű hatókörrel vagy céllal készültek. Ennek megoldására létrehoztunk egy domain-célzott, nagy pontosságú tudás kitermelési csővezetéket, amely az Open IE, a crowdsourcing és egy új kanonikus séma tanulási algoritmust (CASI) használ, amely nagy pontosságú tudást hoz létre egy adott területre - esetünkben az elemi tudományra - célzott. Annak érdekében, hogy mérjük a KB lefedettségét a céltartomány tudására (annak "átfogóságát" a tudomány szempontjából) egy független tartományszöveg tekintetében mérjük a visszahívást, és megmutatjuk, hogy csővezetékünk több mint 80%-os pontossággal és 23%-os visszahívással állítja elő ezt a célt, ami lényegesen nagyobb lefedettséget biztosít a tuple expresszív tudományos tudásnak, mint más hasonló források. Nyilvánosan hozzáférhetővé tettük a KB-t.', 'lt': 'Mūsų tikslas – sukurti srities tikslinę, aukšto tikslumo žinių bazę (KB), kurioje būtų bendri pareiškimai apie pasaulį (objektas, predikatas, objektas), remiant tolesnį klausimų atsakymo (QA) programą. Nepaisant pastarojo meto pažangos informacijos gavimo (IE) metoduose, mūsų užduotims jau nėra tinkamų išteklių; esami ištekliai yra pernelyg triukšmingi, pernelyg centriniai arba per neišsamūs ir paprastai nebuvo sukurti aiškiai aprėptimi ar tikslais. Siekdami spręsti šiuos klausimus, sukūrėme srities tikslinį, aukšto tikslumo žinių gavimo vamzdyną, sutelkėme atvirą IE, visuomenės išteklių naudojimą ir naują kanoniškos schemos mokymosi algoritmą (vadinamą CASI), kuris sukuria aukšto tikslumo žinias, skirtas tam tikrai sričiai - mūsų atveju pradiniam mokslui. Kad KB išmatuotų tikslinės srities žinių aprėptį (jos "visapusiškumą" mokslo atžvilgiu), mes išmatuojame atšaukimą dėl nepriklausomo srities teksto korpuso ir rodome, kad mūs ų vamzdynas gamina produkciją daugiau kaip 80 proc. tikslumu ir 23 proc. atšaukimą dėl to tikslo – gerokai didesnę dvigubai išreikštų mokslo žinių aprėptį nei kiti panašūs ištekliai. Mes paskelbėme KB viešai prieinamą.', 'it': "Il nostro obiettivo è quello di costruire una knowledge base (KB) mirata al dominio, contenente dichiarazioni generali (soggetto, predicato, oggetto) sul mondo, a supporto di un'applicazione downstream di risposta alle domande (QA). Nonostante i recenti progressi nelle tecniche di estrazione delle informazioni (IE), non esiste già alcuna risorsa adatta per il nostro compito; Le risorse esistenti sono troppo rumorose, troppo centrate sulle entità denominate o troppo incomplete e in genere non sono state costruite con un chiaro scopo o scopo. Per affrontare questi problemi, abbiamo creato una pipeline di estrazione della conoscenza mirata al dominio e ad alta precisione, sfruttando Open IE, crowdsourcing e un nuovo algoritmo di apprendimento canonico degli schemi (chiamato CASI), che produce conoscenze di alta precisione mirate a un particolare dominio - nel nostro caso, la scienza elementare. Per misurare la copertura della KB della conoscenza del dominio target (la sua 'completezza' rispetto alla scienza) misuriamo il richiamo rispetto a un corpus indipendente di testo di dominio, e mostriamo che la nostra pipeline produce output con oltre l'80% di precisione e il 23% di richiamo rispetto a tale obiettivo, una copertura sostanzialmente più elevata di conoscenze scientifiche espressive tuple rispetto ad altre risorse comparabili. Abbiamo reso pubblica la KB.", 'ka': "ჩვენი მიზეზი არის სამყაროს საკუთარი საკუთარი საკუთარი საკუთარი კონფიგურაციის ბაზი (KB), რომელიც ყველაფერი (subjekt, predicate, object) გამოსახულების შესახებ მსოფლიოს შესახებ, საკუთარი კითხვის ინფორმაციის ექსტრექციის (IE) ტექნექციების შესახებ, ჩვენი დავალებისთვის უკვე საჭირო რესურსი არსებობს; არსებობს რესურსები ძალიან ძალიან ძალიან ძალიან ძალიან, ძალიან სახელ ინტერტიკური ცენტრიკური, ან ძალიან უკეთესი, და ტიპოლურად არსებობენ წარმოადგილ ს ჩვენ დავწყებთ ეს, ჩვენ დიომინის მიზეზი, უფრო მნიშვნელოვანი მეცნიერების ექსტრექციის გარეშე, გახსნა IE, crowdsourcing და პრომენტიური კანონიკური სქემის სწავლების ალგორიტიმ (CASI) შექმნა, რომელიც გამოვიყენება უფრო მნიშვნელოვ ჩვენ კომპონენტის ტექსტის შესახებ კომპონენტის კომპონენტის კომპონენტის შესახებ (მისი 'ყველაფერი' მეცნიერებაზე) ჩვენ დავწერეთ, რომ ჩვენი კომპონენტის ტექსტის შესახებ, და ჩვენი კომპონენტის გავაკეთება 80% უფრო მნიშვნელობით და 23% უ ჩვენ KB-ს ადამიანურად გავაკეთეთ.", 'ml': "നമ്മുടെ ലക്ഷ്യം ലോകത്തെ സംബന്ധിച്ചുള്ള പൊതുവായ (കെബി) പ്രയോഗത്തിന്റെ പിന്തുണയ്ക്കുന്ന ഡൊമെയിന്\u200d ലക്ഷ്യത്തില്\u200d ഉയര്\u200dന്ന പരിജ്ഞാനത്തിന്റെ ബേ വിവരങ്ങള്\u200d പുറത്തെടുക്കുന്ന സാങ്കേതികവിദ്യകളില്\u200d അടുത്തുള്ള പുരോഗങ്ങള്\u200d സംഭവിച്ചാലും ഞങ്ങളുടെ ജോലിക്കുള്ള നിലവിലുള്ള വിഭവങ്ങള്\u200d ഒരുപാട് ശബ്ദമുണ്ടായിരിക്കുന്നു, അല്ലെങ്കില്\u200d സാധാരണ വ്യക്തമായ ഒരു സ്കോപ്പോ അല്ലെങ്കില്\u200d നിര്\u200dമ്മി ഇതിനെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d, ഞങ്ങള്\u200d ഒരു ഡോമെന്\u200d ലക്ഷ്യമുള്ള, ഉയര്\u200dന്ന പരിജ്ഞാനത്തിന്റെ പുറത്തേക്ക് നിര്\u200dമ്മിക്കുന്ന പൈപ്പെലിന്\u200d, തുറന്ന IE, ഘടസ്രോഷ്ട്രിങ്ങ് വിവരങ് കെബിയുടെ ലക്ഷ്യത്തിന്\u200dറെ അറിവിന്\u200dറെ (ശാസ്ത്രത്തിന്\u200dറെ സംബന്ധിച്ചുള്ള അടിസ്ഥാനത്തിന്\u200dറെ 'സ്വതന്ത്ര്യം' എന്ന സംബന്ധിച്ച് നമ്മള്\u200d ഓര്\u200dമ്മയുണ്ടാക്കുന്നു. നമ്മുടെ പൈപ്പിളിന്\u200dറെ വിഭവങ്ങള്\u200dക്ക് മുകളി ഞങ്ങള്\u200d കെബി പ്രസിദ്ധമായി ലഭിച്ചിട്ടുണ്ട്.", 'mk': "Нашата цел е да изградиме база на знаење со висока прецизност (КБ), која ќе содржи генерални изјави (субјект, предикат, објект) за светот, во поддршка на апликацијата за одговори на прашања (QA). И покрај неодамнешните напредоци во техниките на извлекување информации (IE), веќе не постои соодветен ресурс за нашата задача; постоечките ресурси се или премногу бучни, премногу централни со името на ентитет, или премногу некомплетни, и обично не се изградени со јасен опсег или цел. За да ги решиме овие, создадовме гасовод за извлекување висока прецизност на знаење со цел на домен, користејќи го отворениот ИЕ, пулсурсинг и нов алгоритм за учење на канонички шеми (наречен КАСИ), кој произведува високо прецизно знаење со цел на одреден домен - во нашиот случај, основна наука. To measure the KB's coverage of the target domain's knowledge (its 'comprehensiveness' with respect to science) we measure recall with respect to an independent corpus of domain text, and show that our pipeline produces output with over 80% precision and 23% recall with respect to that target, a substantially higher coverage of tuple-expressible science knowledge than other comparable resources.  Ја направивме КБ јавно достапна.", 'kk': 'Біздің мақсатымыз - доменге мақсатты, дұрыс-дұрыс білім негізін (КБ) құру, әлемдегі жалпы (тақырыпты, предикатты, нысандар) сөйлемелерді жасауға (QA) қолданбаны қолдану. Жаңа мәліметті тарқату (IE) технологияларына қарай, тапсырмамыз үшін қолданылатын ресурс бар ғой; бұл тапсырма жоқ. Бар ресурстар не тым дыбыс, не аталған нысандар орталық, немесе толық аяқталмаған, әдетте бұл көп мақсат не мақсат бойынша құрылмайды. Бұларға қатынау үшін біз доменге мақсатты, дәл дәл мәліметті шығару каналын құрып, Open IE, crowdsourcing және романдық каноникалық сұлбаны үйрену алгоритм (CASI деп аталатын) жасадық. Бұл бір доменге мақсатты дәл дәл мәліметті жасайды КБ- тың мақсатты домендің білімін өлшеу үшін, біз домендің мәтінінің тәуелсіз корпус мәтініне қарсы есептеп тұрып, оның шығысын 80% ден артық және 23% деген мақсатты қалай есептеуге болады. Бұл мақсатты қалай тапсырмаларды тапсырмаларды көрсету үшін, тапсырм Біз КБ дегенді көпшілікті қол жеткіздік.', 'mt': "L-għan tagħna huwa li nibnu bażi ta’ għarfien ta’ preċiżjoni għolja mmirata lejn id-dominju (KB), li tinkludi dikjarazzjonijiet ġenerali (suġġett, predikat, oġġett) dwar id-dinja, b’appoġġ għal applikazzjoni downstream għat-tweġiba għall-mistoqsijiet (QA). Despite recent advances in information extraction (IE) techniques, no suitable resource for our task already exists;  existing resources are either too noisy, too named-entity centric, or too incomplete, and typically have not been constructed with a clear scope or purpose.  Biex nindirizzaw dawn, ħolqejna pipeline ta' estrazzjoni ta' għarfien immirat lejn id-dominju u ta' preċiżjoni għolja, bl-ingranaġġ ta' IE Miftuħa, crowdsourcing, u algoritmu ġdid ta' tagħlim ta' skema kanonika (imsejjaħ CASI), li jipproduċi għarfien ta' preċiżjoni għolja mmirat lejn dominju partikolari - fil-każ tagħna, ix-xjenza elementari. Biex tkejjel il-kopertura tal-KB tal-għarfien tad-dominju fil-mira (l-'komprensività' tiegħu fir-rigward tax-xjenza) tkejjel it-tfakkir fir-rigward ta' korpus indipendenti ta' test tad-dominju, u nuru li l-pipeline tagħna jipproduċi produzzjoni b'aktar minn 80% preċiżjoni u 23% tfakkir fir-rigward ta' dik il-mira, kopertura sostanzjalment ogħla ta' għarfien xjentifiku espressibbli doppju minn riżorsi komparabbli oħra. We have made the KB publicly available.", 'no': 'Målet vårt er å konstruere eit domenemålet, høg nøyaktig kunnskapsbasen (KB), som inneheld generelle (emne, predikat, objekt) uttrykk om verden, for å støtta ein program for nedtrekksverspørjing (QA). Til tross nyleg avansert i informasjonsekstraksjonsteknologikar finst ingen passande ressurs for oppgåva vår allereie. eksisterande ressursar er anten for støy, for namn på eininga sentriske, eller for ikkje komplette, og vanlegvis har ikkje blitt konstruert med eit klart område eller mål. For å handtera desse, har vi laga ein domenemål, høg nøyaktig kunnskap-ekstraksjonspipeline, leveraging Open IE, crowdsourcing, og ein novel kanonisk læringsalgoritme (CASI), som produserer høg nøyaktig kunnskap som er målt til ein bestemt domene - i vårt tilfelle, elementær vitenskap. For å måle KB-dekkefølgja av kjennen til målet domenet (det «komprehensiveness» med hensyn til vitenskap), måler vi rekkefølgje med respekt til eit uavhengig korpus av domenetekst, og viser at pipelinja vårt produserer utdata med over 80 % presisjon og 23 % rekkefølgje med hensyn til målet, eit stort høgare dekkefølgje av tuple-uttrykkbare vitenskap enn andre sammenlignbare Vi har lagt KB tilgjengeleg offentlig.', 'ro': 'Scopul nostru este de a construi o bază de cunoștințe de înaltă precizie (KB) orientată pe domeniu, conținând declarații generale (subiect, predicat, obiect) despre lume, în sprijinul unei aplicații de răspuns la întrebări (QA) din aval. În ciuda progreselor recente în tehnicile de extragere a informațiilor (IE), nu există deja resurse adecvate pentru sarcina noastră; resursele existente sunt fie prea zgomotoase, prea centrate pe entități denumite, fie prea incomplete și, de obicei, nu au fost construite cu un scop sau un scop clar. Pentru a aborda aceste aspecte, am creat o conductă de extragere a cunoștințelor orientată spre domeniu, de înaltă precizie, utilizând Open IE, crowdsourcing și un nou algoritm canonic de învățare a schemei (numit CASI), care produce cunoștințe de înaltă precizie orientate spre un anumit domeniu - în cazul nostru, știința elementară. Pentru a măsura acoperirea de către KB a cunoștințelor domeniului țintă (caracterul său cuprinzător în ceea ce privește știința) măsurăm rechemarea în raport cu un corpus independent de text de domeniu și arătăm că conducta noastră produce rezultate cu o precizie de peste 80% și 23% rechemare în raport cu acest obiectiv, o acoperire substanțial mai mare a cunoștințelor științifice exprimabile tuple decât alte resurse comparabile. Am pus KB la dispoziţia publicului.', 'ms': "Our goal is to construct a domain-targeted, high precision knowledge base (KB), containing general (subject,predicate,object) statements about the world, in support of a downstream question-answering (QA) application.  Walaupun kemajuan baru-baru ini dalam teknik ekstraksi maklumat (IE), tiada sumber yang sesuai untuk tugas kita sudah wujud; existing resources are either too noisy, too named-entity centric, or too incomplete, and typically have not been constructed with a clear scope or purpose.  Untuk mengatasi ini, kami telah mencipta saluran paip pengekstrakan pengetahuan yang ditetapkan domain, ketepatan tinggi, menggunakan Open IE, crowdsourcing, dan algoritma pembelajaran skema canonical (yang dipanggil CASI), yang menghasilkan pengetahuan ketepatan tinggi yang ditetapkan kepada domain tertentu - dalam kes kami, sains asas. To measure the KB's coverage of the target domain's knowledge (its 'comprehensiveness' with respect to science) we measure recall with respect to an independent corpus of domain text, and show that our pipeline produces output with over 80% precision and 23% recall with respect to that target, a substantially higher coverage of tuple-expressible science knowledge than other comparable resources.  We have made the KB publicly available.", 'pl': 'Naszym celem jest stworzenie ukierunkowanej na domenę, precyzyjnej bazy wiedzy (KB), zawierającej ogólne (temat, predykat, obiekt) oświadczenia o świecie, wspierające dalszą aplikację do odpowiedzi na pytania (QA). Pomimo ostatnich postępów w technikach ekstrakcji informacji (IE) nie istnieje już odpowiedni zasób do naszego zadania; istniejące zasoby są albo zbyt hałaśliwe, zbyt skoncentrowane na nazwach jednostek, albo zbyt niekompletne i zazwyczaj nie zostały skonstruowane z jasnym zakresem lub celem. Aby rozwiązać te problemy, stworzyliśmy ukierunkowany na domenę, wysoką precyzję ekstrakcji wiedzy, wykorzystujący Open IE, crowdsourcing oraz nowy algorytm uczenia się schematów kanonicznych (zwany CASI), który generuje wysoką precyzję wiedzę ukierunkowaną na konkretną dziedzinę, w naszym przypadku, naukę podstawową. Aby zmierzyć pokrycie wiedzy w dziedzinie docelowej przez KB (jej "kompleksowość" w odniesieniu do nauki) mierzymy przypomnienie w odniesieniu do niezależnego korpusu tekstu domeny i pokazujemy, że nasz piątek produkuje wyniki z ponad 80% precyzji i 23% odwołania w odniesieniu do tego celu, znacznie większy pokrycie wiedzy naukowej wyrażalnej kropką niż inne porównywalne zasoby. Udostępniliśmy KB publicznie.', 'so': "Ujeedkeennu waa in la dhiso aasaaska aqoonta ee deegaanka oo aad u sahlan (KB), kaasoo ku jira naadiyo guud (mada,predicate,object) oo ku qoran dunida, in la kaalmeeyo codsiga jawaabta su'aalaha hoose ee QA. In kastoo uu horumarinayo horumarinta soo bixinta macluumaadka (IE) xirfadeedka macluumaadka (IE) marnaba ma jirto rasmi ku haboon shaqadeenna; existing resources are either too noisy, too named-entity centric, or too incomplete, and typically have not been constructed with a clear scope or purpose.  Si aannu ula macaamiloonno, waxan u abuurnay sawir aad u sahlan oo aqoonta saxda ah, baabuurta la soo bixiyo IE, waxa lagu daabaco furan IE, koosaarka dadka, iyo qorshaha warqada ah oo la barto algoritm (CASI), kaas oo soo saara aqoon aad u sahlan oo loogu talo galay domain gaar ah, xaaladeena cilmiga hoose ah. Si a an u qiyaasno qarsoodiga aqoonta deegaanka (aqoonta aqoonta la jeedo cilmiga) waxaynu xasuusnaa xuquuqda dhamaanka qorniinka deegaanka oo xor ah, waxaana muujinnaa in pipelaankeenu soo bixiyo wax ka badan 80 boqolkiiba saxda iyo 23% xusuusta, taas oo ku saabsan waxyaabaha aad u sareeya aqoonta cilmiga la muujiyo oo kale oo u eg. KB waxan si bayaan ah u helnay.", 'sv': "Vårt mål är att bygga en domänriktad kunskapsbas med hög precision (KB), som innehåller allmänna (ämne, predikat, objekt) uttalanden om världen, till stöd för en efterföljande frågeställningsapplikation (QA). Trots de senaste framstegen inom informationsutvinningstekniker finns det redan ingen lämplig resurs för vår uppgift. De befintliga resurserna är antingen för bullriga, för namngivna entitetscentrerade eller för ofullständiga och har vanligtvis inte konstruerats med ett tydligt syfte eller omfattning. För att ta itu med dessa har vi skapat en domänriktad kunskapsutvinning med hög precision, med hjälp av Open IE, crowdsourcing, och en ny kanonisk schemainlärningsalgoritm (kallad CASI), som producerar hög precision kunskap riktad till en viss domän - i vårt fall elementär vetenskap. För att mäta KB:s täckning av måldomänens kunskap (dess 'heltäckande' med avseende på vetenskap) mäter vi återkallelse med avseende på en oberoende korpus av domäntext, och visar att vår pipeline producerar output med över 80% precision och 23% återkallelse med avseende på detta mål, en betydligt högre täckning av tuple-expressible vetenskapskunskap än andra jämförbara resurser. Vi har gjort KB tillgänglig för allmänheten.", 'ta': "எங்கள் இலக்கு ஒரு களம் இலக்கப்பட்ட, உயர் துல்லியமான அறிவிப்பு தளத்தை உருவாக்குவது, உலகின் பொது (பொருள், predicate, object) கூற்றுகளை கொண்டுள்ளது, கீழ்நீர் கேள்வி பத (IE) தகவல் பெறுதலில் சமீபத்தில் முன்னேற்றம் இருந்தாலும், எங்கள் பணிக்கு ஏற்கனவே பொருத்தமான மூலம் இல்லை; இருக்கும் வளங்கள் அல்லது மிகவும் சப்தமாக இருக்கும், மிகவும் பெயரிடப்பட்ட பொருள் மையம், அல்லது மிகவும் முழுமையாக இருக்கும், பொதுவாக இவற்றை முகவரிக்க, நாம் ஒரு டோமைன் இலக்கு, அதிக துல்லியமான அறிவு வெளியீட்டு பைப்பெளியை உருவாக்கினோம், திறந்த IE, மக்கள் sourceing, மற்றும் ஒரு புதிய கானோனிகல் முறைமை கற்றுக்கொள்ளு இலக்கு களத்தின் அறிவின் (அறிவியல் பற்றி அதன் 'சூழ்நிலை' என்பதை அளக்க கேபி என்பதை நாம் நினைவில் எடுக்கிறோம் ஒரு சுதந்திரமான களம் உரையைப் பற்றி, எங்கள் பைப்லைன் வெளியீட்டை 80% துல்லியத்திற்கு மேற்பட்டுள்ளத நாங்கள் KB பொதுவாக கிடைத்தது.", 'sr': "Naš cilj je da izgradimo domenu ciljanu, visoku preciznu bazu znanja (KB), koja sadrži generalne izjave (subjekt, predikat, objekt) o svijetu, u podršci aplikacije za spuštanje odgovora na pitanje (QA). Uprkos nedavnim napredovima tehnika izvlačenja informacija (IE), veæ nema odgovarajućeg resursa za naš zadatak; postojeći resursi su ili previše bučni, previše centrični, ili previše nepotpuni, i obično nisu izgrađeni jasnim oblastima ili svrhem. Da bi se riješili ovim, stvorili smo ciljnu domenu, visoke precizne znanje ekstrakcije cijevi otvorenog IE-a, crowdsourcing i novi algoritam za učenje kanoničke scheme (CASI), koji proizvodi visoke precizne znanje ciljane na određenu domenu - u našem slučaju, elementarnu nauku. Da bi izmjerili pokrivanje KB-a znanja ciljnog domena (njegova 'kompleksnost' u odnosu na znanost), mjerimo se sećanja u pogledu nezavisnog korpusa teksta domena i pokazujemo da naša cijevina proizvodi izlaz sa preko 80% preciznosti i 23% se sećanja u pogledu tog cilja, značajno veća pokrivanja znanja koje izražavaju tuple-izražene nauke nego druge usporedne resurse. Uèinili smo KB javno dostupnim.", 'mn': 'Бидний зорилго бол дэлхийн тухай ерөнхийлөгчийн (сурагчид, сурагчид, объект) илтгэлийг бүтээх, бууруулах асуулт хариултын (QA) программыг дэмжих зорилго юм. Мэдээлэл татах (IE) технологиудын саяхан хөгжлийн давхар боловч бидний ажлын төлөө ямар ч хөгжлийн нөөц аль хэдийн байхгүй. Бүгдээрээ байгаа нөөц нь хэтэрхий чимээгүй, хэтэрхий нэрлэгдсэн төв, эсвэл хэтэрхий бүтэлгүйтлэг, ихэвчлэн тодорхой хэмжээнд эсвэл зорилгоор бий болдоггүй. Эдгээрийг зохицуулахын тулд бид холбооны зорилготой, өндөр тодорхой мэдлэг авах холбооны шугам бүтээсэн бөгөөд Open IE, crowdsourcing, мөн CASI гэдэг шинэ зохиолын алгоритм бүтээсэн. Энэ нь тодорхой хэмжээнд зорилготой тодорхой мэдлэг бүтээсэн. КБ-ын зорилготой холбооны мэдлэг (шинжлэх ухааны хамааралтай "бүрэн" хэмжээний тухай) хэмжээний тухай бид холбооны текстэй хамааралтай холбоотой холбоотой талаар санаж, холбооны шугам нь 80% өндөр тодорхой болон 23% өндөр тэр зорилготой талаар үржүүлэхийг харуулж, бусад харьцуулагдах боломжто Бид КБ-г олон нийтэд ашиглаж чадсан.', 'si': "අපේ අරමුණ තමයි ලෝකය ගැන සාමාන්\u200dය (ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක්) ප්\u200dරශ්නයක් සහයෙන් සහයෙන් ප තොරතුරු නිර්මාණය (IE) තාක්ෂණිකාවට අලුත් ප්\u200dරධානයක් තිබුනොත්, අපේ වැඩේ වෙනුවෙන් විශේෂ සඳහා  ඉතින් ඉතින් ඉතින් ඉතින් ඉතින් ඉතින් ඉතින් අවශ්\u200dයයි, නම් ඉතින් අවශ්\u200dයයි, නැත්නම් අවශ්\u200dයයි, සමහරවිට පැහැදි මේ විදිහට, අපි ඩොමේන් ඉලක්කුවෙන්, හොඳ ප්\u200dරශ්නයක් දැනගන්න පායිප්ලයින්, ලෙවර් කරන්න Open IE, ලොක්සෝර්සින්, සහ ප්\u200dරශ්නයක් කැනෝනික් ස්කීමා ඉගෙන ගන්න අල්ගෝ KB's Coverage of the Targe domain's Knowness (its 'comprehersiness' with reverting to science) we Measured recall with a look at an irrependant Corpus of domain text, and show that our tube line extracted with over 80% Precity and 23% recall with reverting to that Targe, a supantially high Coveage of tuble-expressed science Knowness than an other comparing source. අපි KB එක ප්\u200dරතිකාරයෙන් ලැබුනා.", 'ur': 'ہمارا مقصد یہ ہے کہ دنیا کے بارے میں ایک ڈومین کا موقع بنانا، بلند دقیق علم بنسس (KB) ہے، جس میں دنیا کے بارے میں عمومی (subject,predicate,object) واضح ہے، ایک پانی سیدھی سوال جواب دینے والی (QA) अनुप्रयोग کی مدد کے ساتھ۔ اچھی طریقے کے باوجود اگلوں کے استخراج (IE) تکنیک میں اگلوں کی پیشرفت بھی، ہمارے کام کے لئے پہلے کوئی مناسب سرمایہ نہیں ہے۔ موجود موجود سرمایہ بہت آواز ہیں، بہت نامہ دار انٹیٹی منطقی ہیں، یا بہت ناکامل ہیں، اور معمولاً صریح اندازہ یا هدف سے بنایا نہیں جاتا۔ ان کے بارے میں ہم نے ایک ڈومین کا موقع بنایا ہے، بلند دقیق علم اٹھانے والی پیپ لین، کھولنے والی IE، جمعیت سورسینگ، اور ایک نئی کانونیک سیم یادگاری الگوریٹم (CASI) جو ایک خاص ڈومین کے ذریعہ مطابق بالا دقیق علم پیدا کرتا ہے - ہمارے کئے، اصلی علم میں۔ ہم ڈومین کے متعلق ایک مستقل کرپوس کے ساتھ یاد کرتے ہیں اور دکھاتے ہیں کہ ہماری پیپ لین 80% سے زیادہ دقیق اور 23% سے اس موضوع کے بارے میں اخراج کرتا ہے، ایک بہت زیادہ بلند سائنس علم کا پورا کرتا ہے۔ ہم نے KB کو ظاہر طور پر موجود کر دیا ہے۔', 'uz': "Bizning maqsadimiz dunyodagi umumiy (subject, predicate, object) soʻzlarini qoʻllash uchun domen-target, yuqori qiymati maʼlumot bazasini (KB) yaratish mumkin. @ info Mavjud manbalar juda qiyin, ma'lumot markaziga yoki juda kam notoʻgʻri, va oddiy holat yoki qanday bo'lmaydi. Buni tasavvur qilish uchun, biz juda qiymati, juda qiymati maʼlumot uchrashuv pipelini yaratdik, ochiq IE, jamoatlar ko'plab chiqaruvchi va novel kanonik qolipi algoritni o'rganish (CASI) deb nomlanishi mumkin. Bu juda muhim domen'ga ma'lumot yozib olish mumkin, bizning holatimizda elementary ilmni yaratish mumkin. Ko'pchilik domen haqida qismini o'zgartirish uchun biz ilmiy haqida xotira qilamiz, domen matnning tashkilotlarini xotira olamiz va bizning pipelining qismlarimiz 80% darajasi bilan ishlab chiqaradi va 23% istasangiz, bu maqsadda o'zgarishni boshqa murakkab ma'lumot bilan ko'paytirish mumkin. Biz KB'ni faqat ishlab chiqardik.", 'vi': 'Mục tiêu của chúng ta là xây dựng một căn cứ kiến thức với mục đích miền, cao độ chính xác (KB), chứa các tuyên bố chung (chủ đề, khó khăn, đối tượng) về thế giới, hỗ trợ cho ứng dụng trả lời câu hỏi xuôi dòng (QA). Mặc dù tiến bộ gần đây trong các kỹ thuật đào tạo thông tin (IE) chưa có nguồn tài nguyên thích hợp cho nhiệm vụ của chúng ta. Đã có nguồn tài nguyên hoặc là quá ồn ào, quá gọi là trung tâm, hoặc quá đầy đủ, và thường không được xây dựng với một mục đích rõ ràng. Để giải quyết những việc này, chúng tôi đã tạo ra một đường ống dẫn chuyên môn về lĩnh vực, khả năng khai thác kiến thức cao chính xác, nhân lực Cuộc Mở Iễ, tụ họp, và một thuật to án học âm mưu mới (được gọi là CASI), sản xuất ra những kiến thức chính xác cao được nhắm vào một miền đặc biệt... trong trường hợp của chúng tôi, khoa học tiểu học. Để đo s ự bao quát của trình KB về kiến thức của miền đích (sự "to àn diện" về khoa học) chúng tôi đánh giá triệu tập về một tập thể xác thực độc lập về lĩnh vực văn bản, và cho thấy rằng nguồn cung cấp của chúng tôi sản xuất với độ chính xác cao hơn 80 và 23. triệu hồi về mục tiêu đó, một sự bao quát lớn về kiến thức khoa học thốt đáng hơn so với những nguồn tài nguyên tương tự. Chúng tôi đã công khai cấp phép của KB.', 'bg': 'Нашата цел е да изградим насочена към домейн, високопрецизна база от знания (КБ), съдържаща общи (субект, предикат, обект) изявления за света, в подкрепа на приложение за отговор на въпроси надолу по веригата. Въпреки скорошния напредък в техниките за извличане на информация (ИЕ), вече не съществува подходящ ресурс за нашата задача; съществуващите ресурси са или прекалено шумни, прекалено центрирани върху имената, или прекалено непълни и обикновено не са изградени с ясен обхват или цел. За да се справим с тях, създадохме насочен към домейн, високопрецизен канал за извличане на знания, използвайки Отворено ИЕ, crowdsourcing и нов алгоритъм за учене на канонична схема (наречен КАСИ), който произвежда високопрецизно знание, насочено към определена област - в нашия случай елементарната наука. За да измерим обхвата на КБ на знанията на целевия домейн (неговата "изчерпателност" по отношение на науката), измерваме припомнянето по отношение на независим корпус от домейн текст и показваме, че нашият тръбопровод произвежда продукция с над 80% точност и 23% припомняне по отношение на тази цел, значително по-голямо покритие на двуизразни научни знания в сравнение с други сравними ресурси. Направихме КБ публично достъпна.', 'hr': "Naš cilj je izgraditi domenu ciljanu, visoku preciznu bazu znanja (KB), koja sadrži opće izjave (subjekt, predikat, objekt) o svijetu u podršci zahtjeva za spuštanje odgovora na pitanje (QA). Uprkos nedavnim napredovima tehnika izvlačenja informacija (IE), već nema odgovarajućeg resursa za naš zadatak; postojeći resursi su ili previše bučni, previše imenovani entitetski centrični ili previše nepotpuni, i obično nisu izgrađeni čistim područjima ili svrhem. Da bi se riješili ovim, stvorili smo ciljni, visok precizni znanstveni cijevi ekstrakcije cijevi otvorenog IE-a, crowdsourcing i nov algoritam učenja kanoničke scheme (CASI), koji proizvodi visoke precizne znanje ciljane na određenu domenu - u našem slučaju, osnovnu znanost. Da bismo mjerili pokrivanje KB-a znanja ciljnog domena (njezina 'kompleksnost' u odnosu na znanost), mjerili se sjećanja u pogledu nezavisnog korpusa teksta domena, i pokazali da naša cijevina proizvodi izlaz sa preko 80% preciznosti i 23% sjećanja se u pogledu tog cilja, značajno veća pokrivanja znanja koje izražavaju tuple-izražene znanosti nego druge usporedne resurse. Učinili smo KB javno dostupnim.", 'nl': "Ons doel is om een domein-gerichte, high precision knowledge base (KB) op te bouwen met algemene (subject,predicaat,object) uitspraken over de wereld, ter ondersteuning van een downstream vraag-beantwoording (QA) applicatie. Ondanks recente vooruitgang in de technieken voor informatieextractie (IE) bestaat er nog geen geschikte bron voor onze taak; bestaande resources zijn ofwel te luidruchtig, te gericht op naamsbekendheid, of te onvolledig, en zijn meestal niet met een duidelijk doel of bereik geconstrueerd. Om deze aan te pakken, hebben we een domein-gerichte, hoge precisie kennisextractie pipeline gecreëerd, gebruikmakend van Open IE, crowdsourcing en een nieuw canoniek schema learning algoritme (genaamd CASI), dat hoge precisie kennis produceert gericht op een bepaald domein, in ons geval elementaire wetenschap. Om de dekking van de kennis van het doeldomein door de KB te meten (de 'complexiteit' ten opzichte van wetenschap) meten we recall met betrekking tot een onafhankelijk corpus domeintekst, en laten we zien dat onze pipeline output produceert met meer dan 80% precisie en 23% recall met betrekking tot dat doel, een aanzienlijk hogere dekking van tuple-expressible wetenschappelijke kennis dan andere vergelijkbare bronnen. We hebben de KB openbaar gemaakt.", 'da': "Vores mål er at opbygge en domæne-målrettet, høj præcision vidensbase (KB), der indeholder generelle (emne, prædikat, objekt) erklæringer om verden, til støtte for en downstream spørgsmål-besvarelse (QA) ansøgning. Trods de seneste fremskridt inden for informationsudvindingsteknikker findes der allerede ingen egnede ressourcer til vores opgave. Eksisterende ressourcer er enten for støjende, for navngivne enhedscentrerede eller for ufuldstændige og er typisk ikke konstrueret med et klart omfang eller formål. For at løse disse problemer har vi skabt en domæneorienteret, høj præcision viden udvinding pipeline, der udnytter Open IE, crowdsourcing og en ny kanonisk skema learning algoritme (kaldet CASI), der producerer høj præcision viden målrettet et bestemt domæne - i vores tilfælde elementær videnskab. For at måle KB's dækning af måldomænets viden (dets 'omfattende' i forhold til videnskab) måler vi tilbagekaldelse i forhold til et uafhængigt korpus af domænetekst, og viser, at vores pipeline producerer output med over 80% præcision og 23% tilbagekaldelse i forhold til dette mål, en væsentligt højere dækning af tuple-ekspressibel viden end andre sammenlignelige ressourcer. Vi har gjort KB offentligt tilgængelig.", 'de': 'Unser Ziel ist es, eine domänenorientierte, hochpräzise Wissensdatenbank (KB) zu erstellen, die allgemeine Aussagen (Subjekt, Prädikat, Objekt) über die Welt enthält, um eine nachgeschaltete Fragebeantworterung (QA) zu unterstützen. Trotz der jüngsten Fortschritte in den Techniken der Informationsextraktion (IE) gibt es keine geeignete Ressource für unsere Aufgabe; Vorhandene Ressourcen sind entweder zu laut, zu benannte Entitäten zentriert oder zu unvollständig und wurden in der Regel nicht mit einem klaren Umfang oder Zweck konstruiert. Um diese Probleme anzugehen, haben wir eine domänengerechte, hochpräzise Wissensextraktionspipeline geschaffen, die Open IE, Crowdsourcing und einen neuartigen kanonischen Schema-Lernalgorithmus (CASI) nutzt, der hochpräzises Wissen erzeugt, das auf eine bestimmte Domäne ausgerichtet ist, in unserem Fall die Elementarwissenschaft. Um die Abdeckung des Wissens der Zieldomäne durch die KB zu messen (ihre "Vollständigkeit" in Bezug auf die Wissenschaft), messen wir den Rückruf in Bezug auf einen unabhängigen Korpus von Domänentext und zeigen, dass unsere Pipeline Output mit über 80% Präzision und 23% Rückruf in Bezug auf dieses Ziel produziert, eine wesentlich höhere Abdeckung von Tupel-expressiblem Wissenschaftswissen als andere vergleichbare Ressourcen. Wir haben die KB öffentlich zugänglich gemacht.', 'fa': 'هدف ما این است که یک پایگاه دانش دقیق بالا (KB) را با هدف جهان بسازیم، که در پشتیبانی یک کاربرد پاسخ پرسیدن (QA) ژنرال (موضوع، پیشدکال، شیء) درباره جهان است. با وجود پیشرفتهای اخیر در تکنیک اخراج اطلاعات (IE) هیچ منابع مناسب برای کار ما وجود ندارد. منابع موجود یا خیلی صدا، خیلی متوسط به عنوان موجود یا خیلی غیر کامل هستند، و معمولاً با یک منطقه یا هدف روشن ساخته نشده اند. برای اینها، ما یک لوله\u200cی اخراج دانش با هدف و دقیق بالا به دامنی ایجاد کرده\u200cایم، با توجه به IE باز، انجمن\u200cآوری، و یک الگوریتم\u200cی دانش\u200cآموزی کانونیک (CASI) روزنامه\u200cای ایجاد کرده\u200cایم که علم دقیق بالا به یک دامنی خاص هدف می\u200cکند، در مورد ما، علم اصلی. برای اندازه\u200cگیری پوشش KB از دانش دامنه هدف (با احترام علمی) ما با احترام یک قالب مستقل از متن دامنه را اندازه می\u200cگیریم و نشان می\u200cدهیم که لوله\u200cی ما با بیش از ۸۰ درصد دقیق خروج می\u200cکند و ۲۳ درصد به احترام آن هدف یاد می\u200cگیریم، یک پوشش زیادی بالاتر از دانش علمی که توپ\u200cها با استفاده می\u200cکنند از منابع دیگر مق ما KB را به طور عمومي در دسترسي داديم.', 'ko': "다운스트림 Q&amp;A(QA) 애플리케이션을 지원하기 위해 세계에 대한 일반(주어, 술어, 목적어) 문구를 포함하는 영역별 고정밀 지식 라이브러리(KB)를 구축하는 것이 목표다.최근 정보 추출(IE) 기술에 진전이 있었지만 우리의 임무에 적합한 자원이 없다.기존의 자원은 너무 시끄럽거나 실체를 중심으로 명명되거나 완전하지 않아 명확한 범위나 목적이 없다.이러한 문제점을 해결하기 위해 우리는 분야를 목표로 하는 고정밀 지식 추출 파이프라인을 만들었고 개방식 IE, 패키지 및 새로운 규범 모델 학습 알고리즘(CASI라고 부른다)을 이용하여 이 알고리즘은 특정 분야에 대한 고정밀 지식을 생성할 수 있다. 우리의 예에서 기초 과학이다.지식 라이브러리가 목표 분야의 지식에 대한 범위(과학적인'전면성'을 측정하기 위해 우리는 독립된 분야의 텍스트 자료 라이브러리의 리콜률을 측정했고 우리의 파이프 생성 출력은 80%를 넘는 정확도와 23%를 넘는 리콜률을 가지고 다른 비교 가능한 자원에 비해 원조가 표현한 과학 지식의 범위가 훨씬 높다는 것을 나타냈다.우리는 이미 지식고를 공개했다.", 'id': 'Tujuan kita adalah untuk membangun sebuah dasar pengetahuan dengan tujuan domain, presisi tinggi (KB), yang mengandung pernyataan umum (subjek,predikat,objek) tentang dunia, untuk mendukung aplikasi menjawab pertanyaan (QA) turun. Meskipun kemajuan baru-baru ini dalam teknik ekstraksi informasi (IE), tidak ada sumber daya yang cocok untuk tugas kita sudah ada; sumber daya yang ada adalah terlalu bising, terlalu bernama-entitas sentrik, atau terlalu tidak lengkap, dan biasanya tidak dibangun dengan skop atau tujuan yang jelas. Untuk mengatasi ini, kami telah menciptakan sebuah saluran ekstraksi pengetahuan dengan tujuan domain, ketepatan tinggi ekstraksi pengetahuan, mempengaruhi Open IE, crowdsourcing, dan algoritma pembelajaran skema canonical (disebut CASI), yang menghasilkan pengetahuan ketepatan tinggi yang ditujukan ke domain tertentu - dalam kasus kami, ilmu dasar. Untuk mengukur perlindungan KB dari pengetahuan domain sasaran (keseluruhannya) kita mengukur ingatan mengenai sebuah korpus independen teks domain, dan menunjukkan bahwa pipa kami menghasilkan output dengan lebih dari 80% presisi dan 23% ingatan mengenai sasaran itu, perlindungan yang jauh lebih tinggi dari pengetahuan ilmiah dua kali ekspresi daripada sumber daya yang dapat dibandingkan lainnya. Kami telah membuat KB tersedia publik.', 'tr': "Biziň maksadymyz dünýäde dowam edilen maksady, ýokary derejes bilgili bazyny (KB) in şa etmekdir. IE (IE) teknikelerinden iň soňky öňki gelişmeler ýöne, biziň görevimiz üçin hiç hili ýeterli rekurs ýok; meýdança çeşmeler ýa-da gaty gürrüňli, birnäçe ady bar-da birnäçe gabdaly däl, we adatça bir sowgat ýa maksady bilen inşa edilmedi. Şulara çözmek üçin biz domena maksady bolan, ýokary deňil bilgi tapmaky pipelini bejerdik. Open IE'i, crowdsourcing we kitap sistemasy üçin bir roman kanonik öwrenme algoritmi (CASI diýip atlandyrylýan) we bu ýerde belli bir domena netijesinde hedeflenen ýokary bilgi üretýäris. KB'in hedefimizin bilgisini ölçürmek üçin (bilim hakkında 'büyüklük' bir şekilde) domeniň bağımsız korpusu ile bir şekilde hatırlatıyoruz ve pipeline biziň 80% deňli şekilde output üretildigini ve 23% bu hedefi hakkında hatırlatmak üçin, tuple-a çık bilim bilgilerinin diğer karşılaştırılabilir kaynaklardan daha yüksek çözümüni ölçüyoruz. Biz KB'i publikak bilen mejbur etdik.", 'am': "ጉዳዩ የዓለም አዋጅ (ጉዳዩ፣ predicate፣ objects) ውይይት የውይይት ጥያቄ መልስ (QA) ፕሮግራሙን ለመደገፍ ነው፡፡ ከቅርብ ዘመን የመረጃ ማውጣት (IE) ስልጣናዎች ምንም እንኳ፣ ለስራችን አስቀድሞ የተሻለ ዕቃ የለውም፡፡ የአገኘው ሀብት ቢሆን የድምፅ አካባቢ፣ የተባለው የአካባቢ ማዕከል፣ ወይም ያልተፈጸመ ነው፡፡ እነዚህን ለመግለጽ፣ ለፍጹም የእውቀት ውቀት ውጤት ማውጣት ፖሊስ፣ የክፈት IE፣ የድምፅ ጉዳይ እና አሌጎርቲም ትምህርት መምህርት መኖሪያ የካኖኒካዊ ዘዴም (CASI) በተለየ አካባቢ አዋቂ እውቀት የሚያወጣ ነው፡፡ የኪB አካሄዱን የእውቀት (የ'ፍጥረት') እውቀትን ለመለካት እናስታውሳለን፡፡ በኪB ላይ ግልፅ አግኝተናል፡፡", 'sw': "Lengo letu ni kutengeneza msingi wa maarifa yenye lengo la ndani (KB), yenye kauli ya jumla (mada, predicated, object) kuhusu dunia, ili kuunga mkono kituo cha kujibu swali la chini la mto (QA). Pamoja na maendeleo ya hivi karibuni katika mbinu za utoaji habari (IE), hakuna rasilimali sahihi kwa ajili ya kazi yetu tayari ipo; rasilimali zinazopo ni kelele nyingi sana, yenye jina linaloitwa, au isiyo kamili, na kwa kawaida haijajengwa kwa kiwango cha wazi au kwa lengo. Ili kuwasiliana na hizi, tumetengeneza pipeline inayolengwa na maarifa yenye ufahamu mkubwa wa maendeleo, kutoa huduma za wazi IE, vyanzo vya umma, na mpango wa kitabu cha kujifunza algorithi (unaoitwa CASI), inayoleta maarifa ya sahihi yenye lengo la maeneo maalum - katika kesi yetu, sayansi ya msingi. Kupima taarifa za KB kuhusu maarifa ya ndani ya malengo (yenye 'ufahamu wa kamili' kwa ajili ya sayansi) tunaweza kukumbuka kuhusu makampuni huru ya maandishi ya ndani, na kuonyesha kwamba pipeli yetu inaleta matokeo yenye kiasi cha asilimia 80 na asilimia 23 inakumbuka kwa lengo hilo, habari kubwa zaidi ya maarifa ya sayansi yanayoelezea zaidi ya rasilimali mbalimbali. We have made the KB publicly available.", 'sq': 'Qëllimi ynë është të ndërtojmë një bazë të njohurive me qëllim të lartë, me precizion të lartë (KB), që përmban deklarata të përgjithshme (subjekt,predicate,object) rreth botës, në mbështetje të një aplikimi për përgjigjen e pyetjeve (QA). Megjithë përparimet e fundit në teknikat e nxjerrjes së informacionit (IE), tashmë nuk ekziston burim i përshtatshëm për detyrën tonë; burimet ekzistuese janë ose shumë zhurmëshme, shumë qendrore me emër të njësisë apo shumë jo të plota dhe zakonisht nuk janë ndërtuar me një fushë apo qëllim të qartë. To address these, we have created a domain-targeted, high precision knowledge extraction pipeline, leveraging Open IE, crowdsourcing, and a novel canonical schema learning algorithm (called CASI), that produces high precision knowledge targeted to a particular domain - in our case, elementary science.  Për të matur mbulimin e KB-s ë të njohurive të fushës objektive (kompleksiteti i saj lidhur me shkencën) ne matëm kujtimin lidhur me një korpus të pavarur të tekstit të fushës dhe tregojmë se tubacioni ynë prodhon prodhimin me më tepër se 80% saktësi dhe 23% kujtimin lidhur me atë objektiv, një mbulim thelbësisht më të lartë të njohurive shkencore të shprehura dy herë më shumë se burime të tjera të krahasueshme. E kemi bërë KB në dispozicion publik.', 'af': "Ons doel is om 'n domein-doelde, hoë presisie kennisbasis (Kb), bevat algemene (onderwerp,predikaat,voorwerp) uitdrukkings oor die wêreld te bou, in ondersteun van 'n onderstreem vraag-antwoord (QA) aansoek. Onthou onlangse vorderings in inligting uitpakking (IE) teknike, geen geskikte hulpbron vir ons taak alreeds bestaan nie; en bestaande hulpbronne is of te geluid, te genaamd entiteit sentreel of te onvolledige, en tipes is nie met 'n duidelike omvang of doel gebruik nie. Om hierdie adres te stel, het ons 'n domein-doel gemaak, hoë presisie kennis uittrekking pyplyn, opgemaak Open IE, skakelsourcing, en 'n roman kanoniese skema leer algoritme (CASI genoem), wat produseer hoë presisie kennis wat vir 'n bepaalde domein doel, in ons geval, elementêre wetenskap. Om die Kb se aandekking van die doel domein se kennis (sy 'kompenserende' met respek na wetenskap) te maak, maak ons herhaal met respek na 'n onafhanklike korpus van domein teks, en wys dat ons pyplyn uitvoer met meer 80% presisie en 23% herhaal met respek na daardie doel, 'n groot hoër aandekking van tuple-uitdrukkbare wetenskap kennis a s ander vergelykbare hulpbronne. Ons het die Kb openlik beskikbaar gemaak.", 'az': 'Bizim məqsədimiz dünya haqqında genel (subjekt, predicate, object) ifadələr olan domeinin məqsədilə, yüksək məqsədilə bilgi bazı (KB) in şa etməkdir, a şağı sual cavab verən (QA) proqramının dəstəklənməsidir. Əvvəlki məlumat ekstraksiyası (IE) tehniklərində gələnlər istisna olmaqla, işimizin üçün hazırda heç bir faydası yoxdur; mövcud resurslar ya çox səsləndirlər, çox adı ilə mərkəzdir, ya da çox tamamlanmışlar, və genellikle a çıq səviyyə və məqsədilə inşa edilməmişdir. Bunları çəkmək üçün, biz domeinin məqsədilə, yüksək məqsədilə bilgi çıxartma boru çizgisini yaratdıq, Open IE, crowdsourcing və yeni canonical schema öyrənmə algoritmi (CASI adlı) olaraq yaratdıq. Bu, bizim məqsədimizə, ilk bilim təşkil edir. KB\'nin məqsəd domeinin bilgisini ölçürmək üçün (elmi haqqında "bütünlük" yazılması üçün) biz domeinin mətnlərin bağımsız korpusu ilə yada salıb, pipeline 80% dəqiqliyindən artıq çıxış və 23% bu məqsəd haqqında yada salmaq üçün, bu məqsəd ilə, tuple-expressible bilim bilgisinin daha yüksək örtülüyünü digər müxtəlif kaynaqlardan daha yüksək çəkilir. Biz KB\'i açıq-aşkar mövcud etdik.', 'ca': "El nostre objectiu és construir una base de coneixements d'alta precisió centrada en dominis que contenga declaracions generals sobre el món (subjecte, predicate, object), en suport d'una aplicació de resposta a preguntes en avall. Malgrat els avanços recents en les tècniques d'extracció d'informació, ja no hi ha recursos adequats per a la nostra tasca; els recursos existents són massa sorollosos, són massa centriques, o massa incomplets, i normalment no han estat construïts amb un ample o propòsit clars. Per abordar-los, hem creat un tub d'extracció de coneixements d'alta precisió destinat a dominis, aprofitant l'IE obert, la crowdsourcing i un nou algoritme d'aprenentatge canònic d'esquema (anomenat CASI), que produeix un coneixement d'alta precisió destinat a un domini particular - en el nostre cas, la ciència elementar. Per mesurar la cobertura de KB del coneixement del domini d'objectiu (la seva 'integralitat' en relació a la ciència) mesurem el recordatori en relació a un cos independent de text de domini, i demostram que el nostre pipeline produeix producció amb més d'un 80% de precisió i un 23% de recordatori en relació a aquest objectiu, una cobertura substancialment més alta de coneixement científic doble-expressible que altres recursos comparables. Hem fet públic el KB.", 'bn': 'আমাদের লক্ষ্য হচ্ছে ডোমেইন-লক্ষ্যবস্তু, উচ্চ পরিসূক্ষিত জ্ঞানের বেস (কেবি), যার মধ্যে বিশ্বের জেনারেল (বিষয়বস্তু, বিশ্বের বিষয়বস্তু), একটি প্রশ্ন সাম্প্রতিক তথ্য বিনিময়ের (আইই) প্রযুক্তির উন্নয়ন সত্ত্বেও, আমাদের কাজের জন্য ইতোমধ্যে কোন যথেষ্ট সম্পদ নেই; বিদ্যমান সম্পদ বেশি চিৎকার, নামের সেন্ট্রিক, অথবা অনেক অসম্পূর্ণ, এবং সাধারণত কোন পরিষ্কার স্কোপ বা উদ্দেশ্য দিয়ে তৈরি করা হয়নি। এগুলোর সাথে কথা বলার জন্য আমরা একটি ডোমেইন-লক্ষ্যবস্তু তৈরি করেছি, উচ্চ পরিসূচিত জ্ঞান বিস্তারিত পাইপেলাইন, উন্মুক্ত আইE, জনস্রোর্সিং এবং একটি নবনের ক্যানোনিক্যানোনিক স্কীমা শিক্ষ টার্গেট ডোমেইনের জ্ঞান সম্পর্কে (বিজ্ঞান সম্পর্কে) কেবির কাভারেজ পরিমাপ করার জন্য আমরা ডোমেইন টেক্সটের স্বাধীন কোর্পাস সম্পর্কে স্মরণ করি এবং দেখাচ্ছি যে আমাদের পাইপেলাইনের প্রায় ৮০ শতাংশের বেশী পরিমাণ আমরা কেবি প্রকাশ্যে পাওয়া যাচ্ছি।', 'hy': 'Մեր նպատակն է կառուցել տիեզերական, բարձր ճշգրտության գիտելիքների հիմք, որը պարունակում է աշխարհի մասին ընդհանուր հայտարարություններ, որպեսզի աջակցենք հետագա հարցերին պատասխանող (QA) ծրագիրը: Չնայած ինֆորմացիայի վերջին տեխնիկայի զարգացումներին, արդեն գոյություն չունի համապատասխան ռեսուրսներ մեր խնդրի համար: գոյություն ունեցող ռեսուրսները կամ չափազանց աղմկոտ են, չափազանց կոչված էության կենտրոնական, կամ չափազանց անլրիվ, և սովորաբար դրանք չեն կառուցվել պարզ դիրքով կամ նպատակով: Սրանց լուծելու համար մենք ստեղծեցինք բնագավառի նպատակով, բարձր ճշգրիտ գիտելիքների հանման խողովակաշար, օգտագործելով բաց ինտերնետային ինտերնետային ինտերնետը, ժողովրդավարման գործընթացը և նոր կանոնիկ սխեմային ուսումնասիրության ալգորիթմ (որը կոչվում է ՔԱՍ), որը ստեղծում է բարձր ճշգր Որպեսզի ԿԲ-ը չափի նպատակային բնագավառի գիտելիքների ծավալը (դրա "ամբողջությունը" գիտության նկատմամբ), մենք չափում ենք հիշողությունը բնագավառի տեքստի անկախ կորպոսի նկատմամբ և ցույց ենք տալիս, որ մեր խողովակաշարը արտադրում է արդյունքը 80 տոկոսի ճշգրիտությամբ և 23 տոկոսի հիշողություն այդ նպատակի նկա Մենք ԿԲ-ն հանրային հասանելի դարձրեցինք:', 'et': 'Meie eesmärk on luua domeenile suunatud, kõrge täpsusega teadmistebaas (KB), mis sisaldab üldisi (subject, predicate, object) avaldusi maailma kohta, toetades järgmise etapi küsimustele vastamise rakendust. Vaatamata hiljutistele edusammudele teabe kaevandamise tehnikas ei ole meie ülesandeks veel sobivat ressurssi olemas; olemasolevad ressursid on kas liiga mürakad, liiga nimetatud üksuste kesksed või liiga mittetäielikud ning tavaliselt ei ole neid ehitatud selge ulatuse või eesmärgiga. Nende lahendamiseks oleme loonud domeenile suunatud, ülitäpse teadmiste ekstraheerimise toru, mis võimendab avatud IE, ühissourcingi ja uudse kanoonilise skeemi õppealgoritmi (CASI), mis toodab ülitäpseid teadmisi, mis on suunatud konkreetsele valdkonnale - meie puhul elementaarteadusele. Selleks et mõõta sihtvaldkonna teadmiste (selle "terviklikkuse" teaduse suhtes) ulatust, mõõdame tagasikutsumist sõltumatu domeeniteksti korpuse alusel ning näitame, et meie juhtmestik toodab väljundit üle 80% täpsusega ja 23% tagasikutsumist selle eesmärgi suhtes, mis on oluliselt suurem kahekordsete teadusalaste teadmiste katvus kui muud võrreldavad ressursid. Me tegime KB avalikkusele kättesaadavaks.', 'cs': 'Naším cílem je vytvořit doménově cílenou, vysoce přesnou znalostní bázi (KB), obsahující obecné (subjekt, predikát, objekt) výroky o světě, na podporu následné aplikace pro odpověď na otázky (QA). Navzdory nedávnému pokroku v technikách extrakce informací (IE) již neexistuje žádný vhodný zdroj pro náš úkol; existující zdroje jsou buď příliš hlučné, příliš zaměřené na pojmenování entit nebo příliš neúplné a obvykle nebyly vytvořeny s jasným rozsahem nebo účelem. Pro řešení těchto problémů jsme vytvořili doménově cílenou, vysoce přesnou extrakci znalostí, využívající Open IE, crowdsourcing a nový algoritmus učení kanonických schémat (nazývaný CASI), který produkuje vysoce přesné znalosti zaměřené na konkrétní doménu, v našem případě základní vědy. Pro měření pokrytí znalostí cílové domény KB (její "komplexnosti" vůči vědě) měříme vztah s ohledem na nezávislý korpus textu domény a ukazujeme, že naše pipeline produkuje výstup s přesností více než 80% a 23% odvolání vzhledem k tomuto cíli, podstatně vyšší pokrytí vědeckých znalostí než ostatní srovnatelné zdroje. Zveřejnili jsme KB.', 'fi': 'Tavoitteenamme on rakentaa toimialueella kohdennettu, erittäin tarkka tietopohja (KB), joka sisältää yleisiä (subject, predicate, object) lausuntoja maailmasta jatkojalostuksen kysymysvastaussovelluksen tueksi. Vaikka tiedonhankintatekniikat ovat viime aikoina edistyneet, tehtäväämme ei ole vielä olemassa sopivaa resurssia. olemassa olevat resurssit ovat joko liian meluisia, liian nimetyn kokonaisuuden keskeisiä tai liian epätäydellisiä, eikä niitä yleensä ole rakennettu selkeällä soveltamisalalla tai tarkoituksella. Näiden ongelmien ratkaisemiseksi olemme luoneet verkkotunnukseen kohdennetun, erittäin tarkan tiedon hankintaputken, joka hyödyntää Open IE:tä, joukkoistamista ja uutta kanonista schema learning algoritmia (CASI), joka tuottaa erittäin tarkkaa tietoa, joka on suunnattu tietylle toimialueelle - meidän tapauksessamme alkeistieteelle. Mittataksemme kohdeverkkotunnuksen tietämyksen kattavuutta (sen "kattavuutta" suhteessa tieteeseen) mittaamme takaisinkutsua riippumattoman verkkotunnuksen tekstin perusteella ja osoitamme, että putkistomme tuottaa tuotosta yli 80 prosentin tarkkuudella ja 23 prosentin takaisinkutsulla kyseiseen tavoitteeseen nähden, mikä on huomattavasti suurempi tuplasekspressiivisen tieteellisen tietämyksen kattavuus kuin muut vastaavat resurssit. Olemme tehneet KB:n julkisesti saataville.', 'bs': "Naš cilj je da izgradimo ciljanu domenu, visoku preciznu bazu znanja (KB), koja sadrži generalne izjave (temu, predikat, objekt) o svijetu, u podršci aplikacije za spuštanje odgovora na pitanje (QA). Uprkos nedavnim napredovima tehnika izvlačenja informacija (IE), već nema odgovarajućeg resursa za naš zadatak; postojeći resursi su ili previše bučni, previše centrični, ili previše nepotpuni, i obično nisu konstruirani sa jasnim oblastima ili svrhem. Da bi se riješili ovim, stvorili smo ciljnu domenu, visokog preciznog znanja izvlačenja cijevi otvorenog IE-a, crowdsourcing i novog algoritma za učenje kanoničke scheme (CASI), koji proizvodi visoko precizno znanje ciljano na određenu domenu - u našem slučaju, elementarnu nauku. Da bi izmjerili pokrivanje KB-a znanja ciljnog domena (njezina 'kompleksnost' u odnosu na znanost), mjerimo se sjećanja u pogledu nezavisnog korpusa teksta domena, i pokazujemo da naša cijevina proizvodi izlaz sa preko 80% preciznosti i 23% se sjeća u pogledu tog cilja, značajno veći pokrivač znanja koje izražavaju tuple-izražene znanosti od drugih usporedbenih resursa. Učinili smo KB javno dostupnim.", 'jv': '" tab-style Pernak-pernik saiki dianggo deweke ngomong gak buanget, tho ketahanan pangan-ingkang dipun wae, yo sampeyan kiye or a bisa dol To Address this, we have Created a domain-Tared, height exaction knowning extract wireline, méeraging Open SE, multisource, and a new canonsal scheme Learn Algorithm (karate CASI), that manuputs top exaction knowing goal to a partial domain - in we Case, primary Sayensi. To measurement the kb\'s Coveage of the goal domain\'s knowness (it\'s \'comprcomprcompromises\' with responses to Sayensi) we measurement recurall with responses to an free corus of domain text, and show that we wireline manuses output with about 60% presion and 22% recurall with responses to that goal, a supanti-older Coveage of taple-Expressable Sayensi knowingness than additional parable tools. Awak dhéwé wis nggawe kB publik sing gawe gedhéwé.', 'he': 'המטרה שלנו היא לבנות בסיס ידע מדויק גבוה (KB), שמכיל הצהרות כלליות על העולם, בתמיכה לתוכנית שימוש לענות על שאלות (QA). למרות התקדמות האחרונות בטכניקות חיפוש מידע (IE), אין משאב מתאים למשימה שלנו כבר קיים; המשאבים הנוכחים הם או רעשים מדי, מדי מרכזיים של ישות בשם, או לא מלאים מדי, ובדרך כלל לא נבנו עם ספקופ או מטרה ברורה. כדי להתמודד עם אלה, יצרנו צינור חיפוש מידע מדויק גבוה ומתכוון לתחום מסוים, מנצל IE פתוח, crowdsourcing, ואלגוריתם חדש ללמוד רשת קנוניקה (נקרא CASI), שמפיק ידע מדויק גבוה המתכוון לתחום מסוים - במקרה שלנו, מדע יסודי. כדי למדוד את הכיסוי של KB של הידע של התחום המטרה (היכולת שלו בנוגע למדע) אנו ממדודים את הזיכרון בנוגע לקורפוס עצמאי של טקסט התחום, ולהראות שהצינור שלנו מייצר תוצאה עם יותר מ-80% מדויק ו-23% זיכרון בנוגע למטרה הזאת, כיסוי גבוה ביותר ביותר של ידע מדעי כפול-מובן מאשר משאבים שווים אחרים. הפכנו את KB לפומבי.', 'sk': 'Naš cilj je zgraditi domensko usmerjeno, visoko natančno bazo znanja (KB), ki vsebuje splošne (subject, predicate, object) izjave o svetu v podporo aplikaciji za odgovarjanje na vprašanja (QA). Kljub nedavnemu napredku tehnik pridobivanja informacij za našo nalogo še ni ustreznega vira; obstoječi viri so bodisi preveč hrupni, preveč osredotočeni na imenovane entitete ali preveč nepopolni in običajno niso bili zgrajeni z jasnim obsegom ali namenom. Za reševanje teh rešitev smo ustvarili domensko usmerjen, visoko natančen cevovod za pridobivanje znanja, ki izkorišča odprto IE, množično sourcing in nov algoritem za učenje kanoničnih shem (imenovan CASI), ki proizvaja visoko natančno znanje, usmerjeno na določeno področje - v našem primeru osnovno znanost. Za merjenje pokritosti znanja ciljne domene (njegove "celovitosti" v zvezi z znanostjo) merimo odpoklic glede na neodvisno korpus domenskega besedila in pokažemo, da naš cevovod ustvarja rezultate z več kot 80-odstotno natančnostjo in 23-odstotnim odpoklicem glede na ta cilj, kar je bistveno večje pokritost dvojnega znanstvenega znanja kot drugi primerljivi viri. KB smo javno objavili.', 'ha': "Gayinmu na sami wani masana na ilmi wanda aka yi amfani da shi na guda (KB), mai ƙunsa da statements masu jumla (ƙanshi, wanda ke so, na ƙayyade, abun) a cikin duniya, don ya ƙarfafa wani shirin ya tambayi masu ƙarami (QA). Babu da taƙaita masu ƙaranci cikin mafarin aiki (IU), bãbu wani resource mai daidai wa aikin mu yanzu; Tsarin da ke samar da shi ko da sauri ne mai girma, mai sunan-halin, ko kuma ba a sami shi da wani lokaci mai bayyanãwa ba. To, da za mu yi amfani da waɗannan, Mun halitta wani misalin da aka yi amfani da shi da wanda aka ƙayyade shi na Domen, da ake gaura da shirin bayani na IU, da shirin umarni, da kuma shirin karatun na zaman kanonici da aka sanar algoritm (CASA), wanda ke ƙara wani ilmi na ƙayyade da aka yi amfani da shi zuwa wani Domin da aka ƙayyade - a cikin kaskatanmu, sayanin ƙanshi. Ko iya ƙayyade tsarin KB masu sanin komai da ake amfani da shi game da ilmin wanda aka so, za mu tuna tuna game da wani nau'in littãfin Domin, kuma Mu nuna cewa pipilinmu yana fitar da ma'anar 80% da lissafi 23% za'a tuna game da wannan goan, yana da muhimmin tsarin da za'a sami da ilmi na zane-zane da zane-zane-zane-zane masu sami'in. Mun sami KB da bayyani.", 'bo': "ང་ཚོའི་དམིགས་ཡུལ་ནི་དྲ་རྒྱ་སྟངས་ལ་དམིགས་འབེབས་བྱས་པ་ཞིག་བཟོ་རྩིས་ཡོད་ཅིག་རེད། ང་ཚོའི་ལས་ཀ་གསལ་བཤད་ནུས་ཀྱི་འཕེལ་རིམ་གནས་ཚུལ་གསལ་བཤད་ཀྱི་ཐབས་ལམ་ལ་ཕན་ཚུན་མེད་པ་ཡིན་ནའང་ང་ཚོའི་ དངོས་ཡོད་པའི་རྒྱུ་དངོས་ཚོ་གཉིས་ཀྱིས་མིང་དང་གཅིག་པུའི་སྐོར་ཡིན་ནའང་ཡང་མེད་བསྡུར་པ་ཞིག་ཡིན་ནའང་། སྤྱིར་བཏུབ་ཀྱི་ To address these, we have created a domain-targeted, high precision knowledge extraction pipeline, leveraging Open IE, crowdsourcing, and a novel canonical schema learning algorithm (called CASI), that produces high precision knowledge targeted to a particular domain - in our case, elementary science. To measure the KB's coverage of the target domain's knowledge (its 'comprehensiveness' with respect to science) we measure recall with respect to an independent corpus of domain text, and show that our pipeline produces output with over 80% precision and 23% recall with respect to that target, a substantially higher coverage of tuple-expressible science knowledge than other comparable resources. ང་ཚོས་ཀློག་ཆེན་དེ་མང་ཆོས་སྤྱོད་ཐུབ་པ་ཡིན།"}
{'en': 'Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling', 'ar': 'التشفير المتناثر لتضمينات الكلمات العصبية لوصف التسلسل متعدد اللغات', 'es': 'Codificación dispersa de incrustaciones de palabras neuronales para el etiquetado de secuencias multilingüe', 'pt': 'Codificação esparsa de incorporações de palavras neurais para rotulagem de sequência multilíngue', 'fr': "Codage clairsemé d'intégrations de mots neuronaux pour l'étiquetage de séquences multilingues", 'ja': '多言語シーケンスラベリングのための神経ワード埋め込みのまばらなコーディング', 'zh': '多言序神经词嵌疏编码', 'ru': 'Резкое кодирование вложений нейронных слов для многоязычной маркировки последовательностей', 'hi': 'बहुभाषी अनुक्रम लेबलिंग के लिए तंत्रिका शब्द एम्बेडिंग की विरल कोडिंग', 'ga': 'Códú Gann ar Leabaithe Focal Néaracha le haghaidh Lipéadú Seicheamh Ilteangach', 'ka': 'მრავალენგური სიტყვების კოდირება', 'el': 'Σπάνια κωδικοποίηση των νευρωνικών εννοιών για την πολυγλωσσική επισήμανση ακολουθίας', 'hu': 'Idegi szóbeágyazások ritka kódolása többnyelvű sorozatcímkézéshez', 'it': "Codifica sparsa delle incorporazioni di parole neurali per l'etichettatura di sequenze multilingue", 'kk': 'Көптілік тілдер ретінде белгілеу үшін нейрондық сөздер ендірудің орын кодтамасы', 'lt': 'Mažas nervinių žodžių įrangos kodavimas daugiakalbiams sekos ženklinimui', 'ms': 'Pengekodan Kadar Kebenaran Kata Neural untuk Label Kelajuan Berberbilang Bahasa', 'mk': 'Скоро кодирање на внатрешни неурални зборови за меѓујазичко означување на секвенција', 'ml': 'അധിക ഭാഷക്കുറിച്ചുള്ള ലാബിലിങ്ങിനുള്ള നെയുറല്\u200d വാക്ക് എംബഡിങ്ങുകളുടെ സ്പെയിസ് കോഡിങ്', 'mt': 'Kodifikazzjoni żgħira tal-Embeddings tal-kliem newrali għat-Tikkettar tas-Sekwenza Multilingwi', 'mn': 'Олон хэлний дарааллын лабораторийн мэдрэлийн үг нэмж', 'no': 'Sparse- koding av neirale ord- innbygging for fleirspråk- sekvensetiketting', 'ro': 'Codarea spartă a încorporărilor de cuvinte neurale pentru etichetarea secvențelor multilingve', 'pl': 'Rzędne kodowanie neuronowych osadzeń słowa dla wielojęzycznego etykietowania sekwencji', 'si': 'Multilanguage sequence Labeling', 'ta': 'பல மொழி வரிசைக்கான புதிய வார்த்தை உடைந்துள்ளது', 'so': 'Cod of Neural Word Embeddings for Sequence of Luqad badan Labeling', 'sr': 'Sparse koding neuralnih reèi za etiketiranje višejezičkih sekvencija', 'sv': 'Spar kodning av neurala ordinbäddningar för flerspråkig sekvensmärkning', 'ur': 'Multilingual sequence Labeling', 'uz': 'Name', 'vi': 'Cuộn dây ngang của nhúng chữ thần kinh cho hiệu ứng nhanh', 'bg': 'Спешно кодиране на неврални словесни вграждания за многоезично етикетиране на последователност', 'da': 'Sparsom kodning af neurale ord indlejringer til flersproget sekvensmærkning', 'hr': 'Kodiranje neuralnih riječi za označavanje višejezičkih sekvencija', 'nl': 'Sparse codering van neurale woord embeddings voor meertalige sequentie labeling', 'de': 'Sparse Codierung von neuronalen Wort Embeddings für mehrsprachige Sequenz Labeling', 'id': 'Coding Sparte of Neural Word Embeddings for Multilingual Sequence Labeling', 'ko': '다중 언어 시퀀스 표시에 사용되는 신경 단어에 희소 인코딩', 'fa': 'رمزبندی جفت\u200cهای کلمه\u200cهای عصبی برای برچسب\u200cهای تعدادی زبان\u200cها', 'sw': 'Utaratibu wa Uhispania wa Mazingira ya Neural Word kwa ajili ya Kuzungumza kwa lugha nyingi', 'af': 'Name', 'tr': 'Çoklu dilli Diňe Etiketleme üçin näral Kelimiň Ködlemeleri', 'sq': 'Kodifikimi i shpejtë i përfshirjeve të fjalëve neuronale për etiketën e sekuencës shumëgjuhëse', 'am': 'ቦታ፦', 'hy': 'Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling', 'bn': 'Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling', 'bs': 'Kodiranje neuralnih riječi za etiketiranje višejezičkih sekvencija', 'az': 'Çoxlu dil Sıradan Etilməsi üçün nöral Kelimin İçeri Kodlaması', 'ca': "Codificació ràpida d'incorporacions de paraules neuronals per etiquetar seqüències multilingües", 'cs': 'Řídké kódování vložení neuronových slov pro vícejazyčné sekvenční označování', 'et': 'Neuraalsete sõnade põimimiste vähene kodeerimine mitmekeelse järjestuse märgistamiseks', 'fi': 'Neuraalisten sanaupotusten harva koodaus monikielistä sekvenssimerkintää varten', 'jv': 'echoH e l l o space w o r l d periodHelloworldHello worldkey echo', 'he': 'קוד קטן של קידום מילים נוירוליות לטביעות רצף רבות שפות', 'sk': 'Redko kodiranje nevralnih besednih vdelav za večjezično označevanje zaporedja', 'ha': 'KCharselect unicode block name', 'bo': 'སྐད་རིགས་དབྱེ་སྟངས་ལ་མཚོན་རྟགས་ཀྱི་སྣང་བའི་ཡིག་གེ་མཚོན་རྟགས་ཀྱི་བར་སྟོང་ཞིབ'}
{'en': 'In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages. Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks. The proposed model has favorable generalization properties as it retains over 89.8 % of its average POS tagging accuracy when trained at 1.2 % of the total available training data, i.e. 150 sentences per language.', 'ar': 'في هذا البحث نقترح ونقيم بعناية إطار عمل لوضع العلامات على التسلسل والذي يستخدم فقط ميزات المؤشرات المتفرقة المشتقة من تمثيلات الكلمات الموزعة الكثيفة. يحصل النموذج المقترح على (قريب) من أحدث أداء لكل من علامات جزء من الكلام والتعرف على الكيان المحدد لمجموعة متنوعة من اللغات. يعتمد نموذجنا فقط على بضعة آلاف من الميزات المشتقة من الترميز المتناثرة ، دون تطبيق أي تعديل على تمثيلات الكلمات المستخدمة في المهام المختلفة. يحتوي النموذج المقترح على خصائص تعميم مواتية لأنه يحتفظ بأكثر من 89.8٪ من متوسط دقة علامات نقاط البيع عند تدريبه بنسبة 1.2٪ من إجمالي بيانات التدريب المتاحة ، أي 150 جملة لكل لغة.', 'es': 'En este artículo proponemos y evaluamos cuidadosamente un marco de etiquetado de secuencias que utiliza únicamente características indicadoras dispersas derivadas de representaciones de palabras distribuidas densamente. El modelo propuesto obtiene un rendimiento (casi) de última generación tanto para el etiquetado de parte del habla como para el reconocimiento de entidades nombradas para una variedad de idiomas. Nuestro modelo se basa solo en unos pocos miles de funciones escasas derivadas de la codificación, sin aplicar ninguna modificación de las representaciones de palabras empleadas para las diferentes tareas. El modelo propuesto tiene propiedades de generalización favorables, ya que conserva más del 89,8% de su precisión media de etiquetado POS cuando se entrena con un 1,2% del total de datos de capacitación disponibles, es decir, 150 frases por idioma.', 'fr': "Dans cet article, nous proposons et évaluons soigneusement un cadre d'étiquetage de séquences qui utilise uniquement des caractéristiques indicatrices éparses dérivées de représentations de mots distribuées denses. Le modèle proposé obtient des performances (presque) de pointe pour le marquage de parties de discours et la reconnaissance d'entités nommées pour une variété de langues. Notre modèle ne repose que sur quelques milliers de caractéristiques dérivées du codage, sans appliquer de modification aux représentations de mots utilisées pour les différentes tâches. Le modèle proposé présente des propriétés de généralisation favorables puisqu'il conserve plus de 89,8\xa0% de sa précision moyenne de marquage POS lorsqu'il est formé à 1,2\xa0% du total des données de formation disponibles, soit 150 phrases par langue.", 'pt': 'Neste artigo, propomos e avaliamos cuidadosamente uma estrutura de rotulagem de sequências que utiliza apenas recursos de indicadores esparsos derivados de representações densas de palavras distribuídas. O modelo proposto obtém desempenho (quase) de última geração para marcação de parte da fala e reconhecimento de entidade nomeada para uma variedade de linguagens. Nosso modelo depende apenas de alguns milhares de recursos derivados de codificação esparsos, sem aplicar nenhuma modificação nas representações de palavras empregadas para as diferentes tarefas. O modelo proposto tem propriedades de generalização favoráveis, pois retém mais de 89,8% de sua precisão média de marcação POS quando treinado em 1,2% do total de dados de treinamento disponíveis, ou seja, 150 sentenças por idioma.', 'ja': '本稿では、濃密な分散語表現に由来するまばらな指標特徴のみを利用した配列標識フレームワークを提案し、慎重に評価する。提案されたモデルは、様々な言語の音声タグ付けと名前付きエンティティ認識の両方のための（ほぼ）最先端のパフォーマンスを取得します。私たちのモデルは、異なるタスクに使用される単語表現の変更を適用することなく、数千のまばらなコーディング由来の機能のみに依存しています。提案されたモデルは、利用可能なトレーニングデータ全体の1.2 ％、つまり言語ごとに150文でトレーニングされた場合、平均POSタグ付け精度の89.8 ％以上を保持するため、好ましい一般化特性を有しています。', 'hi': 'इस पेपर में हम एक अनुक्रम लेबलिंग ढांचे का प्रस्ताव और सावधानीपूर्वक मूल्यांकन करते हैं जो पूरी तरह से घने वितरित शब्द प्रतिनिधित्व से व्युत्पन्न विरल संकेतक सुविधाओं का उपयोग करता है। प्रस्तावित मॉडल विभिन्न भाषाओं के लिए भाग-भाषण टैगिंग और नामित इकाई मान्यता दोनों के लिए (निकट) अत्याधुनिक प्रदर्शन प्राप्त करता है। हमारा मॉडल केवल कुछ हजार विरल कोडिंग-व्युत्पन्न सुविधाओं पर निर्भर करता है, विभिन्न कार्यों के लिए नियोजित शब्द प्रतिनिधित्व के किसी भी संशोधन को लागू किए बिना। प्रस्तावित मॉडल में अनुकूल सामान्यीकरण गुण हैं क्योंकि यह कुल उपलब्ध प्रशिक्षण डेटा के 1.2% पर प्रशिक्षित होने पर अपनी औसत पीओएस टैगिंग सटीकता का 89.8% से अधिक बरकरार रखता है, यानी प्रति भाषा 150 वाक्य।', 'zh': '本文细评序框架,框架但用密集分布式单词示疏指示符特征。 所立模形为诸语言词性标名实体(近)最先进者。 吾徒赖疏编码数千,非所以异务单词改也。 所立模具有良泛化,当以总可练数者1.2%(每语150句)教之,存过89.8%之均POS标准确性。', 'ru': 'В этой статье мы предлагаем и тщательно оцениваем структуру маркировки последовательностей, которая использует только разреженные признаки индикатора, полученные из плотных распределенных представлений слов. Предложенная модель получает (близкую) к современной производительность как для частичного тегирования речи, так и для распознавания именованных сущностей для различных языков. Наша модель опирается только на несколько тысяч разреженных функций, полученных на основе кодирования, без применения каких-либо модификаций словопрезентаций, используемых для различных задач. Предлагаемая модель обладает благоприятными обобщающими свойствами, так как она сохраняет более 89,8% своей средней точности POS-метки при обучении на уровне 1,2% от общих доступных обучающих данных, т.е. 150 предложений на язык.', 'ga': 'Sa pháipéar seo molaimid agus déanaimid meastóireacht chúramach ar chreatlach lipéadaithe seicheamh a úsáideann gnéithe táscairí tanaí amháin a thagann as léirithe dlúth dáilte focal. Faigheann an tsamhail mholta feidhmíocht (beagnach) den scoth maidir le clibeáil pháirteach cainte agus aitheantas aonáin ainmnithe do theangacha éagsúla. Ní bhraitheann ár múnla ach ar chúpla míle gnéithe tearca códaithe, gan aon mhodhnú ar na huiríll focal a úsáidtear do na tascanna éagsúla a chur i bhfeidhm. Tá tréithe fabhracha ginearálaithe ag an múnla molta toisc go gcoimeádann sé os cionn 89.8% dá mheánchruinneas clibeála POS nuair a chuirtear oiliúint air ag 1.2% de na sonraí oiliúna iomlána atá ar fáil, i.e. 150 abairt in aghaidh na teanga.', 'ka': 'ამ დოკუნეში ჩვენ მხოლოდ დავიწყებთ და ყველაფერად გავამუშავებთ სიტყვების გამოსახულებაზე, რომელიც მხოლოდ გამოიყენება სიტყვების გამოსახულებაში სიტყვების გამო პროგრამის მოდელის შესაძლებლობა მოიღება (გარეშე) სურათის მუშაობა, რომელიც საუკეთესო საუკეთესო საუკეთესო საუკეთესო სიტყვებისთვის და სახელსა ჩვენი მოდელი მხოლოდ მხოლოდ რამდენიმე ახალგაზრული კოდინდური ფუნქციების შესახებ დაახლოებით, რომელიც განსხვავებული საქმებისთვის გამოყენებული სიტყვების შეცვლა პროგრამის მოდელის შესაძლებელი გენერალიზაციის განსაზღვრებები აქვს, რადგან მას განსაზღვრებული POS-ის განსაზღვრებულობაში 89,8% უფრო მარტივია, როდესაც განსაზღვრებულია 1,2% სამყარო შესაძლებელი', 'hu': 'Ebben a tanulmányban egy olyan szekvencia címkézési keretrendszert javasolunk és gondosan értékelünk, amely kizárólag ritka indikátorjellemzőket használ sűrű elosztott szóreprezentációkból. A javasolt modell (közel) korszerű teljesítményt biztosít mind a beszédrész-címkézés, mind a nevezett entitás felismerése számos nyelven. Modellünk csak néhány ezer ritka kódolásból származó funkcióra támaszkodik, anélkül, hogy a különböző feladatokhoz alkalmazott szóreprezentációk bármilyen módosítását alkalmaznánk. A javasolt modell kedvező általánosítási tulajdonságokkal rendelkezik, mivel megtartja átlagos POS címkézési pontosságának 89,8%-át, amikor az összes rendelkezésre álló képzési adat 1,2%-át, azaz nyelvenként 150 mondatot képez.', 'it': "In questo articolo proponiamo e valutiamo attentamente un framework di etichettatura di sequenza che utilizza esclusivamente caratteristiche di indicatore sparse derivate da rappresentazioni di parole dense distribuite. Il modello proposto ottiene prestazioni (quasi) all'avanguardia sia per il tag part-of-speech che per il riconoscimento delle entità denominate per una varietà di lingue. Il nostro modello si basa solo su poche migliaia di scarse caratteristiche derivate dalla codifica, senza applicare alcuna modifica delle rappresentazioni di parola utilizzate per i diversi compiti. Il modello proposto ha proprietà di generalizzazione favorevoli in quanto mantiene oltre l'89,8% della sua precisione media di tag POS quando viene addestrato all'1,2% dei dati di formazione disponibili totali, vale a dire 150 frasi per lingua.", 'el': 'Στην παρούσα εργασία προτείνουμε και αξιολογούμε προσεκτικά ένα πλαίσιο σήμανσης ακολουθίας που χρησιμοποιεί μόνο αραιά χαρακτηριστικά δεικτών που προέρχονται από πυκνές κατανεμημένες αναπαραστάσεις λέξεων. Το προτεινόμενο μοντέλο επιτυγχάνει (σχεδόν) απόδοση τελευταίας τεχνολογίας τόσο για την επισήμανση μέρους του λόγου όσο και για την αναγνώριση ονομαστικής οντότητας για μια ποικιλία γλωσσών. Το μοντέλο μας βασίζεται μόνο σε μερικές χιλιάδες αραιές κωδικοποιητικές λειτουργίες, χωρίς να εφαρμόζει οποιαδήποτε τροποποίηση των αναπαραστάσεων λέξεων που χρησιμοποιούνται για τις διάφορες εργασίες. Το προτεινόμενο μοντέλο έχει ευνοϊκές ιδιότητες γενικοποίησης καθώς διατηρεί πάνω από 89,8% της μέσης ακρίβειας σήμανσης όταν εκπαιδεύεται σε 1,2% των συνολικών διαθέσιμων δεδομένων κατάρτισης, δηλαδή 150 προτάσεις ανά γλώσσα.', 'kk': 'Бұл қағазда біз реттеу жарлықты жарлықты жарлықтың қолдануын және тәжірибелі түрлі үлестірілген сөздердің көрсетілімдерінен шығарылған сызық индикаторлардың қасиеттерін қолдан Келтірілген үлгі бірнеше тілдер үшін бірнеше тілдерге аталған мәліметті таңдау үшін (жақын) өңдеу әдістерін алды. Біздің үлгіміз тек бірнеше мыңдаған кеңістік кодтамасынан келтірілген мүмкіндіктеріне тәуелді, әртүрлі тапсырмалар үшін қолданылатын сөздерді өзгерту үшін. Келтірілген үлгінің жалпы жалпы қасиеттері бар, себебі оның орташа POS- тегтерінің дұрыстығын 1,2% дегенде жеткізген оқыту деректерінің орташа 89,8% дегенді сақтайды, мысалы, тілде 150 сөз.', 'mk': 'Во овој документ предлагаме и внимателно проценуваме рамка за означување на секвенца која искористува само мали индикаторски карактеристики изведени од густите дистрибуирани репрезентации на зборови. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages.  Нашиот модел се потпира само на неколку илјади ретки карактеристики од кодирање, без апликација на никаква модификација на зборовите претставници кои се користат за различните задачи. Предложениот модел има поволни генерализациски сопствености бидејќи задржува над 89,8 отсто од својата просечна точност на означувањето на POS кога е обучен на 1,2 отсто од вкупните достапни податоци за обука, односно 150 реченици по јазик.', 'lt': 'Šiame dokumente siūlome ir atidžiai vertiname sekos ženklinimo sistemą, kuri naudoja tik nedidelius rodiklius, gautus iš tankių paskirstytų žodžių atspindimų. Siūlomu modeliu įgyjama (beveik) naujausia kalbos dalies žymėjimo ir vardinio subjekto pripažinimo įvairiomis kalbomis veikla. Mūsų modelis grindžiamas tik keliomis tūkstančiomis nedidelėmis koduojančiomis savybėmis, netaikant jokių žodžių, naudojamų įvairioms užduotims, pakeitimų. Siūlomas modelis turi palankias generalizacijos savybes, nes jis i šlaiko daugiau kaip 89,8 % savo vidutinio POS ženklinimo tikslumo, kai jis mokomas 1,2 % visų turimų mokymo duomenų, t. y. 150 sakinių vienai kalbai.', 'ms': 'Dalam kertas ini kami melaporkan dan dengan hati-hati menilai kerangka peletakan urutan yang hanya menggunakan ciri-ciri penunjuk jarang yang berasal dari persembahan perkataan yang diterbangkan padat. Model yang diusulkan mendapatkan prestasi (hampir) state-of-the-art untuk kedua-dua bahagian-of-speech tagging dan pengenalan entiti bernama untuk pelbagai bahasa. Model kami hanya bergantung pada beberapa ribu ciri-ciri terkandung pengekodan, tanpa melaksanakan mana-mana perubahan perwakilan perkataan yang digunakan untuk tugas yang berbeza. Model yang diusulkan mempunyai ciri-ciri generalisasi yang menguntungkan kerana ia menyimpan lebih dari 89.8% dari keseluruhan akurat tag POS apabila dilatih pada 1.2% daripada jumlah data latihan yang tersedia, iaitu 150 kalimat per bahasa.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു സെക്കന്\u200dസ് ലേബിള്\u200d ഫ്രെയിമ്പില്\u200d പരിഗണിക്കുകയും ചെയ്യുന്നു. അത് മാത്രമേ സ്പെസ് ഇന്\u200dഡര്\u200d പ്രതിനിധികള്\u200d ഉപയോഗിക പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്\u200d വ്യത്യസംഭാഷണത്തിന്റെ ഭാഗത്തേക്കുള്ള (അടുത്തു) കലാകൃത പ്രവര്\u200dത്തനത്തിനുള്ള സ്ഥിതിയുടെ  നമ്മുടെ മോഡല്\u200d വ്യത്യസ്ത ജോലികള്\u200dക്ക് വേണ്ടി വാക്കുകളുടെ പ്രതിനിധികള്\u200d മാറ്റമില്ലാതെ കുറച്ചായിരം സ്പാസ് കോഡിങ്ങ്  പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡലിന്റെ പ്രധാനപ്പെട്ട ജനറലേഷന്\u200d ഗുണഗണങ്ങളുടെ വിശേഷതകള്\u200dക്ക് ഏറ്റവും ഇഷ്ടപ്പെട്ടിരിക്കുന്നു', 'mt': 'F’dan id-dokument nipproponu u nwettqu bir-reqqa qafas ta’ tikkettar tas-sekwenza li juża biss karatteristiċi ta’ indikaturi rari derivati minn rappreżentazzjonijiet densi ta’ kliem distribwiti. Il-mudell propost jikseb (qrib) prestazzjoni avvanzata kemm għat-tikkettar tal-parti tad-diskors kif ukoll għar-rikonoxximent tal-entità msejħa għal varjetà ta’ lingwi. Il-mudell tagħna jiddependi biss fuq ftit eluf ta’ karatteristiċi rari derivati mill-kodifikazzjoni, mingħajr ma japplika l-ebda modifika tar-rappreżentazzjonijiet tal-kelma użati għall-kompiti differenti. Il-mudell propost għandu proprjetajiet ta’ ġeneralizzazzjoni favorevoli billi jżomm aktar minn 89.8% tal-preċi żjoni medja tiegħu tat-tikkettar tal-POS meta mħarreġ b’1.2% tad-dejta total i disponibbli tat-taħriġ, jiġifieri 150 sentenza għal kull lingwa.', 'no': 'I denne papiret foreslår vi og forsiktig evaluerer eit rekkjefølgjande rammeverk som berre brukar sparse indikatorefunksjonar ut frå tett distribuert ordrepresentasjon. Det foreslåde modellet får (nær) kunsthandlinga for både deler av talemerking og gjenkjenning av entitet for ulike språk. Modellen vårt er berre avhengig av fleire tusen sparse kodingar-avhengige funksjonar, utan å bruka endringar av ordrepresentasjonane som vert arbeida for dei ulike oppgåva. Dette første modellen har favoritt generelliseringseigenskapar, sidan han inneheld over 89,8 % av gjennomsnittlige POS-merking med nøyaktighet når det trengte på 1,2 % av total e tilgjengelege treningsdata, dvs. 150 setningar per språk.', 'pl': 'W niniejszym artykule proponujemy i dokładnie oceniamy ramy etykietowania sekwencji, które wykorzystują wyłącznie rzadkie cechy wskaźników pochodzące z gęstych rozproszonych reprezentacji słów. Proponowany model uzyskuje (blisko) najnowocześniejszą wydajność zarówno w zakresie tagowania części mowy, jak i rozpoznawania nazwanych jednostek dla różnych języków. Nasz model opiera się tylko na kilku tysiącach rzadkich funkcji pochodzących z kodowania, bez stosowania żadnej modyfikacji reprezentacji słów stosowanych do różnych zadań. Proponowany model ma korzystne właściwości uogólnienia, ponieważ zachowuje ponad 89,8% średniej dokładności tagowania POS, gdy trenuje się w 1,2% całkowitej dostępnej ilości danych treningowych, tj. 150 zdań na język.', 'sr': 'U ovom papiru predlažemo i pažljivo procjenjujemo okvir označavanja sekvence koji koristi samo rezervne indikatore iz guste raspodjeljene riječi. Predloženi model dobija (u blizini) stanje umjetnosti za obeleženje dijelogovora i priznanje imena entiteta za razne jezike. Naš model se oslanja samo na nekoliko hiljada rezervnih karakteristika iz kodiranja, a da ne primjenjujemo nikakve modifikacije reči koje su zaposleni za različite zadatke. Predloženi model ima omiljene generalizacije jer zadrži preko 89,8% prosječnih POS-ova tačnosti kada je obučeno na 1,2% ukupnih dostupnih podataka o obuci, to je 150 rečenica po jeziku.', 'mn': 'Энэ цаасан дээр бид зөвхөн хуваагдсан үг илтгэлээс гарч ирсэн загварын загварын загварыг хэрэглэдэг загварын загварын хэмжээний загварын загварын хэмжээг зөвхөн хэрэглэдэг. Өөрчлөгдсөн загвар нь хэлэлцээний хэсэг болон нэрлэгдсэн бүтээлүүдийг олон хэл дээр танихын тулд урлагийн үйл ажиллагааг авдаг. Бидний загварын загвар нь зөвхөн хэдэн мянга мянган кодировчлалын төлөвлөгөөс хамаарч, өөр ажлын төлөвлөгөөнд ажилладаг үгийг өөрчлөхгүй байдаг. Тайлбарласан загварын хувьд ерөнхийлөгчийн хувьд хангалттай байдаг. Учир нь тэр дундаж POS-ийн тодорхой тодорхойлолтын 89.8% нь сургалтын нийт сургалтын өгөгдлийн 1.2% байх үед, яг л хэл дээр 150 өгөгдлийг хадгалдаг.', 'ro': 'În această lucrare propunem și evaluăm cu atenție un cadru de etichetare a secvențelor care utilizează exclusiv caracteristici de indicatori rare derivate din reprezentări dense distribuite de cuvinte. Modelul propus obține performanțe (aproape) de ultimă generație atât pentru etichetarea parțială de vorbire, cât și pentru recunoașterea entităților denumite pentru o varietate de limbi. Modelul nostru se bazează doar pe câteva mii de caracteristici rare derivate de codare, fără a aplica nicio modificare a reprezentărilor cuvântului folosite pentru diferitele sarcini. Modelul propus are proprietăți favorabile de generalizare, deoarece păstrează peste 89,8% din precizia medie a etichetării POS atunci când este instruit la 1,2% din totalul datelor disponibile de formare, adică 150 de propoziții per limbă.', 'so': 'Qoraalkan waxaynu soo jeedaynaa oo si taxadar ah u qiimeynaynaa firaaqada lagu qorayo, kaas oo kaliya u isticmaalaya alaabta dhaqaalaha ah oo ka soo baxay qayb-qaybsan hadalka. Tusaale la soo jeeday wuxuu helaa xaalad farshaxan oo ku dhow (dhow) oo lagu sameeyo qeyb ka mid ah calaamadda hadalka iyo aqoonsashada entity ee luqado kala duduwan. Tusaalkayagu wuxuu ku xiran yahay dhawr kun oo caqli ah oo codsiga, mana codsan kartid beddelinta hadalka noocyada shaqada kala duduwan. Tusaale la soo jeeday waxay leedahay hanti la soo saaray oo aad u jecel yahay, sababtoo ah waxay ku jirtaa wax ka badan 89.8% oo ku qoran saxda tagiga POS marka lagu tababaray 1.2% macluumaadka waxbarashada oo dhan, waa 150 imtixaan af kasta.', 'sv': 'I denna uppsats föreslår vi och utvärderar noggrant en sekvensmärkningsram som enbart använder glesa indikatorfunktioner som härrör från täta distribuerade ordrepresentationer. Den föreslagna modellen erhåller (nära) toppmodern prestanda för både delmärkning och namngiven entitetsigenkänning för en mängd olika språk. Vår modell bygger endast på några tusen glesa kodhärledda funktioner, utan att tillämpa någon ändring av ordrepresentationer som används för de olika uppgifterna. Den föreslagna modellen har gynnsamma generaliseringsegenskaper eftersom den behåller över 89,8% av sin genomsnittliga POS tagging noggrannhet när den tränas på 1,2% av den totala tillgängliga träningsdata, dvs 150 meningar per språk.', 'si': 'මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා සහ පරික්ෂිත විතරයි වචන ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරනවා කියලා පරික්ෂණ ලේබිල් වර්ගයක ප්\u200dරයෝජනය කරුණාකරණය සඳහා විවිධ භාෂාවක් සඳහා සංවිධානය සඳහා ප්\u200dරයෝජනය කරුණාකරණය සඳහා ප්\u200dරයෝජනයක්  අපේ මොඩල් විතරයි වෙනස් වැඩක් වෙනුවෙන් ප්\u200dරතිචාර කරපු වචන වෙනස් වෙනුවෙන් විතරයි. ප්\u200dරයෝජනය කරපු මොඩල් එකට ප්\u200dරතිකෘත සාමාන්\u200dය විශේෂතාවක් තියෙනවා, ඒ වගේම එයාගේ සාමාන්\u200dය POS ටැග් විශේෂතාවක් 89.8% වඩා තියෙනවා කියලා ප', 'ta': 'இந்த காகிதத்தில் நாம் ஒரு வரிசையின் குறிப்பிட்ட சட்டத்தை சரியாக பரிந்துரைக்க வேண்டும். அது மட்டுமே சிறிய குறிக்குறியீட்டு  பரிந்துரைக்கப்பட்ட மாதிரி பல மொழிகளுக்கான பொருள் குறிப்பிடும் பெயரிடப்பட்ட பொருள் குறிப்பிடும் பொருள் குறிப்பிடு எங்கள் மாதிரி வெவ்வேறு பணிகளுக்கு பயன்படுத்தப்பட்ட வார்த்தை பிரதிநிதிகளை பயன்படுத்தாமல் ஒரு சில ஆயிரம் ஸ்பாஸ் குறியீடு குறி முந்திருக்கப்பட்ட மாதிரியில் விருப்பமான உருவாக்குதல் பண்புகள் இருக்கிறது ஏனெனில் அது 89. 8% அதில் சராசரியான POS ஒட்டு சரியானதை வைத்துக் கொள்கிறது, ம', 'ur': 'ہم اس کاغذ میں ایک سفارشی لابلینگ فرمیک کا اندازہ کریں اور دہرے طور پر ارزش کریں جو صرف گہرے تقسیم ہوئے لفظ کی تعلیمات سے اپنا سفارش کرتا ہے۔ پیغمبر کی مدل مختلف زبانوں کے لئے مختلف طریقے کے لئے آهنگ کی عملکرد حاصل کرتا ہے۔ ہمارا مدل صرف چند ہزار اسپریز کوڈینگ کے معاملہ پر اعتماد کرتا ہے، بغیر اس بات کے بدلنے کے جو مختلف کاموں کے لئے استعمال کیا جاتا ہے۔ پیشنهاد کی موڈل کے پاس مہربانی جرائل کی خصوصی ہے کیونکہ اس نے اس کے متوسط پوس کے اندر 89.8% سے زیادہ قائم رکھا ہے جب 1.2% پر آموزش دی جاتی ہے، یعنی ایک زبان پر 150 جماعت.', 'uz': "Bu hujjatda biz murojaat qilamiz va yaxshi qiymatimiz va cheksiz cheksiz cheksiz imkoniyatlaridan foydalanadi. Name Bizning modelimiz faqat bir necha kichkina kodlash imkoniyatlariga ishlatadi, boshqa vazifalar uchun ishlatadigan so'zlarni o'zgartirishni qoʻllamaydi. Name", 'vi': 'Trong tờ giấy này, chúng tôi đề xuất và đánh giá cẩn thận một hệ thống mô phỏng các chuỗi, mà chỉ sử dụng các tính năng chỉ thị thoáng đãng từ các biểu tượng chữ phân phát dày đặc. Người mẫu đã đề nghị đạt được (gần) trình độ nghệ thuật cao cả cho việc đánh dấu bằng giọng nói và nhận diện thực thể tên cho nhiều ngôn ngữ khác nhau. Mẫu của chúng ta chỉ dựa trên vài ngàn tính năng do lập trình ít ỏi, mà không thay đổi các từ biểu hiện được sử dụng cho các nhiệm vụ khác nhau. Mô hình đã đề nghị có đặc tính tổng hợp thuận lợi vì nó vẫn giữ được độ chính xác vị trí bưu kiện trung bình khi được đào tạo tại 1', 'bg': 'В тази статия предлагаме и внимателно оценяваме рамка за етикетиране на последователност, която използва единствено редки индикаторни характеристики, получени от плътно разпределени думи представяния. Предложеният модел получава (почти) най-съвременно представяне както за маркиране на част от речта, така и за разпознаване на наименовани обекти за различни езици. Нашият модел разчита само на няколко хиляди оскъдни функции, получени от кодиране, без да прилага никаква модификация на думичните представи, използвани за различните задачи. Предложеният модел има благоприятни обобщаващи свойства, тъй като запазва над 89,8% от средната си точност на маркиране при обучение при 1,2% от всички налични данни за обучение, т.е. 150 изречения на език.', 'nl': 'In dit artikel stellen we een sequence labeling framework voor en evalueren zorgvuldig dat uitsluitend gebruik maakt van schaarse indicatorkenmerken afgeleid van dichte gedistribueerde woordrepresentaties. Het voorgestelde model verkrijgt (bijna) state-of-the-art prestaties voor zowel part-of-speech tagging als benaming entity herkenning voor een verscheidenheid aan talen. Ons model steunt slechts op een paar duizend schaarse coderingsafgeleide kenmerken, zonder enige wijziging van de woordrepresentaties die worden gebruikt voor de verschillende taken toe te passen. Het voorgestelde model heeft gunstige generalisatie eigenschappen omdat het meer dan 89,8% van zijn gemiddelde POS tagging nauwkeurigheid behoudt wanneer getraind op 1,2% van de totale beschikbare trainingsgegevens, d.w.z. 150 zinnen per taal.', 'hr': 'U ovom papiru predlažemo i pažljivo procjenjujemo okvir označavanja sekvence koji koristi samo rezervne indikatore iz guste raspodjeljene riječi. Predloženi model dobija (blizu) postupak umjetnosti za označavanje djelomičnog govora i priznanje imena entiteta za razne jezike. Naš model se oslanja samo na nekoliko tisuća rezervnih karakteristika iz kodiranja, bez primjene nikakvih izmjena riječi zastupanja zaposlenih za različite zadatke. Predloženi model ima dobre generalizacije jer zadrži preko 89,8% prosječnih POS-a označavanja preciznosti kada je obučeno na 1,2% ukupnih dostupnih podataka o obuci, tj. 150 rečenica po jeziku.', 'da': 'I denne artikel foreslår og omhyggeligt evaluerer vi en sekvensmærkning ramme, der udelukkende bruger sparsomme indikatorfunktioner afledt af tætte distribuerede ord repræsentationer. Den foreslåede model opnår (nær) state-of-the-art performance for både dele-of-speech tagging og navngivet entity anerkendelse for en række sprog. Vores model er kun afhængig af nogle få tusinde sparsomme koder-afledte funktioner, uden at anvende nogen ændring af ordet repræsentationer anvendt til de forskellige opgaver. Den foreslåede model har gunstige generaliseringsegenskaber, da den bevarer over 89,8% af sin gennemsnitlige POS tagging nøjagtighed, når den trænes til 1,2% af de samlede tilgængelige træningsdata, dvs. 150 sætninger pr. sprog.', 'id': 'Dalam kertas ini kami mengusulkan dan dengan hati-hati mengevaluasikan rangkaian label urutan yang hanya menggunakan ciri-ciri indikator langka yang berasal dari persembahan kata yang didistribusikan padat. Model yang diusulkan mendapatkan prestasi (dekat) state-of-the-art untuk kedua tagging bagian dari-pidato dan pengakuan entitas bernama untuk berbagai bahasa. Model kami hanya bergantung pada beberapa ribu ciri-ciri yang berasal dari kode, tanpa menerapkan modifikasi apapun dari kata representation yang digunakan untuk tugas yang berbeda. Model yang diusulkan memiliki ciri-ciri generalisasi favorit karena memelihara lebih dari 89,8% dari akurasi POS tagging rata-rata ketika dilatih pada 1,2% dari total data pelatihan tersedia, yaitu 150 kalimat per bahasa.', 'ko': '본고에서 우리는 하나의 서열 표기 구조를 제기하고 자세하게 평가했다. 이 구조는 밀집 분포 단어 표시 중의 희소 지시 부호 특징만 이용한다.이 모델은 각종 언어의 어성 표시와 명명 실체 식별 방면에서 가장 선진적인 성능을 얻었다.우리의 모델은 수천 개의 희소 인코딩으로 파생된 특징에만 의존하고 서로 다른 임무에 사용되는 단어의 표시를 수정하지 않았다.이 모델은 양호한 범위화 특성을 가지고 있으며 1.2%의 사용 가능한 훈련 데이터(즉 언어당 150구)로 훈련을 진행할 때 단어성 표시의 평균 정확도는 89.8% 이상을 유지한다.', 'de': 'In diesem Beitrag schlagen wir ein Sequenzmarkierungsframework vor und evaluieren sorgfältig, das nur spärliche Indikatormerkmale verwendet, die von dichten verteilten Wortrepräsentationen abgeleitet werden. Das vorgeschlagene Modell erhält (fast) State-of-the-Art Performance sowohl für das Tagging als auch für die Erkennung benannter Entitäten für eine Vielzahl von Sprachen. Unser Modell stützt sich nur auf wenige tausend spärliche, von Codierungen abgeleitete Merkmale, ohne dass die Wortdarstellungen für die verschiedenen Aufgaben modifiziert werden. Das vorgeschlagene Modell hat günstige Generalisierungseigenschaften, da es mehr als 89,8% seiner durchschnittlichen POS-Tagging-Genauigkeit beibehält, wenn es mit 1,2% der gesamten verfügbaren Trainingsdaten trainiert wird, d.h. 150 Sätze pro Sprache.', 'fa': 'در این کاغذ ما پیشنهاد می\u200cکنیم و با دقت یک چهارچوب برچسب برچسب برچسب برچسب را ارزیابی می\u200cکنیم که تنها ویژه\u200cهای نشان\u200cدهنده\u200cی ذره\u200cای را استفاده می\u200cکند که از نمایش\u200cدهندگان کلمه\u200cهای متفاوت این مدل پیشنهاد برای نشان کردن قسمتی از سخنرانی و شناسایی عنوان برای زبانهای مختلف (نزدیک) فعالیت هنری می\u200cیابد. مدل ما تنها بر چند هزار ویژه\u200cهای کودینگ\u200cبندی\u200cهای خاص بستگی دارد، بدون تغییر\u200cبندی از کلمه\u200cای که برای کارهای مختلف استخدام می\u200cکنند. این مدل پیشنهاد ویژه\u200cهای ژنرالی مورد علاقه\u200cای دارد، زیرا بیش از 89.8% از معمولی POS که دقیقات نقاشی را در حالی که ۱.2% از اطلاعات آموزش کامل موجود می\u200cباشد، یعنی ۱۵۰ جمله به زبان نگه می\u200cدارد.', 'af': "In hierdie papier voorstel ons en versigtig evalueer 'n volgorde etiket raamwerk wat slegs gebruik spansewyser funksies wat van dens verdeelde woord voorstellings afgelei word. Die voorgestelde model kry (naby) state-of-the-art performance vir beide deel-van-spreek merking en genoem entiteiterkenning vir 'n verskillende tale. Ons model het slegs op 'n paar duisend sparse kodering-afgeleide funksies afgelaat, sonder om enige veranderinge van die woord verteenwoordes te aanwend wat vir die verskillende taak gebruik word. Die voorgestelde model het gunstige generalisering eienskappe, omdat dit oor 89.8% van sy gemiddelde POS-etiket presies hou wanneer op 1.2% van die totaal beskikbaar onderwerking data opgelei is, bv. 150 setnings per taal.", 'sw': 'In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations.  Mfano huu unapendekezwa unapata (karibu) hali ya sanaa kwa ajili ya upande wa lugha na utambulisho wa entity kwa lugha mbalimbali. Mfano wetu unategemea tu vipengele elfu elfu kadhaa vya kupiga kura, bila kutumia mabadiliko yoyote ya maneno yaliyotumiwa kwa kazi tofauti. Mfano huu unapendekezwa una vifaa vizuri vya uzalishaji kwa sababu inabaki zaidi ya asilimia 89.8 ya wastani wa alama za ujumbe wa POS wakati wa mafunzo ya asilimia 1.2 ya data jumla za mafunzo, yaani hukumu 150 kwa lugha.', 'sq': 'Në këtë letër ne propozojmë dhe vlerësojmë me kujdes një kuadër të etiketave të sekuencës që përdorë vetëm karakteristikat e vogla të treguesve të nxjerra nga përfaqësimet e dendura të shpërndara të fjalëve. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages.  Modeli ynë mbështetet vetëm në disa mijëra karakteristika të vogla të përdorura nga kodimi, pa aplikuar ndonjë modifikim të fjalës përfaqësime të përdorura për detyrat e ndryshme. Modeli i propozuar ka prona të gjeneralizimit të favorshme pasi mban mbi 89.8% të saktësisë mesatare të etiketave të tij POS kur është trajnuar në 1.2% të të dhënave të përgjithshme të trajnimit në dispozicion, pra 150 fjalë për gjuhë.', 'tr': 'Bu kağıtda sık dağıtılmış kelime ifadelerinden gelen sparsi işaretçilerini kullanan ve dikkatli bir şekilde tahmin ediyoruz. Mazmunlar nusgasy bolan çykyş taýýarlamanyň we dilleriň birnäçe görnüşleri üçin sanat taýýarlamanyň durumyny gazanýar. Biziň modelimiz diňe birnäçe müň sany gaýd edip, beýleki görerler üçin işledilen sözlerin üýtgetmegine ynamly. Mazmunlar nusgasynda jeneral hasaplaryň gowy görkezilişi bar sebäbi olaryň orta sany POS-i ň 89,8 % üstünde degişligi bar we olaryň 1.2% öňünde bilim maglumatynyň, diýip dilde 150 sözler bar.', 'hy': 'Այս թղթի մեջ մենք առաջարկում ենք և ուշադիր գնահատում մի հաջորդականության պիտակագրման շրջանակ, որը միայն օգտագործում է հազվադեպ ցուցանիշներ, որոնք ստացվում են խտուն բառերի բառերի ներկայացումներից: Առաջարկված մոդելը ստանում է (մոտ) ամենահետաքրքիր արտադրությունը, ինչպես խոսքի մասի նշանների, ինչպես նաև անվանների ճանաչելու համար տարբեր լեզուների համար: Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks.  Առաջարկված մոդելը ունի ընդհանուր ընդհանուր հատկություններ, քանի որ այն պահպանում է իր միջին POS-ի նշանների ճշմարտությունը 89.8 տոկոսին, երբ ուսուցվում է 1.2 տոկոսին հասանելի ուսուցման տվյալների, այսինքն 150 նախադասություն լեզվի համար:', 'am': 'In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations.  በተዘጋጀው ሞዴል (ቅርብ) የቋንቋ-ቋንቋ ማሰናከል እና በተለየ ቋንቋዎች አካባቢ ማውቀትን ለማግኘት (ቅርብ) የ-አርእስት ድረ ገጽ አግኝቷል፡፡ ሞዴሌያችን ለልዩ ሥርዓት የተደረገውን ቃላት መልዕክት ለማንኛውም መልዕክት ሳይጠቀም በጥቂት ሺህ ሳንቆር የሚቆጠሩ ባሕላቶች ብቻ ነው፡፡ በተዘጋጀው ሞዴል የጠቅላላ ምርጫዎች አለበት፤ በቋንቋው ውስጥ 1.2 በመቶው የተገኘው ማስተማሪ ዳታዎችን በመጠቀም 89.8 በመቶው የPOS tagging እርግጠኛ ነው፡፡', 'bn': 'এই কাগজটিতে আমরা প্রস্তাব করি এবং সাবধানে একটি সেকেন্ড লেবেলিং ফ্রেমের মূল্যায়ন করি যা শুধুমাত্র স্প্যাস ইন্ডিজেক্টরের বৈশিষ্ট প্রস্তাবিত মডেল বিভিন্ন ভাষার বিভিন্ন ভাষার জন্য বিভিন্ন ভাষার জন্য (কাছাকাছি) শিল্প প প্রদর্শনের অবস্থা (কাছাকাছি) প্ Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks.  প্রস্তাবিত মডেলের সুন্দর জেনারেলেশনের বৈশিষ্ট্য আছে যেহেতু সেখানে ৮৯.', 'az': 'Bu kağızda yalnız sıxıntılı dağıtılmış sözlərin göstərilmələrindən alınan uzaq indikator xüsusiyyətlərini istifadə edən seçmə etiketləmə framework ünü təklif edirik. Önülləşdirilmiş modellər müxtəlif dillər üçün müxtəlif tərzlərin etiketi və adlı tərzlərin tanıması üçün sanat performansını alır. Bizim modellərimiz yalnız bir neçə müxtəlif işlər üçün istifadə edilən sözlərin dəyişikliklərinə təvəkkül edir. Önülləşdirilən modellərin ortalama POS etiketindən 89,8%-dən artıq istifadə edilən təhsil verilən təhsil məlumatının %1,2%-ində təhsil edildiyi zaman istifadə edilən təhsil məlumatının %1,2%-ində saxlanıldığı üçün istifadə edir.', 'ca': "En aquest paper proposem i evaluem cuidadosament un marc d'etiquetage de seqüències que només utilitza característiques escassos d'indicadors derivats de denses representacions de paraules distribuïdes. El model proposat obté un rendiment (gairebé) d'última edat tant per etiquetar part-of-speech com per reconèixer entitats anomenades per una varietat de llengües. El nostre model només es basa en unes poques mil característiques escases derivades de codificació, sense aplicar cap modificació de les paraules representacions empregades per les diferents tasques. El model proposat té propietats favorables de generalització, perquè conserva més del 89,8% de la seva mitjana de precisió d'etiquetar POS quan està entrenat al 1,2% de les dades d'entrenament disponibles, és a dir, 150 frases per llenguatge.", 'cs': 'V tomto článku navrhujeme a pečlivě vyhodnocujeme rámec pro značení sekvencí, který využívá výhradně řídkých ukazatelů odvozených z hustých distribuovaných slovních reprezentací. Navržený model získává (téměř) nejmodernější výkon jak pro značení části řeči, tak pro rozpoznávání pojmenovaných entit pro různé jazyky. Náš model se opírá pouze o několik tisíc řídkých kódovaných funkcí, aniž by aplikoval jakoukoliv modifikaci slovních reprezentací používaných pro různé úkoly. Navržený model má příznivé zobecnění vlastnosti, protože si zachovává přes 89,8% průměrné přesnosti POS tagování při tréninku na 1,2% celkových dostupných tréninkových dat, tj. 150 vět na jazyk.', 'bs': 'U ovom papiru predlažemo i pažljivo procjenjujemo okvir označavanja sekvence koji koristi samo rezervne indikatore iz guste raspodjeljene riječi. Predloženi model dobija (blizu) postupak umjetnosti i označavanja dijelogovora i priznanja imena entiteta za razne jezike. Naš model se oslanja samo na nekoliko tisuća rezervnih karakteristika iz kodiranja, bez primjene nikakve modifikacije riječi koje su zaposleni za različite zadatke. Predloženi model ima omiljene generalizacije jer zadrži preko 89,8% prosječnog POS-a označavanja preciznosti kada je obučeno na 1,2% ukupnih dostupnih podataka o obuci, tj. 150 rečenica po jeziku.', 'fi': 'Tﾃ､ssﾃ､ tyﾃｶssﾃ､ ehdotamme ja arvioimme huolellisesti sekvenssimerkintﾃ､kehystﾃ､, joka hyﾃｶdyntﾃ､ﾃ､ vain harvoja indikaattoreita, jotka on johdettu tiheistﾃ､ hajautetuista sanaesityksistﾃ､. Ehdotettu malli tuottaa (lﾃ､hes) viimeisintﾃ､ tekniikkaa edustavaa esitystﾃ､ sekﾃ､ puheen osamerkintﾃ､ﾃ､n ettﾃ､ nimettyjen entiteettien tunnistamiseen useilla kielillﾃ､. Mallimme perustuu vain muutamaan tuhanteen harvaan koodausjohdettuun ominaisuuteen soveltamatta mitﾃ､ﾃ､n muutoksia eri tehtﾃ､vissﾃ､ kﾃ､ytettyihin sanaesityksiin. Ehdotetulla mallilla on suotuisat yleistﾃ､misominaisuudet, sillﾃ､ se sﾃ､ilyttﾃ､ﾃ､ yli 89,8% keskimﾃ､ﾃ､rﾃ､isestﾃ､ POS-merkintﾃ､tarkkuudestaan, kun se on koulutettu 1,2%:lla kﾃ､ytettﾃ､vissﾃ､ olevasta koulutustiedosta eli 150 lausetta kielellﾃ､.', 'et': 'Käesolevas töös pakume välja ja hindame hoolikalt järjestuse märgistamise raamistikku, mis kasutab ainult hõredaid indikaatorifunktsioone, mis tulenevad tihedatest hajutatud sõnade esitustest. Kavandatud mudel võimaldab (peaaegu) kaasaegset esitust nii kõneosa sildistamiseks kui ka nimetatud olemi tuvastamiseks mitmesuguste keelte puhul. Meie mudel tugineb vaid mõnele tuhandele hõredale kodeerimisest tuletatud funktsioonile, rakendamata erinevate ülesannete jaoks kasutatavaid sõnaesitusi. Kavandatud mudelil on soodsad üldistamisomadused, kuna see säilitab üle 89,8% oma keskmisest POS sildistamise täpsusest, kui seda treenitakse 1,2% kogu olemasolevast treeningu andmest, st 150 lauset keele kohta.', 'jv': 'In this paper we proposal and Carely assess a seduling order label frame that simply use the pitch parameters that are generated from the Dense Distributed word representation. Peringatus bener Model sing wis dipateng liyane ing mungkin pating kelengatan pangan Model sing supoyo ndheke perusahaan kelangan kelangan podho Generalizasi dipunangé awak dhéwé, tek yata-babagan barang mangan karo', 'ha': 'Daga wannan takardan, muna buƙata, kuma muna ƙidãya wani firam mai lissafa na sequence, wanda ke amfani da shi kawai masu amfani da fassarar indikatori masu cire daga masu motsari da aka raba maganar damu. @ info: whatsthis Misalinmu yana dõgara kawai kan wasu mistakardar kodin da aka samu, kuma bã ya sami wani gyare wa maganar masu tsari da aka yi aiki a cikin aikin dabam-daban. @ info: whatsthis', 'he': 'בעיתון הזה אנו מציעים ולעריך בזהירות סגרת תווית רצף אשר משתמשת בלבד בתוכניות מדריכים נדירים שמוצאות ממציגות מילים צפופופות. המודל המוצע מקבל ביצועים (קרובים) של מצב האומנות לשני החלקים של תג הנאום והזיהוי של ישות בשם למגוון שפות. המודל שלנו סומך רק על כמה אלפי תכונות שנוצרו מהקוד, מבלי להשתמש בשינוי של מילים מייצגים משומשים למשימות שונות. למודל המוצע יש תכונות הגנרליזציה טובות, כיוון שהוא שומר מעל 89.8% מהמדויקת הממוצעת של התג POS שלו כשהוא מאמן ב-1.2% מהנתונים האימונים הנוכחים, כלומר 150 משפטים לשפה.', 'sk': 'V tem prispevku predlagamo in skrbno ocenimo okvir za označevanje zaporedja, ki uporablja izključno redke indikatorske funkcije, ki izhajajo iz gostih porazdeljenih besednih predstavitev. Predlagani model zagotavlja (skoraj) najsodobnejšo predstavo za označevanje dela govora in prepoznavanje imenovanih entitet za različne jezike. Naš model se opira le na nekaj tisoč redkih funkcij, ki izhajajo iz kodiranja, brez uporabe kakršne koli spremembe besednih predstavitev, uporabljenih za različna opravila. Predlagani model ima ugodne posploševalne lastnosti, saj obdrži več kot 89,8% svoje povprečne točnosti označevanja POS pri usposabljanju pri 1,2% vseh razpoložljivih podatkov o usposabljanju, tj. 150 stavkov na jezik.', 'bo': 'In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations. སྔོན་འཆར་བཀོད་པའི་མིག་སྔའི་ནང་དུ་སྒྲུབ་ཀྱི་གནས་སྟངས ང་ཚོའི་མ་དབྱིབས་བྱ་རིམ་མི་གཅིག་ལས་ཀྱང་སྒྲུབ་པའི་ཁྱད་ཆོས་ཉིད་ཅིག་ལས་ཕར་རྟགས་བྱེད་པའི་ཐ་སྙད་ཅིག་ལས འཆར་ཟིན་པའི་མིག'}
{'en': 'Cross-Lingual Syntactic Transfer with Limited Resources', 'ar': 'نقل نحوي متعدد اللغات بموارد محدودة', 'fr': 'Transfert syntaxique multilingue avec des ressources limitées', 'es': 'Transferencia sintáctica multilingüe con recursos limitados', 'pt': 'Transferência sintática entre idiomas com recursos limitados', 'ja': '限られたリソースでのクロスリンガル構文転送', 'zh': '资源有限跨语言句法传输', 'ru': 'Синтаксическая кросс-лингвистическая передача с ограниченными ресурсами', 'hi': 'सीमित संसाधनों के साथ क्रॉस-लिंगुअल वाक्यात्मक स्थानांतरण', 'ga': 'Aistriú Comhréire Trastheangach le hAcmhainní Teoranta', 'ka': 'Name', 'el': 'Διασγλωσσική συντακτική μεταφορά με περιορισμένους πόρους', 'hu': 'Nyelvközi szintaktikus transzfer korlátozott forrásokkal', 'it': 'Trasferimento sintattico cross-lingual con risorse limitate', 'lt': 'Tarptautinis sintaktinis perdavimas ribotais ištekliais', 'kk': 'Жергілікті ресурстар мен бірнеше тілік синтактикалық транспорт', 'mk': 'Name', 'ms': 'Pemindahan Sintaktik Selata-Bahasa dengan Sumber Terhadir', 'mt': 'Trasferiment Sintattiku Translingwali b’Riżorsi Limitati', 'mn': 'Хязгаарлагдсан боловсролын гишүүн шинжлэх ухаан', 'no': 'Name', 'ml': 'ക്രോസ്- ലിങ്ഗുവല്\u200d സിന്\u200dടാക്ടിക് വിഭവങ്ങളുമായി മാറ്റുക', 'sr': 'Cross-Lingual Syntactic Transfer sa ograničenim resursima', 'pl': 'Transfer syntaktyczny międzyjęzykowy z ograniczonymi zasobami', 'ro': 'Transfer sintactic interlingvistic cu resurse limitate', 'so': 'Transfer-Cross-Lingua Syntactic with Limited Resources', 'si': 'Name', 'ta': 'Cross-Lingual Syntactic Transfer with Limited Resources', 'sv': 'Tvärspråkig syntaktisk överföring med begränsade resurser', 'ur': 'Name', 'uz': 'Name', 'vi': 'Giao dịch chéo Ngôn ngữ Với Cơ Quan Hạn chế', 'da': 'Syntaktisk overførsel på tværs af sprog med begrænsede ressourcer', 'bg': 'Междулингвистичен синтактичен трансфер с ограничени ресурси', 'hr': 'Cross-Lingual Syntactic Transfer s ograničenim resursima', 'id': 'Transfer Sintaktik Selata-Lingua dengan Sumber Terbatas', 'de': 'Sprachübergreifender syntaktischer Transfer mit begrenzten Ressourcen', 'ko': '유한한 자원 아래의 다중 언어 문법 이동', 'fa': 'Transfer Syntactic Cross- Lingual با منابع محدودیت', 'tr': 'Çapraz Lingual Syntaktik Transfer Limited Ressurlar bilen', 'nl': 'Crosslinguale syntactische overdracht met beperkte middelen', 'af': 'Name', 'sq': 'Transferimi Sintaktik Ndërgjuhësor me burime të kufizuara', 'am': 'undo-type', 'hy': 'Cross-Lingual Syntactic Transfer with Limited Resources', 'az': 'Qƒ±ymetli Kaynaklar il…ô X…ôrc-Lingual Sintaktik Transfer', 'bn': 'সীমিত সম্পদের সাথে ক্রস- লিঙ্গুয়াল সিন্ট্যাকটিক ট্রান্সফার', 'sw': 'Uhamiaji wa Msikitiki wa lugha na rasilimali zisizo na mipaka', 'bs': 'Cross-Lingual Syntactic Transfer sa ograničenim resursima', 'cs': 'Mezijazyčný syntaktický transfer s omezenými zdroji', 'ca': 'Transfer sintàtic translingüe amb recursos limitats', 'fi': 'Kielten välinen synteettinen siirto rajoitetuilla resursseilla', 'et': 'Keeleülene süntaktiline ülekanne piiratud ressurssidega', 'jv': 'ProgressBarUpdates', 'he': 'העברה סנטקטית צלב- שפתית עם משאבים מוגבלים', 'ha': '@ action', 'sk': 'Medjezikovni sintaktični prenos z omejenimi viri', 'bo': 'Cross-Lingual Syntactic Transfer with Limited Resources'}
{'en': 'We describe a simple but effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where a large amount of translation data is not available. This method makes use of three steps : 1) a method for deriving cross-lingual word clusters, which can then be used in a multilingual parser ; 2) a method for transferring lexical information from a target language to source language treebanks ; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets from the Universal Dependencies corpora.', 'ar': 'نصف طريقة بسيطة ولكنها فعالة للنقل النحوي عبر اللغات لمحللي التبعية ، في السيناريو الذي لا يتوفر فيه قدر كبير من بيانات الترجمة. تستخدم هذه الطريقة ثلاث خطوات: 1) طريقة لاشتقاق مجموعات الكلمات متعددة اللغات ، والتي يمكن استخدامها بعد ذلك في محلل متعدد اللغات. 2) طريقة لنقل المعلومات المعجمية من لغة الهدف إلى بنوك لغة المصدر ؛ 3) طريقة لدمج هذه الخطوات مع طريقة عرض التعليقات التوضيحية المعتمدة على الكثافة لـ Rasooli و Collins (2015). تظهر التجارب تحسينات على أحدث ما توصل إليه العلم في العديد من اللغات المستخدمة في العمل السابق ، في بيئة يكون فيها المصدر الوحيد لبيانات الترجمة هو الكتاب المقدس ، وهو مجموعة أصغر بكثير من مجموعة يوروبارل المستخدمة في العمل السابق. تظهر النتائج باستخدام مجموعة Europarl كمصدر لبيانات الترجمة تحسينات إضافية على نتائج Rasooli و Collins (2015). نختتم بالنتائج على 38 مجموعة بيانات من Universal Dependencies corpora.', 'fr': "Nous décrivons une méthode simple mais efficace pour le transfert syntaxique multilingue d'analyseurs de dépendance, dans le cas où une grande quantité de données de traduction n'est pas disponible. Ce procédé utilise trois étapes\xa0: 1) un procédé pour dériver des groupes de mots multilingues, qui peuvent ensuite être utilisés dans un analyseur multilingue\xa0; 2) un procédé pour transférer des informations lexicales d'une langue cible vers des banques d'arbres de langue source\xa0; 3) un procédé pour intégrer ces étapes avec la densité méthode de projection d'annotations de Rasooli et Collins (2015). Les expériences montrent des améliorations par rapport à l'état de la technique dans plusieurs langues utilisées dans des travaux précédents, dans un contexte où la seule source de données de traduction est la Bible, un corpus considérablement plus petit que le corpus Europarl utilisé dans les travaux précédents. Les résultats utilisant le corpus Europarl comme source de données de traduction montrent des améliorations supplémentaires par rapport aux résultats de Rasooli et Collins (2015). Nous concluons avec les résultats de 38 ensembles de données des corpus de dépendances universelles.", 'es': 'Describimos un método simple pero eficaz para la transferencia sintáctica multilingüe de analizadores de dependencias, en el escenario en el que no se dispone de una gran cantidad de datos de traducción. Este método utiliza tres pasos: 1) un método para derivar grupos de palabras multilingües, que luego se pueden utilizar en un analizador multilingüe; 2) un método para transferir información léxica de un idioma de destino a los bancos de árboles del idioma de origen; 3) un método para integrar estos pasos con la densidad método de proyección de anotación de Rasooli y Collins (2015). Los experimentos muestran mejoras con respecto al estado de la técnica en varios idiomas utilizados en trabajos anteriores, en un entorno en el que la única fuente de datos de traducción es la Biblia, un corpus considerablemente más pequeño que el corpus de Europarl utilizado en trabajos anteriores. Los resultados que utilizan el corpus de Europarl como fuente de datos de traducción muestran mejoras adicionales con respecto a los resultados de Rasooli y Collins (2015). Concluimos con los resultados de 38 conjuntos de datos del corpus de Dependencias Universales.', 'pt': 'Descrevemos um método simples, mas eficaz, para transferência sintática entre idiomas de analisadores de dependência, no cenário em que uma grande quantidade de dados de tradução não está disponível. Esse método utiliza três etapas: 1) um método para derivar agrupamentos de palavras em vários idiomas, que podem ser usados em um analisador multilíngue; 2) um método para transferir informações lexicais de um idioma de destino para bancos de árvores de idioma de origem; 3) um método para integrar essas etapas com o método de projeção de anotação orientada por densidade de Rasooli e Collins (2015). As experiências mostram melhorias em relação ao estado da arte em várias línguas utilizadas em trabalhos anteriores, num cenário onde a única fonte de dados de tradução é a Bíblia, um corpus consideravelmente menor do que o corpus Europarl utilizado em trabalhos anteriores. Os resultados usando o corpus Europarl como fonte de dados de tradução mostram melhorias adicionais em relação aos resultados de Rasooli e Collins (2015). Concluímos com resultados em 38 conjuntos de dados dos corpora de Dependências Universais.', 'ja': '大量の翻訳データが利用できないシナリオでは、依存構文解析器のクロスリンガル構文転送のための単純で効果的な方法を説明します。 この方法は、次の3つのステップを使用します。1 ）多言語構文解析器で使用できるクロスリンガルワードクラスターを導出する方法。2 ）ターゲット言語からソース言語ツリーバンクに辞書情報を転送する方法。3 ）これらのステップをRasooli and Collins （ 2015 ）の密度駆動型アノテーション投影法と統合する方法。 実験では、翻訳データの唯一のソースが聖書である状況で、前作で使用されたいくつかの言語の最先端のものよりも改善されており、前作で使用されたEuroparlコーパスよりもかなり小さなコーパスであることが示されています。 翻訳データのソースとしてEuroparlコーパスを使用した結果は、RasooliとCollins （ 2015 ）の結果よりもさらに改善されています。 最後に、Universal Dependencies corporaの38個のデータセットの結果を紹介します。', 'zh': '略而言之语法传输恃解析器,重译不可用。 其法用三步:1)用生跨语单词簇之法,然后可于多语言解析器中用之; 2)一将词汇信息从语言传输至源语树库法。 3)以此步骤与RasooliCollins密度驱注投影之法(2015)集成之法。 实验明前作中所用数语,在译数者惟一本圣经,视前事所用Europarl语料库小得多者语料库。 以Europarl语料库为译数据源之的结果表明,比Rasooli、Collins(2015),其他改进矣。 最后,我们得出自通用靠语料库的 38 个数集的结果。', 'hi': 'हम निर्भरता पार्सर के क्रॉस-लिंगुअल वाक्यात्मक हस्तांतरण के लिए एक सरल लेकिन प्रभावी विधि का वर्णन करते हैं, उस परिदृश्य में जहां बड़ी मात्रा में अनुवाद डेटा उपलब्ध नहीं है। यह विधि तीन चरणों का उपयोग करती है: 1) क्रॉस-लिंगुअल शब्द क्लस्टर प्राप्त करने के लिए एक विधि, जिसका उपयोग तब बहुभाषी पार्सर में किया जा सकता है; 2) एक लक्ष्य भाषा से स्रोत भाषा treebanks के लिए लेक्सिकल जानकारी स्थानांतरित करने के लिए एक विधि; 3) रसूली और कोलिन्स (2015) के घनत्व-संचालित एनोटेशन प्रक्षेपण विधि के साथ इन चरणों को एकीकृत करने के लिए एक विधि। प्रयोगों ने पिछले काम में उपयोग की जाने वाली कई भाषाओं में अत्याधुनिक सुधार दिखाया है, एक ऐसी सेटिंग में जहां अनुवाद डेटा का एकमात्र स्रोत बाइबल है, जो पिछले काम में उपयोग किए जाने वाले यूरोपार्ल कॉर्पस की तुलना में काफी छोटा कॉर्पस है। अनुवाद डेटा के स्रोत के रूप में Europarl कॉर्पस का उपयोग करने वाले परिणाम रसूली और कोलिन्स (2015) के परिणामों पर अतिरिक्त सुधार दिखाते हैं। हम यूनिवर्सल निर्भरता निगम से 38 डेटासेट पर परिणामों के साथ निष्कर्ष निकालते हैं।', 'ru': 'Мы описываем простой, но эффективный метод межъязыковой синтаксической передачи парсеров зависимостей в сценарии, когда большой объем данных перевода недоступен. Этот метод использует три этапа: 1) способ получения кросс-лингвистических кластеров слов, который затем может быть использован в многоязычном парсере; 2) способ передачи лексической информации с целевого языка на исходный язык; 3) способ интеграции этих этапов с методом плотностной аннотации Rasooli and Collins (2015). Эксперименты показывают улучшения по сравнению с современным на нескольких языках, использованных в предыдущей работе, в условиях, когда единственным источником данных о переводе является Библия, значительно меньший корпус, чем корпус Europarl, использованный в предыдущей работе. Результаты с использованием Europarl corpus в качестве источника данных перевода показывают дополнительные улучшения по сравнению с результатами Rasooli и Collins (2015). Завершим с результатами по 38 наборам данных из корпусов Универсальных Зависимостей.', 'ga': 'Déanaimid cur síos ar mhodh simplí ach éifeachtach chun parsálaithe spleáchais a aistriú go comhréire tras-teangach, sa chás nach bhfuil cuid mhór sonraí aistriúcháin ar fáil. Baineann an modh seo úsáid as trí chéim: 1) modh chun braislí focal trasteangacha a dhíorthú, ar féidir iad a úsáid ansin i bparsálaí ilteangach; 2) modh chun faisnéis foclóireachta a aistriú ó sprioctheanga go bainc chrainn bhunteanga; 3) modh chun na céimeanna seo a chomhtháthú leis an modh teilgean nótaí dlús-tiomáinte Rasooli and Collins (2015). Léiríonn turgnaimh feabhsuithe ar an úrscothacht sna teangacha éagsúla a úsáideadh i saothar roimhe seo, i suíomh inarb é an Bíobla an t-aon fhoinse sonraí aistriúcháin, corpas i bhfad níos lú ná an corpas Europarl a úsáideadh i saothar roimhe seo. Léiríonn torthaí a úsáideann corpas Europarl mar fhoinse sonraí aistriúcháin feabhsuithe breise ar thorthaí Rasooli and Collins (2015). Tugaimid críoch le torthaí ar 38 tacar sonraí ón gCorparáid um Spleáchas Uilíoch.', 'ka': 'ჩვენ განახსოვრებთ ერთადერთი, მაგრამ ეფექტიური პროცემი, რომელიც სამკუთარი სინტაქტიური გადაწყვეტილების გადაწყვეტილებისთვის, სენარიოში, სადაც ძალიან დიდი განახს ეს მეტი სამი ნაწილის გამოყენება: 1) მეტი სიტყვების კლასტრების გამოყენება, რომელიც შემდეგ შეიძლება გამოყენება მრავალენგური პარასტრებში; 2) ლექსიკალური ინფორმაციის გადატვირთვა მიზეზი ენაზე მხოლოდ ენაზე სახელის სახელისთვის; 3) პროცემი, რომელიც პასული და კოლინსის პროცექციის განმავლობათან დაკავშირება ამ ნაწილების ინტერგურაცია. ექსპერიმენტები წინა სამუშაოში გამოიყენებული რამდენიმე ენების შესაძლებლობა, რომელიც მხოლოდ სამუშაო მონაცემების მხოლოდ ბიბლია, ძალიან პატარა კორპუს ვიდრე წინა სამუშაოში გამ შედეგი, რომლებიც იგოპალური კორპუსის გამოყენება, როგორც თავისულის მონაცემების გამოყენება მონაცემებების შესაძლებლობად დამატებს პასული და კოლინსის (2015 ჩვენ დავაკეთებთ 38 მონაცემების შესახებ სამყარო სამყარო სამყარო სამყარო სამყარო სამყარო.', 'hu': 'Egy egyszerű, de hatékony módszert írunk le a függőség-elemzők többnyelvű szintaktikus transzferére abban a forgatókönyvben, ahol nagy mennyiségű fordítási adat nem áll rendelkezésre. Ez a módszer három lépést alkalmaz: 1) egy módszer a többnyelvű szóklaszterek származtatására, amelyek ezután használhatók egy többnyelvű elemzőben; 2) a lexikai információk célnyelvről a forrásnyelvi háttérbe történő továbbítására szolgáló módszer; 3) ezen lépések integrálásának módszere Rasooli és Collins (2015) sűrűség-vezérelt megjegyzések vetítési módszerével. A kísérletek a korábbi művekben használt több nyelven is javulást mutatnak a korszerűséggel szemben, olyan környezetben, ahol a fordítási adatok egyetlen forrása a Biblia, amely lényegesen kisebb korpusz, mint a korábbi művekben használt Europarl korpusz. Az Europarl korpuszt fordítási adatforrásként használó eredmények további javulást mutatnak a Rasooli és Collins (2015) eredményeihez képest. Az Univerzális Függőségek Corpora 38 adathalmazának eredményeivel zárjuk le.', 'el': 'Περιγράφουμε μια απλή αλλά αποτελεσματική μέθοδο για τη διασυνοριακή συντακτική μεταφορά αναλυτών εξάρτησης, στο σενάριο όπου δεν είναι διαθέσιμη μεγάλη ποσότητα μεταφραστικών δεδομένων. Η μέθοδος αυτή χρησιμοποιεί τρία βήματα: 1) μια μέθοδο για την εξαγωγή γλωσσικών συμπληρωμάτων λέξεων, τα οποία στη συνέχεια μπορούν να χρησιμοποιηθούν σε έναν πολύγλωσσο αναλυτή. 2) μέθοδος μεταφοράς λεξικών πληροφοριών από μια γλώσσα-στόχο σε βάσεις δέντρων γλώσσας-προέλευσης· 3) μια μέθοδος ενσωμάτωσης αυτών των βημάτων με τη μέθοδο προβολής σχολιασμού που βασίζεται στην πυκνότητα των Ρασούλι και Κόλινς (2015). Τα πειράματα δείχνουν βελτιώσεις έναντι της τελευταίας τεχνολογίας σε διάφορες γλώσσες που χρησιμοποιήθηκαν σε προηγούμενες εργασίες, σε ένα περιβάλλον όπου η μόνη πηγή μεταφραστικών δεδομένων είναι η Βίβλος, ένα σημαντικά μικρότερο σώμα από το σώμα που χρησιμοποιήθηκε στο προηγούμενο έργο. Τα αποτελέσματα που χρησιμοποιούν το σώμα Europarl ως πηγή μεταφραστικών δεδομένων δείχνουν πρόσθετες βελτιώσεις σε σχέση με τα αποτελέσματα των Rasooli και Collins (2015). Ολοκληρώνουμε με αποτελέσματα σε 38 σύνολα δεδομένων από τα σώματα καθολικών εξαρτήσεων.', 'it': "Descriviamo un metodo semplice ma efficace per il trasferimento sintattico cross-lingual dei parser di dipendenza, nello scenario in cui una grande quantità di dati di traduzione non è disponibile. Questo metodo si avvale di tre passaggi: 1) un metodo per ricavare cluster di parole cross-lingual, che possono poi essere utilizzati in un parser multilingue; 2) un metodo per trasferire le informazioni lessicali da una lingua di destinazione a treebank della lingua di origine; 3) un metodo per integrare questi passaggi con il metodo di proiezione dell'annotazione basato sulla densità di Rasooli e Collins (2015). Gli esperimenti mostrano miglioramenti rispetto allo stato dell'arte in diverse lingue utilizzate nei lavori precedenti, in un ambiente in cui l'unica fonte di dati di traduzione è la Bibbia, un corpus notevolmente più piccolo rispetto al corpus Europarl utilizzato nei lavori precedenti. I risultati che utilizzano il corpus Europarl come fonte di dati di traduzione mostrano ulteriori miglioramenti rispetto ai risultati di Rasooli e Collins (2015). Concludiamo con risultati su 38 dataset dei corpora delle dipendenze universali.", 'kk': 'Біз тілдерді көптеген синтактикалық талдаушылардың қарапайым, бірақ эффективті әдісін түсіндіреміз, олардың көптеген аудармалардың деректері қол жеткізбеген сценариясында. Бұл әдіс үш қадам қолданылады: 1) бірнеше тілдік сөз кластерін түсіру әдісі, ол кейін көп тілдік талдаушында қолданылады; 1) әдіс 2) лексикалық мәліметті мақсатты тілден көзінің тілдерінің орындарына аудару әдісі; NAME OF TRANSLATORS 3) Бұл қадамдарды Rasooli және Collins (2015 жылы) жынықтығын басқару әдісімен біріктіру әдісі. Тәжірибелер алдыңғы жұмыста қолданылатын бірнеше тілдер үшін өзгертулерді көрсетеді. Алдыңғы жұмыста қолданылатын Европа парламентінің корпусынан артық көп корпус. Еуропальт корпусын аудармалардың көзі ретінде қолданатын нәтижелер Rasooli және Collins (2015) нәтижелерінде қосымша жақсартуларын көрсетеді. Біз әлемдік Тәуелсіздік Корпорасының 38 деректер жиынының нәтижелерін аяқтадық.', 'lt': 'Mes apibūdiname paprastą, bet veiksmingą tarpkalbinio sintaksinio priklausomybės analizatorių perdavimo metodą scenarijuje, kuriame nėra daug vertimo duomenų. Šiuo metodu naudojami trys etapai: 1) tarpkalbinių žodžių klasterių sukūrimo metodas, kuris gali būti naudojamas daugiakalbiame analizatoriuje; 2) lexinės informacijos perdavimo iš tikslinės kalbos į šaltinio kalbos medžių dėžutes metodas; 3) šių žingsnių integravimo į Rasooli ir Collins tankio anotacijos projektavimo metodą (2015 m.). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work.  Rezultatai, naudojantys Europarl corpus kaip vertimo duomenų šaltinį, rodo, kad Rasooli ir Collins (2015 m.) rezultatai dar labiau pagerėjo. Baigiame su rezultatais dėl 38 Universal Dependencies corpora duomenų rinkinių.', 'ms': 'Kami menggambarkan kaedah sederhana tetapi berkesan untuk pemindahan sintaktik saling bahasa penghurai dependensi, dalam skenario di mana jumlah besar data terjemahan tidak tersedia. Kaedah ini menggunakan tiga langkah: 1) kaedah untuk menghasilkan kumpulan perkataan salib-bahasa, yang kemudian boleh digunakan dalam penghurai berbilang-bahasa; 2) kaedah untuk memindahkan maklumat leksikal dari bahasa sasaran ke pangkalan pokok bahasa sumber; 3) kaedah untuk mengintegrasikan langkah-langkah ini dengan kaedah projeksi anotasi yang dipimpin oleh ketepatan Rasooli dan Collins (2015). Eksperimen menunjukkan peningkatan atas kemajuan dalam beberapa bahasa yang digunakan dalam kerja terdahulu, dalam tetapan di mana satu-satunya sumber data terjemahan ialah Alkitab, korpus yang jauh lebih kecil daripada korpus Europarl yang digunakan dalam kerja terdahulu. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015).  We conclude with results on 38 datasets from the Universal Dependencies corpora.', 'mk': 'Опишуваме едноставен, но ефикасен метод за прекујазичен синтактички трансфер на анализатори на зависност, во сценариото каде што голема количина податоци за превод не се достапни. Овој метод користи три чекори: 1) метод за извлекување крстојазични групи на зборови, кој потоа може да се користи во мултијазичен анализатор; 2) метод за пренесување на лексикални информации од јазик на мета на извор на дрвјата на јазикот; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015).  Експериментите покажуваат подобрувања во однос на најновата технологија на неколку јазици кои се користат во претходната работа, во околина каде единствениот извор на преводни податоци е Библијата, значително помал корпус од корпусот на Европарл кој се користи во претходната работа. Резултатите со користењето на корпусот на Europarl како извор на преводни податоци покажуваат дополнителни подобрувања во врска со резултатите на Расули и Колинс (2015). Завршиме со резултатите на 38 податоци од Универзалните зависности.', 'mt': "Aħna niddeskrivu metodu sempliċi iżda effettiv għat-trasferiment sintattiku translingwi tal-analizzaturi tad-dipendenza, fix-xenarju fejn ammont kbir ta’ dejta tat-traduzzjoni mhuwiex disponibbli. Dan il-metodu jagħmel użu minn tliet passi: 1) metodu għad-derivazzjoni ta’ raggruppamenti ta’ kliem translingwi, li mbagħad jista’ jintuża f’analizzatur multilingwi; 2) metodu għat-trasferiment ta’ informazzjoni lexika minn lingwa fil-mira għal banek tas-siġar tal-lingwa tas-sors; 3) metodu għall-integrazzjoni ta’ dawn il-passi mal-metodu ta’ projezzjoni tal-annotazzjoni mmexxi mid-densità ta’ Rasooli u Collins (2015). L-esperimenti juru titjib fuq l-aktar livell avvanzat f’diversi lingwi użati fix-xogħol preċedenti, f’ambjent fejn l-uniku sors ta’ dejta ta’ traduzzjoni huwa l-Bibla, korpus konsiderevolment iżgħar mill-Europarl corpus użat fix-xogħol preċedenti. Ir-riżultati li jużaw il-Europarl corpus bħala sors ta’ dejta ta’ traduzzjoni juru titjib addizzjonali fuq ir-riżultati ta’ Rasooli u Collins (2015). Aħna nikkonkludu b'riżultati fuq 38 sett ta' dejta mill-korpora tad-Dipendenzi Universali.", 'ml': 'ആശ്രയിക്കുന്ന പാര്\u200dസര്\u200dസിന്റെ സിന്റാക്റ്റിക്ക് മാറ്റുന്നതിനുള്ള ഒരു ലളിതമായ, പക്ഷെ പ്രാപ്തികമായ രീതിയാണ് ഞങ്ങള്\u200d വിവരിക്ക ഈ രീതി 2) a method for transferring lexical information from a target language to source language treebanks;  3) ഈ പടികളെ കൂട്ടിച്ചേര്\u200dക്കാനുള്ള ഒരു രീതി പരീക്ഷണങ്ങള്\u200d മുമ്പ് ജോലിയില്\u200d ഉപയോഗിക്കുന്ന പല ഭാഷകളില്\u200d മുന്\u200dഗണന ഭാഷകളുടെ രാജ്യത്തെക്കാളും മുന്\u200dഗണന മുന്\u200dഗണനം കാണിക്കുന്നു. പരിശോധനങ്ങള്\u200d മാത് പരിഭാഷയുടെ വിവരങ്ങളുടെ സ്രോതസ്സായി യൂറോപാര്\u200dല്\u200d കോര്\u200dപ്പുസ് ഉപയോഗിച്ചുള്ള ഫലങ്ങള്\u200d റാസുലിനിയും കോളിന്\u200dസിന്\u200dറെയും ഫല നമ്മള്\u200d 38 ഡാറ്റാസെറ്റില്\u200d നിന്നും അവസാനിപ്പിക്കുന്നു. യൂണിവര്\u200dണലല്\u200d ഡിപ്പെന്\u200dസികള്\u200d കോര്\u200dപ്പോറ.', 'pl': 'Opisujemy prostą, ale skuteczną metodę wielojęzycznego transferu składni parserów zależności, w scenariuszu, gdy duża ilość danych tłumaczeniowych nie jest dostępna. Metoda ta wykorzystuje trzy etapy: 1) metodę pozyskiwania wielojęzycznych klastrów słów, które można następnie wykorzystać w wielojęzycznym parserze; 2) metodę przenoszenia informacji leksykalnych z języka docelowego do baz drzew języka źródłowego; 3) metoda integracji tych kroków z metodą projekcji adnotacji napędzanej gęstością Rasooli i Collins (2015). Eksperymenty pokazują ulepszenia w stosunku do najnowocześniejszych technologii w kilku językach używanych w poprzednich pracach, w otoczeniu, w którym jedynym źródłem danych tłumaczeniowych jest Biblia, znacznie mniejszy korpus niż korpus Europarl stosowany w poprzednich pracach. Wyniki wykorzystania korpusu Europarl jako źródła danych tłumaczeniowych wskazują na dodatkową poprawę w stosunku do wyników Rasooliego i Collinsa (2015). Zakończymy wynikami dotyczącymi 38-zbiorów danych z korpusów Universal Dependencies.', 'mn': 'Бид хэлний шинжлэх ухааныг олон хэлний шинжлэх ухааны шинжлэх ухааны энгийн боловч үр дүнтэй аргыг тайлбарлаж өгдөг. Энэ арга нь 3 алхам ашигладаг: 1) олон хэл хуваалцагч дээр ашиглаж болно. 2) Лексикал мэдээллийг зориулагдсан хэлээс эх хэлний загвар руу шилжүүлэх арга; 3) Русули болон Колинс (2015) гэх зэрэг жинтэй хэмжээний хэвлэлийн аргыг нэгтгэх арга юм. Түүний туршилтууд өмнө ажилдаа хэрэглэгдсэн олон хэл дээр урлагийн уламжлал дээр сайжруулалтыг харуулдаг. Энэ нь Библион гэдэг цорын ганц эх үүсвэр юм. Өмнө ажилдаа хэрэглэгдсэн Европарлын корпус-аас их бага корпус юм. Үүний үр дүнд Европарлын корпус ашиглаж буй хөрөнгө оруулах өгөгдлийн эх үүсвэр нь Расули болон Колинсын (2015) үр дүнд нэмэлт сайжруулалт гаргадаг. Бид ертөнцийн хамааралтай Корпора-ын 38 өгөгдлийн сангийн үр дүнг төгсгөл.', 'no': 'Vi beskriver ein enkel, men effektiv metode for krysspråk syntaksisk overføring av avhengighetstolkar, i scenarioen der mange omsetjingsdata ikkje er tilgjengelege. Denne metoden gjer bruk av tre steg: 1) ein metode for å fjerna krysspråksgrupper, som så kan brukast i ein fleirspråksanalyser. 2) ein metode for å overføra leksiske informasjon frå eit målspråk til kjeldespråk-trekantar; 3) ein metode for å integrere desse stegane med metoden for prosjeksjon av Rasooli og Collins (2015). Eksperiment viser forbedringar over kunsttilstanden i fleire språk som vert brukt i tidlegare arbeid, i eit innstilling der den eneste kjelden av omsetjingsdata er Bibelen, eit svært mindre korpus enn Europarliske korpus som vert brukt i tidlegare arbeid. Resultat med Europarlamentkorpusen som kjelde for omsetjingsdata viser ekstra forbedringar over resultata av Rasooli og Collins (2015). Vi avsluttar med resultat på 38 datasett frå den universele avhengighetskorporen.', 'ro': 'Descriem o metodă simplă, dar eficientă pentru transferul sintactic interlingv al parserelor de dependență, în scenariul în care o cantitate mare de date de traducere nu este disponibilă. Această metodă utilizează trei pași: 1) o metodă de deducere a grupurilor de cuvinte încrucișate, care pot fi apoi utilizate într-un parser multilingv; 2) o metodă de transfer a informaţiilor lexicale dintr-o limbă ţintă în treebankurile de limbă sursă; 3) o metodă de integrare a acestor etape cu metoda de proiecție a adnotării bazată pe densitate a lui Rasooli și Collins (2015). Experimentele arată îmbunătățiri față de cele mai moderne limbi folosite în lucrările anterioare, într-un cadru în care singura sursă de date de traducere este Biblia, un corpus considerabil mai mic decât corpul Europarl folosit în lucrările anterioare. Rezultatele utilizând corpusul Europarl ca sursă de date privind traducerea arată îmbunătățiri suplimentare față de rezultatele lui Rasooli și Collins (2015). Încheiem cu rezultate pe 38 de seturi de date din corpora Dependențelor Universale.', 'sr': 'Mi opisujemo jednostavan, ali efikasan metod za međujezički sintaktički prenos parsera ovisnosti, u scenariju gde nije dostupna velika količin a podataka o prevodu. Ova metoda koristi tri koraka: 1) metodu za izvlačenje krstojezičkih skupina riječi, koja se onda može koristiti u multijezičkom analizatoru; 2) metoda za prebacivanje leksičkih informacija sa ciljnog jezika na izvorne jezičke trgovine; 3) metod integracije tih koraka sa metodom proglašavanja oznake na gustinu Rasooli i Collins (2015). Eksperimenti pokazuju poboljšanje stanja umjetnosti na nekoliko jezika korištenih na prethodnom poslu, u stanju gde je jedini izvor prevodnih podataka Biblija, značajno manji korpus od evropskog korpusa korpusa korištenog u prethodnom poslu. Rezultati korpusa Evropskog parlamenta kao izvor prevodnih podataka pokazuju dodatne poboljšanja rezultata Rasooli i Collins (2015). Završili smo sa rezultatima na 38 podataka od Univerzalne zavisnosti korpore.', 'sv': 'Vi beskriver en enkel men effektiv metod för flerspråkig syntaktisk överföring av beroendetolkare, i det scenario där en stor mängd översättningsdata inte finns tillgänglig. Denna metod använder sig av tre steg: 1) en metod för att härleda korspråkiga ordkluster, som sedan kan användas i en flerspråkig parser; 2) En metod för överföring av lexikal information från ett målspråk till källspråkets treebanks. 3) en metod för att integrera dessa steg med den densitetsdrivna annotationsprojektionsmetoden för Rasooli och Collins (2015). Experiment visar förbättringar jämfört med det senaste på flera språk som använts i tidigare arbeten, i en miljö där den enda källan till översättningsdata är Bibeln, en betydligt mindre korpus än Europarl korpus som användes i tidigare verk. Resultaten som använder Europarl-korpusen som källa till översättningsdata visar ytterligare förbättringar jämfört med resultaten från Rasooli och Collins (2015). Vi avslutar med resultat på 38 datauppsättningar från Universal Dependences corpora.', 'si': 'අපි සාමාන්\u200dය නමුත් ප්\u200dරශ්නයක් විස්තර කරන්නේ විශාල භාෂාවික සංවේදනය විස්තර කරන්න, විශාල දත්ත ගොඩක් ලොකු විශාල මේ විධානය පැත්ත තුනක් භාවිතා කරනවා: 1) විශාල භාෂාවක් වචන ක්\u200dලාස්ටර් විදිහට පාවිච්චි කරන්න විධානයක්,  2) ලෙක්සිකල් තොරතුරු ලක්ෂණ භාෂයෙන් මුළු භාෂාව ට්\u200dරීබැන්ක් වලට ප්\u200dරවර්තනය කරන්න විදිහා 3) රාසුලි සහ කෝලින්ස් වල ප්\u200dරවෘත්තිය සඳහා මෙම පැත්තුව සම්බන්ධ කරන්න විධානයක්. පරීක්ෂණය පෙන්වන්න පුළුවන් ස්ථානය-of-the-art වලට පසුගිය වැඩේ භාෂාවට භාවිත කරපු භාෂාවක් විතරයි, පුළුවන් වැඩේ භාවිත කරපු භ ප්\u200dරතිචාරය යුරෝපල් කොර්පුස් භාවිතා කරන්න ප්\u200dරතිචාරයක් විදිහට පරිවර්තන දත්ත ප්\u200dරතිචාරයක් පෙන්වන් අපි ප්\u200dරතිචාරයක් තියෙන්නේ විශේෂ විශේෂ කොර්පෝරා වලින් තොරතුරු 38 ගැන.', 'so': 'Waxaannu sawirannaa qaab fudud laakiin tayo leh oo ay leedahay wareejinta baarlamaha ay ku xiran tahay, marka aan laga helin macluumaad badan oo turjuman. Midabkan ayaa isticmaali kara sadex tallaabo: 1) qaab uu soo koriyo xarumo luuqadaha kala duwan, kaas oo markaas lagu isticmaali karo baaritaanka luuqadaha kala duduwan; 2) qaabka macluumaadka leksikalka ah looga wareejiyo luqada goalka ah oo looga soo diro luqada treebanka; 3) qaab ay ku qabsato tallaabooyinkaas oo ay ku leedahay qalabka naasaha ee rasooli iyo Collins (2015). Imtixaanka waxaa ka muuqata hagaajinta xaaladda farshaxanka ee ku qoran luuqado kala duduwan oo lagu isticmaalay shaqada hore, marka lagu qoro, marka lagu jiro kooxaha turjumaadda oo kaliya ee macluumaadka lagu turjumo waa Bibelka, kaas oo ka yar qoyska korpuska Yurub ee shaqadii hore lagu isticmaalay. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015).  Waxaynu ku dhamaystirnaa fasaxyo 38-sameynta macluumaadka ee shirkadda macluumaadka caalamiga ah.', 'ta': 'சார்ந்த சார்ந்த பார்சர்களின் ஒத்திசைவு மாற்றும் சுலபமான ஆனால் பயனுள்ள முறைமையை விவரிக்கிறோம். மொழிமொழிபெயர்ப்பு தகவல் கிட இந்த முறை மூன்று படிகளை பயன்படுத்துகிறது: 1) முறைமையை கொண்டு வருவதற்கு, அது பல மொழி பகுதியில் பயன்படுத்தலாம். 2) இலக்கு மொழியிலிருந்து மூல மொழியின் தொடர்புகளுக்கு மாற்றும் முறை; 3) ராசுலி மற்றும் கால்லின்ஸ் முறைமையில் இந்த படிகளை ஒருங்கிணைக்க ஒரு முறையில். முந்தைய வேலையில் பயன்படுத்தப்பட்ட பல மொழிகளின் நிலையில் முன்னேற்றங்களில் முன்னேற்றங்களை காட்டுகிறது, மொழிபெயர்ப்பு தரவு மட்டும் மூலம் பைப்பர்,  Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015).  நாம் முடிவு 38 தரவு அமைப்புகளில் முடிவு செய்கிறது உலக சார்ந்த சார்பு நிறுவனத்தில் இருந்து.', 'ur': 'ہم ایک ساده لیکن اثرات طریقے کی توصیف کریں گے، جہاں بہت بڑی ترجمہ ڈیٹا موجود نہیں ہے۔ یہ طریقہ تین قدم سے استعمال کرتا ہے: 1) ایک طریقہ کروس زبان کلسٹر کے ذریعہ سے استعمال کرتا ہے، پھر ایک بہت سی زبان پارچر میں استعمال کر سکتا ہے۔ 2) لکسیکل معلومات کو ایک موجود زبان سے سورس زبان تریبانک کی طرف تراف کرنے کے لئے ایک طریقہ ہے; 3) راسولی اور کالینز (2015) کی گھونٹی پر چلنے والی اظهار کے مطابق ان قدموں کو متصل کرنے کے لئے ایک طریقہ ہے۔ آزمائش کے باعث بہت سی زبانوں میں جو پہلے کاروبار میں استعمال کئے جاتے ہیں، بہت سی زبانوں میں بہترین ترجمہ ڈیٹے کے سوا صرف ابیبل ہے، ایک بہت چھوٹا کورپوس جو پہلے کاروبار میں استعمال کئے جاتے ہیں۔ نتیجے یورپالٹ کورپوس کے استعمال میں ترجمہ ڈیٹا کے سراسر کے طور پر راسولی اور کالینز (2015) کے نتیجے پر اضافہ تغییرات دکھاتے ہیں۔ ہم نے 38 ڈیٹ سٹ کے نتائج کا نتیجہ پورا کرلیا ہے جینلورڈینسیس کورپورا سے۔', 'vi': 'Chúng tôi mô tả một phương pháp đơn giản nhưng hiệu quả cho việc truyền qua ngôn ngữ pháp của phân tích phụ thuộc, trong trường hợp không có nhiều dữ liệu dịch. Phương pháp này dùng ba bước: 1) một phương pháp phân bổ các cụm từ ngữ khác nhau, có thể được dùng trong một phân tách đa dạng. 2) một phương pháp chuyển thông tin từ ngôn ngữ đích sang ngôn ngữ nguồn Ba) một phương pháp hoà nhập những bậc này với phương pháp xử lý chú thích dựa trên mật độ (Rasooli và Collins) của Rasooli. Thí nghiệm cho thấy cải tiến trạng thái nghệ thuật trong nhiều ngôn ngữ được dùng trong các tác phẩm trước đó, trong một môi trường nơi mà nguồn duy nhất của dữ liệu dịch chuyển là Kinh Thánh, một tập thể còn nhỏ hơn nhiều so với tập đoàn Châu Âu được sử dụng trong các tác phẩm trước. Kết quả sử dụng tập đoàn Châu Âu làm nguồn dữ liệu dịch cho thấy có những cải tiến bổ sung hơn về kết quả của Rasooli và Collins (bộ Lời 95). Chúng tôi kết thúc với kết quả của 38 bộ dữ liệu từ thế hệ chung.', 'uz': "Biz juda ko'p tarjima maʼlumot mavjud emas, bir necha tillar bir necha xil tillar syntactik koʻchirish usulini aytamiz. Bu usul uchta qadam foydalanadi: 1) bir necha tillar uchun qoʻllanmalarni olish usuli, keyin bir nechta ingliz parameterda foydalanish mumkin; Name 3) Rasooli va Collins (2015) bilan birlashtirish usuli. Name @ info Biz 38 maʼlumotlar tarkibini Universal Dependence Corporiyatdan tugatamiz.", 'nl': 'We beschrijven een eenvoudige maar effectieve methode voor cross-lingual syntactische overdracht van afhankelijkheidsparsers, in het scenario waarin een grote hoeveelheid vertaalgegevens niet beschikbaar is. Deze methode maakt gebruik van drie stappen: 1) een methode voor het afleiden van meertalige woordclusters, die vervolgens kunnen worden gebruikt in een meertalige parser; 2) een methode voor het overbrengen van lexicale informatie van een doeltaal naar boombanken in de brontaal; 3) een methode om deze stappen te integreren met de dichtheidsgestuurde annotatieprojectiemethode van Rasooli en Collins (2015). Experimenten tonen verbeteringen aan ten opzichte van de state-of-the-art in verschillende talen die in eerdere werken werden gebruikt, in een omgeving waar de enige bron van vertaalgegevens de Bijbel is, een aanzienlijk kleiner corpus dan het Europarl corpus dat in eerdere werken werd gebruikt. Resultaten met behulp van het Europarl corpus als bron van vertaalgegevens laten extra verbeteringen zien ten opzichte van de resultaten van Rasooli en Collins (2015). We sluiten af met resultaten op 38 datasets uit de Universal Dependencies corpora.', 'bg': 'Описваме прост, но ефективен метод за междуезичен синтактичен трансфер на анализатори на зависимости, в сценария, в който няма голямо количество данни за превод. Този метод използва три стъпки: 1) метод за извличане на междуезични думични клъстери, които след това могат да се използват в многоезичен анализатор; 2) метод за прехвърляне на лексикална информация от целеви езици към изходни езици; 3) метод за интегриране на тези стъпки с метода на проекция на анотация, задвижвана от плътността на Расули и Колинс (2015). Експериментите показват подобрения в сравнение със съвременните технологии в няколко езика, използвани в предишни произведения, в обстановка, където единственият източник на данни за превод е Библията, значително по-малък корпус от Европарл корпуса, използван в предишни произведения. Резултатите от използването на корпуса Европарл като източник на данни за преводи показват допълнителни подобрения спрямо резултатите от Расули и Колинс (2015). Заключваме с резултати от 38 набора от данни от корпусите "Универсални зависимости".', 'da': 'Vi beskriver en enkel, men effektiv metode til tværsproget syntaktisk overførsel af afhængighedsfortolkere, i det scenario, hvor en stor mængde oversættelsesdata ikke er tilgængelig. Denne metode gør brug af tre trin: 1) en metode til at udlede tværsprogede ordklynger, som derefter kan bruges i en flersproget fortolker; 2) en metode til overførsel af leksikalske oplysninger fra et målsprog til kildesprogets treebanks 3) en metode til at integrere disse trin med den densitetsdrevne annoteringsprojektionsmetode Rasooli og Collins (2015). Eksperimenter viser forbedringer i forhold til den nyeste teknologi på flere sprog, der anvendes i tidligere værker, i et miljø, hvor den eneste kilde til oversættelsesdata er Bibelen, et betydeligt mindre korpus end Europarl korpus, der anvendes i tidligere værker. Resultater, der anvender Europarl-korpustet som kilde til oversættelsesdata, viser yderligere forbedringer i forhold til resultaterne fra Rasooli og Collins (2015). Vi afslutter med resultater på 38 datasæt fra Universal Dependences corpora.', 'hr': 'Opišemo jednostavan, ali učinkovit način za prekogranični sintaktički prenos parsera ovisnosti, u scenariju gdje nije dostupna velika količin a podataka o prevodu. Ova metoda koristi tri koraka: 1) metodu za proizvedenje krstojezičkih skupina riječi, koja se onda može koristiti u multijezičkom razmatraču; 2) metodu prebacivanja leksičkih informacija iz ciljnog jezika na izvorne jezičke trgovine; 3) metodu integracije tih koraka s metodom proglašavanja oznake na gustoću Rasooli i Collins (2015). Eksperimenti pokazuju poboljšanje tijela umjetnosti na nekoliko jezika korištenih na prethodnom radu, u stanju gdje je Biblija jedini izvor prevodnih podataka, značajno manji korpus od Europarlskog korpusa korpusa korištenog u prethodnom radu. Rezultati korporacije Europarl a kao izvor prevodnih podataka pokazuju dodatne poboljšanja rezultata Rasooli i Collins (2015). Završili smo s rezultatima na 38 podataka iz Univerzalne zavisnosti korpore.', 'de': 'Wir beschreiben eine einfache, aber effektive Methode für den syntaktischen Transfer von Abhängigkeitsparsern in einem Szenario, in dem eine große Menge an Übersetzungsdaten nicht verfügbar ist. Diese Methode verwendet drei Schritte: 1) eine Methode zur Ableitung von sprachübergreifenden Wortclustern, die dann in einem mehrsprachigen Parser verwendet werden können; 2) eine Methode zur Übertragung lexikalischer Informationen von einer Zielsprache auf Stammbanken der Ausgangssprache; 3) eine Methode zur Integration dieser Schritte mit der dichtegetriebenen Annotationsprojektionsmethode von Rasooli und Collins (2015). Experimente zeigen Verbesserungen gegenüber dem Stand der Technik in mehreren Sprachen, die in früheren Arbeiten verwendet wurden, in einem Umfeld, in dem die einzige Quelle der Übersetzungsdaten die Bibel ist, ein wesentlich kleineres Korpus als das Europarl Korpus, das in früheren Arbeiten verwendet wurde. Ergebnisse, die das Europarl-Korpus als Quelle für Übersetzungsdaten verwenden, zeigen zusätzliche Verbesserungen gegenüber den Ergebnissen von Rasooli und Collins (2015). Wir schließen mit Ergebnissen zu 38-Datensätzen aus den Universal Dependencies-Korpora.', 'id': 'Kami menggambarkan metode sederhana tapi efektif untuk transfer sintaksi saling bahasa dari parser dependensi, dalam skenario di mana jumlah besar data terjemahan tidak tersedia. Metode ini menggunakan tiga langkah: 1) metode untuk menghasilkan kelompok kata saling bahasa, yang kemudian dapat digunakan dalam parser multibahasa; 2) metode untuk memindahkan informasi lexik dari bahasa sasaran ke batang pohon bahasa sumber; 3) metode untuk mengintegrasi langkah-langkah ini dengan metode proyeksi annotasi yang didorong oleh ketepatan Rasooli dan Collins (2015). Eksperimen menunjukkan perkembangan atas state-of-the-art dalam beberapa bahasa yang digunakan dalam pekerjaan sebelumnya, dalam sebuah setting di mana satu-satunya sumber data terjemahan adalah Alkitab, sebuah korpus yang jauh lebih kecil dari corpus Europarl yang digunakan dalam pekerjaan sebelumnya. Hasil menggunakan Europarl corpus sebagai sumber data terjemahan menunjukkan perkembangan tambahan atas hasil Rasooli dan Collins (2015). Kami menyelesaikan dengan hasil pada 38 set data dari Universal Dependencies corpora.', 'sw': 'Tunaelezea njia rahisi lakini yenye ufanisi wa usafirishaji wa mfumo wa lugha mbalimbali wa mabunge wanategemea, katika eneo ambapo takwimu kubwa za tafsiri hazipatikani. Utawala huu unatumia hatua tatu: 1) njia ya kupata viungo vya maneno vingi vya lugha, ambavyo vinaweza kutumika katika mchanganyiko wa lugha mbalimbali; 2) njia ya kuhamisha taarifa za ki-lexico kutoka lugha inayolenga kwenda kwenye lugha za lugha na lugha za lugha: 3) njia ya kuunganisha hatua hizi kwa njia ya michoro ya kuchanganyikiwa na uchochezi wa Rasooli na Collins (2015). Majaribio yanaonyesha maendeleo ya hali ya sanaa kwa lugha kadhaa zilizotumiwa katika kazi zilizopita, katika mazingira ambayo chanzo pekee cha taarifa za kutafsiri ni Biblia, makampuni madogo zaidi ya makampuni ya Ulaya yaliyotumiwa katika kazi zilizopita. Matokeo yaliyotumia makampuni ya Europarl kama chanzo cha taarifa za kutafsiri zinaonyesha maendeleo mengine juu ya matokeo ya Rasooli na Collins (2015). Tuhitimisha na matokeo ya seti 38 kutoka kwenye kampuni ya Ulimwengu.', 'fa': 'ما یک روش ساده ولی موثر برای انتقال سینتیکی متوسط زبان\u200cها از پارسالهای بستگی توصیف می\u200cکنیم، در سناریو که مقدار زیادی از داده\u200cهای ترجمه\u200cای در دسترس نیست. این روش از سه قدم استفاده می\u200cکند: ۱) روش برای تولید کلاس\u200cهای کلاس\u200cهای متوسط زبان، که بعدش می\u200cتواند در یک جداکنده\u200cی متوسط زبان استفاده شود. 2) روش برای انتقال اطلاعات لغوی از زبان هدف به درختهای درخت زبان منبع; و 3) یک روش برای اینکه این قدم\u200cها را با روش توصیف\u200cکننده\u200cی توصیف\u200cکننده\u200cی تنگی راسولی و کالینز (۲۰۱۵) جمع کند. تجربه\u200cها توسط ایالت هنر در چندین زبان که در کار قبل استفاده می\u200cشود، بهترین\u200cها را نشان می\u200cدهند، در یک تنظیم که تنها منبع داده\u200cهای ترجمه انجیل است، یک کورپوس کوچکتر از کورپوس اروپال که در کار قبل استفاده می\u200cشود. نتیجه\u200cهای استفاده از کورپوس اروپارل به عنوان منبع داده\u200cهای ترجمه به نتیجه\u200cهای راسولی و کالینز (2015) اضافه\u200cای را نشان می\u200cدهد. ما با نتیجه\u200cهای 38 دسته\u200cهای داده\u200cای از شرکت اعتماد جهانی به پایان رسیدیم.', 'ko': '우리는 대량의 번역 데이터를 사용할 수 없는 상황에서 관계 해석기에 의존하는 다중 언어 문법 변환에 사용되는 간단하지만 효과적인 방법을 묘사했다.이 방법은 세 가지 절차를 사용했다. 1) 다중 언어 묶음을 내보내는 방법을 사용한 다음에 다중 언어 해석기에서 사용할 수 있다.2) 어휘 정보를 목표 언어에서 원시 언어 트리 라이브러리로 전송하는 방법3) Rasooli 및 Collins(2015)의 밀도 구동 주석 투영법과 이러한 단계를 결합하는 방법실험에 의하면 번역 데이터의 유일한 출처가 성경인 상황에서 이전 업무에서 사용된 몇 가지 언어에 비해 이러한 언어의 수준이 향상되었고 은 이전 업무에서 사용된 유럽 어료 라이브러리보다 훨씬 작은 어료 라이브러리이다.Europarl 어료 라이브러리를 번역 데이터 소스로 사용한 결과 Rasooli와 Collins(2015)의 결과에 비해 더 많이 개선된 것으로 나타났다.Universal Dependencies 자료 라이브러리에서 나온 38개의 데이터 세트의 결과를 요약했습니다.', 'sq': 'Ne përshkruajmë një metodë të thjeshtë por efektive për transferimin ndërgjuhësor sintaktik të analizuesve të varësisë, në skenarin ku një sasi të madhe e të dhënave të përkthimit nuk janë në dispozicion. Ky metodë bën përdorim të tre hapave: 1) një metodë për nxjerrjen e grupeve të fjalëve ndërgjuhësore, të cilat pastaj mund të përdoren në një analizues shumëgjuhësor; 2) një metodë për transferimin e informacionit lexik nga një gjuhë objektive në bazat e drurit të gjuhës së burimit; 3) një metodë për integrimin e këtyre hapave me metodën e projektimit të anotacionit të Rasullit dhe Kollinsit (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work.  Rezultatet e përdorimit të Europarl corpus si burim i të dhënave të përkthimit tregojnë përmirësime shtesë lidhur me rezultatet e Rasoolit dhe Kollinsit (2015). Ne përfundojmë me rezultate në 38 grupe të dhënash nga korpora e Dependencës Universale.', 'af': "Ons beskrywe 'n eenvoudige maar effektief metode vir kruistale sintakteel oordrag van afhanklikheidverwerkers, in die scenario waar 'n groot hoeveelheid vertaling data nie beskikbaar is nie. Hierdie metode maak gebruik van drie stappe: 1) â\x80\x99n metode vir die afgelei van kruistale woord clusters, wat dan kan gebruik word in â\x80\x99n veelvuldige analyseer; 2) â\x80\x99n metode vir oordra van leksiese inligting van â\x80\x99n doel taal na bron taal trebalke; 2) â\x80\x99n metode 3) â\x80\x99n metode vir hierdie stappe integreer met die densiteit gedrywe annotasie projeksie metode van Rasooli en Collins (2015). Eksperimente vertoon verbeteringe oor die staat van die kuns in verskeie tale wat in vorige werk gebruik word, in 'n opstelling waar die enigste bron van vertaling data is die Bibel, 'n aansienlik kleiner korpus as die Europarliese korpus wat in vorige werk gebruik word. Resultate gebruik die Europarl corpus as 'n bron van vertaling data wys addisionele verbeteringe oor die resultate van Rasooli en Collins (2015). Ons sluit met resultate op 38 datastelle van die Universele Afhanklikheid Korpora.", 'tr': 'Biz çykyş dilinde baglanylyk tansçylaryň üstine basit ýöne etkinlik bir yöntemi, senaryda birnäçe terjime maglumaty bar. Bu yöntem üç adımdan ullanýar: 1) çarpaz dilli kelime kluplaryny çykarmak üçin bir yöntem, ondan soňra bir multi dilli tansçylarda ullanýar; 2) Maksad dilden meksika maglumaty çubuqlara geçirmek üçin bir yöntem;  3) Rasooli we Collins (2015). Ýyllaşmalar öňki işde ullanýan birnäçe dillerde, Bibliýanyň diňe çeviri maglumatynyň çeşmesi bolan ýerde, Europarl korpusundan has kiçi korpusy görýär. Netijeler Europarl korpusyny özüniň terjime maglumatynyň çeşmesi bolan ýagdaýynda Rasooli we Collins (2015) netijeleriniň üstüne gelişmelerini görkez. Munus Uniwersaly Baýumlyklar Korporatynyň 38 sany maglumatyň netijesi bilen çykypdyk.', 'hy': 'Մենք նկարագրում ենք պարզ, բայց արդյունավետ մեթոդը կախվածության վերլուծողների փոխլեզվով սինտակտիկ փոխանցման համար, այն սցենարիայում, որտեղ շատ թարգմանման տվյալներ հասանելի չեն: Այս մեթոդը օգտագործում է երեք քայլ. 1) միջլեզվային բառերի խմբերի ստեղծման մեթոդ, որը հետո կարող է օգտագործվել բազլեզվային վերլուծում: 2) լեքսիկական ինֆորմացիայի փոխանցման մեթոդը նպատակային լեզվից աղբյուր լեզվի ծառերի վրա: 3) այս քայլերը ինտեգրելու մեթոդը Ռազուլի և Կոլինսի խտությունից հիմնված նոտացիայի պրոեկցիոն մեթոդի հետ (2015 թ): Փորձարկումները ցույց են տալիս բարելավումներ առաջին աշխատանքի ժամանակ օգտագործվող տարբեր լեզուներում, մի միջավայրում, որտեղ թարգմանման տվյալների միակ աղբյուրն է Աստվածառը, որը շատ ավելի փոքր մարմին է, քան նախորդ աշխատանքի ժամանակ օգտագործված Եվորլա մարմինը: Արդյունքները, որոնք օգտագործում են Եվրոպալ կորպուսը որպես թարգմանման տվյալների աղբյուր, ցույց են տալիս ավելին բարելավումներ Ռազուլի և Կոլինսի (2015) արդյունքների վերաբերյալ: Մենք եզրակացնում ենք համաշխարհային կախվածությունների մարմնի 38 տվյալների արդյունքներով:', 'bn': 'আমরা একটি সহজ কিন্তু কার্যকর পদ্ধতি বর্ণনা করি যেখানে অনুবাদের বিশাল পরিমাণ তথ্য পাওয়া যাচ্ছে না। এই পদ্ধতি তিনটি পদক্ষেপ ব্যবহার করে: ১) ক্রাশ-ভাষাভাষী শব্দ ক্লাস্টার প্রদানের একটি পদ্ধতি, যা তারপর বহুভাষী প্যারেজারে ব্যবহ 2) a method for transferring lexical information from a target language to source language treebanks;  ৩) রাসুলি এবং কলিন্স (২০১৫) এর গুরুত্বপূর্ণ পরিচালনা প্রক্রিয়ার মাধ্যমে এই পদক্ষেপ একত্রিত করার একটি পদ্ধতি। পূর্ববর্তী কাজে ব্যবহৃত বেশ কয়েকটি ভাষায় পরীক্ষা প্রদর্শন করা হয়েছে যেখানে অনুবাদের তথ্যের একমাত্র উৎস হচ্ছে বাইবেল, যা আগের কাজে ব্যবহৃত ইউরোপার্ল কো ইউরোপার্ল কোর্পাস ব্যবহার করে অনুবাদের তথ্যের উৎস হিসেবে ব্যবহার করা ফলাফল রাসুলি এবং কলিনিস (২০১৫) এর ফলাফলের বিষয়ে আরো উন্নতি  আমরা বিশ্ববিদ্যালয়ের নির্ভর কর্পোরা থেকে ৩৮ টি ডাটাসেটের ফলাফল সমাপ্তি করেছি।', 'am': 'We describe a simple but effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where a large amount of translation data is not available.  ይህም ሥርዓት ሦስት ደረጃዎች ይጠቅማል፤ 1) የቋንቋ ቃላት ጉንኙነቶችን ለማግኘት ማድረግ ነው፣ በዚህም ጊዜ በብዙ ቋንቋ ተለይቶ ይጠቀማል; 2) ሌክሲካዊ መረጃን ከምዕራብ ቋንቋ ወደ ቋንቋ ምዕራፍ ለመለወጥ method; 3) እነዚህን እርምጃዎች በጭንቀት የራሶሊ እና ኮሌንስ (2015) የመቀላቀል ድርጅት ለመቀላቀል ነው፡፡ ፈተናዎች የቀድሞው ሥራ ውስጥ በተጠቃሚ ቋንቋዎች የፀሐይ አካባቢ ቋንቋዎች ላይ የተጠቃሚ ክፍተቶችን ያሳያል፡፡ የዩሮፓርል ኮርፓስ (2015) የረሱል እና ኮሊኖስ ውጤቶች ላይ የተጨማሪውን ክፍተት ያሳያል፡፡ በ38 የዓለማዊ ድጋፍ ካርፓር ውስጥ የዳታ ሰርቨሮች ፍሬዎችን እናቆማለን፡፡', 'az': 'Biz çox böyük dəyişiklik məlumatların faydalanmadığı scenariyada, çox dilli sintaktik istifadəçilərin istifadə edilməsi üçün asanlıq, ancaq etkili bir yolu təsdiqləyirik. Bu metod üç adımdan istifadə edir: 1) çoxlu dil ayırıcılıqda istifadə edilə bilən çoxlu sözlər klasterlərini çıxartmaq üçün bir metod. 2) məqsəd dilindən leksik məlumatları mənbə dil çubuqlarına göndərmək üçün bir yolu; 3) bu adımları Rasooli və Collins (2015-ci ildə) yoğunluğu ilə birləşdirmək metodu. Həyatlar əvvəlki işdə istifadə edilən çoxlu dillərdə, təkrarlama məlumatının tək mənbəsi Bibliyadır, əvvəlki işdə istifadə edilən Europarl korpusundan çox kiçik korpus göstərir. Europarl korpusu tərcümə məlumatının mənbəsi olaraq istifadə etdiyi sonuçlar Rasooli və Collins (2015) sonuçlarının üstündə daha yaxşılıqlarını göstərir. Biz Universal Dependencies corpora tərəfindən 38 verilən qurğu ilə sonuçlarını çəkirik.', 'ca': "Descrivem un mètode senzill però efectiu per a la transfer ència sinàctica translingüística de analitzadors de dependencies, en l'escenari on no hi ha gran quantitat de dades de traducció disponibles. Aquest mètode fa servir tres etapes: 1) un mètode per derivar grups de paraules translingües, que després es pot utilitzar en un analitzador multilingüe; 2) un mètode de transferència de la informació lècsica d'un llenguatge de destinació a les barres d'arbres del llenguatge d'origen; 3) un mètode per integrar aquestes etapes amb el mètode de projecció d'anotació basat en la densitat de Rasooli i Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work.  Els resultats que utilitzen el corpus Europarl com una font de dades de traducció mostren millors adicionals sobre els resultats de Rasooli i Collins (2015). Conclouem amb resultats de 38 conjunts de dades de la corpora Universal Dependencies.", 'cs': 'Popisujeme jednoduchou, ale efektivní metodu pro cross-jazyčný syntaktický přenos závislostních parserů, ve scénáři, kdy není k dispozici velké množství překladových dat. Tato metoda využívá tří kroků: 1) metoda pro odvození vícejazyčných slovních clusterů, které pak lze použít ve vícejazyčném parseru; 2) metoda přenosu lexikálních informací z cílového jazyka do stromových bank zdrojového jazyka; 3) metoda integrace těchto kroků s metodou anotace řízenou hustotou Rasooli a Collins (2015). Experimenty ukazují zlepšení oproti modernímu stavu v několika jazycích používaných v předchozí práci, v prostředí, kde jediným zdrojem překladových dat je Bible, podstatně menší korpus než Europarl korpus používaný v předchozí práci. Výsledky využití korpusu Europarl jako zdroje překladových dat ukazují další zlepšení oproti výsledkům Rasooli a Collinsových (2015). Závěrem jsou výsledky 38 datových sad z korpusů Universal Dependencies.', 'bs': 'Mi opisujemo jednostavan, ali efikasan metod za cross-lingual syntactic transfer of dependency parsers, u scenariju gdje nije dostupna velika količin a prevodnih podataka. Ova metoda koristi tri koraka: 1) metodu za izvlačenje krstojezičkih skupina riječi, koja se onda može koristiti u multijezičkom analizatoru; 2) metodu prebacivanja leksičkih informacija sa ciljnog jezika na izvorne jezičke trgovine; 3) metod integracije tih koraka sa metodom projektacije za proglašenje s gustoćom izraženom annotacijom Rasooli i Collins (2015). Eksperimenti pokazuju poboljšanje stanja umjetnosti na nekoliko jezika korištenih na prethodnom radu, u stanju gdje je Biblija jedini izvor prevodnih podataka, značajno manji korpus od korpusa Europarl a korpusa korištenog u prethodnom radu. Rezultati korpusa Europarl a kao izvor prevodnih podataka pokazuju dodatne poboljšanja rezultata Rasooli i Collins (2015). Završili smo sa rezultatima na 38 podataka iz Univerzalne zavisnosti korpore.', 'et': 'Kirjeldame lihtsat, kuid efektiivset meetodit sõltuvuspartserite keeleüleseks süntaktiliseks ülekandmiseks stsenaariumis, kus suur hulk tõlkeandmeid ei ole kättesaadav. Selles meetodis kasutatakse kolme etappi: 1) keeleüleste sõnaklastrite tuletamise meetodit, mida saab seejärel kasutada mitmekeelses parseris; 2) leksikaalse teabe sihtkeelest lähtekeele puupankadele ülekandmise meetod; 3) meetod nende etappide integreerimiseks Rasooli ja Collinsi (2015) tiheduspõhise annotatsiooniprojektsiooni meetodiga. Eksperimentid näitavad, et mitmes varasemas töös kasutatud keeles on edusamme võrreldes tehnika tasemega, kus ainus tõlkeandmete allikas on Piibel, mis on oluliselt väiksem korpus kui varasemates töös kasutatud Europarl korpus. Europarl korpuse kasutamise tulemused tõlkeandmete allikana näitavad täiendavat paranemist võrreldes Rasooli ja Collinsi (2015) tulemustega. Lõpetame tulemustega 38 andmekogumi kohta Universaalsete sõltuvuste korpustest.', 'fi': 'Kuvaamme yksinkertaisen, mutta tehokkaan menetelmän riippuvuuden jäsentäjien monikieliseen syntaktiseen siirtoon skenaariossa, jossa suuri määrä käännöstietoa ei ole saatavilla. Menetelmässä käytetään kolmea vaihetta: 1) monikielisten sanaklusterien johtamisen menetelmä, jota voidaan käyttää monikielisessä jäsentäjässä; 2) menetelmä sanaston tiedon siirtämiseksi kohdekieleltä lähdekielen puupankkeihin; 3) menetelmä näiden vaiheiden integroimiseksi Rasoolin ja Collinsin (2015) tiheyspohjaiseen annotointimenetelmään. Kokeet osoittavat parannuksia nykytekniikkaan verrattuna useilla aikaisemmissa teoksissa käytetyillä kielillä tilanteessa, jossa ainoa käännöstiedon lähde on Raamattu, huomattavasti pienempi korpus kuin aikaisemmissa teoksissa käytetty Europarl-korpus. Tulokset, joissa Europarl-korpusta käytetään käännöstietojen lähteenä, osoittavat parannuksia Rasoolin ja Collinsin (2015) tuloksiin verrattuna. Päätämme tulokset 38 aineistosta Universaaliset riippuvuudet -korpusista.', 'jv': 'Where am I This method make use of 3 pages: 1) a method for removing interlanguage word clusters, that can be used in a multilanguage browser; and 2) singular 3) a method for embeding this phase with the Density-drived anntation proction method of Rastool and Colin (2013). Isopo sing menehi nglanggar langkung banjur-kanggo ngerasakno karo hal-karat kanggo langga sing nyimpen ning cara sing rangke nggawe gerakan kanggo ngerasakno dadi nyong ora bisa perusahaan karo Biblet, akeh langgar sampeyan mrupu sing gawe nguasakno ning cara-kono sing dumadhi uwong Pametuné nggawe cending oleh dumadhakan karo soko perusahaan dumadhakan data anyar supoyo bukané supoyo barang Rastool karo Colin (2013). Awak dhéwé wis beraksi lan gambaran dengané data sing wis numpak ning cara-cara Universal.', 'ha': "Tuna bayyana wani hanyoyi mai sauƙi kuma mai amfani wa transfer da mai haɗiya cikin harshen-ƙunci na daban-harshen, a cikin fasarin da ko yawa ba za'a iya sãmun data na fassarar ba. Wannan hanyor yana amfani da hanyõyi uku: 1) wata hanyo'a ga ta motta danganta lugha-fassara, wanda za'a iya yi amfani da shi a cikin fassarar multilingular;  2) a method for transferring lexical information from a target language to source language treebanks;  3) Methanci na haɗa waɗannan hanyõyin da shiryarwa mai cire-nau'i na Rasooli da Collins (2015). Hajararin na nuna improvements over the state-the-art in several languages used in previous aikin, in a settings where the only source of translation data is the Bible, a significant ƙaranci makarato mafi ƙaranci daga the Euraparl Corbas used in previous aikin. Result uses the EURparl Corbas as source of translation data show addive improvements over the fassarar Rasooli and Collins (2015). Tuna ƙarshe da matsala na mutane 38 daga Companiya Universal Deputies.", 'sk': 'Opisujemo preprosto, a učinkovito metodo za medjezični sintaktični prenos razčlenjevalnikov odvisnosti v scenariju, kjer velika količina podatkov o prevodu ni na voljo. Ta metoda uporablja tri korake: 1) metodo za izpeljavo večjezičnih besednih skupin, ki se nato lahko uporabljajo v večjezičnem razčlenjevalniku; 2) metodo prenosa leksikalnih informacij iz ciljnega jezika na drevesne zbirke izvornega jezika; 3) metoda za integracijo teh korakov z metodo projekcije označevanja gostote Rasooli in Collins (2015). Eksperimenti kažejo izboljšave v primerjavi z najsodobnejšimi jeziki v več jezikih, uporabljenih v prejšnjih delih, v okolju, kjer je edini vir podatkov o prevajanju Sveto pismo, bistveno manjši korpus od korpusa Europarl, uporabljenega v prejšnjih delih. Rezultati, ki uporabljajo korpus Europarl kot vir podatkov o prevajanju, kažejo dodatne izboljšave v primerjavi z rezultati Rasooli in Collins (2015). Zaključimo z rezultati 38 naborov podatkov iz korpusov Univerzalne odvisnosti.', 'he': 'אנחנו מתארים שיטה פשוטה אך יעילה להעברה סינטקטית בין שפות של מחקרי תלויות, בתרחיש שבו כמות גדולה של נתוני תרגום לא זמינים. השיטה הזאת משתמשת בשלושה צעדים: 1) שיטה להוציא קבוצות מילים דרך שפתיים, אשר אפשר להשתמש בהעבדה רבת שפתיים; 2) שיטה להעברת מידע לקסיקלי משפה המטרה לבנקי עץ לשפה המקורית; 3) שיטה להשתלב את השלבים האלה עם שיטת פרויקציה של ציונים מונעת על צפיפות של ראסולי וקולינס (2015). הניסויים מראים שיפורים על המצב המאודן בכמה שפות ששותמשות בעבודה הקודמת, במצב שבו המקור היחיד של נתוני התרגום הוא התנ"ך, קורפוס הרבה יותר קטן מאשר קורפוס האירופרל השתמש בעבודה הקודמת. התוצאות בשימוש בקורפוס Europarl כמקור של נתוני תרגום מראות שיפורים נוספים על התוצאות של Rasooli וקולינס (2015). אנחנו מסתיימים עם תוצאות על 38 קבוצות נתונים מהגופורה של התמכויות היניברסליות.', 'bo': 'ང་ཚོས་སྐད་ཡིག་ཆ་གསལ་ཅན་གྱི་ཆ་འཕྲིན་འགྲེལ་བཤད་ཀྱི་ཐབས་ལམ་ཞིག་གསལ་བཤད་བྱེད་ཀྱི་ཡོད། This method makes use of three steps: 1) a method for deriving cross-lingual word clusters, which can then be used in a multilingual parser; for example 2) དམིགས་ཡུལ་ཡིག་གི་སྐད་ཡིག་དང་ཐོག་མའི་སྐད་རིགས་གནས་ཚུལ་སྐྱེལ་འདྲེན་བྱེད་ཀྱི་ཐབས་ལམ། 3) ལམ་ལུགས་འདི་དག་གི་density-driven annotation projection method of Rasooli and Collins (2015)དང་མཉམ་དུ་བསྡུར་ཐབས་ཤིག་རེད། Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. གྲུབ་འབྲས་གཞུང་སྤྱི་ཚོགས་ཁང་གི་དབུགས་འབྲེལ་མཐུད་དེ་རང་ཉིད་ཀྱི་རྐྱེན་སྒྲིག་ཆ་གསལ་བཤད་ཀྱི་མཐུན་རྐྱེན་ཚད་ལ་ཡར་རྒྱ ང་ཚོས་རྗེས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་ཁང་གི་དབུགས་རྩིས་ཐོག་མཛོད་ཀྱི་གནད་སྡུད་ཞབས་ཡོད་38'}
{'en': 'Overcoming Language Variation in Sentiment Analysis with Social Attention', 'ar': 'التغلب على تباين اللغة في تحليل المشاعر بالاهتمام الاجتماعي', 'fr': "Surmonter les variations linguistiques dans l'analyse des sentiments grâce à l'attention", 'pt': 'Superando a Variação Linguística na Análise de Sentimentos com Atenção Social', 'es': 'Superar la variación lingüística en el análisis de sentimientos con atención social', 'ja': 'センチメント分析における言語変動を克服し、社会的な注意を払う', 'ru': 'Преодоление языковых вариаций в анализе настроений с социальным вниманием', 'zh': '以世情析言异', 'hi': 'सामाजिक ध्यान के साथ भावना विश्लेषण में भाषा भिन्नता पर काबू पाने', 'ga': 'Éagsúlacht Teanga san Anailís Mothúchán a Shárú le Aird Shóisialta', 'ka': 'საზოგადო ანალიზაციის გარეშე ენის გარეშე', 'el': 'Υπερνικώντας την γλωσσική διακύμανση στην ανάλυση συναισθημάτων με κοινωνική προσοχή', 'hu': 'A nyelvi variáció leküzdése az érzelmek elemzésében társadalmi figyelemmel', 'it': "Superare la variazione linguistica nell'analisi dei sentimenti con attenzione sociale", 'lt': 'Kalbos pokyčių įveikimas jautrumo analizėje su socialiniu dėmesiu', 'kk': 'Келесі тіл айнымалылығы жалпы қатынас арқылы Sentiment Analysis', 'mk': 'Преминување на разликата на јазикот во анализата на чувствата со социјално внимание', 'ms': 'Overcoming Language Variation in Sentiment Analysis with Social Attention', 'mn': 'Холбооны хувьсгал, сэтгэл санааны шинжилгээнд нийгмийн анхаарлын тухай', 'ml': 'സാമൂഹിക ശ്രദ്ധയോടൊപ്പം സെന്റിമെന്റ് അന്വേഷണത്തില്\u200d വരുന്ന ഭാഷ മാറ്റങ്ങള്\u200d', 'mt': 'Għeluq tal-Varjazzjoni Lingwistika fl-Analiżi tas-Sentimenti b’Attenzjoni Soċjali', 'pl': 'Przezwyciężanie zmian językowych w analizie sentymentów z uwagą społeczną', 'ro': 'Depășirea variației limbajului în analiza sentimentelor cu atenție socială', 'no': 'Overkommende språk- variasjon i sentralanalysen med sosiale merking', 'sr': 'Prevladavajuća jezička varijacija u analizi sentimenta sa socijalnom pažnjom', 'si': 'සාමාජික අවධානය සඳහා භාෂාව වෙනස් විශ්ලේෂණයෙන් ප්\u200dරවර්තනය කරන්න', 'sv': 'Att övervinna språkvariationer i känsloanalys med social uppmärksamhet', 'ta': 'சமூக கவனத்துடன் வரும் மொழி மாறிகள்', 'so': 'Isku badalka luqada soo socda ee ku saabsan baaritaanka shahaadada ee arrimaha bulshada', 'ur': 'سنٹیمینٹ تحلیل میں زبان متغیر کے ساتھ اجتماعی حفاظت کے ساتھ', 'uz': 'Name', 'vi': 'Vượt qua sự thay đổi ngôn ngữ trong phiên bản phân tích', 'bg': 'Преодоляване на езиковите вариации в анализа на сентимента със социално внимание', 'nl': 'Taalvariatie overwinnen in sentimentanalyse met sociale aandacht', 'da': 'Overvinde sprogvariation i følelsesanalyse med social opmærksomhed', 'hr': 'Prevladavajuća varijacija jezika u analizi poslednjeg trenutka s društvenom pažnjom', 'de': 'Überwindung von Sprachschwankungen in der Stimmungsanalyse mit sozialer Aufmerksamkeit', 'id': 'Mengatasi Variasi Bahasa dalam Analisi Sentiment dengan Perhatian Sosial', 'ko': '사회적 관심으로 정서 분석 중의 언어 변이를 극복하다', 'fa': 'تغییرات زبانی در تحلیل مجموعه با توجه اجتماعی', 'sw': 'Mabadiliko ya lugha inayokuja katika uchambuzi wa Wakati na Tazama za Kijamii', 'af': 'Oorvankende taal verandering in Sentiment Analysis met sosiale aandag', 'tr': 'Sentiment Taýdaly bilen Ullanyş Dil üýtgeşmeleri', 'sq': 'Duke kapërcyer variacionin e gjuhës në analizën e ndjenjave me vëmendje sociale', 'am': 'ቋንቋ አቀማመጥ', 'bn': 'সামাজিক মনোযোগ দিয়ে সেন্টাইমেন্ট বিশ্লেষণের ভাষার বিভাগ', 'bs': 'Prevladavajuća varijacija jezika u analizi sentimenta sa socijalnom pažnjom', 'ca': "superar la variació de llenguatge en l'anàlisi del sentiment amb atenció social", 'cs': 'Překonání jazykových variací v analýze sentimentů se sociální pozorností', 'az': 'Cənnətləşdirilmiş Sözümlü Analizi ilə Cənnətləşdirilmiş Dil dəyişikliği', 'hy': 'Սոցիալական ուշադրություն դարձնելով զգացմունքների վերլուծության լեզվի տարբերությունը հաղթահարելը', 'fi': 'Tunteanalyysin kielivaihtelun voittaminen sosiaalisen huomion avulla', 'et': 'Keele variatsiooni ületamine tunnete analüüsis sotsiaalse tähelepanuga', 'jv': 'text-editor-action', 'ha': 'KCharselect unicode block name', 'he': 'התגבר על שינוי שפה באנליזה רגשות עם תשומת לב חברתית', 'sk': 'Premaganje jezikovnih variacij v analizi sentimenta s socialno pozornostjo', 'bo': 'སྤྱི་ཚོགས་རྣམས་ལ་ཆེན་དུ་ཚོར་བའི་སྐད་ཡིག་གཟུགས་འགྱུར་རྒྱུན་ལྡན་མ་རེད།'}
{'en': 'Variation in language is ubiquitous, particularly in newer forms of writing such as social media. Fortunately, variation is not random ; it is often linked to social properties of the author. In this paper, we show how to exploit social networks to make sentiment analysis more robust to social language variation. The key idea is linguistic homophily : the tendency of socially linked individuals to use language in similar ways. We formalize this idea in a novel attention-based neural network architecture, in which attention is divided among several basis models, depending on the author’s position in the social network. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata. This model significantly improves the accuracies of sentiment analysis on Twitter and on review data.', 'ar': 'الاختلاف في اللغة موجود في كل مكان ، لا سيما في أشكال الكتابة الحديثة مثل وسائل التواصل الاجتماعي. لحسن الحظ ، فإن التباين ليس عشوائياً. غالبًا ما يرتبط بالخصائص الاجتماعية للمؤلف. في هذه الورقة ، نوضح كيفية استغلال الشبكات الاجتماعية لجعل تحليل المشاعر أكثر قوة لتنوع اللغة الاجتماعية. الفكرة الأساسية هي اللواط اللغوي: ميل الأفراد المرتبطين اجتماعياً إلى استخدام اللغة بطرق مماثلة. نقوم بإضفاء الطابع الرسمي على هذه الفكرة في بنية شبكة عصبية جديدة قائمة على الانتباه ، حيث يتم تقسيم الانتباه بين عدة نماذج أساسية ، اعتمادًا على موقع المؤلف في الشبكة الاجتماعية. هذا له تأثير على تبسيط وظيفة التصنيف عبر الشبكة الاجتماعية ، ويجعل من الممكن حث المصنفات الشخصية حتى بالنسبة للمؤلفين الذين لا توجد بيانات مصنفة أو بيانات وصفية ديموغرافية عنهم. يعمل هذا النموذج على تحسين دقة تحليل المشاعر على تويتر وبيانات المراجعة بشكل كبير.', 'pt': 'A variação na linguagem é onipresente, particularmente em novas formas de escrita, como as mídias sociais. Felizmente, a variação não é aleatória; muitas vezes está ligada a propriedades sociais do autor. Neste artigo, mostramos como explorar as redes sociais para tornar a análise de sentimentos mais robusta à variação da linguagem social. A ideia-chave é a homofilia linguística: a tendência de indivíduos socialmente ligados a usar a linguagem de maneiras semelhantes. Formalizamos essa ideia em uma nova arquitetura de rede neural baseada em atenção, na qual a atenção é dividida entre vários modelos de base, dependendo da posição do autor na rede social. Isso tem o efeito de suavizar a função de classificação em toda a rede social e possibilita a indução de classificadores personalizados mesmo para autores para os quais não há dados rotulados ou metadados demográficos. Esse modelo melhora significativamente a precisão da análise de sentimentos no Twitter e nos dados de revisão.', 'es': 'La variación en el lenguaje es omnipresente, particularmente en las formas más nuevas de escritura, como las redes sociales. Afortunadamente, la variación no es aleatoria; a menudo está vinculada a las propiedades sociales del autor. En este artículo, mostramos cómo explotar las redes sociales para hacer que el análisis de sentimientos sea más sólido para la variación del lenguaje social. La idea clave es la homofilia lingüística: la tendencia de las personas socialmente vinculadas a utilizar el idioma de manera similar. Formalizamos esta idea en una novedosa arquitectura de red neuronal basada en la atención, en la que la atención se divide entre varios modelos básicos, según la posición del autor en la red social. Esto tiene el efecto de suavizar la función de clasificación en toda la red social y permite inducir clasificadores personalizados incluso para los autores para los que no hay datos etiquetados o metadatos demográficos. Este modelo mejora significativamente la precisión del análisis de opiniones en Twitter y en los datos de reseñas.', 'fr': "Les variations linguistiques sont omniprésentes, en particulier dans les nouvelles formes d'écriture telles que les réseaux sociaux. Heureusement, la variation n'est pas aléatoire\xa0; elle est souvent liée aux propriétés sociales de l'auteur. Dans cet article, nous montrons comment exploiter les réseaux sociaux pour rendre l'analyse des sentiments plus robuste face aux variations du langage social. L'idée clé est l'homophilie linguistique\xa0: la tendance des personnes socialement liées à utiliser le langage de manière similaire. Nous formalisons cette idée dans une nouvelle architecture de réseau de neurones basée sur l'attention, dans laquelle l'attention est répartie entre plusieurs modèles de base, en fonction de la position de l'auteur dans le réseau social. Cela a pour effet de lisser la fonction de classification sur le réseau social et permet d'induire des classificateurs personnalisés même pour les auteurs pour lesquels il n'existe pas de données étiquetées ou de métadonnées démographiques. Ce modèle améliore considérablement la précision de l'analyse des sentiments sur Twitter et sur les données d'avis.", 'ja': '言語のバリエーションは、特にソーシャルメディアなどのより新しい書き方で普遍的に見られます。幸いなことに、バリエーションはランダムではありません。それはしばしば著者の社会的特性と結びついています。この論文では、社会的ネットワークを活用して、感情分析を社会的言語の変動に対してより堅牢にする方法を示します。鍵となるアイデアは、言語的同質性である。つまり、社会的に結びついた個人が同様の方法で言語を使用する傾向である。このアイデアを、ソーシャルネットワークにおける著者の立場に応じて、いくつかのベースモデル間で注目が分かれる、斬新な注目ベースのニューラルネットワークアーキテクチャで形式化しています。これは、ソーシャルネットワーク全体で分類機能をスムーズにする効果があり、ラベル付けされたデータや人口統計メタデータがない著者であっても、パーソナライズされた分類子を誘導することが可能である。このモデルは、Twitterやレビューデータ上の感情分析の精度を大幅に向上させます。', 'ru': 'Различия в языке широко распространены, особенно в более новых формах письменности, таких как социальные сети. К счастью, вариация не случайна; она часто связана с социальными свойствами автора. В этой статье мы показываем, как использовать социальные сети, чтобы сделать анализ настроений более устойчивым к социальным языковым вариациям. Ключевая идея - лингвистическая гомофилия: склонность социально связанных индивидуумов использовать язык аналогичным образом. Мы формализуем эту идею в новой архитектуре нейронной сети, основанной на внимании, в которой внимание разделено между несколькими базовыми моделями, в зависимости от позиции автора в социальной сети. Это приводит к сглаживанию функции классификации в социальной сети и позволяет создавать персонализированные классификаторы даже для авторов, для которых нет маркированных данных или демографических метаданных. Эта модель значительно повышает точность анализа настроений в Twitter и данных обзора.', 'zh': '言语之变,无所不在,特于社交媒体等新文。 幸也,变化非随机也。 常与世财产相关。 本文何以用社交网络析情更健。 心者,言同质性:世个体以类用言也。 一新之神经网络架构,正式化此心也;一架构之中,分为数基,在于社交网络位。 此有社交网络平滑分类之效,虽无标数、人口计元数者,亦可诱个性化分器也。 形模显著 Twitter 与论数情析准确性。', 'hi': 'भाषा में भिन्नता सर्वव्यापी है, विशेष रूप से सोशल मीडिया जैसे लेखन के नए रूपों में। सौभाग्य से, भिन्नता यादृच्छिक नहीं है; यह अक्सर लेखक के सामाजिक गुणों से जुड़ा हुआ है। इस पेपर में, हम दिखाते हैं कि सामाजिक भाषा भिन्नता के लिए भावना विश्लेषण को और अधिक मजबूत बनाने के लिए सामाजिक नेटवर्क का शोषण कैसे किया जाए। मुख्य विचार भाषाई होमोफिली है: सामाजिक रूप से जुड़े व्यक्तियों की प्रवृत्ति समान तरीकों से भाषा का उपयोग करने के लिए। हम इस विचार को एक उपन्यास ध्यान-आधारित तंत्रिका नेटवर्क वास्तुकला में औपचारिक रूप देते हैं, जिसमें सामाजिक नेटवर्क में लेखक की स्थिति के आधार पर ध्यान को कई आधार मॉडलों के बीच विभाजित किया जाता है। यह सामाजिक नेटवर्क में वर्गीकरण समारोह को चिकना करने का प्रभाव डालता है, और उन लेखकों के लिए भी व्यक्तिगत क्लासिफायरको प्रेरित करना संभव बनाता है जिनके लिए कोई लेबल डेटा या जनसांख्यिकीय मेटाडेटा नहीं है। यह मॉडल ट्विटर पर और समीक्षा डेटा पर भावना विश्लेषण की सटीकता में काफी सुधार करता है।', 'ga': 'Tá éagsúlacht teanga uileláithreach, go háirithe i bhfoirmeacha scríbhneoireachta níos nuaí mar na meáin shóisialta. Fortunately, nach bhfuil éagsúlacht randamach; tá sé nasctha go minic le hairíonna sóisialta an údair. Sa pháipéar seo, léirímid conas leas a bhaint as líonraí sóisialta chun anailís dhearcadh a dhéanamh níos láidre ar éagsúlacht teanga shóisialta. Is é an príomh-smaoineamh ná homafilí teanga: an claonadh atá ag daoine atá nasctha go sóisialta teanga a úsáid ar bhealaí comhchosúla. Déanaimid an smaoineamh seo ar bhonn foirmiúil in ailtireacht líonra néarúil úrnua aird-bhunaithe, ina roinntear aird i measc múnlaí bonn éagsúla, ag brath ar sheasamh an údair sa líonra sóisialta. Is é an éifeacht atá aige seo ná an fheidhm aicmithe a rianú ar fud an líonra shóisialta, agus is féidir aicmitheoirí pearsantaithe a aslú fiú amháin i gcás údair nach bhfuil aon sonraí lipéadaithe nó meiteashonraí déimeagrafacha ann dóibh. Cuireann an tsamhail seo feabhas suntasach ar chruinneas na hanailíse meoin ar Twitter agus ar shonraí athbhreithnithe.', 'hu': 'A nyelvváltozások mindenütt jelen vannak, különösen az újabb írási formákban, mint például a közösségi médiában. Szerencsére a változás nem véletlenszerű; Gyakran kapcsolódik a szerző társadalmi tulajdonságaihoz. Ebben a tanulmányban bemutatjuk, hogyan lehet a közösségi hálózatokat kihasználni annak érdekében, hogy az érzelmek elemzése erőteljesebb legyen a közösségi nyelvi variációkhoz. A legfontosabb elképzelés a nyelvi homofilia: a társadalmilag összefüggő egyének azon tendenciája, hogy hasonló módon használják a nyelvet. Ezt az ötletet egy új figyelem-alapú neurális hálózati architektúrában formalizáljuk, amelyben a figyelmet több alapmodell között osztjuk meg, a szerző helyzetétől függően a közösségi hálózatban. Ez azt eredményezi, hogy a besorolási funkciót simítja a közösségi hálózaton, és lehetővé teszi, hogy személyre szabott osztályozókat indítsanak még azon szerzők számára is, akik számára nincsenek címkézett adatok vagy demográfiai metaadatok. Ez a modell jelentősen javítja az érzelmek elemzésének pontosságát a Twitteren és a felülvizsgálati adatokon.', 'el': 'Οι παραλλαγές στη γλώσσα είναι πανταχού παρούσες, ιδιαίτερα σε νεότερες μορφές γραφής, όπως τα μέσα κοινωνικής δικτύωσης. Ευτυχώς, η διακύμανση δεν είναι τυχαία. συνδέεται συχνά με τις κοινωνικές ιδιότητες του συγγραφέα. Σε αυτή την εργασία, παρουσιάζουμε πώς να εκμεταλλευτούμε τα κοινωνικά δίκτυα για να κάνουμε την ανάλυση συναισθημάτων πιο ισχυρή στην κοινωνική γλωσσική διακύμανση. Η βασική ιδέα είναι η γλωσσική ομοφιλία: η τάση των κοινωνικά συνδεδεμένων ατόμων να χρησιμοποιούν τη γλώσσα με παρόμοιους τρόπους. Τυποποιούμε αυτή την ιδέα σε μια νέα αρχιτεκτονική νευρωνικών δικτύων βασισμένη στην προσοχή, στην οποία η προσοχή χωρίζεται σε διάφορα μοντέλα βάσης, ανάλογα με τη θέση του συγγραφέα στο κοινωνικό δίκτυο. Αυτό έχει ως αποτέλεσμα την εξομάλυνση της λειτουργίας ταξινόμησης σε όλο το κοινωνικό δίκτυο, και καθιστά δυνατή την πρόκληση εξατομικευμένων ταξινομητών ακόμη και για συγγραφείς για τους οποίους δεν υπάρχουν επισημασμένα δεδομένα ή δημογραφικά μεταδεδομένα. Αυτό το μοντέλο βελτιώνει σημαντικά την ακρίβεια της ανάλυσης συναισθημάτων στο Twitter και στα δεδομένα αξιολόγησης.', 'ka': 'ენაში განსხვავება არსებობს, განსაკუთრებით ახალი წერის ფორმებში, როგორც სოციალური მედია. უკეთესიდ, განრავლობა არ არის შემთხვევაში; ეს სოციალური განსაზღვრებით ავტორის სოციალური განსაზღვრებით დაკავშირებულია. ჩვენ ჩვენ აჩვენებთ, როგორ სოციალური ქსელების გამოყენება, რომ სენტიმენტების ანალიზაციას სოციალური ენის განსაცემებისთვის უფრო ძალიან გარ მნიშვნელოვანი იდეა ლენდომისტიკური ჰომოფილია: სოციალურად დაკავშირებული ადამიანების რენდენცია, რომელიც ენერგიის გამოყენება სხვადასხვა გზებით. ჩვენ ამ იდეას პრომენტურად აღმოჩენებთ ნეიროლური ქსელის აქტიქტიქტურაში, რომელიც აღმოჩენება რამდენიმე ბაზის მოდელში გაყოფილი, რომელიც სოციალური ქსელის სოციალური მ ეს აქვს კლასიფიკაციის ფუნქცია სოციალური ქსელის გარეშე და შეუძლებელია პორციალურად კლასიფიკაციული კლასიფიკაციების შესაძლებლობა, რომლებიც არ აქვს მართლა ან დემოგრაფიკური მეტატ ამ მოდელს ძალიან უფრო მნიშვნელოვანია ტვირუტერის სენტიმენტის ანალიზაციის წარმოდგენება და განახლების მონაცემებზე.', 'it': "Le variazioni linguistiche sono onnipresenti, in particolare nelle nuove forme di scrittura come i social media. Fortunatamente, la variazione non è casuale; è spesso legato alle proprietà sociali dell'autore. In questo articolo, mostriamo come sfruttare i social network per rendere l'analisi del sentiment più robusta alle variazioni del linguaggio sociale. L'idea chiave è l'omofilia linguistica: la tendenza degli individui socialmente legati ad usare il linguaggio in modi simili. formalizziamo questa idea in una nuova architettura di rete neurale basata sull'attenzione, in cui l'attenzione è divisa tra diversi modelli base, a seconda della posizione dell'autore nel social network. Ciò ha l'effetto di uniformare la funzione di classificazione attraverso il social network e rende possibile indurre classificatori personalizzati anche per gli autori per i quali non esistono dati etichettati o metadati demografici. Questo modello migliora significativamente l'accuratezza dell'analisi del sentiment su Twitter e sui dati delle recensioni.", 'lt': 'Kalbos skirtumai yra visur įvairūs, ypač naujausiose rašymo formose, pavyzdžiui, social in ėje žiniasklaidoje. Laimei, variacija nėra atsitiktinė; jis dažnai siejamas su autoriaus socialinėmis savybėmis. Šiame dokumente parodomi, kaip išnaudoti socialinius tinklus, kad jausmų analizė taptų patikimesnė socialinių kalbų įvairovei. Pagrindinė idėja yra kalbinė homofilija: socialiniu požiūriu susijusių asmenų tendencija panašiai kalbėti. Mes formalizuojame šią idėją naujoje dėmesiu grindžiamoje neurologinio tinklo architektūroje, kurioje dėmesys skirstomas keliems pagrindiniams modeliams, priklausomai nuo autoriaus pozicijos socialiniame tinkle. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata.  Šis modelis gerokai pagerina sentiment ų analizės tikslumą Twitter ir peržiūros duomenimis.', 'kk': 'Тілдегі айырмашылығы әдеттегі, әсіресе социалдық медиа секілді жаңа жазу түрінде. Кездейсоқ, айырмашылығы кездейсоқ емес. ол автордың әлемдік қасиеттеріне байланысты. Бұл қағазда, әлеуметтік желілерді қалай қолдану үшін көпшілік анализ жасау үшін әлеуметтік тілдердің айнымалылығына көмектесу үшін көрсетеді. Негізгі идея - лингвистикалық гомофилік: әлемдік тілді ұқсас түрде қолданатын адамдардың тенденциясы. Біз бұл идеяны романдағы назардағы невралдық желінің архитектурасында официализацияларық. Бұл идеяны бірнеше негізгі үлгілер арасында бөліп, әлемдік желінде автордың орналасуына тәуелд Бұл әлемдік желінде классификациялау функциясын тегістейтін және өзгертілген классификацияларды өзгертуге мүмкіндік береді. Өзгертілген деректер не демографиялық метадеректері жоқ авторларға Бұл үлгі Твиттердің сезімдік анализиясының дұрыстығын жасайды және мәліметтерді қарау үшін.', 'mk': 'Разнијата на јазикот е насекаде, особено во новите форми на пишување како што се социјалните медиуми. За среќа, варијацијата не е случајна; често е поврзана со социјалните сопствености на авторот. Во овој весник покажуваме како да се искористат социјалните мрежи за да се направи анализата на чувствата посилна на разликата на социјалниот јазик. Клучната идеја е јазичната хомофилија: тенденцијата на социјално поврзаните поединци да користат јазик на слични начини. Ја формализираме оваа идеја во нова архитектура на нервната мрежа базирана на внимание, во која вниманието е поделено меѓу неколку основни модели, во зависност од позицијата на авторот во социјалната мрежа. Ова има ефект на разликување на класификациската функција низ социјалната мрежа и овозможува индукција на персонализирани класификатори дури и за авторите за кои нема означени податоци или демографски метададани. Овој модел значително ја подобрува точноста на анализата на чувствата на Твитер и на податоците за преглед.', 'mt': "Variation in language is ubiquitous, particularly in newer forms of writing such as social media.  Fortunatament, il-varjazzjoni mhijiex każwali; spiss hija marbuta mal-proprjetajiet soċjali tal-awtur. F’dan id-dokument, nagħmlu evidenza ta’ kif nistgħu nesfruttaw in-netwerks soċjali biex l-analiżi tas-sentimenti ssir aktar robusta għall-varjazzjoni tal-lingwi soċjali. L-idea ewlenija hija l-omofilja lingwistika: it-tendenza ta’ individwi marbuta soċjalment li jużaw il-lingwa b’modi simili. Aħna nifformalizzaw din l-idea f'arkitettura ġdida tan-netwerk newrali bbażata fuq l-attenzjoni, li fiha l-attenzjoni hija maqsuma fost diversi mudelli bażi, skont il-pożizzjoni tal-awtur fin-netwerk soċjali. Dan għandu l-effett li jħaffef il-funzjoni tal-klassifikazzjoni fin-netwerk soċjali kollu, u jagħmilha possibbli li jiġu indotti klassifikaturi personalizzati anki għall-awturi li għalihom m’hemmx dejta ttikkettata jew metadejta demografika. Dan il-mudell itejjeb b’mod sinifikanti l-preċiżjoni tal-analiżi tas-sentimenti fuq Twitter u fuq id-dejta tar-reviżjoni.", 'ms': 'Perubahan dalam bahasa ada di mana-mana, terutama dalam bentuk penulisan yang lebih baru seperti media sosial. Untungnya, variasi bukan rawak; ia sering terhubung dengan sifat sosial penulis. Dalam kertas ini, kita menunjukkan bagaimana untuk mengeksploitasi rangkaian sosial untuk membuat analisis perasaan lebih kuat kepada variasi bahasa sosial. Idea utama adalah homofili bahasa: kecenderungan individu yang berhubungan sosial untuk menggunakan bahasa dengan cara yang sama. Kami formalkan idea ini dalam arkitektur rangkaian saraf yang berasaskan perhatian yang baru, di mana perhatian dibahagi antara beberapa model asas, bergantung pada kedudukan penulis dalam rangkaian sosial. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata.  Model ini meningkatkan dengan signifikan ketepatan analisis perasaan di Twitter dan pada data ulasan.', 'ml': 'ഭാഷയിലെ വ്യത്യാസങ്ങള്\u200d പുതിയ രീതികളിലാണ്, പ്രത്യേകിച്ച് സാമൂഹിക മീഡിയ പോലെ എഴുതുന്നതില്\u200d. Fortunately, variation is not random;  എഴുത്തുകാരന്റെ സാമൂഹ്യത്തിന്റെ സ്വത്തുക്കളുമായി ബന്ധപ്പെട്ടിരിക്കുന്നു. ഈ പത്രത്തില്\u200d, സാമൂഹ്യശേഖരങ്ങള്\u200d എങ്ങനെ ഉപയോഗിക്കാന്\u200d സാമൂഹ്യഭാഷയിലേക്ക് കൂടുതല്\u200d വിശ്വാസമുള്ള വ്യത്യാസങ്ങള പ്രധാനപ്പെട്ട ആശയം ഭാഷയിലെ ഹോമോഫിയാണ്: സാമൂഹികമായി ബന്ധപ്പെട്ട വ്യക്തികളുടെ സ്വഭാവം ഇതുപോലെയാണ് ഭാ നമ്മള്\u200d ഈ ആശയം നോവല്\u200d അടിസ്ഥാനത്തുള്ള ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റര്\u200d നെറ്റര്\u200d ശ്രദ്ധിക്കുന്ന സ്ഥാനത്തില്\u200d നിര്\u200dമ്മിക്കുന്നു. അതില്\u200d ശ്രദ ഇത് സോഷ്യല്\u200d നെറ്റ്വര്\u200dക്കില്\u200d മുഴുവന്\u200d വ്യക്തിപരമായ വിഭാഗങ്ങള്\u200dക്കും വേണ്ടി വ്യക്തിപരമാക്കുന്നവര്\u200dക്കും വേണ്ടി വിവരങ്ങളോ ഡേറ്റാറ്റോ ഇല്ലാത ഈ മോഡല്\u200d ടൂട്ടരിലും വിവരങ്ങള്\u200d പരിശോധിക്കുന്നതിലും തീര്\u200dച്ചയായും തെളിവുകളുടെ വിചാരശീലനത്തിന്റെ ശരിയാണ്', 'mn': 'Холны өөрчлөлт нь хаана ч байдаг, ялангуяа нийгмийн хэвлэл шинэ бичих хэлбэрүүд юм. Харамсалтай нь өөрчлөлт санамсаргүй биш. зохиолчдын нийгмийн чанартай холбоотой. Энэ цаасан дээр бид нийгмийн сүлжээг хэрхэн хэрхэн ашиглах вэ гэдгийг харуулж, нийгмийн хэл өөрчлөлттэй сэтгэл санааны шинжилгээг илүү хүчтэй болгодог. Хамгийн чухал санаа нь хэлний бэрхшээл, нийгмийн холбоотой хүмүүсийн холбоотой холбоотой холбоотой байдал юм. Бид энэ санааг нийгмийн сүлжээнд зохиолчдын нөхцөл байдлын хамааралтай шинэ анхаарлын төвөгтэй мэдрэлийн сүлжээний архитектурд хувааж өгдөг. Энэ нь нийгмийн сүлжээнд хуваалцааны функцийг хөгжүүлэх нөлөөтэй. Хэдийгээр хувийн хуваалцааны хуваалцагчид ч тэдний хувьд нэрлэгдсэн өгөгдлийг эсвэл демографик мета өгөгдлийг байхгүй зохиолчдын Энэ загвар нь Твиттерийн мэдрэмжтэй шинжилгээний тодорхойлолт болон шинжилгээний тодорхойлолтыг үнэхээр сайжруулдаг.', 'pl': 'Zmiany języka są wszechobecne, szczególnie w nowszych formach pisania, takich jak media społecznościowe. Na szczęście zmiany nie są losowe. Jest ona często powiązana z właściwościami społecznymi autora. W niniejszym artykule pokazujemy, jak wykorzystać sieci społecznościowe, aby analiza sentymentów była bardziej solidna dla zmian językowych społecznościowych. Kluczową ideą jest homofilia językowa: tendencja społecznie powiązanych osób do używania języka w podobny sposób. Formalizujemy tę ideę w nowej architekturze sieci neuronowej opartej na uwadze, w której uwagę podzielona jest na kilka modeli bazowych, w zależności od pozycji autora w sieci społecznej. Efektem tego jest wygładzenie funkcji klasyfikacji w całej sieci społecznościowej i umożliwia wywołanie spersonalizowanych klasyfikatorów nawet dla autorów, dla których nie ma oznaczonych danych lub metadanych demograficznych. Model ten znacząco poprawia dokładność analizy sentymentów na Twitterze i danych recenzyjnych.', 'no': 'Variasjon i språk er omvendt, spesielt i nyare skriveform som sosialmedia. For godt er variasjonen ikkje tilfeldig. det er ofte kopla til sosiale eigenskapar av forfatteren. I denne papiret viser vi korleis sosiale nettverk skal brukast for å gjera sentimentanalysen meir sterkt til sosiale språk variasjonar. Nøkkelideen er linguistisk homofisk: tendensen til sosialt tilkopla indikatora til å bruka språk på liknande måtar. Vi formaliserer denne ideen i eit nytt oppmerksbasert neuralnettverksarkitektur, der oppmerksomheten er delt blant fleire grunnmodeller, avhengig av forfattarens posisjon i sosialt nettverk. Dette har effekten til å gjera klassifikasjonsfunksjonen over sosialt nettverk, og gjer det mogleg å indusera personaliserte klassifikatorar sjølv for forfatarane som ikkje finst merkelige data eller demografiske metadata for. Dette modellet forbetrar nøyaktigheten av sentimentanalysen på Twitter og om gjennomgang av data.', 'ro': 'Variația limbajului este omniprezentă, în special în forme mai noi de scriere, cum ar fi social media. Din fericire, variația nu este aleatorie; este adesea legată de proprietățile sociale ale autorului. În această lucrare, vă arătăm cum să exploatați rețelele sociale pentru a face analiza sentimentelor mai robustă la variația limbajului social. Ideea cheie este homofilia lingvistică: tendința persoanelor legate social de a folosi limbajul în moduri similare. Formalizăm această idee într-o nouă arhitectură a rețelei neurale bazată pe atenție, în care atenția este împărțită pe mai multe modele de bază, în funcție de poziția autorului în rețeaua socială. Acest lucru are ca efect uniformizarea funcției de clasificare în rețeaua socială și face posibilă inducerea clasificătorilor personalizați chiar și pentru autorii pentru care nu există date etichetate sau metadate demografice. Acest model îmbunătățește semnificativ acuratețea analizei sentimentelor pe Twitter și pe datele de recenzie.', 'sr': 'Razlika jezika je svuda, posebno u novim oblicima pisanja poput društvenih medija. Srećom, varijacija nije sluèajna. često je povezano sa društvenim vlasništvom autora. U ovom papiru pokazujemo kako da iskoristimo socijalne mreže da bi analizirali sentimente jačali društvenoj varijaciji jezika. Ključna ideja je jezička homofila: tendencija socijalno povezanih pojedinaca da koriste jezik na sličnim načinama. Mi formaliziramo ovu ideju u novoj arhitekturi neuralne mreže na pažnji, u kojoj se pažnja podijelja među nekoliko osnovnih modela, ovisno o poziciji autora u društvenoj mreži. To ima efekat glatkovanja klasifikacije širom društvene mreže, i omogućava da inducira personalizovane klasifikatore čak i autore za koje nema označene podatke ili demografske metadata. Ovaj model značajno poboljšava tačnost analize sentimenta na Twitteru i podatke o pregledu.', 'sv': 'Språkvariationer är allestädes närvarande, särskilt i nyare skrivformer som sociala medier. Lyckligtvis är variationen inte slumpmässig. det är ofta kopplat till författarens sociala egenskaper. I denna uppsats visar vi hur man utnyttjar sociala nätverk för att göra sentimentalanalys mer robust för social språkvariation. Nyckelidén är språklig homofil: tendensen hos socialt sammanlänkade individer att använda språket på liknande sätt. Vi formaliserar denna idé i en ny uppmärksamhetsbaserad neural nätverksarkitektur, där uppmärksamheten delas upp mellan flera grundmodeller, beroende på författarens position i det sociala nätverket. Detta leder till att klassificeringsfunktionen jämnas ut över det sociala nätverket och gör det möjligt att skapa anpassade klassificerare även för författare för vilka det inte finns några märkta data eller demografiska metadata. Denna modell förbättrar avsevärt noggrannheten i sentimentalanalys på Twitter och på granskningsdata.', 'si': 'භාෂාවේ වෙනස් වෙනුවෙන් වෙනස් වෙනුවෙන් සාමාජික මාධ්\u200dයමය වගේ අලුත් විදියට ලියන්න. සතුටුයි, වෙනස් වෙනස් නෙමෙයි; ඒක සාමාජික විශේෂතාවට සමාජික විශේෂතාවට සම්බන්ධ වෙනවා. මේ පත්තරේ අපි පෙන්වන්නේ සාමාජික ජාතික විශ්ලේෂණය කරන්න සාමාජික භාෂාව වෙනස් වලට වඩා ශක්තිමත මුළු අදහසය භාෂාවික සමාජිකයි: සමාජිකයෙන් සම්බන්ධ විදියට භාෂාව භාවිත කරන්න භාෂාවික ව අපි මේ අදහසක් නිර්මාණය කරන්නේ නිර්මාණය අධික අවධානය සඳහා නිර්මාණ ජාලය සංවිධානයක් වලින්, ඒ වලින් අවධානය විතර මේකට සාමාජික ජාලයේ විශේෂණ වැඩක් සුදුසුම් කරන්න ප්\u200dරශ්නයක් තියෙනවා, ඒ වගේම පුළුවන් විශේෂ විශේෂ කරුණු ලේඛකය මේ මොඩේල් විශ්වාස කරනවා ට්විටර් වල සංවේදනය විශ්ලේෂණය සහ පරීක්ෂණ දත්ත ගැන.', 'so': 'Isku bedelka luuqadu waa mid aan kala duwan, khusuusan waxay ku qoran noocyo cusub oo qoran sida mitandada bulshada. Nasiib leh, isbedelku ma ahan mid fudud; waxaa inta badan la xiriiraa hantida bulshada ee qoraalka. Warqadan waxan ka muuqanaynaa sida loo isticmaalo shabakada bulshada si aan u sameyno kalabar kaloo ka mid ah kalluuqada bulshada. Fikirada muhiimka ah waa homofisiga luqada: qaabka qofka bulshada isku xiran si ay u isticmaalaan luuqada isku mid ah. Fikirkaas waxaan ku sameynaa dhismaha shabakadda neurada ee warqada ah, kaas oo lagu kala qaybsan yahay tusaalooyin kala duduwan, iyadoo ku xiran qofka qoraalka ah meeshiisa shabakadda bulshada. Tani waxay saamayn ku leedahay simbirta tababarka shabakadda bulshada oo dhan, waxayna suurtogal u yeelan karaan fasaxyo shakhsiyan ah, xataa kuwa qoraalka aan laga helin macluumaad ama macluumaad maamul ah. Tusaaladan ayaa si weyn u hagaajiya saxda baaritaanka fikirka ee Twitterka iyo macluumaadka baaritaanka.', 'ta': 'மொழியில் மாறுதல் ஒற்றைப்படையாக இருக்கிறது, குறிப்பாக புதிய வடிவத்தில், சமூக ஊடகங்கள் போன்ற எழுதுவதில். அதிர்ஷ்டவசமாக, மாறுபாடு குறிப்பில்லை; அது ஆசிரியரின் சமூக பண்புகளுடன் இணைக்கப்படுகிறது. இந்த காகிதத்தில், நாம் எப்படி சமூக வலைப்பின்னல்களை பயன்படுத்த வேண்டும் என்பதை காட்டுகிறோம் என்று உணர்வு மொழிய The key idea is linguistic homophily: the tendency of socially linked individuals to use language in similar ways.  நாம் இந்த யோசனையை புதிய கவனத்தில் அடிப்படையிலான புதிய வலைப்பின்னல் அமைப்பில் வடிவமைக்கிறோம், அதில் கவனத்தை பல மாதிரிகளில் பிரிக்கப்படு இது சமூக வலைப்பின்னலில் வகுப்பு செயல்பாட்டை சுருக்கும் விளைவு உள்ளது, அது தனிப்பட்ட வகுப்பாளர்களை செயல்படுத்த முடியும், அவர்களுக்கு குறிப்பி இந்த மாதிரி தெரியும் உணர்வு ஆராய்ச்சியின் சரியையும் மேம்படுத்துகிறது Twitter மற்றும் மீள்விவரங்களில்.', 'ur': 'زبان میں متفاوت ہر طرف سے ہے، مخصوصاً نوشتہ فرموں میں، جیسے سوسیل میڈیا. خوش شانس، تغییر Random نہیں ہے، یہ اغلب لکھنے والوں کے اجتماعی خصوصیت سے متصلہ ہے۔ اس کاغذ میں ہم کس طرح سوسیل نیٹورک کو استعمال کریں گے کہ سیاسیل زبان تغییرات کے لئے احساسات کا تحلیل زیادہ ثابت ہو جائے۔ کلی ایڈیون زبان شناسی ہموفی ہے: سوسیال طریقے سے متصل ہوئے شخصوں کی تنظیم ہے کہ زبان کا استعمال کریں۔ ہم نے اس ایڈیوں کو ایک نوی توجه پر بنیاد رکھا ہے نیورل نیٹ ورک معماری میں، جہاں توجه مختلف بنیاد نمڈلوں میں تقسیم کی جاتی ہے، سوسیل نیٹ ورک میں لکھنے والے کی موقعیت پر مضبوط ہے. اسے سوسیل نیٹ ورک کے اندر کلاسپیٹ فعالیت کے مطابق ہلکا کرنے کا اثر ہے، اور اسے شخصی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طر This model significantly improves the accuracy of sentiment analysis on Twitter and review data.', 'vi': 'Sự thay đổi ngôn ngữ có thường xuyên, đặc biệt là trong những dạng văn bản mới như các phương tiện truyền thông xã hội. May mắn thay, biến đổi không ngẫu nhiên. Nó thường được liên kết với tính chất xã hội của tác giả. Trong tờ giấy này, chúng tôi cho thấy cách sử dụng mạng xã hội để làm phân tích tình cảm mạnh mẽ hơn với các biến đổi ngôn ngữ xã hội. Chủ đề chính là đồng tính ngôn ngữ: xu hướng những cá nhân liên kết xã hội sử dụng ngôn ngữ theo cách tương tự. Chúng tôi chính thức hoá ý tưởng này trong một kiến trúc dây thần kinh dựa trên s ự chú ý mới, nơi tập trung được chia ra trong nhiều mẫu cơ bản, phụ thuộc vào vị trí tác giả trong mạng xã hội. Việc này có tác dụng làm mịn chức năng phân loại trên mạng xã hội, và làm cho nó có thể tạo ra các phân loại cá nhân cho những tác giả không có dữ liệu hay siêu dữ liệu quần chúng. Cách này cải thiện đáng kể các độ chính xác của phân tích tình cảm trên Twitter và trên dữ liệu xem xét.', 'uz': "Tilda o'zgarishlar o'zgarishdir, hususan yangi yozuvchi formidagi jamiyat media kabi yozish. @ info: whatsthis bu mualliflarning jamiyat xossalariga bog'liq. Bu qogʻozda, jamiyat tarmoqlarini qanday foydalanishini ko'rsatamiz va hissiyotni jamiyat tillari o'zgarishga qo'shishga qo'yish uchun ko'rsatumiz. Mavzu fikr - tillar homofisi: jamiyatli bog'liq odamlarning qo'shilishi huddi tilni o'xshash usulda foydalanish. Biz bu g'oyani yangilik tarmoqning nazar tarmoqni yaratishimiz mumkin. Bu yerda muhalliy tarmoqda mualliflarning joyga bog'liq, bir necha modellarga qaytadi. Bu shaxsiy shaxsiy tarmoq tarmoqda darajalashtirish funksiyasini qo'yish natijasida bajaradi va u uchun hech qachon maʼlumot yoki demografisk metadata yoʻq mualliflarning shaxsiy darajalarni ishga tushirish mumkin. Bu model Twitterda hissiyotni aniqlash va maʼlumotlarni tahrirlash haqida muhimiy o'zgartiradi.", 'bg': 'Вариациите в езика са навсякъде разпространени, особено в по-новите форми на писане като социалните медии. За щастие, вариацията не е случайна. често е свързан със социалните свойства на автора. В тази статия показваме как да използваме социалните мрежи, за да направим анализа на сентимента по-стабилен за вариацията на социалния език. Ключовата идея е лингвистичната хомофилия: тенденцията на социално свързани индивиди да използват езика по подобен начин. Ние формализираме тази идея в нова базирана на вниманието невронна мрежа архитектура, в която вниманието е разделено между няколко базови модела, в зависимост от позицията на автора в социалната мрежа. Това води до изглаждане на функцията за класификация в социалната мрежа и дава възможност за индуциране на персонализирани класификатори дори за автори, за които няма етикетирани данни или демографски метаданни. Този модел значително подобрява точността на анализа на сентимента в Туитър и на данните от прегледа.', 'da': 'Sprogvariationer er allestedsnærværende, især i nyere former for skrivning som sociale medier. Heldigvis er variationen ikke tilfældig. det er ofte forbundet med forfatterens sociale egenskaber. I denne artikel viser vi, hvordan man udnytter sociale netværk til at gøre sentimentalanalyse mere robust til social sprogvariation. Nøgleidéen er sproglig homofil: tendensen hos socialt forbundne individer til at bruge sprog på lignende måder. Vi formaliserer denne idé i en ny opmærksomhedsbaseret neural netværksarkitektur, hvor opmærksomheden er delt mellem flere grundmodeller, afhængigt af forfatterens position i det sociale netværk. Dette betyder, at klassificeringsfunktionen udjævnes på tværs af det sociale netværk og gør det muligt at fremkalde personlige klassificeringer selv for forfattere, for hvem der ikke findes mærkede data eller demografiske metadata. Denne model forbedrer nøjagtigheden af sentimentalanalyse betydeligt på Twitter og på anmeldelsedata.', 'nl': 'Taalvariatie is alomtegenwoordig, vooral in nieuwere vormen van schrijven zoals sociale media. Gelukkig is variatie niet willekeurig; Het is vaak gekoppeld aan sociale eigenschappen van de auteur. In dit artikel laten we zien hoe we sociale netwerken kunnen benutten om sentimentanalyse robuuster te maken voor sociale taalvariaties. Het belangrijkste idee is taalhomofiele: de neiging van sociaal verbonden individuen om taal op vergelijkbare manieren te gebruiken. We formaliseren dit idee in een nieuwe aandacht-gebaseerde neurale netwerkarchitectuur, waarin aandacht wordt verdeeld over verschillende basismodellen, afhankelijk van de positie van de auteur in het sociale netwerk. Dit heeft als effect dat de classificatiefunctie in het sociale netwerk gladstrijkt en maakt het mogelijk om gepersonaliseerde classificatoren te induceren, zelfs voor auteurs waarvoor geen gelabelde gegevens of demografische metadata zijn. Dit model verbetert de nauwkeurigheid van sentimentanalyse op Twitter en review data aanzienlijk.', 'hr': 'Razlika jezika je svuda, posebno u novim oblicima pisanja poput društvenih medija. Srećom, varijacija nije slučajna; često je povezano sa društvenim vlasništvom autora. U ovom papiru pokazujemo kako iskoristiti društvene mreže kako bi analizirali osjećaje jačali društvenoj varijaciji jezika. Ključna ideja je jezička homofijalna: tendencija socijalno povezanih pojedinaca da koriste jezik na sličnim načinama. Mi formaliziramo ovu ideju u novoj arhitekturi neuralne mreže na temelju pažnje, u kojoj je pažnja podijeljena između nekoliko osnovnih modela, ovisno o poziciji autora u društvenoj mreži. To ima učinak olakšanja funkcije klasifikacije u društvenoj mreži i omogućava inducirati osobne klasifikacije čak i za autore za koje nema označene podatke ili demografske metadata. Ovaj model značajno poboljšava preciznost analize osjećaja na Twitter-u i na podacima o pregledu.', 'de': 'Sprachunterschiede sind allgegenwärtig, insbesondere in neueren Schreibformen wie Social Media. Glücklicherweise ist Variation nicht zufällig. Es ist oft mit sozialen Eigenschaften des Autors verbunden. In diesem Beitrag zeigen wir, wie soziale Netzwerke genutzt werden können, um Stimmungsanalysen robuster gegenüber sozialen Sprachvariationen zu machen. Der Grundgedanke ist sprachliche Homophilie: die Tendenz sozial verbundener Individuen, Sprache auf ähnliche Weise zu benutzen. Wir formalisieren diese Idee in einer neuartigen aufmerksamkeitsbasierten neuronalen Netzwerkarchitektur, in der die Aufmerksamkeit je nach Position des Autors im sozialen Netzwerk auf mehrere Basismodelle aufgeteilt wird. Dadurch wird die Klassifikationsfunktion im gesamten sozialen Netzwerk geglättet und es ist möglich, personalisierte Klassifizierer auch für Autoren zu induzieren, für die es keine markierten Daten oder demografischen Metadaten gibt. Dieses Modell verbessert die Genauigkeit der Stimmungsanalyse auf Twitter und auf Bewertungsdaten signifikant.', 'id': 'Variasi dalam bahasa ada di mana-mana, terutama dalam bentuk tulisan yang lebih baru seperti media sosial. Untungnya, variasi bukan acak; sering terhubung dengan properti sosial penulis. Dalam kertas ini, kita menunjukkan bagaimana mengeksploitasi jaringan sosial untuk membuat analisis sentimen lebih kuat untuk variasi bahasa sosial. Ide kunci adalah homofili bahasa: cenderung individu yang berhubungan sosial untuk menggunakan bahasa dengan cara yang sama. Kami formalisasi ide ini dalam arsitektur jaringan saraf berbasis perhatian yang baru, di mana perhatian dibagi antara beberapa model dasar, tergantung pada posisi penulis dalam jaringan sosial. Ini memiliki efek untuk meledakkan fungsi klasifikasi di seluruh jaringan sosial, dan memungkinkan untuk mengakibatkan klasifikasi pribadi bahkan untuk penulis yang tidak ada data yang ditabel atau metadata demografis. Model ini meningkatkan dengan signifikan akurasi analisis sentimen di Twitter dan pada data penelitian.', 'ko': '언어의 변이는, 특히 소셜 미디어 등 새로운 창작 형식에 있다.다행히도 변화는 랜덤이 아니다.이것은 통상적으로 작가의 사회 속성과 관계가 있다.본고에서 우리는 소셜네트워크서비스를 어떻게 활용하여 감정 분석이 소셜네트워크서비스의 변이에 대해 더욱 노봉성을 가지도록 하는지를 보여 주었다.그 핵심 사상은 언어 동질화이다. 사회와 관련된 개체는 비슷한 방식으로 언어를 사용하는 경향이 있다.우리는 주의를 바탕으로 하는 새로운 신경 네트워크 구조로 이 생각을 형식화했다. 이런 구조에서 작가가 소셜네트워크서비스에서 차지하는 위치에 따라 주의는 몇 가지 기본 모델로 나뉜다.이는 전체 소셜네트워크서비스의 분류 기능을 매끄럽게 하는 효과가 있고 표기 데이터나 인구 통계 데이터가 없는 작가에게도 개성화된 분류기가 생길 수 있다.이 모델은 트위터와 평론 데이터의 정서 분석의 정확성을 현저히 높였다.', 'fa': 'تغییرات زبان همه جا است، مخصوصا در شکل نوشتن جدیدتر مثل رسانه\u200cهای اجتماعی. خوشبختانه، تغییرات تصادفی نیست. اغلب به ویژگی اجتماعی نویسنده ارتباط دارد. در این کاغذ، ما نشان می دهیم چگونه شبکه\u200cهای اجتماعی را استفاده کنیم تا تحلیل احساسات را برای تغییرات زبان اجتماعی قوی تر کند. ایده کلیدی همجنسگری زبان\u200cشناسی است: نقشه\u200cای از افراد متصل به اجتماعی برای استفاده از زبان به طریق مشابه. ما این ایده را در یک معماری شبکه عصبی بر اساس توجه نویسی فرمودیم که توجه بین چند مدل بنیادی تقسیم می\u200cشود، بستگی به موقعیت نویسنده در شبکه اجتماعی است. این تأثیر عملکرد گروه\u200cشناسی در شبکه اجتماعی دارد، و این امکان می\u200cدهد که گروه\u200cشناسی شخصی را حتی برای نویسندگان که داده\u200cهای برچسب یا متداده\u200cهای دموگرافیک برای آنها وجود ندارد، تحریک کند. این مدل دقیق تحلیل احساسات توئیتر و اطلاعات بازرسی را به طور معنی بهتر می کند.', 'sw': 'Mabadiliko ya lugha ni tofauti, hasa kwa namna mpya ya kuandika kama vile mitandao ya kijamii. Kwa bahati nzuri, mabadiliko hayana urahisi; mara nyingi huunganishwa na mali za kijamii za mwandishi. Katika karatasi hii, tunaonyesha jinsi ya kutumia mitandao ya kijamii ili kufanya uchambuzi wa hisia zaidi wa mabadiliko ya lugha ya kijamii. Wazo muhimu ni ushoga wa lugha: tabia ya watu wenye uhusiano wa kijamii kutumia lugha kwa namna sawa. Tunaweza kutengeneza wazo hili katika ujenzi wa mtandao wa kijamii wenye msimamo wa kisasa, ambapo hisia zinagawanywa kati ya mifano kadhaa, kwa kutegemea na nafasi ya mwandishi katika mitandao ya kijamii. Hii ina madhara ya kuvutia kazi ya usambazaji katika mitandao ya kijamii, na inafanya uwezekano wa kuwasaidia wataalamu binafsi hata kwa waandishi ambao hawana taarifa au taarifa za kidemografia. Mfano huu unabadilisha ukweli wa uchambuzi wa hisia kwenye mtandao wa Twita na kupitia taarifa.', 'af': "Verandering in taal is omheen, veral in nuwe vorms van skryf soos sosiale media. Gelukkig, verandering is nie willekeurig nie; dit is dikwels verbind met sosiale eienskappe van die outeur. In hierdie papier wys ons hoe om sosiale netwerke te gebruik om sentimentanalisie meer kragtiger te maak aan sosiale taal veranderinge. Die sleutel idee is linguistiese homofiële: die tendensie van sosiale verbind individue om taal in gelyke maniere te gebruik. Ons formaliseer hierdie idee in 'n nuwe aandag-gebaseerde neuralnetwerk-arkitektuur, waarin aandag onder verskeie basis modele gedeel is, afhang van die outeur se posisie in die sosiale netwerk. Hierdie het die effek van gelukkig van die klasifikasie funksie oor die sosiale netwerk, en maak dit moontlik om persoonlike klassifiseerders selfs vir outeurs vir wie daar geen etiketeerde data of demografiese metadata is nie. Hierdie model betekeurig verbeter die presies van sentimentanalisie op Twitter en op hersiening data.", 'tr': "Dilde üýtgeşmeler ýerleşdirilýändir, ýöne sosyal medýýatlar ýazmak ýaly täze şeklinde. Gynansakda, üýtgeşik tesadüfiň däl; ol köplenç awtoryň sosial häsiýetlerine baglanýar. Bu kagyzda, sosial şebekeleriň nädip duýgym çykyşlygyny sosial dilleriň üýtgeşigine nähili ulanmagyny görkezýäris. Öň wajyp ideýa, dil homofiýalydyr: sosial bilen baglanýan adamlaryň dilini meňzeş şekilde ulanmaklygy üçin bilim gürrüňidir. Biz bu ideýany romanda üns berilýän näural şebek arhitekteriýasynda formalýarys. Bu ideýa sosial şebekede awtoryň ýerinde baglanýar. Bu sosial şebekeden klasifikasiýasynyň etkisi ýok edip, we şahsyzlyk klasifikalary hem özlerine etiket edilen hatda demografik metadata ýok awtorlaryň içine ýok bir şekilde üýtgetmegini mümkin edýär. Bu nusga Twitter'da duýgular analýusiýasynyň dogrylygyny we maglumatlaryny üýtgedýär.", 'sq': 'Variation in language is ubiquitous, particularly in newer forms of writing such as social media.  Fatmirësisht, variacioni nuk është i rastësishëm; shpesh lidhet me pronat shoqërore të autorit. Në këtë letër, ne tregojmë se si të shfrytëzojmë rrjetet sociale për të bërë analizën e ndjenjave më të fortë ndaj ndryshimeve sociale të gjuhës. Ideja kryesore është homofilia gjuhësore: tendenca e individëve të lidhur shoqërisht për të përdorur gjuhën në mënyra të ngjashme. Ne formalizojmë këtë ide në një arkitekturë të re të rrjetit nervor të bazuar në vëmendje, në të cilën vëmendja është e ndarë midis disa modeleve bazë, në varësi të pozicionit të autorit në rrjetin social. Kjo ka efektin e lehtësimit të funksionit të klasifikimit nëpër rrjetin social dhe e bën të mundur të induktohet klasifikuesit personalizuar edhe për autorët për të cilët nuk ka të dhëna të etiketuara apo metatë demografike. This model significantly improves the accuracies of sentiment analysis on Twitter and on review data.', 'am': 'ቋንቋ የተለየ ቋንቋ፣ በተለይም በአዲስ ዓይነት እንደ ማኅበራዊ ሚዲያ በመጽሐፍ ነው፡፡ ለዋጭ ቀላል አይደለም ብዙ ጊዜም በጸሐፊው ማኅበራዊ ሀብት ይታሰራል:: በዚህ ካላት፣ ማኅበራዊ መረብ እንዴት እንደሚጠቀም እናሳያቸዋለን፡፡ The key idea is linguistic homophily: the tendency of socially linked individuals to use language in similar ways.  ይህንን አእምሮን በዘላለም የኔትራዊ መረብ መሠረት አካባቢ ላይ እናደርጋለን፡፡ ይህም በማኅበራዊ መረብ ላይ የተለየውን ትርጉም ማቀናቀል ነው፡፡ ይህም ምሳሌ በትዊተር እና ዳራዎችን በመመለስ የስሜት አካሄዱን የሚያበዛ ነው፡፡', 'bn': 'Variation in language is ubiquitous, particularly in newer forms of writing such as social media.  সৌভাগ্যবশত, পার্থক্য অনুযায়ী নয়; এটা প্রায়শই লেখকের সামাজিক বৈশিষ্ট্যের সাথে যুক্ত। এই কাগজটিতে আমরা দেখাচ্ছি কিভাবে সামাজিক নেটওয়ার্ক ব্যবহার করতে পারে যাতে আবেগ বিশ্লেষণ করা যায় সামাজিক ভাষার গুরুত্বপূর্ণ ধারণা হচ্ছে ভাষাগত সমকামীতা: সামাজিক সংযুক্ত ব্যক্তিদের ভাষায় একই ভাবে ভাষা ব্যবহার করার প্রচ আমরা এই ধারণাটিকে একটি উপন্যাসের ভিত্তিক নিউরেল নেটওয়ার্ক কাঠামোর ভিত্তিতে গঠন করি, যেখানে মনোযোগ বিভিন্ন ভিত্তিক মডেলের মধ্যে বিভক্ত সামাজিক যোগাযোগ নেটওয়ার্কের সাথে ব্যক্তিগত শ্রেণীবিষয়কে ধূমপান করার প্রভাব রয়েছে এবং এমনকি লেখকদের কাছে কোন লেবেল ডাটা নেই অথবা গণগ্রা এই মডেলটি টুইটারে অনুভূতির বিশ্লেষণের সঠিকভাবে উন্নত করে এবং তথ্য পর্যবেক্ষণের ব্যাপারে।', 'bs': 'Razlika jezika je svuda, posebno u novim oblicima pisanja poput društvenih medija. Srećom, varijacija nije slucajna; često je povezano sa socijalnim vlasništvom autora. U ovom papiru pokazujemo kako iskoristiti društvene mreže kako bi analizirali osjećaje jača društvenoj varijaciji jezika. Ključna ideja je jezička homofija: tendencija socijalno povezanih pojedinaca da koriste jezik na sličnim načinama. Mi formaliziramo ovu ideju u novoj arhitekturi neuralne mreže na pažnji, u kojoj je pažnja podijeljena između nekoliko osnovnih modela, ovisno o poziciji autora u društvenoj mreži. To ima učinak olakšanja klasifikacije širom društvene mreže i omogućava inducirati personalizovane klasifikatore čak i autore za koje nema označenih podataka ili demografskih metapodataka. Ovaj model značajno poboljšava preciznost analize sentimenta na Twitter-u i na podacima o pregledu.', 'ca': "La variació de llenguatge és omnipresent, especialment en noves formes d'escriptura com els mitjans socials. Per sort, la variació no és aleatòria; sovint està vinculat a les propietats socials de l'autor. En aquest article, demostram com explotar les xarxes socials per fer l'anàlisi del sentiment més robust a la variació del llenguatge social. La idea clau és l'homofilia lingüística: la tendència dels individus socialment vinculats a utilitzar el llenguatge de maneres similars. Formalitzem aquesta idea en una nova arquitectura de xarxa neural basada en l'atenció, en la qual l'atenció està dividida entre diversos models de base, segons la posició de l'autor en la xarxa social. Això té l'efecte de lliurar la funció de classificació a través de la xarxa social, i permet induir classificadors personalitzats fins i tot per als autors per als quals no hi ha dades etiquetades ni metadades demogràfiques. Aquest model millora significativament la precisió de l'anàlisi de sentiments a Twitter i en les dades de revisió.", 'cs': 'Variace jazyka jsou všudypřítomné, zejména v novějších formách psaní, jako jsou sociální média. Naštěstí variace není náhodná. je často spojena se sociálními vlastnostmi autora. V tomto článku ukazujeme, jak využít sociální sítě k tomu, aby analýza sentimentů byla robustnější vůči sociálním jazykovým variacím. Klíčovou myšlenkou je lingvistická homofilie: tendence sociálně propojených jedinců používat jazyk podobným způsobem. Formalizujeme tuto myšlenku v nové architektuře neuronové sítě založené na pozornosti, v níž je pozornost rozdělena na několik základních modelů, v závislosti na pozici autora v sociální síti. To má za následek vyhlazení klasifikační funkce napříč sociální sítí a umožňuje navodit personalizované klasifikátory i pro autory, pro které neexistují označená data nebo demografická metadata. Tento model výrazně zlepšuje přesnost analýzy sentimentů na Twitteru a na recenzích.', 'et': 'Keele varieerumine on kõikjal levinud, eriti uuemates kirjutamisvormides, näiteks sotsiaalmeedias. Õnneks ei ole varieerumine juhuslik; See on sageli seotud autori sotsiaalsete omadustega. Käesolevas artiklis näitame, kuidas kasutada sotsiaalvõrgustikke, et muuta tundeanalüüs sotsiaalse keele variatsiooni jaoks tugevamaks. Peamiseks ideeks on keeleline homofiilia: sotsiaalselt seotud inimeste kalduvus kasutada keelt sarnaselt. Formaliseerime selle idee uudses tähelepanupõhises neurovõrgu arhitektuuris, kus tähelepanu jaguneb mitme baasmudeli vahel sõltuvalt autori positsioonist sotsiaalvõrgustikus. See lihtsustab klassifitseerimisfunktsiooni sotsiaalvõrgustikus ning võimaldab luua isikupärastatud klassifitseerijaid isegi autoritele, kelle kohta puuduvad märgistatud andmed või demograafilised metaandmed. See mudel parandab oluliselt tundeanalüüsi täpsust Twitteris ja ülevaateandmetes.', 'fi': 'Kielen vaihtelu on kaikkialla, erityisesti uudemmissa kirjoitusmuodoissa, kuten sosiaalisessa mediassa. Onneksi vaihtelu ei ole sattumanvaraista. Se liittyy usein tekijän sosiaalisiin ominaisuuksiin. Tässä artikkelissa näytämme, miten sosiaalisia verkostoja hyödynnetään, jotta tunneanalyysi olisi vahvempi sosiaalisen kielen vaihtelulle. Keskeinen ajatus on kielellinen homofiili: sosiaalisesti sidoksissa olevien henkilöiden taipumus käyttää kieltä samalla tavalla. Muodostamme tämän ajatuksen uudenlaisessa huomiopohjaisessa neuroverkkoarkkitehtuurissa, jossa huomio jakautuu useisiin perusmalleihin riippuen tekijän asemasta sosiaalisessa verkostossa. Tämä tasoittaa luokittelutoimintoa sosiaalisessa verkostossa ja mahdollistaa yksilöllisten luokittelijoiden luomisen jopa tekijöille, joille ei ole merkittyä tietoa tai demografista metatietoa. Tämä malli parantaa merkittävästi tunteiden analyysin tarkkuutta Twitterissä ja katsaustiedoissa.', 'hy': 'Լեզվի տարբերությունը ամենուրեք է, հատկապես գրելու նոր ձևերում, ինչպիսիք են սոցիալական լրատվամիջոցները: Բարեբախտաբար, տարբերությունը պատահական չէ, այն հաճախ կապված է հեղինակի սոցիալական հատկությունների հետ: Այս աշխատանքում մենք ցույց ենք տալիս, թե ինչպես օգտագործել սոցիալական ցանցերը, որպեսզի զգացմունքների վերլուծությունը ավելի ուժեղ դարձնի սոցիալական լեզվի տարբերություններին: Հիմնական գաղափարն այն է, որ լեզվական հոմոֆիլիան է. սոցիալապես կապված անհատների հակվածությունը լեզվի օգտագործման նման ձևերով: Մենք կազմակերպում ենք այս գաղափարը ուշադրության վրա հիմնված նոր նյարդային ցանցի ճարտարապետության մեջ, որտեղ ուշադրությունը բաժանում է բազմաթիվ հիմնական մոդելների միջև, կախված հեղինակի դիրքից սոցիալական ցանցում: Սա ազդում է դասակարգման ֆունկցիայի հավասարակշռությունը սոցիալական ցանցում, և հնարավորություն է տալիս անձնական դասակարգողներ ստեղծել նույնիսկ հեղինակների համար, ովքեր չունեն նշանակված տվյալներ կամ դեմոգրաֆիկ մետատվյալներ: Այս մոդելը կարևոր բարելավում է Թվիթերի և վերանայման տվյալների զգացմունքների վերլուծության ճշմարտությունը:', 'az': "Dill…ôrin d…ôyiŇüiklikl…ôri h…ôr yerd…ô, √∂zl…ôrin…ô d…ô sosyal media kimi yeni yazńĪlmńĪŇü formlardńĪr. Nec…ô ki, d…ôyiŇüiklik rastlaŇüdńĪrńĪlmaz. bu yazńĪcńĪnńĪn sosyal √∂zellikl…ôrin…ô bańülńĪ olur. Bu kańüńĪzda, sosyal Ňü…ôb…ôk…ôl…ôrin nec…ô istifad…ô etm…ôsini g√∂st…ôririk ki, hiss analizi sosyal dill…ôrin d…ôyiŇüiklikl…ôrin…ô daha q√ľvv…ôtlidir. Anahtar fikir dil homofiylidir: sosyal t…ôr…ôfind…ôn bańülńĪ kiŇüil…ôrin dill…ôrini b…ônz…ôr yollarla istifad…ô etm…ôk √ľ√ß√ľn istifad…ô edilm…ôsi. Biz bu fikirl…ôri yeni t…ôsirli n√∂ral a ńü arhitektarńĪnda formaliz…ô edirik. Bu fikirl…ôrin m…ôlumatńĪ sosyal ańüda yazńĪcńĪnńĪn posisiyasńĪna bańülńĪ olan bir ne√ß…ô temel modell…ôrd…ôn ayńĪrńĪlńĪr. Bu, sosyal Ňü…ôb…ôk…ôd…ô klasifikasiya funksiyasńĪnńĪ d√ľz…ôltm…ôy…ô m√ľv…ôff…ôqiyy…ôt edir v…ô Ňü…ôxsi klasifikasiya sahib olmayan yazńĪcńĪlar √ľ√ß√ľn he√ß bir m…ôlumat v…ô demografik metadata yoxdur. Bu modell…ôr Twitter'da hissl…ôr analizisinin dońüruluqlarńĪnńĪ v…ô m…ôlumatlarńĪnńĪ d…ôyiŇüdirir.", 'jv': 'Warintang kanggo langkung sapa-sapa sakjane, supoyo iso nggambar tarjamahan sing koyo media sithik lah, ketahan ora sampeyan; perusahaan digawe iso nggawe karo perusahaan resmi nang penyukat. Nang pepul iki, kita sembarang pengguna pembang pengguna tambah sing dadi nggawe salamat luwih apik sing luwih apik bangsa tambah. Panjenengan langkung sampeyan ingkang. Awak dhéwé wayah mengko kuwi nèng dibenakake aturan alat sing is in é ning buturan, ning awak dhéwé kuwi kesempatan ning tinik modèl sing bisa basa, dipujuhé sak nguasai kapan pawaran penyukat nang netujuan sakjane. sing model iki badharsa akeh langgar bantuan kanggo sampeyan pansel Sentimental nang Google lan nganggep dadi nyong.', 'he': 'השינוי בשפה הוא בכל מקום, במיוחד בצורות חדשות יותר של כתיבה כמו מדיה חברתית. למרבה המזל, שוורציה אינה אקראית; זה לעתים קרובות קשור לתכונות חברתיות של הסופר. בעיתון הזה, אנו מראים איך לנצל רשתות חברתיות כדי להפוך ניתוח רגשות חזק יותר לשפת שונות חברתית. הרעיון המפתח הוא הומופיליה שפתית: הנטיה של אנשים שקשורים חברתית להשתמש בשפה בדרכים דומות. אנו פורמלים את הרעיון הזה בארכיטקטורת רשת עצבית שמבוססת על תשומת לב חדשה, שבה תשומת לב מוחלקת בין מספר דוגמנים בסיסיים, בהתאם למיקום של הסופר ברשת החברתית. יש לזה השפעה של להחליק את הפונקציה הסיווגית ברשת החברתית, ומאפשרת לעורר מסווגים אישיים אפילו לכותבים שאין להם נתונים מסוימים או מטאדמוגרפים. מודל זה משפר באופן משמעותי את מדויקת ניתוח הרגשות בטוויטר ובנתונים של ביקורת.', 'ha': "Sauya cikin harshen na'ura ne, hasa'a, cikin takardun kwanan rubutu kamar mitandai da jamii. Babba'a, musamman ba ta zama rabo ba. ko da yawa yana haɗi da dũkiyõyin jamii na mai rubũtãwa. Ga wannan takardan, Munã nũna jinsi za mu yi amfani da mitandao masu jamii dõmin a sanya anadi da hisia mafi ƙaranci zuwa variant na harshen jami. Maɓalli yana da littafin linguistic gayofi: tabar da mutane da ke da haɗuwa a cikin jamii da za'a yi amfani da harshe cikin misãlai. Kana faransa da wannan idãnun a cikin wani bakin tsarin tarakin neura na yanzu a yanzu, a cikinsa akwai muhalli a tsakanin misãlai masu baka, baka kan ma'abũcin marubucin da ke cikin mitandan jamii. Wannan yana da amfani da ya sami aikin classifikari kowace mitandaki na jamii, kuma yana iya iya ƙara wa masu fassarawa masu bastarwa, ko kuwa don a sami wasu data ko metadata na da aka rubũta su. Wannan motel yana ƙara gaskiyar anaƙatan hisãbi a Twitter da kan kure data.", 'sk': 'Spremembe v jeziku so vsepovsod razširjene, zlasti v novejših oblikah pisanja, kot so družbeni mediji. Na srečo variacija ni naključna. Pogosto je povezana s socialnimi lastnostmi avtorja. V tem članku bomo pokazali, kako izkoristiti družabna omrežja, da bi analiza čustva bolj robustna za različne družbene jezike. Ključna ideja je jezikovna homofilija: težnja družbeno povezanih posameznikov, da jezik uporabljajo na podoben način. To idejo formaliziramo v novi pozornosti temelječi nevronski omrežni arhitekturi, v kateri je pozornost razdeljena med več osnovnih modelov, odvisno od avtorjevega položaja v socialnem omrežju. To ima učinek gladke funkcije klasifikacije v družbenem omrežju in omogoča inducijo prilagojenih klasifikatorjev tudi za avtorje, za katere ni označenih podatkov ali demografskih metapodatkov. Ta model bistveno izboljšuje natančnost analize sentimenta na Twitterju in na podatkih pregledov.', 'bo': 'སྐད་ཡིག ཡིན་ནའང་སྤྲོ་བ་དེ་འགྱུར་བ་སྣང་མེད་པར། རྩོམ་པ་པོ་ལ་རང་ཉིད་ཀྱི་སྤྱི་ཚོགས་ཁྱད་ཆོས་དང་འབྲེལ་བ་ཡོད། འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ཇི་ལྟར་ལག་ལེན་བྱེད་མ་ཐུབ་པ་ལ་སྤྱི་ཚོགས་སྐ གལ་ཆེ་བའི་བསམ་ཚུལ་ནི་སྐད་རིགས་ཆེ་ཆུང་ལ་མཚུངས་པ་རེད། སྤྱི་ཚོགས ང་ཚོས་གསར་བ་ལྟ་བུ་དང་མཉམ་དུ་གཞི་བཞག་ཡོད་པའི་མིའུ་རྩལ་འབྲེལ་གྱི་སྒྲིག་འགོད་ནང་གི་ཐབས་ལམ་འདི་སྤྱི་ཚོགས་འབྲེལ་གྱི་གནས་ཡུལ་དང་མཉམ་དུ་ This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata. ཌིས་ཌིར་གྱི་མ་དབྱིབས་དེ་གིས་ཌིས་ཌིར་སྟེང་ནས་སེམས་ཚོར་གྱི་ཆ་གསལ་བཤད་དང་།'}
{'en': 'Semantic Specialization of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints', 'ar': 'التخصص الدلالي لمسافات متجه الكلمات التوزيعية باستخدام قيود أحادية اللغة وعبر اللغات', 'pt': 'Especialização semântica de espaços vetoriais de palavras de distribuição usando restrições monolíngues e entre idiomas', 'es': 'Especialización semántica de espacios vectoriales de palabras distributivas mediante restricciones monolingües y multilinguales', 'fr': "Spécialisation sémantique des espaces vectoriels de mots distributionnels à l'aide de contraintes monolingues et interlinguistiques", 'zh': '用单语、跨语约束者词向量空间语义特化', 'hi': 'मोनोलिंगुअल और क्रॉस-लिंगुअल बाधाओं का उपयोग करके वितरण शब्द वेक्टर रिक्त स्थान की शब्दार्थ विशेषज्ञता', 'ru': 'Семантическая специализация векторных пространств распределения слов с использованием монолингвальных и кросс-лингвальных ограничений', 'ja': '単語およびクロスリンガル制約を使用した分布ワードベクトル空間の意味論的特化', 'ga': 'Speisialtóireacht Shéimeantach ar Spásanna Veicteoir Focal Dáilte ag úsáid Srianta Aonteangacha agus Trastheangacha', 'ka': 'Name', 'el': 'Σημματική εξειδίκευση των διανεμητικών χώρων λέξεων χρησιμοποιώντας μονογλωσσικούς και διαγώνιους περιορισμούς', 'hu': 'Elosztási szóvektorok szemantikus specializálása egynyelvű és többnyelvű korlátozások segítségével', 'it': 'Specializzazione semantica degli spazi vettoriali di parole distribuite utilizzando vincoli monolingue e cross-linguali', 'lt': 'Semantinė paskirstymo žodžių vektorinių erdvių specializacija naudojant monokalbinius ir tarpkalbinius apribojimus', 'kk': 'Біртілі және көшетілі тілі шектеулерді қолдану үшін үлестірілген сөз векторының орындарының семантикалық специализациясы', 'mk': 'Семантичка специјализација на дистрибуционалните векторни простори користејќи монолингуални и крослингуални ограничувања', 'ms': 'Name', 'ml': 'വിതരണ വാക്ക് വെക്റ്റര്\u200d സ്പെയിന്\u200dസ് ഉപയോഗിക്കുന്ന സെമാന്റിക് വിശേഷിപ്പുകള്\u200d', 'mt': 'Speċjalizzazzjoni Semantika tal-Ispazji tal-Vetturi tal-Kliem Distribuzzjonali bl-użu ta’ Restrizzjonijiet Monolingwali u Cross-Lingwali', 'mn': 'Бүлэг хэлний болон олон хэлний хязгаарлалтыг ашиглан хуваарилах үг векторын орон зайны Semantic Specialization of Distribution Word Vector Spaces', 'no': 'Semantisk spesialisering av distribusjonelle ordvektorplassar ved bruk av monolingsk og krysslingsbegrensningar', 'pl': 'Specjalizacja semantyczna dystrybucyjnych przestrzeni wektorowych słowa z wykorzystaniem ograniczeń jednojęzycznych i między językami', 'ro': 'Specializarea semantică a spațiilor vectoriale de cuvinte distribuționale folosind constrângeri monolingve și interlingve', 'sr': 'Semantička specijalizacija distribucijskih vektorskih prostora korištenja monolingviskih i krstolingviskih ograničenja', 'so': 'Semantic Specialization of Distribution Word Vector Spaces using Monolingual and Cross-Lingual Constraints', 'si': 'Name', 'sv': 'Semantisk specialisering av distributionsvektorutrymmen med enspråkiga och tvärspråkliga begränsningar', 'ta': 'Name', 'ur': 'سیمنٹی ویکسٹر جگہ کا تقسیم کرنا', 'uz': 'Name', 'vi': 'Phân biệt chủng hóa các khu vực phát từ cổ tích bằng cấm ngôn ngữ và chữ thập', 'nl': 'Semantische specialisatie van distributionele woordvectorruimten met behulp van monolinguale en crosslinguale beperkingen', 'bg': 'Семантична специализация на разпределителни пространства за вектори на думи, използващи едноезични и междуезични ограничения', 'da': 'Semantisk specialisering af fordelingsordvektorrum ved hjælp af ensprogede og tværsprogede begrænsninger', 'hr': 'Semantička specijalizacija distribucijskih prostora vektora riječi koristeći monojezičke i krstojezičke ograničenje', 'de': 'Semantische Spezialisierung von verteilten Wortvektorräumen unter Verwendung von ein- und sprachlichen Einschränkungen', 'ko': '단어와 크로스 언어의 제약을 바탕으로 하는 분포어 벡터 공간적 의미 특화', 'id': 'Spesialisasi Semantik dari Ruang Vektor Kata Distribusional menggunakan Perbatasan Monolingual dan Cross-Lingual', 'fa': 'استفاده از محدوده\u200cهای یک زبان و یک زبان متوسط', 'sw': 'Tafsiri ya Utafiti wa Sauti za Utafiti kwa kutumia mashindano ya Kimonolinguli na Kilingua', 'tr': 'Monoli dilli we Çapraz Dilli Hatlar ullanýän Distributional Word Vector Spaces', 'af': 'Name', 'sq': 'Specializimi Semantik i hapësirave të vektorit të fjalëve shpërndarë duke përdorur kufizimet monolinguale dhe translinguale', 'am': 'Language', 'hy': 'Տարբերական բառերի բաժանման տարածքների սեմանտիկ մասնագիտացումը՝ օգտագործելով միալեզու և խաչլեզու սահմանափակումներ', 'az': 'Monoli dil v…ô √á…ôrz Dil S…ôtirl…ôrini istifad…ô ed…ôn Distributional Word Vector Spaces', 'bn': 'মোনোলিভাল এবং ক্রস- লিঙ্গুয়াল কন্স্ট্রেন্ট ব্যবহার করে বিতরণের শব্দ ভেক্টর স্পেসের সেম্যান্টিক বিশেষ বিশ', 'bs': 'Semantička specijalizacija distribucijskih prostora vektora riječi koristeći monolingviske i krstolingviske ograničenje', 'ca': 'Specialització Semàtica dels espais de vectors de paraules distribucionals utilitzant restriccions monolíngues i translíngues', 'cs': 'Sémantická specializace distribučních slovních vektorových prostorů s využitím jednojjazyčných a křížových omezení', 'et': 'Jaotud sõnavaktoriruumide semantiline spetsialiseerumine ühekeelsete ja keeleüleste piirangute abil', 'fi': 'Jakelullisten sanavektoritilojen semanttinen erikoistuminen monikielisten ja monikielisten rajoitusten avulla', 'jv': 'semianti Specialization', 'ha': 'KCharselect unicode block name', 'he': 'Semantic Specialization of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints', 'sk': 'Semantna specializacija distribucijskih besednih vektorskih prostorov z uporabo enojezičnih in medjezikovnih omejitev', 'bo': 'Semantic Specialization of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints'}
{'en': 'We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialized vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.', 'ar': 'نقدم Attract-Repel ، وهي خوارزمية لتحسين الجودة الدلالية لمتجهات الكلمات عن طريق حقن قيود مستخرجة من الموارد المعجمية. يسهل Attract-Repel استخدام القيود من الموارد أحادية اللغة وعبر اللغات ، مما ينتج عنه مساحات متجهية متخصصة لغويًا متعددة اللغات. يُظهر تقييمنا أن الطريقة يمكن أن تستفيد من المعاجم الموجودة عبر اللغات لإنشاء مساحات متجهة عالية الجودة لعدد كبير من اللغات المختلفة ، مما يسهل النقل الدلالي من اللغات ذات الموارد العالية إلى منخفضة الموارد. تتضح فعالية نهجنا من خلال أحدث النتائج على مجموعات بيانات التشابه الدلالي بست لغات. نوضح بعد ذلك أن الموجهات المتخصصة في Attract-Repel تعزز الأداء في المهمة النهائية لتتبع حالة الحوار (DST) عبر لغات متعددة. أخيرًا ، نوضح أن المساحات المتجهة عبر اللغات التي تنتجها خوارزمية لدينا تسهل تدريب نماذج التوقيت الصيفي متعددة اللغات ، مما يؤدي إلى مزيد من التحسينات في الأداء.', 'pt': 'Apresentamos o Attract-Repel, um algoritmo para melhorar a qualidade semântica de vetores de palavras por meio da injeção de restrições extraídas de recursos lexicais. O Attract-Repel facilita o uso de restrições de recursos mono e multilíngues, produzindo espaços vetoriais multilíngues semanticamente especializados. Nossa avaliação mostra que o método pode fazer uso de léxicos multilíngues existentes para construir espaços vetoriais de alta qualidade para uma infinidade de idiomas diferentes, facilitando a transferência semântica de idiomas de alto para baixo recurso. A eficácia de nossa abordagem é demonstrada com resultados de última geração em conjuntos de dados de semelhança semântica em seis idiomas. Em seguida, mostramos que os vetores especializados em Attract-Repel aumentam o desempenho na tarefa downstream de rastreamento de estado de diálogo (DST) em vários idiomas. Por fim, mostramos que os espaços vetoriais multilíngues produzidos pelo nosso algoritmo facilitam o treinamento de modelos DST multilíngues, o que traz melhorias adicionais de desempenho.', 'fr': "Nous présentons Attract-Repel, un algorithme permettant d'améliorer la qualité sémantique des vecteurs de mots en injectant des contraintes extraites de ressources lexicales. Attract-Repel facilite l'utilisation des contraintes provenant de ressources multilingues et multilingues, produisant des espaces vectoriels multilingues spécialisés sur le plan sémantique. Notre évaluation montre que la méthode peut utiliser des lexiques multilingues existants pour construire des espaces vectoriels de haute qualité pour une pléthore de langues différentes, facilitant ainsi le transfert sémantique de langues à ressources élevées vers des langues plus faibles. L'efficacité de notre approche est démontrée par des résultats de pointe sur des ensembles de données de similarité sémantique en six langues. Nous montrons ensuite que les vecteurs spécialisés Attract-Repel améliorent les performances dans la tâche en aval du suivi de l'état du dialogue (DST) dans plusieurs langues. Enfin, nous montrons que les espaces vectoriels multilingues produits par notre algorithme facilitent l'apprentissage de modèles DST multilingues, ce qui apporte d'autres améliorations de performances.", 'es': 'Presentamos Attract-Repel, un algoritmo para mejorar la calidad semántica de los vectores de palabras mediante la inyección de restricciones extraídas de los recursos léxicos. Attract-Repel facilita el uso de restricciones de recursos monolingües e interlingües, generando espacios vectoriales multilingües semánticamente especializados. Nuestra evaluación muestra que el método puede utilizar los léxicos multilingües existentes para construir espacios vectoriales de alta calidad para una gran cantidad de idiomas diferentes, lo que facilita la transferencia semántica de los de recursos altos a los más bajos. La eficacia de nuestro enfoque se demuestra con resultados de vanguardia en conjuntos de datos de similitud semántica en seis idiomas. A continuación, mostramos que los vectores especializados en Attract-Repele aumentan el rendimiento en la tarea posterior del seguimiento del estado de diálogo (DST) en varios idiomas. Por último, demostramos que los espacios vectoriales multilingües producidos por nuestro algoritmo facilitan la capacitación de modelos de DST multilingües, lo que aporta mejoras adicionales en el rendimiento.', 'ja': '我々は、語彙リソースから抽出された制約を注入することによって、単語ベクトルの意味的品質を向上させるためのアルゴリズムである、アトラクト・リペルを提示する。Attract - Repelは、単一言語リソースとクロス言語リソースからの制約の使用を容易にし、意味的に特化したクロス言語ベクトル空間をもたらします。私たちの評価は、この方法が既存のクロスリンガル辞書を利用して、多種多様な言語のための高品質のベクトル空間を構築し、高リソースから低リソースへのセマンティック転送を容易にすることができることを示しています。私たちのアプローチの有効性は、6つの言語のセマンティック類似性データセットに関する最先端の結果で実証されています。次に、複数の言語にまたがるダイアログ状態トラッキング（ DST ）の下流タスクにおけるパフォーマンスを向上させるアトラクト-リペル専用ベクトルを示します。最後に、私たちのアルゴリズムによって生成されたクロスリンガルベクトル空間が、さらなるパフォーマンス向上をもたらす多言語DSTモデルのトレーニングを促進することを示します。', 'zh': '吾建Tuct-Repel,此词汇资之约束以重词向量语义量之数也。 Attract-Repel有助于单语言跨语之资,而生语义上特化跨语向量间。 吾评明其法,可以跨语词典,构高质量向量间,趣从高资言语至低资源语语义移。 吾法有效性以六语语义相似性数集之最新验也。 接下,我们将展示吸引排排专用向量可以崇跨多种语言的对话跟 (DST) 下流任的性能。 最后,我们算法所生的跨语向量空间有助于多语言DST模样的训练,所以更加性能改进。', 'ru': 'Представляем Attract-Repel, алгоритм улучшения семантического качества векторов слов путем введения ограничений, извлеченных из лексических ресурсов. Attract-Repel облегчает использование ограничений от моно- и кросс-лингвистических ресурсов, давая семантически специализированные кросс-лингвистические векторные пространства. Наша оценка показывает, что метод может использовать существующие кросс-лингвальные лексиконы для построения высококачественных векторных пространств для множества разных языков, облегчая семантический перенос с высокоресурсных на низкоресурсные. Эффективность нашего подхода демонстрируется самыми современными результатами по наборам данных семантического сходства на шести языках. Далее мы показываем, что специальные векторы Attract-Repel повышают производительность в последующем задании отслеживания состояния диалога (DST) на нескольких языках. Наконец, мы показываем, что межязычные векторные пространства, созданные нашим алгоритмом, облегчают обучение многоязычным моделям DST, что приносит дальнейшие улучшения производительности.', 'hi': 'हम आकर्षित-Repel, लेक्सिकल संसाधनों से निकाले गए बाधाओं को इंजेक्ट करके शब्द वैक्टर की शब्दार्थ गुणवत्ता में सुधार के लिए एक एल्गोरिथ्म प्रस्तुत करते हैं। आकर्षित-रिपेल मोनो- और क्रॉस-लिंगुअल संसाधनों से बाधाओं के उपयोग की सुविधा प्रदान करता है, जिससे शब्दार्थ रूप से विशेष क्रॉस-भाषी वेक्टर रिक्त स्थान प्राप्त होते हैं। हमारे मूल्यांकन से पता चलता है कि विधि विभिन्न भाषाओं की अधिकता के लिए उच्च गुणवत्ता वाले वेक्टर रिक्त स्थान का निर्माण करने के लिए मौजूदा क्रॉस-लिंगुअल शब्दकोशों का उपयोग कर सकती है, जिससे उच्च से कम-संसाधन वाले लोगों तक शब्दार्थ हस्तांतरण की सुविधा मिलती है। हमारे दृष्टिकोण की प्रभावशीलता को छह भाषाओं में शब्दार्थ समानता डेटासेट पर अत्याधुनिक परिणामों के साथ प्रदर्शित किया जाता है। हम अगले दिखाते हैं कि आकर्षित-Repel-विशेष वैक्टर कई भाषाओं में संवाद राज्य ट्रैकिंग (DST) के डाउनस्ट्रीम कार्य में प्रदर्शन को बढ़ावा देते हैं। अंत में, हम दिखाते हैं कि हमारे एल्गोरिथ्म द्वारा उत्पादित क्रॉस-लिंगुअल वेक्टर रिक्त स्थान बहुभाषी डीएसटी मॉडल के प्रशिक्षण की सुविधा प्रदान करते हैं, जो आगे प्रदर्शन में सुधार लाता है।', 'ga': 'Cuirimid Attract-Repel i láthair, algartam chun cáilíocht shéimeantach veicteoirí focal a fheabhsú trí shrianta a bhaintear as acmhainní foclóireachta a instealladh. Éascaíonn Attract-Repel úsáid srianta ó acmhainní aonteangacha agus tras-teangacha, ag cruthú spásanna veicteora tras-teangacha speisialaithe go seimeantach. Léiríonn ár measúnú gur féidir leis an modh úsáid a bhaint as foclóirí trasteangacha atá ann cheana féin chun spásanna veicteora ardcháilíochta a thógáil do raidhse teangacha éagsúla, ag éascú aistriú shéimeantach ó na cinn ard-acmhainne go dtí na teangacha ísle. Léirítear éifeachtacht ár gcur chuige le torthaí den scoth ar thacair sonraí cosúlachta shéimeantacha i sé theanga. Léirímid an chéad uair eile go gcuireann veicteoirí speisialaithe Attract-Repel le feidhmíocht sa tasc iartheachtach de rianú stáit idirphlé (DST) thar teangacha iolracha. Ar deireadh, léirímid go n-éascaíonn spásanna veicteora tras-teangacha arna dtáirgeadh ag ár n-algartam oiliúint samhlacha ilteangacha DST, rud a thugann feabhsuithe feidhmíochta breise.', 'hu': 'Bemutatjuk az Attract-Repel algoritmust, amely a szóvektorok szemantikai minőségének javítására szolgál lexikai erőforrásokból kivont korlátozások befecskendezésével. Az Attract-Repel megkönnyíti a mononyelvű és többnyelvű erőforrásokból származó korlátozások használatát, ami szemantikailag speciális, többnyelvű vektortereket eredményez. Értékelésünk azt mutatja, hogy a módszer a meglévő, többnyelvű lexikonok felhasználásával kiváló minőségű vektortereket építhet különböző nyelvek számára, elősegítve a szemantikai átvitelt a magas és alacsonyabb erőforrású nyelvekről. Megközelítésünk hatékonyságát hat nyelven nyújtott szemantikai hasonlósági adatkészletek korszerű eredményei bizonyítják. Ezután megmutatjuk, hogy az Attract-Repel speciális vektorok növelik a teljesítményt a párbeszédállapot követésének (DST) downstream feladatában több nyelven. Végezetül megmutatjuk, hogy algoritmusunk által létrehozott többnyelvű vektorterek megkönnyítik a többnyelvű DST modellek képzését, ami további teljesítményfejlesztést eredményez.', 'el': 'Παρουσιάζουμε έναν αλγόριθμο για τη βελτίωση της σημασιολογικής ποιότητας των διανυσμάτων λέξεων με την εισαγωγή περιορισμών που εξάγονται από λεξικούς πόρους. Το διευκολύνει τη χρήση περιορισμών από μονογλωσσικούς και διαγώνιους πόρους, παρέχοντας σημασιολογικά εξειδικευμένους διαγώνιους διανυσματικούς χώρους. Η αξιολόγησή μας δείχνει ότι η μέθοδος μπορεί να χρησιμοποιήσει τα υπάρχοντα διαγώνια λεξικά για να κατασκευάσει υψηλής ποιότητας διανυσματικούς χώρους για μια πληθώρα διαφορετικών γλωσσών, διευκολύνοντας τη σημασιολογική μεταφορά από υψηλές σε χαμηλότερες γλώσσες. Η αποτελεσματικότητα της προσέγγισής μας καταδεικνύεται με αποτελέσματα τελευταίας τεχνολογίας σε σύνολα σημασιολογικών ομοιοτήτων σε έξι γλώσσες. Στη συνέχεια, δείχνουμε ότι τα εξειδικευμένα διανύσματα έλξης-απωθήσεως ενισχύουν την απόδοση στο καθήκον παρακολούθησης κατάστασης διαλόγου σε πολλές γλώσσες. Τέλος, δείχνουμε ότι οι διαγώνσιοι διανυσματικοί χώροι που παράγονται από τον αλγόριθμο μας διευκολύνουν την εκπαίδευση πολύγλωσσων μοντέλων DST, γεγονός που επιφέρει περαιτέρω βελτιώσεις απόδοσης.', 'ka': 'ჩვენ ატრაქტი-რეპელი, ალგორიტიმ სიტყვის გვექტორის სიმენტიკური კაalitეტის უფრო მეტადებლად, ლექსიკური რესურსებიდან გამოყენებული ზომილებების ინტექტირებით. Name ჩვენი განსაზღვრება აჩვენებს, რომ მეტი შეუძლია გამოიყენოთ ძალიან მრავალური ლექსიკონების გამოყენებას, რომლებიც უფრო კარგად განსხვავებული ენების სამუშაოდ გვექტორის სივრცესების გარეშე ჩვენი წარმოდგენის ეფექტიურობა ექსმონტიკური მონაცემებით ქვსი ენაში სემონტიკური მონაცემებით. ჩვენ შემდეგ ჩვენ აჩვენებთ, რომ Attract-Repel-სპეციალური გვექტორები უფრო მეტი ენათების განმავლობაში დიალოგის სტატურის მონაცემის მომხმარების მომხმარებაში გამ საბოლოოდ, ჩვენ ჩვენ ჩვენი ალგორიტიმზე გამოვიყენებული მრავალენგური DST მოდელების შემწყენება, რომელიც უფრო მეტად გამოვიყენება.', 'it': "Vi presentiamo Attract-Repel, un algoritmo per migliorare la qualità semantica dei vettori di parole iniettando vincoli estratti da risorse lessicali. Attract-Repel facilita l'uso di vincoli da risorse mono e cross-lingual, producendo spazi vettoriali cross-lingual semanticamente specializzati. La nostra valutazione mostra che il metodo può utilizzare i lessici cross-linguali esistenti per costruire spazi vettoriali di alta qualità per una pletora di lingue diverse, facilitando il trasferimento semantico da quelli ad alta a bassa risorsa. L'efficacia del nostro approccio è dimostrata con risultati all'avanguardia su set di dati di somiglianza semantica in sei lingue. Mostriamo poi che i vettori specializzati Attract-Repel aumentano le prestazioni nell'attività a valle del monitoraggio dello stato di dialogo (DST) in più lingue. Infine, mostriamo che gli spazi vettoriali cross-lingual prodotti dal nostro algoritmo facilitano la formazione di modelli DST multilingue, il che porta ulteriori miglioramenti delle prestazioni.", 'lt': 'Pateikiame Attract-Repel algoritmą, kuriuo siekiama pagerinti žodžių vektorių semantinę kokybę įšvirkštus iš leksinių išteklių išgautus apribojimus. Attract-Repel palengvina monokalbinių ir tarpkalbinių išteklių suvaržymų naudojimą, suteikiant semantiškai specializuotus tarpkalbinius vektorius. Mūsų vertinimas rodo, kad metodas gali naudoti esamus tarpkalbinius leksikonus aukštos kokybės vektorių erdvėms kurti daugeliui skirtingų kalbų, palengvinant semantinį perkėlimą iš aukšto išteklių į mažesnius. Mūsų požiūrio veiksmingumas įrodomas naujausiais semantinio panašumo duomenų rinkinių rezultatais šešiomis kalbomis. Toliau parodysime, kad traukti-pakartoti specializuoti vektoriai didina rezultatus tolesnėje dialogo būklės sekimo (DST) užduotyje įvairiose kalbose. Galiausiai parodome, kad mūsų algoritmu pagamintos tarpkalbės vektorių erdvės palengvina daugiakalbių DST modelių mokymą, o tai dar labiau pagerina našumą.', 'mk': 'We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources.  Attract- Repel го олеснува употребата на ограничувања од монојазичните и прекујазичните ресурси, што дава семантично специјализирани прекујазични векторни простори. Нашата оценка покажува дека методот може да ги искористи постојните меѓујазични лексикони за изградба на висококвалитетни векторни простори за многумина различни јазици, олеснувајќи го семантичкиот трансфер од оние со високи до пониски ресурси. Ефикасноста на нашиот пристап е демонстрирана со најновите резултати на семантичните податоци за сличност на шест јазици. Следно ќе покажеме дека специјализираните вектори Attract-Repel ги зголемуваат резултатите во понатамошната задача на дијалогот за следење на состојбата (DST) преку повеќе јазици. Конечно, покажуваме дека меѓујазичните векторни простори произведени од нашиот алгоритм го олеснуваат обуката на мултијазичните ДСТ модели, што доведе до понатамошни подобрувања на перформансата.', 'kk': 'Біз Attract-Repel, лексикалық ресурстардан тартылған шектерді инжекциялау үшін сөздердің semantiкалық сапасын жақсарту алгоритмін таңдаймыз. Attract- Repel моно- және көп тілді ресурстардан шектеулерді қолдануға мүмкіндік береді, semantically специализияланған көп тілді вектор бос орын береді. Біздің оқиғамыз, әдісіміз бірнеше тілдер үшін көптеген тілдерден төменгі ресурстардан ең сапатты вектор бос орындарды құру үшін бір-бірінші тілдерді қолдануға болады. Біздің тәртібіміздің эффектілігіміз, семантикалық ұқсас деректер жиындарының алты тілде көрсетіледі. Біз келесіден "Attract-Repel" специализияланған векторлар диалог күйін қадағалау (DST) тапсырмасының төменгі тапсырмасын бірнеше тілдерде көтереді. Соңында, біз алгоритміздің көп тілді DST үлгілерін оқытуға көмектеседі, бұл көптеген жұмыс істеу үшін бірнеше тілді векторлық бос орындарды көрсетедік.', 'ml': 'ലെക്സിക്കല്\u200d വിഭവങ്ങളില്\u200d നിന്നും പുറത്തെടുക്കുന്ന നിര്\u200dബന്ധങ്ങള്\u200d പ്രവേശിപ്പിക്കുന്നതിനാല്\u200d വാക്ക് വെക്റ്ററുകളുടെ സെമ ആട്രാക്റ്രാക്റ്റ്- റിപ്പെല്\u200d ചെയ്യുന്നതിന് മോണോ- ക്രില്\u200dഭാഷയുടെ വിഭവങ്ങളില്\u200d നിന്നും നിര്\u200dബന്ധങ്ങള്\u200d ഉപയോഗിക്കുന്നതിന് ഉപയ നമ്മുടെ വിലാസങ്ങള്\u200d കാണിക്കുന്നുവെങ്കില്\u200d നിലവിലുള്ള ലെക്സിക്കോണുകള്\u200d ഉപയോഗിക്കുന്ന രീതി നമ്മുടെ സമ്പ്രദായത്തിന്റെ പ്രഭാവം ആറു ഭാഷകളില്\u200d സെമാന്റിക്ക് തുല്യമായ ഡാറ്റാസറ്റുകളില്\u200d രാജ്യത്തിന്റെ ഫലങ് പിന്നീട് നമ്മള്\u200d കാണിക്കുന്നത് പല ഭാഷകളിലുമുള്ള ഡയലോഗ് സ്റ്റേറ്റ് സ്റ്റേറ്റ് ട്രാക്കിങ്ങിന്\u200dറെ (DST) ഡിസ്റ്റ് ട്ര അവസാനം, ഞങ്ങള്\u200d കാണിച്ചു തരുന്നത് നമ്മുടെ ആല്\u200dഗോരിതം ഉല്\u200dപാദിപ്പിക്കുന്ന ക്രിസ്ലിങ്ങ് വെക്റ്റര്\u200d സ്പെയിസ്റ്റര്\u200d സ്പെയിസ്റ', 'ms': 'Kami perkenalkan Attract-Repel, algoritma untuk meningkatkan kualiti semantik vektor perkataan dengan menyuntik keterangan yang dikeluarkan dari sumber leksikal. Attract- Repel memudahkan penggunaan halangan dari sumber mono- dan saling- bahasa, menghasilkan ruang vektor saling- bahasa yang istimewa secara semantik. Evaluasi kami menunjukkan bahawa kaedah ini boleh menggunakan leksikon saling bahasa yang wujud untuk membina ruang vektor berkualiti tinggi untuk banyak bahasa yang berbeza, memudahkan pemindahan semantik dari sumber tinggi ke sumber rendah. Keefektivitas pendekatan kita dipastikan dengan keputusan terbaik pada set data sememangan semantik dalam enam bahasa. Kita berikutnya tunjukkan bahawa vektor khusus Attract-Repel meningkatkan prestasi dalam tugas turun bagi pengesan keadaan dialog (DST) melalui berbilang bahasa. Akhirnya, kita menunjukkan bahawa ruang vektor saling bahasa yang dihasilkan oleh algoritma kami memudahkan latihan model DST berbilang bahasa, yang membawa perkembangan prestasi lanjut.', 'mt': 'Aħna nippreżentaw Attract-Repel, algoritmu għat-titjib tal-kwalità semantika tal-vetturi tal-kliem billi ninjettaw restrizzjonijiet estratti mir-riżorsi lexiċi. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialized cross-lingual vector spaces.  L-evalwazzjoni tagħna turi li l-metodu jista’ jagħmel użu minn lexicons translingwi eżistenti biex jinbnew spazji ta’ vetturi ta’ kwalità għolja għal plethora ta’ lingwi differenti, li jiffaċilitaw it-trasferiment semantiku minn dawk b’riżorsi għoljin għal dawk b’riżorsi baxxi. L-effikaċja tal-approċċ tagħna tintwera b’riżultati l-aktar avvanzati dwar settijiet ta’ dejta semantiċi ta’ similarità f’sitt lingwi. Imbagħad naraw li l-vetturi speċjalizzati fl-Attract-Repel jagħtu spinta lill-prestazzjoni fil-kompitu downstream tat-traċċar tal-istat tad-djalogu (DST) f’diversi lingwi. Fl-aħħar nett, nuru li l-ispazji ta’ vetturi translingwi prodotti mill-algoritmu tagħna jiffaċilitaw it-taħriġ ta’ mudelli multilingwi DST, li jġibu titjib ulterjuri fil-prestazzjoni.', 'mn': 'Бид Attract-Repel-г илтгэх алгоритм гэдэг үгний векторуудын semantic quality-ыг сайжруулахын тулд хэмжээсүүдийг лексикийн нөөц баасаас гаргасан хязгаарлалтыг инжекцирч өгдөг. Attract-Repel нь моно-болон олон хэл баялаг ашиглах хязгаарлалтуудыг ашиглаж, semantically специалист олон хэл векторын орон зайг өгдөг. Бидний оюун шалгалт нь энэ арга нь олон хэл дээр, бага боловсруулагдсан хэл дээр, өндөр чанартай векторын зай бүтээх боломжтой болно гэдгийг харуулж байна. Бидний ойлголтын үр дүнтэй байдал нь зургаан хэл дээр semantic similarity өгөгдлийн сангийн үр дүнтэй харагдаж байна. Дараа нь Attract-Repel-ийн мэргэжлийн векторууд диалогын байр суурь дагаварын ажил (DST) дээр олон хэл дээр ажиллаж байгааг харуулж байна. Эцэст нь бид бидний алгоритмын бий болсон олон хэлний ДНХ загварын сургалтыг нэмэгдүүлэх боломжтой болгон хэлний вектор зайг харуулж байна.', 'no': 'Vi presenterer Attract-Repel, ein algoritme for å forbetra semantisk kvalitet på ordvektorar ved å injisera begrensningar utpakka frå leksiske ressursar. Attrakt- Repel gjer bruk av begrensningar frå mono- og krysspråk- ressursar, som gjer semantisk spesialiserte krysspråk vektormellomrom. Vårt evaluering viser at metoden kan bruka eksisterande krysspråk- leksikonsar for å konstruere vektormellomrom med høg kvalitet for ein plethora av ulike språk, som gjer tilgjengeleg semantisk overføring frå høg til lågare ressursar. Effektiviteten av tilnærminga vårt er demonstrert med kunsttilstanden på semantiske tilnærmingsdata i seks språk. Vi viser neste at «Attract-Repel-specialiserte vektorar» styrer utviklinga i nedtrekkoppgåva til dialogtilstand-sporing (DST) på fleire språk. I slutt viser vi at krysspråk vektormellomrom som er produsert av algoritmen vårt er lett opplæring av fleirspråk DST-modeller, som fører fram forbedringar av utviklingar.', 'pl': 'Prezentujemy Attract-Repel, algorytm służący poprawie jakości semantycznej wektorów słowa poprzez wstrzykiwanie ograniczeń ekstraktowanych z zasobów leksykalnych. Attract-Repel ułatwia wykorzystanie ograniczeń z zasobów jedno- i wielojęzycznych, dając semantycznie specjalistyczne przestrzenie wektorowe wielojęzyczne. Z naszej oceny wynika, że metoda ta może wykorzystać istniejące leksykony wielojęzyczne do konstruowania wysokiej jakości przestrzeni wektorowej dla wielu różnych języków, ułatwiając przenoszenie semantyczne z wysokich do mniejszych języków. Skuteczność naszego podejścia została wykazana najnowocześniejszymi wynikami dotyczącymi zbiorów podobieństw semantycznych w sześciu językach. Następnie pokazujemy, że wektory specjalistyczne Attract-Repel zwiększają wydajność w dalszym zadaniu śledzenia stanu dialogu (DST) w wielu językach. Wreszcie pokazujemy, że wielojęzyczne przestrzenie wektorowe produkowane przez nasz algorytm ułatwiają szkolenie wielojęzycznych modeli DST, co przynosi dalsze poprawy wydajności.', 'sr': 'Predstavljamo Attract-Repel, algoritam za poboljšanje semantičke kvalitete rečnih vektora injiciranjem ograničenja izvedenih iz leksičkih resursa. Attract-Repel olakšava korištenje ograničenja iz monojezičkih i krstojezičkih resursa, pružajući semantički specijalizovane krstojezičke vektorske prostore. Naša procjena pokazuje da metod može iskoristiti postojeće međujezičke leksikone kako bi izgradili visoke kvalitetne vektorske prostore za plethoru različitih jezika, olakšavajući semantički prijenos od visokih na manje resurse. Efikasnost našeg pristupa se pokazuje sa rezultatima stanja umjetnosti na semantičkim setima podataka sličnosti na šest jezika. Sljedeći pokazujemo da su specijalizovani vektori Attract-Repel povećali učinkovitost u donjem zadatku praćenja država dijaloga (DST) na višestrukim jezicima. Konačno, pokazujemo da međujezički vektorski prostor proizvođen našim algoritmom olakšava obuku multijezičkih DST modela, koji donosi daljnje poboljšanje učinka.', 'so': 'We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources.  Jabsel-Repel wuxuu ka caawinayaa isticmaalidda qasabka laga isticmaalo hantida afka iyo luqadaha kala duduwan, kaas oo sababto goobaha kala duduwan oo kala duduwan. Qiimeyntayada ayaa muuqan kara in qaababka uu isticmaali karo leksikayaasha luuqadaha kala duduwan si uu u dhiso meelo wado oo sare oo ay u dhisaan luqado kala duduwan, oo uu ka caawinayo wareejinta semantika kor-hoose-hoose. Shaqo u yeelashada qaababkayaga waxaa lagu muujiyaa resultinta dowladda farshaxanka oo ku saabsan sawirada isku mid ah lix luuqadood. Waxaynu soo xigtaa tusaynaa in qalabka jabsada-Repel-specialized ay ku boostaan tababarka hoose-dur oo ah shaqooyinka dialog-state tracking (DST) oo luuqado kala duduwan. Ugu dambaysta, waxaynu tusnaynaa in goobaha wadooyinka luuqadaha kala duduwan ee algorithimadeenna lagu soo bixiyey uu u sawiraa waxbarashada modelalka DST oo luuqadaha kala duduwan, taasoo horumarinta horumarinta horumarka.', 'sv': 'Vi presenterar Attract-Repel, en algoritm för att förbättra den semantiska kvaliteten på ordvektorer genom att injicera begränsningar extraherade från lexikala resurser. Attract-Repel underlättar användningen av begränsningar från mono- och tvärspråkliga resurser, vilket ger semantiskt specialiserade tvärspråkliga vektorutrymmen. Vår utvärdering visar att metoden kan använda sig av befintliga korspråkiga lexikon för att konstruera högkvalitativa vektorutrymmen för en mängd olika språk, vilket underlättar semantisk överföring från höga till lägre resurser. Effektiviteten av vårt tillvägagångssätt demonstreras med state-of-the-art resultat på semantiska likhetsdata på sex språk. Därefter visar vi att Attract-Repel-specialiserade vektorer ökar prestandan i efterföljande uppgiften att spåra dialogtillstånd (DST) över flera språk. Slutligen visar vi att korspråkiga vektorutrymmen som produceras av vår algoritm underlättar utbildning av flerspråkiga DST-modeller, vilket ger ytterligare prestandaförbättringar.', 'si': 'අපි ප්\u200dරදේශ කරනවා Atttrac-Rapel, ඇල්ගෝරිතම් වචන වෙක්ටර්ගේ සෙමැන්ටික කුණාවක් විශේෂ කරනවා ලෙක්සිකල් සම්බන්ධයෙන් පි Name අපේ විශ්ලේෂණය පෙන්වන්නේ විදියට ප්\u200dරවේශයක් තියෙන්න පුළුවන් විශේෂ වෙක්ටර් ස්ථානයක් වෙනස් භාෂාවක් සඳහා විශේෂ භාෂාව අපේ පරීක්ෂණයේ ප්\u200dරශ්ණතාවය පෙන්වන්නේ සෙමැන්ටික් සමාන්\u200dය දත්ත සෙට්ටුවට භාෂාවක් හතරයි. අපි ඊළඟ පෙන්වන්නේ Atttrack-Rapel-විශේෂ වෙක්ටර් විශේෂ වෙක්ටර් ක්\u200dරියාත්මක වැඩ කරනවා සංවාද ස්ථානය පරීක්ෂණය අන්තිමේදී, අපි පෙන්වන්නේ අපේ ඇල්ගෝරිතම් වලින් භාෂාවක් වෙක්ටර් ස්ථානයක් අපේ ඇල්ගෝරිතම් වලින් ප්\u200dරයෝජනය කරන්න', 'ta': 'வார்த்தை நெறிகளை மேம்படுத்துவதற்கு நாம் அட்டாக்கு - மீள்நிறுத்துகிறோம், லெக்சிக்சியல் மூலங்களிலிருந்து வெளியேற்றப் Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialized cross-lingual vector spaces.  எங்கள் மதிப்பு காண்பிக்கும் முறைமையில் இருக்கும் பல மொழிகளுக்கு உயர்தரமான நெக்கார இடைவெளிகளை உருவாக்க முடியும், அதிக மூலத்திலிருந்து குறைந்த மூலத எங்கள் செயல்பாட்டின் விளைவு ஆறு மொழிகளில் பாதிப்பு சமமான தகவல் அமைப்புகளின் நிலையில் கலை முடிவுகள் காண்பிக்கப் நாம் அடுத்து காட்டுகிறோம் பல மொழிகளில் உள்ள உரையாடல் நிலை பின்பற்றிய செயல்பாட்டின் கீழே உள்ள செயல்பாட்டை அதிகரிக்கிறது. இறுதியில், நாம் காட்டுகிறோம் பல மொழி DST மாதிரிகளில் உருவாக்கப்பட்டுள்ள இடைவெக்டார் இடைவெளிகள், அது மேலும் செயல்பாடு முன்னேற்', 'ur': 'ہم نے Attract-Repel کو ایک الگوریتم مقرر کر دیا ہے کہ لکسیکل سرمالوں سے نکالے ہوئے محدودیت کو تزریق کریں۔ Attract-Repel نے mono- and cross-lingual resources سے محدودیت کا استعمال کرنا آسان کیا ہے، جسے semantically specialized cross-lingual vector spaces دے رہا ہے. ہمارا ارزیابی دکھاتا ہے کہ یہ طریقہ موجود cross-lingual lexicons کے استعمال کر سکتا ہے کہ بہت سی کیفیت ویکتور جگہ بنانے کے لئے مختلف زبانوں کی جگہ بنا سکتا ہے، اور اس طرح سیمانتیک ترنسیٹ بالا - نیچے منزلوں سے آسان کر سکتا ہے. ہمارے طریقے کی تابعداری چھ زبانوں میں سیمانتی سیمانتی ڈاٹ سٹ کے نتائج کے ساتھ دکھائی جاتی ہے. ہم اگلے دکھاتے ہیں کہ Attract-Repel-specialized vectors بڑھاتے ہیں ڈالیٹ ٹراکینگ (DST) کے دنبال میں بہت سی زبانوں میں۔ آخر میں، ہم دکھاتے ہیں کہ ہمارے الگوریتم سے پیدا ہوئے کرس زبان ویکتور فضائے بہت سی زبان ڈیس ٹی موڈل کی تعلیم آسانی کرتی ہیں، جو اضافہ کرتی ہے۔', 'ro': 'Vă prezentăm Attract-Repel, un algoritm pentru îmbunătățirea calității semantice a vectorilor de cuvinte prin injectarea constrângerilor extrase din resurse lexicale. Atract-Repel facilitează utilizarea constrângerilor din resurse mono- și cross-lingual, generând spații vectoriale cross-lingual specializate semantic. Evaluarea noastră arată că metoda poate utiliza lexicoanele translingve existente pentru a construi spații vectoriale de înaltă calitate pentru o multitudine de limbi diferite, facilitând transferul semantic de la cele cu resurse mari la cele cu resurse mici. Eficiența abordării noastre este demonstrată prin rezultate de ultimă generație privind seturile de date de similitudine semantică în șase limbi. În continuare, vom arăta că vectorii specializați în Atract-Repel sporesc performanța în sarcina din aval de urmărire a stării dialogului (DST) în mai multe limbi. În cele din urmă, arătăm că spațiile vectoriale translingve produse de algoritmul nostru facilitează instruirea modelelor DST multilingve, ceea ce aduce îmbunătățiri suplimentare ale performanței.', 'uz': "We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources.  Name Bizning qiymatlarimizni ko'rsatishimiz mumkin, bu usuli mavjud cross-linglar leksikalardan foydalanishi mumkin va har xil tillarda katta va katta manbalar uchun katta vektorning joylarini yaratish mumkin. Bizning usulidagi effekti 6 tillarda semantik similar maʼlumotlar satrlarining holati natijasi bilan koʻrsatiladi. Keyingi ko'p tillarda muloqat holatning (DST) muloqat tilidagi muloqat taʼminlovchisi vazifasini ko'proq tillarda amalga oshirish mumkin. Endi, biz ko'pchilik DST modellarini o'rganish qo'shilgan tillar vektorlar joylarini ko'rsamiz, bu bir necha tildagi DST modellarini o'rganishga yordam beradi.", 'vi': 'Chúng tôi giới thiệu Quyến-Repel, một thuật toán để cải thiện nét chữ thường của các từ vector bằng cách tiêm các thiết bị trích ra từ tài nguyên từ. Công cụ hấp dẫn giúp việc sử dụng các giới hạn từ các nguồn độc và ngôn ngữ khác nhau, tạo ra các chi tiết khác nhau. Bài đánh giá của chúng tôi cho thấy phương pháp có thể sử dụng ngôn ngữ ngữ rộng mở để xây dựng các căn phòng vector chất lượng cao cho một loạt các ngôn ngữ khác nhau, giúp việc chuyển giao ngữ văn học từ chất cao đến nguồn thấp. Sự hiệu quả của phương pháp này được chứng minh với kết quả hiện đại về các tập tin về nét giống nhau theo sáu ngôn ngữ. Tiếp theo chúng ta sẽ cho thấy các sinh vật tiêu hao Quyến-Repel-đặc biệt tăng khả năng ứng biến trong phi vụ truy tìm bang đối thoại (DST) trên nhiều ngôn ngữ. Cuối cùng, chúng tôi cho thấy không gian xuyên rộng vector sản xuất bởi thuật toán chúng tôi giúp huấn luyện các mô hình DSS đa dạng, mang lại hiệu quả cải tiến thêm.', 'bg': 'Представяме алгоритъм за подобряване на семантичното качество на векторите на думи чрез инжектиране на ограничения, извлечени от лексикални ресурси. Привличане-отблъскване улеснява използването на ограничения от моно- и междуезични ресурси, създавайки семантично специализирани междуезични векторни пространства. Нашата оценка показва, че методът може да използва съществуващи междуезични лексикони за изграждане на висококачествени векторни пространства за множество различни езици, улеснявайки семантичния трансфер от такива с висок към по-нисък ресурс. Ефективността на нашия подход е демонстрирана с най-съвременни резултати за семантични сходства на шест езика. След това показваме, че векторите, специализирани в привличане-отблъскване, повишават производителността в задачата надолу по веригата за проследяване на състоянието на диалога (ДТ) на няколко езика. И накрая, показваме, че междуезичните векторни пространства, произведени от нашия алгоритъм, улесняват обучението на многоезични модели, което води до допълнителни подобрения на производителността.', 'hr': 'Predstavljamo Attract-Repel, algoritam za poboljšanje semantičke kvalitete riječnih vektora injekcijom ograničenja izvučena iz leksičkih resursa. Attract-Repel olakšava primjenu ograničenja iz monojezičkih resursa, pružajući semantički specijalizirane međujezičke vektorske prostore. Naša procjena pokazuje da metod može iskoristiti postojeće međujezičke leksikone kako bi konstruirali visoke kvalitetne vektorske prostore za plethoru različitih jezika, olakšavajući semantički prijenos od visokih na manje resurse. Efikasnost našeg pristupa pokazuje se s rezultatima stanja umjetnosti na semantičkim podacima sličnosti na šest jezika. Sljedeće pokazujemo da su specijalizovani vektori Attract-Repel povećali učinkovitost u donjem zadatku praćenja država dijaloga (DST) na višestrukim jezicima. Konačno, pokazujemo da međujezički vektorski prostor proizvođen našim algoritmom olakšava obuku multijezičkih DST modela, što donosi daljnje poboljšanje učinka.', 'da': 'Vi præsenterer Attract-Repel, en algoritme til at forbedre den semantiske kvalitet af ordvektorer ved at injicere begrænsninger udvundet fra leksikske ressourcer. Attract-Repel letter brugen af begrænsninger fra mono- og tværsprogede ressourcer, hvilket giver semantisk specialiserede tværsprogede vektorrum. Vores evaluering viser, at metoden kan gøre brug af eksisterende tværsprogede leksikoner til at konstruere vektorrum af høj kvalitet til en overflod af forskellige sprog, hvilket letter semantisk overførsel fra høj til lavere ressourcer. Effektiviteten af vores tilgang demonstreres med state-of-the-art resultater på semantiske lighedsdatasæt på seks sprog. Vi viser næste gang, at Attract-Repel-specialiserede vektorer øger ydeevnen i downstream-opgaven med dialog state tracking (DST) på tværs af flere sprog. Endelig viser vi, at tværsprogede vektorrum produceret af vores algoritme letter træningen af flersprogede DST modeller, hvilket medfører yderligere præstationsforbedringer.', 'nl': 'We presenteren Attract-Repel, een algoritme voor het verbeteren van de semantische kwaliteit van woordvectoren door beperkingen uit lexicale bronnen te injecteren. Attract-Repel vergemakkelijkt het gebruik van beperkingen van mono- en cross-lingual resources, wat semantisch gespecialiseerde cross-lingual vectorruimtes oplevert. Onze evaluatie toont aan dat de methode gebruik kan maken van bestaande cross-lingual lexicons om hoogwaardige vectorruimten te construeren voor een overvloed aan verschillende talen, waardoor semantische overdracht van hoge naar lagere talen wordt vergemakkelijkt. De effectiviteit van onze aanpak wordt aangetoond met state-of-the-art resultaten op semantische overeenkomsten datasets in zes talen. Vervolgens laten we zien dat Attract-Repel-gespecialiseerde vectoren de prestaties verbeteren in de downstream taak van dialoogstatusverfolging (DST) in meerdere talen. Tot slot laten we zien dat cross-lingual vectorruimtes geproduceerd door ons algoritme de training van meertalige DST modellen vergemakkelijken, wat verdere prestatieverbeteringen brengt.', 'id': 'Kami mempersembahkan Attract-Repel, algoritma untuk meningkatkan kualitas semantis vektor kata dengan menyuntik batas yang dikeluarkan dari sumber daya leksik. Attract-Repel memfasilitasi penggunaan batas dari sumber daya mono- dan saling bahasa, menghasilkan ruang vektor saling bahasa yang spesialisasi secara semantis. Evaluasi kami menunjukkan bahwa metode dapat menggunakan leksikon saling bahasa yang ada untuk membangun ruang vektor berkualitas tinggi untuk banyak bahasa yang berbeda, memfasilitasi transfer semantis dari bahasa tinggi ke sumber daya yang lebih rendah. Efektivitas pendekatan kita diperkenalkan dengan hasil terbaik pada dataset semantis persamaan dalam enam bahasa. Kita berikutnya menunjukkan bahwa vektor yang spesialisasi Attract-Repel meningkatkan prestasi dalam tugas turun dari pelacakan keadaan dialog (DST) melalui berbagai bahasa. Akhirnya, kami menunjukkan bahwa ruang vektor saling bahasa yang diproduksi oleh algoritma kami memudahkan pelatihan model DST berbagai bahasa, yang membawa perkembangan prestasi lebih lanjut.', 'ko': '우리는 흡수-배척 알고리즘을 제기했다. 이 알고리즘은 어휘 자원에서 추출한 제약을 주입함으로써 어향량의 의미의 질을 향상시킨다.끌기-배척은 단일 언어와 다중 언어 자원의 제약을 사용하고 의미를 전문화하는 다중 언어 벡터 공간을 만드는 데 도움이 된다.우리의 평가에 의하면 이 방법은 기존의 다중 언어 어휘를 이용하여 대량의 서로 다른 언어를 위해 고품질의 벡터 공간을 구축하고 높은 자원에서 낮은 자원으로의 의미 전환을 추진할 수 있다.우리의 방법은 여섯 가지 언어의 의미 유사성 데이터 집합의 최신 결과에서 그 유효성을 나타냈다.다음은 다양한 언어의 대화 상태 추적(DST) 하위 작업에서 전용 벡터를 끌어당기기-배제하는 성능을 보여줍니다.마지막으로 우리는 이 알고리즘이 만들어낸 다중 언어 벡터 공간이 다중 언어 DST 모델의 훈련에 도움이 되고 성능을 더욱 향상시켰다는 것을 증명했다.', 'de': 'Wir präsentieren Attract-Repel, einen Algorithmus zur Verbesserung der semantischen Qualität von Wortvektoren durch Injektion von Einschränkungen, die aus lexikalischen Ressourcen extrahiert werden. Attract-Repel erleichtert die Verwendung von Einschränkungen aus ein- und crosslingualen Ressourcen und liefert semantisch spezialisierte crosslinguale Vektorräume. Unsere Evaluation zeigt, dass die Methode vorhandene crosslinguale Lexikone nutzen kann, um qualitativ hochwertige Vektorräume für eine Vielzahl verschiedener Sprachen zu konstruieren und so den semantischen Transfer von hoch- zu ressourcenärmeren Sprachen zu erleichtern. Die Wirksamkeit unseres Ansatzes wird anhand modernster Ergebnisse zu semantischen Ähnlichkeitsdatensätzen in sechs Sprachen demonstriert. Als nächstes zeigen wir, dass Attract-Repel-spezialisierte Vektoren die Leistung bei der nachgelagerten Aufgabe der Dialogzustandsverfolgung (DST) über mehrere Sprachen steigern. Schließlich zeigen wir, dass durch unseren Algorithmus erzeugte crosslinguale Vektorräume das Training mehrsprachiger DST-Modelle erleichtern, was weitere Leistungsverbesserungen bringt.', 'fa': 'ما الگوریتم Attract-Repel را پیشنهاد می\u200cکنیم، برای improving the semantic quality of words vectors by injecting constraints extracted from lexical resources. Attract-Repel به استفاده از محدودیت\u200cها از منابع\u200cهای mono- و cross-lingual آسان می\u200cکند، که به عنوان فضای واکتور\u200cهای متوسط زبان\u200cهای semantically متخصص می\u200cباشد. ارزیابی ما نشان می\u200cدهد که این روش می\u200cتواند از زبان\u200cهای متوسط زبان استفاده کند تا فضای ویکتور\u200cهای کیفیت بالا برای نوع زبان\u200cهای متفاوتی ساخت، به وسیله انتقال semantic از یک منبع بالا به پایین استفاده کند. فعالیت دستور ما با نتایج ایالت هنری بر مجموعه داده های شباهت semantic در شش زبان نشان داده می شود. ما بعدش نشان می دهیم که ویکتورهای ویژه\u200cهای متخصص Attract-Repel در کار پایین\u200cترین دنبال وضعیت محاوره (DST) در زبان\u200cهای متعدد افزایش می\u200cدهد. بالاخره، ما نشان می دهیم که فضای ویکتورهای متوسط زبانی که توسط الگوریتم ما تولید شده است، آموزش مدل های DST متوسط زبان را آسان می کند، که بهترین عملکرد بیشتری را پیش می دهد.', 'sw': 'Tunawasilisha mkanganyiko wa Repeat, utaratibu wa kuboresha ubora wa sekunde wa maneno kwa kuingiza vikwazo vilivyotolewa na rasilimali za lexico. Mbunge-Replace unasaidia matumizi ya vikwazo kutoka rasilimali za mono na lugha tofauti, na kusababisha maeneo maalum yanayohusika kwa kiasi kikubwa katika lugha. Utafiti wetu unaonyesha kuwa mbinu zinaweza kutumia lexico zilizopo katika lugha mbalimbali ili kujenga nafasi zenye ubora wa lugha tofauti kwa ajili ya jumla ya lugha tofauti, na kusaidia usafirishaji wa sekunde kutoka juu hadi rasilimali za chini. Madhara ya mbinu yetu imeonyeshwa na matokeo ya hali ya sanaa kuhusu seti za takwimu za simu kwa lugha sita. Tunaonyesha kuwa vectors-maalumu wanaobakilisha kuchukua hatua katika kazi ya chini ya mjadala wa ufuatiliaji wa taifa (DST) katika lugha mbalimbali. Mwisho, tunaonyesha kuwa sehemu za vector za lugha zilizotengenezwa na algorithi yetu zinasaidia mafunzo ya mifano ya DST ya lugha mbalimbali, ambayo inaleta maboresho ya utendaji zaidi.', 'tr': 'Biz Attract-Repel\'i, lektik çeşmelerden çykan mümkinçiliklere süýtgetmek üçin semantik bir kelime vektörlerinin kalitesini geliştirmek üçin bir algoritmi sunuyoruz. Attract-Repel, mono ve karşı dil çeşmelerinden çizgiler kullanımını kolaylaştırır, semantik olarak özellikle karşı dil vektör alanları verir. Taýýarlanmamyz çykyşymyz bolan cross dilli lingüňlerden beýleki diller üçin ýokary kalitel vektör seleňleri ullanabiler we semantik çeşmeleri ýokary-ýokary çeşmelere üçin ulanyp biler. Biziň ýaryşymyzyň etkinliýetimizi semantik ýaly daňlap veri setirlerine 6 dilde görkezildi. Biz indiki hatlaryň "Attract-Repel" spesializasyylan vektörleri birnäçe dillerde diýoly durum izlemeginiň (DST) täsirinde eserleşmelerini azaltýandygyny görkez. Sonunda, algoritmus tarafından üretilen çoklu dil DST modellerinin eğitimi kolaylaştırmasını gösteririz. Bu da daha ileri etkinlik geliştirmesi sağlar.', 'sq': 'Ne paraqesim Attract-Repel, një algoritëm për përmirësimin e cilësisë semantike të vektorëve të fjalës duke injektuar kufizime të nxjerra nga burimet lexike. Attract-Repel lehtëson përdorimin e kufizimeve nga burimet mono- dhe ndërgjuhësore, duke dhënë hapësira vektorësh ndërgjuhësore semantike të specializuara. Vlerësimi ynë tregon se metoda mund të përdorë lexikonet ndërgjuhësore ekzistuese për të ndërtuar hapësira vektorësh të cilësisë së lartë për një shumicë gjuhësh të ndryshme, duke lehtësuar transferimin semantik nga a to me burime të larta në më të ulëta. Efektiviteti i qasjes sonë është demonstruar me rezultatet më të mëdha në të dhënat semantike të ngjashmërisë në gjashtë gjuhë. Ne do të tregojmë që vektorët e specializuar në tërheqje-përsëritje rritin performancën në detyrën më poshtë të ndjekjes së gjendjes së dialogut (DST) nëpërmjet gjuhëve të shumta. Më në fund, ne tregojmë se hapësirat vectore ndërgjuhësore të prodhuara nga algoritmi ynë lehtësojnë trainimin e modeleve DST shumëgjuhësore, që sjell përmirësime të mëtejshme të performancës.', 'am': 'አቀማመጥ-Repel፣ ለሌክሲካዊ ሀብት በተወለዱት ግንኙነቶችን በመጠቀም የቃላት ጥያቄ እናሳድጋለን፡፡ Repel ማስታወቂያውን የቋንቋ ቋንቋ ውስጥ ያሉትን ሌክሲኮኖችን የልዩ ልዩ ቋንቋዎች ቦታዎችን ለመሥራት የሚችል ማድረግ ነው፡፡ የሥርዓታችን ውጤት በስድስት ቋንቋዎች የሀገር-የዓርት ውጤቶች ላይ የተሰኘ ነው፡፡ የሚቀጥለውን እናሳየዋለን፡፡ በመጨረሻውም የቋንቋ-ቋንቋ የሜክሮር ቦታዎች በአልgorithም የዘረጋቸውን የዲስቲ ዓይነቶች ማስተማርን እናሳየዋለን፡፡', 'hy': 'Մենք ներկայացնում ենք "Ակտրակ-Ռեպելը", ալգորիթմ բառերի վեկտորների սեմանտիկ որակի բարելավման համար, ներարտադրելով լեքսիկական ռեսուրսներից ստացված սահմանափակումներ: Անտրակտ-Ռեպելը հնարավորություն է տալիս օգտագործել միալեզվի և երկլեզվի ռեսուրսների սահմանափակումները, բերելով սեմանտիկապես մասնավորված երկլեզվի վեկտորների տարածքներ: Մեր գնահատումը ցույց է տալիս, որ մեթոդը կարող է օգտագործել գոյություն ունեցող երկլեզվային լեքսիկոնները բարձր որակային վեկտորների տարածքների կառուցման համար տարբեր լեզուների բազմաթիվ, որպեսզի հեշտացնենք սեմանտիկ փոխանցումը բարձր-ցածր ռե Մեր մոտեցումների արդյունավետությունը ցույց է տալիս վեց լեզուներում սեմանտիկ նմանության տվյալների վերջին արդյունքներով: Մենք հաջորդ ցույց ենք տալիս, որ "Անձգտել-վերադարձնել" մասնավորված վեկտորները բարձրացնում են արտադրողությունը բազմալեզուների միջև գտնվող երկխոսային վիճակի հետևման (DST) գործընթացքում: Վերջապես, մենք ցույց ենք տալիս, որ մեր ալգորիթմից արտադրված միջլեզվային վեկտորների տարածքները հեշտացնում են բազլեզվային DST մոդելների ուսումնասիրությունը, ինչը առաջացնում է ավելի շատ բարելավումներ:', 'af': "Ons stel Attract-Repel voor 'n algoritme om die semantiese kwaliteit van woord vektore te verbeter deur die inprop van begrense wat uit leksiese hulpbronne uitgevoer is. Attract- Repel maak die gebruik van beheinings van mono- en kruistale hulpbronne gemeenskap, wat semantiese spesialiseerde kruistale vektorspasies gee. Ons evaluasie wys dat die metode kan gebruik van bestaande kruistale leksikone om hoë- kwaliteit vektorspasies te konstrukteer vir 'n plethora van ander tale, wat semantiese oordrag van hoë- na onder- hulpbronne te maak. Die effektiviteit van ons toegang is deur die staat van die kunste resultate van semantiese gelykenis datastelle in ses tale te demonstreer. Ons vertoon die volgende vertoon dat Attract-Repel-spesialiseerde vektore uitbreiding in die onderstreem taak van dialoog staat agtervolg (DST) oor veelvuldige tale verhoog. Eindelik, ons wys dat kruistale vektorspasies wat deur ons algoritme geproduseer is, die onderwerking van multitaalske DST-modele, wat verdere prestasie verbeteringe bring.", 'bn': 'লেক্সিক্সিক সম্পদ থেকে বেরিয়ে যাওয়া নিষেধাজ্ঞার মাধ্যমে শব্দ ভেক্টরের সামান্য মান উন্নত করার জন্য আমরা আটরাক্ট-প্রতিক্রিয়া আক্রান্ত-প্রতিরোধের ব্যবহারের সুবিধা প্রদান করে মোনো- এবং ক্রস-ভাষার সম্পদ থেকে নিয়ন্ত্রণ ব্যবহারের সুযোগ প্রদান করে, যার ফলে সেমান্টি আমাদের মূল্য দেখা যাচ্ছে যে বিভিন্ন ভাষার জন্য বিভিন্ন ভাষার জন্য বিভিন্ন ভিন্ন ভাষার জন্য বিভিন্ন ভেক্টরের স্থান ন নির্মাণের জন্য বিভিন্ন ভাষ আমাদের প্রতিক্রিয়ার কার্যক্রম ছয় ভাষায় সেম্পেন্টিক সমতামূলক তথ্যের ফলাফলের সাথে প্রদর্শন করা হয়েছে। পরবর্তীতে আমরা দেখাচ্ছি যে বিশেষ ভেক্টররা ডায়ালগ রাষ্ট্রীয় ট্র্যাকিং (ডিএসটি) বিভিন্ন ভাষায় ডায়ালগের নিচের কাজে প্রদর্শন কর শেষ পর্যন্ত আমরা দেখাচ্ছি যে আমাদের অ্যালগরিদমের দ্বারা ক্রিশ্রুভ ভাষায় ভেক্টরের স্থান উৎপাদন করা হয়েছে বহুভাষায় ডিসিটি মডেল প', 'az': "Biz Attract-Repel'i, leksik kaynaqlardan çıxarılan müəyyənləşdirmələri ilə söz vektörlərinin semantik keyfiyyətini yaxşılaşdırmaq üçün algoritmi göstəririk. Attract-Repel mono-və çox dil kaynaqların istifadəsini olaraq, semantik olaraq xüsusiyyətli çox dil vektör uzaqlarını verir. Bizim değerlendirməkimiz göstərir ki, metod, yüksək-kaliteli vektor alanlarını müxtəlif dillər üçün istifadə edə bilər, çox yüksək-küçük çoxluğundan daha a şağı-çoxluğundan semantik transferini asanlaşdırır. Bizim tərəfimizin etkinlik altı dildə semantik similaritə verilənlərin sonuçları ilə göstərildi. Sonrakı göstəririk ki, Attract-Repel-specialized vektörlər çoxlu dillərdə diyal eyalet takibi (DST) ilə aşağıdaki işin performansını artırar. Sonunda, algoritmus tarafından ürəklənmiş çoxlu dil DST modellərin təhsil edilməsini asanlaşdırmağını göstərdik ki, bu daha çox performanslıq düzəltmələrini gətirir.", 'bs': 'Predstavljamo Attract-Repel, algoritam za poboljšanje semantičke kvalitete riječnih vektora injekcijom ograničenja izvučena iz leksičkih resursa. Attract-Repel olakšava korištenje ograničenja iz monojezičkih i krstojezičkih resursa, pružajući semantički specijalizirane krstojezičke vektorske prostore. Naša procjena pokazuje da metoda može iskoristiti postojeće međujezičke leksikone kako bi izgradili visoke kvalitetne vektorske prostore za plethoru različitih jezika, olakšavajući semantički transfer od visokih na manje resurse. Efikasnost našeg pristupa pokazuje se sa rezultatima države umjetnosti na semantičkim podacima sličnosti na šest jezika. Sljedeći pokazujemo da su specijalizovani vektori Attract-Repel povećali učinkovitost u donjem zadatku praćenja država dijaloga (DST) na višestrukim jezicima. Konačno, pokazujemo da međujezički vektorski prostor proizvođen našim algoritmom olakšava obuku multijezičkih DST modela, što donosi daljnje poboljšanje učinka.', 'cs': 'Představujeme algoritmus Attract-Repel pro zlepšení sémantické kvality slovních vektorů vstřikováním omezení extrahovaných z lexikálních zdrojů. Attract-Repel usnadňuje použití omezení z mono- a cross-jazyčných zdrojů a vytváří sémanticky specializované cross-jazyčné vektorové prostory. Naše hodnocení ukazuje, že metoda může využít existujících křížových slovníků k vytvoření kvalitních vektorových prostorů pro celou řadu různých jazyků, což usnadňuje sémantický přenos z vysokých na nižší zdroje. Účinnost našeho přístupu je demonstrována nejmodernějšími výsledky souborů sémantické podobnosti v šesti jazycích. Dále ukazujeme, že specializované vektory Attract-Repel zvyšují výkon v následném úkolu sledování stavu dialogu (DST) napříč několika jazyky. Nakonec ukazujeme, že vícejazyčné vektorové prostory vytvořené naším algoritmem usnadňují trénink vícejazyčných DST modelů, což přináší další zlepšení výkonu.', 'et': 'Esitleme Attract-Repel, algoritmi sõnavaktorite semantilise kvaliteedi parandamiseks leksikaalsetest ressurssidest eraldatud piirangute süstimise teel. Attract-Repel hõlbustab ühe- ja keeleüleste ressursside piirangute kasutamist, tekitades semantiliselt spetsialiseeritud keeleüleseid vektoriruume. Meie hinnang näitab, et meetod võib kasutada olemasolevaid keeleüleseid leksikone, et ehitada kvaliteetseid vektoriruume paljudele erinevatele keeltele, lihtsustades semantilist ülekannet kõrge ressursiga keeltele. Meie lähenemisviisi efektiivsust tõendavad kaasaegsed tulemused semantilise sarnasuse andmekogumite kohta kuues keeles. Järgmisena näitame, et Attract-Repel spetsialiseerunud vektorid suurendavad dialoogi oleku jälgimise (DST) alljärgneva ülesande jõudlust mitmes keeles. Lõpuks näitame, et meie algoritmi poolt toodetud keeleülesed vektoriruumid hõlbustavad mitmekeelsete DST mudelite koolitamist, mis toob kaasa täiendavaid jõudluse parandusi.', 'fi': 'Esittelemme Attract-Repel -algoritmia sanavektorien semanttisen laadun parantamiseksi lisäämällä sanaston resursseista poimittuja rajoituksia. Attract-Repel helpottaa yhden- ja monikielisten resurssien rajoitusten käyttöä tuottaen semanttisesti erikoistuneita monikielisiä vektoriavaruuksia. Arviointi osoittaa, että menetelmällä voidaan hyödyntää olemassa olevia monikielisiä sanastoja korkealaatuisten vektoriavaruuksien rakentamiseen lukuisille eri kielille, mikä helpottaa semanttista siirtymistä korkean resurssin kielistä matalampaan. Lähestymistapamme tehokkuus osoitetaan viimeisimpillä tuloksilla semanttisen samankaltaisuuden aineistoista kuudella kielellä. Seuraavaksi näytämme, että Attract-Repel-spesifiset vektorit tehostavat dialogin tilan seurannan (DST) loppupään tehtävää useilla kielillä. Lopuksi osoitamme, että algoritmimme tuottamat monikieliset vektoriavaruudet helpottavat monikielisten DST-mallien koulutusta, mikä lisää suorituskykyä.', 'ca': "We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources.  Attract-Repel facilita l'ús de restriccions provenant de recursos monolingües i translingües, produint espais vectoris translingües semànticament especialitzats. La nostra evaluació mostra que el mètode pot fer servir els lexicòns translingües existents per construir espais vectoris d'alta qualitat per a una multitòria de llengües diferents, facilitant la transfer ència semàntica d'espais de alta a baix recursos. L'eficacia del nostre enfocament es demostra amb resultats més moderns en conjunts de dades de similitud semàntica en sis llengües. El següent mostra que els vectors especialitzats en Attract-Repel impulsen el rendiment en la tasca avall de seguiment de l'estat del diàleg (DST) a través de múltiples llengües. Finalment, demostram que els espais vectoris translingües produïts pel nostre algoritme faciliten l'entrenament de models DST multilingües, que porta més millors de rendiment.", 'jv': 'We present Attrak-Refel, an Algorithm for uptake the semanti quality of word vectors by injecting limits extract from Lex-Ressource. Attribute-Refel first available Awakdhéwé nggunian punika dipuangkat oleh akeh basa luwih akeh bantuan ingkang nggawe geranggawe luwih bantuan karo akeh-kalitas vector nggawe sistem sing perusahaan language, akhar sematik nggawe nguasai luwih-bantuan liyane Efek-efek sing dibutuhke punika dipontrolan karo hal-punika sing dadi sing sematik perusahaan ning suxtang langa. We next show that Attrak-Refel-special vectors raise output in the downtream task of dialog state tracking (SST) in multi language. Lha wih, kita ngomong nik, perusahaan langkung sampeyan karo perusahaan vector-sampeyan karo Algorithm kuwi nggawe barang sistem multilenguase', 'ha': "We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources.  Attracte-Repel yana yarda da amfani da tsaro daga manyan mutane da ke tsutar-lugha, mai bãyar da filayen sakanti-na'ura masu ƙayyade Anarari na nuna cewa, metoden za'a iya amfani da shiryoyin leksisi masu cikin lugha-na'ura don ka samu matsayi masu tsari ga masu nau'in-nau'i wa'urar-nau'i, kuma yana da amfani da motsarin mutane daga tsakanin zuwa ƙasan-resource. An nuna fassarar hanyarmu da fassarar-na-art kan mutane da ke daidaita data masu cikin sitan harshe. Tuna ƙara nuna cewa masu iya boost performance cikin aikin zauren akwatin bayani na filin bayani na state tracing (DS) cikin wasu harshe. Haƙĩƙa, Munã nũna duk filayen shiryori na cikin lugha-na'ura wanda aka samar da shi na algoritmu yana da amfani da wa wa'anar DS-na'urar mulki'ura, wanda ke ƙara mafarin aiki.", 'he': 'אנו מציגים את Attract-Repel, אלגוריתם לשפר את איכות הסמנטית של ווקטורים מילים על ידי הזריקה מחסומות מווצאות משאבים לקסיים. משיכה-חזרה מקדימה את השימוש של מחסומות משאבים מונושיים וחצות שפתיים, נותנת מקומות ווקטורים חוצה שפתיים מיוחדים באופן סמנטי. הערכה שלנו מראה שהשיטה יכולה להשתמש בלקסיקונים בין שפתיים קיימים כדי לבנות מקומות ווקטורים של איכות גבוהה למרבה שפות שונות היעילות של הגישה שלנו מוצגת עם תוצאות חדשות על קבוצות נתונים של דמיון סמנטי בשש שפות. אנו מראים הבא שהווקטורים המיוחדים באטרקט-חזרה מגבירים ביצועים במשימה התחתונה של מעקב מדיום דיאלוג (DST) ברחבי שפות רבות. סוף סוף, אנו מראים שמרחבי ווקטורים בין שפתיים שנוצרים על ידי האלגוריתם שלנו מקלים את האימון של דוגמנים DST רבות שפתיים, שמביאים שיפורים נוספים ביצועים.', 'sk': 'Predstavljen je algoritem Attract-Repel za izboljšanje semantične kakovosti besednih vektorjev z vbrizgavanjem omejitev iz leksikalnih virov. Attract-Repel omogoča uporabo omejitev iz enojezičnih in medjezičnih virov, kar ustvarja semantično specializirane vektorske prostore. Naša ocena kaže, da lahko metoda uporablja obstoječe medjezične leksikone za gradnjo visokokakovostnih vektorskih prostorov za mnogo različnih jezikov, kar olajša semantični prenos z visoko-nižjih virov. Učinkovitost našega pristopa je dokazana z najsodobnejšimi rezultati o semantičnih podobnostih v šestih jezikih. Nato pokažemo, da vektorji, specializirani za privlačnost-odbijanje, povečujejo učinkovitost pri nadaljnjem opravilu sledenja stanja dialoga (DST) v več jezikih. Na koncu pokažemo, da vektorski prostori, ki jih izdeluje naš algoritem, omogočajo usposabljanje večjezičnih modelov DST, kar prinaša nadaljnje izboljšave zmogljivosti.', 'bo': 'We present Attract-Repel, an algorithm for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high-to lower-resource ones. ང་ཚོའི་གཟུགས We next show that Attract-Repel-specialized vectors boost performance in the downstream task of dialog state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our algorithm facilitate the training of multilingual DST models, which brings further performance improvements.'}
{'en': 'Colors in Context : A Pragmatic Neural Model for Grounded Language Understanding', 'ar': 'الألوان في السياق: نموذج عصبي عملي لفهم اللغة', 'fr': 'Les couleurs en contexte\xa0: un modèle neuronal pragmatique pour une compréhension linguistique fondée', 'pt': 'Cores em contexto: um modelo neural pragmático para compreensão da linguagem fundamentada', 'es': 'Colores en contexto: un modelo neuronal pragmático para una comprensión fundamentada del lenguaje', 'ja': '文脈内の色：基礎となる言語を理解するための実用的なニューラルモデル', 'zh': '上下文中色:接地气言语实用神经模', 'ru': 'Цвета в контексте: прагматическая нейронная модель для понимания языка', 'hi': 'संदर्भ में रंग: ग्राउंडेड भाषा समझ के लिए एक व्यावहारिक तंत्रिका मॉडल', 'ga': 'Dathanna i gComhthéacs: Múnla Néarrach Pragmatach le haghaidh Tuiscint Bhunaithe Teanga', 'hu': 'Színek a kontextusban: Pragmatikus neurális modell a földi nyelv megértéséhez', 'ka': 'ფერები კონტექსტში: პრაგმატიკური ნეირალური მოდელი დაფრძელებული ენის განსხვავებისთვის', 'el': 'Χρώματα στο πλαίσιο: Ένα πρακτικό Νευρικό Μοντέλο για την κατανόηση της Βασισμένης Γλώσσας', 'kk': 'Контекстің түстері: Төмендегі тілді түсіну үшін Pragmatic Neural Model', 'lt': 'Spalvos kontekste: Pragmatinis nervinis modelis pagrįstos kalbos supratimui', 'it': 'Colori nel contesto: un modello pragmatico neurale per la comprensione del linguaggio a terra', 'ms': 'Warna dalam Konteks: Model Neural Pragmatik untuk Pemahaman Bahasa Tertanah', 'ml': 'ഭൂതഭാഷയ്ക്കുള്ള ഭാഷ മനസ്സിലാക്കുന്നതിനുള്ള പ്രാഗ്മാറ്റിക് നെയുറല്\u200d മോഡല്\u200d', 'mt': 'Kuluri fil-Kuntest: Mudell Newrali Prammatiku għall-Ftehim tal-Lingwa Grounded', 'mn': 'Контекст дэх өнгө: Гурав хэл ойлголтын Pragmatic Neural Model', 'no': 'Fargar i kontekst: eit pragmatisk neuralmodell for grunnleggjande språk', 'pl': 'Kolory w kontekście: pragmatyczny model neuronowy dla zrozumienia języka uziemionego', 'ro': 'Culori în context: un model pragmatic neural pentru înțelegerea limbii împământate', 'sr': 'Boje u kontekstu: Pragmatični neuralni model za razumijevanje jezika', 'si': 'සංවේදනයේ වර්ණ: ප්\u200dරාග්මාටික් න්\u200dයූරල් මොඩේල්', 'mk': 'Бои во контекст: Прагматски неврален модел за разбирање на основаниот јазик', 'so': 'Midabo gudaha ah: A Pragmatic Neural Model for Grouped language Understanding', 'sv': 'Färger i sammanhanget: En pragmatisk neural modell för jordad språkförståelse', 'ta': 'நடுவிலுள்ள நிறங்கள்:', 'ur': 'کنٹکسٹ میں رنگ: گروڈ زبان سمجھنے کے لئے ایک پراگٹیک نیورال موڈل', 'uz': 'Name', 'vi': 'Màu ngữ: Mô hình thần kinh hình bí bí bí bí bí cho hiểu biết ngôn ngữ', 'bg': 'Цветове в контекста: Прагматичен неврален модел за обосновано езиково разбиране', 'da': 'Farver i sammenhæng: En pragmatisk neural model til jordbaseret sprogforståelse', 'nl': 'Kleuren in context: Een pragmatisch neuraal model voor gegrond taalbegrip', 'hr': 'Boje u kontekstu: Pragmatični neuronski model za razumijevanje jezika', 'de': 'Farben im Kontext: Ein pragmatisches neuronales Modell für das Verständnis von Grounded Language', 'id': 'Warna dalam Konteks: Model Neural Pragmatis untuk Pemahaman Bahasa Ditanamkan', 'ko': '언어 환경에서의 색깔: 언어 이해에 뿌리를 둔 언어용 신경 모형', 'fa': 'رنگ در محیط: یک مدل عصبی Pragmatic for Ground Language Understanding', 'sw': 'rangi zilizopo katikati: Utawala wa Nepali kwa ajili ya Kuelewa Lugha Kuanguka', 'tr': 'Renkler', 'af': 'Name', 'sq': 'Ngjyra në Kontekst: Një model neuronal pragmatik për kuptimin e gjuhës së themeluar', 'am': 'የተለመደው ጭብጥ', 'hy': 'Կոնտեքստում գտնվող գույները: Պրագմատիկ նյարդային մոդելը հիմնված լեզվի հասկանալու համար', 'az': 'Kontekstd톛 r톛ngl톛r: Yerli dil anlama 칲칞칲n Pragmatik N칬ral Modeli', 'bn': 'ভাষার বুঝতে পারার জন্য একটি প্রাজ্যামেটিক নিউরেল মডেল', 'bs': 'Boje u kontekstu: Pragmatični neuralni model za razumijevanje jezika', 'ca': 'Colors in Context: Un model neural pragmàtic per a entendre la llengua fundamentada', 'cs': 'Barvy v kontextu: Pragmatický neuronový model pro porozumění uzemněnému jazyku', 'fi': 'Värit kontekstissa: Pragmaattinen neuromalli pohjautuvan kielen ymmärtämiseen', 'et': 'Värvid kontekstis: pragmaatiline neuraalne mudel põhjaliku keele mõistmiseks', 'jv': 'structural navigation', 'sk': 'Barve v kontekstu: Pragmatični nevralni model za razumevanje jezika', 'he': 'צבעים בתוך הקשר: מודל נוירולי פרגמטי להבין שפה מקורמת', 'ha': 'KCharselect unicode block name', 'bo': 'ཁ་དོག་ཚོས་གཞུང་ནང་ཡོད། རྨང་གཞིའི་སྐད་ཡིག་རྟོགས་པའི་སྒེར་གྱི་མ་དབྱིབས།'}
{'en': 'We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives. We observe that pragmatic reasoning helps primarily in the hardest cases : when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors.', 'ar': 'نقدم نموذجًا لتفسير تعبير الإحالة الواقعي في مهمة اتصال مؤرضة (تحديد الألوان من الأوصاف) التي تعتمد على تنبؤات من مصنفين متكررين للشبكة العصبية ، متحدث ومستمع ، موحدين من خلال إطار تفكير عملي متكرر. تُظهر التجارب أن هذا النموذج البراغماتي المدمج يفسر أوصاف الألوان بشكل أكثر دقة من المصنفات التي تم بناؤها منها ، وأن الكثير من هذا التحسين ينتج عن الجمع بين منظور المتحدث والمستمع. نلاحظ أن التفكير العملي يساعد في المقام الأول في أصعب الحالات: عندما يجب أن يميز النموذج ألوانًا متشابهة جدًا ، أو عندما يعبر القليل من الكلام عن اللون المستهدف بشكل مناسب. تستفيد النتائج التي توصلنا إليها من مجموعة الكلمات البشرية التي تم جمعها حديثًا في الألعاب المرجعية الملونة ، والتي تُظهر مجموعة متنوعة من السلوكيات البراغماتية. نوضح أيضًا أن نموذج السماعة المضمنة يعيد إنتاج العديد من هذه السلوكيات البراغماتية.', 'fr': "Nous présentons un modèle d'interprétation pragmatique d'expression référente dans une tâche de communication fondée (identification des couleurs à partir de descriptions) qui s'appuie sur les prédictions de deux classificateurs de réseaux neuronaux récurrents, un locuteur et un auditeur, unifiés par un cadre de raisonnement pragmatique récursif. Les expériences montrent que ce modèle pragmatique combiné interprète les descriptions de couleurs plus précisément que les classificateurs à partir desquels il est construit, et qu'une grande partie de cette amélioration résulte de la combinaison des points de vue de l'orateur et de l'auditeur. Nous observons que le raisonnement pragmatique aide principalement dans les cas les plus difficiles\xa0: lorsque le modèle doit distinguer des couleurs très similaires, ou lorsque peu d'énoncés expriment correctement la couleur cible. Nos résultats utilisent un corpus d'énoncés humains récemment rassemblés dans des jeux de référence de couleurs, qui présentent une variété de comportements pragmatiques. Nous montrons également que le modèle de haut-parleur intégré reproduit bon nombre de ces comportements pragmatiques.", 'es': 'Presentamos un modelo de interpretación pragmática de expresiones de referencia en una tarea de comunicación fundamentada (identificación de colores a partir de descripciones) que se basa en predicciones de dos clasificadores de redes neuronales recurrentes, un hablante y un oyente, unificados por un marco de razonamiento pragmático recursivo. Los experimentos muestran que este modelo pragmático combinado interpreta las descripciones de colores con mayor precisión que los clasificadores a partir de los cuales se construye, y que gran parte de esta mejora es el resultado de combinar las perspectivas del orador y del oyente. Observamos que el razonamiento pragmático ayuda principalmente en los casos más difíciles: cuando el modelo debe distinguir colores muy similares, o cuando pocos enunciados expresan adecuadamente el color objetivo. Nuestros hallazgos hacen uso de un corpus recién recopilado de enunciados humanos en juegos de referencia de colores, que muestran una variedad de comportamientos pragmáticos. También mostramos que el modelo de altavoz integrado reproduce muchos de estos comportamientos pragmáticos.', 'pt': 'Apresentamos um modelo de interpretação pragmática de expressões referenciais em uma tarefa de comunicação fundamentada (identificação de cores a partir de descrições) que se baseia em previsões de dois classificadores de redes neurais recorrentes, um falante e um ouvinte, unificados por uma estrutura de raciocínio pragmático recursivo. Experimentos mostram que esse modelo pragmático combinado interpreta as descrições de cores com mais precisão do que os classificadores a partir dos quais é construído, e que grande parte dessa melhoria resulta da combinação das perspectivas do falante e do ouvinte. Observamos que o raciocínio pragmático ajuda principalmente nos casos mais difíceis: quando o modelo deve distinguir cores muito semelhantes, ou quando poucos enunciados expressam adequadamente a cor alvo. Nossas descobertas fazem uso de um corpus recém-coletado de enunciados humanos em jogos de referência de cores, que exibem uma variedade de comportamentos pragmáticos. Mostramos também que o modelo de falante embutido reproduz muitos desses comportamentos pragmáticos.', 'ja': '我々は、再帰的な実用的な推論フレームワークによって統一された、２つの再帰的なニューラルネットワーク分類子、スピーカー及びリスナーからの予測を引き出す、グラウンディングされた通信タスク（記述から色を識別する）における実用的な参照表現解釈のモデルを提示する。実験は、この組み合わせられた実用的なモデルが、それが構築される分類子よりも色の記述をより正確に解釈し、この改善の多くは、スピーカーとリスナーの視点を組み合わせることから生じることを示している。私たちは、実用的な推論が主に最も難しい場合に役立つことを観察します。モデルが非常に似た色を区別しなければならない場合、またはターゲット色を適切に表現する発話が少ない場合です。私たちの調査結果は、さまざまな実用的な行動を示すカラーリファレンスゲームで新しく収集された人間の発言のコーパスを利用しています。埋め込まれたスピーカーモデルは、これらの実用的な行動の多くを再現することも示しています。', 'hi': 'हम एक ग्राउंडेड संचार कार्य (विवरण से रंगों की पहचान) में व्यावहारिक संदर्भित अभिव्यक्ति व्याख्या का एक मॉडल प्रस्तुत करते हैं जो दो आवर्तक तंत्रिका नेटवर्क क्लासिफायर, एक वक्ता और एक श्रोता से भविष्यवाणियों पर आकर्षित करता है, जो एक पुनरावर्ती व्यावहारिक तर्क ढांचे द्वारा एकीकृत होता है। प्रयोगों से पता चलता है कि यह संयुक्त व्यावहारिक मॉडल क्लासिफायर्स की तुलना में रंग विवरणों की अधिक सटीक व्याख्या करता है, जिसमें से यह बनाया गया है, और इस सुधार का अधिकांश परिणाम वक्ता और श्रोता दृष्टिकोण के संयोजन से होता है। हम देखते हैं कि व्यावहारिक तर्क मुख्य रूप से सबसे कठिन मामलों में मदद करता है: जब मॉडल को बहुत समान रंगों को अलग करना चाहिए, या जब कुछ कथन पर्याप्त रूप से लक्ष्य रंग को व्यक्त करते हैं। हमारे निष्कर्ष रंग संदर्भ खेलों में मानव कथनों के एक नए-एकत्र कॉर्पस का उपयोग करते हैं, जो विभिन्न प्रकार के व्यावहारिक व्यवहारों को प्रदर्शित करते हैं। हम यह भी दिखाते हैं कि एम्बेडेड स्पीकर मॉडल इनमें से कई व्यावहारिक व्यवहारों को पुन: पेश करता है।', 'zh': '臣等于接地通信之任(于言中识色)中发一实引表达式解模,当模用两递归神经网络分类器(一言者与一听者)之占,递归实推理框架一。 实验明其用,确于构分类器,其改入甚大,合言者与听众之说而生也。 吾观之,理在最难:形必分相似之色,或当少言表达目标色。 见用色参考戏中新集人语料库,语料库见实行。 吾犹明之,嵌入式扬声器复见其实。', 'ru': 'Представлена модель прагматической ссылающейся интерпретации выражения в обоснованной коммуникационной задаче (выявление цветов по описаниям), которая опирается на предсказания двух рекуррентных нейросетевых классификаторов, спикера и слушателя, объединенных рекурсивной прагматической системой рассуждений. Эксперименты показывают, что эта комбинированная прагматическая модель интерпретирует описания цветов более точно, чем классификаторы, из которых она построена, и что большая часть этого улучшения является результатом сочетания перспектив говорящего и слушателя. Мы отмечаем, что прагматическое мышление помогает в первую очередь в самых трудных случаях: когда модель должна различать очень похожие цвета, или когда мало высказываний адекватно выражают целевой цвет. Наши результаты используют недавно собранный корпус человеческих высказываний в играх с цветовыми эталонами, которые демонстрируют разнообразное прагматическое поведение. Мы также показываем, что встроенная модель динамика воспроизводит многие из этих прагматических моделей поведения.', 'ga': 'Cuirimid i láthair samhail de léirmhíniú slonn tagartha pragmatach i dtasc cumarsáide bunaithe (dathanna a aithint ó chur síos) a tharraingíonn ar thuar ó dhá aicmitheora líonra néaracha athfhillteacha, cainteoir agus éisteoir, arna aontú ag creat réasúnaíochta pragmatach athfhillteach. Léiríonn turgnaimh go ndéanann an tsamhail phragmatach chomhcheangailte seo léirmhíniú ar chur síos dathanna níos cruinne ná na haicmitheoirí as a dtógtar é, agus go n-eascraíonn cuid mhór den fheabhsúchán seo as peirspictíochtaí an chainteora agus an éisteoir a chomhcheangal. Tugaimid faoi deara go gcabhraíonn réasúnaíocht phragmatach go príomha sna cásanna is deacra: nuair a chaithfidh an tsamhail idirdhealú a dhéanamh ar dhathanna an-chosúil, nó nuair nach gcuireann mórán cainte an dath sprice in iúl go sásúil. Baineann ár dtorthaí úsáid as corpas nua-bhailithe de chaint dhaonna i gcluichí tagartha datha, a léiríonn iompraíochtaí éagsúla pragmatach. Léirímid freisin go ndéanann an tsamhail cainteoir leabaithe go leor de na hiompraíochtaí pragmatacha seo a atáirgeadh.', 'el': 'Παρουσιάζουμε ένα μοντέλο ρεαλιστικής ερμηνείας αναφερθείσας έκφρασης σε μια τεκμηριωμένη εργασία επικοινωνίας (αναγνώριση χρωμάτων από περιγραφές) που βασίζεται σε προβλέψεις από δύο επαναλαμβανόμενους ταξινομητές νευρωνικών δικτύων, έναν ομιλητή και έναν ακροατή, ενοποιημένα από ένα αναδρομικό πλαίσιο ρεαλιστικής συλλογιστικής. Τα πειράματα δείχνουν ότι αυτό το συνδυασμένο ρεαλιστικό μοντέλο ερμηνεύει τις περιγραφές χρωμάτων με μεγαλύτερη ακρίβεια από τους ταξινομητές από τους οποίους είναι χτισμένο, και ότι μεγάλο μέρος αυτής της βελτίωσης προκύπτει από το συνδυασμό της προοπτικής του ομιλητή και του ακροατή. Παρατηρούμε ότι η ρεαλιστική συλλογιστική βοηθά κυρίως στις δυσκολότερες περιπτώσεις: όταν το μοντέλο πρέπει να διακρίνει πολύ παρόμοια χρώματα, ή όταν λίγες εκφράσεις εκφράζουν επαρκώς το χρώμα στόχου. Τα ευρήματά μας χρησιμοποιούν ένα νεοσυλλέκτο σώμα ανθρώπινων εκφράσεων σε χρωματικά παιχνίδια αναφοράς, τα οποία παρουσιάζουν ποικίλες πρακτικές συμπεριφορές. Δείχνουμε επίσης ότι το ενσωματωμένο μοντέλο ηχείων αναπαράγει πολλές από αυτές τις ρεαλιστικές συμπεριφορές.', 'hu': 'A pragmatikus referenciakifejezések értelmezésének modelljét mutatjuk be egy olyan megalapozott kommunikációs feladatban (színek azonosítása a leírásokból), amely két visszatérő neurális hálózati osztályozótól, egy beszélőtől és egy hallgatótól származó előrejelzésekre épül, rekurzív pragmatikus érvelési keretrendszerrel egyesítve. A kísérletek azt mutatják, hogy ez a kombinált pragmatikus modell pontosabban értelmezi a színleírásokat, mint az osztályozók, amelyekből épült, és hogy a fejlesztés nagy része a hangszóró és a hallgató perspektívák kombinálásából ered. Megfigyeljük, hogy a pragmatikus érvelés elsősorban a legnehezebb esetekben segít: amikor a modellnek nagyon hasonló színeket kell megkülönböztetnie, vagy amikor kevés kimondás megfelelően kifejezi a célszínt. Eredményeink egy újonnan összegyűjtött emberi kijelentéseket használnak fel színes referenciajátékokban, amelyek sokféle pragmatikus viselkedést mutatnak. Azt is megmutatjuk, hogy a beágyazott hangszóró modell sok ilyen pragmatikus viselkedést reprodukál.', 'ka': 'ჩვენ პრაგმატიკური განსხვავებული გამოსახულების მოდელის გამოსახულება კომუნიკაციის რაოდენობაში (გამოსახულებული ფერების გამოსახულება) რომელიც ორი განსხვავებული ნეიროლური ქსელის კლასიფიკაციის განსხვავებების მოდელის გამოსახულება, ს ექსპერიმენტები გამოჩვენებს, რომ ეს კომბიცირებული პრაგმატიკური მოდელი უფრო ექსექტურია ფერის გამოსახულება, რომელიც კლასიფიკაცირებით შექმნა, და რომ ეს უფრო მეტი შექმნარების შედეგი ჩვენ დავხედავთ, რომ პრაგმატიკური პარაგმაცია უფრო ძალიან ძალიან ძალიან მსგავსი ფერების განსხვავება, ან როდესაც რამდენიმე პარაგმაციები მარტივი ფერების განსხვავება. ჩვენი შესაძლებლობები ახალი კოლექცირებული ადამიანის სიტყვების კოპუსის გამოყენება ფერის რეფერენციო თამაში, რომელიც გამოყენებს განსხვავებული პრაგმატიკური ქცევაზე. ჩვენ ასევე ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენებულია, რომ ჩვენი მოდელი პრაგმატიკური მოქმედების მრავალს გამოცდილობს.', 'it': "Presentiamo un modello di interpretazione pragmatica dell'espressione di riferimento in un compito di comunicazione basato (identificare i colori dalle descrizioni) che si basa sulle previsioni di due classificatori ricorrenti di reti neurali, uno speaker e un ascoltatore, unificati da un quadro di ragionamento pragmatico ricorsivo. Gli esperimenti dimostrano che questo modello pragmatico combinato interpreta le descrizioni dei colori in modo più accurato rispetto ai classificatori da cui è costruito, e che gran parte di questo miglioramento deriva dalla combinazione delle prospettive dell'altoparlante e dell'ascoltatore. Osserviamo che il ragionamento pragmatico aiuta soprattutto nei casi più difficili: quando il modello deve distinguere colori molto simili, o quando poche parole esprimono adeguatamente il colore di destinazione. I nostri risultati fanno uso di un corpus di parole umane recentemente raccolto nei giochi di riferimento a colori, che mostrano una varietà di comportamenti pragmatici. Mostriamo anche che il modello embedded speaker riproduce molti di questi comportamenti pragmatici.", 'kk': 'Біз қайталанатын невралдық желінің классификациясынан екі қайталанатын невралдық классификациясынан, сөйлейтін және тыңдаушысынан біріктірілген прагматикалық түстердің түсін анықтау тапсырмасында прагматикалық сөйлейтін өрнегінің түрін көрсетедік. Тәжірибелер біріктірілген прагматикалық моделі түстер сипаттамасын құрылған классификациялардан артық түсінің түсініктемелерінен артық түсініктемелерді түсініктеп береді, және бұл жақсартулардың көп н Біз прагматикалық сезімдердің негізінде ең қиын жағдайда көмектеседі деп белгіледік: үлгісі өте ұқсас түстерді айыру керек немесе бірнеше сөздердің мақсатты түстерді дұрыс түсінде айыр Біздің табуларымыз жаңа жинақталған адамдардың сөздерінің корпусын түсті сілтеме ойындарында қолданылады. Бұл әртүрлі прагматикалық әрекеттерді көрсетеді. Біз сондай-ақ ендірілген орындаушы үлгісі бұл прагматикалық әрекеттердің көпшілігін жасайды.', 'lt': 'Pateikiame pragmatinio nuorodos išraiškos aiškinimo model į pagrįstoje komunikacijos užduotyje (nustatant spalvas iš apibūdinimų), kuris grindžiamas dviejų pasikartojančių nervinių tinklų klasifikatorių, kalbėtojo ir klausytojo, vieningų pasikartojančių pragmatinių motyvų, prognozėmis. Eksperimentai rodo, kad šis kombinuotas pragmatinis modelis aiškina spalvų aprašymus tiksliau nei klasifikatoriai, iš kurių jis yra sukurtas, ir kad daugelis šių patobulinimų atsiranda derinant kalbėtojo ir klausytojo perspektyvas. Mes pastebime, kad pragmatiškas motyvavimas pirmiausia padeda sunkiausiais atvejais: kai modelis turi skirti labai panašias spalvas arba kai keli žodžiai tinkamai išreiškia tikslinę spalvą. Mūsų rezultatai naudojasi naujai surinktu žmogaus išraiškų korpusu spalvų lyginamuosiuose žaidimuose, kurie rodo įvairius pragmatinius elgesius. Taip pat rodome, kad įterptas kalbėtojo modelis atspindi daugelį šių pragmatinių elgesių.', 'mk': 'Презентираме модел на прагматична референциска интерпретација на изразот во задача за комуникација (идентификување на боите од описите) која се базира на предвидувањата од двајца рецидентни класификатори на нервната мрежа, говорник и слушач, обединети од рецидентна прагматична рамка за размислување. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives.  Забележуваме дека прагматичното размислување помага првенствено во најтешките случаи: кога моделот мора да разликува многу слични бои, или кога неколку изрази соодветно ја изразуваат бојата на целта. Нашите откритија користат ново собран корпус на човечки изрази во игрите за референција на бои, кои покажуваат различни прагматични однесувања. Исто така покажуваме дека вградениот говорник модел репродуктира многу од овие прагматични однесувања.', 'ml': 'We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework.  പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് ഈ കൂട്ടിചേര്\u200dത്ത പ്രസ്താമിക് മോഡല്\u200d നിറം വിശദീകരിക്കുന്നതിനെക്കാള്\u200d വിശദീകരിക്കുന്നു. അതില്\u200d നി ഏറ്റവും കഠിനമായ കേസുകളില്\u200d പ്രസ്മാനിക്കുന്ന കാരണങ്ങള്\u200d പ്രധാനപ്പെടുത്തുന്നുണ്ടെന്ന് ഞങ്ങള്\u200d കാണുന്നു; മോഡല്\u200d വളരെ പോലുള്ള നിറങ് നമ്മുടെ കണ്ടുപിടികള്\u200d നിറമുള്ള വാക്കുകളില്\u200d മനുഷ്യരുടെ പുതിയ സംസാരം ഉപയോഗിക്കുന്ന ഒരു കോര്\u200dപ്പസ് ഉപയോഗിക്കുന്നു. അത് വ്യത അകത്തുള്ള സംസാരിക്കുന്ന മാതൃകയാണെന്നും നമ്മള്\u200d കാണിക്കുന്നു', 'no': 'Vi presenterer eit modell av pragmatisk refereringsuttrykk i ein grunnleggjande kommunikasjonsprogram (identifisering fargar frå beskrivelser) som teiknar på foregåver frå to rekursære neuralnettverksklassifikatorar, eit opplesar og ein lyttar, unifisert av eit rekursivt pragmatisk redensingsrammeverk. Eksperimentar viser at denne kombinerte pragmatiske modellen tolkar fargeskriftene meir nøyaktig enn klassifiseringane som den er bygd frå, og at mykje av denne forbetringa resulterer av å kombinere opplysningar og lysarperspektiva. Vi observerer at pragmatiske grunnlag hjelper hovudsakelig i dei vanskeste tilfellene: når modellen må distirere veldig liknande fargar, eller når få uttrykk tilsvarande uttrykk målfargen. Finningane våre gjer bruk av ein nytt samla korpus av menneske uttaler i fargereferansspel, som viser mange pragmatiske oppførsel. Vi viser også at den innebygde talemodellen gjev mange av desse pragmatiske oppførselsane.', 'mn': 'Бид pragmatic referring expression interpretation in a grounded communication task (descriptions from colors identifying) that draws up a prediction from two recurrent neural network classifiers, a speaker and a listener, combined by a recursive pragmatic reasoning framework. Энэ нийлүүлэгдэх прагматикийн загвар нь түүний бүтээгдэхүүнээс илүү тодорхой тодорхойлолтыг илүү тодорхойлдог гэдгийг харуулж байна. Энэ сайжруулалтын үр дүнг илтгэгч, сонсогч үзүүлэлтийг цуглуулахаас илүү тодорхойлдог Бид прагматикийн урьдчилан хамгийн хэцүү тохиолдолд тусалдаг гэдгийг анзаарсан: загвар нь маш ижил өнгөөр ялгах хэрэгтэй, эсвэл хэд хэдэн хэлбэрүүд зориулагдсан өнгөөр адилхан илэрхийлэх хэрэгтэй. Бидний олж мэдсэн зүйлс нь хүн төрөлхтний хэлэлцээний шинэ цуглуулсан корпус ашигладаг. Энэ нь олон төрлийн прагматикийн үйл явдал үзүүлдэг. Мөн бид илтгэгчийн загвар нь эдгээр прагматикийн үйл ажиллагааны олон зүйлийг бүтээж чадна.', 'ro': 'Prezentăm un model de interpretare pragmatică a expresiei de referință într-o sarcină de comunicare bazată (identificarea culorilor din descrieri) care se bazează pe predicțiile a doi clasificatori de rețele neurale recurente, un vorbitor și un ascultător, unificate printr-un cadru de raționament pragmatic recursiv. Experimentele arată că acest model pragmatic combinat interpretează descrierile culorilor mai precis decât clasificatorii din care este construit și că o mare parte din această îmbunătățire rezultă din combinarea perspectivelor difuzorului și ascultătorului. Observăm că raționamentul pragmatic ajută în primul rând în cele mai grele cazuri: atunci când modelul trebuie să distingă culori foarte similare, sau când puține pronunțări exprimă în mod adecvat culoarea țintă. Descoperirile noastre fac uz de un corpus recent colectat de expresii umane în jocurile de referință color, care prezintă o varietate de comportamente pragmatice. De asemenea, arătăm că modelul de difuzoare încorporate reproduce multe dintre aceste comportamente pragmatice.', 'pl': 'Przedstawiamy model pragmatycznej interpretacji wyrażeń odnoszących się do gruntowanego zadania komunikacyjnego (identyfikacja kolorów z opisów), który opiera się na przewidywaniach dwóch powtarzających się klasyfikatorów sieci neuronowej, mówcy i słuchacza, ujednoliconych przez rekursywny pragmatyczny framework rozumowania. Eksperymenty pokazują, że ten połączony model pragmatyczny interpretuje opisy kolorów dokładniej niż klasyfikatory, z których jest zbudowany, a duża część tej poprawy wynika z łączenia perspektywy mówcy i słuchacza. Obserwujemy, że pragmatyczne rozumowanie pomaga przede wszystkim w najtrudniejszych przypadkach: gdy model musi odróżniać bardzo podobne kolory, lub gdy niewiele wypowiedzi odpowiednio wyraża docelowy kolor. Nasze odkrycia wykorzystują nowo zebrany korpus ludzkich wypowiedzi w kolorowych grach referencyjnych, które wykazują różnorodne pragmatyczne zachowania. Pokazujemy również, że model wbudowanych głośników reprodukuje wiele z tych pragmatycznych zachowań.', 'ms': 'Kami perkenalkan model interpretasi ungkapan rujukan pragmatik dalam tugas komunikasi berdasarkan tanah (mengenalpasti warna dari deskripsi) yang menggunakan prediksi dari dua klasifikasi rangkaian saraf berulang-ulang, pembicara dan pendengar, disatukan oleh kerangka reasoning pragmatik berulang-ulang. Eksperimen menunjukkan bahawa model pragmatik kombinasi ini menerangkan deskripsi warna dengan lebih tepat daripada pengklasifikasi dari mana ia dibina, dan bahawa kebanyakan peningkatan ini berasal dari kombinasi perspektif pembicara dan pendengar. Kami memperhatikan bahawa alasan pragmatik membantu terutama dalam kes-kes yang paling sukar: apabila model mesti membezakan warna yang sangat serupa, atau apabila beberapa ungkapan mengekspresikan warna sasaran dengan cukup. Penemuan kami menggunakan korpus baru-dikumpulkan ucapan manusia dalam permainan rujukan warna, yang menunjukkan berbagai perilaku pragmatik. Kami juga menunjukkan bahawa model pembicara terbenam mereproduksi kebanyakan perilaku pragmatik ini.', 'sr': 'Predstavljamo model pragmatičnog preglednika izraza u temeljnom komunikacijskom zadatku (identifikacija boja od opisa) koji privlači predviđanja od dva rekonstruiranog klasifikatora neuralne mreže, govornika i slušatelja, ujedinjenog rekonstruzivnim pragmatičnim okvirom razuma. Eksperimenti pokazuju da ovaj kombinirani pragmatski model interpretira opise boja tačnije od klasifikatora iz kojih se izgradi, i da većina ovog poboljšanja rezultira od kombinacije perspektiva govornika i slušača. Primećujemo da pragmatički razgovor primarno pomaže u najtežim slučajevima: kada model mora da razlikuje veoma slične boje, ili kada nekoliko rečenica odgovaraju izraziti ciljnu boju. Naši nalazi koriste novo skupljenog korpusa ljudskih govora u bojnim referencijskim igricama, koja pokazuje razne pragmatične ponašanja. Takođe pokazujemo da uključeni model govornika reprodukuje mnoge od tih pragmatičnih ponašanja.', 'si': 'අපි ප්\u200dරාග්මතික ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරනවා (ප්\u200dරවේශනයෙන් ප්\u200dරතිචිත වර්ණයක් ප්\u200dරවේශනය කරනවා) ඒක ප්\u200dරවේශනයක් දෙක පරීක්ෂණය පෙන්වන්නේ මේ සම්බන්ධ ප්\u200dරාග්මික් මොඩල් වර්ණ වර්ණ විස්තර කිරීම් වලට වර්ණ විස්තර කිරීම් වලට වඩා ඇත්තටම විශේෂකයෙ අපි බලාපොරොත්තු කරනවා කියලා ප්\u200dරාග්මාටික හේතුව ප්\u200dරධාන විශ්වාස කරන්න පුළුවන් අමාරු විදිහට උදව් කරනවා: මොඩේල් එක ගොඩක් වග අපේ හොයාගන්න පුළුවන් අලුත් සම්පූර්ණයෙන් මිනිස්සුන්ගේ කොර්පුස් එකක් පාවිච්චි කරන්න පුළුවන් වර්ණ සෙල්ල අපිට පෙන්වන්න පුළුවන් වෙන්නේ මේ ප්\u200dරාග්මාටික ව්\u200dයාපෘතියක් ගොඩක් ප්\u200dරතිචාර කරනවා කියලා.', 'mt': 'Aħna nippreżentaw mudell ta’ interpretazzjoni prammatika ta’ espressjoni ta’ referenza f’kompitu ta’ komunikazzjoni bbażat fuq il-bażi (li jidentifika l-kuluri mid-deskrizzjonijiet) li jibbaża fuq tbassir minn żewġ klassifikaturi rikorrenti tan-netwerk newrali, kelliem u min jisma’, unifikat minn qafas ta’ raġunament prammatiku rikorrenti. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives.  Aħna ninnota li r-raġunament prammatiku jgħin primarjament fil-każijiet l-aktar diffiċli: meta l-mudell irid jiddistingwi kuluri simili ħafna, jew meta ftit kliem jesprimu b’mod adegwat il-kulur fil-mira. Is-sejbiet tagħna jagħmlu użu minn korpus li għadu kif in ġabar ta’ espressjonijiet umani fil-logħob ta’ referenza tal-kuluri, li juru varjetà ta’ mġibiet prammatiċi. Aħna nuru wkoll li l-mudell tal-kelliema inkorporat jirriproduċi ħafna minn dawn l-imġibiet prammatiċi.', 'so': 'Tusaale caagmad ah oo ku qoran turjubaan hadalka, waxan ku qornaa shaqada macluumaadka (aqoonsiga midabyada qoraalka) oo ka soo saara wax ka sii sheegaya labada fasaxyada shabakadda neurada ee soo socda, hadalka iyo dhegaysta, oo ku hagaajiya qashinka waxyaabaha ku saabsan. Imtixaanka waxaa muujinaya in tilmaamahan isku darsamay ay turjumaan tilmaamaha midibka oo si saxda ah ugu saxda fasalka laga dhisay, iyo in hagaajinta badan ka soo bandhigta aragtida hadalka iyo dhegta. Waxaynu aragnaa in sababta caadiga ah uu ugu horeyn caawiyaa xaaladaha ugu adag: marka modelku uu kala soocaa midabkaas oo kale ama marka uu ku hadlo hadal yar oo ku filan ku hadlo midabka goalka. Helitaankeenu waxay isticmaalaan hadallada dadka oo cusub loo soo ururiyey oo ku qoran ciyaaro kala duduwan oo kala duduwan. Sidoo kale waxaynu muujinnaa in muusikada hadalka ku hadlaa uu soo celiyo tababaradan badan.', 'sv': 'Vi presenterar en modell av pragmatisk referensuttryck tolkning i en grundad kommunikationsuppgift (identifiering av färger från beskrivningar) som bygger på förutsägelser från två återkommande neurala nätverksklassificerare, en talare och en lyssnare, förenade av ett rekursivt pragmatiskt resonemang ramverk. Experiment visar att denna kombinerade pragmatiska modell tolkar färgbeskrivningar mer exakt än de klassificerare som den bygger ifrån, och att mycket av denna förbättring är resultatet av att kombinera högtalare och lyssnare perspektiv. Vi observerar att pragmatiskt resonemang hjälper främst i de svåraste fallen: när modellen måste skilja mycket liknande färger, eller när få yttranden tillräckligt uttrycker målfärgen. Våra fynd använder sig av en nyligen samlad samling mänskliga yttranden i färgreferensspel, som uppvisar en mängd olika pragmatiska beteenden. Vi visar också att den inbyggda högtalarmodellen återger många av dessa pragmatiska beteenden.', 'ta': 'நாம் ஒரு மாதிரி குறிப்பிட்ட வெளிப்பாட்டை மாதிரியை கூறுகிறோம் ஒரு அடிப்படையான தொடர்பு பணியில் (விவரிப்புகளிலிருந்து வண்ணங்களை காட்டும்) அது மீண்டும் நிகழ்ந்த புத Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives.  மிகவும் கடினமான நிகழ்ச்சிகளில் முக்கியமாக காரணம் உதவுகிறது என்பதை நாம் பார்க்கிறோம்: மாதிரி முறைமையில் அதே போன்ற வண்ணங்களை பிரித்து எங்கள் கண்டுபிடிப்புகள் நிறம் குறிப்பு விளையாட்டு விளையாட்டுகளில் ஒரு புதிய சேகரிக்கப்பட்ட மனித பேச்சுகள் பயன்படுத்துகிறத உட்பொதிந்த பேசுபவர் மாதிரி இந்த புதிய நடத்தைகளில் பெரும்பாலான நடத்தைகளை மீட்டுகிறது என்பதை நாம் கா', 'ur': 'ہم ایک نمڈل پراگماتیک منظورت منظورت کی تعبیر کے مطابق بنیادی کمنیٹنی ٹاکس میں پیش آتے ہیں جو دوبارہ نیورل نیورل کلاسیر سے پیش آئی ہے، ایک سخنچیر اور ایک سننے والا، ایک دوبارہ پراگماتیک منظورت فرم سے متحد ہوئی ہے۔ تجربے دکھاتے ہیں کہ یہ ترکیب پراگماتیک موڈل رنگ کی تعریف کرتا ہے جس سے اس کو بنایا گیا ہے اس سے زیادہ دقیق تعریف کرتا ہے اور اس کی بہت سی ترکیب کا نتیجہ ہے کہ صحبت کرنے والی اور سننے والی نظریں ترکیب کرنے والی ہے۔ ہم دیکھتے ہیں کہ پراگرماتیک منظورت سب سے سخت کیسیوں میں مدد کرتی ہے: جب مدل بہت برابر رنگ اختلاف کرنا چاہیے، یا جب کم کلمات موجود رنگ کو اچھی طرح بیان کرتی ہیں۔ ہمارے نتیجے نئی جمع کئے ہوئے انسان کی کلمات کو رنگ رسالٹ کھیلیں میں استعمال کرتے ہیں، جو مختلف طریقے پراگٹیک رفتار کو دکھاتے ہیں. ہم نے بھی دکھایا ہے کہ انڈیلڈ سپیکر موڈل ان کی بہت سی پراگٹیک رفتار کو دوبارہ پیدا کرتا ہے۔', 'uz': "Biz tashkilotning asosiy aloqa vazifani (taʼriflar bilan ranglarni aniqlash) haqida gapiruvchi modelni hozir qilamiz. Bu ikkita takrorlanadigan tarmoq turlarini, gapiruvchi va tinglovchilarga birlashtirish mumkin. Tajribalar bu birlashtirilgan pragmatik modeli rang taʼriflarini o'rganish mumkin, uni quyidagi darajalardan ham juda muhimiy o'rganish mumkin. Bu ko'pchilik gapiruvchi va tinglovchi shakllarni birlashtirish natijalariga ega beradi. Biz shunday ko'rinamiz, pragmatik sababning asosiy eng qiyin holatda yordam beradi: model huddi ko'proq rangni ajratilishi kerak, yoki qanchalik so'zlarda qancha so'zlarning foydalanishi kerak. Bizning murakkablarimiz rang reference oʻyinlarida yangi bir necha тўпланган inson so'zlarini ishlatadi. Bu ko'plab turli pragmatik xuddi ko'rsatadi. Ko'rib chiqqan gapiruvchi modeli bu ko'pchilik tabiiy xuddi qaytadi.", 'vi': 'Chúng tôi giới thiệu một mô hình của trình diễn ngữ dụng dụng trong một nhiệm vụ liên lạc dựa trên các màu sắc từ mô tả, mà dựa trên dự đoán từ hai phân loại mạng thần kinh liên tục, một người đọc và một người nghe, thống nhất bởi một điều lý lập trường đệ tử. Thí nghiệm cho thấy rằng mô hình phối hợp thực dụng này hiểu mô tả màu một cách chính xác hơn các phân loại mà nó được tạo ra, và rằng phần lớn tiến bộ này là nhờ kết hợp các góc nhìn của loa và thính giả. Chúng tôi nhận thấy rằng suy nghĩ thực tế giúp đỡ đầu tiên trong những trường hợp khó khăn nhất: khi mẫu phải phân biệt màu sắc rất giống nhau, hoặc khi một số nét đủ trình diễn tả màu đích. Những phát hiện của chúng tôi sử dụng một tập thể người mới thu được trong các trò chơi tôn trọng màu sắc, những thứ có nhiều hành vi thực dụng. Chúng tôi cũng cho thấy mô hình loa được gắn vào này tái tạo nhiều hành vi thực dụng này.', 'bg': 'Представяме модел на прагматична интерпретация на референтните изрази в обоснована комуникационна задача (идентифициране на цветовете от описания), която се основава на прогнози от два повтарящи се класификатора на невронната мрежа, говорител и слушател, обединени от рекурсивна прагматична рамка на разсъждение. Експериментите показват, че този комбиниран прагматичен модел интерпретира цветовите описания по-точно от класификаторите, от които е изграден, и че голяма част от това подобрение е резултат от комбинирането на гледната точка на говорителя и слушателя. Наблюдаваме, че прагматичното разсъждение помага предимно в най-трудните случаи: когато моделът трябва да разграничава много сходни цветове или когато малко изказвания изразяват адекватно целевия цвят. Нашите открития използват новосъбран корпус от човешки изказвания в цветни референтни игри, които показват разнообразие от прагматични поведения. Показваме също, че вграденият модел на високоговорител възпроизвежда много от тези прагматични поведения.', 'nl': 'We presenteren een model van pragmatische verwijzende expressie interpretatie in een geaard communicatietaak (het identificeren van kleuren uit beschrijvingen) dat gebaseerd is op voorspellingen van twee terugkerende neurale netwerkclassificatoren, een spreker en een luisteraar, verenigd door een recursief pragmatisch redeneringskader. Experimenten tonen aan dat dit gecombineerde pragmatische model kleurbeschrijvingen nauwkeuriger interpreteert dan de classificatoren waaruit het is opgebouwd, en dat veel van deze verbeteringen voortvloeit uit het combineren van het spreker- en luisterperspectief. We zien dat pragmatisch redeneren vooral helpt in de moeilijkste gevallen: wanneer het model zeer gelijkaardige kleuren moet onderscheiden, of wanneer weinig uitspraken de doelkleur adequaat uitdrukken. Onze bevindingen maken gebruik van een nieuw verzameld corpus van menselijke uitspraken in kleurenreferentiespellen, die een verscheidenheid aan pragmatisch gedrag vertonen. We laten ook zien dat het embedded speaker model veel van deze pragmatische gedragingen reproduceert.', 'da': 'Vi præsenterer en model for pragmatisk referenceudtryksfortolkning i en grundlagt kommunikationsopgave (identificering af farver fra beskrivelser), der trækker på forudsigelser fra to tilbagevendende neurale netværksklassificere, en taler og en lytter, forenet af en rekursiv pragmatisk ræsonneringsramme. Eksperimenter viser, at denne kombinerede pragmatiske model fortolker farvebeskrivelser mere præcist end klassifikationerne, hvorfra den er bygget, og at meget af denne forbedring skyldes at kombinere højttaler- og lytterperspektiver. Vi bemærker, at pragmatisk ræsonnement hjælper primært i de sværeste tilfælde: når modellen skal skelne meget lignende farver, eller når få udtalelser tilstrækkeligt udtrykker målfarven. Vores resultater gør brug af et nyligt indsamlet korpus af menneskelige udtalelser i farvereferencespil, som udviser en række pragmatiske adfærd. Vi viser også, at den integrerede højttalermodel gengiver mange af disse pragmatiske adfærd.', 'hr': 'Predstavljamo model pragmatičnog interpretacije izražavanja izražavanja u temeljnom komunikacijskom zadatku (identifikacija boja iz opisa) koji se nalazi predviđanja od dva rekonstruiranog klasifikatora neuralne mreže, govornika i slušatelja, ujedinjenog rekonstruiranim pragmatičnim okvirom razuma. Eksperimenti pokazuju da ovaj kombinirani pragmatski model interpretira opise boja preciznije od klasifikatora iz kojih se izgradi, i da većina ovog poboljšanja rezultira od kombinacije perspektiva govornika i slušača. Primjećujemo da pragmatički razgovor primarno pomaže u najtežim slučajevima: kada model mora odlučiti vrlo slične boje, ili kada nekoliko izraza odgovaraju izraziti ciljnu boju. Naši nalazi koriste novo skupljenog korpusa ljudskih govora u bojnim referentnim igricama, koja pokazuje razne pragmatične ponašanja. Također pokazujemo da uključeni model govornika reprodukuje mnoge od tih pragmatičnih ponašanja.', 'de': 'Wir präsentieren ein Modell der pragmatischen Interpretation referierender Ausdrücke in einer geerdeten Kommunikationsaufgabe (Identifizierung von Farben aus Beschreibungen), die auf Vorhersagen von zwei wiederkehrenden Klassifikatoren neuronaler Netze basiert, einem Sprecher und einem Hörer, vereint durch ein rekursives pragmatisches Argumentationsframework. Experimente zeigen, dass dieses kombinierte pragmatische Modell Farbbeschreibungen genauer interpretiert als die Klassifikatoren, aus denen es aufgebaut ist, und dass ein großer Teil dieser Verbesserung auf die Kombination der Sprecher- und Zuhörerperspektive zurückzuführen ist. Wir beobachten, dass pragmatisches Denken vor allem in den schwierigsten Fällen hilft: wenn das Modell sehr ähnliche Farben unterscheiden muss, oder wenn wenige Äußerungen die Zielfarbe adäquat ausdrücken. Unsere Ergebnisse nutzen einen neu gesammelten Korpus menschlicher Äußerungen in Farbreferenzspielen, die eine Vielzahl pragmatischer Verhaltensweisen aufweisen. Wir zeigen auch, dass das Embedded Speaker Modell viele dieser pragmatischen Verhaltensweisen reproduziert.', 'id': 'Kami mempersembahkan model interpretasi ekspresi pragmatis yang merujuk dalam tugas komunikasi berdasarkan dasar (mengidentifikasi warna dari deskripsi) yang berdasarkan prediksi dari dua klasifikasi jaringan saraf yang berulang-ulang, pembicara dan pendengar, bersatu dengan rangka reasoning pragmatis yang berulang-ulang. Eksperimen menunjukkan bahwa model pragmatis kombinasi ini menerjemahkan deskripsi warna dengan lebih akurat daripada klasifikasi dari mana ia dibangun, dan bahwa kebanyakan dari perkembangan ini berasal dari kombinasi perspektif pembicara dan pendengar. Kami memperhatikan bahwa alasan pragmatis membantu terutama dalam kasus yang paling sulit: ketika model harus membedakan warna yang sangat mirip, atau ketika beberapa ucapan secara adekwat mengekspresikan warna sasaran. Penemuan kami menggunakan tubuh manusia yang baru dikumpulkan dalam permainan referensi warna, yang menunjukkan berbagai perilaku pragmatis. Kami juga menunjukkan bahwa model pembicara terbenam mereproduksi kebanyakan perilaku pragmatis ini.', 'ko': '우리는 뿌리 깊은 교류 임무(묘사에서 색채를 식별하는 것)에서의 어용 지칭 표현 해석 모델을 제시했다. 이 모델은 두 개의 귀속신경 네트워크 분류기(말하는 사람과 듣는 사람)의 예측을 활용하고 귀속어용 추리 구조가 통일되었다.실험에 의하면 이런 조합어용 모델은 색채 묘사를 구축하는 분류기보다 색채 묘사를 정확하게 해석할 수 있고 이러한 개선은 어느 정도에 말하는 사람과 듣는 사람의 시각의 결합 덕분이다.우리는 언어용 추리가 가장 어려운 상황에서 도움이 된다는 것을 관찰했다. 모델이 매우 비슷한 색깔을 구분해야 할 때나 목표의 색깔을 충분히 표현할 수 있는 말이 적을 때.우리의 발견은 새로 수집된 색깔을 이용하여 게임 속의 인간 언어 자료 라이브러리를 참조했다. 이 자료 라이브러리는 다양한 언어 사용 행위를 보여주었다.우리는 또 삽입식 말하는 사람 모델이 이런 언어 사용 행위를 많이 재현한 것을 발견했다.', 'fa': 'ما یک مدل تعبیر عبارت پراگرماتیک را در یک کار ارتباطی پایین (شناسایی رنگ از توصیف\u200cها) نشان می\u200cدهیم که بر پیش\u200cبینی\u200cها از دو گروه\u200cکننده شبکه عصبی تکرار می\u200cکند، یک سخنرانی و یک گوش\u200cکننده، با یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچ تجربه\u200cها نشان می\u200cدهند که این مدل پراگرماتیک ترکیب می\u200cدهد توضیح\u200cهای رنگ دقیقاً بیشتر از کلاسیه\u200cها که ساخته می\u200cشود، و بیشتر از این توسعه\u200cها نتیجه\u200cهای توسعه\u200cهای صحبت کننده و گوش کننده\u200cها را ترکیب می\u200cدهد. ما مشاهده می\u200cکنیم که دلیل پراگرماتیک در مورد سخت\u200cترین موارد کمک می\u200cکند: زمانی که مدل باید رنگ\u200cهای بسیار مشابه را تفاوت کند، یا زمانی که چند کلمه\u200cها رنگ هدف را به طور مناسب بیان می\u200cکند. پیدا کردن ما از یک جسد جدید جمع شده از سخنرانی انسان در بازی های مربوط به رنگ استفاده می کنند که به طریق رفتارهای مختلف پراگرماتیک نشان می دهد. ما همچنین نشان می دهیم که مدل صحبت\u200cکننده\u200cی پیدا شده بسیاری از این رفتارهای پراگرماتیک را تولید می\u200cکند.', 'sw': 'Tunaweka mfano wa tafsiri ya kujieleza katika kazi ya mawasiliano yenye msingi (kutambua rangi kutoka maelezo) inayoonyesha utabiri kutoka kwa wataalamu wawili wa mtandao wa neura unaoendelea, mzungumzaji na msikilizaji, ulioanganishwa na mfumo wa maneno yanayoelezea. Majaribio yanaonyesha kuwa mtindo huu wa pamoja unatafsiri maelezo ya rangi yenye sahihi zaidi ya wataalamu ambao unajengwa, na kwamba maendeleo haya yanatokana na kuunganisha mtazamo wa sauti na kusikiliza. Tunaona kwamba sababu za msingi zinasaidia hasa katika kesi ngumu: wakati model lazima kutofautisha rangi kama hizo, au wakati maneno machache yanapoelezea rangi inayolenga. Matokeo yetu yanatumia makampuni mapya ya maneno ya binadamu katika michezo ya maoni ya rangi, ambayo inaonyesha tabia mbalimbali za utamaduni. Tunaonyesha pia kuwa mtindo wa mazungumzaji wa mazungumzo yaliyoingizwa unabadilisha tabia hizi za uongozi.', 'tr': 'Biz pragmatik surat çykyşynyň bir nusgasyny (tassyklardan renkler identifikaýan) sistemasynda çykyş etmek üçin bir nusgasy çykyşynyň, suratçy we diňleyär bilen birleştirilýäris. Experimentalar bu birleşen pragmatik nusgasy renk tassymlaryny tanyşdyrýandygyny görkezýär we bu gelişmeleriň köpüsi çykyş we diňläk perspektiblerini birleştirmekden çykýardygyny görkezýär. Pragmatik mantıklar en zor durumlarda özellikle yardımcı olur diye göz önüne getiriyoruz: modelde örän benzeri renkleri farklı etmeli, ya da birkaç söz hedef rengini yeterli ifade etmeli. Biziň tapylarymyz täze toplanýan adam sözleriniň reňk oýunlarynda ullanýar, şol bir näçe pragmatik hereketleriň görnüşi görkeýär. Biz hem daşary çykyş nusgasynyň bu pragmatik hereketleriň köpüsini taýýarlandyrýandygyny görkeýäris.', 'af': "Ons stel 'n model van pragmatike verwysing uitdrukking in 'n gegrónde kommunikasie taak (identifiseer kleure van beskrywings) wat teken op voorskoude van twee herhaalde neuralnetwerk klassifiseerders, 'n sprekker en 'n luister, geeenigde deur 'n rekursief pragmatike rederaamwerk. Eksperimente wys dat hierdie gekombineerde pragmatike model uittel kleur beskrywings meer presies as die klassifiseerders waarvan dit gebou is, en dat baie van hierdie verbetering resultate van die sprekker en luister perspeksies te kombinerer. Ons bewaar dat pragmatiske redening hulp voorskynlik in die hardeste geval: wanneer die model baie gelyke kleure moet uitvee, of wanneer paar uitdrukkings die doel kleur adequate uitdruk. Ons vindings maak gebruik van 'n nuwe versameling korpus van menslike uitspraak in kleur verwysing speletjies wat 'n verskeie pragmatike gedrag vertoon. Ons wys ook dat die inbêde sprekker model baie van hierdie pragmatiske gedragte herhaal.", 'sq': 'Ne paraqesim një model të interpretimit pragmatik të shprehjes në një detyrë komunikimi të themeluar (identifikimi i ngjyrave nga përshkrimet) që mbështetet në parashikimet nga dy klasifikuesit e rrjetit neural të përsëritur, një folës dhe një dëgjues, të unifikuar nga një kuadër pragmatik të përsëritur arsyetimi. Eksperimentet tregojnë se ky model pragmatik i kombinuar interpreton përshkrimin e ngjyrave më saktësisht se klasifikuesit nga të cilët është ndërtuar dhe se shumica e këtij përmirësimi rezulton nga kombinimi i perspektivave të folurit dhe të dëgjuesve. Ne vëzhgojmë se arsyetimi pragmatik ndihmon kryesisht në rastet më të vështira: kur modeli duhet të dallojë ngjyra shumë të ngjashme, ose kur pak shprehje shprehin ngjyrën e objektivit në mënyrë të përshtatshme. Gjetjet tona përdorin një korpus të sapo-mbledhur shprehje njerëzore në lojrat e referimit të ngjyrave, të cilat ekspozojnë një varietet sjelljesh pragmatike. Ne gjithashtu tregojmë se modeli i zëdhënësve të përfshirë riprodhon shumë nga këto sjellje pragmatike.', 'am': 'በተመሳሳይ የደብዳቤ መረብ ክፍተቶችን፣ ተናጋሪ እና ሰሚ፣ በተለየ አካባቢ አካባቢ ክፍል የተጠቃሚ የደብዳቤ መረብ ክፍተቶችን በሚያሳውቅ (ከትርጓሜዎች የተለየ ቀለም የሚታወቅ ቀለም) የሚታወቅ ምሳሌ እናደርጋለን፡፡ ፈተናዎች ይህ የተጠቃበ ፕሮግራሞች ሞዴል ከዚያ ከተገነባው ክፍሎች ይልቅ ቀለም ጽሑፎችን እንዲያስተርጉታል፡፡ አካባቢ ምክንያት በተጨማሪው ጉዳዮች ላይ የሚረዳው መሆኑን እናደርጋለን፤ ምሳሌው በተለያዩ ቀለም መሆኑን ወይም የተጠቃሚ ቃላት የተጠቃሚ ቀለም በሚያሳየው ጊዜ እናስታውቃለን፡፡ ፍጥረታችን አዲስ የተሰበሰቡ የሰው ንግግር አፍሪካ አካላት በዘር አፍሪካዊ ጨዋታ ላይ ነው፡፡ እናሳያቸዋለን፡፡', 'hy': 'Մենք ներկայացնում ենք պրագմատիկ արտահայտության մեկնաբանության մի մոդել հիմնված հաղորդակցման խնդրում (նկարագրություններից ստացված գույները հայտնաբերվում են), որը հիմնված է երկու կրկնվող նյարդային ցանցի դասակարգչի կանխատեսումների վրա, խոսնակի և լսողի կողմից, միավորված կրկնվող պրագմատիկ Փորձարկումները ցույց են տալիս, որ այս համադրված պրագմատիկ մոդելը գույների նկարագրությունները ավելի ճշգրիտ մեկնաբանում է, քան այն դասակարգերը, որից այն կառուցվում է, և որ այս բարելավման մեծ մասը հանգեցնում է խոսացողի և լսողի տեսանկյունների համադրման: Մենք նկատում ենք, որ պրագմատիկ մտածելակերպը հիմնականում օգնում է ամենաբարդ դեպքերում. երբ մոդելը պետք է տարբերակի շատ նմանատիպ գույներ, կամ երբ մի քանի արտահայտություններ հարմար են արտահայտում նպատակային գույնը: Մեր հայտնաբերությունները օգտագործում են նորից հավաքված մարդկային արտահայտությունների մարմին գույների հաղորդակցման խաղերում, որոնք ցույց են տալիս տարբեր պրագմատիկ վարքագծեր: Մենք նաև ցույց ենք տալիս, որ ներդրված խոսնակի մոդելը վերարտադրում է այս պրագմատիկ վարքագիծը:', 'bn': 'আমরা একটি ভিত্তিক যোগাযোগের কাজে (বর্ণনা থেকে রংগুলো চিহ্নিত করা) ব্যবহারকারীদের ব্যাখ্যা প্রকাশ করার মডেল উপস্থাপন করি যা প্রত্যাবর্তনের দুই নিউরেল নেটওয়ার্ক বিভাগের প্রত পরীক্ষাগুলো দেখাচ্ছে যে এই একত্রিত প্রাম্যামেটিক মডেল রঙের বর্ণনার ব্যাখ্যা বেশি সঠিকভাবে ব্যাখ্যা করে যেখান থেকে তা নির্মাণ করা হয়েছে এবং এই আমরা দেখতে পাচ্ছি যে প্রচণ্ড কারণ প্রধান কঠিন ক্ষেত্রে সাহায্য করে: যখন মডেলটি খুব একই রকম রঙের বিচ্ছিন্ন করা উচিত, অথবা যখন কয়েকটি ভাষায় লক্ষ আমাদের আবিস্কার নতুন সংগ্রহ করা মানুষের ভাষার কোর্পাস ব্যবহার করে, যা রঙের রেফারেন্স খেলায় বিভিন্ন ধরনের বিভিন্ন ধরনের প্রা আমরা একই সাথে দেখাচ্ছি যে আবদ্ধ স্পিকারের মডেল এই ব্যাপারটির অনেক আচরণ পুনরুদ্ধার করেছে।', 'az': 'Biz pragmatik ifad…ôsi yorumlayńĪcńĪnńĪn modelini t…ôsdiql…ôyirik. Bu, iki tekrarlńĪ n√∂ral a ńü klasifikatńĪndan, danńĪŇüńĪcńĪ v…ô dinl…ôyici t…ôsdiql…ôyici pragmatik d…ôyiŇüiklik frameworkl…ô birlikl…ônir. H…ôqiq…ôt…ôn, t…ôcr√ľb…ôl…ôr bunun birl…ôŇüdirilmiŇü pragmatik modelinin r…ôngli t…ôcr√ľb…ôl…ôrinin √∂z√ľn√ľn inŇüa edildikl…ôrind…ôn daha dońüru olduńüunu g√∂st…ôrir v…ô bu t…ôcr√ľb…ôl…ôrin √ßoxu danńĪŇüńĪcńĪ v…ô dinl…ôyici perspektivl…ôrinin birl…ôŇüdirilm…ôsind…ôn sonu√ßlarńĪnńĪ g√∂st…ôrir. Biz pragmatik razńĪlńĪq …ôn √ß…ôtin m…ôs…ôl…ôl…ôrd…ô ilk d…ôf…ô k√∂m…ôk edir: modeli √ßox b…ônz…ôr r…ôngl…ôri ayńĪrmalńĪdńĪr, yaxud az s√∂zl…ôr m…ôqs…ôdil…ô r…ôngli ifade edirl…ôr. Bizim tapńĪlarńĪmńĪz yeni toplanmńĪŇü insan s√∂zl…ôrini r…ôngli referans oyunlarńĪnda istifad…ô edir ki, bunun m√ľxt…ôlif pragmatik davranńĪŇülarńĪnńĪ g√∂st…ôrir. Biz d…ô g√∂st…ôririk ki, i√ß…ôrisind…ô olan s√∂hb…ôt√ßi modeli bu pragmatik davranńĪŇülarńĪn √ßoxunu t…ômizl…ôyir.', 'bs': 'Predstavljamo model pragmatičnog interpretacije izražavanja izražavanja u temeljnom komunikacijskom zadatku (identifikacija boja iz opisa) koji privlači predviđanja od dva povratnih klasifikatora neuralne mreže, govornika i slušatelja, ujedinjenog rekursivnim pragmatičnim okvirom razuma. Eksperimenti pokazuju da ovaj kombinirani pragmatski model interpretira opise boja preciznije od klasifikatora iz kojih se izgradi, i da većina ovog poboljšanja rezultira od kombinacije perspektiva govornika i slušača. Primećujemo da pragmatički razgovor pomaže primarno u najtežim slučajevima: kada model mora da razlikuje veoma slične boje, ili kada nekoliko izraza odgovaraju izraziti ciljnu boju. Naši nalazi koriste novo skupljenog korpusa ljudskih govora u bojnim referencijskim igricama, koja pokazuje razne pragmatične ponašanja. Također pokazujemo da uključeni model govornika reprodukuje mnoge od tih pragmatičnih ponašanja.', 'ca': "Presentam un model d'interpretació de l'expressió de referència pragmàtica en una tasca de comunicació basada (identificant colors de descripcions) que es basa en prediccions de dos classificadors recurrents de xarxa neural, un parlant i un escoltant, unificats per un marc de raonament pragmàtic recurrent. Els experiments demostren que aquest model pragmàtic combinat interpreta les descripcions de color amb més precisió que els classificadors a partir dels quals es construeix, i que gran part d'aquesta millora resulta de combinar les perspectives del parlant i de l'escoltar. Observem que el raonament pragmàtic ajuda principalment en els casos més difícils: quan el model ha de distingir colors molt similars, o quan poques expressions expressen el color de l'objectiu adequadament. Els nostres descobriments utilitzen un cos de frases humanes recentment recollits en jocs de referència de color, que mostran una varietat de comportaments pragmàtics. També demostram que el model d'orador incorporat reprodueix molts d'aquests comportaments pragmàtics.", 'cs': 'Představujeme model pragmatické interpretace referenčních výrazů v uzemněné komunikační úloze (identifikace barev z popisů), který vychází z predikcí dvou recidivujících se klasifikátorů neuronových sítí, řečníka a posluchače, sjednocených rekurzivním pragmatickým uvažovacím rámcem. Experimenty ukazují, že tento kombinovaný pragmatický model interpretuje barevné popisy přesněji než klasifikátory, ze kterých je postaven, a že velká část tohoto zlepšení vyplývá z kombinace pohledu řečníka a posluchače. Pozorujeme, že pragmatické uvažování pomáhá především v těch nejtěžších případech: kdy model musí rozlišovat velmi podobné barvy, nebo když málo výroků adekvátně vyjadřuje cílovou barvu. Naše zjištění využívají nově shromážděného korpusu lidských výroků v barevných referenčních hrách, které vykazují řadu pragmatických chování. Také ukazujeme, že model vestavěných reproduktorů reprodukuje mnoho z těchto pragmatických chování.', 'et': 'Esitleme pragmaatilise viitava väljenduse tõlgendamise mudelit põhjendatud kommunikatsioonitöös (värvide identifitseerimine kirjeldustest), mis tugineb kahe korduva närvivõrgu klassifikaatori, kõneleja ja kuulaja prognoosidele, mida ühendab rekursiivne pragmaatiline arutlusraamistik. Eksperimentid näitavad, et see kombineeritud pragmaatiline mudel tõlgendab värvikirjeldusi täpsemalt kui klassifitseerijad, millest see on ehitatud, ning et suur osa sellest paranemisest tuleneb kõneleja ja kuulaja perspektiivide kombineerimisest. Me täheldame, et pragmaatiline mõtlemine aitab eelkõige kõige raskematel juhtudel: kui mudel peab eristama väga sarnaseid värve või kui vähesed sõnad väljendavad sihtvärvi piisavalt. Meie tulemused kasutavad värviviitemängudes äsja kogutud inimsõnade korpust, mis näitavad erinevaid pragmaatilisi käitumisi. Samuti näitame, et sisseehitatud kõlarimudel reprodutseerib paljusid neid pragmaatilisi käitumisi.', 'fi': 'Esitämme pragmaattisen viittaavan ilmaisun tulkinnan mallin pohjautuvassa viestintätehtävässä (värien tunnistaminen kuvauksista), joka perustuu kahden toistuvan neuroverkkoluokittelijan, puhujan ja kuuntelijan ennusteisiin, jotka yhdistyvät rekursiivisen pragmaattisen päättelykehyksen avulla. Kokeet osoittavat, että tämä yhdistetty pragmaattinen malli tulkitsee värikuvauksia tarkemmin kuin luokittelijat, joista se on rakennettu, ja että suuri osa tästä parannuksesta johtuu puhujan ja kuuntelijan näkökulmien yhdistämisestä. Havaitsemme, että pragmaattinen päättely auttaa ensisijaisesti vaikeimmissa tapauksissa: kun mallin täytyy erottaa hyvin samankaltaiset värit tai kun harvat lauseet ilmaisevat riittävästi kohdeväriä. Löydöksissämme hyödynnetään hiljattain kerättyä ihmisilmaisujen korpusta värireferenssipeleissä, joissa esiintyy erilaisia pragmaattisia käyttäytymisiä. Osoitamme myös, että sulautettu kaiutinmalli toistaa monia näistä käytännönläheistä käyttäytymistä.', 'ha': "Tuna gabatar da wani misali na nemi fassarar magana a cikin wani aikin maganar ajiya a baka (kana gane launin daga descripti) wanda ke nuna wa'adi daga dangani biyu masu dangantar tarayya na bakwai, mai magana da mai saurãre, wanda ya yi haɗi da firam mai fassara mai fassara. Jajararin na nuna cewa, wannan misali da aka haɗa shi na fassara tsarin launi mafi tsari daga sifilado wanda aka gina shi daga, kuma, ƙarami masu yawa daga wannan gyarata ta ƙara daga haɗi da gannain mai magana da mai saurãre. Tuna ganin cewa sababin pragaiti na ƙara amfani kaɗan a cikin masu hushi masu tsananin: idan misãlin ya ƙayyade launin da ke daidaita, ko idan da sauran magana masu daidai ta bayyana launin goan. MataimakinMu na yi amfani da wata takardar mutane da aka samu a yanzu cikin gamuwa na misalin launi, wanda ke nuna wasu abubuwa masu bastarwa. Kayya da Muke nũna, da misãlin mai faɗa da ke ƙara masu yawa na hanyoyin wannan.", 'jv': 'We present a model of pragram reference Expression Name Awak dhéwé éntukno pragatik, sapa-sanggunaké luwih nggawe Kasama sing apik dhéwé: nek model kudu isih alaman barang sampeyan sampeyan, opo, sapa kelangan langgar sampeyan gewisak nggawe aturan tambahan. Ndheke awak dhéwé nggawe barang-barang uwong gawe ngubah perkaran sing nganggep nggawe barang uwong, sing uwis kuwi tindak nggawe barang-uwong sing entuk dhéwé. Awak dhéwé ngerasakno ngono, akeh modèl wong liyané perbudhakan neng akeh pragmatik iki.', 'he': 'אנו מציגים מודל של פירוש ביטוי פרגמטי במשימת תקשורת מבוססת (מזהה צבעים מהתיאורים) שמבוסס על חזיונות משני מערכות רשת עצבית חוזרות, רמקול ומקשיב, מאוחד על ידי סגרת הגיון פרגמטי חוזרת. ניסויים מראים שהמודל הפרגמטי המשולב הזה מפרסם תיאורים צבעים יותר מדויקים מהקלאספים ממנו הוא בנוי, ושרבה מהשיפור הזה תוצאה משולב הנקודות של הרמקול והמקשיב. אנו רואים שהסיבה פרגמטית עוזרת בעיקר במקרים הקשים ביותר: כאשר המודל צריך להבדיל צבעים דומים מאוד, או כאשר מעט מבטאות מבטאות בצורה מתאימה לצבע המטרה. הממצאים שלנו משתמשים בקורפוס אוסף חדש של מילים אנושיים במשחקי ציור צבעים, אשר מציגים מגוון של התנהגויות פרגמטיות. אנחנו גם מראים שדוגמנית הרמקול המוכנה מתחזרת הרבה מההתנהגויות הפרגמטיות האלה.', 'sk': 'Predstavljamo model pragmatične interpretacije referenčnih izrazov v osnovljeni komunikacijski nalogi (identifikacija barv iz opisov), ki temelji na napovedih dveh ponavljajočih se nevronskih mrež klasifikatorjev, govorca in poslušalca, združenih z rekurzivnim pragmatičnim okvirom razmišljanja. Eksperimenti kažejo, da ta kombinirani pragmatični model razlaga barvne opise natančneje kot klasifikatorji, iz katerih je zgrajen, in da je velik del teh izboljšav posledica združevanja perspektiv govornika in poslušalca. Ugotavljamo, da pragmatično razmišljanje pomaga predvsem v najtežjih primerih: ko mora model razlikovati zelo podobne barve ali ko malo izgovorov ustrezno izraža ciljno barvo. Naše ugotovitve uporabljajo na novo zbran korpus človeških izgovorov v barvnih referenčnih igrah, ki kažejo različno pragmatično vedenje. Pokazali smo tudi, da vgrajeni model zvočnikov reproducira veliko teh pragmatičnih vedenj.', 'bo': 'ང་ཚོས་རྗེས་སུ་འབྲེལ་བ་དང་ཐོག་ལས་གཟུགས་རིས་བཤད་ཀྱི་མ་དཔེ་གཏོང་བ་དེ། Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives. ང་ཚོས་བློ་གཏོང་ཁང་གི་རྒྱུ་མཚན་དེ་དག་ལ་ཁག་ཅིག་ཁག་མཐུན་ཁག་ཅིག་ཡོད་པ་དེ་ལས། ང་ཚོའི་མཐོང་སྣང་ཚུལ་འདི་ལྟ་བུའི་མཐུན་སྣེ་གསར་བསྐྲུན་པའི་མིང་ཚོའི་ཐ་སྙད་ཅིག་ལག་ལེན་འཐབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ནང་དུ་ཡོད་པའི་ཁ་གཟུགས་རིས་བློ་གཏོང་མཁན་གྱི་སྒེར་གྱི་འགྲོ་སྟངས་མང་པོ་ཞིག་ཏུ་སྐྱེལ་འདུག'}
{'en': 'Google’s Multilingual Neural Machine Translation System : Enabling Zero-Shot Translation', 'ar': 'نظام ترجمة الآلة العصبية متعدد اللغات من Google: تمكين الترجمة بدون طلقة', 'fr': 'Le système de traduction automatique neuronale multilingue de Google\xa0: permettre la traduction zero-shot', 'es': 'El sistema de traducción automática neuronal multilingüe de Google: habilitación de la traducción cero', 'pt': 'Sistema de tradução automática neural multilíngue do Google: como ativar a tradução zero-shot', 'ja': 'Googleの多言語ニューラルマシン翻訳システム:ゼロショット翻訳を有効にする', 'zh': '谷歌多语言神经机器翻译系统:成零点击译', 'hi': 'Google की बहुभाषी तंत्रिका मशीन अनुवाद प्रणाली: शून्य-शॉट अनुवाद सक्षम करना', 'ru': 'Многоязычная система нейронного машинного перевода Google: включение нулевого перевода', 'ga': 'Córas Néar-Aistrithe Meaisín Ilteangach Google: Aistriú Zero-Shot a Chumasú', 'hu': 'A Google többnyelvű neurális gépi fordítási rendszere: Zero-Shot fordítás engedélyezése', 'el': 'Το πολυγλωσσικό νευρωνικό σύστημα μηχανικής μετάφρασης της επιτρέπει τη μετάφραση μηδενικού πυροβολισμού', 'it': 'Il sistema multilingue di traduzione automatica neurale di Google: abilitazione della traduzione zero-shot', 'lt': 'Google daugiakalbė neurologinių mašinų vertimo sistema: įgalinti nulinį vertimą', 'kk': 'Google- нің көп тілді нейрал машинаны аудару жүйесі: 0- Shot аудармасын рұқсат ету', 'mk': 'Мултијазичен систем на преведување на неврални машини на Гугл: овозможува преведување со нула пукање', 'ms': 'Sistem Terjemahan Mesin Neural Berbahasa Google: Membenarkan Terjemahan-Zero-Shot', 'ml': 'ഗൂഗിളിന്റെ പല ഭാഷ നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷ സിസ്റ്റം: പൂജ്യ- ഷോട്ട് പരിഭാഷപ്പെടുത്തുന്നത് പ്രാവര്\u200dത', 'mt': 'Is-Sistema ta’ Traduzzjoni Multilingwi tal-Magna Newrali ta’ Google: Tippermetti Traduzzjoni Żero-Shot', 'pl': 'Wielojęzyczny system maszynowego tłumaczenia neuronowego Google: umożliwiający tłumaczenie zerowe', 'ro': 'Sistemul multilingv de traducere automată neurală Google: activarea traducerii zero-shot', 'ka': 'Google- ის მრავალენგური ნეირალური მაქსინის გადატყვება სისტემა: Zero- Shot გადატყვება', 'si': 'ගූගුල් ගේ ගොඩක් භාෂාවක් න්\u200dයූරල් මැෂින් වාර්තාව පද්ධතිය: Zero- Shot වාර්තාව සක්\u200dරිය කරන්න', 'so': 'Turjumista qoraalka qoraalka', 'sv': 'Googles flersprĂ¥kiga neurala maskinĂ¶versĂ¤ttningssystem: Aktivera noll-skott Ă¶versĂ¤ttning', 'ta': "Google' s Multilingual Neural Machine Translation System: Zero- Shot மொழிபெயர்ப்பை செயல்படுத்துகிறது", 'sr': 'Google-ov Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation', 'ur': 'گوگل کی Multilingual Neural Machine Translation System: Zero-Shot Translation Enabling', 'mn': 'Google-ийн олон хэлний мэдрэлийн машин хөгжүүлэх систем: Zero-Shot хөгжүүлэх боломжтой', 'no': 'Google sin fleirspråk neuralmaskinsomsetjingssystem: Slår på null- skot- omsetjing', 'uz': 'Tarjima- ketlikni yoqish', 'vi': 'Hệ thống dịch ngôn ngữ đa ngôn ngữ thần kinh của Google:', 'bg': 'Многоезичната система за неврален машинен превод на Гугъл: разрешаване на превод с нулев изстрел', 'hr': 'Google-ov Multijezički Neuralni sustav prevoda stroja: omogućavajući prevod nula pucnjava', 'da': 'Googles flersprogede neurale maskinoversættelsessystem: Aktivering af Zero-Shot-oversættelse', 'nl': 'Het meertalige neurale machinevertaalsysteem van Google: Zero-Shot-vertaling mogelijk maken', 'de': 'Googles mehrsprachiges neuronales maschinelles Übersetzungssystem: Zero-Shot-Übersetzung ermöglicht', 'fa': 'سیستم ترجمه ماشین عصبی چندین زبان گوگل: فعال کردن ترجمه صفر', 'ko': '구글의 다국어 신경 기계 번역 시스템: 제로 렌즈 번역 실현', 'sw': "Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation", 'id': "Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation", 'af': 'Google se Multilingual Neurale Masjien Vertaling Stelsel: Aktiveer Nuwe- Shot Vertaling', 'tr': "Google'yň köp dilli näyral maşyny terjime sistemi: Zero-Shot terjime etkinleýär", 'am': 'የጎግል ቋንቋ ቋንቋዎች የኔural machine ትርጉም ሲስተም', 'hy': 'Google-ի բազլեզու նյարդային մեքենայի թարգմանման համակարգը. զրո-կրակի թարգմանման հնարավորությունը', 'sq': 'Sistemi shumëgjuhës i përkthimit të Makinës Neurale të Google: Aktivizimi i përkthimit zero-shot', 'az': "Google'ın çoxlu dil nöral maşın çevirim sistemi: Sıfır-Shot çevirimi fəallaşdırılır", 'bn': 'গুগলের মাল্টিভাষায় নিউরেল মেশিন অনুবাদ সিস্টেম: জিরো- শোট অনুবাদ সক্রিয় করা হচ্ছে', 'ca': 'Sistema de traducció multilingüe de màquines neuronales de Google: Activar traducció zero-shot', 'cs': 'Vícejazyčný neuronový strojový překlad Googlu: umožňuje nulový překlad', 'bs': 'Google-ov Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation', 'et': "Google'i mitmekeelne neuroaalne masintõlke süsteem: nullkatse tõlkimise võimaldamine", 'fi': 'Googlen monikielinen hermojen konekäännösjärjestelmä: Nollashot-käännöksen mahdollistaminen', 'jv': 'Sistem Terjamahan Multilengkang Neral kang Google:', 'sk': 'Googlov večjezični sistem strojnega prevajanja nevronov: omogočanje prevajanja brez posnetkov', 'ha': '@ item Text character set', 'he': 'מערכת תרגום של מכונות נוירויות רבות של גוגל: אפשרת תרגום אפס', 'bo': 'Google ལ་སྐད་རིགས་དབྱིབས་དབང་ཆ་གྱི་མ་ལག་ལུགས་དབང་གི་མ་ལག་(Neural Machine)ཡིན་འདུག：ས Zero-Shot་ཡིན་སྒྱུར'}
{'en': 'We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT’14 benchmarks, a single multilingual model achieves comparable performance for EnglishFrench and surpasses state-of-theart results for EnglishGerman. Similarly, a single multilingual model surpasses state-of-the-art results for FrenchEnglish and GermanEnglish on WMT’14 and WMT’15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.', 'ar': "نقترح حلاً بسيطًا لاستخدام نموذج واحد لترجمة الآلة العصبية (NMT) للترجمة بين لغات متعددة. لا يتطلب حلنا أي تغييرات في بنية النموذج من نظام NMT القياسي ، ولكنه بدلاً من ذلك يقدم رمزًا مصطنعًا في بداية جملة الإدخال لتحديد اللغة الهدف المطلوبة. باستخدام مفردات نصية مشتركة ، يتيح نهجنا أنظمة NMT متعددة اللغات باستخدام نموذج واحد. وفقًا لمعايير WMT'14 ، يحقق نموذج متعدد اللغات أداءً مشابهًا للغة الإنجليزية → الفرنسية ويتفوق على أحدث النتائج للغة الإنجليزية → الألمانية. وبالمثل ، يتفوق نموذج واحد متعدد اللغات على أحدث النتائج للفرنسية ← الإنجليزية والألمانية ← الإنجليزية على معايير WMT'14 و WMT'15 ، على التوالي. في مجموعات الإنتاج ، تسمح النماذج متعددة اللغات لما يصل إلى اثني عشر زوجًا من اللغات بترجمة أفضل للعديد من الأزواج الفردية. يمكن لنماذجنا أيضًا أن تتعلم أداء الجسر الضمني بين أزواج اللغات التي لم يسبق رؤيتها صراحةً أثناء التدريب ، مما يوضح أن نقل التعلم والترجمة الصفرية ممكنان للترجمة العصبية. أخيرًا ، نعرض التحليلات التي تلمح إلى تمثيل Interlingua عالمي في نماذجنا ونعرض أيضًا بعض الأمثلة المثيرة للاهتمام عند مزج اللغات.", 'pt': "Propomos uma solução simples para usar um único modelo de tradução automática neural (NMT) para traduzir entre vários idiomas. Nossa solução não requer alterações na arquitetura do modelo de um sistema NMT padrão, mas introduz um token artificial no início da frase de entrada para especificar o idioma de destino necessário. Usando um vocabulário compartilhado, nossa abordagem permite sistemas NMT multilíngues usando um único modelo. Nos benchmarks WMT'14, um único modelo multilíngue alcança desempenho comparável para inglês→francês e supera resultados de última geração para inglês→alemão. Da mesma forma, um único modelo multilíngue supera os resultados de última geração para francês→inglês e alemão→inglês nos benchmarks WMT'14 e WMT'15, respectivamente. Em corpora de produção, modelos multilíngues de até doze pares de idiomas permitem uma melhor tradução de muitos pares individuais. Nossos modelos também podem aprender a realizar pontes implícitas entre pares de idiomas nunca vistos explicitamente durante o treinamento, mostrando que o aprendizado de transferência e a tradução zero-shot são possíveis para a tradução neural. Por fim, mostramos análises que apontam para uma representação universal da interlíngua em nossos modelos e também mostramos alguns exemplos interessantes de mistura de idiomas.", 'fr': "Nous proposons une solution simple pour utiliser un seul modèle de traduction automatique neuronale (NMT) pour traduire entre plusieurs langues. Notre solution ne nécessite aucune modification de l'architecture du modèle par rapport à un système NMT standard, mais introduit un jeton artificiel au début de la phrase d'entrée pour spécifier la langue cible requise. En utilisant un vocabulaire de mots partagé, notre approche permet d'utiliser des systèmes NMT multilingues à l'aide d'un seul modèle. Sur les bancs d'essai du WMT'14, un seul modèle multilingue atteint des performances comparables pour l'anglais→le français et surpasse les résultats de pointe pour l'anglais→allemand. De même, un modèle multilingue unique surpasse les résultats les plus récents pour le français→anglais et l'allemand→anglais sur les benchmarks WMT'14 et WMT'15, respectivement. Sur les corpus de production, les modèles multilingues comprenant jusqu'à douze paires de langues permettent une meilleure traduction de nombreuses paires individuelles. Nos modèles peuvent également apprendre à effectuer un pontage implicite entre des paires de langues jamais vues explicitement pendant la formation, montrant ainsi que l'apprentissage par transfert et la traduction zero-shot sont possibles pour la traduction neuronale. Enfin, nous montrons des analyses qui suggèrent une représentation interlingua universelle dans nos modèles et montrons également quelques exemples intéressants lors du mélange de langues.", 'es': "Proponemos una solución simple para utilizar un único modelo de traducción automática neuronal (NMT) para traducir entre varios idiomas. Nuestra solución no requiere cambios en la arquitectura del modelo de un sistema NMT estándar, sino que introduce un token artificial al principio de la oración de entrada para especificar el idioma de destino requerido. Mediante el uso de un vocabulario de palabras compartido, nuestro enfoque permite que los sistemas de NMT multilingües utilicen un único modelo. En los puntos de referencia del WMT'14, un solo modelo multilingüe logra un rendimiento comparable para inglés→francés y supera los resultados de vanguardia para inglés→alemán. Del mismo modo, un único modelo multilingüe supera los resultados de última generación para francés→inglés y alemán→inglés en los puntos de referencia WMT'14 y WMT'15, respectivamente. En los corpus de producción, los modelos multilingües de hasta doce pares de idiomas permiten una mejor traducción de muchos pares individuales. Nuestros modelos también pueden aprender a realizar puentes implícitos entre pares de idiomas nunca vistos explícitamente durante el entrenamiento, lo que demuestra que el aprendizaje por transferencia y la traducción cero son posibles para la traducción neuronal. Finalmente, mostramos análisis que apuntan a una representación interlingüística universal en nuestros modelos y también mostramos algunos ejemplos interesantes al mezclar idiomas.", 'ja': "単一の神経機械翻訳（ NMT ）モデルを使用して、複数の言語間で翻訳する簡単な解決策を提案します。 当社のソリューションは、標準的なNMTシステムからのモデルアーキテクチャへの変更を必要とせず、代わりに入力文の先頭に人工トークンを導入して、必要なターゲット言語を指定します。 共有ワードピースボキャブラリーを使用して、当社のアプローチは、単一のモデルを使用して多言語NMTシステムを可能にします。 WMT '14ベンチマークでは、単一の多言語モデルは、英語と→フランス語で同等のパフォーマンスを達成し、英語と→ドイツ語で最先端の結果を上回ります。 同様に、単一の多言語モデルは、それぞれWMT '14およびWMT' 15ベンチマークにおけるフランス語→→英語およびドイツ語英語の最先端の結果を上回っています。 プロダクションコーパスでは、最大12の言語ペアの多言語モデルが、多くの個々のペアのより良い翻訳を可能にします。 私たちのモデルは、トレーニング中に明示的に見たことのない言語ペア間の暗黙の橋渡しを行うことも学ぶことができ、転送学習とゼロショット翻訳がニューラル翻訳で可能であることを示しています。 最後に、私たちのモデルにおける普遍的な言語間表現を示唆する分析を示し、言語を混合する際のいくつかの興味深い例も示します。", 'zh': '吾举简解决方案,用单神经机器翻译(NMT)于多种语言间译之。 吾解决方案不须从格 NMT 统改模体系结构,乃于句首引入一人工标记以定所需。 用共享之词汇表,吾道使多言 NMT 统能用单形。 WMT"14准试中,单多言模英语→法语成其比,过于英语→德语之先进也。 多言过之WMT14与WMT15准法语→英语德语→英语之最新也。 生产语料库上,多至 12 语,更译独语。 吾法可以习未见式言行隐式桥接,明神经译可以迁学零次译也。 最后,我们展示了模形中通用的话,并在混合语言时展示了些有趣的例子。', 'hi': "हम कई भाषाओं के बीच अनुवाद करने के लिए एक एकल तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल का उपयोग करने के लिए एक सरल समाधान का प्रस्ताव करते हैं। हमारे समाधान के लिए एक मानक एनएमटी सिस्टम से मॉडल आर्किटेक्चर में कोई बदलाव की आवश्यकता नहीं है, लेकिन इसके बजाय आवश्यक लक्ष्य भाषा निर्दिष्ट करने के लिए इनपुट वाक्य की शुरुआत में एक कृत्रिम टोकन पेश करता है। एक साझा वर्डपीस शब्दावली का उपयोग करते हुए, हमारा दृष्टिकोण एक एकल मॉडल का उपयोग करके बहुभाषी एनएमटी सिस्टम को सक्षम बनाता है। WMT'14 बेंचमार्क पर, एक एकल बहुभाषी मॉडल अंग्रेजी→फ्रेंच के लिए तुलनीय प्रदर्शन प्राप्त करता है और अंग्रेजी→जर्मन के लिए अत्याधुनिक परिणामों को पार करता है। इसी तरह, एक एकल बहुभाषी मॉडल क्रमशः WMT'14 और WMT'15 बेंचमार्क पर फ्रेंच→एंग्लिश और जर्मन→एंगलिश के लिए अत्याधुनिक परिणामों को पार करता है। उत्पादन निगम पर, बारह भाषा जोड़े तक के बहुभाषी मॉडल कई व्यक्तिगत जोड़े के बेहतर अनुवाद की अनुमति देते हैं। हमारे मॉडल प्रशिक्षण के दौरान कभी भी स्पष्ट रूप से नहीं देखे गए भाषा जोड़े के बीच अंतर्निहित ब्रिजिंग करना भी सीख सकते हैं, यह दिखाते हुए कि तंत्रिका अनुवाद के लिए स्थानांतरण सीखने और शून्य-शॉट अनुवाद संभव है। अंत में, हम उन विश्लेषणों को दिखाते हैं जो हमारे मॉडल में एक सार्वभौमिक इंटरलिंगुआ प्रतिनिधित्व पर संकेत देते हैं और भाषाओं को मिलाते समय कुछ दिलचस्प उदाहरण भी दिखाते हैं।", 'ru': "Мы предлагаем простое решение для использования одной модели нейронного машинного перевода (NMT) для перевода между несколькими языками. Наше решение не требует никаких изменений в архитектуре модели от стандартной системы NMT, а вместо этого вводит искусственный токен в начале входного предложения, чтобы указать необходимый целевой язык. Используя общий словарный запас, наш подход позволяет многоязычным системам NMT использовать одну модель. На эталонах WMT'14 одна многоязычная модель достигает сопоставимых показателей для английского и→ французского языков и превосходит самые современные результаты для английского и→ немецкого языков. Аналогичным образом, одна многоязычная модель превосходит самые современные результаты для французского→английского и немецкого→английского языков по критериям WMT'14 и WMT'15, соответственно. На производственных корпусах многоязычные модели до двенадцати языковых пар позволяют лучше переводить многие отдельные пары. Наши модели также могут научиться выполнять неявное соединение между языковыми парами, которые никогда не были явно видны во время обучения, показывая, что обучение переносу и перевод с нулевым выстрелом возможны для нейронного перевода. Наконец, мы показываем анализы, которые намекают на универсальное представление interlingua в наших моделях, а также показываем некоторые интересные примеры при смешивании языков.", 'ga': "Molaimid réiteach simplí chun múnla aonair Néar-Aistriúcháin Meaisín (NMT) a úsáid chun aistriú idir teangacha iolracha. Ní éilíonn ár réiteach aon athruithe ar ailtireacht na samhla ó chóras caighdeánach NMT ach ina ionad sin tugtar isteach comhartha saorga ag tús na habairte ionchuir chun an sprioctheanga riachtanach a shonrú. Trí stór focal comhroinnte a úsáid, cuireann ár gcur chuige ar chumas córais NMT Ilteangacha a úsáideann múnla amháin. Ar thagarmharcanna WMT’14, baineann samhail ilteangach aonair feidhmíocht inchomparáide amach don Bhéarla → Fraincis agus sáraíonn sé torthaí úrscothacha don Bhéarla → Gearmáinis. Mar an gcéanna, sáraíonn samhail ilteangach amháin na torthaí úrscothacha don Fhraincis → Béarla agus Gearmáinis → Béarla ar thagarmharcanna WMT'14 agus WMT'15, faoi seach. Ar chorpas táirgthe, ceadaíonn samhlacha ilteangacha suas le dhá phéire teanga dhéag aistriúchán níos fearr a dhéanamh ar go leor péirí aonair. Is féidir lenár múnlaí foghlaim freisin conas idirlinne intuigthe a dhéanamh idir péirí teangacha nach bhfacthas riamh roimhe le linn na hoiliúna, rud a thaispeánann gur féidir foghlaim aistrithe agus aistriúchán gan urchar a dhéanamh d’aistriúchán néarach. Ar deireadh, taispeántar anailísí a thugann le tuiscint d’ionadaíocht uilechoiteann idirtheanga inár múnlaí agus léirímid freisin roinnt samplaí suimiúla agus teangacha á meascadh againn.", 'ka': "ჩვენ მხოლოდ გამოყენებთ ერთი ნეიროლური მაქსინის გასაგრძელება (NMT) მოდელს, რამდენიმე ენების შორის გასაგრძელება. ჩვენი პასუხი არ მოჭირდება მოდელური არქტიქტიკურის ცვლილებები სტანდარტული NMT სისტემიდან, მაგრამ შემდეგ შეცვალობა სტანდარტული სისტემის დასაწყისაში მომხმარება, რომ მო ჩვენი პროგრამის გამოყენება მრავალური NMT სისტემის გამოყენება ერთი მოდელზე. WMT-ის 14 ბენქმარიკაში ერთი მრავალენგური მოდელი განაზღვრებულია ანგლისური ფრანგური და გადავიწყება ინგლისური გერმანური წარმოდგენებისთვის. ასე იგივეა, ერთი მრავალენგური მოდელის შესაძლებლობად WMT'14 და WMT'15 ბანქმეპების შესაძლებლობად ფრანგური ანგლისური და გერმანური ანგლისური შესაძლებლობას გადარჩენა. პროდისტურის კოპორაში, მრავალენგური მოდელები 12 ენგური ზოგებისთვის უფრო მეტი განაწყვებას. ჩვენი მოდელები შეიძლება ასევე ვისწავლოთ იმპლიციტური ბრიგტის შესაძლებლობა, რომელიც ენეროლის ზოგების საშუალებაში არასწორად აღმოჩნდა, რომ გასწავლობა და ნულ შტატის საბოლოოდ, ჩვენ ანალიზების გამოჩვენება, რომ უნივერსოლური ინტერლუგური გამოსახულებაში ჩვენი მოდელში გამოჩვენება და ჩვენი მოდელში გამოჩვენება ზოგიერთი ინტერსოფ", 'hu': "Egyszerű megoldást javaslunk egy egyetlen Neural Machine Translation (NMT) modell használatára több nyelv közötti fordításhoz. Megoldásunk nem igényel módosítást a modell architektúrájában egy szabványos NMT rendszerből, hanem egy mesterséges tokent vezet be a beviteli mondat elején a szükséges célnyelv megadására. Megközelítésünk a megosztott szótár segítségével lehetővé teszi a többnyelvű NMT rendszerek egyetlen modell használatát. A WMT'14 referenciaértékei szerint egyetlen többnyelvű modell hasonló teljesítményt ér el az angol francia nyelven, és meghaladja az angol német nyelven elért legkorszerűbb eredményeket. Hasonlóképpen, egyetlen többnyelvű modell felülmúlja a francia angol és a német angol nyelvű legkorszerűbb eredményeket a WMT'14 és WMT'15 referenciaértékeken. A legfeljebb tizenkét nyelvpárból álló többnyelvű modellek a gyártási corporák esetében sok egyéni pár jobb fordítását teszik lehetővé. Modelljeink azt is megtanulhatják, hogy implicit áthidalást végezzenek a képzés során soha nem látott nyelvpárok között, bizonyítva, hogy a transzfer tanulás és a zero-shot fordítás lehetséges az idegi fordításhoz. Végezetül olyan elemzéseket mutatunk be, amelyek modelleinkben univerzális interlingua reprezentációra utalnak, és néhány érdekes példát mutatunk a nyelvek keverésénél.", 'el': "Προτείνουμε μια απλή λύση για τη χρήση ενός ενιαίου μοντέλου Νευρικής Μηχανικής Μετάφρασης (NMT) για τη μετάφραση μεταξύ πολλών γλωσσών. Η λύση μας δεν απαιτεί αλλαγές στην αρχιτεκτονική του μοντέλου από ένα τυποποιημένο σύστημα αλλά εισάγει ένα τεχνητό σήμα στην αρχή της πρότασης εισαγωγής για να καθορίσει την απαιτούμενη γλώσσα-στόχο. Χρησιμοποιώντας ένα κοινό λεξιλόγιο, η προσέγγισή μας επιτρέπει τα πολυγλωσσικά συστήματα χρησιμοποιώντας ένα μόνο μοντέλο. Στα κριτήρια αναφοράς WMT'14, ένα ενιαίο πολύγλωσσο μοντέλο επιτυγχάνει συγκρίσιμες επιδόσεις για τα αγγλικά γαλλικά και ξεπερνά τα σημερινά αποτελέσματα για τα αγγλικά γερμανικά. Ομοίως, ένα ενιαίο πολύγλωσσο μοντέλο ξεπερνά τα αποτελέσματα τελευταίας τεχνολογίας για τα γαλλικά αγγλικά και τα γερμανικά αγγλικά στα κριτήρια αναφοράς WMT'14 και WMT'15 αντίστοιχα. Στα σώματα παραγωγής, τα πολύγλωσσα μοντέλα έως και δώδεκα γλωσσικών ζευγαριών επιτρέπουν την καλύτερη μετάφραση πολλών μεμονωμένων ζευγαριών. Τα μοντέλα μας μπορούν επίσης να μάθουν να εκτελούν έμμεση γεφύρωση μεταξύ γλωσσικών ζευγαριών που δεν έχουν δει ποτέ ρητά κατά τη διάρκεια της εκπαίδευσης, δείχνοντας ότι η εκμάθηση μεταφοράς και η μετάφραση μηδενικού πυροβολισμού είναι δυνατή για τη νευρωνική μετάφραση. Τέλος, παρουσιάζουμε αναλύσεις που υποδηλώνουν μια καθολική αναπαράσταση μεταξύ γλωσσών στα μοντέλα μας και επίσης δείχνουν μερικά ενδιαφέροντα παραδείγματα κατά την ανάμειξη γλωσσών.", 'kk': "Біз бірнеше тілдер арасында аудару үшін бір нейрондық машинаны аудару үлгісін қолдану үшін қарапайым шешімін ұсынамыз. Біздің шешіміміз стандартты NMT жүйесінен үлгі архитектурасының өзгерістерін талап ете алмайды, бірақ олардың орнына керек мақсатты тілді келтіру үшін келтірілген мәліметтің басын Ортақ сөз жолының сөздігін қолдану үшін бірнеше үлгі қолдану үшін бірнеше тілдік NMT жүйелерін қолдануға мүмкіндік береді. WMT 14 бағдарламаларында бір көп тіл үлгісі ағылшын французша үшін салыстырылатын және ағылшын тілінің ағылшын тілінің күйінің нәтижесін өзгертеді. Мұндай секілде бір көп тіл үлгісі WMT'14 және WMT'15 бағдарламаларының ағылшын және неміс ағылшын тілінің күйінің нәтижесін өзгертеді. Өндіру корпорасында көптеген тілдер үлгілері 12 тіл екеуіне көптеген жеке екеуін жақсы аударуға мүмкіндік береді. Өзіміздің үлгілеріміз де тіл екеуінің арасында ешқашан көрілмеген тәжірибесін үйрене алады, олардың оқытуы және нөл түрлендіріміздің аудару мүмкіндігін көрсетеді. Соңында, біз анализ үлгілерімізде әлемдік интерлингвиялық түсініктерді көрсетеді және тілдерді араластырғанда бірнеше қызықты мысалдар көрсетеді.", 'it': "Proponiamo una soluzione semplice per utilizzare un unico modello di traduzione automatica neurale (NMT) per tradurre tra più lingue. La nostra soluzione non richiede modifiche all'architettura del modello da un sistema NMT standard, ma introduce invece un token artificiale all'inizio della frase di input per specificare la lingua di destinazione richiesta. Utilizzando un vocabolario condiviso, il nostro approccio abilita sistemi NMT multilingue utilizzando un unico modello. Per quanto riguarda i parametri di riferimento WMT'14, un unico modello multilingue raggiunge prestazioni comparabili per il francese inglese e supera i risultati più recenti per il tedesco inglese. Analogamente, un unico modello multilingue supera i risultati all'avanguardia per l'inglese francese e l'inglese tedesco rispettivamente sui parametri WMT'14 e WMT'15. Sui corpora di produzione, modelli multilingue fino a dodici coppie linguistiche consentono una migliore traduzione di molte coppie individuali. I nostri modelli possono anche imparare ad eseguire un ponte implicito tra coppie linguistiche mai viste esplicitamente durante la formazione, dimostrando che l'apprendimento di trasferimento e la traduzione zero-shot è possibile per la traduzione neurale. Infine, mostriamo analisi che suggeriscono una rappresentazione interlinguistica universale nei nostri modelli e mostrano anche alcuni esempi interessanti quando si mescolano linguaggi.", 'lt': "We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages.  Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language.  Naudojant bendrą žodžių kūrinio žodyną, mūsų metodas leidžia naudoti daugiakalbes NMT sistemas naudojant vieną model į. Atsižvelgiant į WMT 14 kriterijus, vienas daugiakalbis modelis pasiekia panašių anglų prancūzų rezultatų ir viršija anglų vokiečių teatro rezultatus. Similarly, a single multilingual model surpasses state-of-the-art results for French English and German English on WMT'14 and WMT'15 benchmarks, respectively.  Daugiakalbiai modeliai, sudaryti iš ne daugiau kaip dvylikos kalbų porų, leidžia geriau išversti daugelį atskirų porų. Mūsų modeliai taip pat gali išmokti atlikti netiesioginį tarpusavio ryšį tarp kalbų poros, kurios mokymo metu niekada nebuvo aiškiai matytos, rodydami, kad perdavimo mokymasis ir nulinis vertimas yra įmanomas nerviniam vertimui. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.", 'mk': "We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages.  Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language.  Користејќи споделен зборовен речник, нашиот пристап овозможува мултијазички НМТ системи користејќи еден модел. Во врска со резултатите на ВМТ14, еден мултијазичен модел постигнува споредливи резултати за англискиот француски и ги надминува резултатите на државата на театарот за англискиот германски. Исто така, еден мултијазичен модел ги надминува најдобрите резултати за францускиот англиски и германски англиски на ВМТ'14 и ВМТ'15, односно. На производствениот корпора, мултијазичните модели од до 12 јазички парови овозможуваат подобар превод на многу индивидуални парови. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation.  Конечно, покажуваме анализи кои укажуваат на универзална меѓујазична претстава во нашите модели и исто така покажуваат некои интересни примери кога се мешаат јазиците.", 'ms': "We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages.  Solusi kami tidak memerlukan perubahan pada arkitektur model dari sistem NMT piawai tetapi menggantikan token buatan pada permulaan kalimat input untuk nyatakan bahasa sasaran yang diperlukan. Mengguna kamus pekan kata berkongsi, pendekatan kami membolehkan sistem NMT berbilang menggunakan model tunggal. Pada tanda referensi WMT'14, model berbilang bahasa tunggal mencapai prestasi yang sama untuk bahasa Perancis Inggeris dan melebihi keputusan keadaan teater untuk bahasa Jerman Inggeris. Sama seperti, model berbilang bahasa tunggal melebihi keputusan state-of-the-art untuk bahasa Inggeris Perancis dan bahasa Inggeris Jerman pada tanda referensi WMT'14 dan WMT'15, berdasarkan. Pada korpra produksi, model berbilang bahasa sehingga dua belas pasangan bahasa membolehkan terjemahan lebih baik banyak pasangan individu. Model kita juga boleh belajar untuk melakukan hubungan implicit antara pasangan bahasa tidak pernah dilihat secara eksplicit semasa latihan, menunjukkan bahawa pembelajaran pemindahan dan terjemahan-sifar adalah mungkin untuk terjemahan saraf. Akhirnya, kami menunjukkan analisis yang menunjukkan kepada perwakilan interlingua universal dalam model kami dan juga menunjukkan beberapa contoh menarik apabila mencampur bahasa.", 'ml': "ഒരു നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷ (NMT) മോഡല്\u200d ഉപയോഗിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു എളുപ്പമായ ഒരു പരിഹാരം പ്രായശ്ചിത്തം ചെയ്യുന്ന നമ്മുടെ പരിഹാരം ഒരു സാധാരണ NMT സിസ്റ്റത്തില്\u200d നിന്നും മോഡല്\u200d ആര്\u200dക്ടിക്കറ്റിക്കാര്\u200dക്ക് മാറ്റങ്ങള്\u200d ആവശ്യമുള്ള ലക്ഷ്യം ഭാഷ വ്യക്തമാക്കുവ പങ്കെടുത്ത വാര്\u200dഡ്\u200cപാസ്റ്റ് പദാവലി ഉപയോഗിക്കുന്നു, നമ്മുടെ സമ്പാദ്യം ഒരു മോഡല്\u200d ഉപയോഗിക്കുന്നതിനായി മിടു On the WMT'14 benchmarks, a single multilingual model achieves comparable performance for English French and surpasses state-of-theart results for English German.  അതുപോലെ, ഒരു മുള്\u200dട്ടില്\u200d ഭാഷ മോഡല്\u200d വ്യുഎംടി'14-15 ബെന്\u200dമാര്\u200dക്കുകളില്\u200d ഫ്രെഞ്ച് ഇംഗ്ലീഷും ജര്\u200dമ്മന്\u200d ഇംഗ്ലീഷുകള്\u200dക്കും സ്ഥാനത്തില്\u200d  ഉല്\u200dപാദിപ്പിക്കുന്ന കോര്\u200dപ്പോരിയില്\u200d, പന്ത്രണ്ട് ഭാഷ ഇണകള്\u200dക്ക് മുകളില്\u200d പല ഭാഷ മാതൃകങ്ങള്\u200d അനുവദിക്കുന് പരിശീലനത്തില്\u200d വ്യക്തമായി കണ്ടിട്ടില്ലാത്ത ഭാഷ ജോട്ടുകാര്\u200dക്കിടയില്\u200d പ്രധാനപ്പെടുത്താന്\u200d നമ്മുടെ മോഡലുകളും പഠിക്കാന്\u200d പഠ അവസാനം, നമ്മള്\u200d നമ്മുടെ മോഡലില്\u200d ഒരു പ്രതിനിധിയില്\u200d വിശദീകരണങ്ങള്\u200d കാണിക്കുന്നു. ഭാഷകള്\u200d കലര്\u200dത്തുമ്പോള്\u200d കുറച്ചു രസകരമ", 'mt': "Aħna nipproponu soluzzjoni sempliċi biex jintuża mudell uniku ta’ Traduzzjoni ta’ Magni Newrali (NMT) għat-traduzzjoni bejn diversi lingwi. Is-soluzzjoni tagħna ma teħtieġ l-ebda bidla fl-arkitettura mudell minn sistema NMT standard iżda minflok tintroduċi token artifiċjali fil-bidu tas-sentenza input biex tispeċifika l-lingwa fil-mira meħtieġa. Bl-użu ta’ vokabulari ta’ wordpiece kondiviż, l-approċċ tagħna jippermetti sistemi NMT Multilingwi bl-użu ta’ mudell wieħed. On the WMT'14 benchmarks, a single multilingual model achieves comparable performance for English French and surpasses state-of-theart results for English German.  Bl-istess mod, mudell multilingwi wieħed jaqbeż ir-riżultati l-aktar avvanzati għall-Ingliż Franċiż u l-Ingliż Ġermaniż fuq il-punti ta’ riferiment WMT’14 u WMT’15, rispettivament. Fuq il-korpra tal-produzzjoni, mudelli multilingwi ta’ sa tnax-il pari lingwistiċi jippermettu traduzzjoni aħjar ta’ ħafna pari individwali. Il-mudelli tagħna jistgħu wkoll jitgħallmu jwettqu pont impliċitu bejn il-pari tal-lingwi li qatt ma dehru espliċitament waqt it-taħriġ, li juri li t-tagħlim tat-trasferiment u t-traduzzjoni b’zero shot huwa possibbli għat-traduzzjoni newrali. Fl-a ħħar nett, nuru analiżi li tindika rappreżentanza interlingwistika universali fil-mudelli tagħna u nuru wkoll xi eżempji interessanti meta nħalltu l-lingwi.", 'pl': "Proponujemy proste rozwiązanie do wykorzystania pojedynczego modelu neuronowego tłumaczenia maszynowego (NMT) do tłumaczenia między wieloma językami. Nasze rozwiązanie nie wymaga zmian w architekturze modelu ze standardowego systemu NMT, ale zamiast tego wprowadza sztuczny token na początku zdania wejściowego w celu określenia wymaganego języka docelowego. Korzystając ze wspólnego słownictwa, nasze podejście umożliwia wielojęzyczne systemy NMT wykorzystujące jeden model. W odniesieniu do standardów WMT'14 pojedynczy wielojęzyczny model osiąga porównywalną wydajność dla angielskiego francuskiego i przewyższa aktualne wyniki dla angielskiego niemieckiego. Podobnie pojedynczy model wielojęzyczny przewyższa najnowocześniejsze wyniki dla angielskiego francuskiego i niemieckiego w odniesieniu do standardów WMT'14 i WMT'15. W korpusach produkcyjnych wielojęzyczne modele maksymalnie dwunastu par językowych pozwalają na lepsze tłumaczenie wielu pojedynczych par. Nasze modele mogą również nauczyć się wykonywania ukrytego mostu pomiędzy parami językowymi nigdy nie widzianymi wyraźnie podczas treningu, co pokazuje, że nauka transferowa i tłumaczenie zero-shot jest możliwe dla tłumaczenia neuronowego. Na koniec przedstawiamy analizy, które wskazują na uniwersalną reprezentację międzylingua w naszych modelach, a także pokazują kilka ciekawych przykładów mieszania języków.", 'ta': "நாம் ஒரு சுலபமான தீர்வை பயன்படுத்த ஒரு நெயுரல் இயந்திரம் மொழிமாற்றம் (NMT) மாதிரிமாதிரி மாதிரியை மொழிபெயர்ப் எங்கள் தீர்வு தேவைப்படும் இலக்கு மொழியை குறிப்பிடுவதற்கு பதிலாக நிலையான NMT அமைப்பிலிருந்து மாதிரி உருவாக்குதல் தேவையில்லை. பங்கிடப்பட்ட வார்த்தைத் துண்டு சொற்கோவைப் பயன்படுத்தி, எங்கள் முன்னேற்றம் ஒரு மாதிரி பயன்படுத்தி பல மொழி NMT அமைப WMT '14 பெங்குருக்களில், ஒரு பல மொழி மாதிரி மாதிரி ஆங்கிலத்திற்கு ஒப்பிட்ட செயல்பாட்டை பெருகுகிறது மற்றும் ஆங்கிலத்திற்கு ஆங அதே போன்று, ஒரு பல மொழி மாதிரி விளைவுகள் விருப்பமான ஆங்கிலத்தில் மற்றும் ஜெர்மன் ஆங்கிலத்திற்கான முடிவுகளை மாற்றுகிறது, WMT'14 மற்றும்  On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs.  Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation.  இறுதியில், நாம் ஒரு பொதுவான மொத்த மாதிரியில் ஒரு பொதுவான மொழிக்காவின் பிரதிநிதியில் குறிப்பிடுகிறது மற்றும்", 'ur': "ہم ایک نئورل ماشین ترجمہ (NMT) موڈل کے استعمال کرنے کے لئے ایک ساده حل پیشنهاد کرتے ہیں۔ ہمارے حل کے لئے ایک استاندارڈ NMT سیسٹم سے موڈل معماری کے بدلنے کی ضرورت نہیں ہے لیکن اس کے بدلے ایک قابل ٹوکنے کی ابتداء کے لئے ضرورت کی موجود زبان کی تعریف کرنا چاہتا ہے۔ ایک مشترک کلمات پائیس کا استعمال کرنا، ہمارا طریقہ ایک مدل کے مطابق بہت سی زبان NMT سیسٹم کو امکان دیتا ہے. WMT's 14 benchmarks پر ایک متعدد زبان مدل انگلیسی فرانسوی کے لئے مقایسہ کاربری حاصل کرتا ہے اور انگلیسی جرمن کے لئے استیٹ کے نتیجے سے زیادہ اضافہ کرتا ہے. اسی طرح ایک متعدد زبان کی موڈل فرانسوی انگلیسی اور جرمانی انگلیسی کے نتائج پر WMT'14 اور WMT'15 بینچمارک پر غالب ہوتا ہے۔ پیدائش کورپورا پر، بارہ زبان جوڑوں کے بہترین ترجمہ کرنے کے لئے بہت سی زبان کی موڈل ہیں. ہمارے مدلز بھی سکھائیں گے کہ زبان جوڑوں کے درمیان کبھی کھلی طور پر نہیں دیکھا گیا ہے، یہ دکھائے جاتے ہیں کہ ترنسیٹر کی تعلیم اور صفر شٹ کی ترجمہ نیورال ترجمہ کے لئے ممکن ہے. آخر میں ہم تحقیقات کو دکھاتے ہیں کہ ہمارے مدل میں یونلوسٹی بیٹی زبان کی نمونش میں ہنسی کرتی ہے اور زبانوں کی مخلوقات میں بھی کچھ جالب مثالیں دکھاتے ہیں۔", 'ro': "Propunem o soluție simplă pentru a utiliza un singur model Neural Machine Translation (NMT) pentru a traduce între mai multe limbi. Soluția noastră nu necesită modificări ale arhitecturii modelului dintr-un sistem NMT standard, ci introduce în schimb un token artificial la începutul propoziției de intrare pentru a specifica limba țintă necesară. Folosind un vocabular comun pentru piese de cuvinte, abordarea noastră permite sisteme NMT multilingve utilizând un singur model. În ceea ce privește criteriile WMT'14, un singur model multilingv atinge performanțe comparabile pentru franceza engleză și depășește rezultatele de ultimă oră pentru germana engleză. În mod similar, un singur model multilingv depășește rezultatele de ultimă oră pentru engleza franceză și engleza germană pe criteriile WMT'14 și WMT'15. Pe corpurile de producție, modelele multilingve de până la douăsprezece perechi de limbi permit o traducere mai bună a multor perechi individuale. Modelele noastre pot învăța, de asemenea, să efectueze o punte implicită între perechile de limbi care nu au fost văzute în mod explicit în timpul antrenamentului, arătând că învățarea transferului și traducerea zero-shot este posibilă pentru traducerea neurală. În cele din urmă, prezentăm analize care sugerează o reprezentare interlingvă universală în modelele noastre și, de asemenea, prezentăm câteva exemple interesante atunci când amestecăm limbile.", 'sv': "Vi föreslår en enkel lösning för att använda en enda Neural Machine Translation (NMT) modell för att översätta mellan flera språk. Vår lösning kräver inga ändringar i modellarkitekturen från ett standard NMT-system utan introducerar istället en artificiell token i början av inmatningssatsen för att ange önskat målspråk. Med hjälp av ett gemensamt ordspråk ordförråd möjliggör vårt tillvägagångssätt flerspråkiga NMT-system med en enda modell. På WMT'14-riktmärkena uppnår en enda flerspråkig modell jämförbar prestanda för engelska franska och överträffar de senaste resultaten för engelska tyska. På samma sätt överträffar en enda flerspråkig modell de senaste resultaten för fransk engelska och tysk engelska på WMT'14 respektive WMT'15 riktmärken. På produktionskorpor möjliggör flerspråkiga modeller med upp till tolv språkpar bättre översättning av många enskilda par. Våra modeller kan också lära sig att utföra implicit överbryggning mellan språkpar som aldrig setts explicit under utbildningen, vilket visar att transferinlärning och noll-shot översättning är möjligt för neural översättning. Slutligen visar vi analyser som antyder en universell interlingua representation i våra modeller och visar också några intressanta exempel vid blandning av språk.", 'no': 'Vi foreslår ein enkel løysing for å bruka ein enkel neuralmaskinsomsetjingsmodul (NMT) for å oversette mellom fleire språk. Løysinga vårt krev ingen endringar i modellearkitekturen frå eit standard NMT- systemet, men i staden introduserer ein kunstig teikn på begynnelsen av innsetjingsetninga for å oppgje den nødvendige målspråket. Bruk eit delt ordlisteordliste, kan tilnærminga vårt slå på fleirspråkssystemet NMT med ein enkelt modell. På WMT-14-benchmarken oppnår eit enkelt fleirspråk modell samanlikbar utvikling for engelsk fransk og overstyrer tilstandsforsultat for engelsk tysk. Det er likevel eit enkelt multispråk modell som overstyrer kunstige resultat for fransk engelsk og tysk engelsk på WMT « 14 » og WMT « 15 » benchmarker. På produksjonskorpora kan fleirspråksmodeller av opp til tolv språksparer bruka for bedre omsetjing av mange individuelle par. Modellene våre kan også lære å utføra implisitt bryting mellom språkparar som aldri er sett eksplisisk under opplæring, viser at overføringslæring og omsetjing av nullstart er mulig for neuraloversettelse. I slutt viser vi analyser at det gjer hjelp på eit universelt interlingua-representasjon i våre modeller og også viser nokre interessante eksemplar når språk blander.', 'so': "Waxaynu soo jeedaynaa xal fudud oo aan isticmaalno qaab u fudud qoraal ah tarjumaadda kooral (NMT) si loo turjumo luqado badan. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language.  Isku isticmaalista hadal qayb ah, qaababkayaga ayaa ku habboon kara nidaamka afka badan ee NMT isticmaalka model kaliya. WMT'14 waxyaabaha lagu qoro, qaab keliya oo luuqad kala duduwan ayaa lagu sameeyaa bandhig u eg afka ingiriisiga oo afkiisa ingiriisiga ah, wuxuuna kor u baxaa matooyinka farshaxanka ee afka Ingiriis. Sidoo kale, tusaale oo kaliya oo luuqadaha kala duduwan ayaa u gudbaya dowlad-of-the-art resultiyadooda af Ingiriis iyo Ingiriis ee ugu qoran qoraalka WMT'14 iyo WMT'15. Shirkadaha wax soo saarista noocyada luuqadaha kala duduwan ee ugu sareeya laba iyo toban luuqadood waxay u ogolaan karaan turjumidda labada nooc oo gaar ah. Tusaalooyinkayada sidoo kale waxay baran karaan in la sameeyo iswada-xidhiidhka labada luuqadood oo aan weligood lagu arag si cad xilliga waxbarashada, waxayna tusi karaan in waxbarashada beddelinta iyo tarjumaadda nuurka ah ay u suurtagal tahay turjumidda neurada. Ugu dambaysta, waxaynu muujinaynaa baaritaanka, taasoo ku hindisaya qaabilaada luuqadaha caalamiga ah, waxaana sidoo kale tusaalooyin kale oo xiiseynaya marka luuqadaha isku xiriira.", 'mn': "Бид нэг мэдрэлийн машин хөгжүүлэх (NMT) загварыг олон хэл хоорондоо орлуулахын тулд энгийн шийдвэр гаргаж байна. Бидний шийдэл нь стандарт NMT системээс загварын архитектурын өөрчлөлт хэрэггүй, гэхдээ үүний оронд шаардлагатай загварын хэл тодорхойлж өгсөн өгүүллийн эхлээд уран бүтээлч тэмдэг бий болгодог. Олон хэлний үгийг ашиглан бидний арга нь олон хэлний NMT системийг ганц загвар ашиглаж чадна. WMT-ийн 14 салбарт нэг олон хэл загвар Англи хэлний французтай харьцуулагдах үйл ажиллагааг гаргаж, Англи хэлний Германы хувьд орших үйл ажиллагааны үр дүнг дутагдаж байна. Мөн нэг олон хэл загвар нь WMT'14 болон WMT'15-ын үзүүлэлт дээр Француз, Германы Англи хэлний улс төрлийн урлагийн үр дүнг илүү өндөртэй. Өдөр бүтээлтийн корпора дээр олон хэл загвар нь 12 хэл хоёр хүртэл олон төрлийн хоёрыг илүү сайн орчуулах боломжтой. Бидний загварууд мөн хэл хоёр хоёр хоорондоо хэзээ ч сургалтын үед тодорхой харагдаагүй, сургалтын шилжүүлэлт болон шууд шилжүүлэлт нь сэтгэл хөрөнгө оруулах боломжтой байдаг. Эцэст нь бид өөрсдийн загварын ертөнцийн интервал хэлний илэрхийлэл дээр шинжилгээ үзүүлдэг. Мөн хэлний цуглуулах үед зарим сонирхолтой жишээг үзүүлдэг.", 'si': "අපි සාමාන්\u200dය විවේදනයක් ප්\u200dරයෝජනය කරනවා වගේම භාෂාවක් අතර භාෂාවක් අතර පරිවර්තනය කරන්න. අපේ විසරණය අවශ්\u200dය නැහැ NMT පද්ධතියෙන් මොඩේල් විස්තාරයකට වෙනස් කරන්න ඕනේ නැහැ නමුත් ඒ වගේම අවශ්\u200dය ලක්ෂණ භාෂය ස්ථ භාවිත වචනයක් භාවිත කරන්න, අපේ විදියට බොහොම භාෂාවක් NMT පද්ධතියක් ප්\u200dරයෝජනය කරන්න පුළුවන්. WMT' 14 බෙන්ච්මාර්ක් වලින්, එකම භාෂාවක් මොඩල් එකක් ඉංග්\u200dරීසි ෆ්\u200dරෑන්ස් වලින් සම්පූර්ණය වෙනුවෙන් සම්පූර් ඒ වගේම, විශේෂ භාෂාවක් මොඩල් විශේෂයෙන් ප්\u200dරේන්සි ඉංග්\u200dරීෂි සහ ජර්මන් ඉංග්\u200dරීෂි වල ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප නිර්මාණ කර්පෝරා වලින් භාෂාවක් මොඩල් වලින් භාෂාවක් දෙන්නකට වඩා හොඳ වාර්තාවෙන්න පුළුව අපේ මෝඩල් වලින් ඉගෙන ගන්න පුළුවන් භාෂා ජෝඩු වලින් කවදාවත් ප්\u200dරශ්නයක් දැක්කේ නැහැ කියලා, ප්\u200dරශ්නයක් වෙලා අන්තිමේදී, අපි විශ්ලේෂණය පෙන්වන්නේ අපේ මොඩේල් එකේ සාමාන්\u200dය භාෂාවක් පෙන්වන්න පුළුවන් කියලා භාෂාවක", 'sr': "Predlažemo jednostavno rješenje za korištenje jednog model a neuronskog prevoda (NMT) za prevod između višestrukih jezika. Naše rešenje ne zahteva promjene modelne arhitekture iz standardnog NMT sistema, ali umjesto toga predstavlja umjetnu znak na početku ulazne rečenice da specifikuje potrebni ciljni jezik. Koristeći podijeljeni rečnik riječi, naš pristup omogućava višejezičke NMT sisteme koristeći jednog model a. Na standardima WMT'14, jedan multijezički model postiže usporedbenu izvedbu za engleski francuski i prelazi rezultate države umetnosti za engleski njemački. Isto tako, jedan multijezički model prelazi rezultate umetnosti za francuski engleski i njemački engleski na standardima WMT'14 i WMT'15. Na proizvodnju korporacije, multijezički modeli do 12 jezičkih parova omogućavaju bolji prevod mnogih pojedinačnih parova. Naši modeli takođe mogu naučiti da izvršavaju implicitne moste između jezičkih parova koje nikada nisu videle jasno tokom treninga, pokazujući da je moguće da je prevođenje prijenosa i prevođenje nule snimke moguće za neuralno prevođenje. Na kraju, pokazujemo analize koje ukazuju na univerzalnu interlingujsku predstavu u našim modelima i pokazuju neke zanimljive primjere kada miješamo jezike.", 'uz': "Biz bir necha tillar orasidan bir necha tilda tarjima qilish (NMT) modelini ishlatish uchun oddiy muammola qilamiz. Бизнинг ҳаётларимиз стандарт NMT системадан модел архивга ўзгартириш лозим эмас, аммо талаб қилинган ҳозир тилни аниқлаш учун киритиш орқасидаги ҳукумат аломатини кўрсатади. Boʻlishilgan soʻzlar soʻzni ishlatishda, bizning usuli bitta model yordamida multili NMT tizimlarini yordam beradi. WMT 14 parametrlarda, bir necha tilda bir xil model ingliz tilida bir xil tilni bajaradi va ingliz tilida bir xil tilda bir xil muzmat natijalarini bajaradi va ingliz tili tili uchun shaxsiy rasm natijalarini o'zgartiradi. Shunday qilib, bir necha tildagi model WMT'14 va WMT'15 parametrlarda Fransuzcha va Inglizcha tili natijasi holatiga o'zgartiradi. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs.  Bizning modellarimiz o'rganadi va o'rganish vaqtida o'rganilmagan tillar qo'llari orasidagi muvaffaqiyatlarni o'rganish mumkin. va o'rganishni o'rganishni va nuqta sifatida tarjima qilishni nazar tarjima qilishi mumkin. Oxirgi, biz o'ylaymiz, bizning modellarimizdagi universal interlingua representarida qiziqarli misollarni ko'rsamiz va bir necha qiziqarli misollarni birlashtirish mumkin.", 'vi': "Chúng tôi đề xuất một giải pháp đơn giản để sử dụng một mô hình Dịch Thần kinh (NMB) để dịch giữa nhiều ngôn ngữ. Giải pháp của chúng ta không cần thay đổi cấu trúc mô hình từ một hệ thống NMT tiêu chuẩn, mà thay vào đó là biểu tượng nhân tạo ở đầu câu để xác định ngôn ngữ đích cần thiết. Sử dụng từ văn bản có chung, cách tiếp cận của chúng tôi cho phép hệ thống NMT đa ngôn dùng một cách duy nhất. Dựa trên tiêu chuẩn WRT'14, một mô-típ đa dạng đã đạt được hiệu quả tương đương với người Anh Pháp và vượt qua kết quả công nghệ của Đức. Một một một một một một cách đã vượt qua những kết qua những kết quát luật quốc của Anh và Đức tiếng thống với những hành vĩ cao nhất. Trên cơ thể sản xuất, các mẫu đa dạng của lên tới mười hai cặp ngôn ngữ cho phép dịch tốt hơn nhiều cặp đôi cá nhân. Các mô hình của chúng tôi cũng có thể học cách kết nối ngầm giữa các cặp ngôn ngữ chưa bao giờ được thấy rõ ràng trong khi huấn luyện, cho thấy việc học chuyển nhượng và dịch chuyển bằng không có thể dịch chuyển thần kinh. Cuối cùng, chúng tôi đưa ra các phân tích gợi ý sự sắp xếp Liên kết trong các mẫu của chúng tôi và cũng có vài ví dụ thú vị khi trộn ngôn ngữ.", 'hr': "Predlažemo jednostavno rješenje za korištenje jednog model a neuronskog prevoda (NMT) za prevod između višestrukih jezika. Naše rješenje ne zahtijeva promjene model a arhitekture iz standardnog NMT sustava, ali umjesto toga predstavlja umjetni znak na početku ulazne rečenice kako bi se odredila potrebni ciljni jezik. Koristeći dijeljenu riječ za riječ, naš pristup omogućava višejezičke NMT sustave koristeći jednog model a. Na standardima WMT'14, jedan multijezički model postiže usporedno izvršenje za engleski francuski i prelazi rezultate države umjetnosti za njemački engleski. Isto tako, jedan multijezički model prelazi rezultate umjetnosti francuskog engleskog i njemačkog engleskog na standardima WMT'14 i WMT'15. U proizvodnjoj korporaciji, multijezički modeli do 12 jezičkih parova omogućavaju bolji prevod mnogih pojedinačnih parova. Naši modeli mogu također naučiti izvršavati implicitni prekidač između jezičkih parova koji nikada nisu vidjeli jasno tijekom treninga, pokazujući da je moguće prevoditi učenje prijenosa i prevod od nule snimke za neurološki prevod. Napokon, pokazujemo analize koje ukazuju na univerzalnu interlingujsku predstavu u našim modelima i pokazuju neke zanimljive primjere kada miješamo jezike.", 'bg': "Предлагаме просто решение за използване на един модел за неврален машинен превод (НМТ) за превод между няколко езика. Нашето решение не изисква промени в архитектурата на модела от стандартна система, а вместо това въвежда изкуствен символ в началото на входното изречение, за да определи необходимия целев език. Използвайки споделен речник, нашият подход позволява многоезични НМТ системи, използващи един модел. По референтните показатели на WMT'14 един многоезичен модел постига сравними резултати за английския френски и надминава актуалните резултати за английския немски. По подобен начин един многоезичен модел надминава най-съвременните резултати за френския и германския английски по референтните показатели съответно WMT'14 и WMT'15. При производствените корпуси многоезичните модели от до дванадесет езикови двойки позволяват по-добър превод на много отделни двойки. Нашите модели могат също така да се научат да извършват имплицитни мостове между езикови двойки, които никога не са виждани изрично по време на обучение, което показва, че трансферното обучение и нулевият превод са възможни за невронния превод. Накрая, показваме анализи, които подсказват за универсално интерлингуално представяне в нашите модели, а също така показват някои интересни примери при смесване на езици.", 'nl': "Wij stellen een eenvoudige oplossing voor het gebruik van één NMT-model (Neural Machine Translation) voor het vertalen tussen meerdere talen. Onze oplossing vereist geen wijzigingen in de modelarchitectuur van een standaard NMT-systeem, maar introduceert een kunstmatige token aan het begin van de invoerzin om de gewenste doeltaal te specificeren. Met behulp van een gedeelde woordenschat maakt onze aanpak meertalige NMT-systemen mogelijk met behulp van één model. Op de WMT'14 benchmarks bereikt één meertalig model vergelijkbare prestaties voor Engels Frans en overtreft de huidige resultaten voor Engels Duits. Op dezelfde manier overtreft een enkel meertalig model de state-of-the-art resultaten voor Frans Engels en Duits Engels op respectievelijk WMT'14 en WMT'15 benchmarks. Op productiecorpora's maken meertalige modellen van maximaal twaalf taalparen een betere vertaling van vele individuele paren mogelijk. Onze modellen kunnen ook leren impliciete overbruggen tussen taalparen die nooit expliciet tijdens de training zijn gezien, wat aantoont dat transfer learning en zero-shot vertaling mogelijk zijn voor neurale vertaling. Tot slot tonen we analyses die wijzen op een universele interlingua representatie in onze modellen en tonen we ook enkele interessante voorbeelden bij het mengen van talen.", 'da': "Vi foreslår en enkel løsning til at bruge en enkelt Neural Machine Translation (NMT) model til at oversætte mellem flere sprog. Vores løsning kræver ingen ændringer i modelarkitekturen fra et standard NMT-system, men introducerer i stedet et kunstigt token i begyndelsen af inputsætningen for at angive det ønskede målsprog. Ved hjælp af et fælles ordforråd muliggør vores tilgang flersprogede NMT-systemer ved hjælp af en enkelt model. På WMT'14 benchmarks opnår en enkelt flersproget model sammenlignelig præstation for engelsk fransk og overgår de bedste resultater for engelsk tysk. På samme måde overgår en enkelt flersproget model de nyeste resultater for fransk engelsk og tysk engelsk på henholdsvis WMT'14 og WMT'15 benchmarks. På produktionscorpora giver flersprogede modeller på op til tolv sprogpar mulighed for bedre oversættelse af mange individuelle par. Vores modeller kan også lære at udføre implicit broforbindelse mellem sprogpar, der aldrig er set eksplicit under træningen, og vise, at overførsel og zero-shot oversættelse er mulig for neural oversættelse. Endelig viser vi analyser, der antyder en universel interlingua repræsentation i vores modeller, og også viser nogle interessante eksempler ved blanding af sprog.", 'de': "Wir schlagen eine einfache Lösung für die Verwendung eines einzigen neuronalen maschinellen Übersetzungsmodells (NMT) vor, um zwischen mehreren Sprachen zu übersetzen. Unsere Lösung erfordert keine Änderungen an der Modellarchitektur von einem Standard-NMT-System, sondern führt am Anfang des Eingabesatzes ein künstliches Token ein, um die gewünschte Zielsprache zu spezifizieren. Mit einem gemeinsamen Wortschatz ermöglichen wir mehrsprachige NMT-Systeme mit einem einzigen Modell. Auf den WMT'14 Benchmarks erreicht ein einziges mehrsprachiges Modell vergleichbare Leistungen für Englisch Französisch und übertrifft die aktuellen Ergebnisse für Englisch Deutsch. Ebenso übertrifft ein einziges mehrsprachiges Modell die aktuellen Ergebnisse für französisches Englisch und deutsches Englisch auf WMT'14 bzw. WMT'15 Benchmarks. Auf Produktionskorpora ermöglichen mehrsprachige Modelle von bis zu zwölf Sprachpaaren eine bessere Übersetzung vieler einzelner Paare. Unsere Modelle können auch lernen, implizite Brücken zwischen Sprachpaaren durchzuführen, die während des Trainings nie explizit gesehen wurden, was zeigt, dass Transferlernen und Zero-Shot-Übersetzung für neuronale Übersetzungen möglich sind. Abschließend zeigen wir Analysen, die auf eine universelle Interlingua-Repräsentation in unseren Modellen hinweisen und zeigen einige interessante Beispiele für das Mischen von Sprachen.", 'ko': "우리는 단일 신경기계 번역(NMT) 모델을 사용하여 다양한 언어 사이에서 번역하는 간단한 해결 방안을 제시했다.우리의 해결 방안은 표준 NMT 시스템의 모델 구조를 바꾸지 않고 입력 문장의 첫머리에 인공 표시를 도입하여 필요한 목표 언어를 지정할 필요가 있다.공유된 단어 어휘표를 사용하면 하나의 모델을 사용하여 다중 언어 NMT 시스템을 실현할 수 있습니다.WMT'14의 기준 테스트에서 단일한 다국어 모델은 영어-프랑스어 방면에서 상당한 성능을 보였고 영어-독일어의 최신 결과를 초과했다.마찬가지로 WMT'14와 WMT'15의 기준 테스트에서 단일 다국어 모델은 프랑스어 영어와 독일어 영어의 최신 결과를 각각 앞질렀다.생산 어료 라이브러리에서 12개 언어 쌍에 달하는 다중 언어 모델은 많은 단독 언어 쌍을 더욱 잘 번역할 수 있다.우리의 모델은 훈련 과정에서 명확하게 보지 못했던 언어가 사이를 은밀하게 연결하는 것을 배울 수 있다. 이것은 전이 학습과 제로 렌즈 번역이 신경 번역에 가능하다는 것을 나타낸다.마지막으로 우리는 우리의 모델에서 통용되는 언어 간의 표현을 암시하는 분석을 보여 주었고 혼합언어를 할 때 재미있는 예를 보여 주었다.", 'sw': "Tunazipendekeza suluhisho rahisi kutumia muundo mmoja wa Tafsiri ya Mashine ya NMT ili kutafsiri kati ya lugha mbalimbali. ufumbuzi wetu hauhitaji mabadiliko ya ujenzi wa modeli kutoka mfumo wa kiwango cha NMT lakini badala yake inaonyesha alama ya kimaadili mwanzoni ya hukumu ya input ili kuweka lugha inayohitajika. Kwa kutumia mfumo wa lugha nyingine unaotumika kwa kutumia muundo mmoja. Katika bendera ya WMT'14, mwelekeo mmoja wa lugha nyingine hufanikiwa utendaji uliofanana kwa Kiingereza na hupitia matokeo ya sanaa kwa Kiingereza. Vivyo hivyo, muundo mmoja wa lugha nyingine hupitia matokeo ya sanaa kwa lugha ya Kifaransa na Kiingereza kwa asilimia ya WMT'14 na WMT'15. Katika makampuni ya uzalishaji, mifano ya lugha mbalimbali ya wanandoa wa lugha kumi na mbili huruhusu tafsiri bora ya wanandoa binafsi. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation.  Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.", 'fa': 'ما پیشنهاد می\u200cکنیم یک راه حل ساده برای استفاده از یک مدل ترجمه ماشین عصبی (NMT) برای ترجمه بین زبانهای متعدد. راه حل ما نیاز به تغییرات مدل معماری از یک سیستم NMT استاندارد نیست ولی به جای آن یک نشان هنری در آغاز جمله ورودی برای مشخص زبان هدف لازم را معرفی می کند. با استفاده از کلمه\u200cی کلمه\u200cهای مشترک، دستور ما به سیستم\u200cهای NMT Multilingual با استفاده از یک مدل توانایی می\u200cدهد. در ۱۴ برچسب WMT، یک مدل متعدد زبان برای فرانسوی انگلیسی مقایسه قابل انجام می\u200cشود و نتیجه\u200cهای ایالت\u200cهنری برای آلمانی انگلیسی از آن تغییر می\u200cدهد. همچنین، یک مدل متعدد زبان، نتیجه\u200cهای هنری برای انگلیسی فرانسوی و آلمانی در ارتباط WMT ۱۴ و WMT ۱۵ تخمین می\u200cگذرد. در مورد شرکت تولید، مدل های زیادی زبان تا دوازده جفت زبان اجازه می دهد که ترجمه بهتر از جفت های فردی باشد. مدل\u200cهای ما می\u200cتوانند همچنین یاد بگیرند که در طول آموزش هیچ\u200cگاه در جفت زبان مشخص ندیده\u200cاند و نشان دهند که آموزش انتقال و ترجمه\u200cهای صفر برای ترجمه\u200cهای عصبی ممکن است. بالاخره، ما تحلیل\u200cها را نشان می\u200cدهیم که در یک نمایش بین زبان\u200cهای جهانی در مدل\u200cهای ما نشان می\u200cدهد و همچنین چند نمونه جالبی را نشان می\u200cدهیم وقتی زبان\u200cها را ترکیب می\u200cکند.', 'sq': "Ne propozojmë një zgjidhje të thjeshtë për të përdorur një model të vetëm të Translacionit të Makinës Neurale (NMT) për të përkthyer mes gjuhëve të shumta. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language.  Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model.  Në pikat e referimit të WMT'14, një model i vetëm shumëgjuhës arrin performancë të krahasueshme për anglishtin francez dhe tejkalon rezultatet e shtetit të teatrit për anglishtin gjerman. Në mënyrë të ngjashme, një model i vetëm shumëgjuhësor kapërcen rezultatet më të larta për anglishtin francez dhe anglishtin gjerman respektivisht në WMT'14 dhe WMT'15. Në korprën e prodhimit, modelet shumëgjuhësore me deri në dymbëdhjetë çifte gjuhësh lejojnë përkthimin më të mirë të shumë çifteve individuale. Modelet tona mund të mësojnë gjithashtu të kryejnë një lidhje implicite midis çifteve gjuhësh që nuk janë parë kurrë eksplicitisht gjatë trajnimit, duke treguar se transferimi i mësimit dhe përkthimi zero-shot është i mundur për përkthimin nervor. Më në fund, ne tregojmë analiza që tregojnë një përfaqësim universal ndërgjuhësor në modelet tona dhe tregojnë gjithashtu disa shembuj interesante kur përziehen gjuhët.", 'tr': "Biz n채챌e diller arasynda terjime etmek 체챌in 첵ekeje 챌철z체m maslahat ber첵채ris Bizi흫 챌철zg체miz standart NMT sisteminden model arhitektura 체첵tgewler gerek d채l, 첵철ne girdi s철zlerini흫 ba힊ynda gerek maksady dilini takyklamak 체챌in bir surat t채blisa tap첵ar. Pa첵la힊an s철z s철zlerini ullan첵arys, bizi흫 첵ary힊ymyz k철p dilli NMT sistemlerini 첵eke bir nusga ulanarak m체mkin ed첵채r. WMT 14 d체z체mlerinde bir k철p dil nusgasynda i흫lis챌e fransuz챌a 체챌in kar힊캇la힊yp biljek t채sirini 첵etip bil첵채r we i흫lis챌e Alman챌a 체챌in ta첵첵arlar. Munu흫 첵aly birn채챌e dilli nusga WMT'14 we WMT'15 netijesinde Fransuz we Alman챌a i흫lis챌e 체stine gelen 첵agda첵lary 체st체nde ge챌첵채r. 횥첵tgetmek korporasynda, 12-nji dil nusgalarynda birn채챌e 챌iftleri흫 has gowy terjime etm채ge rugsat ber첵채r. Bizi흫 modellerimiz hem dil 챌iftleri arasynda hi챌 ha챌an g철r체lme첵채n 채hli 첵erle힊meleri 철wrenip biler. 횜wrenmegi we sy첵al terjime etmegimiz neural terjime 체챌in m체mkin d채ldir. So흫unda, 챌yky힊larymyzda uniwersal interlingua 철rneklerini 철rneklerimizde k철mekle첵채n 챌yky힊laryny we dillerimizi kar캇힊t캇rdykda hem birn채챌e gyzykly mysal g철rkez첵채ris.", 'af': "Ons voorstel 'n eenvoudige oplossing om 'n enkele neurale masjien vertaling (NMT) model te gebruik om tussen veelvuldige tale te vertaling. Ons oplossing benodig geen veranderinge na die model arkitektuur van 'n standaard NMT stelsel nie, maar in plaas introduseer 'n kunstenaar teken op die begin van die invoer seting om die benodige doel taal te spesifiseer. By gebruik van 'n gedeelde woordbalk woordeboek, kan ons toegang Multilingual NMT stelsels gebruik met 'n enkele model. Op die WMT' 14 benchmarke word 'n enkele multitaalse model vergelykbaar prestasie vir Engels Frans en verbygaan die status-van-theartresultate vir Engels Duits. Soos gelyk is 'n enkele multitaalse model oorvloedig die state- of- the- art resultate vir Frans Engels en Duitse Engels op WMT' 14 en WMT' 15 benchmarke. Op produksiekorpora laat multitaalse modele van tot twaalf taal paar toe vir beter vertaling van baie individuele paar. Ons modelles kan ook leer om inplisite bruiding te doen tussen taal paars nooit uitgelyk gesien nie tydens onderwerp, wys dat oordrag leer en nul- skoot vertaling moontlik is vir neurale vertaling. Ons wys eindelik analiseerdes wat hint by 'n universele interlingua voorstelling in ons modele en ook 'n paar interessante voorbeelde wys wanneer taal gemeenskap word.", 'am': "በሁለት ቋንቋዎች መካከል ትርጉም ዘንድ አንዲት ነዌራዊ መኪን ትርጉም (NMT) ሞዴል ለመጠቀም ቀላል ማቀናጃ እናስጀጋለን፡፡ መፍትወታችን የሞዴል መሠረት ማድረግ አይፈልግም፤ ነገር ግን የሚያስፈልገውን የአካባቢ ቋንቋ ለመግለጥ በጥቅምት መጀመሪያ የምስል ምልክት ማግኘት ነው፡፡ Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model.  በWMT-14 benchmarks ላይ አንዲት ብልቋንቋ ምሳሌ በንግግሊዝኛ ፈረንሳይ እንዲመስል እና ለኢንግሊዝኛ ጀርመን የሀገር-የ-ቴርሲ ውጤቶች ትልቅ ነው፡፡ እንዲሁም አንድ ብዙልቋንቋ ሞዴል በWMT'14 እና WMT'15 benchmark ላይ ለፈረንሳይ እንግሊዘኛ እና የጀርመን እንግሊዘኛ ፍሬዎችን በሀገር-የ-አርእስት ላይ ይሻላል፡፡ On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs.  ሞዴላዎቻችን ደግሞ በቋንቋዎች ሁኔታዎች መካከል ግልፅ ያላዩትን ግልፅ ማድረግ ይችላሉ፡፡ ትምህርትን ለመለስ እና በዝግጅት ትርጓሜን ለመለወጥ ይችላል፡፡ በመጨረሻውም በአቀናዊ የቋንቋ ቋንቋዎች በዓይነታችን የቋንቋዎች መልዕክት ላይ የሚያስታውቀውን አስተያየት እናሳየዋለን እና እና አንዳንዶችን የሚጠያየቅ ምሳሌዎች እናሳየዋለን፡፡", 'hy': "Մենք առաջարկում ենք պարզ լուծում օգտագործելու մեկ նյարդային մեքենայի թարգմանման (NMT) մոդել բազմաթիվ լեզուների միջև թարգմանելու համար: Մեր լուծումն անհրաժեշտ է ոչ մի փոփոխություն կառուցվածքի մոդելի համար ստանդարտ NMT համակարգում, այլ փոխարենը ներկայացնում է արհեստական նշան ներկայացնելու նախադասության սկզբին, որպեսզի նշենք պահանջված նպատակային լեզուն Օգտագործելով ընդհանուր բառերի բառարան, մեր մոտեցումը հնարավորություն է տալիս բազլեզու NMT համակարգերին մեկ մոդել օգտագործելով: ՈւՄԹ-14 հարաբերականների վրա մեկ բազլեզու մոդել հասնում է անգլերենի ֆրանսերենի համեմատական արտադրողություններին և գերազանցում է անգլերենի թատրոնային արդյունքները: Նմանապես, մեկ բազլեզու մոդել հակառակ է ֆրանսերենի անգլերենի և գերմանացի անգլերենի ամենաբարձր արդյունքները, համապատասխանաբար, ՎՄԹ'14-ի և ՎՄԹ'15-ի հարաբերականների վրա: On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs.  Մեր մոդելները կարող են նաև սովորել կապել լեզվի զույգերի միջև, որոնք երբեք արտահայտ չեն տեսել ուսումնասիրության ընթացքում, ցույց տալով, որ փոխանցման ուսումնասիրությունը և զրոյի թարգմանումը հնարավոր են նյարդային թարգ Վերջապես, մենք ցույց ենք տալիս վերլուծություններ, որոնք ցույց են տալիս մեր մոդելների միջլեզվի համաշխարհային ներկայացումը, ինչպես նաև որոշ հետաքրքիր օրինակներ լեզուների խառնման ժամանակ:", 'bn': "আমরা একটি সাধারণ সমাধান প্রস্তাব করছি একটি নেউরাল মেশিন অনুবাদ (এনএমটি) মডেল ব্যবহার করার জন্য যাতে বেশ কয়েকটি ভাষার মধ্যে  Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language.  একটি শেয়ার করা শব্দপাত্রের শব্দভাণ্ডার ব্যবহার করে, আমাদের প্রতিযোগিতা একটি মডেল ব্যবহার করে মাল্টিভাষায় NMT সিস্ট উইএমটি'১৪ বেনমার্কে একটি মাল্টিভাল ভাষার মডেল ইংরেজি ফরাসীর সমতুল্য প্রদর্শন এবং ইংরেজি জার্মানের জন্য রাষ্ট্র-অফ-থিয়ার্ট একই সাথে একটি মাল্টিভাল ভাষার মডেল উইএমটি'১৪ এবং উইএমটি'১৫ বেনমার্কে ফরাসী ইংরেজি ও জার্মান ইংরেজীর জন্য রাষ্ট্র-অফ-শিল্পের উৎপাদন কোর্পোরায় অনেক ব্যক্তিগত জোড়া অনুবাদের জন্য মাল্টিভাষার মডেল প্রদান করা হয়েছে। আমাদের মডেল শিখতে পারে যে ভাষার জোড়ার মধ্যে স্পষ্ট প্রশিক্ষণের সময় ভাষার জোড়া জোড়ার মধ্যে ব্যাপারটি প্রকাশিত ব্রিজিং করতে পারে, যেখ অবশেষে, আমরা বিশ্লেষণ দেখাচ্ছি যে বিশ্লেষণ আমাদের মডেলে একটি বিশ্বব্যাপী ইন্টার্লিঙ্গুয়ার প্রতিনিধিত্বের বিষয়টি দে", 'az': "Biz çoxlu dillər arasında tercümə etmək üçün bir nöral maşına çevirilən modeli istifadə etmək üçün basit bir çətinlik təklif edirik. Bizim çətinliklərimiz standart NMT sistemindən model arhitektura dəyişiklik istəməz, amma bunun yerinə, lazım olan məqsəd dilini belirtmək üçün girdi cümləsinin başlangıcında bir sanatlı token təşkil edir. Bölüşülmüş sözlər sözlərini istifadə edərək, bizim tərzimiz çoxlu dil NMT sistemlərini tək modeli ilə istifadə edər. WMT'nin 14 benchmarklərində, bir çoxlu dil modeli İngilizce Fransızca üçün qarşılaşdırılabilir və İngilizce Almanca üçün müəyyən müddəti sonuçlarını a şar. Beləcə, bir çox dil modeli WMT'14 və WMT'15 benchmarkləri üzərində Fransız İngilizce və Almanca İngilizce üçün istifadə edilən məsələlərdən üstün gəlir. Üstəlik korporasında, 12 dil çiftlərinin çoxlu modelləri birçoxlu kişinin daha xeyirli çevirisini daha yaxşılaşdırmağa imkan verirlər. Bizim modellərimiz həmçinin dil çiftləri arasında heç vaxt açıq-aydın görünmədiyini öyrənə bilər, təhsil öyrənməsini və sıfır-shot tercüməsini nöral tercümə üçün mümkün olduğunu göstərə bilər. Sonunda, modellərimizdə universel interlingua göstərilməsini göstərir və dilləri karıştırırken də bazı ilginç nümunələri göstəririk.", 'id': "Kami mengusulkan solusi sederhana untuk menggunakan model Translation Neural Machine (NMT) untuk menerjemahkan antara berbagai bahasa. Solusi kami tidak memerlukan perubahan pada arsitektur model dari sistem NMT standar tetapi sebagai gantinya memperkenalkan token buatan pada awal kalimat masukan untuk menentukan bahasa sasaran yang diperlukan. Menggunakan vocabulari wordpiece berbagi, pendekatan kita memungkinkan sistem NMT berbilang menggunakan model tunggal. Pada benchmark WMT'14, satu model berbagai bahasa satu mencapai prestasi yang bisa dibandingkan untuk bahasa Perancis Inggris dan melebihi hasil negara-negara teater untuk bahasa Jerman Inggris. Demikian juga, satu model berbagai bahasa melebihi hasil terbaik untuk bahasa Inggris Perancis dan bahasa Inggris Jerman pada tanda referensi WMT'14 dan WMT'15, sesuai. Pada produksi corpora, model berbagai bahasa sehingga 12 pasangan bahasa memungkinkan untuk terjemahan lebih baik dari banyak pasangan individu. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation.  Akhirnya, kami menunjukkan analisis yang menunjukkan pada representation interbahasa universal dalam model kami dan juga menunjukkan beberapa contoh menarik ketika mencampur bahasa.", 'ca': "Proposem una solució senzilla per utilitzar un únic model de traducció neural de màquines (NMT) per traduir entre múltiples llengües. La nostra solució no requereix canvis en l'arquitectura model d'un sistema NMT estàndard però introdueix una fitxa artificial al principi de la frase d'entrada per especificar el llenguatge d'objectiu requerit. Utilitzant un vocabulari compartit, el nostre enfocament permet que els sistemes multilingües de MTN utilitzen un únic model. On the WMT'14 benchmarks, a single multilingual model achieves comparable performance for English French and surpasses state-of-theart results for English German.  De la mateixa manera, un únic model multilingüe supera els resultats més avançats per anglès francès i alemany en els punts de referència WMT'14 i WMT'15, respectivament. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs.  Els nostres models també poden aprendre a fer un pont implícit entre parelles de llenguatges que mai s'ha vist explícitament durant l'entrenament, mostrant que l'aprenentatge de transfer ència i la traducció de zero fotos és possible per a la traducció neuronal. Finalment, mostrem anàlisis que indican una representació universal entre idiomes en els nostres models i també mostren alguns exemples interessants al barrejar llengües.", 'bs': "Predlažemo jednostavno rješenje za korištenje jednog model a neuronskog prevoda (NMT) za prevod između višestrukih jezika. Naše rješenje ne zahtijeva nikakve promjene model a arhitekture iz standardnog NMT-ovog sistema, ali umjesto toga predstavlja umjetnu znak na početku ulazne rečenice za specifikaciju potrebnog ciljnog jezika. Koristeći zajednički rečnik riječi, naš pristup omogućava višejezičke NMT sisteme koristeći jednog model a. Na standardima WMT'14, jedan multijezički model postiže usporedbenu izvedbu za engleski francuski i prelazi rezultate države umetnosti za njemački engleski. Isto tako, jedan multijezički model prelazi rezultate umjetnosti za francuski engleski i njemački engleski na standardima WMT'14 i WMT'15. Na proizvodnju korporacije, multijezički modeli do 12 jezičkih parova omogućavaju bolji prevod mnogih pojedinačnih parova. Naši modeli također mogu naučiti da izvršavaju implicitne moste između jezičkih parova koje nikada nisu vidjele jasno tijekom treninga, pokazujući da je moguće prevoditi učenje prema transferu i prevoditi nulu snimku za neurološki prevod. Napokon, pokazujemo analize koje ukazuju na univerzalnu interlingujsku predstavu u našim modelima i pokazuju neke zanimljive primjere kada miješamo jezike.", 'cs': "Navrhujeme jednoduché řešení pro použití jediného neuronového strojového překladu (NMT) modelu pro překlad mezi více jazyky. Naše řešení nevyžaduje žádné změny modelové architektury ze standardního NMT systému, ale místo toho zavádí umělý token na začátku vstupní věty pro specifikaci požadovaného cílového jazyka. Pomocí sdílené slovní zásoby slovníků umožňuje náš přístup vícejazyčné NMT systémy pomocí jediného modelu. Na referenčních hodnotách WMT'14 dosahuje jediný vícejazyčný model srovnatelného výkonu pro anglickou francouzštinu a překonává aktuální výsledky pro anglickou němčinu. Podobně jediný vícejazyčný model překonává nejmodernější výsledky pro francouzskou angličtinu a německou angličtinu na referenčních hodnotách WMT'14 a WMT'15. Na produkčních korpusech umožňují vícejazyčné modely až dvanácti jazykových párů lepší překlad mnoha jednotlivých párů. Naše modely se také mohou naučit provádět implicitní přemostění jazykových párů nikdy explicitně neviděných během tréninku, což ukazuje, že transferové učení a nulový překlad je možné pro neuronový překlad. Na závěr ukazujeme analýzy, které naznačují univerzální reprezentaci mezilinguů v našich modelech a také několik zajímavých příkladů při míchání jazyků.", 'et': "Pakume välja lihtsa lahenduse, et kasutada ühte neuroaalse masintõlke mudelit mitme keele vahel tõlkimiseks. Meie lahendus ei nõua standardse NMT süsteemi mudeli arhitektuuri muutmist, vaid sisendlause alguses lisatakse kunstlik märk, et määrata vajalik sihtkeel. Kasutades ühist sõnavara, võimaldab meie lähenemine mitmekeelseid NMT süsteeme kasutada ühte mudelit. WMT'14 võrdlusnäitajate puhul saavutab üks mitmekeelne mudel inglise prantsuse keele puhul võrreldavat tulemust ja ületab inglise saksa keele puhul prantsuse keele hetkeolukorra. Samamoodi ületab üks mitmekeelne mudel prantsuse inglise ja saksa inglise keele uusimaid tulemusi vastavalt WMT'14 ja WMT'15 võrdlusnäitajate puhul. Tootmiskorporates võimaldavad mitmekeelsed mudelid kuni kaheteistkümnest keelepaarist paremini tõlkida palju üksikuid paare. Meie mudelid õpivad ka läbi viima kaudset sildu keelepaaride vahel, mida pole kunagi treeningu käigus selgesõnaliselt nähtud, näidates, et siirdeõpe ja nullkatse tõlkimine on võimalik neurotõlkimiseks. Lõpuks näitame analüüse, mis viitavad meie mudelites universaalsele interkeelelisele esitusele ning näitame ka huvitavaid näiteid keelte segamisel.", 'fi': "Ehdotamme yksinkertaista ratkaisua yhden neurokonekäännösmallin (NMT) käyttämiseen useiden kielten välillä. Ratkaisumme ei vaadi muutoksia vakiomallista NMT-järjestelmästä malliarkkitehtuuriin, vaan tuo syöttölauseen alussa keinotekoisen tunnuksen, joka määrittää tarvittavan kohdekielen. Käyttämällä jaettua sanastoa lähestymistapamme mahdollistaa monikieliset NMT-järjestelmät käyttämällä yhtä mallia. WMT'14 -vertailuarvoissa yksi monikielinen malli saavuttaa vertailukelpoisen suorituskyvyn englannin ranskan osalta ja ylittää englannin saksan nykytulokset. Vastaavasti yksi monikielinen malli ylittää uusimmat tulokset ranskankielisen englannin ja saksankielisen englannin osalta WMT'14:n vertailuarvoissa ja WMT'15:n vertailuarvoissa. Tuotantokorpussa monikieliset mallit, joissa on jopa 12 kieliparia, mahdollistavat useiden yksittäisten parien paremman kääntämisen. Mallimme voivat myös oppia tekemään implisiittisiä siltoja kieliparejen välillä, joita ei ole nähty nimenomaisesti harjoittelun aikana, mikä osoittaa, että siirtooppiminen ja nollakäännös ovat mahdollisia neurokäännöksessä. Lopuksi näytämme analyysejä, jotka viittaavat universaaliseen interlingua-edustukseen malleissamme, sekä mielenkiintoisia esimerkkejä kielten sekoittamisesta.", 'jv': "Awak dhéwé nggunakake sistem sing sampeyan kanggo nggambar model Senegal Inggal Nyural (NMT) kang terjamahan ning wisalat saben. Relative Ngawe Perintah NMT kang sampeyan kelas nang dikenakno Nang bench-bench sing WT'14, model sing sampeyan kanggo langgar sampeyan kanggo ngerasahan kanggo Perancis karo mulasah layang-layang kanggo ngerasahan ingles. Sak karo, akeh model sing sampeyan kanggo langgar sampeyan kanggo ngerasah barang kanggo ngerasah Inggris lan alam sing karo WWT'14 lan kalibonan WT'16. Ngawe Perusahaan banget, model sing sampeyan anyar sampeyan sampeyan sampeyan wis rampung pangan banget kanggo tarjamahan sing luwih apik. Model dhéwé iso nggambar nggawe tarjamahan kanggo ngilangno pawar neng pawar neng ijolan winih, iso nggawe tarjamahan karo ingkang nul-ot. Lha wih-wih, kéné iso ngomongke karo cara-cara sing ngerasakno karo universel interlanga sing nyelaraké ning model sing nganggep kuwi, akeh iso ngomongke tindakan Where", 'sk': "Predlagamo enostavno rešitev za uporabo enega samega modela nevralnega strojnega prevajanja (NMT) za prevajanje med več jeziki. Naša rešitev ne zahteva sprememb v arhitekturi modela iz standardnega NMT sistema, ampak namesto tega na začetku vhodnega stavka uvaja umetni žeton za določitev zahtevanega ciljnega jezika. Naš pristop z uporabo skupnega besedišča omogoča večjezične NMT sisteme z uporabo enega modela. Pri referenčnih vrednostih WMT'14 enoten večjezični model dosega primerljivo učinkovitost za angleško francoščino in presega najnovejše rezultate za angleško nemščino. Podobno enoten večjezični model presega najsodobnejše rezultate za francosko angleščino in nemško angleščino glede referenčnih vrednosti WMT'14 oziroma WMT'15. Na produkcijskih korpusih večjezični modeli do dvanajstih jezikovnih parov omogočajo boljši prevod številnih posameznih parov. Naši modeli se lahko naučijo tudi implicitnega premostitve jezikovnih parov, ki jih med treningom nikoli niso videli eksplicitno, kar kaže, da sta transferno učenje in ničelni prevod možni za nevronsko prevajanje. Nazadnje prikazujemo analize, ki namigujejo na univerzalno interjezikovno reprezentacijo v naših modelih in prikazujemo tudi nekaj zanimivih primerov pri mešanju jezikov.", 'ha': "Tuna goyyar da wata suluya mai sauƙi wa'azi da misãlin Tarjima na Ingirin Naural (NMT) don a translate tsakanin harshen masu yawa. Cikakken ayuka ba ta buƙat a musanyi zuwa matsayin ayuka na motsi daga tsarin na'urar NMT na daidaita, kuma amma yana ƙara da wata alama na baka-gaba ta farkon salon da aka shigar da shi dõmin ya ƙayyade harshen wanda ake ƙayyade. Yi amfani da wani zane-zane na share maganar, hanyoyinmu na amfani da tsarin NMT na'ura da wani motel guda. On the WMT'14 bangon, wata misalin multilala guda na sami wani mai kama da fassarar wa Ingiriya faransa kuma yana surge fassarar-state-of-theart for Ingiriya. Kamar hakan, wani misalin multilingular yana surge state-of-the-art matsalar wa faransa Ingiriya da kuma Ingiriya ya zama na WMT'14 da WMT'15 bangons. Daga shirin manunuwan, misãlai masu mulki-lingui na bakin harshen sau biyu biyu zaɓe ko kuma don su yarda da fassarar fassarar mutane masu yawa. @ info: whatsthis Haƙĩƙa, Munã nũna analyi da ke gaya cikin wani mataimaki na cikin lingui da ke cikin misãlai masu amfani da kuma munã nuna wasu misãlai na sha'awa idan sun haɗa zimanmu.", 'he': "אנו מציעים פתרון פשוט להשתמש במודל אחד של תרגום מכונת נוירולית (NMT) כדי לתרגם בין שפות רבות. הפתרון שלנו לא דורש שינויים לארכיטקטורת הדוגמנית ממערכת NMT סטנדרטית, אבל במקום זה מציג סימן מלאכותי בתחילת משפט הכניסה בשימוש במילים משותפים, הגישה שלנו מאפשרת מערכות NMT רבות בשימוש מודל אחד. בנקודות הרווחים של WMT'14, מודל רב-שפתי אחד משיג ביצועים שווים לצרפתית אנגלית, ומעביר את תוצאות המדינה של התיארט לגרמנית אנגלית. באופן דומה, מודל רב-שפתי אחד מעליף תוצאות חדשות לאנגלית צרפתית ואנגלית גרמנית על נקודות רמז WMT'14 ו-WMT'15, בהתאם. על גופורה יצירה, דוגמנים רבים שפותיים של עד 12 זוגות שפות מאפשרים לתרגום טוב יותר של זוגות בודדים רבים. הדוגמנים שלנו יכולים גם ללמוד לבצע גשר מילוי בין זוגות שפות מעולם לא ראויים באופן ברור במהלך האימונים, מראים כי ההעברה ללמוד ותרגום אפס-יריות אפשרית לתרגום עצבי. סוף סוף, אנו מראים ניתוחים שמרמזים על מייצג בין שפות אוניברסלי בדוגמנים שלנו וגם מראים כמה דוגמאות מעניינות כשמערבבים שפות.", 'bo': "ང་ཚོས་སྔོན་ལྟའི་ཐབས་ལམ་སླ་བོ་ཞིག་ལག་ལེན་འཐབ་རྩིས་མེད་ཅིག་གནང་བ་དེ་སྔོན་སྒྲིག་ལ། ང་ཚོའི་ཐབས་ཤེས་ཀྱི་ཐབས་ཤེས་དེ་རྣམ་གྲངས་སྒྲིག་བཟོ་བཀོད་ནང་ལས་བཟོ་བཅོས་དགོས་མེད་པ་ཡིན་ནའང་ཚད་གཞི་NMT་མ་ལག་ཐོག་ནས་བཟོ་རྣམ་ ང་ཚོའི་གཟུགས On the WMT's 14 benchmarks, a single multilingual model achieves comparable performance for English French and surpasses state-of-theart results for English German. Similarly, a single multilingual model surpasses state-of-the-art results for French English and German English on WMT'14 and WMT'15 benchmarks respectively. སྤྱི་ཚོགས་འབྲེལ་མཐུད་དང་། སྐད་རིགས་ཀྱི་མིང་དཔེ་གཞིའི་ནང་གི་རྣམ་པ་གཉིས་ལས་ཀྱང་གཅིག་མཚུངས་ཡིན། ང་ཚོའི་མིག་གཟུགས་རྣམས་ཀྱིས་སྐད་ཡིག་ཆའི་ནང་དུ་ལས་འཕགས་རིས་ཀྱང་མཐོང་མི་ཐུབ་པ་དང་། མཐའ་མར་མ་དེ། འུ་ཅག་གིས་སྤྱི་ཚོགས་སྐད་རིགས་ཅིག་གི་མིག་ཆས་ནང་གི་དཔེ་བརྗོད་རྟགས་ལ་འཆར་བྱེད་ཀྱི་དཔེ་བརྗོད་རྣམས་"}
{'en': 'Unsupervised Learning of Morphological Forests', 'ar': 'التعلم غير الخاضع للإشراف للغابات المورفولوجية', 'es': 'Aprendizaje no supervisado de bosques morfológicos', 'pt': 'Aprendizagem não supervisionada de florestas morfológicas', 'fr': 'Apprentissage non supervisé des forêts morphologiques', 'ja': '形態学的な森の教師なし学習', 'zh': '形林者无监督', 'ru': 'Неконтролируемое изучение морфологических лесов', 'hi': 'रूपात्मक वनों की अप्रशिक्षित शिक्षा', 'ga': 'Foghlaim Foraoisí Moirfeolaíocha gan Maoirseacht', 'ka': 'Morphological Forests', 'el': 'Μη εποπτευόμενη Μάθηση Μορφολογικών Δασών', 'hu': 'A morfológiai erdők felügyeletlen tanulása', 'it': 'Apprendimento non supervisionato delle foreste morfologiche', 'kk': 'Морфологикалық ормандарды оқыту', 'ml': 'നിരീക്ഷിക്കപ്പെടാത്ത കാടുകളുടെ പഠനം', 'mt': 'Tagħlim Mhux Sorveljat tal-Foresti Morfoloġiċi', 'mn': 'Марфологик ой модны суралцах', 'lt': 'Unsupervised Learning of Morphological Forests', 'ms': 'Pembelajaran Hutan Morfologik Tidak Dipengawasi', 'mk': 'Ненадгледувано учење на морфолошките шуми', 'no': 'Ikkje oppretta læring av morfologiske skor', 'pl': 'Nauka lasów morfologicznych bez nadzoru', 'ro': 'Învățarea nesupravegheată a pădurilor morfologice', 'sr': 'Nepotrebno učenje morfoloških šuma', 'so': 'Learning of Morphological Forests', 'ta': 'கண்காணிக்கப்படாத கல்வி', 'si': 'Name', 'sv': 'Oservänt lärande av morfologiska skogar', 'ur': 'Morphological Forests کی غیرقابل تعلیم', 'uz': 'Name', 'vi': 'Không giám sát học về rừng Morphological', 'nl': 'Onbegeleid leren van morfologische bossen', 'bg': 'Неконтролирано изучаване на морфологичните гори', 'hr': 'Nepotrebno učenje morfoloških šuma', 'da': 'Uovervåget læring af morfologiske skove', 'id': 'Pembelajaran Hutan Morfologi Tidak Disupervisi', 'de': 'Unbeaufsichtigtes Lernen morphologischer Wälder', 'ko': '형태삼림의 무감독 학습', 'fa': 'یادگیری غیرقابل تحقیق از جنگل های مورفولوژیک', 'sw': 'Kujifunza Msitu wa Kimorphological', 'tr': 'Marfolojik Otlaryň öwrenmesini goramaýan', 'af': 'Onondersteunde leer van morfologiese woestyn', 'sq': 'Mësimi i Pambikqyrur i Pyjeve Morfologjike', 'am': 'የሞርፎሎጂ ዱሮች መማር', 'hy': 'Մորֆոլոգիական անտառների առանց վերահսկման սովորելը', 'az': 'Morphological Forests 칐yr톛nm톛si', 'bs': 'Neodređeno učenje morfoloških šuma', 'bn': 'মরোফোলজিক্যাল বনের শিক্ষা', 'ca': 'Unsupervised Learning of Morphological Forests', 'et': 'Morfoloogiliste metsade järelevalveta õppimine', 'cs': 'Nehlídané učení morfologických lesů', 'fi': 'Morfologisten metsien valvomaton oppiminen', 'jv': 'Learn Mode', 'sk': 'Nenadzorovano učenje morfoloških gozdov', 'ha': 'Unsupervised Learning of Morphological Forests', 'he': 'ללמוד לא מפקח על יערות מורפולוגיות', 'bo': 'ཕལ་ཆེར་སྡོང་གི་ནགས་ཚལ་གྱི་སྐོར་ཚད་སྣང་མེད་པའི་ཤེས་ཚད་'}
{'en': 'This paper focuses on unsupervised modeling of morphological families, collectively comprising a forest over the language vocabulary. This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest. These global properties constrain the size of the affix set and encourage formation of tight morphological families. The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation. We train the model by alternating between optimizing the local log-linear model and the global ILP objective. We evaluate our system on three tasks : root detection, clustering of morphological families, and segmentation. Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.', 'es': 'Este artículo se centra en el modelado no supervisado de familias morfológicas, que en conjunto comprenden un bosque sobre el vocabulario del idioma. Esta formulación nos permite capturar las propiedades de los bordes que reflejan las derivaciones morfológicas de un solo paso, junto con las propiedades de distribución global de todo el bosque. Estas propiedades globales limitan el tamaño del conjunto de afijos y fomentan la formación de familias morfológicas estrechas. El objetivo resultante se resuelve mediante la programación lineal de enteros (ILP) combinada con la estimación contrastiva. Entrenamos el modelo alternando entre la optimización del modelo log-lineal local y el objetivo global de ILP. Evaluamos nuestro sistema en tres tareas: detección de raíces, agrupación de familias morfológicas y segmentación. Nuestros experimentos demuestran que nuestro modelo produce ganancias consistentes en las tres tareas en comparación con los mejores resultados publicados.', 'pt': 'Este artigo se concentra na modelagem não supervisionada de famílias morfológicas, que compõem coletivamente uma floresta sobre o vocabulário da língua. Essa formulação nos permite capturar propriedades de borda refletindo derivações morfológicas de uma única etapa, juntamente com propriedades de distribuição global de toda a floresta. Essas propriedades globais restringem o tamanho do conjunto de afixos e estimulam a formação de famílias morfológicas compactas. O objetivo resultante é resolvido usando Programação Linear Inteira (ILP) emparelhada com estimação contrastiva. Treinamos o modelo alternando entre a otimização do modelo log-linear local e o objetivo global do ILP. Avaliamos nosso sistema em três tarefas: detecção de raízes, agrupamento de famílias morfológicas e segmentação. Nossos experimentos demonstram que nosso modelo produz ganhos consistentes em todas as três tarefas em comparação com os melhores resultados publicados.', 'ar': 'تركز هذه الورقة على النمذجة غير الخاضعة للرقابة للعائلات المورفولوجية ، والتي تضم مجتمعة غابة فوق مفردات اللغة. تمكننا هذه الصيغة من التقاط خصائص الحافة التي تعكس المشتقات المورفولوجية ذات الخطوة الواحدة ، جنبًا إلى جنب مع الخصائص التوزيعية العالمية للغابة بأكملها. هذه الخصائص العالمية تقيد حجم مجموعة الألقاب وتشجع على تكوين عائلات مورفولوجية ضيقة. يتم حل الهدف الناتج باستخدام البرمجة الخطية الصحيحة (ILP) المقترنة بتقدير تباين. نقوم بتدريب النموذج بالتناوب بين تحسين نموذج السجل الخطي المحلي وهدف ILP العالمي. نقوم بتقييم نظامنا في ثلاث مهام: الكشف عن الجذر ، وتجميع العائلات المورفولوجية ، والتجزئة. توضح تجاربنا أن نموذجنا يحقق مكاسب ثابتة في جميع المهام الثلاث مقارنة بأفضل النتائج المنشورة.', 'fr': "Cet article se concentre sur la modélisation non supervisée de familles morphologiques, formant collectivement une forêt sur le vocabulaire linguistique. Cette formulation nous permet de saisir les propriétés des bords reflétant des dérivations morphologiques en une seule étape, ainsi que les propriétés distributionnelles globales de l'ensemble de la forêt. Ces propriétés globales limitent la taille de l'ensemble d'affixes et favorisent la formation de familles morphologiques étroites. L'objectif obtenu est résolu à l'aide de la programmation linéaire entière (ILP) associée à une estimation contrastive. Nous entraînons le modèle en alternant entre l'optimisation du modèle log-linéaire local et l'objectif global de l'ILP. Nous évaluons notre système en fonction de trois tâches\xa0: la détection des racines, le regroupement des familles morphologiques et la segmentation. Nos expériences démontrent que notre modèle génère des gains constants dans les trois tâches par rapport aux meilleurs résultats publiés.", 'hi': 'यह पेपर रूपात्मक परिवारों के असुरक्षित मॉडलिंग पर केंद्रित है, जिसमें सामूहिक रूप से भाषा शब्दावली पर एक जंगल शामिल है। यह सूत्रीकरण हमें पूरे जंगल के वैश्विक वितरण गुणों के साथ-साथ एकल-चरण रूपात्मक व्युत्पत्ति को प्रतिबिंबित करने वाले किनारे-वार गुणों को पकड़ने में सक्षम बनाता है। ये वैश्विक गुण चिपकाने वाले सेट के आकार को बाधित करते हैं और तंग रूपात्मक परिवारों के गठन को प्रोत्साहित करते हैं। परिणामी उद्देश्य पूर्णांक रैखिक प्रोग्रामिंग (ILP) contrastive अनुमान के साथ युग्मित का उपयोग कर हल किया जाता है। हम स्थानीय लॉग-रैखिक मॉडल और वैश्विक आईएलपी उद्देश्य को अनुकूलित करने के बीच बारी-बारी से मॉडल को प्रशिक्षित करते हैं। हम तीन कार्यों पर हमारे सिस्टम का मूल्यांकन करते हैं: रूट डिटेक्शन, रूपात्मक परिवारों का क्लस्टरिंग, और विभाजन। हमारे प्रयोगों से पता चलता है कि हमारे मॉडल सबसे अच्छे प्रकाशित परिणामों की तुलना में सभी तीन कार्यों में लगातार लाभ प्राप्त करते हैं।', 'ja': 'この論文は、言語語彙の上に森をまとめて構成する、形態学的ファミリーの監督されていないモデリングに焦点を当てている。この配合により、フォレスト全体のグローバル分布特性とともに、単一ステップの形態的導出を反映するエッジワイズ特性を捕捉することができます。これらのグローバル特性は、アフィックスセットのサイズを制限し、緊密な形態学的ファミリーの形成を促進する。得られた目的は、コントラスト推定と対になった整数線形プログラミング（ ＩＬＰ ）を使用して解決される。ローカル対数線形モデルとグローバルILP目標を最適化することで、モデルをトレーニングします。私たちは、ルート検出、形態ファミリーのクラスタリング、セグメンテーションの3つのタスクでシステムを評価します。私たちの実験は、私たちのモデルが、最高の公開結果と比較して、3つのタスクすべてで一貫した利得をもたらすことを示しています。', 'zh': '本文重点言形家无监建模,共构语言词汇表上林。 当公式使得言单步形态学推导缘,及一林之全局布性。 全局属性限了词缀集的大小,并劝成紧密的形族。 用全数线性规画 (ILP) 与比量相合,求解所归。 以优化局对数线性全局 ILP 迭习之。 吾以三事论吾统:根检,形族聚类分。 吾实验之明,与发之最善者,三务一也。', 'ru': 'В настоящем документе основное внимание уделяется неконтролируемому моделированию морфологических семейств, в совокупности составляющих лес над языковым словарным запасом. Эта формулировка позволяет нам фиксировать краевые свойства, отражающие одноступенчатые морфологические производные, наряду с глобальными распределительными свойствами всего леса. Эти глобальные свойства ограничивают размер набора аффикса и стимулируют формирование тесных морфологических семейств. Полученная цель решается с помощью целочисленного линейного программирования (ILP) в паре с контрастной оценкой. Мы обучаем модель, чередуя оптимизацию локальной логарифмической линейной модели и глобальной цели ILP. Мы оцениваем нашу систему по трем задачам: обнаружение корней, кластеризация морфологических семейств и сегментация. Наши эксперименты показывают, что наша модель дает последовательные выгоды по всем трем задачам по сравнению с лучшими опубликованными результатами.', 'ga': 'Díríonn an páipéar seo ar shamhaltú gan mhaoirseacht na dteaghlach moirfeolaíocha, le chéile mar fhoraois thar an stór focal teanga. Cuireann an foirmiú seo ar ár gcumas airíonna imeall-chiallmhara a léiríonn díorthaigh moirfeolaíocha aonchéime a ghabháil, mar aon le hairíonna dáileacháin dhomhanda na foraoise ar fad. Cuireann na hairíonna domhanda seo srian ar mhéid an tsocraithe greamaithe agus spreagann siad bunú teaghlaigh moirfeolaíocha daingean. Réitítear an cuspóir a bhíonn mar thoradh air trí úsáid a bhaint as Ríomhchlárú Líneach Slánuimhir (ILP) in éineacht le meastachán codarsnachta. Cuirimid oiliúint ar an tsamhail trí mhalartach a dhéanamh idir an tsamhail loglíneach áitiúil a bharrfheabhsú agus cuspóir domhanda an ILP. Déanaimid luacháil ar ár gcóras ar thrí thasc: braiteadh fréamhacha, cnuasú teaghlaigh moirfeolaíocha, agus deighilt. Léiríonn ár dturgnaimh go mbíonn gnóthachain chomhsheasmhacha as ár samhail sna trí thasc i gcomparáid leis na torthaí is fearr foilsithe.', 'el': 'Η παρούσα εργασία επικεντρώνεται στην ανεμπόδιστη μοντελοποίηση μορφολογικών οικογενειών, η οποία αποτελείται συλλογικά από ένα δάσος πάνω από το γλωσσικό λεξιλόγιο. Αυτή η διατύπωση μας επιτρέπει να αποτυπώσουμε τις οριακές ιδιότητες που αντικατοπτρίζουν μορφολογικές παράγωγες ενός σταδίου, μαζί με τις παγκόσμιες ιδιότητες κατανομής ολόκληρου του δάσους. Αυτές οι παγκόσμιες ιδιότητες περιορίζουν το μέγεθος του συνόλου προσάρτησης και ενθαρρύνουν το σχηματισμό σφιχτών μορφολογικών οικογενειών. Ο στόχος που προκύπτει επιλύεται χρησιμοποιώντας Ακέραιο Γραμμικό Προγραμματισμό (ILP) σε συνδυασμό με αντιπαθητική εκτίμηση. Εκπαιδεύουμε το μοντέλο εναλλάσσοντας μεταξύ της βελτιστοποίησης του τοπικού λογότυπου-γραμμικού μοντέλου και του παγκόσμιου στόχου ILP. Αξιολογούμε το σύστημά μας σε τρεις εργασίες: ανίχνευση ριζών, ομαδοποίηση μορφολογικών οικογενειών και τμηματοποίηση. Τα πειράματά μας αποδεικνύουν ότι το μοντέλο μας αποδίδει σταθερά κέρδη και στις τρεις εργασίες σε σύγκριση με τα καλύτερα δημοσιευμένα αποτελέσματα.', 'hu': 'A tanulmány a morfológiai családok felügyelet nélküli modellezésére összpontosít, amelyek együttesen egy erdőt alkotnak a nyelvi szókincs felett. Ez a megfogalmazás lehetővé teszi számunkra, hogy az egylépéses morfológiai eredetű tulajdonságokat tükrözzük, valamint az egész erdő globális eloszlási tulajdonságait. Ezek a globális tulajdonságok korlátozzák az affixhalmaz méretét és ösztönzik a szűk morfológiai családok kialakulását. Az eredményt a kontrasztos becsléssel párosított egész lineáris programozás (ILP) segítségével oldjuk meg. A modellt a helyi log-lineáris modell optimalizálásával és a globális ILP célkitűzéssel képezzük. Rendszerünket három feladat alapján értékeljük: gyökérdetektálás, morfológiai családok klaszterezése és szegmentálás. Kísérleteink azt mutatják, hogy modellünk mindhárom feladat során következetes nyereséget eredményez a legjobb publikált eredményekhez képest.', 'ka': 'ეს დოკუმენტი მოპოროლოგიური ოჯახის მოდელირებაზე დააყენებულია, რომელიც კოლექტურად იყენებს ქალი ენის სიტყვებულაზე. ეს ფორმულაცია გვაქვს, რომ ჩვენ დავწეროთ მარტივი განსაზღვრებები, რომლებიც ერთ-ჟრყოფი მოპოროლოგიური განსაზღვრებების განსაზღვრებით, გლობალური განსაზღვრებული განსა ეს დოლობალური განსაზღვრებები განსაზღვრებულია მოფიქსის ზომის და მოწყვებულია ძალიან მორპოლოგიური ოჯახის ფორმაცია. შემდეგი მიზეზი მიზეზი გადაწყვეტილია, როგორც კონტრასტიური განსაზღვრება გამოყენებული Integer Linear Programming (ILP) გამოყენებული. ჩვენ მოდელის შეცვალობით ლოკალური ლოგიური ლოგიური მოდელის და გლობალური ILP მიზეზი. ჩვენ მისი სისტემის სამი დავალების შესახებ გავუმუშავებთ: ფესტური განახლება, მორპოლოგიური ოჯახის კლასტერი და სეგენდაცია. ჩვენი ექსპერიმენტები გამოჩვენება, რომ ჩვენი მოდელის მონაცემები დაიწყება ყველა სამი სამუშაობაში, როგორც უკეთესი პოვუკურებული შედეგი.', 'it': "Questo articolo si concentra sulla modellazione non supervisionata delle famiglie morfologiche, comprendendo collettivamente una foresta sopra il vocabolario linguistico. Questa formulazione ci permette di acquisire proprietà perimetrali che riflettono derivazioni morfologiche a singolo passo, insieme alle proprietà distributive globali dell'intera foresta. Queste proprietà globali limitano la dimensione dell'insieme di affissi e incoraggiano la formazione di famiglie morfologiche strette. L'obiettivo risultante è risolto utilizzando la Programmazione Lineare Integer (ILP) accoppiata con stima contrastante. Formiamo il modello alternando tra l'ottimizzazione del modello log-lineare locale e l'obiettivo ILP globale. Valutiamo il nostro sistema su tre compiti: rilevamento delle radici, raggruppamento delle famiglie morfologiche e segmentazione. I nostri esperimenti dimostrano che il nostro modello produce guadagni costanti in tutte e tre le attività rispetto ai migliori risultati pubblicati.", 'kk': 'Бұл қағаз морфологиялық отбасының моделизациялық моделизациялауына көмектеседі, тіл сөздерінің үстінде орманы құрып тұрады. Бұл формулация бір қадамды морфологиялық түрлерді бірге жалпы орманың үлкен үлестіру қасиеттерін түсіруге мүмкіндік береді. Бұл жалпы қасиеттер көпшіліктің өлшемін шектеп, қатты морфологиялық үйлерін құру үшін көмектеседі. Нәтижесі мақсатты контрастық оқиғалармен біріктірілген бүтін линиялық бағдарлама (ILP) дегенмен шешу. Біз үлгісін жергілікті журналдық үлгісін және журналдық ILP мақсатын оптимизациялау арасындағы аударып үйренеміз. Біз жүйемізді үш тапсырма бойынша бағалаймыз: түбір тапсырмалар, морфологиялық үйлердің кластері және сегментация. Біздің тәжірибеміздің моделіміз үш тапсырмалардың ең жақсы шығарылған нәтижелерімен салыстырып тұратынын көрсетеді.', 'ml': 'ഈ പത്രത്തില്\u200d മോര്\u200dഫോളജിക്കല്\u200d കുടുംബങ്ങളുടെ മാതൃകയെ ശ്രദ്ധിച്ചിരിക്കുന്നു, ഭാഷയുടെ പദവിഭാഷയ്ക്ക് മേല്\u200d ഒരു കാട് ക ഈ ഫോര്\u200dമാലേഷന്\u200d മുഴുവന്\u200d കാട്ടിന്റെയും വിതരണ വിഭവങ്ങളുടെയും പ്രതിഫലങ്ങള്\u200d പിടികൂടാന്\u200d ഞങ്ങള്\u200dക്ക് സാധ്യമല്ല. ആഫിക്സ് സെറ്റിന്റെ വലിപ്പം ഈ ഗ്ലോബല്\u200d ഗുണഗണങ്ങള്\u200d നിര്\u200dബന്ധിക്കുന്നു. മുറുകെപ്പിടിച്ച മോര്\u200dഫോളിക്കല അതിന്റെ ഫലമായ ലക്ഷ്യം മുഴുവന്\u200d ലൈനൈറ്റ് പ്രോഗ്രാമിങ്ങിനെ ഉപയോഗിച്ചു് പരിഹരിക്കുന്നു. ലോക്കല്\u200d ലോഗ് ലൈനര്\u200d മോഡലിനെയും ഗ്ലോബല്\u200d ഐഎല്\u200dപി ലക്ഷ്യത്തെയും ഉപയോഗിക്കുന്നതിനുമിടയില്\u200d മാറ്റം മാറ്റുന്നതി മൂന്നു ജോലികളില്\u200d നമ്മുടെ സിസ്റ്റത്തെ വിലയിക്കുന്നു നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ മോഡല്\u200d മൂന്ന് ജോലികളില്\u200d നിലനില്\u200dക്കുന്ന സമ്പത്തിന', 'mt': 'Dan id-dokument jiffoka fuq mudell mhux sorveljat ta’ familji morfoloġiċi, li kollettivament jinkludi forest a fuq il-vokabulari lingwistiku. Din il-formulazzjoni tippermettilna nqabdu proprjetajiet lejn ix-xifer li jirriflettu derivazzjonijiet morfoloġiċi f’pass wieħed, flimkien mal-proprjetajiet tad-distribuzzjoni globali tal-foresta kollha. Dawn il-karatteristiċi globali jillimitaw id-daqs tas-sett tat-twaħħil u jħeġġu l-formazzjoni ta’ familji morfoloġiċi stretti. L-objettiv li jirriżulta jiġi solvut bl-użu ta’ Programmazzjoni Linjari Integri (ILP) flimkien ma’ stima kontrastanti. Aħna nħarrġu l-mudell billi nalternaw bejn l-ottimizzazzjoni tal-mudell log-lineari lokali u l-objettiv globali tal-ILP. Aħna jevalwaw is-sistema tagħna fuq tliet kompiti: l-iskoperta tal-għeruq, il-raggruppament tal-familji morfoloġiċi, u s-segmentazzjoni. L-esperimenti tagħna juru li l-mudell tagħna jagħti qligħ konsistenti fit-tliet kompiti kollha meta mqabbel mal-aħjar riżultati ppubblikati.', 'mn': 'Энэ цаас нь морфологик гэр бүлийн загвар зохион байгуулалт, хэлний үг дээр ойг бүрдүүлж байдаг. Энэ томъёо нь бидэнд нэг алхам морфологикийн хуваалцааны шинж чанарыг бүх ой дэлхийн хуваалцааны шинж чанартай холбоотой. Эдгээр дэлхийн хувьцааны хэмжээг хязгаарладаг бөгөөд хатуу морфологик гэр бүлийн бүтээлүүдийг дэмжиж байна. Үүний үр дүнтэй зорилго нь бүтэн шугам програмчлалын (ILP) ашиглан эсрэг тооцооллоор холбогдсон юм. Бид загварын загварыг орон нутгийн лог-шугамын загвар болон дэлхийн ILP зорилготой хоорондын өөрчлөлт хийж сургадаг. Бид системийг гурван ажил дээр үнэлдэг: үндсэн ололт, морфологик гэр бүлийн бүлэг, хэсэг. Бидний туршилтууд бидний загвар нь хамгийн сайн нийтлэгдсэн үр дүнтэй харьцуулахад 3 дасгал ажлын үр дүнтэй үр дүнг авдаг гэдгийг харуулдаг.', 'no': 'Denne papiret fokuserer på ulike modellering av morfologiske familier, som samanlig inkluderer eit skog over språkkordlista. Denne formelen gjer oss å ta inn eigenskapar som reflekserar enkelt steg morfologiske derivasjonar, saman med globale distribusjonelle eigenskapar for hele skogen. Desse globale eigenskapane avgrenser storleiken på affiksen sett og oppfordrer formatering av sterke morfologiske familier. Det følgjande målet er løyst med heiltal linjerprogram (ILP) saman med kontrastvurdering. Vi treng modellen ved å endra mellom å optimisera den lokale loglineære modellen og den globale ILP-målet. Vi evaluerer systemet vårt på tre oppgåver: rotoppdaging, klassering av morfologiske familier og segmentering. Eksperimentane våre viser at modellen vårt gjev konsekvent vinn i alle tre oppgåver sammenlignet med dei beste utgjevne resultatene.', 'pl': 'Niniejszy artykuł skupia się na modelowaniu rodzin morfologicznych bez nadzoru, zbiorowo składających się z lasu nad słownictwem językowym. Formuła ta pozwala nam uchwycić właściwości krawędziowe odzwierciedlające jednostopniowe pochodne morfologiczne, wraz z globalnymi właściwościami rozkładu całego lasu. Te globalne właściwości ograniczają wielkość zestawu afiksów i sprzyjają tworzeniu ciasnych rodzin morfologicznych. Wynikowy cel rozwiązany jest za pomocą programowania liniowego całkowitego (ILP) w połączeniu z oszacowaniem kontrastywnym. Szkolimy model na przemian między optymalizacją lokalnego modelu log-liniowego a globalnym celem ILP. Oceniamy nasz system pod kątem trzech zadań: wykrywania korzeni, grupowania rodzin morfologicznych oraz segmentacji. Nasze eksperymenty pokazują, że nasz model przynosi konsekwentne zyski we wszystkich trzech zadaniach w porównaniu z najlepszymi opublikowanymi wynikami.', 'lt': 'Šiame dokumente daugiausia dėmesio skiriama nepastebimam morfologinių šeimų modeliavimui, kurį sudaro miškas virš kalbų žodyno. This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest.  Šios pasaulinės savybės riboja pritvirtinimo rinkinio dydį ir skatina susidaryti tvirtas morfologines šeimas. Atitinkamas tikslas išspręsiamas naudojant visą linijinę programavimą (angl. Integer Linear Programming, ILP) ir kontrastinį vertinimą. Mokome model į keičiant nuo vietos log linijinio modelio optimizavimo iki pasaulinio ILP tikslo. Mūsų sistemą vertiname trimis uždaviniais: šaknių aptikimu, morfologinių šeimų grupavimu ir segmentavimu. Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.', 'mk': 'Оваа вест се фокусира на ненадгледуваното моделирање на морфолошките семејства, кое колективно сочинува шума над јазичниот речник. Оваа формулација ни овозможува да ги заработиме морфолошките дериентации на еден чекор, заедно со глобалните дистрибуционални сопствености на целата шума. Овие глобални сопствености ја ограничуваат големината на поставката и охрабруваат формирање на тесни морфолошки семејства. Резултатната цел е решена користејќи целосно линијарно програмирање (ILP) во пар со контрастивна проценка. Го тренираме моделот со алтернатива помеѓу оптимизацијата на локалниот локален лог-линијарен модел и глобалната цел на ИЛП. Го проценуваме нашиот систем на три задачи: детекција на корени, групирање на морфолошки семејства и сегментација. Нашите експерименти демонстрираат дека нашиот модел дава константни добивки во сите три задачи во споредба со најдобрите објавени резултати.', 'ro': 'Această lucrare se concentrează pe modelarea nesupravegheată a familiilor morfologice, cuprinzând colectiv o pădure peste vocabularul lingvistic. Această formulă ne permite să captăm proprietățile de margine care reflectă derivațiile morfologice într-un singur pas, împreună cu proprietățile distribuționale globale ale întregii păduri. Aceste proprietăți globale restricționează dimensiunea setului de afix și încurajează formarea de familii morfologice strânse. Obiectivul rezultat este rezolvat utilizând Programarea Lineară întreagă (ILP) asociată cu estimare contrastantă. Instruim modelul alternând între optimizarea modelului log-liniar local și obiectivul ILP global. Evaluăm sistemul nostru pe trei sarcini: detectarea rădăcinilor, gruparea familiilor morfologice și segmentarea. Experimentele noastre demonstrează că modelul nostru obține câștiguri constante în toate cele trei sarcini comparativ cu cele mai bune rezultate publicate.', 'ms': 'This paper focuses on unsupervised modeling of morphological families, collectively comprising a forest over the language vocabulary.  Formulasi ini membolehkan kita menangkap ciri-ciri bijak pinggir yang mencerminkan derivasi morfologi langkah tunggal, bersama dengan ciri-ciri distribusi global seluruh hutan. Ciri-ciri global ini mengendalikan saiz set lampiran dan menyokong pembentukan keluarga morfologi ketat. The resulting objective is solved using Integer Linear Programming (ILP) paired with contrastive estimation.  Kami melatih model dengan mengganti antara optimizasi model log-linear setempat dan objektif ILP global. Kami menilai sistem kami pada tiga tugas: pengesan akar, kumpulan keluarga morfologi, dan segmen. Eksperimen kita menunjukkan bahawa model kita memberikan keuntungan konsisten dalam tiga tugas dibandingkan dengan hasil terbaik yang diterbitkan.', 'so': 'Warqaddaas wuxuu ku qoran yahay tusaale aan la ilaalinayn qoysaska qoyska morphologiga ah, kaas oo dhammaan ku qoran kayn ku qoran luqada. Muuqashadan ayaa inagu qabsan kara hantidiisa caqliga leh oo ka fiirsan kara hal qadood oo morphological ah, iyo xuquuqda kala qaybsan ee kaynta oo dhan. Xuquuqdan caalamiga ah waxay leedahay tirada rasmiga la dhigo iyo waxay ku dhiirrigeliyaan dhismaha qoysaska dhaqdhaqaaqa ah. Waqtiga la soo jeedo waxaa lagu xallinayaa isticmaalka qorsheynta caadiga Linear (ILP). Tusaalada waxaynu ku tababarinnaa si aan bedelka u bedelno noocyada qoriga-qoriga ee deegaanka iyo goalka caalamiga ah ee ILP. Sidoo kale waxaynu ku qiimeynaynaa nidaamka oo ku qoran saddex shaqooyin: xidida, dhaqdhaqaaqa qoysaska iyo qeybinta. Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.', 'sr': 'Ovaj papir se fokusira na neodređenu modelizaciju morfoloških porodica, kolektivno uključujući šumu na jezički rečenik. Ova formulacija nam omogućava da uhvatimo svojstva na ivici koji odražavaju morfološke derivacije jednokoraka, zajedno sa globalnim distribucijskim vlasništvom cele šume. Ove globalne vlasništvo ograničavaju veličinu postavljenog afiksa i ohrabruju formaciju čvrste morfološke porodice. Rešava se rezultat cilja koristeći integer Linear Programming (ILP) povezan sa kontrastivnom procjenom. Vježbamo model između optimizacije lokalnog loglinearnog modela i globalnog cilja ILP-a. Procjenjujemo naš sistem na tri zadatka: otkrivanje korijena, skupljanje morfoloških porodica i segmentacije. Naši eksperimenti pokazuju da naš model donosi konsekventne dobitke u svim tri zadatka u usporedbi sa najboljim objavljenim rezultatima.', 'sv': 'Denna uppsats fokuserar på oövervakad modellering av morfologiska familjer, kollektivt bestående av en skog över språkordförrådet. Denna formulering gör det möjligt för oss att fånga kantvisa egenskaper som återspeglar enstaka morfologiska härledningar, tillsammans med globala fördelningsegenskaper för hela skogen. Dessa globala egenskaper begränsar storleken på affisset och uppmuntrar bildandet av snäva morfologiska familjer. Det resulterande målet löses med hjälp av heltalslinjär programmering (ILP) i kombination med kontrastiv uppskattning. Vi tränar modellen genom att växla mellan att optimera den lokala logglinjärmodellen och det globala ILP-målet. Vi utvärderar vårt system utifrån tre uppgifter: rotdetektion, klustring av morfologiska familjer och segmentering. Våra experiment visar att vår modell ger konsekventa vinster i alla tre uppgifterna jämfört med de bästa publicerade resultaten.', 'si': 'මේ පත්තුව ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් නැති ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන්, සම්බන්ධ විශ්ණ මේ සංවේදනය අපිට ප්\u200dරතික්\u200dරියාත්මක විශේෂතාවක් ප්\u200dරතික්\u200dරියා කරන්න පුළුවන් වෙනවා, සමග ජාතික විශේෂ විශේෂ මේ ජාතික විශේෂ විශේෂතාවන් ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සම්බන්ධ විශේෂ පවුලේ සං ප්\u200dරතිචාර අරක්\u200dෂාව ප්\u200dරතිචාරය (ILP) සමඟ ප්\u200dරතිචාර විශේෂය සමඟ සම්බන්ධ විශේෂය සඳහා සම්බන්ධ අපි මොඩල් එක ප්\u200dරධානය කරන්නේ ස්ථානික ලෝග් ලේනියර් මොඩල් එක සහ ජාතික ILP අරමුණ සඳහා වෙනස් කරන්න. අපි අපේ පද්ධතිය විශ්වාස කරන්නේ වැඩ තුනක් විතරයි: මුළු හොයාගන්න, මොර්ෆෝලෝගික පවුලේ සංවේදනය අපේ පරීක්ෂණය පෙන්වන්නේ අපේ මොඩේල් එක්ක සාමාන්\u200dය විදියට හැම වැඩ තුනක්ම ප්\u200dරකාශ කරනවා කියලා.', 'ur': 'یہ کاغذ فورفالوژیکی خاندانوں کی ناپورپورٹی موڈلینگ پر تمرکز کرتا ہے، جو زبان لکھنے پر ایک جنگل ہے۔ یہ فرمول ہمیں صرف ایک قدم مرفولجی ڈرائیٹ کے پھیرنے کے لئے اجازت دیتا ہے، جو تمام جنگل کے گھروں میں تقسیم کرنے والی خصوصیات کے ساتھ ہے۔ یہ گروئیل ویژگی کے سازوں کو محدود کرتی ہیں اور مضبوط مورفولوجی خاندان کے سازوں کو ترغیب دیتے ہیں. نتیجہ کا موضوع کامل لینیر پروگرامینگ (ILP) کے استعمال سے حل ہوا گیا ہے جو مقابلہ مقابلہ کے ساتھ جوڑا ہوا ہے. ہم مدل کو دولت دیتے ہیں لگ لینیر موڈل اور گلوبی ایلپی موضوع کے درمیان بدلنے کے ذریعہ۔ ہم تین کاموں پر اپنے سیستم کا ارزش کررہے ہیں: ریٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈی ہمارے آزمائش دکھاتے ہیں کہ ہماری مدل تین کاموں میں ثابت قدم فائدہ حاصل کرتا ہے جو سب سے بہترین پیدا کئے ہوئے نتائج کے مقابلہ میں ہے.', 'ta': 'இந்த தாள் மொழி சொல்வளத்திற்கு மேல் ஒரு காட்டை சேர்க்கப்படாத மாதிரியில் கவனம் செலுத்துகிறது. This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest.  இந்த பொதுவான பண்புகள் குறிப்பு அமைப்புகளின் அளவை கட்டுப்படுத்தி கட்டுப்படுத்தி கடுமையான குடும்பங்களை உருவா முடிவு பொருள் முழு கோட்டு நிரலில் (ILP) ஜோடியை பயன்படுத்தி தீர்க்கப்படும் முறைமையான மதிப்புடன். உள்ளார்ந்த பதிவு கோடு மாதிரி மற்றும் உலக ILP பொருள் மாதிரியை மாற்றி மாற்றி மாதிரியில் நாம் மாதிரியை பய மூன்று பணிகளில் எங்கள் கணினியை மதிப்பீடு செய்கிறோம்: மூலம் கண்டுபிடிப்பு, குடும்பத்திற்கு தொடர்பு மற்றும் ப எங்கள் சோதனைகள் எங்கள் மாதிரி முறையில் மூன்று பணிகளில் மாதிரியும் வெளிப்படையான முடிவுகளை ஒப்பிடும் மூன்று வ', 'uz': "Бу саҳифа фойдаланмайдиган фойдаланмаган оилалар моделявий фойдаланади, у билан тил тил тил тилида машҳур дарахт мосламаларини жамланади. Bu formulyat bizga bir qadam morfologik qoidalarini ko'rsatishga imkoniyatlar beradi va butun skog'ining dunyo tarqatish xossalari bilan. Ushbu dunyo xossalari affix moslamasining oʻlchamini yaratadi va qiyin morfologik qo'llanmalarni formatlashga amalga oshirish mumkin. Name Biz modelni lokal log-liner modeli va dunyo yo ILP obʼektini aniqlash orqali o'zgarishni o'rganamiz. Biz tizimmizni uchta vazifalar bilan qiymatmiz: root aniqlash, morfologik oilasi qo'llanmalarni birlashtirish va bir qismlash. Bizning imtiyozlarimiz modelimizning hamma uchta vazifalar bilan eng yaxshi berilgan natijalariga davom etiladi.", 'vi': 'Tờ giấy này tập trung vào việc mô hình không giám sát của các gia đình lịch sử, gồm một khu rừng trên các ngôn ngữ. Công thức này cho phép chúng ta thu thập các đặc tính theo chiều cao phản ánh các rãnh lịch của từng bước, cùng với các tính chất phân phối to àn cầu của cả khu rừng. Những tính chất toàn cầu này giới hạn kích thước của bộ gắn kết và thúc thúc thúc đẩy hình thành các gia đình có độ bền. Kết quả được giải quyết bằng lắp ghép tuyến giáp (ILP) kết hợp với giá trị tương phản. Chúng tôi đào tạo mô hình này bằng cách xoay chuyển giữa mô hình nhật tính địa phương và mục tiêu ILP toàn cầu. Chúng tôi đánh giá hệ thống về ba nhiệm vụ: phát hiện rễ cây, kết hợp các gia đình morphical, và phân chia. Những thí nghiệm của chúng tôi cho thấy mô hình của chúng tôi đạt được lợi nhuận liên tục trong ba nhiệm vụ so với kết quả xuất bản tốt nhất.', 'bg': 'Настоящата статия се фокусира върху ненадзорно моделиране на морфологични семейства, съставляващи колективно гора над езиковия речник. Тази формулировка ни позволява да улавяме свойства, отразяващи едностъпални морфологични производни, заедно с глобалните разпределителни свойства на цялата гора. Тези глобални свойства ограничават размера на афикса и насърчават образуването на тесни морфологични семейства. Получената цел е решена с помощта на цялостно линейно програмиране (ИЛП), съчетано с контрастна оценка. Обучаваме модела като редуваме между оптимизиране на локалния логлинеен модел и глобалната цел на ИЛП. Ние оценяваме нашата система на три задачи: откриване на корени, групиране на морфологични семейства и сегментиране. Нашите експерименти показват, че нашият модел дава последователни печалби и при трите задачи в сравнение с най-добрите публикувани резултати.', 'da': 'Dette arbejde fokuserer på upraveghed modellering af morfologiske familier, der samlet omfatter en skov over sprogordforrådet. Denne formulering gør det muligt for os at indfange kantmæssige egenskaber, der afspejler enkelt-trins morfologiske derivater, sammen med globale fordelingsegenskaber af hele skoven. Disse globale egenskaber begrænser størrelsen af affiksættet og fremmer dannelsen af stramme morfologiske familier. Det resulterende mål løses ved hjælp af Integer Linear Programmering (ILP) parret med kontrast estimering. Vi træner modellen ved at skifte mellem optimering af den lokale log-lineære model og det globale ILP mål. Vi evaluerer vores system på tre opgaver: roddetektion, klyngning af morfologiske familier og segmentering. Vores eksperimenter viser, at vores model giver ensartede gevinster i alle tre opgaver sammenlignet med de bedste offentliggjorte resultater.', 'nl': 'Dit artikel richt zich op het niet-begeleide modelleren van morfologische families, collectief bestaande uit een bos boven de taalvocabulaire. Deze formulering stelt ons in staat om randachtige eigenschappen vast te leggen die morfologische afgeleidingen in één stap weerspiegelen, samen met globale distributieeigenschappen van het hele bos. Deze globale eigenschappen beperken de grootte van de affixset en stimuleren de vorming van strakke morfologische families. Het resulterende doel wordt opgelost met behulp van Integer Linear Programming (ILP) gekoppeld aan contrastieve schatting. We trainen het model door af te wisselen tussen het optimaliseren van het lokale log-lineaire model en de globale ILP doelstelling. We evalueren ons systeem op drie taken: worteldetectie, clustering van morfologische families en segmentatie. Onze experimenten tonen aan dat ons model consistente winsten oplevert in alle drie de taken vergeleken met de best gepubliceerde resultaten.', 'hr': 'Ovaj papir se fokusira na neodređenu modelizaciju morfoloških obitelji, kolektivno uključujući šumu nad jezičkim riječi. Ova formulacija nam omogućava da uhvatimo svojstva na ivici odražavajući morfološke derivacije jednokoraka, zajedno s globalnim distribucijskim vlasništvom cijele šume. Ove globalne vlasništvo ograničavaju veličinu postavljenog afiksa i poticaju formiranje čvrstih morfoloških obitelji. Rezultatni cilj je riješen koristeći integer Linear Programming (ILP) povezan s kontrastivnom procjenom. Vježbamo model između optimizacije lokalnog dnevnog modela i globalnog cilja ILP-a. Procjenjujemo naš sustav na tri zadatka: otkrivanje korijena, skupljanje morfoloških obitelji i segmentacije. Naši eksperimenti pokazuju da naš model donosi konsekventne dobiće u svim tri zadatka u usporedbi s najboljim objavljenim rezultatima.', 'de': 'Diese Arbeit konzentriert sich auf die unbeaufsichtigte Modellierung morphologischer Familien, die gemeinsam einen Wald über dem Sprachvokabular bilden. Diese Formulierung ermöglicht es uns, kantenweise Eigenschaften zu erfassen, die einstufige morphologische Ableitungen widerspiegeln, zusammen mit globalen Verteilungseigenschaften des gesamten Waldes. Diese globalen Eigenschaften beschränken die Größe des Affixsatzes und fördern die Bildung enger morphologischer Familien. Das resultierende Ziel wird mittels Integer Linear Programming (ILP) in Kombination mit kontrastiver Schätzung gelöst. Wir trainieren das Modell, indem wir abwechselnd das lokale log-lineare Modell und das globale ILP-Ziel optimieren. Wir bewerten unser System anhand von drei Aufgaben: Wurzelerkennung, Clustering von morphologischen Familien und Segmentierung. Unsere Experimente zeigen, dass unser Modell bei allen drei Aufgaben im Vergleich zu den besten veröffentlichten Ergebnissen konsistente Gewinne erzielt.', 'ko': '본고는 주로 형태 가족의 무감독 모델을 연구하는데 이들은 언어 어휘표의 숲을 공동으로 구성한다.이 공식은 우리로 하여금 단보 형태가 유도하는 가장자리 특성과 전체 삼림의 전역 분포 특성을 포착할 수 있게 한다.이러한 전체적인 속성은 접미사 집합의 크기를 제한하고 긴밀한 형태학 가족을 형성하도록 장려한다.최종 목표는 ILP(정수 선형 계획)와 비교 추정 쌍을 해결하는 것입니다.Dell은 로컬 대수 선형 모델과 글로벌 ILP 목표를 번갈아 최적화하여 모델을 훈련합니다.우리는 세 가지 임무에서 우리의 시스템을 평가한다. 그것이 바로 뿌리 검사, 형태 가족 집합, 분할이다.우리의 실험은 가장 좋은 발표 결과에 비해 우리의 모델이 모든 세 가지 임무에서 일치된 수익을 얻었다는 것을 보여 주었다.', 'id': 'Kertas ini fokus pada model keluarga morfologi yang tidak diawasi, yang kolektif mengandung hutan melalui kata-kata bahasa. Formulasi ini memungkinkan kita untuk menangkap properti bijaksana pinggir yang merefleksikan derivasi morfologi satu langkah, bersama dengan properti distribusi global seluruh hutan. Properti global ini membatasi ukuran set afiks dan mendorong formasi keluarga morfologi ketat. Objektif hasilnya diselesaikan menggunakan Integer Linear Programming (ILP) dipasang dengan perkiraan kontras. Kami melatih model dengan alternatif antara optimisasi model log-linear lokal dan objektif ILP global. Kami mengevaluasi sistem kami pada tiga tugas: deteksi akar, kumpulan keluarga morfologi, dan segmentasi. Eksperimen kami menunjukkan bahwa model kami memberikan keuntungan konsisten dalam tiga tugas dibandingkan dengan hasil terbaik yang diterbitkan.', 'sw': 'Makala haya yanalenga kwenye muundo wa familia za kifolojia usio na uhakika, kwa pamoja unajumuisha misitu juu ya lugha ya lugha. Utengenezaji huu unatuwezesha kutukamata vifaa vinavyoelezea vifaa vya kifolojia pekee, pamoja na utaratibu wa usambazaji wa misitu yote. Utawala huu wa dunia unazuia ukubwa wa kituo hicho kinachotengenezwa na kuhamasisha kutengeneza familia za kifolojia. Lengo la matokeo linasuliwa kwa kutumia programu ya Ujumbe wa Linear (ILP) inayochanganyika kwa estimation mbadala. Tunifundisha muundo kwa kubadilisha kati ya kutengeneza mifano ya kisasa na malengo ya ILP duniani. Tunatathmini mfumo wetu katika kazi tatu: uchunguzi wa asili, kuunganisha familia za kifolojia, na kujitenga. Majaribio yetu yanaonyesha kuwa mifano yetu inaleta mafanikio yanayoendelea katika kazi zote tatu ukilinganisha na matokeo bora yaliyochapishwa.', 'tr': 'Bu kagyz morfolojik maşgalalaryň görkezilmesine üns berip, dil sözleriniň üstünde tokaý daşarylýar. Bu formül bize tüm ormanların küresel dağıtım hasaplarıyla birlikte bir adım morfolojik çözümlerini gözden almamıza mümkin edir. Bu küresel özellikler affiks ayarlarının boyutunu kısıtlıyor ve sıkı morfolojik ailelerinin biçimlenmesini güçlendirir. netijä bolan maksady çözüldir, Haýyl Hat Programlamak (ILP) bilen kontrast deňleýşenler bilen gabdaly. Biz modelini ýerli log-çyzgyly nusgasyny we dünýädäki ILP maksadyny bejererek üýtgederis. Sistemimizi üç görevlerde değerlendiriyoruz: kök tahrip, morfolojik maşgalaryn kopyasını ve bölümleri. Biziň deneylerimiz modelimiz üç zadyň iň gowy görkezilen netijelerimiz bilen daşary gazanýandygyny görkezýär.', 'af': "Hierdie papier fokus op ononderwerpende modellering van morfologiese families, gemeenskap van 'n bos oor die taal woordeboek. Hierdie formulasie laat ons toe om kantwyse eienskappe te vang wat spesifiseer enkel-stap morfologiese afgeleidings, saam met globale verspreidingseienskappe van die hele bos. Hierdie globale eienskappe beperk die grootte van die affix stel en bevestig formasie van tige morfologiese families. Die resulteerde doel is opgelos deur die gebruik van Heelgetalle Lineêre Programming (ILP) saam met kontrastiewe estimatie. Ons tref die model deur alternatief tussen die optimaliseer van die plaaslike log-lineêre model en die globale ILP-doel. Ons evalueer ons stelsel op drie opdragte: wortel opdecking, clustering van morfologiese families en segmentasie. Ons eksperimente bevestig dat ons model konsistente verkry in alle drie taak vergelyk het met die beste gepubliseerde resultate.", 'am': 'ይህ ገጽ በቋንቋው ቋንቋ ቋንቋ ቋንቋ አካባቢ ላይ የሞሮፎሎጂ ቤተሰቦችን መተላለፊያ ላይ ያሳያል፡፡ ይህ አካባቢ የጥበብ ምርጫዎች በሙሉ ዱር ሁሉ ላይ የሞፎሎጂ ግንኙነትን በመመለከት እናስችላለን፡፡ እነዚህ ዓለምአቀፍ ምርጫዎች የአፍሪካ መጠን ይግለጹታል እና ጥብቅ የሞፎሎጂ ቤተሰቦችን መፍጠር ያበረታሉ፡፡ የመጨረሻው አካሄድ በተለየ ተቃውሞ የኢሌፕ ፕሮግራም (ILP) በተጠቃሚ ግምት የተደረገ ነው፡፡ እናስተማርናለን፡፡ We evaluate our system on three tasks: root detection, clustering of morphological families, and segmentation.  ፈተናዎቻችን ምሳሌያችን ከመልካም በተለወጠው ፍሬዎች ጋር በሦስት ስራ ሁሉ ላይ ትክክል እንዲያሳየው ያሳያል፡፡', 'az': 'Bu kağıt, dil sözlərinin üstündə bir orman olan morfolojik ailələrin modellərini təmizləməyən bir modellərə odaqlanır. Bu formül bizə tək adım morfolojik təkrarlarını, bütün ormanın küresel dağıtım özellikləri ilə birlikdə təkrarlanan təkrarları təkrarlamasına imkan verir. Bu küresel xüsusiyyətlərin qədərini sıxınlaşdırır və sıxıntılı morfolojik ailələrinin formasını təşkil edir. Növbəti məqsəd, müxtəlif hesablama ilə birləşdirilmiş Integer Linear Programming (ILP) vasitəsilə çəkilir. Biz modeli yerli log-linear modeli və küresel ILP məqsədili optimizləmək üçün dəyişdiririk. Biz sistemimizi üç işdə değerləşdiririk: kök keşif, morfolojik ailələrinin və segmentasyonu. Bizim təcrübələrimiz modellərimizin ən yaxşı yayınlanmış sonuçları ilə qarşılaşdığı üç işdə müəyyən bir qəniməti verir.', 'hy': 'Այս աշխատանքը կենտրոնանում է մորֆոլոգիական ընտանիքների անվերահսկված մոդելավորման վրա, որը հավաքապես կազմում է անտառ լեզվի բառարանի վերաբերյալ: Այս ձևադրությունը հնարավորություն է տալիս մեզ վերցնել եզերքին հատկություններ, որոնք արտացոլում են մեկ քայլ մորֆոլոգիական առաջնորդներ, միասին ամբողջ անտառի գլոբալ տարածման հատկությունները: Այս գլոբալ հատկությունները սահմանափակում են կապերի չափսերը և խրախուսում են խիստ մորֆոլոգիական ընտանիքների կառուցվածքը: Արդյունքում ստացված նպատակը լուծվում է օգտագործելով ամբողջ գծային ծրագրավորումը (ILP), որը զուգավորվում է հակադրական գնահատման հետ: Մենք վարժեցնում ենք մոդելը, փոխելով տեղական լոգ-գծային մոդելի և համաշխարհային ILP օբյեկտիվացման միջև: We evaluate our system on three tasks: root detection, clustering of morphological families, and segmentation.  Մեր փորձարկումները ցույց են տալիս, որ մեր մոդելը հաստատուն շահույթ է ստանում բոլոր երեք խնդիրներում համեմատած լավագույն հրատարակված արդյունքների հետ:', 'bn': 'এই পত্রিকাটি ভাষাভাষার শব্দভাণ্ডারের বিরুদ্ধে একটি জঙ্গলের প্রতি মনোযোগ দিয়েছে। এই ফর্মুলেশন আমাদেরকে পুরো বনের বিতরণের বৈশ্বিক বৈশিষ্ট্যাবলীর বৈশিষ্ট্যাবলী বৈশিষ্ট্যাবলী বৈশিষ্ট্যাবলীর সাথে প্রতিফলিত কর এই বিশ্ব বৈশ্বিক বৈশিষ্ট্যাবলীগুলোর আফ্রিক্সের আকার নির্ধারিত এবং কঠোর মরোফোলিক্যাল পরিবারের গঠনের উ ফলাফলের উদ্দেশ্য সমাধান করা হয়েছে গুরুত্বপূর্ণ লাইনের প্রোগ্রামিং (আইএলপি) ব্যবহার করে বিরোধী হিসেবে। আমরা মডেল প্রশিক্ষণ করি স্থানীয় লগ-লাইনার মডেল এবং বিশ্বব্যাপী আইএলপি উদ্দেশ্যের মধ্যে বিকল্প করার মাধ্যমে। আমরা তিন কাজের উপর আমাদের সিস্টেম মূল্যায়ন করি: মূল আবিষ্কার, মরোফোলজিক পরিবারের ক্ষেত্রে সংযুক্ত এবং বিভিন্ন ভ আমাদের পরীক্ষাগুলো প্রমাণ করে যে আমাদের মডেল প্রকাশিত ফলাফলের সাথে তিনটি কাজের মধ্যে সাধারণত অর্জন প্রদান করে।', 'bs': 'Ovaj papir se fokusira na neodređenu modelizaciju morfoloških porodica, kolektivno uključujući šumu nad jezičkim rečenicima. Ova formulacija nam omogućava da uhvatimo svojstva na ivici odražavajući morfološke derivacije jednokoraka, zajedno sa globalnim distribucijskim svojstvima cijele šume. Ove globalne vlasništvo ograničavaju veličinu postavljenog afiksa i ohrabruju formaciju čvrstih morfoloških porodica. Rezultatni cilj je rešen koristeći integer Linear Programming (ILP) povezan sa kontrastivnim procjenama. Vježbamo model između optimizacije lokalnog dnevnog modela i globalnog cilja ILP-a. Procjenjujemo naš sistem na tri zadatka: otkrivanje korijena, skupljanje morfoloških porodica i segmentacije. Naši eksperimenti pokazuju da naš model donosi konsekventne dobiće u svim tri zadatka u usporedbi sa najboljim objavljenim rezultatima.', 'fa': 'این کاغذ روی نمونه\u200cهای ناپایدار از خانواده\u200cهای مورفیولوژیکی تمرکز می\u200cکند، که جمعیت یک جنگل بر روی کلمات زبان است. این فرمول به ما اجازه می\u200cدهد که ویژگی\u200cهای کناره\u200cی کناره\u200cای را برعکس کنیم که تولید\u200cهای مرفولژیک یک قدم، همراه با ویژگی\u200cهای تقسیم جهانی کل جنگل است. این ویژگی\u200cهای جهانی اندازه\u200cی مجموعه\u200cی مجموعه\u200cی ماشین\u200cها را محدود می\u200cکند و تشویق می\u200cدهد که ساختن خانواده\u200cهای مورفولوژیک محکم است. هدف نتیجه با استفاده از برنامه\u200cبندی کلی خطی (ILP) که با ارزیابی متفاوتی جفت دارد حل می\u200cشود. ما مدل را با تغییر دادن بین optimization of the log-linear local and the global ILP objective آموزش می دهیم. ما سیستم خود را بر سه کار ارزیابی می\u200cکنیم: کشف ریشه، گروهی از خانواده\u200cهای مورفولوژیکی و گروهی. آزمایشات ما نشان می دهند که مدل ما در تمام سه کار پیروزی قابل توجه با بهترین نتایج منتشر شده است.', 'ca': "Aquest article es centra en la modelació no supervisada de famílies morfològiques, que componen col·lectivament un bosc sobre el vocabulari de llenguatges. Aquesta formulació ens permet capturar propietats de punta a punta que reflecteixen derivacions morfològiques d'un pas, juntament amb propietats distribucionals globals de tot el bosc. Aquestes propietats globals limitan la mida del conjunt d'afixes i estimulan la formació de famílies morfològiques estretes. L'objectiu resultant és resolt fent servir la programació linear intega (ILP) parellada amb estimació contrastiva. Ensenyem el model alternant entre l'optimització del model log-linear local i l'objectiu global de l'ILP. Evaluam el nostre sistema en tres tasques: detecció raíc, agrupament de famílies morfològiques i segmentació. Els nostres experiments demostren que el nostre model produeix guanys consistents en les tres tasques comparats amb els millors resultats publicats.", 'cs': 'Tento článek se zaměřuje na bezdozorované modelování morfologických rodin, které společně tvoří les nad jazykovou slovní zásobou. Tato formulace nám umožňuje zachytit okrajové vlastnosti odrážející jednostupňové morfologické odvození, spolu s globálními distribučními vlastnostmi celého lesa. Tyto globální vlastnosti omezují velikost sady afixů a podporují tvorbu těsných morfologických rodin. Výsledný cíl je řešen pomocí integer lineárního programování (ILP) v kombinaci s kontrastním odhadem. Model trénujeme střídavou optimalizací lokálního log-lineárního modelu a globálního ILP cíle. Systém hodnotíme na třech úkolech: detekci kořenů, shlukování morfologických rodin a segmentaci. Naše experimenty ukazují, že náš model přináší konzistentní zisky ve všech třech úkolech ve srovnání s nejlepšími publikovanými výsledky.', 'et': 'Käesolev töö keskendub morfoloogiliste perekondade järelevalveta modelleerimisele, mis koosnevad ühiselt metsast üle keele sõnavara. Selline koostis võimaldab meil jäädvustada servaomadusi, mis peegeldavad üheastmelisi morfoloogilisi tuletisi, koos kogu metsa globaalsete jaotusomadustega. Need globaalsed omadused piiravad kinnituskogumi suurust ja soodustavad tihedate morfoloogiliste perekondade moodustumist. Saadud eesmärk on lahendatud kasutades Integer Linear Programming (ILP) koos kontrastse hindamisega. Me treenime mudelit vaheldudes kohaliku log-lineaarse mudeli optimeerimise ja globaalse ILP eesmärgi vahel. Hindame oma süsteemi kolmel ülesandel: juurte tuvastamine, morfoloogiliste perekondade klastristamine ja segmenteerimine. Meie katsed näitavad, et meie mudel annab kõigis kolmes ülesandes pidevat kasu võrreldes parimate avaldatud tulemustega.', 'sq': 'Kjo letër përqëndrohet në modelimin e pa mbikqyrur të familjeve morfologjike, duke përfshirë kolektivisht një pyll mbi fjalorin gjuhësor. This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest.  Këto prona globale kufizojnë madhësinë e grupit të lidhjeve dhe inkurajojnë formimin e familjeve morfologjike të ngushta. Objektivi që rezulton është zgjidhur duke përdorur Programimin Integer Linear (ILP) të barazuar me vlerësimin kontrastiv. We train the model by alternating between optimizing the local log-linear model and the global ILP objective.  Ne vlerësojmë sistemin tonë në tre detyra: zbulimin e rrënjës, grupimin e familjeve morfologjike, dhe segmentimin. Eksperimentet tona tregojnë se modeli ynë jep fitime konsistente në të tre detyrat krahasuar me rezultatet më të mira botuar.', 'fi': 'Tässä artikkelissa keskitytään morfologisten perheiden valvomattomaan mallintamiseen, jotka muodostavat yhdessä metsän kielisanaston yli. Tämän formulaation avulla voimme tallentaa reunaviisaita ominaisuuksia, jotka heijastavat yksivaiheisia morfologisia johdannaisia sekä koko metsän maailmanlaajuisia jakautumisominaisuuksia. Nämä globaalit ominaisuudet rajoittavat kiinnityksen kokoa ja kannustavat muodostamaan tiukkoja morfologisia perheitä. Tuloksena oleva tavoite ratkaistaan käyttämällä kokonaislineaarista ohjelmointia (ILP) ja kontrastiestimointia. Koulutamme mallia vuorotellen paikallisen log-lineaarisen mallin optimoinnin ja globaalin ILP-tavoitteen välillä. Arvioimme järjestelmäämme kolmella tehtävällä: juurien havaitseminen, morfologisten perheiden klusterointi ja segmentointi. Kokeemme osoittavat, että mallimme tuottaa yhdenmukaisia voittoja kaikissa kolmessa tehtävässä verrattuna parhaisiin julkaistuihin tuloksiin.', 'jv': 'Awak-awak iki macem kuwi wis ngerasakno kanggo ngerasakno karo perbudhakan maneh, akeh nguasakno sing ngebokake karo perbudhakan langga. ProgressBarUpdates Ngperusahaan wong iki iso nggunakaé nduwé kuwi aturan anyar nggawe lan ngubah cara-cara kuwi tindong nggawe Raylan Awak dhéwé luwih akeh model sing alih mruput tinimbang nggawe model log-linear karo Gambar kanggo ngerggo IBP. Monday Awakdhéwé éntuk éntuk sawetara dadi model sing ngenggo perusahaan segala karo ngono perusahaan sing luwih apik dhéwé.', 'ha': "Wannan takardan na fokus a kan misalin gidan morfologi da ba'a tsare ba, mai haɗuwa yana da wani misitu a kan maganar harshen. Wannan ƙayyade yana amfani da mu kãma gefen-mai-Hikima, mai yi tunãni ga taƙaita masu motsi guda, sami da properties na fassarar duniya da duk misitun. Wannan tayari na global ana ƙunsa girmar affx na daidaita kuma ana kwaɗaitar da danna danna iyãlanci masu mutumci. An nuna abun da aka ƙara shi da shirin Programme na Intel Line (ILP) wanda aka haɗa shi da ƙayyade mai motsi. Tuna kõre shirin ayuka da za'a yi amfani da shirin ayuka na lokal-log da abun GL. Tuna ƙaddara kanmu a kan aikin uku: misalin ruwan zaren mutane, da dangi na mutane da jini. Kayan jarrabõyinmu sun nuna cewa misalinmu yana fitar da rabo daidai a cikin duk aikin uku sami da mafi kyaun fassarar da aka bayyana.", 'he': 'העבודה הזו מתמקדת בדוגמאות לא משומרת של משפחות מורפולוגיות, המכילה באופן קולטיבי יער מעל מילון השפה. This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest.  הנכונות הגלובליות האלה מגבילות את גודל קבוצת הציוד ולעודד ליצור משפחות מורפולוגיות צמודות. האובייקטיב הנוצא נפתר באמצעות תוכנית לינרית שלמה (Integer Linear Programming - ILP) זווית עם הערכה בניגוד. אנחנו מאמן את המודל על ידי התחלפות בין אופטימיזם מודל לוג-לינרי מקומי למטרה של ILP הגלובלית. אנחנו מעריכים את המערכת שלנו על שלושה משימות: זיהוי שורש, קבוצת משפחות מורפולוגיות, וסגמנציה. Our experiments demonstrate that our model yields consistent gains in all three tasks compared with the best published results.', 'sk': 'Prispevek se osredotoča na nenadzorovano modeliranje morfoloških družin, ki skupaj sestavljajo gozd nad jezikovnim besednjakom. Ta formulacija nam omogoča, da zajamemo robne lastnosti, ki odražajo enostopenjske morfološke derivacije, skupaj z globalnimi distribucijskimi lastnostmi celotnega gozda. Te globalne lastnosti omejujejo velikost nabora pritrditev in spodbujajo tvorbo tesnih morfoloških družin. Dobljeni cilj je rešen z uporabo celotnega linearnega programiranja (ILP) v kombinaciji s kontrastno oceno. Model treniramo z izmenjavo med optimizacijo lokalnega log-linearnega modela in globalnim ciljem ILP. Naš sistem ocenjujemo na treh nalogah: odkrivanje korenin, grudiranje morfoloških družin in segmentacija. Naši poskusi dokazujejo, da naš model prinaša dosledne dobičke pri vseh treh nalogah v primerjavi z najboljšimi objavljenimi rezultati.', 'bo': 'ཤོག་བྱང་འདིས་མཐོང་བཟོས་མིན་པའི་ནང་དུ་བཟོས་ཁང་གི་མིང་དཔྱད་མེད་པར་མཐོང་ནུས་ཡོད། This formulation enables us to capture edge-wise properties reflecting single-step morphological derivations, along with global distributional properties of the entire forest. These global properties constrain the size of the affix set and encourage formation of tight morphological families. དཔག་འབྲས་ཡོད་པའི་དམིགས་ཡུལ་ནི་ཧྲིལ་ཨང་གྲངས་ཀྱི་བྱ་རིམ་སྤྱོད་ཀྱིས་མཐུན་པར་མཐུན་ཡོད། ང་ཚོས་རང་ཁུལ ང་ཚོའི་མ་ལག་ནི་བྱ་ཚིག་གསུམ་གྱི་གནད་སྡུད་མིན་དུ་རྩ་བ་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་བརྟག་ཞིག་གིས་མིག་གཟུགས་རིས་མི་གཅིག་གི་ལས་འགུལ་གསུམ་ཀྱི་རྒྱལ་ཁབ་སྐྱེས་རྒྱུ་ཡིན་ན།'}
{'en': 'Fully Character-Level Neural Machine Translation without Explicit Segmentation', 'pt': 'Tradução automática neural totalmente em nível de caractere sem segmentação explícita', 'ar': 'ترجمة آلية عصبية على مستوى الحرف بالكامل بدون تجزئة صريحة', 'es': 'Traducción automática neuronal totalmente a nivel de caracteres sin segmentación explícita', 'fr': 'Traduction automatique neuronale entièrement au niveau des caractères sans segmentation explicite', 'zh': '全符之神经机器翻译,无待显式分', 'ja': '明示的なセグメンテーションを伴わない完全な文字レベルの神経機械翻訳', 'hi': 'स्पष्ट विभाजन के बिना पूरी तरह से चरित्र-स्तरीय तंत्रिका मशीन अनुवाद', 'ru': 'Полностью персонажевый нейронный машинный перевод без явной сегментации', 'ga': 'Aistriúchán Meaisín Neural ar Leibhéal Carachtair go hiomlán gan deighilt shoiléir', 'hu': 'Teljesen karakterszintű neurális gépi fordítás explicit szegmentáció nélkül', 'el': 'Νευρική μηχανική μετάφραση πλήρους επιπέδου χαρακτήρων χωρίς ρητή τμηματοποίηση', 'ka': 'სიმბოლოების ნაწილის ნეიროლური მაქსინის შეცვლა', 'kk': 'Толық таңбалар деңгейі нейрондық машинаның аудармасыName', 'it': 'Traduzione automatica neurale completamente a livello di carattere senza segmentazione esplicita', 'lt': 'Visiškas ženklų lygio neurologinio mašinos vertimas be aiškios segmentacijos', 'ml': 'എക്സ്പ്ലിക്റ്റ് സെഗ്മെന്റേഷനില്ലാതെ പൂര്\u200dണ്ണമായ അക്ഷരസഞ്ചയം നെയുറല്\u200d യന്ത്രം പരിഭാഷ', 'mt': 'Traduzzjoni sħiħa tal-Magna Newrali fil-Livell tal-Karatteri mingħajr Segmentazzjoni Espliċita', 'mk': 'Целосно преведување на неурална машина на ниво на знаци без експлицитна сегментација', 'ms': 'Terjemahan Mesin Neural Aras-Aksara Penuh Tanpa Segmentasi Jelas', 'mn': 'Тодорхой хэмжээний түвшинд мэдрэлийн машин хөгжүүлэхгүй', 'no': 'Fullt teiknrivå neuralmaskineomsetjing utan eksplisitt segmentasjon', 'pl': 'W pełni znakowe tłumaczenie maszynowe neuronowe bez wyraźnej segmentacji', 'ro': 'Traducere automată neurală complet la nivel de caracter fără segmentare explicită', 'sr': 'Potpuno prevod neurološke mašine na nivou karaktera bez eksplicitne segmentacije', 'si': 'සම්පූර්ණයෙන්ම අක්ෂර- තත්වය න්\u200dයුරල් මැෂින් පරිවර්තනය', 'so': 'Turjumista dhamaan xarafta-darajada Neural machine without Explicit Segmentation', 'sv': 'Neural maskinöversättning helt på teckenivå utan explicit segmentering', 'ta': 'முழு எழுத்து- நிலை நெருக்கர் இயந்திரம் மொழிபெயர்ப்பு', 'ur': 'مفصل سیگنٹمنٹ کے بغیر پورے کراکٹر- سطح نیورال ماشین کا ترجمہ', 'uz': 'Name', 'vi': 'Dịch cỗ máy thần kinh mà không có đoạn theo yêu cầu', 'bg': 'Невроден машинен превод без изрична сегментация', 'nl': 'Volledig karakterniveau Neural Machine Translation zonder expliciete segmentatie', 'da': 'Neural maskinoversættelse på tegneniveau uden eksplicit segmentering', 'hr': 'Potpuno prevod neuroloških strojeva na nivou znakova bez eksplicitne segmentacije', 'de': 'Neurale maschinelle Übersetzung auf Zeichenebene ohne explizite Segmentierung', 'ko': '무현식 분할의 전 문자급 신경', 'fa': 'ترجمه ماشین عصبی سطح شخصیت کامل بدون جدایی مشخص', 'id': 'Penuh Translation Mesin Neural Aras-Karakter Tanpa Segmentasi Jelas', 'sw': 'Tafsiri ya Kifaransa-Kiwango cha Neural bila Segmentation', 'tr': 'Tamamlar Karakter-Derje Näral Mazmunlar Çevirmeki', 'sq': 'Përkthimi i plotë i makinës nervore me nivelin e karakterit pa segmentim të shprehur', 'af': 'Volledig Karakter- Vlak Neural Masjien Vertaling sonder Explicit Segmentation', 'am': 'ምርጫዎች', 'hy': 'Ամբողջ նյարդային մեխանիզմի մակարդակի թարգմանություն առանց բացահայտ սեգմետացիայի', 'az': 'T칲m Karakter-Seviye N칬ral Makinesi T톛rc칲m톛', 'bs': 'Potpuno prevod neuroloških strojeva na nivou karaktera bez eksplicitne segmentacije', 'bn': 'এক্সপ্লিকিট বিভাগ ছাড়া পুরো অক্ষর- স্তর নিউরাল মেশিন অনুবাদ', 'ca': 'La traducció completa de màquina neuronal a nivell de caràcters sense segmentació explícita', 'cs': 'Neurální strojový překlad na úrovni znaků bez explicitní segmentace', 'et': 'Täielikult märgitasemel neuraalne masintõlge ilma selgesõnalise segmentatsioonita', 'fi': 'Täysin merkkitason neurokonekäännös ilman eksplisiittistä segmentointia', 'jv': 'politenessoffpolite"), and when there is a change ("assertive', 'ha': 'translation', 'sk': 'Živčni strojni prevod v celoti znakov brez eksplicitne segmentacije', 'he': 'תורגם וסונכרן ע"י תורגם וסונכרן ע"י', 'bo': 'ཁྱད་དུ་འཕགས་པའི་ཆ་རྟགས་དང་སྐྱེལ་ཚད་neural རྩིས་འཁོར་གྱི་སྐད་བསྒྱུར་མེད་པ'}
{'en': 'Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens. We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any segmentation. We employ a character-level convolutional network with max-pooling at the encoder to reduce the length of source representation, allowing the model to be trained at a speed comparable to subword-level models while capturing local regularities. Our character-to-character model outperforms a recently proposed baseline with a subword-level encoder on WMT’15 DE-EN and CS-EN, and gives comparable performance on FI-EN and RU-EN. We then demonstrate that it is possible to share a single character-level encoder across multiple languages by training a model on a many-to-one translation task. In this multilingual setting, the character-level encoder significantly outperforms the subword-level encoder on all the language pairs. We observe that on CS-EN, FI-EN and RU-EN, the quality of the multilingual character-level translation even surpasses the models specifically trained on that language pair alone, both in terms of the BLEU score and human judgment.', 'ar': "تعمل معظم أنظمة الترجمة الآلية الحالية على مستوى الكلمات ، وتعتمد على التجزئة الصريحة لاستخراج الرموز المميزة. نقدم نموذج الترجمة الآلية العصبية (NMT) الذي يقوم بتعيين تسلسل الأحرف المصدر إلى تسلسل الأحرف المستهدف دون أي تقسيم. نحن نستخدم شبكة تلافيفية على مستوى الحرف مع أقصى تجمع في المشفر لتقليل طول تمثيل المصدر ، مما يسمح للنموذج بالتدريب بسرعة مماثلة لنماذج مستوى الكلمات الفرعية أثناء التقاط الانتظام المحلي. يتفوق نموذجنا من حرف إلى حرف على خط الأساس المقترح مؤخرًا باستخدام برنامج تشفير على مستوى الكلمة الفرعية على WMT'15 DE-EN و CS-EN ، ويوفر أداءً مشابهًا على FI-EN و RU-EN. نوضح بعد ذلك أنه من الممكن مشاركة برنامج تشفير واحد على مستوى الأحرف عبر لغات متعددة من خلال تدريب نموذج على مهمة ترجمة متعددة الأطراف. في هذا الإعداد متعدد اللغات ، يتفوق برنامج التشفير على مستوى الأحرف بشكل كبير على برنامج التشفير على مستوى الكلمات الفرعية في جميع أزواج اللغات. نلاحظ أنه في CS-EN و FI-EN و RU-EN ، فإن جودة الترجمة متعددة اللغات على مستوى الأحرف تفوق حتى النماذج المدربة خصيصًا على هذا الزوج اللغوي وحده ، سواء من حيث درجة BLEU أو الحكم البشري.", 'pt': "A maioria dos sistemas de tradução automática existentes opera no nível de palavras, contando com segmentação explícita para extrair tokens. Apresentamos um modelo de tradução automática neural (NMT) que mapeia uma sequência de caracteres de origem para uma sequência de caracteres de destino sem qualquer segmentação. Empregamos uma rede convolucional em nível de caractere com pool máximo no codificador para reduzir o comprimento da representação da fonte, permitindo que o modelo seja treinado a uma velocidade comparável aos modelos de nível de subpalavra enquanto captura regularidades locais. Nosso modelo de caractere a caractere supera uma linha de base proposta recentemente com um codificador de nível de subpalavra no WMT'15 DE-EN e CS-EN e oferece desempenho comparável em FI-EN e RU-EN. Em seguida, demonstramos que é possível compartilhar um único codificador de nível de caractere em vários idiomas treinando um modelo em uma tarefa de tradução de muitos para um. Nesta configuração multilíngue, o codificador de nível de caractere supera significativamente o codificador de nível de subpalavra em todos os pares de idiomas. Observamos que em CS-EN, FI-EN e RU-EN, a qualidade da tradução multilíngue em nível de caractere supera até mesmo os modelos treinados especificamente para esse par de idiomas sozinho, tanto em termos de pontuação BLEU quanto em julgamento humano.", 'es': "La mayoría de los sistemas de traducción automática existentes funcionan al nivel de las palabras y se basan en la segmentación explícita para extraer los tokens. Presentamos un modelo de traducción automática neuronal (NMT) que asigna una secuencia de caracteres de origen a una secuencia de caracteres de destino sin ninguna segmentación. Empleamos una red convolucional a nivel de caracteres con agrupación máxima en el codificador para reducir la longitud de la representación de la fuente, lo que permite que el modelo se entrene a una velocidad comparable a los modelos a nivel de subpalabra mientras se capturan las regularidades locales. Nuestro modelo de carácter a personaje supera a una línea de base propuesta recientemente con un codificador a nivel de subpalabra en WMT'15 DE-EN y CS-EN, y ofrece un rendimiento comparable en FI-EN y RU-EN. A continuación, demostramos que es posible compartir un único codificador a nivel de caracteres en varios idiomas mediante la formación de un modelo en una tarea de traducción de varios a uno. En este entorno multilingüe, el codificador a nivel de caracteres supera significativamente al codificador a nivel de subpalabra en todas las combinaciones de idiomas. Observamos que en CS-EN, FI-EN y RU-EN, la calidad de la traducción multilingüe a nivel de caracteres incluso supera los modelos específicamente entrenados solo en ese par de idiomas, tanto en términos de puntuación BLEU como de juicio humano.", 'fr': "La plupart des systèmes de traduction automatique existants fonctionnent au niveau des mots, s'appuyant sur une segmentation explicite pour extraire les jetons. Nous introduisons un modèle de traduction automatique neuronale (NMT) qui mappe une séquence de caractères source à une séquence de caractères cible sans aucune segmentation. Nous utilisons un réseau convolutif au niveau des caractères avec mise en commun maximale au niveau de l'encodeur afin de réduire la longueur de la représentation source, ce qui permet d'entraîner le modèle à une vitesse comparable à celle des modèles au niveau des sous-mots tout en capturant les régularités locales. Notre modèle caractère à caractère surpasse une base récemment proposée avec un encodeur de niveau sous-mot sur WMT'15 DE-EN et CS-EN, et offre des performances comparables sur FI-EN et RU-EN. Nous démontrons ensuite qu'il est possible de partager un seul encodeur de niveau caractère dans plusieurs langues en entraînant un modèle sur une tâche de traduction plusieurs-à-un. Dans ce paramètre multilingue, l'encodeur au niveau des caractères surpasse de manière significative l'encodeur au niveau des sous-mots sur toutes les paires de langues. Nous observons que sur CS-EN, FI-EN et RU-EN, la qualité de la traduction multilingue au niveau des caractères dépasse même les modèles spécifiquement formés sur cette paire de langues uniquement, à la fois en termes de score BLEU et de jugement humain.", 'hi': "अधिकांश मौजूदा मशीन अनुवाद प्रणालियां शब्दों के स्तर पर काम करती हैं, टोकन निकालने के लिए स्पष्ट विभाजन पर निर्भर करती हैं। हम एक तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल पेश करते हैं जो किसी भी विभाजन के बिना एक लक्ष्य चरित्र अनुक्रम के लिए एक स्रोत चरित्र अनुक्रम को मैप करता है। हम स्रोत प्रतिनिधित्व की लंबाई को कम करने के लिए एन्कोडर पर अधिकतम-पूलिंग के साथ एक चरित्र-स्तरीय कनवल्शनल नेटवर्क को नियोजित करते हैं, जिससे मॉडल को स्थानीय नियमितताओं पर कब्जा करते समय सबवर्ड-स्तर के मॉडल के तुलनीय गति से प्रशिक्षित किया जा सकता है। हमारा चरित्र-से-चरित्र मॉडल WMT'15 DE-EN और CS-EN पर एक सबवर्ड-स्तर एन्कोडर के साथ हाल ही में प्रस्तावित बेसलाइन को मात देता है, और FI-EN और RU-EN पर तुलनीय प्रदर्शन देता है। फिर हम प्रदर्शित करते हैं कि कई-से-एक अनुवाद कार्य पर एक मॉडल को प्रशिक्षित करके कई भाषाओं में एक एकल चरित्र-स्तरीय एन्कोडर साझा करना संभव है। इस बहुभाषी सेटिंग में, वर्ण-स्तर एन्कोडर सभी भाषा जोड़े पर सबवर्ड-स्तर एन्कोडर को महत्वपूर्ण रूप से बेहतर बनाता है। हम देखते हैं कि सीएस-ईएन, एफआई-एन और आरयू-ईएन पर, बहुभाषी चरित्र-स्तर के अनुवाद की गुणवत्ता विशेष रूप से उस भाषा जोड़ी पर विशेष रूप से प्रशिक्षित मॉडलों को भी पार कर जाती है, दोनों BLEU स्कोर और मानव निर्णय के संदर्भ में।", 'ja': "ほとんどの既存の機械翻訳システムは、トークンを抽出するための明示的なセグメンテーションに依存して、単語レベルで動作します。 ソース文字シーケンスをセグメンテーションなしでターゲット文字シーケンスにマッピングするニューラルマシン翻訳（ ＮＭＴ ）モデルを導入する。 ソース表現の長さを短縮するために、エンコーダで最大プーリングを備えた文字レベルの畳み込みネットワークを採用し、ローカルの規則性をキャプチャしながら、サブワードレベルのモデルに匹敵する速度でモデルをトレーニングすることができます。 当社の文字間モデルは、WMT '15 DE - ENおよびCS - ENのサブワードレベルエンコーダを使用して、最近提案されたベースラインを上回り、FI - ENおよびRU - ENで同等のパフォーマンスを提供します。 次に、マルチツーワン翻訳タスクでモデルをトレーニングすることにより、複数の言語で単一の文字レベルのエンコーダを共有することが可能であることを実証します。 この多言語設定では、文字レベルのエンコーダは、すべての言語ペアでサブワードレベルのエンコーダを大幅に上回ります。 CS - EN、FI - EN、RU - ENでは、多言語の文字レベルの翻訳の品質は、BLEUスコアと人間の判断の両方の観点から、その言語ペアだけで特に訓練されたモデルを超えていることが観察されます。", 'zh': "大抵机器翻译系于单词级,因显式分割以取标记。 引入一神经机器翻译(NMT),映源字符序,无所分割。 余用字符级卷积网络,于编码器最大池化,以减其长,而许以子词等训练,兼获局法。 我们的字符到字符模形在 WMT'15 DE-EN 和 CS-EN 上用子字级编码器优于近发的基线,并在 FI-EN 和 RU-EN 上供给可比的性能。 然后,我们证明,因在多对一译职务上训练模样,可以跨多种语言共享单个字符级编码器。 多言置中,字符级编码器于诸言对上者显优于子字级编码器。 观其CS-EN,FI-ENRU-EN之上,多语言符译者,过于专习,BLEU分人伦。", 'ru': "Большинство существующих систем машинного перевода работают на уровне слов, полагаясь на явную сегментацию для извлечения токенов. Мы вводим модель нейронного машинного перевода (НМП), которая отображает последовательность исходного символа в последовательность целевого символа без какой-либо сегментации. Мы используем сверточную сеть на уровне символов с макс-пулингом на кодере, чтобы сократить длину представления источника, что позволяет обучать модель со скоростью, сопоставимой с моделями на уровне подслова, в то же время фиксируя локальные закономерности. Наша межсимвольная модель превосходит недавно предложенную базовую линию с кодером уровня подслова на WMT'15 DE-EN и CS-EN и дает сопоставимую производительность на FI-EN и RU-EN. Затем мы демонстрируем, что можно использовать один кодировщик на нескольких языках, обучая модель задаче перевода «много к одному». В этой многоязычной настройке кодировщик на уровне символов значительно превосходит кодировщик на уровне подслова по всем языковым парам. Мы наблюдаем, что в CS-EN, FI-EN и RU-EN качество многоязычного перевода на уровне символов даже превосходит модели, специально обученные только этой языковой паре, как с точки зрения оценки BLEU, так и с точки зрения человеческого суждения.", 'ga': "Feidhmíonn formhór na gcóras aistriúcháin meaisín atá ann faoi láthair ar leibhéal na bhfocal, ag brath ar dheighilt shoiléir chun comharthaí a bhaint as. Tugaimid isteach múnla néaraistriúcháin meaisín (NMT) a mhapálann seicheamh carachtar foinseach go seicheamh sprioccharachtair gan aon deighilt. Bainimid úsáid as líonra comhdhlúite carachtar-leibhéal le comhthiomsú uasta ag an ionchódóir chun fad ionadaíochta na foinse a laghdú, rud a ligeann don tsamhail a bheith oilte ag luas atá inchomparáide le samhlacha leibhéal fofhocail agus ag an am céanna rialtacht áitiúil a ghabháil. Sáraíonn ár múnla carachtar-go-carachtar bonnlíne a moladh le déanaí le hionchódóir leibhéal fofhocail ar WMT'15 DE-EN agus CS-EN, agus tugann sé feidhmíocht inchomparáide ar FI-EN agus RU-EN. Léirímid ansin gur féidir ionchódóir aonair ar leibhéal na gcarachtar a roinnt thar iltheangacha trí mhúnla a oiliúint ar thasc aistriúcháin go leor le duine. Sa socrú ilteangach seo, is fearr go mór an t-ionchódóir ar leibhéal na gcarachtar ná an t-ionchódóir leibhéal fofhocail ar na péirí teangacha go léir. Tugaimid faoi deara, ar CS-EN, FI-EN agus RU-EN, go sáraíonn cáilíocht an aistriúcháin ilteangach ar leibhéal na gcarachtar na múnlaí atá oilte go sonrach sa phéire teanga sin amháin, i dtéarmaí scór BLEU agus breithiúnas daonna araon.", 'ka': "მნიშვნელოვანი მაქსინური გაგრძელება სიტყვების დონეში მუშაობს, რომელიც გამოყენებული სიმბოლოების სიგრძელობაზე დააყენებულია. ჩვენ შევცვალოთ ნეიროლური მანქანის გადაწყვეტილება (NMT) მოდელს, რომელიც მხოლოდ სიმბოლოს სიმბოლოს გადაწყვეტილის სიმბოლოს სიმბოლოს სიმბოლოს ჩვენ კონტუალური ქსელის კონტუალური სახლის გამოყენება, რომელიც კონტუალური სახლის სიგრძე გამოყენება კონტუალური ქსელი, რომელიც კონტუალური სახლის სიგრძე გამოყენება, რომ მხოლოდ რეგილური ჩვენი სიმბოლოების მოდელი გავაკეთება მხოლოდ საუკეთესო სიტყვების კოდირებით WMT'15 DE-EN და CS-EN-ზე, და FI-EN და RU-EN-ზე შემდგომარებელი გამოყენება. შემდეგ ჩვენ გამოჩვენებთ, რომ შესაძლებელია ერთი სიმბოლოების კოდირების კოდირების მრავალ ენათების განმავლობაში მოდელის განმავლობაში მრავალზე ერთი განმავლობაში. ამ მრავალენგური პარამეტრებში სიმბოლოების დონე კოდირები მნიშვნელოვანია ყველა ენგური ზოგის სუბსიმბოლოების კოდირების მნიშვნელოვანია. ჩვენ დავხედავთ, რომ CS-EN, FI-EN და RU-EN, მრავალენგური სიტყვების გადაწყვეტილების კალგატი უფრო მეტი სიტყვების სიტყვების გადარჩენა მოდელების განსაკუთრებულად განსწავლებული ამ ენის ზოგში, რომელიც BLEU წერტი", 'hu': "A legtöbb meglévő gépi fordító rendszer szavak szintjén működik, kifejezett szegmentálásra támaszkodva a tokenek kivonásához. Bemutatunk egy neurális gépi fordítási (NMT) modellt, amely szegmentáció nélkül leképezi a forrásjegysorozatot egy célkaraktersorozathoz. Karakterszintű konvolúciós hálózatot alkalmazunk a kódolónál maximális összevonással, hogy csökkentsük a források ábrázolásának hosszát, lehetővé téve, hogy a modell az alszó szintű modellekhez hasonló sebességgel képezze, miközben rögzíti a helyi szabályosságokat. Karakter-karakter modellünk felülmúlja a közelmúltban javasolt alapközpontot WMT'15 DE-EN és CS-EN alszószintű kódolóval, és hasonló teljesítményt nyújt FI-EN és RU-EN esetén. Ezt követően bebizonyítjuk, hogy egyetlen karakterszintű kódolót lehetséges megosztani több nyelven azáltal, hogy modellt képzünk egy sok az egyhez fordítási feladatra. Ebben a többnyelvű beállításban a karakterszintű kódoló jelentősen felülmúlja az alszó szintű kódolót az összes nyelvpárban. Megfigyeljük, hogy a CS-EN, FI-EN és RU-EN esetében a többnyelvű karakterszintű fordítás minősége meghaladja az adott nyelvpárra kifejezetten képzett modelleket, mind a BLEU pontszám, mind az emberi ítélőképesség tekintetében.", 'el': "Τα περισσότερα υπάρχοντα συστήματα μηχανικής μετάφρασης λειτουργούν στο επίπεδο λέξεων, βασιζόμενοι σε σαφή τμηματοποίηση για την εξαγωγή σημάτων. Παρουσιάζουμε ένα μοντέλο νευρωνικής μηχανικής μετάφρασης (NMT) που χαρτογραφεί μια ακολουθία χαρακτήρων προέλευσης σε μια ακολουθία χαρακτήρων στόχων χωρίς καμία τμηματοποίηση. Χρησιμοποιούμε ένα δίκτυο διαστολής σε επίπεδο χαρακτήρων με μέγιστη συγκέντρωση στον κωδικοποιητή για να μειώσουμε το μήκος της αναπαράστασης πηγής, επιτρέποντας στο μοντέλο να εκπαιδευτεί με ταχύτητα συγκρίσιμη με μοντέλα σε επίπεδο υπολέξεων, ενώ καταγράφουμε τοπικές κανονικότητες. Το μοντέλο χαρακτήρας προς χαρακτήρα ξεπερνά μια πρόσφατα προτεινόμενη βάση βάσης με έναν κωδικοποιητή σε επίπεδο υπολέξεων σε WMT'15 DE-EN και CS-EN, και παρέχει συγκρίσιμη απόδοση σε FI-EN και RU-EN. Στη συνέχεια, αποδεικνύουμε ότι είναι δυνατή η κοινή χρήση ενός ενιαίου κωδικοποιητή σε επίπεδο χαρακτήρων σε πολλές γλώσσες εκπαιδεύοντας ένα μοντέλο σε μια εργασία μετάφρασης πολλών προς ενός. Σε αυτήν την πολυγλωσσική ρύθμιση, ο κωδικοποιητής επιπέδου χαρακτήρων ξεπερνά σημαντικά τον κωδικοποιητή επιπέδου υπολέξεων σε όλα τα ζεύγη γλωσσών. Παρατηρούμε ότι στην CS-EN, FI-EN και RU-EN, η ποιότητα της πολύγλωσσης μετάφρασης σε επίπεδο χαρακτήρων ξεπερνά ακόμη και τα μοντέλα ειδικά εκπαιδευμένα σε αυτό το γλωσσικό ζεύγος μόνο, τόσο όσον αφορά την βαθμολογία BLEU όσο και την ανθρώπινη κρίση.", 'it': "La maggior parte dei sistemi di traduzione automatica esistenti opera a livello di parole, facendo affidamento su segmentazione esplicita per estrarre i token. Introducemo un modello di traduzione automatica neurale (NMT) che mappa una sequenza di caratteri sorgente a una sequenza di caratteri target senza alcuna segmentazione. Impieghiamo una rete convoluzionale a livello di carattere con max-pooling all'encoder per ridurre la lunghezza della rappresentazione sorgente, consentendo al modello di essere addestrato ad una velocità paragonabile ai modelli a livello di subparola, catturando le regolarità locali. Il nostro modello character-to-character supera una linea di base recentemente proposta con un codificatore a livello di subword su WMT'15 DE-EN e CS-EN e offre prestazioni comparabili su FI-EN e RU-EN. Dimostriamo quindi che è possibile condividere un unico codificatore a livello di carattere in più lingue formando un modello su un compito di traduzione multi-to-one. In questa impostazione multilingue, l'encoder a livello di caratteri supera significativamente l'encoder a livello di subparola su tutte le coppie linguistiche. Osserviamo che su CS-EN, FI-EN e RU-EN, la qualità della traduzione multilingue a livello di carattere supera addirittura i modelli specificamente formati su quella coppia linguistica, sia in termini di punteggio BLEU che di giudizio umano.", 'kk': "Машин аудару жүйелерінің көпшілігі сөздер деңгейінде жұмыс істейді, белгілерді тарқату үшін таңбаша бөліміне көмектеседі. Біз невралдық компьютердің аудармасын (NMT) үлгісін келтіреміз. Бұл көзі таңбалардың ретін бір белгісіз белгілі таңбалардың ретінде картасын көрсетеді. Біз кодердің көзінің ұзындығын азайту үшін таңбалардың деңгейіндегі қосымша желісін қолданамыз. Бұл үлгі жергілікті үлгіліктерді қалғанда, ішкі сөз деңгейіндегі үлгілерімен салыстыратын жылдамдығымен о Біздің таңбалар мен таңбалар үлгісіміз WMT'15 DE- EN және CS- EN және FI- EN және RU- EN ішкі сөздер деңгейіндегі негізгі жолды жасайды. Кейін біз бірнеше тілдерде бір таңбаның деңгейіндегі кодерді бірнеше тілдерде ортақтастыруға мүмкін екенін көрсету үшін бірнеше түрлендіру тапсырмасының үлгісін оқытуға Бұл көп тілдік параметрлерде, таңбаның деңгейінің кодері тіл екеуінде ішкі сөздің деңгейінің кодерін өзгертеді. Біз CS-EN, FI-EN және RU-EN дегенде бірнеше тіл деңгейіндегі аудармалардың сапасы бір-бірінші тіл екеуінде өзгертілген үлгілерді өзгерте аламыз. БЛЕС нәтижесін және адамдардың оқиғасы қажетті.", 'lt': "Dauguma esamų mašinų vertimo sistemų veikia žodžių lygiu, remdamasi aiškia segmentacija, kad būtų ištraukti ženklai. Įdiegiame neurologinio mašinos vertimo (NMT) model į, kuris žemėlapizuoja šaltinio simbolių seką tikslinio simbolio sekai be jokios segmentacijos. Mes naudojame simbolio lygio konvoliucinį tinklą su maksimaliu susijungimu koduotoje, siekiant sumažinti šaltinio atstovavimo trukmę, kad modelis būtų mokomas greičiu, palyginamu su subžodžio lygio modeliais, tuo pačiu metu nustatant vietinius reguliarumus. Mūsų kiekvieno simbolio modelis pasiekė neseniai pasiūlytą bazinį rodiklį su WMT'15 DE-EN ir CS-EN subžodiniu kodatoriumi, o FI-EN ir RU-EN rezultatai yra panašūs. We then demonstrate that it is possible to share a single character-level encoder across multiple languages by training a model on a many-to-one translation task.  Šiame daugiakalbyje nustatyme simbolių lygio kodatorius žymiai viršija subžodžių lygio kodatorių visoms kalbų poroms. Mes pastebime, kad CS-EN, FI-EN ir RU-EN daugiakalbio vertimo kokybė net viršija modelius, specialiai išmokytus vien tik šioje kalbų poroje, tiek BLEU rezultatų, tiek žmogaus vertinimo požiūriu.", 'mk': "Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens.  Ние воведуваме модел на нервен машински превод (НМТ) кој мапира секвенца на изворни знаци на секвенца на знаци на цел без секвенција. Ние употребуваме конволуционална мрежа на ниво на карактери со максимално обединување на кодерот за да ја намалиме должината на репрезентацијата на изворот, овозможувајќи му на моделот да биде трениран со брзина споредлива со моделите на ниво на подзборови, при што ќе се фатат локални Our character-to-character model outperforms a recently proposed baseline with a subword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable performance on FI-EN and RU-EN.  Потоа демонстрираме дека е можно да се сподели еден кодер на ниво на карактери преку повеќе јазици со обука на модел за превод од многу до еден. Во ова мултијазично поставување, кодерот на нивото на знаци значително го надминува кодерот на нивото на подзборот на сите парови јазици. Ние забележуваме дека на CS-EN, FI-EN и RU-EN квалитетот на преведувањето на повеќејазичното ниво на карактер дури ги надминува моделите специфично обучени само на тој јазик пар, како во поглед на оценката БЛЕУ, така и на човечката пресуда.", 'ms': "Kebanyakan sistem terjemahan mesin yang ada berfungsi pada aras perkataan, bergantung pada segmen eksplicit untuk mengekstrak token. Kami memperkenalkan model terjemahan mesin saraf (NMT) yang memetakan urutan aksara sumber ke urutan aksara sasaran tanpa sebarang segmen. Kami menggunakan rangkaian konvolusi aras-aksara dengan pengumpulan maksimum pada pengekod untuk mengurangkan panjang perwakilan sumber, membolehkan model dilatih dengan kelajuan yang boleh dibandingkan dengan model aras-subkata semasa menangkap regularitas tempatan. Model aksara-kepada-aksara kami melampaui dasar yang baru-baru ini dilaporkan dengan pengekod aras-subkata pada WMT'15 DE-EN dan CS-EN, dan memberikan prestasi yang sama pada FI-EN dan RU-EN. We then demonstrate that it is possible to share a single character-level encoder across multiple languages by training a model on a many-to-one translation task.  Dalam tetapan berbilang bahasa ini, pengekod aras-aksara melampaui pengekod aras-subkata secara signifikan pada semua pasangan bahasa. Kami memperhatikan bahawa pada CS-EN, FI-EN dan RU-EN, kualiti terjemahan-aras aksara berbilang bahasa bahkan melebihi model yang dilatih secara khusus pada pasangan bahasa itu sahaja, kedua-dua dalam terma skor BLEU dan penilaian manusia.", 'ml': "നിലവിലുള്ള യന്ത്രത്തിന്റെ പരിഭാഷ സിസ്റ്റം വാക്കുകളുടെ നിലയില്\u200d പ്രവര്\u200dത്തിക്കുന്നു. ഒട്ടുകള്\u200d പുറത്തെടുക്കാ നമ്മള്\u200d ഒരു ന്യൂറല്\u200d യന്ത്രത്തിന്റെ പരിഭാഷ (NMT) മോഡല്\u200d പരിചയപ്പെടുത്തുന്നു. അത് ഒരു സോര്\u200dസ്സ് അക്ഷരരൂപത്തിന്റെ സെക്കന്\u200dസ് ക്രമത് നിയമങ്ങളെ പിടിക്കുമ്പോള്\u200d സോര്\u200dസ് പ്രതിനിധിയ്ക്കുള്ള നീളം കുറഞ്ഞു കൊടുക്കാന്\u200d ഞങ്ങള്\u200d ഒരു അക്ഷരരൂപത്തിന്റെ നിലപാട് കൂടി കൂടുതല്\u200d കൂടുതല്\u200d കൂടുതല്\u200d കൂടു ഞങ്ങളുടെ അക്ഷരരൂപത്തിലേക്കുള്ള മോഡല്\u200d അടുത്തുള്ള ഒരു പ്രായശ്ചിത്തമായ ബെസ്ലൈനിലേക്ക് പ്രദര്\u200dശിപ്പിക്കുന്നു. WMT'15 DE-EN, CS-EN എന്നിലേക്കുള്ള ഒരു  പിന്നീട് നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് ഒരു സാധ്യതയുള്ള അക്ഷരരൂപത്തിന്റെ നിലവിലുള്ള ഒരു കോഡെര്\u200d പങ്കാളിയാക്കാന ഈ പല ഭാഷ സജ്ജീകരണത്തില്\u200d, അക്ഷരസഞ്ചയത്തിന്റെ അക്ഷരസഞ്ചയം എല്ലാ ഭാഷയിലും സബ്\u200cവോര്\u200dഡ്- നില കോഡെര്\u200d കൂടുതല്\u200d പ്രദര്\u200dശി ഞങ്ങള്\u200d നോക്കുന്നുണ്ട്, CS-EN, FI-EN, RU-EN, multilingual character- level translation-quality, പ്രത്യേകിച്ച് ആ ഭാഷ ജോടിയില്\u200d മാത്രം പഠിപ്പിക്കപ്പെട്ട മോഡലുകള്\u200d പ്രത്യേകിച്ച് മാതൃകങ", 'mt': 'Il-biċċa l-kbira tas-sistemi ta’ traduzzjoni tal-magni eżistenti joperaw fil-livell tal-kliem, u jiddependu fuq segmentazzjoni espliċita biex jiġu estratti t-tokens. Aħna nintroduċu mudell ta’ traduzzjoni tal-magna newrali (NMT) li jimmappa sekwenza ta’ karattri tas-sors għal sekwenza ta’ karattri fil-mira mingħajr ebda segmentazzjoni. Aħna nużaw netwerk konvoluzzjonali fil-livell tal-karattru b’aggregazzjoni massima fil-kodifikatur biex inaqqsu t-tul tar-rappreżentazzjoni tas-sors, li jippermetti li l-mudell jitħarreġ b’veloċità komparabbli mal-mudelli fil-livell tas-subkliem filwaqt li jinqabdu r-regolaritajiet lokali. Il-mudell tagħna karattru b’karattru jaqbeż linja bażi proposta reċentement b’kodifikatur fil-livell ta’ subkliem fuq WMT’15 DE-EN u CS-EN, u jagħti prestazzjoni komparabbli fuq FI-EN u RU-EN. Imbagħad nippruvaw li huwa possibbli li wieħed jaqsam kodifikatur uniku fil-livell tal-karattri f’diversi lingwi billi nħarrġu mudell dwar kompitu ta’ traduzzjoni minn ħafna għal waħda. F’dan is-sett multilingwi, il-kodifikatur tal-livell tal-karattri jaqbeż b’mod sinifikanti l-kodifikatur tal-livell tas-subkelma fuq il-pari kollha tal-lingwi. Aħna ninnota li fis-CS-EN, FI-EN u RU-EN, il-kwalità tat-traduzzjoni fil-livell tal-karattru multilingwi saħansitra taqbeż il-mudelli mħarrġa speċifikament fuq dak il-par lingwistiku waħdu, kemm f’termini tal-punteġġ BLEU kif ukoll f’termini tal-ġudizzju uman.', 'pl': "Większość istniejących systemów tłumaczenia maszynowego działa na poziomie słów, polegając na wyraźnej segmentacji w celu wyodrębnienia tokenów. Wprowadzamy model neuronowego tłumaczenia maszynowego (NMT), który mapuje źródłową sekwencję znaków do docelowej sekwencji znaków bez żadnej segmentacji. Wykorzystujemy sieć konwolucyjną na poziomie znaków z maksymalnym poolingiem w koderze, aby zmniejszyć długość reprezentacji źródła, umożliwiając szkolenie modelu z prędkością porównywalną do modeli na poziomie podsłów, przy jednoczesnym przechwytywaniu lokalnych regularności. Nasz model znaków-znaków przewyższa niedawno proponowaną bazę bazową z koderem na poziomie podsłów na WMT'15 DE-EN i CS-EN oraz zapewnia porównywalną wydajność na FI-EN i RU-EN. Następnie pokazujemy, że możliwe jest współdzielenie jednego kodera na poziomie znaków w wielu językach poprzez szkolenie modelu w zadaniu tłumaczeniowym wiele do jednego. W tym wielojęzycznym ustawieniu koder na poziomie znaków znacznie przewyższa koder na poziomie podsłów we wszystkich parach językowych. Obserwujemy, że w CS-EN, FI-EN i RU-EN jakość wielojęzycznego tłumaczenia na poziomie znaków przewyższa nawet modele specjalnie przeszkolone na tej parze językowej, zarówno pod względem wyniku BLEU, jak i osądu ludzkiego.", 'mn': "Ихэнх оршиж байгаа машины орчуулах систем үгний хэмжээнд ажиллаж, тодорхой хэмжээсүүдийг татаж тайлбарлаж байдаг. Бид мэдрэлийн машины хөгжлийн загвар (NMT) загварыг тайлбарлаж, эх үүсвэрийн тэмдэгтийн дарааллыг зориулагдсан тэмдэгтийн дарааллаар загвар өгдөг. Бид үүсвэрийн загварын уртыг багасгаж, загварыг субдуу хэмжээний загвартай харьцуулах хурдаар субдуу хэмжээний загвартай багасгах боломжтой болгодог. Бидний харилцааны загвар нь саяхан WMT'15 DE-EN, CS-EN дээрх субдуу хэмжээний коддогч болон FI-EN болон RU-EN дээрх харьцуулагдмал үйл ажиллагааг гаргадаг. Дараа нь бид олон хэл дээр нэг харьцаа-түвшин коддогчийг олон хэл дээр хуваалцах боломжтой гэдгийг харуулж байна. Энэ олон хэлний тохиолдолд хариу түвшин коддогч нь бүх хэлний хоёр дээр суб-үг түвшин коддогч нарийвчлагдсан юм. Бид CS-EN, FI-EN, RU-EN дээр олон хэл хэлний хэлбэрийн хөгжлийн чанар нь тэр хэл хоёрын тухай зөвхөн сургалтын загваруудыг зөвхөн өндөр өндөртэй байдаг.", 'no': "Dei fleste eksisterande maskineoversettelsystemene fungerer på ord nivået, ved hjelp av eksplisitt segmentasjon for å pakka ut teikn. Vi introduserer eit neuralmaskinsomsetjingsmodul (NMT) som karterer ei kjeldeteiknkombinasjon til ei målteiknkombinasjon utan noen segmentasjon. Vi brukar eit konvolusjonell nettverk med maksimal samlingar på koderen for å redusera lengden på kjelderepresentasjonen, slik at modellen skal trenjast på ein fart som er samanlikbar med underordnivåmodeller mens du hentar lokale reguleringar. Vårt teikn-til-teikn-modell utfører ei nyleg foreslått baseline med ein underordnivåkoder på WMT'15 DE-EN og CS-EN, og gir sammenlignbare utvikling på FI-EN og RU-EN. Vi viser derfor at det er mogleg å dele eit enkelt teiknkoder på fleire språk ved å trenga eit modell på ei mange til ein oversettelsoppgåve. I denne fleirspråksinnstillinga utfører teiknkodinga signifikante over underordnivåkoderen på alle språkopla. Vi observerer at på CS-EN, FI-EN og RU-EN kvaliteten til fleirspråksnivåomsetjinga overpassar sjølv modellen som er spesifikke trent på den språksparen alene, både i høve til BLEU-poeng og menneske uttrykk.", 'ro': "Majoritatea sistemelor de traducere automată existente funcționează la nivelul cuvintelor, bazându-se pe segmentarea explicită pentru extragerea jetoanelor. Introducem un model de traducere automată neurală (NMT) care cartografiază o secvență de caractere sursă la o secvență de caractere țintă fără nicio segmentare. Utilizăm o rețea convoluțională la nivel de caractere cu max-pooling la encoder pentru a reduce lungimea reprezentării sursei, permițând modelului să fie instruit la o viteză comparabilă cu modelele la nivel de subcuvânt, capturând în același timp regularitatea locală. Modelul nostru caracter-la-caracter depășește o bază de referință propusă recent cu un codificator la nivel de subcuvânt pe WMT'15 DE-EN și CS-EN și oferă performanțe comparabile pe FI-EN și RU-EN. Apoi demonstrăm că este posibil să partajați un singur codificator la nivel de caractere în mai multe limbi prin instruirea unui model pentru o sarcină de traducere multi-to-one. În această setare multilingvă, encoderul la nivel de caractere depășește semnificativ encoderul la nivel de subcuvânt pe toate perechile de limbi. Observăm că în CS-EN, FI-EN și RU-EN, calitatea traducerii multilingve la nivel de caracter depășește chiar modelele instruite în mod specific numai pentru acea pereche de limbi, atât în ceea ce privește scorul BLEU, cât și judecata umană.", 'sr': "Najvećina postojećih sistema prevoda mašine funkcioniše na nivou reči, oslanjajući se na pojasnu segmentaciju da izvuče znakove. Predstavljamo model neuralne mašine prevode (NMT), koji mapira sekvenciju izvornog karaktera ciljnom sekvencijom karaktera bez ikakve segmentacije. Koristimo konvolucionu mrežu na nivou karaktera sa maksimalnim skupljanjem na koderu kako bi smanjili dužinu predstavljanja izvora, omogućavajući da model bude obučen brzinom u usporedbi sa modelima podrečenih nivoa dok uhvate lokalne regularitete. Naš model karaktera do karaktera iznosi nedavno predloženu početnu liniju sa koderom podriječja na WMT'15 DE-EN i CS-EN, i daje usporedno izvršenje FI-EN i RU-EN. Onda pokazujemo da je moguće podeliti jedan koder na nivou karaktera na višestrukim jezicima, obučavajući model na jednom prevodnom zadatku. U ovom multijezičkom nastavku koder nivoa karaktera značajno iznosi koder nivoa podriječi na svim jezičkim parovima. Primećujemo da na CS-EN, FI-EN i RU-EN kvaliteta multijezičkog prevoda na nivou karaktera čak i nadmaže modele posebno obučene samo na tom jezičkom par, kako u smislu BLEU rezultata i ljudskog sudjenja.", 'so': "Inta badan nidaamka turjumidda mashiinka ah waxay ku shaqeeyaan heerka hadalka, waxay ku kalsoonaan yihiin qeyb cad si ay calaamado u soo saaraan. Waxaynu soo bandhignaynaa muusikada tarjumaadda neural machine (NMT) oo ku sawiraa xarafta farsamada oo ku qoran xarafta waxyaabaha la'aanta. Waxaynu u shaqaynaynaa shabakad heer ka mid ah oo aad u baahan tahay si aan ugu hoosaystiro tirada nooc, waxaana ku raadsan kara qaababka in loo baro si dhaqso u eg samooyinka heerka hoose-hadalka marka aad qabsato qaynuunnada deegaanka. Tusaale-to-character ayaa ka muuqata qoraal-hoos-word codder oo ku qoran WMT'15 DE-EN iyo CS-EN, wuxuuna sameeyaa muuqasho u eg FI-EN iyo RU-EN. Markaas waxaynu muujinnaa in waxaa suurtogal ah in aad qeyb ka dhigto heer isku mid ah oo luuqado kala duduwan lagu barto model ah oo lagu sameynayo shaqada turjumista. Isku qoran qoraalka luuqadaha kala duduwan, heerka aqoonta ayaa si weyn ugu muujiya kooxda qoraalka hoose ee ku qoran labada luqadood oo dhan. Waxaynu fiirinaynaa in hoosta CS-EN, FI-EN iyo RU-EN, takhastiga tarjumaadka heerka luuqadaha kala duduwan xittaa uu koobi karo qaababka lagu baray labada labood oo kaliya ee luqada BLEU scorta iyo xukunka biniaadaba.", 'sv': "De flesta befintliga maskin철vers채ttningssystem fungerar p책 ordniv책 och f철rlitar sig p책 explicit segmentering f철r att extrahera tokens. Vi introducerar en neural maskin철vers채ttning (NMT) modell som kartl채gger en k채llteckensekvens till en m책lteckensekvens utan segmentering. Vi anv채nder ett konvulutionsn채tverk p책 teckeniv책 med max-pooling vid kodaren f철r att minska l채ngden p책 k채llrepresentation, vilket g철r det m철jligt f철r modellen att utbildas med en hastighet som 채r j채mf철rbar med underordsmodeller samtidigt som den f책ngar lokala regelbundenhet. V책r karakt채r-till-tecken-modell 철vertr채ffar en nyligen f철reslagen baslinje med en kodare p책 underordsniv책 p책 WMT'15 DE-EN och CS-EN, och ger j채mf철rbar prestanda p책 FI-EN och RU-EN. Sedan visar vi att det 채r m철jligt att dela en enda teckeniv책 kodare 철ver flera spr책k genom att tr채na en modell p책 en m책nga-till-en 철vers채ttningsuppgift. I den h채r flerspr책kiga inst채llningen 철vertr채ffar kodaren p책 teckeniv책 kodaren betydligt kodaren p책 underordsniv책 p책 alla spr책kpar. Vi konstaterar att p책 CS-EN, FI-EN och RU-EN 철vertr채ffar kvaliteten p책 den flerspr책kiga 철vers채ttningen till och med de modeller som 채r s채rskilt utbildade p책 enbart detta spr책kpar, b책de n채r det g채ller BLEU-po채ng och m채nsklig bed철mning.", 'si': "ගොඩක් අවස්ථානයේ පද්ධතිය පද්ධතිය පද්ධතිය වචන ස්ථානයෙන් වැඩ කරන්න, පැහැදිලි විශේෂ විශේෂයෙන අපි න්\u200dයූරාල් මැෂින් පරිවර්තනය (NMT) නිර්මාණයක් පෙන්වන්න පුළුවන් අක්ෂර පරිවර්තනයක් ලක්ෂ අක්ෂර පර අපි අක්ෂර-තත්වය සම්පූර්ණ ජාලයෙක් භාවිතා කරනවා ස්ථානික සාමාන්\u200dය විදියට පරීක්ෂණය කරන්න, ස්ථානික සාමාන්\u200dය විදියට පරීක්ෂණය කරන්න පුළුව අපේ අක්ෂර ප්\u200dරතිකාරයෙන් අක්ෂර ප්\u200dරතිකාරය ප්\u200dරතිකාරයක් ප්\u200dරතිකාරය කරන්නේ WMT'15 DE-ENE සහ CS-ENE සඳහා අක්ෂර ප්\u200dරතිකාරයෙන් ප්\u200dරතිකාරයෙන් ප්\u200d ඊට පස්සේ අපි පෙන්වන්න පුළුවන් විදිහට විශේෂයෙන් විශේෂ භාෂාවක් වලින් එකක් අක්ෂර ප්\u200dරතිකාරකයෙක් බෙදාග මේ බොහොම භාෂාවක් සැකසුමේදී, අක්ෂර- ස්තූතිය සංකේතකය සාමාන්\u200dය භාෂාවක් සම්පූර්ණයෙන් සබ්වර්ඩ- ස් අපි බලාපොරොත්තු කරනවා කියලා, CS-ENE, FI-ENE සහ RU-ENE වලින්, විශේෂ භාෂාවක් වලින් විශේෂ පරිවර්තනය සහ මිනිස්සු විශේෂ විශේෂයෙන් අර භ", 'ta': "பெரும்பாலான இருக்கும் இயந்திர மொழிமாற்று அமைப்புகள் சொல்லின் நிலையில் செயல்படுகிறது, வெளிப்படையான துண்டு நாம் ஒரு புதிய மொழி மொழிபெயர்ப்பு (NMT) மாதிரி முறைமையை குறிப்பிடுகிறோம். இது மூல எழுத்து வரிசையில் ஒரு இலக்கு எழுத்து வரிசை நாம் ஒரு எழுத்து- மட்டத்தில் சாதாரண வலைப்பின்னலை குறியீட்டில் அதிகபட்ச குறியீட்டில் உள்ள விதிமுறைகளை குறைக்கும் போது பயிற்சி செய்ய அனுமதிக்கிறோம். எங்கள் எழுத்து எழுத்து மாதிரி சமீபத்தில் முன்நிர்ணயிக்கப்பட்ட அடிப்பகுதியை வெளியிடுகிறது WMT'15 DE-EN மற்றும் CS-EN மீது ஒரு துணை நிலைகுறியீட்டை கொண் We then demonstrate that it is possible to share a single character-level encoder across multiple languages by training a model on a many-to-one translation task.  இந்த பல மொழி அமைப்பில், எழுத்து- மட்டத்தின் குறியீடு முக்கியமாக அனைத்து மொழி ஜோடி நாம் CS-EN, FI-EN மற்றும் RU-EN, பல மொழி எழுத்து மட்டத்தின் தரம், அந்த மொழி ஜோடி மட்டும் பயிற்சிக்கப்பட்ட மாதிரிகளை மாற்றுகிறோம், BLEU மதிப்பு மற்றும் மனித நி", 'ur': "بہت سے موجود ماشین ترجمہ سیسٹم کلمات کے سطح پر کام کرتی ہیں، کھول کھول کھول کھول جانے کے لئے ٹوکنوں کو استعمال کرتی ہیں. ہم ایک نئورل ماشین ترجمہ (NMT) موڈل کو معرفی کرتے ہیں جو کسی سیگنٹ کے بغیر کسی موجود شخصت کی ترجمہ کے ساتھ موجود کرتا ہے۔ ہم ایک شخص-سطح کانلوریشن نیٹ ورک کا استعمال کرتے ہیں جو کوڈر میں سب سے زیادہ پولینگ کے ساتھ استعمال کرتا ہے کہ سورج کی روشنی کی لمبی کم کرے، اور موڈل کو ایک سرعت کے ذریعہ تطالب کرنا چاہتے ہیں جو سوبرویڈ-سطح موڈل کے مطابق مطابق ہے جبکہ ہمارا شخص-to-character Model ایک اخیر پیشنهاد بنسلین کے ساتھ WMT'15 DE-EN اور CS-EN پر ایک سوبرویڈ سطح کا کوڈر کرتا ہے اور FI-EN اور RU-EN پر برابری کرتا ہے. پھر ہم دکھاتے ہیں کہ ایک شخص سطح کا اکنور کرنا ممکن ہے کئی زبانوں میں ایک نمڈل کی تعلیم کے ذریعہ ایک شخص کے سطح کا اکنور کرنا۔ یہ بہت سی زبان تنظیمات میں، Character-level encoder بہت اضافہ ہے کہ تمام زبان جوڑوں پر subword-level encoder کرتا ہے. ہم دیکھتے ہیں کہ CS-EN, FI-EN اور RU-EN پر multilingual character-level ترجمہ کی کیفیت صرف اس زبان جوڑے پر استعمال کی مدلکوں سے زیادہ زیادہ گزر جاتی ہے، دونوں BLEU score اور انسان فیصلہ کے مطابق.", 'uz': "Name Biz bir tarjima qilish modelini (NMT) koʻrsatimiz. Bu yerda hech qanday bogʻlash yoʻq, manba belgi chegarasining chegarasini koʻrsatish mumkin. Biz murakkab tarmoqni foydalanamiz, maksimal manbaning representisini kamaytirish uchun kodlash orqali ishlayapmiz. Name Biz belgilangan modelimiz yaqinda yaqinlangan soʻzni WMT'15 DE-EN va CS-EN bilan bir tub soʻzning kodlash usuli bilan ishlatiladi va FI-EN va RU-EN bilan mos keladigan amalni bajaradi. Keyin biz bir necha tillar orqali bir necha tillar bilan bitta tarjima qilish modelini o'rganish mumkin. Ushbu bir nechta tilda, harf- darajasi kodlash usuli hamma tillar qoʻllangan subword- darajasi kodlash usulini aniqlaydi. Biz CS-EN, FI-EN va RU-EN bilan ko'pchilik harf darajasi tarjima sifatida o'rganish modellarini faqat o'sha tillar qo'l bilan o'rganish modellarini ko'proq o'zgartiradi, BLEU scorning va odamning xususiyatlarida.", 'vi': "Hầu hết các hệ thống dịch chuyển máy đã có hoạt động ở mức chữ, dựa vào sự phân đoạn rõ ràng để trích các thẻ. Chúng tôi giới thiệu một mô hình dịch cỗ máy thần kinh (NMB) để bản đồ một chuỗi ký tự gốc tới một chuỗi ký tự đích mà không cần phân biệt. Chúng tôi sử dụng một mạng lưới kết cấu cung cấp ký tự với Max-pool tại bộ mã hóa để giảm độ dài của sự mô tả nguồn, cho phép mô hình được huấn luyện với tốc độ tương đương với mô hình dạng dạng dạng dưới từ, trong khi đo được các quy tắc địa phương. Cách mô hình giữa cá nhân chúng ta hoàn thành một thiết lập vừa được đề xuất với một mã hóa cấp chữ phụ trên WRT'15 de-GEN và CS-en, và cho kết quả tương xứng với với điều đó trên AF-GEN. Sau đó chúng tôi chứng minh rằng có thể chia sẻ một bộ mã hóa đơn cấp ký tự qua nhiều ngôn ngữ bằng cách huấn luyện một mô hình về một nhiệm vụ dịch chuyển nhiều đến một. Trong thiết lập đa dạng, bộ mã hóa cấp ký tự thực hiện đáng kể mã hóa cấp dưới trên tất cả các cặp ngôn ngữ. Chúng tôi nhận thấy trên CS-en, fi-en và Ru-en, chất lượng của bản dịch đa dạng con người thậm chí còn vượt trội các mô hình được đào tạo riêng về cặp ngôn ngữ đó, cả về tỉ số người và giá trị của người máy.", 'bg': "Повечето съществуващи системи за машинен превод работят на ниво думи, разчитайки на изрична сегментация за извличане на символи. Въвеждаме модел на невронен машинен превод (НМТ), който картографира последователността на изходните знаци към целевата последователност на знаците без сегментация. Използваме конволюционна мрежа на ниво символ с максимално обединяване на кодера, за да намалим дължината на представянето на източника, позволявайки моделът да бъде обучен със скорост, сравнима с моделите на ниво поддума, като същевременно улавяме локални редовности. Нашият модел символ-символ превъзхожда наскоро предложената базова база с кодер на ниво поддума на WMT'15 DE-EN и CS-EN и дава сравними показатели на FI-EN и RU-EN. След това демонстрираме, че е възможно да се сподели един кодер на ниво символ на няколко езика чрез обучение на модел за превод от много към едно. В тази многоезична настройка кодерът на ниво знаци значително превъзхожда кодера на ниво поддума във всички езикови двойки. Наблюдаваме, че при CS-EN, FI-EN и RU-EN качеството на многоезичния превод на ниво символи дори надминава моделите, специално обучени само за тази езикова двойка, както по отношение на оценката на BLEU, така и по отношение на човешката преценка.", 'da': "De fleste eksisterende maskinoversættelsessystemer fungerer på ordniveau og er afhængige af eksplicit segmentering for at udtrække tokens. Vi introducerer en neural maskinoversættelsesmodel (NMT), der kortlægger en kildekontraktsekvens til en målsekvens uden segmentering. Vi anvender et konvulutivt netværk på tegneniveau med maks-pooling ved encoderen for at reducere længden af kilderepræsentation, så modellen kan trænes med en hastighed, der kan sammenlignes med underordsniveau modeller, samtidig med at den registrerer lokale regelmæssigheder. Vores tegn-til-tegn model overgår en nyligt foreslået baseline med en koder på underordsniveau på WMT'15 DE-EN og CS-EN og giver sammenlignelig ydeevne på FI-EN og RU-EN. Vi demonstrerer derefter, at det er muligt at dele en enkelt koder på tegneniveau på tværs af flere sprog ved at træne en model på en mange-til-én oversættelsesopgave. I denne flersprogede indstilling overstiger koderen på tegnniveau koderen betydeligt koderen på underordsniveau på alle sprogpar. Vi bemærker, at kvaliteten af den flersprogede oversættelse på karakterniveau på CS-EN, FI-EN og RU-EN endog overgår de modeller, der er specielt uddannet på dette sprogpar alene, både med hensyn til BLEU-score og menneskelig dømmekraft.", 'nl': "De meeste bestaande systemen voor machinevertaling werken op woordniveau en vertrouwen op expliciete segmentatie om tokens te extraheren. We introduceren een neural machine translation (NMT) model dat een brontekenreeks toewijst aan een doeltekenreeks zonder enige segmentatie. We maken gebruik van een convolutioneel netwerk op karakterniveau met max-pooling bij de encoder om de lengte van bronrepresentatie te verminderen, waardoor het model kan worden getraind met een snelheid vergelijkbaar met subwoordmodellen terwijl lokale regelmatigheden worden vastgelegd. Ons teken-tot-teken model overtreft een recent voorgestelde baseline met een subwoord-niveau encoder op WMT'15 DE-EN en CS-EN, en levert vergelijkbare prestaties op FI-EN en RU-EN. Vervolgens tonen we aan dat het mogelijk is om een enkele tekenniveau encoder in meerdere talen te delen door een model te trainen op een veel-op-één vertaaltaak. In deze meertalige instelling presteert de coder op tekenniveau aanzienlijk beter dan de coder op subwoordniveau op alle taalparen. We zien dat op CS-EN, FI-EN en RU-EN de kwaliteit van de meertalige vertaling op karakterniveau zelfs de modellen overtreft die specifiek op dat taalpaar zijn getraind, zowel wat betreft de BLEU-score als het menselijk oordeel.", 'de': "Die meisten bestehenden maschinellen Übersetzungssysteme arbeiten auf Wortebene und setzen auf explizite Segmentierung, um Token zu extrahieren. Wir führen ein neuronales maschinelles Übersetzungsmodell (NMT) ein, das eine Quellzeichenfolge ohne Segmentierung einer Zielzeichenfolge zuordnet. Wir verwenden ein Faltungsnetzwerk auf Zeichenebene mit Max-Pooling am Encoder, um die Länge der Quelldarstellung zu reduzieren, so dass das Modell mit einer Geschwindigkeit trainiert werden kann, die mit Subword-Level-Modellen vergleichbar ist, während lokale Regelmäßigkeiten erfasst werden. Unser Zeichen-zu-Zeichen-Modell übertrifft eine kürzlich vorgeschlagene Baseline mit einem Subword-Level-Encoder auf WMT'15 DE-EN und CS-EN und bietet vergleichbare Leistung auf FI-EN und RU-EN. Anschließend zeigen wir, dass es möglich ist, einen einzigen Zeichenkodierer über mehrere Sprachen hinweg zu nutzen, indem wir ein Modell für eine Viel-zu-Eins-Übersetzungsaufgabe trainieren. In dieser mehrsprachigen Einstellung übertrifft der Kodierer auf Zeichenebene den Kodierer auf Unterwortebene bei allen Sprachpaaren deutlich. Wir beobachten, dass bei CS-EN, FI-EN und RU-EN die Qualität der mehrsprachigen Übersetzung auf Zeichenebene sogar die Modelle übertrifft, die speziell für dieses Sprachpaar trainiert wurden, sowohl in Bezug auf den BLEU-Score als auch auf das menschliche Urteil.", 'id': "Kebanyakan sistem terjemahan mesin yang ada beroperasi pada tingkat kata, bergantung pada segmen eksplisit untuk mengekstrak token. Kami memperkenalkan model terjemahan mesin saraf (NMT) yang memetakan urutan karakter sumber ke urutan karakter sasaran tanpa segmentasi apapun. Kami menggunakan jaringan konvolusi tingkat karakter dengan pengumpulan maksimum di pengekoder untuk mengurangi panjang representation sumber, memungkinkan model untuk dilatih dengan kecepatan yang dapat dibandingkan dengan model tingkat subword sementara menangkap regularitas lokal. Model karakter-ke-karakter kami melampaui batas dasar yang baru-baru ini diusulkan dengan pengekode tingkat-subword di WMT'15 DE-EN dan CS-EN, dan memberikan prestasi yang sama pada FI-EN dan RU-EN. Kemudian kami menunjukkan bahwa mungkin untuk berbagi satu pengekode tingkat karakter melalui berbagai bahasa dengan melatih model pada tugas terjemahan berbagai-satu. Dalam pengaturan berbilang bahasa ini, pengekode tingkat karakter jauh lebih besar dari pengekode tingkat subkata pada semua pasangan bahasa. Kami memperhatikan bahwa pada CS-EN, FI-EN dan RU-EN, kualitas terjemahan karakter-tingkat berbagai bahasa bahkan melebihi model yang secara khusus dilatih pada pasangan bahasa itu sendiri, baik dalam terma skor BLEU dan penghakiman manusia.", 'hr': "Većina postojećih sustava prevoda stroja funkcionira na razini riječi, oslanjajući se na objašnjenje segmentacije da izvuče znakove. Predstavljamo model prevoda neuralnih strojeva (NMT), koji mapira sekvenciju izvornog karaktera ciljnom sekvencijom karaktera bez ikakve segmentacije. Koristimo konvolucionu mrežu na nivou karaktera s maksimalnim skupljanjem na koderu kako bi smanjili dužinu predstavljanja izvora, omogućavajući da model bude obučen brzinom usporednom s modelima podriječja razine dok se uhvate lokalne regularne redovitosti. Naš model karaktera do karaktera iznosi nedavno predloženu početnu liniju s koderom podriječja na WMT'15 DE-EN i CS-EN, i daje usporedno izvršenje FI-EN i RU-EN. Onda pokazujemo da je moguće dijeliti jednog kodera na nivou karaktera na višestrukim jezicima vježbamo model na jednom prevodnom zadatku. U ovom multijezičkom nastavku koder nivoa karaktera značajno iznosi koder nivoa podriječja na svim jezičkim parovima. Primjećujemo da na CS-EN, FI-EN i RU-EN kvaliteta prevoda na razini višejezičkih karaktera čak i nadmaže modele posebno obučene samo na tom jezičkom parovu, kako u smislu BLEU rezultata i ljudskog sudjenja.", 'ko': "대부분의 기존의 기계 번역 시스템은 모두 단어의 차원에서 운행되고 현식 절분에 의존하여 표기를 추출한다.우리는 소스 문자 서열을 대상 문자 서열에 비추어 분할할 필요가 없는 신경기계번역(NMT) 모델을 소개했다.우리는 문자급 볼륨 네트워크를 사용하여 인코더에 최대 탱크를 사용하여 원본의 표시 길이를 줄이고, 자자급 모델과 비슷한 속도로 모델을 훈련할 수 있으며, 동시에 국부 규칙을 포착할 수 있다.우리의 문자 대조 문자 모델은 최근에 제기된 기선보다 우수하여 WMT'15 DE-EN과 CS-EN에 하위 문자급 인코더를 사용하고 FI-EN과 RU-EN에 상당한 성능을 제공하였다.그리고 우리는 다대일 번역 임무에서 훈련 모델을 통해 다양한 언어에서 단일 문자급 인코더를 공유하는 것이 가능하다는 것을 증명했다.이런 다중 언어 설정에서 문자급 인코더는 모든 언어의 대조에서 자자급 인코더보다 현저히 우수하다.CS-EN, FI-EN, RU-EN에서 다국어 문자급 번역의 질은 해당 언어만 전문적으로 훈련하는 모델을 넘어섰고 BLEU 점수든 인간의 판단이든 상관없다는 것을 관찰했다.", 'fa': "بیشترین سیستم\u200cهای ترجمه ماشین موجود در سطح کلمات کار می\u200cکنند، بر جدایی مشخص برای خروج نشانه\u200cها اعتماد می\u200cکنند. ما یک مدل ترجمه ماشین عصبی (NMT) را معرفی می\u200cکنیم که یک رده شخصیت منبع را به یک رده شخصیت هدف بدون هیچ جدایی نقشه می\u200cدهد. ما شبکه\u200cای از سطح شخصیت\u200cها را استفاده می\u200cکنیم که با مجموعه\u200cهای بزرگترین مجموعه در کوردر است تا طول نمایش منبع را کاهش دهیم، که اجازه می\u200cدهد مدل را با سرعتی که قابل مقایسه با مدل\u200cهای سطح زیر کلمه\u200cها در زمان گرفتن قانونی\u200cهای محلی آموزش شود. مدل شخصیت به شخصیت\u200cهای ما در اخیراً یک خط بنیادی پیشنهاد داده شده با یک رمز\u200cکننده\u200cی سطح زیر کلمه بر WMT'15 DE-EN و CS-EN را اجرا می\u200cکند و اجرا قابل مقایسه روی FI-EN و RU-EN را می\u200cدهد. سپس نشان می دهیم که ممکن است یک قالب رمز شخصیت را در زبان\u200cهای متعدد با آموزش یک مدل در یک کار ترجمه\u200cی بسیاری به یک تک تقسیم کنیم. در این تنظیم بسیاری از زبان\u200cهای زبان، رمزگار سطح شخصیت به طور معنی رمزگار سطح زیر کلمه بر همه جفت زبان\u200cها بیشتر است. ما مشاهده می\u200cکنیم که در CS-EN, FI-EN و RU-EN، کیفیت ترجمه\u200cهای طبقه\u200cی زیادی زبان\u200cها حتی از مدل\u200cهای ویژه\u200cای که تنها روی آن جفت زبان آموزش داده شده\u200cاند، به عنوان امتیاز BLEU و فیصله\u200cهای انسان بیشتر است.", 'sw': "Mfumo wa utafsiri wa mashine uliopo unafanya kazi kwa kiwango cha maneno, wanategemea utofauti wa wazi ili kuondoa alama. Tunaonyesha muundo wa kutafsiri mashine ya kidini (NMT) unaoandika mfululizo wa kituo cha msingi kwa mfululizo wa wahusika bila utaratibu wowote. Tunaweza kutumia mtandao wa kiwango cha mhusika wa kiwango kikubwa na kuongezeka kwa kiwango kikubwa kwa ajili ya kupunguza kiwango cha uwakilishi wa vyanzo, na kuiruhusu mtindo wa mafunzo kwa kiwango kinachofanana na mifano ya kiwango cha chini ya maneno wakati wakitafuta utawala wa mitandao ya eneo hilo. Mfano wetu wa mhusika na wahusika unaonyesha msingi wa hivi karibuni unapendekezwa na kodi ya kiwango cha chini cha maneno juu ya WMT'15 DE-EN na CS-EN, na inatoa ufanisi uliofanana na FI-EN na RU-EN. Kisha tunaonyesha kwamba inawezekana kushirikisha kodi ya kiwango cha tabia moja katika lugha mbalimbali kwa kufundisha muundo katika kazi ya kutafsiri moja kwa moja. Katika mazingira haya ya lugha mbalimbali, kodi la kiwango cha wahusika kinaonyesha utaratibu wa kiwango cha chini wa lugha katika jingine zote za lugha. Tunaona kwamba katika CS-EN, FI-EN na RU-EN, ubora wa tafsiri ya kiwango cha lugha mbalimbali hata huvuka mifano yenye mafunzo ya lugha hiyo peke yake, kwa namna ya vipindi vya BLEU na hukumu ya binadamu.", 'tr': "Iň köp bar maşynyň terjime sistemleri sözleriň derejesinde işleýär. Çikgi baglaýyşlary açmak üçin paýlaşýar. Biz näral maşynyň terjimesini (NMT) nusgasyna girdirýäris ki bu çeşme karakterlerniň dizini hiç hili bir segmentasiz gaýd etmelidir. Biz ködlemeleri taýýarlamak üçin karakter derejesi konvolwasyonal şebekeni ködlerde azaltýarys. Bu modeli ýerleri düzgün derejesi yakarken subsöz derejesi modellerine karşılaşyk bilen täzeleştirilýär. Biziň karakterlerimiz nusgasymyz WMT'15 DE-EN we CS-EN üstünde ýakynlaşykly hereket edip FI-EN we RU-EN üstünde gollaşykly bir üssüň çizgisini çykar. Sonra bir karakter ködlerini birnäçe dilde bir ködleme taýýarlamak mümkin diýip görkezip bileris. Bu köp dilli düzümlerde, karakter-derejesi kodçysynyň bütin dil çiftliklerinde ýeterlik edip bilmedi. Biz CS-EN, FI-EN we RU-EN, multi-dil karakter derejesiniň kalitesinde hatda bu dil çiftinde edil özellikle bilinmiş nusgalardan hem BLEU netijesinde we adamlaryň hökmünde öräni ýok edip bilýäris.", 'af': "Die meeste bestaande masjien vertalingsstelsels werk by die vlak van woorde, verwag op eksplisiese segmentasie om tekens te uitpak. Ons introduseer 'n neurale masjien vertaling (NMT) model wat 'n bron karakter sekwensie kaart na' n doel karakter sekwensie sonder enige segmentasie. Ons gebruik 'n karaktervlak konvolusionele netwerk met maksimum-pooling by die enkoder om die lengte van bron voorstelling te reduseer, toelaat die model op 'n spoed vergelykbaar word met subwoord-vlak modele terwyl plaaslike regulariseite opgeneem word. Ons karakter-na-karaktermodel uitvoer 'n onlangs voorgestelde basislien met 'n subwoord-vlak enkoder op WMT'15 DE-EN en CS-EN, en gee vergelykbare prestasie op FI-EN en RU-EN. Ons wys dan dat dit moontlik is om 'n enkele karaktervlak-koder te deel oor veelvuldige tale deur 'n model op 'n baie na-een vertaling taak te onderwerp. In hierdie multitaalske instelling, die karaktervlak-enkoder betekenlik uitvoer die subwoord-vlak-enkoder op alle taal pare. Ons bewaar dat op CS-EN, FI-EN en RU-EN, die kwaliteit van die multitaalse karaktervlak-oorsetting selfs die modele wat spesifieke opgelei is op daardie taal paar alleen, beide in terms van die BLEU-aantal en menslike oordeel.", 'sq': "Shumica e sistemeve ekzistuese të përkthimit të makinave funksionojnë në nivelin e fjalëve, duke u mbështetur në segmentimin eksplicit për të nxjerrë tokens. We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any segmentation.  Ne përdorim një rrjet konvolutiv të nivelit të karakterit me bashkimin maksimum në koduesin për të reduktuar gjatësinë e përfaqësimit të burimit, duke lejuar modelin të trajnohet me një shpejtësi të krahasueshme me modelet e nivelit të nënfjalëve ndërsa kapin rregullalitetet lokale. Our character-to-character model outperforms a recently proposed baseline with a subword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable performance on FI-EN and RU-EN.  Pastaj demonstrojmë se është e mundur të ndahemi një kodues të vetëm në nivelin e karakterit nëpërmjet gjuhëve të shumta duke trajnuar një model në një detyrë përkthimi shumë-në-një. Në këtë vendosje shumëgjuhëse, koduesi i nivelit të karaktereve ekziston ndjeshëm më shumë se koduesi i nivelit të nënfjalëve në të gjitha çiftet e gjuhës. Ne vëzhgojmë se në CS-EN, FI-EN dhe RU-EN, cilësia e përkthimit të nivelit të karakterit shumëgjuhës madje tejkalon modelet specifikisht të trajnuar vetëm në atë çift gjuhësh, si në lidhje me rezultatin BLEU-së dhe gjykimin njerëzor.", 'am': 'Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens.  የናቡር መሣሪያን ትርጉም (NMT) ሞዴል እናስታውቃለን፡፡ የሥርዓት ሥርዓቶችን በመያዝ በተቃራኒ ቃላት ማስተካከል እናስፈልጋለን፡፡ የፊደል ቅርጽ-ወደ-ፊደል ምሳሌ በቅርብ ጊዜ በWMT-15 DE-EN እና CS-EN ላይ የደብዳቤ-ደረጃ የኮድ ክፈት ይደረጋል፡፡ ከዚያም በኋላ አንድ የፊደል-ደረጃ ኮድዶችን በብዙ ቋንቋዎች ላይ ማሳየት እናስታውቃለን፡፡ በዚህ በቋንቋ አቋራጭ ውስጥ የፊደል-ደረጃ ኮድ በሙሉ ቋንቋ ዓይነቶች ሁሉ ላይ የደብዳቤ-ደረጃ የፊደል ኮድ አግኝቷል። በCS-EN፣ FI-EN እና RU-EN፣ የብልቋንቋ-ቋንቋ-ደረጃ ትርጉም ብዛት፣ ለዚህ ቋንቋ ለብቻው የተጠቃሚ ሁለቶችን፣ BLEU score እና በሰው ፍርድ ላይ በተለየ ሙላትን እንጨምራለን፡፡', 'hy': "Գոյություն ունի մեքենայի թարգմանման համակարգերի մեծ մասը գործում է բառերի մակարդակում, հիմնվելով բացատրական սեգմետրացիաների վրա՝ նշաններ հանելու համար: Մենք ներկայացնում ենք նյարդային մեքենայի թարգմանման (NMT) մոդել, որը քարտեզագրում է աղբյուր բնորոշների հաջորդականությունը նպատակային բնորոշների հաջորդականության առանց որևէ սեգմետրացիայի: Մենք օգտագործում ենք բնավորության մակարդակի կոնվոլյուցիոն ցանց, որտեղ կոդավորվում է մաքսային հավաքածությունը, որպեսզի նվազեցնենք աղբյուրի ներկայացման երկարությունը, թույլ տալով, որ մոդելը սովորեցվի առանբառերի մակարդակի մոդելների հետ համեմատական արա Մեր բնավոր-բնավոր մոդելը արտադրում է վերջերս առաջարկված հիմքային արտահայտությունը, որն ունի ենթաբառի մակարդակի կոդեր, որը տեղադրվում է ՎՄԹ'15 ԴԵ-Է և CS-Է վրա, և տալիս է համեմատական արտահայտություն ՖԻ-Է և Այնուհետև մենք ցույց ենք տալիս, որ հնարավոր է բազմաթիվ լեզուներում կիսվել մեկ բնավորության մակարդակի կոդերով՝ վարժեցնելով մի մոդել բազմաթիվ մեկի թարգմանման խնդրի վրա: Այս բազլեզու սահմանափակում բնավորության մակարդակի կոդերը նշանակալիորեն գերազանցում է բոլոր լեզվի զույգերի ենթաբառերի մակարդակի կոդերը: Մենք նկատում ենք, որ CS-en, FI-en և RU-en-ում բազմալեզու բնավորության մակարդակի թարգմանման որակը նույնիսկ գերազանցում է միայն այդ լեզվի զույգի վրա մասնավորապես վարժեցված մոդելներին, ինչպիսիք են ԲԼԵՎ գնահատականը և մարդկային դատողությունը:", 'bn': 'বেশীরভাগ বিদ্যমান মেশিন অনুবাদ সিস্টেম শব্দের স্তরে কাজ করে, স্পষ্ট বিভাগের উপর নির্ভর করে চিহ্নিত করার জন্য। আমরা একটি নিউরেল মেশিন অনুবাদ (এনএমটি) মডেল পরিচয় করিয়ে দিচ্ছি যা কোন বিভাগ ছাড়াই একটি সোর্স অক্ষরের সেকেন্সের মানচিত্রে একটি লক্ষ স্থানীয় নিয়ম গ্রহণের সময় সাবওয়ার্ড-স্তরের মডেলের সাথে তুলনায় আমরা একটি চরিত্র-স্তরের বিশ্বাসযোগ্য নেটওয়ার্ক ব্যবহার করি স্থানীয় নিয়ম গ্রহণ করার জন্য কো আমাদের চরিত্র-থেকে চরিত্রের মডেল সম্প্রতি প্রস্তাবিত বেসার্লাইনের সাবওয়ার্ড-স্তরের একটি সাবওয়ার্ড-এনকোডারের সাথে প্রস্তাব করেছে এবং এফআই-এন এবং RU-EN-এ তারপর আমরা প্রদর্শন করি যে অনেক-থেকে এক অনুবাদ কাজে একটি মডেল প্রশিক্ষণের মাধ্যমে একটি অক্ষর-স্তরের কোডার শেয়ার করা সম্ভব। এই মাল্টিভাষার বৈশিষ্ট্যে, অক্ষর- স্তরের এনকোডার অনেক গুরুত্বপূর্ণ ভাষার জোড়ায় সাবওয়ার্ড- স্তরের কোডার প্রদর্ আমরা দেখতে পাচ্ছি যে সিসি-এন, FI-EN এবং RU-EN-এ, বহুভাষার চরিত্র-স্তরের অনুবাদের মান, এমনকি এই ভাষার প্রশিক্ষিত মডেলের মান বিলিউ স্কোর এবং মানুষের বিচার', 'az': "Ən çox mašin tərcümə sistemi sözlərin səviyyəsində işləyir, möcüzələri çıxartmaq üçün açıq segmentasiya təvəkkül edir. Biz bir nöral maşın çevirimi modelini tanıdırıq ki, bir mənbə karakter sequencesini məqsəd karakter sequencesini heç bir segmentasiya olmadan xəritələyir. Biz kodaddakı max-pooling ilə qarşılıq səviyyəsinə istifadə edirik ki, mənbə göstəricisinin uzunluğunu azaltsın, modeli yerli düzgünlükləri almaq üçün altsözlər səviyyəsinə qarşılaşan modellərlə təhsil edilsin. Bizim karakter-to-character modelimiz, WMT'15 DE-EN və CS-EN üstündə olan alt-sözlər kodlayıcısı ilə yenidən təklif edilən təklif çizgisini seçir və FI-EN və RU-EN üstündə müqayisədə göstərir. Sonra göstəririk ki, çoxlu dillərdən bir modeli təhsil etmək üçün bir karakter-seviyyəti kodlayıcı paylaşmaq mümkün olar. Bu çoxlu dil ayarlarında, karakter səviyyəsi kodlayıcısı dil çiftlərinin altı-söz səviyyəsi kodlayıcısını çox üstün edir. Biz CS-EN, FI-EN və RU-EN ilə çoxlu dilli karakter-seviyyətinin keyfiyyəti, hətta bu dil çiftində özlərinə təhsil edilmiş modellərdən çox üstün olduğunu görürük.", 'bs': "Većina postojećih sustava prevoda mašine funkcioniše na nivou riječi, oslanjajući se na objašnjenje segmentacije da izvuče znakove. Predstavljamo model neuronskog prevoda (NMT) koji mapira sekvencu izvornog karaktera ciljnoj sekvenci karaktera bez ikakve segmentacije. Koristimo konvolucionu mrežu na nivou karaktera sa maksimalnim skupljanjem na koderu kako bi smanjili dužinu zastupanja izvora, omogućavajući da model bude obučen brzinom u usporedbi s modelima podriječja razine dok se uhvate lokalne regularitete. Naš model karaktera do karaktera iznosi nedavno predloženu početnu liniju sa koderom podriječja na WMT'15 DE-EN i CS-EN, i daje usporedbenu predstavu na FI-EN i RU-EN. Onda pokazujemo da je moguće dijeliti jednog kodera na nivou karaktera na višestrukim jezicima vježbamo model na jednom prevodnom zadatku. U ovom multijezičkom nastavku koder nivoa karaktera značajno iznosi koder nivoa podriječi na svim jezičkim parovima. Primijetimo da na CS-EN, FI-EN i RU-EN kvaliteta multijezičkog prevoda na nivou karaktera čak i nadmaže modele posebno obučene samo na tom jezičkom parovu, kako u smislu BLEU rezultata i ljudskog sudjenja.", 'cs': "Většina stávajících systémů strojového překladu pracuje na úrovni slov a spoléhá na explicitní segmentaci pro extrakci tokenů. Představujeme model neuronového strojového překladu (NMT), který mapuje zdrojovou znakovou sekvenci na cílovou znakovou sekvenci bez segmentace. Používáme konvoluční síť na úrovni znaků s maximálním poolingem na kodéru, abychom zkrátili délku reprezentace zdroje, což umožňuje trénovat model rychlostí srovnatelnou s modely na úrovni podslov a zachycovat lokální pravidelnosti. Náš model znaků na znak překonává nedávno navržený základní model s kodérem na úrovni podslov na WMT'15 DE-EN a CS-EN a poskytuje srovnatelný výkon na FI-EN a RU-EN. Následně ukážeme, že je možné sdílet jediný kodér na úrovni znaků napříč více jazyky školením modelu na překladatelské úkoly mnoho na jednoho. V tomto vícejazyčném nastavení kodér na úrovni znaků výrazně předčí kodér na úrovni podslov u všech jazykových párů. Pozorujeme, že u CS-EN, FI-EN a RU-EN kvalita vícejazyčného překladu na úrovni znaků dokonce překonává modely speciálně vycvičené na tomto jazykovém páru, a to jak z hlediska skóre BLEU, tak z hlediska lidského úsudku.", 'ca': "Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens.  Introduïm un model de traducció neural de màquina (NMT) que mapeix una seqüència de caràcters fonts a una seqüència de caràcters alvo sense segmentació. Empreguem una xarxa de convolució a nivell de caràcter amb max-pooling al codificador per reduir la llargada de la representació de fonts, permetent que el model sigui entrenat a una velocitat comparable als models a nivell de subparaules mentre capturem regularitats locals. El nostre model de caràcter a caràcter supera una línia de referència proposta recentment amb un codificador de nivell de subparaules a WMT'15 DE-EN i CS-EN, i dóna rendiment comparable a FI-EN i RU-EN. Ens demostram que és possible compartir un codificador únic de nivell de caràcter a diverses llengües formant un model en una tasca de traducció de molts a un. En aquest entorn multilingüe, el codificador de nivell de caràcter supera significativament el codificador de nivell de subparaules en tots els parells de llengües. Observem que en CS-EN, FI-EN i RU-EN, la qualitat de la traducció a nivell multilingüe supera fins i tot els models especialment entrenats només en aquest parell de llenguatges, tant en termes de puntuació BLEU com de judici humà.", 'et': "Enamik olemasolevaid masintõlke süsteeme töötab sõnade tasandil, tuginedes märkide väljavõtmisel selgesõnalisele segmenteerimisele. Tutvustame neuraalse masintõlke (NMT) mudelit, mis kaardistab lähtemärkide jada sihtmärkide jadasse ilma segmenteerimata. Me kasutame märgitasemel konvolutsioonivõrku koos maksimaalse koondamisega kodeerijal, et vähendada allika esituse pikkust, võimaldades mudelit koolitada kiirusel, mis on võrreldav alamsõna tasemel mudelitega, jäädvustades samal ajal kohalikud regulaarsused. Meie märk-märgile mudel ületab hiljuti väljapakutud lähtetaseme WMT'15 DE-EN ja CS-EN alamsõnatasemel kodeerija ning annab võrreldava jõudluse FI-EN ja RU-EN puhul. Seejärel näitame, et on võimalik jagada ühte märgitasemel kodeerijat mitmes keeles, koolitades mudelit mitmest ühele tõlketööle. Selles mitmekeelses seadistuses ületab märgitaseme kodeerija märkimisväärselt alamsõna taseme kodeerijat kõigis keelepaarides. Me märgime, et CS-EN, FI-EN ja RU-EN puhul ületab mitmekeelse tähemärkide taseme tõlke kvaliteet isegi mudeleid, mida on spetsiaalselt koolitatud ainult sellele keelepaarile, nii BLEU skoori kui ka inimliku hinnangu poolest.", 'fi': "Useimmat olemassa olevat konekäännösjärjestelmät toimivat sanojen tasolla, tukeutuen eksplisiittiseen segmentointiin tokenien poimimiseksi. Esittelemme neurokonekäännösmallin, joka kartoittaa lähdemerkkisekvenssin kohdemerkkisekvenssiin ilman segmentointia. Käytämme merkkitason konvolutionaalista verkkoa, jossa kooderissa on max-pooling, joka lyhentää lähdekuvan pituutta, jolloin mallia voidaan kouluttaa alemman tason malliin verrattavalla nopeudella samalla kun paikallista säännöllisyyttä otetaan talteen. Merkkitasoinen mallimme ylittää äskettäin ehdotetun perusaikataulun WMT'15 DE-EN- ja CS-EN-kooderilla ja antaa vertailukelpoisen suorituskyvyn FI-EN- ja RU-EN-standardeilla. Tämän jälkeen osoitamme, että on mahdollista jakaa yksi merkkitason kooderi useille kielille kouluttamalla malli moniin yhteen käännöstehtävään. Tässä monikielisessä asetuksessa merkkitason kooderi ylittää huomattavasti alasanatason kooderin kaikissa kielipareissa. Havaitsemme, että CS-EN-, FI-EN- ja RU-EN-kielissä monikielisen merkkitason käännöksen laatu ylittää jopa pelkästään kyseiselle kieliparille erityisesti koulutetut mallit sekä BLEU-pisteen että inhimillisen harkinnan osalta.", 'he': "רוב מערכות התרגום מכונות קיימות פועלות ברמה של מילים, סומכות על סגמנציה ברורה כדי להוציא סימנים. אנחנו מציגים מודל מכונת עצבית (NMT) שמפות רצף אופי מקור לרצף אופי מטרה ללא סגמנציה כלשהי. אנו משתמשים ברשת שינוי ברמה אופיינית עם ריכוב מקסימום בקודר כדי להפחית את אורך היציגה של מקור, מאפשר למודל להיות מאומן במהירות שווה למודלים ברמה תת-מילים בזמן שתתפוס תקופות מקומיות. Our character-to-character model outperforms a recently proposed baseline with a subword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable performance on FI-EN and RU-EN.  ואז אנחנו מראים שאפשר לחלוק קודד אחד ברמה של אופיים ברחבי שפות רבות על ידי אימון דוגמן על משימה תרגום רבות לאחד. בסטה רבת-שפותית הזאת, הקודן ברמה של אופים יוצא משמעות יותר ממקוד רמת התת-מילים בכל זוגות השפה. אנו מסתכלים על כך שבסי-אן, פי-אן ורו-אן, איכות התרגום ברמה של אופיים רבות-שפתיים אפילו מעלית את הדוגמנים המתאימים במיוחד על זוג השפה הזו לבד, גם בנוגע לתוצאות BLEU וגם לשיפוט אנושי.", 'jv': 'Jute string" in "context_BAR_stringLink Awak dhéwé nglebah tanggal caratar-nambah convolution netwisen karo koder Kita model karo Karakter iso nggawe nyimpen liyane dadi sing bisa nggawe barang kelas telu-kelas telu nggo koder perangkat saben nggo WT\'16 de-ENE karo CS-ENE, lan nyimpen iso nggawe barang nggawe barang FU-ENE karo RU-ENE Awak dhéwé éntuk ngerasakno lan akeh sampeyan karo koder sampeyan karo uga luwih Nang akeh multi-langkung punika, koder-nambah caratar nang ngerasahan Awak dhéwé nglanggar tarjamahan CS-LU, FILE-LU lan RU-LU, kaliwat kanggo tarjamahan karo alèh-alèh kuwi kesempatan kanggo ngerasah model sing ngwalikno surat kanggo ngerasah winih dhéwé, sampeyan nggo ngerasah tarjamahan kanggo ngerasah sing luwih dumadhi iki lan ujaran uwong.', 'ha': "Babu mafi yawan fassarar ɗin ayuka da ke gaba yana aiki a kan zane-zane, sunã dõgara kan shirin cire-bayani don ya fito ayuka. Tuna ƙara wani motsi na fassarar kwamfyutan neural (NMT) wanda ke karta wani sequence na karin maɓallin nau'in zuwa wani sequence na taga idan ba da wani segment ba. Tuna amfani da wani zanen-daraja mai inganci da kwamfyutan kode don ka ƙara tsawo ga mai nuna wa maɓallin source, kuma Munã yarda a sanar da shi motel a cikin kashi mai kamata da misalin-zane-zane-zane-zane-zane sami idan ana sami sharuɗen lokaci. @ label: listbox KDE style Sa'an nan kuma Muke nuna cewa, za'a iya iya shirin kodi guda na-daraja a cikin wasu harshen dabam-daban, da kuma Mu sanar da wani motel kan wani aikin fassarar-daban-zuwa-guda. @ label Kanã ganin cewa, a kan SA-EN, FI-EN da RU-EN, tsarin fassarar-daraja na mulki ko kuma yana ƙaranci misãlai wanda aka yi wa shirin da shi kawai, kan nau'in da aka sanar da shi dukkan harshen, dukkan cikin muhimman na BLEU ko kuma ma'abun mutum.", 'sk': "Večina obstoječih sistemov strojnega prevajanja deluje na ravni besed in se zanaša na eksplicitno segmentacijo za pridobivanje žetonov. Predstavljamo model nevronskega strojnega prevajanja (NMT), ki kartira zaporedje izvornih znakov v ciljno zaporedje znakov brez segmentacije. Uporabljamo konvolucijsko omrežje na ravni znakov z maksimalnim združevanjem v kodirniku, da se zmanjša dolžina predstavitve vira, kar omogoča usposabljanje modela s hitrostjo, primerljivo z modeli na ravni podbesed, ob zajemanju lokalnih pravilnosti. Naš model znakov do znakov presega nedavno predlagano osnovno zasnovo z kodirnikom na ravni podbesed na WMT'15 DE-EN in CS-EN ter zagotavlja primerljivo zmogljivost na FI-EN in RU-EN. Nato dokazujemo, da je mogoče deliti en kodirnik na ravni znakov v več jezikih z usposabljanjem modela za prevajanje več v eno. V tej večjezični nastavitvi kodirnik na ravni znakov bistveno presega kodirnik na ravni podbesed na vseh jezikovnih parov. Ugotavljamo, da pri CS-EN, FI-EN in RU-EN kakovost večjezičnega prevoda na ravni znakov celo presega modele, ki so posebej usposobljeni samo za ta jezikovni par, tako z vidika ocene BLEU kot človeške presoje.", 'bo': "ཡིན་ཡང་མ་ཡོད་པའི་མ་ལག་གི་ཚིག་ཡིག་ཆ་དེ་སྐབས་ཡིག་གཟུགས་རིས་ཀྱི་ཚད་ལྟར་བཀོད་སྤྱོད་བཞིན་ཡོད། We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any segmentation. We employ a character-level convolutional network with max-pooling at the encoder to reduce the length of source representation, allowing the model to be trained at a speed comparable to subword-level models while capturing local regularities. Our character-to-character model outperforms a recently proposed baseline with a subword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable performance on FI-EN and RU-EN. འུ་ཅག་གིས་སྐད་རིགས སྐད་རིགས་ཀྱི་སྒྲིག We observe that on CS-EN, FI-EN and RU-EN, the quality of the multilingual character-level translation even surpasses the models specifically trained on that language pair alone, both in terms of the BLEU score and human judgment."}
{'en': 'Ordinal Common-sense Inference', 'ar': 'الاستدلال الترتيبي الحس السليم', 'fr': 'Inférence ordinale de bon sens', 'es': 'Inferencia ordinal de sentido común', 'pt': 'Inferência Ordinal de Senso Comum', 'ja': '順序常識的推論', 'zh': '序数常识推理', 'hi': 'क्रमसूचक सामान्य ज्ञान अनुमान', 'ru': 'Обычный здравомыслящий вывод', 'ga': 'Tátal Gnáthchiall', 'ka': 'სხვადასხვა სხვადასხვა განსხვავება', 'hu': 'Rendes józan ész fertőzés', 'el': 'Συνηθές συμπέρασμα κοινής λογικής', 'it': 'Inferenza ordinaria del buonsenso', 'kk': 'Әдеттегі жалпы сезім қасиеті', 'mk': 'Обична инференција со здрава смисла', 'ms': 'Inferensi Normal Common-sense', 'ml': 'സാധാരണ സാമാന്യ-സെന്റ് അഭിപ്രായം', 'mt': 'Inferenza Ordinali tas-Sens Komuni', 'mn': 'Эдийн ерөнхий мэдрэмж', 'no': 'Ordinal vanleg innstillingar', 'pl': 'Wniosek zwykłego zdrowego rozsądku', 'ro': 'Inferenţă ordinară de bun simţ', 'lt': 'Įprasta bendro proto infekcija', 'sr': 'Obična neprijateljstva zajedničkog smisla', 'si': '喾冟窂喽膏窂喽编穵鈥嵿逗 喾冟窂喽膏窂喽编穵鈥嵿逗 喽呧穩喾佮穵鈥嵿逗 喽呧穩喾佮穵鈥嵿逗', 'so': 'Dhibaatooyinka caadiga ah ee caadiga ah', 'ta': 'Ordinal Common-sense Inference', 'sv': 'Vanlig sunt förnuft inferens', 'ur': 'معمولی عام سمجھ', 'uz': 'Umumiy kattalashtirish', 'vi': 'Thông thường', 'da': 'Almindelig sund fornuft', 'hr': 'Obična neprijatnost čestitog smisla', 'bg': 'Обикновено заключение за здравия разум', 'nl': 'Gewoon gezond verstand conclusie', 'id': 'Inferensi Normal Seni Biasa', 'de': 'Ordinale Vernunft Schlussfolgerung', 'fa': 'تفاوت حس معمولی', 'ko': '서수 상식 추리', 'sw': 'Kuingiliwa na maana ya kawaida', 'tr': 'Adatça duýgunlaşdyrma', 'sq': 'Inferenca e zakonshme e kuptimit të zakonshëm', 'af': 'Ordinale Gewone Sense Inferensie', 'am': 'Ordinal Common-sense Inference', 'az': 'Ordinal Common sense Inference', 'hy': 'Ordinal Common-sense Inference', 'bs': 'Obična neprijateljstva zajedničkog smisla', 'ca': 'Inferència normal de sentit comú', 'bn': 'সাধারণ সংক্রান্ত বৈশিষ্ট্য', 'cs': 'Obyčejný závěr zdravého rozumu', 'et': 'Tavaline terve mõistuse järeldus', 'fi': 'Tavallinen tervejärkinen päätelmä', 'jv': 'layer-mode-effects', 'sk': 'Navadna sklepanja zdravega razuma', 'ha': 'Ordinal Common-sense Inference', 'he': 'אינפרנציה רגילה', 'bo': 'སྤྱིར་བཏང་བའི་སྤྱིར་བཏང་བ'}
{'en': 'Humans have the capacity to draw common-sense inferences from natural language : various things that are likely but not certain to hold based on established discourse, and are rarely stated explicitly. We propose an evaluation of automated common-sense inference based on an extension of recognizing textual entailment : predicting ordinal human responses on the subjective likelihood of an inference holding in a given context. We describe a framework for extracting common-sense knowledge from corpora, which is then used to construct a dataset for this ordinal entailment task. We train a neural sequence-to-sequence model on this dataset, which we use to score and generate possible inferences. Further, we annotate subsets of previously established datasets via our ordinal annotation protocol in order to then analyze the distinctions between these and what we have constructed.', 'ar': 'يمتلك البشر القدرة على استخلاص استدلالات المنطق السليم من اللغة الطبيعية: أشياء مختلفة من المحتمل ولكن ليس من المؤكد أن تتمسك بها بناءً على خطاب راسخ ، ونادرًا ما يتم ذكرها صراحة. نقترح تقييمًا للاستدلال الآلي للفطرة السليمة استنادًا إلى امتداد التعرف على الاستنتاج النصي: التنبؤ بالردود البشرية الترتيبية على الاحتمال الذاتي للاحتفاظ بالاستدلال في سياق معين. نصف إطار عمل لاستخراج معرفة الفطرة السليمة من الجسم ، والتي تُستخدم بعد ذلك لإنشاء مجموعة بيانات لهذه المهمة الترتيبية. نقوم بتدريب نموذج التسلسل العصبي إلى التسلسل على مجموعة البيانات هذه ، والتي نستخدمها للتسجيل وإنشاء استنتاجات محتملة. علاوة على ذلك ، نقوم بتعليق مجموعات فرعية من مجموعات البيانات التي تم إنشاؤها مسبقًا عبر بروتوكول التعليقات التوضيحية الترتيبي الخاص بنا من أجل تحليل الفروق بين هذه المجموعات وما قمنا بإنشائه.', 'es': 'Los seres humanos tienen la capacidad de sacar conclusiones de sentido común del lenguaje natural: varias cosas que probablemente, pero no con certeza, se sostienen en función del discurso establecido, y rara vez se declaran explícitamente. Proponemos una evaluación de la inferencia automatizada de sentido común basada en una extensión del reconocimiento de la implicación textual: predecir las respuestas humanas ordinales sobre la probabilidad subjetiva de que una inferencia se mantenga en un contexto dado. Describimos un marco para extraer conocimiento de sentido común de los corpus, que luego se utiliza para construir un conjunto de datos para esta tarea de implicación ordinal. Entrenamos un modelo neuronal de secuencia a secuencia en este conjunto de datos, que utilizamos para puntuar y generar posibles inferencias. Además, anotamos subconjuntos de conjuntos de datos previamente establecidos a través de nuestro protocolo de anotación ordinal para luego analizar las distinciones entre estos y lo que hemos construido.', 'pt': 'Os humanos têm a capacidade de extrair inferências de senso comum da linguagem natural: várias coisas que são prováveis, mas não certas, de se sustentar com base no discurso estabelecido e raramente são declaradas explicitamente. Propomos uma avaliação da inferência automatizada de senso comum baseada em uma extensão do reconhecimento de vinculação textual: predição de respostas humanas ordinais sobre a probabilidade subjetiva de uma inferência ser mantida em um determinado contexto. Descrevemos uma estrutura para extrair conhecimento de senso comum de corpora, que é então usado para construir um conjunto de dados para essa tarefa de vinculação ordinal. Treinamos um modelo neural de sequência a sequência nesse conjunto de dados, que usamos para pontuar e gerar possíveis inferências. Além disso, anotamos subconjuntos de conjuntos de dados previamente estabelecidos por meio de nosso protocolo de anotação ordinal para então analisar as distinções entre eles e o que construímos.', 'fr': "Les humains ont la capacité de tirer des conclusions de bon sens à partir du langage naturel\xa0: diverses choses qui sont susceptibles de tenir, mais pas certaines, sur la base d'un discours établi, et qui sont rarement énoncées explicitement. Nous proposons une évaluation de l'inférence automatique de bon sens basée sur une extension de la reconnaissance de l'implication textuelle\xa0: prédire des réponses humaines ordinales sur la probabilité subjective d'une inférence maintenue dans un contexte donné. Nous décrivons un cadre pour extraire des connaissances de bon sens à partir de corpus, qui est ensuite utilisé pour construire un ensemble de données pour cette tâche d'implication ordinale. Nous entraînons un modèle de séquence neuronale à séquence sur cet ensemble de données, que nous utilisons pour noter et générer des inférences possibles. De plus, nous annotons des sous-ensembles de jeux de données précédemment établis via notre protocole d'annotation ordinale afin d'analyser ensuite les distinctions entre ceux-ci et ce que nous avons construit.", 'ja': '人間は、自然言語から常識的な推論を引き出す能力を持っている。すなわち、確立された話題に基づいている可能性が高いが、確実には持つことができないさまざまなものであり、明示的に述べられることはほとんどない。私たちは、テキストの帰結を認識する拡張に基づいて自動化された常識的推論の評価を提案します：所与の文脈における推論の保持の主観的可能性に関する順序人間の応答を予測します。ここでは、コーパから常識的な知識を抽出するためのフレームワークについて説明します。これは、この順序付きタスクのデータセットを構築するために使用されます。このデータセット上でニューラルシーケンスツーシーケンスモデルをトレーニングし、これを使用してスコアを付け、可能な推論を生成します。さらに、順序アノテーションプロトコルを介して以前に確立されたデータセットのサブセットにアノテーションを行い、これらと構築したものとの区別を分析します。', 'zh': '人有能于自然语言得常识性推之:以既定之言,百可不定之事,鲜有明言。 立本蕴涵自理之评,占人给定上下文之序量应。 述语料库中常识之框架,以构数集蕴涵。 吾于此数集上神经序于序,以评分而成理。 此外因序号注协议注前所立数集子集,以析其数集与吾数集之别。', 'hi': 'मनुष्य ों में प्राकृतिक भाषा से सामान्य ज्ञान के अनुमानों को आकर्षित करने की क्षमता है: विभिन्न चीजें जो संभवतः हैं लेकिन स्थापित प्रवचन के आधार पर पकड़ना निश्चित नहीं है, और शायद ही कभी स्पष्ट रूप से कहा जाता है। हम पाठ्य अनिवार्यता को पहचानने के विस्तार के आधार पर स्वचालित सामान्य ज्ञान अनुमान के मूल्यांकन का प्रस्ताव करते हैं: किसी दिए गए संदर्भ में एक अनुमान धारण की व्यक्तिपरक संभावना पर क्रमसूचक मानव प्रतिक्रियाओं की भविष्यवाणी करना। हम कॉर्पोरेट से सामान्य ज्ञान ज्ञान निकालने के लिए एक ढांचे का वर्णन करते हैं, जिसका उपयोग तब इस क्रमसूचक कार्य के लिए डेटासेट का निर्माण करने के लिए किया जाता है। हम इस डेटासेट पर एक तंत्रिका अनुक्रम-से-अनुक्रम मॉडल को प्रशिक्षित करते हैं, जिसका उपयोग हम स्कोर करने और संभावित अनुमान उत्पन्न करने के लिए करते हैं। इसके अलावा, हम अपने क्रमसूचक एनोटेशन प्रोटोकॉल के माध्यम से पहले से स्थापित डेटासेट के सबसेट को एनोटेट करते हैं ताकि इन और हमने जो निर्माण किया है, उसके बीच के अंतर का विश्लेषण किया जा सके।', 'ru': 'Люди обладают способностью делать здравые выводы из естественного языка: различные вещи, которые, вероятно, но не обязательно будут удерживаться на основе установленного дискурса, и которые редко излагаются прямо. Мы предлагаем оценку автоматического вывода здравого смысла на основе расширения распознавания текстового влечения: прогнозирования порядковых человеческих ответов на субъективную вероятность проведения вывода в данном контексте. Мы описываем структуру для извлечения общепринятых знаний из корпусов, которая затем используется для построения набора данных для этой задачи упорядоченного влечения. На этом наборе данных мы обучаем нейронную модель последовательности, которую мы используем для оценки и генерирования возможных выводов. Кроме того, мы аннотируем подмножества ранее установленных наборов данных с помощью нашего протокола порядковых аннотаций, чтобы затем проанализировать различия между ними и тем, что мы построили.', 'ga': 'Tá sé d’acmhainn ag daoine tátail chomhchiallmhara a bhaint as teanga nádúrtha: rudaí éagsúla ar dócha ach nach bhfuil cinnte go gcoinneofar iad bunaithe ar dhioscúrsa seanbhunaithe, agus is annamh a luaitear go sainráite iad. Molaimid meastóireacht ar thátal comhchiallta uathoibrithe a bheidh bunaithe ar shíneadh ar aitheantas téacsúil: gnáthfhreagraí daonna a thuar ar an dóchúlacht go suibiachtúil go mbeidh tátal i gcomhthéacs ar leith. Déanaimid cur síos ar chreat chun eolas ciallmhar a bhaint as an gcorpas, a úsáidtear ansin chun tacar sonraí a chruthú don ghnáth-thasc seo. Cuirimid oiliúint ar shamhail seicheamh-go-seicheamh néaraigh ar an tacar sonraí seo, a úsáidimid chun tátail fhéideartha a scóráil agus a ghiniúint. Ina theannta sin, déanaimid anótáil ar fho-thacair de thacair sonraí a bunaíodh roimhe seo trínár ngnáthphrótacal anótála chun anailís a dhéanamh ansin ar na hidirdhealú idir iad seo agus an méid atá tógtha againn.', 'el': 'Οι άνθρωποι έχουν την ικανότητα να αντλούν συμπεράσματα κοινής λογικής από τη φυσική γλώσσα: διάφορα πράγματα που είναι πιθανό αλλά όχι βέβαιο να έχουν βάση τον καθιερωμένο λόγο, και σπάνια αναφέρονται ρητά. Προτείνουμε μια αξιολόγηση αυτοματοποιημένων συμπερασμάτων κοινής λογικής με βάση την επέκταση της αναγνώρισης κειμενικών συνεπειών: την πρόβλεψη κανονικών ανθρώπινων αντιδράσεων σχετικά με την υποκειμενική πιθανότητα συγκράτησης συμπερασμάτων σε ένα δεδομένο πλαίσιο. Περιγράφουμε ένα πλαίσιο για την εξαγωγή γνώσεων κοινής λογικής από σώματα, το οποίο στη συνέχεια χρησιμοποιείται για την κατασκευή ενός συνόλου δεδομένων για αυτήν την κανονική εργασία συνεπαγόμενης. Εκπαιδεύουμε ένα μοντέλο νευρικής αλληλουχίας σε αυτό το σύνολο δεδομένων, το οποίο χρησιμοποιούμε για να βαθμολογήσουμε και να παράγουμε πιθανά συμπεράσματα. Περαιτέρω, σχολιάζουμε υποσύνολα προηγουμένως καθιερωμένων συνόλων δεδομένων μέσω του κανονικού πρωτοκόλλου σχολιασμού μας προκειμένου στη συνέχεια να αναλύσουμε τις διακρίσεις μεταξύ αυτών και αυτών που έχουμε κατασκευάσει.', 'hu': 'Az embereknek megvan a képessége arra, hogy józan ész következtetéseket vonjanak le a természetes nyelvből: különböző dolgok, amelyek valószínűleg, de nem biztosak, hogy megállapíthatók a megalapozott diskurzus alapján, és ritkán vannak kifejezetten kimondva. Javasoljuk az automatizált józan ész következtetés értékelését a szöveges vonatkozások felismerésének kiterjesztésén alapuló kiterjesztése alapján: rendes emberi válaszok előrejelzése az adott kontextusban való következtetés szubjektív valószínűségére. Leírjuk a józan ész tudás corporákból való kinyerésének keretét, amelyet ezután egy adatkészlet létrehozására használunk erre a rendes vonatkozási feladatra. Egy idegi szekvencia-szekvencia modellt készítünk ezen az adatkészleten, amelyet arra használunk, hogy pontozhassunk és lehetséges következtetéseket generáljunk. Ezenkívül a korábban létrehozott adatkészletek részhalmazait jegyzeteljük a rendszerinti jegyzetelési protokollunkon keresztül, hogy elemezzük ezek és az általunk létrehozott különbségeket.', 'ka': 'ადამიანები აქვს სახელსაწარმოდგენების შესაძლებლობა სახელსაწარმოდგენების ინფრენციების ნახელსაწარმოდგენების შესაძლებლობა: განსხვავებული რამეები, რომელიც შესაძლებელია, მაგრამ არ და ჩვენ გვეძლევა ავტომატიკური საერთო სიგრძნობის ინფრენციის განსაზღვრება, რომელიც ტექსტულ წარმოდგენების განსაზღვრება დაბაზიან: განსაზღვრება ადამიანის განსახულებების განსაზღვრება განსაზღვრება ჩვენ კოპორადან საერთო სიცოცხლეების გამოყენების ფრამეტრის გამოყენება, რომელიც შემდეგ გამოყენება მონაცემების კონფიგურაციისთვის ამ კონფიგურაციის დასაწყ ჩვენ ამ მონაცემების შესაბამისათვის ნეიროლური შესაბამისათვის მოდელის შესაბამისათვის, რომელიც ჩვენ გამოყენებთ შესაძლებელი ინფრენციების შესაბამისათვის. დამატებით, ჩვენ წინასწორედ დავყენებული მონაცემების სპოსტები ჩვენი პროტოკოლის გამოყენებით, რომ შემდეგ ანალიზიცით განსხვავებების განსხვავება ამ და რაც ჩვენ შევქმნა.', 'it': "Gli esseri umani hanno la capacità di trarre deduzioni del buon senso dal linguaggio naturale: varie cose che probabilmente, ma non certo, manterranno sulla base del discorso stabilito, e sono raramente dichiarate esplicitamente. Proponiamo una valutazione dell'inferenza automatizzata del buon senso basata su un'estensione del riconoscimento del coinvolgimento testuale: predire le risposte umane ordinari sulla probabilità soggettiva che un'inferenza si mantenga in un dato contesto. Descriviamo un framework per estrarre conoscenze di buon senso dai corpora, che viene poi utilizzato per costruire un set di dati per questo compito di implicazione ordinale. Alleniamo un modello neurale sequenza-sequenza su questo set di dati, che usiamo per segnare e generare possibili inferenze. Inoltre, annotiamo sottoinsiemi di set di dati precedentemente stabiliti tramite il nostro protocollo di annotazione ordinale per poi analizzare le distinzioni tra questi e ciò che abbiamo costruito.", 'lt': 'Žmonės gali daryti prastos prasmės išvadas iš natūralios kalbos: įvairių dalykų, kurie greičiausiai, bet neapibrėžti, pagrįsti nuolatine kalba, ir retai aiškiai nurodomi. Siūlome įvertinti automatizuotą sveiko proto išvadą, pagrįstą tekstinio įtraukimo pripažinimo išplėtimu: numatyti įprastus žmogaus atsakus į subjektyvią išvados laikymo tikimybę tam tikru kontekstu. Mes apibūdiname sistemą, pagal kurią gaunamos bendros proto žinios iš korpros, kuri tada naudojama sukurti duomenų rinkinį šiai įprastinei įtraukimo užduotims. Šiame duomenų rinkinyje treniruojame nervų sekos model į, kuris naudojamas galimoms išvadoms gauti. Be to, per mūsų įprastinį anotacijos protokolą anotuojame anksčiau sukurtų duomenų rinkinių pogrupius, kad vėliau analizuotume skirtumus tarp jų ir to, ką sukūrėme.', 'kk': 'Адамдарға табиғи тілден жалпы сезімдерді түсіргендіру мүмкіндігі бар, бірақ құрылған дискурстарға негізделген әртүрлі нәрселерді түсіргендіру мүмкіндігі бар. Біз мәтіндік таңдау үшін автоматты түрде жалпы сезімдік инфекциясын бағалау үшін ұсынып тастаймыз: мәтіндік таңдау үшін адамдардың бағдарламалық жауаптарын көрсету үшін керек контекстікте байланыс Біз корпорадан жалпы мәліметті тарқату үшін қоршау бағдарламасын таңдаймыз. Содан кейін бұл бағдарлама тапсырмасының деректер жиынын құру үшін қолданылады. Бұл деректер жинағында невралдық реттеу үлгісін оқыту үшін қолданамыз. Сонымен қатар, біз бұрынғы құрылған деректер қорларының ішіндегі бөлігін баяндау протоколыбыз арқылы баяндау үшін бұл және біз құрылған деректер қорларының арасындағы бөлігін анализ еті', 'ml': 'മനുഷ്യര്\u200dക്ക് സാധാരണ ഭാഷയില്\u200d നിന്നും സാധാരണമായ സ്വാഭാഷയില്\u200d നിന്നും സാധാരണമുള്ള അപകടത്തിന്റെ കഴിവുണ്ട്: സ്ഥാപിതമായ സംസാരം അടി ടെക്സ്ട്ടിക്കല്\u200d പരിചയപ്പെടുത്തുന്നതിന്\u200dറെ അടിസ്ഥാനത്ത് സ്വയം സാധാരണമായ സാധാരണ മനസ്സിലുള്ള അപരിഹാരം നാം പരിഗണിക്കുന്നു: കൊടുത്തിരിക്കുന്ന ഒര നമ്മള്\u200d ഒരു ഫ്രെയിമെയില്\u200d വിശദീകരിക്കുന്നു കോര്\u200dപ്പോരിയില്\u200d നിന്നും പൊതുവായ അറിവ് പുറത്തെടുക്കുന്നതിന്, അതിനു ശേഷം ഈ ഈ ഡാറ്റാസസെറ്റില്\u200d നമ്മള്\u200d ന്യൂറല്\u200d സെക്കന്\u200dസ് മോഡല്\u200d പരിശീലനം ചെയ്യുന്നു. സാധ്യതയുള്ള അപകടകങ്ങള്\u200d സൃഷ്ടിക്കാനും ഉപയ അതിനുശേഷം, നമ്മുടെ സാധാരണ പ്രോട്ടോക്കോള്\u200d മുമ്പ് സ്ഥാപിച്ച ഡാറ്റാസറ്റുകളുടെ വിഭാഗങ്ങള്\u200d ഞങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. അത', 'mk': 'Луѓето имаат капацитет да извлечат конференции од природниот јазик со здрав смисл: различни работи кои најверојатно но не се сигурни дека ќе се одржат врз основа на поставен дискурс, и ретко се изјавуваат експлицитно. Предложуваме проценка на автоматизираната инференција на здраво-смислено мислење базирана на проширување на признавањето на текстуалното вмешање: предвидување на редовни човечки одговори на субјективната веројатност на инференција во одреден контекст. Опишуваме рамка за извлекување на здраво-смислено знаење од капората, која потоа се користи за изградба на податоци за оваа ординална задача за вклучување. Тренираме нервен модел од секвенца до секвенца на овој податок, кој го користиме за да постигнеме и генерираме можни инференции. Покрај тоа, ги анотираме подгрупите од претходно воспоставени датотеки преку нашиот редовен протокол за анотирање со цел потоа да ги анализираме разликите меѓу овие и она што го изградивме.', 'mt': 'Il-bnedmin għandhom il-kapaċità li jagħmlu inferenzi ta’ sens komuni mil-lingwa naturali: diversi affarijiet li x’aktarx iżda mhux ċerti li jkollhom ibbażati fuq diskors stabbilit, u rarament huma ddikjarati b’mod espliċitu. Aħna nipproponu evalwazzjoni tal-inferenza awtomatizzata tas-sens komuni bbażata fuq estensjoni tar-rikonoxximent tal-involviment testwali: it-tbassir tar-risponsi ordinali umani dwar il-probabbiltà soġġettiva ta’ holding ta’ inferenza f’kuntest partikolari. Aħna niddeskrivu qafas għall-estrazzjoni tal-għarfien tas-sens komuni mill-korpora, li mbagħad jintuża biex jinbena sett ta’ dejta għal dan il-kompitu ordinali ta’ involviment. Aħna nħarrġu mudell minn sekwenza għal sekwenza newrali fuq dan is-sett tad-dejta, li a ħna nużaw biex niggradaw u niġġeneraw inferenzi possibbli. Barra minn hekk, aħna nnotaw settijiet ta’ settijiet ta’ dejta stabbiliti qabel permezz tal-protokoll ta’ annotazzjoni ordinali tagħna sabiex imbagħad janalizzaw id-distinzjonijiet bejn dawn u dak li nbnew.', 'mn': 'Хүн төрөлхтөн байгалийн хэлээс ерөнхий оюун ухааны төвөгтэй зүйлсийг зурах боломжтой байдаг. Байгалийн хэлээс байгуулсан ярианы үндсэн хэлбэрээр байх боломжгүй олон зүйлсийг ойлгох боломжтой, ховор Бид автоматжуулагдсан ерөнхий мэдрэмжтэй халдварын үнэлгээ мөн текстүүдийн санааг хүлээн зөвшөөрсөн байдал дээр байгуулагдсан: хүн төрөлхтний хариултыг тодорхойлж өгсөн нөхцөлд халдвар автоматжуулагдсан магадлал дээ Бид корпоратаас ерөнхий оюун ухааны мэдлэгийг авахын тулд үүнийг тайлбарлаж, дараа нь энэ захирамжлалтын ажил дээр өгөгдлийн санг бүтээхэд хэрэглэгддэг. Бид энэ өгөгдлийн суурь дээр мэдрэлийн дарааллын дарааллын загварыг суралцдаг. Бид үүнийг тооцоолж, боломжтой халдвар үүсгэхийн тулд хэрэглэдэг. Дараа нь, бид өмнө нь бүтээсэн өгөгдлийн сангуудын дараа нь бидний бүтээсэн зүйлс хоорондын ялгааг шинжилүүлэхийн тулд бидний хууль загварын протоколыг ашиглаж байдаг.', 'no': 'Menneskene har kapasiteten til å teikna felles-sens inferensen frå naturspråk: ulike ting som er sannsynleg, men ikkje sikker på å holde basert på oppretta diskursar, og er ofte spesifisert. Vi foreslår eit evaluering av automatisk fellesskapslingsinfeksjon basert på eit utviding av gjenkjenning av tekstinnstillingar: forhåndsvising av ordentlige menneske svar på den subjektive sannsynligheten av ein infeksjon som har holdt i eit gitt kontekst. Vi beskriver eit rammeverk for å ekstrahera kunnskap frå korpora, som er derfor brukt til å konstruera ein dataset for denne ordinnleggingsoppgåva. Vi treng ein neuralsekvens- til- sekvensmodell på denne dataset, som vi brukar for å scorera og laga mulige inferensningar. I tillegg annoterar vi undergrupper av førre oppretta datasett via vår ordealprotokoll for å analysera forskjellingane mellom desse og det vi har konstruert.', 'ro': 'Oamenii au capacitatea de a trage concluzii ale bunului simț din limbajul natural: diferite lucruri care sunt probabil, dar nu sigur, să dețină bazate pe discursul stabilit și sunt rareori declarate explicit. Propunem o evaluare a inferenței automate a bunului simț bazată pe o extensie a recunoașterii implicațiilor textuale: predicția răspunsurilor umane obișnuite asupra probabilității subiective a unei inferențe menținute într-un anumit context. Descriem un cadru pentru extragerea cunoștințelor de bun simț din corpore, care este apoi folosit pentru a construi un set de date pentru această sarcină de implicare ordinară. Antrenăm un model neuronal secvență-la-secvență pe acest set de date, pe care îl folosim pentru a scora și a genera posibile deducții. Mai mult, adnotăm subseturi ale seturilor de date stabilite anterior prin intermediul protocolului nostru de adnotare ordinară pentru a analiza apoi distincțiile dintre acestea și ceea ce am construit.', 'pl': 'Ludzie mają zdolność do wyciągania wniosków zdrowego rozsądku z języka naturalnego: różne rzeczy, które są prawdopodobne, ale nie pewne, że będą trzymać w oparciu o ustalony dyskurs i rzadko są wyraźnie określane. Proponujemy ocenę zautomatyzowanych wniosków zdrowego rozsądku w oparciu o rozszerzenie rozpoznawania implikacji tekstowej: przewidywanie zwykłych odpowiedzi człowieka na subiektywne prawdopodobieństwo utrzymania wniosku w danym kontekście. Opisujemy ramy wydobywania wiedzy zdrowego rozsądku z korpusów, która jest następnie wykorzystywana do skonstruowania zbioru danych dla tego ordynalnego zadania związanego z implikacją. Trenujemy neuronowy model sekwencji-sekwencji na tym zbiorze danych, który używamy do oceny i generowania ewentualnych wniosków. Ponadto adnotacja podzbiorów wcześniej ustalonych zbiorów danych poprzez nasz zwykły protokół adnotacji, aby następnie analizować rozróżnienia między nimi a tym, co skonstruowaliśmy.', 'sr': 'Ljudi imaju kapacitet da izvlače inferencije zajedničkog smisla iz prirodnog jezika: različite stvari koje su vjerojatno ali ne sigurne da drže na temelju ustanovljenih diskursa, i rijetko se pojavljuju jasno. Predlažemo procjenu automatske infekcije zajedničkog smisla na osnovu produženja prepoznavanja tekstualne želje: predviđanje pravilnih ljudskih odgovora na subjektivnu vjerojatnost držanja infekcije u određenom kontekstu. Opišemo okvir za izvlačenje znanja zajedničkog smisla iz korpore, koji se onda koristi za izgradnju kompleta podataka za ovaj uredni zadatak. Vježbamo model neuralne sekvence do sekvence na ovom setu podataka, koji koristimo da rezultiramo i proizvedemo moguće inferencije. Nadalje, annotiramo podskupine prethodno uspostavljenih podataka putem našeg pravilnog protokola za annotaciju kako bi onda analizirali razlike između ovih i onoga što smo izgradili.', 'ms': 'Manusia mempunyai kemampuan untuk melukis kesimpulan yang masuk akal dari bahasa alam: berbagai-bagai perkara yang mungkin tetapi tidak pasti untuk memegang berdasarkan pidato yang ditetapkan, dan jarang ditetapkan secara eksplicit. Kami cadangkan penilaian dari kesimpulan yang berarti secara automatik berdasarkan sambungan mengenali penyelesaian teks: meramalkan respon manusia biasa pada kemungkinan subjektif kesimpulan yang memegang dalam konteks tertentu. Kami menggambarkan kerangka untuk mengekstrak pengetahuan yang masuk akal dari corpora, yang kemudian digunakan untuk membina set data untuk tugas peringkat ini. Kita melatih model urutan-ke-urutan saraf pada set data ini, yang kita gunakan untuk skor dan menghasilkan kesimpulan yang mungkin. Further, we annotate subsets of previously established datasets via our ordinal annotation protocol in order to then analyze the distinctions between these and what we have constructed.', 'so': 'Dadku waxay awood u leeyihiin in ay ka soo bixiso cudurada maanka ah oo afka dabiicadda ah: waxyaalo kala duduwan oo suurtagal ah laakiin ayan hubin inay ku haystaan hadal la dhigay, waana wax yar oo la caddeeyo. Waxaynu soo jeedaynaa qiimeynta cudurka caadiga ah oo ku saleysan furitaanka aqoonsashada qofka dhaqanka ah: waxaan ka hormarinaynaa jawaabaha qofka caadiga ah oo ku saabsan suurtagalka cudurka ku jirta xilliga la siiyey. Waxaynu sawiraynaa qorshaha ka soo bixinta aqoonta caadiga ah ee shirkadda, kaas waxaa loo isticmaalaa in loo dhiso sawir macluumaad ah oo loo sameynayo shaqada aqoonta caadiga ah. Waxaynu ku tababarinnaa tusaale ahaan xilli-xilli, taasoo aan u isticmaalno si aan u qiimeyno oo aan u abuurno cuduro suurtagal ah. Sidoo kale, waxaynu kooxo kooxo ka mid ah taariikhda horay loo dhisay, si aan u baaritaano kala duwanaanshaha labadaas iyo waxa aan dhisnay.', 'sv': 'Människan har förmågan att dra sunt förnuft slutsatser från naturligt språk: olika saker som sannolikt men inte säkert kommer att hålla baserat på etablerad diskurs, och sällan anges uttryckligen. Vi föreslår en utvärdering av automatiserad sunt förnuft slutsats baserad på en förlängning av erkännande av textinvolvering: förutsäga ordinära mänskliga svar på subjektiv sannolikhet för att en slutsats hålls i ett givet sammanhang. Vi beskriver ett ramverk för utvinning av sunt förnuft från corpora, som sedan används för att konstruera en datauppsättning för denna ordinära involveringsuppgift. Vi tränar en neural sekvens-till-sekvensmodell på denna dataset, som vi använder för att score och generera möjliga slutsatser. Vidare kommenterar vi deluppsättningar av tidigare etablerade datauppsättningar via vårt ordinarie annotationsprotokoll för att sedan analysera skillnaden mellan dessa och vad vi har konstruerat.', 'si': 'මිනිස්සුන්ට ප්\u200dරාකෘතික භාෂාවෙන් සාමාන්\u200dය-අවස්ථාවක් ගන්න පුළුවන් තියෙනවා: සාමාන්\u200dය භාෂාවෙන් සාමාන්\u200dය-අවස අපි ස්වයංක්\u200dරියාත්මක විශ්වාස කරන්න පුළුවන් සාමාන්\u200dය අවස්ථාවක් සිද්ධ විශ්වාස කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් විශ්වා අපි කොර්පෝරා වලින් සාමාන්\u200dය අදහස් දැනගන්න ප්\u200dරවේශයක් විස්තර කරනවා, ඒක පස්සේ මේ නියෝජිත වැඩකට දත්ත සැට් හදන අපි මේ තොරතුරු සෙට් එකේ න්\u200dයූරාල ක්\u200dරමයක් පරික්ෂා කරනවා, ඒක අපි ප්\u200dරයෝජනය කරන්න සහ ප්\u200dරයෝජනයක් නිර්මාණය කර තවත්, අපි පස්සේ ස්ථාපනය කරපු දත්ත සේට් වලින් අපේ නියෝජිත ප්\u200dරොටෝකල් වලින් පරික්ෂා කරනවා ඒ වගේම අපි හදපු දේවල් වල', 'ur': 'انسانوں کے پاس طبیعی زبان سے عام سمجھانے کے ذریعے کمزوری کا اختیار ہے: مختلف چیزوں کا احتمال ہے لیکن مطمئن نہیں ہے کہ مضبوط صحبت پر رکھیں اور بہت کم واضح طور پر بیان کیا جاتا ہے. ہم نے اپنے ساتھ عام سمجھ کے کفار کا ارزش کرنا پیش کرتا ہے کہ ایک معاملہ میں حامل ہونے والی کفار کے معاملہ میں اضافہ کرنا ہے ہم ایک فرمود بیان کرتے ہیں کہ شرکت سے معلوم علم نکالنے کے لئے، اور اس کے بعد اس مقررہ کام کے لئے ایک ڈیٹ سٹ بنانے کے لئے استعمال کیا جاتا ہے. ہم نے اس ڈیٹ سٹ پر ایک نئورل سٹ-سے-سٹ-سٹ موڈل کی تعلیم دی ہے، جسے ہم اسکور کرنے کے لئے استعمال کرتے ہیں اور امکان نازل کرنے کے لئے استعمال کرتے ہیں. اور اس کے بعد ہم پہلے سائل ڈیٹ سٹوں کو ہمارے قانونی اظہار پروٹوکول کے ذریعے اظہار کرتے ہیں تاکہ ان کے اور ان کے درمیان تفریق کا تحقیق کریں جو ہم نے بنایا ہے.', 'ta': 'Humans have the capacity to draw common-sense inferences from natural language: various things that are likely but not certain to hold based on established discourse, and are rarely stated explicitly.  கொடுக்கப்பட்ட சூழ்நிலையில் உள்ள பொது பொது உணர்ச்சியின் நோயை அடிப்படையில் நாம் ஒரு தானாகவே பரிந்துரைக்க வேண்டும் என்று பரிந்துரைக்கிறோம். நாம் நிறுவனத்திலிருந்து பொது உணர்வு அறிவை வெளியேற்றும் சட்டத்தை விவரிக்கிறோம், அது பின்னர் இந்த இயல்பான அறிவில்லாத ச நாம் இந்த தரவுத் தளத்தில் ஒரு புதிய தொடர்ச்சி மாதிரியை பயிற்சி செய்கிறோம், அதை நாம் மதிப்பெண்ணை மதிப்பிடுவதற்கும் ச மேலும், நாம் முன்பு நிறுவப்பட்ட தகவல் அமைப்புகளின் துணுக்குகளை அறிவிக்க வேண்டும் நமது சாதாரண அறிவிப்பு நெறிமுறையில் மூலம் வ', 'uz': "Humans have the capacity to draw common-sense inferences from natural language: various things that are likely but not certain to hold based on established discourse, and are rarely stated explicitly.  Biz texnologiya ilmentini aniqlashni aniqlashga asosida avtomatik bog'liq kasalliklarni qiymatlashni talab qilamiz: oddiy inson javoblarini ko'rib chiqqamiz. Ko'rsatilgan muhimkoniyatlarning murakkablarini tasavvur qiling. Biz kompaniyadan umumiy ma'lumotni chiqarish uchun freymni tuzamiz, keyin bu oddiy ilmiy vazifa uchun maʼlumotni yaratish uchun ishlatiladi. Biz bu maʼlumotlar tarkibida neyural seksirlik modelini o'rganamiz. Bu yerda biz muvaffaqiyatli kasalliklarni qo'yish va yaratish uchun foydalanamiz. Ko'rib, biz oldin tashlangan maʼlumotlar tarkibini oddiy taʼminlovchi protokollamiz orqali tahlil qilamiz, va keyin biz qurilgan va biz qanday tuzuvchi soʻzlarimizning orasidagi o'zgarishni aniqlash uchun.", 'vi': 'Loài người có khả năng rút ra những nhận xét chung từ ngôn ngữ tự nhiên: nhiều thứ có khả năng nhưng không chắc chắn để giữ dựa trên ngôn ngữ đã lập, và hiếm khi được nói rõ. Chúng tôi đề nghị một đánh giá luận lý đồng cảm tự động dựa trên một phần mở rộng nhận thức kết cấu: dự đoán các phản ứng pháp luật của con người về khả năng nhận biết kết quả nằm trong một trường hợp cụ thể. Chúng tôi mô tả một cơ sở để lấy kiến thức tỉnh táo từ Hạ sĩ, sau đó được dùng để xây dựng một bộ dữ liệu cho nhiệm vụ tuân định này. Chúng tôi đào tạo một mô hình phân tử thần kinh trên bộ dữ liệu này, chúng tôi sử dụng để ghi điểm và tạo ra các ngụ ý có thể. Thêm vào đó, chúng tôi ghi chú các nhóm dữ liệu đã được thiết lập trước đó qua giao thức ghi chú của chúng tôi để phân tích sự khác biệt giữa chúng và những gì chúng tôi đã tạo ra.', 'bg': 'Хората имат способността да правят изводи за здрав разум от естествения език: различни неща, които вероятно, но не сигурно, ще се поддържат въз основа на установения дискурс и рядко се заявяват изрично. Предлагаме оценка на автоматизираното заключение на здравия разум въз основа на разширение на разпознаването на текстовото обвързване: прогнозиране на обикновени човешки отговори относно субективната вероятност от провеждане на заключение в даден контекст. Описваме рамка за извличане на здрав разум знания от корпуси, която след това се използва за изграждане на набор от данни за тази задача за редовен обвързване. Обучаваме невронен модел последователност към последователност на този набор от данни, който използваме за оценка и генериране на възможни заключения. Освен това, ние анотираме поднабори от предварително установени набори от данни чрез нашия протокол за ординална анотация, за да анализираме разграниченията между тях и това, което сме изградили.', 'da': 'Mennesker har evnen til at drage sund fornuft konklusioner fra det naturlige sprog: forskellige ting, som sandsynligvis, men ikke sikkert vil holde baseret på etableret diskurs, og sjældent udtrykkeligt angives. Vi foreslår en evaluering af automatiseret sund fornuft baseret på en udvidelse af anerkendelse af tekst involvering: forudsigelse af ordinære menneskelige reaktioner på den subjektive sandsynlighed for, at en konklusion holder i en given kontekst. Vi beskriver en ramme for at udtrække sund fornuft viden fra corpora, som derefter bruges til at konstruere et datasæt til denne ordinære involveringsopgave. Vi træner en neural sekvens-til-sekvens model på dette datasæt, som vi bruger til at score og generere mulige konklusioner. Desuden annoterer vi delmængder af tidligere etablerede datasæt via vores ordinære annoteringsprotokol for derefter at analysere skelnen mellem disse og det, vi har konstrueret.', 'nl': 'Mensen hebben het vermogen om conclusies te trekken uit de natuurlijke taal: verschillende dingen die waarschijnlijk maar niet zeker zullen zijn op basis van gevestigde discours, en zelden expliciet worden vermeld. We stellen een evaluatie voor van geautomatiseerde inferentie op basis van een uitbreiding van het herkennen van tekstuele implicaties: het voorspellen van ordinale menselijke reacties op de subjectieve waarschijnlijkheid van een inferentie in een bepaalde context. We beschrijven een raamwerk voor het extraheren van gezond verstand kennis uit corpora, dat vervolgens wordt gebruikt om een dataset te construeren voor deze ordinale implicatietaak. We trainen een neuraal sequence-to-sequence model op deze dataset, die we gebruiken om te scoren en mogelijke conclusies te genereren. Verder annoteren we subsets van eerder vastgestelde datasets via ons ordinale annotatieprotocol om vervolgens de verschillen tussen deze en wat we hebben geconstrueerd te analyseren.', 'de': 'Menschen haben die Fähigkeit, aus der natürlichen Sprache vernünftige Schlussfolgerungen zu ziehen: verschiedene Dinge, die wahrscheinlich, aber nicht sicher sind, basierend auf etablierten Diskursen zu halten und selten explizit angegeben werden. Wir schlagen eine Evaluation der automatisierten Vernunft-Inferenz vor, die auf einer Erweiterung des Erkennens textueller Implikationen basiert: Vorhersage ordinaler menschlicher Reaktionen auf die subjektive Wahrscheinlichkeit einer Inferenz-Halten in einem gegebenen Kontext. Wir beschreiben ein Framework, um gesundes Wissen aus Korpora zu extrahieren, das dann verwendet wird, um einen Datensatz für diese ordinale Implementierungsaufgabe zu konstruieren. Wir trainieren auf diesem Datensatz ein neuronales Sequenzmodell, mit dem wir bewerten und mögliche Schlussfolgerungen generieren. Darüber hinaus kommentieren wir Teilmengen bereits etablierter Datensätze über unser ordinales Annotationsprotokoll, um dann die Unterschiede zwischen diesen und dem, was wir konstruiert haben, zu analysieren.', 'id': 'Manusia memiliki kapasitas untuk menggambar kesimpulan yang masuk akal dari bahasa alam: berbagai hal yang mungkin tetapi tidak yakin untuk memegang berdasarkan pidato yang ditentukan, dan jarang ditentukan secara eksplisit. Kami mengusulkan sebuah evaluasi dari kesimpulan yang berarti secara otomatis berdasarkan ekstensi mengenali keterlibatan tekstual: memprediksi respon manusia biasa pada kemungkinan subjektif dari kesimpulan yang memegang dalam konteks tertentu. Kami menggambarkan rangkaian untuk mengekstraksi pengetahuan yang masuk akal dari corpora, yang kemudian digunakan untuk membangun dataset untuk tugas penggabungan ordinal ini. Kami melatih model urutan-urutan saraf pada set data ini, yang kami gunakan untuk mencetak dan menghasilkan kemungkinan kesimpulan. Selain itu, kami menganoterasi subset dari set data yang terdapat sebelumnya melalui protokol anotasi ordinal kami untuk kemudian menganalisis perbedaan antara ini dan apa yang telah kami bina.', 'fa': 'انسان\u200cها توانایی دارند که از زبان طبیعی آلودگی\u200cهای معمولی را بکنند: چیزهای مختلف است که احتمالاً ولی مطمئن نیستند که بر اساس گفتگوهای ثابت شده نگه دارند، و کمی به طور مشخص تعریف می\u200cشوند. ما پیشنهاد می\u200cکنیم ارزیابی آلودگی عامل خودکار را بر اساس گسترش شناسایی آلودگی متن: پیش\u200cبینی پاسخ\u200cهای عامل انسان بر احتمال عامل آلودگی که در یک محیط معین دارد. ما یک چهارچوب برای اخراج دانش معنوی مشترک از شرکت توصیف می\u200cکنیم، که سپس برای ساختن یک مجموعه داده برای این وظیفه قانونی استفاده می\u200cشود. ما یک مدل از طریقه\u200cهای عصبی به طریقه\u200cای روی این مجموعه\u200cهای داده\u200cها آموزش می\u200cکنیم که برای امتیاز و تولید آلودگی\u200cهای ممکن استفاده می\u200cکنیم. بعدش، ما زیر جمله\u200cها از مجموعه\u200cهای داده\u200cای که قبلاً ساخته شده\u200cایم را از طریق پروتکل اظهار قانونی ما نشان می\u200cدهیم تا آن\u200cگاه اختلاف بین این و آنچه ساخته\u200cایم تحلیل کنیم.', 'hr': 'Ljudi imaju sposobnost izvlačiti inferencije zajedničkog smisla iz prirodnog jezika: različite stvari koje su vjerojatno ali nisu sigurne da drže temeljno na ustanovljenim diskusijama i rijetko se pojavljuju jasno. Predlažemo procjenu automatske infekcije zajedničkog smisla na temelju proširenja priznanja tekstualne želje: predviđanje redovnih ljudskih odgovora na subjektivnu vjerojatnost držanja infekcije u određenom kontekstu. Opišemo okvir za izvlačenje znanja zajedničkog smisla iz korporacije, koji se onda koristi za izgradnju kompleta podataka za ovaj uredni zadatak. Vježbamo model neuralne sekvence do sekvence na ovom setu podataka, koji koristimo za rezultate i proizvedenje mogućih inferencija. Nadalje, annotiramo podskupine prethodno uspostavljenih podataka putem našeg pravilnog protokola za annotaciju kako bi onda analizirali razlike između tih i onoga što smo izgradili.', 'sw': 'Humani wana uwezo wa kuondoa maambukizi yanayofahamika kutoka katika lugha ya asili: mambo mbalimbali yanayoweza lakini hayakuwa na uhakika wa kulingana na mazungumzo yaliyotengenezwa, na ni nadra sana yanayoelezwa. We propose an evaluation of automated common-sense inference based on an extension of recognizing textual entailment: predicting ordinal human responses on the subjective likelihood of an inference holding in a given context.  Tunaelezea mfumo wa kuondoa maarifa yanayofahamika kutoka kwa kampuni hiyo, ambazo ndilo linatumiwa kutengeneza seti ya taarifa kwa ajili ya kazi hii ya kawaida inayofahamika. Tunafundisha muundo wa mfululizo wa mfululizo wa neura kwenye seti hii, ambazo tunatumia kuchukua na kutengeneza maambukizi yanayoweza. Zaidi ya hayo, tunaelezea makundi ya seti za taarifa zilizopita kupitia protoko yetu ya matangazo ya kawaida ili baadae kuchambua tofauti kati ya hizi na kile tulichokijenga.', 'ko': '인류는 자연 언어에서 상식적인 추론을 얻어낼 능력이 있다. 이미 정해진 논술에 따라 각종 가능하지만 반드시 성립되지는 않는 사물은 명확하게 표현되지 않는다.우리는 텍스트의 내포된 식별을 바탕으로 확장된 자동 상식 추리 평가 방법을 제시했다. 추리가 주어진 언어 환경에서 주관적인 가능성에 따라 인류의 질서정연한 반응을 예측한다.우리는 언어 자료 라이브러리에서 상식 지식을 추출하는 구조를 묘사한 다음에 이 구조로 이 질서정연한 내포 임무를 위해 데이터 집합을 구축했다.우리는 이 데이터 집합에서 하나의 신경 서열을 서열 모델로 훈련시켜 가능한 추론을 평가하고 생성한다.또한 우리는 순서 주석 프로토콜을 통해 이전에 만들어진 데이터 집합의 서브집합에 대해 주석을 해서 이러한 데이터 집합과 우리가 구축한 데이터 집합 간의 차이를 분석할 수 있다.', 'tr': 'Adamlaryň tebigy dilinden umumy duýgularyň azalygyny çykarmagy ukyplary bar: beýleki zatlary beýleki, ýöne guruldan gürrüňe daşary tutamagyna ynamly däldir we köplenç net-de aýdylýar. Biz ayrı mantıklı ifadeleri tanıma dayanan, otomatik mantıklı hisselerin değerlendirmesini teklif ediyoruz: verilen bir kontekstde hastalanın resmi sorumluluğu tahmin ediyoruz. Biz korporadan umumy duýgularyň bilgilerini a çmak üçin bir çerçewçigi tassyýarys. Şol soňra bu düzgün işi üçin bir dataset inşa etmek üçin ullanylýar. Biz bu data düzeninde näyral sequence-to-sequence modelini öwredýäris. Bu şekilde mümkin a şyglary çykarmak we çykarmak üçin ulanýarys. Daha da, biz öňki düzenli hasaplanjak protokollarymyz bilen düzenli hasaplanjak bilen düzenli hasaplanjak protokollarymyzdan geçirip başladyk.', 'am': 'የሰዎች የአባቢ ቋንቋ የሆኑን ድካም ከመቀበል መቻል አለባቸው፤ በተዘጋጀ ንግግር ላይ የተመሳሳይ ነገር ግን በጽኑ ንግግር ላይ የሚቆጠሩ ሊሆኑ የሚችሉበት ነገር እና ግልፅ የተለየ ጥቂት ነገር ሳይገልጹ ነው፡፡ የመጽሐፍ ማውቀትን በመስጠት በማስፋት ላይ የተመሳሳይ የህብረት ድህነትን ማስታወቂያ እናሳውቃለን፡፡ ከኮርፖርት የውይይት እውቀትን ለማውጣት ፍሬም እናሳውቃለን፡፡ በዚህ ዳታ ሳንተር ላይ የኔural sequence-to-sequence model እናስተምራለን፤ ስለዚህም እናሳውቃለን የሚቻለውን ደካማዎች እናደርጋለን፡፡ ከዚህም በኋላ በእነዚህ እና በሠራንበት መካከል ያለውን ልዩነት እናስተምር ዘንድ አስቀድሞ የተካሄደውን ዳታ ሰርተቶችን በመጠቅለያችን እናሳውቃለን፡፡', 'sq': 'Njerëzit kanë aftësinë për të tërhequr përfundime të kuptimit të përbashkët nga gjuha natyrore: gjëra të ndryshme që janë të mundshme por jo të sigurta për të mbajtur bazuar në diskursin e përcaktuar, dhe rrallë shprehen në mënyrë të qartë. Ne propozojmë një vlerësim të përfundimit të ndjeshëm të zakonshëm të automatizuar bazuar në një zgjerim të njohjes së përfshirjes tekstuale: parashikimin e përgjigjeve të zakonshme njerëzore mbi mundësinë subjektive të një përfundimi të mbajtur në një kontekst të caktuar. Ne përshkruajmë një kuadër për nxjerrjen e njohurive të kuptueshme nga korpra, e cila pastaj përdoret për të ndërtuar një grup të dhënash për këtë detyrë ordinale të përfshirjes. We train a neural sequence-to-sequence model on this dataset, which we use to score and generate possible inferences.  Për më tepër, ne anotojmë nëngrupe të të dhënave të vendosura më parë nëpërmjet protokollit tonë ordinal të anotacionit me qëllim që pastaj të analizojmë dallimet midis këtyre dhe asaj që kemi ndërtuar.', 'af': "Mense het die kapasiteit om gemeenskaplike-sens inferences van natuurlike taal te teken: verskillende dinge wat waarskynlik is, maar nie seker om te hou gebaseer op geïnstalleerde diskursie, en is selfs uitgelyk gespesifiseer. Ons voorstel 'n evaluering van outomatiese gemeenskap-sens inferensie gebaseer op 'n uitbreiding van herkening van tekstuele aanhouding: voorskou van ordenale menslike antwoordelings op die subjektiewe waarskynlik van 'n inferensie wat in 'n gegewe konteks hou. Ons beskryf 'n raamwerk vir uitpakking van gemeenskaplike-sens kennis van korpora, wat dan gebruik word om 'n datastel vir hierdie ordeelde aanhouding taak te bou. Ons trein 'n neurale sekwensie-na-sekwensie model op hierdie datastel wat ons gebruik om te skep en genereer moontlike inferences. Verder, ons annoteer subartikels van voorheen geïnstalleerde datastelle deur ons ordeelde annotasie protokol om dan die verskilinge tussen hierdie en wat ons gebou het.", 'hy': "Մարդիկ կարողանում են բնական լեզվից առողջ զգացմունքի հետևանքներ կազմել. տարբեր բաներ, որոնք հավանական են, բայց վստահ չեն, հիմնված հաստատուն խոսակցության վրա, և հազվադեպ բացատրված են: Մենք առաջարկում ենք ավտոմատիկ առողջ զգացմունքի եզրակացության գնահատումը, որը հիմնված է տեքստային ներգրավման ճանաչման ընդլայնման վրա' կանխատեսելով մարդկային սովորական արձագանքները որոշ կոնտեքստում կատարվող եզրակացության սուբյեկտիվ հավանական Մենք նկարագրում ենք համակարգ առողջ զգացմունքի գիտելիքների հանելու համար, որը հետո օգտագործվում է կառուցելու տվյալների համակարգ այս սովորական ներգրավման խնդրի համար: Մենք պատրաստում ենք այս տվյալների համակարգում նյարդային հաջորդականության մոդել, որը մենք օգտագործում ենք գնահատելու և ստեղծելու հնարավոր հետևանքներ: Further, we annotate subsets of previously established datasets via our ordinal annotation protocol in order to then analyze the distinctions between these and what we have constructed.", 'az': 'İnsanların təbiətli dildən ortaq hisslərin zəifliyini çəkməyə qadirləri vardır: müxtəlif şeylərdir, lakin möhkəm danışmaqla təsdiqlənməyə əmin deyildir, və az da açıq-aydın danışılır. Biz özünüzə təsdiqlənmək üçün tədriclə ortaq hiss infeksiyonu təsdiqləyirik: tədriclə insan cavab verəcəyini təsdiqləyirik, müəyyən edilmiş bir məsələdə olan infeksiya sahibi olaraq tədriclə təsdiqləyirik. Biz korporadan ortaq anlayış bilgiləri çıxartmaq üçün bir çerçivi təsdiqləyirik. Sonra bu düzgün işlər üçün verilən qurmaq üçün istifadə edilir. Biz bu verilənlər qutusunda nöral sequence-to-sequence modeli təhsil edirik, bu da mümkün inferences yaratmaq üçün istifadə edirik. Daha sonra, əvvəllər qurulmuş verilən qurulmuş verilən qurulmuş qurulmuş qurulmuş quruluş quruluş protokollarımız vasitəsilə danışırıq ki, bunların və in şa etdiyimiz şeylərin arasındakı fərqlərini analiz etmək üçün.', 'bn': 'মানুষের প্রাকৃতিক ভাষা থেকে সাধারণ মানুষের সংক্রান্ত সংক্রান্ত আক্রান্ত আক্রান্ত তুলে ধরার ক্ষমতা আছে: বিভিন্ন বিষয় যা সম্ আমরা স্বয়ংক্রিয়ভাবে সাধারণ মানুষের সংক্রান্ত আক্রান্তের পরিমাণের মূল্য প্রস্তাব করছি: একটি নির্দিষ্ট প্রেক্ষাপটে একটি অসুস্থ সম্ভাবনার উপর সাধারণ মা আমরা কোর্পোরা থেকে সাধারণ বুদ্ধিমান জ্ঞান বের করার একটি ফ্রেম বর্ণনা করি, যা তারপর এই সাধারণ বিজ্ঞানী কাজের জন্য একটি ডাটাসেট তৈর আমরা এই ডাটাসেটে একটি নিউরেল সেকেন্স-থেকে সেকেন্স মডেল প্রশিক্ষণ করি, যা আমরা স্কোর এবং সম্ভাব্য আক্রান্ত তৈরি করতে ব্যবহার করি। এছাড়াও, আমরা পূর্ববর্তী প্রতিষ্ঠিত তথ্য সংক্রান্ত প্রোটোকলের মাধ্যমে প্রতিষ্ঠিত তথ্যের বিভিন্ন বস্তুকে বিশ্লেষণ করি যাতে আমর', 'bs': 'Ljudi imaju kapacitet da izvlače inferencije zajedničkog smisla iz prirodnog jezika: različite stvari koje su vjerojatno ali nisu sigurne da drže na temelju ustanovljenih govora, i rijetko se pojavljuju jasno. Predlažemo procjenu automatske infekcije zajedničkog smisla na temelju proširenja prepoznavanja tekstualne želje: predviđanje redovnih ljudskih odgovora na subjektivnu vjerojatnost držanja infekcije u određenom kontekstu. Opišemo okvir za izvlačenje znanja zajedničkog smisla iz korporacije, koji se onda koristi za izgradnju kompleta podataka za ovaj zadatak o urednom zadatku. Vježbamo model neuralne sekvence do sekvence na ovom setu podataka, koji koristimo da rezultiramo i proizvedemo moguće inferencije. Nadalje, annotiramo podskupine prethodno uspostavljenih podataka putem našeg pravilnog protokola za annotaciju kako bi onda analizirali razlike između tih i onoga što smo izgradili.', 'et': 'Inimestel on võime teha terve mõistuse järeldusi looduslikust keelest: erinevaid asju, mis on tõenäoliselt, kuid mitte kindel, põhinevad väljakujunenud diskursusel ja mida harva sõnaselgelt välja öeldakse. Pakume välja automatiseeritud terve mõistuse järelduste hindamise, mis põhineb tekstilise kaasatuse äratundmise laiendamisel: tavapäraste inimvastuste prognoosimine subjektiivse tõenäosuse kohta järelduse pidamiseks antud kontekstis. Kirjeldame raamistikku terve mõistuse teadmiste hankimiseks korpustest, mida seejärel kasutatakse andmekogumi loomiseks selle tavalise kaasamise ülesande jaoks. Me treenime sellel andmekogumil neuraalset jadast järjestusse mudelit, mida me kasutame punktide ja võimalike järelduste tegemiseks. Lisaks märgistame varem loodud andmekogumite alamhulke ordinaalse annotatsiooni protokolli kaudu, et analüüsida nende ja meie konstrueeritud vahelisi eristusi.', 'cs': 'Lidé mají schopnost vyvozovat závěry zdravého rozumu z přirozeného jazyka: různé věci, které jsou pravděpodobné, ale ne jisté, že budou platit na základě zavedeného diskurzu a zřídka jsou explicitně uvedeny. Navrhujeme vyhodnocení automatizované inference zdravého rozumu založené na rozšíření rozpoznávání textové implikace: predikci normálních lidských reakcí na subjektivní pravděpodobnost, že inference drží v daném kontextu. Popisujeme rámec pro extrakci zdravého rozumu znalostí z korpusů, který je poté použit k sestavení datové sady pro tento ordinální implikační úkol. Na této datové sadě trénujeme neuronový model sekvence-sekvence, který používáme k skórování a generování možných závěrů. Dále anotujeme podmnožiny dříve zavedených datových sad pomocí našeho ordinálního anotačního protokolu, abychom pak analyzovali rozdíly mezi těmito sadami a tím, co jsme vytvořili.', 'ca': "Els humans tenen la capacitat de dibuixar inferències de sentit comú de la llengua natural: diverses coses que són probables però no segures de mantenir basades en un discurs estable, i rarament es diuen explícitament. Proposem una evaluació de la inferència de sentit comú automatitzada basada en una extensió del reconeixement de l'involucració textual: predir respostes humanes ordinals sobre la probabilitat subjectiva d'una inferència sostenida en un context determinat. Descrivem un marc per extrair coneixements de sentit comú de la corpora, que després s'utilitza per construir un conjunt de dades per aquesta tasca ordinal d'involucració. Ensenyem un model seqüència a seqüència neuronal en aquest conjunt de dades, que utilitzem per puntuar i generar possible inferències. També anotem subgrups de conjunts de dades estabelects anteriorment mitjançant el nostre protocol ordinal d'anotació per analitzar les distincions entre aquests i el que hem construït.", 'fi': 'Ihmisillä on kyky tehdä tervejärkisiä johtopäätöksiä luonnollisesta kielestä: erilaisia asioita, jotka todennäköisesti mutta eivät varmoja pidetään vakiintuneen diskurssin perusteella ja joita harvoin ilmaistaan nimenomaisesti. Ehdotamme automatisoidun tervejärkisen päättelyn arviointia, joka perustuu tekstillisen osallisuuden tunnistamisen laajentamiseen: ordinaalien ihmisten vastausten ennustamiseen subjektiivisesta todennäköisyydestä päätelmän pitämisestä tietyssä kontekstissa. Kuvailemme kehystä tervejärkisen tiedon poimimiseksi korpusista, jota käytetään tämän ordinaalin implementointitehtävän aineiston rakentamiseen. Harjoittelemme neurosekvenssimallia, jota käytämme pisteyttääksemme ja tuottaaksemme mahdollisia johtopäätöksiä. Lisäksi teemme muistiinpanoja aiemmin vakiintuneiden aineistojen osajoukoista ordinaalimannotointiprotokollamme avulla analysoidaksemme näiden ja rakentamiemme eron.', 'jv': 'Olomong wong kuwi kapan kanggo nggawe luwih dumateng kuwi tindang dadi: uga cah-cah sing paling apik kuwi kesempatan kanggo nganggo kuwi tindang pasang awak, lan ora bisa pasang karang apik. Awak dhéwé nggunakaé karo kaluwargane soko perusahaan lagi nggambar luwih-luwih Awak dhéwé éntuk sistem kanggo nggawe akeh luwih-luwih hayo nang ora, nik nguasai perusahaan kanggo nggawe dataset kanggo nggawe nguasakno operasi iki. Awak dhéwé sistem sing dibenalke sampek -ne -akhir -ne -uwis model kuwi dataset iki, sing uwis nggambar uwis kuwi nggawe barang etek dhéwé Lakok, kéné mlaku ngerti podho karo hal-hal dadi sing ditambah podho sing ngendalikne ning acara protokol sing dadi nggawe aturan, dadi bisa nguasai perusahaan tanggal dipun wae iki le neng sampeyan sing nggawe nggawe', 'sk': 'Ljudje imajo sposobnost, da iz naravnega jezika naredijo zdrave pametne sklepe: različne stvari, ki so verjetno, vendar ne zagotovo, da bodo držale na podlagi uveljavljenega diskurza in so redko izrecno navedene. Predlagamo vrednotenje avtomatiziranega sklepanja zdravega razuma na podlagi razširitve prepoznavanja besedilne posledice: napovedovanje običajnih človeških odzivov na subjektivno verjetnost sklepanja v danem kontekstu. Opisujemo okvir za pridobivanje zdravega pametnega znanja iz korpusov, ki ga nato uporabimo za izdelavo nabora podatkov za to običajno nalogo implementiranja. Na tem naboru podatkov treniramo model nevronskega zaporedja do zaporedja, ki ga uporabljamo za oceno in ustvarjanje možnih sklepov. Poleg tega oponašamo podnabore predhodno vzpostavljenih naborov podatkov prek našega ordinalnega protokola oponašanja, da bi nato analizirali razlike med temi in tistim, kar smo zgradili.', 'ha': "Mutane na da awon su karɓi wata ana'ura daga harshen kawaici: abubuwa masu yiwuwa ne kuma bã su da yaƙĩni ga su dace a kan maganar da aka tabbatar, kuma ba da abu da ake bayyanawa ba. Kayyari ne kafin da ake iya ƙayyade kasar da ɗayan mutane a kan bayani da aka faɗa ɗabi'a da ake sani na littãfin: Munã bayyana wani firam na fita daga makampuni na da saniya, wanda aka yi amfani da shi na samun wani matsayi wa wannan aikin da ba'a sani ba. Tuna kõre wani misali na'urar-zuwa-sequence kan wannan tsari, wanda Muke amfani da yin score da za'a iya ƙiƙiro kasa masu yiwuwa. Ko kuma, muna sanar da jama'a masu tsari da aka riga ta kafo a sami da shiryoyin ayukanmu, dõmin mu yi anadi a tsakanin waɗannan da muka samu.", 'he': 'בני אדם יש את היכולת לצייר תוצאות בהיגיון רגיל משפה טבעית: דברים שונים שכנראה אבל לא בטוחים להחזיק בהתבסס על דיבור קבוע, ובלעיתים נדירות מוצהירים באופן ברור. אנו מציעים עריכה של תוצאה אוטומטית של הגיון הנפשי מבוססת על התרחבות של זיהוי התערבות טקסטלית: צפוי תגובות אנושיות רגילות על הסבירות הסביביקטיבית של תוצאה שמחזיקה בקשר מסוים. אנו מתארים מסגרת לחלץ ידע בהיגיון שפוי מקפורה, אשר משתמש אז לבנות קבוצת נתונים למשימה המיוחדת הזאת. אנחנו מאמן דוגמנית רצף לרצף עצבי על קבוצת נתונים הזאת, שאנחנו משתמשים בה כדי לקבוע וליצור תוצאות אפשריות. Further, we annotate subsets of previously established datasets via our ordinal annotation protocol in order to then analyze the distinctions between these and what we have constructed.', 'bo': 'Humans have the ability to draw common-sense inferences from natural language: various things that are likely but not certain to hold based on established discourse, and are rarely stated explicitly. ང་ཚོས་རང་བཞིན་གྱིས་རྒྱུན་ལྡན་པའི་གསལ་བཤད་ཀྱི་དཔྱད་རིམ་དཔྱད་ཡོད་པ་དེ་རྟོགས་བཞག་ཡོད། རྣམ་གྲངས་མེད་པའི་མཐུན་རྐྱེན་ཚུལ་ལྟར་བསམ་བླ ང་ཚོས་སྡོང་འཛིན་གྱི་ཐབས་ལམ་ལ་སྤྱིར་བཏང་བའི་མིང་ཚོའི་འབྲེལ་བ་དེ་རང་ཉིད་ཀྱི་རྩོམ་པ་ཞིག་གསར་འཛུགས་བྱེད་ཀྱི་ཡོད། We train a neural sequence-to-sequence model on this dataset, which we use to score and generate possible inferences. འོན་ཀྱང་། ང་ཚོས་སྔོན་གྱི་ལྟ་བུའི་གནད་སྡུད་དག་སྔོན་འཛུགས་པའི་ཡིག་ཆ་སྒྲིག་འགོད་བྱས་པའི་མཐུན་སྒྲིག་འགོད་བྱས་པ་དེ་ཚོ་དང་གསར'}
{'en': 'Learning Distributed Representations of Texts and Entities from Knowledge Base', 'fr': "Apprentissage des représentations distribuées de textes et d'entités à partir de la", 'ar': 'تعلم التمثيل الموزع للنصوص والكيانات من قاعدة المعرفة', 'es': 'Aprendizaje de representaciones distribuidas de textos y entidades de la base de conocimientos', 'pt': 'Aprendendo Representações Distribuídas de Textos e Entidades da Base de Conhecimento', 'ja': 'ナレッジベースからテキストとエンティティの分散表現を学習する', 'zh': '以知识库学文实之分布式', 'hi': 'नॉलेज बेस से ग्रंथों और संस्थाओं के वितरित प्रतिनिधित्व सीखना', 'ru': 'Изучение распределенных представлений текстов и сущностей из базы знаний', 'ga': 'Léirithe Dáilte Téacsanna agus Aonáin a Fhoghlaim ón Bhonn Eolais', 'ka': 'მეცნიერების ბაზის ტექსტის და ელემენტების გარეშე', 'el': 'Κατανεμημένες αναπαραστάσεις κειμένων και οντοτήτων από τη Γνωσιακή Βάση', 'hu': 'Tanulás Szövegek és entitások elosztott képviseletei a Tudásbázisból', 'it': 'Rappresentazioni distribuite di testi e entità dalla Knowledge Base', 'lt': 'Mokymasis pasiskirstytais tekstų ir subjektų atstovavimais iš žinių bazės', 'mk': 'Научи дистрибуирани претставувања на текстови и ентитети од базата на знаење', 'kk': 'Білім негізінен мәтін мен нысандардың таратылған таңбаларын үйрену', 'ms': 'Learning Distributed Representations of Texts and Entities from Knowledge Base', 'ml': 'അറിവുകളുടെ അടിസ്ഥാനത്തുനിന്നും പദാവലികളുടെയും പ്രതികരണങ്ങള്\u200d പഠിക്കുന്നു', 'mt': 'Tagħlim Rappreżentazzjonijiet Distribwiti tat-Testi u l-Entitajiet mill-Bażi tal-Għarfien', 'no': 'Læring av distribuerte representasjonar av tekst og einingar frå kunnskapsbasen', 'mn': 'Мэдлэгийн суурь дээрх хуваарилагдсан Текст болон Объектуудын суралцах', 'ro': 'Reprezentarea distribuită a textelor și entităților din baza de cunoștințe', 'sr': 'Naučenje raspodijeljenih predstavljanja teksta i subjekta iz baze znanja', 'so': 'Barista Representations of Texts and Entries from Basic Knowledge', 'si': 'Name', 'sv': 'Lärande distribuerade representationer av texter och enheter från kunskapsbasen', 'pl': 'Uczenie się rozproszonych reprezentacji tekstów i podmiotów z bazy wiedzy', 'ta': 'அறிவிப்பு அடிப்படையில் இருந்து உரைகள் மற்றும் உள்ளீடுகளின் பங்கிடப்பட்ட மின்னஞ்சல்கள்', 'ur': 'علم Base سے متفرقہ ٹیکسٹ اور ایٹنیٹوں کی نمایش سکھائی', 'uz': 'Name', 'vi': 'Trình tự phát hành Văn bản và đơn vị từ Nhà tri thức', 'nl': 'Leren gedistribueerde representaties van teksten en entiteiten uit de kennisbank', 'bg': 'Учебни разпределени представи на текстове и образувания от базата знания', 'da': 'Læring Distribueret repræsentation af tekster og enheder fra Knowledge Base', 'hr': 'Naučenje distribuiranih predstavljanja teksta i subjekta iz baze znanja', 'ko': '지식 라이브러리에서 텍스트와 실체의 분포식 표시를 배우다', 'de': 'Lernen von verteilten Darstellungen von Texten und Entitäten aus der Wissensdatenbank', 'id': 'Belajar Perwakilan Didistribusikan Teks dan Entitas dari Pangkalan Pengetahuan', 'sw': 'Kujifunza maoni yaliyogawanywa kwa Maandishi na Mipango kutoka Ujuzi', 'tr': 'Bilim Basisinden Metin we Entitekleriň Paýlaşdyrylan Wagtlaýyşlaryny öwrenmek', 'fa': 'یاد گرفتن نمایش\u200cهای توزیع متن\u200cها و اجتماعات از بنیاد دانش', 'am': 'ጽሑፎች እና አቀማመጥ', 'af': 'Leer verspreidige voorstellings van teks en eenhede van kennis basis', 'hy': 'Սովորեցնել տեքստների և առանձնահատկությունների բաշխված ներկայացումները գիտելիքների հիմքից', 'sq': 'Mësimi i përfaqësimeve të shpërndara të teksteve dhe njësive nga baza e njohurive', 'bn': 'জ্ঞান বেস থেকে টেক্সট এবং এন্টিটের প্রতিনিধি বিতরণ শিখানো', 'bs': 'Naučenje distribuiranih predstavljanja teksta i subjekta iz baze znanja', 'az': 'Bilim Basesindən Mətn və Entitələrin dağıtılmış göstərilmələrini öyrənmək', 'ca': 'Aprendre representacions distribuïdes de textos i entitats a partir de la base de coneixements', 'cs': 'Výuka distribuovaných reprezentací textů a entit ze znalostní báze', 'et': 'Tekstide ja üksuste jaotatud esinduste õppimine teabebaasist', 'fi': 'Oppiminen Tekstien ja entiteettien hajautettuja representaatioita Knowledge Base -tietokannasta', 'jv': 'Ngerti Gambar Kebebasan Gambar Kemerdekaan Teks lan Entitêm nang Daerah Kemerdekaan', 'sk': 'Učenje porazdeljenih predstavitev besedil in entitet iz baze znanja', 'he': 'ללמוד מייצגים מתפשטים של טקסטים ואנשים מבסיס ידע', 'ha': 'KCharselect unicode block name', 'bo': 'Learning Distributed Representations of Texts and Entities from Knowledge Base'}
{'en': 'We describe a neural network model that jointly learns distributed representations of texts and knowledge base (KB) entities. Given a text in the KB, we train our proposed model to predict entities that are relevant to the text. Our model is designed to be generic with the ability to address various NLP tasks with ease. We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia. We evaluated the model on three important NLP tasks (i.e., sentence textual similarity, entity linking, and factoid question answering) involving both unsupervised and supervised settings. As a result, we achieved state-of-the-art results on all three of these tasks. Our code and trained models are publicly available for further academic research.', 'ar': 'نصف نموذج الشبكة العصبية الذي يتعلم بشكل مشترك التمثيلات الموزعة للنصوص وكيانات قاعدة المعرفة (KB). بالنظر إلى نص في قاعدة المعارف ، نقوم بتدريب نموذجنا المقترح للتنبؤ بالكيانات ذات الصلة بالنص. تم تصميم نموذجنا ليكون عامًا مع القدرة على معالجة مهام البرمجة اللغوية العصبية المختلفة بسهولة. نقوم بتدريب النموذج باستخدام مجموعة كبيرة من النصوص والتعليقات التوضيحية للكيانات المستخرجة من ويكيبيديا. قمنا بتقييم النموذج في ثلاث مهام مهمة في البرمجة اللغوية العصبية (أي ، تشابه نصي الجملة ، وربط الكيان ، والإجابة على الأسئلة الواقعية) التي تتضمن إعدادات غير خاضعة للإشراف وخاضعة للإشراف. نتيجة لذلك ، حققنا أحدث النتائج في جميع هذه المهام الثلاث. الكود الخاص بنا والنماذج المدربة متاحة للجمهور لمزيد من البحث الأكاديمي.', 'fr': "Nous décrivons un modèle de réseau neuronal qui apprend conjointement des représentations distribuées de textes et d'entités de la base de connaissances (KB). À partir d'un texte dans la base de connaissances, nous entraînons notre modèle proposé pour prédire les entités pertinentes par rapport au texte. Notre modèle est conçu pour être générique avec la capacité de traiter facilement diverses tâches de PNL. Nous entraînons le modèle à l'aide d'un vaste corpus de textes et d'annotations d'entités extraites de Wikipédia. Nous avons évalué le modèle sur trois tâches NLP importantes (similitude textuelle de phrase, liaison d'entité et réponse à des questions factuelles) impliquant à la fois des environnements non supervisés et supervisés. Nous avons ainsi obtenu des résultats de pointe pour ces trois tâches. Notre code et nos modèles formés sont accessibles au public pour d'autres recherches universitaires.", 'pt': 'Descrevemos um modelo de rede neural que aprende conjuntamente representações distribuídas de textos e entidades da base de conhecimento (KB). Dado um texto na KB, treinamos nosso modelo proposto para prever entidades relevantes para o texto. Nosso modelo foi projetado para ser genérico com a capacidade de lidar com várias tarefas de PNL com facilidade. Treinamos o modelo usando um grande corpus de textos e suas anotações de entidade extraídas da Wikipedia. Avaliamos o modelo em três importantes tarefas de PNL (ou seja, semelhança textual de frases, vinculação de entidades e resposta a questões factóides) envolvendo configurações não supervisionadas e supervisionadas. Como resultado, obtivemos resultados de última geração em todas essas três tarefas. Nosso código e modelos treinados estão disponíveis publicamente para futuras pesquisas acadêmicas.', 'es': 'Describimos un modelo de red neuronal que aprende conjuntamente representaciones distribuidas de textos y entidades de bases de conocimiento (KB). Dado un texto en la base de conocimientos, entrenamos nuestro modelo propuesto para predecir las entidades que son relevantes para el texto. Nuestro modelo está diseñado para ser genérico con la capacidad de abordar varias tareas de PNL con facilidad. Entrenamos el modelo utilizando un gran corpus de textos y sus anotaciones de entidad extraídas de Wikipedia. Evaluamos el modelo en tres tareas importantes de PNL (es decir, similitud textual de oraciones, vinculación de entidades y respuesta factoide a preguntas) que involucran entornos supervisados y no supervisados. Como resultado, logramos resultados de vanguardia en estas tres tareas. Nuestro código y modelos entrenados están disponibles públicamente para futuras investigaciones académicas.', 'ja': 'テキストとナレッジベース（ KB ）エンティティの分散表現を共同で学習するニューラルネットワークモデルについて説明します。チームドットのテキストを使用して、提案されたモデルをトレーニングして、テキストに関連するエンティティを予測します。当社のモデルは、さまざまなNLPタスクに簡単に対処できるように設計されています。ウィキペディアから抽出された大量のテキストとその実体注釈を使用してモデルをトレーニングします。私たちは、3つの重要なNLPタスク（すなわち、文章の類似性、エンティティのリンク、および事実関係の質問への回答）で、監督されていない設定と監督されている設定の両方に関わるモデルを評価しました。その結果、これら3つのタスクすべてで最先端の結果を達成しました。当社のコードと訓練されたモデルは、さらなる学術研究のために公開されています。', 'zh': '凡言神经网络模,共学文本,与知识库(KB)实体之分布式。 给定知识库中文本,训练规模,以占其实。 吾道为通用者,能轻解百NLP之务。 用维基百科中大文本及实体注以训模形。 臣等三要NLP务(句文本相似性,实体链接与事实问答)上评模形,涉无监设。 是以三者皆得先进之功。 吾代码与训练之法明矣,所以益学术研究也。', 'hi': 'हम एक तंत्रिका नेटवर्क मॉडल का वर्णन करते हैं जो संयुक्त रूप से ग्रंथों और नॉलेज बेस (केबी) संस्थाओं के वितरित प्रतिनिधित्व सीखता है। KB में एक पाठ को देखते हुए, हम अपने प्रस्तावित मॉडल को उन संस्थाओं की भविष्यवाणी करने के लिए प्रशिक्षित करते हैं जो पाठ के लिए प्रासंगिक हैं। हमारे मॉडल को आसानी से विभिन्न एनएलपी कार्यों को संबोधित करने की क्षमता के साथ सामान्य होने के लिए डिज़ाइन किया गया है। हम विकिपीडिया से निकाले गए ग्रंथों और उनकी इकाई एनोटेशन के एक बड़े कॉर्पस का उपयोग करके मॉडल को प्रशिक्षित करते हैं। हमने तीन महत्वपूर्ण एनएलपी कार्यों (यानी, वाक्य पाठ्य समानता, इकाई लिंकिंग, और फैक्टॉइड प्रश्न उत्तर) पर मॉडल का मूल्यांकन किया, जिसमें दोनों असुरक्षित और पर्यवेक्षित सेटिंग्स शामिल हैं। नतीजतन, हमने इन तीनों कार्यों पर अत्याधुनिक परिणाम प्राप्त किए। हमारे कोड और प्रशिक्षित मॉडल आगे के अकादमिक अनुसंधान के लिए सार्वजनिक रूप से उपलब्ध हैं।', 'ru': 'Мы описываем модель нейронной сети, которая совместно изучает распределенные представления текстов и сущностей базы знаний (КБ). Учитывая текст в КБ, мы обучаем нашу предлагаемую модель предсказанию сущностей, которые имеют отношение к тексту. Наша модель разработана, чтобы быть универсальной с возможностью легко решать различные задачи NLP. Мы обучаем модель, используя большой корпус текстов и их сущностные аннотации, извлеченные из Википедии. Мы оценили модель по трем важным задачам NLP (т.е. текстовое сходство предложений, связывание сущностей и ответы на фактические вопросы), включающим как неконтролируемые, так и контролируемые настройки. В результате мы достигли самых современных результатов по всем трем этим задачам. Наш код и обученные модели общедоступны для дальнейших академических исследований.', 'ga': 'Déanaimid cur síos ar shamhail líonra néaraigh a fhoghlaimíonn i gcomhpháirt uiríll dáilte téacsanna agus eintitis bonn eolais (KB). I bhfianaise téacs sa KB, cuirimid oiliúint ar ár múnla molta chun aonáin a bhaineann leis an téacs a thuar. Tá ár múnla deartha le bheith cineálach leis an gcumas tabhairt faoi thascanna éagsúla NLP gan stró. Cuirimid oiliúint ar an tsamhail trí úsáid a bhaint as corpas mór téacsanna agus a gcuid nótaí aonáin a bhaintear as Vicipéid. Rinneamar measúnú ar an tsamhail ar thrí thasc thábhachtacha NLP (i.e. cosúlacht théacs na habairte, nascadh aonáin, agus freagairt ceisteanna factoid) a bhaineann le suíomhanna gan mhaoirseacht agus faoi mhaoirseacht. Mar thoradh air sin, bhaineamar torthaí den scoth amach ar na trí thasc seo. Tá ár gcód agus ár múnlaí oilte ar fáil go poiblí le haghaidh tuilleadh taighde acadúil.', 'hu': 'Olyan neurális hálózati modellt írunk le, amely közösen tanulja meg a szövegek és a tudásbázis (KB) entitások elosztott reprezentációit. A KB szövegét tekintve a javasolt modellünket arra képezzük, hogy előrejelezzük a szöveg szempontjából releváns entitásokat. Modellünket úgy terveztük, hogy általános legyen, és képes a különböző NLP feladatok könnyedén kezelni. A modellt a Wikipédiából kivont szövegek nagy korpuszával és entitásjegyzékekkel képezzük. A modellt három fontos NLP feladat alapján értékeltük (azaz mondatszöveghasonlóság, entitáskötés és tényleges kérdések megválaszolása) mind felügyelet nélküli, mind felügyelet nélküli, mind felügyelt beállításokkal. Ennek eredményeként mindhárom feladat tekintetében korszerű eredményeket értünk el. Kódunk és képzett modelleink nyilvánosan hozzáférhetők további tudományos kutatásokhoz.', 'el': 'Περιγράφουμε ένα μοντέλο νευρωνικού δικτύου που μαθαίνει από κοινού κατανεμημένες αναπαραστάσεις κειμένων και οντοτήτων της βάσης γνώσης. Δεδομένου ενός κειμένου στην ΚΒ, εκπαιδεύουμε το προτεινόμενο μοντέλο μας για να προβλέψουμε οντότητες που σχετίζονται με το κείμενο. Το μοντέλο μας έχει σχεδιαστεί για να είναι γενικό με τη δυνατότητα να αντιμετωπίζει διάφορες εργασίες με ευκολία. Εκπαιδεύουμε το μοντέλο χρησιμοποιώντας ένα μεγάλο σώμα κειμένων και σχολιασμούς οντότητας που εξάγονται από τη Βικιπαίδεια. Αξιολογήσαμε το μοντέλο σε τρεις σημαντικές εργασίες (δηλ. ομοιότητα κειμένου προτάσεων, σύνδεση οντότητας και απάντηση πραγματικών ερωτήσεων) που αφορούν τόσο τις ανεξέλεγκτες όσο και τις εποπτευόμενες ρυθμίσεις. Ως αποτέλεσμα, επιτύχαμε αποτελέσματα τελευταίας τεχνολογίας και στις τρεις αυτές εργασίες. Ο κώδικας και τα εκπαιδευμένα μοντέλα μας είναι δημόσια διαθέσιμα για περαιτέρω ακαδημαϊκή έρευνα.', 'ka': 'ჩვენ აღწერეთ ნეიროლური ქსელის მოდელი, რომელიც ერთად აღწერს ტექსტის და ცნობის ბაზის განსაზღვრებების განსაზღვრება. KB-ში ტექსტის შესახებ, ჩვენ გვეტვირთვალობთ ჩვენი მოდელს, რომელიც ტექსტისთვის შესახებ ინტერტიების განსაზღვრება. ჩვენი მოდელი განსაზღვრებულია, რომ განსაზღვრებული იყოს სხვადასხვა NLP დავალებების შესაძლებლობა. ჩვენ მოდელს გავისწავლეთ, რომელიც გამოყენება დიდი ტექსტის კორპუსს და მათი ინტერტიკური ანოტაციების გამოყენება ვიკიპედიაზე. ჩვენ მოდელის შესახებ სამი მნიშვნელოვანი NLP დავამუშაოთ (მაგალითად, ტექსტური სინამდვილეობა, ელექტის დაკავშირება და ფაქტოიდის კითხვის პასუხისთვის), რომლებიც ორივე უნდა დააკეთ როგორც შედეგი, ჩვენ მივიღეთ ყველა სამუშაო სამუშაო სამუშაო დავალება. ჩვენი კოდი და შესწავლობული მოდელები უფრო დიდი აკადემიკური შესწავლებისთვის ხელსახულია.', 'it': "Descriviamo un modello di rete neurale che impara congiuntamente rappresentazioni distribuite di testi e entità della base di conoscenza (KB). Dato un testo nella KB, addestriamo il nostro modello proposto per prevedere entità rilevanti per il testo. Il nostro modello è progettato per essere generico con la capacità di affrontare varie attività NLP con facilità. Formiamo il modello utilizzando un ampio corpus di testi e le loro annotazioni entità estratte da Wikipedia. Abbiamo valutato il modello su tre importanti compiti del PNL (cioè, somiglianza testuale delle frasi, collegamento di entità e risposta alle domande di fatto) che coinvolgono sia impostazioni non supervisionate che supervisionate. Di conseguenza, abbiamo ottenuto risultati all'avanguardia su tutti e tre questi compiti. Il nostro codice e i modelli formati sono pubblicamente disponibili per ulteriori ricerche accademiche.", 'lt': 'Mes apibūdiname neurologinio tinklo model į, kuris kartu mokosi paskirstytų tekstų ir žinių bazės (KB) subjektų atstovavimų. Atsižvelgdami į KB tekstą, mes mokome savo pasiūlytą model į prognozuoti su tekstu susijusius subjektus. Mūsų model is sukurtas taip, kad jis būtų generinis ir galėtų lengvai spręsti įvairias NLP užduotis. Mes mokome model į naudojant didelį tekstų korpusą ir jų subjekto anotacijas iš Vikipedijos. Vertinome model į pagal tris svarbias NLP užduotis (t. y. tekstinį sakinio panašumą, subjektų susiejimą ir faktinį klausimų atsakymą), kuriose dalyvavo ir nepastebimi, ir priži ūrimi nustatymai. Todėl pasiekėme naujausius rezultatus visose trijose iš šių užduočių. Mūsų kodeksas ir parengti modeliai yra viešai prieinami tolesniems akademiniams tyrimams.', 'mk': 'Го опишуваме моделот на нервната мрежа кој заедно научи дистрибуирани претставувања на текстите и ентитетите на базата на знаење (КБ). Со оглед на текстот во КБ, го обучуваме нашиот предложен модел за предвидување на ентитетите кои се релевантни за текстот. Нашиот модел е дизајниран за да биде генеричен со способност да се решат различни НЛП задачи со лесност. Го обучуваме моделот користејќи голем корпус текстови и нивните анотации на ентитетот извадени од Википедија. Го проценивме моделот на три важни НЛП задачи (т.е., текстуална сличност на речениците, поврзување на ентитетите и одговор на фактоидните прашања) кои вклучуваат и ненадгледувани и надгледувани поставувања. Како резултат на тоа, постигнавме најдобри резултати на сите три од овие задачи. Нашиот код и обучените модели се јавно достапни за понатамошно академско истражување.', 'ms': 'Kami menggambarkan model rangkaian saraf yang bersama-sama belajar perwakilan terhapus teks dan entiti pangkalan pengetahuan (KB). Berdasarkan teks dalam KB, kita melatih model kami untuk meramalkan entiti yang berkaitan dengan teks. Model kami direka untuk generik dengan kemampuan untuk mengatasi berbagai tugas NLP dengan mudah. Kami melatih model menggunakan banyak teks dan anotasi entiti mereka yang dikeluarkan dari Wikipedia. Kami menilai model pada tiga tugas NLP penting (iaitu persamaan teks kalimat, sambungan entiti, dan jawapan soalan faktoid) yang melibatkan kedua-dua tetapan tidak diawasi dan diawasi. As a result, we achieved state-of-the-art results on all three of these tasks.  Kod kami dan model terlatih tersedia secara awam untuk kajian akademik lanjut.', 'kk': 'Біз мәтін мен білім негізінің үлгілерін біріктіретін невралдық желінің үлгісін таңдаймыз. КБ- дегі мәтінді көрсету үшін, мәтінде қатынасыз бар нысандарды алдын- ала көру үшін қолданатын үлгілерімізді үйренеміз. Біздің моделіміз көмегімен NLP тапсырмаларын өзгерту мүмкіндігімен жалпы болу үшін құрылған. Біз үлгісін Википедиядан алып тастаған үлкен мәтін корпус мен оның жазбаларын қолдануға үйренеміз. Біз үш маңызды NLP тапсырмаларында үлгі бағаладық (мысалы, мәтіндік ұқсас, бірлік сілтемелер мен фактоидтік сұрақ жауап беру) деген мәтіндіктерді қолданып тұрдық. Бұл мәтіндік мәтінді Сонымен біз бұл үш тапсырманың күй-жайы нәтижесін жеткіздік. Біздің кодымыз және оқылған моделдеріміз жалпы академиялық зерттеулерге қол жеткізеді.', 'mn': 'Бид мэдлэг суурь болон мэдлэг суурь (КБ) бүлгүүдийн хуваарилагддаг мэдрэлийн сүлжээний загварын загварыг нийлүүлдэг. КБ-д байгаа текст учраас, бид өөрсдийн санал өгсөн загварыг тексттэй холбоотой бүтээлүүдийг таамаглах зорилготой. Бидний загвар нь олон NLP ажлыг амархан зохицуулах чадвартай ихэвчлэн төсөөлөгдсөн. Бид загварыг Википедиадаас гаргасан том бичгийн корпус болон бичгийг ашиглаж суралцаж байна. Бид NLP-ийн гурван чухал даалгаварын загварыг (яг л текст төстэй, бүтэц холбогдол, фактоид асуулт хариулт) дээр үнэлгээд үзсэн. Үүний үр дүнд бид эдгээр 3 даалгаварын уламжлалтыг гаргасан. Бидний код болон сургалтын загварууд олон нийтэд сургалтын судалгаанд ашиглагддаг.', 'ml': 'ഞങ്ങള്\u200d ഒരു ന്യൂറല്\u200d നെറ്റര്\u200d നെറ്റര്\u200d മോഡല്\u200d വിവരിച്ചുകൊടുക്കുന്നു. പദാവലികളുടെയും അറിവുകളുടെയും ബേസിന്റെയും പ്രത കെബിയില്\u200d ഒരു ടെക്സ്റ്റെന്\u200dറ് കൊടുത്താല്\u200d, ഞങ്ങള്\u200d ഞങ്ങളുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്\u200d പരിശീലിപ്പിക്കുന് നമ്മുടെ മോഡല്\u200d സാധാരണ പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു. വ്യത്യസ്തമായി NLP ജോലികളെ സംസാരിക്കാനുള് വിക്കിപിഡിയയില്\u200d നിന്നും പുറത്തുകൊണ്ടുവന്ന ഒരു വലിയ കോര്\u200dപ്പുസിനെയും ഉപയോഗിക്കുന്ന മോഡലിനെയും ഞങ്ങള്\u200d പരിശ പ്രധാനപ്പെട്ട NLP ജോലികളില്\u200d മൂന്ന് പ്രധാനപ്പെട്ട മോഡലിനെ ഞങ്ങള്\u200d വിലാസപ്പെടുത്തി (ഉദാഹരണത്തിന്റെ വാക്ക് ടെക്സ്കൂള്\u200d ടെക്സ്ട്രൂക്കല അതിന്റെ ഫലമായി, ഈ മൂന്ന് ജോലികളില്\u200d നമ്മള്\u200d സ്ഥിതിയുടെ ഫലങ്ങള്\u200d എത്തി. നമ്മുടെ കോഡും പരിശീലിക്കപ്പെട്ട മോഡലുകളും കൂടുതല്\u200d അക്കാഡിക്ക് ഗവേഷണത്തിന് പ്രസ്താവികമാണ്.', 'no': 'Vi skildrar eit neuralnettverksmodell som lærer samanlikt distribuert representasjonar av tekst og kunnskapsbasen (KB). Given ein tekst i KB, treng vi vår foreslått modell for å forhåndsvisa einingar som er relevant for teksten. Modellen vårt er designert for å vera generelt med kapasitet til å adressa ulike NLP- oppgåver med enkelt. Vi treng modellen med ein stor korpus av tekstar og entitetsnotasjonane deres utpakka frå Wikipedia. Vi evaluerte modellen på tre viktige NLP-oppgåver (t.d. setningsstyrkelikhet, eininga lenkje, og faktoidspørsmålssvar) med både ulike og oversikte innstillingar. I resultatet har vi oppnådd tilstanden av kunsten på alle tre av desse oppgåvene. Våre kode og trengte modeller er offentlig tilgjengeleg for fleire akademiske forskning.', 'pl': 'Opisujemy model sieci neuronowej, który wspólnie uczy się rozproszonych reprezentacji tekstów i podmiotów bazy wiedzy (KB). Biorąc pod uwagę tekst w KB, trenujemy nasz proponowany model do przewidywania istotnych dla tekstu podmiotów. Nasz model został zaprojektowany tak, aby był ogólny z możliwością łatwości realizacji różnych zadań NLP. Szkolimy model przy użyciu dużego korpusu tekstów i ich adnotacji jednostek wydobytych z Wikipedii. Oceniliśmy model na trzech ważnych zadaniach NLP (tj. podobieństwo tekstowe zdań, łączenie podmiotów i faktyczne odpowiedzi na pytania) obejmujących zarówno ustawienia bez nadzoru, jak i nadzorowane. W rezultacie osiągnęliśmy najnowocześniejsze wyniki we wszystkich trzech zadaniach. Nasz kod i przeszkolone modele są publicznie dostępne do dalszych badań akademickich.', 'ro': 'Descriem un model de rețea neurală care învață împreună reprezentări distribuite ale textelor și entităților bazei de cunoștințe (KB). Având în vedere un text în KB, pregătim modelul propus pentru a prezice entitățile relevante pentru text. Modelul nostru este conceput pentru a fi generic, cu capacitatea de a aborda diferite sarcini PNL cu ușurință. Instruim modelul folosind un corpus mare de texte și adnotările entității lor extrase din Wikipedia. Am evaluat modelul pe trei sarcini importante PNL (adică similaritatea textuală a propozițiilor, legătura entităților și răspunsul factoid la întrebări) care implică atât setări nesupravegheate, cât și cele supravegheate. Ca urmare, am obținut rezultate de ultimă generație în toate cele trei dintre aceste sarcini. Codul și modelele noastre instruite sunt disponibile public pentru cercetări academice suplimentare.', 'sr': 'Mi opisujemo model neuralne mreže koji zajedno uči raspodjeljene predstave tekstova i baze znanja (KB). S obzirom na tekst u KB-u, treniramo naš predloženi model da predvidimo entitete koje su relevantne za tekst. Naš model je dizajniran da bude generièan sa sposobnošæu da se olakša raznim NLP zadacima. Treniramo model koristeći veliki korpus tekstova i njihove annotacije entiteta izvučene iz Wikipedije. Procjenjivali smo model na tri važna NLP zadatka (tj. tekstualna sličnost rečenica, povezanost entiteta i odgovor na faktoidno pitanje) uključujući i neodređene i nadzorne nastave. Kao rezultat toga, postigli smo rezultate umjetnosti na svim tri zadatka. Naši kod i obučeni modeli su javno dostupni za daljnje akademske istraživanje.', 'si': 'අපි විස්තර කරන්නේ න්\u200dයූරල් ජාලයේ මොඩල් එක්කම ඉගෙන ගන්නේ පැත්ත සහ දන්න අධ්\u200dයානය (KB) වලින් වලින් ප්\u200dරතින Name අපේ මෝඩේල් සාමාන්\u200dය විදියට සාමාන්\u200dය විදියට හැකියෙන්න පුළුවන් විදියට NLP වැඩ කරන්න. අපි විකිපිඩියාවෙන් ප්\u200dරයෝජනය කරන්න පුළුවන් පැත්තක් සහ ඔවුන්ගේ ප්\u200dරයෝජනයක් පාවිච්චි කරනවා. අපි ලොකු NLP වැදගත් වැදගත් වැඩක් තුනක් විශ්වාස කරලා තියෙනවා (ඉතින්, වාක්ෂාව සම්බන්ධතාවක්, අයිතිය සහ ප්\u200dරශ්න ප්\u200dරශ්න උත්තර ද ඉතින්, අපිට මේ වැඩේ තුනක් විසින් ස්ථානය ප්\u200dරතිචාරයක් ලැබුනා. අපේ කෝඩ් සහ පුහුණුවන් විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාව', 'so': "Tusaale ahaan shabakadda neurada ah oo si wada jir ah u baranaya noocyada xarumaha iyo waxyaabaha aqoonta (KB). Sida uu qoro qoraal KB, waxaynu tababarinnaa modelkeeni la soo jeeday si aan u sii sheegno waxyaabaha la xiriira qoraalka. Tusaale ahaan waxaa loo qoray in uu noqdo mid caadi ah oo awood u leh in la hadlo shaqaalaha NLP oo kala duduwan si fudud. Tusaalada waxaynu ku tababarinnaa isticmaalka xarumaha farshaxanka badan iyo alaabtooda ee Wikipediya ka soo baxay. Tusaalada waxaan ku qiimeynay saddex shaqooyin oo muhiim ah e e NLP (tusaale ahaan xafiiska qoraalka ah, isku xiran, jidhka isku xiran iyo jawaabta su'aalka xaqiiqyada) oo ku saabsan labada heer oo aan ilaalinayn iyo ilaalinayn. Sababtaas darteed sadex shaqooyin oo dhan ayaannu helnay arimaha farshaxanka. Codeynta iyo modelalkayaga la tababaray waxay si bayaan ah u heli karaan waxbarasho dheeraad ah.", 'sv': 'Vi beskriver en neural nätverksmodell som gemensamt lär sig distribuerade representationer av texter och kunskapsbas (KB) entiteter. Med en text i KB tränar vi vår föreslagna modell för att förutsäga entiteter som är relevanta för texten. Vår modell är utformad för att vara generisk med förmågan att hantera olika NLP-uppgifter med lätthet. Vi tränar modellen med hjälp av en stor samling texter och deras entitetsanteckningar extraherade från Wikipedia. Vi utvärderade modellen på tre viktiga NLP-uppgifter (dvs meningens textlikhet, entitetslänkning och faktaundersökning) som involverar både oövervakade och övervakade inställningar. Som ett resultat uppnådde vi toppmoderna resultat på alla tre av dessa uppgifter. Vår kod och utbildade modeller är offentligt tillgängliga för vidare akademisk forskning.', 'ta': 'நாம் ஒரு புதிய வலைப்பின்னல் மாதிரியை விவரிக்கிறோம். அது ஒன்றாக உரைகள் மற்றும் அறிவு அடிப்படைகளின் பங்கிட்ட பகிர்ந KB யில் ஒரு உரையை கொடுத்தால், நாம் எங்கள் பரிந்துரைக்கப்பட்ட மாதிரியை பயிற்சி செய்து உரையுடன் தொடர்புடைய பொர எங்கள் மாதிரி சுலபமாக NLP பணிகளை பேசும் சக்தியுடன் பொதுவாக இருக்க வடிவமைக்கப்பட்டுள்ளது. நாம் ஒரு பெரிய உரைகள் மற்றும் விகிபிடியியாவிலிருந்து வெளியேற்றப்பட்ட உரையாடல் பெரிய அலங்காரங்களை பயன்படுத் பாதுகாப்பாக்கப்படாத மற்றும் கண்காணிக்கப்படாத அமைப்புகளுக்கும் மூன்று முக்கியமான NLP பணிகளில் மாதிரியை மதிப்பிட்டோம். முடிவில், நாங்கள் இந்த மூன்று பணிகளின் மாநிலையில் முடிவுகளை அடைந்தோம். எங்கள் குறியீடு மற்றும் பயிற்சி மாதிரிகள் மேலும் கல்வி ஆயாரம் கிடைக்கும்.', 'ur': 'ہم ایک نیورال نیٹ ورک موڈل کو توصیح دیتے ہیں جو متن اور علم بنسس (KB) ایٹنیٹیوں کی تقسیم کی تعلیم سکھاتا ہے۔ کیب میں ایک متن کے ذریعہ، ہم نے اپنی پیشنهاد کی موڈل کی تطارین کی کہ متن کے معاملہ میں موجودات کی پیشنهاد کریں. ہماری مدل آسانی کے ساتھ مختلف NLP کاموں کے بارے میں آسانی کے ساتھ کام کرنے کی قابلیت کے ساتھ عمومی ہونے کے لئے طراحی کی گئی ہے. ہم مدل کو ویکیپیڈیا سے اٹھایا گیا ہے ایک بڑے ٹیکسٹ کی کورپوس اور ان کی ایٹیٹ کی اظہار سے استعمال کرتے ہیں۔ ہم نے مدل کو تین اہم NLP کے کاموں پر (یعنی مجلس کی تفصیل برابری، اتنی اتصال کرنے والی اور فکتوئیڈ سؤال جواب دینے والی) کا ارزش کیا تھا جو ان دونوں کے ساتھ غیر قابل تحقیق اور تحقیق کی جگہ ہے۔ اس کے نتیجے میں ہم نے ان تین کاموں پر اثرات کا نتیجہ پہنچا۔ ہمارے کڈ اور تعلیم کی موڈل اضافہ علمی تحقیقات کے لئے ظاہر طور پر موجود ہیں.', 'mt': 'Aħna niddeskrivu mudell ta’ netwerk newrali li jitgħallem b’mod konġunt rappreżentazzjonijiet distribwiti ta’ testi u entitajiet tal-bażi tal-għarfien (KB). Minħabba test fil-KB, a ħna nħarrġu l-mudell propost tagħna biex nipprevedi entitajiet li huma rilevanti għat-test. Il-mudell tagħna huwa mfassal biex ikun ġeneriku bil-kapaċità li jindirizza diversi kompiti NLP faċilment. We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia.  Aħna evalwajna l-mudell fuq tliet kompiti important i tal-NLP (jiġifieri, similarità testwali tas-sentenza, rabta bejn l-entitajiet, u tweġiba għall-mistoqsijiet fattojdi) li jinvolvu kemm ambjenti mhux sorveljati kif ukoll superviżi. B’riżultat ta’ dan, kisbna riżultati l-aktar avvanzati dwar it-tliet kompiti kollha. Il-kodiċi tagħna u l-mudelli mħarrġa huma disponibbli pubblikament għal aktar riċerka akkademika.', 'uz': "Biz bir necha tarmoq modelini tahlil qilamiz. Ularni birlashtirishni o'rganamiz va textlar va илм bazasi (KB) obʼektlarining xususiyatlarini o'rganadi. KB'da matn ifodalari bilan, biz rivojlanadigan modelmizni taʼminlaydimiz va matn bilan bog'liq narsalarni oldin. Bizning modelimiz oddiy bilan boshqa NLP vazifalarini boshqarish imkoniyatini o'zgartirish imkoniyati bo'ladi. Biz modelni Wikipedia'dan chiqqan bir katta textlar va ma'lumot tajribalari bilan o'rganamiz. Biz uchta muhim NLP vazifalarda modelni qiymatlashimiz mumkin, maktab huddi bogʻlash va faktoid savol javobi bilan saqlash va taʼminlovlovchi moslamalar bilan. Biz shu hamma vazifalarning uchta vazifalar haqida saqlash natijalarini bajardik. Kodlash va o'rganilgan modellar faqat akademik tafitiyatlari uchun mavjud.", 'vi': 'Chúng tôi mô tả một mô hình mạng thần kinh mà học cùng nhau các bộ trình bày của các thực thể văn bản và kiến thức (KB). Dựa vào một văn bản trong KB, chúng tôi đào tạo mô hình đề xuất để dự đoán các thực thể liên quan đến cơ bản. Mẫu của chúng tôi được thiết kế để trở nên giống nhau với khả năng thực hiện các công việc kiểu sục sạo. Chúng tôi đào tạo mô hình này bằng một tập tin đầy đủ các văn bản và bản ghi chú thực thể từ Wikipedia. Chúng tôi đánh giá mô hình dựa trên ba công việc quan trọng của NMB (v.d., nét giống cấu trúc, liên kết thực thể, và câu hỏi Factionless) gồm cả những thiết lập không giám sát và giám sát. Kết quả là, chúng tôi đạt được kết quả hiện đại về ba nhiệm vụ này. Phần mã và mẫu được đào tạo của chúng tôi được công khai để nghiên cứu thêm.', 'da': 'Vi beskriver en neural netværksmodel, der i fællesskab lærer distribuerede repræsentationer af tekster og vidensbaserede enheder (KB). Med en tekst i KB træner vi vores foreslåede model til at forudsige enheder, der er relevante for teksten. Vores model er designet til at være generisk med evnen til at løse forskellige NLP-opgaver med lethed. Vi træner modellen ved hjælp af et stort korpus af tekster og deres entitetsnoter udvundet fra Wikipedia. Vi evaluerede modellen på tre vigtige NLP-opgaver (dvs. sætningernes tekstlighed, entitetslinkning og faktisk spørgsmål besvarelse), der involverer både upraverede og overvågede indstillinger. Som følge heraf opnåede vi topmoderne resultater på alle tre af disse opgaver. Vores kode og uddannede modeller er offentligt tilgængelige for yderligere akademisk forskning.', 'bg': 'Описваме модел на невронна мрежа, който съвместно изучава разпределени представи на текстове и обекти от базата на знания (КБ). Предвид текст в КБ, ние обучаваме нашия предложен модел за предсказване на обекти, които са от значение за текста. Нашият модел е проектиран да бъде генеричен с възможност да се справя с различни задачи на НЛП с лекота. Обучаваме модела с помощта на голям корпус от текстове и техните анотации на същността, извлечени от Уикипедия. Оценихме модела по три важни задачи на НЛП (т.е. текстово сходство на изреченията, свързване на entiтети и фактически отговор на въпроси), включващи както незаблюдавани, така и надзорни настройки. В резултат на това постигнахме най-съвременни резултати и по трите от тези задачи. Нашият код и обучени модели са публично достъпни за по-нататъшни академични изследвания.', 'hr': 'Mi opisujemo model neuralne mreže koji zajedno uči raspodjeljene predstave tekstova i znanstvenih podataka (KB). S obzirom na tekst u KB-u, treniramo naš predloženi model kako bi predvidjeli entitate koje su relevantne za tekst. Naš model je dizajniran da bude općenito s sposobnošću riješiti razne NLP zadatke lako. Vježbamo model koristeći veliki korpus tekstova i njihove oznake entiteta izvučene iz Wikipedije. Procjenjivali smo model na tri važna zadatka NLP-a (tj. tekstualna sličnost rečenica, povezanost entiteta i odgovor na faktoidno pitanje) uključujući i neodređene i nadzorne nastave. Kao rezultat toga, postigli smo rezultate države umjetnosti na svim tri zadatka. Naši kod i obučeni modeli su javno dostupni za daljnje akademske istraživanje.', 'id': 'Kami menggambarkan model jaringan saraf yang bersama-sama mempelajari representation distribusi dari teks dan dasar pengetahuan (KB) entitas. Mengingat teks dalam KB, kami melatih model kami untuk memprediksi entitas yang relevan untuk teks. Model kami dirancang untuk menjadi generik dengan kemampuan untuk mengatasi berbagai tugas NLP dengan mudah. Kami melatih model menggunakan banyak teks dan anotasi entitas mereka yang dikeluarkan dari Wikipedia. Kami mengevaluasi model pada tiga tugas penting NLP (i.e., persamaan tekstual kalimat, hubungan entitas, dan jawaban pertanyaan faktoid) yang melibatkan seting yang tidak diawasi dan diawasi. Sebagai hasilnya, kami mencapai hasil terbaik pada tiga tugas ini. Kode kami dan model terlatih tersedia publik untuk penelitian akademik lanjut.', 'nl': 'We beschrijven een neuraal netwerkmodel dat gezamenlijk gedistribueerde representaties van teksten en kennisbaseentiteiten leert. Gezien een tekst in de KB trainen we ons voorgestelde model om entiteiten te voorspellen die relevant zijn voor de tekst. Ons model is ontworpen om generiek te zijn met de mogelijkheid om verschillende NLP-taken met gemak aan te pakken. We trainen het model met behulp van een groot corpus van teksten en hun entiteitsannotaties uit Wikipedia. We hebben het model geëvalueerd op drie belangrijke NLP-taken (d.w.z. tekstuele gelijkenis van zinnen, entiteitskoppeling en factoïde vragenbeantwoording) waarbij zowel onbeheerde als begeleide instellingen betrokken zijn. Hierdoor hebben we bij alle drie deze taken state-of-the-art resultaten behaald. Onze code en getrainde modellen zijn openbaar beschikbaar voor verder academisch onderzoek.', 'ko': '우리는 학습 텍스트와 지식 라이브러리 (KB) 실체의 분포식 표시를 결합한 신경 네트워크 모델을 묘사했다.지식 라이브러리의 텍스트를 정하고 우리가 제시한 모델을 훈련시켜 텍스트와 관련된 실체를 예측한다.다양한 NLP 작업을 쉽게 처리할 수 있는 공통 모델입니다.우리는 위키백과에서 추출한 대량의 텍스트와 실체 주석을 사용하여 모형을 훈련시킨다.우리는 세 가지 중요한 NLP 임무(즉 문장-텍스트 유사성, 실체 링크와 인자 문답)에서 이 모델을 평가했는데 감독과 감독 설정이 없는 것을 포함한다.그래서 우리는 이 세 가지 임무에서 모두 가장 선진적인 성과를 거두었다.우리의 코드와 훈련을 거친 모델은 진일보한 학술 연구에 공개적으로 사용될 수 있다.', 'sw': 'Tunaelezea muundo wa mtandao wa neura ambao kwa pamoja wanajifunza uwakilizaji wa maandishi na vitu vya maarifa (KB). Kwa kutumia ujumbe wa maandishi kwenye KB, tunafundisha mtindo wetu unaopendekezwa kutabiri vitu ambavyo vina maandishi yanayohusiana na maandishi. Mradi wetu umeundwa kuwa wa kawaida na uwezo wa kuzungumza kazi mbalimbali za NLP kwa urahisi. Tunafundisha muundo huo kwa kutumia viungo vikubwa vya maandishi na matatizo yao yaliyotolewa kutoka Wikipedia. Tulifuatilia mfano wa kazi tatu muhimu za NLP (yaani hukumu inayofanana na uhalisia, yenye kuunganisha na majibu ya swali halisi) ikiwa ni pamoja na mazingira yasiyoelewekwa na kudhibitiwa. Matokeo yake, tulipata matokeo ya hali ya sanaa katika kazi zote tatu hizi. Kodi zetu na mifano ya mafunzo yanapatikana hadharani kwa ajili ya utafiti zaidi wa kitaaluma.', 'tr': 'Biz nöral a ğ modelini bir arada tekst we bilim tabanının (KB) hasaplanýar. KB-de bir metin görä, metin üçin baglanýan guramlary öňden geçirmek üçin teklibimizi tren edýäris. Biziň modelimiz dürli NLP işlerini aňsatlyk bilen çözmegi ukyp bilen döredildi. Biz nusgany Wikipediýadan çykyş edilen uly tekst korpusyny ulanyp öwredýäris. NLP üç möhüm zadynda nusgany çykdy (mysal. sözlem metinçe meňzeşliki, bir zat baglaşdyrma we faktoid soraglaryň jogabyny) hem garaşylmadyk we kontrol edilmegi bar. Sonuçta biz bu üç zadyň üstünde sanat taýýarlaryny ýetdik. Biziň kodymyz we bilim sistemalarymyz halkara öňündeki akademiki araştyrymyz üçin bar.', 'af': "Ons beskryf 'n neurale netwerk model wat saamstig leer verspreidige voorstellings van teks en kennis basis (Kb) entiteite. Gien 'n teks in die Kb, ons tref ons voorgestelde model om entiteite te voorskou wat relevant is aan die teks. Ons model is ontwerp om algemeen te wees met die moontlikheid om verskillende NLP taak te adres met maklik. Ons tref die model met 'n groot korpus van tekste en hul entiteit-notasies wat uit Wikipedia uitgevoer is. Ons evalueer die model op drie belangrike NLP-opdragte (t.d., voordeel tekstuele gelykenis, entiteit wat verkop en faktoide vraag antwoord) met beide onderwerp en onderwerp instellings. As 'n resultaat het ons die staat-van-kunsten-resultate op alle drie van hierdie taak bereik. Ons kode en opgevoerde modele is openlik beskikbaar vir verdere akademiese ondersoek.", 'de': 'Wir beschreiben ein neuronales Netzwerkmodell, das gemeinsam verteilte Repräsentationen von Texten und Wissensdatenbanken (KB) lernt. Ausgehend von einem Text in der KB trainieren wir unser vorgeschlagenes Modell, um Entitäten vorherzusagen, die für den Text relevant sind. Unser Modell ist so konzipiert, dass es generisch ist und verschiedene NLP-Aufgaben problemlos bewältigen kann. Wir trainieren das Modell anhand eines großen Korpus von Texten und deren Entitätenannotationen, die aus Wikipedia extrahiert wurden. Wir evaluierten das Modell anhand von drei wichtigen NLP-Aufgaben (d.h. Satztextähnlichkeit, Entitätsverknüpfung und faktoide Beantwortung von Fragen), die sowohl unbeaufsichtigte als auch überwachte Einstellungen betrafen. So konnten wir bei allen drei Aufgaben State-of-the-Art-Ergebnisse erzielen. Unser Code und unsere trainierten Modelle stehen öffentlich für weitere wissenschaftliche Forschung zur Verfügung.', 'am': 'የኔውራዊ መረብ ሞዴል እና የጽሑፎች እና እውቀት መሠረት (KB) አካባቢዎችን በተለየ ትክክል የሚተማርትን እናሳውቃለን፡፡ በ KB ጽሑፍ በመጠቀም፣ በተዘጋጀው የጽሑፉን አካላት ለመቀበል እናስተምራለን፡፡ ሞዴሌያችን በተለየ የNLP ስራዎችን በመቀናኘት የሚችል ስልጣን ለመሆን የተፈጠረ ነው፡፡ ምሳሌውን ከWikipedia የተወለደውን ትልቅ ጽሑፎች እና አካሄዳቸውን እናስተምራለን፡፡ በሦስት አስፈላጊ የNLP ስራ (ምሳሌ የጽሑፍ ትክክለኛ፣ አካባቢ ግንኙነት እና የውይይት ጥያቄ መልስ) ሞዴላውን በማይጠበቅና በተጠበቀው ግንኙነቶች እና በመጠበቅ ጥያቄዎችን አስተያየን፡፡ ይሄን በሦስቱ ስራ ሁሉ የ-የ-የ-ዐርድ ፍሬዎችን አግኝተናል፡፡ የኮድማችን እና የተማሩ ሞዴሎቻችን ለሌላ አስተማሪ ትምህርት የተገኙ ናቸው፡፡', 'hy': 'Մենք նկարագրում ենք նյարդային ցանցի մոդել, որը միասին սովորում է հաղորդագրությունների և գիտելիքի հիմքի (ԿԲ) առանձնահատկությունների բաշխված ներկայացումները: Ք.Բ-ի տեքստին հաշվի առնելով, մենք սովորեցնում ենք մեր առաջարկված մոդելը, որպեսզի կանխատեսենք էակներ, որոնք կարևոր են տեքստին: Մեր մոդելը ստեղծված է այնպես, որ ընդհանուր է, որպեսզի հնարավորություն լինի հեշտությամբ լուծել բազմաթիվ ՆԼՊ խնդիրներ: We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia.  Մենք գնահատեցինք մոդելը երեք կարևոր ՆԼՊ-ի առաջադրանքների վրա (այսինքն, նախադասությունների տեքստային նմանությունը, միավորների կապը և փակտային հարցերի պատասխանը), որոնք ներառում են ոչ վերահսկված, ոչ էլ վերահսկված միջոցներ: Արդյունքում, մենք հասանք ամենաբարձր արդյունքներ այս երեք խնդիրների վրա: Մեր կոդը և պատրաստված մոդելները հանրային հասանելի են ավելի շատ ակադեմիական հետազոտությունների համար:', 'sq': 'Ne përshkruajmë një model rrjeti nervor që mëson së bashku përfaqësime të shpërndara të teksteve dhe njësive të bazës së njohurive (KB). Duke dhënë një tekst në KB, ne trajnojmë model in tonë të propozuar për të parashikuar njësitë që janë të rëndësishme për tekstin. Modeli ynë është dizajnuar për të qenë gjenerik me aftësinë për të trajtuar me lehtësi detyra të ndryshme NLP. We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia.  Ne e vlerësuam modelin në tre detyra të rëndësishme NLP (pra, ngjashmëri tekstuale të fjalëve, lidhje e njësisë dhe përgjigje e pyetjeve faktoide) duke përfshirë si rregullime të pazgjidhura dhe të mbikqyrura. Si rezultat, arritëm rezultate më të larta në të tre detyrat. Kodi ynë dhe modelet tona të trajnuar janë në dispozicion publik për kërkime të mëtejshme akademike.', 'bn': 'আমরা একটি নিউরেল নেটওয়ার্ক মডেল বর্ণনা করি যা একসাথে লেখা এবং জ্ঞানের বিভিন্ন বস্তুর প্রতিনিধি বিতরণ শিখে থাকে। কেবিতে একটি টেক্সট দিয়ে আমরা আমাদের প্রস্তাবিত মডেল প্রশিক্ষণ দিয়েছি ভবিষ্যদ্বাণী করার জন্য যারা লেখার সাথে যুক আমাদের মডেলটি সৌন্দর্যের সাথে বিভিন্ন এনএলপি কাজ সহজে কথা বলতে সক্ষম হবে। আমরা উইকিপিডিয়া থেকে বেরিয়ে যাওয়া একটি বিশাল ল লেখা এবং তাদের বস্তুর বিষয়বস্তু ব্যবহার করে মডেলের প্রশিক্ষণ দেই। আমরা তিনটি গুরুত্বপূর্ণ এনএলপি কাজের উপর মডেল মূল্য দিয়েছি (যেমন বাক্য টেক্সটুয়াল টেক্সচুয়ালের সমতুল্য, বস্তুর লিংক এবং ফ্যাক্টোড প্রশ্নের উত এর ফলে আমরা এই সমস্ত তিনটি কাজের উপর শিল্পের রাষ্ট্রের ফলাফল অর্জন করেছি। আরো একাডেমিক গবেষণার জন্য আমাদের কোড এবং প্রশিক্ষিত মডেল প্রকাশ করা হয়েছে।', 'bs': 'Mi opisujemo model neuralne mreže koji zajedno uči raspodjeljene predstave tekstova i baze znanja (KB). S obzirom na tekst u KB-u, treniramo naš predloženi model da predvidimo entitate koje su relevantne za tekst. Naš model je dizajniran da bude generičan sa sposobnošću da se olakša riješimo različitim NLP zadacima. Treniramo model koristeći veliki korpus tekstova i njihove oznake entiteta izvučene iz Wikipedije. Procjenjivali smo model na tri važna zadatka NLP-a (tj. tekstualna sličnost rečenica, povezanost entiteta i odgovor na faktoidno pitanje) uključujući i neodređene i nadzorne nastave. Kao rezultat toga, postigli smo rezultate države umjetnosti na svim tri zadatka. Naši kod i obučeni modeli su javno dostupni za daljnje akademske istraživanje.', 'fa': 'ما یک مدل شبکه عصبی را توصیف می\u200cکنیم که با هم نمایش\u200cهای جدایی از متن\u200cها و پایگاه علم\u200cها (KB) را یاد می\u200cگیرد. با توجه به یک متن در کیب، ما مدل پیشنهاد خود را آموزش می دهیم تا ابزارهای متن را پیش بینی کنیم. مدل ما طراحی شده است که با توانایی با آسانی به کار های مختلف NLP بررسی کنیم. ما مدل را با استفاده از یک کورپوس بزرگ از متن\u200cها و اعلام\u200cهایشان از ویکیپدیا خارج شده تمرین می\u200cکنیم. ما مدل را در سه کار مهم NLP ارزیابی کردیم (یعنی مشابه\u200cای از جمله\u200cهای متن، ارتباط\u200cهای متن\u200cجمله\u200cای و جواب سوال\u200cهای فاکتوئید) که شامل تنظیم\u200cهای غیرقابل تحت نظر و تحت نظر است. به نتیجه، نتیجه\u200cهای ایالت هنری را در تمام سه تا از این کار رسیدیم. رمز و مدل آموزش ما برای تحقیقات علمی بیشتری در دسترس عمومی هستند.', 'az': 'Biz məktub və elm bazı (KB) mətnlərin dağıtılmış tərzlərini öyrənən nöral a ğ modelini təsdiqləyirik. KB-də yazılmış məktub təhsil etdiyimiz modelləri məktubla əlaqəsiz olan məlumatları təhsil etmək üçün təhsil edirik. Bizim modelimiz müxtəlif NLP işlərini asanlıqla çəkməyə qadir olmaq üçün müəyyən edilmişdir. Biz modeli Wikipediyadan çıxarılan böyük mətn korpusu və mətnlərini istifadə edirik. Biz model i üç möhüm NLP i şlərində değerlendirdik (məsələn, sözlərin məlumatı, bağlantı və faktoid sual cavab vermək üçün) həmçinin müdafiə edilməmiş və nəzarət edilməmiş qurğular barəsində. Sonuç olaraq, biz bu üç işin sonuçlarına müvəffəq etdik. Bizim kodumuz və təhsil modellərimiz artıq akademik araştırmaları üçün yayınlaşdırılır.', 'et': 'Kirjeldame närvivõrgu mudelit, mis õpib ühiselt teksti ja teadmistebaasi (KB) olemuste hajutatud esitusi. Arvestades KB-s olevat teksti, koolitame oma kavandatud mudelit, et ennustada teksti jaoks asjakohaseid üksusi. Meie mudel on loodud nii, et see on üldine ja võimaldab lihtsalt käsitleda erinevaid NLP ülesandeid. Me treenime mudelit, kasutades suurt tekstikorpust ja nende olemi annotatsioone, mis on välja võetud Wikipediast. Hindasime mudelit kolmel olulisel NLP ülesandel (st lausete teksti sarnasus, olemuse sidumine ja faktiline küsimustele vastamine), mis hõlmasid nii järelevalveta kui ka järelevalveta seadeid. Selle tulemusena saavutasime kõigi kolme ülesande puhul tipptasemel tulemusi. Meie kood ja koolitatud mudelid on avalikult kättesaadavad edasisteks akadeemilisteks uuringuteks.', 'fi': 'Kuvaamme neuroverkkomallia, joka oppii yhdessä hajautettuja esityksiä teksteistä ja tietopohjan (KB) kokonaisuuksista. KB:ssä olevan tekstin perusteella harjoittelemme ehdotettua mallia ennustamaan tekstin kannalta merkityksellisiä kokonaisuuksia. Mallimme on suunniteltu yleisluonteiseksi, sillä se pystyy käsittelemään erilaisia NLP-tehtäviä helposti. Koulutamme mallia käyttämällä suurta tekstikorpusta ja niiden entiteettimerkintöjä Wikipediasta. Mallia arvioitiin kolmella tärkeällä NLP-tehtävällä (lauseiden tekstien samankaltaisuus, entiteettilinkitys ja faktoidinen kysymysvastaus) sekä valvomattomalla että valvotulla tavalla. Tuloksena saavutimme huipputason tulokset kaikissa kolmessa tehtävässä. Koodimme ja koulutetut mallit ovat julkisesti saatavilla jatkotutkimusta varten.', 'ca': "Descrivem un model de xarxa neural que aprenen conjuntament representacions distribuïdes de textos i entitats de base de coneixement (KB). Dant un text al KB, entrenem el nostre model proposat per predir entitats que són rellevants al text. El nostre model està dissenyat per ser genèric amb l'habilitat d'abordar amb fàcil diverses tasques del NLP. Ensenyem el model fent servir un gran cos de textos i anotacions de la seva entitat extraïdes de Wikipedia. Vam evaluar el model en tres tasques importants de NLP (és a dir, similitud textual de frases, vinculació d'entitats i resposta a preguntes factoides) que implicaven configuracions no supervisades i supervisades. Com a resultat, vam aconseguir resultats més avançats en totes les tres tasques. El nostre codi i models entrenats estan a disposició del públic per a continuar la recerca acadèmica.", 'cs': 'Popisujeme model neuronové sítě, který se společně učí distribuované reprezentace textů a entit znalostní báze (KB). Vzhledem k textu v KB trénujeme náš navržený model tak, aby předpovídal entity, které jsou pro text relevantní. Náš model je navržen tak, aby byl obecný se schopností řešit různé NLP úkoly s lehkostí. Model trénujeme pomocí velkého korpusu textů a jejich anotací extrahovaných z Wikipedie. Model jsme hodnotili na třech důležitých NLP úlohách (tj. textová podobnost vět, linkování entit a faktoidní odpověď na otázky) zahrnujících jak bez dohledu, tak i kontrolovaná nastavení. V důsledku toho jsme dosáhli nejmodernějších výsledků ve všech třech těchto úkolech. Náš kód a školené modely jsou veřejně dostupné pro další akademický výzkum.', 'jv': 'Awakdhéwé éntuk sistem netwark taung nggawe ngupakan seneng pisan kelangan anyar tentang karo nggawe layang seneng pisan (K) Nanging tèks nang kB,awak dhéwé luwih akeh model sing tolunggawe kanggo ngerasai Entèraksi sing gagal kanggo teks. model sing dibenalke sampeyan karo akeh kapan kanggo sampeyan operasi NLP karo akeh barang. Awak dhéwé luwih akeh model ngono akeh dumadhi batir ditambah karo ngono cah-cah dumadhi sing ujaran akhir winih Awak dhéwé éntuk sistem sing wis ana ing telu nggawe NLP luwih (dadi, seneng langgambar textual, saiki nggambar, lan ingkang karo paketekno) sing isiné perusahaan gambar gak dhéwé, iso nggawe ngubah sing wis nguasai nggawe nguasai sistêm nggawe caret nggawe. Rasané, awak dhéwé wis ngerasakno state-of-the-arts barang kanggo kalah basa iki dadi. Awakdhéwé karo model sing ditresaké publik gawe kanggo resaké akadémik.', 'ha': "Tuna bayyana wani misali na'urar neural wanda ke iya sanar da shi da ake gaura masu gaura wa misalin littattafai da maɓallin ilmi (KB). Gida wani matsayi cikin KB, za mu kõre misalinmu wanda aka buƙata dõmin ka yi bayani ga abubuwa da ke da amfani da matsayin. Ana designe misalinmu dõmin a iya zama jeniya da awon a yi magana ga aikin NLP-wasu da ke sauƙi. We train the model using a large corpus of texts and their entity annotations extracted from Wikipedia.  Mun ƙaddara shirin a kan aikin NLP masu muhimmi uku (misali, misali misalin matsayi, masu haɗi da abun da kuma masu tambayi faktoid) wanda ke cikin tsarin da ba'a tsare da kuma an tsare su ba. Kayya, mun sami matsayin-sanar duk aikin waɗannan uku. Kodĩniyarmu da misalin an sanar da su ana samu zuwa ga tafarkin akada.", 'he': 'אנחנו מתארים מודל רשת עצבית שלמד ביחד מייצגים מרוחקים של טקסטים ובסיס הידע (KB). Given a text in the KB, we train our proposed model to predict entities that are relevant to the text.  המודל שלנו מעוצב כדי להיות גנרלי עם היכולת להתמודד עם משימות NLP שונות בקלות. אנחנו מאמן את המודל באמצעות גופוס גדול של טקסטים והציונים של היחידות שלהם מווצאים מוויקיפדיה. הערכנו את המודל על שלושה משימות חשובות של NLP (כלומר, דמיון טקסטי משפט, קשר יחידה, ומעניין על שאלות פקטואידיות) שמעורבים גם את ההגדרות הלא מעוקבות ושופעות. כתוצאה מכך, השגנו תוצאות חדשות בכל שלושת המשימות האלה. הקוד שלנו ודוגמנים מאומנים זמינים לציבור למחקר אקדמי נוסף.', 'sk': 'Opisujemo model nevronskega omrežja, ki skupaj uči porazdeljene predstavitve besedil in subjektov baze znanja (KB). Glede na besedilo v KB usposabljamo naš predlagani model za napovedovanje entitet, ki so pomembne za besedilo. Naš model je zasnovan tako, da je generičen z zmožnostjo enostavnega obravnavanja različnih nalog NLP. Model treniramo z velikim korpusom besedil in njihovimi entitetnimi opombami, pridobljenimi iz Wikipedije. Model smo ocenili na treh pomembnih nalogah NLP (tj. besedilna podobnost stavkov, povezovanje entitet in dejansko odgovarjanje na vprašanja), ki so vključevale tako nenadzorovane kot nadzorovane nastavitve. Zato smo dosegli najsodobnejše rezultate pri vseh treh nalogah. Naš kodeks in usposobljeni modeli so javno dostopni za nadaljnje akademske raziskave.', 'bo': 'ང་ཚོས་ཡིག་ཚགས་དང་ཤེས་པའི་དབྱིབས་དཔེ་དབྱིབས་ཡིག KB་ཐོག་གི་ཡི་གེའི་ནང་དུ་ང་ཚོའི་མ་དབྱིབས་སྔོན་འཆར་བྱེད་ཀྱི་རྣམ་པ་ཞིག་ལ་ཡི་གེའི་གནས་ཚུལ་མཐུན་དང་། ང་ཚོའི་མ་གཟུགས་རིས་འདི་ལ་སྤྱིར་བཏང་བའི་རྐྱེན་ཚད་དང་མཐུན་རྐྱེན་བྱས་པ་ཡིན་པས། ང་ཚོས་མ་དབྱིབས་གྱི་རྣམ་པ་ཞིག་ཡིག་གི་འབྲེལ་བ་ཆེན་པོ་ཞིག་དང་ཁོ་ཚོའི་དབང་འབྲེལ་གྱི་བསྐུལ་སྒྲུབ་ཀྱི་ཕྱི་ཁ ང་ཚོས་NLP གལ་ཆེན་གྱི་བྱ་འགུལ་གསུམ་ཀྱི་མིག་གཟུགས་རིས་དཔྱད་བྱས་ན། ཚིག་ཡིག་གི་མཐུན་དང་། འབྲེལ་མཐུད་དང་། ཡིག་ཆ་རྐྱེན་དུ་འདྲི་ཚིག་ལ་ལན་ དབྱངས་འབྲས་ན། འུ་ཚོས་བྱ་འགུལ་འདི་གསུམ་ལས་རྒྱལ་ཁབ་བཀོད་པའི་གནས་སྟངས་མང་པོར་ཡོད་པ་རེད། ང་ཚོའི་སྔོན་འཛིན་གྱི་ཨང་དང་སྒྲིག་འཛིན་པའི་མིག་གཟུགས་རིས་མང་ཙམ་སྤྱོད་ཀྱི་ཡོད།'}
{'en': 'Evaluating Low-Level Speech Features Against Human Perceptual Data', 'ar': 'تقييم سمات الكلام منخفضة المستوى مقابل البيانات الإدراكية البشرية', 'es': 'Evaluación de las características del habla de bajo nivel contra los datos perceptuales humanos', 'fr': 'Évaluation des caractéristiques vocales de bas niveau par rapport aux données perceptuelles humaines', 'pt': 'Avaliando recursos de fala de baixo nível em relação a dados de percepção humana', 'zh': '因人知数', 'ja': '人間の知覚データに対する低レベルの発話機能の評価', 'hi': 'मानव अवधारणात्मक डेटा के खिलाफ निम्न-स्तरीय भाषण सुविधाओं का मूल्यांकन करना', 'ru': 'Оценка низкоуровневых речевых характеристик в сравнении с данными человеческого восприятия', 'ga': 'Gnéithe Cainte Íseal a Mheas i gCoinne Sonraí Dearcadh Daonna', 'ka': 'ადამიანის პერსპექტიულ მონაცემების შესახებ საუკეთესო საუკეთესო საუკეთესო', 'el': 'Αξιολόγηση χαρακτηριστικών ομιλίας χαμηλού επιπέδου έναντι δεδομένων ανθρώπινης αντίληψης', 'hu': 'Az alacsony szintű beszédfunkciók értékelése az emberi érzékelési adatok alapján', 'it': 'Valutazione delle caratteristiche vocali di basso livello contro i dati percettivi umani', 'mk': 'Оценувањето на лошото ниво на јазикот против човековите перцептуални податоци', 'lt': 'Evaluating Low-Level Speech Features Against Human Perceptual Data', 'kk': 'Төменгі деңгейіндегі сөйлеу мүмкіндіктерін адамдардың процептуалды деректеріне қарсы оқу', 'ms': 'Mengevaluasi Ciri-ciri Cahaya Aras Rendah terhadap Data Perceptual Manusia', 'ml': 'മനുഷ്യരുടെ വിവരങ്ങള്\u200dക്കെതിരെ കുറഞ്ഞ നില വാക്കുകളുടെ വിശേഷതകള്\u200d പരിഗണിക്കുന്നു', 'mt': 'L-evalwazzjoni tal-karatteristiċi tal-kelma ta’ livell baxx kontra d-Dejta Perċettwali tal-Bniedem', 'mn': 'Бага түвшинд ярианы талаар хүн төрөлхтний мэдээллийн эсрэг', 'no': 'Evaluerer talefunksjonar på låg nivå mot menneskelige prosektekte data', 'pl': 'Ocena funkcji mowy niskiego poziomu na tle danych percepcyjnych człowieka', 'ro': 'Evaluarea caracteristicilor de vorbire la nivel scăzut în raport cu datele perceptive umane', 'sr': 'Evaluacija karakteristika govora na niskoj nivou protiv ljudskih proceptualnih podataka', 'so': 'Against Human Perceptual Data', 'sv': 'Utvärdering av lågnivåtalfunktioner mot mänskliga perceptuella data', 'ta': 'மனித செயல் தகவலுக்கு எதிரான குறைந்த மட்டத்தில் பேச்சு பண்புகளை மதிப்பிடுகிறது', 'si': 'මනුෂ්\u200dය ප්\u200dරතිශීල දත්ත විරුද්ධයෙන් අඩු තත්වයට කතා කරන්න අවශ්\u200dය', 'ur': 'کم سطح بات کا ارزش انسان کی پرسپٹولی ڈاٹے کے مقابلہ میں', 'uz': 'Name', 'vi': 'Đánh giá yếu tố phát ngôn thấp đối với cá nhận thức con người', 'bg': 'Оценка на функциите на говора на ниско ниво спрямо човешките възприятия', 'da': 'Evaluering af talefunktioner på lavt niveau mod menneskelige perceptuelle data', 'hr': 'Procjenjivanje karakteristika govora na niskoj nivou protiv ljudskih proceptnih podataka', 'nl': 'Evaluatie van spraakfuncties op laag niveau tegen menselijke perceptuele gegevens', 'de': 'Bewertung von Low-Level-Sprachfunktionen anhand menschlicher Wahrnehmungsdaten', 'ko': '인류 감지 데이터에 근거하여 저급 음성 특징을 평가하다', 'fa': 'ارزیابی ویژه\u200cهای سخنرانی سطح پایین علیه داده\u200cهای منطقی انسان', 'af': 'Name', 'id': 'Mengevaluasi Features Speech Low-Level terhadap Data Perceptual Manusia', 'sw': 'Kupima Tamko za Hotuba za Kiwango cha chini dhidi ya Takwimu za Perizo za Binadamu', 'tr': 'Adamlar Proseptual Maglumaty Gaýratyn düşük dereje Sözler', 'hy': 'Նվագ մակարդակի խոսքի առանձնահատկությունների գնահատումը մարդկային ընկալելի տվյալների դեմ', 'sq': 'Vlerësimi i funksioneve të fjalimit të nivelit të ulët kundër të dhënave perceptive njerëzore', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'bs': 'Procjenjivanje karakteristika govora na niskoj nivou protiv ljudskih proceptualnih podataka', 'ca': 'Evaluar les característiques de discurs de baix nivell contra les dades perceptives humanes', 'et': 'Madala taseme kõnefunktsioonide hindamine inimese tajumise andmete põhjal', 'cs': 'Hodnocení funkcí nízké úrovně řeči proti lidským perceptuálním datům', 'az': 'İnsan Perseptual Data Against aşağı səviyyə Sözü Özünü Qüdrətləndirir', 'fi': 'Matalan tason puheominaisuuksien arviointi ihmisen havaintotietoja vastaan', 'bn': 'মানুষের প্রাপ্ত তথ্যের বিরুদ্ধে নিম্ন- স্তরের ভাষণের বৈশিষ্ট্য পরিমাপ করা হচ্ছে', 'jv': 'Wanda kuwi nggambar Keterangan sing Nisro Layar Gak Percetual data', 'ha': 'KCharselect unicode block name', 'sk': 'Ocena značilnosti govora na nizki ravni glede na človeške percepcijske podatke', 'he': 'הערכה של אופייני דיבור רמה נמוכה נגד נתונים ראויים אנושיים', 'bo': 'མིའི་རྒྱ་བསྐྱེད་ཚད་ལྟར་ཉུང་བའི་ཁ་ཤས་ཀྱི་ཆོས་ཉིད་ཅིག་གིས་'}
{'en': 'We introduce a method for measuring the correspondence between low-level speech features and human perception, using a cognitive model of speech perception implemented directly on speech recordings. We evaluate two speaker normalization techniques using this method and find that in both cases, speech features that are normalized across speakers predict human data better than unnormalized speech features, consistent with previous research. Results further reveal differences across normalization methods in how well each predicts human data. This work provides a new framework for evaluating low-level representations of speech on their match to human perception, and lays the groundwork for creating more ecologically valid models of speech perception.', 'ar': 'نقدم طريقة لقياس التطابق بين ميزات الكلام منخفضة المستوى والإدراك البشري ، باستخدام نموذج معرفي لإدراك الكلام يتم تنفيذه مباشرة على تسجيلات الكلام. نقوم بتقييم طريقتين لتطبيع المتحدثين باستخدام هذه الطريقة ووجدنا أنه في كلتا الحالتين ، تتنبأ ميزات الكلام التي يتم تطبيعها عبر المتحدثين بالبيانات البشرية بشكل أفضل من ميزات الكلام غير الطبيعية ، بما يتوافق مع البحث السابق. تكشف النتائج أيضًا عن الاختلافات عبر طرق التطبيع في مدى جودة توقع كل منها للبيانات البشرية. يوفر هذا العمل إطارًا جديدًا لتقييم التمثيلات منخفضة المستوى للكلام على مطابقتها للإدراك البشري ، ويضع الأساس لإنشاء المزيد من النماذج الصالحة بيئيًا لإدراك الكلام.', 'es': 'Presentamos un método para medir la correspondencia entre las características del habla de bajo nivel y la percepción humana, utilizando un modelo cognitivo de percepción del habla implementado directamente en las grabaciones de voz. Evaluamos dos técnicas de normalización de hablantes utilizando este método y descubrimos que, en ambos casos, las características del habla que se normalizan entre los hablantes predicen los datos humanos mejor que las características del habla no normalizadas, de acuerdo con investigaciones anteriores. Los resultados revelan además diferencias entre los métodos de normalización en cuanto a la forma en que cada uno predice los datos humanos. Este trabajo proporciona un nuevo marco para evaluar las representaciones de bajo nivel del habla en su correspondencia con la percepción humana, y sienta las bases para crear modelos de percepción del habla más válidos desde el punto de vista ecológico.', 'fr': "Nous présentons une méthode de mesure de la correspondance entre les caractéristiques vocales de bas niveau et la perception humaine, à l'aide d'un modèle cognitif de perception de la parole implémenté directement sur les enregistrements vocaux. Nous évaluons deux techniques de normalisation des locuteurs à l'aide de cette méthode et nous avons constaté que, dans les deux cas, les caractéristiques vocales normalisées entre les locuteurs prédisent mieux les données humaines que les caractéristiques vocales non normalisées, conformément aux recherches précédentes. Les résultats révèlent également des différences entre les méthodes de normalisation quant à la façon dont chacune prédit les données humaines. Ce travail fournit un nouveau cadre pour évaluer les représentations de bas niveau de la parole en fonction de leur correspondance avec la perception humaine, et jette les bases de la création de modèles de perception de la parole plus valables sur le plan écologique.", 'pt': 'Apresentamos um método para medir a correspondência entre características de fala de baixo nível e percepção humana, usando um modelo cognitivo de percepção de fala implementado diretamente em gravações de fala. Avaliamos duas técnicas de normalização de falantes usando esse método e descobrimos que, em ambos os casos, os recursos de fala normalizados entre os falantes predizem dados humanos melhor do que os recursos de fala não normalizados, consistente com pesquisas anteriores. Os resultados revelam ainda diferenças entre os métodos de normalização em quão bem cada um prevê dados humanos. Este trabalho fornece uma nova estrutura para avaliar representações de baixo nível da fala em sua correspondência com a percepção humana e estabelece as bases para a criação de modelos ecologicamente mais válidos de percepção da fala.', 'ja': '音声録音に直接実装された音声知覚の認知モデルを用いて、低レベルの音声特徴と人間の知覚との対応関係を測定する方法を紹介する。私たちは、この方法を使用して２つのスピーカー正規化技術を評価し、両方の場合において、スピーカー全体で正規化されている音声特徴が、非正規化された音声特徴よりも人間のデータをより良く予測していることを発見し、これまでの研究と一致している。結果は、各々がヒトデータをどの程度うまく予測するかにおける正規化方法間の差異をさらに明らかにする。この研究は、人間の知覚と一致する低レベルの音声表現を評価するための新しい枠組みを提供し、より生態学的に有効な音声知覚モデルを作成するための基礎を築きます。', 'zh': '我们说了一种测量低级语音特征与人感知的法术,用直在语音记上的语音感知认识。 以此论二言人归一化术,见此二者,言者归一化语音特征比非规范化语音特征,占人数据,与前同也。 更明归一化法在占候之数。 此论语音之卑者,与人知匹而新框架之,创更具生态有效性之音而始基焉。', 'hi': 'हम भाषण रिकॉर्डिंग पर सीधे लागू किए गए भाषण धारणा के संज्ञानात्मक मॉडल का उपयोग करके निम्न-स्तरीय भाषण सुविधाओं और मानव धारणा के बीच पत्राचार को मापने के लिए एक विधि पेश करते हैं। हम इस विधि का उपयोग करके दो स्पीकर सामान्यीकरण तकनीकों का मूल्यांकन करते हैं और पाते हैं कि दोनों मामलों में, भाषण विशेषताएं जो वक्ताओं में सामान्यीकृत होती हैं, पिछले शोध के अनुरूप, सामान्यीकृत भाषण सुविधाओं की तुलना में मानव डेटा की बेहतर भविष्यवाणी करती हैं। परिणाम आगे सामान्यीकरण विधियों में अंतर को प्रकट करते हैं कि प्रत्येक मानव डेटा की कितनी अच्छी तरह से भविष्यवाणी करता है। यह काम मानव धारणा के लिए अपने मैच पर भाषण के निम्न-स्तरीय प्रतिनिधित्व का मूल्यांकन करने के लिए एक नया ढांचा प्रदान करता है, और भाषण धारणा के अधिक पारिस्थितिक रूप से मान्य मॉडल बनाने के लिए आधार तैयार करता है।', 'ru': 'Введем метод измерения соответствия низкоуровневых речевых признаков восприятию человека, используя когнитивную модель восприятия речи, реализованную непосредственно на речевых записях. Мы оцениваем два метода нормализации динамиков с помощью этого метода и обнаруживаем, что в обоих случаях речевые функции, которые нормализуются между говорящими, предсказывают человеческие данные лучше, чем ненормализованные речевые функции, что согласуется с предыдущими исследованиями. Результаты дополнительно выявляют различия между методами нормализации в том, насколько хорошо каждый предсказывает данные человека. Эта работа обеспечивает новую основу для оценки низкоуровневых представлений речи на их соответствие человеческому восприятию и закладывает основу для создания более экологически обоснованных моделей восприятия речи.', 'ga': 'Tugaimid isteach modh chun an comhfhreagras idir gnéithe cainte ísealleibhéil agus dearcadh an duine a thomhas, ag baint úsáide as samhail chognaíoch de aireachtáil cainte a chuirtear i bhfeidhm go díreach ar thaifeadtaí cainte. Déanaimid meastóireacht ar dhá theicníc normalaithe cainteoir ag baint úsáide as an modh seo agus aimsímid sa dá chás, go ndéanann gnéithe cainte a normalaítear ar fud na gcainteoirí sonraí daonna a thuar níos fearr ná gnéithe cainte neamhnormalaithe, ag teacht le taighde roimhe seo. Léiríonn torthaí a thuilleadh difríochtaí trasna modhanna normalaithe maidir le cé chomh maith agus a dhéanann gach ceann díobh sonraí daonna a thuar. Soláthraíonn an obair seo creat nua chun ionadaíochtaí cainte ar leibhéal íseal a mheas ar a gcomhoiriúnú le dearcadh an duine, agus leagann sé síos an bhunchloch chun múnlaí braistintí cainte atá níos bailí ó thaobh na héiceolaíochta de a chruthú.', 'el': 'Παρουσιάζουμε μια μέθοδο μέτρησης της αντιστοιχίας μεταξύ των χαρακτηριστικών χαμηλού επιπέδου ομιλίας και της ανθρώπινης αντίληψης, χρησιμοποιώντας ένα γνωστικό μοντέλο αντίληψης ομιλίας που υλοποιείται απευθείας σε ηχογραφήσεις ομιλίας. Αξιολογούμε δύο τεχνικές ομαλοποίησης ομιλητών χρησιμοποιώντας αυτή τη μέθοδο και διαπιστώνουμε ότι και στις δύο περιπτώσεις, χαρακτηριστικά ομιλίας που είναι ομαλοποιημένα μεταξύ των ομιλητών προβλέπουν τα ανθρώπινα δεδομένα καλύτερα από τα μη φυσιολογικά χαρακτηριστικά ομιλίας, σύμφωνα με προηγούμενες έρευνες. Τα αποτελέσματα αποκαλύπτουν περαιτέρω διαφορές μεταξύ των μεθόδων ομαλοποίησης στο πόσο καλά προβλέπουν τα ανθρώπινα δεδομένα. Η εργασία αυτή παρέχει ένα νέο πλαίσιο για την αξιολόγηση των χαμηλού επιπέδου αναπαραστάσεων της ομιλίας σχετικά με την αντιστοιχία τους με την ανθρώπινη αντίληψη, και θέτει τις βάσεις για τη δημιουργία πιο οικολογικά έγκυρων μοντέλων αντίληψης της ομιλίας.', 'hu': 'Bevezetünk egy módszert az alacsony szintű beszédjellemzők és az emberi érzékelés kapcsolatának mérésére, a beszédérzékelés kognitív modelljét közvetlenül a beszédfelvételeken alkalmazva. Ezzel a módszerrel két hangszóró normalizációs technikát értékelünk, és megállapítjuk, hogy mindkét esetben a hangszórók között normalizált beszédfunkciók jobban előrejelzik az emberi adatokat, mint a nem formált beszédfunkciók, összhangban a korábbi kutatásokkal. Az eredmények továbbá feltárják a normalizációs módszerek közötti különbségeket abban, hogy mennyire jól előrejelzik az emberi adatokat. Ez a munka új keretet biztosít az alacsony szintű beszédreprezentációk értékeléséhez az emberi érzékeléshez való illeszkedésük alapján, és lefekteti az alapot a beszédérzékelés ökológiailag érvényesebb modelljeinek kialakításához.', 'ka': 'ჩვენ ჩვენ შევაჩვენეთ მეტი, რომელიც კონპორციენტის სიტყვების ფუნქციები და ადამიანის სიტყვების შორის შეზემობისათვის, რომელიც კონციგური მოდელს სიტყვების სიტყვე ჩვენ ორი სიტყვების ნორმალიზაციის ტექნონიკის გამოყენება და აღმოჩნეთ, რომ ორივე შემთხვევაში სიტყვების ფუნქციები, რომლებიც ნორმალიზებულია სტყვების განმავლობაში, ადამიანის მონაც შედეგი შედეგი განსხვავება ნორმალიზაციის მეტოვების განსხვავებაში, როგორც ყოველ ადამიანის მონაცემების განსხვავება. ეს სამუშაო ახალი პარამეტრის გაუმუშავება საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთესო მოდელების შექ', 'kk': 'Біз сөйлеу мүмкіндіктері мен адамдардың түсініктері арасындағы сәйкестіктерді өлшейту әдісін келтіреміз. Сәйкестік жазуларында тәуелді сәйкестіктер үлгісін қолдану ар Біз осы әдісті қолданып екі сөйлейтін нормализациялау техникасын оқиға береміз. Екі жағдайда сөйлейтін сөйлеу мүмкіндіктері адамдардың деректерін алдыңғы зерттеулерге сәйкес келетін сөйлеу Нәтижелер адамдардың деректерін қанша жақсы таңдау арқылы нормализациялау әдістерінің түрлерін көрсетеді. Бұл жұмыс адамдардың түсініктеріне сәйкес келетін сөйлеу деңгейінің бағалау үшін жаңа бағдарлама береді, және сөйлеу үлгілерінің экологиялық дұрыс үлгілерін жасау үшін негізгі', 'it': 'Introducemo un metodo per misurare la corrispondenza tra caratteristiche vocali di basso livello e percezione umana, utilizzando un modello cognitivo di percezione vocale implementato direttamente sulle registrazioni vocali. Valutiamo due tecniche di normalizzazione degli altoparlanti utilizzando questo metodo e scopriamo che in entrambi i casi, le caratteristiche vocali normalizzate tra gli altoparlanti predicono i dati umani meglio delle caratteristiche vocali non normalizzate, in linea con le ricerche precedenti. I risultati rivelano inoltre differenze tra i metodi di normalizzazione in quanto bene ciascuno predice i dati umani. Questo lavoro fornisce un nuovo quadro per valutare le rappresentazioni di basso livello del discorso sulla loro corrispondenza con la percezione umana, e pone le basi per creare modelli di percezione del parlato più ecologicamente validi.', 'lt': 'Įdiegiame metodą, kuriuo matuojama korespondencija tarp žemo lygio kalbos savybių ir žmogaus suvokimo, naudojant pažintinį kalbos suvokimo model į, tiesiogiai įdiegtą kalbos įrašais. Vertiname du kalbėtojų normalizavimo metodus taikant šį metodą ir nustatome, kad abiem atvejais kalbėtojų normalizuotos kalbos savybės geriau prognozuoja žmogaus duomenis nei nenormaliuotos kalbos savybės, atitinkančios ankstesnius tyrimus. Iš rezultatų matyti, kad normalizavimo metodai skiriasi, kaip gerai kiekvienas prognozuoja žmogaus duomenis. Šis darbas sudaro naują pagrindą įvertinti mažo lygio kalbos atstovavimus, susijusius su jų atitiktimi žmogaus suvokimui, ir sudaro pagrindą kurti ekologiniu požiūriu tinkamesnius kalbos suvokimo modelius.', 'ms': 'Kami memperkenalkan kaedah untuk mengukur persamaan antara ciri-ciri ucapan tahap rendah dan perasaan manusia, menggunakan model kognitif perasaan ucapan yang dilaksanakan secara langsung pada rekaman ucapan. Kami menilai dua teknik normalisasi pembicara menggunakan kaedah ini dan mencari bahawa dalam kedua-dua kes, ciri-ciri pidato yang normalisasi di seluruh pembicara meramalkan data manusia lebih baik daripada ciri-ciri pidato yang tidak normal, konsisten dengan kajian sebelumnya. Keputusan menunjukkan perbezaan melalui kaedah normalisasi dalam bagaimana baik setiap meramalkan data manusia. Kerja ini menyediakan kerangka baru untuk menilai perwakilan ucapan aras rendah pada persamaan mereka dengan perasaan manusia, dan menetapkan dasar untuk mencipta model perasaan ucapan yang lebih sah secara ekologis.', 'ml': 'ഞങ്ങള്\u200d ഒരു രീതിയില്\u200d പരിചയപ്പെടുത്തുന്നു. സംസാരിക്കുന്നത് നേരിട്ട് പ്രവര്\u200dത്തിപ്പിക്കപ്പെട്ടിരിക്കുന്ന ഒരു സംസാരത്തിന്റെ വിശേഷതക ഈ രീതി ഉപയോഗിക്കുന്ന രണ്ടു സംസാരിക്കുന്ന സാധാരണ സാങ്കേതികവിദ്യകളെ ഞങ്ങള്\u200d വിലാസപ്പെടുത്തുന്നു. രണ്ട് കാര്യങ്ങളിലും സംസാരിക്കുന്ന സ്വഭാഷണങ വിവിധ വ്യത്യാസങ്ങള്\u200d സാധാരണമാക്കുന്ന രീതികളില്\u200d കൂടുതല്\u200d വ്യത്യാസങ്ങള്\u200d വെളിപ്പെടുത്തുന്നു. മനുഷ ഈ പ്രവര്\u200dത്തിക്കുന്നത് മനുഷ്യരുടെ പ്രതിനിധികളില്\u200d സംസാരിക്കുന്നതിന് കുറഞ്ഞ നിലയിലെ പ്രതിനിധികളെ വിശദീകരിക്കാന്\u200d പുതിയ ഫ്രെയിമെക്ക് നല', 'mt': 'Aħna nintroduċu metodu għall-kejl tal-korrispondenza bejn karatteristiċi tad-diskors ta’ livell baxx u l-perċezzjoni umana, bl-użu ta’ mudell konjittiv ta’ perċezzjoni tad-diskors implimentat direttament fuq ir-reġistrazzjonijiet tad-diskors. Aħna jevalwaw żewġ tekniki ta’ normalizzazzjoni tal-kelliema bl-użu ta’ dan il-metodu u nsibu li fiż-żewġ każijiet, karatteristiċi tad-diskors li huma normalizzati fost il-kelliema jipprevedu dejta umana aħjar minn karatteristiċi tad-diskors mhux normalizzati, konsistenti mar-riċerka preċedenti. Ir-riżultati jiżvelaw aktar differenzi bejn il-metodi ta’ normalizzazzjoni f’kemm kull wieħed jipprevedi tajjeb id-dejta umana. Dan ix-xogħol jipprovdi qafas ġdid għall-evalwazzjoni tar-rappreżentazzjonijiet ta’ livell baxx tad-diskors dwar il-qbil tagħhom mal-perċezzjoni umana, u jistabbilixxi l-bażi għall-ħolqien ta’ mudelli ta’ perċezzjoni tad-diskors aktar ekoloġikament validi.', 'mk': 'Ние воведуваме метод за мерење на кореспонденцијата помеѓу ниско ниво на говорните карактеристики и човечката перцепција, користејќи го когнитивниот модел на перцепција на говорот имплементиран директно на снимките на говорот. Ние ги проценуваме двете техники за нормализација на говорниците користејќи го овој метод и откриваме дека во двата случаи, говорните карактеристики кои се нормализирани меѓу говорниците предвидуваат човечки податоци подобро од неормализираните говорни карактеристики, во согласност со пре Резултатите понатаму откриваат разлики меѓу нормализациските методи во тоа колку добро секој предвидува човечки податоци. Оваа работа обезбедува нова рамка за проценка на репрезентациите на ниско ниво на говорот во врска со нивното одговарање со човечката перцепција, и ја поставува основата за создавање поеколошки валидни модели на перцепција на говорот.', 'no': 'Vi introduserer ein metode for å måle korsvarenskapen mellom låg nivå talefunksjonar og menneskeoppfatning, med ein kognitiv modell for taleoppfatning som er implementert direkte på taleopptak. Vi evaluerer to talenormaliseringssteknikk med denne metoden og finn at i begge tilfeller er talefunksjonar som er normalisert over talerar forventar menneskelige data bedre enn uformaliserte talefunksjonar, som er konsistent med førre forskning. Resultat viser meir forskjellingar over normaliseringsmetoder i kor godt kvar foregår menneske data. Dette arbeidet gjev eit nytt rammeverk for å evaluera låg nivå representasjonar av tale på dei samsvara med menneskeoppfatningane, og legger grunnarbeidet for å laga meir ekologisk gyldige modeller for taleoppfatning.', 'pl': 'Wprowadzamy metodę pomiaru korespondencji pomiędzy niskopoziomowymi cechami mowy a percepcją człowieka, wykorzystując model poznawczy percepcji mowy implementowany bezpośrednio na nagraniach mowy. Oceniamy dwie techniki normalizacji mówców przy użyciu tej metody i stwierdzimy, że w obu przypadkach znormalizowane cechy mowy przewidują dane ludzkie lepiej niż nienormalizowane cechy mowy, zgodne z poprzednimi badaniami. Wyniki ujawniają różnice między metodami normalizacji w tym, jak dobrze każda z nich przewiduje dane ludzkie. Niniejsza praca stanowi nowe ramy oceny niskopoziomowych reprezentacji mowy pod kątem ich dopasowania do ludzkiej percepcji oraz stworzy podstawy do stworzenia bardziej ekologicznie ważnych modeli percepcji mowy.', 'mn': 'Бид бага хэмжээний илтгэл болон хүн төрөлхтний ойлголтын хоорондох харилцааныг хэмжээний арга загвар тайлбарлаж, илтгэл бичлэг дээр шууд дамжуулагдсан. Бид энэ аргыг ашиглан ярьдаг хоёр илтгэгчийн нормализацийн технологийг үнэлдэг. Хоёр тохиолдолд илтгэгчийн давтамжтайгаар хүн төрөлхтний өгөгдлийг өмнөх судалгаанаас харьцуулахаас илүү сайн таамагладаг. Үүний үр дүнд хүний өгөгдлийг хэрхэн сайн тодорхойлж байгааг харуулдаг. Энэ ажил нь хүн төрөлхтний ойлголтын тухай бага хэмжээний илтгэлийг үнэлэх шинэ хэлбэрүүдийг хангаж, илтгэлийн ойлголтын илүү экологийн үнэ цэнэтэй загварыг бүтээх шаардлагатай.', 'ro': 'Introducem o metodă de măsurare a corespondenței dintre caracteristicile vorbirii de nivel scăzut și percepția umană, folosind un model cognitiv de percepție a vorbirii implementat direct pe înregistrările vorbirii. Evaluăm două tehnici de normalizare a vorbitorilor folosind această metodă și constatăm că, în ambele cazuri, caracteristicile vorbirii care sunt normalizate între vorbitori prezic datele umane mai bine decât caracteristicile vorbirii neormalizate, în concordanță cu cercetările anterioare. Rezultatele relevă în continuare diferențe între metodele de normalizare în cât de bine prezice fiecare date umane. Această lucrare oferă un nou cadru pentru evaluarea reprezentărilor la nivel scăzut ale vorbirii privind potrivirea lor cu percepția umană și pune bazele pentru crearea unor modele mai ecologice de percepție a vorbirii.', 'so': "Waxaynu soo bandhignaa qaab ku qiyaasaynaa isku xiriirka hadalka hoose iyo aragtida dadka, sida loo isticmaalo model aqoonta aragtida hadalka oo toos lagu soo dejiyey diiwaanka hadalka. Waxaannu qiimeynaynaa laba qaabab caadi ah oo hadalka ku hadla, waxaana ka helaynaa in labada xaaladood, hadal ku saabsan oo lagu caadi karo hadalka ku hadlayaasha ayaa ka sii sheegi kara macluumaadka dadka si ka wanaagsan qaabilaad hadal la'aan oo ku habboon waxbarasho hore. Fashihiisu waxay sidoo kale u muuqataa kala duwan qaababka caadiga ah, sida ugu wanaagsan mid kastaaba u sheegayo macluumaadka dadka. Shaqadaasu wuxuu samaysaa noocyo cusub oo ku qiimeeyaa noocyada hoose ee hadalka oo la xiriira aragtida dadka, wuxuuna dhigaa sabab u ah abuuridda qaabab ka shaqeeya aragtida hadalka.", 'sv': 'Vi introducerar en metod för att mäta korrespondansen mellan lågnivåtalfunktioner och mänsklig perception, med hjälp av en kognitiv modell av taleuppfattning implementerad direkt på talinspelningar. Vi utvärderar två högtalarnormaliseringstekniker med hjälp av denna metod och finner att talfunktioner som normaliseras mellan högtalarna i båda fallen förutspår mänskliga data bättre än onormala talfunktioner, vilket överensstämmer med tidigare forskning. Resultaten visar vidare skillnader mellan normaliseringsmetoder i hur väl var och en förutspår humandata. Detta arbete ger en ny ram för att utvärdera lågnivårepresentationer av tal om deras matchning till mänsklig uppfattning, och lägger grunden för att skapa mer ekologiskt giltiga modeller av talsuppfattning.', 'sr': 'Predstavljamo metodu za mjerenje dopisnosti između karakteristika govora na niskom nivou i ljudske percepcije, koristeći kognitivni model govornog percepcije provedenog direktno na snimanju govora. Procjenjujemo dve tehnike normalizacije govornika koristeći ovu metodu i pronađemo da u oba slučaja, karakteristike govora koje su normalizirane preko govornika predviđaju ljudske podatke bolje od neonormaliziranih karakteristika govora u skladu sa prethodnim istraživanjem. Rezultati dalje otkrivaju razlike između metoda normalizacije u tome kako dobro svaki predviđa ljudske podatke. Ovaj rad pruža novi okvir za procjenu predstavljanja govora na niskom nivou o njihovom odgovaranju sa ljudskim percepcijama, i stavlja temelj za stvaranje ekološki validnijih modela govornog percepcije.', 'si': 'අපි අඩු ස්ථානයේ කතාව සහ මිනිස්සු බලන්න අතර සම්බන්ධ විදියට පරීක්ෂණය කරන්න විදියට පරීක්ෂණය කරනවා, කතාව බලන්න පුළු අපි ස්පීකර් සාමාන්\u200dය විධානය කරන්නේ මේ විධානය භාවිතා කරනවා කියලා හොයාගන්නවා කියලා දෙන්නම්, සාමාන්\u200dය විධානය කරනවා කියලා ස්පී ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් සාමාන්\u200dය විධානයක් විසින් ප්\u200dරතිචාර කරනවා හැමෝම මි මේ වැඩේ අලුත් ප්\u200dරමාණයක් ප්\u200dරමාණය කරනවා කියලා කියන්න අඩුත් ප්\u200dරමාණයක් ගැන ඔවුන්ගේ මිනිස්සු බලන්න ප්\u200dරමාණය සඳහා අලුත් ප්\u200d', 'ur': 'ہم ایک طریقہ مقرر کریں گے کہ کم سطح کی بات کی تعریفیں اور انسان کی نظر کے درمیان مختلف بات کا اندازہ کریں، ایک زبان کی نظر کے مطابق صاف صاف صاف صاف صاف فیصلہ کیا گیا ہے۔ ہم نے اس طریقہ سے دو صحبت کرنے والوں کی عامل تخصیل کا ارزش کیا ہے اور دیکھتے ہیں کہ دونوں قسموں میں صحبت کرنے والوں کے سامنے عامل ہونے والی صحبت کے متعلق انسان ڈیٹا کو بہتر پیش بینی کرتا ہے جو غیر عامل صحبت کے متعلق ہے، جو پہلے کی تح نتائج اس سے زیادہ تفاوت کو عام طریقوں میں ظاہر کرتا ہے کہ ہر انسان کے ڈیٹے کو کس طرح اچھی پیش بینی کرتا ہے۔ یہ کام کم سطح کے نمونات کا ارزش کرنے کے لئے نئی فرمود دیتا ہے کہ ان کے مطابق انسان کی نظر سے مطابق مطابق بات کے مطابق مطابق کریں، اور بات کے مطابق زیادہ زیادہ منطقی موڈل بنانے کے لئے زیادہ زیادہ بنیاد', 'ta': 'நாம் குறைந்த நிலையில் பேச்சு குணங்கள் மற்றும் மனித பார்வைகளுக்கும் இடையேயுள்ள தொடர்பை அளவிட ஒரு முறையை குறிப்பிடுகிறோம், பேச்சு ப நாம் இந்த முறையை பயன்படுத்தி இரண்டு பேச்சாளர் இயல்பான தொழில்நுட்பத்தை மதிப்பிடுகிறோம் மற்றும் இரண்டு நிகழ்விலும், பேச்சாளர்கள் மீது இயல்பாக்கப்படு முடிவு This work provides a new framework for evaluating low-level representations of speech on their match to human perception, and lays the groundwork for creating more ecologically valid models of speech perception.', 'uz': "Biz suhbat xossalari va odamning fikrini o'zgartirish uchun bir usulni o'zgartirish mumkin, gapirish tugmasining foydalanishi mumkin. Biz bu usuldan foydalanuvchi ikkita gapiruvchi qoidalarni qiymatimiz va bu ikkita holatda gapiruvchilarga oddiy hodisalarni o'rganamiz, gapiruvchilarga qo'shilgan gapiruvchidan o'xshash ma'lumotlarni o'rganamiz, oldingi taʼminot bilan bir qanday o'rganish imkoniyatlari @ info: whatsthis This work provides a new framework for evaluating low-level representations of speech on their match to human perception, and lays the groundwork for creating more ecologically valid models of speech perception.", 'vi': 'Chúng tôi giới thiệu một phương pháp đo lại sự tương ứng giữa tính năng ngôn ngữ thấp và nhận thức của con người, sử dụng một mô hình nhận thức ngôn ngữ được thực hiện trực tiếp trên âm thanh. Chúng tôi đánh giá hai cách thức tổng hợp diễn giả dùng phương pháp này và thấy rằng cả hai trường hợp diễn thuyết đều bình thường trong các diễn viên dự đoán dữ liệu con người tốt hơn tính năng phát biểu bất thường, phù hợp với nghiên cứu trước. Kết quả phát hiện sự khác nhau trong các phương pháp bình thường về cách dự đoán thông tin con người. Công việc này tạo ra một cơ sở mới để đánh giá những diễn văn ở mức thấp về sự phù hợp với nhận thức của con người, và đặt nền móng để tạo ra những mô hình nhận thức giọng nói có giá trị kinh tế hơn.', 'bg': 'Въвеждаме метод за измерване на кореспонденцията между ниско ниво на речта и човешкото възприятие, използвайки когнитивен модел на възприемане на речта, внедрен директно върху записите на речта. Ние оценяваме две техники за нормализиране на говорителите с помощта на този метод и откриваме, че и в двата случая характеристиките на речта, които са нормализирани между говорителите, предсказват човешките данни по-добре от ненормалните функции на речта, съответстващи на предишни изследвания. Резултатите допълнително разкриват разлики между методите за нормализиране в това колко добре всеки прогнозира човешките данни. Тази работа предоставя нова рамка за оценка на ниско ниво на представяне на речта за съответствието им с човешкото възприятие и полага основите за създаване на по-екологично валидни модели на възприятие на речта.', 'da': 'Vi introducerer en metode til måling af korrespondancen mellem lavt niveau talefunktioner og menneskelig opfattelse ved hjælp af en kognitiv model for taleopfattelse implementeret direkte på taleoptagelser. Vi evaluerer to højttaler normaliseringsteknikker ved hjælp af denne metode og finder ud af, at talefunktioner, der er normaliseret på tværs af højttalere, i begge tilfælde forudsiger menneskelige data bedre end uormaliserede talefunktioner, i overensstemmelse med tidligere forskning. Resultaterne afslører yderligere forskelle på tværs af normaliseringsmetoder i, hvor godt hver forudsiger menneskelige data. Dette arbejde giver en ny ramme for evaluering af talerepræsentationer på lavt niveau på deres match til menneskelig opfattelse, og lægger grunden til at skabe mere økologisk gyldige modeller for taleopfattelse.', 'nl': 'We introduceren een methode voor het meten van de correspondentie tussen low-level spraakkenmerken en menselijke perceptie, met behulp van een cognitief model van spraakperceptie direct geïmplementeerd op spraakopnames. We evalueren twee normalisatietechnieken van sprekers met behulp van deze methode en vinden dat in beide gevallen spraakkenmerken die over sprekers zijn genormaliseerd, menselijke gegevens beter voorspellen dan onnarmaliseerde spraakkenmerken, in overeenstemming met vorig onderzoek. De resultaten onthullen verder verschillen tussen normalisatiemethoden in hoe goed elk menselijke gegevens voorspelt. Dit werk biedt een nieuw kader voor het evalueren van low-level representaties van spraak op hun match met menselijke perceptie, en legt de basis voor het creëren van meer ecologisch valide modellen van spraakperceptie.', 'de': 'Wir stellen eine Methode zur Messung der Korrespondenz zwischen low-level Sprachmerkmalen und menschlicher Wahrnehmung vor, wobei ein kognitives Modell der Sprachwahrnehmung direkt auf Sprachaufnahmen implementiert wird. Wir evaluieren zwei Lautsprechernormalisierungstechniken mit dieser Methode und stellen fest, dass in beiden Fällen Sprachmerkmale, die über Lautsprecher normalisiert werden, menschliche Daten besser vorhersagen als unnormalisierte Sprachmerkmale, im Einklang mit früheren Forschungen. Die Ergebnisse zeigen weiter Unterschiede zwischen den Normalisierungsmethoden in der Vorhersage menschlicher Daten. Die vorliegende Arbeit bietet einen neuen Rahmen für die Bewertung niederer Repräsentationen von Sprache auf ihre Übereinstimmung mit der menschlichen Wahrnehmung und legt die Grundlage für die Schaffung ökologisch gültigerer Modelle der Sprachwahrnehmung.', 'ko': '우리는 저급 음성 특징과 인류 감지 간의 대응 관계를 측정하는 방법을 소개하고 음성 기록에서 직접 실현된 음성 감지 인지 모델을 사용했다.우리는 이런 방법을 이용하여 두 가지 말하는 사람의 규범화 기술을 평가했는데 이 두 가지 상황에서 다중 말하는 사람의 규범화된 음성 특징이 규범화되지 않은 음성 특징보다 인류 데이터를 더 잘 예측하는 것을 발견했다. 이것은 이전의 연구와 일치한다.그 결과 표준화 방법이 인간의 데이터를 예측하는 데 있어서의 차이를 한층 더 드러냈다.이 작업은 음성의 저급 표징이 인류의 감지와 일치하는지 평가하고 더욱 생태적이고 효과적인 음성 감지 모델을 만드는 데 기반을 다졌다.', 'sw': 'Tunaonyesha njia ya kupima mawasiliano kati ya vipengele vya hotuba vya chini na mtazamo wa binadamu, kwa kutumia mifano ya ujuzi wa mtazamo wa hotuba uliotumika moja kwa moja kwenye rekodi za hotuba. Tunatathmini mbinu za utaratibu wa mazungumzaji wawili kwa kutumia mbinu hii na kutafuta kwamba katika hali hizi mbili, hotuba zinazowekwa kawaida katika mazungumzo yanatabiri takwimu za binadamu bora kuliko vipengele vya mazungumzo yasiyoeleweka, ikilinganisha na utafiti uliopita. Matokeo mengine yanaonyesha tofauti katika njia za kawaida katika namna gani kila mmoja anatabiri takwimu za binadamu. Kazi hii inatoa mfumo mpya wa kutathmini uwakilishi wa kiwango cha chini wa mazungumzo yao kwenye michezo yao yanayohusiana na mtazamo wa binadamu, na inatengeneza msingi wa kutengeneza mifano yenye uhakika zaidi ya mazungumzo ya mazungumzo.', 'tr': 'Biz d체힊체k dereje 챌yky힊 we adam g철z체ni tany힊 etmek 체챌in bir y철ntem 챌yky힊 etmek 체챌in, 챌yky힊 kay캇tlarda edilen bilimsel nusga ullan첵arys. Biz bu y철ntemi ulanan iki 챌yky힊 normalization tekniklerini de흫le첵채ris we iki 첵agda첵da 챌yky힊챌ylar arasynda adat챌a adamlary흫 maglumatyny di흫e adat챌a 챌yky힊syz 챌yky힊yndan gowy 챌akla첵ar we 철흫ki ylmy bilen t채sirli bol첵ar. Netijeler adamlary흫 maglumatyny n채hili gowy 철wr체l첵채ndigini d체첵b체rle첵채r. Bu i힊e adamlary흫 g철z체ne gola첵la힊yny흫 d체힊체k derejesini 챌ykmak 체챌in t채ze bir 챌er챌ew 체첵tged첵채r we 챌yky힊 d체힊체nmesi 체챌in 첵ene-de k철p ekologik 첵agda첵 nusgalary d철ret첵채r.', 'hr': 'Upoznajemo metodu za mjerenje dopisnosti između karakteristika niskog razina govora i ljudske percepcije, koristeći kognitivni model govornog percepcije provedenog direktno na snimanju govora. Procjenjujemo dvije tehnike normalizacije govornika koristeći ovu metodu i otkrijemo da u oba slučaja, karakteristike govora koje normaliziraju preko govornika predviđaju ljudske podatke bolje od neonormaliziranih karakteristika govora u skladu s prethodnim istraživanjem. Rezultati dalje otkrivaju razlike između metoda normalizacije u tome kako dobro predviđa svaki čovjek podaci. Ovaj rad pruža novi okvir za procjenu predstavljanja govora na niskoj razini o njihovoj odgovarajući ljudskom percepciji i stavlja temelj za stvaranje ekološki validnijih modela govornog percepcije.', 'af': "Ons introduseer 'n metode vir die ooreenkomstigheid tussen lae vlak sprekking funksies en menslike oorskou, met die gebruik van 'n kognitiewe model van spraak oorskou wat direk op spraak opneem is. Ons evalueer twee sprekkers normalisering tekens met hierdie metode en vind dat in beide gevalle, spraak funksies wat genormaliseer word deur sprekkers voorskou menslike data beter as onnormaliseerde spraak funksies, ooreenstemmende met vorige forsoek. Resultate verder vertoon verskille oor normalisering metodes in hoe goed elke menslike data voorskou. Hierdie werk verskaf 'n nuwe raamwerk vir die evaluering van lae vlak voorstellings van spraak op hul ooreenstemming met die menslike aandag, en lê die grondwerk vir die skep van meer ekologies geldige modele van spraak aandag.", 'id': 'Kami memperkenalkan metode untuk mengukur korespondensi antara fitur pidato tingkat rendah dan persepsi manusia, menggunakan model kognitif persepsi pidato yang direksploitasi langsung pada rekaman pidato. Kami mengevaluasi dua teknik normalisasi pembicara menggunakan metode ini dan menemukan bahwa dalam kedua kasus, fitur pidato yang normalisasi di antara pembicara memprediksi data manusia lebih baik daripada fitur pidato tidak normalisasi, konsisten dengan penelitian sebelumnya. Hasil menunjukkan perbedaan melalui metode normalisasi dalam bagaimana baik setiap prediksi data manusia. Kerja ini menyediakan rangka baru untuk mengevaluasi representation tingkat rendah dari pidato pada persimpangan mereka dengan persepsi manusia, dan meletakkan dasar untuk menciptakan model persepsi pidato yang lebih ekologis.', 'sq': 'Ne futim një metodë për matjen e korrespondencës midis karakteristikave të nivelit të ulët të fjalës dhe perceptimit njerëzor, duke përdorur një model kognitiv të perceptimit të fjalës të zbatuar drejtpërdrejt në regjistrimet e fjalës. Ne vlerësojmë dy teknika normalizimi të folësve duke përdorur këtë metodë dhe zbulojmë se në të dy rastet, karakteristikat e fjalimit që janë normalizuar nëpër folës parashikojnë të dhënat njerëzore më të mira se karakteristikat e fjalimit të pazakontë, në përputhje me kërkimet e mëparshme. Rezultatet zbulojnë më tej dallime nëpër metodat e normalizimit në se sa mirë çdo parashikon të dhënat njerëzore. This work provides a new framework for evaluating low-level representations of speech on their match to human perception, and lays the groundwork for creating more ecologically valid models of speech perception.', 'am': 'በንግግር ማሳየት እና በሰው አስተያየት መካከል ግንኙነትን ለመለካት እናስታውቃለን፡፡ ሁለትን የንግግር ቃላት ማቀናቀል ሀብትን እናስተውላለን እና በሁለቱም ጉዳይ፣ ንግግር በተቃዋሚዎች ላይ የተደገመ የሰው ዳታዎችን ከቀድሞው ትምህርት የተሻለውን እናስታውቃለን፡፡ ፍጥረቶች ሁሉ የሰው አዳራዎችን እንዴት ያሳያል የሚለውጡትን መለያየት ይታያል፡፡ ይህ ሥራ የሰው አስተያየት ጋር የንግግር መልዕክቶችን በሚያስተካክሉ አዲስ አዲስ ፍሬማር ያስተካክላል፡፡', 'hy': 'Մենք ներկայացնում ենք խոսքի ցածր մակարդակի հատկությունների և մարդկային ընկալության միջև համեմատության չափման մեթոդ, օգտագործելով խոսքի ընկալության ճանաչողական մոդել, որը տեղադրվում է անմիջապես խոսքի ձայնագրությունների վրա: Մենք գնահատում ենք երկու խոսացողների նորմալիզացիայի տեխնիկան օգտագործելով այս մեթոդը և հայտնաբերում ենք, որ երկու դեպքերում խոսացողների միջև նորմալիզացված խոսքի հատկությունները ավելի լավ են կանխատեսում մարդկային տվյալները, քան աննորմալիզացված խոսացողների Արդյունքները նույնպես բացահայտում են նորմալիզացիայի մեթոդների տարբերությունները մարդկային տվյալների լավ կանխագուշակում: Այս աշխատանքը ստեղծում է նոր հիմք խոսքի ցածր մակարդակի ներկայացումների գնահատելու համար, որոնք համապատասխանում են մարդկային ընկալումներին, և հիմք է դնում խոսքի ընկալության ավելի էկոլոգիապես ճշգրիտ մոդելների ստեղծման համար:', 'fa': 'ما یک روش برای اندازه اندازه تعامل بین ویژه\u200cهای سخنرانی پایین و احساس انسان را معرفی می\u200cکنیم، با استفاده از یک مدل مفهومی از احساس سخنرانی که مستقیماً روی ضبط سخنرانی انجام شده است. ما با استفاده از این روش دو تکنیک نورمیزی صحبت\u200cکننده را ارزیابی می\u200cکنیم و می\u200cبینیم که در هر دو مورد، ویژه\u200cهای سخنرانی که در بین صحبت\u200cکننده\u200cها طبیعی شده\u200cاند، اطلاعات انسان بهتر از ویژه\u200cهای سخنرانی غیرعادی پیش بینی نتیجه\u200cهای دیگر تفاوت\u200cهایی را در روش\u200cهای عامل\u200cسازی در حالی که هر یک داده\u200cهای انسان را چگونه خوب پیش\u200cبینی می\u200cکند نشان می\u200cدهد. این کار یک چهارچوب جدید برای ارزیابی نمایش\u200cهای سطح پایین سخنرانی را در مسابقه با مشاهده\u200cهای انسان پیشنهاد می\u200cکند، و پایگاه\u200cهای برای ایجاد مدل\u200cهای زیست\u200cشناسی\u200cتر از مشاهده\u200cهای سخنرانی قرار می\u200cدهد.', 'az': 'Biz düşük səviyyə sözləri və insan görünüşü arasındakı müəyyənləşdirmək üçün bir metodu təşkil edirik, sözlərin kayıtlarında müəyyən edilmiş bilikli modeli istifadə edirik. Biz bu metodları istifadə edərək iki danışıcı normalizasyon tekniklərini değerləşdiririk və hər iki təqdirdə danışıcıların arasında normalizasyon edilən danışmaq tərzlərini, əvvəlki araştırmalarla uyğun kimi, insan məlumatlarını normalizasyonsuz danışmaq tərzlərindən daha yaxşı tə Sonuçlar insanların məlumatlarının necə yaxşı tədbir edildiyini göstərər. Bu işin insan görünüşünə uyğunlaşdırmaq üçün düşük səviyyə göstəricilərini değerləşdirmək üçün yeni bir çerçive təklif edir və daha ekolojik münasibətli danışma görünüşünün modellərini yaratmaq üçün təklif edir.', 'bn': 'আমরা নীচের ভাষণের বৈশিষ্ট্য এবং মানুষের দৃষ্টিভঙ্গির মধ্যে সংস্করণ মাপের একটি পদ্ধতি পরিচয় করিয়ে দিচ্ছি যা ভাষণের দৃষ্টিভঙ্গি নিয়ে সরাসরি ভ আমরা এই পদ্ধতি ব্যবহার করে দুটি ভাষণাকারীর স্বাভাবিক প্রযুক্তি মূল্যায়ন করি এবং দুটি ক্ষেত্রে ভাষণের বৈশিষ্ট্যের বৈশিষ্ট্য প্রতিষ্ঠান যা ভাষণের বি ফলাফল আরো প্রকাশ করে স্বাভাবিকভাবে মানুষের তথ্য কত ভালো ভবিষ্যদ্বাণী করে। এই কাজে তাদের মানুষের দৃষ্টিভঙ্গির মাধ্যমে ভাষণের প্রতিনিধিত্ব নির্মাণ করার জন্য একটি নতুন কার্যক্রম প্রদান করা হয়েছে এবং তারা বেশী অর্থনৈতিক ভ', 'ca': 'We introduce a method for measuring the correspondence between low-level speech features and human perception, using a cognitive model of speech perception implemented directly on speech recordings.  Evaluam dues tècniques de normalització dels oradors fent servir aquest mètode i descobrim que en ambdós casos, les característiques de la fala normalitzades a través dels oradors predeixen les dades humanes millor que les característiques de la fala no normalitzades, consistents amb la recerca anterior. Els resultats revelen més diferències entre els mètodes de normalització en com cada una prediu les dades humanes. Aquesta feina proporciona un nou marc per avaluar representacions de baix nivell de la fala sobre la seva coincidencia amb la percepció human a, i posa la base per crear models de percepció de la fala més ecològicament válids.', 'et': 'Tutvustame meetodit madala taseme kõnefunktsioonide ja inimese taju vastavuse mõõtmiseks, kasutades kõnetaju kognitiivset mudelit, mida rakendatakse otse kõnesalvestustel. Hindame seda meetodit kasutades kahte kõnelejate normaliseerimise meetodit ja leiame, et mõlemal juhul ennustavad kõnelejate vahel normaliseeritud kõnefunktsioonid inimandmeid paremini kui normaliseerimata kõnefunktsioonid, mis on kooskõlas varasemate uuringutega. Tulemused näitavad ka erinevusi normaliseerimismeetodite vahel selles, kui hästi iga inimese andmeid prognoosib. Käesolev töö annab uue raamistiku kõnede madala taseme esindamise hindamiseks nende vastavuse kohta inimese tajumisega ning loob aluse ökoloogiliselt kehtivamate kõnetaju mudelite loomiseks.', 'cs': 'Představujeme metodu měření korespondence mezi nízkými řečovými rysy a lidským vnímáním s využitím kognitivního modelu vnímání řeči implementovaného přímo na záznamech řeči. Vyhodnocujeme dvě techniky normalizace mluvčích pomocí této metody a zjišťujeme, že v obou případech normalizované funkce řeči předpovídají lidská data lépe než nerormalizované funkce řeči, což je v souladu s předchozím výzkumem. Výsledky dále odhalují rozdíly mezi normalizačními metodami v tom, jak dobře každá z nich předpovídá lidská data. Tato práce poskytuje nový rámec pro hodnocení nízkých reprezentací řeči na jejich shodě s lidským vnímáním a položí základy pro vytvoření ekologicky platnějších modelů vnímání řeči.', 'fi': 'Esittelemme menetelmän, jolla mitataan matalan tason puheominaisuuksien ja ihmisen havainnoinnin vastaavuutta käyttäen puheentunnistuksen kognitiivista mallia, joka on toteutettu suoraan puhetallenteisiin. Arvioimme kahta puhujien normalisointitekniikkaa käyttämällä tätä menetelmää ja havaitsimme, että molemmissa tapauksissa puhujien välillä normalisoidut puheen ominaisuudet ennustavat ihmisen dataa paremmin kuin normalisoimattomat puheen ominaisuudet, mikä on johdonmukaista aikaisemman tutkimuksen kanssa. Tulokset paljastavat myös eroja normalisointimenetelmien välillä siinä, kuinka hyvin kukin ennustaa ihmisen tietoja. Tämä työ tarjoaa uuden viitekehyksen matalatasoisten puheen esitysten arvioimiselle niiden vastaavuudesta ihmisen havaintoon ja luo pohjan ekologisesti pätevien puheen havainnointimallien luomiselle.', 'bs': 'Predstavljamo metodu za mjerenje dopisnosti između karakteristika govora niskog nivoa i ljudske percepcije, koristeći kognitivni model govornog percepcije provedenog direktno na snimanju govora. Procjenjujemo dvije tehnike normalizacije govornika koristeći ovu metodu i otkrijemo da u oba slučaja, karakteristike govora koje normaliziraju preko govornika predviđaju ljudske podatke bolje od neonormaliziranih karakteristika govora u skladu s prethodnim istraživanjem. Rezultati dalje otkrivaju razlike između metoda normalizacije u tome kako dobro svaki predviđa ljudske podatke. Ovaj rad pruža novi okvir za procjenu predstavljanja govora na niskom nivou o njihovom odgovaranju sa ljudskim percepcijama, i stavlja temelj za stvaranje ekološki validnijih modela govornog percepcije.', 'jv': 'Awak dhéwé éntuk sistem sing nggawe gerambut tindakan langgambar apakno karo perbudhakan langgambar uwong. Awak dhéwé éntuk sistem sing nyebuturan gambar apakno karo perusahaan ingkang sampeyan ingkang sampeyan gak dhéwé, kuwi kesempatan sing dipun nguasakno perusahaan karo perusahaan langgar sampeyan sing luwih apik dhéwé. Language Workspace Names', 'he': 'אנחנו מציגים שיטה למדוד התכתבות בין תכונות דיבור רמה נמוכה לתפיסה אנושית, באמצעות מודל קוגניטיבי של התפיסה דיבורית שהופך ישירות על הקלטות דיבורים. אנו מעריכים שתי טכניקות נורמליזציה של רמקולים בשימוש בשיטה זו ומצאים שבשני המקרים, תכונות הנאום הנורמליזציות ברחבי הרמקולים חושפים נתונים אנושיים טובים יותר ממתכונות הנאום לא נורמליזציות, בתאים למחקר קודם. תוצאות חושפות עוד הבדלים בין שיטות נורמליזציה באיזה טוב כל אחד חושף נתונים אנושיים. This work provides a new framework for evaluating low-level representations of speech on their match to human perception, and lays the groundwork for creating more ecologically valid models of speech perception.', 'ha': "Tuna fara wani hanyo da za'a iya ƙayyade maganar-daraja da bakin mazaɓa na mutane, ko kuma za'a yi amfani da wani misali na gannair magana da aka samar da shi dira kan rekodin hotarwa. Tuna ƙaddara laban shiryoyin ayuka da ke yi amfani da wannan metode kuma tuna cewa, a cikin duk biyu, masu shiryuwa na magana, masu shiryuwa a tsakanin masu magana, masu bastarwa masu bastarwa sun yi bayani ga data masu fi da tsari ga mutane da ba'a sãɓa ba, da kuma a sami da research na farko. Matunan ta ƙara bayyana diffuka a cikin metoden shiryarwa, a cikin yadda kõwane abu yana yi bayani ga data na mutum. Wannan aikin yana da wani firam na daban dõmin an evaluate masu takarda-daraja masu maganar da ke sami da gannain mutum, kuma yana daidaita wani bango dõmin ya ƙiƙira misãlai masu inganci masu da saurãre.", 'sk': 'Predstavljamo metodo za merjenje korespondence med nizkimi govornimi značilnostmi in človeško percepcijo z uporabo kognitivnega modela zaznavanja govora, ki se uporablja neposredno na posnetkih govora. Z uporabo te metode smo ocenili dve tehniki normalizacije govornikov in ugotovili, da v obeh primerih značilnosti govora, ki so normalizirane med govorniki, napovedujejo človeške podatke bolje kot nenormalizirane značilnosti govora, skladno s prejšnjimi raziskavami. Rezultati nadalje kažejo razlike med metodami normalizacije v tem, kako dobro vsaka napoveduje človeške podatke. Delo zagotavlja nov okvir za ocenjevanje nizkih reprezentacij govora glede na njihovo ujemanje s človeško percepcijo in postavlja temelje za ustvarjanje ekološko veljavnejših modelov zaznavanja govora.', 'bo': 'ང་ཚོས་ཀྱི་ཐབས་ལམ་དེ་ལྟར་ཉུང་བའི་ཁ་ཤར་དང་མི་ཤེས་ཚོར་བ་གཉིས་ཀྱི་ཆོས་ཉུང་བའི་གྲངས་སྒྲིག་དང་མཐུན་རྐྱེན་ཚད་སྒྲིག་ཐབས་ལམ་སྟོན ང་ཚོས་ཐབས་ལམ་འདི་བེད་སྤྱོད་པའི་རྒྱུན་ལྡན་བཟོ་བྱེད་པའི་ཐབས་ལམ་གཉིས་ཀྱི་གནད་དོན་དག་ཞིབ་བྱེད་ཀྱི་ཡོད་པ་དང་། སྐད་ཆ་འདི་རྣམས་མེད་པའི་ནང་ནས་ གྲུབ་འབྲས་གཞན་ལས་མི་རྣམས་ལ་རྒྱུན་ལྡན་ཐབས་ལམ་སྟངས་པར་མཐུན་རྐྱེན་བྱས་མྱོང་། ལས་ཀ་འདིས་མི་མང་གི་མཐུན་རྐྱེན་ཚད་ལྡན་པ་ལས་ཉུང་བའི་ཞལ་འཚོལ་བ་དང་མཐུན་སྒྲིག་framework་གསར་པ་ཞིག་བྱས་ཡོད།'}
{'en': 'Unsupervised Acquisition of Comprehensive Multiword Lexicons using Competition in an n-gram Lattice', 'ar': 'الاستحواذ غير الخاضع للإشراف على معجم شامل متعدد الكلمات باستخدام المنافسة في شبكة n-gram شعرية', 'pt': 'Aquisição não supervisionada de léxicos multipalavras abrangentes usando competição em uma rede n-gram', 'es': 'Adquisición sin supervisión de lexicones integrales de varias palabras mediante la competencia en una red de n-gramas', 'fr': "Acquisition non supervisée de lexiques multimots complets à l'aide de la concurrence dans un réseau de n-grammes", 'ja': 'Nグラム格子内の競合を使用した包括的なマルチワードレキシコンの監督なしの取得', 'zh': '用 n-gram 格中竞争法无监综多词词典', 'ru': 'Неконтролируемое приобретение комплексных многословных лексиконов с использованием конкуренции в n-граммовой решетке', 'hi': 'एक n-ग्राम जाली में प्रतिस्पर्धा का उपयोग कर व्यापक Multiword शब्दकोशों का असुरक्षित अधिग्रहण', 'ga': 'Fáil Neamh-mhaoirsithe ar Fhoclóirí Cuimsitheacha Ilfhocail ag úsáid Comórtas i Laitís n-gram', 'hu': 'Átfogó többszós lexikonok felügyelet nélküli beszerzése verseny használatával n-grammos hálóban', 'ka': 'N- გრამის ლატტიკში კომპეციციაცია გამოყენებული მრავალური სიტყვების მიღება', 'el': 'Μη εποπτευόμενη απόκτηση περιεκτικών πολυλέξεων Λεξικό χρησιμοποιώντας τον Ανταγωνισμό σε πλέγμα ν-γραμμάτων', 'it': 'Acquisizione non supervisionata di Lexicons multiword completi utilizzando la concorrenza in un reticolo n-gram', 'mk': 'Ненадгледувано купување на сеопфатни мултизборни лексикони користејќи конкуренција во n- грам латика', 'kk': 'n- грамм латтикасында конкурс қолданатын комплекс көп сөзді лексикалық қабылдау мүмкін емес', 'lt': 'Neprižiūrimas kompleksinių daugiakalbių leksikonų įsigijimas, naudojant konkurenciją n gram ų plokštelėje', 'ms': 'Pemilihan Lexikon Berkata Berkomprehensif tanpa diawasi menggunakan Pertandingan dalam Lattik n-gram', 'mt': 'Akkwist Mhux Sorveljat ta’ Lexicons Komprensivi Multikliem bl-użu tal-Kompetizzjoni f’Lattika n-gramma', 'pl': 'Niekontrolowane nabycie kompleksowych leksykonów wielowłowych z wykorzystaniem konkurencji w n-gramowej sieci', 'ml': 'നിരീക്ഷിക്കപ്പെടാത്ത ഒരു n- ഗ്രാം ലാറ്റിക്സിസില്\u200d ഉപയോഗിച്ചു് പൂര്\u200dണ്ണവാക്ക് ലെക്സിക്കനുകളുടെ സമ്പൂര്\u200d', 'mn': 'Н-грамм Латтик дахь Сөрсөлдөөнийг ашиглаж буй комплекс олон үг Лексикцийн хүлээн авах', 'no': 'Ikkje oppretta akseptering av komprehensive fleire ord leksjonar ved hjelp av kompetisjon i en n-gram Lattice', 'si': 'Name', 'so': 'Unwatched Acquisition of Comprehensive Lexicons using Competition in an n-gram Lattice', 'ro': 'Achiziționarea nesupravegheată a Lexicoanelor multicuvinte cuprinzătoare utilizând Concurența într-o rețea n-gram', 'sr': 'Nepotrebno prihvatanje komplektivnih lekcija sa mnogim rečima koristeći konkurenciju u n-gramu Lattice', 'sv': 'Obehandlat förvärv av heltäckande flerordsloxikoner med hjälp av konkurrens i ett n-gramsnät', 'ta': 'Unsupervised Acquisition of Comprehensive Multiword Lexicons using Competition in an n-gram Lattice', 'ur': 'N-gram Lattice میں Competition کے مطابق مختلف Multiword Lexicons کی حاصل غیر پابندی کی', 'uz': 'Name', 'vi': 'Không tuân theo luật pháp Truyền hình từ đa diện sử dụng sự cạnh tranh trong n-gram Lát n ữa.', 'bg': 'Неконтролирано придобиване на всеобхватни многословни лексикони с използване на конкуренция в n-грамова решетка', 'hr': 'Nepotrebno prihvaćenje kompleksnog višeriječnog leksija koristeći konkurenciju u n-gramu Lattice', 'da': 'Ikke-overvåget erhvervelse af omfattende multiword Lexikoner ved hjælp af konkurrence i et n-gram gitter', 'nl': 'Onbegeleide verwerving van uitgebreide meerwoord Lexiconen met behulp van concurrentie in een n-gram rooster', 'de': 'Unbeaufsichtigter Erwerb umfassender Mehrwortlexikone mittels Konkurrenz in einem n-Gramm-Gitter', 'id': 'Perambilan Lexikon Multikata Komprensif tanpa diawasi menggunakan Kompetisi dalam n-gram Lattice', 'ko': 'n-gram 격자 경쟁을 바탕으로 한 종합 다사 어휘 무감독 획득', 'fa': 'غیرقابل تحصیل دریافت کلمات زیادی با استفاده از Competition in an-gram Lattice', 'sw': 'Uthibitisho usiokuwa na uwezekano wa Kilexico Kijumla cha Maneno kwa kutumia Ubaguzi wa Tamko', 'sq': 'Akvizioni i Pambikqyrur i Lexikonëve Komprensive Multiword duke përdorur Konkurrencën n ë një n-gram Lattice', 'af': "Onondersteunde aanvang van komprehensiewe Multiwoord Leksiese gebruik Kompatisie in 'n n n- gram Lattice", 'tr': 'N-gram Lattikiýada Täsirlenme Ululyklaryň Maýyp Gaýd Edilmesi', 'az': "n-gram Lattice'd톛 m칲qayis톛d톛 istifad톛 edil톛n m칲xt톛lif 칞oxlu s칬zl톛r Leksiksiyonlar캼n q톛bul edilm톛si", 'hy': 'Անվերահսկված ընդհանուր բազմաբառ լեքսիկոնների գնումը, օգտագործելով n-գրամ լատիկի մրցակցությունը', 'bn': 'অন্তরঙ্গ গ্রাম ল্যাটিস ব্যবহার করে পুরোপুরি সম্পূর্ণ মাল্টিভার্ড লেক্সিকোন প্রতিযোগিতা', 'am': 'CategoryName', 'bs': 'Nepotrebno prihvaćenje komprehensive multiword leksijuna koristeći konkurenciju u n-gramu Lattice', 'ca': 'Acquisició sense supervisió de Lexicòns Multiparaules Comprehensives utilitzant Competition en un n-gram de làtice', 'cs': 'Nekontrolovan챕 z챠sk찼v찼n챠 komplexn챠ch v챠ceslovn첵ch Lexikon킁 pomoc챠 konkurence v n-gramov챕 m힂챠탑ce', 'et': 'Terviklike mitmesõnaleksikoonide järelevalveta soetamine konkurentsi abil n-grammises võrgus', 'fi': 'Kattavien monikanavaisten leksikonien valvomaton hankinta n-gramman ristikon kilpailulla', 'jv': 'Align to:', 'he': 'רכישה בלתי מפוקפקת של לקסיקונים מורכבים במילים רבות בשימוש בתחרות במקלטת n-גרם', 'sk': 'Nenadzorovan nabav celovitih večbesednih leksikon z uporabo konkurence v n-gramski mreži', 'ha': 'KCharselect unicode block name', 'bo': 'Competition in an n-gram Lattice'}
{'en': 'We present a new model for acquiring comprehensive multiword lexicons from large corpora based on competition among n-gram candidates. In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item. We show how the configuration of such a lattice can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 F-score across several corpora and languages.', 'ar': 'نقدم نموذجًا جديدًا للحصول على معاجم شاملة متعددة الكلمات من مجموعات كبيرة على أساس المنافسة بين المرشحين n-gram. على عكس النهج القياسي للترتيب البسيط من خلال مقياس الارتباط ، في نموذجنا n-grams يتم ترتيبها في هيكل شبكي قائم على علاقات الامتصاص والتداخل ، مع العقد التي تمنع العقد الأخرى في جوارها عند اختيارها كعنصر معجمي. نعرض كيف يمكن تحسين تكوين مثل هذه الشبكة بشكل سهل ، ونوضح باستخدام التعليقات التوضيحية لعينة n-grams أن طريقتنا تتفوق باستمرار على البدائل بما لا يقل عن 0.05 درجة F عبر العديد من المؤسسات واللغات.', 'fr': "Nous présentons un nouveau modèle d'acquisition de lexiques multimots complets à partir de grands corpus, basé sur la concurrence entre candidats n-gram. Contrairement à l'approche standard du classement simple par mesure d'association, dans notre modèle, les n-grammes sont disposés dans une structure en treillis basée sur des relations de sous-somption et de chevauchement, les nœuds inhibant les autres nœuds à proximité lorsqu'ils sont sélectionnés comme élément lexical. Nous montrons comment la configuration d'un tel réseau peut être optimisée de manière tractable, et démontrons à l'aide d'annotations de n-grammes échantillonnés que notre méthode surpasse systématiquement les alternatives d'au moins 0,05 F-score dans plusieurs corpus et langages.", 'es': 'Presentamos un nuevo modelo para adquirir lexicones integrales de varias palabras de grandes corpus basado en la competencia entre los candidatos de n-gram. En contraste con el enfoque estándar de clasificación simple por medida de asociación, en nuestro modelo los n-gramas están dispuestos en una estructura reticular basada en relaciones de subsunción y superposición, con nodos que inhiben otros nodos en su vecindad cuando se seleccionan como un elemento léxico. Mostramos cómo la configuración de una red de este tipo se puede optimizar de manera manejable, y demostramos mediante anotaciones de n-gramas muestreados que nuestro método supera constantemente a las alternativas en al menos un puntaje F de 0,05 en varios cuerpos e idiomas.', 'pt': 'Apresentamos um novo modelo para aquisição de léxicos multipalavras abrangentes de grandes corpora com base na competição entre candidatos a n-gram. Em contraste com a abordagem padrão de classificação simples por medida de associação, em nosso modelo os n-gramas são organizados em uma estrutura de rede baseada em relações de subsunção e sobreposição, com nós inibindo outros nós em sua vizinhança quando são selecionados como um item lexical. Mostramos como a configuração de tal rede pode ser otimizada de maneira tratável e demonstramos usando anotações de n-gramas amostrados que nosso método supera consistentemente as alternativas em pelo menos 0,05 F-score em vários corpora e linguagens.', 'ja': '我々は、n - gram候補者間の競争に基づいて、大規模なコーパから包括的な多言語辞典を取得するための新しいモデルを提示します。関連測定による単純なランク付けの標準的なアプローチとは対照的に、我々のモデルでは、n - gramは、帰納および重複関係に基づいて格子構造に配置され、ノードは、それらが語彙項目として選択されたときに、その近傍の他のノードを阻害する。私たちは、そのような格子の構成をどのように牽引可能に最適化できるかを示し、サンプリングされたn - gramの注釈を使用して、私たちの方法がいくつかのコーパスと言語で少なくとも0.05 Fスコアで代替案を一貫して上回っていることを実証します。', 'zh': '建一基于n-gram候选者争于大语料库,取备多词词典之新式。 与度量相违,在吾模形之中,n-gram基于包重,列于格构,节点在选为词法目,抑其近节点。 吾示以可处优化此格之配,并用采样n-gram注证,吾法于数语料库言语终优于代方案至少0.05 F分数。', 'ru': 'Представляем новую модель приобретения комплексных многословных лексиконов у крупных корпусов на основе конкуренции среди n-грамм-кандидатов. В отличие от стандартного подхода простого ранжирования по мере ассоциации, в нашей модели n-граммы расположены в решетчатой структуре, основанной на зависимостях поглощения и перекрытия, с узлами, ингибирующими другие узлы в их окрестностях, когда они выбраны в качестве лексического элемента. Мы показываем, как конфигурация такой решетки может быть оптимизирована трактативно, и демонстрируем с помощью аннотаций выборочных n-грамм, что наш метод последовательно превосходит альтернативы по меньшей мере на 0,05 F-балла по нескольким телам и языкам.', 'hi': 'हम एन-ग्राम उम्मीदवारों के बीच प्रतिस्पर्धा के आधार पर बड़े कॉर्पोरेट से व्यापक मल्टीवर्ड शब्दकोश प्राप्त करने के लिए एक नया मॉडल प्रस्तुत करते हैं। एसोसिएशन माप द्वारा सरल रैंकिंग के मानक दृष्टिकोण के विपरीत, हमारे मॉडल में एन-ग्राम को एक जालीदार संरचना में व्यवस्थित किया जाता है जो subsumption और ओवरलैप संबंधों के आधार पर होता है, नोड्स के साथ उनके आस-पास के अन्य नोड्स को बाधित करते हैं जब उन्हें एक लेक्सिकल आइटम के रूप में चुना जाता है। हम दिखाते हैं कि इस तरह की जाली के विन्यास को कैसे अनुकूलित किया जा सकता है, और नमूना एन-ग्राम के एनोटेशन का उपयोग करके प्रदर्शित किया जा सकता है कि हमारी विधि लगातार कई कॉर्पोरेट और भाषाओं में कम से कम 0.05 एफ-स्कोर द्वारा विकल्पों को मात देती है।', 'ga': 'Cuirimid samhail nua i láthair chun foclóir cuimsitheach ilfhocail a fháil ó mhórchorparáid bunaithe ar iomaíocht i measc iarrthóirí n-gram. I gcodarsnacht leis an gcur chuige caighdeánach maidir le rangú simplí de réir tomhais comhlachais, inár múnla socraítear n-gramanna i struchtúr laitíse bunaithe ar choibhneasa comhchuimsithe agus forluí, le nóid a chuireann cosc ar nóid eile ina gcomharsanacht nuair a roghnaítear iad mar mhír fhoclóra. Léirímid conas is féidir cumraíocht laitíse den sórt sin a bharrfheabhsú, agus léirímid agus nótaí á n-úsáid againn as n-ghraim sampláilte go n-éiríonn lenár modh go seasta na roghanna eile 0.05 F-scór ar a laghad thar roinnt corpora agus teangacha éagsúla.', 'el': 'Παρουσιάζουμε ένα νέο μοντέλο για την απόκτηση περιεκτικών πολυλέξεων λεξικών από μεγάλα σώματα με βάση τον ανταγωνισμό μεταξύ υποψηφίων ν-γραμμάτων. Σε αντίθεση με την τυπική προσέγγιση της απλής κατάταξης ανά μέτρο συσχέτισης, στο μοντέλο μας τα ν-γραφήματα είναι τοποθετημένα σε μια δομή πλέγματος βασισμένη σε σχέσεις υποτίμησης και επικάλυψης, με κόμβους που εμποδίζουν άλλους κόμβους στην περιοχή τους όταν επιλέγονται ως λεξικό στοιχείο. Δείχνουμε πώς η διαμόρφωση ενός τέτοιου πλέγματος μπορεί να βελτιστοποιηθεί εύκολα, και καταδεικνύουμε χρησιμοποιώντας σχολιασμούς δειγματοληψίας ν-γραμμάτων ότι η μέθοδος μας ξεπερνά σταθερά τις εναλλακτικές επιλογές κατά τουλάχιστον 0.05 σε διάφορα σώματα και γλώσσες.', 'ka': 'ჩვენ ჩვენ ახალი მოდელს, რომელიც გავიღებთ უფრო მრავალური სიტყვების ლექსიკონები დიდი კორპორაზე, რომელიც n-გრამის კანდიდენტების კონკრენტებ ჩვენი n-გრამის მოდელში ლატისკური სტრუქტურაში, რომელსაც სუბსუმპურაციის და გადარწმუნების შესახებ დაბათებულია, სხვა კონტურაციის გადარწმუნებელია, როდესაც ისინი ლექსიკური ელექტიკალური ელექტიკალური გა ჩვენ ჩვენ აჩვენებთ როგორ ასეთი ლატიკის კონფიგურაცია შეიძლება აპტიმიზება tractably, და გამოყენება n-გრამის ნიოტაციების გამოყენებით, რომ ჩვენი მეტი შემდეგ უნდა გავაკეთება ალტენტიფიკაციების შემდეგ 0,05 F-score', 'hu': 'Bemutatunk egy új modellt az n-grammos jelöltek közötti verseny alapján a nagy korpuszokból származó, átfogó többszós lexikonok beszerzésére. Az egyszerű asszociációs mértékek szerinti rangsorolás standard megközelítésével ellentétben modellünkben az n-grammok szubszumációs és átfedési kapcsolatokon alapuló rácsszerkezetben vannak elrendezve, és a közelükben lévő csomópontok gátolják őket lexikális elemként kiválasztva. Megmutatjuk, hogy egy ilyen rács konfigurációja hogyan optimalizálható vonhatóan, és bemutatjuk, hogy a mintázott n-grammok megjegyzéseivel következetesen felülmúlja az alternatívákat legalább 0,05 F pontszámmal több korpuszon és nyelven.', 'it': "Presentiamo un nuovo modello per l'acquisizione di lessici multiword completi da grandi corpora basato sulla concorrenza tra candidati n-gram. Contrariamente all'approccio standard della classificazione semplice per misura di associazione, nel nostro modello n-grammi sono disposti in una struttura reticolare basata su relazioni di subsumption e sovrapposizione, con nodi che inibiscono altri nodi nelle loro vicinanze quando vengono selezionati come elemento lessicale. Mostriamo come la configurazione di un tale reticolo può essere ottimizzata in modo tracciabile e dimostriamo utilizzando annotazioni di n-grammi campionati che il nostro metodo supera costantemente le alternative di almeno 0,05 F-score in diversi corpora e lingue.", 'kk': 'Біз n-грамм кандидаттарының конкуренциясына негізделген үлкен көп сөз лексиканын алу үшін жаңа үлгісін таңдаймыз. Қарапайым реттеу стандартты арқылы қарапайым реттеу үлгісіне қарсы, n- граммалар үлгісімізде латис құрылымында, латис құрылымына негізделген және қатынастарының қатынастарына қарсы болады. Олар лексикалық нәтижесі ретінде таңдалғанда, оның Бұл латицедің баптауларын қалай оңтимизациялау мүмкіндігін көрсету және нәтижелердің нәтижелерін қолдану арқылы нәтижелерін көрсету арқылы, біздің әдіміміздің альтернативерін кемінде 0,05 F- нәтижелерін бірн', 'mk': 'Презентираме нов модел за набавување комплетни мултизборни лексикони од голема корпора базирани на конкуренцијата помеѓу кандидатите на n-грам. In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item.  Ние покажуваме како конфигурацијата на ваквата лактика може да биде оптимизирана трактивно, и демонстрираме користејќи анатации на примерените n-грами дека нашиот метод константно ги надминува алтернативите со најмалку 0,05 F-оценка во неколку корпора и јазици.', 'lt': 'Pateikiame naują model į, pagal kurį gausime išsamius daugiakalbius leksikonus iš didelių korporų, grindžiamus n-gram ų kandidatų konkurencija. Priešingai nei standartinis paprasto klasifikavimo pagal asociacijos matavimą metodas, mūsų modelyje n-gramai yra išdėstyti lazdinėje struktūroje, grindžiamoje požymiais ir sutampančiais santykiais, su mazgais, slopinančiais kitus mazgus jų aplinkoje, kai jie yra pasirinkti kaip leksinis objektas. Mes parodysime, kaip tokios plokštelės konfigūracija gali būti optimizuota traukiamai, ir naudojant mėginių paimtų n-gramų anotacijas įrodome, kad mūsų metodas nuosekliai viršija alternatyvas bent 0,05 F tašku keliose kūnose ir kalbose.', 'ms': 'Kami memperkenalkan model baru untuk mendapatkan leksikon berbilang perkataan yang meliputi dari korpra besar berdasarkan persaingan diantara calon n-gram. Sebaliknya kepada pendekatan piawai bagi peringkat sederhana mengikut ukuran persekutuan, dalam model n-gram kita diatur dalam struktur lattik berdasarkan subumpsi dan hubungan meliputi, dengan nod yang menghalang nod lain di sekitar mereka apabila mereka dipilih sebagai item leksikal. Kita tunjukkan bagaimana konfigurasi lattice seperti ini boleh optimum secara menarik, dan menunjukkan menggunakan anotasi n-gram yang dicampur bahawa kaedah kita secara konsisten melampaui alternatif dengan sekurang-kurangnya 0.05 skor F melalui beberapa korpra dan bahasa.', 'mt': 'Aħn a nippreżentaw mudell ġdid għall-akkwist ta’ lexicons komprensivi b’ħafna kliem minn korpora kbira bbażati fuq il-kompetizzjoni fost kandidati n-gramma. B’kuntrast mal-approċċ standard ta’ klassifikazzjoni sempliċi skont il-miżura ta’ assoċjazzjoni, fil-mudell tagħn a n-grammi huma rranġati fi struttura lattika bbażata fuq is-sottomissjoni u r-relazzjonijiet sovrapposti, b’nodi li jinibixxu nodi oħra fil-viċinanza tagħhom meta jintgħa żlu bħala oġġett lexiku. We show how the configuration of such a lattice can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 F-score across several corpora and languages.', 'ml': 'നമ്മള്\u200d ഒരു പുതിയ മോഡല്\u200d കൊണ്ടുവരുന്നു. നിങ്ങളുടെ പ്രാര്\u200dത്ഥികള്\u200dക്കിടയില്\u200d നിന്നും വലിയ കോര്\u200dപ്പോരിയില്\u200d നിന്നും ഒരു മ സങ്കീര്\u200dണ്ണത്തിന്റെ സാധാരണ റാങ്ങിങ്ങിന്റെ സ്ഥാനത്തില്\u200d നിന്നും വിരോധമാണ്, നമ്മുടെ മോഡല്\u200d n-ഗ്രാമില്\u200d നിര്\u200dമ്മിക്കപ്പെടുന്നത് ഒരു ലാറ്റിക്സ് സ്ഥാനത്താണ ഈ ലാറ്റിക്സിന്റെ ക്രമീകരണങ്ങള്\u200d എങ്ങനെയാണ് ട്രാക്കാബില്\u200d മെച്ചപ്പെടുത്തുന്നതെന്ന് ഞങ്ങള്\u200d കാണിക്കുന്നു. നമ്മുടെ രീതിയില്\u200d നമ്മുടെ മാര്\u200dഗ്ഗം കുറഞ്ഞത് 0', 'mn': 'Бид N-грамм удирдагчдын өрсөлдөөнд үндсэн олон хэлний лексиконуудыг авах шинэ загварыг тайлбарлаж байна. Холбоотой хэмжээгээр энгийн хэмжээний стандарт аргын эсрэг бидний n-граммын загвар нь лексик элемент гэж сонгогдож бусад хэмжээсүүдийг холбогдох, холбоотой холбоотой латис бүтэц дээр зохион байгуулагддаг. Бид яаж ийм латицейн загварыг хэрхэн сайжруулж болох вэ гэдгийг харуулж байгаа бөгөөд хэдэн корпора болон хэл дээр 0,05 F-тоо хэрхэн зарцуулж байгааг харуулж байна.', 'pl': 'Prezentujemy nowy model pozyskiwania kompleksowych leksykonów wielosłownych z dużych korpusów opartych na konkurencji kandydatów n-gramowych. W przeciwieństwie do standardowego podejścia prostego rankingu według miary asocjacji, w naszym modelu n-gramy są ułożone w strukturze siatkowej opartej na relacjach subsumpcji i nakładających się, a węzły hamujące inne węzły w ich sąsiedztwie, gdy są one wybrane jako element leksykalny. Pokazujemy, jak konfigurację takiej siatki można zoptymalizować w sposób ściągający i demonstrujemy przy użyciu adnotacji próbkowanych n-gramów, że nasza metoda konsekwentnie przewyższa alternatywy o co najmniej 0,05 F-score w kilku korpusach i językach.', 'ro': 'Vă prezentăm un nou model pentru achiziționarea de lexicoane multicuvinte cuprinzătoare din corpore mari bazate pe concurența dintre candidații n-gram. Spre deosebire de abordarea standard a clasificării simple pe măsură de asociere, în modelul nostru n-gramele sunt aranjate într-o structură de rețea bazată pe relații de subsumpție și suprapunere, cu noduri inhibând alte noduri din vecinătatea lor atunci când sunt selectate ca element lexical. Vă arătăm cum configurația unei astfel de rețele poate fi optimizată în mod tractabil și demonstrăm folosind adnotări de n-grame eșantionate că metoda noastră depășește constant alternativele cu cel puțin 0,05 F-scor în mai multe corpore și limbi.', 'sr': 'Predstavljamo novi model za kupovinu sveobuhvatnih multiriječnih leksiona iz velike korporacije baziranog n a konkurenciji među kandidatima n-grama. Za suprotnost standardnom pristupu jednostavnog reda po mjeri asocijacije, u n a šem modelu n-grama se organizuju u lattice strukturu baziranoj n a podsumpi i preklapanju odnosa, sa čvorovima koji inhibiraju druge čvorove u svojoj blizini kada su izabrani kao leksički predmet. Mi pokazujemo kako se konfiguracija takve lattice može optimizirati traktabilno, i pokazujemo korištenjem annotacija uzorka n-grama da n a ša metoda konsekventno iznosi alternative od najmanje 0,05 F-rezultata na nekoliko korporacija i jezika.', 'si': 'අපි අළුත් මොඩේලයක් පෙන්වන්නේ න්-ග්\u200dරාම් කාන්ඩියාන්ට අධාරිත්වයෙන් විශේෂ වචන ලෙක්සිකන්ස් ගන්න. ප්\u200dරමාණය සඳහා සාමාන්\u200dය ප්\u200dරමාණය සඳහා සාමාන්\u200dය ප්\u200dරමාණය සඳහා සාමාන්\u200dය ප්\u200dරමාණය සඳහා, අපේ නොඩේල් n-ග්\u200dරාම්ස් වල ලැටිස් ස්ථාපනය සඳහා ප්\u200dරමාණය සඳහා අනිත්  අපි පෙන්වන්නේ කොහොමද මේ ලේටිස්ගේ සැකසුම් කිරීමට හොඳයි, සහ සැම්පල් n-ග්\u200dරාම්ස් වලට පෙන්වන්න පුළුවන් කියලා, අපේ විදියට අඩුම 0.05 F-score විතරය', 'so': 'Tusaale cusub oo a a n shirkad badan ka soo qaadano leksikayaasha luqada kala duduwan oo ku saleysan tartanka kandidiyayaasha n-gram. Iska duwan qaabka caadiga ah ee saqafka saxda ee midowga ururka, waxaa lagu qabanqaabiyaa tusaale n-grams, taasoo ku saleysan xariir dhamaadka iyo xiriirka la xiriira, waxaana la xiriiraa noocyo kale oo ku qarinaya dhinaciisa ku yaal marka loo dooranayo wax la lexico ah. Waxaynu tusnaynaa sida loo tixgelin karo qaababka lambarka ah, waxaana sidoo kale ku bandhigi karnaa calaamada tusaale ahaan n-gram, in qaabkanagu uu si joogto ah u sameynayo bedelyo ugu yaraan 0.05 F-scor oo ku qoran koorasyada iyo afafka kala duduwan.', 'no': 'Vi presenterer eit nytt modell for å henta komplette multiordleksikon frå stor korpora basert på konkurranse mellom n-gram-kandidatar. I contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item. Vi viser korleis oppsettet av slike lattice kan optimaliserast på spor, og demonstrerer med notasjonar på utvalte n-gramer at metoden vår konsistent utfører alternativer med minst 0,05 F-poeng over fleire korporar og språk.', 'ur': 'ہم ایک نئی مدل پیش کرتے ہیں کہ ان گرم کاندینٹوں کے درمیان رقابت پر بنیاد رکھتے ہیں بہت سی کلمات لکسونز کو ملنے کے لئے۔ ساده رینگ کے استاندارڈ طریقے کے مقابلہ میں، ہمارے نمڈل n-گرم میں ایک لاتیس ساختار میں رکھا گیا ہے جو غلطی اور غلطی رابطہ پر بنیاد ہے، اور نوڈ کے ساتھ دوسرے نوڈوں کو ان کے قریب میں پھیر رہے ہیں جب وہ لکسیکل اتم کے طور پر انتخاب کئے جاتے ہیں. ہم دکھاتے ہیں کہ ایسی لاتیس کی پیکربندی کس طرح اچھی طرح تراکٹ کر سکتی ہے اور نمونۂ n-گرم کے مطابق دکھاتے ہیں کہ ہماری طریقہ بہت کم 0.05 F-اسکور کے ذریعہ بہت سی کوروں اور زبانوں میں اچھی طرح اضافہ کرتی ہے۔', 'sv': 'Vi presenterar en ny modell för att förvärva omfattande flerords lexikon från stora corpora baserat på konkurrens mellan n-gramkandidater. I motsats till standardmetoden för enkel rangordning efter associationsmått är n-gram i vår modell ordnade i en gitterstruktur baserad på subsumption och överlappning relationer, med noder som hämmar andra noder i deras närhet när de väljs som ett lexikalt objekt. Vi visar hur konfigurationen av ett sådant galler kan optimeras spårbart, och visar med hjälp av noteringar av provtagna n-gram att vår metod konsekvent överträffar alternativ med minst 0,05 F-poäng över flera korpor och språk.', 'ta': 'நாம் பெரிய நிறுவனத்திலிருந்து முழுமையான பல்வார்த்தை லெக்சிக்களை பெறுவதற்கு புதிய மாதிரியை கொண்டு வருகிறோம இணைப்பு அளவில் சுலபமான வரிசையின் இயல்பான செயல்பாட்டிற்கு எதிராக, எங்கள் மாதிரியில் n- கிராம் ஒப்பிணைப்பு மற்றும் மேல் உறவுகளை அடிப்படையில் அமைக்கப்பட்டுள்ளது, மற் நாம் இத்தகைய லாட்டிக்ஸின் வடிவமைப்பு எவ்வாறு தேர்ந்தெடுக்க முடியும் என்பதை காட்டுகிறோம் மற்றும் மாதிரி n- கிராம்களின் அறிவிப்புகளை பயன்படுத்தி காட்டுக', 'uz': "Biz bir yangi modelni n a gram kandidalarning katta kompaniyadan o'zgarishga ega bo'lgan katta so'zlar leksikalarini olish uchun yaratdik. Name Biz bu lattikning moslamalarini qanday tractabda optimiz mumkin, va sampul n-grammalarning annotatlarini ishlatish mumkin. Ushbu usulning bir nechta ko'plab korpora va tillar bilan bir necha 0.05 F scorning boshqalarini bajaradi.", 'vi': 'Chúng tôi giới thiệu một mô hình mới cho việc mua đồ từ đa từ toàn diện từ tập đoàn lớn dựa trên sự cạnh tranh giữa các ứng viên n-gram. Khác với cách tiếp cận tiêu chuẩn của xếp hạng đơn giản theo biện pháp liên quan, trong mẫu n- g của chúng tôi được sắp xếp theo một cấu trúc phản trắc dựa trên các mối quan hệ ngầm và chồng chéo, với các n út ngăn các nút khác trong vùng lân cận khi chúng được chọn là một mục ngôn ngữ. Chúng tôi cho thấy cách cấu hình của tấm lưới n ày có thể được tối đa tỉ mỉ, và bằng cách sử dụng chú thích của n-gam thử ra rằng phương pháp của chúng tôi hoàn toàn vượt trội các lựa chọn khác nhau bằng ít nhất 0.05, điểm F trong nhiều loại bằng cơ thể và ngôn ngữ khác nhau.', 'bg': 'Представяме нов модел за придобиване на всеобхватни многословни лексикони от големи корпуси въз основа на конкуренцията между кандидатите за n-грам. За разлика от стандартния подход на простото класиране по асоциационна мярка, в нашия модел n-грамите са подредени в решетка структура, базирана на взаимоотношенията на поглъщане и припокриване, като възлите инхибират други възли в тяхната околност, когато са избрани като лексикален елемент. Показваме как конфигурацията на такава решетка може да бъде оптимизирана проследимо и демонстрираме чрез анотации на извадени образци н-грамове, че методът ни постоянно превъзхожда алтернативите с най-малко 0,05 точки в няколко корпуса и езика.', 'nl': 'We presenteren een nieuw model voor het verwerven van uitgebreide multiword lexicons uit grote corpora gebaseerd op concurrentie tussen n-gram kandidaten. In tegenstelling tot de standaardbenadering van eenvoudige rangschikking per associatiemaat, zijn in ons model n-grammen gerangschikt in een roosterstructuur gebaseerd op subsumptie- en overlappingsverbanden, waarbij knooppunten andere knooppunten in hun omgeving remmen wanneer ze worden geselecteerd als lexicaal item. We laten zien hoe de configuratie van een dergelijk rooster traceerbaar kan worden geoptimaliseerd, en demonstreren aan de hand van annotaties van sampled n-gram dat onze methode consequent alternatieven overtreft met ten minste 0,05 F-score in verschillende corpora en talen.', 'da': 'Vi præsenterer en ny model for erhvervelse af omfattende multiword leksikoner fra store korpora baseret på konkurrence mellem n-gram kandidater. I modsætning til standardmetoden med simpel rangering efter associationsmål, er n-grams i vores model arrangeret i en gitterstruktur baseret på subsumpation og overlapning relationer, med knuder, der hæmmer andre knuder i deres nærhed, når de vælges som et leksikalsk element. Vi viser, hvordan konfigurationen af et sådant gitter kan optimeres markant, og demonstrerer ved hjælp af noteringer af prøveudtagne n-gram, at vores metode konsekvent overgår alternativer med mindst 0,05 F-score på tværs af flere korpora og sprog.', 'hr': 'Predstavljamo novi model za kupovinu sveobuhvatnih multiriječnih leksiona iz velike korporacije n a temelju konkurencije među kandidatima n-grama. Za suprotnost standardnom pristupu jednostavnog reda po mjeri udruženja, u n a šem modelu n-grama se organiziraju u lattice strukturu koja se temelji n a podsumpi i preklapanju odnosa, s čvorovima koji inhibiraju druge čvorove u svojoj blizini kada su izabrani kao leksički predmet. Mi pokazujemo kako se konfiguracija takvog lattice može optimizirati n a traktan n a čin, i pokazujemo koristeći annotacije uzorka n-grama da naša metoda konsekventno iznosi alternative najmanje 0,05 F-rezultata na nekoliko tijela i jezika.', 'de': 'Wir präsentieren ein neues Modell für den Erwerb umfassender Mehrwortlexicons aus großen Korpora basierend auf der Konkurrenz unter n-Gramm Kandidaten. Im Gegensatz zum Standardansatz der einfachen Rangfolge nach Assoziationsmaßstab sind in unserem Modell n-Gramm in einer Gitterstruktur angeordnet, die auf Subsumtion- und Überlappungsbeziehungen basiert, wobei Knoten andere Knoten in ihrer Nähe hemmen, wenn sie als lexikalisches Element ausgewählt werden. Wir zeigen, wie die Konfiguration eines solchen Gitters nachvollziehbar optimiert werden kann, und zeigen anhand von Annotationen von gesampelten n-Gramm, dass unsere Methode Alternativen konsequent um mindestens 0,05 F-Score in mehreren Korpora und Sprachen übertrifft.', 'id': 'Kami mempersembahkan model baru untuk mendapatkan leksikon multikata komprensif dari korpora besar berdasarkan kompetisi di antara kandidat n-gram. Berbeda dengan pendekatan standar dari rangkaian sederhana berdasarkan ukuran asosiasi, dalam model n-gram kita diatur dalam struktur lattice berdasarkan sumpah dan hubungan meliputi, dengan node yang menghalangi node lain di sekitar mereka ketika mereka dipilih sebagai item leksik. Kami menunjukkan bagaimana konfigurasi dari lattice seperti itu dapat optimisasi secara traktif, dan menunjukkan menggunakan anotasi n-gram yang ditempatkan sampel bahwa metode kami secara konsisten melampaui alternatif dengan setidaknya 0,05 F-skor melalui beberapa corpora dan bahasa.', 'fa': 'ما یک مدل جدید برای خریدن کلمه\u200cهای کلمه\u200cای از شرکت بزرگ بر اساس رقابت بین کاندیداتهای n گرم پیشنهاد می\u200cکنیم. بر خلاف طریق استاندارد صف ساده با اندازه اندازه اتصال، در مدل n-گرم ما در یک ساختار لاتیس بر اساس رابطه\u200cهای ضبط و غیرقابل تغییر قرار گرفته می\u200cشوند، با گرم\u200cها که در نزدیک\u200cشان گرم\u200cهای دیگری را مانع می\u200cکنند وقتی آنها به عنوان یک عنوان زبان انتخاب می\u200cشوند. ما نشان می دهیم که چگونه پیکربندی چنین لاتیس می تواند به طور کامل ترکیب داده شود، و با استفاده از نوشته\u200cهای نمونه\u200cهای n گرم نشان می\u200cدهیم که روش ما به طور کاملاً با حداقل 0.05 امتیاز F در چندین شرکت و زبان تغییر داده می\u200cشود.', 'ko': '우리는 n-gram 후보어 간의 경쟁을 바탕으로 대형 어료 라이브러리에서 종합적인 다사 어휘를 얻는 새로운 모델을 제시했다.관련 도량을 통해 간단하게 정렬하는 표준 방법과 달리 우리 모델에서 n-gram은 포용과 중첩 관계를 바탕으로 하는 격자 구조에 배치되고 노드가 어휘항으로 선택될 때 노드는 그 부근의 다른 노드를 억제한다.우리는 이러한 결정격의 배치가 어떻게 조작 가능하게 최적화되었는지 보여주었고 샘플링된 n-그림의 주석을 사용하여 우리의 방법이 여러 개의 어료 라이브러리와 언어에서 예비 방안, 적어도 0.05F-점수보다 우수하다는 것을 증명했다.', 'tr': 'Biz täze bir nusga örän uly korporadan ähli köp söz leksiklerini almak üçin täze bir nusga görkeýäris Esasy çyzygyň düzümleri görä, n-gramlarymyzyň nusgasyna sereden we golaýlaşyklaryň üstine golaýlaşyk we golaýlaşyk düzümlerinde düzenlenýär. Biz bu şekilde lattice yapılandyrmasynyň n ädip göz önüne getirilip biljek bolandygyny görkez we biziň metodamyz birnäçe korpora we dilleriň içinde 0,05 F अಂwatynyň üstüne getirip biljekdigini görkez.', 'af': "Ons stel 'n nuwe model om kompleksies multiwoorde leksies te kry van groot korpora gebaseer op samenskap onder n-gram kandidate. In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item. Ons wys hoe die konfigurasie van sodanige 'n lattice kan optimaliseer word, en wys deur die gebruik van notasies van opgemaakte n-grame dat ons metode konsistentlik alternatiewe uitvoer deur minste 0,05 F-telling oor verskeie korpore en tale.", 'sw': 'Tunaweza kutengeneza mfano mpya wa kupata lexico makusanyiko ya lugha mbalimbali kutoka makampuni makubwa kwa sababu ya ushindani kati ya wagombea picha za gram. Tofauti n a mbinu za msingi wa rangi rahisi kwa njia ya ushirikiano, katika mifano yetu n-gram imeandaliwa katika muundo wa vifaa vya vifaa kwa kutumia mahusiano na upana, na vipande vinavyozuia vipande vingine katika maeneo yao wakati wanachaguliwa kama bidhaa ya lexico. Tunaonyesha jinsi ubunifu wa kitendo hicho unavyoweza kuchukuliwa vizuri, n a kuonyesha kwa kutumia matangazo ya vipindi vipimo vya vipimo vya n-gram ambavyo mbinu yetu kwa ujumla hufanya mabadiliko kwa kiwango cha 0.05 F katika makampuni na lugha mbalimbali.', 'am': 'አዲስ ምሳሌ በ-ግራም ተቃዋሚዎች መካከል ትልቁ ኮርፖርተር ውስጥ የተቃውሞ ብዛት ሌክሲዎችን ለማግኘት እናቀርባለን፡፡ በአካባቢ መስኮት የቀላል አካሄዱን አካሄድ በተቃውሞ፣ በዓይነታችን n-ግራም ግንኙነት ላይ በተመሳሳይ እና በተጨማሪው ግንኙነት ላይ በተመሳሳይ እና በአካባቢነታቸው ላይ ሌሎችን አካሄድ በመለጠፍ ይደረጋል፡፡ እንደዚህ የደረጃ መሠረት እንዴት እንደተሻለ እናሳየዋለን፣ እና በክሮፓርና ቋንቋዎች ላይ በሙሉ የn-gram ማስታወቂያውን እናሳያልን፡፡', 'sq': 'Ne paraqesim një model të ri për blerjen e lexikonëve të plotë shumë fjalë nga korpra e madhe bazuar n ë konkurrencën midis kandidatëve n-gram. Në kundërshtim me qasjen standard të renditjes së thjeshtë sipas masës së shoqërimit, n ë model in tonë n-gram janë të rregulluar në një strukturë lattice bazuar në nënsupozimin dhe lidhjet e kapërcimit, me nyje që pengojnë nyje të tjera në afërsinë e tyre kur janë zgjedhur si një element lexik. Ne tregojmë se si konfigurimi i një kërcimi të tillë mund të optimizohet n ë mënyrë tërheqëse, dhe demonstrojmë duke përdorur anotacionet e n-grameve të marrë në moshë se metoda jonë vazhdimisht mbizotëron alternativat me të paktën 0.05 pikë F në disa korpra dhe gjuhë.', 'az': "Biz n-gram kandidātları arasında müharibəyə dayanan bütün çoxlu söz leksiklərini almaq üçün yeni bir modeli göstəririk. Əlavə ölçüləri ilə basit səviyyələrin standart tərzinə baxmayaraq, n-gramlarımızın modelləri leksik məlumatı olaraq seçilmiş olaraq başqa düğümləri təhlükəsizləyən bir lattice yapısında hazırlanmışdır. Biz bu lattice'in yapılandırmasın ı necə optimizləndiriləcəyini göstəririk, və nöqtəli n-gramların nöqtələrini istifadə edərək göstəririk ki, metodumuzun ən azından 0,05 F-score ilə bir neçə korpora və dillərin arasında alternatiflarını sürəkləndirir.", 'bn': 'আমরা একটি নতুন মডেল উপস্থাপন করছি ন-গ্রাম প্রার্থীদের মধ্যে প্রতিযোগিতার ভিত্তিতে বিশাল কোর্পোরা থেকে মাল্টিশব্দ লে সংযোগ মাপের মাধ্যমে সহজ রেঙ্কিং এর স্বাভাবিক পদ্ধতির বিপরীতে, আমাদের মডেল এন-গ্রামের একটি ল্যাটিক কাঠামোর স্থাপন করা হয়েছে বিভিন্ন সম্পর্কের ভিত্তিতে এবং অতিরিক্ত সম We show how the configuration of such a lattice can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 F-score across several corpora and languages.', 'hy': 'Մենք ներկայացնում ենք նոր մոդել, որպեսզի ստանանք բազմաբառ լեքսիկոններ մեծ կառուցվածքից, հիմնված n-գրամ թեկնածուների մրցակցության վրա: Ի հակադրություն պարզ դասավորման ստանդարտ մոտեցումներին, ըստ ասոցացիայի չափումների, մեր n-գրամամը դասավորվում է կառուցվածքի մեջ, որը հիմնված է ենթահարման և հակադրման հարաբերությունների վրա, հանգույցները արգելափակում են այլ հանգույցները իրենց շրջապատում, երբ ընտրվում են որպես լեք Մենք ցույց ենք տալիս, թե ինչպես կարող է այդպիսի կառուցվածքը օպտիմացվել լավագույն ձևով, և ցույց ենք տալիս, օգտագործելով նմուշ վերցված n-գրամ նոտացիաներ, որ մեր մեթոդը մշտապես գերազանցում է այլընտրանքային արտադրողությունները առնվազն 0.05F-գնով մի քանի', 'bs': 'Predstavljamo novi model za kupovinu sveobuhvatnih multiriječnih leksiona iz velike korporacije n a temelju konkurencije među kandidatima n-grama. Za suprotnost standardnom pristupu jednostavnog reda po mjeri asocijacije, u n a šem modelu n-grama se organizuju u lattice strukturi baziranoj n a podsumpi i preklapanju odnosa, sa čvorovima koji inhibiraju druge čvorove u svojoj blizini kada su izabrani kao leksički predmet. Mi pokazujemo kako se konfiguracija takvog lattice može optimizirati n a traktan n a čin, i pokazujemo koristeći annotacije uzorke n-grama da naša metoda konsekventno iznosi alternative od najmanje 0,05 F-rezultata na nekoliko korporacija i jezika.', 'cs': 'Představujeme nový model pro získávání komplexních multislovních lexikonů z velkých korpusů založený na konkurenci kandidátů na n-gramech. Na rozdíl od standardního přístupu jednoduchého řazení podle asociační míry jsou v našem modelu n-gramy uspořádány do mřížkové struktury založené na subsumpčních a překrývacích vztazích, přičemž uzly inhibují další uzly v jejich blízkosti, když jsou vybrány jako lexikální prvek. Ukážeme, jak lze konfiguraci takové mřížky optimalizovat trajektelně a pomocí anotací vzorkovaných n-gramů demonstrujeme, že naše metoda konzistentně předčuje alternativy alespoň o 0,05 F-skóre napříč několika korpusy a jazyky.', 'ca': "Presentam un nou model per adquirir lexicòns multiparaules integrals de grans corpores basats en la competició entre candidats a n-gram. Contrariament a l'enfocament normal de la classificació simple per mesura d'associació, en el nostre model n-grams es organitzen en una estructura de lattice basada en la suposició i les relacions sovrapposes, amb nodos que inhibeixen altres nodes al seu voltant quan són seleccionats com a objecte lèxic. Mostrem com la configuració d'una així llatícia pot ser optimitzada de manera tractable, i demostram utilitzant anotacions de n-grams de mostra que el nostre mètode supera constantment alternatives per almenys 0,05 puntuació F en diverses corpores i llengües.", 'et': 'Tutvustame uut mudelit laiaulatuslike mitmesõnaliste leksikonide omandamiseks suurkorpustest, mis põhineb n-grammi kandidaatide konkurentsil. Erinevalt tavapärasest lähenemisviisist lihtsale järjestamisele seosmõõtme järgi, on n-grammid meie mudelis paigutatud võre struktuuriks, mis põhineb allumis- ja kattumissuhetel, kus sõlmed pärsivad teisi nende läheduses olevaid sõlme, kui need valitakse leksikaalseks elemendiks. Näitame, kuidas sellise võre konfiguratsiooni saab jälgitavalt optimeerida, ja näitame, kasutades näidistatud n-grammide annotatsioone, et meie meetod on järjepidevalt alternatiividest üle vähemalt 0,05 F-skoori mitmes korpuses ja keeles.', 'fi': 'Esittelemme uuden mallin kattavien monikanavaisten sanakirjojen hankkimiseksi suurista korpusista, joka perustuu n-gram-ehdokkaiden väliseen kilpailuun. Toisin kuin perinteisessä lähestymistavassa yksinkertaisesta luokittelusta assosiointiteetin mukaan, mallissamme n-grammit on järjestetty ristikkorakenteeseen, joka perustuu subsumptio- ja päällekkäissuhteisiin, jolloin solmut estävät muita solmuja niiden läheisyydessä, kun ne valitaan leksikaaliseksi kohteeksi. Näytämme, miten tällaisen ristikon konfigurointi voidaan optimoida jäljitettävästi, ja osoitamme näytteiden n-grammojen huomautusten avulla, että menetelmämme suoriutuu johdonmukaisesti vaihtoehtoisista vaihtoehdoista vähintään 0,05 F-pisteellä useilla korpusilla ja kielillä.', 'jv': 'Awak dhéwé éntuk model sing dibuté kanggo nggawe akeh luwih akeh akeh luwih akeh akeh onh dumadhi kaé kabèh dumadhi sak kandidé n-gram. Genjer-Genjer Awak dhéwé éntukno sistem sampeyan karo akeh sistêm nggawe tracTably, lan n êmêrke ngerasakno ngono video nggawe n-gram sampeyan sing bisalakno sistem dhéwé ngerasakno liyane 0.05 F-sampeyan sing paling dhéwé', 'he': 'אנו מציגים מודל חדש להשיג מלקסיקונים ממילים רבות מורכבות ממורה גדולה מבוסס על תחרות בין מועמדים n-גרם. בניגוד לגישה הסטנדרטית של הדרגה הפשוטה על ידי מדידת איגוד, במודל n-גרם שלנו מאורגנים במבנה מתקן המבוסס על מערכות התעללות ומערכת יחסים מתקפלות, עם קשרים שמעצרים קשרים אחרים בסביבתם כאשר הם נבחרים כפריט לקסיקלי. אנו מראים כיצד ניתן לאופטיזם את התבנות של כזה מעגל באופן אופטימלי, ולהראות באמצעות ציונים של n-גרם שנבחרו בדגימה שהשיטה שלנו עולה באופן קבוע מעל אלטרנטיביות על ידי לפחות 0.05 F-נקודה ברחבי מספר גופרות ושפות.', 'ha': "Tuna gabatar da wani misali n a sami multi-word leksiya daga makampuni makusanci, a kan karatun-gram. Tsarin hanyarwa n a daidaita matsayin mai sauƙi da matsayin association, a cikin misãlai na n-gram, ana ƙayyade a cikin matsayin latice, a kan kan salon da kuma ya rufe danganta, da node sunã tsare wasu node a ƙarƙashin su idan an zãɓe su kamar abun leksisi. Tuna n ũn a canza tsarin wannan littarin da za a iya amfani da taƙaitaccen, kuma Mu nuna su yi amfani da sunayen n-gram da misãlai da za'a kiyaye musamman da ko da a ƙara 0.05 F-score kowace ko da harshen.", 'sk': 'Predstavljamo nov model pridobivanja celovitih večbesednih leksikonov iz velikih korpusov, ki temelji na tekmovanju med kandidati n-gramov. V nasprotju s standardnim pristopom enostavnega razvrščanja po asociacijskem merilu so n-grami v našem modelu razporejeni v mrežno strukturo, ki temelji na razmerjih med subsumpcijo in prekrivanjem, pri čemer vozlišča zavirajo druga vozlišča v njihovi bližini, ko so izbrana kot leksikalna postavka. Pokazali bomo, kako je konfiguracijo takšne mreže mogoče optimizirati trajnostno, in z uporabo opomb vzorčenih n-gramov dokazali, da naša metoda dosledno presega alternative za vsaj 0,05 F-score v več korpusih in jezikih.', 'bo': 'ང་ཚོས་བྱ་ཚིག་ཆེན་པོ་ཞིག་ལས་སྡོམ་ཁང་ཆེན་ཡིག་གི་སྣ་ཚོགས་མང་པོ་ཞིག་མཉམ་དུ་བཞག་སྟེ། In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item. We show how the configuration of such a lattice can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 F-score across several corpora and languages.'}
{'en': 'Replicability Analysis for Natural Language Processing : Testing Significance with Multiple Datasets', 'ar': 'تحليل قابلية النسخ المتماثل لمعالجة اللغة الطبيعية: اختبار الأهمية باستخدام مجموعات بيانات متعددة', 'pt': 'Análise de Replicabilidade para Processamento de Linguagem Natural: Testando a Importância com Vários Conjuntos de Dados', 'fr': 'Analyse de réplicabilité pour le traitement du langage naturel\xa0: tester la signification avec plusieurs ensembles de données', 'es': 'Análisis de replicabilidad para el procesamiento del lenguaje natural: comprobación de la importancia con varios conjuntos de datos', 'ja': '自然言語処理の複製可能性分析：複数のデータセットでの意義のテスト', 'zh': '自然语言处可重复性析:以数集试显著性', 'hi': 'प्राकृतिक भाषा प्रसंस्करण के लिए Replicability विश्लेषण: एकाधिक डेटासेट के साथ परीक्षण महत्व', 'ru': 'Анализ воспроизводимости для обработки на естественном языке: тестирование значимости с несколькими наборами данных', 'ga': 'Anailís Macasamhailteachta le haghaidh Próiseáil Teanga Nádúrtha: Tábhacht a Thástáil le Tacair Shonraí Il', 'ka': 'ნაირადი ენერგიის პროცესისთვის რედაქტიფიკაცია ანალიზი: მრავალური ენერგიის პროცესისთვის შესაძლებლობა', 'el': 'Ανάλυση αντιγραφιμότητας για επεξεργασία φυσικής γλώσσας: Δοκιμή σπουδαιότητας με πολλαπλά σύνολα δεδομένων', 'hu': 'replikálhatósági elemzés a természetes nyelv feldolgozásához: Jelentőség tesztelése több adatkészlettel', 'it': "Analisi della replicabilità per l'elaborazione del linguaggio naturale: testare la significatività con più set di dati", 'lt': 'Gamtinės kalbos perdirbimo pakaitalumo analizė: reikšmingumo bandymas naudojant kelis duomenų rinkinius', 'mk': 'Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets', 'ms': 'Analisis Kembalian untuk Pemprosesan Bahasa Semulajadi: Menuji Kemuliaan dengan Set Data Berbilang', 'ml': 'സ്വാഭാവ ഭാഷയുടെ പ്രക്രിയയ്ക്കുവേണ്ടി പകര്\u200dത്താവുന്നതിനുള്ള അന്യായം', 'mt': 'Analiżi tar-Replikabbiltà għall-Ipproċessar tal-Lingwi Naturali: Sinfikanza tal-Ittestjar b’Settijiet ta’ Dejta Multipli', 'no': 'Analyser for replikabilitet for naturspråk- handsaming: Tester signifikans med fleire databaser', 'mn': 'Байгалийн хэл процессийн хувьд хариултын шинжилгээ: олон өгөгдлийн өгөгдлийн үнэ цэнэтэй шалгалт', 'pl': 'Analiza powielalności dla przetwarzania języka naturalnego: testowanie znaczenia z wieloma zbiorami danych', 'sr': 'Analiza replikabilnosti prirodnog jezika: testiranje značajnosti sa višestrukim podacima', 'ro': 'Analiza replicabilității pentru procesarea limbajului natural: testarea semnificației cu seturi de date multiple', 'si': 'ප්\u200dරාකෘතික භාෂාව ප්\u200dරක්\u200dරියාපනය සඳහා ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණය: ගොඩක් දත්ත සැකසු', 'so': 'Analyska u baahan kara shaqooyinka afka asalka ah: Imtixaanka Significance with Multiple Datasets', 'sv': 'Replikabilitetsanalys för behandling av naturligt språk: Testning av signifikans med flera datauppsättningar', 'ta': 'Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets', 'ur': 'طبیعی زبان پرسس کے لئے جواب دینے والی تحلیل: بہت سی ڈیٹائیسٹ کے ساتھ نشانیاں امتحان کرنا', 'kk': 'Табиғи тіл процессерінің қайталанушылығын анализ: Бірнеше деректер қорымен маңыздылығын тексеру', 'uz': 'Name', 'vi': 'Dịch hóa ngôn ngữ tự nhiên: Kiểm tra ký hiệu với nhiều bộ dữ liệu', 'bg': 'Анализ на възпроизвеждането за обработка на естествен език: тестване на значимостта с множество набори от данни', 'nl': 'Replicability Analysis voor Natural Language Processing: Significance testen met meerdere datasets', 'hr': 'Analiza replikabilnosti prirodnog jezika: testiranje značajnosti s višestrukim podacima', 'da': 'Replikabilitetsanalyse til behandling af naturligt sprog: Test af betydning med flere datasæt', 'de': 'Replizierbarkeitsanalyse für die Verarbeitung natürlicher Sprache: Signifikanz mit mehreren Datensätzen testen', 'ko': '자연 언어 처리의 복제성 분석: 여러 데이터 집합으로 현저성 테스트', 'id': 'Analis Replikabilitas untuk Proses Bahasa Alami: Menguji Significance dengan Multiple Dataset', 'fa': 'تحلیل قابلیت تغییر قابلیت برای فرایند زبان طبیعی: امتحان تعریف با داده های چندین', 'sq': 'Analiza e Replikabilitetit për Procesimin e gjuhës natyrore: Testimi i rëndësisë me shumë të dhëna', 'sw': 'Uchambuzi wa Umoja wa Utafiti wa Kiraia: Kujaribu Uonyesho na Taarifa nyingi', 'af': 'Replikabiliteit Analiseer vir Natuurlike Taal Prosessering: Toets belangrikheid met Veelvuldige Databasis', 'tr': 'Natal dil işlemek üçin Replicability Analizi: Birden Maglumaty bilen Ullanyş Taýramy', 'am': 'ምርጫዎች', 'hy': 'Բնական լեզվի մշակույթի վերարտադրողականության վերլուծությունը. նշանակության փորձում բազմաթիվ տվյալների օգնությամբ', 'az': 'Təbiətli Dil İşləməsi üçün Replicability Analizi: Birçoxlu Verici Üstüsü ilə İşaretlənməsi', 'bn': 'স্বাভাবিক ভাষা প্রক্রিয়ার জন্য প্রতিক্রিয়া বিশ্লেষণ: বহুবার তথ্যের স্বাক্ষর পরীক্ষা করা হচ্ছে', 'cs': 'Analýza replikovatelnosti pro zpracování přirozeného jazyka: testování významnosti s více datovými sadami', 'et': 'Loodusliku keele töötlemise korratavuse analüüs: olulisuse testimine mitme andmekogumiga', 'bs': 'Analiza replikabilnosti prirodnog jezika: testiranje značajnosti sa višestrukim podacima', 'ca': 'Anàlisi de Replicabilitat per al Procesament de Llingues Naturals: Probar la significància amb Multiple Datasets', 'fi': 'Toistettavuusanalyysi luonnollisen kielen käsittelyyn: Merkittävyyden testaus useilla tietosarjoilla', 'jv': 'Replika iku', 'ha': 'Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets', 'he': 'Analysis of Replicability for Natural Language Processing: Testing Significance with Multiple Datasets', 'sk': 'Analiza ponovljivosti za obdelavo naravnega jezika: testiranje pomembnosti z več nabori podatkov', 'bo': 'Natural Language Processing for Replicability Analysis: Testing Significance with Multiple Datasets'}
{'en': 'With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups. However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions. In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks. We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications : multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.', 'ar': 'مع الكم المتزايد باستمرار من البيانات النصية من مجموعة كبيرة ومتنوعة من اللغات والمجالات والأنواع ، أصبح تقييم خوارزميات البرمجة اللغوية العصبية على مجموعات بيانات متعددة من أجل ضمان أداء ثابت عبر الإعدادات غير المتجانسة. ومع ذلك ، فإن مثل هذه المقارنات المتعددة تشكل تحديات كبيرة لأساليب التحليل الإحصائي التقليدية في البرمجة اللغوية العصبية ويمكن أن تؤدي إلى استنتاجات خاطئة. في هذا البحث نقترح إطار عمل لتحليل النسخ المتماثل لتحليل سليم إحصائيًا للمقارنات المتعددة بين الخوارزميات لمهام البرمجة اللغوية العصبية. نناقش المزايا النظرية لهذا الإطار على الممارسة الحالية ، غير المبررة إحصائيًا ، في أدبيات البرمجة اللغوية العصبية ، ونوضح قيمتها التجريبية عبر أربعة تطبيقات: تحليل التبعية متعدد المجالات ، وعلامات نقاط البيع متعددة اللغات ، وتصنيف المشاعر عبر المجالات وتنبؤ تشابه الكلمات.', 'fr': "Avec la quantité toujours croissante de données textuelles provenant d'une grande variété de langues, de domaines et de genres, il est devenu standard d'évaluer les algorithmes NLP sur plusieurs ensembles de données afin de garantir des performances cohérentes dans des configurations hétérogènes. Cependant, de telles comparaisons multiples posent des défis importants aux méthodes d'analyse statistique traditionnelles en PNL et peuvent conduire à des conclusions erronées. Dans cet article, nous proposons un cadre d'analyse de réplicabilité pour une analyse statistiquement solide de comparaisons multiples entre des algorithmes pour des tâches de PNL. Nous discutons des avantages théoriques de ce cadre par rapport à la pratique actuelle, statistiquement injustifiée, dans la littérature NLP, et démontrons sa valeur empirique dans quatre applications\xa0: analyse de dépendance multidomaine, marquage POS multilingue, classification des sentiments entre domaines et similarité de mots prédiction.", 'pt': 'Com a quantidade cada vez maior de dados textuais de uma grande variedade de idiomas, domínios e gêneros, tornou-se padrão avaliar algoritmos de PNL em vários conjuntos de dados para garantir um desempenho consistente em configurações heterogêneas. No entanto, essas comparações múltiplas representam desafios significativos para os métodos tradicionais de análise estatística em PNL e podem levar a conclusões errôneas. Neste artigo propomos um framework de Análise de Replicabilidade para uma análise estatisticamente sólida de múltiplas comparações entre algoritmos para tarefas de PNL. Discutimos as vantagens teóricas dessa estrutura sobre a prática atual, estatisticamente injustificada, na literatura de PNL e demonstramos seu valor empírico em quatro aplicações: análise de dependência de vários domínios, marcação de POS multilíngue, classificação de sentimento entre domínios e previsão de similaridade de palavras.', 'es': 'Con la cantidad cada vez mayor de datos textuales de una gran variedad de idiomas, dominios y géneros, se ha convertido en estándar evaluar los algoritmos de PNL en múltiples conjuntos de datos para garantizar un rendimiento uniforme en configuraciones heterogéneas. Sin embargo, estas comparaciones múltiples plantean desafíos significativos para los métodos tradicionales de análisis estadístico en PNL y pueden conducir a conclusiones erróneas. En este artículo proponemos un marco de análisis de replicabilidad para un análisis estadísticamente sólido de comparaciones múltiples entre algoritmos para tareas de PNL. Discutimos las ventajas teóricas de este marco sobre la práctica actual, estadísticamente injustificada, en la literatura de PNL, y demostramos su valor empírico en cuatro aplicaciones: análisis de dependencias multidominio, etiquetado POS multilingüe, clasificación de sentimientos entre dominios y similitud de palabras predicción.', 'ja': '多種多様な言語、ドメイン、およびジャンルからのテキストデータの量が増大しているため、異種のセットアップ全体で一貫したパフォーマンスを確保するために、複数のデータセット上のNLPアルゴリズムを評価することが標準化されています。しかしながら、このような複数の比較は、NLPにおける従来の統計分析手法に重大な課題をもたらし、誤った結論をもたらす可能性がある。本稿では， NLPタスクのアルゴリズム間の複数比較の統計的に健全な分析のための複製可能性分析フレームワークを提案する．私たちは、NLP文献における現在の統計的に不当な実践に対するこのフレームワークの理論的利点を論じ、マルチドメイン依存性解析、多言語POSタグ付け、クロスドメイン感情分類、および単語類似性予測の4つのアプリケーションにわたってその実証的価値を実証します。', 'ru': 'С постоянно растущим объемом текстовых данных от большого разнообразия языков, доменов и жанров, стало стандартным оценивать алгоритмы NLP на нескольких наборах данных, чтобы обеспечить согласованную производительность в гетерогенных установках. Однако такие многочисленные сопоставления создают значительные проблемы для традиционных методов статистического анализа в НЛП и могут приводить к ошибочным выводам. В этой статье мы предлагаем структуру анализа воспроизводимости для статистически обоснованного анализа множественных сравнений между алгоритмами для задач NLP. Мы обсуждаем теоретические преимущества этого фреймворка по сравнению с текущей, статистически необоснованной, практикой в литературе NLP и демонстрируем его эмпирическую ценность в четырех приложениях: многодоменный синтаксический анализ зависимостей, многоязычная маркировка POS, междоменная классификация настроений и прогнозирование подобия слов.', 'zh': '随诸语言领域及流派文本数据量增长,于数集上评估 NLP 算法已为率,以保跨异构设之一体。 然此多NLP故事统计分析大挑战,或致非论。 本文有可复制性析框架,NLP算法多重较理。 臣等论框架对时计之不中者NLP文献受用之论,并验其验于四:多域赖解析,多言POS记,跨域情类与单词相似性占。', 'hi': 'भाषाओं, डोमेन और शैलियों की एक बड़ी विविधता से पाठ्य डेटा की बढ़ती मात्रा के साथ, विषम सेटअप में एक सुसंगत प्रदर्शन सुनिश्चित करने के लिए कई डेटासेट पर एनएलपी एल्गोरिदम का मूल्यांकन करना मानक बन गया है। हालांकि, इस तरह की कई तुलनाएं एनएलपी में पारंपरिक सांख्यिकीय विश्लेषण विधियों के लिए महत्वपूर्ण चुनौतियां पैदा करती हैं और गलत निष्कर्ष निकाल सकती हैं। इस पेपर में हम एनएलपी कार्यों के लिए एल्गोरिदम के बीच कई तुलनाओं के सांख्यिकीय रूप से ध्वनि विश्लेषण के लिए एक Replicability विश्लेषण ढांचे का प्रस्ताव करते हैं। हम एनएलपी साहित्य में वर्तमान, सांख्यिकीय रूप से अनुचित, अभ्यास पर इस ढांचे के सैद्धांतिक लाभों पर चर्चा करते हैं, और चार अनुप्रयोगों में इसके अनुभवजन्य मूल्य का प्रदर्शन करते हैं: बहु-डोमेन निर्भरता पार्सिंग, बहुभाषी पीओएस टैगिंग, क्रॉस-डोमेन भावना वर्गीकरण और शब्द समानता भविष्यवाणी।', 'ga': 'Leis an méadú de shíor ag teacht ar an méid sonraí téacsúla ó éagsúlacht mhór teangacha, fearainn agus seánraí, tá sé caighdeánach anois halgartaim NLP a mheas ar il-thacair sonraí chun feidhmíocht chomhsheasmhach a chinntiú ar fud socruithe ilchineálacha. Mar sin féin, cruthaíonn comparáidí iolracha den sórt sin dúshláin shuntasacha do mhodhanna traidisiúnta anailíse staitistiúla in NLP agus d’fhéadfadh conclúidí earráideacha a bheith mar thoradh orthu. Sa pháipéar seo molaimid creat Anailíse Inchaiteachta le haghaidh anailíse fónta go staitistiúil ar chomparáidí iolracha idir algartaim le haghaidh tascanna NLP. Déanaimid plé ar bhuntáistí teoiriciúla an chreata seo thar an gcleachtas reatha, nach bhfuil call leis go staitistiúil, sa litríocht NLP, agus léirímid a luach eimpíreach thar cheithre fheidhm: parsáil spleáchais ilfhearainn, clibeáil POS ilteangach, aicmiú meoin tras-fearainn agus tuar cosúlachta focal.', 'ka': 'ტექსტუალური მონაცემების ზომა, დიომენები და გენერების განსაზღვრებით, განსაზღვრებით NLP ალგორიტების განსაზღვრება მრავალური მონაცემების განსაზღვრებისთვის განსაზღვრებისთვის განსაზღვრებისთვის განსაზღვ მაგრამ ასეთი მრავალური შემდგომარები განსაზღვრებულია განსაზღვრებულია ტრადიციონალური ანალიზიციის მეტოვებისთვის და შეიძლება შეცდომა გადაწყვება. ამ დოკუნეში ჩვენ განვითარებთ განახლებელობის ანალიზიციის კონფიგურაცია NLP დავალებებისთვის ალგორიტიმების განმავლობაზე. ჩვენ ამ ფრამეტრის ტეორეტიკური გამოსახულებების შესახებ, სტატისტიკურად არაფექმებულია, პრაქტიკურად NLP ლიტერატურაში, და გამოჩვენებთ მისი ემპერიკური მნიშვნელობა ოთხი პროგრამეტში: მრავალეთომენური დასახულებელობა პარას', 'it': "Con la quantità sempre crescente di dati testuali provenienti da una grande varietà di lingue, domini e generi, è diventato standard valutare algoritmi NLP su più set di dati al fine di garantire prestazioni coerenti tra configurazioni eterogenee. Tuttavia, tali confronti multipli pongono sfide significative ai metodi di analisi statistica tradizionali nel PNL e possono portare a conclusioni erronee. In questo articolo proponiamo un framework di analisi di replicabilità per un'analisi statisticamente solida di confronti multipli tra algoritmi per attività NLP. Discutiamo i vantaggi teorici di questo framework rispetto alla pratica attuale, statisticamente ingiustificata, nella letteratura NLP, e dimostriamo il suo valore empirico in quattro applicazioni: analisi delle dipendenze multi-dominio, tag POS multilingue, classificazione dei sentiment cross-domain e previsione della somiglianza delle parole.", 'el': 'Με την συνεχώς αυξανόμενη ποσότητα κειμένων από μια μεγάλη ποικιλία γλωσσών, τομέων και ειδών, έχει γίνει πρότυπο η αξιολόγηση αλγορίθμων σε πολλαπλά σύνολα δεδομένων προκειμένου να εξασφαλιστεί μια συνεπής απόδοση σε ετερογενείς ρυθμίσεις. Ωστόσο, τέτοιες πολλαπλές συγκρίσεις θέτουν σημαντικές προκλήσεις για τις παραδοσιακές μεθόδους στατιστικής ανάλυσης στο NLP και μπορούν να οδηγήσουν σε εσφαλμένα συμπεράσματα. Στην παρούσα εργασία προτείνουμε ένα πλαίσιο ανάλυσης αντιγραφιμότητας για μια στατιστικά έγκυρη ανάλυση πολλαπλών συγκρίσεων μεταξύ αλγορίθμων για εργασίες NLP. Συζητούμε τα θεωρητικά πλεονεκτήματα αυτού του πλαισίου έναντι της τρέχουσας, στατιστικά αδικαιολόγητης πρακτικής στη βιβλιογραφία και καταδεικνύουμε την εμπειρική αξία του σε τέσσερις εφαρμογές: ανάλυση εξάρτησης πολλαπλών τομέων, πολύγλωσση σήμανση, ταξινόμηση συναισθημάτων μεταξύ τομέων και πρόβλεψη ομοιότητας λέξεων.', 'kk': 'Тілдер, домендер және жанрлардың көптеген мәтіндік деректерінің саны көптеген кезде, бірнеше деректер қорларындағы NLP алгоритмдерін бағалау үшін, гетероген баптауларында тұрақты істеу үшін стандартты болды. Бірақ бұл көптеген салыстырулар NLP-де традиционалдық статистикалық анализ әдістеріне маңызды мәселелерді өзгертеді және қате шешімдерге болады. Бұл қағазда NLP тапсырмаларының алгоритмдері арасындағы статистикалық дыбыс анализиясы үшін қайталану мүмкіндігін анализиялау бағдарламасын ұсындық. Біз оның теоретикалық артықшылықтарын қазіргі, статистикалық дұрыс емес, NLP литературасындағы практика және оның эмпирикалық мәнін төрт қолданбаларында көрсетедік: көптеген домендің тәуелдік талдау, көптеген POS тегтері, көптеген домендің', 'hu': 'A számos nyelvből, tartományból és műfajból származó egyre növekvő mennyiségű szöveges adat miatt szabványossá vált az NLP algoritmusok értékelése több adatkészleten annak érdekében, hogy biztosítsák a heterogén beállítások következetes teljesítményét. Az ilyen többszörös összehasonlítás azonban jelentős kihívást jelent a hagyományos statisztikai elemzési módszerek számára az NLP-ben, és téves következtetésekhez vezethet. Jelen tanulmányban javasoljuk a Replikability Analysis keretrendszert az NLP feladatok algoritmusai közötti többszörös összehasonlítások statisztikailag megalapozott elemzésére. Ennek a keretrendszernek a jelenlegi, statisztikailag indokolatlan gyakorlatával szembeni elméleti előnyeit vitatjuk meg az NLP irodalomban, és empirikus értékét négy alkalmazásban mutatjuk be: több domain függőség elemzés, többnyelvű POS címkézés, cross-domain sentiment osztályozás és szóhasonlóság előrejelzés.', 'lt': 'Kadangi vis daugiau tekstinių duomenų gaunama iš įvairių kalbų, domenų ir genrų, tapo įprasta vertinti įvairių duomenų rinkinių NLP algoritmus, kad būtų užtikrintas nuoseklus įvairių sistemų veiksmingumas. However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions.  In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks.  Mes aptariame šios sistemos teorinius pranašumus, palyginti su dabartine, statistiškai nepagrįsta NLP literatūros praktika, ir parodome jos empirinę vertę keturiose taikomosiose srityse: daugiakalbis priklausomybės analizavimas, daugiakalbis POS ženklinimas, tarpšakinės jautrumo klasifikacija ir žodžių panašumo prognozė.', 'ms': 'Dengan jumlah data teks yang semakin berkembang dari berbagai bahasa, domain, dan genre yang besar, ia telah menjadi piawai untuk menilai algoritma NLP pada set data berbilang untuk memastikan prestasi konsisten melalui tetapan heterogene. Namun, perbandingan berbilang ini menghasilkan cabaran yang signifikan kepada kaedah analisis statistik tradisional dalam NLP dan boleh membawa kepada kesimpulan yang salah. In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks.  Kami membincangkan keuntungan teori kerangka ini atas latihan semasa, secara statistik tidak sah, dalam literatur NLP, dan menunjukkan nilai empiriknya melalui empat aplikasi: penghuraian dependensi berbilang-domain, tag POS berbilang-bahasa, klasifikasi sentimen melintas-domain dan ramalan persamaan perkataan.', 'ml': 'ഒരു വലിയ ഭാഷകള്\u200d, ഡൊമെന്\u200dസ്, ജെന്\u200dററുകളില്\u200d നിന്നും എപ്പോഴെങ്കിലും വര്\u200dദ്ധിപ്പിച്ച ടെക്സ്കൂള്\u200d ഡേറ്റായിട്ടുള്ള വിവരങ്ങള്\u200d വളര്\u200dന്നിരിക്കുന്നുവെങ്കില്\u200d, പല ഡ എന്നാലും ഇത്തരം താല്\u200dക്കാലികങ്ങള്\u200d NLP യിലെ പാഠമായ പരിശോധനയ്ക്കുള്ള പ്രധാനപ്പെട്ട വിലാസങ്ങള്\u200dക്ക് പ്രധാനപ്പെട്ട വ ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു റിപ്ലിക്ലിക്സൈവിബ്ലിസ്റ്റലിസ് ഫ്രെയിമെക്ക് പ്രൊദ്ദേശിക്കുന്നു. എംഎല്\u200dപി ജോലികള്\u200dക്കിടയി We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.', 'mt': 'With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups.  Madankollu, paraguni multipli bħal dawn joħolqu sfidi sinifikanti għall-metodi tradizzjonali ta’ analiżi statistika fil-NLP u jistgħu jwasslu għal konklużjonijiet żbaljati. In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks.  We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.', 'mn': 'Түүнчлэн олон хэл, сүлжээ, жанрын хэлбэрээс хамгийн их хэмжээний мөн өгөгдлийн хэмжээний хэмжээний хэмжээний хэмжээний хэмжээний хувьд хэдэн өгөгдлийн санд NLP алгоритмыг олон өгөгдлийн сангийн алгоритмыг үнэлэх стандарт бол Гэвч ийм олон харьцуулалт нь NLP-ийн уламжлалтын статистикийн шинжилгээний арга замыг маш чухал сорилт үүсгэдэг. Тэгээд буруу шинжилгээ гаргаж чадна. Энэ цаасан дээр бид NLP ажлын алгоритмын хоорондын олон тооны харьцуулалтын статистикийн үндсэн дуу шинжилгээний харьцуулах боломжтой шинжилгээ дэвшүүлдэг. Бид энэ хэлбэрийн теоретик давуу талаар орчин үеийн, статистик буруу шударга, NLP уран зохиолын дасгал хөдөлгөөн дээр ярилцаж, дөрвөн хэрэглээнд эмператикийн үнэ цэнийг харуулж байна: олон хэлбэрийн хамааралтай хуваалцах, олон хэлний POS маркинг, олон хэлний мэдрэмжүү', 'mk': 'With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups.  Сепак, ваквите повеќекратни споредби претставуваат значителни предизвици за традиционалните методи на статистичка анализа во НЛП и можат да доведат до грешни заклучоци. Во овој документ предложуваме рамка за анализа на репликабилноста за статистички здрава анализа на повеќето споредби помеѓу алгоритмите за задачите на НЛП. Разговараме за теоретските предности на оваа рамка во однос на сегашната, статистички неоправдана практика во литературата на НЛП, и ја демонстрираме својата емпирична вредност во четири апликации: анализирање на мултидомени зависност, мултијално означување на ПоС, класификација на сентиментите на прекудомени', 'ro': 'Odată cu cantitatea tot mai mare de date textuale dintr-o mare varietate de limbi, domenii și genuri, a devenit standard evaluarea algoritmilor NLP pe mai multe seturi de date pentru a asigura o performanță consistentă în setările eterogene. Cu toate acestea, astfel de comparații multiple reprezintă provocări semnificative pentru metodele tradiționale de analiză statistică din PNL și pot conduce la concluzii eronate. În această lucrare propunem un cadru de analiză a replicabilității pentru o analiză statistic solidă a comparațiilor multiple între algoritmi pentru sarcinile PNL. Discutăm avantajele teoretice ale acestui cadru față de practica actuală, nejustificată din punct de vedere statistic, în literatura PNL și demonstrăm valoarea sa empirică în patru aplicații: analizarea dependenței multidomenii, etichetarea POS multilingvă, clasificarea sentimentelor cross-domenii și predicția similarității cuvintelor.', 'no': 'Med den aldri voksne mengda tekstdata frå ein stor forskjellig språk, domene og genre, har det blitt standard å evaluera NLP-algoritme på fleire datasett for å sikra at ein konsistent utvikling er gjennom heterogenene innstillingar. Desse fleire sammenlikningane gjer imidlertid signifikante utfordringar til tradisjonelle statistiske analysmetoder i NLP og kan føre til feil konklusjonar. I denne papiret foreslår vi eit rammeverk for analysering av replikabilitet for ein statistisk lyd-analyse av fleire sammenligningar mellom algoritmer for NLP-oppgåver. Vi diskuterer teoretiske fordelene av dette rammeverket over gjeldande, statistisk ugyldige, praktisk i NLP- literaturen, og demonstrerer sin empirisk verdi over fire program: multidomeneavhengighetstolking, multilingual POS- tagging, cross-domain sentiment- klassifikasjon og forventing av ordsimilaritet.', 'pl': 'Wraz z coraz większą ilością danych tekstowych z różnych języków, domen i gatunków, standardem stała się ocena algorytmów NLP na wielu zbiorach danych w celu zapewnienia spójnej wydajności w różnych konfiguracjach. Takie wielokrotne porównania stanowią jednak istotne wyzwania dla tradycyjnych metod analizy statystycznej w NLP i mogą prowadzić do błędnych wniosków. W niniejszym artykule proponujemy ramy analizy replikalności dla statystycznie rzetelnej analizy wielokrotnych porównań między algorytmami dla zadań NLP. Omówiono teoretyczne zalety tego frameworku w stosunku do obecnej, statystycznie nieuzasadnionej, praktyki w literaturze NLP oraz demonstrujemy jego wartość empiryczną w czterech aplikacjach: parsowanie zależności wielu domen, wielojęzyczne tagowanie POS, klasyfikacja sentymentów między domenami i predykcja podobieństwa słów.', 'si': 'විශාල භාෂා, ඩෝමේන්, සහ ජේන්ර් වලින් විශාල දත්ත ප්\u200dරමාණයක් වැඩි විශාල වෙලා තියෙන්නේ NLP ඇල්ගෝරිත්ම් වලට ගොඩක් දත්ත සෙට්ටුවට පර නමුත්, අනිවාර්ය වගේ විශේෂ ප්\u200dරශ්නයක් NLP වල සාමාන්\u200dය ස්ථානික විශ්ලේෂණ විශ්ලේෂණ විශ්ලේෂණ වි මේ පත්තරේ අපි ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණ පරීක්ෂණ ක්\u200dරියාමක් ප්\u200dරතික්\u200dරියාත්මක කරනවා NLP වැඩ කරන්න ඇල්ගෝරි අපි මේ පරීක්ෂක ප්\u200dරයෝජනයේ සාධාරණික ප්\u200dරයෝජනය කළා, ස්ථානයික වැරැද්ධයි, NLP ප්\u200dරයෝජනයේ ප්\u200dරයෝජනය, සහ ප්\u200dරයෝජනය කරනවා ඒ වගේ ප්\u200dරයෝජනය හතරක් විතරයේ අ', 'so': "Inta lagu jiro macluumaad qoraal ah oo ka soo baxay luuqado kala duduwan oo kala duduwan, deegaan, iyo jinsiyad, waxay noqotay mid u adag in lagu qiimeeyo algorithm NLP ah oo ku qoran kooxda macluumaadka kala duduwan si uu u xaqiijiyo sameyn tababar kala duduwan oo dhan. Si kastaba ha ahaatee tusaalooyinkaas oo kala duduwan waxay leeyihiin dhibaatooyin muhiim ah oo ku saabsan qaababka tartanka sanamka ee NLP waxay ku socon karaan dhamaadka qaladka ah. Kanu warqaddan waxaan ka soo jeedaynaa frame analyaal kara si aan u sameyno sawir dhaw oo kala duduwan u dhexeeya algorithms oo u dhexeeya shaqaalaha NLP. Waxaannu ka sheekaynaa faa'iidada theoretical ah ee aan xaq u lahayn, baaritaanka qoraalka NLP, waxaana tusnaa qiimaheeda ku saabsan afka codsiga ah: baarshaha ku xiran ee multi-domen, baaritaanka POS oo luuqadaha kala duduwan, tababarida xisaabta iyo hadalka isku mid ah.", 'sv': 'Med den ständigt växande mängden textdata från en mängd olika språk, domäner och genrer har det blivit standard att utvärdera NLP-algoritmer på flera datauppsättningar för att säkerställa en konsekvent prestanda över heterogena konfigurationer. Sådana jämförelser innebär dock betydande utmaningar för traditionella statistiska analysmetoder i NLP och kan leda till felaktiga slutsatser. I denna uppsats föreslår vi ett ramverk för replikabsanalys för en statistiskt sund analys av flera jämförelser mellan algoritmer för NLP-uppgifter. Vi diskuterar de teoretiska fördelarna med detta ramverk jämfört med den nuvarande, statistiskt omotiverade, praktiken i NLP-litteraturen, och demonstrerar dess empiriska värde över fyra tillämpningar: beroendetolkning av flera domäner, flerspråkig POS-märkning, sentimentklassificering över flera domäner och prediktion av ordlikhet.', 'sr': 'Uz sve rastuće količine tekstualnih podataka iz velikih različitih jezika, domena i genra, postalo je standardno procijeniti algoritme NLP-a na višestrukim setima podataka kako bi se osigurala konsekventna izvodnja preko heterogeneznih setova. Međutim, takve višestruke usporedbe predstavljaju značajne izazove tradicionalnim metodama statističke analize u NLP-u i mogu dovesti do pogrešnih zaključka. U ovom papiru predlažemo okvir analize replikabilnosti statistički zvučne analize višestrukih usporedba između algoritma za NLP zadataka. Razgovaramo o teorijskim prednostima ovog okvira o trenutnom, statistički nepravednom, praksi u literaturi NLP-a i pokazujemo njegovu empiričku vrijednost u četiri aplikacije: razmatranje ovisnosti o multidomenu, multijezičkog označavanja POS-a, klasifikacija sentimenta preko domena i predviđanje sličnosti riječi.', 'ta': 'பெரிய மொழி, களங்கள், மற்றும் மரங்களிலிருந்து மென்போதும் வளர்ந்து கொண்டிருக்கும் மென்மாதிரி தரவுகளின் அளவு அதிகரிக்கப்பட்டிருக்கும் பொழுது அதிகரிக்கும்  எனினும், இத்தகைய பல ஒப்பீடுகள் NLP-ல் மரபார்ந்த புள்ளிவிவரமான ஆய்வு முறைகளுக்கு முக்கியமான சவால்கள் ஆகும் மற்றும் தவறான ம இந்த காகிதத்தில் நாம் NLP பணிகளுக்கு இடையே பல ஒப்பிடுகளுக்கு புள்ளிவிவரமான ஒலி ஆய்வு சட்டத்தை பரிந்துரைக்கிறோம். நாம் தற்போது, புள்ளிவிவரமில்லாத, NLP நிரலில் பயிற்சியை விவாதம் செய்து, நான்கு பயன்பாடுகள் முழுவதும் அதிக மதிப்பை காட்டுகிறோம்: பல- domain சார்பு பாடல், பல மொழி POS குறிப்பு, குறிப்பு க', 'ur': 'ایک بڑی مختلف زبان، ڈومین، اور جنر سے لکھی ہوئی ڈیٹسٹ کی تعداد سے زیادہ اضافہ کرنے کے لئے NLP الگوریتموں کو بہت سی ڈیٹسٹ کے ارزش کے لئے استاندارڈ بنایا گیا ہے۔ However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to errors conclusions. ہم اس کاغذ میں NLP کے کاموں کے لئے الگوریتم کے درمیان بہت سی مقایسات کے آواز تحلیل کے لئے ایک جواب دینے والی تحلیل فرمود پیش کریں گے۔ ہم نے اس فرمود کے نظریہ فائدہ کے مطابق مشورہ کر رہے ہیں، ایستستانیک طور پر ناحق، NLP ادبیات میں تمرین کیا ہے، اور چار کاربریوں میں اس کا مطابق ارزش دکھاتے ہیں: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.', 'uz': "Har doim katta tillar, domen, va genlar kabi matn maʼlumotlar soni ko'paytirishda, bu bir nechta maʼlumot tarkibidagi NLP algoritlarini qiymatga ega bo'ladi. Va ikki nechta maʼlumot tartiblardan bir xil tartiblardan bir xil vaqt bajariladigan bajarlikni ishlatish uchun. Lekin, bu ko'pchilik muammolari NLP'ning traditional statistical analyzer usullarda juda qiziqarli muammolar bo'ladi va xato natijalariga ega bo'ladi. Bu hujjatda, biz NLP vazifalari uchun bir nechta taʼminlovchi algoritlarga aniqlash uchun Replicability Analysis freymini taʼminlaydimiz. Biz joriy, statistik haqiqiqiylik emas, NLP litteratoriga harakat qilamiz va to'rt dasturdagi qiymatni ko'rsatdik: multi-domen ishlatuvchisi, multi-tillar POS yozlashtirish, multi-tillar foydalanuvchi, muloqat foydalanuvchi darajalashtirish va so'zning bir xil taʼminlovchisi.", 'vi': 'Với số lượng dữ liệu cấu trúc ngày càng lớn từ nhiều ngôn ngữ, miền và các loại, nó đã trở thành tiêu chuẩn để đánh giá thuật to án lập gia trên nhiều dữ liệu để đảm bảo một hiệu suất ổn định trong các cài đặt khác nhau. Tuy nhiên, nhiều cuộc so sánh như vậy gây ra nhiều thử thách lớn với các phương pháp phân tích thống kê trong chọc dò tủy sống. Trong tờ giấy này, chúng tôi đề xuất một cơ sở phân tích đột biến về tính toán âm thanh cho việc phân tích đa số các thuật toán cho các nhiệm vụ NLP. Chúng ta thảo luận về những lợi ích lý thuyết của bộ khung này trên nền văn học NLP hiện tại, và chứng minh nó có giá trị theo kinh nghiệm trong bốn ứng dụng: phân tích độ phụ thuộc đa miền, thẻ vị trí vị trí vị thành nhiều trường, phân loại cảm xúc đa miền và dự đoán nét giống từ.', 'hr': 'Uz sve rastuće količine tekstualnih podataka iz velikih različitih jezika, domena i genra, postalo je standardno procijeniti algoritme NLP-a na višestrukim setima podataka kako bi se osigurala konsekventna učinka kroz heterogenene nastave. Međutim, takve višestruke usporedbe predstavljaju značajne izazove tradicionalnim metodama statističke analize u NLP-u i mogu dovesti do pogrešnih zaključka. U ovom papiru predlažemo okvir analize replikabilnosti za statistički zvučnu analizu višestrukih usporedba između algoritma za NLP zadatke. Razgovaramo o teorijskim prednostima ovog okvira o trenutnom, statistički nepravednom, praksi u literaturi NLP-a i pokazujemo njegovu empiričku vrijednost u četiri aplikacije: analiza zavisnosti multidomena, multijezičkog označavanja POS-a, klasifikacija sentimenta preko domena i predviđanja sličnosti riječi.', 'nl': 'Met de steeds groeiende hoeveelheid tekstgegevens uit een grote verscheidenheid aan talen, domeinen en genres, is het standaard geworden om NLP-algoritmen op meerdere datasets te evalueren om consistente prestaties te garanderen in heterogene opstellingen. Dergelijke meervoudige vergelijkingen vormen echter aanzienlijke uitdagingen voor traditionele statistische analysemethoden in NLP en kunnen leiden tot onjuiste conclusies. In dit artikel stellen we een Replicability Analysis framework voor een statistisch verantwoorde analyse van meerdere vergelijkingen tussen algoritmen voor NLP taken voor. We bespreken de theoretische voordelen van dit raamwerk ten opzichte van de huidige, statistisch ongerechtvaardigde, praktijk in de NLP literatuur, en demonstreren de empirische waarde ervan in vier toepassingen: multi-domein dependence parsing, meertalige POS tagging, cross-domein sentiment classificatie en woordgelijkheidsvoorspelling.', 'da': 'Med den stadigt voksende mængde tekstdata fra en lang række sprog, domæner og genrer er det blevet standard at evaluere NLP algoritmer på flere datasæt for at sikre en ensartet ydeevne på tværs af heterogene opsætninger. Sådanne flere sammenligninger udgør imidlertid betydelige udfordringer for traditionelle statistiske analysemetoder i NLP og kan føre til fejlagtige konklusioner. I denne artikel foreslår vi en replikabsanalyseramme til en statistisk sund analyse af flere sammenligninger mellem algoritmer til NLP-opgaver. Vi diskuterer de teoretiske fordele ved denne ramme i forhold til den nuværende, statistisk uberettigede praksis i NLP litteraturen, og demonstrerer dens empiriske værdi på tværs af fire applikationer: multi-domæne afhængighed parsing, flersproget POS tagging, cross-domæne sentiment klassificering og ordlighed forudsigelse.', 'bg': 'С все по-нарастващото количество текстови данни от голямо разнообразие от езици, домейни и жанрове, стана стандарт да се оценяват алгоритмите на НЛП на множество набори от данни, за да се гарантира последователно представяне при хетерогенни настройки. Тези многократни сравнения обаче поставят значителни предизвикателства пред традиционните методи за статистически анализ в НЛП и могат да доведат до погрешни заключения. В настоящата статия предлагаме рамка за анализ на репликативността за статистически стабилен анализ на множество сравнения между алгоритми за задачи от НЛП. Обсъждаме теоретичните предимства на тази рамка пред настоящата, статистически неоправдана практика в литературата на НЛП и демонстрираме емпиричната й стойност в четири приложения: многодомейнен анализ на зависимостта, многоезично маркиране на ПОС, междудомейнна класификация на сентимента и прогнозиране на сходството на думите.', 'id': 'Dengan jumlah data tekstual yang semakin tumbuh dari berbagai bahasa, domain, dan genre besar, telah menjadi standar untuk mengevaluasi algoritma NLP pada berbagai set data untuk memastikan prestasi konsisten melalui setup heterogene. Namun, perbandingan berbilang seperti itu menghasilkan tantangan yang signifikan untuk metode analisis statistik tradisional di NLP dan dapat menyebabkan kesimpulan yang salah. Dalam kertas ini kami mengusulkan cadangan Analisi Replikabilitas untuk analisis statistik yang kuat dari perbandingan berbilang antara algoritma untuk tugas NLP. Kami mendiskusikan keuntungan teori dari kerangka ini atas praktek saat ini, secara statistik tidak dibenarkan, dalam literatur NLP, dan menunjukkan nilai empirik di antara empat aplikasi: penganalisan dependensi multi-domain, penandaan POS multibahasa, klasifikasi sentimen cross-domain dan prediksi persamaan kata.', 'ko': '다양한 언어, 분야, 장르에서 온 텍스트 데이터의 양이 끊임없이 증가함에 따라 여러 데이터 집합에서 NLP 알고리즘을 평가하여 이구 설정의 일치된 성능을 확보하는 것이 표준이 되었다.그러나 이런 다중 비교는 NLP의 전통적인 통계 분석 방법에 중대한 도전을 주었고 잘못된 결론을 초래할 수 있다.본고에서 우리는 복제성 분석 구조를 제시하여 NLP 임무 알고리즘 간의 다중 비교를 통계적으로 합리적으로 분석하는 데 사용한다.우리는 이 구조가 현재 NLP 문헌에서 통계적으로 불합리한 실천에 비해 이론적 우위를 논의했고 네 가지 응용에서 그 경험적 가치를 보여 주었다. 그것이 바로 다역 의존 분석, 다언어 어성 표시, 다역 감정 분류와 단어 유사성 예측이다.', 'fa': 'با توجه به اندازه رشد داده\u200cهای متن از زبان، دامنه\u200cهای بزرگ و ژن\u200cها، این استاندارد برای ارزیابی الگوریتم\u200cهای NLP در مجموعه\u200cهای داده\u200cهای متعدد به عنوان تضمین یک عملکرد هماهنگی در تنظیمات متعدد است. با این حال، چنین مقایسه\u200cهای متعدد با روش\u200cهای تحلیل آمار سنتی در NLP چالش\u200cهای بزرگی را می\u200cگذارند و می\u200cتوانند به نتیجه\u200cهای اشتباهی رهبری کنند. در این کاغذ ما یک چهارچوب تحلیل قابلیت تغییر قابلیت برای تحلیل صدای متعدد از مقایسه های متعدد بین الگوریتم برای کار NLP پیشنهاد می کنیم. ما مطابق منافع نظریه\u200cای از این چهار چهار کاربرد در حال حاضر، به طور آماری غیر منصفانه، تمرین در ادبیات NLP، و ارزش عمومی آن را در چهار کاربرد نشان می\u200cدهیم: بررسی بستگی بستگی زیادی از دومین، بررسی POS متعدد زبان، بررسی احساسات متعدد دامین و پیش\u200cبینی شبیه\u200c', 'de': 'Mit der stetig wachsenden Menge an Textdaten aus einer Vielzahl von Sprachen, Domänen und Genres ist es mittlerweile Standard, NLP-Algorithmen auf mehreren Datensätzen zu evaluieren, um eine konsistente Leistung in heterogenen Setups sicherzustellen. Solche Mehrfachvergleiche stellen jedoch traditionelle statistische Analysemethoden in NLP vor große Herausforderungen und können zu falschen Schlussfolgerungen führen. In diesem Beitrag schlagen wir ein Replizierbarkeitsanalyseframework für eine statistisch fundierte Analyse multipler Vergleiche zwischen Algorithmen für NLP-Aufgaben vor. Wir diskutieren die theoretischen Vorteile dieses Frameworks gegenüber der aktuellen, statistisch unberechtigten Praxis in der NLP-Literatur und demonstrieren seinen empirischen Wert in vier Anwendungen: Multi-Domain Dependency Parsing, mehrsprachiges POS Tagging, domänenübergreifende Sentiment Klassifizierung und Wortähnlichkeitsvorhersage.', 'sq': 'Me sasinë gjithmonë në rritje të të dhënave tekstuale nga një varietet i madh gjuhësh, domeneve dhe xhenerash, është bërë standart për të vlerësuar algoritmet NLP në grupe të shumta të dhënash me qëllim që të sigurohet një performancë konsistente nëpërmjet strukturave heterogjene. Megjithatë, krahasimet e tilla të shumta paraqesin sfida të rëndësishme ndaj metodave tradicionale të analizës statistike në NLP dhe mund të çojnë në përfundime të gabuara. Në këtë letër propozojmë një kuadër të Analizës së Përkthimit për një analizë statistikisht të mirë të krahasimeve të shumta midis algoritmave për detyrat NLP. We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.', 'sw': 'With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups.  Hata hivyo, tofauti hizo mbalimbali zina changamoto kubwa kwa njia za uchambuzi wa takwimu za kitamaduni katika NLP na zinaweza kuongoza hitimisho lisilo sahihi. Katika gazeti hili tunapendekeza mfumo wa Uchambuzi wa Umoja wa Uhalisi wa Uchambuzi wa uchambuzi wa sauti kwa takwimu wa ulinganisho mbalimbali kati ya kazi za NLP. Tunajojiana na manufaa ya nadharia ya mfumo huu kuhusu sasa, takwimu isiyo sahihi, mazoezi katika fasihi ya NLP, na kuonyesha thamani yake ya msimamo mkubwa katika matumizi minne: kutegemea matumizi ya ndani mbalimbali, wimbo wa POS kwa lugha mbalimbali, kutafsiri hisia za ndani na utabiri wa neno linalofanana.', 'af': "Met die ooit groei hoeveelheid tekstuele data van 'n groot verskillende tale, domeine en genre, het dit standaard geword om NLP algoritme op veelvuldige datastelle te evalueer om 'n konsistente prestasie te verseker oor heterogeneese opstelling. Alhoewel, sodanige veelvuldige vergelykings betekende uitdagings aan tradisionele statistiese analisie metodes in NLP staan en kan lei na foute conclusions. In hierdie papier voorstel ons 'n Replicability Analysis raamwerk vir' n statistiese klank analiseer van veelvuldige vergelykings tussen algoritme vir NLP taak. Ons bespreek die teorieese voordeel van hierdie raamwerk oor die huidige, statistiese ongeregverdige, praktiese in die NLP literateit, en wys sy empiriese waarde oor vier toepassings: multi-domein afhanklikheid verwerking, multilinguele POS merking, kruis-domein sentiment klasifikasie en woordgelykheid voorskou.", 'am': 'በተለያዩ ቋንቋዎች፣ ዲሞኖችን እና የሥልጣኖች የጽሑፍ ዳታዎች በሚያደጋገ ጊዜ የNLP አልጎርጂምን በብዙ ዳታተሮች ላይ ለማስተካከል የተደላደለ ሆኖአል፡፡ ነገር ግን እንደነዚህ ብዙዎች ምሳሌዎች በNLP ውስጥ የባሕላዊ ተሳታፊ ትምህርት እና የስህተት ውይይቶች ሊመራ ይችላል፡፡ በዚህ ፕሮግራም ውስጥ የNLP ስራቶች መካከል በብዙ ተሳያየት በሚያሳየው የድምፅ ድምፅ የሚያስተምር የReplicable Analysis ፍሬማር እናሳውቃለን፡፡ የአሁኑ፣ በቁጥር ሳይፈቀድ፣ በNLP ባለምህርት ትምህርት እናሳየዋለን፡፡ የአራቱ ፕሮግራሞች ላይ የዚህን ፍሬማድ የtheoretical ጥቅም እናሳያልን፡፡', 'hy': 'Տարբեր լեզուներից, տիեզերքներից և ժենրերից բազմաթիվ տեքստային տվյալների անընդհատ աճող քանակությամբ ստանդարտ դարձավ գնահատել բազմաթիվ տվյալների համակարգերի համար ՆԼՊ ալգորիթմները, որպեսզի ապահովեն համապատասխան արտադրողականություն Այնուամենայնիվ, այս բազմաթիվ համեմատությունները նշանակալի մարտահրավեր են առաջացնում սովորական վիճակագրական վերլուծության մեթոդներին ՆԼՊ-ում և կարող են հանգեցնել սխալ եզրակացություններին: Այս թղթի մեջ մենք առաջարկում ենք վերարտադրողականության վերլուծության շրջանակ, որպեսզի վիճակագրական հնչյուր վերլուծություն կատարի բազմաթիվ համեմատությունների միջև ՆԼՊ-ի խնդիրների համար: We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.', 'az': "Bütün dillərdən, domenalardan və genlərdən textual məlumatların böyüklüyü ilə, çoxlu verilən qurğularda NLP algoritmini müəyyən etmək üçün heterogenel qurğular arasında müəyyən bir performans təmin etmək üçün standartdır. Ancaq bu çoxlu dəyişikliklər NLP'də nəticəli statistik analizi metodlarına möhkəm çətinliklər yaradır və yanlış sonuçlarına yol açar. Bu kağızda NLP işləri üçün algoritmi arasında çoxlu dəyişiklik analizi üçün Replicability Analysis framework təklif edirik. Biz bu çerçivesinin teoriki faydalarını ağımdaki, statistik haqsız olaraq, NLP qismətində təcrübə edirik və dörd uyğulamalar arasında onun empirik qiymətini göstəririk: çox-domani bağımlılıq analizi, çoxlu dil POS etiketi, çoxlu domani hissləri klasifikasyonu və sözlərin bənzər təcrübəsini göstəririk.", 'tr': "Bir näçe köp dilden, sahypalardan we jenerallardan tekstül maglumatynyň azalşy köp sany, heterogenen düzümlerden bir hereket etmäge garamak üçin NLP algoritmalaryny çarpmak standartdyr. Ýöne, bu näçe karşılaşdyrylşyklar NLP'da däpli statistik analýşiň yöntemlerine örän kynçylyklar döreýär we ýalňyş çözgütleri ýok edip biler. Bu kagyzda NLP işleri üçin birnäçe goloritmalar arasyndaky çykyşlyklaryň statistiki ses analizi üçin ýeterlik çykyşlygyny teklip edýäris. NLP edebiýatynda bu framynyň teoriýaly bahatlaryny häzirki, statistik ýagdaýynda adalatmaýan, praktika we munyň empiriýalygyny dört uygulamalaryň arasynda görkezip berýäris: köp-domenyň bağlyklyk parslamasyny, köp dilli POS taglamasyny, çarp-domenyň duýgularyny we sözleriň meňzeşliklerini öňünden çyk", 'bn': 'বিশাল বিভিন্ন ভাষা, ডোমেইন এবং জিনিস থেকে টেক্সচুয়াল ডাটা বৃদ্ধির পরিমাণ বৃদ্ধির পরিমাণে এনএলপি অ্যালগরিদম বিভিন্ন ধরনের ডাটাসেটের মূল্যায়ন করার জন্য এট তবে এনএলপির ঐতিহ্যবাহী পরিসংখ্যান বিশ্লেষণ পদ্ধতিতে এ ধরনের বেশ কয়েকটি তুলনায় তুলে ধরা হয়েছে এবং তারা ভুল সমাপ্তিতে পরিণতি প এই কাগজটিতে আমরা এনএলপির কাজের জন্য বেশ কয়েকটি তুলনার বিশ্লেষণের প্রস্তাব করছি। আমরা বর্তমান, পরিসংখ্যানে অবিচার, এনএলপি সাহিত্যে প্রশিক্ষণ, এবং চার অ্যাপ্লিকেশনের বিভিন্ন প্রাকৃতিক মূল্য প্রদর্শন করি: বহুডোমেইনের নির্ভর পার্সিং, বহুভাষায় পোস ট্যাগিং, বিভিন্', 'ca': "Amb la quantitat cada cop més creixent de dades textuals d'una gran varietat de llengües, dominys i gèneres, s'ha convertit en un estàndard per avaluar algoritmes NLP en múltiples conjunts de dades per assegurar un rendiment coherent entre configuracions heterogènes. However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions.  En aquest paper proposem un marc d'anàlisi de replicabilitat per a una anàlisi estadísticament bona de múltiples comparacions entre algoritmes per a tasques NLP. We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.", 'cs': 'S neustále rostoucím množstvím textových dat z široké škály jazyků, domén a žánrů se stalo standardem vyhodnocovat algoritmy NLP na více datových sadách s cílem zajistit konzistentní výkon napříč heterogenními nastaveními. Taková mnohočetná srovnání však představují pro tradiční metody statistické analýzy v NLP významné problémy a mohou vést k chybným závěrům. V tomto článku navrhujeme rámec analýzy replikovatelnosti pro statisticky solidní analýzu vícenásobných srovnání algoritmů pro NLP úlohy. Diskutujeme teoretické výhody tohoto rámce oproti současné, statisticky neodůvodněné, praxi v NLP literatuře a demonstrujeme jeho empirickou hodnotu ve čtyřech aplikacích: multi-domain dependence parsing, multijazyčné POS tagging, cross-domain sentiment klasifikace a predikce slovní podobnosti.', 'et': 'Kuna tekstiandmete hulk erinevatest keeltest, domeenidest ja žanritest kasvab, on NLP algoritmide hindamine muutunud standardseks mitme andmekogumi puhul, et tagada järjepidev jõudlus heterogeensetes seadistustes. Sellised mitmekordsed võrdlused tekitavad siiski märkimisväärseid probleeme uue õppekava traditsioonilistele statistilistele analüüsimeetoditele ja võivad viia valedeni järeldusteni. Käesolevas töös pakume välja korratavuse analüüsi raamistiku statistiliselt usaldusväärseks analüüsiks mitmekordsete võrdluste algoritmide vahel NLP ülesannete jaoks. Arutleme selle raamistiku teoreetilisi eeliseid praeguse statistiliselt põhjendamatu praktika suhtes NLP kirjanduses ning demonstreerime selle empiirilist väärtust neljas rakenduses: mitmedomeenilise sõltuvuse parsimine, mitmekeelne POS sildistamine, domeenidevaheline sentimentaalne klassifikatsioon ja sõnassarnasuse prognoosimine.', 'fi': 'Koska tekstidataa on yhä enemmän eri kielistä, toimialueista ja genreistä, NLP-algoritmien arviointi useilla tietojoukoilla on tullut standardiksi, jotta varmistetaan yhtenäinen suorituskyky heterogeenisissä kokoonpanoissa. Tällaiset moninkertaiset vertailut aiheuttavat kuitenkin merkittäviä haasteita perinteisille tilastollisille analyysimenetelmille NLP:ssä ja voivat johtaa virheellisiin johtopäätöksiin. Tässä työssä ehdotamme toistettavuusanalyysin viitekehystä tilastollisesti luotettavaan analyysiin algoritmien välisistä monivertailuista NLP-tehtävissä. Keskustelemme viitekehyksen teoreettisista eduista nykyiseen, tilastollisesti perusteettomaan käytäntöön verrattuna NLP-kirjallisuudessa ja osoitamme sen empiiristä arvoa neljässä sovelluksessa: monitoimialueen riippuvuuden parsauksessa, monikielisessä POS-tagauksessa, eri toimialueiden tunteiden luokittelussa ja sanojen samankaltaisuuden ennustamisessa.', 'bs': 'Uz sve rastuće količine tekstualnih podataka iz velikih različitih jezika, domena i genra, postalo je standardno procijeniti algoritme NLP-a na višestrukim setima podataka kako bi se osigurala konsekventna učinka kroz heterogenene nastave. Međutim, takve višestruke usporedbe predstavljaju značajne izazove tradicionalnim metodama statističke analize u NLP-u i mogu dovesti do pogrešnih zaključka. U ovom papiru predlažemo okvir analize replikabilnosti statistički zvučne analize višestrukih usporedba između algoritma za NLP zadatke. Razgovaramo o teorijskim prednostima ovog okvira o trenutnom, statistički nepravednom, praksi u literaturi NLP-a i pokazujemo njegovu empiričku vrijednost u četiri aplikacije: razmatranje ovisnosti o multidomenu, multijezičkog označavanja POS-a, klasifikacija sentimenta preko domena i predviđanje sličnosti riječi.', 'jv': 'Text editor politenessoffpolite"), and when there is a change ("assertive Nang pemilit iki, kita supoyo sistem Replika-kalibar kanggo kebebasan dadi kapan dadi kapan kanggo nggawe barang sampeyan karo Algorithm kanggo ngilangno NLP tasks We debuted the theoretial advances of this frame about the current, istatically unjustified, prakse in the NLP architecture, and displayed her empircal value against 4 Application: multi-domain diphensitive PASSing, multilanguage po tagging, interdomain Sensitive CLASS and word Simlarity preview.', 'sk': 'Z vedno večjo količino besedilnih podatkov iz različnih jezikov, domen in žanrov je postalo standardno ocenjevanje algoritmov NLP na več naborih podatkov, da bi zagotovili dosledno delovanje v heterogenih nastavitvah. Vendar pa takšne večkratne primerjave predstavljajo pomembne izzive za tradicionalne metode statistične analize v novem programu in lahko vodijo do napačnih zaključkov. V prispevku predlagamo okvir za analizo ponovljivosti za statistično zanesljivo analizo večkratnih primerjav algoritmov za naloge NLP. Razpravljamo o teoretičnih prednostih tega okvira v primerjavi s trenutno statistično neupravičeno prakso v literaturi NLP in dokazujemo njegovo empirično vrednost v štirih aplikacijah: razčlenjevanje odvisnosti več domen, večjezično označevanje POS, meddomensko klasifikacijo sentimenta in napovedovanje podobnosti besed.', 'he': 'עם כמות הנתונים הטקסטאליים המגדלת ממגוון גדול של שפות, שדות וגנרס, זה הפך לסטנדרטי להעריך אלגוריתמים NLP על קבוצות נתונים רבות עם זאת, שיווחים רבים כאלה יוצרים אתגרים משמעותיים לשיטות ניתוח סטטיסטי מסורתיות ב-NLP ויכולים להוביל למסקנות שגויות. בעיתון הזה אנו מציעים מסגרת ניתוח שיכפילות לניתוח סטטיסטי צלול של שיוואות רבות בין אלגוריתמים למשימות NLP. אנו מדברים על היתרונות התיאוריות של המסגרת הזו על השימוש הנוכחי, מבחינה סטטיסטית לא צדק, בספרות NLP, ולהראות את ערכו האמפרי בארבע היישומים: מחקר תלויות במספר תרומות, תוויות POS רבות שפויות, קליזציה של רגשות במספר תרומות וחזוי דמיון מילים.', 'ha': "Ko da ana ƙara da yawan data na rubutu daga wasu harshe, guda da sauran, ko, ya kasance na da ƙayyadadde wa NLP kan kowace tsari masu yawa, dõmin ya yi tsari ga aikin mai daidai a tsakanin tsari masu motsi. A lokacin da, misãlai masu yawa daga wannan yana da kimada mai girma zuwa hanyoyin fasarin taratibu a cikin NLP kuma yana iya shiryar da fassaran makosa. Daga wannan takardan, muna goyyade wani firam na Analyza na Replicable for a statistically analyza na masu tsakanin algoritm masu amfani da aikin NLP. Tuna jayayya da amfani na wannan firam a kan yanzu, statistically ba da hakki ba, da mazaɓa a cikin littafan NLP, kuma Muke nuna kimar muhimmanci a kowace shiryoyin ayuka huɗu: manyan-Domen da ɗabi'a, tagogi masu mulki-Domen, fassarar fanel na fara-wuri da kalma mai daidaita.", 'bo': 'སྐད་ཡིག་དང་ཆེ་བའི་ནང་ནས་ཡིག་གེ་འཕྱུར་འགྲོས་ཀྱི་ཚད་ཆེ་བའི་སྐད་ཡིག་ཆ་དང་ཅིག ཡིན་ནའང་། འདི་ལྟ་བུའི་བཟོ་བཅོས་མང་པོ་ཞིག་ནི་རྒྱུན་སྤྲོད་ཀྱི་ཚད་རྩིས་མཐུན་གྱི་ཐབས་ལམ་ལུགས་གནད་དོན་གསལ་པོ་ཡོད། འོག We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.'}
{'en': 'Joint Prediction of Word Alignment with Alignment Types', 'ar': 'توقع مشترك لمحاذاة الكلمات مع أنواع المحاذاة', 'fr': "Prédiction conjointe de l'alignement des mots avec les types d'alignement", 'es': 'Predicción conjunta de la alineación de palabras con los tipos de alineación', 'pt': 'Previsão conjunta de alinhamento de palavras com tipos de alinhamento', 'ja': 'アライメントタイプとの単語アライメントの共同予測', 'zh': '单词齐与齐合占', 'hi': 'संरेखण प्रकारों के साथ शब्द संरेखण की संयुक्त भविष्यवाणी', 'ru': 'Совместное прогнозирование выравнивания слов с типами выравнивания', 'ga': 'Comhthuar ar Ailíniú Focal le Cineálacha Ailínithe', 'ka': 'სიტყვების დაწყვეტილების შესახებ', 'it': "Predizione congiunta dell'allineamento delle parole con i tipi di allineamento", 'kk': 'Сөздің туралау түрлерімен біріктіру', 'el': 'Κοινή πρόβλεψη ευθυγράμμισης λέξεων με τύπους ευθυγράμμισης', 'lt': 'Joint Prediction of Word Alignment with Alignment Types', 'hu': 'A szóigazítás közös előrejelzése az igazítási típusokkal', 'mt': 'Tbassir Konġunt ta’ Allinjament tal-Kliem mat-Tipi ta’ Allinjament', 'mk': 'Заедничка прогноза за израмнување на зборовите со типовите на израмнување', 'mn': 'Хэрэгцүүлэх хэлбэртэй үгийн тусламжтай нэгтгэх', 'pl': 'Wspólne przewidywanie wyrównania słów z typami wyrównania', 'ms': 'Penjadian Perkongsian Jajaran Perkataan dengan Jenis Jajaran', 'ml': 'വാക്ക് ചേര്\u200dക്കുന്നതിന്റെ മുന്നിലുള്ള മാന്യം', 'ro': 'Predicția comună a alinierii cuvintelor cu tipurile de aliniere', 'sr': 'Zajednička predviðanja poravnanja reèi sa tipovima poravnanja', 'si': 'සම්පූර්ණ වර්ගය සමග වචන සංවිධානය', 'no': 'Slå saman forhåndsvising av ordjustering med justeringstypar', 'sv': 'Gemensam förutsägelse av ordjustering med justeringstyper', 'ur': 'Word Alignment', 'so': 'Heshiis Horizontal Alignment', 'ta': 'ஒழுங்கு வகைகளுடன் வார்த்தை ஒழுங்குப்படுத்தும் விருப்பத்தேர்வு', 'uz': 'Boò£yiga tekislash', 'vi': 'Định trước hiệu ứng từ ngữ với dạng liên kết', 'nl': 'Gezamenlijke voorspelling van woorduitlijning met uitlijningstypes', 'bg': 'Съвместно прогнозиране на подравняване на думите с типове подравняване', 'da': 'Fælles forudsigelse af ordjustering med justeringstyper', 'hr': 'Zajednička predviđanja rješenja riječi sa tipovima ispravljanja', 'de': 'Gemeinsame Vorhersage der Wortausrichtung mit Ausrichtungstypen', 'ko': '단어 정렬과 정렬 유형의 결합 예측', 'sw': 'Uzungumzo wa Uzungumzo wa neno kwa aina ya Uzungumzo', 'id': 'Prediksi Peraturan Kata bersama dengan Jenis Peraturan', 'tr': '_Metini Dolamak', 'fa': 'پیشنهاد مشترک تنظیم کلمه با نوع تنظیم', 'af': 'Aangesluit Voorskou van Woord Oplyn met Oplyn Tipe', 'sq': 'Parashikimi i përbashkët i përshtatjes së fjalëve me llojet e përshtatjes', 'hy': 'Joint Prediction of Word Alignment with Alignment Types', 'am': 'undo-type', 'az': 'Sözlərin Tərfləməsi Tərfləmə Növləri ilə Qoşul', 'bn': 'প্রতিনিধিত্বের মাধ্যমে শব্দ প্রতিযোগিতার পছন্দ', 'cs': 'Společná predikce zarovnání slov s typy zarovnání', 'et': 'Sõna joonduse ühine prognoos joondustüüpidega', 'fi': 'Yhteinen ennuste sanalinjauksesta linjaustyyppien kanssa', 'ca': "Predicció conjunta d'allinjament de paraules amb tipus d'allinjament", 'bs': 'Zajednička predviđanja poravnanja riječi sa tipovima poravnanja', 'jv': 'Join', 'sk': 'Skupna napoved poravnave besed z vrstami poravnave', 'ha': '@ action', 'he': 'Joint Prediction of Word Alignment with Alignment Types', 'bo': 'གྲལ་སྒྲིག་རིགས་དང་བསྡུས་པའི་ཡིག་གི་སྔོན་སྒྲིག་དང་མཐུད་པ'}
{'en': 'Current word alignment models do not distinguish between different types of alignment links. In this paper, we provide a new probabilistic model for word alignment where word alignments are associated with linguistically motivated alignment types. We propose a novel task of joint prediction of word alignment and alignment types and propose novel semi-supervised learning algorithms for this task. We also solve a sub-task of predicting the alignment type given an aligned word pair. In our experimental results, the generative models we introduce to model alignment types significantly outperform the models without alignment types.', 'ar': 'لا تميز نماذج محاذاة الكلمات الحالية بين الأنواع المختلفة من روابط المحاذاة. في هذه الورقة ، نقدم نموذجًا احتماليًا جديدًا لمحاذاة الكلمات حيث ترتبط محاذاة الكلمات بأنواع المحاذاة ذات الدوافع اللغوية. نقترح مهمة جديدة للتنبؤ المشترك لأنواع محاذاة الكلمات والمحاذاة ونقترح خوارزميات تعلم جديدة شبه خاضعة للإشراف لهذه المهمة. نقوم أيضًا بحل مهمة فرعية للتنبؤ بنوع المحاذاة باستخدام زوج من الكلمات المحاذاة. في نتائجنا التجريبية ، تفوقت النماذج التوليدية التي نقدمها لأنواع محاذاة النموذج بشكل كبير على النماذج بدون أنواع المحاذاة.', 'fr': "Les modèles d'alignement de mots actuels ne font pas de distinction entre les différents types de liens d'alignement. Dans cet article, nous proposons un nouveau modèle probabiliste pour l'alignement des mots dans lequel les alignements de mots sont associés à des types d'alignement motivés par la langue. Nous proposons une nouvelle tâche de prédiction conjointe de l'alignement des mots et des types d'alignement et proposons de nouveaux algorithmes d'apprentissage semi-supervisés pour cette tâche. Nous résolvons également une sous-tâche de prédiction du type d'alignement en fonction d'une paire de mots alignés. Dans nos résultats expérimentaux, les modèles génératifs que nous introduisons pour les types d'alignement de modèles surpassent de manière significative les modèles sans types d'alignement.", 'pt': 'Os modelos atuais de alinhamento de palavras não distinguem entre diferentes tipos de links de alinhamento. Neste artigo, fornecemos um novo modelo probabilístico para alinhamento de palavras em que alinhamentos de palavras são associados a tipos de alinhamento motivados linguisticamente. Propomos uma nova tarefa de predição conjunta de alinhamento de palavras e tipos de alinhamento e propomos novos algoritmos de aprendizado semi-supervisionado para esta tarefa. Também resolvemos uma subtarefa de prever o tipo de alinhamento dado um par de palavras alinhadas. Em nossos resultados experimentais, os modelos generativos que introduzimos aos tipos de alinhamento de modelos superam significativamente os modelos sem tipos de alinhamento.', 'es': 'Los modelos actuales de alineación de palabras no distinguen entre los diferentes tipos de enlaces de alineación. En este artículo, proporcionamos un nuevo modelo probabilístico para la alineación de palabras en el que las alineaciones de palabras se asocian con tipos de alineación motivados lingüísticamente. Proponemos una nueva tarea de predicción conjunta de los tipos de alineación y alineación de palabras y proponemos algoritmos de aprendizaje semisupervisado novedosos para esta tarea. También resolvemos una subtarea de predecir el tipo de alineación dado un par de palabras alineadas. En nuestros resultados experimentales, los modelos generativos que introducimos para los tipos de alineación de modelos superan significativamente a los modelos sin tipos de alineación.', 'ja': '現在の単語整列モデルは、異なるタイプの整列リンクを区別しません。この論文では、言語的に動機づけられたアラインメントタイプに関連付けられた単語アラインメントの新しい確率論的モデルを提供する。ワードアライメントとアライメントタイプの共同予測の新規タスクを提案し、このタスクのために新規の半監督学習アルゴリズムを提案します。また、整列された単語ペアを与えられた整列タイプを予測するサブタスクも解決します。実験結果では、モデルアライメントタイプに導入する生成モデルは、アライメントタイプなしのモデルよりも著しく優れています。', 'zh': '今单词对齐不异链接。 于文为单词齐为新概率,其单词齐与言语相关。 合预测词齐、齐,新型半督算法。 吾犹解给定对齐词对齐子之事也。 在我实验中,引入齐形,明优无齐。', 'hi': 'वर्तमान शब्द संरेखण मॉडल विभिन्न प्रकार के संरेखण लिंक के बीच अंतर नहीं करते हैं। इस पेपर में, हम शब्द संरेखण के लिए एक नया संभाव्य मॉडल प्रदान करते हैं जहां शब्द संरेखण भाषाई रूप से प्रेरित संरेखण प्रकारों से जुड़े होते हैं। हम शब्द संरेखण और संरेखण प्रकारों की संयुक्त भविष्यवाणी के एक उपन्यास कार्य का प्रस्ताव करते हैं और इस कार्य के लिए उपन्यास अर्ध-पर्यवेक्षित सीखने के एल्गोरिदम का प्रस्ताव करते हैं। हम एक संरेखित शब्द जोड़ी दिए गए संरेखण प्रकार की भविष्यवाणी करने के एक उप-कार्य को भी हल करते हैं। हमारे प्रयोगात्मक परिणामों में, हम मॉडल संरेखण प्रकारों को पेश करने वाले उत्पादक मॉडल संरेखण प्रकारों के बिना मॉडल को काफी बेहतर बनाते हैं।', 'ru': 'Текущие модели выравнивания слов не различают различные типы связей выравнивания. В этой статье мы предоставляем новую вероятностную модель выравнивания слов, где выравнивание слов связано с лингвистически мотивированными типами выравнивания. Мы предлагаем новую задачу совместного прогнозирования выравнивания слов и типов выравнивания и предлагаем новые алгоритмы полунаблюдаемого обучения для этой задачи. Мы также решаем подзадачу предсказания типа выравнивания при наличии выровненной пары слов. В наших экспериментальных результатах генеративные модели, которые мы вводим в типы выравнивания моделей, значительно превосходят модели без типов выравнивания.', 'ga': 'Ní dhéanann samhlacha ailínithe focal reatha idirdhealú idir cineálacha éagsúla naisc ailínithe. Sa pháipéar seo, cuirimid múnla nua dóchúlachta ar fáil d’ailíniú focal ina bhfuil baint ag ailíniú focal le cineálacha ailínithe atá spreagtha ag teanga. Molaimid tasc nua de chomhthuar ar ailíniú focal agus ar chineálacha ailínithe agus molaimid halgartaim foghlama leath-mhaoirseachta úrnua don tasc seo. Réitímid fothasc freisin maidir leis an gcineál ailínithe a thuar nuair a thugtar péire focal ailínithe. Inár dtorthaí turgnamhacha, is fearr go mór na samhlacha giniúna a thugaimid isteach do chineálacha ailínithe samhlacha ná na samhlacha gan cineálacha ailínithe.', 'ka': 'მიმდინარე სიტყვების განზომილების მოდელები არ განსხვავებს განსხვავებული ტიპების განზომილება. ამ დოკუნეში ჩვენ ახალი პრობილისტიკური მოდელს სიტყვების დაწყვეტილებისთვის, სადაც სიტყვების დაწყვეტილებები ლენგურიტიკურად მოტივირული დაწყვეტილების ტიპ ჩვენ პრომენტის დავაწყვებთ სიტყვების გადაწყვეტილების და გადაწყვეტილების საერთო დაწყვეტილების და პრომენტის ნახევარწმუნებული სწავლების ალგორიტემის პრომენტი. ჩვენ ასევე გავაკეთებთ სამუშაო დავაკეთება, რომელიც დავაკეთებული სიტყვის სამუშაო ტიპის წინასწორება. ჩვენი ექსპერიმენტიური შედეგებში, გენერიციური მოდელები, რომლებიც ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ მოდელური განტოლების ტიპებისთვის მნიშ', 'hu': 'A jelenlegi szóigazítási modellek nem tesznek különbséget a különböző típusú igazítási hivatkozások között. Ebben a tanulmányban egy új valószínűségi modellt nyújtunk be a szóigazításhoz, ahol a szóigazítások nyelvi motivációjú igazítási típusokhoz kapcsolódnak. Egy új feladatot javasolunk a szóigazítás és igazítás típusainak közös előrejelzésére, és ehhez új, félig felügyelt tanulási algoritmusokat javasolunk. Azt is megoldjuk, hogy az igazítás típusának előrejelzése egy igazított szópárban. Kísérleti eredményeinkben az általunk bemutatott generációs modellek jelentősen meghaladják az igazítástípusok nélküli modelleket.', 'el': 'Τα τρέχοντα μοντέλα ευθυγράμμισης λέξεων δεν διακρίνουν μεταξύ διαφορετικών τύπων συνδέσεων ευθυγράμμισης. Σε αυτή την εργασία, παρέχουμε ένα νέο πιθανό μοντέλο ευθυγράμμισης λέξεων όπου οι ευθυγραμμίσεις λέξεων συνδέονται με γλωσσικά κίνητρα τύπους ευθυγράμμισης. Προτείνουμε ένα νέο έργο κοινής πρόβλεψης τύπων ευθυγράμμισης λέξεων και ευθυγράμμισης και προτείνουμε νέους αλγόριθμους ημι-εποπτευόμενης μάθησης για αυτό το έργο. Επίσης λύνουμε ένα δευτερεύον έργο της πρόβλεψης του τύπου ευθυγράμμισης που δίνεται σε ένα ευθυγραμμισμένο ζεύγος λέξεων. Στα πειραματικά μας αποτελέσματα, τα παραγωγικά μοντέλα που εισάγουμε στους τύπους ευθυγράμμισης μοντέλων ξεπερνούν σημαντικά τα μοντέλα χωρίς τύπους ευθυγράμμισης.', 'it': "I modelli attuali di allineamento delle parole non distinguono tra diversi tipi di collegamenti di allineamento. In questo articolo, forniamo un nuovo modello probabilistico per l'allineamento delle parole in cui gli allineamenti delle parole sono associati a tipi di allineamento motivati linguisticamente. Proponiamo un nuovo compito di previsione congiunta dei tipi di allineamento e allineamento delle parole e proponiamo nuovi algoritmi di apprendimento semi-supervisionati per questo compito. Risolviamo anche un sotto-compito di prevedere il tipo di allineamento dato una coppia di parole allineate. Nei nostri risultati sperimentali, i modelli generativi che introduciamo ai tipi di allineamento dei modelli superano significativamente i modelli senza tipi di allineamento.", 'lt': 'Dabartiniai žodžių derinimo modeliai atskiria skirtingų rūšių derinimo ryšius. Šiame dokumente mes pateikiame naują probabilistinį žodžių suderinimo model į, kuriame žodžių suderinimai yra susiję su kalbomis motyvuotais derinimo tipais. Siūlome naują užduotį bendrai prognozuoti žodžių suderinimo ir suderinimo tipus ir siūlome naujus pusiau prižiūrimus mokymosi algoritmus šiam uždaviniui. Mes taip pat išspręsime subužduotį prognozuoti suderinimo tipą, suteiktą suderintos žodžių poros. Mūsų eksperimentinių rezultatų duomenimis, generaciniai modeliai, kuriuos įvedame modelių suderinimo tipams, gerokai viršija modelius be suderinimo tipų.', 'kk': 'Қолданыстағы сөздерді түрлендіру үлгілері түрлі тірлендіру сілтемелер арасында айырмайды. Бұл қағазда сөздерді түзету үшін жаңа ықтималдық үлгісін келтіреміз. Бұл сөздерді тілдік түрлеріне монтификациялық түрлермен байланысты. Біз сөздерді түрлендіру және түрлендіру түрлерінің жалпы бақылау тапсырмасын жұмыс істеп, бұл тапсырма үшін романдың жарты бақылау алгоритмдерін ұсынамыз. Біз сондай-ақ бөлек тапсырманы таңдаймыз. Бірақ бөлек сөздердің түрін таңдаймыз. Өзіміздің тәжірибелі нәтижелерімізде, біз үлгі теңдеу түрлеріне келтірген үлгілеріміз үлгілерін теңдеу түрлері болмаса, үлгілерді теңдеу түрлері', 'mk': 'Сегашните модели на уредување на зборови не разликуваат меѓу различни типови на уредување на врски. Во оваа хартија, обезбедуваме нов веројатен модел за уредување на зборовите каде што уредувањата на зборовите се поврзани со јазички мотивирани типови на уредување. Ние предложуваме нова задача за заедничко предвидување на типовите на зборови за израмнување и израмнување и предложуваме нови полунадгледувани алгоритми за учење за оваа задача. Ние, исто така, решаваме подзадача за предвидување на типот на уредување даден уреден збор пар. Во нашите експериментални резултати, генеративните модели кои ги воведуваме за моделите на типовите на изедначување значително ги надминуваат моделите без типови на изедначување.', 'ms': 'Model penyesuaian perkataan semasa tidak membezakan antara jenis berbeza pautan penyesuaian. Dalam kertas ini, kami menyediakan model kemungkinan baru untuk penyesuaian perkataan di mana penyesuaian perkataan berkaitan dengan jenis penyesuaian bermotivasi bahasa. Kami cadangkan tugas baru untuk ramalan kongsi jenis penyesuaian perkataan dan penyesuaian dan cadangkan algoritma pembelajaran setengah-mengawasi novel untuk tugas ini. Kami juga menyelesaikan sub-tugas untuk meramalkan jenis penyesuaian diberikan pasangan perkataan disesuaikan. Dalam hasil percubaan kami, model generatif yang kami perkenalkan kepada jenis penyesuaian model secara signifikan melebihi model tanpa jenis penyesuaian.', 'ml': 'ഇപ്പോഴത്തെ വാക്കിന്റെ മാതൃകങ്ങള്\u200d വ്യത്യസ്ത തരത്തിലുള്ള ലിങ്കുകള്\u200dക്കിടയില്\u200d വേര്\u200dതിരിച്ചുവെക ഈ പത്രത്തില്\u200d, വാക്കിന്റെ മാതൃകയ്ക്കുള്ള ഒരു പുതിയ സാധ്യതയുള്ള മോഡല്\u200d നാം നല്\u200dകുന്നു. വാക്കുകള്\u200d ഭാഷയില്\u200d നിന്നും മാറ്റുന്ന ഭ വാക്കിന്റെ സഹജമാക്കുന്നതിന്റെയും മാന്യമാക്കുന്നതിന്റെയും പ്രവചനത്തിന്റെയും നോവല്\u200d ജോലിയുടെയും പ്രൊദ്ദേശിപ്പിക്കുന്ന ഒരു വാക്കിന്റെ ജോലി കൊടുക്കപ്പെട്ടിരിക്കുന്ന സബ് ജോലിയെ പ്രവചിപ്പിക്കുന്നതിനുള്ള ഒരു ഉപ-ജോല നമ്മുടെ പരീക്ഷിക്കുന്ന ഫലങ്ങളില്\u200d, നമ്മുടെ ജനററിവ് മോഡല്\u200d പരിചയപ്പെടുത്തുന്നത് മോഡലിങ്ങ് ടൈപ്പുകള്\u200d ഇല്ലാതെ മോഡലുകള്\u200d പ്', 'mt': "Il-mudelli attwali tal-allinjament tal-kliem ma jiddistingwux bejn tipi differenti ta’ konnessjonijiet tal-allinjament. F’dan id-dokument, nipprovdu mudell probabilistiku ġdid għall-allinjament tal-kliem fejn l-allinjamenti tal-kliem huma assoċjati ma’ tipi ta’ allinjament motivati lingwistikament. Aħna nipproponu kompitu ġdid ta' tbassir konġunt tat-tipi ta' allinjament tal-kelmiet u allinjament u nipproponu algoritmi ġodda ta' tagħlim semisorveljati għal dan il-kompitu. We also solve a sub-task of predicting the alignment type given an aligned word pair.  Fir-riżultati sperimentali tagħna, il-mudelli ġenerattivi li nintroduċu għall-mudelli tat-tipi ta’ allinjament jaqbżu b’mod sinifikanti l-mudelli mingħajr tipi ta’ allinjament.", 'no': 'Gjeldande ordjusteringsmodeller forskjeller ikkje mellom ulike typar justeringslenkjer. I denne papiret gir vi eit nytt sannsynlig modell for ordjustering der ordjusteringa er tilknytta med språkstisk motivert justeringstypar. Vi foreslår eit nytt oppgåve om kopla forhåndsvising av ordjustering og justeringstypar og foreslår novelle semioversikte læringsalgoritme for denne oppgåva. Vi løyser også ein underoppgåve for å forhåndsvisa utformingstypen som er gitt eit utformingsord-par. I våre eksperimentelle resultater introduserer vi generativne modellen til modellejusteringstypar betydelig utfører modellen utan justeringstypar.', 'pl': 'Aktualne modele wyrównania słów nie rozróżniają różnych typów łączy wyrównania. W niniejszym artykule przedstawiamy nowy model prawdopodobieństwa wyrównania słów, w którym wyrównania słów są związane z językowo motywowanymi typami wyrównania. Proponujemy nowe zadanie wspólnego przewidywania typów wyrównania słów i wyrównania oraz proponujemy nowe algorytmy uczenia się pół-nadzorowane do tego zadania. Rozwiązujemy również podzadanie polegające na przewidywaniu typu wyrównania podanego wyrównanej parze słów. W naszych wynikach eksperymentalnych modele generatywne, które wprowadzamy do typów osiowania modeli, znacznie przewyższają modele bez typów osiowania.', 'ro': 'Modelele curente de aliniere a cuvintelor nu fac distincție între diferite tipuri de legături de aliniere. În această lucrare, oferim un nou model probabilistic pentru alinierea cuvintelor în cazul în care alinierea cuvintelor sunt asociate cu tipuri de aliniere motivate lingvistic. Propunem o sarcină nouă de predicție comună a tipurilor de aliniere și aliniere a cuvintelor și propunem algoritmi de învățare semi-supravegheați noi pentru această sarcină. De asemenea, rezolvăm o subsarcină de predicție a tipului de aliniere dat unei perechi de cuvinte aliniate. În rezultatele noastre experimentale, modelele generative pe care le introducem tipurilor de aliniere a modelului depășesc semnificativ modelele fără tipuri de aliniere.', 'mn': 'Одоогийн үгний тэгшитгэлийн загварууд өөр төрлийн тэгшитгэлийн холбоог ялгаагүй. Энэ цаасан дээр бид хэлний урам зохицуулах төрлийн үг зохицуулах шинэ магадлал загвар өгдөг. Бид үгийг нэгтгэх, нэгтгэх төрлийн шинэ таамаглалтын шинэ даалгаврыг санал болгож, энэ даалгаврын тулд шинэ semi-supervised суралцах алгоритмыг санал болгож байна. Бид мөн хэлбэртэй хэлбэрийг тодорхойлж өгсөн хэлбэрийг таамаглах суб-даалгаварыг олох юм. Бидний туршилтын үр дүнд бидний загварын загварын төрлүүд нь загварын төрлүүдийг тэгшитгэлийн төрлүүд байхгүй загваруудыг илүү их ашигладаг.', 'si': 'වෙනස් වර්ගයක් සම්බන්ධ වර්ගයක් වෙනස් වර්ගයක් සම්බන්ධ වර්ගයක් අතර වෙනස් කරන්නේ නැහැ. මේ පත්තරේ අපි අළුත් ප්\u200dරමාණයක් දෙන්නේ වචන ප්\u200dරමාණය සඳහා වචන ප්\u200dරමාණයක් සම්බන්ධ වෙන්නේ වචන ප්\u200dරමාණය සමග වච අපි ප්\u200dරශ්නයක් කරනවා වචන සංවිධානය සහ සංවිධානය වගේ සම්බන්ධ විශ්වාසය සම්බන්ධ විශ්වාසය සම්බන්ධ විදිහට,  අපි සබ් වැඩක් විස්තර කරන්නේ සබ් වැඩක් විස්තර කරන්නේ සබ් වැඩක්. අපේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයෙන්, අපි ප්\u200dරතිචාරිත විද්\u200dයාපයක් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් ප්\u200d', 'sr': 'Trenutni model poravnanja riječi ne razlikuju različite vrste poravnanja. U ovom papiru pružamo novi verovatni model za poravnanje reèi gde su poravnanje reèi povezane sa tipovima jezički motiviranog poravnanja. Predlažemo novi zadatak zajedničkog predviđanja tipa poravnanja i poravnanja reči i predlažemo novi polu nadzorni algoritmi učenja za ovaj zadatak. Takoðe rešimo podzadatak predviðanja tipa poravnanja koji je dao poravnani parov. U našim eksperimentalnim rezultatima, generativni modeli koje predstavljamo modelima poravnanja značajno iznosi modele bez vrsta poravnanja.', 'so': 'Tusaalada isbedelka ee hada ma kala soocdo noocyo kala duwan oo isbedelka ah. Qoraalkan waxaynu ku siinaynaa model cusub oo ku sawirida hadalka, taasoo ay ku xiran yihiin noocyada isbedelka luuqada. Waxaannu horumarinaynaa shaqada saxda ah oo la sii sheegayo noocyada isbedelka iyo isbedelka, waxaana soo jeedaynaa qoraalka waxbarashada oo la ilaaliyo semi-supervised. Sidoo kale waxaynu xajisiinnay shuqul hoos u dhigid si a an u sii sheegno nooca siman ee la siiyey labo si siman. Imtixaanka jirrabka ah, noocyada geneeral ee aan ku soo bandhignaa noocyada isbedelka si muhiim ah u sameeya modellada aan u sameyn noocyada isbedelka.', 'sv': 'Nuvarande ordjusteringsmodeller skiljer inte mellan olika typer av justeringslänkar. I denna uppsats ger vi en ny sannolikhetsmodell för ordjustering där ordjusteringar associeras med språkligt motiverade anpassningstyper. Vi föreslår en ny uppgift med gemensam prediktion av ordjusterings- och justeringstyper och föreslår nya halvövervakade inlärningsalgoritmer för denna uppgift. Vi löser också en underuppgift att förutsäga justeringstypen givet ett justerat ordpar. I våra experimentella resultat överträffar de generativa modeller vi introducerar för modelljusteringstyper betydligt modellerna utan justeringstyper.', 'ta': 'தற்போதைய வார்த்தை ஒழுங்குபடுத்தல் மாதிரி இந்த காகிதத்தில், நாம் வார்த்தை ஒழுங்குபடுத்தும் புதிய சாத்தியமான மாதிரியை வழங்குகிறோம். சொல்லை ஒழுங்குப்படுத்த வார்த்தை ஒழுங்குபடுத்துதல் மற்றும் ஒழுங்குபடுத்தல் வகைகளின் சேர்ந்து ஒரு புதிய பணியை நாம் பரிந்துரைக்கிறோம் மற்றும் இந்த பணி We also solve a sub-task of predicting the alignment type given an aligned word pair.  எங்கள் சோதனையின் முடிவுகளில், பொதுவான மாதிரிகளில், ஒழுங்குபடுத்தல் வகைகள் இல்லாமல் மாதிரிகளை முறைமையாக முடியும்.', 'ur': 'اوسنی کلمات الیٹ منٹ موڈل مختلف طرح الیٹ منٹ لینکوں کے درمیان تفریق نہیں کرتے۔ اس کاغذ میں ہم ایک نئی احتمالات موڈل دیتے ہیں کہ کلمات الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ کے ساتھ ملے جاتے ہیں۔ ہم کلمات کی تعمیر اور تعمیر کی مخلوقات کا ایک نئی تابع کام پیش کریں گے اور اس کام کے لئے نئی نصف نظارت کی تعلیم الگوریتم کو پیش کریں گے۔ ہم نے بھی ایک سوب-کار کو حل کر دیا ہے کہ ایک متصلہ کلمات جوڑے کی پیش بینی کریں۔ ہمارے آزمائش نتیجے میں، ہم نے موڈل الیزانگ ٹائپ کو معلوم کر رکھا ہے، موڈل کو الیزانگ ٹائپ کے بغیر معلوم ہوتے ہیں.', 'uz': "@ info Bu hujjatda, biz soʻzni tasdiqlash uchun yangi probablik modelni yaratishimiz mumkin. Bu yerda soʻzlar tekislash turlari bilan bogʻliq boʻladi. Biz soʻzni birlashtirish va birlashtirish turlarining bir novel vazifani taqdim qilamiz va bu vazifa uchun qayta taʼminlovchi algoritni taqdim qilamiz. Shunday qilib, biz bir tenglashtirilgan soʻzning ikkita so'zni oldin bir sub-vazifani aniqlash. Bizning tajriba natijalarimizda, biz modelni tasdiqlash turlari bilan ishlatiladigan generativ modellarni tasdiqlash modellarini tasdiqlash mumkin.", 'vi': 'Các mô hình định dạng từ hiện thời không phân biệt được giữa các kiểu liên kết thẳng hàng. Trong tờ giấy này, chúng tôi cung cấp một mô hình xác suất mới cho việc chỉnh các từ nơi các khẩu thích được liên kết với các kiểu phối hợp ngôn ngữ. Chúng tôi đề xuất một nhiệm vụ mới với dự đoán đồng thời về các loại sắp xếp các từ và các loại thẳng hàng và đề xuất các thuật toán học bán giám sát mới cho nhiệm vụ này. Chúng tôi cũng giải quyết việc dự đoán kiểu định vị trí theo một cặp từ liên kết. Trong kết quả thử nghiệm, các mô hình tạo hóa chúng tôi giới thiệu về các kiểu cấu trúc mô hình hoàn to àn vượt trội các mẫu mà không có các kiểu dáng.', 'nl': 'Huidige woorduitlijningsmodellen maken geen onderscheid tussen verschillende typen uitlijningskoppelingen. In dit artikel bieden we een nieuw probabilistisch model voor woorduitlijning waarbij woorduitlijningen worden geassocieerd met taalkundig gemotiveerde uitlijningstypes. We stellen een nieuwe taak voor van gezamenlijke voorspelling van woorduitlijning en uitlijningstypes en stellen nieuwe semi-begeleide leeralgoritmen voor deze taak voor. We lossen ook een subtaak op van het voorspellen van het uitlijningstype gegeven een uitgelijnd woordpaar. In onze experimentele resultaten presteren de generatieve modellen die we introduceren bij model uitlijningstypes aanzienlijk beter dan de modellen zonder uitlijningstypes.', 'bg': 'Текущите модели за подравняване на думите не правят разлика между различните видове връзки за подравняване. В тази статия предлагаме нов вероятностен модел за подравняване на думите, при който подравняванията на думите са свързани с лингвистично мотивирани типове подравняване. Предлагаме нова задача за съвместно прогнозиране на типовете подравняване и подравняване на думите и предлагаме нови полу-надзорни учебни алгоритми за тази задача. Също така решаваме подзадача за предсказване на типа подравняване, дадена подравнена двойка думи. В нашите експериментални резултати генеративните модели, които въвеждаме в типовете подравняване на моделите, значително превъзхождат моделите без типове подравняване.', 'hr': 'Trenutni modeli poravnanja riječi ne razlikuju različite vrste poravnanja. U ovom papiru pružamo novi vjerojatni model za poravnanje riječi gdje su poravnanje riječi povezane s tipovima jezički motiviranog poravnanja. Predlažemo novi zadatak zajedničkog predviđanja vrsta poravnanja i poravnanja riječi i predlažemo novi polu nadzorni algoritmi učenja za ovaj zadatak. Također riješimo podzadatak predviđanja tipa poravnanja koji je dao određen par riječi. U našim eksperimentalnim rezultatima, generativni modeli koje predstavljamo modelima vrste poravnanja značajno iznosi modele bez vrsta poravnanja.', 'da': 'Nuværende ordjusteringsmodeller skelner ikke mellem forskellige typer justeringslinks. I denne artikel giver vi en ny sandsynlighedsmodel for ordjustering, hvor ordjusteringer er forbundet med sprogligt motiverede justeringstyper. Vi foreslår en ny opgave med fælles forudsigelse af ordjustering og justeringstyper og foreslår nye semi-overvågede læringsalgoritmer til denne opgave. Vi løser også en underopgave med at forudsige justeringstypen givet et tilpasset ordpar. I vores eksperimentelle resultater overgår de generative modeller, vi introducerer til model justeringstyper betydeligt modellerne uden justeringstyper.', 'id': 'Model penyesuaian kata saat ini tidak membedakan antara tipe berbeda dari sambungan penyesuaian. Dalam kertas ini, kami menyediakan model probabilis baru untuk penyesuaian kata di mana penyesuaian kata diassokasikan dengan tipe penyesuaian yang bermotivasi bahasa. Kami mengusulkan tugas baru dari prediksi kongsi tentang penyesuaian kata dan tipe penyesuaian dan mengusulkan algoritma pembelajaran semi-mengawasi novel untuk tugas ini. Kita juga memecahkan sub-tugas untuk memprediksi tipe penyesuaian yang diberikan sepasang kata yang disesuaikan. In our experimental results, the generative models we introduce to model alignment types significantly outperform the models without alignment types.', 'de': 'Aktuelle Wortausrichtungsmodelle unterscheiden nicht zwischen verschiedenen Arten von Ausrichtungsverbindungen. In diesem Beitrag stellen wir ein neues probabilistisches Modell zur Wortausrichtung zur Verfügung, bei dem Wortausrichtungen mit sprachlich motivierten Ausrichtungstypen assoziiert werden. Wir schlagen eine neuartige Aufgabe der gemeinsamen Vorhersage von Wortausrichtungs- und Ausrichtungstypen vor und schlagen neue semi-überwachte Lernalgorithmen für diese Aufgabe vor. Wir lösen auch eine Unteraufgabe, den Ausrichtungstyp vorauszusagen, der einem ausgerichteten Wortpaar gegeben ist. In unseren experimentellen Ergebnissen übertreffen die generativen Modelle, die wir in Modellausrichtungstypen einführen, deutlich die Modelle ohne Ausrichtungstypen.', 'ko': '현재 단어 정렬 모델은 서로 다른 유형의 정렬 링크를 구분하지 않습니다.본고에서 우리는 새로운 단어 정렬 확률 모델을 제공했는데 그 중에서 단어 정렬은 언어 동기의 정렬 유형과 관련이 있다.우리는 단어 정렬과 정렬 유형을 연합하여 예측하는 새로운 임무를 제시했고 이 임무에 대해 새로운 반감독 학습 알고리즘을 제시했다.우리는 또 정해진 대조어의 대조 유형을 예측하는 하위 임무도 해결했다.우리의 실험 결과에서 우리는 모델 정렬 유형의 생성 모델을 도입했는데 정렬 유형이 없는 모델보다 현저히 우수하다.', 'sw': 'Mfano wa usambazaji wa maneno ya sasa hautofauti kati ya aina tofauti za viungo vya usambazaji. Katika karatasi hii, tunatoa mtindo mpya wa uwezekano wa kujitengeneza maneno ambapo usambazaji wa maneno unahusiana na aina za usambazaji wa lugha. Tunajaribu jukumu la riwaya la utabiri wa pamoja wa aina za kujitengeneza maneno na kujitengeneza na pendekeza vipengele vya kujifunza kwa ajili ya kazi hii. We also solve a sub-task of predicting the alignment type given an aligned word pair.  Katika matokeo yetu ya majaribio, mifano ya uzalendo tunaoonyesha mifano ya usambazaji kwa kiasi kikubwa unafanya mifano bila aina ya usambazaji.', 'fa': 'مدلهای تنظیم کلمه فعلی بین نوع تنظیم ارتباطات متفاوت جدا نمی\u200cشوند. در این کاغذ، ما یک مدل احتمالی جدید برای تنظیم کلمات را پیشنهاد می کنیم، جایی که تنظیم کلمات با نوع تنظیم انگیزه\u200cهای زبانی ارتباط دارند. ما یک وظیفه جدید از پیش\u200cبینی مشترک از نوع تعمیر و تعمیر کلمات پیشنهاد می\u200cکنیم و الگوریتم\u200cهای یادگیری که نیمه تحت نظر قرار گرفته\u200cاند را برای این وظیفه پیشنهاد می\u200cکنیم. ما همچنین یک کار زیر از پیش بینی کردن نوع تنظیم که یک جفت کلمه تنظیم شده است حل می کنیم. در نتیجه آزمایشی ما، مدل\u200cهای ژنتریفی را که ما به نوع\u200cهای تنظیم مدل معرفی می\u200cکنیم، مدل\u200cها بدون نوع تنظیم بیشتر از مدل\u200cها انجام می\u200cدهند.', 'tr': 'Metini poz Bu kagyzda s철z 챌yzygy 체챌in t채ze bir m철h체m modi sa첵la첵rys. Di흫e s철z 챌yzygy dilinde n채hili g철rkezil첵채n 챌yzyglama t체rleri bilen baglan첵arlar. Biz s철z s철zleri we 챌yzyglama tary힊laryny흫 bir t채ze t채ze ta첵첵arlamasyny teklip edip, we bu zady흫 체챌in 첵arym-g철zle첵채n 철wrenme algoritmalaryny teklip edip g철r첵채ris. Biz hem 챌yky힊 체챌in 챌yky힊 체챌in 챌yky힊 체챌in 챌yky힊 체챌in 챌철z체ldik. Deneysel netijelerimizde, jenerativ nusgalarymyz 챌yzyglama nusgalarymyz 챌yzyglama nusgalarymyzdan 철r채n 챌yzyglama nusgalarymyzdan 챌ykar.', 'af': "Huidige woord oplyn modele verskiller nie tussen verskillende tipes oplyn skakels nie. In hierdie papier, ons verskaf 'n nuwe waarskynlike model vir woord-oplyning waar woord-oplyning geassosieer is met lingvisiese motiveer-oplyning tipes. Ons voorstel 'n nuwe taak van joint voorskou van woord-alignment en alignment tipes en voorstel novele semi-superviseerde leer algoritme vir hierdie taak. Ons lê ook 'n sub-taak van voorskou van die belyning tipe gegee 'n belynde woord paar. In ons eksperimentele resultate, die genereerbare modele wat ons voorstel aan model belyning tipes betekeurig uitvoer die modele sonder belyning tipes.", 'am': 'የአሁኑን ፋይል አስቀምጥ በዚህ ፕሮግራም፣ የቋንቋ ቋንቋ-ቋንቋ ማቀናቀል በተደረገበት ቃላት የቋንቋ ግንኙነት የተያያያየ አዲስ የስህተት ምሳሌ እናደርጋለን፡፡ የቃላትን ማቀናቀል እና መቀናቀል ሥርዓት እና ለመቀናቀል እና ለዚህ ስርዓት የደረጃ መማር አልgorithምን ለመዘጋጀት አቅራቢያ እናደርጋለን፡፡ እናም አካባቢ ቃላት ሁለት የተሰኘውን የመስመር አካባቢ ስራ እናቆርጣለን፡፡ በተፈተና ፍሬዎቻችን፣ የዘረኝነት ዓይነቶችን ምሳሌ እናሳውቃለን፡፡', 'az': 'Hazırkı söz tərəfləmə modelləri müxtəlif tərəfləmə bağları arasında ayırmaz. Bu kağızda, sözlərin tərəflənməsi üçün yeni mümkün bir modeli təyin edirik ki, sözlərin tərəflənməsi dil tərəflənməsi tərəflənməsi tərəflənməsi ilə əlaqədir. Biz sözlərin tərəflənməsi və tərəflənməsi türünün yeni bir işi təklif edirik və bu işin üçün yeni yarı tərəflənmiş öyrənmə algoritmini təklif edirik. Biz həmçinin çəkilən söz cütünü təmin etmək üçün bir sub-task çəkirik. Bizim təcrübəmiz sonuçlarımızda, modellər tərəfləndirmək növlərinə göstəririk, modelləri tərəfləndirmək növlərindən çox böyük bir şeydir.', 'sq': 'Modelet aktuale të përshtatjes së fjalëve nuk dallojnë midis llojeve të ndryshme të lidhjeve të përshtatjes. Në këtë letër, ne ofrojmë një model të ri probabilistik për përshtatjen e fjalëve ku përshtatjet e fjalëve janë të lidhura me llojet e përshtatjeve të motivuara gjuhësisht. Ne propozojmë një detyrë të re të parashikimit të përbashkët të llojeve të përshtatjes së fjalëve dhe të përshtatjes dhe propozojmë algoritme të reja të mësimit gjysmë-mbikqyrur për këtë detyrë. Ne gjithashtu zgjidhim një nëndetyrë të parashikimit të llojit të rregullimit të dhënë një çift fjalësh të rregulluar. Në rezultatet tona eksperimentale, modelet gjenerative që ne i prezantojmë modeleve të përshtatjes së llojeve të modeleve arrijnë në mënyrë të konsiderueshme modelet pa tipat e përshtatjes.', 'hy': 'Այսօրվա բառերի հավասարման մոդելները տարբեր տեսակի հավասարման կապերի միջև չեն տարբերակում: In this paper, we provide a new probabilistic model for word alignment where word alignments are associated with linguistically motivated alignment types.  Մենք առաջարկում ենք բառերի հավասարման և հավասարման տեսակների միասին կանխատեսելու նոր խնդիր և առաջարկում ենք այս խնդիրի համար նոր կիսակառավարվող ուսումնական ալգորիթմներ: Մենք նաև լուծում ենք հարմարեցման տեսակի կանխատեսման ենթախնդիրը, որը պարունակում է հարմարեցված բառերի զույգ: Մեր փորձարկումների արդյունքներում, սերունդային մոդելները, որոնք մենք ներկայացնում ենք մոդելների հավասարման տեսակներին, նշանակաբար գերազանցում են մոդելներին առանց հավասարման տեսակների:', 'bn': 'বর্তমান শব্দের স্থানান্তরের মডেল বিভিন্ন ধরনের অংশীদার লিংকের মধ্যে পার্থক্য করে না। এই কাগজটিতে আমরা শব্দের স্থানান্তরের জন্য একটি নতুন সম্ভাব্য মডেল প্রদান করি যেখানে শব্দের সাথে ভাষাভাষিকভাবে উদ্দীপ্ত স্থা আমরা একটি উপন্যাস প্রস্তাব করি শব্দের স্থাপন এবং স্থাপনের ধরনের প্রতি যৌথ ভবিষ্যদ্বাণী এবং এই কাজের জন্য সেমি পর্যবেক্ষণ করা অ্যালগরিদম প্রস্ আমরা একত্রিত শব্দের জোড়া দিয়ে একটি সাব-কাজ সমাধান করি। আমাদের পরীক্ষার ফলাফলের মধ্যে জেনারেটিভ মডেলটি আমরা মডেলের সাথে পরিচয় করিয়ে দিচ্ছি যে মডেলের সাথে স্থানান্তরের ধরন ছাড়া মড', 'ca': "Els models actuals d'allinjament de paraules no distingeixen entre diferents tipus de enllaços d'allinjament. En aquest article, proporcionem un nou model probabilístic per a l'allinjament de paraules on les allinjaments de paraules estan associats amb tipus d'allinjament motivats lingüísticament. Proposem una nova tasca de predicció conjunta de tipus d'allinjament de paraules i d'allinjament i proposem nous algoritmes d'aprenentatge semisupervisats per aquesta tasca. També resolem una subtasca de predir el tipus d'alliniament donat un parell de paraules allinjats. En els nostres resultats experimentals, els models generadors que introduim als tipus de models d'allinjament superen significativament els models sense tipus d'allinjament.", 'cs': 'Současné modely zarovnání slov nerozlišují mezi různými typy zarovnání vazeb. V tomto článku představujeme nový pravděpodobnostní model zarovnání slov, kde jsou zarovnání slov spojeny s jazykově motivovanými typy zarovnání. Navrhujeme nový úkol společné predikce typů zarovnání slov a zarovnání a navrhujeme pro tento úkol nové semi-supervisované učební algoritmy. Také řešíme dílčí úlohu předpovědi typu zarovnání daného zarovnaného slovního páru. V našich experimentálních výsledcích generativní modely, které zavádíme do typů zarovnání modelů, výrazně překonávají modely bez typů zarovnání.', 'et': 'Praegused sõnade joondamise mudelid ei erista erinevat tüüpi joondamislinke. Käesolevas töös pakume uut tõenäosuslikku mudelit sõnade joondamiseks, kus sõnade joondamised on seotud keeleliselt motiveeritud joondamise tüüpidega. Pakume välja uue ülesande sõna joondamise ja joondamise tüüpide ühiseks prognoosimiseks ning pakume välja uudseid pooljuhitatud õppealgoritme selle ülesande jaoks. Samuti lahendame allülesande prognoosida joondustüüpi antud joondatud sõnapaari. Meie eksperimentaalsetes tulemustes ületavad generatiivsed mudelid mudelite joondustüüpidele märkimisväärselt mudeleid ilma joondustüüpideta.', 'bs': 'Trenutni modeli poravnanja riječi ne razlikuju različite vrste poravnanja. U ovom papiru pružamo novi verovatni model za poravnanje riječi gdje su poravnanje riječi povezane sa tipovima jezički motiviranog poravnanja. Predlažemo novi zadatak zajedničkog predviđanja vrsta poravnanja i poravnanja riječi i predlažemo novi polu nadzorni algoritmi učenja za ovaj zadatak. Također ćemo riješiti podzadatak predviđanja tipa poravnanja koji je dao određen par riječi. U našim eksperimentalnim rezultatima, generativni modeli koje predstavljamo modelima vrsta poravnanja značajno iznosi modele bez vrsta poravnanja.', 'fi': 'Nykyiset sanakohdistusmallit eivät erota erityyppisiä tasauslinkkejä. Tässä työssä tarjoamme uuden todennäköisyysmallin sanalinjaukselle, jossa sanalinjaukset liitetään kielellisesti motivoituihin linjaustyypeihin. Ehdotamme uutta tehtävää sanalinjaus- ja linjaustyyppien yhteiseksi ennustamiseksi ja ehdotamme uusia puoliohjattuja oppimisalgoritmeja tähän tehtävään. Ratkaisemme myös alitehtävän, jossa ennustetaan tasaantuneen sanaparin tasaustyyppi. Kokeellisissa tuloksissa mallinnustyypeihin esittelemämme generatiiviset mallit suoriutuvat huomattavasti paremmin kuin mallit ilman kohdistustyyppejä.', 'sk': 'Trenutni modeli poravnave besed ne razlikujejo med različnimi vrstami povezav poravnave. V prispevku predstavljamo nov verjetnostni model poravnave besed, kjer so poravnave besed povezane z jezikovno motiviranimi vrstami poravnave. Predlagamo novo nalogo skupnega napovedovanja vrst poravnave besed in poravnave ter za to nalogo predlagamo nove polnadzorovane algoritme učenja. Rešujemo tudi podnalogo napovedovanja vrste poravnave v poravnanem besednem paru. V naših eksperimentalnih rezultatih so generativni modeli, ki jih uvajamo v tipe poravnave modelov, bistveno boljši od modelov brez poravnave.', 'he': 'דוגמני התאמת מילים הנוכחים לא מבחינים בין סוגים שונים של קשרים התאמה. בעיתון הזה, אנו מספקים מודל חדש סיבירליסטי לאימון מילים שבו המילים מחוברות לסוגים של מילים מוטיבציה שפתית. אנו מציעים משימה חדשה של חיזוי משותף של סוגי המילים המתאימים ומתאימים ומצייעים אלגוריתמים חדשים למידה חצי-מפקחים למשימה זו. אנחנו גם פותרים תחת משימה של לחזות את הטיפוס של התאמה נתן זוג מילים מתאמת. בתוצאות הניסויים שלנו, הדוגמנים הדורתיים שאנחנו מכירים לסוגים של התאמה מודל משמעותיים יותר מהדוגמנים ללא סוגי התאמה.', 'ha': "@ info: whatsthis Daga wannan takardan, Munã samar da wani misali mai yiwuwa wa masu tsari ga faɗa ɗawa da aka yi haɗa da nau'i masu cikin lingui da aka juyi. Tuna buɗe wani aikin nowaya na halayyar wa kunyar da ke faɗa ɗawa da nau'in faɗaɗawa kuma muna buɗe algoritori na kwanan-da aka tsare wa lõkaci wa wannan aikin. Mu raba wani sub-aikin da za'a yi bayani ga nau'in juyi wanda aka bai wa kalmar da aka daidaita. Ga majarin da ke jarraba mu, misãlai na jenatacce wanda Muke iya ƙara wa misãlai masu cikin juyi da muhimmi, za'a sami misãlai bã da nau'i masu daidaita.", 'jv': 'align-reference-type Nang pepulan iki, kita enyeste model sing gawe perusahaan kanggo nggawe pawaran luwih Anyone Learn Mode Genjer-genjer paling-paling dhéwé, model sing nyimpen dadi nggawe model sing nyimpen karo nggawe model sing bisa diantepakan seneng pisan anyar nggawe model.', 'bo': 'ད་ལྟོའི་གྲལ་སྒྲིག་འཇུག་སྟངས་མ་དབྱེ་སྒྲིག་གི་སྦྲེལ་མཐུད་མི་འདྲ་བ ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ལྟ་བུའི་གྲལ་སྒྲིག་ཕྲེང་གི་ཐོག་སྒྲིག་ཆ་གི་ཆོས་ཉིད་ཅིག་སྟོན་ཡོད། ང་ཚོས་དུས་མཐུན་གྱི་སྔོན་ལྟའི་གྲངས་སྒྲིག་དང་གྲངས་སྒྲིག་རིགས་ཀྱི་ལས་ཀ་གསར་བ་ལྟ་རྟོག་པའི་སློབ་གླེང་སྒྲིག་སྟངས་ཆ་རྐྱེན་དེ་བས ང་ཚོས་གྲངས་སྒྲིག་གི་རིགས་རྣམས་གྲངས་སྒྲིག་པའི་ལྟ་བུ ང་ཚོའི་བརྟག་འཕྲུལ་གྱི་གྲུབ་འབྲས་བ་དེ་ལྟ་བུའི་དཔེ་དབྱིབས་གྲལ་སྒྲིག'}
{'en': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'es': 'Redes adversarias aumentadas de aspecto para la adaptación de dominios', 'pt': 'Redes Adversárias com Aspecto Aumentado para Adaptação de Domínio', 'ar': 'شبكات الخصومة المعززة بالعرض لتكييف المجال', 'fr': "Réseaux contradictoires augmentés par aspect pour l'adaptation de domaines", 'ja': 'ドメインアダプテーションのためのアスペクト拡張された対抗ネットワーク', 'zh': '向域宜者增抗网络', 'hi': 'डोमेन अनुकूलन के लिए पहलू संवर्धित प्रतिकूल नेटवर्क', 'ru': 'Аспектно-дополняемые сопернические сети для адаптации домена', 'ga': "Líonraí Sáraimh Mhéadaithe Gné d'Oiriúnú Fearainn", 'ka': 'Name', 'hu': 'Aspect-kiterjesztett Adversarial Networks for Domain adaptation', 'it': "Reti Adversariali Aspect-Augmented per l'Adattamento del Dominio", 'el': 'Ενσωματωμένα δίκτυα για την προσαρμογή των τομέων', 'lt': 'Su aspektais susiję prieštaringi pritaikymo prie domeno tinklai', 'ms': 'Rangkaian Adversarial Ditambah Aspect untuk Penyesuaian Domain', 'kk': 'Домен адаптациясы үшін аспекті көтерілген конверсариялық желі', 'mn': 'Домены адаптацийн тусламжтайгаар дэвшүүлсэн сэтгэл зүйн сүлжээ', 'mk': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'ml': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'no': 'Forhøgde rekursariale nettverk for domenetilpassing', 'pl': 'Rozszerzone aspekty sieci przeciwnych dla adaptacji domen', 'ro': 'Rețele adverse cu aspect augmentat pentru adaptarea domeniului', 'si': 'Name', 'sr': 'Povećan aspekt. Adversarijske mreže za adaptaciju domena', 'mt': 'Netwerks Adversarji miżjuda bl-aspett għall-Adattament tad-Dominju', 'so': 'Shabakada caawimaadda ee Domain', 'sv': 'Aspektförstärkta Adversarial Networks for Domain Adaption', 'ur': 'ڈومین اڈپٹیٹ کے لئے اضافہ کیا گیا', 'ta': 'Domain Adaptation', 'uz': 'Name', 'vi': 'Quan hệ kế tiếp Lãnh địa', 'bg': 'Рекламни мрежи с разширени аспекти за адаптация на домейна', 'da': 'Aspect-augmented Adversarial Networks for Domain Adaption', 'de': 'Aspect-augmented Adversarial Networks für Domain Adaptation', 'id': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'ko': '영역에 적응하는 방면으로 대항 네트워크를 강화하다', 'hr': 'Povećana na aspektu poremećajna mreža za adaptaciju domena', 'nl': 'Aspect-augmented Adversarial Networks voor Domeinaanpassing', 'sw': 'Mtandao wa Utawala wa Utawala kwa ajili ya Adaptation Domain', 'fa': 'شبکه\u200cهای تجاوز\u200cکننده\u200cای برای تغییرات دامین\u200c', 'sq': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'af': 'Name', 'tr': 'domain', 'am': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'bn': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'az': 'Domain Adjustasyonu üçün mənfəət-artırılmış Adversarial Netikləri', 'bs': 'Povećana na aspektu Adversarijska mreža za adaptaciju domena', 'hy': 'Aspect-augmented Adversarial Networks for Domain Adaptation', 'cs': 'Aspect-rozšířené nepříznivé sítě pro adaptaci domén', 'ca': "Redes adversaries per l'adaptació al domini augmentates amb aspectes", 'et': 'Aspektiga täiendatud domeeni kohandamise kõrvaltoimete võrgustikud', 'fi': 'Aspect-added Adversarial Networks for Domain Adaptation', 'jv': 'Language', 'ha': 'KCharselect unicode block name', 'he': 'Name', 'sk': 'Oglaševalna omrežja, povečana z vidiki, za prilagajanje domen', 'bo': 'Aspect-augmented Adversarial Networks for Domain Adaptation'}
{'en': 'We introduce a neural method for transfer learning between two (source and target) classification tasks or aspects over the same domain. Rather than training on target labels, we use a few keywords pertaining to source and target aspects indicating sentence relevance instead of document class labels. Documents are encoded by learning to embed and softly select relevant sentences in an aspect-dependent manner. A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents. We ensure transfer through aspect-adversarial training so that encoded documents are, as sets, aspect-invariant. Experimental results demonstrate that our approach outperforms different baselines and model variants on two datasets, yielding an improvement of 27 % on a pathology dataset and 5 % on a review dataset.', 'fr': "Nous introduisons une méthode neuronale pour l'apprentissage par transfert entre deux tâches ou aspects de classification (source et cible) sur le même domaine. Plutôt que de former sur les étiquettes cibles, nous utilisons quelques mots-clés relatifs aux aspects source et cible indiquant la pertinence de la phrase au lieu des étiquettes de classes de documents. Les documents sont codés en apprenant à intégrer et à sélectionner doucement des phrases pertinentes en fonction de l'aspect. Un classificateur partagé est formé sur les documents codés source et les étiquettes, et appliqué aux documents codés cibles. Nous assurons le transfert par le biais d'une formation aspect-contradictoire afin que les documents codés soient, en tant qu'ensembles, invariants d'aspect. Les résultats expérimentaux démontrent que notre approche surpasse les différentes bases de référence et variantes de modèle sur deux ensembles de données, ce qui donne une amélioration de 27\xa0% sur un ensemble de données de pathologie et de 5\xa0% sur un ensemble de données de revue.", 'ar': 'نقدم طريقة عصبية لنقل التعلم بين مهمتين أو جوانب تصنيف (المصدر والهدف) في نفس المجال. بدلاً من التدريب على التسميات المستهدفة ، نستخدم بعض الكلمات الرئيسية المتعلقة بجوانب المصدر والهدف التي تشير إلى صلة الجملة بدلاً من تسميات فئة المستندات. يتم ترميز المستندات من خلال تعلم تضمين الجمل ذات الصلة واختيارها برفق بطريقة تعتمد على الجانب. يتم تدريب المصنف المشترك على المستندات والتسميات المشفرة المصدر ، ويتم تطبيقه على المستندات المشفرة المستهدفة. نحن نضمن النقل من خلال التدريب على الخصومة بحيث تكون المستندات المشفرة ، كمجموعات ، غير متغيرة. توضح النتائج التجريبية أن نهجنا يتفوق على خطوط الأساس المختلفة ومتغيرات النموذج في مجموعتي بيانات ، مما يؤدي إلى تحسن بنسبة 27٪ في مجموعة بيانات علم الأمراض و 5٪ في مجموعة بيانات المراجعة.', 'es': 'Introducimos un método neuronal para transferir el aprendizaje entre dos tareas o aspectos de clasificación (origen y destino) en el mismo dominio. En lugar de capacitarnos en etiquetas de destino, utilizamos algunas palabras clave relacionadas con los aspectos de origen y destino que indican la relevancia de la oración en lugar de etiquetas de clase de documento. Los documentos se codifican aprendiendo a incrustar y seleccionar suavemente oraciones relevantes de una manera dependiente del aspecto. Un clasificador compartido se entrena en los documentos y etiquetas codificados de origen y se aplica a los documentos codificados de destino. Garantizamos la transferencia a través de la capacitación de aspectos adversarios para que los documentos codificados sean, como conjuntos, invariantes de aspecto. Los resultados experimentales demuestran que nuestro enfoque supera a las diferentes líneas de base y variantes del modelo en dos conjuntos de datos, lo que produce una mejora del 27% en un conjunto de datos de patología y del 5% en un conjunto de datos de revisión.', 'pt': 'Introduzimos um método neural para transferência de aprendizado entre duas tarefas ou aspectos de classificação (origem e destino) sobre o mesmo domínio. Em vez de treinar em rótulos de destino, usamos algumas palavras-chave relacionadas a aspectos de origem e destino que indicam a relevância da frase em vez de rótulos de classe de documento. Os documentos são codificados aprendendo a incorporar e selecionar suavemente frases relevantes de uma maneira dependente do aspecto. Um classificador compartilhado é treinado nos documentos e rótulos codificados de origem e aplicado aos documentos codificados de destino. Garantimos a transferência por meio de treinamento de adversário de aspecto para que os documentos codificados sejam, como conjuntos, invariantes de aspecto. Os resultados experimentais demonstram que nossa abordagem supera diferentes linhas de base e variantes de modelo em dois conjuntos de dados, gerando uma melhoria de 27% em um conjunto de dados de patologia e 5% em um conjunto de dados de revisão.', 'ja': '2つの（ソースとターゲット）分類タスクまたは側面の間で同じドメインにわたって学習を転送するためのニューラルメソッドを紹介します。ターゲットラベルに関するトレーニングではなく、ドキュメントクラスラベルの代わりに、文の関連性を示すソースとターゲットの側面に関連するいくつかのキーワードを使用します。文書は、アスペクト依存的な方法で関連する文章を埋め込み、柔らかく選択することを学ぶことによってエンコードされます。共有分類子は、ソースエンコードされたドキュメントとラベルに関するトレーニングを受け、ターゲットエンコードされたドキュメントに適用されます。私たちは、エンコードされたドキュメントがセットとしてアスペクト不変であるように、アスペクト対立トレーニングを通じて転送することを保証します。実験結果は、我々のアプローチが２つのデータセットで異なるベースラインおよびモデルバリアントを上回り、病理学的データセットで２ ７ ％、レビューデータセットで５ ％の改善をもたらすことを実証している。', 'hi': 'हम एक ही डोमेन पर दो (स्रोत और लक्ष्य) वर्गीकरण कार्यों या पहलुओं के बीच स्थानांतरण सीखने के लिए एक तंत्रिका विधि पेश करते हैं। लक्ष्य लेबल पर प्रशिक्षण के बजाय, हम स्रोत और लक्ष्य पहलुओं से संबंधित कुछ कीवर्ड का उपयोग करते हैं जो दस्तावेज़ वर्ग लेबल के बजाय वाक्य प्रासंगिकता को इंगित करते हैं। दस्तावेज़ों को एम्बेड करने के लिए सीखने और धीरे-धीरे एक पहलू-निर्भर तरीके से प्रासंगिक वाक्यों का चयन करके एन्कोड किया जाता है। एक साझा क्लासिफायर को स्रोत एन्कोडेड दस्तावेज़ों और लेबल्स पर प्रशिक्षित किया जाता है, और एन्कोडेड दस्तावेज़ों को लक्षित करने के लिए लागू किया जाता है। हम पहलू-प्रतिकूल प्रशिक्षण के माध्यम से हस्तांतरण सुनिश्चित करते हैं ताकि एन्कोडेड दस्तावेज़ सेट के रूप में, पहलू-अपरिवर्तनीय हों। प्रयोगात्मक परिणामों से पता चलता है कि हमारा दृष्टिकोण दो डेटासेट पर विभिन्न बेसलाइन और मॉडल वेरिएंट को मात देता है, जिससे पैथोलॉजी डेटासेट पर 27% और समीक्षा डेटासेट पर 5% का सुधार होता है।', 'zh': '吾言一神经之法,施于同域之二(源、趋)分类迁学。 吾不教之于标签,而以关键字指句相关性,非文档类也。 以学相关,以软择文档编码。 共享分类器教于源编码文档、标签,而用于招编码文档。 吾保抗教传输,以编码其文档为不易也。 实验结果表明,吾法优于两数集上异基线形变体,于病理学数集上生27%,于审数集上生5%。', 'ru': 'Введем нейронный метод передачи обучения между двумя задачами или аспектами классификации (исходной и целевой) в одной области. Вместо обучения целевым меткам мы используем несколько ключевых слов, относящихся к исходным и целевым аспектам, указывающим на релевантность предложения вместо меток классов документов. Документы кодируются путем обучения внедрять и мягко выбирать соответствующие предложения в зависимости от аспекта. Общий классификатор обучается исходным закодированным документам и меткам и применяется к целевым закодированным документам. Мы обеспечиваем передачу с помощью обучения на основе противоречивых аспектов, чтобы закодированные документы были, как наборы, аспект-инвариантными. Экспериментальные результаты показывают, что наш подход превосходит различные исходные уровни и варианты модели на двух наборах данных, что дает улучшение на 27% на наборе данных о патологии и 5% на наборе данных обзора.', 'ga': 'Tugaimid isteach modh néarúil chun foghlaim a aistriú idir dhá thasc aicmithe (foinse agus sprioc) nó gnéithe thar an bhfearann céanna. Seachas oiliúint a chur ar sprioclipéid, úsáidimid cúpla eochairfhocal a bhaineann le gnéithe foinse agus sprice a léiríonn ábharthacht na habairte in ionad lipéid ranga doiciméad. Ionchódaítear doiciméid trí fhoghlaim conas abairtí ábhartha a leabú agus a roghnú go bog ar bhealach a bhraitheann ar ghnéithe. Cuirtear oiliúint ar aicmitheoir comhroinnte ar na doiciméid agus ar na lipéid fhoinse-ionchódaithe, agus cuirtear i bhfeidhm é ar spriocdhoiciméid ionchódaithe. Cinnteoimid go n-aistrítear trí oiliúint sáraíochta gné ionas go mbeidh doiciméid ionchódaithe, mar thacair, mar ghné-athraitheach. Léiríonn torthaí turgnamhacha go sáraíonn ár gcur chuige bonnlínte difriúla agus malairtí samhlacha ar dhá thacar sonraí, rud a thugann feabhas 27% ar thacar sonraí paiteolaíochta agus 5% ar thacar sonraí athbhreithnithe.', 'hu': 'Idegi módszert vezetünk be a tanulás transzferére két (forrás és cél) osztályozási feladat vagy aspektus között ugyanazon a területen. A célcímkékre vonatkozó képzés helyett néhány olyan kulcsszót használunk, amelyek a forrás- és célszempontokra vonatkoznak, amelyek a mondatok relevanciáját jelzik a dokumentum osztály címkéi helyett. A dokumentumokat úgy kódolják, hogy megtanulják beágyazni és finoman kiválasztani a releváns mondatokat aspektfüggő módon. A megosztott osztályozót képezik a forráskódolt dokumentumokra és címkékre, és alkalmazzák a célkódolt dokumentumokra. Az aspektus-ellenséges képzésen keresztül biztosítjuk az átvitelt, hogy a kódolt dokumentumok, mint halmazok, aspektinvariánsak legyenek. Kísérleti eredmények azt mutatják, hogy megközelítésünk két adatkészleten felülmúlja a különböző alapvető és modellváltozatokat, ami 27%-os javulást eredményez egy patológiai adatkészleten és 5%-os vizsgálati adatkészleten.', 'ka': 'ჩვენ შევცვალობთ ნეიროლური მეტი, რომელიც ორი (მხოლოდ და მიtarget) კლასიფიკაციის დავალება ან აპექტები იგივე დიომენზე. მინიშვნელოვანი ლაბეტების საცვლად, ჩვენ გამოყენებთ რამდენიმე კლასი სიტყვების შესახებ, რომელიც მინიშვნელოვანი და მინიშვნელოვანი აპექტირების შესახებ, რომელიც დოკუმენტები კოდირებულია აპექტიკური განსაზღვრებული სიტყვების შესაძლებელად შესწავლად და მართლად მონიშნოთ შესაძლებელი სიტყვები. საზოგადოებული კლასიფიკაცია კოდირებული დოკუმენტებში და etiket-ში მოყენებულია და მიზეზი კოდირებული დოკუმენტებში მოყენებულია. ჩვენ დარწმუნდებით აპექტიკური განაკეთებას, რომ კოდირებული დოკუმენტები, როგორც კოდირებულია, აპექტიკური განაკეთებას. ექსპერიმენტიური წარმოდგენები გამოჩვენებენ, რომ ჩვენი პროგენტი განსხვავებული ბაზის და მოდელური გარიანტები ორი მონაცემენტის კონფიგურაციაში გავაკეთებენ, რომელიც 27%-ის გაუკეთება', 'el': 'Εισάγουμε μια νευρωνική μέθοδο για τη μάθηση μεταφοράς μεταξύ δύο (πηγής και στόχου) εργασιών ταξινόμησης ή πτυχών στον ίδιο τομέα. Αντί να εκπαιδεύσουμε σε ετικέτες στόχων, χρησιμοποιούμε μερικές λέξεις-κλειδιά που σχετίζονται με πτυχές προέλευσης και στόχου που υποδεικνύουν συνάφεια με προτάσεις αντί για ετικέτες κλάσης εγγράφων. Τα έγγραφα κωδικοποιούνται μαθαίνοντας να ενσωματώνουν και να επιλέγουν απαλά σχετικές προτάσεις με τρόπο που εξαρτάται από τις πτυχές. Ένας κοινόχρηστος ταξινομητής εκπαιδεύεται στα κωδικοποιημένα έγγραφα προέλευσης και τις ετικέτες και εφαρμόζεται σε κωδικοποιημένα έγγραφα προορισμού. Διασφαλίζουμε τη μεταφορά μέσω της εκπαίδευσης πλευρών-αντιδιαστάσεων έτσι ώστε τα κωδικοποιημένα έγγραφα να είναι, ως σύνολα, αναλλοίωτα στις πτυχές. Τα πειραματικά αποτελέσματα δείχνουν ότι η προσέγγισή μας ξεπερνά τις διαφορετικές γραμμές βάσης και τις παραλλαγές μοντέλων σε δύο σύνολα δεδομένων, επιτυγχάνοντας βελτίωση 27% σε ένα σύνολο δεδομένων παθολογίας και 5% σε ένα σύνολο δεδομένων ανασκόπησης.', 'it': "Introduciamo un metodo neurale per trasferire l'apprendimento tra due compiti o aspetti di classificazione (sorgente e target) sullo stesso dominio. Piuttosto che allenarci sulle etichette target, utilizziamo alcune parole chiave relative agli aspetti sorgente e target che indicano la rilevanza della frase invece delle etichette di classe documento. I documenti vengono codificati imparando ad incorporare e selezionare delicatamente frasi pertinenti in modo dipendente dall'aspetto. Un classificatore condiviso viene addestrato sui documenti codificati di origine e sulle etichette e applicato ai documenti codificati di destinazione. Garantiamo il trasferimento attraverso l'addestramento aspect-adversary in modo che i documenti codificati siano, come set, aspect-invariant. I risultati sperimentali dimostrano che il nostro approccio supera diverse linee di base e varianti di modello su due set di dati, ottenendo un miglioramento del 27% su un set di dati patologici e del 5% su un set di dati di revisione.", 'kk': 'Біз бір доменде екі (көзі мен мақсатты) классификациялық тапсырмалар не аспекттер арасындағы оқыту үшін невралдық әдісін келтіреміз. Мақсатты жарлықтарды оқыту орнына, құжатты класс жарлықтарының орнына, көзі мен мақсатты аспектерінің бірнеше кілт сөздерді қолданамыз. Құжаттар сәйкес тәуелді мәліметтерді ендіру және таңдау үшін оқып кодтады. Ортақтастырылған классификатор көзі кодталған құжаттар мен жарлықтарда оқылған және нақты кодталған құжаттар үшін қолданылады. Біз аспекттің қарсы-қарсы оқыту арқылы, кодталған құжаттарды баптау үшін, аспекттің қарсы-қарсы оқыту арқылы көмектесеміз. Эксперименталдық нәтижелері біздің тәсіліміз екі деректер қорларында түрлі негізгі жолдар мен үлгі варианттарды жасайды, патологиялық деректер қорларында 27% жақсарту және қарау деректер қорларында 5%.', 'lt': 'We introduce a neural method for transfer learning between two (source and target) classification tasks or aspects over the same domain.  Vietoj mokymo tikslinėse etiketėse naudojame keletą pagrindinių žodžių, susijusių su šaltiniais ir tiksliniais aspektais, kurie rodo reikšmę sakiniams, o ne dokumentų klasės etiketėmis. Dokumentai koduojami mokant įtraukti ir lengvai pasirinkti atitinkamus sakinius priklausomai nuo aspekto. Bendras klasifikatorius mokomas koduotuose šaltinio dokumentuose ir etiketėse ir taikomas tiksliniams koduotiems dokumentams. Užtikriname perkėlimą rengiant priešingus aspektus, kad koduoti dokumentai, kaip rinkiniai, būtų skirtingi aspektams. Eksperimentiniai rezultatai rodo, kad mūsų požiūris viršija skirtingas bazines linijas ir modelių variantus dviejuose duomenų rinkiniuose, o patologinių duomenų rinkinys pagerėjo 27 %, o peržiūros duomenų rinkinys – 5 %.', 'mt': 'Aħna nintroduċu metodu newrali għat-trasferiment tat-tagħlim bejn żewġ kompiti ta’ klassifikazzjoni (sors u mira) jew aspetti fuq l-istess qasam. Minflok it-taħriġ fuq it-tikketti fil-mira, a ħna nużaw ftit kliem ewlieni li jappartjenu għall-aspetti tas-sors u tal-mira li jindikaw ir-rilevanza tas-sentenza minflok it-tikketti tal-klassi tad-dokumenti. Id-dokumenti huma kkodifikati billi jitgħallmu biex jiġu inkorporati u jagħżlu bil-mod sentenzi rilevanti b’mod dipendenti fuq l-aspett. A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents.  Aħna niżguraw it-trasferiment permezz ta’ taħriġ kontra l-aspetti sabiex id-dokumenti kkodifikati jkunu, bħala settijiet, invarji mill-aspetti. Riżultati esperimentali juru li l-approċċ tagħna jaqbeż linji bażi u varjanti mudell differenti fuq żewġ settijiet ta’ dejta, u dan iwassal għal titjib ta’ 27% fuq sett ta’ dejta patoloġika u 5% fuq sett ta’ dejta ta’ reviżjoni.', 'ms': 'We introduce a neural method for transfer learning between two (source and target) classification tasks or aspects over the same domain.  Daripada berlatih pada label sasaran, kami menggunakan beberapa kata kunci yang berkaitan dengan aspek sumber dan sasaran yang menunjukkan relevansi kalimat selain dari label kelas dokumen. Dokumen dikodifikasikan dengan belajar untuk memasukkan dan memilih kalimat yang berkaitan dengan cara tergantung aspek. Pengeklasifikasi terkongsi dilatih pada dokumen dan label terkod sumber, dan dilaksanakan pada dokumen terkod sasaran. Kami memastikan pemindahan melalui latihan aspek-musuh sehingga dokumen terkod, sebagai set, aspek-invarian. Hasil percubaan menunjukkan bahawa pendekatan kita melampaui garis dasar dan varian model yang berbeza pada dua set data, memberikan peningkatan 27% pada set data patologi dan 5% pada set data ulasan.', 'mk': 'We introduce a neural method for transfer learning between two (source and target) classification tasks or aspects over the same domain.  Наместо да обучуваме на ознаките на метата, користиме неколку клучни зборови кои се однесуваат на изворот и целните аспекти кои покажуваат релевантност на речениците наместо ознаките на класата на документите. Документите се кодирани со учење да се вградат и меко да се изберат релевантните реченици на начин кој зависи од аспектот. Поделен класификатор е обучен на изворот кодирани документи и етикети, и аплициран на кодирани документи. We ensure transfer through aspect-adversarial training so that encoded documents are, as sets, aspect-invariant.  Experimental results demonstrate that our approach outperforms different baselines and model variants on two datasets, yielding an improvement of 27% on a pathology dataset and 5% on a review dataset.', 'ml': 'രണ്ട് (സോര്\u200dസ്സും ലക്ഷ്യത്തിനും ഇടയില്\u200d പഠിപ്പിക്കുന്നതിനും നമ്മള്\u200d ഒരു പുതിയ രീതിയില്\u200d പരിചയപ്പെടുത്തുന്ന രീതിയിലാണ്  ലക്ഷ്യത്തിന്റെ ലക്ഷ്യത്തില്\u200d പരിശീലിക്കുന്നതിനെക്കാള്\u200d ഞങ്ങള്\u200d സോര്\u200dസിന്റെയും ലക്ഷ്യത്തിന്റെയും കുറച്ച് കീവോര്\u200dഡുകള്\u200d ഉപയോഗ പ്രധാനപ്പെട്ട വാക്കുകള്\u200d സൌമ്യമായി തെരഞ്ഞെടുക്കാനും പഠിപ്പിക്കാനും രേഖകള്\u200d കോഡിങ്ങ് ചെയ്യുന്നു ഒരു പങ്കാളിയുള്ള ക്ലാസ്ഫിഫയര്\u200d സ്രോതസ്സില്\u200d എക്കോഡ് ചെയ്ത രേഖകളും ലേബലുകളും പരിശീലിച്ചിരിക്കുന്നു. ലക്ഷ്യ പ്രത്യേക പരിശീലനത്തിലൂടെ മാറ്റുന്നത് നമുക്ക് ഉറപ്പ് വരുത്തുന്നു. അതുകൊണ്ട് എന്\u200dകോഡിപ്പിക്കപ്പെട്ട രേഖകള്\u200d സ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ അടുത്ത് വ്യത്യസ്ത ബെസ്ലൈനുകളില്\u200d നിന്നും മോഡല്\u200d വേറെന്റര്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നത', 'pl': 'Wprowadzamy neuronową metodę transferowego uczenia się między dwoma (źródłowymi i docelowymi) zadaniami klasyfikacyjnymi lub aspektami w tej samej dziedzinie. Zamiast szkolenia na etykietach docelowych używamy kilku słów kluczowych odnoszących się do aspektów źródłowych i docelowych wskazujących istotność zdania zamiast etykiet klas dokumentów. Dokumenty są kodowane poprzez naukę osadzania i delikatnego wyboru odpowiednich zdań w sposób zależny od aspektu. Udostępniony klasyfikator jest szkolony na źródłowo zakodowanych dokumentach i etykietach i stosowany do docelowych zakodowanych dokumentów. Zapewniamy transfer poprzez szkolenie aspektowo-przeciwne, tak aby zakodowane dokumenty były, jako zbiory, aspektowo-niezmienne. Wyniki eksperymentalne pokazują, że nasze podejście przewyższa różne linie bazowe i warianty modeli na dwóch zbiorach danych, dając poprawę 27% na zbiorze danych patologicznym i 5% na zbiorze danych przeglądowym.', 'ro': 'Introducem o metodă neurală de transfer de învățare între două sarcini sau aspecte de clasificare (sursă și țintă) din același domeniu. Mai degrabă decât instruirea pe etichetele țintă, folosim câteva cuvinte cheie referitoare la aspectele sursă și țintă care indică relevanța propoziției în loc de etichetele clasei documentelor. Documentele sunt codificate prin învățarea de a încorpora și selecta ușor propoziții relevante într-o manieră dependentă de aspect. Un clasificator partajat este instruit pe documentele și etichetele codificate sursă și aplicat documentelor codificate țintă. Asigurăm transferul prin instruire aspect-adversar astfel încât documentele codificate să fie, ca seturi, invariante de aspect. Rezultatele experimentale demonstrează că abordarea noastră depășește diferitele linii de bază și variante de model pe două seturi de date, ceea ce duce la o îmbunătățire de 27% a unui set de date patologice și 5% a unui set de date de revizuire.', 'sr': 'Predstavljamo neuralnu metodu za učenje premeštaja između dva (izvora i cilja) klasifikacije ili aspekta u istom domenu. Umesto obuke ciljnih etiketa, koristimo nekoliko ključnih reči u vezi izvora i ciljnih aspekta koji ukazuju na relevantnost rečenica umjesto etiketa klase dokumenta. Dokumenti su kodirani učenjem da uključimo i meko odaberemo relevantne rečenice na način na koji ovisi o aspektu. Podijeljeni klasifikator je obučen na kodiranim dokumentima i etiketama izvora i primjenjen na ciljne kodirane dokumente. Mi osiguravamo prijenos kroz aspekt-neprijateljsku obuku kako bi kodirani dokumenti, kao setovi, bili neprijatelji aspekta. Eksperimentalni rezultati pokazuju da naš pristup iznosi različite osnovne linije i modelne varijante na dva dataset a, koji daje poboljšanje od 27% na setu patoloških podataka i 5% na setu podataka za pregled.', 'so': 'Waxaynu soo bandhignaynaa qaab neuro ah oo ku wareejinta waxbarashada u dhexeeya labo shaqo fasax (sourceed iyo goal) ama qeybo ku saabsan isku domain. Isku xiriirta waxbarashada calaamadaha goalka, waxaynu isticmaalnaa dhawr erayo oo ku saabsan sourceed iyo dhinacyada goalka, taas oo ku qoran habboon erayada ku saabsan calaamada wargeyska. Qoraalka dukumentiyada waxaa lagu qoraa barashada lagu soo bandhigi karo oo si qarsoodi ah u doorta erayada la xiriira oo ku xiran. Shaqeyb ahaan waxaa lagu tababariyaa waraaqaha warqada lagu qoray iyo alaabta, waxaana lagu codsadaa dukumentiyada la qoray waxyaabaha lagu qoray. Waxaynu ka xaqiijinnaa in lagu soo wareejiyo waxbarashada ka geesta ah, si ay dukumentiyada kooban yihiin sida qoraalka loo soo galo. Imtixaanka waxaa ka muuqda in dhaqdhaqaalahayagu uu ka soo saaraa qoraal kala duduwan iyo isbedelka kala duduwan labada databases, wuxuuna ka keenaa hagaajinta 27% oo ka kordhiya kooxda macluumaadka caafimaadka iyo 5% oo ka qoran sawirada baaritaanka.', 'mn': 'Бид хоёр (эх үүсвэр болон зорилго) хуваалцах үйл ажиллагаа эсвэл асуудлын хооронд суралцах мэдрэлийн арга зам бий болгодог. Бид зориулагдсан загварын жагсаалтын сургалтын оронд бичил ангийн жагсаалтын оронд хэдэн түлхүүр үг ашигладаг. Документ нь харьцааны хамааралтай аргаар холбогдолтой өгүүлбэрийг суралцаж, бага зэрэг сонгож байдаг. Хувь хуваалтын классификатор эх үүсвэр кодлогдсон баримтууд, etiket дээр суралцагддаг. Цагийн кодлогдсон баримтууд дээр хэрэглэгддэг. Бид хэсэг эсрэг сургалтын дасгал хөдөлгөөндөө шилжүүлэх боломжтой болгон шилжүүлсэн бичил баримтууд нь хэсэг хэлбэртэй байдаг. Эмчилгээний үр дүнд бидний арга нь хоёр өгөгдлийн сангийн суурь шугам болон загварын өөр өөр өөрчлөлт гаргадаг гэдгийг харуулж байна. Эмчилгээний өгөгдлийн сангийн 27 хувьд сайжруулж, шийдвэрлэлийн өгөгдлийн сангийн 5 хувьд', 'no': 'Vi introduserer ein neuralmetode for å læra overføring mellom to (kjelde og mål) klassifikasjonar eller aspektar over same domene. I staden for opplæring på målsetikettar, bruker vi nokre nøkkelord for kjelde og målspesifikat som viser setningsvar i staden for dokumentklassesetikettar. Dokument er koda ved å læra å innebygge og velja relevante setningar på ein aspektavhengig måte. Eit delt klassifiserer er trent på kjeldekode dokument og etikettar, og brukt til målkoderte dokument. Vi sikrer at overføring gjennom aspekt-adversarial trening er slik at koderte dokument er, som sett, aspekt-invariant. Eksperimentale resultat viser at tilnærminga vårt utfører forskjellige baselinjer og modellvariantar på to datasett, som fører til å forbedra 27 % på ein patologisk datasett og 5 % på ei omsyningsdatasett.', 'si': 'අපි එකම ඩෝමේන් වලින් දෙන්න (මුළු සහ ඉලක්කය) විශේෂණ වැඩක් සහ අනුවෙන් ඉගෙනගන්න න්\u200dයුරල් විධානයක්  ලක්ෂණ ලේබල් වලට ප්\u200dරශ්නයක් වෙනුවෙන්, අපි ප්\u200dරශ්නයක් සහ ලක්ෂණ ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් ප්\u200dරයෝජනය දස්තාවේදී සම්බන්ධ විදියට සම්බන්ධ විදියට සම්බන්ධ වාක්ය තෝරාගන්න සහ සම්බන්ධ විදියට ඉගෙ සමාගත විශේෂකයෙක් ප්\u200dරධානය කරලා තියෙන්නේ මුළු සංකේත විශේෂකය සහ ලේබල් වලට, ඉලක්කේත විශේෂක අපි සැකසුම් කරනවා විරෝද්ධ විරෝද්ධ ප්\u200dරශ්නයක් නිසා සැකසුම් වලින්, සැකසුම් වලින්. පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ විදියට වෙනස් පරීක්ෂණ ප්\u200dරතිචාරය සහ මන්ද්\u200dරණ ප්\u200dරතිචාරය දෙකක් තියෙන්නේ වෙ', 'ta': 'இரண்டு (மூலம் மற்றும் இலக்கு) வகுப்பு பணிகள் அல்லது ஒரே களத்திற்கு மேல் உள்ள புதிய முறைமையை மாற்றுவதற்கு நாம் ஒரு புதிய முறையை  இலக்கு சிட்டைகளில் பயிற்சியை விட, மூலம் மற்றும் இலக்கு விளைவுகளில் சில விசைகளை பயன்படுத்துகிறோம் ஆவண வகுப்பு சிட்டைகளை பதில புகுதிய வாக்கியங்களை மெதுவாக தேர்ந்தெடுத்து முறையாக தொடர்புடைய வாக்கியங்களை மூலம் குறியிடப்படுகிறது. ஒரு பகிர்ந்த வகுப்பாளர் மூலத்தில் குறியீட்டு ஆவணங்கள் மற்றும் சிட்டைகளில் பயிற்சி செய்யப்படுகிறது, இலக்குறியீ நாம் குறியீட்டாக்கப்பட்ட ஆவணங்கள் அமைப்புகள், பக்கத்திற்கு நுழைந்துள்ள பயிற்சி மூலம் மாற்றுதலை உறுதிப்படுத சோதனையின் முடிவுகள் தெரிவிக்கிறது என்றால் எங்கள் நெருக்கம் வேறுபாடு அடிப்படைகள் மற்றும் மாதிரி மாறிகளை இரண்டு தரவுத் தளங்களில் செய்யும், ஒர', 'ur': 'ہم نے ایک نئورل طریقہ پہنچا دیں کہ دو (سورس اور موقع) کلاسیفوں کے درمیان تعلیم سکھانے کے لئے ایک نئورل طریقہ ہے۔ ہدایت لیبل پر تطارین کے بدلے، ہم ایک چند کلوئیں استعمال کرتے ہیں جن کے متعلق سورج اور موجود الگوں کے متعلق ہیں، جو جماعت کی نسبت دکھاتے ہیں، دکھانے کے کلاس لیبل کے بدلے. ڈکومئنٹ ڈیکوڈ کیے جاتے ہیں اس طرح کہ انبوہ اور نرم طریقے سے معاملہ فیصلہ کا انتخاب کریں۔ ایک مشترک کلاسیٹر سورس کے اکنود دکھانے اور لابل پر آموزش کی جاتی ہے، اور موقع کا اکنود دکھانے پر لازم کیا جاتا ہے. ہم اس طرح مخالف تعلیم کے ذریعے انتقال کے ذریعے مطمئن کر رہے ہیں تاکہ اس طرح کوڈ دکھانے کے مطابق، سٹ کے مطابق، منظور-غیر غیر غیر غیر غیر غیر غ آزمائش کے نتائج دکھاتے ہیں کہ ہمارا طریقہ دو ڈاٹ سٹ پر مختلف بنسس لین اور موڈل الفائریٹ کام کرتا ہے، جو ایک پٹولوژی ڈاٹ سٹ پر 27% کی سوداگری کرتا ہے اور 5% کی روشن ڈاٹ سٹ پر۔', 'sv': 'Vi introducerar en neural metod för överföring av lärande mellan två (källa och mål) klassificeringsuppgifter eller aspekter inom samma domän. Istället för att träna på måletiketter använder vi några nyckelord som rör källa- och målaspekter som indikerar meningsrelevans istället för dokumentklassetiketter. Dokument kodas genom att lära sig att bädda in och mjukt välja relevanta meningar på ett aspektberoende sätt. En delad klassificerare utbildas i källkodade dokument och etiketter och tillämpas på målkodade dokument. Vi säkerställer överföring genom aspekt-adversary utbildning så att kodade dokument, som uppsättningar, är aspekt-invariant. Experimentella resultat visar att vårt tillvägagångssätt överträffar olika baslinjer och modellvarianter på två datauppsättningar, vilket ger en förbättring på 27% på ett patologidataset och 5% på ett granskningsdataset.', 'uz': "Biz ikkita (manba va qanday) darajalashtirish vazifalarni yoki bitta domen bilan o'rganish uchun neyural usulini koʻrsatimiz. Hujjatning sinf tugmalarini oʻzgartirish uchun bir necha tugmalar soʻzni ishlatamiz. Name @ info: whatsthis Kodlash hujjatlari, parametrlar, qismga kiruvchi kabi. Tekshirish natijalari bilan bir ikki maʼlumot tarkibidagi boshqa asosiy va model varianlarini bajaradi, bu patolog maʼlumotlari sohasida 27% bajarish va 5% taʼminlovchi maʼlumotlar sohasida bajaradi.", 'vi': 'Chúng tôi nhập một phương pháp thần kinh để học cách truyền tải giữa hai nhiệm vụ phân loại (nguồn và mục tiêu) hoặc các khía cạnh trên cùng một miền. Thay vì tập luyện trên nhãn mục tiêu, chúng tôi sử dụng vài từ khoá liên quan đến nguồn và các khía cạnh đích chỉ ra sự liên quan đến bản án thay vì nhãn lớp tài liệu. Các tài liệu được mã hóa bằng cách học cách tác hợp và nhẹ nhàng chọn những câu liên quan theo cách nhân biến. Một người phân loại được huấn luyện trên nguồn tài liệu và nhãn được mã hóa và được áp dụng cho những tài liệu đã mã hóa. Chúng tôi đảm bảo việc chuyển giao qua hình thức đối thủ để các tài liệu bị mã hóa không xâm phạm. Kết quả thí nghiệm cho thấy phương pháp của chúng ta hoàn thiện các bản mẫu khác nhau và biến thể mô hình trên hai tập tin, cho thấy sự cải tiến của gần 277.', 'bg': 'Въвеждаме невронен метод за трансферно обучение между две (източник и цел) класификационни задачи или аспекти в една област. Вместо обучение по целеви етикети, ние използваме няколко ключови думи, отнасящи се до източника и целевите аспекти, показващи релевантността на изречението вместо етикетите на класа на документи. Документите се кодират, като се научат да вграждат и меко избират съответните изречения в зависимост от аспекта начин. Споделен класификатор се обучава за кодираните документи и етикети на източника и се прилага за целеви кодирани документи. Осигуряваме трансфер чрез аспектно-съперническо обучение, така че кодираните документи да са, като комплекти, аспектно инвариращи. Експерименталните резултати показват, че нашият подход превъзхожда различните базови линии и варианти на модела на два набора от данни, като дава подобрение от 27% при набор от данни за патологията и 5% при набор от данни за преглед.', 'hr': 'Predstavljamo neuralnu metodu za učenje prijenosa između dva (izvora i cilja) klasifikacijskih zadataka ili aspekta u istom domenu. Umjesto obuke ciljnih etiketa, koristimo nekoliko ključnih riječi o izvoru i ciljnim aspektima koji ukazuju na relevantnost rečenica umjesto etiketa klase dokumenta. Dokumenti su kodirani učeći uključiti i meko odabrati relevantne rečenice na način ovisnog o aspektu. Podijeljeni klasifikator je obučen na kodiranim dokumentima i etiketama izvora i primjenjen na ciljne kodirane dokumente. Mi osiguravamo prijenos kroz aspekt-adversarnu obuku kako bi kodirani dokumenti, kao setovi, bili invarični aspekti. Eksperimentalni rezultati pokazuju da naš pristup iznosi različite osnovne linije i modelne varijante na dvije datasete, koji pružaju poboljšanje od 27% na setu patoloških podataka i 5% na setu podataka za pregled.', 'de': 'Wir führen eine neuronale Methode zum Transferlernen zwischen zwei (Quell- und Ziel-) Klassifizierungsaufgaben oder Aspekten über die gleiche Domäne ein. Anstatt auf Zieletiketten zu trainieren, verwenden wir einige Schlüsselwörter, die sich auf Quell- und Zielaspekte beziehen, die die Satzrelevanz anstelle von Dokumentenklassenbeschriftungen anzeigen. Dokumente werden verschlüsselt, indem man lernt, relevante Sätze aspektabhängig einzubetten und sanft auszuwählen. Ein gemeinsam genutzter Klassifikator wird auf die quellencodierten Dokumente und Etiketten geschult und auf Ziel-codierte Dokumente angewendet. Wir stellen den Transfer durch aspect-adversarial Training sicher, so dass verschlüsselte Dokumente als Sets aspect-invariant sind. Experimentelle Ergebnisse zeigen, dass unser Ansatz verschiedene Baselines und Modellvarianten auf zwei Datensätzen übertrifft, was zu einer Verbesserung von 27% auf einem Pathologiedatensatz und 5% auf einem Übersichtsdatensatz führt.', 'id': 'Kami memperkenalkan metode saraf untuk transfer belajar antara dua tugas klasifikasi (sumber dan sasaran) atau aspek di domain yang sama. Daripada berlatih pada label sasaran, kami menggunakan beberapa kata kunci yang berkaitan dengan aspek sumber dan sasaran yang menunjukkan relevansi kalimat daripada label kelas dokumen. Dokumen dikodeksi dengan belajar untuk memasukkan dan lembut memilih kalimat relevan dalam cara tergantung aspek. Klasifikator berbagi dilatih pada dokumen dan label yang dikodeksi sumber, dan diterapkan pada dokumen yang dikodeksi sasaran. We ensure transfer through aspect-adversarial training so that encoded documents are, as sets, aspect-invariant.  Hasil eksperimen menunjukkan bahwa pendekatan kita melebihi garis dasar dan varian model yang berbeda pada dua set data, memberikan peningkatan 27% pada set data patologi dan 5% pada set data revisi.', 'ko': '우리는 같은 분야의 두 가지 (원과 목표) 분류 임무나 방면 간에 전이 학습을 하는 신경 네트워크 방법을 소개했다.우리는 문서류 라벨이 아니라 원본과 목표와 관련된 키워드를 사용하여 문장의 관련성을 나타낸다.문서는 관련 문장을 방면으로 삽입하고 소프트 선택해서 인코딩하는 것을 배운다.공유 분류기는 원본 인코딩 문서와 라벨에 따라 훈련을 하고 목표 인코딩 문서에 적용됩니다.우리는 방면 대항 훈련을 통해 전송을 확보하는데, 이렇게 인코딩된 문서는 집합으로서 방면이 변하지 않는다.실험 결과에 의하면 우리의 방법은 두 데이터 집합에서 서로 다른 기선과 모델 변수보다 우수하고 병리학 데이터 집합과 회고 데이터 집합에서 각각 27%와 5% 증가했다.', 'nl': 'We introduceren een neurale methode voor transfer learning tussen twee (bron en doel) classificatietaken of aspecten over hetzelfde domein. In plaats van te trainen op doellabels, gebruiken we een paar trefwoorden die betrekking hebben op bron- en doelaspecten die duiden op zinsrelevantie in plaats van documentclasslabels. Documenten worden gecodeerd door relevante zinnen te leren insluiten en zachtjes te selecteren op een aspect-afhankelijke manier. Een gedeelde classificator wordt getraind op de brongecodeerde documenten en labels en toegepast op doelgecodeerde documenten. We zorgen voor overdracht door middel van aspect-contrarial training, zodat gecodeerde documenten als sets aspect-invariant zijn. Experimentele resultaten tonen aan dat onze aanpak beter presteert dan verschillende baselines en modelvarianten op twee datasets, wat resulteert in een verbetering van 27% op een pathologie dataset en 5% op een review dataset.', 'fa': 'ما یک روش عصبی برای تعلیم یادگیری بین دو (منبع و هدف) کارهای مختلف یا منبع در یک دامنه معرفی می\u200cکنیم. به جای آموزش بر برچسب\u200cهای هدف، ما از چند کلمه کلیدی استفاده می\u200cکنیم که مربوط به منبع و نقطه\u200cهای هدف نشان می\u200cدهند که تعلق جمله به جای برچسب\u200cهای کلاس سند است. سند\u200cها با یاد گرفتن برای وارد کردن و به نرم برگزیدن جمله\u200cهای مربوط به طریق بستگی به عنوان منطقه رمز می\u200cشوند. یک راهنمایی مشترک روی سند و برچسب\u200cهای منبع رمزگذاری شده آموزش داده می\u200cشود و برای سند رمزگذاری هدف کاربرد می\u200cشود. ما مطمئن می\u200cکنیم که از طریق تمرین\u200cهای مخالف و مخالف تغییر دهیم تا مدارک\u200cهای رمزگذاری، به عنوان مجموعه\u200cها، بی\u200cنیازمند باشند. نتیجه\u200cهای تجربه\u200cی ما نشان می\u200cدهند که دستور ما خط\u200cهای بنیادی و مدل\u200cهای مختلف را در دو مجموعه داده\u200cها انجام می\u200cدهد، با توجه به 27 درصد توسط یک مجموعه داده\u200cهای بیماری و 5 درصد توسط یک مجموعه داده\u200cهای تحقیق می', 'da': 'Vi introducerer en neural metode til overførsel af læring mellem to (kilde og mål) klassifikationsopgaver eller aspekter over samme domæne. I stedet for at træne i måletiketter bruger vi et par søgeord vedrørende kilde- og målaspekter, der angiver sætningsrelevans i stedet for dokumentklasse etiketter. Dokumenter kodes ved at lære at integrere og blødt vælge relevante sætninger på en aspektafhængig måde. En delt klassificering trænes i kildekodede dokumenter og etiketter og anvendes på målkodede dokumenter. Vi sikrer overførsel gennem aspekt-adversial træning, så kodede dokumenter, som sæt, er aspekt-invariant. Eksperimentelle resultater viser, at vores tilgang overgår forskellige baselines og modelvarianter på to datasæt, hvilket giver en forbedring på 27% på et patologidatasæt og 5% på et review datasæt.', 'sq': 'Ne futim një metodë nervore për transferimin e mësimit midis dy detyrave klasifikuese (burimi dhe objektivi) apo aspekteve në të njëjtin fushë. Në vend të trajnimit në etiketat objektive, ne përdorim disa fjalë kyçe lidhur me aspektet burimi dhe objektivi që tregojnë rëndësinë e fjalëve në vend të etiketave të klasës së dokumenteve. Dokumentet janë koduar duke mësuar të përfshijnë dhe të zgjedhin lehtë fjalët e duhura në një mënyrë të varur nga aspekti. A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents.  Ne sigurojmë transferimin nëpërmjet stërvitjeve kundërshtare në mënyrë që dokumentet e koduar të jenë, si grupe, aspekte-invazive. Experimental results demonstrate that our approach outperforms different baselines and model variants on two datasets, yielding an improvement of 27% on a pathology dataset and 5% on a review dataset.', 'sw': 'Tunaonyesha njia ya kidini ya kuhamisha kujifunza kati ya kazi mbili za usambazaji (chanzo na lengo) au mambo katika eneo hilo hilo. Badala ya mafunzo kwenye alama za malengo, tunatumia maneno machache yanayohusiana na vyanzo na mambo yanayolenga kuonyesha umuhimu wa hukumu badala ya alama za tabaka la nyaraka. Makala yanajumuishwa na kujifunza kuingia na kuchagua sentensi muhimu kwa namna inayotegemea. Mfanuzi wa usambazaji unafundishwa kwenye chanzo cha habari kinachojumuisha nyaraka na mabango, na kutumika kwa ajili ya nyaraka zilizowekwa. Tunaweza kuhakikisha kuhamisha kupitia mafunzo yanayotokana na upinzani ili kuweka nyaraka zilizojumuisha ni, kama seti, kwa upande wa uvamiaji. Matokeo ya majaribio yanaonyesha kwamba mbinu yetu inafanya tofauti tofauti na mabadiliko ya mifano kwenye seti mbili za data, na kusababisha maboresho ya asilimia 27 kwenye seti ya taarifa za patology na asilimia 5 kwenye seti ya tafiti za data.', 'tr': 'Biz iki (çeşme we maksady) klasifikasyon zady ýa-da aspektler arasynda öwrenmek üçin näyral yöntemi bir domenyň içine alýarys. Mazmunlar etiketlerde eğlenmek ýerine, çeşme we maksady aspektlerde sözlem metini sened klas etiketleriň ýerine görkezilýän birnäçe a ç sözleri ulanýarys. Senedler içeri girdirmek üçin öwrenmek üçin ködlenýär we ýumursyz sözleriň baglany şeklinde saýlamak üçin. A ýratyn kodlanmış senedler we etitler üzerinde ýazylşyrlybdyr we maksady kodlanmış senedler üçin ullanylýar. Biz aspekt-täsirli okuwçylary tarapyndan geçirmeleri garaşýarys şonuň üçin ködlemeler, sahypa-täsirli sened edilsin. Testeniýa netijeleri biziň metodamyz iki datasetede farklı baz hatlary we modelleriň üýtgeşmelerini çykarýandygyny görkez, patologiýa veri setinde 27% gelişmeleri we çykyş setinde 5%.', 'hy': 'Մենք ներկայացնում ենք նյարդային մեթոդ ուսումնասիրության փոխանցման երկու (աղբյուր և նպատակային) դասակարգման առաջադրանքների կամ նույն ոլորտի ասպեկտների միջև: Փոխարենը նպատակային պիտակների ուսումնասիրությունը, մենք օգտագործում ենք մի քանի բառ, որը կապված է աղբյուրի և նպատակային ասպեկտների հետ, որոնք ցույց են տալիս նախադասությունների կարևորությունը փաստաթղթերի դասարանի պիտակնե Տեսագրերը կոդավորվում են սովորելով ներառել և թեթև ընտրել համապատասխան նախադասությունները ասպեկտմամբ կախված կերպով: A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents.  Մենք վստահում ենք փոխանցումը հակառակ ասպեկտների ուսումնասիրության միջոցով, որպեսզի կոդավորված փաստաթղթերը, ըստ հատվածների, լինեն տարբեր ասպեկտների: Experimental results demonstrate that our approach outperforms different baselines and model variants on two datasets, yielding an improvement of 27% on a pathology dataset and 5% on a review dataset.', 'af': "Ons introduseer 'n neurale metode vir oordrag leer tussen twee (bron en doel) klassifikasie taak of aspekte oor dieselfde domein. In plaas as onderwerp op doel etikette, gebruik ons 'n paar sleutelwoorde wat betref bron en doel aspekte wat die setrelevansie indiek in plaas van dokumentklas etikette. Dokumente word gekodeer deur te leer om te inbêer en sagtig te kies relevante teikens in 'n aspek- afhanklik manier. 'n Gedeelde klassifiseerder is opgelei op die bron gekodeerde dokumente en etikette, en toewend na doel enkodeerde dokumente. Ons verseker oordrag deur aspekt-teenstandaar onderwerp sodat kodeerde dokumente, soos stel, aspekt-invariant is. Eksperimentale resultate bevestig dat ons toegang verskillende basis lyne en model variante uitvoer op twee datastelle, wat 'n verbetering van 27% op 'n patologie datastel en 5% op 'n hersieningsdata.", 'bn': 'আমরা দুই (উৎস এবং লক্ষ্য) ক্লাস্ফিকেশন কাজ অথবা একই ডোমেইনের বিষয়ের মধ্যে শিক্ষা পরিবর্তনের জন্য নিউরেল পদ্ধতি চিহ্নিত করি। টার্গেট লেবেলের প্রশিক্ষণের পরিবর্তে আমরা সূত্র এবং লক্ষ্যের বিষয়ে কিছু কীবোর্ড ব্যবহার করি যা নথিপত্রের ক্লাসের লেবেলের বদলে ব প্রাক্তন নির্ভর করে প্রাপ্ত বাক্য নির্ধারিত ভাবে প্রসঙ্গিক বাক্য নির্বাচন করার শিক্ষা দ্বারা নথিগুলো এ A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents.  আমরা প্রতিপক্ষ-বিরোধী প্রশিক্ষণের মাধ্যমে পরিবর্তন নিশ্চিত করি যাতে এনকোডিং ডকুমেন্টগুলো প্রতিক্রিয়ার হিসেবে  পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের প্রতিযোগিতা দুই ডাটাসেটে ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন', 'az': 'Biz iki (mənbə və məqsəd) klasifikasiya işləri və ya aspektləri arasında öyrənmək üçün nöral metodları təşkil edirik. Heç etiketlərin təhsil edilməsindən əvəzinə, bir neçə anahtar sözlərini mənbə və məqsəd aspektlərinə istifadə edirik ki, cümlələr dəstə etiketlərinin yerini göstərən məqsəd etiketlərini göstərir. Dökümətlər ünvanlı cümlələrdən istifadə etmək və yumuşaqlı seçmək üçün kodlandırılır. Bölüşülmüş klasifikatçı kodlanmış səhifələr və etiketlər üzərində təhsil edilir və məqsəd kodlanmış belələrə istifadə edilir. Biz aspekt-düşmənçilik təhsil vasitəsilə keçirməyi təmin edirik ki, kodlanmış dökümələr, qurğular kimi, aspect-invariant olarlar. Experimental sonuçları göstərir ki, bizim tərzimiz iki veri qurularında müxtəlif baz çətinlərini və modellərini daha yaxşılaşdırır, patolojik veri qurularında 27%-dən daha yaxşılaşdırır və dərhal veri qurularında 5%.', 'cs': 'Představujeme neuronovou metodu přenosu učení mezi dvěma (zdrojovými a cílovými) klasifikačními úkoly nebo aspekty ve stejné oblasti. Namísto školení na cílových štítkách používáme několik klíčových slov týkajících se zdrojových a cílových aspektů, které ukazují relevanci vět namísto popisků tříd dokumentů. Dokumenty jsou kódovány učením se vkládat a jemně vybírat relevantní věty způsobem závislým na aspektu. Sdílený klasifikátor je školen na zdrojové kódované dokumenty a štítky a aplikován na cílové kódované dokumenty. Zajišťujeme přenos prostřednictvím aspect-adversariálního školení tak, aby kódované dokumenty byly jako sady aspect-invariantní. Experimentální výsledky ukazují, že náš přístup překonává různé základní linie a modelové varianty na dvou datových sadách, což vede ke zlepšení 27% u patologického datového souboru a 5% u recenzního datového souboru.', 'am': 'በሁለቱ (ምንጭ እና አጉዳዩ) ክፍል ስራዎችን ወይም በአንድ ዶሜን ላይ ለመለወጥ የሚችሉትን የኒጀር ሥርዓት እናሳውቃለን፡፡ በአካባቢው ምልክቶች ላይ ከማስተምር በቀር፣ ከሰነድ ክፍል ምልክቶች ፋንታ ቃላትን ማሳየት እና ማሰቃየትን እናስቀምጣለን፡፡ ሰነዱን በመግለጽ እና በዝግታ የግንኙነት ቃላት በመምረጥ በይፋ በመታሰል ይክፈዋል። ፋይል sን መክፈት አልቻለም፦ %s፦ %s አካባቢ-ተቃዋሚ ትምህርት ማድረግ እንዲያረጋግጠን ሰነዱን እንደ ተቃውሞ አካባቢ እናደርጋለን፡፡ ፈተና ፍሬዎች የሁለት ዳታተሮች ላይ የተለየ መሳሪያ እና የሞዴል መለያየት እንዲያሳየው፣ የ27 በመቶ የፖለቲology ዳታተር ማድረጊያውን እና 5 በመቶ በመቶ በመጠየቂያ ዳታተር ማድረጊያውን የሚያሳውቅ ነው፡፡', 'bs': 'Predstavljamo neuralnu metodu za učenje prijenosa između dva (izvora i cilja) klasifikacije ili aspekta u istom domenu. Umjesto obuke na ciljnim etiketama, koristimo nekoliko ključnih riječi u vezi izvora i ciljnih aspekta koji ukazuju na relevantnost rečenica umjesto etiketa klase dokumenta. Dokumenti su kodirani učenjem da uključimo i meko odaberemo relevantne rečenice na način na koji ovisi o aspektu. Podijeljeni klasifikator je obučen na kodiranim dokumentima i etiketama izvora i primjenjen na ciljne kodirane dokumente. Mi osiguravamo prijenos kroz aspekt-neprijateljsku obuku tako da su kodirani dokumenti, kao setovi, neprijatelji aspekta. Eksperimentalni rezultati pokazuju da naš pristup iznosi različite osnovne linije i modelne varijante na dva dataset a, koji pružaju poboljšanje od 27% na setu patoloških podataka i 5% na setu podataka za pregled.', 'et': 'Tutvustame neuromeetodit siirdeõppeks kahe (lähte- ja sihtülesande) või aspekti vahel samas valdkonnas. Sihtmärkide koolitamise asemel kasutame dokumendiklassi siltide asemel mõningaid märksõnu, mis on seotud lähte- ja sihtmärkide aspektidega, mis näitavad lause asjakohasust. Dokumendid kodeeritakse, õppides manustama ja pehmelt valima asjakohaseid lauseid aspektist sõltuval viisil. Ühisklassifitseerijat koolitatakse lähtekodeeritud dokumentide ja siltide kohta ning rakendatakse sihtkodeeritud dokumentide suhtes. Me tagame ülekande läbi aspekti-vastase koolituse nii, et kodeeritud dokumendid on komplektidena aspekti-invariant. Eksperimentaalsed tulemused näitavad, et meie lähenemisviis ületab erinevaid lähtejooni ja mudelivariante kahe andmekogumi puhul, parandades patoloogia andmekogumi puhul 27% ja läbivaatamisandmekogumi puhul 5%.', 'fi': 'Esittelemme neuromenetelmän kahden (lähde- ja kohdetason) luokittelutehtävän tai saman toimialueen näkökulman väliseen siirtooppimiseen. Kohdelaitteita koskevan koulutuksen sijaan käytämme muutamia avainsanoja, jotka liittyvät lähde- ja kohdenäkökohtiin, jotka osoittavat lauseen merkityksen asiakirjaluokkamerkintöjen sijaan. Dokumentit koodataan oppimalla upottamaan ja valitsemalla pehmeästi relevantteja lauseita näkökulmista riippuvalla tavalla. Jaettua luokittelijaa koulutetaan lähdekoodatuista asiakirjoista ja etiketeistä, ja sitä käytetään koodattujen asiakirjojen kohdentamiseen. Varmistamme siirron aspekti-adversariaalisen koulutuksen kautta siten, että koodatut asiakirjat ovat kokonaisuuksina aspekti-invariantteja. Kokeelliset tulokset osoittavat, että lähestymistapamme suoriutuu paremmin kuin eri lähtö- ja mallivariantit kahdessa aineistossa, tuottaen 27% parannusta patologisessa aineistossa ja 5% tarkistusaineistossa.', 'ca': "Introduïm un mètode neural per transferir l'aprenentatge entre dues tasques de classificació (fonts i objectius) o aspectes sobre el mateix domini. En comptes d'entrenar en etiquetes d'objectiu, utilitzem unes quantes paraules clau relacionades amb aspectes d'origen i d'objectiu que indiquen la pertinencia de frases en comptes d'etiquetes de classe de documents. Documents are encoded by learning to embed and softly select relevant sentences in an aspect-dependent manner.  Un classificador compartit s'entrena en documents codificats i etiquetes de fonts i s'aplica a documents codificats destinataris. We ensure transfer through aspect-adversarial training so that encoded documents are, as sets, aspect-invariant.  Els resultats experimentals demostren que el nostre enfocament supera les diferents línies de base i variants models en dos conjunts de dades, produint una millora del 27% en un conjunt de dades de patologia i del 5% en un conjunt de dades de revisió.", 'jv': 'We insert a Neral method for transfer Learning amongst 2 (source and goal) category tasks or Aspects about the same domain. @title: window politenessoffpolite"), and when there is a change ("assertivepoliteness email-custom-header-Security Anyone EMAIL OF TRANSLATORS', 'sk': 'Predstavljamo nevronsko metodo za prenosno učenje med dvema (izvornim in ciljnim) klasifikacijskima nalogama ali vidikom na istem področju. Namesto usposabljanja o ciljnih oznakah uporabljamo nekaj ključnih besed, ki se nanašajo na izvorne in ciljne vidike, ki označujejo ustreznost stavka namesto oznak razreda dokumenta. Dokumenti so kodirani tako, da se naučijo vdelati in nežno izbirati ustrezne stavke na način, odvisen od vidika. Razvrščevalec v skupni rabi je usposobljen za izvorno kodirane dokumente in oznake ter uporabljen za ciljanje kodiranih dokumentov. Zagotavljamo prenos skozi aspektivno kontradiktorsko usposabljanje, tako da so kodirani dokumenti, kot sklopi, vidikovno invariantni. Eksperimentalni rezultati kažejo, da naš pristop presega različne izhodiščne linije in variante modela na dveh naborih podatkov, kar prinaša 27-odstotno izboljšanje pri naboru podatkov o patologiji in 5-odstotno izboljšanje pri naboru podatkov o pregledu.', 'he': 'אנחנו מציגים שיטה עצבית להעברה לימוד בין שתי משימות (מקור ומטרה) מסווג או היבטים על אותו תחום. במקום להתאמן על תוויות המטרה, אנחנו משתמשים בכמה מילים מפתחות שייכות למקור ובהיבטים המטרה שמצביעים על רלוונטיות משפטים במקום תוויות מסמכים. מסמכים מוצפנים על ידי לימוד להכניס ולבחר בעדינות משפטים רלוונטיים באופן תלוי באפקטים. מסגר משותף מאומן על מסמכים וקודדים המקורים, ומשתמש על מסמכים מקודדים. אנו מאבטחים העברה באמצעות אימונים נוגדיים כדי שמסמכים מוצפנים יהיו, כמו קבוצות, שונים. תוצאות ניסיוניות מראות שהגישה שלנו מעלית שונות בסיסיים ומודלים שונים בשני קבוצות נתונים, מה שמביא שיפור של 27% על קבוצת נתונים פתולוגית ו-5% על קבוצת נתונים ביקורת.', 'ha': "Mu ƙara wata hanyon neura wa ka motsa wa zane-zane a tsakanin aikin su biyu (kwance da shiryoyin ayuka) ko masu sakan kayan su sami guda. Babu yin amfani da wasu kalmõmi masu amfani da kuma masu amfani da sunayen alama na tagan, masu da amfani da wasu kalmõmi masu hususan na source da alama masu amfani da shi idan an nuna muhimmin maganar da ba'a rubutun sunaye na takardar. Ana kodi takardun aiki da aka sanar da za'a ƙunsa da kuma a zãɓi sauri masu husũma da takardar-daban-daban. An sanar da wani mai raba fasafi a kan source kodi na takardun kodi da alama, kuma an yi amfani da shi zuwa takardun kodi na gabatar da. Ina yarda da in shige kode takardar da za'a yi amfani da shi a cikin kwanan-motsi, don haka kuma idan an kodi takardun su zama, kamar daidaita da-sura. Matarin jarrabai ya nuna cewa hanyoyinmu ke fitar bambanci masu daban-daban da motel-daban a kan danne-biyu, yana ƙara koda 27% a kan danne-bayani na hanyoyi da 5% a kan kanana bayani.", 'bo': 'ང་ཚོས་དབྱིབས་མཐུན་སྣེ་གཉིས་དབྱིབས་བྱ་རིམ་དང་རྒྱུ་མཚན་གཉིས་དབྱིབས་དབྱིབས་མཐུན་གྱི་ཐབས་ལམ་སྟོན་བྱེད་ཀྱི་ཡོད། Rather than training on target labels, we use a few keywords pertaining to source and target aspects indicating sentence relevance instead of document class labels. ཡིག་གེ A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents. འུ་ཅག་གིས་འདུས་ཀྱི་གནད་དོན་འགའ་བློ་གཏོང་གི་ནང་དུ་ཡིག་ཆ་གསང་པོ་ཡིན་པ་ལྟར་བཤད་ཀྱི་ཡོད། Experimental Results demonstrate that our approach performs different baselines and model variants on two datasets. This leads to an improvement of 27% in a pathology dataset and 5% in a review dataset.'}
{'en': 'Anchored Correlation Explanation : Topic Modeling with Minimal Domain Knowledge', 'ar': 'شرح الارتباط الراسخ: نمذجة الموضوع مع الحد الأدنى من المعرفة بالمجال', 'pt': 'Explicação da Correlação Ancorada: Modelagem de Tópicos com Conhecimento Mínimo de Domínio', 'es': 'Explicación de la correlación anclada: modelado de temas con un conocimiento mínimo del dominio', 'fr': 'Explication de la corrélation ancrée\xa0: modélisation de sujets avec une connaissance minimale du domaine', 'ja': 'アンカー相関の説明：最小限のドメイン知識によるトピックモデリング', 'zh': '锚定相关性说:用最少之域,主题建模', 'ru': 'Объяснение привязанной корреляции: моделирование темы с минимальными знаниями в области', 'hi': 'Anchored सहसंबंध स्पष्टीकरण: न्यूनतम डोमेन ज्ञान के साथ विषय मॉडलिंग', 'ga': 'Míniú ar Chomhghaol Ancaire: Samhaltú Ábhair le hEolas ar Fhearann Íosta', 'hu': 'Horgonyzott korreláció Magyarázat: Téma modellezés minimális domain ismeretekkel', 'el': 'Εξήγηση αγκυροβολημένης συσχέτισης: Μοντελοποίηση θέματος με ελάχιστη γνώση τομέα', 'it': 'Spiegazione: Modellazione degli argomenti con conoscenza minima del dominio', 'kk': 'Тіркелген түзету түсініктемесі: Минималдық домен білімімен нақышты үлгілеу', 'lt': 'Susietas koreliacijos paaiškinimas: Temos modeliavimas su minimaliomis žiniomis apie sritį', 'ms': 'Penjelasan Korelasi Terikat: Modelan Topik dengan Pengetahuan Domain Minimal', 'ml': 'തെരഞ്ഞെടുത്ത കോര്\u200dബന്ധത്തിന്റെ എക്സ്പ്ലാനേഷന്\u200d: കുറഞ്ഞ മോഡല്\u200d ഡോമെയിന്\u200d അറിവുമുള്ള പ്രമേയം', 'mt': 'Spjegazzjoni ta’ Korelazzjoni Anchored: Mudellar Topiku b’Għarfien Minimu tad-Dominju', 'mn': 'Төгсгөл сайжруулах тодорхойлолт: Багахан домайн мэдлэгтэй тодорхойлолт', 'mk': 'Anchored Correlation Explanation: Topic Modeling with Minimal Domain Knowledge', 'no': 'Ankorrigeringsforklaring: Emne- modellering med minimal kjenning av domene', 'ka': 'კონფორური კოლეციაცია: მინიმალური დომენის მეცნიერებით ტემიკური მოდელირება', 'ro': 'Explicație: Modelarea subiectelor cu cunoștințe minime de domeniu', 'sr': 'Објаснено исправљање: модел теме са минималним знањем домена', 'si': 'ඇන්කෝර්ඩ් සුදුසුම් ප්\u200dරශ්නයක්: ප්\u200dරශ්නයක් ප්\u200dරශ්නයක්: ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් අඩුම', 'sv': 'Förklaring: Ämnesmodellering med minimal domänkunskap', 'so': 'Anchored Correlation Explanation: Topic Modeling with Minimal Domain Knowledge', 'ta': 'தேர்ந்தெடுக்கப்பட்ட தொடர்பு வெளியீடு: குறைந்தபட்ச களம் அறிவுடன் மாற்றுதல்', 'pl': 'Wyjaśnienie zakotwiczonej korelacji: Modelowanie tematów z minimalną wiedzą o domenie', 'ur': 'اضطراب اصلاح کا پتفصیل: کم ڈومین علم کے ساتھ موضوع موڈلینگ', 'uz': 'Name', 'vi': 'Giải thích liên tục: Chế độ theo chủ đề với kiến thức miền nhỏ.', 'bg': 'Обяснение за анкерирана корелация: Моделиране на теми с минимално познание за домейна', 'nl': 'Verankerde correlatie Verklaring: Topic Modeling met minimale domeinkennis', 'hr': 'Objašnjenje usklađene korelacije: Modeliranje teme s minimalnim znanjem domena', 'da': 'Forklaring: Emnemodellering med minimal domæne viden', 'de': 'Verankerte Korrelationserklärung: Themenmodellierung mit minimalem Domänenwissen', 'id': 'Penjelasan Korelasi Terikat: Modeling Topik dengan Pengetahuan Domain Minimal', 'ko': '앵커 관련 해석: 영역 지식이 가장 적은 주제 모델링', 'sw': 'Tamko la Uhusiano: Maudhui yenye ufahamu wa Kidogo', 'sq': 'Shpjegim i lidhjes së ankoruar: Modelimi i temës me njohuri minimale të domenit', 'fa': 'توضیح اصلاح متصل: مدل موضوع با دانش minimal Domain', 'af': 'Enkorrigeerde Verduideling: Onderwerp Modelering met Minimale Domein kennis', 'tr': 'Eskiden Düzeltme Taýýarlama: Azak Aýik Bilim bilen Tema Modeli', 'am': 'ምርጫዎች', 'hy': 'Կոռելացված հաղորդակցման բացատրություն. թեմային մոդելավորումը մինիմալ տիեզերքի գիտելիքներով', 'bn': 'নির্বাচিত কর্মেন্ট এক্সপ্ল্যানেশন: সর্বনিম্ন ডোমেইন জ্ঞানের সাথে বিষয় মডেলিং', 'az': 'Anchored Correction Explanation: Minimal Domain Knowledge Topic Modeling', 'bs': 'Apkorirano korelacijsko objašnjenje: Modeliranje teme sa minimalnim znanjem domena', 'et': 'Ankru korrelatsiooni selgitus: teemade modelleerimine minimaalse domeeniteadmisega', 'fi': 'Ankkuroitu korrelaatio Selitys: Aihemallinnus minimaalisella verkkotunnuksella', 'ca': 'Explicació de correlació anclada: Modell de tòpics amb coneixement mínim de domini', 'cs': 'Vysvětlení ukotvené korelace: Modelování témat s minimálními znalostmi domény', 'jv': 'Ngubah Keterangan Keterangan: Temika model karo minimal domain knownMonitor', 'he': 'הסבר הקשר הקשור: מודל נושא עם ידע מינימלי של שטח', 'sk': 'Razlaga sidrane korelacije: Modeliranje teme z minimalnim znanjem domen', 'ha': 'KCharselect unicode block name', 'bo': 'Anchored Correlation Explanation: Subject Modeling with Minimal Domain Knowledge'}
{'en': 'While generative models such as Latent Dirichlet Allocation (LDA) have proven fruitful in topic modeling, they often require detailed assumptions and careful specification of hyperparameters. Such model complexity issues only compound when trying to generalize generative models to incorporate human input. We introduce Correlation Explanation (CorEx), an alternative approach to topic modeling that does not assume an underlying generative model, and instead learns maximally informative topics through an information-theoretic framework. This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional modeling assumptions. In particular, word-level domain knowledge can be flexibly incorporated within CorEx through anchor words, allowing topic separability and representation to be promoted with minimal human intervention. Across a variety of datasets, metrics, and experiments, we demonstrate that CorEx produces topics that are comparable in quality to those produced by unsupervised and semi-supervised variants of LDA.', 'ar': 'بينما أثبتت النماذج التوليدية مثل تخصيص Latent Dirichlet (LDA) أنها مثمرة في نمذجة الموضوع ، فإنها تتطلب غالبًا افتراضات مفصلة ومواصفات دقيقة للمعلمات الفائقة. تتعقد مشكلات تعقيد النموذج هذه فقط عند محاولة تعميم النماذج التوليدية لدمج المدخلات البشرية. نقدم شرح الارتباط (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation Explanation (Correlation (( يُعمم هذا الإطار بشكل طبيعي على الامتدادات الهرمية وشبه الخاضعة للإشراف مع عدم وجود افتراضات نمذجة إضافية. على وجه الخصوص ، يمكن دمج المعرفة بالمجال على مستوى الكلمات بمرونة في CorEx من خلال كلمات الربط ، مما يسمح بترويج إمكانية الفصل والتمثيل مع الحد الأدنى من التدخل البشري. عبر مجموعة متنوعة من مجموعات البيانات والمقاييس والتجارب ، نوضح أن CorEx تنتج موضوعات يمكن مقارنتها من حيث الجودة بتلك التي تنتجها المتغيرات غير الخاضعة للإشراف وشبه الإشراف لـ LDA.', 'es': 'Si bien los modelos generativos como la asignación de Dirichlet latente (LDA) han demostrado ser fructíferos en el modelado de temas, a menudo requieren suposiciones detalladas y una especificación cuidadosa de los hiperparámetros. Estos problemas de complejidad de los modelos solo se agravan cuando se trata de generalizar modelos generativos para incorporar el aporte humano. Presentamos la Explicación de Correlación (CoReX), un enfoque alternativo al modelado de temas que no asume un modelo generativo subyacente, sino que aprende temas de máxima información a través de un marco de teoría de la información. Este marco generaliza naturalmente a extensiones jerárquicas y semi-supervisadas sin suposiciones de modelado adicionales. En particular, el conocimiento del dominio a nivel de palabras se puede incorporar de manera flexible en CoReX a través de palabras de anclaje, lo que permite promover la separabilidad y la representación de los temas con una intervención humana mínima. A través de una variedad de conjuntos de datos, métricas y experimentos, demostramos que CoReX produce temas que son comparables en calidad a los producidos por variantes de LDA no supervisadas y semisupervisadas.', 'fr': "Bien que les modèles génératifs tels que l'allocation de Dirichlet latente (LDA) se soient révélés efficaces dans la modélisation thématique, ils nécessitent souvent des hypothèses détaillées et une spécification minutieuse des hyperparamètres. Ces problèmes de complexité des modèles ne font que s'aggraver lorsqu'on essaie de généraliser des modèles génératifs afin d'intégrer l'apport humain. Nous introduisons Correlation Explication (CoreX), une approche alternative à la modélisation de sujets qui ne suppose pas de modèle génératif sous-jacent, et qui apprend plutôt des sujets informatifs au maximum grâce à un cadre de théorie de l'information. Ce framework se généralise naturellement aux extensions hiérarchiques et semi-supervisées sans aucune hypothèse de modélisation supplémentaire. En particulier, les connaissances du domaine au niveau des mots peuvent être intégrées de manière flexible dans CoreX par le biais de mots d'ancrage, ce qui permet de promouvoir la séparabilité et la représentation des sujets avec une intervention humaine minimale. À travers une variété d'ensembles de données, de métriques et d'expériences, nous démontrons que CoreX produit des sujets d'une qualité comparable à ceux produits par des variantes non supervisées et semi-supervisées de LDA.", 'pt': 'Embora os modelos generativos, como a Alocação de Dirichlet Latente (LDA), tenham se mostrado frutíferos na modelagem de tópicos, eles geralmente exigem suposições detalhadas e especificação cuidadosa de hiperparâmetros. Tais problemas de complexidade de modelo só aumentam quando se tenta generalizar modelos generativos para incorporar a entrada humana. Apresentamos a Explicação de Correlação (CorEx), uma abordagem alternativa à modelagem de tópicos que não assume um modelo generativo subjacente e, em vez disso, aprende tópicos informativos ao máximo por meio de uma estrutura de teoria da informação. Essa estrutura se generaliza naturalmente para extensões hierárquicas e semi-supervisionadas sem suposições de modelagem adicionais. Em particular, o conhecimento de domínio em nível de palavra pode ser incorporado de forma flexível no CorEx por meio de palavras âncoras, permitindo que a separação e a representação de tópicos sejam promovidas com o mínimo de intervenção humana. Em uma variedade de conjuntos de dados, métricas e experimentos, demonstramos que a CorEx produz tópicos que são comparáveis em qualidade aos produzidos por variantes não supervisionadas e semisupervisionadas de LDA.', 'ja': '潜在ディリクレ割り当て（ LDA ）などの生成モデルは、トピックモデリングで実りあることが証明されているが、詳細な仮定とハイパーパラメータの慎重な指定が必要な場合が多い。 このようなモデルの複雑さは、人間の入力を取り入れるために生成モデルを一般化しようとするときにのみ問題となる。 基礎となる生成モデルを前提としないトピックモデリングの代替アプローチである相関説明（ Correlation Explanation ： COREx ）を導入し、代わりに情報理論の枠組みを通じて最大限に情報に富んだトピックを学習する。 このフレームワークは、追加のモデリングの仮定なしに、階層的および半監督的な拡張に自然に一般化します。 特に、単語レベルのドメイン知識は、アンカーワードを通じてCorEx内に柔軟に組み込むことができ、最小限の人間の介入でトピックの分離性と表現を促進することができます。 さまざまなデータセット、指標、および実験を通じて、CORExは、LDAの無監督および半監督のバリアントによって生成されたものと同等の品質のトピックを生成することを実証します。', 'zh': '虽潜于狄利克雷分(LDA)之类建模见于题富有成效,常须详假细超参数。 凡此诸复杂性,唯试广生成之,以入人输入乃复杂化。 引入相关性说(CorEx),此题建模之代法也,不假底以成形,而以息论框架学最大者也。 其框架自推至分层及半监扩,无额外建模假设。 单词知可以锚词生整合于CorEx,而以至少者为分离性。 凡诸数集、指标、实验,吾证 CorEx 所生之主,与 LDA 无监、半监变体所生相当。', 'hi': 'जबकि अव्यक्त Dirichlet आवंटन (LDA) जैसे उत्पादक मॉडल विषय मॉडलिंग में उपयोगी साबित हुए हैं, उन्हें अक्सर विस्तृत मान्यताओं और हाइपरपैरामीटर के सावधानीपूर्वक विनिर्देश की आवश्यकता होती है। इस तरह के मॉडल जटिलता के मुद्दे केवल यौगिक जब मानव इनपुट को शामिल करने के लिए उत्पादक मॉडल को सामान्यीकृत करने की कोशिश कर रहे हैं। हम सहसंबंध स्पष्टीकरण (CorEx) पेश करते हैं, जो विषय मॉडलिंग के लिए एक वैकल्पिक दृष्टिकोण है जो एक अंतर्निहित उत्पादक मॉडल को नहीं मानता है, और इसके बजाय एक सूचना-सैद्धांतिक ढांचे के माध्यम से अधिकतम जानकारीपूर्ण विषयों को सीखता है। यह ढांचा स्वाभाविक रूप से बिना किसी अतिरिक्त मॉडलिंग मान्यताओं के साथ पदानुक्रमित और अर्ध-पर्यवेक्षित एक्सटेंशन के लिए सामान्यीकृत करता है। विशेष रूप से, शब्द-स्तरीय डोमेन ज्ञान को लंगर शब्दों के माध्यम से CorEx के भीतर लचीलापन से शामिल किया जा सकता है, जिससे विषय पृथक्करण और प्रतिनिधित्व को न्यूनतम मानव हस्तक्षेप के साथ बढ़ावा दिया जा सकता है। विभिन्न प्रकार के डेटासेट, मीट्रिक और प्रयोगों में, हम प्रदर्शित करते हैं कि CorEx उन विषयों का उत्पादन करता है जो LDA के असुरक्षित और अर्ध-पर्यवेक्षित संस्करणों द्वारा उत्पादित गुणवत्ता में तुलनीय हैं।', 'ru': 'Хотя генеративные модели, такие как Latent Dirichlet Allocation (LDA), оказались плодотворными в моделировании тем, они часто требуют детальных допущений и тщательного определения гиперпараметров. Такая сложность модели только усугубляется при попытке обобщить генеративные модели, чтобы включить человеческий вклад. Мы вводим объяснение корреляции (CorEx), альтернативный подход к моделированию тем, который не предполагает базовую генеративную модель, а вместо этого изучает максимально информативные темы через информационно-теоретическую структуру. Эта структура, естественно, обобщает иерархические и полунадзорные расширения без дополнительных допущений моделирования. В частности, знание домена на уровне слов может быть гибко включено в CorEx с помощью якорных слов, что позволяет продвигать разделяемость и представление тем с минимальным вмешательством человека. В различных наборах данных, метриках и экспериментах мы демонстрируем, что CorEx производит темы, которые по качеству сопоставимы с теми, которые производятся неконтролируемыми и полуконтролируемыми вариантами LDA.', 'ga': 'Cé gur chruthaigh samhlacha giniúna cosúil le Leithdháileadh Dirichlet Folaigh (LDA) torthúil i samhaltú topaicí, is minic a éilíonn siad boinn tuisceana mionsonraithe agus sonraíocht chúramach hipearpharaiméadair. Ní thagann saincheisteanna castachta samhail den sórt sin chun cinn ach amháin nuair a dhéantar iarracht samhlacha ginearálaithe a ghinearálú chun ionchur daonna a ionchorprú. Tugaimid Míniú Comhghaolaithe (CorEx) isteach, cur chuige eile maidir le samhaltú topaicí nach nglactar leis go bhfuil bunsamhail ghiniúna ann, agus ina ionad sin a fhoghlaimíonn ábhair is mó faisnéiseach trí chreat faisnéise-theoiric. Déanann an creat seo ginearálú go nádúrtha chuig síntí ordlathacha agus leathmhaoirsithe gan aon toimhdí samhaltaithe breise. Go háirithe, is féidir eolas fearainn ar leibhéal focal a ionchorprú go solúbtha laistigh de CorEx trí fhocail ancaire, rud a fhágann gur féidir deighilt topaicí agus ionadaíocht a chur chun cinn le híosmhéid idirghabhála daonna. Thar raon tacair sonraí, méadracht agus turgnaimh éagsúla, léirímid go dtáirgeann CorEx topaicí atá inchomparáide ó thaobh cáilíochta leo siúd a tháirgtear trí athraithigh LDA gan mhaoirseacht agus leath-mhaoirseacht.', 'hu': 'Míg a generációs modellek, mint például a Latent Dirichlet Allocation (LDA) gyümölcsözőnek bizonyultak a téma modellezésében, gyakran részletes feltételezéseket és a hiperparaméterek gondos specifikációját igénylik. Az ilyen modellkomplexitási problémák csak akkor keverednek össze, amikor generációs modelleket próbálnak általánosítani az emberi beavatkozások beépítésére. Bemutatjuk a korrelációs magyarázatot (CorEx), egy alternatív megközelítést a téma modellezéséhez, amely nem feltételezi a mögöttes generációs modellt, hanem információelméleti keretrendszeren keresztül maximálisan informatív témákat tanul. Ez a keretrendszer természetesen hierarchikus és félig felügyelt kiterjesztésekre általánosít további modellezési feltételezések nélkül. Különösen a szószintű domain ismeretek rugalmasan beépíthetők a CorEx-be horgonyszavak segítségével, lehetővé téve, hogy a témák szétválaszthatóságát és reprezentációját minimális emberi beavatkozással előmozdítsák. A különböző adatkészleteken, metrikákon és kísérleteken keresztül bebizonyítjuk, hogy a CorEx olyan témákat készít, amelyek minőségükben hasonlóak az LDA felügyelet nélküli és félig felügyelet alatt álló változataival.', 'el': 'Ενώ τα παραγωγικά μοντέλα, όπως η κατανομή λανθάνουσας διρίκλετας (έχουν αποδειχθεί γόνιμα στη μοντελοποίηση θεμάτων, συχνά απαιτούν λεπτομερείς υποθέσεις και προσεκτική προδιαγραφή υπερπαραμέτρων. Τέτοια ζητήματα πολυπλοκότητας μοντέλων ενώθηκαν μόνο όταν προσπαθούν να γενικεύσουν τα παραγωγικά μοντέλα για να ενσωματώσουν την ανθρώπινη εισροή. Παρουσιάζουμε την Εξήγηση συσχέτισης (μια εναλλακτική προσέγγιση στη μοντελοποίηση θεμάτων που δεν υποθέτει ένα υποκείμενο γενετικό μοντέλο, αλλά μαθαίνει τα μέγιστα ενημερωτικά θέματα μέσα από ένα πληροφοριακό-θεωρητικό πλαίσιο. Αυτό το πλαίσιο γενικεύει φυσικά σε ιεραρχικές και ημιεποπτικές επεκτάσεις χωρίς πρόσθετες παραδοχές μοντελοποίησης. Ειδικότερα, η γνώση του τομέα σε επίπεδο λέξεων μπορεί να ενσωματωθεί ευέλικτα στο CorEx μέσω λέξεων αγκύρωσης, επιτρέποντας την προώθηση της διαχωρισιμότητας και της αναπαράστασης θεμάτων με ελάχιστη ανθρώπινη παρέμβαση. Σε μια ποικιλία συνόλων δεδομένων, μετρήσεων και πειραμάτων, καταδεικνύουμε ότι η CorEx παράγει θέματα που είναι συγκρίσιμα σε ποιότητα με αυτά που παράγονται από μη εποπτευμένες και ημιεποπτικές παραλλαγές LDA.', 'ka': 'მაგრამ განვითარებული მოდელები, როგორც Latent Dirichlet Allocation (LDA) ტემების მოდელეციაში გამოყენებულია, ისინი ზოგიერთად უნდა განვითარებული წარმოდგენები და დარწმუნელი განსაზღვრება ჰიპერომეტრი ასეთი მოდელური კომპლექსიტეტის პრობლემები მხოლოდ შემყვებულია, როდესაც უნდა გენერალიზაციოს მოდელები, რომ ადამიანის შეტყობინებას შე ჩვენ შევცვალობთ კორელაციის გამოსახულება (CorEx), ტემისტის მოდელის ალტენტიგური პროგრამა, რომელიც არ იყენებს ქვემოთ გენერაციული მოდელის მოდელის, და შემდეგ მაქსიმალურად ინფორმაციული ტემისტები ინფ ეს პარამეტრი ნართლად იერაქტიკური და ნახევართო დანარჩენებული გაფართლებისთვის, რომელიც არ აქვს დამატებული მოდელური დასაწყვება. განსაკუთრებით, სიტყვების დომინის ცნობიერება CorEx-ში შეიძლება გრძნობით ფრძნელი სიტყვებით, რომლებიც მინუს ადამიანის ინტერვანციით გაყოფილება და გამოსახულება შეიძლება მონაცემების, მეტრიკის და ექსპერიმენტების განსხვავებული განსხვავებულობით, ჩვენ გამოჩვენებთ, რომ CorEx გამოყენებს ტემები, რომლებიც LDA-ის განსხვავებულია, რომლებიც კვალეტში შემდგომარებულია, რო', 'kk': 'Соңғы дириклеттік бөлімі (LDA) секілді құрылған үлгілер нақышты моделдеу үшін маңызды болғанда, олар көбінде гиперпараметрлердің егжей- тегжейлі таңдау және тәжірибелі анықтау керек. Бұл үлгі тәжірибелік мәселелері тек адамдардың келтірімін жалпы үлгілерді жасау үшін жалпы үлгілерді жасау үшін біріктіріледі. Біз түзету түсініктемесін (CorEx) келтіреміз, оның негізгі генеративті үлгі деген тақырыптарды моделдеу альтернативті тәсілді, олардың орнына мәлімет теоретикалық фреймінен максималды мәліметтік тақыры Бұл қосымша модель үлгісінің қосымша кеңейтулері жоқ иерархикалық және жарты бақылау кеңейтулеріне жалпы болады. Әрине, сөздер деңгейіндегі доменнің білімі CorEx арқылы батыр сөздері арқылы гибсиялық түрде орналасуға мүмкін, нақыштарды бөлу және түрлендіру мүмкін болады. Түрлі деректер жинақтары, метрикалық және эксперименттердің арасында CorEx бағдарламасын LDA бағдарламасының сапасында салыстырып, жарым-бақылау варианттарынан шығарылмаған тақырыптарды жасайды деп көрсетеді.', 'it': "Mentre modelli generativi come Latent Dirichlet Allocation (LDA) si sono dimostrati fruttuosi nella modellazione degli argomenti, spesso richiedono ipotesi dettagliate e specifiche accurate degli iperparametri. Tali problemi di complessità del modello si aggravano solo quando si cerca di generalizzare modelli generativi per incorporare input umani. Introducemo Correlation Explanation (CorEx), un approccio alternativo alla modellazione topica che non assume un modello generativo sottostante, ma apprende argomenti al massimo informativi attraverso un framework informativo-teorico. Questo framework si generalizza naturalmente alle estensioni gerarchiche e semi-supervisionate senza ulteriori ipotesi di modellazione. In particolare, la conoscenza del dominio a livello di parola può essere incorporata in modo flessibile all'interno di CorEx attraverso parole di ancoraggio, consentendo di promuovere la separabilità e la rappresentazione degli argomenti con il minimo intervento umano. Attraverso una varietà di set di dati, metriche ed esperimenti, dimostriamo che CorEx produce argomenti di qualità paragonabile a quelli prodotti da varianti di LDA non supervisionate e semi-supervisionate.", 'lt': 'Nors modeliuojant teminius modelius pasirodė naudingi generaciniai modeliai, pavyzdžiui, paskutinės dilgėlinės paskirstymas (LDA), dažnai jiems reikalingos išsamios prielaidos ir kruopščios hiperparatorių specifikacijos. Tokie modelių sudėtingumo klausimai sudėtingi tik bandant generalizuoti kartų modelius, kad būtų įtrauktas žmogaus indėlis. Įdiegiame koreliacijos paaiškinimą (CorEx), alternatyvų metodą temų modeliavimui, kuris neturi pagrindinio kartos modelio, o vietoj to mokomi kuo daugiau informacinių temų naudojant informacinę teorinę sistemą. Ši sistema, be jokių papildomų modeliavimo prielaidų, paprastai apima hierarchinius ir pusiau prižiūrimus išplėtimus. Visų pirma žodžių srities žinios gali būti lanksčiai įtraukiamos į CorEx tekstą įtvirtinant įtvirtintus žodžius, kad būtų galima skatinti temų atskyrimą ir atstovavimą minimaliu žmogaus įsikišimu. Per įvairius duomenų rinkinius, metrinius rodiklius ir eksperimentus įrodome, kad CorEx gamina temas, kurios yra panašios kokybės į tas, kurias gamina nepastebimi ir pusiau prižiūrimi LDA variantai.', 'mk': 'Иако генерациските модели како што е Ладент Диричлет Allocation (LDA) се докажаа како плодовни во темското моделирање, тие честопати бараат детални претпоставки и внимателна спецификација на хиперпараметрите. Таквите проблеми со комплексноста на моделот се комплицирани само кога се обидува да ги генерализира генералните модели за вклучување на човечкиот внес. Го воведуваме Корелациското објаснување (CorEx), алтернативен пристап до моделирање на теми кој не претпоставува основен генерациски модел, а наместо тоа научи максимално информативни теми преку информациска теоретска рамка. Оваа рамка природно се генерализира на хиерархични и полунадгледувани проширувања без дополнителни претпоставки за моделирање. In particular, word-level domain knowledge can be flexibly incorporated within CorEx through anchor words, allowing topic separability and representation to be promoted with minimal human intervention.  Across a variety of datasets, metrics, and experiments, we demonstrate that CorEx produces topics that are comparable in quality to those produced by unsupervised and semi-supervised variants of LDA.', 'ms': 'While generative models such as Latent Dirichlet Allocation (LDA) have proven fruitful in topic modeling, they often require detailed assumptions and careful specification of hyperparameters.  Masalah kompleksiti model tersebut hanya berkumpul bila cuba menyebarkan model generatif untuk memasukkan input manusia. Kami memperkenalkan Penjelasan Korelasi (CorEx), pendekatan alternatif untuk pemodelan topik yang tidak menganggap model generatif didasarkan, dan malah belajar topik maklumat maksimum melalui kerangka maklumat-teori. Bingkai ini secara alami mengawal ke sambungan hierarkis dan setengah-mengawasi tanpa asumsi model tambahan. Secara khususnya, pengetahuan domain aras perkataan boleh disertai secara fleksibel dalam CorEx melalui perkataan penyancar, membolehkan pemisahan topik dan perwakilan dipromosikan dengan intervensi manusia minimal. Melalui berbagai set data, metrik, dan eksperimen, kami menunjukkan bahawa CorEx menghasilkan topik yang boleh dibandingkan kualiti dengan topik yang dihasilkan oleh varian LDA yang tidak diawasi dan setengah diawasi.', 'ml': 'ലാറ്റെന്റ് ഡിരിച്ചില്ലെറ്റ് സംഘടിപ്പിക്കുന്ന (LDA) പോലുള്ള ജനറല്\u200d മോഡലുകള്\u200d പ്രധാനപ്പെടുത്തിയിരിക്കുമ്പോള്\u200d അവര്\u200dക്ക് പ്രാ ഇത്തരം മോഡലിന്റെ സങ്കീര്\u200dണ്ണമായ പ്രശ്നങ്ങള്\u200d മാത്രമേ കൂട്ടുന്നുള്ളൂ മനുഷ്യരുടെ ഇന്\u200dപുട്ടില്\u200d ചേര്\u200dക്കാന കോര്\u200dബന്ധം എക്സ്പ്ലാനേഷന്\u200d (കൊര്\u200dഎക്സ്) നാം പരിചയപ്പെടുത്തുന്നു. വിവരങ്ങള്\u200d തിയോറിറ്റിക് ഫ്രെയിമെക്കിലൂടെ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്ന ഒരു മാത് ഈ ഫ്രെയിമ്പ് സ്വാഭാവികമായി ഹിയറാര്\u200dക്കിക്കല്\u200d വികസിക്കുന്നതും കൂടുതല്\u200d മാതൃകയുള്ള ഊഹം ഇല്ലാത്ത വികസ്ഥകളിലേക പ്രത്യേകിച്ച്, വാക്ക്-നില വിവരങ്ങളുടെ അറിവ് കോര്\u200dഎക്സിന്റെ ഉള്ളില്\u200d ഉള്\u200dപ്പെടുത്താന്\u200d സാധ്യമല്ല, ആങ്കോര്\u200d വാക്കുകളിലൂടെ ചേര്\u200dക വ്യത്യസ്ത ഡാറ്റാസറ്റുകള്\u200d, മെട്രിക്കകള്\u200d, പരീക്ഷണങ്ങള്\u200dക്കും കൂടിയിട്ട്, കോര്\u200dഎക്സ് പ്രദര്\u200dശിപ്പിക്കുന്നുണ്ടെന്ന് നമ്മള്\u200d കാണിക്കുന്നു, കോര്\u200dഎക', 'mt': 'Filwaqt li mudelli ġenerattivi bħall-Allokazzjoni Latent Dirichlet (LDA) urew li huma ta’ frott fl-immudellar tas-suġġetti, ta’ spiss jeħtieġu suppożizzjonijiet dettaljati u speċifikazzjoni bir-reqqa ta’ parametri eċċessivi. Kwistjonijiet ta’ kumplessità bħal dawn tal-mudell jikkompletaw biss meta jippruvaw jiġġeneralizzaw mudelli ġenerattivi biex jinkorporaw il-kontribut uman. Aħna nintroduċu Spjegazzjoni ta’ Korelazzjoni (CorEx), approċċ alternattiv għall-immudellar ta’ suġġetti li ma jassumix mudell ġenerattiv sottostanti, u minflok jitgħallmu suġġetti massimament informativi permezz ta’ qafas teoretiku tal-informazzjoni. Dan il-qafas ġeneralizza b’mod naturali għal estensjonijiet ġerarkiċi u semisuperviżi mingħajr suppożizzjonijiet addizzjonali ta’ mudellar. B’mod partikolari, l-għarfien tad-dominju fil-livell tal-kliem jista’ jiġi inkorporat b’mod flessibbli fi ħdan CorEx permezz ta’ kliem ankrat, li jippermetti li s-separabbiltà u r-rappreżentanza tas-suġġett jiġu promossi b’intervent minimu uman. Permezz ta’ varjetà ta’ settijiet ta’ dejta, metriċi, u esperimenti, a ħna nuru li CorEx jipproduċi suġġetti li huma komparabbli fil-kwalità ma’ dawk prodotti minn varjanti mhux sorveljati u semisorveljati ta’ LDA.', 'mn': 'Latent Dirichlet Allocation (LDA) шиг генериал загварууд сэдэв загварын загвар дээр үр дүнтэй байдаг ч ихэвчлэн нарийвчлалтай тодорхойлолт болон гиперпараметрын тодорхойлолт хэрэгтэй. Ийм загварын төвөгтэй асуудлууд л хүн төрөлхтний оролцоог оруулахын тулд генерал загвар бүрдүүлэхэд холбогдон байдаг. Бид сайжруулах тодорхойлолт (CorEx), сэдвийн загварын загварын альтернатив арга загварыг танилцуулдаг. Үүний оронд мэдээллийн теоретик хэлбэрээр хамгийн их мэдээллийн сэдэв суралцдаг. Энэ үйл ажиллагаа нь байгалийн түвшинд нэмэлт загварчлалын тодорхойлолтгүй байдлаар ерөнхийлөгдөж байдаг. Ялангуяа, үг хэмжээний мэдлэг CorEx-д хамгийн бага хэлбэрээр гишүүн хэмжээгээр нэгтгэгдэж болно. Хүн төрөлхтний хамгийн бага оролцоогоор сэдэв хуваагдах болон харилцааныг дэвшүүлж болно. Бид олон төрлийн өгөгдлийн сангууд, метрик, туршилтуудын тулд CorEx нь LDA-ын төрлийн багтаагүй, хагас удирдлагагүй хувилбараар бүтээгдэхүүнтэй харьцуулагддаг тухай харуулж байна.', 'no': 'Mens genererte modeller som Latent Dirichlet Allocation (LDA) har bevist frukt i temamodellen, krev dei ofte detaljerte antar og forsiktig spesifikasjon av hyperparametrar. Dette modellet er berre kompleksitetsproblemet samansert når du prøver å generelisera generelle modeller for å inkludere menneskelige inndata. Vi introduserer korrigeringsforklaring (CorEx), eit alternativ tilnærming til temamodellering som ikkje antar ein underlagt generativ modell, og i staden lærer maksimal informativ emne gjennom eit informasjonsteoretisk rammeverk. Dette rammeverket genereliserer naturleg til hierarkiske og semioversikte utvidingar med ingen ekstra modellingsantar. Spesielt kan ordnivådomenekunnskap bli fleksibelt inkludert i CorEx gjennom ankoraord, slik at temaskiljeteiknet og representasjon kan gjerast med minimal menneske intervensjon. På ein del dataset, metrikar og eksperimenter viser vi at CorEx produserer emne som er samanlikbar i kvalitet med dei som produserer av ulike og semioversikte variantar av LDA.', 'pl': 'Chociaż modele generatywne takie jak Latent Dirichlet Allocation (LDA) okazały się owocne w modelowaniu tematycznym, często wymagają szczegółowych założeń i starannej specyfikacji hiperparametrów. Takie problemy złożoności modelu zwiększają się tylko podczas próby uogólnienia modeli generacyjnych w celu uwzględnienia ludzkiego wkładu. Wprowadzamy wyjaśnienie korelacji (CorEx), alternatywne podejście do modelowania tematów, które nie zakłada podstawowego modelu generacyjnego, a zamiast tego uczy się maksymalnie informacyjnych tematów poprzez ramy teoretyczne informacji. Rama ta naturalnie uogólnia się do hierarchicznych i pół-nadzorowanych rozszerzeń bez dodatkowych założeń modelowania. W szczególności wiedza o domenie na poziomie słów może być elastycznie włączana do CorEx poprzez słowa kotwicące, co pozwala promować rozdzielność i reprezentację tematów przy minimalnej interwencji człowieka. W różnych zbiorach danych, wskaźnikach i eksperymentach pokazujemy, że CorEx produkuje tematy porównywalne pod względem jakości do tych produkowanych przez nienadzorowane i pół-nadzorowane warianty LDA.', 'ro': 'În timp ce modelele generative, cum ar fi Allocarea Latent Dirichlet (LDA) s-au dovedit fructuoase în modelarea subiectelor, ele necesită adesea ipoteze detaliate și specificarea atentă a hiperparametrilor. Astfel de probleme de complexitate a modelului se compun doar atunci când încercați să generalizați modelele generative pentru a include input uman. Introducem Corelation Explication (CorEx), o abordare alternativă la modelarea subiectelor care nu presupune un model generativ subiacent, ci în schimb învață subiecte maxim informative printr-un cadru teoretic informațional. Acest cadru generalizează în mod natural la extensii ierarhice și semi-supravegheate fără ipoteze suplimentare de modelare. În special, cunoștințele de domeniu la nivel de cuvinte pot fi încorporate flexibil în CorEx prin cuvinte de ancoră, permițând promovarea separării și reprezentării subiectelor cu intervenție umană minimă. Prin intermediul unei varietăți de seturi de date, metrice și experimente, demonstrăm că CorEx produce subiecte care sunt comparabile ca calitate cu cele produse de variante nesupravegheate și semi-supravegheate de LDA.', 'so': 'Inta lagu sameeyo tusaale ahaan Dirichlet Ururka Latent (LDA) waxay caddeysay midho ku filan sameynta mada, waxay marar badan u baahan yihiin malooyin gaar ah iyo xisaab aad u taxadar ah heerarka. Isticmaalkaas dhibaatooyin adag oo kaliya marka aad isku dayayso in uu sameeyo tusaalooyin geneeral ah si uu u galo input dadka. Waxaynu soo bandhignaynaa korrelation Explanation (CorEx), qaab kale oo ku saabsan sameynta mada oo aan heysan model generative hoose ah, taas oo badalka lagu barto mada macluumaadka si ugu badnaan waxaa lagu bartaa shabakad macluumaad ah. Shaqooyinkan waxay si dabiiqada ah u generaysaa hierarchical iyo semi-super-ilaaliyey, mana laha malayo kale oo sameynaya. Si gaar ah, aqoonta deegaanka waxaa si fudud loogu soo qori karaa KorEx gudahooda, si uu ugu badbaadiyo hadal horumarinta ah, oo uu u ogolaado in la horumariyo isbedelka dadka ugu yaraan. Qoraalka macluumaadka kala duduwan, metricyada iyo imtixaanka, waxaynu muujinnaa in CorEx uu soo saaraa maadooyin u eg qiimo u eg kuwaas oo ay ka soo bixiyaan kala duwan ee LDA oo aan la ilaalinayn iyo hal ka ilaalinayn.', 'sv': 'Även om generativa modeller som Latent Dirichlet Allocation (LDA) har visat sig givande i ämnesmodellering, kräver de ofta detaljerade antaganden och noggrann specifikation av hyperparametrar. Sådana modellkomplexitetsfrågor uppstår bara när man försöker generalisera generativa modeller för att införliva mänsklig input. Vi introducerar Correlation Explanation (CorEx), ett alternativt förhållningssätt till ämnesmodellering som inte antar en underliggande generativ modell, utan istället lär sig maximalt informativa ämnen genom ett informationsteoretiskt ramverk. Detta ramverk generaliserar naturligtvis till hierarkiska och halvövervakade tillägg utan ytterligare modellering antaganden. Särskilt kan domänkunskap på ordnivå integreras flexibelt i CorEx genom förankringsord, vilket gör det möjligt att främja särskiljbarhet och representation av ämnen med minimal mänsklig intervention. Genom en mängd olika datauppsättningar, mätvärden och experiment visar vi att CorEx producerar ämnen som är jämförbara i kvalitet med dem som produceras av oövervakade och halvövervakade varianter av LDA.', 'sr': 'Iako su generični modeli poput Latent Dirichlet Allocation (LDA) dokazali plodno u modelima tema, često zahtevaju detaljne pretpostavke i pažljive specifikacije hiperparametara. Takve probleme sa kompleksnošću modela su povezani samo kada se pokušavaju generalizirati generativni modeli da bi uključili ljudski ulaz. Predstavljamo korelacijsko objašnjenje (CorEx), alternativni pristup modelima tema koji ne prima temeljni generativni model, a umjesto toga nauči maksimalno informativne teme kroz informativni i teoretički okvir. Ovaj okvir prirodno generalizuje na hijerarhičke i polu-nadzorne proširenje bez dodatnih pretpostavki za modelizaciju. Posebno, znanje domena riječi na razini može biti fleksibilno uključeno u Koreks kroz čvrste reči, omogućavajući razdvojivost i predstavljanje tema sa minimalnim ljudskim intervencijama. Preko različitih seta podataka, metrika i eksperimenata, pokazujemo da CorEx proizvodi teme koje su usporedne u kvaliteti sa onima koji su proizvodili neodređeni i polu-nadzorni varianti LDA-a.', 'si': 'ලේටින් ඩිරිච්ලෙට් ඇලෝකේෂණ් වලින් ප්\u200dරභාවිත විදියට ප්\u200dරභාවිත විදියට ප්\u200dරභාවිත විදියට ප්\u200dරභාවිත විදියට ප්\u200dරශ්නයක්  මිනිස්සු ඇතුලත් එක්ක සම්පූර්ණය කරන්න උත්සාහ කරන්නේ සාමාන්\u200dය විද්\u200dයාවක් සම්පූර්ණ විතරයි. අපි සම්පූර්ණ විස්තර (CorEx) විස්තර කරන්න, ප්\u200dරශ්ණ විස්තර විස්තර ප්\u200dරශ්නයක්, විස්තර ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් නැති විස්තර ප්\u200dරශ්නයක මේ පරීක්ෂණය සාමාන්\u200dයයෙන්ම සාමාන්\u200dයයෙන්ම සාමාන්\u200dය විශේෂණය සහ සම්පාර්ෂික විශේෂණය නැති විශේෂණය විශේෂයෙන්, වචන-ලේවල් ඩොමේන් දන්නවම CorEx වලට පුළුවන් පුළුවන් විශේෂ වචන වලින් සම්බන්ධ වෙන්න, ප්\u200dරශ්නයක් සහ ප්\u200dර විවිධ දත්ත සෙට්, මෙට්\u200dරික්ස්, සහ පරීක්ෂණාවක් වලින්, අපි ප්\u200dරකාශ කරනවා CorEx ප්\u200dරකාශ කරනවා කියලා LDA වලින් නිර්මාණය කරපු අවස්ථාවක් ස', 'ta': 'Latent Dirichlet Allocation (LDA) போன்ற பொது பொதுவான மாதிரிகள் தலைப்பு மாதிரியும் போது, அவை பெரும்பாலும் விவரமான எண்ணங்கள் மற்றும் மின்னெழுத்து அளப இத்தகைய மாதிரி சிக்கல் பிரச்சனைகள் மட்டும் ஒருங்கிணைப்பு மட்டும் மனித உள்ளீட்டை உள்ளிட முயற்சிக்கும் போத நாம் கார்த்தொடர்பு வெளியீட்டு (CorEx) குறிப்பிடுகிறோம், தலைப்பு மாதிரியின் மாற்று வழிமுறையை குறிப்பிடுகிறோம், அது ஒரு அடிப்படையான பொது மாத This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional modeling assumptions.  குறிப்பிட்டு, வார்த்தை மட்டத்தில் அறிவு கோர்எக்ஸ் உள்ளே புள்ளியில் சேர்க்கப்பட முடியும், முன்னேற்ற வார்த்தைகள் மூலம், தலைப்புகளை  பல்வேறு தரவுத்தளங்கள், மேட்ரிக்கள் மற்றும் சோதனைகள் முறையில், கோர்எக்ஸ் தலைப்புகளை உருவாக்குகிறது மற்றும் காப்பாற்றப்படாத மற்றும் பாதுகாப்பு மேற', 'ur': 'اگرچہ پیدا کرنے والی موڈلیاں جیسے Latent Dirichlet Allocation (LDA) موڈلیاں میں پھل پھل دکھائی گئی ہیں، انہوں نے اکثر تفصیل معلومات اور اہپر پارامیٹروں کی دکھائی کی ضرورت کی ہے. یہ موڈل پیچیدگی مسئلہ صرف پیچیدہ ہونے کی کوشش کرتا ہے جب انسان کے اینپیٹ میں شامل ہونے کے لئے جنرائیٹ موڈلہ بنانے کی کوشش کرتا ہے. ہم اصلاح سفارش (CorEx) کو معرفی کرتے ہیں، ایک متعلق موڈلینگ کے متعلق ایک الٹ تقریبا ہے جو ایک نیچے پیدا کرنے والی موڈل کو قبول نہیں کرتا، اور اس کے بدلے معلومات-نظریہ فرمود کے ذریعہ مکمل معلومات کی موضوع سکھاتا ہے. یہ فرم طبیعی طور پر جرائل کرتا ہے کہ ہیرارکیک اور نصف نظارت کی اضافہ کے بغیر کوئی اضافہ نمڈلینگ فرض نہیں ہوتی۔ مخصوصاً کلمات-سطح ڈومین علم کورکس کے اندر اندھیرے کلمات کے ذریعہ ہلکی طرح شامل ہو سکتا ہے، اس کے ذریعہ سے موضوع جدائی اور نمایش کی اجازت دیتا ہے کہ کم انسان کی intervention سے منتقل ہو جائے۔ ہم نے ایک مختلف ڈاٹ سٹ، میٹریک اور آزمائش کے درمیان دکھایا ہے کہ CorEx نے ایسے موضوع پیدا کئے ہیں جو LDA کی ناپابندی اور نیم نظارت والی مختلف مختلف موضوع سے پیدا کئے جاتے ہیں۔', 'uz': "@ info: whatsthis Bu model murakkablik muammolari faqat umumiy kiritish uchun umumiy modellarni yaratishni istasangiz mumkin. Biz Correlation Exploration (CorEx), mavzu modelining boshqa usulni o'rganamiz. Bu mavzu modelning asosiy generativ modeli emas, va uning o'rniga ma'lumot mavzularini o'rganadi. Name Hullas, so'zlar darajada ma'lumot qo'shish mumkin, kichkina inson intervention bilan o'xshash so'zlar orqali CorEx ichida qo'yish mumkin. Ko'pchilik maʼlumotlar, metrik va tajribalar bilan, CorEx mavzularini ko'rsatamiz va LDA'ning haqida saqlab qolmagan va semi taʼminlovchi varianter bilan yaratiladigan mavzularga mos beradi.", 'vi': 'Trong khi các mô hình sinh sản như Latent DirIChlet Allocation (LDAP) đã chứng minh có hiệu quả trong việc tạo mẫu về chủ đề, họ thường cần các giả thiết chi tiết và cẩn thận xác định các siêu tham số. Mô hình phức tạp chỉ kết hợp khi cố tổng hợp các mô hình tạo hóa để nhập vào cơ thể con người. Chúng tôi giới thiệu Điều Giải thích Phóng Phóng Phóng Tương đối với lẽ mẫu về chủ đề mà không sử dụng một mô hình gen cơ bản, và thay vào đó học các chủ đề tối đa thông tin qua một quy định thông tin. Thông tin này tổng hợp lại với hệ thống leo thang và bán giám sát mà không có giả thiết thiết mẫu khác. Đặc biệt, hiểu biết về lĩnh vực từ cấp trên có thể dễ dàng được áp dụng trong tuyến đường Corex, nhờ những từ neo, giúp việc phân biệt chủ đề và đại diện được thúc đẩy với mức tối thiểu. Bên trong một loạt các bộ dữ liệu, âm lượng và các thí nghiệm, chúng tôi chứng minh rằng CorEX đã phát triển các môi trường chất lượng tương đương với các loại chưa được giám sát và bán giám sát.', 'bg': 'Въпреки че генеративните модели като Латент Дирихлет Allocation (LDA) са се оказали ползотворни в тематичното моделиране, те често изискват подробни предположения и внимателно специфициране на хиперпараметрите. Такива проблеми с сложността на модела се усложняват само когато се опитват да обобщят генеративните модели, за да включват човешки принос. Въвеждаме обяснение на корелацията (алтернативен подход към моделирането на теми, който не приема основен генеративен модел, а вместо това научава максимално информативни теми чрез информационно-теоретична рамка. Тази рамка естествено обобщава йерархични и полунадзорни разширения без допълнителни предположения за моделиране. По-специално, познанията на ниво дума могат да бъдат гъвкаво вградени в КорЕкс чрез водещи думи, позволявайки разграничаването на темата и представянето да бъдат насърчавани с минимална човешка намеса. Чрез различни набори от данни, показатели и експерименти ние демонстрираме, че произвежда теми, които са сравними по качество с тези, произведени от ненадзорни и полунадзорни варианти на LDA.', 'hr': 'Iako su generični modeli poput Latent Dirichlet Allocation (LDA) pokazali plodno u modelima tema, često zahtijevaju detaljne pretpostavke i pažljive specifikacije hiperparametara. Takve probleme sa kompleksnošću modela su povezani samo kada se pokušavaju generalizirati generativni modeli uključiti ljudski ulaz. Predstavljamo korelacijsko objašnjenje (CorEx), alternativni pristup modelima tema koji ne prima temeljni generativni model, a umjesto toga uči maksimalno informativne teme kroz informativni i teorijski okvir. Ovaj okvir se prirodno generalizira na hijerarhičke i polu nadzorne proširenje bez dodatnih pretpostavki modela. Posebno, znanje domena riječi na razini može biti fleksibilno uključeno u CorEx kroz čvrste riječi, omogućavajući razdvojivanje teme i predstavljanje s minimalnom ljudskom intervencijom. Preko različitih seta podataka, metrika i eksperimenata pokazujemo da CorEx proizvodi teme koje su usporedbene u kvaliteti onima koji su proizvedeni od neodređenih i polu nadzornih varianta LDA-a.', 'nl': 'Hoewel generatieve modellen zoals Latent Dirichlet Allocation (LDA) vruchtbaar zijn gebleken in topic modeling, vereisen ze vaak gedetailleerde aannames en zorgvuldige specificatie van hyperparameters. Dergelijke problemen met de complexiteit van het model maken alleen maar groter wanneer men probeert generatieve modellen te generaliseren om menselijke input op te nemen. We introduceren Correlation Exlaration (CorEx), een alternatieve benadering van topic modelling die geen onderliggend generatief model aanneemt, maar in plaats daarvan maximaal informatieve onderwerpen leert door middel van een informatietheoretisch raamwerk. Dit framework generaliseert natuurlijk naar hiërarchische en semi-supervised extensies zonder extra modelleringsaannames. Met name kan domeinkennis op woordniveau flexibel worden geïntegreerd in CorEx via ankerwoorden, waardoor de scheidbaarheid en representatie van onderwerpen met minimale menselijke interventie kan worden bevorderd. Aan de hand van verschillende datasets, metrics en experimenten tonen we aan dat CorEx onderwerpen produceert die qua kwaliteit vergelijkbaar zijn met die welke worden geproduceerd door niet-begeleide en semi-begeleide varianten van LDA.', 'da': 'Mens generative modeller som Latent Dirichlet Allocation (LDA) har vist sig at være frugtbare i emnemodellering, kræver de ofte detaljerede antagelser og omhyggelig specifikation af hyperparametre. Sådanne model kompleksitet problemer bliver kun sammensat, når man forsøger at generalisere generative modeller til at indarbejde menneskelig input. Vi introducerer Correlation Explanation (CorEx), en alternativ tilgang til emnemodellering, der ikke antager en underliggende generativ model, og i stedet lærer maksimalt informative emner gennem en informationsteoretisk ramme. Denne ramme generaliserer naturligvis til hierarkiske og semi-overvågede udvidelser uden yderligere modellering antagelser. Især kan viden om ordniveau indarbejdes fleksibelt i CorEx gennem ankerord, hvilket gør det muligt at fremme adskillelighed og repræsentation af emner med minimal menneskelig indgriben. På tværs af en række datasæt, metrics og eksperimenter viser vi, at CorEx producerer emner, der er sammenlignelige i kvalitet med dem, der produceres af uautoriserede og halvovervågede varianter af LDA.', 'de': 'Generative Modelle wie Latent Dirichlet Allocation (LDA) haben sich in der Themenmodellierung bewährt, erfordern jedoch häufig detaillierte Annahmen und eine sorgfältige Spezifikation von Hyperparametern. Solche Modellkomplexitätsprobleme verschärfen sich nur, wenn versucht wird, generative Modelle zu verallgemeinern, um menschlichen Input zu integrieren. Wir stellen Correlation Exlaration (CorEx) vor, einen alternativen Ansatz zur Themenmodellierung, der kein zugrunde liegendes generatives Modell annimmt, sondern durch ein informationstheoretisches Framework maximal informative Themen erlernt. Dieses Framework verallgemeinert sich natürlich auf hierarchische und semi-überwachte Erweiterungen ohne zusätzliche Modellierungsannahmen. Insbesondere Domänenwissen auf Wortebene kann durch Ankerwörter flexibel in CorEx integriert werden, wodurch die Trennbarkeit und Repräsentation von Themen mit minimalem menschlichem Eingriff gefördert werden kann. Anhand einer Vielzahl von Datensätzen, Metriken und Experimenten zeigen wir, dass CorEx Themen produziert, die in ihrer Qualität mit denen vergleichbar sind, die von unbeaufsichtigten und halbüberwachten LDA-Varianten produziert werden.', 'id': 'Sementara model generatif seperti Latent Dirichlet Allocation (LDA) telah terbukti berguna dalam model topik, mereka sering membutuhkan asumsi terperinci dan spesifikasi hati-hati hyperparameter. Masalah kompleksitas model seperti ini hanya berkumpul ketika mencoba untuk generalisasi model generasi untuk mengikorporasi input manusia. Kami memperkenalkan Penjelasan Korelasi (CorEx), pendekatan alternatif untuk model topik yang tidak menganggap model generasi yang didasarkan, dan malah mempelajari topik maksimal informasi melalui struktur teori-informasi. Bingkai ini secara alami mendeneralisasikan ke ekstensi hierarkis dan semi-mengawasi tanpa asumsi model tambahan. Terutama, pengetahuan domain tingkat kata dapat fleksibel disertai dalam CorEx melalui kata-kata jangkar, memungkinkan pemisahan topik dan representasi untuk dipromosikan dengan intervensi manusia minimal. Melalui berbagai set data, metrik, dan eksperimen, kami menunjukkan bahwa CorEx menghasilkan topik yang dapat dibandingkan dengan kualitas yang dihasilkan oleh varian LDA yang tidak diawasi dan semi-diawasi.', 'fa': 'در حالی که مدل\u200cهای ژنترافی مانند تقسیم دیریکلت latent (LDA) در مدل\u200cسازی موضوع ثابت شده\u200cاند، اغلب به فرضیه\u200cهای جزئیات و مشخص دقیق از پارامترها نیاز دارند. این مشکلات پیچیدگی مدل فقط در زمانی که سعی می\u200cکنیم مدل\u200cهای ژنرالیز را جمع کنیم تا وارد بشر را جمع کند. ما توضیح اصلاح (CorEx) را معرفی می\u200cکنیم، یک دستور alternative برای مدل\u200cسازی موضوع که یک مدل ژنتریفی پایین نمی\u200cگیرد، و به جای آن، موضوع\u200cهای بیشترین اطلاعات را از طریق یک چهارچهارچهارچهارچهارچهارچهارچهارچها این چهارچوب طبیعی به وسیله\u200cهای معمولی و نیمه\u200cبررسی با هیچ فرضیه\u200cهای نمونه\u200cبندی اضافه می\u200cکند. در خصوص، علم دامنی کلمه\u200cها می\u200cتواند از طریق کلمات محافظت در CorEx با flexible incorporate شود، که اجازه می\u200cدهد جدایی و نمایش موضوع را با تعامل کمترین انسان توسعه دهد. از طریق مختلف مجموعه\u200cهای داده\u200cها، متریک و آزمایش\u200cها، نشان می\u200cدهیم که CorEx موضوع را تولید می\u200cکند که در کیفیت قابل مقایسه با کسانی که تولید شده\u200cاند توسط متفاوتهای غیرقابل تحت نظر و نیمه تحت نظر LDA است.', 'ko': '잠재적 딜릭 분배 (LDA) 와 같은 생성성 모델은 테마 모델링에서 탁월한 효과가 있음을 증명했지만, 보통 상세한 가설과 슈퍼 파라미터에 대한 상세한 설명이 필요하다.생성 모델을 인류의 입력을 포함하는 것으로 확대하려고 시도할 때 이런 모델의 복잡성 문제는 더욱 복잡해진다.우리는 잠재적인 생성 모델을 가정하지 않고 정보 이론 구조를 통해 정보량이 가장 많은 주제를 학습하는 주제 모델링의 대체 방법인 관련 해석(CorEx)을 도입했다.이 틀은 자연스레 층별 확대와 반감독 확대로 확대되어 별도의 모델링 가설이 필요 없다.특히 단어급 분야 지식은 닻말을 통해 코어엑스에 유연하게 통합해 최소한의 인위적인 관여 아래 주제의 가분성과 표현성을 높일 수 있다.다양한 데이터 세트, 지표 및 실험을 통해 CorEx에서 만들어진 주제가 LDA의 무감독 및 반감독 변형에서 만들어진 주제와 질적으로 비슷하다는 것을 입증했습니다.', 'sw': 'Wakati mifano ya jeneral kama vile Shirika la Kiarabu la Dirichlet (LDA) imethibitisha matunda katika mifano ya mada, mara nyingi huhitaji dhana zilizofafanana na uthibitisho wa vifaa vyema. Tatizo la tatizo la mifano hiyo ni moja tu pale wanapojaribu kutengeneza mifano ya jenerali ili kuingiza input ya binadamu. Tunawasilisha Maelezo ya CorEx (CorEx), njia mbadala ya mifano ya mada ambayo haiwezi kudhibiti muundo wa kizalendo, na badala yake tunajifunza mada yenye taarifa kupitia mfumo wa taarifa. This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional modeling assumptions.  Kwa hakika, maarifa ya ndani ya maeneo ya maneno yanaweza kuingizwa kwa kiasi kikubwa ndani ya CorEx kwa kutumia maneno ya kigaidi, na kusaidia kutenganisha mada na uwakilishi kuhamasisha kwa ajili ya kuingilia kati binadamu kwa kiasi kidogo. Katika seti mbalimbali za taarifa, mitiri na majaribio, tunaonyesha kwamba CorEx hutengeneza mada ambazo zinafanana na sifa na zile zilizotengenezwa na tofauti za kisasa zisizo sahihi na zile zinazofuatiliwa na LDA.', 'tr': 'Latent Dirichlet Allocation Häzirki modler çykyş meseleleri diňe döredijilik nusgalary adam girişini dahyl etmek üçin birleştirilýär. Biz düzeltmek düşündirişi (CorEx), meýdança nusgasyna golaý bir nusgasyny alyp bilmeýän meýdança nusgasyny çykarýarys we munyň ýerine maglumat-teoriýa çerýäsinden beýleki informatiýa meýdanlary öwrenýär. Bu çerçew dogrudan iýerarhiýa we semi-gözleýän eklenenlere daşary modelleme assumplary ýok. Adatça, söz derejesi domaýynyň bilimi CorEx-de anchor sözleri bilen fleksibil bilen birleştirilip biler, temalaryň aýrylyşlygyny we täsirlerini iň kiçi adam aralygy bilen tanyşdyrylmage mümkin edip biler. Birnäçe sany veri setirli, metrik we deneyler arasynda, biz CorEx-iň LDA garşy boýunça we semi-gözleýän wariantlary tarapyndan ýakynlaşyp biljek temalary üretýäris diýip görkeýäris.', 'af': "Terwyl genereerde modele soos Latent Dirichlet Allocation (LDA) vrugbaar in onderwerp modellering bevestig het, het hulle dikwels gedetale aanvaardes en versigtige spesifikasie van hiperparameters nodig. Soos model kompleksiteit probleme slegs verbind wanneer probeer om genereer modele te genereer om menslike invoer te inkorpreer. Ons introduseer Korrigeringsverklaring (CorEx), â\x80\x99n alternatiewe toegang tot onderwerp modellering wat nie 'n onderwerp genereerder model aanneem nie, en in plaas leer maksimaal informatiewe onderwerpe deur â\x80\x99n informasie-teorieese raamwerk. Hierdie raamwerk natuurlik generaliseer na hierarkies en semi-ondersoekte uitbreidings met geen addisionele modellering aanvaardings nie. In besonderhede kan woord-vlak domein kennis fleksibel ingesluit word binne CorEx deur anker woorde, toelaat onderwerp skeidigheid en voorstelling met minimale menslike intervensie ontwikkeld word. Deur 'n verskillende datastelle, metries en eksperimente, wys ons dat CorEx onderwerp onderwerpe wat in kwaliteit vergelykbaar is met die wat deur ononderwerp en semi-onderwerp variante van LDA produseer is.", 'am': 'በተጨማሪው አካባቢ (LDA) ምሳሌ ውስጥ ፍሬያዊ አካባቢ ሲገልጹ፣ ብዙ ጊዜም የፍሬዎችን አካሄድ እና የhyperparameters ማስታወቂያ ያስፈልጋል፡፡ እንደዚህ የሞዴል አካባቢ ጉዳዮች የሰው ውስጥ ለመግባት ሲሞክሩ አዲስ ጉዳይ ብቻ ነው፡፡ የኮርተርኔት Explanation (CorEx)፣ የውይይት አዋጅ ሞዴል እንደሌለው ለዋጭ ሥርዓት እናስታውቃለን፡፡ ይሄ ፍሬም በተለየ አካባቢ እና በsemi-በተጠበቀው ግንኙነቶችን በተጨማሪም ምሳሌ ባይኖር ያስተካክላል፡፡ በተለይም፣ የቃላት-ደረጃ ውቀት በኮርEx ውስጥ በጥንካሬ ቃላት እንዲገቡ ይችላል፡፡ የተለየ ውይይት እና መልዕክት በትንሹ የሰው ማቀናቀል በመጠቀም ይችላል፡፡ በተለያዩ የዳታ ሰርተሮች፣ ሜትሪክ እና ፈተናዎች ላይ፣ ኮርEx የLDA ተቃዋሚዎች በጥሩ እና በsemi ተለይታ የተደረገውን ጉዳዮች እንዲያሳየው እናሳያልን፡፡', 'hy': 'Մինչդեռ սերունդային մոդելները, ինչպիսիք են Վերջին դիրիկլետի բաժանվածությունը (ԼԴԱ), արդյունավետ են ապացուցել թեմային մոդելների մեջ, նրանք հաճախ պահանջում են մանրամասն ենթադրություններ և հիպերպարամետրերի ուշադիր նշանակ Այսպիսի բարդ մոդելների խնդիրները միայն բարդ են, երբ փորձում են ընդհանուր սերունդների մոդելներ ներառել մարդկային ներմուծը: Մենք ներկայացնում ենք Կորելացիայի բացատրությունը (COREEx), թեմային մոդելների այլընտրանքային մոտեցում, որը չի ենթադրում հիմնական սերունդային մոդելը, և փոխարենը սովորում է առավել ինֆորմատիվ թեմաներ տեղեկատվական-տեսական շրջանակի միջոցով: Այս շրջանակը բնականաբար ընդհանրացվում է հիերարխիկական և կիսակառավարվող ընդլայնումների վրա, առանց որևէ ավելին մոդելավորման ենթադրության: Մասնավորապես բառի մակարդակի գիտելիքները կարող են ճկուն ներգրավվել ԿորԷքսի մեջ կապվածքային բառերի միջոցով, թույլ տալով թեմայի բաժանելիությունը և ներկայացումը առաջ քաղել մարդկային ինտերկցիայի միջոցով: Տարբեր տվյալների, մետրիկների և փորձարկումների միջոցով մենք ցույց ենք տալիս, որ COREX-ը ստեղծում է թեմաներ, որոնք համեմատուկ են որակի հետ, որոնք ստեղծվում են ԼԴԱ-ի ոչ վերահսկվող և կես վերահսկվող տարբերակների միջոցով:', 'bn': 'যখন জেনারেটিভ মডেল যেমন ল্যাটেন্ট ডিরিচেলেট অ্যালোকেশন (এলডিএ) বিষয়টি মডেলিং এ ফলাফল প্রমাণ করেছে, তখন তাদের প্রায়শই বিস্তারিত ধারণা এবং হ এই মডেলের জটিল বিষয় শুধুমাত্র জেনারেটিভ মডেল তৈরি করার চেষ্টা করছে মানুষের ইনপুটের মধ্যে যোগ দেয়ার জন্য। We introduce Correlation Explanation (CorEx), an alternative approach to topic modeling that does not assume an underlying generative model, and instead learns maximally informative topics through an information-theoretic framework.  এই ফ্রেমের কাঠামো স্বাভাবিকভাবে হিয়ারার্কিক্যাল এবং সেমি পর্যবেক্ষণের বিস্তারিত এক্সটেনশনের সাধারণত সাধা বিশেষ করে, শব্দ-স্তরের জ্ঞান কোরেক্সের ভেতরে কৌতুকিকভাবে যোগ দিতে পারে, যাতে বিষয়বস্তু বিচ্ছিন্ন এবং প্রতিনিধিত্ব নিয়ে কম মানুষের বিভিন্ন ধরনের ডাটাসেট, মেট্রিক এবং পরীক্ষার মাধ্যমে আমরা প্রমাণ করি যে কোরেক্স বিষয়গুলো তৈরি করে যারা মানের সাথে সমতুল্য করে এবং এলডিএ এর সামান্য পরিচালন', 'sq': 'Ndërsa modelet gjenerative të tilla si Allokimi Latent Dirichlet (LDA) janë vërtetuar të dobishëm në modelimin tematik, ato shpesh kërkojnë supozime të detajuara dhe specifikime të kujdesshme të hiperparametrave. Të tilla çështje të kompleksitetit të modelit komplikuan vetëm kur përpiqen të gjeneralizojnë modelet gjenerative për të përfshirë input njerëzor. Ne paraqesim shpjegimin e korrelacionit (CorEx), një metodë alternative për modelimin e temës që nuk supozon një model gjenerativ bazues dhe në vend të kësaj mëson temat maksimalisht informative nëpërmjet një kuadri informacioni-teoretik. Ky kuadër gjeneralizohet natyralisht në zgjerime hierarkike dhe gjysmë-mbikqyrura pa supozime shtesë modelimi. Në veçanti, njohuria e domenit të nivelit të fjalëve mund të përfshihet fleksibilisht brenda CorEx nëpërmjet fjalëve ankor, duke lejuar ndarjen e temës dhe përfaqësimin të nxitet me ndërhyrje minimale njerëzore. Nëpërmjet një varieteti të grupeve të dhënash, metrikëve dhe eksperimenteve, ne demonstrojmë se CorEx prodhon temë që janë të krahasueshme në cilësi me a to të prodhuara nga variantet jo të mbikqyrura dhe gjysmë të mbikqyrura të LDA.', 'az': "Later Dirichlet Allocation (LDA) kimi n…ôz…ôriyy…ôtli modell…ôr m…ôs…ôl…ôl…ôrin modell…ôrind…ô meyv…ôlik g√∂st…ôrdikl…ôri halda, onlar √ßox √ßox detaylńĪ t…ôs…ôvv√ľrl…ôr v…ô hiperparametrl…ôrin m√ľ…ôyy…ôn edilm…ôsini ist…ôyirl…ôr. Bu modeli kompleksit…ô m…ôs…ôl…ôl…ôri yalnńĪz insan giriŇüini birl…ôŇüdirm…ôk √ľ√ß√ľn generik modell…ôri yaratmańüa √ßalńĪŇüńĪrlar. Biz d√ľz…ôltm…ô a√ßńĪqlamasńĪnńĪ (CorEx) tanńĪyńĪrńĪq, m…ôs…ôl…ônin modell…ôrin…ô alternatif bir metod g√∂st…ôririk ki, bunun …ôv…ôzind…ô m…ôlumat-teoriki frameworkl…ô …ôn √ßox informativ m…ôs…ôl…ôl…ôri √∂yr…ônir. Bu √ßer√ßive hiyerarŇüik v…ô yarńĪ-g√∂zl…ôyir geniŇül…ônm…ôy…ô t…ôbii edir, artńĪq modell…ôŇüdirm…ôyin ehtimallarńĪ olmadan. √Ėzellikle, s√∂z s…ôviyy…ôsi domeinin elmi CorEx i√ßind…ô ancor s√∂zl…ôr vasit…ôsil…ô fleksiyonla birl…ôŇüdirilebilir, m…ôs…ôl…ôl…ôrin ayrńĪlńĪqlńĪńüńĪ v…ô t…ôsirl…ôrini minimal insan intervenci il…ô t…ôŇükil ed…ô bil…ôr. Bir ne√ß…ô-ne√ß…ô veril…ôn qurńüular, metrikl…ôr v…ô eksperimentl…ôr arasńĪnda, CorEx'in LDA'nin m√ľ…ôyy…ôn edilm…ômiŇü v…ô yarńĪ-g√∂zl…ôm…ômiŇü variablarńĪ il…ô √ľr…ôkl…ônmiŇü m…ôs…ôl…ôl…ôr yaratdńĪńüńĪnńĪ g√∂st…ôririk.", 'ca': "Mentre que models generadors com la Latent Dirichlet Allocation (LDA) s'han demostrat fructuosos en la modelació temàtica, sovint requereixen suposicions detalladas i especificacions atentes dels hiperparamètres. Aquests problemes de complexitat només es compliquen quan intenten generalitzar els models generadors per incorporar la informació humana. Introduïm l'Explicació de Correlació (CorEx), un enfocament alternativ a la modelació de temes que no suposa un model de generació subjacente, i en canvi aprenem temes més informatius a través d'un marc teòric d'informació. This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional modeling assumptions.  En particular, el coneixement de domini de nivell de paraules pot ser incorporat flexiblement a la CorEx a través de paraules ancladas, permetent promoure la separabilitat del tema i la representació amb una mínima intervenció humana. A través de diversos conjunts de dades, mètriques i experiments, demostram que CorEx produeix temes que són comparables en qualitat a aquells produïts per variants no supervisats i semisupervisats de LDA.", 'bs': 'Iako su generični modeli poput Latent Dirichlet Allocation (LDA) dokazali plodno u modelima tema, često zahtijevaju detaljne pretpostavke i pažljive specifikacije hiperparametara. Takve probleme sa kompleksnošću modela su povezani samo kada se pokušavaju generalizirati generični modeli da bi uključili ljudski ulaz. Predstavljamo korelacijsko objašnjenje (CorEx), alternativni pristup modelima tema koji ne prima temeljni generativni model, a umjesto toga uči maksimalno informativne teme kroz informativni i teorijski okvir. Ovaj okvir prirodno generalizuje na hijerarhičke i polu-nadzorne proširenje bez dodatnih pretpostavki modela. Posebno, znanje domena riječi na razini može biti fleksibilno uključeno unutar CorEx kroz riječi čvorova, omogućavajući da se razdvajateljstvo i predstavljanje tema promoviraju sa minimalnom ljudskom intervencijom. Preko različitih seta podataka, metrika i eksperimenata, pokazujemo da CorEx proizvodi teme koje su usporedbene u kvaliteti onima koji su proizvodili neodređeni i polu-nadzorni varianti LDA-a.', 'cs': 'Generativní modely jako Latent Dirichletová alokace (LDA) se v tématickém modelování ukázaly jako plodné, často vyžadují detailní předpoklady a pečlivou specifikaci hyperparametrů. Takové problémy složitosti modelu se složí pouze při pokusu o zobecnění generativních modelů začlenění lidského vstupu. Představujeme korelační vysvětlení (CorEx), alternativní přístup k modelování témat, který nepředpokládá základní generační model, ale místo toho se učí maximálně informativní témata prostřednictvím informačně-teoretického rámce. Tento rámec se přirozeně zobecňuje na hierarchická a polovičně dohledovaná rozšíření bez dalších modelovacích předpokladů. Zejména znalosti domény na úrovni slova mohou být flexibilně začleněny do CorEx prostřednictvím kotevních slov, což umožňuje podporovat oddělitelnost a reprezentaci tématu s minimálním lidským zásahem. Napříč různými datovými sadami, metrikami a experimenty ukazujeme, že CorEx produkuje témata, která jsou kvalitně srovnatelná s těmi vytvářenými bez dohledu a polovičně dohledu variantami LDA.', 'et': 'Kuigi generatiivsed mudelid, nagu latent dirichlet allocation (LDA), on osutunud teemamodelleerimisel viljakaks, nõuavad nad sageli üksikasjalikke eeldusi ja hüperparameetrite hoolikat määratlemist. Sellised mudeli keerukuse küsimused ühendavad ainult siis, kui üritatakse generatiivseid mudeleid inimese sisendi kaasamiseks üldistada. Tutvustame korrelatsiooni selgitust (CorEx), alternatiivset lähenemisviisi teemade modelleerimisele, mis ei eelda aluseks olevat generatiivset mudelit, vaid õpib selle asemel maksimaalselt informatiivseid teemasid infoteoreetilise raamistiku kaudu. See raamistik üldistab loomulikult hierarhilisi ja pooljärelevalvega laiendusi ilma täiendavate modelleerimise eeldusteta. Eelkõige saab CorExis paindlikult integreerida sõnatasemel valdkonna teadmisi ankrusõnade kaudu, võimaldades edendada teemade eraldatavust ja esindamist minimaalse inimsekkumisega. Erinevate andmekogumite, mõõdikute ja katsete abil näitame, et CorEx toodab teemasid, mis on kvaliteedilt võrreldavad järelevalveta ja pooljärelevalveta LDA variantidega.', 'fi': 'Vaikka generatiiviset mallit, kuten Latent Dirichlet Allocation (LDA), ovat osoittautuneet hedelmällisiksi aihemallinnuksessa, ne vaativat usein yksityiskohtaisia oletuksia ja tarkkaa hyperparametrien määrittelyä. Tällaiset mallikompleksisuuden ongelmat muodostuvat vain, kun yritetään yleistää generatiivisia malleja ihmisen panoksen sisällyttämiseksi. Esittelemme korrelaatioselityksen (CorEx), vaihtoehtoisen lähestymistavan aihemallinnukseen, joka ei oleta taustalla olevaa generatiivista mallia, vaan oppii maksimaalisesti informatiivisia aiheita informaatioteoreettisen kehyksen avulla. Tämä viitekehys yleistyy luonnollisesti hierarkkisiin ja puolivalvottuihin laajennuksiin ilman muita mallinnusoletuksia. Erityisesti sanatason verkkotieto voidaan liittää joustavasti CorExiin ankkurisanan avulla, jolloin aihepiirien erottuvuutta ja esitystä voidaan edistää mahdollisimman vähän inhimillisiä toimia. Eri tietokokonaisuuksissa, mittareissa ja kokeissa osoitetaan, että CorEx tuottaa aiheita, jotka ovat laadultaan verrattavissa LDA:n valvomattomien ja puolivalvottujen varianttien tuottamiin aiheisiin.', 'jv': 'Speaking Daerah model sing komplikasi uwong nesalaman apa-nesalaung Awake dhéwé nyebutaké Cubism iki dadi sa akeh genelisis kanggo nyeasakno karo akeh-akeh lansangan karo akeh model sing bisa ngono nggawe model tambah. @item:checkbox Dino sampeyan dataset, metarike lan surihan, kita ngomongke ngomongke cerêter', 'ha': "Alhãli kuwa misãlai na General kamar Allocation ya Latent Dirikla (LDA) sun jarraba 'ya'yan 'ya'yan mai kyau a cikin shirin madaidaici, suna ƙayyade zato da kuma ana ƙayyade ƙayyade masu tsari da wajen ƙayyade. @ action: button Tuna ƙara shirin Cikakken CorRelation (CorEx), wata matsayi mai canza zuwa misalin madaidaici wanda bai ɗauki wani motsi na ƙarani ba, kuma yana karanta madaidaita masu labanci a ƙaranci a bakin wani firam na-teori. Wannan firam na ɗabi'a ɗabi'a, yana mai nuna zuwa faɗaɗari masu hiera da sakan-wato, kuma bã da wasu zato masu motsi. A kan da ƙayyade, za'a shigar da ilmi na maganar-daraja a cikin CorEx ko kuma a yarda da rarraba madaidaici da kuma a gabatar da shi a tsakanin mutum ƙarami. Ko cikin wasu mutane da aka tsare, metric da aka samu, Muna nuna ko CorEx ke sami wasu madaidaita masu daidaita da waɗand a aka samar da su na tsari da kuma an yi-tsaro da aka canza variants na LDA.", 'sk': 'Generativni modeli, kot je Latent Dirichlet Allocation (LDA), so se izkazali za plodne pri modeliranju teme, vendar pogosto zahtevajo podrobne predpostavke in skrbno specifikacijo hiperparametrov. Takšna kompleksna vprašanja modela se pojavljajo le, ko poskušamo posplošiti generativne modele za vključitev človeškega vnosa. Predstavljamo Korelacijsko pojasnjevanje (CorEx), alternativni pristop k modeliranju teme, ki ne predpostavlja osnovnega generativnega modela, temveč se uči maksimalno informativne teme skozi informacijsko-teoretični okvir. Ta okvir se seveda posploši na hierarhične in polnadzorovane razširitve brez dodatnih predpostavk modeliranja. Zlasti znanje na ravni besed je mogoče prožno vključiti v CorEx prek sidrnih besed, kar omogoča spodbujanje ločljivosti in reprezentacije teme z minimalnim človeškim posredovanjem. V različnih naborih podatkov, meritvah in poskusih dokazujemo, da CorEx proizvaja teme, ki so po kakovosti primerljive s tistimi, ki jih proizvajajo nenadzorovane in polnadzorovane različice LDA.', 'he': 'While generative models such as Latent Dirichlet Allocation (LDA) have proven fruitful in topic modeling, they often require detailed assumptions and careful specification of hyperparameters.  בעיות מסובכות דוגמניות כאלה מתרכבות רק כשמנסים לגנרליזציה דוגמניות דוגמניות כדי להכיל תוכנית אנושית. אנחנו מציגים הסבר הקשר (CorEx), גישה אלטרנטיבית לדוגמה נושאית שלא מניחה דוגמה דולרית בסיסית, ובמקום זה לומד נושאים מידעיים באופן מקסימלי דרך סגרת מידע-תיאורטית. המסגרת הזאת מתפשטת באופן טבעי למרחבות הייררכיות וחצי-מפקחות ללא הנחות נוספות לדוגמה. במיוחד, ידע על רמת המילים יכול להיות מעורב בצורה גמישה בתוך CorEx באמצעות מילים עוגנים, מאפשר להפריד נושא ויציגה לקדם עם התערבות אנושית מינימלית. באמצעות מגוון של קבוצות נתונים, מטריות, וניסויים, אנחנו מראים שקוראקס מייצר נושאים שאיכות שווה לאותם שנוצרים על ידי שונים בלתי מעוקבים וחצי מעוקבים אחריהם של LDA.', 'bo': 'While generative models such as Latent Dirichlet Allocation (LDA) have proven fruitful in topic modeling, they often require detailed assumptions and careful specification of hyperparameters. Such model complexity issues only compound when trying to generalize generative models to incorporate human input. ང་ཚོས་གནད་དོན་གསལ་བཤད་དང་ངོས་འཛིན་བྱེད་པའི་གནད་དོན་བཟོ་བྱེད་ཀྱི་མ་ལག་ལེན་པ་ཞིག་ལ་སྤྲོད་ཀྱི་མི་འདུག This framework naturally generalizes to hierarchical and semi-supervised extensions with no additional modeling assumptions. In particular, word-level domain knowledge can be flexibly incorporated within CorEx through anchor words, allowing topic separability and representation to be promoted with minimal human intervention. Across a variety of datasets, metrics, and experiments, we demonstrate that CorEx produces topics that are comparable in quality to those produced by unsupervised and semi-supervised variants of LDA.'}
