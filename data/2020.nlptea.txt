{'en': 'Integrating BERT and Score-based Feature Gates for Chinese Grammatical Error Diagnosis', 'ar': 'دمج BERT والبوابات القائمة على النقاط لتشخيص الأخطاء النحوية الصينية', 'pt': 'Integrando BERT e portas de recursos baseados em pontuação para diagnóstico de erros gramaticais em chinês', 'es': 'Integración de puertas de características basadas en la puntuación y BERT para el diagnóstico de errores gramaticales chinos', 'fr': 'Intégration du BERT et des fonctionnalités basées sur les scores pour le diagnostic des erreurs grammaticales chinoises', 'ja': '中国語文法エラー診断のためのBERTとスコアベースの機能ゲートの統合', 'zh': '集成 BERT 基于分数之门,施于中文语法错误诊断', 'hi': 'चीनी व्याकरणिक त्रुटि निदान के लिए BERT और स्कोर-आधारित फीचर गेट्स को एकीकृत करना', 'ru': 'Интеграция BERT и Score-based Feature Gates для китайской грамматической диагностики ошибок', 'ga': 'Comhtháthú Geataí Gné BERT agus Scórbhunaithe le haghaidh Diagnóisiú Earráide Gramadaí na Síne', 'el': 'Ενσωματώνοντας πύλες χαρακτηριστικών με βάση το σκορ για την κινεζική γραμματική διάγνωση σφαλμάτων', 'hu': 'BERT és Score-alapú funkciókapuk integrálása a kínai nyelvtani hibadiagnosztizáláshoz', 'ka': 'BERT და სუპორტიური ფუტური გეტურის ინტერგურაცია ჩინეთის გრამატური შეცდომა დიანოზისთვის', 'it': 'Integrazione di BERT e Funzioni Gates basati su Score per la diagnosi degli errori grammaticali cinesi', 'kk': 'BERT және Score- негіздеген Қытай граматикалық қатесін диагнозиялау үшін мүмкіндік терезелерін біріктіру', 'mk': 'Интегрирање на BERT и резултати за дијагноза на кинеска граматска грешка', 'lt': 'BERT ir rezultatais pagrįstų savybių vartų integravimas Kinijos gramatinėms klaidoms diagnozuoti', 'ms': 'Menyempurnakan Gerbang Feature Berasas BERT dan Skor untuk Diagnosis Ralat Grammatik Cina', 'ml': 'Name', 'mt': 'L-integrazzjoni tal-BERT u tal-Portijiet tal-Karatteristiċi bbażati fuq il-Punteġġ għad-Dijanjożi ta’ Żbalji Grammatiċi Ċiniżi', 'mn': 'BERT болон Score-based Feature Gates-ийг Хятад Грамматикийн Алдаа Диагнозын тулд нэгтгэх', 'pl': 'Integracja BERT i bram funkcji opartych na wynikach do diagnostyki błędów gramatycznych w Chinach', 'no': 'Integrerer BERT- og poengbaserte funksjonsportar for kinesisk grammatisk feildiagnose', 'ro': 'Integrarea BERT și a porților de caracteristici bazate pe scoruri pentru diagnosticul erorilor gramaticale chinezești', 'sr': 'Интеграцијујући Врате функција базиране на БРТ и Поценке за китајску граматичну диагнозију Грешке', 'si': 'BERT සහ Score-based Featuring Gates සම්බන්ධ කරනවා චීනි ග්\u200dරාමාටිකාලික වැරදි සංඥානය සඳහා', 'so': 'Isku qabsashada Gates-tababar ee BERT iyo Score-based tababarida khaladda fasaxa China', 'sv': 'Integrering av BERT och poängbaserade funktionsportar för kinesisk grammatisk feldiagnos', 'ta': 'Name', 'ur': 'BERT اور Score-based Feature Gates کو چینی گرماٹیکل خطا دیاگنوزی کے لئے ترکیب کیا جاتا ہے', 'uz': 'Name', 'vi': 'KCharselect unicode block name Lý do ví dụ:', 'da': 'Integrering af BERT og scorebaserede funktionsporte til diagnosticering af kinesisk grammatisk fejl', 'nl': 'Integratie van BERT en score-gebaseerde feature gates voor Chinese grammaticale foutdiagnose', 'bg': 'Интегриране на функционни портали за диагностика на китайската граматична грешка', 'hr': 'Integracija BERT-a i kapija na osnovu rezultata za dijagnozu kineskih gramatičnih greška', 'id': 'Integrating BERT and Score-based Feature Gates for Chinese Grammatical Error Diagnosis', 'de': 'Integration von BERT und Score-basierten Feature Gates für die chinesische Grammatikfehlerdiagnose', 'ko': 'BERT와 점수의 특징을 바탕으로 중국어 문법 오류 진단에서의 통합', 'fa': 'جمع کردن دروازه\u200cهای ویژه\u200cهای بنیادی BERT و امتیاز برای شناسایی خطاهای گرماتیک چینی', 'sw': 'Kuunganisha BERT na Miango ya Tamko kwa ajili ya Kugundua Tatizo la Kichina', 'tr': 'BERT we Skor-dan Bu첵ruk Gatunlary 횉in챌e Grammatikal Hata tansi첵asy 체챌in birle힊tiril첵채r', 'af': 'Integrasie van BERT en Score- based Feature Gates vir Sjinese Grammatical Fout Diagnosies', 'sq': 'Integrimi i portave funksionale të BERT dhe me pikë për diagnozën kineze të gabimeve Gramatike', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'Ինտեգրելով BER-ը և գնահատականներով հիմնված ֆունկցիոնալ դարպասները Չինաստանի գրամմատիկ սխալների ախտորոշության համար', 'bs': 'Integracija BERT-a i kapija na osnovu rezultata za kinesku dijagnozu greške', 'az': 'Çin Gramatik Hata Diagnosisi üçün BERT və Score-based Feature Gates Integrating for Chinese Grammatical Error Diagnosis', 'bn': 'Name', 'cs': 'Integrace BERT a funkčních brán založených na skóre pro diagnostiku čínských gramatických chyb', 'ca': "Integrar BERT i porta de característiques basada en puntuacions per el diagnòstic d'errors gramàtics xinès", 'fi': 'BERT- ja pistepohjaisten ominaisuusporttien integrointi kiinalaisen kielioppivirheen diagnosointiin', 'et': 'BERT-i ja skooripõhiste funktsiooniväravate integreerimine hiina grammatiliste vigade diagnoosimiseks', 'jv': 'Backing', 'sk': 'Vključevanje BERT in vrat funkcij, ki temeljijo na ocenah, za kitajsko slovnično diagnozo napak', 'ha': 'KCharselect unicode block name', 'bo': 'Integrating BERT and Score-based Feature Gates for Chinese Grammatical Error Diagnosis', 'he': 'שילוב את השערים המבוססים על ציונים BERT ולאבחנת שגיאות גראמטיות סיניות'}
{'en': 'This paper describes our proposed model for the Chinese Grammatical Error Diagnosis (CGED) task in NLPTEA2020. The goal of CGED is to use natural language processing techniques to automatically diagnose Chinese grammatical errors in sentences. To this end, we design and implement a CGED model named BERT with Score-feature Gates Error Diagnoser (BSGED), which is based on the BERT model, Bidirectional Long Short-Term Memory (BiLSTM) and conditional random field (CRF). In order to address the problem of losing partial-order relationships when embedding continuous feature items as with previous works, we propose a gating mechanism for integrating continuous feature items, which effectively retains the partial-order relationships between feature items. We perform LSTM processing on the encoding result of the BERT model, and further extract the sequence features. In the final test-set evaluation, we obtained the highest F1 score at the detection level and are among the top 3 F1 scores at the identification level.', 'ar': 'تصف هذه الورقة نموذجنا المقترح لمهمة تشخيص الأخطاء النحوية الصينية (CGED) في NLPTEA2020. الهدف من CGED هو استخدام تقنيات معالجة اللغة الطبيعية لتشخيص الأخطاء النحوية الصينية تلقائيًا في الجمل. تحقيقا لهذه الغاية ، قمنا بتصميم وتنفيذ نموذج CGED يسمى BERT مع أداة تشخيص أخطاء بوابات النقاط (BSGED) ، والتي تعتمد على نموذج BERT ، والذاكرة ثنائية الاتجاه طويلة المدى (BiLSTM) والحقل العشوائي المشروط (CRF). من أجل معالجة مشكلة فقدان علاقات الترتيب الجزئي عند تضمين عناصر ميزة مستمرة كما هو الحال مع الأعمال السابقة ، نقترح آلية بوابة لدمج عناصر الميزات المستمرة ، والتي تحافظ بشكل فعال على علاقات الترتيب الجزئي بين عناصر الميزة. نقوم بإجراء معالجة LSTM على نتيجة التشفير لنموذج BERT ، واستخراج ميزات التسلسل بشكل أكبر. في التقييم النهائي لمجموعة الاختبار ، حصلنا على أعلى درجة F1 على مستوى الاكتشاف ، ونحن من بين أعلى 3 درجات في F1 على مستوى التعريف.', 'es': 'Este artículo describe nuestro modelo propuesto para la tarea de diagnóstico de errores gramaticales chinos (CGED) en NLPTEA2020. El objetivo del CGED es utilizar técnicas de procesamiento del lenguaje natural para diagnosticar automáticamente los errores gramaticales chinos en las oraciones. Para ello, diseñamos e implementamos un modelo CGED llamado BERT con Score-Feature Gates Error Diagnoser (BSGED), que se basa en el modelo BERT, Bidirectional Long Short-Short-Term Memory (BILSTM) y campo aleatorio condicional (CRF). Para abordar el problema de perder relaciones de orden parcial al incrustar elementos de función continua como en trabajos anteriores, proponemos un mecanismo de control para integrar elementos de función continuos, que retiene efectivamente las relaciones de orden parcial entre elementos de función. Realizamos el procesamiento LSTM en el resultado de codificación del modelo BERT y extraemos aún más las características de la secuencia. En la evaluación final del conjunto de pruebas, obtuvimos la puntuación más alta de F1 en el nivel de detección y estamos entre las 3 mejores puntuaciones de F1 en el nivel de identificación.', 'pt': 'Este artigo descreve nosso modelo proposto para a tarefa Chinese Grammatical Error Diagnosis (CGED) no NLPTEA2020. O objetivo do CGED é usar técnicas de processamento de linguagem natural para diagnosticar automaticamente erros gramaticais chineses em frases. Para tanto, projetamos e implementamos um modelo CGED denominado BERT com Score-feature Gates Error Diagnoser (BSGED), que é baseado no modelo BERT, Bidirectional Long Short-Term Memory (BiLSTM) e condicional random field (CRF). A fim de resolver o problema de perder relacionamentos de ordem parcial ao incorporar itens de recursos contínuos como em trabalhos anteriores, propomos um mecanismo de gating para integrar itens de recursos contínuos, que efetivamente retém os relacionamentos de ordem parcial entre itens de recursos. Realizamos o processamento LSTM no resultado da codificação do modelo BERT e extraímos ainda mais os recursos da sequência. Na avaliação final do conjunto de testes, obtivemos a pontuação F1 mais alta no nível de detecção e estamos entre as 3 melhores pontuações F1 no nível de identificação.', 'fr': "Cet article décrit notre modèle proposé pour la tâche de diagnostic des erreurs grammaticales chinoises (CGED) dans NLPTEA2020. L'objectif du CGED est d'utiliser des techniques de traitement du langage naturel pour diagnostiquer automatiquement les erreurs grammaticales chinoises dans les phrases. À cette fin, nous concevons et mettons en œuvre un modèle CGED nommé BERT avec Score-feature Gates Error Diagnoser (BSGED), qui est basé sur le modèle BERT, la mémoire bidirectionnelle à long terme (BilsTM) et le champ aléatoire conditionnel (CRF). Afin de résoudre le problème de la perte de relations d'ordre partiel lors de l'intégration d'éléments d'entités continues, comme dans les travaux précédents, nous proposons un mécanisme de porte pour intégrer des éléments de fonction continue, qui conserve efficacement les relations d'ordre partiel entre les éléments de fonction. Nous effectuons un traitement LSTM sur le résultat de codage du modèle BERT, puis extrayons les caractéristiques de la séquence. Lors de l'évaluation finale de l'ensemble de tests, nous avons obtenu le score F1 le plus élevé au niveau de détection et nous sommes parmi les 3 meilleurs scores F1 au niveau d'identification.", 'ja': '本稿では、NLPTEA 2020における中国語文法エラー診断（ CGED ）タスクの提案モデルについて説明します。 CGEDの目標は、自然言語処理技術を使用して、文章の中国語文法の誤りを自動的に診断することです。 このために、BERTモデル、双方向長期記憶（ BiLSTM ）および条件付きランダムフィールド（ CRF ）に基づいて、スコア機能ゲートエラー診断器（ BSGED ）を備えたBERTという名前のCGEDモデルを設計および実装します。 これまでの作品のように連続特徴項目を埋め込む際に部分的な順序関係が失われる問題に対処するために、連続特徴項目を統合するためのゲーティング機構を提案し、特徴項目間の部分的な順序関係を効果的に保持する。 BERTモデルの符号化結果に対してLSTM処理を行い、さらにシーケンス特徴を抽出する。 最終的なテストセット評価では、検出レベルで最も高いF 1スコアを得ており、識別レベルでは上位3つのF 1スコアに入っています。', 'ru': 'В этой статье описывается наша предлагаемая модель для задачи китайской грамматической диагностики ошибок (CGED) в NLPTEA2020. Целью CGED является использование методов обработки естественного языка для автоматической диагностики китайских грамматических ошибок в предложениях. С этой целью мы разрабатываем и реализуем модель CGED под названием BERT с функцией Score Gates Error Diagnoser (BSGED), которая основана на модели BERT, двунаправленной долгосрочной краткосрочной памяти (BiLSTM) и условном случайном поле (CRF). Для решения проблемы потери отношений частичного порядка при встраивании непрерывных элементов признаков, как и в предыдущих работах, мы предлагаем механизм стробирования для интеграции непрерывных элементов признаков, который эффективно сохраняет отношения частичного порядка между элементами признаков. Мы выполняем обработку LSTM по результату кодирования модели BERT, и далее извлекаем признаки последовательности. В окончательной оценке тестового набора мы получили наивысший балл F1 на уровне обнаружения и вошли в тройку лучших баллов F1 на уровне идентификации.', 'zh': '本文引NLPTEA2020中汉语语法错误诊断(CGED)形势。 CGED者,用自然语言术以自语法错误也。 故设而为BERT者CGED为之BERT,双向长短期记(BiLSTM)随机场(CRF)。 嵌连项时失偏序关系,条上门控机,宜存其偏序关系。 吾于BERT之编码而LSTM之,更取其序。 于终测集评估,于检测级得最高F1分数,并于识级上排名前3位。', 'hi': 'यह पेपर NLPTEA2020 में चीनी व्याकरणिक त्रुटि निदान (CGED) कार्य के लिए हमारे प्रस्तावित मॉडल का वर्णन करता है। CGED का लक्ष्य वाक्यों में चीनी व्याकरणिक त्रुटियों का स्वचालित रूप से निदान करने के लिए प्राकृतिक भाषा प्रसंस्करण तकनीकों का उपयोग करना है। इस अंत के लिए, हम स्कोर-फीचर गेट्स एरर डायग्नोसिसर (बीएसजीईडी) के साथ बर्ट नामक एक सीजीईडी मॉडल को डिजाइन और कार्यान्वित करते हैं, जो बर्ट मॉडल, द्विदिश दीर्घकालिक अल्पकालिक मेमोरी (बीआईएलएसटीएम) और सशर्त यादृच्छिक क्षेत्र (सीआरएफ) पर आधारित है। पिछले कार्यों के साथ निरंतर सुविधा वस्तुओं को एम्बेड करते समय आंशिक-क्रम संबंधों को खोने की समस्या को हल करने के लिए, हम निरंतर फीचर आइटम को एकीकृत करने के लिए एक गेटिंग तंत्र का प्रस्ताव करते हैं, जो सुविधा आइटम के बीच आंशिक-क्रम संबंधों को प्रभावी ढंग से बनाए रखता है। हम BERT मॉडल के एन्कोडिंग परिणाम पर LSTM प्रसंस्करण करते हैं, और आगे अनुक्रम सुविधाओं को निकालते हैं। अंतिम परीक्षण-सेट मूल्यांकन में, हमने पता लगाने के स्तर पर उच्चतम एफ 1 स्कोर प्राप्त किया और पहचान स्तर पर शीर्ष 3 एफ 1 स्कोर में से एक हैं।', 'ga': 'Déanann an páipéar seo cur síos ar an múnla atá molta againn do thasc Diagnóisithe Earráide Gramadaí na Síne (CGED) in NLPTEA2020. Is é sprioc CGED teicnící próiseála teanga nádúrtha a úsáid chun earráidí gramadaí na Síne in abairtí a dhiagnóiseadh go huathoibríoch. Chun na críche sin, déanaimid múnla CGED darb ainm BERT a dhearadh agus a chur i bhfeidhm le Diagnóiseoir Earráide Scór-ghné Gates (BSGED), atá bunaithe ar mhúnla BERT, Cuimhne Gearrthéarmach Déthreo Déthreo (BiLSTM) agus réimse randamach coinníollach (CRF). Chun dul i ngleic leis an bhfadhb a bhaineann le caidreamh páirt-ordaithe a chailleadh agus míreanna gné leanúnacha á neadú againn mar a rinneadh le hoibreacha roimhe seo, molaimid meicníocht geataithe chun míreanna gné leanúnacha a chomhtháthú, rud a choinníonn go héifeachtach na caidrimh pháirt-ordaithe idir míreanna gné. Déanaimid próiseáil LSTM ar thoradh ionchódaithe shamhail BERT, agus bainimid amach na gnéithe seichimh a thuilleadh. Sa mheasúnú trialach deiridh, fuaireamar an scór F1 is airde ag an leibhéal braite agus tá muid i measc na 3 scóir is airde F1 ag an leibhéal aitheantais.', 'el': 'Αυτή η εργασία περιγράφει το προτεινόμενο μοντέλο για την εργασία Διαγνωσής Γραμματικού Σφάλματος της Κίνας στο NLPTEA2020. Στόχος του είναι η χρήση τεχνικών επεξεργασίας φυσικής γλώσσας για την αυτόματη διάγνωση των κινεζικών γραμματικών σφαλμάτων σε προτάσεις. Για το σκοπό αυτό, σχεδιάζουμε και υλοποιούμε ένα μοντέλο που ονομάζεται με διαγνωστικό σφάλμα πυλών (το οποίο βασίζεται στο μοντέλο και το πεδίο υπό όρους τυχαίου πεδίου (με δυνατότητα ανάλυσης). Προκειμένου να αντιμετωπιστεί το πρόβλημα της απώλειας σχέσεων μερικής διαταγής κατά την ενσωμάτωση συνεχών στοιχείων χαρακτηριστικών όπως και με προηγούμενες εργασίες, προτείνουμε έναν μηχανισμό ενσωμάτωσης συνεχών στοιχείων χαρακτηριστικών, ο οποίος διατηρεί αποτελεσματικά τις σχέσεις μερικής διαταγής μεταξύ στοιχείων χαρακτηριστικών. Εκτελούμε επεξεργασία στο αποτέλεσμα κωδικοποίησης του μοντέλου και εξάγουμε περαιτέρω τα χαρακτηριστικά ακολουθίας. Στην τελική αξιολόγηση του σετ δοκιμών, λάβαμε την υψηλότερη βαθμολογία στο επίπεδο ανίχνευσης και συγκαταλέγονται στις κορυφαίες βαθμολογίες 3 στο επίπεδο αναγνώρισης.', 'hu': 'Ez a tanulmány bemutatja a kínai nyelvtani hibadiagnosztika (CGED) feladat javasolt modelljét az NLPTEA2020-ban. A CGED célja, hogy természetes nyelvfeldolgozási technikákat használjon a kínai nyelvtani hibák automatikus diagnosztizálására a mondatokban. Ebből a célból egy BERT nevű CGED modellt tervezünk és valósítunk meg, amely a BERT modell, a kétirányú rövid távú memória (BiLSTM) és a feltételes véletlenszerű mező (CRF) alapján alapul. A folyamatos funkcióelemek beágyazásakor történő részrendes kapcsolatok elveszítésének problémáját a korábbi munkákhoz hasonlóan javasoljuk a folyamatos funkcióelemek integrálására szolgáló átjáró mechanizmust, amely hatékonyan megtartja a funkcióelemek közötti részrendes kapcsolatokat. LSTM feldolgozást végzünk a BERT modell kódolási eredményén, és tovább bontjuk ki a szekvencia funkciókat. A végső tesztkészlet-értékelés során megszereztük a legmagasabb F1 pontszámot az észlelési szinten és a legjobb 3 F1 pontszám közé tartozunk az azonosítási szinten.', 'ka': 'ამ კაურაში ჩვენი საზოგადომის მოდელს NLPTEA2020-ში ჩინეთი გრამატიკური შეცდომის დიანოზაციის (CGED) დავაწერა. CGED-ის მიზეზი არის ჩინეთი გრამიკალური შეცდომების ავტომატურად დიონგიზონტიკური შეცდომების გამოყენება. ამ დასავლეთისთვის, ჩვენ დავყენებთ და ინტერმისტურებთ CGED მოდელის სახელით BERT- ს შეცდომა დაკავშირების დიანოზერით (BSGED), რომელიც BERT მოდელის ბაზეულია, ორდირექციონალური მარტი მეხსიერით (BiLSTM) და კონდიციონალური ამ პრობლემაში, როდესაც წინა მუშაობით მოქმედებით, ჩვენ მივიღებთ მოქმედებითი მოქმედებით, როდესაც წინა მუშაობით მოქმედებით, მოქმედებით მუშაობით მოქმედებითი მოქმედებითი ელემენტების ინტერგურაციის ჩვენ LSTM პროცესის გავაკეთებთ BERT მოდელის კოდირების შედეგი და დამატებით შედეგი ფუნქციების გამოყენება. საბოლოო ტესტის შესაბამისათვის, ჩვენ მივიღეთ უფრო დიდინტიფიკაციის დონეში ყველაზე დიდინტიფიკაციის შესაბამისათვის და ჩვენ ვართ საბოლოო F1 შესაბამისათვის დონეში.', 'it': "Questo articolo descrive il modello proposto per l'attività CGED (Chinese Grammatical Error Diagnosi) in NLPTEA2020. L'obiettivo di CGED è quello di utilizzare tecniche di elaborazione del linguaggio naturale per diagnosticare automaticamente errori grammaticali cinesi nelle frasi. A tal fine, progettiamo e implementiamo un modello CGED chiamato BERT con Score-feature Gates Error Diagnostier (BSGED), basato sul modello BERT, sulla memoria bidirezionale a breve termine (BiLSTM) e sul campo casuale condizionale (CRF). Al fine di affrontare il problema della perdita di relazioni di ordine parziale quando si incorporano elementi di funzionalità continue come per i lavori precedenti, proponiamo un meccanismo di gating per integrare elementi di funzionalità continue, che mantiene efficacemente le relazioni di ordine parziale tra elementi di funzionalità. Eseguiamo l'elaborazione LSTM sul risultato della codifica del modello BERT ed estraiamo ulteriormente le funzioni di sequenza. Nella valutazione finale del set di test, abbiamo ottenuto il punteggio F1 più alto a livello di rilevamento e siamo tra i primi 3 punteggi F1 a livello di identificazione.", 'lt': 'Šiame dokumente aprašomas mūsų siūlomas Kinijos Gramatinės klaidų diagnozės (CGED) uždavinio NLPTEA2020 modelis. The goal of CGED is to use natural language processing techniques to automatically diagnose Chinese grammatical errors in sentences.  Šiuo tikslu sukuriame ir įgyvendiname CGED model į BERT su taškų savybių vartų klaidų diagnozatoriu (BSGED), kuris grindžiamas BERT modeliu, dvikryptiniu ilgalaikiu prisiminimu (BiLSTM) ir sąlyginiu atsitiktiniu lauku (CRF). Siekiant išspręsti problem ą, susijusią su dalinių santykių praradimu įtraukiant nepertraukiamus požymius, kaip ir ankstesniuose darbuose, siūlome gating mechanizmą nepertraukiamų požymių integracijai, kuris veiksmingai išlaiko dalinių požymių santykius. Mes atliekame LSTM apdorojimą pagal BERT modelio kodavimo rezultatą ir toliau ištraukiame sekos charakteristikas. Galutiniame bandymų rinkinio vertinime mes pasiekėme didžiausią F1 tašką aptikimo lygiu ir esame tarp didžiausių 3 F1 taškų identifikavimo lygiu.', 'kk': 'Бұл қағаз NLPTEA2020 тапсырмасының Кытайша граматикалық қателер диагнозиясы (CGED) тапсырмасының үлгісін анықтайды. CGED мақсаты - табиғлық тілдерді өңдеу техникаларын Қытай грамматикалық қателерді сөйлемелерде автоматты түрде диагностикациялау үшін қолдану. Бұл үшін біз BERT деген CGED үлгісін құрастырып орындаймыз. Бұл BERT үлгісіне негізделген, екі бағытты ұзын қысқа уақыт жады (BiLSTM) және шарттардың кездейсоқ өрісіне негізделген CGED үлгісін орындаймыз. Бірінші жұмыс істерін ендіру үшін бөлшекті реттік қатынастарын жоғалу мәселесін өзгерту үшін, біз бұрынғы жұмыс істерінде тұрақты мүмкіндіктерді ендіру механизмін ұсынамыз. Бұл мүмкіндіктер арасындағы бөл Біз BERT үлгісінің кодтамасының нәтижесін LSTM процесін орындап, келесі реттеу мүмкіндіктерін тарқатып тастаймыз. Соңғы сынақтар жинағында, анықтау деңгейіндегі ең жоғары F1 деңгейінде болып, идентификациялау деңгейіндегі жоғары 3 F1 деңгейінде болып тұрмыз.', 'mk': 'Овој документ го опишува нашиот предложен модел за кинеската дијагноза на граматска грешка (CGED) во NLPTEA2020. Целта на ЦГЕД е да се користат природни техники за процес на јазик за автоматска дијагностика на кинеските граматички грешки во речениците. За ова, дизајнираме и имплементираме модел CGED наречен BERT со дијагнозатор на грешки на портите со оценки (BSGED), кој е базиран на моделот BERT, двојно долго краткорочен меморија (BiLSTM) и условно случајно поле (CRF). Со цел да се реши проблемот со изгубувањето на односите со парцијален ред кога се вклучуваат континуирани елементи на карактеристики како и со претходните дела, предложуваме механизам за интеграција на континуирани елементи на карактеристики, кој ефикасно ги задржува односите со парцијален ред помеѓу елементите на каракт Ние го спроведуваме LSTM процесорот на кодирањето на резултатот на BERT моделот, и понатаму ги извадуваме карактеристиките на секвенцијата. Во последната проценка на тестот, ја добивме највисоката оценка на Ф1 на нивото на детекција и сме меѓу најдобрите 3 оценки на Ф1 на нивото на идентификација.', 'ms': 'Kertas ini menggambarkan model kami yang diusulkan untuk tugas Diagnosis Ralat Grammatik Cina (CGED) dalam NLPTEA2020. Tujuan CGED adalah menggunakan teknik pemprosesan bahasa semulajadi untuk mendiagnosis secara automatik ralat grammatik Cina dalam kalimat. Untuk tujuan ini, kami merancang dan melaksanakan model CGED bernama BERT dengan Pengesan Ralat Gates (BSGED), yang berdasarkan model BERT, Ingatan Panjang Berarah (BiLSTM) dan medan rawak bersyarat (CRF). Untuk mengatasi masalah kehilangan hubungan tertib-bahagian bila memasukkan item fitur terus menerus seperti pada kerja sebelumnya, kami cadangkan mekanisme gating untuk mengintegrasikan item fitur terus menerus, yang secara efektif menyimpan hubungan tertib-bahagian diantara item fitur. Kami melakukan proses LSTM pada hasil pengekodan model BERT, dan mengekstrak lebih lanjut ciri-ciri urutan. Dalam penilaian setuju terakhir, kami mendapat skor F1 tertinggi pada tahap pengesan dan berada di antara skor F1 tertinggi pada tahap pengenalan.', 'mt': 'Dan id-dokument jiddeskrivi l-mudell propost tagħna għall-kompitu tad-Dijanjożi ta’ Żbalji Grammatiċi Ċiniżi (CGED) f’NLPTEA2020. The goal of CGED is to use natural language processing techniques to automatically diagnose Chinese grammatical errors in sentences.  Għal dan il-għan, a ħna niddisinjaw u nimplimentaw mudell CGED imsejjaħ BERT b’Dijanjostikatur ta’ Żbalji tal-Gates b’Karatteristiċi ta’ Punteġġ (BSGED), li huwa bbażat fuq il-mudell BERT, Memorja Bidirezzjonali fuq terminu qasir (BiLSTM) u kamp kondizzjonali aleatorju (CRF). Sabiex nindirizzaw il-problem a tat-telf ta’ relazzjonijiet ta’ ordni parzjali meta jiġu inkorporati elementi ta’ karatteristiċi kontinwi bħal f’xogħlijiet preċedenti, nipproponu mekkaniżmu ta’ gating għall-integrazzjoni ta’ elementi ta’ karatteristiċi kontinwi, li effettivament iżomm ir-relazzjonijiet ta’ ordni parzjali bejn elementi ta’ karatteristiċi. Aħna nagħmlu l-ipproċessar LSTM fuq ir-riżultat tal-kodifikazzjoni tal-mudell BERT, u neħħew aktar il-karatteristiċi tas-sekwenza. Fl-evalwazzjoni finali tas-sett tat-testijiet, kisbu l-ogħla punteġġ F1 fil-livell ta’ detezzjoni u jinsabu fost l-ogħla 3 punteġġi F1 fil-livell ta’ identifikazzjoni.', 'ml': 'ഈ പത്രത്തില്\u200d NLPTEA2020-ല്\u200d ചൈനീസ് ഗ്രാമാറ്റിക്കല്\u200d പിശക് ഡിയോഗിഷന്\u200dറെ (സിജിഡി) ജോലിയുടെ പ്രൊദ്ദേശിച്ച മോഡല്\u200d  സിജിഡിന്റെ ലക്ഷ്യം സ്വാഭാവ ഭാഷ പ്രവര്\u200dത്തിപ്പിക്കുന്ന സാങ്കേതികമായി ചൈനീസ് ഗ്രാമാറ്റിക്കല്\u200d തെറ്റുകള്\u200d പരിചയപ ഈ അവസാനത്തിനു വേണ്ടി നാം ബെര്\u200dട്ടിന്റെ പേരില്\u200d ബോര്\u200dട്ട് എന്ന ഒരു സിജിഡി മോഡല്\u200d പ്രവര്\u200dത്തിപ്പിക്കുകയും ചെയ്യുന്നു. അത് ബെര്\u200dട്ടി മോഡല്\u200d, ബൈഡഡിയല്\u200d ലോങ്ങ് ചെറുതായ മെമ്മറി ( നിലനില്\u200dക്കുന്ന വിശിഷ്ടമുള്ള വസ്തുക്കള്\u200d മുമ്പ് പ്രവര്\u200dത്തിക്കുമ്പോള്\u200d പാര്\u200dട്ടിക്കല്\u200d ബന്ധങ്ങള്\u200d നഷ്ടപ്പെടുന്നതിനുള്ള പ്രശ്നത്തില്\u200d ഞങ്ങള്\u200d ഒരു ഗെറ്റിങ് മ ബെര്\u200dട്ടി മോഡലിന്റെ കോഡിങ്ങിന്റെ ഫലം നമ്മള്\u200d LSTM പ്രവര്\u200dത്തിപ്പിക്കുന്നു, പിന്നീട് സെക്കന്\u200dസ് വിശേഷതകള്\u200d പ അവസാനത്തെ പരീക്ഷണസെറ്റ് വിലാസങ്ങളില്\u200d, കണ്ടെത്തുന്നതിന്റെ ഏറ്റവും വലിയ എഫ്\u200c1 സ്കോര്\u200d ഞങ്ങള്\u200dക്ക് ലഭിച്ചു. തിരിച്ചറിയാനുള', 'mn': 'Энэ цаас NLPTEA2020 дахь Хятадын грамматикийн алдаа гаргах (CGED) ажлын загварын загварыг тайлбарладаг. CGED-ын зорилго нь Хятад грамматикийн алдаа өгүүлбэрт автоматаар оношлох байгалийн хэл үйлдвэрлэх техникуудыг ашиглах юм. Энэ төгсгөлд бид Score-feature Gates Error Diagnoser (BSGED) гэдэг CGED загварыг бүтээж, үйлдвэрлэж, үүнийг BERT загвар дээр суурилуулсан, хоёр загвар богино хугацааны Memory (BiLSTM) болон шаардлагатай санамсаргүй талбар (CRF) гэдэг загвар хийдэг. Өмнөх үйл ажиллагаатай адилаар үргэлжлүүлэх үйл ажиллагааны холбоонуудыг алдахын тулд бид үргэлжлүүлэх үйл ажиллагааны холбоонуудыг нэгтгэх механизмийг санал болгоно. Энэ нь үргэлжлүүлэх үйл ажиллагааны холбоонуудын хэсэг хэсэг хэсэ Бид БЕРТ загварын кодлогын үр дүн дээр LSTM процесс хийж, дарааллаар дарааллаар дамжуулах боломжтой. Сүүлийн туршилтын үнэлгээнд бид F1-ийн хамгийн өндөр тоог олж мэдэх түвшинд авсан бөгөөд бид тодорхойлолтын түвшинд 3 F1-ийн хамгийн өндөр тоог авсан.', 'no': 'Denne papiret beskriver vår foreslått modell for det kinesiske grafiske feildiagnosen (CGED) i NLPTEA2020. Målet til CGED er å bruka naturspråkkhandteringsteknikk for å automatisk diagnossera kinesiske grammatiske feil i setningar. I denne slutten design and implement a CGED model named BERT with Score-feature Gates Error Diagnoser (BSGED), which is based on the BERT model, Bidirectional Long-Term Memory (BiLSTM) and conditional random field (CRF). For å handtera problemet med å mista delvis rekkefølgjande forhold når det innebygger kontinuerlege funksjonskapslar som med førre arbeid, foreslår vi ein gating-mekanisme for å integrera kontinuerlege funksjonskapslar, som faktisk beholder dei delvis rekkefølgjande forhold mellom funksjonskapslar. Vi utfører LSTM-prosessering på kodingsresultatet av BERT-modellen, og ekstraherer sekvensfunksjonane. I den siste testsettevalueringa har vi fått den høgste F1- poeng på oppdagingsnivået og er blant de øvste 3 F1- poeng på identifikasjonsnivået.', 'pl': 'Niniejszy artykuł opisuje nasz proponowany model zadania Chińskiej diagnostyki błędów gramatycznych (CGED) w NLPTEA2020. Celem CGED jest wykorzystanie technik przetwarzania języka naturalnego do automatycznej diagnozowania błędów gramatycznych chińskich w zdaniach. W tym celu projektujemy i wdrażamy model CGED o nazwie BERT z funkcją Score-feature Gates Error Diagnoser (BSGED), który opiera się na modelu BERT, dwukierunkowej długiej pamięci krótkoterminowej (BiLSTM) oraz warunkowym polu losowym (CRF). Aby rozwiązać problem utraty relacji częściowo-porządkowych podczas osadzania elementów ciągłych, jak w przypadku poprzednich prac, proponujemy mechanizm gating do integracji elementów ciągłych funkcji, który skutecznie zachowuje relacje częściowo-porządkowych pomiędzy elementami funkcji. Wykonujemy przetwarzanie LSTM na wyniku kodowania modelu BERT, a następnie wyodrębniamy cechy sekwencji. W końcowej ocenie zestawu testowego uzyskaliśmy najwyższy wynik F1 na poziomie detekcji i znajdujemy się wśród najlepszych wyników 3 F1 na poziomie identyfikacji.', 'ro': 'Această lucrare descrie modelul nostru propus pentru activitatea Chinese Grammatical Error Diagnostic (CGED) în NLPTEA2020. Scopul CGED este de a utiliza tehnici de procesare a limbajului natural pentru a diagnostica automat erorile gramaticale chinezești în propoziții. În acest scop, proiectăm și implementăm un model CGED numit BERT cu scor-feature Gates Error Diagnostier (BSGED), care se bazează pe modelul BERT, bidirecțional Long-Term Memory (BiLSTM) și câmpul aleatoriu condiționat (CRF). Pentru a rezolva problema pierderii relațiilor parțiale de ordine atunci când încorporează elemente de caracteristică continuă ca și lucrările anterioare, propunem un mecanism de gating pentru integrarea elementelor de caracteristică continuă, care păstrează efectiv relațiile de ordine parțială dintre elementele de caracteristică. Efectuăm procesarea LSTM pe rezultatul codării modelului BERT și extragem în continuare caracteristicile secvenței. În evaluarea finală a setului de teste, am obținut cel mai mare scor F1 la nivel de detecție și suntem printre primele 3 scoruri F1 la nivel de identificare.', 'sr': 'Ovaj papir opisuje naš predloženi model za zadatak kineskog gramatičkog dijagnoza greške (CGED) u NLPTEA2020. Cilj CGED je koristiti prirodne tehnike obrade jezika kako bi automatski dijagnosticirali kineske gramatičke greške u rečenicama. Za taj cilj, dizajniramo i implementiramo model CGED po imenu BERT sa dijagnosorom greške Gates Error (BSGED), koji je zasnovan na modelu BERT, dvosmjernom dugoročnom pamćenju (BiLSTM) i uslovnom slučajnom polju (CRF). Da bi se riješili problem gubitka delovih redovnih odnosa kada uključujemo kontinualne funkcije kao i sa prethodnim radovima, predlažemo mehanizam prikupljanja za integraciju kontinualnih elementa funkcija, koji efektivno zadržava delovi redovne odnose između elementa funkcija. Izvodimo LSTM obradu na rezultat kodiranja BERT modela i dalje izvlačimo karakteristike sekvence. U konačnoj procjeni testova, dobili smo najviši rezultat F1 na nivou detekcije i bili smo među najvišim rezultatima 3 F1 na nivou identifikacije.', 'si': 'මේ පැත්තේ අපේ ප්\u200dරයෝජනය විස්තර කරන්නේ චීනි ග්\u200dරාමාටිකාලික වැරදි සංඥානය (CGED) කාර්යය NLPTE2020 වල. CGED ලක්ෂණය තමයි ස්වභාවික භාෂාව ප්\u200dරක්\u200dරියාත්මක ව්\u200dයාප්\u200dතිකාරය භාවිත කරන්න චීනි ග්\u200dරාමාත්මක වැරද මේ අවසානයෙන්, අපි ස්කෝර්-විශේෂතාවක් ගේට්ස් විශේෂකය (BSGED) එක්ක CGED මොඩේලයක් සැලසුම් කරනවා, ඒක BERT මොඩේලයේ අධාරණය කරලා තියෙනවා, බිදිරික්ෂිත ලොක ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය සම්බන්ධතාවක් නැතිවීම සඳහා ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය කරන්න, අපි ප්\u200dරශ්නය කරනවා ප්\u200dරශ්න අපි LSTM පරීක්ෂණය කරනවා BERT මෝඩේලයේ සංකේතනයේ ප්\u200dරතිචාරයේ පරීක්ෂණය සඳහා, ඊටපස්සේ පරීක්ෂණය අවශ්\u200d අන්තිම පරීක්ෂණ සෙට් විශ්ලේෂණයේ අපි පරීක්ෂණා ස්ථානයේ උඩ F1 ස්කෝර් ගත්තා, පරීක්ෂණා ස්ථානයේ ඉහලම F1 ස්කෝ', 'so': "Kanu wuxuu ku qoran yahay modelkeen la soo jeeday ee ku saabsan baaritaanka khaladda ee China (CGED) shaqada NLPTEA2020. Ujeedada CGED waa in lagu isticmaalo teknikada baaritaanka luuqada dabiicadda ah si ay automatic u ogaato qalabka grammatika ee Shiino. Taas darteed waxaynu u qoraynaa iyo waxaynu soo dejinaynaa model CGED oo la magacaabay BERT with Score-feature Gates Error Diagnoser (BSGED), kaas oo ku saleysan BERT model, Bidirectional Long Short-Term Memory (BiLSTM) iyo field xaalad la'aan ah (CRF). In order to address the problem of losing partial-order relationships when embedding continuous feature items as with previous works, we propose a gating mechanism for integrating continuous feature items, which effectively retains the partial-order relationships between feature items.  Waxaynu sameynaa baaritaanka LSTM oo ku saabsan qaababka codsiga ee BERT, waxaana kaloo soo saarnaa qalabka dabaqa. Qiimeynta ugu dambeysay ee imtixaanka, waxaan helay heerka ugu sarreeya ee F1, waxaana ka mid ah kooxaha aqoonsiga 3 F1 ee ugu sareeya.", 'sv': 'Denna uppsats beskriver vår föreslagna modell för uppgiften Chinese Grammatical Error Diagnosis (CGED) i NLPTEA2020. Målet med CGED är att använda naturliga språkbehandlingstekniker för att automatiskt diagnostisera kinesiska grammatiska fel i meningar. För detta ändamål utformar och implementerar vi en CGED-modell som heter BERT med Score-feature Gates Error Diagnostier (BSGED), som är baserad på BERT-modellen, Bidirectional Long Short-Term Memory (BiLSTM) och villkorligt slumpfält (CRF). För att lösa problemet med att förlora partiella ordningsförhållanden vid inbäddning av kontinuerliga funktionsobjekt som med tidigare arbeten föreslår vi en gatingmekanism för att integrera kontinuerliga funktionsobjekt, som effektivt behåller partiella ordningsförhållanden mellan funktionsobjekt. Vi utför LSTM-bearbetning på BERT-modellens kodningsresultat och extraherar ytterligare sekvensfunktionerna. I den slutliga utvärderingen av testset fick vi högsta F1-poäng på detektionsnivå och är bland de 3 bästa F1-poängen på identifieringsnivå.', 'ta': 'இந்த தாள் NLPTEA2020-ல் சீனா சிக்கல் பிழை கண்டுபிடிப்பு (CGED) செயலின் முன்னிருப்பு மாதிரி விவரிக்கும். CGED குறிப்பு என்பது இயல்பான மொழி செயல்படுத்தும் தொழில்நுட்பத்தை பயன்படுத்த தானாகவே சீனம் வரையறை பிழைகளை வாக்கியங்களில இந்த முடிவிற்கு, நாம் BERT பெயர் ஒரு CGED மாதிரியை வடிவமைத்து இயக்குகிறோம் மற்றும் மதிப்பெண் குறிப்பிட்ட வாயில் பிழை கண்டுபிடிப்பான் (BSGED), BERT மாதிரியான, இருதிசை ந முந்தைய பண்புகளுடன் உள்ளிடும்போது பிரிவு வரிசையின் இணைப்புகளை இழக்கும் போது தொடர்ந்து கொள்ளும் பொழுது தொடர்ந்து செல்லும் பண்புகளுக்கு இடையே பிரிவு வரிச BERT மாதிரியின் குறியீட்டு முடிவில் LSTM செயல்படுத்தலை நாம் செயல்படுத்துகிறோம், மற்றும் தொடர் குணங்களை வெளி கடைசி சோதனை அமைப்பு மதிப்பில், கண்டுபிடிப்பு நிலையில் அதிகபட்ச F1 மதிப்பெண்ணை பெற்றோம் மற்றும் மேல் 3 F1 மதிப்புகளில் உள', 'ur': 'This paper describes our proposed model for the Chinese Grammatical Error Diagnosis (CGED) task in NLPTEA2020. CGED کا موقع یہ ہے کہ کلمات میں چین کی گراماتیکی خطاؤں کو اپنے ساتھ تشخیص دینے کے لئے طبیعی زبان پرینس کی تکنیک استعمال کریں. اس کے لئے ہم نے ایک CGED موڈل کی طراحی اور عملہ کریں جن کا نام BERT ہے اسکور-فوجیٹ گیٹ تغییر دیاگنوزر (BSGED) کے ساتھ، جو BERT موڈل پر بنیاد ہے، دوسری دئیرسیٹ لانگ ٹرمر مہمانی (BiLSTM) اور کنڈیسی ناقص فیلڈ (CRF) پر ہے۔ اس لئے کہ اگلوں کے کاموں کے ساتھ دائمی فکرتوں کو گھاٹ دینے کے لئے مشکل کو حل کرنے کے لئے، ہم ایک گٹینگ مکانیسم پیش کریں گے کہ ہمیشہ فکرتوں کو جمع کریں، جو فکرتوں کے درمیان حصہ-اورڈ رابطہ رکھتی ہے۔ ہم BERT موڈل کے اکنوڈینگ نتیجے پر LSTM پرسس کر رہے ہیں، اور اس سے زیادہ سفارش فرصت نکالتے ہیں. آخری امتحان سٹ کی ارزیابی میں، ہم نے اچھی F1 اسکور کو پہچان لیا تھا، اور ہم نے اچھی 3 F1 اسکور کے درمیان پہچان لیا تھا.', 'uz': 'Bu hujjat NLPTEA2020 yildagi Xitoycha grammatikal xato diagnosti (CGED) vazifasini anglatadi. Name Bu yerda biz BERT (BSGED), BERT modeli, BiLSTM (BiLSTM) va hodisa Tasodifiy maydoni asosida boʻlgan BERT modeli bilan ishga tushirish va ishga tushirish. @ info: whatsthis Biz BERT modelining kodlash natijasini bajaramiz va cheksiz imkoniyatlarini bajaramiz. Oxirgi sinov qiymatda biz aniqlash darajadagi eng yuqori F1 scori topdik va uning 3 F1 darajadagi qiymatda.', 'vi': 'Tờ giấy này mô tả mẫu đề xuất của chúng ta cho nhiệm vụ Chẩn đoán lỗi lỗi lỗi của Trung Quốc (CGed) tại NLLLLlái-2-00. Các kỹ thuật tự nhiên của CGed là dùng kỹ thuật xử lý ngôn ngữ để tự động chẩn đoán lỗi ngôn ngữ Trung Quốc theo câu. Về mục đích này, chúng tôi thiết kế và thực hiện một mô hình CGed tên là BERT với Score-biến số Gates Nhận lỗi vượt qua (BSGD), based on the BERT model, Biceosắt Long-term Memory (BiLSTM) và trường ngẫu nhiên điều khiển (CRF). Để giải quyết vấn đề mất các mối quan hệ hàng loạt khi trộn các chi tiết liên tiếp như với các công trình trước, chúng tôi đề nghị một cơ chế chọn lọc để nhập các chi tiết liên tiếp, mà thực sự giữ lại các mối quan hệ trật tự giữa các chi tiết. Chúng tôi thực hiện thao tác LSTM trên kết quả mã hóa của mô hình BERT, và thêm phần cấu tạo chuỗi. Trong phần đánh giá thử nghiệm cuối cùng, chúng tôi đạt được điểm F1 cao nhất ở mức phát hiện và nằm trong điểm số F1 cao nhất ở cấp nhận diện.', 'bg': 'Настоящата статия описва нашия предложен модел за задачата за диагностика на китайската граматична грешка в НЛПТЕA2020. Целта на ЦЕД е да използва техники за обработка на естествения език за автоматично диагностициране на китайски граматически грешки в изреченията. За тази цел проектираме и внедряваме модел, наречен БЕРТ с диагностициране на грешки на вратите (БГЕД), който се основава на модела БЕРТ, двупосочна дългосрочна краткосрочна памет (BiLSTM) и условно случайно поле (CRF). За да се реши проблемът с загубата на релации от частичен ред при вграждане на елементи от непрекъснати функции, както при предишни работи, предлагаме механизъм за включване на елементи от непрекъснати функции, който ефективно запазва релациите от частичен ред между елементи от функционални функции. Извършваме обработка на резултата от кодирането на модела и допълнително извличаме характеристиките на последователността. При окончателната оценка на тестовете получихме най-високия резултат на ниво откриване и сме сред първите 3 точки на ниво идентифициране.', 'nl': 'Dit document beschrijft ons voorgestelde model voor de Chinese Grammatical Error Diagnosis (CGED) taak in NLPTEA2020. Het doel van CGED is om natuurlijke taalverwerkingstechnieken te gebruiken om automatisch Chinese grammaticale fouten in zinnen te diagnosticeren. Hiervoor ontwerpen en implementeren we een CGED model genaamd BERT met Score-feature Gates Error Diagnoser (BSGED), dat is gebaseerd op het BERT model, Bidirectioneel Long Short-Term Memory (BiLSTM) en Conditional Random Field (CRF). Om het probleem van het verliezen van gedeeltelijke orderrelaties bij het inbedden van continue feature items zoals bij eerdere werken aan te pakken, stellen we een gating mechanisme voor het integreren van continue feature items voor, dat effectief de gedeeltelijke volgorde relaties tussen feature items behoudt. We voeren LSTM-verwerking uit op het coderingsresultaat van het BERT-model en extraheren de sequentiekenmerken verder. In de definitieve test-set evaluatie behaalden we de hoogste F1 score op het detectieniveau en behoren we tot de top 3 F1 scores op het identificatieniveau.', 'da': 'Denne artikel beskriver vores foreslåede model til opgaven CGED (Chinese Grammatical Error Diagnose) i NLPTEA2020. Målet med CGED er at bruge naturlige sprogbehandlingsteknikker til automatisk at diagnosticere kinesiske grammatiske fejl i sætninger. Til dette formål designer og implementerer vi en CGED-model ved navn BERT med Score-feature Gates Error Diagnoser (BSGED), som er baseret på BERT-modellen, Bidirectional Long Short-Term Memory (BiLSTM) og betinget tilfældigt felt (CRF). For at løse problemet med at miste delordreforhold ved integrering af kontinuerlige funktionselementer som med tidligere værker, foreslår vi en gating mekanisme til integrering af kontinuerlige funktionselementer, som effektivt bevarer delordreforholdet mellem funktionselementer. Vi udfører LSTM-behandling på BERT-modellens kodningsresultat og udtrækker sekvensfunktionerne yderligere. I den endelige test-sæt evaluering opnåede vi den højeste F1 score på detektionsniveauet og er blandt de 3 bedste F1 score på identifikationsniveauet.', 'hr': 'Ovaj papir opisuje naš predloženi model za zadatak kineske gramatičke dijagnoze greške (CGED) u NLPTEA2020. Cilj CGED je koristiti prirodne tehnike obrađivanja jezika kako bi automatski dijagnosticirali kineske gramatičke greške u rečenicama. Za taj cilj, mi dizajniramo i implementiramo model CGED po imenu BERT sa dijagnozom pogrešnih vrata (BSGED), koji se temelji na modelu BERT, dvosmjernoj dugoročnoj memoriji (BiLSTM) i uvjetnom slučajnom polju (CRF). Za rješavanje problem a gubitka djelomičnih odnosa kada uključujemo kontinualne elemente funkcije kao i prethodni rad, predlažemo mehanizam prikupljanja za integraciju kontinualnih elementa funkcija, koji djelotvorno zadržava djelomične odnose između elementa funkcije. Proizvodimo obradu LSTM na rezultatu kodiranja BERT modela i dalje izvlačimo karakteristike sekvence. U konačnoj procjeni testa, dobili smo najviši rezultat F1 na razini otkrivanja i bili smo među najvišim rezultatima F1 na razini identifikacije.', 'id': 'Kertas ini menjelaskan model kami yang diusulkan untuk tugas Diagnosis Galat Grammatis Cina (CGED) di NLPTEA2020. Tujuan CGED adalah menggunakan teknik proses bahasa alam untuk secara otomatis mendiagnosis kesalahan grammatik Cina dalam kalimat. Untuk tujuan ini, kami merancang dan implementasikan model CGED bernama BERT dengan Score-feature Gates Error Diagnoser (BSGED), yang berdasarkan model BERT, Bidirectional Long-Term Memory (BiLSTM) dan bidang acak kondisional (CRF). Untuk mengatasi masalah kehilangan hubungan tertib-bagian ketika memasukkan objek karakteristik terus menerus seperti dengan pekerjaan sebelumnya, kami melamar mekanisme gating untuk mengintegrasi objek karakteristik terus menerus, yang secara efektif memelihara hubungan tertib-bagian antara objek karakteristik. Kami melakukan proses LSTM pada hasil pengekodan dari model BERT, dan ekstrak lebih lanjut fitur urutan. Dalam evaluasi setuju akhir, kami mendapatkan skor F1 tertinggi di tingkat deteksi dan berada di antara skor F1 tertinggi di tingkat identifikasi.', 'de': 'Dieses Papier beschreibt unser vorgeschlagenes Modell für die chinesische Grammatical Error Diagnosis (CGED)-Aufgabe in NLPTEA2020. Das Ziel von CGED ist es, mithilfe natürlicher Sprachverarbeitungstechniken chinesische Grammatikfehler in Sätzen automatisch zu diagnostizieren. Zu diesem Zweck entwerfen und implementieren wir ein CGED-Modell namens BERT mit Score-Feature Gates Error Diagnoser (BSGED), das auf dem BERT-Modell, Bidirektionalem Long-Term Memory (BiLSTM) und Conditional Random Field (CRF) basiert. Um das Problem des Verlustes von Teilordnungsbeziehungen beim Einbetten kontinuierlicher Feature-Elemente wie in früheren Arbeiten zu beheben, schlagen wir einen Gating-Mechanismus zur Integration kontinuierlicher Feature-Elemente vor, der effektiv die Teilordnungsbeziehungen zwischen Feature-Elementen beibehält. Wir führen LSTM-Verarbeitung auf dem Kodierungsergebnis des BERT-Modells durch und extrahieren die Sequenzmerkmale weiter. In der abschließenden Test-Set-Bewertung erzielten wir die höchste F1-Punktzahl auf Erkennungsebene und gehören zu den besten 3-F1-Punktzahlen auf Identifikationsebene.', 'ko': '본고는 우리가 NLPTEA 2020에서 제기한 중국어 문법 오류 진단(CGED) 임무 모델을 묘사한다.CGED는 자연 언어 처리 기술을 활용해 문장 속 중국어 문법 오류를 자동으로 진단하는 것이 목표다.이를 위해 우리는 BERT 모델, 양방향 장단시 기억(BilSTM)과 조건 랜덤 필드(CRF)를 바탕으로 분수 특징 문 오류 진단기(BSGED)를 가진 CGED 모델 BERT를 설계하고 실현했다.연속 특징 항목을 삽입할 때 편차 관계를 잃는 문제를 해결하기 위해 우리는 연속 특징 항목을 통합하는 선택 메커니즘을 제기하여 특징 항목 간의 편차 관계를 효과적으로 보존했다.BERT 모델의 인코딩 결과를 LSTM 처리하여 시퀀스 피쳐를 추가로 추출합니다.최종 테스트 세트 평가에서 우리는 테스트 단계에서 가장 높은 F1 점수를 얻었고 식별 단계에서 상위 3위의 F1 점수 중 하나였다.', 'tr': "Bu kagyz NLPTEA2020'da Çin çe Grammatikal Hata diagnostikasy (CGED) täblisasy üçin teklip edilen nusganymyzy tassyýar. CGED'iň maksady, sözleriň Hytaý gramatik hatalaryny otomatik bilen tanyşdyrmak üçin tebigy diller işlemek teknikleridir. Bu üçin, BERT adly CGED nusgasyny Score-feature Gates Hat Diagnoser (BSGED) bilen tasarlandyrys we implementeris We çözmek üçin öňki işler bilen birleşirýän bölüm-tertibler baglaýyşlaryny ýitirmek üçin mesele çözmek üçin, durmuş özellikleri integrasy üçin gating meýdançasyny teklif edip, bu da özellikler arasynda bölüm-tertibler baglaýyşlaryny taýýarlaýar. Biz BERT modeliniň kodlemesiniň netijesinde LSTM işlemegini çykarýarys we yzyna süzmeleri çykarýarys. Soňky synag düzümlerinde, detector düzümlerinde iň yükselen F1 अ'ini tapdyk we kimligi düzümlerinde 3 F1 अ'lerinde bar.", 'fa': 'این کاغذ مدل پیشنهاد ما را برای مشخص خطای گرماتیک چینی در NLPTEA2020 توصیف می\u200cکند. هدف CGED استفاده از تکنیک\u200cهای پردازش زبان طبیعی برای تشخیص خطاهای گراماتیک چینی در جمله\u200cها است. برای این قسمت، ما یک مدل CGED را طراحی می\u200cکنیم و اجرای می\u200cکنیم به نام BERT با مشخص خطای دروازه\u200cهای مقدار (BSGED) که بر روی مدل BERT، حافظه کوتاه طولانی دورانی (BiLSTM) و زمینه تصادفی (CRF) است. برای حل مشکل از دست دادن رابطه\u200cهای قسمتی در زمانی که وسیله\u200cهای ویژه\u200cهای پایدار به عنوان کارهای پیشینه، ما پیشنهاد می\u200cکنیم یک مکانیسم جمع کردن برای جمع کردن وسیله\u200cهای ویژه\u200cهای پایدار، که به طور تاثیر رابطه\u200cهای قسمتی بین عناصر ویژه\u200cها را نگه ما پروسیس LSTM را روی نتیجه رمزبندی مدل BERT انجام می دهیم، و ویژگی های رمزبندی را اخراج می کنیم. در آخرین ارزیابی مجموعه آزمایش، ما بالاترین امتیاز F1 را در سطح شناسایی گرفتیم و در میان امتیاز بالاترین 3 F1 در سطح شناسایی هستیم.', 'af': "Hierdie papier beskrywe ons voorgestelde model vir die Sjinese Gramatiese Fout Diagnosis (CGED) taak in NLPTEA2020. Die doel van CGED is om natuurlike taal verwerking tekens te gebruik om Sjinese grammatiese foute in setnings outomaties te diagnoseer. Na hierdie einde, ons ontwerp en implementeer 'n CGED model genaamd BERT met Score- feature Gates Fout Diagnoseer (BSGED), wat is gebaseer op die BERT model, Bidireksionale Lang- Term Geheue (BiLSTM) en voorwaarde willekeurige veld (CRF). In order to address the problem of losing partial-order relationships when embedding continuous feature items as with previous works, we propose a gating mechanism for integrating continuous feature items, which effectively retains the partial-order relationships between feature items. Ons uitvoer LSTM verwerking op die enkoderingsresultaat van die BERT model, en verder uitpak die volgorde funksies. In die eindelike toets- stel evaluering, het ons die hoogste F1 telling op die opdekking vlak ontvang en is onder die boonste 3 F1 telling op die identifikasie vlak.", 'sw': 'Gazeti hili linaelezea muundo wetu wa mapendekezo kwa ajili ya Uchaguzi wa Tamko wa Kichina (CGED) kazi ya NLPTEA2020. Lengo la CGED ni kutumia mbinu za upasuaji wa lugha za asili ili kutambua makosa ya kiuchumi nchini China katika hukumu. Kwa mwisho huu, tunaunda na kutekeleza muundo wa CGED anayeitwa BERT na Mfumbuzi wa makosa ya Taifa ya Madola ya BSGED (BSGED), anayeishi kwenye muundo wa BERT, kumbukumbu ya Mfupi wa muda mfupi wa BiLSTM (BiLSTM) na uwanja wa hali halisi (CRF). Ili kukabiliana na tatizo la kupoteza mahusiano ya kidini wakati wakiweka vifaa vya kiendeleo kama kwa kazi zilizopita, tunapendekeza mfumo wa kuunganisha vifaa vinavyoendelea, ambavyo kwa ufanisi unabaki mahusiano ya kidini kati ya vitu vya utaalamu. Tunafanya upasuaji wa LSTM kuhusu matokeo ya kodi ya modeli ya BERT, na kuondoa zaidi vipengele vya mfululizo. Katika uchunguzi wa mwisho wa jaribio la mwisho, tulipata score bora ya F1 katika kiwango cha uchunguzi na ni miongoni mwa vipimo 3 F1 vya juu katika kiwango cha utambulisho.', 'sq': 'Ky dokument përshkruan model in tonë të propozuar për detyrën kineze të Diagnozës së Gabimeve Gramatike (CGED) në NLPTEA2020. Qëllimi i CGED është të përdorë teknika natyrore të përdorimit të gjuhës për të diagnostikuar automatikisht gabimet gramatike kineze në fjalime. Për këtë qëllim, ne dizajnojmë dhe zbatojmë një model CGED të quajtur BERT me Score-feature Gates Error Diagnoser (BSGED), i cili bazohet në modelin BERT, BiLSTM dhe CRF. Me qëllim që të trajtojmë problemin e humbjes së marrëdhënieve me rend të pjesshëm kur përfshihet objektet e vazhdueshme me funksione si me punët e mëparshme, ne propozojmë një mekanizëm gating për integrimin e objekteve të vazhdueshme me funksione, i cili mban efektivisht marrëdhëniet me rend të pjesshëm midis objekteve të funksioneve. Ne kryejmë procesin LSTM në rezultatin e kodimit të modelit BERT, dhe nxjerrim më tej karakteristikat e sekuencës. Në vlerësimin përfundimtar të testit, kemi marrë rezultatin më të lartë të F1 në nivelin e zbulimit dhe jemi midis rezultateve më të larta të F1 në nivelin e identifikimit.', 'hy': 'Այս հոդվածը նկարագրում է մեր առաջարկած մոդելը Չինաստանի Գրամատիկ սխալների ախտորոշության (CGeD) հանձնարարության համար ՆԼՊՏԵԱ2020-ում: CGeD-ի նպատակն է օգտագործել բնական լեզվի վերամշակման մեթոդներ, որպեսզի ավտոմատ ախտորոշեն չինական գրամատիկ սխալները նախադասություններում: Այս նպատակով մենք ստեղծում ենք և իրականացնում ենք մի CGeD մոդել, որը կոչվում է BER-ը, որի օգնությամբ օգտագործվում է Գորտերի սխալների ախտորոշումը (ԲՍԳԵԴ), որը հիմնված է BER-ի մոդելի, երկու ուղղությամբ երկարաժամկետ հիշողության (ԲիLSԹՄ) և պայմանավոր պատահ Որպեսզի լուծենք մասամբ-կարգչային հարաբերությունների կորցնելու խնդիրը, երբ ներառում ենք անընդհատ հատկանիշների առարկաներ, ինչպես նախորդ աշխատանքների դեպքում, մենք առաջարկում ենք անընդհատ հատկանիշների առարկաների ինտեգրացիայի մեխանիզմ, որը արդյունքում պահպանում է մասամբ- Մենք կատարում ենք LSMT-ի վերլուծումը BER մոդելի կոդավորման արդյունքի վրա, և ավելի շատ հանում ենք հաջորդականության հատկանիշները: Վերջին փորձարկումների ընթացքում մենք ստացանք F1-ի ամենաբարձր գնահատականը հայտնաբերման մակարդակում և գտնվում ենք F1-ի ամենաբարձր 3 գնահատականների մեջ հայտնաբերման մակարդակում:', 'az': 'Bu kańüńĪt NLPTEA2020 i√ßind…ô √áin Gramatik Hata Diagnosisi (CGED) iŇüinin qurńüulu modelini t…ôsdiql…ôyir. CGED m…ôqs…ôdi, c√ľml…ôl…ôrd…ô √áin gramatik hatalarńĪnńĪ avtomatik olaraq diagnostik etm…ôk √ľ√ß√ľn t…ôbi…ôtli dil iŇül…ôm…ô teknikl…ôrini istifad…ô etm…ôkdir. Bu s…ôb…ôbd…ô, BERT adńĪnda CGED modeli t…ôyin edirik v…ô t…ôyin edirik. Bu, BERT modeli, ńį-y√∂n…ôlmiŇü Uzun QńĪsqa-Term YadńĪnńĪ (BiLSTM) v…ô ŇüartlńĪ v…ôziyy…ôtli sah…ôsi (CRF) il…ô t…ôyin edilir. ∆Źvv…ôlki iŇül…ôrl…ô birlikd…ô h…ômiŇü…ô f…ôaliyy…ôt m…ôlumatlarńĪnńĪ daxil etdikd…ô par√ßacńĪq sńĪralama iliŇükilerini yox etm…ôk √ľ√ß√ľn, s√ľr…ôkli f…ôaliyy…ôtl…ôr m…ôlumatlarńĪnńĪ integrallaŇüdńĪrmaq √ľ√ß√ľn m…ôlumatlarńĪ t…ôklif edirik ki, bu f…ôaliyy…ôt m…ôlumatlarńĪ arasńĪndakńĪ par√ßacńĪq sńĪralama iliŇükilerini saxlayar. Biz BERT modelinin kodlama n…ôtic…ôsind…ô LSTM iŇül…ôm…ôsini v…ô se√ßm…ô x√ľsusiyy…ôtl…ôrini artńĪq √ßńĪxarńĪrńĪq. Sonuncu sńĪnama qurmasńĪnda, keŇüif seviyesind…ô …ôn y√ľks…ôk F1 n√∂qt…ôsini q…ôbul etdik v…ô t…ôsdiql…ôm…ô seviyesind…ô …ôn y√ľks…ôk 3 F1 n√∂qt…ôsi arasńĪnda idik.', 'am': 'ይህ ፕሮግራም በNLPTEA2020 ውስጥ የቻይና የግራማቲካዊ ስህተት አቋራጭ (CGED) ስራ ላይ የተዘጋጀውን ሞዴል ይናገራል፡፡ የCGED goal is to use natural language processing techniques to automatically diagnose Chinese grammatical errors in sentences. ወደዚህ ምክንያት BERT (BSGED) የተጠቃሚ BERT የነጥብ-ፍትሕ Gates ስህተት አዲስ የCGED ሞዴል እናደርጋለን፡፡ የክፍለ ሥርዓት ግንኙነትን ለመጠቀም፣ የቀድሞው ሥራ እንደተጨማሪው አካባቢ አካባቢዎችን በመጠቀም ጊዜ፣ በሥርዓት ዕቃ መካከል የክፍል ግንኙነትን በመጠቀም እናስጠጋለን፡፡ በBERT ሞዴል ላይ የሆኑን የሆኑት የLSTM ሥርዓት እናደርጋለን፣ ከዚያም የሥርዓት ምርጫዎችን እናወጣለን፡፡ በመጨረሻው ፈተና ማረጋገጫ ውስጥ የF1 ደረጃ ደረጃ ደረጃውን አግኝተናል፡፡', 'ca': "Aquest paper descriu el nostre model proposat per a la tasca de Diagnòsis d'Errors Gramàtics xinès (CGED) a NLPTEA2020. L'objectiu de la CGED és utilitzar tècniques naturals de processament de llenguatges per diagnosticar automàticament errors gramàtics xinesos en frases. Per això, dissenyem i implementam un model CGED anomenat BERT amb Score-feature Gates Error Diagnoser (BSGED), que està basat en el model BERT, BiLSTM (BiLSTM) i el camp aleatòric condicional (CRF). Per abordar el problem a de perdre relacions d'ordre parcial quan incorporem elements de característiques continus com en treballs anteriors, proposem un mecanisme de gating per integrar elements de característiques continus, que manteneix efectivament les relacions d'ordre parcial entre elements de característiques. Fem un processament LSTM amb el resultat de codificació del model BERT i extraiem més les característiques de seqüència. In the final test-set evaluation, we obtained the highest F1 score at the detection level and are among the top 3 F1 scores at the identification level.", 'bs': 'Ovaj papir opisuje naš predloženi model za zadatak kineske gramatičke dijagnoze greške (CGED) u NLPTEA2020. Cilj CGED je koristiti prirodne tehnike obrade jezika kako bi automatski dijagnosticirali kineske gramatične greške u rečenicama. Za taj cilj, dizajniramo i implementiramo model CGED po imenu BERT sa dijagnozom greške Gates Error (BSGED), koji je zasnovan na modelu BERT, dvosmjernom dugoročnom pamćenju (BiLSTM) i uslovnom slučajnom polju (CRF). Da bi se riješili problem gubitka djelomičnih odnosa kada ugrađujemo kontinualne funkcije kao i sa prethodnim radovima, predlažemo mehanizam prikupljanja za integraciju kontinualnih elementa funkcija, koji efektivno zadržava djelomične veze između elementa funkcija. Proizvodimo LSTM obradu na rezultatu kodiranja BERT modela i dalje izvlačimo karakteristike sekvence. U konačnoj procjeni testa, dobili smo najviši rezultat F1 na razini otkrivanja i bili smo među najvišim rezultatima 3 F1 na razini identifikacije.', 'bn': 'এই পত্রিকা এনএলপিটে২০০-এ চীনা গ্রামাটিক্যাল ত্রুটি ডিজিনেশন (সিজেডি) কাজের জন্য আমাদের প্রস্তাবিত মডেল বর্ণনা কর সিজেডির লক্ষ্য হচ্ছে স্বাভাবিক ভাষা প্রক্রিয়ার প্রযুক্তি ব্যবহার করার জন্য চীনা গ্রাম্যাটিক্যাল ভুল স্বয়ংক্রি এই পর্যন্ত আমরা বিআরটি নামের একটি সিজেডি মডেল ডিজাইন করি এবং ব্যবস্থা করি স্কোর- ফিফার গেটস ত্রুটি ডিজাইনার (BSGED), যা BERT মডেল, বাইডেডিয়েল ল লম্বা শর্টটার মেমোরি (বিএলস্টি)  পূর্ববর্তী কাজের মাধ্যমে অনলাইন বৈশিষ্ট্যের বিষয়বস্তুর সাথে প্রবেশ করার সময় অংশ-অর্ডারের সম্পর্ক হারানোর সমস্যা নিয়ে আমরা একটি গেটিং মেক্সিমেন্ট প্রস্তাব করি, যা ব আমরা এলস্টিএম এনকোডিং এর ফলাফল বিবেরেট মডেলের উপর প্রক্রিয়া চালাই এবং সেক্রেন্সের বৈশিষ্ট্যাবলীর বৈশিষ্ট্য বিন শেষ পরীক্ষা সেট মূল্যের মাধ্যমে আমরা সনাক্তি স্তরে সর্বোচ্চ F1 স্কোর পেয়েছি এবং পরিচিতি স্তরে সর্বোচ্চ ৩ এফ১ স্কোরের মধ্য', 'cs': 'Tento článek popisuje náš navržený model pro čínskou gramatickou diagnostiku chyb (CGED) v NLPTEA2020. Cílem CGED je využít techniky zpracování přirozeného jazyka k automatické diagnostice čínských gramatických chyb ve větách. Za tímto účelem navrhujeme a implementujeme CGED model BERT s funkcí Score-feature Gates Error Diagnoser (BSGED), který je založen na modelu BERT, obousměrné dlouhodobé paměti (BiLSTM) a podmíněném náhodném poli (CRF). Abychom řešili problém ztráty vztahů s částečným pořadím při vkládání průběžných prvků, jako v předchozích prácích, navrhujeme gating mechanismus pro integraci průběžných prvků, který efektivně zachovává vztahy s částečným pořadím mezi prvky. Provádíme LSTM zpracování na výsledku kódování modelu BERT a dále extrahujeme sekvenční prvky. V závěrečném vyhodnocení testovací sady jsme získali nejvyšší F1 skóre na úrovni detekce a patří mezi nejlepší 3 F1 skóre na úrovni identifikace.', 'et': 'Käesolevas artiklis kirjeldatakse meie pakutud mudelit Hiina grammatilise vea diagnostika (CGED) ülesandeks NLPTEA2020. CGED eesmärk on kasutada loodusliku keele töötlemise meetodeid, et automaatselt diagnoosida hiina grammatilisi vigu lausetes. Selleks projekteerime ja rakendame CGED mudeli nimega BERT, mis põhineb BERT mudelil, kahesuunalisel pikaajalisel lühiajalisel mälul (BiLSTM) ja tingimuslikul juhuslikul väljal (CRF). Selleks et lahendada probleemi osalise järjekorra seoste kaotamisega pideva funktsiooni elementide manustamisel nagu varasematel töödel, pakume välja värvimismehhanismi pideva funktsiooni elementide integreerimiseks, mis säilitab efektiivselt osalise järjekorra seosed funktsioonide elementide vahel. Me teostame LSTM-i töötlemist BERT mudeli kodeerimise tulemusel ja ekstraheerime järjestuse funktsioonid. Lõplikus testikomplekti hindamises saime tuvastamistasemel kõrgeima F1 skoori ja oleme tuvastamistasemel 3 parima F1 skoori hulgas.', 'fi': 'Tässä artikkelissa kuvataan ehdotettua mallia Kiinan kielioppivirheiden diagnostiikkaan (CGED) NLPTEA2020. CGED:n tavoitteena on käyttää luonnollisen kielen käsittelytekniikoita kiinalaisten kielioppivirheiden automaattiseen diagnosointiin lauseissa. Tätä varten suunnittelemme ja toteutamme CGED-mallin nimeltä BERT Score-feature Gates Error Diagnostic (BSGED), joka perustuu BERT-malliin, Bidirectional Long Short-Term Memory (BiLSTM) ja ehdolliseen satunnaiskenttään (CRF). Jotta voitaisiin ratkaista ongelma osittaisten tilaussuhteiden menettämisestä upotettaessa jatkuvia ominaisuuskohteita kuten aiemmissa töissä, ehdotamme porttimekanismia jatkuvien ominaisuuskohteiden integroimiseksi, joka tehokkaasti säilyttää osittaisten tilaussuhteiden ominaisuuskohteiden välillä. Suoritamme LSTM-prosessoinnin BERT-mallin koodaustuloksen perusteella ja poistamme sekvenssioominaisuudet edelleen. Lopullisessa testisarjan arvioinnissa saimme korkeimman F1-pisteen tunnistustasolla ja olemme kolmen parhaan F1-pisteen joukossa tunnistustasolla.', 'jv': 'Samsul A4 Ere segondi iki, kita design lan ngetik aplikasi un model CGED sing nganggo BERT barêng Point-option gates Eror diagn (GSGED), sing wis basa nang model BERT, Bidirective politenessoffpolite"), and when there is a change ("assertivepoliteness Clear Nyong ngomongke dolanan surat sing gawe, awak dhéwé ngegolok F1 sing paling dhéwé ning nambah kebuturan lan wis nambah 3 F1 sing nambah dhéwé.', 'sk': 'Ta prispevek opisuje naš predlagani model za opravilo kitajske slovnične napake diagnoze (CGED) v NLPTEA2020. Cilj CGED je uporaba tehnik obdelave naravnega jezika za samodejno diagnosticiranje kitajskih slovničnih napak v stavkih. V ta namen oblikujemo in izvajamo CGED model z imenom BERT z diagnostikom napak vrat z oceno funkcij (BSGED), ki temelji na BERT modelu, dvosmernem dolgoročnem kratkoročnem pomnilniku (BiLSTM) in pogojnem naključnem polju (CRF). Da bi rešili problem izgube odnosov delnega reda pri vdelavi neprekinjenih elementov funkcij kot pri prejšnjih delih, predlagamo mehanizem za povezovanje neprekinjenih elementov funkcij, ki učinkovito ohranja odnose delnega reda med elementi funkcij. Izvajamo LSTM obdelavo na rezultatu kodiranja modela BERT in dodatno izvlečemo funkcije zaporedja. Pri končni vrednotenju testnih nizov smo dobili najvišjo F1 rezultat na ravni detekcije in smo med najboljšimi 3 F1 rezultati na ravni identifikacije.', 'ha': "Wannan takardan na bayyana misalinmu wanda aka buƙata wa Diagnosis na Grammatis Kuskure na China (CGED) cikin NLPTeA2020. The goal of CGED is to use natural language processing techniques to automatically diagnose Chinese grammatical errors in sentences.  Ga wannan, Munã ƙayyade kuma Muke cika wani motel na CGED wanda aka suna BERT da Diagnostic Kyaure-Taurar Gigon Haske (BSGED), wanda ke kan asansa da misalin BERT, Narrarranin Long-Long-Long-Time na BiLStatM) da field na ƙayyade ransa (CRF). To, dõmin mu tambayi masu hasara ga gama da danganta-rabo idan an shigar da wasu abubuwa masu daidai kamar da suka aiki na gabani, za'a buɗa wani matsayi na gaske dõmin ka haɗa abubuwa masu daidai, da kuma yana tsare danganta-rabo tsakanin abubuwa. Munã tafiyar da shirin LSM a kan kodi-matsalan BERT, kuma Mu sami wasu zaɓalli masu saka. Kuma a cikin ƙaddara ta ƙarshen jarraba, an sami mafiya girma F1 score a cikin zanen gano kuma za'a cikin score 3 F1 ta saman cikin zanen gane.", 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་སྔོན་སྒྲིག་པའི་རྣམ་གྲངས་ཀྱི་རྣམ་གྲངས་འདིས་NLPTEA2020 ནང་གི་བྱ་འགུལ་ལ་སྤྱོད་པའི་མིང་། CGED ཡི་དམིགས་ཡུལ་ནི་རང་བཞིན་གྱི་སྐད་རིགས་ལས་སྦྱོར་ནུས་ཀྱི་ཐབས་ལམ་ལ་བེད་སྤྱོད་དགོས། To this end, we design and implement a CGED model named BERT with Score-feature Gates Error Diagnoser (BSGED), which is based on the BERT model, Bidirectional Long-Term Memory (BiLSTM) and conditional random field (CRF). In order to address the problem of losing partial-order relationships when embedding continuous feature items as with previous works, we propose a gating mechanism for integrating continuous feature items, which effectively retains the partial-order relationships between feature items. We perform LSTM processing on the encoding result of the BERT model, and further extract the sequence features. In the last test-set evaluation, we obtained the highest F1 score at the detection level and are among the top 3 F1 scores at the identification level.', 'he': 'העיתון הזה מתאר את המודל המוצע שלנו למשימה של דיאגנוז שגיאות גרמטית סינית (CGED) ב NLPTEA2020. The goal of CGED is to use natural language processing techniques to automatically diagnose Chinese grammatical errors in sentences.  To this end, we design and implement a CGED model named BERT with Score-feature Gates Error Diagnoser (BSGED), which is based on the BERT model, Bidirectional Long Short-Term Memory (BiLSTM) and conditional random field (CRF).  כדי להתמודד עם הבעיה של איבדת מערכות יחסים חלקיות בהכנת פריטים תכונות ממשיכים כמו בעבודות קודמות, אנו מציעים מנגנון גייט להכנת פריטים תכונות ממשיכים, אשר בעצם שומר את מערכות יחסים חלקיות בכוננות בין פריטים תכונות. אנחנו מבצעים עיבוד LSTM על תוצאת הקוד של מודל BERT, ולמשיך לחלץ את תכונות הרצף. In the final test-set evaluation, we obtained the highest F1 score at the detection level and are among the top 3 F1 scores at the identification level.'}
{'en': 'CYUT Team Chinese Grammatical Error Diagnosis System Report in NLPTEA-2020 CGED Shared Task', 'ar': 'تقرير نظام تشخيص الأخطاء النحوية الصيني لفريق CYUT في مهمة CGED المشتركة NLPTEA-2020', 'fr': "Rapport du système de diagnostic des erreurs grammaticales chinoises de l'équipe CYUT dans la tâche partagée NLPTEA-2020 CGED", 'es': 'Informe del sistema de diagnóstico de errores gramaticales chinos del equipo CYUT en la tarea compartida CGED NLPTEA-2020', 'pt': 'Relatório do Sistema de Diagnóstico de Erro Gramatical Chinês da Equipe CYUT na Tarefa Compartilhada NLPTEA-2020 CGED', 'ja': 'NLPTEA -2020 CGED共有タスクにおけるCYUTチーム中国語文法エラー診断システムレポート', 'zh': 'CYUT团队中文语法错误诊断系统告于NLPTEA-2020 CGED共之', 'ru': 'Команда CYUT Отчет китайской системы диагностики грамматических ошибок в NLPTEA-2020 CGED Shared Task', 'hi': 'CYUT टीम चीनी व्याकरणिक त्रुटि निदान प्रणाली रिपोर्ट NLPTEA-2020 CGED साझा कार्य में', 'ga': 'Foireann CYUT Tuairisc Córas Diagnóisithe Earráide Gramadaí na Síne i dTasc Comhroinnte CGED NLPTEA-2020', 'ka': 'Name', 'hu': 'CYUT csapat kínai nyelvtani hibadiagnosztikai rendszer jelentése az NLPTEA-2020 CGED megosztott feladatban', 'el': 'Έκθεση του κινεζικού συστήματος διάγνωσης γραμματικών σφαλμάτων ομάδας στην κοινή εργασία', 'it': "Rapporto del sistema di diagnosi degli errori grammaticali cinesi del team CYUT nell'attività condivisa CGED NLPTEA-2020", 'mk': 'Извештај на Системот за дијагностика на граматска грешка на тимот CYUT во NLPTEA- 2020 CGED споделена задача', 'kk': 'CYUT тобы қытайша граматикалық қате NLPTEA- 2020 CGED ортақ тапсырманың жүйелік хабарламасын диагнозиялау', 'lt': 'CYUT komanda Kinijos Gramatinių klaidų diagnozavimo sistemos ataskaita NLPTEA-2020 m. CGED bendra užduotis', 'ms': 'CYUT Team Chinese Grammatical Error Diagnosis System Report in NLPTEA-2020 CGED Shared Task', 'mt': 'Rapport tas-Sistema ta’ Dijanjożi ta’ Żbalji Grammatiċi Ċiniżi tat-Tim CYUT f’NLPTEA-2020 CGED Kompitu Konġunt', 'ml': 'NLPTEA- 2020 CGED പങ്കുചേര്\u200dത്ത പണിയില്\u200d സിയുട്ട് ടീം ചൈനീസ് ഗ്രാമ്മാറ്റിക്കല്\u200d പിശക് ഡിഗ്നോഷന്\u200d സിസ്റ്റം റിപ', 'mn': 'CYUT Баг Хятад Грамматикийн алдаа НLPTEA-2020 CGED хуваалтын ажил', 'no': 'CYUT-gruppe kinesisk grammatisk feil i systemrapport i NLPTEA-2020 CGED delt oppgåve', 'pl': 'CYUT Team Chiński raport systemu diagnostyki błędów gramatycznych w NLPTEA-2020 CGED Shared Task', 'ro': 'Raportul sistemului de diagnosticare a erorilor gramaticale chinezești al echipei CYUT în activitatea partajată CGED NLPTEA-2020', 'sr': 'CYUT Team Kineski Gramatični izveštaj o sistemu dijagnoze greške u NLPTEA-2020 CGED zajedničkom zadatku', 'si': 'CYUT කණ්ඩායම් චීනි ග්\u200dරමාටිකල් දෝෂය NLPTEA-2020දී පද්ධති වාර්තාව සංඥානය කරනවා', 'so': 'CYUT Team China Grammatical Error Diagnosis System Report in NLPTEA-2020 CGED Shared Task', 'sv': 'CYUT Team Kinesisk grammatisk feldiagnostisk systemrapport i NLPTEA-2020 CGED delad uppgift', 'ta': 'Comment', 'ur': 'CYUT تیم چینی گراماتیکل خطا NLPTEA-2020 CGED شریک ٹاکس میں سیسٹم راپور', 'uz': 'Name', 'vi': 'CYUT Team Dịch vụ lỗi lỗi lỗi lỗi của Trung Quốc', 'bg': 'Отборът на Китайската граматична диагностика на системите за грешки в Споделена задача', 'nl': 'CYUT Team Chinese Grammatische Foutdiagnosesysteem Rapport in NLPTEA-2020 CGED Gedeelde Taak', 'da': 'CYUT Team Kinesisk grammatisk fejldiagnosesystemrapport i NLPTEA-2020 CGED delt opgave', 'de': 'CYUT Team Chinese Grammatical Error Diagnosis System Report in NLPTEA-2020 CGED Shared Task', 'fa': 'گروه CYUT چینی گزارش سیستم گزارش گرامی خطای شناسایی در کار مشترک NLPTEA-2020 CGED', 'hr': 'CYUT Team Kineski Gramatični izvještaj sustava za dijagnozu greške u NLPTEA-2020 CGED zajedničkom zadatku', 'ko': 'CYUT 팀의 NLPTEA-2020 CGED 공유 작업 중 중국어 구문 오류 진단 시스템 보고서', 'id': 'Tim CYUT Sistem Diagnosis Galat Grammatis Cina Laporan dalam NLPTEA-2020 CGED Tugas Berkongsi', 'sw': 'Timu ya CYUT Taarifa ya Uchaguzi wa Kichina ya Tamko cha Tamko cha UKIMWI katika Tamko la NLPTEA-2020 CGED', 'am': 'CYUT Team Chinese Grammatical Error Diagnosis System Report in NLPTEA-2020 CGED Shared Task', 'tr': 'CYUT Topary Çin çe Grammatikal Hatalar NLPTEA-2020 CGED Beýleki Görevi', 'af': 'CYUT Team Sjinese Grammaticale Fout Diagnosis Stelsel Raporteer in NLPTEA-2020 CGED Gedeelde Opdrag', 'az': 'CYUT Təmi Çin Gramatik Hatası NLPTEA-2020 CGED paylaşılmış Gözmü', 'bn': 'Name', 'bs': 'CYUT Team Kineski Gramatični izvještaj o sistemu dijagnoze greške u NLPTEA-2020 CGED zajedničkom zadatku', 'ca': "L'equip CYUT del sistema xinès de diagnòstic d'errors gramàtics en NLPTEA-2020 CGED Shared Task", 'cs': 'CYUT Team Čínský systém diagnostiky gramatických chyb v NLPTEA-2020 CGED Shared Task', 'sq': 'Ekipi CYUT Raporti i Sistemit të Diagnozës së Gabimeve Gramatike Kineze në NLPTEA-2020 CGED', 'et': 'CYUT Team Hiina grammatilise vea diagnostika süsteemi aruanne NLPTEA-2020 CGED jagatud ülesandes', 'fi': 'CYUT Team Kiinan kielioppivirheiden diagnosointijĂ¤rjestelmĂ¤n raportti NLPTEA-2020 CGED Jaettu tehtĂ¤vĂ¤', 'hy': 'Comment', 'sk': 'Poročilo o sistemu diagnosticiranja slovničnih napak skupine CYUT v skupni opravili NLPTEA-2020 CGED', 'ha': 'KCharselect unicode block name', 'bo': 'CYUT Team Chinese Grammatical Error Diagnosis System Report in NLPTEA-2020 CGED Shared Task', 'jv': 'CYUT Group Chinese Grama-Tik Rusak', 'he': 'צוות CYUT דיווח על מערכת אבחנת שגיאות גרמטיות סינית במשימה משותפת CGED NLPTEA-2020'}
{'en': 'This paper reports our Chinese Grammatical Error Diagnosis system in the NLPTEA-2020 CGED shared task. In 2020, we sent two runs with two approaches. The first one is a combination of conditional random fields (CRF) and a BERT model deep-learning approach. The second one is a BERT model deep-learning approach. The official results shows that our run1 achieved the highest precision rate 0.9875 with the lowest false positive rate 0.0163 on detection, while run2 gives a more balanced performance.', 'ar': 'تشير هذه الورقة إلى نظام تشخيص الأخطاء النحوية الصيني في المهمة المشتركة NLPTEA-2020 CGED. في عام 2020 ، أرسلنا مرحلتين بنهجين. الأول هو مزيج من الحقول العشوائية المشروطة (CRF) ونموذج التعلم العميق لنموذج BERT. والثاني هو نهج التعلم العميق نموذج بيرت. تظهر النتائج الرسمية أن تشغيلنا 1 حقق أعلى معدل دقة 0.9875 مع أدنى معدل موجب خاطئ 0.0163 عند الكشف ، بينما يعطي التشغيل 2 أداء أكثر توازناً.', 'es': 'Este documento informa sobre nuestro sistema de diagnóstico de errores gramaticales chinos en la tarea compartida del CGED NLPTEA-2020. En 2020, enviamos dos carreras con dos enfoques. El primero es una combinación de campos aleatorios condicionales (CRF) y un enfoque de aprendizaje profundo del modelo BERT. El segundo es un enfoque de aprendizaje profundo del modelo BERT. Los resultados oficiales muestran que nuestra corrida1 logró la tasa de precisión más alta de 0,9875 con la tasa de falsos positivos más baja de 0,0163 en la detección, mientras que la corrida2 proporciona un rendimiento más equilibrado.', 'fr': "Cet article présente notre système de diagnostic des erreurs grammaticales chinoises dans la tâche partagée NLPTEA-2020 CGED. En 2020, nous avons envoyé deux descentes avec deux approches. Le premier est une combinaison de champs aléatoires conditionnels (CRF) et d'une approche d'apprentissage en profondeur du modèle BERT. Le second est une approche d'apprentissage en profondeur du modèle BERT. Les résultats officiels montrent que notre run1 a atteint le taux de précision le plus élevé de 0,9875 avec le taux de faux positifs le plus faible de 0,0163 à la détection, tandis que run2 donne une performance plus équilibrée.", 'pt': 'Este artigo relata nosso sistema de diagnóstico de erros gramaticais em chinês na tarefa compartilhada NLPTEA-2020 CGED. Em 2020, enviamos duas corridas com duas abordagens. O primeiro é uma combinação de campos aleatórios condicionais (CRF) e uma abordagem de aprendizado profundo do modelo BERT. A segunda é uma abordagem de aprendizado profundo do modelo BERT. Os resultados oficiais mostram que nosso run1 alcançou a taxa de precisão mais alta 0,9875 com a menor taxa de falsos positivos 0,0163 na detecção, enquanto run2 oferece um desempenho mais equilibrado.', 'ja': '本稿では、NLPTEA -2020 CGED共有タスクにおける中国語文法エラー診断システムについて報告する。2020年には、2つのアプローチで2つのランを送信しました。1つ目は、条件付きランダムフィールド（ CRF ）とBERTモデルの深層学習アプローチの組み合わせです。2つ目は、BERTモデルの深層学習アプローチです。公式の結果は、我々のRUN 1が検出時に最低の偽陽性率0.0163で最高の精度0.9875を達成し、RUN 2はよりバランスの取れたパフォーマンスを提供することを示しています。', 'zh': '本文报汉语语法错误诊断系统在NLPTEA-2020 CGED中共同任务。 在 2020 年,发两次行,用二法。 一曰随机字段(CRF)与BERT深相学合。 二曰BERT模深度学法。 官结果显示,吾 run1 检得至精 0.9875,至卑之误报率 0.0163,而 run2 性更平。', 'ru': 'В этой статье сообщается о нашей китайской системе грамматической диагностики ошибок в совместной задаче NLPTEA-2020 CGED. В 2020 году мы отправили два прогона с двумя подходами. Первый - это комбинация условных случайных полей (ИРК) и подхода модели BERT к глубокому обучению. Второй - это модель BERT, основанная на глубоком обучении. Официальные результаты показывают, что наш прогон 1 достиг наивысшей точности 0,9875 с наименьшей ложноположительной частотой 0,0163 при обнаружении, в то время как прогон 2 дает более сбалансированную производительность.', 'hi': 'यह पेपर NLPTEA-2020 CGED साझा कार्य में हमारे चीनी व्याकरणिक त्रुटि निदान प्रणाली की रिपोर्ट करता है। 2020 में, हमने दो दृष्टिकोणों के साथ दो रन भेजे। पहला सशर्त यादृच्छिक क्षेत्रों (सीआरएफ) और एक BERT मॉडल गहरी सीखने के दृष्टिकोण का एक संयोजन है। दूसरा एक BERT मॉडल गहरी सीखने का दृष्टिकोण है। आधिकारिक परिणामों से पता चलता है कि हमारे रन 1 ने पता लगाने पर सबसे कम झूठी सकारात्मक दर 0.0163 के साथ उच्चतम परिशुद्धता दर 0.9875 हासिल की, जबकि रन 2 अधिक संतुलित प्रदर्शन देता है।', 'ga': 'Tuairiscíonn an páipéar seo ár gcóras Diagnóisithe Earráide Gramadaí na Síne sa tasc roinnte NLPTEA-2020 CGED. In 2020, chuireamar dhá rith le dhá chur chuige. Is é atá sa chéad cheann ná meascán de réimsí randamacha coinníollach (CRF) agus cur chuige domhainfhoghlama samhail BERT. Is cur chuige domhainfhoghlama samhail BERT an dara ceann. Léiríonn na torthaí oifigiúla gur bhain ár run1 amach an ráta cruinneas is airde 0.9875 leis an ráta dearfach bréagach 0.0163 is ísle ar bhrath, agus tugann run2 feidhmíocht níos cothroime.', 'hu': 'Ez a tanulmány a kínai nyelvtani hibadiagnosztikai rendszerünket jelenti az NLPTEA-2020 CGED megosztott feladatban. 2020-ban két futást küldtünk két megközelítéssel. Az első a feltételes véletlenszerű mezők (CRF) és a BERT modell mélytanulási megközelítése kombinációja. A második a BERT modell mélytanulási megközelítése. A hivatalos eredmények azt mutatják, hogy run1 elérte a legmagasabb pontossági rátát 0,9875, a legalacsonyabb hamis pozitív rátát 0,0163 detektáláskor, míg run2 kiegyensúlyozottabb teljesítményt nyújt.', 'el': 'Αυτή η εργασία αναφέρει το κινεζικό σύστημα διάγνωσης γραμματικών σφαλμάτων στην κοινή εργασία NLPTEA-2020. Τον 2020, στείλαμε δύο διαδρομές με δύο προσεγγίσεις. Το πρώτο είναι ένας συνδυασμός τυχαίων πεδίων υπό όρους (CRF) και μια προσέγγιση βαθιάς μάθησης του μοντέλου BERT. Το δεύτερο είναι μια προσέγγιση βαθιάς μάθησης του μοντέλου BERT. Τα επίσημα αποτελέσματα δείχνουν ότι το τρέξιμο μας πέτυχε το υψηλότερο ποσοστό ακρίβειας 0.9875 με το χαμηλότερο ψευδώς θετικό ποσοστό 0.0163 κατά την ανίχνευση, ενώ το τρέξιμο 2 δίνει μια πιο ισορροπημένη απόδοση.', 'ka': 'ამ დოკუმენტის შეცდომის სისტემაში ჩვენი ჩინეთი გრამატიკური შეცდომის დიაგნოზის სისტემა NLPTEA-2020 CGED გაყოფილი საქაღალდე. 2020 წელში, ჩვენ ორი ბრძანები გაგზავნეთ ორი მიღება. პირველი არის კომბინციაციური გამოსხვავებული ფერების კომბინციაცია და BERT მოდელის დიბოლო სწავლების კომბინციაცია. მეორე არის BERT მოდელის დიდი სწავლების მიღება. ჲტთუთალნთრვ პვჱსლრამთ ოჲკაჱგარ, ფვ ნაქთწრ ბყპჱ 1 ეჲჟრигნა ნაი-დჲლვმთწრ ოპთკპთრთრვლვნ ფაჟ 0,9875 ჟ ნაი-მალკთწრ ოჲლთუთრთრვლვნ ფაჟ 0,0163, ა ბყპჱ 2 ეაგ', 'it': "Questo articolo riporta il nostro sistema di diagnosi degli errori grammaticali cinesi nell'attività condivisa CGED NLPTEA-2020. Nel 2020 abbiamo inviato due run con due approcci. Il primo è una combinazione di campi casuali condizionali (CRF) e un approccio di deep learning modello BERT. Il secondo è un approccio di deep learning modello BERT. I risultati ufficiali mostrano che la nostra run1 ha raggiunto il tasso di precisione più alto 0,9875 con il tasso di falsi positivi più basso 0,0163 al rilevamento, mentre run2 offre prestazioni più equilibrate.", 'lt': 'Šiame dokumente pranešama apie mūsų Kinijos Gramatinių klaidų diagnostikos sistemą NLPTEA-2020 CGED bendroje užduotyje. 2020 m. pasiuntėme du runs su dviem metodais. Pirmasis yra sąlyginių atsitiktinių imčių laukų (CRF) ir BERT modelio gilaus mokymosi metodo derinys. The second one is a BERT model deep-learning approach.  Oficialūs rezultatai rodo, kad mūsų run1 pasiekė aukščiausią tikslumo greitį 0,9875 ir mažiausią klaidingą teigiamą greitį 0,0163 aptikimo metu, o run2 rezultatai yra labiau subalansuoti.', 'mk': 'This paper reports our Chinese Grammatical Error Diagnosis system in the NLPTEA-2020 CGED shared task.  Во 2020, испративме две трки со два пристапи. Првата е комбинација на условни случајни полиња (CRF) и пристап на БЕРТ модел за длабоко учење. The second one is a BERT model deep-learning approach.  Официјалните резултати покажуваат дека нашата трка1 ја постигна највисоката прецизност 0,9875 со најниска лажна позитивна стапка 0,0163 на детекција, додека трка2 дава побалансирана резултат.', 'kk': 'Бұл қағаз NLPTEA-2020 CGED ортақ тапсырмасында Қытай граматикалық қате диагнозы жүйесіне хабарлады. 2020 жылы, екі жағдайда екі жерді жібердік. Біріншісі - кездейсоқ өрістер (CRF) және BERT үлгі қалыпты оқыту тәсілдерінің біріктірімі. Екіншісі - BERT үлгісін түсіндіру тәсілі. Ақпараттық нәтижелер біздің жұмыс 1- іміздің ең дәрежесі 0, 9875 жылдамдығын табылған кезде ең төменгі дәрежесі 0, 0163 жылдамдығын жеткізеді, жұмыс 2- іміздің балансировалған жұмыс і', 'ms': 'Kertas ini melaporkan sistem Diagnosis Ralat Grammatik Cina dalam tugas kongsi CGED NLPTEA-2020. Pada tahun 2020, kami menghantar dua runs dengan dua pendekatan. Yang pertama adalah kombinasi medan rawak syarat (CRF) dan pendekatan belajar dalam model BERT. Yang kedua adalah pendekatan belajar dalam model BERT. Hasil rasmi menunjukkan bahawa run1 kami mencapai kadar ketepatan tertinggi 0.9875 dengan kadar positif palsu tertinggi 0.0163 pada pengesan, sementara run2 memberikan prestasi yang lebih seimbang.', 'mt': 'Dan id-dokument jirrapporta s-sistema tagħna ta’ Dijanjożi ta’ Żbalji Grammatiċi fil-kompitu konġunt NLPTEA-2020 CGED. Fl-2020, bagħtu żewġ runs b’żewġ approċċi. L-ewwel waħda hija kombinazzjoni ta’ oqsma kondizzjonali aleatorji (CRF) u approċċ ta’ mudell BERT ta’ tagħlim profond. It-tieni wieħed huwa approċċ ta’ mudell BERT ta’ tagħlim profond. Ir-riżultati uffiċjali juru li r-run1 tagħna laħqet l-ogħla rata ta’ preċiżjoni 0.9875 bl-inqas rata pożittiva foloz 0.0163 fuq id-detezzjoni, filwaqt li r-run2 tagħti prestazzjoni aktar ibbilanċjata.', 'no': 'Denne papiret rapporterer vår kinesisk grammatisk feildiagnosisystem i NLPTEA-2020 CGED delt oppgåve. I 2020 sendte vi to runner med to tilnærmingar. Den første er ein kombinasjon av vilkårlege tilfeller (CRF) og ein BERT-modell dypt læringstilnærming. Den andre er ein BERT-modell dyp læringstilnærming. Den offisielle resultatene viser at køyren1 vårt oppnådd den høgste presisjonsfarten 0,9875 med den lågste falske positivhasten 0,0163 ved oppdaging, mens køyren2 gjev ein meir balansert utvikling.', 'mn': 'Энэ цаас NLPTEA-2020 CGED хуваалцааны ажил дээр Хятад Грамматикийн Алдаа Диагнозын системийг мэддэг. 2020 онд бид хоёр арга барилгатай хоёр дагуулыг явуулсан. Эхний нэг нь нөхцөл санамсаргүй салбарын холбоотой (CRF) болон BERT загварын гүн гүнзгий суралцах арга зам юм. Хоёр дахь нь БЕРТ загварын гүн гүнзгий суралцах арга юм. Эрийн үр дүнд бидний run1 нь 0.9875-ийн хамгийн өндөр тодорхой хурдыг олж мэдэхэд 0.0163-ийн хамгийн бага тодорхой тодорхой хурдыг олж авсан ба run2 нь илүү баланслагдсан үйл ажиллагааг олж авдаг.', 'pl': 'Niniejszy artykuł przedstawia nasz chiński system diagnostyki błędów gramatycznych w zadaniu wspólnym NLPTEA-2020 CGED. W latach 2020 wysłaliśmy dwa biegi z dwoma podejściami. Pierwszy z nich to połączenie warunkowych pól losowych (CRF) i podejścia głębokiego uczenia się modelu BERT. Drugim z nich jest podejście do głębokiego uczenia się modelu BERT. Oficjalne wyniki pokazują, że nasz run1 osiągnął najwyższą precyzję 0.9875 przy najniższym fałszywie dodatnim wskaźniku 0.0163 po wykryciu, natomiast run2 daje bardziej zrównoważoną wydajność.', 'ro': 'Această lucrare raportează sistemul nostru de diagnosticare a erorilor gramaticale chinezești în sarcina comună CGED NLPTEA-2020. În 2020, am trimis două runde cu două abordări. Primul este o combinație de câmpuri aleatorii condiționate (CRF) și o abordare de învățare profundă a modelului BERT. Al doilea este o abordare bazată pe învățarea profundă a modelului BERT. Rezultatele oficiale arată că run1 a atins cea mai mare rată de precizie de 0,9875 cu cea mai mică rată fals pozitivă de 0,0163 la detectare, în timp ce run2 oferă o performanță mai echilibrată.', 'sr': 'Ovaj papir prijavljuje naš kineski sistem za dijagnozu greške u delu CGED-a NLPTEA-2020. 2020. poslali smo dva trka sa dva pristupa. Prvi je kombinacija uslovnih slučajnih polja (CRF) i pristupa BERT model a dubokog učenja. Drugi je model dubokog učenja BERT. Zvanični rezultati pokazuju da je naš run1 postigao najvišu precizniju stopu 0,9875 sa najnižim lažnom pozitivnom stopom 0,0163 na detekciji, dok run2 daje balanciraniju funkciju.', 'so': 'Kanu warqaddaas wuxuu ku qoraa nidaamka baaritaanka khaladda ee Chinese ee ku qoran NLPTEA-2020 CGED shaqo qayb ah. 2020, waxaan u dirnay laba oroddo oo laba qaab ah. Kii ugu horeysa waa isku xiran beeraha sharciga ah (CRF) iyo qaab aad u bartaan dugsiga hoose ah BERT. Kii labaadna waa qaab waxbarasho mool dheer ah BERT. The official results shows that our run1 achieved the highest precision rate 0.9875 with the lowest false positive rate 0.0163 on detection, while run2 gives a more balanced performance.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മുടെ ചൈനീസ് ഗ്രാമാറ്റിക്കല്\u200d തെറ്റുകള്\u200d ഡിയോഗിസ് സിസ്റ്റം NLPTEA-2020 CGED പങ്കെടുത്ത ജോലി In 2020, we sent two runs with two approaches.  ആദ്യത്തെ ഒരു കൂട്ടത്തില്\u200d നിലനില്\u200dക്കുന്ന പ്രദേശങ്ങളുടെ (CRF) പിന്നെ ബെര്\u200dട്ടി മോഡല്\u200d ആഴത്തെ പഠിക്കുന് രണ്ടാമത്തേതാണ് ബെര്\u200dട്ടി മോഡല്\u200d ആഴത്തില്\u200d പഠിക്കാനുള്ള വഴി ഓഫീസല്\u200d ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ റൂണ്\u200d1 ഏറ്റവും മികച്ച പരിഗണന വില 0. 9875 പ്രാപ്തിയില്\u200d ഏറ്റവും കൂടുതല്\u200d തെറ്റായ പ്രകടന', 'si': 'මේ පැත්තේ අපේ චීනි ග්\u200dරාම්ටික් වැරදිලි වැරදිලි පද්ධතිය NLPTEA-2020යි CGED භාවිත වැඩක් තියෙනවා. 2020දී, අපි දුවන්න දෙකක් දුවන්නා අවස්ථානය දෙකක් තියෙන්නේ. පළමුවෙනි එක තමයි සාමාන්\u200dය විසින්දු ක්\u200dෂේත්\u200dර (CRF) සහ BERT මොඩල් ගොඩක් ගොඩක් ඉගෙන ගන්න ප්\u200dරයෝජනය. දෙවෙනි එක තමයි BERT මොඩල් ගොඩක් ඉගෙන ගන්න පුළුවන්. සාමාන්\u200dය ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ රන්න 1 විශ්වාසය 0.9875 විශ්වාසයෙන් අඩුම විශ්වාසය අඩුම විශ්වාසය 0.0163 විශ්වාස', 'sv': 'Denna uppsats rapporterar vårt kinesiska grammatiska feldiagnossystem i den delade uppgiften NLPTEA-2020 CGED. Under 2020 skickade vi två omgångar med två tillvägagångssätt. Den första är en kombination av villkorliga slumpmässiga fält (CRF) och en BERT-modell djupinlärningsmetod. Den andra är en BERT-modell för djupinlärning. De officiella resultaten visar att vår run1 uppnådde högsta precision 0,9875 med lägsta falska positiva frekvens 0,0163 vid detektering, medan run2 ger en mer balanserad prestanda.', 'ta': 'இந்த காகிதம் NLPTEA- 2020 CGED பகிர்ந்த பணியில் எங்கள் சீனா சிக்கல் சிக்கல் பிழை கண்டுபிடிப்பு அமைப்பை அறிக்கிறது. 2020-ல், நாங்கள் இரண்டு வழிகளுடன் இரண்டு ஓடுகளை அனுப்பினோம். முதல் ஒரு நிபந்தனையில் குறிப்பில்லாத புலங்கள் (CRF) மற்றும் ஒரு BERT மாதிரி ஆழமான கற்றுக்கொள்ள முறையில். இரண்டாவது பிரெட் மாதிரி ஆழமான கற்றுக்கொள்ளும் வழியாகும். Official results show that our run1 achieved the highest precision rate 0. 9875 with the lowest false positive rate 0. 0163 on detection, while run2 gives a more balanced performance.', 'ur': 'This paper reports our Chinese Grammatical Error Diagnosis system in the NLPTEA-2020 CGED shared task. ۲۰۰۲ میں ہم نے دو رونڈ بھیج دیئے۔ سب سے پہلے ایک کانڈیشن راندمالک کھیتیں (CRF) اور BERT موڈل عمیق سیکھنے کے طریقے کی ترکیب ہے. دوسرا ایک BERT موڈل سیکھنے کی طرح ہے۔ رسمی نتائج دکھاتے ہیں کہ ہمارے رون۱ نے سب سے زیادہ دقیق दर 0.9875 کو پہنچایا تھا اور سب سے کم غلط مثبت दर 0.0163 کو پہنچانے پر، حالانکہ run2 ایک زیادہ مثبت فعالیت دیتا ہے.', 'vi': 'Tờ giấy này báo cáo hệ thống phân tích lỗi máy Trung Quốc của chúng ta trong một nhiệm vụ chung chung Chúng tôi đã gửi hai lượt chạy với hai cách tiếp cận. Cái thứ nhất là sự kết hợp các trường ngẫu nhiên có các điều kiện và một phương pháp nghiên cứu sâu học của BERT. Cái thứ hai là một phương pháp nghiên cứu sâu học của BERT. Những kết quả chính thức cho thấy rằng hệ thống run1 đã đạt mức độ chính xác cao nhất 0.9875 với tỉ lệ sai sai lệch thấp nhất 0.1263 khi phát hiện ra, trong khi run2 còn hiệu quả cân bằng hơn.', 'uz': "Bu qogʻoz NLPTEA-2020 CGED bilan bogʻliq vazifani aniqlash tizimini Xitoycha grammatikal xato nazoratadi. In 2020, we sent two runs with two approaches.  Birinchi birinchi shaxsiy maydonlarni birlashtirish va BERT modeli o'rganish usuli. Ikkinchi esa BERT modeli o'rganish usuli. Tafsilotlar natijalari esa bizning run1 yuqori murakkablarimiz 0. 9875 darajaga erishildi va aniqlash uchun eng eng kichik yolg'on positiv foiz 0. 0163, va run2 bilan ko'proq o'zgarishga ega.", 'nl': 'Dit document rapporteert ons Chinese Grammatical Error Diagnosis systeem in de NLPTEA-2020 CGED gedeelde taak. In 2020 stuurden we twee runs met twee benaderingen. De eerste is een combinatie van conditional random fields (CRF) en een BERT model deep learning aanpak. De tweede is een BERT model deep learning aanpak. De officiële resultaten tonen aan dat onze run1 de hoogste precisiesnelheid 0.9875 behaalde met de laagste valse positieve snelheid 0.0163 bij detectie, terwijl run2 een uitgebalanceerde prestatie geeft.', 'de': 'Dieses Papier berichtet über unser chinesisches Grammatical Error Diagnosis System in der NLPTEA-2020 CGED Shared Task. In 2020 haben wir zwei Läufe mit zwei Ansätzen verschickt. Das erste ist eine Kombination aus bedingten Zufallsfeldern (CRF) und einem BERT Modell Deep Learning Ansatz. Der zweite Ansatz ist ein BERT Modell Deep Learning Ansatz. Die offiziellen Ergebnisse zeigen, dass unser run1 bei Erkennung die höchste Präzision 0.9875 mit der niedrigsten falsch positiven Rate 0.0163 erreicht hat, während run2 eine ausgewogenere Leistung liefert.', 'da': 'Dette papir rapporterer vores kinesiske grammatiske fejldiagnosesystem i den delte opgave NLPTEA-2020 CGED. I 2020 sendte vi to kørsler med to tilgange. Den første er en kombination af betingede tilfældige felter (CRF) og en BERT model dyb læring tilgang. Den anden er en BERT-model tilgang til dyb læring. De officielle resultater viser, at vores run1 opnåede den højeste præcisionsrate 0,9875 med den laveste falske positive rate 0,0163 ved detektion, mens run2 giver en mere afbalanceret ydeevne.', 'ko': '본고는 NLPTEA-2020 CGED 공유 작업 중의 중국어 문법 오류 진단 시스템을 보고합니다.2020년에 우리는 두 가지 방법으로 두 번의 달리기를 했다.첫 번째는 조건랜덤필드(CRF)와 버트모델 딥러닝 방법의 결합이다.두 번째는 베르토 모형의 심도 있는 학습 방법이다.공식 결과에 따르면 우리의run1은 검측할 때 가장 높은 정확률 0.9875, 가장 낮은 오보율 0.0163을 얻었고run2의 성능은 더욱 균형을 이루었다.', 'bg': 'Тази статия докладва нашата система за диагностика на китайската граматична грешка в споделената задача. През 2020 г. изпратихме два писта с два подхода. Първият е комбинация от условни произволни полета (КРФ) и модел подход за дълбоко обучение. Вторият е модел на задълбочено обучение. Официалните резултати показват, че нашето бягане1 е постигнало най-високата скорост на прецизност 0.9875 с най-ниската честота на фалшиво положителни резултати 0.0163 при откриване, докато бягане 2 дава по-балансирана производителност.', 'fa': 'این کاغذ گزارش می\u200cدهد که سیستم شناسایی خطای گراماتیک چینی ما در کار مشترک NLPTEA-2020 CGED است. در سال ۲۰۰۲، دو راه با دو دسترسی فرستادیم. اولین یک ترکیب از زمینه\u200cهای تصادفی (CRF) و یک روش عمیق یادگیری مدل BERT است. دوم یک دستور عمیق یادگیری BERT است. نتایج رسمی نشان می دهد که چرخۀ ۱ ما بالاترین مقدار دقیق 0.9875 را به دست آورد با پایین مقدار مثبت 0.0163 در کشف، در حالی که run2 اجرای تطبیق بیشتری را می دهد.', 'tr': 'Bu kagyz Çin çe Grammatik Hatlaryň NLPTEA-2020 CGED bölýän işinde aýdylýar 2020-nji ýylda iki golaý bilen iki golaý gönderdik. Ilkinji şartly hassas alanlaryň (CRF) we BERT nusgasyny derin öwrenmek üçin bir kombinatsiyadyr. Ikinjisi BERT nusgasy derin öwrenmek nusgasy. Resmi netijeler çykyşymyzyň 1-iniň esasy derejä 0.9875-iniň iň depesinde ýalňyş derejä 0.0163-iniň tapylygyny bardygyny görkezýär, we run2-iň baýlygyny daňlaşýar.', 'id': 'Kertas ini melaporkan sistem Diagnosis Galat Grammatis Cina dalam tugas kongsi NLPTEA-2020 CGED. Pada tahun 2020, kami mengirim dua runs dengan dua pendekatan. Yang pertama adalah kombinasi bidang acak kondisional (CRF) dan pendekatan belajar dalam model BERT. Yang kedua adalah pendekatan belajar dalam model BERT. The official results shows that our run1 achieved the highest precision rate 0.9875 with the lowest false positive rate 0.0163 on detection, while run2 gives a more balanced performance.', 'sw': 'Gazeti hili linaripoti mfumo wetu wa Uchaguzi wa Tamko wa Kichina wa Uchaguzi wa Tamko katika kazi ya NLPTEA-2020 CGED. Mwaka 2020, tulituma mbili kwa njia mbili. Kila kwanza ni muunganiko wa masharti yasiyo na urahisi (CRF) na mbinu za kuelimisha kina ya BERT. Pili ni mbinu za kujifunza kwa kina zaidi ya BERT. Matokeo rasmi yanaonyesha kwamba run1 yetu ilifanikiwa kiwango kikubwa cha stahiki cha 0.9875 kwa kiwango cha chini cha uongo chanya cha 0.0163 kinachogundua, wakati run2 kinatoa utendaji wa usawa zaidi.', 'hr': 'Ovaj papir izvještava naš kineski sistem za dijagnozu greške u zajedničkom zadatku NLPTEA-2020 CGED-a. 2020. godine smo poslali dva trka sa dva pristupa. Prvi je kombinacija uvjetnih slučajnih polja (CRF) i pristupa dubokog učenja BERT model a. Drugi je model dubokog učenja BERT. Zvanični rezultati pokazuju da je naš run1 postigao najvišu precizniju stopu 0,9875 sa najnižim lažnom pozitivnom stopom 0,0163 na detekciji, dok run2 daje balanciraniju funkciju.', 'hy': 'Այս հոդվածը հայտարարում է, որ մեր Չինաստանի Գրամատիկ սխալների ախտորոշման համակարգը ՆԼՊՏԵԱ-2020-ի CGeD-ի ընդհանուր խնդիրներում է: 2020 թվականին մենք երկու արագություն ուղարկեցինք երկու մոտեցումներով: Առաջինը պայմանավոր պատահական դաշտերի (ԿՌՖ) և BER մոդելի խորը ուսումնասիրության համակցություն է: Երկրորդը խորը սովորելու մոդելն է: Ապաշտոնական արդյունքները ցույց են տալիս, որ մեր արագություն1-ը հասավ 0.9875-ի ամենաբարձր ճշգրիտության արագությանը, որն ավելի ցածր սխալ դրական արագությամբ է 0.0063-ը հայտնաբերելու համար, մինչդեռ արագություն2-ը ավելի հավասարա', 'az': 'Bu kağıt NLPTEA-2020 CGED paylaşılan işdə Çin Gramatik Hatalarımızın NLPTEA-2020 sistemini bildirir. 2020-ci ildə iki yol göndərdik. İlk kişi şartlı rastgele sahələrin (CRF) və BERT modeli derin öyrənmə tərzidir. İkincisi BERT modeli derin öyrənmə tərzidir. Resmi sonuçlar göstərir ki, run1-imizin ən yüksək dəqiqliyyat hızı 0.9875 ilə keşfetməkdə ən düşük pozitif hızı 0.0163 oldu, run2 daha balanslı performansı verir.', 'am': 'የቻይና የግራማሲካዊ ስህተት ማግኘት ስርዓታችንን በNLPTEA-2020 CGED የተሰራጨውን ስራ ይዘረዝራል፡፡ በ2020 ውስጥ ሁለት የሮዎችን ሁለት ደረጃዎች ላክን:: የመጀመሪያው የአካባቢው እርሻ (CRF) እና የBERT model ጥልቅ ትምህርት ማቀናቀል ነው፡፡ ሁለተኛውም BERT የጥልቅ ትምህርት መግለጫ ነው The official results shows that our run1 achieved the highest precision rate 0.9875 with the lowest false positive rate 0.0163 on detection, while run2 gives a more balanced performance.', 'bs': 'Ovaj papir izvještava naš kineski gramatični sistem dijagnoze greške u delom zadatku NLPTEA-2020 CGED-a. 2020. godine smo poslali dva trka sa dva pristupa. Prvi je kombinacija uslovnih slučajnih polja (CRF) i pristupa BERT model a dubokog učenja. Drugi je model dubokog učenja BERT. Zvanični rezultati pokazuju da je naš run1 postigao najvišu preciznu stopu 0,9875 sa najnižim lažnom pozitivnom stopom 0,0163 na detekciji, dok run2 daje balanciraniji učinkoviti.', 'af': "Hierdie papier rapporteer ons Sjinese Gramatiese Fout Diagnosis stelsel in die NLPTEA-2020 CGED gedeelde taak. In 2020 het ons twee hardloop gestuur met twee toegang. Die eerste een is 'n kombinasie van voorwaardes willekeurige velde (CRF) en 'n BERT model diep- leer toegang. Die tweede een is 'n BERT model diep-leer toegang. Die offisiele resultate vertoon dat ons hardloop1 die hoogste presisie tempo 0.9875 bereik het met die laagste valse positiewe tempo 0.0163 op opspoor, terwyl hardloop2 gee 'n meer balanse presisie presisie.", 'sq': 'Ky dokument raporton se sistemi ynë kinez për diagnozimin e gabimeve Gramatike në detyrën e përbashkët të NLPTEA-2020 CGED. Në 2020, dërguam dy vrapime me dy afrime. I pari është një kombinim i fushave të rastësishme të kushtueshme (CRF) dhe një metode të mësimit të thellë të modelit BERT. E dyta është një metodë e mësimit të thellë të modelit BERT. Rezultatet zyrtare tregojnë se run1 arriti normën më të lartë të saktësisë 0.9875 me normën më të ulët pozitive false 0.0163 në zbulim, ndërsa run2 jep një performancë më të ekuilibruar.', 'cs': 'Tento článek popisuje náš systém diagnostiky gramatických chyb v rámci sdíleného úkolu NLPTEA-2020 CGED. V roce 2020 jsme vyslali dva běhy se dvěma přístupy. První z nich je kombinace podmíněných náhodných polí (CRF) a BERT model hlubokého učení. Druhým z nich je BERT model hlubokého učení. Oficiální výsledky ukazují, že náš run1 dosáhl nejvyšší přesnosti 0.9875 s nejnižší falešně kladnou rychlostí 0.0163 při detekci, zatímco run2 poskytuje vyváženější výkon.', 'et': 'Käesolevas artiklis kirjeldatakse meie Hiina grammatilise veadiagnostika süsteemi NLPTEA-2020 CGED jagatud ülesandes. 2020. aastal saatsime kaks jooksu kahe lähenemisega. Esimene neist on tingimuslike juhuslike väljade (CRF) ja BERT mudeli sügavõppe lähenemisviisi kombinatsioon. Teine on BERTi mudeli sügavõppe lähenemisviis. Ametlikud tulemused näitavad, et meie run1 saavutas kõrgeima täpsuskiiruse 0,9875, väikseima valepositiivse kiirusega 0,0163 tuvastamisel, samas kui run2 tagab tasakaalustatuma jõudluse.', 'fi': 'Tﾃ､mﾃ､ artikkeli raportoi kiinalaisen kielioppivirheiden diagnosointijﾃ､rjestelmﾃ､mme NLPTEA-2020 CGED jaettuun tehtﾃ､vﾃ､ﾃ､n. Vuonna 2020 lﾃ､hetimme kaksi ajoa kahdella lﾃ､hestymisellﾃ､. Ensimmﾃ､inen on ehdollisten satunnaisten kenttien (CRF) ja BERT-mallin syvﾃ､oppimismenetelmﾃ､n yhdistelmﾃ､. Toinen on BERT-mallin syvﾃ､oppimisen lﾃ､hestymistapa. Viralliset tulokset osoittavat, ettﾃ､ run1 saavutti korkeimman tarkkuuden 0,9875 ja alhaisimman vﾃ､ﾃ､rien positiivisten tulosten 0,0163 havaitsemisessa, kun taas run2 tarjoaa tasapainoisemman suorituskyvyn.', 'bn': 'এই পত্রিকা আমাদের চীনা গ্রামাটিক্যাল ত্রুটিক্যাল ডিজাইনিং সিস্টেম এনএলপিটেএ-২০২০ সিজেডি শেয়ার কর্মসূচী ২০২০ সালে আমরা দুটো পালিয়েছিলাম দুটি পালিয়েছিলাম। প্রথমটি হচ্ছে অবস্থানের ক্ষেত্রে (CRF) এবং বিবেরেটি মডেল গভীর শিক্ষার উপায়। দ্বিতীয় একটি বিরেটি মডেল গভীর শিক্ষার উপায়। The official results shows that our run1 achieved the highest precision rate 0.9875 with the lowest false positive rate 0.0163 on detection, while run2 gives a more balanced performance.', 'ca': "Aquest article diu que el nostre sistema xinès de diagnòstic d'errors gramàtics a la tasca compartida de NLPTEA-2020 CGED. Al 2020 vam enviar dues carreres amb dos enfocaments. La primera és una combinació de camps aleatoris condicionats (CRF) i un enfocament d'aprenentatge profund del model BERT. La segona és un enfocament d'aprenentatge profund del model BERT. Els resultats oficials mostren que la nostra run1 va aconseguir la velocitat de precisió més alta 0,9875 amb la velocitat falsa positiva més baixa 0,0163 a la detecció, mentre la run2 dóna un rendiment més equilibrat.", 'he': 'העיתון הזה דווח על מערכת אבחנת שגיאות גראמטיות הסינית שלנו במשימה משותפת NLPTEA-2020 CGED. בשנת 2020 שלחנו שתי רצויות עם שתי גישות. הראשון הוא שילוב של שדות אקראיים בתנאים (CRF) וגישה של מודל BERT ללמוד עמוק. השנייה היא גישה למידה עמוקה מודל BERT. התוצאות הרשמיות מראות שהריון1 שלנו השיג את שיעור הדיוק הגבוה ביותר 0.9875 עם שיעור חיובי שווא נמוך ביותר 0.0163 על גילוי, בעוד ריון2 נותן ביצוע מאוזן יותר.', 'jv': "Perintah sing ngabarang basa ning Chinese Grama-Tik Dikenalis Sistem NLPMEA-2020 CGED tahun nggawe barang nggawe Warsa 2020, awak dhéwé seneng dolanan sing wis didasah durung. Awak dhéwé sing perusahaan karo perusahaan kanggo sabanjuré mulai (CF) lan nganggo model BERT kuwi nggambar barang nggambar. Iki segondi kanggo sabên ngerti 'BERT' dadi nggambar barang. Ofisial dipoleh sing ngomong nik awak dhéwé 1 sampek sing gak dhéwé, 0.5875 barêng sing katêpakan uwong sing katêpakan 0.583 ngono cah sing apik dhéwé, terus run2 ngeweh sabên lanjut sing berarti.", 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་རྒྱ་ནག་གི་བྱ་རིམ་འགྱུར་བའི་ནོར་འཁྲུལ་ལ་སྤྱོད་མ་ལག་ལ་ཐོག་ཏུ་སྙན་ཞུ་བ་ཡིན། སྤྱི་ལོ་༢༠༠༢༠་ནང་ང་ཚོས་གཟུགས་གཟུགས་གཉིས་བྲིས་པ་ཡིན། The first one is a combination of conditional random fields (CRF) and a BERT model deep-learning approach. གཉིས་པ་དེ་ཅིག་ནི་BERT Model སྒྲིག་གི་ཟབ་གཞི་སློབ་གྱི་ཐབས་ལམ་ཞིག་རེད། གཞུང་འབྲེལ་གྱི་གནད', 'ha': "@ item license (short name) A shekara 2020, Muka aika da sauran biyu da aka samu hanyoyi biyu. Babban ta farko yana da haɗi da filin da aka ƙayyade (CRF) da wata hanyor motsi na BERT masu ƙari da sanarwa. Dukkan na zama wata misalin BERT-na'asar da aka sanar da kai. Mataimakin rasmi na nuna cewa run1 ya sami da sauri mafi daidai 0.9870 da sauri mafi ƙasƙanci na sifar ƙarya a gane 0.0163, alhãli kuwa run2 yana iya ƙaranci da aikin taƙaita.", 'sk': 'Ta prispevek poroča o našem kitajskem sistemu diagnoze slovničnih napak v skupni nalogi NLPTEA-2020 CGED. Leta 2020 smo poslali dve vožnji z dvema pristopoma. Prvo je kombinacija pogojnih naključnih polj (CRF) in pristopa BERT modela globokega učenja. Drugi je model globokega učenja BERT. Uradni rezultati kažejo, da je naš run1 dosegel najvišjo stopnjo natančnosti 0,9875 z najnižjo stopnjo lažnih pozitivov 0,0163 pri zaznavanju, medtem ko run2 zagotavlja bolj uravnoteženo zmogljivost.'}
{'en': 'Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task', 'ar': 'نظام تشخيص الأخطاء النحوية الصيني المستند إلى BERT في المهمة المشتركة NLPTEA-2020 CGED', 'pt': 'Sistema de diagnóstico de erros gramaticais chinês com base no BERT na tarefa compartilhada NLPTEA-2020 CGED', 'es': 'Sistema de diagnóstico de errores gramaticales chinos basado en BERT en NLPTEA-2020 CGED Shared Task', 'fr': 'Système de diagnostic des erreurs grammaticales chinoises basé sur le BERT lors de la tâche partagée NLPTEA-2020 CGED', 'ja': 'NLPTEA -2020 CGED共有タスクでのBERTに基づく中国語文法エラー診断システム', 'zh': '盖BERT之汉语语法错误诊断系统在NLPTEA-2020 CGED共之', 'ru': 'Китайская система диагностики грамматических ошибок на основе BERT на NLPTEA-2020 CGED Shared Task', 'hi': 'चीनी व्याकरणिक त्रुटियाँ निदान प्रणाली NLPTEA-2020 CGED साझा कार्य पर BERT पर आधारित', 'ga': 'Córas Diagnóisithe Earráidí Gramadaí na Síne Bunaithe ar BERT ag Tasc Comhroinnte CGED NLPTEA-2020', 'ka': 'QFontDatabase', 'hu': 'Kínai nyelvtani hibák diagnosztikai rendszere BERT alapján az NLPTEA-2020 CGED megosztott feladaton', 'el': 'Κινεζικό σύστημα διάγνωσης γραμματικών σφαλμάτων βασισμένο στο Κοινή Εργασία', 'it': 'Sistema di diagnosi degli errori grammaticali cinesi basato su BERT al compito condiviso CGED NLPTEA-2020', 'kk': 'NLPTEA- 2020 CGED ортақ тапсырмасына негізделген қытайша грамматикалық қателер диагнозы жүйесі', 'lt': 'Kinijos gramatinių klaidų diagnozavimo sistema, pagrįsta BERT NLPTEA-2020 CGED bendroje užduotyje', 'mk': 'Кинескиот систем за дијагностика на граматски грешки базиран на BERT на NLPTEA-2020 CGED споделена задача', 'ms': 'Sistem Diagnosis Ralat Grammatik Cina Berdasarkan BERT pada Tugas Berkongsi NLPTEA-2020 CGED', 'ml': 'NLPTEA- 2020 CGED പങ്കുചേര്\u200dത്ത പണിയില്\u200d BERT അടിസ്ഥാനമായി അടിസ്ഥാനമായി ചൈനീസ് ഗ്രാമാറ്റിക്കല്\u200d പിശകുകള്\u200d', 'mn': 'НLPTEA-2020 CGED хуваалтын ажил дээр BERT-д багтсан Хятад Грамматикийн алдаа', 'mt': 'Sistema ta’ Dijanjożi ta’ Żbalji Grammatiċi Ċiniżi bbażata fuq BERT f’Kompitu Konġunt NLPTEA-2020 CGED', 'ro': 'Sistemul de diagnosticare a erorilor gramaticale chinezești bazat pe BERT la activitatea partajată CGED NLPTEA-2020', 'no': 'Kinesisk Grammatiske feil Diagnosis System basert på BERT på NLPTEA-2020 CGED delt oppgåve', 'pl': 'Chiński system diagnostyki błędów gramatycznych oparty na BERT w NLPTEA-2020 CGED Shared Task', 'sr': 'Kineski sistem za dijagnozu grešaka baziran na BERT na NLPTEA-2020 CGED zajedničkom zadatku', 'si': 'චීනි ග්\u200dරාම්ටික් වැරදිලි සංඥානය පද්ධතිය NLPTEA-2020දී පද්ධතිය', 'sv': 'Kinesiskt grammatiska fel Diagnossystem baserat på BERT vid NLPTEA-2020 CGED delad uppgift', 'so': 'Xiineeya dhibaatooyinka ku saabsan diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task', 'ta': 'Comment', 'ur': 'NLPTEA-2020 CGED Shared Task پر BERT پر بنیاد رکھی چینی گرامٹیکل تخطار', 'uz': 'Name', 'vi': 'Hệ thống phân tích biểu đồ học của Trung Quốc', 'bg': 'Система за диагностика на китайски граматични грешки въз основа на споделена задача', 'hr': 'Kineski sistem za dijagnozu grešaka baziran na BERT-u na NLPTEA-2020 CGED zajedničkom zadatku', 'da': 'Kinesisk grammatiske fejldiagnosesystem baseret på BERT ved NLPTEA-2020 CGED delt opgave', 'nl': 'Chinese grammaticale fouten diagnosesysteem gebaseerd op BERT bij NLPTEA-2020 CGED Gedeelde taak', 'de': 'Chinesisches Grammatikfehler-Diagnosesystem basierend auf BERT bei NLPTEA-2020 CGED Shared Task', 'id': 'Sistem Diagnosis Galat Grammatis Cina Berdasarkan BERT di NLPTEA-2020 CGED Shared Task', 'ko': 'BERT 기반 NLPTEA-2020 CGED 공유 작업 중국어 문법 오류 진단 시스템', 'fa': 'سیستم شناسایی خطاهای گرماتیک چینی بر اساس BERT در کار مشترک NLPTEA-2020', 'tr': 'Grammatikal Hatalar', 'af': 'Sjinese Gramatiese Foute Diagnosies Stelsel Gebaseer op BERT by NLPTEA- 2020 CGED Gedeelde Opdrag', 'sq': 'Sistemi Kinez i Diagnozës së Gabimeve Gramatike Bazuar në BERT në NLPTEA-2020 CGED Task Shared', 'am': 'Chinese Grammatical Error Diagnosis System Based on NLPTEA-2020 CGED Shared Task', 'hy': 'Չինաստանի գրամմատիկ սխալների ախտորոշման համակարգը, հիմնված BER-ի վրա, ՆԼՊՏԵԱ-2020 թվականի CGeD ընդհանուր հանձնարարության ժամանակ', 'az': 'NLPTEA-2020 CGED paylaşdırılmış Gözmə Based on BERT', 'bn': 'NLPTEA-2020 CGED ভাগাভাগি করা কাজের উপর ভিত্তিক চীনা গ্রামাটিক্যাল ত্রুটি ডিয়াগনিং সিস্টেম', 'bs': 'Kineski sistem za dijagnozu grešaka baziran na BERT na NLPTEA-2020 CGED zajedničkom zadatku', 'ca': "Sistema de diagnòstic d'errors gramàtics xinès basat en BERT a NLPTEA-2020 CGED Shared Task", 'cs': 'Čínský systém diagnostiky gramatických chyb založený na BERT na NLPTEA-2020 CGED Shared Task', 'sw': 'Mfumo wa Uchaguzi wa Tamko wa Kichina umetokana na BERT kwenye kazi ya NLPTEA-2020 CGED', 'et': 'Hiina grammatiliste vigade diagnostika süsteem, mis põhineb BERT-il NLPTEA-2020 CGED jagatud ülesanne', 'fi': 'Kiinan kielioppivirheiden diagnosointijärjestelmä perustuu BERT-järjestelmään NLPTEA-2020 CGED Shared Task -tapahtumassa', 'jv': 'Chinese Graph Eror', 'he': 'Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task', 'ha': 'KCharselect unicode block name', 'sk': 'Kitajski slovnični sistem diagnosticiranja napak na podlagi BERT na skupni nalogi NLPTEA-2020 CGED', 'bo': 'རྒྱ་ནག་གི་Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task'}
{'en': 'In the process of learning Chinese, second language learners may have various grammatical errors due to the negative transfer of native language. This paper describes our submission to the NLPTEA 2020 shared task on CGED. We present a hybrid system that utilizes both detection and correction stages. The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation. The correction stage is a hybrid model based on the n-gram and Seq2Seq. Without adding additional features and external data, the BERT contextual word representation can effectively improve the performance metrics of Chinese grammatical error detection and correction.', 'ar': 'في عملية تعلم اللغة الصينية ، قد يكون لمتعلمي اللغة الثانية أخطاء نحوية مختلفة بسبب النقل السلبي للغة الأم. تصف هذه الورقة تقديمنا إلى المهمة المشتركة لـ NLPTEA 2020 على CGED. نقدم نظامًا هجينًا يستخدم كل من مرحلتي الكشف والتصحيح. مرحلة الاكتشاف عبارة عن نموذج تصنيف متسلسل يعتمد على تمثيل الكلمات السياقية BiLSTM-CRF و BERT. مرحلة التصحيح عبارة عن نموذج هجين يعتمد على n-gram و Seq2Seq. بدون إضافة ميزات وبيانات خارجية إضافية ، يمكن لتمثيل الكلمات السياقية BERT تحسين مقاييس أداء اكتشاف الأخطاء النحوية الصينية وتصحيحها بشكل فعال.', 'fr': "Dans le processus d'apprentissage du chinois, les apprenants de langue seconde peuvent avoir diverses erreurs grammaticales en raison du transfert négatif de la langue maternelle. Ce document décrit notre soumission à la tâche partagée NLPTEA 2020 sur la CGED. Nous présentons un système hybride qui utilise à la fois des étapes de détection et de correction. L'étape de détection est un modèle de marquage séquentiel basé sur la représentation de mots contextuels BILSTM-CRF et BERT. L'étape de correction est un modèle hybride basé sur le n-gramme et Seq2Seq. Sans ajouter de fonctionnalités supplémentaires ni de données externes, la représentation contextuelle des mots BERT peut améliorer efficacement les mesures de performance de la détection et de la correction des erreurs grammaticales chinoises.", 'es': 'En el proceso de aprendizaje del chino, los estudiantes de un segundo idioma pueden tener varios errores gramaticales debido a la transferencia negativa de la lengua materna. Este documento describe nuestra presentación a la tarea compartida de la NLPTEA 2020 sobre CGED. Presentamos un sistema híbrido que utiliza etapas de detección y corrección. La etapa de detección es un modelo de etiquetado secuencial basado en la representación de palabras contextuales BILSTM-CRF y BERT. La etapa de corrección es un modelo híbrido basado en n-gram y Seq2Seq. Sin añadir funciones adicionales ni datos externos, la representación contextual de palabras BERT puede mejorar eficazmente las métricas de rendimiento de la detección y corrección de errores gramaticales chinos.', 'pt': 'No processo de aprendizagem do chinês, os aprendizes de segunda língua podem ter vários erros gramaticais devido à transferência negativa da língua nativa. Este artigo descreve nossa submissão à tarefa compartilhada NLPTEA 2020 no CGED. Apresentamos um sistema híbrido que utiliza etapas de detecção e correção. A etapa de detecção é um modelo de rotulagem sequencial baseado na representação de palavras contextuais BiLSTM-CRF e BERT. A etapa de correção é um modelo híbrido baseado no n-gram e Seq2Seq. Sem adicionar recursos adicionais e dados externos, a representação de palavras contextuais do BERT pode melhorar efetivamente as métricas de desempenho da detecção e correção de erros gramaticais em chinês.', 'ja': '中国語を学習する過程で、第二言語の学習者はネガティブな母国語の転送のためにさまざまな文法的誤りを抱える可能性があります。本稿では、CGEDに関するNLPTEA 2020共有タスクへの提出について説明します。検出段階と補正段階の両方を利用するハイブリッドシステムを提示します。検出段階は、ＢｉＬＳＴＭ － ＣＲＦ及びＢＥＲＴ文脈的単語表現に基づく逐次標識モデルである。補正段階は、n - gramとSeq 2 Seqに基づくハイブリッドモデルである。追加機能や外部データを追加することなく、BERTコンテキスト単語表現は、中国語文法のエラー検出と修正のパフォーマンスメトリクスを効果的に改善することができます。', 'hi': 'चीनी सीखने की प्रक्रिया में, दूसरी भाषा सीखने वालों में मूल भाषा के नकारात्मक हस्तांतरण के कारण विभिन्न व्याकरणिक त्रुटियां हो सकती हैं। यह पेपर CGED पर NLPTEA 2020 साझा कार्य के लिए हमारे सबमिशन का वर्णन करता है। हम एक हाइब्रिड सिस्टम प्रस्तुत करते हैं जो पता लगाने और सुधार दोनों चरणों का उपयोग करता है। पता लगाने का चरण BiLSTM-CRF और BERT प्रासंगिक शब्द प्रतिनिधित्व के आधार पर एक अनुक्रमिक लेबलिंग मॉडल है। सुधार चरण n-gram और Seq2Seq पर आधारित एक हाइब्रिड मॉडल है। अतिरिक्त सुविधाओं और बाहरी डेटा को जोड़ने के बिना, BERT प्रासंगिक शब्द प्रतिनिधित्व प्रभावी ढंग से चीनी व्याकरणिक त्रुटि का पता लगाने और सुधार के प्रदर्शन मैट्रिक्स में सुधार कर सकते हैं।', 'zh': '学汉语者,母语负面移,第二语言学者或有语法错误。 本文介我NELPTEA 2020交CGED共之。 臣等建一混合系统,当以检测校正之。 检者,BiLSTM-CRFBERT上下文词之序也。 校正者,n-gramSeq2Seq之混形也。 不加特征、外数者,BERT语境词有效汉语语法错误检正之性能指标。', 'ru': 'В процессе изучения китайского языка, изучающие второй язык, могут иметь различные грамматические ошибки из-за отрицательной передачи родного языка. В этом документе описывается наше представление совместной задаче NLPTEA 2020 по CGED. Мы представляем гибридную систему, которая использует как стадии обнаружения, так и стадии коррекции. Этап обнаружения представляет собой последовательную модель маркировки, основанную на представлении контекстного слова BiLSTM-CRF и BERT. Этап коррекции представляет собой гибридную модель, основанную на n-грамме и Seq2Seq. Без добавления дополнительных функций и внешних данных представление контекстного слова BERT может эффективно улучшить показатели производительности китайского грамматического обнаружения и исправления ошибок.', 'ga': 'I bpróiseas foghlama na Síne, d’fhéadfadh go mbeadh earráidí gramadaí éagsúla ag foghlaimeoirí dara teanga mar gheall ar aistriú diúltach na teanga dúchais. Déanann an páipéar seo cur síos ar ár n-aighneacht do thasc roinnte NLPTEA 2020 ar CGED. Cuirimid córas hibrideach i láthair a úsáideann céimeanna braite agus ceartúcháin araon. Múnla lipéadaithe seicheamhach atá sa chéim braite bunaithe ar léiriú focal comhthéacsúla BiLSTM-CRF agus BERT. Samhail hibrideach atá sa chéim cheartúcháin bunaithe ar an n-gram agus an Seq2Seq. Gan gnéithe breise agus sonraí seachtracha a chur leis, is féidir le hionadaíocht focail comhthéacsúla BERT feabhas a chur go héifeachtach ar mhéadracht feidhmíochta braite agus ceartú earráide gramadaí na Síne.', 'hu': 'A kínai tanulás során a második nyelvtanulóknak különböző nyelvtani hibák lehetnek az anyanyelv negatív átadása miatt. Ez a tanulmány bemutatja, hogy benyújtottunk az NLPTEA 2020 közös feladatra a CGED-re. Bemutatunk egy hibrid rendszert, amely mind az észlelési, mind a korrekciós szakaszokat használja. Az észlelési szakasz egy szekvenciális címkézési modell, amely BiLSTM-CRF és BERT kontextuális szóábrázoláson alapul. A korrekciós szakasz egy hibrid modell, amely az n-grammon és Seq2Seq alapul. További funkciók és külső adatok hozzáadása nélkül a BERT kontextuális szóábrázolása hatékonyan javíthatja a kínai nyelvtani hibaészlelés és -korrekció teljesítménymutatóit.', 'el': 'Κατά τη διαδικασία εκμάθησης κινέζικων, οι μαθητές δεύτερης γλώσσας ενδέχεται να έχουν διάφορα γραμματικά λάθη λόγω της αρνητικής μεταφοράς της μητρικής γλώσσας. Η παρούσα εργασία περιγράφει την υποβολή μας στο κοινό έργο του NLPTEA 2020 για την CGED. Παρουσιάζουμε ένα υβριδικό σύστημα που χρησιμοποιεί τόσο τα στάδια ανίχνευσης όσο και διόρθωσης. Το στάδιο ανίχνευσης είναι ένα διαδοχικό μοντέλο επισήμανσης βασισμένο στην αναπαράσταση λέξεων BiLSTM-CRF και BERT. Το στάδιο διόρθωσης είναι ένα υβριδικό μοντέλο βασισμένο στο n-γραμμάριο και το Seq2Seq. Χωρίς προσθήκη πρόσθετων χαρακτηριστικών και εξωτερικών δεδομένων, η απεικόνιση λέξεων στο πλαίσιο μπορεί αποτελεσματικά να βελτιώσει τις μετρήσεις απόδοσης της κινεζικής γραμματικής ανίχνευσης και διόρθωσης σφαλμάτων.', 'ka': 'ჩინეთის სწავლების პროცესში, მეორე ენის სწავლებელი შესაძლებელია განსხვავებული გრამიმატური შეცდომილებები, რადგან მისი ენის გადატანსტრიქციის განსაკუთრებული ეს დოკუმენტი ჩვენი გახსნა NLPTEA 2020-ის გაყოფილი CGED-ზე. ჩვენ აჩვენებთ ჰიბრიდის სისტემა, რომელიც გამოიყენებს განახლება და კონფიგურაცია. განახლების ფაეზი არის სიტყვების გამოსახულება BiLSTM-CRF და BERT კონტექსტური სიტყვების გამოსახულება. კონფიგურაციის ფაეზია n-გრამის და Seq2Seq-ის დაბაზეული ჰიბრიტის მოდელი. BERT-ის კონტექსტური სიტყვების გამოსახულება შეუძლია წინასწარმოდგენება ჩინეთის გრამიკალური შეცდომის განსახულება და კონტექსტური შეცდომის გამოსახულება.', 'it': 'Nel processo di apprendimento del cinese, gli studenti di seconda lingua possono avere vari errori grammaticali a causa del trasferimento negativo della lingua madre. Questo articolo descrive la nostra presentazione al compito condiviso NLPTEA 2020 su CGED. Presentiamo un sistema ibrido che utilizza sia fasi di rilevamento che di correzione. La fase di rilevamento è un modello di etichettatura sequenziale basato sulla rappresentazione contestuale di parole BiLSTM-CRF e BERT. La fase di correzione è un modello ibrido basato su n-gram e Seq2Seq. Senza aggiungere funzionalità aggiuntive e dati esterni, la rappresentazione contestuale delle parole BERT può migliorare efficacemente le metriche di performance del rilevamento e correzione degli errori grammaticali cinesi.', 'lt': 'Mokymosi kinų kalba metu antrosios kalbos mokytojai gali patirti įvairių gramatinių klaidų dėl neigiamo gimtosios kalbos perdavimo. Šiame dokumente apibūdinamas mūsų pranešimas bendrai NLPTEA 2020 uždaviniui CGED. Mes pristatome hibridinę sistemą, kuri naudoja ir aptikimo, ir koregavimo etapus. Nustatymo etapas yra sekos ženklinimo model is, pagrįstas BiLSTM-CRF ir BERT kontekstiniu žodžių vaizdu. Korekcijos etapas yra hibridinis model is, pagrįstas n-gramais ir Seq2Seq. Be papildomų charakteristikų ir išorinių duomenų BERT kontekstinis žodžių atstovavimas gali veiksmingai pagerinti Kinijos gramatinių klaidų nustatymo ir ištaisymo rezultatų rodiklius.', 'kk': 'Қытай тілді оқыту процесінде, екінші тілді оқытушылардың негативті тілді аудару үшін грамматикалық қатесі болуы мүмкін. Бұл қағаз NLPTEA 2020 бағытталған тапсырмаға CGED жіберімізді таңдайды. Біз анықтау мен түзету сәттерін қолданатын гибрид жүйесін таңдаймыз. Табу кезегі - BiLSTM- CRF және BERT контекстік сөздерді таңдау үлгісі. Түзету кезегі n- грамма және Seq2Seq негіздеген гибрид моделі. Қосымша мүмкіндіктерді және сыртқы деректерді қосуға болмаса, BERT контексті сөздерді таңдау үшін Қытай грамматикалық қателерді анықтау және түзетуге болады.', 'mk': 'Во процесот на учење кинески, учениците на вториот јазик можеби имаат различни граматични грешки поради негативниот трансфер на родниот јазик. Овој документ го опишува нашето поднесување на заедничката задача на НЛПТЕА 2020 за ЦГЕД. Презентираме хибриден систем кој ги користи и стадиите на детекција и корекција. Стапата на детекција е секвенцијален модел за означување базиран на БиLSTM-CRF и BERT контекстна претстава на зборовите. Стапата на корекција е хибриден модел базиран на n-грам и Seq2Seq. Без додавање дополнителни карактеристики и надворешни податоци, контекстното претставување на зборовите БЕРТ може ефикасно да ја подобри метриката на резултатите на детекцијата и корекцијата на кинеските граматички грешки.', 'ms': 'Dalam proses belajar bahasa Cina, pelajar bahasa kedua mungkin mempunyai pelbagai ralat grammatik disebabkan pemindahan negatif bahasa asli. Kertas ini menjelaskan penghantaran kami kepada tugas kongsi NLPTEA 2020 pada CGED. Kami memperkenalkan sistem hibrid yang menggunakan kedua-dua tahap pengesan dan pembetulan. Tahap pengesan adalah model label sekuensi berdasarkan perwakilan perkataan kontekstual BiLSTM-CRF dan BERT. Tahap penyesuaian adalah model hibrid berdasarkan n-gram dan Seq2Seq. Tanpa menambah ciri-ciri tambahan dan data luaran, perwakilan perkataan kontekstual BERT boleh meningkatkan metrik prestasi pengesan dan perbaikan ralat grammatik Cina.', 'ml': 'ചൈനീസ് പഠിക്കുന്ന പ്രക്രിയയില്\u200d, രണ്ടാമത്തെ ഭാഷ പഠിക്കുന്നവര്\u200dക്ക് നേരിട്ട് ഭാഷ മാറ്റുന്നതിനാല്\u200d പല ഗ്രാമാ ഈ പത്രത്തില്\u200d സിജെഡിയില്\u200d പങ്കുചേര്\u200dത്ത ജോലിയെ നമ്മുടെ നിയന്ത്രണത്തെക്കുറിച്ച് പറയുന്നു. ഞങ്ങള്\u200d ഒരു ഹൈബ്രിഡ് സിസ്റ്റം കൊണ്ടുവരുന്നു. അത് കണ്ടുപിടിക്കുന്നതും ശരിയാക്കുന്നതും ഉപയോഗിക്കു ബിഎല്\u200dഎസ്റ്റി- CRF- നെ അടിസ്ഥാനമാക്കിയ ഒരു സാധാരണ ലേബെലിങ്ങ് മോഡലാണ് കണ്ടുപിടിക്കുന്നത്. ബെര്\u200dട്ടി നിലവിലുള്ള ന്\u200d ഗ്രാമും സെക്ക്2സെക്കും അടിസ്ഥാനമായി ഒരു ഹൈബ്രിഡ് മോഡലാണ്. കൂടുതല്\u200d ഗുണഗണങ്ങളും പുറത്തുള്ള വിവരങ്ങളും കൂട്ടിചേര്\u200dക്കാതെ, ബെര്\u200dട്ടി നിലവിലുള്ള വാക്ക് പ്രദര്\u200dശിപ്പിക്കുന്നത് ചൈനീസ് ഗ്രാമ്ര', 'mt': 'Fil-proċess tat-tagħlim taċ-Ċiniż, l-istudenti tat-tieni lingwa jista’ jkollhom diversi żbalji grammatiċi minħabba t-trasferiment negattiv tal-lingwa nattiva. Dan id-dokument jiddeskrivi s-sottomissjoni tagħna lill-kompitu komuni NLPTEA 2020 dwar is-CGED. Aħna nippreżentaw sistema ibrida li tuża kemm l-istadji ta’ detezzjoni kif ukoll ta’ korrezzjoni. L-istadju ta’ detezzjoni huwa mudell sekwenzjali ta’ tikkettar ibbażat fuq ir-rappreżentazzjoni kuntestwali tal-kelma BiLSTM-CRF u BERT. L-istadju ta’ korrezzjoni huwa mudell ibridu bbażat fuq n-gramma u Seq2Seq. Mingħajr iż-żieda ta’ karatteristiċi addizzjonali u dejta esterna, ir-rappreżentanza tal-kelma kuntestwali BERT tista’ ttejjeb b’mod effettiv il-metriċi tal-prestazzjoni tal-identifikazzjoni u l-korrezzjoni ta’ żbalji grammatiċi Ċiniżi.', 'mn': 'Хятад хэлний суралцах үйл явцдаа хоёр дахь хэл сурагчид ээж хэлийн сөрөг шилжүүлэлтийн шалтгаан олон грамматикийн алдаа байж болно. Энэ цаас бидний NLPTEA 2020-ийн CGED-д хуваалцах ажлыг тайлбарладаг. Бид олох болон зөв загварыг ашигладаг гибрид системийг харуулж байна. Тайлбарлах шатан нь BiLSTM-CRF болон BERT контекст үг илэрхийлэх загвар юм. Шулгалтын шатан нь n-грамм болон Seq2Seq-ын үндсэн гибрид загвар юм. Нэг нэмэлт чанар болон гадаад өгөгдлийг нэмэгдэхгүй байвал, BERT-ын орчин үеийн үзүүлэлт нь Хятад грамматикийн алдаа гаргах болон шууд байдлын үйлдвэрлэлтийн метрикийг үр дүнтэй сайжруулж чадн', 'no': 'I læring av kinesisk kan andre språkelærar ha ulike grammatiske feil på grunn av negativt overføring av språk. Denne papiret beskriver vårt oppføring til delt oppgåve NLPTEA 2020 på CGED. Vi presenterer eit hybrid system som brukar både oppdaging og rettingsstader. Oppdagingsstaden er ein sekvensisk merkelappemodell basert på BiLSTM-CRF og BERT-kontekstalt ordrepresentasjon. Korrigeringsstaden er ein hybridmodell basert på n-gram og Seq2Seq. Utan å leggja til eksterne funksjonar og eksterne data, kan BERT- kontekst- ordrepresentasjonen effektivt forbedra utviklingsmeterikatoren til kinesisk grammatisk feiloppdaging og retting.', 'pl': 'W procesie nauki chińskiego uczący się języka drugiego mogą mieć różne błędy gramatyczne z powodu negatywnego transferu języka ojczystego. Niniejszy artykuł opisuje nasze zgłoszenie do wspólnego zadania NLPTEA 2020 na CGED. Prezentujemy system hybrydowy, który wykorzystuje zarówno etapy detekcji, jak i korekcji. Etap wykrywania jest sekwencyjnym modelem etykietowania opartym na kontekstowej reprezentacji słów BiLSTM-CRF i BERT. Etap korekcji jest modelem hybrydowym opartym na n-gramie i Seq2Seq. Bez dodawania dodatkowych funkcji i danych zewnętrznych, kontekstowa reprezentacja słów BERT może skutecznie poprawić wskaźniki wydajności chińskiego wykrywania i korekcji błędów gramatycznych.', 'ro': 'În procesul de învățare a limbii chineze, cursanții de limbă a doua pot avea diferite erori gramaticale din cauza transferului negativ al limbii materne. Această lucrare descrie prezentarea noastră la sarcina comună NLPTEA 2020 privind CGED. Vă prezentăm un sistem hibrid care utilizează atât etapele de detecție, cât și cele de corecție. Etapa de detectare este un model de etichetare secvențială bazat pe reprezentarea contextuală a cuvintelor BiLSTM-CRF și BERT. Etapa de corecție este un model hibrid bazat pe n-gram și Seq2Seq. Fără a adăuga caracteristici suplimentare și date externe, reprezentarea contextuală a cuvintelor BERT poate îmbunătăți eficient măsurătorile performanței detectării și corectării erorilor gramaticale chinezești.', 'sr': 'U procesu učenja kineskog jezika drugi učitelji mogu imati različite gramatičke greške zbog negativnog prenošenja jezika. Ovaj papir opisuje našu predanost podijeljenom zadatku NLPTEA 2020 o CGED-u. Predstavljamo hibridni sistem koji koristi detektive i korekcije. Stadija otkrivanja je sekvencijski model označavanja na temelju BiLSTM-CRF i BERT kontekstualne reči. Korekcija je hibridni model baziran n a n-gramu i Seq2Seq. Bez dodavanja dodatnih karakteristika i spoljnih podataka, predstavljanje BERT-a kontekstualne reči može učinkovito poboljšati metriku učinkovitosti kineskog gramatičkog otkrivanja i isprave grešaka.', 'si': 'චීනි භාෂාව ඉගෙන ගන්න ප්\u200dරකාරයේ දෙවෙනි භාෂාව ඉගෙන ගන්න පුළුවන් විවිධ වැරදිලි තියෙන්න පුළු මේ පැත්තේ අපේ පිළිගන්නේ NLPTEA 2020යි CGED ගැන කැමති වැඩක් විතරයි. අපි හායිබ්\u200dරිඩ් පද්ධතියක් පෙන්වන්නේ, ඒ වගේම හොයාගන්න සහ සුදුසුම් පද්ධතියක් ප්\u200dරයෝජන හොයාගන්න ස්ථානය තමයි BiLSTM-CRF සහ BERT සාමාන්\u200dය වචන ප්\u200dරතිනිධානය සඳහා ප්\u200dරතිනිධානයක් විසින් ලේබිල් මඩ The correction stage is a hybroid Model based on the n-gram and Seq2Seq. විශේෂතාවක් සහ ප්\u200dරතික්\u200dරිය දත්ත සම්බන්ධ නොකරලා, BERT සම්බන්ධ වාර්තාවක් වචන ප්\u200dරතික්\u200dරියාපනය ප්\u200dරතික්\u200dරියාපන', 'sv': 'I processen att lära sig kinesiska kan andraspråkslärare ha olika grammatiska fel på grund av negativ överföring av modersmål. Denna uppsats beskriver vår inlämning till NLPTEA 2020 delade uppgift om CGED. Vi presenterar ett hybridsystem som använder både detekterings- och korrigeringsstadier. Detektionssteget är en sekventiell märkningsmodell baserad på BiLSTM-CRF och BERT kontextuell ordrepresentation. Korrigeringsfasen är en hybridmodell baserad på n-gram och Seq2Seq. Utan att lägga till ytterligare funktioner och externa data kan BERT:s kontextuella ordrepresentation effektivt förbättra prestandamätningarna för detektering och korrigering av kinesiska grammatiska fel.', 'so': "Marka lagu jiro barashada Shiino waxaa laga yaabaa in dadka baranaya luqada labaad ay leeyihiin khalad kala duduwan grammatika sababtoo ah wareejinta afka hooyo. This paper describes our submission to the NLPTEA 2020 shared task on CGED.  Waxaan keenaynaa nidaam hibir ah oo isticmaalaya baaritaanka iyo hagitaanka. Xarunta caddeyntu waa model sawir ah oo ku saleysan BiLSTM-CRF iyo BERT oo ku qoran qoraalka xilliga ah. Heerka hagitaanku waa muusikada hybridka oo ku saleysan n-gram iyo Seq2Seq. Xiriir dheeraad ah iyo macluumaad dibadda ah la'aanta, qayb-dhigista erayga joogtada ah ee BERT wuxuu si fiican u beddeli karaa qaababka ku saabsan cadayn iyo hagaajinta khaladda ee Shiino.", 'ta': 'சீன கற்றுக்கொள்ளும் செயல்பாட்டில், இரண்டாவது மொழி கற்றுக்கொள்பவர் This paper describes our submission to the NLPTEA 2020 shared task on CGED.  நாம் கண்டறிதல் மற்றும் திருத்தம் முறைகளை பயன்படுத்தும் ஒரு ஹைப்ரி அமைப்பை காண்பிக்கிறோம். The detection stage is a sequential labelling model based on BiLSTM- CRF and BERT contextual word representation. The correction stage is a hybrid model based on the n- gram and Seq2Seq. கூடுதல் குணங்கள் மற்றும் வெளி தரவுகளை சேர்க்காமல், BERT தற்காலிக வார்த்தை குறிப்பிடுதல் சீனா வரையறை பிழை கண்டுபிடிப்பு மற்றும் திருத', 'ur': 'چین کی تعلیم کے مطابق دوسری زبان سکھانے والوں کے لئے مختلف گراماتیکی خطا ہوسکتے ہیں ماں کی زبان کی منفی ترافرست کے سبب۔ This paper describes our submission to the NLPTEA 2020 shared task on CGED. ہم ایک ہیبراڈ سیستم کو پیش کریں جو پہچان اور اصلاح مرحلے کو استعمال کرتا ہے۔ آشنا سٹیج BiLSTM-CRF اور BERT contextual word representation پر بنیاد ایک سٹیل لیبلینگ موڈل ہے. اصلاح مرحلہ ایک ہیبراڈ موڈل ہے جو n-گرم اور Seq2Seq پر بنیاد ہے. بغیر اس کے کہ زیادہ ویژگی اور بیرونی ڈیٹا اضافہ نہ کریں، BERT کنٹکسٹیول کلمات کی نمایش چینی گراماتیکی خطا شناسایی اور اصلاح کی عملکرد متریک کو عمدہ کر سکتی ہے.', 'uz': "Xitoycha o'rganishda ikkinchi tillar o'rganishlari natiy tillarining negativ tarjima qilishi sababini boshqa grammatik xatolari bo'lishi mumkin. Bu qogʻoz CGED (NLPTEA 2020) bilan birlashtirilgan vazifani anglatadi. Biz haybrid tizimini aniqlash va toʻgʻrilash holatidan foydalanishimiz. Name Toʻgʻri sahifa - n- gram va Seq2Seq asosida ishlatilgan hybrid modeli. Qoʻshimcha moslamalar va externa maʼlumot qoʻshilmaydi, BERT'ning davomida soʻzni taʼminlashtirish va Xitoycha grammatikal xato aniqlashni va toʻgʻrilishini bajarishi mumkin.", 'vi': 'Trong quá trình học tiếng Trung, học giả ngôn ngữ thứ hai có thể có lỗi theo ngữ pháp khác nhau do sự chuyển đổi âm tính của ngôn ngữ bản xứ. Tờ giấy này mô tả việc chúng tôi đăng ký vào một nhiệm vụ chung chung NLlái 2020 ở CGEDed. Chúng tôi giới thiệu một hệ thống lai sử dụng cả các giai đoạn phát hiện và sửa chữa. Phát hiện trường là một mô hình mô phỏng sắp xếp dựa trên BiLSTM-CRF và BERT nền đại diện các từ ngữ. Bộ sửa chữa là một mô hình lai dựa trên n-gram và Seq2Seq. Không cần thêm các tính năng và dữ liệu bên ngoài, sự mô tả ngữ cảnh của thiếu sót sót sót sót sót sót của ngôn ngữ học Trung Hoa có thể cải thiện tỉ lệ hiệu quả.', 'bg': 'В процеса на изучаване на китайски, обучаващите се на втори език могат да имат различни граматически грешки поради отрицателния трансфер на родния език. Настоящата статия описва нашето представяне на споделената задача на НЛПТЕА 2020 по ЦЕД. Представяме хибридна система, която използва както етапите на откриване, така и на корекция. Етапът на откриване е модел на последователно етикетиране, базиран на контекстното представяне на думи. Етапът на корекция е хибриден модел, базиран на n-грама и Seq2Seq. Без добавяне на допълнителни функции и външни данни, контекстното представяне на думи може ефективно да подобри показателите за ефективност на откриването и корекцията на китайската граматична грешка.', 'da': "I processen med at lære kinesisk, andetsprogslærere kan have forskellige grammatiske fejl på grund af den negative overførsel af modersmål. Denne artikel beskriver vores indsendelse til NLPTEA 2020 delte opgave på CGED. Vi præsenterer et hybridsystem, der bruger både detektions- og korrektionsstadier. Detektionsfasen er en sekventiel mærkningsmodel baseret på BiLSTM-CRF og BERT kontekstuel ordrepræsentation. Korrektionsfasen er en hybridmodel baseret på n-grammet og Seq2Seq. Uden at tilføje yderligere funktioner og eksterne data kan BERT's kontekstuelle ordrepræsentation effektivt forbedre ydelsesmålingerne for registrering og korrektion af kinesisk grammatisk fejl.", 'nl': 'Tijdens het leren van Chinees kunnen tweetalige leerlingen verschillende grammaticale fouten hebben als gevolg van de negatieve overdracht van moedertaal. Dit document beschrijft onze inzending aan de NLPTEA 2020 gedeelde taak op CGED. We presenteren een hybride systeem dat zowel detectie- als correctiefasen gebruikt. De detectiefase is een sequentieel labelmodel gebaseerd op BiLSTM-CRF en BERT contextuele woordweergave. De correctiefase is een hybride model gebaseerd op de n-gram en Seq2Seq. Zonder extra functies en externe gegevens toe te voegen, kan de contextuele woordweergave van BERT de prestatiestatistieken van Chinese grammaticale foutdetectie en -correctie effectief verbeteren.', 'hr': 'U procesu učenja kineskog jezika, učitelji drugih jezika mogu imati različite gramatičke greške zbog negativnog prenošenja jezika. Ovaj papir opisuje naše podnošenje zajedničkom zadatku NLPTEA 2020 o CGED-u. Predstavljamo hibridni sustav koji koristi detektive i korekcije. Stadija otkrivanja je sekvencijski model označavanja na temelju BiLSTM-CRF i BERT kontekstualne riječi. Pozor isprave je hibridni model baziran n a n-gramu i Seq2Seq. Bez dodavanja dodatnih karakteristika i vanjskih podataka, predstavljanje BERT-a kontekstualne riječi može učinkovito poboljšati provedbenu metriku kineskog gramatičkog otkrivanja i isprave grešaka.', 'de': 'Während des Lernens von Chinesisch können Zweitsprachenlerner aufgrund des negativen Transfers der Muttersprache verschiedene grammatikalische Fehler haben. Dieses Papier beschreibt unsere Einreichung zur gemeinsamen Aufgabe NLPTEA 2020 auf CGED. Wir präsentieren ein Hybridsystem, das sowohl Detektions- als auch Korrekturstufen nutzt. Die Erkennungsstufe ist ein sequentielles Beschriftungsmodell basierend auf BiLSTM-CRF und BERT kontextueller Wortdarstellung. Die Korrekturstufe ist ein Hybridmodell basierend auf dem n-Gramm und Seq2Seq. Ohne zusätzliche Funktionen und externe Daten hinzuzufügen, kann die BERT kontextbezogene Wortdarstellung die Leistungskennzahlen der chinesischen grammatischen Fehlererkennung und -korrektur effektiv verbessern.', 'ko': '중국어를 배우는 과정에서 모국어의 마이너스 변화로 인해 제2언어 학습자는 각종 문법 오류가 발생할 수 있다.이 문서에서는 NLPTEA 2020 CGED 공유 임무에 제출된 상황을 설명합니다.우리는 검측과 교정 단계를 이용한 혼합 시스템을 제시했다.체크 단계는 BiLSTM CRF 및 BERT 컨텍스트 단어를 기반으로 하는 순차 태그 모델입니다.교정 단계는 n-gram과 Seq2Seq를 기반으로 한 혼합 모델이다.BERT 컨텍스트 단어는 추가 피쳐와 외부 데이터를 추가하지 않고도 중국어 구문 오류를 효과적으로 감지하고 수정할 수 있는 성능 지표를 나타냅니다.', 'id': 'Dalam proses belajar bahasa Cina, para pelajar bahasa kedua mungkin memiliki beberapa kesalahan grammatik karena transfer negatif bahasa asli. Kertas ini menjelaskan pengiriman kita ke NLPTEA 2020 tugas berbagi di CGED. Kami mempersembahkan sistem hibrid yang menggunakan kedua tahap deteksi dan koreksi. The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation.  Stadium koreksi adalah model hibrid berdasarkan n-gram dan Seq2Seq. Tanpa menambahkan karakteristik tambahan dan data luar, representasi kata kontekstual BERT dapat secara efektif meningkatkan metrik prestasi dari deteksi dan koreksi kesalahan grammatik Cina.', 'fa': 'در فرایند یادگیری چینی، دانش\u200cآموزان دوم زبان ممکن است اشتباه\u200cهای گرامیک مختلف داشته باشد به سبب انتقال منفی زبان مادری. این کاغذ تحویل ما به کار مشترک NLPTEA 2020 در CGED توصیف می\u200cکند. ما یک سیستم هیبرید را پیشنهاد می\u200cکنیم که از مرحله\u200cهای شناسایی و اصلاح استفاده می\u200cکند. مرحله شناسایی یک مدل نقاشی دنباله بر اساس نمایش کلمات متوسط BiLSTM-CRF و BERT است. مرحله اصلاح یک مدل hybrid بر اساس n-gram و Seq2Seq است. بدون اضافه کردن ویژگی\u200cهای اضافه و داده\u200cهای خارجی، نمایش کلمه\u200cهای متوسط BERT می\u200cتواند به طور تاثیر متریک عملکرد خطاهای گراماتیکی چینی را دریافت و درست کند.', 'sw': 'Katika mchakato wa kujifunza Kichina, wanafunzi wa lugha ya pili wanaweza kuwa na makosa mbalimbali ya kiuchumi kutokana na uhamishaji hasi wa lugha ya asili. Gazeti hili linaelezea ujumbe wetu wa NLPTEA 2020 uliosambazwa na kazi ya CGED. We present a hybrid system that utilizes both detection and correction stages.  Jukwaa la kutambua ni modeli ya maambukizi inayohusiana na BiLSTM-CRF na uwakilishi wa maneno ya wakati wa BERT. Jukwaa la uharibifu ni modeli ya hybrid inayotumiwa n a n-gram na Seq2Seq. Bila kuongezea vipengele vya ziada na takwimu za nje, uwakilishi wa maneno ya sasa ya BERT yanaweza kuboresha mbinu za uchunguzi wa makosa ya kiuchumi nchini China na kuharibiwa.', 'tr': 'Çinçe öwrenmek procesinde, ikinji dil öwrenmeýänleriň ene diliniň göçürmesi üçin dürli gramatik hatalarynyň bolup biler. Bu kagyz NLPTEA 2020-nji ýygnagymyzy CGED barada paýlaşýar. Biz bir hybrid sistemini tanyş we düzeltmek sahypalaryny ulanýan Bu deteksion sahnesi BiLSTM-CRF we BERT tesbitli kelime temsiline dayanan bir sıralan etiketleme modeldir. Düzeltmek sahypasy n-gram we Seq2Seq-a dayanan hybrid nusgasydir. Eger özellikler we daşarydaky maglumatlary eklemeýän bolsa, BERT senesasy sözleriň üýtgetmesi Çinçe gramatik hatalaryň tanymasynyň we düzeltmeginin üstine çykaryp biler.', 'sq': 'Në procesin e mësimit të kinezës, mësuesit e gjuhës së dytë mund të kenë gabime të ndryshme grammatike për shkak të transferimit negativ të gjuhës natyrore. Ky dokument përshkruan paraqitjen tonë në detyrën e përbashkët të NLPTEA 2020 për CGED. Ne prezantojmë një sistem hibridë që përdorë si fazat e zbulimit, ashtu edhe të korrigjimit. Faza e zbulimit është një model shequencial etiketash bazuar në përfaqësimin kontekstual të fjalëve BiLSTM-CRF dhe BERT. Faza e korrigjimit është një model hibridë bazuar n ë n-gram dhe Seq2Seq. Pa shtimin e karakteristikave shtesë dhe të dhënave të jashtme, përfaqësimi kontekstual i fjalëve BERT mund të përmirësojë efektivisht metrikat e performancës të zbulimit dhe korrektimit të gabimeve grammatike kineze.', 'am': 'ቻይና በተማሩ ክፍል፣ ሁለተኛው ቋንቋ ተማሪዎቹ በአገሪው ቋንቋ መዘዋወር ምክንያት የግራማዊ ስህተት ይኖራል፡፡ ይህ ገጽ በCGED ላይ 2020 የNLPTEA አካባቢነታችንን ይናገራል፡፡ የኬብሪድ ስርዓት እና ማስታወቂያውን እና ማስታወቂያውን የሚጠቀም ነው፡፡ በቢLSTM-CRF እና BERT በተገኘ ቃላት መልዕክት ላይ የተመሳሳይ የጽሑፍ ሞዴል ነው፡፡ የ-ግራም እና Seq2Seq የተመሠረተ የኬብሪድ ሞዴል ነው፡፡ ባይጨመር ምርጫዎች እና ውጭ ዳታ ባይጨመር፣ የBERT የአሁኑን ቃል መልዕክት የቻይና የግራማሲካዊ ስህተት ማግኘት እና ማስተካከል ማድረግ ይችላል፡፡', 'af': "In die proses van die leer van Sjinese, tweede taal leerders mag verskeie grammatiese foute hê vanweë die negatiewe oordrag van die taal. Hierdie papier beskrywe ons onderskrywing aan die NLPTEA 2020 deel taak op CGED. Ons stel 'n hybrid stelsel wat gebruik word beide opdekking en korreksie stadige. Die opdekking stadium is 'n sekwensielle etiketting model gebaseer op BiLSTM- CRF en BERT konteksual woord voorsiening. Die korreksie stadium is 'n hibridmodel gebaseer op die n-gram en Seq2Seq. Sonder om addisionele funksies en eksterne data byvoeg te voeg, kan die BERT contextual woord verteenwoording effektief die prestasie metries van Sjinese grammatiese fout opdecking en korreksie verbeter.", 'hy': 'Չինաստանի ուսումնասիրության ընթացքում երկրորդ լեզվի ուսանողները կարող են ունենալ տարբեր գրամատիկ սխալներ՝ ծննդյան լեզվի բացասական փոխանցման պատճառով: Այս հոդվածը նկարագրում է մեր ներկայացումը ՆԼՊՏԵԱ 2020-ի ընդհանուր հանձնարարությանը CGeD-ի մասին: Մենք ներկայացնում ենք հիբրիդ համակարգ, որը օգտագործում է բացահայտումների և ուղղումների փուլերը: Բացահայտության փուլը հաջորդական պիտակագրման մոդել է, որը հիմնված է ԲիLSԹՄ-ԿՌՖ և ԲԵԹ-ի կոնտեքստային բառերի ներկայացման վրա: Կարգավորման փուլը հիբրիդ մոդել է, որը հիմնված է n-գրամի և SeQ2SeQ-ի վրա: Առանց ավելացնելու առանձնահատկություններ և արտաքին տվյալներ, BER-ի կոնտեքստիկ բառերի ներկայացումը կարող է արդյունավետ բարելավել չինական գրամատիկ սխալների հայտնաբերման և ուղղումների արտադրողականության չափում', 'bn': 'চীনা শিক্ষা প্রক্রিয়ায় দ্বিতীয় ভাষা শিক্ষার্থীদের স্থানীয় ভাষার নেতিবাচক পরিবর্তনের কারণে বিভিন্ন গ্রামাট এই পত্রিকাটি সিজেডিতে আমাদের এনএলপিটেয়া ২০২০ সালের প্রতি আমাদের প্রতিষ্ঠান বর্ণনা করেছে। আমরা একটা হাইব্রিড সিস্টেম উপস্থাপন করছি যা আবিষ্কার এবং সংস্কারের মাধ্যমে ব্যবহার করে। বিএলস্টিএম-CRF এবং বিবের্টি প্রতিনিধিত্বের উপর ভিত্তিক একটি পরবর্তী লেবেলিং মডেল। ন-গ্রাম এবং সেক২সেকের উপর ভিত্তিক একটি হাইব্রিড মডেল। অতিরিক্ত বৈশিষ্ট্য এবং বাইরের তথ্য যোগ করা ছাড়াই বিবেরেটি প্রতিনিধিত্ব বিভিন্ন শব্দের প্রতিনিধিত্বে চীনা গ্রাম্যাটিক্যাল ত্র', 'az': 'Çinli dilləri öyrənmək üçün ikinci dil öyrənənənçilərin yerli dillərin negatif tərəfindən müxtəlif qrammatik xətaları olar. Bu kağıt bizim NLPTEA 2020 CGED barəsində paylaşdığımız işləri tarif edir. Biz hər ikisini tanıma və düzəltmə fərqlərini istifadə edən hibrid sistemini göstəririk. İnternet sahəsi BiLSTM-CRF və BERT müxtəlif söz göstəricisinə dayanan sıralar etiketləmə modelidir. Düzeltme sahəsi n-gram və Seq2Seq üzərində dayanan hibrid modelidir. Əlavə fərqli və dış məlumatları əlavə etmədən, BERT müxtəlif sözlərin göstəricisi Çin qrammatik xətaların keşfini və düzəltməsini etkili olaraq daha yaxşılaşdıra bilər.', 'bs': 'U procesu učenja kineskog jezika, učitelji drugih jezika mogu imati različite gramatične greške zbog negativnog prenošenja jezika. Ovaj papir opisuje našu predanost podijeljenom zadatku NLPTEA 2020 o CGED-u. Predstavljamo hibridni sistem koji koristi detektive i korekcije. Stadija otkrivanja je sekvencijski model označavanja na temelju BiLSTM-CRF i BERT kontekstualne riječi. Korekcija je hibridni model baziran n a n-gramu i Seq2Seq. Bez dodavanja dodatnih karakteristika i vanjskih podataka, predstavljanje BERT-a kontekstualne riječi može učinkovito poboljšati metriku učinkovitosti kineskog gramatičkog otkrivanja i isprave grešaka.', 'ca': "In the process of learning Chinese, second language learners may have various grammatical errors due to the negative transfer of native language.  Aquest paper descriu la nostra presentació a la tasca compartida NLPTEA 2020 sobre CGED. Presentam un sistema híbrid que utilitza les etapes de detecció i correcció. L'etapa de detecció és un model d'etiquetage seqüencial basat en la representació contextual de paraules BiLSTM-CRF i BERT. L'etapa de correcció és un model híbrid basat en n-gram i Seq2Seq. Sense afegir característiques adicionals i dades externes, la representació contextual de paraules BERT pot millorar efectivament les mètriques de rendiment de la detecció i correcció d'errors gramàtics xinesos.", 'cs': 'Během výuky čínštiny mohou studenti druhého jazyka mít různé gramatické chyby v důsledku negativního přenosu rodného jazyka. Tento článek popisuje náš předložení sdíleného úkolu NLPTEA 2020 na CGED. Představujeme hybridní systém, který využívá jak detekční, tak korekční fáze. Detekční fáze je sekvenční model značení založený na kontextové reprezentaci slov BiLSTM-CRF a BERT. Korekční fáze je hybridní model založený na n-gramu a Seq2Seq. Bez přidávání dalších funkcí a externích dat může kontextová reprezentace slov BERT efektivně zlepšit výkonnostní metriky čínské gramatické chyby detekce a opravy.', 'fi': 'Toisen kielen oppijoilla voi olla erilaisia kieliopillisia virheitä äidinkielen negatiivisen siirron vuoksi. Tässä artikkelissa kuvataan osallistumismme NLPTEA 2020:n yhteiseen tehtävään CGED:ssä. Esittelemme hybridijärjestelmän, joka hyödyntää sekä havaitsemis- että korjausvaihetta. Havaintovaihe on BiLSTM-CRF- ja BERT-kontekstuaaliseen sanaesitykseen perustuva perättäinen merkintämalli. Korjausvaihe on hybridimalli, joka perustuu n-grammiin ja Seq2Seq. Ilman lisäominaisuuksia ja ulkoista dataa BERT-kontekstuaalinen sanaesitys voi tehokkaasti parantaa kiinalaisten kielioppivirheiden havaitsemisen ja korjaamisen suorituskykymittareita.', 'et': 'Hiina keele õppimisel võivad teise keele õppijatel olla emakeele negatiivse ülekande tõttu erinevad grammatikavead. Käesolevas dokumendis kirjeldatakse meie esitamist NLPTEA 2020 jagatud ülesandele CGED. Esitleme hübriidsüsteemi, mis kasutab nii tuvastamise kui ka parandamise etappi. Avastamisetapp on järjestikuse märgistuse mudel, mis põhineb BiLSTM-CRF ja BERT kontekstipõhisel sõnaesitusel. Korrigeerimisetapp on hübriidmudel, mis põhineb n-grammil ja Seq2Seq-il. Täiendavaid funktsioone ja välisandmeid lisamata saab BERT kontekstipõhine sõnaesitus tõhusalt parandada hiina grammatiliste vigade tuvastamise ja parandamise jõudlusnäitajaid.', 'jv': 'Nang pengguna sampeyan Cines, sampeyan tanggal saiki unyak gak bener Perintah iki rambarang nggawe nyimpen NLPMEA 2020 nganggo CGED Awak dhéwé éntuk sistem sing wis ana ing nggo tahirno karo Ngubah Sayensi Kampèng rection kuwi model HyBridge sing basa ning n-gram karo Seq2Seq. Nanging nambah peringatan tambah lan data anyar, gambar BERT contextual', 'sk': 'V procesu učenja kitajščine imajo učenci drugega jezika lahko različne slovnične napake zaradi negativnega prenosa maternega jezika. Ta prispevek opisuje našo predložitev skupni nalogi NLPTEA 2020 na CGED. Predstavljamo hibridni sistem, ki uporablja tako stopnjo odkrivanja kot korekcije. Stopnja odkrivanja je model zaporednega označevanja, ki temelji na kontekstni predstavitvi besed BiLSTM-CRF in BERT. Korekcijska faza je hibridni model, ki temelji na n-gramu in Seq2Seq. Brez dodajanja dodatnih funkcij in zunanjih podatkov lahko kontekstna predstavitev besed BERT učinkovito izboljša meritve učinkovitosti kitajskega slovničnega odkrivanja in popravljanja napak.', 'ha': "Haƙĩƙa, a cikin jararin da aka karanta wa China, masu kara na lugha na ƙarƙashin, watau su iya da wasu ɓatattu masu karatun grammaci ne sababin shige-motsi na lugha native. This paper describes our submission to the NLPTEA 2020 shared task on CGED.  Muna halatar da wani na'ura da ya yi amfani da duk ganin da za'a sani. Halin da za'a gane shi wata salon mai biyayyar bayãni ne a kan bincike BiLStM-CRF da maɓallin maganar da BERT. Halin da aka daidaita shi yana wata salon zaɓani n a n-gram da Seq2Seq. Bai ƙara da wasu hushi da data masu ƙaranci, mai gaya maganar BERT na koma, yana iya amfani da gyarata metric mai gyarawa na ganin ɓata na grammati na China.", 'bo': 'རྒྱ་ནག་གི་སློབ་བརྗོད་ཀྱི་ལས་སྦྱོར་ནང་ན་སྐད་རིགས་ཤེས་པ་གཉིས་ཀྱི་ནང་དུ་ནོར ཤོག་བྱང་འདིས་ང་ཚོའི་རྗེས་སུ་NLPTEA 2020་ལ་མཉམ་དུ་གཏོང་གི་བྱ་རིམ་CGED་དུ་བཤད་པ ང་ཚོས་རྟོགས་དང་བདེ་འཇགས་ཀྱི་ཆེན་གཉིས་ལས་སྤྱོད་པའི་ཆ་རྐྱེན་གྱི་མ་ལག་གི་སྟོན་པ་ཞིག་འཆར་ཡོད། The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation. The correction stage is a hybrid model based on the n-gram and Seq2Seq. Without adding additional features and external data, the BERT contextual word representation can effectively improve the performance metrics of Chinese grammatical error detection and correction.', 'he': 'In the process of learning Chinese, second language learners may have various grammatical errors due to the negative transfer of native language.  העיתון הזה מתאר את ההעברה שלנו למשימה משותפת NLPTEA 2020 על CGED. אנחנו מציגים מערכת היברידית שמשתמשת בשלבי גילוי ותיקון. The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation.  שלב התיקון הוא מודל היברידי מבוסס על n-גרם וסקק2Seq. Without adding additional features and external data, the BERT contextual word representation can effectively improve the performance metrics of Chinese grammatical error detection and correction.'}
{'en': 'SEMA : Text Simplification Evaluation through Semantic Alignment', 'pt': 'SEMA: Avaliação de Simplificação de Texto por Alinhamento Semântico', 'ar': 'SEMA: تقييم تبسيط النص من خلال المحاذاة الدلالية', 'fr': "SEMA\xa0: Évaluation de la simplification de texte grâce à l'alignement sémantique", 'es': 'SEMA: Evaluación de simplificación de textos mediante alineación semántica', 'ja': 'SEMA ：セマンティックアライメントによるテキストの簡略化評価', 'zh': 'SEMA曰:语义简齐也', 'ru': 'SEMA: Оценка упрощения текста посредством семантического выравнивания', 'hi': 'SEMA: शब्दार्थ संरेखण के माध्यम से पाठ सरलीकरण मूल्यांकन', 'ga': 'SEMA: Meastóireacht ar Shimpliú Téacs trí Ailíniú Séimeantach', 'ka': 'SEMA: ტექსტის გამოსახულების განსახულების განსახულება', 'el': 'ΣΕΜΑ: Αξιολόγηση Απλοποίησης Κειμένου μέσω Σημαντικής Ευθυγραμμίσεως', 'hu': 'SEMA: Szövegegyszerűsítés értékelése szemantikus igazítással', 'it': 'SEMA: Valutazione della semplificazione del testo tramite allineamento semantico', 'kk': 'SEMA: Мәтін қарапайым түрлендіру бағалау', 'lt': 'SEMA: Teksto supaprastinimo vertinimas atliekant semestinį suderinimą', 'mk': 'Семантично израмнување', 'ms': 'SEMA: Evaluasi Permudahan Teks melalui Jajaran Semantik', 'ml': 'SEMA: പദാവലി എളുപ്പമാക്കുന്നതിനുള്ള വിശ്വാസം സെമാന്റിക് ഏല്\u200dപ്പിക്കുക', 'mn': 'SEMA: Текст хялбарчлалын үнэлгээ Semantic Alignment through', 'mt': 'SEMA: Evalwazzjoni tas-Simplifikazzjoni tat-Test permezz ta’ Allinjament Semantiku', 'no': 'SEMA: Evaluering av tekst- forenklingar gjennom semiantisk justering', 'pl': 'SEMA: Ocena uproszczenia tekstu poprzez wyrównanie semantyczne', 'ro': 'SEMA: Evaluarea simplificării textului prin aliniere semantică', 'sr': 'SEMA: Evaluacija pojednostavljanja teksta kroz semantičko ispravljanje', 'si': 'SEMA: පාළ සාමාන්\u200dය විශ්ලේෂණය සෙමැන්ටික් විශ්ලේෂණය', 'so': 'SEMA: Qiimeynta saxda qoraalka ee isbedelka', 'ta': 'SEMA: Text Simplification Evaluation through Semantic Alignment', 'sv': 'SEMA: Utvärdering av textförenkling genom semantisk anpassning', 'ur': 'SEMA: سیمنٹی الیجینٹ کے ذریعہ متن سادھایی ارزش', 'uz': '@ info: whatsthis', 'vi': 'SEMA: Bộ Đánh giá Đơn giản hóa văn bản qua Liên Kết Semantic', 'bg': 'Оценка за опростяване на текста чрез семантично подравняване', 'da': 'SEMA: Tekstforenkling Evaluering gennem semantisk justering', 'hr': 'SEMA: Evaluacija pojednostavljanja teksta kroz semantičko ispravljanje', 'nl': 'SEMA: Evaluatie van tekstvereenvoudiging door semantische uitlijning', 'de': 'SEMA: Evaluation der Textvereinfachung durch semantische Ausrichtung', 'id': 'SEMA: Evaluasi Simplifikasi Teks melalui Penjajaran Semantik', 'fa': 'SEMA: ارزیابی ساده\u200cسازی متن از طریق تنظیم سیمانتیک', 'ko': 'SEMA: 의미 정렬을 통한 텍스트 단순화 평가', 'sw': 'SEMA: Uthibitisho wa Uurahisi wa Mataifa kupitia Ujinga', 'tr': 'SEMA: Metin Basitlendirme Önemli Çizgi Aracılığı', 'sq': 'SEMA: Vlerësimi i Simplifikimit të Tekstit nëpërmjet Kornizimit Semantik', 'af': 'SEMA: Teks Vereenvoudiging Evaluering deur Semantiese Oplyn', 'hy': 'SEMA: Տեքստի պարզաբանության գնահատումը սեմատիկ հարմարեցման միջոցով', 'az': 'SEMA: Metin BasitlaŇüdńĪrma Q…ôrcl…ôm…ôsi Semantik Q…ôrcl…ôm…ôsi il…ô', 'am': 'undo-type', 'bn': 'SEMA: লেখার সাধারণ মূল্য', 'ca': "SEMA: Evaluació de la simplificació del text a través de l'alliniament Semàtic", 'bs': 'SEMA: Evaluacija pojednostavljanja teksta kroz semantičko ispravljanje', 'cs': 'SEMA: Zjednodušení textu pomocí sémantického zarovnání', 'et': 'SEMA: Teksti lihtsustamise hindamine semantilise joondamise kaudu', 'fi': 'SEMA: Tekstin yksinkertaistamisen arviointi semanttisen linjauksen avulla', 'jv': 'SEMAS: Text Simplification invaluation by semanti Align', 'ha': 'KCharselect unicode block name', 'sk': 'SEMA: Vrednotenje poenostavitve besedila s semantično poravnavo', 'bo': 'SEMA: ཆུང་ལྡོག་སྒྲིག་ཕྱོགས་ཀྱིས་ཡིག་གི་སྔོན་སྒྲིག་བཟོ་བཅོས་ལ་བསྟུན་ནས་བཟོ་བཅོས་བྱེད།', 'he': 'הערכה של הפשטת טקסט באמצעות התאמה סמנטית'}
{'en': 'Text simplification is an important branch of natural language processing. At present, methods used to evaluate the semantic retention of text simplification are mostly based on string matching. We propose the SEMA (text Simplification Evaluation Measure through Semantic Alignment), which is based on semantic alignment. Semantic alignments include complete alignment, partial alignment and hyponymy alignment. Our experiments show that the evaluation results of SEMA have a high consistency with human evaluation for the simplified corpus of Chinese and English news texts.', 'ar': 'يعد تبسيط النص فرعًا مهمًا من فروع معالجة اللغة الطبيعية. في الوقت الحاضر ، تعتمد الطرق المستخدمة لتقييم الاحتفاظ الدلالي لتبسيط النص في الغالب على مطابقة السلسلة. نقترح SEMA (إجراء تقييم تبسيط النص من خلال المحاذاة الدلالية) ، والذي يعتمد على المحاذاة الدلالية. تشمل المحاذاة الدلالية المحاذاة الكاملة والمحاذاة الجزئية والمحاذاة hyponymy. تظهر تجاربنا أن نتائج التقييم الخاصة بـ SEMA متسقة بدرجة عالية مع التقييم البشري للمجموعة المبسطة للنصوص الإخبارية الصينية والإنجليزية.', 'fr': "La simplification de texte est une branche importante du traitement du langage naturel. À l'heure actuelle, les méthodes utilisées pour évaluer la rétention sémantique de la simplification de texte sont principalement basées sur la correspondance de chaînes. Nous proposons le SEMA (text Simplification Evaluation Measure through Semantic Alignment), qui est basé sur l'alignement sémantique. Les alignements sémantiques comprennent l'alignement complet, l'alignement partiel et l'alignement par hyponymie. Nos expériences montrent que les résultats d'évaluation de SEMA sont très cohérents avec l'évaluation humaine pour le corpus simplifié de textes d'actualités en chinois et en anglais.", 'pt': 'A simplificação de texto é um ramo importante do processamento de linguagem natural. Atualmente, os métodos usados para avaliar a retenção semântica da simplificação de texto são baseados principalmente na correspondência de strings. Propomos o SEMA (texto Medida de Avaliação de Simplificação por Alinhamento Semântico), que se baseia no alinhamento semântico. Alinhamentos semânticos incluem alinhamento completo, alinhamento parcial e alinhamento hiponímico. Nossos experimentos mostram que os resultados da avaliação do SEMA têm uma alta consistência com a avaliação humana para o corpus simplificado de textos de notícias em chinês e inglês.', 'es': 'La simplificación del texto es una rama importante del procesamiento del lenguaje natural. En la actualidad, los métodos utilizados para evaluar la retención semántica de la simplificación del texto se basan principalmente en la comparación de cadenas. Proponemos el SEMA (texto Simplification Evaluation Measure through Semantic Alignment), que se basa en la alineación semántica. Las alineaciones semánticas incluyen alineación completa, alineación parcial y alineación de hiponimia. Nuestros experimentos muestran que los resultados de la evaluación de SEMA tienen una alta coherencia con la evaluación humana para el corpus simplificado de textos de noticias en chino e inglés.', 'hi': 'पाठ सरलीकरण प्राकृतिक भाषा प्रसंस्करण की एक महत्वपूर्ण शाखा है। वर्तमान में, पाठ सरलीकरण के शब्दार्थ प्रतिधारण का मूल्यांकन करने के लिए उपयोग की जाने वाली विधियां ज्यादातर स्ट्रिंग मिलान पर आधारित हैं। हम SEMA (शब्दार्थ संरेखण के माध्यम से पाठ सरलीकरण मूल्यांकन उपाय) का प्रस्ताव करते हैं, जो शब्दार्थ संरेखण पर आधारित है। शब्दार्थ संरेखण में पूर्ण संरेखण, आंशिक संरेखण और हाइपोनिमी संरेखण शामिल हैं। हमारे प्रयोगों से पता चलता है कि SEMA के मूल्यांकन परिणामों में चीनी और अंग्रेजी समाचार ग्रंथों के सरलीकृत कॉर्पस के लिए मानव मूल्यांकन के साथ एक उच्च स्थिरता है।', 'ja': 'テキストの簡略化は、自然言語処理の重要な分岐である。現在、テキストの単純化の意味的保持を評価するために使用される方法は、ほとんどが文字列マッチングに基づいています。SEMA (Simplification Evaluation Measure through Semantic Alignment)という、セマンティックアライメントに基づくテキストを提案します。セマンティックアライメントには、完全アライメント、部分アライメント、およびハイポニミーアライメントが含まれます。私たちの実験では、SEMAの評価結果は、中国語と英語のニューステキストの単純化されたコーパスに対する人間の評価と高い整合性を示しています。', 'ru': 'Упрощение текста - важная отрасль обработки естественного языка. В настоящее время методы, используемые для оценки семантического удержания упрощения текста, в основном основаны на сопоставлении строк. Мы предлагаем SEMA (text Simplification Evaluation Measure through Semantic Alignment), которая основана на семантическом выравнивании. Семантические выравнивания включают полное выравнивание, частичное выравнивание и выравнивание гипонимии. Наши эксперименты показывают, что результаты оценки SEMA имеют высокую согласованность с оценкой человека для упрощенного корпуса текстов новостей на китайском и английском языках.', 'zh': '文本简化,自然语言处要支。 目前以评估文本简化语义存者多基字符串匹配。 盖语义齐之文本简而估之SEMA(文本简而评之)。 语义齐、下齐。 实验明SEMA之论,与人简体中英文新闻文本之论高一致性。', 'ga': 'Is brainse tábhachtach de phróiseáil teanga nádúrtha é simpliú téacs. Faoi láthair, tá na modhanna a úsáidtear chun coinneáil shéimeantach an tsimplithe téacs a mheas bunaithe go príomha ar mheaitseáil sreang. Molaimid an SEMA (téacs Beart Measúnaithe Simplithe trí Ailíniú Séimeantach), atá bunaithe ar ailíniú shéimeantach. Áirítear le hailínithe shéimeantacha ailíniú iomlán, ailíniú páirteach agus ailíniú hiponymy. Léiríonn ár dturgnaimh go bhfuil comhsheasmhacht ard ag torthaí meastóireachta SEMA le meastóireacht dhaonna do chorpas simplithe téacsanna nuachta na Síne agus Béarla.', 'hu': 'A szövegegyszerűsítés a természetes nyelvfeldolgozás fontos ága. Jelenleg a szövegegyszerűsítés szemantikai megőrzésének értékelésére használt módszerek leginkább karakterláncokra épülnek. Javasoljuk a SEMA (szöveg Simplification Evaluation Measure through Semantic Alignment), amely szemantikai igazításon alapul. A szemantikus igazítások magukban foglalják a teljes igazítást, a részleges igazítást és a hiponymia igazítást. Kísérleteink azt mutatják, hogy a SEMA értékelési eredményei nagy összhangban vannak az emberi értékeléssel a kínai és angol hírszövegek egyszerűsített korpuszában.', 'el': 'Η απλοποίηση κειμένου είναι ένας σημαντικός κλάδος της επεξεργασίας φυσικής γλώσσας. Επί του παρόντος, οι μέθοδοι που χρησιμοποιούνται για την αξιολόγηση της σημασιολογικής διατήρησης της απλοποίησης κειμένου βασίζονται κυρίως στην αντιστοίχιση συμβολοσειρών. Προτείνουμε το SEMA (κείμενο Μέτρο Αξιολόγησης Απλοποίησης μέσω Σημματικής Ευθυγραμμίσεως), το οποίο βασίζεται στη σημασιολογική ευθυγράμμιση. Οι σημαματικές ευθυγραμμίσεις περιλαμβάνουν πλήρη ευθυγράμμιση, μερική ευθυγράμμιση και ευθυγράμμιση υπονύμων. Τα πειράματά μας δείχνουν ότι τα αποτελέσματα αξιολόγησης του SEMA έχουν υψηλή συνέπεια με την ανθρώπινη αξιολόγηση για το απλοποιημένο σώμα κινεζικών και αγγλικών ειδήσεων.', 'ka': 'ტექსტის გამოყენება არის მნიშვნელოვანი სახელის გამოყენება. ახლა ტექსტის სუფლიქტირებას სენმანტიკური დახმარებას გამოყენებული მეტოვები უფრო მეტად სტრიქონის სხვადასხვადასხვადასხვადასხვადასხვა. ჩვენ SEMA-ს (ტექსტის გამოსახულების განსახულების განსახულების განსახულების განსახულების განსახულების განსახულების განსახულების განსახულების განსახულების განსახულების განსახულების გან Semantic alignments include complete alignment, partial alignment and hyponymy alignment. ჩვენი ექსპერიმენტები გამოჩვენება, რომ SEMA-ის განსაზღვრებების შედეგი უფრო დიდი შემდგომარეობა ადამიანის განსაზღვრებისთვის ჩინეთის და ანგლისური ნუტუქების გან', 'it': "La semplificazione del testo è un ramo importante dell'elaborazione del linguaggio naturale. Attualmente, i metodi utilizzati per valutare la conservazione semantica della semplificazione del testo sono principalmente basati sulla corrispondenza delle stringhe. Proponiamo il SEMA (testo Simplification Evaluation Measure through Semantic Alignment), che si basa sull'allineamento semantico. Gli allineamenti semantici includono allineamento completo, allineamento parziale e allineamento iponimico. I nostri esperimenti dimostrano che i risultati della valutazione di SEMA hanno un'elevata coerenza con la valutazione umana per il corpus semplificato di testi di notizie cinesi e inglesi.", 'mk': 'Поедноставувањето на текстот е важна гранка на природното обработување јазик. Моментално, методите кои се користат за проценка на семантичното задржување на текстовите поедноставувања се базирани претежно на совпаѓање на линии. Ние ја предложуваме SEMA (текстова мерка за проценка на поедноставувањето преку семантичко прилагодување), која е базирана на семантичко прилагодување. Семантичките подрачби вклучуваат целосно подрачје, делумно подрачје и хипонимско подрачје. Нашите експерименти покажуваат дека резултатите на евалуацијата на СЕМА имаат висока констанција со човечката евалуација за едноставен корпус на кинески и англиски вести тексти.', 'lt': 'Teksto supaprastinimas yra svarbus natūralaus kalbų apdorojimo šakas. Šiuo metu metodai, naudojami semantiniam teksto supaprastinimo išlaikymui įvertinti, daugiausia grindžiami juostų derinimu. Siūlome SEMA (teksto supaprastinimo vertinimo priemonė per Semantinį suderinimą), kuri grindžiama semantiniu suderinimu. Semantiniai sureguliavimai apima visišką sureguliavimą, dalinį sureguliavimą ir hiponimiją. Mūsų eksperimentai rodo, kad SEMA vertinimo rezultatai yra labai nuoseklūs su žmogaus vertinimu supaprastinto Kinijos ir anglų naujienų tekstų korpuso atžvilgiu.', 'kk': 'Мәтінді қарапайым - табиғи тілді өңдеу маңызды бөлігі. Қазіргі уақытта, мәтін қарапайымдамасын бағалау үшін қолданылатын әдістер көпшілігі жол сәйкестігіне негізделген. Біз SEMA (мәтін қарапайым бағдарламалық бағдарламалық бағдарламалық бағдарламалық бағдарламалық өлшемі) дегенді таңдаймыз. Бұл semantic бағдарламасына негізделген. Semantic alignments include complete alignment, partial alignment and hyponymy alignment. Біздің тәжірибеміздің SEMA бағалау нәтижесінің көбірек қызық және ағылшын жаңалық мәтіндерінің қарапайым корпус үшін адамдардың бағалауына сәйкес болады дегенді көр', 'ms': 'Simplifikasi teks adalah cabang penting pemprosesan bahasa alami. Pada masa ini, kaedah yang digunakan untuk menilai penyimpanan semantik pemudahan teks kebanyakan berdasarkan persamaan rentetan. Kami cadangkan SEMA (Teks Simplification Evaluation Measure melalui Semantic Alignment), yang berdasarkan aliran semantik. Jajaran Semantik termasuk jajaran lengkap, jajaran sebahagian dan jajaran hiponymi. Eksperimen kami menunjukkan hasil penilaian SEMA mempunyai konsistensi tinggi dengan penilaian manusia untuk corpus mudah teks berita Cina dan Inggeris.', 'ml': 'പദാവലി ലളിതമാക്കുന്നത് സ്വാഭാവിക ഭാഷയുടെ പ്രധാനപ്പെട്ട ശാഖയാണ്. ഇപ്പോള്\u200d, ടെക്സ്റ്റ് എളുപ്പത്തിന്റെ സെമാന്റിക് റിപ്പെഷന്\u200d നിരീക്ഷിക്കാന്\u200d ഉപയോഗിക്കുന്ന രീതികള്\u200d സ്ട് ഞങ്ങള്\u200d സെമാന്റിക്ക് മാന്ത്രികമാക്കുന്നതിന്റെ അടിസ്ഥാനത്തിലാണ് സെമാന്\u200dറിക് ചേര്\u200dന്ന് എളുപ്പമാക്കുന്നതിന്റെ അളവ സെമാന്റിക് സങ്കീര്\u200dണ്ണങ്ങള്\u200d പൂര്\u200dണ്ണമായ ഒരുമിച്ചിരിക്കുന്നു, പകുതി സങ്കീര്\u200dണ്ണമാക്കുന്നതും ഹൈപ് Our experiments show that the evaluation results of SEMA have a high consistency with human evaluation for the simplified corpus of Chinese and English news texts.', 'mt': 'Is-simplifikazzjoni tat-test hija fergħa importanti tal-ipproċessar tal-lingwi naturali. Bħalissa, il-metodi użati biex tiġi evalwata ż-żamma semantika tas-simplifikazzjoni tat-test huma bbażati l-aktar fuq it-tqabbil tal-linji. Aħna nipproponu s-SEMA (test Simplification Evaluation Measure through Semantic Alignment), li hija bbażata fuq allinjament semantiku. L-allinjamenti semantiċi jinkludu allinjament sħiħ, allinjament parzjali u allinjament iponimiku. L-esperimenti tagħna juru li r-riżultati tal-evalwazzjoni tas-SEMA għandhom konsistenza għolja mal-evalwazzjoni umana għall-korpus simplifikat tat-testi tal-a ħbarijiet Ċiniżi u Ingliżi.', 'pl': 'Uproszczenie tekstu jest ważną gałęzią przetwarzania języka naturalnego. Obecnie metody stosowane do oceny semantycznej retencji uproszczenia tekstu opierają się głównie na dopasowaniu ciągów. Proponujemy SEMA (tekst Simplification Evaluation Measure through Semantic Alignment), który opiera się na wyrównaniu semantycznym. Wyrównania semantyczne obejmują całkowite wyrównanie, częściowe wyrównanie i wyrównanie hiponimii. Nasze eksperymenty pokazują, że wyniki oceny SEMA mają wysoką spójność z oceną ludzką dla uproszczonego korpusu chińskich i angielskich tekstów wiadomości.', 'ro': 'Simplificarea textului este o ramură importantă a procesării limbajului natural. În prezent, metodele utilizate pentru evaluarea retenției semantice a simplificării textului se bazează în principal pe corelarea șirurilor. Propunem SEMA (text Simplification Evaluation Measure through Semantic Alignment), care se bazează pe aliniere semantică. Alinierile semantice includ alinierea completă, alinierea parțială și alinierea hiponimică. Experimentele noastre arată că rezultatele evaluării SEMA au o consistență ridicată cu evaluarea umană pentru corpul simplificat de texte de știri chinezești și engleză.', 'sr': 'Jednostavnost teksta je važna grana prirodnog obrade jezika. U ovom trenutku, metode koje se koriste za procjenu semantičkog zadržavanja pojednostavljanja teksta uglavnom su zasnovane na odgovarajućem režima. Predlažemo SEMA (mjera procjene teksta za procjenu pojednostavljanja kroz semantičko ispravljanje), koja se temelji na semantičkom poravnanju. Semantička poravnanja uključuju kompletno poravnanje, djelomično poravnanje i hiponimijsko poravnanje. Naši eksperimenti pokazuju da rezultati procjene SEMA imaju visoku konsekvenciju sa ljudskim procjenama za jednostavljeni korpus kineskih i engleskih vesti.', 'si': 'පාළුව සරලීකරණය තමයි ස්වභාවික භාෂාව ප්\u200dරක්\u200dරියාපනය ගැන වැදගත් ක්\u200dරමයක්. මේ විදියට, පාළුව සරලීකරණයේ සෙමැන්ටික් තියාගන්න භාවිත විදියට ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය විශේ අපි SEMA (පැත්තක් සාමාන්\u200dය විශ්ලේෂණය අවශ්\u200dය විශ්ලේෂණය අවශ්\u200dය විශ්ලේෂණය සඳහා සෙමාන්ටික් අවශ්\u200dය විශ්ල සෙමැන්ටික් සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සහ හි අපේ පරීක්ෂණය පෙන්වන්නේ SEMA ගේ විශ්ලේෂණ ප්\u200dරතිචාරයේ මිනිස්සුන්ගේ විශ්ලේෂණ ප්\u200dරතිචාරය සහ ඉංග්\u200dරීසි', 'so': 'Isfududeynta qoraalka waa laamo muhiim ah oo ka baaraandegista luqada dabiicadda ah. Hada la joogo qaababka lagu qiimeeyo dib u dhigista qoraalka sahliga ah waxaa ugu badan ku saleysan qoraal isku mid ah. Waxaannu soo jeedaynaa SEMA (qiyaastii saxdaada fududaanka ee qoraalka ee ku qoran isbedelka Semantic), kaasoo ku saleysan isbedelka semantika. Iskuulaadka galmada waxaa ku jira isbedelin dhamaan, isbedelka qeybta ah iyo isbedelka hyponymiga. Our experiments show that the evaluation results of SEMA have a high consistency with human evaluation for the simplified corpus of Chinese and English news texts.', 'sv': 'Textförenkling är en viktig gren av bearbetningen av naturligt språk. För närvarande är metoder som används för att utvärdera semantisk bevarande av textförenkling huvudsakligen baserade på strängmatning. Vi föreslår SEMA (text Simplification Evaluation Measure through Semantic Alignment), som bygger på semantisk anpassning. Semantiska justeringar inkluderar fullständig justering, partiell justering och hyponymi justering. Våra experiment visar att utvärderingsresultaten från SEMA har en hög överensstämmelse med mänsklig utvärdering för den förenklade korpusen av kinesiska och engelska nyhetstexter.', 'ta': 'உரை எளிதாக்கம் இயல்பான மொழி செயல்படுத்தலின் முக்கியமான கிளை ஆகும். தற்போது, உரை எளிதாக்கத்தை மதிப்பதற்கு பயன்படுத்தப்பட்ட முறைமைகள் சரம் பொருத்தமாக அடிப்படையில் உள்ளன. நாம் SEMA (உரை எளிதாக்குதல் மதிப்பீடு அளவு செமாண்டிக் ஒழுங்குபடுத்தல் மூலம்) என்பதை பரிந்துரைக்கிறோம். செமான்டிக் ஒழுங்குபடுத்தல் முழுமையான ஒழுங்குப்பு, பாகம் ஒழுங்குப்பு மற்றும் hyponymy ஒழுங்குப்படு எளிதாக்கப்பட்ட சீனா மற்றும் ஆங்கிலத்தின் செய்தி உரைகளுக்கான சீமா மற்றும் ஆங்கிலத்தின் செய்தி செய்தி முடிவுகளின் மதிப்ப', 'mn': 'Текст хялбарлах нь байгалийн хэл үйлдвэрлэлийн чухал хэсэг юм. Одоогийн үед, текст хялбарчлалын semantic хадгалах арга нь ихэнхдээ стринг холбоотой. Бид SEMA-г (Текст хялбарчлалын үнэлгээ хэмжээгээр Semantic Alignment-ээр) санал болгож байна. Энэ нь semantic alignment-ээр үндсэн. Semantic alignments include complete alignment, partial alignment and hyponymy alignment. Бидний туршилтууд SEMA-ын үнэлгээний үр дүн нь Хятад болон Англи мэдээний текстүүдийн хялбар корпус болон хүн төрөлхтний үнэлгээтэй байдаг.', 'ur': 'پیغام سادگی ایک اہم شاخہ ہے طبیعی زبان پردازش کی۔ اوس وقت، متن کے سیمنٹی حفاظت کے لئے استعمال کئے جاتے ہیں، اکثر متن مطابق استرینگ مطابق پر بنیاد ہیں. ہم SEMA کو پیشنهاد کرتے ہیں (سمantic Alignment through text Simplification Evaluation Measure) جو semantic alignment پر بنیاد ہے. سیمنٹی الیٹینیٹ مکمل الیٹینیٹ، حصہ الیٹینیٹ اور ہیپونیمی الیٹینیٹ شامل ہیں. ہمارے آزمائش دکھاتے ہیں کہ SEMA کے ارزش نتیجے میں انسان کی ارزش کے ساتھ بہت ساده چینی اور انگلیسی خبروں کے متن کے قابل تعلق ہیں.', 'no': 'Tekstforenklinga er ein viktig grenn av naturspråkshandtering. I dag er metodar som brukar til å evaluera semantisk retning av tekstforenklinga hovudsakelig basert på treff. Vi foreslår SEMA (tekst- Evalueringsmål gjennom semiantisk justering), som er basert på semantisk justering. Semantiske justeringar inneheld fullstendig justering, delvis justering og hyponymisk justering. Eksperimentane våre viser at evalueringsresultatene av SEMA har ein høg konsistens med menneske evaluering for den enkelte korpusen av kinesiske og engelske nyhetstekstar.', 'uz': 'Matn oddiylashtirish asl tilni boshqarish muhim chegara. Joriy hozirda matnning semantik cheksizlikni qiymatlash uchun foydalanilgan usullar moslama matn moslamalari qiymatiga asoslangan. Soddalashtirish uchun SEMA (Semantic Alignment orqali matn toʻgʻrilashni soddalashtirish oʻlchamini soʻzlashtiramiz), bu semantik tekislash asosida asoslangan. Boʻyiga tekislash Bizning imtiyozlarimiz SEMA natijalarining qiymatlari esa oddiy Xitoycha va Ingliz xabarlar matnlarining oddiy qiymatlariga inson qiymatlariga juda katta ishlatiladi.', 'vi': 'Đơn giản văn bản là một nhánh quan trọng trong việc xử lý ngôn ngữ tự nhiên. Hiện tại, phương pháp được dùng để đánh giá việc đơn giản duy trì văn bản chỉ dựa trên sự khớp chuỗi. Chúng tôi đề nghị SEMA (thước đo quy mô hóa quy mô hóa thông qua Liên kết Giữa kỳ kỳ, kỳ cục), nó dựa trên độ thẳng. Đối chỉnh giữa kỳ bao gồm cả độ thẳng, thẳng hàng một phần và độ giảm vị. Những thí nghiệm của chúng tôi cho thấy kết quả đánh giá của SEMA có độ đồng nhất với việc đánh giá nhân loại trong tập hợp văn bản tin tức Trung Quốc và Anh.', 'da': "Tekstforenkling er en vigtig gren af naturlig sprogbehandling. På nuværende tidspunkt er metoder, der anvendes til at vurdere semantisk fastholdelse af tekst forenkling hovedsageligt baseret på strengmatching. Vi foreslår SEMA (tekst Simplification Evaluation Measure through Semantic Alignment), som er baseret på semantisk justering. Semantiske justeringer omfatter komplet justering, delvis justering og hyponymi justering. Vores eksperimenter viser, at SEMA's evalueringsresultater har en høj konsistens med menneskelig evaluering for det forenklede korpus af kinesiske og engelske nyhedstekster.", 'bg': 'Опростяването на текста е важен клон на обработката на естествения език. Понастоящем методите, използвани за оценка на семантичното задържане на опростяването на текста, се основават предимно на съвпадение на низове. Предлагаме СЕМА (текст Оценка за опростяване чрез семантично подравняване), която се основава на семантично подравняване. Семантичните подравнявания включват пълно подравняване, частично подравняване и подравняване на хипонимията. Нашите експерименти показват, че резултатите от оценката на СЕМА имат висока съгласуваност с човешката оценка за опростения корпус от китайски и английски новинарски текстове.', 'nl': 'Textvereenvoudiging is een belangrijke tak van de verwerking van natuurlijke taal. Momenteel worden methoden gebruikt om de semantische retentie van tekstvereenvoudiging te evalueren meestal gebaseerd op string matching. We stellen de SEMA (tekst Simplification Evaluation Measure through Semantic Alignment) voor, die gebaseerd is op semantische uitlijning. Semantische uitlijningen omvatten volledige uitlijning, gedeeltelijke uitlijning en hyponiemieuitlijning. Onze experimenten tonen aan dat de evaluatieresultaten van SEMA een hoge consistentie hebben met de menselijke evaluatie voor het vereenvoudigde corpus van Chinese en Engelse nieuwsteksten.', 'hr': 'Jednostavnost teksta je važna grana prirodnog obrade jezika. Trenutno su metode koje se koriste za procjenu semantičkog zadržavanja pojednostavljanja teksta uglavnom temeljene na odgovaranju žica. Predlažemo SEMA (mjera procjene teksta za procjenu pojednostavljanja kroz semantičko ispravljanje), koja je temeljena na semantičkom poravnanju. Semantička poravnanja uključuju kompletno poravnanje, djelomično poravnanje i hiponimijsko poravnanje. Naši eksperimenti pokazuju da rezultati procjene SEMA imaju visoku konsekvenciju s ljudskim procjenama za jednostavljeni korpus kineskih i engleskih vijesti.', 'id': 'Simplifikasi teks adalah cabang penting dari proses bahasa alami. Saat ini, metode yang digunakan untuk mengevaluasi pemeliharaan semantis penyimplifikasi teks kebanyakan berdasarkan persamaan string. We propose the SEMA (text Simplification Evaluation Measure through Semantic Alignment), which is based on semantic alignment.  Alinjasi Semantik termasuk alignment lengkap, partial alignment dan hyponymy alignment. Eksperimen kami menunjukkan bahwa hasil evaluasi SEMA memiliki konsistensi tinggi dengan evaluasi manusia untuk corpus sederhana teks berita Cina dan Inggris.', 'de': 'Die Textvereinfachung ist ein wichtiger Zweig der Verarbeitung natürlicher Sprache. Derzeit basieren Methoden zur Bewertung der semantischen Beibehaltung von Textvereinfachung meist auf String Matching. Wir schlagen den SEMA (Text Simplification Evaluation Measure through Semantic Alignment) vor, der auf semantischer Ausrichtung basiert. Semantische Ausrichtungen umfassen vollständige Ausrichtung, partielle Ausrichtung und Hyponymiausrichtung. Unsere Experimente zeigen, dass die Evaluationsergebnisse von SEMA eine hohe Übereinstimmung mit der menschlichen Evaluation für den vereinfachten Korpus chinesischer und englischer Nachrichtentexte aufweisen.', 'fa': 'ساده کردن متن یک شاخه مهم از پرداخت زبان طبیعی است. در حال حاضر، روش\u200cهایی که برای ارزیابی بازداشتن سنتی ساده\u200cسازی متن استفاده می\u200cشوند، بیشتر بر پایه\u200cی مسابقه\u200cهای string هستند. ما پیشنهاد می\u200cکنیم SEMA (مقدار ارزیابی ساده\u200cسازی متن از طریق تنظیم ساده\u200cسازی) که بر اساس تنظیم ساده\u200cسازی است. تغییرات قسمتی شامل تغییرات کامل، تغییرات قسمتی و تغییرات هیپونیمی است. آزمایشات ما نشان می دهند که نتیجه ارزیابی SEMA با ارزیابی انسان برای ساده\u200cترین شرکت\u200cهای خبرهای چینی و انگلیسی بسیار بالا دارد.', 'ko': '텍스트의 간소화는 자연 언어 처리의 중요한 부분이다.현재 텍스트의 의미 보존을 간소화하는 방법은 대부분 문자열의 일치에 기반을 두고 있다.우리는 의미 정렬을 바탕으로 한 텍스트 간소화 평가 방법(SEMA)을 제시했다.의미 정렬에는 전체 정렬, 부분 정렬 및 하의 정렬이 포함됩니다.우리의 실험에 의하면 의미 분석의 평가 결과는 간소화된 중영문 뉴스 텍스트 자료 라이브러리에 대한 인류의 평가 결과와 매우 높은 일치성을 가진다.', 'sw': "Ufumbuzi wa maandishi ni mfumo muhimu wa upasuaji wa lugha asilia. Kwa sasa, mbinu zinazotumiwa kutathmini kujificha kwa kiasi kikubwa kwa urahisi wa maandishi, zinatumiwa zaidi kwa msingi wa mfumo unaofanana. Tunazipendekeza SEMA (Hema ya Uchunguzi wa Uchunguzi wa Mataifa kwa kupitia Uchunguzi wa Semantic), ambayo ni kwa msingi wa usambazaji wa kimapenzi. Uwezekano wa kimapenzi unajumuisha usambazaji kamili, unyang'anyi wa kidini na upinzani wa kidini. Majaribio yetu yanaonyesha kwamba matokeo ya uchunguzi wa SEMA yamekuwa na msimamo mkubwa na utafiti wa binadamu kwa viungo rahisi vya vitabu vya habari vya Kichina na Kiingereza.", 'tr': "Metin bejermeleri tebigy dil işlemeginiň wajyp çetleidir. Şu wagt, semantik hasaplanjak üçin ullanýan metin bejermelerini çaklamak üçin ullanýan yöntemler köplenç täze bir şekilde eşleýär. Biz SEMA'y (metin Besitlendirme Taýýarlama ölçüsi Semantik Çyzyglama Aralygy) teklip edip, bu semantik çyzyglama basady. Çot çyzyglamak doly çyzyglamak, parça çyzyglamak we hiponymyn çyzyglamak biler Biziň deneylerimiz SEMA'nyň deňleşmeniň netijeleriniň ýokary ynsanyň deňleşmegi bilen beýleki çykyşlygyny görkezýär.", 'sq': 'Simplifikimi i tekstit është një degë e rëndësishme e procesimit natyror të gjuhës. At present, methods used to evaluate the semantic retention of text simplification are mostly based on string matching.  Ne propozojmë SEMA (tekst Simplification Evaluation Measure through Semantic Alignment), e cila është bazuar në alignment semantic. Kornizimet Semantike përfshijnë rregullimin e plotë, rregullimin e pjesshëm dhe rregullimin e hiponimit. Eksperimentet tona tregojnë se rezultatet e vlerësimit të SEMA kanë një konsistencë të lartë me vlerësimin njerëzor për korpusin e thjeshtë të teksteve të lajmeve kineze dhe angleze.', 'am': 'የጽሑፍ ቀላል የፍጥረት ቋንቋ ማቀናቀል ግንኙነት ነው፡፡ በሁኑ ጊዜ የጽሑፍ ቀላልነት በመጠቀም የሚጠቅሙት ሥርዓቶች በመጠቀም በሥርዓት ተቃውሞ በመጠቀም ነው፡፡ የSEMA (የጽሑፍ ቀላል ማስታወቂያ መጠን በSemantic Alignment) በተገኘው የsemantic መጠቀሚያ መጠቀሚያ እናሳልጋለን፡፡ ኩልኩል ፈተናዎቻችን የSEMA ውጤቶች ለቀላል የቻይና እና እንግሊዝኛ ዜና ጽሑፎች በሚያስተካክሉ የሰው ውጤት አካባቢ እንደሆነ የሚያሳየው ነው፡፡', 'az': 'Metin təbiətli dil işləməsinin mövcuddur. Şimdilik, mətn oxumasının semantik tutulmasını değerləşdirmək üçün istifadə edilən metodlar çox yüksək mətn eşitməsinə dayanılır. Biz SEMA (mətn Yaxınlaşdırma Ölçüsü Ölçüsü Semantik İlçüsi Aracılığıyla) təklif edirik, ki bu semantik İlçüyə dayanan. Semantik tərəflər tamamlama tərəflənməsi, parça tərəflənməsi və hiponimi tərəflənməsi də dahil edir. Bizim təcrübələrimiz SEMA təcrübəsi sonuçlarının Çin və İngilizə xəbərləri mətnlərinin basit korpusu üçün insan təcrübəsi ilə yüksək bir uyğunluğunu göstərir.', 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ার একটি গুরুত্বপূর্ণ শাখা। বর্তমানে টেক্সটের সেম্যান্টিক আটকানোর জন্য ব্যবহৃত পদ্ধতি বেশীরভাগ স্ট্রিং মিল্যান্টের উপর ভিত্তিত। আমরা সেমার প্রস্তাব করছি (সেম্যান্টিক বৈষম্যের মাধ্যমে লেখা সুসংক্রান্ত পরিমাপ) যা সেম্যান্টিক সমন্বয়ের ভিত্তিক। সেম্যান্টিক স্থানান্তরের মধ্যে সম্পূর্ণ স্থান, অংশের আত্মসমন্বয় এবং হাইপ্যানিমির আকার। Our experiments show that the evaluation results of SEMA have a high consistency with human evaluation for the simplified corpus of Chinese and English news texts.', 'af': "Teks eenvoudiging is 'n belangrike takk van natuurlike taal verwerking. Op die huidige dag, metodes gebruik word om die semantiese houding van teks eenvoudiging te evalueer word meeste gebaseer op string ooreenstemmende. Ons voorstel die SEMA (teks Vereenvoudiging Evaluering Maat deur Semantiese Belyning), wat gebaseer word op semantiese belyning. Semantiese belyning insluit volledige belyning, gedeeltelike belyning en hiponiem belyning. Ons eksperimente wys dat die evalueringsresultate van SEMA 'n hoë konsistensie het met menslike evaluering vir die eenvoudige korpus van Sjinese en Engelse nuustekste.", 'bs': 'Jednostavnost teksta je važna grana prirodnog obrade jezika. Trenutno su metode koje se koriste za procjenu semantičkog zadržavanja pojednostavljanja teksta uglavnom temeljene na odgovaranju žica. Predlažemo SEMA (mjera procjene teksta za procjenu pojednostavljenja kroz semantičko ispravljanje), koja je temeljena na semantičkom poravnanju. Semantička poravnanja uključuju kompletno poravnanje, djelomično poravnanje i hiponimijsko poravnanje. Naši eksperimenti pokazuju da rezultati procjene SEMA imaju visoke konsekvence sa ljudskim procjenama za jednostavljeni korpus kineskih i engleskih vesti.', 'cs': 'Zjednodušení textu je důležitým odvětvím zpracování přirozeného jazyka. V současné době jsou metody používané k hodnocení sémantického zachování zjednodušení textu založeny převážně na shodě řetězců. Navrhujeme SEMA (text Simplification Evaluation Measure through Semantic Alignment), který je založen na sémantickém zarovnání. Sémantická zarovnání zahrnuje kompletní zarovnání, částečné zarovnání a zarovnání hyponymií. Naše experimenty ukazují, že výsledky hodnocení SEMA mají vysokou konzistenci s lidským hodnocením pro zjednodušený korpus čínských a anglických zpravodajských textů.', 'hy': 'Տեքստի պարզաբանությունը բնական լեզվի վերլուծության կարևոր ճյուղ է: Այս պահին, տեքստի պարզաբանության սեմանտիկ պահպանության գնահատման մեթոդները հիմնված են լարերի համապատասխանման վրա: Մենք առաջարկում ենք SEMA-ը, որը հիմնված է սեմանտիկ հավասարման վրա: Սեմանտիկ ուղղությունները ներառում են ամբողջական ուղղություն, մասամբ ուղղություն և հիպոնիմիկ ուղղություն: Our experiments show that the evaluation results of SEMA have a high consistency with human evaluation for the simplified corpus of Chinese and English news texts.', 'et': 'Teksti lihtsustamine on looduskeele töötlemise oluline haru. Hetkel põhinevad teksti lihtsustamise semantilise säilimise hindamiseks kasutatavad meetodid enamasti stringide sobitamisel. Pakume välja SEMA (teksti Simplification Evaluation Measure through Semantic Alignment), mis põhineb semantilisel joondamisel. Semantilised joondused hõlmavad täielikku joondust, osalist joondust ja hüponüümiat. Meie eksperimendid näitavad, et SEMA hindamistulemused on hiina ja inglise uudistekirjade lihtsustatud korpuse inimhinnanguga väga kooskõlas.', 'fi': 'Tekstin yksinkertaistaminen on tärkeä osa luonnollisen kielen käsittelyä. Tällä hetkellä tekstin yksinkertaistamisen semanttisen säilymisen arviointimenetelmät perustuvat enimmäkseen merkkijonojen vastaavuuteen. Ehdotamme SEMA:ta (tekstin Simplification Evaluation Measure through Semantic Alignment), joka perustuu semanttiseen linjaukseen. Semanttiset linjaukset sisältävät täydellisen linjauksen, osittaisen linjauksen ja hyponyymin linjauksen. Kokeemme osoittavat, että SEMA:n arviointitulokset ovat hyvin yhdenmukaisia yksinkertaistetun kiinalaisten ja englanninkielisten uutistekstien ihmisarvioinnin kanssa.', 'ca': "La simplificació del text és una branca important del processament natural del llenguatge. Actualment, els mètodes utilitzats per avaluar la retenció semàntica de la simplificació del text estan basats principalment en la combinació de cadenes. Proposem el SEMA (text Simplification Evaluation Measure through Semantic Alignment), que està basat en l'allinjament semàntic. Els alliniaments Semàtics inclouen alliniament complet, alliniament parcial i alliniament hipònimic. Els nostres experiments demostren que els resultats de l'evaluació del SEMA tenen una gran consistencia amb l'evaluació human a per al còrpus simplificat de textos de notícies xinès i anglès.", 'ha': '@ info: whatsthis @ action: inmenu Munã buɗar da MA (Mai Yaurin Sura na Kibaini na Kibaiko na Kibaini na Semantic), wanda ke kan daidaita na semantic. Juyin faɗi na Semantic yana ƙunsa da cikakken juyi, juyi mai rabo da tsaye na difnymy. Kayan jarrabõyinmu na nũna cewa, evaluation matsalar na SAMA yana da wata kyauta mai daidai da mutane zuwa littãfin na rubutun na Kinesi da Ingiriya.', 'sk': 'Poenostavitev besedila je pomembna veja obdelave naravnega jezika. Trenutno metode, ki se uporabljajo za ocenjevanje semantičnega ohranjanja poenostavitve besedila, temeljijo večinoma na ujemanju nizov. Predlagamo SEMA (besedilo Simplification Evaluation Measure through Semantic Alignment), ki temelji na semantični poravnavi. Semantne poravnave vključujejo popolno poravnavo, delno poravnavo in hiponimijsko poravnavo. Naši eksperimenti kažejo, da so rezultati evalvacije SEMA visoko skladni s človeško evalvacijo za poenostavljeni korpus kitajskih in angleških novic.', 'jv': 'Go underline Ngawe We proposal the SEMAs (text Simplification measurement measurement by semanti Align), that is used on semanti alignment. undo-type Awak dhéwé éntukno wong hal dadi kapan ning SEMAs iki dadi luwih sekondasar tentang karo hal-hal kuwi nggawe barang kelas barang dhéwé basa sing perusahaan Chinese lan basa sing basa Inggris.', 'bo': 'ཡི་གེ་ཆུང་སྒྲིག་ནི་རང་བཞིན་པའི་སྐད་རིགས་ལས་སྤྱོད་ཀྱི་གལ་ཆེ་ཤིག་རེད། ད་ལྟ་བུའི་ལམ་ལུགས་འདི་སྔོན་སྒྲིག་ཡིག་གི་ཆེ་མཐུན་པ་ལས་རྟགས་བཀལ་ནུས་ཡོད་པའི་ཐབས་ལམ་ལ་མཐུན་སྒྲིག་ཡོད། ང་ཚོས་SEMA(text Simplification Evaluation Measure through Semantic Alignment) ལྟར་སྒྲིག་འཇུག་གི་མཐོ་རིམ་དང་གཞི་རྟེན་ནས་ཡོད། Semantic alignment includes complete alignment, partial alignment and hyponymy alignment. ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་རྒྱ་ནག་དང་ཨིན་ཡིག་གི་བརྡ་འཕྲིན་ཡིག་ཆའི་མཐུན་རྐྱེན་བཟོ་བ་མང་པོ་ཞིག་ཡོད་པས།', 'he': 'הפשטות טקסט היא ענף חשוב של עיבוד שפת טבעית. כרגע, שיטות שמשתמשות כדי להעריך את ההחזקה הסמנטית של הפשטות טקסט מבוססות בעיקר על התאמת רצועות. אנחנו מציעים את SEMA (אמצע ההערכה של הפשטה טקסטית באמצעות התאמה סמנטית), שמבוסס על התאמה סמנטית. התאמות סמנטיות כוללות התאמה מושלמת, התאמה חלקית ותאמה היפונימית. Our experiments show that the evaluation results of SEMA have a high consistency with human evaluation for the simplified corpus of Chinese and English news texts.'}
