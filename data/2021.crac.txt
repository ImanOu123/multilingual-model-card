{'en': 'DramaCoref : A Hybrid Coreference Resolution System for German Theater Plays', 'ar': 'DramaCoref: نظام تحليل Coreference المختلط لمسرحيات المسرح الألماني', 'es': 'DramaCoref: un sistema híbrido de resolución de correferencias para obras de teatro alemanas', 'fr': 'DramaCoref\xa0: un système de résolution de coréférence hybride pour les pièces de théâtre allemandes', 'pt': 'DramaCoref: Um Sistema Híbrido de Resolução de Correferência para Peças de Teatro Alemãs', 'zh': 'DramaCoref:德国戏剧混共演解析统', 'ja': 'DramaCoref:ドイツの劇場用ハイブリッドコアレゾリューションシステム', 'ru': 'DramaCoref: гибридная система разрешения ядра для немецких театральных пьес', 'hi': 'DramaCoref: जर्मन थिएटर नाटकों के लिए एक हाइब्रिड Coreference संकल्प प्रणाली', 'ga': 'DramaCoref: Córas Réitigh Croílár Hibrid le haghaidh Drámaí Amharclainne Gearmánacha', 'ka': 'DramaCoref: ჰიბრიდის კოფერენციის რეზოციონის სისტემა გერმანული ტეარერის თამაში', 'el': 'Ένα υβριδικό σύστημα επίλυσης συγχορήγησης για γερμανικά θεατρικά έργα', 'it': 'DramaCoref: un sistema ibrido di risoluzione della coreferenza per spettacoli teatrali tedeschi', 'hu': 'DramaCoref: Hibrid Coreferencia Felbontó Rendszer a német színházi játékokhoz', 'kk': 'DramaCoref: Неміс театр ойындарының гибрид қасиеттері Айырымдау жүйесі', 'lt': 'DramaCoref: A Hybrid Coreference Resolution System for German Theater Plays', 'ms': 'DramaCoref: Sistem Resolusi Koreferensi Hybrid untuk Permainan Teater Jerman', 'mk': 'DramaCoref: Хибриден резолуциски систем за германски театарски игри', 'ml': 'ഡ്രാമാക്കോര്\u200dഫ്: ജര്\u200dമ്മന്\u200d തീയേറ്റര്\u200d കളിക്കുന്നതിനുള്ള ഹൈബ്രിഡ് കോര്\u200dഫെന്\u200dസ് വിധി സിസ്റ്റം', 'mt': 'DramaCoref: Sistema ta’ Riżoluzzjoni ta’ Koreferenza Ibrida għall-Logħob tat-Teatru Ġermaniż', 'mn': 'DramaCoref: Германы театр тоглоомын гибрид удирдлагын шийдвэр систем', 'pl': 'DramaCoref: hybrydowy system rozdzielczości koreferencji dla niemieckich spektakli teatralnych', 'ro': 'DramaCoref: Un sistem hibrid de rezoluție a corefențelor pentru piesele de teatru germane', 'sr': 'DramaCoref: Hibridni sistem rezolucije za njemačku teatru igra', 'si': 'ඩ්\u200dරාමාකෝර්ෆ්: ජර්මාන් තියාර් සෙල්ලම්', 'so': 'DramaCoref: A Hybrid Coreference Resolution System for German Theater Plays', 'sv': 'DramaCoref: En hybrid Coreference upplösning system för tyska teaterspel', 'ta': 'DramaCoref: ஜெர்மன் தீயர் விளையாடுதல்களுக்கான ஒரு ஹைப்ரிட் கோர்னென்ஸ் திருத்திறன் அமைப்பு', 'no': 'DramaCoref: Eit hybrid- hjelpefølgje- oppløysingssystem for tysk teatraspel', 'ur': 'ڈراماکورف: جرمن تئاتر کھیل کے لئے ایک ہیبراڈ کریفرنس روشنی سیسٹم', 'uz': 'DramaCoref: A Hybrid Coreference Resolution System for German Theater Plays', 'vi': 'Kịch bản bản bản phân giải tách người lai cho các rạp hát Đức', 'bg': 'Хибридна система за резолюция на кореференцията за германски театрални пиеси', 'hr': 'DramaCoref: Hibridni sustav rezolucije korisnosti za njemačku teatru igra', 'da': 'DramaCoref: En hybrid Coreference opløsning system til tyske teaterspil', 'de': 'DramaCoref: Ein hybrides Coreference Resolution System für deutsche Theaterstücke', 'nl': 'DramaCoref: Een hybride Coreference Resolution Systeem voor Duitse theaterstukken', 'ko': '독일 연극의 혼합 공지 해소 시스템', 'fa': 'DramaCoref: یک سیستم حل\u200cسازی Hybrid Coreference برای تئاتر آلمانی بازی می\u200cکند', 'id': 'DramaCoref: A Hybrid Coreference Resolution System for German Theater Plays', 'sw': 'DramaCoref: Mfumo wa Mazinduzi ya Mifumo ya Mapinduzi ya Kijerumani', 'tr': 'DramaCoref', 'af': "DramaCoref: 'n Hybrid Hoeferensie Resolusie Stelsel vir Duitse Theater Speletjies", 'am': 'DramaCoref: A Hybrid Coreference Resolution System for German Theater Players', 'az': 'DramaCoref: Alman teatru oyunları üçün Hybrid Coreference Resolution System', 'sq': 'DramaCoref: Një Sistem i Rizolucionit të Koreferencës Hibride për Lojrat e Teatrit Gjerman', 'bn': 'ড্রামাকোরেফ: জার্মান থিয়েটার খেলার জন্য হাইব্রিড কোরেন্স সিস্টেম', 'hy': 'Դրամակորեֆ: Գերմանական թատրոնի խաղերի հիբրիդ կորեֆերանսի լուծման համակարգը', 'bs': 'DramaCoref: Hibridni sistem rezolucije korisnosti za njemačku teatru igra', 'ca': 'DramaCoref: Un sistema de resolució de la coreferència híbrida per a jocs teatrals alemans', 'cs': 'DramaCoref: Hybrid Coreference Resolution System pro německé divadelní hry', 'et': 'DramaCoref: Hübriid Coreference Resolutsioonisüsteem Saksa teatrinäitustele', 'fi': 'DramaCoref: Hybridi Coreference Resolution System saksalaisiin teatteriesityksiin', 'jv': 'DraMacoref: A HyBridge corefern Resolution System for German Theter Play', 'ha': 'KCharselect unicode block name', 'he': 'DramaCoref: A Hybrid Coreference Resolution System for German Theater Plays', 'sk': 'DramaCoref: hibridni sistem ločljivosti Coreference za nemške gledališke predstave', 'bo': 'DramaCoref:སྔོན་ཤུགས་གཙོ་བོའི་མ་དབང་ཚད་ལུགས་སྒྲིག་ཆས་གཞི་སྒྲིག་ཚོགས་སྒོ་གཏོང་བ'}
{'en': 'We present a ', 'ar': 'نقدم نظامًا لحل المرجع في المسرحيات المسرحية ، DramaCoref. يستخدم النظام تقنيات الشبكة العصبية لتقديم قائمة بالإشارات المحتملة. يتم تعيين هذه الإشارات إلى كيانات مشتركة باستخدام قواعد عامة وقواعد خاصة بالمجال. نجد أن DramaCoref يعمل جيدًا على المسرحيات عند مقارنته بالمجموعات من المجالات الأخرى والأرباح من تضمين معلومات خاصة بالمسرحيات المسرحية. في الإعداد الأفضل أداءً ، فإنه يحقق درجة CoNLL بنسبة 32٪ عند استخدام الإشارات المكتشفة تلقائيًا و 55٪ عند استخدام الإشارات الذهبية. القواعد الفردية تحقق درجات عالية الدقة ؛ ومع ذلك ، فإن القواعد المصممة على مجالات أخرى غالبًا ما تكون غير قابلة للتطبيق أو تؤدي إلى نتائج غير مرضية. يوضح تحليل الأخطاء أن الكشف عن الإشارة هو نقطة الضعف الرئيسية في النظام ، مما يوفر اتجاهات للتحسينات المستقبلية.', 'es': 'Presentamos un sistema para resolver la correferencia en obras de teatro, DramaCoref. El sistema utiliza técnicas de redes neuronales para proporcionar una lista de posibles menciones. Estas menciones se asignan a entidades comunes mediante reglas genéricas y específicas del dominio. Encontramos que DramaCoref funciona bien en las obras de teatro en comparación con los corpus de otros dominios y se beneficia de la inclusión de información específica de las obras de teatro. En la configuración de mejor rendimiento, logra una puntuación de ConLL del 32% cuando se utilizan menciones detectadas automáticamente y del 55% cuando se utilizan menciones de oro. Las reglas únicas logran puntuaciones de alta precisión; sin embargo, las reglas diseñadas en otros dominios a menudo no son aplicables o producen resultados insatisfactorios. El análisis de errores muestra que la detección de menciones es la principal debilidad del sistema, ya que proporciona instrucciones para futuras mejoras.', 'fr': "Nous présentons un système de résolution de coréférence sur les pièces de théâtre, DramaCoref. Le système utilise des techniques de réseau neuronal pour fournir une liste de mentions potentielles. Ces mentions sont attribuées à des entités communes à l'aide de règles génériques et spécifiques au domaine. Nous trouvons que DramaCoref fonctionne bien sur les pièces de théâtre par rapport aux corpus d'autres domaines et profite de l'inclusion d'informations spécifiques aux pièces de théâtre. Sur la configuration la plus performante, il obtient un score ConLL de 32\xa0% en utilisant des mentions détectées automatiquement et de 55\xa0% en utilisant des mentions Gold. Les règles uniques permettent d'obtenir des scores de haute précision\xa0; cependant, les règles conçues pour d'autres domaines ne sont souvent pas applicables ou donnent des résultats insatisfaisants. L'analyse des erreurs montre que la détection des mentions est la principale faiblesse du système, fournissant des orientations pour les améliorations futures.", 'pt': 'Apresentamos um sistema de resolução de correferência em peças de teatro, DramaCoref. O sistema usa técnicas de rede neural para fornecer uma lista de possíveis menções. Essas menções são atribuídas a entidades comuns usando regras genéricas e específicas de domínio. Constatamos que o DramaCoref funciona bem nas peças teatrais quando comparado aos corpora de outros domínios e lucra com a inclusão de informações específicas das peças teatrais. Na configuração de melhor desempenho, ele alcança uma pontuação CoNLL de 32% ao usar menções detectadas automaticamente e 55% ao usar menções de ouro. Regras únicas alcançam pontuações de alta precisão; no entanto, as regras projetadas em outros domínios geralmente não são aplicáveis ou produzem resultados insatisfatórios. A análise de erros mostra que a detecção de menções é o principal ponto fraco do sistema, fornecendo orientações para melhorias futuras.', 'zh': '建一以决戏剧戏剧共生之统,DramaCoref。 统用神经网络术,以资潜表。 及用通则及特定于域则分给公共体。 臣等观之,比他域语料库,DramaCoref效戏剧剧中善,而益于含特定之戏剧。 至善之设,自动检测及时,其CoNLL为32%,金色为55%。 一则成高精度评分。 然而他领地设计的法则往往不适用或生不快意的。 差分析表明,检测者,系统之大端,为未来改进之方也。', 'ja': '劇場劇へのコアリファレンスを解決するためのシステム、DramaCorefを提示します。システムは、ニューラルネットワーク技術を使用して、潜在的な言及のリストを提供します。これらのメンションは、一般的なルールとドメイン固有のルールを使用して、共通のエンティティに割り当てられます。DramaCorefは、他のドメインのコーポラと比較して、劇場の芝居でうまく機能し、劇場の芝居に固有の情報を含めることで利益を得ていることがわかります。最高のパフォーマンスを発揮するセットアップでは、自動検出メンションを使用すると32%、ゴールドメンションを使用すると55%のCoNLLスコアを達成します。単一のルールは高精度スコアを達成しますが、他のドメインで設計されたルールは、しばしば適用されないか、満足のいかない結果をもたらします。エラー解析では、言及検出がシステムの主な弱点であることが示されており、今後の改善の方向性が示されています。', 'hi': 'हम थिएटर नाटकों, DramaCoref पर coreference को हल करने के लिए एक प्रणाली प्रस्तुत करते हैं। सिस्टम संभावित उल्लेखों की एक सूची प्रदान करने के लिए तंत्रिका नेटवर्क तकनीकों का उपयोग करता है। ये उल्लेख जेनेरिक और डोमेन-विशिष्ट नियमों का उपयोग करके सामान्य संस्थाओं को असाइन किए जाते हैं। हम पाते हैं कि DramaCoref थिएटर नाटकों पर अच्छी तरह से काम करता है जब अन्य डोमेन से कॉर्पोरेट की तुलना में और थिएटर नाटकों के लिए विशिष्ट जानकारी को शामिल करने से लाभ होता है। सबसे अच्छा प्रदर्शन करने वाले सेटअप पर, यह स्वचालित रूप से पता लगाए गए उल्लेखों का उपयोग करते समय 32% का CoNLL स्कोर प्राप्त करता है और सोने के उल्लेख का उपयोग करते समय 55% प्राप्त करता है। एकल नियम उच्च परिशुद्धता स्कोर प्राप्त करते हैं; हालांकि, अन्य डोमेन पर डिज़ाइन किए गए नियम अक्सर लागू नहीं होते हैं या असंतोषजनक परिणाम नहीं देते हैं। त्रुटि विश्लेषण से पता चलता है कि उल्लेख का पता लगाना सिस्टम की मुख्य कमजोरी है, जो भविष्य में सुधार के लिए दिशा-निर्देश प्रदान करता है।', 'ru': 'Мы представляем систему разрешения сущности театральных пьес, DramaCoref. Система использует методы нейронной сети, чтобы предоставить список потенциальных упоминаний. Эти упоминания присваиваются общим сущностям с использованием общих и специфичных для домена правил. Мы обнаружили, что DramaCoref хорошо работает над театральными пьесами по сравнению с театрами из других областей и получает прибыль от включения информации, специфичной для театральных пьес. На наиболее эффективной установке он достигает показателя CoNLL 32% при использовании автоматически обнаруженных упоминаний и 55% при использовании золотых упоминаний. Отдельные правила обеспечивают высокую точность оценок; однако правила, разработанные в других областях, часто не применимы или дают неудовлетворительные результаты. Анализ ошибок показывает, что обнаружение упоминания является основным недостатком системы, обеспечивая направления для будущих улучшений.', 'ga': 'Cuirimid córas i láthair chun an croí-chomhdháil a réiteach ar dhrámaí téatair, DramaCoref. Úsáideann an córas teicníochtaí néarlíonra chun liosta tagairtí féideartha a sholáthar. Sanntar na tagairtí sin d’eintitis choiteanna ag baint úsáide as rialacha cineálacha agus a bhaineann go sonrach leis an bhfearann. Feictear dúinn go n-oibríonn DramaCoref go maith ar na drámaí téatair i gcomparáid le corpora ó réimsí eile agus go mbaintear brabús as cuimsiú faisnéise a bhaineann go sonrach le drámaí téatair. Maidir leis an socrú is fearr, baintear amach scór CoNLL de 32% nuair a úsáidtear tagairtí a bhraitear go huathoibríoch agus 55% nuair a bhíonn tagairtí óir á n-úsáid. Baineann rialacha aonair scóir ardchruinneas amach; áfach, is minic nach mbíonn rialacha arna gceapadh ar fhearann eile infheidhme nó go mbíonn torthaí míshásúla acu. Léiríonn anailís earráide gurb é an bhrath lua príomh-laige an chórais, ag soláthar treoracha le haghaidh feabhsúcháin sa todhchaí.', 'ka': 'ჩვენ აჩვენებთ სისტემა, რომელსაც გადაწყვეტის სწორესება თამაში, DramaCoref. Name ეს მონიშნულებები საერთო ინტერტიკებისთვის, რომლებიც ყველაფერი და დიომინის განსაკუთრებული წესებისთვის გამოყენება. ჩვენ აღმოჩნეთ, რომ ეპამაკორეფი სამუშაოდ სამუშაო თამაში სამუშაო, როდესაც კოპორა სხვა სამუშაოებიდან და პროგრამიდან ინფორმაციის კონფიგურაციის შეყვარებადან თა საუკეთესო შესაძლებელი შესაძლებელებაში, ეს მიიღება 32% CoNLL წერტილი, როცა ავტომატურად განაკვირული წერტილებების გამოყენება და 55%, როცა მომხმარებული დლავის წერტილებები ერთი წესები უფრო დიდი წესების მიღება; მაგრამ სხვა დიომენტების განსაზღვრებული წესები ზოგიერთად არ აყენებელია ან არ აყენებელია განსაზღვრებული წესები. შეცდომის ანალიზაცია ჩვენებს, რომ ამოხსენებული განახსენება სისტემის მნიშვნელოვანი სისტემის მნიშვნელოვანობა, რომელიც მომავალეთ შესაძლებლობისთვი', 'el': 'Παρουσιάζουμε ένα σύστημα επίλυσης της συγχορήγησης σε θεατρικά έργα, DramaCoref. Το σύστημα χρησιμοποιεί τεχνικές νευρωνικών δικτύων για να παρέχει μια λίστα πιθανών αναφορών. Αυτές οι αναφορές αντιστοιχούν σε κοινές οντότητες χρησιμοποιώντας γενικούς και ειδικούς κανόνες τομέα. Διαπιστώνουμε ότι το έργο λειτουργεί καλά στα θεατρικά έργα σε σύγκριση με τα σώματα άλλων τομέων και επωφελείται από την συμπερίληψη πληροφοριών που αφορούν τα θεατρικά έργα. Στην καλύτερη ρύθμιση επιτυγχάνει βαθμολογία 32% όταν χρησιμοποιείτε αυτόματα ανιχνευμένες αναφορές και 55% όταν χρησιμοποιείτε χρυσές αναφορές. Οι ενιαίοι κανόνες επιτυγχάνουν βαθμολογίες υψηλής ακρίβειας· Ωστόσο, οι κανόνες που έχουν σχεδιαστεί για άλλους τομείς συχνά δεν εφαρμόζονται ή αποφέρουν μη ικανοποιητικά αποτελέσματα. Η ανάλυση σφαλμάτων δείχνει ότι η ανίχνευση αναφορών είναι η κύρια αδυναμία του συστήματος, παρέχοντας οδηγίες για μελλοντικές βελτιώσεις.', 'hu': 'Bemutatunk egy rendszert a színházi előadások coreferenciájának megoldására, DramaCoref. A rendszer neurális hálózati technikákat használ a lehetséges említések listájára. Ezeket a megemlítéseket általános és tartományspecifikus szabályok alkalmazásával rendelik közös szervezetekhez. Úgy találjuk, hogy a DramaCoref jól működik a színházi előadásokon, ha összehasonlítjuk más területekből származó corporákat, és profitál a színházi előadásokra vonatkozó információk bevonásából. A legjobb teljesítményű beállítás esetén 32%-os CoNLL pontszámot ér el automatikusan felismert említések használata esetén és 55%-os arany említések használata esetén. Az egységes szabályok nagy pontosságú pontszámokat érnek el; azonban a többi területre vonatkozó szabályok gyakran nem alkalmazandók, vagy nem kielégítő eredményeket eredményeznek. A hibaelemzés azt mutatja, hogy az említések felismerése a rendszer fő gyengesége, és iránymutatást ad a jövőbeli fejlesztésekhez.', 'it': "Presentiamo un sistema per risolvere la coreferenza sulle rappresentazioni teatrali, DramaCoref. Il sistema utilizza tecniche di rete neurale per fornire un elenco di potenziali menzioni. Queste menzioni sono assegnate a entità comuni utilizzando regole generiche e specifiche per il dominio. Troviamo che DramaCoref funziona bene sulle rappresentazioni teatrali rispetto ai corpora di altri domini e trae profitto dall'inclusione di informazioni specifiche per le rappresentazioni teatrali. Nella configurazione più performante, raggiunge un punteggio CoNLL del 32% quando si utilizzano menzioni rilevate automaticamente e del 55% quando si utilizzano menzioni dorate. Regole singole ottengono punteggi di alta precisione; Tuttavia, spesso le norme elaborate su altri settori non sono applicabili o danno risultati insoddisfacenti. L'analisi degli errori mostra che il rilevamento delle menzioni è la principale debolezza del sistema, fornendo indicazioni per miglioramenti futuri.", 'mk': 'Презентираме систем за решавање на соодветноста во театарските претстави, Драма Кореф. Системот користи техники на нервната мрежа за да обезбеди листа на потенцијални спомени. Овие спомени се доделени на заеднички ентитети користејќи генерални и доменски правила. Најдовме дека Драмакореф добро работи на театарските игри во споредба со капората од други домени и профитот од вклучувањето на информации специфични на театарските игри. На најдоброто поставување, таа постигнува резултат на CoNLL од 32 отсто кога користи автоматски детектирани спомени и 55 отсто кога користи златни спомени. Single rules achieve high precision scores;  however, rules designed on other domains are often not applicable or yield unsatisfactory results.  Анализата на грешките покажува дека детекцијата на спомените е главната слабост на системот, обезбедувајќи насоки за идни подобрувања.', 'lt': 'Mes pristatome sistemą, skirtą išspręsti koreferenciją teatro žaidimuose, DramaCoref. Siekiant sudaryti galimų paminėjimų sąrašą, sistema naudoja nervų tinklo metodus. Šios nuorodos priskiriamos bendriems subjektams, taikantiems bendrąsias ir konkrečioms sritims taikomas taisykles. Matome, kad DramaCoref gerai veikia teatro žaidimuose, palyginti su korpora iš kitų sričių ir pelnu, gautu įtraukus teatro žaidimams būdingą informaciją. Geriausių rezultatų nustatymo atveju, naudojant automatiškai aptiktus minėjimus, CoNLL rezultatas pasiekiamas 32 %, o naudojant aukso minėjimus – 55 %. Bendromis taisyklėmis pasiekti aukšto tikslumo rezultatai; however, rules designed on other domains are often not applicable or yield unsatisfactory results.  Error analysis shows that the mention detection is the main weakness of the system, providing directions for future improvements.', 'ms': 'We present a system for resolving coreference on theater plays, DramaCoref.  Sistem menggunakan teknik rangkaian saraf untuk menyediakan senarai sebutan yang berpotensi. Sebutan ini ditugaskan kepada entiti umum menggunakan peraturan generik dan domain-spesifik. Kami mendapati bahawa DramaCoref bekerja dengan baik pada permainan teater apabila dibandingkan dengan corpora dari domain lain dan keuntungan dari penyampilan maklumat khusus untuk permainan teater. On the best-performing setup, it achieves a CoNLL score of 32% when using automatically detected mentions and 55% when using gold mentions.  Peraturan tunggal mencapai skor ketepatan tinggi; however, rules designed on other domains are often not applicable or yield unsatisfactory results.  Analisis ralat menunjukkan bahawa pengesan sebutan adalah kelemahan utama sistem, menyediakan arah untuk peningkatan masa depan.', 'ml': 'തീയേറ്റര്\u200d കളികളില്\u200d കോര്\u200dഫെന്\u200dസ് തീരുമാനിക്കാനുള്ള ഒരു സിസ്റ്റം ഞങ്ങള്\u200d കൊണ്ടുവരുന്നു, ഡ്രാമാക സിസ്റ്റത്തില്\u200d സാധ്യതയുള്ള സാധ്യതകളുടെ നെയൂറല്\u200d നെറ്റര്\u200d നെറ്റോവര്\u200dക്ക് ടെക്കിനോക്കുകള്\u200d ഉപയ ഈ പ്രഖ്യാപങ്ങള്\u200d സാധാരണ സാധാരണ വിധികള്\u200d ഉപയോഗിച്ച് സാധാരണ വസ്തുക്കള്\u200dക്ക് വിതരണം ചെയ്യുന്നു. ഡ്രാമകോര്\u200dഫ് തീയേറ്റര്\u200d കളികളില്\u200d നന്നായി പ്രവര്\u200dത്തിക്കുന്നുണ്ടെന്ന് ഞങ്ങള്\u200d കണ്ടെത്തുന്നു. മറ്റു ഡൊമെയിനുകളില്\u200d നിന്നും കോ ഏറ്റവും നല്ല പ്രവര്\u200dത്തിപ്പിക്കുന്ന സജ്ജീകരണത്തില്\u200d, 32% കോണ്\u200dഎല്\u200d സ്കോര്\u200d പ്രാപിക്കുന്നു. സ്വർണ്ണ മെന്നറിയിപ്പുകള്\u200d ഉപയോഗി ഒരു നിയമങ്ങള്\u200d ഉയര്\u200dന്ന സ്കോര്\u200dട്ട് എത്തുന്നു; however, rules designed on other domains are often not applicable or yield unsatisfactory results.  പിശക് അന്വേഷണം കാണിക്കുന്നത് സിസ്റ്റത്തിന്റെ പ്രധാന ദുര്\u200dബലം ആണെന്നാണ്, ഭാവിയുടെ മെച്ചപ്പെടുത', 'mt': 'We present a system for resolving coreference on theater plays, DramaCoref.  The system uses neural network techniques to provide a list of potential mentions.  Dawn in-noti huma assenjati lil entitajiet komuni li jużaw regoli ġeneriċi u speċifiċi għad-dominju. Aħna nsibu li DramaCoref jaħdem tajjeb fuq il-logħob teatrali meta mqabbel mal-korpora minn dominji oħra u profitti mill-inklużjoni ta’ informazzjoni speċifika għall-logħob teatrali. Fuq l-aqwa struttura, tikseb punteġġ CoNLL ta’ 32% meta tuża semmijiet identifikati awtomatikament u 55% meta tuża semmijiet tad-deheb. Regoli uniċi jiksbu punteġġi ta’ preċiżjoni għolja; madankollu, regoli mfassla f’oqsma oħra spiss mhumiex applikabbli jew jagħtu riżultati mhux sodisfaċenti. L-analiżi tal-iżbalji turi li d-detezzjoni tal-imsemmija hija d-dgħufija prinċipali tas-sistema, li tipprovdi direzzjonijiet għal titjib fil-ġejjieni.', 'pl': 'Przedstawiamy system rozwiązywania koreferencji na spektaklach teatralnych, DramaCoref. System wykorzystuje techniki sieci neuronowej, aby dostarczyć listę potencjalnych wzmianek. Wspomnienia te są przypisywane do wspólnych podmiotów stosujących reguły ogólne i specyficzne dla domeny. Stwierdzimy, że DramaCoref dobrze sprawdza się w sztukach teatralnych w porównaniu z korpusami z innych dziedzin i zyskuje na włączeniu informacji specyficznych dla sztuk teatralnych. W najlepiej wydajnej konfiguracji osiąga wynik CoNLL 32% przy użyciu automatycznie wykrywanych wzmianek i 55% podczas używania złotych wzmianek. Jednolite zasady osiągają wysoką precyzję wyników; Jednakże zasady opracowane w innych dziedzinach często nie mają zastosowania lub przynoszą niezadowalające wyniki. Analiza błędów pokazuje, że wykrywanie wspomnień jest główną słabością systemu, dostarczając kierunków do przyszłych ulepszeń.', 'kk': 'Біз театр ойындарының сәйкестігін шешу жүйесін таңдаймыз, DramaCoref. Жүйе невралдық желі техникаларын қолданып, мүмкін мәліметтер тізімін келтіру үшін. Бұл мәліметтер жалпы және домен ережелерін қолдану үшін жалпы бірліктерге беріледі. Біз ДрамаКореф театр ойындарында жұмыс істейді. Басқа домендерден корпора және театр ойындарына белгіленген мәліметті қосудан салыстыру кезінде. Ең жақсы орнатылғанда, ол автоматты түрде анықталғанда 32% CoNLL нәтижесін және 55% нәтижесін қолданады. Бір ережелер дұрыс деңгейлерді жеткізеді; жалғыз ережелер дұрыс деңгейлерді жеткізеді. Бірақ басқа доменге құрылған ережелер көбінде қолданылмайды немесе құрылмайды. Қате анализиясы келтірілген анықтау жүйеңіздің негізгі бағдарламалығы, келесі жақсартулар үшін бағыттарды көрсетеді.', 'ro': 'Vă prezentăm un sistem de rezolvare a corefenței pe piesele de teatru, DramaCoref. Sistemul folosește tehnici de rețea neurală pentru a oferi o listă de mențiuni potențiale. Aceste mențiuni sunt atribuite entităților comune folosind reguli generice și specifice domeniului. Considerăm că DramaCoref funcționează bine pe piesele de teatru în comparație cu corporele din alte domenii și profită din includerea informațiilor specifice pieselor de teatru. Pe cea mai performantă configurație, acesta obține un scor CoNLL de 32% atunci când se utilizează mențiuni detectate automat și 55% atunci când se utilizează mențiuni de aur. Regulile unice obțin scoruri de înaltă precizie; Cu toate acestea, normele concepute pentru alte domenii nu sunt adesea aplicabile sau produc rezultate nesatisfăcătoare. Analiza erorilor arată că detectarea mențiunilor este principala slăbiciune a sistemului, oferind direcții pentru îmbunătățiri viitoare.', 'mn': 'Бид театр тоглоомууд дээр сайхан санааг шийдэх системийг тайлбарлаж байна, ДрамаКорфе. Энэ систем нь мэдрэлийн сүлжээний техникуудыг ашиглаж боломжтой ярианы жагсаалт гаргах боломжтой. Эдгээр нэр тодорхойлолтууд нь ерөнхий, домены тодорхойлолтой дүрмийг ашиглаж байдаг нийтлэг байгууллагууд. ДрамаКореф бусад орнуудын корпоратаас харьцуулахдаа театр тоглоомонд сайн ажилладаг гэдгийг бид олж мэднэ. Хамгийн сайн үйлдвэрлэлт дээр CoNLL оноо 32%-ын хувьд автоматаар нээлттэй хэмжээсүүдийг ашиглах үед, алт хэмжээсүүдийг ашиглах үед 55%. Нэг дүрэм нь өндөр тодорхой тоонуудыг гаргадаг. Гэхдээ бусад хэсэгт зохион байгуулагдсан дүрмийг ихэвчлэн ашиглаж чадахгүй, эсвэл сэтгэл хөдлөлгүй үр дүн гаргадаг. Алдаа асуудлын шинжилгээ нь хэлэлцэх нь системийн гол хүчтэй байдал, ирээдүйн сайжруулалтын тухай замаар хангалттай гэдгийг харуулдаг.', 'no': 'Vi presenterer eit system for å løysa koreferansen på teatraspelar, DramaCoref. Name Desse opplysningane er tildelt til felles einingar med generiske og domenespesifikke reglar. Vi finn at DramaCoref fungerer bra på teatrospelene når det sammenlignet med korpora frå andre domene og profiterer frå inkludering av informasjonen spesifikke til teatrospelene. På den beste innstillinga, oppnår det gjer ein CoNLL- poeng med 32% når det gjer automatisk oppdaga oppføringar og 55% når du brukar gull- oppføringar. Eine reglar oppnår høg nøyaktig poeng. Reglar som er laga på andre domene er ofte ikkje tilgjengelege eller gjev ugjennomsiktige resultat. Feilanalysen viser at oppdaginga av oppgjevnaden er hovudsaktet i systemet, og tilbyr retningar for framtidige forbetringar.', 'so': "Waxaynu soo bandhignaynaa nidaam ku saabsan tiyaatarada, DramaCoref. Isticmaalku wuxuu isticmaalaa qaababka shabakada naadiga ah si uu u helo liiska macluumaadka awoodda ah. Waxyaabahaas waxaa loo qeybiyaa qeybaha caadiga ah oo lagu isticmaalaa sharciyada gaarka ah iyo deegaanka. Waxaynu heli nahay in DramaCoref si wanaagsan u shaqeeyo ciyaaraha tiyaatarada marka la barbaranayo shirkadaha kale iyo faa'iidooyin laga helo ku qoran macluumaad gaar ah oo la xiriira ciyaaraha tiyaatarada. On the best-performing setup, it achieves a CoNLL score of 32% when using automatically detected mentions and 55% when using gold mentions.  Sharciyada kaliya waxay gaadhaan scoro aad u sahlan; Si kastaba ha ahaatee sharciyada lagu qoray meelaha kale inta badan ma habboon ama ma soo bixiyo resulto aan la faleyn karin. Baaritaanka khaladda waxaa muuqda in la soo sheegayo waa itaalka ugu weyn ee nidaamka, kaas oo hagaya hagitaanka mustaqbalka dambe.", 'sv': 'Vi presenterar ett system för att lösa coreference på teaterpjäser, DramaCoref. Systemet använder neurala nätverkstekniker för att ge en lista över potentiella omnämnanden. Dessa omnämnanden tilldelas gemensamma enheter med hjälp av allmänna och domänspecifika regler. Vi finner att DramaCoref fungerar bra på teaterpjäserna jämfört med korpor från andra domäner och tjänar på att inkludera information specifik för teaterpjäser. På den bästa konfigurationen uppnår den en CoNLL-poäng på 32% när du använder automatiskt identifierade omnämnanden och 55% när du använder guldomnämnanden. Enskilda regler ger höga precisionspoäng. Regler som utformats för andra områden är dock ofta inte tillämpliga eller ger otillfredsställande resultat. Felanalys visar att identifieringen av omnämnanden är systemets största svaghet och ger anvisningar för framtida förbättringar.', 'ta': 'நாங்கள் தியேட்டர் விளையாட்டுகளில் குறிப்பு முறைமையை தீர்வு செய்ய ஒரு அமைப்பை காண்பிக்கிறோ கணினி புதிய வலைப்பின்னல் தொழில்நுட்பங்களை பயன்படுத்துகிறது சாத்தியமான குறிப்புகளின் பட்டியலை  இந்த குறிப்புகள் பொதுவான பொருள்களுக்கு வழங்கப்பட்டுள்ளது மரபணு மற்றும் களம் குறிப்பிட்ட விதிகளை  நாங்கள் கண்டுபிடிக்கிறோம் ட்ராமாகோர்ப் தியேடியர் விளையாட்டுகளில் நன்றாக செயல்படுகிறது மற்ற தளங்களில் இருந்து நிறுவனத்த On the best-performing setup, it achieves a CoNLL score of 32% when using automatically detected mentions and 55% when using gold mentions.  ஒரே விதிகள் அதிக துல்லியமான மதிப்பெண்களை அடைக்கும். ஆனால், மற்ற களங்களில் வடிவமைக்கப்பட்ட விதிகள் பெரும்பாலும் பயன்படுத்தப்படவில்லை அல்லது புரியாத முடிவுகளை  பிழை அறிவிப்பு கண்டுபிடிப்பு கணினியின் முக்கிய பலஹீனமாகும் என்பதை காட்டுகிறது, எதிர்கால முன்னேற்றத்', 'ur': 'ہم تئاتر کھیلیوں پر مہربانی کا حل کرنے کے لئے ایک سیستم پیش کرتے ہیں، ڈراماکورف۔ سیسٹم نیورل نیٹ ورک ٹیکنیک استعمال کرتا ہے کہ امکانات کے ذکر کی لکھ دے۔ یہ ذکر جنریک اور ڈومین خاص قوانین کے مطابق مشترک ایٹنیٹیوں کے لئے مقرر کیے جاتے ہیں. ہم دیکھتے ہیں کہ DramaCoref تئاتر میں بہتر کام کرتا ہے جب دوسری جگہ سے corpora کے مقابلہ میں اور تئاتر کھیلیں کے مطابق مطلوب اطلاعات کے شامل ہونے سے فائدہ دیتا ہے سب سے بہترین سٹاپ پر یہ 32% کی CoNLL اسکور پہنچتا ہے جب سونے کے ذکر کے مطابق اپنے ساتھ پہنچے ہوئے ذکر اور 55% کو استعمال کرتے ہیں. ایک قانون بلند دقیق اسکور تک پہنچ رہے ہیں۔ لیکن دوسرے ڈومین پر طراحی کی قوانین اکثر موجود نہیں ہیں یا غیر قابل تحقیق کے نتائج حاصل کرتے ہیں۔ غلطی تحلیل دکھاتا ہے کہ ذکر اچانک سیسٹم کی اصلی کمزوری ہے، آیندہ تحقیقات کے لئے طریقے پیش کرتے ہیں.', 'sr': 'Predstavljamo sistem za rješavanje pristojnosti pozorišta, DramaCoref. Sistem koristi tehnike neuralne mreže kako bi pružio spisak potencijalnih spomena. Ova spomena su dodeljena zajedničkim entitetima koristeći generalna i domena specifična pravila. Pronašli smo da DramaCoref dobro radi na teatru kad je u usporedbi sa korporom iz drugih domena i profita od uključenja informacija specifičnih na teatru. Na najboljem nastavku postiže CoNLL rezultat od 32% kada koristi automatski otkrivene spomena i 55% kada koristi zlatne spomena. Jedino pravilo postiže visoke rezultate preciznosti; međutim, pravila dizajnirana na drugim domenama često se ne primjenjuju niti donose rezultate neodoljivosti. Analiza greške pokazuje da je otkrivanje spomena glavna slabost sistema, pružajući upute za buduće poboljšanje.', 'si': 'අපි ප්\u200dරදේශයක් තියෙන්නේ සෙල්ලම් සෙල්ලම් ගැන සිද්ධ විශ්වාස කරන්න, ඩ්\u200dරාමාකෝර්ෆ්. පද්ධතිය න්\u200dයුරාල් ජාලය තාක්ෂණය භාවිත කරන්න පුළුවන් කිරීමක් ලැයිස්තුවක් දෙන්න. සාමාන්\u200dය සහ ඩෝමින් විශේෂ නීතිය භාවිත කරන සාමාන්\u200dය අයිතියෙන් මේ කියන්න තියෙනවා. අපිට හොයාගන්න පුළුවන් විදිහට ඩ්\u200dරාමා කෝරෙෆ් සෙල්ලම් එකේ හොඳ වැඩ කරන්න පුළුවන් තියෙනවා අනිත් ඩොමේන් වලින් කොර්පෝර ස්වයංක්\u200dරියාත්මක සැකසුම් වෙනුවෙන්, ස්වයංක්\u200dරියාත්මක පරීක්ෂණය සහ 55% රත්තු පරීක්ෂණය සඳහා CoNLL ප්\u200dරමාණය 32% ව එකම නියෝජිත විශේෂතාවක් ගොඩක් විශේෂතාවක් ලැබෙනවා; නමුත්, අනිත් ඩෝමේන් වල සැලසුම් කරලා තියෙන නියෝජිත නියෝජිත වෙන්නේ නැහැ නැහැ නැහැ න ප්\u200dරශ්න විශ්ලේෂණය පෙන්වන්නේ පද්ධතියේ ප්\u200dරධාන දුර්වලයි කියලා, අනාගතයේ වැඩ කරන්න ප්\u200dරධානය.', 'vi': 'Chúng tôi giới thiệu một hệ thống để giải quyết khả năng phá hoại kịch nghệ. Hệ thống sử dụng các kỹ thuật mạng thần kinh để cung cấp một danh sách các khả năng đề cập. Những đề cập này được gán cho các đơn vị chung, dùng các quy định chung và miền. Chúng tôi thấy rằng DrameCoref hoạt động tốt trên các vở kịch khi so sánh với Hạ sĩ từ các lãnh vực khác và lợi nhuận từ việc thêm các thông tin đặc biệt cho các vở kịch kịch nghệ. Ở chế độ hiệu suất tốt nhất, nó đạt được một điểm Colt dưới 32. Khi sử dụng các chỉ thị tự động được phát hiện và 55. Mỗi quy tắc đạt điểm cao độ chính xác. Tuy nhiên, những quy định trên những lĩnh vực khác thường không được áp dụng hoặc mang lại kết quả không tốt. Phân tích lỗi cho thấy việc phát hiện đề cập là yếu điểm chính của hệ thống, cung cấp hướng dẫn cho cải tiến tương lai.', 'uz': "Biz tashqi o'ynash uchun tizimni DramaCoref. Name Bu taʼminlar umumiy va domen qoidalari yordamida qoʻllaniladi. Biz o'rganamiz, DramaCoref, boshqa domanidan ham qisqa maʼlumotni tashqi o'ynashga taʼminot qilishga bajariladi. Eng yaxshi bajarish moslamalarida, u 32% CONLL scori topadi. Avtomatik aniqlashda va 55% nuqta bilan gull taxminan foydalanayotganda. Bir xil qoidalar yuqori qiymatni bajaradi; Lekin, boshqa domenalarda yaratilgan qoidalar odatda qoʻllanmagan yoki ishlatilmagan natijalarni ishga tushirib boʻlmaydi. @ info", 'bg': 'Представяме система за решаване на кореференция по театрални пиеси, ДрамаКореф. Системата използва техники на невронната мрежа, за да осигури списък с потенциални споменавания. Тези споменавания се възлагат на общи субекти, използващи общи и специфични за домейн правила. Намираме, че ДрамаКореф работи добре върху театралните пиеси в сравнение с корпорите от други области и печели от включването на специфична информация за театралните пиеси. При най-ефективната настройка, тя постига резултат от 32% при използване на автоматично открити споменания и 55% при използване на златни споменания. Единните правила постигат висока прецизност; обаче правилата, разработени в други области, често не са приложими или дават незадоволителни резултати. Анализът на грешките показва, че откриването на споменаването е основната слабост на системата, давайки насоки за бъдещи подобрения.', 'hr': 'Predstavljamo sistem za rješavanje pristojnosti u teatrovima, DramaCoref. Sistem koristi tehnike neuralne mreže kako bi pružio popis potencijalnih spomena. Te spomena su dodijeljene zajedničkim subjektima koristeći generična i domena specifična pravila. Nalazimo da DramaCoref dobro radi na kazalištu u usporedbi s korporacijom iz drugih domena i profitima od uključenja informacija specifičnih na kazalište. Na najboljem uspostavljanju postiže CoNLL rezultat od 32% kada koristi automatski otkrivene spojeve i 55% kada koristi zlatne spojeve. Jedna pravila postiže visoke precizne rezultate; međutim, pravila dizajnirana na drugim domenama često se ne primjenjuju niti donose rezultate neodoljivosti. Analiza greške pokazuje da je otkrivanje spominjanja glavna slabost sustava, pružajući upute za buduće poboljšanje.', 'nl': 'We presenteren een systeem voor het oplossen van coreferentie op theaterstukken, DramaCoref. Het systeem maakt gebruik van neurale netwerktechnieken om een lijst van potentiële vermeldingen te verstrekken. Deze vermeldingen worden toegewezen aan gemeenschappelijke entiteiten met behulp van generieke en domeinspecifieke regels. We vinden dat DramaCoref goed werkt op de theaterstukken in vergelijking met corpora uit andere domeinen en profiteert van het opnemen van informatie specifiek voor theaterstukken. Op de best presterende setup bereikt het een CoNLL score van 32% bij gebruik van automatisch gedetecteerde vermeldingen en 55% bij gebruik van gouden vermeldingen. Enkele regels zorgen voor hoge precisiescores; Regels voor andere domeinen zijn echter vaak niet van toepassing of leveren onvoldoende resultaten op. Foutanalyse toont aan dat de vermelding detectie de belangrijkste zwakte van het systeem is en aanwijzingen geeft voor toekomstige verbeteringen.', 'da': 'Vi præsenterer et system til løsning af coreference på teaterstykker, DramaCoref. Systemet bruger neurale netværksteknikker til at give en liste over potentielle omtaler. Disse nævnelser tildeles fælles enheder ved hjælp af generiske og domænespecifikke regler. Vi finder ud af, at DramaCoref fungerer godt på teaterstykkerne sammenlignet med korpora fra andre domæner og profiterer af inkluderingen af oplysninger, der er specifikke for teaterstykker. På den bedst ydende opsætning opnår den en CoNLL score på 32% ved brug af automatisk registrerede omtaler og 55% ved brug af guld omtaler. Enkle regler giver høj præcision Men regler, der er udarbejdet på andre områder, er ofte ikke gældende eller giver utilfredsstillende resultater. Fejlanalyse viser, at registreringen af nævnelser er systemets største svaghed og giver retningslinjer for fremtidige forbedringer.', 'de': 'Wir präsentieren ein System zur Lösung von Coreferenz auf Theaterstücken, DramaCoref. Das System verwendet neuronale Netzwerktechniken, um eine Liste potenzieller Erwähnungen bereitzustellen. Diese Erwähnungen werden gemeinsamen Entitäten unter Verwendung generischer und domänenspezifischer Regeln zugeordnet. Wir finden, dass DramaCoref im Vergleich zu Korpora aus anderen Bereichen gut auf Theaterstücken funktioniert und von der Einbeziehung von Informationen profitiert, die spezifisch für Theaterstücke sind. Im leistungsstärksten Setup erreicht es einen CoNLL-Score von 32% bei Verwendung automatisch erkannter Erwähnungen und 55% bei Verwendung von Gold-Erwähnungen. Einzelregeln erzielen hohe Präzisionswerte; Regeln für andere Bereiche sind jedoch häufig nicht anwendbar oder führen zu unbefriedigenden Ergebnissen. Die Fehleranalyse zeigt, dass die Erwähnungserkennung die wichtigste Schwachstelle des Systems ist und Hinweise für zukünftige Verbesserungen gibt.', 'id': 'Kami mempersembahkan sistem untuk memecahkan koreferensi di drama, DramaCoref. Sistem menggunakan teknik jaringan saraf untuk menyediakan daftar pembicaraan potensial. Sebutan ini ditugaskan kepada entitas umum menggunakan aturan generik dan domain-spesifik. Kami menemukan bahwa DramaCoref bekerja dengan baik di permainan teater ketika dibandingkan dengan corpora dari domain lain dan keuntungan dari inklusi informasi spesifik untuk permainan teater. Pada setup yang paling berhasil, ia mencapai skor CoNLL 32% ketika menggunakan sebutan yang terdeteksi secara otomatis dan 55% ketika menggunakan sebutan emas. Aturan tunggal mencapai skor presisi tinggi; namun, peraturan yang dirancang pada domain lain sering tidak berlaku atau memberikan hasil yang tidak memuaskan. Analisi kesalahan menunjukkan bahwa deteksi sebutan adalah kelemahan utama sistem, menyediakan arah untuk perkembangan masa depan.', 'ko': '우리는 연극 공지를 해결하는 시스템, 즉 연극 공지 시스템을 제시했다.이 시스템은 신경 네트워크 기술을 사용하여 잠재적인 언급 목록을 제공한다.공통 및 도메인별 규칙을 사용하여 이러한 언급을 공통 엔티티에 할당합니다.우리는 다른 분야의 어료 라이브러리에 비해 Drama Coref가 연극 분야에서 양호하고 연극 특유의 정보를 포함하는 데 이익을 얻었다는 것을 발견했다.가장 성능이 좋은 설정에서 자동 검출을 사용할 때 언급된 코넬 점수는 32% 이고, 황금을 사용할 때 코넬 점수는 55% 이다.단일 규칙의 득점 정밀도가 높다.그러나 다른 분야에서 설계된 규칙은 종종 적용되지 않거나 만족스럽지 못한 결과를 낳는다.오류 분석에 따르면 검측을 언급하는 것이 시스템의 주요 약점으로 향후 개선에 방향을 제공했다.', 'fa': 'ما یک سیستم برای حل رضایت در بازی های تئاتر، درماکورف را پیشنهاد می کنیم. سیستم از تکنیک شبکه عصبی استفاده می\u200cکند تا یک لیست اشاره\u200cهای پتانسیل را پیشنهاد کند. این اشاره\u200cها به عنوان شرکت\u200cهای مشترک با استفاده از قانون\u200cهای مخصوص ژنرال و دامنی تعریف می\u200cشوند. ما فهمیدیم که دراماکورف در بازی های تئاتر خوب کار می کند وقتی با شرکت های دیگر در مقایسه با شرکت و سود از شامل اطلاعات خاص به بازی های تئاتر است. در بهترین تنظیمات انجام می\u200cدهد، در زمان استفاده از یادآوری\u200cهای خودکار و 55 درصد در زمان استفاده از یادآوری طلا به نمایش ۲۲ درصد CoNLL می\u200cرسد. قانون تنها به امتیاز دقیق بالا رسیده است. ولی قانون طراحی روی دومین های دیگر اغلب نتیجه\u200cهای غیرقابل تأکید و غیرقابل تأکید نیستند. تحلیل خطای نشان می دهد که کشف اشاره ضعیف اصلی سیستم است، که راه\u200cهای پیشرفت آینده را پیشنهاد می\u200cکند.', 'tr': "Biz teatro oýunçysyny çözmek üçin bir sistemasyny DramaCoref'a görkeýäris. Sistem potansiyel agzalaryň listini temin etmek üçin näyral şebeke teknikleri ulanýar. Bu agzalar generiki we domena häzirki düzgünleri ulanan bölegi jemi bir taýýarlara berildir. DramaCoref teatroda gowy işleýändigini düşünýäris, haçan başga alanlardan korpora we teatro oýunçalaryna görä beren informasiýanyň bolmagyndan has gazandyrýar. Iň gowy ýeterli düzümlerde ol CoNLL noty 32% netijesini otomatik a ňladykda, altyn sözlerini ulananda 55% netijesini ýetip bilýär. Tek kurallar beýik hasaplamalary ýetişir;  ýöne başga alanlarda tasarlanýan kurallar köplenç uygulanmayar ýa-da täsirsizlik netijesi getirilmeýär. Hata analyzasynda agzalanýan tapylmagyň sistemiň esasy zaýalygyny görkezýär, gelejek gelişmeler üçin yönlere üýtgedýär.", 'sw': 'Tunaweka mfumo wa kutatua umuhimu wa michezo ya theatre, DramaCoref. Mfumo huu unatumia mbinu za mtandao wa uraia kutoa orodha ya majina ya uwezekano. Tamko hizi zinagawanywa kwa vifaa vya kawaida kwa kutumia kanuni maalum za kawaida na ndani. We find that DramaCoref works well on the theater plays when compared to corpora from other domains and profits from the inclusion of information specific to theater plays.  Katika taasisi nzuri zaidi, inafanikiwa score la CoNLL la asilimia 32 ambapo kwa kutumia majina ya kujitegemea na asilimia 55 kwa kutumia majina ya dhahabu. Sheria moja zinafanikiwa vipimo vya sahihi; Hata hivyo, sheria zilizotengenezwa kwenye maeneo mengine mara nyingi hazitumiki wala hutoa matokeo yasiyo na uhakika. Uchambuzi wa makosa unaonyesha kuwa utambuzi huo ni udhaifu mkuu wa mfumo, unaotengeneza maendeleo ya baadaye.', 'am': 'የቴና አርእስቶች ላይ የኮርፌንሽን መፍታት ስርዓት እናቀርባለን፣ ድራማኮር፡፡ ሲስተምሩ የጠየር መረብ ስክሮዎችን ለመጠቀም የሚችሉትን ዝርዝር ለመስጠት ይጠቅማል፡፡ እነዚህ ማስታወቂያዎች የgeneric እና የdomain-specific ሥርዓቶች ለመጠቀም በተለየ አካባቢዎች ናቸው፡፡ ድራማኮር ከሌሎቹ ሀገሮች ጋር ከኮርፖር እና ከታይተር አካባቢ መረጃዎችን ለመጨመር በጨዋታ ላይ መልካም ሲሠራ እናገኛለን፡፡ በተሻለፈው ግንኙነት ላይ፣ ለ32 በመቶ የኮንLL ቆርጦ ማድረግ እና የወርቅ ማሳሰሪያ በመጠቀም ጊዜ፣ 55 በመቶ ማሰናከል ይደረጋል፡፡ Single rules achieve high precision scores;  however, rules designed on other domains are often not applicable or yield unsatisfactory results.  የስህተት ትምህርት ግንኙነቱ የሲስተም ድካም መጀመሪያ ደካማነት ነው፤ ለኋለኛይቱ ትክክለኛ መንገድ የሚያደርግ ነው፡፡', 'sq': 'Ne paraqesim një sistem për zgjidhjen e koreferencës në lojrat e teatrit, DramaCoref. Sistemi përdor teknika të rrjetit nervor për të dhënë një list ë përmendimesh të mundshme. Këto përmendime janë caktuar njësive të përbashkëta duke përdorur rregulla gjenerale dhe specifike për domenin. Ne zbulojmë se DramaCoref punon mirë në lojrat e teatrit kur krahasohet me korporën nga fusha të tjera dhe përfitimet nga përfshirja e informacionit specifik për lojrat e teatrit. Në konfigurimin më të mirë, ajo arrin një pikë CoNLL prej 32% kur përdor përmendime të zbuluara automatikisht dhe 55% kur përdor përmendime të artë. Single rules achieve high precision scores;  megjithatë, rregullat e dizajnuara në fusha të tjera shpesh nuk janë të aplikueshme apo japin rezultate të pakënaqura. Analiza e gabimeve tregon se zbulimi i përmendur është dobësia kryesore e sistemit, duke ofruar drejtime për përmirësimet e ardhshme.', 'hy': 'Մենք ներկայացնում ենք թատրոնային երաժշտությունների համակարգ, Դրամա Կորեֆ: Համակարգը օգտագործում է նյարդային ցանցի մեթոդներ պոտենցիալ նշանների ցուցակ տալու համար: These mentions are assigned to common entities using generic and domain-specific rules.  We find that DramaCoref works well on the theater plays when compared to corpora from other domains and profits from the inclusion of information specific to theater plays.  Ամենալավ արդյունավետ կառուցվածքի ժամանակ այն հասնում է CONAL-ի 32 տոկոսի գնահատականը, երբ օգտագործվում է ինքնաբերաբար հայտնաբերված հիշողություններ, իսկ ոսկու 55 տոկոսը: Միայն կանոնները հասնում են բարձր ճշգրիտության գնահատականների, այնուամենայնիվ, ուրիշ ոլորտներում նախագծված կանոնները հաճախ չեն օգտագործվում կամ չեն տալիս բավարար արդյունքներ: Սխալների վերլուծությունը ցույց է տալիս, որ նշումների հայտնաբերումը համակարգի հիմնական թույլ է, որը ուղղություններ է տալիս ապագա բարելավման համար:', 'az': 'Biz teatro oyunlarında mərhəmət çəkmək üçün bir sistemi göstəririk, DramaCoref. Sistem potansiyel məlumatların listesini təmin etmək üçün nöral a ğ tekniklərini istifadə edir. Bu məlumatlar generiki və domena müəyyən qaydalarını istifadə edərək ortaq məlumatlara verilir. DramaCoref başqa alanlardan korpora ilə qarşılaşdığı və teatro oyunlarına müəyyən edilmiş məlumatların istifadəsindən faydalanmasından yaxşı çalışır. Ən yaxşı təqdirdə, altın adlandırmalarını istifadə etdikdə, CoNLL dərəcəsini 32%-dən istifadə edəcək və 55%-dən istifadə edəcək. Tek kurallar yüksək dəqiqlik nöqtələrini başa düşər; Ancaq başqa domenalar üzərində dizayn edilən kurallar çox dəfə istifadə edilməz və ya təhlükəsizlik sonuçlarını verirlər. Xəta analizi göstərir ki, yada salınmaq sistemin ən zəifliyidir, gələcək düzəltmələr üçün yollar təyin edir.', 'bn': 'We present a system for resolving coreference on theater plays, DramaCoref.  সিস্টেম নিউরেল নেটওয়ার্ক প্রযুক্তি ব্যবহার করে সম্ভাব্য মেন্টের তালিকা প্রদান করার জন্য। এই উল্লেখ করা হচ্ছে সাধারণ বস্তুর জন্য সাধারণ এবং ডোমেইন-নির্দিষ্ট নিয়ম ব্যবহার করে। আমরা দেখতে পাচ্ছি যে ড্রামাকোরেফ অন্যান্য ডোমেন থেকে কোর্পোরার তুলনা করে থিয়েটার খেলায় ভালো কাজ করেছে এবং থিয়েটার খেলায় বিশ সবচেয়ে ভালো প্রদর্শনের ব্যাপারে, স্বয়ংক্রিয়ভাবে আবিষ্কার করা হয়েছে এবং স্বর্ণের কথা ব্যবহার করে স্বয়ংক্রিয়ভাবে ৫৫% ব্যবহার করে  একটি নিয়ম উচ্চ পরিসূচক স্কোর অর্জন করে; তবে অন্যান্য ডোমেইনে নির্ধারিত নিয়ম প্রায়শই ব্যবহার করে না অথবা অসফল ফল ফলাফল প্রদান করে না। ত্রুটি বিশ্লেষণ দেখাচ্ছে যে উল্লেখ করা হচ্ছে সিস্টেমের প্রধান দুর্বলতা, ভবিষ্যতের উন্নয়নের জন্য নির্দে', 'ca': "Presentam un sistema per resoldre la coreferencia en teatres, DramaCoref. El sistema utilitza tècniques de xarxa neural per proporcionar una llista de mentions potencials. Aquestes mencions s'assenyen a entitats comunes utilitzant normes genèriques i específices per domini. We find that DramaCoref works well on the theater plays when compared to corpora from other domains and profits from the inclusion of information specific to theater plays.  En la configuració de millor rendiment, aconsegueix una puntuació CoNLL del 32% quan utilitza mencions detectades automàticament i el 55% quan utilitza mentions d'or. Regles senzilles aconsegueixen puntuacions d'alta precisió; no obstant això, les regles dissenyades en altres dominis sovint no són aplicables o donen resultats insatisfactoris. L'anàlisi d'errors mostra que la detecció de la menció és la debilitat principal del sistema, proporcionant direccions per a millores futures.", 'cs': 'Představujeme systém pro řešení společné reference na divadelních hrách, DramaCoref. Systém využívá techniky neuronové sítě k poskytnutí seznamu potenciálních zmínek. Tyto zmínky jsou přiřazeny běžným entitám pomocí obecných a doménově specifických pravidel. Zjišťujeme, že DramaCoref funguje dobře na divadelních hrách ve srovnání s korpusy z jiných oblastí a profituje z zahrnutí informací specifických pro divadelní hry. V nejlepším nastavení dosahuje CoNLL skóre 32% při použití automaticky detekovaných zmínek a 55% při použití zlatých zmínek. Jednotná pravidla dosahují vysoce přesného skóre; Nicméně pravidla navržená pro jiné oblasti nejsou často použitelná nebo přinášejí neuspokojivé výsledky. Analýza chyb ukazuje, že detekce zmínek je hlavní slabinou systému a poskytuje směry pro budoucí zlepšení.', 'fi': 'Esitämme DramaCoref-järjestelmän teatterinäytelmien koreferenssin ratkaisemiseksi. Järjestelmä käyttää neuroverkkotekniikoita tarjotakseen luettelon mahdollisista maininnoista. Nämä maininnat annetaan yleisille yhteisöille, jotka käyttävät yleisiä ja toimialueekohtaisia sääntöjä. Havaitsemme, että DramaCoref toimii hyvin teatterinäytelmissä verrattuna muiden toimialojen korpusiin ja hyötyy teatterinäytelmiin liittyvän tiedon sisällyttämisestä. Parhaiten suoriutuvassa kokoonpanossa se saavuttaa CoNLL-pisteen 32%, kun käytetään automaattisesti havaittuja mainintoja, ja 55%, kun käytetään kultamainintoja. Yksittäisillä säännöillä saavutetaan erittäin tarkat pisteet; Muille aloille suunniteltuja sääntöjä ei kuitenkaan usein sovelleta tai ne tuottavat epätyydyttäviä tuloksia. Virheanalyysi osoittaa, että mainintojen havaitseminen on järjestelmän tärkein heikkous, joka antaa ohjeita tuleviin parannuksiin.', 'et': 'Tutvustame teatrietenduste koreferentsi lahendamise süsteemi DramaCoref. Süsteem kasutab närvivõrgu tehnikaid, et anda nimekiri võimalikest mainimistest. Need märked määratakse tavalistele üksustele, kes kasutavad üldisi ja domeenispetsiifilisi reegleid. Leiame, et DramaCoref töötab teatrietendustes hästi võrreldes teiste valdkondade korpustega ning kasutab teatrietenduste spetsiifilise teabe lisamisest. Parima tulemusega seadistuse puhul saavutab see CoNLL skoori 32% automaatselt tuvastatud märkuste kasutamisel ja 55% kullamärkuste kasutamisel. Üksikreeglid saavutavad suure täpsuse skoorid; kuid muude valdkondade eeskirjad ei ole sageli kohaldatavad või annavad ebarahuldavaid tulemusi. Vigade analüüs näitab, et märkimise tuvastamine on süsteemi peamine nõrkus, mis annab suunised edasisteks parandusteks.', 'af': "Ons voorsien 'n stelsel vir die oplossing van goedertierenheid op theaterspeletjies, DramaCoref. Name Hierdie bepaalde is aan gemeenskappe entiteite toegewys deur generieke en domein-spesifieke reëls te gebruik. Ons vind dat DramaCoref goed werk op die teater speel wanneer vergelyk word met korpora van ander domeine en profite van die inkluiting van informasie spesifieke na teater speletjies. Op die beste uitvoerde opstelling, word dit 'n CoNLL telling van 32% bereik wanneer dit outomaties opgemerk mentione en 55% gebruik word wanneer goud mentione gebruik word. Enkel reëls bereik hoë presisie punte; maar reëls ontwerp op ander domeine is dikwels nie toewenbaar of onbevestig resultate gegee nie. Fout analisie vertoon dat die minste opdekking die hoofswakheid van die stelsel is, verskaf rigtings vir toekomstige verbeteringe.", 'bs': 'Predstavljamo sistem za rješavanje pristojnosti kazališta, DramaCoref. Sistem koristi tehnike neuralne mreže kako bi pružio spisak potencijalnih spomena. Ova spomena su dodeljena zajedničkim entitetima koristeći generična i domena specifična pravila. Pronašli smo da DramaCoref dobro radi na kazalištu u usporedbi sa korporom iz drugih domena i profita od uključenja informacija specifičnih na kazalište. Na najboljem uspostavljanju, postiže CoNLL rezultat od 32% kada koristi automatski otkrivene spojeve i 55% kada koristi zlatne spojeve. Jedna pravila postiže visoke rezultate preciznosti; međutim, pravila dizajnirana na drugim domenama često se ne primjenjuju niti donose rezultate neodoljivosti. Analiza greške pokazuje da je otkrivanje spomena glavna slabost sistema, pružajući upute za buduće poboljšanje.', 'sk': 'Predstavljamo sistem reševanja koreference gledaliških predstav DramaCoref. Sistem uporablja tehnike nevronskega omrežja, da zagotovi seznam potencialnih omemb. Te omembe so dodeljene skupnim subjektom z uporabo splošnih in domenskih pravil. Ugotavljamo, da DramaCoref dobro deluje na gledaliških predstavah v primerjavi s korpusi iz drugih področij in ima dobiček od vključitve informacij, specifičnih za gledališke predstave. Pri najboljši nastavitvi doseže CoNLL rezultat 32% pri uporabi samodejno zaznanih omemb in 55% pri uporabi zlatih omemb. Ena pravila dosegajo visoko natančne ocene; vendar se pravila, oblikovana na drugih področjih, pogosto ne uporabljajo ali prinašajo nezadovoljive rezultate. Analiza napak kaže, da je odkrivanje omembe glavna slabost sistema, ki zagotavlja smernice za prihodnje izboljšave.', 'ha': "Tuna gabatar da wani na'ura da za'a karɓi mataimaki a kan tare zayen rawaya, DemaCorf. @ info: whatsthis Wannan sunan za'a ƙayyade zuwa abubuwa masu daidai da amfani da Rubuwa masu cikin kwanan da aka ƙayyade. Tuna gane cewa, DanmaCorf yana aiki mai kyau a kan tare-hoto idan an sammenliki makampuni daga wasu wurãre da amfani daga da za'a haɗa shi da wasu mutane da aka ƙayyade gamuwa. Daga tsarin da ake samar da shi mafi kyauta, yana sãmu wani ko'ron CoNLL mai ƙididdige shi da %32n idan yana yi amfani da sunan farat-gane da 55% idan ana yi amfani da sunan zĩnãriya. Single rules achieve high precision scores;  A lokacin da aka ƙayyade Rubuwan da aka designe a kan wasu wurãren kwanan ba su iya amfani ba ko kuma bã su fitar da matsalar wanda ba'a fasahan ba. Ana bayyana ɓata yana nuna cewa ganin bayani na zama mafi ƙaranci na'urar na'urar na'ura, da kuma yana da shiryarwa wa improvements masu gaba ɗaya.", 'jv': 'Awak dhéwé éntuk sistem kanggo nggawe corefer karo nganggo dolanan ping tiyar Drama coref Sistem sistem sistem kang teknik alat nang sampeyan akeh dumadhi kapan banggungan This ments are given to Common Entions use generic and domain-special rule. Awak dhéwé luwih nêmêng DraMacoref lan alam lan nganggo dolanan ping-dolanan sing dirampakan kanggo urèh dumadhiné karo dolanan liyane gawe nguasakno lan mbuluh lané perbudhakan kanggo ngerasakno sing luwih dumadhi Nang setup sing paling nêmêr, ditambah saben tanggal CoNLL kotak 32% dumaten neng nambah kang automatik dadi nambah lan 75% nambah dolanan nambah Multiple politenessoffpolite"), and when there is a change ("assertivepoliteness Ndeleksyon kesalahan menehi kuwi nggawe barang nggawe barang nggawe sistem, iso nggawe tarjamahan kanggo dianggap kanggo bisa dianten.', 'bo': 'ང་ཚོས་སྙིང་རྩེདམ་སའི་ནང་དུ་ཚོར་བ་ཐག་མོས་མཐུན་གྱི་ཐབས་ལམ་ལུགས་བྱེད་མི་ཐུབ་པ། མ་ལག་གིས་རྒུལ་ཁུངས་ཀྱི་ཐོ་འགོད་འདོགས་ཀྱི་ལག་ལེན་པའི་ནུས་མཐུན་དྲ་བ་ལག་སྟར་བྱེད་པ These mentions are assigned to common entities using generic and domain-specific rules. འུ་ཅག་གིས་DramaCoref སྙན་སྡེ་རིམ་གྱི་ནང་དུ་སྡེ་རིམ་པ་དང་མཉམ་ཁང་གཞན་ལས་མཐུན་པའི་སྐོར་དང་རྩེ་བ་དག་ཚོ་སྤྱད་ནས་དབུལ་ཁུལ་གྱི་ནང་ད འཛམ་གླིང་གི་སྒྲིག་འཛུགས་ཚད་ལ་ཕལ་ཆེ་ཤོས་བའི་སྒྲིག་སྟངས་ལ་ཉེན་ཀྱི་ཨང་ཀི32% ཡིན་པས། དེ་ནི་རང་འགུལ་གྱིས་རྙེད་སྐབས་སྤྱོད་ Single rules achieve high precision scores;  ཡིན་ནའང་། domains གཞན་དང་བཟོ་བཅོས་པའི་ཉེན་ཁུངས་སྤྱོད་མེད་པར། ཡང་ན་ཕན་འབྱེད་ཀྱི་ཉེན་ཁ་འབྱུང་མེད། ནོར་འཁྲུལ་གྱི་དབྱེ་ཞིབ་དཔྱད་ན་དམིགས་གསལ་བཤད་ནི་མ་ལག་གི་རྩ་བའི་ཞན་ཆ་ཉུང་ཡིན་པ་དང་མ་འོངས་ལ་ཡར་རྒྱས་', 'he': 'אנחנו מציגים מערכת לפתור התאמה במשחקי תיאטרון, דראם קורף. The system uses neural network techniques to provide a list of potential mentions.  הזכרונות האלה מוקבלים לאישויות משותפות בשימוש חוקים גנרליים ומספציפיים לתחום. אנחנו מוצאים שדראמקורף עובד היטב במשחקי התיאטרון בהשוואה לקופורה מתחומים אחרים ורווחים מהכוללת מידע ספציפי למשחקי התיאטרון. במערכת ההופעה הטובה ביותר, היא משיגה נקודת CoNLL של 32% כשמשתמשת בזכרונות שגילו באופן אוטומטי ו-55% כשמשתמשת בזכרונות זהב. חוקים בודדים משיגים נקודות מדויקות גבוהות; בכל אופן, חוקים שנועדו בתחומים אחרים לעתים קרובות לא מתאימים או נותנים תוצאות לא מספקות. ניתוח שגיאות מראה שזיהוי הזכר הוא החולשה הראשית של המערכת, מספק כיוונים לשיפורים עתידים.'}
{'en': 'Lazy Low-Resource Coreference Resolution : a Study on Leveraging Black-Box Translation Tools', 'ar': 'حل مرجعي منخفض الموارد كسول: دراسة حول الاستفادة من أدوات ترجمة الصندوق الأسود', 'es': 'Resolución de correferencias perezosas de bajos recursos: un estudio sobre cómo aprovechar las herramientas de traducción de caja negra', 'fr': "Résolution de coréférence lente à faibles ressources\xa0: une étude sur l'utilisation des outils de traduction en boîte noire", 'pt': 'Resolução de correferência preguiçosa de poucos recursos: um estudo sobre como aproveitar as ferramentas de tradução de caixa preta', 'ja': 'Lazy Low - Resource Coreference Resolution ：ブラックボックス翻訳ツールの活用に関する研究', 'ru': 'Lazy Low-Resource Coreference Resolution: A Study on Leveraging Black-Box Translation Tools', 'zh': '惰低资源协理解析:因黑盒译之具', 'hi': 'आलसी कम संसाधन Coreference संकल्प: ब्लैक बॉक्स अनुवाद उपकरण का लाभ उठाने पर एक अध्ययन', 'ga': 'Taifeach Croí-Acmhainne Íseal Leisciúil: Staidéar ar Uirlisí Aistriúcháin Black-Bosca a Ghiaráil', 'el': 'Ψήφισμα συντονισμού χαμηλής περιεκτικότητας σε πόρους: μελέτη για τη χρησιμοποίηση μεταφραστικών εργαλείων μαύρων κουτιών', 'ka': 'Name', 'hu': 'Lazy Low Resource Coreference Resolution: tanulmány a fekete dobozos fordítóeszközök hasznosításáról', 'lt': 'Netinkama mažų išteklių koreferencijos rezoliucija: Juodosios dėžutės vertimo įrankių naudojimo efektyvumo tyrimas', 'it': "Lazy Low-Resource Coreference Risoluzione: uno studio sull'utilizzo degli strumenti di traduzione Black-Box", 'kk': 'Қара- жақ аудару құрылғылары', 'mk': 'Лажна резолуција на коференција со ниски ресурси: студија за зголемување на алатките за преведување во црна кутија', 'ms': 'Resolusi Kesuaian Sumber Bawah Lazy: sebuah kajian mengenai Alat Terjemahan Kotak Hitam', 'ml': 'Lazy- low- resource Coreference Resolution: a Study on Leveraging Black- Box Translation Tools', 'mt': 'Riżoluzzjoni ta’ Koreferenza ta’ Riżorsi Bażi Mhux Riżorsi: Studju dwar l-Inżistenza tal-Għodod tat-Traduzzjoni tal-Kaxxa l-Iswed', 'mn': 'Lazy Low-Resource Coreference Resolution: Leveraging Black-Box Translation Tools', 'pl': 'Lazy Low-Resource Coreference Resolution: studium na temat wykorzystania narzędzi tłumaczeniowych czarnych skrzynek', 'no': 'Låg låg ressurskoreferanse oppløysing: eit studie om utviklingsverktøy for å levera svart boks', 'ro': 'Rezoluția de corefență leneșă cu resurse reduse: un studiu privind utilizarea instrumentelor de traducere a cutiilor negre', 'sr': 'Lazy Low-Resource Coreference Resolution: Ispitivanje o privlačnim alatima za prevod crnog boksa', 'ta': 'Lazy Low- Resource Coreference Resolution: a study on Leveraging Black- Box Translation Tools', 'so': 'Lazy Low-Resource Coreference Resolution: a Study on Leveraging Black-Box Translation Tools', 'sv': 'Lazy Low-Resource Coreference Resolution: en studie om att utnyttja Black Box översättningsverktyg', 'si': 'Name', 'ur': 'لازی کم-سروسیز سرپرست سرپرست روشنی: سیاہ باکس ترجمہ تولید کے بارے میں ایک تحقیق', 'uz': 'Qisqa manbaning oĘ»lchami:', 'vi': 'Phân giải bản năng lượng thấp lười biếng: một nghiên cứu về công cụ dịch thuật hộp đen', 'bg': 'Мързелива резолюция на кореференцията с ниски ресурси: проучване за използване на инструментите за превод на черни кутии', 'da': 'Lazy Low-Resource Coreference Resolution: en undersøgelse af udnyttelse af Black-Box Oversættelsesværktøjer', 'nl': 'Lazy Low Resource Coreference Resolutie: een studie naar het inzetten van black-box vertaaltools', 'hr': 'Lazy Low-Resource Coreference Resolution: Ispitivanje o privlačnim alatima za prevod crne kutije', 'id': 'Resolusi Koreferensi Sumber Daya Bawah Lazy: sebuah Studi tentang Menegang Alat Terjemahan Kotak Hitam', 'de': 'Lazy Low Resource Coreference Resolution: eine Studie zur Nutzung von Black-Box-Übersetzungstools', 'fa': 'راه حل پیشنهاد کم منابع لازی: یک مطالعه در مورد ابزارهای ترجمه جعبه سیاه', 'ko': '불활성 저자원 공지 해소: 블랙박스 번역 도구를 이용한 연구', 'tr': 'Aýak Ressurat Karma-Kabuky Çaltylygy', 'sw': 'Lazy Low-Resource Coreference Resolution: a Study on Leveraging Black-Box Translation Tools', 'af': 'Name', 'am': 'Lazy Low-Resource Coreference Resolution: a Study on Leveraging Black-Box Translation Tools', 'sq': 'Rezoluta e Koreferencës me burime të ulëta: një studim mbi nxitjen e mjeteve të përkthimit të kutisë së zezë', 'hy': 'Մոտ ցածր ռեսուրսների համառեֆերանսի լուծումն. սևամորթ արկղի թարգմանման գործիքների հավասարման ուսումնասիրություն', 'az': 'Lazy Low-Resource Coreference Resolution: Leveraging Black-Box Translation Tools', 'bs': 'Lazy Low-Resource Coreference Resolution: Ispitivanje o privlačnim alatima za prevod crnog boksa', 'bn': 'Lazy- low- resource Corefrence Resolution: Levering on a Levering Black- Box Translator tool', 'ca': 'Resolució de coerència de baix recursos falsa: un estudi sobre la valoració dels eines de traducció de caixa negra', 'cs': 'Lazy Low-Resource Coreference Resolution: studie o využití černých překladatelských nástrojů', 'fi': 'Lazy Low-Resource Coreference Resolution: Tutkimus mustan laatikon käännöstyökalujen hyödyntämisestä', 'et': 'Laisk vähese ressursiga korrektseerimislahendus: uuring musta kasti tõlkevahendite kasutamise kohta', 'he': 'פיתרון משאבים נמוכים עלוב: מחקר על התעלות כלי תרגום קופסת שחורה', 'ha': '@ action: button', 'jv': 'Resolution', 'sk': 'Lazy Low-Resolution Coreference: a Study on Leveraging Black Box Prevajalska orodja', 'bo': 'ཆུང་དུ་ཉུང་བའི་རྒྱུ་དངོས་ཉུང་བའི་གནད་དོན་མཐའ་དབྱིབས་ཆོག'}
{'en': 'Large annotated corpora for ', 'ar': 'تتوفر مجموعات كبيرة مشروحة لتحليل المرجع لعدد قليل من اللغات. بالنسبة للترجمة الآلية ، توجد أنظمة الصندوق الأسود القوية للعديد من اللغات. نحن نستكشف بشكل تجريبي الفكرة الجذابة للاستفادة من أدوات الترجمة هذه لإقلاع دقة المرجع المرجعي في اللغات ذات الموارد المحدودة. يتم تحليل سيناريوهين ، حيث يتم استخدام مجموعة مرجعية كبيرة بلغة عالية الموارد للتنبؤات المرجعية بلغة أصغر ، أي عن طريق الترجمة الآلية إما لمجموعة التدريب أو بيانات الاختبار. في تقييمنا التجريبي لقرار المرجع باستخدام السيناريوهين على عدة لغات متوسطة الموارد ، لم نجد أي تحسن على نماذج خط الأساس أحادية اللغة. يكشف تحليلنا لمصادر الخطأ المختلفة المتأصلة في السيناريوهات المدروسة أن جودة أدوات الترجمة الآلية المعاصرة هي في الواقع العامل المحدد الرئيسي.', 'fr': "Les grands corpus annotés pour la résolution de coréférence sont disponibles dans quelques langues. Pour la traduction automatique, cependant, il existe de solides systèmes de boîtes noires pour de nombreuses langues. Nous explorons de manière empirique l'idée intéressante de tirer parti de tels outils de traduction pour amorcer la résolution de coréférence dans des langues aux ressources limitées. Deux scénarios sont analysés, dans lesquels un grand corpus de coréférence dans un langage à ressources élevées est utilisé pour des prédictions de coréférence dans un langage plus petit, c'est-à-dire par traduction automatique du corpus d'apprentissage ou des données de test. Dans notre évaluation empirique de la résolution de coréférence à l'aide des deux scénarios sur plusieurs langues de ressources moyennes, nous ne trouvons aucune amélioration par rapport aux modèles de référence monolingues. Notre analyse des différentes sources d'erreur inhérentes aux scénarios étudiés révèle que la qualité des outils de traduction automatique modernes est en fait le principal facteur limitant.", 'pt': 'Grandes corpora anotados para resolução de correferência estão disponíveis para alguns idiomas. Para tradução automática, no entanto, existem fortes sistemas de caixa preta para muitos idiomas. Exploramos empiricamente a ideia atraente de alavancar essas ferramentas de tradução para iniciar a resolução de correferência em idiomas com recursos limitados. Dois cenários são analisados, nos quais um grande corpus de correferência em uma linguagem de alto recurso é usado para previsões de correferência em uma linguagem menor, ou seja, pela tradução automática do corpus de treinamento ou dos dados de teste. Em nossa avaliação empírica da resolução de correferência usando os dois cenários em vários idiomas de recursos médios, não encontramos melhorias em relação aos modelos de linha de base monolíngues. A nossa análise das várias fontes de erro inerentes aos cenários estudados, revela que, de facto, a qualidade das ferramentas de tradução automática contemporâneas é o principal fator limitante.', 'es': 'Los grandes corpus anotados para la resolución de correferencias están disponibles en algunos idiomas. Sin embargo, para la traducción automática, existen sistemas sólidos de caja negra para muchos idiomas. Exploramos empíricamente la atractiva idea de aprovechar estas herramientas de traducción para iniciar la resolución de correferencias en idiomas con recursos limitados. Se analizan dos escenarios, en los que se utiliza un gran corpus de correferencias en un lenguaje de recursos altos para las predicciones de correferencia en un idioma más pequeño, es decir, mediante la traducción automática del corpus de entrenamiento o los datos de prueba. En nuestra evaluación empírica de la resolución de correferencias utilizando los dos escenarios en varios idiomas de recursos medios, no encontramos ninguna mejora con respecto a los modelos de referencia monolingües. Nuestro análisis de las diversas fuentes de error inherentes a los escenarios estudiados revela que, de hecho, la calidad de las herramientas contemporáneas de traducción automática es el principal factor limitante.', 'ja': 'コアリファレンス解像度のための大きな注釈付きコーパスは、ほとんどの言語で利用できます。しかし、機械翻訳では、多くの言語に強力なブラックボックスシステムが存在します。このような翻訳ツールを活用して、限られたリソースを持つ言語でのブートストラップコーレファレンス解決に役立てるという魅力的なアイデアを実証的に探求しています。２つのシナリオが分析され、ハイリソース言語の大きなコアレファレンスコーパスが、より小さな言語のコアレファレンス予測のために、すなわち、訓練コーパスまたはテストデータのいずれかを機械翻訳することによって使用される。いくつかの中規模リソース言語の2つのシナリオを使用したコアレファレンス分解能の経験的評価では、単一言語のベースラインモデルよりも改善されていないことがわかります。研究されたシナリオに固有のさまざまなエラー源を分析した結果、現代の機械翻訳ツールの品質が主な制限要因であることが明らかになりました。', 'ru': 'Большие аннотированные корпуса для разрешения ядра доступны для нескольких языков. Однако для машинного перевода существуют сильные системы "черного ящика" для многих языков. Мы эмпирически исследуем привлекательную идею использования таких инструментов перевода для загрузки разрешения ядра на языках с ограниченными ресурсами. Проанализированы два сценария, в которых большой корпус кернов в языке с высоким уровнем ресурсов используется для прогнозирования кернов на меньшем языке, т.е. машинным переводом либо обучающего корпуса, либо тестовых данных. В нашей эмпирической оценке базового разрешения с использованием двух сценариев на нескольких языках со средними ресурсами мы не обнаружили никаких улучшений по сравнению с одноязычными базовыми моделями. Наш анализ различных источников ошибок, присущих изученным сценариям, показывает, что на самом деле качество современных инструментов машинного перевода является основным ограничивающим фактором.', 'hi': 'कोरफेरेंस रिज़ॉल्यूशन के लिए बड़े एनोटेटेड कॉर्पोरेट कुछ भाषाओं के लिए उपलब्ध हैं। मशीन अनुवाद के लिए, हालांकि, कई भाषाओं के लिए मजबूत ब्लैक-बॉक्स सिस्टम मौजूद हैं। हम अनुभवजन्य रूप से सीमित संसाधनों वाली भाषाओं में बूटस्ट्रैपिंग कोरफेरेंस रिज़ॉल्यूशन के लिए इस तरह के अनुवाद उपकरणों का लाभ उठाने के आकर्षक विचार का पता लगाते हैं। दो परिदृश्यों का विश्लेषण किया जाता है, जिसमें एक उच्च-संसाधन भाषा में एक बड़े सह-संदर्भ कॉर्पस का उपयोग एक छोटी भाषा में सह-संदर्भित भविष्यवाणियों के लिए किया जाता है, यानी, मशीन द्वारा या तो प्रशिक्षण कॉर्पस या परीक्षण डेटा का अनुवाद करके। कई मध्यम-संसाधन भाषाओं पर दो परिदृश्यों का उपयोग करके कोरेफेरेंस रिज़ॉल्यूशन के हमारे अनुभवजन्य मूल्यांकन में, हमें मोनोलिंगुअल बेसलाइन मॉडल पर कोई सुधार नहीं मिलता है। अध्ययन किए गए परिदृश्यों में निहित त्रुटि के विभिन्न स्रोतों के हमारे विश्लेषण से पता चलता है कि वास्तव में समकालीन मशीन अनुवाद उपकरणों की गुणवत्ता मुख्य सीमित कारक है।', 'zh': '用调引解析大带注者语料库可用少语。 然于机器翻译,多言强大之黑匣子。 我们据经验寻找了这种译具在资源有限的话中导引解解的诱人的意思。 析其二者,其高资言语大同推理语料库以小言协推理占候,即以机器翻译练语料库测试数据。 凡此二者,共指征解析实质,比单语基线未改。 所论固有误差之分析表明,事实之上,当世机器翻译器者,大限也。', 'ga': 'Tá corpora móra anótáilte le haghaidh taifeach croíchomhdhála ar fáil i gcúpla teanga. Maidir le haistriúchán meaisín, áfach, tá córais láidre bhosca dhubh ann do go leor teangacha. Déanaimid iniúchadh go heimpíreach ar an smaoineamh tarraingteach uirlisí aistriúcháin dá leithéid a ghiaráil chun taifeach croíchomhdhála a bhrú chun cinn i dteangacha le hacmhainní teoranta. Déantar anailís ar dhá chás, ina n-úsáidtear corpas mór croí-chomhdhála i dteanga ard-acmhainne le haghaidh réamh-mheastacháin croí-chomhdhála i dteanga níos lú, i.e., trí mheaisín-aistriúchán a dhéanamh ar an gcorpas oiliúna nó ar na sonraí tástála. Inár meastóireacht eimpíreach ar réiteach croí-chomhdhála ag baint úsáide as an dá chás ar roinnt teangacha meán-acmhainne, ní bhfuarthas aon fheabhas ar mhúnlaí bonnlíne aonteangacha. Léiríonn ár n-anailís ar na foinsí éagsúla earráide a bhaineann leis na cásanna a ndearnadh staidéar orthu, gurb é cáilíocht na n-uirlisí meaisín-aistrithe comhaimseartha an príomhfhachtóir teorannaithe.', 'hu': 'A korreferencia felbontásához szükséges nagyméretű jegyzetelt testek néhány nyelven érhetők el. A gépi fordítás esetében azonban sok nyelven léteznek erős fekete dobozos rendszerek. empirikusan feltárjuk azt a vonzó ötletet, hogy ilyen fordítóeszközöket használjunk fel a korlátozott erőforrásokkal rendelkező nyelveken történő coreferencia felbontás indítására. Két forgatókönyvet elemeznek, amelyekben egy nagy erőforrású nyelvű coreferencia korpuszt használnak egy kisebb nyelvű coreferencia előrejelzésekhez, azaz gépi fordítással vagy a képzési korpuszt vagy a tesztadatokat. A coreferencia felbontásának empirikus értékelése során több közepes erőforrású nyelven a két forgatókönyv felhasználásával nem találtunk javulást az egynyelvű alapmodellekhez képest. A vizsgált forgatókönyvekhez kapcsolódó különböző hibaforrások elemzése azt mutatja, hogy valójában a kortárs gépi fordítóeszközök minősége a legfőbb korlátozó tényező.', 'el': 'Μεγάλα σχολιασμένα σώματα για ανάλυση συγχορήγησης είναι διαθέσιμα για λίγες γλώσσες. Για τη μηχανική μετάφραση, ωστόσο, υπάρχουν ισχυρά συστήματα μαύρων κουτιών για πολλές γλώσσες. Ερευνούμε εμπειρικά την ελκυστική ιδέα της αξιοποίησης τέτοιων εργαλείων μετάφρασης για την επίλυση της συγχορήγησης σε γλώσσες με περιορισμένους πόρους. Αναλύονται δύο σενάρια, στα οποία ένα μεγάλο σώμα σε γλώσσα υψηλής περιεκτικότητας χρησιμοποιείται για προβλέψεις σε μικρότερη γλώσσα, δηλαδή με μηχανική μετάφραση είτε του σώματος εκπαίδευσης είτε των δεδομένων δοκιμής. Στην εμπειρική μας αξιολόγηση της επίλυσης της συνάφειας χρησιμοποιώντας τα δύο σενάρια σε διάφορες γλώσσες μεσαίων πόρων, δεν διαπιστώνουμε καμία βελτίωση σε σχέση με τα μονογλωσσικά μοντέλα βάσης. Η ανάλυση των διαφόρων πηγών σφαλμάτων που είναι εγγενείς στα μελετημένα σενάρια, αποκαλύπτει ότι η ποιότητα των σύγχρονων εργαλείων μηχανικής μετάφρασης αποτελεί τον κύριο περιοριστικό παράγοντα.', 'ka': 'მარტივი ენებისთვის უფრო დიდი ანოტირებული კოპორაა შესაძლებელია. მაქინის გაგრძელებისთვის, მაგრამ ძალიან შავ-ბოსტის სისტემი მრავალზე არსებობს. ჩვენ ემპერიკურად გავაკვირეთ ეს გადაწყვეტილების ხელსაწყოთა ხელსაწყოთა ხელსაწყოთა წარმოდგენისთვის წარმოდგენის წარმოდგენისთვის ენაში, რომელიც დავ ორი სენარიო ანალიზაციულია, რომელიც დიდი კოპეფერენციის კოპოსს მაღალი რესურსის ენაში გამოყენება კოპეფერენციის განსაზღვრებისთვის პატარა ენაში, ანუ მანქანის განსაზღვრებით, ანუ ტესტის მო ჩვენი ემპერიკალური წარმოდგენების გამოყენებაში ორი სინარიოს რამდენიმე მედირესისურსისურსისურსის ენაში, ჩვენ ვერ მოიძებნა მონოლენგური ფესისური მოდელების შესახებ. ჩვენი ანალიზია განსხვავებული შეცდომის გამოსახულება, რომელიც სწავლილი სინარიოში იყოს, რომ სინამდვილეში მდგომარეობის მაქინის გარგუნების გამოსახულება უფრო ფაქტორია.', 'it': "Corpora annotati di grandi dimensioni per la risoluzione di coreferenza sono disponibili per poche lingue. Per la traduzione automatica, tuttavia, esistono forti sistemi black-box per molte lingue. Esploriamo empiricamente l'interessante idea di sfruttare tali strumenti di traduzione per avviare la risoluzione della coreferenza in lingue con risorse limitate. Vengono analizzati due scenari, in cui un corpus di coreferenza grande in un linguaggio ad alta risorsa viene utilizzato per predizioni di coreferenza in un linguaggio più piccolo, cioè traducendo automaticamente il corpus di formazione o i dati del test. Nella nostra valutazione empirica della risoluzione della coreferenza utilizzando i due scenari su diversi linguaggi di media risorsa, non troviamo alcun miglioramento rispetto ai modelli di base monolingue. La nostra analisi delle varie fonti di errore inerenti agli scenari studiati, rivela che infatti la qualità degli strumenti di traduzione automatica contemporanei è il principale fattore limitante.", 'lt': 'Large annotated corpora for coreference resolution are available for few languages.  For machine translation, however, strong black-box systems exist for many languages.  Mes empiriniu požiūriu tiriame patrauklią idėją panaudoti tokias vertimo priemones, kad būtų galima sustabdyti koreferencijos sprendimą ribotų išteklių turinčiomis kalbomis. Analizuojami du scenarijai, kuriuose didelis koreferencinis korpusas didelio i šteklio kalba naudojamas koreferenciniams prognozėms mažesne kalba, t. y. perskaičiuojant mokymo korpusą arba bandymų duomenis. Mūsų empiriniame koreferencijos rezoliucijos vertinime naudojant du scenarijus keliose vidutinio išteklio kalbose nenustatome jokio pagerėjimo lyginant su vienkalbiniais pradiniais modeliais. Mūsų analizė įvairių klaidų šaltinių, susijusių su tirtais scenarijais, rodo, kad iš tikrųjų šiuolaikinių mašin ų vertimo priemonių kokybė yra pagrindinis ribojantis veiksnys.', 'kk': 'Құсбелгісінің айырмашылығының үлкен белгіленген корпора бірнеше тілдер үшін бар. Бірақ машинаны аудару үшін көптеген тілдер үшін қара жүйелер бар. Біз мұндай аудармалар құрылғыларын шектелген ресурстар тілдерде айырмашылығын жүктеу үшін империялық идеясын зерттеп көрдік. Екі сценарий анализ етіледі, оларда жоғары ресурстар тіліндегі үлкен көпшілік корпус кішкентай тілде, мысалы, көпшілік корпус немесе сынақтар деректерін аудару машинасы үшін қолданылады. Біз бірнеше орташа ресурс тілдерінің екі сценариясын қолданатын сәйкестік айырмашылығының эмпирикалық оқу үшін біз бірнеше тіл негізгі үлгілерінен жақсарту жоқ. Біздің зерттеулі сценариялардың әртүрлі қатенің көзінің анализациясы, қазіргі машинаны аудару құралдарының сапасы - негізгі шектеу факторы.', 'mk': 'Голем обележан корпора за резолуција на конференција се достапни за неколку јазици. Сепак, за машински превод постојат силни црни системи за многу јазици. Импирички ја истражуваме привлечната идеја за искористување на вакви алатки за превод за отстранување на резолуцијата на соодветноста на јазиците со ограничени ресурси. Two scenarios are analyzed, in which a large coreference corpus in a high-resource language is used for coreference predictions in a smaller language, i.e., by machine translating either the training corpus or the test data.  Во нашата емпирична оценка на резолуцијата на соодветноста користејќи ги двата сценарија на неколку јазици со средни ресурси, не најдовме подобрување во однос на монојазичните основни модели. Нашата анализа на различните извори на грешки inerenti на проучените сценарија открива дека всушност квалитетот на современите алатки за машински превод е главниот ограничувачки фактор.', 'ml': 'കോര്\u200dഫെന്\u200dസിന്റെ റിസ്റ്റേഷനുള്ള വലിയ കോര്\u200dപ്പോരാ കുറച്ചു ഭാഷകള്\u200dക്കായി ലഭ്യമാകുന്നു. മെഷീന്\u200d പരിഭാഷകള്\u200dക്ക്, എങ്കിലും ധാരാളം ഭാഷകള്\u200dക്ക് ശക്തമായ കറുത്ത ബോക്സ് സിസ്റ്റമുണ്ട്. അത്തരം പരിഭാഷയുടെ ഉപകരണങ്ങള്\u200d നിയന്ത്രിക്കുന്നതിനായി ബൂട്ട്രാക്കിപ്പിങ്ങ് കോര്\u200dഫെന്\u200dസ് റിസ്റ്റേഷന്\u200d ഭാഷകളില്\u200d ന രണ്ടു സിനേരറിയോസ് അന്വേഷിക്കുന്നു, അവിടെ ഒരു വലിയ വിഭവഭാഷയിലെ കോര്\u200dഫെന്\u200dസ് കോര്\u200dപ്പസ് ഉപയോഗിക്കുന്നു. ചെറിയ ഭാഷയില്\u200d കോര്\u200dഫെന്\u200dസ് പ്രവചനങ്ങള്\u200dക്ക് ഉപയോഗ നമ്മുടെ കോര്\u200dഫെന്\u200dസിന്\u200dറെ സിസ്റ്റല്\u200d നിര്\u200dണയിക്കുന്നതിന്\u200dറെ ശാസ്ത്രീകരണത്തിന്\u200dറെ വിശദീകരണത്തില്\u200d കൂടുതല്\u200d മദ്ധ്യ വിഭവഭാഷ പരിശോധിക്കപ്പെട്ട സിനേറിയോസിന്റെ വ്യത്യസ്ഥാനങ്ങളിലുള്ള പിഴവിന്റെ സ്രോതസ്സുകളെക്കുറിച്ച് നമ്മുടെ അന്വേഷണം വ്യക്തമാക്കു', 'no': 'Stor merkte korpora for oppløysing av koreferanse er tilgjengeleg for få språk. For maskineoversettelse finst imidlertid sterke svartbokssystemer for mange språk. Vi undersøker den tilbakekalende ideen om å levera slike omsetjingsverktøya for å oppretta oppløysing av koreferansen i språk med begrensede ressursar. To scenarior er analysert, der e in stor koreferens korpus i eit høg ressursspråk vert brukt for koreferens foregåver i ein mindre språk, dvs. ved maskina som omsetjer anten korpusen eller test data. I vårt empirisk evaluering av koreferanse-oppløysing med dei to scenarioane på fleire mediesressursspråk finn vi ingen forbedring over monospråk-basemodular. Analysen vårt av dei ulike kildene for feil som inneheld dei studierte scenarioane viser at kvaliteten til vanleg maskineomsetjingsverktøya er hovudgrensefaktoren.', 'mn': 'Хэдэн хэлний хувьд маш том анзаарагдсан корпора хэд хэдэн хэлний шийдвэрлэлд байдаг. Гэхдээ машины хөрөнгө оруулахад маш хүчтэй хар хайрцаг систем олон хэл дээр байдаг. Бид хэл дээр хязгаарлагдсан нөөц баялаг болох хэлбэрээр тайлбарлахын тулд ийм хөгжлийн хөгжлийн хэрэгсэл ашиглах боломжтой санааг судалж байна. Хоёр хувилбар шинжилгээ хийгддэг. Үүнд өндөр боловсролын хэл дээрх том хүндрэлтэй корпус жижиг хэл дээр зөвхөн таамаглалтын тулд хэрэглэгддэг. Хоёр дундаж боловсролын хэл дээр хоёр хувилбарыг ашиглан зөвхөн зөвшөөрөл шийдвэрлэлийн үнэлгээнд бид ганц хэлний суурь шугам загваруудын хувьд сайжруулалт олж чадахгүй. Бидний судалсан хувилбаруудын өөр олон алдааны эх үүсвэрийн талаар шинжилгээ нь орчин үеийн машин орчуулах хэрэгсэл нь хамгийн хязгаарлагч хүчин зүйл гэдгийг харуулдаг.', 'pl': 'Duże adnotacje korpusów dla rozdzielczości koreferencji są dostępne dla kilku języków. W przypadku tłumaczenia maszynowego istnieją jednak silne systemy czarnej skrzynki dla wielu języków. Empirycznie badamy atrakcyjny pomysł wykorzystania takich narzędzi tłumaczeniowych do bootstrapping coreference rozwiązywania w językach o ograniczonych zasobach. Analizowane są dwa scenariusze, w których duży korpus koreferencji w języku o wysokim zasobie jest wykorzystywany do prognozowania koreferencji w mniejszym języku, tj. przez tłumaczenie maszynowe korpusu treningowego lub danych testowych. W naszej empirycznej ocenie rozwiązywania współdzielności z wykorzystaniem dwóch scenariuszy dla kilku języków średnich zasobów nie stwierdzono poprawy w stosunku do jednojęzycznych modeli bazowych. Analiza różnych źródeł błędów nieodłącznych dla badanych scenariuszy pokazuje, że w rzeczywistości jakość współczesnych narzędzi do tłumaczenia maszynowego jest głównym czynnikiem ograniczającym.', 'ro': 'Corporele mari adnotate pentru rezoluția coreferenței sunt disponibile pentru câteva limbi. Cu toate acestea, pentru traducerea automată, există sisteme puternice de cutie neagră pentru multe limbi. Explorăm empiric ideea atrăgătoare de a utiliza astfel de instrumente de traducere pentru bootstraping rezoluția coreferenței în limbi cu resurse limitate. Sunt analizate două scenarii, în care un corp mare de corefență într-un limbaj cu resurse mari este utilizat pentru predicțiile corefenței într-o limbă mai mică, adică prin traducerea automată a corpului de formare sau a datelor de testare. În evaluarea empirică a rezoluției coreferenței utilizând cele două scenarii pe mai multe limbi cu resurse medii, nu găsim nicio îmbunătățire față de modelele de bază monolingve. Analiza diverselor surse de eroare inerente scenariilor studiate arată că, de fapt, calitatea instrumentelor contemporane de traducere automată este principalul factor limitator.', 'sr': 'Velika annotirana korpora za rezoluciju korisnosti dostupna je za nekoliko jezika. Međutim, za prevod mašine postoje jaki crne kutije za mnoge jezike. Mi praktično istražujemo apelujuću ideju o utjecavanju takvih alata za prevod za rezoluciju odgovarajućih odnosa na jezike sa ograničenim resursima. Analizirani su dva scenarija, u kojem se koristi veliki korpus dobrodošlosti na jeziku visokog resursa za predviđanje dobrodošlosti na manjom jeziku, tj. mašinom koja prevodi ili korpus treninga ili test podataka. U našem empiričkom procjenu rezolucije dobrote koristeći dva scenarija na nekoliko srednjih jezika resursa, mi ne pronađemo poboljšanje u monojezičkim modelima početnih linija. Naša analiza različitih izvora greške koje sadrže ispitivane scenarije pokazuje da je u stvari kvalitet savremenih alata za prevod mašine glavni ograničavajući faktor.', 'so': 'Shirkad aad u baahan tahay oo ku saabsan heshiiska qeybta waxaad ku heli kartaa luuqado yar. Si kastaba ha ahaatee waxaa jira nidaam xoog badan oo madow ah oo luuqado badan. Waxaynu si fiican u baaraynaa fikrada caafimaadka ah oo aan u soo dirno qalabka turjumaadda oo kale si aan ugu sameynno qayb-qayb-kaarka oo afka lagu qoro oo ay ku haystaan resources xadiiqada ah. Waxaa lagu analyadaa laba sano oo ku qoran luqada aad u weyn oo ku qoran luqada sare, kaas oo lagu isticmaalaa wax la sii sheegayo af koonfureed oo ku qoran luqad yar, waa tusaale ahaan machine turjuma cudurada waxbarashada ama macluumaadka imtixaanka. Qiimeynta qiimeynta qaynuunka ee aan ku isticmaalno labada muusikood oo ku qoran luqado kala duduwan ee noocyada dhexe ee noocyada hoose ee noocyada afka. Anaalbaarinayada noocyo badan oo qalabka ah oo ku jirta xaaladaha lagu akhriyey waxay caddaysaa in qiimaha turjumidda machineyda ee ku dhow ay yihiin qalabka wax lagu turjumo.', 'si': 'ප්\u200dරශ්නය විශේෂය සඳහා ලොකු ප්\u200dරශ්නයක් තියෙන්නේ භාෂාවක් ටිකක් විතරයි. ඒත් මැෂින් පරිවර්තනය සඳහා, බලපු කළු බොක්ස් පද්ධතිය බොහොම භාෂාවට තියෙනවා. අපි ක්\u200dරියාත්මක විශ්වාස කරනවා මේ වාර්ථාපන උපකරණයක් බුට්ස්ට්\u200dරෑප් ක්\u200dරියාත්මක විශ්වාස කරනවා භාෂාවල සීනාරියෝ දෙකක් විශ්ලේෂණය කරලා තියෙනවා, ඒ වගේම ලොකු කෝරෙෆෙරෙන්ස් කෝපස් එකක් ඉහළ භාෂාවට ප්\u200dරයෝජනය කරනවා පොඩි භාෂාවක් වලින අපේ අධ්\u200dයාත්මක විශ්ලේෂණ විශ්ලේෂණයේ අධ්\u200dයාත්මක විශ්ලේෂණ දෙකක් භාෂාවට ප්\u200dරයෝජනය කරන්න, අපිට එක භාෂාවික ප අපේ විශ්ලේෂණයේ විවිධ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ අධ්\u200dයානය කරලා තියෙන ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක් තියෙන්නේ අ', 'mt': "Large annotated corpora for coreference resolution are available for few languages.  Madankollu, għat-traduzzjoni bil-magna jeżistu sistemi b’kaxxa sewda b’saħħithom għal ħafna lingwi. Aħna esploraw b'mod empiriku l-idea attraenti ta' ingranaġġ ta' għodod ta' traduzzjoni bħal dawn biex nibdew ir-riżoluzzjoni tal-koreferenza f'lingwi b'riżorsi limitati. Jiġu analizzati żewġ xenarji, li fihom jintuża korpus kbir ta’ koreferenza f’lingwa b’riżorsi għoljin għat-tbassir ta’ koreferenza f’lingwa i żgħar, jiġifieri permezz ta’ traduzzjoni bil-magna jew il-korpus tat-taħriġ jew id-dejta tat-test. Fl-evalwazzjoni empirika tagħna tar-riżoluzzjoni tal-koreferenza bl-użu taż-żewġ xenarji fuq diversi lingwi ta’ riżorsi medji, ma nstabu l-ebda titjib fuq mudelli ta’ linja bażi monolingwi. L-analiżi tagħna tad-diversi sorsi ta’ żball inerenti għax-xenarji studjati, turi li fil-fatt il-kwalità tal-għodod ta’ traduzzjoni tal-magni kontemporanji hija l-fattur ta’ limitazzjoni ewlieni.", 'sv': 'Stora kommenterade korpora för coreference upplösning finns tillgängliga för få språk. För maskinöversättning finns dock starka svartboxsystem för många språk. Vi utforskar empiriskt den tilltalande idén att utnyttja sådana översättningsverktyg för att starta upp coreferenceloösning på språk med begränsade resurser. Två scenarier analyseras, där en stor coreferencekorpus på ett högresursspråk används för coreferenceprevisioner på ett mindre språk, dvs. genom maskinöversättning av antingen träningskorpus eller testdata. I vår empiriska utvärdering av coreference resolution med hjälp av de två scenarierna på flera medium-resource språk finner vi ingen förbättring jämfört med enspråkiga basmodeller. Vår analys av de olika felkällorna i de studerade scenarierna visar att kvaliteten på moderna maskinöversättningsverktyg faktiskt är den viktigaste begränsande faktorn.', 'ur': 'کم زبانوں کے لئے بہت بڑے مضبوط کورپورا ہے۔ لیکن ماشین کی ترجمہ کے لئے بہت سی زبانوں کے لئے مضبوط سیسٹم موجود ہیں۔ ہم نے اس طرح کی ترجمہ ابزار کے ذریعے زبانوں میں محدودہ سرمایہ کے ساتھ بوٹ سٹرپٹ پڑنے کے لئے زیادتی کرنے والی ایڈیوں کی تحقیق کرتی ہے. دو سناریوں کا تحلیل کیا جاتا ہے، جہاں ایک بڑی مہربانی کورپوس ایک بلند منبع زبان میں ایک چھوٹی زبان میں مہربانی کی پیش بینی کے لئے استعمال کیا جاتا ہے، یعنی مہینہ کے ذریعہ سے کہ تدریس کورپوس یا تدریس ڈیٹا کو ترجمہ کرتا ہے. ہمیں ایک زبان کی بنیس لین نمڈل پر کوئی سوداگری نہیں پاتا۔ ہماری تحقیق کی مختلف خطاؤں کے منبع کی مختلف تحقیق کرتی ہے جو مطالعہ کی سناریوں میں موجود ماشین کی ترجمہ ابزار کی کیفیت سب سے زیادہ محدود ہے۔', 'ta': 'குறிப்பிட்ட தெளிவுத்திறனுக்கு பெரிய அறிவிக்கப்பட்ட நிறுவனத்தை சில மொழிகளுக்கு கிடை For machine translation, however, strong black-box systems exist for many languages.  நாங்கள் மொழிகளில் உள்ள வளங்கள் உள்ள மொழிக்கான மொழிகளில் தொடக்கும் குறிப்பு தெளிவுத்திறனை மூலம் தொடக்கும் மொழிகளி இரண்டு காட்சிகள் ஆய்வு செய்யப்படுகின்றன, அதில் உயர்மூலத்தில் ஒரு பெரிய கோர்பென்ஸ் கூட்டு மொழியில் சிறிய மொழியில் குறைந்த மொழியில் மொழியில் மொழி கூற்று தெளிவுத்திறன் இரண்டு காட்சியை பயன்படுத்தி நமது முக்கியமான மதிப்பெண் மூலங்களில் முன்னேற்றம் காணவில்லை. படிக்கப்பட்ட காட்சியில் உள்ள பல்வேறு பிழையின் மூலங்களின் ஆய்வு, தற்போதைய இயந்திர மொழிபெயர்ப்பு கருவிகளின் தரம் உண்மையில் உள்ள முக', 'ms': 'Korpora besar yang dicatat untuk resolusi rujukan tersedia untuk beberapa bahasa. Untuk terjemahan mesin, bagaimanapun, sistem kotak hitam yang kuat wujud untuk banyak bahasa. Kami secara empirik mengeksplorasi idea menarik untuk menggunakan alat terjemahan seperti ini untuk bootstrapping resolusi persamaan dalam bahasa dengan sumber terbatas. Dua skenario dianalisis, di mana corpus coreference besar dalam bahasa sumber-tinggi digunakan untuk ramalan coreference dalam bahasa yang lebih kecil, iaitu dengan mesin menerjemahkan sama ada corpus latihan atau data ujian. Dalam penilaian empirik kita tentang resolusi persamaan menggunakan dua skenario dalam beberapa bahasa sumber-tengah, kita tidak mendapati peningkatan daripada model dasar monobahasa. Our analysis of the various sources of error inherent to the studied scenarios, reveals that in fact the quality of contemporary machine translation tools is the main limiting factor.', 'uz': "Name Masofina tarjima qilish uchun ko'p tillar uchun katta qora qutis tizimi mavjud. Biz bunday tarjima asboblarni boshqarish uchun qo'shimcha o'ylab o'ylab ko'rayapmiz, cheksiz manbalar bilan boshlash uchun. Ikkita scenario analyzed i, bu yerda juda katta manbalar tilida katta coreference kopusi bir kichkina tilda ishlatiladi, balki mashinani taʼminlovchi kopus yoki sinov maʼlumotni tarjima qilish uchun ishlatiladi. Bizning bir necha markaziy manbalar tilida qo'shimcha raqamli qiymatlarimizda, biz monolingual asosiy modellaridan o'xshash ko'rinishimiz mumkin. Biz o'rganilgan ko'pchilik aniqlariga ega xato manbaslarimizni aniqlash imkoniyatini anglatadi, aslida hozir mavjud mashina tarjima asboblar sifatida muhim chegara faktor.", 'vi': 'Có rất nhiều thông tin ghi chú để giải quyết hạn hẹp cho vài ngôn ngữ. Tuy nhiên, trong dịch vụ máy, có rất nhiều hệ thống hộp đen tồn tại. Chúng ta nghiên cứu kinh nghiệm ý tưởng lôi cuốn này để sử dụng các công cụ dịch chuyển để khởi động giải quyết khả năng cao bằng ngôn ngữ có giới hạn. Hai kịch bản được phân tích, trong đó có một khả năng cao cao trong một ngôn ngữ có nguồn cao được sử dụng để dự đoán hạn hẹp trong một ngôn ngữ nhỏ hơn, tức là thông qua máy dịch chuyển cơ thể huấn luyện hoặc các dữ liệu thử nghiệm. Trong kinh nghiệm đánh giá nhiệt độ nghị quyết dựa trên hai viễn cảnh với nhiều ngôn ngữ phổ biến, chúng tôi không thấy có tiến triển gì hơn mô hình cơ bản. Phân tích của chúng tôi về các nguồn gây ra sai lầm liên quan đến các tình huống nghiên cứu, cho thấy chất lượng của các công cụ dịch chuyển máy thời đại là yếu tố giới hạn chính.', 'bg': 'Големи анотирани корпуси за резолюция на кореференцията са налични за няколко езика. За машинния превод обаче съществуват силни черни кутии за много езици. Емпирично изследваме привлекателната идея за използване на такива инструменти за превод за стартиране на резолюция на кореференцията на езици с ограничени ресурси. Анализирани са два сценария, при които голям корпус на кореференция на високоресурсен език се използва за прогнозиране на кореференция на по-малък език, т.е. чрез машинен превод или тренировъчния корпус, или тестовите данни. В нашата емпирична оценка на резолюцията на кореференцията, използвайки двата сценария на няколко езика със среден ресурс, не откриваме подобрение в сравнение с моноезичните базови модели. Нашият анализ на различните източници на грешки, присъщи на изследваните сценарии, разкрива, че всъщност качеството на съвременните инструменти за машинен превод е основният ограничаващ фактор.', 'nl': "Grote geannoteerde corpora's voor coreferentie resolutie zijn beschikbaar voor enkele talen. Voor machinevertaling bestaan er echter sterke black-box systemen voor vele talen. We onderzoeken empirisch het aantrekkelijke idee om dergelijke vertaaltools te gebruiken voor bootstrapping coreference resolutie in talen met beperkte middelen. Twee scenario's worden geanalyseerd, waarbij een groot coreferentiecorpus in een taal met veel resources wordt gebruikt voor coreferentievoorspellingen in een kleinere taal, d.w.z. door machinaal het trainingscorpus of de testgegevens te vertalen. In onze empirische evaluatie van coreferentieresolutie met behulp van de twee scenario's op verschillende middelgrote talen, vinden we geen verbetering ten opzichte van eentalige basismodellen. Uit onze analyse van de verschillende foutbronnen die inherent zijn aan de bestudeerde scenario's, blijkt dat de kwaliteit van hedendaagse machinevertaaltools de belangrijkste beperkende factor is.", 'da': 'Store noterede korpora til coreferenceopløsning er tilgængelige for få sprog. For maskinoversættelse findes der imidlertid stærke sorte bokssystemer for mange sprog. Vi undersøger empirisk den tiltalende idé om at udnytte sådanne oversættelsesværktøjer til opstart af coreferenceopløsning på sprog med begrænsede ressourcer. Der analyseres to scenarier, hvor et stort coreferencekorpus på et højt ressourcesprog anvendes til coreferencekorpus på et mindre sprog, dvs. ved maskinoversættelse enten træningskorpus eller testdata. I vores empiriske evaluering af coreferenceopløsning ved hjælp af de to scenarier på flere medium-resource sprog finder vi ingen forbedring i forhold til ensprogede basismodeller. Vores analyse af de forskellige fejlkilder, der er forbundet med de undersøgte scenarier, viser, at kvaliteten af moderne maskinoversættelsesværktøjer faktisk er den vigtigste begrænsende faktor.', 'hr': 'Velika annotirana korpora za rješenje dobrodošlosti dostupna je za nekoliko jezika. Međutim, za prevod strojeva postoje jaki crno-kutijski sustavi za mnoge jezike. Mi empirički istražujemo privlačnu ideju o primjeni takvih alata za prevod za rješavanje odgovarajućih mjera na jezicima s ograničenim resursima. Analiziraju se dva scenarija, u kojem se koristi veliki korpus dobrodošlosti na jeziku visokog resursa za predviđanje dobrodošlosti na manjem jeziku, tj. strojem koji prevodi ili korpus treninga ili test podataka. U našem empiričkom procjenu rezolucije liječnosti koristeći dva scenarija na nekoliko srednjih jezika resursa, ne pronađemo poboljšanje u monojezičkim početnim modelima. Naša analiza različitih izvora greške koje sadrže ispitivane scenarije pokazuje da je u stvari kvalitet savremenih alata za prevod strojeva glavni ograničavajući faktor.', 'de': 'Große kommentierte Korpora zur Coreferenzauflösung sind für wenige Sprachen verfügbar. Für die maschinelle Übersetzung existieren jedoch starke Black-Box-Systeme für viele Sprachen. Wir erforschen empirisch die attraktive Idee, solche Übersetzungstools für die Bootstrapping-Coreferenzauflösung in Sprachen mit begrenzten Ressourcen einzusetzen. Es werden zwei Szenarien analysiert, in denen ein großer Coreferenzkorpus in einer ressourcenintensiven Sprache für Coreferenzvorhersagen in einer kleineren Sprache verwendet wird, d.h. durch maschinelle Übersetzung des Trainingskorpus oder der Testdaten. In unserer empirischen Auswertung der Coreferenzauflösung anhand der beiden Szenarien für mehrere Sprachen mit mittlerer Ressource finden wir keine Verbesserung gegenüber monolingualen Basismodellen. Unsere Analyse der verschiedenen Fehlerquellen, die den untersuchten Szenarien inhärent sind, zeigt, dass tatsächlich die Qualität der modernen maschinellen Übersetzungswerkzeuge der wichtigste einschränkende Faktor ist.', 'id': 'Kopora besar yang dicatat untuk resolusi koreferensi tersedia untuk beberapa bahasa. Bagi terjemahan mesin, bagaimanapun, sistem kotak hitam yang kuat ada untuk banyak bahasa. Kami secara empiris mengeksplorasi ide menarik untuk menggunakan alat terjemahan tersebut untuk bootstrapping resolusi koreferensi dalam bahasa dengan sumber daya terbatas. Dua skenario dianalisis, di mana corpus coreference besar dalam bahasa sumber daya tinggi digunakan untuk prediksi coreference dalam bahasa yang lebih kecil, yaitu dengan mesin menerjemahkan baik corpus pelatihan atau data tes. Dalam evaluasi empirik kita dari resolusi koreferensi menggunakan dua skenario pada beberapa bahasa sumber daya tengah, kita tidak menemukan peningkatan dibanding model dasar monobahasa. Analisis kami dari berbagai sumber kesalahan yang ada pada skenario yang dipelajari, mengungkapkan bahwa pada kenyataannya kualitas alat terjemahan mesin kontempor adalah faktor pembatasan utama.', 'ko': '공통적으로 소해를 가리키는 대형 주석 자료 라이브러리는 소수의 언어에 사용할 수 있다.그러나 기계 번역에 있어 많은 언어에 강력한 블랙박스 시스템이 존재한다.우리는 이런 번역 도구를 이용하여 자원에 한계가 있는 언어에서 공지해소를 유도하는 유혹적인 생각을 경험적으로 탐색했다.두 가지 상황을 분석했다. 즉, 기계 번역을 통해 자료 라이브러리나 테스트 데이터를 훈련시키고 고자원 언어 중의 대형 공지 자료 라이브러리를 사용하여 비교적 작은 언어 중의 공지 예측을 한다.우리가 이 두 가지 장면을 이용하여 몇 가지 미디어 자원 언어의 공통된 지칭을 해소하는 실증 평가를 실시한 결과 우리는 단어 기선 모델에 비해 아무런 개선이 없다는 것을 발견했다.우리가 연구한 장면 고유의 각종 오류원에 대한 분석에 의하면 사실상 현대 기계 번역 도구의 질은 주요한 제한 요소이다.', 'fa': 'شرکت\u200cهای بزرگی که برای حل\u200cسازی رضایت می\u200cکنند برای چند زبان دسترسی دارند. ولی برای ترجمه ماشین سیاه جعبه قوی برای زبانهای زیادی وجود دارد. ما به صورت عمومی ایده\u200cی تحقیق کردن این ابزارهای ترجمه را برای تغییر دادن تغییر منابع محدودیت در زبانها تحقیق می\u200cکنیم. دو سناریو تحلیل می\u200cشود که در آن یک کورپوس بزرگی در زبان منابع بالا برای پیش\u200cبینی\u200cهای منابعی کوچک، یعنی با دستگاه که یا کورپوس آموزش یا داده\u200cهای آزمایش را ترجمه می\u200cکند، برای پیش\u200cبینی\u200cهای منابعی کوچک استفاده می\u200cشود. در ارزیابی امپراطوری ما از استفاده از دو سناریو در زبان\u200cهای منبع متوسط، هیچ بهتری بر مدل\u200cهای متوسط زبان نمی\u200cیابیم. تحلیل ما از منابع مختلف خطایی که در اختیار سناریو مطالعه شده، نشان می دهد که در حقیقت کیفیت ابزار ترجمه ماشین مدرن اصلی محدودیت کننده است.', 'sw': 'Kampuni kubwa iliyotolewa kwa ajili ya suluhisho la mafanikio yanapatikana kwa lugha chache. Kwa kutafsiri mashine, hata hivyo, mifumo madhubuti yanakuwepo kwa lugha nyingi. Tunafahamu kwa makini wazo la kukabiliana na kutuma zana za tafsiri kama hizi kwa ajili ya kuzuia suluhisho la msingi kwa lugha zenye rasilimali chache. Matokeo mawili yanachambuwa, ambapo makampuni makubwa yenye lugha ya rasilimali ya juu yanatumiwa kwa ajili ya utabiri wa kibiashara kwa lugha ndogo, yaani kwa kutumia mashine kutafsiri ama vifaa vya mafunzo au taarifa za jaribio. Katika tathmini yetu ya utambulisho wa mafanikio kwa kutumia mitazamo miwili kwenye lugha kadhaa za rasilimali za kati, hatupati maendeleo zaidi ya mifano ya msingi wa lugha za kimonolinguli. Our analysis of the various sources of error inherent to the studied scenarios, reveals that in fact the quality of contemporary machine translation tools is the main limiting factor.', 'tr': 'H채zirki diller 체챌in uly t채sirli janla힊dyryldy. 횦철ne ma힊yny흫 terjimesi 체챌in k채n k철p diller 체챌in g체첵챌li gara kassy sistemleri bar. Biz aslynda 챌yky힊 g체첵챌leri bilen dillerde terjime edip bilmek 체챌in bejermek isle첵채n pikirleri ke힊fed첵채ris. Iki sanary첵a 챌철z체l첵채r, 첵okary resurslardaki 첵okary 챌yky힊 dilinde 철r채n uly korpus, ki챌ijek dilde (di첵p g철rn체힊 dili) 철ng철r체mler 체챌in ulanyl첵ar, men체첵e-de ma힊yny흫 korpusu 첵a-da synaglary흫 terjime edendir. N채챌e orta orta 챌yky힊 dilinde iki senaryony ulan첵an 챌yky힊 etm채ni흫 empiriki 챌yky힊ymyzda, monodil baz 챌yky힊 modellerinde hi챌 hili gowurak tapma첵arys. Bizi흫 철wrenmeli senaryo흫da 첵al흫y힊y흫 d체rli 챌e힊itli kaynaklaryny흫 analyzasymyz 힊ol g체n체mizdeki ma힊yny흫 terjime edip bilmek 체챌in esasy 챌ykarylykdyr.', 'sq': 'Korpora e madhe e anotuar për zgjidhjen e korreferencës janë në dispozicion për pak gjuhë. Për përkthimin automatik, megjithatë, sistemet e forta të kutisë së zezë ekzistojnë për shumë gjuhë. Ne empirikisht eksplorojmë idenë tërheqëse të përdorimit të mjeteve të tilla përkthimi për zgjidhjen e bashkëdrejtimit në gjuhë me burime të kufizuara. Dy skenarë janë analizuar, në të cilën një korpus i madh koreference në një gjuhë me burime të larta përdoret për parashikime koreference në një gjuhë më të vogël, pra, duke përkthyer makinën ose korpus trajnimit ose të dhënat e testit. Në vlerësimin tonë empirik të rezolutës së korreferencës duke përdorur dy skenarët në disa gjuhë të burimeve të mesme, nuk gjejmë përmirësim lidhur me modelet monogjuhësore bazë. Analiza jonë e burimeve të ndryshme të gabimeve inerente në skenarët e studiuara, tregon se në fakt cilësia e mjeteve të përkthimit të makinave bashkëkohore është faktori kryesor kufizues.', 'am': 'የኮርፖርት ማስታወቂያውን ለጥቂት ቋንቋዎች ማግኘት ነው፡፡ ለመmachine ትርጉም፣ ኃይለኛ ጥቁር-box ስርዓቶች በብዙ ቋንቋዎች ውስጥ አሉ፡፡ እንደዚህ ያሉትን ትርጉም መሣሪያዎች በተለየ ቋንቋዎች የቆርፌርሽን ማስታወቂያውን በመስጠት እናስፈልጋለን፡፡ ሁለቱ ሳንተርናዮችን ይፈልጋሉ፣ በዚህም ውስጥ ትልቅ የኮርፋንስ ካርፓስ ቋንቋ ታናሽ ቋንቋ ለመፍጠር ይጠቀማል፣ ምናልባት ማስተምር ካርፓስ ወይም የፈተና ዳታ በመግለጽ ነው፡፡ በሁለት የመካከለኛዊ resource ቋንቋዎች ላይ በመጠቀም የኮርፌንስ ማስታወቂያውን በማድረግ፣ በሞሎልጋዊ መደገፊያ ምሳሌዎችን ማድረግ አግኝተናል፡፡ የስሕተት መልዕክቶችን ለመተማርከው የስህተት ክፍሎች የሚያስተምር፣ የአሁኑን መሣሪያዎች ትርጉም ዕቃዎች ጥሩ መጀመሪያ ግንኙነት ነው፡፡', 'af': "Groot aanmerkte korpora vir koreferensieresolusie is beskikbaar vir paar tale. Vir masjien vertaling, maar sterk swart- boks stelsels bestaan vir baie tale. Ons het empiriese uitprobeer die aangeroep idee om sodanige vertaling nutsprogramme te verwyder vir opstarting van koreferensieresolusie in tale met beperkte hulpbronne. Twee scenarios word analiseer, waarin 'n groot koreferensie korpus in 'n hoë-hulpbron taal gebruik word vir koreferensie voorskoude in 'n kleiner taal, t.d. deur masjien deur die oefening korpus of die toets data te vertaling. In ons empiriese evaluering van koreferensie-oplossing gebruik die twee scenarios op verskeie middelhulpbron tale, vind ons geen verbetering oor monolinglike basis-modelle nie. Ons analiseer van die verskillende bronne van fout onderwerp van die studieerde scenarios, vertel dat die kwaliteit van die huidige masjien vertaling nutsprogramme is die hoofbeperking faktor.", 'az': 'Nöqsanlıq çəkişməsi üçün böyük nöqsanlı korpora az dillər üçün faydalanır. Lakin maşın çevirilməsi üçün çox dillər üçün güclü siyah qutusu sistemləri var. Biz böyük tercümə vasitələrini müəyyən edilmiş məlumatları dillərin çətinliklərinə götürmək üçün istifadə edən fikrini keşfetmişik. İki scenario analiz edilir, orada yüksək ressurs dilində böyük bir korpus, kiçik dildə, yoxsa təhsil korpusu, yoxsa test verilən maşına ilə təhsil etmək üçün istifadə edilir. Biz bir çox orta ressurs dilində iki senaryoyu istifadə edərək mərhəmət çətinliklərinin impirik değerlendirməsində, monodil baz çətinliklərin modellərinin üstündə heç bir uzlaşma tapmırıq. Bizim analizimiz təhsil edilmiş scenariyaların müxtəlif xətaların mənbələrini göstərir ki, əslində müəyyən edilmiş maşın çeviri vasitələrinin keyfiyyəti əsas limiti faktorudur.', 'hy': 'Կորեֆերանսի լուծումների համար գոյություն ունի մի քանի լեզուների համար: Սակայն մեքենայի թարգմանման համար շատ լեզուների համար հզոր սև արկղի համակարգեր կան: We empirically explore the appealing idea of leveraging such translation tools for bootstrapping coreference resolution in languages with limited resources.  Երկու սցենարներ վերլուծում են, որտեղ բարձր ռեսուրսների լեզու մեծ կորեֆերանսի կորպուսը օգտագործվում է ավելի փոքր լեզվով կորեֆերանսի կանխատեսումների համար, այսինքն՝ մեքենայով թարգմանելով կամ մարզիչ կորպուսը, կամ թեստերի տվյալները: Մեր համալեզվի լուծումների էմպրիկական գնահատման արդյունքում, օգտագործելով միջին ռեսուրսների երկու սցենարները, մենք չենք գտնում զարգացում միալեզվի հիմնական մոդելների նկատմամբ: Մեր ուսումնասիրված սցենարների տարբեր աղբյուրների վերլուծությունը ցույց է տալիս, որ ժամանակակից մեքենայի թարգմանման գործիքների որակը հիմնական սահմանափակում է:', 'bn': 'কোরেফেন্সের সিদ্ধান্তের জন্য ব্যাপক কোর্পোরা কয়েকটি ভাষায় পাওয়া যাচ্ছে। মেশিন অনুবাদের জন্য, তবে অনেক ভাষার জন্য শক্তিশালী কালো বাক্স সিস্টেম রয়েছে। আমরা সীমিত সম্পদের সীমিত ভাষায় বুটস্ট্র্যাপিং কর্ফেন্স সিদ্ধান্তের মাধ্যমে এই ধরনের অনুবাদের টুল প্রদানের আপিলিক দুটি দৃশ্য বিশ্লেষণ করা হচ্ছে, যেখানে একটি উচ্চ সম্পদ ভাষায় একটি বিশাল কোরেফেন্স কোর্পাস ব্যবহার করা হচ্ছে সামান্য ভাষায়, যেমন মেশিন প্রশিক্ষণ কোর্পাস অথবা পরীক্ষ বেশ কয়েকটি মাধ্যম-সম্পদ ভাষায় দুটি দৃশ্যমান ব্যবহার করে আমাদের ক্ষমতার মূল্যের মাধ্যমে আমরা মোনোলিভাল ভাষার বেসাইন মডেলের উপর উন্নতি পা আমাদের বিভিন্ন ভুলের সূত্রের বিশ্লেষণ, যা গবেষণা করা হয়েছে সেগুলোর মধ্যে রয়েছে, তা প্রকাশ করেছে যে বর্তমান মেশিন অনুবাদের টুলসের মান হচ', 'bs': 'Velika annotirana korpora za rezoluciju pristojnosti je dostupna za nekoliko jezika. Međutim, za prevod mašine postoje jaki crne kutije za mnoge jezike. Mi empirički istražujemo privlačnu ideju o utjecavanju takvih alata za prevod za rješavanje odgovarajućih mjera na jezicima s ograničenim resursima. Analizirani su dva scenarija, u kojem se koristi veliki korpus dobrodošlosti na jeziku visokog resursa za predviđanje dobrodošlosti na manjom jeziku, tj. strojem koji prevodi ili korpus treninga ili test podataka. U našem empiričkom procjenu rezolucije pristojnosti koristeći dva scenarija na nekoliko srednjih jezika resursa, mi ne pronađemo poboljšanje nad monojezičkim početnim modelima. Naša analiza različitih izvora greške koje sadrže ispitivane scenarije pokazuje da je u stvari kvalitet savremenih alata za prevod mašine glavni ograničavajući faktor.', 'ca': "Els grans corpores anotats per a resoldre les referències són disponibles en poques llengües. For machine translation, however, strong black-box systems exist for many languages.  Explorem empíricament la idea atractiva d'utilitzar aquestes eines de traducció per a arrancar la resolució de coreferencia en llengües amb recursos limitats. S'analitzen dos escenaris, en els quals un gran cos de coreferència en un llenguatge d'alt recurso s'utilitza per predir coreferència en un llenguatge més petit, és a dir, per traduir la màquina o el cos d'entrenament o les dades de prova. In our empirical evaluation of coreference resolution using the two scenarios on several medium-resource languages, we find no improvement over monolingual baseline models.  La nostra anàlisi de les diverses fonts d'error inherents a les escenaris estudiates revela que, de fet, la qualitat de les eines contemporanes de traducció màquina és el principal factor limitador.", 'cs': 'Velké anotované korpusy pro rozlišení koreference jsou k dispozici pro několik jazyků. Pro strojový překlad však existují silné systémy černé skříňky pro mnoho jazyků. Empiricky zkoumáme atraktivní myšlenku využití takových překladových nástrojů pro bootstrapping coreference řešení v jazycích s omezenými zdroji. Jsou analyzovány dva scénáře, ve kterých je velký korpus koreference v jazyce s vysokými zdroji použit pro predikci koreference v menším jazyce, tj. strojovým překladem buď tréninkového korpusu nebo testovacích dat. V našem empirickém hodnocení koreferenčního řešení pomocí dvou scénářů na několika jazycích se středními zdroji nenašli žádné zlepšení oproti monojazyčným základním modelům. Naše analýza různých zdrojů chyb, které jsou součástí zkoumaných scénářů, ukazuje, že hlavním limitujícím faktorem je ve skutečnosti kvalita současných strojových překladů.', 'fi': 'Suuria annotoituja korpusia koreoferenssin resoluutiota varten on saatavilla muutamalle kielelle. Konekäännöksen osalta on kuitenkin olemassa vahvoja mustan laatikon järjestelmiä monille kielille. Tutkimme empiirisesti houkuttelevaa ajatusta hyödyntää tällaisia käännöstyökaluja koreferenssiresoluution käynnistämiseen kielillä, joilla on rajalliset resurssit. Analysoidaan kahta skenaariota, joissa suurta koreferenssikorpusta käytetään koreferenssiennusteisiin pienemmällä kielellä eli konekääntämällä joko koulutuskorpus tai testiaineisto. Kokeellisessa arviossamme koreferenssiresoluutiosta käyttäen kahta skenaariota useilla keskiresursseilla käytetyillä kielillä emme löydä parannusta yksikielisiin perusmalleihin. Analyysimme eri skenaarioihin liittyvistä virheiden lähteistä paljastaa, että nykyajan konekäännöstyökalujen laatu on itse asiassa tärkein rajoittava tekijä.', 'et': 'Suured anoteeritud korpused kortereferentsi eraldusvõime jaoks on saadaval mõnes keeles. Masintõlke puhul on paljudes keeltes siiski olemas tugevad musta kasti süsteemid. Me uurime empiiriliselt ahvatlevat ideed selliste tõlketööriistade kasutamise kasutamiseks koreferensi lahenduse alustamiseks piiratud ressurssidega keeltes. Analüüsitakse kahte stsenaariumi, kus väiksemas keeles kasutatakse suurt koreference korpust, st masintõlkides kas koolituskorpust või katseandmeid. Meie empiirilises hindamises koreferensi resolutsiooni kohta, kasutades kahte stsenaariumi mitme keskmise ressursiga keele puhul, ei leitud me ühekeelsete baasmudelitega võrreldes paranemist. Uuritud stsenaariumidele omaste erinevate vigaallikate analüüs näitab, et tegelikult on peamine piirav tegur kaasaegsete masintõlke tööriistade kvaliteet.', 'jv': 'politenessoffpolite"), and when there is a change ("assertive Nanging, njuk-njuk saben ditambahak kelas-iwak kanggo saben basa. Awak dhéwé éntuk kebuturan nggawe barang nggawe barang-alat kanggo nggawe gerakan tarjamahan kanggo nggawe gerakan karo perusahaan sing nggawe Seneng alih sing dipunangé, ning langgampun bener Nang dhéwé éntukno empirrikal sing nggawe geranggé nggawe geranggé karo nggawe sistem sing duwé ning langgambar medium-Resolusi, kéné ora luwih akeh operasi ning model sing basa bangsane. Ndoleh awak dhéwé karo perkoro sing gak bener tentang kanggo ngerasah seneng pisan sing bisa diujaraké, nggarap kuwi nggawe barang nggawe barang kelas kuwi karo perusahaan karo perusahaan sing nguasai nggawe', 'ha': "QXml @ info: whatsthis Tuna ƙididdige idãnar rufaffiyar da za'a gajiya zance-fassar kamar wannan na fassarar-zance da za'a yi amfani da yin tafiyar da rabon-kure-kure cikin lugha da maɓallin haske. Ana Ana Ana yi fassara biyu, a cikinsa, akwai amfani da kure mai girma cikin lugha na sarki, kuma ana yi amfani da wa'azi ga bashirin littafan korfence da ke ƙaranci, misali, da fassarar mashine ta fassara ko kuma da data na jarraba. Ina iya ƙaddara wa rabon sarrafiya, da amfani da fasarin biyu a kan lugha masu tsakanin-resource, ba mu sãmi wani gyãra ba kan misalin misalin misalin mutane. Ana fassararmu ga manyan ɓata cikin kwanan nan da aka karanta, yana bayyana cewa, sifar da zanen fassarori na cikin maɓallin ayuka da ke buƙata yanzu, shi ne babban fakta mai ƙayyade.", 'sk': 'Veliki korpusi z oznakami za ločljivost korekcije korekcije so na voljo za nekaj jezikov. Za strojno prevajanje pa obstajajo močni sistemi črnih škatlic za številne jezike. Empirično raziskujemo privlačno idejo uporabe takšnih prevajalskih orodij za zagonsko ločljivost koreference v jezikih z omejenimi viri. Analizirana sta dva scenarija, v katerih se za napovedi koreference v manjšem jeziku uporablja velik koreferenčni korpus v jeziku z visokimi viri, tj. s strojnim prevajanjem bodisi korpusa usposabljanja bodisi testnih podatkov. V naši empirični oceni ločljivosti koreference z uporabo obeh scenarijev v več jezikih srednjih virov ne najdemo izboljšav v primerjavi z enojezičnimi osnovnimi modeli. Naša analiza različnih virov napak, ki so značilni za preučevane scenarije, kaže, da je pravzaprav kakovost sodobnih strojnih prevajalskih orodij glavni omejevalni dejavnik.', 'he': 'גופורה גדולה מועטפת לפתרון התאמה זמינה לכמה שפות. למרות זאת, לתרגום מכונות, מערכות שחורות חזקות קיימות לשפות רבות. אנו חוקרים באימפריקה את הרעיון המתוקף של השימוש כלי תרגום כאלה לפתור את הפתרון הגבוה בשפות עם משאבים מוגבלים. שני תרחישים ניתוחים, שבהם קורפוס גבוה בתוך שפת משאבים גבוהה משתמש לחזויות מתוך שפת קטנה יותר, כלומר על ידי מכונת שתרגם את קורפוס האימון או את נתוני הבדיקה. בהערכה האמפרית שלנו של פתרון התאמה באמצעות שני התקרים על כמה שפות משאבים בינוניים, אנחנו לא מוצאים שיפור מעל דוגמנים בסיסיים מונולשונים. הניתוח שלנו על המקורים השונים של טעות הנכונים לתסריטים המחקרים, מגלה שבאמת איכות כלי התרגום המכונה contemporary הוא גורם המגביל הראשי.', 'bo': 'སྐད་རིགས་ཉུང་ཅིག་ལ་སྤྱོད་པའི་གནད་དོན་འགྱུར་བ་ཁང་ཆེ་བ། ཡིན་ནའང་། མ་ལག་གི་སྐད་རིགས་མང་པོ་ཞིག་ལ་མཚུངས་ཡིན། ང་ཚོས་སྐད་ཡིག་ཆ་དང་ཆུང་ཚད་ལྡན་པའི་སྐད་ཡིག སྐད་ཡིག་ཆ་མཐོ་བོ་ཞིག་ཡོད་པའི་ནང་དུ་མཐུན་རིམ་པ་ཞིག་གིས་མཐུན་རྐྱེན་ཅན་ཞིག ང་ཚོའི་དབང་ཆ་མཐོང་གི་ཐབས་ལམ་ནང་དུ་མཐུན་རིམ་སྒྲིག་གི་ཐབས་ལམ་གཉིས་ཀྱི་ཆ་རྐྱེན་གྱི་སྐད་རིགས་ཤིག་དང་། ང་ཚོའི་སྐད་ཡིག་གནས་ཚུལ་ ང་ཚོའི་ལྟ་བུའི་ནང་དུ་ནོར་འཁྲུལ་གྱི་འབྱུང་ཁུངས་འདྲ་ཞིག་ཡོད་པའི་དབྱེ་ཞིབ'}
{'en': 'CoreLM : Coreference-aware Language Model Fine-Tuning', 'es': 'CoreLM: ajuste fino del modelo de lenguaje compatible con Coreference', 'fr': 'CorelM\xa0: réglage fin du modèle de langage compatible avec Coreference', 'ar': 'CoreLM: التوليف الدقيق لنموذج اللغة مع مراعاة Coreference', 'pt': 'CoreLM: ajuste fino do modelo de linguagem com reconhecimento de correferência', 'hi': 'CoreLM: Coreference-जागरूक भाषा मॉडल ठीक ट्यूनिंग', 'zh': 'CoreLM曰:Coreference 知言语', 'ja': 'CoreLM: Coreference - awareness Language Model Fine - Tuning', 'ru': 'CoreLM: Точная настройка базовой языковой модели', 'ga': 'CoreLM: Mionchoigeartú Samhail Teanga atá feasach ar chroílár', 'ka': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'el': 'CoreLM: Εκσυγχρονισμός γλωσσικού μοντέλου με γνώμονα την συνάφεια', 'hu': 'CoreLM: Coreferencia-tudatos nyelvi modell finomhangolása', 'it': 'CoreLM: Sintonizzazione fine del modello linguistico consapevole della coreferenza', 'lt': 'Pagrindinis LM: nuodugniai pritaikytas kalbos modelis, žinomas apie koreferenciją', 'kk': 'Негізгі LM: Тіл үлгісін баптау үлгісі', 'ms': 'CoreLM: Penyesuaian Model Bahasa yang sedar-samaran', 'mk': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'ml': 'കോര്\u200dഎല്\u200d: കോര്\u200dഫെന്\u200dസ്- വിവരമുള്ള ഭാഷ മോഡല്\u200d ഫൈന്\u200d- ട്യൂണിങ്ങ്', 'mt': 'CoreLM: Mudell tal-Lingwa ta’ Aġġustament Irfinat li jaf il-Koreferenza', 'mn': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'no': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'pl': 'CoreLM: Dostosowanie modelu językowego świadomego koreferencji', 'ro': 'CoreLM: Coreference-conștient de modelul lingvistic fin-tuning', 'sr': 'KoreLM: Fine-Tuning jezički model svestan sa koreferencijom', 'so': 'CoreLM: Koreference-aware Language Model Fine-Tuning', 'ta': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'si': 'CoreLM: Core Reference-Known language Model Fine-Tuning', 'sv': 'CoreLM: Coreference-medveten språkmodell finjustering', 'ur': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'uz': 'Name', 'vi': 'CoreLM: Coreference-knowledge Language Model fine-tuning', 'hr': 'CoreLM: Fine-Tuning jezički model poznat s korisnošću', 'bg': 'CoreLM: Финно настройване на езиковия модел, осъзнаващ кореференцията', 'da': 'CoreLM: Coreference-bevidst sprogmodel finjustering', 'nl': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'de': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'id': 'CoreLM: Pengaturan Model Bahasa yang menyadari kebenaran', 'fa': 'CoreLM: Model Fine-Tuning Language', 'ko': 'CoreLM: 공동 참조를 지원하는 언어 모델 미세 조정', 'af': 'CoreLM: Coreference-aware Taal Model Fine-Tuning', 'sq': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'tr': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'sw': 'CoreLM: Utamaduni wa Lugha inayofahamika', 'hy': 'LM: Կորեֆերանսի գիտակցած լեզվի մոդել Fine-Tuning', 'am': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'bs': 'CoreLM: Fine-Tuning jezički model svjestan korisnosti', 'az': 'CoreLM: Coreference-aware Dil Model Fine-Tuning', 'ca': 'CoreLM: Correlació del model de llenguatge conscient de la coreferència', 'bn': 'কোরেএলএম: কোরেফেন্স- পরিচিত ভাষা মোডেল ফিন- টিউনিং', 'cs': 'CoreLM: Jemné ladění jazykového modelu s ohledem na Coreference', 'et': 'CoreLM: Coreference-teadlik keelemudel Fine-Tuning', 'fi': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'jv': 'coreLM: corefern-awake Language model Fine-Tuning', 'he': 'CoreLM: Coreference-aware Language Model Fine-Tuning', 'ha': 'KCharselect unicode block name', 'sk': 'CoreLM: fino nastavitev jezikovnega modela, ki se zaveda Coreference', 'bo': 'CoreLM: Coreference-aware Language Model Fine-Tuning'}
{'en': 'Language Models are the underpin of all modern Natural Language Processing (NLP) tasks. The introduction of the Transformers architecture has contributed significantly into making ', 'pt': 'Os Modelos de Linguagem são a base de todas as tarefas modernas de Processamento de Linguagem Natural (NLP). A introdução da arquitetura Transformers contribuiu significativamente para tornar a Modelagem de Linguagem muito eficaz em muitas tarefas de PNL, levando a avanços significativos no campo. No entanto, os Transformadores apresentam um grande custo computacional, que cresce quadraticamente em relação ao comprimento de entrada. Isso apresenta um desafio, pois entender textos longos requer muito contexto. Neste artigo, propomos uma estrutura de ajuste fino, chamada CoreLM, que estende a arquitetura dos atuais modelos de linguagem pré-treinados para que eles incorporem informações de entidade explícitas. Ao introduzir representações de entidade, disponibilizamos informações fora do espaço contextual do modelo, o que resulta em um Modelo de Linguagem melhor por uma fração do custo computacional. Implementamos nossa abordagem usando GPT2 e comparamos o modelo ajustado com o original. Nosso modelo proposto alcança uma perplexidade menor nos conjuntos de dados GUMBY e LAMBDADA quando comparado ao GPT2 e uma versão ajustada do GPT2 sem nenhuma alteração. Também comparamos o desempenho dos modelos em termos de Acurácia no LAMBADA e no Teste do Livro Infantil, com e sem o uso de anotações de correferência criadas pelo modelo.', 'fr': "Les modèles linguistiques sont la base de toutes les tâches modernes de traitement du langage naturel (NLP). L'introduction de l'architecture Transformers a contribué de manière significative à rendre la modélisation du langage très efficace pour de nombreuses tâches de PNL, menant à des avancées significatives dans le domaine. Cependant, les transformateurs ont un coût de calcul élevé, qui augmente de façon quadratique par rapport à la longueur d'entrée. Cela représente un défi car comprendre de longs textes nécessite beaucoup de contexte. Dans cet article, nous proposons un cadre de réglage fin, appelé CorelM, qui étend l'architecture des modèles de langage préentraînés actuels afin qu'ils intègrent des informations explicites sur les entités. En introduisant des représentations d'entités, nous mettons à disposition des informations en dehors de l'espace contextuel du modèle, ce qui permet d'obtenir un meilleur modèle de langage pour une fraction du coût de calcul. Nous mettons en œuvre notre approche à l'aide de GPT2 et comparons le modèle affiné au modèle original. Le modèle que nous proposons permet d'obtenir une plus faible perplexité dans les ensembles de données GUMBY et LAMBDADA par rapport à GPT2 et à une version affinée de GPT2 sans aucune modification. Nous comparons également les performances des modèles en termes de précision dans LAMBADA et Children's Book Test, avec et sans l'utilisation d'annotations de coréférence créées par le modèle.", 'ar': 'نماذج اللغة هي الدعامة الأساسية لجميع مهام معالجة اللغة الطبيعية الحديثة (NLP). ساهم إدخال هندسة المحولات بشكل كبير في جعل نمذجة اللغة فعالة للغاية عبر العديد من مهام البرمجة اللغوية العصبية ، مما أدى إلى تقدم كبير في هذا المجال. ومع ذلك ، تأتي المحولات بتكلفة حسابية كبيرة ، والتي تنمو بشكل تربيعي فيما يتعلق بطول الإدخال. يمثل هذا تحديًا لأن فهم النصوص الطويلة يتطلب الكثير من السياق. في هذه الورقة ، نقترح إطار عمل ضبط دقيق ، يسمى CoreLM ، يوسع بنية نماذج اللغة سابقة التدريب الحالية بحيث تتضمن معلومات كيان صريحة. من خلال تقديم تمثيلات الكيانات ، فإننا نوفر المعلومات خارج المساحة السياقية للنموذج ، مما ينتج عنه نموذج لغوي أفضل لجزء بسيط من التكلفة الحسابية. ننفذ نهجنا باستخدام GPT2 ونقارن النموذج الدقيق بالنموذج الأصلي. يحقق نموذجنا المقترح قدرًا أقل من الارتباك في مجموعات بيانات GUMBY و LAMBDADA عند مقارنته بـ GPT2 وإصدار مُحسَّن من GPT2 دون أي تغييرات. نقوم أيضًا بمقارنة أداء النماذج من حيث الدقة في LAMBADA واختبار كتاب الأطفال ، مع استخدام التعليقات التوضيحية المرجعية التي تم إنشاؤها بواسطة النموذج وبدونها.', 'es': 'Los modelos de lenguaje son la base de todas las tareas modernas de procesamiento del lenguaje natural (NLP). La introducción de la arquitectura Transformers ha contribuido significativamente a que el modelado del lenguaje sea muy eficaz en muchas tareas de PNL, lo que ha llevado a avances significativos en el campo. Sin embargo, los Transformers tienen un gran costo computacional, que crece cuadráticamente con respecto a la longitud de entrada. Esto presenta un desafío, ya que entender textos largos requiere mucho contexto. En este artículo, proponemos un marco de ajuste fino, denominado CoreLM, que amplía la arquitectura de los modelos lingüísticos preentrenados actuales para que incorporen información explícita de la entidad. Al introducir representaciones de entidades, ponemos a disposición la información fuera del espacio contextual del modelo, lo que da como resultado un mejor Modelo de Lenguaje por una fracción del costo computacional. Implementamos nuestro enfoque utilizando GPT2 y comparamos el modelo ajustado con el original. Nuestro modelo propuesto logra una perplejidad más baja en los conjuntos de datos GUMBY y LAMBDADA en comparación con GPT2 y una versión ajustada de GPT2 sin ningún cambio. También comparamos el rendimiento de los modelos en términos de Precisión en LAMBADA y Prueba del Libro Infantil, con y sin el uso de anotaciones de correferencia creadas por el modelo.', 'zh': '言语模形,凡今世自然语言治(NLP)之本也。 Transformers架构引入为使言建模多NLP效重大贡献,取重大进展域中。 然Transformers有大计算成本,相对输长,当成本二长。 此一挑战,解长文须大上下文也。 本文有CoreLM调框架,当框架广其预训语形之体系结构,以包显式体信息。 入实体者,上下文空间之外,以小计算成本得善言。 吾用 GPT2 成吾法,以微调比于始。 比GPT2、GPT2之微调版本,则GUMBY、LAMBDADA数集于下,无所变更。 较之 LAMBADA 童图书之准确性,无论共指注。', 'ja': "言語モデルは、すべての現代の自然言語処理（ NLP ）タスクの基盤です。 Transformersアーキテクチャの導入は、多くのNLPタスクで言語モデリングを非常に効果的にすることに大きく貢献し、この分野で大きな進歩をもたらしました。 しかし、変圧器には大きな計算コストがかかり、入力の長さに対して二次的に成長します。 これは、長いテキストを理解するには多くの文脈が必要であるという課題を提示している。 この論文では、現在の事前訓練された言語モデルのアーキテクチャを拡張して、明示的なエンティティ情報を組み込むように、CoreLMと名付けられたファインチューニングフレームワークを提案する。 エンティティ表現を導入することで、モデルのコンテキスト空間外で利用可能な情報を提供し、計算コストのほんの一部でより良い言語モデルをもたらします。 GPT 2を使用してアプローチを実装し、微調整されたモデルを元のモデルと比較します。 提案されたモデルは、GPT 2と比較して、GumbyおよびLAMBDADAデータセットにおけるより低いPerplexityを達成し、GPT 2の微調整されたバージョンを変更することなく達成します。 また、モデル作成のコアレファレンスアノテーションを使用しているかどうかにかかわらず、LambadaとChildren 's Book Testの精度の観点からモデルのパフォーマンスを比較します。", 'hi': 'भाषा मॉडल सभी आधुनिक प्राकृतिक भाषा प्रसंस्करण (एनएलपी) कार्यों के आधार हैं। ट्रांसफॉर्मर आर्किटेक्चर की शुरूआत ने भाषा मॉडलिंग को कई एनएलपी कार्यों में बहुत प्रभावी बनाने में महत्वपूर्ण योगदान दिया है, जिससे क्षेत्र में महत्वपूर्ण प्रगति हुई है। हालांकि, ट्रांसफॉर्मर एक बड़ी कम्प्यूटेशनल लागत के साथ आते हैं, जो इनपुट लंबाई के संबंध में द्विघाती रूप से बढ़ता है। यह लंबे ग्रंथों को समझने के लिए एक चुनौती प्रस्तुत करता है, जिसके लिए बहुत सारे संदर्भ की आवश्यकता होती है। इस पेपर में, हम एक फाइन-ट्यूनिंग फ्रेमवर्क का प्रस्ताव करते हैं, जिसका नाम कोरएलएम है, जो वर्तमान प्रीट्रेन्ड लैंग्वेज मॉडल की वास्तुकला का विस्तार करता है ताकि वे स्पष्ट इकाई जानकारी को शामिल कर सकें। एंटिटी अभ्यावेदन पेश करके, हम मॉडल के प्रासंगिक स्थान के बाहर जानकारी उपलब्ध कराते हैं, जिसके परिणामस्वरूप कम्प्यूटेशनल लागत के एक अंश के लिए एक बेहतर भाषा मॉडल होता है। हम GPT2 का उपयोग करके अपने दृष्टिकोण को लागू करते हैं और मूल से ठीक-ठाक मॉडल की तुलना करते हैं। हमारा प्रस्तावित मॉडल GPT2 की तुलना में GUMBY और LAMBDADA डेटासेट में कम उलझन प्राप्त करता है और बिना किसी परिवर्तन के GPT2 का एक ठीक-ठाक संस्करण प्राप्त करता है। हम लैम्बाडा और चिल्ड्रन बुक टेस्ट में सटीकता के संदर्भ में मॉडल के प्रदर्शन की तुलना भी करते हैं, मॉडल-निर्मित कोरेफेरेंस एनोटेशन के उपयोग के साथ और बिना।', 'ru': 'Языковые модели являются основой всех современных задач по обработке естественного языка (NLP). Внедрение архитектуры Transformers значительно способствовало тому, что языковое моделирование стало очень эффективным во многих задачах NLP, что привело к значительным достижениям в данной области. Однако трансформаторы имеют большую вычислительную стоимость, которая растет квадратично по отношению к входной длине. Это ставит задачу понять, что длинные тексты требуют много контекста. В этой статье мы предлагаем фреймворк Fine-Tuning, называемый CoreLM, который расширяет архитектуру текущих предварительно обученных языковых моделей, чтобы они включали явную информацию о сущностях. Внедряя представления сущностей, мы делаем доступной информацию за пределами контекстного пространства модели, что приводит к лучшей языковой модели для части вычислительной стоимости. Мы реализуем наш подход с помощью GPT2 и сравниваем доработанную модель с оригиналом. Наша предлагаемая модель достигает более низкой степени смятения в наборах данных GUMBY и LAMBDADA по сравнению с GPT2 и тонкой версией GPT2 без каких-либо изменений. Мы также сравниваем эффективность моделей с точки зрения точности в LAMBADA и теста детской книги с использованием и без использования аннотаций, созданных моделью.', 'ga': 'Tá Múnlaí Teanga mar bhonn agus mar thaca ag gach tasc nua-aimseartha um Phróiseáil Teanga Nádúrtha (NLP). Chuir tabhairt isteach ailtireacht na gClaochladáin go mór le Samhaltú Teanga a dhéanamh an-éifeachtach thar go leor tascanna NLP, rud a d’fhág go bhfuil dul chun cinn suntasach sa réimse. Mar sin féin, tagann Claochladáin le costas ríomhaireachtúil mór, a fhásann go cearnach i leith an fad ionchuir. Cruthaíonn sé seo dúshlán mar go dteastaíonn go leor comhthéacs chun téacsanna fada a thuiscint. Sa pháipéar seo, molaimid creat Mionchoigeartaithe, darb ainm CoreLM, a leathnaíonn ailtireacht na Múnlaí Teanga Réamhoilte ionas go n-ionchorpraítear iontu faisnéis shainráite aonáin. Trí léiriú aonáin a thabhairt isteach, cuirimid faisnéis ar fáil lasmuigh de spás comhthéacsúil na samhla, rud a fhágann go mbeidh Múnla Teanga níos fearr ann do chodán den chostas ríomhaireachta. Cuirimid ár gcur chuige i bhfeidhm ag baint úsáide as GPT2 agus cuirimid an tsamhail mhionchoigeartaithe i gcomparáid leis an múnla bunaidh. Baineann an tsamhail atá beartaithe againn amach Perplexity níos ísle i dtacar sonraí GUMBY agus LAMBDADA i gcomparáid le GPT2 agus leagan mionchoigeartaithe de GPT2 gan aon athruithe. Déanaimid comparáid freisin maidir le feidhmíocht na múnlaí ó thaobh Cruinneas i LAMBADA agus i dTriail Leabhar na bPáistí, le agus gan úsáid a bhaint as nótaí croíchomhdhála a chruthaítear sa tsamhail.', 'it': "I modelli linguistici sono la base di tutti i moderni compiti di elaborazione del linguaggio naturale (NLP). L'introduzione dell'architettura Transformers ha contribuito in modo significativo a rendere il Language Modeling molto efficace in molte attività NLP, portando a significativi progressi nel campo. Tuttavia, i Transformers hanno un grande costo computazionale, che cresce quadraticamente rispetto alla lunghezza di input. Questo rappresenta una sfida in quanto comprendere testi lunghi richiede molto contesto. In questo articolo, proponiamo un framework Fine-Tuning, denominato CoreLM, che estende l'architettura degli attuali modelli linguistici pretrained in modo che incorporano informazioni esplicite sull'entità. Introducendo rappresentazioni di entità, rendiamo disponibili le informazioni al di fuori dello spazio contestuale del modello, il che si traduce in un modello linguistico migliore per una frazione del costo computazionale. Implementiamo il nostro approccio utilizzando GPT2 e confrontiamo il modello perfezionato con l'originale. Il nostro modello proposto raggiunge una minore Perplexity nei dataset GUMBY e LAMBDADA rispetto al GPT2 e una versione perfezionata di GPT2 senza modifiche. Confrontiamo anche le prestazioni dei modelli in termini di accuratezza in LAMBADA e Children's Book Test, con e senza l'uso di annotazioni di coreferenza create dal modello.", 'ka': 'ენის მოდელები ყველა მოდირებული ენერგიის პროცესის (NLP) დასაწყებელია. ტრანფორმეტრის არქტიქტურის შესახებ ძალიან მნიშვნელოვანია ენის მოდელირებაში მნიშვნელოვანი NLP დავალების შესახებ, რომელიც მნიშვნელოვანი პროგრამების გარეშე. მაგრამ, ტრანფორმაციელი დიდი კომპუტაციონალური ღირებებით, რომელიც კვადრატიკურად იზრდება ჩასვლის სიგრძე. ეს გამოსახულება, რომელიც ძლიერი ტექსტის გაგრძნობა უფრო მნიშვნელოვანია. ამ დოკუნეში ჩვენ მივიღებთ კონფინური კონფინური კონფიგურაცია, სახელი CoreLM, რომელიც მიმდინარე სახელის მსოფლიო ენის მოდელების არქტიქტურაციას გაფართებს, რომ ისინი გამოყენ ინტერტის გამოსახულებების შესახებ, ჩვენ მოდელის კონტექსტური სივრცე გარეშე ინფორმაციას გავაკეთებთ, რომელიც კონტექსტური სივრცე მოდელის უკეთესი ენის მოდელის გარე ჩვენ GPT2 გამოყენებთ ჩვენი პროგრამა და გამოყენებთ მარტივი მოდელს ორიგინალზე. ჩვენი მოდულის მოდელი GUMBY და LAMBDADA მონაცემების დამატებით, როდესაც GPT2 და GPT2-ის კონფიგურაციული ვერსია არაფერი ცვლილების შემდეგ დაიწყება. ჩვენ ასევე მოდელების გამოყენებას LAMBADA და ბავშვების წიგნის ტესტის წიგნის შესახებ და გამოყენება მოდელს შექმნილი წიგნის წიგნის შესახებ.', 'hu': 'A nyelvi modellek az összes modern Natural Language Processing (NLP) feladat alapját képezik. A Transformers architektúra bevezetése jelentősen hozzájárult ahhoz, hogy a nyelvi modellezés nagyon hatékony legyen számos NLP feladatban, ami jelentős fejlődést eredményezett a területen. A transzformátorok azonban nagy számítási költségekkel járnak, amelyek négyszázalékos mértékben nőnek a bemeneti hosszúsághoz képest. Ez kihívást jelent, mivel a hosszú szövegek megértése sok kontextust igényel. Ebben a tanulmányban egy CoreLM nevű finomhangolási keretrendszert javasolunk, amely kiterjeszti a jelenlegi előzetes nyelvi modellek architektúráját úgy, hogy azok magukban foglalják a kifejezett entitási információkat. Az entitások reprezentációjának bevezetésével a modell kontextuális terén kívül elérhetővé tesszük az információkat, ami jobb nyelvi modellt eredményez a számítási költség töredékéért. Megközelítésünket GPT2 segítségével hajtjuk végre, és összehasonlítjuk a finomhangolt modellt az eredetihez. Javasolt modellünk változtatás nélkül alacsonyabb Perplexitást ér el a GUMBY és LAMBDADA adatkészletekben a GPT2-hez képest és a GPT2 finomhangolt verziójához képest. Összehasonlítjuk a modellek teljesítményét a LAMBADA és a gyermekkönyvteszt pontossága tekintetében, modellek által létrehozott coreferencia jegyzetek használatával és anélkül.', 'kk': 'Тіл үлгілері - бүкіл қазіргі Түзіндік тіл процессорының (NLP) тапсырмаларының астындағы. Түрлендіруші архитектурасының кіріспесі тіл үлгісін NLP тапсырмасының көпшілігіне көп ең эффективні жасау үшін көмектеседі. Ол өрісте маңызды жақсартылып Бірақ түрлендірушілер квадратикалық түрлендіру ұзындығына қарай үлкен есептеу бағасы бар. Бұл ұзын мәтіндерді түсіну үшін көп контексті талап етеді. Бұл қағазда CoreLM деп аталатын "Fine-Tuning" қоршауын таңдаймыз. Бұл қағазда назардағы "Pretrained Language Models" үлгілерінің архитектурасын кеңейту үшін оның түсінікті мәліметін қосу үшін. Біріктерді таңдау арқылы, біз үлгісінің контексті орындың сыртында мәліметтерді таңдаймыз. Бұл компьютер бағасының бөлшегін жақсы тіл үлгісі үшін жақсы болады. Біз GPT2 арқылымызды іске асырып, жақсы бапталған үлгісін бастапқы үлгілерімен салыстырып көрдік. Біздің келтірілген үлгіміз GUMBY және LAMBDADA деректер қорларында GPT2 және GPT2 нұсқасы кез-келген өзгерістерімен салыстырғанда төмен Perplexity дегенді жеткізеді. Мұндай-ақ, LAMBADA және Балалардың кітапшасының сынақтарында үлгілердің дайындылығын, үлгілерді құрылған мәселелердің жаңалықтарын қолданбаған және қолданбаған түрде салыстырып тұрмыз.', 'el': 'Τα γλωσσικά μοντέλα αποτελούν το θεμέλιο όλων των σύγχρονων εργασιών επεξεργασίας φυσικής γλώσσας. Η εισαγωγή της αρχιτεκτονικής έχει συμβάλει σημαντικά στο να καταστεί η μοντελοποίηση γλωσσών πολύ αποτελεσματική σε πολλές εργασίες, οδηγώντας σε σημαντικές εξελίξεις στον τομέα. Ωστόσο, οι μετασχηματιστές έρχονται με ένα μεγάλο υπολογιστικό κόστος, το οποίο αυξάνεται τετραδιάστατα σε σχέση με το μήκος εισόδου. Αυτό αποτελεί πρόκληση καθώς η κατανόηση μεγάλων κειμένων απαιτεί πολύ πλαίσιο. Στην παρούσα εργασία, προτείνουμε ένα πλαίσιο λεπτής ρύθμισης, που ονομάζεται το οποίο επεκτείνει την αρχιτεκτονική των σημερινών Προκατασκευασμένων Γλωσσικών Μοντέλων έτσι ώστε να ενσωματώνουν ρητές πληροφορίες οντότητας. Με την εισαγωγή αναπαραστάσεων οντοτήτων, κάνουμε διαθέσιμες πληροφορίες εκτός του περιβάλλοντος χώρου του μοντέλου, γεγονός που έχει ως αποτέλεσμα ένα καλύτερο γλωσσικό μοντέλο για ένα κλάσμα του υπολογιστικού κόστους. Εφαρμόζουμε την προσέγγισή μας χρησιμοποιώντας και συγκρίνουμε το εκλεπτυσμένο μοντέλο με το πρωτότυπο. Το προτεινόμενο μοντέλο επιτυγχάνει χαμηλότερη Perplexity στα σύνολα δεδομένων GUMBY και LAMBDADA σε σύγκριση με το GPT2 και μια εκλεπτυσμένη έκδοση του GPT2 χωρίς αλλαγές. Επίσης συγκρίνουμε τις επιδόσεις των μοντέλων όσον αφορά την ακρίβεια στο τεστ και το παιδικό βιβλίο, με και χωρίς τη χρήση σχολίων που δημιουργούνται από μοντέλα.', 'ml': 'ഭാഷ മോഡലുകള്\u200d ആധുനിക സ്വാഭാവിക ഭാഷ പ്രവര്\u200dത്തനങ്ങളുടെ (NLP) പ്രവര്\u200dത്തനങ്ങളുടെ അടിപ്പിനാണ്. ട്രാന്\u200dസ്ഫോര്\u200dഫര്\u200dമാര്\u200d ആര്\u200dക്ടിക്കേറ്റര്\u200d പരിചയപ്പെടുത്തുന്നത് ഭാഷ മോഡില്\u200d വളരെ പ്രധാനപ്പെട്ടതാക്കുന്നു എന്\u200dഎല്\u200dപി ജോലിയില്\u200d മു എങ്കിലും ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d വലിയ കണക്കൂട്ടികൊണ്ട് വന്നിരിക്കുന്നു. അത് ഇന്\u200dപുട്ടിന്\u200dറെ നീളം ക്വാഡ്രാക് നീണ്ട ട ടെക്സ്റ്റുകള്\u200d മനസ്സിലാക്കുന്നതിനാല്\u200d ഇത് ഒരു വ്യാല്\u200dച്ചല്\u200d കൊണ്ടുവരുന്നു. ഈ പത്രത്തില്\u200d നമ്മള്\u200d കൊരെല്\u200dഎം എന്ന പേരുള്ള ഒരു നല്ല ട്യൂണിങ്ങിങ് ഫ്രെയിമെക്ക് പ്രായണം ചെയ്യുന്നു. അത് ഇപ്പോഴത്തെ പരിശീലന ഭാഷ മോഡേലുകള വസ്തുവിന്റെ പ്രതിനിധികളെ പരിചയപ്പെടുത്തുന്നതിനാല്\u200d, മോഡലിന്റെ നിലവിലുള്ള സ്ഥലത്തിനു പുറത്തുള്ള വിവരങ്ങള്\u200d ഞങ്ങള്\u200d ലഭ്യമാക്കു ഞങ്ങള്\u200d ജിപിടി2 ഉപയോഗിച്ച് നമ്മുടെ നടപടി പ്രവര്\u200dത്തിപ്പിക്കുന്നു. പിന്നെ നമ്മുടെ മോഡലിനെ ആദ്യത്തിലേ ഞങ്ങളുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്\u200d ജിപിടി2യോടും ഒരു മാറ്റങ്ങള്\u200dക്കുമില്ലാതെ ഗുബ്ബിയിലും ലാബ്ദാഡ ഡ ഡാറ്റാസറ്റിലും കുറച്ച് പെ ലാമ്പേഡായും കുട്ടികളുടെ ബുക്കിന്\u200dറെ പരീക്ഷണത്തിലും നാം മോഡലുകളുടെ പ്രദര്\u200dശനത്തെ താല്\u200dക്കാലികമാക്കുന്നു. മോഡല്\u200d സൃഷ്ടിച്ച കോര്\u200d', 'mk': 'Моделите на јазик се основата на сите модерни задачи за процес на природен јазик (NLP). Вклучувањето на архитектурата на Трансформерите значително придонесе во направувањето на Моделирањето на јазикот многу ефикасно во многуте задачи на НЛП, што доведе до значителни напредоци на теренот. Сепак, Трансформерите доаѓаат со голема компјутациска цена, која расте квадратно во однос на должината на влезот. Ова претставува предизвик што разбирањето на долгите тексти бара многу контекст. Во овој весник, предложуваме рамка за фино налаштување, наречена CoreLM, која ја проширува архитектурата на актуелните претренирани јазични модели за да вклучат експлицитни информации за ентитетот. Со воведување на претставувања на ентитетите, ги поставуваме достапните информации надвор од контекстниот простор на моделот, што резултира со подобар Модел на јазик за дел од пресметките трошоци. Го спроведуваме нашиот пристап користејќи го GPT2 и го споредуваме фино прилагодениот модел со оригиналот. Нашиот предложен модел постигнува пониска перплексија во компјутерите на податоци GUMBY и LAMBDADA во споредба со GPT2 и фино прилагодена верзија на GPT2 без никакви промени. Ние, исто така, ги споредуваме изведувањата на моделите во поглед на точноста во ЛАМБАДА и тестот за книги за деца, со и без употреба на моделот создадени анатации за соодветност.', 'ms': 'Model Bahasa adalah dasar bagi semua tugas Pemprosesan Bahasa Alami (NLP) modern. Perkenalan arkitektur Transformers telah berkontribusi secara signifikan untuk membuat Modelan Bahasa sangat efektif melalui banyak tugas NLP, yang membawa kepada kemajuan yang signifikan dalam medan. Namun, Transformers datang dengan biaya pengiraan yang besar, yang tumbuh kuadratik terhadap panjang input. Ini menghasilkan cabaran untuk memahami teks panjang memerlukan banyak konteks. Dalam kertas ini, kami melamar kerangka Penyesuaian Baik, bernama CoreLM, yang memperluas arkitektur Model Bahasa Terlatih semasa sehingga mereka memasukkan maklumat entiti eksplicit. Dengan memperkenalkan perwakilan entiti, kita membuat maklumat tersedia diluar ruang kontekstual model, yang mengakibatkan Model Bahasa yang lebih baik untuk sebahagian daripada kos pengiraan. Kami melaksanakan pendekatan kami menggunakan GPT2 dan membandingkan model yang disesuaikan dengan yang asli. Model kami diusulkan mencapai Perpleksiti yang lebih rendah dalam set data GUMBY dan LAMBDADA apabila dibandingkan dengan GPT2 dan versi terjemput GPT2 tanpa sebarang perubahan. Kami juga membandingkan prestasi model dalam terma Kepastian dalam Ujian LAMBADA dan Buku Anak-anak, dengan dan tanpa menggunakan anotasi koreferensi yang dicipta oleh model.', 'lt': 'Kalbos modeliai yra visų šiuolaikinių gamtos kalbų apdorojimo (NLP) užduočių pagrindas. Įdiegus transformatorių architektūrą daug prisidėta prie to, kad kalbų modeliavimas daugelyje NLP užduočių tapo labai veiksmingas, todėl šioje srityje padaryta didelė pažanga. Tačiau transformatoriai patiria dideles skaičiavimo sąnaudas, kurios didėja kvadratiniu požiūriu į įvedimo ilgį. Tai kelia iššūkį, nes norint suprasti ilgus tekstus reikia daug konteksto. Šiame dokumente siūlome tikslaus pritaikymo sistemą, vadinamą CoreLM, kuri išplėstų dabartinių išankstinio mokymo kalbų modelių architektūrą, kad jie apimtų aiškią subjekto informaciją. Įvedami subjekto atstovavimus, mes pateikiame informaciją už modelio kontekstinės erdvės ribų, o tai lemia geresnį kalbos model į dalį skaičiavimo išlaidų. We implement our approach using GPT2 and compare the fine-tuned model to the original.  Mūsų siūlomas modelis pasiekia mažesnį Perpleksiškumą GUMBY ir LAMBDADA duomenų rinkiniuose, palyginti su GPT2 ir patobulinta GPT2 versija be jokių pakeitimų. Taip pat palyginame modelių rezultatus, susijusius su tikslumu LAMBADA ir vaikų knygos testuose, su modelio sukurtomis koreferencijos anotacijomis ir be jų.', 'no': 'Språk- modeller er understreken av alle moderne naturlege språk- prosesseringar (NLP). Innføring av arkitekturen for Transformerande har bidra signifikante til å gjera språk-modellering veldig effektivt i mange NLP-oppgåver, som fører til signifikante avansertingar i feltet. Transformerer er imidlertid med ein stor datakostnad, som aukar kvadratisk med hensyn til inndata-lengden. Dette viser eit utfordring for å forstå lange tekstar krev mykje kontekst. I denne papiret foreslår vi eit Fine-Tuning-rammeverk, kalla CoreLM, som utvidar arkitekturen av gjeldande Pretrained Language Models slik at dei inkluderer eksplisitt entitetsinformasjon. Ved å introdusere einingsrepresentasjonar, gjer vi tilgjengelege informasjon utenfor kontekstplassen av modellen, som fører til ein bedre språk-modell for ein brøk av datakostnaden. Vi implementerer tilnærminga vårt med GPT2 og sammenlikna det fint oppsettet modellet med originalen. Vårt foreslått modell oppnår ein lavere Perplexity i GUMBY- og LAMBDADA- datasett når sammenlignet med GPT2 og ein fint- oppsett versjon av GPT2 utan endringar. Vi sammenliknar også utviklinga av modelane med nøyaktighet i LAMBADA og barnesboktesten, med og utan bruk av modellet oppretta koreferanslar.', 'mt': 'Il-mudelli lingwistiċi huma l-bażi tal-kompiti moderni kollha tal-ipproċessar tal-lingwi naturali (NLP). L-introduzzjoni tal-arkitettura tat-Transformers ikkontribwiet b’mod sinifikanti biex il-Mudellar tal-Lingwi jsir effettiv ħafna f’ħafna kompiti tal-NLP, li wasslu għal avvanzi sinifikanti fil-qasam. Madankollu, it-Trasformaturi ġejjin bi spiża komputattiva kbira, li tikber kwadratikament fir-rigward tat-tul tal-input. Dan jippreżenta sfida biex wieħed jifhem testi twal jeħtieġ ħafna kuntest. F’dan id-dokument, qed nipproponu qafas ta’ Tuning Fin, imsejjaħ CoreLM, li jestendi l-arkitettura tal-Mudelli tal-Lingwa Mħarrġa minn qabel attwali sabiex jinkorporaw informazzjoni espliċita tal-entità. By introducing entity representations, we make available information outside the contextual space of the model, which results in a better Language Model for a fraction of the computational cost.  Aħna nimplimentaw l-approċċ tagħna bl-użu tal-GPT2 u nqabblu l-mudell irfinat mal-oriġinali. Il-mudell propost tagħna jikseb Perplessità aktar baxxa fis-settijiet tad-dejta GUMBY u LAMBDADA meta mqabbel mal-GPT2 u verżjoni rfinata tal-GPT2 mingħajr ebda bidla. Aħna nqabblu wkoll il-prestazzjoni tal-mudelli f’termini ta’ eżattezza fil-LAMBADA u t-Test tal-Ktieb tat-Tfal, mal-użu u mingħajr l-użu ta’ annotazzjonijiet ta’ koreferenza maħluqa mill-mudell.', 'mn': 'Холны загварууд бол орчин үеийн Байгалийн хэл Процессорын (NLP) ажлын төлөө. Трансформаторын архитектурын орлуулалт нь хэл загварын үндсэн үр дүнтэй болгож, олон NLP ажил дээр ажиллаж, салбарт маш чухал хөгжлийг хөгжүүлж байна. Гэхдээ Трансформацууд маш том тооцоололтын үнэтэй болж ирдэг. Энэ нь орлуулалтын уртыг квадратик хэлбэрээр нэмэгддэг. Энэ нь урт textуудыг ойлгохын тулд маш олон нөхцөл хэрэгтэй. Энэ цаасан дээр бид CoreLM нэртэй Fine-Tuning хэлбэрийн архитектурыг нэмэгдүүлдэг бөгөөд эдгээр нь тодорхой нэгж мэдээллийг бүрдүүлэх боломжтой болно. Объектын үзүүлэлтийг танилцуулахад бид загварын орчин дотор мэдээллийг ашиглаж байна. Энэ нь тооцоолон зардалын хэсэг хэсгийг илүү сайн хэл загвартай болгодог. Бид GPT2-г ашиглан арга загварыг хэрэгжүүлж эхний загвартай харьцуулж байна. Бидний санал дэвшүүлсэн загвар GUMBY болон LAMBDADA өгөгдлийн санд GPT2-тай харьцуулахад, GPT2-ын төгсгөл хувилбарыг өөрчлөгдсөн бага Перплексийг олгодог. Мөн бид загварын үйл ажиллагааг LAMBADA болон хүүхдүүдийн номын шалгалтын тухай харьцуулж, загварын бүтээгдэхүүний зөвхөн зөвхөн хэрэглэгдэхгүй.', 'pl': 'Modele językowe stanowią podstawę wszystkich nowoczesnych zadań przetwarzania języka naturalnego (NLP). Wprowadzenie architektury Transformers znacząco przyczyniło się do bardzo efektywnego modelowania języka w wielu zadaniach NLP, co doprowadziło do znaczących postępów w tej dziedzinie. Jednak transformatory wiążą się z dużym kosztem obliczeniowym, który rośnie kwadratowo w odniesieniu do długości wejścia. Stanowi to wyzwanie, ponieważ zrozumienie długich tekstów wymaga dużego kontekstu. W niniejszym artykule proponujemy framework Fine-Tuning o nazwie CoreLM, który rozszerza architekturę obecnych pretreningowych modeli językowych tak, aby uwzględniały one wyraźne informacje o jednostkach. Wprowadzając reprezentacje jednostek, udostępniamy informacje poza kontekstową przestrzenią modelu, co skutkuje lepszym modelem językowym za ułamek kosztów obliczeniowych. Nasze podejście wdrażamy za pomocą GPT2 i porównujemy dopracowany model do oryginału. Proponowany przez nas model osiąga niższą Perplexity w zbiorach danych GUMBY i LAMBDADA w porównaniu do GPT2 oraz dostrojonej wersji GPT2 bez żadnych zmian. Porównujemy również wydajność modeli pod względem dokładności w LAMBADA i Książce Dziecięcej, z użyciem i bez użycia adnotacji koreferencyjnych tworzonych przez model.', 'ro': 'Modelele lingvistice reprezintă baza tuturor sarcinilor moderne de procesare a limbajului natural (PNL). Introducerea arhitecturii Transformers a contribuit semnificativ la eficientizarea modelării limbajului în multe sarcini PNL, conducând la progrese semnificative în domeniu. Cu toate acestea, Transformers vin cu un cost computațional mare, care crește cuadratic în ceea ce privește lungimea intrării. Acest lucru reprezintă o provocare deoarece înțelegerea textelor lungi necesită mult context. În această lucrare, propunem un cadru Fine-Tuning, numit CoreLM, care extinde arhitectura modelelor actuale de limbaj pretrained astfel încât acestea să includă informații explicite despre entitate. Prin introducerea reprezentărilor entităților, punem la dispoziție informații în afara spațiului contextual al modelului, ceea ce duce la un model lingvistic mai bun pentru o fracțiune din costul de calcul. Implementăm abordarea noastră folosind GPT2 și comparăm modelul reglat fin cu originalul. Modelul nostru propus obține o Perplexitate mai mică în seturile de date GUMBY și LAMBDADA în comparație cu GPT2 și o versiune fină de GPT2 fără nicio modificare. De asemenea, comparăm performanțele modelelor în ceea ce privește acuratețea în LAMBADA și testul cărții pentru copii, cu și fără utilizarea adnotărilor de corefență create de model.', 'so': 'Modelooyinka afka waa hoos u qoran dhamaan shaqooyinka la qabanayo afka asalka ah (NLP). Isu soo saaridda dhismaha turjumista ayaa si muhiim ah u faa’iidey in luqada lagu sameeyo mid aad u faa’iido leh oo ka mid ah shaqada NLP oo badan, wuxuuna horumarinayay horumar wayn ee duurka. Si kastaba ha ahaatee turjubaanku waxay yimaadaan kharash aad u weyn oo xisaab ah, taasoo si koowaad ah ugu kordha dhererka gudaha. Tan waxaa soo saara dhibaato ah in aad fahanto qoraal dhaadheer ay u baahan tahay mid aad u badan. Qoraalkan waxaynu soo jeedaynaa koorsho Fine-Tuning, magaca CoreLM, kaas oo fidiya dhismaha dhismaha muusikada afka hore ee la tababaray si ay ugu soo buuxiyaan macluumaad cadcad. Markii aan soo bandhijinno macluumaad ka soo baxsan goobaha sameynta, kaas oo sababtaa Modelka afka ka wanaagsan in qayb ka mid ah kharashka xisaabta. Waxaynu sameynaa qaababka aan ku isticmaalno GPT2, waxaynu isbarbardhignaa noocyada hore oo wanaagsan. Tusaale la soo jeeday wuxuu gaadhaa qoraal hoos ah ee GUMBY iyo LAMBDADA macluumaadkooda marka la barbardhigo GPT2 iyo warqad fiican oo GPT2 ah oo aan beddelin. Sidoo kale waxaynu isbarbardhignaa sameynta sameynta tusaalaha, si waafaqsan xarunta xafiiska ah ee LAMBADA iyo imtixaanka kitaabka carruurta, taas oo aan isticmaaleyn warqadaha muusikada oo sameynaya.', 'sr': 'Modeli jezika su pod temeljem svih modernih zadataka prirodnog procesa jezika (NLP). Uvedenje arhitekture transformera značajno je doprinijelo da se modelira jezika vrlo efikasno u mnogim zadacima NLP-a, dovedeći do značajnih napredaka na terenu. Međutim, transformeri dolaze sa velikim računalnim troškovima, koja se kvadratično raste u odnosu na dužinu ulaza. To predstavlja izazov u razumijevanju dugih tekstova zahteva mnogo konteksta. U ovom papiru predlažemo okvir Fine-Tuning, pod nazivom CoreLM, koji proširi arhitekturu trenutnih prisiljenih jezičkih modela tako da uključuju pojasne informacije o entitetu. Predstavljajući predstave entiteta, mi dajemo dostupne informacije izvan kontekstnog prostora model a, što rezultira boljim jezičkim modelom za deo kompjuterskih troškova. Mi implementiramo naš pristup koristeći GPT2 i uspoređujemo dobar model sa originalom. Naš predloženi model postiže niži Perplexity u GUMBY i LAMBDADA podacima u usporedbi sa GPT2-om i ispravnom verzijom GPT2 bez bilo kakvih promjena. Također uspoređujemo izvršnost modela u smislu preciznosti u testu LAMBADA i dječje knjige, sa i bez upotrebe navodnih pristojnih annotacija koji su stvorili modele.', 'ta': 'மொழி மாதிரிகள் அனைத்து modern Natural Language Processing (NLP) பணிகளின் கீழே உள்ளது. மாற்றுபவர்கள் உருவாக்குதல் மொழி மாதிரியை மிகவும் விருப்பமாக செயல்படுத்துகிறது, பல NLP பணிகள் முழுவதும் மாதிரியும், புலத்தில் மிக மு ஆனால், மாற்றுபவர்கள் ஒரு பெரிய கணக்கீட்டு விலையுடன் வருகின்றன, அது உள்ளீட்டு நீளம் பற்றி வரைவாக வளருகிறது. நீண்ட உரைகளை புரிந்து கொள்வதற்காக இது ஒரு சவால் அளிக்கிறது நிறைய சூழல் தேவைப்படுகிறது. In this paper, we propose a Fine-Tuning framework, named CoreLM, that extends the architecture of current Pretrained Language Models so that they incorporate explicit entity information.  பொருள் குறிப்புகளை அறிவித்து, மாதிரியின் தற்போதைய இடைவெளியில் உள்ள தகவல் கிடைக்கும், அது கணிப்பு விலையின் பின்னத்திற்கு மேல GPT2 பயன்படுத்தி நாம் எங்கள் செயல்பாட்டை நிறைவேற்றுகிறோம் மற்றும் சரியான முறைமையை மூலத்திற்கு ஒப GUMBY மற்றும் LAMBDADA தகவல் அமைப்புகளில் எங்கள் பரிந்துரைக்கப்பட்ட மாதிரி பெறுகிறது GPT2 மற்றும் எந்த மாற்றங்களும் இல்லாமல் GPT2 பதிப்புகளை ஒ லாம்பேடா மற்றும் குழந்தைகள் சோதனையில் நாம் மாதிரியின் செயல்பாட்டை ஒப்பிடுகிறோம், மாதிரியாக உருவாக்கப்பட்ட குறிப்புகளை பயன்', 'si': 'භාෂාව මොඩේල්ස් තමයි සියළුම සාමාන්\u200dය භාෂාව ප්\u200dරක්\u200dරියාස (NLP) වැඩක් අඩුවෙන්. Name නමුත්, ප්\u200dරවර්තනය කරන්නේ ලොකු ගණණක විශාලයක් තියෙන්නේ, ඒක ප්\u200dරවර්තනය විශාලයෙන් ප්\u200dරවර්තනය කරන්නේ ඇ මේක ප්\u200dරශ්නයක් තේරුම් ගන්න ලොකු පාළුවක් ගොඩක් සංවේදනය අවශ්\u200dයයි. මේ පැත්තේ, අපි හොඳ ටුන්ජින් ස්ථානයක්, CoreLM කියල, ප්\u200dරස්තූත භාෂා මොඩේල්ස් වලින් ස්ථානයක් විස්තර කරනවා, එතකොට ඔවුන්  මොඩල් එකේ ප්\u200dරතිනිධානය ප්\u200dරතිනිධානය කරන්න පුළුවන් තොරතුරු තියෙන්නේ, මොඩල් එකේ ප්\u200dරතිනිධානයේ ප්\u200dරතිනිධානයේ ප අපි GPT2 භාවිතා අපේ ප්\u200dරවේශනය පරීක්ෂණය කරන්න සහ ප්\u200dරවේශනය සඳහා ප්\u200dරවේශනය සඳහා ප්\u200dරවේශනය කරන්න. අපේ ප්\u200dරශ්නය කරපු මොඩල් එක GUMBY සහ LAMBDADA දත්ත සේට් වල පහළ ප්\u200dරශ්නයක් ලැබෙනවා GPT2 සහ GPT2 ගේ සැකසුම් සඳහා මොකක් වෙනස් නැති ව අපි පරීක්ෂණය ලම්බාඩා සහ ළමයින්ගේ පොත පරීක්ෂණය සමඟත් මොඩේල්ස්ගේ වැඩසටහන් පරීක්ෂණය ලැබෙනවා, මොඩේල් නිර්මාණය කරපු කෝ', 'ur': 'Language Models are the underpin of all modern Natural Language Processing (NLP) tasks. تبدیل کرنے والوں کی معماری معماری کا معلوم بہت سے NLP کام میں زبان مدل کرنے کے لئے بہت اثر دینے کے لئے بہت اثر دیتا ہے، جو کھیل میں اثر اضافہ کرنے کے لئے ہے. However, Transformers come with a big computational cost, which grows quadratically with respect to the input length. یہ ایک چال پیش کرتا ہے کہ طویل پیغام سمجھنے کے لئے بہت سی متصلہ کی ضرورت ہے. اس کاغذ میں، ہم ایک فین ٹونگ فرم ڈرائیں، CoreLM کے نام سے، جو موجود Pretrained Language Models کی معماری پھیلاتا ہے تاکہ وہ صریح انٹیٹی معلومات میں شامل کریں. انٹیٹیوں کی نمایش پیش کرکے، ہم مدل کے کنٹکسٹیوال جگہ کے باہر موجود معلومات کر رہے ہیں، جو کامپیوتر کے قیمت کے برابر بہترین زبان مدل کے نتیجے ہیں. ہم نے GPT2 کے مطابق اپنے طریقے کو مطابق کرلیا ہے اور اصلی موڈل سے مطابق کرلیا ہے۔ ہماری پیشنهاد مدل GUMBY اور LAMBDADA ڈیٹ سٹ میں کم پرپرپرلکستی حاصل کرتی ہے جبکہ GPT2 کے مقابلہ میں اور GPT2 کی کوئی بدلنے کے بغیر ایک پاکیزہ نسخہ حاصل کرتی ہے۔ ہم نے بھی مدلکوں کی عمدگی کو LAMBADA اور بچوں کی کتاب آزمائش کے مطابق مطابق کے مطابق اور بغیر مدلکوں کے مطابق مطابق کرتے ہیں.', 'sv': "Språkmodeller är grunden för alla moderna Natural Language Processing (NLP) uppgifter. Införandet av Transformers-arkitekturen har avsevärt bidragit till att göra språkmodellering mycket effektiv för många NLP-uppgifter, vilket har lett till betydande framsteg inom området. Transformers kommer dock med en stor beräkningskostnad, som växer kvadratiskt med avseende på inmatningslängden. Detta innebär en utmaning eftersom att förstå långa texter kräver mycket sammanhang. I denna uppsats föreslår vi ett ramverk för finjustering, som heter CoreLM, som utökar arkitekturen för nuvarande Pretrained Language Models så att de inkluderar explicit entitetsinformation. Genom att introducera entitetsrepresentationer gör vi information tillgänglig utanför modellens kontextuella utrymme, vilket resulterar i en bättre språkmodell för en bråkdel av beräkningskostnaden. Vi implementerar vårt tillvägagångssätt med GPT2 och jämför den finjusterade modellen med originalet. Vår föreslagna modell uppnår en lägre Perplexity i GUMBY och LAMBDADA datauppsättningar jämfört med GPT2 och en finjusterad version av GPT2 utan några ändringar. Vi jämför även modellernas prestanda när det gäller noggrannhet i LAMBADA och Children's Book Test, med och utan användning av modellskapade coreferenceannonteringar.", 'uz': "Tilning modellari esa yangi tabiiy tillar jarayonlarining (NLP) vazifalarining pastki. Vazifalar arxituvlarini tahrirlash uchun tillar modulini ko'p NLP vazifalari bilan juda ishlaydi. Bu holatda juda muhim rivojlanishi mumkin. Va albatta, Transformerlar tarkibini kiritish uzunligi bilan katta kompyutlar bilan keladi. Bu yerda uzun matnlarni tushunish uchun juda ko'p muhit kerak. Bu hujjatda, biz CoreLM nomli yaxshi tugmalar qolipini rivojlanishimiz, bu hozirgi Tahrirlangan tillar modellarining architektiyasini ajratuvchi va ularning shaxsiy maʼlumotni kiritish uchun. Mualliflik tashkilotlarini aniqlash orqali modelning davomida maʼlumot yordam beramiz. Bu kompyuterning qiymatini bir qismiga yaxshi tillar modul qiladi. Biz GPT2 yordamida ruxsatimizni bajaramiz va yaxshi tuzilgan modelni asl asosiga kamaytamiz. Maʼlumot bazasini GPT2 va GPT2 versiyasi bilan birga murakkab o'zgarishlar yoʻq, GGUMBY va LAMBDADA maʼlumotlar tarkibini bajaradi. Biz LoMBADA va Kitoblar Testiyotda modellar bajarishini kamaytamiz, va model yaratilgan bir xil taʼminotlarni ishlatilmaydi.", 'vi': 'Các mô- đun ngôn ngữ là nền tảng của mọi công việc tự nhiên (chọc ngoáy ngôn ngữ) hiện đại. The Introduction of the transformers kiến trúc đ. đã góp phần đóng góp đáng kể vào việc biến Ngôn ngữ Modeling trở nên rất hiệu quả trong nhiều nhiệm vụ của NLP, lead to significant advances in the field. Tuy nhiên, các robot biến hình có một giá trị tổng tính lớn, mà phát triển theo góc với độ dài nhà nhập. Đây là một thách thức trong việc hiểu được những văn bản dài đòi hỏi nhiều bối cảnh. Trong tờ giấy này, chúng tôi đề xuất một bộ khung ánh sáng, tên là CoreLM, để mở rộng cấu trúc của các mô- đun ngôn ngữ sẵn sàng để họ có thông tin chi tiết về thực thể. Bằng cách đưa ra các biểu hiện thực thể, chúng tôi cung cấp thông tin ngoài các địa điểm ngữ cảnh của mô hình, kết quả là một mô hình ngôn ngữ tốt hơn với một phần giá trị toán. Chúng tôi áp dụng cách tiếp cận của mình bằng GP2 và so sánh mô hình chính xác với mẫu gốc. Trong tập tin về GUMB và LAMB sau khi so sánh với GP2 và một bản hoàn chỉnh hoàn hảo của GP2 mà không thay đổi. Chúng tôi cũng so s ánh kết quả của các mô hình về độ chính xác trong LAMB và Điều Thử Sách Trẻ em, với và không sử dụng chú thích hồng cầu kiểu mẫu tạo ra.', 'hr': 'Modeli jezika su pod temeljem svih modernih zadataka prirodnog procesa jezika (NLP). Uvedenje arhitekture transformatora značajno je doprinijelo učiniti Modeliranje jezika vrlo učinkovitom u mnogim zadacima NLP-a, što vodi do značajnih napredak na terenu. Međutim, transformeri dolaze sa velikim računalnim troškovima, koja se kvadratično raste u odnosu na dužinu ulaza. To predstavlja izazov za razumijevanje dugih tekstova zahtijeva mnogo konteksta. U ovom papiru predlažemo okvir za fino prilagođenje po imenu CoreLM, koji proširi arhitekturu trenutnih modela jezika Pretrained kako bi uključili pojasne informacije o entitetu. Predstavljajući predstave entiteta, pružamo dostupne informacije izvan kontekstnog prostora model a, što rezultira boljim jezičkim modelom za dijelom računalnih troškova. Mi implementiramo svoj pristup koristeći GPT2 i uspoređujemo dobar model s originalom. Naš predloženi model postiže niži Perplexity u GUMBY i LAMBDADA podacima u usporedbi s GPT2-om i ispravnim verzijom GPT2 bez bilo kakvih promjena. Također uspoređujemo provedbu modela u smislu preciznosti u testu lijeka LAMBADA i dječje knjige, sa i bez primjene primjene oznake o dobrodošlosti stvorenih modela.', 'nl': 'Taalmodellen vormen de basis van alle moderne Natural Language Processing (NLP) taken. De introductie van de Transformers-architectuur heeft aanzienlijk bijgedragen aan het zeer effectief maken van taalmodellering in vele NLP-taken, wat leidde tot aanzienlijke vooruitgang in het veld. Transformers komen echter met een grote rekenkosten, die kwadratisch groeien ten opzichte van de invoerlengte. Dit is een uitdaging omdat het begrijpen van lange teksten veel context vereist. In dit artikel stellen we een Fine-Tuning framework voor, genaamd CoreLM, dat de architectuur van huidige Pretrained Language Models uitbreidt zodat ze expliciete entiteitsinformatie bevatten. Door entiteitsrepresentaties te introduceren, maken we informatie beschikbaar buiten de contextuele ruimte van het model, wat resulteert in een beter Taalmodel voor een fractie van de rekenkosten. We implementeren onze aanpak met GPT2 en vergelijken het verfijnde model met het origineel. Ons voorgestelde model bereikt een lagere Perplexity in GUMBY en LAMBDADA datasets in vergelijking met GPT2 en een verfijnde versie van GPT2 zonder enige wijzigingen. We vergelijken ook de prestaties van de modellen op het gebied van nauwkeurigheid in LAMBADA en Kinderboektest, met en zonder het gebruik van model-gecreëerde coreference annotaties.', 'da': 'Sprogmodeller er grundlaget for alle moderne Natural Language Processing (NLP) opgaver. Introduktionen af Transformers-arkitekturen har bidraget betydeligt til at gøre Language Modeling meget effektiv på tværs af mange NLP-opgaver, hvilket har ført til betydelige fremskridt på området. Transformers kommer dog med en stor beregningsomkostning, som vokser kvadratisk i forhold til input længde. Dette udgør en udfordring for at forstå lange tekster kræver en masse kontekst. I denne artikel foreslår vi en Fine-Tuning framework, der hedder CoreLM, der udvider arkitekturen af nuværende Pretrained Language Models, så de indarbejder eksplicitte entity information. Ved at indføre entitetsrepræsentationer gør vi oplysninger tilgængelige uden for modellens kontekstuelle rum, hvilket resulterer i en bedre sprogmodel for en brøkdel af de beregningsmæssige omkostninger. Vi implementerer vores tilgang ved hjælp af GPT2 og sammenligner den finjusterede model med originalen. Vores foreslåede model opnår en lavere Perplexity i GUMBY og LAMBDADA datasæt sammenlignet med GPT2 og en finjusteret version af GPT2 uden ændringer. Vi sammenligner også modellernes ydeevne med hensyn til nøjagtighed i LAMBADA og Børnebogstest, med og uden brug af model-skabte coreference annotationer.', 'bg': 'Езиковите модели са в основата на всички съвременни задачи за обработка на естествени езици. Въвеждането на архитектурата на трансформаторите допринесе значително за превръщането на езиковото моделиране в много задачи, водещи до значителен напредък в областта. Трансформаторите обаче идват с голяма изчислителна цена, която расте квадратно по отношение на дължината на входа. Това представлява предизвикателство, тъй като разбирането на дълги текстове изисква много контекст. В тази статия предлагаме рамка за фино настройване, наречена която разширява архитектурата на настоящите предварително обучени езикови модели, така че те да включват изрична информация за същността. Чрез въвеждането на представяне на обекти, ние предоставяме информация извън контекстното пространство на модела, което води до по-добър Езиков Модел за част от изчислителните разходи. Ние прилагаме нашия подход с помощта на GPT2 и сравняваме фино настроения модел с оригинала. Нашият предложен модел постига по-ниска перплексичност в наборите от данни ГУМБИ и ЛАМБДАДА в сравнение с ГУТ2 и фина версия на ГУТ2 без никакви промени. Сравняваме и ефективността на моделите по отношение на точността в ламбада и теста за детска книга, със и без използването на създадени от модела кореферентни анотации.', 'id': 'Model Bahasa adalah dasar dari semua tugas Proses Bahasa Alami (NLP) modern. Perkenalan arsitektur Transformers telah berkontribusi secara signifikan untuk membuat Modeling Bahasa sangat efektif di banyak tugas NLP, yang menyebabkan kemajuan yang signifikan di lapangan. Namun, Transformers datang dengan biaya komputasi yang besar, yang tumbuh kuadratis terhadap panjang masukan. Ini menantang untuk memahami teks panjang membutuhkan banyak konteks. Dalam kertas ini, kami mengusulkan cadangan Penyesuaian Baik, bernama CoreLM, yang memperluas arsitektur Model Bahasa Terlatih saat ini sehingga mereka memasukkan informasi entitas eksplicit. Dengan memperkenalkan perwakilan entitas, kami membuat informasi tersedia diluar ruang kontekstual model, yang berasal dari Model Bahasa yang lebih baik untuk sebagian dari biaya komputasi. Kami menerapkan pendekatan kami menggunakan GPT2 dan membandingkan model yang disesuaikan dengan model asli. Our proposed model achieves a lower Perplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a fine-tuned version of GPT2 without any changes.  Kami juga membandingkan prestasi model dalam terma Kepastian di LAMBADA dan Tes Buku Anak-anak, dengan dan tanpa menggunakan anotasi koreferensi yang dibuat model.', 'fa': 'مدل\u200cهای زبان پایین تمام کار\u200cهای پردازش زبان طبیعی مدرن (NLP) است. معماری تغییر\u200cسازی\u200cکننده\u200cها به عنوان مدل\u200cسازی زبان در بسیاری از کار NLP بسیار تاثیر داده\u200cاند، که به پیشرفت\u200cهای بزرگی در این زمینه رهبری می\u200cکند. ولی تغییر دهندگان با هزینه\u200cهای بزرگ محاسباتی می\u200cآیند که با ارتباط به طول ورودی چهارچهارچهارچهارچهارچهارچهارچهارچهارچهار می\u200cشود. این یک چالش را برای فهمیدن متن های طولانی نیاز به محیط زیادی دارد. در این کاغذ، ما یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها با توجه به نمایش\u200cهای شرکت، ما اطلاعات را بیرون فضای متوسط مدل در دسترسی می\u200cدهیم، که به یک مدل زبان بهتر برای بخشی از هزینه\u200cهای کامپیوتر نتیجه می\u200cدهد. ما روش خود را با استفاده از GPT2 انجام می دهیم و مدل اصلی را با اصلی مقایسه می کنیم. مدل پیشنهاد ما در مجموعه\u200cهای داده\u200cهای GUMBY و LAMBDADA پایین پایین در مقایسه با GPT2 و یک نسخه\u200cی کامل سازی از GPT2 بدون هیچ تغییر می\u200cرسد. ما همچنین عملکرد مدلها را در مورد دقیق در LAMBADA و آزمایش کتاب کودکان مقایسه می کنیم، با و بدون استفاده از اظهار رضایت مدل ساخته شده است.', 'sw': 'Modeli za lugha ni msingi wa kazi zote za utaratibu wa lugha za asili (NLP). Kuanzishwa kwa ujenzi wa Wasafiri umechangia kwa kiasi kikubwa katika kufanya Modeling of Lugha yenye ufanisi sana katika kazi nyingi za NLP, na kusababisha maendeleo makubwa katika uwanja huo. Hata hivyo, Wasafiri wanakuja na gharama kubwa za hisabati, ambazo huongezeka kwa kiasi kikubwa kuheshimu kiwango cha input. Hii inaleta changamoto kwa kuelewa maandishi ndefu yanahitaji muktadha mkubwa. Katika gazeti hili, tunapendekeza mfumo wa kuanzisha vizuri, unaoitwa CoreLM, ambao unaeneza ujenzi wa Modeli za Lugha zilizojifunza hivi sasa ili wawezee kuunganisha taarifa wazi. Kwa kuwasilisha uwakilishi wa kituo, tunatoa taarifa nje ya nafasi ya kisasa ya muundo, ambayo inasababisha Modeli bora ya Lugha kwa sehemu ya gharama za hesabu. Tunatumia mbinu yetu kwa kutumia GPT2 na kulinganisha mtindo mzuri na asili. Mradi wetu ulipendekezwa unapata ukosefu wa chini kabisa katika GUMBY na taarifa za LAMBDA wakati ukilinganishwa na GPT2 na toleo lililofanana na GPT2 bila mabadiliko yoyote. Pia tunafananisha utendaji wa mifano katika kuhusiana na Ukurasa wa LAMBADA na Vitabu vya Watoto, pamoja na bila matumizi ya matangazo yanayotengenezwa na mifano.', 'de': 'Sprachmodelle sind die Grundlage für alle modernen Aufgaben der Natural Language Processing (NLP). Die Einführung der Transformers-Architektur hat maßgeblich dazu beigetragen, dass Sprachmodellierung über viele NLP-Aufgaben hinweg sehr effektiv ist und zu erheblichen Fortschritten in diesem Bereich geführt hat. Transformatoren haben jedoch einen hohen Rechenkosten, der in Bezug auf die Eingangslänge quadratisch wächst. Das stellt eine Herausforderung dar, denn lange Texte zu verstehen erfordert viel Kontext. In diesem Beitrag schlagen wir ein Fine-Tuning-Framework namens CoreLM vor, das die Architektur aktueller Vortrainierter Sprachmodelle erweitert, um explizite Entitätsinformationen einzubeziehen. Durch die Einführung von Entitätsrepräsentationen stellen wir Informationen außerhalb des Kontextraums des Modells zur Verfügung, was zu einem besseren Sprachmodell für einen Bruchteil der Rechenkosten führt. Wir setzen unseren Ansatz mit GPT2 um und vergleichen das fein abgestimmte Modell mit dem Original. Unser vorgeschlagenes Modell erreicht eine geringere Perplexität in GUMBY- und LAMBDADA-Datensätzen im Vergleich zu GPT2 und eine fein abgestimmte Version von GPT2 ohne Änderungen. Wir vergleichen auch die Leistung der Modelle hinsichtlich Genauigkeit in LAMBADA und Kinderbuchtest, mit und ohne die Verwendung von modellerstellten Coreferenz-Anmerkungen.', 'ko': '언어 모델은 모든 현대자연언어처리(NLP) 임무의 기초이다.Transformers 체계 구조의 도입은 많은 NLP 임무에서 언어 모델링의 유효성을 크게 추진했고 이 분야에서 중대한 진전을 거두었다.그러나 변압기는 입력 길이에 따라 2차 증가하는 막대한 계산 원가를 가져왔다.긴 텍스트를 이해하려면 대량의 상하문이 필요하기 때문에 이것은 도전이다.본고에서 우리는CoreLM이라는 마이크로스피커 프레임워크를 제시했는데 이 프레임워크는 현식 실체 정보를 포함하도록 현재의 예비 훈련 언어 모델의 체계 구조를 확장시켰다.실체 표시를 도입함으로써 우리는 모델의 상하문 공간 외에 사용 가능한 정보를 제공하여 원가를 계산하는 일부분으로 더욱 좋은 언어 모델을 얻었다.GPT2를 사용하여 접근법을 구현했으며 미세 조정된 모델을 원본 모델과 비교했습니다.GPT2와 GPT2의 마이크로 버전에 비해 우리가 제시한 모델은 GUMBY와 LAMBDADA 데이터 집중에서 더욱 낮은 복잡도를 실현했고 아무런 변화도 없었다.LAMBADA와 어린이 도서 테스트에서 모델의 정확성과 모델이 만든 공지 주석을 사용하고 사용하지 않는 상황에서의 성능도 비교했다.', 'sq': 'Modelet e gjuhës janë baza e të gjitha detyrave moderne të Procesimit të gjuhës natyrore (NLP). Futja e arkitekturës së Transformuesve ka kontribuar ndjeshëm në bërjen e modelimit të gjuhës shumë efektiv nëpërmjet shumë detyrave të NLP, duke çuar në përparime të rëndësishme në fushë. Megjithatë, Transformuesit vijnë me një kosto të madhe kompjuterike, e cila rritet katrorisht lidhur me gjatësinë e hyrjes. Kjo paraqet një sfidë për të kuptuar tekstet e gjata kërkon shumë kontekst. In this paper, we propose a Fine-Tuning framework, named CoreLM, that extends the architecture of current Pretrained Language Models so that they incorporate explicit entity information.  Duke përfaqësuar përfaqësimet e njësisë, ne bëjmë informacionin në dispozicion jashtë hapësirës kontekstuale të modelit, që rezulton në një model gjuhësh më të mirë për një pjesë të kostos llogaritare. Ne zbatojmë qasjen tonë duke përdorur GPT2 dhe krahasojmë modelin e rregulluar me origjinalin. Modeli ynë i propozuar arrin një Perpleksitet më të ulët në grupet e të dhënave GUMBY dhe LAMBDADA kur krahasohet me GPT2 dhe një version të rregulluar të GPT2 pa ndryshime. Ne krahasojmë gjithashtu shfaqjen e modeleve në lidhje me saktës in ë në LAMBADA dhe Test in e Librit të Fëmijëve, me dhe pa përdorimin e anotacioneve të përbashkëta të krijuara nga modeli.', 'af': "Taal Modelle is die ondersteun van alle moderne Natuurlike Taal Prosessering (NLP) taak. Die inligting van die Transformers-arkitektuur het betekeurig bydraai in die maak van Taal Modeling baie effektief oor baie NLP-taak, wat lei na betekende avansies in die veld. Alhoewel, Transformers kom met 'n groot rekenaasjonale koste, wat groei quadratik met respek na die invoer lengte. Hierdie stel 'n uitdrukking voor om lange teks te verstaan, benodig baie konteks. In hierdie papier, voorstel ons 'n Fine-Tuning raamwerk, genaamd CoreLM, wat die arkitektuur van huidige Pretrained Taal Models uitbrei sodat hulle eksplisiese entiteit inligting inkorpreer. Deur eenheid verteenwoordings te introduseer, maak ons beskikbaar inligting buite die kontekstuele ruimte van die model, wat resultaat in 'n beter taal Model vir 'n breuk van die rekenaar koste. Ons implementeer ons toegang deur GPT2 te gebruik en vergelyk die fine-tuned model met die oorspronklike. Ons voorgestelde model bereik 'n laer Perplexity in GUMBY en LAMBDADA datastelle wanneer vergelyk word met GPT2 en 'n fyn- tuned weergawe van GPT2 sonder enige veranderinge. Ons vergelyk ook die modelle se prestasie in terms of Accuracy in LAMBADA en kinders se Book Toestel, met en sonder die gebruik van model-geskepe koreferensienotasies.", 'tr': "Dil nusgalar ähli modi Taryh Dili İşlemleriniň altynda. Transformer arhitekturumynyň girişinde dil nusgasyny NLP täblisasynda örän täsirli bolmak üçin örän köpüsi kömekleyär. Ýöne, terjimeler uly hasaplamak bedeli bilen gelip, giriş uzunluğuna görä kvadratik şekilde ulaşýar. Bu uzak metinleri düşünmek üçin kynçylyk görkezýär. Bu kağıtda, CoreLM adlı Fine-Tuning çerçevesini teklif ediyoruz. Bu şekilde şimdiki Pretrained Dil Modellerinin arhitektiğini a çık bir tek bilgi içeren şekilde uzatır. Birim suratlaryny tanyşdyryp, hatlary modyň daşynda hat laryny bar. Bu da kalkularyň bahalarynyň birnäçesi üçin has gowy Modeli bolar. Biz öz ýaryşymyzy GPT2'den ullanýarys we gowy düzümlenmiş modelini original bilen karşılaştyrýarys. Biziň teklip eden nusgadymyz GUMBY we LAMBDADA veri düzümlerinde GPT2 we GPT2'iň eňli düzümlenmeden düzümlenmiş bir versiýany çykar. Biz hem modelleriň eden zadyny LAMBADA we Çagalaryň Kitap Synagynda, nusgasy döredilen ýüregi duýdurmanyň ulanmasy bilen we çykarypdyk.", 'az': "Dil modelləri modern Natural Language Processing (NLP) işlərinin altındadır. Transformers arhitektarının tanışması, dil modellərini çox NLP işində çox etkili yaratmaq üçün çox faydalı olaraq, sahədə böyük ilerlemelərə yol açar. Ancaq, Transformers, giriş uzunluğuna qarşı kvadratik olaraq böyük bir hesap maliyyəti ilə gəlir. Bu, uzun metinləri anlamaq üçün çətin göstərir ki, çox məlumat lazımdır. Bu kağızda, CoreLM adlı Fine-Tuning framework ünü təklif edirik ki, şimdiki Pretrained Dil Modellərinin arhitektarını genişləyir və onlar a çıq-aydın bir məlumatı içərisində istifadə edirlər. Birlik göstəricilərini tanıdıraq, model in in müxtəlif alanın dışında məlumatları verərik. Bu, hesap maliyyətlərinin bir bölümünə daha yaxşı Dil Modeli olar. Biz GPT2 vasitəsilə yaxınlığımızı uygulayıq və düzgün düzgün modeli original ilə qarşılaşdırırıq. Bizim təbliğ etdiyimiz modelimiz GUMBY və LAMBDADA veri qurularında GPT2 ilə qarşılaşdığında və GPT2'nin düzgün düzgün versiyonu heç bir dəyişiklik olmadan daha düzgün bir Perplexiti başa düşər. Biz də modellərin əməllərini LAMBADA və çocukların Kitabı s ınaması ilə, modellərin yaratdığı mərhəmətli məlumatların istifadəsi olmadan ilə qarşılaşdırırıq.", 'am': 'ቋንቋ የዘረፋዎች መሠረት ማግኘት ቋንቋ ሞዴል በብዙ NLP አድራጊዎች ላይ እጅግ ፍጥረት ለማድረግ አግኝቷል፡፡ ነገር ግን ተርጓሚዎች በመስመር ላይ በጥቅልቅ በሚያድጋት ትልቅ ቁጥር ይመጣሉ፡፡ ይህ የረጅም ጽሑፎች ለማስተዋል ብዙ ጽሑፎች ያስፈልጋል፡፡ In this paper, we propose a Fine-Tuning framework, named CoreLM, that extends the architecture of current Pretrained Language Models so that they incorporate explicit entity information.  አካባቢ መልዕክቶችን በመግለጽ፣ ከሞዴል ውጭ የሚሆነውን መረጃ እናደርጋለን፡፡ የGPT2 ጥያቄን እናደርጋለን እና መልካሙን ዓይነት ለመጀመሪያው እናስተያየዋለን፡፡ በGGUMBY እና LAMBDADA ዳታዎችን በተለየ GPT2 እና የተለወጠውን የGPT2 ክፍል ጥሩ የGPT2 ክፍል በተደረገ ጊዜ የተዘጋጀውን ሞዴል አግኝቷል፡፡ በLAMBADA እና የልጆች መጻሕፍት ተፈተና እና በሞዴል የተፈጠረውን የድምፅ አካባቢዎችን እናሳያታለን፡፡', 'bn': 'ভাষার মোডেল হচ্ছে আধুনিক প্রাকৃতিক ভাষার প্রক্রিয়া (NLP) কাজ ট্রান্সফর্মার্স স্থানান্তরের প্রতিষ্ঠানগুলোর প্রযুক্তি অনেক এনএলপি কাজে ভাষা মডেলিং খুব কার্যকর করে সাহায্য করেছে, যা ক্ষে তবে ট্রান্সফর্মাররা একটি বিশাল গণমূল্য নিয়ে এসেছে, যা ইনপুটের দৈর্ঘ্যের প্রতি সম্মান বৃদ্ধি পায়। এটি একটি চ্যালেঞ্জ উপস্থাপন করেছে যেহেতু দীর্ঘ লেখাগুলো বুঝতে পারে তার অনেক প্রয়োজন। এই কাগজটিতে আমরা একটি ভাল টিউনিং ফ্রেম প্রস্তাব করছি, যার নাম কোরেএলএম, যা বর্তমান প্রশিক্ষিত ভাষা মডেলের স্থাপত্য বিস্তৃত করে যাতে তারা সুস্পষ বস্তুর প্রতিনিধিত্ব প্রদান করার মাধ্যমে আমরা মডেলের বর্তমান স্থানের বাইরে তথ্য পাই, যার ফলে গণনাত্রিক খরচের একটি ভাষার মোডেলের জন্য ভ আমরা জিপিটি২ ব্যবহার করে আমাদের পদক্ষেপ বাস্তবায়িত করি এবং মূল মডেলের সাথে তুলনা করি। আমাদের প্রস্তাবিত মডেল জিপিটি২র তুলনায় গুম্বি এবং লাম্বিডার ডাটাটাসেটে কম পার্পলিক্সিটি অর্জন করে এবং কোন পরিবর্তন ছাড়াই জিপিটি২র সংস্ লাম্বেডা এবং শিশুদের বই পরীক্ষার মাধ্যমে আমরা মডেলের প্রদর্শনের তুলনা করি এবং মডেল-তৈরি কর্মকর্তা বিবৃতি ব্যবহার না করে।', 'ca': "Els Models de Llingua són el fons de totes les tasques modernes de Procesament de Llingua Natural (NLP). L'introducció de l'arquitectura dels transformadors ha contribuït significativament a fer que la Modellació de Llingua sigui molt efectiva en moltes tasques de la NLP, i ha portat a avanços significatius en aquest camp. Tot i així, els transformadors tenen un gran cost computacional, que creix quadràticament en relació amb la llargada d'entrada. Això representa un repte per entendre els llargs textos requereix molt context. En aquest article, proposem un marc d'ajustes fins, anomenat CoreLM, que estendra l'arquitectura dels models de llenguatge pretrained actuals de manera que incorporen informació explícita de l'entitat. Introducint representacions d'entitats, fem disponible informació for a de l'espai contextual del model, que resulta en un model de llenguatge millor per una fracció del cost computacional. Implementam el nostre enfocament fent servir GPT2 i comparem el model ajustat amb l'original. El nostre model proposat aconsegueix una menor Perplexitat en els conjunts de dades GUMBY i LAMBDADA en comparació amb GPT2 i una versió fina de GPT2 sense canvis. També comparem el desempeny dels model s en termes de Precisió en LAMBADA i el Test de llibres infantils, amb i sense l'ús d'anotacions de coreferença creades per model.", 'et': 'Keelemudelid on kõigi kaasaegsete looduskeelte töötlemise (NLP) ülesannete aluseks. Transformerite arhitektuuri kasutuselevõtt on aidanud oluliselt kaasa keele modelleerimise väga tõhusaks muutmisele paljudes NLP ülesannetes, mis on viinud oluliste edusammudeni valdkonnas. Transformeritel on siiski suur arvutuskulu, mis kasvab sisendi pikkuse suhtes kvartaalselt. See kujutab endast väljakutset, sest pikkade tekstide mõistmine nõuab palju konteksti. Käesolevas dokumendis pakume välja Fine-Tuning raamistiku nimega CoreLM, mis laiendab praeguste eelnevate keelemudelite arhitektuuri nii, et need sisaldavad selgesõnalist olemiteavet. Üksuste esituste tutvustamisega teeme kättesaadavaks informatsiooni väljaspool mudeli kontekstiruumi, mille tulemuseks on parem keelemudel murdosa arvutuskulust. Rakendame oma lähenemisviisi GPT2 abil ja võrdleme täpsustatud mudelit originaaliga. Meie pakutud mudel saavutab GUMBY ja LAMBDADA andmekogumite väiksema Perplexity võrreldes GPT2ga ja GPT2 peenhäälestatud versiooni ilma muudatusteta. Samuti võrdleme mudelite täpsust LAMBADA ja lasteraamatutesti puhul, kasutades mudeli loodud kordferentsimärkusi ja ilma.', 'hy': 'Լեզվի մոդելները հիմնականում են բոլոր ժամանակակից բնական լեզվի վերլուծության (ՆԼՊ) խնդիրների վրա: Փոփոխակերպիչների ճարտարապետության ներդրումը նշանակալի նշանակություն է դարձրել լեզվի մոդելը շատ արդյունավետ շատ ՆԼՊ խնդիրների ընթացքում, ինչը հանգեցնում է նշանակալի առաջընթաց այս ոլորտում: Այնուամենայնիվ, տրանֆորմերները ունեն մեծ հաշվարկների արժեքը, որը քառակուսին աճում է ներմուծի երկարության հարաբերությամբ: Սա մարտահրավեր է առաջացնում, որովհետև երկար տեքստներ հասկանալը շատ կոնտեքստ է պահանջում: Այս թղթի մեջ մենք առաջարկում ենք մի լավ հարմարեցման շրջանակ, որը կոչվում է coreLM, որը ընդլայնում է ներկայիս նախապատրաստված լեզվի մոդելների ճարտարապետությունը, որպեսզի դրանք ներառեն բացատրական անհատականության տեղեկատվություն: By introducing entity representations, we make available information outside the contextual space of the model, which results in a better Language Model for a fraction of the computational cost.  Մենք կիրառում ենք մեր մոտեցումը GPT2-ի օգնությամբ և համեմատում ենք բարձրացված մոդելը օրինակի հետ: Մեր առաջարկած մոդելը հասնում է ավելի ցածր PerPLեքսիվություն ԳՈՄԲԻ և ԼԱՄԲԴԱԴԱ տվյալների համակարգերի մեջ, երբ համեմատում է GPT2-ին և GPT2-ի բարձրակարգված տարբերակին առանց որևէ փոփոխության: Մենք նաև համեմատում ենք մոդելների արտադրությունը ԼԱՄԲԱԴԱ-ի և Երեխաների գրքի թեստերի ճշգրտության տեսանկյունից, մոդելների ստեղծված համեմատական նշումների օգտագործման հետ և առանց դրանից:', 'bs': 'Modeli jezika su pod temeljem svih modernih zadataka prirodnog procesa jezika (NLP). Uvedenje arhitekture transformera značajno je doprinijelo da se obrazovanje jezika vrlo efikasno čini u mnogim zadacima NLP-a, što vodi do značajnih napredak na terenu. Međutim, transformeri dolaze sa velikim računalnim troškovima, koja se kvadratično raste u odnosu na dužinu ulaza. To predstavlja izazov u razumijevanju dugih tekstova zahtijeva mnogo konteksta. U ovom papiru predlažemo okvir za fino prilagođenje, po imenu CoreLM, koji proširi arhitekturu trenutnih modela jezika Pretrained kako bi uključili pojasne informacije o entitetu. Predstavljajući predstave entiteta, pružamo dostupne informacije izvan kontekstnog prostora model a, što rezultira boljim jezičkim modelom za dijelom računalnih troškova. Mi implementiramo naš pristup koristeći GPT2 i uspoređujemo dobar model sa originalom. Naš predloženi model postiže niži Perplexity u GUMBY i LAMBDADA datasetima u usporedbi sa GPT2 i fino određenom verzijom GPT2 bez ikakvih promjena. Također uspoređujemo izvršnost modela u smislu preciznosti u testu LAMBADA i dječje knjige, sa i bez upotrebe navodnih pristojnih annotacija stvorenih modela.', 'fi': 'Kielimallit ovat kaikkien nykyaikaisten Natural Language Processing (NLP) -tehtävien perusta. Transformers-arkkitehtuurin käyttöönotto on vaikuttanut merkittävästi kielimallinnuksen tehokkuuteen monissa NLP-tehtävissä, mikä on johtanut merkittäviin edistysaskeliin alalla. Muuntajilla on kuitenkin suuri laskennallinen kustannus, joka kasvaa neliöllisesti suhteessa syöttöpituuteen. Tämä on haaste, sillä pitkien tekstien ymmärtäminen vaatii paljon kontekstia. Tässä työssä ehdotamme CoreLM-nimistä Fine-Tuning -kehystä, joka laajentaa nykyisten esikoulutettujen kielimallien arkkitehtuuria siten, että ne sisältävät eksplisiittiset entiteettitiedot. Esittämällä entiteettiesityksiä tarjoamme tietoa mallin kontekstuaalisen tilan ulkopuolella, mikä johtaa parempaan kielimalliin murto-osalla laskennallisista kustannuksista. Toteutamme lähestymistapamme GPT2:n avulla ja vertaamme hienosäädettyä mallia alkuperäiseen. Ehdotetulla mallilla saavutetaan pienempi Perplexity GUMBY- ja LAMBDADA-aineistoissa verrattuna GPT2-aineistoon ja hienosäädettyyn GPT2-versioon ilman muutoksia. Vertailemme myös mallien suorituskykyä LAMBADA- ja Lastenkirjatestin tarkkuuden suhteen mallien luomalla koreferenssimerkinnällä ja ilman sitä.', 'cs': 'Jazykové modely jsou základem všech moderních úloh zpracování přirozeného jazyka (NLP). Zavedení architektury Transformers významně přispělo k tomu, aby jazykové modelování bylo velmi efektivní napříč mnoha úkoly NLP, což vedlo k významnému pokroku v oboru. Transformátory však přicházejí s velkými výpočetními náklady, které rostou kvadraticky s ohledem na vstupní délku. To představuje výzvu, protože porozumět dlouhým textům vyžaduje mnoho kontextu. V tomto článku navrhujeme jemné ladění frameworku s názvem CoreLM, který rozšiřuje architekturu současných předtrénovaných jazykových modelů tak, aby zahrnovaly explicitní informace o entitách. Zavedením reprezentace entit zpřístupníme informace mimo kontextový prostor modelu, což vede k lepšímu jazykovému modelu za zlomek výpočetních nákladů. Náš přístup implementujeme pomocí GPT2 a porovnáváme jemně vyladěný model s originálem. Náš navržený model dosahuje nižší Perplexity v datových sadách GUMBY a LAMBDADA ve srovnání s GPT2 a jemně vyladěnou verzí GPT2 bez jakýchkoli změn. Dále porovnáváme výkonnost modelů z hlediska přesnosti v LAMBADA a Dětském knižním testu, s a bez použití modelově vytvořených koreferenčních anotací.', 'sk': 'Jezikovni modeli so temelj vseh sodobnih nalog obdelave naravnega jezika (NLP). Uvedba arhitekture transformatorjev je bistveno prispevala k temu, da je jezikovno modeliranje zelo učinkovito pri številnih nalogah NLP, kar je privedlo do znatnega napredka na tem področju. Vendar pa transformatorji prihajajo z velikimi računalniškimi stroški, ki rastejo kvadratno glede na dolžino vhoda. To predstavlja izziv, saj razumevanje dolgih besedil zahteva veliko konteksta. V tem prispevku predlagamo okvir fine-tuning, imenovan CoreLM, ki razširi arhitekturo sedanjih predtreniranih jezikovnih modelov tako, da vključujejo eksplicitne informacije o entitetah. Z uvedbo predstavitev entitet dajemo na voljo informacije zunaj kontekstnega prostora modela, kar rezultat je boljši jezikovni model za delček računalniških stroškov. Naš pristop izvajamo z uporabo GPT2 in natančno nastavljen model primerjamo z originalom. Naš predlagani model dosega nižjo Perpleksiteto v naborih podatkov GUMBY in LAMBDADA v primerjavi z GPT2 in fino nastavljeno različico GPT2 brez kakršnih koli sprememb. Primerjamo tudi učinkovitost modelov v smislu natančnosti pri LAMBADA in testu otroških knjig z in brez uporabe modelov ustvarjenih koreferenčnih opomb.', 'ha': "@ action: button An ƙara wa ¦akirin Mai Transformers' na ƙara muhimmin ya sami muhimmin su aikata Modelling na Lugha mai amfani da shi a kowace aikin NLP mai yawa, kuma yana ƙara masu gabatar da amfani masu girma a birnin. Ina kasa, Transformers za su zo da wani abu mai girma na lissafa, wanda yana ƙara da gwargwadon gaske. Wannan yana bãyar da wani yanki dõmin ka fahimta matsayin kwanan kuma ma'anar mutane ne. Ga wannan takardan, Munã buɗa wani firam mai kyautata-Tuning, sunan CoreLM, wanda ke shimfiɗa matsayin da Modellun da aka yi wa zaman Aljani na Fasahan Lugha don su shigar da maɓalli bayyananne. Ina iya ƙara wa masu tsari da halin, za mu sami bayan fili wanda ke cikin shirin ayuka na guda, wanda ke ƙara shi da zama mafi alhẽri a Motel na harshe wa ɗan rabon nau'in lissafi. Yana amfani da GPT2 kuma muna daidaita misalin da aka samar da shi na farko. Shirin da aka buɗa shi ya sami wata ƙaranci Perfeksiya cikin GUMY da MAMADADA da tsari da aka sammenliki GPT2 da wani version mai kyau na GPT2 bã da musanyawa ba. Kamar misãlan misalin misalin misãlai da aka samã shi a cikin jarrabi na LalabADA da ɗiyan Littafin, ko kuma bã zã mu yi amfani da ko-abubuwa da misãlai-wanda aka halitta.", 'he': 'דוגמני שפת הם מרכז כל משימות תהליך שפת טבעית מודרניות (NLP). ההצגה של הארכיטקטורה של הטרנספורטרים תורמה משמעותית לגרום למודל שפה יעיל מאוד במשימות רבות של NLP, מה שמוביל להתקדמות משמעותיות בשטח. בכל אופן, Transformers מגיעים עם עלות מחשבית גדולה, אשר גדלה ברובע בנוגע לאורך הכניסה. זה מציג אתגר להבין טקסטים ארוכים דורש הרבה קשר. בעיתון הזה, אנו מציעים מסגרת התאמה היטב, בשם CoreLM, שמארכה את הארכיטקטורה של מודלים לשפה מתאמנים הנוכחים כך שהם מכילים מידע ישות ברור. על ידי הצגת מייצגים של יחידות, אנו מכניסים מידע זמין מחוץ לחלל הקונטקטי של המודל, מה שמוביל במדל שפה טוב יותר עבור חלק מהמחיר. We implement our approach using GPT2 and compare the fine-tuned model to the original.  Our proposed model achieves a lower Perplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a fine-tuned version of GPT2 without any changes.  אנחנו משווה גם את ההופעה של הדוגמנים במונחים של מדויקת בלאמבאדה ובדיקת ספר הילדים, עם ובלי השימוש בהערכות התאמה שנוצרו על ידי דוגמנים.', 'jv': 'structural navigation Ngubah akeh sing dibenakake architecture Transformer dumadhi luwih operasi kanggo nggawe Model Language sing apik efes karo akeh operasi NLP, dadi bisa bantuan akeh bantuan kanggo awak dhéwé. Name Iki iso mulai perbudhakan kanggo ngerasai nggo ngerasai textil sing takon akeh sampek. Nang pepulan iki, kita supoyata sistem Fine-Tuning, nganggo coreLM, sing nambah Arkturaturatura kanggo modèle denis-denis Language Modes nggawe nguasakno iki dadi ono mulasah informasi layang kelas. Nambah nambah kelompok Entire Awak dhéwé ngeweji sistem sing nêmên GP2 karo nggawe model sing dibenalke nggawe barang tanggal nggo awak dhéwé. Kita pergunakake model sing gawe perpliksi sing klêrung nêmên ning guMBY karo LAMBDEDa kuwi nggawe dataset dadi kapan nggo nggawe ngubah kang GP2 karo versi sing dibenalke tanggal GP2 lan akeh barêng-barêng kuwi mau. Awak dhéwé nganggo perusahaan dengané model nang titimbang kelangan apakno karo LAMBANA karo Manus Bocah sing nganggo, lan ngono nggawe model sing bisa ngelarane eferadhé sing apik dadi nyong.', 'bo': 'སྐད་ཡིག་མ་དབྱིབས་འདི་moderག་རྒྱུན་ལྡན་ཆ་ལས་སྦྱོར་བའི་བྱ་འགུལ་གྱི་རྒྱབ་གཞུང་ཡིན། The introduction of the Transformers architecture has significantly contributed in to making Language Modeling very effective across many NLP task, leading to significant advancements in the field. ཡིན་ནའང་། བཟོ་བཅོས་པ་དེ་ནི་རྩིས་འཁོར་གྱི་སྐྱེས་ཚད་ཆེན་པོ་ཞིག་ཡིན་པས། འདིས་ཡི་གེ་རིང་ཡིག་རིང་ལ་རྟོང་བའི་སྐད་ཡིག་རིང་ལ་དཀའ་ངལ་ཞིག་བྱེད་ཀྱི་ཡོད། In this paper, we propose a Fine-Tuning framework, named CoreLM, that extends the architecture of current Pretrained Language Models so that they incorporate explicit entity information. དབུལ་གྱི་མིང་ཚུལ་སྟོན་པ་ལས་བརྗོད་ཐུབ་ན། འུ་ཅག་གིས་རྣམ་གྲངས ང་ཚོས་GPT2་སྤྱོད་བཞིན་པའི་ཐབས་ལམ་ལ་ལག་སྟར་བྱེད་པ་ལས་སྔོན་སྒྲིག་བཟོ་བྱས་པའི་མ་དཔེ་དབྱིབས་དང་མཉམ་སྒྲི Our proposed model achieves a lower Perplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a fine-tuned version of GPT2 without any changes. ང་ཚོས་LAMBADA དང་ཕྲུག'}
{'en': 'On Generalization in ', 'ar': 'في التعميم في Coreference Resolution', 'es': 'Sobre la generalización en la resolución de correferencias', 'fr': 'Sur la généralisation dans la résolution de coréférence', 'pt': 'Sobre Generalização na Resolução de Correferência', 'zh': '其共推理解析中泛化', 'ja': 'コアリファレンス分解能の一般化について', 'hi': 'Coreference संकल्प में सामान्यीकरण पर', 'ru': 'Об обобщении в ключевом разрешении', 'ga': 'Ar Ghinearálú i Rún Croíthagartha', 'ka': 'გენერალიზაციის რეზიოციაში', 'el': 'Για τη γενίκευση στο ψήφισμα της συναδέλφου', 'hu': 'Általánosítás a Coreferencia-állásfoglalásban', 'it': 'Sulla generalizzazione nella risoluzione di Coreferenza', 'kk': 'Жалпы қасиеттердің Айырымдылығында', 'ms': 'Pada Jeneralisasi dalam Resolusi Coreference', 'ml': 'കോര്\u200dഫെന്\u200dസ് റിപ്പോര്\u200dഷനില്\u200d ജനറലേഷന്\u200d ചെയ്യുമ്പോള്\u200d', 'lt': 'Dėl bendrosios konferencijos rezoliucijos', 'mk': 'За генерализација во резолуцијата на кореференцијата', 'mn': 'Хэрэглэгчдийн шийдвэрлэлийн ерөнхийлөгч', 'ro': 'Cu privire la generalizarea în rezoluția Coreferenței', 'pl': 'W sprawie uogólnienia w rezolucji współpracy', 'mt': 'On Generalization in Coreference Resolution', 'sr': 'Na generalizaciji u rezoluciji korisnosti', 'so': 'Waxyaabaha guud ee koreference Resolution', 'no': 'På Generalisering i oppløysing av koreferansen', 'ta': 'திரைத்திறனில் பொதுவாக்குதலில்', 'si': 'ප්\u200dරමාණ විශේෂණයේ සාමාන්\u200dය විශේෂණය සඳහා', 'sv': 'Generalisering i Coreference-resolutionen', 'ur': 'قابل رخصت رخصت میں جرائنالیزی پر', 'uz': 'Name', 'vi': 'Về việc mời gọi giải quyết', 'bg': 'Относно обобщението в резолюцията на кореференцията', 'hr': 'O generalizaciji u rezoluciji korisnosti', 'nl': 'Over generalisering in de resolutie van de Coreferentie', 'da': 'Generalisering i Coreference-resolutionen', 'de': 'Zur Generalisierung in der Coreferenz Resolution', 'id': 'Pada Generalisasi dalam Resolusi Koreference', 'ko': '논공지 소해 중의 범화', 'fa': 'ШҜШұ ШӘЩҲЩ„ЫҢШҜ ЪҳЩҶШұШ§Щ„ ШҜШұ ШӯЩ„вҖҢШіШ§ШІЫҢ ЩҫЫҢШҙЩҶЩҮШ§ШҜ', 'sw': 'Katika Ujumla wa Mazingiro', 'af': 'Op Generalisasie in Hoofheidsoplossing', 'tr': 'Däşer Seçenekleri Çaşyrmakda', 'sq': 'Për gjeneralizimin në rezolutën e Koreferencës', 'am': 'ምርጫዎች', 'az': '캻fad톛 칂칬z칲n칲rl칲y칲nd톛 Generalizasyonda', 'bn': 'সাধারণ সংস্থা', 'cs': 'O obecnění v usnesení společné reference', 'bs': 'O generalizaciji u rezoluciji korisnosti', 'et': 'Korralduse resolutsiooni üldistamine', 'fi': 'Coreference-päätöslauselman yleistämisestä', 'hy': 'Կորեֆերանսի լուծումների ընդհանուր հաստատության մասին', 'ca': 'En la Generalització en la Resolució de Coreferència', 'jv': 'iku', 'sk': 'O splošnosti v resoluciji Coreference', 'ha': '@ action', 'he': 'על הגנרליזציה בפתרון הקבוצה', 'bo': 'མཐའ་དབྱིབས་གདམ་ཁ་ཚོགས་ནང་དུ་སྤྱིར་བཏང་བ'}
{'en': 'While ', 'fr': "Alors que la résolution de coréférence est définie indépendamment du domaine de l'ensemble de données, la plupart des modèles permettant d'effectuer une résolution de coréférence ne sont pas correctement transférés vers des domaines invisibles Nous consolidons un ensemble de 8 ensembles de données de résolution de coréférence ciblant différents domaines afin d'évaluer les performances standard des modèles. Nous mélangeons ensuite trois ensembles de données pour la formation\xa0; même si leur domaine, leurs directives d'annotation et leurs métadonnées diffèrent, nous proposons une méthode pour entraîner conjointement un seul modèle sur ce mélange de données hétérogènes en utilisant l'augmentation des données pour tenir compte des différences d'annotation et l'échantillonnage pour équilibrer les quantités de données. Nous constatons que dans un environnement de tir zéro, les modèles entraînés sur un seul ensemble de données transfèrent mal tandis que l'entraînement conjoint améliore les performances globales, ce qui conduit à une meilleure généralisation dans les modèles de résolution de coréférence. Ce travail constitue une nouvelle référence en matière de résolution de coréférence robuste et de multiples nouveaux résultats de pointe.", 'es': 'Si bien la resolución de correferencia se define independientemente del dominio del conjunto de datos, la mayoría de los modelos para realizar la resolución de correferencias no se transfieren bien a dominios no visibles. Consolidamos un conjunto de 8 conjuntos de datos de resolución de correferencia dirigidos a diferentes dominios para evaluar el rendimiento estándar de los modelos. Luego, mezclamos tres conjuntos de datos para la capacitación; aunque su dominio, las pautas de anotación y los metadatos difieren, proponemos un método para entrenar conjuntamente un solo modelo en esta mezcla de datos heterogénea mediante el uso del aumento de datos para tener en cuenta las diferencias de anotación y el muestreo para equilibrar las cantidades de datos. Encontramos que en un entorno de tiro cero, los modelos entrenados en un solo conjunto de datos transfieren de manera deficiente, mientras que el entrenamiento conjunto produce un mejor rendimiento general, lo que lleva a una mejor generalización en los modelos de resolución de correferencia. Este trabajo aporta un nuevo punto de referencia para una resolución de correferencia sólida y múltiples resultados nuevos de última generación.', 'pt': 'Embora a resolução de correferência seja definida independentemente do domínio do conjunto de dados, a maioria dos modelos para realizar a resolução de correferência não se transfere bem para domínios não vistos. Consolidamos um conjunto de 8 conjuntos de dados de resolução de correferência direcionados a diferentes domínios para avaliar o desempenho de modelos prontos para uso. Em seguida, misturamos três conjuntos de dados para treinamento; mesmo que seu domínio, diretrizes de anotação e metadados sejam diferentes, propomos um método para treinar em conjunto um único modelo nessa mistura de dados heterogênea usando aumento de dados para levar em conta as diferenças de anotação e amostragem para equilibrar as quantidades de dados. Descobrimos que, em uma configuração de tiro zero, os modelos treinados em um único conjunto de dados transferem mal, enquanto o treinamento conjunto produz um desempenho geral aprimorado, levando a uma melhor generalização em modelos de resolução de correferência. Este trabalho contribui com um novo benchmark para resolução de correferência robusta e vários novos resultados de última geração.', 'ar': 'بينما يتم تحديد دقة المرجع بشكل مستقل عن مجال مجموعة البيانات ، فإن معظم النماذج الخاصة بأداء دقة المرجع لا تنتقل بشكل جيد إلى المجالات غير المرئية. نقوم بدمج مجموعة من 8 مجموعات بيانات ذات دقة مرجعية تستهدف مجالات مختلفة لتقييم الأداء الجاهز للنماذج. ثم نمزج ثلاث مجموعات بيانات للتدريب ؛ على الرغم من اختلاف المجال وإرشادات التعليقات التوضيحية والبيانات الوصفية ، فإننا نقترح طريقة للتدريب المشترك لنموذج واحد على مزيج البيانات غير المتجانسة هذا باستخدام زيادة البيانات لحساب اختلافات التعليقات التوضيحية وأخذ العينات لموازنة كميات البيانات. نجد أنه في إعداد اللقطة الصفرية ، فإن النماذج المدربة على نقل مجموعة بيانات واحدة بشكل سيئ بينما يؤدي التدريب المشترك إلى تحسين الأداء العام ، مما يؤدي إلى تعميم أفضل في نماذج دقة المرجع. يساهم هذا العمل في معيار جديد للقرار المرجعي القوي ونتائج متعددة جديدة على أحدث طراز.', 'ja': 'コアレファレンス分解能は、データセットドメインとは独立して定義されていますが、コアレファレンス分解能を実行するためのほとんどのモデルは、見えないドメインにうまく転送されません。異なるドメインを対象とした8つのコアレファレンス分解能データセットのセットを統合して、モデルの既製のパフォーマンスを評価します。次に、トレーニングのために3つのデータセットを混合します。ドメイン、注釈ガイドライン、およびメタデータが異なるにもかかわらず、注釈の違いを説明するためにデータ拡張を使用し、データ量のバランスを取るためにサンプリングすることによって、この異種データ混合物に関する単一のモデルを共同でトレーニングする方法を提案します。ゼロショット設定では、単一のデータセット転送でトレーニングされたモデルが不十分である一方、共同トレーニングでは全体的なパフォーマンスが向上し、コアレファレンス解像度モデルの一般化が向上することがわかります。この作業は、堅牢なコアリファレンス解決と複数の最新の結果のための新しいベンチマークに貢献します。', 'ru': 'Хотя разрешение керна определяется независимо от домена набора данных, большинство моделей для выполнения разрешения керна плохо переносятся в невидимые домены. Мы консолидируем набор из 8 наборов данных с разрешением керна, ориентированных на различные области, чтобы оценить стандартную производительность моделей. Затем мы смешиваем три набора данных для обучения; даже несмотря на то, что их область, руководящие принципы аннотирования и метаданные различаются, мы предлагаем метод совместного обучения одной модели на этой неоднородной смеси данных с использованием дополнения данных для учета различий аннотаций и выборки для сбалансирования объемов данных. Мы обнаружили, что в условиях нулевого выстрела модели, обученные передаче одного набора данных, плохо переносятся, в то время как совместное обучение дает улучшенную общую производительность, что приводит к лучшему обобщению в моделях разрешения ядра. Эта работа вносит вклад в новый эталон для надежного разрешения ядра и множественных новых современных результатов.', 'zh': '虽共推理解析独立集域义,然大抵用于行共推理解析之法,不能善传输于未见之域。 整合其异域者 8 共推理解析数集,以质其能。 然后混合三数集。 虽领域、注南与元数不同,然吾建一法,因用数以虑异采样以平数据量,而合练于异构混合物。 吾见零次之设也,单集上之传输不善,而合之以善,因而成之于共分辨率之泛化。 其事强大者共推理分辨率与数新之最先进者给之。', 'hi': 'जबकि coreference रिज़ॉल्यूशन डेटासेट डोमेन से स्वतंत्र रूप से परिभाषित किया गया है, coreference resolution करने के लिए अधिकांश मॉडल अनदेखी डोमेन में अच्छी तरह से स्थानांतरित नहीं होते हैं। हम मॉडल के ऑफ-द-शेल्फ प्रदर्शन का मूल्यांकन करने के लिए विभिन्न डोमेन को लक्षित करने वाले 8 कोरफेरेंस रिज़ॉल्यूशन डेटासेट के एक सेट को समेकित करते हैं। फिर हम प्रशिक्षण के लिए तीन डेटासेट मिश्रण करते हैं; भले ही उनके डोमेन, एनोटेशन दिशानिर्देश, और मेटाडेटा अलग-अलग होते हैं, हम डेटा वृद्धि का उपयोग करके इस विषम डेटा मिश्रण पर एक एकल मॉडल को संयुक्त रूप से प्रशिक्षित करने के लिए एक विधि का प्रस्ताव करते हैं एनोटेशन मतभेदों के लिए खाते में और डेटा मात्रा को संतुलित करने के लिए नमूनाकरण। हम पाते हैं कि एक शून्य-शॉट सेटिंग में, एकल डेटासेट हस्तांतरण पर प्रशिक्षित मॉडल खराब रूप से स्थानांतरित होते हैं जबकि संयुक्त प्रशिक्षण पैदावार ने समग्र प्रदर्शन में सुधार किया, जिससे कोरेफेरेंस रिज़ॉल्यूशन मॉडल में बेहतर सामान्यीकरण होता है। यह काम मजबूत coreference संकल्प और कई नए अत्याधुनिक परिणामों के लिए एक नया बेंचमार्क योगदान देता है।', 'ga': 'Cé go sainmhínítear taifeach croí-chomhdhála go neamhspleách ar fhearann na dtacar sonraí, ní aistrítear go maith go dtí fearainn nach bhfeictear an chuid is mó de na samhlacha chun réiteach croí-chomhdhála a dhéanamh. Comhdhlúthaímid sraith de 8 tacar sonraí réitigh croíchomhdhála a dhíríonn ar fhearainn éagsúla chun feidhmíocht as an tseilf na samhlacha a mheas. Ansin meascaimid trí thacar sonraí le haghaidh oiliúna; cé go bhfuil difríocht idir a bhfearann, treoirlínte anótála, agus meiteashonraí, molaimid modh chun samhail aonair a oiliúint ar an meascán sonraí ilchineálach seo trí úsáid a bhaint as méadú sonraí chun cuntas a thabhairt ar dhifríochtaí anótála agus sampláil chun na cainníochtaí sonraí a chothromú. Feictear dúinn i suíomh nialas lámhaigh, go n-aistríonn múnlaí oilte ar thacar sonraí amháin go dona, agus go mbíonn feabhas ar fheidhmíocht fhoriomlán ag torthaí comhoiliúna, rud a fhágann go mbíonn ginearálú níos fearr i múnlaí réitigh croífhreagartha. Cuireann an obair seo tagarmharc nua le haghaidh réiteach láidir croí-chomhdhála agus torthaí iolracha nua den scoth.', 'hu': 'Míg a coreferencia felbontást az adatkészlet tartományától függetlenül definiálják, a legtöbb modell a coreferencia felbontás végrehajtásához nem jut jól át láthatatlan tartományokra. A különböző tartományokat célzó 8 coreferencia felbontású adatkészletet konszolidálunk, hogy értékeljük a modellek nem használható teljesítményét. Ezután három adatkészletet keverünk össze a képzéshez; Annak ellenére, hogy tartományuk, jegyzetelési irányelvük és metaadataik eltérnek, javasoljuk egy módszert arra, hogy egyetlen modellt közösen képezzünk erről a heterogén adatkeverékről, adatbővítés alkalmazásával a jegyzetelési különbségek figyelembevételére és az adatmennyiségek kiegyensúlyozására. Úgy találjuk, hogy egy nullás beállításban az egyetlen adatkészletre képzett modellek rosszul továbbítanak, míg a közös képzés javítja az általános teljesítményt, ami a coreferencia felbontási modellek jobb általánosítását eredményezi. Ez a munka új referenciaértéket jelent a robusztus coreferencia felbontás és a több új, korszerű eredmény számára.', 'it': "Mentre la risoluzione di coreferenza è definita indipendentemente dal dominio del set di dati, la maggior parte dei modelli per eseguire la risoluzione di coreferenza non si trasferisce bene a domini invisibili. Consolidamo un set di 8 set di dati con risoluzione di coreferenza mirati a diversi domini per valutare le prestazioni off-the-shelf dei modelli. Mescoliamo quindi tre set di dati per la formazione; Anche se il loro dominio, le linee guida di annotazione e i metadati differiscono, proponiamo un metodo per formare congiuntamente un singolo modello su questa miscela eterogenea di dati utilizzando l'aumento dei dati per tenere conto delle differenze di annotazione e il campionamento per bilanciare le quantità di dati. Troviamo che in un'impostazione zero-shot, i modelli addestrati su un singolo set di dati si trasferiscono male mentre l'allenamento congiunto produce prestazioni complessive migliorate, portando a una migliore generalizzazione dei modelli di risoluzione della coreferenza. Questo lavoro contribuisce a un nuovo punto di riferimento per una risoluzione robusta della coreferenza e molteplici nuovi risultati all'avanguardia.", 'el': 'Ενώ η ανάλυση συνάφειας ορίζεται ανεξάρτητα από τον τομέα συνόλου δεδομένων, τα περισσότερα μοντέλα για την εκτέλεση της ανάλυσης συνάφειας δεν μεταφέρονται καλά σε αόρατους τομείς. Ενσωματώνουμε ένα σύνολο 8 συνόλων δεδομένων επίλυσης αλληλοδιαφορών που στοχεύουν σε διαφορετικούς τομείς για να αξιολογήσουμε την απόδοση των μοντέλων. Στη συνέχεια, αναμιγνύουμε τρία σύνολα δεδομένων για την κατάρτιση. Παρόλο που ο τομέας, οι κατευθυντήριες γραμμές σχολιασμού και τα μεταδεδομένα διαφέρουν, προτείνουμε μια μέθοδο για την κοινή εκπαίδευση ενός ενιαίου μοντέλου σε αυτό το ετερογενή μείγμα δεδομένων χρησιμοποιώντας την αύξηση δεδομένων για να υπολογίσουν τις διαφορές σχολιασμού και τη δειγματοληψία για να εξισορροπήσουν τις ποσότητες δεδομένων. Διαπιστώνουμε ότι σε μια ρύθμιση μηδενικής λήψης, μοντέλα εκπαιδευμένα σε ένα μόνο σύνολο δεδομένων μεταφέρονται ανεπαρκώς, ενώ η κοινή εκπαίδευση αποδίδει βελτιωμένη συνολική απόδοση, οδηγώντας σε καλύτερη γενίκευση στα μοντέλα ανάλυσης αλληλοδιαφορών. Η εργασία αυτή συμβάλλει σε ένα νέο σημείο αναφοράς για την εύρωστη ανάλυση της συνάφειας και πολλαπλά νέα αποτελέσματα τελευταίας τεχνολογίας.', 'mk': 'While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains.  Ние консолидираме сет 8 компјутери на податоци за резолуција на кореференција кои се насочени кон различни домени за проценка на изведувањето на моделите надвор од полицата. We then mix three datasets for training;  even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities.  Најдовме дека во седиште на нула снимка, моделите обучени за едно пренесување на податоци лошо, додека заедничката обука предизвикува подобрување на целокупната резултатност, што води до подобра генерализација на моделите за резолуција на конференцијата. This work contributes a new benchmark for robust coreference resolution and multiple new state-of-the-art results.', 'ka': 'თუმცა კონფერენციის რეზიციო განსაზღვრებულია მონაცემების დემომინისგან განსაზღვრებულია, ბევრი მოდელები კონფერენციის რეზიციოს გავაკეთებელად არ მუშაობს ჩვენ კონსოლიდირებული 8 წინასწორების მონაცემების კონსოლიდირება, რომლებიც განსხვავებული დიომენების მიზეზი, რომ მოდელების გამოკლებული კონსოციენტის შესახებ გადა შემდეგ ჩვენ სამი მონაცემების კონფიგურაციის შესახებ დავწყებთ; მათი დიომინი, ანოტაციის მინუსები და მეტადეტაციის განსხვავებულია, ჩვენ მინუსვთ ერთადერთი მოდელს ამ ჰეტეროგენური მონაცემების შემთხვევაზე ერთადერთი მოდულის შემწყვება, გამოყენებით მონაცემების აგგენტირება ჩვენ აღმოჩნეთ, რომ ნულ სტატის შენახვეში, მოდელები ერთი მონაცემების გადატანისაზე ცოტა, როცა ერთმანეთი განაცემების შესაძლებლობა უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ ეს სამუშაო ახალი ბანქმერტის შესახებ ძალიან წარმოდგენებისთვის და მრავალი ახალი წარმოდგენების შესახებ.', 'lt': 'Nors koreferencinė rezoliucija apibrėžiama nepriklausomai nuo duomenų rinkinio domeno, dauguma koreferencinės rezoliucijos atlikimo modelių netinka nematoms domenams. Sujungiame 8 duomenų rinkinius, skirtus skirtingoms sritims, kad būtų galima įvertinti modelių eksploatacinius rodiklius. Tada deriname tris mokymo duomenų rinkinius; nors jų sritis, anotacijos gairės ir metaduomenys skiriasi, mes siūlome metodą bendram vieno modelio mokymui šiame heterogeniškame duomenų mišinyje, naudojant duomenų didinimą, kad būtų atsižvelgta į anotacijos skirtumus ir mėginių ėmimą duomenų kiekiams balansuoti. We find that in a zero-shot setting, models trained on a single dataset transfer poorly while joint training yields improved overall performance, leading to better generalization in coreference resolution models.  Šis darbas prisideda prie naujo patikimos koreferencijos sprendimo ir kelių naujų naujausių rezultatų lyginamojo rodiklio.', 'ml': 'ഡാറ്റാസറ്റ് ഡോമെനിനെ സ്വാതന്ത്രമായി കോര്\u200dഫെന്\u200dസിന്\u200dറെ റിസ്റ്റല്\u200d നിര്\u200dണയിക്കുമ്പോള്\u200d, കോര്\u200dഫെന്\u200dസ് റിസ്റ്റല്\u200d പ മോഡലുകളുടെ ഓഫ് ഷെല്\u200dഫ് പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d വ്യത്യസ്തമായ ഡോമീനുകളെ ലക്ഷ്യം വരുത്തുന്ന 8 കോര്\u200dഫെന്\u200dസ് റെല്\u200dസല്\u200d ഡേറ പിന്നീട് പരിശീലനത്തിനായി മൂന്നു ഡാറ്റാസറ്റുകള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നു; അവരുടെ ഡൊമെയിന്\u200d, അഭിപ്രായശ്ചിത്രത്തിന്റെ വഴികാട്ടികള്\u200d, മെറ്റേഡാറ്റാ വ്യത്യാസങ്ങള്\u200d വ്യത്യസ്തമാണെങ്കിലും ഞങ്ങള്\u200d ഒരു മാറ്റം പരിശീലിപ്പിക്കുന്നത് ഈ ഹെറോ ഒരു പൂര്\u200dണ്ണമായ വെടിവെക്കുന്ന സെറ്റില്\u200d, ഒരു ഡാറ്റാസേറ്റ് മാറ്റങ്ങളില്\u200d പരിശീലിക്കപ്പെട്ട മോഡലുകള്\u200d തെറ്റായി പരിശീലനം നടത്തിയിരിക്ക ഈ ജോലി റോബോസ്റ്റ് കോര്\u200dഫെന്\u200dസ് റിസല്\u200dമെന്\u200dസിനുള്ള പുതിയ ബെങ്ക്മാര്\u200dക്ക് ചെയ്യുന്നു. പിന്നെ പുതിയ സ്ഥ', 'ms': 'Sementara resolusi rujukan ditakrif secara independen dari domain set data, kebanyakan model untuk melakukan resolusi rujukan tidak dipindahkan dengan baik ke domain yang tidak terlihat. Kami mengkonsolidasi set 8 set data resolusi koreferensi yang menargetkan domain yang berbeza untuk menilai prestasi off-the-shelf model. Kemudian kita campur tiga set data untuk latihan; walaupun domain, arah anotasi, dan metadata mereka berbeza, kami cadangkan satu kaedah untuk melatih bersama model tunggal dalam campuran data heterogene ini dengan menggunakan peningkatan data untuk menganggap perbezaan anotasi dan pengumpulan sampel untuk seimbang kuantiti data. Kami mendapati bahawa dalam seting tembakan sifar, model dilatih pada pemindahan set data tunggal kurang sementara pelatihan kongsi memberikan prestasi umum yang lebih baik, yang membawa kepada generalisasi lebih baik dalam model resolusi koreferensi. Kerja ini menyumbangkan tanda referensi baru untuk resolusi persamaan yang kuat dan pelbagai hasil state-of-the-art baru.', 'kk': 'Мұқсаттық айырымдылығы деректер жинақтау доменінен тәуелсіз анықталғанда, мұқсаттық айырымдылығын орындау үшін көпшілігі домендерге жақсы аударылмайды. Біз 8 сәйкестік айырмашылық деректер жиынын консолидациялау үшін басқа домендердің үлгілерін шектеу үшін басқа домендерді оқу үшін. Содан кейін бұл үш деректер жинағын біріктіреміз. Олардың домені, жаңарту бағыттаулары және метадеректері айырмаса да, біз деректердің сандарын баланстыру үшін деректерді көптеу үшін бір үлгісін біріктіру үшін, бір ретерген деректердің араласуын қолдануға арналадық. Біз нөл сүру баптауында бір деректер жиынының алмасуына оқылған үлгілері жалғастырып, біріктірілген оқыту үлгілері жалғастырып жатқан жұмыс істеу үлгілерінде жақсы жасайды. Бұл жұмыс құпты мәселелердің айырмашылығына және бірнеше жаңа күйінің нәтижесін жасайды.', 'pl': 'Chociaż rozdzielczość koreferencji jest definiowana niezależnie od domeny zestawu danych, większość modeli wykonywania rozdzielczości koreferencji nie jest dobrze przenoszona do niewidocznych domen. Konsolidujemy zestaw danych o rozdzielczości ośmiu współdzielczości skierowanych do różnych domen w celu oceny gotowej wydajności modeli. Następnie łączymy trzy zbiory danych dla szkoleń; Chociaż ich domena, wytyczne adnotacyjne i metadane różnią się od siebie, proponujemy metodę wspólnego szkolenia pojedynczego modelu na temat tej heterogenicznej mieszanki danych poprzez wykorzystanie rozszerzenia danych w celu uwzględnienia różnic adnotacyjnych i próbkowania w celu zrównoważenia ilości danych. Stwierdzimy, że w ustawieniach zerowych modele przeszkolone na pojedynczym zbiorze danych są źle przesyłane, podczas gdy wspólne treningi dają poprawę ogólnej wydajności, prowadząc do lepszego uogólnienia modeli rozdzielczości współdzielczej. Praca ta przyczynia się do nowego punktu odniesienia dla solidnej rozdzielczości współdziałania i wielu nowych, najnowocześniejszych wyników.', 'ro': 'În timp ce rezoluția coreferenței este definită independent de domeniul setului de date, majoritatea modelelor pentru efectuarea rezoluției coreferenței nu se transferă bine în domeniile nevăzute. Consolidăm un set de 8 seturi de date cu rezoluție de corefență care vizează diferite domenii pentru a evalua performanța off-the-shelf a modelelor. Apoi amestecăm trei seturi de date pentru formare; Chiar dacă domeniul lor, liniile directoare de adnotare și metadatele diferă, propunem o metodă de formare comună a unui singur model pe acest amestec de date eterogen prin utilizarea măririi datelor pentru a lua în considerare diferențele de adnotare și eșantionare pentru a echilibra cantitățile de date. Considerăm că, într-o setare zero-shot, modelele instruite pe un singur set de date transferă slab, în timp ce formarea comună oferă performanțe generale îmbunătățite, ducând la o mai bună generalizare a modelelor de rezoluție coreferență. Această lucrare contribuie la un nou punct de referință pentru rezoluția robustă a corefenței și multiple rezultate noi de ultimă generație.', 'mt': 'Filwaqt li r-riżoluzzjoni tal-koreferenza hija definita indipendentement mid-dominju tas-sett tad-dejta, il-biċċa l-kbira tal-mudelli għat-twettiq tar-riżoluzzjoni tal-koreferenza ma jittrasferixxux tajjeb għal dominji mhux osservati. Aħna nikkonsolidaw sett ta’ 8 settijiet ta’ dejta dwar ir-riżoluzzjoni tal-koreferenza mmirati lejn dominji differenti biex jevalwaw il-prestazzjoni off-the-shelf tal-mudelli. We then mix three datasets for training;  even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities.  Aħna nsibu li f’ambjent b’zero shot, mudelli mħarrġa fuq trasferiment ta’ sett wieħed ta’ dejta b’mod ħa żin filwaqt li taħriġ konġunt jirriżulta f’prestazzjoni globali mtejba, li twassal għal ġeneralizzazzjoni aħjar fil-mudelli ta’ riżoluzzjoni ta’ korreferenza. Dan ix-xogħol jikkontribwixxi għal punt ta’ riferiment ġdid għar-riżoluzzjoni robust a tal-koreferenza u għal diversi riżultati ġodda l-aktar avvanzati.', 'sr': 'Iako je rezolucija ljubaznosti definisana nezavisno od domena podataka, većina modela za izvršavanje rezolucije ljubaznosti ne prenose dobro u nevidljive domene. Konsolidiramo setu 8 podataka za rezoluciju pristojnosti koji ciljaju različite domene za procjenu izveštaja izveštaja modela. Onda pomiješamo tri seta podataka za obuku; Iako se njihova domena, uputstva za annotaciju i metadatove razlikuju, predlažemo metodu za zajedničku obuku jednog model a o ovoj heterogeneznoj mješavini podataka koristeći povećanje podataka kako bi se računalo za razlike za annotaciju i uzorke za ravnotežu količine podataka. Našli smo da u nulom snimanju, modeli koji su obučeni na jednom prenošenju podataka loše, dok zajednička obuka donosi poboljšanje ukupnog izvođenja, koji vodi do boljih generalizacije u modelima rezolucije. Ovaj rad doprinosi novim kriterijom za jaku rezoluciju pristojnosti i više novih rezultata umjetnosti.', 'no': 'Mens koreferanse oppløysing er definert uavhengig av datasettdomene, vil dei fleste modelane for å utføra koreferanse oppløysing ikkje overføra godt til ulike domene. Vi konsoliderer eit sett av 8 datasett for oppløysing av koreferansen som mål på ulike domene for å evaluere utgåva av hjelp av modeller. Vi blander derfor tre datasett for trening. Selv om dei domene, notasjonshjelpelinjene og metadata er forskjellige, foreslår vi ein metode for å kopla opplæring av eit enkelt modell på denne heterogeneske data-mixturen ved å bruka data-augmentasjon for å rekna på forskjeller på annotasjonar og samling for å balansera datakvantitetane. Vi finn at i eit nullsatt innstilling treng modeller på ein enkelt dataset overføring slik dårlig mens samanlig opplæring fører til forbetra overalt utvikling, som fører til bedre generellisering i høgreoppløysingsmodular. Dette arbeidet bidra til ein ny benchmarke for kraftig oppløysing av koreferansen og fleire nye resultat av kunsten.', 'mn': 'Хэдийгээр зөвхөн зөвхөн шийдвэрлэл өгөгдлийн хэлбэрээс ялгаагүй тодорхойлдог ч ихэнх загвар нь зөвхөн тодорхойлдоггүй хэлбэрээр шийдвэрлэлт хийх загварууд сайн харагдахгүй Бид 8 сайхан шийдвэрлэлийн өгөгдлийн сангуудыг удирддаг. Загваруудын ажиллагааг үнэлэхэд өөр загваруудыг зориулдаг. Дараа нь бид 3 өгөгдлийн санг сургалтын тулд цуглуулдаг. Хэдийгээр бид өгөгдлийн хэмжээсүүдийг баланслахын тулд өгөгдлийн нэмэгдүүлэлтийг ашиглаж өгөгдлийн нэмэгдүүлэлтийг ашиглаж өгөгдлийн загвар, мета өгөгдлийн хэмжээсүүдийг баланслахын тулд нэг загвар суралцах боломжтой. Нэг өгөгдлийн сангийн шинжлэх ухаан дээр сургалтын загварууд нь хамтдаа сургалтын үр дүнд бүх үйл ажиллагааг улам сайжруулж, эсрэг шийдвэрлэлтийн загваруудыг илүү ерөнхийлөгчилж чадна. Энэ ажлын хувьд хүчтэй сайхан шийдвэрлэлийн шийдвэрлэлийн шинэ багц болон олон шинэ урлагийн үр дүн үүсгэдэг.', 'si': 'කෝරෙෆෙරෙන්ස් රිසෝල්යුෂන් දත්ත සැට් ඩෝමේන් වලින් ස්වයංක්\u200dරියාවක් විශේෂ කරලා තියෙන්නේ, බොහෝ මොඩේ අපි කොන්සෝලිඩ් කරනවා කෝරෙෆෙරෙෆෙන්ස් රිසෝල්යුෂ් දත්ත සෙට්ටුවක් වෙනස් ඩෝමේන්ස්ට් ලක්ෂණය කරනවා මොඩේ ඊට පස්සේ අපි දත්ත සෙට් තුනක් ප්\u200dරශ්නයක් වෙනුවෙන්. ඒ වගේම ඔවුන්ගේ ඩෝමේන්, අනුවාර්ථන ප්\u200dරවේශය, මෙටාඩේටා වෙනස් වෙනස් වුනොත්, අපි ප්\u200dරවේශයක් සම්බන්ධ වෙනුවෙන් ප්\u200dරවේශය කරන්න ප්\u200dරවේශය කරනවා මේ  අපිට හොයාගන්න පුළුවන් විදිහට සුන්ධ වෙඩි තියෙන්නේ, මොඩේල් එක්ක දත්ත සැට් එකක් විදිහට පරීක්ෂා කරලා තියෙන්නේ සාමාන්\u200dය ප්\u200dරේෂ මේ වැඩේ අළුත් බෙන්ච්මාර්ක් එකක් සම්බන්ධ විශේෂණය සහ අළුත් ස්ථානය ප්\u200dරතිචාරයක් සම්බන්ධ වෙන', 'so': 'Inta lagu qorayo go’aanka kaararka oo iskaa u gaar ah gudaha macluumaadka, tusaalooyin badan oo lagu sameeyo qayb-qaadashada kaarka ma bedeli karo meelaha qarsoon. Waxaannu koobnaynaa koox 8 koox oo kala duduwan oo lagu talo galay meelo kala duduwan si aan u qiimeyno sameynta dabeecada. We then mix three datasets for training;  xitaa in kastoo ay ku kala duwan yihiin deegaankooda, hagitaanka caafimaadka iyo macluumaadka, waxaynu u soo jeedaynaa qaab ku tababarida wadajirka ah oo ku wada tababarida tusaale isku mid ah oo lagu isku xiriirayo macluumaadkan la isku xiriira marka lagu isticmaalo kordhiska data si loo xisaabiyo kala duwanaansho iyo tusaale ahaan si loo balansiyo qiimaha macluumaadka. Waxaynu heli nahay in qaab nuur ah lagu tababariyo samooyin lagu soo wareejiyo koobashada wadajirka ah ay kordhiso tababar-horumar oo dhan, waxaana ka horumarinaya qaababka ku saabsan qeybta. Shaqadaasu waxay leedahay habka cusub ee ku saabsan heshiiska qofka la isticmaalay iyo arimaha cusub ee farshaxanka.', 'sv': 'Koreferensupplösningen definieras oberoende av datauppsättningens domän, men de flesta modeller för att utföra coreferensupplösning överförs inte bra till osedda domäner. Vi konsoliderar en uppsättning av 8 datauppsättningar med coreferencelopplösning som riktar sig till olika domäner för att utvärdera modellernas prestanda. Vi blandar sedan tre dataset för utbildning; Även om deras domän, kommenteringsriktlinjer och metadata skiljer sig åt föreslår vi en metod för att gemensamt utbilda en enda modell på denna heterogena datablandning genom att använda dataförstärkning för att ta hänsyn till kommenteringsskillnader och sampling för att balansera datakvantiteterna. Vi finner att modeller som tränats på en enda datauppsättning i en noll-shot inställning överför dåligt medan gemensam träning ger förbättrad övergripande prestanda, vilket leder till bättre generalisering av coreference resolution modeller. Detta arbete bidrar med ett nytt riktmärke för robust coreferencelopplösning och flera nya toppmoderna resultat.', 'ta': 'குறிப்பு தெளிவுத்திறன் தகவல் அமைப்பு களத்தின் தனித்தனாக வரையறுக்கப்பட்டுள்ளது, பெரும்பாலான குறிப்பு தெளிவுத்திறனை ச நாம் மாதிரிகளின் செயல்பாட்டை மதிப்பிட 8 கோரின் தெளிவுத்திறன் தகவல் அமைப்புகளை சேர்க்க வேண்டும். பின்னர் பயிற்சிக்கு மூன்று தரவுத்தளங்களை கலக்குவோம். அவர்களுடைய களம், அறிவிப்பு வழிகாட்டிகள், மற்றும் metadata மாறுபட்டாலும், நாம் ஒரு முறையை ஒன்றாக பயிற்சி செய்ய ஒரு முறையாக, இந்த அடர்ந்த தரவு கலப்பில் ஒரு மாதிரியை பயன் ஒரு சூழ்நிலையான செயல்பாட்டில், ஒரே தரவுத்தளத்தை மாற்றும் மாதிரிகளில் பயிற்சி செய்யப்பட்டுள்ளது, ஒரு சேர்ந்த பயிற்சி மாற்றும் போது சே இந்த வேலை ரோப்ட் குறிப்பு தெளிவுத்திறன் மற்றும் பல புதிய நிலையில் கலை முடிவு', 'ur': 'حاﻻنکہ مہربانی رخصت ڈاٹ سٹ ڈومین کے بغیر تعریف کے طور پر تعریف کی جاتی ہے، اکثر مہربانی رخصت کرنے کے لئے مہربانی رخصت کے طور پر اچھی طرح غیب کی ڈومین کو ترغیر نہیں دیتے۔ ہم نے 8 مہربانی ریزیولوسٹ ڈیٹ سٹ کو متصل کیا ہے جو مختلف ڈومین کا موقع رکھتے ہیں کہ مدل کے غیر شالف فعالیت کا ارزش کریں۔ اس کے بعد ہم تین ڈیٹ سٹ کو تمرین کے لئے ملحق کرتے ہیں۔ اگرچہ ان کے دامنی، انٹوریٹ ہدایت لینڈ، اور متڈیٹ ڈیٹ ڈیٹ لینڈ مختلف ہوتے ہیں، ہم ایک طریقہ پیش کرتے ہیں اس طریقہ پر ایک متحدہ ڈیٹ میکسٹ پر ایک مدل کی آموزش کریں، اس طریقہ سے ڈیٹ اضافہ کرنے کے لئے ڈیٹ اضافہ کرنے کے ہم دیکھتے ہیں کہ ایک صفر-شٹ سٹینٹ میں، ایک ڈیٹ سٹ ترنسیٹ پر مطالعہ کیا گیا تھا، حالانکہ joint training yields improved overall performance, leading to better generalization in coreference resolution models. یہ کام ایک نئی بنچم مارک مضبوط مضبوط مضبوط رسولی کے لئے اور بہت سی نئی موقعیت کے نتائج کے لئے اضافہ کرتا ہے.', 'vi': 'Mặc dù có phải giải quyết khả năng cao được xác định độc lập với miền tập tin, nhưng hầu hết các mẫu để thực hiện giải quyết hạn mức cao không chuyển tốt đến miền không nhìn thấy. Chúng tôi củng cố một bộ dữ liệu tám khả năng giải quyết nhằm mục tiêu mỗi miền khác nhau để đánh giá hiệu suất của mô- đun. Sau đó chúng ta sẽ kết hợp ba bộ dữ liệu. Dù thuộc lĩnh vực, hướng dẫn ghi chú và siêu dữ liệu có khác nhau, chúng tôi đề xuất một phương pháp để cùng nhau huấn luyện một mô hình duy nhất về hỗn hợp dữ liệu khác nhau này bằng cách sử dụng sự gia tăng dữ liệu để tính to án sự khác nhau và lấy mẫu để cân bằng lượng dữ liệu. Chúng ta thấy các một cách chưa được chảy tới một bộ thống riêng rất xấu, trong khi sự giải trị của một bộ thống của một bộ thống một bộ trí đơn giải và tống tố Công việc này đóng góp một tiêu chuẩn mới cho quyết định khả năng chiến thắng mạnh mẽ và nhiều kết quả mới nhất.', 'uz': "Name Biz modellarni qiymatish uchun boshqa domenelarni qiymatlash uchun 8 ta ta ta'minlovchi ravishda foydalanuvchimiz. We then mix three datasets for training;  Agar ularning domen, taʼminlovchi qoidalari, metadata va taʼlumotlar tarkibini o'zgartirib boʻlishi kerak bo'lsa, biz bu yetarli maʼlumot tarkibida bir modelni birlashtirish usulini talab qilamiz va maʼlumot qiymatlarini o'zgartirish uchun maʼlumot yordamida foydalanish mumkin. Biz shunday o'zgarishni o'rganamiz, bitta maʼlumotlar tarjimasida o'rganish modellari yomon, bir bir xil taʼminlovchisi umumiy amalni bajaradi, va bir xil o'zgarish modellarida yaxshi o'zgartiradi. Name", 'bg': 'Докато резолюцията на кореференцията се определя независимо от домейна на набора от данни, повечето модели за извършване на резолюция на кореференцията не се прехвърлят добре към невидими домейни. Консолидираме набор от 8 набора от данни за разделителна способност, насочени към различни области, за да оценим ефективността на моделите. След това смесваме три набора данни за обучение; въпреки че техните области, насоки за анотация и метаданни се различават, ние предлагаме метод за съвместно обучение на един модел за тази хетерогенна смес от данни чрез използване на увеличаване на данните, за да се отчетат разликите в анотацията, и вземане на проби за балансиране на количествата данни. Установяваме, че при нулева обстановка моделите, обучени върху един набор от данни, се пренасят слабо, докато съвместното обучение дава подобрена цялостна производителност, което води до по-добро обобщаване на моделите за резолюция на кореференцията. Тази работа допринася за нов еталон за стабилна резолюция на кореференцията и множество нови най-съвременни резултати.', 'nl': 'Hoewel de coreferentie-resolutie onafhankelijk van het datasetdomein wordt gedefinieerd, worden de meeste modellen voor het uitvoeren van coreferentie-resolutie niet goed overgebracht naar onzichtbare domeinen. We consolideren een set van 8 coreference resolutie datasets die gericht zijn op verschillende domeinen om de standaard prestaties van modellen te evalueren. Vervolgens mengen we drie datasets voor training; Hoewel hun domein, annotatierichtlijnen en metadata verschillen, stellen we een methode voor om gezamenlijk één model te trainen op dit heterogene gegevensmengsel door data augmentation te gebruiken om rekening te houden met annotatieverschillen en sampling om de datahoeveelheden in evenwicht te brengen. We merken dat in een zero-shot setting modellen die zijn getraind op een enkele dataset slecht overdragen terwijl gezamenlijke training betere algehele prestaties oplevert, wat leidt tot een betere generalisatie in coreferentie resolutiemodellen. Dit werk draagt bij aan een nieuwe benchmark voor robuuste coreferentie resolutie en meerdere nieuwe state-of-the-art resultaten.', 'hr': 'Iako se rješenje liječnosti definira nezavisno od domena podataka, većina modela za provedbu rješenja liječnosti ne prenose dobro u nevidljive domene. Konsolidiramo niz 8 podataka za rješavanje pristojnosti koji ciljaju različite domene za procjenu izvanrednih učinka modela. Onda pomiješamo tri podatke za obuku; Iako se njihova domena, uputstva za annotaciju i metapodatke razlikuju, predlažemo metodu za zajedničku obuku jednog model a o ovoj heterogeneznoj mješavini podataka koristeći povećanje podataka kako bi se računalo o različitim annotacijom i uzorak za ravnotežu količina podataka. Pronašli smo da u nulom snimanju, modeli koji su obučeni na jednom prenošenju podataka loše, dok zajednička obuka donosi poboljšanje ukupnog učinka, dovedeći do bolje generalizacije u modele rješavanja pristojnosti. Ovaj rad doprinosi novim kriterijom za jaku rezoluciju dobrote i više novih rezultata umjetnosti.', 'da': 'Mens coreferenceopløsning defineres uafhængigt af datasæt domæne, overføres de fleste modeller til udførelse af coreferenceopløsning ikke godt til usynlige domæner. Vi konsoliderer et sæt af 8 datasæt med coreferenceopløsning målrettet mod forskellige domæner for at evaluere modellernes off-the-shelf ydeevne. Vi blander derefter tre datasæt til uddannelse; Selvom deres domæne, retningslinjer for noteringer og metadata er forskellige, foreslår vi en metode til i fællesskab at træne en enkelt model om denne heterogene datablanding ved at bruge dataforøgelse til at tage højde for annotationsforskelle og prøveudtagning for at balancere datamængderne. Vi finder, at modeller, der trænes på et enkelt datasæt, i en nulskudsindstilling, overføres dårligt, mens fælles træning giver forbedret samlet ydeevne, hvilket fører til bedre generalisering af coreferenceopløsningsmodeller. Dette arbejde bidrager med et nyt benchmark for robust coreferenceopløsning og flere nye state-of-the-art resultater.', 'de': 'Während die Coreferenz-Auflösung unabhängig von der Dataset-Domäne definiert wird, können die meisten Modelle zur Durchführung der Coreferenz-Auflösung nicht gut auf unsichtbare Domänen übertragen werden. Wir konsolidieren einen Satz von 8-Coreferenz-Auflösungsdatensätzen für verschiedene Domänen, um die Standardleistung von Modellen zu bewerten. Anschließend mischen wir drei Datensätze für die Ausbildung; Obwohl ihre Domäne, Annotationsrichtlinien und Metadaten unterschiedlich sind, schlagen wir eine Methode vor, um gemeinsam ein einziges Modell über diese heterogene Datenmischung zu trainieren, indem wir Daten-Augmentation verwenden, um Annotationsunterschiede zu berücksichtigen und Sampling, um die Datenmengen auszugleichen. Wir stellen fest, dass Modelle, die auf einem einzelnen Datensatz trainiert wurden, in einer Null-Schuss-Einstellung schlecht übertragen, während gemeinsames Training eine verbesserte Gesamtleistung liefert, was zu einer besseren Verallgemeinerung in Coreferenz-Auflösungsmodellen führt. Diese Arbeit leistet einen neuen Benchmark für robuste Coreferenzauflösung und mehrere neue State-of-the-Art Ergebnisse.', 'id': 'Sementara resolusi koreferensi didefinisikan secara independen dari domain set data, kebanyakan model untuk melakukan resolusi koreferensi tidak dipindahkan dengan baik ke domain yang tidak terlihat. Kami mengkonsolidasi set 8 set data resolusi koreferensi yang menargetkan domain yang berbeda untuk mengevaluasi prestasi off-the-shelf model. Kemudian kita campur tiga set data untuk latihan; meskipun domain mereka, arah anotasi, dan metadata berbeda, kami mengusulkan metode untuk bersama-sama melatih model tunggal pada campuran data heterogene ini dengan menggunakan peningkatan data untuk memperhitungkan perbedaan anotasi dan sampel untuk seimbang jumlah data. Kami menemukan bahwa dalam setting zero-shot, model dilatih pada satu set data transfer buruk sementara pelatihan kongsi memberikan prestasi umum yang lebih baik, yang menyebabkan generalisasi lebih baik dalam model resolusi koreferensi. Pekerjaan ini berkontribusi benchmark baru untuk resolusi koreferensi yang kuat dan beberapa hasil baru state-of-the-art.', 'fa': 'در حالی که راه حل رضایت به طور مستقل از حوزه\u200cهای مجموعه داده\u200cها تعریف می\u200cشود، بیشتر مدل\u200cها برای انجام راه حل رضایت رضایت به حوزه\u200cهای غیرقابل تغییر داده نمی\u200cشوند. ما مجموعه\u200cای از 8 تنظیم داده\u200cهای حل\u200cسازی که هدف\u200cهای دامنه\u200cهای مختلف را برای ارزیابی عملکرد مدل\u200cهای خارج از پناهگاه می\u200cدهیم. سپس سه مجموعه داده برای تمرین می\u200cکنیم، با وجود اینکه مدل، رهبری\u200cهای نوشته\u200cها و متداده\u200cها متفاوت می\u200cشوند، ما یک روش برای آموزش یک مدل در این ترکیب داده\u200cهای متفاوتی با استفاده از افزایش داده\u200cها برای حساب تفاوت\u200cهای نوشته\u200cها و نمونه\u200cهایی برای تعادل اندازه\u200cهای داده\u200cها پیشنهاد می\u200cکنیم. ما فهمیدیم که در یک تنظیمات صفر، مدل\u200cها در یک تنظیمات داده\u200cهای بد آموزش یافته\u200cاند، در حالی که تولید آموزش مشترک اجرات عمومی را بهتر می\u200cکند، که باعث می\u200cشود به بهترین تولید عمومی در مدل\u200cهای حل\u200cکننده\u200cای باشد. این کار یک مقدار جدید برای حل شدیدی از ارتباط و نتیجه\u200cهای جدیدی از هنر تولید می\u200cکند.', 'ko': '공지소해는 데이터 집합 영역에서 정의된 것이지만 공지소해를 실행하는 데 사용되는 대부분의 모델은 보이지 않는 영역으로 잘 옮겨지지 않는다.우리는 모델의 기존 성능을 평가하기 위해 서로 다른 분야에 대한 8개의 공지 소해 데이터 집합을 통합했다.그리고 우리는 세 개의 데이터 집합을 혼합하여 훈련을 진행한다.비록 그들의 역, 주석 지침과 메타데이터는 다르지만 우리는 이러한 이구 데이터 혼합에서 단일 모델을 연합하여 훈련하는 방법을 제시했다. 방법은 데이터의 확충을 이용하여 주석의 차이를 해석하고 샘플링을 통해 데이터의 양을 균형 있게 하는 것이다.우리는 영포 설정에서 단일 데이터 집합에서 훈련하는 모델의 전송 효과가 매우 나쁘고 연합 훈련은 전체적인 성능을 향상시켜 공지 소해 모델에서 더욱 좋은 범주화를 실현할 수 있음을 발견했다.이 작업은 안정된 공지 해소와 여러 개의 최신 결과에 새로운 기준을 제공했다.', 'sw': 'Wakati suluhisho la mafanikio linaelezwa huru ya tovuti ya taarifa, mifano mingi ya kutekeleza suluhisho la msingi hazihamishi vizuri kwenda ndani isiyo fichikana. Tunaweza kuunganisha seti ya taarifa za suluhisho la kompyuta 8 zinazolenga maeneo tofauti ili kutathmini utendaji wa mifano. Kisha tunachanganya seti tatu za taarifa kwa ajili ya mafunzo; even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities.  Tunapata kwamba katika mazingira ya picha sifuri, mifano iliyoendeshwa kwenye usafirishaji wa data moja kwa mbaya wakati mafunzo ya pamoja yanaongeza ufanisi wa jumla, na yanasababisha uzalishaji mzuri katika mifano ya ufumbuzi. Kazi hii inachangia bendera mpya kwa ajili ya suluhisho la mafanikio na matokeo mengi ya hali mpya ya sanaa.', 'tr': 'Karefleksiýa çözümlenme dataset domenyň özgürlügini tanyşdyrylýan halda, karefleksiýa çözümlenme üçin köp nusgalar daşyrmady. Biz 8 sany çekişmeler çözümlerini consolidatýarys. Farklı sahypalary nusgala etmek üçin nusgalar bar. Sonra okuw üçin üç sany veri setirini çaşyrýarys; Hatta onların domeny, duyurarlama düzenleri ve metadata farklı olmasına rağmen biz veri miktarlarını dengelemek için birlikte bir modeli eğitirmek için bir yöntemi teklif ediyoruz. 0-atjyk düzümlerinde, sanlaryň ýeke bir dataseti üýtgetmesinde ýok bir şekilde eğitilenen nusgalary tapýarys. Birleşik okuw taýýarlanmagyň hemme performansyny gowurak getirilýär we çözümler nusgalarynda has gowurak döredilýär. Bu işe güýçli ýüregiň çözümlerini we täze täze bir sanat netijesi üçin täze bir etiket täsirleýär.', 'af': "Terwyl koreferensieresolusie onveilig van datastel domein gedefinieer is, die meeste modele vir die uitvoer van koreferensieresolusie doen nie goed oordra na onversekende domeine nie. Ons konsoliseer 'n stel van 8 koreferensie oplossing datastelle wat verskillende domeine doen om die af-die-shelf-prestasie van modele te evalueer. Ons het dan drie datastel vir onderwerp gemeng; selfs al is hulle domein, annotasie gidsels, en metadata verskillig, ons voorstel 'n metode vir joint onderwerp van 'n enkele model op hierdie heterogeneese data gemeng deur data vergroot te gebruik om rekening vir annotasie verskillinge en verskillinge te bereik om die data quantiteite te balanse. Ons vind dat in 'n nul-skoot instelling, modele wat op 'n enkele datastel oordrag verkeerd is, terwyl saamste onderwerking vergeet het die hele prestasie verbeter, wat na beter generellisering in koreferensie-oplossing modele lei. Hierdie werk bydra 'n nuwe benchmark vir kragtige koreferensie-oplossing en veelvuldige nuwe staat-van-kuns-resultate.", 'am': 'ምንም እንኳን የኮርፌንቨርስቲ ግንኙነት ከዳታ ሳንተር ብልሃት የተረጋገጠ ሲሆን፣ ብዙዎቹ ምሳሌዎች የኮርፌንሬሽን ማስታወቂያውን ለመፈለግ በመልካም አይለውጡም፡፡ የዓይነቶች አካሄዱን ለማስተካከል የክፍለ ሥርዓት አካባቢ አካባቢ እናደርጋለን፡፡ ከዚያም ሦስት ዳታ ሰርተቶችን ለትምህርት እናጣብቃለን:: ምንም እንኳን አካሄዳቸው፣ ማስታወቂያው መሪ እና ማህተት ቢለዩም እንኳን፣ የዳታ ክፍተቶችን በማስተካከል እና የዳታ ክፍተቶችን ለመቆጣጠር እናሳውቃለን፡፡ በzero-shot ክፍል፣ በአንድ ዳታ-ሰርቨር ማቀናጃ ላይ የተማረ ምሳሌዎች በሙሉ ተማርኮ ይሻላል፡፡ ይህ ሥራ አዲስ የኮርፖስቲካ ማስታወቂያውን እና አዲስ የ-አርእስት ውጤቶች አዲስ አዲስ የአፍሪካ ውጤቶች ያሳያል፡፡', 'az': 'Mərhəmətli çözünürlük verilən qurğulu domena bağımsız tərzdə belirlənirsə, çox mərhəmətli çözünürlük etmək üçün modellər gözəl görünməyən domena tərəfindən keçirilməz. Biz 8 rəftar çözünürlük verilənləri birləşdiririk ki, modellərin dəyişikliyini değerləşdirmək üçün müxtəlif domenalar nişanlayırlar. Sonra təhsil üçün üç verilən qurğu karışırıq. Onların domeini, bildirim doğruluqlarını və metadata fərqli olmasına rağmen, biz bu heterogenel veri karışması barəsində bir modeli birlikdə təhsil etmək üçün məlumatları artırmaq və məlumatları müəyyən etmək üçün məlumatları hesablamaq üçün bir modeli təklif edirik. Sıfır-fəsad qurğularında, tək veri qurğularında təhsil edilən modellər pis bir dəyişiklikdə, birlikdə təhsil təhsil ürəklərinin bütün performanslarını daha yaxşı təhsil edir, daha yaxşı generalizasyon modellərdə təhsil edir. Bu işin yeni bir benchmark möhkəm mərhəmət çözünürlərini və çoxlu yeni mərhəmət sonuçlarını sağlar.', 'bn': 'যদিও কোরেফেন্সের রিসেশন ডাটাসেট ডোমেইনের স্বাধীনতা নির্ধারণ করা হয়, তবে কোরেফেন্সের সিদ্ধান্ত নির্ধারণের বেশীরভাগ ম মডেলের অফ-শেল্ফ প্রদর্শনের মূল্যের লক্ষ্য করার জন্য আমরা ৮টি কোরেফেন্সের রিলেশন ডাটাসেট সংশ্লিষ্ট করে দেই। তারপর আমরা প্রশিক্ষণের জন্য তিনটি ডাটাসেট মিশ্রণ করি; এমনকি যদিও তাদের ডোমেইন, বিশ্লেষণ নির্দেশ এবং মেটেডাটা বিভিন্ন ভিন্ন ভিন্ন, আমরা একত্রিত তথ্য মিশ্রিত একটি মডেল প্রশিক্ষণের জন্য একটি পদ্ধতি প্রস্তাব করি যেখানে  আমরা খুঁজে পেয়েছি যে একটি শূন্য গুলি ব্যবস্থায়, একটি ডাটাসেট ট ট্রান্সফারেশনে মডেল প্রশিক্ষণ করা হয়েছে, যেখানে যৌথ প্রশিক্ষণের ফলে সারাটার প্রয এই কাজটি রোবস্ট কর্ফেন্সের সিদ্ধান্তের জন্য নতুন বেনম্যার্ক এবং নতুন স্টেট-অফ-শিল্পের ফলাফলের জন্য প্রদান করে।', 'bs': 'Iako je rezolucija dobrote definisana nezavisno od domena podataka, većina modela za provedbu rješenja dobrote ne prenose dobro na nedostajene domene. Konsolidiramo setu podataka o rezoluciji 8 pristojnosti koji ciljaju različite domene da procjenjuju izvanrednu funkciju modela. Onda pomiješamo tri dataseta za obuku; Iako se njihova domena, uputstva za annotaciju i metadatove razlikuju, predlažemo metodu za zajedničku obuku jednog model a o ovoj heterogeneznoj mješavini podataka koristeći povećanje podataka kako bi se računalo o različitim annotacijom i uzorak za ravnotežu količina podataka. Pronašli smo da u nulom snimanju, modeli koji su obučeni na jednom prenošenju podataka loše, dok zajednička obuka donosi poboljšanje ukupnog učinka, koji vodi do boljih generalizacije u modelima rješavanja pristojnosti. Ovaj rad doprinosi novim kriterijom za jaku rezoluciju pristojnosti i više novih rezultata umjetnosti.', 'ca': "Mentre que la resolució de coreència es defineix independentment del domini del conjunt de dades, la majoria dels models per a fer la resolució de coreència no es transfereixen bé a dominis invisibles. Consolidem un conjunt de 8 conjunts de dades de resolució de coreferencia que s'apunten a dominis diferents per avaluar el rendiment off-shelf dels models. Ens barregem tres conjunts de dades per a formar-nos; encara que el seu domini, les directrices d'anotació i les metadades difereixin, proposem un mètode per formar conjuntament un únic model sobre aquesta mezcla heterogènia de dades utilitzant l'augmentació de dades per tenir en compte les diferències d'anotació i el recolliment de mostres per equilibrar les quantitats de dades. Trobem que en un entorn de fotografies zero, els models entrenats en un conjunt únic de dades transfereixen malament mentre que l'entrenament conjunt produeix millor rendiment global, portant a una millor generalització en els models de resolució de coreferença. Aquesta feina contribueix a un nou punt de referència per a una solució de coreferencia robusta i múltiples resultats més avançats.", 'cs': 'Zatímco rozlišení koreference je definováno nezávisle na doméně datové sady, většina modelů pro provádění koreference se nepřenáší dobře do neviděných domén. Konsolidujeme sadu osmi datových sad s rozlišením koreferencí zaměřených na různé domény, abychom vyhodnotili standardní výkon modelů. Poté smícháme tři datové sady pro školení; I když se jejich doména, anotační směrnice a metadata liší, navrhujeme metodu společného tréninku jediného modelu na této heterogenní datové směsi pomocí rozšíření dat k zohlednění anotačních rozdílů a vzorkování pro vyvážení množství dat. Zjišťujeme, že v nastavení nulového záběru se modely trénované na jedné datové sadě špatně přenášejí, zatímco společný trénink přináší lepší celkový výkon, což vede k lepší zobecnění modelů rozlišení koreferencí. Tato práce přináší nové měřítko pro robustní rozlišení koreferencí a několik nových nejmodernějších výsledků.', 'et': 'Kuigi kortereferentsi resolutsioon on määratletud sõltumatult andmekogumi domeenist, ei kandu enamik kortereferentsi resolutsiooni teostamise mudeleid hästi nähtamatutesse domeenidesse. Konsolideerime 8 erinevatele valdkondadele suunatud andmekogumi, et hinnata mudelite kasutusvalmis jõudlust. Seejärel segame koolituseks kolm andmekogumit; Kuigi nende valdkond, annoteerimisjuhised ja metaandmed erinevad, pakume välja meetodi, mille abil koolitada ühiselt üks mudel selle heterogeense andmesegu kohta, kasutades andmete suurendamist annoteerimise erinevuste arvessevõtmiseks ja valimi andmekoguste tasakaalustamiseks. Leiame, et null-shot seadistuses edastavad ühe andmekogumi jaoks koolitatud mudelid halvasti, samas kui ühistreening parandab üldist jõudlust, mis toob kaasa parema üldistamise kordferentsiresolutsiooni mudelites. See töö annab uue võrdlusaluse tugevale kortereferentsi resolutsioonile ja mitmetele uutele kaasaegsetele tulemustele.', 'sq': 'While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains.  Ne konsolidojmë një sërë 8 të dhënash të rezolutës së korreferencës që synojnë fusha të ndryshme për të vlerësuar performancën jashtë raftit të modeleve. We then mix three datasets for training;  edhe pse domenia e tyre, udhëzimet e anotacionit dhe metatë ndryshojnë, ne propozojmë një metodë për trajnimin e përbashkët të një modeli të vetëm në këtë përzierje heterogjene të të dhënave duke përdorur rritjen e të dhënave për të llogaritur ndryshimet e anotacionit dhe marrjen e mostrave për të balancuar sasitë e të dhënave. Ne zbulojmë se në një vendosje zero-shot, modelet e trajnuar në një transferim të vetëm të të dhënave keq ndërsa trajnimi i përbashkët jep përmirësim të performancës së përgjithshme, duke çuar në gjeneralizim më të mirë në modelet e zgjidhjes së korreferencës. Ky punë kontribuon në një pikë të re për zgjidhjen e fortë të korreferencës dhe rezultate të shumta të reja të gjendjes së lartë.', 'fi': 'Vaikka koreferenssin resoluutio määritellään datajoukon toimialueesta riippumatta, useimmat koreferenssin resoluution suorittamismallit eivät siirry hyvin näkymättömiin toimialueisiin. Yhdistämme kahdeksan eri toimialoille suunnatun koreferenssiresoluution datajoukon arvioidaksemme mallien suorituskykyä. Sitten sekoitamme kolme dataa koulutusta varten. Vaikka niiden toimialue, huomautussuunnitelmat ja metatiedot eroavat toisistaan, ehdotamme menetelmää, jolla voidaan yhdessä kouluttaa yksi malli tästä heterogeenisestä tietoseoksesta käyttämällä tietojen lisäystä merkintöjen erojen huomioimiseksi ja näytteenottoa tietomäärien tasapainottamiseksi. Havaitsemme, että nollalaukauksessa yksittäiseen aineistoon koulutetut mallit siirtyvät huonosti, kun taas yhteisharjoittelu parantaa yleistä suorituskykyä, mikä johtaa parempaan yleistymiseen koreferenssiresoluutiomalleissa. Tämä työ antaa uuden vertailukohdan vahvalle koreferenssiresoluutiolle ja useille uusille huippuluokan tuloksille.', 'hy': 'Մինչդեռ կորֆերենսի լուծումը սահմանվում է անկախ տվյալների համակարգի տիեզերքից, կորֆերենսի լուծումը կատարելու մոդելների մեծամասնությունը լավ չի փոխանցվում անտեսված տիեզերքին: Մենք կազմակերպում ենք 8 կորեֆերանսի լուծումների տվյալների համակարգ, որոնք նպատակացնում են տարբեր բնագավառների վրա մոդելների արտադրողականությունը գնահատելու համար: We then mix three datasets for training;  չնայած դրանց բնագավառին, annoտացիայի ուղղություններին և մետատվյալներին տարբերվում են, մենք առաջարկում ենք մի մեթոդ, որպեսզի միասին վերապատրաստենք մի մոդել տվյալների խառնուրդի մասին օգտագործելով տվյալների աճը annoտացիայի տարբերությունների հաշվի առնելու և նմուշների Մենք հայտնաբերում ենք, որ զրոյական նկարների ընթացքում, մոդելները, որոնք պատրաստված են միակ տվյալների համակարգի փոխանցման վրա, վատ են, մինչդեռ միասին պատրաստման արդյունքները բարելավում են ընդհանուր արդյունքները, ինչը հանգեցնում է ավելի լավ ընդհան Այս աշխատանքը ներդրում է նոր համեմատային արտահայտություն ուժեղ կորֆերենսի լուծումների և նոր բարձրագույն արդյունքների համար:', 'jv': 'When corefern Resolution is defined separately of dataset domain, all modes for effecting corefern Resolution do not transfer right to unseen domain. 2 Awak dhéwé ngewehi telu dataset kanggo tukang; iki -- [Ctrl-click to open a link in a popup window] and select a new key from the [Ctrl-click] button in the middle of the reference box. Awak dhéwé éntuk kuwi nggawe 0-0 saiki, model sing ditambah akeh nguasai perusahaan dataset sing gak bener, ngono nggawe kudu nggawe barang apik dhéwé, dadi nggawe ngubah Generalizasi model sing apik dhéwé. Ngubah iné kaé gunaké perusahaan kanggo nggawe geranggé hukum sing nggawe geranggap karo hal-hal sing paling-karang mbukak.', 'ha': "Waka da an bayyana juyin korsference an bayyana shi ɗai'a cikin tsarin database, masu yawa masu motsi wa da za'a aikata juyin shawara cire-bone ba su shige shi da alhẽri zuwa sauyen nan da ba'a sani ba. Tuna ƙara koɓa masu daidaita danna masu motsi na cire 8, don su yi amfani da dukka daban-daban, dõmin su canza tsarin-shelf-don-motsi. Sa'an nan kuma muna haɗa matsayin data uku dõmin wa'anar; Haƙĩƙa, kuma kõ dã shirin ayuka, da shirin ayuka da metadata sun sãɓã, sai mu buɗa wata hanyoyi wa shirin su yi wa shirin haɗi a kan wannan shirin da aka haɗa mutane da data ɗin tsohatarwa, ko da amfani da ƙaramako da data dõmin ya yi amfani da zane-zane-zane-zane ko kuma misali dõmin ya daidaita nau'in data. Muna gane cewa, a cikin tsarin sifiri-sifo, misãlai wanda aka yi wa tunkuɗe a kan transfer ɗin da aka saka bayan bayani, a lokacin da shirin haɗi ya ƙara mafarin aikin jumla, yana ƙara wa mafi kyau a cikin misãlai masu motsi na kure. Wannan aikin yana ƙara wani bangon na buƙata don rabon sararin bangon nan da aka samu mutane da fassarar-state-of-art.", 'he': 'למרות שהפתרון התאמה מוגדר באופן עצמאי משטח נתונים, רוב הדוגמנים לבצע פתרון התאמה לא מעבירים היטב לשטחים בלתי נראים. אנו קונצנצים קבוצה של 8 קבוצות נתונים של פיתרון קופורנציה שמתכוונים לתחומים שונים כדי להעריך ביצועים מחוץ למדף של דוגמנים. ואז אנחנו מערבבים שלושה קבוצות נתונים לאימון; למרות שהשטח שלהם, המדרגות להציאה, ומטאדאטה שונות, אנו מציעים שיטה לאימון יחד מודל אחד על תערובת הנתונים ההטרוגנית הזאת, על ידי השימוש בתעלות הנתונים כדי לחשבון על הבדלים בהציאה ומדוגמנים כדי לאזן את כמויות הנתונים. We find that in a zero-shot setting, models trained on a single dataset transfer poorly while joint training yields improved overall performance, leading to better generalization in coreference resolution models.  העבודה הזו תורמת נקודת רמז חדשה לפתרון חוזק של התאמה ומספר תוצאות חדשות.', 'sk': 'Čeprav je ločljivost jedrske reference opredeljena neodvisno od domene nabora podatkov, se večina modelov za izvajanje ločljivosti jedrske reference ne prenaša dobro na nevidne domene. Združujemo nabor osmih naborov podatkov o ločljivosti jedrske reference, ki so usmerjeni v različna področja, da bi ocenili učinkovitost modelov na trgu. Nato združimo tri nabore podatkov za usposabljanje; čeprav se njihova domena, smernice za opombe in metapodatki razlikujejo, predlagamo metodo za skupno usposabljanje enega modela o tej heterogeni mešanici podatkov z uporabo povečanja podatkov za upoštevanje razlik v opombeh in vzorčenje za uravnoteženje količin podatkov. Ugotovili smo, da se v nastavitvi ničelnega strela modeli, usposobljeni za en sam nabor podatkov, slabo prenašajo, medtem ko skupni trening prinaša izboljšano splošno zmogljivost, kar vodi do boljše generalizacije modelov ločljivosti koreference. To delo prispeva novo merilo za robustno ločljivost jedrske reference in več novih najsodobnejših rezultatov.', 'bo': 'While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains. ང་ཚོས་སྒྲིག་འཛུགས་གཙང་གཅད་གྱི་མིག་ཐང་གཙང་གཅད་ཀྱི་ཚད་ལྟར་བྱུང་བའི་སྒྲིག་ཡིག འོན་ཀྱང་ང་ཚོས་སློབ་གྲྭར་གྱི་གནད་སྡུད་ཚན་གསུམ་མཉམ་བྱེད་ཀྱི་ཡོད། even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities. The most important thing is that ང་ཚོས་ཀླད་པའི་སྒྲིག་འགོད་ཀྱི་རྣམ་པ་ཞིག་གིས་མཐུན་རྐྱེན་གྱིས་མིག ལས་ཀ་འདིས་བརྟན་པར་བཟོ་བྱེད་ཀྱི་ཡོད་ཚད་གསར་བ་ཞིག་གིས་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད།'}
