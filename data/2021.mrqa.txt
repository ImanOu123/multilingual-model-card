{'en': 'MFAQ : a Multilingual FAQ Dataset', 'ar': 'MFAQ: مجموعة بيانات الأسئلة الشائعة متعددة اللغات', 'fr': 'MFAQ\xa0: un jeu de données de FAQ multilingue', 'es': 'MFAQ: un conjunto de datos de preguntas frecuentes', 'pt': 'MFAQ: um conjunto de dados de perguntas frequentes multilíngues', 'zh': 'MFAQ:多言问题解答数集', 'ja': 'MFAQ ：多言語FAQデータセット', 'ru': 'MFAQ: многоязычный набор часто задаваемых вопросов', 'hi': 'MFAQ: एक बहुभाषी अकसर किये गए सवाल डेटासेट', 'ga': 'MFAQ: Tacar Sonraí Ceisteanna Coitianta Ilteangacha', 'ka': 'MFAQ: მრავალენგური FAQ მონაცემები', 'hu': 'MFAQ: többnyelvű GYIK adatkészlet', 'kk': 'MFAQ: көптеген FAQ деректер қоры', 'it': 'MFAQ: un set di dati multilingue FAQ', 'mk': 'Name', 'ms': 'MFAQ: Set Data FAQ Berbahasa', 'ml': 'MFAQ: ഒരു പല ഭാഷ FAQ ഡാറ്റാസറ്റ്', 'el': 'MFAQ: ένα πολύγλωσσο σύνολο δεδομένων FAQ', 'mn': 'MFAQ: олон хэлний FAQ өгөгдлийн санг', 'mt': 'MFAQ: a Multilingual FAQ Dataset', 'no': 'MFAQ: ein fleirspråk FAQ- databaser', 'sr': 'MFAQ: Multilingual FAQ Dataset', 'ro': 'MFAQ: un set de date multilingv de întrebări frecvente', 'pl': 'MFAQ: wielojęzyczny zestaw danych FAQ', 'so': 'MFAQ: FAQ macluumaad luuqado badan', 'ta': 'MFAQ: ஒரு பல மொழி FAQ தகவல் அமைப்பு', 'si': 'MFAQ: ගොඩක් භාෂාවක FAQ දත්ත සැකසුම්', 'sv': 'MFAQ: en flerspråkig FAQ-dataset', 'lt': 'MFAQ: daugiakalbis FAQ duomenų rinkinys', 'ur': 'MFAQ: ایک Multilingual FAQ Dataset', 'uz': 'MFAQ: bir nechta tillar FAQ maò¥lumot set', 'vi': 'Bộ nhớ thẻ:', 'bg': 'MFAQ: многоезичен набор от данни с често задавани въпроси', 'nl': 'MFAQ: een meertalige FAQ Dataset', 'da': 'MFAQ: et flersproget datasæt med ofte stillede spørgsmål', 'hr': 'MFAQ: multijezički FAQ podaci', 'id': 'MFAQ: Satu Set Data FAQ Berbahasa', 'de': 'MFAQ: ein mehrsprachiger FAQ-Datensatz', 'fa': 'MFAQ: یک پایگاه اطلاعات FAQ multilingual', 'sw': 'MFAQ: seti ya data za lugha nyingi za FAQ', 'tr': 'MFAQ: Çoklu dilli FAQ verileri', 'sq': 'MFAQ: një bazë të dhënash FAQ shumëgjuhëse', 'am': 'MFAQ: a Multilingual FAQ Dataset', 'af': "MFAQ: ' n Multilingual FAQ Databasis", 'ko': 'MFAQ: 다국어 FAQ 데이터 세트 1개', 'hy': 'MFAQ: a Multilingual FAQ Dataset', 'az': 'MFAQ: 칞oxlu dilli FAQ veril톛nl톛ri', 'bn': 'MFAQ: একটি বহুভাষী FAQ ডাটাসেট', 'ca': 'MFAQ: un conjunt de dades multilingües de preguntes FAQ', 'et': 'MFAQ: mitmekeelne KKK andmekogum', 'fi': 'MFAQ: monikielinen FAQ-tietokokonaisuus', 'cs': 'MFAQ: vícejazyčná sada FAQ', 'bs': 'MFAQ: multijezički FAQ podaci', 'sk': 'MFAQ: večjezični nabor pogosta vprašanja', 'ha': 'QUnicodeControlCharacterMenu', 'he': 'MFAQ: a Multilingual FAQ Dataset', 'jv': 'MFILE: data model Multi-Lingui', 'bo': 'MFAQ: སྐད་རིགས་དབྱིབས་གྱི་FAQ གནད་སྡུད་གཞི་རྩིས་ཅན་ཅིག་'}
{'en': 'In this paper, we present the first multilingual FAQ dataset publicly available. We collected around 6 M FAQ pairs from the ', 'ar': 'في هذه الورقة ، نقدم أول مجموعة بيانات أسئلة وأجوبة متعددة اللغات متاحة للجمهور. جمعنا حوالي 6 ملايين زوج من الأسئلة الشائعة من الويب بـ 21 لغة مختلفة. على الرغم من أن هذا أكبر بكثير من مجموعات بيانات استرجاع الأسئلة الشائعة الحالية ، إلا أنه يأتي مع تحدياته الخاصة: تكرار المحتوى والتوزيع غير المتكافئ للموضوعات. نعتمد إعدادًا مشابهًا مثل Dense Passage Retrieval (DPR) ونختبر العديد من التشفير الثنائي على مجموعة البيانات هذه. تكشف تجاربنا أن نموذجًا متعدد اللغات يعتمد على XLM-RoBERTa يحقق أفضل النتائج ، باستثناء اللغة الإنجليزية. يبدو أن اللغات ذات الموارد الأقل تتعلم من بعضها البعض لأن نموذج متعدد اللغات يحقق معدل MRR أعلى من اللغات الخاصة بلغة معينة. يكشف تحليلنا النوعي عن هشاشة النموذج في التغييرات البسيطة في الكلمات. نصدر علنًا مجموعة البيانات ، والنموذج ، والبرنامج النصي للتدريب.', 'fr': "Dans cet article, nous présentons le premier jeu de données de FAQ multilingue accessible au public. Nous avons collecté environ 6 millions de paires de FAQ sur le Web, dans 21 langues différentes. Bien que cela soit beaucoup plus important que les ensembles de données de récupération de FAQ existants, il comporte ses propres défis\xa0: duplication du contenu et répartition inégale des sujets. Nous adoptons une configuration similaire à celle de Dense Passage Retrieval (DPR) et testons divers bi-encodeurs sur cet ensemble de données. Nos expériences révèlent qu'un modèle multilingue basé sur XLM-Roberta donne les meilleurs résultats, sauf pour l'anglais. Les langues à faibles ressources semblent apprendre les unes des autres, car un modèle multilingue atteint un MRR plus élevé que les langues spécifiques. Notre analyse qualitative révèle la fragilité du modèle pour les simples changements de mots. Nous publions notre jeu de données, notre modèle et notre script de formation.", 'pt': 'Neste artigo, apresentamos o primeiro conjunto de dados de FAQ multilíngue disponível publicamente. Coletamos cerca de 6 milhões de pares de perguntas frequentes da web, em 21 idiomas diferentes. Embora isso seja significativamente maior do que os conjuntos de dados de recuperação de perguntas frequentes existentes, ele vem com seus próprios desafios: duplicação de conteúdo e distribuição desigual de tópicos. Adotamos uma configuração semelhante à Recuperação de Passagem Densa (DPR) e testamos vários bi-codificadores neste conjunto de dados. Nossos experimentos revelam que um modelo multilíngue baseado em XLM-RoBERTa alcança os melhores resultados, exceto o inglês. Idiomas de recursos mais baixos parecem aprender uns com os outros, pois um modelo multilíngue atinge um MRR mais alto do que os específicos de idioma. Nossa análise qualitativa revela a fragilidade do modelo em simples trocas de palavras. Lançamos publicamente nosso conjunto de dados, modelo e script de treinamento.', 'es': 'En este artículo, presentamos el primer conjunto de datos multilingüe de preguntas frecuentes disponible al público. Recopilamos alrededor de 6 millones de pares de preguntas frecuentes de la web, en 21 idiomas diferentes. Si bien esto es significativamente mayor que los conjuntos de datos de recuperación de preguntas frecuentes existentes, conlleva sus propios desafíos: duplicación de contenido y distribución desigual de los temas. Adoptamos una configuración similar a la recuperación de paso denso (DPR) y probamos varios bicodificadores en este conjunto de datos. Nuestros experimentos revelan que un modelo multilingüe basado en XLM-Roberta logra los mejores resultados, excepto el inglés. Los idiomas con menos recursos parecen aprender unos de otros, ya que un modelo multilingüe logra un MRR más alto que los idiomas específicos. Nuestro análisis cualitativo revela la fragilidad del modelo de cambios simples de palabras. Publicamos públicamente nuestro conjunto de datos, modelo y guión de capacitación.', 'zh': '本文中,首公可用者多语FAQ集。 于网络上收600万个FAQ对,有21异语。 虽大于今FAQ检数集要,而挑战重复,题布不均。 余以密集通道检(DPR)类设,并于此数集上试诸双编码器。 吾实验之明,盖XLM-RoBERTa之多言取英语外之最也。 资源卑语似相学,多言模形胜特定MRR。 吾定性分析示形于单词变之脆弱性。 明发数集、模形、教脚本。', 'ja': 'この論文では、公開されている最初の多言語FAQデータセットを紹介します。ウェブから21の言語で約600万のFAQペアを収集しました。これは、既存のFAQ取得データセットよりも大幅に大きいものの、コンテンツの重複とトピックの不均一な配分という独自の課題があります。Dense Passage Retrieval （ DPR ）と同様の設定を採用し、このデータセット上のさまざまなバイエンコーダをテストします。私たちの実験は、XLM - RoBERTaに基づく多言語モデルが、英語を除いて最高の結果を達成することを明らかにしています。多言語モデルは、言語固有のものよりも高いMRRを達成するため、低いリソースの言語は互いに学ぶように思われる。私たちの定性分析は、単純な単語の変化に関するモデルの脆さを明らかにします。データセット、モデル、トレーニングスクリプトを公開します。', 'hi': 'इस पेपर में, हम सार्वजनिक रूप से उपलब्ध पहला बहुभाषी FAQ डेटासेट प्रस्तुत करते हैं। हमने 21 अलग-अलग भाषाओं में वेब से लगभग 6M FAQ जोड़े एकत्र किए। यद्यपि यह मौजूदा एफएक्यू पुनर्प्राप्ति डेटासेट की तुलना में काफी बड़ा है, यह अपनी चुनौतियों के साथ आता है: सामग्री का दोहराव और विषयों का असमान वितरण। हम घने पैसेज रिट्रीवल (डीपीआर) के समान सेटअप को अपनाते हैं और इस डेटासेट पर विभिन्न द्वि-एन्कोडर का परीक्षण करते हैं। हमारे प्रयोगों से पता चलता है कि XLM-RoBERTa पर आधारित एक बहुभाषी मॉडल अंग्रेजी को छोड़कर, सर्वोत्तम परिणाम प्राप्त करता है। कम संसाधन भाषाएं एक दूसरे से सीखती हैं क्योंकि एक बहुभाषी मॉडल भाषा-विशिष्ट लोगों की तुलना में एक उच्च एमआरआर प्राप्त करता है। हमारे गुणात्मक विश्लेषण से सरल शब्द परिवर्तनों पर मॉडल की भंगुरता का पता चलता है। हम सार्वजनिक रूप से हमारे डेटासेट, मॉडल और प्रशिक्षण स्क्रिप्ट जारी करते हैं।', 'ru': 'В настоящем документе мы представляем первый многоязычный набор общедоступных данных FAQ. Мы собрали около 6 миллионов пар часто задаваемых вопросов из Интернета на 21 языке. Хотя она значительно больше, чем существующие наборы данных поиска часто задаваемых вопросов, она сопряжена со своими собственными проблемами: дублированием контента и неравномерным распределением тем. Мы принимаем такую же конфигурацию, как Dense Passage Retrieval (DPR), и тестируем различные бикодирующие датчики на этом наборе данных. Наши эксперименты показывают, что многоязычная модель на базе XLM-RoBERTa достигает наилучших результатов, кроме английского. Языки с более низкими ресурсами, по-видимому, учатся друг у друга, поскольку многоязычная модель достигает более высокого MRR, чем языковые. Наш качественный анализ выявляет хрупкость модели при простых сменах слов. Мы публично выпускаем наш набор данных, модель и сценарий обучения.', 'ga': 'Sa pháipéar seo, cuirimid i láthair an chéad tacar sonraí Ceisteanna Coitianta ilteangach atá ar fáil go poiblí. Bhailíomar timpeall 6M péirí Ceisteanna Coitianta ón ngréasán, i 21 teanga éagsúla. Cé go bhfuil sé seo i bhfad níos mó ná na tacair sonraí aisghabhála Ceisteanna Coitianta atá ann cheana féin, tagann sé lena dhúshláin féin: dúbailt ábhair agus dáileadh míchothrom na dtopaicí. Glacaimid le socrú cosúil le Dlúth Aisghabháil Pasáiste (DPR) agus tástálaimid dé-ionchódóirí éagsúla ar an tacar sonraí seo. Léiríonn ár dturgnaimh go mbaineann samhail ilteangach atá bunaithe ar XLM-RoBERTa na torthaí is fearr amach, seachas an Béarla. Dealraíonn sé go bhfoghlaimíonn teangacha acmhainní níos ísle óna chéile mar go mbaineann samhail ilteangach amach MRR níos airde ná na cinn a bhaineann go sonrach le teanga. Nochtann ár n-anailís cháilíochtúil brittleness an mhúnla ar athruithe simplí focal. Eisímid go poiblí ár dtacar sonraí, ár múnla agus ár script oiliúna.', 'el': 'Σε αυτή την εργασία, παρουσιάζουμε το πρώτο πολύγλωσσο σύνολο δεδομένων που είναι διαθέσιμο στο κοινό. Συγκεντρώσαμε περίπου 6ζεύγη Συχνές ερωτήσεις από το διαδίκτυο, σε 21 διαφορετικές γλώσσες. Αν και αυτό είναι σημαντικά μεγαλύτερο από τα υπάρχοντα σύνολα δεδομένων ανάκτησης Συχνών Ερωτήσεις, έρχεται με τις δικές του προκλήσεις: αναπαραγωγή περιεχομένου και άνιση κατανομή θεμάτων. Υιοθετούμε μια παρόμοια ρύθμιση με την ανάκτηση πυκνού περάσματος (και δοκιμάζουμε διάφορους δύο κωδικοποιητές σε αυτό το σύνολο δεδομένων. Τα πειράματά μας αποκαλύπτουν ότι ένα πολύγλωσσο μοντέλο βασισμένο στο επιτυγχάνει τα καλύτερα αποτελέσματα, εκτός από τα αγγλικά. Οι γλώσσες χαμηλότερων πόρων φαίνεται να μαθαίνουν η μία από την άλλη καθώς ένα πολύγλωσσο μοντέλο επιτυγχάνει υψηλότερο MRR από αυτές που αφορούν τη γλώσσα. Η ποιοτική ανάλυση μας αποκαλύπτει την ευθραυστότητα του μοντέλου σε απλές αλλαγές λέξεων. Δημοσιεύουμε δημόσια το σύνολο δεδομένων, το μοντέλο και το εκπαιδευτικό μας σενάριο.', 'hu': 'Ebben a tanulmányban bemutatjuk az első többnyelvű GYIK adatkészletet, amely nyilvánosan elérhető. Körülbelül 6 millió GYIK párt gyűjtöttünk össze a webről, 21 különböző nyelven. Bár ez lényegesen nagyobb, mint a meglévő GYIK visszakeresési adatkészletek, saját kihívásokkal jár: a tartalom megkettőzése és a témák egyenlőtlen elosztása. Hasonló beállítást alkalmazunk, mint a Dense Passage Retrieval (DPR), és különböző kétkódolókat tesztelünk ezen az adatkészleten. Kísérleteink azt mutatják, hogy az XLM-RoBERTa-n alapuló többnyelvű modell a legjobb eredményeket éri el, kivéve az angol nyelvet. A nyelvek alacsonyabb erőforrásokat tanulnak egymástól, mivel a többnyelvű modell magasabb MRR-t ér el, mint a nyelvspecifikus modellek. Minőségi elemzésünk feltárja a modell törékenységét egyszerű szóváltozásokon. Nyilvánosan kiadjuk adatkészletünket, modellünket és képzési forgatókönyvünket.', 'ka': 'ჩვენ პირველი მრავალენგური FAQ მონაცემების სახელსაწყისში ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ გა ჩვენ 6M FAQ ზოგების გარეშე ვებიდან, 21 განსხვავებული ენაში. მაგრამ ეს მნიშვნელოვანი უფრო დიდია, რაც არსებობს FAQ მიღებული მონაცემების კონფიგურაცია, მან თავისთან განსაცემებით მოთავსდება: მონაცემების ექსპულაცია და გან ჩვენ განვიყენებთ განსხვავებული ორივე კოდერები, როგორც Dense Passage Retrieval (DPR) და ამ მონაცემების კოდერების განსხვავება. ჩვენი ექსპერიმენტები აღმოჩნდება, რომ XLM-RoBERTa-ზე დაბაზეული მრავალენგური მოდელი მიიღებს უფრო მსგავსი შედეგი, მაგრამ ანგლისური შედეგი. შემდეგ მინუს რესურსების ენები ერთმანეთიდან ვისწავლოთ, როგორც მრავალენგური მოდელი უფრო მეტი MRR მიიღებს, ვიდრე ენის განსაკუთრებული ენებიდან. ჩვენი კვალიტატიური ანალიზი აღმოჩნდება მოდელის სიტყვის ცვლილების ბრძელობას. ჩვენ საუკეთესოდ ჩვენი მონაცემები, მოდელი და სკრიპტის განახლება.', 'lt': 'Šiame dokumente pristatome pirmąjį daugiakalbį FAQ duomenų rinkinį, kuris yra viešai prieinamas. Iš tinklo surinkėme maždaug 6 M FAQ porų 21 skirtingomis kalbomis. Nors ji gerokai didesnė už esamus FAQ duomenų rinkinius, ji susiduria su savo uždaviniais: turinio dubliavimu ir nevienodu temų paskirstymu. Priimame panašią sistemą kaip Dense Passage Retrieval (DPR) ir bandome įvairius dvikodatorius šiame duomenų rinkinyje. Mūsų eksperimentai rodo, kad daugiakalbis modelis, pagrįstas XLM-RoBERTa, pasiekia geriausius rezultatus, išskyrus anglų kalbą. Mažesnių išteklių kalbos, atrodo, mokosi viena iš kitos, nes daugiakalbis modelis pasiekia didesnę MRR nei kalboms skirtos kalbos. Our qualitative analysis reveals the brittleness of the model on simple word changes.  We publicly release our dataset, model, and training script.', 'it': "In questo articolo, presentiamo il primo set di dati multilingue FAQ disponibile pubblicamente. Abbiamo raccolto circa 6 milioni di coppie FAQ dal web, in 21 lingue diverse. Anche se questo è significativamente più grande dei set di dati di recupero delle FAQ esistenti, esso presenta le sue sfide: duplicazione dei contenuti e distribuzione irregolare degli argomenti. Adottiamo un setup simile al Dense Passage Retrieval (DPR) e testiamo vari bi-encoder su questo set di dati. I nostri esperimenti rivelano che un modello multilingue basato su XLM-RoBERTa ottiene i migliori risultati, tranne che per l'inglese. Le lingue con risorse inferiori sembrano imparare l'una dall'altra in quanto un modello multilingue raggiunge un MRR superiore a quelli specifici per la lingua. La nostra analisi qualitativa rivela la fragilità del modello su semplici cambiamenti di parola. Pubblichiamo pubblicamente il nostro set di dati, modello e script di formazione.", 'mk': 'Во овој весник, го претставуваме првиот мултијазичен набор на податоци за FAQ јавно достапни. Собравме околу 6 милиони FAQ парови од интернет, на 21 различни јазици. Although this is significantly larger than existing FAQ retrieval datasets, it comes with its own challenges: duplication of content and uneven distribution of topics.  Ние усвојуваме слично поставување како Денс Пасаж Отворање (ДПР) и тестираме различни бикодери на овој податок. Нашите експерименти откриваат дека мултијазичен модел базиран на XLM-RoBERTa постигнува најдобри резултати, освен англиски. Изгледа дека јазиците со пониски ресурси учат еден од друг бидејќи мултијазичкиот модел постигнува повисок МРР од јазичките специфични. Нашата квалитетна анализа ја открива слабоста на моделот за едноставни промени на зборовите. Јавно ги објавуваме нашите податоци, моделот и сценариото за тренинг.', 'ms': 'Dalam kertas ini, kami memperkenalkan set data FAQ berbilang bahasa pertama yang tersedia secara umum. Kami mengumpulkan sekitar 6 M pasangan FAQ dari web, dalam 21 bahasa yang berbeza. Walaupun ini jauh lebih besar daripada set data pemulihan FAQ yang ada, ia datang dengan cabaran sendiri: gandaan kandungan dan distribusi tidak sama topik. Kami mengadopsi tetapan yang sama seperti Penerimaan Dense Passage (DPR) dan menguji pelbagai bi-pengekod pada set data ini. Our experiments reveal that a multilingual model based on XLM-RoBERTa achieves the best results, except for English.  Bahasa sumber rendah nampaknya belajar dari satu sama lain kerana model berbilang bahasa mencapai MRR yang lebih tinggi daripada bahasa-spesifik. Analisis kualitatif kami mengungkapkan kelemahan model pada perubahan perkataan sederhana. We publicly release our dataset, model, and training script.', 'ml': 'In this paper, we present the first multilingual FAQ dataset publicly available.  നമ്മള്\u200d വെബ്റ്റില്\u200d നിന്നും 6M FAQ ജോടികളെ കൂട്ടിച്ചേര്\u200dത്തു, 21 വ്യത്യസ്ത ഭാഷകളില്\u200d. ഇത് നിലവിലുള്ള FAQ വിവരങ്ങളെക്കാള്\u200d വലുതാണെങ്കിലും അത് സ്വന്തം വിലാസങ്ങളോടൊപ്പം വരുന്നു. ഉള്ളടക്കം ഇരട്ടി വിതരണം ചെയ്യുന്നതും  ഡെന്\u200dസ് പാസ്സേജ് വീണ്ടെടുക്കുന്നതിനെപ്പോലുള്ള ഒരു സജ്ജീകരണങ്ങള്\u200d ഞങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുകയും, ഈ ഡാറ്റാസ നമ്മുടെ പരീക്ഷണങ്ങള്\u200d വെളിപ്പെടുത്തുന്നത് എക്സ്\u200cഎംഎംറോ-റോബെര്\u200dട്ടാ അടിസ്ഥാനമായ ഒരു പല ഭാഷ മോഡല്\u200d ആണെന്നാണ ഭാഷകളില്\u200d നിന്നും കുറഞ്ഞ വിഭവങ്ങളില്\u200d നിന്നും പഠിക്കാന്\u200d തോന്നുന്നു. ഒരു പല ഭാഷ മോഡല്\u200d മാതൃകയാണ് MRR ഭാഷ പ്രത് നമ്മുടെ ക്വാലിട്ടിവിലാസ്റ്റീവ് വാക്ക് മാറ്റങ്ങള്\u200d കാണിക്കുന്നതിന്റെ മോഡലിന്റെ കുറച്ച്  ഞങ്ങള്\u200d നമ്മുടെ ഡാറ്റാസെറ്റ്, മോഡല്\u200d, പരിശീലന സ്ക്രിപ്റ്റ് പ്രസ്താവിക്കുന്നു.', 'mt': 'In this paper, we present the first multilingual FAQ dataset publicly available.  Inġabru madwar 6M par ta’ FAQ mill-internet, f’21 lingwa differenti. Għalkemm dan huwa akbar b’mod sinifikanti mis-settijiet ta’ dejta eżistenti dwar l-irkupru tal-FAQ, dan joħloq l-isfidi tiegħu stess: id-duplikazzjoni tal-kontenut u d-distribuzzjoni mhux uniformi tas-suġġetti. Aħna niddottaw struttura simili għall-kisba ta’ Dense Passage Retrieval (DPR) u ntestjaw diversi bi-kodifikaturi fuq dan is-sett ta’ dejta. L-esperimenti tagħna juru li mudell multilingwi bbażat fuq XLM-RoBERTa jikseb l-a ħjar riżultati, ħlief għall-Ingliż. Jidher li lingwi b’riżorsi aktar baxxi jitgħallmu minn xulxin billi mudell multilingwi jikseb MRR ogħla minn dawk speċifiċi għall-lingwa. Our qualitative analysis reveals the brittleness of the model on simple word changes.  We publicly release our dataset, model, and training script.', 'mn': 'Энэ цаасан дээр бид анхны олон хэлний FAQ өгөгдлийн санг олон нийтэд ашиглаж байна. Бид Вебээс 6М FAQ хоёрыг 21 өөр хэл дээр цуглуулсан. Хэдийгээр энэ нь суурилсан ФАQ өгөгдлийн санаас их том боловч өөрийн сорилтуудыг давхарлах боломжтой юм. Бид Dense Passage Retrieval (DPR) болон энэ өгөгдлийн санд олон хоёр кодеруудыг шалгана. Бидний туршилтууд XLM-RoBERTa-ын үндсэн олон хэлний загвар Англи хэлний бусад хамгийн сайн үр дүн гаргадаг гэдгийг харуулдаг. Бага мөнгө оруулалт хэлнүүд хэлээс олон хэл загвар нь хэлээс илүү өндөр MRR гаргадаг мэт санагдаж байна. Бидний чадвартай шинжилгээ нь энгийн үгийн өөрчлөлт дээр загварын загварыг илэрхийлдэг. Бид өгөгдлийн сангууд, загвар, сургалтын скриптийг олон нийтэд гаргаж өгдөг.', 'no': 'I denne papiret viser vi den første fleirspråk FAQ- datasettet offentlig tilgjengeleg. Vi samla rundt 6M FAQ-par frå nettet, i 21 ulike språk. Selv om dette er betydelig større enn dei eksisterande FAQ- hendingsdata, kjem det med sine eige utfordringar: duplikasjon av innhaldet og ulike distribusjon av emner. Vi adopterer ein liknande oppsett som Dense Passagehenting (DPR) og testar ulike bi- kodar på denne datasettet. Eksperimentane våre viser at ein multispråk modell basert på XLM- RoBERTa oppnår dei beste resultatene, unntatt for engelsk. Lågare ressursspråk ser ut til å lære frå kvarandre som ein fleirspråk modell oppnår ein høgare MRR enn språkspesifikant. Kvalitativ analysen vårt viser breidde av modellen på enkle ordendringar. Vi publiserer datasettet, modell og opplæringsskript våre.', 'sr': 'U ovom papiru predstavljamo prvu multijezičku kompletu podataka FAQ javno dostupnu. Skupljali smo oko 6M FAQ pare sa mreže, na 21 različitih jezika. Iako je to značajno veće od postojećih kompleta podataka FAQ-a, dolazi sa svojim izazovima: duplikacija sadržaja i nepravedne distribucije tema. Usvojimo sličnu postavku kao prikupljanje Dense Passage (DPR) i testiranje različitih bi-kodera na ovom setu podataka. Naši eksperimenti otkrivaju da multijezički model baziran na XLM-RoBERTa postiže najbolji rezultat, osim engleskog. Niži jezici resursa izgleda da se uče jedni od drugih kao multijezički model postiže veći MRR od jezika specifičnih. Naša kvalitativna analiza otkriva velikost modela na jednostavnim promjenama reči. Publièno objavljujemo naš set podataka, model i obuku scenarija.', 'kk': 'Бұл қағазда бірінші көп тілді FAQ деректер жиынын көпшілікті қол жеткіземіз. Біз Интернеттен 6M FAQ екі тілде 21 түрлі тілде жинақтадық. Бұл бар FAQ алу деректер жиындарынан ең үлкен болса да, оның өзінің мәселелерімен келеді: мазмұның көшірмесін және тақырыптардың көшірмесі жоқ. Біз Dense Passage Retrieval (DPR) деп ұқсас параметрлерді қолданып, бұл деректер жиынында әртүрлі екі кодерлерді сынап көрдік. Біздің тәжірибеміз XLM- RoBERTa негіздеген көп тілді моделі ағылшын тілінен басқа ең жақсы нәтижелерді жеткізеді. Ресурстардың төменгі тілдері бір-бірінен бір-бірінен үйрену сияқты, бірнеше тіл үлгісінде MRR тілдерінен артық болып келеді. Қалапайым анализ үлгісін қарапайым сөздерді өзгерту үшін көрсетеді. Біз деректер жиынымызды, моделімізді және оқыту скриптерімізді жалғастырамыз.', 'so': 'Qoraalkan waxaan ku soo bandhignaa kooxda macluumaadka ee ugu horeeyay ee FAQ ee luuqadaha kala duduwan oo si bayaan ah. Internetka waxaan ka soo ururiyey labo badan 6M FAQ, 21 luuqadood oo kala duduwan. In kastoo ay taasu aad uga weyn tahay sawirada helitaanka FAQ, waxay la timaadaa dhibaatooyinkeeda: dupliisiga waxyaabaha iyo qaybinta maadooyinka aan baahnayn. Waxaynu qaadannaa qoraal u eg oo kale oo loo soo celinayo baasaboorka Dense (DPR) waxaana ku imtixaannaa kookookooyin kala duduwan oo ku qoran macluumaadkan. Imtixaankayada waxay muuqataa in model luuqado kala duduwan oo ku saleysan XLM-RoBERTA uu helaa resultiyada ugu wanaagsan ee Ingiriiska mooyaane. Luqadaha hoose waxay u muuqataa in luqadaha qaarkood laga barto sida model luuqado kala duduwan oo ay u helaan MRR ka sarreeya kuwa ku qoran luuqadaha. Analyadaada aqoontu wuxuu muujiyaa muusikada fudud ee ku saabsan beddelka hadalka fudud. Si bayaan ah ayaannu u bixinnaa sawirkayada, modellka iyo tababarida.', 'sv': 'I denna uppsats presenterar vi den första flerspråkiga FAQ-datauppsättningen offentligt tillgänglig. Vi samlade runt 6 miljoner FAQ par från webben, på 21 olika språk. Även om detta är betydligt större än befintliga FAQ-datauppsättningar, kommer det med sina egna utmaningar: dubblering av innehåll och ojämn distribution av ämnen. Vi använder en liknande konfiguration som Dense Passage Retrieval (DPR) och testar olika bi-kodare på denna dataset. Våra experiment visar att en flerspråkig modell baserad på XLM-RoBERTa uppnår de bästa resultaten, förutom engelska. Språk med lägre resurser verkar lära sig av varandra eftersom en flerspråkig modell uppnår en högre MRR än språkspecifika. Vår kvalitativa analys avslöjar modellens skör vid enkla ordförändringar. Vi publicerar vårt dataset, modell och utbildningsskript offentligt.', 'pl': 'W niniejszym artykule przedstawiamy pierwszy wielojęzyczny zestaw danych FAQ dostępny publicznie. Zebraliśmy około 6M FAQ pary z sieci, w 21-tych różnych językach. Chociaż jest to znacznie większe niż istniejące zbiory danych dotyczących pobierania FAQ, wiąże się z własnymi wyzwaniami: powielaniem treści i nierównomiernej dystrybucji tematów. Przyjmujemy podobną konfigurację jak Dense Passage Retrieval (DPR) i testujemy różne bi-kodery na tym zbiorze danych. Nasze eksperymenty pokazują, że wielojęzyczny model oparty na XLM-RoBERTa osiąga najlepsze wyniki, z wyjątkiem angielskiego. Języki niższych zasobów wydają się uczyć od siebie nawzajem, ponieważ model wielojęzyczny osiąga wyższy MRR niż językowe. Nasza analiza jakościowa ujawnia kruchość modelu na prostych zmianach słowowych. Publikujemy publicznie nasz zestaw danych, model i skrypt szkoleniowy.', 'ro': 'În această lucrare, prezentăm primul set de date multilingv FAQ disponibil public. Am colectat aproximativ 6 milioane de perechi FAQ de pe web, în 21 de limbi diferite. Deși acest lucru este semnificativ mai mare decât seturile de date existente de recuperare a FAQ, vine cu propriile provocări: duplicarea conținutului și distribuirea inegală a subiectelor. Adoptăm o configurație similară cu DPR (Dense Passage Retrieval) și testăm diferite bi-encodere pe acest set de date. Experimentele noastre arată că un model multilingv bazat pe XLM-RoBERTa obține cele mai bune rezultate, cu excepția limbii engleze. Limbile cu resurse mai mici par să învețe unul de la altul, deoarece un model multilingv atinge un MRR mai mare decât cele specifice limbilor. Analiza noastră calitativă dezvăluie fragilitatea modelului pe simple schimbări de cuvinte. Publicăm public setul nostru de date, modelul și scenariul de instruire.', 'si': 'මේ පත්තරේ අපි පලවෙනි විශාල භාෂාවක් FAQ දත්ත සෙට් ප්\u200dරතිකාරයෙන් පිළිගත්තා. අපි 6M FAQ වලින් වෙනි භාෂාවල් 21 වලින් එකතු කළා. මේක තියෙන්නේ FAQ ලැබෙන දත්ත සෙට්ටුවට වඩා විශේෂයෙන් වැඩියි, ඒක එයාගේ පුළුවන් ප්\u200dරශ්නයක් තියෙනවා: ප්\u200dරශ්නයක අපි මේ දත්ත සැටියේ විවිධ දෙන්න බින්කෝඩර් පරීක්ෂා කරනවා. අපේ පරීක්ෂණයක් ප්\u200dරකාශ කරනවා කියලා XLM-RoBERTa විසින් විශේෂ භාෂාවක් නිර්මාණයක් ඉංග්\u200dරීසිය විසින බොහෝ භාෂාවක් විශේෂ විශේෂයෙන් වඩා විශේෂ MRR වලින් එක්කෙනෙක් ඉගෙන ගන්න පුළුවන් වගේ. අපේ විශේෂ විශ්ලේෂණය ප්\u200dරකාශ කරනවා සාමාන්\u200dය වචන වෙනස් වෙනුවෙන් මොඩේල් එකේ ප්\u200dරමාණය ප්\u200dරක අපි අපේ දත්ත සෙට්, මොඩේල්, ස්ක්\u200dරිප්ට් ස්ක්\u200dරිප්ට් එක ප්\u200dරකාශ කරනවා.', 'ta': 'இந்த காகிதத்தில், நாம் முதல் பல மொழி FAQ தகவல் அமைப்பை பொதுவாக கிடைக்கும். நாங்கள் வலையத்தில் இருந்து 6M FAQ ஜோடிகளை சேர்த்து, 21 வேறு மொழிகளில். இது இருக்கும் FAQ மீட்டெடுப்பு தகவல் அமைப்புகளை விட மிகப் பெரியதாக இருந்தாலும், அது தன் சொந்த சவால்களுடன் வருகிறது: உள்ளடக்கத்தை இரட்ட நாம் டென்ஸ் கடவுச்செல் திரும்ப திரும்ப திரும்ப திரும்ப அமைப்பை எடுத்து இந்த தரவுத்தளத்தில் பல பி குறியீட எக்ஸ்எல்எம்- ரோபிரெட்டா அடிப்படையில் ஒரு பல மொழி மாதிரி முடிவுகள் மிகவும் சிறந்த முடிவுகள் பெறுகிறது ஆங்கிலத் குறைந்த வளங்களின் மொழிகள் ஒருவர் மற்றொருவரிடமிருந்து கற்றுக் கொள்வது போல் மொழிக்குறிப்பிட்ட மாதிரி மாதிரி  எளிய வார்த்தை மாற்றங்கள் பற்றி மாதிரியான மாதிரியின் சுருக்கம் வெளிப்படுத்துகிறது. நாங்கள் எங்கள் தகவல் அமைப்பு, மாதிரி, மற்றும் பயிற்சிக்குறிநிரலை வெளியேறுகிறோம்.', 'ur': 'اس کاغذ میں ہم پہلی ملتی زبان فاکیو ڈیٹسٹ کو ظاہر طور پر حاضر کرتے ہیں۔ ہم نے ویب سے 6M FAQ جوڑے جمع کیے 21 مختلف زبانوں میں۔ اگرچہ یہ موجود FAQ retrieval datasets سے زیادہ بڑا ہے، یہ اپنے ہی چالیں کے ساتھ آتا ہے: موجود منصوبات کا دوپیٹ اور مسائل کے بغیر برابر تقسیم. ہم نے دنس پاسج پھیر لینے (DPR) کے طور پر ایک جیسی سیٹ اپ لیا ہے اور اس ڈیٹ سٹ پر مختلف بین کوڈر جانچ لیا ہے۔ ہماری آزمائش ظاہر کرتی ہے کہ XLM-RoBERTa پر بنیاد ایک multilingual model بہترین نتائج حاصل کرتا ہے مگر انگلیسی کے سوا۔ بہت سی زبان کی مدل کی وجہ سے ایک دوسرے سے چھوٹی منابع زبانیں سیکھ رہی ہیں کہ زبان کے مطابق بہت زیادہ MRR حاصل کرتی ہیں۔ ہماری کیلوٹیٹی تحلیل سادہ کلمات بدلنے پر موڈل کی گھاٹی ظاہر کرتا ہے۔ ہم عمومی طور پر اپنے ڈاٹ سٹ، موڈل اور تربین سکرپٹ کو آزاد کرتے ہیں۔', 'uz': "Bu hujjatda biz birinchi necha tilda FAQ maʼlumot tarkibini jamoatlar bilan koʻrsatimiz. Biz veb- saytdagi 6M FAQ ko'pchiligimiz, 21 tillardan ko'pchilikni birlashdik. @ info: whatsthis Name Bizning imtiyozlarimiz XLM-RoBERTA asosida bir necha tildagi modeli eng yaxshi natijalarni topadi. Quyidagi rasmlar bir necha tildan o'rganadi, bir necha til modeli uchun MRR tildan foydalanadi. Bizning kvlitativ analytikimiz modelning kichkina o'zgarishlarini ko'rsatadi. Biz faqat maʼlumot, modeli, va taʼminlovchi skriptni chiqaramiz.", 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu bộ dữ liệu FAQ đa dạng đầu tiên công khai. Chúng tôi sưu tầm quanh 6M FAQ: bằng ngôn ngữ khác nhau trên Internet, bằng 21. Mặc dù nó lớn hơn nhiều so với các tập tin dữ liệu thu hồi của FAQ hiện nay, nhưng nó có những thử thách riêng, gồm việc làm gấp đôi nội dung và phân chia các chủ đề không chính xác. Chúng tôi sử dụng một thiết lập tương tự như Dense Passage Retrievel (DR) và thử nhiều mã hóa khác nhau trên bộ dữ liệu này. Những thí nghiệm của chúng ta cho thấy một mô hình ngôn ngữ rộng dựa trên XLM-RoennTa đã đạt được kết quả tốt nhất, ngoại trừ tiếng Anh. Các ngôn ngữ dưới lực có vẻ học hỏi lẫn nhau bởi vì một mô hình ngôn ngữ đa dạng đạt được MRR cao hơn mã ngôn ngữ. Phân tích chất lượng của chúng tôi cho thấy tính tinh tế của mô hình thay đổi đơn giản. Chúng tôi công khai phát hành tập tin, mô hình và tập luyện kịch bản.', 'nl': 'In dit artikel presenteren we de eerste meertalige FAQ dataset die publiekelijk beschikbaar is. We verzamelden ongeveer 6M FAQ paren van het web, in 21 verschillende talen. Hoewel dit aanzienlijk groter is dan bestaande FAQ retrieval datasets, brengt het zijn eigen uitdagingen met zich mee: duplicatie van inhoud en ongelijke verdeling van onderwerpen. We gebruiken een vergelijkbare setup als Dense Passage Retrieval (DPR) en testen verschillende bi-encoders op deze dataset. Uit onze experimenten blijkt dat een meertalig model gebaseerd op XLM-RoBERTa de beste resultaten behaalt, behalve Engels. Talen met lagere resources lijken van elkaar te leren omdat een meertalig model een hogere MRR bereikt dan talen met een taalspecifieke. Onze kwalitatieve analyse onthult de broosheid van het model op eenvoudige woordveranderingen. We publiceren publiekelijk onze dataset, model en trainingsscript.', 'bg': 'В тази статия представяме първия многоезичен набор от данни с ЧЗВ, публично достъпен. Събрахме около 6 милиона двойки от интернет, на 21 различни езика. Въпреки че това е значително по-голямо от съществуващите набори от данни за извличане на ЧЗВ, то идва със свои собствени предизвикателства: дублиране на съдържанието и неравномерно разпределение на темите. Приемаме подобна настройка като извличане на плътен пасаж (DPR) и тестваме различни бикодери на този набор от данни. Нашите експерименти показват, че многоезичен модел, базиран на постига най-добри резултати, с изключение на английския. Езиците с по-ниски ресурси изглежда се учат един от друг, тъй като многоезичният модел постига по-висока MRR от специфичните за езика. Нашият качествен анализ разкрива крехкостта на модела при прости думи промени. Публично публикуваме нашия набор от данни, модел и тренировъчен скрипт.', 'hr': 'U ovom papiru predstavljamo prvu multijezičku kompletu podataka FAQ javno dostupnu. Skupljali smo oko 6M FAQ pare iz mreže, na 21 različitih jezika. Iako je to značajno veće od postojećih kompleta podataka FAQ-a, dolazi s svojim izazovima: duplikacija sadržaja i neobična distribucija tema. Usvojimo sličnu postavku kao prikupljanje Dense Passage (DPR) i testiranje različitih bi-kodera na ovom setu podataka. Naši eksperimenti otkrivaju da multijezički model baziran na XLM-RoBERTa postigne najbolje rezultate, osim engleskog. Niži jezici resursa čini se da se uče jedni od drugih kao multijezički model postiže viši MRR od jezika specifičnih. Naša kvalitativna analiza otkriva velikost modela o jednostavnim promjenama riječi. Publično objavljujemo naš podaci, model i obuku scenarija.', 'da': 'I denne artikel præsenterer vi det første flersprogede FAQ datasæt offentligt tilgængeligt. Vi samlede omkring 6 millioner FAQ par fra internettet, på 21 forskellige sprog. Selvom dette er væsentligt større end eksisterende FAQ hentning datasæt, kommer det med sine egne udfordringer: duplikation af indhold og ujævn fordeling af emner. Vi anvender en lignende opsætning som DPR (Dense Passage Retrieval) og tester forskellige bi-encodere på dette datasæt. Vores eksperimenter afslører, at en flersproget model baseret på XLM-RoBERTa opnår de bedste resultater, bortset fra engelsk. Sprog med lavere ressourcer synes at lære af hinanden, da en flersproget model opnår en højere MRR end sprogspecifikke. Vores kvalitative analyse afslører modellens skønhed ved simple ordændringer. Vi offentliggør vores datasæt, model og træningsskript.', 'de': 'In diesem Beitrag stellen wir den ersten mehrsprachigen FAQ-Datensatz vor, der öffentlich verfügbar ist. Wir haben rund 6M FAQ Paare aus dem Web in 21 verschiedenen Sprachen gesammelt. Obwohl dies deutlich größer ist als bestehende FAQ Retrieval Datasets, bringt es seine eigenen Herausforderungen mit sich: Duplizierung von Inhalten und ungleichmäßige Verteilung von Themen. Wir verwenden ein ähnliches Setup wie Dense Passage Retrieval (DPR) und testen verschiedene Bi-Encoder auf diesem Datensatz. Unsere Experimente zeigen, dass ein mehrsprachiges Modell auf Basis von XLM-RoBERTa die besten Ergebnisse erzielt, außer Englisch. Sprachen mit geringeren Ressourcen scheinen voneinander zu lernen, da ein mehrsprachiges Modell eine höhere MRR als sprachspezifische erreicht. Unsere qualitative Analyse zeigt die Sprödigkeit des Modells auf einfache Wortwechsel. Wir veröffentlichen öffentlich unseren Datensatz, unser Modell und unser Trainingsskript.', 'id': 'Dalam kertas ini, kami mempersembahkan dataset FAQ berbilang bahasa pertama yang tersedia publik. Kami mengumpulkan sekitar 6 M pasangan FAQ dari web, dalam 21 bahasa yang berbeda. Meskipun ini jauh lebih besar dari sett data penghasilan FAQ yang ada, ia datang dengan tantangan sendiri: duplikasi isi dan distribusi tidak sama topik. Kami mengadopsi seting yang sama dengan Dense Passage Retrieval (DPR) dan menguji berbagai bi-encoder pada set data ini. Eksperimen kami mengungkapkan bahwa model berbagai bahasa berdasarkan XLM-RoBERTa mencapai hasil terbaik, kecuali bahasa Inggris. Bahasa sumber daya yang lebih rendah tampaknya belajar dari satu sama lain sebagai model berbagai bahasa mencapai MRR yang lebih tinggi dari bahasa-spesifik. Analisi kualitatif kami mengungkapkan kelemahan model pada perubahan kata sederhana. Kami publik melepaskan dataset, model, dan skrip latihan kami.', 'ko': '본문에서 최초로 공개된 다국어 FAQ 데이터 세트를 선보였다.우리는 인터넷에서 약 600만 쌍의 흔한 문제를 수집하여 21개의 다른 언어를 사용했다.비록 이것은 기존의 FAQ 검색 데이터 집합보다 훨씬 크지만, 내용 중복과 주제 분포가 고르지 않다는 자신만의 도전도 있다.우리는 밀집 채널 검색 (DPR) 과 유사한 설정을 사용하고, 이 데이터 집합에서 각종bi 인코더를 테스트했다.우리의 실험은 영어를 제외하고 XLM-RoBERTA의 다언어 모델을 바탕으로 가장 좋은 결과를 얻었다는 것을 나타냈다.비교적 낮은 자원의 언어는 서로 배울 수 있을 것 같다. 왜냐하면 다중 언어 모델이 정해진 언어 모델의 MRR보다 높기 때문이다.우리의 정성 분석은 이 모델이 간단한 단어 변화에 대한 취약성을 보여 주었다.우리는 데이터 집합, 모델, 교육 스크립트를 공개적으로 발표한다.', 'sw': 'Katika gazeti hili, tunaweka taarifa za kwanza za za lugha za FAQ zinazopatikana hadharani. Tumekusanya takribani wanaume 6M FAQ kutoka mtandaoni, kwa lugha 21 tofauti. Ingawa hii ni kubwa zaidi ya seti za upatikanaji wa data za FAQ zilizopo, inakuja na changamoto zake wenyewe: mara mbili ya maudhui na usambazaji wa mada zisizo na uwezo. Tunaweza kutekeleza taasisi kama ilivyofanana na kurudisha huduma za Dense (DPR) na kuwajaribu jumbe mbalimbali katika seti hii ya data. Majaribio yetu yanaonyesha kuwa mtindo wa lugha mbalimbali unaotengenezwa na XLM-RoBERTa hupata matokeo bora zaidi, isipokuwa kwa Kiingereza. Lugha za chini zinaonekana kujifunza kutoka kwa wenyewe kwa kuwa mifano ya lugha nyingi hufanikiwa zaidi ya MRR kuliko zile zenye lugha maalum. Uchambuzi wetu wa sifa unaonyesha upungufu wa mifano kuhusu mabadiliko ya maneno rahisi. Tunatoa hadharani taarifa zetu, mifano na mafunzo.', 'sq': 'Në këtë letër, ne paraqesim të dhënat e para shumëgjuhëse FAQ në dispozicion publik. Ne mbledhëm rreth 6 milion palë FAQ nga rrjeti, në 21 gjuhë të ndryshme. Megjithëse kjo është ndjeshëm më e madhe se të dhënat ekzistuese për marrjen e FAQ-ve, ajo vjen me sfidat e saj: dyfishimin e përmbajtjes dhe shpërndarjen e pabarazishme të temave. Ne miratojmë një konfigurim të ngjashëm me Dense Passage Retrieval (DPR) dhe testojmë dy-koduesit e ndryshëm në këtë set të dhënash. Eksperimentet tona zbulojnë se një model shumëgjuhës bazuar në XLM-RoBERTa arrin rezultatet më të mira, përveç anglishtit. Gjuhat më të ulëta të burimeve duken të mësojnë nga njëri-tjetri pasi një model shumëgjuhës arrin një MRR më të lartë se a to specifike gjuhës. Our qualitative analysis reveals the brittleness of the model on simple word changes.  Ne publikisht lëshojmë skenën tonë të dhënash, modelin dhe stërvitjen.', 'am': 'በዚህ ገጽ የመጀመሪያውን የብዙልቋ የFAQ ዳታዎችን በህዝብ የተገኘን እናቀርባለን፡፡ በ6M FAQ ያሉትን ሁለት ሁለት በሀገር 21 ልዩ ቋንቋዎች ሰብሰብን፡፡ ምንም እንኳን ይህ ከአሁኑ FAQ አድራጊ ዳታዎችን ከመስጠት በጣም ትልቅ ቢሆን ግን ከገዛ ችሎታዎቹ ጋር ይመጣል፤ የውይይት ጥያቄ እና የውይይት አካባቢ ትክክል ነው፡፡ የዳንስ Passage Retrieval (DPR) እና በዚህ ዳታ ማውጣት ላይ የተለያዩ የቢ-code እናሞክራለን፡፡ ፈተናዎቻችን በXLM-RoBERTA ላይ የተመሠረተ የበለጠ የቋንቋ-ቋንቋ ምሳሌ ከኢንጂልስቲክ በቀር መልካሙን ፍሬቶች ያገኛል፡፡ ቋንቋዎች ከቋንቋ-ቋንቋዎች ይልቅ የበለጠ MRR የሚደረገውን እንደምታስቡ ይመስላል፡፡ የተመሳሳይነታችን ትርጓሜ የሞዴል ውጤት በቀላል ቃላት ለውጥ ላይ ያሳያል፡፡ የዳታ ሳጥን፣ ምሳሌ እና ትምህርት ጽሑፎችንን በግልጽ እናስወግዳለን፡፡', 'hy': 'Այս թղթի մեջ մենք հրապարակում ենք առաջին բազմալեզու ֆԱԿ տվյալների համակարգը: Մենք հավաքեցինք ինտերնետից մոտ 6M-ի պայմանագրությունների զույգեր 21 տարբեր լեզուներով: Չնայած, որ սա շատ ավելի մեծ է, քան գոյություն ունեցող ՀՀՀ-ի վերադարձման տվյալների համակարգերը, այն հանդիպում է իր սեփական մարտահրավերներին՝ պարունակության կրկնօրինակումը և թեմաների անհավասար տարածումը: Մենք ընդունում ենք նույն կառուցվածքը, ինչպիսիք են "Դենս ճանապարհի վերցնելը" և փորձում ենք տարբեր երկկոդերներ այս տվյալների համակարգում: Our experiments reveal that a multilingual model based on XLM-RoBERTa achieves the best results, except for English.  Թվում է, որ ավելի ցածր ռեսուրսների լեզուները միմյանց սովորում են, քանի որ բազլեզու մոդելը հասնում է ավելի բարձր մագնիսական ռեսուրսներ, քան լեզվին հատուկ լեզուները: Մեր որակային վերլուծությունը բացահայտում է, որ մոդելը պարզ բառերի փոփոխությունների վերաբերյալ է: Մենք հանրային կերպ հրապարակում ենք մեր տվյալների համակարգը, մոդելը և ուսուցման սցեպտորը:', 'fa': 'در این کاغذ، اولین مجموعه داده های FAQ multilingual را به طور عمومی در دسترس می دهیم. ما حدود 6M FAQ جفت از وب را در ۲۱ زبان متفاوت جمع کردیم. اگرچه این بسیار بزرگتر از مجموعه\u200cهای داده\u200cهای FAQ موجود است، با چالش\u200cهای خود می\u200cآید: دوباره\u200cسازی محتویات و تقسیم نابرابر موضوع. ما یک تنظیم مشابهی را به عنوان بازیابی سفر دنس (DPR) می\u200cگیریم و در این مجموعه\u200cی داده\u200cها دو تنظیم می\u200cکنیم. آزمایشات ما نشان می دهند که یک مدل متعدد زبان بر اساس XLM-RoBERTa بهترین نتیجه را به جز انگلیسی می رساند. به نظر می رسد زبانهای منابع کمتری از یکدیگر به عنوان یک مدل متعدد زبان آموزش یاد می گیرند MRR بالاتر از زبان مخصوص. تحلیل کیفیت ما درباره تغییرات کلمه ساده را نشان می دهد. ما مجموعه\u200cی داده\u200cها، مدل\u200cها و مجموعه\u200cهای آموزش را به طور عمومی آزاد می\u200cکنیم.', 'tr': 'Bu kagyzda, biz ilkinji multidilli FAQ veri setini publika meşgullaýarys. Biz 6M FAQ netijesinden 21 dürli dilde topladyk. Bu bar FAQ maýyp maglumaty tesbitlerden has möhüm uly bolsa hem öz kynçylyklary bilen meňzeşlik edýär: maksadyň duplikatyny we çykarmadan mesele daýlamagyny. Biz Dens Jaňky Mazmunlary (DPR) şeklinde meňzeş bir düzeni kabul edip bu datasynda çarpan iki ködlemeler üçin synanyşýarys. Biziň deneylerimiz XLM-RoBERTa daýanýan bir köp dil nusgasy iñlis dilinden başga iň gowy netijeleri başarýar. Ullanyş diller birbirinden öwrenmek üçin esasy çeşmeleri dillerden ýokaryn MRR bilen ýeterlik edip görünýär. Biziň mykdarlyk analyzamyz nusganyň ýigrendigini basit söz üýtgewlerinde görkezýär. Berüvlerimizi, nusgasymyzy we okuw skriptlerimizi publika çykarýarys.', 'bn': 'এই পত্রিকায় আমরা প্রথম বহুভাষী FAQ ডাটাসেট প্রকাশ্যে উপস্থাপন করি। We collected around 6M FAQ pairs from the web, in 21 different languages.  যদিও এটা বিদ্যমান FAQ পুনরুদ্ধার তথ্য সেট থেকে বেশী বড়, তবুও এটি নিজের চ্যালেঞ্জের সাথে এসেছে: বিষয়বস্তুর দ্বিগুণ এবং বিষয়বস্তু ডেন্স প্যাসেজ পুনরুদ্ধার (ডিপিআর) হিসেবে আমরা একই ধরনের সেট গ্রহণ করি এবং এই ডাটাসেটে বিভিন্ন বিক্রিয় কোডার পরীক্ আমাদের পরীক্ষা প্রকাশ করে যে এক্সএলএম-রোবের্তা ভিত্তিক একটি বহুভাষায় মডেল পাওয়া যায়, ইংরেজি ছাড়া। নিম্নলিখিত সম্পদের ভাষা একে অপরের কাছ থেকে শিখে মনে হচ্ছে যেহেতু একটি বহুভাষার মডেলের মাধ্যমে ভাষার বিশেষ ভাষার আমাদের পরিমাণ বিশ্লেষণ সাধারণ শব্দ পরিবর্তনের ব্যাপারে মডেলের সংকুচিতি প্রকাশ করে। আমরা প্রকাশ্যে আমাদের ডাটাসেট, মডেল এবং প্রশিক্ষণ স্ক্রিপ্ট প্রকাশ করি।', 'af': "In hierdie papier, ons stel die eerste multitaalske FAQ datastel openlik beskikbaar. Ons het omtrent 6m FAQ paar van die web versamel, in 21 verskillende tale. Alhoewel hierdie is betekenlik groter as bestaande FAQ ontvang datastelle, kom dit met sy eie uitdagings: duplikasie van inhoud en ongeregte verspreiding van onderwerpe. Ons aanvaar 'n gelyke opstelling as Dense Passage Retrieval (Dpi) en toets verskillende bi- encoders op hierdie datastel. Ons eksperimente vertoon dat 'n multitaalse model gebaseer op XLM-RoBERTa die beste resultate bereik, behalwe vir Engels. Sagter hulpbronne taal lyk soos een van die ander geleer as 'n multitaal model bereik 'n hoër MRR as taal spesifieke taal. Ons kwaliteit analiseer vertoon die brittlenheid van die model op eenvoudige woord verander. Ons verlos ons datastel, model en onderwerp skrip openlik.", 'az': 'Bu kağızda ilk çoxlu dilli FAQ veri quruluğunu açıq-aşkar göstəririk. İnternettən 6M FAQ çift topladıq, 21 fərqli dildə. Bu, mevcut FAQ verilən verilənlər qurularından çox böyükdürsə belə, öz çətinlikləri ilə gəlir: məlumatların duplikasyonu və bənzər məlumatların dağıtılması. Biz Dense Passage Retrieval (DPR) kimi bənzər bir qurğu qəbul edirik və bu verilən qurğuda müxtəlif bi-kodlayıcıları sınayırıq. Bizim təcrübələrimiz XLM-RoBERTa tabanlı çoxlu dil modeli İngilizdən başqa ən yaxşı nəticələri başa çatdığını göstərir. Daha düşük mənbələr dilləri bir-birindən öyrənən kimi çoxlu dil modeli dilindən daha yüksək MRR olar. Bizim qabiliyyətimiz analizimiz modelinin çoxluğunu basit söz dəyişikliklərinə göstərir. Biz məlumatlarımızı, modellərimizi və təhsil skriptlərini yayındırıq.', 'bs': 'U ovom papiru predstavljamo prvu multijezičku kompletu podataka FAQ javno dostupnu. Skupljali smo oko 6M FAQ pare iz mreže, na 21 različitih jezika. Iako je to značajno veće od postojećih kompleta datoteka FAQ-a, dolazi sa svojim izazovima: duplikacija sadržaja i nepravedne distribucije tema. Usvojimo sličnu postavku kao prikupljanje Dense Passage (DPR) i testiranje različitih bi-kodera na ovom setu podataka. Naši eksperimenti otkrivaju da multijezički model baziran na XLM-RoBERTa postigne najbolje rezultate, osim engleskog. Niži jezici resursa izgleda da se uče jedni od drugih kao multijezički model postiže viši MRR od jezika specifičnih. Naša kvalitativna analiza otkriva velikost modela o jednostavnim promjenama riječi. Publično objavljujemo naš podaci, model i obuku scenarija.', 'ca': "En aquest article, presentem el primer conjunt de dades multilingües FAQ disponible al públic. Vam recollir uns parells de 6M de les qüestions FAQ de la Web, en 21 llengües diferents. Tot i que això és significativament més gran que els conjunts de dades de recuperació de QFA existents, té els seus propis reptes: duplicació de contingut i distribució desigual de temes. Adopem una configuració similar a la Dense Passage Retrieval (DPR) i provem diversos bicodificadors en aquest conjunt de dades. Els nostres experiments revelen que un model multilingüe basat en XLM-RoBERTa aconsegueix els millors resultats, excepte en anglès. Sembla que les llengües amb recursos baixos aprenen entre elles, mentre un model multilingüe aconsegueix una RMR més alta que la de llengües específices. La nostra anàlisi qualitativa revela la fragilitat del model en canvis senzills de paraules. Publiquem el nostre conjunt de dades, model i escriptura d'entrenament.", 'cs': 'V tomto článku představujeme první vícejazyčný datový soubor FAQ veřejně dostupný. Shromáždili jsme kolem 6M FAQ páry z webu, v 21 různých jazycích. Přestože je to výrazně větší než existující datasety FAQ vyhledávání, přichází s vlastními problémy: duplikace obsahu a nerovnoměrné distribuce témat. Přijímáme podobné nastavení jako Dense Passage Retrieval (DPR) a testujeme různé bi-kodéry na této datové sadě. Naše experimenty ukazují, že vícejazyčný model založený na XLM-RoBERTa dosahuje nejlepších výsledků, kromě angličtiny. Jazyky nižších zdrojů se zdá, že se od sebe navzájem učí, protože vícejazyčný model dosahuje vyššího MRR než jazykově specifické jazyky. Naše kvalitativní analýza odhaluje křehkost modelu na jednoduchých slovních změnách. Veřejně zveřejňujeme datovou sadu, model a školicí skript.', 'et': 'Käesolevas artiklis tutvustame esimest mitmekeelset KKK andmekogumit avalikult kättesaadavat. Kogusime veebist umbes 6 miljonit KKK paari 21 erinevas keeles. Kuigi see on märkimisväärselt suurem kui olemasolevad KKK-andmekogumid, kaasneb see oma väljakutsetega: sisu dubleerimine ja teemade ebaühtlane jaotus. Me võtame kasutusele sarnase seadistuse nagu Dense Passage Retrieval (DPR) ja testime sellel andmekogumil erinevaid kahekodeerijaid. Meie eksperimendid näitavad, et XLM-RoBERTa-l põhinev mitmekeelne mudel saavutab parimad tulemused, välja arvatud inglise keeles. Vähemate ressurssidega keeled näivad üksteiselt õppivat, sest mitmekeelse mudeli puhul saavutatakse keelespetsiifilistest mudelitest suurem MRR. Meie kvalitatiivne analüüs näitab lihtsate sõnavahetuste mudeli haprust. Avaldame avalikult oma andmekogumi, mudeli ja koolitusskeemi.', 'fi': 'Tässä artikkelissa esittelemme ensimmäisen monikielisen FAQ-aineiston julkisesti saatavilla. Keräsimme verkosta noin 6 miljoonaa FAQ paria 21 eri kielellä. Vaikka tämä on huomattavasti suurempi kuin olemassa olevat FAQ-hakuaineistot, siihen liittyy omat haasteensa: sisällön päällekkäisyys ja aiheiden epätasainen jakautuminen. Otamme käyttöön samanlaisen asennuksen kuin Dense Passage Retrieval (DPR) ja testaamme erilaisia bi-koodereita tässä aineistossa. Kokeet osoittavat, että XLM-RoBERTa-malliin perustuva monikielinen malli tuottaa parhaat tulokset englantia lukuun ottamatta. Vähemmän resursseja käyttävät kielet näyttävät oppivan toisiltaan, koska monikielinen malli saavuttaa suuremman MRR-arvon kuin kielikohtainen malli. Laadullinen analyysimme paljastaa mallin haurauden yksinkertaisissa sanamuutoksissa. Julkaisemme julkisesti aineistomme, mallimme ja koulutusskriptimme.', 'jv': 'Nang pebuk iki, kita mulai nggawe dataset yang banter, liyane, banget kanggo mewong liyane Awak dhéwé ngêmên ning limian 6 M Faq ning web, kaya 16 luwih sing mengko. politenessoffpolite"), and when there is a change ("assertivepoliteness We sumong-sumong mulai setup sing dibenakake Dense pass retribution (PPR) lan ujian sampeyan bi-koder nang dataset iki. Awakdhéwé éntuk ngerasakno karo model sing sampeyan anyar lengkang basa ning XLM-RBERT sampeyan gawe barang apik dhéwé, njuk kesempatan Inggris. Tulung ingkang apat kanggo langgar sapa-apat kanggo sampek karo akeh liyane Ndalasi paten sing paling dhéwé ngerasai awak dhéwé kuwi model nang ngerasai gambaran anyar. Awak dhéwé ngewehke pernik-pernik akeh dadi, model lan seneng nggawe barang.', 'sk': 'V tem prispevku predstavljamo prvi večjezični nabor podatkov o pogosta vprašanja, ki so javno dostopni. Iz spleta smo zbrali okoli 6 milijonov parov FAQ v 21 različnih jezikih. Čeprav je to bistveno večje od obstoječih naborov podatkov za pridobivanje pogosta vprašanja, se pojavlja z lastnimi izzivi: podvajanje vsebine in neenakomerno porazdelitev tem. Sprejemamo podobno nastavitev kot Dense Passage Retrieval (DPR) in testiramo različne bi-kodirje na tem naboru podatkov. Naši poskusi kažejo, da večjezični model, ki temelji na XLM-RoBERTa, dosega najboljše rezultate, razen angleščine. Zdi se, da se jeziki z nižjimi viri učijo drug od drugega, saj večjezični model dosega višje MRR kot značilni za jezik. Naša kvalitativna analiza razkriva krhkost modela pri preprostih besednih spremembah. Javno objavljamo naš nabor podatkov, model in scenarij za usposabljanje.', 'ha': "Ga wannan takardan, muna halatar da kodi na farkon FAQ na cikin mulki-lingui. Ba mu samun duk biyu daga intani na 6M FAQ, cikin harshen 21 dabam-daban. Ingawa wannan mai girma ne mafi girma daga masu motsa da FAQ wanda ke jira, sai ta zo da zanen kansa: dubiyar cikin maɓalli da rabon da ba'a sani ba. Tuna zãɓi tsarin da ke daidai kamar Dakata Gaza ta kõma (daidai) kuma Muke jarraba wasu kodi masu bin-kodi kan wannan database. Kayan jarrabõnmu sun bayyana cewa wata misalin mulki-lingui a kan XLM-RoBERTA ya sãmu mafi kyaun matsala, fãce da Ingiriya. Harsunan da ke ƙas ƙanci, za'a sanar da shi daga ɗayan, kamar wata misalin multilala na ƙari ya sami da mafiya da MRR daga masu ƙayyade-harshe. AnalyyinMu na ƙididdige, yana bayyana mai ƙari daga misalin na kan musanya magana masu sauƙi. Muna sakar da misalin mutane, misalin da umarni.", 'he': 'In this paper, we present the first multilingual FAQ dataset publicly available.  We collected around 6M FAQ pairs from the web, in 21 different languages.  למרות שזה גדול באופן משמעותי מאספי נתונים של FAQ קיימים, הוא מגיע עם אתגרים משלו: כפילה של התוכן והפיצול לא שווה של נושאים. אנו מאמצים סדרה דומה כמו השיגת דרכים דנס (Dense Passage Retrieval - DPR) ולבדוק שני קודנים שונים על סדרת הנתונים הזאת. הניסויים שלנו חושפים שמודל רב-שפוי מבוסס על XLM-RoBERTa משיג את התוצאות הטובות ביותר, מלבד אנגלית. שפות משאבים נמוכות יותר נראות ללמוד אחד מהשני כאשר מודל רב-שפתי משיג MRR גבוה יותר מאשר שפות ספציפיות. הניתוח האיכותי שלנו מגלה את חולשתו של המודל על שינויים פשוטים במילים. אנחנו פורסמים בפומבי את התסריט המידע, המודל והאימון שלנו.', 'bo': 'ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ཤོག་བྱང་ཐོག་མའི་སྐད་རིགས་ཆ་མང་པོ་ཞིག་གི་ཆ་འཕྲིན་ཡིག ང་ཚོས་དྲ་ཐོག་ཏུ་6M FAQ་གི་ཆ་ཤས་གཅིག་སྒྲིག་བྱས་པ་ནི་སྐད་རིགས་གཞན་21ནང་དུ་རེད། འདི་གནས་ཡོད་པའི་FAQ་ལྟ་ཀློག་པའི་ཆ་འཕྲིན་སྒྲིག ང་ཚོས་Dense Passage Retrieval (DPR)དང་གནད་སྡུད་འདིའི་ནང་གི་སྒྲིག་འཛུགས་ཆས་འདྲ་མིན་བཟོ་བྱེད་པ ང་ཚོའི་བརྟག་ཞིག་གིས་XLM-RoBERTa བརྟེན་ནས་སྐད་ཡིག ཆ་རྐྱེན་དང་ཐོག་མའི་སྐད་རིགས་གཅིག་ལས་སྦྱར་བའི་སྐད་རིགས་ཀྱི་མ་དཔེ་གཏན་ཁེལ་ནི་སྐད ང་ཚོའི་སྒེར་གྱི་དབྱེ་ཞིབ་ཀྱིས་རྣམ་གྲངས་ཀྱི་ཆེད་དུ་འཕགས་པ་སྟོན་ཡོད། We publicly release our dataset, model and training script.'}
{'en': 'Can Question Generation Debias ', 'pt': 'O Debias de geração de perguntas pode responder aos modelos de perguntas? Um estudo de caso sobre sobreposição lexical de pergunta-contexto', 'fr': 'Les modèles de réponse aux questions Debias peuvent-ils poser des questions\xa0? Une étude de cas sur le chevauchement lexical question-contexte', 'ar': 'هل يستطيع توليد الأسئلة Debias نماذج الإجابة على الأسئلة؟ دراسة حالة حول التداخل المعجمي بين السؤال والسياق', 'es': '¿Puede la generación de preguntas de Debian cuestionar modelos de respuesta Un estudio de caso sobre la pregunta: superposición léxica de contexto', 'ru': 'Может ли генерация вопросов Дебиас ответить на вопросы моделей? Тематическое исследование о лексическом перекрытии вопросов и контекста', 'ja': '質問生成デビアス質問回答モデルは使用できますか？質問文と文脈の語彙の重複に関するケーススタディ', 'zh': '问可以对乎? 其问-上下文词法重叠案例究之', 'hi': 'प्रश्न जनरेशन Debias सवाल जवाब मॉडल कर सकते हैं? प्रश्न-संदर्भ लेक्सिकल ओवरलैप पर एक केस स्टडी', 'ga': 'An féidir Múnlaí Freagartha Ceist a Dhéanamh Debias Giniúint Ceisteanna? Cás-Staidéar ar Fhorluí Foclaíochta Ceist–Comhthéacs', 'ka': 'შეიძლება კითხვების შექმნა Debias კითხვების გარეშე მოდელები? Name', 'hu': 'Kérdezheti meg a kérdések generációját Debias a modellek megválaszolását? Esettanulmány a kérdés-kontextus lexikai átfedéséről', 'el': 'Μπορεί η γενιά ερωτήσεων να ερωτήσει μοντέλα απάντησης; Μια μελέτη περίπτωσης σχετικά με την Lexical Overlap ερωτήσεων-πλαισίου', 'it': 'Può Question Generation Debias interrogare i modelli di risposta? Un caso di studio sulla sovrapposizione lessicale del contesto interrogativo', 'kk': 'Сұрақ құру Debias сұрақ жауап беру үлгілері бола ма? Сұрақ- контексті лексикалық үстінен үлкен әріптерді оқу', 'lt': 'Ar klausimų generavimo klausimai gali būti svarstomi klausimų atsakymo modeliais? Klausimų konteksto Lexikos apžvalgos atvejų tyrimas', 'mk': 'Can Question Generation Debias Question Answering Models?  Name', 'ml': 'ചോദ്യം തലമുറന്ന ഡെബിയസ് ചോദ്യം ഉത്തരം നല്\u200dകുന്ന മോഡലുകള്\u200dക്ക് സാധിക്കുമോ? ചോദ്യത്തില്\u200d - ഉള്ളിലുള്ള ലെക്സിക്കല്\u200d ഒഴിവാക്കുന്നതില്\u200d ഒരു കേസ് പഠനം', 'ms': 'Bolehkah Model Jawapan Soalan Menjana Debias? Name', 'mt': 'Il-mudelli tat-tweġiba għall-mistoqsijiet jistgħu jiġu diskussi fil-Ġenerazzjoni tal-mistoqsijiet? Studju ta’ Każ dwar il-Kuntest ta’ Mistoqsijiet', 'mn': 'асуулт бий болгох Debias асуулт хариултын загварууд болох уу? Судалгаан-нөхцөл сэтгэл хөдлөлийн тухай судалгаа', 'pl': 'Czy Debaty Generacji Pytań mogą pytać modele odpowiedzi na pytania? Studium przypadku dotyczące nakładki leksykalnej w kontekście pytań', 'no': 'Kan oppretta spørsmålmodular for å svara på spørsmål i Debias? Name', 'ro': 'Poate întreba Generația Debias să pună întrebări despre modelele de răspuns? Un studiu de caz privind suprapunerea lexicală a întrebărilor-context', 'si': 'ප්\u200dරශ්න නිර්මාණයෙන් ඩෙබියාස් ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්නයක් ප්\u200dරතික්\u200dරියා Name', 'so': 'Can Question Generation Debias Question Answering Models?  A Case Study on Question-Context Lexical Overlap', 'sr': 'Može li modeli odgovora na pitanja? Proučavanje slučajeva o suštini sa pitanjima', 'sv': 'Kan Question Generation Debias fråga besvarande modeller? En fallstudie om frågesammanhang Lexical Overlap', 'ta': 'Can Question Generation Debias Question Answering Models?  கேள்வி உள்ளடக்கத்தில் உள்ள மேல்மேற்கோள் மீது ஒரு நிலை ஆய்வு', 'ur': 'سؤال پیدا کرنے کے لئے Debias سؤال جواب دینے کے موڈل سکتے ہیں؟ Name', 'vi': 'Có thể đặt câu hỏi cho các câu hỏi mẫu được không? Nghiên cứu về câu hỏi: ¶ Câu hỏi 811Sự chung quy vi ngôn ngữ', 'uz': '@ info Name', 'nl': 'Kan Question Generation Debias Vragen beantwoorden aan modellen? Een casestudy over Lexical Overlap tussen vragen en context', 'hr': 'Može li modeli odgovora na pitanja za generaciju pitanja Debias? Ispitivanje slučajeva o leksičkom preklapanju pitanja', 'bg': 'Могат ли Дебиас да отговаря на въпроси модели? Проучване на казус по въпросите и контекста на лексиката', 'da': 'Kan spørgsmål Generation Debias spørge om besvarelse af modeller? En case-undersøgelse om spørgsmål-sammenhæng Lexical Overlap', 'de': 'Kann Question Generation Debias Antwortmodelle in Frage stellen? Eine Fallstudie zu Fragenkontext Lexical Overlap', 'ko': '질문 생성을 퀴즈 모델로 할 수 있습니까?문제-어경-어휘 중첩의 개안 연구', 'id': 'Dapatkah Generasi Pertanyaan Debias Menjawab Model Pertanyaan? Sebuah studi kasus tentang Pertanyaan-Konteks Leksikal Overlap', 'fa': 'آیا می\u200cتواند نسل سوال\u200cها مدل\u200cهای پاسخ\u200cدهنده سوال Debias را بپرسید؟ یک مطالعه پرونده در مورد جریان سوال و موضوع جریان', 'sw': 'Je swali linaweza kujibu Maswali ya Maswali? Utafiti wa Mashtaka kuhusu Swali-Context Overlap', 'af': 'Kan Fraag Generasie Debias Vrag Antwoord Modelle? Name', 'am': 'የጥያቄ ትውልድ ዲቢስ ጥያቄን ለመመልስ ሞዴል ይችላልን? Question-Context Lexical Overlap', 'hy': 'Կարո՞ղ է հարցեր ստեղծելու համար քննարկել հարցերին պատասխանելու մոդելները: Հարցողական-կոնտեքստի լեքսիկական վերածման դեպքերի ուսումնասիրությունը', 'tr': 'Sorag generalizasy Debias sorag jogap nusgala edip bilermi? Sorag-Kontekst Leksik Üstini barada Kiçi/beýik Okuwy', 'ca': 'Poden la generació de preguntesdebatir els models de resposta a preguntes? Un estudi de cas sobre la superfície lèxica del contest de preguntes', 'bs': 'Može li modeli odgovora na pitanja za generaciju pitanja Debias? Ispitivanje slučajeva o prepreku leksičkog konteksta pitanja', 'sq': 'A mund gjenerimi i pyetjeve të debatojë modelet për përgjigjen e pyetjeve? Një studim rasti mbi përmbysjen lexike në kontekstin e pyetjeve', 'bn': 'প্রশ্ন জেনারেশন ডেবিয়াস প্রশ্নের উত্তর মোডেল কি প্রশ্ন করতে পারে? প্রশ্ন- বিষয়বস্তু লেক্সিক্যাল ওপার্ল্যাপে একটি কেস স্টিডি', 'fi': 'Voiko Question Generation Debias Question Answering Models? Tapaustutkimus kysymyksen kontekstin Lexical Overlapista', 'az': 'sual Generasyonu Debias sual cavab vermﾉ冖 modellﾉ决i ola bilﾉ决mi? Suﾄ殷l-Kontekst Leksik ﾃ僕ﾃｧﾃｼsﾃｼ', 'cs': 'Může generace otázek Debias dotazovat modely zodpovězení? Případová studie o Lexickém překrytí otázek a kontextu', 'et': 'Kas küsimuste generatsioon Debias küsimustele vastamise mudelid võivad? Juhtumiuuring küsimuse konteksti leksikomplekti ülekandmise kohta', 'jv': 'Gak Iso Kelangang Generasi Galian Debiah Panjenengan Mbal? Language', 'ha': '@ action KCharselect unicode block name', 'sk': 'Ali lahko generacija vprašanj Debias vprašanja odgovarja modeli? Študija primera o leksičnem prekrivanju vprašanj in konteksta', 'bo': 'དྲི་ཚིག་ལ་བཟོ་བྱེད་མི་ཐུབ་པ་དེ་Debias་ལ་བསམ་བློ་གཏོང་གི་མ་དབྱིབས་ལན་གསལ་མོས་པ། Question-Context Lexical Overlap', 'he': 'Can Question Generation Debias Question Answering Models?  A Case Study on Question-Context Lexical Overlap'}
{'en': 'Question answering (QA) models for ', 'ar': 'تم إثبات أن نماذج الإجابة على الأسئلة (QA) لفهم القراءة تستغل التحيزات غير المقصودة في مجموعة البيانات مثل التداخل المعجمي في سياق السؤال. هذا يعيق نماذج ضمان الجودة من التعميم على العينات الممثلة تمثيلاً ناقصًا مثل الأسئلة ذات التداخل المعجمي المنخفض. يمكن أن يكون إنشاء الأسئلة (QG) ، وهو طريقة لزيادة مجموعات بيانات ضمان الجودة ، حلاً لمثل هذا التدهور في الأداء إذا كان بإمكان QG تصحيح مجموعات بيانات ضمان الجودة بشكل صحيح. ومع ذلك ، نكتشف أن نماذج QG العصبية الحديثة منحازة لتوليد أسئلة ذات تداخل معجمي مرتفع ، مما قد يؤدي إلى تضخيم تحيز مجموعة البيانات. علاوة على ذلك ، يكشف تحليلنا أن زيادة البيانات باستخدام نماذج QG هذه تؤدي في كثير من الأحيان إلى إعاقة الأداء في الأسئلة ذات التداخل المعجمي المنخفض ، مع تحسين ذلك في الأسئلة ذات التداخل المعجمي العالي. لمعالجة هذه المشكلة ، نستخدم نهجًا قائمًا على استبدال المرادفات لزيادة الأسئلة ذات التداخل المعجمي المنخفض. لقد أوضحنا أن نهج زيادة البيانات المقترح بسيط ولكنه فعال للتخفيف من مشكلة التدهور باستخدام 70 ألف مثال تركيبي فقط.', 'fr': "Il a été démontré que les modèles de réponse aux questions (AQ) pour la compréhension de la lecture exploitent les biais involontaires des ensembles de données tels que le chevauchement lexical question-contexte. Cela empêche les modèles d'assurance qualité de se généraliser à des échantillons sous-représentés tels que les questions avec un faible chevauchement lexical. La génération de questions (QG), une méthode d'augmentation des ensembles de données d'assurance qualité, peut être une solution à une telle dégradation des performances si QG peut correctement débiaiser les jeux de données d'AQ. Cependant, nous découvrons que les modèles récents de QG neuronal sont biaisés pour générer des questions avec un fort chevauchement lexical, ce qui peut amplifier le biais de l'ensemble de données. De plus, notre analyse révèle que l'augmentation des données avec ces modèles QG nuit fréquemment aux performances sur les questions présentant un faible chevauchement lexical, tout en améliorant celles sur les questions à fort chevauchement lexical. Pour résoudre ce problème, nous utilisons une approche basée sur le remplacement de synonymes afin de compléter les questions présentant un faible chevauchement lexical. Nous démontrons que l'approche d'augmentation des données proposée est simple mais efficace pour atténuer le problème de dégradation avec seulement 70 000 exemples synthétiques.", 'es': 'Se ha demostrado que los modelos de respuesta a preguntas (QA) para la comprensión lectora aprovechan los sesgos no intencionados de los conjuntos de datos, como la superposición léxica de preguntas y Esto impide que los modelos de control de calidad generalicen a muestras infrarrepresentadas, como preguntas con baja superposición léxica. La generación de preguntas (QG), un método para aumentar los conjuntos de datos de control de calidad, puede ser una solución para dicha degradación del rendimiento si QG puede debilitar correctamente los conjuntos de datos de control de calidad. Sin embargo, descubrimos que los modelos QG neuronales recientes están sesgados a generar preguntas con una alta superposición léxica, lo que puede amplificar el sesgo del conjunto de datos. Además, nuestro análisis revela que el aumento de datos con estos modelos QG con frecuencia perjudica el rendimiento en las preguntas con baja superposición léxica, al tiempo que mejora el de las preguntas con alta superposición léxica. Para abordar este problema, utilizamos un enfoque basado en la sustitución de sinónimos para aumentar las preguntas con baja superposición léxica. Demostramos que el enfoque de aumento de datos propuesto es simple pero efectivo para mitigar el problema de la degradación con solo 70 mil ejemplos sintéticos.', 'pt': 'Os modelos de resposta a perguntas (QA) para compreensão de leitura demonstraram explorar vieses não intencionais de conjuntos de dados, como sobreposição lexical de contexto de pergunta. Isso impede que os modelos de controle de qualidade sejam generalizados para amostras sub-representadas, como perguntas com baixa sobreposição lexical. A geração de perguntas (QG), um método para aumentar conjuntos de dados de QA, pode ser uma solução para essa degradação de desempenho se o QG puder corrigir adequadamente os conjuntos de dados de QA. No entanto, descobrimos que os modelos QG neurais recentes são tendenciosos para gerar perguntas com alta sobreposição lexical, o que pode amplificar o viés do conjunto de dados. Além disso, nossa análise revela que o aumento de dados com esses modelos QG frequentemente prejudica o desempenho em questões com baixa sobreposição lexical, enquanto melhora em questões com alta sobreposição lexical. Para resolver esse problema, usamos uma abordagem baseada na substituição de sinônimos para aumentar as perguntas com baixa sobreposição lexical. Demonstramos que a abordagem de aumento de dados proposta é simples, mas eficaz para mitigar o problema de degradação com apenas 70 mil exemplos sintéticos.', 'hi': 'समझने की समझ को पढ़ने के लिए प्रश्न उत्तर (क्यूए) मॉडल को अनपेक्षित डेटासेट पूर्वाग्रहों जैसे प्रश्न-संदर्भ लेक्सिकल ओवरलैप का शोषण करने के लिए प्रदर्शित किया गया है। यह क्यूए मॉडल को कम लेक्सिकल ओवरलैप वाले प्रश्नों जैसे कम-प्रतिनिधित्व वाले नमूनों को सामान्यीकृत करने से रोकता है। प्रश्न पीढ़ी (क्यूजी), क्यूए डेटासेट को बढ़ाने के लिए एक विधि, इस तरह के प्रदर्शन गिरावट के लिए एक समाधान हो सकती है यदि क्यूजी क्यूए डेटासेट को ठीक से डिबियास कर सकता है। हालांकि, हमें पता चलता है कि हाल के तंत्रिका क्यूजी मॉडल उच्च लेक्सिकल ओवरलैप के साथ प्रश्न उत्पन्न करने की दिशा में पक्षपाती हैं, जो डेटासेट पूर्वाग्रह को बढ़ा सकते हैं। इसके अलावा, हमारे विश्लेषण से पता चलता है कि इन क्यूजी मॉडल के साथ डेटा वृद्धि अक्सर कम लेक्सिकल ओवरलैप वाले प्रश्नों पर प्रदर्शन को बाधित करती है, जबकि उच्च लेक्सिकल ओवरलैप वाले प्रश्नों पर सुधार करती है। इस समस्या को हल करने के लिए, हम कम लेक्सिकल ओवरलैप के साथ प्रश्नों को बढ़ाने के लिए एक समानार्थक प्रतिस्थापन-आधारित दृष्टिकोण का उपयोग करते हैं। हम प्रदर्शित करते हैं कि प्रस्तावित डेटा संवर्धन दृष्टिकोण केवल 70k सिंथेटिक उदाहरणों के साथ गिरावट की समस्या को कम करने के लिए सरल अभी तक प्रभावी है।', 'ja': '理解度を読み取るための質問回答（ QA ）モデルは、質問文脈の語彙的重複などの意図しないデータセットのバイアスを利用することが実証されています。 これにより、QAモデルは、単語の重複が少ない質問などのサンプルを一般化することができなくなります。 QAデータセットを拡張するための方法である質問生成（ QG ）は、QGがQAデータセットを適切にデバイアスできる場合、そのようなパフォーマンス低下の解決策となり得る。 しかし、最近のニューラルQGモデルは、データセットのバイアスを増幅させる可能性のある高い語彙重複のある質問を生成することに偏っていることが発見されました。 さらに、私たちの分析では、これらのQGモデルを使用したデータ増強は、語彙重複の少ない質問のパフォーマンスを損なうことが多いことが明らかになりました。一方で、語彙重複の多い質問のパフォーマンスを改善しました。 この問題に対処するために、代名詞置換ベースのアプローチを使用して、語彙の重複が少ない質問を拡張します。 私たちは、提案されたデータ拡張アプローチが、わずか70,000の合成例で分解問題を軽減するために単純でありながら効果的であることを実証します。', 'zh': '以观解对(QA)模形已验可因意外数集偏差,如问 - 上下文词汇重叠。 此格 QA 模样本及代表性不足之样本,词汇重叠也。 (QG) 者,所以广 QA 数集也,若 QG 正消 QA 数集之偏倚,则可以为降解决方案。 然见近神经QG偏向生高词汇重叠,或会放大数集差。 此外,吾分析表明用此QG数增常损词汇重轻之性,兼善词汇重叠之性。 所以然者,用同义词易之道以益词汇重也。 臣等证其数增而效缓退化,惟7万个合为实。', 'ru': 'Было продемонстрировано, что модели ответов на вопросы (QA) для понимания чтения используют непреднамеренные погрешности набора данных, такие как лексическое перекрытие вопросов и контекстов. Это мешает моделям QA от обобщающих до недопредставленных образцов, таких как вопросы с низким лексическим перекрытием. Генерация вопросов (QG), метод для увеличения наборов данных QA, может быть решением для такого ухудшения производительности, если QG может правильно дебировать наборы данных QA. Тем не менее, мы обнаружили, что последние нейронные модели QG склонны генерировать вопросы с высоким лексическим перекрытием, что может усилить смещение набора данных. Кроме того, наш анализ показывает, что увеличение данных с помощью этих моделей QG часто снижает эффективность по вопросам с низким лексическим перекрытием, в то же время улучшая их по вопросам с высоким лексическим перекрытием. Для решения этой проблемы мы используем подход, основанный на замене синонимов, для дополнения вопросов с низким лексическим перекрытием. Мы демонстрируем, что предлагаемый подход к увеличению данных прост, но эффективен для смягчения проблемы деградации с помощью только 70 тыс. синтетических примеров.', 'ga': 'Léiríodh go mbaineann samhlacha freagartha ceisteanna (QA) don léamhthuiscint leas a bhaint as laofachtaí neamhbheartaithe tacair sonraí ar nós forluí foclóireachta ceist-chomhthéacs. Cuireann sé seo bac ar mhúnlaí QA ó ghinearálú go samplaí nach bhfuil dóthain ionadaíochta déanta orthu ar nós ceisteanna a bhfuil forluí foclóireachta íseal acu. Is féidir le giniúint ceisteanna (QG), modh chun tacair shonraí QA a mhéadú, a bheith ina réiteach le haghaidh díghrádaithe feidhmíochta dá leithéid más féidir le QG tacair sonraí QA a dhíchlaonadh i gceart. Faighimid amach, áfach, go bhfuil samhlacha néaracha QG le déanaí claonta i dtreo ceisteanna a ghiniúint a bhfuil forluí ard foclóireachta ag baint leo, ar féidir leo an claonadh tacar sonraí a mhéadú. Ina theannta sin, léiríonn ár n-anailís go gcuireann méadú ar shonraí leis na samhlacha QG seo isteach go minic ar an bhfeidhmíocht ar cheisteanna a bhfuil forluí foclóireachta íseal ag baint leo, agus é sin á fheabhsú ar cheisteanna a bhfuil forluí ard foclóireachta acu. Chun dul i ngleic leis an bhfadhb seo, bainimid úsáid as cur chuige ionadaíoch comhchiallach chun ceisteanna a mhéadú le forluí foclóireachta íseal. Léirímid go bhfuil an cur chuige méadaithe sonraí atá beartaithe simplí ach éifeachtach chun fadhb an díghrádaithe a mhaolú agus gan ach 70k samplaí sintéiseacha ann.', 'ka': 'კითხვის პასუხი (QA) მოდელები კითხვის შესაძლებელობის შესახებ მოდელესებულია, როგორც კითხვა- კონტექსტური ლექსიკალური გადარჩენა. ეს უნდა QA მოდელების გენერალიზაციას უფრო გამოსახულებული მოდელებისთვის, როგორც კითხვები ცოტა ლექსიკალური გადატანა. Name მაგრამ ჩვენ აღმოჩნეთ, რომ ახლა ნეიროლური QG მოდელები უნდა იყოს კითხვების შექმნა, რომლებიც მეტი ლექსიკალური გადატანა, რომლებიც შეუძლიათ მონაცემების გადა დამატებით, ჩვენი ანალიზია აღმოჩნდება, რომ ეს QG მოდელებით ზოგიერთად გამოცდილობას კითხვების შესახებ, რომლებიც ცოტა ლექსიკალური შესახებ, ამას უფრო მეტადება კითხვების შესახებ ამ პრობლემას გადაწყვეტისთვის, ჩვენ გამოვიყენებთ სინონიმური შეცვლის მიხედვით კითხვების გაზრუქებას, რომლებიც ცოტა ლექსიკალური გადაწყვეტი ჩვენ გამოჩვენებთ, რომ მოწყობინებული მონაცემების აღმოქმედება უფრო მაგრამ ეფექტიურია, რომ დეგრადიაციის პრობლემას გადაკვეტირება მხოლოდ 70k სინტეტიული მა', 'el': 'Τα μοντέλα απάντησης ερωτήσεων (QA) για την κατανόηση ανάγνωσης έχουν αποδειχθεί ότι εκμεταλλεύονται ακούσιες προκατάληψη συνόλου δεδομένων, όπως η λεξική επικάλυψη ερωτήματος-πλαισίου. Αυτό εμποδίζει τα μοντέλα QA από τη γενίκευση σε υποεκπροσωπούμενα δείγματα, όπως ερωτήσεις με χαμηλή λεξική επικάλυψη. Η δημιουργία ερωτήσεων (QG), μια μέθοδος για την αύξηση των συνόλων δεδομένων QA, μπορεί να αποτελέσει λύση για μια τέτοια υποβάθμιση της απόδοσης, εάν η QG μπορεί να αποσβέσει σωστά τα σύνολα δεδομένων QA. Ωστόσο, ανακαλύπτουμε ότι τα πρόσφατα νευρωνικά μοντέλα είναι προκατειλημμένα στη δημιουργία ερωτήσεων με υψηλή λεξική επικάλυψη, τα οποία μπορούν να ενισχύσουν την προκατάληψη του συνόλου δεδομένων. Επιπλέον, η ανάλυση μας αποκαλύπτει ότι η αύξηση δεδομένων με αυτά τα μοντέλα συχνά μειώνει την απόδοση σε ερωτήματα με χαμηλή λεξική επικάλυψη, ενώ βελτιώνει αυτή σε ερωτήματα με υψηλή λεξική επικάλυψη. Για να αντιμετωπιστεί αυτό το πρόβλημα, χρησιμοποιούμε μια συνώνυμη προσέγγιση αντικατάστασης για την αύξηση των ερωτήσεων με χαμηλή λεξική επικάλυψη. Αποδεικνύουμε ότι η προτεινόμενη προσέγγιση αύξησης δεδομένων είναι απλή αλλά αποτελεσματική για να μετριάσει το πρόβλημα υποβάθμισης με μόνο 70συνθετικά παραδείγματα.', 'hu': 'Az olvasásértéshez szükséges kérdésválaszolási modellek kimutatták, hogy kihasználják a nem szándékos adatkészlet-előítéleteket, mint például a kérdés-kontextus lexikai átfedés. Ez akadályozza a minőségbiztosítási modellek általánosítását alulreprezentált mintákra, például alacsony lexikális átfedéssel rendelkező kérdésekre. Kérdések generálása (QG), a QA adatkészletek bővítésére szolgáló módszer, megoldást jelenthet az ilyen teljesítménycsökkentésre, ha a QG megfelelően meg tudja rontani a QA adatkészleteket. Felfedeztük azonban, hogy a legújabb neurális QG modellek elfogultak a nagy lexikális átfedéssel rendelkező kérdések generálására, ami felerősítheti az adatkészlet elfogultságát. Továbbá elemzésünk azt mutatja, hogy ezekkel a QG modellekkel történő adatok nagyobbítása gyakran rontja az alacsony lexikális átfedéssel rendelkező kérdések teljesítményét, miközben javítja a nagy lexikális átfedéssel rendelkező kérdések teljesítményét. A probléma megoldásához szinonimás helyettesítő megközelítést alkalmazunk az alacsony lexikális átfedéssel rendelkező kérdések kiegészítésére. Kimutatjuk, hogy a javasolt adatbővítési megközelítés egyszerű, mégis hatékony a bomlási probléma enyhítésére mindössze 70 ezer szintetikus példával.', 'it': "I modelli di risposta alle domande (QA) per la comprensione della lettura sono stati dimostrati in grado di sfruttare pregiudizi involontari del set di dati come la sovrapposizione lessicale domanda-contesto. Ciò impedisce ai modelli QA di generalizzare a campioni sottorappresentati come domande con bassa sovrapposizione lessicale. Question generation (QG), un metodo per aumentare i dataset QA, può essere una soluzione per tale degradazione delle prestazioni se QG può debiare correttamente i dataset QA. Tuttavia, scopriamo che i recenti modelli di QG neurali sono orientati verso la generazione di domande con elevata sovrapposizione lessicale, che possono amplificare il bias del set di dati. Inoltre, la nostra analisi rivela che l'aumento dei dati con questi modelli QG spesso compromette le prestazioni su domande con bassa sovrapposizione lessicale, migliorando quella su domande con elevata sovrapposizione lessicale. Per risolvere questo problema, utilizziamo un approccio basato sulla sostituzione di sinonimi per aumentare le domande con bassa sovrapposizione lessicale. Dimostriamo che l'approccio proposto per l'aumento dei dati è semplice ma efficace per mitigare il problema della degradazione con soli 70k esempi sintetici.", 'lt': 'Įrodyta, kad atsakymai į klausimus (QA) skaitymo supratimo modeliai naudoja nenumatytus duomenų rinkinio iškraipymus, pavyzdžiui, klausimų ir konteksto leksinius sutapimus. Tai trukdo QA modeliams generalizuoti į nepakankamai atstovaujamus mėginius, pavyzdžiui, nedidelio lexinio dubliavimo klausimus. Klausimų generavimas (QG), QA duomenų rinkinių didinimo metodas, gali būti tokio veikimo blogėjimo sprendimas, jei QG gali tinkamai susilpninti QA duomenų rinkinius. Vis dėlto mes atradome, kad neseniai taikomi neurologiniai QG modeliai yra nukreipti į klausimų su dideliu leksiniu dubliavimu sukūrimą, kuris gali sustiprinti duomenų rinkinio nukreipimą. Be to, mūsų analizė atskleidžia, kad duomenų didinimas naudojant šiuos QG modelius dažnai mažina rezultatus, susijusius su nedideliu lexinio dubliavimu, tuo pat metu gerina rezultatus, susijusius su dideliu leksiniu dubliavimu. Siekdami išspręsti šią problem ą, naudojame sinonimu pagrįstą pakaitinį metodą, kad būtų padidinti klausimai, kurių leksinis dubliavimas mažas. We demonstrate that the proposed data augmentation approach is simple yet effective to mitigate the degradation problem with only 70k synthetic examples.', 'mk': 'Моделите за одговори на прашања (QA) за разбирање на читањето се покажани дека ги искористуваат ненамерните предрасуди на датотеките како што се прашање-контекст лексикална прекривање. Ова ги попречува моделите на QA од генерализирање на примероци кои се недостаточно претставени, како што се прашањата со ниско лексикално прекривање. Генерација на прашања (QG), метод за зголемување на QA датотеките, може да биде решение за ваква деградација на резултатите ако QG може да ги дебира QA датотеките. Сепак, откриваме дека неодамнешните неурални QG модели се пристрасни кон генерирање прашања со висока лексикална прекривање, што може да ја зголеми пристрасноста на податоците. Покрај тоа, нашата анализа открива дека зголемувањето на податоците со овие QG модели често ја намалува резултатот на прашањата со ниска лексикална прекривка, истовремено подобрувајќи го тоа на прашањата со висока лексикална прекривка. To address this problem, we use a synonym replacement-based approach to augment questions with low lexical overlap.  Демонстрираме дека предложениот пристап за зголемување на податоците е едноставен, но ефикасен за олеснување на проблемот со деградација со само 70 илјади синтетички примери.', 'kk': 'Сұрақ жауап беру (QA) үлгілері оқу үшін керек деректер жинақтарын қолдану үшін көрсетілді, мысалы, сұрақ- контекстік лексикалық үстінен шығу үшін. Бұл QA үлгілерін жалпы түрлендіру үлгілеріне, мысалы, лексикалық түрлендіру үлгілерімен сұрақтарды жасауға болады. QA деректер қорларын қосу құру (QG), QA деректер қорларын қосу әдісі, QG QA деректер қорларын дұрыс дебиялау мүмкін болса, бұл істеу деградациясының шешімі болады. Бірақ біз жаңа невралдық QG үлгілері лексикалық үстінен сұрақтарды жасау үшін, деректер жинағын көтеруге болады. Сонымен қатар, анализ бұл QG үлгілерінде деректерді көбірек көбірек лексикалық теңдеу сұрақтардың көбіректігін көбірек өзгертеді. Бұл сұрақтарды жоғары лексикалық теңдеу үшін жақсарту Бұл мәселеге шешу үшін, біз синонимді алмастыру тәсілдерін лексикалық үстінен төмен сұрақтарды көтеру үшін қолданамыз. Біз қолданылатын деректерді жақсарту тәсілі 70 км синтетикалық мысалдармен деградациялау мәселесін көшірмелеу үшін қарапайым, бірақ ең әсер ететін деңгейін көрсетед', 'ms': 'Model menjawab soalan (QA) untuk pemahaman pembacaan telah diaktifkan untuk mengeksploitasi biases set data tidak disengaja seperti salin leksikal konteks-soalan. Ini menghalangi model QA daripada menambah ke sampel yang dibawah-mewakili seperti soalan dengan meliputi leksikal rendah. Generasi soalan (QG), kaedah untuk menambah set data QA, boleh menjadi penyelesaian untuk penghancur prestasi seperti ini jika QG boleh debias set data QA dengan betul. Namun, kita menemukan bahawa model QG saraf baru-baru ini adalah bias untuk menghasilkan soalan dengan meliputi leksikal tinggi, yang boleh amplifikasi bias set data. Selain itu, analisis kami mengungkapkan bahawa peningkatan data dengan model QG ini sering mengurangkan prestasi pada soalan dengan meliputi leksikal rendah, sementara meningkatkannya pada soalan dengan meliputi leksikal tinggi. Untuk mengatasi masalah ini, kita menggunakan pendekatan berdasarkan penggantian sinonim untuk menambah soalan dengan meliputi leksikal rendah. We demonstrate that the proposed data augmentation approach is simple yet effective to mitigate the degradation problem with only 70k synthetic examples.', 'ml': 'വായിക്കുന്നതിനുള്ള ചോദ്യങ്ങള്\u200d ഇത് ക്യൂഎ മോഡലുകള്\u200d കുറഞ്ഞ ലെക്സിക്കല്\u200d മേല്\u200dപ്പിലുള്ള ചോദ്യങ്ങളുടെ കീഴിലേക്ക് പ്രതിനിധികളായ മാമ്പുകള്\u200d  ക്യൂഎ ഡാറ്റാസറ്റുകള്\u200d കൂട്ടിചേര്\u200dക്കുന്നതിനുള്ള ചോദ്യ തലമുറയാകുന്ന ചോദ്യ (കിയിജി), ക്യൂഎ ഡാറ്റാസറ്റുകള്\u200d കൂടുതല്\u200d പ് However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias.  അതുകൊണ്ടും, നമ്മുടെ അന്വേഷണം വെളിപ്പെടുത്തുന്നു ഈ ക്യൂജി മോഡലുകളുമായി ഡേറ്റാ കൂട്ടിചേര്\u200dക്കുന്നത് എപ്പോഴും കുറഞ്ഞ ലെക്സിക്കല്\u200d മേ ഈ പ്രശ്നത്തെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d, ഞങ്ങള്\u200d സിനോനിമിന്റ് പകര്\u200dത്തുന്നതിന്റെ അടിസ്ഥാനത്തിലുള്ള ഒരു സി പ്രൊദ്ദേശിക്കപ്പെട്ട വിവരങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നത് സാധാരണമാണെന്ന് ഞങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു. 70ക്', 'mt': 'Il-mudelli tat-tweġiba għall-mistoqsijiet (QA) għall-komprensjoni tal-qari ntwerew li jisfruttaw preġudizzji mhux intenzjonati tas-sett tad-dejta bħal dubju bejn mistoqsijiet u kuntest lexiku. Dan ifixkel il-mudelli QA milli jiġġeneralizzaw għal kampjuni mhux rappreżentati biżżejjed bħal mistoqsijiet b’sovrappożizzjoni lexika baxxa. Il-ġenerazzjoni tal-mistoqsijiet (QG), metodu biex jiżdiedu settijiet ta’ dejta QA, tista’ tkun soluzzjoni għal tali degradazzjoni tal-prestazzjoni jekk QG tista’ tiddebija b’mod xieraq settijiet ta’ dejta QA. Madankollu, niskopru li mudelli reċenti ta’ QG newrali huma preġudizzjati lejn il-ġenerazzjoni ta’ mistoqsijiet b’sovrappożizzjoni lexikali għolja, li jistgħu jimplimentaw il-preġudizzju tas-sett tad-dejta. Barra minn hekk, l-analiżi tagħna turi li ż-żieda fid-dejta b’dawn il-mudelli QG ta’ spiss tfixkel il-prestazzjoni fuq kwistjonijiet b’sovrappożizzjoni lexikali baxxa, filwaqt li ttejjeb dik fuq kwistjonijiet b’sovrappożizzjoni lexikali għolja. Biex nindirizzaw din il-problem a, a ħna nużaw approċċ ibbażat fuq is-sostituzzjoni sinonimu biex iżidu l-mistoqsijiet b’sovrappożizzjoni lexikali baxxa. Aħna nuru li l-approċċ propost ta’ żieda fid-dejta huwa sempliċi iżda effettiv biex itaffi l-problema tad-degradazzjoni b’eżempji sintetiċi ta’ 70k biss.', 'pl': 'Wykazano, że modele odpowiedzi na pytania (QA) służące zrozumieniu czytania wykorzystują niezamierzone uprzedzenia zbiorów danych, takie jak nakładanie się leksykaliczne pytań-kontekstu. Utrudnia to uogólnianie modeli QA do niedostatecznie reprezentowanych próbek, takich jak pytania o niskim nakładaniu się leksykalicznym. Generowanie pytań (QG), metoda powiększania zbiorów danych QA, może być rozwiązaniem dla takiej degradacji wydajności, jeśli QG może prawidłowo odbić zbiory danych QA. Odkrywamy jednak, że najnowsze neuronowe modele QG są uprzedzone do generowania pytań o dużym nakładaniu się leksykalicznym, co może wzmocnić tendencję zbioru danych. Ponadto nasza analiza ujawnia, że powiększanie danych za pomocą tych modeli QG często ogranicza wydajność w pytaniach o niskim nakładaniu się leksykalicznym, jednocześnie poprawiając ją w pytaniach o dużym nakładaniu się leksykalicznym. Aby rozwiązać ten problem, stosujemy podejście oparte na synonimie zastępczym do rozszerzania pytań o niskie nakładanie się leksykaliczne. Wykazujemy, że proponowane podejście do powiększania danych jest proste, ale skuteczne, aby złagodzić problem degradacji tylko na przykładach syntetycznych 70k.', 'no': 'Spørsmønsterelement (QA) for lesing av forståelse er demonstrert for å ekspluatera utvilkårlege datasett- forståking som spørsmønsterelementekst- leksisk overlapp. Dette hindrar QA-modeller frå å generellisering til underrepresenterte prøver, slik som spørsmål med låg leksisk overlapping. Oppretting av spørsmål (QG), eit metode for å auka QA- datasett, kan vera eit løysing for slike funksjonsdegradasjon dersom QG kan rett debias QA- datasett. Men vi oppdager at nyleg neirale QG-modeller er forskyvne mot å laga spørsmål med høg leksisk overlapp, som kan forstørra datasettet. Denne analysen viser også at dataaugmentasjonen med disse QG-modelane ofte påvirkar utviklinga på spørsmålene med låg leksisk overlapp, mens det er forbetra på spørsmålene med høg leksisk overlapp. For å setja opp dette problemet, bruker vi ein synonym- basert tilnærming til å økja spørsmål med låg leksisk overlapp. Vi demonstrerer at den foreslåde data-augmentasjonen er enkelt men effektivt for å redusera degradasjonsproblemet med berre 70k syntetiske eksemplar.', 'mn': 'Унших ойлголтын асуулт хариулт (QA) загварууд нь асуулт-контекст лексикийн давхарлалтыг ашиглаж чадахгүй өгөгдлийн сангийн загваруудыг ашиглаж байна. Энэ нь QA загваруудыг ерөнхийлөгчийн төлөвлөгдсөн жишээ нь бага хэлбэртэй асуултууд юм. QA өгөгдлийн сануудыг нэмэгдүүлэх арга бол QG QA өгөгдлийн сануудыг зөв дэвшүүлж чадвал ийм үйл ажиллагааны бууруулах арга юм. Гэхдээ бид саяхан мэдрэлийн QG загваруудыг өндөр хэлбэртэй асуулт үүсгэхийн тулд, өгөгдлийн хэлбэрийг нэмэгдүүлж чадна гэдгийг олж мэдсэн. Мөн бидний шинжилгээнд энэ QG загваруудын өгөгдлийн нэмэгдүүлэлт нь хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэд хэдэн хэмжээсүүдийг бага хэмжээсүүдийг нөлөөлж Энэ асуудлыг олохын тулд бид хэлэлцээний бага хэмжээний асуултыг нэмэгдүүлэхэд синоним орлуулах арга зам ашигладаг. Бид санал өгөгдлийн нэмэлт арга зам нь 70k синтетик жишээнээс бууруулахын тулд энгийн ч үр дүнтэй гэдгийг харуулж байна.', 'ro': 'S-a demonstrat că modelele de răspuns la întrebări (QA) pentru înțelegerea citirii exploatează prejudecățile neintenționate ale seturilor de date, cum ar fi suprapunerea lexicală întrebări-context. Acest lucru împiedică modelele QA să generalizeze la eșantioane subreprezentate, cum ar fi întrebările cu suprapunere lexicală scăzută. Generarea de întrebări (QG), o metodă de mărire a seturilor de date QA, poate fi o soluție pentru o astfel de degradare a performanței dacă QG poate debia corespunzător seturile de date QA. Cu toate acestea, descoperim că modelele QG neurale recente sunt părtinitoare spre generarea de întrebări cu suprapunere lexicală ridicată, care pot amplifica părtinirea setului de date. Mai mult decât atât, analiza noastră arată că mărirea datelor cu aceste modele QG afectează frecvent performanța întrebărilor cu suprapunere lexicală scăzută, îmbunătățind în același timp performanța întrebărilor cu suprapunere lexicală ridicată. Pentru a rezolva această problemă, folosim o abordare bazată pe sinonime de înlocuire pentru a mări întrebările cu suprapunere lexicală scăzută. Demonstrăm că abordarea propusă de augmentare a datelor este simplă, dar eficientă pentru a atenua problema degradării cu doar 70k exemple sintetice.', 'sr': 'Pokazani su modeli odgovora na pitanja (QA) za čitanje razumijevanja kako bi iskoristili nepredvidne predrasude seta podataka poput pregleda leksičkog konteksta pitanja. To sprječava modele QA od generalizacije na pod predstavljenim uzorcima, kao što su pitanja sa niskim leksičkim preklapanjem. Generacija pitanja (QG), metoda za povećanje podataka QA, može biti rešenje za degradaciju takve funkcije ako QG može pravilno debijarati QA podatake. Međutim, otkrili smo da su nedavni neuronski QG modeli predrasudeni prema stvaranju pitanja sa visokim leksičkim preklapanjem, što može pojačati predrasude za set podataka. Nadalje, naša analiza pokazuje da povećanje podataka sa ovim modelima QG često utječe na učinkovitost na pitanja sa niskim leksičkim preklapanjem, dok to poboljšava na pitanja sa visokim leksičkim preklapanjem. Da bi se riješili ovaj problem, koristimo sinonim zamjenom bazirani pristup povećanju pitanja sa niskim leksičkim preklapanjem. Pokazujemo da je predloženi pristup povećanja podataka jednostavan, ali efikasan da se smanji problem sa degradacijom samo sa 70k sintetskim primjerima.', 'so': "Iska jawaabta su'aalka (QA) modellada akhriska waxaa lagu muujiyey in la isticmaalo baaritaanka macluumaadka la'aanta, tusaale ahaan saabsan-context overlap lexical. Tani waxay ka hor jeedisaa samooyinka QA in la soo saaro samooyin ka hooseeya tusaale ahaan su'aalo la xiriira dhaqaale leksikal. Muujinta su'aalaha (QG), qaabka ku kordhinta QA databaseyaasha, wuxuu noqon karaa xal u sameynta sameynta sameynta, haddii QG si rasmi ah u debias karo QA databases. Si kastaba ha ahaatee waxaynu ogaannay in tusaalayaasha QG ee ugu dambeeyey ay u khilaafsan yihiin in lagu sameeyo su'aalo la xiriira dhibaato dhaadheer, kaas oo ku kordhi kara tartanka macluumaadka. Fasirkayaga waxaa sidoo kale muuqata in la kordhiyo macluumaadkan QG sameynta ayaa inta badan saameyn ku yeelan kara su'aalaha la xiriira dhibaatada leksikalka yar, iyadoo horumarinta ku saabsan su'aalaha la xiriira leksikal sare. Si aan u qabsado dhibaatadan, waxaynu u isticmaalnaa qaab ka bedelashada sinoonimada si aan u dalbanno su'aalaha la kordhiyo dhibaatada la xiriira leksikalka yar. Waxaynu muujinnaa in qaababka laguu soo jeeday kordhinta macluumaadku waa fudud laakiin waa mid faa’iido leh in lagu qiyaaso dhibaatada hooseeya tusaalooyin isbitaalada oo kaliya 70k oo keliya.", 'sv': 'Frågeställningsmodeller (QA) för läsförståelse har visats utnyttja oavsiktliga datauppsättningar fördomar såsom frågekontext lexikal överlappning. Detta hindrar QA-modeller från att generalisera till underrepresenterade prover såsom frågor med låg lexikal överlappning. Frågagenerering (QG), en metod för att öka QA-datauppsättningar, kan vara en lösning för sådan prestandaförbättring om QG korrekt kan debias QA-datauppsättningar. Vi upptäcker dock att de senaste neurala QG-modellerna är partiska mot att generera frågor med hög lexikal överlappning, vilket kan förstärka datauppsättningens bias. Dessutom visar vår analys att dataökning med dessa QG-modeller ofta försämrar prestandan på frågor med låg lexikal överlappning, samtidigt som den förbättrar prestandan på frågor med hög lexikal överlappning. För att lösa detta problem använder vi ett synonymt ersättningsbaserat tillvägagångssätt för att utöka frågor med låg lexikal överlappning. Vi visar att den föreslagna dataförstärkningen är enkel men effektiv för att mildra nedbrytningsproblemet med endast 70k syntetiska exempel.', 'ta': 'கேள்வி பதில் (QA) மாதிரிகளை படிக்கும் தொகுதி Name கேள்வி உருவாக்கு (QG), QA தகவல் அமைப்புகளை அதிகரிக்க ஒரு முறை, QA தகவல் அமைப்புகளை சரியாக பிழைதிருத்த முடியும் என்றால் QA தரவுத்தளத்தை ப ஆனால், நாம் கண்டுபிடித்துக் கொண்டிருக்கிறோம் சமீபத்திய புதிய கியூஜி மாதிரிகள் உயர்ந்த லெக்சியல் மேலேற்பாட்டை உருவா மேலும், எங்கள் ஆராய்ச்சி தெரிவிக்கிறது இந்த QG மாதிரிகளுடன் தரவு அதிகப்படுத்தல் கேள்விகள் குறைந்த லெக்சியல் மேலேற்பாட்டில் செயல்பாட்டை  இந்த பிரச்சினையை நிர்வகிக்க, நாம் ஒரு ஒத்திசைவு மாற்றுதல் அடிப்படையான முறைமையை பயன்படுத்தி குறைந்த லெக் நாம் தெரிவிக்கிறோம் முன்நிர்ணயிக்கப்பட்ட தரவு கூட்டுதல் செயல்பாடு எளிதாகும் ஆனாலும் வெறுமையாக இருக்கும் என்பது', 'si': 'ප්\u200dරශ්න ප්\u200dරතිච්චාර (QA) මෝඩල් කියවන්න පුළුවන් විදිහට ප්\u200dරශ්නයක් තියෙන්නේ නැති දත්ත සැට ප්\u200dරශ්නයක් විදිහ මේක QA මොඩේල් එක සාමාන්\u200dය විදියට අඩු ප්\u200dරතිනිධානය කරන්න ප්\u200dරශ්නයක් වගේ ප්\u200dරශ්නයක් අඩු ලෙක්සිකාල් අඩ Name නමුත්, අපි හොයාගත්තා අලුත් න්\u200dයූරාල් QG මොඩේල්ස් එක ප්\u200dරශ්නයක් නිර්මාණය කරන්න ප්\u200dරශ්නයක් විශ්වාස කරනවා කියලා,  තවත්, අපේ විශ්ලේෂණය ප්\u200dරකාශ කරනවා මේ QG මොඩේල් එක්ක දත්ත විශාලනය ප්\u200dරශ්නයක් අඩු ලෙක්සිකල් ප්\u200dරශ්නයක් සමඟ ප්\u200dරශ්නයක් ව මේ ප්\u200dරශ්නයක් විස්තර කරන්න, අපි සමාන්\u200dය විස්තර කරන්න ප්\u200dරශ්නයක් පාවිච්චි කරනවා ප්\u200dරශ්නයක් අඩු ලෙක්සි අපි ප්\u200dරදර්ශනය කරනවා කියලා තියෙන්නේ තොරතුරු විශාල විශාල ප්\u200dරශ්නයක් සාමාන්\u200dයයි ඒත් ප්\u200dරශ්නයක් තියෙන්', 'ur': 'سؤال جواب دینے کے لئے (QA) موڈل کی سمجھ پڑھنے کے لئے دکھائی گئی ہے کہ غیر منتظر ڈاٹ سٹ کے بغیر منتظر بغیر منتظر ہیں جیسے سؤال-کنٹنس لکسیکل اورلاپ۔ یہ QA نمڈلوں کو عمومی نمڈلوں سے کم نمونڈلوں سے روکتا ہے جیسے کم لکسیکل اورلپ کے سوال ہیں۔ Name ہمیں معلوم ہوتا ہے کہ اچھی نئورل کیجی موڈل اچھی لکسیکل اورلاپ کے ساتھ سوال جوڑنے کے لئے منحصر ہو رہے ہیں، جو ڈاٹ سٹ منحصر کو بڑھا سکتا ہے۔ اور ہماری تحلیل ظاہر کرتی ہے کہ ان QG موڈلوں کے ساتھ ڈیٹا اضافہ کرنا بہت زیادہ اضافہ کرتا ہے کہ کم لکسیکل اورلاپ کے سوالوں پر اضافہ کرتا ہے، اور اس کے سوالوں پر اضافہ کرتا ہے جو بالکل لکسیکل اورلاپ کے ساتھ ہیں. اس مسئلہ کے بارے میں ہم ایک سینونیم بدل دینے کی بنیادی طریقہ استعمال کرتے ہیں کم لکسیکل اورلپ کے ساتھ سوال اضافہ کرنے کے لئے۔ ہم دکھاتے ہیں کہ مقرر کیا گیا ڈیٹا اضافہ کا طریقہ صرف 70 کیک سینٹیٹی مثال کے ذریعہ سزاوار ہے اور اس کے ذریعہ سزاوار ہے۔', 'uz': "Name Name Name Lektor, biz yaqinda yangi neyural QG modellari juda katta leksikal boshqaruv savollarini yaratishga qo'llanmagan, bu maʼlumot satrlarni ko'paytirish mumkin. Ko'rib, bizning analytikimiz shu QG modellari bilan maʼlumot yordamida ko'p ko'paytirish qo'llanmalarning natijasini ko'paytirish mumkin, va bu narsalarni yuqori leksikal qo'llash soʻllarini ko'paytirish mumkin. Bu muammolarni boshqarish uchun biz synonym almashtirish asosida soʻzni qo'shish savollarini qo'shish uchun ishlatimiz. Biz tasavvur qiladigan maʼlumotni oshirish usuli oddiy va faqat 70k syntetik misollarini kamaytirish uchun ishlatish muammolari.", 'vi': 'Các mô hình trả lời câu hỏi (kiểu QA) cho sự hiểu biết đọc được đã được chứng minh sử dụng khả năng sử dụng các giả lập không liên quan, như câu hỏi 8111;ngữ ngữ cảnh ngôn ngữ kép. Điều này ngăn cách mô hình QA khai rộng sang tả lại ví dụ như những câu hỏi có độ gấp bội chữ thấp. Thế hệ câu hỏi (QG), một phương pháp hỗ trợ dữ liệu QA, có thể là giải pháp cho sự thoái hóa chức năng đó nếu QG có thể thao túng hệ thống dữ liệu cá nhân thích đáng. Tuy nhiên, chúng tôi khám phá ra các mô hình thần kinh QG gần đây có khuynh hướng tạo ra các câu hỏi với độ gấp bội cao từ, mà có thể khuếch đại khuynh hướng của bộ dữ liệu. Hơn nữa, phân tích của chúng tôi cho thấy việc gia tăng dữ liệu với các mô hình QG thường làm ảnh hưởng của khả năng trong các câu hỏi có độ gấp bội từ thấp, trong khi tăng khả năng về các vấn đề có độ gấp bội cao từ. Để giải quyết vấn đề này, ta dùng phương pháp thay thế đồng nghĩa để tăng thêm các câu hỏi có độ gấp bội ngôn ngữ thấp. Chúng tôi cho thấy phương pháp gia tăng dữ liệu đề xuất là đơn giản nhưng hiệu quả để giảm thiểu vấn đề phân hủy chỉ bằng mẫu người máy 70k.', 'nl': 'Vragen beantwoorden (QA) modellen voor leesbegrip zijn aangetoond om onbedoelde dataset biases zoals vraag-context lexicale overlapping te benutten. Dit belemmert QA-modellen om te generaliseren naar ondervertegenwoordigde steekproeven, zoals vragen met een lage lexicale overlap. Question generation (QG), een methode voor het vergroten van QA datasets, kan een oplossing zijn voor dergelijke prestatieverslechtering als QG QA datasets correct kan debias. We ontdekken echter dat recente neurale QG modellen bevooroordeeld zijn om vragen te genereren met een hoge lexicale overlap, wat de dataset bias kan versterken. Bovendien blijkt uit onze analyse dat data augmentatie met deze QG-modellen vaak de prestaties van vragen met een lage lexicale overlap aantast, terwijl die verbetert bij vragen met een hoge lexicale overlap. Om dit probleem aan te pakken, gebruiken we een synoniem vervangende benadering om vragen met een lage lexicale overlap aan te vullen. We tonen aan dat de voorgestelde data augmentatie aanpak eenvoudig maar effectief is om het degradatieprobleem te beperken met slechts 70k synthetische voorbeelden.', 'bg': 'Доказано е, че моделите за отговор на въпроси за разбиране на четенето използват непредвидени отклонения в набора от данни, като например лексикално припокриване въпрос-контекст. Това пречи на моделите за оценка на качеството да се обобщават към недостатъчно представени образци, като например въпроси с ниско лексикално припокриване. Генерирането на въпроси (QG), метод за увеличаване на наборите от данни за оценка на качеството, може да бъде решение за такова влошаване на ефективността, ако QG може правилно да дебитира наборите от данни за оценка на качеството. Въпреки това, откриваме, че последните невронни модели са предубедени към генериране на въпроси с високо лексикално припокриване, което може да увеличи отклонението на набора от данни. Освен това нашият анализ разкрива, че увеличаването на данните с тези модели често нарушава ефективността при въпроси с ниско лексикално припокриване, като същевременно подобрява това при въпроси с високо лексикално припокриване. За да се справим с този проблем, използваме синоним заместващ подход към въпроси за увеличаване с ниско лексикално припокриване. Ние демонстрираме, че предложеният подход за увеличаване на данните е прост, но ефективен за смекчаване на проблема с разграждането само със 70 хиляди синтетични примери.', 'hr': 'Pokazani su modeli odgovora na pitanja (QA) za čitanje razumijevanja kako bi iskoristili nepredvidne predrasude seta podataka poput pregleda leksičkog konteksta pitanja. To sprječava modele QA-a od generalizacije na pod predstavljenim uzorcima poput pitanja s niskim leksičkim preklapanjem. Generacija pitanja (QG), metoda povećanja QA dataseta, može biti rješenje za degradaciju takve učinkovitosti ako QG može ispravno debijati QA datasete. Međutim, otkrili smo da su nedavni neuronski QG modeli predrasudeni prema stvaranju pitanja sa visokom leksičkom preklapanjem, što može pojačati predrasude podataka. Nadalje, naša analiza pokazuje da povećanje podataka s ovim modelima QG često utječe na učinkovitost na pitanja s niskim leksičkim preklapanjem, dok to poboljšava na pitanja s visokom leksičkom preklapanjem. Za rješavanje ovog problem a, koristimo sinonim zamjenom bazirani pristup povećanju pitanja s niskim leksičkim preklapanjem. Pokazujemo da je predloženi pristup povećanja podataka jednostavan, ali učinkovit za smanjenje problema s degradacijom samo 70k sintetičkih primjera.', 'de': 'Fragebeantwortungsmodelle (QA) für das Leseverständnis haben gezeigt, dass sie unbeabsichtigte Datensatzverzerrungen wie Fragenkontext-lexikalische Überlappung ausnutzen. Dies hindert QA-Modelle daran, zu unterrepräsentierten Stichproben zu verallgemeinern, wie Fragen mit geringer lexikalischer Überlappung. Fragegenerierung (QG), eine Methode zur Erweiterung von QA-Datensätzen, kann eine Lösung für solche Leistungseinbußen sein, wenn QG QA-Datensätze ordnungsgemäß debias kann. Wir entdecken jedoch, dass neuere neuronale QG-Modelle dazu neigen, Fragen mit hoher lexikalischer Überlappung zu generieren, was den Datensatzbias verstärken kann. Darüber hinaus zeigt unsere Analyse, dass die Datenaugmentation mit diesen QG-Modellen häufig die Leistung bei Fragen mit geringer lexikalischer Überlappung beeinträchtigt, während sie die Leistung bei Fragen mit hoher lexikalischer Überlappung verbessert. Um dieses Problem anzugehen, verwenden wir einen synonymersatzbasierten Ansatz, um Fragen mit geringer lexikalischer Überlappung zu erweitern. Wir zeigen, dass der vorgeschlagene Ansatz zur Datenauswertung einfach und effektiv ist, um das Degradationsproblem mit nur 70k synthetischen Beispielen zu mindern.', 'fa': 'مدلهای پاسخ سوال (QA) برای خواندن درک برای استفاده از تعدادهای مجموعه داده\u200cهای ناخواسته\u200cای مثل تغییره\u200cهای زبان\u200cشناسی سوال نشان داده شده\u200cاند. این مدلهای QA را مانع می\u200cکند که عمومی به نمونه\u200cهای کمتر نمایش داده شود، مانند سوالات با پایین تغییرات زبانی. نسل سوال (QG) یک روش برای افزایش مجموعه داده\u200cهای QA می\u200cتواند راه حل برای افزایش چنین فعالیت باشد اگر QG می\u200cتواند مجموعه\u200cهای داده\u200cهای QA را به درستی debias کند. با این حال، ما کشف می\u200cکنیم که مدلهای عصبی QG اخیرا به سوی تولید سوال\u200cهای بالا با تغییرات زبان\u200cشناسی است که می\u200cتواند تغییرات مجموعه\u200cهای داده\u200cها را افزایش دهد. علاوه بر این، تحلیل ما نشان می دهد که افزایش داده\u200cها با این مدل\u200cهای QG اغلب اجرای سوالات را با افزایش زبانی کم تأثیر می\u200cدهد، در حالی که این را در سوالات با افزایش زبانی بالا تأثیر می\u200cدهد. برای حل این مشکل، ما از طریق جایگزینی که بر اساس تغییر سنونیم برای افزایش سوالات با افزایش تغییر دهنده\u200cی کم استفاده می\u200cکنیم. ما نشان می دهیم که روش افزایش داده های پیشنهاد ساده و تاثیر است تا مشکل افزایش را با مثالهای سنتتی ۷۰ کیلومتر کاهش دهیم.', 'ko': '읽기와 이해의 문답(QA) 모델은 문제의 상하문 어휘가 겹치는 등 예상치 못한 데이터 집합의 편차를 이용할 수 있다는 것이 증명되었다.이것은 QA모델이 대표적으로 부족한 견본, 예를 들어 어휘의 중첩도가 비교적 낮은 문제로 확대되는 것을 방해한다.문제생성(QG)은 QA 데이터 집합을 강화하는 방법으로 QG가 이를 QA 데이터 집합으로 정확하게 정의할 수 있다면 성능 저하 문제를 해결할 수 있다.그러나 최근의 신경 QG 모델은 높은 어휘가 중첩된 문제를 생성하는 경향이 있어 데이터 집합의 편견을 확대하는 것으로 나타났다.그 밖에 이러한 QG모델을 사용하여 데이터를 늘리면 어휘의 중첩도가 낮은 문제의 표현을 손상시키고 어휘의 중첩도가 높은 문제의 표현을 높일 수 있다는 분석이 나왔다.이 문제를 해결하기 위해서, 우리는 동의어를 바탕으로 교체하는 방법을 사용하여 어휘의 중첩이 비교적 적은 문제를 증가시킨다.우리는 제시된 데이터 강화 방법이 간단하고 효과적이며 70k의 합성 실례만으로도 퇴화 문제를 완화시킬 수 있다는 것을 증명했다.', 'sw': 'Maswali ya majibu (QA) mifano ya kusoma yenye ufafanuzi umeonyesha kutumia upendeleo wa taarifa zisizo na ushirikiano kama vile upepo wa maswali-mazingira ya kisaikolojia. Hii inazuia mifano ya QA kutokana na kutengeneza hadi sampuli zilizowakilishwa chini kama vile maswali yenye uzito wa lexico. Kizazi cha swali (QG), njia ya kuongeza seti za data za QA, inaweza kuwa suluhisho la kuharibiwa kwa ufanisi wa namna hiyo kama QG inaweza kuharibu seti za data za QA. However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias.  Zaidi ya hayo, uchambuzi wetu unaonyesha kuwa kuongezeka kwa takwimu hizi za QG mara nyingi huathiri utendaji wa maswali yenye upana wa lexico kidogo, wakati huo huo utaboresha maswali yanayohusu upana wa vifaa vya lexico. Ili kukabiliana na tatizo hili, tunatumia mbinu za kubadilishana kwa ushirikiano wa simu ili kuongeza maswali yenye upana wa lexico kidogo. We demonstrate that the proposed data augmentation approach is simple yet effective to mitigate the degradation problem with only 70k synthetic examples.', 'da': 'Spørgsmålsbesvarelsesmodeller (QA) til læseforståelse har vist sig at udnytte utilsigtede datasæt fordele såsom spørgsmål-kontekst leksikal overlapning. Dette forhindrer QA-modeller i at generalisere til underrepræsenterede prøver såsom spørgsmål med lavt leksikalsk overlapning. Spørgsmålstegnelse (QG), en metode til at forøge QA datasæt, kan være en løsning på en sådan ydeevne nedbrydning, hvis QG korrekt kan debias QA datasæt. Vi opdager imidlertid, at nylige neurale QG modeller er forudindtaget i retning af at generere spørgsmål med høj leksikalsk overlapning, hvilket kan forstærke datasættets bias. Desuden afslører vores analyse, at dataforøgelse med disse QG-modeller ofte forringer ydeevnen på spørgsmål med lav leksikalsk overlapning, samtidig med at den forbedres på spørgsmål med høj leksikalsk overlapning. For at løse dette problem bruger vi en synonym erstatningsbaseret tilgang til at forøge spørgsmål med lavt leksikalsk overlapning. Vi demonstrerer, at den foreslåede dataaugmentation tilgang er enkel, men effektiv til at afbøde nedbrydningsproblemet med kun 70k syntetiske eksempler.', 'az': 'QA məlumatları oxumaq üçün sual cavab vermək modelləri sual-kontekst leksik çoxluğu kimi istəməmiş veri qurğularını istifadə etmək üçün göstərildi. Bu QA modellərini düşük leksik üstünlüyü ilə suallar kimi nümunələrə generalizməyə mane edir. QA veri qurğularını artırmaq üçün sual nəzəriyyəti (QG), QG QA veri qurğuları düzgün debias edə bilərsə, böyük performans degradasyonun çözümü olar. Ancaq biz yeni nöral QG modellərinin yüksək leksik çoxluğu ilə suallar yaratmaq üçün tədbir edildiyini öyrənirik ki, veri qutusu tədbirlərini genişləşdirə bilər. Daha sonra, analizimiz belə göstərir ki, bu QG modelləri ilə verilən məlumatlar artırması çox sık-sık leksik üstünlüyü ilə sualların üstünlüyünü təşkil edir, bu sualları yüksək leksik üstünlüyü ilə yaxşılaşdırır. Bu problemi çəkmək üçün, biz sinonim yerinə qoyub düşük leksik çoxluğu ilə suallarını artırmaq üçün istifadə edirik. Biz göstəririk ki, təklif edilmiş məlumatları artırmaq tərzində sadəcə olaraq, sadəcə 70k sintetik məsəllərlə degradasyon problemini azaltmaq üçün etkilidir.', 'id': 'Model menjawab pertanyaan (QA) untuk pemahaman pembacaan telah diungkapkan untuk mengeksploitasi biases dataset tidak disengaja seperti overlap lexik pertanyaan-konteks. This hinders QA models from generalizing to under-represented samples such as questions with low lexical overlap.  Generasi pertanyaan (QG), metode untuk meningkatkan set data QA, dapat menjadi solusi untuk degradasi prestasi seperti itu jika QG dapat debias dataset QA dengan benar. Namun, kami menemukan bahwa model QG saraf baru-baru ini bias untuk menghasilkan pertanyaan dengan overlap lexik tinggi, yang dapat memperbesar bias dataset. Moreover, our analysis reveals that data augmentation with these QG models frequently impairs the performance on questions with low lexical overlap, while improving that on questions with high lexical overlap.  Untuk mengatasi masalah ini, kita menggunakan pendekatan berbasis penggantian sinonim untuk menambah pertanyaan dengan overlap lexik rendah. Kami menunjukkan bahwa pendekatan peningkatan data yang diusulkan sederhana namun efektif untuk mengurangi masalah degradasi hanya dengan contoh sintetis 70k.', 'bn': 'প্রশ্নের উত্তর (কিউ এ) মডেল পাঠানোর জন্য প্রকাশিত হয়েছে যেমন প্রশ্ন-context লেক্সিক্সিক্যাল আপলেপ। এটি কিউএ মডেল নিচের প্রতিনিধিত্বিত নমুনাগুলোতে প্রতিনিধিত্ব করা থেকে বাধা দেয়, যেমন কম লেক্সিক্সিক্যাল প্রশ্নের প্রজন্ম (QG), QA ডাটাসেট বাড়িয়ে দেওয়ার একটি পদ্ধতি, কিউ- এ ডেটাসেটকে সঠিকভাবে ডিবিয়াস করতে পারে কিউ- এ ডেটাসেটের সমাধান হল তবে আমরা আবিষ্কার করি যে সাম্প্রতিক কিউজি মডেল উচ্চ লেক্সিক্সিক্যাল প্রাপ্ত প্রশ্ন তৈরি করার বিরুদ্ধে বিদ্রোহী হয়েছে, যা ডা এছাড়াও, আমাদের বিশ্লেষণ প্রকাশ করেছে যে এই কিউজি মডেলের সাথে ডাটা যোগাযোগের সাথে প্রায়শই কম লেক্সিক্যাল আপেপের প্রশ্নের প্রতি প্রভাব ফ এই সমস্যাটিকে ঠিক করার জন্য আমরা সিনোনিম প্রতিস্থাপনের একটি উপায় ব্যবহার করি লেক্সিক্যাল আপেপের সাথে যুক্ত করার প্রশ্ আমরা দেখাচ্ছি যে প্রস্তাবিত তথ্য যোগাযোগের উপায় সাধারণ এবং এখনো কার্যকর যে সমস্যাটি মাত্র ৭০ কিছু সিন্টেটিক উদাহরণের মাধ্যম', 'am': 'ጥያቄ መልስ ይህ የQA ሞዴላዎችን ማቀናቀል ከሌክሲካል ጉዳይ ጋር እንደሚያነሳው ምሳሌዎች ከታች እንዲገልጽ የሚከለክል ነው፡፡ የጥያቄ ትውልድ However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias.  በተጨማሪም፣ አካላቢያችን እንደዚህ የQG ዓይነቶች መጨመር በጥያቄ ጥያቄ ላይ በጥያቄ ላይ በጥያቄ ይጨምርበታል፡፡ ይህንን ጉዳይ ለመቀበል፣ የሲንዮኒም መተላለፊያ ለመጨመር የሌክሲካዊ ጥያቄዎችን ለመጨመር እንጠይቃለን፡፡ የአደጋገመው የዳታ አካባቢ መግለጫ ቀላል ነገር ግን ከ70 ሺሕ ምሳሌዎች ጋር የሚያንቀላቅል ጥቅም ነው ብለን እናሳያቸዋለን፡፡', 'sq': 'Question answering (QA) models for reading comprehension have been demonstrated to exploit unintended dataset biases such as question-context lexical overlap.  Kjo pengon modelet QA nga gjeneralizimi në mosha të nënpërfaqësuara të tilla si pyetjet me mbishtypje të ulët lexike. Question generation (QG), a method for augmenting QA datasets, can be a solution for such performance degradation if QG can properly debias QA datasets.  However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias.  Moreover, our analysis reveals that data augmentation with these QG models frequently impairs the performance on questions with low lexical overlap, while improving that on questions with high lexical overlap.  To address this problem, we use a synonym replacement-based approach to augment questions with low lexical overlap.  We demonstrate that the proposed data augmentation approach is simple yet effective to mitigate the degradation problem with only 70k synthetic examples.', 'tr': 'Sorag jogap (QA) nusgalary okamak üçin sistemasy çykyş edildi. Sorag-kontekst leksiýaly geçişinden üýtgetmek üçin döwüredildi. Bu QA modelleri düşük leksik üstünde soraglar ýaly örneklere döredilmekden çykarýar. Sorag jenaýaty (QG), QA veri düzümlerini ýeterlemek üçin bir yöntem, eger QG bu şekilde QA veri düzümlerini ýeterlemek üçin bir çözüm olar. Ýagna görä biz öňki näural QG nusgalarynyň ýokary leksiýa üstünde soraglary döretmek üçin üýtgedigini görerdik. Bu nusgalary tertiblemek üçin üýtgedip biler. Munuň üçin biziň analýusymyz bu QG modelleri bilen maglumatlary ýetişdirilýän ýagdaýynyň düşük leksiýaly üstünlik bilen soraglaryň üstine täsirleýär. Bu meseleyi çözmek üçin sinonim öňünden düşük leksiýal üstünde soraglary ýeterleştirmek üçin bir ýalaýyşy ulanýarys. Biz munuň teklip eden maglumatyň ýetişdirmegi ýagdaýynyň diňe 70k syntetik mysal bilen azaltmak üçin basit we ýeňil däldigini görkeýäris.', 'bs': 'Pokazani su modeli odgovora na pitanja (QA) za čitanje razumijevanja kako bi iskoristili nepredvidne predrasude set podataka poput pregleda leksičkog konteksta pitanja. To sprječava modele QA-a od generalizacije na pod predstavljenim uzorcima kao što su pitanja s niskim leksičkim preklapanjem. Generacija pitanja (QG), metoda za povećanje QA dataseta, može biti rješenje za degradaciju takve funkcije ako QG može ispravno debijati QA datasete. Međutim, otkrivamo da su nedavni neuronski QG modeli predrasudeni prema stvaranju pitanja sa visokom leksičkom preoklapanjem, što može pojačati predrasude za set podataka. Nadalje, naša analiza pokazuje da povećanje podataka sa ovim QG modelima često utječe na učinkovitost na pitanja s niskim leksičkim preprekom, dok to poboljšava na pitanja sa visokom leksičkom preprekom. Da bi se riješili ovaj problem, koristimo sinonim zamjenski pristup povećanju pitanja sa niskim leksičkim preklapanjem. Pokazujemo da je predloženi pristup povećanja podataka jednostavan, ali efikasan da se smanji problem degradacije sa samo 70k sintetičkih primjera.', 'af': "Vraog antwoord (QA) modele vir lees verstandigheid is gedemonstreer om onbekende datastel voorskrifte soos vraag- konteks leksies oorvloediging te gebruik. Hierdie hinder QA modelles van generellisering na onder- verteenwoordige voorbeelde soos vrae met lae leksiese oorvloei. Vraog generasie (QG),  'n metode vir QA datastelle opgroei, kan 'n oplossing wees vir sodanige prestasie degradasie as QG korrek QA datastelle kan debias. Maar ons ontdek dat onlangse neurale QG-modelles voorspoedig word teenoor die genereer van vraagte met hoë leksiese oorvloediging, wat die datastel voorspoediging kan ampliëer. Ook, ons analisie vertel dat data augmentasie met hierdie QG-modele dikwels die prestasie op vrae met lae leksiese oorvloei, terwyl dit op vrae met hoë leksiese oorvloei verbeter word. Om hierdie probleem te adres, gebruik ons 'n sinonime vervang-gebaseerde toegang na vergroot vrae met lae leksiese oorvloei. Ons wys dat die voorgestelde data-augmentasie toegang eenvoudig is nog effektief om die degradasie-probleem te verminder met slegs 70k sintetiese voorbeelde.", 'cs': 'Bylo prokázáno, že modely odpovědí na otázky (QA) pro porozumění čtení využívají nezamýšlených předsudků datových sad, jako je lexikální překrývání otázek a kontextu. To brání modelům QA zobecnění na nedostatečně zastoupené vzorky, jako jsou otázky s nízkým lexikálním překrytím. Generování otázek (QG), metoda pro rozšíření QA datových sad, může být řešením pro takové zhoršení výkonu, pokud QG může správně debias QA datové sady. Nicméně zjišťujeme, že nedávné neuronové QG modely jsou zaujaté k generování otázek s vysokým lexikálním překrýváním, což může zesílit bias datové sady. Naše analýza navíc ukazuje, že rozšíření dat těmito QG modely často zhoršuje výkon u otázek s nízkým lexikálním překrytím a zároveň zlepšuje výkon u otázek s vysokým lexikálním překrytím. K řešení tohoto problému používáme přístup založený na synonymu nahrazení otázek s nízkým lexikálním překrytím. Dokazujeme, že navržený přístup rozšíření dat je jednoduchý, ale efektivní pro zmírnění problému degradace pouze na 70k syntetických příkladech.', 'et': 'Küsimustele vastamise mudelid lugemise mõistmiseks on näidatud, et nad kasutavad ära tahtmatuid andmekogumi kallakuid, näiteks küsimuse ja konteksti leksikaalset kattumist. See takistab kvaliteedi tagamise mudelite üldistamist alaesindatud proovidele, näiteks madala leksikaalse kattumisega küsimustele. Küsimuste genereerimine (QG), mis on meetod kvaliteedi tagamise andmekogumite täiendamiseks, võib olla lahendus sellisele jõudluse halvenemisele, kui QG suudab kvaliteedi tagamise andmekogumite nõuetekohaselt debiteerida. Siiski avastame, et hiljutised neuraalsed QG mudelid on suunatud kõrge leksikaalse kattumisega küsimuste tekitamisele, mis võib võimendada andmekogumi erapooletust. Lisaks näitab meie analüüs, et andmete suurendamine nende QG mudelitega sageli halvendab tulemuslikkust madala leksikaalse kattumisega küsimustel, parandades samas seda kõrge leksikaalse kattumisega küsimustel. Selle probleemi lahendamiseks kasutame sünonüümi asendamisel põhinevat lähenemisviisi madala leksikaalse kattumisega küsimuste täiendamiseks. Näitame, et kavandatud andmete suurendamise lähenemisviis on lihtne, kuid tõhus lagunemisprobleemi leevendamiseks vaid 70k sünteetiliste näidetega.', 'hy': 'Հարցերին պատասխանելու (QA) մոդելները կարդալու ընկալումների համար ապացուցել են, որ օգտագործում են անկանխատեսված տվյալների համակարգի կողմնականություններ, ինչպիսիք են հարցերի-կոնտեքստի լեքսիկական կապը: Սա խոչընդոտում է QA մոդելներին ընդհանրացնել դեպի թերներկայացված նմուշներ, ինչպիսիք են ցածր լեքսիկական կապվածություն ունեցող հարցերը: Հարցերի ստեղծումը (QG), QA տվյալների համակարգերի աճի մեթոդը, կարող է լուծում լինել նման արդյունավետության դեգրադացիայի համար, եթե QG-ը կարողանա ճիշտ դիբեյել QA տվյալների համակարգերը: Այնուամենայնիվ, մենք բացահայտում ենք, որ վերջին նյարդային QG մոդելները կողմնականում են հարցեր ստեղծելու համար, որոնք բարձր լեքսիկական կապված են, ինչը կարող է աճեցնել տվյալների համակարգի կողմնականությունը: Moreover, our analysis reveals that data augmentation with these QG models frequently impairs the performance on questions with low lexical overlap, while improving that on questions with high lexical overlap.  To address this problem, we use a synonym replacement-based approach to augment questions with low lexical overlap.  Մենք ցույց ենք տալիս, որ առաջարկված տվյալների աճի մոտեցումը պարզ է, բայց արդյունավետ է դեգրադացիայի խնդիրը նվազեցնելու համար միայն 70k սինթետիկ օրինակներով:', 'fi': 'Kysymysten vastausmallien (QA) on osoitettu hyödyntävän tahattomia datajoukon vääristymiä, kuten kysymyksen ja kontekstin leksikaalista päällekkäisyyttä. Tämä estää laadunvarmistusmalleja yleistymästä aliedustettuihin näytteisiin, kuten kysymyksiin, joilla on pieni sanastollinen päällekkäisyys. Kysymysten generointi (QG), menetelmä laadunvarmistustietojen lisäämiseksi, voi olla ratkaisu tällaiseen suorituskyvyn heikkenemiseen, jos QG voi asianmukaisesti debitoida laadunvarmistustietoja. Havaitsemme kuitenkin, että viimeaikaiset neuraaliset QG-mallit ovat taipuvaisia luomaan kysymyksiä, joilla on suuri lexikaalinen päällekkäisyys, mikä voi vahvistaa aineiston vääristymistä. Lisäksi analyysimme osoittaa, että tietojen lisääminen näillä QG-malleilla heikentää usein suorituskykyä kysymyksissä, joilla on alhainen leksikaalinen päällekkäisyys, ja parantaa sitä kysymyksissä, joilla on korkea leksikaalinen päällekkäisyys. Tämän ongelman ratkaisemiseksi käytämme synonyymien korvaamiseen perustuvaa lähestymistapaa lisäkysymyksiin, joilla on alhainen sanastollinen päällekkäisyys. Osoitamme, että ehdotettu datan lisäämistä koskeva lähestymistapa on yksinkertainen, mutta tehokas hajoamisongelman lieventämiseksi vain 70 000 synteettisellä esimerkillä.', 'ca': "Question answering (QA) models for reading comprehension have been demonstrated to exploit unintended dataset biases such as question-context lexical overlap.  Això dificulta que els models QA s'generalitzen a mostres poc representades, com les preguntes amb baixa sobreposició lèxica. Question generation (QG), a method for augmenting QA datasets, can be a solution for such performance degradation if QG can properly debias QA datasets.  However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias.  A més, la nostra anàlisi revela que el augment de les dades amb aquests models QG freqüentement afecta el rendiment en preguntes amb baixa sobreposició lexical, mentre millora això en preguntes amb gran sobreposició lexical. Per abordar aquest problem a, utilitzem un enfocament basat en la substitució de sinònims per augmentar preguntes amb baixa sobreposió lèxica. Demostram que l'enfocament proposat d'augment de dades és simple però efectiu per mitigar el problema de degradació amb només 70k exemples sintètics.", 'jv': 'color-profile-policy Ndoleh iso nggawe model KA kang jeral-jeral sapar model sing ditambah-nyelehake lagi model sing nyimpen karo perusahaan lagi leksikalan. section politenessoffpolite"), and when there is a change ("assertivepoliteness Nambah, akeh pansinipun nambah ngomong nik akeh perusahaan dadi ampungan karo model iki, KSG kuwi biasane sak jane mebalé gak perusahaan langkung arah sing katya luwih apik, lan akeh nambah dhéwé kuwi mau. Nyong ngomong kelas boten iki, kita ngubah ndelok sane supra-seneng pisan kang angkang karo akeh langgambar. Awak dhéwé éntuk mungkin ngono hal-hal akeh gunakake data ampuhsi luwih apik dadi sing apik dadi nggawe gerakan kelas perbudhakan kanggo mbelak akses ditulak sing pasar tentang punika (sing paling-teka) sedhaya.', 'sk': 'Dokazano je, da modeli odgovarjanja na vprašanja za branje izkoriščajo nenamerne pristranskosti nabora podatkov, kot je leksikalno prekrivanje vprašanj-konteksta. To preprečuje posploševanje modelov kakovosti na premalo zastopane vzorce, kot so vprašanja z nizkim leksikalnim prekrivanjem. Generacija vprašanj (QG), metoda za povečanje naborov podatkov o kakovosti, je lahko rešitev za takšno zmanjšanje učinkovitosti, če lahko QG pravilno obremeni nabore podatkov o kakovosti. Vendar pa smo ugotovili, da so nedavni nevronski QG modeli pristranski k ustvarjanju vprašanj z visokim leksikalnim prekrivanjem, kar lahko poveča pristranskost nabora podatkov. Poleg tega naša analiza pokaže, da povečanje podatkov s temi modeli QG pogosto zmanjšuje učinkovitost pri vprašanjih z nizkim leksikalnim prekrivanjem, hkrati pa izboljšuje učinkovitost pri vprašanjih z visoko leksikalnim prekrivanjem. Za reševanje tega problema uporabljamo pristop, ki temelji na nadomestitvi sinonimov, za povečanje vprašanj z nizkim leksikalnim prekrivanjem. Dokazujemo, da je predlagani pristop povečanja podatkov preprost, vendar učinkovit za ublažitev problema degradacije s samo 70.000 sintetičnimi primeri.', 'ha': "An nuna motsi na tambayi (QA) wa matsalon karatun ɗin karanta don a yi amfani da sunayen da ba'a yi lokaci ba, kamar nau'in-context-lex. Wannan yana hana misãlai QA daga ƙiƙiro zuwa misãlai masu da ke ƙaranci kamar masu tambayar da za'a yi nau'in leksi. QG, wata hanya na ƙarfafa da tsarin QA, za'a iya zama masu buƙata wa dizagon aiki kamar wannan idan QG na iya iya buƙata tsarin QA masu daidaita. Hata haka, munã gane cewa misãlai na QG na ƙara yanzu za'a sami masu tambayar da za'a sami nau'i mai girma, da za'a ƙara bayani na danganta. Furan, Analyyinmu ya bayyana cewa, ƙarancin data da waɗannan QG misãlai ko da yawa, yana shagala aikin su a kan masu tambayar da za'a yi nau'in leksisi masu rauni, alhãli kuwa yana ƙaranci wannan a kan tambayar masu da za'a yi nau'in leksisi. Yana amfani da wata matsayi mai saɓa da synonim zuwa matsayin auguwar maswali da nau'i mai sauƙin leksisi. Tuna nũna cewa zagon augutarwa da aka buƙata zadata yana mai sauƙi kuma amma yana da amfani dõmin ya cire matabbatar taƙaitacce da misãlai 70 koki kawai.", 'bo': 'འདྲི་ཞིབ་ལན་གསལ་མོས་པ(QA)རྣམ་གྲངས་ཀྱི་ཀློག་འཇུག་གི་མིག་དཔེ་གཞི་སྒྲིག་འགོད་ཀྱི་གནད་སྡུད་མེད་སྤྱོད་མི་འདུག འདིས་ཕལ་ཆེན་རྣམ་པ་ལྟར་བཀག་མིན་པའི་དཔེ་བརྗོད་རིགས་ཀྱི་རྣམ་པ་ཇུས་ཡོད་མེད་པའི་མིང་དཔེ་བརྗོད་ནི། QA གནས་སྟངས་ཕྱོགས་སྒྲིག་ཚེ་ཆེ་རུ་གཏོང་བའི་ཐབས་ལམ་ཞིག་ཡིན་པས་QG འདིས་བདེ་འཇགས་རིམ་སྒྲིག་འཛུགས་ཀྱི་ཐབས་ལམ་ཞིག་ཡིན་ཚེ། འོན་ཀྱང་། ང་ཚོར་མཐོང་ནི་ཉེ་ཆར་ཡིན་པའི་ནུས་ཡུལ་གྱི་ཐབས་ལམ་ལུགས་དེ་གནད་དོན་རིམ་སྒྲིག་གནས་ཚུལ་གཞི་སྒྲིག འོན་ཀྱང་། ང་ཚོའི་དབྱེ་ཞིབ་ཀྱིས་QG རྣམ་པ་འདི་དག་གི་གནས་ཚུལ་ཆེ་མཐོང་ན་རྒྱུན་ལྡན་མིན་པའི་དོན་ལྟར་སྐྱེན་ཚུལ་ཉུང་བའི་བསྐྱེད་ཚད་ལྟ དཀའ་ངལ་འདི་ལ་བཤད་ན། ང་ཚོས་མཚོན་རྟགས་ཀྱི་ཚབ་བཅུག ང་ཚོས་བྱ་ཚིག་གི་སྔོན་འཛུགས་པའི་ཆ་འཕྲིན་ཡིག་ཆ་བསྐྱེད་ཐབས་ལམ་དེ་སྟབས་བདེ་བ་ཡིན་ནའང་། དེ་ལས་ཀྱང་ཉེན་བརྗོད་བ', 'he': 'Question answering (QA) models for reading comprehension have been demonstrated to exploit unintended dataset biases such as question-context lexical overlap.  This hinders QA models from generalizing to under-represented samples such as questions with low lexical overlap.  דור שאלות (QG), שיטה להגדיל קומות מידע QA, יכולה להיות פתרון לפיתוח ביצועים כאלה אם QG יכול לדבות קומות מידע QA כראוי. However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias.  Moreover, our analysis reveals that data augmentation with these QG models frequently impairs the performance on questions with low lexical overlap, while improving that on questions with high lexical overlap.  To address this problem, we use a synonym replacement-based approach to augment questions with low lexical overlap.  We demonstrate that the proposed data augmentation approach is simple yet effective to mitigate the degradation problem with only 70k synthetic examples.'}
{'en': 'Eliciting Bias in Question Answering Models through Ambiguity', 'ar': 'استخلاص التحيز في الإجابة على الأسئلة من خلال الغموض', 'pt': 'Elicitando o viés em modelos de resposta a perguntas por meio da ambiguidade', 'es': 'Provocar sesgos en los modelos de respuesta a preguntas mediante la ambigüedad', 'fr': 'Incitation de biais dans les modèles de réponse aux questions par ambiguïté', 'ja': 'あいまいさを通じて質問回答モデルに偏見を引き起こす', 'zh': '因模糊性于问答模引偏差', 'ru': 'Выявление предвзятости в ответах на вопросы в моделях через двусмысленность', 'hi': 'अस्पष्टता के माध्यम से प्रश्न का उत्तर देने वाले मॉडल में पूर्वाग्रह को प्राप्त करना', 'ga': 'Laofacht á lorg i Múnlaí Freagartha Ceisteanna trí Athbhrí', 'ka': 'კითხვის გასაგების მოდელების გამოყენება', 'hu': 'A kérdésekre vonatkozó modellek kétségtelen megválaszolása', 'el': 'Εξάλειψη προκαταλήψεων στα μοντέλα απάντησης ερωτήσεων μέσω αμφιβολίας', 'kk': 'Сұрақ жауап беру үлгілерінде шектеу', 'it': "Eliminare Bias nei modelli di risposta alle domande attraverso l'ambiguità", 'ml': 'ചോദ്യത്തിന്റെ ഉത്തരം മോഡലുകളില്\u200d ബിയാസുകള്\u200d എലിയാസ് ചെയ്യുന്നു', 'lt': 'Eliciting Bias in Question Answering Models through Ambiguity', 'ms': 'Memilih Bias dalam Model Jawab soalan melalui Ambiguity', 'mn': 'Биас асуулт хариултын загваруудыг хадгалах', 'no': 'Gjennomsiktige oppgåver i spørsmålmodular', 'mt': 'L-eliġibbiltà tal-ħsara fil-mudelli tat-tweġiba għall-mistoqsijiet permezz tal-Ambigurtà', 'ro': 'Eliberarea Bias în modelele de răspuns la întrebări prin ambiguitate', 'sr': 'Eliminiranje Bija u modelima odgovora na pitanje kroz ambicioznost', 'pl': 'Wyeliminowanie uprzedzeń w modelach odpowiadania na pytania poprzez niejasność', 'si': 'ප්\u200dරශ්න ප්\u200dරතික්\u200dරියාවට ප්\u200dරතික්\u200dරියාවට ප්\u200dරතික්\u200dරියාවට ප්\u200dරතික්\u200dරියාවක් නිර්මාණය', 'so': 'Eliciting Bias in Question answering Models through Ambiguity', 'sv': 'Eliminera missförhållanden i fråga Svarsmodeller genom Ambiguity', 'ta': 'கேள்வி பதில் மாதிரிகளில் பியாஸ்களை நீக்குகிறது அமைப்பு வழியாக', 'ur': 'سوال کے جواب دینے کے موڈل کے ذریعہ دوسری باتوں کو ٹال دیا جاتا ہے', 'mk': 'Одбивање на непријатности во моделите за одговори на прашања преку амбигија', 'vi': 'KCharselect unicode block name', 'uz': 'Name', 'bg': 'Елиминиране на предразсъдъци в моделите за отговор на въпроси чрез амбициозност', 'da': 'Eliminering af bias i spørgsmål besvarelse modeller gennem Ambiguity', 'hr': 'Eliminiranje Bia u modelima odgovora na pitanje kroz obilaznost', 'nl': 'Het elimineren van vooroordelen in vragenbeantwoordingsmodellen door dubbelzinnigheid', 'id': 'Memiliki gangguan dalam Model Jawab Pertanyaan melalui Ambiguity', 'de': 'Beseitigung von Vorurteilen bei Fragebeantworter Modelle durch Ambiguität', 'ko': '잘못된 뜻을 통해 문답 모델 중의 편견을 끌어내다', 'fa': 'پاک کردن بیها در مدل جواب سوال از طریق آزمایش', 'sw': 'Akiondoa Bias katika maswali ya maswali kupitia Ubalozi', 'tr': 'Sorag jogabaty nusgala hillerden çykar', 'sq': 'Duke hequr dëmet në modelet e përgjigjes për pyetje nëpërmjet ambigjitetit', 'af': 'Verwyder Bias in Vrag Antwoord Modelle deur Ambiguity', 'hy': 'Eliciting Bias in Question Answering Models through Ambiguity', 'am': 'Bias in Question Answering Models through Ambiguity', 'az': 'Söylə cavab vermək modelləri məhşərə olaraq', 'bn': 'প্রশ্নের উত্তর প্রশ্ন মোডেলে বিয়াস তুলে ধরা হচ্ছে', 'bs': 'Eliminiranje Bija u modelima odgovora na pitanje kroz ambicioznost', 'ca': "Eliminar els biais en els models de resposta a preguntes a través de l'ambigüitat", 'cs': 'Odstraňování předsudků v modelech zodpovědí na otázky prostřednictvím nejasnosti', 'et': 'Küsimustele vastamise mudelite eelarvamuste kõrvaldamine ambiguity kaudu', 'fi': 'Kyselymallien ennakkoluulojen poistaminen epäselvyyden avulla', 'jv': 'echoH e l l o space w o r l d periodHelloworldHello world', 'sk': 'Odpravljanje pristranskosti pri modelih odgovarjanja na vprašanja prek ambiguitete', 'ha': 'KCharselect unicode block name', 'he': 'ניתן להוציא סבלנות במודלים לענות על שאלות באמצעות אמביגיות', 'bo': 'གནས་ཚུལ་གྱི་གནས་ཚུལ་ནང་གི་བྲི་ཚིག་Eliciting Bias in Question Answering Models through Ambiguity'}
{'en': 'Question answering (QA) models use retriever and reader systems to answer questions. Reliance on training data by ', 'ar': 'تستخدم نماذج الإجابة على الأسئلة (QA) أنظمة المسترد والقارئ للإجابة على الأسئلة. الاعتماد على بيانات التدريب بواسطة أنظمة ضمان الجودة يمكن أن يضخم أو يعكس عدم المساواة من خلال استجاباتهم. يتم تدريب العديد من نماذج ضمان الجودة ، مثل تلك الخاصة بمجموعة بيانات SQuAD ، واختبارها على مجموعة فرعية من مقالات ويكيبيديا التي تشفر تحيزاتها وتعيد إنتاج عدم المساواة في العالم الحقيقي. يمكن أن يساعد فهم كيفية تأثير بيانات التدريب على التحيز في أنظمة ضمان الجودة على توجيه طرق التخفيف من عدم المساواة. نقوم بتطوير مجموعتين من الأسئلة لأسئلة المجال المغلق والمفتوح على التوالي ، والتي تستخدم أسئلة غامضة لفحص نماذج ضمان الجودة للتحيز. نقوم بتغذية ثلاثة أنظمة لضمان الجودة قائمة على التعلم العميق بمجموعات الأسئلة الخاصة بنا وتقييم الاستجابات للتحيز عبر المقاييس. باستخدام مقاييسنا ، وجدنا أن نماذج ضمان الجودة ذات المجال المفتوح تضخم التحيزات أكثر من نظيراتها في المجال المغلق وتقترح أن التحيزات في سطح المسترد أكثر سهولة بسبب حرية أكبر في الاختيار.', 'pt': 'Os modelos de resposta a perguntas (QA) usam sistemas de recuperação e leitura para responder a perguntas. A confiança nos dados de treinamento dos sistemas de controle de qualidade pode amplificar ou refletir a desigualdade por meio de suas respostas. Muitos modelos de controle de qualidade, como os do conjunto de dados SQuAD, são treinados e testados em um subconjunto de artigos da Wikipedia que codificam seus próprios preconceitos e também reproduzem a desigualdade do mundo real. Compreender como os dados de treinamento afetam o viés em sistemas de controle de qualidade pode informar métodos para mitigar a desigualdade. Desenvolvemos dois conjuntos de perguntas para perguntas de domínio fechado e aberto, respectivamente, que usam perguntas ambíguas para sondar modelos de controle de qualidade quanto a vieses. Alimentamos três sistemas de controle de qualidade baseados em aprendizado profundo com nossos conjuntos de perguntas e avaliamos as respostas por viés por meio das métricas. Usando nossas métricas, descobrimos que os modelos de controle de qualidade de domínio aberto amplificam mais os vieses do que suas contrapartes de domínio fechado e propomos que os vieses no retriever apareçam mais prontamente devido à maior liberdade de escolha.', 'fr': "Les modèles de réponse aux questions (AQ) utilisent des systèmes de récupération et de lecture pour répondre aux questions. Le recours aux données de formation par les systèmes d'assurance qualité peut amplifier ou refléter l'iniquité dans leurs réponses. De nombreux modèles d'assurance qualité, tels que ceux du jeu de données SQuad, sont entraînés et testés sur un sous-ensemble d'articles Wikipédia qui encodent leurs propres biais et reproduisent également les inégalités réelles. Comprendre comment les données de formation affectent les biais dans les systèmes d'assurance qualité peut éclairer les méthodes permettant de réduire les inégalités. Nous développons deux séries de questions pour les questions de domaine fermé et ouvert respectivement, qui utilisent des questions ambiguës pour sonder les modèles d'AQ afin de détecter les biais. Nous alimentons trois systèmes d'assurance qualité basés sur le deep learning avec nos ensembles de questions et évaluons les réponses pour détecter les biais via les métriques. À l'aide de nos métriques, nous constatons que les modèles d'assurance qualité de domaine ouvert amplifient davantage les biais que leurs homologues en domaine fermé et nous proposons que les biais dans le récupérateur apparaissent plus facilement grâce à une plus grande liberté de choix.", 'es': 'Los modelos de respuesta a preguntas (QA) utilizan sistemas de recuperación y lectura para responder preguntas. La confianza en los datos de capacitación por parte de los sistemas de control de calidad puede amplificar o reflejar la desigualdad a través de sus respuestas. Muchos modelos de control de calidad, como los del conjunto de datos sQuad, se entrenan y prueban en un subconjunto de artículos de Wikipedia que codifican sus propios sesgos y también reproducen la desigualdad del mundo real. Comprender cómo los datos de entrenamiento afectan el sesgo en los sistemas de control de calidad puede informar los métodos para mitigar la desigualdad. Desarrollamos dos conjuntos de preguntas para preguntas de dominio cerrado y abierto, respectivamente, que utilizan preguntas ambiguas para investigar los modelos de control de calidad en busca de sesgos. Alimentamos tres sistemas de control de calidad basados en el aprendizaje profundo con nuestros conjuntos de preguntas y evaluamos las respuestas para detectar sesgos a través de las métricas. Utilizando nuestras métricas, descubrimos que los modelos de control de calidad de dominio abierto amplifican los sesgos más que sus homólogos de dominio cerrado y proponemos que los sesgos en el recuperador surjan más fácilmente debido a una mayor libertad de elección.', 'ja': '質疑応答（ QA ）モデルは、リトリーバーとリーダーシステムを使用して質問に答えます。QAシステムによるトレーニングデータへの依存は、応答を通じて不公平性を増幅または反映する可能性があります。SQuADデータセットのような多くのQAモデルは、独自のバイアスを符号化し、現実世界の不平等も再現するウィキペディアの記事のサブセットで訓練され、テストされています。トレーニングデータがQAシステムのバイアスにどのように影響するかを理解することは、不公平を軽減する方法に役立ちます。私たちは、クローズドドメイン質問とオープンドメイン質問の2つの質問セットをそれぞれ開発しています。これらの質問は、曖昧な質問を使用して、バイアスについてQAモデルを調査します。私たちは、3つのディープラーニングベースのQAシステムに質問セットをフィードバックし、メトリクスを介してバイアスに対する応答を評価します。当社の指標を使用して、オープンドメインのQAモデルは、クローズドドメインの対応モデルよりもバイアスを増幅し、より自由な選択により、リトリーバー表面のバイアスがより容易に増幅することを提案しています。', 'zh': '问答 (QA) 模用检索器与阅读器系统以对。 QA系统对培训数者,所以应大与不平也。 诸QA模形,如SQuAD数集者,皆于维基百科文子集上习试,编码己偏见,复现世界不等。 知训练之数 QA 偏差可以为缓不平之法。 各为封闭开放域开两组问,以模棱测QA差。 吾等用问集为三基于深学 QA 系统供反馈,并以指标评估应有差。 用我之指标,见开放域QA大于闭域对应物,而大择自由,检索器中之差易浮也。', 'hi': 'प्रश्न उत्तर (क्यूए) मॉडल प्रश्नों के उत्तर देने के लिए रिट्रीवर और रीडर सिस्टम का उपयोग करते हैं। क्यूए सिस्टम द्वारा प्रशिक्षण डेटा पर निर्भरता उनकी प्रतिक्रियाओं के माध्यम से असमानता को बढ़ा या प्रतिबिंबित कर सकती है। कई क्यूए मॉडल, जैसे कि SQuAD डेटासेट के लिए, विकिपीडिया लेखों के सबसेट पर प्रशिक्षित और परीक्षण किए जाते हैं जो अपने स्वयं के पूर्वाग्रहों को एन्कोड करते हैं और वास्तविक दुनिया की असमानता को भी पुन: पेश करते हैं। यह समझना कि प्रशिक्षण डेटा क्यूए सिस्टम में पूर्वाग्रह को कैसे प्रभावित करता है, असमानता को कम करने के तरीकों को सूचित कर सकता है। हम क्रमशः बंद और खुले डोमेन प्रश्नों के लिए प्रश्नों के दो सेट विकसित करते हैं, जो पूर्वाग्रह के लिए क्यूए मॉडल की जांच करने के लिए अस्पष्ट प्रश्नों का उपयोग करते हैं। हम अपने प्रश्न सेट के साथ तीन गहरी-सीखने-आधारित क्यूए प्रणालियों को खिलाते हैं और मीट्रिक के माध्यम से पूर्वाग्रह के लिए प्रतिक्रियाओं का मूल्यांकन करते हैं। हमारे मैट्रिक्स का उपयोग करते हुए, हम पाते हैं कि ओपन-डोमेन क्यूए मॉडल अपने बंद-डोमेन समकक्षों की तुलना में पूर्वाग्रहों को अधिक बढ़ाते हैं और प्रस्ताव करते हैं कि पसंद की अधिक स्वतंत्रता के कारण पुनर्प्राप्ति सतह में पूर्वाग्रह अधिक आसानी से।', 'ru': 'В моделях ответов на вопросы (QA) для ответов на вопросы используются системы извлечения и считывания. Опора на данные обучения со стороны систем ОК может усилить или отразить неравенство через их ответы. Многие модели QA, такие как для набора данных SQuAD, обучены и протестированы на подмножестве статей Википедии, которые кодируют свои собственные смещения, а также воспроизводят реальное неравенство. Понимание того, как обучающие данные влияют на предвзятость в системах обеспечения качества, может повлиять на методы смягчения неравенства. Мы разрабатываем два набора вопросов для вопросов закрытого и открытого домена соответственно, которые используют неоднозначные вопросы для проверки моделей QA на предвзятость. Мы подпитываем три системы контроля качества на основе глубокого обучения с помощью наших наборов вопросов и оцениваем ответы на предвзятость с помощью метрик. Используя наши метрики, мы обнаружили, что модели QA с открытым доменом усиливают смещения больше, чем их аналоги с закрытым доменом, и предположили, что смещения на поверхности ретривера легче из-за большей свободы выбора.', 'ga': "Úsáideann samhlacha freagartha ceisteanna (QA) córais aisghabhálaí agus léitheora chun ceisteanna a fhreagairt. Má bhíonn córais QA ag brath ar shonraí oiliúna, féadtar éagothroime a mhéadú nó a léiriú trína gcuid freagraí. Déantar go leor samhlacha QA, mar iad siúd do thacair sonraí SQuAD, a oiliúint agus a thástáil ar fho-thacar d'ailt Vicipéid a ionchódaíonn a gcuid laofachta féin agus a atáirgeann freisin éagothroime sa saol fíor. Má thuigtear conas a théann sonraí oiliúna i bhfeidhm ar laofacht i gcórais QA, féadtar eolas a chur ar mhodhanna chun éagothroime a mhaolú. Forbraímid dhá shraith ceisteanna do cheisteanna fearainn iata agus oscailte faoi seach, a úsáideann ceisteanna débhríoch chun samhlacha QA a fhiosrú le haghaidh laofachta. Cuirimid trí chóras QA domhainfhoghlama lenár dtacar ceisteanna agus measúnaítear freagraí maidir le claonadh tríd an méadracht. Agus ár méadracht á úsáid againn, feicimid go méadaíonn samhlacha QA fearainn oscailte laofachtaí níos mó ná a gcomhghleacaithe d’fhearann dúnta agus molann siad go mbeidh laofachtaí sa dromchla aisghabhála níos éasca mar gheall ar níos mó saoirse rogha.", 'ka': 'Name QA სისტემების შესახებ მონაცემების შესახებ შესაძლებელია გააკეთება ან გააკეთება განსხვავებას მათი განსხვავებებით. QA მოდელები, როგორც SQuAD მონაცემებისთვის მონაცემებისთვის, უკეთესოდიის მონაცემებისთვის სუბსეტიდან შემოწმება და შემოწმება, რომლებიც საკუთარი წინასწორებების კოდირებით და მ გავიგოთ, როგორ განათლების მონაცემები QA სისტემებში შეუძლიათ ინფორმაციო მეტისები განათლების განათლებისთვის. ჩვენ განვითარებთ ორი კითხვების კითხვები დახურებული და გახურებული დემომინის კითხვებისთვის, რომლებიც გამოყენებენ უცნობიერი კითხვები QA მოდელებისთვის წინასწორებ ჩვენ სამი ძალიან სწავლებული QA სისტემი ჩვენი კითხვის კონფიგურაციებისთვის გავუმუშავებთ და მეტრიკის გამოყენებისთვის გაუმუშავება. ჩვენი მეტრიკის გამოყენება, ჩვენ აღმოვაჩნეთ, რომ გახსნა დიომინული QA მოდელები უფრო მეტად გახსენებს, ვიდრე ჩვენი გახსენებული დიომინის კონტეპორტები და დავიწყებთ, რომ გახსენებელი საფუძ', 'hu': 'A kérdésre válaszoló modellek retriever és olvasó rendszereket használnak a kérdések megválaszolására. A minőségbiztosítási rendszerek képzési adataira való támaszkodás válaszaik révén fokozhatja vagy tükrözheti az igazságtalanságot. Számos minőségbiztosítási modellt, mint például az SQUAD adatkészletet, képeznek és tesztelnek a Wikipédia cikkek egy részhalmazán, amelyek kódolják saját előítéleteiket és reprodukálják a valós világbeli egyenlőtlenségeket. Annak megértése, hogy a képzési adatok hogyan befolyásolják a minőségbiztosítási rendszerekben előforduló elfogultságokat, segíthet az igazságtalanságok enyhítésére szolgáló módszereket. Két kérdéscsomagot dolgozunk ki zárt és nyílt domain kérdésekhez, amelyek kétértelmű kérdéseket használnak fel a minőségbiztosítási modellek vizsgálatára. Kérdéskészleteinkkel három mélytanulási alapú minőségbiztosítási rendszert táplálunk, és a mutatók segítségével értékeljük a válaszokat az elfogultságra. Metrikáink segítségével megállapítjuk, hogy a nyílt domain minőségbiztosítási modellek jobban erősítik az elfogultságokat, mint a zárt domain társaik, és javasoljuk, hogy a retriever felületén a nagyobb választási szabadság miatt könnyebben előforduljanak.', 'kk': 'Сұрақ жауап беру (QA) үлгілері сұрақтарды жауап беру үшін алу және оқу жүйелерін қолданады. QA жүйелерінің оқыту деректерінің қатынасы өзінің жауаптары арқылы бұл қатынасын көтеруге немесе қатынасыздығын көтеруге болады. SQuAD деректер қорларының көп QA үлгілері, мысалы, Wikipedia мақалаларының ішінде оқылған және тексеріледі. Олар өзінің өзінің қарсылығын кодтамасыз және сондай-ақ әлемдегі қасиеттерді қайта жаса QA жүйелерінде оқыту деректері қалай әсер ететінін түсіндіруге болады. Біз доменге жабылған және ашылған сұрақтар үшін екі сұрақ жасаймыз. Бұл QA үлгілерін бақылау үшін бұл сұрақтар қолданылады. Біз біздің сұрақ жиынымыз менен үш түсіндірілген QA жүйелерін метрикалық арқылы жауаптарды бағалаймыз. Метрикаларымызды қолдану үшін ашық домендық QA үлгілері өзінің жабылған домендық партнерінен артық көбейту үшін көбейту үшін көбейту үшін көбейту үшін қолданып, алу үшін таңдау мүмкіндіктерінің арты', 'it': "I modelli di risposta alle domande (QA) utilizzano sistemi di recupero e lettura per rispondere alle domande. L'affidamento sui dati di formazione da parte dei sistemi QA può amplificare o riflettere l'iniquità attraverso le loro risposte. Molti modelli di QA, come quelli per il dataset SQUAD, sono addestrati e testati su un sottoinsieme di articoli di Wikipedia che codificano i propri pregiudizi e riproducono anche disuguaglianze nel mondo reale. Capire come i dati di formazione influiscono sui pregiudizi nei sistemi di QA può informare i metodi per mitigare l'iniquità. Sviluppiamo due serie di domande rispettivamente per domande a dominio chiuso e aperto, che utilizzano domande ambigue per sondare i modelli QA per il bias. Alimentamo tre sistemi di QA basati su deep learning con i nostri set di domande e valutiamo le risposte per il bias tramite le metriche. Utilizzando le nostre metriche, scopriamo che i modelli di QA a dominio aperto amplificano i bias più delle loro controparti a dominio chiuso e propongono che i bias nella superficie del retriever siano più facilmente a causa di una maggiore libertà di scelta.", 'el': 'Τα μοντέλα απάντησης ερωτήσεων (QA) χρησιμοποιούν συστήματα ανάκτησης και ανάγνωσης για να απαντήσουν σε ερωτήσεις. Η εμπιστοσύνη στα δεδομένα κατάρτισης από τα συστήματα QS μπορεί να ενισχύσει ή να αντικατοπτρίζει την ανισότητα μέσω των απαντήσεών τους. Πολλά μοντέλα QA, όπως αυτά για το σύνολο δεδομένων SQuAD, εκπαιδεύονται και δοκιμάζονται σε ένα υποσύνολο άρθρων της Βικιπαίδειας που κωδικοποιούν τις δικές τους προκαταλήψεις και επίσης αναπαράγουν την πραγματική ανισότητα. Η κατανόηση του τρόπου με τον οποίο τα δεδομένα κατάρτισης επηρεάζουν την προκατάληψη στα συστήματα QS μπορεί να ενημερώσει τις μεθόδους μετριασμού της ανισότητας. Αναπτύσσουμε δύο σύνολα ερωτήσεων για κλειστές και ανοικτές ερωτήσεις αντίστοιχα, τα οποία χρησιμοποιούν ασάφειες ερωτήσεις για να εξετάσουν μοντέλα QA για προκατάληψη. Τροφοδοτούμε τρία συστήματα ποιοτικής αξιολόγησης βασισμένα σε βαθιά μάθηση με τα σύνολα ερωτήσεων μας και αξιολογούμε τις απαντήσεις για προκατάληψη μέσω των μετρήσεων. Χρησιμοποιώντας τις μετρήσεις μας, διαπιστώνουμε ότι τα μοντέλα QA ανοικτού τομέα ενισχύουν τις προκατάληψη περισσότερο από ό,τι τα ομόλογά τους κλειστού τομέα και προτείνουν ότι οι προκατάληψη στην επιφάνεια του ανακτητή είναι πιο εύκολα λόγω της μεγαλύτερης ελευθερίας επιλογής.', 'mk': 'Question answering (QA) models use retriever and reader systems to answer questions.  Reliance on training data by QA systems can amplify or reflect inequity through their responses.  Многу QA модели, како што се оние за SQuAD податоците, се тренирани и тестирани на подгрупа на статии од Википедија кои ги кодираат своите предрасуди и исто така ја репродуктираат нееднаквоста во реалниот свет. Разбирање како податоците за обука влијаат на предрасудите во системите на QA може да ги информира методите за намалување на нееднаквоста. Развиваме два набора прашања за затворени и отворени прашања на домен, кои користат двогледни прашања за проверка на моделите на QA за пристрасност. Ние храниме три системи на длабоко учење на QA со нашите поставувања прашања и оценуваме одговори за предрасуди преку метриката. Користејќи ги нашите метрики, откриваме дека моделите на отворен домен QA ги зголемуваат предрасудите повеќе од нивните колеги на затворен домен и предложуваме предрасудите на површината на преземачот да бидат полесни поради поголемата слобода на избор.', 'lt': 'Klausimų atsakymo (QA) modeliai, atsakydami į klausimus, naudoja paieškos ir skaitymo sistemas. Pasikliauti QA sistemų mokymo duomenimis gali sustiprinti arba atspindėti nelygybę jų atsakymais. Daugelis QA modelių, pavyzdžiui, SQuAD duomenų rinkinio modelių, rengiami ir išbandomi Wikipedia straipsnių pogrupyje, kuriame koduojami jų nusikaltimai ir taip pat atkuriama realaus pasaulio nelygybė. Understanding how training data affects bias in QA systems can inform methods to mitigate inequity.  Mes parengiame du klausimų rinkinius atitinkamai uždarytiems ir atviriems domeniniams klausimams, kurie naudoja dviprasmiškus klausimus, kad ištirtų QA modelius, kad būtų galima nustatyti sąžiningumą. Mes naudojame tris giliai mokymosi pagrindu grindžiamas QA sistemas savo klausimų rinkiniais ir vertiname atsakymus į sąžiningumą taikant metrinius rodiklius. Naudodami mūsų metrinius rodiklius nustatome, kad atvirojo domeno QA modeliai labiau sustiprina šoninius rodiklius nei jų uždarojo domeno kolegos ir siūlo, kad šoniniai rodikliai atkūrimo paviršiuje būtų lengviau nukreipti dėl didesnės pasirinkimo laisvės.', 'ms': 'Model menjawab soalan (QA) menggunakan sistem pemulihan dan pembaca untuk menjawab soalan. Percayaan pada data latihan oleh sistem QA boleh memperkuat atau merefleksikan ketidakadilan melalui balasan mereka. Banyak model QA, seperti yang untuk set data SQuAD, dilatih dan diuji pada subset artikel Wikipedia yang mengekodkan biases mereka sendiri dan juga mengembalikan ketidaksamaan dunia nyata. Memahami bagaimana data latihan mempengaruhi bias dalam sistem QA boleh maklumkan kaedah untuk mengurangi ketidaksamaan. Kami mengembangkan dua set soalan untuk soalan domain tertutup dan terbuka secara berdasarkan, yang menggunakan soalan yang ambiguh untuk menguji model QA untuk bias. Kami memberi makan tiga sistem QA berasaskan belajar dalam dengan set soalan kami dan menilai jawapan untuk bias melalui metrik. Dengan menggunakan metrik kita, kita mendapati bahawa model QA domain terbuka amplifikasi biases lebih daripada rakan-rakan domain tertutup mereka dan melamar biases di permukaan pemulihan lebih mudah disebabkan kebebasan pilihan yang lebih besar.', 'ml': 'ചോദ്യം ഉത്തരം (ക്യൂഎ) മോഡലുകള്\u200d ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകാനും വായിക്കുന്ന സിസ്റ്റം ഉപയോഗിക്കു ക്യൂഎ സിസ്റ്റമുകളില്\u200d നിന്നുള്ള പരിശീലനത്തിന്റെ വിശ്വാസം അവരുടെ ഉത്തരങ്ങളിലൂടെ കൂടുതല്\u200d കൂടുതലാക സ്കുവാഡ് ഡാറ്റാസെറ്റിന്റെ പോലുള്ള ക്യൂഎ മോഡലുകളില്\u200d പലരും വിക്കിപിഡിയയുടെ ലേഖനങ്ങളില്\u200d പരിശീലിക്കപ്പെടുകയും ചെയ്തിരിക്കുന്നു.  പരിശീലന വിവരങ്ങള്\u200d ക്യൂഎ സിസ്റ്റത്തിലെ പിശാചുക്കളെ എങ്ങനെ ബാധിക്കുന്നുവെന്ന് മനസ്സിലാക്കുന്നു എന് നമ്മള്\u200d രണ്ടു ചോദ്യങ്ങള്\u200d നിര്\u200dമ്മിക്കുന്നു. നിര്\u200dണ്ണയിക്കുന്നത് പൂര്\u200dണ്ണമായും തുറന്ന ഡൊമെയിന്\u200d ചോദ്യങ്ങള്\u200dക്ക് വ ഞങ്ങള്\u200d മൂന്നു ആഴത്തില്\u200d പഠിക്കുന്ന ക്യൂഎ സിസ്റ്റമുണ്ടാക്കുന്നത് നമ്മുടെ ചോദ്യ സജ്ജീകരണങ്ങള്\u200d കൊണ്ടാണ്  നമ്മുടെ മെറ്റിക്കുകള്\u200d ഉപയോഗിച്ച്, തുറന്ന ഡൊമെയിന്\u200d ക്യൂഎ മോഡലുകള്\u200d അവരുടെ അടച്ചുമൂടിയ ഡോമെയിന്\u200d കൂടുതല്\u200d പ്രതിയോഗിക്കുന്നതാണ്, തിരിച്ചുവര', 'mn': 'асуулт хариулт (QA) загварууд асуултад хариулт өгөхийн тулд авагч болон уншигч системийг ашигладаг. QA системийн сургалтын өгөгдлийн тухай хариу үйлдэл нь тэдний хариу үйлдэл бус байдлыг нэмэгдүүлж эсвэл харуулж чадна. SQuAD өгөгдлийн сангийн олон QA загварууд нь Wikipedia өгөгдлийн багц дээр суралцаж, шалгалт хийгддэг. Энэ нь өөрсдийн өрөөсгөл байдлыг дүрслэж, мөн бодит ертөнцийн тэгш байдлыг үржүүлдэг. QA системд сургалтын өгөгдлийн мэдээллийг хэрхэн нөлөөлж байгааг ойлгохын тулд тэгш байдлыг багасгах арга замыг мэдэх боломжтой. Бид хоёр олон асуултуудыг бүтээж, нээлттэй холбоотой. Энэ нь QA загварын талаар шалгахын тулд гайхалтай асуултуудыг ашигладаг. Бид суралцаж суралцах 3 гүнзгий QA системийг суралцах асуулт хэмжээтэй хандуулж, метрийн аргаар хариултыг үнэлдэг. Манай метрикийг ашиглан, QA-ын нээлттэй загварын загвар нь түүний холбоотой холбоотой холбоотой хүмүүсээс илүү ойлголтыг нэмэгдүүлдэг ба түүний сонголтын эрх чөлөөтэй учраас хадгалагч гадаргуудад байдал илүү амархан байдлы', 'mt': 'Il-mudelli tat-tweġiba għall-mistoqsijiet (QA) jużaw sistemi ta’ ġbir lura u qarrejja biex iwieġbu mistoqsijiet. Id-dipendenza fuq id-dejta tat-taħriġ mis-sistemi QA tista’ tamplifika jew tirrifletti l-inugwaljanza permezz tar-reazzjonijiet tagħhom. Ħafna mudelli QA, bħal dawk għas-sett tad-dejta SQuAD, huma mħarrġa u ttestjati fuq sottosett ta’ oġġetti tal-Wikipedia li jikkodifikaw il-preġudizzji tagħhom stess u jirriproduċu wkoll l-inugwaljanza fid-dinja reali. Il-fehim ta’ kif id-dejta tat-taħriġ taffettwa l-preġudizzju fis-sistemi QA jista’ jinforma metodi biex itaffi l-inugwaljanza. Aħna niżviluppaw żewġ settijiet ta’ mistoqsijiet għal mistoqsijiet magħluqa u miftuħa ta’ dominju rispettivament, li jużaw mistoqsijiet ambigwi biex jinstabu mudelli ta’ QA għal preġudizzju. Aħna nużaw tliet sistemi ta’ QA bbażati fuq tagħlim profond bis-settijiet ta’ mistoqsijiet tagħna u jivvalutaw ir-risposti għal preġudizzju permezz tal-metriċi. Bl-użu tal-metriċi tagħna, isibu li mudelli ta’ QA ta’ dominju miftuħ jimplifikaw il-preġudizzji aktar mill-kontropartijiet tagħhom ta’ dominju magħluq u jipproponu li l-preġudizzji fis-superfiċje tal-irkupru jkunu aktar faċli minħabba libertà akbar ta’ għażla.', 'no': 'Name Tilsvar på treningsdata av QA-systemet kan styrke eller refleksera ulikheten gjennom dei svara. Mange QA-modeller, som dei for SQuAD-datasettet, vert trengte og testa på ein undergruppe av Wikipedia-artiklar som kodar sine eige forsikt og også gjenopprettar ulikheten i verden. For å forstå korleis opplæringsdata påvirkar bias i QA-systemet kan informera metodar for å gjere ulikhet. Vi utviklar to sett spørsmål for lukka og opna domenespørsmål respectivt, som brukar uavhengige spørsmål for å prøve QA-modeller for forsiktighet. Vi får tre dype læringsbaserte QA-systemar med våre spørsmålssett og evaluerer svar for forsiktighet via metrikane. Bruk metrikane våre finn vi at open-domain QA-modeller forstørrar forstørringar meir enn dei lukka-domenekontorene og foreslår at forstørringane i tilhendingsfarget meir lett på grunn av større frihet av valet.', 'pl': 'Modele odpowiedzi na pytania (QA) wykorzystują systemy retrievera i czytnika do odpowiedzi na pytania. Poleganie na danych szkoleniowych przez systemy QA może zwiększyć lub odzwierciedlać nierówność poprzez ich reakcje. Wiele modeli jakości, takich jak te dla zbioru danych SQuAD, są trenowane i testowane na podzbiorze artykułów Wikipedii, które kodują własne uprzedzenia, a także reprodukują nierówności w świecie rzeczywistym. Zrozumienie, w jaki sposób dane szkoleniowe wpływają na stronniczość w systemach jakości, może pomóc metodom łagodzenia nierówności. Opracowujemy dwa zestawy pytań odpowiednio dla pytań zamkniętych i otwartych, które wykorzystują niejednoznaczne pytania do badania modeli jakości pod kątem uprzedzeń. Naszymi zestawami pytań wykorzystujemy trzy systemy jakości oparte na głębokim uczeniu i oceniamy odpowiedzi pod kątem uprzedzeń za pomocą wskaźników. Korzystając z naszych wskaźników, stwierdzimy, że modele QA otwartej domeny wzmacniają uprzedzenia bardziej niż ich odpowiedniki w zamkniętej domenie i proponują, że uprzedzenia w powierzchni retrievera łatwiej ze względu na większą swobodę wyboru.', 'si': 'Name QA පද්ධතියෙන් ප්\u200dරශ්නය දත්තේ සම්බන්ධ වෙන්න පුළුවන් ඔවුන්ගේ ප්\u200dරතික්\u200dරියාවයෙන් අනිවාර්ය වි ගොඩක් QA මොඩල්, හරියට SQuAD දත්ත සෙට් වෙනුවෙන්, විකිපිඩියා ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති QA පද්ධතියේ ප්\u200dරශ්නය දත්ත කොහොමද ප්\u200dරශ්නය කරන්නේ කියලා තේරුම් ගන්න පුළුවන් විදිහට අනිවාර්ය අපි ප්\u200dරශ්නයක් දෙකක් විස්තර කරනවා සහ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විස්තර කරනවා, ඒ වගේම QA මොඩේල් එක අපි ගොඩක් ඉගෙන ගන්නේ QA පද්ධතිය තුනක් පද්ධතිය අපේ ප්\u200dරශ්න සෙට් එක්ක කැමති කරනවා ඒ වගේම ප්\u200dරශ්නයක් ප්\u200dර අපේ මෙට්\u200dරික්ස් එක භාවිතා කරන්න, අපි හොයාගන්නවා ඒ විවෘත්ත QA මෝඩේල් එක්ක ඔවුන්ගේ වහල් ඩොමේන් එක්ක ප්\u200dරතිකාරයෝ වඩා වඩා ප්\u200dරතිකාරය', 'ro': 'Modelele de răspuns la întrebări (QA) utilizează sisteme de retriever și cititor pentru a răspunde la întrebări. Baza pe datele de formare de către sistemele de asigurare a calității poate amplifica sau reflecta inegalitatea prin răspunsurile lor. Multe modele QA, cum ar fi cele pentru setul de date SQUAD, sunt instruite și testate pe un subset de articole Wikipedia care codează propriile prejudecăți și reproduc, de asemenea, inegalitatea din lumea reală. Înțelegerea modului în care datele de formare afectează părtinirea în sistemele de calitate poate informa metode de atenuare a inegalității. Dezvoltăm două seturi de întrebări pentru întrebări cu domeniu închis și, respectiv, deschis, care utilizează întrebări ambigue pentru a analiza modelele QA pentru părtinire. Furnizăm trei sisteme de calitate bazate pe învățare profundă cu seturile noastre de întrebări și evaluăm răspunsurile pentru părtinire prin intermediul măsurătorilor. Folosind metricile noastre, constatăm că modelele QA cu domeniu deschis amplifică prejudecățile mai mult decât omologii lor cu domeniu închis și propun ca prejudecățile din suprafața retrieverului să fie mai ușor datorită unei mai mari libertăți de alegere.', 'sr': 'Modeli odgovora na pitanja (QA) koriste povratničke i čitačke sisteme za odgovor na pitanja. Odstupanje na podatke o obuci podataka QA sistema može pojačati ili odražavati nepravednost kroz njihove odgovore. Mnogi QA modeli, kao što su oni za SQuAD dataset, obučeni su i testirani na podskupu Wikipedijskih članaka koji kodiraju sopstvene predrasude i takođe reproduciraju nepravednost stvarnog svijeta. Razumejući kako podaci obuke utiču na pristrasnost u QA sistemima mogu obavijestiti metode za smanjenje neispravnosti. Razvijamo dve sete pitanja za zatvorene i otvorene pitanja domena, koje koriste ambigutne pitanja za probu modela QA za predrasude. Hranimo tri sistema na dubokom učenju QA sa našim setima pitanja i procjenjujemo odgovore na predrasude putem metrika. Koristeći našu metriku, našli smo da modeli otvorenog domena QA pojačaju predrasude više od njihovih kolega zatvorenih domena i predlažemo da predrasude na površini površine povratnika lakše zbog veće slobode izbora.', 'so': "Isku jawaabta su'aalaha su'aalaha (QA) waxay isticmaaliyaan dib u qaadista iyo nidaamka akhriska si ay ugu jawaabaan su'aalaha. Kaalmada waxbarashada ee nidaamka QA waxay ku kordhi karaan ama ka fikiri karaan sinnaanta jawaabahooda. Tusaale badan QA, tusaale ahaan kuwa SQuAD dataset, waxaa lagu tababaray oo lagu tijaabiyey qeyb ka mid ah warqadaha Wikipedia oo ku qoran baaritaankooda islamarkaasna lagu soo bandhigaa sinnaanta dunida ee halis ah. Waan garashada sida macluumaadka waxbarashadu ay u saameyn karaan hababka nidaamka QA, waxay ogeysiin karaan qaababka ku qiyaasta sinnaanta. Waxaan horumarinaa laba su'aalood oo su'aalo ah si qarsoon oo furan, kuwaas oo lagu isticmaalaa su'aalo qalloocan ah si aan u caddeyno tusaalooyin QA ah oo baas ah. Saddex nidaam ee QA ee hoose-u-barashada ayaannu ku quudinnaa kooxaha su'aalahana, waxaynu qiimeynaynaa jawaabayaasha baaritaanka xagga metrikada. Isku isticmaalidda qaababkayada QA ee furan waxaynu aragnaa in qaababka QA ay ku kordhiyaan khilaafka ay ka badnaan yihiin saaxiibbadooda degmooyinka qarsoonka ah, waxaana soo jeedinayaa in dabeecada dib u soo celinta ay si fudud ugu fududaato xorriyadda doorashada badan darteed.", 'ta': 'Question answering (QA) models use retriever and reader systems to answer questions.  QA அமைப்புகள் மூலம் பயிற்சி தரவுகள் மீது மாற்றலாம் அல்லது அவர்களுடைய பதில்கள் மூலம் நியாயத்தை பார்க்கலாம். Many QA models, like those for the SQuAD dataset, are trained and tested on a subset of Wikipedia articles which encode their own biases and also reproduce real- world inequality. பயிற்சி தரவு எவ்வாறு QA முறைமைகளில் பிரச்சனைகளை பாதிக்கும் என்பதை புரிந்து கொள்வது எவ்வாறு நியாயத்த நாம் மூடப்பட்டுள்ள மற்றும் திறந்த களம் கேள்விகளுக்கு இரண்டு கேள்விகளை உருவாக்குகிறோம். அது கியூஏ மாதிரிகளை பாதி நாங்கள் மூன்று ஆழமான கற்றல் அடிப்படையிலான கியூஏ அமைப்புகளை எங்கள் கேள்வி அமைப்புகளுடன் உணவளிக்கிறோம் மெட்ரிக் எங்கள் மெட்ரிக்களை பயன்படுத்தி, திறந்த களம் கியூஏ மாதிரிகள் அவர்களுடைய மூடிய களஞ்சியத்தை விட பெரிதாக்குகிறது மற்றும் திரும்ப திருப்பும் மேல்', 'sv': 'Frågor besvarande modeller använder retriever- och läsarsystem för att svara på frågor. Att kvalitetssäkringssystem förlitar sig på träningsdata kan förstärka eller återspegla orättvisor genom deras svar. Många QA-modeller, till exempel de för SQUAD-datauppsättningen, är utbildade och testade på en delmängd av Wikipediaartiklar som kodar deras egna fördomar och även reproducerar verklig ojämlikhet. Att förstå hur träningsdata påverkar bias i QA-system kan bidra till metoder för att mildra orättvisor. Vi utvecklar två uppsättningar frågor för stängda respektive öppna domänfrågor, som använder tvetydiga frågor för att undersöka QA-modeller för bias. Vi matar tre djupinlärningsbaserade QA-system med våra frågeuppsättningar och utvärderar svar för bias via mätvärdena. Med hjälp av våra mätvärden ser vi att QA-modeller med öppen domän förstärker fördomar mer än deras motsvarigheter med sluten domän och föreslår att fördomar i retriever ytan lättare på grund av större valfrihet.', 'ur': 'سوال جواب دینے کے لئے (QA) موڈل استعمال کرتے ہیں سوال جواب دینے کے لئے پھیرنے اور پڑھنے کی سیسٹم. QA سیستموں کے ذریعہ تربیت ڈیٹوں پر اعتبار ہے کہ ان کے جواب کے ذریعہ انصاف کو بڑھا یا دکھا سکتا ہے. بہت سے QA موڈل، جیسے SQuAD ڈیٹ سٹ کے لئے، ویکیپیڈیا لکھائیوں کے سپسٹ پر آموزش اور آزمائش کی جاتی ہیں جو اپنی مخالفت کو Encoding کرتے ہیں اور اصل دنیا کی نابرابری کو بھی دوبارہ پیدا کرتے ہیں۔ تعلیم دیٹا کیسے QA سیستموں میں غیر انصافی کو کمزور کرنے کے لئے روش بتائی جاتی ہے۔ ہم دو سٹ سوالوں کو بند اور کھول دینے کے لئے مختلف سوالوں کے لئے تخلیق کریں گے، جو QA موڈل کو بغیر غیر مشکلات کے لئے استعمال کرتے ہیں۔ ہم تین عمیق سیکھنے کی QA سیستموں کو پوچھنے کے ساتھ کھلاتے ہیں اور منٹریک کے ذریعے انعام کے لئے جواب دیتے ہیں۔ ہمارے مٹریک کے استعمال سے ہم دیکھتے ہیں کہ open-domain QA موڈل ان کے بند ڈومین کے کنٹرپارتوں سے زیادہ غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر', 'uz': "Name Name Koʻp QA modellari, SQuAD maʼlumotlari uchun o'rganilgan va Wikipedia maqolalarining tub qismlarida ishlatilgan va ularning o'zimlarini kodlash va asl dunyodagi sinflikni qaytadi. @ info Biz boshqa yopilgan va ochiq domen savollari uchun ikkita savollarni yaratishmiz. Bu savollar QA modellarini bias uchun ishlab chiqaradi. Biz uchta ta ta'lim bo'lgan QA tizimlarimizni soʻrovimiz moslamalarimiz bilan ishlatamiz va metriklar orqali bizning qiymatlarimizni qiymatimiz. Bizning metriklarimizdan foydalanishimiz mumkin, open domain QA modellari yopilgan domen kompyuterlaridan ko'proq ishlarni oshirishni ko'rsatamiz va o'zgartirib chiqishni o'zgartirish xolosi sababini ko'proq o'zgartirib turadi.", 'vi': 'Các mẫu câu hỏi (QA) sử dụng hệ thống phục hồi và đọc để trả lời câu hỏi. Sự tin tưởng vào dữ liệu huấn luyện của hệ thống QA có thể khuếch đại hay phản ánh bất công qua các phản ứng. Nhiều mô hình QA, như hệ thống dữ liệu SCOAD, được đào tạo và thử nghiệm trên một nhóm các tạp chí Wikipedia đã mã hóa các giả của chính họ và cũng tạo ra sự bất công trong thế giới thực. Sự hiểu tại sao dữ liệu về huấn luyện ảnh hưởng đến khuynh hướng trong hệ thống QA có thể cung cấp phương pháp chống lại bất công. Chúng tôi phát triển hai bộ câu hỏi cho hai câu hỏi riêng lẻ và mở, hai câu hỏi dùng những câu mơ hồ để thăm dò biểu tượng thiên vị. Chúng tôi cung cấp ba hệ thống QA dựa vào sâu học với các bộ câu hỏi và đánh giá các phản ứng về khuynh hướng thông qua âm lượng. Sử dụng âm lượng của chúng tôi, chúng tôi tìm thấy các mô hình QA mở rộng hơn so với các chủng giả trong vùng kín và đề xuất khả năng biến dạng trên bề mặt phục hồi nhanh hơn nhờ vào sự tự do lựa chọn nhiều hơn.', 'bg': 'Моделите за отговор на въпроси използват системи за изтегляне и четене, за да отговорят на въпроси. Разчитането на данните за обучението от системите за контрол на качеството може да увеличи или отрази неравенството чрез техните отговори. Много модели за оценка на качеството, като тези за набора от данни SQuAD, са обучени и тествани върху поднабор от статии в Уикипедия, които кодират собствените си пристрастия и също възпроизвеждат неравенството в реалния свят. Разбирането как данните от обучението влияят на пристрастията в системите за контрол на качеството може да информира методите за смекчаване на неравенството. Разработваме два комплекта въпроси съответно за въпроси със затворен и отворен домейн, които използват двусмислени въпроси за проучване на модели за оценка на качеството за пристрастия. Ние подхранваме три системи за оценка на качеството, базирани на дълбоко обучение, с нашите набори от въпроси и оценяваме отговорите за пристрастия чрез показателите. Използвайки нашите показатели, откриваме, че моделите с отворен домейн увеличават пристрастията повече от техните затворени домейни колеги и предлагат пристрастията в повърхността на ретривера по-лесно поради по-голяма свобода на избор.', 'hr': 'Modeli odgovora na pitanja (QA) koriste sustave prikupljača i čitača za odgovor na pitanja. Odstupanje na podatke o obuci sustava QA-a može povećati ili odražiti nejednakost kroz njihove odgovore. Mnogi QA modeli, kao što su oni za SQuAD dataset, obučeni su i testirani na podskupu Wikipedijskih članaka koji kodiraju vlastite predrasude i reproduktiraju nepravednost stvarnog svijeta. Razumijeti kako podaci obuke utječu na pristrasnost u QA sustavima mogu obavijestiti metode za smanjenje neispravnosti. Razvijamo dvije vrste pitanja za zatvorena i otvorena pitanja domena, koje koriste dvosmislene pitanja za probu modela QA za predrasude. Hranimo tri sustava na dubokom učenju QA sa našim postavima pitanja i procjenjujemo odgovore na predrasude putem metrika. Koristeći našu metriku, nalazimo se da modeli otvorenog domena QA pojačaju predrasude više od njihovih kolega zatvorenih domena i predlažemo da predrasude na površini površine povlačenja lakše zbog veće slobode izbora.', 'nl': 'Vragen beantwoorden (QA) modellen gebruiken retriever- en readersystemen om vragen te beantwoorden. Vertrouwen op trainingsgegevens door QA-systemen kan ongelijkheid vergroten of weerspiegelen door hun reacties. Veel QA modellen, zoals die voor de SQuAD dataset, worden getraind en getest op een subset Wikipedia artikelen die hun eigen vooroordelen coderen en ook echte ongelijkheid reproduceren. Inzicht in hoe trainingsdata bias in QA-systemen beïnvloedt, kan informatie geven over methoden om ongelijkheid te verminderen. We ontwikkelen twee sets vragen voor respectievelijk gesloten en open domeinvragen, die dubbelzinnige vragen gebruiken om QA modellen te onderzoeken op bias. We voeden drie op deep learning gebaseerde QA-systemen met onze vragensets en evalueren antwoorden op bias via de statistieken. Met behulp van onze metrics, ontdekken we dat open-domein QA modellen biases meer versterken dan hun closed-domein tegenhangers en stellen we voor dat biases in de retriever gemakkelijker opduiken als gevolg van een grotere keuzevrijheid.', 'da': 'Spørgsmålsbesvarelsesmodeller bruger retriever- og læsersystemer til at besvare spørgsmål. Afhængighed af træningsdata fra QA-systemer kan forstærke eller afspejle ulighed gennem deres reaktioner. Mange QA modeller, såsom dem for SQUAD datasættet, er trænet og testet på en del af Wikipedia artikler, der koder deres egne fordomme og også reproducerer ulighed i den virkelige verden. At forstå, hvordan træningsdata påvirker bias i QA-systemer, kan danne grundlag for metoder til at afhjælpe uligheder. Vi udvikler to sæt spørgsmål til henholdsvis lukkede og åbne domæne spørgsmål, som bruger tvetydige spørgsmål til at undersøge QA modeller for bias. Vi fodrer tre deep-learning-baserede QA-systemer med vores spørgsmålsæt og evaluerer svar for bias via målene. Ved hjælp af vores metrics finder vi, at open-domain QA modeller forstærker bias mere end deres lukkede domæne modstykker og foreslår, at bias i retriever overfladen lettere på grund af større valgfrihed.', 'de': 'Fragebeantworter (QA)-Modelle verwenden Retriever- und Lesesysteme, um Fragen zu beantworten. Die Abhängigkeit von Trainingsdaten durch QS-Systeme kann Ungleichheit durch ihre Reaktionen verstärken oder widerspiegeln. Viele QA-Modelle, wie die für den SQuAD-Datensatz, werden an einer Teilmenge von Wikipedia-Artikeln trainiert und getestet, die ihre eigenen Verzerrungen kodieren und auch reale Ungleichheiten reproduzieren. Zu verstehen, wie Trainingsdaten Verzerrungen in QS-Systemen beeinflussen, kann Methoden zur Minderung von Ungleichheiten unterstützen. Wir entwickeln zwei Sätze von Fragen für geschlossene und offene Fragen, die mehrdeutige Fragen verwenden, um QA-Modelle auf Bias zu untersuchen. Wir speisen drei Deep-Learning-basierte QA-Systeme mit unseren Fragesets und bewerten Antworten auf Bias anhand der Metriken. Anhand unserer Metriken finden wir heraus, dass offene QA-Modelle Verzerrungen stärker verstärken als ihre geschlossenen Pendants und schlagen vor, dass Verzerrungen in der Retrieveroberfläche aufgrund größerer Wahlfreiheit leichter auftreten.', 'ko': 'Q&amp;A 모델은 검색기와 카드 리더기 시스템을 사용하여 질문에 대답합니다.QA시스템의 교육 데이터에 대한 의존도는 그들의 반응을 통해 불공평함을 확대하거나 반영할 수 있다.많은 품질 보증 모델, 예를 들어 단체 데이터 집합에 사용되는 모델은 모두 위키백과 문장의 서브집합에서 훈련과 테스트를 실시한 것이다. 이런 문장들은 자신의 편견을 인코딩하고 현실 세계의 불평등을 재현했다.교육 데이터가 QA 시스템의 편차에 어떻게 영향을 미치는지 이해하면 불공평함을 완화할 수 있는 방법을 제공할 수 있다.폐쇄적 영역 문제와 개방적 영역 문제에 대해 모호한 문제로 QA모델의 편견을 탐색하는 두 그룹을 개발했다.우리는 깊이 있는 학습을 바탕으로 하는 세 개의 QA 시스템에 문제집을 제공하고 이러한 지표를 통해 피드백에 편차가 있는지 평가한다.우리의 지표를 사용하면 개방역 QA모델이 폐쇄역 QA모델보다 편차를 확대하기 쉽다는 것을 알 수 있고 더 큰 선택의 자유로 인해 검색기에서의 편차가 더욱 쉽게 나타난다는 것을 알 수 있다.', 'id': 'Model menjawab pertanyaan (QA) menggunakan sistem retriever dan pembaca untuk menjawab pertanyaan. Bergantung pada data pelatihan oleh sistem QA dapat memperkuat atau merefleksikan ketidakadilan melalui respon mereka. Banyak model QA, seperti yang untuk set data SQuAD, dilatih dan diuji pada subset artikel Wikipedia yang mengekodikan biases mereka sendiri dan juga mereproduksi ketidaksamaan dunia nyata. Memahami bagaimana data pelatihan mempengaruhi bias dalam sistem QA dapat memberitahu metode untuk mengurangi ketidaksetara. Kami mengembangkan dua set pertanyaan untuk pertanyaan domain tertutup dan terbuka secara sesuai, yang menggunakan pertanyaan ambiguh untuk memeriksa model QA untuk bias. Kami memberi makan tiga sistem QA berbasis belajar dalam dengan set pertanyaan kami dan mengevaluasi respon untuk bias melalui metrik. Menggunakan metrik kami, kami menemukan bahwa model QA domain terbuka amplifikasi biases lebih dari rekan domain tertutup mereka dan menyarankan biases di permukaan retriever lebih mudah karena kebebasan pilihan yang lebih besar.', 'fa': 'مدلهای پاسخ سوال (QA) برای پاسخ از سوالات استفاده از سیستم گیرنده و خواننده استفاده می\u200cکنند. ارتباط به داده آموزش توسط سیستم\u200cهای QA می\u200cتواند به وسیله پاسخ\u200cهایشان عدالتی را افزایش یا توضیح دهد. بسیاری از مدل QA، مانند آن\u200cها که برای مجموعه داده\u200cهای SQuAD، روی زیر مجموعه\u200cهای ویکیپدییا آموزش داده می\u200cشوند و آزمایش می\u200cشوند که همچنین تغییرات خود را رمز می\u200cکنند و همچنین نابرابری دنیای واقعی را بازسازی می\u200cکنند. درک کردن اطلاعات آموزش چگونه در سیستم\u200cهای QA تحت تاثیر قرار می\u200cگیرد می\u200cتواند روش\u200cهایی را برای کاهش دادن عدالتی اطلاع دهد. ما دو مجموعه سوال برای سوال های بسته و باز دامنی را به صورت مختلف توسعه می کنیم، که از سوال های مختلف استفاده می کنند تا مدل های QA را برای تحقیق کردن طبیعی تحقیق کنند. ما سه سیستم QA بنیاد عمیق یادگیری را با مجموعه سوال\u200cهایمان تغذیه می\u200cکنیم و پاسخ\u200cهایی برای تغییرات در طول متریک ارزیابی می\u200cکنیم. با استفاده از متریک\u200cهایمان، ما پیدا می\u200cکنیم که مدل\u200cهای باز دامنه\u200cای QA از همکاران دامنه\u200cهای بسته\u200cشان بیشتری را افزایش می\u200cدهد و پیشنهاد می\u200cدهیم که توسط آزادی\u200cهای انتخاب بیشتری در سطح بازیابی\u200cکننده\u200cها بسیار آسانتر است.', 'tr': 'Sorag jogap (QA) nusgalary almak we okamak sistemlerini soraglary jogaplamak üçin ulanýarlar. QA sistemalary tarapyndan okuwçylyk maglumatynda ynamlyk çykyşlygyny ýagdaýlaşdyryp biler. SQuAD maglumatlary üçin köp QA modelleri, Wikipediýanyň bir toparyny kodýan we dünýäde ýetişiklikleri diýip test edilýär. QA sistemalarda öwrenme maglumatyň nähili nähili ýeterlik edýändigini biljek bolýar. Qapyk we açyk domena soraglary üçin iki topar soragy düzenleýäris. Bu ýerler QA modellerini bias üçin öňünde örän möhüm soraglary ulanýarlar. Biz 3 derin öwrenme tabanly QA sistemalary soraglarymyz bilen üýtgedýäris we metriýa görä jogaplarymyzy deňleýäris. Metriklerimizi kullanarak, open-domain QA modelleri kapalı domeny karşındakilerinden ötesini arttırmak ve daha kolay çekişin yüzeyinde bu sowukları saýlamak özgürlüğüne göre daha kolay düşürmeyi teklif ediyoruz.', 'sw': 'Swali likijibu mifano (QA) hutumia mfumo wa kurejea na wasomaji kujibu maswali. Uimani wa taarifa za mafunzo na mfumo wa QA unaweza kuongeza au kutafakari kutokuwepo usawa kupitia majibu yao. Mfano mwingi wa QA, kama vile wale wa seti ya data ya SQuAD, wanafundishwa na kuchapishwa kwenye mfululizo wa makala za Wikipedia ambazo hujumuisha upendeleo wao wenyewe na pia kuonyesha usawa wa kimataifa halisi. Understanding how training data affects bias in QA systems can inform methods to mitigate inequity.  Tunaendeleza vitu viwili vya maswali kwa ajili ya kufungwa na wazi maswali ya ndani, ambavyo hutumia maswali yasiyo na matatizo ya kuthibitisha mifano ya QA kwa upendeleo. Tunawalisha mfumo wa QA wenye msingi wa elimu tatu kwa maswali yetu na kutathmini majibu ya upendeleo kupitia mitindo. Kwa kutumia mbinu zetu, tunagundua kuwa mifano ya wazi ya QA inaongezea upendeleo zaidi ya wapinzani wao waliofungwa ndani na kupendekeza kwamba upendeleo katika upinzani wa kurejea kwa urahisi zaidi kwa sababu ya uhuru mkubwa wa uchaguzi.', 'sq': 'Modelet që përgjigjen pyetjeve (QA) përdorin sistemet e marrjes dhe lexuesit për të përgjigjur pyetjeve. Reliance on training data by QA systems can amplify or reflect inequity through their responses.  Shumë modele QA, të tillë si ato për grupin e të dhënave SQuAD, janë trajnuar dhe testuar në një nëngrup artikujsh të Wikipedias që kodojnë paragjykimet e tyre dhe gjithashtu riprodhojnë pabarazinë e botës reale. Duke kuptuar se si treinimi i të dhënave ndikon në paragjykimet në sistemet QA mund të informojë metodat për të lehtësuar pabarazinë. Ne zhvillojmë dy grupe pyetjesh për pyetje të mbyllura dhe të hapura respektivisht, të cilat përdorin pyetje të qarta për të hetuar modelet QA për paragjykim. Ne ushqejmë tre sisteme QA bazuar në mësim të thellë me grupet tona të pyetjeve dhe vlerësojmë përgjigjet për paragjykimet nëpërmjet metrikave. Duke përdorur metrikat tona, ne gjejmë se modelet QA në domeni të hapur amplifikojnë paragjykimet më shumë se homologët e tyre në domeni të mbyllur dhe propozojnë që paragjykimet në sipërfaqen e ripërmarrësit më lehtë për shkak të lirisë më të madhe të zgjedhjes.', 'af': "Name Verwantigheid op onderwerp data deur QA stelsels kan onregtigheid versterk of reflekteer deur hul antwoordes. Baie QA-modelles, soos dié vir die SQuAD-datastel, word onderwerp en toets op 'n subgrup van Wikipedia-artikels wat hul eie voorspoedies kodeer en ook reël-wêreld-inekwaliteit herhaal. Om te verstaan hoe onderwerking data beïnvloor bias in QA stelsels kan metodes inlig om onregtigheid te verminder. Ons ontwikkel twee stel vrae vir toegesluit en oop domein vrae respektief, wat gebruik onbepaalde vrae om QA-modele vir bias te probeer. Ons voer drie diep-leer-gebaseerde QA stelsels met ons vraagstellings en evalueer antwoordes vir bias deur die metriek. By die gebruik van ons metries, vind ons dat open-domain QA-modeller versterk biasies meer as hulle toegesluit-domein-kenaars en voorstel dat voorspoedies in die ontvanger-oortjie meer leeg weens groot vryheid van keuse.", 'az': 'Soru cavab vermək (QA) modelləri suallarına cavab vermək üçün alıcı və oxuyan sistemləri kullanır. QA sistemlərinin təhsil məlumatlarının bağlılığı onların cavab vermələri ilə ədalətliyini artıra və ya göstərə bilər. SQuAD veri qutusu üçün bir çox QA modelləri Wikipedia maddələrinin subgruplarında təhsil edilir və təhsil edilir ki, özlərinin önlərini kodlayar və həmçinin həqiqət dünyanın ədalətini təhsil edirlər. QA sistemlərində təhsil məlumatları necə təsir edir ki, ədaləti azaltmaq üçün metodları bilər. Qapılmış və açıq domena sualları üçün iki sorğu inşa edirik ki, QA modellərini bias üçün təşkil etmək üçün münasibətli suallara istifadə edirlər. Biz 3 dərin öyrənmə sistemi QA sistemlərini sorğu qurularımızla besləyirik və metrik vasitəsilə təqsirlərin cavablarını değerləyirik. Metriklərimizi istifadə edirək, açıq-domani QA modelləri onların qapılmış domenin qardaşlarından daha çox təsirlərini artırar və seçim özgürlüyünün səbəbi üçün bu təsirlərin geri almaq üzərində daha asanlıqla təsirlərini təbliğ edirik.', 'bn': 'প্রশ্নের উত্তর (QA) মডেল প্রশ্নের উত্তর দেয়ার জন্য পুনরুদ্ধার এবং পাঠক সিস্টেম ব্যবহার করে। কিউএ সিস্টেমের প্রশিক্ষণের তথ্য বিশ্বাস তাদের প্রতিক্রিয়ার মাধ্যমে বৃদ্ধি বা অসমর্থতা প্রতিফলিত করত অনেক কিউএ মডেল, যেমন এসকুয়াড ডাটাসেটের জন্য প্রশিক্ষণ ও পরীক্ষা করা হয় উইকিপিডিয়া প্রবন্ধের একটি সাবস্কেটে যা তাদের নিজেদের বিরুদ্ধে প্রতি বুঝতে পারলাম কিভাবে প্রশিক্ষণের তথ্য কিউএ সিস্টেমের বিভ্রান্তির উপর প্রভাব ফেলে দেয়া যায়, যাতে নৈত আমরা প্রত্যেক ভাবে বন্ধ এবং খোলা ডোমেইন প্রশ্নের জন্য দুই ধরনের প্রশ্ন তৈরি করি, যা কিউএ মডেল ব্যবহার করে বিভিন্ন প্রশ্নের জন আমরা তিনটি গভীর শিক্ষার ভিত্তিক কিউএ সিস্টেম খাওয়াচ্ছি আমাদের প্রশ্নের সেট দিয়ে এবং মেট্রিকের মাধ্যমে বিভ্রান আমাদের মেট্রিক ব্যবহার করে আমরা দেখতে পাচ্ছি যে উন্মুক্ত ডোমেইন কিউএ মডেল তাদের বন্ধ-ডোমেইন বিরোধীদের চেয়ে বেশী প্রতিযোগিতা বৃদ্ধি করে এবং প্রস্তা', 'am': 'ጥያቄ መልስ የQA ስርዓት ድምፅ በማድረግ ወይም በመስጠታቸው በጥቅነት ማድረግ ይችላል፡፡ ብዙዎች የQA ምሳሌዎች፣ እንደነዚህ SQuAD ዳታ ሰርቨሮች፣ የራሳቸውን ጥያቄ የሆኑትን እና እውነተኛውን ዓለም ትክክል በማድረግ በWikipedia ጽሑፎች ክፍል ተማርተዋል፡፡ የትምህርት ዳታዎች በQA ስርዓቶች ውስጥ የውስደትን ማቀናቀል እንዴት እንዲያስጨንቃቸው እንዳስተውሉ ነው፡፡ ሁለት ጥያቄዎችን ለመዘጋጀት እና ለመክፈት የዶሜን ጥያቄዎች እናስገድዳለን፡፡ የጥልቅ ትምህርት መሆኑን የQA ሲስተማርን በመጠየቃችን ሰርሰናል እና የመተማሪዎችን መልስ እናስተዋልታለን፡፡ ማተሚያዎቻችንን በመጠቀም የክፈት ዲሜইন የQA ሙሉ አካባቢዎችን ከመዘጋጀት የሚጨምር ሁኔታዎችን እና የመለስ ነጻነት ምክንያት በጥቅልነት የሚደረገውን እናሳውቃለን፡፡', 'bs': 'Modeli odgovora na pitanja (QA) koriste povratničke i čitačke sisteme za odgovor na pitanja. Odstupanje na podatke o obuci podataka QA sustava može pojačati ili odražavati nepravednost kroz njihove odgovore. Mnogi QA modeli, kao što su oni za SQuAD dataset, obučeni su i testirani na podskupu Wikipedijskih članaka koji kodiraju sopstvene predrasude i također reproduktuju nepravednost stvarnog svijeta. Razumijeti kako podaci obuke utiču na pristrasnost u QA sistemima mogu obavijestiti metode za smanjenje neispravnosti. Razvijamo dvije vrste pitanja za zatvorene i otvorene pitanja domena, koje koriste ambigutne pitanja za probu modela QA za predrasude. Hranimo tri sistema na dubokom učenju QA sa našim setima pitanja i procjenjujemo odgovore na predrasude putem metrika. Koristeći našu metriku, našli smo da modeli otvorenog domena QA pojačaju predrasude više od njihovih kolega zatvorenih domena i predlažemo da predrasude na površini površine povlačenja lakše zbog veće slobode izbora.', 'ca': "Question answering (QA) models use retriever and reader systems to answer questions.  La confiança en les dades d'entrenament dels sistemes QA pot amplificar o reflexionar la desigualtat a través de les seves respostes. Molts models QA, com els del conjunt de dades SQuAD, són entrenats i testats en un subconjunt d'articles de Wikipedia que codifiquen les seves pròpies tendències i també reprodueixen la desigualtat del món real. Entendre com les dades d'entrenament afecten els bias dels sistemes QA poden informar mètodes per mitigar la desigualtat. Desenvolvem dos conjunts de preguntes per preguntes de domini tancat i obert, respectivament, que utilitzen preguntes ambigues per investigar els models QA per al bias. Ens alimentem tres sistemes de QA basats en aprenentatge profund amb els nostres conjunts de preguntes i evaluem les respostes de bias a través de les mètriques. Utilitzant les nostres mètriques, trobem que els models de QA de domini obert amplifiquen les biases més que els seus homosexuals de domini tancat i proponem que les biases a la superfície del recuperador siguin més fàcilment degut a una llibertat d'elecció més gran.", 'hy': 'Հարցերին պատասխանելու (QA) մոդելները օգտագործում են վերադարձնող և կարդացնող համակարգեր հարցերին պատասխանելու համար: Հաշվի առնելը QA համակարգերի կողմից տեղեկատվության ուսումնասիրության վրա կարող է աճեցնել կամ արտացոլում անհավասարությունը իրենց արձագանքների միջոցով: Շատ QA մոդելներ, ինչպիսիք են SQUADի տվյալների համակարգի մոդելները, սովորեցվում են և փորձարկում են Վիքիփեդիայի հոդվածների մի ենթահամակարգի վրա, որոնք կոդավորում են իրենց սեփական կողմնականությունները և նաև վերարտադրում են իրական աշխարհ Հասկանալ, թե ինչպես են կրթության տվյալները ազդում QA համակարգերի կողմնականության վրա, կարող են տեղեկացնել անհավասարության նվազեցնելու մեթոդները: Մենք զարգանում ենք երկու հարցեր փակ և բաց դաշտային հարցերի համար, որոնք օգտագործում են երկու հարցեր QA մոդելների ուսումնասիրելու համար: Մենք կերակրում ենք երեք խորը ուսումնասիրության հիմնված QA համակարգեր մեր հարցերի համակարգերի միջոցով և գնահատում ենք կողմնականության պատասխանները մետրիկայի միջոցով: Օգտագործելով մեր մետրիկները, մենք հայտնաբերում ենք, որ բաց տիեզերքի QA մոդելները ամպլիֆիացնում են կողմնականությունները ավելի շատ, քան իրենց փակ տիեզերքի հակառակը և առաջարկում են, որ կողմնականությունները վերադարձնող մակերևույթի վրա ավելի հեշտ ընտրության', 'cs': 'Modely zodpovězení otázek (QA) využívají k odpovědi na otázky systémy retriever a čtečky. Spoléhání na výcviková data systémy QA může prostřednictvím jejich reakcí zesílit nebo odrážet nerovnost. Mnoho modelů QA, například modelů pro datovou sadu SQuAD, je trénováno a testováno na podmnožině článků Wikipedie, které kódují své vlastní předsudky a také reprodukují nerovnost v reálném světě. Pochopení toho, jak tréninková data ovlivňují zaujatost v systémech QA, může informovat o metodách ke zmírnění nerovnosti. Vyvíjíme dvě sady otázek pro otázky uzavřené a otevřené domény, které používají nejednoznačné otázky k zkoumání modelů kvality kvality pro zaujatost. Našimi sadami otázek krmíme tři systémy QA založené na hlubokém učení a vyhodnocujeme odpovědi na zaujatost prostřednictvím metrik. Pomocí našich metrik zjišťujeme, že modely QA otevřené domény zesilují předsudky více než jejich protějšky v uzavřené doméně a navrhujeme, že předsudky v retrieveru povrchu snadněji díky větší svobodě volby.', 'et': 'Küsimustele vastamise mudelid kasutavad küsimustele vastamiseks otsija- ja lugejasüsteeme. Kvaliteedi tagamise süsteemide tuginemine koolitusandmetele võib nende vastuste kaudu võimendada või kajastada ebavõrdsust. Paljud kvaliteedi tagamise mudelid, näiteks SQuAD andmekogumi mudelid, on koolitatud ja testitud Vikipeedia artiklite alamhulga alusel, mis kodeerivad nende enda kallakud ja reprodutseerivad ka reaalset ebavõrdsust. Mõistmine, kuidas koolitusandmed mõjutavad kvaliteedi tagamise süsteemide eelarvamusi, võib anda teavet ebavõrdsuse leevendamise meetoditest. Töötame välja kaks küsimuste komplekti vastavalt suletud ja avatud domeeni küsimustele, mis kasutavad ebaselgeid küsimusi kvaliteedi tagamise mudelite uurimiseks erapooletuse suhtes. Me lisame oma küsimustega kolme sügavõppepõhist kvaliteedi tagamise süsteemi ja hindame mõõdikute kaudu vastuseid erapooletuse suhtes. Meie mõõdikute abil leiame, et avatud domeeni kvaliteedi tagamise mudelid võimendavad kallakuid rohkem kui nende suletud domeeni kolleegid ja pakuvad välja, et kallakud retriiveri pinnal kergemini tänu suuremale valikuvabadusele.', 'fi': 'Kysymysten vastausmallit kﾃ､yttﾃ､vﾃ､t hakuja ja lukijoita kysymyksiin vastaamiseen. Luottamus laadunvarmistusjﾃ､rjestelmien koulutustietoihin voi lisﾃ､tﾃ､ tai heijastaa eriarvoisuutta vastauksissaan. Monet laadunvarmistusmallit, kuten SQuAD-aineiston mallit, on koulutettu ja testattu Wikipedia-artikkeleiden alaryhmﾃ､llﾃ､, joka koodaa omia ennakkoluulojaan ja myﾃｶs toistaa reaalimaailman eriarvoisuutta. Sen ymmﾃ､rtﾃ､minen, miten koulutustiedot vaikuttavat laadunvarmistusjﾃ､rjestelmien ennakkoluuloihin, voi auttaa vﾃ､hentﾃ､mﾃ､ﾃ､n eriarvoisuutta. Kehitﾃ､mme kaksi kysymystﾃ､ suljetuille ja avoimille kysymyksille, jotka kﾃ､yttﾃ､vﾃ､t epﾃ､selviﾃ､ kysymyksiﾃ､ kartoittaakseen laadunvarmistusmalleja puolueellisuuden varalta. Syﾃｶtﾃ､mme kysymyksiﾃ､ kolmelle syvﾃ､oppimiseen perustuvalle laadunvarmistusjﾃ､rjestelmﾃ､lle ja arvioimme vastauksia vinoutumisen varalta mittarien avulla. Mittareidemme avulla havaitsemme, ettﾃ､ avoimen verkkotunnuksen laadunvarmistusmallit vahvistavat vﾃ､ﾃ､ristymiﾃ､ enemmﾃ､n kuin suljetun verkkotunnuksen vastineet ja ehdottavat, ettﾃ､ vﾃ､ﾃ､ristymﾃ､t noutajan pinnalla helpommin johtuen suuremmasta valinnanvapaudesta.', 'jv': 'Name Lakan nganggo data nggawe barang kelas Daftar model Tulung ngerasai perangkat kuwi nggambar dadi kanggo biasane ning sistem KA iso nggawe barang nggawe barang kanggo mbelikasi layang. We create 2 set of question for Clock and open domain question responsibly, that use ambguent question to likely qA modes for bias. Awak dhéwé éntuk telu sistem sing basa-ingkang dipun-ingkang kelas barang awak dhéwé kuwi nggawe barang nggambar barang maning. Ngawe gunakake meter, kita bukane open-domain qA model amplify bias liyane karo hal-domain count nggawe lan supoyo bias kanggo awak dhéwé iso nggawe aturan tambah kebebasan perusahaan langgar-sistem sing luwih akeh lani kanggo kebebasané perusahaan winih dhéwé.', 'sk': 'Modeli za odgovarjanje na vprašanja (QA) uporabljajo sisteme za iskanje in branje za odgovore na vprašanja. Zanašanje na podatke o usposabljanju s strani sistemov za zagotavljanje kakovosti lahko poveča ali odraža neenakost z njihovimi odzivi. Mnogi modeli kakovosti, kot so modeli za nabor podatkov SQuAD, so usposobljeni in testirani na podskupini Wikipedijskih člankov, ki kodirajo njihove pristranskosti in tudi reproducirajo neenakost v realnem svetu. Razumevanje, kako podatki o usposabljanju vplivajo na pristranskost v sistemih za zagotavljanje kakovosti, lahko upošteva metode za ublažitev neenakosti. Razvijamo dva sklopa vprašanj za zaprta in odprta vprašanja, ki uporabljata dvoumna vprašanja za proučevanje pristranskosti modelov kakovosti. Z našimi nabori vprašanj hranimo tri sisteme za zagotavljanje kakovosti, ki temeljijo na globokem učenju, in ocenjujemo odgovore na pristranskost prek meritev. Z uporabo naših meritev ugotavljamo, da modeli odprtega domena kakovosti bolj povečujejo pristranske pristranske kot njihove zaprte domene in predlagamo, da pristranske na površini iskalnika lažje zaradi večje svobode izbire.', 'he': 'דוגמנים לענות על שאלות (QA) משתמשים במערכות מערכות מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מע תלויה במידע האימוני על ידי מערכות QA יכולות להגדיל או לשקף אי-שוויון דרך התגובות שלהם. דוגמנים רבים של QA, כמו אלה עבור קבוצת מידע SQuAD, מאומנים ומבחנים על תחת קבוצת מאמרים בוויקיפדיה שמקודדים את ההתמחות שלהם, וגם משחזרים את אי-שוויון בעולם האמיתי. Understanding how training data affects bias in QA systems can inform methods to mitigate inequity.  אנחנו מפתחים שתי סדרות של שאלות לשאלות סגורות ופתוחות בתחום, בהתאם, אשר משתמשות בשאלות סביבות כדי לחקור דוגמנים QA למיוחד. אנחנו מאכילים שלושה מערכות QA מבוססות על למידה עמוקה עם קבוצות השאלות שלנו ולעריך תגובות למחיות דרך המטריות. בשימוש במטריקה שלנו, אנו מוצאים שדוגמנים QA של שטח פתוח מגבירים את ההתמחות יותר מאשר שותפיהם של שטח סגור ולהציע שהתמחות בשטח המחזיר בקלות יותר בגלל חופש בחירה גדול יותר.', 'ha': "Socket error code ConnectionTimeout Mutarin da za'a sami data na tsari da QA na iya ƙara ko kuma zai yi rabo da ɓarna a bayan majiɓincinsu. masu yawa na QA misãlai, kamar waɗand a ke tsaron SQuAD data, an karanta kuma aka jarraba a ƙarƙashin makala na Wikimedia wanda ke kodi sigarinsu da kuma yana dubuɗe masu daidaita duniya. Ana gane yadda data na ƙidãya za'a yi amfani da ɓangare cikin QA's system, za'a iya sanar da shiryoyin su cire kasancẽwa. Tuna buɗe sau biyu masu tambayi ga aka rufe da kuma aka buɗe masu tambayar kwamfyuta, wanda ke amfani da su masu sauna wa'anar QA dõmin ya jarraba misalin QA dõmin ya yi kuskure. Ana ciyar da QA's system uku masu ƙaranci da ke samun tambayarinmu kuma munã qiimata majiɓintan sauri a kan misalin ta. Using our metrics, we find that open-domain QA models amplify biases more than their closed-domain counterparts and propose that biases in the retriever surface more readily due to greater freedom of choice.", 'bo': 'འདྲི་ཚིག་ལན་གསལ(QA)མ་དཔེ་གཞུང་གིས་ལྟ་ཀློག་བྱེད་པ་དང་ལྟ་ཀློག་བྱེད་མི་ལག་ལེན་འཐབ་པ་ཡིན། QA་རིམ་ལག་གི་སྒེར་གྱི་གཙོ་སློང་གི་གནས་ཚུལ་དང་མཐུན་རྐྱེན་ཚད་ལ་ཆེ་རུ་གཏོང་དང་འགྱུར་བ་ཡིན། QA མ་དབྱིབས་མང་པོ་ཞིག་ཡིན། དཔེར་ན། SQuAD གནད་སྡུད་ཆ་འཕྲིན་གྱི་ནང་དུ་གཞི་སྒྲིག་ནས་བརྟག་ཞིབ་བྱེད་ཀྱི་ཡོད། QA་མ་ལག་གི་དབྱིབས་གཙོ་སློང་ཆ་ཡིག་ཆ་གིས་ཇི་ལྟར་འགྱུར་བའི་ནད་ཅིག་ནི་རྒྱུན་ལྡན་ཞིག We develop two sets of questions for closed and open domain questions respectively, which use ambiguous questions to probe QA models for bias. We feed three deep-learning-based QA systems with our question sets and evaluate responses for bias via the metrics. Using our metrics, we find that open-domain QA models amplify biases more than their closed-domain counterparts and propose that biases in the retriever surface more readily due to greater freedom of choice.'}
{'en': 'Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer', 'ar': 'التدريب المسبق على المحاذاة ثنائية اللغة من أجل النقل عبر اللغات بدون طلقة', 'es': 'Entrenamiento previo de alineación bilingüe para la transferencia interlingüística de tiro cero', 'pt': 'Pré-Treinamento de Alinhamento Bilíngue para Transferência Multilíngue Zero-Shot', 'fr': "Formation préalable à l'alignement bilingue pour le transfert multilingue Zero-Shot", 'ja': 'ゼロショットクロスリンガル転送のためのバイリンガルアライメント事前トレーニング', 'zh': '零次跨语移者双语准预训练', 'hi': 'शून्य-शॉट क्रॉस-लिंगुअल स्थानांतरण के लिए द्विभाषी संरेखण पूर्व-प्रशिक्षण', 'ru': 'Предварительное обучение двуязычному выравниванию для кросс-лингвальной передачи с нулевым выстрелом', 'ga': 'Réamh-Oiliúint Ailínithe Dátheangach le haghaidh Aistriú Trastheangach ar Neamh-Shot', 'ka': 'ბილუნგიური დასწორება წინ გასწორება Zero-Shot Cross-Lingual Transfer- ისთვის', 'el': 'Προεκπαίδευση δίγλωσσης ευθυγράμμισης για τη διαγώνια μεταφορά μηδενικού πυροβολισμού', 'hu': 'Kétnyelvű igazítás előkészítő képzés Zero-Shot többnyelvű transzferhez', 'kk': 'Нөл- түрлі тілікті біріктіру үшін екі түрлендіру алдындағы оқыту', 'it': "Pre-training sull'allineamento bilingue per il trasferimento cross-linguale a colpo zero", 'lt': 'Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer', 'mt': 'Taħriġ ta’ Qabel ta’ Allinjament Bilinguali għal Trasferiment Cross-Lingwali Żero-Shot', 'mk': 'Преобука за двојно израмнување за префрлање низ низ јазик', 'no': 'Førehandsvising for null-Shot krysslingsoverføring', 'pl': 'Dwujęzyczne przygotowanie wstępne do przesyłania dwujęzycznego Zero-Shot Cross-Lingual Transfer', 'ro': 'Pregătire de aliniere bilingvă pentru transferul translingvistic Zero-Shot', 'sr': 'Pre obuke za prebacivanje nulo-pogođenog krstoLingualnog prebacivanja', 'si': 'සීරෝවෙඩි වෙඩි ක්\u200dරොස් ලින්ගුවාල් ස්ථානය සඳහා ප්\u200dරධානය', 'ms': 'Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer', 'sv': 'Tvåspråkig justering Pre-Training för Zero-Shot tvärspråklig överföring', 'ta': 'பூரோ- ஷாட் கிராஸ் மாற்றுதலுக்கான பைலிங்கல் ஒழுங்கு முன் பயிற்சி', 'ml': 'സെറോ- ഷോട്ട് ക്രോസ്- ലിങ്ഗുവല്\u200d മാറ്റുന്നതിനുള്ള ബൈലിങ്കുള്ള ചേര്\u200dന്നിരിക്കുന്നതിനുള്ള പ്രിന', 'mn': 'Зөл-шүдний давхар хэлбэрийн давхарлалтын хоёр давхарлалтын өмнө дасгал хөдөлгөөн', 'ur': 'صفر-شٹ کرس-لینگئال ٹرانسفر کے لئے دوئینگ الیگن پیش ترینینگ', 'so': 'Waxbarashada iskuulka qoraalka ah', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'nl': 'Voortraining voor tweetalige uitlijning voor Zero-Shot Cross-Lingual Transfer', 'da': 'Tosproget tilpasning Pre-Training for Zero-Shot tværsproglig overførsel', 'hr': 'Prevježba za prebacivanje nulo-pucnjave preko linije', 'bg': 'Предварително обучение за двуезично подравняване за междулингвен трансфер с нулев изстрел', 'id': 'Penyesuaian Bilingual Pre-Training untuk Transfer Lingua Sementara Zero-Shot', 'de': 'Zweisprachiges Alignment Pre-Training für Zero-Shot Cross-Lingual Transfer', 'sw': 'Ufundisho wa Ujumbe wa Kiingereza kwa ajili ya Uhamiaji wa Msalama wa Kupiga risasi', 'ko': '영사 크로스 언어 이동의 이중 언어 정렬 훈련', 'tr': 'Zero-Shot Çapraz Hat Transferi üçin Çapraz Ýagtylamak Öňki', 'fa': 'پیش\u200cآموزشی پیش\u200cآموزشی دوگانه برای انتقال کراس\u200cلینگ\u200cهای صفر', 'sq': 'Përgatitje për përcaktimin dygjuhësor për transferimin ndërgjuhësor zero-shot', 'hy': 'Երկլեզվային հարմարեցման նախապատրաստումը զրո-կրակի միջլեզվային փոխանցման համար', 'am': 'undo-type', 'bn': 'জিরো- শোট ক্রস- লিঙ্গুয়াল ট্রান্সফারের জন্য বৈলিঙ্গুয়েল প্রতিযোগিতার পূর্ব প্রশিক্ষণ', 'af': 'Tweede oplyn voor- oefening vir Zero- Shot Kruis- Linguaal Oordrag', 'az': 'Sıfır-vuruş Çift-Çift Transferi üçün İkinci Tərfləmə Önceki Tərfləmə', 'bs': 'Prevježba za prebacivanje nulo-pucnjave preko linije', 'ca': "Preentrenament bilingüe d'allinjament per a transferència de llengua cruzada sense dispars", 'fi': 'Kaksikielinen linjaus Pre-Training for Zero-Shot Cross-Lingual Transfer', 'et': 'Kahekeelse joondamise eelkoolitus Zero-Shot keeleülese ülekande jaoks', 'cs': 'Předškolení dvojjazyčného zarovnání pro Zero-Shot Cross-Lingual Transfer', 'sk': 'Predusposabljanje dvojezične poravnave za medjezikovni prenos brez strela', 'he': 'אימון מראש בהתאם מיליוני עבור העברת לינגלית ללא יריות', 'jv': 'Bilingual Align Preview-Learning kanggo 0-shot', 'ha': 'Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer', 'bo': 'Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer'}
{'en': 'Multilingual pre-trained models have achieved remarkable performance on cross-lingual transfer learning. Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the ', 'ar': 'حققت النماذج متعددة اللغات المدربة مسبقًا أداءً رائعًا في تعلم النقل عبر اللغات. تم تدريب بعض النماذج متعددة اللغات مثل mBERT مسبقًا على مجموعات غير مصنفة ، وبالتالي قد لا يتم تنسيق حفلات الزفاف للغات المختلفة في النماذج بشكل جيد للغاية. في هذه الورقة ، نهدف إلى تحسين أداء النقل متعدد اللغات من خلال اقتراح مهمة ما قبل التدريب تسمى نموذج محاذاة تبادل الكلمات (WEAM) ، والتي تستخدم معلومات المحاذاة الإحصائية كمعرفة مسبقة لتوجيه الكلمات متعددة اللغات تنبؤ. نقوم بتقييم نموذجنا على مهمة فهم قراءة الآلة متعددة اللغات MLQA ومهمة واجهة اللغة الطبيعية XNLI. تظهر النتائج أن WEAM يمكنها تحسين أداء التسديدة الصفرية بشكل ملحوظ.', 'pt': 'Modelos pré-treinados multilíngues alcançaram um desempenho notável na aprendizagem de transferência multilíngue. Alguns modelos multilíngues, como o mBERT, foram pré-treinados em corpora não rotulados, portanto, a incorporação de diferentes idiomas nos modelos pode não estar muito bem alinhada. Neste artigo, visamos melhorar o desempenho da transferência multilíngue de tiro zero, propondo uma tarefa de pré-treinamento chamada Word-Exchange Aligning Model (WEAM), que usa as informações de alinhamento estatístico como o conhecimento prévio para guiar palavras multilíngues. predição. Avaliamos nosso modelo na tarefa de compreensão de leitura de máquina multilíngue MLQA e na tarefa de interface de linguagem natural XNLI. Os resultados mostram que o WEAM pode melhorar significativamente o desempenho do tiro zero.', 'es': 'Los modelos multilingües preentrenados han logrado un rendimiento notable en el aprendizaje de transferencia multilingüe. Algunos modelos multilingües, como mBert, se han entrenado previamente en corpus sin etiqueta, por lo que las incorporaciones de diferentes idiomas en los modelos pueden no estar muy bien alineadas. En este artículo, nuestro objetivo es mejorar el rendimiento de la transferencia multilingüe de tiro cero mediante la propuesta de una tarea de preentrenamiento llamada Modelo de alineación de intercambio de palabras (WEAM), que utiliza la información de alineación estadística como conocimiento previo para guiar la predicción de palabras en varios idiomas. Evaluamos nuestro modelo en la tarea de comprensión de lectura automática multilingüe MLQA y la tarea de interfaz de lenguaje natural XNLI. Los resultados muestran que WEAM puede mejorar significativamente el rendimiento de tiro cero.', 'fr': "Les modèles pré-entraînés multilingues ont obtenu des performances remarquables en matière d'apprentissage par transfert multilingue. Certains modèles multilingues, tels que mBerT, ont été pré-formés sur des corpus non étiquetés. Par conséquent, l'intégration de différentes langues dans les modèles peut ne pas être très bien alignée. Dans cet article, nous visons à améliorer les performances de transfert interlinguistique zero-shot en proposant une tâche de pré-apprentissage nommée Word-Exchange Aligning Model (WEAM), qui utilise les informations d'alignement statistiques comme connaissances préalables pour guider la prédiction de mots interlinguaux. Nous évaluons notre modèle sur la tâche de compréhension de lecture automatique multilingue MLQA et la tâche d'interface en langage naturel XNLI. Les résultats montrent que WEAM peut améliorer de manière significative les performances de tir zéro.", 'ja': '多言語事前トレーニングモデルは、クロスリンガル転送学習で卓越したパフォーマンスを達成しています。mBERTなどの一部の多言語モデルは、ラベル付けされていないコーパで事前にトレーニングされているため、モデル内の異なる言語の埋め込みはあまり整合していない可能性があります。本稿では，統計的アライメント情報を事前知識として用いて，クロスリンガルワード予測を導く， Word - Exchange Aligning Model (WEAM)という事前トレーニングタスクを提案することで，ゼロショットのクロスリンガル転送性能の向上を目指す．多言語機械読解タスクMLQAと自然言語インターフェースタスクXNLIのモデルを評価します。その結果、WEAMはゼロショット性能を大幅に向上させることができることがわかりました。', 'hi': 'बहुभाषी पूर्व-प्रशिक्षित मॉडल ने क्रॉस-लिंगुअल ट्रांसफर लर्निंग पर उल्लेखनीय प्रदर्शन हासिल किया है। MBERT जैसे कुछ बहुभाषी मॉडल, बिना लेबल वाले कॉर्पोरेट पर पूर्व-प्रशिक्षित किए गए हैं, इसलिए मॉडल में विभिन्न भाषाओं के एम्बेडिंग को बहुत अच्छी तरह से संरेखित नहीं किया जा सकता है। इस पेपर में, हम वर्ड-एक्सचेंज एलाइनिंग मॉडल (WEAM) नामक एक पूर्व-प्रशिक्षण कार्य का प्रस्ताव करके शून्य-शॉट क्रॉस-लिंगुअल ट्रांसफर प्रदर्शन में सुधार करने का लक्ष्य रखते हैं, जो क्रॉस-लिंगुअल शब्द भविष्यवाणी का मार्गदर्शन करने के लिए पूर्व ज्ञान के रूप में सांख्यिकीय संरेखण जानकारी का उपयोग करता है। हम बहुभाषी मशीन पढ़ने की समझ कार्य MLQA और प्राकृतिक भाषा इंटरफ़ेस कार्य XNLI पर हमारे मॉडल का मूल्यांकन करते हैं। परिणाम बताते हैं कि WEAM काफी शून्य शॉट प्रदर्शन में सुधार कर सकते हैं.', 'zh': '多言预训模,跨语迁学著。 多语言模(如mBERT)已豫教于未识之语料库,故其嵌之不同者或非善齐也。 本文之中,指Word-Exchange Aligning Model(WEAM)之预训练任务以重零次跨言移性,当用计齐信息为先验知以导跨语单词占。 多言机器读解事MLQA与自然语言界面XNLI评模样。 结果表明,WEAM可以显零射性。', 'ru': 'Многоязычные модели, прошедшие предварительную подготовку, добились замечательных результатов в области межязыкового трансферного обучения. Некоторые многоязычные модели, такие как mBERT, были предварительно обучены на немеченных телах, поэтому вложения различных языков в модели могут быть не очень хорошо выровнены. В этом документе мы стремимся улучшить производительность кросс-лингвистической передачи с нулевым выстрелом, предлагая предварительную учебную задачу под названием «Модель выравнивания обмена словами» (WEAM), которая использует статистическую информацию о выравнивании в качестве предварительного знания для руководства прогнозированием кросс-лингвистических слов. Мы оцениваем нашу модель на многоязычной задаче понимания машинного чтения MLQA и задаче интерфейса естественного языка XNLI. Результаты показывают, что WEAM может значительно улучшить производительность нулевого выстрела.', 'ga': 'Tá feidhmíocht iontach bainte amach ag samhlacha réamhoilte ilteangacha ar fhoghlaim aistrithe tras-teanga. Tá roinnt samhlacha ilteangacha ar nós mBERT, réamh-oilte ar chorpora neamhlipéadaithe, mar sin d’fhéadfadh sé nach mbeadh leabú teangacha éagsúla sna samhlacha ailínithe go han-mhaith. Sa pháipéar seo, tá sé mar aidhm againn feabhas a chur ar fheidhmíocht aistrithe tras-teanga nialasach trí thasc réamh-oiliúna a mholadh darb ainm Samhail Ailínithe Word-Exchange (WEAM), a úsáideann an fhaisnéis ailínithe staitistiúil mar an t-eolas roimh ré chun focal tras-teangach a threorú. réamhinsint. Déanaimid measúnú ar ár múnla ar thasc ilteangach léamh tuisceana meaisín MLQA agus tasc comhéadan teanga nádúrtha XNLI. Léiríonn na torthaí gur féidir le WEAM feabhas suntasach a dhéanamh ar fheidhmíocht náid lámhaigh.', 'ka': 'მრავალენგური წინატრიქტირებული მოდელები გავაკეთეთ შესანიშვნელოვანი მრავალენგური ტრანსტრიქტის სწავლებაზე. რამდენიმე მრავალენგური მოდელები, როგორც mBERT, უცნობილი კოპორაზე უფრო უცნობილი მოდელეები იყო, რადგან განსხვავებული ენების მოდელში შეიძლება არ უფრო მსგავსია. ამ დოკუნში ჩვენ უნდა გავაკეთოთ ნულ სტრიქტურის კრესიენგური ტრანსტრიქტურის გამოსახულებას, რომელიც გამოიყენება სტრიქტიკური მხარდაპირებული სიტყვების მოდელი (WEAM) სტრიქტიკური მხარდაპირება როგორც წინა ჩვენ მრავალენგური მაქსინის კითხვის მოდელზე გავამუშავებთ MLQA და ნაირთი ენგური ინტერფექტის დავალება XNLI. შედეგები ჩვენებენ, რომ WEAM შეუძლია მნიშვნელოვანად უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ', 'hu': 'A többnyelvű előképzett modellek figyelemreméltó teljesítményt értek el a nyelvek közötti transzfer tanulás terén. Néhány többnyelvű modellt, mint például az mBERT, előzetesen képzettek a címke nélküli corporákra, ezért előfordulhat, hogy a különböző nyelvek beágyazása a modellekbe nem igazítható túl jól. Jelen tanulmány célja, hogy javítsuk a zéró nyelvű transzfer teljesítményét azzal, hogy javasoljuk a Word-Exchange Aligning Model (WEAM) elnevezésű előképzési feladatot, amely a statisztikai igazítási információkat használja előzetes tudásként a keresztnyelvű szó előrejelzéséhez. Modellünket értékeljük a többnyelvű gépi olvasásértési feladat MLQA és természetes nyelvű interfész feladat XNLI. Az eredmények azt mutatják, hogy a WEAM jelentősen javíthatja a zero-shot teljesítményt.', 'el': 'Τα πολύγλωσσα προ-εκπαιδευμένα μοντέλα έχουν επιτύχει αξιοσημείωτες επιδόσεις στην εκμάθηση διασυνοριακής μεταφοράς. Ορισμένα πολύγλωσσα μοντέλα, όπως το mBERT, έχουν προ-εκπαιδευτεί σε μη επισημασμένα σώματα, επομένως οι ενσωμάτωση διαφορετικών γλωσσών στα μοντέλα μπορεί να μην ευθυγραμμίζονται πολύ καλά. Στην παρούσα εργασία, στόχος μας είναι να βελτιώσουμε την απόδοση της διασυνοριακής μεταφοράς μηδενικού πυροβολισμού προτείνοντας μια εργασία προεκπαίδευσης με το όνομα Μοντέλο ευθυγράμμισης ανταλλαγής λέξεων (το οποίο χρησιμοποιεί τις στατιστικές πληροφορίες ευθυγράμμισης ως τις προηγούμενες γνώσεις για να καθοδηγήσει την πρόβλεψη γλωσσών. Αξιολογούμε το μοντέλο μας για την πολύγλωσση εργασία κατανόησης ανάγνωσης μηχανών και την εργασία διεπαφής φυσικής γλώσσας. Τα αποτελέσματα δείχνουν ότι μπορεί να βελτιώσει σημαντικά την απόδοση μηδενικής βολής.', 'it': "I modelli plurilingui pre-formati hanno raggiunto notevoli prestazioni nell'apprendimento translinguale di trasferimento. Alcuni modelli multilingue come mBERT, sono stati pre-addestrati su corpora non etichettati, quindi le incorporazioni di lingue diverse nei modelli potrebbero non essere allineate molto bene. In questo articolo, miriamo a migliorare le prestazioni di trasferimento cross-lingual zero-shot proponendo un compito pre-training chiamato Word-Exchange Aligning Model (WEAM), che utilizza le informazioni statistiche di allineamento come conoscenza preliminare per guidare la previsione cross-lingual word prediction. Valutiamo il nostro modello sul compito multilingue di comprensione della lettura automatica MLQA e sull'interfaccia del linguaggio naturale XNLI. I risultati mostrano che WEAM può migliorare significativamente le prestazioni zero-shot.", 'lt': 'Daugiakalbiai iš anksto parengti modeliai pasiekė nemažai rezultatų tarpkalbinio mokymosi srityje. Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the models may not be aligned very well.  Šiame dokumente siekiame pagerinti nulinius tarpkalbinio perdavimo rezultatus siūlant parengiamąjį mokymą, vadinamą žodžių mainų derinimo modeliu (WEAM), kuriame kaip išankstines žinias naudojama statistinė suderinimo informacija tarpkalbiniam žodžių prognozavimui pagrįsti. Vertiname savo model į daugiakalbio mašinų skaitymo supratimo užduotis MLQA ir gamtinės kalbos sąsajos užduotis XNLI. Iš rezultatų matyti, kad WEAM gali gerokai pagerinti nulinio nuotraukos rezultatus.', 'ms': 'Multilingual pre-trained models have achieved remarkable performance on cross-lingual transfer learning.  Beberapa model berbilang bahasa seperti mBERT, telah dilatih-dilatih pada korpra tidak berlebihan, oleh itu penerbangan bahasa berbeza dalam model mungkin tidak disesuaikan dengan baik. Dalam kertas ini, kami bertujuan untuk meningkatkan prestasi pemindahan saling bahasa dengan menembak sifar dengan melamar tugas praselatihan bernama Model Penjajaran Pertukaran Perkataan (WEAM), yang menggunakan maklumat penyesuaian statistik sebagai pengetahuan terdahulu untuk memimpin ramalan perkataan saling bahasa. Kami menilai model kami pada tugas pemahaman mesin berbilang bahasa MLQA dan tugas antaramuka bahasa semulajadi XNLI. Hasilnya menunjukkan bahawa WEAM boleh meningkatkan prestasi tembakan sifar secara signifikan.', 'kk': 'Бірнеше тілді алдын- ала оқылған үлгілер бірнеше тілді аудару оқыту үшін белгілі істеу жеткізді. МЕБЕРТ секілді көп тілді үлгілер алдын- ала жазылмаған корпорада оқылған, сондықтан үлгілерде басқа тілдерді ендіру керек болуы мүмкін. Бұл қағазда, біз нөл тілдерді біртінші аудару үшін, Word Exchange бағыттау үлгісі (WEAM) деген алдын- оқыту тапсырмасын ұсынып, статистикалық түзету мәліметін бірінші мәлімет ретінде қолданады. Біз бірнеше тіл интерфейсінің көптілік машинаны оқу тапсырмасының MLQA және табиғи тіл интерфейсінің XNLI тапсырмасының үлгісін бағалаймыз. Нәтижелер WEAM нәтижесінің нәтижесін жасай алады.', 'mt': 'Multilingual pre-trained models have achieved remarkable performance on cross-lingual transfer learning.  Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the models may not be aligned very well.  In this paper, we aim to improve the zero-shot cross-lingual transfer performance by proposing a pre-training task named Word-Exchange Aligning Model (WEAM), which uses the statistical alignment information as the prior knowledge to guide cross-lingual word prediction.  We evaluate our model on multilingual machine reading comprehension task MLQA and natural language interface task XNLI.  Ir-riżultati juru li l-WEAM jista’ jtejjeb b’mod sinifikanti l-prestazzjoni b’zero shot.', 'mk': 'Мултијазичните предобучени модели постигнаа извонредни резултати во меѓујазичното префрлање на учењето. Некои мултијазични модели, како што е mBERT, беа преобучени на неозначени корпора, затоа вградувањата на различни јазици во моделите можеби не се многу добро прилагодени. Во овој документ, ние имаме за цел подобрување на резултатите на нула-снимка преку преку јазички трансфер со предложување на предобука задача наречена Word-Exchange Aligning Model (WEAM), која ги користи статистичките информации за прилагодување како претходно знаење за водење на преку-јазичките предвидувања на зб Ние го проценуваме нашиот модел на мултијазичната машинска задача за читање разбирање MLQA и природната задача на јазички интерфејс XNLI. The results show that WEAM can significantly improve the zero-shot performance.', 'pl': 'Wielojęzyczne modele wstępnie przeszkolone osiągnęły niezwykłą wydajność w nauce transferowej między językami. Niektóre wielojęzyczne modele, takie jak mBERT, zostały wstępnie przeszkolone na korpusach nieoznakowanych, dlatego osadzenie różnych języków w modelach może nie być zbyt dobrze dopasowane. W niniejszym artykule chcemy poprawić efektywność transferu między językami zerowymi poprzez zaproponowanie zadania przedszkoleniowego o nazwie Word-Exchange Aligning Model (WEAM), które wykorzystuje statystyczne informacje dotyczące dostosowania jako wiedzę wcześniejszą do prognozowania słów między językami. Oceniamy nasz model na wielojęzycznym zadaniu rozumienia odczytu maszynowego MLQA i zadaniu interfejsu języka naturalnego XNLI. Wyniki pokazują, że WEAM może znacznie poprawić wydajność zerowych strzałów.', 'mn': 'Ихэнх хэл дээр сургалтын өмнө сургалтын загварууд хэл дээр шилжүүлэх сургалтын тухай гайхалтай үйл ажиллагааг гаргасан. МБЕРТ зэрэг олон хэл загварууд нь бичигдэггүй корпора дээр урьд суралцагдсан. Тиймээс загваруудын өөр хэл үүсгэх нь маш сайн зохицуулагддаггүй. Энэ цаасан дээр бид "Word-Exchange Aligning Model" (WEAM) нэртэй урд сургалтын үйл ажиллагааг ашиглаж, хэлний хэлний тодорхойлолтын өмнөх мэдлэг болгон статистикийн тодорхойлолтын мэдээллийг ашигладаг. Бид олон хэл унших машины загварыг MLQA болон байгалийн хэл интерфейс ажлын тухай үнэлдэг. Үүний үр дүнд WEAM-н тэгш шалгалтын үйл ажиллагааг үнэхээр сайжруулж чадна.', 'no': 'Fleirspråksprøvde modeller har oppnådd merkelige utviklingar ved læring av krysspråk overføring. Nokre fleirspråk modeller som mBERT har vært forelært på ulike korpora, derfor innbygginga av ulike språk i modelane kan ikkje vera veldig rett. I denne papiret må vi forbedra utviklinga av null-shot krysspråk ved å foreslå eit føreøvingsoppgåve med namn Word-Exchange Aligning Model (WEAM), som brukar statistiske innstillingsinformasjon som førre kunnskap for å hjelpa framtidspunkt på krysspråk ordforhåndsvising. Vi evaluerer modellen vårt på fleirspråksmaskinen som lesar forståelse av oppgåve MLQA og naturleg språksgrensesnitt XNLI. Resultatet viser at WEAM kan betydelig forbedra utviklinga med nullsatt.', 'si': 'ගොඩක් භාෂාවක් ප්\u200dරධානය කරලා තියෙන්න පුළුවන් විදිහට පුළුවන් විදිහට පුළුවන් විදිහට වි මෙබෙර්ට් වලින් විශේෂ භාෂාවක් මොඩේල් වලින් මොඩේල් වලින් වෙනස් භාෂාවක් සම්පූර්ණය කරලා තියෙන්නේ නැහැ කොර්පෝ මේ පැත්තේ, අපි ඉලක්කම් කරන්නේ ශූර්ය-ශෝට් ක්\u200dරිස් භාෂාව ප්\u200dරවර්තනය වැඩ කරන්න ප්\u200dරශ්නයක් විතරයි, වර්ඩ් එක්ස්චින් අලිගින් මොඩේල් (WEAM) කිරීම අපි ගොඩක් භාෂාත්මක යන්ත්\u200dරය කියවන්නේ අපේ මොඩල් විශ්වාස කරන්නේ MLQA වැඩේ සහ ස්වභාවික භාෂාත්මක වැඩ X ප්\u200dරතිචාරය පෙන්වන්නේ WEAM විශේෂයෙන් ශූන්ය වැඩ කරන්න පුළුවන් කියලා.', 'so': 'Tusaale luuqado badan oo la tababariyey waxay sameeyeen bandhig aad u wanaagsan oo ku saabsan barashada luuqadaha kala duwan. Tusaale luuqado kala duduwan, sida mBERT, waxaa horay loo tababaray shirkad aan la aqoon, sidaas darteed sameynta noocyada kala duwan loogama dhigi karo si fiican. Qoraalkan waxaynu ku talo galaynaa inuu hago joojinta luqada ah oo nuurka lagu dhufto, si aan u soo jeedno shaqada hore oo lagu qoro hadal-Exchange Isku-gnigning Model (WEAM), kaasoo isticmaalaya macluumaadka sawirida sida aqoonta hore oo uu ku hago wax u sii sheego hadalka luuqadaha kala duwan. Tusaalkayaga waxaan ku qiimeynayaa mashiinka luuqadaha kala duduwan oo akhrinaya shaqada hoose ee MLQA iyo shaqada Interfacka luuqada ee dabiiciga ah XNLI. Abaalku waxay muuqataa in WEAM si muhiim ah u hagaajin karo sameynta nooca ah.', 'ml': 'മുമ്പ് പരിശീലിക്കപ്പെട്ട മോഡലുകള്\u200d ക്രിസ്ലിങ്ങ് മാറ്റങ്ങള്\u200d പഠിക്കുന്നതില്\u200d വിശിഷ്ടമായ പ്രദര്\u200dശനം നേ MBERT പോലുള്ള പല ഭാഷകങ്ങളുടെ മാതൃകങ്ങള്\u200d മുന്\u200dപ് പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു. അതുകൊണ്ട് മാതൃകങ്ങളിലെ വ്യത്യസ്ത ഭാഷകങ്ങളുടെ അഭി ഈ പത്രത്തില്\u200d നമ്മള്\u200d ശൂന്യമായി വെടിവെക്കാന്\u200d ഉദ്ദേശിക്കുന്നു. വാക്ക്-എക്സ്ചെന്റ് എക്സ്മെന്റ് അനന്തരം മോഡേല്\u200d എന്ന ഒരു പ്രദര്\u200dശിപ്പിക്കുന്നതിനാല്\u200d പൂര്\u200dണ്ണമായി വെടി ഞങ്ങള്\u200d പല ഭാഷ യന്ത്രത്തിലുള്ള മോഡല്\u200d വായിക്കുന്നതിനെക്കുറിച്ച് വിലയിക്കുന്നതിനെക്കുറിച്ച് നമ്മുടെ മാതൃകയെ  The results show that WEAM can significantly improve the zero-shot performance.', 'ta': 'பல மொழிகள் முன் பயிற்சி முன்பு மாதிரிகள் பல மொழி மொழிமொழி மாற்றும் கற்றத்தில் செயல்பாட்டை அடைந்துள்ளது. Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the models may not be aligned very well.  இந்த காக்கியத்தில், நாம் பூஜ்ஜியத்தை மேம்படுத்த வேண்டும் முன் பயிற்சி முறைமையை மாற்ற வேண்டும் வார்த்தை - Exchange Aligning Model (WEAM) என்று பரிந்துரைக்கிறோம். இது புள்ளிவ MLQA மற்றும் இயல்பான மொழி இடைமுகப்பு பணியை எக்ஸ்என்லியில் நாம் பல மொழி இயந்திரத்தை படிக்கும் பாதிப்பு மாதிரியை  முடிவுகள் WEAM பூஜ்ஜியத்தை மேம்படுத்த முடியும் என்பதை காட்டுகிறது.', 'ur': 'بہت سی زبان کی پیش آموزش کی موڈلیاں کرسی زبان ترافرست کی تعلیم کے بارے میں بہت اچھی فعالیت پہنچ چکی ہیں۔ کئی بہت سی زبان مدل جیسے mBERT، غیر قابل تحصیل کی گئی ہے، اس لئے مدل میں مختلف زبانوں کی پیدائش بہت اچھی طرح نہیں کی جاتی۔ اس کاغذ میں ہم چاہتے ہیں کہ صفر-شٹ کرس-زبان ترنسیٹ فعالیت کو اضافہ کریں، اس کے ذریعہ سے Word-Exchange Aligning Model (WEAM) کے نام سے ایک پیش آموزش کام کی پیش آموزش کے ذریعہ سے استعمال کریں، جس نے مقررہ تعمیر معلومات کو پہلے علم کے طور پر استعمال کرتا ہے کہ ہم multilingual machine reading task MLQA اور natural language interface task XNLI پر ہماری مدل کا ارزش کرتے ہیں. نتیجے دکھاتے ہیں کہ WEAM صفر-شٹ کی عملکرد بہتر کر سکتا ہے.', 'ro': 'Modelele pre-instruite multilingve au obținut performanțe remarcabile în ceea ce privește învățarea translingvă. Unele modele multilingve, cum ar fi mBERT, au fost pre-instruite pe corpore fără etichete, prin urmare încorporările diferitelor limbi în modele nu pot fi aliniate foarte bine. În această lucrare, ne propunem să îmbunătățim performanța transferului interlingv zero-shot, propunând o sarcină pre-training numită Word-Exchange Aligning Model (WEAM), care utilizează informațiile statistice de aliniere ca cunoștințe anterioare pentru a ghida predicția cuvintelor interlingve. Evaluăm modelul nostru privind sarcina multilingvă de înțelegere a citirii mașinilor MLQA și sarcina de interfață cu limbajul natural XNLI. Rezultatele arată că WEAM poate îmbunătăți semnificativ performanța zero-shot.', 'sr': 'Većina jezičkih pre-obučenih modela postigla su izvanrednu izvedbu o učenju preko jezika. Neki multijezički modeli kao što je mBERT, pre-obučeni su na nezabeliranoj korpori, stoga se uključivanje različitih jezika u modele ne može baš dobro uskladiti. U ovom papiru imamo cilj da poboljšamo provedbu prijenosnog prevođenja nulog snimka pred obrazovanjem predstavljajući zadatak po imenu Model Aligning Word-Exchange (WEAM), koji koristi statističke informacije o usklađivanju kao prethodno znanje da bi vodili predviđanje preko jezika. Procjenjujemo naš model na multijezičkim mašinama za čitanje razumijevanja zadataka MLQA i prirodnog jezičkog interfejsa XNLI. Rezultati pokazuju da WEAM može značajno poboljšati izvršnost nule pucnjave.', 'sv': 'Flerspråkiga förutbildade modeller har uppnått anmärkningsvärda resultat när det gäller tvärspråkigt transferlärande. Vissa flerspråkiga modeller som mBERT har tränats i förväg på omärkta corpora, varför inbäddningar av olika språk i modellerna kanske inte är särskilt anpassade. I denna uppsats syftar vi till att förbättra noll-skott cross-lingual transfer prestanda genom att föreslå en pre-training uppgift som heter Word-Exchange Aligning Model (WEAM), som använder statistisk justeringsinformation som förhandskunskap för att vägleda korspråkiga ord prediktion. Vi utvärderar vår modell på flerspråkig maskinläsförståelse uppgift MLQA och naturlig språkgränssnittsuppgift XNLI. Resultaten visar att WEAM avsevärt kan förbättra nollskottets prestanda.', 'uz': "Ko'pchilik tildan oldin o'rganilgan modellar bir necha tillar o'rganishda juda ajoyib ishlaydi. MBERT kabi bir necha tillar modellari notoʻgʻri kompaniyadan oldin o'rganilgan edi, chunki modellarning turli tillar ichidagi bir xil modellar juda yaxshi bir necha tartib kelmaydi. Bu qogʻozda, biz bir necha tillar orqali o'zgartirish vazifasini o'zgartirib chiqarishni istaysizki, so'zning birinchi taʼminlovchi soʻzni almashtirish usuli (WEAM) nomli so'zni almashtirish usuli (WEAM) deb ataymiz, bu statistik tarjima qilish maʼlumotini birinchi so'zlar so'zlarining oldingi taʼminotini Biz bir necha tilda o'qish uchun modelimizni qiymatimiz MLQA va tabiiy tillar interfeys vazifasi XNLI. Natijalar WEAM noto'g'ri ishni bajarishi mumkin.", 'vi': 'Các mô- đun đa ngôn ngữ được đào tạo đã đạt hiệu quả đáng chú ý trong việc học xuyên ngôn ngữ. Một số cách đá loại một loại một loạt loại nội nội giáp đã được huấn luyện trước ở thế giới lỗ vũ của chúng, thế nên sự hợp của khác ngôn ngữ khác trong Trong tờ giấy này, chúng tôi muốn cải thiện khả năng chuyển nhượng xuyên ngôn ngữ bằng cách đề xuất một nhiệm vụ trước khi đào tạo có tên là Từ Exchange Aligning Model (WEAM) dùng thông tin cấu hình thống kê như là kiến thức dẫn đến dự đoán ngôn ngữ khác nhau. Chúng tôi đánh giá mẫu của chúng tôi về công việc hiểu thấu máy nhiều loại có nghĩa vụ MLQA và giao diện ngôn ngữ tự nhiên XLI. Kết quả cho thấy WEAM có thể cải thiện hiệu suất bắn không đáng kể.', 'da': 'Flersprogede præuddannede modeller har opnået bemærkelsesværdige resultater inden for tværsproget overførselslæring. Nogle flersprogede modeller, såsom mBERT, er blevet forududdannet på ikke-mærkede corpora, derfor er indlejringer af forskellige sprog i modellerne måske ikke særlig godt justeret. I denne artikel har vi til formål at forbedre nul-shot tværsproget overførsel ydeevne ved at foreslå en pre-training opgave kaldet Word-Exchange Aligning Model (WEAM), som bruger de statistiske justeringsoplysninger som forudgående viden til at guide tværsproget ord forudsigelse. Vi evaluerer vores model på flersproget maskinlæseforståelsesopgave MLQA og naturlig sproggrænseflade opgave XNLI. Resultaterne viser, at WEAM kan forbedre zero-shot ydeevnen betydeligt.', 'nl': "Meertalige voorgetrainde modellen hebben opmerkelijke prestaties bereikt op het gebied van cross-lingual transfer learning. Sommige meertalige modellen, zoals mBERT, zijn vooraf getraind op ongelabelde corpora's, waardoor de inbeddingen van verschillende talen in de modellen mogelijk niet goed op elkaar zijn afgestemd. In dit artikel willen we de zero-shot cross-lingual transfer prestaties verbeteren door een pre-training taak voor te stellen genaamd Word-Exchange Aligning Model (WEAM), dat de statistische uitlijningsinformatie gebruikt als de voorkennis om cross-lingual woordvoorspelling te begeleiden. We evalueren ons model op meertalige machine reading begrijping taak MLQA en natuurlijke taal interface taak XNLI. De resultaten tonen aan dat WEAM de zero-shot prestaties aanzienlijk kan verbeteren.", 'hr': 'Većina jezičkih predobučenih modela postigli su izvanredne učinke o učenju preko jezika. Neki multijezički modeli kao što je mBERT, predobučeni su na neopisivanom tijelu, stoga uključenje različitih jezika u modele ne može biti prilagođeno vrlo dobro. U ovom papiru imamo cilj poboljšati provedbu prijenosa na nulu-pucnjavu pred jezicima pred obukom po imenu Model Aligning Word-Exchange Model (WEAM), koji koristi statističke informacije o prilagodbi kao prethodno znanje kako bi vodili predviđanje preko jezika. Procjenjujemo naš model o multijezičkim strojevima koji čitaju razumijevanje zadatka MLQA i prirodnog jezičkog interfejsa XNLI. Rezultati pokazuju da WEAM može značajno poboljšati rezultat nule pucnjave.', 'bg': 'Многоезичните предварително обучени модели са постигнали забележителни резултати в интерезичното трансферно обучение. Някои многоезични модели, като например mBERT, са предварително обучени за немаркирани корпуси, поради което вграждането на различни езици в моделите може да не е много добре подравнено. В тази статия ние се стремим да подобрим ефективността на трансфера между езиците с нулев изстрел, като предложим задача преди обучение, наречена Модел за подравняване на обмена на думи (който използва статистическата информация за подравняване като предварителни знания за насочване на прогнозирането на междуезичните думи. Ние оценяваме нашия модел на многоезична задача за машинно четене и задача за интерфейс с естествен език. Резултатите показват, че може значително да подобри ефективността при нулев изстрел.', 'de': 'Mehrsprachige vortrainierte Modelle haben bemerkenswerte Leistungen beim translingualen Transferlernen erreicht. Einige mehrsprachige Modelle, wie z.B. mBERT, wurden auf nicht beschrifteten Korpora vortrainiert, daher sind die Einbettungen verschiedener Sprachen in die Modelle möglicherweise nicht sehr gut ausgerichtet. In diesem Beitrag wollen wir die Leistung des Zero-Shot Cross-Lingual Transfer verbessern, indem wir eine Vortrainingsaufgabe namens Word-Exchange Aligning Model (WEAM) vorschlagen, die die statistischen Ausrichtungsinformationen als Vorwissen verwendet, um die sprachübergreifende Wortvorhersage zu leiten. Wir evaluieren unser Modell für mehrsprachige maschinelle Leseverständnisaufgaben MLQA und natürliche Sprachschnittstellenaufgaben XNLI. Die Ergebnisse zeigen, dass WEAM die Zero-Shot-Performance deutlich verbessern kann.', 'id': 'Model berbagai bahasa yang terlatih telah mencapai prestasi yang luar biasa dalam pembelajaran trans-bahasa. Beberapa model berbeda-bahasa seperti mBERT, telah dilatih-dilatih pada korpra tidak berlebihan, sehingga penerbangan bahasa berbeda dalam model mungkin tidak disesuaikan dengan baik. Dalam kertas ini, kami bertujuan untuk meningkatkan prestasi transfersi saling bahasa tanpa tembakan dengan melaporkan tugas prapelatihan bernama Word-Exchange Aligning Model (WEAM), yang menggunakan informasi penyesuaian statistik sebagai pengetahuan sebelumnya untuk memimpin prediksi kata saling bahasa. Kami mengevaluasi model kami pada mesin berbilang bahasa membaca tugas pemahaman MLQA dan tugas antaramuka bahasa alam XNLI. Hasilnya menunjukkan bahwa WEAM dapat meningkatkan prestasi zero-shot.', 'ko': '다중 언어 예비 훈련 모델은 다중 언어 이동 학습에서 현저한 성과를 거두었다.일부 다중 언어 모델, 예를 들어 mBERT는 이미 표시되지 않은 어료 라이브러리에서 사전 훈련을 했기 때문에 모델에 서로 다른 언어의 삽입이 잘 맞지 않을 수 있다.본고에서 우리는 단어교환 정렬모델(WEAM)이라는 예비 훈련 임무를 제시했다. 이 임무는 통계 정렬 정보를 선험지식으로 삼아 크로스 언어 단어 예측을 지도하고 제로 렌즈 크로스 언어 이동 성능을 향상시키는 데 목적을 둔다.우리는 다국어 기계 읽기 이해 임무 MLQA와 자연 언어 인터페이스 임무 XNLI에서 우리의 모델을 평가했다.그 결과 WEAM은 제로 포의 성능을 크게 향상시킬 수 있습니다.', 'fa': 'مدل های پیش آموزش های زیادی زبان در مورد تعلیم انتقال زیادی زبان به دست آورده اند. بعضی مدل های زیادی زبان مثل mBERT، پیش از این روی شرکت غیرقابل تعلیم داده شده\u200cاند، بنابراین پیوند زبانهای مختلف در مدل ممکن است خیلی خوب متصل نشود. در این کاغذ، ما هدف داریم که عملکرد انتقال متصل زبان صفر را بهتر کنیم با پیشنهاد یک کار پیش آموزش به نام مدل مشخص کردن Word-Exchange (WEAM) که از اطلاعات متصل آماری به عنوان دانش قبلی برای هدایت پیش آموزش کلمات متصل زبان استفاده می\u200cکند. ما مدل خودمان را بر روی ماشین\u200cهای مطالعه\u200cهای زیادی زبان\u200cها ارزیابی می\u200cکنیم که کار MLQA و کار interface ی زبان طبیعی XNLI را درک می\u200cکنند. نتیجه\u200cها نشان می\u200cدهند که WEAM می\u200cتواند عملکرد صفر را بسیار بهتر کند.', 'tr': 'Birnäçe dilli öňünden öňünden bilim taýýarlanan nusgalary çykyp bilim taýýarlandyrylyp başarmady. MBERT ýaly köp dilli nusgalar, sözlemeýän korporada öň-öňe öwrenmedi, şonuň üçin nusgalarda farklı dilleriň integrasy örän gowy çyzylmagy mümkin däl. Bu kagyzda, biz 0-atly çarpaz diller arasynda geçirmek üçin hedeflerimizi ýeterleştirmek üçin Word-Exchange Tuşlama Modeli (WEAM) adly öňki bilim şeklinde statistik gabdalyk maglumaty ullanýarys. Biz örän dilli maşynlarymyzy MLQA we tebigy dil interfejesini XNLI duýgunlarynda çykýarys. Netijeler WEAM-iň nul atly etkinleşigini örän gowy görkezip biler.', 'sq': 'Modelet shumëgjuhëse të paratrajnuara kanë arritur performancë të shquar mbi mësimin ndërgjuhësor të transferimit. Disa modele shumëgjuhëse të tilla si mBERT, janë trajnuar para në korpra pa etiketë, prandaj përfshirjet e gjuhëve të ndryshme në modele mund të mos jenë të përshtatshme shumë mirë. Në këtë letër, ne synojmë të përmirësojmë performancën e transferit ndërgjuhësor me zero-shot duke propozuar një detyrë parastërvitëse të quajtur Word-Exchange Aligning Model (WEAM), i cili përdor informacionin statistikor të përputhjes si njohurinë e mëparshme për të udhëzuar parashikimin e fjalëve ndërgjuhësore. Ne vlerësojmë modelin tonë për punën e kuptimit të makinave shumëgjuhëse MLQA dhe punën e interfaqes natyrore të gjuhës XNLI. Rezultatet tregojnë se WEAM mund të përmirësojë ndjeshëm performancën zero-shot.', 'sw': 'Mfano wa lugha nyingi zilizofunzwa vimepata ufanisi mkubwa wa kujifunza kwa lugha mbalimbali. Baadhi ya mifano ya lugha mbalimbali kama vile mBERT, zimekuwa imefundishwa kabla kwenye kampuni isiyo na ujuzi, kwa hiyo mipango ya lugha tofauti katika mifano inawezekana hayaweze kuunganishwa vizuri sana. Katika karatasi hii, tunakusudia kuboresha ufanisi wa usafirishaji wa lugha sifuri kwa kupendekeza kazi ya mafunzo ya awali inayoitwa Mradi wa Ubadilishaji wa Uhambuzi wa Kireno (WEAM), ambao unatumia taarifa za usambazaji wa takwimu kama ufahamu wa zamani wa kuongoza utabiri wa neno la lugha mbalimbali. Tutathmini mtindo wetu wa mashine ya lugha mbalimbali inayosoma kazi ya kompyuta MLQA na kazi ya lugha za asili XNLI. Matokeo yanaonyesha kuwa WEAM inaweza kuboresha utendaji wa picha sifuri.', 'af': "Veelvuldige voorafgeleerde modele het betekende prestasie op kruistale oordrag leer bereik. Sommige multitaalse modele soos mBERT, is vooraf opgelei op ongeabelde korpora, dus die inbêding van verskillende tale in die modele dalk mag nie baie goed gelyk word nie. In hierdie papier, ons doen doel om die nul-skoot kruistale oordragting te verbeter deur 'n voor-oerwinning taak genoem word-Exchange Aligning Model (WEAM), wat gebruik die statistiese belyning inligting as die vooraf kennis om kruistale woord voorskou te lei. Ons evalueer ons model op multilingual masjien lees verstanding taak MLQA en natuurlike taal koppelvlak taak XNLI. Die resultate wys dat WEAM betekenlik die nul-skoot prestasie kan verbeter.", 'am': 'የቋንቋ ቋንቋዎች በተለየ ቋንቋ ትምህርት ላይ የበለጠ የድምፅ ስርዓት አግኝተዋል፡፡ ብሔርቴን የሚመስሉ ብዙዎች የቋንቋዎች ምሳሌዎች ሳይታወቁ ኮርፖርት ላይ ተማርተዋል፡፡ ስለዚህ በዓይነቶች ውስጥ የልዩ ቋንቋዎች አካባቢ በመልካም መሳሰል አይችልም፡፡ በዚህ ፕሮግራም፣ የቋንቋ ቋንቋ-ቋንቋ የተለወጠውን የክፍለ ስርዓት ማሻሻል እናደርጋለን፡፡ የብዙልቋ ቋንቋዎች ማተሚያ ላይ የድምፅ ማድረጊያውን እና የፍጥረት ቋንቋ interface ስራ XNLI እናስተዋልታለን፡፡ ፍጥረቱም WEAM የzero-shot performance በማድረግ ይችላል፡፡', 'hy': 'Բազլեզվով նախապատրաստված մոդելները հաջողվեցին աներևակայելի արդյունք փոխլեզվով փոխանցվող ուսումնասիրության համար: Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the models may not be aligned very well.  Այս թղթի մեջ մենք նպատակով ենք բարելավել զրոյական հատվածային լեզվի փոխանցման արտադրողականությունը, առաջարկելով նախավարժական գործընթաց, որը կոչվում է Word-Trade-Adիմարեցման Մոդել (WEPM), որը օգտագործում է վիճակագրական համապատասխանման տեղեկատվությունը որպես նախկին գիտելիք, որպե Մենք գնահատում ենք մեր մոդելը բազլեզու մեքենայի ընթերցման հասկանալու առաջադրանքի MLQA-ի և բնական լեզվի ինտերֆեյսի XNSI-ի համար: Արդյունքները ցույց են տալիս, որ WEPM-ը կարող է նշանակալի բարելավել զրոյի արտադրողականությունը:', 'bs': 'Većina jezičkih predobučenih modela ostvarila su izvanrednu izvedbu o učenju preko jezika. Neki multijezički modeli kao što je mBERT, predobučeni su na nezabeliranom korporaciji, stoga uključenje različitih jezika u modele ne može biti prilagođeno vrlo dobro. U ovom papiru imamo cilj da poboljšamo provedbu prijenosnog prenošenja nula snimka pred jezicima pred obukom po imenu Model Aligning Word-Exchange (WEAM), koji koristi statističke informacije o prilagodbi kao prethodno znanje kako bi vodili predviđanje preko jezika. Procjenjujemo naš model o multijezičkim mašinama za čitanje razumijevanja zadatka MLQA i prirodnog jezičkog interfejsa XNLI. Rezultati pokazuju da WEAM može značajno poboljšati performancu nule pucnjave.', 'az': 'Çoxlu dil öyrənmiş modellər çoxlu dil transfer öyrənməsi haqqında möhtərəm performansı başa düşdü. MBERT kimi çoxlu dil modelləri əvvəlcə yazılmamış korpora təhsil edilmişdir, buna görə modellərdə fərqli dillərin qatılması çox yaxşı təhsil edilməz. Bu kağızda, biz sıfır-vuruş, dil çoxluğu təhsil etmək üçün, Word-Exchange Aligning Model (WEAM) adlı əvvəl təhsil etmək üçün statistik təhsil məlumatını əvvəlki bilgi kimi istifadə etmək istəyirik. Biz çoxlu dil maşını oxuyan işlərimizin MLQA və təbiətli dil interfejsi işləri XNLI üçün modeliyimizi değerləşdiririk. Sonuçlar, WEAM sıfır-shot performansını çox yaxşılaşdıra bilər.', 'cs': 'Vícejazyčné předškolené modely dosáhly pozoruhodného výkonu při transferovém učení mezi jazyky. Některé vícejazyčné modely, jako je mBERT, byly předškoleny na neznačených korpusech, proto vkládání různých jazyků do modelů nemusí být příliš dobře zarovnáno. V tomto článku se snažíme zlepšit výkonnost přenosu mezi jazyky nulovým záběrem navržením předškolení s názvem Word-Exchange Aligning Model (WEAM), který využívá statistické informace o zarovnání jako předchozí znalosti k řízení predikce mezi jazyky. Hodnotíme náš model na vícejazyčné úloze porozumění strojovému čtení MLQA a úloze rozhraní přirozeného jazyka XNLI. Výsledky ukazují, že WEAM může výrazně zlepšit nulový výkon.', 'et': 'Mitmekeelsed eelkoolitud mudelid on saavutanud märkimisväärse tulemuse keeleülese siirdeõppe puhul. Mõned mitmekeelsed mudelid, näiteks mBERT, on eelnevalt koolitatud märgistamata korpustele, mistõttu erinevate keelte manustamine mudelitesse ei pruugi olla väga hästi ühtlustatud. Käesolevas dokumendis soovime parandada keeleülese ülekande tulemuslikkust, pakkudes välja koolituseelse ülesande nimega Word-Exchange Aligning Model (WEAM), mis kasutab statistilist vastavusteavet eelnevalt keeleüleste sõnade prognoosimiseks. Hindame oma mudelit mitmekeelse masinlugemise mõistmise ülesande MLQA ja looduskeele liidese ülesande XNLI kohta. Tulemused näitavad, et WEAM võib oluliselt parandada null-shot jõudlust.', 'fi': 'Monikieliset esikoulutetut mallit ovat saavuttaneet huomattavan suorituskyvyn monikielisessä siirtooppimisessa. Jotkin monikieliset mallit, kuten mBERT, on koulutettu etukäteen merkitsemättömiin korpusiin, joten eri kielien upotukset malleihin eivät välttämättä ole kovin hyvin linjassa. Tässä artikkelissa pyrimme parantamaan kielten välistä tiedonsiirtoa nollakuvan avulla ehdottamalla esikoulutusta koskevaa tehtävää nimeltä Word-Exchange Aligning Model (WEAM), jossa käytetään tilastollista linjaustietoa ennakkotietona kielten välisten sanojen ennustamiseen. Arvioimme monikielisen konelukutaitotehtävän MLQA ja luonnollisen kielen rajapintatehtävän XNLI mallia. Tulokset osoittavat, että WEAM voi merkittävästi parantaa nollalaukauksen suorituskykyä.', 'ca': "Els models multilingües pré-entrenats han aconseguit un rendiment notable en l'aprenentatge translingüístic. Alguns models multilingües, com mBERT, han estat pré-entrenats en corpora sense etiqueta, per tant l'incorporació de diferents llengües als models pot ser que no s'allinyi gaire bé. En aquest paper, busquem millorar el desempeny de transfer ència translingüística amb fotografies zero proposant una tasca de pré-entrenament anomenada Word-Exchange Alignment Model (WEAM), que utilitza la informació estadística d'allinjament com el coneixement anterior per guiar la predicció de paraules translingües. Evaluam el nostre model en la tasca de comprensió multilingüe de llegir màquines MLQA i la tasca XNLI d'interfície de llenguatge natural. The results show that WEAM can significantly improve the zero-shot performance.", 'bn': 'অনেক ভাষায় প্রশিক্ষণ পূর্ব প্রশিক্ষিত মডেল শিক্ষা শিক্ষার ব্যাপারে চমৎকার কাজ অর্জন করেছে। এমবিবের্টের মতো কিছু মাল্টিভাষায় মডেল প্রশিক্ষণ পূর্বে প্রশিক্ষণ প্রদান করা হয়েছে, যার ফলে মডেলের ভিন্ন ভাষার বিভিন্ন ভাষার প্রবেশ খুব এই কাগজটিতে আমরা শুধুমাত্র ক্রস-ভাষার পরিবর্তনের প্রস্তাব প্রস্তাব করি শব্দ-এক্সচেঞ্জ অ্যালিঙ্গিং মডেল (উইএম) নামে একটি প্রশিক্ষণের পূর্বার্তা কাজের প্রস্তাব করে, যা পরিস আমরা মাল্টিভাষার মেশিনে আমাদের মডেলের মূল্য মূল্যায়ন করি সম্পূর্ণ কাজ এমএলকিউ এবং প্রাকৃতিক ভাষার ইন্টারফেস ক্ ফলাফল দেখা যাচ্ছে যে উইএম এই শুটের প্রদর্শনীকে গুরুত্বপূর্ণ ভাবে উন্নত করতে পারে।', 'sk': 'Večjezični predhodno usposobljeni modeli so dosegli izjemno uspešnost pri medjezičnem prenosnem učenju. Nekateri večjezični modeli, kot je mBERT, so bili predhodno usposobljeni za neoznačene korpuse, zato vgradnje različnih jezikov v modele morda ne bo dobro usklajeno. V tem prispevku želimo izboljšati učinkovitost ničelnega medjezičnega prenosa s predlogom naloge pred usposabljanjem z imenom Word-Exchange Aligning Model (WEAM), ki uporablja informacije o statistični poravnavi kot predhodno znanje za vodenje napovedovanja medjezičnih besed. Naš model ocenjujemo na nalogi večjezičnega strojnega branja MLQA in nalogi vmesnika naravnega jezika XNLI. Rezultati kažejo, da lahko WEAM bistveno izboljša zmogljivost brez strela.', 'jv': 'Multi-Linguke model sing paling kelas telas nang bantuan kuwi bantuan surat Genjer-genjer model sing sampeyan banget, kaya mBERT, dadi wis mulai terus-terus ngono perusahaan sing gak nggawe, dadi bisa embedding language karo perusahaan banget kanggo model bisa diantelak durung bisa diantelak. Nang kuwi iki, awak dhéwé iso nggawe barang nggawe gerakan nul-shot karo nggawe barang pengguna bantuan ingkang supoyo nggawe task gawe Word-Replace Align model (WAAM), sing usungé stasitik tekan nggawe alamat surat banjuré kebebasan pertualisi nggawe pawaran langkung sambanjuré. Monday Rejalakno ngomong barang "KEAM" iso nggambar obang gambar pisan kang nul', 'he': 'Multilingual pre-trained models have achieved remarkable performance on cross-lingual transfer learning.  כמה דוגמנים רבות שפות כמו mBERT, הוכשרו מראש על גופורה ללא סימנים, לכן התקפות של שפות שונות בדוגמנים אולי לא מתאימות היטב. בעיתון הזה, אנו מתכוונים לשפר את ביצועי ההעברה לשפתיים ללא צלילים על ידי הצעה משימה לפני האימונים בשם מודל התאמה של החלפת מילים (Word Exchange Aligning Model - WEAM), אשר משתמש במידע ההתאימות הסטטיסטית כידע הקודם כדי להדריך חיזוי מילים לשפתיים. אנו מעריכים את המודל שלנו על משימת ההבנה של קריאת מכונות רבות שפות MLQA וממשימת משימת השפה הטבעית XNLI. התוצאות מראות כי WEAM יכול לשפר באופן משמעותי את ההופעה של אפס יריות.', 'ha': "@ info: whatsthis Babu wasu misãlai masu mulki-lingui kamar mBERT, an tafiyar da shi gaba ɗaya a kan firma ba'a yi taƙaita ba, sabõda haka, kada za'a daidaita wasu harshen daban cikin misalin. Daga wannan takardan, Munã kwaɗayin mu ƙara samar da shirin shifo-na-sifanci cikin lugha ta sifanci ko kuma Mu buɗa wani wani aikin da ya yi amfani da shi a gaba-wa'azi da sunan maganar-Aladige Aligning Model (WEAM), wanda ke amfani da maɓallin sarrafiya kamar wani ilmi ya gaba ga ya shirya bayani ga kalmar-harshe. Kana ƙaddara misalinmu a kan mashine masu mulki'abũta da ke karãtun aikin makaranta MLQA da aikin fassarar harshe na asili XNLI. Mataimakin na nuna cewa WEAM zai iya kanza mai kyau ga gyaran gyaran sifiri.", 'bo': 'སྐད་རིགས་སྔོན་གྲངས་བསླབ་པའི་མིག་དཔེ་དབྱིབས་ཡོད་པའི་སྣ་ཚོགས་ཀྱི་གནས་སྟངས་མངོན་གསལ་ཅན་ཡོད་པ་དང་། སྐད་ཡིག་དབྱིབས་ཀྱི་སྣ་མང་ཆེ་བའི་མིག་དཔེ་བརྗོད་ཀྱི་དབང་ཆ་གྱི་ནང་དུ་སྔོན་གྲངས་སྒྲིག འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་དུ་འུ་ཅག་གིས་zero-shot cross-lingual transfer་ཡི་སྐྱེས་ཚད་ལེགས་སུ་ཡར་རྒྱས་གཏོང་བྱེད་པའི་སྔོན་གྲངས་སྒྲིག་འགོད་དང་མིང་Word-Exchange Aligning Model ང་ཚོས་སྐད རྩིས་འབྲས་བུའི་ནང་ལུ་ "WEAM" གི་ཉེན་ཁ་བྱེད་ཀྱི་ལས་འགུལ་སྒྲུབ་མངོན་གསལ་བ་ཐུབ་པ་ཡིན།'}
{'en': 'Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering', 'ar': 'التحقيق في محاذاة التمثيل بعد التدريب للإجابة على الأسئلة عبر اللغات', 'fr': "Recherche de l'alignement de la représentation post-formation pour la réponse aux questions multilingues", 'pt': 'Investigando o Alinhamento de Representação Pós-Pré-treinamento para Respostas a Perguntas em Vários Idiomas', 'es': 'Investigación de la alineación de la representación posterior al entrenamiento para la respuesta a preguntas multilingües', 'zh': '治跨语问答', 'ru': 'Изучение выравнивания представлений после предварительного обучения для ответов на перекрестные языковые вопросы', 'hi': 'क्रॉस-लिंगुअल प्रश्न उत्तर देने के लिए पोस्ट-प्रीट्रेनिंग प्रतिनिधित्व संरेखण की जांच करना', 'ja': 'クロスリンガルクエスチョンアンサーのための事前研修後の表現アラインメントの調査', 'ga': 'Ionadaíocht Iar-réamhoiliúint a Imscrúdú Ailíniú le haghaidh Freagra Ceisteanna Trastheangacha', 'ka': 'შესაბამისი შემდეგ შემდეგ შემდეგ შემდეგ შემდეგ შემდეგ განსხვავების შესაბამისი კითხვების შესაბამისათვის', 'el': 'Διερεύνηση ευθυγράμμισης αντιπροσώπευσης μετά την προεπιλογή για την απάντηση διαγλωσσικών ερωτήσεων', 'hu': 'Az előkészítés utáni képviseleti igazítás vizsgálata a nyelvközi kérdések megválaszolásához', 'it': "Indagine sull'allineamento post-pre-formazione della rappresentanza per la risposta alle domande interlinguistiche", 'kk': 'Тішкі тілікті сұрақтар жауап беру үшін кейінгі сұрақтарды түзету', 'lt': 'Tyrimas po ikimokyklinio atstovavimo suderinimas atsakant į tarpkalbinius klausimus', 'mk': 'Истражување на пост-претренирање на прилагодување на претставувањето за прекујазичните одговори на прашањата', 'ms': 'Menyelidiki Jajaran Perwakilan Setelah Pralatihan untuk Jawapan Pertanyaan Selata-Bahasa', 'ml': 'ക്രോസ്- ലിങ്ഗല്\u200d ചോദ്യം ഉത്തരം ചോദ്യം പിന്നീട് പ്രതിനിധിയുടെ അന്വേഷിക്കുന്നു', 'mn': 'Дараа нь хэлбэрийн асуултын хариултын төлөөлөлт дээр суралцах', 'no': 'Investigasjon etter omsetjing av reprezentasjon for å svara på krysslingsspørsmål', 'pl': 'Badanie dostosowania reprezentacji po wstępnym treningu do odpowiedzi na pytania między językami', 'mt': 'Investigazzjoni ta’ Allinjament tar-Rappreżentanza ta’ wara t-taħriġ minn qabel għat-tweġiba għal mistoqsijiet translingwi', 'si': 'ක්\u200dරොස් ලින්ගුවාල් ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතිස්ථානය සඳහා ප්\u200dරශ්න ප්\u200dරතිස්ථානය', 'ro': 'Investigarea alinierii post-pregătire a reprezentării pentru răspunsul la întrebări translingvistice', 'so': "Baaritaanka dib-pretrinta u bedelashada jawaabta su'aalaha luuqada", 'sv': 'Utredning av post-pretraining Representation Alignment for Cross-Language Question Svaring', 'sr': 'Istraživanje postpredstavničkog pristupanja za odgovor na krstoLingualno pitanje', 'ta': 'கிருஸ்- கோட்டு கேள்விக்கான பின்வரும் ஒழுங்குப்படுத்தல் ஆய்வு செய்கிறது', 'ur': 'Cross-Lingual Question Answering کے لئے پاسٹ پرٹرینڈنگ ریسپینسٹن الیگن کی تحقیق کرتا ہے', 'uz': 'Name', 'vi': 'Điều tra liên lạc sau vẻ vẻ đẹp', 'bg': 'Разследване на подравняване на представителството след подготовката за междуезиково отговаряне на въпроси', 'nl': 'Onderzoek naar de afstemming van representatie na pretraining voor het beantwoorden van translinguale vragen', 'da': 'Undersøgelse af efteruddannelse af repræsentationstilpasning til tværsprogede spørgsmål', 'de': 'Untersuchung der Reprﾃ､sentationsausrichtung nach dem Pretraining fﾃｼr die sprachﾃｼbergreifende Beantwortung von Fragen', 'hr': 'Istraživanje isprave poslije pretraživanja predstavnika za odgovor na krstojezično pitanje', 'fa': 'تحقیق مجموعه نماینده\u200cهای بعد از تحقیق برای پاسخ سوال\u200cهای متوسط زبان', 'sw': 'Tafiti la Uwekezaji wa Mahakama ya Baada ya Utawala kwa ajili ya swali la Kusini-Lugha', 'id': 'Menyelidiki Penyesuaian Perwakilan Setelah Pralatihan untuk Jawaban Pertanyaan Selasa Bahasa', 'ko': '크로스 언어 문답 훈련 전 표징 정렬 연구', 'af': 'Voorskou Post- Pretraining Voorskou Oplyn vir Cross- Lingual Vrag Antwoord', 'tr': 'Çapraz Sorag Cevaplamak üçin Eýtgeden Ýygymy Görkezilişi', 'sq': 'Hetimi i rregullimit të përfaqësimit pas stërvitjes për përgjigjet e pyetjeve ndërgjuhësore', 'am': 'ምርጫዎች', 'az': 'Çərz-dilli sual cavab vermək üçün Qərcləndirici İzləşdirmək', 'bs': 'Istraživanje isprave zastupanja nakon pretraživanja za odgovor na krstoLingualno pitanje', 'bn': 'ক্রস-লিঙ্গুয়াল প্রশ্নের উত্তরের জন্য প্রতিনিধি প্রতিনিধিত্বের তদন্ত করা হচ্ছে', 'cs': 'Vyšetřování vyrovnání reprezentace po předběžném tréninku pro zodpovězení mezi jazyky', 'et': 'Koolitusjärgse esinduse vastavuse uurimine keeleülese küsimustele vastamise jaoks', 'ca': "Investigar l'allinjament de la representació postpretraining per respondre preguntes translingües", 'fi': 'Esikoulutuksen jälkeisen edustuksen linjauksen tutkiminen kielienvälisessä kyselyvastauksessa', 'hy': 'Հետազոտությունը հետադասական ներկայացման համապատասխանման հետադասական ուսումնասիրությունը', 'jv': 'istraigating After-praying representation Align for', 'ha': 'Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering', 'he': 'Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering', 'sk': 'Preiskava usklajevanja predstavništva po predusposabljanju za medjezikovno odgovarjanje na vprašanja', 'bo': 'Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering'}
{'en': 'Human knowledge is collectively encoded in the roughly 6500 languages spoken around the world, but ', 'ar': 'يتم ترميز المعرفة البشرية بشكل جماعي في ما يقرب من 6500 لغة يتم التحدث بها حول العالم ، ولكنها لا يتم توزيعها بالتساوي عبر اللغات. ومن ثم ، لكي تخدم أنظمة الإجابة عن الأسئلة (QA) التي تسعى للحصول على المعلومات بشكل مناسب المتحدثين من جميع اللغات ، فإنها تحتاج إلى العمل بلغات متعددة. في هذا العمل نتحرى إمكانيات نماذج اللغة متعددة اللغات سابقة التدريب على ضمان الجودة عبر اللغات. وجدنا أن محاذاة التمثيلات عبر اللغات بشكل صريح مع خطوة ضبط دقيق لاحقة تؤدي عمومًا إلى تحسين الأداء. بالإضافة إلى ذلك ، نحقق في تأثير حجم البيانات بالإضافة إلى اختيار اللغة في خطوة الضبط الدقيق هذه ، ونصدر أيضًا مجموعة بيانات لتقييم أنظمة ضمان الجودة عبر اللغات.', 'es': 'El conocimiento humano está codificado colectivamente en los aproximadamente 6500 idiomas que se hablan en todo el mundo, pero no se distribuye por igual en todos los idiomas. Por lo tanto, para que los sistemas de respuesta a preguntas (QA) de búsqueda de información sirvan adecuadamente a los hablantes de todos los idiomas, deben funcionar de manera multilingüe. En este trabajo investigamos las capacidades de los modelos lingüísticos preentrenados multilingüe en control de calidad multilingüe. Descubrimos que alinear explícitamente las representaciones en todos los idiomas con un paso de ajuste posterior a las necesidades generalmente conduce a un mejor rendimiento. Además, investigamos el efecto del tamaño de los datos y la elección del idioma en este paso de ajuste, y también publicamos un conjunto de datos para evaluar los sistemas de control de calidad multilingües.', 'pt': 'O conhecimento humano é codificado coletivamente nas cerca de 6.500 línguas faladas em todo o mundo, mas não é distribuído igualmente entre as línguas. Portanto, para que os sistemas de resposta a perguntas (QA) de busca de informações atendam adequadamente aos falantes de todas as línguas, eles precisam operar em vários idiomas. Neste trabalho, investigamos as capacidades de modelos de linguagem pré-treinados multilíngue em QA multilíngue. Descobrimos que alinhar explicitamente as representações entre linguagens com uma etapa de ajuste fino post-hoc geralmente leva a um desempenho aprimorado. Além disso, investigamos o efeito do tamanho dos dados, bem como a escolha do idioma nesta etapa de ajuste fino, também liberando um conjunto de dados para avaliar sistemas de controle de qualidade em vários idiomas.', 'fr': "Les connaissances humaines sont codées collectivement dans les quelque 6 500 langues parlées dans le monde, mais elles ne sont pas réparties également entre les langues. Par conséquent, pour que les systèmes de réponse aux questions (AQ) de recherche d'informations puissent servir de manière adéquate les locuteurs de toutes les langues, ils doivent fonctionner de manière multilingue. Dans ce travail, nous étudions les capacités des modèles linguistiques préentraînés multilingues en matière d'assurance qualité multilingue. Nous constatons que l'alignement explicite des représentations entre les langues avec une étape de réglage fin post-hoc conduit généralement à une amélioration des performances. Nous étudions également l'effet de la taille des données ainsi que le choix de la langue dans cette étape de réglage fin, en publiant également un ensemble de données pour évaluer les systèmes d'assurance qualité multilingues.", 'ja': '人間の知識は、世界中で話されているおよそ6500の言語で一括してエンコードされていますが、言語間で均等に分布しているわけではありません。したがって、情報検索質問回答（ QA ）システムがすべての言語の話者に適切にサービスを提供するためには、クロスリンガルで動作する必要があります。この研究では、クロスリンガルQAに関する多言語事前訓練言語モデルの能力を調査します。言語間の表現を事後的な微調整ステップに明示的に合わせることは、一般的にパフォーマンスの向上につながることがわかっています。さらに、この微調整ステップでは、データサイズと言語の選択の効果を調査し、クロスリンガルQAシステムを評価するためのデータセットもリリースします。', 'zh': '人伦编码为全世界约6500种语,而不平均于言语之间。 是以信息搜问(QA)统足以备言语之用,跨言而行。 于此之事,多言预训语言之能 QA 。 吾见微调步骤显式以跨语对齐常可以益性。 微调步骤,究其大小语言,发一以评估跨语 QA 系统之数集。', 'hi': 'मानव ज्ञान को सामूहिक रूप से दुनिया भर में बोली जाने वाली लगभग 6500 भाषाओं में एन्कोडेड किया गया है, लेकिन इसे भाषाओं में समान रूप से वितरित नहीं किया जाता है। इसलिए, सभी भाषाओं के वक्ताओं की पर्याप्त रूप से सेवा करने के लिए सूचना-मांग प्रश्न उत्तर (क्यूए) प्रणालियों के लिए, उन्हें क्रॉस-लिंगुअल रूप से संचालित करने की आवश्यकता है। इस काम में हम क्रॉस-लिंगुअल क्यूए पर बहुभाषी रूप से पूर्व-प्रशिक्षित भाषा मॉडल की क्षमताओं की जांच करते हैं। हम पाते हैं कि स्पष्ट रूप से एक पोस्ट-हॉक फाइनट्यूनिंग चरण के साथ भाषाओं में प्रतिनिधित्व को संरेखित करने से आमतौर पर बेहतर प्रदर्शन होता है। हम इसके अलावा डेटा के आकार के प्रभाव के साथ-साथ इस ठीक-ट्यूनिंग चरण में भाषा की पसंद की जांच करते हैं, क्रॉस-लिंगुअल क्यूए सिस्टम का मूल्यांकन करने के लिए एक डेटासेट भी जारी करते हैं।', 'ru': 'Человеческие знания в совокупности кодируются примерно на 6500 языках, на которых говорят во всем мире, но они не распределяются поровну между языками. Следовательно, для того, чтобы системы поиска информации и ответов на вопросы (QA) могли адекватно обслуживать носителей всех языков, они должны работать на нескольких языках. В этой работе мы исследуем возможности многоязычно подготовленных языковых моделей по межязычному обеспечению качества. Мы обнаружили, что четкое выравнивание представлений между языками с шагом апостериорной настройки обычно приводит к улучшению производительности. Мы дополнительно изучаем влияние размера данных, а также выбора языка на этом этапе тонкой настройки, а также выпускаем набор данных для оценки кросс-лингвистических систем обеспечения качества.', 'ga': 'Tá eolas daonna ionchódaithe le chéile i thart ar 6500 teanga a labhraítear ar fud an domhain, ach ní dhéantar é a dháileadh go cothrom trasna teangacha. Mar sin, le go bhfreastalóidh córais chuardaigh faisnéise ar cheisteanna (QA) mar is cóir do chainteoirí gach teanga, ní mór dóibh oibriú go tras-teangach. San obair seo déanaimid iniúchadh ar chumais na múnlaí teanga ilteangacha réamhoilte ar QA tras-teanga. Feicimid go n-eascraíonn feidhmíocht feabhsaithe go ginearálta na léiriúcháin trasna teangacha a ailíniú go soiléir le céim mhionchoigeartaithe iar-hoc. Déanaimid imscrúdú freisin ar éifeacht mhéid na sonraí chomh maith leis an rogha teanga sa chéim mhionchoigeartaithe seo, ag scaoileadh tacar sonraí freisin chun córais tras-teangacha QA a mheas.', 'el': 'Η ανθρώπινη γνώση κωδικοποιείται συλλογικά στις περίπου 6500 γλώσσες που ομιλούνται σε όλο τον κόσμο, αλλά δεν κατανέμεται εξίσου μεταξύ των γλωσσών. Ως εκ τούτου, για να εξυπηρετήσουν επαρκώς τους ομιλητές όλων των γλωσσών τα συστήματα απάντησης ερωτήσεων (QA) για την αναζήτηση πληροφοριών, πρέπει να λειτουργούν γλωσσικά. Σε αυτή την εργασία διερευνούμε τις δυνατότητες των πολύγλωσσων προτύπων γλωσσών για τη διαγώνια QA. Διαπιστώνουμε ότι η ρητή ευθυγράμμιση των αναπαραστάσεων σε όλες τις γλώσσες με ένα βήμα τελειοποίησης μετά το hoc οδηγεί γενικά σε βελτιωμένη απόδοση. Επιπλέον, διερευνούμε την επίδραση του μεγέθους των δεδομένων καθώς και της επιλογής γλώσσας σε αυτό το βήμα λεπτομέρειας, απελευθερώνοντας επίσης ένα σύνολο δεδομένων για την αξιολόγηση των γλωσσικών συστημάτων QS.', 'kk': 'Адам білімі әлемдегі 6500 тілде жалпы кодтады, бірақ ол тілдерге сәйкес таратылмайды. Сондықтан, мәліметті іздеу сұрақ жауап беру (QA) жүйелері барлық тілдердің тілдерінің сөйлейтіншілеріне жеткізу үшін, олар тілдерді біріктіру үшін жұмыс істеу керек. Бұл жұмыс ішінде біз көптеген тіл үлгілерін көптеген QA үлгілерінде зерттеуді қалаймыз. Біз тілдердің өзгерістерін өзгерту үшін кейінгі қадамымен жақсы түрлендіру керек деп ойлаймыз. Біз қосымша деректер өлшемінің эффектін және тілді таңдау қадамында, сондай-ақ тілді QA жүйелерді бағалау үшін деректер жинағын шығару.', 'ka': 'ადამიანის მეცნიერება კოლექტიურად კოდირებულია სამყარო მსოფლიოს 6500 ენაში, მაგრამ ის არ განსაზღვრული ენაში. ამიტომ, ინფორმაციის ძებნა კითხვის პასუხისთვის (QA) სისტემებისთვის, რომ ყველა ენათების მუშაობელად მუშაობს, ისინი უნდა კრისი ენათების მუშაობა. ამ სამუშაოში ჩვენ განსხვავებთ მრავალენგურად წავლის მოდელეების შესაძლებლობა სამუშაო QA-ზე. ჩვენ ვფიქრობთ, რომ განსაკუთრებულად განსაკუთრებულებას ენების განმავლობაში, რომელიც პოსჰოკის კონფინტურაციის კონფინტურაციის კონფინტურაციის კონფი ჩვენ დამატებით მონაცემების ზომის ეფექტის შესახებ და ენათის ამოირჩევა ამ კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაცი', 'hu': 'Az emberi tudást a világ körülbelül 6500 nyelvén együttesen kódolják, de nem osztják el egyenlően a nyelveken. Ezért ahhoz, hogy az információkereső kérdésre válaszoló rendszerek megfelelően kiszolgálják az összes nyelv beszélőjét, nyelveken át kell működniük. Ebben a munkában megvizsgáljuk a többnyelvűen előképzett nyelvi modellek képességeit a többnyelvű minősítéssel kapcsolatban. Úgy találjuk, hogy a nyelvek közötti reprezentációk kifejezetten egy post-hoc finomhangolási lépéssel történő igazítása általában jobb teljesítményt eredményez. Ebben a finomhangolási lépésben továbbá vizsgáljuk az adatméret hatását és a nyelvválasztás nyelvét, valamint adatkészletet bocsátunk ki a többnyelvű minősítési rendszerek értékelésére.', 'it': "La conoscenza umana è codificata collettivamente nelle circa 6500 lingue parlate in tutto il mondo, ma non è distribuita equamente tra le lingue. Pertanto, affinché i sistemi di risposta alle domande alla ricerca di informazioni (QA) possano servire adeguatamente i parlanti di tutte le lingue, essi devono operare in modo translinguale. In questo lavoro analizziamo le capacità di modelli linguistici multilingumente pre-addestrati sul QA cross-lingual. Troviamo che l'allineamento esplicito delle rappresentazioni tra le lingue con una fase di finetuning post-hoc porta generalmente a migliorare le prestazioni. Analizziamo inoltre l'effetto della dimensione dei dati e la scelta della lingua in questa fase di messa a punto, rilasciando anche un set di dati per la valutazione dei sistemi QA cross-lingual.", 'lt': 'Žmogaus žinios yra kolektyviai koduojamos maždaug 6500 kalbų, kalbėtų visame pasaulyje, tačiau jos nėra vienodai paskirstytos visoms kalboms. Taigi, norint, kad į klausimus ieškantys informacijos būtų atsakytos (QA) sistemos, tinkamai tarnautų visų kalbų kalbėtojams, jos turi veikti įvairiomis kalbomis. In this work we investigate the capabilities of multilingually pretrained language models on cross-lingual QA.  Mes manome, kad aiškiai suderinus atstovavimus tarp kalbų su post hoc tikslinimo žingsniu paprastai pagerinami rezultatai. Papildomai tiriame duomenų dydžio poveikį ir kalbų pasirinkimą šiame tikslinamame etape, taip pat skelbiame duomenų rinkinį, skirtą vertinti tarpkalbines QA sistemas.', 'mk': 'Човечкото знаење е колективно кодирано на околу 6500 јазици кои се зборуваат низ целиот свет, но не се дистрибуира еднакво низ јазиците. Затоа, за системите за одговори на прашања кои бараат информации (QA) да им служат на говорниците на сите јазици, тие мора да функционираат преку јазик. Во оваа работа ги истражуваме способностите на мултијазички предобучени јазички модели на прекујазичниот QA. Најдовме дека експлицитното прилагодување на претставувањата низ јазиците со постхок чекор на финетирање генерално води до подобрена резултатност. Дополнително го истражуваме ефектот на големината на податоците, како и изборот на јазикот во овој чекор на финетизирање, исто така објавувајќи набор податоци за проценка на меѓујазичните системи на QA.', 'ms': 'Pengetahuan manusia dikodifikasi secara kolektif dalam kira-kira 6500 bahasa yang bercakap di seluruh dunia, tetapi ia tidak disebarkan secara sama di seluruh bahasa. Oleh itu, untuk sistem menjawab soalan mencari maklumat (QA) untuk melayani pembicara semua bahasa secara adekwat, mereka perlu beroperasi secara melintasi bahasa. Dalam kerja ini kami menyelidiki kemampuan model bahasa yang dilatih berbilang bahasa pada QA saling bahasa. Kami mendapati bahawa secara eksplicit menyesuaikan perwakilan di seluruh bahasa dengan langkah post-hoc penentuan biasanya membawa kepada prestasi yang lebih baik. Kami tambahan menyelidiki kesan saiz data serta pilihan bahasa dalam langkah penyesuaian baik ini, juga melepaskan set data untuk menilai sistem QA saling bahasa.', 'mt': 'L-għarfien uman huwa kkodifikat b’mod kollettiv f’madwar 6500 lingwa mitkellma madwar id-dinja, iżda mhuwiex imqassam b’mod ugwali bejn il-lingwi. Għalhekk, għas-sistemi li jwieġbu għall-mistoqsijiet li jfittxu informazzjoni (QA) biex iservu b’mod adegwat lil dawk li jitkellmu l-lingwi kollha, jeħtieġ li joperaw b’mod translingwi. F’dan ix-xogħol ninvestigaw il-kapaċitajiet ta’ mudelli lingwistiċi mħarrġa minn qabel b’mod multilingwistiku dwar il-QA translingwistika. We find that explicitly aligning the representations across languages with a post-hoc finetuning step generally leads to improved performance.  We additionally investigate the effect of data size as well as the language choice in this fine-tuning step, also releasing a dataset for evaluating cross-lingual QA systems.', 'ml': 'ലോകത്തില്\u200d മുഴുവന്\u200d സംസാരിക്കുന്ന ഏകദേശം 6500 ഭാഷകളില്\u200d മനുഷ്യന്റെ അറിവ് ഒരുമിച്ച് കോണ്\u200dഡ് ചെയ്യപ്പെടുന്നു. പക്ഷ അതുകൊണ്ട്, വിവരങ്ങള്\u200d അന്വേഷിക്കുന്ന ചോദ്യങ്ങളുടെ ഉത്തരം സിസ്റ്റത്തിന് വേണ്ടി എല്ലാ ഭാഷകളിലും സംസാരിക്കുന്നവരെ സേവിക ഈ ജോലിയില്\u200d നമ്മള്\u200d പല ഭാഷക്കാരുടെ കഴിവുകള്\u200d അന്വേഷിക്കുന്നു. ക്യൂഎ ക്യൂഎയില്\u200d നിന്നും ഭാഷ മോഡലുകളുടെ സാധ നമുക്ക് കണ്ടെത്തുന്നത് ഭാഷകളിലെ പ്രതിനിധികളെ വ്യക്തമായി പരിശോധിക്കുന്നതാണെന്നാണ്. പിന്നീട് ഹോക്ക് ഫിന്റിങ് വിവരങ്ങളുടെ വലിപ്പത്തിന്റെയും ഭാഷ തെരഞ്ഞെടുക്കുന്നതിനെയും കൂടുതല്\u200d നാം അന്വേഷിക്കുന്നു. ക്യൂഎ സിസ്റ്റം പരിശോധിക്കാന്\u200d വേണ്ട', 'no': 'Menneske kunnskap er kopla kodert i omtrent 6500 språk som er snakket rundt verden, men det er ikkje distribuert like på språk. For å søkja etter informasjonsspørsmålsystemet (QA) for å tilpassa opplesarar av alle språk, må dei fungera krysspråk. I dette arbeidet undersøker vi kapasiteten for fleire språk-modeller på krysspråk QA. Vi finn at uttrykkelig alignering av representasjonane på språk med ein post-hoc finetuning steg fører til forbetra utvikling. I tillegg undersøker vi effekten av datastorleiken, og språk-valet i denne finnstillingsstegen, og utgjer også ein dataset for evaluering av krysspråk QA-systemer.', 'mn': 'Хүн төрөлхтний мэдлэг дэлхий даяар ярьж байгаа 6500 хэл дээр нийтлэг шинэчлэгдсэн байна. Гэхдээ тэнцүү хэл дээр хуваагдахгүй. Иймээс, мэдээллийн асуулт олох (QA) системүүд нь бүх хэл дээрх илтгэгчид адилхан ажиллах хэрэгтэй. Энэ ажлын тулд бид олон хэл хэл загваруудын тухай олон хэл загваруудыг судалж байна. Бид хэл дээр илтгэлийг тодорхой хэлбэртэй холбогдох шатаар илтгэлийг сайжруулж чадна. Мөн бид өгөгдлийн хэмжээний нөлөөг, хэлний сонголтын нөлөөг судалж, мөн хэлний QA системийг батлах өгөгдлийн санг ашиглаж байна.', 'ro': 'Cunoașterea umană este codificată colectiv în aproximativ 6500 de limbi vorbite în întreaga lume, dar nu este distribuită în mod egal între limbi. Prin urmare, pentru ca sistemele de răspuns la întrebări de căutare a informațiilor (QA) să servească în mod adecvat vorbitorilor de toate limbile, acestea trebuie să funcționeze în mod translingv. În această lucrare investigăm capacitățile modelelor lingvistice pre-instruite în mai multe limbi în ceea ce privește calitatea interlingvă. Considerăm că alinierea explicită a reprezentărilor între limbi cu o etapă de finărire post-hoc duce, în general, la o performanță îmbunătățită. În plus, investigăm efectul dimensiunii datelor, precum și alegerea limbii în această etapă de reglare fină, lansând, de asemenea, un set de date pentru evaluarea sistemelor de calitate interlingvistică.', 'pl': 'Wiedza ludzka jest zbiorowo zakodowana w około 6500 językach używanych na całym świecie, ale nie jest ona równomiernie rozprowadzana w różnych językach. W związku z tym, aby systemy odpowiedzi na pytania poszukujące informacji (QA) mogły odpowiednio obsługiwać mówców wszystkich języków, muszą one działać między językami. W niniejszej pracy badamy możliwości wielojęzycznie uprzednio przeszkolonych modeli językowych na wielojęzyczne QA. Uważamy, że wyraźne dostosowanie reprezentacji w różnych językach z etapem dopracowania po hoc generalnie prowadzi do poprawy wydajności. Dodatkowo badamy wpływ wielkości danych oraz wyboru języka w tym kroku dostrajania, a także udostępniamy zbiór danych do oceny wielojęzycznych systemów jakości.', 'sr': 'Ljudsko znanje je kolektivno kodirano na oko 6500 jezika koji se govore širom svijeta, ali ne širi se jednako na jezicima. Stoga, za odgovor na pitanja koji traže informacije (QA) za odgovarajuće sisteme za odgovarajuće službe govornicima svih jezika, moraju raditi preko jezika. U ovom poslu istražujemo mogućnosti multijezičkih modela jezika na preko jezika QA. Nalazimo da se pojasno uključivanje predstavljanja na jezike sa posthočnim korakom finetuniranja obično vodi do poboljšanog izvođenja. Dodatno istražujemo učinak veličine podataka, kao i izbor jezika u ovom koraku za finaliziranje, također objavljujući set podataka za procjenu međujezičkih QA sistema.', 'si': 'මිනිස්සු දන්නවය සාමාන්\u200dයයෙන් සංකේතය කරලා තියෙන්නේ ලෝකයේ වලින් කතා කරපු භාෂාවල් 6500 වලින්, ඒත් ඒක සම ඉතින්, තොරතුරු හොයාගන්න ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්න (QA) පද්ධතියට හැම භාෂාවක්ම ප්\u200dරශ්නයක්ම සේවා කරන්න, ඔවුන මේ වැඩේ අපි පරීක්ෂා කරනවා විශේෂ භාෂාත්මක භාෂාත්මක විශේෂ කරපු භාෂාත්මක විශේෂ කරනවා. අපිට හොයාගන්න පුළුවන් විශේෂයෙන් භාෂාවල් වලින් ප්\u200dරතිචාරයක් සම්පූර්ණයෙන් සම්පූර්ණයෙන් ප්\u200dරත අපි තවත් දත්ත ප්\u200dරමාණයේ පරීක්ෂණය සහ භාෂාව තෝරාගන්නේ මේ විශේෂ ප්\u200dරමාණයේ තෝරාගන්න, ඒ වගේම දත්ත සැටියක් ප්\u200dරතික්\u200d', 'so': "Aqoonta dadku waxay ku qoran yihiin qiyaastii 6500 luqadood oo lagu hadlo dunida oo dhan, laakiin si isku mid ah looma kala qaybiyo luuqadaha. Sidaa darteed waxaa loo baahan yahay in ay si ku filan ugu adeegaan luuqadaha oo dhan ku hadlaan jawaabta su'aalaha macluumaadka raadinta (QA). In this work we investigate the capabilities of multilingually pretrained language models on cross-lingual QA.  Waxaynu helnaa in si cad loo sawiriyo muuqashada luuqadaha oo dhan ay ku leedahay tallaabooyin kordhaya dabaqada hooyo-horaadka. Sidoo kale waxaynu u baaraynaa saamaynta macluumaadka iyo doorashada luuqada oo ku qoran tallaabistan sawir ah, waxaana sidoo kale u baaraynaa sawirada lagu qiimeeyo nidaamka luqada QA.", 'sv': 'Mänsklig kunskap kodas kollektivt på ungefär 6500 språk som talas runt om i världen, men den är inte lika fördelad över språk. För att system för informationssökande frågesvar ska kunna betjäna talare på alla språk på ett tillfredsställande sätt måste de därför fungera tvärspråk. I detta arbete undersöker vi möjligheterna hos flerspråkigt förkränade språkmodeller på tvärspråkig QA. Vi finner att en explicit anpassning av representationer över språk med ett post-hoc finjusteringssteg generellt leder till förbättrad prestanda. Dessutom undersöker vi effekten av datastorlek och språkval i detta finjusterande steg, och släpper också en datauppsättning för utvärdering av flerspråkiga QA-system.', 'ta': 'மனித அறிவு குறியீட்டாக்கப்பட்டுள்ளது உலகில் முழுவதும் 6500 மொழிகளில், ஆனால் அது சமமான மொழிகளில் பங்கிடப்படவில்லை. அதனால், தகவல் தேடும் கேள்வி பதில் (QA) அமைப்புகளுக்கு, அனைத்து மொழிகளின் பேச்சாளர்களுக்கும் போதுமான சேவைப்பாட்டாளர்களை  இந்த வேலையில் நாம் பல மொழிகளில் மொழி மாதிரி மாதிரிகளின் தேவைகளை ஆய்வு செய்கிறோம். கியூஏ மொழியில் உள்ள ம நாம் கண்டுபிடிக்க வேண்டும் என்று தெளிவாக மொழிகளில் உள்ள பிரதிநிதிகளை ஒழுங்குபடுத்துவது ஒரு பின்சோக்கி முடிவ நாம் கூடுதலாக தரவு அளவின் விளைவையாட்டையும் இந்த நன்று தூண்டும் படியில் மொழி தேர்வுகளையும் தேர்வு செய்கிறோம், கியூஏ முறைமைகள', 'ur': 'انسان کا علم جمع ہوتا ہے جو دنیا میں لکھی ہوئی 6500 زبانوں میں اکڈ کر دی جاتی ہے، لیکن یہ زبانوں میں برابر طرح تقسیم نہیں کی جاتی۔ لہٰذا، تمام زبانوں کی سخنرانی کرنے کے لئے (QA) سؤال کے جواب دینے کے لئے ان کی ضرورت کرتی ہے کہ ان کو کلاس زبان سے کام کریں۔ ہم اس کام میں تحقیق کریں گے کہ کئی زبان کے متوسط QA پر بہت سی زبان مدل کے قابلیت ہیں۔ ہمیں یہ معلوم ہے کہ زبانوں میں نمائندوں کو پوسٹ-هوک فینٹونگ سٹم کے ذریعے مضبوط طور پر سیدھی عملکرد کی طرف لے جاتا ہے۔ ہم اضافہ سے ڈیٹا سائز کے اثر اور اس پاکیزہ تنظیم سٹم میں زبان کا انتخاب کرنے کے لئے بھی تحقیق کرتے ہیں، اور کروس زبان کے QA سیستموں کے مطابق ایک ڈیٹ سٹ کو بھی آزاد کرتا ہے.', 'uz': "Inson haqida bir necha dunyoning dunyo bo'lgan 6500 tilda kodlash mumkin, ammo bu huddi tillarda teng tarqatish emas. Шундай қилиб, маълумот талаб қилинадиган саволлар жавоб бериш (QA) системаҳои барча тиллар tildagi tillarga yetarli xizmatlarni ishlab chiqarish kerak. Bu ishda biz ko'pchilik tildagi modellarning qobiliyatini o'rganamiz. Biz o'ylaymiz, har bir necha bir necha qadamni ko'rsatish oddiy tilni o'rganishni ko'rsatganimiz oddiy o'zgarishga ega bo'ladi. Biz qo'shimcha maʼlumot oʻlchamining effektini va bu yaxshi tugmalar birikmasida o'rganamiz va QA tizimini qiymatish uchun maʼlumot etishni o'rganamiz.", 'vi': 'Kiến thức con người được tích hợp trong ngôn ngữ gần 6500 khắp thế giới, nhưng nó không được phân phối ngang nhau trong các ngôn ngữ. Cho nên, để hệ thống trả lời câu hỏi dễ thông tin (QA) có thể cung cấp đầy đủ cho người phát ngôn ngữ, họ cần phải hoạt động ngôn ngữ khác nhau. Chúng tôi nghiên cứu khả năng của các mô- đun ngôn ngữ ngữ được xếp trước nhiều thứ về QA ngôn ngữ khác nhau. Chúng tôi thấy việc hợp các biểu tượng của ngôn ngữ qua một bước tinh chỉnh thời gian sau kỳ thường dẫn đến hiệu suất tốt hơn. Chúng tôi cũng nghiên cứu các hiệu ứng của kích thước dữ liệu cũng như ngôn ngữ lựa chọn trong bước độ cẩn thận này, cũng đưa ra một tập tin dữ liệu để đánh giá hệ thống QA chéo ngôn ngữ.', 'bg': 'Човешкото знание е колективно кодирано на около 6500 езика, говорени по целия свят, но не е разпределено равномерно между езиците. Следователно, за да могат системите за търсене на информация да обслужват адекватно говорителите на всички езици, те трябва да работят междуезично. В тази работа се изследват възможностите на многоезични предварително обучени езикови модели за междуезично качество. Установяваме, че изричното подравняване на представителствата между езиците с стъпка за фина настройка обикновено води до подобрена производителност. Освен това изследваме ефекта от размера на данните, както и избора на език в тази стъпка за фина настройка, като публикуваме набор от данни за оценка на междуезичните системи за контрол на качеството.', 'da': 'Menneskelig viden er kollektivt kodet på de omkring 6500 sprog, der tales rundt om i verden, men den er ikke fordelt ligeligt på tværs af sprog. For at informationssøgende spørgsmålsbesvarelsessystemer skal kunne betjene alle sprogtalere på passende vis, skal de fungere på tværs af sprog. I dette arbejde undersøger vi mulighederne for flersprogede prætrænede sprogmodeller på tværsproget QA. Vi finder ud af, at en eksplicit tilpasning af repræsentationer på tværs af sprog med et post-hoc finjusteringstrin generelt fører til forbedret ydeevne. Vi undersøger desuden effekten af datastørrelse samt sprogvalget i dette finjusterende trin og frigiver også et datasæt til evaluering af tværsprogede QA-systemer.', 'de': 'Menschliches Wissen ist kollektiv in den rund 6500 Sprachen codiert, aber es ist nicht gleichmäßig auf Sprachen verteilt. Damit Informationssuchende Fragebeantworungssysteme (QA) Sprecher aller Sprachen angemessen bedienen können, müssen sie daher sprachübergreifend arbeiten. In dieser Arbeit untersuchen wir die Möglichkeiten von mehrsprachig vortrainierten Sprachmodellen für sprachübergreifende Qualitätssicherung. Wir finden, dass die explizite Ausrichtung der Repräsentationen über Sprachen hinweg mit einem post-hoc Finetuning Schritt in der Regel zu einer verbesserten Performance führt. Zusätzlich untersuchen wir in diesem Feinabstimmungsschritt den Einfluss der Datengröße sowie die Sprachwahl und veröffentlichen einen Datensatz zur Auswertung von sprachübergreifenden QS-Systemen.', 'nl': 'Menselijke kennis is collectief gecodeerd in de ongeveer 6500 talen die over de hele wereld gesproken worden, maar het is niet gelijkmatig verdeeld over talen. Daarom moeten informatiezoekende vragenbeantwoordingssystemen (QA) meertalig werken om sprekers van alle talen adequaat te bedienen. In dit werk onderzoeken we de mogelijkheden van meertalig voorgetrainde taalmodellen op cross-lingual QA. We merken dat het expliciet afstemmen van de representaties in verschillende talen met een post-hoc finetuning stap over het algemeen leidt tot verbeterde prestaties. Daarnaast onderzoeken we het effect van de datagrootte en de taalkeuze in deze fine-tuning stap, waarbij we ook een dataset vrijgeven voor het evalueren van meertalige QA systemen.', 'hr': 'Ljudsko znanje je kolektivno kodirano na oko 6500 jezika koji se govore širom svijeta, ali se ne širi jednako na jezicima. Stoga, za odgovor na pitanje koje traže informacije (QA) sustave za odgovarajuće odgovornosti na odgovarajuće službe govornicima svih jezika, moraju raditi preko jezika. U ovom poslu istražujemo mogućnosti multijezičkih modela na međujezičkim QA-ima. Nalazimo da se pojasno uključivanje predstavljanja na jezicima s posthočnim korakom finetuniranja obično vodi do poboljšanog učinka. Dodatno istražujemo učinak veličine podataka, kao i izbor jezika u ovom koraku za finaliziranje, također objavljujući komplet podataka za procjenu međujezičkih QA sustava.', 'ko': '인류의 지식은 전 세계 약 6500개 언어로 공통적으로 인코딩되어 있지만 서로 다른 언어 간의 분포는 불균형적이다.따라서 정보탐구문답(QA) 시스템이 모든 언어의 사용자에게 충분히 서비스를 제공하기 위해서는 다중 언어 조작이 필요하다.이 작업에서 우리는 다중 언어의 예훈련 언어 모델이 다중 언어 문답에서의 능력을 연구했다.우리는 후기의 미세한 조정 절차를 통해 서로 다른 언어 사이를 현저하게 정렬하여 표시하면 통상적으로 성능을 향상시킬 수 있다는 것을 발견하였다.이 미세 조정 단계에서 우리는 데이터 크기와 언어 선택의 영향을 연구했고 크로스 언어 QA 시스템을 평가하는 데이터 집합을 발표했다.', 'fa': 'دانش انسان در حدود 6500 زبان در سراسر جهان صحبت می\u200cشود، ولی به طور مساوی در زبانها تقسیم نمی\u200cشود. به همین دلیل، برای پاسخ دادن سؤال\u200cجواب (QA) از اطلاعات برای مناسب خدمت کردن صحبت\u200cکنندگان از همه زبانها، آنها باید با زبان\u200cهای مختلف عمل کنند. در این کار ما توانایی مدل های زبانی زیادی را بر روی QA متوسط زبان تحقیق می کنیم. ما فهمیدیم که توضیح توضیح نمایش\u200cهای زبان\u200cها را با یک قدم بعد از هوک تغییر دهنده\u200cای به عمومی به انجام\u200cدهنده\u200cی بهتر می\u200cرساند. ما اضافه\u200cای از تاثیر اندازه داده\u200cها و انتخاب زبان در این قدم تنظیم\u200cکننده\u200cای تحقیق می\u200cکنیم، همچنین یک مجموعه داده\u200cها برای ارزیابی سیستم\u200cهای QA متوسط زبان استفاده می\u200cکنیم.', 'tr': 'Adamlar bilgi d체n첵채de g체rle힊첵채n 6500 dilde bir yerde kodlanma첵ar, 첵철ne bu diller birbirine e힊it dillerde pa첵lanma첵ar. 힇ol seb채pli, informasi첵a g철zle첵채n soraglar (QA) sistemalary 체챌in 채hli dilleri흫 s철zlerini adalat hizmet etmek 체챌in olara 챌arpaz dilli i힊lemek gerek. Bu i힊de biz 챌er챌e dilli QA-da 챌oklu dilli nusgalary흫 m체mkin챌iligini incele첵채ris. Biz diller arasyndaky suratlaryny post hoc finetuning ad캇mlary bilen belli edip g철r첵채ris. Umumy bolsa gowurak etm채ge yol a 챌ar. Biz daty ululykny흫 t채sirini we dil sa첵lamagyny hem bu dogry d체zeltmek ad캇nda soru힊첵arys, we bu dillerden cross-lingual QA sistemlerini de흫lemek 체챌in bir dataseti 챌ykar첵arys.', 'id': 'Pengetahuan manusia dikodeksi secara kolektif dalam sekitar 6500 bahasa yang dibicarakan di seluruh dunia, tetapi tidak disebarkan secara sama di seluruh bahasa. Oleh karena itu, untuk sistem pencarian informasi menjawab pertanyaan (QA) untuk melayani pembicara dari semua bahasa, mereka perlu beroperasi secara melintasi bahasa. Dalam pekerjaan ini kami menyelidiki kemampuan dari model bahasa berbagai bahasa yang dilatih sebelum dilatih pada QA saling bahasa. Kami menemukan bahwa secara eksplicit menyesuaikan representation di seluruh bahasa dengan langkah post-hoc penentuan umumnya menyebabkan prestasi yang lebih baik. Kami tambahan menyelidiki efek ukuran data dan pilihan bahasa dalam langkah penyesuaian ini, juga melepaskan set data untuk mengevaluasi sistem QA saling bahasa.', 'sw': 'Ufahamu wa binadamu umewekwa kwa pamoja katika lugha takriban 6500 zinazozungumzwa duniani kote, lakini haisambazwa kwa usawa katika lugha mbalimbali. Kwa hiyo, kwa mfumo wa kutafuta maswali (QA) wa kuwatumia lugha zote za kutosha, wanahitaji kufanya kazi kwa lugha mbalimbali. Katika kazi hii tunachunguza uwezo wa mifano ya lugha mbalimbali iliyopigwa katika lugha mbalimbali ya QA. Tunapata kwamba kuwaweka wazi uwakilishi katika lugha mbalimbali kwa hatua ya kupunguza baada ya ujumla unapelekea kuendeleza utendaji. We additionally investigate the effect of data size as well as the language choice in this fine-tuning step, also releasing a dataset for evaluating cross-lingual QA systems.', 'af': "Mense kennis is saamstig gekodeer in die omtrent 6500 taal wat rondom die wêreld praat, maar dit is nie gelyk versprei oor tale nie. Daarom, vir inligting soek vraag antwoord (QA) stelsels om die sprekkers van alle tale adequate te dien, moet hulle kruis-tale bestuur. In hierdie werk ondersoek ons die moontlikhede van multilinglike taal modele op kruistale QA. Ons vind dat die voorstellings met 'n post-hoc finetuning stap uitgelyk verlys het tot verbeterde prestasie. Ons ondersoek ook die effek van data grootte en die taal keuse in hierdie fyn-tuning stap, ook 'n datastel verlos vir die evaluering van kruistale QA stelsels.", 'am': 'የሰው እውቀት በዓለም ውስጥ 6500 ቋንቋዎች የሚናገሩት በአንድነት የተለየ ነው፤ ነገር ግን በአንድ ቋንቋ አይለያዩም፡፡ ስለዚህም የመረጃ ጥያቄ መልስ (QA) ስርዓቶች በቋንቋዎች ሁሉ ቋንቋዎችን ለማገልገል ያስፈልጋሉ በመስመር ቋንቋ ማቆየት ያስፈልጋል፡፡ በዚህ ስራ የቋንቋ ቋንቋ ቋንቋ ላይ የቋንቋ ምሳሌዎችን ለመፍጠር እናደርጋለን፡፡ በቋንቋዎች ያሉትን መልዕክቶች በተለየ ግልፅ በማድረግ እናገኛለን፡፡ የዳታ መጠን እና የቋንቋውን ምርጫዎች በዚህ መልካም ደረጃ ውስጥ እና የቋንቋ ምርጫዎችን እናሳውቃለን፡፡', 'az': 'İnsan elmi dünyanın ətrafında danışan 6500 dillərdə birlikdə kodlandırılmışdır, amma bu dil eyni olaraq dillərdə dağılmışdır. Bütün dillərin danışanlarına uyğun tərzdə istifadə etmək üçün məlumat istəyən sual cevapları (QA) sistemləri üçün çox dilli işləmək lazımdır. Bu işdə biz çoxlu dil modellərinin çoxlu QA dillərinin qabaqlı modellərini incidirik. Biz dillərin tərzlərini post-hoc finetuning adımları ilə a çıq-aydın tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə göstəririk. Biz həmçin in məlumatların böyüklüyünü və dil seçməsini də araşdırırıq, bu çox dilli QA sistemlərini değerləşdirmək üçün dağlar setini də yayındırırıq.', 'bn': 'সারা বিশ্বের প্রায় ৬৫০০ ভাষায় কথা বলা মানব জ্ঞান সম্মিলিতভাবে এনকোড করা হয়েছে, কিন্তু এটা সারা ভাষায় একই রকম বিতরণ করা  যার ফলে তথ্য অনুসন্ধানের প্রশ্নের উত্তর (কিউ এ) সিস্টেমের জন্য যথেষ্ট ভাষার ভাষার ভাষাকে সেবা করার জন্য তাদের ক্রাশ-ভা এই কাজে আমরা অনেক ভাষায় ভাষার ভাষার মডেলের ক্ষমতার তদন্ত করি কিউএ-এর উপর। আমরা দেখতে পাচ্ছি যে সারা ভাষার প্রতিনিধিদের প্রতিনিধিত্বের সাথে সাধারণত একটি পদক্ষেপের সাথে সাধারণত ভাষায় প্ আমরা আরো তথ্যের আকার এবং এই ভাষার পদক্ষেপে ভাষার বিনিময়ের প্রভাব অনুসন্ধান করি, কিউএ সিস্টেম ম মূল্যায়নের জন্য একটি ডাটাসেট প্রকাশ করি।', 'bs': 'Ljudsko znanje je kolektivno kodirano na oko 6500 jezika koji se govore širom svijeta, ali se ne distribuira jednako na jezicima. Stoga, za sustave odgovora na pitanje koje traže informacije (QA) da odgovaraju govornicima svih jezika, moraju raditi preko jezika. U ovom poslu istražujemo mogućnosti multijezičkih modela jezika na cross-lingual QA. Mi smatramo da se pojasno uključuje predstavljanja na jezicima sa posthočnim korakom finetuniranja obično dovede do poboljšanog izvođenja. Dodatno istražujemo učinak veličine podataka, kao i izbor jezika u ovom koraku za finaliziranje, također objavljujući komplet podataka za procjenu međujezičkih QA sustava.', 'sq': 'Njerëzit janë të koduar kolektivisht në rreth 6500 gjuhë të folura anembanë botës, por nuk shpërndahen në mënyrë të barabartë nëpër gjuhë. Për këtë arsye, për sistemet që përgjigjen pyetjeve për informacion për të shërbyer në mënyrë të përshtatshme folësit e të gjitha gjuhëve, ata duhet të veprojnë ndërgjuhësisht. Në këtë punë ne hetojmë aftësitë e modeleve gjuhësore të mësuara në mënyrë shumëgjuhëse në QA ndërgjuhëse. We find that explicitly aligning the representations across languages with a post-hoc finetuning step generally leads to improved performance.  Përveç kësaj ne hetojmë efektin e madhësisë së të dhënave si dhe zgjedhjen e gjuhës në këtë hap të përshtatshëm, duke lëshuar gjithashtu një sërë të dhënash për vlerësimin e sistemeve QA ndërgjuhësore.', 'cs': 'Lidské znalosti jsou kolektivně kódovány v zhruba 6500 jazycích mluvících po celém světě, ale nejsou rozděleny rovnoměrně mezi jazyky. Proto aby systémy odpovědí na otázky hledající informace (QA) dostatečně sloužily mluvčím všech jazyků, musí fungovat napříč jazyky. V této práci zkoumáme možnosti vícejazyčně předtrénovaných jazykových modelů na vícejazyčné QA. Zjišťujeme, že explicitní sladění reprezentací napříč jazyky s post-hoc krokem jemného ladění obecně vede ke zlepšení výkonu. Dále zkoumáme vliv velikosti dat a volby jazyka v tomto kroku jemného ladění a uvolňujeme datovou sadu pro hodnocení systémů kvality v různých jazycích.', 'ca': "El coneixement humà està codificat col·lectivament en aproximadament 6500 llengües parlades arreu del món, però no està distribuït igualment a les llengües. Per tant, per a que els sistemes de resposta a preguntes (QA) busquen informació serveixin adequadament als parlants de totes les llengües, necessiten funcionar de manera translingüística. En aquest treball investigam les capacitats dels models de llenguatge multilingüísticament pré-entrenats en QA translingüística. Trobem que alinejar explícitament les representacions entre les llengües amb un pas post-hoc d'ajustament generalment porta a millor rendiment. També investigam l'efecte de la mida de les dades i l'elecció de llenguatge en aquest pas d'ajustament, també alliberant un conjunt de dades per avaluar els sistemes QA translingües.", 'hy': 'Մարդկային գիտելիքը հավաքապես կոդավորված է մոտ 6500 լեզուներով, որոնք խոսում են ամբողջ աշխարհում, բայց դրանք հավասարապես չեն տարածվում լեզուների միջև: Hence, for information-seeking question answering (QA) systems to adequately serve speakers of all languages, they need to operate cross-lingually.  In this work we investigate the capabilities of multilingually pretrained language models on cross-lingual QA.  Մենք հայտնաբերում ենք, որ բացահայտորեն հավասարեցնելը լեզուների ներկայացումների միջև հետ-հոք փորձարկումների հետ ընդհանուր առմամբ հանգեցնում է բարելավված արդյունքների: Մենք նաև ուսումնասիրում ենք տվյալների չափսի ազդեցությունը, ինչպես նաև լեզվի ընտրությունը այս բարձրացման քայլի ընթացքում, ինչպես նաև արտադրում ենք տվյալների համակարգ, որպեսզի գնահատենք երկլեզվային QA համակարգերը:', 'et': 'Inimteadmised on kollektiivselt kodeeritud umbes 6500 keeles, mida räägitakse üle maailma, kuid neid ei jagata võrdselt keelte vahel. Seega peavad teabepõhised küsimustele vastamise süsteemid kõikide keelte kõnelejate piisavaks teenindamiseks toimima keeleüleselt. Käesolevas töös uurime mitmekeelselt väljaõpetatud keelemudelite võimalusi keeleülese kvaliteedi tagamisel. Leiame, et esituste selgesõnaline ühtlustamine keelte vahel järgneva täpsustamise etapiga toob üldiselt kaasa parema jõudluse. Lisaks uurime andmete suuruse ja keele valiku mõju selles peenhäälestuses, avaldades andmekogumi keeleüleste kvaliteedi tagamise süsteemide hindamiseks.', 'fi': 'Ihmistieto on kollektiivisesti koodattu noin 6500 kielellﾃ､, joita puhutaan ympﾃ､ri maailmaa, mutta se ei jakaudu tasaisesti eri kielille. Jotta tietoa hakevat kysymyksenvastausjﾃ､rjestelmﾃ､t palvelevat riittﾃ､vﾃ､sti kaikkien kielten puhujia, niiden on toimittava monikielisesti. Tﾃ､ssﾃ､ tyﾃｶssﾃ､ tutkitaan monikielisten esikoulutettujen kielimallien mahdollisuuksia monikieliseen laadunvarmistukseen. Havaitsemme, ettﾃ､ esitysten selkeﾃ､ yhdenmukaistaminen eri kielillﾃ､ post-hoc hienosﾃ､ﾃ､tﾃｶvaiheella johtaa yleensﾃ､ parempaan suorituskykyyn. Lisﾃ､ksi tutkimme datakoon vaikutusta ja kielivalintaa tﾃ､ssﾃ､ hienosﾃ､ﾃ､tﾃｶvaiheessa ja julkaisemme aineiston monikielisten laadunvarmistusjﾃ､rjestelmien arviointiin.', 'ha': "Sannin mutum na kodi kodi cikin taki 65000 harshen waɗanda aka yi magana a cikin duniya, kuma ba a raba shi da daidai a cikin harshen. Dõmin haka, don a samun tambayi masu tambaya (QA) na'ura, don su yi amfani da masu sha'awa da ke cikakken ayuka duk harshe, sai sun kamata su yi aiki a cikin fassarar-harshe. Daga wannan aikin da Muke jarraba awon misãlai na lugha masu baka mulki-talli a kan QA. Muna gane cewa, a sami taƙaita taƙaitãwa a cikin harshen kowane da wata taƙaita ta baka-hoc, ko da kawaici, yana iya ƙaranci taƙaitãwa. We additionally investigate the effect of data size as well as the language choice in this fine-tuning step, also releasing a dataset for evaluating cross-lingual QA systems.", 'he': 'הידע האנושי מוצפן באופן קולטיבי ב-6500 שפות מדברות ברחבי העולם, אך הוא לא מופיע באופן שווה דרך שפות. לכן, למען מערכות תשובות על שאלות מחפשות מידע (QA) כדי לשרת בהתאם את מדברים של כל השפות, הם צריכים לפעול בצורה דרך שפה. בעבודה הזו אנו חוקרים את היכולות של דוגמני שפות המואמנים מראש לשפה רבות על QA-שפות. אנו מוצאים שמתאים באופן ברור את היציגות ברחבי שפות עם צעד מתאים אחר-hoc בדרך כלל מוביל להופעה משתפרת. אנחנו חוקרים באופן נוסף את השפעה של גודל נתונים כמו גם את בחירת השפה בצעד התאמה המיוחד הזה, גם משחרר קבוצת נתונים להערכה מערכות QA בין שפות.', 'bo': 'འཛམ་གླིང་གི་སྐད་རིགས་ཀྱི་ནང་དུ་འཛམ་གླིང་ཐོག་ལས་ཀྱང་ཉིན་6500ཡིག་ཆ་གཅིག་སྒྲིག དེར་བརྟེན། ཆ་འཕྲིན་འཚོལ་བའི་དྲི་ཚིག་ལ་ལན་གསལ་བ(QA)མ་ལག་གི་ཆ་འཕྲིན་ཡིན་སྐད་རིགས་སྐད་ཡིག་གཏོང་པ་ཚོར་སྤྱོད་དགོ ང་ཚོས་གཞུང་འདིའི་ནང་དུ་སྐད་ཡིག་ཆ་ལའང་བའི་སྐད་རིགས་ཀྱི་མིང་དཔེ་དབྱེ་བ་དག་གི་ཆ་རྟོགས་བཙལ་ཞིབ་བྱེད། ང་ཚོས་སྐད་ཡིག འུ་ཚོས་གཞུང་གི་ཆེ་ཆུང་ཀྱི་དབྱེ་བ་དང་སྐད་ཀྱི་གདམ་ཀ་ཡིག་ཆ་ཀྱང་ཞིབ་བཤེར་བྱེད་ཀྱི་ཡོད།', 'sk': 'Človeško znanje je skupaj kodirano v približno 6500 jezikih, ki se govorijo po vsem svetu, vendar ni enako porazdeljeno med jeziki. Zato morajo sistemi za odgovarjanje na vprašanja, ki iščejo informacije, ustrezno služiti govornikom vseh jezikov, delovati medjezično. V tem delu raziskujemo zmožnosti večjezično predurjenih jezikovnih modelov na medjezičnem zagotavljanju kakovosti. Ugotavljamo, da izrecno usklajevanje predstavitev med jeziki z post-hoc korakom finega nastavitve na splošno vodi do izboljšane učinkovitosti. Dodatno preučujemo učinek velikosti podatkov in izbiro jezika v tem koraku natančnega nastavitve ter objavimo tudi nabor podatkov za ocenjevanje medjezičnih sistemov kakovosti.', 'jv': 'Awal sing wong liya sing nggawe gerangkat dhéwé kuwi nggawe gerangkat luwih kanggo awak kanggo awak dhéwé, maca kuwi nggawe barang langga kuwi. Kaya, kanggo nggunakake informasi-ngeneje sistem sing ngomong (KA) kang adalah kanggo seperakan kanggo langa kuwi, dheweke kudu opera uga-langa. Nang barêng-barêng iki, kéné ujian akeh kapan kanggo model sing luwih bantuan karo akeh lan luwih bantuan. Awak dhéwé ngerasah luwih-luwih nggawe pawarturan gar-luwih saben nggawe gerakan kanggo nggawe barang bantuan ingkang bantuan. Awak dhéwé nambah menehi sak cara-cara nggawe sistem dadi ngono nggawe langkung kanggo kuwi nggawe barang nggawe gerakan, meka bantayan dataset kanggo ngesalakno sistem yang luwih-luwih.'}
{'en': 'Semantic Answer Similarity for Evaluating Question Answering Models', 'pt': 'Semântica de Resposta Semântica para Avaliação de Modelos de Resposta a Perguntas', 'es': 'Similitud de respuestas semánticas para evaluar los modelos de respuesta', 'ar': 'تشابه الإجابات الدلالية لتقييم نماذج الإجابة على الأسئلة', 'fr': 'Similarité de réponse sémantique pour évaluer les modèles de réponse', 'hi': 'प्रश्न उत्तर मॉडल का मूल्यांकन करने के लिए शब्दार्थ उत्तर समानता', 'ja': '質問応答モデルを評価するためのセマンティックアンサーの類似性', 'zh': '评估问答模形语义答案相似性', 'ru': 'Сходство семантических ответов для оценки моделей ответов на вопросы', 'ga': 'Cosúlacht Freagra Shéimeantach maidir le Meastóireacht a dhéanamh ar Mhúnlaí Freagartha Ceist', 'el': 'Σημαντική ομοιότητα απάντησης για την αξιολόγηση μοντέλων απάντησης ερωτήσεων', 'ka': 'Semantic Answer Similarity for Evaluating Question Answering Models', 'hu': 'Szemantikus válasz hasonlóság a kérdésre válaszoló modellek értékeléséhez', 'it': 'Similitudine semantica per la valutazione dei modelli di risposta alle domande', 'kk': 'Сұрақ жауап беру үлгілерін оқу үшін семантикалық жауап ұқсастығы', 'lt': 'Semantinis atsakymų panašumas vertinant atsakymų į klausimus modelius', 'mk': 'Сличност на семантични одговори за евалуирање на моделите на одговори на прашања', 'ml': 'ചോദ്യങ്ങളുടെ ഉത്തരം മോഡലുകള്\u200d പരിശോധിക്കുന്നതിനുള്ള സെമാന്റിക് ഉത്തരം സമമാണ്', 'mt': 'Similarità Semantika tat-tweġibiet għall-Evalwazzjoni tal-Mudelli tat-tweġibiet għall-mistoqsijiet', 'ms': 'Sama-sama Jawapan Semantik untuk menilai Model Jawapan soalan', 'no': 'Semantisk svar liknande for evaluering av spørsmålssvarmodeller', 'pl': 'Podobieństwo odpowiedzi semantycznej do oceny modeli odpowiedzi na pytania', 'ro': 'Similaritate de răspuns semantic pentru evaluarea modelelor de răspuns la întrebări', 'si': 'ප්\u200dරශ්න ප්\u200dරතික්\u200dරියාත්මක විශ්වාස කරන්න සැමැන්තික ප්\u200dරතික්\u200dරියාත්මක වගේම', 'sr': 'Semantična sličnost odgovora za procjenu modela odgovora na pitanja', 'so': "Jawaabta Semantic Similarity of evaluating su'aalaha jawaabta", 'mn': 'Суулт хариултын загварыг тооцоолох Semantic Response Similarity for Evaluating Question Response Models', 'ta': 'கேள்வி பதில் மாதிரிகளை மதிப்பிடுவதற்கு செமான்டிக் விடையாகும்', 'sv': 'Semantisk svar Likhet för utvärdering av frågesvarsmodeller', 'ur': 'سؤال جواب مدل کے مطالب کے لئے سیمانٹی جواب سیمانٹی', 'uz': 'Name', 'vi': 'Hơi giống trả lời trung bình cho cách đánh giá câu hỏi', 'nl': 'Semantische antwoordgelijkenis voor het evalueren van modellen voor het beantwoorden van vragen', 'da': 'Semantisk svar Lighed til evaluering af spørgsmål besvarelse modeller', 'hr': 'Semantička sličnost odgovora za procjenu modela odgovora na pitanja', 'de': 'Semantische Answer Ähnlichkeit zur Bewertung von Fragebeantwortungsmodellen', 'ko': '퀴즈 모델의 의미 답안의 유사성을 평가하는 데 쓰인다', 'bg': 'Сходство със семантични отговори за оценка на моделите за отговор на въпроси', 'fa': 'شبیه پاسخ\u200cهای سطح برای ارزیابی مدل جواب سوال', 'sw': 'Jibu la Semantic Simplified for Evaluating Question Models Answering', 'tr': 'Sorag jogabat nusgasyny Taýýarlamak üçin Semantik jogabat', 'id': 'Semantic Answer Similarity for Evaluating Question Answering Models', 'af': 'Semantiese antwoord gelykbaarheid vir evaluering vraag antwoord model', 'am': 'መልስ', 'sq': 'Semantic Answer Similarity for Evaluating Question Answering Models', 'hy': 'Սեմանտիկ պատասխանների նմանությունը հարցերի պատասխանների մոդելների գնահատման համար', 'bs': 'Semantična sličnost odgovora za procjenu modela odgovora na pitanja', 'cs': 'Podobnost sémantické odpovědi pro hodnocení modelů odpovědi na otázky', 'az': 'sual cavab vermək modellərini değerləşdirmək üçün Semantik cavab oxuması', 'bn': 'প্রশ্নের উত্তর মোডেল মূল্যায়নের জন্য সেম্যান্ডিক উত্তর সমতা', 'fi': 'Semanttinen vastaus Samankaltainen kysymys vastausmallien arvioinnissa', 'ca': 'Similaritat Semàtica de Responsa per Evaluar Models de Responsa a Preguntes', 'et': 'Semantiline vastus Sarnasus küsimustele vastamise mudelite hindamisel', 'ha': '@ action', 'jv': 'Sampeyan Sampeyan kanggo Keusun Panjenengan', 'sk': 'Sementna podobnost odgovorov za ocenjevanje modelov za odgovore na vprašanja', 'bo': 'ཆ་མཚུངས་པའི་ལན་གསལ་ལྡན་རྟགས་ལྡན་བ། དྲི་ཚིག་ལན་གསལ་མཁན་མ་དབྱིབས', 'he': 'Semantic Answer Similarity for Evaluating Question Answering Models'}
{'en': 'The evaluation of question answering models compares ', 'ar': 'يقارن تقييم نماذج الإجابة على الأسئلة شروح الحقيقة الأرضية مع تنبؤات النموذج. ومع ذلك ، اعتبارًا من اليوم ، تعتمد هذه المقارنة في الغالب على المعجم ، وبالتالي تفقد الإجابات التي لا تحتوي على تداخل معجمي ولكنها لا تزال متشابهة لغويًا ، وبالتالي يتم التعامل مع الإجابات الصحيحة على أنها خاطئة. هذا التقليل من الأداء الحقيقي للنماذج يعيق قبول المستخدم في التطبيقات ويعقد المقارنة العادلة بين النماذج المختلفة. لذلك ، هناك حاجة إلى مقياس تقييم يعتمد على الدلالات بدلاً من تشابه السلسلة الخالصة. في هذه الورقة القصيرة ، نقدم SAS ، وهو مقياس قائم على التشفير المتقاطع لتقدير تشابه الإجابات الدلالية ، ومقارنته بسبعة مقاييس موجودة. تحقيقًا لهذه الغاية ، قمنا بإنشاء مجموعة بيانات تقييم مشروحة باللغتين الإنجليزية والألمانية تحتوي على أزواج من الإجابات جنبًا إلى جنب مع الحكم البشري على التشابه الدلالي ، والتي نصدرها جنبًا إلى جنب مع تنفيذ مقياس SAS والتجارب. نجد أن مقاييس التشابه الدلالي المستندة إلى نماذج المحولات الحديثة ترتبط بشكل أفضل بالحكم البشري من مقاييس التشابه المعجمية التقليدية في مجموعتي بيانات تم إنشاؤهما حديثًا ومجموعة بيانات واحدة من العمل ذي الصلة.', 'es': 'La evaluación de los modelos de respuesta a preguntas compara las anotaciones de la verdad del terreno con las predicciones del modelo. Sin embargo, a día de hoy, esta comparación se basa principalmente en el léxico y, por lo tanto, pierde respuestas que no tienen superposición léxica pero que siguen siendo semánticamente similares, por lo que las respuestas correctas se consideran falsas. Esta subestimación del rendimiento real de los modelos dificulta la aceptación de los usuarios en las aplicaciones y complica una comparación justa de los diferentes modelos. Por lo tanto, existe la necesidad de una métrica de evaluación que se base en la semántica en lugar de en la mera similitud de cadenas. En este breve artículo, presentamos SAS, una métrica basada en un codificador cruzado para la estimación de la similitud de respuestas semánticas, y la comparamos con siete métricas existentes. Con este fin, creamos un conjunto de datos de evaluación anotado de tres vías en inglés y alemán que contiene pares de respuestas junto con el juicio humano de su similitud semántica, que publicamos junto con una implementación de la métrica SAS y los experimentos. Encontramos que las métricas de similitud semántica basadas en modelos de transformadores recientes se correlacionan mucho mejor con el juicio humano que las métricas de similitud léxica tradicionales en nuestros dos conjuntos de datos recién creados y un conjunto de datos de trabajos relacionados.', 'pt': 'A avaliação de modelos de resposta a perguntas compara as anotações de verdade com as previsões do modelo. No entanto, a partir de hoje, essa comparação é principalmente baseada no léxico e, portanto, perde respostas que não têm sobreposição lexical, mas ainda são semanticamente semelhantes, tratando as respostas corretas como falsas. Essa subestimação do verdadeiro desempenho dos modelos dificulta a aceitação do usuário nas aplicações e dificulta uma comparação justa de diferentes modelos. Portanto, há a necessidade de uma métrica de avaliação que seja baseada em semântica em vez de pura similaridade de strings. Neste breve artigo, apresentamos o SAS, uma métrica baseada em cross-encoder para a estimativa de similaridade de resposta semântica, e a comparamos com sete métricas existentes. Para este fim, criamos um conjunto de dados de avaliação anotado em inglês e alemão em três vias contendo pares de respostas juntamente com julgamento humano de sua semelhança semântica, que liberamos juntamente com uma implementação da métrica SAS e os experimentos. Descobrimos que as métricas de similaridade semântica baseadas em modelos de transformadores recentes se correlacionam muito melhor com o julgamento humano do que as métricas tradicionais de similaridade lexical em nossos dois conjuntos de dados recém-criados e um conjunto de dados de trabalhos relacionados.', 'fr': "L'évaluation des modèles de réponse aux questions compare les annotations de la vérité de terrain aux prévisions des modèles. Cependant, à ce jour, cette comparaison est principalement basée sur le lexique et ne tient donc pas compte des réponses qui n'ont pas de chevauchement lexical mais qui sont toujours similaires sur le plan sémantique, ce qui permet de traiter les réponses correctes comme fausses. Cette sous-estimation de la performance réelle des modèles nuit à l'acceptation des applications par les utilisateurs et complique la comparaison équitable des différents modèles. Par conséquent, il est nécessaire de disposer d'une métrique d'évaluation basée sur la sémantique plutôt que sur la similarité de chaînes pure. Dans ce court article, nous présentons SAS, une métrique basée sur des encodeurs croisés pour l'estimation de la similitude des réponses sémantiques, et nous la comparons à sept métriques existantes. À cette fin, nous créons un jeu de données d'évaluation annoté en anglais et en allemand contenant des paires de réponses ainsi que le jugement humain de leur similitude sémantique, que nous publions avec une implémentation de la métrique SAS et les expériences. Nous trouvons que les mesures de similarité sémantique basées sur des modèles de transformateurs récents sont beaucoup mieux corrélées avec le jugement humain que les métriques de similarité lexicale traditionnelles sur nos deux ensembles de données nouvellement créés et un ensemble de données provenant de travaux connexes.", 'ja': '質問応答モデルの評価は、真実の注釈とモデル予測を比較する。 しかし、今日の時点では、この比較はほとんどが語彙に基づくものであり、したがって、語彙的に重複していないが、意味的に類似している答えを見逃しているため、正しい答えは誤りとして扱われます。 このモデルの真のパフォーマンスの過小評価は、アプリケーションでのユーザーの受け入れを妨げ、異なるモデルの公正な比較を複雑にします。 したがって、純粋な文字列類似性の代わりに意味論に基づいた評価指標が必要である。 この短い論文では、セマンティックアンサーの類似性を推定するためのクロスエンコーダベースの指標であるSASを提示し、既存の7つの指標と比較します。 この目的のために、私たちは英語とドイツ語の3方向注釈付き評価データセットを作成します。このデータセットには、セマンティック類似性の人間による判断とともに、回答のペアが含まれています。これは、SASメトリックと実験の実装とともにリリースされます。 最近の変圧器モデルに基づく意味論的類似性指標は、関連する研究から得られた2つの新しく作成されたデータセットと1つのデータセットの従来の語彙的類似性指標よりも、人間の判断とはるかに良好に相関していることがわかりました。', 'hi': 'प्रश्न का उत्तर देने वाले मॉडल का मूल्यांकन मॉडल भविष्यवाणियों के साथ जमीनी-सत्य एनोटेशन की तुलना करता है। हालांकि, आज के रूप में, यह तुलना ज्यादातर लेक्सिकल-आधारित है और इसलिए उन उत्तरों को याद करती है जिनमें कोई लेक्सिकल ओवरलैप नहीं है, लेकिन अभी भी शब्दार्थ रूप से समान हैं, इस प्रकार सही उत्तरों को गलत मानते हैं। मॉडल के सच्चे प्रदर्शन का यह कम करके आंकना अनुप्रयोगों में उपयोगकर्ता स्वीकृति में बाधा डालता है और विभिन्न मॉडलों की उचित तुलना को जटिल बनाता है। इसलिए, एक मूल्यांकन मीट्रिक की आवश्यकता है जो शुद्ध स्ट्रिंग समानता के बजाय शब्दार्थ पर आधारित है। इस छोटे से पेपर में, हम एसएएस, शब्दार्थ उत्तर समानता के अनुमान के लिए एक क्रॉस-एनकोडर-आधारित मीट्रिक प्रस्तुत करते हैं, और इसकी तुलना सात मौजूदा मीट्रिक से करते हैं। इस अंत तक, हम एक अंग्रेजी और एक जर्मन तीन-तरफ़ा एनोटेट मूल्यांकन डेटासेट बनाते हैं जिसमें उनके शब्दार्थ समानता के मानव निर्णय के साथ-साथ उत्तरों के जोड़े होते हैं, जिसे हम एसएएस मीट्रिक और प्रयोगों के कार्यान्वयन के साथ जारी करते हैं। हम पाते हैं कि हाल के ट्रांसफॉर्मर मॉडल के आधार पर शब्दार्थ समानता मीट्रिक हमारे दो नए बनाए गए डेटासेट और संबंधित काम से एक डेटासेट पर पारंपरिक लेक्सिकल समानता मीट्रिक की तुलना में मानव निर्णय के साथ बेहतर सहसंबंधित हैं।', 'ru': 'Оценка моделей ответов на вопросы сопоставляет аннотации "земля-правда" с прогнозами моделей. Однако на сегодняшний день это сравнение в основном основано на лексике и поэтому упускает ответы, которые не имеют лексического перекрытия, но все еще семантически схожи, таким образом рассматривая правильные ответы как ложные. Такая недооценка реальных характеристик моделей затрудняет принятие пользователей в приложениях и затрудняет справедливое сравнение различных моделей. Поэтому существует потребность в оценочной метрике, основанной на семантике, а не на чисто строковом сходстве. В этой короткой статье мы представляем SAS, метрику, основанную на кросс-кодере, для оценки сходства семантических ответов и сравниваем ее с семью существующими метриками. С этой целью мы создаем трехсторонний оценочный набор данных на английском и немецком языках, содержащий пары ответов наряду с человеческим суждением об их семантическом сходстве, который мы выпускаем вместе с реализацией метрики SAS и экспериментами. Мы обнаружили, что семантические метрики сходства, основанные на последних моделях трансформаторов, гораздо лучше коррелируют с человеческим суждением, чем традиционные лексические метрики сходства на наших двух недавно созданных наборах данных и одном наборе данных из связанной работы.', 'zh': '问模质将本事注与模测相较。 然截至今日,较之大较于词汇,故过无词汇重叠而语义相似者,以为非是。 此对模型真性之低估阻矣用户于应用程序之接受度,而使平比较变得复杂。 故须一本于语义而非纯字符串相似性之评指标。 此篇短论,介于SAS,盖交编码器之指标,以度语义对相似性,校之七指标。 创一英语、德语三注评估数集,其对案及人语义相似性,与SAS指标、实验俱发。 吾见最新变压器之语义相似性指标与人决者相关性贤于二新之数集与一相关者词汇相似性指标相关性多矣。', 'ga': 'Déanann an mheastóireacht ar shamhlacha freagartha ceisteanna comparáid idir nótaí bunfhírinne agus tuar na samhla. Mar sin féin, sa lá atá inniu ann, tá an chomparáid seo bunaithe ar fhoclóireacht den chuid is mó agus mar sin cailleann sí amach ar fhreagraí nach bhfuil aon fhorluí foclóireachta acu ach atá fós cosúil le séimeantach, rud a dhéileálann le freagraí cearta mar fhreagraí bréagacha. Cuireann an tearcmheastachán seo ar fhíorfheidhmíocht na samhlacha bac ar ghlacadh úsáideoirí in iarratais agus cuireann sé casta ar chomparáid chothrom idir samhlacha éagsúla. Dá bhrí sin, tá gá le méadrach meastóireachta atá bunaithe ar shéimeantaic in ionad cosúlacht sreang íon. Sa pháipéar gairid seo, cuirimid SAS i láthair, méadrach tras-ionchódóra-bhunaithe chun cosúlacht fhreagra shéimeantach a mheas, agus cuirimid i gcomparáid é le seacht méadracht atá ann cheana féin. Chuige sin, cruthaímid tacar sonraí meastóireachta trí-bhealach anótáilte Béarla agus Gearmánach ina bhfuil péirí freagraí mar aon le breithiúnas daonna ar a gcosúlacht shéimeantach, a scaoilfimid mar aon le cur i bhfeidhm an mhéadrach SAS agus na turgnaimh. Faighimid amach go bhfuil comhghaol i bhfad níos fearr idir méadracht chosúlachta shéimeantach atá bunaithe ar mhúnlaí claochladán le déanaí agus breithiúnas an duine ná méadracht chosúlachtaí foclóireachta traidisiúnta ar ár dhá thacar sonraí nuachruthaithe agus tacar sonraí amháin ó obair ghaolmhar.', 'ka': 'კითხვის შესაბამისი მოდელების შესაბამისი შესაბამისი მოდელების შესაბამისია მოდელური წარმოდგენებით. მაგრამ, დღედან, ეს შემდგომარება ძალიან ლექსიკალური დაბათებული და ამიტომ არ უნდა წარმოდგომარება, რომლებიც ლექსიკალური შემდგომარები არაა, მაგრამ ისინი სმენტიკურად მ ეს მოდელების მართლა კეთესტაციას შეუძლებელია მომხმარებლის მიღებას პროგრამებში და შემდეგ განსხვავებული მოდელების მართლა შემდგომარება. ამიტომ, არსებობს უნდა გავამუშაოთ მეტრიკის, რომელიც სენმანტიკის დაბაზიან, უფრო სტრიქონის სხვადასხვების ადგილად. ამ კონტაქტის წერტილში, ჩვენ SAS-ს გამოყენებთ, კრანტაქტიური კოდირებული მეტრიკი, რომელიც სემონტიური პასუხის განსაზღვრებისთვის, და ამას 7 მსგავსი მეტრიკისთვის შედგ ამისთვის, ჩვენ შევქმნით ანგლისური და გერმანური სამყარო მონაცემების მონაცემების სამყარო მონაცემები, რომლებიც ადამიანის სემონტიკური განსხვავება, რომელიც ჩვენ გახსნა SAS მეტრიკის და ექსპერ ჩვენ აღმოჩნეთ, რომ სემონტიკური განსხვავებულობა მეტრიკა, რომელიც ახლა განსხვავებული რენფორმენტრუმენტიკური მოდელებიდან ბაზიან, უფრო უკეთესია ადამიანის გადაწყვებაზე, ვიდრე ტრადიცი', 'hu': 'A kérdésre válaszoló modellek értékelése összehasonlítja az alap-igazság jegyzékeket a modell előrejelzéseivel. A mai naptól azonban ez az összehasonlítás többnyire lexikai alapú, ezért kihagyja azokat a válaszokat, amelyek nem rendelkeznek lexikai átfedéssel, de még mindig szemantikailag hasonlóak, így a helyes válaszokat hamisnak tekintik. A modellek valódi teljesítményének alulbecsülése akadályozza a felhasználók elfogadását az alkalmazásokban, és megnehezíti a különböző modellek tisztességes összehasonlítását. Ezért szükség van egy olyan értékelési metriára, amely szemantikán alapul a tiszta karakterlánc hasonlóság helyett. Ebben a rövid tanulmányban bemutatjuk a SAS-t, egy keresztkódoló alapú metrikát a szemantikai válaszok hasonlóságának becslésére, és összehasonlítjuk azt hét meglévő metrikával. Ennek érdekében létrehozunk egy angol és német, háromutas jegyzetelésű értékelési adatkészletet, amely válaszpárokat tartalmaz szemantikai hasonlóságukra vonatkozó emberi megítélésükkel, és amelyet a SAS metrika és a kísérletek implementációjával együtt kiadunk. Úgy találjuk, hogy a legutóbbi transzformátormodelleken alapuló szemantikai hasonlósági mutatók sokkal jobban korrelálnak az emberi ítélőképességgel, mint a hagyományos lexikális hasonlósági mutatók két újonnan létrehozott adathalmazunkon és egy kapcsolódó munkából származó adathalmazunkon.', 'el': 'Η αξιολόγηση των μοντέλων απάντησης σε ερωτήσεις συγκρίνει τις παρατηρήσεις επίγειας αλήθειας με τις προβλέψεις μοντέλων. Ωστόσο, από σήμερα, αυτή η σύγκριση βασίζεται κυρίως σε λεξικά και ως εκ τούτου παραλείπει απαντήσεις που δεν έχουν λεξική επικάλυψη αλλά εξακολουθούν να είναι σημασιολογικά παρόμοιες, αντιμετωπίζοντας έτσι τις σωστές απαντήσεις ως ψευδείς. Αυτή η υποτίμηση της πραγματικής απόδοσης των μοντέλων εμποδίζει την αποδοχή των χρηστών στις εφαρμογές και περιπλέκει τη δίκαιη σύγκριση των διαφορετικών μοντέλων. Ως εκ τούτου, υπάρχει ανάγκη για μια μέτρηση αξιολόγησης που βασίζεται στη σημασιολογία αντί για καθαρή ομοιότητα συμβολοσειρών. Σε αυτή τη σύντομη εργασία, παρουσιάζουμε μια μετρική βασισμένη σε διασταυρούμενους κωδικοποιητές για την εκτίμηση της ομοιότητας σημασιολογικών απαντήσεων, και τη συγκρίνουμε με επτά υπάρχουσες μετρήσεις. Για το σκοπό αυτό, δημιουργούμε ένα αγγλικό και ένα γερμανικό τριπλό σχολιασμένο σύνολο δεδομένων αξιολόγησης που περιέχει ζεύγη απαντήσεων μαζί με την ανθρώπινη κρίση της σημασιολογικής ομοιότητάς τους, το οποίο δημοσιεύουμε μαζί με την εφαρμογή της μετρικής και των πειραμάτων. Διαπιστώνουμε ότι οι σημασιολογικές μετρήσεις ομοιότητας που βασίζονται σε πρόσφατα μοντέλα μετασχηματιστών συσχετίζονται πολύ καλύτερα με την ανθρώπινη κρίση από τις παραδοσιακές μετρήσεις λεξικής ομοιότητας στα δύο πρόσφατα δημιουργημένα σύνολα δεδομένων μας και ένα σύνολο δεδομένων από σχετική εργασία.', 'it': "La valutazione dei modelli di risposta alle domande confronta le annotazioni della verità di base con le previsioni dei modelli. Tuttavia, ad oggi, questo confronto è prevalentemente lessicale e quindi manca risposte che non hanno sovrapposizioni lessicali ma sono ancora semanticamente simili, trattando così risposte corrette come false. Questa sottovalutazione delle reali prestazioni dei modelli ostacola l'accettazione da parte degli utenti nelle applicazioni e complica un equo confronto tra i diversi modelli. Pertanto, c'è bisogno di una metrica di valutazione basata sulla semantica invece che sulla somiglianza pura delle stringhe. In questo breve articolo, presentiamo SAS, una metrica basata su encoder incrociato per la stima della somiglianza semantica delle risposte, e la confrontiamo con sette metriche esistenti. A tal fine, creiamo un dataset di valutazione annotato a tre vie inglese e tedesco contenente coppie di risposte insieme al giudizio umano della loro somiglianza semantica, che rilasciamo insieme a un'implementazione della metrica SAS e degli esperimenti. Troviamo che le metriche di somiglianza semantica basate su modelli recenti di trasformatori correlano molto meglio con il giudizio umano rispetto alle metriche di somiglianza lessicale tradizionali sui nostri due set di dati appena creati e un set di dati provenienti da lavori correlati.", 'kk': 'Сұрақ жауап беру үлгілерінің бағалауы үлгілер үлгілерімен қалыптастырады. Бірақ бұл салыстыру көпшілігі лексикалық негіздеген, сондықтан, лексикалық жауаптары жоқ, бірақ әлі semantiкалық ұқсас болып тұрады, сондықтан дұрыс жауаптарды дұрыс деп тұрады. Бұл үлгілердің дұрыс істеуі қолданбаларда пайдаланушыларды қабылдауға көмектеседі және басқа үлгілерді салыстыруға көмектеседі. Сондықтан таза жолдар ұқсастығының орнына semantics негіздеген метрикалық бағалау керек. Бұл қысқақ қағазында, SAS-ді біріктіреміз, мектрикалық жауаптардың ұқсастығын бағалау үшін көпкодтағы метрикалық метрикалық, және оны жеті метрикалық метрикалық салыстырамыз. Бұл үшін біз ағылшынша және неміс үш жолдағы оқу деректерін құрамыз. Біз адамдардың семантикалық ұқсастылығының екі жауапты жауаптарды жазып, SAS метрикалық және эксперименттердің іске асырамыз. Біз жаңа түрлендіру үлгілеріне негізделген семантикалық ұқсастық метрикалық адамдардың оқиғаларына көп жақсы түрлендіру үлгілеріміздің екі жаңа құрылған деректер жиынында және бір деректер жиынынан қатына', 'lt': 'Vertinant atsakymo į klausimus modelius palyginamos antžeminės tiesos anotacijos su modelių prognozėmis. Tačiau nuo šiandien šis palyginimas daugiausia grindžiamas leksika, todėl netenka atsakymų, kurie neturi leksikos dubliavimo, tačiau vis dar semantiškai panašūs, todėl teisingi atsakymai vertinami kaip klaidingi. Šis nepakankamas tikrų modelių veiksmingumo vertinimas trukdo naudotojams priimti paraiškas ir apsunkina teisingą skirtingų modelių palyginimą. Todėl reikia vertinimo metrijos, pagrįstos semantika, o ne grynu string ų panašumu. In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing metrics.  Šiuo tikslu sukuriame anglų ir vokiečių trikrypčių anotuotų vertinimo duomenų rinkinį, kuriame pateikiamos poros atsakymų ir žmogaus nuomonė dėl jų semantinio panašumo, kurią paskelbiame kartu su SAS metrikos ir eksperimentų įgyvendinimu. Mes matome, kad semantiniai panašumo metriniai rodikliai, pagrįsti naujausiais transformatorių modeliais, gerokai geriau koreliuoja su žmogaus vertinimu nei tradiciniai tekstiniai panašumo metriniai rodikliai mūsų dviejuose naujai sukurtuose duomenų rinkiniuose ir viename susijusių darbų duomenų rinkinyje.', 'ml': 'ചോദ്യത്തിന്റെ ഉത്തരം മോഡലുകളുടെ വിലാസങ്ങള്\u200d ഭൂമിയിലെ സത്യസന്ദേശങ്ങള്\u200dക്ക് മോഡല്\u200d പ്രവചനങ്ങള്\u200dക്ക് താ എന്നാലും ഇന്നുമുതല്\u200d ഇതിന്റെ താല്\u200dപ്പര്യം മിക്കവാറും ലെക്സിക്കല്\u200d അടിസ്ഥാനമാണ്. അതുകൊണ്ട് ലെക്സിക്കല്\u200d മൂടുതല്\u200d ഉത്തരങ്ങള്\u200d ഇല്ലാത്ത മറുപടികള്\u200dക് This underestimation of the true performance of models hinders user acceptance in applications and complicates a fair comparison of different models.  അതുകൊണ്ട്, ശുദ്ധ സ്ട്രീങ്ങള്\u200dക്ക് പകരം സെമാന്റിക്സ് അടിസ്ഥാനമായി ഒരു വിലാസപ്രകാരം ആവശ്യമുണ്ട്. ഈ ചെറിയ പേപ്പറില്\u200d, ഞങ്ങള്\u200d SAS, ഒരു ക്രിസ്കോഡെര്\u200d അടിസ്ഥാനമായ മെട്രിക്ക് കാണിക്കുന്നു, സെമാന്റിക് ഉത്തരം ഒരുപോലെയാണെന്ന് വിചാ അതിനുശേഷം, ഞങ്ങള്\u200d ഒരു ഇംഗ്ലീഷ് സൃഷ്ടിക്കുന്നു. ഒരു ജര്\u200dമ്മന്\u200d മൂന്ന് വഴിയില്\u200d വിലപിക്കപ്പെട്ട മൂന്ന് വിവരങ്ങളുടെ ഡാറ്റാസെറ്റ് ഉണ്ടാക്കുന്നു. അതില്\u200d  നമ്മള്\u200d കണ്ടെത്തുന്നത് സമാധാനപൂര്\u200dണ്ണമായ മെട്രിക്കുകള്\u200d അടിസ്ഥാനമായി മാറ്റങ്ങളില്\u200d അടിസ്ഥാനമായിട്ടുണ്ടെങ്കില്\u200d നമ്മുടെ രണ്ട് പുതിയ ഡാറ്റാസ', 'mk': 'Оваа оценка на моделите за одговори на прашања ги споредува анотациите на земјата-вистината со моделните предвидувања. Сепак, од денес, оваа споредба е претежно лексикална и затоа недостасува на одговорите кои немаат лексикална прекривка, но се сé уште семантично слични, така што правилните одговори се третираат како лажни. Оваа потценка на вистинската перформанса на моделите го попречува прифаќањето на корисниците во апликациите и комплицира фер споредба на различните модели. Therefore, there is a need for an evaluation metric that is based on semantics instead of pure string similarity.  In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing metrics.  За оваа цел, создаваме англиски и германски тринасочен национален податок за евалуација кој содржи пар одговори заедно со човечкиот пресуд за нивната семантична сличност, кој го објавуваме заедно со спроведувањето на метриката на САС и експериментите. Најдовме дека семантичките метрики на сличност базирани на неодамнешните трансформаторски модели се корелираат многу подобро со човечкото судење отколку традиционалните метрики на лексикалната сличност на нашите две новоформирани податоци и еден податок од поврзаната работа.', 'mt': "L-evalwazzjoni tal-mudelli li jwieġbu għall-mistoqsijiet tqabbel l-annotazzjonijiet tal-ground-truth mal-previżjonijiet tal-mudelli. Madankollu, mill-lum 'l quddiem, dan it-tqabbil huwa bbażat l-aktar fuq il-lexiċi u għaldaqstant jonqos mit-tweġibiet li ma għandhom l-ebda sovrappożizzjoni lexika iżda li għadhom semantikament simili, u b'hekk it-tweġibiet korretti jiġu ttrattati bħala foloz. Din is-sottostima tal-prestazzjoni vera tal-mudelli tfixkel l-a ċċettazzjoni tal-utent fl-applikazzjonijiet u tikkumplika tqabbil ġust ta’ mudelli differenti. Għalhekk, hemm il-ħtieġa għal metrika ta’ evalwazzjoni bbażata fuq is-semantika minflok fuq similarità pura ta’ strings. F’din il-karta qasira, nippreżentaw SAS, metrika bbażata fuq il-cross-encoder għall-istima ta’ similarità ta’ risposta semantika, u nqabblu ma’ seba’ metriċi eżistenti. Għal dan il-għan, a ħna nħolqu sett ta’ dejta ta’ evalwazzjoni annotata bl-Ingliż u bil-Ġermanja bi tliet direzzjonijiet li jkun fih pari ta’ tweġibiet flimkien mal-ġudizzju uman tas-similarità semantika tagħhom, li nirrilaxxaw flimkien ma’ implimentazzjoni tal-metrika SAS u l-esperimenti. Aħna nsibu li metriċi semantiċi ta’ similarità bbażati fuq mudelli riċenti ta’ trasformaturi jikkorrelaw ħafna aħjar mal-ġudizzju uman milli metriċi tradizzjonali ta’ similarità lexika fuq iż-żewġ settijiet ta’ dejta li nħolqu reċentement tagħna u sett ta’ dejta wieħed minn xogħol relatat.", 'ms': 'Evaluasi model yang menjawab soalan membandingkan anotasi kebenaran-tanah dengan ramalan model. Bagaimanapun, mulai hari ini, perbandingan ini kebanyakan berdasarkan leksik dan oleh itu terlepas pada jawapan yang tidak mempunyai meliputi leksik tetapi masih semantik sama, menjaga jawapan yang betul sebagai palsu. Penghargaan rendah model sebenar ini menghalangi penerimaan pengguna dalam aplikasi dan rumit perbandingan yang adil bagi model yang berbeza. Oleh itu, ada perlukan metrik penilaian yang berdasarkan semantik selain daripada persamaan rentetan murni. Dalam kertas pendek ini, kita memperkenalkan SAS, metrik berdasarkan penyilang-pengekod untuk perhitungan persamaan jawapan semantik, dan membandingkannya dengan tujuh metrik yang wujud. To this end, we create an English and a German three-way annotated evaluation dataset containing pairs of answers along with human judgment of their semantic similarity, which we release along with an implementation of the SAS metric and the experiments.  Kami mendapati bahawa metrik perbandingan semantik berdasarkan model pengubah baru-baru ini berkorrelasi jauh lebih baik dengan penghakiman manusia daripada metrik perbandingan lexik tradisional pada dua set data yang baru dicipta kita dan satu set data dari kerja berkaitan.', 'no': 'Evalueringa av spørsmønsterelementet som svarar på spørsmønsteret samanliknar bakgrunnsannhetsnotasjonar med modelleforegåver. Dette sammenligninga er imidlertid mest på leksisk basert, og derfor går ut på svar som har ingen leksisk overlapp, men er fortsatt semantisk liknande, slik at rette svar er falsk. Denne underestimereringa av sann utvikling av modeller hindrar brukaren i programmet og kompliserer eit rett samanlikning av ulike modeller. Derfor er det ein måte for ein evalueringsmetrik som er basert på semantikk i staden for rein strenglikhet. I denne korte papiret presenterer vi SAS, eit kryskodebasert metrisk for estimerasjonen av semantiske svarlikhet, og sammenlignar det med sju eksisterande metrikar. I denne slutten oppretter vi eit engelsk og eit tysk trekant annoterart evalueringsdataset som inneheld par svar saman med menneske uttrykk av semantiske likhet, som vi løyser saman med ein implementering av SAS-metrikken og eksperimentene. Vi finn at semantiske similaritetsmetrikar basert på nyleg transformeringsmodeller korrelarer mykje bedre med menneske sprøym enn tradisjonelle leksiske similaritetsmetrikar på våre to nye lagde datasett og ein datasett frå relaterte arbeid.', 'mn': 'Хариултын загварыг хариулах асуултын үнэлгээ загварын таамаглалттай харьцуулдаг. Гэвч өнөөдөр энэ харьцуулалт ихэнхдээ лексикийн үндсэн учраас хэлэлцээгүй хариултуудыг алдагдаж байна. Гэхдээ энэ харьцуулалт үргэлж ихэнхдээ төстэй байдаг. Тиймээс зөв хариултыг худлаа хэлбэртэй гэж үз Энэ загварын жинхэнэ үйлдэл нь хэрэглэгчийн хэрэглэгчдийн хүлээн зөвшөөрөхөд өөр загварын зөв харьцуулалтыг төвөгтэй болгодог. Тиймээс цэвэр стринг тэнцүү байхын оронд семантик дээр суурилсан тооцоолох метрик хэрэгтэй. Энэ богино цаасан дээр бид SAS-г хэмжээний кодлогчийн төстэй метрик өгсөн бөгөөд 7 метрийг харьцуулж байна. Үүний тулд бид Англи, Герман гурван дахь дахь дүгнэлтийн өгөгдлийн санг бүтээж, хүний төрөлхтний төстэй шийдвэрлэлтэй хоёр хариултуудыг харуулдаг. Энэ нь SAS метрик болон туршилтуудын дасгал хөгжүүлэх боломжтой. Бид саяхан шинэчлэгч загварын үндсэн семантик төстэй метрик нь хүн төрөлхтний шүүмжлээсээ уламжлалтай лексикийн төстэй метрикийн хоёр шинэ бүтээгдсэн өгөгдлийн сангууд болон хамааралтай ажлын нэг өгөгдлийн сангууд', 'pl': 'Ocena modeli odpowiadających na pytania porównuje adnotacje gruntowe z przewidywaniami modeli. Na dziś jednak porównanie to jest w większości oparte na leksykalii i dlatego omija odpowiedzi, które nie mają nakładania się leksykalicznego, ale nadal są podobne semantycznie, traktując poprawne odpowiedzi jako fałszywe. To niedocenianie rzeczywistej wydajności modeli utrudnia akceptację użytkowników w aplikacjach i komplikuje uczciwe porównanie różnych modeli. W związku z tym istnieje potrzeba stosowania metryki oceny opartej na semantyce zamiast czystego podobieństwa łańcuchów. W niniejszym krótkim artykule przedstawiamy SAS, metrykę opartą na koderze krzyżowym do oszacowania podobieństwa odpowiedzi semantycznych i porównujemy ją z siedmioma istniejącymi metrykami. W tym celu tworzymy angielski i niemiecki trójkierunkowy zestaw danych oceniających zawierający pary odpowiedzi wraz z ludzką oceną ich semantycznego podobieństwa, który udostępniamy wraz z implementacją metryki SAS i eksperymentów. Odkrywamy, że wskaźniki podobieństwa semantycznego oparte na najnowszych modelach transformatorów korelują znacznie lepiej z ludzkim osądem niż tradycyjne wskaźniki podobieństwa leksykalnego na naszych dwóch nowo utworzonych zbiorach danych i jednym zbiorze danych z powiązanych prac.', 'ro': 'Evaluarea modelelor de răspuns la întrebări compară adnotările de la sol-adevăr cu predicțiile modelului. Cu toate acestea, de astăzi, această comparație este în mare parte bazată pe lexical și, prin urmare, ratează răspunsurile care nu au suprapunere lexicală, dar sunt încă semantic similare, tratând astfel răspunsurile corecte ca fiind false. Această subestimare a performanței reale a modelelor împiedică acceptarea utilizatorilor în aplicații și complică o comparație echitabilă a diferitelor modele. Prin urmare, este nevoie de o metrică de evaluare care se bazează pe semantică în loc de similitudine pură a șirurilor. În această lucrare scurtă, prezentăm SAS, o metrică bazată pe codare încrucișate pentru estimarea similitudinii răspunsurilor semantice, și o comparăm cu șapte metrice existente. În acest scop, creăm un set de date de evaluare adnotată în trei căi engleză și germană conținând perechi de răspunsuri împreună cu judecata umană a similarității lor semantice, pe care o lansăm împreună cu implementarea metricei SAS și a experimentelor. Considerăm că măsurătorile de similitudine semantică bazate pe modele recente de transformator corelează mult mai bine cu judecata umană decât măsurile tradiționale de similitudine lexicală pe cele două seturi de date nou create și un set de date din lucrările conexe.', 'sr': 'Procjena pitanja odgovarajućih modela uspoređuje oznake zemaljske istine sa predviđanjem modela. Međutim, od danas, ova usporedba je uglavnom na leksičkoj bazi i stoga propušta odgovore koje nemaju leksičke pretvaranje, ali su još semantički slične, tako da se tretiraju prave odgovore kao lažne. To podcjenjivanje pravog izvođenja modela ometa prihvatanje korisnika u aplikacijama i komplikuje fer usporedbu različitih modela. Stoga postoji potreba za procjenom metrika koja se temelji na semantici umjesto čistoj sličnosti žica. U ovom kratkom papiru predstavljamo SAS-u, metriku baziranu na krstokoderu za procjenu sličnosti semantičkog odgovora i uspoređujemo ga sa sedam postojećih metrika. Za taj cilj, stvorili smo engleski i njemački tri strane annotirani podaci o procjenama koji sadrže par odgovora zajedno sa ljudskim procenama o njihovoj semantičkoj sličnosti, koje oslobodimo zajedno sa provedbom SAS metrika i eksperimenata. Smatramo da semantička metrika sličnosti bazirana na nedavnim modelima transformatora mnogo bolje povezuje sa ljudskim procenama od tradicionalne leksičke sličnosti metrike na našim dvama novim stvaranjima kompeta podataka i jedan komplet podataka iz povezanih poslova.', 'sv': 'Utvärderingen av frågesvarsmodeller jämför marksanningsanateringar med modellförutsägelser. Men från och med idag är denna jämförelse mestadels lexikalbaserad och missar därför svar som inte har någon lexikal överlappning men som fortfarande är semantiskt likartade, och därmed behandlar korrekta svar som falska. Denna underskattning av modellernas verkliga prestanda hindrar användarnas acceptans i applikationer och komplicerar en rättvis jämförelse av olika modeller. Därför finns det ett behov av en utvärderingsmetod som baseras på semantik istället för ren strängslikhet. I denna korta uppsats presenterar vi SAS, ett korskodningsbaserat mätvärde för uppskattning av semantisk svarslimitation, och jämför det med sju befintliga mätvärden. För detta ändamål skapar vi en engelsk och tysk trevägskommenterad utvärderingsdata som innehåller par svar tillsammans med mänsklig bedömning av deras semantiska likhet, som vi släpper tillsammans med en implementering av SAS-metrin och experimenten. Vi finner att semantiska likhetsmätningar baserade på senaste transformatormodeller korrelerar mycket bättre med mänskligt omdöme än traditionella lexikala likhetsmätningar på våra två nyskapade datauppsättningar och en datauppsättning från relaterat arbete.', 'si': 'ප්\u200dරශ්න විශ්වාසයේ උත්තර දෙන්න ප්\u200dරශ්නය මොඩේල්ස් වලින් ප්\u200dරශ්නය- ඇත්ත විශ්වාසය සමග ප්\u200d නමුත්, අද වෙනුවෙන්, මේ සම්පූර්ණය ප්\u200dරමාණයක් ලෙක්සිකාලික විසිද්ධ වෙන්නේ ඒ වගේම ප්\u200dරතිචාරයක් නැති ප්\u200dරතිචාරයක් නැති  මේ මොඩේල් ඇත්ත ප්\u200dරමාණයේ ඇත්ත ප්\u200dරමාණයක් ප්\u200dරයෝජනයට ප්\u200dරතික්\u200dරීයාවක් ප්\u200dරතික්\u200dරීයාව අනුමාණය කරනවා ඒ වග ඉතින්, සිමැන්ටික් වලින් විශ්වාස කරන්න අවශ්\u200dයයක් තියෙනවා. මේ කොටස් පැත්තේ, අපි SAS වෙනුවෙන්, ක්\u200dරිස්කෝඩර් අධාරිත මෙට්\u200dරික් විදිහට සෙමැන්ටික් ප්\u200dරතික්\u200dරියාවක් සමාන්\u200dය විදිහට,  මේ අවසානයට, අපි ඉංග්\u200dරීසි සහ ජර්මන් තුන්වෙනි ප්\u200dරතිශ්නයක් නිර්මාණය කරනවා ජර්මාන් තුන්වෙනි ප්\u200dරතිශ්නයක් තියෙන්නේ ප්\u200dරතිශ්නයක් සම අපිට හොයාගන්න පුළුවන් විදියට සෙමැන්ටික් සාමාන්තික සාමාන්තික සාමාන්තික මෙට්\u200dරික්ස් විදියට අලුත් වෙනුවෙන් මිනිස්සු නිර්ධ', 'ta': 'கேள்வி பதில் அளிக்கும் மாதிரிகளின் மதிப்பு However, as of today, this comparison is mostly lexical-based and therefore misses out on answers that have no lexical overlap but are still semantically similar, thus treating correct answers as false.  Name ஆகையால், சுத்தமான சரத்திற்கு பதிலாக semantics அடிப்படையில் ஒரு மதிப்பீடு மெட்ரிக்கு தேவையுண்டு. இந்த சிறிய காகிதத்தில், SAS, ஒரு குறியீட்டு குறியீட்டு அடிப்படையிலான மெட்ரிக் காண்பிக்கிறோம், பெம்மென்டிக் விடையை சமமாக மத இந்த முடிவிற்கு, நாம் ஒரு ஆங்கிலம் மற்றும் ஒரு ஜெர்மன் மூன்று வழியில் குறிப்பிடப்பட்ட மதிப்பீட்டு தகவல் அமைப்பை உருவாக்குகிறோம், அதில் மனித விடைகள் இருக் சமீபத்தில் மாற்றும் மாதிரிகளை அடிப்படையில் அமைப்பு மெட்ரிக் கண்டுபிடிக்கும் போது மரபார்ந்த லெக்சியல் ஒப்பிடும் மெட்ரிக்களை விட மனித நிய', 'so': "Qiimeynta sameynta jawaabta su'aalaha waxaa la dhigi karaa warqadaha dhulka ee runta ah oo la sii sheegayo qaababka. Si kastaba ha ahaatee, tan iyo maantadan is-barbarka ah waa mid ku saleysan leksikal, sababtoo darteed wuu ka baabba'aa jawaabaha aan haysan marnaba dhibaato lexico laakiin weli way isku mid yihiin, sidaas darteed waxay u macaamiloodaan jawaabo saxda ah sida been oo kale. Qiimeynta sameynta rasmiga ah ayaa ka hor jeediya aqbalka isticmaalaha codsiga, wuxuuna sameynayaa isbarbardhigga tusaalooyin kala duduwan. Sidaa darteed waxaa loo baahan yahay qiimeynta metric oo ku saleysan semantika, taasoo a an ku habboonayn siman xadhig daahir ah. Qoraalkan gaaban waxaan soo wadaa SAS, taasoo ah metric ku qoran koocoder, qiimeynta jawaabta semantiki si siman, waxaana isbarbardhignaa todoba metric oo jira. Taas darteed waxaynu abuurnaa qoraal af Ingiriis ah iyo Jarmal saddex jid oo loo baahanayo oo ku jira jawaabo noocyo ah oo ku jira xukunka biniaadamka isku mid ah, kaas oo aynu ku sii daajinnaa si lagu sameeyo qoraalka SAS iyo imtixaanka. Waxaynu aragnaa in qaab u eg metric ku saabsan qaababka bedelka ee ugu dhow ay ku xiran yihiin xukunka biniaadamka oo ka fiican xukunka caadiga ah ee leksikada isku mid ah labadayada macluumaadka ee cusub ee la abuuray iyo hal macluumaad oo ka mid ah shaqo la xiriira.", 'ur': 'موڈل کے جواب دینے کے سوال کی ارزیابی موڈل کے مطابق زمینی حقیقت کی ارزیابی کے مطابق موڈل پیش بینی کے مطابق ہے. However, as of today, this comparison is mostly language-based and therefore missing answers that have no lexical overlap but are still semantically similar, thus treating correct answers as false. یہ موڈل کے حقیقی عملکرد کی کم آزمائش کاروبار کے قبول کرنے سے روکتی ہے اور مختلف موڈل کے مطابق عدالت کا مقایسہ کرتا ہے. لہٰذا، ایک ارزش میٹریک کے لئے ضرورت ہے جو پاک سیٹرینگ برابری کے بدلے سیمنٹریک پر بنیاد ہے. اس چھوٹے کاغذ میں ہم SAS کو پیش کرتے ہیں، ایک کروس کوڈر بنیاد متریک سیمنٹی جواب کے مطابق مطابق کے لئے، اور اسے سات موجود متریک کے مطابق مقایسہ کرتے ہیں۔ اس کے لئے ہم ایک انگلیسی اور ایک جرمانی تین طریقے کی ارزیابی ڈیٹ سٹ بناتے ہیں جو انسان کے سیمانٹی برابری کے ساتھ جواب دو جواب دیتے ہیں، جسے ہم SAS متریک اور آزمائش کی عملومات کے ساتھ چھوڑ دیتے ہیں. ہم دیکھتے ہیں کہ سیمانٹی سیمانٹی مٹریک جو اچھی تغییر مدل پر بنیاد ہے انسان کے فیصلہ سے بہت اچھی نسبت سنتی لکسیکلی سیمانٹی مٹریک سے زیادہ اچھی نسبت ہے جو ہمارے دو نئی ساختہ ڈیٹ سٹ اور ایک ڈیٹ سٹ رابطہ دار', 'uz': "Name Hozirda, bu nazarda ko'pchilik leksikal asosida emas va shunday qilib leksikal qopqo'shilmagan javoblarga yetishmaydi, lekin bunday o'xshash bo'lgan javoblarni o'xshash ko'rsatish mumkin. Name Shunday qilib, bu semantika asosida qiymati kerak, bu bog'liq satrning qiymatlarini oʻzgartirish mumkin. Bu qisqa qogʻozda, biz SAS, semantik javob qiymatiga qiymatlashning cross-kodlash asosida metrik, va ularni 7 mavjud metriklarga kamaytirish mumkin. Mana shu paytda biz ingliz tilini yaramiz va uchta yo'l Olmoncha qiymatlar maʼlumotlar tarkibini bir xil javoblar bilan boshlanamiz va biz SAS metric va tajribalarni bajarishni bajaramiz. Biz o'rganamiz, yangi ўзгартириш modellari asosida esa semantik huddi metrikalar bizning ikkinchi yangi yaratilgan maʼlumotlar tizimimizdagi bir maʼlumot va bog'liq ishdan bir maʼlumot yordamida inson xukunga juda yaxshi bog'langan.", 'vi': 'Bài đánh giá về các mô hình trả lời câu hỏi so sánh các chú thích Chân Lý với dự đoán mẫu. Tuy nhiên, từ ngày hôm nay, so sánh này hầu hết là từ ngữ, và do đó nó thiếu các câu trả lời không có sự gấp bội ngôn ngữ nhưng vẫn theo ngữ pháp tương tự, và đối với câu trả lời đúng là sai. Sự đánh giá thấp khả năng thực sự của mô hình gây cản trở người dùng chấp nhận ứng dụng và làm phức tạp việc so sánh công bằng với các mô hình khác nhau. Do đó, cần một thước đo đánh giá dựa trên ngữ pháp thay vì nét giống dây thuần khiết. Chúng tôi đưa ra một thước đo hiển thị bởi SAS, dựa trên mã hóa, để đánh giá nét giống nhau về các câu trả lời theo ngữ nghĩa, và so sánh nó với bảy âm lượng đã có. Chúng tôi tạo ra một bộ dữ liệu đánh giá bằng ba chiều Anh và Đức chứa đựng các câu trả lời, cùng với sự đánh giá về nét giống nhau của loài người, mà chúng tôi phát hành cùng với hệ thống đo mét SAS và thí nghiệm. Chúng tôi thấy rằng đo nét giống nhau cơ bản dựa trên các mô hình biến đổi gần đây phù hợp với phán đoán con người tốt hơn so với tỉ lệ mô phỏng ngôn ngữ của chúng tôi trên hai tập tin mới tạo ra và một bộ dữ liệu từ công việc liên quan.', 'da': 'Evalueringen af spørgsmålsbesvarelsesmodeller sammenligner jordsandhedsmærkninger med modelforudsigelser. Denne sammenligning er imidlertid pr. i dag for det meste leksikalsbaseret og går derfor glip af svar, der ikke har nogen leksikalsk overlapning, men stadig semantisk ligner hinanden, hvorved korrekte svar behandles som falske. Denne undervurdering af modellernes reelle ydeevne hindrer brugernes accept i ansøgninger og komplicerer en rimelig sammenligning af forskellige modeller. Derfor er der behov for en evalueringsmetric, der er baseret på semantik i stedet for ren streng lighed. I denne korte artikel præsenterer vi SAS, en cross-encoder-baseret metric til estimering af semantisk svarlighed, og sammenligner den med syv eksisterende metrics. Til dette formål skaber vi et engelsk og et tysk trevejs kommenteret evalueringsdatasæt indeholdende par svar sammen med menneskelig vurdering af deres semantiske lighed, som vi frigiver sammen med en implementering af SAS metric og eksperimenterne. Vi finder ud af, at semantiske lighedsmetrics baseret på nyere transformatormodeller korrelerer meget bedre med menneskelig dømmekraft end traditionelle leksikalske lighedsmetrics på vores to nyoprettede datasæt og et datasæt fra relateret arbejde.', 'nl': 'De evaluatie van vragenantwoordmodellen vergelijkt ground-truth annotaties met model voorspellingen. Echter, vanaf vandaag is deze vergelijking grotendeels lexicaal gebaseerd en mist daarom antwoorden die geen lexicale overlapping hebben maar toch semantisch vergelijkbaar zijn, waardoor correcte antwoorden als vals worden behandeld. Deze onderschatting van de werkelijke prestaties van modellen belemmert de acceptatie van gebruikers in toepassingen en bemoeilijkt een eerlijke vergelijking van verschillende modellen. Daarom is er behoefte aan een evaluatiemetric die gebaseerd is op semantiek in plaats van pure tekenovereenkomsten. In dit korte artikel presenteren we SAS, een cross-encoder-gebaseerde metric voor de schatting van semantische antwoorden gelijkenis, en vergelijken deze met zeven bestaande metrics. Hiertoe maken we een Engelse en een Duitse drieweg geanotateerde evaluatie dataset met antwoorden en menselijke beoordeling van hun semantische gelijkenis, die we samen met een implementatie van de SAS metric en de experimenten vrijgeven. We vinden dat semantische vergelijkingsmetrieken gebaseerd op recente transformatormodellen veel beter correleren met menselijk oordeel dan traditionele lexicale vergelijkingsmetrieken op onze twee nieuw gemaakte datasets en één dataset uit gerelateerd werk.', 'bg': 'Оценката на моделите за отговор на въпроси сравнява анотациите на истината с прогнозите на моделите. От днес обаче това сравнение е предимно лексикално базирано и следователно пропуска отговори, които нямат лексикално припокриване, но все още са семантично сходни, като по този начин третират правилните отговори като неверни. Това подценяване на действителните показатели на моделите възпрепятства приемането на потребителите в приложенията и усложнява справедливото сравнение на различните модели. Ето защо е необходимо измерване, което се основава на семантика, вместо на чисто сходство на низовете. В тази кратка статия представяме метрика, базирана на кръстосан кодер, за оценка на сходството на семантичните отговори и я сравняваме със седем съществуващи показателя. За тази цел създаваме английски и немски трипосочен анотиран набор от данни за оценка, съдържащ двойки отговори заедно с човешката преценка за тяхната семантична прилика, който публикуваме заедно с внедряване на метриката и експериментите. Намираме, че семантичните показатели за сходство, базирани на последните трансформаторни модели, корелират много по-добре с човешката преценка, отколкото традиционните показатели за лексикална сходство на нашите два новосъздадени набора от данни и един набор от данни от свързани работи.', 'hr': 'Procjenjivanje pitanja odgovarajućih modela uspoređuje oznake zemaljske istine s modelima predviđanja. Međutim, od danas, ova usporedba je uglavnom na leksičkom temelju i stoga propušta odgovore koje nemaju leksički preklapanje ali još uvijek su semantički slične, tako da se tretiraju prave odgovore kao lažne. To podcjenjivanje pravog učinka modela sprječava prihvatanje korisnika u prijavama i komplicira fer usporedbu različitih modela. Stoga postoji potreba za procjenom metrika koja se temelji na semantici umjesto čiste sličnosti žica. U ovom kratkom papiru predstavljamo SAS-u, preko kodera baziranu metriku za procjenu sličnosti semantičkog odgovora i uspoređujemo ga sa sedam postojećih metrika. Za taj cilj, stvorimo engleski i njemački trosmjerno annotirani broj podataka za procjenu koji sadrže par odgovora zajedno s ljudskim procjenom o njihovoj semantičkoj sličnosti, koje oslobodimo zajedno s provedbom SAS metrika i eksperimenata. Mi smatramo da semantička metrika sličnosti bazirana na nedavnim modelima transformacija mnogo bolje koreliraju s ljudskim sudom nego tradicionalne leksičke sličnosti metrike na našim dvije nove stvorene baze podataka i jednu grupu podataka iz povezanih poslova.', 'de': 'Die Auswertung von Fragebeantwortungsmodellen vergleicht Ground-Truth-Annotationen mit Modellvorhersagen. Dieser Vergleich ist jedoch bis heute weitgehend lexikalisch begründet und verpasst daher Antworten, die keine lexikalischen Überschneidungen aufweisen, aber dennoch semantisch ähnlich sind, und behandelt daher korrekte Antworten als falsch. Diese Unterschätzung der tatsächlichen Leistung von Modellen behindert die Akzeptanz der Anwender in Anwendungen und erschwert einen fairen Vergleich verschiedener Modelle. Daher besteht die Notwendigkeit einer Evaluationsmetrik, die auf Semantik statt reiner String-Ähnlichkeit basiert. In diesem kurzen Beitrag stellen wir SAS vor, eine Cross-Encoder-basierte Metrik zur Schätzung der semantischen Antwortähnlichkeit, und vergleichen sie mit sieben bestehenden Metriken. Zu diesem Zweck erstellen wir einen englischen und einen deutschen Drei-Wege-annotierten Auswertungsdatensatz mit Antwortpaaren und menschlicher Beurteilung ihrer semantischen Ähnlichkeit, den wir zusammen mit einer Implementierung der SAS-Metrik und der Experimente veröffentlichen. Wir finden, dass semantische Ähnlichkeitsmetriken auf Basis aktueller Transformatormodelle viel besser mit menschlichem Urteilsvermögen korrelieren als traditionelle lexikalische Ähnlichkeitsmetriken auf unseren beiden neu erstellten Datensätzen und einem Datensatz aus verwandter Arbeit.', 'ko': '퀴즈 모델의 평가는 지면 진상 주석과 모델 예측을 비교한다.그러나 지금까지 이런 비교는 주로 어휘에 기초한 것이기 때문에 어휘가 중첩되지 않았지만 의미가 비슷한 답안을 빠뜨렸기 때문에 정답을 오류로 간주했다.이러한 모델의 실제 성능에 대한 과소평가는 사용자가 응용 프로그램에서 받아들이는 것을 방해하고 서로 다른 모델의 공평한 비교를 복잡하게 만든다.따라서 순수 문자열의 유사성이 아닌 의미를 바탕으로 하는 평가 도량이 필요하다.이 단문에서 우리는 교차 인코더를 바탕으로 하는 의미 답안 유사성 도량 SAS를 제기하고 기존의 7가지 도량과 비교했다.이를 위해 우리는 영어와 독일어 삼방향 주석 평가 데이터 집합을 만들었는데 그 중에서 쌍을 이루는 답안과 인류의 의미 유사성에 대한 판단을 포함하고 SAS 도량과 실험의 실현과 함께 발표하였다.우리는 우리가 새로 만든 두 개의 데이터 집합과 관련 작업의 한 데이터 집합에서 최신transformer모델을 바탕으로 하는 의미 유사성 도량이 전통적인 어휘 유사성 도량보다 인류 판단의 상관성이 더 높다는 것을 발견했다.', 'tr': "Sorag nusgalarynyň çykyşynyň çykyşyny model öňündürmeleri bilen kelläp görýär. Şu wagtdan bäri bu karşılaşyk köplenç leşik derejesi bar we onuň üçin leşik geçmegi ýok jogabalary ýok, emma häli hem semantik sebäbi meňzeýär, şonuň üçin dogry jogablary ýalňyş şeklinde gözleýär. Bu nusgalaryň dogry ukyplarynyň deňleşmegi uygulamalaryň kabul etmegini engelleýär we dürli nusgalaryň adil karşılaşygyny çykarýar. Şol sebäpli, semantika daýan ýan çyzgylygyň ýerine daýanýan çyzgylygyň meňzeşligi üçin deňleme metrikleri gerek. Bu gysga kagyzda, SAS'i semantik jogabynyň meňzeşliklerini ulanmak üçin karkasa ködleme metrik we muny 7 bar metriklere karşılaştyrýarys. Şonuň üçin biz Iňlisçe we Almança üç ýoly hasaplanýan çykyş datasyny bejerdik. Bu semantik ýaly adamlaryň deňleşliklerini we SAS metriýasynyň we experimentalaryň implementasiýasy bilen çykarýarys. Semantik meňzeşlik metriklerini ýakyn transformer modellerine daýanýar adamlaryň hökmünde däpli köp deňleýşenler. Şu iki täze döredilen veri setirlerimizde we bir dataset edilen işden has gowy bir şekilde çykýar.", 'fa': 'ارزیابی سوال جواب مدل\u200cها با پیش\u200cبینی\u200cهای مدل، اخطار حقیقت زمینی را مقایسه می\u200cکند. ولی از امروز، این مقایسه بیشتر بر اساس زبان زبان است و بنابراین پاسخ های زبانی را از دست می دهد که هیچ تغییر زبانی ندارند ولی هنوز به semantic شبیه هستند، بنابراین با پاسخ های درست به عنوان دروغ رفتار می کنند. این تحقیق عملکرد حقیقی مدل\u200cها از پذیرفتن کاربر در کاربردها جلوگیری می\u200cکند و یک مقایسه مناسب از مدل\u200cهای مختلف را پیچیده می\u200cکند. بنابراین، نیازی به یک متریک ارزیابی وجود دارد که بر اساس سیمانتیک به جای شباهت string پاکیزه است. در این کاغذ کوتاه، ما SAS را نشان می دهیم، یک متریک متریک بر اساس متقابل کودک برای ارزیابی شبیه جواب semantic، و آن را با هفت متریک موجود مقایسه می کنیم. برای این قسمت، ما یک مجموعه داده\u200cهای ارزیابی با سه راه آلمانی انگلیسی و سه راه آلمانی را ایجاد می\u200cکنیم که با قضاوت انسانی از شبیه\u200cهای semantic آنها جواب داده می\u200cشود، که همراه با عملیات متریک SAS و آزمایش\u200cها آزاد می\u200cکنیم. ما پیدا می\u200cکنیم که متریک شبیه\u200cسازی semantic based on recent transformer models much better with human judgment than traditional language similarity metrics on our two newly created datasets and one data set from related work.', 'sq': 'Vlerësimi i modeleve që përgjigjen pyetjeve krahason anotacionet tokësore-të vërtetës me parashikimet modelore. Megjithatë, nga sot, ky krahasim është kryesisht i bazuar në lexik dhe prandaj humb përgjigjet që nuk kanë kapërcime lexike por janë ende semantikisht të ngjashme, duke trajtuar kështu përgjigjet e sakta si të rreme. Kjo nënvlerësim i performancës së vërtetë të modeleve pengon pranimin e përdoruesve në aplikime dhe komplikuon një krahasim të drejtë të modeleve të ndryshme. Prandaj, ka nevojë për një vlerësim metrik që bazohet në semantikë në vend të ngjashmërisë së zinxhirit të pastër. In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing metrics.  Për këtë qëllim, krijojmë një grup të dhënash për vlerësim anglez dhe gjerman në tre drejtime që përmban dy përgjigje së bashku me gjykimin njerëzor të ngjashmërisë semantike të tyre, të cilën e lëshojmë së bashku me një zbatim të metrikës SAS dhe eksperimenteve. Ne zbulojmë se metrikat semantike të ngjashmërisë bazuar në modelet e fundit të transformuesve korrelohen shumë më mirë me gjykimin njerëzor sesa metrikat tradicionale të ngjashmërisë lexike në dy grupet tona të reja të krijuara të dhënash dhe një grup të dhënash nga punët e lidhura.', 'id': 'Evaluasi dari model menjawab pertanyaan membandingkan anotasi kebenaran-tanah dengan prediksi model. Namun, mulai hari ini, perbandingan ini kebanyakan berdasarkan lexik dan oleh itu melewatkan jawaban yang tidak memiliki overlap lexik tetapi masih semantis mirip, sehingga memperlakukan jawaban yang benar sebagai palsu. Ini meremehkan prestasi asli dari model menghalangi penerimaan pengguna dalam aplikasi dan menyulitkan perbandingan yang adil dari model yang berbeda. Therefore, there is a need for an evaluation metric that is based on semantics instead of pure string similarity.  Dalam kertas pendek ini, kami mempersembahkan SAS, metrik berdasarkan kode salib untuk perhitungan persamaan jawaban semantis, dan membandingkannya dengan tujuh metrik yang ada. Untuk tujuan ini, kami menciptakan data evaluasi bahasa Inggris dan Jerman bertiga arah yang dicatat berisi sepasang jawaban bersama dengan penilaian manusia tentang persamaan semantis mereka, yang kami lepaskan bersama dengan implementasi metrik SAS dan eksperimen. Kami menemukan bahwa metrik perbedaan semantis berdasarkan model transformer baru-baru ini berkorelasi jauh lebih baik dengan penghakiman manusia daripada metrik perbedaan lexik tradisional pada dua set data baru-baru kami dan satu set data dari pekerjaan terkait.', 'af': "Die evaluering van vraag antwoord model vergelyk grond- waarheid annotasies met model voorskou. Maar van vandag, hierdie vergelyking is mees leksies gebaseer en daarom mis op antwoordes wat geen leksies oorvloei het nie, maar is nog semantiese gelyk, sodat regte antwoordes as vals behandel. Hierdie onderstesting van die waarde prestasie van modele hinder gebruiker aanvaar in toepassings en kompliseer 'n regverdige vergelyking van verskillende modele. Daarom is daar 'n benodig vir 'n evalueringsmetriek wat op semantieke gebaseer is in plaas van suiwer string gelykheid. In hierdie kort papier, stel ons SAS voor 'n kruiskoder-gebaseerde metriek vir die estimatie van semantiese antwoord gelykbaarheid en vergelyk dit met sewe bestaande metrike. En tot hierdie einde, skep ons 'n Engels en 'n Duitse drie manier aanmerkte evalueringsdatastel wat met paar antwoordes bevat saam met menslike oordeel van hul semantiese gelykenis, wat ons verlos saam met 'n implementering van die SAS metrie en die eksperimente. Ons vind dat semantiese gelykenis metriek gebaseer op onlangse transformer modele baie beter met menslike oordeel as tradisionele leksiese gelykenis metriek op ons twee nuwe geskepe datastelle en een datastel van verwante werk.", 'hy': 'Հարցը պատասխանելու մոդելների գնահատումը համեմատում է հիմնական-ճշմարտության նոտացիաները մոդելի կանխատեսումների հետ: Այնուամենայնիվ, այսօրվա սկզբից այս համեմատությունը հիմնականում լեքսիկական է, և հետևաբար բացակայում է պատասխաններ, որոնք չեն ունենում լեքսիկական համեմատություն, բայց դեռևս սեմանտիկապես նման են, այսպիսով ճիշտ պատասխանները սխալ են Մոդելների իրական արտադրողականության այս թերագնահատումը դժվարանում է օգտագործողների ընդունման ծրագրերում և դժվարանում է տարբեր մոդելների արդարացի համեմատությունը: Այսպիսով, կարիք կա գնահատման մետրիկ, որը հիմնված է սեմանտիկայի վրա պարզ լարերի նմանության փոխարեն: Այս կարճ թղթի մեջ մենք ներկայացնում ենք ՍԱՍ-ը, որը հիմնված է խաչը կոդերի վրա, սեմանտիկ պատասխանի նմանության գնահատման համար, և համեմատում ենք այն գոյություն ունեցող յոթ մետրերի հետ: Այսպիսով, մենք ստեղծում ենք անգլերեն և գերմանացի երեք ուղղությամբ նկարագրված գնահատման տվյալների համակարգ, որը պարունակում է երկու պատասխաններ, միասին մարդկային դատողությամբ իրենց սեմանտիկ նմանության մասին, որը մենք հրապարակում ենք միասին ԱՍՍ մետրիկայի և փորձա Մենք հայտնաբերում ենք, որ սեմանտիկ նմանության մետրիկները, հիմնված վերջին վերափոխման մոդելների վրա, ավելի լավ կապված են մարդկային դատողության հետ, քան ավանդական լեքսիկական նմանության մետրիկները մեր երկու նոր ստեղծված տվյալների համակարգերի վրա և մեկ կապված աշխատան', 'am': 'የጥያቄ መልስ ምሳሌዎች ማስታወቂያው የመሬት-እውነትን ማስታወቂያ በሞዴል ውይይት ይተካክላል፡፡ ነገር ግን ከዛሬ ጀምሮ ይህ ምሳሌ በብዛት የሜክሲካዊ መሠረት ነው፡፡ ይህ የሞዴሎችን እውነተኛ ስርዓት በፕሮግራሞች ውስጥ ተጠቃሚዎችን መቀበል የሚከለክል እና የተለየ ዓይነቶች ትክክል ማሳሰል፡፡ ስለዚህ ከንጹሕ እስራት ፋንታ በተመሳሳይ ላይ የተመሠረተ የሜትሪክ ማስታወቂያ ያስፈልጋል፡፡ በዚህ አቋራጭ ገጾች ውስጥ የሆኑትን ሰባት ማተሚያዎች እናስተያየዋለን፡፡ ለዚህ ምክንያት የኢንግሊዝኛ እና የጀርመን ሦስት መንገዶች በሚያደነግጡ የዳታ ማድረጊያውን እናደርጋለን፤ በሰው ብጤያቸው በሰው ፍርድ እና በSAS ሜትሪክ እና ፈተና እናደርጋለን፡፡ አዲስ አዲስ ፍጥረት ካደረጉት ዳታዎችን እና የተገኘውን የዳታ ማህበረሰብ ከባሕላዊው ሌክሲካዊ ብጤቶች በላይ ከሰው ፍርድ የተሻለ ሚትሪኮችን እና አንድ ዳታተር የተደረገውን እና እና አዲስ ስራ ላይ የተደረገውን የዳታ ማህበረሰብ እና እንደገና እናገኘዋለን፡፡', 'sw': 'Tathmini ya mifano ya kujibu maswali inalinganisha mabadiliko ya ukweli wa ardhi na utabiri wa mifano. Hata hivyo, mpaka leo, ulinganisho huu umetokana na msingi wa kisaikolojia na kwa hiyo hukosa majibu ambayo hayana vifaa vya lexico lakini bado vinaendelea sawa, kwa hivyo kutibu majibu sahihi kama uwongo. Uchambuzi huu wa ufanisi wa kweli wa mifano unazuia kukubaliana na watumiaji katika matumizi na unachanganya ulinganisho sahihi wa mifano tofauti. Therefore, there is a need for an evaluation metric that is based on semantics instead of pure string similarity.  Katika karatasi hii fupi, tunawasilisha SAS, mbinu yenye kodi kwa kiasi kikubwa kwa kadiria ya majibu ya kimapenzi yanayofanana na mbinu saba zilizopo. Kwa mwisho huu, tunatengeneza Kiingereza na Mjerumani kwa njia tatu ya uchunguzi wa taarifa zinazohusu majibu mawili pamoja na uamuzi wa binadamu wa usawa wao wa kimapenzi, ambao tunaachia pamoja na utekelezaji wa mitandao ya SAS na majaribio hayo. Tunapata mbinu za usawa wa kimapenzi zinazotokana na mifano ya mabadiliko ya hivi karibuni yanaunganisha zaidi na uamuzi wa binadamu kuliko mitindo inayofanana na kizamani ya lexico katika seti zetu mbili mpya zilizotengenezwa na taarifa moja kutoka kwenye kazi zinazohusiana.', 'bn': 'প্রশ্নের উত্তরের মডেলের মূল্যের মূল্য ভূমি-সত্যের বিষয়বস্তুর সাথে মডেলের ভবিষ্যতের সাথে তুলনা করে। তবে আজকের পর্যন্ত এই তুলনাটি বেশীরভাগ লেক্সিকাল ভিত্তিক এবং তাই তাদের উত্তরের বিরুদ্ধে হারিয়ে যায় যাদের কোন লেক্সিক্সিয়াল ক্ষতি নেই কিন্ মডেলের সত্যিকারের প্রদর্শনের এই ধারণা অ্যাপলিকেশনে ব্যবহারকারীদের গ্রহণ বাধা দেয় এবং বিভিন্ন মডেলের তুলনায় ন্যায়পরায়ণ তাই স্ট্রিং এর পরিবর্তে সেমেন্টিক্স ভিত্তিক মূল্যায়নের প্রয়োজন। In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing metrics.  এই পর্যন্ত আমরা একটি ইংরেজি এবং একটি জার্মানী তিনটি উপায় বিরক্তিকর মূল্যবোধের তথ্য সৃষ্টি করি, যার মধ্যে মানুষের সাথে তাদের সেম্পেন্টিক বিচারের সাথে দুটি উত্তর আমরা খুঁজে পাচ্ছি যে সাম্প্রতিক পরিবর্তনের মডেলের ভিত্তিতে সেমান্টিক সমতার মেট্রিক যা মানুষের বিচারের সাথে মানুষের সাথে সংশ্লিষ্ট হয়েছে ঐ', 'bs': 'Procjena pitanja odgovarajućih modela uspoređuje oznake zemaljske istine sa predviđanjem modela. Međutim, od danas, ova usporedba je uglavnom na leksičkoj bazi i stoga propušta odgovore koje nemaju leksičke pretvaranje, ali su još semantički slične, tako da se tretiraju prave odgovore kao lažne. To podcjenjivanje pravog učinka modela sprječava prihvatanje korisnika u aplikacijama i komplicira fer usporedbu različitih modela. Stoga je potrebna metrika za procjenu koja se temelji na semantici umjesto čiste sličnosti žica. U ovom kratkom papiru predstavljamo SAS-u, preko kodera baziranu metriku za procjenu sličnosti semantičkog odgovora i uspoređujemo ga sa sedam postojećih metrika. Za taj cilj, stvorimo engleski i njemački tri puta annotirani podaci o procjenama koji sadrže par odgovora zajedno sa ljudskim procjenom o njihovoj semantičkoj sličnosti, koje oslobodimo zajedno s provedbom SAS metrika i eksperimenata. Mi smatramo da semantička metrika sličnosti bazirana na nedavnim modelima transformatora mnogo bolje povezuje sa ljudskim sudom od tradicionalne leksičke sličnosti metrike na našim dvije nove stvorene baze podataka i jednu grupu podataka iz povezanih poslova.', 'ca': "The evaluation of question answering models compares ground-truth annotations with model predictions.  Tot i així, a partir d'avui en dia, aquesta comparació es basa principalment en la lexia i, per tant, falta en respostes que no tenen cap sobreposició lexical però encara són semànticament similars, tractant les respostes correctes com falses. Aquesta subestimació del veritable rendiment dels models dificulta l'acceptació dels usuaris en aplicacions i complica una comparació justa de diferents models. Per tant, hi ha la necessitat d'una metèrica d'evaluació basada en semàntica en lloc de pura similitud de cadenes. En aquest curt paper, presentem SAS, una mètrica basada en codificadors cruços per estimar la similitud de resposta semàntica, i la comparam amb set mètrices existents. Per això creem un conjunt de dades d'evaluació en anglès i alemanya de tres direccions que contenen parells de respostes juntament amb el judici humà de la seva similitud semàntica, que publicam juntament amb una implementació de la mètrica SAS i els experiments. Trobem que les mètriques semàntiques de similitud basades en models recents de transformador correlacionen molt millor amb el judici humà que les mètriques tradicionals de similitud lèxica en els nostres dos nou conjunts de dades i un conjunt de dades de treball relacionat.", 'cs': 'Vyhodnocení modelů zodpovězení otázek porovnává anotace základní pravdy s modelovými predikcemi. Od dnešního dne je toto srovnání většinou založeno na lexikálním základě, a proto přehlíží odpovědi, které nemají žádné lexikální překrývání, ale jsou stále sémanticky podobné, takže správné odpovědi považují za falešné. Toto podceňování skutečné výkonnosti modelů brání uživatelské akceptaci v aplikacích a komplikuje spravedlivé srovnání různých modelů. Proto je potřeba vyhodnocovací metriky založené na sémantice namísto čisté řetězcové podobnosti. V tomto krátkém článku představujeme SAS, metriku založenou na křížovém kodéru pro odhad podobnosti sémantických odpovědí a porovnáme ji se sedmi existujícími metrikami. Za tímto účelem vytvoříme anglickou a německou třícestnou anotovanou hodnotící sadu obsahující dvojice odpovědí spolu s lidským posuzováním jejich sémantické podobnosti, kterou uvolníme spolu s implementací SAS metriky a experimentů. Zjišťujeme, že sémantické metriky podobnosti založené na nedávných transformátorových modelech korelují mnohem lépe s lidským úsudkem než tradiční lexikální metriky podobnosti na našich dvou nově vytvořených datových sadách a jedné sadě dat z související práce.', 'az': "Modellərə cavab verən sual değerlendirməsi modeli tədbirlərlə yerdə həqiqət tədbirləri ilə qarşılaşdırır. Ancaq bu müqayisədə, bu müqayisədə əksəriyyətdə leksik tabanlıdır və buna görə də leksik müqayisədə olmayan cavablardan qeyb edilməz, amma hələ də semantik kimi bənzəyirlər, buna görə də doğru cavabları yalan hesab edirlər. Bu modellərin həqiqi performans istifadəçilərin istifadəçilərinin qəbul edilməsini engel edir və müxtəlif modellərin ədalətli kompleksiyasını çəkir. Buna görə də, təmiz məsələlər kimiliğinin yerinə semantik üzərində dayanan bir ölçü metrik üçün ehtiyacı var. Bu qısa kağızda, SAS'i, semantik cevabın similaritəsini hesablamaq üçün çox kodlayıcı bir metrik göstəririk və yeddi metrik ilə qarşılaşdırırıq. Bu məqsədilə, biz İngilizce və Almanca üç yol çəkilən değerlendirmə verilən verilənlər quruluruq, insanların semantik bənzəri ilə birlikdə bir cüt cevap verilən, bu da SAS metrik və eksperimentlərin uygulaması ilə birlikdə yayındırırıq. Gördük ki, son transformer modellərinə dayanan semantik similarlıq metriklərinin insan hökmünü daha yaxşı ilə insan hökmünü yeni yaratdığımız iki veri seti və bir veri seti ilə daha yaxşı ilə dəyişdirirlər.", 'et': 'Küsimustele vastamise mudelite hindamisel võrreldakse alustõe annotatsioone mudeli ennustustega. Praeguse seisuga on see võrdlus aga enamasti leksikaalne ja seetõttu jääb ilma vastustest, millel pole leksikaalset kattumist, kuid mis on endiselt semantiliselt sarnased, käsitledes õigeid vastuseid valedena. Mudelite tegeliku jõudluse alahindamine takistab kasutajate aktsepteerimist rakendustes ja raskendab erinevate mudelite õiglast võrdlemist. Seetõttu on vaja hindamismeetodit, mis põhineb semantikal, mitte puhtalt stringisarnasusel. Käesolevas lühikeses töös esitame SAS-i, ristkodeerijal põhinevat meetrit semantiliste vastuste sarnasuse hindamiseks ja võrdleme seda seitsme olemasoleva meetriga. Selleks loome inglise ja saksa kolmesuunalise annoteeritud hindamisandmekogumi, mis sisaldab paare vastuseid koos inimese arvamusega semantilise sarnasuse kohta, mille avaldame koos SAS meetrika ja katsete rakendamisega. Leiame, et hiljutistel transformaatormudelitel põhinevad semantilise sarnasuse mõõdikud korrelatsioonivad palju paremini inimese hinnanguga kui traditsioonilised leksikaalse sarnasuse mõõdikud meie kahel äsja loodud andmekogumil ja ühel andmekogumil seotud tööst.', 'fi': 'Kysymysten vastausmallien arvioinnissa verrataan pohjatotuutta koskevia huomautuksia malliennusteisiin. Tästä päivästä lähtien vertailu on kuitenkin enimmäkseen sanastopohjainen, joten siinä jätetään huomiotta vastaukset, joilla ei ole sanastollista päällekkäisyyttä mutta jotka ovat edelleen semanttisesti samankaltaisia, joten oikeat vastaukset pidetään väärinä. Mallien todellisen suorituskyvyn aliarviointi vaikeuttaa käyttäjien hyväksyntää sovelluksissa ja vaikeuttaa eri mallien oikeudenmukaista vertailua. Siksi tarvitaan semantiikkaan perustuva arviointimetriikka puhtaan merkkijonon samankaltaisuuden sijaan. Tässä lyhyessä artikkelissa esitellään SAS, ristikoodaajapohjainen metriikka semanttisten vastausten samankaltaisuuden arvioimiseksi, ja vertaamme sitä seitsemään olemassa olevaan metriikkaan. Tätä varten luomme englanninkielisen ja saksankielisen kolmisuuntaisen annotoidun arviointiaineiston, joka sisältää vastauspareja sekä ihmisen arvion semanttisesta samankaltaisuudesta, jonka julkaisemme yhdessä SAS-metriikan ja kokeiden toteutuksen kanssa. Havaitsemme, että viimeaikaisiin muuntajamalleihin perustuvat semanttiset samankaltaisuusmetriikat korreloivat paljon paremmin ihmisen arvostelukykyyn kuin perinteiset sanastolliset samankaltaisuusmetriikat kahdessa äskettäin luodussa aineistossamme ja yhdessä aineistossa toisiinsa liittyvästä työstä.', 'jv': 'Language Nanging, namuhi, nggerarangke iki dadi luwih-luwih apik lan kaya mbok kuwi rawurung sing ora ono luwih apik, nango sampek semana sak yo sampek, iso nggawe luwih apik. Digawe iki ngono nggawe akeh pengguna anyar ning model kuwi bisa ngubah akses ngubah aplikasi lan karo akeh sampeyan karo model sing sampeyan sampeyan Kayané, wis dipunangé kanggo kelompok metik sing diangkat semanti dipunangé karo perusahaan kelompok. Nang pentunggu punika, kita sumulakno karo SUS, dadi karo koder-basa meta kanggo ngakwih dumadhi semanti karo perusahaan semanti, lan ngakwih-karo sepatu karo akeh meta sing saiki banget. Saiki iki, awak dhéwé nggawe Inggris lan alaman sing telu-maneh sing nganggo perusahaan gambaran karo hal-hal sing dirampakan nganggo perusahaan karo hal-hal sing sematik dhéwé, awak dhéwé iso nguasai perusahaan SMS Metric karo perusahaan sing nyenggap banjuré. Awak dhéwé luwih akeh sistem semantar sampeyan Metik sing basa ning model transformer sampeyan karo perbudhakan langgar sampeyan luwih apik dhéwé karo perusahaan langgar sampeyan luwih dumadhi iki sampeyan sing paling dhéwé.', 'he': 'הערכה של דוגמנים לענות על שאלות שווות ציונים אמת-קרקע עם ציונים דוגמנים. However, as of today, this comparison is mostly lexical-based and therefore misses out on answers that have no lexical overlap but are still semantically similar, thus treating correct answers as false.  This underestimation of the true performance of models hinders user acceptance in applications and complicates a fair comparison of different models.  לכן, יש צורך למטרית הערכה שמבוססת על סמנטיקה במקום דמיון טהור. בנייר הקצר הזה, אנחנו מציגים SAS, מטריקה מבוססת על קודד צלב להערכה של דומות תשובה סמנטית, ושווה אותה לשבע מטריות קיימות. למטרה זו, אנו יוצרים נתוני עריכה אנגלית וגרמנית בשלושה כיוונים שמכילים זוגות תשובות יחד עם שיקול אנושי של הדמיון הסמנטי שלהם, שאנחנו משחררים יחד עם השימוש של המטריקה של SAS והניסויים. We find that semantic similarity metrics based on recent transformer models correlate much better with human judgment than traditional lexical similarity metrics on our two newly created datasets and one dataset from related work.', 'ha': 'Ana ƙaddara wa masu karɓa misalin su sami da sunayen bakin-gaske da misalin motsi. Kayya, ko da yau, misalin wannan yana da mafi kamaki a kan littãfi, kuma don haka sai ya ɓace a kan majibu wanda bã ya da wani nauyi wa leftiki kuma amma yana daidai da kwatanki, sai ya yi zaman su zama daidai kamar ƙarya. Wannan ana ƙidãya wa cikakken shiryoyin ayuka da aka hanã wa mai amfani da shi a cikin shiryoyin ayuka kuma ya sami wani misãlai masu daidaita. To, don haka, aka buƙata wani muhalli na metric wanda aka ƙaddara shi ne a kan semantiki, kuma ba da daidaita rasmi ba. Ga wannan takardan ƙaranci, Munã halatar da SAS, metric mai kore-kode-based dõmin ya yi ƙidãya ga cema mai daidaita kuma ka samã shi da bakwai metrici wanda ke cikin. To this end, we create an English and a German three-way annotated evaluation dataset containing pairs of answers along with human judgment of their semantic similarity, which we release along with an implementation of the SAS metric and the experiments.  Tun gane cewa, misalin mitrici ne a kan misalin mutane a yanzu, yana da mafi alhẽri ga hukuncin mutum ko kuma da metric masu daidaita na laƙaitar leksisi a kanan biyu na yanzu aka halitta, da taki guda daga aikin da aka yi danganta.', 'sk': 'Ocena modelov odgovarjanja na vprašanja primerja oznake resnice z napovedi modelov. Vendar pa od danes ta primerjava večinoma temelji na leksikalnem in zato zamuja odgovore, ki nimajo leksikalnega prekrivanja, vendar so še vedno semantično podobni, zato pravilne odgovore obravnavajo kot napačne. To podcenjevanje dejanske učinkovitosti modelov ovira sprejemanje uporabnikov v aplikacijah in otežuje pošteno primerjavo različnih modelov. Zato obstaja potreba po meritvi ocenjevanja, ki temelji na semantiki namesto čiste podobnosti nizov. V tem kratkem prispevku predstavljamo SAS, metriko, ki temelji na navzkrižnem kodiranju za oceno semantične podobnosti odgovorov, in jo primerjamo s sedmimi obstoječimi metrikami. V ta namen izdelamo angleško in nemško trosmerno označeno vrednotenje podatkov, ki vsebujejo pare odgovorov skupaj s človeško presojo njihove semantične podobnosti, ki jih objavimo skupaj z implementacijo meritve SAS in eksperimentov. Ugotavljamo, da so meritve semantične podobnosti, ki temeljijo na novejših transformatorskih modelih, veliko bolje povezane s človeško presojo kot tradicionalne metrike leksikalne podobnosti na naših dveh novoustvarjenih naborih podatkov in enem naboru podatkov iz sorodnega dela.', 'bo': 'འདྲི་ཚིག་གི་དཔེ་དབྱིབས་དང་མཐུན་པ་ལྟ་བུའི་རྣམ་གྲངས་དང་མཉམ་དུ་མཐུན་བཟོས་ཡོད། འོན་ཀྱང་། ད་ལྟ་བུའི་མཉམ་དུ་བཟོ་བཅོས་འདི་ཆེ་ཆུང་ལ་སྐད་ཡིག་གཟུགས་རིས་མེད་པའི་ལན་གསལ་ཚུ་ལྷག་སོང་། འདི་ལྟ་བུའི་ལན་གསལ་ཚོར་ཉར་ཚར This underestimation of the true performance of models hinders the user acceptance in applications and complicates a fair comparison of different models. Therefore, there is a need for an evaluation metric that is based on semantics instead of pure string similarity. In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing metrics. To this end, we create an English and a German three-way annotated evaluation dataset containing pairs of answers along with human judgment of their semantic similarity, which we release along with an implementation of the SAS metric and the experiments. We find that semantic similarity metrics based on recent transformer models correlate much better with human judgment than traditional lexical similarity metrics on our two newly created datasets and one dataset from related work.'}
