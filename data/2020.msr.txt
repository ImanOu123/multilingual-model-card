{'en': 'The Third Multilingual Surface Realisation Shared Task (SR’20): Overview and Evaluation Results', 'ar': "المهمة المشتركة الثالثة لإدراك السطح متعدد اللغات (SR'20): نظرة عامة ونتائج التقييم", 'es': "La tercera tarea compartida multilingüe de realización de superficies (SR'20): descripción general y resultados de la evaluación", 'fr': "Troisième tâche partagée de réalisation de surface multilingue (SR'20)\xa0: aperçu et résultats de l'évaluation", 'pt': "A Terceira Tarefa Compartilhada de Realização de Superfícies Multilíngües (SR'20): Visão Geral e Resultados da Avaliação", 'ja': "第3の多言語面実現共有タスク（ SR '20 ） ：概要と評価結果", 'ru': "Третья многоязычная совместная задача по реализации на поверхности (SR'20): обзор и результаты оценки", 'hi': "तीसरा बहुभाषी सतह प्राप्ति साझा कार्य (SR'20): सिंहावलोकन और मूल्यांकन परिणाम", 'zh': '其三多言外成共享(SR20):概述与评终', 'ga': "An Tr챠첬 Tasc Comhroinnte um R챕ad첬 Dromchla Ilteangach (SR'20): Forbhreathn첬 agus Tortha챠 Meast처ireachta", 'hu': "A harmadik többnyelvű felületmegvalósítási megosztott feladat (SR'20): Áttekintés és értékelés eredményei", 'el': "Η τρίτη κοινή εργασία υλοποίησης πολυγλωσσικών επιφανειών (SR'20): Επισκόπηση και αξιολόγηση αποτελεσμάτων", 'it': "Terzo compito condiviso multilingue per la realizzazione di superfici (SR'20): Panoramica e risultati della valutazione", 'kk': "Үшінші тілдік көп- тілік үстінің реализациясы ортақтастырылған тапсырма (SR' 20): Көрініс және оқу нәтижесі", 'mk': "Третата заедничка задача за реализација на поверхната површина (СР'20): Резултати на прегледот и евалуацијата", 'ka': 'მესამე მრავალენგური ზემოსახური რეალიზაციის გაყოფილი დავალება', 'lt': "Trečioji daugiakalbė paviršiaus realizavimo bendra užduotis (SR'20): Apžvalga ir vertinimo rezultatai", 'mn': "Гуравдах олон хэлний гадаргуу бодит байдлын хуваалтын ажил (SR'20): Үүний үзэл, үнэлгээ", 'ms': "The Third Multilingual Surface Realisation Shared Task (SR'20): Overview and Evaluation Results", 'ml': "മൂന്നാമത്തെ പല ഭാഷകങ്ങളുടെ മുഖം റിയാജിഷന്\u200d പങ്കുചേര്\u200dത്ത ജോലി (SR'20): പരിശോധിപ്പിന്റെ ഫലങ്ങള്\u200d നോക്കുക", 'mt': "It-Tielet Kompitu Konġunt dwar ir-Realizzazzjoni tal-wiċċ Multilingwi (SR'20): Ħarsa ġenerali u Riżultati tal-Evalwazzjoni", 'pl': "Trzecie wielojęzyczne wspólne zadanie realizacji powierzchni (SR'20): przegląd i wyniki oceny", 'sr': "Treći zajednički zadatak za realizaciju višejezičkih površina (SR'20): rezultati preglede i procjene", 'so': "The Third Multilingual Surface Realisation Shared Task (SR'20): Overview and Evaluation Results", 'ro': "A treia sarcină comună de realizare a suprafețelor multilingvă (SR'20): Prezentare generală și rezultate ale evaluării", 'no': "Den tredje delte oppgåva for realisering av fleirspråksområde (SR'20): Resultatet for oversikt og evaluering", 'si': "තුන්වෙනි භාෂාවික පැත්ත ප්\u200dරතිභාෂාව සාමාන්\u200dය වැඩකරණය (SR'20): ප්\u200dරතිභාෂාව සහ විශේෂණ ප්\u200dරත", 'sv': "Den tredje flerspråkiga gemensamma uppgiften för att förverkliga ytor (SR'20): Översikt och utvärderingsresultat", 'ta': 'மூன்றாம் பல மொழி முகப்பு சரிபார்ப்பு பகிர்ந்த பணி', 'ur': "تیسری مثالی زبان سپریز ریلیزانیز شریک ٹاکس (SR'20): اوورویز اور ارزش نتائج", 'uz': 'Ikkinchi nechta tillar surveys to\xa0Ľg\xa0Ľrilash (SR- 20): Ta\xa0ľrifi natijalarini ko\xa0Ľrish va tasdiqlash', 'vi': 'Nhiệm vụ chia sẻ "Thực hiện mặt đất đa dạng" thứ ba (SR\'20: Kết quả kiểm soát và đánh giá', 'bg': "Третата споделена задача за многоезична реализация на повърхностите (SR'20): преглед и резултати от оценката", 'da': "Den tredje flersprogede delte opgave til realisering af overflader (SR'20): Oversigt og evalueringsresultater", 'nl': "De derde meertalige gezamenlijke taak voor oppervlakterealisatie (SR'20): Overzicht en evaluatieresultaten", 'hr': "Treći zajednički zadatak realizacije višejezičkih površina (SR'20): rezultati preglede i procjene", 'ko': "세 번째 다중 언어 표면 공유 작업 실현(SR'20): 개술 및 평가 결과", 'fa': "کار مشترک سطح زیادی زبان (SR'20): نتیجه\u200cهای پیش\u200cبینی و ارزیابی", 'de': "Die dritte mehrsprachige Aufgabe der Oberflächenrealisierung (SR'20): Übersicht und Evaluation der Ergebnisse", 'id': "Tugas Berkongsi Realisasi Permukaan Berbahasa Keketiga (SR'20): Penjelasan dan Hasil Evaluasi", 'sw': "Toleo la Utawala wa lugha ya tatu lilishiriki kazi (SR'20): Matokeo ya Mapitio na Utafiti", 'sq': "Detyra e tretë e përbashkët e realizimit të sipërfaqes shumëgjuhësore (SR'20): Rezultatet e mbikqyrjes dhe vlerësimit", 'tr': "횥챌체nji Ilmi Mody Suraty Ger챌ekle힊mek Be첵lenen G철rev (SR'20): G철rn철힊 we Ta첵첵arlama netijesi", 'af': "Die derde veelvuldige oorskrifte Realisering Gedeelde Opdrag (SR' 20): Oorskyk en Evaluering Resultate", 'hy': "Երրորդ բազլեզու մակերևույթի իրականացման կիսված առաջադրանքը (ՍՌ'20): Անցողություն և գնահատման արդյունքները", 'bn': "The Third Multilingual Surface Realisation Shared Task (SR'20): Overview and Evaluation Results", 'az': "Üçüncü Dil Yüzü Realizasyonu paylaşılan Task (SR'20):", 'bs': "Treći zajednički zadatak za realizaciju višejezičkih površina (SR'20): rezultati preglede i procjene", 'am': "የሦስተኛው ብልቋንቋ አቀማመጥ ማድረግ የተሰራጨው ስራ (SR'20): ተመልከት እና ማስታወቂያ ፍሬዎች", 'cs': "Třetí vícejazyčný úkol pro realizaci povrchu (SR'20): Přehled a hodnocení výsledků", 'ca': "La tercera tasca compartida de la realització de la superfície multilingüe (SR'20): Resultats d'una visió general i d'una evaluació", 'et': "Kolmas mitmekeelne pinna realiseerimise ühine ülesanne (SR'20): ülevaade ja hindamise tulemused", 'fi': "Kolmas monikielinen pintatoteutuksen yhteinen tehtävä (SR'20): yleiskatsaus ja arviointitulokset", 'ha': '@ item Text character set', 'sk': "Tretja skupna naloga večjezične uresničitve površin (SR'20): pregled in rezultati ocenjevanja", 'jv': "Terasai Multilenguang Cine Rejang Rejang Daftar Taakno (SS'2]: Ngelengkat lan Validity", 'bo': "The Third Multilingual Surface Realization Shared Task (SR'20): Overview and Evaluation Results", 'he': "המשימה המשותפת של השטח המרבית השלישית (SR'20): תוצאות הערכה"}
{'en': 'This paper presents results from the Third Shared Task on Multilingual Surface Realisation (SR’20) which was organised as part of the COLING’20 Workshop on Multilingual Surface Realisation. As in SR’18 and SR’19, the shared task comprised two tracks : (1) a Shallow Track where the inputs were full UD structures with word order information removed and tokens lemmatised ; and (2) a Deep Track where additionally, functional words and morphological information were removed. Moreover, each ', 'ar': "تقدم هذه الورقة نتائج المهمة المشتركة الثالثة حول إدراك السطح متعدد اللغات (SR'20) والتي تم تنظيمها كجزء من ورشة عمل COLING'20 حول إدراك السطح متعدد اللغات. كما في SR'18 و SR'19 ، تتألف المهمة المشتركة من مسارين: (1) مسار ضحل حيث كانت المدخلات عبارة عن هياكل UD كاملة مع إزالة معلومات ترتيب الكلمات والرموز المميزة ؛ و (2) مسار عميق حيث تمت إزالة الكلمات الوظيفية والمعلومات الصرفية بالإضافة إلى ذلك. علاوة على ذلك ، كان لكل مسار مساران فرعيان: (أ) مورد مقيد ، حيث يمكن فقط استخدام البيانات المقدمة أو المعتمدة كجزء من المسار لنماذج التدريب ، و (ب) الموارد المفتوحة ، حيث يمكن استخدام أي بيانات. تم تقديم المسار الضحل بـ 11 لغة ، بينما تم تقديم المسار العميق بثلاث لغات. تم تقييم الأنظمة باستخدام كل من المقاييس التلقائية والتقييم المباشر من قبل مقيمين بشريين من حيث قابلية القراءة وتشابه المعنى مع المخرجات المرجعية. نقدم نتائج التقييم ، جنبًا إلى جنب مع أوصاف مسارات SR'19 والبيانات وطرق التقييم ، بالإضافة إلى ملخصات موجزة للأنظمة المشاركة. للحصول على أوصاف كاملة للأنظمة المشاركة ، يرجى الاطلاع على تقارير النظام المنفصلة في مكان آخر في هذا المجلد.", 'pt': "Este artigo apresenta os resultados da Terceira Tarefa Compartilhada sobre Realização de Superfícies Multilíngues (SR'20) que foi organizada como parte do Workshop COLING'20 sobre Realização de Superfícies Multilíngues. Como em SR'18 e SR'19, a tarefa compartilhada compreendia duas trilhas: (1) uma trilha rasa onde as entradas eram estruturas UD completas com informações de ordem de palavras removidas e tokens lematizados; e (2) uma Deep Track onde, adicionalmente, palavras funcionais e informações morfológicas foram removidas. Além disso, cada trilha tinha duas subtrilhas: (a) recurso restrito, onde apenas os dados fornecidos ou aprovados como parte de uma trilha poderiam ser usados para modelos de treinamento, e (b) recurso aberto, onde qualquer dado poderia ser usado. O Shallow Track foi oferecido em 11 idiomas, enquanto o Deep Track em 3 idiomas. Os sistemas foram avaliados usando métricas automáticas e avaliação direta por avaliadores humanos em termos de Legibilidade e Semelhança de Significado com os resultados de referência. Apresentamos os resultados da avaliação, juntamente com descrições das trilhas da SR'19, dados e métodos de avaliação, bem como breves resumos dos sistemas participantes. Para obter descrições completas dos sistemas participantes, consulte os relatórios de sistema separados neste volume.", 'fr': "Cet article présente les résultats de la troisième tâche partagée sur la réalisation de surfaces multilingues (SR'20) qui a été organisée dans le cadre de l'atelier COLING'20 sur la réalisation de surfaces multilingues. Comme dans SR'18 et SR'19, la tâche partagée comprenait deux pistes\xa0: (1) une piste peu profonde où les entrées étaient des structures UD complètes avec des informations d'ordre des mots supprimées et des jetons lemmatisés\xa0; et (2) une piste profonde où en outre, les mots fonctionnels et les informations morphologiques ont été supprimés. De plus, chaque piste comportait deux sous-pistes\xa0: (a) ressources restreintes, où seules les données fournies ou approuvées dans le cadre d'une piste pouvaient être utilisées pour les modèles de formation, et (b) ressources ouvertes, où toutes les données pouvaient être utilisées. Le Shallow Track était proposé en 11 langues, tandis que le Deep Track en 3 langues. Les systèmes ont été évalués à l'aide de mesures automatiques et d'une évaluation directe par des évaluateurs humains en termes de lisibilité et de similitude de signification avec les résultats de référence. Nous présentons les résultats de l'évaluation, ainsi que des descriptions des pistes SR'19, des données et des méthodes d'évaluation, ainsi que de brefs résumés des systèmes participants. Pour une description complète des systèmes participants, veuillez consulter les rapports système séparés ailleurs dans ce volume.", 'es': "Este artículo presenta los resultados de la Tercera tarea compartida sobre realización de superficies multilingües (SR'20) que se organizó como parte del taller COLING'20 sobre realización de superficies multilingües. Al igual que en SR'18 y SR'19, la tarea compartida comprendía dos vías: (1) una pista poco profunda donde las entradas eran estructuras UD completas con información de orden de palabras eliminada y fichas lematizadas; y (2) una pista profunda donde, además, se eliminaban palabras funcionales e información morfológica. Además, cada vía tenía dos subvías: (a) recursos restringidos, donde solo los datos proporcionados o aprobados como parte de una vía podían utilizarse para modelos de capacitación, y (b) recursos abiertos, donde se podía utilizar cualquier dato. El Shallow Track se ofreció en 11 idiomas, mientras que el Deep Track se ofreció en 3 idiomas. Los sistemas se evaluaron mediante métricas automáticas y evaluación directa por parte de evaluadores humanos en términos de legibilidad y similitud de significado con los resultados de referencia. Presentamos los resultados de la evaluación, junto con descripciones de las pistas de SR'19, datos y métodos de evaluación, así como breves resúmenes de los sistemas participantes. Para obtener una descripción completa de los sistemas participantes, consulte los informes del sistema por separado en otra parte de este volumen.", 'ja': "本稿では、COLING '20多言語面実現ワークショップの一環として開催された多言語面実現に関する第3回共有タスク（ SR' 20 ）の結果を紹介する。 SR '18およびSR' 19と同様に、共有タスクは2つのトラックで構成されています。（ 1 ）入力が完全なUD構造であり、語順情報が削除され、トークンがレマティゼーションされた浅いトラック、および（ 2 ）機能的な単語と形態情報が削除された深いトラック。 さらに、各トラックには2つのサブトラックがありました。(a)トラックの一部として提供または承認されたデータのみがトレーニングモデルに使用できる制限付きリソース、および(b)任意のデータが使用できるオープンリソースです。 Shallow Trackは11の言語で提供され、Deep Trackは3つの言語で提供されました。 システムは、自動測定基準と人間の評価者による直接評価の両方を使用して、参照出力に対する可読性と意味の類似性の観点から評価した。 評価結果、SR '19トラックの説明、データ、評価方法、および参加システムの簡単な要約を提示します。 参加システムの詳細については、本巻の別紙システムレポートを参照してください。", 'zh': '本文引为COLING20多言外成研讨会者三共同任务(SR20)也。 与SR18、SR同19,共享二道:(1)浅道,其输全UD,删词序信而词序之。 与(2)一深轨,除功能性单词形息。 凡此二道:(a)受限资源,其为道之一,可得而练;(b)开之,可得而用也。 Shallow Track以11种语,而Deep Track供3种语。 用自指标与人工评人参输之可读性与义相似性直评以质之。 臣等言估终,及SR19轨道,数与评法,及参统之要摘要。 有司与统者具言之,请参阅本卷其别者独以闻。', 'ru': "В настоящем документе представлены результаты третьей совместной задачи по реализации многоязычных поверхностей (SR'20), которая была организована в рамках рабочего совещания COLING'20 по реализации многоязычных поверхностей. Как и в SR'18 и SR'19, общая задача состояла из двух треков: (1) Мелководный трек, где входные данные были полными структурами UD с удалением информации о порядке слов и лематизацией маркеров; и (2) Глубокий трек, где дополнительно удалялись функциональные слова и морфологическая информация. Кроме того, каждый трек имеет два подтекста: a) ограниченный ресурс, где для учебных моделей могут использоваться только данные, представленные или утвержденные в рамках трека, и b) открытый ресурс, где могут использоваться любые данные. Shallow Track был предложен на 11 языках, в то время как Deep Track - на 3. Системы оценивали с использованием как автоматических метрик, так и прямой оценки специалистами по оценке человека с точки зрения читабельности и сходства значений с эталонными результатами. Мы представляем результаты оценки вместе с описанием путей SR'19, данными и методами оценки, а также кратким обзором участвующих систем. Полное описание участвующих систем см. в отдельных системных отчетах в других частях настоящего тома.", 'hi': "यह पेपर बहुभाषी सतह प्राप्ति (SR'20) पर तीसरे साझा कार्य से परिणाम प्रस्तुत करता है, जिसे बहुभाषी सतह प्राप्ति पर COLING'20 कार्यशाला के हिस्से के रूप में आयोजित किया गया था। SR'18 और SR'19 के रूप में, साझा कार्य में दो ट्रैक शामिल थे: (1) एक उथला ट्रैक जहां इनपुट पूर्ण यूडी संरचनाएं थीं, जिसमें शब्द आदेश की जानकारी को हटा दिया गया था और टोकन को हटा दिया गया था; और (2) एक डीप ट्रैक जहां अतिरिक्त रूप से, कार्यात्मक शब्दों और रूपात्मक जानकारी को हटा दिया गया था। इसके अलावा, प्रत्येक ट्रैक में दो सबट्रैक थे: (ए) प्रतिबंधित-संसाधन, जहां केवल ट्रैक के हिस्से के रूप में प्रदान किए गए या अनुमोदित डेटा का उपयोग प्रशिक्षण मॉडल के लिए किया जा सकता था, और (बी) ओपन-रिसोर्स, जहां किसी भी डेटा का उपयोग किया जा सकता था। उथले ट्रैक को 11 भाषाओं में पेश किया गया था, जबकि डीप ट्रैक को 3 में पेश किया गया था। सिस्टम का मूल्यांकन मानव मूल्यांकनकर्ताओं द्वारा पठनीयता और संदर्भ आउटपुट के लिए अर्थ समानता के संदर्भ में स्वचालित मीट्रिक और प्रत्यक्ष मूल्यांकन दोनों का उपयोग करके किया गया था। हम मूल्यांकन परिणामों को SR'19 पटरियों, डेटा और मूल्यांकन विधियों के विवरण के साथ-साथ भाग लेने वाली प्रणालियों के संक्षिप्त सारांश के साथ प्रस्तुत करते हैं। भाग लेने वाले सिस्टम के पूर्ण विवरण के लिए, कृपया इस खंड में कहीं और अलग-अलग सिस्टम रिपोर्ट देखें।", 'ga': "Cuireann an páipéar seo i láthair torthaí ón Tríú Tasc Comhroinnte ar Réadú Dromchla Ilteangach (SR'20) a eagraíodh mar chuid de Cheardlann COLING'20 ar Réadú Dromchla Ilteangach. Amhail SR'18 agus SR'19, chuimsigh an tasc comhroinnte dhá rian: (1) Rian Éadomhain ina raibh na hionchuir ina struchtúir UD iomlána agus an fhaisnéis ord focal bainte agus na comharthaí leamaithe; agus (2) Rian domhain inar baineadh freisin focail fheidhmiúla agus faisnéis mhoirfeolaíoch. Ina theannta sin, bhí dhá fho-rian ag gach rian: (a) acmhainn shrianta, i gcás nach bhféadfaí ach na sonraí a soláthraíodh nó a formheasadh mar chuid de rian a úsáid le haghaidh samhlacha oiliúna, agus (b) acmhainn oscailte, i gcás ina bhféadfaí aon sonraí a úsáid. Cuireadh an Rian Éadomhain ar fáil i 11 theanga, agus an Deep Track i 3 cinn. Rinneadh meastóireacht ar chórais ag baint úsáide as méadracht uathoibríoch agus measúnú díreach ag meastóirí daonna i dtéarmaí Inléiteacht agus Cosúlacht Brí le haschuir tagartha. Cuirimid i láthair na torthaí meastóireachta, mar aon le cur síos ar rianta SR'19, sonraí agus modhanna meastóireachta, chomh maith le hachoimrí gairide ar na córais rannpháirteacha. Le cur síos iomlán a fháil ar na córais rannpháirteacha, féach le do thoil ar na tuarascálacha córais ar leith in áit eile san imleabhar seo.", 'el': "Η παρούσα εργασία παρουσιάζει αποτελέσματα από την Τρίτη Κοινή Εργασία για την Πολυγλωσσική Επιφανειακή Πραγματοποίηση (SR'20), η οποία διοργανώθηκε στο πλαίσιο του Εργαστηρίου για την Πολυγλωσσική Επιφανειακή Πραγματοποίηση. Όπως και στις περιπτώσεις SR'18 και SR'19, η κοινή εργασία περιελάμβανε δύο κομμάτια: (1) ένα ρηχό κομμάτι όπου οι εισόδοι ήταν πλήρεις δομές UD με αφαιρούμενες πληροφορίες σειράς λέξεων και λεμματοποιημένες μάρκες· και (2) ένα Βαθύ Μονοπάτι όπου επιπλέον αφαιρέθηκαν λειτουργικές λέξεις και μορφολογικές πληροφορίες. Επιπλέον, κάθε πίστα είχε δύο υποτάξεις: α) περιορισμένου πόρου, όπου μόνο τα δεδομένα που παρασχέθηκαν ή εγκρίθηκαν ως μέρος μιας πίστας μπορούσαν να χρησιμοποιηθούν για μοντέλα κατάρτισης, και β) ανοικτού πόρου, όπου θα μπορούσαν να χρησιμοποιηθούν οποιαδήποτε δεδομένα. Το ρηχό κομμάτι προσφέρθηκε σε 11 γλώσσες, ενώ το βαθύ κομμάτι σε 3 γλώσσες. Τα συστήματα αξιολογήθηκαν τόσο με αυτόματες μετρήσεις όσο και με άμεση αξιολόγηση από ανθρώπινους αξιολογητές όσον αφορά την αναγνωσιμότητα και την ομοιότητα σήματος με τα αποτελέσματα αναφοράς. Παρουσιάζουμε τα αποτελέσματα της αξιολόγησης, μαζί με περιγραφές των διαδρομών, δεδομένα και μεθόδους αξιολόγησης, καθώς και σύντομες περιλήψεις των συμμετεχόντων συστημάτων. Για πλήρεις περιγραφές των συμμετεχόντων συστημάτων, ανατρέξτε στις ξεχωριστές εκθέσεις συστήματος αλλού σε αυτόν τον τόμο.", 'ka': "ეს დოკუმენტი სამყარო საზოგადოებული დავალების შემდეგ მრავალური საზოგადოება რეალიზაციაზე (SR'20) რომელიც იყო COLING'20 მრავალური საზოგადოება რეალიზაციაზე. როგორც SR'18 და SR'19-ში, საზოგადომი საქაღალდე იყო ორი სტრიქტი: (1) სტრიქტური სტრიქტურები, რომლებიც მონაცემები უფრო UD სტრუქტურები იყო სიტყვების წერილი ინ და (2) დამატებული სიტყვები და მორპოლოგიური ინფორმაცია წაშლა. დამატებით, ყოველ ტრაქტის ორი სტრაქტი იყო: a) სტრაქტირებული რესურსი, სადაც მხოლოდ მონაცემები, ან მონიშნული მონაცემები როგორც სტრაქტირების ნაწილი, შეიძლება გამოყენება მოდელებისთ Name სისტემის გამოყენება ადამიანის განსაზღვრებელობის და განსაზღვრებელობის განსაზღვრებით და განსაზღვრებელობის განსაზღვრებით გამოყენებულია. ჩვენ გავაკეთებთ გავაკეთებული წარმოდგენების შესახებ SR'19 სიტყვების, მონაცემების და გავაკეთების პროცემების შესახებ და გავაკეთებული სისტემების კონტაქტი საზოგადოებ ყველა განსაზღვრებისთვის სისტემის განსაზღვრებისთვის, მოდით ხედავთ განსაზღვრებული სისტემის შეტყობინებების სხვადასხვა ადგილში.", 'hu': "Ez a tanulmány bemutatja a többnyelvű felületek megvalósításáról szóló harmadik közös feladat eredményeit (SR'20), amely a COLING'20 többnyelvű felületek megvalósításáról szóló workshopja részeként került megrendezésre. Az SR'18-hoz és SR'19-hez hasonlóan a megosztott feladat két sávból állt: (1) egy Shallow Track, ahol a bemenetek teljes UD struktúrák voltak, a szósorrendre vonatkozó információk eltávolításával és a tokenek lemmatizálásával; és (2) egy Deep Track, ahol a funkcionális szavakat és morfológiai információkat eltávolították. Ezenkívül minden pályának két részrésze volt: a) korlátozott erőforrás, ahol csak a pálya részeként szolgáltatott vagy jóváhagyott adatokat lehetett felhasználni képzési modellekhez, és b) nyílt erőforrás, ahol bármilyen adat felhasználható. A Shallow Track 11 nyelven, míg a Deep Track 3 nyelven jelent meg. A rendszereket automatikus mérőszámok és humán értékelők által végzett közvetlen értékelések alkalmazásával értékelték az olvashatóság és a referenciakimenetekhez való hasonlóság szempontjából. Bemutatjuk az értékelési eredményeket, az SR'19 pályák leírásával, adatokkal és értékelési módszerekkel, valamint a résztvevő rendszerek rövid összefoglalóival. A részt vevő rendszerek teljes körű leírását a kötet másik részében találja.", 'it': "Questo articolo presenta i risultati del terzo compito condiviso sulla realizzazione delle superfici multilingue (SR'20), organizzato nell'ambito del workshop COLING'20 sulla realizzazione delle superfici multilingue. Come in SR'18 e SR'19, il compito condiviso comprendeva due tracce: (1) una traccia superficiale in cui gli input erano strutture UD complete con informazioni sull'ordine delle parole rimosse e i token lemmatizzati; e (2) un Deep Track dove inoltre, parole funzionali e informazioni morfologiche sono state rimosse. Inoltre, ogni traccia presentava due sottrazioni: (a) risorse limitate, in cui solo i dati forniti o approvati come parte di una traccia potevano essere utilizzati per modelli di formazione, e (b) risorse aperte, in cui potevano essere utilizzati tutti i dati. Lo Shallow Track è stato offerto in 11 lingue, mentre il Deep Track in 3 lingue. I sistemi sono stati valutati utilizzando sia metriche automatiche che valutazioni dirette da parte di valutatori umani in termini di Readability e Meaning Similarity ai risultati di riferimento. Presentiamo i risultati della valutazione, insieme a descrizioni dei percorsi SR'19, dati e metodi di valutazione, nonché brevi riassunti dei sistemi partecipanti. Per una descrizione completa dei sistemi partecipanti, consultare i rapporti di sistema separati altrove in questo volume.", 'lt': "This paper presents results from the Third Shared Task on Multilingual Surface Realisation (SR'20) which was organised as part of the COLING'20 Workshop on Multilingual Surface Realisation.  Kaip ir SR'18 ir SR'19 dalyse, bendra užduotis buvo sudaryta iš dviejų kelių: 1) šešėlinio kelio, kuriame įvestis buvo pilnos UD struktūros su pašalinta žodžių eilės informacija ir lemmatizuota žymens; ir (2) gilią kelią, kurioje buvo pašalinti papildomi funkciniai žodžiai ir morfologinė informacija. Be to, kiekvienas kelis turėjo du atskyrimus: a) ribotus išteklius, kai mokymo modeliams galėtų b ūti naudojami tik duomenys, pateikti arba patvirtinti kaip kelio dalis, ir b) atviri ištekliai, kai galėtų būti naudojami duomenys. Šešėlinis kelis buvo siūlomas 11 kalbų, o gilusis kelis – 3 kalbomis. Sistemos buvo vertinamos naudojant tiek automatines metrijas, tiek tiesioginį žmogaus vertintojų vertinimą skaitomumo ir reikšmės panašumo į referencinius rezultatus požiūriu. Pateikiame vertinimo rezultatus, taip pat SR 19 sekų, duomenų ir vertinimo metodų aprašymus, taip pat trumpas dalyvaujančių sistemų santraukas. For full descriptions of the participating systems, please see the separate system reports elsewhere in this volume.", 'kk': "Бұл қағаз бірнеше тілдік үстінің реализациясы (SR'20) үшінші ортақтастырылған тапсырманың нәтижесін көрсетеді. Бұл COLING' 20 бірнеше тілдік үстінің реализациясы бойынша ортақтастырылған. SR'18 және SR'19 дегенде ортақтастырылған тапсырма екі жолдарды құрылды: (1) келтірілген UD құрылғылары сөз ретіндегі мәліметті алып тастау және белгілерді lemmatized деген толық UD құрылғылары; бұл және (2) қосымша функциялық сөздер мен морфологиялық мәліметтер өшірілген терең жолы. Қосымша, әрбір жолдың екі субтракты болды: a) шектелген ресурс, олардың тек жолдың бір бөлігі ретінде келтірілген не қолданылған деректер үшін қолданылады, және b) ашық ресурс, барлық деректер қолданылады. Тұтас жолы 11 тілде қолданылды, бірақ 3 тілде Тұтас жолы. Жүйелерді оқу мүмкіндігі мен мәліметтердің сілтемелеріне ұқсас ұқсастығы бойынша автоматты түрде метрикалық және адамның бағалаушыларының дұрыс оқу мүмкіндігі мен Біз SR'19 жолдарын, деректерді және бағалау әдістерінің түсініктемелерін және қатысушылардың қысқа тұжырымдамасын таңдаймыз. Қатысушылық жүйелердің толық сипаттамасы үшін бұл үнділіктің басқа жерде бөлек жүйелік хабарламаларды қараңыз.", 'mk': "Овој документ претставува резултати од третата заедничка задача за повеќејазична реализација на површината (СР'20), која беше организирана како дел од работилницата COLING'20 за повеќејазична реализација на површината. Како и во СР'18 и СР'19, заедничката задача сочинуваше две траги: (1) Шатка трага каде што внесувањата беа целосни УД структури со отстранети информации за редот на зборови и симматизирани симболи; и (2) длабока трага каде што додатно беа отстранети функционални зборови и морфолошки информации. Покрај тоа, секоја трага имаше две субстракции: (a) ограничени ресурси, каде само податоците што се обезбедуваат или одобрени како дел од трагата може да се користат за моделите на обука, и (b) отворени ресурси, каде што може да се користат сите податоци. The Shallow Track was offered in 11 languages, whereas the Deep Track in 3 ones.  Системите беа оценети користејќи и автоматска метрика, и директна оценка од страна на човечките оценувачи во поглед на читливоста и значењето сличност на референциските излези. Ги претставуваме резултатите на евалуацијата, заедно со описите на трагите на СР19, податоците и методите на евалуација, како и кратки резултати на учествувачките системи. За целосни описи на учествувачките системи, ве молам погледнете ги одделните системски извештаи на друго место во овој обем.", 'ml': "ഈ പത്രത്തില്\u200d മൂന്നാമത്തെ പങ്കാളിയുള്ള പണിയില്\u200d നിന്നും വര്\u200dദ്ധിപ്പിക്കുന്നുണ്ട്. മിട്ടില്ലിങ്ങ് 20 വര്\u200dക്കിങ്ങിന്റെ വിശേഷത്തില്\u200d കോളിങ SR'18 എന്നിട്ടും SR'19 ലും പങ്കുചേര്\u200dത്ത ജോലി രണ്ട് ട്രാക്കുകള്\u200d ചേര്\u200dത്തിരിക്കുന്നു: (1) ഒരു തണുത്ത ട്രാക്ക് അവിടെ ഇന്\u200dപുട്ടുകള്\u200d മുഴുവന്\u200d യു and (2) a Deep Track where additionally, functional words and morphological information were removed.  അതുകൊണ്ടും, ഓരോ ട്രാക്കിലും രണ്ടു സബ്ട്രാക്കുകള്\u200d ഉണ്ടായിരുന്നു: (a) പരിധിയില്ലാത്ത വിഭവങ്ങള്\u200d മാത്രമേ അവിടെ ട്രാക്കിന്\u200dറെ ഒരു ഭാഗമായോ ഉപയോഗിക്ക മഞ്ഞ ട്രാക്ക് 11 ഭാഷകളില്\u200d അര്\u200dപ്പിക്കപ്പെട്ടിരുന്നു, മൂന്ന് ഭാഷകളില്\u200d ആഴത്തിലെ ട്രാക്കിന് കൂട സിസ്റ്റമില്ലാത്ത മെട്രിക്കുകള്\u200d ഉപയോഗിച്ചും മനുഷ്യരുടെ നേരിട്ടുള്ള വിലാസങ്ങള്\u200d ഉപയോഗിച്ചും പ്രഖ്യാപിപ്പിക്കുന്നതിന്റെ നമ്മള്\u200d പരിഗണിക്കുന്ന ഫലങ്ങള്\u200d കൊണ്ട് SR'19 ട്രാക്കുകളുടെ വിശദീകരിക്കുന്നതും, ഡേറ്റായും വിലാസങ്ങളുടെ രീതികളും, പങ്കുചേര്\u200dക്കുന് പങ്കുചേര്\u200dക്കുന്ന സിസ്റ്റത്തിന്റെ പൂര്\u200dണ്ണമായ വിശദീകരണങ്ങള്\u200dക്ക്, ദയവായി ഈ വോളിമില്\u200d വേറൊരു സിസ്", 'mt': "Dan id-dokument jippreżenta r-riżultati mit-Tielet Kompitu Konġunt dwar ir-Realizzazzjoni Multilingwi tas-Superfiċje (SR'20) li ġie organizzat bħala parti mill-Workshop COLING'20 dwar ir-Realizzazzjoni Multilingwi tas-Superfiċje. Bħal f’SR’18 u SR’19, il-kompitu kondiviż kien jinkludi żewġ binarji: (1) Shallow Track fejn l-inputs kienu strutturi UD sħa ħ b’informazzjoni dwar l-ordni tal-kliem imneħħija u t-tokens limmatizzati; u (2) Trekk Profond fejn ġew imneħħija wkoll kliem funzjonali u informazzjoni morfoloġika. Barra minn hekk, kull binarju kellu żewġ tnaqqis: (a) riżorsi ristretti, fejn id-dejta pprovduta jew approvata biss b ħala parti minn binarju tista’ tintuża għal mudelli ta’ taħriġ, u (b) riżorsi miftuħa, fejn tista’ tintuża kwalunkwe dejta. Il-Pjan Xgħir ġie offrut fi 11-il lingwa, filwaqt li l-Pjan Fond fi 3 lingwi. Is-sistemi ġew evalwati bl-użu kemm ta’ metriċi awtomatiċi kif ukoll ta’ valutazzjoni diretta mill-evalwaturi umani f’termini ta’ Readability and Meaning Similarity to reference outputs. We present the evaluation results, along with descriptions of the SR'19 tracks, data and evaluation methods, as well as brief summaries of the participating systems.  Għal deskrizzjonijiet sħaħ tas-sistemi parteċipanti, jekk jogħġbok ara r-rapporti tas-sistema separati band’oħra f’dan il-volum.", 'mn': "Энэ цаас олон хэлний гадаргуу бодит байдлын 3-р хуваалтын ажил (SR'20) болон COLING'20 олон хэлний гадаргуу бодит байдлын нэг хэсэгт зохион байгуулагдсан ажил гаргадаг. SR'18, SR'19 гэх мэт хуваалцаагүй ажил нь хоёр хэлбэртэй: (1) хэлбэрээр орлуулагдсан UD бүтээгдэхүүний бүтээгдэхүүнд хэлбэрээр мэдээллийг хадгалж, тэмдэглэгдсэн хоёр хэлбэрүүд байсан. (2) нэмэлтэй функцийн үг болон морфологик мэдээлэл хасагдсан гүн зам. Дараа нь, загвар бүр хоёр дотрог байлаа: a) хязгаарлагдсан нөөц байлаа. Зөвхөн загварын нэг хэсэг болгон өгөгдлийн эсвэл зөвхөн зөвхөн сургалтын загвар болон b) нээлттэй нөөц байлаа. Шулуун зам 11 хэл дээр санал өгсөн, Гүн гүнзгий зам нь 3 хэлбэрээр санал өгсөн. Хүн оюутнуудын оюутнуудын хувьд автоматически метрик болон шууд үнэлгээ ашиглаж, унших боломжтой тэнцүү байдлыг хоёуланг ашиглан үнэлгээ хийсэн. Бид оюутнуудын үр дүнг, SR'19 шугам, өгөгдлийн, оюутнуудын тодорхойлолтуудыг харуулж байна. Холбоотой системийн бүрэн тодорхойлолтын тулд энэ хэмжээний бусад хэсэгт ялгаатай системийн мэдээллийг харъя.", 'ms': "Kertas ini memperkenalkan keputusan dari Tugas Terkongsi ketiga mengenai Penyesuaian Surface Berbahasa (SR'20) yang dijalankan sebagai sebahagian dari Workshop COLING'20 mengenai Penyesuaian Surface Berbahasa. Seperti dalam SR'18 dan SR'19, tugas berkongsi terdiri dari dua trek: (1) Trek Gelombang dimana input adalah struktur UD penuh dengan maklumat tertib perkataan dibuang dan token lemmatis; dan (2) Trek Dalam di mana secara tambahan, perkataan berfungsi dan maklumat morfologik dibuang. Selain itu, setiap trek mempunyai dua tolak: (a) sumber-hadir, di mana hanya data yang diberikan atau disetujui sebagai sebahagian trek boleh digunakan untuk model latihan, dan (b) sumber-terbuka, di mana mana mana-mana data boleh digunakan. Trek Gelombang ditawarkan dalam 11 bahasa, sementara Trek Dalam dalam 3 bahasa. Sistem telah diuji menggunakan metrik automatik dan penilaian langsung oleh penilai manusia dalam terma Kemudahan membaca dan Kesamaan Maksud kepada output rujukan. Kami memperkenalkan hasil penilaian, bersama dengan deskripsi trek SR'19, data dan kaedah penilaian, serta ringkasan singkat sistem yang berpartisipasi. Untuk deskripsi lengkap sistem yang berpartisipasi, sila lihat laporan sistem terpisah di tempat lain dalam volum ini.", 'no': "Denne papiret viser resultatet frå den tredje delte oppgåva om fleirspråksområde (SR'20) som er organisert som del av COLING'20 arbeidsområdet på fleirspråksområde. Som i SR' 18 og SR' 19, den delte oppgåva inneheld to spor: (1) ei skylåspor der inndata var fulle UD- strukturer med ordrekkefølgje fjerna informasjon og lemmatiserte teikn. og (2) ein dyp spor der funksjonelle ord og morfologiske informasjon er fjerna tillegg. I tillegg hadde kvar spor to subtraktar: a) begrenset ressurs, der berre data som er levert eller godkjent som del av ei spor kan brukast for øvingsmodeller, og b) opna ressurs der alle data kan brukast. Skalesporet ble tilbygd i 11 språk, mens dyppa sporet i 3 språk. Systemet ble evaluert med både automatisk metrikn og direkte evalueringa av menneske evalueringar ved hjelp av lesabilitet og gjennomsnittsverdighet til referanse. Vi presenterer evalueringsresultatene, saman med skildringar av SR'19 spor, data og evalueringsmetodane, og korte samandringar av deltakende systema. For fullstendige skildringar av deltakarsystemet, sjå systemrapporten andre stader i denne volumet.", 'sr': "Ovaj papir predstavlja rezultate trećeg zajedničkog zadatka o realizaciji višejezičkih površina (SR'20), koji je organizovan kao deo radionice COLING'20 o realizaciji višejezičkih površina. Kao u SR'18 i SR'19, zajednièki zadatak je sastojio dva traga: (1) Shallow Track gdje su ulazi bili pune UD strukture sa uklonjenim informacijama o reèima reda i limuziranim znakovima; i (2) duboki trag gde su dodatno uklonili funkcionalne reči i morfološke informacije. Osim toga, svaki trag je imao dva podrakta: a) ograničena resursa, gdje bi se samo podaci koje su pružene ili odobrene kao deo traga mogli koristiti za modele obuke, i b) otvorene resurse, gde bi se mogli koristiti svaki podaci. Zadnji trag je ponudio na 11 jezika, a duboki trag u 3. Sistemi su procjenjivali koristeći automatsku metriku i direktnu procjenu ljudskih procjenjivača u smislu čitanja i značenja sličnosti referentnim ishodama. Predstavljamo rezultate procjene, zajedno sa opisima tragova SR'19, metoda podataka i procjene, kao i kratkih sažetaka sustava sudjelovanja. Za potpune opise sustava sudjelovanja, molim vas, vidite odvojene izveštaje sistema negde drugdje u ovom volumu.", 'pl': "W artykule przedstawiono wyniki trzeciego wspólnego zadania dotyczącego realizacji powierzchni wielojęzycznych (SR'20), które zostało zorganizowane w ramach warsztatów COLING'20 dotyczących realizacji powierzchni wielojęzycznych. Podobnie jak w przypadku SR'18 i SR'19, wspólne zadanie składało się z dwóch ścieżek: (1) płytki tor, w którym wejścia były pełnymi strukturami UD z usuniętymi informacjami o kolejności słów i lemmatyzowanymi tokenami; oraz (2) Deep Track, gdzie dodatkowo usunięto słowa funkcjonalne i informacje morfologiczne. Ponadto każdy tor miał dwa podziały: a) ograniczone zasoby, w których do modeli szkoleniowych mogły być wykorzystywane tylko dane dostarczone lub zatwierdzone jako część toru, oraz b) otwarte zasoby, w których można było wykorzystać wszelkie dane. Płytki Track był oferowany w 11-językach, natomiast Deep Track w 3-językach. Systemy były oceniane zarówno przy użyciu automatycznych wskaźników, jak i bezpośredniej oceny przez ludzi pod kątem czytelności i podobieństwa znaczenia do wyników referencyjnych. Przedstawiamy wyniki oceny wraz z opisem ścieżek SR'19, danymi i metodami oceny, a także krótkie streszczenia uczestniczących systemów. Pełny opis uczestniczących systemów można znaleźć w oddzielnych raportach systemowych w innym miejscu tego tomu.", 'si': "මේ පත්තුව පෙන්වන්නේ තුන්වෙනි භාෂාවික පුළුවන් වැඩසටහන (SR'20) වලින් තුන්වෙනි වැඩසටහන් වැඩසටහන් වලින් පුළුවන් වැඩසටහ SR'18 සහ SR'19 වලින්, කොටස් දෙකක් තිබුණු කාර්ය: (1) ශාලෝ ට්\u200dරැක් එකක් තිබුණා වචන පද්ධති තොරතුරු සඳහා පුරුණු UD නිර්මාණය සඳ ඒ වගේම (2) ගොඩක් පරීක්ෂණයක් තියෙන්නේ, සම්පූර්ණ වචන සහ මෝර්ෆෝලෝජික තොරතුරු අතුරුද තවත්, හැම ප්\u200dරකාරයෙක්ම සබ්ට්\u200dරැක්ස් දෙකක් තිබුනා: a) සීමාවිත ප්\u200dරකාරයක් තිබුනා, කොහොමත් ප්\u200dරකාරයක් විතරයි ප්\u200dරකාරයක් විතරයි ප්\u200dරක ශැල්ලෝ ට්\u200dරැක් එක භාෂාවල් 11 වලින් පෙනුම් කරලා තියෙනවා, ඒත් ගොඩක් ට්\u200dරැක් 3 වලින්. පද්ධතිය ස්වයංක්\u200dරියාත්මක මෙට්\u200dරික් සහ මිනිස්සු විශේෂකයෙන් ප්\u200dරතික්\u200dරියාත්මක විශේෂකය සහ අදහස් ප්\u200dරතික්\u200d අපි විශ්ලේෂණ ප්\u200dරතිචාරය, SR'19 ට්\u200dරේක්, දත්ත හා විශ්ලේෂණ ප්\u200dරතිචාරය, සහ සමාව සම්පූර්ණ පද්ධතියේ ප්\u200dරතිච සම්පූර්ණ පද්ධතියේ සම්පූර්ණ විස්තරණය සඳහා, කරුණාකරලා මේ වෝල්යුම් වලින් වෙනස් තැනට ප", 'ro': "Această lucrare prezintă rezultatele celei de-a treia sarcini comune privind realizarea suprafețelor multilingve (SR'20), organizate în cadrul atelierului COLING'20 privind realizarea suprafețelor multilingve. Ca și în SR'18 și SR'19, sarcina partajată a cuprins două piese: (1) o pistă subterană în care intrările erau structuri UD complete, informațiile privind ordinea cuvintelor eliminate și jetoanele lemmatizate; și (2) o pistă profundă unde, în plus, cuvintele funcționale și informațiile morfologice au fost eliminate. Mai mult decât atât, fiecare pistă a avut două substraturi: (a) resurse restricționate, în cazul în care numai datele furnizate sau aprobate ca parte a unei piste ar putea fi utilizate pentru modele de formare și (b) resurse deschise, în cazul în care orice date ar putea fi utilizate. The Shallow Track a fost oferit în 11 limbi, în timp ce Deep Track în 3 limbi. Sistemele au fost evaluate utilizând atât măsurători automate, cât și evaluarea directă de către evaluatorii umani în ceea ce privește lizibilitatea și semnificația similară cu rezultatele de referință. Prezentăm rezultatele evaluării, împreună cu descrierile traseelor SR'19, datele și metodele de evaluare, precum și scurte rezumate ale sistemelor participante. Pentru descrieri complete ale sistemelor participante, vă rugăm să consultați rapoartele de sistem separate din altă parte a acestui volum.", 'sv': "Denna uppsats presenterar resultaten från den tredje gemensamma uppgiften om flerspråkig ytrealisering (SR'20) som organiserades som en del av COLING'20 Workshop om flerspråkig ytrealisering. Precis som i SR'18 och SR'19 bestod den delade uppgiften av två spår: (1) en tunn bana där ingångarna var fullständiga UD-strukturer med ordordningsinformation borttagen och tokens lemmatiserade. och (2) ett Deep Track där dessutom funktionella ord och morfologisk information togs bort. Dessutom hade varje spår två subtrakter: a) begränsad resurs, där endast de uppgifter som lämnats eller godkänts som en del av ett spår kunde användas för utbildningsmodeller, och b) öppen resurs, där alla data kunde användas. The Shallow Track erbjöds på 11 språk, medan Deep Track i 3 språk. Systemen utvärderades med hjälp av både automatiska mätvärden och direkt bedömning av mänskliga utvärderare när det gäller läsbarhet och signifikant likhet med referensresultat. Vi presenterar utvärderingsresultaten, tillsammans med beskrivningar av SR'19-spåren, data och utvärderingsmetoder samt korta sammanfattningar av de deltagande systemen. För fullständiga beskrivningar av de deltagande systemen, se de separata systemrapporterna någon annanstans i denna volym.", 'so': "Warqaddan waxaa ka soo jeeda shaqada saddexaad ee loo sharciyey (SR'20) oo loo qabanqaabiyey qeyb ka mid ah COLING'20 Workshop on Realisation of luuqadaha badan. Sidii SR'18 iyo SR'19, shaqada la qaybsaday waxay ka kooban yihiin laba waddooyin: (1) Baar Shallo ah oo ay inputku buuxeen dhismo UD ah oo ku qoran macluumaad ku saabsan qoraalka oo la dhaqaajiyey iyo calaamado la xarrimay; iyo jid hoos u dheer oo ay ka qaadeen hadalo shaqo badan iyo macluumaad morphologi ah. Sidoo kale wado walba waxay lahayd laba kooban: (a) resource xadiiqad ah, meesha lagu isticmaali karo macluumaad oo kaliya ama loo ogolaanayo sida qayb ka mid ah wado, iyo (b) resource furan, meesha macluumaad oo dhan lagu isticmaali karo. Gaadiidka cas waxaa lagu bixiyey 11 luuqadood, iyadoo lagu daray 3 kooxood. Systemada waxaa lagu qiimeeyay isticmaalka caadooyinka iyo qiimeynta tooska ah ee qofka qiimeynaya si waafaqsan iyo waxyaabaha u jeeda isku mid ah ee soo jeedidda. We present the evaluation results, along with descriptions of the SR'19 tracks, data and evaluation methods, as well as brief summaries of the participating systems.  Si aad u qortid qoraalka buuxda nidaamka ka qeybqaadashada, waxaad aragtaa wargelinta nidaamka gooni ah meel kale oo codsigaas ku qoran.", 'ta': "இந்த காகிதத்தில் மூன்றாம் பகிர்ந்த பணி SR'18 மற்றும் SR'19-ல் பகிர்ந்த செயல் இரண்டு தடங்களாக உள்ளீடுகள் முழுமையான UD அமைப்புகளுடன் வார்த்தை வரிசையில் நீக்கப்பட்ட தகவல் மற்றும் குறிகள்  (2) ஒரு ஆழமான தடம் அதில் கூடுதலாக, செயல்பாடு வார்த்தைகள் மற்றும் கூடுதல் தகவல் நீக்கப்பட்டது. மேலும், ஒவ்வொரு தடத்திலும் இரண்டு துணை தடங்கள் இருந்தது: (a) கட்டுப்படுத்தப்பட்ட மூலத்தை மட்டும் தடத்தில் கொடுக்கப்பட்டுள்ள தகவல் அல்லது அனுமதிக்கப்பட்டுள Name தானியங்கி மெட்ரிக்களையும் மற்றும் மனித மதிப்பீட்டாளர்களால் நேரடியாக மதிப்பிடும் அமைப்புகளுக்கு மதிப்பிடப்பட்டது மற்றும் புரி இந்த மதிப்பின் முடிவுகளைக் கொண்டு SR'19 தடங்கள் வரையறையுடன், தரவுகள் மற்றும் மதிப்பிட முறைமைகளையும் கொண்டு காண்பிக்கிறோம், மற்றும பகிர்ந்து கொள்ளும் அமைப்புகளின் முழு விவரங்களுக்கு, இந்த ஒலியளவில் வேறு இடத்தில் உள்ள தனிப்பட்ட அமைப்பு", 'ur': "یہ کاغذ متعدد زبان سپریز ریلیزانیز (SR'20) پر تیسرے مشترک ٹاکس کے نتائج کا ذریعہ پیش کرتا ہے جو COLING'20 کارشاپ کے حصہ میں متعدد زبان سپریز ریلیزانیز کے بارے میں سازمان کیا گیا تھا. جیسے SR'18 اور SR'19 میں، مشترک کام دو ٹراک میں شامل ہوا: (1) ایک شالوی ٹراک جہاں اینپوٹ پورے UD ساختاروں میں لفظ کے ذریعہ معلومات مٹائے ہوئے تھے اور نشانیاں لیمیٹ کیے گئے تھے۔ اور (2) ایک عمیق ٹراک جہاں اضافہ کے ساتھ، فعالیت کی کلمات اور مورفولوجی معلومات ہٹ دی گئی تھی۔ اور اس کے علاوہ، ہر ٹراک کے پاس دو سوٹراک تھا: a) محدود-سروسیز، جہاں صرف ایک ٹراک کے حصہ سے دیئے گئے یا تصدیق کئے گئے ہیں، ٹراک کے لئے استعمال کئے جاتے ہیں، اور b) کھولے-سروسیز، جہاں کوئی ڈیٹا استعمال کر سکتا ہے. Shallow Track کو 11 زبانوں میں پیش کیا گیا تھا، حالانکہ عمیق ترک تین میں ہے. سیسٹموں کو پڑھنے کے قابلیت اور منظورت کے مطابق سیدھی میٹریک اور مستقیم ارزیابی کے مطابق انسان کی ارزیابی کے ذریعے مطابق کیا گیا تھا. ہم نے ارزیابی نتیجے پیش کیے ہیں، SR'19 ٹریک، ڈیٹا اور ارزیابی طریقے کے مطابق، اور مشارکت سیستموں کی تھوڑی سی مطابق۔ شرکت کرنے والے سیسٹم کی پوری توصیف کے لئے، لطفا اس واوئل میں دوسرے جگہ مختلف سیسٹم راپورٹ دیکھو.", 'uz': "Bu hujjat bir necha tillar survey haqida bogʻliq boʻlgan Vazifani (SR'20) haqida ishga tushirish natijalariga ega beradi. SR-18 va SR-19 kabi boʻlishilgan vazifani ikki yo'plarga qo'shilgan: (1) Oʻyin tuzuvlar toʻliq UD strukturelari bilan bir so'z tartibi maʼlumot olib tashlangan va belgilarni olib tashlash mumkin. (2) qo'shimcha, ishlaydigan so'zlar va morfological maʼlumot olib tashlanmoqda. Moreover, each track had two subtracks: (a) restricted-resource, where only the data provided or approved as part of a track could be used for training models, and (b) open-resource, where any data could be used.  Name Tizimlarni avtomatik metrikdan foydalanish va oddiy qiymatlarga qo'yish va Nadam qiymatlari qo'yish natijalariga oʻxshash mumkin. Biz qiymatlar natijalarini hozir qilamiz, SR'19 tracklarining taʼriflari bilan, maʼlumot va qiymatlar usullarini va qiymatlash usullarining qisqarli tizimlarning qisqartmalari. @ info: whatsthis", 'vi': 'Tờ giấy này đưa ra kết quả từ tập đoàn chia sẻ "Việc thực hiện mặt đất đa ngôn ngữ" (SR\'20) được tổ chức như một phần của "Cuộc thực hiện mặt đất đa ngôn ngữ". Giống như SR\'18 và SR\'19, nhiệm vụ chia sẻ gồm hai dấu vết: 1) một đường tàu Shalalow, nơi nhập đã có cấu trúc UD đầy đủ với việc gỡ bỏ thông tin trật tự từ ngữ và hiệu hòa hợp; và (2) một con đường mòn sâu nơi còn gỡ bỏ các từ chức năng và các thông tin lịch sử. Thêm vào đó, mỗi đường ray có hai loại trừ: a) nguồn hạn chế, khi chỉ những dữ liệu được cung cấp hay chấp nhận như một phần của đường ray có thể được dùng cho các mô hình huấn luyện, và b) nguồn mở, nơi có thể dùng b ất kỳ dữ liệu nào. The Shalow track was đề nghị in 11 language, while the Deep track in 3 ones. Hệ thống được đánh giá dựa trên khả năng đo lường tự động và đánh giá trực tiếp của người đánh giá về mức dựa trên mức dựa trên khả năng gần đạt kết quả. Chúng tôi cung cấp kết quả đánh giá cùng với mô tả các đường ray SR\'19, dữ liệu và phương pháp đánh giá, cũng như mô tả ngắn gọn các hệ thống tham gia. Để mô tả đầy đủ các hệ thống tham gia, hãy xem báo cáo hệ thống khác nhau ở đâu đó trong số lượng này.', 'da': "Dette dokument præsenterer resultaterne af den tredje delte opgave om realisering af flersprogede overflader (SR'20), som blev organiseret som en del af COLING'20 Workshop om realisering af flersprogede overflader. Som i SR'18 og SR'19 omfattede den fælles opgave to spor: (1) et Shallow Track, hvor indgangene var fulde UD-strukturer med ordrækkefølgeoplysninger fjernet og tokens lemmatiseret; og (2) et dybt spor, hvor desuden funktionelle ord og morfologiske oplysninger blev fjernet. Desuden havde hvert spor to subtraktater: a) begrænset ressource, hvor kun de data, der blev leveret eller godkendt som en del af et spor, kunne anvendes til uddannelsesmodeller, og b) open ressource, hvor eventuelle data kunne anvendes. The Shallow Track blev tilbudt på 11 sprog, mens Deep Track i 3 sprog. Systemerne blev evalueret ved hjælp af både automatiske målinger og direkte vurdering af menneskelige evaluatorer med hensyn til læsbarhed og betydning lighed med referenceoutput. Vi præsenterer evalueringsresultaterne sammen med beskrivelser af SR'19 spor, data og evalueringsmetoder samt korte resuméer af de deltagende systemer. For fuldstændige beskrivelser af de deltagende systemer henvises til de særskilte systemrapporter andre steder i dette bind.", 'bg': "Настоящата статия представя резултатите от Третата споделена задача за многоезично реализиране на повърхности (SR'20), организирана като част от семинара COLING'20 за многоезично реализиране на повърхности. Както и в SR'18 и SR'19, споделената задача се състои от две писти: (1) плитка писта, в която входовете са били пълни структури на UD с премахната информация за реда на думите и символите са лематизирани; и (2) Дълбока пътека, където допълнително са премахнати функционални думи и морфологична информация. Освен това всяка писта е имала две изваждания: а) ограничен ресурс, при който само предоставените или одобрени като част от пистата данни могат да бъдат използвани за модели на обучение, и б) открит ресурс, при който могат да бъдат използвани всякакви данни. Плитката писта се предлага на 11 езика, докато Дълбоката писта на 3 езика. Системите бяха оценени както чрез автоматични показатели, така и чрез директна оценка от човешки оценители по отношение на четливостта и сходството на значението с референтните изходи. Представяме резултатите от оценката, както и описания на пистите на СР'19, данни и методи за оценка, както и кратки обобщения на участващите системи. За пълно описание на участващите системи вижте отделните системни доклади другаде в този том.", 'nl': "Dit artikel presenteert de resultaten van de derde gedeelde taak voor meertalige oppervlakterealisatie (SR'20) die werd georganiseerd in het kader van de COLING'20 Workshop over meertalige oppervlakterealisatie. Net als in SR'18 en SR'19 bestond de gedeelde taak uit twee tracks: (1) een Shallow Track waar de invoer volledige UD-structuren waren waarbij woordordeinformatie werd verwijderd en tokens werden gemamatiseerd; en (2) een Deep Track waarbij bovendien functionele woorden en morfologische informatie werden verwijderd. Bovendien bestond elk spoor uit twee subtracks: a) beperkte hulpbronnen, waarbij alleen de gegevens die als onderdeel van een spoor werden verstrekt of goedgekeurd voor opleidingsmodellen konden worden gebruikt, en b) open hulpbronnen, waar gegevens konden worden gebruikt. De Shallow Track werd aangeboden in elf talen, terwijl de Deep Track in drie talen. Systemen werden geëvalueerd met behulp van zowel automatische metrics als directe beoordeling door menselijke beoordelaars in termen van leesbaarheid en betekenisgelijkenis met referentieoutputs. We presenteren de evaluatieresultaten, samen met beschrijvingen van de SR'19 tracks, gegevens en evaluatiemethoden, evenals korte samenvattingen van de deelnemende systemen. Zie de afzonderlijke systeemrapporten elders in dit deel voor een volledige beschrijving van de deelnemende systemen.", 'hr': "Ovaj papir predstavlja rezultate trećeg zajedničkog zadatka o stvaranju multijezičkih površina (SR'20), koji je organiziran kao dio radionice COLING'20 o stvaranju multijezičkih površina. Kao u SR'18 i SR'19, zajednički zadatak sastojio je dva traga: (1) Shallow Track gdje su ulazi bili pune UD strukture s uklonjenim informacijama o riječima reda i limmatiziranim znakovima; i (2) duboki trag gdje su dodatno uklonili funkcionalne riječi i morfološke informacije. Osim toga, svaki trag imao je dva podrakta: a) ograničena resursa, gdje se mogu koristiti samo podaci koje su pružene ili odobrene kao dio traga za modele obuke, i b) otvorene resurse, gdje bi se bilo koje podatke moglo koristiti. Skloni trag je ponudio na 11 jezika, dok je duboki trag u 3. Sistemi su procjenjivali kako koriste automatsku metriku, tako i direktnu procjenu ljudskih procjenjivača u smislu Readability i Meaning Similarity to reference outputs. Predstavljamo rezultate procjene, zajedno s opisima tragova SR'19, metoda podataka i procjene, kao i kratkih sažetaka sustava sudjelovanja. Za potpune opise sustava sudjelovanja, molim vas vidjeti odvojene izvještaje sustava negdje drugdje u ovom objektu.", 'de': "Dieser Beitrag stellt Ergebnisse der dritten gemeinsamen Aufgabe zur mehrsprachigen Oberflächenrealisierung (SR'20) vor, die im Rahmen des COLING'20 Workshops zur mehrsprachigen Oberflächenrealisierung organisiert wurde. Wie in SR'18 und SR'19 umfasste die gemeinsame Aufgabe zwei Spuren: (1) einen Shallow Track, bei dem die Eingaben vollständige UD-Strukturen waren, wobei Wortreiheninformationen entfernt und Token lemmatisiert wurden; und (2) ein Deep Track, bei dem zusätzlich funktionelle Wörter und morphologische Informationen entfernt wurden. Darüber hinaus hatte jede Strecke zwei Subtrakte: a) begrenzte Ressourcen, bei denen nur die im Rahmen einer Strecke bereitgestellten oder genehmigten Daten für Trainingsmodelle verwendet werden konnten, und b) offene Ressourcen, bei denen Daten verwendet werden konnten. Der Shallow Track wurde in elf Sprachen angeboten, während der Deep Track in drei Sprachen angeboten wurde. Die Systeme wurden sowohl mit automatischen Metriken als auch mit direkter Bewertung durch menschliche Evaluatoren hinsichtlich Lesbarkeit und Bedeutungsgleichheit zu Referenzergebnissen bewertet. Wir stellen die Evaluierungsergebnisse zusammen mit Beschreibungen der SR'19 Tracks, Daten und Evaluierungsmethoden sowie kurzen Zusammenfassungen der teilnehmenden Systeme vor. Ausführliche Beschreibungen der teilnehmenden Systeme finden Sie in den separaten Systemberichten an anderer Stelle in diesem Band.", 'id': "Kertas ini mempersembahkan hasil dari Tugas Tertiga Berkongsi tentang Realisasi Surface Berbahasa (SR'20) yang diatur sebagai bagian dari Workshop COLING'20 tentang Realisasi Surface Berbahasa. Seperti dalam SR'18 dan SR'19, tugas berbagi terdiri dari dua trek: (1) Trek Shallow dimana masukan adalah struktur UD penuh dengan informasi perintah kata dihapus dan token lemmatis; dan (2) Trek Dalam di mana tambahan, kata-kata fungsional dan informasi morfologis dihapus. Selain itu, setiap trek memiliki dua tolak: (a) sumber daya terbatas, di mana hanya data yang disediakan atau disetujui sebagai bagian dari trek dapat digunakan untuk model pelatihan, dan (b) sumber daya terbuka, di mana data apapun dapat digunakan. The Shallow Track ditawarkan dalam 11 bahasa, sementara Deep Track dalam 3 bahasa. Sistem diteliti menggunakan metrik otomatis dan penelitian langsung oleh evaluasi manusia dalam terma Readability and Meaning Similarity to reference outputs. We present the evaluation results, along with descriptions of the SR'19 tracks, data and evaluation methods, as well as brief summaries of the participating systems.  Untuk deskripsi lengkap sistem yang berpartisipasi, silakan lihat laporan sistem terpisah di tempat lain dalam volume ini.", 'ko': "본고는 세 번째 다국어 표면 실현 공유 임무(SR'20)의 결과를 소개했다. 이 임무는 코린'20다국어 표면 실현 세미나의 일부로 조직된 것이다.SR'18과 SR'19과 마찬가지로 공유 작업은 두 개의 궤도로 구성된다. (1) 얕은 궤도, 그 중에서 완전한 UD 구조를 입력하고 어순 정보를 삭제하며 표시를 레몬화했다.(2) 기능어와 형태 정보가 삭제된 깊은 궤적그 밖에 모든 트랙에는 두 개의 서브 트랙이 있다. (a) 제한된 자원이 있는데 그 중에서 트랙의 일부분으로 제공되거나 승인된 데이터만 훈련 모델에 사용할 수 있다. (b) 자원을 개방하고 그 중에서 어떠한 데이터도 사용할 수 있다.얕은 트랙은 11개 언어, 깊은 트랙은 3개 언어가 있다.가독성과 참고 출력의 의미와 유사성에 있어 시스템은 자동 도량과 인류 평가 인원의 직접 평가를 통해 평가한다.우리는 평가 결과와 SR'19 궤도, 데이터와 평가 방법에 대한 설명, 그리고 참여 시스템의 간략한 요약을 소개할 것이다.참여 시스템에 대한 완전한 설명은 본 권의 다른 곳에 있는 단독 시스템 보고서를 참조하십시오.", 'sw': "Gazeti hili linaonyesha matokeo ya kazi ya Tatu inayoshirikishwa kwenye Ukweli wa Surface Multilingua (SR'20) ulioandaliwa kama sehemu ya warsha ya 20 ya COLING kuhusu Ukweli wa Surface Multilingua. Kama ilivyokuwa kwenye SR'18 na SR'19, kazi hiyo ilishirikiana ilikuwa ni njia mbili: (1) Shirika la Mshindo lililokuwa na majengo ya UD ambapo matokeo yalikuwa yamejaa viungo vya UD pamoja na taarifa za maneno yaliyoondolewa na ishara zilizotengenezwa; na barabara la ndani ambapo maneno mengi na taarifa za kifo ziliondolewa. Zaidi ya hayo, kila njia ilikuwa na vifaa viwili vya chini: (a) rasilimali zilizozuiwa, ambapo taarifa tu zinazotoa au kupitishwa kama sehemu ya mfumo unaweza kutumika kwa ajili ya mifano ya mafunzo, na (b) rasilimali huru, ambapo taarifa zote zinaweza kutumika. Barabara ya Mekundu ilitolewa kwa lugha 11, wakati barabara la kina katika moja tatu. Mfumo ulivutiwa kwa kutumia mbinu za kujitegemea na kutathmini moja kwa moja na watafiti wa binadamu kwa mujibu wa Uhuru na maana yanayofanana na matokeo ya maoni. Tunaonyesha matokeo ya uchunguzi, pamoja na maelezo ya viwanja vya SR-19, taarifa na njia za uchunguzi, pamoja na muhtasari mfupi wa ushiriki. Kwa maelezo kamili ya mifumo ya ushiriki, tafadhali tazama mfumo huo unaripoti sehemu nyingine katika ujazo huu.", 'fa': "این کاغذ نتیجه\u200cهایی از کار سوم مشترک در مورد Realization Surface Multilingual (SR'20) که به عنوان بخشی از کارگاه COLING'20 در مورد Realization Multilingual Surface واقع شده است را نشان می\u200cدهد. همانطور که در SR'18 و SR'19، وظیفه مشترک دو رد شامل شد: (۱) یک رد شالوی جایی که ورودها ساختار UD کامل بودند با اطلاعات سفارشی کلمه\u200cها از دست داده شده و نشانه\u200cهای لیماتیک شده بود. و (۲) یک ردیابی عمیق جایی که به اضافه\u200cای، کلمات عملکرد و اطلاعات مورفولوژیک حذف شده است. علاوه بر این، هر نقاشی دو قطعه\u200cای داشت: a) منبع محدود، جایی که تنها داده\u200cها که به عنوان بخشی از یک نقاشی به عنوان بخشی از یک نقاشی داده شده یا تصدیق شده\u200cاند می\u200cتوانند برای مدل آموزش استفاده کنند، و b) منبع باز، جایی که هر داده\u200cای ردیاب شالوی در ۱۱ زبان پیشنهاد شد، در حالی که ردیاب عمیق در ۳ تن. سیستم\u200cها با استفاده از متریک\u200cهای خودکار و ارزیابی مستقیم توسط ارزیابگران انسان در نظر خواندن قابلیت و معنی شبیه به نتیجه\u200cهای ارزیابی ارزیابی ارزیابی شدند. ما نتیجه ارزیابی را با توضیح\u200cهای سیستم\u200cهای SR'19، داده\u200cها و روش\u200cهای ارزیابی و جمع\u200cآوری\u200cهای کوتاه\u200cای از سیستم\u200cهای مشارکت نشان می\u200cدهیم. برای توضیح کامل سیستم\u200cهای مشترک، لطفا گزارش سیستم جدا را در جایی دیگر در این صفحه ببینید.", 'tr': "Bu kagyz Multilingual Surface Realization (SR'20) üzerinden üçünji Paýlaşmış zadynyň netijesini COLING'20 Multilingual Surface Realization'yň bir parçasynda bellenilýär. SR'18 we SR'19'da ýazmak täblisasynda iki hatlary bar: (1) giriş gaplarynyň doly UD düzümleri söz düzümleri ýitilýär we bellenenleri bilen tapylýan täblisasynda (UD düzümleri) bar. (2) Bir derin çizgi eklenmiş, fonksiyonel sözler ve morfolojik bilgiler silinen bir çizgi. Munuň ýene-de, her ritmäň iki astrasy bardy: a) mahsus-resow, ol ýerde diňe berilen ýa-da bir ritmäň bir b ölegi ýaly tassyklanýan maglumaty modeller üçin ullanyp biler, we (b) a ç-resow we her maglumaty ullanabiler. 11 dilde geçirilýär Sistemler okuwçylyk we golaýlaşyk çykyşlary bilen otomatik metriklerden we düzgünçiliklerden hem ynsan çykyşlaryny ulanyp deňlendirildi. Ýükleme netijesini SR'19 hatlaryň, maglumat we çykyş metodlarynyň tassymlary bilen birlikde çykýarys. Gatnaşmak sistemlerin doly düşündirilmesi üçin, haýyşt bu volume'yň başga ýerinde ayrı sistem raporlaryny göräň.", 'sq': "Ky dokument paraqet rezultatet e Detyrës së Tretë të Përbashkët mbi Realizimin e Surfaqes Shumë-gjuhëse (SR'20) që u organizua si pjesë e Workshop COLING'20 mbi Realizimin e Surfaqes Shumë-gjuhëse. Ashtu si në SR'18 dhe SR'19, detyra e përbashkët përfshinte dy gjurmë: (1) një gjurmë të hijshme ku hyrjet ishin struktura të plota UD me informacion të rendit të fjalëve të hequr dhe shenjat limmatizuar; dhe (2) një rrugë të thellë ku shtesë, fjalët funksionale dhe informacioni morfologjik u hoqën. Përveç kësaj, çdo gjurmë kishte dy heqje: (a) burime të kufizuara, ku vetëm të dhënat e dhëna apo të miratuara si pjesë e një gjurmë mund të përdoreshin për modelet e trajnimit dhe (b) burime të hapura, ku mund të përdoreshin çdo të dhëna. Pika e Zi u ofrua në 11 gjuhë, ndërsa Pika e thellë në 3 gjuhë. Sistemet u vlerësuan duke përdorur si metrika automatike ashtu edhe vlerësimin e drejtpërdrejtë nga vlerësuesit njerëzor lidhur me lexueshmërinë dhe kuptimin e ngjashmërisë me rezultatet e referimit. Ne paraqesim rezultatet e vlerësimit, së bashku me përshkrimin e gjurmëve të SR'19, të dhënave dhe metodave të vlerësimit si dhe përmbledhje të shkurtra të sistemeve pjesëmarrëse. Për përshkrimin e plotë të sistemeve pjesëmarrëse, ju lutem shihni raportet e sistemit të veçanta diku tjetër në këtë volum.", 'am': "ይህ ገጽ በብዛት ቋንቋ የፊት አቀማመጥ (SR'20) የተዘጋጀ በCOLING 20 workshop ላይ ተካክሎ ከሦስተኛው የተካፈለ ስራ ነው፡፡ እንደ SR-18 እና SR-19, የተካፈሉት ስራ ሁለት መንገዶች ነው:(1) ጥቁር የውጤቶች ውስጥ በሙሉ UD መሠረቶች የተደረጉበት የንግግር መረጃዎች በተነሳው እና ምልክቶች በተለየ ማተሚያ የተደረጉበት ጥቁር Track:) (2) የጥልቅ መንገዶች፣ በተጨማሪም፣ የሥራ ቃላት እና የሞፎሎጂ መረጃዎች ተወስደዋል፡፡ ከዚህም በላይ ለሁሉም መንገዱ ሁለት ጥቅሎች ነበሩት:(a) የተከለከለ-resource, where the data provided or approved as part of a track, and (b) data can be used for training models, and (b) open resource where the data can be used. የጥልቅ መንገድ በአሥራ 11 ቋንቋዎች አቀረበ፥ የጥልቅ መንገድ ግን በ3 ቋንቋዎች ነው፡፡ ሲስተምሮቹ በአካባቢነት እና የአየር ውጤቶች በሚያስተካክሉ የሰው ውጤቶች ማሰናከል እና ማሰናከል በሚያስተካከሉ ነው፡፡ አካሄደውን ፍጥረቶች እና SR-19 እግር፣ ዳታዎችን እና ማስታወቂያውን እና የአካባቢው ስርዓት አቁራጭ እናደርጋለን፡፡ በሙሉ ግንኙነት ሲስተም ለመጠቀም፣ እባክዎ የተለየ ሲስተም በዚህ ድምፅ በሌላ ስፍራ እንደሆነ ተመልከቱ፡፡", 'af': "Hierdie papier stel resultate van die Trede Gedeelde Opdrag op Multilingual Surface Realisation (SR'20) wat georganiseer is as deel van die Koling'20 Werkshop op Multilingual Surface Realisation. Soos in SR' 18 en SR' 19, het die gedeelde taak twee snitte bevat: (1) ' n Skaal Snit waar die inputs volledige UD strukture was met woord volgorde inligting verwyder en tokens lemmatiseer; en en (2) â\x80\x99n Deep Snit waar by addisionele, funksionele woorde en morfologiese inligting verwyder is. Ook het elke snit twee subtrakke gehad: (a) beperkte-hulpbron, waar slegs die data verskaf of geantwoord word as deel van 'n snit kon gebruik word vir onderwerp modele, en (b) oop-hulpbron, waar enige data kon gebruik word. Die Skaal Snit is in 11 taal aangebring, maar die Deep Snit in 3 een. Stelsels is geevalueer deur automatiese metries en direkte evalueering deur menslike evalueerders in terms of Readability and Meaning Similarity to reference outputs. Ons voorsien die evalueringsresultate, saam met beskrywings van die SR'19 snitte, data en evalueringsmetodes, en kort opsommings van die deelnadende stelsels. Vir volledige beskrywings van die gedeeldende stelsels, sien asseblief die aparte stelsel raporteer anders in hierdie volume.", 'hy': "Այս աշխատանքը ներկայացնում է բազմալեզու մակերևույթի իրականացման երրորդ հանձնարարության արդյունքները (ՍՌ'20), որը կազմակերպել է որպես COLinG'20-ի բազլեզու մակերևույթի իրականացման աշխատասենյակի մի մաս: Ինչպես ՍՌ'18 և ՍՌ'19 դեպքում, ընդհանուր առաջադրանքը կազմված էր երկու հետագիր: (1) Սպիտակ հետագիր, որտեղ ներմուծները լիարժեք UD կառուցվածքներ էին բառի կարգով տեղեկատվություն վերացնելով և նշանները լիմմատիզացված էին: և (2) խորը ճանապարհ, որտեղ նաև ֆունկցիոնալ բառերը և մորֆոլոգիական տեղեկատվությունը հեռացվեցին: Ավելին, յուրաքանչյուր ճանապարհ ունի երկու հանձնարարություն: a) սահմանափակ ռեսուրսներ, որտեղ միայն ճանապարհի մեջ տրամադրված կամ ընդունված տվյալները կարող էին օգտագործվել ուսուցման մոդելների համար, և b) բաց ռեսուրսներ, որտեղ կարող էին օգտագործվել Սպիտակ ճանապարհը առաջարկում էր 11 լեզուներով, իսկ խորը ճանապարհը՝ 3 լեզուներով: Այս համակարգերը գնահատվեցին օգտագործելով ոչ ավտոմատիկ մետրիկներ, այլ նաև մարդկային գնահատողների կողմից անմիջական գնահատումներ կարդալիության և նշանակության առումով՝ համեմատական արդյունքների նման: We present the evaluation results, along with descriptions of the SR'19 tracks, data and evaluation methods, as well as brief summaries of the participating systems.  մասնակցող համակարգերի ամբողջական նկարագրությունների համար, խնդրում եմ տեսնել այս ծավալի տարբեր համակարգերի զեկույցները:", 'ca': "Aquest paper presenta resultats de la Tercera Task Compartida sobre la Realització de la Superfície Multilingüe (SR'20), que va ser organitzada com part de l'atelier COLING'20 sobre la Realització de la Superfície Multilingüe. Com en SR'18 i SR'19, la tasca compartida consistia en dues pistes: (1) una pista sombra on les entrades eren estructures UD plenes amb informació d'ordre de paraules eliminada i fitxes lemmatitzades; i (2) una pista profunda on, a més, es van eliminar paraules funcionals i informació morfològica. A més, cada pista tenia dos subtraccions: a) recursos restringits, on només les dades proporcionades o aprovades com part d'una pista podrien ser utilitzades per a models d'entrenament, i b) recursos oberts, on podrien ser utilitzades qualsevol data. El Shallow Track es va oferir en 11 llengües, mentre el Deep Track en 3. Els sistemes van ser evaluats utilitzant tant la mètrica automàtica com la directa d'evaluadors humans en termes de llegibilitat i significat Similaritat als productes de referència. Presentam els resultats d'evaluació, juntament amb descripcions de les pistes de l'SR 19, les dades i els mètodes d'evaluació, i breus resumes dels sistemes participants. Per descripcions completas dels sistemes participants, veureu els informes del sistema diferents en altres llocs d'aquest volum.", 'bs': "Ovaj papir predstavlja rezultate trećeg zajedničkog zadatka o realizaciji višejezičkih površina (SR'20), koji je organiziran kao dio radionice COLING'20 o realizaciji višejezičkih površina. Kao u SR'18 i SR'19, zajednički zadatak sastojio je dva traga: (1) Shallow Track gdje su ulazi bili pune UD strukture sa uklonjenim informacijama o redu riječi i limmatiziranim znakovima; i (2) duboki trag gdje su dodatno uklonili funkcionalne riječi i morfološke informacije. Osim toga, svaki trag imao je dva podrakta: a) ograničena resursa, gdje se mogu koristiti samo podaci koji su pruženi ili odobreni kao dio traga za modele obuke, i b) otvoreni resurs, gdje bi se mogli koristiti svaki podaci. Zadnji trag je ponudio na 11 jezika, dok je duboki trag u 3. Sistemi su procijenjeni koristeći automatsku metriku i direktnu procjenu ljudskih procjenitelja u smislu Readability i Meaning Similarity to reference outputs. Predstavljamo rezultate procjene, zajedno sa opisima tragova SR'19, metoda podataka i procjene, kao i kratkih sažetaka sustava sudjelovanja. Za potpune opise sustava sudjelovanja, molim vas, vidite odvojene izvještaje sustava negdje drugdje u ovom volumu.", 'az': "Bu kağıt çoxlu dil Yüzü Realizasyonu (SR'20) barəsindəki üçüncü paylaşılmış Taskin sonuçlarını COLING'20 Çalışması haqqında çoxlu dil Yüzü Realizasyonu barəsində organize edilmişdir. SR'18 və SR'19 kimi, paylaşılmış işin iki parçası vardır: (1) İçərilərin dolu UD quruları ilə söz sıralama məlumatı alındı və limmatizirlənmiş işaretlər ilə dolu UD quruları vardır. və (2) funksiyal sözlər və morfolojik məlumatları çəkildiyi bir derin izlər. Daha sonra, hər parça iki dəstək vardı: a) dəstəkləndirilmiş ressurs, o yerdə hər bir məlumat istifadə edilə biləcəyi və ya dəstəkləndirilən məlumatlar təhsil etmək üçün istifadə edilə bilər. Xızıl İzləri 11 dildə təbliğ edildi, lakin derin İzləri 3 dildə təbliğ edildi. Sistemlərin oxuyabiləcəyi və dəyişiklik sonuçlarına bənzəyəcəyi məsələlər haqqında insan değerlendirənlərin automatik metrikləri və doğru değerlendirmələri ilə istifadə edildi. Növbəti sonuçlarını, SR'19 parçalarının, məlumatların və değerlendirmə metodlarının, həmçinin də müəyyən edilən sistemlərin qısa istiqamlarını göstəririk. Bölüş sistemlərin tamamlanması üçün, lütfen bu səviyyədə başqa yerlərdə ayrı sistem raportlarını görün.", 'bn': "এই পত্রিকাটি মাল্টিভাষার সার্ফেস রিয়েশন (এসআর২০) নামে তৃতীয় শেয়ার করা কাজের ফলাফল উপস্থাপন করেছে যা মাল্টিভাষার সার্ফেস রিয়েশনের কোলিঙিং ২০ ওয়া এসআর১৮ এবং এসআর১৯-এ শেয়ার করা কাজের মধ্যে দুটি ট্র্যাক ছিল: (১) একটি শালো ট্র্যাক যেখানে ইনপুট পুরো ইউডি কাঠামো ছিল যেখানে শব্দের আদেশে এবং (২) একটি গভীর ট্র্যাক যেখানে অতিরিক্ত, কার্যকর শব্দ এবং নৈতিক তথ্য অপসারণ করা হয়। এছাড়াও, প্রত্যেক ট্র্যাকে দুটি সাবট্র্যাক ছিল: (a) সীমিত-সম্পদ, যেখানে কেবল তথ্য প্রদান করা অথবা অনুমোদন করা হয় ট্র্যাকের একটি অংশ হিসেবে ব্যবহার করা যাব ১১ ভাষায় শালো ট্র্যাক প্রদান করা হয়, যদিও তিন ভাষায় গভীর ট্র্যাক। স্বয়ংক্রিয়ভাবে মেট্রিক ব্যবহার করা এবং মানুষের মুল্যায়নের দ্বারা সরাসরি মূল্যায়ন করা হয়েছে সিস্টেমের মূল্য প্রতিরোধ এবং এর মানে সে We present the evaluation results, along with descriptions of the SR'19 tracks, data and evaluation methods, as well as brief summaries of the participating systems.  অংশগ্রহণকারী সিস্টেমের সম্পূর্ণ বর্ণনার জন্য অনুগ্রহ করে এই ভলিমে অন্য কোথাও বিভিন্ন সিস্টেমের প্রতি", 'cs': "Tento článek představuje výsledky třetího sdíleného úkolu o vícejazyčné realizaci povrchu (SR'20), který byl pořádán v rámci workshopu COLING'20 o vícejazyčné realizaci povrchu. Stejně jako v případě SR'18 a SR'19, společný úkol zahrnoval dvě stopy: (1) mělkou stopu, kde vstupy byly plné UD struktury s odstraněním informací o pořadí slov a lemmatizovanými tokeny; a (2) Deep Track, kde byly navíc odstraněny funkční slova a morfologické informace. Kromě toho každá trať měla dvě části: a) omezené zdroje, kde mohly být pro modely výcviku použity pouze údaje poskytnuté nebo schválené jako součást trati, a b) otevřené zdroje, kde mohly být použity jakékoli údaje. Shallow Track byl nabízen v jedenácti jazycích, zatímco Deep Track ve třech jazycích. Systémy byly hodnoceny jak pomocí automatických metrik, tak přímého hodnocení lidskými hodnotiteli z hlediska čitelnosti a významové podobnosti s referenčními výstupy. Představujeme výsledky hodnocení spolu s popisem tratí SR'19, daty a metody hodnocení, stejně jako stručné shrnutí zúčastněných systémů. Úplný popis zúčastněných systémů naleznete v samostatných systémových zprávách jinde v tomto svazku.", 'et': "Käesolevas dokumendis esitatakse mitmekeelse pinnarealiseerimise kolmanda ühisülesande (SR'20) tulemusi, mis korraldati mitmekeelse pinnarealiseerimise COLING'20 seminari raames. Nagu ka SR'18 ja SR'19 puhul, hõlmas ühine ülesanne kahte rada: 1) madal rada, kus sisendid olid täielikud UD-struktuurid, kus sõnajärjekorra teave eemaldati ja märgid lemmatiseeriti; ja (2) Deep Track, kus lisaks eemaldati funktsionaalsed sõnad ja morfoloogiline teave. Lisaks sellele oli igal rajal kaks lahutamist: a) piiratud ressurss, kus koolitusmudeliteks saab kasutada ainult raja osana esitatud või heakskiidetud andmeid, ja b) avatud ressurss, kus saab kasutada mis tahes andmeid. Shallow Track pakuti 11 keeles, Deep Track aga 3 keeles. Süsteemide hindamisel kasutati nii automaatseid mõõdikuid kui ka otsest hindamist inimhindajate poolt loetavuse ja tähenduse sarnasuse osas võrdlusväljunditega. Tutvustame hindamise tulemusi, SR'19 rajade kirjeldusi, andmeid ja hindamismeetodeid ning osalevate süsteemide lühikokkuvõtteid. Osalevate süsteemide täieliku kirjelduse saamiseks vaadake eraldi süsteemiaruandeid mujal käesolevas köites.", 'fi': "Tässä artikkelissa esitellään tuloksia kolmannesta monikielistä pintatajua käsittelevästä jaetusta tehtävästä (SR'20), joka järjestettiin osana monikielistä pintatajua käsittelevää COLING'20-työpajaa. Kuten SR'18:ssa ja SR'19:ssä, jaettu tehtävä sisälsi kaksi raitaa: (1) matalan raitan, jossa syötteet olivat täydellisiä UD-rakenteita, sanajärjestyksen tiedot poistettiin ja tunnukset lemmatisoitiin; ja (2) Deep Track, josta lisäksi poistettiin toiminnalliset sanat ja morfologiset tiedot. Lisäksi jokaisella radalla oli kaksi vähennystä: a) rajoitettu resurssi, jossa koulutusmalleihin voitiin käyttää vain radan osana toimitettuja tai hyväksyttyjä tietoja, ja b) avoin resurssi, jossa tietoja voitiin käyttää. Shallow Track oli tarjolla 11 kielellä ja Deep Track kolmella kielellä. Järjestelmät arvioitiin sekä automaattisilla mittareilla että ihmisarvioijien suorilla arvioinneilla luettavuuden ja merkityksen samankaltaisuuden suhteen viitetuotoksiin. Esittelemme arviointitulokset, kuvaukset SR'19-reitistä, tiedot ja arviointimenetelmät sekä lyhyen yhteenvedon osallistuvista järjestelmistä. Täydelliset kuvaukset osallistuvista järjestelmistä löytyvät erillisistä järjestelmäraporteista muualla tässä osassa.", 'jv': 'Perintah iki mudhak akeh tanggal tanggal tanggal 3 (Samplin task) ning Multilanguage surhead Actualisasi (SS\'2) sing dipun dianggo oleh dumadhi buku corLING\'2 Workspace nang Multilanguage surhead Actualisasi. Tuning lan (2) a deep trac Where Additionly, funtional words and shape information are deleted. Label The Wang track is ndheng 11 idisa, wong-wong kuwi deep trac ning 3 lih sing diralah. System ProgressBarUpdates politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': "Wannan karatun na bãyar da ƙarshen aikin na SR'20 wanda aka yi organiza kamar part of the COLIING'20 workspace on Surface Sure-Signition na Kullum. Kamin SR'18 da SR'19, aikin da aka raba su haɗi shi na hanyõyi biyu: (1) wata Shallow Track, inda inputai da aka cika masu tsarin UD da tsarin tsarin maganar da aka tafiyar da information da kuma ayõyin za'a lissafa; kuma wata Trakan Deƙas, inda aka tafiyar da wasu kalmõmi masu amfani da magana na mutfologi. Da haka, kõwane bango yana da sauran biyu: (a) resource mai ƙunci, inda kawai data za'a iya amfani da shi ko kuma a yi yarda da shi kamar rabon hanci ne dõmin yin amfani da misalin mafaka, da (b) resource mai buɗe, inda duk data za'a iya amfani da. The Shallow Track was offered in 11 languages, whereas the Deep Track in 3 ones.  An evaluate Systems da za'a yi amfani da metric farat ɗaya kuma a ƙaddara wa mutane masu ƙaddara da inganci da Ina daidaita zuwa matsayin mazaɓa. Munã halatar da fassarar evaluation, sami da misãlai na SR'19-hanyõyin, da shiryoyin data da evaluation, da kuma ƙari kaɗan na fassarar masu haɗuwa. Don ka sami tsarin bayani na'urar shirin ayuka da ke haɗa, sai ka dũba bayani na tsarin na'urar da ke cikin wannan ƙarami.", 'bo': "ཤོག་བྱང་འདིས་སྒྲུང་གི་དབར་ཆ་མཐུན་གྱི་བྱ་ཚིག་ལས་རྒྱལ་ཁབ་གསུམ་ཆ་མཐུན་གྱི་བྱ་བ་ཞིག་སྟོན་པ་ཡིན། As in SR'18 and SR'19, the shared task comprised two tracks: (1) a Shallow Track where the inputs were full UD structures with word order information removed and tokens lemmatised; and and (2) a Deep Track where additionally, functional words and morphological information were removed. Moreover, each track had two subtracks: (a) restricted-resource, where only the data provided or approved as part of a track could be used for training models, and (b) open-resource, where any data could be used. Name The Shallow Track was offered in 11 languages, whereas the Deep Track in 3 ones. Systems were evaluated using both automatic metrics and direct assessment by human evaluators in terms of Readability and Meaning Similarity to reference outputs. We present the evaluation results, along with descriptions of the SR'19 tracks, data and evaluation methods, as well as brief summaries of the participating systems. རྒྱབ་སྐྱོར་མ་ལག་གི་གསལ་བཤད་ཆེན་པ་ལ་འཇུག་སྣོད་འདིའི་ནང་གི་མ་ལག་གསལ་བཤད་པ་སྟོན་རོགས", 'sk': "Ta prispevek predstavlja rezultate tretje skupne naloge o večjezični realizaciji površin (SR'20), ki je bila organizirana v okviru delavnice COLING'20 o večjezični realizaciji površin. Kot v SR'18 in SR'19 je bila skupna naloga sestavljena iz dveh skladb: (1) plitve skladbe, kjer so bili vnosi polni strukturi UD, z odstranjenimi informacijami o vrstnem redu besed in žetoni lemmatizirani; in (2) Deep Track, kjer so bile dodatno odstranjene funkcionalne besede in morfološke informacije. Poleg tega je vsaka proga imela dva odštevka: (a) omejeni viri, kjer se lahko za modele usposabljanja uporabijo le podatki, ki so bili predloženi ali odobreni kot del proge, in (b) odprti viri, kjer se lahko uporabijo kakršni koli podatki. Plitva sled je bila na voljo v 11 jezikih, medtem ko Deep Track v 3 jezikih. Sistemi so ocenjevali z uporabo avtomatskih meritev in neposrednega ocenjevanja človeških ocenjevalcev glede berljivosti in podobnosti pomena referenčnim rezultatom. Predstavljamo rezultate vrednotenja, opise sledi SR'19, podatke in metode vrednotenja ter kratke povzetke sodelujočih sistemov. Za popolne opise sodelujočih sistemov si oglejte ločena poročila o sistemih drugje v tem zbirku.", 'he': 'העבודה הזו מציגה תוצאות מהמשימה השלישית המשותפת על המציאות של שטח רבותי (SR\'20), אשר הוארגנה כחלק מהWorkshop COLING\'20 על המציאות של שטח רבותי. כמו ב SR\'18 ו SR\'19, המשימה המשותפת כוללה שני מסלולים: (1) מסלול מסלול שבו הכניסות היו מבנים UD מלאים (2) מסלול עמוק שבו באופן נוסף, מילים פונקציונליות ומידע מורפולוגי הוסרו. חוץ מזה, לכל מסלול היו שני ניתוחים: a) משאב מוגבל, שבו רק הנתונים שנוספים או מאושרים כחלק מסלול יכולים להשתמש במודלים אימונים, ובb) משאב פתוח, שבו כל נתונים יכולים להשתמש. המסלול הציע ב-11 שפות, בעוד המסלול העמוק ב-3 שפות. מערכות הוערכו בשימוש של מטריקה אוטומטית ובעריכה ישירה על ידי מערכים אנושיים במונחים של קריאות ומשומעות דומה לתוצאות התייחסות. אנחנו מציגים את תוצאות הערכה, יחד עם תיאורים של עקבות SR\'19, נתונים ושיטות הערכה, כמו גם סדרות קצרות של מערכות המשתתפות. עבור תיאורים מלאים של המערכות המשתתפות, אנא ראה את הדו"חות המערכת הנפרדים במקום אחר במידה זו.'}
{'en': 'BME-TUW at SR’20 : Lexical grammar induction for surface realization', 'fr': "BME-TUW au SR'20\xa0: Induction grammaticale lexicale pour la réalisation de surfaces", 'ar': "BME-TUW at SR'20: تحريض نحوي معجمي لإدراك السطح", 'pt': "BME-TUW em SR'20: Indução gramatical lexical para realização de superfície", 'es': "BME-TUW en SR'20: Inducción gramatical léxica para la realización de superficies", 'zh': 'SR曰:20之BME-TUW,词汇语法归也', 'ja': "SR '20のBME - TUW ：表面実現のための語彙文法誘導", 'hi': "SR'20 पर BME-TUW: सतह प्राप्ति के लिए लेक्सिकल व्याकरण प्रेरण", 'ru': "BME-TUW в SR'20: Лексическая грамматическая индукция для реализации на поверхности", 'ga': "BME-TUW ag SR'20: Ionduchtú gramadaí foclóireachta le haghaidh réadú dromchla", 'ka': "BME-TUW SR'20: ლექსიკალური გრამიკალური ინდექცია", 'el': "Β.Μ.Ε. στο SR'20: Λεξική γραμματική επαγωγή για την υλοποίηση επιφάνειας", 'it': "BME-TUW a SR'20: induzione grammaticale lessicale per la realizzazione superficiale", 'lt': "BME-TUW at SR'20: Lexical grammar induction for surface realization", 'kk': "BME- TUW SR' 20: Жергілікті реализациялау үшін лексикалық грамматикалық индукция", 'ms': "BME-TUW di SR'20: Induksi grammar leksikal untuk penyelesaian permukaan", 'mt': "BME-TUW at SR'20: Lexical grammar induction for surface realization", 'hu': "BME-TUW SR'20: Lexikai nyelvtani indukció a felületi megvalósításhoz", 'mk': "BME-TUW во SR'20: Лексикална граматска индукција за реализирање на површината", 'no': "BME-TUW ved SR'20: Leksisk grammatisk induksjon for overflate", 'ml': "BME-TUW at SR'20: Lexical grammar induction for surface realization", 'pl': "BME-TUW na SR'20: Leksykalna indukcja gramatyki do realizacji powierzchni", 'ro': "BME-TUW la SR'20: Inducție gramaticală lexicală pentru realizarea suprafeței", 'sr': "BME-TUW na SR'20: Leksička gramatička indukcija za realizaciju površine", 'si': "BME-TUW SR'20: පුළුවන් අවස්ථානය සඳහා ලෙක්සිකාල් ග්\u200dරාමාර්ක්\u200dරියාව ප්\u200dරදේශනය", 'so': "BME-TUW at SR'20: Lexical grammar induction for surface realization", 'ur': "BME-TUW SR'20 میں: سطح معلومات کے لئے لکسیکل گراماری انڈاکشن", 'sv': "BME-TUW på SR'20: Lexisk grammatisk induktion för ytförverkligande", 'ta': "SR'20-ல் BME- TUW: surface உணர்தலுக்கான Lexical grammar induction", 'mn': "SR'20-д BME-TUW: гадаргуу ойлгохын тулд лексикийн грамматикийн үйлдвэрлэл", 'vi': "(BME-TUW) ở SR'20: kiến trúc văn học Y tế để thực hiện bề mặt", 'uz': "SR'20 bilan BME- TUW: Jarayon aniqlash uchun Leksika grammatika induksiyati", 'bg': "БМЕ-ТУУ в СР'20: Лексикална граматика за реализация на повърхността", 'nl': "BME-TUW op SR'20: Lexical grammatica induction voor oppervlakterealisatie", 'da': "BME-TUW ved SR'20: Lexisk grammatisk induktion til overfladebehandling", 'hr': "BME-TUW na SR'20: Leksička gramatička indukcija za realizaciju površine", 'id': "BME-TUW at SR'20: Lexical grammar induction for surface realization", 'ko': "SR'20의 BME-TUW: 표면적으로 이루어진 어휘 문법 귀납", 'fa': "BME-TUW در SR'20: اثبات گرامی لکسیکی برای realization سطح", 'de': "BME-TUW auf der SR'20: Lexikale Grammatikinduktion zur Oberflächenrealisierung", 'tr': "BME-TUW SR'20:", 'sw': "BME-TUW kwenye SR'20: Ujenezaji wa grafu za Lexico kwa ajili ya kutambua usoni", 'af': "BME-TUW by SR'20: Leksiese grammatiese induksie vir oorspronklike realisasie", 'am': 'BME-TUW', 'sq': "BME-TUW në SR'20: induksion gramatik leksikal për realizimin e sipërfaqes", 'bn': "SR'২০-এ বিমি-টুউউ: পৃথিবীর বুঝতে লেক্সিকাল গ্রামার শিল্প", 'bs': "BME-TUW na SR'20: Leksička gramatička indukcija za realizaciju površine", 'cs': "BME-TUW na SR'20: Lexická gramatická indukce pro realizaci povrchu", 'et': "BME-TUW SR'20: Lexikaalse grammatika induktsioon pinna realiseerimiseks", 'hy': "BME-TuW-ը ՍՌ'20-ում. Լեքսիկական գրամագրական ինդուկցիան մակերեսի իրականացման համար", 'ca': "BME-TUW a SR'20: Inducció gramàtica lèxica per a la concretització de la superfície", 'fi': "BME-TUW SR'20: Lexical grammatic induction for surface realisation", 'az': "SR'20'də BME-TUW: Yüzə realizasyonu üçün leksiqli gramatik indukciju", 'ha': 'QUnicodeControlCharacterMenu', 'jv': 'paper size', 'he': "BME-TUW ב SR'20: דליקת גרמטיקה לקסיקה להבינה על פני השטח", 'sk': "BME-TUW na SR'20: indukcija leksične slovnice za uresničitev površine", 'bo': "BME-TUW at SR'20: Lexical grammar induction for surface realization"}
{'en': 'We present a system for mapping Universal Dependency structures to raw text which learns to restore word order by training an Interpreted Regular Tree Grammar (IRTG) that establishes a mapping between string and graph operations. The reinflection step is handled by a standard sequence-to-sequence architecture with a biLSTM encoder and an LSTM decoder with ', 'ar': 'نقدم نظامًا لتعيين هياكل التبعية العالمية إلى النص الخام الذي يتعلم استعادة ترتيب الكلمات من خلال تدريب قواعد الشجرة المنتظمة المفسرة (IRTG) التي تنشئ تعيينًا بين عمليات السلسلة والرسم البياني. تتم معالجة خطوة إعادة الانعكاس من خلال بنية قياسية من التسلسل إلى التسلسل مع مشفر biLSTM وفك تشفير LSTM مع الانتباه. نقوم بتعديل نظام 2019 الخاص بنا (Koväcs et al. ، 2019) بآلية تحريض نحوي جديدة تسمح لقواعد IRTG بالعمل على lemmata بالإضافة إلى علامات جزء من الكلام وتضمن إعادة ترتيب كل كلمة وعائلاتها باستخدام الأكثر تحديدًا مجموعة من الأنماط المكتسبة. نقدم أيضًا نهجًا هرميًا لاستعادة ترتيب الكلمات والذي يحدد بشكل مستقل ترتيب الكلمات لكل جملة في جملة قبل ترتيبها فيما يتعلق بالفقرة الرئيسية ، وبالتالي تحسين قابلية القراءة الشاملة وأيضًا جعل مهمة تحليل IRTG قابلة للتتبع. شاركنا في مهمة 2020 Surface Realization Shared ، والمسار الفرعي T1a (ضحل ، مغلق). يُظهر التقييم البشري أننا نحقق تحسينات كبيرة في اثنتين من مجموعات البيانات الثلاثة خارج المجال مقارنةً بنظام 2019 الذي قمنا بتعديله. يتوفر كلا مكوني نظامنا على GitHub بموجب ترخيص MIT.', 'fr': "Nous présentons un système de mappage des structures de dépendance universelle au texte brut qui apprend à restaurer l'ordre des mots en entraînant une grammaire d'arbre régulière interprétée (IRTG) qui établit un mappage entre les opérations de chaîne et de graphe. L'étape de réinflexion est gérée par une architecture séquence-séquence standard avec un codeur BilsTM et un décodeur LSTM avec attention. Nous modifions notre système 2019 (Koväcs et al., 2019) avec un nouveau mécanisme d'induction grammaticale qui permet aux règles IRTG d'agir sur les lemmes en plus des balises de partie du discours et garantit que chaque mot et ses dépendants sont réordonnés en utilisant l'ensemble le plus spécifique de modèles appris. Nous introduisons également une approche hiérarchique de la restauration de l'ordre des mots qui détermine indépendamment l'ordre des mots de chaque clause dans une phrase avant de les organiser par rapport à la clause principale, améliorant ainsi la lisibilité globale et rendant également la tâche d'analyse IRTG réalisable. Nous avons participé à la tâche partagée de réalisation de surface 2020, sous-piste T1a (peu profonde, fermée). L'évaluation humaine montre que nous obtenons des améliorations significatives sur deux des trois ensembles de données hors domaine par rapport au système de 2019 que nous avons modifié. Les deux composants de notre système sont disponibles sur GitHub sous licence MIT.", 'pt': 'Apresentamos um sistema para mapeamento de estruturas de Dependência Universal para texto bruto que aprende a restaurar a ordem das palavras treinando uma Gramática de Árvore Regular Interpretada (IRTG) que estabelece um mapeamento entre operações de string e gráfico. A etapa de reinflexão é tratada por uma arquitetura padrão de sequência a sequência com um codificador biLSTM e um decodificador LSTM com atenção. Modificamos nosso sistema de 2019 (Koväcs et al., 2019) com um novo mecanismo de indução gramatical que permite que as regras do IRTG operem em lemas, além de tags de parte da fala e garante que cada palavra e seus dependentes sejam reordenados usando o mais específico conjunto de padrões aprendidos. Também introduzimos uma abordagem hierárquica para a restauração da ordem das palavras que determina independentemente a ordem das palavras de cada cláusula em uma frase antes de organizá-las em relação à cláusula principal, melhorando assim a legibilidade geral e também tornando a tarefa de análise do IRTG tratável. Participamos da tarefa 2020 Surface Realization Shared, subpista T1a (raso, fechado). A avaliação humana mostra que alcançamos melhorias significativas em dois dos três conjuntos de dados fora do domínio em comparação com o sistema de 2019 que modificamos. Ambos os componentes do nosso sistema estão disponíveis no GitHub sob uma licença do MIT.', 'es': 'Presentamos un sistema para mapear estructuras de dependencia universal al texto sin formato que aprende a restaurar el orden de las palabras mediante el entrenamiento de una gramática de árbol regular interpretada (IRTG) que establece un mapeo entre las operaciones de cadenas y gráficas. La etapa de reinflexión se maneja mediante una arquitectura de secuencia a secuencia estándar con un codificador BilsTM y un decodificador LSTM con atención. Modificamos nuestro sistema de 2019 (Koväcs et al., 2019) con un nuevo mecanismo de inducción gramatical que permite que las reglas del IRTG operen con lemas además de etiquetas de parte del discurso y garantiza que cada palabra y sus dependientes se reordenen utilizando el conjunto más específico de patrones aprendidos. También introducimos un enfoque jerárquico para la restauración del orden de las palabras que determina de forma independiente el orden de las palabras de cada cláusula de una oración antes de organizarlas con respecto a la cláusula principal, mejorando así la legibilidad general y haciendo que la tarea de análisis del IRTG sea manejable. Participamos en la tarea Compartida de Realización de Superficies 2020, subpista T1a (superficial, cerrada). La evaluación humana muestra que logramos mejoras significativas en dos de los tres conjuntos de datos fuera del dominio en comparación con el sistema de 2019 que modificamos. Ambos componentes de nuestro sistema están disponibles en GitHub bajo una licencia MIT.', 'ja': 'ユニバーサル依存構造を生テキストにマッピングするためのシステムを提示し、文字列とグラフ演算の間のマッピングを確立する解釈された正規ツリー文法（ IRTG ）をトレーニングすることで、単語の秩序を回復することを学びます。 再反射ステップは、BiLSTMエンコーダとLSTMデコーダを備えた標準的なシーケンスツーシーケンスアーキテクチャによって処理されます。 私たちは、2019年のシステム（ Koväcs et al., 2019 ）を新しい文法帰納メカニズムで修正し、IRTGルールが音声タグの一部に加えてlemmataで動作することを可能にし、各単語とその依存関係が最も具体的な学習パターンのセットを使用して並べ替えられるようにします。 また、主節に関して各節を配置する前に、文章内の各節の語順を独立して決定し、全体的な可読性を向上させ、IRTG構文解析タスクをトラッキング可能にする、語順復元への階層的アプローチを導入する。 2020 Surface Realization Sharedタスク、サブトラックT 1 a （浅い、閉じている）に参加しました。 ヒトの評価では、修正した2019年のシステムと比較して、3つのドメイン外データセットのうち2つで大幅な改善を達成しています。 当社システムの両方のコンポーネントは、MITライセンスの下でGitHubで利用できます。', 'zh': '建一将通用以结构原始文本之统,当训练解释性常树语法(IRTG)以学复单词序,当语法立映于字符串图形之间。 重度线步由格序至序架构,并 biLSTM 编码器、 LSTM 解码器。 用新语法归机改2019年系统(Koväcs等,2019),宜机制许IRTG则除词性标签外,仍可操作于lemmata,并保每单词及依赖项用最学模式集重行排序。 引入一法以复词序,当于主句之前,独立句之词序,以重其可读性,而使IRTG解析事易处也。 吾侪预2020年,子道T1a(浅)。 人工评明,比我2019年系统,我于三域外数集两上显进。 二组件皆得施于 MIT 许可证下 GitHub 上。', 'hi': 'हम कच्चे पाठ के लिए यूनिवर्सल निर्भरता संरचनाओं को मैप करने के लिए एक प्रणाली प्रस्तुत करते हैं जो एक व्याख्या की गई नियमित ट्री ग्रामर (आईआरटीजी) को प्रशिक्षित करके शब्द क्रम को बहाल करना सीखता है जो स्ट्रिंग और ग्राफ संचालन के बीच एक मैपिंग स्थापित करता है। reinflection चरण एक मानक अनुक्रम-से-अनुक्रम आर्किटेक्चर द्वारा एक biLSTM एन्कोडर और ध्यान के साथ एक LSTM विकोडक के साथ संभाला जाता है। हम अपने 2019 सिस्टम (Koväcs et al., 2019) को एक नए व्याकरण प्रेरण तंत्र के साथ संशोधित करते हैं जो IRTG नियमों को भाग-भाषण टैग के अलावा लेमाटा पर काम करने की अनुमति देता है और यह सुनिश्चित करता है कि प्रत्येक शब्द और उसके आश्रितों को सीखे गए पैटर्न के सबसे विशिष्ट सेट का उपयोग करके फिर से क्रमबद्ध किया जाए। हम शब्द क्रम बहाली के लिए एक पदानुक्रमित दृष्टिकोण भी पेश करते हैं जो स्वतंत्र रूप से मुख्य खंड के संबंध में उन्हें व्यवस्थित करने से पहले एक वाक्य में प्रत्येक खंड के शब्द क्रम को निर्धारित करता है, जिससे समग्र पठनीयता में सुधार होता है और आईआरटीजी पार्सिंग कार्य को भी असभ्य बनाता है। हमने 2020 सरफेस रिकॉलाइजेशन साझा कार्य, सबट्रैक टी 1 ए (उथले, बंद) में भाग लिया। मानव मूल्यांकन से पता चलता है कि हम 2019 प्रणाली की तुलना में तीन आउट-ऑफ-डोमेन डेटासेट में से दो पर महत्वपूर्ण सुधार प्राप्त करते हैं जिसे हमने संशोधित किया था। हमारे सिस्टम के दोनों घटक एक एमआईटी लाइसेंस के तहत GitHub पर उपलब्ध हैं।', 'ru': 'Мы представляем систему отображения структур универсальной зависимости в необработанный текст, которая учится восстанавливать порядок слов, обучая интерпретированную грамматику регулярного дерева (IRTG), которая устанавливает отображение между строковыми и графовыми операциями. Этап рефлексии обрабатывается стандартной последовательной архитектурой с кодером biLSTM и декодером LSTM с вниманием. Мы модифицируем нашу систему 2019 года (Koväcs et al., 2019) с помощью нового механизма индукции грамматики, который позволяет правилам IRTG работать на леммате в дополнение к тегам части речи и гарантирует, что каждое слово и его зависимые будут переупорядочены с использованием наиболее конкретного набора изученных шаблонов. Мы также вводим иерархический подход к восстановлению порядка слов, который независимо определяет порядок слов каждого пункта в предложении, прежде чем упорядочить их по отношению к основному пункту, тем самым улучшая общую читаемость, а также делая задачу синтаксического анализа IRTG тяжимой. Мы участвовали в задаче Surface Realization Shared 2020, субпуть T1a (мелкая, закрытая). Оценка человеческого фактора показывает, что мы добились значительных улучшений по двум из трех наборов внедоменных данных по сравнению с системой 2019 года, которую мы модифицировали. Оба компонента нашей системы доступны на GitHub по лицензии MIT.', 'ga': 'Cuirimid i láthair córas chun struchtúir Spleáchais Uilíoch a mhapáil chuig amhthéacs a fhoghlaimíonn conas ord focal a athbhunú trí oiliúint a chur ar Ghramadach Chrainn Rialta a Léirmhínithe (IRTG) a bhunaíonn léarscáiliú idir oibríochtaí teaghrán agus graif. Láimhseálann ailtireacht chaighdeánach seicheamh-go-seicheamh an chéim athmhínithe le ionchódóir biLSTM agus díchódóir LSTM ar a bhfuil aird. Déanaimid ár gcóras 2019 (Koväcs et al., 2019) a mhodhnú le meicníocht nua ionduchtaithe gramadaí a ligeann do rialacha IRTG oibriú ar leamaí i dteannta le clibeanna cuid cainte agus a chinntíonn go ndéantar gach focal agus a chleithiúnaithe a athordú ag baint úsáide as na cinn is sainiúla. sraith de phatrúin foghlamtha. Tugaimid isteach freisin cur chuige ordlathach maidir le hathchóiriú ord na bhfocal a chinneann go neamhspleách ord focal gach clásail in abairt sula n-eagrófar iad maidir leis an bpríomhchlásal, rud a fheabhsaíonn inléiteacht iomlán agus a fhágann go mbeidh tasc parsála IRTG inrianaithe. Ghlacamar páirt i dtasc Comhroinnte Réadú Dromchla 2020, fo-rian T1a (éadomhain, dúnta). Léiríonn meastóireacht dhaonna go bhfuil feabhsuithe suntasacha bainte amach againn ar dhá cheann de na trí thacar sonraí lasmuigh den fhearann i gcomparáid le córas 2019 a d’athraíomar. Tá an dá chomhpháirt dár gcóras ar fáil ar GitHub faoi cheadúnas MIT.', 'hu': 'Bemutatunk egy olyan rendszert, amely az univerzális függőségi struktúrák nyers szöveghez történő leképezésére szolgál, amely megtanulja visszaállítani a szó sorrendjét egy Interpreted Regular Tree Grammar (IRTG) képzésével, amely létrehozza a leképezést a karakterlánc és a gráf műveletek között. Az újrafeltükrözési lépést egy szabványos szekvencia-szekvencia architektúra kezeli biLSTM kódolóval és LSTM dekódolóval. 2019-es rendszerünket (Kovacs et al., 2019) egy új nyelvtani indukciós mechanizmussal módosítjuk, amely lehetővé teszi az IRTG szabályok számára, hogy a beszédrész címkék mellett lemmátán működjenek, és biztosítja, hogy minden szó és függője átrendeződjön a legspecifikusabb tanult minták használatával. Bevezetünk egy hierarchikus megközelítést a szósorrend helyreállítására is, amely függetlenül határozza meg az egyes mondatok szósorrendjét, mielőtt azokat a főzáradékhoz viszonyítja, ezáltal javítva az általános olvashatóságot és az IRTG elemzési feladatot is vonhatóvá teszi. Részt vettünk a 2020-as Felületmegvalósítási Megosztott feladatban, a T1a kivonásában (sekély, zárt). Az emberi értékelés azt mutatja, hogy a három domain kívüli adatkészlet közül kettőt jelentős javulást értünk el az általunk módosított 2019-es rendszerhez képest. Rendszerünk mindkét komponense elérhető a GitHub-on MIT licenc alatt.', 'ka': 'ჩვენ ჩვენ უნივერსოლური განსაკუთრებულობის სტრუქტურების მაპოვაციის სისტემის შესახებ, რომელიც ვისწავლის სიტყვების შესაძლებლობა, რომელიც ინტერპრექტირებული რეგრალური ხე გრამარი (IRTG) განა რეფლექციის კოდენტი სტანდარტული კოდენტიკოდენტიკოდენტიკოდენტიკოდენტიკოდენტი და LSTM დეკოდენტიკოდენტიკოდენტი დააყენება. ჩვენ 2019 წლის სისტემის შეცვლა (Kovacs et al., 2019) ახალი გრამატური ინდექციის მექანიზმით, რომელიც IRTG წესების შესაძლებლობა ლემეტაზე მუშაობას და დავხმარებთ, რომ ყოველ სიტყვი და მისი დასაწყვებელი განსხვავებული სიტყვის ჩვენ ასევე იერაქტიკური პროგრამა სიტყვების რესტორიაციის შესახებ, რომელიც განსაკუთრებით განსაკუთრებს ყველა კლასოზის სიტყვების პროგრამა, სანამ ყველა კლასოზის განსაკუთრებისთვის გადავადგინოთ, რადგან ყ ჩვენ 2020 წლის განმავლობა რეალიზაციის გაყოფილი საქმე, T1a წლის გარეშე. ადამიანის განსაზღვრება ჩვენ გავაკეთებთ მნიშვნელოვანი გაუკეთება დომინის სამი დანაშორებულ მონაცემების ორზე, რომელიც ჩვენ შევაკეთებული სისტემაზე შედგენა 201 ეგამარა კომპონენტები ჩვენი სისტემის შესაძლებელია GitHub-ზე, რომელიც MIT ლიცენსია.', 'lt': 'We present a system for mapping Universal Dependency structures to raw text which learns to restore word order by training an Interpreted Regular Tree Grammar (IRTG) that establishes a mapping between string and graph operations.  Reinfliacijos žingsnis tvarkomas standartine sekos po sekos architektūra su biLSTM kodatoriumi ir LSTM kodatoriumi. Pakeitime savo 2019 m. sistemą (Kovacs et al., 2019 m.), naudojant naują gramatikos indukcijos mechanizmą, kuris leidžia IRTG taisyklėms veikti citrinose, be kalbos dalinių žymenų, ir užtikrina, kad kiekvienas žodis ir jo priklausomi asmenys būtų perskirstyti naudojant konkrečiausius įgytus modelius. Taip pat įvedame hierarchinį požiūrį į žodžių tvarkos atkūrimą, kuris nepriklausomai nustato kiekvienos punkto žodžių tvarką sakinyje, prieš juos nustatydamas pagrindinio punkto atžvilgiu, taip pagerinant bendrą skaitomumą ir taip užtikrinant IRTG analizavimo užduotį. Dalyvavome 2020 m. paviršiaus įgyvendinimo bendroje užduotyje, atėmėme T1a (plokščią, uždarytą). Žmogaus vertinimas rodo, kad mes pasiekėme reikšmingus dviejų iš trijų ne srities duomenų rinkinių patobulinimus, palyginti su mūsų pakeista 2019 m. sistema. Abu mūsų sistemos komponentai yra prieinami GitHub licencijoje MIT.', 'el': 'Παρουσιάζουμε ένα σύστημα για την αντιστοίχιση δομών καθολικής εξάρτησης σε ακατέργαστο κείμενο το οποίο μαθαίνει να επαναφέρει τη σειρά λέξεων εκπαιδεύοντας μια ερμηνευμένη τακτική γραμματική δέντρου (που εγκαθιστά μια αντιστοίχιση μεταξύ των λειτουργιών συμβολοσειράς και γραφήματος. Το βήμα επανεμφάνισης χειρίζεται μια τυπική αρχιτεκτονική ακολουθίας-ακολουθίας με έναν κωδικοποιητή και έναν αποκωδικοποιητή LSTM με προσοχή. Τροποποιούμε το σύστημά μας 2019 (κ.α., 2019) με έναν νέο μηχανισμό επαγωγής γραμματικής που επιτρέπει στους κανόνες να λειτουργούν σε λεμώματα εκτός από τις ετικέτες τμήματος ομιλίας και εξασφαλίζει ότι κάθε λέξη και τα εξαρτώμενα της αναδιατάσσονται χρησιμοποιώντας το πιο συγκεκριμένο σύνολο μαθημένων προτύπων. Επίσης, εισάγουμε μια ιεραρχική προσέγγιση στην αποκατάσταση της σειράς λέξεων που καθορίζει ανεξάρτητα τη σειρά λέξεων κάθε ρήτρας σε μια πρόταση πριν την τακτοποιήσει σε σχέση με την κύρια ρήτρα, βελτιώνοντας έτσι τη συνολική αναγνωσιμότητα και καθιστώντας την εργασία ανάλυσης ανιχνεύσιμη. Συμμετείχαμε στην 2020 Κοινή Εργασία Υλοποίησης επιφάνειας, αφαίρεση Τ1α (ρηχή, κλειστή). Η ανθρώπινη αξιολόγηση δείχνει ότι επιτυγχάνουμε σημαντικές βελτιώσεις σε δύο από τα τρία σύνολα δεδομένων εκτός τομέα σε σύγκριση με το σύστημα 2019 που τροποποιήσαμε. Και τα δύο συστατικά του συστήματός μας είναι διαθέσιμα στο υπό άδεια ΜΙΤ.', 'it': "Presentiamo un sistema per la mappatura delle strutture di Dipendenza Universale al testo grezzo che impara a ripristinare l'ordine delle parole addestrando una grammatica ad albero regolare interpretata (IRTG) che stabilisce una mappatura tra le operazioni stringhe e grafici. La fase di rifunzione è gestita da un'architettura sequenza-sequenza standard con encoder biLSTM e decoder LSTM con attenzione. Modifichiamo il nostro sistema 2019 (Kovacs et al., 2019) con un nuovo meccanismo di induzione grammaticale che consente alle regole IRTG di operare sulla lemmata oltre ai tag part-of-speech e garantisce che ogni parola e i suoi dipendenti siano riordinati utilizzando l'insieme più specifico di modelli appresi. Introducemo anche un approccio gerarchico al ripristino dell'ordine delle parole che determina in modo indipendente l'ordine delle parole di ogni frase in una frase prima di organizzarle rispetto alla clausola principale, migliorando così la leggibilità complessiva e rendendo anche tracciabile l'attività di analisi IRTG. Abbiamo partecipato al compito condiviso di realizzazione superficiale 2020, sottrarre T1a (poco profondo, chiuso). La valutazione umana mostra che abbiamo ottenuto miglioramenti significativi su due dei tre set di dati fuori dominio rispetto al sistema 2019 che abbiamo modificato. Entrambi i componenti del nostro sistema sono disponibili su GitHub sotto licenza MIT.", 'mk': 'Презентираме систем за мапирање на универзалните структури на зависност на суров текст кој научи да го врати редот на зборовите со обука на Интерпретирана регуларна грама на дрво (IRTG) која поставува мапирање помеѓу редови и графички операции. Крајот на реинфлекција се справува со стандардна архитектура од секвенца до секвенца со biLSTM кодер и LSTM декодер со внимание. Ние го модификуваме нашиот систем 2019 (Kovacs и други, 2019) со новиот механизам за индукција на граматика кој им овозможува на ИРТГ правилата да функционираат на лимата, покрај дел од говорните ознаки и да се осигура дека секој збор и неговите зависни се реординирани со користење на најспецифичните научени шеми We also introduce a hierarchical approach to word order restoration that independently determines the word order of each clause in a sentence before arranging them with respect to the main clause, thereby improving overall readability and also making the IRTG parsing task tractable.  We participated in the 2020 Surface Realization Shared task, subtrack T1a (shallow, closed).  Човечката проценка покажува дека постигнуваме значителни подобрувања на двајца од трите надвор од доменот податоци во споредба со системот 2019 година кој го модификувавме. Двете компоненти од нашиот систем се достапни на Гит Хаб под МИТ лиценца.', 'kk': 'Біз әлемдегі тәуелсіздік құрылғыларды сызық мәтінде картаптау жүйесін таңдаймыз. Бұл сөздердің ретін қайталау үшін оқыту үшін, мәтіндегі мәтінде, мәтінді тізім мен график операцияларының арасындағы Қайталау қадамын biLSTM кодері мен LSTM декодері бойынша стандартты қадамдастыру архитектурасы менеджеріледі. Біз 2019 жылы жүйемізді (Kovacs et al., 2019) жаңа грамматикалық индукциялық механизммен өзгертіп, IRTG ережелерін сөйлеу тегтерінің бірнеше бөлігіне қосып, әрбір сөз мен оның тәуелдіктері білім үлгілерін қолдану үшін қайта реттеу ү Біз сондай-ақ әрбір сөздердің тізбегін негізгі клаузға қатынау алдында, әрбір сөздердің тізбегін қайталау ретіне иерархиялық тәртібін келтіреміз. Бұл сөздердің әрбір сөздердің тізбегін өзгерту үшін, оларды негізгі Біз 2020 жылы Жергілікті Реализацияның ортақтастырылған тапсырмасына қатысу үшін T1a көшірмесі (жабылған, жабылған). Адам оқиғасы 2019 жылы өзгертілген жүйесімізге салыстырылған үш домен деректер қорларының екі жақсартылығын көрсетеді. Жүйеміздің екі компоненттері MIT лицензиясы арқылы GitHub- та бар.', 'ml': 'വാക്കിന്റെ ഉത്തരവ് വീണ്ടെടുക്കാന്\u200d പഠിക്കുന്ന ഒരു സിസ്റ്റം മാപ്പ് ചെയ്യുന്നു. അത് സ്ട്രിങ്ങും ഗ്രാഫ് പ്രവര്\u200dത്തനങ്ങള്\u200dക്കും ഇടയില്\u200d ഒരു മാപ്പ്  പുന്നിയോഗിക്കുന്ന പടി ഒരു സാധാരണ സെക്കന്\u200dസെക്കന്\u200dസ് മുതല്\u200d സെക്കന്\u200dസ് സെക്കന്\u200dസ് സെക്കന്\u200dസ് ആര്\u200dക്ടിക്കറ്റര്\u200d കൈകാര്യം ചെയ്യുന്ന ഞങ്ങള്\u200d ഞങ്ങളുടെ 2019 സിസ്റ്റത്തെ മാറ്റുന്നു. കോവാക്സ് എറ്റ് അല്\u200d, 2019, ഒരു പുതിയ ഗ്രാമാര്\u200d ഇന്\u200dസ്റ്റാന്\u200dഷന്\u200d മെനിസ്റ്റമുണ്ട്. അത് ഇംഗി നിയമങ്ങള്\u200dക്ക് പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d അന പ്രധാന വാക്കുകളില്\u200d സ്വാതന്ത്ര്യമായി ഓരോ വാക്കിന്റെയും വാക്കുകളുടെയും ഉത്തരവാക്കുകളില്\u200d നിര്\u200dണ്ണയിക്കുന്നതിനു മുമ്പായി വാക്കുകളുടെയും വാക്കുകള്\u200d പുനര 2020 സര്\u200dഫെസ്റ്റ് റിയാജിഷന്\u200d പങ്കെടുത്ത ജോലിയില്\u200d ഞങ്ങള്\u200d പങ്കുചേര്\u200dന്നു. ടി1a (തണുത്ത, അടച്ചുപൂട്ടി). മനുഷ്യരുടെ വിലാസങ്ങള്\u200d കാണിക്കുന്നു. ഞങ്ങള്\u200d മാറ്റിയിട്ടുള്ള 2019 സിസ്റ്റത്തിനെതിരില്\u200d മൂന്ന് ഡേറ്റാറ്സെറ്റില്\u200d  നമ്മുടെ സിസ്റ്റത്തിന്റെ രണ്ടു ഭാഗങ്ങളും ജിറ്റ്ഹുബില്\u200d ലഭ്യമാണ് MIT ലൈസന്\u200dസിന്\u200dറെ അടിസ്ഥാനത്ത്.', 'mn': 'Бид универсал хамааралтай байдлын бүтцийг зураг зураг хийх системийг суралцаж өгүүлсэн үг дарааллыг эргүүлэхийг суралцаж, стринг болон график үйл ажиллагааны хоорондын зураг зураг зохион байгуулах боломжтой Интерпретийн Загварын грамматар (IR Дахин гүйцэтгэх алхам нь биLSTM коддогч болон LSTM коддогч, анхаарлаа хангалттай стандарт дарааллаар дарааллаар хангалттай архитектур юм. Бид 2019 оны системийг (Kovacs et al., 2019) шинэ грамматикийн үйлдвэрлэлийн механизмаар өөрчилж байна. Энэ нь IRTG дүрмийг хэсэг хэсэг хэлбэрийн тэмдэгүүд дээр уламт дээр ажиллах боломжтой болгодог бөгөөд үг бүр, хамааралтай нь хамгийн тодорхой сургалтын хэлбэрээр да Мөн бид үгийн дарааллын дахин дахин хэлбэрээр хэлбэрээр үгийн дарааллын дарааллын дарааллыг тодорхойлж өгдөг. Тэдгээрийг гол дарааллаар зохион байгуулахаас өмнө хэлбэрээр илүү унших боломжтой, Мөн IRTG ажлын дарааллын дарааллын дарааллыг хийх Бид 2020 оны гадаргуу реализацийн хуваалтын ажилд оролцсон. T1a-ын гадаргуу (гүн гүнзгий, хоцрогдсон). Хүн төрөлхтний оюутнууд бид 2019 оны өөрчлөгдсөн системтэй харьцуулсан гурван хүн төрөлхтний өгөгдлийн сангийн хоёр дахь чухал сайжруулалт гаргадаг. Бидний системийн хоёр компонент нь MIT лицензийн доор GitHub дээр ашиглаж байна.', 'pl': 'Przedstawiamy system mapowania struktur uniwersalnej zależności do tekstu surowego, który uczy się przywracać kolejność słów poprzez trening Interpreted Regular Tree Grammar (IRTG), który ustanawia mapowanie między operacjami ciągu i wykresu. Krok reinflekcji jest obsługiwany przez standardową architekturę sekwencji-sekwencji z koderem biLSTM i dekoderem LSTM z uwagą. Modyfikujemy nasz system 2019 (Kovacs et al., 2019) o nowy mechanizm indukcji gramatycznej, który umożliwia działanie reguł IRTG na lemmatach oprócz tagów części mowy i zapewnia, że każde słowo i jego zależne są zmieniane przy użyciu najbardziej konkretnego zestawu nauczonych wzorców. Wprowadzamy również hierarchiczne podejście do przywracania kolejności słów, które niezależnie określa kolejność słów każdej klauzuli w zdaniu przed ułożeniem ich w odniesieniu do klauzuli głównej, poprawiając tym samym ogólną czytelność, a także sprawiając, że zadanie parsowania IRTG jest ściągalne. Uczestniczyliśmy w zadaniu 2020 Realizacja Powierzchni Wspólnym, odejmowaniu T1a (płytkie, zamknięte). Ocena ludzka pokazuje, że osiągamy znaczące ulepszenia dwóch z trzech zbiorów danych poza domeną w porównaniu z modyfikowanym przez nas systemem 2019. Oba komponenty naszego systemu są dostępne na GitHub na licencji MIT.', 'ro': 'Vă prezentăm un sistem de cartografiere a structurilor de dependență universală la text brut care învață să restabilească ordinea cuvintelor prin instruirea unei Grammatici Interpretate Regular Tree (IRTG) care stabilește o cartografiere între operațiunile de șir și grafic. Pasul de reinflecție este gestionat de o arhitectură standard secvență-secvență cu un encoder biLSTM și un decoder LSTM cu atenție. Modificăm sistemul nostru 2019 (Kovacs et al., 2019) cu un nou mecanism de inducție gramaticală care permite regulilor IRTG să funcționeze pe lemmata în plus față de etichetele parțiale de vorbire și asigură că fiecare cuvânt și persoanele dependente sunt reordonate folosind cel mai specific set de modele învățate. Introducem, de asemenea, o abordare ierarhică a restaurării ordinii de cuvinte care determină independent ordinea de cuvinte a fiecărei clauze dintr-o propoziție înainte de a le aranja în raport cu clauza principală, îmbunătățind astfel lizibilitatea generală și, de asemenea, făcând sarcina de analizare IRTG trasabilă. Am participat la sarcina partajată de realizare a suprafeței 2020, subtract T1a (superficial, închis). Evaluarea umană arată că obținem îmbunătățiri semnificative la două dintre cele trei seturi de date din afara domeniului comparativ cu sistemul din 2019 pe care l-am modificat. Ambele componente ale sistemului nostru sunt disponibile pe GitHub sub o licență MIT.', 'no': 'Vi presenterer eit system for mapping av universelle avhengighetsstrukturer til råtekst som lærer å gjenoppretta ordrekkefølgje ved opplæring av eit regulært tregrammar (IRTG) som opprettar ei mapping mellom streng og grafenoperasjonar. Reinfleksjonsstegnet vert handsama av ein standard arkitektur med ein biLSTM-kodar og ein LSTM-dekoder med oppmerksomhet. Vi endrar vår 2019-system et (Kovacs et al., 2019) med ein ny grammatisk induksjonsmekanismen som tillater IRTG-reglar å fungere på lemmatikk i tillegg til delvis taletaggar og sikre at kvar ord og avhengigheten vert rekordert med dei mest spesifikke settet av lærte mønsteret. Vi introduserer også ein hierarkisk tilnærming til ordordrekkefølgje som avhengig bestemmer ordrekkefølgja for kvar klausul i eit setning før du ordna dei med respekt til hovudklausulen, dermed å forbetra overalt lesabilitet og også gjera IRTG-tillesingssportabellen. Vi delta i den delte oppgåva for overflaten Realization 2020, subtrakt T1a (sållog, lukka). Menneske evalueringa viser at vi har nådd signifikante forbedringar på to av dei tre datasetta som ikkje er domenet sammenlignet med systemet 2019 vi endra. Begge komponentar av systemet vårt er tilgjengelege på GitHub under ein MIT- lisens.', 'sr': 'Predstavljamo sistem za mapiranje univerzalne nezavisnosti strukture na sirov tekst koji nauči da obnovi red riječi obučavajući preglednu regularnu grammaru drveta (IRTG) koja utvrđuje mapiranje između funkcija žica i grafika. Korak reinflekcije se obrađuje standardna arhitektura sekvence do sekvence sa koderom biLSTM i LSTM dekoderom sa pažnjom. Mi izmijenimo naš sistem 2019. godine (Kovacs et al., 2019) sa novim gramatičkim indukcijskim mehanizam koji omogućava da IRTG pravila funkcioniše na lematici u dodatnom delu govornih etiketa i osiguravaju da se svaka reč i njegovi ovisnici ponovno urede koristeći najspecifičniju skupu naučenih obrazaca. Takođe predstavljamo hijerarhički pristup restauraciji rečenica koja neovisno određuje rečenicu svake klauzule u rečenici pre nego što ih sredimo u pogledu glavne klauzule, tako poboljšavajući ukupnu čitljivost i također činiti praćenje zadataka IRTG-a. Mi smo sudjelovali u zajedničkom zadatku realizacije površine 2020. godine, subtrakt T1a (plitko, zatvoren). Ljudska procjena pokazuje da postignemo značajno poboljšanje na dva od tri podataka iz domena u usporedbi sa sistemom 2019 koji smo modificirali. Obje komponente našeg sistema su dostupne na GitHubu pod MIT dozvolu.', 'si': 'අපි සාමාන්\u200dය විශේෂ විශේෂතාව ස්ථාපනය කරන්න පද්ධතියක් පෙන්වන්න පුළුවන් පද්ධතියක් පෙන්වන්න පුළුවන් පද්ධතියක් පෙන්වන්න. ඒක පු ආපහු ප්\u200dරවේශනය පැත්තක් ප්\u200dරමාණික පද්ධතියෙන් ප්\u200dරමාණික පද්ධතියෙන් බිල්ස්ටිම් සංකේතකය සහ LSTM සංකේතකයෙන් අ අපි 2019 පද්ධතිය (KOvacs et al., 2019) වෙනස් කරනවා අළුත් ගර්මාර් සංවේදනය සඳහා IRTG නීතිය ලම්මාතාවට පරීක්ෂණය කරන්න පුළුවන් වෙන්නේ කොටස් කිරීමේ ටැග් සඳහා සඳහා පරී අපි වචන පණිවිධානයක් වචන පණිවිධානය කරනවා කියලා වචන පණිවිධානය කරනවා වචන පණිවිධාන පණිවිධානය සඳහා ඔවුන්ව ප්\u200dරධාන පණිවිධානය සඳහා සාම අපි 2020යි ප්\u200dරතිමූණ ප්\u200dරතිමූණ ක්\u200dරියාත්මක වැදගත් වැඩේ සම්ප්\u200dරේක්ට් T1a (අඩුවෙන්, වහලා). මිනිස්සු විශ්ලේෂණය පෙන්වනවා අපි 2019 පද්ධති වෙනස් කරපු පද්ධතියෙන් ප්\u200dරමාණය කරපු දත්ත තුරු දෙකක් ගැන වැඩ අපේ පද්ධතියේ අංකය දෙන්නම තියෙන්නේ MIT ලායිසන්ස් එකේ GitHub වලින්.', 'sv': 'Vi presenterar ett system för att kartlägga Universal Dependency strukturer till råtext som lär sig att återställa ordordningen genom att träna en Tolked Regular Tree Grammar (IRTG) som etablerar en kartläggning mellan sträng och grafoperationer. Återflektionssteget hanteras av en standard sekvens-till-sekvensarkitektur med en biLSTM-kodare och en LSTM-avkodare med uppmärksamhet. Vi modifierar vårt system 2019 (Kovacs et al., 2019) med en ny grammatisk induktionsmekanism som gör det möjligt för IRTG-regler att arbeta på lemmata förutom delar av tal taggar och ser till att varje ord och dess beroende ordnas om med hjälp av de mest specifika uppsättningen av lärda mönster. Vi introducerar också ett hierarkiskt tillvägagångssätt för ordordning restaurering som självständigt bestämmer ordordningen för varje sats i en mening innan de ordnar dem med avseende på huvudsatsen, vilket förbättrar den övergripande läsbarheten och gör IRTG-tolkningsaktiviteten spårbar. Vi deltog i 2020 Surface Realization Shared uppgift, subtract T1a (grunt, stängt). Mänsklig utvärdering visar att vi uppnår betydande förbättringar på två av de tre datauppsättningarna utanför domänen jämfört med 2019 års system vi modifierade. Båda komponenterna i vårt system är tillgängliga på GitHub under en MIT-licens.', 'ta': 'நாம் பொதுவான சார்ந்த அமைப்புகளை வரைபடத்திற்கான அமைப்புகளை குறைக்கவும், உரையை மீட்டெடுக்கவும் கற்றுக் கொள்ள முடியும். ஒரு மொழிபெயர்ப்பு வழக்கமா The reinflection step is handled by a standard sequence-to-sequence architecture with a biLSTM encoder and an LSTM decoder with attention.  நாங்கள் எங்கள் 2019 அமைப்பை (Kovacs et al., 2019) மாற்றுகிறோம் ஒரு புதிய குறிப்பிட்ட பேச்சு குறிப்பிட்ட உருவங்களை பயன்படுத்தி IRTG விதிகளை லிம்மாட்டை செயல்படுத்த அனுமதிக்கிறது மற்று நாம் வார்த்தை மீட்டெடுப்பதற்கு ஒரு முன்னிருப்பு முறையான சொல்லை மீட்டெடுப்பு செயலை முன்னால் தீர்மானிக்கும் ஒவ்வொரு குறிப்பின் வரிசையை வாக்கியத் 2020 மேற்கோள்களில் நாங்கள் பங்கிடப்பட்ட பணி நாங்கள் மாற்றியது 2019 முறைமையை ஒப்பிட்ட மூன்று தரவுத்தளங்களில் இரண்டில் முக்கியமான முன்னேற்றங்களை நாம் பெறுகிற எங்கள் கணினியின் இரு பகுதிகளும் MIT அனுமதிக்கு கீழ் GitHub கிடைக்கும்.', 'so': 'Waxaan diyaarinaynaa nidaam u sawira dhismaha ku xirnaanta caalamiga ah si a an u sawiro qoraalka lagu barto ku cusboonaysiinta nidaamka hadalka ee lagu barto qoraal-ku-tababarida Tree Regular Grammar (IRTG) oo sawiraad u dhexeeya sawir iyo waxqabadka graph. Qoraalka dib u soo celinta waxaa lagu maamulaa dhismaha saxda ah ee standard-to-sequence, kaas oo leh biLSTM encoder iyo LSTM coder aad u taxadaraysaa. Waxaynu beddelinaynaa nidaamka 2019 (Kovacs et al., 2019) iyadoo leh mekani cusub oo lagu sameeyo maamulka IRTG in uu ku shaqeeyo lemmata ka sokow alaabta hadalka, waxaynu hubsanaynaa in eray walba iyo qofka ku xiran lagu amro isticmaalka noocyada ugu wacan waxbarashada. We also introduce a hierarchical approach to word order restoration that independently determines the word order of each clause in a sentence before arranging them with respect to the main clause, thereby improving overall readability and also making the IRTG parsing task tractable.  Waxaannu ka qayb galnay 2020 Surface Realization Shared task, subtract T1a (shallow, closed). Qiimeynta biniaadamka waxaa muuqanaya horumarin aad u weyn labada kooban oo ka mid ah saddexda macluumaadka ee domain-ka-baxsan, barbarka ah nidaamka 2019 ee aan beddelinay. Labada qeybood oo nidaamka ah waxaa lagu heli karaa GitHub sharciga MIT.', 'ms': 'Kami perkenalkan sistem untuk memetakan struktur Dependensi Universal ke teks mentah yang belajar untuk memulihkan perintah perkataan dengan melatih Grammar Pohon Regular Terinterpretasi (IRTG) yang menetapkan pemetaan antara operasi rentetan dan graf. Langkah refleksi dikendalikan oleh arkitektur rangkaian-ke-rangkaian piawai dengan pengekod biLSTM dan pengekod LSTM dengan perhatian. Kami mengubahsuai sistem 2019 kami (Kovacs et al., 2019) dengan mekanisme induksi grammar baru yang membolehkan peraturan IRTG untuk beroperasi pada lemma tambahan kepada sebahagian-tag-ucapan dan memastikan bahawa setiap perkataan dan dependennya diubahsuai menggunakan set yang paling spesifik corak belajar. Kami juga memperkenalkan pendekatan hierarkis untuk pemulihan perintah perkataan yang secara independen menentukan perintah perkataan setiap klausul dalam kalimat sebelum mengatur mereka terhadap klausul utama, dengan demikian meningkatkan pembacaan keseluruhan dan juga membuat tugas hurai IRTG boleh ditarik. Kami berpartisipasi dalam tugas Perwujudan Surface 2020 Berkongsi, tolak T1a (rendah, ditutup). Evaluasi manusia menunjukkan kita mencapai peningkatan yang signifikan pada dua dari tiga set data luar domain dibandingkan dengan sistem 2019 yang kita ubahsuaikan. Kedua-dua komponen sistem kita tersedia di GitHub di bawah lesen MIT.', 'ur': 'ہم ایک سیسٹم کی مکاپیٹ کرنے کے لئے یونلورٹ ڈیپنڈنسیٹ ساختروں کو روئیں ٹیکسٹ کے لئے پیش کریں جو کلمات کے اوقات کو دوبارہ پلٹانے کی تعلیم کے ذریعہ سکھاتا ہے کہ ایک قانونی تری گرم (IRTG) جو استرینگ اور گراف عملیات کے درمیان دوبارہ تغییر پڑھنے کی سطح ایک استاندارڈ سٹرنڈ-تا-سٹرنڈ آرکیٹ کے ذریعہ ایک بیLSTM اکوڈر اور ایک LSTM ڈیکوڈر کے ذریعہ منظور ہوتی ہے. ہم نے 2019 کی سیستم (Kovacs et al., 2019) کو ایک نئی گرامماری انڈاکس مکانیسم کے ساتھ بدل دیا ہے جو IRTG قوانین کو ایک قسمت کی بات ٹاگ کے ساتھ چلنے کی اجازت دیتا ہے اور اس کا مضبوط ہے کہ ہر کلم اور اس کے اعتباروں کو سب سے زیادہ مشخص طریقوں کے مطابق دوبارہ سمجھا جائے۔ ہم نے کلمات کے ذریعے ایک حکومت طریقے کو بھی پیش کیا ہے جو ہر کلمات کے کلمات کے ذریعے ایک کلمات کے ذریعہ سے پہلے ان کو اصلی کلمات کے معاملہ میں ترکیب کرنے سے پہلے ایک کلمات کے کلمات کے ذریعہ مطابق مقرر کرتا ہے، اس کے ذریعہ سے سب کی پڑھنے کی طاقت اور IRTG کو ترکیب ہم نے ۲۰۰۲ سارے سطح ریلیزانیز شریک کام میں شریک ہوا، ٹی 1ا (گلے، بند ہوا)۔ انسان کا ارزیابی دکھاتا ہے کہ ہم نے 2019 سیستم کے مقابلہ میں بدل دیا تھا کہ ہم نے تین ڈومین کے خارج سے دوسرے سے بہترین سوداگری حاصل کی۔ ہمارے سیسٹم کی دو قسمتیں ایک MIT لائیس کے نیچے GitHub پر موجود ہیں.', 'mt': 'Aħna nippreżentaw sistema għall-immappjar tal-istrutturi tad-Dipendenza Universali għat-test mhux ipproċessat li jitgħallem jirritorna l-ordni tal-kliem permezz tat-taħriġ ta’ Grammar Regolatorju tas-Siġar Interpretat (IRTG) li jistabbilixxi mmappjar bejn operazzjonijiet ta’ strings u grafiċi. The reinflection step is handled by a standard sequence-to-sequence architecture with a biLSTM encoder and an LSTM decoder with attention.  Aħna nimmodifikaw is-sistema tagħna tal-2019 (Kovacs et al., 2019) b’mekkaniżmu ġdid ta’ induzzjoni grammarja li jippermetti li r-regoli tal-IRTG joperaw fuq il-limma flimkien ma’ tikketti ta’ parti mid-diskors u jiżguraw li kull kelma u d-dipendenti tagħha jiġu ordnati mill-ġdid bl-użu tal-aktar sett speċifiku ta’ mudelli miksuba. Inintroduċu wkoll approċċ ġerarkiku għar-restawr tal-ordni tal-kelma li jiddetermina b’mod indipendenti l-ordni tal-kelma ta’ kull klawżola f’sentenza qabel ma jorganizzawhom fir-rigward tal-klawżola ewlenija, u b’hekk itejjeb il-leġibbiltà ġenerali u jagħmel il-kompitu tal-analiżi tal-IRTG attrabbli wkoll. Parteċipajna fil-kompitu Kondiviż tar-Realizzazzjoni tas-Suq tal-2020, nieqes it-T1a (baxx, magħluq). L-evalwazzjoni tal-bniedem turi li nkisbu titjib sinifikanti fuq tnejn mit-tliet settijiet tad-dejta barra d-dominju meta mqabbla mas-sistema tal-2019 li mmodifikaw. Iż-żewġ komponenti tas-sistema tagħna huma disponibbli fuq GitHub taħt liċenzja MIT.', 'uz': "Biz bir tizimni koʻchirish uchun tugmalar tartibi yaratish mumkin. Bu soʻzni qayta taklif qilish mumkin. Name @ info: whatsthis We modify our 2019 system (Kovacs et al., 2019) with a new grammar induction mechanism that allows IRTG rules to operate on lemmata in addition to part-of-speech tags and ensures that each word and its dependents are reordered using the most specific set of learned patterns.  Biz bu so'zni o'zgartirish orqali o'zgartirish imkoniyatini o'rganamiz. Bu so'zlarni asosiy soʻzni boshqarishdan avval bir so'zlarning soʻzni o'zgartirish imkoniyatini o'zgartirish mumkin. Bu yerda umumiy oʻqishni oshirish va IRTG parsing vazifani taʼminlovchiga bajarishi mumkin. Biz 2020 tashkilotni tashkilotga ega bo'lgan vazifani, T1a (yopish, yopilgan). Inson qiymatlari esa biz 2019 tizimga o'zgartirilgan uchta domen maʼlumotlar tarkibidagi uchta ta ta'lim rivojlanishimizni ko'rsatadi. Bizning ikki komponenti MIT litsenziyasi bilan GitHub'da imkoniyatlar mumkin.", 'vi': 'Chúng tôi giới thiệu một hệ thống để vẽ bản đồ các cấu trúc nắm giữ sự phụ thuộc to àn cầu thành văn bản nguyên bản mà học để phục hồi trật tự bằng cách đào tạo một Grammar (IRTG) cấu hình thành một bản đồ giữa các thao tác dòng và đồ thị. Các bước xây dựng được điều khiển bởi một cấu trúc dãy-tới-dãy tiêu chuẩn có bộ mã hóa bialTM và một bộ giải mã LSTM kèm theo sự chú ý. Chúng tôi sửa đổi hệ thống thẩm tê (Kovacs et al., 99) với một cơ chế cảm ứng từ ngữ pháp mới cho phép các quy tắc IRTG hoạt động trên lemmata, thêm các thẻ phần ngôn ngữ, và đảm bảo rằng mỗi từ và những người thân thuộc của nó được sắp đặt lại bằng các mẫu được học hỏi đặc biệt nhất. Chúng tôi cũng thiết lập lại hệ thống phân cấp các chức vụ phục hồi trật tự từ mà quyết định trật tự của mỗi điều khoản trong một câu, trước khi xử lý các điều khoản về điều khoản chính, để nâng mức độ dễ đọc tổng quát và cũng làm cho bộ phân tích các nhiệm vụ của IRTG. Chúng tôi tham gia vụ thực hiện mặt đất 2020 Phân chia nhiệm vụ, trừ T1a (cạn, đóng). Kết quả đánh giá con người cho thấy ta đạt được những cải tiến đáng kể về hai trong ba bộ dữ liệu ngoài lĩnh vực so với hệ thống tê-99 mà ta đã thay đổi. Cả hai thành phần của hệ thống đều có mặt ở GitHub dưới giấy phép MIT.', 'bg': 'Представяме система за картографиране на структурите на универсална зависимост към суров текст, която се научава да възстановява реда на думите чрез обучение на интерпретирана регулярна дървесна граматика (IRTG), която установява картографиране между низови и графични операции. Стъпката за рефлекция се обработва от стандартна архитектура последователност към последователност с кодер и декодер с внимание. Ние модифицираме нашата система за 2019 г. (Ковац и др., 2019 г.) с нов граматически индукционен механизъм, който позволява правилата да работят върху лемата в допълнение към таговете за част от речта и гарантира, че всяка дума и нейните зависими са пренаредени, използвайки най-специфичния набор от научени модели. Също така въвеждаме йерархичен подход към възстановяването на реда на думите, който независимо определя реда на думите на всяка клауза в изречение, преди да ги подреди по отношение на основната клауза, като по този начин подобрява общата четливост и прави задачата за анализ проследима. Участвахме в задачата "Споделена реализация на повърхността 2020", изваждане на Т1а (плитко, затворено). Оценката на хората показва, че постигаме значителни подобрения в два от трите набора от данни извън домейна в сравнение със системата от 2019 г., която модифицирахме. И двата компонента на нашата система са достъпни в ГитХъб под лиценз на МИТ.', 'nl': 'We presenteren een systeem voor het toewijzen van universele afhankelijkheidsstructuren aan ruwe tekst dat leert om de woordvolgorde te herstellen door een Interpreted Regular Tree Grammar (IRTG) te trainen die een toewijzing tussen string- en grafiekbewerkingen tot stand brengt. De herflectie stap wordt afgehandeld door een standaard sequence-to-sequence architectuur met een biLSTM encoder en een LSTM decoder met aandacht. We modificeren ons 2019-systeem (Kovacs et al., 2019) met een nieuw grammatica-inductiemechanisme dat IRTG-regels toestaat om te werken op lemmata naast part-of-speech tags en ervoor zorgt dat elk woord en zijn afhankelijke personen opnieuw worden geordend met behulp van de meest specifieke set geleerd patronen. We introduceren ook een hiërarchische benadering van het herstellen van woordvolgorde die onafhankelijk de woordvolgorde van elke zin in een zin bepaalt alvorens deze te rangschikken met betrekking tot de hoofdzin, waardoor de algehele leesbaarheid wordt verbeterd en ook de IRTG parsing taak traceerbaar wordt gemaakt. We namen deel aan de 2020 Surface Realization Shared taak, subtrack T1a (ondiep, gesloten). Menselijke evaluatie toont aan dat we significante verbeteringen bereiken op twee van de drie out-of-domain datasets in vergelijking met het 2019-systeem dat we hebben aangepast. Beide componenten van ons systeem zijn beschikbaar op GitHub onder een MIT licentie.', 'hr': 'Predstavljamo sistem za mapiranje struktura univerzalne zavisnosti na sirov tekst koji uči da obnovi red riječi obučavajući protumačeni regularni grammar drveta (IRTG) koji utvrđuje mapiranje između operacija žica i grafa. Korak reinflekcije se rješava standardnim arhitekturom sekvence do sekvence s koderom biLSTM i LSTM dekoderom s pažnjom. Mi izmijenimo naš sistem 2019. godine (Kovacs et al., 2019) s novim gramatičkim indukcijskim mehanizam koji omogućava da se IRTG pravila djeluju na lematici u dodatnom dijelom govornih znakova i osigurava da se svaka riječ i njegova zavisnost ponovno urede koristeći najspecifičniji skup učenih obrazaca. Također predstavljamo hijerarhički pristup restauraciji reda riječi koji neovisno određuje redak riječi svake klauzule u rečenici prije nego što ih sredimo u pogledu glavne klauzule, tako poboljšavajući ukupnu čitljivost i učiniti praćenje zadataka IRTG-a. Učelili smo u zajedničkom zadatku realizacije površine 2020. godine, subtrakt T1a (plitko, zatvoren). Ljudska procjena pokazuje da postignemo značajno poboljšanje na dvije od tri podataka izvan domena u usporedbi s sustavom 2019 koji smo modificirali. Obje komponente našeg sustava su dostupne na GitHub pod MIT dozvolu.', 'de': 'Wir stellen ein System zur Zuordnung universeller Abhängigkeitsstrukturen auf Rohtext vor, das lernt, die Wortreihenfolge wiederherzustellen, indem eine Interpreted Regular Tree Grammar (IRTG) trainiert wird, die eine Zuordnung zwischen String- und Graphenoperationen herstellt. Der Reinflektionsschritt wird von einer Standard Sequenz-zu-Sequenz Architektur mit einem biLSTM Encoder und einem LSTM Decoder mit Aufmerksamkeit abgewickelt. Wir modifizieren unser 2019-System (Kovacs et al., 2019) mit einem neuen Grammatik-Induktionsmechanismus, der es ermöglicht, IRTG-Regeln auf Lemmata zusätzlich zu Teilen-der-Sprache-Tags zu arbeiten und sicherstellt, dass jedes Wort und seine Abhängigkeiten mit den spezifischsten erlernten Mustern neu geordnet werden. Wir führen auch einen hierarchischen Ansatz zur Wiederherstellung der Wortreihenfolge ein, der unabhängig die Wortreihenfolge jedes Satzes in einem Satz bestimmt, bevor er sie in Bezug auf den Hauptsatz anordnet, wodurch die allgemeine Lesbarkeit verbessert und auch die IRTG Parsing Task nachvollziehbar gemacht wird. Wir haben an der 2020 Surface Realization Shared Task teilgenommen, subtrack T1a (flach, geschlossen). Human Evaluation zeigt, dass wir signifikante Verbesserungen bei zwei der drei Out-of-Domain-Datensätze im Vergleich zum 2019-System erzielen, das wir modifiziert haben. Beide Komponenten unseres Systems sind auf GitHub unter einer MIT-Lizenz verfügbar.', 'ko': '문자열과 그래픽 작업 사이에 매핑된 해석 규칙 트리 구문(IRTG)을 만드는 훈련을 통해 복구 어순을 학습하는 일반 종속 구조를 원본 텍스트에 매핑하는 시스템을 제안했습니다.재반사 절차는 표준 시퀀스에서 시퀀스 구조로 처리되며, biLSTM 인코더와 LSTM 디코더가 있습니다.새로운 구문 귀납 메커니즘으로 IRTG 규칙이 단어 표기 외에 인용을 조작할 수 있도록 하고 가장 구체적인 학습 모델을 사용하여 단어와 종속어를 순서재정리할 수 있도록 하는 2019 시스템(Kovacs et al., 2019)을 수정했습니다.문장의 각 자구를 주자구에 비해 배열하기 전에 독자적으로 어순을 확정하여 전체적인 가독성을 높이고 IRTG 분석 임무를 처리하기 쉽도록 하는 층별 방법도 도입했다.우리는 2020년 지상 공유 임무, 하위 궤도 T1a(얕은층, 폐쇄)에 참여했다.인류 평가에 따르면 우리가 수정한 2019 시스템에 비해 우리는 세 개의 역외 데이터가 집중된 두 가지 측면에서 현저한 개선을 얻었다.우리 시스템의 두 구성 요소는 모두 GitHub에서 MIT 라이센스를 받을 수 있습니다.', 'sw': 'Tunaweza kuweka mfumo wa ramani ya muundo wa kutegemea Uhuru ulimwenguni kote ili kuvunja ujumbe ambao unajifunza kurejesha amri ya maneno kwa kufundisha mti wa mara kwa mara (IRTG) unaoanzisha ramani kati ya mfumo na operesheni za ramani. Hatua ya upya ya utafiti inakabiliwa na ujenzi wa kiwango cha kiwango cha mfululizo wa mfululizo wa mfululizo wa mfululizo wa mfululizo wa mfululizo wa mfululizo wa mfululizo wa mfululizo wa mfululizo na mfumo wa LSTM kwa makini. Tunaweza kubadilisha mfumo wetu wa mwaka 2019 (Kovacs et al., 2019) na mfumo mpya wa viwanda vya grammani ambao unaruhusu sheria za IRTG kufanya kazi kwa ajili ya lemmata pamoja na sehemu ya viungo vya hotuba na kuhakikisha kwamba kila neno na wategemewa wake huamrishwa upya kwa kutumia seti maalum za kujifunza. We also introduce a hierarchical approach to word order restoration that independently determines the word order of each clause in a sentence before arranging them with respect to the main clause, thereby improving overall readability and also making the IRTG parsing task tractable.  Tumeshiriki katika jukumu la Kusambaza Sura 2020, lililoshiriki T1a (kivumbi, kilifungwa). Utafiti wa binadamu unaonyesha kwamba tunapata maendeleo makubwa juu ya seti mbili za takwimu hizi mbili za nje ya ndani ukilinganishwa na mfumo wa 2019 ambao tulibadilisha. Sehemu mbili za mfumo wetu zinapatikana kwenye GitHub chini ya leseni ya MIT.', 'id': 'We present a system for mapping Universal Dependency structures to raw text which learns to restore word order by training an Interpreted Regular Tree Grammar (IRTG) that establishes a mapping between string and graph operations.  Langkah refleksi ditangani oleh arsitektur rangkaian-ke-rangkaian standar dengan pengekode biLSTM dan pengekode LSTM dengan perhatian. Kami mengubah sistem 2019 kami (Kovacs et al., 2019) dengan mekanisme induksi gramatika baru yang memungkinkan aturan IRTG untuk beroperasi pada lemma tambahan pada bagian dari tags pidato dan memastikan bahwa setiap kata dan dependensinya diubah dengan menggunakan set yang paling spesifik pola belajar. Kami juga memperkenalkan pendekatan hierarkis untuk pemulihan perintah kata yang secara independen menentukan perintah kata setiap klausul dalam kalimat sebelum mengatur mereka terhadap klausul utama, dengan demikian meningkatkan keseluruhan pembacaan dan juga membuat tugas penghuraian IRTG traktable. Kami berpartisipasi di Surface Realization 2020, tugas berbagi, tolak T1a (rendah, tertutup). Evaluasi manusia menunjukkan kita mencapai peningkatan yang signifikan pada dua dari tiga dataset luar domain dibandingkan dengan sistem 2019 yang kita modifikasikan. Kedua komponen sistem kita tersedia di GitHub di bawah lisensi MIT.', 'tr': 'Biz uniwersal Baýumlylik strukturalary setir metine reňdirmek üçin bir sistemi görkezýäris. Bu sistemi sözleriň düzenini ýagdaýa görkezä öwrenip otyr. Bu sistemi string we grafik operasiýasynyň arasynda reňdirme bilen tanyýar. Tekrar fleksiýa adım biLSTM ködleme we üns berilýän bir LSTM ködleme tarapynda süýtgedilýär. Biz 2019-njy ýyldaky sistemimizi (Kovacs et al., 2019) yeni bir gramatik induksyonun mekanizması ile, IRTG kurallaryna limmatik täglerini bir parça söz etiketlerine eklemek üçin mümkin edip, her söz we bağlı tägleriniň iň takyk öğrenýän şartlaryň ullanyşyny garaşýarys. Biz hem sözleriň ýene-täzeliklerini sözleriň sözleriň sırasyny bir sözleriň ýüzünde düzenlemeden önce bir iýerarhiýa ýalaýyşyny tanyşdyrýarys we şonuň üçin hemme okamak mümkinçiligini gelişdirýän we IRTG a ýdyşyny bejermek üçin bir sözleriň sırasyny bejerip barýarys. 2020-nji ýylyň ýüze Gerçekleşme Paýlaşylyş Taýdaly zada goşuldyk. İnsanyň çykyşyklamasynda, 2019-njy üýtgediğimiz sisteme we 2-nji domain veri setlerinde möhüm gelişmeleri ýetip bilýäris. Sistemimiziň ikisi hem parçalary MIT lisansynda GitHub üçin bar.', 'da': 'Vi præsenterer et system til kortlægning af Universal Dependency strukturer til rå tekst, som lærer at gendanne ordrækkefølge ved at træne en Tolked Regular Tree Grammar (IRTG), der etablerer en kortlægning mellem streng og grafoperationer. Genflektionstrinet håndteres af en standard sekvens-til-sekvens arkitektur med en biLSTM encoder og en LSTM dekoder med opmærksomhed. Vi ændrer vores 2019-system (Kovacs et al., 2019) med en ny grammatisk induktionsmekanisme, der gør det muligt for IRTG regler at fungere på lemmata ud over del-of-tale tags og sikrer, at hvert ord og dets afhængige er omorrangeret ved hjælp af de mest specifikke sæt af lærte mønstre. Vi indfører også en hierarkisk tilgang til gendannelse af ordrækkefølge, der uafhængigt bestemmer ordrækkefølgen af hver sætning i en sætning, før de arrangeres i forhold til hovedsætningen, hvilket forbedrer den generelle læsbarhed og også gør IRTG parsing opgaven tracable. Vi deltog i 2020 Surface Realization Shared opgave, subtrak T1a (lavvandet, lukket). Menneskelige evalueringer viser, at vi opnår betydelige forbedringer på to af de tre datasæt uden for domænet sammenlignet med det system, vi ændrede i 2019. Begge komponenter i vores system er tilgængelige på GitHub under en MIT licens.', 'am': 'የዓለማዊ ግንኙነት ሥርዓት መክፈቻን ለመቀላቀል እናስቀምጣለን፡፡ አዲስ ማስታወቂያው በቢልSTM የኮድ እና የLSTM ዶዶሴ በጥያቄ ይደረጋል፡፡ በ2019 ስርዓታችንን (Kovacs et al., 2019) እና አዲስ የግራማር ጉዳይ አካባቢ እና IRTG ሥርዓቶችን ከንግግር ማዕከል በቀር ሊሞራ እንዲፈቅድ እና ሁሉንም ቃል እና ደጋፊዎቹ በተለይም የተማሩ ዓይነቶች እንዲጠቀም እንዲያረጋግጡ እናረጋግጣለን፡፡ በዋነኛው ክፍል ላይ ከመስጠት በፊት የሁሉን ክፍል ቃላትን ለብልሃት ማሳየት እናደርጋለን፡፡ በ2020 ፊትር አካባቢነት የተሰራጨውን ስራ፣ T1a (ጥቁር፣ ተዘጋጀን) አጋራጠርን፡፡ Human evaluation shows we achieve significant improvements on two of the three out-of-domain datasets compared to the 2019 system we modified.  የስርዓታችን ሁለቱ ክፍሎች ከ MIT ፍቃዱን በታች በGitHub ላይ ይገኛሉ፡፡', 'fa': 'ما یک سیستم برای نقشه\u200cسازی ساختارهای بستگی جهانی را به متن خاکستری که با آموزش یک گرم درخت معمولی (IRTG) تغییر دادن یک نقشه\u200cسازی بین تکه\u200cها و عملیات گراف یاد می\u200cگیریم. قدم تغییر تغییر تغییر تغییر تغییر دادن با یک معماری استاندارد به رده با یک رمز\u200cدهنده biLSTM و یک رمز\u200cدهنده LSTM با توجه است. ما سیستم ۲۰۱۹ را تغییر می\u200cدهیم (Kovacs et al., 2019) با یک مکانیسم فعالیت گرامی جدید که اجازه می\u200cدهد قانون IRTG روی لیماتای در اضافه به برچسب\u200cهای سخنرانی عمل کند و مطمئن می\u200cشود که هر کلمه و بستگی\u200cهای آن با استفاده از ترین مجموعه\u200cای از الگوهای یادآ ما همچنین یک دستور تدریجی برای بازسازی دستور کلمات را معرفی می کنیم که به طور مستقل سفارش کلمات هر کلمات را در یک جمله تصمیم می گیرد قبل از اینکه آنها را با ارتباط به کلمات اصلی تدریجی کنیم، به وسیله آن، توانایی کلمات پذیرش را بهتر می کنیم و همچنین ردیابی کار IR ما در کار مشترک سطح واقعیت ۲۰۰۲ شرکت کردیم، subtrack T1a (گسترده، بسته). ارزیابی انسان نشان می\u200cدهد که ما در دو از سه مجموعه داده\u200cهای خارج از دومین در مقایسه با سیستم ما تغییر داده\u200cایم، بهترین\u200cهای بزرگی را دریافت می\u200cکنیم. هر دو قسمت از سیستم ما در GitHub تحت اجازه\u200cی MIT دسترسی دارند.', 'az': "Biz üniversal bağımlılıq qurularını çizgi metinə maplama sistemini göstəririk ki, sözlərin sıralamasını öyrənir. İşləndirilən düzgün a ğac Grammar (IRTG) təhsil edir ki, ağac və grafik işləri arasında maplama yaradır. Refleksiyon adımı biLSTM kodlayıcısı və LSTM kodlayıcısı ilə standart sequence-to-sequence arhitektura ilə müdafiə edilir. Biz 2019-ci sistemimizi (Kovacs et al., 2019) yeni bir gramatika induksyon mehānismi ilə dəyişdiririk ki, IRTG kurallarının bir qismi sözlərin etiketlərini və hər sözü və bağımlıqlarının ən müəyyən öyrəndiyi modellərdən istifadə etməsinə imkan verir. Biz həmçin in hər clauzun sözlərinin sıralamasını özgürsüz təsdiqləməsindən əvvəl özlərinə təsdiqləməsindən əvvəl onları ana clauzula qarşı düzəltməkdən əvvəl hiyerarşik tərzini təşkil edirik, bununla bütün oxuyabiləcəyi və IRTG öyrənəcəyi işlər tərzini də daha yaxşılaşdırırıq. Biz 2020 Yüzü Realizasyon paylaşılmış iş, T1a subtrack (çəkilmiş, kapalı) ilə iştirak etdik. İnsan değerlendirməsi göstərir ki, 2019 sistemi ilə dəyişdiyimiz üç dəyişiklik veri qurularından iki dəyişiklik düzəltdi. Sistemimizin iki komponenti MIT lisansının altında GitHub'da faydalanır.", 'af': "Ons voorsien 'n stelsel vir kartering van Universele Afhanklikheid strukture na raai teks wat leer om woord volgorde te herstel deur die onderwerp van 'n Gewone Gewone Boom Grammar (IRTG) wat stel 'n kaart tussen string en graaf operasies. Die reinfleksie stap is behandel deur 'n standaard volgorde-na-sekwensies-arkitektuur met 'n biLSTM-enkoder en 'n LSTM-dekoder met aandag. Ons verander ons 2019 stelsel (Kovacs et al., 2019) met 'n nuwe grammatiese induksie mekanisme wat die IRTG reëls laat toe om op lemmatie te werk, in addition to part-of-speech tags and verseker dat elke woord en sy afhanklikhede herordeniseer word deur die mees spesifieke stel van geleerde patrone. Ons introduseer ook 'n hierarkies toegang tot woord volgorde herstelling wat onveilig die woord volgorde van elke klaus in 'n seting bepaal voordat hulle met betrekking tot die hoof klaus aanstel, daarom verbeter die hele leesbaarde en ook die IRTG verwerking opdragtabel. Ons het deel in die 2020 Surface Realization Gedeelde taak, subtrakk T1a (skaal, gesluit). Die menslike evaluering vertoon dat ons betekende verbeteringe op twee van die drie uit-domein datastelle vergelyk het met die 2019 stelsel wat ons verander het. Beide komponente van ons stelsel is beskikbaar op GitHub onder 'n MIT lisensie.", 'sq': "Ne paraqesim një sistem për hartimin e strukturave të Varësisë Universale në tekst të papërpunuar që mëson të rikthejë rendin e fjalëve duke stërvitur një Gramë të Interpretuar të Treve Regular (IRTG) që krijon një hartim midis operacioneve të rreshtave dhe grafikëve. Hapi i reflektimit trajtohet nga një arkitekturë standarte sekuencë-në-sekuencë me një kodues biLSTM dhe një dekoder LSTM me vëmendje. Ne modifikojmë sistemin tonë 2019 (Kovacs et al., 2019) me një mekanizëm të ri induktimi gramatik që lejon rregullat e IRTG të funksionojnë në limanë përveç etiketave pjesë-të-fjalës dhe siguron që çdo fjalë dhe varësit e saj të riorganizohen duke përdorur grupin më specifik të modeleve të mësuara. Ne gjithashtu futim një qasje hierarkike për restaurimin e rendit të fjalës që përcakton në mënyrë të pavarur rendin e fjalës të çdo klauzule në një fjalë përpara se t'i rregullojmë a to lidhur me klauzulën kryesore, duke përmirësuar kështu lexueshmërinë e përgjithshme dhe duke bërë gjithashtu të trajtueshme detyrën e analizimit të IRTG. Ne morëm pjesë në detyrën e përbashkët të realizimit të sipërfaqes për 2020, duke hequr T1a (të sipërfaqen, të mbyllur). Human evaluation shows we achieve significant improvements on two of the three out-of-domain datasets compared to the 2019 system we modified.  Të dy komponentet e sistemit tonë janë në dispozicion në GitHub nën një licencë MIT.", 'bn': 'আমরা বিশ্ববিদ্যালয়ের নির্ভরশীল কাঠামোর মানচিত্রের জন্য একটি সিস্টেম উপস্থাপন করি যা টেক্সট ভেঙ্গে ফেলার জন্য বাক্যের আদেশ পুনরুদ্ধার করতে শিখে যাচ্ বাইলস্টিএম এনকোডার এবং একটি এলএসএসএমএস ডিকোডার দ্বারা একটি স্ট্যান্ডারেন্ড সেকেন্ড-থেকে সেকেন্ডারের ক্ষেত্রে পুনরায় বিক আমরা ২০১৯ সিস্টেম পরিবর্তন করি (কোভাক্স এবং আল, ২০১৯) একটি নতুন গ্রামার শিল্প প্রতিষ্ঠানের মাধ্যমে একটি নতুন শিক্ষার্থীর মাধ্যমে আইআরটিজি নিয়মের কাজ করার সুযোগ দিয়েছি এবং ভাষণের ট্ We also introduce a hierarchical approach to word order restoration that independently determines the word order of each clause in a sentence before arranging them with respect to the main clause, thereby improving overall readability and also making the IRTG parsing task tractable.  আমরা ২০২০০ সার্ফেস রিয়ালিজেশন শেয়ার করার কাজে অংশগ্রহণ করেছিলাম, সাবট্র্যাক টি১ (ধূল, বন্ধ)। মানুষের মুল্যায়ন দেখাচ্ছে যে ২০১৯ সিস্টেমের তুলনায় আমরা পরিবর্তন করেছি ২০১৯ সালের তুলনায় তিনটি ডাটাসেটের উপর আমরা গুরুত্ব এমআইটি লাইসেন্সের অধীনে আমাদের সিস্টেমের দুটো অংশ গিটহাবে পাওয়া যাচ্ছে।', 'hy': 'Մենք ներկայացնում ենք համաշխարհային կախվածության կառուցվածքների քարտեզագրման համակարգ, որը սովորում է վերականգնել բառի կարգը՝ վարժեցնելով մեկնաբանված կանոնական ծառի գրամար (ԻՏԳ), որը կառուցնում է լարերի և գծագրի գործողությունների միջև քարտեզագրություն: Հետախուզական քայլը վերահսկվում է ստանդարտ հաջորդականության ճարտարապետության միջոցով, որտեղ ներկայացված է բիLSԹՄ կոդեր և LSԹՄ կոդեր: We modify our 2019 system (Kovacs et al., 2019) with a new grammar induction mechanism that allows IRTG rules to operate on lemmata in addition to part-of-speech tags and ensures that each word and its dependents are reordered using the most specific set of learned patterns.  We also introduce a hierarchical approach to word order restoration that independently determines the word order of each clause in a sentence before arranging them with respect to the main clause, thereby improving overall readability and also making the IRTG parsing task tractable.  We participated in the 2020 Surface Realization Shared task, subtrack T1a (shallow, closed).  Մարդկային գնահատումը ցույց է տալիս, որ մենք հասնում ենք նշանակալի բարելավումներին 2019 թվականին փոխված համակարգի հետ համեմատելով 3-ից դուրս գալիս տեղեկատվական համակարգից երկուսին: Մեր համակարգի երկու բաղադրիչները հասանելի են ԳիթՀուբի վրա MIT-ի արտոնագրության տակ:', 'ca': "Presentam un sistema de mapeament estructures de Dependencia Universal a text brut que aprenen a restaurar l'ordre de paraules treinant un grama d'arbre regular interpretat (IRTG) que estableix un mapeament entre les operacions de cadenes i gràfics. El pas de reinflexió està gestionat per una arquitectura de seqüència a seqüència estàndard amb un codificador biLSTM i un codificador LSTM amb atenció. Modifiquem el nostre sistema de 2019 (Kovacs et al., 2019) amb un nou mecanisme d'inducció gramàtica que permet que les normes IRTG operin en limàtes a més d'etiquetes de part de la xerrada i asseguri que cada paraula i les seves dependents es reordenen utilitzant el conjunt més específic de patrons aprenguts. També introduïm un enfocament jeràrquic a la restauració de l'ordre de paraules que determina de manera independent l'ordre de paraules de cada clàusula en una frase abans d'organitzar-los en relació a la clàusula principal, millorant així la llegibilitat global i també tornant tractable la tasca d'analització IRTG. Vam participar en la tasca compartida de la Realització de la Superfície del 2020, subtraccionant T1a (baix, tancat). L'evaluació humana mostra que aconsegueixem millores significatives en dos dels tres conjunts de dades fora de domini comparats amb el sistema del 2019 que vam modificar. Ambdós components del nostre sistema estan disponibles a GitHub amb una llicència MIT.", 'bs': 'Predstavljamo sistem za mapiranje struktura univerzalne zavisnosti na sirov tekst koji nauči da obnovi red riječi obučavajući preglednu regularnu granicu drveta (IRTG) koja utvrđuje mapiranje između operacija žica i grafika. Korak reinflekcije se rješava standardnim arhitekturom sekvence do sekvence sa koderom biLSTM i LSTM dekoderom sa pažnjom. Mi izmijenimo naš sistem 2019. godine (Kovacs et al., 2019) sa novim gramatičkim indukcijskim mehanizam koji omogućava da se IRTG pravila funkcioniše na limeti u dodatnom dijelom govornih etiketa i osigurava da se svaka riječ i njegovi ovisnici ponovno urede koristeći najspecifičniji skup učenih obrazaca. Također predstavljamo hijerarhički pristup restauraciji reda riječi koji neovisno određuje redak riječi svake klauzule u rečenici prije nego što ih sredimo u pogledu glavne klauzule, tako poboljšavajući ukupnu čitljivost i čineći i praćenje zadataka IRTG-a. Učelili smo u zajedničkom zadatku realizacije površine 2020. godine, subtrakt T1a (plitko, zatvoren). Ljudska procjena pokazuje da postignemo značajno poboljšanje na dva od tri podataka izvan domena u usporedbi s sistemom 2019 koji smo modificirali. Obje komponente našeg sistema su dostupne na GitHubu pod MIT dozvolu.', 'cs': 'Představujeme systém mapování struktur univerzální závislosti na surový text, který se naučí obnovit pořadí slov tréninkem Interpretované gramatiky regulárního stromu (IRTG), která vytváří mapování mezi řetězcovými a grafovými operacemi. Krok reinflekce je řešen standardní architekturou sekvence-sekvence s pozorností snímačem biLSTM a dekodérem LSTM. Upravujeme náš 2019 systém (Kovacs et al., 2019) o nový mechanismus gramatické indukce, který umožňuje pravidla IRTG pracovat na lemmatě kromě značek části řeči a zajišťuje, že každé slovo a jeho závislé slovo budou přeorganizovány pomocí nejspecifickější sady naučených vzorců. Představujeme také hierarchický přístup k obnově slovního pořadí, který nezávisle určuje pořadí slov každé věty před jejich uspořádáním s ohledem na hlavní větu, čímž zlepšuje celkovou čitelnost a zároveň umožňuje trasovat IRTG parsing úlohu. Podíleli jsme se na 2020 Surface Realization Shared Task, subtrack T1a (mělký, uzavřený). Lidské hodnocení ukazuje, že ve srovnání se systémem 2019, který jsme upravili, dosahujeme významných zlepšení u dvou ze tří datových sad mimo doménu. Obě komponenty našeho systému jsou dostupné na GitHubu pod licencí MIT.', 'et': 'Esitleme universaalse sõltuvuse struktuuride kaardistamise süsteemi toortekstile, mis õpib taastama sõnade järjestuse, treenides tõlgendatud regulaarset puugrammatikat (IRTG), mis loob stringi ja graafikutoimingute kaardistamise. Taasinflektsiooni etappi käsitletakse standardse järjestuse-järjestuse arhitektuuriga biLSTM kodeerija ja LSTM dekooderiga tähelepanu pöörates. Muudame oma 2019. aasta süsteemi (Kovacs jt., 2019) uue grammatika induktsioonimehhanismiga, mis võimaldab IRTG reeglitel lisaks kõneosalistele siltidele töötada lemmatal ning tagab, et iga sõna ja selle sõltuvad on ümber järjestatud, kasutades kõige spetsiifilisemaid õppitud mustreid. Lisaks võtame kasutusele hierarhilise lähenemisviisi sõnade järjekorra taastamisele, mis määrab sõnade järjekorra sõltumatult kindlaks iga lause sõnade järjekorra enne nende korraldamist põhiklausli suhtes, parandades seeläbi üldist loetavust ja muutes IRTG parsimise ülesande jälgitavaks. Osalesime 2020. aasta pinnarealiseerimise jagatud ülesandes T1a mahaarvamine (madal, suletud). Inimeste hindamine näitab, et oleme saavutanud märkimisväärseid edusamme kolmest domeenivälisest andmekogumist kahes võrreldes 2019. aasta süsteemiga, mida me muutsime. Mõlemad meie süsteemi komponendid on GitHub saadaval MIT litsentsi all.', 'fi': 'Esittelemme järjestelmän universaalin riippuvuuden rakenteiden kartoittamiseen raakatekstiin, joka oppii palauttamaan sanajärjestyksen harjoittelemalla tulkattua säännöllistä puun kielioppia (IRTG), joka muodostaa merkkijonon ja graafisen toiminnan välisen kartoituksen. Uudelleenkorjausvaihetta käsitellään standardilla sekvenssi-sekvenssi-arkkitehtuurilla biLSTM-kooderilla ja LSTM-dekooderilla tarkkaavaisesti. Muokkaamme vuoden 2019 järjestelmäämme (Kovacs et al., 2019) uudella kieliopin induktiomekanismilla, jonka avulla IRTG-säännöt voivat toimia lemmatalla puhetunnisteiden lisäksi ja varmistaa, että jokainen sana ja sen riippuvaiset järjestellään uudelleen käyttämällä tarkimpia opittuja kuvioita. Toteutamme myös hierarkkisen lähestymistavan sanajärjestyksen palauttamiseen, joka määrittää itsenäisesti jokaisen lauseen sanajärjestyksen ennen niiden järjestämistä päälauseen nähden, mikä parantaa yleistä luettavuutta ja tekee IRTG-jäsennystehtävästä jäljitettävän. Osallistuimme vuoden 2020 Surface Realization Shared -tehtävään, vähentää T1a (matala, suljettu). Ihmisten arviointi osoittaa, että olemme saaneet aikaan merkittäviä parannuksia kahdessa kolmesta verkkotunnuksen ulkopuolisesta aineistosta verrattuna vuoden 2019 järjestelmään, jota muokkasimme. Järjestelmämme molemmat komponentit ovat saatavilla GitHubissa MIT-lisenssillä.', 'jv': 'We present a sistem for maping Universal Dehendehensible structural to red text that Learn to restitura word order by tutorial an interprehensible Regular Grimm (IRT G) that setup a maping amongst string and graphoperasi. Laptop" and "Desktop Awak dhéwé ngerti sistem dhéwé (KoVaVas et al, 2011) lan akeh sistem sing berarti perbudhakan winih kanggo nyelarane kapan pangan nggawe sistem dhéwé (KoVas et al), lan akeh sistem anyar tentang kanggo nyelarane kapan IRT kebutuhan lemmatik dadi batir tanggal gawe lan ujaran winih-uwong sing berarti secara word lan dianggap dhéwé bera Awak dhéwé éntuk sistem sistem akeh perusahaan kanggo awak dhéwé ngerasakno dadi, nik awak dhéwé kuwi kesempatan kanggo ngubah dhéwé Awak dhéwé ngejaraké karo Mbak-Ngerawat \'2020 Iwatahan Ngawe gerakan karo Mbak-Ngerawat, Tu1a-Ngerawat (tigeh, tigeh). Human measurement Shows we success of a Signual Progress on 2 of the 3 out-of-domain dataset Sampeyan durung sing dibutuhke sistem sing dibutuhke nang GIthub sanes alih MT.', 'he': 'אנחנו מציגים מערכת למפות מבנים של תלויות יוניברסליות לטקסט חומר שמלמד לשחזר את סדר המילים על ידי אימון גרמאר עץ רגיל מתפרש שלב ההשתקפות מתמודד על ידי ארכיטקטורה סטנדרטית רצף-רצף עם קודד biLSTM וקודר LSTM עם תשומת לב. אנו משנים את מערכת 2019 שלנו (Kovacs et al., 2019) עם מנגנון ניתוח גרמטיקה חדש שמאפשר לחוקי IRTG לפעול על לימטה בנוסף לחלק של תגים של דיבור ומבטיחים שכל מילה והתלויות שלה מתארגנים מחדש באמצעות קבוצה ספציפית ביותר של דפוסים ללמודים. אנחנו גם מציגים גישה היררכית לשיקום סדר מילים שמקבלת באופן עצמאי את סדר המילים של כל פסק במשפט לפני שהסדרנו אותם בנוגע לחלק העיקרי, כך משפר את הקריאות הכללית וגם הופך את המשימה של בדיקת IRTG למשוך. השתתפנו במשימה המשותפת של השטח של 2020, למשוך T1a (שטח, סגור). הערכה האנושית מראה שאנחנו משיגים שיפורים משמעותיים בשני משלושת קבוצות נתונים מחוץ לתחום בהשוואה למערכת 2019 ששינינו. שני המרכיבים של המערכת שלנו זמינים על GitHub תחת רישיון MIT.', 'ha': "Tuna gabatar da wani na'ura wa yin ramani da matsayin Kyauta Duniyar Duniani dõmin ya yi raw matsayin da za'a sanar da su sake tsari tsarin magana da za'a yi amfani da wani grammar Tree na Kiɗari da aka Fassar (IRTG) wanda ke daidaita wani map a tsakanin jumla da aikin taskõkin grafyutan. Gago na canza da aka yi amfani da matsayin na'urar-duhun-sequence na ɗabi'a mai biLSSM kode da kuma an kode LSSM da aikin. Tuna gyarar tsarin 2019 (Kozaks et al., 2019) da wata na'urar manunufi na grammar wanda ke yarda da iznin IRTG ya yi aiki a kan limmata, da kuma a ƙara rabo-tagogi na magana kuma za'a tabbatar da kowace kalma da kamfaniyarsa a yi amfani da tsarin tsari masu ƙayyade ƙayyadadde. Kayya, Munã ƙãga wani takwara wa rehabilita kalma da aka canza tsari da magana wanda yana yarda da shi kaɗai na ƙayyade tsarin duk jama'a a cikin birane a gabãnin ka haɗa su da sharuya mai girma, kuma da haka, za'a kyautata karatun duk kuma za'a sami aikin IRTG mai parse. Mun yi shirin da shi a 2020 Surface real Shared job, subtract T1a (shallow, rufated). Ana ƙaddara mutum yana ganin mu sami mafiya ƙari ko biyu daga data-waɗanda ba'a-Domen ba sammenliki da na tsarin 2019 wanda muka gyare. Dukiya na'uranmu biyu ana iya sãmun GitHub da wata lissãfi na MIT.", 'sk': 'Predstavljamo sistem za mapiranje struktur univerzalne odvisnosti v surovo besedilo, ki se nauči obnoviti vrstni red besed z usposabljanjem Interpreted Regular Tree Grammar (IRTG), ki vzpostavlja mapiranje med operacijami nizov in grafov. Korak ponovne reflekcije se obravnava s standardno arhitekturo zaporedja do zaporedja s kodirjem biLSTM in sprejemnikom LSTM s pozornostjo. Naš sistem za leto 2019 (Kovacs et al., 2019) spreminjamo z novim mehanizmom za indukcijo slovnice, ki omogoča, da pravila IRTG delujejo na lemmata poleg oznak dela govora in zagotavlja, da se vsaka beseda in njeni odvisni osebi preuredijo z uporabo najbolj specifičnega nabora učenih vzorcev. Uvedli smo tudi hierarhični pristop k obnovi vrstnega reda besed, ki neodvisno določa vrstni red besed vsakega stavka v stavku, preden ga uredi glede na glavno stavko, s čimer izboljša splošno berljivost in omogoča sledenje opravila IRTG razčlenjanja. Sodelovali smo pri deljeni nalogi uresničevanja površin 2020, odštevanje T1a (plitvo, zaprto). Ocena ljudi kaže, da smo dosegli znatne izboljšave pri dveh od treh zunajdomenskih podatkovnih nizov v primerjavi s sistemom za leto 2019, ki smo ga spremenili. Obe komponenti našega sistema sta na voljo na GitHub pod MIT licenco.', 'bo': 'We present a system for mapping Universal Dependency structures to raw text which learns to restore word order by training an Interpreted Regular Tree Grammar (IRTG) that establishes a mapping between string and graph operations. The reinflection step is handled by a standard sequence-to-sequence architecture with a biLSTM encoder and an LSTM decoder with attention. We modify our 2019 system (Kovacs et al., 2019) with a new grammar induction mechanism that allows IRTG rules to operate on lemmata in addition to part-of-speech tags and ensures that each word and its dependents are reordered using the most specific set of learned patterns. ང་ཚོས་ཀྱང་དབུས་འཛིན་གྱི་ཐབས་ལམ་ལ་འཇུག་སྣོད་ཀྱི་གོ་རིམ་སྟོན་པ་དེ་ལས་རང་བཞིན་གྱིས་ཐ་སྙད་ཀྱི་གོ་རིམ་སྟོན་པའི་ཡིག ང་ཚོས་༢༠༠2020་རིང་གདོང་རིས་ལྕགས་རིམ་དང་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་ནང་དུ་མཉམ་དུ་འགྲོ། Human evaluation shows we achieve significant improvements on the two of the three out-of-domain datasets compared to the 2019 system we modified. ང་ཚོའི་མ་ལག་གི་ཆ་ཤས་གཉིས་པོ་གཉིས་ཀྱིས་MIT ཆོག་ཐང་ཐོག་ཏུ་GitHub སྤྱོད་ཐུབ་པ'}
{'en': 'NILC at SR’20 : Exploring Pre-Trained Models in Surface Realisation', 'ar': "NILC في SR'20: استكشاف النماذج المدربة مسبقًا في إدراك السطح", 'es': "NILC en SR'20: Exploración de modelos preentrenados en la realización de superficies", 'pt': "NILC no SR'20: Explorando Modelos Pré-Treinados na Realização de Superfícies", 'fr': "NILC au SR'20\xa0: Exploration de modèles pré-entraînés dans la réalisation de surfaces", 'zh': 'SR曰:20上NILC:求其先成', 'ja': "SR '20のNILC ：表面実現における事前トレーニングモデルの探求", 'hi': "SR'20 में NILC: सतह प्राप्ति में पूर्व-प्रशिक्षित मॉडल की खोज", 'ru': "NILC на SR'20: Изучая Предварительно Обученные Модели в Поверхностной Реализации", 'ga': "NILC ag SR'20: Samhlacha RéamhOilte a Iniúchadh i Réadú Dromchla", 'ka': "NILC SR'20- ში: სამუშაო რეალიზაციაში სამუშაო მოდელების გამოყენება", 'el': 'Η έρευνα των προ-εκπαιδευμένων μοντέλων στην υλοποίηση επιφάνειας', 'hu': "NILC az SR'20-on: Előképzett modellek feltárása a felületmegvalósításban", 'kk': "SR'20 дегенде NILC: Жергілікті реализациялау үлгілерін зерттеу", 'mk': "NILC во SR'20: Истражување на предобучени модели во реализацијата на површината", 'ms': "NILC di SR'20: Menjelajah Model Pra-Latihan dalam Pengesahan Surface", 'lt': "NILC SR'20: Išankstinio mokymo paviršiaus realizavimo modelių tyrimas", 'mt': 'NILC f’SR’20: L-esplorazzjoni ta’ mudelli mħarrġa minn qabel fir-Realizzazzjoni tal-wiċċ', 'mn': "SR'20 дээр NILC: Төмөр бодит байдлын өмнөх сургалтын загваруудыг судлах", 'ml': 'SR- 20- ലെ NILC: മുമ്പ് പരിശീലന മോഡലുകള്\u200d പരിശോധിക്കുന്നു', 'it': "NILC a SR'20: Esplorare modelli pre-addestrati nella realizzazione di superfici", 'no': "NILC ved SR' 20: Utforskar føreøvinga modeller i overflate", 'ro': "NILC la SR'20: Explorarea modelelor pregătite în realizarea suprafețelor", 'pl': "NILC na SR'20: Badanie wstępnie przeszkolonych modeli w realizacji powierzchni", 'sr': "NILC na SR'20: istraživanje predobučenih modela u realizaciji površine", 'si': "NILC SR'20 වල: ප්\u200dරතිමූණ ඇත්තටම ප්\u200dරශ්නය කරනවා ප්\u200dරශ්නය", 'sv': "NILC på SR'20: Att utforska förberedda modeller inom ytrealisering", 'ta': 'SR- 20- ல் NILC: முன்பு பயிற்சி மாதிரிகளை தெரிவிக்கும் முன்னோட்டம்', 'so': "NILC at SR'20: Exploring Pre-Trained Models in Surface Realisation", 'ur': "SR'20 میں NILC: Surface Realization میں پیش ترینس کی موڈل پھیلاتے ہیں", 'uz': "NILC at SR'20: Exploring Pre-Trained Models in Surface Realisation", 'vi': "NILC tại SR'20: Khám phá mẫu trước-huấn luyện trong thực tế mặt đất", 'bg': "НИЛК в СР'20: Изследване на предварително обучени модели в реализацията на повърхността", 'da': "NILC på SR'20: Udforsk prætrænede modeller i overfladebehandling", 'id': "NILC di SR'20: Menjelajah Model Pra-Latihan dalam Realisasi Surface", 'hr': "NILC na SR'20: istraživanje predobučenih modela u realizaciji površine", 'nl': "NILC op SR'20: Vooropgeleide modellen verkennen in oppervlakterealisatie", 'ko': "NILC SR'20: 표면 실현 중의 예비 훈련 모델 탐색", 'de': "NILC auf der SR'20: Erforschung vortrainierter Modelle in der Oberflächenrealisierung", 'fa': "NILC در SR'20: تحقیق مدل پیش آموزش در واقعیت سطح", 'sw': "NILC kwenye SR'20: Kuchunguza Modeli zilizojifunza kabla ya Uhalilishaji", 'tr': "NILC SR'20", 'hy': "NILC at SR'20: Exploring Pre-Trained Models in Surface Realisation", 'am': "SR'20: Exploring Pre-Trained Models in Surface Realisation", 'bn': "SR'20-এ এনআইসি: প্রাক্তন প্রশিক্ষিত মোডেল বিশ্লেষণ করা হচ্ছে", 'sq': "NILC at SR'20: Exploring Pre-Trained Models in Surface Realisation", 'bs': "NILC na SR'20: istraživanje predobučenih modela u realizaciji površine", 'ca': "NILC a SR'20: Explorar models pré-capacitats en la realització de la superfície", 'cs': "NILC na SR'20: Prozkoumání předškolených modelů v povrchové realizaci", 'az': "SR'20'də NILC: Yüzü Realizasyonda Ön Eğitimli Modelləri Exploring", 'fi': "NILC SR'20: Esikoulutettujen mallien tutkiminen pintatoteutuksessa", 'et': "NILC SR'20: Eeltreenitud mudelite uurimine pinna realiseerimisel", 'af': 'Name', 'jv': "NILC nang SS'22: Isobah Daftar Pri-Triangkat model nang surmask Actualisasi", 'ha': '@ info: whatsthis', 'he': "NILC ב SR'20: חקירה מודלים מאומנים מראש במציאות שטח", 'sk': "NILC na SR'20: Raziskovanje vnaprej usposobljenih modelov pri uresničevanju površin", 'bo': "NILC at SR'20: Exploring Pre-Trained Models in Surface Realisation"}
{'en': 'This paper describes the submission by the NILC Computational Linguistics research group of the University of S ao Paulo / Brazil to the English Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020. The success of the current pre-trained models like ', 'ar': 'تصف هذه الورقة التقديم الذي قدمته مجموعة أبحاث اللغويات الحاسوبية التابعة لـ NILC بجامعة ساو باولو / البرازيل إلى المسار الإنجليزي 2 (مسار فرعي مغلق) في Surface Realization Shared Task 2020. نجاح النماذج الحالية المدربة مسبقًا مثل إن BERT أو GPT-2 معروفان جيدًا في العديد من المهام ، ومع ذلك ، ليس هذا هو الحال بالنسبة لمهام إنشاء تحويل البيانات إلى نص ، ومؤخراً ركزت بعض المبادرات عليها. بهذه الطريقة ، نستكشف كيفية أداء نموذج مدرب مسبقًا (GPT-2) في مهمة إنشاء UD إلى نص. بشكل عام ، كانت النتائج المحققة ضعيفة ، ولكن هناك بعض الأفكار المثيرة للاهتمام لاستكشافها. من بين الدروس المستفادة ، قد نلاحظ أنه من الضروري دراسة الاستراتيجيات لتمثيل مدخلات UD وإدخال المعرفة الهيكلية في هذه النماذج المدربة مسبقًا.', 'fr': "Cet article décrit la soumission par le groupe de recherche NILC Computational Linguistics de l'Université de São Paulo/Brésil à la piste anglaise 2 (sous-piste fermée) lors de la tâche partagée de réalisation de surface 2020. Le succès des modèles pré-entraînés actuels tels que BERT ou GPT-2 dans plusieurs tâches est bien connu, mais ce n'est pas le cas pour les tâches de génération de données en texte et, récemment, certaines initiatives y ont été axées. De cette façon, nous explorons comment un modèle pré-entraîné (GPT-2) fonctionne sur la tâche de génération d'UD-texte. En général, les résultats obtenus étaient médiocres, mais il y a quelques idées intéressantes à explorer. Parmi les leçons apprises, nous pouvons noter qu'il est nécessaire d'étudier des stratégies pour représenter les entrées de l'UD et d'introduire des connaissances structurelles dans ces modèles pré-entraînés.", 'es': 'Este artículo describe la presentación del grupo de investigación de Lingüística Computacional de NILC de la Universidad de S ̃ao Paulo/Brasil al Track 2 en inglés (sub-pista cerrada) en la Tarea Compartida de Realización de Superficies 2020. El éxito de los modelos actuales previamente entrenados como BERT o GPT-2 en varias tareas es bien conocido, sin embargo, este no es el caso de las tareas de generación de datos a texto y, recientemente, algunas iniciativas se han centrado en ello. De esta manera, exploramos cómo funciona un modelo preentrenado (GPT-2) en la tarea de generación de UD a texto. En general, los resultados obtenidos fueron malos, pero hay algunas ideas interesantes que explorar. Entre las lecciones aprendidas podemos señalar que es necesario estudiar estrategias para representar los insumos de la UD e introducir el conocimiento estructural en estos modelos previamente entrenados.', 'pt': 'Este artigo descreve a submissão do grupo de pesquisa em Linguística Computacional NILC da Universidade de São Paulo/Brasil para a Trilha 2 em Inglês (sub-trilha fechada) na Tarefa Compartilhada de Realização de Superfícies 2020. O sucesso dos atuais modelos pré-treinados como O BERT ou GPT-2 em várias tarefas é bem conhecido, no entanto, este não é o caso para tarefas de geração de dados para texto e apenas recentemente algumas iniciativas focaram nisso. Dessa forma, exploramos o desempenho de um modelo pré-treinado (GPT-2) na tarefa de geração de UD para texto. Em geral, os resultados alcançados foram fracos, mas existem algumas ideias interessantes a serem exploradas. Entre as lições aprendidas podemos notar que é necessário estudar estratégias para representar os insumos UD e introduzir conhecimentos estruturais nesses modelos pré-treinados.', 'ja': '本稿では、ブラジルのサンパウロ大学のNILC計算言語学研究グループがSurface Realisation Shared Task 2020で英語トラック2 （クローズドサブトラック）に提出したものについて述べる。いくつかのタスクにおけるBERTやGPT -2などの現在の事前トレーニング済みモデルの成功はよく知られていますが、データツーテキスト生成タスクではそうではなく、最近ではそれに焦点を当てたイニシアチブもあります。この方法では、事前にトレーニングされたモデル(GPT -2)がUD - to - text生成タスクでどのように実行されるかを説明します。一般的に、達成された結果は貧弱でしたが、探求すべき興味深いアイデアがいくつかあります。学習した教訓の中で、UD入力を表現するための戦略を研究し、これらの事前にトレーニングされたモデルに構造的知識を導入する必要があることに留意することができる。', 'zh': '本文述巴西圣保罗大学NILC计语言学究小组于2020年表成共享英语道2(封闭子轨道)提交之文。 今预练模形(如BERT、GPT-2)成功于众所周知,然数于文本生事者不然,但近者专注于此。 以此观之,吾将求预练模样 (GPT-2) UD 于文本。 要之,取果甚劣,但有趣思须探索。 或留意于UD输之策,引入于先训之中。', 'hi': 'यह पेपर सतह प्राप्ति साझा कार्य 2020 में अंग्रेजी ट्रैक 2 (बंद उप-ट्रैक) के लिए एस 1आओ पाउलो / ब्राजील विश्वविद्यालय के NILC कम्प्यूटेशनल भाषाविज्ञान अनुसंधान समूह द्वारा प्रस्तुत करने का वर्णन करता है। कई कार्यों में BERT या GPT-2 जैसे वर्तमान पूर्व-प्रशिक्षित मॉडल की सफलता अच्छी तरह से ज्ञात है, हालांकि, यह डेटा-टू-टेक्स्ट जनरेशन कार्यों के लिए मामला नहीं है और हाल ही में कुछ पहलों ने इस पर ध्यान केंद्रित किया है। इस तरह, हम यह पता लगाते हैं कि एक पूर्व-प्रशिक्षित मॉडल (जीपीटी -2) यूडी-टू-टेक्स्ट जनरेशन कार्य पर कैसे प्रदर्शन करता है। सामान्य तौर पर, प्राप्त परिणाम खराब थे, लेकिन पता लगाने के लिए कुछ दिलचस्प विचार हैं। सीखे गए पाठों में से हम ध्यान दे सकते हैं कि यूडी इनपुट का प्रतिनिधित्व करने और इन पूर्व-प्रशिक्षित मॉडलों में संरचनात्मक ज्ञान पेश करने के लिए रणनीतियों का अध्ययन करना आवश्यक है।', 'ru': 'В этой статье описывается представление исследовательской группой NILC по вычислительной лингвистике Университета Сан-Паулу/Бразилия английскому направлению 2 (закрытое подразделение) в рамках общей задачи реализации на поверхности 2020 года. Успех существующих предварительно обученных моделей, таких как BERT или GPT-2, в нескольких задачах хорошо известен, однако это не относится к задачам генерации данных в текст, и совсем недавно некоторые инициативы были сосредоточены на этом. Таким образом, мы исследуем, как предварительно обученная модель (GPT-2) выполняет задачу генерации UD-to-text. В целом достигнутые результаты были плохими, но есть некоторые интересные идеи для изучения. Среди извлеченных уроков можно отметить, что необходимо изучить стратегии представления входных данных UD и внедрить структурные знания в эти предварительно обученные модели.', 'ga': "Déanann an páipéar seo cur síos ar an aighneacht a rinne grúpa taighde Teangeolaíocht Ríomhaireachtúil NILC de chuid Ollscoil S ̃ao Paulo/An Bhrasaíl ar Rian Béarla 2 (fo-rian dúnta) ag Tasc Comhroinnte Réadú Dromchla 2020. D'éirigh leis na samhlacha réamhoilte reatha amhail Tá aithne mhaith ar BERT nó GPT-2 i roinnt tascanna, áfach, ní hé seo an cás maidir le tascanna giniúna sonraí go téacs agus díreach le déanaí bhí roinnt tionscnamh dírithe air. Ar an mbealach seo, déanaimid iniúchadh ar an gcaoi a bhfeidhmíonn samhail réamhoilte (GPT-2) ar an tasc giniúna UD-go-téacs. Go ginearálta, bhí na torthaí a baineadh amach lag, ach tá roinnt smaointe suimiúla le fiosrú. I measc na gceachtanna foghlamtha féadfaimid a thabhairt faoi deara go bhfuil sé riachtanach staidéar a dhéanamh ar straitéisí chun ionchuir UD a léiriú agus chun eolas struchtúrach a thabhairt isteach sna samhlacha réamhoilte seo.", 'el': 'Η παρούσα εργασία περιγράφει την υποβολή της ερευνητικής ομάδας Υπολογιστικής Γλωσσολογίας του Πανεπιστημίου της Βραζιλίας στην Αγγλική Διαδρομή 2 (κλειστό υπο-κομμάτι) στην Κοινή Εργασία Εκτέλεσης επιφάνειας 2020. Η επιτυχία των σημερινών προ-εκπαιδευμένων μοντέλων όπως το BERT ή το GPT-2 σε αρκετές εργασίες είναι ευρέως γνωστή, ωστόσο, αυτό δεν ισχύει για τις εργασίες δημιουργίας δεδομένων σε κείμενο και μόλις πρόσφατα ορισμένες πρωτοβουλίες επικεντρώθηκαν σε αυτό. Με αυτόν τον τρόπο, εξερευνούμε πώς λειτουργεί ένα προ-εκπαιδευμένο μοντέλο (GPT-2) στην εργασία δημιουργίας κειμένου. Γενικά, τα επιτευχθέντα αποτελέσματα ήταν φτωχά, αλλά υπάρχουν κάποιες ενδιαφέρουσες ιδέες που πρέπει να διερευνηθούν. Μεταξύ των διδαχθέντων διδαγμάτων μπορεί να σημειωθεί ότι είναι απαραίτητο να μελετηθούν στρατηγικές για την αναπαράσταση των εισροών και να εισαχθούν δομικές γνώσεις σε αυτά τα προ-εκπαιδευμένα μοντέλα.', 'hu': 'A tanulmány bemutatja a brazil S ao Paulo Egyetem NILC Számítógépes Nyelvészeti Kutatócsoportjának a felületmegvalósítás megosztott feladatának angol pályájára (zárt alpályára) való benyújtását. A jelenlegi, előre képzett modellek, például a BERT vagy a GPT-2 sikere több feladatban is jól ismert, azonban nem ez a helyzet az adat-szöveg generálási feladatok esetében, és csak a közelmúltban néhány erre összpontosított kezdeményezés. Így megvizsgáljuk, hogyan teljesít egy előre képzett modell (GPT-2) az UD-to-text generálási feladat. Általában az elért eredmények gyengék voltak, de van néhány érdekes ötlet, amit feltárni kell. Az elsajátított tanulságok közül meg kell jegyeznünk, hogy stratégiákat kell tanulmányozni az UD bemeneteinek bemutatására és strukturális ismereteket kell bevezetni ezekbe az előkészített modellekbe.', 'ka': 'ამ დოკუმენტი დააწერა NILC კომპუტაციალური ლინგურისტიკის გასწავლობის ჯგუფის სუნივერტის აოოოლო/ბრაზილო ინგლისური სიტყვის 2-ზე (დახურებული სუფერი) საზოგადო რეალიზაციის მიმდინარე მოდელების წარმატება, როგორც BERT ან GPT-2 რამდენიმე დავალებში, მაგრამ ეს არ არის მოცემული მოდელების დავალებისთვის და მხოლოდ მხოლოდ რამდენიმე ინტივიციატებისთვის, რომლებიც იქნება. ასე, ჩვენ ვხედავთ, როგორ დავიწყებთ პრეტრექტირებული მოდელი (GPT-2) UD-დან ტექსტის წარმოადგენის რაოდენობაში. გულისხმებით, მიღებული წარმოდგენები ცოტა, მაგრამ არსებობს საინტერესო იდეები. შეგვიძლია აღმოჩნოთ, რომ სტრატიგიების შესახებ UD შესახებ და სტრუქტური ცოდნენების შესახებ ამ წინ შესახებ მოდელში უნდა იყოს.', 'lt': 'Šiame dokumente aprašytas S. ao Paulo / Brazilijos universiteto NILC kompiuterinės kalbos mokslinių tyrimų grupės pateiktas anglų kelio 2 (uždarasis kelio poskyris) bendroje užduotyje „Surface Realisation 2020“. Dabartinių iš anksto parengtų modelių, pavyzdžiui, BERT arba GPT-2, sėkmė keliose užduotyse yra gerai žinoma, tačiau taip nėra duomenų ir tekstų kūrimo užduočių atveju, o tik neseniai tam skirtos iniciatyvos. Tokiu būdu mes tiriame, kaip iš anksto parengtas modelis (GPT-2) atlieka UD-to-text generacijos užduotį. Apskritai pasiekti rezultatai buvo prasti, tačiau reikia išnagrinėti keletą įdomių idėjų. Among the learned lessons we may note that it is necessary to study strategies to represent UD inputs and to introduce structural knowledge into these pre-trained models.', 'kk': 'Бұл қағаз S. ao Paulo/Brazil университетінің NILC компьютерлік лингвистикалық зерттеу тобының 2- ші (жабылған ішкі жолы) Ағылшын тілігіне (жабылған) Жерфейс Реализациясы 2020 жылы ортақ тапсырмасында жіберілген жұмыс Бірнеше тапсырмаларда BERT не GPT-2 секілді бірнеше оқылған үлгілердің сәттілігі, бірақ бұл деректер мен мәтін құру тапсырмаларын жасау үшін емес және соңғы уақытта бірнеше инициативаларды көздеген. Бұл үшін біз UD- ден мәтін құру тапсырмасының алдын- оқылған моделі (GPT- 2) қалай істейді. Жалпы нәтижелер керек болды, бірақ зерттеу үшін кейбір қызықты идеялар бар. Біз оқылған сыныптардың арасында, UD енгізімін көрсету стратегияларды зерттеу және структуралық білімдерді бұл алдын- оқылған моделдерге келтіру керек.', 'it': "Questo articolo descrive la presentazione del gruppo di ricerca NILC Computational Linguistics dell'Università di S ao Paulo/Brasile alla traccia inglese 2 (sotto-traccia chiusa) al Surface Realisation Shared Task 2020. Il successo degli attuali modelli pre-formati come BERT o GPT-2 in diversi compiti è noto, tuttavia questo non è il caso delle attività di generazione dati-testo e solo recentemente alcune iniziative incentrate su di esso. In questo modo, esploriamo come un modello pre-addestrato (GPT-2) esegue l'attività di generazione UD-to-text. In generale, i risultati raggiunti sono stati scarsi, ma ci sono alcune idee interessanti da esplorare. Tra le lezioni apprese possiamo notare che è necessario studiare strategie per rappresentare gli input UD e introdurre conoscenze strutturali in questi modelli pre-formati.", 'ml': 'ഈ പത്രത്തില്\u200d എന്\u200dഎല്\u200dസി കണക്കാക്കുന്ന ലിങ്ഗിസ്റ്റിക്സ് പഠിപ്പിക്കുന്ന കൂട്ടത്തില്\u200d നിന്ന് നിര്\u200dദേശിക്കുന്നത് എസ്- ഓ പാളോ/ബ്രാസീലിലേക്ക The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, however, this is not the case for data-to-text generation tasks and just recently some initiatives focused on it.  ഇങ്ങോട്ട് ഞങ്ങള്\u200d പരിശീലിക്കുന്ന ഒരു മോഡല്\u200d (ജിപിടി-2) യുഡി-ലേക്ക് ടെക്സ്റ്റ് തലമുറയുടെ ജോലിയില്\u200d എങ്ങനെ പ്രവര്\u200d പൊതുവായി, സമ്പാദിച്ചതിന്റെ ഫലങ്ങള്\u200d ദരിദ്രനായിരുന്നു, പക്ഷെ പരിശോധിക്കാന്\u200d കുറച്ച് രസകരമായ ആശയങ്ങളു പഠിച്ച പാഠങ്ങളില്\u200d ഉഡി ഇന്\u200dപുട്ടുകള്\u200d പ്രതിനിധിപ്പിക്കുന്നതിനായി പഠിക്കുന്ന പദ്ധതികള്\u200d പഠിപ്പിക്കുന്നതും ഈ മുന്\u200dപരി', 'mk': 'Овој весник го опишува поднесувањето на истражувачката група на НИЛК за компјутационална лингвистика на Универзитетот на С. ао Пауло/Бразил на англиската трака 2 (затворена подтрака) на заедничката задача за реализација на површината 2020 година. Успехот на актуелните предобучени модели како BERT или GPT-2 во неколку задачи е добро познат, но ова не е случај за задачите на генерација на податоци до текст и само неодамна некои иницијативи фокусирани на тоа. На овој начин, ние истражуваме како предобучен модел (ГПТ-2) функционира на задачата на генерација од УД до текст. Генерално, постигнатите резултати беа лоши, но постојат некои интересни идеи за истражување. Помеѓу научените лекции можеме да забележиме дека е неопходно да се проучуваат стратегии за претставување на влозите на УД и да се воведе структурно знаење во овие предобучени модели.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni mill-grupp ta’ riċerka dwar il-Lingwistika Komputazzjonali tal-NILC tal-Università ta’ S ° ao Paulo/Brażil lill-English Track 2 (sub-track magħluqa) fil-Surface Realisation Shared Task 2020. Is-suċċess tal-mudelli attwali mħarrġa minn qabel bħall-BERT jew il-GPT-2 f’diversi kompiti huwa magħruf sew, madankollu, dan mhuwiex il-każ għall-kompiti ta’ ġenerazzjoni tad-dejta għat-test u reċentement xi inizjattivi ffukati fuqu. B’dan il-mod, nistudjaw kif mudell imħarreġ minn qabel (GPT-2) iwettaq il-kompitu ta’ ġenerazzjoni UD għal test. In general, the achieved results were poor, but there are some interesting ideas to explore.  Among the learned lessons we may note that it is necessary to study strategies to represent UD inputs and to introduce structural knowledge into these pre-trained models.', 'ms': 'This paper describes the submission by the NILC Computational Linguistics research group of the University of S  ao Paulo/Brazil to the English Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020.  The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, however, this is not the case for data-to-text generation tasks and just recently some initiatives focused on it.  Dengan cara ini, kita mengeksplorasi bagaimana model pra-dilatih (GPT-2) berfungsi pada tugas generasi UD-ke-teks. Secara umum, hasil yang dicapai adalah buruk, tetapi terdapat beberapa idea menarik untuk mengeksplorasi. Di antara pelajaran yang telah dipelajari, kita mungkin memperhatikan bahawa perlu mempelajari strategi untuk mewakili input UD dan untuk memperkenalkan pengetahuan struktur ke dalam model yang telah dilatih.', 'no': 'Denne papiret beskriver tillegget av NILC Computational Linguistics Research Group i Universiteten S. ao Paulo/Brazil til engelsk spor 2 (lukka underspor) på surfaces Realisation Shared Task 2020. Dette er likevel kjent til at det gjeldande først trengte modellen som BERT eller GPT-2 i fleire oppgåver er godt kjent, men dette er ikkje tilfellet for oppgåver som genererar data-to-text og berre nyleg nokre oppgåver fokuserte på det. Denne måten utforskar vi korleis ein føretrained modell utfører på UD- til- tekstoppgåva. Generelt var resultatene fattige, men det er nokre interessante idear å utforske. I lærte leksjonane kan vi merke på at det er nødvendig å studera strategiar for å representera UD-inndata og introdusera strukturære kunnskap i desse føretrainerte modelane.', 'mn': 'Энэ цаас НИЛС Компьютерийн Лингистик судалгааны багийны дараа S-Ао Пауло/Бразилийн Их Сургуулиудын Англи хэлбэрт 2-р (нэвтрэгдсэн) газрын зургийг харуулж байна. БЕРТ эсвэл GPT-2 шиг одоогийн дасгал сургалтын загварын амжилт олон ажил дээр маш сайн мэддэг. Гэхдээ энэ нь өгөгдлийн болон текст бүтээлтийн ажлын тухай биш. Саяхан зарим инициативууд нь үүнд төвлөрсөн. Иймээс бид UD-ээс текст бүтээлийн даалгаврыг хэрхэн хөгжүүлэхийг судалж байна. Эцэст нь, амжилттай үр дүнд ядуу байсан ч судлах зарим сонирхолтой санаанууд байдаг. Сургуулсан хичээлийн дунд бид UD өгөгдлийг илэрхийлэх стратегийг судалж, бүтэц мэдлэг эдгээр сургалтын өмнө сургалтын загвар руу илэрхийлэх хэрэгтэй гэдгийг анзаарч болно.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie przez grupę badawczą NILC Computational Linguistics Uniwersytetu w S ao Paulo/Brazylii do ścieżki angielskiej 2 (podścieżka zamknięta) w ramach wspólnego zadania realizacji powierzchni 2020. Sukces obecnych wstępnie przeszkolonych modeli, takich jak BERT czy GPT-2 w kilku zadaniach jest dobrze znany, jednak nie dotyczy to zadań generowania danych do tekstu, a dopiero ostatnio niektóre inicjatywy skupiają się na tym. W ten sposób badamy, jak wstępnie przeszkolony model (GPT-2) wykonuje zadanie generowania UD-do-tekstu. Ogólnie rzecz biorąc, osiągnięte wyniki były słabe, ale istnieje kilka ciekawych pomysłów do zbadania. Wśród wyciągniętych wniosków możemy zauważyć, że konieczne jest studiowanie strategii reprezentowania wejść UD oraz wprowadzenie wiedzy strukturalnej do tych wstępnie przeszkolonych modeli.', 'ro': 'Această lucrare descrie prezentarea de către grupul de cercetare NILC Computational Linguistics al Universității din S ao Paulo/Brazilia la pista engleză 2 (subpista închisă) la sarcina partajată de realizare a suprafeței 2020. Succesul actualelor modele pre-instruite precum BERT sau GPT-2 în mai multe sarcini este bine cunoscut, cu toate acestea, acest lucru nu este cazul sarcinilor de generare date-text și doar recent unele inițiative axate pe aceasta. În acest fel, explorăm modul în care un model pre-instruit (GPT-2) efectuează activitatea de generare UD-to-text. În general, rezultatele obținute au fost slabe, dar există câteva idei interesante de explorat. Printre lecțiile învățate putem observa că este necesar să se studieze strategii pentru a reprezenta intrările UD și să se introducă cunoștințe structurale în aceste modele pre-instruite.', 'sr': 'Ovaj papir opisuje podnošenje istraživačke grupe za računalne lingwistike NILC Univerziteta S ao Paulo/Brazila na engleski trag 2 (zatvoren podtrag) na delnom zadatku za realizaciju površine 2020. Uspjeh trenutnih predobučenih modela poput BERT ili GPT-2 u nekoliko zadataka je dobro poznat, međutim, to nije slučaj za zadatak generacije podataka do teksta i nedavno su se fokusirali na nju neke inicijative. Ovako istražujemo kako predobučeni model (GPT-2) radi na zadatku generacije UD-to-teksta. Generalno, postignuti rezultati su bili siromašni, ali postoje zanimljive ideje za istraživanje. Među naučenim lekcijama možemo primjetiti da je potrebno proučavati strategije za predstavljanje ulaganja UD-a i uvesti strukturno znanje u te predobučene modele.', 'sv': 'Denna uppsats beskriver inlämningen av NILC Computational Linguistics forskargrupp vid universitetet i S ao Paulo/Brasilien till engelska spår 2 (sluten delspår) vid Surface Realisation Shared Task 2020. Framgången för de nuvarande förkunskaperade modellerna som BERT eller GPT-2 i flera uppgifter är välkänd, men detta är inte fallet för data-till-text-genereringsuppgifter och bara nyligen några initiativ inriktade på det. På så sätt undersöker vi hur en förintränad modell (GPT-2) presterar på UD-till-text-genereringsuppgiften. Generellt sett var de uppnådda resultaten dåliga, men det finns några intressanta idéer att utforska. Bland de lärdomar vi lärt oss kan vi notera att det är nödvändigt att studera strategier för att representera UD input och att introducera strukturell kunskap i dessa pre-utbildade modeller.', 'so': 'Kanu warqaddan waxaa ka muuqata kooxda jaamacadda S/ ao Paulo/Brazil oo ku qoran kooxaha NILC Computational Linguistics Research Group of Universities S/ ao Paulo/Brazil to the Ingiriis Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020. Uguulaysta modellada horay loo tababariyey, sida BERT ama GPT-2 oo shaqooyin badan lagu sameeyo waa mid aad u yaqaan, habase yeeshee taasi ma aha xaalad ku saabsan shaqooyin macluumaad-u-qoraal sameynta iyo ugu dhowaad waxqabadyo ka mid ah oo uu ku kalsoonaaday. Sidan, waxaynu baarinaynaa sida model horay loo tababaray (GPT-2) u sameeyo shaqada UD-to-text-generation. Inta caadiga ah, arimaha la soo helay waxay ahaayeen miskiin, laakiin waxaa jira fikrada xiiso leh in la baadho. Waxbarashada lagu bartay waxaa ka mid ah in loo baahan yahay in lagu baro qorshaha lagu soo bandhigi karo qalabka UD iyo in loo soo bandhigi karo aqoonta aasaasiga ah modelladan horay loo tababaray.', 'ta': 'இந்த காகிதத்திற்கு மேல்முகத்தில் சேர்த்தல் திட்டத்தில் NILC கணிப்பிடிப்பு லிங்கிஸ்ட் ஆராய்ச்சி குழுவின் கூட்டத்தை குறிப்பிடுகிறது எஸ்- யோ ப The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, however, this is not the case for data-to-text generation tasks and just recently some initiatives focused on it.  இந்த வழியில், முன்பயிற்சிக்கப்பட்ட மாதிரி (GPT-2) UD-ல் இருந்து உரை உருவாக்கும் பணியில் எப்படி செயல்படுத்துகிறது என் பொதுவாக, முடிவுகள் ஏழைகளாக இருந்தன, ஆனால் ஆராய்ச்சியமான யோசனைகள் உள்ளன. முன் பயிற்சி மாதிரிகளை குறிப்பிடுவதற்கு UD உள்ளீடுகளை குறிப்பிட வேண்டிய திட்டங்களை படிக்க வேண்டும்', 'ur': 'This paper describes the submission by the NILC Computational Linguistics research group of the University of S ،ao Paulo/Brazil to the English Track 2 (closed sub-track) at the Surface Realization Shared Task 2020. بہت سی کاموں میں BERT یا GPT-2 کی موفقیت بہتر معلوم ہے، لیکن یہ ڈیٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ کے کاموں کے لئے نہیں ہے اور اچھے وقت اس پر کچھ اندازے ل اسی طرح ہم دیکھتے ہیں کہ UD-to-text generation task پر ایک پیش آموزش کی موڈل (GPT-2) کس طرح عمل کرتا ہے۔ عمومی طور پر، کامیاب نتائج فقیر تھے، لیکن exploration کے لئے کچھ دلچسپ اندازے ہیں۔ ہم یاد رکھتے ہیں کہ استراتژیکوں کی تعلیم کرنا ضرورت ہے کہ UD اینپوٹوں کی تعلیم کریں اور ان سے پہلے تعلیم کی مدل میں ساختار علم معلوم کریں۔', 'si': 'මේ පැත්තේ NILC පරීක්ෂණ ලින්ගිස්ටික් පරීක්ෂණා කණ්ඩායම් කණ්ඩායම් සම්පූර්ණයේ S  ආයෝ පෝලෝ/බ්\u200dරාජිලේ ඉංග්\u200dරීසි ට්\u200dරැක් 2 (ව BERT නැත්තම් GPT-2 වගේ ප්\u200dරධාන ප්\u200dරධානය කරපු මොඩේලන්ගේ සාර්ථකය හොඳින් දන්නවා, ඒත් මේක නෙමෙයි දත්ත පිළිබඳින් ප්\u200dරධානය කරපු වැඩේ ස මෙහෙම විදියට, අපි පරීක්ෂණය කරනවා කොහොමද ප්\u200dරීක්ෂණා කරලා තියෙන්නේ (GPT-2) UD-ට-ට-පාළුවන් පරීක්ෂණාව සාමාන්\u200dයයෙන්, ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප අපි දැනගන්න පුළුවන් ඉගෙනගන්න පුළුවන් විදියට UD ඇතුලට ප්\u200dරතිචාර කරන්න ප්\u200dරයෝජනය අවශ්\u200dය වෙනවා කියලා, ඒ වගේම මේ ප්\u200d', 'vi': 'Tờ giấy này mô tả sự đệ trình của nhóm nghiên cứu ngôn ngữ học NILC của University of S ao Paulo/Brazil đến đường ray Anh (con đường ngầm đóng kín) tại bộ mặt đất chia sẻ Nhiệm vụ 2020. Sự thành công của những mẫu được huấn luyện trước đây như BERT hay GPT-2 trong nhiều nhiệm vụ, tuy nhiên, không phải là trường hợp của các công việc truyền dữ liệu sang văn bản, và chỉ mới gần đây vài dự án được tập trung vào nó. Bằng cách này, chúng ta sẽ khám phá cách một mô hình được huấn luyện trước (GPT-2) thực hiện trong nhiệm vụ tạo từ UD-to-text. Nói chung, kết quả thành công không tốt, nhưng có vài ý tưởng thú vị cần khám phá. Trong những bài học đã học, chúng ta có thể thấy rằng cần phải nghiên cứu các chiến lược để đại diện cho các nội dung của UD và đưa kiến thức cấu trúc vào các mô hình được rèn luyện trước.', 'uz': "Бу саҳифа S. ao Paulo/Brazil Universitetdagi NILC Computational Linguistics research guruhi o'zgarishni 2020-yilda birlashtirilgan vazifani o'rganishga o'rganish 2 (o'qishni yopish tugmasi) yaratadi. The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, however, this is not the case for data-to-text generation tasks and just recently some initiatives focused on it.  Bu yerda, biz UD-to-matn yaratish vazifasida oldin o'rganilgan model (GPT-2) qanday bajarishini aniqlamiz. Umumiy bo'lgan natijalar faqat yo'q edi, lekin qiziqarli g'oyalar bor. Bu o'rganilgan o'rganishlardan o'rganadigan o'rganadigan o'rganishda, UD yozuvlarini tahrirlash imkoniyatlarini o'rganish kerak va o'rganishdan oldin o'rganilgan modellarni o'rganish kerak.", 'bg': 'Настоящата статия описва представянето на изследователската група по компютърна лингвистика на Университета в Сао Пауло/Бразилия на английската песен 2 (затворена подпис) в споделената задача за реализация на повърхността 2020. Успехът на настоящите предварително обучени модели като BERT или GPT-2 в няколко задачи е добре известен, но това не е случаят с задачите за генериране на данни към текст и наскоро някои инициативи, насочени към него. По този начин изследваме как един предварително обучен модел (GPT-2) изпълнява задачата за генериране на UD към текст. Като цяло постигнатите резултати бяха лоши, но има някои интересни идеи, които трябва да се изследват. Сред извлечените поуки можем да отбележим, че е необходимо да се изучават стратегии за представяне на входящите данни и да се въведат структурни знания в тези предварително обучени модели.', 'da': 'Denne artikel beskriver indsendelsen af NILC Computational Linguistics forskningsgruppe ved University of S ao Paulo/Brasilien til det engelske spor 2 (lukket sub-track) på Surface Realisation Shared Task 2020. Succesen med de nuværende præuddannede modeller som BERT eller GPT-2 i flere opgaver er velkendt, men dette er ikke tilfældet med data-til-tekst generering opgaver og for nylig nogle initiativer fokuseret på det. På denne måde undersøger vi, hvordan en prætrænet model (GPT-2) udfører sig på UD-til-tekst generationsopgaven. Generelt var de opnåede resultater dårlige, men der er nogle interessante ideer at undersøge. Blandt de lærte erfaringer kan vi bemærke, at det er nødvendigt at studere strategier til at repræsentere UD input og at introducere strukturel viden i disse præuddannede modeller.', 'nl': 'Deze paper beschrijft de inzending door de onderzoeksgroep NILC Computational Linguistics van de Universiteit van S ao Paulo/Brazilië aan het Engels Track 2 (gesloten subtrack) bij de Surface Realisation Shared Task 2020. Het succes van de huidige voorgetrainde modellen zoals BERT of GPT-2 in verschillende taken is bekend, maar dit is niet het geval voor data-to-text generatietaken en onlangs zijn er enkele initiatieven op gericht. Op deze manier onderzoeken we hoe een vooraf getraind model (GPT-2) presteert op de UD-naar-tekst generatie taak. Over het algemeen waren de behaalde resultaten slecht, maar er zijn enkele interessante ideeën te verkennen. Onder de geleerde lessen kunnen we opmerken dat het noodzakelijk is om strategieën te bestuderen om UD inputs weer te geven en structurele kennis in deze voorgetrainde modellen te introduceren.', 'de': 'Dieser Beitrag beschreibt die Einreichung der NILC Computational Linguistics Forschungsgruppe der Universität von S ao Paulo/Brasilien zum Englischen Track 2 (geschlossener Teilabschnitt) im Rahmen der Surface Realisation Shared Task 2020. Der Erfolg der derzeitigen vortrainierten Modelle wie BERT oder GPT-2 in mehreren Aufgaben ist bekannt, dies ist jedoch nicht der Fall für Daten-zu-Text-Generierungsaufgaben und erst kürzlich konzentrierten sich einige Initiativen darauf. Auf diese Weise untersuchen wir, wie ein vortrainiertes Modell (GPT-2) bei der UD-zu-Text-Generierungsaufgabe funktioniert. Im Allgemeinen waren die erzielten Ergebnisse schlecht, aber es gibt einige interessante Ideen zu erkunden. Unter den gelernten Lektionen können wir feststellen, dass es notwendig ist, Strategien zu studieren, um UD Inputs darzustellen und strukturelles Wissen in diese vortrainierten Modelle einzuführen.', 'id': 'Kertas ini menjelaskan pengiriman oleh kelompok penelitian Linguistik Komputasi NILC dari Universitas S ° ao Paulo/Brazil ke Trek Inggris 2 (sub-trek tertutup) di Surface Realisation Shared Task 2020. Sukses dari model prapelatih saat ini seperti BERT atau GPT-2 dalam beberapa tugas yang dikenal, bagaimanapun, ini bukan kasus untuk tugas generasi data-ke-teks dan baru-baru ini beberapa inisiatif fokus padanya. Dengan cara ini, kita mengeksplorasi bagaimana model prapelatih (GPT-2) melakukan tugas generasi UD-to-text. Secara umum, hasil yang dicapai adalah buruk, tapi ada beberapa ide yang menarik untuk dieksplorasi. Di antara pelajaran yang kita pelajari, kita mungkin memperhatikan bahwa perlu mempelajari strategi untuk mewakili masukan UD dan untuk memperkenalkan pengetahuan struktur ke dalam model yang sudah dilatih ini.', 'fa': 'این کاغذ توسط گروهی تحقیقات لینگ\u200cاستیک کامپیوتری NILC از دانشگاه S آئو پائولو/برزیل به ترک ۲ انگلیسی (زیر ترک بسته) در کار مشترک سطح\u200cسازی ۲۰۰۲ توصیف می\u200cکند. موفقیت مدلهای پیش آموزش شده جاری مانند BERT یا GPT-2 در چند وظیفه خوب شناخته می\u200cشود، ولی این پرونده برای وظیفه\u200cهای تولید داده\u200cها و متن نیست و تازگی چند فعالیت روش تمرکز شده است. از این طریق، ما تحقیق می کنیم که چگونه یک مدل پیش آموزش شده (GPT-2) روی کار نسل UD-to-text انجام می\u200cدهد. در general, نتایج موفق شدن فقیر بودند، اما ایده های جالبی برای تحقیق وجود دارد. بین درس یاد گرفته می\u200cتوانیم یاد بگیریم که لازم است استراتژی\u200cها را مطالعه کنیم تا ورودهای UD را نمایش دهیم و دانش ساختاری را در این مدل پیش آموزش دهیم.', 'ko': '본고는 브라질 상파울루대학 NILC 계산언어학 연구팀이 2020년 서피스 리얼라이제이션 Shared Task(표면 구현 공유 임무)에 제출한 영어 제2 트랙(폐쇄 하위 트랙) 보고서를 기술한다.현재의 예비 훈련 모델(예를 들어 BERT나 GPT-2)이 여러 임무에서 성공한 것은 잘 알려져 있지만, 데이터에서 텍스트로 임무를 생성하는 상황은 그렇지 않다. 단지 최근의 일부 계획은 그것에 중점을 두었다.이런 방식을 통해 우리는 예비훈련모델(GPT-2)이 UD에서 텍스트 생성 임무를 어떻게 수행하는지 탐색했다.전체적으로 말하자면, 얻은 성과는 매우 나쁘지만, 여전히 약간의 흥미로운 생각들이 모색되어야 한다.경험과 교훈에서 우리는 UD 입력을 나타내는 전략을 연구하고 구조 지식을 이러한 사전 교육 모델에 도입할 필요가 있음을 알 수 있다.', 'hr': 'Ovaj papir opisuje podatke istraživačke skupine za računalne lingwistike NILC-a Univerziteta S „ao Paulo/Brazila na engleski trag 2 (zatvoren podtrag) na delnom zadatku za realizaciju površine 2020. Uspjeh trenutnih predobučenih modela poput BERT ili GPT-2 u nekoliko zadataka je dobro poznat, međutim, to nije slučaj za zadatak generacije podataka do teksta i nedavno su se fokusirali na njega neke inicijative. Ovako istražujemo kako predobučeni model (GPT-2) izvodi na zadatku generacije UD-to-teksta. Generalno, postignuti rezultati su bili siromašni, ali postoje zanimljive ideje za istraživanje. Među naučenim lekcijama možemo primjetiti da je potrebno proučavati strategije za predstavljanje ulaganja UD-a i uvesti strukturno znanje u te predobučene modele.', 'sw': 'Gazeti hili linaelezea ujumbe wa utafiti wa lugha za kompyuta ya NILC wa Chuo Kikuu cha S ) ao Paulo/Brazil kwa ajili ya Barabara la Kiingereza la 2 (kufungwa kwa njia ya chini) kwenye Idara ya Uhuru wa Surface ilishiriki kazi 2020. Mafanikio ya mifano ya sasa ya mafunzo kama BERT au GPT-2 katika kazi kadhaa inafahamika vizuri, hata hivyo, hii si suala la kazi za vizazi vya taarifa na hivi karibuni baadhi ya miradi yanayolenga. This way, we explore how a pre-trained model (GPT-2) performs on the UD-to-text generation task.  Kwa ujumla, matokeo yaliyofanikiwa yalikuwa masikini, lakini kuna wazo la kuvutia kuchunguza. Miongoni mwa masomo yaliyojifunza tunaweza kuona kwamba ni muhimu kusoma mkakati wa kuwakilisha vitu vya UD na kuweka maarifa ya ujenzi katika mifano haya ya awali iliyoendeshwa.', 'tr': 'Bu kagyz S  ao Paulo/Braziliýa Uniwersitetiň NILC Kompýuterler Lingüstikler barlag toparynyň 2-nji Iňlisçe Şablon 2-nji (ýapylan süýşik) surat Realization Beýleki Görevi 2020-nji ýylda bellenilýär. Aýry birnäçe işde BERT ýa GPT-2 ýaly öňünden öňünden bilinmiş nusgalaryň başarnygy ýok, ýöne bu data-täze metin döredilişi üçin däldir we olaryň üstine üns berilýän birnäçe girişimleri däldir. Bu şekilde, biz öňünden öňünden eğlenmiş bir nusga (GPT-2) UD-täze metin döredilmesinde nähili edip barýandygyny keşfetýäris. Adatça netijeler gazypdy, ýöne keşfedilmek üçin birnäçe gyzykly pikir bar. Öwrenmeli ders arasynda UD girişini temsil etmek we strukturel bilgileri bu öňünden öňünden öňünden bilim almak üçin stratejiýalary öwrenmek gerekli olduğunu düşünebiliriz.', 'af': "Hierdie papier beskrywe die onderskrywing deur die NILC Rekenaasjonale Linguistics-onderskrywing groep van die Universiteit van S ’ao Paulo/Brazil na die Engelske Snit 2 (gesluit subsnit) by die Surface Realisation Gedeelde Opdrag 2020. Die sukses van die huidige voorafgeleerde modele soos BERT of GPT-2 in verskeie opdragte is goed bekend, maar hierdie is nie die geval vir data-to-text generasie opdragte en net onlangs sommige iniciatiewe gefokus op dit nie. Hierdie manier, ons ondersoek hoe 'n voorafgevorderde model (GPT-2) uitvoer op die UD-na-teks generasie taak. Algemeen was die gevolg resultate arm, maar daar is 'n paar interessante idee om te ondersoek. onder die geleerde leksies kan ons opmerk dat dit nodig is om strategies te studeer om UD inputs te verteenwoordig en strukturele kennis in hierdie voorafgeleerde modele te introduseer.", 'sq': 'This paper describes the submission by the NILC Computational Linguistics research group of the University of S  ao Paulo/Brazil to the English Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020.  Suksesi i modeleve të tanishëm të paratrajnuar si BERT apo GPT-2 në disa detyra është i njohur mirë, megjithatë, kjo nuk është rasti për detyrat e gjenerimit të të dhënave në tekst dhe vetëm kohët e fundit disa nisma u përqëndruan në të. Kështu, ne eksplorojmë se si një model i trajnuar para (GPT-2) funksionon në detyrën e gjenerimit UD-në-tekst. Në përgjithësi, rezultatet e arritura ishin të dobëta, por ka disa ide interesante për të eksploruar. Midis mësimeve të mësuara ne mund të vëmë në dukje se është e nevojshme të studiohen strategjitë për të përfaqësuar hyrjet e UD dhe të futen njohuritë strukturore në këto modele të paratrajnuar.', 'bn': 'এই পত্রিকাটি বিশ্ববিদ্যালয়ের এনআইএলসি কম্পিউটিশনাল লিঙ্গিস্টিক্স গবেষণা গ্রুপের প্রতি উল্লেখ করেছে সার্ফেস রিয়েশন শেয়ার করা কাজ ২০২০-এ ইংরেজি ট্র বর্তমান প্রশিক্ষণের পূর্ব প্রশিক্ষিত মডেলের সফলতা বেশ কয়েকটি কাজে জিপিটি বা জিপিটি-২, তবে এটা ডাটা থেকে টেক্সট প্রজন্মের কাজের জন্য নয় এবং সম্প্রতি কি এইভাবে আমরা খুঁজে বের করি কিভাবে পূর্ব প্রশিক্ষিত মডেল (জিপিটি-২) UD-থেকে টেক্সট প্রজন্মের কাজে করে। সাধারণত অর্জনের ফলাফল দারিদ্র ছিল, কিন্তু কিছু মজার চিন্তা রয়েছে খুঁজে বের করতে। শিক্ষিত শিক্ষাগুলোর মধ্যে আমরা মনে করি যে ইউডি ইনপুটের প্রতিনিধিত্ব করার কৌশলগুলো পড়ার প্রয়োজন এবং এই পূর্ব প্রশিক্ষিত মডেলে কা', 'am': 'ይህ ገጽ የኢንILC ኮምፕዩተርቲክ የኢ.አ. ፓሎ/ባራዚል ዩንቨርስቲ የኢንግሊዘኛ መንገድ 2 (የታተመ ደብዳቤ-track) የተሰራጨውን ስራ 2020 የተባለው የኢንጂል መግለጫ ያሳያል፡፡ የአሁኑ ቀድሞ ተማርኮች ምሳሌዎች እንደ BERT ወይም GPT-2 በጥቂት ስራ ውስጥ የተማረኩ ናቸው፡፡ እንደዚህ መንገድ የፊተኛ ተማሪ model (GPT-2) UD-to-text ትውልድ ስራ እንዴት እንደሚሠራ እናውቃለን፡፡ በጠቅላላ የደረሰው ፍሬዎች ድሆች ናቸው ነገር ግን የሚያስፈልጋቸው አእምሮዎች አሉ፡፡ በተማሩት ትምህርት ውስጥ የዩዲ ጥያቄዎችን ለማስተካከል እና ወደዚህ አስቀድሞ ተማሪዎች ዓይነቶችን ማሳየት ያስፈልጋል፡፡', 'ca': "Aquest article descriu la presentació del grup de recerca NILC de Lingüística Computacional de la Universitat de S ° ao Paulo/Brasil al Track 2 anglès (subpista tancada) de la Task Compartida de Realització de la Superfície 2020. The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, however, this is not the case for data-to-text generation tasks and just recently some initiatives focused on it.  D'aquesta manera, explorem com un model pré-entrenat (GPT-2) funciona en la tasca de generació UD-text. En general, els resultats aconseguits eren pobres, però hi ha algunes idees interessants per explorar. Entre les lliçons aprengutes podem notar que és necessari estudiar estratègies per representar les entrades d'UD i introduir coneixements estructurals en aquests models pré-entrenats.", 'hy': 'This paper describes the submission by the NILC Computational Linguistics research group of the University of S  ao Paulo/Brazil to the English Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020.  Ներկայումս նախապատրաստված մոդելների հաջողությունը, ինչպիսիք են BER-ը կամ GPT-2-ը մի քանի խնդիրների ընթացքում, լավ հայտնի է, սակայն սա տեղեկատվություն-տեքստի ստեղծման խնդիրների դեպքում չէ, և վերջերս որոշ նախաձեռնություններ կենտրոնաց This way, we explore how a pre-trained model (GPT-2) performs on the UD-to-text generation task.  In general, the achieved results were poor, but there are some interesting ideas to explore.  Սովորված դասերի միջոցով մենք կարող ենք նկատել, որ անհրաժեշտ է ուսումնասիրել ռազմավարություններ, որոնք ներկայացնեն UD ներմուծները և ներկայացնեն կառուցվածքային գիտելիքներ այս նախապատրաստված մոդելների մեջ:', 'et': 'Käesolevas artiklis kirjeldatakse, kuidas S ao Paulo Ülikooli NILC arvutuslingvistika uurimisrühm esitas inglise keele rada 2 (suletud alamrada) pinna realiseerimise jagatud ülesandes 2020. Praeguste eelkoolitud mudelite, näiteks BERT või GPT-2 edukus mitmes ülesandes, on hästi teada, kuid see ei ole nii andmete loomise ülesannete puhul ja alles hiljuti on mõned sellele keskendunud algatused. Sel viisil uurime, kuidas eelkoolitud mudel (GPT-2) toimib UD-tekstiks genereerimise ülesandel. Üldiselt olid saavutatud tulemused kehvad, kuid on mõningaid huvitavaid ideid uurida. Saadud õppetundide hulgas võime märkida, et on vaja uurida strateegiaid, mis esindavad UD sisendeid ja tutvustavad struktuurseid teadmisi nendesse eelkoolituse mudelitesse.', 'az': 'Bu kağıt, S “ ao Paulo/Brazilya Universitetinin NILC Computational Linguistics Research Grubunun İngiliz Track 2 (kapalı sub-track) surətdə Realization Shared Task 2020 tərəfindən təbliğ edir. Həqiqətən, çoxlu işlərdə BERT və GPT-2 kimi təhsil edilmiş modellərin başarısızlığı çox yaxşı tanınmışdır, amma bu, data-to-text təhsil işləri üçün deyildir. Yalnız son zamanlarda bazı başlanğıçlar buna odaqlanır. Bəlkə, öyrənmiş modeli (GPT-2) UD-dən-mətn nəslində necə işlədiyini keşfetirik. Əslində başarılı sonuçlar yoxsulluq idi, amma keşfetmək üçün maraqlı fikirlər var. Öyrənmiş dərslərdən öyrəndiyimiz üçün UD inputlərini göstərmək və bu öyrənmiş modellərə strukturlu bilgiləri təsdiqləmək üçün strateji təhsil etmək lazımdır.', 'fi': 'Tässä artikkelissa kuvataan Brasilian yliopiston NILC Computational Linguistics -tutkimusryhmän esittämää englanninkielistä raitaa 2 (suljettu alaraita) Surface Realisation Shared Task 2020 -tapahtumassa. Nykyisten esikoulutettujen mallien, kuten BERT:n tai GPT-2:n, menestys useissa tehtävissä on tiedossa, mutta tämä ei ole totta datan ja tekstin tuottamisen tehtävissä ja vasta äskettäin joissakin siihen keskittyneissä aloitteissa. Tällä tavoin tutkimme, miten esikoulutettu malli (GPT-2) suoriutuu UD-to-text-generointitehtävässä. Yleisesti ottaen saavutetut tulokset olivat heikkoja, mutta mielenkiintoisia ideoita on tutkittava. Saaduista kokemuksista voidaan todeta, että on tarpeen tutkia strategioita UD-panosten esittämiseksi ja tuoda rakenteellista tietoa näihin esikoulutettuihin malleihin.', 'bs': 'Ovaj papir opisuje podnošenje grupe istraživanja kompjuterskih lingwistike NILC-a Univerziteta S i ao Paulo/Brazila na engleski trag 2 (zatvoren podtrag) na delnom zadatku za realizaciju površine 2020. Uspjeh trenutnih predobučenih modela poput BERT ili GPT-2 u nekoliko zadataka je dobro poznat, međutim, to nije slučaj za zadatak generacije podataka do teksta i nedavno su se fokusirali na njega neke inicijative. Ovako istražujemo kako predobučeni model (GPT-2) radi na zadatku generacije UD-to-teksta. Generalno, postignuti rezultati su bili siromašni, ali postoje zanimljive ideje za istraživanje. Među naučenim lekcijama možemo primjetiti da je potrebno proučavati strategije za predstavljanje ulaganja UD-a i uvesti strukturno znanje u te predobučene modele.', 'cs': 'Tento článek popisuje předlohu výzkumné skupiny NILC Computational Linguistics University of S ao Paulo/Brazílie na anglickou trať 2 (uzavřená podstopa) na Shared Task 2020 povrchové realizace. Úspěch současných předškolených modelů jako BERT nebo GPT-2 v několika úkolech je dobře známý, nicméně to není případ pro úkoly generování dat do textu a teprve v poslední době se na něj zaměřily některé iniciativy. Tímto způsobem zkoumáme, jak předškolený model (GPT-2) funguje při generování UD-textu. Obecně platí, že dosažené výsledky byly špatné, ale existují některé zajímavé nápady k prozkoumání. Mezi získané lekce lze poznamenat, že je nutné studovat strategie reprezentovat UD vstupy a zavést strukturální znalosti do těchto předškolených modelů.', 'he': 'העיתון הזה מתאר את ההעברה על ידי קבוצת מחקר לינגסטיקה מחשבית NILC של האוניברסיטה של S · ao Paulo / ברזיל למסלול אנגלי 2 (תחת-מסלול סגור) במשימה המשותפת של השטח 2020. ההצלחה של המודלים המאמנים הנוכחים כמו BERT או GPT-2 בכמה משימות ידועה היטב, עם זאת, זה לא המקרה עבור משימות דורת נתונים לטקסט ורק לאחרונה כמה מיזמות ממוקדות עליה. בדרך זו, אנו חוקרים איך מודל מאומן מראש (GPT-2) מבצע על משימה של דור UD-לטקסט. באופן כללי, התוצאות השיגות היו עניות, אבל יש כמה רעיונות מעניינים לחקור. Among the learned lessons we may note that it is necessary to study strategies to represent UD inputs and to introduce structural knowledge into these pre-trained models.', 'sk': 'Ta prispevek opisuje predložitev raziskovalne skupine NILC za računalniško jezikoslovje Univerze v S. Paulu/Braziliji na angleški sled 2 (zaprta podsled) v okviru skupne naloge uresničevanja površin 2020. Uspeh sedanjih vnaprej usposobljenih modelov, kot sta BERT ali GPT-2, pri več nalogah je dobro znan, vendar to ne velja za naloge ustvarjanja podatkov v besedilo in šele pred kratkim so se nanj osredotočile nekatere pobude. Na ta način raziskujemo, kako usposobljen model (GPT-2) deluje pri opravilu ustvarjanja UD-v-besedilo. Na splošno so bili doseženi rezultati slabi, vendar je treba raziskati nekaj zanimivih idej. Med pridobljenimi izkušnjami lahko ugotovimo, da je treba preučiti strategije za predstavitev vložkov UD in vključiti strukturno znanje v te vnaprej usposobljene modele.', 'ha': "Wannan karatun describes the Sub-trace by the NILC Computation Linguistics research group of the University of S/ ão Paulo/brazil to the English Track 2 (rufated sub-trace) at the Surface real Shared Takar 2020. Tsarin shiryoyin ayuka da aka sani yanzu a gabã ɗaya kamar BERT ko GPT-2 cikin wasu aikin daban, kuma amma, wannan bã jarraba ba ga aikin data-zuwa-text kuma a yanzu, akwai wasu shiryoyi masu fokusa da shi. Kamar wannan, Munã jarraba yadda wata misalin ta yi aiki a kan aikin UD-zuwa-text (GPT-2). Jama'a, matsaran da suka samu sun kasance matalauci, kuma amma akwai wasu idãna mai amfani da su sami. Babu daga laƙin waɗanda aka sani, za mu tuna tuna cewa, ana buƙata a karanta kimatattu dõmin a ƙayyade masu tsari da UD kuma a shigar da ilmi na rubutu cikin waɗannan misãlai masu da aka yi wa zaman-danganta.", 'jv': 'Perintah iki rambaran kelompok nggawe barang NILC Perintah Linguistika sing nggawe Universite S  eo Pablo/Brazzal kanggo nganggo Trak 2 Inggris Perusahaan model sing sampeyan luwih-tolangkat gak bener, kaya BERT karo PPT-2 ning sampeyan sing dianggawe barang pengguna bantuan, tho, iki ora iso kelompok nggo sampeyan data-to-text ngon sampeyan mruput gak nggawe hasis mengko kuwi. Ngomongke iki, kita isih kelas piye model sing sampek banter (GNU T-2) iso nggawe barang nggawe sistem Ubek-to-text. Jeneng-jeneng, ditambah panjenengan langgar, njuk wis kelas ngono sing entuk sing apik sing arep nggawe. Genjer sampeyan kelas peduli sing paling kelas kuwi diangkat awak dhéwé kudu nggawe Sitteri kanggo nggambar inputs UT lan nggawe ngertuan ajeng structural diangkat model sing bisa pasar iki.', 'bo': 'This paper describes the submission by the NILC Computational Linguistics research group of the University of S  ao Paulo/Brazil to the English Track 2 (closed sub-track) at the Surface Realisation Shared Task 2020. The success of the current pre-trained models like BERT or GPT-2 in several tasks is well-known, but this is not the case for data-to-text generation tasks and just recently some initiatives focused on it. འདི་ལྟར། ང་ཚོས་ཀྱིས་སྔོན་འཛུགས་བྱས་པའི་མ་དབྱིབས(GPT-2)ཞིག་གིས་UD-to-text བཟོ་བྱ་རིམ་གྱི་ལས་ཀ་གནང་བ་ཅིག སྤྱིར་བཏང་གི་གྲུབ་འབྲས་མངོན་པོ་ཞིག་རེད། ཡིན་ནའང་སྐྱེས་པའི་བསམ་ཚུལ་གཞན་ཞིག་ཡོད་པས་བལྟ་བཤེ འུ་ཅག་གིས་སྔོན་གྲངས་སྒྲིག་འཛིན་གྱི་ནང་དུ་འཇུག་སྣོད་བྱེད་དགོས་པའི་གྲངས་རིག་གི་ནང་དུ་མཐོང་སྣང་བྱེད་དགོས་པ་ཡིན།'}
