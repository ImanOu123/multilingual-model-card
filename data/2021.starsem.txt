{'en': 'Can Transformer Language Models Predict Psychometric Properties?', 'fr': 'Les modèles de langage du transformateur peuvent-ils prédire les propriétés psychométriques', 'es': '¿Pueden los modelos de lenguaje transformador predecir propiedades psicométricas?', 'pt': 'Os modelos de linguagem do transformador podem prever propriedades psicométricas?', 'ar': 'هل يمكن لنماذج لغة المحولات أن تتنبأ بالخصائص السيكومترية؟', 'zh': '变压器言可以测心度性乎?', 'ja': 'トランスフォーマー言語モデルは心理測定特性を予測できますか？', 'hi': 'ट्रांसफॉर्मर भाषा मॉडल साइकोमेट्रिक गुणों की भविष्यवाणी कर सकते हैं?', 'ru': 'Могут ли трансформерные языковые модели предсказывать психометрические свойства?', 'ga': 'An féidir le Múnlaí Teanga Trasfhoirmeora Airíonna Síciméadracha a Thuar?', 'hu': 'A transzformátor nyelvi modellei megjósolhatják a pszichometriai tulajdonságokat?', 'el': 'Μπορούν τα μοντέλα γλώσσας μετασχηματιστών να προβλέψουν ψυχομετρικές ιδιότητες;', 'ka': 'შეიძლება ტრანფორმეტრის ენათის მოდელების განსაზღვრება სიქომეტრიკური განსაზღვრება?', 'it': 'I modelli linguistici dei trasformatori possono prevedere proprietà psicometriche?', 'lt': 'Ar kalbos modeliai gali numatyti psichometrines savybes?', 'kk': 'Тілді түрлендіру үлгілерінің психометриялық қасиеттері таңдай алады ба?', 'mk': 'Може ли трансформираните јазички модели да предвидат психометрички сопствености?', 'ml': 'ഭാഷ മോഡലുകള്\u200dക്ക് സൈക്കോമീറ്ററിക് ഗുണഗണങ്ങള്\u200d മാറ്റാന്\u200d കഴിയുമോ?', 'ms': 'Boleh Model Bahasa Penukar Prediksi Ciri-ciri Psikometrik?', 'mt': 'Can Transformer Language Models Predict Psychometric Properties?', 'mn': 'Холны шилжүүлэгч загварууд психометрийн шинж чанарыг төсөөлж чадах уу?', 'pl': 'Czy transformatorowe modele językowe mogą przewidywać właściwości psychometryczne?', 'no': 'Kan transformera språk- modeller forhåndsvisa psykometriske eigenskapar?', 'sr': 'Može li transformatorski jezik modeli predviđati psiholometrijske vlasništvo?', 'ro': 'Modelele lingvistice transformatorului pot prezice proprietățile psihometrice?', 'si': 'භාෂාව ප්\u200dරවර්තනය කරන්න පුළුවන්ද පිසිකෝමීට්\u200dරික විශේෂතාවක් ප්\u200dරවර්තනය කරන්න?', 'so': 'Isticmaalka dhimirka miyaa u hormari kara qaababka afka?', 'sv': 'Kan transformatorspråkmodeller förutse psykometriska egenskaper?', 'ta': 'மொழி மாற்ற மாதிரிகள் முன்னுரிமை மாற்ற முடியுமா?', 'ur': 'تبدیل کرنے کی زبان موڈلز روانشنی ویژگی کا مقرر کر سکتے ہیں؟', 'uz': 'Tilni tarjima qilishni istaysizmi?', 'vi': 'Chế độ biến hình Ngôn ngữ có khả năng đo hồ sơ?', 'hr': 'Može li modeli transformera jezika predviđati psiholometrijske vlasti?', 'nl': 'Kunnen Transformer Taalmodellen psychometrische eigenschappen voorspellen?', 'de': 'Können Transformer Language Models psychometrische Eigenschaften vorhersagen?', 'bg': 'Могат ли трансформаторните езикови модели да предсказват психометрични свойства?', 'da': 'Kan transformatorsprogmodeller forudsige psykometriske egenskaber?', 'ko': 'Transformer 언어 모델은 심리 측정학적 특성을 예측할 수 있습니까?', 'fa': 'می\u200cتواند مدل\u200cهای زبان تغییر دهنده ویژه\u200cهای روانشناسی را پیشنهاد کند؟', 'sw': 'Je, Modeli za Kiafgha za Tafsiri zinaweza Tamko Tafsiri za Kipsychometric?', 'af': 'Kan Transformer Taal Modele voorskryf Psychometriese Eienskappe?', 'sq': 'Mund modelet e gjuhës Transformer të parashikojnë pronësitë psikometrike?', 'tr': 'Dil nusgala', 'hy': 'Can Transformer Language Models Predict Psychometric Properties?', 'az': 'Dil √únvan Modell…ôri Psikometrik Xass…ôl…ôrini √ñn-n…ôsih…ôt ed…ô bil…ôr?', 'am': 'የቋንቋ አናቶች ምርጫዎች', 'bn': 'ভাষার মোডেল কি সাইকোমেট্রিক বৈশিষ্ট্যাবলী বৈশিষ্ট্য?', 'cs': 'Mohou transformátorové jazykové modely předvídat psychometrické vlastnosti?', 'ca': 'Els models de llenguatge transformadors poden predir propietats psicòmetriques?', 'bs': 'Može li modeli transformera jezika predviđati psiholometrijske vlasništvo?', 'et': 'Kas transformaatori keelemudelid suudavad ennustada psühhomeetrilisi omadusi?', 'fi': 'Voiko muuntajan kielimallit ennustaa psykometrisiä ominaisuuksia?', 'id': 'Bisakah Model Bahasa Transformer memprediksi Properti Psikometrik?', 'jv': 'Puwede Ngubah Ngubah Resolusi Layaran Perdiktuan Panjenengan', 'sk': 'Ali lahko transformatorski jezikovni modeli napovedujejo psihometrične lastnosti?', 'bo': 'འགྱུར་བརྗོད་པའི་སྐད་ཡིག་གཟུགས་རིས་སྔོན་འཛུགས་ཀྱི་རྣམ་པ།', 'ha': '@ action', 'he': 'האם דוגמני שפת המעברת יכולים לחזות תכונות פסיכומטריות?'}
{'en': 'Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired commonsense competencies. To better understand the degree to which LMs can be said to have certain linguistic reasoning skills, researchers are beginning to adapt the tools and concepts of the field of psychometrics. But to what extent can the benefits flow in the other direction? I.e., can LMs be of use in predicting what the psychometric properties of test items will be when those items are given to human participants? We gather responses from numerous human participants and LMs (transformer- and non-transformer-based) on a broad diagnostic test of linguistic competencies. We then use the responses to calculate standard psychometric properties of the items in the diagnostic test, using the human responses and the LM responses separately. We then determine how well these two sets of predictions match. We find cases in which transformer-based LMs predict psychometric properties consistently well in certain categories but consistently poorly in others, thus providing new insights into fundamental similarities and differences between human and LM reasoning.', 'es': 'Los modelos de lenguaje (LM) basados en transformadores continúan mejorando el rendimiento de vanguardia en las tareas de referencia de PNL, incluidas las tareas diseñadas para imitar las competencias de «sentido común» inspiradas en el ser humano. Para entender mejor el grado en que se puede decir que los LM tienen ciertas habilidades de razonamiento lingüístico, los investigadores están empezando a adaptar las herramientas y los conceptos del campo de la psicometría. Pero, ¿hasta qué punto pueden los beneficios fluir en la otra dirección? Es decir, ¿pueden los LM ser útiles para predecir cuáles serán las propiedades psicométricas de los elementos de prueba cuando esos elementos se entreguen a participantes humanos? Recopilamos respuestas de numerosos participantes humanos y LM (basados en transformadores y no transformadores) en una amplia prueba de diagnóstico de competencias lingüísticas. Luego utilizamos las respuestas para calcular las propiedades psicométricas estándar de los elementos en la prueba de diagnóstico, utilizando las respuestas humanas y las respuestas de ML por separado. Luego determinamos qué tan bien coinciden estos dos conjuntos de predicciones. Encontramos casos en los que los LM basados en transformadores predicen las propiedades psicométricas consistentemente bien en ciertas categorías, pero consistentemente mal en otras, lo que proporciona nuevos conocimientos sobre las similitudes y diferencias fundamentales entre el razonamiento humano y el LM.', 'ar': 'تستمر نماذج اللغة المستندة إلى المحولات (LMs) في تطوير أداء متطور في مهام قياس البرمجة اللغوية العصبية ، بما في ذلك المهام المصممة لتقليد الكفاءات "المنطقية" المستوحاة من الإنسان. من أجل فهم أفضل للدرجة التي يمكن أن يقال فيها أن لدى LM مهارات تفكير لغوية معينة ، بدأ الباحثون في تكييف أدوات ومفاهيم مجال القياس النفسي. ولكن إلى أي مدى يمكن أن تتدفق الفوائد في الاتجاه الآخر؟ أي ، هل يمكن أن تكون LM مفيدة في التنبؤ بالخصائص السيكومترية لعناصر الاختبار عندما تُعطى هذه العناصر لمشاركين بشريين؟ نقوم بجمع الردود من العديد من المشاركين البشريين و LMs (المحولات وغير القائمة على المحولات) على اختبار تشخيصي واسع للكفاءات اللغوية. ثم نستخدم الردود لحساب الخصائص السيكومترية القياسية للعناصر في الاختبار التشخيصي ، باستخدام الاستجابات البشرية واستجابات LM بشكل منفصل. ثم نحدد مدى تطابق هاتين المجموعتين من التوقعات. نجد الحالات التي تتنبأ فيها LM المستندة إلى المحولات بخصائص القياس النفسي بشكل جيد باستمرار في فئات معينة ولكن بشكل ضعيف باستمرار في فئات أخرى ، مما يوفر رؤى جديدة لأوجه التشابه والاختلاف الأساسية بين المنطق البشري والمنطق LM.', 'pt': 'Modelos de linguagem baseados em transformadores (LMs) continuam a melhorar o desempenho de última geração em tarefas de benchmark de PNL, incluindo tarefas projetadas para imitar competências de “senso comum” inspiradas em humanos. Para entender melhor o grau em que se pode dizer que os LMs possuem certas habilidades de raciocínio linguístico, os pesquisadores estão começando a adaptar as ferramentas e conceitos do campo da psicometria. Mas até que ponto os benefícios podem fluir na outra direção? Ou seja, os LMs podem ser úteis para prever quais serão as propriedades psicométricas dos itens de teste quando esses itens forem dados a participantes humanos? Reunimos respostas de vários participantes humanos e LMs (baseados em transformadores e não transformadores) em um amplo teste de diagnóstico de competências linguísticas. Em seguida, usamos as respostas para calcular as propriedades psicométricas padrão dos itens no teste de diagnóstico, usando as respostas humanas e as respostas LM separadamente. Em seguida, determinamos quão bem esses dois conjuntos de previsões combinam. Encontramos casos em que LMs baseados em transformadores preveem propriedades psicométricas consistentemente bem em certas categorias, mas consistentemente mal em outras, fornecendo assim novos insights sobre semelhanças e diferenças fundamentais entre o raciocínio humano e o LM.', 'fr': "Les modèles de langage basés sur les transformateurs (LM) continuent de faire progresser les performances de pointe sur les tâches de référence de la PNL, y compris les tâches conçues pour imiter les compétences de «\xa0bon sens\xa0» inspirées par l'homme. Pour mieux comprendre dans quelle mesure on peut dire que les ML possèdent certaines compétences de raisonnement linguistique, les chercheurs commencent à adapter les outils et les concepts du domaine de la psychométrie. Mais dans quelle mesure les avantages peuvent-ils aller dans l'autre sens\xa0? C'est-à-dire, les ML peuvent-ils être utiles pour prédire quelles seront les propriétés psychométriques des items de test lorsque ces items seront donnés à des participants humains\xa0? Nous recueillons les réponses de nombreux participants humains et LM (basés sur des transformateurs et des non-transformateurs) sur un large test diagnostique des compétences linguistiques. Nous utilisons ensuite les réponses pour calculer les propriétés psychométriques standard des items du test de diagnostic, en utilisant séparément les réponses humaines et les réponses LM. Nous déterminons ensuite dans quelle mesure ces deux séries de prédictions correspondent. Nous trouvons des cas dans lesquels les ML basés sur des transformateurs prédisent les propriétés psychométriques de manière constante dans certaines catégories mais toujours mal dans d'autres, fournissant ainsi de nouvelles informations sur les similitudes et les différences fondamentales entre le raisonnement humain et le raisonnement LM.", 'zh': '盖转换器言模样(LM)续于NLP准试务先进之性,指象人之常识。 为善知LM于多大程度,可谓有言理,治人始适心测量学域之器名。 然益于多大程度可以别向乎? 曰:RM与人参与者,LM可以占测试项目之心乎? 集众参与者LM(,变压器非变压器)应,博试言语。 然后以应计中项目之心,各用人LM之应。 然后定两组之匹配。 吾见变压器之LM,一心相度,而终劣于人伦LM推理之本相似性异于新见也。', 'ru': 'Языковые модели, основанные на трансформаторах (LMS), продолжают улучшать современную производительность при выполнении контрольных задач NLP, включая задачи, предназначенные для имитации человеческих компетенций «здравого смысла». Чтобы лучше понять, в какой степени LMs, можно сказать, обладают определенными лингвистическими навыками мышления, исследователи начинают адаптировать инструменты и концепции в области психометрии. Но в какой степени выгоды могут течь в другом направлении? Т.е., могут ли LMs быть полезны в прогнозировании того, какими будут психометрические свойства тестовых предметов, когда эти предметы будут предоставлены участникам-человекам? Мы собираем ответы от многочисленных участников и LM (на основе трансформатора и нетрансформатора) на широкий диагностический тест лингвистических компетенций. Затем мы используем ответы для расчета стандартных психометрических свойств элементов в диагностическом тесте, используя человеческие ответы и ответы LM отдельно. Затем мы определяем, насколько хорошо совпадают эти два набора прогнозов. Мы находим случаи, в которых ЖМ на основе трансформаторов последовательно хорошо прогнозируют психометрические свойства в некоторых категориях, но последовательно плохо в других, тем самым предоставляя новые представления о фундаментальных сходствах и различиях между рассуждениями человека и ЖМ.', 'ja': '変圧器ベースの言語モデル（ LM ）は、人間にインスパイアされた「コモンセンス」コンピテンシーを模倣するように設計されたタスクを含む、NLPベンチマークタスクの最先端のパフォーマンスを進め続けている。 LMが特定の言語推論スキルを持つと言える程度をよりよく理解するために、研究者は心理測定の分野のツールと概念を適応させ始めている。 しかし、どの程度メリットが反対方向に流れることができますか？ すなわち、LMは、テスト項目が人間の参加者に与えられたときに、それらの項目の心理測定特性がどのようになるかを予測するのに役立ちますか？ 私たちは、言語能力の広範な診断テストで、多数の人間の参加者とLM （変圧器ベースと非変圧器ベース）から応答を収集します。 次に、ヒト応答とLM応答を別々に使用して、診断テストの項目の標準的な心理測定特性を計算するために応答を使用します。 これら2つの予測がどれだけ一致するかを決定します。 変圧器ベースのLMが、特定のカテゴリでは一貫して良好であるが、他のカテゴリでは一貫して不十分に心理測定特性を予測するケースを発見し、人間とLMの推論の間の根本的な類似点と違いについて新しい洞察を提供する。', 'hi': 'ट्रांसफॉर्मर-आधारित भाषा मॉडल (एलएम) एनएलपी बेंचमार्क कार्यों पर अत्याधुनिक प्रदर्शन को आगे बढ़ाना जारी रखते हैं, जिसमें मानव-प्रेरित "कॉमनसेंस" दक्षताओं की नकल करने के लिए डिज़ाइन किए गए कार्य शामिल हैं। उस डिग्री को बेहतर ढंग से समझने के लिए जिसके लिए एलएम को कुछ भाषाई तर्क कौशल कहा जा सकता है, शोधकर्ता साइकोमेट्रिक्स के क्षेत्र के उपकरणों और अवधारणाओं को अनुकूलित करना शुरू कर रहे हैं। लेकिन लाभ दूसरी दिशा में किस हद तक प्रवाहित हो सकता है? यानी, क्या एलएम का यह अनुमान लगाने में उपयोग किया जा सकता है कि परीक्षण वस्तुओं के साइकोमेट्रिक गुण क्या होंगे जब उन वस्तुओं को मानव प्रतिभागियों को दिया जाता है? हम भाषाई दक्षताओं के एक व्यापक नैदानिक परीक्षण पर कई मानव प्रतिभागियों और एलएम (ट्रांसफॉर्मर- और गैर-ट्रांसफॉर्मर-आधारित) से प्रतिक्रियाएं इकट्ठा करते हैं। फिर हम नैदानिक परीक्षण में वस्तुओं के मानक साइकोमेट्रिक गुणों की गणना करने के लिए प्रतिक्रियाओं का उपयोग करते हैं, मानव प्रतिक्रियाओं और एलएम प्रतिक्रियाओं का अलग से उपयोग करते हैं। फिर हम यह निर्धारित करते हैं कि भविष्यवाणियों के ये दो सेट कितनी अच्छी तरह से मेल खाते हैं। हम ऐसे मामलों को पाते हैं जिनमें ट्रांसफॉर्मर-आधारित एलएम कुछ श्रेणियों में साइकोमेट्रिक गुणों की लगातार अच्छी तरह से भविष्यवाणी करते हैं, लेकिन दूसरों में लगातार खराब होते हैं, इस प्रकार मानव और एलएम तर्क के बीच मौलिक समानता और अंतर में नई अंतर्दृष्टि प्रदान करते हैं।', 'ga': 'Leanann samhlacha teanga atá bunaithe ar chlaochladán (LManna) ag cur chun cinn feidhmíocht den scoth ar thascanna tagarmharcála NLP, lena n-áirítear tascanna atá deartha chun aithris a dhéanamh ar inniúlachtaí “comónta” arna spreagadh ag an duine. Chun tuiscint níos fearr a fháil ar a mhéid is féidir a rá go bhfuil scileanna áirithe réasúnaíochta teanga ag LManna, tá taighdeoirí ag tosú ar uirlisí agus coincheapa réimse na síciméadrachta a oiriúnú. Ach cé chomh mór agus is féidir na sochair a shreabhadh sa treo eile? I.e., an féidir le LManna a bheith úsáideach chun na hairíonna síciméadracha a bheidh ag míreanna tástála a thuar nuair a thugtar na míreanna sin do rannpháirtithe daonna? Bailímid freagraí ón iliomad rannpháirtithe daonna agus LManna (claochladán-bhunaithe agus neamh-chlaochladán) ar thástáil dhiagnóiseach leathan ar inniúlachtaí teanga. Bainimid úsáid ansin as na freagraí chun airíonna caighdeánacha síciméadracha na míreanna sa tástáil dhiagnóiseach a ríomh, ag baint úsáide as na freagraí daonna agus na freagraí LM ar leithligh. Cinnimid ansin cé chomh maith agus atá an dá thacar tuar seo ag teacht le chéile. Faighimid cásanna ina ndéanann LManna claochladán-bhunaithe a thuar airíonna síciméadracha go comhsheasmhach go maith i gcatagóirí áirithe ach go comhsheasmhach go dona i gcatagóirí eile, rud a thugann léargas nua ar chosúlachtaí agus difríochtaí bunúsacha idir réasúnaíocht dhaonna agus LM.', 'hu': 'A transzformátorok alapú nyelvi modellek továbbra is előmozdítják a legkorszerűbb teljesítményt az NLP referenciafeladatok terén, beleértve az ember által inspirált "közérzeti" kompetenciák utánzására irányuló feladatokat is. Annak érdekében, hogy jobban megértsék, milyen mértékben lehet elmondani, hogy az LM-ek milyen mértékben rendelkeznek bizonyos nyelvi érvelési készségekkel, a kutatók kezdik adaptálni a pszichometria területének eszközeit és fogalmait. De milyen mértékben áramlhatnak az előnyök a másik irányba? Vagyis hasznosak lehetnek-e az LM-ek annak megjósolására, hogy milyen pszichometriai tulajdonságok lesznek a teszteletek, amikor ezeket az elemeket emberi résztvevőknek adják? Számos emberi résztvevőtől és LM-től (transzformátor- és nem transzformátor alapú) választ gyűjtünk a nyelvi kompetenciák széles körű diagnosztikai tesztjén. Ezután a válaszokat használjuk a diagnosztikai teszt elemeinek standard pszichometriai tulajdonságainak kiszámítására, az emberi válaszok és az LM válaszok külön-külön felhasználásával. Ezután meghatározzuk, hogy ez a két jóslat mennyire egyezik. Olyan eseteket találunk, amikor a transzformátor alapú LM-k bizonyos kategóriákban következetesen jól előrejelzik a pszichometriai tulajdonságokat, másokban pedig következetesen rosszul, így új betekintést nyújtanak az emberi és LM érvelés közötti alapvető hasonlóságokra és különbségekre.', 'el': 'Τα γλωσσικά μοντέλα με βάση τους μετασχηματιστές συνεχίζουν να προάγουν τις επιδόσεις τελευταίας τεχνολογίας σε εργασίες αναφοράς, συμπεριλαμβανομένων των εργασιών που έχουν σχεδιαστεί για να μιμούνται τις ικανότητες "κοινής λογικής" εμπνευσμένες από τον άνθρωπο. Για να κατανοήσουν καλύτερα τον βαθμό στον οποίο μπορούν να ειπωθούν ότι έχουν ορισμένες γλωσσικές δεξιότητες συλλογισμού, οι ερευνητές αρχίζουν να προσαρμόζουν τα εργαλεία και τις έννοιες του τομέα της ψυχομετρίας. Αλλά σε ποιο βαθμό μπορούν τα οφέλη να ρέουν προς την άλλη κατεύθυνση; Δηλαδή, μπορούν να είναι χρήσιμα για να προβλέψουν ποιες θα είναι οι ψυχομετρικές ιδιότητες των αντικειμένων δοκιμής όταν αυτά τα αντικείμενα δοθούν σε ανθρώπους συμμετέχοντες; Συγκεντρώνουμε απαντήσεις από πολλούς ανθρώπους συμμετέχοντες και LM (με βάση μετασχηματιστή και μη μετασχηματιστή) σε μια ευρεία διαγνωστική δοκιμή γλωσσικών ικανοτήτων. Στη συνέχεια, χρησιμοποιούμε τις απαντήσεις για να υπολογίσουμε τις τυποποιημένες ψυχομετρικές ιδιότητες των στοιχείων της διαγνωστικής δοκιμής, χρησιμοποιώντας τις ανθρώπινες απαντήσεις και τις απαντήσεις των LM ξεχωριστά. Στη συνέχεια καθορίζουμε πόσο καλά ταιριάζουν αυτά τα δύο σύνολα προβλέψεων. Βρίσκουμε περιπτώσεις στις οποίες οι μετασχηματιστές προβλέπουν ψυχομετρικές ιδιότητες σταθερά καλά σε ορισμένες κατηγορίες αλλά σταθερά ανεπαρκείς σε άλλες, παρέχοντας έτσι νέες γνώσεις σχετικά με θεμελιώδεις ομοιότητες και διαφορές μεταξύ της ανθρώπινης και της λογικής.', 'ka': 'Name თუ უფრო უკეთესიდ გავიგეთ სიგრძე, რომელიც სიგრძელებული სიგრძელების რაოდენობების შესაძლებლობად, მსწავლობელი ფსიკომეტრიკას საფეხის ხელსაწყობილობის და კონცექტების მაგრამ რამდენი განმავლობა შეიძლება მეორე მხარეს გამოყენება? მაგალითად, LMs შეიძლება გამოიყენება თუ რა იქნება ტესტის ფსიკომეტრიკური განსაზღვრებების შესაძლებლობა, როდესაც ეს ელემენტები ადამიანის მოცემულებისთვის მომხმა ჩვენ მნიშვნელოვანი ადამიანის სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა და LMs (ტრან შემდეგ ჩვენ გამოყენებთ განსხვავებების სტანდარტული ფსიკომეტრიკური განსაზღვრებების გამოყენება დიაგონტიკური ტესტიში, ადამიანის განსხვავებების გამოყენება და LM განსხვავებების გან შემდეგ ჩვენ განვითარებთ რამდენია ეს ორი წარმოდგენების კონფიგურაცია. ჩვენ აღმოჩნეთ შემთხვევაში, რომლებიც ტრანფორმეტრის ბაზაციული LMs პროგრამეტრიკური განსაზღვრებაში კონსომეტრიკური განსაზღვრებულია განსაზღვრებულია განსაზღვრებულია განსაზღვრებულია, მაგრამ განსაზ', 'it': 'I modelli linguistici basati su trasformatori (LM) continuano a migliorare le prestazioni all\'avanguardia sui compiti di benchmark della PNL, compresi quelli progettati per imitare competenze di "buon senso" ispirate all\'uomo. Per comprendere meglio il grado in cui i LM possono essere detti di avere determinate capacità di ragionamento linguistico, i ricercatori stanno iniziando ad adattare gli strumenti e i concetti del campo della psicometria. Ma in che misura i benefici possono fluire nell\'altra direzione? Cioè, i LM possono essere utili per predire quali saranno le proprietà psicometriche degli elementi di prova quando questi elementi saranno dati ai partecipanti umani? Raccogliamo risposte da numerosi partecipanti umani e LM (basati su trasformatori e non trasformatori) su un ampio test diagnostico delle competenze linguistiche. Usiamo quindi le risposte per calcolare le proprietà psicometriche standard degli elementi nel test diagnostico, utilizzando le risposte umane e le risposte LM separatamente. Quindi determiniamo quanto bene queste due serie di previsioni coincidono. Troviamo casi in cui LM basati su trasformatori predicono le proprietà psicometriche costantemente bene in alcune categorie ma costantemente male in altre, fornendo così nuove intuizioni sulle somiglianze e differenze fondamentali tra il ragionamento umano e LM.', 'lt': 'Performuojant kalbų modelius toliau tobulinami naujausi NLP lyginamųjų užduočių rezultatai, įskaitant užduotis, skirtas imituoti žmogaus įkvėptas „bendrąsias“ kompetencijas. Siekiant geriau suprasti, kokiu mastu LM turi tam tikrų kalbinių motyvavimo įgūdžių, mokslininkai pradeda pritaikyti psichometrikos srities priemones ir koncepcijas. Bet kokiu mastu nauda gali tekti kitoje kryptimi? Taigi, ar LM gali būti naudinga prognozuojant, kokios bus bandomųjų objektų psichometrinės savybės, kai šie objektai bus duoti žmonėms? Daugelio žmonių ir LM (transformatorių ir ne transformatorių) atsakymai surenkami remiantis plačiu kalbinių gebėjimų diagnostiniu tyrimu. Tuomet naudojame atsakus, kad būtų apskaičiuotos standartinės diagnostinio tyrimo objektų psichometrinės savybės, naudojant žmogaus atsakus ir LM atsakus atskirai. We then determine how well these two sets of predictions match.  Rasime atvejus, kai transformatoriumi pagrįstos LM nuosekliai gerai prognozuoja psichometrines savybes tam tikrose kategorijose, bet nuosekliai blogai kitose, taip suteikiant naują supratimą apie esminius žmogaus ir LM motyvų panašumus ir skirtumus.', 'mk': "Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired 'commonsense' competencies.  За подобро да се разбере степенот до кој може да се каже дека ЛМ имаат одредени јазични размислувачки вештини, истражувачите почнуваат да ги адаптираат алатките и концептите на полето на психометриката. Но во каков степен може бенефициите да течат во друга насока? Или, може ли ЛМ да бидат корисни за предвидување на психометричните сопствености на тестираните предмети кога тие предмети ќе бидат дадени на човечките учесници? Собираме одговори од бројни човечки учесници и ЛМ (базирани на трансформатори и не трансформатори) на широк дијагностички тест на јазични способности. Потоа ги користиме одговорите за да ги пресметаме стандардните психометрични сопствености на предметите во дијагностичкиот тест, користејќи ги човековите одговори и LM одговорите одделно. Тогаш ќе одредиме колку добро се совпаѓаат овие два сета предвидувања. Најдовме случаи во кои трансформираните ЛМ предвидуваат психометрични сопствености константно добро во одредени категории, но константно лошо во други, со што обезбедуваме нови погледи за фундаменталните сличности и разлики помеѓу човечкото и ЛМ размислување.", 'kk': "Трансформациялық тіл үлгілері (LMs) NLP бақылау тапсырмаларының күй- жайындағы жұмыс істеуді жалғастыру үшін, мәліметті 'көпшілік' көмектесу үшін құрылған тапсырмаларды қоса алады. ЛМ-ның бір лингвистикалық тәжірибесі бар деп айтылатын градусын жақсы түсіну үшін зерттеушілер психометрикалық өрісінің құралдарын және концепцияларын адаптауға бастайды. Бірақ басқа бағытта қаншалық пайдаланулар бар? Мысалы, LMs- дер сынақ нысандарының психометриялық қасиеттері адам қатысушыларға берілген кезде не болады? Біз көптеген адам қатысушылардан және LMs (трансформациялық және трансформациялық емес) жауаптарды лингвистикалық көпшіліктердің көп диагностикалық сынақтарына жинақтаймыз. Содан кейін, диагностикалық сынақтағы нысандардың стандартты психометриялық қасиеттерін есептеу үшін, адамдардың жауаптарын және LM жауаптарын бөлек түрле есептеп қолданамыз. Содан кейін бұл екі бағдарламалардың қанша жақсы сәйкес келетінін анықтаймыз. Біз психометриялық қасиеттерді кейбір категорияларда тәуелді, бірақ басқаларға тәуелді тәуелді, сондықтан адам мен LM бағыттауларының негізгі ұқсастықтарына жаңа түсініктерді және түсініктерін көрсетеді.", 'ms': "Model bahasa berasaskan-Transformer (LMs) terus maju prestasi state-of-the-art pada tugas tanda referensi NLP, termasuk tugas yang direka untuk meniru kemampuan 'commonsense' inspirasi manusia. Untuk memahami lebih baik darjah yang mana LMs boleh dikatakan mempunyai keterampilan pemikiran bahasa tertentu, peneliti mula menyesuaikan alat dan konsep bidang psikometrik. Tetapi seberapa besar keuntungan boleh mengalir ke arah yang lain? Maksud saya, adakah LMs boleh digunakan untuk meramalkan apa sifat psikometrik objek ujian apabila benda-benda itu diberikan kepada peserta manusia? Kami mengumpulkan jawapan dari banyak peserta manusia dan LMs (pengubah- dan bukan-pengubah-berdasarkan) pada ujian diagnostik luas kompetensi bahasa. We then use the responses to calculate standard psychometric properties of the items in the diagnostic test, using the human responses and the LM responses separately.  Kemudian kita menentukan betapa baik kedua set ramalan ini sepadan. Kami mendapati kes-kes di mana LM berasaskan pengubah meramalkan ciri-ciri psikometrik secara konsisten dengan baik dalam kategori tertentu tetapi konsisten dengan buruk dalam yang lain, sehingga menyediakan pandangan baru kepada persamaan dasar dan perbezaan antara manusia dan LM alasan.", 'mt': 'Il-mudelli lingwistiċi bbażati fuq it-trasformaturi (LMs) ikomplu javvanzaw il-prestazzjoni l-aktar avvanzata fil-kompiti ta’ referenza tal-NLP, inklużi kompiti mfassla biex jimitikaw il-kompetenzi “komuni” ispirati mill-bniedem. Biex wieħed jifhem aħjar il-grad sa fejn jistgħu jingħataw ċerti ħiliet lingwistiċi ta’ raġunament, ir-riċerkaturi qed jibdew jadattaw l-għodod u l-kunċetti tal-qasam tal-psikometrika. But to what extent can the benefits flow in the other direction?  Jista’ jkun utli li l-LMs jipprevedu x’ser ikunu l-proprjetajiet psikometriċi tal-oġġetti tat-test meta dawk l-oġġetti jingħataw lill-parteċipanti umani? Aħna nġabru reazzjonijiet minn bosta parteċipanti umani u LMs (ibbażati fuq trasformaturi u mhux trasformaturi) fuq test dijanjostiku wiesa’ ta’ kompetenzi lingwistiċi. Imbagħad nużaw ir-risponsi biex nikkalkulaw il-proprjetajiet psikometriċi standard tal-oġġetti fit-test dijanjostiku, billi nużaw ir-risponsi umani u r-risponsi LM separatament. Imbagħad niddeterminaw kemm dawn iż-żewġ settijiet ta’ tbassir jaqblu tajjeb. Issibu każijiet fejn l-LMs ibbażati fuq it-trasformaturi jipprevedu l-proprjetajiet psikometriċi b’mod konsistenti tajjeb f’ċerti kategoriji iżda b’mod konsistenti ħażin f’oħrajn, u b’hekk jipprovdu fehmiet ġodda dwar similaritajiet u differenzi fundamentali bejn ir-raġunament tal-bniedem u l-LM.', 'no': 'Transformeringsspråk-modeller (LMs) fortsetter å framgå utviklinga av kunsttilstanden på NLP-benchmarkoppgåver, inkludert oppgåver som er utvikla til å imisera menneskelige «vanleg» kompetanser. For å bedre forstå kor grad LMs kan seiast å ha nokre språkstiske rasjonsverktøy, begynner forstørrar å tilpassa verktøya og konseptane for feltet psychometrisk. Men på kva måte kan fordelene flytte i den andre retninga? I tillegg kan LMs brukast i å forventa kva psychometriske eigenskapane til testelementa skal vera når dei vert gjeve til menneske deltakarar? Vi samler svar frå mange menneske deltakarar og LMs (transformeringsog ikkje-transformeringsbasert) på ein bred diagnostisk test av språkstiske kompetanser. Vi bruker derfor svara for å rekna ut standardspsychometriske eigenskapar for elementa i diagnostisk testen, med menneske svar og LM-svar separat. Vi bestemmer så kor godt desse to setta foregåver passar. Vi finn tilfeller som transformeringsbaserte LMs forventar psykometriske eigenskapar konsistent godt i enkelte kategoriar, men konsistent dårlig i andre, slik at det gjer nye innsyningar i grunnleggjande liknande og forskjeller mellom menneske og LM-rasjon.', 'ml': 'ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200dസ് ഭാഷ മോഡലുകള്\u200d (LMs) NLP ബെന്\u200dച്മാര്\u200dക്ക് ജോലികളില്\u200d സ്റ്റേറ്റ് ഓഫ്- ആര്\u200dട്ട് പ്രവര്\u200dത്തനങ്ങള്\u200d മുന്\u200dകൂട്ടുന്നുണ്ട്. മൈ കുറച്ച് ഭാഷ കാര്യങ്ങളുടെ കഴിവുകളുണ്ടെന്ന് എംഎസ് പറയുന്ന ഡിഗ്രിയില്\u200d കൂടുതല്\u200d മനസ്സിലാക്കാന്\u200d ശ്രമിക്കുന്നവര്\u200d സൈക്കോമീറ്റരിക്കിന്\u200d എന്നാല്\u200d മറ്റൊരു ദിശയത്തില്\u200d ഉപകരണങ്ങള്\u200dക്ക് എങ്ങനെ ഒഴുകാന്\u200d കഴിയും? ഐ,എ.എ.എ.എ.എ.എ.എ.എ.എസ് ഉപയോഗിക്കാന്\u200d കഴിയുമോ? പരീക്ഷിക്കുന്ന വസ്തുക്കളുടെ സൈക്കോമീറ്ററിക് ഗുണഗണങ്ങള്\u200d  മനുഷ്യരുടെ പങ്കാളികളില്\u200d നിന്നും LMs (മാറ്റം മാറ്റുന്നത്- മാറ്റങ്ങള്\u200d അടിസ്ഥാനമില്ലാത്ത മാറ്റങ്ങള്\u200dക്കും) നമ്മുടെ ഉത്തരങ്ങള്\u200d ഒരു വ പിന്നീട് നമ്മുടെ ഉത്തരങ്ങള്\u200d ഉപയോഗിക്കുന്നത് ഡിയോഗിസ്റ്റിക്ക് പരീക്ഷണത്തിലുള്ള വസ്തുക്കളുടെ സാധാരണ മൈക്കോമെറ്റിക്ക് ഗുണപ് പിന്നീട് ഈ രണ്ട് പ്രവചനങ്ങള്\u200d എത്ര നന്നായി പൊരുതുന്നുണ്ടെന്ന് നമുക്ക് തീരുമാനിക്കാം. നമുക്ക് കേസുകള്\u200d കണ്ടെത്താം, അവിടെ മാറ്റങ്ങള്\u200d അടിസ്ഥാനമാക്കുന്ന എല്\u200dമിസ് സൈക്കോമീറ്ററിക്ക് വ്യവസ്ഥകള്\u200d പ്രവചിക്കുന്നുണ്ട്. ചില വിഭാഗങ്ങളില്\u200d മാത്രമേ നല', 'pl': 'Modele językowe oparte na transformatorach (LM) nadal poprawiają najnowocześniejszą wydajność w zakresie zadań referencyjnych NLP, w tym zadań zaprojektowanych w celu naśladowania kompetencji "zdrowego rozsądku" inspirowanych człowiekiem. Aby lepiej zrozumieć stopień, w jakim LM można powiedzieć, że posiadają pewne umiejętności językowe rozumowania, naukowcy zaczynają dostosowywać narzędzia i koncepcje z dziedziny psychometrii. Ale w jakim stopniu korzyści mogą płynąć w innym kierunku? Czy LM mogą być użyteczne w przewidywaniu właściwości psychometrycznych przedmiotów testowych, gdy te przedmioty zostaną podane uczestnikom ludzkim? Zbieramy odpowiedzi licznych uczestników ludzkich i LM (opartych na transformatorach i nietransformatorach) na szerokim testie diagnostycznym kompetencji językowych. Następnie wykorzystujemy odpowiedzi do obliczania standardowych właściwości psychometrycznych elementów testu diagnostycznego, wykorzystując oddzielnie odpowiedzi ludzkie i odpowiedzi LM. Następnie określamy, jak dobrze te dwa zestawy przewidywań pasują. Znajdujemy przypadki, w których LM oparte na transformatorach konsekwentnie dobrze przewidują właściwości psychometryczne w niektórych kategoriach, ale konsekwentnie słabo w innych, zapewniając tym samym nowy wgląd w fundamentalne podobieństwa i różnice między rozumowaniem ludzkim a LM.', 'ro': 'Modelele lingvistice bazate pe transformatori (LM) continuă să avanseze performanțele de ultimă generație în ceea ce privește sarcinile de referință ale PNL, inclusiv sarcinile concepute pentru a imita competențele de "bun simț" inspirate de oameni. Pentru a înțelege mai bine gradul în care se poate spune că LM au anumite abilități de raționament lingvistic, cercetătorii încep să adapteze instrumentele și conceptele din domeniul psihometricii. Dar în ce măsură beneficiile pot circula în cealaltă direcție? Adică, pot fi folositoare LM-urile pentru a prezice care vor fi proprietățile psihometrice ale elementelor testate atunci când aceste elemente sunt date participanților umani? Colectăm răspunsuri de la numeroși participanți umani și LM (pe bază de transformator și non-transformator) pe un test larg de diagnosticare a competențelor lingvistice. Apoi folosim răspunsurile pentru a calcula proprietățile psihometrice standard ale elementelor din testul de diagnosticare, folosind răspunsurile umane și răspunsurile LM separat. Apoi determinăm cât de bine se potrivesc aceste două seturi de predicții. Găsim cazuri în care LM-urile bazate pe transformatori prezic în mod constant bine proprietățile psihometrice în anumite categorii, dar în mod constant slab în altele, oferind astfel noi perspective asupra similarităților fundamentale și diferențelor dintre raționamentul uman și LM.', 'sr': 'Modeli jezika koji su osnovani na transformaciji (LMs) nastavljaju da napreduju postupak umjetnosti na zadatkima NLP-a, uključujući zadatke dizajnirane za imitiranje ljudskih inspirisanih "zajedničkih smisla". Da bi bolje shvatili stepenicu kojoj se LGs može reæi da ima odreðene linguisticke razumne vještine, istraživači počinju da prilagođavaju alate i koncept polja psihoterije. Ali u kojoj mjeri koristi mogu teći u drugom smjeru? Mogu li LGs koristiti u predviđanju šta će psihoterijske vlasništva testnih predmeta biti kada se te predmete daju ljudskim sudionicima? Skupljamo odgovore od mnogih ljudskih učesnika i LMs (transformator-i-ne-transformator-baziranih) na širokom dijagnostičnom testu jezičkih kompetencija. Onda koristimo odgovore da računamo standardne psihoterijske vlasništvo predmeta u dijagnostičkom testu, koristeći ljudske odgovore i odgovore na LM odvojeno. Onda ćemo odrediti kako dobro odgovaraju ova dva seta predviđanja. Nalazimo slučajeve u kojima se transformacijski LMs predviđaju psiholometrijske vlasništvo u određenim kategorijama, ali konsekventno loše u drugima, tako pružajući nove uvjete u temeljne sličnosti i razlike između razmatranja ljudskih i LM.', 'so': "Tusaalada afka hore ee loo soo wareejiyay (LMs) waxay sii socotaa horumarinta xaaladda farshaxanta ah oo ku saabsan shaqooyinka bangiga ee NLP, kuwaas oo ku qoran shaqooyin lagu qoray awoodda u waxyooday dadka-soo-inspired-commonsense. Si aad ugu fiican u garan kartid shahaadada lagu sheegi karo in ay leeyihiin aqoonta luuqadda qaarkood, baaritaanka ayaa bilaabaya inay beddelaan qalabka iyo fikrada beerta dhimirka. Laakiin sidee bay faa'iidadu ugu socon karaan dhanka kale? Ma isticmaali karaa tusaale ahaan marka la siiyo waxyaabahaas dadka ka qayb qaata? Waxaan ka soo ururiyaa jawaabo ka mid ah dadka badan oo ka qayb qaata dadka iyo Ms (isbedelka- iyo isbedelka-bedelka) oo ku saabsan imtixaanka kala duduwan ee aqoonta luuqada. Markaas waxaynu isticmaalnaa jawaabaha si aan u xisaabinno tayada dhimirka caadiga ah ee alaabta, si aan ugu isticmaalno jawaabaha dadka iyo jawaabaha LM gooni ahaan. Markaas waxaynu go'aanno in labadan kooban ay u eg yihiin wax la sii sheego. Waxaynu helaynaa xaaladaha lagu beddelayo, taas oo ay ku sii dooranayaan hantida dhimirka ah oo si fiican u ah kooxo qaarkood, laakiin ugu sii liita qaarka kale, sababtaas darteed waxay ka dhigaan aragtida cusub isku mid ah iyo kala duwanaanshaha u dhexeeya sababta dadka iyo LM.", 'si': 'Name හොඳට තේරුම් ගන්න LMs ට කියන්න පුළුවන් විදිහට භාෂාවික විශ්වාස කරුණාවක් තියෙන්න, පරීක්ෂකයෝ පරීක්ෂකයෝ මානසිකා නමුත් අනිත් පැත්තට ප්\u200dරයෝජනය කොච්චර ප්\u200dරමාණය කරන්න පුළුවන්ද? ඉතින්, LMs පාවිච්චි කරන්න පුළුවන් විදිහට පරීක්ෂා අයිතියේ මානසික අයිතියෙන්ට දෙන්න පුළුවන්ද? අපි ගොඩක් මිනිස්සු සාමාන්\u200dයයෝ සහ LMs (වෙනස් කරනවා- සහ නොවෙනස් වෙනස් කරනවා) භාෂාත්මක සාමාන්තික පරීක්ෂණයේ විශාල පර අපි පස්සේ ප්\u200dරතිචාර ප්\u200dරතිචාරය පාවිච්චි කරන්න ප්\u200dරමාණයක් විශේෂ පරීක්ෂණයේ ස්ථානය මනුස්සුමීතික විශේෂතාවක ඊට පස්සේ අපි තේරුම් ගන්නේ මේ දෙන්න ප්\u200dරශ්නයක් කොච්චර හොඳයි කියලා. අපිට හොයාගන්න පුළුවන් වෙනස් විදියට පත්වෙන්න පුළුවන් මානසික විශේෂතාවක් සාමාන්\u200dය විශේෂතාවක් සාමාන්\u200dය විදියට හොඳ විදියට හොඳ විද', 'sv': 'Transformerbaserade språkmodeller (LM) fortsätter att förbättra den senaste prestandan när det gäller referensuppgifter för NLP, inklusive uppgifter som utformats för att efterlikna mänskligt inspirerade "allmännyttiga" kompetenser. För att bättre förstå i vilken grad LM kan sägas ha vissa språkliga resonemang färdigheter börjar forskarna anpassa verktygen och begreppen inom området psykometri. Men i vilken utsträckning kan fördelarna flöda åt andra hållet? Det vill säga, kan LM vara till nytta för att förutsäga vilka psykometriska egenskaper testobjekt kommer att vara när dessa objekt ges till mänskliga deltagare? Vi samlar in svar från många mänskliga deltagare och LM (transformator- och icke-transformator-baserade) på ett brett diagnostiskt test av språkliga kompetenser. Vi använder sedan svaren för att beräkna standardpsykometriska egenskaper hos objekten i det diagnostiska testet, med hjälp av de mänskliga svaren och LM-svaren separat. Vi bestämmer sedan hur väl dessa två uppsättningar av förutsägelser matchar. Vi finner fall där transformatorbaserade LM förutspår psykometriska egenskaper konsekvent bra i vissa kategorier men konsekvent dåligt i andra, vilket ger nya insikter i grundläggande likheter och skillnader mellan mänskligt och LM resonemang.', 'ur': 'Name اس لئے بہتر سمجھنا چاہیے کہ LMs کو کس طرح کہہ سکتے ہیں کہ ان کے لئے کچھ زبان شناسی منظور کا اختیار ہے، تحقیقات کرنے والوں نے روانشناسی کے کھیلے کے ابزار اور منظور اضافہ کرنے کی شروع کی ہے۔ لیکن فائدے کس طرح دوسری طرف چلتے ہیں؟ اس کے مطابق، کیا LMs آزمائش چیزوں کی psychometric properties کیا ہوگی جب ان چیزوں کو انسان شرکت کرنے والوں کے لئے دیا جائے گا؟ ہم نے بہت سی انسان شرکت کرنے والوں اور LMs (تغییر اور غیر تغییر کرنے والوں کی) ایک گھیری دیاگنٹی کی آزمائش پر جواب جمع کیا ہے۔ اس کے بعد ہم نے جواب استعمال کیا ہے کہ ان چیزوں کی استاندارڈ روانشن گواہی کا شمار کریں، انسان کی جواب اور LM کی جواب مختلف طریقے سے۔ پھر ہم تصدیق کرتے ہیں کہ یہ دو مخلوقات کیسے اچھی طرح مطابق ہوتی ہیں۔ ہم ایسے مواقع کو پاتے ہیں جن میں تغییر دینے والی LMs روانشن گواہی کے مطابق بہت اچھے طریقے سے پیش بینی کرتے ہیں لیکن دوسروں میں دائمی کمی ہے، یہاں تک کہ انسان اور LM کے درمیان تغییرات کی بنیادی شباهت اور تغییرات کے مطابق نوی نظر دیتے ہیں', 'ta': 'மாற்று அடிப்படையான மொழி மாதிரிகள் (LMs) NLP பெங்க்மார்க் பணிகளில் நிலையில்- கலை செயல்பாட்டை முன்னேற்றுவது தொடர்ந்து கொண்டிருக்கிறது, ம எல்எம்ஸ் சில மொழியில் புரிந்து கொள்ளும் திறமையை நன்றாக புரிந்து கொள்ள முடியும், ஆராய்ச்சிகள் தொடர்ந்து செல்கிறார்கள் மைக்கோம ஆனால் எந்த அளவில் பயன்பாடுகள் மற்ற திசையில் செல்ல முடியும்? உதாரணமாக, எல்எம்ஸ் பயன்படுத்த முடியுமா சோதனை உருப்படிகளின் மனநிலை பண்புகள் என்ன இருக்கும் என்று பார்க்கலாம் என்று முடியும் என்ற நாம் பல மனித பகிர்வாளர்களில் இருந்து பதில் மற்றும் LMs (மாற்றம் மற்றும் மாற்றம் அடிப்படையில் இல்லாத மாற்றம்) மொழி திட்டமைப்பு சோதனையில்  We then use the responses to calculate standard psychometric properties of the items in the diagnostic test, using the human responses and the LM responses separately.  இந்த இரண்டு முன்னாட்சிகள் எவ்வளவு நன்றாக பொருந்தும் என்பதை நாம் தீர்மானிக்கிறோம். மாற்றம் அடிப்படையிலான LMs மாற்றம் மாற்றங்களை மாற்றும் முறைமைத்துள்ள பண்புகள் சில வகுப்புகளில் முழுமையாக நன்றாக முடியும் ஆனால் தொடர்ந்து மிகவும் குறைவ', 'mn': "Төгсгөлдөгч дээр суурилсан хэл загварууд (LMs) NLP банклах үйл ажиллагааны хувьд хөгжүүлэх үйл ажиллагааг үргэлжлүүлнэ. Хүн төрөлхтний урам зориулсан 'ихэвчлэн мэдрэмжтэй' үйл ажиллагааг дүрслэх зориул Судлаачид хэлэлцээний урьдчилгааны чадвартай гэдгийг илүү ойлгохын тулд сэтгэл судлаачид сэтгэл зүйн талбарын хэрэгсэл болон ойлголтыг засаж эхэлсэн. Гэхдээ нөгөө талаар ашиг хэр хэмжээнд орж болох вэ? Зөвхөн ЛХ-нүүд хүн оролцогчдын психометрийн хувьцааны шинж чанар ямар байх вэ? Бид олон хүн оролцогчдын хариулт, хэлний талаарх шинжлэх ухааны шинжлэх ухааны шинжлэх ухааны шалгалтын тухай LMs болон LMs-ээс хамт авч ирсэн. Дараа нь бид мэдээллийн шалгалтын стандарт психометрийн хариултыг ашиглаж, хүн төрөлхтний хариулт болон ЛМ хариултыг ялгаа ашиглаж байна. Дараа нь бид эдгээр хоёр таамаглал хэр сайн тоглодог вэ? Бид өөрчлөгч дээр суурилсан LMs-г зарим категориудад психометрийн өөрчлөлтийг сайн тодорхойлж байдаг, гэхдээ бусад хүмүүс болон LM ойлголтын хоорондын өөрчлөлтийг шинэ ойлголт өгдөг.", 'vi': 'Các mô hình ngôn ngữ biến hình nền biến hình (LMs) tiếp tục cải tiến tiến tiến tiến tiến tiến tiến tiến trình cao nhất trên các công việc tiêu chuẩn NMB, bao gồm các nhiệm vụ được thiết kế nhằm bắt chước các "hầu hạ" đầy đủ. Để hiểu rõ hơn mức độ mà người LM có thể nói là có một số kỹ năng ngôn ngữ, các nhà nghiên cứu đang bắt đầu thích nghi các công cụ và khái niệm của lĩnh vực tâm lý. Nhưng liệu lợi ích có đi theo hướng khác không? Tức là, liệu LM có thể được dùng để dự đoán được các tính chất tâm lý của các vật thí nghiệm sẽ là gì khi những vật này được trao cho người tham gia? Chúng tôi thu thập các phản ứng từ nhiều người tham dự và LMs (máy biến hình- và không-chuyển hoá) dựa trên một kiểm tra chẩn đoán rộng về kỹ năng ngôn ngữ. Sau đó chúng tôi sử dụng các phản ứng để tính tính tính các tính chất tâm linh tiêu chuẩn của các mục trong bài kiểm tra chẩn đoán, sử dụng các phản ứng con người và các phản ứng LM riêng. Sau đó chúng ta quyết định hai dự đoán tương đồng thuận thế nào. Chúng tôi tìm những trường hợp mà các LM dựa trên người biến đổi dự đoán các tính chất tâm lý theo chiều sâu của một số loại, nhưng luôn kém ở những loại khác, cung cấp thêm những nhận thức mới về những điểm tương đồng cơ bản và sự khác nhau giữa suy nghĩ của người và LM.', 'uz': "Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired 'commonsense' competencies.  LMs ma'lum tillar ma'lumotlari bo'lishi mumkin darajaga yaxshi o'rganish uchun o'rganishlar psykometrik sohalarining asboblarni va g'oyalarini o'zgartirib boshlanadi. Lekin faqat qanday darajada foydalanishi mumkin? Masalan, ma'lumotlar bir narsalar inson bilan bog'liq bo'lganda psykometrik xossalari nima bo'ladi deb hisoblash mumkin? Biz ko'pchilik odamlar bilan ta'minlovchilar va LMs (transformer- va o'zgarish asosida) javoblarni ko'pchilik tillar kompaniyalarini ko'plab ko'pchiligimiz. Keyin biz diagnostik tizimida narsalarning andoza psykometrik xossalarini hisoblash uchun javoblarni ishlatamiz, inson javoblari va LM javoblarini alohida ishlatish uchun. Keyin biz bu ikkita ta'siri hozirga qanday o'xshash ko'rinishini aniqlamiz. Biz o'zgarishning asosida LMs o'zgarishga ega bo'lgan narsalarni boshqa turdagi psykometrik xususiyatlarini o'zgartiradi, lekin davomida ko'p ko'plab o'zgarishga ega bo'ladi, shunday qilib, yangi ko'rini inson va LM sabablarida o'zgarishga ega bo'ladi.", 'nl': "Transformatorgebaseerde taalmodellen (LM's) blijven de state-of-the-art prestaties van NLP-benchmarktaken verbeteren, waaronder taken die zijn ontworpen om door mensen geïnspireerde 'gezond verstand' competenties na te bootsen. Om beter te begrijpen in welke mate LM's bepaalde linguïstische redeneringsvaardigheden kunnen hebben, beginnen onderzoekers de instrumenten en concepten op het gebied van psychometrie aan te passen. Maar in hoeverre kunnen de voordelen in de andere richting stromen? D.w.z., kunnen LMs van nut zijn om te voorspellen wat de psychometrische eigenschappen van testitems zullen zijn wanneer deze items aan menselijke deelnemers worden gegeven? We verzamelen reacties van tal van menselijke deelnemers en LM's (transformator- en non-transformator-based) op een brede diagnostische test van linguïstische competenties. Vervolgens gebruiken we de antwoorden om standaard psychometrische eigenschappen van de items in de diagnostische test te berekenen, waarbij de menselijke reacties en de LM-reacties afzonderlijk worden gebruikt. Vervolgens bepalen we hoe goed deze twee sets voorspellingen overeenkomen. We vinden gevallen waarin transformatorgebaseerde LMs psychometrische eigenschappen consistent goed voorspellen in bepaalde categorieën, maar consistent slecht in andere, waardoor nieuwe inzichten worden verkregen in fundamentele overeenkomsten en verschillen tussen menselijk en LM redeneren.", 'bg': 'Езиковите модели, базирани на трансформатори, продължават да усъвършенстват най-съвременните постижения по задачите за референтна програма за НЛП, включително задачи, предназначени да имитират вдъхновените от човека "общ разум" компетенции. За да се разбере по-добре степента, до която може да се каже, че ЛМ имат определени умения за лингвистично разсъждаване, изследователите започват да адаптират инструментите и концепциите в областта на психометрията. Но до каква степен ползите могат да текат в другата посока? Тоест, могат ли ЛМ да бъдат полезни за предсказване какви ще бъдат психометричните свойства на тестовите елементи, когато тези елементи се дават на участниците от хора? Събираме отговори от множество човешки участници и ЛМ (трансформаторни и нетрансформаторни) на широк диагностичен тест за езикови компетенции. След това използваме отговорите, за да изчислим стандартните психометрични свойства на елементите в диагностичния тест, като използваме човешките отговори и отговорите на ЛМ поотделно. След това ще определим колко добре съвпадат тези два набора от прогнози. Намираме случаи, в които трансформаторните ЛМ прогнозират психометричните свойства последователно добре в определени категории, но последователно слабо в други, като по този начин осигуряват нови прозрения за фундаменталните прилики и разлики между човешкото и ЛМ разсъждение.', 'da': "Transformer-baserede sprogmodeller (LM'er) fortsætter med at fremme den nyeste ydeevne i forbindelse med benchmarkopgaver inden for NLP, herunder opgaver, der er designet til at efterligne menneskelige inspirerede 'almindelige' kompetencer. For bedre at forstå, i hvilken grad LM'er kan siges at have visse sproglige ræsonnement færdigheder, er forskerne begyndt at tilpasse værktøjer og begreber inden for psykometri. Men i hvilket omfang kan fordelene strømme i den anden retning? Det vil sige, kan LM'er være nyttige til at forudsige, hvad de psykometriske egenskaber af testgenstande vil være, når disse genstande gives til menneskelige deltagere? Vi indsamler svar fra mange menneskelige deltagere og LM'er (transformer- og ikke-transformer-baserede) på en bred diagnostisk test af sproglige kompetencer. Vi bruger derefter svarene til at beregne standard psykometriske egenskaber for elementerne i den diagnostiske test ved hjælp af de menneskelige responser og LM respons separat. Vi bestemmer derefter, hvor godt disse to sæt forudsigelser matcher. Vi finder tilfælde, hvor transformer-baserede LM'er forudsiger psykometriske egenskaber konsekvent godt i visse kategorier, men konsekvent dårligt i andre, hvilket giver ny indsigt i fundamentale ligheder og forskelle mellem menneskelig og LM-ræsonnement.", 'hr': 'Modeli jezika koji su temeljeni na transformaciji (LMs) nastavljaju napredovati postupak umjetnosti na zadatkima NLP-a, uključujući zadatke koje su dizajnirane za imitiranje ljudskih inspiracija "češće" kompetencije. Da bi bolje razumjeli stupanj kojoj se LMs može reći da ima određene jezičke vještine razuma, istraživači počinju prilagoditi alate i koncept polja psihoterije. Ali u kojoj mjeri koristi mogu proći u drugom smjeru? Znači, može li LGs koristiti u predviđanju što će psihotičke vlasništva testnih predmeta biti kada se te predmete daju ljudskim sudionicima? Skupljamo odgovore od mnogih ljudskih učesnika i LMs (na transformaciji i ne transformaciji) na širokom dijagnostičnom testu jezičkih kompetencija. Onda koristimo odgovore kako bi izračunali standardne psihoterijske vlasništvo predmeta u dijagnostičnom testu, koristeći ljudske odgovore i odgovore LM odvojeno. Onda određujemo kako dobro odgovaraju ova dva seta predviđanja. Nalazimo slučajeve u kojima se transformacijski LMs predviđaju psihoterijske vlasništvo u određenim kategorijama, ali konsekventno loše u drugima, tako pružajući nove uvide u temeljne sličnosti i razlike između razmatranja ljudskih i LM-a.', 'ko': "변환기 기반 언어모델(Transformer-based language models, LMs)은 인간이 계발하는'상식'능력을 모방하기 위한 임무를 포함해 NLP 기준 임무의 최신 성능을 계속 향상시킨다.LMs가 어느 정도 언어 추리력을 가지고 있는지 이해하기 위해 연구원들은 심리 측정학 분야의 도구와 개념을 조정하기 시작했다.그러나 어느 정도에 이런 장점들이 다른 방향으로 흐를 수 있습니까?즉 테스트 항목이 인간 참여자에게 제공될 때 LMs가 테스트 항목의 심리 측정 특성을 예측하는 데 쓰일 수 있을까?우리는 대량의 인간 참여자와 LMs(변압기와 비변압기 기반)가 언어 능력에 대한 광범위한 진단 테스트에 대한 반응을 수집했다.그리고 우리는 각각 인간 반응과 LM 반응을 사용하고 이런 반응을 이용하여 진단 테스트 중의 항목의 표준 심리 측정 특성을 계산한다.그리고 우리는 이 두 그룹의 예측의 일치 정도를 확정했다.우리는 변압기를 바탕으로 하는 LMs가 일부 유형에서 심리 측정학적 특성을 예측하는 능력은 줄곧 좋았지만 다른 유형에서는 줄곧 좋지 않다는 것을 발견하여 인류와 LM 추리 간의 기본적인 유사성과 차이에 새로운 견해를 제공하였다.", 'sw': "Mfano wa lugha za zamani (LMs) unaendelea kuendelea kuendelea utendaji wa hali ya sanaa juu ya kazi za bendera za NLP, ikiwa ni pamoja na kazi zilizotengenezwa kwa ajili ya kushindana na ushirikiano wa 'mashirika' yanayohamasishwa na binadamu. Ili kuelewa vyeo vinavyoweza kusema kuwa na ujuzi fulani wa lugha, watafiti wanaanza kubadilisha zana na dhana za mtaalamu wa kisaikolojia. Lakini kwa kiwango gani faida zinaweza kusambaa upande mwingine? Mnamo, je, Bi-Bi inaweza kutumia kutabiri nini utaalamu wa kisaikolojia wa vitu vya kujaribu zitakuwa pale vitu vinavyopewa kwa washiriki wa binadamu? We gather responses from numerous human participants and LMs (transformer- and non-transformer-based) on a broad diagnostic test of linguistic competencies.  Kisha tunatumia majibu ya kuhesabu vifaa vya kisaikolojia vya kawaida vya vitu katika jaribio la uchunguzi, kwa kutumia miitikio ya binadamu na jibu la LM tofauti. Kisha tunaamua namna hii mifumo miwili yanavyofanana na utabiri. Tunapata kesi ambazo LMs. anayeishi mabadiliko yanatabiri mali za kisaikolojia zinaendelea vizuri katika makundi fulani lakini kwa kawaida ni masikini sana katika wengine, kwa hiyo inatoa maoni mapya kuwa sawa na tofauti kati ya sababu za binadamu na LM.", 'fa': 'مدل\u200cهای زبانی (LMs) بر اساس تغییر\u200cپذیر\u200cکننده (LMs) ادامه می\u200cدهند فعالیت\u200cهای حالت هنری بر کار\u200cهای نقطه\u200cبندی NLP، شامل وظیفه\u200cهای طراحی برای تغییر\u200cپذیر مسائل\u200cهای «معمولی» به انسان الهام داده برای بهتر فهمیدن درجه\u200cای که LMs می\u200cتوانند به آن گفته شود که مهارت منطقی زبان\u200cشناسی دارند، محققان شروع می\u200cکنند که ابزارها و مفهوم\u200cهای زمینه روانشناسی را adapt کنند. اما چقدر میتونه سودها در سمت دیگر روان بشه؟ می\u200cتواند خانم\u200cها در پیش\u200cبینی کردن ویژه\u200cهای روانی\u200cمتریک آزمایش\u200cها در زمانی که این وسیله\u200cها به شرکت\u200cکنندگان انسان داده می\u200cشوند چه خواهد بود؟ ما پاسخ\u200cهای بسیاری از شرکت\u200cکنندگان انسان و LMs (تغییر\u200cپذیر و غیر تغییر\u200cپذیر) را بر آزمایش گسترده تشخیص توانایی زبان جمع می\u200cکنیم. سپس از پاسخ\u200cها استفاده می\u200cکنیم تا ویژگی\u200cهای روانی استاندارد را در آزمایش تشخیص محاسبه کنیم، از پاسخ\u200cهای انسان و پاسخ\u200cهای LM جدا استفاده کنیم. سپس ما تصمیم می\u200cگیریم که این دو مجموعه پیش بینی چقدر خوبه. ما پرونده\u200cهایی را پیدا می\u200cکنیم که LMs based on transformer پیش بینی می\u200cکنند که ویژه\u200cهای روانشناسی به طور کامل در بعضی kategoriها خوب است ولی به طور کامل بد در بعضی دیگر، بنابراین مشاهده\u200cهای جدید به شبیه\u200cهای بنیادی و تفاوت بین منظورات انسان و LM.', 'de': 'Transformatorbasierte Sprachmodelle (LMs) fördern weiterhin den Stand der Technik bei NLP-Benchmark-Aufgaben, einschließlich Aufgaben, die von Menschen inspirierte "Commonsense"-Kompetenzen nachahmen. Um besser zu verstehen, inwieweit LMs bestimmte sprachliche Denkfähigkeiten besitzen, beginnen Forscher, die Werkzeuge und Konzepte des Bereichs Psychometrie anzupassen. Aber inwieweit kann der Nutzen in die andere Richtung fließen? D.h., können LMs nützlich sein, um vorherzusagen, welche psychometrischen Eigenschaften von Testobjekten sein werden, wenn diese an menschliche Teilnehmer gegeben werden? Wir sammeln Antworten von zahlreichen menschlichen Teilnehmern und LMs (transformator- und non-transformator-basiert) auf einem breiten diagnostischen Test sprachlicher Kompetenzen. Wir verwenden die Antworten dann, um die psychometrischen Standardeigenschaften der Elemente im diagnostischen Test zu berechnen, wobei die menschlichen Antworten und die LM-Antworten getrennt voneinander verwendet werden. Wir bestimmen dann, wie gut diese beiden Sätze von Vorhersagen übereinstimmen. Wir finden Fälle, in denen transformatorbasierte LMs psychometrische Eigenschaften in bestimmten Kategorien konsistent gut vorhersagen, in anderen jedoch konsistent schlecht, wodurch neue Erkenntnisse über grundlegende Ähnlichkeiten und Unterschiede zwischen menschlichem und LM-Denken gewonnen werden.', 'tr': "NLP benchmark täzeliklerinde terjime edip görkezilen dil nusgalary (LMs) NLP taryşma täzeliklerinden öňünde durum-of-the-art täzeliklerini döretmäge dowam edýär Adamlaryň dil düşünüp ukyplarynyň nähili derejesini gowy düşünmek üçin, araştyranlar psikopetik alanynyň aletlerini we düşünjelerini üýtgetmeye başlaýarlar. Fakat işe yarar ne kadardır? Meniň pikirimçe, Hanlaryň testiň häsiýetleriniň psykometrik häsiýetleriniň näme boljakdygyny tahmin etmek üçin ullanyp bilermi? Biz birçok insan iştirakçilerinden ve LM'lerin (transformer- ve transformer-olmayan) bir denetim denetimi üzerine cevaplar topladık. Sonra diagnostikiň testindeki elementleriň standart psikopetrik hasaplamak üçin jogaplaryny ulanýarys, adamlaryň jogaplaryny we LM jogaplaryny ayrı-ayrı ulanýarys. Sonra bu iki öngörüm nähili gowy duşuşygyny çykarýarys. Adamlar üçin üýtgeden ilat sanlaryny belli kategoriýalarda diýip gowy çaklaýan ýagdaýlary tapýarys, şonuň üçin adam we LM razylygynyň arasynda täze düşünjeleri täze bir ýagdaýa üýtgedýäris.", 'am': 'የተለየ የቋንቋ ምሳሌዎች (LMs) የNLP benchmark ስራዎች ላይ የሀገር-የ-art አድራሻ እንዲቀድሙ ይኖራል፡፡ የLMs ቋንቋዊ አእምሮ ባለው ጥያቄን ለማስተዋል የሚችሉትን ደረጃዎች ለማስተዋል፣ አስተማሪዎቹ የሲኮሜትርክ እርሻ መሣሪያና የልውና ጥያቄዎችን ለማሻሻል ጀምረዋል፡፡ ነገር ግን ጥቅማቸው በሌላ መንገድ እንዴት ይሄዳል? I.e., can LMs be of use in predicting what the psychometric properties of test items will be when those items are given to human participants?  ብዙዎች ከሰው ተጋሪዎች እና የኤምዚ (ለውጦች- እና ለውጦች-በቋንቋዊ አካላዊ ተፈተና) መልስ ሰብስባቸዋለን፡፡ በኋላም የሰው መልስ እና LM መልስ ለብቻ ለመቆጣጠር የምንጠይቅ የሲኮሜትሪካ ምርጫዎችን እናስቀምጣለን፡፡ We then determine how well these two sets of predictions match.  እንደዚህም አዲስ ዓይነቶች በሰው እና LM ምክንያት በተለያዩ ክፍሎች ውስጥ ደካማ ሆነው ሲኮሜትሪክ እውስቶችን በመቀበል እና ለልዩነት አዲስ አስተያየት እናደርጋለን፡፡', 'af': "Transformer-gebaseerde taal modele (LMs) gaan voortgaan om state-of-the-art-prestasie op NLP benchmark-opdragte te vordering, insluitend opdragte ontwerp om mens-inspireerde 'gemeenskap' kompetensies te mimiseer. Om die grad te beter verstaan waarop LMs gesê kan word om sekere lingwisiese redekeningskunstenaars te hê, begin resekers om die nutsprogramme en konsepte van die veld van psykometrika te pas. Maar na wat exten kan die voordele in die ander rigting vloei? I.e., kan LMs gebruik word in die voorskou van wat die psychometriese eienskappe van toets items sal wees wanneer dié items aan menslike deelnaders gegee word? Ons versamel antwoordes van veelvuldige menslike deelnaders en LMs (transformer- en non- transformer-based) op 'n breë diagnostike toets van lingvisse kompetenties. Ons gebruik dan die antwoordes om die standaard psychometriese eienskappe van die items in die diagnosiese toets te bereken, met die gebruik van die menslike antwoordes en die LM antwoordes indien. Ons bepaal dan hoe goed hierdie twee stelle voorskou ooreenstem. Ons vind gevalle waarin die transformer-gebaseerde LMs psykometriese eienskappe konsistentlik goed voorskou in sekere kategorie, maar konsistentlik sleg in ander, sodat nuwe inligtings in fundamentele gelykenisse en verskille tussen menslike en LM-redering verskaf.", 'az': "Transformer-tabanlı dil modelləri (LMs) NLP benchmark işləri üzərində, insanların təhlükəsizlərini mimik etmək üçün müəyyən edilmiş işləri də dahil edər. LMs'lərin bəzi dil razılığı yetenekləri olduğuna dair dərəcəsini daha yaxşı anlamaq üçün araştırmacılar psixometrik sahəsinin vasitələrini və nəfslərini uygulamağa başladılar. Lakin mənfəətlər digər tərəfdə nə qədər yayılır? Məsələn, LMs test elementlərin psixometrik xüsusiyyətlərinin insan iştirakçılara veriləcəyi zaman nədir? Biz çoxlu insan iştirakçılarından və dillərin çoxlu diagnostiki tərzlərinin təsdiqlənməsi üzerində LMs-lərdən cavab verərik. Sonra diagnostik testindəki elementlərin standart psixometrik xüsusiyyətlərini hesablamaq üçün, insan cavablarını və LM cavablarını ayrı-ayrı istifadə etmək üçün istifadə edirik. Sonra bu iki tədbirlərin necə gözəl uyğunlaşdığını təyin edirik. Biz, transformer-based LMs-lər kimi psixometrik xüsusiyyətlərini bəzi kategoriyalarda daha yaxşı təmin edirlər, lakin digərlərində daha pislik edirlər, buna görə də insan və LM razılığı arasındakı fərqlərə yeni baxışlar təmin edirlər.", 'bn': 'ভিত্তিক ভিত্তিক ভাষার মডেল (এলএমএস) এনএলপি বেনম্যার্ক কাজের উপর রাষ্ট্র-শিল্প প্রদর্শনের রাষ্ট্রের প্রতিযোগিতা অগ্রগতি চালিয়ে যাচ্ছ ভালো বুঝতে এলএমএস যে ভাষায় কোন ভাষার কৌশল আছে তা বলতে পারে, গবেষকরা মানসিক ক্ষেত্রের ক্ষেত্রের যন্ত্র ও ধারণা মানাতে শুরু করেছে। কিন্তু অন্য দিকে সুবিধা প্রবাহ করতে পারে? I.e., can LMs be of use in predicting what the psychometric properties of test items will be when those items are given to human participants?  আমরা অনেক মানুষ অংশগ্রহণকারী এবং এলএমএস (পরিবর্তন- এবং পরিবর্তনের ভিত্তিক ভিত্তিক ভিত্তিক পরীক্ষার উপর) প্রতিক্রিয়া সংগ্রহ করি। তারপর আমরা ডিজিনিস্টিক পরীক্ষায় বস্তুর স্বাভাবিক মানসিকোমেট্রিক বৈশিষ্ট্য গণনা করতে পারি, মানুষের প্রতিক্রিয়া এবং এলএম প্রতিক্রি তারপর আমরা নির্ধারণ করি এই দুটি প্রত্যেকটি ভবিষ্যৎবাণীর মিল কত ভাল। আমরা কেস খুঁজে পাচ্ছি যেখানে পরিবর্তনের ভিত্তিক এলএমএস মানসিক বৈশিষ্ট্যাবলীর বৈশিষ্ট্যাবলীতে সবচেয়ে ভালো ভবিষ্যদ্বাণী করেছে কিন্তু অন্যদের মধ্যে সবচেয়ে দু', 'sq': "Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired 'commonsense' competencies.  To better understand the degree to which LMs can be said to have certain linguistic reasoning skills, researchers are beginning to adapt the tools and concepts of the field of psychometrics.  Por sa mund të rrjedhin përfitimet në drejtimin tjetër? Pra, a mund të përdoren LMs në parashikimin se cilat do të jenë pronësitë psikometrike të objekteve të testuara kur këto objekte u jepen pjesëmarrësve njerëzorë? Ne mbledhim përgjigje nga pjesëmarrës të shumtë njerëzore dhe LMs (me bazë në transformues dhe jo-transformues) në një test diagnostik të gjerë të kompetencave gjuhësore. Pastaj përdorim përgjigjet për të llogaritur pronësitë psikometrike standarde të objekteve në test in diagnostik, duke përdorur përgjigjet njerëzore dhe përgjigjet LM veçanërisht. Pastaj përcaktojmë se sa mirë përputhen këto dy grupe parashikimesh. Ne gjejmë raste në të cilat LMs bazuar në transformues parashikojnë pronësitë psikometrike vazhdimisht mirë në disa kategori por vazhdimisht keq në të tjerë, duke ofruar kështu kuptime të reja në ngjashmëritë dhe dallimet thelbësore midis arsyetimit njerëzor dhe LM.", 'ca': 'Els models de llenguatge basats en transformadors segueixen avançant el rendiment més avançat en tasques de referència de la NLP, incloent tasques dissenyades per imitar competències "comunes" inspirades per l\'humà. Per tal d\'entendre millor el grau en què es poden dir que les MM tenen certes habilitats de raonament lingüístic, els investigadors comencen a adaptar les eines i conceptes del camp psicòmetric. Però fins a quin punt els beneficis poden fluir en l\'altra direcció? És a dir, poden les LMs ser útils per predir quines seran les propietats psicomètriques dels objectes de prova quan aquests objectes es donen als participants humans? Recollegim respostes de molts participants humans i ML (basats en transformadors i no transformadors) en un test diagnòstic ampli de competencies lingüístices. Després utilitzem les respostes per calcular les propietats psicomètriques estándar dels objectes de la prova diagnòstica, fent servir les respostes humanes i les respostes LM per separat. We then determine how well these two sets of predictions match.  Trobem casos en els quals els LM basats en transformadors predeixen propietats psicomètriques consistentment bé en certes categories però consistentment malament en altres, proporcionant així noves informacions sobre similaritats fonamentals i diferències entre raonament humà i LM.', 'bs': 'Modeli jezika koji su temeljeni na transformaciji (LMs) nastavljaju napredovati postupak umjetnosti na zadatkima NLP-a, uključujući zadatke dizajnirane za imitiranje ljudskih inspiracija o "zajedničkom smislu". Da bi bolje shvatili stupnju na koju se LMs može reći da ima određene lingvističke vještine razuma, istraživači počinju prilagoditi alate i koncept polja psihoterije. Ali u kolikoj mjeri koristi mogu teći u drugom smjeru? Znači, može li LGs koristiti u predviđanju šta će psihoterijske vlasništva testnih predmeta biti kada se te predmete daju ljudskim sudionicima? Skupljamo odgovore od mnogih ljudskih učesnika i LMs (transformator-i-ne-transformator-baziranih) na širokom dijagnostičnom testu jezičkih kompetencija. Onda koristimo odgovore da bi proračunali standardne psihometričke vlasništvo elementa u dijagnostičkom testu, koristeći ljudske odgovore i odgovore na LM odvojeno. Onda odlučimo koliko dobro odgovaraju ova dva seta predviđanja. Nalazimo slučajeve u kojima se LGs na transformaciji predviđaju psihoterijske vlasništvo u određenim kategorijama, ali konsekventno loše u drugima, tako pružajući nove uvide u temeljne sličnosti i razlike između razuma ljudskih i LM-a.', 'cs': 'Transformátorové jazykové modely (LM) pokračují v posilování nejmodernějších výkonů referenčních úloh NLP, včetně úloh navržených tak, aby napodobovaly "zdravý rozum" inspirované lidmi. Aby bylo možné lépe porozumět tomu, do jaké míry lze říci, že LM mají určité jazykové dovednosti uvažování, výzkumníci začínají přizpůsobovat nástroje a koncepty z oblasti psychometriky. Ale do jaké míry mohou výhody plynout opačným směrem? To znamená, mohou být LM užitečné při predikci psychometrických vlastností testovacích položek, když budou tyto položky dány lidským účastníkům? Na základě širokého diagnostického testu jazykových kompetencí shromažďujeme odpovědi od četných lidských účastníků a LM (transformátorových i non-transformátorových). Odpovědi pak používáme k výpočtu standardních psychometrických vlastností položek v diagnostickém testu, pomocí lidských a LM odpovědí odděleně. Poté určíme, jak dobře se tyto dvě sady předpovědí shodují. Našli jsme případy, kdy transformátorové LM předpovídají psychometrické vlastnosti konzistentně dobře v určitých kategoriích, ale konzistentně špatně v jiných, čímž poskytují nové pohledy na základní podobnosti a rozdíly mezi lidským a LM uvažováním.', 'hy': "Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired 'commonsense' competencies.  Որպեսզի ավելի լավ հասկանանք, թե ինչքանով է կարելի ասել, որ LM-ները ունեն որոշ լեզվաբանական մտածողական հմտություններ, հետազոտողները սկսում են հարմարեցնել հոգեբանության ոլորտի գործիքները և գաղափարները: Բայց ի՞նչ չափով կարող է շահույթը հոսում հակառակ ուղղությամբ: Այսինքն, արդյո՞ք LM-ները կարելի է օգտագործել փորձարկումների հոգեչափական հատկությունները կանխատեսելու համար, երբ դրանք տրվում են մարդկային մասնակիցներին: Մենք հավաքում ենք արձագանքներ շատ մարդկային մասնակիցներից և LM-ներից (վերափոխողների և ոչ վերափոխողների հիմնված) լեզվաբանական հմտությունների լայն ախտորոշման թեստի վրա: Այնուհետև մենք օգտագործում ենք արձագանքները ախտորոշման թեստերի ստանդարտ հոգեչափ հատկությունների հաշվարկելու համար, օգտագործելով մարդկային արձագանքները և LM արձագանքները առանձին: Հետո մենք որոշում ենք, թե ինչքան լավ են այս երկու կանխատեսումները համապատասխանում: Մենք գտնում ենք դեպքեր, որոնց ընթացքում փոփոխակերպման հիմնված բջիջները հոգեչափ հատկություններ կանխագուշակում են որոշ կատեգորիաներում, բայց մյուսների դեպքում միշտ վատ, այնպես որ նոր ընկալումներ են տրվում մարդկային և բջիջների մտածողության հիմնական նման", 'fi': 'Muuntajapohjaiset kielimallit (LM) edistävät edelleen NLP:n vertailutehtävien huipputasoa, mukaan lukien tehtävät, jotka on suunniteltu jäljittelemään ihmisen inspiroimia "maalaisjärjestyksen" taitoja. Ymmärtääkseen paremmin, missä määrin LM:llä voidaan sanoa olevan tiettyjä kielellisiä päättelytaitoja, tutkijat ovat alkaneet mukauttaa psykometrian alan työkaluja ja käsitteitä. Mutta missä määrin hyödyt voivat virrata toiseen suuntaan? Eli voidaanko LM:istä olla hyötyä ennustettaessa, mitkä testikohteiden psykometriset ominaisuudet ovat, kun niitä annetaan ihmisille? Keräämme vastaukset lukuisilta ihmisistä ja LM:iltä (muuntajapohjainen ja ei-muuntajapohjainen) laajassa kielellisen osaamisen diagnostisessa testissä. Tämän jälkeen käytämme vasteita diagnostisen testin kohteiden psykometristen ominaisuuksien laskemiseen käyttäen ihmisen ja LM-vasteita erikseen. Sen jälkeen määritämme, kuinka hyvin nämä kaksi sarjaa ennusteita vastaavat. Löydämme tapauksia, joissa muuntajapohjaiset LM ennustavat psykometrisiä ominaisuuksia johdonmukaisesti hyvin tietyissä kategorioissa, mutta johdonmukaisesti huonosti toisissa, tarjoten näin uusia oivalluksia ihmisen ja LM-päättelyn perustavanlaatuisista yhtäläisyyksistä ja eroista.', 'id': "Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired 'commonsense' competencies.  Untuk memahami lebih baik derajat ke mana LMs dapat dikatakan memiliki keterampilan pemikiran bahasa tertentu, peneliti mulai mengadaptasi alat dan konsep dari bidang psikometrik. But to what extent can the benefits flow in the other direction?  Maksudku, apakah LMs dapat digunakan untuk memprediksikan apa sifat psikometrik dari objek ujian ketika benda-benda itu diberikan kepada peserta manusia? Kami mengumpulkan respon dari banyak peserta manusia dan LMs (transformer- dan non-transformer-berdasarkan) pada tes diagnostik luas kompetensi bahasa. Kemudian kami menggunakan respon untuk menghitung properti psikometrik standar dari objek dalam tes diagnostik, menggunakan respon manusia dan respon LM secara terpisah. Kemudian kita menentukan betapa baik kedua set prediksi ini cocok. We find cases in which transformer-based LMs predict psychometric properties consistently well in certain categories but consistently poorly in others, thus providing new insights into fundamental similarities and differences between human and LM reasoning.", 'et': 'Transformeritel põhinevad keelemudelid edendavad jätkuvalt uue õppekava võrdlusülesannete tipptasemel jõudlust, sealhulgas ülesandeid, mille eesmärk on imiteerida inimese inspireeritud "üldsuse" pädevust. Selleks et paremini mõista, mil määral võib LMidel öelda, et neil on teatud keeleline mõtlemisoskus, hakkavad teadlased psühhomeetria valdkonna vahendeid ja kontseptsioone kohandama. Kui suures ulatuses võib kasu liikuda teises suunas? See tähendab, kas LM-d võivad olla kasulikud prognoosides, millised on katseseadmete psühholomeetrilised omadused, kui neid esemeid antakse inimosalejatele? Kogume vastuseid paljudelt inimosalejatelt ja LMidelt (trafo- ja mittetrafo-põhiselt) laiaulatuslikul keeleoskuse diagnostilisel testil. Seejärel kasutame vastuseid diagnostilise testi objektide standardsete psühhomeetriliste omaduste arvutamiseks, kasutades inimeste ja LM vastust eraldi. Seejärel määrame, kui hästi need kaks ennustuste komplekti sobivad. Leiame juhtumeid, kus trafopõhised LMid ennustavad psühhomeetrilisi omadusi järjepidevalt hästi teatud kategooriates, kuid järjepidevalt halvasti teistes kategooriates, andes seega uue ülevaate inimese ja LM arutluse põhimõttelistest sarnasustest ja erinevustest.', 'sk': 'Jezikovni modeli, ki temeljijo na transformatorjih, še naprej izboljšujejo najsodobnejšo uspešnost pri referenčnih nalogah NLP, vključno z nalogami, namenjenimi posnemanju kompetenc, ki jih navdihuje človek. Da bi bolje razumeli, v kolikšni meri imajo LM določene znanje jezikovnega razmišljanja, raziskovalci začenjajo prilagajanje orodij in konceptov s področja psihopetrije. Toda v kakšni meri lahko koristi tečejo v drugo smer? Torej, ali so LM uporabni pri napovedovanju psihopetričnih lastnosti preskusnih izdelkov, ko se ti izdelki dajejo človeškim udeležencem? Odgovore številnih človeških udeležencev in LM-jev zbiramo na podlagi širokega diagnostičnega testa jezikovnih kompetenc. Nato uporabimo odzive za izračun standardnih psihometričnih lastnosti elementov diagnostičnega testa, pri čemer uporabimo človeške odzive in LM odzive ločeno. Nato ugotovimo, kako dobro se ta dva sklopa napovedi ujemata. Našli smo primere, v katerih transformatorski LM dosledno dobro napovedujejo psihometrične lastnosti v določenih kategorijah, v drugih pa dosledno slabo, s čimer zagotavljajo nove vpoglede v temeljne podobnosti in razlike med človeškim in LM razmišljanjem.', 'jv': 'File Rasané luwih apik dhéwé kuwi mesthi awak dhéwé bakal nguasaé Kemerdekaan karo hal-hal sing luwih apik, maburén kuwi ngubah perusahaan karo perusahaan karo perusahaan sing apik dhéwé. Nanging, hayo kowe kudu piye mbengok kanggo ngilangno iki dadi? Andeh, iso kelas LM iso nggunakake dipunangé supoyo urip mengko karo perusahaan kelas mi ? Awak dhéwé ngregani responsaké karo akeh sanggunaké karo akeh sampeyan luwih dumadhi lan luwih (transformer- lan Gak-transformer-basa) sak ujian karo perusahaan languangkap Awak dhéwé wis nggambar barang kanggo kalungunggal perintah sing nyengkap karo ingkang dipunangkat ujian, gambar barang-ujaran uwong karo barang-ujaran LM Awak dhéwé ngerti piye ngerti yang dipun Awak dhéwé luwih Kasama sing paling-manut anyar tentang dipunangé luwih dumadhi winih dhéwé kuwi kesempatan sing beraksi ngono nggawe kategori sing gak dhéwé, dadi ngono nggawe persilangan alam sing paling dhéwé, kuwi nggawe persilangan alam sing dumadhi sak barêng-alam kuwi sakjane uw', 'he': 'מודלים שפות מבוססים במעבר (LMs) ממשיכים להתקדם ביצועים חדשים במשימות רמז NLP, כולל משימות שנועדות כדי לחקות את הכישורים "משמעותיים משותפים". כדי להבין טוב יותר את המידה שבה אפשר לומר שיש לאל-מיס כישורי הגיון שפתיים מסוימים, מחקרים מתחילים להסתגל את הכלים והמושג של שדה הפסיכומטריקה. אבל באיזו מידה היתרונות יכולות לזרום בכיוון השני? I.e., can LMs be of use in predicting what the psychometric properties of test items will be when those items are given to human participants?  אנו אוספים תגובות ממספר משתתפים אנושיים ו LMs (מבוסס על מעבר ולא מעבר) על בדיקת אבחנה רחבה של כישורים שפתיים. ואז אנו משתמשים בתגובות כדי לחשב תכונות פסיכומטריות סטנדרטיות של החפצים במבחן האבחנה, בשימוש בתגובות האנושיות והתגובות LM בנפרד. ואז נקבע כמה טוב שני הקבוצות האלה מתאימות. אנו מוצאים מקרים שבהם LMs מבוססים במעבר חושפים תכונות פסיכומטריות באופן קבוע טוב בקטגוריות מסוימות אבל באופן קבוע רע באחרים, כך מספקים תובנות חדשות לתגובות בסיסיות וההבדלים בין הגיון האנושי לבין LM.', 'bo': "Transformer-based language models (LMs) continue to advance state-of-the-art performance on NLP benchmark tasks, including tasks designed to mimic human-inspired 'commonsense' competencies. To better understand the degree to which LMs can be said to have certain linguistic reasoning skills, researchers are beginning to adapt the tools and concepts of the field of psychometrics. འོན་ཀྱང་། ཕྱོགས་གཞན་ཞིག་གི་ཁྲོད་ཚོགས་ཀྱི་ཕྱོགས་སུ་ཡིན་ནམ། དེའི་དཔེར་ན། མིང་གིས་རྣམ་གྲངས་འདི་ཞིབ་དཔྱད་པའི་རྣམ་གྲངས་ལ་psychometric རྒྱུ་དངོས་གང་ཞིག་ཡིན་པ་དང་། རྣམ་གྲངས ང་ཚོས་རྒྱ་ནག་ཚང་མི་མང་པོ་ཞིག་དང་ཐོག་འཕྲུལ་ལ་བསྡད་པའི་གནད་དོན་དག་ཆ་རྐྱེན་མེད་པའི་བརྟག་དཔྱད་ཞིག་ལ་བསྡད་བྱེད་ཀྱི་ཡོད། འོན་ཀྱང་། ང་ཚོས་རྣམ་གྲངས་ཀྱི་ཆ་འཕྲིན་གྱི་རྒྱུ་དངོས་ཀྱི་ཚད་རྩིས་ཐུབ་ཀྱི་རྒྱུ་དངོས་ལག་ལེན་འཐབ་པ་ལས། མི་ཚོའི་ལན་གསལ་བཤད་དང་LM འོན་ཀྱང་། ང་ཚོས་རྟོགས་པའི་སྔོན་ཚོགས་གཉིས་ཀྱི་མཐུན་སྒྲིག་རྒྱུ་རེད། ང་ཚོས་དེ་ལྟ་བུའི་ནང་དུ་བཟོ་བཅོས་མཁན་གྱི་LMs་དག་གི་རྒྱུ་དངོས་ཉེན་ཅིག་ཡིན་པའི་སྒེར་གྱི་རྒྱུ་དངོས་རྣམས་ལས་ཕན་མེད་པའི་དབྱེ་རིམ་གཞན་ཞིག་ཏུ་མཐུན་རྐྱེན", 'ha': "@ item: inmenu To, dõmin ka fi fahimta daraja da za'a ce da LM ana da kunnufi masu cikin lugha, watani na fara yin adadi da zance da zato'anar manyan aikin misali. Kayya da manyan amfãni zai iya gudãna a kan gefen? Shin, za'a iya amfani da LM kan ka yi bayani ga wanne properties na kisaikomi za'a kasance idan an ba da waɗannan abubuwa ga mutum? Munã samun mataimaki daga mãsu yawa daga mutane da LM (transformer- da-transformer-da-bane) kan jarraba mai bayani na fassarar mulki-linguistic. Sa'an nan kuma Munã yi amfani da majibu dõmin Mu ƙidãya tsari na masu aikin aikocomimetric cikin jarraban diagnostic, don Mu yi amfani da majibu ga mutum da kuma kuma LM ya jibar da su separately. Sa'an nan kuma Mu hukunta yadda waɗannan matsayi biyu suke kami. Tuna gane kashfa da aka danne LM a cikinsa, yana bayani ga masu shawarar misãlai masu cikin wasu categori masu daidai kuma yana daidai a cikin wasu mutane, sabõda haka yana sanya gannai na dabam a cikin misãlai da sãɓãni tsakanin mutum da LM."}
{'en': 'A Study on Using Semantic Word Associations to Predict the Success of a Novel', 'fr': "Une étude sur l'utilisation des associations de mots sémantiques pour prédire le succès d'un roman", 'ar': 'دراسة حول استخدام ارتباطات الكلمات الدلالية للتنبؤ بنجاح رواية', 'es': 'Un estudio sobre el uso de asociaciones de palabras semánticas para predecir el éxito de una novela', 'pt': 'Um estudo sobre o uso de associações de palavras semânticas para prever o sucesso de um romance', 'ja': '小説の成功を予測するための意味論的な単語の関連付けの使用に関する研究', 'ru': 'Исследование по использованию семантических ассоциаций слов для предсказания успеха романа', 'zh': '用语义词关联占小说成功', 'hi': 'एक उपन्यास की सफलता की भविष्यवाणी करने के लिए शब्दार्थ शब्द संघों का उपयोग करने पर एक अध्ययन', 'ga': 'Staidéar ar Úsáid Cumainn Focal Séimeantach le Rathúlacht Úrscéal a Thuar', 'ka': 'Name', 'el': 'Μελέτη για τη χρήση σημασιολογικών συσχετισμών λέξεων για την πρόβλεψη της επιτυχίας ενός μυθιστορήματος', 'hu': 'Tanulmány a szemantikus szótársítások használatáról egy regény sikerének előrejelzésére', 'it': "Uno studio sull'uso delle associazioni semantiche di parole per prevedere il successo di un romanzo", 'kk': 'Жаңалық сәтті бақылау үшін Semantic Word Association қолдануды зерттеу', 'mk': 'A Study on Using Semantic Word Associations to Predict the Success of a Novel', 'lt': 'Semantinių žodžių asociacijų naudojimo romano sėkmei prognozuoti tyrimas', 'ms': 'Name', 'ml': 'ഒരു നോവലിന്റെ വിജയം മുന്\u200dകൂട്ടുവാന്\u200d സെമാന്റിക് വാക്കുകള്\u200d സങ്കേഷനുകള്\u200d ഉപയോഗിക്കുന്ന ഒരു പഠനം', 'no': 'Name', 'mt': 'Studju dwar l-Użu ta’ Assoċjazzjonijiet Semantiċi tal-Kliem biex jipprevedi s-Suċċess ta’ Novell', 'mn': 'Шинэ сарын амжилтын тулд Semantic Word Association ашиглах судалгаа', 'pl': 'Badanie nad wykorzystaniem semantycznych skojarzeń słowowych do przewidywania sukcesu powieści', 'ro': 'Un studiu privind utilizarea asocierilor de cuvinte semantice pentru a anticipa succesul unui roman', 'sr': 'Ispitivanje o korištenju semantičkih udruženja reči za predviđanje uspjeha novčanika', 'si': 'Name', 'ta': 'Name', 'sv': 'En studie om hur man använder semantiska ordassociationer för att förutsäga en romans framgång', 'ur': 'Name', 'so': 'Waxbarashada ku saabsan isticmaalka ururada hadalka galmada si uu u diyaariyo liibaanka bannaanka', 'uz': 'Name', 'vi': 'Một nghiên cứu về sử dụng các tổ chức từ ngữ kỳ diệu để đoán trước sự thành công của một tiểu thuyết', 'hr': 'Ispitivanje o upotrebi semantičkih udruženja riječi za predviđanje uspjeha novčanika', 'nl': 'Een studie over het gebruik van semantische woordassociaties om het succes van een roman te voorspellen', 'da': 'En undersøgelse om brug af semantiske ordsammenslutninger til at forudsige succesen af en roman', 'bg': 'Проучване за използването на семантични словесни асоциации за прогнозиране на успеха на роман', 'fa': 'یک مطالعه در مورد استفاده از اتصال کلمه\u200cهای سیمانتیک برای پیش\u200cبینی موفقیت یک نوئل', 'de': 'Eine Studie über die Verwendung von semantischen Wortassoziationen, um den Erfolg eines Romans vorherzusagen', 'sw': 'Utafiti wa kutumia Chama cha Matokeo ya Kijinsia Kujiandaa mafanikio ya Eneo', 'id': 'Sebuah Penelitian Menggunakan Asosiasi Kata Semantik untuk memprediksi Sukses Novel', 'tr': 'Bir Täze Successi Beklemek üçin Semantik söz jemgyýetleri ulanmakda öwrenme', 'ko': '어의어 연상을 활용하여 소설의 성공을 예측하는 연구', 'af': 'Name', 'sq': 'Një studim mbi përdorimin e shoqatave Semantike të Fjalëve për të parashikuar suksesin e një romani', 'hy': 'A Study on Using Semantic Word Associations to Predict the Success of a Novel', 'bs': 'Ispitivanje o upotrebi semantičkih udruženja riječi za predviđanje uspjeha novčanika', 'am': 'A study on using Semantic Word Associations to Predict the Success of a Novel', 'az': 'Növbənin başarısızlığını öyüd-nəsihət etmək üçün Semantik Söz İşkiləri', 'ca': "Un estudi sobre l'ús d'associacions de paraules Semàtiques per predir l'èxit d'un roman", 'bn': 'একটি নোভেলের সফলতা প্রেসিডেন্ট করার জন্য সেম্যান্টিক শব্দ সংস্থা ব্যবহার করার একটি গবেষণা', 'cs': 'Studie o použití sémantických slovních asociací k predikci úspěchu románu', 'fi': 'Tutkimus semanttisten sanayhdistysten käytöstä romaanin onnistumisen ennustamiseen', 'et': 'Uuring semantiliste sõnade ühenduste kasutamisest romaani edu prognoosimiseks', 'jv': 'tab', 'ha': 'KCharselect unicode block name', 'sk': 'Študija o uporabi semantičnih besednih povezav za napovedovanje uspeha romana', 'he': 'מחקר על השימוש באיגוד מילים סמנטיות כדי לחזות את הצלחה של רומן', 'bo': 'གསར་ཤོག་གི་ལྟ་བུའི་རྗེས་སུ་སྤྱད་ནས་Semantic Word Associations ་བྱ་ཚིག་གི་སྔོན་སྒྲིག་གི་གོ་སྐབས་'}
{'en': 'Many new books get published every year, and only a fraction of them become popular among the readers. So the prediction of a book success can be a very useful parameter for publishers to make a reliable decision. This article presents the study of semantic word associations using the word embedding of book content for a set of Roget’s thesaurus concepts for book success prediction. In this work, we discuss the method to represent a book as a spectrum of concepts based on the association score between its content embedding and a global embedding (i.e. fastText) for a set of semantically linked word clusters. We show that the semantic word associations outperform the previous methods for book success prediction. In addition, we present that semantic word associations also provide better results than using features like the frequency of word groups in Roget’s thesaurus, LIWC (a popular tool for linguistic inquiry and word count), NRC (word association emotion lexicon), and part of speech (PoS). Our study reports that concept associations based on Roget’s Thesaurus using word embedding of individual novel resulted in the state-of-the-art performance of 0.89 average weighted F1-score for book success prediction. Finally, we present a set of dominant themes that contribute towards the popularity of a book for a specific genre.', 'fr': "De nombreux nouveaux livres sont publiés chaque année, et seule une fraction d'entre eux devient populaire auprès des lecteurs. La prédiction du succès d'un livre peut donc être un paramètre très utile pour permettre aux éditeurs de prendre une décision fiable. Cet article présente l'étude des associations de mots sémantiques à l'aide de l'intégration de mots dans le contenu d'un livre pour un ensemble de concepts de thésaurus de Roget pour la prédiction du succès des livres. Dans ce travail, nous discutons de la méthode pour représenter un livre sous la forme d'un spectre de concepts basé sur le score d'association entre son intégration de contenu et une intégration globale (c'est-à-dire FastText) pour un ensemble de groupes de mots liés sémantiquement. Nous montrons que les associations de mots sémantiques surpassent les méthodes précédentes de prédiction du succès des livres. De plus, nous présentons que les associations de mots sémantiques fournissent également de meilleurs résultats que l'utilisation de fonctionnalités telles que la fréquence des groupes de mots dans le thésaurus de Roget, LIWC (un outil populaire pour la recherche linguistique et le décompte de mots), le NRC (lexique des émotions des associations de mots) et les parties de la parole (PoS). Notre étude rapporte que les associations de concepts basées sur le thésaurus de Roget utilisant l'intégration de mots dans un roman individuel ont permis d'obtenir des performances de pointe d'un score F1 pondéré moyen de 0,89 pour la prédiction du succès des livres. Enfin, nous présentons un ensemble de thèmes dominants qui contribuent à la popularité d'un livre pour un genre spécifique.", 'ar': 'يتم نشر العديد من الكتب الجديدة كل عام ، ولا يحظى سوى جزء صغير منها بشعبية كبيرة بين القراء. لذا فإن توقع نجاح الكتاب يمكن أن يكون معيارًا مفيدًا جدًا للناشرين لاتخاذ قرار موثوق. تقدم هذه المقالة دراسة ارتباطات الكلمات الدلالية باستخدام كلمة تضمين محتوى الكتاب لمجموعة من مفاهيم روجيت لقاموس المرادفات للتنبؤ بنجاح الكتاب. في هذا العمل ، نناقش طريقة تمثيل الكتاب كطيف من المفاهيم بناءً على درجة الارتباط بين تضمين المحتوى والتضمين العالمي (أي النص السريع) لمجموعة من مجموعات الكلمات المرتبطة دلاليًا. نظهر أن ارتباطات الكلمات الدلالية تتفوق على الأساليب السابقة للتنبؤ بنجاح الكتاب. بالإضافة إلى ذلك ، نقدم أيضًا أن ارتباطات الكلمات الدلالية توفر أيضًا نتائج أفضل من استخدام ميزات مثل تكرار مجموعات الكلمات في قاموس روجيت ، LIWC (أداة شائعة للاستعلام اللغوي وعدد الكلمات) ، NRC (معجم العاطفة لترابط الكلمات) ، وجزء من الكلام (PoS). تشير دراستنا إلى أن ارتباطات المفاهيم القائمة على قاموس روجيت المرادفات باستخدام تضمين كلمة في الرواية الفردية أدت إلى أحدث أداء بلغ 0.89 متوسط درجة F1 مرجحة للتنبؤ بنجاح الكتاب. أخيرًا ، نقدم مجموعة من الموضوعات السائدة التي تساهم في زيادة شعبية كتاب لنوع معين.', 'es': 'Cada año se publican muchos libros nuevos, y solo una fracción de ellos se hace popular entre los lectores. Así que la predicción del éxito de un libro puede ser un parámetro muy útil para que los editores tomen una decisión fiable. Este artículo presenta el estudio de las asociaciones de palabras semánticas utilizando la incrustación de palabras en el contenido del libro para un conjunto de conceptos de tesauro de Roget para la predicción del éxito del libro. En este trabajo, discutimos el método para representar un libro como un espectro de conceptos basado en la puntuación de asociación entre su incrustación de contenido y una incrustación global (es decir, FastText) para un conjunto de grupos de palabras enlazados semánticamente. Mostramos que las asociaciones de palabras semánticas superan a los métodos anteriores para la predicción del éxito de los libros. Además, presentamos que las asociaciones semánticas de palabras también proporcionan mejores resultados que el uso de funciones como la frecuencia de los grupos de palabras en el tesauro de Roget, LIWC (una herramienta popular para la investigación lingüística y el recuento de palabras), NRC (léxico de emociones de asociación de palabras) y parte del habla (PoS). Nuestro estudio informa que las asociaciones de conceptos basadas en el Thesaurus de Roget que utilizan la incorporación de palabras de novelas individuales dieron como resultado un rendimiento de última generación de 0,89 puntaje F1 ponderado promedio para la predicción del éxito del libro. Finalmente, presentamos un conjunto de temas dominantes que contribuyen a la popularidad de un libro para un género específico.', 'pt': 'Muitos livros novos são publicados todos os anos, e apenas uma fração deles se torna popular entre os leitores. Assim, a previsão do sucesso de um livro pode ser um parâmetro muito útil para as editoras tomarem uma decisão confiável. Este artigo apresenta o estudo de associações semânticas de palavras usando a incorporação de palavras de conteúdo de livros para um conjunto de conceitos de tesauro de Roget para previsão de sucesso de livros. Neste trabalho, discutimos o método para representar um livro como um espectro de conceitos baseado na pontuação de associação entre sua incorporação de conteúdo e uma incorporação global (ou seja, fastText) para um conjunto de clusters de palavras semanticamente vinculados. Mostramos que as associações semânticas de palavras superam os métodos anteriores para previsão de sucesso de livros. Além disso, apresentamos que as associações semânticas de palavras também fornecem melhores resultados do que o uso de recursos como a frequência de grupos de palavras no tesauro de Roget, LIWC (uma ferramenta popular para pesquisa linguística e contagem de palavras), NRC (léxico de emoção de associação de palavras) e parte do fala (PoS). Nosso estudo relata que as associações de conceito baseadas no Thesaurus de Roget usando a incorporação de palavras de romances individuais resultaram no desempenho de última geração de 0,89 pontuação F1 média ponderada para previsão de sucesso do livro. Por fim, apresentamos um conjunto de temas dominantes que contribuem para a popularidade de um livro para um gênero específico.', 'ja': '毎年多くの新書が出版され、読者の間で人気が出ているのはごく一部である。 したがって、本の成功を予測することは、出版社が信頼できる決定を下すために非常に有用なパラメータになる可能性があります。 この記事では、書籍の成功予測のためのRogetの類義語辞典の概念のセットについて、書籍コンテンツの単語埋め込みを使用した意味論的な単語関連付けの研究を紹介します。 この研究では、意味的にリンクされた単語クラスタのセットについて、そのコンテンツ埋め込みとグローバル埋め込み（すなわち、fastText ）の間の関連スコアに基づいて、概念のスペクトルとして本を表す方法について説明します。 意味論的な単語の関連付けは、書籍の成功予測の以前の方法を上回っていることを示しています。 さらに、意味論的な単語の関連付けは、Rogetの類義語辞典、LIWC （言語学的な探究と単語数のための一般的なツール）、NRC （単語の関連付けの感情語彙）、および発話の一部（ PoS ）における単語グループの頻度のような特徴を使用するよりも良い結果をもたらすことを提示する。 私たちの研究では、個々の小説の単語埋め込みを使用したRogetの類義語辞典に基づく概念の関連付けが、書籍の成功予測のための0.89の平均加重F 1スコアの最先端のパフォーマンスをもたらしたことが報告されています。 最後に、特定のジャンルの本の人気に貢献する一連の支配的なテーマを提示します。', 'hi': 'हर साल कई नई किताबें प्रकाशित होती हैं, और उनमें से केवल एक अंश पाठकों के बीच लोकप्रिय हो जाता है। तो एक पुस्तक की सफलता की भविष्यवाणी प्रकाशकों के लिए एक विश्वसनीय निर्णय लेने के लिए एक बहुत ही उपयोगी पैरामीटर हो सकती है। यह लेख पुस्तक की सफलता की भविष्यवाणी के लिए रोगेट की थिसॉरस अवधारणाओं के एक सेट के लिए पुस्तक सामग्री के एम्बेडिंग शब्द का उपयोग करके शब्दार्थ शब्द संघों का अध्ययन प्रस्तुत करता है। इस काम में, हम एक पुस्तक को अवधारणाओं के स्पेक्ट्रम के रूप में प्रतिनिधित्व करने की विधि पर चर्चा करते हैं, जो इसकी सामग्री एम्बेडिंग और एक वैश्विक एम्बेडिंग (यानी fastText) के बीच एसोसिएशन स्कोर के आधार पर शब्दार्थ रूप से जुड़े शब्द समूहों के एक सेट के लिए है। हम दिखाते हैं कि शब्दार्थ शब्द संघों पुस्तक सफलता की भविष्यवाणी के लिए पिछले तरीकों से बेहतर प्रदर्शन करते हैं। इसके अलावा, हम प्रस्तुत करते हैं कि शब्दार्थ शब्द संघ भी रोगेट के थिसॉरस में शब्द समूहों की आवृत्ति, LIWC (भाषाई जांच और शब्द गणना के लिए एक लोकप्रिय उपकरण), NRC (शब्द संघ भावना शब्दकोश), और भाषण (पीओएस) के हिस्से जैसी सुविधाओं का उपयोग करने की तुलना में बेहतर परिणाम प्रदान करते हैं। हमारे अध्ययन की रिपोर्ट है कि व्यक्तिगत उपन्यास के शब्द एम्बेडिंग का उपयोग करके रोगेट के थिसॉरस पर आधारित अवधारणा संघों के परिणामस्वरूप पुस्तक की सफलता की भविष्यवाणी के लिए 0.89 औसत भारित एफ 1-स्कोर के अत्याधुनिक प्रदर्शन का परिणाम हुआ। अंत में, हम प्रमुख विषयों का एक सेट प्रस्तुत करते हैं जो एक विशिष्ट शैली के लिए एक पुस्तक की लोकप्रियता में योगदान करते हैं।', 'ru': 'Многие новые книги публикуются каждый год, и лишь небольшая их часть становится популярной среди читателей. Таким образом, предсказание успеха книги может быть очень полезным параметром для издателей, чтобы принять надежное решение. В данной статье представлено исследование семантических ассоциаций слов с использованием вложения слов книжного содержания для набора концепций тезауруса Роже для прогнозирования успеха книги. В этой работе мы обсуждаем метод представления книги как спектра понятий на основе оценки связи между встраиванием ее контента и глобальным встраиванием (т.е. fastText) для набора семантически связанных кластеров слов. Показано, что семантические ассоциации слов превосходят предыдущие методы предсказания успеха книги. Кроме того, мы представляем, что семантические ассоциации слов также дают лучшие результаты, чем использование таких функций, как частота групп слов в тезаурусе Роже, LIWC (популярный инструмент для лингвистических исследований и подсчета слов), NRC (лексикон эмоций ассоциации слов) и часть речи (PoS). Наше исследование сообщает, что концептуальные ассоциации, основанные на Тезаурусе Роже с использованием вложения слов отдельного романа, привели к современной производительности 0,89 средневзвешенного балла F1 для предсказания успеха книги. Наконец, мы представляем набор доминирующих тем, которые способствуют популярности книги для конкретного жанра.', 'zh': "每岁多新书出版,其中惟一小部在读者中甚受欢迎。 故图成之占,于出版商或至有用之参数,可以为可恃之决。 本文引用书单词嵌语义词关联研究,用于Roget书成占词库概。 议以群语义链接词簇嵌(即fastText)联分数为一书。 臣等明之,语义词联优于前书成算之术。 此外,臣等以为语义词联亦比Roget词库中词组频率,LIWC(于语言询访,字数计行具),NRC(词关情词典)词性(PoS)等事。 臣等考言,盖Roget's Thesaurus之概关联用单小说词嵌致0.89均加权F1分数之最先进者,书成占之。 最后,我们发出一朋主导主题,这些主题有助于特定类的书籍流行。", 'ga': 'Foilsítear go leor leabhar nua gach bliain, agus ní bhíonn ráchairt ach ar chodán díobh i measc na léitheoirí. Mar sin d’fhéadfadh sé a bheith ina pharaiméadar an-úsáideach chun rath leabhar a thuar d’fhoilsitheoirí chun cinneadh iontaofa a dhéanamh. Cuireann an t-alt seo i láthair an staidéar ar chomhcheangail shéimeantacha focal ag baint úsáide as leabú focal ábhar leabhair le haghaidh sraith de choincheapa teasáras Roget chun rath leabhar a thuar. Sa saothar seo, pléimid an modh chun leabhar a léiriú mar speictream coincheap atá bunaithe ar an scór comhlachais idir leabú an ábhair agus leabú domhanda (i.e. fastText) do shraith de bhraislí focal atá nasctha go séimeantach. Léirímid go sáraíonn cumainn na bhfocal shéimeantach na modhanna roimhe seo chun rathúlacht na leabhar a thuar. Ina theannta sin, cuirimid i láthair go soláthraíonn comhlachais shéimeantacha focal torthaí níos fearr freisin ná úsáid a bhaint as gnéithe cosúil le minicíocht na ngrúpaí focal i dtásáras Roget, LIWC (uirlis choitianta le haghaidh fiosrúchán teanga agus líon focal), NRC (foclóir mothúcháin comhlachais focal), agus cuid de. cainte (PoS). Tuairiscíonn ár staidéar gur eascair feidhmíocht úrscothach de 0.89 meánscór F1 ualaithe le haghaidh tuar rathúlachta leabhar mar gheall ar chomhlachais choincheapa a bhí bunaithe ar Theasáras Roget ag baint úsáide as leabú focal ar úrscéalta aonair. Ar deireadh, cuirimid i láthair sraith de théamaí ceannasacha a chuireann leis an éileamh atá ar leabhar do seánra ar leith.', 'el': 'Πολλά νέα βιβλία δημοσιεύονται κάθε χρόνο, και μόνο ένα κλάσμα από αυτά γίνεται δημοφιλές μεταξύ των αναγνωστών. Έτσι, η πρόβλεψη της επιτυχίας ενός βιβλίου μπορεί να είναι μια πολύ χρήσιμη παράμετρος για τους εκδότες για να πάρουν μια αξιόπιστη απόφαση. Αυτό το άρθρο παρουσιάζει τη μελέτη των σημασιολογικών συσχετισμών λέξεων χρησιμοποιώντας τη λέξη ενσωμάτωση περιεχομένου βιβλίου για ένα σύνολο εννοιών θησαυρού του Ρότζετ για την πρόβλεψη επιτυχίας βιβλίων. Στην παρούσα εργασία, συζητάμε τη μέθοδο αναπαράστασης ενός βιβλίου ως φάσματος εννοιών με βάση τη βαθμολογία συσχέτισης μεταξύ της ενσωμάτωσης περιεχομένου του και μιας καθολικής ενσωμάτωσης (δηλαδή του γρήγορου κειμένου) για ένα σύνολο σημασιολογικά συνδεδεμένων συλλόγων λέξεων. Δείχνουμε ότι οι σημασιολογικές ενώσεις λέξεων ξεπερνούν τις προηγούμενες μεθόδους πρόβλεψης επιτυχίας βιβλίων. Επιπλέον, παρουσιάζουμε ότι οι σημασιολογικές ενώσεις λέξεων παρέχουν επίσης καλύτερα αποτελέσματα από τη χρήση χαρακτηριστικών όπως η συχνότητα των ομάδων λέξεων στο θησαυρό του Ρότζετ, το LIWC (ένα δημοφιλές εργαλείο γλωσσικής έρευνας και μέτρησης λέξεων), το NRC (λεξικό συναισθημάτων σύνδεσης λέξεων) και το μέρος της ομιλίας (PoS). Η μελέτη μας αναφέρει ότι οι συσχετισμοί εννοιών που βασίζονται στο Θησαυρό του Ρότζετ με τη χρήση λέξεων ενσωμάτωσης μεμονωμένου μυθιστορήματος είχαν ως αποτέλεσμα την υπερσύγχρονη απόδοση του μέσου σταθμισμένου βαθμού F1 για την πρόβλεψη επιτυχίας του βιβλίου. Τέλος, παρουσιάζουμε ένα σύνολο κυρίαρχων θεμάτων που συμβάλλουν στη δημοτικότητα ενός βιβλίου για ένα συγκεκριμένο είδος.', 'it': "Molti nuovi libri vengono pubblicati ogni anno, e solo una frazione di essi diventa popolare tra i lettori. Quindi la previsione del successo di un libro può essere un parametro molto utile per gli editori per prendere una decisione affidabile. Questo articolo presenta lo studio delle associazioni semantiche di parole che utilizzano la parola incorporazione del contenuto del libro per una serie di concetti del thesaurus di Roget per la previsione del successo del libro. In questo lavoro, discutiamo il metodo per rappresentare un libro come uno spettro di concetti basati sul punteggio di associazione tra il suo embedding dei contenuti e un embedding globale (cioè fastText) per un insieme di cluster di parole semanticamente collegati. Mostriamo che le associazioni semantiche delle parole superano i metodi precedenti per la previsione del successo del libro. Inoltre, presentiamo che le associazioni semantiche di parole forniscono risultati migliori rispetto all'uso di caratteristiche come la frequenza dei gruppi di parole nel thesaurus di Roget, LIWC (uno strumento popolare per l'indagine linguistica e il conteggio di parole), NRC (lessico emotivo di associazione di parole) e parte del discorso (PoS). Il nostro studio riporta che le associazioni concettuali basate sul Thesaurus di Roget che utilizzano l'incorporazione di parole di singoli romanzi hanno portato alla performance all'avanguardia di 0,89 media ponderata F1-score per la previsione del successo del libro. Infine, presentiamo una serie di temi dominanti che contribuiscono alla popolarità di un libro per un genere specifico.", 'ka': 'ბევრი ახალი წიგნი ყოველ წლის განახლება, და მხოლოდ ერთი წიგნი იყო პოლიპური წიგნის შორის. ასე რომ წიგნის წარმატების წარმატება შეიძლება მნიშვნელოვანი პარამეტრი გამოსახულებელებისთვის გავაკეთოთ დარწმუნებელი წარმატება. ეს წესტილის შესახებ სემონტიკური სიტყვების აზოციაციების სწავლას, როგორც წიგნის შემდგენელობის შემდგენელობის სიტყვების გამოყენება როგორეტის ცესაპუზის კონ ამ სამუშაოში, ჩვენ განსხვავებთ წიგნის გამოსახულება როგორც კონფექტების სპექტრმი, როგორც აციოციაციის წიგნის შესახებ და გლობალური ინბექტირება (მაგალითად fastText) სემონტიკურად დაკავშირებული ჩვენ ჩვენ აჩვენებთ, რომ სემონტიკური სიტყვების აზოციაციები უფრო გავაკეთებენ წინასწარმოდგენისთვის წინასწარმოდგენისთვის. დამატებით, ჩვენ აჩვენებთ, რომ სემონტიკური სიტყვის შესაძლებლობაც უკეთესი წარმოდგენება, ვიდრე როგორც პროგეტის ტესასურში სიტყვის ჯგუფის სიტყვის სიტყვის სიტყვის სიტყვის სიტყვის სიტყვის სიტყვის სიტყვის სიტყვის სი ჩვენი სწავლის შესახებ, რომ პოგენტის ტესასორუსის დაბაზეული კონცექტური აზოციაციები გამოყენებული სიტყვას, რომელიც ინდიველური პრომენტის შესახებ გამოყენებული სიტყვას შემდეგ 0,89 წლის სიტყვას საბოლოოდ, ჩვენ ჩვენ აჩვენებთ დომინტების რაოდენობა, რომელსაც წიგნის პოლუგარიტებისთვის სპექტიფიკური გენერისთვის.', 'hu': 'Sok új könyv jelenik meg évente, és csak töredéke válik népszerűvé az olvasók körében. Tehát egy könyv sikerének előrejelzése nagyon hasznos paraméter lehet a kiadók számára, hogy megbízható döntést hozzanak. Ez a cikk bemutatja a szemantikai szóasszociációk tanulmányozását, amelyek a könyvtartalom beágyazása szót használják Roget szótárjainak előrejelzésére. Ebben a munkában azt a módszert vitatjuk meg, hogy egy könyvet a tartalom beágyazása és a globális beágyazás (azaz fastText) közötti asszociációs pontszámon alapuló koncepciók spektrumaként reprezentáljuk. Megmutatjuk, hogy a szemantikus szóasszociációk felülmúlják a könyv sikeres előrejelzésének korábbi módszereit. Ezenkívül bemutatjuk, hogy a szemantikus szóasszociációk is jobb eredményeket nyújtanak, mint például a Roget szótárjában található szócsoportok gyakorisága, LIWC (a nyelvi kutatás és szószámlálás népszerű eszköze), NRC (szóasszociációs érzelmi lexikon) és a beszéd része (PoS). Tanulmányunk szerint Roget Thezauruszán alapuló koncepciós asszociációk az egyes regények szóbeágyazásával eredményezték a legkorszerűbb teljesítményt 0,89 átlagos súlyozott F1 pontszámot a könyv sikeres előrejelzéséhez. Végül bemutatunk egy sor domináns témát, amelyek hozzájárulnak egy könyv népszerűségéhez egy adott műfajhoz.', 'lt': "Many new books get published every year, and only a fraction of them become popular among the readers.  Taigi knygos sėkmės prognozė gali būti labai naudinga leidėjams priimti patikimą sprendimą. Šiame straipsnyje pateikiamas semantinių žodžių asociacijų tyrimas, naudojantis žodžiu įrašyti knygos turinį Roget tezauro koncepcijoms knygos s ėkmės prognozėms. In this work, we discuss the method to represent a book as a spectrum of concepts based on the association score between its content embedding and a global embedding (i.e. fastText) for a set of semantically linked word clusters.  We show that the semantic word associations outperform the previous methods for book success prediction.  Be to, mes pristatome, kad semantinės žodžių asociacijos taip pat teikia geresnius rezultatus nei naudoja tokius požymius kaip žodžių grupių dažnis Roget tezauruse, LIWC (populiarus įrankis kalbiniam tyrimui ir žodžių skaičiui), NRC (žodžių asociacijos emocijų leksikonas) ir kalbos dalis (PoS). Our study reports that concept associations based on Roget's Thesaurus using word embedding of individual novel resulted in the state-of-the-art performance of 0.89 average weighted F1-score for book success prediction.  Finally, we present a set of dominant themes that contribute towards the popularity of a book for a specific genre.", 'kk': 'Әр жыл көп жаңа кітаптар шығарылады, олардың бірнеше бөлігі оқушылардың арасындағы көптеген. Бұл кітаптардың сәттілігін бақылау үшін басып шығарушыларға сенімді шешім беру үшін өте пайдалы параметр болуы мүмкін. Бұл мақала рогеттің тесаурусының бағдарламасының сәттілігін бақылау үшін семантикалық сөздер қосымшаларының зерттеулерін көрсетеді. Бұл жұмыс ішінде, біз кітапшаны семантикалық тіркелген сөз кластері арасындағы мазмұны ендіру мен жүйелік ендіру (т. е. FastText) сәйкестіктерінің сәйкестіктері ретінде көрсету әдісін сәйкестік ретінде талқылады Біз семантикалық сөздердің байланыстары кітаптардың сәттілігін бақылау арқылы алдыңғы әдістерді орындайды. Қосымша, біз семантикалық сөздердің байланыстары Рогеттің тесаурысындағы сөздер топтардың жиілігі, LIWC (лингвистикалық сұрақтар мен сөздер саны үшін мәліметтік құралы), NRC (сөздердің байланыстыру эмоциялық лексикалық) және сөздердің бөлі Біздің зерттеулеріміз Рогет тесаурусына негізделген концепциялық құрылымдар, әрбір романдың сөздерін ендіру арқылы, 0,89 жылдамдығының орташа жұмыс істеу арқылы, кітаптардың сәтті бағалау үшін, орта Соңғы сәтте, біз бір кітаптың бір жанры үшін көмектесетін доминистік нақыштарды таңдаймыз.', 'ml': 'എല്ലാ വര്\u200dഷവും പുതിയ പുസ്തകങ്ങള്\u200d പ്രസിദ്ധീകരിക്കുന്നു. പിന്നെ വായിക്കുന്നവരുടെ കൂട്ടത്തില്\u200d ഒരു പ്ര അതുകൊണ്ട് ഒരു പുസ്തകത്തിന്റെ വിജയം പ്രവചിക്കുന്നത് വിശ്വസ്തനായ ഒരു തീരുമാനം പ്രസിദ്ധിക്കാന്\u200d വളരെ ഉപയോ ഈ രേഖയില്\u200d ഒരു കൂട്ടം റോജെറ്റിന്റെ തിയോസറുകളുടെ പുസ്തകത്തിന് വിജയം പ്രവചിപ്പിക്കാനുള്ള വാക്കുകളുടെ ഉള്\u200dപ്പെടുത്തി ഈ പ്രവൃത്തിയില്\u200d, ഒരു പുസ്തകത്തെ പ്രതിനിധിക്കാനുള്ള രീതിയില്\u200d നാം സംസാരിക്കുന്നു. അതിന്റെ ഉള്ളടക്കത്തിന്റെ സ്കോര്\u200dട്ട് അടിസ്ഥാനമായി സംസാരിക്കുന്ന ആശയങ We show that the semantic word associations outperform the previous methods for book success prediction.  കൂടാതെ, സെമാന്റിക് വാക്കുകളുടെ സമൂഹങ്ങളും റോജെറ്റിന്റെ തിയോസറുകളിലെ വാക്ക് ഗ്രൂപ്പുകളുടെ ഫ്രെയിന്\u200dസ് പോലെ ഉപയോഗിക്കുന്നതിനേക്കാള്\u200d നല്ല ഫലങ്ങള്\u200d നല്\u200dകുന്നു ഞങ്ങളുടെ പഠനത്തില്\u200d റോജെറ്റിന്\u200dറെ തീസോറസിന്\u200dറെ അടിസ്ഥാനത്തുള്ള ആശയങ്ങള്\u200d സംബന്ധിച്ചിടത്തോളം വ്യക്തിപരമായ നോവലിന്\u200dറെ വാക്കുകള്\u200d ഉപയോഗിച്ച് വാക്ക് പ് അവസാനം, ഒരു പ്രത്യേക ജീവിതത്തിന് ഒരു പുസ്തകത്തിന്\u200dറെ പ്രധാനപ്പെട്ടത്തിലേക്ക് സഹായിക്കുന്ന ഒരു കൂട്ടം മാ', 'ms': "Many new books get published every year, and only a fraction of them become popular among the readers.  Jadi ramalan kejayaan buku boleh menjadi parameter yang sangat berguna bagi penerbit untuk membuat keputusan yang boleh dipercayai. Artikel ini memperkenalkan kajian perusahaan perkataan semantik menggunakan perkataan penyampaian kandungan buku untuk set konsep tesaurus Roget untuk ramalan kejayaan buku. Dalam kerja ini, kita membincangkan kaedah untuk mewakili sebuah buku sebagai spektrum konsep berdasarkan skor asosiasi antara penyembedding kandungannya dan penyembedding global (iaitu fastText) untuk set kelompok perkataan yang terhubung secara semantik. Kami menunjukkan bahawa persatuan kata semantik melampaui kaedah terdahulu untuk ramalan kejayaan buku. In addition, we present that semantic word associations also provide better results than using features like the frequency of word groups in Roget's thesaurus, LIWC (a popular tool for linguistic inquiry and word count), NRC (word association emotion lexicon), and part of speech (PoS).  Pelajaran kami melaporkan bahawa persekutuan konsep berdasarkan Thesaurus Roget menggunakan perkataan penyembedding novel individu menghasilkan prestasi state-of-the-art 0.89 nilai F1 berlebihan rata-rata untuk ramalan kejayaan buku. Akhirnya, kami memperkenalkan satu set tema dominan yang menyumbangkan kepada popularitas buku untuk jenis tertentu.", 'mt': "Ħafna kotba ġodda jiġu ppubblikati kull sena, u frazzjoni biss minnhom isiru popolari fost il-qarrejja. So the prediction of a book success can be a very useful parameter for publishers to make a reliable decision.  This article presents the study of semantic word associations using the word embedding of book content for a set of Roget's thesaurus concepts for book success prediction.  F’dan ix-xogħol, niddiskutu l-metodu biex nirrappreżentaw ktieb bħala spettru ta’ kunċetti bbażati fuq il-punteġġ ta’ assoċjazzjoni bejn l-inkorporazzjoni tal-kontenut tiegħu u inkorporazzjoni global i (jiġifieri fastText) għal sett ta’ raggruppamenti ta’ kliem marbuta semantikament. We show that the semantic word associations outperform the previous methods for book success prediction.  Barra minn hekk, nippreżentaw li assoċjazzjonijiet semantiċi tal-kelma jipprovdu wkoll riżultati a ħjar mill-użu ta’ karatteristiċi bħall-frekwenza tal-gruppi tal-kelma fit-tesauru ta’ Roget, LIWC (għodda popolari għall-inkjesta lingwistika u l-għadd tal-kelma), NRC (lexicon emozzjonali tal-assoċjazzjoni tal-kelma), u parti mid-diskors (PoS). Our study reports that concept associations based on Roget's Thesaurus using word embedding of individual novel resulted in the state-of-the-art performance of 0.89 average weighted F1-score for book success prediction.  Finally, we present a set of dominant themes that contribute towards the popularity of a book for a specific genre.", 'no': 'Mange nye bøker blir publisert kvar år, og berre ein brøk av dei blir populært blant lesarane. Så forhåndsvisinga av ein boksuksess kan vera ein veldig nyttig parameter for publiserande for å gjera eit betrig beslutning. Denne artikkelen viser studien av semantiske ordassociasjonar ved å bruka ord innebygd av bokinnhaldet for eit sett av Roget sin teoruskonseptar for å foregå boksuksess. I denne arbeida diskuterer vi metoden for å representera ein bok som spektrum av konseptar basert på tilknytingspoeng mellom innhaldet og eit globalt innbygging (t.d. fastText) for eit sett av semantisk lenka ordklassar. Vi viser at semantiske ordassociasjonane utfører dei førre metodane for å foregå boksuksess. I tillegg viser vi at semantiske ordassociasjonar også gjev bedre resultat enn å bruka funksjonar som frekvensen av ordgrupper i Roget s in tesaurus, LIWC (eit populært verktøy for sprøytebruk og ordtale), NRC (ordassociasjon emosjon lexicon) og del av tale (PoS). Våre studie rapporterer at konseptassosisjonane basert på Roget s in Thesaurus ved å bruka ord innebygd av individuelle roman resulterte i tilstanden av kunsten til 0,89 gjennomsnittsverket F1-poeng for å foregå boksuksess. I slutt presenterer vi eit sett av dominerande tema som bidrar til populariteten av eit bok for eit spesifikke genre.', 'pl': 'Co roku wydaje się wiele nowych książek, a tylko ułamek z nich staje się popularny wśród czytelników. Tak więc przewidywanie sukcesu książki może być bardzo przydatnym parametrem dla wydawców do podjęcia rzetelnej decyzji. W artykule przedstawiono badanie semantycznych skojarzeń słów z wykorzystaniem osadzenia treści książek dla zbioru koncepcji tezaura Rogeta do prognozowania sukcesu książki. W niniejszej pracy omówiono metodę reprezentowania książki jako spektrum pojęć opartą na wyniku skojarzenia pomiędzy jej osadzeniem treści a globalnym osadzeniem (tj. fastText) dla zestawu semantycznie powiązanych klastrów słów. Pokazujemy, że semantyczne skojarzenia słów przewyższają poprzednie metody przewidywania sukcesu książek. Ponadto przedstawiamy, że semantyczne skojarzenia słów również zapewniają lepsze wyniki niż stosowanie funkcji takich jak częstotliwość występowania grup słów w tezaurze Rogeta, LIWC (popularne narzędzie do badań językowych i liczby słów), NRC (leksykon skojarzeń emocji słowa) i część mowy (PoS). Z naszego badania wynika, że skojarzenia koncepcyjne oparte na tezaurze Rogeta przy użyciu osadzenia słów indywidualnej powieści zaowocowały najnowocześniejszą wydajnością średniego ważonego punktu F1 0.89 dla przewidywania sukcesu książki. Na koniec przedstawiamy zestaw dominujących tematów, które przyczyniają się do popularności książki dla konkretnego gatunku.', 'mk': "Многу нови книги се објавуваат секоја година, а само дел од нив стануваат популарни меѓу читателите. Значи предвидувањето на успехот на книгата може да биде многу корисен параметр за издавачите да донесат доверлива одлука. This article presents the study of semantic word associations using the word embedding of book content for a set of Roget's thesaurus concepts for book success prediction.  Во оваа работа, разговараме за методот за претставување на книгата како спектар на концепти базиран на оценката на асоцијација помеѓу нејзиното вградување на содржината и глобалното вградување (т.е. fastText) за семантично поврзани зборови групи. We show that the semantic word associations outperform the previous methods for book success prediction.  Покрај тоа, претставуваме дека семантичките зборни здруженија, исто така, обезбедуваат подобри резултати отколку користењето на карактеристики како фреквенцијата на зборните групи во ресаурусот на Рогет, ЛИВЦ (популарна алатка за лингвистичко истражување и броење зборови), НРЦ (зборна здруженост емоцио Нашата студија известува дека концептските асоцијации базирани на Тезаурусот на Рогет користејќи зборови вклучување на индивидуалниот роман резултираа со најновата изведба на 0,89 просечна тежирана оценка F1 за предвидување на успехот на книгата. Finally, we present a set of dominant themes that contribute towards the popularity of a book for a specific genre.", 'mn': 'Жил бүр олон шинэ ном хэвлэгддэг. Тэдний хэсэг нь уншигчид дунд алдартай болж байна. Тэгэхээр номын амжилтын таамаглал нь хэвлэгчид итгэлтэй шийдвэр гаргах үнэхээр ашигтай параметр болно. Энэ сэтгүүл нь рогеттын амжилтын таамаглалтын төлөвлөгөөнд номын сорилтуудыг ашиглан семантик үгийн байгууллагуудын судалгааг илэрхийлж байна. Энэ ажлын хувьд бид нэг номыг нэг төрлийн ойлголтын спектр гэж үзүүлэх аргыг хэлэлцдэг. Энэ бүхнийг солилцоогоор хамтын тоо болон дэлхийн солилцоогоор холбогдох (т.е. fastText) хэдэн семантийн холбогдсон үгний кластеруудын Бид анхны үг холбоотой байгууллагууд номын амжилтын таамаглалтын аргыг илүү өнгөрүүлдэг. Мөн бид рогеттын тесаур, LIWC (хэлний судалгаа, хэлний тоо гэх мэт хүмүүс), NRC (үгний холбоотой сэтгэл хөдлөлийн лексикон) болон ярианы хэсгийг ашиглахаас илүү сайн үр дүнг өгдөг. Бидний судалгаанд Рогетын Тесаурусын үндсэн ойлголтын холбоотой байгууллагууд хэн нэгэн зохиолын нэгтгэлтэй үг ашиглан 0.89-ын урлагийн үйл ажиллагаанд номын амжилтын таамаглалтын дундаж хэмжээний F1 хэмжээний түвшинд орж ирсэн. Эцэст нь, бид нэг төрлийн жинхэнэ номын нэр төрөлхтний тулд давамгайлагч сэдвүүдийг тайлбарлаж байна.', 'sr': "Mnoge nove knjige se objavljuju svake godine, a samo dio njih postaje popularan među čitačima. Dakle predviđanje uspeha knjige može biti vrlo korisni parameter za izdavače da donesu pouzdanu odluku. Ovaj članak predstavlja studiju semantičkih udruženja riječima koristeći reč uključenje sadržaja knjiga za skup koncepta Rogetove tezaru za predviđanje uspeha knjiga. U ovom poslu razgovaramo o metodi da predstavljamo knjigu kao spektru koncepta na osnovu rezultata asocijacije između njegovog sadržaja ugrađenog i globalnog ugrađenja (tj. fastText) za setu semantički povezanih skupina riječi. Pokazujemo da semantičke udruženje riječi iznose prethodne metode predviđanja uspeha knjiga. Osim toga, predstavljamo da semantičke udruženje rijeèi takođe pružaju bolji rezultat nego koristiti karakteristike poput frekvencije reèi grupa u Rogetovom thesaurusu, LIWC (popularni alat za lingvistièko istraživanje i broj reèi), NRC (emocionalni leksikon reèi asocijacije), i deo govora (PoS). Naše studije izvještava da asocijacije koncepta bazirane na Roget's Thesaurus koristeći reč uključenje individualnog romana rezultirale su u stanju umjetnosti 0,89 prosječne težine F1 rezultata za predviđanje uspeha knjiga. Konačno predstavljamo set dominantnih tema koji doprinose popularnosti knjige za određeni genr.", 'ro': 'Multe cărți noi sunt publicate în fiecare an și doar o fracțiune dintre ele devin populare printre cititori. Astfel, predicția succesului unei cărți poate fi un parametru foarte util pentru editori pentru a lua o decizie fiabilă. Acest articol prezintă studiul asocierilor semantice de cuvinte folosind cuvântul încorporare a conținutului cărții pentru un set de concepte de tezaur Roget pentru predicția succesului cărții. În această lucrare, discutăm metoda de a reprezenta o carte ca un spectru de concepte bazate pe scorul de asociere dintre încorporarea conținutului său și o încorporare globală (de exemplu fastText) pentru un set de clustere de cuvinte legate semantic. Arătăm că asociațiile semantice de cuvinte depășesc metodele anterioare de predicție a succesului cărții. În plus, prezentăm că asociațiile semantice de cuvinte oferă, de asemenea, rezultate mai bune decât utilizarea caracteristicilor cum ar fi frecvența grupurilor de cuvinte în tezaurul lui Roget, LIWC (un instrument popular pentru investigarea lingvistică și numărul de cuvinte), NRC (lexicon emoțional asociere de cuvinte) și o parte a vorbirii (PoS). Studiul nostru raportează că asociațiile conceptuale bazate pe Tezaurul lui Roget folosind încorporarea cuvintelor de roman individual au rezultat în performanța de ultimă oră a scorului F1 ponderat mediu de 0,89 pentru predicția succesului cărții. În cele din urmă, prezentăm un set de teme dominante care contribuie la popularitatea unei cărți pentru un anumit gen.', 'si': "හැම අවුරුද්දක් අලුත් පොත් ප්\u200dරකාශ කරනවා, ඒ වගේම ඔවුන්ගේ කොටසක් විතරයි කියවන්නේ කියවන්නේ  ඉතින් පොතේ සාර්ථක විශ්වාස කරන්න පුළුවන් ප්\u200dරකාශකයන්ට විශ්වාස කරන්න ප්\u200dරයෝජනයක් වෙන්න පුළුවන මේ ලේඛනය පෙන්වන්නේ සෙමැන්ටික් වචන සම්බන්ධ වචන සම්බන්ධ වචන සම්බන්ධ වචන සඳහා රොජෙට්ගේ සාවුරුස් සැකසුම් සඳහ මේ වැඩේ අපි පොතේ පෙන්වන්න විදිහට කතා කරනවා ඒකේ සාමාන්\u200dය සංවේදනය සහ ජාතික සංවේදනය සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන අපි පෙන්වන්නේ සෙමාන්ටික් වචන සම්බන්ධය පොත්තුවේ සාර්ථක විදියට පුරානුවෙන් විදියට ප්\u200dරතික In add, we present that semantic word association a s well as use better scores than use the frefrequess of word Groups in Roget's Thesauros, LIWC (a Popular toolkit for language investigation and word number), NRC (word association emoticon lexico), and part of language (POS). අපේ පරීක්ෂණය වාර්තා කරනවා කියලා රෝජෙට්ස් තෙසෝරුස් වලට අධිරූපය විදියට පරීක්ෂණය සංවිධාන සංවිධාන සංවිධාන සංවිධාන සං අන්තිමේදී, අපි ප්\u200dරධාන විශේෂ තේමාවක් පෙනුම් කරනවා ඒ වගේම පොතේ ප්\u200dරධාන විශේෂ විශේෂ විශේෂ ව", 'so': "buugaagta cusub waxaa sanad la soo daabacaa, waxaadna ka mid tahay wax yar oo ka mid ah kuwa akhriya. Sidaa darteed wixii la sii sheegay liibaanka kitaabka oo dhan waxay noqon kartaa heer aad u faa’iido leh oo ay gaaraan go'aan aamin ah. Warqaddan wuxuu soo bandhigaa waxbarashada ururada semantika hadalka ee uu ku isticmaalayo erayga ku qoran qoraalka ku qoran qoraalka oo uu u sameeyo fikrada qoraalka ee Roget oo ku qoran liibaanta buugaagta. Markaas waxan, waxaynu ka sheekeynaynaa qaabka looga jeedo buug oo ku qoran fikrada, taas oo ku saleysan kooxda iskuulka ururka e e ku jirta iyo kooxaha caalamiga ah (tusaale ahaan fast Text) si loo qoro qoraal kamid ah oo isku xiran. Waxaynu muujinnaa in ururada hadalka semantika ah ay sameeyaan qaababka hore oo ku saabsan horumarinta liibaanka kitaabka. Intaas waxaa dheer oo aan soo wadannaa in ururada semantika ah ay sidoo kale ka heli karaan resulto ka wanaagsan isticmaalidda tusaale ahaan frequencies of word groups in Roget's thesaurus, LIWC (taas oo ah qalabka maaruf la xiriira luuqadaha iyo tirada hadalka), NRC (word association lexicon) iyo qayb ka mid ah hadalka (PoS). Waxbarashadannada ayaa wargelinaya in ururada fekerka ku saleysan Roget's Thesaurus ku saabsan hadal ku qoran warqada shakhsi ah ayaa sababtay xaaladda farshaxanka ugu dhexaysa 0.89 qiimaha guud ee F1-score oo ku qoran liibaanka. Ugu dambaysta, waxaynu keenaynaa maadooyin madax u ah oo ku caawinaya dadku buug qorniin gaar ah.", 'sv': 'Många nya böcker publiceras varje år, och bara en bråkdel av dem blir populära bland läsarna. Så förutsägelsen av en bokframgång kan vara en mycket användbar parameter för förläggare att fatta ett tillförlitligt beslut. Denna artikel presenterar studien av semantiska ordassociationer med hjälp av ordet inbäddning av bokinnehåll för en uppsättning av Rogets tesauruskoncept för bokframgångsprediktion. I detta arbete diskuterar vi metoden att representera en bok som ett spektrum av begrepp baserat på associationspoängen mellan dess innehållsinbäddning och en global inbäddning (dvs fastText) för en uppsättning semantiskt länkade ordkluster. Vi visar att de semantiska ordassociationerna överträffar de tidigare metoderna för bokframgångsprediktion. Dessutom presenterar vi att semantiska ordassociationer också ger bättre resultat än att använda funktioner som frekvensen av ordgrupper i Rogets tesaurus, LIWC (ett populärt verktyg för språklig undersökning och ordräkning), NRC (ordassociation emotion lexikon) och del av tal (PoS). Vår studie rapporterar att konceptassociationer baserade på Rogets Thesaurus med hjälp av ord inbäddning av enskilda romaner resulterade i toppmodern prestanda på 0,89 genomsnittlig viktad F1-poäng för bokframgångsprediktion. Slutligen presenterar vi en uppsättning dominerande teman som bidrar till populariteten av en bok för en specifik genre.', 'ta': "பல புதிய புத்தகங்கள் ஒவ்வொரு ஆண்டும் வெளியிடப்படுகின்றன, மற்றும் அவற்றில் ஒரு பிரிவு படிப்பாளர்களுக்கு  எனவே ஒரு புத்தகத்தின் வெற்றியை எதிர்பார்ப்பது ஒரு நம்பிக்கையான தீர்ப்பு எடுக்க ஒரு பயனுள்ள அளபுரு ஆகும். இந்த கட்டுரையில் புத்தகத்தின் உள்ளடக்கத்திற்கான வார்த்தையை பயன்படுத்தி புத்தகத்தின் உள்ளடக்கத்தை கொண்டு அரைந்திக் சொல்லு த இந்த வேலையில், நாம் ஒரு புத்தகத்தை புத்தகத்தை குறிப்பிடுவதற்கான முறையில் விவாதம் செய்து கொண்டிருக்கும் இணைப்பு புள்ளியின் குறிப்பிட்ட குறிப்பிட் நாம் காண்பிக்கிறோம் புத்தகத்தின் வெற்றி முன்னோட்டத்திற்கு அர்த்தமான சொல்லு அமைப்பு In addition, we present that semantic word associations also provide better results than using features like the frequency of word groups in Roget's thesaurus, LIWC (a popular tool for linguistic inquiry and word count), NRC (word association emotion lexicon), and part of speech (PoS).  எங்கள் ஆராய்ச்சி அறிக்கையில் ரோஜெட் தியூஸர் அடிப்படையில் கருத்து கூட்டும் சொல்லை உள்ளடக்கம் செய்து கொண்டுள்ளது புத்தகத்தின் வெற்றிகரமான முன்ன இறுதியில், நாம் ஒரு குறிப்பிட்ட மரத்திற்கு ஒரு புத்தகத்தின் மக்களுக்கு பங்கு செய்யும் மேலான தலைப்புகளை க", 'ur': 'بہت سی نوی کتابیں ہر سال منتشر کیے جاتے ہیں، اور ان میں سے صرف ایک حصہ پڑھنے والوں میں مشهور ہو جاتا ہے۔ تو ایک کتاب کی پیش بینی کامیابی کا ایک بہت فائدہ پارامیٹر ہے جو پھیلانے والوں کے لئے ایک قابل فیصلہ کریں۔ یہ لکھا ایک صحیح راجت کے تئزاروس نظریوں کے لئے کتاب موفقیت کی پیش بینی کے لئے لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہے۔ اس کام میں ہم نے ایک کتاب کی تصویر کی طریقہ سے بحث کیا ہے جو اس کے منصوبے میں جمع ہونے اور ایک گلوبی ابڈینگ (یعنی fastText) کے ساتھ ایک سیمنٹی لکھی ہوئی لکھی لکھی ہوئی لکھی لکھی ہوئی لکھی ہوئی لکھی لکھی ہوئی لکھی لکھی ہوئی لکھی لکھی ہوئی سٹم کے ہم دکھاتے ہیں کہ سامنٹی کلمات شرکت کتاب کے موفقیت کی پیش بینی کے لئے پہلے طریقے سے زیادہ کامل ہیں۔ اور اس کے علاوہ ہم نشان دیتے ہیں کہ سیمنٹی کلمات اتحادیوں نے بھی راجت کے ٹیسوروس میں کلمات گروہوں کے فرکانس کے مطابق بہترین نتیجے پہنچا دیتے ہیں۔ ہمارے مطالعہ کی گزارش یہ ہے کہ راجٹ کے تساروس پر بنیاد رکھے ہوئے مطالعہ تساروس کے متعلق کلمات کی مطالعہ کے مطالعہ کے ذریعے 0.89 آرت کی فعالیت کے نتیجے میں کتاب موفقیت کی پیش بینی کے لئے متوسط F1-اسکور کا وزن ہوا۔ بالآخر، ہم ایک مجموعہ مسائل کو پیش کرتے ہیں جو ایک خاص جنر کے لئے ایک کتاب کی جماعت کی حفاظت کرتی ہیں۔', 'uz': 'Ko\'pchilik yangi kitoblar har yilda nashr bo\'ladi, va ular o\'quvchilar orasidagi bir necha ko\'pchilik mashhur bo\'ladi. Xullas, kitob muvaffaqiyatlarining kutilganligi o\'zgarishlar uchun juda foydali parametr bo\'lishi mumkin. Bu maqola yordamida "Roget\'s thesaurus conceptlari" tuzuvlari uchun "book muvaffaqiyatli oldingan so\'zlar tarkibini ishlatiladi. Bu vazida, biz kitobni birga bog\'liq so\'zlar bilan birga bogʻliq so\'zlar tuzuvlarining tarkibi va global kengaytmalarning (m\'anaviy fast Text) tarkibini o\'zgartirish natijasida fikrlarni ajratish usuli haqida javob beramiz. Biz esa semantik so\'zlar tashkilotlari oldingi usullarni kitob muvaffaqiyatli oldini ishlab chiqaradi. Ko\'rib chiqqamiz, semantik so\'zlar qoidalari Roget\'s thesaurusidagi so\'zlar guruhlaridan foydalanishidan ham yaxshi natijalarni qo\'shiladi. LIWC (lingʻlik soʻrov va soʻzni qidirish uchun umumiy asbobi), NRC (tashkilotni hisoblash leksisiyoni) va gapirish qismidan bir qismi (PoS). Bizning taʼminlovchimiz haqida, Roget\'s Thesaurus asosida, oddiy novel yordamida so\'z tuzilishi mumkin, u 0.89 asosiy muvaffaqiyatlarni taqdim qilish uchun 0.89 ta\'minlovchi soʻzni o\'zgartiradi. Finally, we present a set of dominant themes that contribute towards the popularity of a book for a specific genre.', 'vi': "Nhiều sách mới được xuất bản mỗi năm, và chỉ một phần nhỏ trong số chúng trở nên phổ biến trong các độc giả. Nên dự đoán thành công sách có thể là một tham số rất hữu ích cho các nhà xuất bản để đưa ra quyết định đáng tin cậy. Bài viết này đưa ra nghiên cứu về các liên quan ngôn ngữ ngữ ngữ ngữ, s ử dụng từ'sự tác hợp nội dung sách'cho một bộ từ điển của Roget để dự đoán thành công sách. Trong công việc này, chúng ta thảo luận phương pháp tượng trưng cho một cuốn sách như một phổ biến các khái niệm dựa trên đi ểm kết hợp giữa sự nhúng nội dung của nó và một sự nhúng vào to àn cầu (tức là nhanh Text) cho một nhóm các từ được liên kết theo ngữ nghĩa. Chúng tôi cho thấy các từ ngữ ngữ ngữ thì chiếm lĩnh các phương pháp trước đây để dự đoán thành công sách. Thêm vào đó, chúng tôi giới thiệu rằng các tổ chức từ ngữ ngữ ngữ cũng có kết quả tốt hơn s ử dụng các tính năng như tần số các nhóm từ trong từ điển của Roget, LlW (một công cụ phổ biến để điều tra ngôn ngữ và đếm từ), NRC (ngôn ngữ cảm xúc từ ngôn ngữ) và một phần của ngôn ngữ (POS). Các nghiên cứu của chúng tôi báo cáo rằng các tổ chức khái niệm dựa trên Theseus của Roget s ử dụng sự nhúng vào từ từ của một quyển tiểu thuyết riêng đã tạo ra hiệu quả tuyệt vời 0.899 số đông đúc F1 để dự đoán thành công sách. Cuối cùng, chúng tôi giới thiệu một loạt các chủ đề chủ mưu đóng góp vào việc phổ biến một cuốn sách cho một thể loại cụ thể.", 'bg': 'Всяка година се публикуват много нови книги и само част от тях стават популярни сред читателите. Така че прогнозирането на успеха на една книга може да бъде много полезен параметър за издателите да вземат надеждно решение. Настоящата статия представя изучаването на семантичните словни асоциации, използвайки думата вграждане на съдържание на книга за набор от концепции за речник на Роже за прогнозиране на успеха на книгата. В тази работа обсъждаме метода за представяне на книга като спектър от концепции въз основа на асоциационния резултат между вграждането на съдържанието и глобалното вграждане (т.е. за набор от семантично свързани словни клъстери). Показваме, че семантичните асоциации на думи превъзхождат предишните методи за прогнозиране на успеха на книгите. В допълнение, представяме, че семантичните словни асоциации също дават по-добри резултати от използването на функции като честотата на словните групи в речника на Роже, популярен инструмент за лингвистично запитване и броене на думи, и част от речта. Нашето проучване докладва, че концептуалните асоциации, базирани на речника на Роже, използващи вграждане на думи в индивидуален роман, са довели до най-съвременното представяне на 0,89 среднопретеглена оценка за прогнозиране на успеха на книгата. Накрая, представяме набор от доминиращи теми, които допринасят за популярността на книга за конкретен жанр.', 'hr': "Mnoge nove knjige objavljuju svake godine, a samo dio njih postaje popularan među čitačima. Dakle predviđanje uspjeha knjige može biti vrlo korisni parameter za izdavače da donesu pouzdanu odluku. Ovaj članak predstavlja ispitivanje semantičkih udruženja riječima koristeći riječ uključenje sadržaja knjiga za skup Rogetovih teosauruskih koncepta za predviđanje uspjeha knjiga. U ovom poslu razgovaramo o metodi predstavljanja knjige kao spektr koncepta na temelju rezultata asocijacije između njegovog sadržaja ugrađenog i globalnog ugrađenja (tj. fastText) za skupinu semantički povezanih skupina riječi. Pokazujemo da semantičke udruženje riječi iznose prethodne metode predviđanja uspjeha knjiga. Osim toga, predstavljamo da semantičke udruženje riječi također pružaju bolji rezultat nego koristiti karakteristike poput učestalosti riječnih skupina u Rogetovom kazaru, LIWC (popularni alat za jezičko istraživanje i broj riječi), NRC (emocionalni leksikon pridruživanja riječi) i dio govora (PoS). Naše ispitivanje izvještava da udruženja koncepta bazirana na Roget's Thesaurus koristeći riječ uključujući individualni roman rezultirala je u stanju umjetnosti 0,89 prosječne težine F1 rezultata za predviđanje uspjeha knjiga. Konačno predstavljamo skup dominantnih tema koji doprinose popularnosti knjige za određeni genr.", 'nl': "Elk jaar verschijnen er veel nieuwe boeken, waarvan slechts een fractie populair wordt onder de lezers. De voorspelling van een boeksucces kan dus een zeer nuttige parameter zijn voor uitgevers om een betrouwbare beslissing te nemen. Dit artikel presenteert de studie van semantische woordassociaties met behulp van het woord inbedden van boekinhoud voor een set van Rogets thesaurusconcepten voor boeksuccesvoorspelling. In dit werk bespreken we de methode om een boek weer te geven als een spectrum van concepten op basis van de associatiescore tussen de inhoudelijke inbedding en een globale inbedding (d.w.z. fastText) voor een set semantisch gekoppelde woordclusters. We laten zien dat de semantische woordassociaties beter presteren dan de vorige methoden voor boeksuccesvoorspelling. Daarnaast presenteren we dat semantische woordassociaties ook betere resultaten opleveren dan het gebruik van functies als de frequentie van woordgroepen in Rogets thesaurus, LIWC (een populair hulpmiddel voor taalonderzoek en woordtelling), NRC (woordassociatie emotie lexicon) en deel van spraak (PoS). Onze studie meldt dat conceptassociaties gebaseerd op Rogets Thesaurus met behulp van woord embedding van individuele roman resulteerden in de state-of-the-art prestaties van 0.89 gemiddelde gewogen F1-score voor boeksuccesvoorspelling. Tot slot presenteren we een reeks dominante thema's die bijdragen aan de populariteit van een boek voor een bepaald genre.", 'de': 'Viele neue Bücher erscheinen jedes Jahr, und nur ein Bruchteil davon wird bei den Lesern beliebt. So kann die Vorhersage eines Bucherfolgs ein sehr nützlicher Parameter für Verlage sein, um eine verlässliche Entscheidung zu treffen. Dieser Artikel stellt die Untersuchung semantischer Wortassoziationen unter Verwendung der Worteinbettung von Buchinhalten für eine Reihe von Rogets Thesauruskonzepten für die Erfolgsvorhersage von Büchern vor. In dieser Arbeit diskutieren wir die Methode, ein Buch als Spektrum von Konzepten darzustellen, basierend auf dem Assoziationsscore zwischen seiner Inhaltseinbettung und einer globalen Einbettung (d.h. fastText) für eine Reihe semantisch verknüpfter Wortcluster. Wir zeigen, dass die semantischen Wortassoziationen die bisherigen Methoden zur Erfolgsvorhersage von Büchern übertreffen. Darüber hinaus zeigen wir, dass semantische Wortassoziationen auch bessere Ergebnisse liefern als Funktionen wie die Häufigkeit von Wortgruppen in Rogets Thesaurus, LIWC (ein beliebtes Werkzeug für linguistische Untersuchung und Wortzählung), NRC (Wortassoziation Emotion Lexikon) und Part of Speech (PoS). Unsere Studie berichtet, dass Konzeptassoziationen basierend auf Rogets Thesaurus unter Verwendung von Worteinbettungen einzelner Romane zu der State-of-the-Art Leistung des 0.89 durchschnittlichen gewichteten F1-Scores für die Erfolgsvorhersage von Büchern führten. Schließlich präsentieren wir eine Reihe dominanter Themen, die zur Popularität eines Buches für ein bestimmtes Genre beitragen.', 'id': 'Many new books get published every year, and only a fraction of them become popular among the readers.  Jadi prediksi sukses buku bisa menjadi parameter yang sangat berguna bagi penerbit untuk membuat keputusan yang dipercaya. Artikel ini memperlihatkan studi tentang asosiasi kata semantis menggunakan kata embedding konten buku untuk set konsep thesaurus Roget untuk prediksi sukses buku. Dalam pekerjaan ini, kami mendiskusikan metode untuk mewakili sebuah buku sebagai spektrum konsep berdasarkan skor asosiasi antara penyembedding isi dan penyembedding global (i.e. fastText) untuk set kelompok kata yang terhubung secara semantis. Kami menunjukkan bahwa asociasi kata semantis melebihi metode sebelumnya untuk prediksi sukses buku. Selain itu, kami mempersembahkan bahwa asosiasi kata semantis juga memberikan hasil yang lebih baik daripada menggunakan fitur seperti frekuensi kelompok kata dalam tesaur Roget, LIWC (alat populer untuk penyelidikan bahasa dan hitungan kata), NRC (leksikon emosi asosiasi kata), dan bagian dari pidato (PoS). Studi kami melaporkan bahwa konsep asosiasi berdasarkan Thesaurus Roget menggunakan kata embedding novel individu berasal dari prestasi state-of-the-art dari 0,89 nilai F1 berberat rata-rata untuk prediksi sukses buku. Akhirnya, kami mempersembahkan set tema dominan yang berkontribusi menuju popularitas sebuah buku untuk genre spesifik.', 'ko': '매년 많은 새 책이 출판되는데, 그 중 일부분만이 독자들의 환영을 받는다.따라서 한 권의 책에 대한 성공 예측은 출판사가 믿을 만한 결정을 내리는 데 매우 유용한 매개 변수가 될 수 있다.이 글은 어의어와 관련된 연구를 소개하고 단어로 삽입된 책 내용을 로지트의 동의어 라이브러리 개념에 대한 도서 성공 예측으로 소개했다.이 작업에서 우리는 의미 링크 어구의 내용 삽입과 전역 삽입 (즉fastText) 간의 관련 점수를 바탕으로 한 책을 일련의 개념으로 표현하는 방법을 토론했다.우리는 어의어가 도서의 성공률을 예측하는 데 있어서 이전의 방법보다 관련이 있다는 것을 발견했다.또한 의미어 연관성도 로거의 동의어 라이브러리에서 어구의 빈도, LIWC(유행하는 언어 조회와 글자수 통계 도구), NRC(단어 관련 감정 사전)와 어성(Pos) 등의 기능을 사용하는 것보다 더 좋은 결과를 제공하는 것으로 나타났다.우리의 연구 보고서에 따르면 로지트의 동의어 라이브러리의 개념 관련을 바탕으로 단일 소설의 단어를 삽입하여 도서의 성공률을 예측하는 데 있어서 가장 선진적인 성능은 0.89 가중 평균 F1 점수라고 한다.마지막으로 우리는 한 권의 책이 특정 유형의 유행에 도움이 되는 주도적인 주제를 제시했다.', 'da': 'Mange nye bøger udgives hvert år, og kun en brøkdel af dem bliver populære blandt læserne. Så forudsigelsen af en bog succes kan være en meget nyttig parameter for forlag til at træffe en pålidelig beslutning. Denne artikel præsenterer undersøgelsen af semantiske ordforeninger ved hjælp af ordet indlejring af bogindhold til et sæt af Rogets tesaurusbegreber til forudsigelse af bog succes. I dette arbejde diskuterer vi metoden til at repræsentere en bog som et spektrum af begreber baseret på associationsscoren mellem dens indholdsindlejring og en global indlejring (dvs. fastText) for et sæt semantisk forbundne ordklynger. Vi viser, at de semantiske ordassociationer overgår de tidligere metoder til bogssuccesforudsigelse. Derudover præsenterer vi, at semantiske ordsammenslutninger også giver bedre resultater end at bruge funktioner som hyppigheden af ordgrupper i Rogets tesaurus, LIWC (et populært værktøj til sproglig undersøgelse og ordtælling), NRC (ordsammenslutning følelsesleksik) og en del af tale (PoS). Vores undersøgelse rapporterer, at konceptassociationer baseret på Rogets Thesaurus ved hjælp af ord embedding af individuel roman resulterede i state-of-the-art præstation på 0,89 gennemsnitlig vægtet F1-score for bog succes forudsigelse. Endelig præsenterer vi et sæt dominerende temaer, der bidrager til populariteten af en bog for en bestemt genre.', 'sw': 'Vitabu vipya vinavyochapishwa kila mwaka, na ni wachache tu miongoni mwa wasomaji. Kwa hiyo utabiri wa mafanikio ya kitabu unaweza kuwa kipimo kinachofaa sana kwa waandishi kuamua kuaminika. Makala hii inaonyesha utafiti wa mashirika ya maneno ya kimapenzi kwa kutumia neno lililoandikwa kwenye maudhui ya kitabu kwa ajili ya seti ya dhana za nadharia za Roget kwa kutabiri mafanikio ya kitabu. Katika kazi hii, tunajadili njia ya kuwawakilisha kitabu kama mtazamo wa dhana inayotumia vipande vya ushirikiano kati ya maudhui yake yanayoingia pamoja na maeneo ya kimataifa (yaani, fast Text) kwa ajili ya set i ya viungo vya maneno yanayohusiana na kimwili. Tunaonyesha kuwa mashirika ya maneno ya kishindani yanafanya mbinu za zamani za kutabiri mafanikio ya kitabu. Zaidi ya hayo, tunaweka sasa kwamba taasisi za maneno ya kigaidi pia zinatoa matokeo bora zaidi ya kutumia vipengele kama frequency of word s in thesaurus ya Roget, LIWC (zana maarufu kwa ajili ya utafiti wa lugha na nambari za maneno), NRC (Shirikisho la Kihisia la Maneno), na sehemu ya hotuba (PoS). Utafiti wetu unaripoti kuwa jumuiya za dhana zinazotumia utafiti wa Roget kwa kutumia neno la kuingiza riwaya binafsi lilisababisha utendaji wa sanaa wa wastani wa wastani wa wastani wa wastani 0.89 ulibeba vipimo vya F1 kwa kutabiri mafanikio ya kitabu. Mwisho, tunaleta mada kadhaa yenye nguvu inayochangia umaarufu wa kitabu kwa ajili ya jeni maalumu.', 'fa': "بسیاری از کتابهای جدید هر سال منتشر می شوند، و تنها بخشی از آنها در میان خوانندگان محبوب می شوند. بنابراین پیش\u200cبینی موفقیت کتاب می\u200cتواند یک پارامتر بسیار مفید برای منتشر کنندگان باشد تا تصمیم قابل اعتماد بگیرند. این مقاله مطالعه اتصال کلمه\u200cهای semantic را با استفاده از کلمه\u200cای که محتوای کتاب را برای مجموعه\u200cای از نظریه\u200cهای تزاوروس روجت برای پیش\u200cبینی موفقیت کتاب نشان می\u200cدهد. در این کار، ما در مورد روش صحبت می کنیم که یک کتاب را به عنوان یک spektrum از مفهومی که بر اساس امتیاز ارتباط بین محتوای پیدا کردن آن و یک پیدا کردن جهانی (یعنی fastText) برای مجموعه کلاس\u200cهای کلاس\u200cهای کلمه\u200cهای نسبت به semantically ارتباط داشته باشد. ما نشان می دهیم که اتصال کلمه\u200cهای semantic از طریق قبلی برای پیش\u200cبینی موفقیت کتاب انجام می\u200cدهند. در addition, we present that semantic word association s also provide better results than using features like the frequency of words groups in Roget's thesaurus, LIWC (a popular tool for linguistic inquiry and word count), NRC (word association emotion lexicon) and part of speech (PoS). مطالعه\u200cمون گزارش می\u200cدهد که اتحادیه\u200cهای مفهوم بر اساس تزاوروس روجت با استفاده از کلمه\u200cای از روزنامه\u200cهای فردی به نتیجه\u200cی تحصیلات هنری 0.89 در میانگین نمونه\u200cهای متوسط وزن\u200cشده F1 برای پیش\u200cبینی موفقیت کتاب است. بالاخره، ما مجموعه\u200cای از موضوعات پادشاهی را نشان می\u200cدهیم که در مورد شهرت یک کتاب برای یک نوع خاص حاصل می\u200cکنند.", 'af': "Baie nuwe boeke word elke jaar uitgepubliseer, en net 'n breuk van hulle word populaar onder die lesers. So die voorskou van 'n boek sukses kan 'n baie nuttige parameter wees vir publeerders om 'n betroubare besluit te maak. Hierdie artikel stel die studie van semantiese woord assosiasies met gebruik van die woord ingesluit van boekinhoud vir 'n stel van Roget se thesaurus konsepte vir boeksuksesvoorskou. In hierdie werk bespreek ons die metode om 'n boek te verteenwoordig as 'n spektrum van konsepte gebaseer op die assosiasie telling tussen sy inhoud ingesluit en 'n global e inbêding (t.d. fastText) vir' n stel van semantiese gekoppelde woordklasters. Ons wys dat die semantiese woord assosiasies die vorige metodes vir boeksuksesvoorskou uitvoer. In addition, we present that semantic word association s also provide better results than using features like the frequency of word groups in Roget's thesaurus, LIWC (a popular tool for linguistic inquiry and word count), NRC (word association emotion lexicon), and part of speech (PoS). Ons studie rapporteer dat konsepsieassosiasies gebaseer op Roget se Thesaurus met gebruik van woord inbetering van individuele roman resulteer in die staat-van-kuns-prestasie van 0.89 gemiddelde geweeg F1-telling vir boeksuksesvoorskou. Eindelik, ons stel 'n stel dominante tema wat bydraai tot die populariteit van 'n boek vir 'n spesifieke genre.", 'sq': 'Shumë libra të rinj publikohen çdo vit dhe vetëm një pjesë e tyre bëhen popullore midis lexuesve. Pra parashikimi i suksesit të librit mund të jetë një parametrë shumë i dobishëm për botuesit për të marrë një vendim të besueshëm. Ky artikull paraqet studimin e shoqatave semantike të fjalëve duke përdorur fjalën përfshirje të përmbajtjes s ë librit për një sërë konceptesh tezaurore të Roget për parashikimin e suksesit të librit. In this work, we discuss the method to represent a book as a spectrum of concepts based on the association score between its content embedding and a global embedding (i.e. fastText) for a set of semantically linked word clusters.  Ne tregojmë se shoqatat semantike të fjalëve tejkalojnë metodat e mëparshme për parashikimin e suksesit të librit. Përveç kësaj, ne paraqesim se shoqatat semantike të fjalëve ofrojnë gjithashtu rezultate më të mira se përdorimi i karakteristikave si frekuenca e grupeve të fjalëve në thesaurin e Roget, LIWC (një mjet popullor për hetimin gjuhësor dhe numërimin e fjalëve), NRC (lexikon emocional të shoqatës s ë fjalëve) dhe pjesë e fjalimit (PoS). Studimi ynë raporton se shoqatat e konceptit të bazuara në Thesaurus të Roget duke përdorur fjalë përfshirje të romanit individual ë rezultuan në performancën më të lartë të 0.89 pikë mesatare F1 për parashikimin e suksesit të librit. Më në fund, ne paraqesim një sërë temësh mbizotëruese që kontribuojnë drejt popullaritetit të një libri për një xhener të caktuar.', 'hy': 'Ամեն տարի շատ նոր գրքեր են հրատարակում, և ընթերցողների մեջ ընդամենը մի մասը հայտնի է դառնում: Այսպիսով, գրքի հաջողության կանխատեսումը կարող է շատ օգտակար պարամետր լինել հրատարակիչների համար վստահելի որոշում կայացնելու համար: Այս հոդվածը ներկայացնում է սեմանտիկ բառերի կազմակերպությունների ուսումնասիրությունը, օգտագործելով գրքի պարունակության ներառման բառը Ռոգետի թեզավրուսի գաղափարների մի շարք հաջողության կանխատեսման համար: Այս աշխատանքի ընթացքում մենք քննարկում ենք գիրքը ներկայացնելու մեթոդը որպես գաղափարների սպեկտր, որը հիմնված է նրա պարունակության ներդրման և գլոբալ ներդրման (այսինքն՝ արագ տեքստի) համակարգի հետ կապված բառերի խմբերի միջև: Մենք ցույց ենք տալիս, որ սեմանտիկ բառերի կապերը գերազանցում են գրքի հաջողության կանխատեսման նախորդ մեթոդները: Ավելին, մենք ներկայացնում ենք, որ սեմանտիկ բառերի կապերը նաև ավելի լավ արդյունք են տալիս, քան օգտագործելով այնպիսի հաճախականություններ, ինչպիսիք են Ռոգետի թեզավրուսում բառերի խմբերի հաճախականությունը, ԼիՎԿ (լեզվաբանական հետազոտության և բառերի հաշվարկի հանրահայտ գործիք), ՆՌԿ (բառերի կա Մեր ուսումնասիրությունը հայտարարում է, որ Ռոգետի թեզավրուսի վրա հիմնված գաղափարների կապերը, օգտագործելով անհատական վեպերի բառերը, հանգեցրին գրքի հաջողության կանխատեսման համար 0.89 միջին կեշտրված F1-գնահատականի լավագույն արդյունքներին: Վերջապես, մենք ներկայացնում ենք մի շարք գերիշխող թեմաներ, որոնք ներդրում են կոնկրետ գենդերային գրքի բնակչության մեջ:', 'am': 'በየዓመቱ ብዙ አዲስ መጻሕፍት ይታወካሉ፣ ከእነርሱም አንባቢዎች መካከል ጥቂቶች ብቻ ይታወካሉ፡፡ ስለዚህ የመጽሐፍ ፍለጋት የደኅንነት ማቀናኘት ለባለፉት የሚጠቅመው ትክክለኛ ፍርድ እንዲያደርጉ በጣም የሚጠቅመው አካላት ይችላል፡፡ ይህ ጽሑፍ የሮጌ የthesaurus አእምሮዎች ለመጽሐፍ ፍለጋት የሚደረገውን ቃል በመጽሐፍ ማኅበረሰብ የሚጠቅመውን የsemantic word associations ትምህርት የሚያቀርብ ነው፡፡ በዚህ ስራ፣ መጽሐፉን ለመቆጣጠር እና በተካሄደው እና በዓለምአቀፍ ጉዳይ (ምናልባት ጾም ጽሑፍ) በተጠቃሚ የንግግር ጉዳይ ላይ የተጠቃሚ የቃላት ጉዳይ መሆኑን በመጠቀም የመጽሐፉ ጉዳይ እንዲሆን እናሳውቃለን፡፡ የቀድሞውን የንግግር ማኅበረሰብ የመጽሐፉ ፍለጋት ለመቀበል የሚደረገውን ሥርዓት እናሳያቸዋለን፡፡ በተጨማሪም፣ የsemantic ቃላት ማኅበረሰቦች፣ የሮጌ ቴሶሮስ፣ LIWC (የቋንቋዊ ጥያቄ እና ቃላት ቁጥር የሚቆጠሩ የንግግር ጉዳይ፣ NRC (የንግግር ማኅበረሰብ lexicon) እና የንግግር ክፍል የሚሆን የንግግር ጉዳይ ክፍተቶችን ከመጠቀም የበለጠ ፍሬዎችን አቀረብናል፡፡ ትምህርታችን የሮጌ ቴሶሮስ የተገኘ የአንድ ቃላት በጥቅልፍ የተደረገው የሮጌ ተቃውሞ የተደረገውን የሥርዓት አርእስት የ0.89 ብዛት የኢንተርኔት ትክክል የF1-score በመጽሐፉ የድል ቅድሚያ መታሰቢያ ሆኖአል፡፡ በመጨረሻውም ለታወቀ የጽሑፍ ውይይት ለመጠቀም የሚጠቅሙትን የሥልጣን ጉዳዮች እናቀርባታለን፡፡', 'tr': "Her ýyl köp täze kitaplar bişirýär we diňe olaryň bir bölümi okuwçylar arasynda meşhur bolýar. Bu yüzden kitap başarısızlığın tahmini bastırıcılar için güvenilir bir karar vermek için çok faydalı bir parameter olabilir. Bu makala Roget'iň tesorus düşünceleri üçin semantik s öz baglaşyklaryny ulanýar. Bu i şde, kitaby semantik bilen baglanmış söz klasterleri üçin bir spektrom şeklinde täze bir kitap täze etmek üçin gurulduk. Semantik söz baglaýyşlaryň kitaplaryň başarnygy öňünden geçen yöntemleri üstün edýändigini görkeýäris. Munuň üçin semantik s öz baglaýyşlaryň Roget tesorusynda, LIWC (dil soragy we söz sany üçin meşhur araç), NRC Biziň araşdyrymyz Roget'iň Thesaurusyna daýanýan düşünjän guramlaryň indiki romanyň içine daýanýan s özleri 0.89 sanat eserleriniň ortalama çykyşlygyny kitap başarnyga çaklamak üçin önüne getirdi. Soňunda, bir kitap täze bir jener üçin kömekleşen dominiýan temalary görkezýäris.", 'bs': "Mnoge nove knjige se objavljuju svake godine, a samo dio njih postaje popularan među čitačima. Dakle predviđanje uspjeha knjige može biti vrlo korisni parameter za izdavače da donesu pouzdanu odluku. Ovaj članak predstavlja studiju semantičkih udruženja riječi koristeći riječ uključenje sadržaja knjiga za skup koncepta Rogetove tezaru za predviđanje uspjeha knjiga. U ovom poslu, razgovaramo o metodi predstavljanja knjige kao spektr koncepta na temelju rezultata asocijacije između njegovog sadržaja ugrađenog i globalnog ugrađenja (tj. fastText) za setu semantički povezanih skupina riječi. Pokazujemo da semantičke udruženje riječi iznose prethodne metode predviđanja uspjeha knjiga. Osim toga, predstavljamo da semantičke udruženje riječi također pružaju bolji rezultat nego koristiti karakteristike poput frekvencije grupa riječi u Rogetovom kazaru, LIWC (popularni alat za ispitivanje jezika i broj riječi), NRC (emocionalni leksikon riječi asocijacije), i dio govora (PoS). Naše istraživanje izvještava da asocijacije koncepta bazirane na Roget's Thesaurus koristeći riječ ugrađenje individualnog romana rezultirale su u stanju umjetnosti 0,89 prosječnog težinog F1 rezultata za predviđanje uspjeha knjiga. Konačno predstavljamo niz dominantnih tema koji doprinose popularnosti knjige za određeni genr.", 'bn': 'প্রতি বছর অনেক নতুন বই প্রকাশ করা হয় এবং তাদের মধ্যে শুধুমাত্র কয়েকজন জনপ্রিয় হয়। তাই একটি বইয়ের ভবিষ্যৎবাণী একটি বিশ্বস্ত সিদ্ধান্ত গ্রহণের জন্য প্রকাশকারীদের জন্য একটি খুব কার্যকর পরামিতি হতে পা এই প্রবন্ধে বই সফল ভবিষ্যতের জন্য রোজেটের কিছু ধারণার ধারণা দিয়ে বই বিষয়বস্তু ব্যবহার করে সেমেন্টিক শব্দ সংগঠনের গবেষণা উপস্থাপন করে এই কাজে আমরা একটি বই প্রতিনিধিত্ব করার পদ্ধতি নিয়ে আলোচনা করি যেটি সংযোগের স্কোরের ভিত্তিতে একটি ধারণা হিসেবে তুলে ধরা যায়, যা তার বিষয়বস্তুর বিভিন্ন স্কোর এবং বিশ্ব আমরা দেখাচ্ছি যে সেমেন্টিক শব্দের সংস্থাগুলো বই সফল ভবিষ্যতের পূর্ববর্তী পদ্ধতি প্রদান করেছে। এছাড়াও আমরা উপস্থাপন করছি যে সেমেন্টিক শব্দের সংস্থাও রোজেটের থিওসুরাস, লিওডিউসি (ভাষাগত তদন্ত এবং শব্দ গণনার জন্য জনপ্রিয় টুল), এনআরসি (শব্দ সংস্থার অনুভূতি লেক্সিকোন) এবং  আমাদের গবেষণা রিপোর্ট করেছে যে রোজেটের থিসোরাস ভিত্তিক ধারণার সংগঠন ব্যবহার করে ব্যক্তিগত উপন্যাসের শব্দ ব্যবহার করে ব্যক্তিগত উপন্যাসের মাধ্যমে প্রতিষ্ঠ শেষ পর্যন্ত আমরা একটি বিশেষ জিনিসের জন্য একটি বইয়ের জনপ্রিয়তার প্রতি সহযোগিতা করছি।', 'az': "Hər il bir çox yeni kitab yayınlanar və onlardan yalnız bir hissəsi oxuyanlar arasında məşhur olar. Kitabın müvəffəqiyyətinin tədbir edilməsi müşahidlərə güvenilir bir karar vermək üçün çox faydalı bir parametrdir. Bu məktub, kitab məlumatını Roget'in tezorus fikirlərini kitab başarıs ızlığı tədbirlərinə uygulamaq üçün semantik söz birlikləri təhsil edir. Bu i şdə, bir kitabı semantik bağlı kelimelər clusterlərinin arasındakı bağlılıq nöqtəsinə dayanan bir spektrum kimi göstərmək üçün müzakirə edirik. Biz göstəririk ki, semantik söz birlikləri kitabın başarılı tədbirlərinin əvvəlki metodlarından üstün olduğunu göstərir. Daha sonra, semantik s öz birlikləri Roget'in tezorusu, LIWC (dil araştırması və söz sayı üçün məşhur aracı), NRC (söz birlikləri emosiyası lexicon) və sözlərin bir parçasının istifadəsindən daha xeyirli sonuçlarını daxil edirik. Bizim araşdırmalarımız bildirir ki, Roget's Thesaurus-a dayanan konsept birlikləri, individual romanın içərisində yazılmış s özləri ilə 0,89 sanat performansının ortalama ölçülü F1-score olduğunu kitab müvəffəqiyyətində təsbiq etdi. Sonunda, bir kitabın məşhurluğuna kömək edən dominant temaları göstəririk.", 'cs': 'Každý rok se vydává mnoho nových knih a jen zlomek z nich se mezi čtenáři stává populární. Takže predikce úspěchu knihy může být velmi užitečným parametrem pro vydavatele, aby učinili spolehlivé rozhodnutí. Tento článek představuje studium sémantických slovních asociací s využitím slovního vložení obsahu knihy pro sadu Rogetových tezaurových konceptů pro predikci úspěšnosti knihy. V této práci diskutujeme metodu reprezentace knihy jako spektra pojmů založených na asociačním skóre mezi jejím obsahovým vložením a globálním vložením (tj. fastText) pro sadu sémanticky propojených slovních clusterů. Ukazujeme, že sémantické asociace slov překonávají předchozí metody pro predikci úspěšnosti knih. Kromě toho uvádíme, že sémantické slovní asociace poskytují lepší výsledky než použití funkcí jako frekvence slovních skupin v Rogetově tezauře, LIWC (populární nástroj pro jazykové šetření a počet slov), NRC (slovní asociace emoční lexikon) a část řeči (PoS). Naše studie uvádí, že koncepční asociace založené na Rogetově tezauře pomocí slovního vložení jednotlivého románu vedly k nejmodernějšímu výkonu průměrného váženého F1 skóre 0,89 pro predikci úspěchu knihy. Nakonec představujeme soubor dominantních témat, která přispívají k popularitě knihy pro konkrétní žánr.', 'ca': "Molts llibres nous es publiquen cada any, i només una fracció d'ells es fan popular entre els lectors. Així que la predicció d'un èxit del llibre pot ser un paràmetre molt útil per als editors per prendre una decisió fiable. This article presents the study of semantic word associations using the word embedding of book content for a set of Roget's thesaurus concepts for book success prediction.  En aquesta feina, discutem el mètode de representar un llibre com un espectre de conceptes basat en la puntuació d'associació entre la seva incorporació de contingut i una incorporació global (i.e. fastText) per un conjunt de grups de paraules vinculats semànticament. Mostrem que les associacions semàntiques de paraules superen els mètodes anteriors per a predir l'èxit del llibre. A més, presentem que les associacions semàntiques de paraules també proporcionen millors resultats que utilitzar característiques com la freqüència de grups de paraules en el tesaure de Roget, LIWC (una eina popular per a la investigació lingüística i el nombre de paraules), NRC (lexicó emocional de l'associació de paraules) i part del discurs (PoS). El nostre estudi diu que les associacions de concepte basades en el Tesaure de Roget utilitzant la paraula incorporadora de novel s individuals van resultar en un rendiment més avançat de 0,89 puntuació F1 pesada mitjana per predir l'èxit del llibre. Finalment, presentem un conjunt de temes dominants que contribueixen a la popularitat d'un llibre per un gènere específic.", 'et': 'Igal aastal avaldatakse palju uusi raamatuid ja ainult murdosa neist muutub lugejate seas populaarseks. Nii et raamatu edu prognoosimine võib olla väga kasulik parameeter kirjastajatele usaldusväärse otsuse tegemiseks. Käesolevas artiklis tutvustatakse semantiliste sõnaseoste uurimist, kasutades raamatusisu sõna manustamist Rogeti tesauruse kontseptsioonide komplekti raamatuedu ennustamiseks. Käesolevas töös arutleme raamatu kui kontseptsioonide spektri esindamise meetodit, mis põhineb seosskooril sisu manustamise ja globaalse manustamise (st fastText) vahel semantiliselt seotud sõnaklastrite hulgas. Näitame, et semantilised sõnaseosed ületavad varasemaid raamatu edu ennustamise meetodeid. Lisaks esitame, et semantilised sõnaseosed annavad paremaid tulemusi kui kasutada selliseid funktsioone nagu sõnarühmade sagedus Rogeti tesauruses, LIWC (populaarne vahend keelelise uurimise ja sõnade arvu jaoks), NRC (sõnaseoste emotsiooni leksikon) ja osa kõnest (PoS). Meie uurimus näitab, et Rogeti tesaurusel põhinevad kontseptsioonilised seosed, mis kasutasid individuaalse romaani sõna manustamist, viisid kaasaegse tulemuse 0,89 keskmise kaalutud F1-skoori raamatu eduprognoosimiseks. Lõpuks esitame hulga domineerivaid teemasid, mis aitavad kaasa raamatu populaarsusele konkreetse žanri jaoks.', 'fi': "Monet uudet kirjat julkaistaan vuosittain, ja vain murto-osa niistä tulee suosittuja lukijoiden keskuudessa. Kirjan menestyksen ennustaminen voi siis olla erittäin hyödyllinen parametri kustantajille luotettavan päätöksen tekemisessä. Tässä artikkelissa esitellään semanttisten sanayhteyksien tutkimusta kirjasisällön sanaupottamisen avulla Rogetin tesaurukonseptien kirjojen menestyksen ennustamiseen. Tässä työssä keskustellaan menetelmästä esittää kirjaa käsitteiden spektrinä, joka perustuu sen sisällönupotuksen ja globaalin upotuksen (fastText) väliseen assosiointipistemäärään semanttisesti linkitettyjen sanaklusterien joukosta. Osoitamme, että semanttiset sanaassosiaatiot ylittävät aikaisemmat menetelmät kirjan menestyksen ennustamiseksi. Lisäksi esitämme, että semanttiset sanaassosiaatiot tuottavat parempia tuloksia kuin Rogetin tesauruksen sanaryhmien esiintymistiheys, LIWC (suosittu kielellisen tutkimuksen ja sanamäärän työkalu), NRC (word association emotion lexicon) ja osa puhetta (PoS). Tutkimuksemme raportoi, että Roget's Thesaurus -sanakirjaan perustuvat käsitteelliset yhteenliittymät, joissa käytetään yksittäisen romaanin sanaupotusta, johtivat viimeisimpään tulokseen 0,89 painotetulla F1-pisteellä kirjan menestysennusteessa. Lopuksi esittelemme joukon hallitsevia teemoja, jotka edistävät kirjan suosiota tietylle genrelle.", 'jv': "Awak dhéwé éntuk akeh moco sing nari, lan akeh sing entuk dhéwé kuwi kesempatan luwih apik lan akeh sing ngewehi. bookmark Inggal iki dadi akeh stir dadi sinau semanti word ingkang gambar kelas embedding of a bookmark kanggo sampek kelas konjure penting a butuh nggawe barang seneng pisan buku. Awak dhéwé nggunakake iki, kita diwusegno sistem kanggo nyelaraké buku iki dadi kelompok nggawe tarjamahan karo perusahaan sing nggawe ngubah untarané (i.e.g. fast-Text) kanggo kelompok word luwih dumaten. Awak dhéwé ngerasakno karo semanti kuwi alam tentang kanggo ngerasakno Nambah, awak dhéwé éntuk karo pawarno semanti karo pawarno sing luwih dadi, akeh dhéwé éntuk karo perangkat dhéwé kesempatan kanggo kelompok gambaran karo katesêruso nang Rong's, LIWC Awakdhéwé éntuk barêng-barêng nggawe barang kelompok sing basa ning Rong's Thesarus kuwi nggambar barang sing dikenakno sing wis ana luwih nêmên-karo iso nggawe barang 0.64 eo sampeyan sing paling dhéwé operasi layang F1-uwong nggawe barang nggawe basa sing berarti. Saiki, awak dhéwé nambah sing tema sing wis ana sing nyumbang nggawe popularno sing gawe buku kanggo kelas sing uwis.", 'ha': "Wasu littattafai na fita a yearli, kuma sai kaɗan daga cikinsu ke karatun. Kayya da kuskure ga mafaniyar littafi na iya zama parameter mai amfani ga masu fassarar da za su sami wani fatauci mai aminci. Wannan makala na gaya karatun kalma masu semantic associations da ke amfani da word embedded in littãfi wa wani set of notions of thesaurus na Roget for birnin babban littafi. Daga wannan aikin, Munã jãyayya hanyor da za'a gaya wani littãfi kamar spectrum na idãnun zato a kan kwamfyutan shirin da ke danne a tsakanin maɓallin shirin da ke ƙunsa da wani matsayi (misali, matsayin matsayi) zuwa wani matsayin da aka haɗa shi na semantically-linked word clubs. Muna nũna cewa musamman kalmõmi na semantic ne mafiya gabani da hanyoyin littafi. Da wannan, Munã halarce, musamman masu semantic na ƙarai da mafiya alhẽri ko su yi amfani da wasu fassara kamar misali na komai na saurari na Roget, LIWC (wani zance wa tambayar linguistic da lissafi), NRC (magana association da za'a yi hisani da kuma rabon magana (PoS). Raɗe da littafinMu na gaya cewa misãlai masu daidaita a kan Roget's Tesaurus da ke amfani da word embedded in nonin wanda ke da shi ya ƙara-the-art na halarce a 0.89 gwargwadon F1-score wa basĩrin littafin. Gani, Munã halatar da wasu maɓalli masu domin ta ƙara zuwa ga umarin littãfi wa wani geni na ƙayyade.", 'sk': 'Vsako leto se objavi veliko novih knjig in le delček njih postane priljubljen med bralci. Zato je napoved uspeha knjige lahko zelo uporaben parameter za založnike, da sprejmejo zanesljivo odločitev. V prispevku je predstavljena študija semantičnih besednih asociacij z uporabo besedne vdelave knjižnih vsebin za nabor Rogetovih konceptov tesavra za napovedovanje uspeha knjig. V tem delu obravnavamo metodo predstavitve knjige kot spektra konceptov, ki temelji na povezavi med njeno vsebinsko vdelavo in globalno vdelavo (tj. fastText) za nabor semantično povezanih besednih grozdov. Pokazali smo, da semantične besedne asociacije presegajo prejšnje metode napovedovanja uspeha knjig. Poleg tega predstavljamo, da semantične besedne asociacije zagotavljajo boljše rezultate kot uporaba funkcij, kot so frekvenca besednih skupin v Rogetovem slovarju, LIWC (priljubljeno orodje za jezikovno poizvedbo in število besed), NRC (besedni asociacijski čustveni leksikon) in del govora (PoS). Naša študija poroča, da so konceptne povezave, ki temeljijo na Rogetovem tezavru z uporabo besednega vključevanja posameznega romana, povzročile najsodobnejšo zmogljivost 0,89 povprečnega tehtanega F1-rezultata za napovedovanje uspeha knjige. Na koncu predstavljamo nabor prevladujočih tem, ki prispevajo k priljubljenosti knjige za določen žanr.', 'he': "ספרים חדשים רבים פורסמים כל שנה, ורק חלק מהם הופכים לפופולרי בין הקוראים. אז החזוי של הצלחה בספר יכול להיות פרמטר מאוד שימושי עבור המוציאים כדי לקבל החלטה אמינה. המאמר הזה מציג את המחקר של איגודים מילים סמנטיים בשימוש במילה קישום של תוכן ספרים לקבוצה של מושג התזאורוס של רוג'ט לחזות הצלחה ספרית. בעבודה הזו, אנחנו מדברים על השיטה לייצג ספר כספקטר של מושגים מבוסס על נקודת האיגוד בין התוכן שלה להכניסה גלובלית (כלומר FasText) לקבוצה של קבוצות מילים מקושרות סמנטית. אנחנו מראים שהארגונות המילים הסמנטיות מעליפות את השיטות הקודמות לחזוי הצלחה בספרים. בנוסף, אנו מציגים כי ארגוני מילים סמנטיים גם מספקים תוצאות טובות יותר מאשר להשתמש בתפקידים כמו התדירות של קבוצות מילים בתזאורוס של רוג'ט, LIWC (כלי פופולרי לחקירה שפתית וספירת מילים), NRC (ליקסיקון רגשות ארגון מילים), וחלק מהנאום (PoS). Our study reports that concept associations based on Roget's Thesaurus using word embedding of individual novel resulted in the state-of-the-art performance of 0.89 average weighted F1-score for book success prediction.  Finally, we present a set of dominant themes that contribute towards the popularity of a book for a specific genre.", 'bo': "ལོ་རེར་བཞིན་བྲིས་ཆེན་མང་པོ་ཞིག་བསྐྲུན་ཡོད། དེ་ལས་ཀློག དེར་བརྟེན། དཔེ་དེབ་ཅིག་གི་རྔོན་སྒྲིག་ནི་རྒྱལ་ཁབ་སྤྱིར་བཏང་བའི་ཚད་ལྟར་ཆེན་པོ་ཞིག་ཡིན། འདིས་གྲངས་འདིས་སྔོན་ལྟ་བུའི་ནང་དུ་རྣམ་པ་གྱི་སྒྲུང་ཚིག་གི་སྒྲུང་ཕྱོགས་ཀྱི་ཆ་རྐྱེན་སྒྲིག་ཚོགས་ལ་སྤྱོད་བཞིན་པའི་ཐ་སྙད་ཅི འུ་ཅག་གིས་ཀྱི་ལས་ཀ་འདིའི་ནང་དུ་ཡིག་ཆ་ཁྱེར་གྱི་ནང་དོན་དབྱེ་བ་དང་འཛམ་གླིང་སྦྲེལ་མཐུད་གྱི་ཚིག་རྟགས་ལ་སྟོན་པའི་ཐབས་ལམ་ལ་བཤད་བྱས་པ་ཡིན། ང་ཚོས་སྔོན་གྱི་ཐབས་ལམ་དེ་ཚོའི་ཆེ་ཚོས་མཐུན་རྐྱེན་གྱི་ཐབས་ལམ་ལ་རྗེས་འབྱུང་བ་ཡིན་པས། འོ་ན་ཀྱང་། semantic word association s also provide better results than using features like the frequency of words groups in Roget's thesaurus, LIWC (a popular tool for linguistic inquiry and word count), NRC (word association emotion lexicon), and part of speech (PoS). ང་ཚོའི་བརྩལ་ཞིབ་ནི་རྣམ་པའི་སྦྲེལ་མཐུད་དང་རྟེན་Roget's Thesaurus་ལ་གཞི་སྒྲིག་ཀྱི་ཚིག་བྲིས་ཁག་ཅིག མཐའ་མར་ང་ཚོས་རྗེས་སུ་གྲོང་ཁྱེར་གྱི་ཕྱི་ཁོག་གི་ཚོགས་ཆེན་པོ་ཞིག་གི་མིང་ཁག་ཅིག་གི་སྐྱེས་ཚུལ་ལ་སྤྱོད་"}
{'en': 'ParsFEVER : a Dataset for Farsi Fact Extraction and Verification', 'es': 'ParsFever: un conjunto de datos para la extracción y verificación de datos en persa', 'ar': 'ParsFEVER: مجموعة بيانات لاستخراج الحقائق الفارسية والتحقق منها', 'fr': "PARSfever\xa0: un ensemble de données pour l'extraction et la vérification de faits en farsi", 'pt': 'ParsFEVER: um conjunto de dados para extração e verificação de fatos em farsi', 'ja': 'ParsFEVER ： Farsiファクト抽出と検証のためのデータセット', 'zh': 'ParsFEVER:以波斯事取验数集', 'hi': 'ParsFEVER: फारसी तथ्य निष्कर्षण और सत्यापन के लिए एक डेटासेट', 'ru': 'ParsFEVER: набор данных для извлечения и проверки фактов Фарси', 'ga': 'ParsFEVER: Tacar Sonraí le haghaidh Eastóscadh Fíricí Farsi agus Fíorú', 'ka': 'Name', 'hu': 'ParsFEVER: egy adatkészlet a fárszi tények kivonásához és ellenőrzéséhez', 'el': 'ΠάρsFEVER: ένα σύνολο δεδομένων για την εξαγωγή και επαλήθευση γεγονότων στα Φαρσί', 'it': "ParsFEVER: un dataset per l'estrazione e la verifica dei fatti farsi", 'kk': 'ParsFEVER: фарси факттерді тарқату мен тексеру деректер бағдарламасы', 'mk': 'ParsFEVER: датотека за извлекување и верификација на факти од Фарси', 'lt': 'ParsFEVER: Farsi faktų ekstrahavimo ir tikrinimo duomenų rinkinys', 'ms': 'ParsFEVER: Set Data untuk Ekstraksi Fakta Farsi dan Pengesahan', 'ml': 'പാര്\u200dസ്ഫെവെര്\u200d: ഫാര്\u200dസി ഫാക്റ്റ് പുറത്താക്കുന്നതിനും പരിശോധനത്തിനും ഒരു ഡാറ്റാസെറ്റ്', 'mt': 'ParsFEVER: Sett ta’ Dejta għall-Estrazzjoni u l-Verifika tal-Fatti Farsi', 'mn': 'ParsFEVER', 'no': 'Name', 'ro': 'ParsFEVER: un set de date pentru extragerea și verificarea faptelor farsi', 'pl': 'ParsFEVER: zbiór danych do ekstrakcji i weryfikacji faktów z Farsi', 'sr': 'ParsFEVER: datum za izvlačenje i proverenje fakta Farsi', 'si': 'Name', 'so': 'ParsFEVER: A Dataset for Farsi Fact Extraction and Imtixaanka', 'sv': 'ParsFEVER: ett dataset för utvinning och verifiering av farsi', 'ta': 'பார்ஸ்FEVER: ஃபார்சி கண்டுபிடிப்பு மற்றும் செலுத்தலுக்கான தகவல் அமைப்பு', 'ur': 'Name', 'uz': 'Name', 'vi': ':từng bộ nhớ dữ liệu cho chiết xuất và kiểm tra dữ liệu Farsi', 'id': 'ParsFEVER: Dataset untuk Ekstraksi dan Verifikasi Fakta Farsi', 'bg': 'ПарсФЕВЕР: набор от данни за извличане и проверка на фарси факти', 'da': 'ParsFEVER: et datasæt til farsi fakta ekstraktion og verifikation', 'ko': 'Parsferre: 페르시아어 팩트 추출 및 검증을 위한 데이터 세트', 'de': 'ParsFEVER: ein Datensatz für Farsi Fact Extraction and Verification', 'nl': 'ParsFEVER: een dataset voor Farsi Fact Extraction en Verificatie', 'fa': 'Name', 'sw': 'ParsFEVER: Taarifa kwa ajili ya Kutoa Ukweli wa Farsi na Kuthibitishwa', 'tr': 'ParsFEVER: a Dataset for Farsi Fact Extraction and Verification', 'af': 'Name', 'am': 'ምርጫዎች', 'sq': 'ParsFEVER: një bazë të dhënash për nxjerrjen dhe verifikimin e fakteve Farsi', 'hy': 'Ֆարսի փաստերի վերացման և ստուգումների տվյալներ', 'bn': 'ParsFEVER: ফার্সি ফ্যাক্ট এক্সট্র্যাকশন এবং সার্টিফিকেশনের জন্য একটি ডাটাসেট', 'hr': 'ParsFEVER: datum za ekstrakciju činjenica i provjeru Farsi', 'az': 'ParsFEVER: Farsi Fact Extraction and Verification üçün bir Dataset', 'bs': 'ParsFEVER: datum za izvlačenje činjenica i provjeru Farsi', 'ca': 'ParsFEVER: a Dataset for Farsi Fact Extraction and Verification', 'cs': 'ParsFEVER: sada dat pro extrakci a ověřování faršských faktů', 'fi': 'ParsFEVER: tietokokonaisuus farsin tietojen keräämistä ja todentamista varten', 'et': 'ParsFEVER: andmekogum farsi faktide väljavõtmiseks ja kontrollimiseks', 'jv': 'NAME OF TRANSLATORS', 'ha': 'ParsFEVER: a Dataset for Farsi Fact Extraction and Verification', 'sk': 'ParsFEVER: nabor podatkov za pridobivanje in preverjanje dejstev farsi', 'bo': 'ParsFEVER: a Dataset for Farsi Fact Extraction and Verification', 'he': 'ParsFEVER: a Dataset for Farsi Fact Extraction and Verification'}
{'en': 'Training and evaluation of automatic fact extraction and verification techniques require large amounts of annotated data which might not be available for low-resource languages. This paper presents ParsFEVER : the first publicly available Farsi dataset for fact extraction and verification. We adopt the construction procedure of the standard English dataset for the task, i.e., FEVER, and improve it for the case of low-resource languages. Specifically, claims are extracted from sentences that are carefully selected to be more informative. The dataset comprises nearly 23 K manually-annotated claims. Over 65 % of the claims in ParsFEVER are many-hop (require evidence from multiple sources), making the dataset a challenging benchmark (only 13 % of the claims in FEVER are many-hop). Also, despite having a smaller training set (around one-ninth of that in Fever), a model trained on ParsFEVER attains similar downstream performance, indicating the quality of the dataset. We release the dataset and the annotation guidelines at https://github.com/Zarharan/ParsFEVER.', 'fr': "La formation et l'évaluation des techniques d'extraction et de vérification automatiques des faits nécessitent de grandes quantités de données annotées qui peuvent ne pas être disponibles pour les langues à faibles ressources. Cet article présente PARSfever\xa0: le premier jeu de données farsi accessible au public pour l'extraction et la vérification des faits. Nous adoptons la procédure de construction du jeu de données anglais standard pour la tâche, c'est-à-dire FEVER, et l'améliorons pour les langues à faibles ressources. Plus précisément, les allégations sont extraites de phrases soigneusement sélectionnées pour être plus informatives. L'ensemble de données comprend près de 23 000 demandes annotées manuellement. Plus de 65\xa0% des affirmations dans ParsFever sont des sauts multiples (nécessitent des preuves provenant de sources multiples), ce qui fait de l'ensemble de données un point de référence difficile (seulement 13\xa0% des affirmations dans FEVER sont des sauts multiples). De plus, malgré un ensemble d'entraînement plus restreint (environ un neuvième de celui de Fever), un modèle entraîné sur PARSfever atteint des performances similaires en aval, ce qui indique la qualité de l'ensemble de données. Nous publions le jeu de données et les directives relatives aux annotations sur https://github.com/Zarharan/ParsFEVER.", 'ar': 'يتطلب التدريب والتقييم لتقنيات الاستخراج التلقائي للحقائق والتحقق منها كميات كبيرة من البيانات المشروحة التي قد لا تكون متاحة للغات منخفضة الموارد. تقدم هذه الورقة ParsFEVER: أول مجموعة بيانات فارسية متاحة للجمهور لاستخراج الحقائق والتحقق منها. نعتمد إجراءات إنشاء مجموعة البيانات الإنجليزية القياسية للمهمة ، أي FEVER ، ونقوم بتحسينها في حالة اللغات منخفضة الموارد. على وجه التحديد ، يتم استخراج المطالبات من الجمل التي تم اختيارها بعناية لتكون أكثر إفادة. تضم مجموعة البيانات ما يقرب من 23 ألف مطالبة مشروحة يدويًا. أكثر من 65٪ من المطالبات في ParsFEVER متعددة المراحل (تتطلب أدلة من مصادر متعددة) ، مما يجعل مجموعة البيانات معيارًا صعبًا (13٪ فقط من المطالبات في FEVER متعددة المراحل). أيضًا ، على الرغم من وجود مجموعة تدريب أصغر (حوالي تسعة من ذلك في Fever) ، فإن النموذج الذي تم تدريبه على ParsFEVER يحقق أداءً مماثلًا في المصب ، مما يشير إلى جودة مجموعة البيانات. أصدرنا مجموعة البيانات وإرشادات التعليقات التوضيحية على https://github.com/Zarharan/ParsFEVER.', 'pt': 'O treinamento e a avaliação de técnicas automáticas de extração e verificação de fatos exigem grandes quantidades de dados anotados que podem não estar disponíveis para idiomas de poucos recursos. Este artigo apresenta o ParsFEVER: o primeiro conjunto de dados Farsi disponível publicamente para extração e verificação de fatos. Adotamos o procedimento de construção do conjunto de dados padrão em inglês para a tarefa, ou seja, FEVER, e o aprimoramos para o caso de idiomas com poucos recursos. Especificamente, as afirmações são extraídas de frases cuidadosamente selecionadas para serem mais informativas. O conjunto de dados compreende quase 23 mil declarações anotadas manualmente. Mais de 65% das declarações no ParsFEVER são de muitos saltos (requer evidências de várias fontes), tornando o conjunto de dados uma referência desafiadora (apenas 13% das declarações no FEVER são de muitos saltos). Além disso, apesar de ter um conjunto de treinamento menor (cerca de um nono do Fever), um modelo treinado no ParsFEVER atinge desempenho downstream semelhante, indicando a qualidade do conjunto de dados. Lançamos o conjunto de dados e as diretrizes de anotação em https://github.com/Zarharan/ParsFEVER.', 'es': 'La capacitación y la evaluación de técnicas automáticas de extracción y verificación de datos requieren grandes cantidades de datos anotados que pueden no estar disponibles para idiomas de bajos recursos. Este artículo presenta ParsFever: el primer conjunto de datos farsi disponible públicamente para la extracción y verificación de hechos. Adoptamos el procedimiento de construcción del conjunto de datos estándar en inglés para la tarea, es decir, FEVER, y lo mejoramos para el caso de idiomas de bajos recursos. Específicamente, las afirmaciones se extraen de frases que se seleccionan cuidadosamente para que sean más informativas. El conjunto de datos comprende casi 23 000 afirmaciones anotadas manualmente. Más del 65% de las afirmaciones en ParsFever son de muchos saltos (requieren evidencia de múltiples fuentes), lo que hace que el conjunto de datos sea un punto de referencia desafiante (solo el 13% de las afirmaciones en FEVER son de muchos saltos). Además, a pesar de tener un conjunto de entrenamiento más pequeño (alrededor de una novena parte del de Fever), un modelo entrenado en ParsFever logra un rendimiento posterior similar, lo que indica la calidad del conjunto de datos. Publicamos el conjunto de datos y las pautas de anotación en https://github.com/Zarharan/ParsFEVER.', 'hi': 'स्वचालित तथ्य निष्कर्षण और सत्यापन तकनीकों के प्रशिक्षण और मूल्यांकन के लिए बड़ी मात्रा में एनोटेटेड डेटा की आवश्यकता होती है जो कम संसाधन वाली भाषाओं के लिए उपलब्ध नहीं हो सकती है। यह पेपर ParsFEVER प्रस्तुत करता है: तथ्य निष्कर्षण और सत्यापन के लिए पहला सार्वजनिक रूप से उपलब्ध फारसी डेटासेट। हम कार्य के लिए मानक अंग्रेजी डेटासेट की निर्माण प्रक्रिया को अपनाते हैं, यानी, बुखार, और कम संसाधन वाली भाषाओं के मामले के लिए इसे बेहतर बनाते हैं। विशेष रूप से, दावों को उन वाक्यों से निकाला जाता है जिन्हें अधिक जानकारीपूर्ण होने के लिए सावधानीपूर्वक चुना जाता है। डेटासेट में लगभग 23K मैन्युअल रूप से-एनोटेट किए गए दावे शामिल हैं। पार्सएफईईआर में 65% से अधिक दावे कई-हॉप हैं (कई स्रोतों से सबूत की आवश्यकता होती है), जिससे डेटासेट एक चुनौतीपूर्ण बेंचमार्क बन जाता है (बुखार में केवल 13% दावे कई-हॉप हैं)। इसके अलावा, एक छोटा प्रशिक्षण सेट होने के बावजूद (बुखार में इसका लगभग नौवां हिस्सा), पार्सएफईईआर पर प्रशिक्षित एक मॉडल समान डाउनस्ट्रीम प्रदर्शन प्राप्त करता है, जो डेटासेट की गुणवत्ता को दर्शाता है। हम डेटासेट और एनोटेशन दिशानिर्देशों को https://github.com/Zarharan/ParsFEVER पर जारी करते हैं।', 'ru': 'Обучение и оценка методов автоматического извлечения и проверки фактов требуют больших объемов аннотированных данных, которые могут быть недоступны для языков с ограниченными ресурсами. В настоящем документе представлен ParsFEVER: первый общедоступный набор данных фарси для извлечения и проверки фактов. Мы принимаем процедуру построения стандартного английского набора данных для задачи, т.е. ЛИХОРАДКИ, и улучшаем ее для малоресурсных языков. В частности, пункты формулы изобретения извлекаются из предложений, которые тщательно подбираются, чтобы быть более информативными. Набор данных содержит почти 23 ТЫС. ручных аннотированных формул изобретения. Более 65% утверждений в ParsFEVER являются многохоповыми (требуют доказательств из нескольких источников), что делает набор данных сложным эталоном (только 13% утверждений в ЛИХОРАДКЕ являются многохоповыми). Кроме того, несмотря на меньший набор тренировок (примерно одна девятая от набора в лихорадке), модель, обученная на ParsFEVER, достигает аналогичной производительности ниже по потоку, указывая на качество набора данных. Мы выпускаем набор данных и рекомендации по аннотации по адресу https://github.com/Zarharan/ParsFEVER.', 'zh': '自事实取验术数,评估须大注数,而此数或不宜于资源匮乏之语。 本文ParsFEVER:首明可用之波斯语数据集,施于事实取验。 臣等准英语数集,即FEVER,并低资源语言改进。 权利取诸精择,以给信息。 该数据集包含近 23,000 一手动注声明。 ParsFEVER之过于65%者多跳(须出于数证),此使数集为一挑战性之准(FEVER惟13%声明为多跳之)。 此外虽练集较小(盖 Fever 之九分之一),而得类于 ParsFEVER 者,明数集之量也。 于 https://github.com/Zarharan/ParsFEVER 发数据集注指南。', 'ja': '自動事実抽出と検証技術のトレーニングと評価には、低資源言語では利用できない可能性のある大量の注釈付きデータが必要です。 ParsFEVER ：事実抽出と検証のための最初の一般公開されているFarsiデータセットを紹介します。 タスクに標準的な英語データセットの構築手順、すなわち発熱を採用し、低リソース言語の場合に改善します。 具体的には、特許請求の範囲は、より情報量が多いように慎重に選択された文章から抽出される。 データセットは、23,000件近くの手動で注釈された特許請求の範囲を含む。 ParsFEVERの申し立ての65%以上がマルチホップ（複数のソースからの証拠が必要）であり、データセットは困難なベンチマークとなっています（ FEVERの申し立ての13%のみがマルチホップです）。 また、より小さいトレーニングセット（フィーバーの約9分の1 ）を有するにもかかわらず、ParsFEVERでトレーニングされたモデルは、データセットの品質を示す同様のダウンストリームパフォーマンスを達成します。 データセットと注釈ガイドラインはhttps://github.com/Zarharan/ParsFEVERで公開されています。', 'ga': 'Teastaíonn méideanna móra sonraí anótáilte chun oiliúint agus meastóireacht a dhéanamh ar theicnící uathbhainte fíorais agus d’fhéadfadh nach mbeadh siad ar fáil i dteangacha íseal-acmhainne. Cuireann an páipéar seo i láthair ParsFEVER: an chéad tacar sonraí Farsi atá ar fáil go poiblí le haghaidh eastóscadh agus fíorú fíricí. Glacaimid leis an nós imeachta maidir le tacar sonraí caighdeánach Béarla a thógáil don tasc, i.e., FEVER, agus feabhsaítear é i gcás teangacha íseal-acmhainne. Go sonrach, baintear éilimh as abairtí a roghnaítear go cúramach le bheith níos faisnéiseach. Tá beagnach 23K éileamh anótáilte de láimh sa tacar sonraí. Is iomaí hop atá os cionn 65% de na héilimh in ParsFEVER (tá fianaise ag teastáil ó fhoinsí iolracha), rud a fhágann gur tagarmharc dúshlánach an tacar sonraí (níl ach 13% de na héilimh in FEVER lán-hop). Chomh maith leis sin, in ainneoin sraith oiliúna níos lú a bheith aige (thart ar an naoú cuid de sin i bhFiabhras), sroicheann samhail atá oilte ar ParsFEVER feidhmíocht iartheachtach den chineál céanna, rud a léiríonn cáilíocht an tacair sonraí. Eisímid an tacar sonraí agus na treoirlínte nótaí ag https://github.com/Zarharan/ParsFEVER.', 'ka': 'ავტომატური ფექტურის ექსტრექციის და შემოწმების ტექნოგიების განაკეთება და განაკეთება უნდა დიდი მონიშნული მონაცემები, რომლებიც შეიძლება არ შეიძლება დამატებული მნი ამ დოკუმენტი ParsFEVER: პირველი ადამიანურად ხელმისაწყებელი ფაქტის ექსტრაქციის და დარწმუნებისთვის ფაქტის მონაცემების შესახებ. ჩვენ განვიყენებთ სტანდარტური ანგლისური მონაცემების მონაცემების პროცესი, რადგან, FEVER, და დავიწყენებთ მარტივი რესურსის ენების შემთხვევაში. განსაკუთრებულია, შესაძლებლობები უფრო ინფორმატიურად გამოყენებულია სიტყვებისგან, რომლებიც უფრო მნიშვნელოვანია. მონაცემების კონფიგურაციაში მხოლოდ 23K პირდაპირად მონაცემებულია. ParsFEVER-ში 65% უფრო მეტი წარმოდგენები უფრო მეტი იქნება (უფრო მეტი წარმოდგენების წარმოდგენება) მონაცემების სექტის შესაძლებელი წარმოდგენება (მხოლოდ 13% FEVER-ში წარმოდგ მაგრამ, მაშინ, ცოტა განაკლებების შესახებ (ცოტა-ში ერთი-ცხრად) მოდელი, რომელიც ParsFEVER-ზე განაკლებული მოდელი მიიღება მსგავსი კონტაქტის შესახებ, რომელიც მონაცემების კონ ჩვენ მონაცემების საზოგადოება და მონაცემების საზოგადოება https://github.com/Zarharan/ParsFEVER.', 'el': 'Η εκπαίδευση και η αξιολόγηση των τεχνικών αυτόματης εξαγωγής γεγονότων και επαλήθευσης απαιτούν μεγάλες ποσότητες σχολιασμένων δεδομένων τα οποία ενδέχεται να μην είναι διαθέσιμα για γλώσσες χαμηλής περιεκτικότητας. Η παρούσα εργασία παρουσιάζει το πρώτο δημόσιο διαθέσιμο σύνολο δεδομένων για εξαγωγή και επαλήθευση γεγονότων. Υιοθετούμε τη διαδικασία κατασκευής του τυποποιημένου αγγλικού συνόλου δεδομένων για την εργασία, δηλαδή, και τη βελτιώνουμε για την περίπτωση γλωσσών χαμηλού πόρου. Συγκεκριμένα, οι ισχυρισμοί εξάγονται από προτάσεις που επιλέγονται προσεκτικά για να είναι πιο ενημερωτικές. Το σύνολο δεδομένων περιλαμβάνει σχεδόν 23Κ χειροκίνητα σχολιασμένους ισχυρισμούς. Πάνω από 65% των ισχυρισμών στο ParsFEVER είναι πολλά-hop (απαιτούν αποδεικτικά στοιχεία από πολλές πηγές), καθιστώντας το σύνολο δεδομένων ένα απαιτητικό σημείο αναφοράς (μόνο 13% των ισχυρισμών στο FEVER είναι πολλά-hop). Επίσης, παρά το γεγονός ότι έχει μικρότερο εκπαιδευτικό σύνολο (περίπου το ένα ένατο από αυτό στο Fever), ένα μοντέλο εκπαιδευμένο στο ParsFEVER επιτυγχάνει παρόμοιες μεταγενέστερες επιδόσεις, υποδεικνύοντας την ποιότητα του συνόλου δεδομένων. Δημοσιεύουμε το σύνολο δεδομένων και τις οδηγίες σχολιασμού στο https://github.com/Zarharan/ParsFEVER.', 'hu': 'Az automatikus ténykitermelési és ellenőrzési technikák képzése és értékelése nagy mennyiségű jegyzetelt adatot igényel, amelyek esetleg nem állnak rendelkezésre az alacsony erőforrású nyelvek esetében. Ez a tanulmány bemutatja a ParsFEVER-t: az első nyilvánosan elérhető fársi adatkészletet a tények kivonására és ellenőrzésére. A feladathoz elfogadjuk a szabványos angol adatkészlet, azaz a FEVER építési eljárását, és fejlesztjük azt alacsony erőforrású nyelvek esetén. Konkrétan az állításokat olyan mondatokból vonják ki, amelyeket gondosan kiválasztottak, hogy információsabbak legyenek. Az adatkészlet közel 23 000 manuálisan jegyzetelt állítást tartalmaz. A ParsFEVER állításainak több mint 65%-a sok-hop (több forrásból származó bizonyítékot igényel), így az adatkészlet kihívást jelent (a FEVER állításainak csak 13%-a sok-hop). Továbbá, annak ellenére, hogy kisebb edzéskészlettel rendelkezik (mintegy egykilencedik a lázas edzéskészletnek), egy ParsFEVER-re képzett modell hasonló downstream teljesítményt ér el, jelezve az adatkészlet minőségét. Az adatkészletet és a jegyzetelési irányelveket a következő oldalon adjuk ki: https://github.com/Zarharan/ParsFEVER.', 'it': "La formazione e la valutazione delle tecniche automatiche di estrazione e verifica dei fatti richiedono grandi quantità di dati annotati che potrebbero non essere disponibili per i linguaggi a basso contenuto di risorse. Questo articolo presenta ParsFEVER: il primo dataset farsi pubblicamente disponibile per l'estrazione e la verifica dei fatti. Adottiamo la procedura di costruzione del dataset inglese standard per il compito, cioè FEVER, e lo miglioriamo nel caso di lingue a basso contenuto di risorse. In particolare, le affermazioni vengono estratte da frasi accuratamente selezionate per essere più informative. Il set di dati comprende quasi 23K dichiarazioni annotate manualmente. Oltre il 65% dei reclami in ParsFEVER sono multi-hop (richiedono prove da più fonti), rendendo il set di dati un punto di riferimento impegnativo (solo il 13% dei reclami in FEVER sono multi-hop). Inoltre, nonostante abbia un set di allenamento più piccolo (circa un nono di quello in Febbre), un modello addestrato su ParsFEVER raggiunge prestazioni simili a valle, indicando la qualità del set di dati. Rilasciamo il dataset e le linee guida di annotazione a https://github.com/Zarharan/ParsFEVER.", 'kk': 'Автоматты факттарды тарқату және тексеру техникаларының оқытуы және оқытуы керек, бұл көп ресурс тілдері үшін қол жеткізбейтін деректердің үлкен сандары керек. Бұл қағаз ParsFEVER дегенді көрсетеді: факты тарқату мен тексеру үшін алғашқы жеткізетін Farsi деректер жиыны. Біз тапсырма үшін стандартты ағылшын деректер қорларының құрылғы процедурын қолданып, мәселен, FEVER және оны төменгі ресурстар тілдері үшін жасап береміз. Ескерілікті, мәліметті болу үшін таңдалған сөздерден шығарылады. Деректер жиында 23 К қолмен белгіленген сұрақтар бар. ParsFEVER деген жағдайлардың 65% артық көп-хопты (бірнеше көзгертілген көзгертілген мәліметтерді талап етеді), деректер жиынының көмектесу белгісін жасау (FEVER деген жағдайлардың тек 13% ғана к Сонымен қатар, жиілікті оқыту бағдарламасы (Fever дегеннің 9-інші жағында), ParsFEVER бағдарламасындағы оқыту үлгісі ұқсас жеткізеді, деректер жиының сапатын көрсетеді. Біз деректер жиынын және жазбалардың бағыттауларын https://github.com/Zarharan/ParsFEVER.', 'ms': 'Latihan dan penilaian teknik ekstraksi fakta dan pengesahan automatik memerlukan jumlah besar data yang dicatat yang mungkin tidak tersedia untuk bahasa sumber rendah. Kertas ini memperkenalkan ParsFEVER: set data Farsi pertama yang tersedia secara awam untuk pengekstrakan dan pengesahan fakta. Kami menerima prosedur pembinaan set data Inggeris piawai untuk tugas, iaitu FEVER, dan memperbaikinya untuk kes bahasa sumber rendah. Specifically, claims are extracted from sentences that are carefully selected to be more informative.  Set data terdiri hampir 23K klaim yang dicatat secara manual. Lebih dari 65% klaim di ParsFEVER adalah banyak-hop (memerlukan bukti dari sumber berbilang), menjadikan set data benchmark mencabar (hanya 13% klaim di FEVER adalah banyak-hop). Juga, walaupun mempunyai set latihan yang lebih kecil (sekitar satu-sembilan daripada yang pada Fever), model yang dilatih pada ParsFEVER mencapai prestasi turun yang sama, menunjukkan kualiti set data. Kami melepaskan set data dan arahan anotasi di https://github.com/Zarharan/ParsFEVER.', 'ml': 'Training and evaluation of automatic fact extraction and verification techniques require large amounts of annotated data which might not be available for low-resource languages.  ഈ പത്രത്തില്\u200d പാര്\u200dസ്ഫെവെര്\u200d കാണിക്കുന്നു: ആദ്യത്തെ പ്രധാനപ്പെടുത്തുന്ന ഫാര്\u200dസി ഡാറ്റാസറ്റ് പ്രത് ജോലിക്കുള്ള സാധാരണ ഇംഗ്ലീഷ് ഡാറ്റാസെറ്റിന്റെ നിര്\u200dമ്മാണപ്രക്രിയയെ ഞങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്നു, ഉദാഹരണത്തിനായി FEVER, അതി പ്രത്യേകിച്ച്, കൂടുതല്\u200d വിവരങ്ങള്\u200d ആയിരിക്കാന്\u200d ശ്രദ്ധിച്ച് തെരഞ്ഞെടുക്കപ്പെട്ട വാക്കുകളില്\u200d നിന് ഡാറ്റാസെറ്റ് കൂടുതല്\u200d 23K കൈയ്യില്\u200d കൈകാര്യം വിചാരിക്കപ്പെട്ട വാക്കുകളുണ്ട്. പാര്\u200dസ്\u200cഫെവെരിലെ 65% കൂടുതല്\u200d പാര്\u200dസ്ഫെവെര്\u200d വാക്കുകള്\u200d ഒരുപാട് തെളിവുകളാണ് (പല സ്രോതസ്സുകളില്\u200d നിന്നും തെളിവുകള്\u200d ആവശ്യമുണ്ട്), ഡാറ്റാസെറ്റ് വ ഒരു ചെറിയ പരിശീലനത്തിന്റെ സെറ്റ് ഉണ്ടായിരുന്നില്ലെങ്കിലും പാര്\u200dസ്ഫെവെരില്\u200d പരിശീലിക്കപ്പെട്ട ഒരു മോഡല്\u200d പ്രദര്\u200dശിപ്പിക്കുന്നു. ഡാ നമ്മള്\u200d ഡാറ്റാസെറ്റും പ്രഖ്യാപിക്കുന്ന വഴികാട്ടുകളും വിട്ടുകളയുന്നു https://github.com/Zarharan/ParsFEVER.', 'mk': 'Training and evaluation of automatic fact extraction and verification techniques require large amounts of annotated data which might not be available for low-resource languages.  Овој весник го претставува ParsFEVER: првиот јавно достапен фарсиски податок за извлекување и верификација на факти. Ние ја усвоивме процедурата на изградба на стандардниот англиски податок за задачата, tj. ФЕВЕР, и ја подобруваме за случајот на јазици со ниски ресурси. Специфично, тврдењата се извадени од речениците кои се внимателно избрани за да бидат поинформативни. Податоците се состојат од речиси 23K рачно анотирани тврдења. Повеќе од 65 отсто од тврдењата во ПарсФЕВЕР се многу-хоп (бараат докази од повеќе извори), што го прави наборот на податоци предизвикувачки референц (само 13 отсто од тврдењата во ФЕВЕР се многу-хоп). Исто така, и покрај тоа што има помал набор обуки (околу една деветка од она во февруари), модел обучен на ParsFEVER постигнува слична понатамошна перформанса, што покажува квалитет на наборот на податоци. Ги објавуваме податоците и насоките за анотација на https://github.com/Zarharan/ParsFEVER.', 'lt': 'Mokymui ir automatinio faktų gavimo ir tikrinimo metodų vertinimui reikalingas didelis užrašytų duomenų kiekis, kuris gali būti nesuteiktas mažai išteklių turinčioms kalboms. Šiame dokumente pateikiamas ParsFEVER: pirmasis viešai prieinamas Farsi duomenų rinkinys faktų gavimui ir tikrinimui. We adopt the construction procedure of the standard English dataset for the task, i.e., FEVER, and improve it for the case of low-resource languages.  Konkrečiai teiginiai ištraukiami iš nuodugniai atrinktų sakinių, kad jie būtų išsamesni. Duomenų rinkinį sudaro beveik 23K rankiniu būdu užrašytų reikalavimų. Daugiau kaip 65 proc. pareiškimų pagal ParsFEVER yra daug apynių (reikalaujama įrodymų iš įvairių šaltinių), todėl duomenų rinkinys yra sudėtingas lyginamasis rodiklis (tik 13 proc. pareiškimų pagal FEVER yra daug apynių). Be to, nepaisant mažesnio mokymo rinkinio (maždaug devyniasdešimtojo, palyginti su vasario mėn.), ParsFEVER parengtas modelis pasiekia panašius tolesnius rezultatus, rodančius duomenų rinkinio kokybę. Mes skelbiame duomenų rinkinį ir anotacijų gaires https://github.com/Zarharan/ParsFEVER.', 'mt': 'It-taħriġ u l-evalwazzjoni ta’ tekniki awtomatiċi ta’ estrazzjoni u verifika tal-fatti jeħtieġu ammonti kbar ta’ dejta annotata li jista’ ma jkunx disponibbli għal lingwi b’riżorsi baxxi. Dan id-dokument jippreżenta ParsFEVER: l-ewwel sett ta’ dejta Farsi disponibbli għall-pubbliku għall-estrazzjoni u l-verifika tal-fatti. Aħna niddottaw il-proċedura ta’ kostruzzjoni tas-sett tad-dejta standard Ingliż għall-kompitu, jiġifieri FEVER, u ntejbuha għall-każ ta’ lingwi b’riżorsi baxxi. Speċifikament, it-talbiet jiġu estratti minn sentenzi li jintgħażlu bir-reqqa biex ikunu aktar informativi. The dataset comprises nearly 23K manually-annotated claims.  Aktar minn 65% tal-pretensjonijiet fil-ParsFEVER huma ħafna ħops (jeħtieġu evidenza minn diversi sorsi), li jagħmlu s-sett tad-dejta punt ta’ riferiment ta’ sfida (13% biss tal-pretensjonijiet fil-FEVER huma ħafna ħops). Barra minn hekk, minkejja li għandu sett ta’ taħriġ iżgħar (madwar disa’ minn dak ta’ Deni), mudell imħarreġ fuq ParsFEVER jikseb prestazzjoni simili downstream, li tindika l-kwalità tas-sett tad-dejta. Aħna nħarġu s-sett tad-dejta u l-linji gwida għall-annotazzjoni fuq https://github.com/Zarharan/ParsFEVER.', 'mn': "Автоматик үйлдэл гаргах, шийдвэрлэх технологиудын суралцах, үнэлгээ нь бага боломжтой хэл дээр байж болохгүй маш олон анзаарсан өгөгдлийг хэрэгтэй. Энэ цаас ParsFEVER-г харуулж байна: анхны олон нийтэд Фарси өгөгдлийн санг үнэндээ гаргаж, шийдвэрлэх боломжтой. Бид энэхүү ажлын стандарт Англи өгөгдлийн сангийн бүтээлтийн процедурыг ашиглаж, яг л FEVER, бага боловсролын хэлний тухай сайжруулж байна. Ялангуяа, илүү мэдээлэл өгүүлбэр сонгогдсон өгүүлбэрээс гарч ирдэг. Өгөгдлийн хэлбэр нь бараг 23K гараар анзаарсан утгыг агуулдаг. ParsFEVER-ын хэлэлцээний 65%-аас илүү олон холбоотой (олон эх үүсвэрээс баталгаа хэрэгтэй), өгөгдлийн санг шаардлагатай салбар болгодог (FEVER-д зөвхөн 13% нь олон холбоотой). Мөн бага сургалтын сургалтын тоо байхдаа (Fever's 9-р орчим нь) ParsFEVER-д сургалтын загвар нь төстэй доорх үйл ажиллагааг хүртэл өгөгдлийн сангийн салбарыг харуулдаг. Бид өгөгдлийн сангууд болон анзаарлын удирдлагуудыг https://github.com/Zarharan/ParsFEVER.", 'no': 'Treng og evaluering av automatiske faktiske ekstraksjon og verifikasjonsverktøyar krev stor mengda notata data som kanskje ikkje er tilgjengeleg for låg ressursspråk. Denne papiret viser ParsFEVER: den første offentlig tilgjengelege Farsi- dataset for faktisk utpakking og verifikasjon. Vi adopterer konstruksjonsprosedyren for standardingsdatasettet for oppgåva, t.d. FEVER, og forbedrar det i tilfellet med låg ressursspråk. Spesielt vert søknader ekstraherte frå setningar som er forsiktig valde for å vera meir informativ. Datasettet inneheld nesten 23K manuelt oppmerking. Over 65% av tiltak i ParsFEVER er mange hopper (krev beviser frå fleire kjelde), og lager datasettet eit vanskeleg benchmarkt (berre 13% av tiltak i FEVER er mange hopper). Dess tross å ha eit mindre treningsinnstilling (rundt ein ni av det i Fever), har eit modell trent på ParsFEVER tilnærming som er liknande nedstrekkutvikling, som viser kvaliteten på datasettet. Vi løyser datasettet og hjelpelinjene for merking på https://github.com/Zarharan/ParsFEVER.', 'pl': 'Szkolenie i ocena technik automatycznego ekstrakcji i weryfikacji faktów wymagają dużych ilości adnotacji danych, które mogą nie być dostępne dla języków o niskich zasobach. W artykule przedstawiono ParsFEVER: pierwszy publicznie dostępny zestaw danych z perskiego języka do ekstrakcji i weryfikacji faktów. Przyjmujemy do tego zadania procedurę budowy standardowego zestawu danych angielskiego, czyli FEVER, i ulepszamy ją w przypadku języków niskich zasobów. W szczególności, roszczenia są ekstraktowane ze zdań, które są starannie dobrane, aby były bardziej informacyjne. Zestaw danych obejmuje prawie 23K ręcznie adnotatowane roszczenia. Ponad 65% roszczeń w ParsFEVER są liczne (wymagają dowodów z wielu źródeł), co sprawia, że zbiór danych stanowi wyzwanie odniesienia (tylko 13% roszczeń w FEVER to wiele-hop). Ponadto, pomimo mniejszego zestawu treningowego (około jednej dziewiątej tego w Fever), model trenowany na ParsFEVER osiąga podobną wydajność, wskazując na jakość zbioru danych. Publikujemy zbiór danych i wytyczne dotyczące adnotacji na stronie internetowej https://github.com/Zarharan/ParsFEVER.', 'ro': 'Instruirea și evaluarea tehnicilor automate de extragere și verificare a faptelor necesită cantități mari de date adnotate, care ar putea să nu fie disponibile pentru limbile cu resurse reduse. Această lucrare prezintă ParsFEVER: primul set de date farsi disponibil public pentru extragerea și verificarea faptelor. Adoptăm procedura de construcție a setului standard de date engleză pentru sarcină, adică FEVER, și o îmbunătățim în cazul limbilor cu resurse reduse. Mai exact, afirmațiile sunt extrase din propoziții care sunt atent selectate pentru a fi mai informative. Setul de date cuprinde aproape 23.000 de afirmații adnotate manual. Peste 65% din afirmațiile din ParsFEVER sunt multi-hop (necesită dovezi din mai multe surse), ceea ce face ca setul de date să fie un criteriu de referință provocator (doar 13% din afirmațiile din FEVER sunt multi-hop). De asemenea, în ciuda faptului că are un set de antrenamente mai mic (aproximativ o nouă din cel din febră), un model instruit pe ParsFEVER atinge performanțe similare în aval, indicând calitatea setului de date. Lansăm setul de date și ghidurile de adnotare la https://github.com/Zarharan/ParsFEVER.', 'sr': 'Treniranje i procjena automatskih tehnika izvlačenja činjenica i verifikacije zahteva velike količine annotiranih podataka koje možda nisu dostupne za jezike niskih resursa. Ovaj papir predstavlja ParsFEVER: prvi javno dostupni komplet podataka Farsi za izvlačenje i verificiju. Usvojimo gradnju standardne engleske dataset za zadatak, tj. FEVER, i poboljšamo ga za slučaj jezika niskih resursa. Posebno, tvrdnja su izvučena iz rečenica koje su pažljivo izabrane da budu informativnije. Podaci sastavljaju skoro 23K manualno annotirane tvrdnje. Preko 65% tvrdnji u ParsFEVERu su mnogi-hopovi (zahtevaju dokaze iz višestrukih izvora), čineći kompletu podataka izazovnom kritiku (samo 13% tvrdnji u FEVER su mnogi-hopovi). Također, uprkos manjim treningama (oko devetog od toga u groznici), model obučen na ParsFEVER postiže sličan niz stručnjak, ukazujući na kvalitet set a podataka. Puštamo podatke i uputstva za annotaciju https://github.com/Zarharan/ParsFEVER.', 'si': 'ස්වයංක්\u200dරියාත්මක විශ්වාසය සහ පරීක්ෂණ ප්\u200dරක්\u200dරියාත්මක විශ්වාසය සඳහා ස්වයංක්\u200dරියාත්මක විශ්වාසය සඳහා  මේ පත්තර ප්\u200dරදේශය ParsFEVER: මුලින්ම ප්\u200dරධාන ප්\u200dරතිකාරයෙන් ෆාර්සි දත්ත සෙට් විතරයි ඇත්තටම ප්\u200dරතිකා අපි ප්\u200dරමාණය ඉංග්\u200dරීසි දත්ත සෙට්ටුවේ ස්ථාවිත භාෂාව සඳහා නිර්මාණය කරනවා, ඉතින්, FEVER, ඒ වගේම ඒක අඩුම භාෂ විශේෂයෙන්, ප්\u200dරශ්නයක් විශේෂයෙන් ප්\u200dරශ්නයක් තියෙන්නේ වචන වලින් ප්\u200dරශ්නයක් විතරයි.  දත්ත සෙට් එක්ක 23K වලින් අත්තර්ජනය කරලා තියෙනවා. ParsFEVER වලින් ප්\u200dරශ්නයක් 65% වඩා ගොඩක් හොප් වෙනවා (වඩා මුළු ප්\u200dරශ්නයක් නිසා සාක්ෂි අවශ්\u200dයයි), දත්ත සෙට් එක ප්\u200dරශ්නයක් වෙන්න පු ඒ වගේම, පොඩි ප්\u200dරශ්නයක් තියෙන්න තියෙන්නේ නැත්නම් (Fever වලින් ඒකෙන් අනුවෙන් 9 වෙනි වලින්), ParsFEVER වලින් ප්\u200dරශ්නයක් ප්\u200dරශ්න අපි දත්ත සෙට් එක්ක සහ ආරංචිකරණ මාර්ගය ප්\u200dරකාශ කරනවා https://github.com/Zarharan/ParsFEVER.', 'so': 'Waxbarashada iyo qiimeynta dhaqdhaqaalaha iyo xaqiiqsashada waxaa loo baahan yahay macluumaad faro badan oo aan laga helin luqadaha hoose-resource. Kanu warqaddaas wuxuu soo bandhigaa ParsFEVER: marka ugu horeysa la soo diro iyo xaqiijinta farsi. Waxaynu qaadannaa baaritaanka dhismaha macluumaadka afka Ingiriiska e e caadiga ah, tusaale ahaan FEVER, waxaana horumarinaynaa xaalada luqadaha hoose-resource. Specifically, claims are extracted from sentences that are carefully selected to be more informative.  Taariikhda macluumaadku waxay ka kooban tahay in dhowr 23K oo qof qof u baahan. 65% oo ka badnaan dacwadda ParsFEVER waa fara badan (waxay u baahan yihiin calaamado badan, waxayna macluumaadka ka dhigaan bangiyo adag (13% oo ka mid ah dacwadda FEVER waa dad badan). Sidoo kale, in kastoo uu haysto waxbarasho yar (qiyaastii sagaal iyo sagaal ka mid ah xafiiska), model lagu baranayo ParsFEVER wuxuu helaa sameynta u eg xiliga webiga hoose, kaas oo muuqata tijaabada macluumaadka. Waxaynu bixinnaa kooxda macluumaadka iyo hogaamiyayaasha caafimaadka https://github.com/Zarharan/ParsFEVER.', 'sv': 'Utbildning och utvärdering av tekniker för automatisk faktautvinning och verifiering kräver stora mängder kommenterade data som kanske inte är tillgängliga för språk med låg resurs. Denna uppsats presenterar ParsFEVER: den första offentligt tillgängliga farsi datauppsättningen för faktautvinning och verifiering. Vi antar konstruktionsproceduren för den engelska standarddatauppsättningen för uppgiften, dvs FEVER, och förbättrar den för lågresursspråk. Specifikt extraheras påståenden från meningar som är noggrant utvalda för att vara mer informativa. Datauppsättningen omfattar nästan 23 000 manuellt kommenterade anspråk. Över 65% av påståendena i ParsFEVER är många-hop (kräver bevis från flera källor), vilket gör datauppsättningen till ett utmanande riktmärke (endast 13% av påståendena i FEVER är många-hop). Även om en modell som tränats på ParsFEVER har en mindre träningsuppsättning (ungefär en nionde av den i Feber), uppnår en modell som tränats på ParsFEVER liknande prestanda nedströms, vilket indikerar datasetets kvalitet. Vi publicerar datauppsättningen och kommenteringsriktlinjerna på https://github.com/Zarharan/ParsFEVER.', 'ta': 'தானியங்கி உண்மை பிரித்தல் மற்றும் சரிபார்க்கப்படும் தொழில்நுட்பத்திற்கு பயிற்சி மற்றும் மதிப்பிடுதல் குறைந்த மூலத்திற்க இந்த தாள் ParsFEVER காட்டுகிறது: உண்மையை வெளியேற்றுதல் மற்றும் உறுதிப்படுத்தலுக்கான முதல் பார்சி தரவு அமைப நாம் பணிக்கான இயல்பான ஆங்கிலத்தின் தரவு அமைப்பின் கட்டும் செயலை எடு குறிப்பிட்ட குறிப்பிட்டு, மேலும் தகவலாக தேர்ந்தெடுக்கப்பட்ட வாக்கியங்களிலிருந்து குறிப்பிட தகவல் அமைப்பு கிட்டத்தட்ட 23K கைமுறையாக குறிக்கப்பட்ட கோப்புகள் உள்ளது. 65% க்கு மேல் பார்ஸ்FEVER என்ற கூறுகள் பல- ஹாப் (பல மூலங்களிலிருந்து தெளிவான ஆதாரங்கள் தேவை), தகவல்கள் சவாலிக்கையான பெங்க்குருக்கு உருவாக்குகிறத மேலும், சிறிய பயிற்சி அமைப்புகள் இருந்தாலும் (பெப்வரில் ஒன்பது ஒன்பது முறை), பார்ஸ்FEVER மீது பயிற்சிக்கப்பட்ட ஒரு மாதிரி கிடைக்கும், தரவ நாங்கள் தகவல் அமைப்பு மற்றும் அறிவிப்பு நேர்வழிகாட்டிகளை வெளியேற்றுகிறோம் https://github.com/Zarharan/ParsFEVER.', 'ur': 'آٹوٹی حقیقت اٹھانے اور تصدیق کی ٹیکنیک کی ترینینگ اور ارزیابی کی بہت سی اندازے اٹھانے والی ڈیٹا کی ضرورت ہے جو کم منبع زبانوں کے لئے موجود نہیں ہو سکتی۔ This paper presents ParsFEVER: the first publicly available Farsi data set for fact extraction and verification. ہم اس کام کے لئے استاندارڈ انگلیسی ڈیٹ سٹ کی بنیاد پردازی کو قبول کرتے ہیں، یعنی FEVER، اور اسے کم منبع زبانوں کے مطابق بہتر کر دیتے ہیں. مخصوص طور پر، مطلوبات کلمات سے نکالے جاتے ہیں جو زیادہ اطلاعات کے لئے انتخاب کئے جاتے ہیں. ڈاٹا سٹ میں تقریباً 23 کیلومتر کے ذریعہ مضبوط تعلیم ہیں. ParsFEVER میں سے 65 درصد سے زیادہ بڑھ کر بہت سے ہوپ ہیں (بہت سی سورجوں سے دلیل لازم ہے) اور ڈیٹ سٹ کو اچانک بنچم مارک بناتے ہیں (FEVER میں صرف 13 درصد کے سوال بہت سے ہوپ ہیں). اس کے علاوہ بھی، ایک چھوٹا تربیت مجموعہ ہوتا ہے (اس میں سے ایک نوینویں مہینے مہینے مہینے) پر ParsFEVER پر آموزش کی مدل ایسی طرح کی پرورش حاصل کرتا ہے جو ڈیٹسٹ کی کیفیت دکھاتا ہے۔ ہم ڈاٹ سٹ اور انٹوریٹ ہدایت کریں https://github.com/Zarharan/ParsFEVER.', 'uz': "Name Bu hujjat ParsFEVER: faqat olish va tasdiqlash uchun birinchi toʻgʻri boʻlgan Farsi maʼlumot set. Biz vazifa uchun andoza ingliz tili maʼlumotlar tizimini ishlab chiqarish imkoniyatini, balki FEVER, va buni qisqa manbaning tili uchun bajaramiz. @ info Name ParsFEVERdagi 65% dan ortiq so'zlarni ko'p yozuvlar kerak (bir nechta manbalar uchun hujjatlar kerak), maʼlumotlarni qandaydir benchmark qilishi mumkin (faqat FEVER sohasida 13% soʻzlari ko'p jump. Ko'pchilik taʼminlovchi bo'lsa ham (Fever'da birinchi sagacha o'rnatilgan bo'lsa, ParsFEVER'da o'rnatilgan model taʼminlovchi soʻzni o'zgartiradi, maʼlumot tizimning sifatini koʻrsatish mumkin. Biz maʼlumotlar sahifasini va taʼminlovchi qoidalarni https://github.com/Zarharan/ParsFEVER.", 'vi': "Việc đào tạo và đánh giá kỹ thuật thực tế tự động khai thác và kiểm tra đòi hỏi một lượng lớn dữ liệu ghi chú mà có thể không có sẵn cho ngôn ngữ ít nguồn. Tờ giấy này trình bày:bộ nhớ dữ liệu Farsi đầu tiên công khai để thực tế trích và kiểm tra. Chúng tôi sử dụng quy trình xây dựng của bộ dữ liệu Anh tiêu chuẩn cho nhiệm vụ này, luôn luôn luôn có liên quan đến các ngôn ngữ có ít tài nguyên. Cụ thể, các yêu cầu được trích ra từ câu được chọn cẩn thận để có thêm thông tin. Bộ dữ liệu bao gồm gần 23K khai thác bằng bút. Hơn 682='các tuyên bố ở ParsFEer là nhiều nhà hàng (yêu cầu bằng chứng từ nhiều nguồn) khiến bộ nhớ dữ liệu trở thành tiêu chuẩn đầy thử thách (chỉ 13=' của các yêu cầu trong tập truyện viễn chinh là nhiều nhà buôn). Mặc dù có một bộ huấn luyện nhỏ hơn (khoảng một lần thứ chín trong số đó ở Fever), một mô hình được huấn luyện trên Parsifer cũng đạt được hiệu suất xuôi dòng tương tự, chỉ ra chất lượng của bộ dữ liệu. Chúng tôi công bố bộ dữ liệu và hướng dẫn ghi chú ở... https://github.com/Zarharan/ParsFEVER.", 'bg': 'Обучението и оценката на техниките за автоматично извличане и проверка на факти изискват големи количества анотирани данни, които може да не са налични за езици с нисък ресурс. Настоящата статия представя първият обществено достъпен фарси набор от данни за извличане и проверка на факти. Приемаме процедурата по конструиране на стандартния английски набор от данни за задачата, т.е. ФЕВЕР, и я подобряваме за случая с нискоресурсни езици. По-конкретно, твърденията се извличат от изречения, които са внимателно подбрани, за да бъдат по-информативни. Наборът от данни включва близо 23 000 ръчно анотирани твърдения. Над 65% от твърденията в ПарsFEVER са многохопови (изискват доказателства от множество източници), което прави набора от данни предизвикателен референтен показател (само 13% от твърденията във ФЕVER са многохопови). Също така, въпреки че има по-малък набор от тренировки (около една девета от този при треска), модел, обучен на ParsFEVER, постига сходни резултати надолу по веригата, което показва качеството на набора от данни. Публикуваме набора от данни и указанията за анотация на адрес: https://github.com/Zarharan/ParsFEVER.', 'da': 'Uddannelse og evaluering af automatiske teknikker til udvinding og verifikation af fakta kræver store mængder noterede data, som muligvis ikke er tilgængelige for sprog med lav ressource. Denne artikel præsenterer ParsFEVER: det første offentligt tilgængelige farsi datasæt til faktaudveksling og verifikation. Vi anvender byggeproceduren for det almindelige engelske datasæt til opgaven, dvs. FEVER, og forbedrer det til tilfælde af lav ressource sprog. Specielt udvindes påstande fra sætninger, der er omhyggeligt udvalgt til at være mere informative. Datasættet omfatter næsten 23K manuelt kommenterede krav. Over 65% af påstandene i ParsFEVER er mange-hop (kræver dokumentation fra flere kilder), hvilket gør datasættet til et udfordrende benchmark (kun 13% af påstandene i FEVER er mange-hop). På trods af at have et mindre træningssæt (omkring en niende af det i feber), opnår en model, der er trænet på ParsFEVER, tilsvarende downstream performance, hvilket indikerer kvaliteten af datasættet. Vi frigiver datasættet og retningslinjerne for anmærkning på https://github.com/Zarharan/ParsFEVER.', 'nl': 'Opleiding en evaluatie van automatische feitenextractie- en verificatietechnieken vereisen grote hoeveelheden geannoteerde gegevens die mogelijk niet beschikbaar zijn voor talen met weinig middelen. Dit artikel presenteert ParsFEVER: de eerste publiek beschikbare Farsi dataset voor factextractie en verificatie. We hanteren de constructieprocedure van de standaard Engelse dataset voor de taak, dat wil zeggen FEVER, en verbeteren deze voor het geval van low-resource talen. Specifiek worden claims geëxtraheerd uit zinnen die zorgvuldig zijn geselecteerd om meer informatief te zijn. De dataset bestaat uit bijna 23K manueel geannoteerde claims. Meer dan 65% van de claims in ParsFEVER zijn many-hop (vereist bewijs uit meerdere bronnen), waardoor de dataset een uitdagende benchmark is (slechts 13% van de claims in FEVER zijn many-hop). Ook ondanks een kleinere trainingsset (ongeveer een negende van die in Fever), bereikt een model dat getraind is op ParsFEVER vergelijkbare downstreamprestaties, wat de kwaliteit van de dataset aangeeft. We geven de dataset en de annotatie richtlijnen vrij op https://github.com/Zarharan/ParsFEVER.', 'hr': 'Vježba i procjena tehnika automatske izvlačenja činjenica i provjere zahtijeva velike količine annotiranih podataka koje možda nisu dostupne za jezike niskih resursa. Ovaj papir predstavlja ParsFEVER: prvi javno dostupni komplet podataka Farsi za izvlačenje i potvrdu. Usvojimo postupak izgradnje standardne engleske dataset za zadatak, tj. FEVER, i poboljšamo ga za slučaj jezika niskih resursa. Posebno, tvrdnja su izvučena iz rečenica koje su pažljivo odabrane da budu informativnije. Podaci uključuju gotovo 23K priručno označene tvrdnje. Preko 65% tvrdnji u ParsFEVERu su mnogi hopovi (zahtijevaju dokaze iz višestrukih izvora), čineći kompletu podataka izazovnom kritiku (samo 13% tvrdnji u FEVER su mnogi hopovi). Također, uprkos manjim treningama (oko devetog od toga u groznici), model obučen na ParsFEVER postiže sličan niz stručnjak, ukazujući na kvalitetu kompleta podataka. Puštamo podatke i uputstva za annotaciju https://github.com/Zarharan/ParsFEVER.', 'de': 'Die Schulung und Bewertung von automatischen Faktenextraktions- und Verifizierungstechniken erfordert große Mengen annotierter Daten, die für ressourcenarme Sprachen möglicherweise nicht verfügbar sind. Dieser Beitrag stellt ParsFEVER vor: den ersten öffentlich zugänglichen Farsi-Datensatz zur Faktenextraktion und Verifizierung. Wir übernehmen das Konstruktionsverfahren des englischen Standarddatensatzes für die Aufgabe, d.h. FEVER, und verbessern es für den Fall von ressourcenarmen Sprachen. Konkret werden Ansprüche aus Sätzen extrahiert, die sorgfältig ausgewählt wurden, um informativer zu sein. Der Datensatz umfasst fast 23K manuell annotierte Ansprüche. Mehr als 65% der Ansprüche in ParsFEVER sind Many-Hop (erfordern Beweise aus mehreren Quellen), was den Datensatz zu einem herausfordernden Benchmark macht (nur 13% der Ansprüche in FEVER sind Many-Hop). Auch wenn ein auf ParsFEVER trainiertes Modell einen kleineren Trainingssatz hat (etwa ein Neuntel davon in Fever), erreicht es eine ähnliche Downstream-Performance, was die Qualität des Datensatzes anzeigt. Den Datensatz und die Anmerkungsrichtlinien veröffentlichen wir unter https://github.com/Zarharan/ParsFEVER.', 'id': 'Pelatihan dan evaluasi teknik ekstraksi fakta otomatis dan verifikasi memerlukan jumlah besar data yang dicatat yang mungkin tidak tersedia untuk bahasa sumber daya rendah. Kertas ini mempersembahkan ParsFEVER: set data Farsi pertama yang tersedia publik untuk ekstraksi fakta dan verifikasi. Kami mengadopsi prosedur konstruksi dari set data standar Inggris untuk tugas, yaitu FEVER, dan memperbaikinya untuk kasus bahasa sumber daya rendah. Secara spesifik, klaim dikeluarkan dari kalimat yang dipilih dengan hati-hati untuk lebih informatif. Set data terdiri hampir 23K klaim yang dicatat secara manual. Lebih dari 65% klaim di ParsFEVER adalah banyak-hop (membutuhkan bukti dari berbagai sumber), membuat dataset benchmark yang menantang (hanya 13% klaim di FEVER adalah banyak-hop). Juga, meskipun memiliki set pelatihan yang lebih kecil (sekitar satu-sembilan dari yang di Fever), model yang dilatih di ParsFEVER mencapai prestasi turun yang sama, menunjukkan kualitas dataset. Kami melepaskan dataset dan petunjuk anotasi di https://github.com/Zarharan/ParsFEVER.', 'sw': 'Kufundisha na kutathmini mbinu za kujitokeza za ukweli na kuthibitishwa zinahitaji kiasi kikubwa cha taarifa ambazo haziwezi kupatikana kwa lugha ndogo ya rasilimali. Gazeti hili linawasilisha ParsFEVER: kituo cha kwanza kinachopatikana hadharani cha data cha Farsi kwa ajili ya utekelezaji na kuthibitishwa kwa ukweli. Tunaweza kutekeleza mchakato wa ujenzi wa taarifa za kawaida za Kiingereza kwa ajili ya kazi hiyo, yaani FEVER, na kuboresha kwa kesi ya lugha za chini za rasilimali. Kwa hakika, madai yanaondolewa kutoka sentensi ambazo zinachaguliwa kwa makini ili kuwa taarifa zaidi. Taasisi ya taarifa hiyo ina takribani madai yanayotangazwa kwa manufaa. Over 65% of the claims in ParsFEVER are many-hop (require evidence from multiple sources), making the dataset a challenging benchmark (only 13% of the claims in FEVER are many-hop).  Pia, pamoja na kuwa na seti ndogo ya mafunzo (takribani tisa moja ya hilo jijini Februari), mtindo wa mafunzo kwenye ParsFEVER unapata ufanisi unaofanana na mito ya chini, unaonyesha kiwango cha takwimu. Tunaachia taarifa na miongozo ya kutangaza https://github.com/Zarharan/ParsFEVER.', 'ko': '자동 사실 추출과 검증 기술의 교육과 평가는 대량의 주석 데이터를 필요로 하는데 이런 데이터는 저자원 언어에 적합하지 않을 수 있다.본고는 Parsferre: 최초로 공개된 사실 추출과 검증에 사용되는 페르시아어 데이터 집합을 소개한다.우리는 표준 영어 데이터 집합의 구축 과정, 즉 FERE를 완성하고 저자원 언어의 상황에서 이를 개선했다.구체적으로 성명은 더 많은 정보를 제공하기 위해 정성들여 고른 문장에서 추출된 것이다.이 데이터 세트에는 23K개에 가까운 수동 주석에 대한 클레임이 포함되어 있다.Parsferre에서 65%가 넘는 성명은 다중 점프(여러 출처에서 나온 증거가 필요함)이다. 이로 인해 데이터 집합은 도전적인 기준이 된다(13%의 성명만 다중 점프이다).또한 작은 훈련집(열이 날 때의 약 9분의 1)이 있지만 파르스퍼러에서 훈련된 모델은 유사한 하류 성능을 얻을 수 있어 데이터 집합의 질을 나타낸다.데이터 세트와 주석 가이드를 발표했습니다.https://github.com/Zarharan/ParsFEVER.', 'af': "Onderwysing en evaluering van outomatiese fakte uittrekking en verifikasie teknike benodig groot hoeveelheid notate data wat dalk mag nie beskikbaar wees vir lae hulpbron tale. Hierdie papier stel ParsFEVER voor: die eerste openlik beskikbaar Farsi datastel vir feit uittrek en verifikasie. Ons aanvaar die konstruksieprosedure van die standaard Engelske datastel vir die taak, i.e. FEVER, en verbeter dit vir die geval van lae hulpbron tale. Spesifieke, versoekte word uitgevoer van setnings wat versigtig gekose word om meer inligting te wees. Die datastel bevat byna 23K hand- annotated voorwaardes. Oor 65% van die aandrukkings in ParsFEVER is baie-hop (benodig bevestigheid van veelvuldige bronne), maak die datastel 'n pragtige benchmark (slegs 13% van die aandrukkings in FEVER is baie-hop). Ook, ten trots 'n kleiner onderwerp stel (omtrent een-negende van dit in Fever), het 'n model onderwerp op ParsFEVER gelyk onderwerp prestasie aangekom en die kwaliteit van die datastel aandui. Ons verlos die datastel en die annotasie gidselyn op https://github.com/Zarharan/ParsFEVER.", 'fa': 'آموزش و ارزیابی تکنیک\u200cهای استخراج و تایید حقیقت\u200cهای خودکار نیاز به اندازه\u200cهای زیادی از داده\u200cهای یادآوری که ممکن است برای زبانهای کم منابع در دسترس نیستند. این کاغذ ParsFEVER را نشان می دهد: اولین مجموعه داده های فارسی برای اخراج و تصدیق حقیقت. ما روش ساختن داده\u200cهای استاندارد انگلیسی برای این کار، یعنی FEVER، و آن را برای پرونده زبانهای کم منابع بهبود می\u200cدهیم. مخصوصاً ادعا از جمله\u200cها خارج شده\u200cاند که به طور دقت انتخاب شده\u200cاند تا اطلاعات بیشتری باشند. مجموعه داده\u200cها تقریباً 23 کیلومتر درخواست\u200cهای دستگیر شده است. بیش از ۶۵ درصد از ادعا در ParsFEVER بسیاری از هوپ هستند (مدرک از منبع متعدد نیاز دارند) که مجموعه داده\u200cها را یک مقدار مشکل (تنها ۱۳ درصد از ادعا در FEVER بسیاری از هوپ است). همچنین، با وجود مجموعه آموزش کوچکتر (حدود یک نومین از آن در فشر) یک مدل آموزش یافته در ParsFEVER به عملکرد پایین\u200cترین موجود می\u200cرسد، نشان می\u200cدهد کیفیت مجموعه داده\u200cها. ما مجموعه\u200cهای داده\u200cها و راهنمایی\u200cهای نوشته\u200cها را آزاد می\u200cکنیم https://github.com/Zarharan/ParsFEVER.', 'tr': "Otomatik fakty gaýşartma we barlamak teknikleri düşük-çeşme dilleri üçin mejbur bolmaýan uly sanlary gerek. Bu kagyz ParsFEVER'i görkezýär: ilkinji sahypa uzak faýllary çekmek we barlamak üçin peýdalanýar. Biz adatça Iňlis dilleriniň esasy üçin adatça datawatlarynyň gurama procedesini kabul edip görýäris, i ň. FEVER we muny iň az resurslar dili üçin gowy görýäris. Adatça, dykkatly saýlanan sözlerden daşary maglumaty bolmak üçin aýyrylýar. Maglumat setiriniň eýdançasynda 23 Ködler ýaly tanyşdyrylýan iddialary bar. ParsFEVERyň 65% sany üstünde köp hop (birnäçe çeşmeden kanıtlary gerek), veri setirini çykyş salgyny edip görkezilýär (FEVER'de diňe 13% sany köp hop diýip görünýär). Ýöne kiçiräk okuw taýýarlanmagyna raň (Febriýada 9-njy ýylyň töwereginde), ParsFEVER'de okuw taýýarlanmagyna meňzeş bir nusga ýetýär we veri düzümleriniň keyfiýetini görkezýär. Biz veri setirini we ýazgyt düzümlerini boşadyrys https://github.com/Zarharan/ParsFEVER.", 'sq': 'Trenimi dhe vlerësimi i teknikave automatike të nxjerrjes dhe verifikimit të fakteve kërkojnë sasi të mëdha të dhënash të anotuara që mund të mos jenë në dispozicion për gjuhët me burime të ulta. Ky dokument paraqet ParsFEVER: grupi i parë i të dhënave të disponueshme publikisht Farsi për nxjerrjen dhe verifikimin e fakteve. Ne miratojmë procedurën e ndërtimit të sistemit standart të të dhënave angleze për detyrën, pra FEVER, dhe e përmirësojmë atë për rastin e gjuhëve me burime të ulëta. Veçanërisht, pretendimet nxirren nga fjalët që zgjedhen me kujdes për të qenë më informative. Grupi i të dhënave përfshin gati 23K pretendime të anotuara manualisht. Mbi 65% e pretendimeve në ParsFEVER janë shumë-hop (kërkojnë prova nga burime të shumta), duke e bërë grupin e të dhënave një referencë sfiduese (vetëm 13% e pretendimeve në FEVER janë shumë-hop). Gjithashtu, pavarësisht se ka një set trainimi më të vogël (rreth një e nënta e asaj në Shkurt), një model i trajnuar në ParsFEVER arrin performancë të ngjashme poshtë rrjedhës, duke treguar cilësinë e dataset. Ne lëshojmë të dhënat dhe udhëzimet e anotacionit në https://github.com/Zarharan/ParsFEVER.', 'am': 'የእውነት ማውጣት እና ማረጋገጫ የፖስቲካ ማውጣት እና ማረጋገጫ የዝቅተኛ-resource ቋንቋዎች የማይቻል የዳታ ቁጥጥር እንዲያስፈልጋል፡፡ ይህ ገጽ የፊርሲ ዳታዎችን ለማውጣት እና ማረጋገጫ ለመጀመሪያ የተገኘውን የፋርሲን ዳታ ማረጋገጫ ያቀርባል፡፡ የኢንጂልኛ ዳታዎችን ለመሥራት የተደላደለውን የመሠረት ሥርዓት እናደርጋለን፣ አዲስ FEVER እና ለዋናው የክፍለ ሀብት ቋንቋ ቋንቋ እናሳድጋታለን፡፡ በተለያይነት፣ የተጨማሪው ማስታወቂያ ለመሆን ከተመረጡት ከክፍሎች ይወስዳሉ፡፡ የዳታ ሰርቨርስቲው በ23K እጃቸው የተጠቃሚ ጥያቄ ነው፡፡ በፓርስፍEVER ውስጥ 65 በመቶ የሚቆጠሩ ሰዎች ብዙዎች ናቸው (ከብዙ ምንጮች የመረጃ ማስረጃ ያስፈልጋል), የዳውሬውን አዋቂዎች የውጤት ማሰሪያ ማድረግ ማድረግ ማድረግ ማድረግ ብቻ ነው (FEVER ውስጥ 13 በመቶ ብቻ የተመሳሳይ ጉዳይ ብዙዎች ናቸው). በፌፌፌር ውስጥ በዘጠኝ ዘጠኝ ተማሪ ምንም እንኳ ቢኖር የፋስFEVER የተማረ ሞዴል የዳታ ጥያቄን የሚያሳየው የውኃው ፈሳሽ ድምፅ አግኝቷል፡፡ የዳታ ሰርቨርስቲ እና የግንኙነቱን መሪ እናወጣለን https://github.com/Zarharan/ParsFEVER.', 'hy': "Ավտոմատիկ փաստերի վերացման և ստուգումների մեթոդների ուսումնասիրությունը և գնահատումը պահանջում են մեծ քանակությամբ գրված տվյալներ, որոնք կարող են չլինել հասանելի ցածր ռեսուրսների լեզուների համար: Այս փաստաթղթին ներկայացնում է Փարսֆեյվերը' ֆարսի առաջին հանրային հասանելի տվյալների համակարգը փաստերի վերացման և ստուգումների համար: Մենք ընդունում ենք այս խնդրի համար ստանդարտ անգլերեն տվյալների համակարգի կառուցվածքային գործընթացը, այսինքն' ֆեյվերը, և բարելավում ենք այն ցածր ռեսուրսների լեզուների դեպքում: Specifically, claims are extracted from sentences that are carefully selected to be more informative.  Տվյալների համակարգը կազմում է գրեթե 23K ձեռքով գրված հայտարարություններ: Over 65% of the claims in ParsFEVER are many-hop (require evidence from multiple sources), making the dataset a challenging benchmark (only 13% of the claims in FEVER are many-hop).  Նույնպես, չնայած ավելի փոքր ուսուցման համակարգի ունեցածին (Մոտ մեկ իննգերորդը Fever-ին), մի օրինակ, որն ուսուցվում է ՓարսՖԵՎերում, հասնում է նմանատիպ հետագա արտադրողությունների, որոնք ցույց են տալիս տվյալների համակարգի որ Մենք հրապարակում ենք տվյալների համակարգը և annoտացիայի ուղղությունները https://github.com/Zarharan/ParsFEVER.", 'az': "Avtomatik fakt əlaqəsi və təsdiqləmə tekniklərinin təhsil və değerlənməsi düşük ressurs dillərinə faydalanmayan böyük məlumatları lazımdır. Bu kağıt ParsFEVER'i göstərir: ilk halda faydalanır Farsi verilən qutusu faktiski çıxarma və təsdiqləmə üçün. Biz bu i şin standart İngilis veri qutusunun inşaat prosedüsini, həmçinin FEVER və düşük ressurs dillərinin məsəlinə düzəltdik. Əsas olaraq, məlumatlar daha informatif olmaq üçün tərzdə seçilmiş cümlələrdən çıxarılır. Verilər qurğuları əlində 23 K ilə məlumatlandır. ParsFEVER'deki iddiaların 65%-dən artıq çox-hop (çoxlu kaynaqlardan dəlillər lazımdır), verilən qutusu çətin bir benchmark etdi (FEVER'deki iddiaların yalnız 13%-i çox-hop edir). Daha az təhsil qurulmasına rağmen, ParsFEVER'də təhsil edilən modeli, verilən quruluğun keyfiyyətini göstərir. Biz verilən qurğuları və məlumatların doğru yollarını https://github.com/Zarharan/ParsFEVER.", 'ca': "La formació i l'evaluació de tècniques automàtiques d'extracció i verificació de fets requereixen grans quantitats de dades anotates que potser no estarien disponibles per llengües de baix recursos. Aquest paper presenta ParsFEVER: el primer conjunt de dades Farsi disponible per a l'extracció i la verificació de fets. Adopem el procediment de construcció del conjunt de dades estandards anglès per a la tasca, és a dir, FEVER, i ho millorem en el cas de llengües amb baix recursos. Concretament, les reclamacions s'extraeixen de frases que es seleccionen cuidadosament per ser més informatives. El conjunt de dades té pràcticament 23K afirmacions anotats manualment. Més del 65% de les reclamacions de ParsFEVER són molts hops (necessiten evidències de múltiples fonts), fent que el conjunt de dades sigui un punt de referència desafiant (només el 13% de les reclamacions de FEVER són molts hops). També, malgrat tenir un conjunt d'entrenaments més petit (aproximadament una novena d'aquest a Febre), un model entrenat en ParsFEVER aconsegueix un rendiment similar a avall, indicant la qualitat del conjunt de dades. Vam publicar el conjunt de dades i les directrices d'anotació a https://github.com/Zarharan/ParsFEVER.", 'cs': 'Školení a vyhodnocování technik automatické extrakce a ověřování faktů vyžaduje velké množství anotovaných dat, které nemusí být k dispozici pro jazyky s nízkými zdroji. Tento článek představuje ParsFEVER: první veřejně dostupný farštinský datový soubor pro extrakci a ověřování faktů. Pro daný úkol přijímáme postup konstrukce standardního anglického datového souboru FEVER a zlepšujeme jej pro případ jazyků s nízkými zdroji. Konkrétně, tvrzení jsou extrahovány z vět, které jsou pečlivě vybrány tak, aby byly informativnější. Datová sada obsahuje téměř 23K ručně anotované deklarace. Více než 65% tvrzení v ParsFEVER jsou mnoho-hop (vyžadují důkazy z více zdrojů), což činí datovou sadu náročným měřítkem (pouze 13% tvrzení v FEVERu jsou mnoho-hop). Navíc i přes menší tréninkovou sadu (asi devětinu toho, co je v Feveru), model trénovaný na ParsFEVER dosahuje podobného následného výkonu, což ukazuje kvalitu datové sady. Datovou sadu a pokyny k anotaci uvolníme na adrese: https://github.com/Zarharan/ParsFEVER.', 'bn': 'স্বয়ংক্রিয় বাস্তবতা বের করা এবং পরিচালনা করার প্রযুক্তির প্রশিক্ষণ ও মূল্যায়ন করার প্রয়োজনীয় বিশাল পরিমাণ তথ্য যা কম-সম্পদ ভাষার জন্ এই পত্রিকা প্যার্সফেভের উপস্থাপন করেছে: প্রথম প্রকাশিত ফার্সি ডাটাসেট বাস্তবতা বের করে নেওয়া এবং পরীক্ষা কর আমরা কাজের জন্য স্ট্যান্ডার্ড ইংরেজি ডাটাসেটের নির্মাণ প্রক্রিয়া নির্মাণ করি, যেমন FEVER এবং কম সম্পদ ভাষার ক্ষেত্রে এটি উন্নত করি। বিশেষ করে দাবি করা হয়েছে যে বাক্য থেকে সাবধানে আরো তথ্য হিসেবে নির্বাচিত হয়েছে। ডাটাসেট প্রায় ২৩ হাজার হাতে বিরক্তিকর দাবিগুলোর মধ্যে রয়েছে। প্যার্সফেভারের ৬৫ শতাংশের দাবিগুলোর মধ্যে অনেক বেশি (বেশ কিছু সূত্র থেকে প্রমাণ প্রয়োজন), তথ্যটি একটি চ্যালেঞ্জ বেনম্যার্ক বানানো হয় (ফেভের দা এছাড়াও একটা ছোট প্রশিক্ষণের সেট থাকা সত্ত্বেও (ফেভারে প্রায় ১৯ টায়) একটি মডেল প্রশিক্ষণ প্রদান করা হয়েছে প্যার্সএফেভেরের একটি মডেল প্রশিক্ষণ আমরা ডাটাসেট এবং বিজ্ঞাপনের নির্দেশাবলী মুক্তি দেই https://github.com/Zarharan/ParsFEVER.', 'fi': 'Automaattisten tietojen keruu- ja todentamistekniikoiden koulutus ja arviointi edellyttävät suuria määriä merkintöjä sisältäviä tietoja, joita ei välttämättä ole saatavilla vähävaraisille kielille. Tässä artikkelissa esitellään ParsFEVER: ensimmäinen julkisesti saatavilla oleva farsi-aineisto faktojen poimimiseen ja todentamiseen. Toteutamme tehtävään englanninkielisen standardiaineiston eli FEVERin rakentamismenettelyn ja parannamme sitä vähäresurssisten kielten tapauksessa. Erityisesti väitteet otetaan lauseista, jotka valitaan huolellisesti informatiivisiksi. Aineisto sisältää lähes 23 000 manuaalisesti merkittyä väitettä. Yli 65% ParsFEVERin väitteistä on monihyppyjä (vaatii näyttöä useista lähteistä), mikä tekee aineistosta haastavan vertailuarvon (vain 13% FEVERin väitteistä on monihyppyjä). Vaikka ParsFEVER-ohjelmalla koulutettu malli on pienempi (noin yhdeksännes Feverin koulutusryhmästä), se saavuttaa samanlaisen jatkotason suorituskyvyn, mikä osoittaa aineiston laadun. Julkaisemme aineiston ja huomautusohjeet osoitteessa https://github.com/Zarharan/ParsFEVER.', 'et': 'Faktide automaatse väljavõtmise ja kontrollimise meetodite koolitamine ja hindamine nõuab suurt hulka märgitud andmeid, mis ei pruugi vähese ressursiga keelte puhul kättesaadavad olla. Käesolevas töös esitletakse ParsFEVER: esimene avalikult kättesaadav Farsi andmekogum faktide väljavõtmiseks ja kontrollimiseks. Võtame ülesande jaoks kasutusele inglise standardse andmekogumi ehk FEVER konstrueerimisprotseduuri ja parandame seda vähese ressursiga keelte puhul. Eelkõige võetakse väited lausetest, mis on hoolikalt valitud informatiivsemaks. Andmekogum koosneb ligi 23K käsitsi märgitud väidetest. Enam kui 65% ParsFEVERi väidetest on palju-hop (nõuab tõendeid mitmest allikast), muutes andmekogumi keeruliseks võrdlusaluseks (vaid 13% FEVERi väidetest on palju-hop). Vaatamata väiksemale koolituskomplektile (umbes üheksanda sellest, kui see on Feveri puhul), saavutab ParsFEVER-il koolitatud mudel sarnase järgmise etapi tulemuslikkuse, mis näitab andmekogumi kvaliteeti. Avaldame andmekogumi ja kommenteerimisjuhised aadressil https://github.com/Zarharan/ParsFEVER.', 'bs': 'Vježba i procjena tehnika automatske izvlačenja činjenica i provjere zahtijeva velike količine annotiranih podataka koje možda nisu dostupne za jezike niskih resursa. Ovaj papir predstavlja ParsFEVER: prvi javno dostupni komplet podataka Farsi za izvlačenje i verificiju. Usvojimo građevinski postupak standardne engleske dataset za zadatak, tj. FEVER, i poboljšamo ga za slučaj jezika niskih resursa. Posebno, tvrdnja su izvučena iz rečenica koje su pažljivo odabrane da budu informativnije. Podaci sadrže gotovo 23K manualno annotirane tvrdnje. Preko 65% tvrdnji u ParsFEVERu su mnogi-hopovi (zahtijevaju dokaze iz višestrukih izvora), čineći kompletu podataka izazovnom kritiku (samo 13% tvrdnji u FEVER su mnogi-hopovi). Također, uprkos manjim treningama (oko devetog od toga u groznici), model obučen na ParsFEVER postiže sličan niz stručnjak, ukazujući na kvalitetu kompleta podataka. Puštamo podatke i uputstva za annotaciju https://github.com/Zarharan/ParsFEVER.', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness Perintah sing nambah, ParasBEVer: nggo sabên populasno bukên, dataset Awak dhéwé nggunaké perusahaan nggawe dataset inggiles kanggo nggawe kesempatan, t.i.DEBER, lan nggawe mbukaké nggawe barang kelas depasar-depasar. Laptop" and "Desktop dataset dumateng section Nejer, mengko nganggep sistem menyang paling-toleransa (gambar tanggal 1/9 sekang dolanan ing Fev), model sing ditambah nêmêr, padsBEVer iso diandelak sistem sing gawe beh dadi, mengko kedhah nesaturan dataset kuwi. Tulung https://github.com/Zarharan/ParsFEVER.', 'ha': "Ana ƙidãya da evaluation ga masu fitarwa da masu tabbatarwa na farat ɗaya, yana ƙayyade yawan data mai girma da za'a iya iya amfani da wa lugha-nau'in-resource. Wannan takardar da ke gauraya ParsFEWR: na farkon da ba'a iya samar da shirin Farsi ba dõmin fitarwa da gaskiyar. Mu zãɓi tsarin da aka daidaita maɓallin Ingiriya na daidaita zuwa aikin, misali FEWR, kuma Mu gyãra shi dõmin masu sakan lugha masu ƙaranci. Aka ƙayyade, za'a fizge zaɓallin su daga sonar waɗanda aka zãɓe su taƙaitãwa dõmin a zama masu tsari. Suna haɗi da shi nesti 23,000 na ƙididdige daidaita da hannayen da aka nuna. Over 65% of the claims in ParsFEVER are many-hop (require evidence from multiple sources), making the dataset a challenging benchmark (only 13% of the claims in FEVER are many-hop).  Da haka, kuma, ingawa ya sami ƙarami da tsarin aiki (taki guda na guda na Fever), wani motel wanda aka yi wa shirin ParsFEWR yana sãmu mai kama da danni na ƙarami, yana nũna sifar da tsarin da aka tsare shi. Munã sakar da shirin ayuka da https://github.com/Zarharan/ParsFEVER.", 'sk': 'Usposabljanje in ocenjevanje tehnik samodejnega pridobivanja in preverjanja dejstev zahteva velike količine podatkov z oznakami, ki morda niso na voljo za jezike z nizkimi viri. Ta prispevek predstavlja ParsFEVER: prvi javno dostopen nabor podatkov Farsi za pridobivanje in preverjanje dejstev. Za nalogo sprejmemo postopek gradnje standardnega angleškega nabora podatkov, tj. FEVER, in ga izboljšamo za primer jezikov z nizkimi viri. Natančneje, trditve so izvlečene iz stavkov, ki so skrbno izbrani, da so bolj informativni. Zbirka podatkov obsega skoraj 23K ročno navedenih trditev. Več kot 65% trditev v ParsFEVER je mnogo-hop (zahtevajo dokaze iz več virov), zaradi česar je nabor podatkov zahtevno merilo (le 13% trditev v FEVER je mnogo-hop). Poleg tega ima model, usposobljen za ParsFEVER, kljub manjšemu naboru usposabljanja (približno devetini od nabora treningov pri vročini), podobno uspešnost, kar kaže na kakovost nabora podatkov. Podatkovni nabor in smernice za opombe objavljamo na spletni strani https://github.com/Zarharan/ParsFEVER.', 'bo': 'Training and evaluation of automatic fact extraction and verification techniques require large amounts of annotated data which may not be available for low-resource languages. ཤོག་བྱང་འདིས་ParsFEVER སྟོན་པ། མི་མང་ཆོས་སྤྱིར་བཏང་བའི་Farsi་ཡིག་ཆ་སྒྲིག་ཆ ང་ཚོས་དབྱིན་ཡིག་གི་ཆ་འཕྲིན་གྱི་ལས་འགན་ལ་ལས་སྒྲིག ཁྱད་དོན་དག་གིས་གསལ་བཤད་པ་དེ་ཚོར་བརྟན་པར་བདམས་ཟིན་པའི་ཚིག་རྟགས་སྣང་བྱེད་ཐུབ་པ སྒྲིག་ཡིག་ཆ་སྒྲིག་ནང་དུ་ལག་བཟོས་ཟིན་པའི་གསལ་བཤད་ཀྱི་ཉེན་ཁ་ཡོད། Over 65% of the claims in ParsFEVER are many-hop (require evidence from multiple sources), making the dataset a challenging benchmark (only 13% of the claims in FEVER are many-hop). Also, having a smaller training set (around one-ninth of that in Fever), a model trained on ParsFEVER attains similar downstream performance, indicating the quality of the data set. ང་ཚོས་གནས་ཚུལ་སྒྲིག་ཆ་འཕྲིན་དང་སྒྲུབ་གཏོང་གི་གྲངས་སྒྲིག་ཕྲེང་མཐུད་དང་ https://github.com/Zarharan/ParsFEVER.', 'he': 'האימונים והעריכה של טכניקות חיפוש ועובדות אוטומטיות דורשות כמויות גדולות של נתונים מצוינים שאולי לא יהיו זמינות לשפות משאבים נמוכות. This paper presents ParsFEVER: the first publicly available Farsi dataset for fact extraction and verification.  אנו מאמצים את הליך הבנייה של קבוצת הנתונים האנגלית הסטנדרטית למשימה, כלומר, FEVER, ושיפרים אותה במקרה של שפות משאבים נמוכות. Specifically, claims are extracted from sentences that are carefully selected to be more informative.  The dataset comprises nearly 23K manually-annotated claims.  Over 65% of the claims in ParsFEVER are many-hop (require evidence from multiple sources), making the dataset a challenging benchmark (only 13% of the claims in FEVER are many-hop).  Also, despite having a smaller training set (around one-ninth of that in Fever), a model trained on ParsFEVER attains similar downstream performance, indicating the quality of the dataset.  אנחנו משחררים את קבוצת המידע והציונים https://github.com/Zarharan/ParsFEVER.'}
{'en': 'BiQuAD : Towards QA based on deeper text understanding', 'fr': 'BiQuad\xa0: Vers une assurance qualité basée sur une meilleure compréhension du texte', 'ar': 'BiQuAD: نحو ضمان الجودة على أساس فهم أعمق للنص', 'es': 'BiQuad: Hacia un control de calidad basado en una comprensión más profunda', 'pt': 'BiQuaAD: Rumo ao controle de qualidade baseado em uma compreensão de texto mais profunda', 'zh': 'BiQuAD曰:基于深迈向 QA', 'ja': 'BiQuAD ：より深いテキスト理解に基づくQAに向けて', 'hi': 'BiQuAD: गहरी पाठ समझ के आधार पर QA की ओर', 'ru': 'BiQuAD: К QA основано на более глубоком понимании текста', 'ga': 'BiQuAD: I dTreo QA bunaithe ar thuiscint níos doimhne ar an téacs', 'el': 'BiQuAD: Προς την QA βασισμένη σε βαθύτερη κατανόηση κειμένου', 'ka': 'BiQuAD: QA-ის გარეშე ტექსტის გარეშე', 'kk': 'BiQuAD: QA жағына түсінуге негізделген', 'it': 'BiQuAD: Verso un QA basato su una comprensione più profonda del testo', 'mk': 'BiQuAD: Надвор кон QA врз основа на подлабоко разбирање на текстот', 'lt': 'BiQuAD: Towards QA based on deeper text understanding', 'hu': 'BiQuAD: A mélyebb szövegmegértésen alapuló minőségbiztosítás felé', 'ms': 'BiQuAD: Ke arah QA berdasarkan pemahaman teks yang lebih dalam', 'mt': 'BiQuAD: Lejn QA bbażat fuq fehim aktar profond tat-test', 'mn': 'BiQuAD: QA руу илүү гүн гүнзгий текст ойлголтын тулд', 'ro': 'BiQuAD: Către QA bazată pe înțelegerea mai profundă a textului', 'pl': 'BiQuAD: W kierunku jakości opartej na głębszym zrozumieniu tekstu', 'sr': 'BiQuAD: prema QA baziranom na dubljem razumijevanju teksta', 'si': 'BiQAD: QA වලට ගොඩක් ලිපින් තේරුම් අධාරණය කරන්න', 'so': 'BiQuAD: Towards QA based on a deeper text understanding', 'ml': 'ബിക്വാഡ്: ആഴത്തെ ടെക്സ്റ്റ് ബുദ്ധിമുട്ട് അടിസ്ഥാനമായി ക്യൂഎ മുകളിലേക്കു്', 'ta': 'பிக்வாட்: ஆழமான உரை புரியும் அடிப்படையில் மேலே QA', 'no': 'BiQuAD: Gå til QA basert på dypere tekstforståelse', 'sv': 'BiQuAD: Mot QA baserat på djupare textförståelse', 'ur': 'BiQuAD: QA کی طرف جو عمیق متن سمجھنے پر بنیاد ہے', 'uz': 'BiQuAD: Juda yuqori matn tushunishga asosida', 'vi': 'BiCOAD: Hướng tới QA dựa trên sự hiểu biết sâu hơn về văn bản', 'bg': 'БиКуАД: Към постигане на качество въз основа на по-задълбочено разбиране на текста', 'nl': 'BiQuAD: Naar QA gebaseerd op dieper begrip van tekst', 'da': 'BiQuAD: Mod QA baseret på dybere tekstforståelse', 'hr': 'BiQuAD: prema QA na temelju dubljeg razumijevanja teksta', 'ko': 'BiQuaD: 더 깊은 텍스트 이해를 바탕으로 하는 QA', 'fa': 'BiQuAD: به سمت QA based on deeper text understanding', 'de': 'BiQuAD: Auf dem Weg zur Qualitätssicherung basierend auf tieferem Textverständnis', 'sw': 'BiQuAD: Toka QA kwa msingi wa ufahamu wa kina wa maandishi', 'id': 'BiQuAD: Menuju QA berdasarkan pemahaman teks yang lebih dalam', 'tr': 'BiQuAD:', 'am': 'BiQuAD: የጥልቅ ጽሑፍ ማስተዋል ላይ ወደ QA', 'hy': 'ԲիՔԱԴ. Հաջորդ տեքստի հասկանալու հիմնված QA-ի ուղղությամբ', 'az': 'BiQuAD: QA t톛r톛find톛 daha derin m톛tn anlamas캼na dayanan', 'bn': 'বিকুয়াড: গভীর লেখা বুঝতে ভিত্তিক কিয়ার উপরে', 'af': 'BiQuAD: Na QA gebaseer op dieper teks verstanding', 'sq': 'BiQuAD: drejt QA bazuar në kuptimin më të thellë të tekstit', 'bs': 'BiQuAD: prema QA baziranom na dubljem razumijevanju teksta', 'cs': 'BiQuAD: Směrem k QA založenému na hlubším porozumění textu', 'fi': 'BiQuAD: Kohti laadunvarmistusta, joka perustuu syvempään tekstin ymmärtämiseen', 'et': 'BiQuAD: sügavamal tekstimõistmisel põhineva kvaliteedi tagamise suunas', 'ca': 'BiQuAD: Al QA basat en una comprensió més profunda del text', 'jv': 'BiCED: Tambanjur kang KA basa nang langgambar teks seneng luwih', 'ha': 'QA', 'sk': 'BiQuAD: K zagotavljanju kakovosti na podlagi poglobljenega razumevanja besedila', 'he': 'BiQuAD: לכיוון QA מבוסס על הבנה טקסטית עמוקה יותר', 'bo': 'BiQuAD:གྲོང་གཏོང་གི་ཡིག་གེ་ལ་གཞི་རྟེན་ནས་'}
{'en': 'Recent question answering and machine reading benchmarks frequently reduce the task to one of pinpointing spans within a certain text passage that answers the given question. Typically, these systems are not required to actually understand the text on a deeper level that allows for more complex reasoning on the information contained. We introduce a new dataset called BiQuAD that requires deeper comprehension in order to answer questions in both extractive and deductive fashion. The dataset consist of 4,190 closed-domain texts and a total of 99,149 question-answer pairs. The texts are synthetically generated soccer match reports that verbalize the main events of each match. All texts are accompanied by a structured Datalog program that represents a (logical) model of its information. We show that state-of-the-art QA models do not perform well on the challenging long form contexts and reasoning requirements posed by the dataset. In particular, transformer based state-of-the-art models achieve F1-scores of only 39.0. We demonstrate how these synthetic datasets align structured knowledge with natural text and aid model introspection when approaching complex text understanding.', 'pt': 'Referências recentes de resposta a perguntas e leitura de máquina freqüentemente reduzem a tarefa a uma tarefa de identificar intervalos dentro de uma determinada passagem de texto que responde a determinada pergunta. Normalmente, esses sistemas não são obrigados a realmente entender o texto em um nível mais profundo que permite um raciocínio mais complexo sobre as informações contidas. Apresentamos um novo conjunto de dados chamado BiQuAD que requer uma compreensão mais profunda para responder perguntas de forma extrativa e dedutiva. O conjunto de dados consiste em 4.190 textos de domínio fechado e um total de 99.149 pares de perguntas e respostas. Os textos são relatórios de partidas de futebol gerados sinteticamente que verbalizam os principais acontecimentos de cada partida. Todos os textos são acompanhados por um programa Datalog estruturado que representa um modelo (lógico) de suas informações. Mostramos que os modelos de QA de última geração não funcionam bem nos desafiadores contextos de formato longo e nos requisitos de raciocínio impostos pelo conjunto de dados. Em particular, os modelos de última geração baseados em transformadores atingem pontuações F1 de apenas 39,0. Demonstramos como esses conjuntos de dados sintéticos alinham o conhecimento estruturado com o texto natural e auxiliam a introspecção do modelo ao abordar a compreensão de texto complexo.', 'ar': 'كثيرًا ما تؤدي الإجابة عن الأسئلة الحديثة ومعايير قراءة الآلة إلى تقليل المهمة إلى واحدة تتمثل في تحديد الامتدادات داخل فقرة نصية معينة تجيب على السؤال المحدد. عادةً ، لا تكون هذه الأنظمة مطلوبة لفهم النص فعليًا على مستوى أعمق يسمح بتفكير أكثر تعقيدًا بشأن المعلومات الواردة. نقدم مجموعة بيانات جديدة تسمى BiQuAD تتطلب فهماً أعمق للإجابة على الأسئلة بطريقة استخلاصية واستنتاجية. تتكون مجموعة البيانات من 4190 نصًا ذات مجال مغلق وما مجموعه 99149 زوجًا من الأسئلة والأجوبة. النصوص عبارة عن تقارير عن مباريات كرة القدم تم إنشاؤها بطريقة صناعية والتي تشرح الأحداث الرئيسية لكل مباراة. جميع النصوص مصحوبة ببرنامج Datalog منظم يمثل نموذجًا (منطقيًا) لمعلوماتها. نظهر أن أحدث نماذج ضمان الجودة لا تؤدي أداءً جيدًا في السياقات الطويلة الصعبة ومتطلبات التفكير التي تطرحها مجموعة البيانات. على وجه الخصوص ، تحقق الطرازات الحديثة القائمة على المحولات درجات F1 تبلغ 39.0 فقط. نوضح كيف تقوم مجموعات البيانات التركيبية هذه بمواءمة المعرفة المنظمة مع النص الطبيعي وتساعد على استبطان النموذج عند الاقتراب من فهم النص المعقد.', 'es': 'Las respuestas a preguntas recientes y los puntos de referencia de lectura automática con frecuencia reducen la tarea a una de señalar los intervalos dentro de un cierto pasaje de texto que responde a la pregunta dada. Por lo general, no se requiere que estos sistemas entiendan realmente el texto a un nivel más profundo que permita un razonamiento más complejo sobre la información contenida. Presentamos un nuevo conjunto de datos llamado BiQuad que requiere una comprensión más profunda para responder a las preguntas de manera extractiva y deductiva. El conjunto de datos consta de 4.190 textos de dominio cerrado y un total de 99.149 pares de preguntas y respuestas. Los textos son informes de partidos de fútbol generados sintéticamente que verbalizan los principales eventos de cada partido. Todos los textos van acompañados de un programa Datalog estructurado que representa un modelo (lógico) de su información. Demostramos que los modelos de control de calidad de última generación no funcionan bien en los desafiantes contextos de formato largo y los requisitos de razonamiento que plantea el conjunto de datos. En particular, los modelos de última generación basados en transformadores alcanzan puntuaciones F1 de solo 39,0. Demostramos cómo estos conjuntos de datos sintéticos alinean el conocimiento estructurado con el texto natural y ayudan a modelar la introspección al abordar la comprensión compleja del texto.', 'fr': "Les récents tests de réponse aux questions et de lecture automatique réduisent souvent la tâche à identifier les plages dans un certain passage de texte qui répond à la question donnée. Généralement, ces systèmes ne sont pas tenus de comprendre réellement le texte à un niveau plus approfondi qui permet un raisonnement plus complexe sur les informations contenues. Nous introduisons un nouvel ensemble de données appelé BiQuad qui nécessite une compréhension plus approfondie afin de répondre aux questions de manière extractive et déductive. L'ensemble de données comprend 4 190 textes en domaine fermé et un total de 99 149 paires question-réponse. Les textes sont des rapports de matchs de football générés synthétiquement qui verbalisent les principaux événements de chaque match. Tous les textes sont accompagnés d'un programme Datalog structuré qui représente un modèle (logique) de ses informations. Nous montrons que les modèles d'assurance qualité de pointe ne fonctionnent pas bien dans les contextes complexes de formulaires longs et les exigences de raisonnement posées par l'ensemble de données. En particulier, les modèles de pointe basés sur des transformateurs obtiennent des scores F1 de seulement 39,0. Nous montrons comment ces ensembles de données synthétiques alignent les connaissances structurées avec le texte naturel et facilitent l'introspection du modèle lors de l'approche de la compréhension de textes complexes.", 'hi': 'हाल के प्रश्न उत्तर और मशीन रीडिंग बेंचमार्क अक्सर दिए गए प्रश्न का उत्तर देने वाले एक निश्चित पाठ मार्ग के भीतर पिनपॉइंटिंग स्पैन में से एक के लिए कार्य को कम करते हैं। आमतौर पर, इन प्रणालियों को वास्तव में एक गहरे स्तर पर पाठ को समझने की आवश्यकता नहीं होती है जो निहित जानकारी पर अधिक जटिल तर्क की अनुमति देता है। हम BiQuAD नामक एक नया डेटासेट पेश करते हैं जिसे निष्कर्षण और निगमनात्मक फैशन दोनों में प्रश्नों का उत्तर देने के लिए गहरी समझ की आवश्यकता होती है। डेटासेट में 4,190 क्लोज्ड-डोमेन टेक्स्ट और कुल 99,149 प्रश्न-उत्तर जोड़े शामिल हैं। ग्रंथों सिंथेटिक रूप से उत्पन्न फुटबॉल मैच रिपोर्ट है कि प्रत्येक मैच की मुख्य घटनाओं verbalize रहे हैं. सभी ग्रंथों के साथ एक संरचित डेटालॉग प्रोग्राम होता है जो इसकी जानकारी के एक (तार्किक) मॉडल का प्रतिनिधित्व करता है। हम दिखाते हैं कि अत्याधुनिक क्यूए मॉडल डेटासेट द्वारा प्रस्तुत चुनौतीपूर्ण लंबे रूप संदर्भों और तर्क आवश्यकताओं पर अच्छा प्रदर्शन नहीं करते हैं। विशेष रूप से, ट्रांसफॉर्मर आधारित अत्याधुनिक मॉडल केवल 39.0 के F1-स्कोर प्राप्त करते हैं। हम प्रदर्शित करते हैं कि ये सिंथेटिक डेटासेट प्राकृतिक पाठ के साथ संरचित ज्ञान को कैसे संरेखित करते हैं और जटिल पाठ समझ के करीब आने पर मॉडल आत्मनिरीक्षण की सहायता करते हैं।', 'ja': '最近の質問への回答と機械読み取りベンチマークは、与えられた質問に回答する特定のテキストパス内のスパンを特定するタスクを頻繁に1つに減らします。 通常、これらのシステムは、含まれる情報についてより複雑な推論を可能にするより深いレベルでテキストを実際に理解する必要はありません。 BiQuADと呼ばれる新しいデータセットを導入しました。これは、抽出と推論の両方で質問に答えるために、より深い理解を必要とします。 データセットは、4,190のクローズドドメインテキストと合計99,149の質問回答ペアで構成されています。 テキストは、各試合のメインイベントを言語化したサッカーの試合レポートを合成したものです。 すべてのテキストには、その情報の（論理的な）モデルを表す構造化されたデータログプログラムが付属しています。 最先端のQAモデルは、データセットがもたらす厳しい長いフォームコンテキストと推論要件ではうまく機能しないことを示しています。 特に、変圧器ベースの最先端モデルは、わずか39.0のF 1スコアを達成します。 これらの合成データセットは、複雑なテキスト理解にアプローチする際に、構造化された知識を自然なテキストと整合させ、モデル内観を支援する方法を実演します。', 'zh': '近问答机器读准试常简对给定某文本段落精确定位跨度之一。 凡此等统,不须更深层次实解文本,而许于所含信息更杂推理。 引入一BiQuAD新数集,当更深解,以取演绎答之。 据集由4,190闭域文本与凡99,149问对成。 此合成生成之足球比赛告,语言每场大要也。 凡文本皆附一结构化数日志,以示信息(逻辑)模形。 臣等明最先进之QA,于数集挑战性长格上下文推理不佳。 盖变压器之先进型号者F1得分为39.0。 展此合成数据集结构化与自然文本相合,并于近杂文本解时助模内省。', 'ru': 'Недавние контрольные показатели ответов на вопросы и машинного чтения часто сводят задачу к точному определению диапазона в определенном текстовом отрывке, который отвечает на данный вопрос. Как правило, эти системы не обязаны фактически понимать текст на более глубоком уровне, что позволяет более сложно рассуждать о содержащейся в нем информации. Мы вводим новый набор данных под названием BiQuAD, который требует более глубокого понимания, чтобы отвечать на вопросы как в экстрактивной, так и в дедуктивной манере. Набор данных состоит из 4190 текстов закрытого домена и в общей сложности 99 149 пар вопросов-ответов. Тексты синтетически сгенерированы отчеты футбольных матчей, которые вербализируют основные события каждого матча. Все тексты сопровождаются структурированной программой Datalog, которая представляет собой (логическую) модель ее информации. Мы показываем, что современные модели обеспечения качества неэффективны в сложных контекстах длинной формы и требованиях к рассуждениям, предъявляемых набором данных. В частности, самые современные модели на основе трансформаторов достигают F1-оценок всего 39,0. Мы демонстрируем, как эти синтетические наборы данных согласуют структурированные знания с естественным текстом и самоанализом модели помощи при приближении к сложному пониманию текста.', 'ga': 'Is minic a laghdaíonn freagraí ceisteanna le déanaí agus tagarmharcanna léitheoireachta meaisín an tasc go ceann de réisí pinnte laistigh de sliocht téacs áirithe a fhreagraíonn an cheist a tugadh. Go hiondúil, ní cheanglaítear ar na córais seo an téacs a thuiscint i ndáiríre ar leibhéal níos doimhne a cheadaíonn réasúnú níos casta ar an bhfaisnéis atá ann. Tugaimid isteach tacar sonraí nua dar teideal BiQuAD a éilíonn tuiscint níos doimhne chun ceisteanna a fhreagairt ar bhealach eastóscach agus asbhainteach araon. Is éard atá sa tacar sonraí ná 4,190 téacs fearainn dúnta agus 99,149 péirí ceisteanna-freagra. Is tuairiscí ar chluichí sacair iad na téacsanna a ghintear go sintéiseach a chuireann príomhimeachtaí gach cluiche i bhfocail. Tá clár struchtúrtha Datalog ag gabháil le gach téacs a léiríonn samhail (loighciúil) dá chuid faisnéise. Léirímid nach n-éiríonn go maith leis na samhlacha QA úrscothacha ar na comhthéacsanna fada dúshlánacha agus na riachtanais réasúnaíochta a chuireann an tacar sonraí i bhfeidhm. Go háirithe, ní ghnóthaíonn samhlacha nua-aimseartha atá bunaithe ar chlaochladán scóir F1 ach 39.0. Léirímid conas a ailíníonn na tacair sonraí sintéiseacha seo eolas struchtúrtha le téacs nádúrtha agus le hinfheasacht samhail cabhrach agus muid ag druidim le tuiscint chasta téacs.', 'el': 'Πρόσφατα κριτήρια αναφοράς απάντησης και ανάγνωσης μηχανών συχνά μειώνουν το καθήκον του εντοπισμού περιόδων μέσα σε ένα συγκεκριμένο κείμενο που απαντά στη δεδομένη ερώτηση. Συνήθως, αυτά τα συστήματα δεν απαιτούνται για να κατανοήσουν πραγματικά το κείμενο σε ένα βαθύτερο επίπεδο που επιτρέπει πιο περίπλοκη συλλογιστική σχετικά με τις πληροφορίες που περιέχονται. Εισάγουμε ένα νέο σύνολο δεδομένων που ονομάζεται BiQuAD που απαιτεί βαθύτερη κατανόηση προκειμένου να απαντηθούν ερωτήσεις τόσο με αποσπαστικό όσο και με συμπεραστικό τρόπο. Το σύνολο δεδομένων αποτελείται από 4,190 κείμενα κλειστού τομέα και συνολικά ζεύγη ερωτήματος-απάντησης 99,149. Τα κείμενα είναι συνθετικές αναφορές ποδοσφαιρικών αγώνων που εκφράζουν προφορικά τα κύρια γεγονότα του κάθε αγώνα. Όλα τα κείμενα συνοδεύονται από ένα δομημένο πρόγραμμα που αντιπροσωπεύει ένα (λογικό) μοντέλο των πληροφοριών του. Δείχνουμε ότι τα σύγχρονα μοντέλα QA δεν αποδίδουν καλά στα δύσκολα πλαίσια μακράς μορφής και τις απαιτήσεις συλλογισμού που θέτει το σύνολο δεδομένων. Ειδικότερα, τα μοντέλα τελευταίας τεχνολογίας που βασίζονται σε μετασχηματιστές επιτυγχάνουν βαθμολογίες F1 μόνο 39.0. Επιδεικνύουμε πώς αυτά τα συνθετικά σύνολα δεδομένων ευθυγραμμίζουν τη δομημένη γνώση με το φυσικό κείμενο και βοηθούν την ενδοσκόπηση του μοντέλου κατά την προσέγγιση της κατανόησης σύνθετων κειμένων.', 'ka': 'შემდეგ კითხვების პასუხი და მაქსინური კითხვის ბენქმარი ზოგიერთად დაახლოების ერთი ტექსტის პროგორეში, რომელიც მიუთითებული კითხვების პასუხი. ეს სისტემები უფრო დიდი დონეზე, რომელიც უფრო კომპლექსი პარამენტის შესაძლებელია ინფორმაციის შესახებ. ჩვენ ჩვენ ახალი მონაცემების სახელი BiQuAD, რომელიც უნდა უფრო დიდი გაგრძნობა, რომ კითხვების შესახებ ექსტრაქტური და განსხვავებული ფორმაში. მონაცემების კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კონფიგურაციის კო ტექსტი სინტეტიკურად შექმნილი ტუბოლის თანამდვილეების შეტყობინებები, რომლებიც ყოველ თანამდვილეების მნიშვნელოვანი მოვლენების ვერბა ყველა ტექსტი იქნება სტრუქტურაციული მონაცემების პროგრამით, რომელიც იგის ინფორმაციის (ლოგიკური) მოდელის გამოყენება. ჩვენ ჩვენ გამოჩვენებთ, რომ QA მოდელების მდგომარეობა არ მუშაობს საშუალებელი ფორმის კონტექსტში და რედაქტორის მოსახულებების შესახებ. განსაკუთრებულია, ტრანფორმეტრისტური განსაკუთრებული სურათის მოდელები F1-სურათების მხოლოდ 39.0. ჩვენ გამოჩვენებთ, როგორ ეს სინტეტიკური მონაცემები სტრუქტურული ცნობილებების შესაბამისი ტექსტით და მოდის მოდელს ინტეროსპექციის შესაბამისი შესაბამისი ტექს', 'hu': 'A legutóbbi kérdésválaszolási és gépi olvasási referenciaértékek gyakran csökkentik a feladatot egy adott kérdésre adott szövegrészen belüli meghatározási tartományra. Általában ezeknek a rendszereknek nincs szükségük arra, hogy ténylegesen megértsék a szöveget olyan mélyebb szinten, amely lehetővé teszi a benne található információk összetettebb érvelését. Bemutatjuk a BiQuAD nevű új adatkészletet, amely mélyebb megértést igényel ahhoz, hogy mind extraktív, mind deduktív módon válaszolhassunk a kérdésekre. Az adatkészlet 4 190 zárt tartományú szövegből és összesen 99 149 kérdés-válasz párból áll. A szövegek szintetikusan generált focimeccsjelentések, amelyek szó szerint az egyes mérkőzések főbb eseményeit fogalmazzák meg. Minden szöveget egy strukturált Datalog program kísér, amely az információk (logikai) modelljét képviseli. Megmutatjuk, hogy a legkorszerűbb minősítési modellek nem teljesítenek jól az adatkészlet által támasztott kihívást jelentő hosszú formában és érvelési követelményekben. Különösen a transzformátorok alapú, korszerű modellek mindössze 39,0 F1 pontszámot érnek el. Bemutatjuk, hogy ezek a szintetikus adatkészletek hogyan igazítják össze a strukturált tudást a természetes szöveggel, és segítik a modell introspektícióját a komplex szövegmegértés megközelítésekor.', 'kk': 'Жуырдағы сұрақ жауап беру және машинаның оқу белгілері тапсырманы келтірілген сұраққа жауап беретін мәтін пассажасының біреуіне көбірек қысқарту керек. Әдетте, бұл жүйелердің мәтіні қалай мәліметтің артық деңгейінде түсінуге мүмкін емес. Біз BiQuAD деп аталатын жаңа деректер жиынын келтіреміз. Бұл түсініктерді түсініктіру үшін сұрақтардың жауап беру үшін дұрыс түсініктері керек. Деректер жиынында 4 190 жабылған домендің мәтіндері және 99 149 сұрақ жауап жиындары бар. Мәтіндер әрбір сәйкестіктің негізгі оқиғаларын вербализациялау үшін синтетикалық құрылған футболдың сәйкестігі туралы хабарламалары. Барлық мәтіндерді мәліметінің (логикалық) үлгісін көрсету үшін құрылған Деталог бағдарламасы қолданылады. Біз QA моделдерінің күй- жай моделдері деректер қорларының орналасатын ұзындық тәртіптерінде жұмыс істемейді. Әсіресе, түрлендіруші күй- жай моделдері тек 39, 0 деген F1- нәтижесін жеткізеді. Біз бұл синтетикалық деректер қорларының құрылған білімдерді табиғи мәтіннен және көмектесу үлгісінің интроспекциясына көмектесу үлгісін көрсетедік.', 'lt': 'Pastarojo meto klausimų atsakymo ir mašininio skaitymo kriterijai dažnai sumažina užduotį iki vieno iš tam tikro teksto dalių, į kurią atsakoma į pateiktą klausimą, nustatymo. Paprastai nereikalaujama, kad šios sistemos iš tikrųjų suprastų tekstą gilesniu lygiu, kuris leistų sudėtingiau pagrįsti turimą informaciją. Įvedame naują duomenų rinkinį, vadinamą BiQuAD, kuriam reikia išsamesnio supratimo, kad būtų galima atsakyti į klausimus tiek gavybos, tiek atskaitomybės būdu. Duomenų rinkinį sudaro 4 190 uždarojo domeno tekstai ir iš viso 99 149 atsakymų į klausimus poros. Tekstai yra sintetiškai sukurti futbolo žaidimų pranešimai, kuriuose žodžiu rašomi pagrindiniai kiekvieno žaidimo įvykiai. Prie visų tekstų pridedama struktūrizuota Datalog program a, kuri atitinka (logišką) jos informacijos model į. Mes rodome, kad naujausi kokybės vertinimo modeliai nepakankamai veiksmingi atsižvelgiant į sunkias ilgalaikes aplinkybes ir duomenų rinkinio pagrįstus reikalavimus. Visų pirma, transformatoriumi pagrįsti moderniausi modeliai pasiekia tik 39,0 F1 balai. Mes parodome, kaip šie sintetiniai duomenų rinkiniai suderina struktūrizuotas žinias su natūraliu teksto ir pagalbos modelio įvaizdžiu artėjant prie sudėtingo teksto supratimo.', 'mk': 'Неодамнешните резултати за одговори на прашања и читање на машина често ја намалуваат задачата на една од одредените граници во одреден текст пауз кој одговара на даденото прашање. Обично, овие системи не се бараат да го разберат текстот на подлабоко ниво што овозможува покомплексно размислување за содржаните информации. Ние воведуваме нови податоци наречени БиКВАД кои бараат подлабоко разбирање со цел да одговориме на прашањата на екстрактивен и дедуктивен начин. Податоците се состојат од 4.190 тексти со затворен домен и вкупно 99.149 парови со одговор на прашања. Текстите се синтетички генерирани извештаи за фудбалски натпревари кои ги вербализираат главните настани на секој натпревар. Сите тексти се придружени од структурирана програма Даталог која претставува (логичен) модел на нејзините информации. Покажуваме дека најсовремените модели на QA не успеваат добро во предизвикувачките долги форма контексти и размислувачките барања поставени од податоците. Особено, најновите модели базирани на трансформаторите постигнуваат оценки F1 од само 39,0. Демонстрираме како овие синтетички податоци го прилагодуваат структурираното знаење со природното текст и помошниот модел на интроспекција кога се приближува до комплексното разбирање на текстот.', 'mt': 'Punti ta’ riferiment riċenti għat-tweġibiet għall-mistoqsijiet u l-qari bil-magna ta’ spiss inaqqsu l-kompitu għal wieħed mill-firxiet li jindikaw f’ċertu passaġġ tat-test li jwieġeb għall-mistoqsija mogħtija. Tipikament, dawn is-sistemi mhumiex meħtieġa li fil-fatt jifhmu t-test fuq livell aktar profond li jippermetti raġunament aktar kumpless dwar l-informazzjoni li tinsab. Aħna nintroduċu sett ġdid ta’ dejta msejjaħ BiQuAD li jeħtieġ fehim aktar profond sabiex iwieġbu mistoqsijiet kemm b’mod estrattiv kif ukoll b’mod deduttiv. Is-sett tad-dejta jikkonsisti f’4,190 test b’dominju magħluq u total ta’ 99,149 par ta’ mistoqsijiet u tweġibiet. The texts are synthetically generated soccer match reports that verbalize the main events of each match.  It-testi kollha huma akkumpanjati minn programm strutturat ta’ Datalog li jirrappreżenta mudell (loġiku) tal-informazzjoni tiegħu. Aħna nuru li l-mudelli tal-QA l-aktar avvanzati ma jwettqux tajjeb fuq il-kuntesti ta’ forma twila ta’ sfida u r-rekwiżiti ta’ raġunament ippreżentati mis-sett tad-dejta. B’mod partikolari, mudelli l-aktar avvanzati bbażati fuq it-trasformaturi jiksbu punteġġi F1 ta’ 39.0 biss. Aħna nuru kif dawn is-settijiet ta’ dejta sintetiċi jallinjaw l-għarfien strutturat mal-introspezzjoni tat-test naturali u tal-mudell ta’ għajnuna meta jkunu qed jintlaħqu fehim kumpless tat-test.', 'it': "I recenti parametri di riferimento per la risposta alle domande e la lettura automatica riducono spesso il compito di individuare intervalli all'interno di un determinato passaggio di testo che risponde alla domanda data. In genere, questi sistemi non sono tenuti a comprendere effettivamente il testo a un livello più profondo che consente di ragionare più complesso sulle informazioni contenute. Introducemo un nuovo dataset chiamato BiQuAD che richiede una comprensione più profonda per rispondere alle domande sia in modo estrattivo che deduttivo. Il set di dati è composto da 4.190 testi a dominio chiuso e un totale di 99.149 coppie domande-risposte. I testi sono report di partite di calcio generati sinteticamente che verbalizzano i principali eventi di ogni partita. Tutti i testi sono accompagnati da un programma Datalog strutturato che rappresenta un modello (logico) delle sue informazioni. Dimostriamo che i modelli di QA all'avanguardia non funzionano bene nei contesti difficili di forma lunga e nei requisiti di ragionamento posti dal set di dati. In particolare, i modelli all'avanguardia basati su trasformatori raggiungono punteggi F1 di soli 39,0. Dimostriamo come questi set di dati sintetici allineano la conoscenza strutturata con il testo naturale e aiutano l'introspezione del modello quando ci si avvicina alla comprensione del testo complessa.", 'mn': 'Саяхан асуулт хариулт, машины унших багц загварууд нь үүнийг тодорхой асуултанд хариулт өгсөн текст загварын нэг загвар руу багасгадаг. Эдгээр системүүд мэдээллийн тухай илүү нарийн бодлого боломж олгодог гүн гүнзгий түвшинд бичсэн текстийг ойлгох шаардлагагүй. Бид BiQuAD гэдэг шинэ өгөгдлийн санг илүү гүнзгий ойлголт хэрэгтэй гэдгийг танилцуулдаг. Ингээд нэмэлт болон бусад асуултуудыг хариулах хэрэгтэй. Өгөгдлийн сангууд нь 4,190 онгоцны баримт, 99,149 асуулт хариултын хоёр байдаг. Текст нь тоглоом бүрийн гол үйл явдлыг шинжлэх ухаан боловсруулдаг бөмбөлөгийн тоглоом юм. Бүх текст нь мэдээллийн (логик) загварын бүтээгдэхүүнтэй хамтран байдаг. Бид урлагийн QA загварууд өгөгдлийн сангийн зориулагдсан шаардлагатай урт хугацааны туршилтын тухай сайн ажиллахгүй гэдгийг харуулж байна. Ялангуяа өөрчлөгчийн суурь загвар нь зөвхөн 39.0 тооны F1 оноо гаргадаг. Бид эдгээр синтетик өгөгдлийн сангууд байгалийн текст болон загварын интроспекторын тусламжтай бүтэц мэдлэг хэрхэн холбоотой талаар харуулж байна.', 'no': 'Nyleg svar på spørsmål og lesing av maskinen ofte reduserer oppgåva til ein av spesifiserte mellomrom i eit viss tekstpassage som svarar på det oppgjevne spørsmålet. Vanlegvis er desse systema ikkje nødvendig for å forstå teksten på ein dypere nivå som tillater meir komplisert rasjon på informasjonen som inneheld. Vi introduserer eit nytt dataset kalla BiQuAD som krev dypere forståelse for å svara på spørsmål både ekstraktivt og deduktivt måte. Datasettet inneheld av 4,190 lukka domenetekst og totalt 99,149 svarpar. Tekstene er syntetisk genererte fotball-treff rapporter som verbaliserer hovudhendingane for kvar treff. Alle tekstar er lagt med eit strukturert dataalogprogram som representerer ein (logisk) modell av informasjonen sin. Vi viser at QA-modeller for kunsten ikkje utfører godt på dei vanskelege lange skjemakontekstane og grunnleggingane for datasettet. Spesielt har transformeringsmodeller basert på tilstanden av kunsten fått bare F1-poeng med 39,0. Vi viser korleis disse syntetiske datasettene alignerer strukturerte kunnskap med naturtekst og hjelpemodellen introspeksjon når det nærmer komplekse tekstforståelse.', 'pl': 'Ostatnie wskaźniki odniesienia do odpowiedzi na pytania i odczytu maszynowego często redukują zadanie do określenia zakresów w określonym fragmencie tekstu, który odpowiada na dane pytanie. Zazwyczaj systemy te nie są wymagane do faktycznego zrozumienia tekstu na głębszym poziomie, który pozwala na bardziej złożone rozumowanie zawartych informacji. Wprowadzamy nowy zestaw danych o nazwie BiQuAD, który wymaga głębszego zrozumienia w celu odpowiedzi na pytania zarówno w sposób ekstrakcyjny, jak i dedukcyjny. Zestaw danych składa się z 4,190 tekstów zamkniętych domen oraz łącznie par pytania-odpowiedzi 99,149. Teksty są syntetycznie generowanymi raportami meczu piłki nożnej, które werbalizują główne wydarzenia każdego meczu. Wszystkim tekstom towarzyszy ustrukturyzowany program Datalog, który reprezentuje (logiczny) model jego informacji. Pokazujemy, że najnowocześniejsze modele jakości nie sprawdzają się dobrze w trudnych kontekstach długiej formy i wymaganiach rozumowania stawianych przez zbiór danych. W szczególności nowoczesne modele oparte na transformatorach osiągają punkty F1 tylko 39,0. Pokazujemy, jak te syntetyczne zbiory danych dostosowują strukturalną wiedzę do tekstu naturalnego i pomagają modelowi introspekcji podczas zbliżania się do złożonego zrozumienia tekstu.', 'ms': 'Jawapan soalan baru-baru ini dan tanda benchmark pembacaan mesin sering mengurangkan tugas ke salah satu jangkauan penunjuk dalam laluan teks tertentu yang menjawab soalan yang diberi. Biasanya, sistem ini tidak diperlukan untuk memahami teks pada tahap yang lebih dalam yang membolehkan alasan yang lebih kompleks pada maklumat yang terkandung. Kami memperkenalkan set data baru bernama BiQuAD yang memerlukan pemahaman lebih dalam untuk menjawab soalan dengan cara ekstraktif dan deduktif. Set data terdiri dari 4,190 teks domain tertutup dan total 99,149 pasangan soalan-jawapan. Teks dijana secara sintetik laporan pertandingan sepak bola yang mengalirkan perkataan peristiwa utama setiap pertandingan. Semua teks disertai oleh program Datalog struktur yang mewakili model (logik) maklumatnya. Kami menunjukkan bahawa model QA yang terbaik tidak berjaya dengan baik pada konteks bentuk panjang yang menantang dan keperluan alasan yang dipilih oleh set data. Secara khususnya, model terbaik berdasarkan pengubah mencapai skor F1 hanya 39.0. Kami menunjukkan bagaimana set data sintetik ini menyesuaikan pengetahuan struktur dengan teks semulajadi dan introspeksi model bantuan apabila mendekati pemahaman teks kompleks.', 'sr': 'Nedavno odgovarajuće pitanja i kriterije čitanja mašina često smanjuje zadatak na jedan od određenih prostora u određenom tekstskom prolazu koji odgovara na određeno pitanje. Obično, ovi sistemi nisu potrebni da zapravo razumeju tekst na dubljoj nivou koji omogućava kompleksniji razgovor o sadržanoj informaciji. Upoznajemo novi set podataka po imenu BiQuAD koji zahteva dublje razumevanje kako bi odgovorili na pitanja na ekstraktivan i deduktivan način. Podaci se sastavljaju od 4.190 teksta zatvorenih domena i ukupno 99.149 parova odgovora na pitanje. Teksti su sintetički stvoreni izveštaji o fudbalskoj utakmici koji verbalizuju glavne događaje svake utakmice. Svi teksti su praćeni strukturiranim Datalogskim programom koji predstavlja (logički) model njegovih informacija. Pokazujemo da modeli state-of-the-art QA ne izvršavaju dobro na izazovnim dugačkim kontekstima i razumnim zahtjevima koje su postavili komplet podataka. Posebno, transformator bazirani modeli umjetnosti postiže F1 rezultate samo 39,0. Pokazujemo kako se te sintetičke podatke prilagođavaju strukturirane znanje prirodnim tekstom i model pomoći introspekcijom pri pristupanju kompleksnog razumevanja teksta.', 'ml': 'അടുത്ത ചോദ്യം ഉത്തരം ചോദിക്കുന്നതും മെഷീന്\u200d വായിക്കുന്നതും കൊടുത്ത ചോദ്യം ഉത്തരം നല്\u200dകുന്ന ചോദ്യം ഉത്തരം നല്\u200dകുന്ന ഒരു ചില സാധാരണ വിവരങ്ങളുടെ വിവരങ്ങള്\u200d കൂടുതല്\u200d കൂടുതല്\u200d പരിഗണിക്കാന്\u200d ഈ സിസ്റ്റത്തില്\u200d പദാവലിയെ മനസ്സിലാക്കാന്\u200d ആവശ്യമില്ല. ബിക്വാഡ് എന്ന ഒരു പുതിയ ഡാറ്റാസസെറ്റിനെ ഞങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു. അതിന് ആഴത്തിലുള്ള സൂക്ഷ്മമാണ് ആവശ്യമുള്ളത്. അതി ഡാറ്റാസെറ്റ് 4,190 അടച്ച ഡൊമെയിന്\u200d ടെക്സ്റ്റുകളിലും 99,149 ചോദ്യം ഉത്തരം ജോടികളിലും ഉണ്ട്. പദാവലികള്\u200d സങ്കീര്\u200dണ്ണമായി സൃഷ്ടിച്ചുകൊണ്ടിരിക്കുന്ന ഫുട്ടറുകള്\u200d പൊരുത്തിയിരിക്കുന്നു എല്ലാ ടെക്സ്റ്റുകളും അതിന്റെ വിവരങ്ങളുടെ (ലോഗിക്ക്) മോഡല്\u200d പ്രതിനിധിയ്ക്കുന്ന ഒരു ഡാറ്റാലോഗ് പ്രോഗ് നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് ക്യൂഎ-സ്റ്റേറ്റ് മോഡലുകള്\u200d നീണ്ട രൂപത്തിലെ പങ്കാളികളും ഡാറ്റാസെറ്റിന്റെ വിവേച പ്രത്യേകിച്ച്, മാറ്റം അടിസ്ഥാനമാക്കുന്ന സ്റ്റേറ്റ് ഓഫ്- കലാകാര്യ മോഡലുകള്\u200d F1- സ്കോര്\u200d മാത്രം 39. 0 മാത സ്വാഭാവികമായ ടെക്സ്റ്റും സഹായിക്കുന്ന മോഡലുമായി പരിശോധിക്കുമ്പോള്\u200d ഈ സിന്തെറ്റിക്ക് ഡാറ്റാസറ്റുകള്\u200d എങ്ങനെ', 'so': "Jawaabta su'aalaha la soo dhowaaday iyo aqriska waxyaabaha lagu akhriyey ayaa inta badan shaqada ugu hoosaysiiya mid ka mid ah baasabka qoraalka oo ka jawaabaya su'aalaha la siiyey. Sida caadiga ah nidaamkan looma baahna in aad xaqiiqa u fahanto qoraalka heerka hoose, kaas oo u ogolaada sabab aad u adag oo ku saabsan macluumaadka. Waxaynu soo bandhignaa sawir cusub oo la yidhaahdo BiQuAD oo u baahan yahay hoos-hoos, si aan ugu jawaabno su'aalo si ay u jawaabaan qaab la soo saaro iyo kharash. Taariikhda macluumaadku waxay ka mid yihiin 4,190 qoraal xiran oo domen ah iyo dhamaan 99,149 qof oo su'aal ka jawaaba su'aalaha. Qoraayinka waxaa lagu sameeyaa si sinnaan ah oo u soo bandhigaya kaalmada soccer, waxayna soo sheegayaan in lagu soo beddelo dhacdooyinka ugu horreeya ee isku mid ah. Dhammaan qoraalka waxaa ku jira barnaamijka qoraalka datalog oo u jeeda modelka macluumaadkiisa (logical). We show that state-of-the-art QA models do not perform well on the challenging long form contexts and reasoning requirements posed by the dataset.  Si gaar ah, bedelka noocyada farshaxanka ee ku saleysan wuxuu gaadhaa koorasyada F1 oo kaliya 39.0. Waxaynu muujinnaa siday macluumaadyadanu u sawiraan aqoonta asalka ah iyo qaabka caawimaadda marka ay u soo dhowaadaan waxgarashada qallafsan.", 'sv': 'Senaste frågeställnings- och maskinläsriktmärken minskar ofta uppgiften till att identifiera spännvidder inom en viss textpassage som besvarar den givna frågan. Typiskt krävs inte dessa system för att faktiskt förstå texten på en djupare nivå som möjliggör mer komplexa resonemang om den information som ingår. Vi introducerar en ny dataset kallad BiQuAD som kräver djupare förståelse för att kunna besvara frågor på både extraktivt och deduktivt sätt. Datauppsättningen består av 4 190 slutna texter och totalt 99 149 frågor-svar par. Texterna är syntetiskt genererade fotbollsmatchrapporter som verbaliserar de viktigaste händelserna i varje match. Alla texter åtföljs av ett strukturerat datalogprogram som representerar en (logisk) modell av dess information. Vi visar att toppmoderna kvalitetssäkringsmodeller inte presterar bra på de utmanande långa formsammanhang och resonemangskrav som datauppsättningen ställer. I synnerhet, transformatorbaserade state-of-the-art modeller uppnår F1-poäng på endast 39,0. Vi visar hur dessa syntetiska datauppsättningar anpassar strukturerad kunskap till naturlig text och hjälper modellintrospektion när man närmar sig komplex textförståelse.', 'ur': 'اچھا سوال جواب دینے اور ماشین پڑھنے بانچمارک کثرت سے کام کو ایک مقررہ ٹیکسٹ پاسٹ کے اندر دھوکا دیتے ہیں جو اس سوال کی جواب دیتا ہے۔ یہ سیستموں کی ضرورت نہیں ہے کہ حقیقت میں ایک عمیق سطح پر متن سمجھ سکیں جو اس کی اطلاعات کے بارے میں زیادہ پیچیدہ دلیل کرنے کی اجازت دیں. ہم ایک نوی ڈیٹ سٹ کو معرفی کرتے ہیں جو BiQuAD کے نام سے زیادہ عمیقی سمجھ کی ضرورت ہے تاکہ سوالیوں کی جواب دو اخلاقی اور دھوکا دینے کے لئے۔ ڈاٹ سٹ میں 4,190 بند ڈومین ٹیکسٹ اور 99,149 سوال جوڑوں کی جمع ہے. ٹیکسٹ سینٹیٹی طور پر پیدا کیے گئے ہیں کہ فوٹ بول مڈیٹ راپوروں میں جو ہر مڈیٹ کی اصلی ایڈیونٹ کو وربلیج کر رہے ہیں. سارے پیغام کے ساتھ ایک ساختہ ڈاٹلاگ پروگرام کے ساتھ ہوتے ہیں جو اس کے معلومات کی ایک (منطقی) موڈل کی نمایش کرتا ہے. ہم دکھاتے ہیں کہ QA موڈل کو اچھی طرح دکھائی نہیں دیتے کہ ڈاٹ سٹ کے ذریعہ مشکل طویل فرم کی موضوعات اور منطقی معاملات پر اچھی طرح عمل نہیں کرتے۔ مخصوصاً ترفنٹر بنیاد آرت کی موڈل صرف 39.0 کے F1-اسکو پہنچ سکتے ہیں۔ ہم دکھاتے ہیں کہ یہ سینٹٹیسی ڈیٹسٹ کس طرح ساختہ علم کو طبیعی متن کے ساتھ تسبیح کرتی ہے اور مدد کی مدد کی مدد کی مدد کی جگہ پیچیدہ متن سمجھنے کے قریب آتی ہے۔', 'si': 'අලුත් ප්\u200dරශ්න ප්\u200dරතිච්චාරය සහ පණිවිඩය කියවන්න බෙන්ච්මාර්ක් සාමාර්ගයෙන් වැඩ කරන්න පුළුවන් ප්\u200dරශ්නයට ප්\u200dර සාමාන්\u200dයයෙන්, මේ පද්ධතිය අවශ්\u200dය නැහැ ඇත්තටම ගොඩක් ස්ථානයේ පාළුව තේරුම් ගන්න, ඒකෙන් තොරතුරු ගැන ත අපි බික්වාඩ් කියලා අළුත් දත්ත සූද්ධයක් පෙනුම් කරනවා ඒක ගොඩක් ගොඩක් තේරුම් අවශ්\u200dය වෙනුවෙන් ප්\u200dරශ්න ප්\u200dරශ් ඩේටාසෙට් එක්ක 4,190 වහලා තියෙන්නේ ප්\u200dරශ්න ප්\u200dරතිච්චාරයක් සම්පූර්ණ 99,149 කුණු සම්පූර්ණයි. පාළුවන් සංවිධානයෙන් නිර්මාණය කරලා තියෙන්නේ ප්\u200dරධාන අවස්ථාවක් හැම සංවිධානයේ ප්\u200dරධ සියළු පාළුවන් සම්බන්ධ වැඩසටහන් කරලා තොරතුරු ප්\u200dරවෘත්තියක් සමග (ලෝජකික) නිර්මාණයක් ප්\u200dරති අපි පෙන්වන්නේ ක්\u200dරියාත්මක QA මොඩේල් එකේ ප්\u200dරශ්නයක් හොඳ විදිහට ප්\u200dරශ්නයක් නැහැ දත්ත සැට වලින් ප්\u200dරශ්නයක් සහ හි විශේෂයෙන්, වෙනස් කරුණාකරණය අධ්\u200dයාත්මක විදිහට අධ්\u200dයාත්මක විදිහට F1-ස්කෝර් 39.0 විතරයි. අපි පෙන්වන්නේ මේ සංවිධාන දත්ත සැකසුම් සංවිධානය සඳහා ස්වභාවික පාළුවන් සහ උදව් ප්\u200dරමාණය සඳහා සංවිධ', 'ro': 'Criteriile recente de referință pentru răspunsul la întrebări și citirea automată reduc frecvent sarcina la una de a identifica intervale într-un anumit pasaj text care răspunde la întrebarea dată. De obicei, aceste sisteme nu sunt obligate să înțeleagă textul la un nivel mai profund, care permite un raționament mai complex asupra informațiilor conținute. Introducem un nou set de date numit BiQuAD care necesită o înțelegere mai profundă pentru a răspunde la întrebări atât în mod extractiv, cât și deductiv. Setul de date constă din 4.190 de texte cu domeniu închis și un total de 99.149 perechi de întrebări-răspunsuri. Textele sunt rapoarte generate sintetic de meciuri de fotbal care verbalizează principalele evenimente ale fiecărui meci. Toate textele sunt însoțite de un program Datalog structurat care reprezintă un model (logic) al informațiilor sale. Noi arătăm că modelele de calitate de ultimă generație nu funcționează bine în contextele dificile de formă lungă și cerințele de raționament impuse de setul de date. În special, modelele de ultimă generație bazate pe transformator ating scoruri F1 de numai 39,0. Demonstrăm modul în care aceste seturi de date sintetice aliniază cunoștințele structurate cu textul natural și ajută la introspecția modelului atunci când abordăm înțelegerea complexă a textului.', 'ta': 'சமீபத்தில் கேள்வி பதில் மற்றும் இயந்திரக் கேள்விக்கு பதில் கொடுக்கப்பட்ட கேள்விக்கு பதில் கொடுக்கப்பட்ட ஒரு சில புள்ளிய பொதுவாக, இந்த அமைப்புகள் உண்மையில் உரையை ஆழமான நிலையில் புரிந்து கொள்ள வேண்டாம். அது தகவல் கொண்டிருக்கும் மிக ச நாம் பிகுவாட் என்ற பெயர் புதிய தகவல் அமைப்பை குறிப்பிடுகிறோம். அது ஆழமான குழுக்கம் தேவைப்படுகிறது. அவை வெளியேற்றும் த 4,190 மூடப்பட்ட ட டொமைன் உரைகள் மற்றும் மொத்தமாக 99,149 கேள்வி கேள்வி ஜோடிகள். The texts are synthetically generated soccer match reports that verbalize the main events of each match.  அனைத்து உரைகளும் உருவாக்கப்பட்ட தரவுத்தளபதிவு நிரலால் சேர்க்கப்பட்டுள்ளது அது தகவலின் (logical) மாதிரியை குறிப் நாம் காண்பிக்கிறோம் என்றால் கியூஏ மாதிரிகள் நீண்ட வடிவத்தில் செயல்படுத்த முடியாது மற்றும் தரவு அமைப்பு கொண்டுள்ள குறிப்பிட்டு, மாற்றம் அடிப்படையிலான நிலைமை- கலை மாதிரிகள் F1- புள்ளிகள் மட்டும் 39. 0 மட்டும் பெறுகிறது. நாம் எப்படி இந்த கூட்டிணைப்பு தகவல் அமைப்புகள் சிக்கலான உரை மற்றும் உதவி மாதிரி புரியும் பொழுது சிக்கலான உரை புரியும் வர', 'uz': "@ info: whatsthis Oddiy, bu tizimlar maʼlumot haqida qo'shimcha matnni tushirish uchun kerak emas. Biz BiQuAD deb nomli yangi maʼlumotlar tarkibini koʻrsatimiz. Bu savollarni ekstraktiv va dedektiv usulda javob berish kerak. Name @ info: whatsthis @ info Biz hodisa QA modellari maʼlumotlar sahifadagi muddat shakllar va ma'lumotlar tartibi davomida yaxshi ishlamaydi. Ko'pchilik, shaxsiy modellarning asosida oʻzgarishlar faqat 39.0 darajaga keladi. Biz buning bir kompyuterdagi matn tushunishga murakkab tushunishga ega bo'lganda bu syntetik maʼlumotlar qanday tuzilishini ko'rsatamiz.", 'vi': 'Những tiêu chuẩn trả lời câu hỏi gần đây và đọc máy thường làm giảm nhiệm vụ thành một nút nhọn nằm trong một đoạn văn bản nhất định giải đáp câu hỏi này. Thông thường, những hệ thống này không cần thiết để thực sự hiểu được chữ viết ở một mức độ sâu hơn cho phép lập luận phức tạp hơn về những thông tin bên trong. Chúng tôi giới thiệu một tập tin mới có tên là BiCOAD cần sự thấu hiểu sâu hơn để trả lời câu hỏi theo cách thu thập và thu thập. Bộ dữ liệu gồm bốn,190 văn bản riêng và tổng bộ 99 câu trả lời câu hỏi. Những văn bản này được tạo ra tổng hợp các báo cáo đá bóng diễn tả các sự kiện chính trong mỗi trận đấu. Tất cả các văn bản đều được kèm theo một chương trình Dữ liệu có cấu trúc đại diện cho mô hình (logic) của thông tin. Chúng tôi cho thấy các mô hình QA hiện đại không hoạt động tốt với các mặt ngữ cảnh dài dạng đầy thử thách và các yêu cầu lập luận của bộ dữ liệu. Đặc biệt, mẫu người máy biến đổi dựa trên nghệ thuật đạt điểm F1 chỉ trên 39.0. Chúng tôi chứng minh cách những bộ dữ liệu tổng hợp này kết hợp kiến thức cấu trúc với quy luật tự nhiên và phương pháp hỗ trợ khi tiến tới hiểu biết văn bản phức tạp.', 'bg': 'Последните показатели за отговор на въпроси и машинно четене често намаляват задачата до определяне на диапазони в рамките на определен текстов пасаж, който отговаря на даден въпрос. Обикновено от тези системи не се изисква действително да разбират текста на по-дълбоко ниво, което позволява по-сложно разсъждаване на съдържащата се информация. Въвеждаме нов набор от данни, наречен БиКуАД, който изисква по-задълбочено разбиране, за да отговори на въпросите както по екстрактивен, така и по дедуктивен начин. Наборът от данни се състои от 4190 текста със затворен домейн и общо 99 149 двойки въпроси-отговори. Текстовете са синтетично генерирани доклади за футболни мачове, които вербализират основните събития на всеки мач. Всички текстове са придружени от структурирана програма, която представлява (логически) модел на нейната информация. Показваме, че най-съвременните модели за оценка на качеството не се представят добре в предизвикателните контексти на дългите форми и изискванията за разсъждения, поставени от набора от данни. По-специално, трансформаторните модели постигат резултати само от 39.0. Ние демонстрираме как тези синтетични набори от данни привеждат структурираното знание в съответствие с естествения текст и подпомагат интроспекцията на модела при приближаване до сложното разбиране на текста.', 'da': 'Seneste spørgsmål besvarelse og maskinlæsning benchmarks reducerer ofte opgaven til at fastlægge spændinger inden for en bestemt tekstpassage, der besvarer det givne spørgsmål. Typisk er disse systemer ikke nødvendige for faktisk at forstå teksten på et dybere niveau, der giver mulighed for mere komplekse ræsonnementer om de indeholdte oplysninger. Vi introducerer et nyt datasæt kaldet BiQuAD, der kræver dybere forståelse for at kunne besvare spørgsmål på både ekstraktiv og deduktiv måde. Datasættet består af 4.190 lukkede domænetekster og i alt 99.149 spørgsmål-svar par. Teksterne er syntetisk genererede fodboldkamp rapporter, der ordbogfører de vigtigste begivenheder i hver kamp. Alle tekster ledsages af et struktureret Datalog program, der repræsenterer en (logisk) model af dets oplysninger. Vi viser, at state-of-the-art QA-modeller ikke klarer sig godt på de udfordrende langformede kontekster og ræsonnementskrav, datasættet stiller. Især opnår transformer baserede state-of-the-art modeller F1-scores på kun 39,0. Vi demonstrerer, hvordan disse syntetiske datasæt tilpasser struktureret viden med naturlig tekst og hjælper model introspektion, når man nærmer sig kompleks tekstforståelse.', 'nl': 'Recente benchmarks voor vragenbeantwoording en machinelezen reduceren vaak de taak tot het vaststellen van overspanningen binnen een bepaalde tekstpassage die de gegeven vraag beantwoordt. Meestal zijn deze systemen niet verplicht om de tekst daadwerkelijk te begrijpen op een dieper niveau dat een complexere redenering over de informatie mogelijk maakt. We introduceren een nieuwe dataset genaamd BiQuAD die dieper begrip vereist om vragen zowel extractief als deductief te beantwoorden. De dataset bestaat uit 4.190 gesloten domeinteksten en in totaal 99.149 vraag-antwoord paren. De teksten zijn synthetisch gegenereerde voetbalwedstrijdrapporten die de belangrijkste gebeurtenissen van elke wedstrijd verbaliseren. Alle teksten worden vergezeld van een gestructureerd Datalog programma dat een (logisch) model van zijn informatie vertegenwoordigt. We laten zien dat state-of-the-art QA modellen niet goed presteren op de uitdagende lange vorm contexten en redeneringsvereisten die worden gesteld door de dataset. Met name transformatorgebaseerde state-of-the-art modellen bereiken F1-scores van slechts 39,0. We laten zien hoe deze synthetische datasets gestructureerde kennis afstemmen op natuurlijke tekst en helpen model introspectie bij het benaderen van complexe tekst begrijpen.', 'hr': 'Nedavno odgovarajuće pitanja i kriterije čitanja strojeva često smanjuje zadatak na jedno od određenih mjesta u određenom tekstskom prolazu koji odgovara na određeno pitanje. Obično, ovi sustavi nisu potrebni da zapravo razumiju tekst na dubljoj razini koji omogućava kompleksniji razgovor o sadrženim informacijama. Upoznajemo novu podatku po imenu BiQuAD koja zahtijeva dublje razumijevanje kako bi odgovorili na pitanja na ekstraktivan i deduktivan način. Podaci se sastoje od 4.190 teksta zatvorenih domena i ukupno 99.149 parova odgovora na pitanje. Teksti su sintetički proizvještaji o fudbalskoj utakmici koji verbaliziraju glavne događaje svake utakmice. Svi teksti su praćeni strukturiranim Datalogskim programom koji predstavlja (logički) model njegovih informacija. Pokazujemo da modeli države umjetnosti QA ne izvode dobro na izazovnim dugačkim uvjetima i razumnim zahtjevima koje su postavili komplet podataka. Posebno, transformacijski modeli na temelju stanja umjetnosti postignu F1 rezultate samo 39,0. Pokazujemo kako se te sintetičke podatke prilagođavaju strukturirane znanje prirodnim tekstom i model pomoći introspekcijom pri pristupanju kompleksnog razumijevanja teksta.', 'de': 'Jüngste Benchmarks für die Beantwortung von Fragen und das maschinelle Lesen reduzieren häufig die Aufgabe, Spannweiten innerhalb eines bestimmten Textabschnitts festzulegen, der die gegebene Frage beantwortet. In der Regel sind diese Systeme nicht erforderlich, um den Text tatsächlich auf einer tieferen Ebene zu verstehen, was eine komplexere Begründung der enthaltenen Informationen ermöglicht. Wir führen einen neuen Datensatz namens BiQuAD ein, der tieferes Verständnis erfordert, um Fragen sowohl extraktiv als auch deduktiv beantworten zu können. Der Datensatz besteht aus 4.190 geschlossenen Texten und insgesamt 99.149 Frage-Antwort-Paaren. Die Texte sind synthetisch generierte Fußballspielberichte, die die wichtigsten Ereignisse jedes Spiels verbalisieren. Alle Texte werden von einem strukturierten Datalog-Programm begleitet, das ein (logisches) Modell seiner Informationen darstellt. Wir zeigen, dass moderne QA-Modelle in den herausfordernden Langform-Kontexten und Argumentationsanforderungen des Datensatzes nicht gut abschneiden. Insbesondere transformatorbasierte State-of-the-Art Modelle erreichen F1-Werte von nur 39,0. Wir zeigen, wie diese synthetischen Datensätze strukturiertes Wissen mit natürlichem Text in Einklang bringen und unterstützen die Modellintrospektion bei der Annäherung an komplexes Textverständnis.', 'fa': 'پاسخ اخیر سوال و نوشته\u200cهای خواندن ماشین اغلب کار را به یکی از فضایی\u200cهای مشخص\u200cکننده در یک مسیر متن خاص کاهش می\u200cدهد که پاسخ به سوال داده می\u200cشود. معمولاً این سیستم ها لازم نیستند که در واقع متن را در سطح عمیق تر درک کنند که اجازه می دهد برای دلیل پیچیده\u200cتر در اطلاعات حاوی باشد. ما یک مجموعه اطلاعات جدید به نام BiQuAD را معرفی می کنیم که نیاز به درک عمیق تر برای جواب سوالات در هر صورت استثناء و تخفیف است. مجموعه داده\u200cها از ۱۴،۹۰۰ متن\u200cهای دامنی بسته و جمعیت ۹۹،149 جفت جواب سوال است. متن\u200cها گزارش\u200cهای مسابقه فوتبال ساخته شده\u200cاند که رویداد\u200cهای اصلی هر مسابقه\u200cای را تولید می\u200cکنند. همه\u200cی متن\u200cها توسط برنامه\u200cی ساخته\u200cشده\u200cی برنامه\u200cی دادالوگ\u200cهای ساخته شده\u200cاند که یک مدل (منطقی) از اطلاعات آن را نمایش می\u200cدهد. ما نشان می دهیم که مدل های ایالت هنری QA در مورد موضوعات طولانی و نیازهای منطقی که توسط مجموعه داده ها قرار دارند خوب انجام نمی دهند. مخصوصا، مدلهای موقعیت هنری بنیاد تغییر دهنده فقط 39.0 امتیاز F1 را می رساند. ما نشان می دهیم که این مجموعه\u200cهای داده\u200cهای سینتیک چگونه علم ساخته شده را با متن طبیعی تنظیم می\u200cکنند و مدل\u200cهای داخل بازرسی کمک می\u200cکنند وقتی به درک متن پیچیده نزدیک می\u200cشوند.', 'sw': 'Swali la hivi karibuni na kusoma misingi ya mashine mara nyingi hupunguza kazi kwa moja ya siku za kuchapisha kwa kutumia ujumbe fulani wa maandishi yanayojibu swali hilo. Kwa kawaida, mfumo huu hauhitaji kuelewa maandishi katika kiwango cha kina kinachoruhusu sababu tatizo zaidi kuhusu taarifa zilizopo. Tunaonyesha seti mpya ya taarifa iitwayo BiQuAD inayohitaji ufahamu wa kina zaidi ili kujibu maswali kwa njia za kutosha na kujitenga. Taarifa hiyo imejumuisha maandishi ya vifungu vya ndani 4,190 na jumla ya majibu 99,149. Maandishi yanazungumzwa kwa pamoja na mapambano ya soka yanaripoti kuwa mabadiliko ya matukio muhimu ya kila mechi. Makala yote yanaungana na programu ya Datalog iliyoandaliwa inayowakilisha mtindo wa taarifa yake. Tunaonyesha kuwa mifano ya hali ya sanaa ya QA hazifanyi vizuri kuhusu michango ya muda mrefu na mahitaji yanayotolewa na seti ya data. hasa, mabadiliko yanayohusiana na hali ya sanaa yanafanikiwa vipimo vya F1 pekee 39.0. Tunaonyesha jinsi taarifa hizi za pamoja zinavyotengeneza ufahamu wa maandishi ya asili na mifano ya misaada inapokaribia kuelewa vigumu vya maandishi.', 'id': 'Jawaban pertanyaan dan benchmark pembacaan mesin baru-baru ini sering mengurangi tugas ke salah satu jangkauan yang menunjukkan dalam beberapa kalimat teks yang menjawab pertanyaan yang diberikan. Biasanya, sistem-sistem ini tidak diperlukan untuk benar-benar memahami teks pada tingkat yang lebih dalam yang memungkinkan untuk alasan yang lebih kompleks pada informasi yang terkandung. Kami memperkenalkan dataset baru bernama BiQuAD yang membutuhkan pemahaman lebih dalam untuk menjawab pertanyaan dengan cara ekstraktif dan deduktif. Set data terdiri dari 4.190 teks domain tertutup dan total 99.149 pasangan pertanyaan-jawaban. Teksnya dihasilkan secara sintetis melaporkan pertandingan sepak bola yang menyatakan peristiwa utama setiap pertandingan. Semua teks disertai oleh program Datalog struktur yang mewakili model (logis) informasinya. Kami menunjukkan bahwa model QA terbaik tidak berjalan dengan baik pada konteks bentuk panjang yang menantang dan keperluan alasan yang ditentukan oleh dataset. Terutama, model terbaik berbasis transformer mencapai skor F1 hanya 39,0. Kami menunjukkan bagaimana set data sintetik ini menyesuaikan pengetahuan strukturasi dengan teks alami dan introspeksi model bantuan ketika mendekati pemahaman teks kompleks.', 'af': "Onlangse vraag antwoord en masjien lees benchmarke dikwels verduur die taak na een van pinpointing spans binne 'n sekere teks wagwoord wat antwoord die gegewe vraag. Tipe is hierdie stelsels nie nodig om die teks te verstaan op 'n dieper vlak wat toelaat vir meer kompleks redening op die inligting bevat. Ons introduseer 'n nuwe datastel genoem BiQuAD wat dieper verstanding vereis om vrae te antwoord in ekstraktiewe en afgedruktiewe manier. Die datastel bestaan van 4,190 gesluit-domein-teks en 'n totaal van 99,149 vraag-antwoordepaar. Die teks is sinteties genereer fotball ooreenstemmende raporte wat die hoofgebeurtenis van elke ooreenstemming verbaliseer. Alle teks word gevolg deur 'n struktureerde Dataloog program wat 'n (logiese) model van sy inligting verteenwoordig. Ons wys dat state-of-the-art QA-modele nie goed uitvoer op die verwagte lang vorm-konteks en redekende benodighede wat deur die datastel posisie is nie. In besonderhede, transformeerder gebaseerde staat-van-die-kuns-modelles bereik F1-telling van slegs 39.0. Ons wys hoe hierdie sintetiese datastelle structureerde kennis met natuurlike teks en hulp model introspeksie aligneer wanneer daardie kompleks teks verstanding naby kom.", 'ko': '최근의 문답과 기계적 읽기 기준은 주어진 문제에 대한 특정한 텍스트 세그먼트에서 위치를 정하는 경계로 임무를 간소화하는 경우가 많다.통상적으로 이런 시스템은 텍스트를 더욱 깊은 차원에서 진정으로 이해할 필요가 없으며, 포함된 정보에 대해 더욱 복잡한 추리를 허용한다.BiQuad라는 새로운 데이터 세트를 도입했는데 추출과 연역으로 질문에 대답할 수 있도록 더 깊은 이해가 필요합니다.이 데이터 세트는 4190개의 폐쇄역 텍스트와 99149개의 문답 쌍으로 구성되어 있다.이 텍스트들은 종합적으로 생성된 축구 경기 보고서로 매 경기의 주요 사건을 묘사한다.모든 텍스트에는 구조화된 데이터 기록 프로그램이 첨부되어 있으며, 이 프로그램은 그 정보의 (논리적) 모델을 나타낸다.우리는 가장 선진적인 QA모델이 데이터 집합에서 제기한 도전적인 긴 형식의 상하문과 추리 수요에서 좋지 않다는 것을 발견했다.특히 변압기 기반 최첨단 모델의 F1 성적은 39.0점에 그쳤다.우리는 이러한 합성 데이터 집합이 구조화된 지식과 자연 텍스트를 어떻게 결합시키는지 보여주었고 복잡한 텍스트 이해에 접근할 때 모델의 내성을 돕는다.', 'tr': 'Ýakyndaky soraglar we maşynyň okamaky benchmarklary görnüşi görnüşi birnäçe soragyna jogap beren metin geçmesinde görkezilýän noktalaryny azaltýar. Adatça bu sistemler içerideki daşky derejede metini düşünmek üçin gerek däl. Biz BiQuAD adında yeni bir veri setini ortaya koyuyoruz ki, a şama ve çözümlendirmek için sorulara cevap vermek için daha derin anlama gerekiyor. Veri setir 4,190 ýapylan sahypa metinlerinden we 99,149 sorag-jogaby çiftlerden bar. Metinler futbol meýilleşdirilýan hasaplar üçin her eşleşişiniň esasy hadysyny verbalize ýän netijesi bar. Hemme metin öz maglumatynyň (logik) nusgasyny täze bir strukturlyk programi bilen birleştirilýär. Biz sungat sistemi QA modelleriniň nähili kynçylyk möhüm durumlarda we berüvlendirilen soňunlar üçin gowy etmezligini görkeýäris. Aýratyn bilen, sanat nusgalarynyň daýanýar durumyny diňe 39.0 degişlerini ýetip biler. Biz bu sintetik veri setirleri tebigy metin bilen düzümlendirilýän bilimleri we kelläp metin düşünmesine ýakynda nusgala edip görkeýäris.', 'am': 'የቀን ጥያቄ መልስ እና መሳሳይ አካሄዱን ማነብ በጊዜው ስራውን በተሰጠው ጥያቄ በሚመልስ ከጽሑፍ ፋይሎች ውስጥ ወደአንዱ መስኮት ያጎድላል፡፡ በተጨማሪም፣ እነዚህ ስርዓቶች ጽሑፉን በጥልቅ ደረጃ ለማስተዋል አይፈለጉም፡፡ በጥልቅ ውጤት የሚያስፈልገውን እና በጥልቅ እና በጥያቄ ጥያቄን ለመመልስ የሚችሉትን አዲስ ዳታተር setን እናስጠጋለን፡፡ የዳታ ሰርቨሮች 4,190 የተዘጋጁ ዶሜን ጽሑፎች እና በሙሉ 99,149 ጥያቄ መልስ ሁለት ናቸው፡፡ ጽሑፎቹ የእያንዳንዱ የዋና ጉዳይ ጉዳይ እየተመሳሰሉ የእግር እግር ቃላት እንዲያስተካክሉ ነው፡፡ የጽሑፎች ሁሉ በተመሠረተ ዳይሎጂ ፕሮግራም የመረጃውን (logical) ሞዴል የሚያስተካክል ነው፡፡ የ-የ-የ የ.አ-የ-የ.አ-አካባቢ ሞዴላዎች በዳታ የተደረገውን የረጅም ፎርማት ውጤቶች እና የመሳሰል ውጤቶች የሚያስፈልጉትን ጥሩ አያደርጉም፡፡ In particular, transformer based state-of-the-art models achieve F1-scores of only 39.0.  እነዚህ የድምፅ ጽሑፍ እና የረጂ ዓይነት ማቀናቀል በተደረገ ጊዜ እንደምናሳያቸው እናሳያቸዋለን፡፡', 'az': 'Son sual cavab verm…ôk v…ô maŇüńĪna oxunmaq benchmarkl…ôri iŇül…ôri √ßox sńĪk-sńĪk veril…ôn suala cavab ver…ôn m…ôtn ke√ßm…ôsind…ôn birin…ô t…ôr…ôf √ß…ôkir. Bu sisteml…ôrin sad…ôc…ô olaraq i√ß…ôrisind…ô olanlar bar…ôsind…ô daha kompleks d…ôyiŇüiklik yaratmańüa imkan verm…ôk √ľ√ß√ľn daha derin s…ôviyy…ôd…ô m…ôlumatńĪ anlamaq √ľ√ß√ľn ehtiyacńĪ yoxdur. Biz BiQuAD adlńĪ yeni veril…ônl…ôr qutusunu t…ôŇükil edirik ki, h…ôr ikisi istifad…ô ed…ôc…ôk v…ô √ß…ôkil…ôc…ôk Ňü…ôkild…ô suallara cavab verm…ôk √ľ√ß√ľn daha derin anlama ehtiyacńĪ vardńĪr. Veri qurńüularńĪ 4,190 qapńĪlmńĪŇü domena metinl…ôrind…ôn v…ô toplam 99,149 sual cevap √ßiftl…ôrind…ôndir. M…ôtnl…ôr sintetik olaraq yaradńĪlmńĪŇü futbol eŇüitm…ôsi raporlarńĪdńĪr ki, h…ôr oyunun …ôsl vaxtlarńĪnńĪ verbalize edir. B√ľt√ľn m…ôtnl…ôr √∂z m…ôlumatńĪnńĪn (lojik) modeli g√∂st…ôril…ôn strukturlu Datalog proqramńĪnńĪn yanńĪndadńĪr. Biz QA modell…ôrinin √ßox √ß…ôtin olduńüu uzun formu m√ľxt…ôlifl…ôrd…ô v…ô veri qutusu t…ôr…ôfind…ôn qoyulan razńĪlaŇüma ŇüartlarńĪ bar…ôsind…ô yaxŇüńĪ iŇül…ôr g√∂rm…ôy…ôc…ôyini g√∂st…ôririk. √Ėzellikle, transformer-based state-of-the-art modell…ôri F1-scores yalnńĪz 39,0 d…ôyiŇüdirirl…ôr. Biz bu sintetik veril…ônl…ôr t…ôbi…ôtli m…ôtn il…ô m√ľxt…ôlif m…ôtn anlaŇüńĪlmasńĪna yaxńĪnlaŇüdńĪńüńĪ zaman strukturlu bilgi il…ô nec…ô d√ľz…ôltdiyini g√∂st…ôririk.', 'bn': 'সাম্প্রতিক প্রশ্নের উত্তর এবং মেশিনের বেনমার্ক পড়তে পারে তার কাজ প্রায়শই নির্দিষ্ট ট টেক্সট পাসেজের মধ্যে একটি পিন্টিং প Typically, these systems are not required to actually understand the text on a deeper level that allows for more complex reasoning on the information contained.  আমরা একটি নতুন ডাটাসেটের পরিচয় করিয়ে দিচ্ছি যার নাম বিকুয়াদের গভীর সম্পূর্ণ দরকার যাতে প্রশ্নের উত্তর দিতে পারে এক্সটেক্ট এবং  ডাটাসেটের মধ্যে ৪,190 বন্ধ ডোমেইন টেক্সট এবং মোট ৯৯,149 প্রশ্নের উত্তর জোট। টেক্সট সাথে সাথে সাথে ফুটবল ম্যাচ তৈরি করা হয়েছে সংবাদ প্রদান করা হয়েছে যে প্রত্যেক মিলের প্রধান অনুষ্ঠানে সকল টেক্সটের সাথে একটি স্থাপনিত ডাটালগ প্রোগ্রাম যা তার তথ্যের (লজিক্যাল) মডেল প্রতিনিধিত্ব করে। আমরা দেখাচ্ছি যে কিউ-শিল্পের রাষ্ট্রের মডেল দীর্ঘদিনের প্রতিযোগিতা এবং ডাটাসেটের দ্বারা যুক্তিগত প্রয়োজনীয় প্রতিয বিশেষ করে, পরিবর্তনের ভিত্তিক রাষ্ট্র-অফ-শিল্প মডেল শুধুমাত্র ৩৯. আমরা প্রদর্শন করি কিভাবে এই সিন্টেটিক ডাটাসেট প্রাকৃতিক টেক্সট এবং সাহায্য মডেলের প্রাকৃতিক পরিচিতির সাথে জ্ঞানের', 'sq': 'Përgjigja e fundit e pyetjeve dhe shënimet e leximit të makinave shpesh reduktojnë detyrën në një nga pikat e caktuara brenda një pasazhi të caktuar teksti që përgjigjet pyetjes së dhënë. Zakonisht, këto sisteme nuk kërkohen të kuptojnë tekstin në një nivel më të thellë që lejon për arsyetim më kompleks mbi informacionin e përmbajtur. Ne paraqesim një set të ri të dhënash të quajtur BiQuAD që kërkon një kuptim më të thellë me qëllim që të përgjigjem pyetjeve në mënyrë si nxjerrëse ashtu edhe përfundimtare. Të dhënat përbëhen nga 4,190 tekste me domeni të mbyllur dhe një total prej 99,149 çiftesh pyetjeje-përgjigje. Tekstet janë sintetikisht të gjeneruar raportet e ndeshjeve të futbollit që verbalizojnë ngjarjet kryesore të çdo ndeshje. Të gjitha tekstet janë shoqëruar nga një program i strukturuar Datalog që përfaqëson një model (logjik) të informacionit të tij. Ne tregojmë se modelet QA më të moderne nuk funksionojnë mirë në kontekstet e sfidueshme të form ës së gjatë dhe kërkesat arsyetimi të paraqitura nga grupi i të dhënave. Veçanërisht, modelet me bazë në transformues të moderne arrijnë rezultate F1 prej vetëm 39.0. Ne demonstrojmë se si këto grupe të dhënash sintetike përshtaten njohuritë e strukturuara me tekstin natyror dhe introspekcionin e modelit të ndihmës kur afrohen kuptimit kompleks të tekstit.', 'ca': "Recent question answering and machine reading benchmarks frequently reduce the task to one of pinpointing spans within a certain text passage that answers the given question.  Normalment, aquests sistemes no són obligats a entendre el text en un nivell més profund que permet raonament més complexe sobre la informació contenida. Introduïm un nou conjunt de dades anomenat BiQuAD que requereix una comprensió més profunda per respondre preguntes de manera extractiva i deductiva. El conjunt de dades consisteix en 4.190 textos de domini tancat i un total de 99.149 parells de respostes a preguntes. Els textos es generen sintèticament informes de partit de futbol que verbalitzen els principals esdeveniments de cada partit. Tots els textos estan acompanyats d'un program a estructurat de Datalog que representa un model (lògic) de la seva informació. Mostrem que els models QA més moderns no funcionen bé en els difícils contextes de llarga forma i requisits de raonament que posen el conjunt de dades. En particular, els models més avançats basats en transformadors aconsegueixen puntuacions F1 de només 39,0. Mostrem com aquests conjunts de dades sintètiques alineixen el coneixement estructurat amb l'introspecció del text natural i del model d'ajuda quan s'aproxima a la comprensió complexa del text.", 'hy': 'Վերջին հարցերի պատասխանը և մեքենային կարդալը հաճախ նվազեցնում են խնդիրը մինչև որոշակի տեքստի հատվածում գտնվող հատվածներից մեկը, որը պատասխանում է տվյալ հարցին: Սովորաբար, այս համակարգերը պարտադիր չեն, որ իրականում հասկանան տեքստը ավելի խորը մակարդակում, որը հնարավորություն է տալիս ավելի բարդ մտածելակերպ տեղեկատվության մասին: Մենք ներկայացնում ենք մի նոր տվյալների համակարգ, որը կոչվում է «ԲիՔԱԴ», որը պահանջում է ավելի խորը հասկացություն, որպեսզի պատասխանի տալիս հարցերին բացատրողական և հետևողական ձևով: Տվյալների համակարգը կազմում է 4,190 փակ բնագավառի տեքստ և 99,149 հարցերի պատասխանների զույգ: The texts are synthetically generated soccer match reports that verbalize the main events of each match.  Բոլոր տեքստերը ուղեկցված են կառուցվածքավորված Դատալոգ ծրագիր, որը ներկայացնում է իր տեղեկատվության (տրամաբանական) մոդել: Մենք ցույց ենք տալիս, որ ամենահետաքրքիր QA մոդելները լավ չեն աշխատում այն մարտահրավեր երկար ձևերի կոնտեքստների և մտածողական պահանջների վրա, որոնք առաջացել են տվյալների համակարգում: Մասնավորապես, վերափոխման հիմնված ամենաբարձր մոդելները հասնում են F1-ի միայն 39.0 գնահատականների: Մենք ցույց ենք տալիս, թե ինչպես են այս սինթետիկ տվյալների համակարգերը հարմարեցնում կառուցվածված գիտելիքները բնական տեքստի հետ և օգնում են մոտենալ բարդ տեքստի ընկալումը:', 'bs': 'Nedavno odgovarajuće pitanja i kriterije čitanja mašina često smanjuje zadatak na jedno od određenih mjesta u okviru određenog tekstskog prolaza koji odgovara na određeno pitanje. Obično, ovi sistemi nisu potrebni da zapravo razumiju tekst na dublji nivo koji omogućava kompleksniji razgovor o sadrženim informacijama. Upoznajemo novi set podataka po imenu BiQuAD koji zahtijeva dublje razumijevanje kako bi odgovorili na pitanja na ekstraktivan i deduktivan način. Podaci se sastoje od 4.190 teksta zatvorenih domena i ukupno 99.149 parova odgovora na pitanje. Teksti su sintetički stvoreni izvještaji o fudbalskoj utakmici koji verbalizuju glavne događaje svake utakmice. Svi teksti su praćeni strukturiranim programom Datalog a koji predstavlja (logički) model njegovih informacija. Pokazujemo da modeli state-of-the-art QA ne ispunjavaju dobro na izazovnim dugačkim kontekstima i razumnim zahtjevima koje postavljaju komplet podataka. Posebno, transformacijski modeli u stanju umjetnosti ostvaruju F1 rezultate samo 39,0. Pokazujemo kako ove sintetičke podatke prilagođavaju strukturirane znanje prirodnim tekstom i model pomoći introspekcijom pri pristupanju kompleksnog razumijevanja teksta.', 'cs': 'Nedávné referenční hodnoty pro zodpovězení otázek a strojové čtení často snižují úkol na určení rozpětí v určité textové pasáži, která odpovídá na danou otázku. Obvykle tyto systémy nejsou požadovány, aby skutečně porozuměly textu na hlubší úrovni, což umožňuje složitější uvažování o obsažených informacích. Představujeme novou datovou sadu BiQuAD, která vyžaduje hlubší porozumění, aby bylo možné odpovědět na otázky extraktivním i deduktivním způsobem. Datová sada se skládá z textů s uzavřenou doménou 4,190 a celkem z párů otázek-odpověď 99,149. Texty jsou synteticky generované fotbalové zprávy, které verbalizují hlavní události každého zápasu. Všechny texty jsou doprovázeny strukturovaným programem Datalog, který představuje (logický) model jeho informací. Ukazujeme, že nejmodernější QA modely nefungují dobře v náročných dlouhodobých kontextech a požadavcích na uvažování, které datová sada klade. Zejména moderní modely založené na transformátorech dosahují F1 skóre pouze 39,0. Ukážeme, jak tyto syntetické datové sady sladí strukturované znalosti s přirozeným textem a pomáhají modelové introspekci při přístupu k komplexnímu porozumění textu.', 'et': 'Hiljutised küsimustele vastamise ja masinlugemise võrdlusnäitajad vähendavad sageli ülesande määratleda ulatused teatud tekstilõigus, mis vastab antud küsimusele. Tavaliselt ei pea need süsteemid tegelikult teksti mõistma sügavamal tasandil, mis võimaldab sisalduva teabe keerulisemat arutlust. Tutvustame uut andmekogumit nimega BiQuAD, mis nõuab sügavamat arusaamist, et vastata küsimustele nii ekstraktiivselt kui ka deduktiivselt. Andmekogum koosneb 4190 suletud domeenist tekstist ja kokku 99 149 küsimuse-vastuse paarist. Tekstid on sünteetiliselt genereeritud jalgpallimängude aruanded, mis sõnastavad iga mängu põhisündmused. Kõikidele tekstidele on lisatud struktureeritud Datalogi programm, mis kujutab endast (loogilist) informatsiooni mudelit. Näitame, et tipptasemel kvaliteedi tagamise mudelid ei toimi hästi andmekogumi keerulistes pikakujulistes kontekstides ja arutlusnõuetes. Eelkõige saavutavad trafopõhised kaasaegsed mudelid F1-skoorid ainult 39,0. Näitame, kuidas need sünteetilised andmekogumid ühitavad struktureeritud teadmised loodusliku tekstiga ja aitavad mudeli introspektsiooni lähenemisel keerulisele tekstimõistmisele.', 'fi': 'Viimeaikaiset kysymyksenvalvonnan ja konelukemisen vertailuarvot vähentävät usein tehtävän tiettyyn kysymykseen vastanneeseen tekstikappaleeseen sisältyvien alueiden määrittämiseen. Tyypillisesti näiden järjestelmien ei tarvitse ymmärtää tekstiä syvemmällä tasolla, joka mahdollistaa monimutkaisemman päättelyn sisällöstä. Esittelemme uuden tietokokonaisuuden nimeltä BiQuAD, joka vaatii syvempää ymmärrystä vastatakseen kysymyksiin sekä ekstraktiivisesti että deduktiivisesti. Aineisto koostuu 4 190 suljetusta tekstistä ja yhteensä 99 149 kysymys-vastausparista. Tekstit ovat synteettisesti luotuja jalkapallo-otteluraportteja, jotka verbalisoivat kunkin ottelun päätapahtumat. Kaikkiin teksteihin liittyy jäsennelty Datalog-ohjelma, joka edustaa (loogista) mallia sen tiedoista. Osoitamme, että uusimmat laadunvarmistusmallit eivät toimi hyvin aineiston asettamissa haastavissa pitkän muodon konteksteissa ja päättelyvaatimuksissa. Muuntajapohjaiset huippumallit saavuttavat F1-pisteet vain 39,0. Esittelemme, miten nämä synteettiset aineistot yhdistävät strukturoidun tiedon luonnolliseen tekstiin ja auttavat mallin introspektiota lähestyttäessä monimutkaista tekstin ymmärtämistä.', 'jv': 'Game Tipik, sistem iki ora bisa dianggap kanggo kuwi nggunakake teks ning titik dhéwé sing apik. Sistem iki dadi sing bisa dianggap luwih apik, ning informasi sing nduwe. Awak dhéwé nggunakake data set sing dibutuhke BiCED sing nyaaké wisasara luwih dumadhi kanggo ngono cebagian sing ditambah dumadhi layang lan tambah modus The dataset compr of 4,190 opened-domain texts and a total of Nine, echoH e l l o space w o r l d periodHelloworldHello world politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé ngolesi model state-of-the-arts structural navigation Awak dhéwé éntuk sistem sing dikarepaké dataset sing nggawe gerakan luwih nggambar kelangan anyar tentang kanggo teks lan bantuan modèl', 'ha': "QUnicodeControlCharacterMenu A kan da'a, ba za a buƙata wannan na'ura ba dõmin a fahimta matsayin a kan wani daraja mafi ƙaranci, wanda ya yarda wa masu saka masu sauya kan maɓallin da aka ƙunsa. Mu ƙara wani tsari na zaluman da ake kiran BiQuAD, yana da amfani da tsari mafi ƙaranci dõmin su karɓa wa masu tambayar su cikin shirin tafiyar da baka. @ info: whatsthis @ info: whatsthis Duk matsayi na haɗi da wata shirin Datalog da aka samar da shi yana mai ƙayyade wani misalin (logical) da maɓallinsa. Tuna nũna cewa misalin-halin-kwanan QA bã su tafiyar da mazaɓa mai kyau a kan matsayin mutane da aka danne da shi. A cikin ƙayyade, jujjuya masu motsi na-halin-sanar da aka samar da F1-score kawai 39.0. Tuna nũna jinin da waɗannan danne-na-synthetic ke samar da ilmi na bakin rubutu da misalin misãlai na taimako idan yana kusa ya samu fahimta matacce.", 'sk': 'Nedavna merila za odgovarjanje na vprašanja in strojno branje pogosto zmanjšajo opravilo na določitev razponov znotraj določenega besedilnega odlomka, ki odgovarja na dano vprašanje. Običajno teh sistemov ni treba dejansko razumeti besedila na globljem nivoju, ki omogoča bolj kompleksno razumevanje vsebovanih informacij. Predstavljamo nov nabor podatkov z imenom BiQuAD, ki zahteva globlje razumevanje za odgovore na vprašanja tako ekstraktivno kot deduktivno. Zbirka podatkov je sestavljena iz 4.190 zaprtih domenskih besedil in skupaj 99.149 parov vprašanj-odgovorov. Besedila so sintetično ustvarjena poročila o nogometnih tekmah, ki dobesedno izražajo glavne dogodke vsake tekme. Vsa besedila spremlja strukturiran program Datalog, ki predstavlja (logični) model njegovih informacij. Pokazali smo, da najsodobnejši modeli kakovosti ne delujejo dobro v zahtevnih kontekstih dolgih oblik in zahtevah glede razmišljanja, ki jih postavlja nabor podatkov. Zlasti najsodobnejši modeli na podlagi transformatorjev dosegajo rezultate F1 le 39,0. Prikazujemo, kako ti sintetični nabori podatkov uskladijo strukturirano znanje z naravnim besedilom in pomagajo introspekciji modela pri pristopu k kompleksnemu razumevanju besedila.', 'bo': 'ཉེ་ཆར་ཡོད་པའི་དྲི་ཚིག སྤྱིར་བཏང་ནུས་མ་ལག་འདི་དག་གིས་ཡིག་གེ་ཁྱབ་པར་ཁ་ཤས་ཀྱི་གནས་རིམ ང་ཚོས་BiQuAD(BiQuAD)མི་སྒྲིག་གྱི་གནད་སྡུད་གསར་བ་ཞིག་གསལ་བཤད་བྱེད་དགོས་པའི་དོན་དག་གི་ལྟ་བུའི་རྐྱེན་སྟངས་གསལ་བ་ཞིག་ས སྒྲིག་ཆ་འཕྲིན་ཡིག ཡི་གེ All texts are accompanied by a structured Datalog program that represents a (logical) model of its information. ང་ཚོས་གནས་སྟངས་གནས་སྟངས་དང་འཆར་བཀོད་པའི་ཐབས་ལམ་གྱི་གནས་སྟངས་དེ་ལས་གནད་དོན་མེད་པའི་དབྱིབས་ཡུལ་རིམ དམིགས་བསལ་ནི། བཟོ་བཅོས་བྱེད་མཁན་གྱི་གནས་སྟངས་དང་རང་ཉིད་ཀྱི་ཐབས་ལམ་ལུགས་ཡོད་པའི་སྣང་བའི་ཚད་ལྡན་39.0་ལས་ཡོད། We demonstrate how these synthetic datasets align structured knowledge with natural text and help model introspection when approaching complex text understanding.', 'he': 'עניין לשאלות האחרונות וקריאה מכונות נקודות רמזים לעתים קרובות להפחית את המשימה לאחד מהנקודות מגוון בתוך מעבר טקסט מסוים שמענה על השאלה הנתונה. בדרך כלל, המערכות האלה לא דורשות להבין את הטקסט ברמה עמוקה יותר שמאפשר להסבירה מורכבת יותר על המידע שנמצא. We introduce a new dataset called BiQuAD that requires deeper comprehension in order to answer questions in both extractive and deductive fashion.  קבוצת המידע מורכבת מ-4,190 טקסטים בתחום סגור וכל 99,149 זוגות תשובות לשאלות. הטקסטים מיוצרים באופן סינטטי דיווחים על משחקי כדורגל שמפתחים את האירועים הראשיים של כל משחק. כל הטקסטים מולווים בתוכנית Datalog מבוססת שמייצגת מודל (הגיוני) של המידע שלה. אנחנו מראים שדוגמני QA המאוחרים לא מצליחים להצליח היטב על הקשר האתגר בצורה ארוכה והדרישות ההיגיון שנוצרו על ידי קבוצת המידע. במיוחד, דוגמנים המבוססים על המעבר מצוינים להשיג נקודות F1 של 39.0 בלבד. אנחנו מראים כיצד קבוצת נתונים סינטטיים אלה מתאימות ידע מובנה עם טקסט טבעי ומודל עזרה תוספת כשמתקרבים להבנה טקסטית מורכבת.'}
{'en': 'Evaluating Universal Dependency Parser Recovery of Predicate Argument Structure via CompChain Analysis', 'fr': "Évaluation de la récupération par analyseur de dépendance universel de la structure d'arguments de prédicat via l'analyse CompChain", 'ar': 'تقييم الاسترداد المحلل اللغوي العالمي لبنية الحجة الأصلية عبر تحليل CompChain', 'pt': 'Avaliando a recuperação do analisador de dependência universal da estrutura do argumento predicado por meio da análise CompChain', 'es': 'Evaluación de la recuperación del analizador de dependencias universal de la estructura de argumentos de predicado mediante el análisis de Comp', 'zh': '因 CompChain 析评估谓词参数结构通用赖解析器复', 'ja': 'CompChain Analysisを介した述語引数構造の普遍的な依存関係の解析回復の評価', 'hi': 'यूनिवर्सल निर्भरता पार्सर CompChain विश्लेषण के माध्यम से विधेय तर्क संरचना की वसूली का मूल्यांकन', 'ru': 'Оценка восстановления универсального парсера зависимостей предикатной структуры аргументов с помощью анализа CompChain', 'ga': 'Meastóireacht a dhéanamh ar Parsálaí Spleáchais Uilíoch Aisghabháil Struchtúr Argóintí Réamhthuartha trí Anailís CompChain', 'hu': 'Az univerzális függőség-elemző értékelése Predicate argumentum struktúra helyreállítása CompChain Analysis segítségével', 'el': 'Αξιολόγηση της καθολικής ανάλυσης εξάρτησης ανάκτηση της προκαθορισμένης δομής επιχειρημάτων μέσω ανάλυσης σύνθετης αλυσίδας', 'it': "Valutazione Universal Dependency Parser Recupero della struttura dell'argomento Predicate tramite CompChain Analysis", 'ka': 'უნივერსალური დამხოლობულობის პერიზერის განახლება პრედიკომენტის სტრუქტურის განახლება CompChain ანალიზაციით', 'kk': 'CompChain Analysis арқылы әлемдік тәуелсіздік талдағыш аргументтің құрылымын қайталау', 'lt': 'Universalaus priklausomybės analizatoriaus išankstinės argumentų struktūros atkūrimo vertinimas atliekant kompleksinės grandinės analizę', 'mk': 'Оценувањето на универзалниот анализиран апаратор за зависност на предикатната аргументна структура преку комплајн анализа', 'ms': 'Mengevaluasi Penyuarat Dependensi Universal Recovery of Predicate Argument Structure via CompChain Analysis', 'ml': 'പ്രിഡിക്കേറ്റ് ആര്\u200dഗുമെന്റ് സ്ട്രാക്ട്രൂക്ട്രൂക്ടിക്കേറ്റ് സംവീകരിക്കുന്നതിനുള്ള പ്രധാനപ്പെട്', 'mn': 'CompChain Analysis аргаар дэлхийн хамааралтай хамааралтай Parser Recovery of Predicate Argument Structure', 'no': 'Evaluerer universell avhengighetstolkar gjenoppretting av predikate argumentstruktur via CompChain Analysis', 'mt': 'Evaluating Universal Dependency Parser Recovery of Predicate Argument Structure via CompChain Analysis', 'sr': 'Оценивање универсалне зависимости родителе вратења предицитне аргументских структуре путем анализа компцејна анализа', 'si': 'CompChain විශ්ලේෂණය විධානයෙන් විශේෂයෙන් විශ්වාසයෙන් ජාතික විශේෂ විශ්ලේෂණය සඳහා ප්\u200dරධාන', 'so': 'Qiimeynta baaritaanka baaritaanka ka baaraandegista sharciga ee jaamacadda via CompChain Analysis', 'pl': 'Ocena uniwersalnego parsera zależności Odzyskiwanie predykowanej struktury argumentów za pomocą analizy CompChain', 'ro': 'Evaluarea parserului universal de dependenţă recuperarea structurii argumentelor predicate prin analiza CompChain', 'ta': 'Evaluating Universal Dependency Parser Recovery of Predicate Argument Structure via CompChain Analysis', 'ur': 'CompChain Analysis (CompChain Analysis) کے ذریعے ارومین اعتباری پارسر کی ارزش کرنا', 'sv': 'Utvärdering av Universal Dependency Parser Återvinning av Predicate Argumentstruktur via CompChain Analysis', 'uz': 'Name', 'vi': 'Đánh giá sự phụ thuộc chung cực kỳ Phục hồi cấu trúc biện hộ sẵn sàng thông qua Kết cấu phân tích', 'hr': 'Procjenjivanje univerzalne zavisnosti roditelja povratka strukture predrasude Argumenta putem analize CompChain', 'nl': 'Evaluatie van Universal Dependency Parser Recovery van Predicate Argument Structure via CompChain Analysis', 'bg': 'Оценка на възстановяването на структурата на аргументите чрез анализ на компактната верига', 'de': 'Bewertung der Universal Dependency Parser Wiederherstellung prädikierter Argumentstruktur mittels CompChain Analysis', 'id': 'Mengevaluasi Pemproses Dependensi Universal Recovery of Predicate Argument Structure via CompChain Analysis', 'ko': 'CompChain 분석을 통해 술어 매개 변수 구조를 평가하는 유니버설 의존 해상도 복구', 'fa': 'ارزیابی پزشکی اعتمادی جهانی از ساختار ارزیابی پیش\u200cبینی از طریق تحلیل CompChain', 'da': 'Evaluering af Universal Dependency Parser Gendannelse af Predicate Argument Structure via CompChain Analyse', 'af': 'Assebliseer Universele Afhanklikheid Ontvaring van Predikteer Argumentstruktuur deur CompChain Analysis', 'sq': 'Duke vlerësuar ripërtëritjen e analizuesit universal të varësisë të strukturës së argumentit të parashikuar nëpërmjet analizës së CompChain', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'sw': 'Kupima Mradi wa Uhuru wa Uamuzi wa Uamuzi wa Uamuzi wa Uamuzi ulimwenguni kupitia Uchambuzi wa Uchambuzi', 'az': 'CompChain Analizi vasitəsilə Universal Dependency Parser Recovery of Predicate Argument Structure', 'bs': 'Procjenjivanje univerzalne zavisnosti roditelja povratka strukture predikata argumenta preko analize CompChain', 'tr': 'Uniwersal Baýumlyk Aýratynyň Taýýarlanmasy Öňe Baglanyş Argument struktury Çarpmasy Aralygy Görkezilýär', 'ca': 'Evaluation Universal Dependence Parser Recovery of Predicate Argument Structure via CompChain Analysis', 'et': 'Hinnatakse universaalset sõltuvuse parserit Predicate Argumenti struktuuri taastamine CompChain analüüsi abil', 'hy': 'Համաշխարհային կախվածության վերարտադրողի վերականգնումը նախատեսված բանավեճի կառուցվածքի միջոցով', 'fi': 'Universal Dependency Parser Recovery of Predicate Argument Structure by CompChain Analysis', 'bn': 'কম্পিচেইন বিশ্লেষণের মাধ্যমে বিশ্ববিদ্যালয়ের মাধ্যমে বিশ্ববিদ্যালয়ের মূল্যায়ন করা হচ্ছে', 'cs': 'Vyhodnocení Universal Dependency Parser Recovery predikátní struktury argumentů pomocí CompChain analýzy', 'jv': 'Language', 'ha': 'KCharselect unicode block name', 'sk': 'Vrednotenje univerzalnega razčlenjevalnika odvisnosti Obnovitev strukture predhodnih argumentov z analizo kompaktnih verig', 'bo': 'Evaluating Universal Dependency Parser Recovery of Predicate Argument Structure via CompChain Analysis', 'he': 'הערכה של מחקר תלויות יוניברסלי של מבנה התווכחות מתוכנן באמצעות ניתוח Compchain'}
{'en': 'Accurate recovery of predicate-argument structure from a Universal Dependency (UD) parse is central to downstream tasks such as extraction of semantic roles or event representations. This study introduces compchains, a categorization of the hierarchy of predicate dependency relations present within a UD parse. Accuracy of compchain classification serves as a proxy for measuring accurate recovery of predicate-argument structure from sentences with embedding. We analyzed the distribution of compchains in three UD English treebanks, EWT, GUM and LinES, revealing that these treebanks are sparse with respect to sentences with predicate-argument structure that includes predicate-argument embedding. We evaluated the CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) models as compchain classifiers for the EWT, GUMS and LinES UD treebanks. Our results indicate that these three baseline models exhibit poorer performance on sentences with predicate-argument structure with more than one level of embedding ; we used compchains to characterize the errors made by these parsers and present examples of erroneous parses produced by the parser that were identified using compchains. We also analyzed the distribution of compchains in 58 non-English UD treebanks and then used compchains to evaluate the CoNLL’18 Shared Task baseline model for each of these treebanks. Our analysis shows that performance with respect to compchain classification is only weakly correlated with the official evaluation metrics (LAS, MLAS and BLEX). We identify gaps in the distribution of compchains in several of the UD treebanks, thus providing a roadmap for how these treebanks may be supplemented.', 'ar': "يعد الاسترداد الدقيق لهيكل الوسيطة الأصلية من تحليل التبعية العالمية (UD) أمرًا أساسيًا للمهام النهائية مثل استخراج الأدوار الدلالية أو تمثيلات الأحداث. تقدم هذه الدراسة compchains ، وهو تصنيف للتسلسل الهرمي لعلاقات التبعية الأصلية الموجودة داخل تحليل UD. تعمل دقة تصنيف compchain كبديل لقياس الاسترداد الدقيق لهيكل الحجة الأصلية من الجمل مع التضمين. قمنا بتحليل توزيع السلاسل في ثلاثة بنوك شجرية إنجليزية UD ، EWT ، GUM و LinES ، وكشفنا أن بنوك الأشجار هذه متفرقة فيما يتعلق بالجمل ذات بنية الحجة الأصلية التي تتضمن تضمين الحجج الأصلية. قمنا بتقييم نماذج خط الأساس UDPipe (v1.2) للمهام المشتركة CoNLL 2018 كمصنفات compchain لبنوك الشجرة EWT و GUMS و LinES UD. تشير نتائجنا إلى أن هذه النماذج الأساسية الثلاثة تظهر أداءً ضعيفًا في الجمل ذات بنية الحجة الأصلية مع أكثر من مستوى واحد من التضمين ؛ استخدمنا compchains لتوصيف الأخطاء التي قام بها هؤلاء المحللين وتقديم أمثلة للتحليلات الخاطئة التي تم إنتاجها بواسطة المحلل اللغوي والتي تم تحديدها باستخدام compchains. قمنا أيضًا بتحليل توزيع المجموعات في 58 بنكًا شجريًا غير إنجليزي UD ثم استخدمنا compchains لتقييم نموذج خط الأساس للمهمة المشتركة CoNLL'18 لكل من هذه البنوك الشجرية. يوضح تحليلنا أن الأداء فيما يتعلق بتصنيف compchain يرتبط ارتباطًا ضعيفًا فقط بـ\nمقاييس التقييم الرسمية (LAS و MLAS و BLEX). نحدد الفجوات في توزيع السلاسل في العديد من ضفاف الأشجار UD ، وبالتالي نقدم خارطة طريق لكيفية تكملة بنوك الأشجار هذه. نختتم بمناقشة كيفية توفير الكتيبات لمنظور جديد حول تباين بيانات التدريب لمحللي UD ، فضلاً عن دقة تحليلات UD الناتجة.", 'fr': "La récupération précise de la structure prédicat-argument à partir d'une analyse de dépendance universelle (UD) est essentielle pour les tâches en aval, telles que l'extraction de rôles sémantiques ou de représentations d'événements. Cette étude présente les compchains, une catégorisation de la hiérarchie des relations de dépendance des prédicats présentes dans une analyse UD. La précision de la classification compchain sert de proxy pour mesurer la récupération précise de la structure prédicat-argument à partir de phrases incorporées. Nous avons analysé la distribution des chaînes de compilation dans trois banques d'arbres anglais UD, EWT, GUM et LINes, révélant que ces banques d'arbres sont rares en ce qui concerne les phrases avec une structure prédicate-argument qui inclut l'inclusion d'arguments prédicaux. Nous avons évalué les modèles de base (analyse de dépendance) ConLL 2018 Shared Task UDPipe (v1.2) en tant que classificateurs compchain pour les banques d'arbres EWT, GUMS et LinES UD. Nos résultats indiquent que ces trois modèles de base présentent de moins bonnes performances sur des phrases avec une structure prédicat-argument avec plus d'un niveau d'intégration\xa0; nous avons utilisé des compchains pour caractériser les erreurs commises par ces analyseurs et présenter des exemples d'analyses erronées produites par l'analyseur qui ont été identifiés à l'aide de compchains. Nous avons également analysé la distribution des compchains dans 58 banques d'arbres UD non anglaises, puis nous avons utilisé des compchains pour évaluer le modèle de référence Conll'18 Shared Task pour chacune de ces banques d'arbres. Notre analyse montre que les performances relatives à la classification compchain ne sont que faiblement corrélées avec la\nmesures d'évaluation officielles (LAS, MLAS et BLEX). Nous identifions les lacunes dans la distribution des chaînes de compchains dans plusieurs des banques d'arbres de l'UD, fournissant ainsi une feuille de route sur la façon dont ces banques d'arbres peuvent être complétées. Nous concluons en discutant de la façon dont les compchains fournissent une nouvelle perspective sur la rareté des données d'entraînement pour les analyseurs UD, ainsi que sur la précision des analyses UD résultantes.", 'es': "La recuperación precisa de la estructura de predicado-argumento de un análisis de Dependencia Universal (UD) es fundamental para las tareas posteriores, como la extracción de roles semánticos o representaciones de eventos. Este estudio presenta compchains, una categorización de la jerarquía de las relaciones de dependencia de predicados presentes dentro de un análisis UD. La precisión de la clasificación de compchain sirve como un indicador para medir la recuperación precisa de la estructura del argumento predicado de las oraciones con incrustación. Analizamos la distribución de compchains en tres bancos de árboles en inglés UD, EWT, GUM y LINes, revelando que estos bancos de árboles son escasos con respecto a oraciones con estructura de predicado-argumento que incluye incrustación de predicado-argumento. Evaluamos los modelos de línea base (análisis de dependencias) de la tarea compartida UDPipe (v1.2) de CoNll 2018 como clasificadores compchain para los bancos de árboles EWT, GUMS y LIneS UD. Nuestros resultados indican que estos tres modelos de referencia muestran un rendimiento más pobre en oraciones con estructura de predicado-argumento con más de un nivel de incrustación; utilizamos compchains para caracterizar los errores cometidos por estos analizadores y presentamos ejemplos de análisis erróneos producidos por el analizador que eran identificado mediante compchains. También analizamos la distribución de compchains en 58 bancos de árboles de UD no ingleses y luego utilizamos compchains para evaluar el modelo de línea base de tareas compartidas de Conll'18 para cada uno de estos bancos de árboles. Nuestro análisis muestra que el rendimiento con respecto a la clasificación de la compchain solo está débilmente correlacionado con la\nmétricas de evaluación oficiales (LAS, MLAS y BLEX). Identificamos brechas en la distribución de compchains en varios de los bancos de árboles de la UD, proporcionando así una hoja de ruta sobre cómo se pueden complementar estos bancos de árboles. Concluimos discutiendo cómo las compchains proporcionan una nueva perspectiva sobre la escasez de datos de entrenamiento para los analizadores UD, así como la precisión de los análisis UD resultantes.", 'pt': "A recuperação precisa da estrutura predicado-argumento de uma análise de Dependência Universal (UD) é fundamental para tarefas de downstream, como extração de funções semânticas ou representações de eventos. Este estudo apresenta compchains, uma categorização da hierarquia de relações de dependência de predicado presentes em uma análise UD. A precisão da classificação do compchain serve como um proxy para medir a recuperação precisa da estrutura predicado-argumento de sentenças com incorporação. Analisamos a distribuição de compchains em três treebanks da UD English, EWT, GUM e Lines, revelando que esses treebanks são esparsos em relação a sentenças com estrutura predicado-argumento que inclui embutimento predicado-argumento. Avaliamos os modelos de linha de base (análise de dependência) do CoNLL 2018 Shared Task UDPipe (v1.2) como classificadores de cadeia de compilação para os treebanks EWT, GUMS e LinES UD. Nossos resultados indicam que esses três modelos de linha de base apresentam desempenho inferior em sentenças com estrutura predicado-argumento com mais de um nível de incorporação; usamos compchains para caracterizar os erros cometidos por esses analisadores e apresentamos exemplos de análises errôneas produzidas pelo analisador que foram identificadas usando compchains. Também analisamos a distribuição de compchains em 58 treebanks UD não ingleses e, em seguida, usamos compchains para avaliar o modelo de linha de base CoNLL'18 Shared Task para cada um desses treebanks. Nossa análise mostra que o desempenho em relação à classificação da cadeia de compchain é apenas fracamente correlacionado com a\nmétricas oficiais de avaliação (LAS, MLAS e BLEX). Identificamos lacunas na distribuição de compchains em vários bancos de árvores UD, fornecendo assim um roteiro de como esses bancos de árvores podem ser suplementados. Concluímos discutindo como compchains fornecem uma nova perspectiva sobre a escassez de dados de treinamento para analisadores UD, bem como a precisão das análises UD resultantes.", 'ja': "ユニバーサル依存性（ UD ）パースからの述語引数構造の正確な回復は、セマンティックロールまたはイベント表現の抽出などのダウンストリームタスクの中心です。 この研究では、UD構文解析内に存在する述語依存関係の階層の分類であるコンピューティングチェーンを紹介します。 コンプチェイン分類の精度は、埋め込みを伴う文から述語-引数構造の正確な回復を測定するためのプロキシとして機能します。 我々は、UD英語のツリーバンク、EWT、GUM、LinESの3つのツリーバンクにおけるコンプチェインの分布を分析し、これらのツリーバンクは、述語論証埋め込みを含む述語論証構造を持つ文に関してまばらであることを明らかにした。 CoNLL 2018 Shared Task UDPipe (v1.2)ベースライン（依存性解析）モデルを、EWT、GUMS、LinES UDツリーバンクのコンプチェーン分類子として評価しました。 私たちの結果は、これらの3つのベースラインモデルは、複数のレベルの埋め込みを持つ述語論証構造を持つ文章では、より悪いパフォーマンスを示していることを示しています。私たちは、これらの構文解析器によって行われたエラーを特徴付けるためにコンプチェインを使用し、コンプチェインを使用して識別された構文解析器によって生成された誤った構文解析の例を提示しました。 また、58の非英語UDツリーバンクにおけるコンプチェインの分布を分析し、その後、これらのツリーバンクのCoNLL '18共有タスクのベースラインモデルを評価するためにコンプチェインを使用しました。 当社の分析によると、コンプチェインの分類に関するパフォーマンスは、\n公式の評価指標（ LAS、MLAおよびBLEX ）。私たちは、いくつかのUDツリーバンクにおけるコンプチェーンの配分のギャップを特定し、これらのツリーバンクがどのように補完されるかのロードマップを提供します。最後に、コンプチェインがUDパーサーのトレーニングデータの希少性と、結果として生じるUDパーサーの精度について、どのように新しい視点を提供するかについて説明します。", 'zh': '自通用倚 (UD) 解析中准复谓词-参数结构为下流之任(如取语义角色事示)心。 本论复合,此 UD 解析之所谓词恃层次结构之类也。 复合之类准确性可为摄,以度嵌句之确复谓词参数结构。 析三UD英语树库(EWT,GUM与LinES)中复合之分布,揭此树库相对有谓词参数结构之句(谓词参数嵌)疏也。 估 CoNLL 2018 共事 UDPipe (v1.2) 基线(赖解析)模形,以为 EWT、GUMS 、 LinES UD 树库复合之器。 吾之的结果表明,此三基线者,多嵌级之谓词 - 参数结构,差也; 以复合链来表此解析器所犯之过,而给解析器生用复合之解析示例。 论58非英语UD树库中复合之分,然后以复合链来评树库之CoNLL18共其任基线。 吾之分析表明,于复合之类也\n官方评估指标(LAS、MLAS 和 BLEX)。 定数UD树库中复合之差,以补此树库之路线图。 最后,将议复合为 UD 解析器练数疏性及生成 UD 解析准确性供新视角。', 'ga': "Is cuid lárnach de thascanna iartheachtacha é struchtúr na hargóintí réamhaithrise a ghnóthú go cruinn ó pharsáil Spleáchais Uilíoch (UD) mar asbhaint róil shéimeantacha nó léirithe imeachtaí. Tugann an staidéar seo isteach compchains, catagóiriú ar an ordlathas de chaidrimh spleáchais tuar i láthair laistigh de pharsáil UD. Feidhmíonn cruinneas an aicmithe compchain mar sheachvótálaí chun aisghabháil cruinn a dhéanamh ar struchtúr argóinte preideacáide ó abairtí le neadú. Rinneamar anailís ar dháileadh na gcomhshlabhra i dtrí chrann crann Béarla de chuid na Ríochta Aontaithe, EWT, GUM agus Línte, ag tabhairt le fios go bhfuil na bainc chrainn seo gann maidir le habairtí a bhfuil struchtúr argóinte réamh-mheastacháin acu a chuimsíonn neadú réamh-argóint. Rinneamar measúnú ar mhúnlaí bonnlíne (parsáil spleáchais) Tasc Comhroinnte CoNLL 2018 UDPipe (v1.2) mar aicmitheoirí compchain do bhainc chrainn EWT, GUMS agus LineS UD. Léiríonn ár dtorthaí go léiríonn na trí mhúnla bonnlíne seo feidhmíocht níos measa ar phianbhreitheanna le struchtúr argóinte réamh-mheastacháin le níos mó ná leibhéal amháin neadaithe; d’úsáideamar compchain chun na hearráidí a rinne na parsálaithe seo a thréithriú agus samplaí a chur i láthair de pharsálacha earráideacha a tháirg an parsálaí a aithníodh ag baint úsáide as compchains. Rinneamar anailís freisin ar dháileadh compchain i 58 banc crann UD neamh-Bhéarla agus ansin d'úsáideamar compchain chun múnla bonnlíne Tasc Comhroinnte CoNLL'18 a mheas do gach ceann de na bainc crann seo. Léiríonn ár n-anailís nach bhfuil comhghaolú lag idir an fheidhmíocht maidir le haicmiú compchain agus an\nméadracht mheastóireachta oifigiúil (LAS, MLAS agus BLEX). Aithnímid bearnaí i ndáileadh na gcomhshlabhraí i roinnt de na bainc chrainn UD, rud a sholáthraímid treochlár don chaoi ar féidir na bainc chrainn seo a fhorlíonadh. Críochnóimid trí phlé a dhéanamh ar an gcaoi a dtugann compchains peirspictíocht nua ar ghanntanas na sonraí oiliúna do pharsálaithe UD, chomh maith le cruinneas na bparsanna UD a thagann as.", 'ru': "Точное восстановление структуры предикат-аргумент из синтаксического анализа универсальной зависимости (UD) является центральным для последующих задач, таких как извлечение семантических ролей или представлений событий. Данное исследование вводит компчейны, категоризацию иерархии предикатных зависимостей, присутствующих в UD-синтаксическом анализе. Точность компчейн-классификации служит косвенным показателем для измерения точного восстановления структуры предикат-аргумент из предложений с вложением. Мы проанализировали распределение комплайнов в трех английских древостоях UD, EWT, GUM и LinES, показав, что эти древовидные цепи редки по отношению к предложениям со структурой предикат-аргумент, которая включает в себя вложение предикат-аргумент. Мы оценили базовые модели CoNLL 2018 Shared Task UDPipe (v1.2) (синтаксический анализ зависимостей) как компактные классификаторы для EWT, GUMS и LinES UD treebanks. Наши результаты показывают, что эти три базовые модели демонстрируют худшую производительность по предложениям со структурой предикат-аргумент с более чем одним уровнем встраивания; мы использовали compchains для характеристики ошибок, допущенных этими парсерами, и представили примеры ошибочных парсеров, произведенных парсером, которые были идентифицированы с помощью compchains. Мы также проанализировали распределение компчейнов в 58 неанглоязычных банках деревьев UD, а затем использовали компчейны для оценки базовой моделиCoNLL '18 Shared Task для каждого из этих блоков деревьев. Наш анализ показывает, что производительность в отношении классификации компаний лишь слабо коррелирует с\nофициальные показатели оценки (LAS, MLAS и BLEX). Мы выявляем пробелы в распределении комплайнов в нескольких банках деревьев UD, таким образом предоставляя дорожную карту того, как эти банки деревьев могут быть дополнены. В заключение мы обсуждаем, как цепочки обеспечивают новую перспективу относительно редкости данных обучения для парсеров UD, а также точность получаемых UD-парсинга.", 'hi': "यूनिवर्सल डिपेंडेंसी (UD) पार्स से विधेय-तर्क संरचना की सटीक वसूली डाउनस्ट्रीम कार्यों के लिए केंद्रीय है जैसे कि शब्दार्थ भूमिकाओं या घटना प्रतिनिधित्व का निष्कर्षण। यह अध्ययन कॉम्पचेन का परिचय देता है, जो एक यूडी पार्स के भीतर मौजूद विधेय निर्भरता संबंधों के पदानुक्रम का वर्गीकरण है। Compchain वर्गीकरण की सटीकता एम्बेडिंग के साथ वाक्यों से विधेय-तर्क संरचना की सटीक वसूली को मापने के लिए एक प्रॉक्सी के रूप में कार्य करती है। हमने तीन UD अंग्रेजी ट्रीबैंक, EWT, GUM और LinES में compchains के वितरण का विश्लेषण किया, यह खुलासा करते हुए कि ये treebanks विधेय-तर्क संरचना के साथ वाक्यों के संबंध में विरल हैं जिसमें विधेय-तर्क एम्बेडिंग शामिल है। हमने CoNLL 2018 साझा कार्य UDPipe (v1.2) बेसलाइन (निर्भरता पार्सिंग) मॉडल का मूल्यांकन EWT, GUMS और LinES UD treebanks के लिए compchain क्लासिफायरके रूप में किया। हमारे परिणामों से संकेत मिलता है कि ये तीन बेसलाइन मॉडल एम्बेडिंग के एक से अधिक स्तर के साथ विधेय-तर्क संरचना के साथ वाक्यों पर खराब प्रदर्शन प्रदर्शित करते हैं; हम इन पार्सर द्वारा की गई त्रुटियों को चिह्नित करने के लिए compchains का उपयोग किया और पार्सर है कि compchains का उपयोग कर की पहचान की गई थी द्वारा उत्पादित गलत पार्स के उदाहरण प्रस्तुत करते हैं. हमने 58 गैर-अंग्रेजी यूडी ट्रीबैंक में कॉम्पचेन के वितरण का भी विश्लेषण किया और फिर इन ट्रीबैंक्स में से प्रत्येक के लिए CoNLL'18 साझा कार्य बेसलाइन मॉडल का मूल्यांकन करने के लिए compchains का उपयोग किया। हमारे विश्लेषण से पता चलता है कि compchain वर्गीकरण के संबंध में प्रदर्शन केवल कमजोर रूप से सहसंबद्ध है\nआधिकारिक मूल्यांकन मैट्रिक्स (LAS, MLAS और BLEX)। हम यूडी ट्रीबैंक के कई हिस्सों में कॉम्पचेन के वितरण में अंतराल की पहचान करते हैं, इस प्रकार इन ट्रीबैंकों को पूरक करने के तरीके के लिए एक रोडमैप प्रदान करते हैं। हम इस बात पर चर्चा करके निष्कर्ष निकालते हैं कि कॉम्पचेन यूडी पार्सर्स के लिए प्रशिक्षण डेटा की स्पार्सिटी पर एक नया परिप्रेक्ष्य कैसे प्रदान करते हैं, साथ ही परिणामस्वरूप यूडी पार्स की सटीकता भी।", 'ka': "სამყარო დამხოლობა (UD) პარასტიდან წარმოადგენებული არგუმენტიური სტრუქტურის წარმოადგენება ცენტრუალურია, როგორც სემონტიური პროლის ან მოვლენების გამოსახულებების გამოყენ ეს სწავლად კომპოფეციები, სუდის პასუზაციაში არსებულია სუდიატური დაკავშირებების თერაქტიკის კატეგორიზაცია. კომპოფეციის კლასიფიკაციის წარმატება იყო პროქსი, როგორც წარმატებითი არგუმენტის სტრუქტურაციის წარმატებით გადასვლა. ჩვენ ანალიზიციეთ სამი UD ინგლისური ტრებონში, EWT, GUM და LinES-ში, რომელიც გამოჩვენებულია, რომ ეს ტრებონები არსებობენ წარმოდგენების შესახებ წარმოდგენების სტრუქტურაციას, რომელიც პრედიკატიკურ ჩვენ CoNLL 2018-ის გაყოფილი საქმე UDPipe (v1.2) მუშაობის მოდელების შესახებ, როგორც EWT, GUMS და LinES UD კლასიფიკაციებისთვის კომპოფენტის კლასიფიკაციები. ჩვენი წარმოდგენები გვაჩვენებს, რომ ეს სამი მხარეს მოდელები გამოიყენებს უფრო ცოტა გამოყენება წარმოდგენებით, რომლებიც წარმოდგენებული არგუმენტის სტრუქტ ჩვენ გამოყენეთ კომპოფეციები, რომლებიც ამ პარასერების შეცდომის შეცდომების განსაკუთრებისთვის და შეცდომა პარასერების მაგალითები, რომლებიც კომპოფეციების გამოყ ჩვენ ასევე გავაანალიზეთ კომპოფეციის გაყოფილი 58 არ ანგლისური UD საბოლოში და შემდეგ გამოყენეთ კომპოფეციები, რომლებიც CoNLL'18 გაყოფილი საბოლოო მოდელს ყველა საბოლოო საბოლოო ჩვენი ანალიზია, რომ კომპოფეციის კლასიფიკაციის შესახებ მხოლოდ ცოტა კომპოფეციის შესახებ\nუფრო მეტრიკალური განსაზღვრება (LAS, MLAS და BLEX). ჩვენ განვიცნობით კომპოფეციების გაყოფილების რამდენიმე UD კომპოფეციების განმავლობაში, როგორც ეს კომპოფეციები შეიძლება დამატება. ჩვენ გავაკეთებთ, როგორ კომპოფეციები ახალი პერსტიფიკაციის შესახებ UD პარასერებისთვის მონაცემების შესახებ, და შემდეგ UD პარასერების მართლა.", 'kk': "Жалпы Тәуелсіздік (UD) талдауынан алдын- ала аргументтің құрылымының тәртібі қалпына келтіру - семантикалық рольдерді не оқиғаларды таңдау сияқты тапсырмалардың ортасында төмендету тапсы Бұл зерттеу UD талдауындағы тәуелсіздік қатынастарының иерархиясының жинақтауын, композицияларды көрсетеді. Комплекциялау классификациясының дұрыс қалпындығын ендіру үшін прокси ретінде анықтайды. Біз үш UD ағылшын тіркесімдерінде композицияларды, EWT, GUM және LinES тіркесімдерінде тарату үшін анализ етіп, бұл жол тіркесімдері алдын- ала аргументті ендіру үшін сұлбалармен қатынасыз келеді. Біз CoNLL 2018 ортақтастырылған тапсырма UDPipe (v1.2) негізгі жол (тәуелдік талдау) үлгілерін EWT, GUMS және LinES UD бағыттарының композициялық классификаторлары ретінде анықтадық. Біздің нәтижелеріміз бұл үш негізгі үлгі үлгілер бірнеше деңгейінде аргументтің құрылымы бар сөздерге аргументтік құрылымыз керек болады дегенді көрсетеді. Біз осы талдаушылардың қателерін таңдау үшін композицияларды қолдандық және композициялармен анықталған талдаушылардың қате талдау мысалдарын таңдадық. Сонымен қатар, 58 ағылшын тілінде UD бақылау үшін композициялардың үлестірімін анализ және содан кейін CoNLL'18 ортақ тапсырмалар негізгі үлгісін бақылау үшін композицияларды қолдандық. Біздің анализиямыз композициялық классификациясына қатысты жылдамдығы тек бақытты қатысты\nресми оқу метрикалары (LAS, MLAS және BLEX). Біз композициялардың үлестірімінің бірнеше UD құрылғыларындағы кеңістіктерді анықтаймыз, сондықтан бұл құрылғылардың қалай қосылуы мүмкін екенін жол картасын көрсетеді. Біз UD талдаушыларының бақылау мәліметтерінің жаңа перспективін қалай бақылау керектігін және UD талдаушыларының дұрыстығын талдап тұрып тұрамыз.", 'el': 'Η ακριβής ανάκτηση της δομής προκαθορισμένων ορίων από μια ανάλυση καθολικής εξάρτησης (είναι κεντρική σε μεταγενέστερες εργασίες, όπως η εξαγωγή σημασιολογικών ρόλων ή αναπαραστάσεων συμβάντων. Η παρούσα μελέτη εισάγει σύνθετες αλυσίδες, μια κατηγοριοποίηση της ιεραρχίας των σχέσεων υπαρκτών εξαρτήσεων που υπάρχουν μέσα σε μια ανάλυση UD. Η ακρίβεια της ταξινόμησης συναλυσίδας χρησιμεύει ως αντιπρόσωπος για τη μέτρηση της ακριβούς ανάκτησης της δομής των υπαρκτών-ορίων από προτάσεις με ενσωμάτωση. Αναλύσαμε την κατανομή των σύνθετων αλυσίδων σε τρεις αγγλικές βάσεις δέντρων, EWT, GUM και LinES, αποκαλύπτοντας ότι αυτές οι βάσεις δέντρων είναι αραιές σε σχέση με προτάσεις με δομή υπαρκτού-ορίσματος που περιλαμβάνει ενσωμάτωση υπαρκτού-ορίσματος. Αξιολογήσαμε τα μοντέλα βάσης βάσης (ανάλυση εξαρτήσεων) ως ταξινομητές σύνθετης αλυσίδας για τις τράπεζες δέντρων EWT, GUMS και LinES UD. Τα αποτελέσματά μας δείχνουν ότι αυτά τα τρία βασικά μοντέλα παρουσιάζουν χειρότερη απόδοση σε προτάσεις με δομή υπαρκτού-επιχειρήματος με περισσότερα από ένα επίπεδα ενσωμάτωσης. Χρησιμοποιήσαμε συνθέσεις για να χαρακτηρίσουμε τα λάθη που έγιναν από αυτούς τους αναλυτές και να παρουσιάσουμε παραδείγματα λανθασμένων αναλύσεων που παράγονται από τον αναλυτή που εντοπίστηκαν χρησιμοποιώντας συνθέσεις. Αναλύσαμε επίσης την κατανομή των σύνθετων αλυσίδων σε 58 μη αγγλικές δένδρες και στη συνέχεια χρησιμοποιήσαμε σύνθετες αλυσίδες για να αξιολογήσουμε το μοντέλο βάσης κοινής εργασίας για κάθε μία από αυτές τις δένδρες. Η ανάλυσή μας δείχνει ότι η απόδοση όσον αφορά την ταξινόμηση της αλυσίδας συσχετίζεται ελάχιστα με την\nεπίσημες μετρήσεις αξιολόγησης (LAS, MLAS και BLEX). Εντοπίζουμε κενά στην κατανομή των συμπληρωμάτων σε αρκετές από τις δενδρόχθες, παρέχοντας έτσι έναν οδικό χάρτη για τον τρόπο με τον οποίο μπορούν να συμπληρωθούν αυτές οι δενδρόχθες. Ολοκληρώνοντας συζητώντας πώς οι συνθέσεις παρέχουν μια νέα προοπτική για τη σπανιότητα των δεδομένων κατάρτισης για τους αναλυτές καθώς και την ακρίβεια των αναλύσεων που προκύπτουν.', 'it': "Il recupero accurato della struttura predicato-argomento da un'analisi UD (Universal Dependency) è centrale per attività a valle come l'estrazione di ruoli semantici o rappresentazioni di eventi. Questo studio introduce compchains, una categorizzazione della gerarchia delle relazioni di dipendenza predicate presenti all'interno di un parse UD. L'accuratezza della classificazione compchain serve da proxy per misurare il recupero accurato della struttura predicato-argomento da frasi con incorporazione. Abbiamo analizzato la distribuzione delle compchains in tre treebanks inglesi UD, EWT, GUM e LinES, rivelando che questi treebanks sono scarsi rispetto alle frasi con struttura predicato-argomento che include l'embedding predicato-argomento. Abbiamo valutato i modelli di base (analisi delle dipendenze) di CoNLL 2018 Shared Task UDPipe (v1.2) come classificatori compchain per i treebank EWT, GUMS e LinES UD. I nostri risultati indicano che questi tre modelli di base mostrano prestazioni più scarse su frasi con struttura predicato-argomento con più di un livello di incorporazione; Abbiamo usato compchains per caratterizzare gli errori commessi da questi parser e presentare esempi di pars erronei prodotti dal parser che sono stati identificati utilizzando compchains. Abbiamo anche analizzato la distribuzione di compchains in 58 treebank UD non inglesi e poi usato compchains per valutare il modello di base CoNLL'18 Shared Task di ciascuno di questi treebank. La nostra analisi mostra che la performance rispetto alla classificazione compchain è solo debolmente correlata con la\nmetriche ufficiali di valutazione (LAS, MLAS e BLEX). Identifichiamo le lacune nella distribuzione delle catene compchain in diversi dei banchi degli alberi UD, fornendo così una roadmap per come questi ultimi possono essere completati. Concludiamo discutendo come le compchains forniscono una nuova prospettiva sulla scarsità dei dati di addestramento per i parser UD, così come l'accuratezza dei pars UD risultanti.", 'hu': "A predikát-argumentum struktúra pontos helyreállítása az univerzális függőség (UD) elemezésből központi szerepet játszik az olyan downstream feladatokban, mint a szemantikai szerepek vagy eseményreprezentációk kivonása. Ez a tanulmány bemutatja a compchains-okat, a predikátus függőségi kapcsolatok hierarchiájának kategorizálását egy UD elemzésben. A compchain osztályozás pontossága proxyként szolgál a predikátus-argumentum struktúra pontos helyreállításának mérésére beágyazással. Elemeztük a kompchainok eloszlását három UD angol fákban, EWT-ben, GUM-ben és LinES-ben, feltárva, hogy ezek a fákban ritkák a predikát-argumentum struktúrájú mondatok tekintetében, amelyek magukban foglalják a predikát-argumentum beágyazást. A CoNLL 2018 Shared Task UDPipe (v1.2) alapértelmezési modelleket (függőség elemzése) az EWT, a GUMS és a LinES UD fák kompchain osztályozójaként értékeltük. Eredményeink azt mutatják, hogy ez a három alapvető modell rosszabb teljesítményt mutat olyan mondatokon, amelyek predikát-argumentum struktúrájú, több mint egy szintű beágyazással rendelkeznek; Kompchains segítségével jellemeztük az említett elemzők hibáit és bemutattuk a kompchains segítségével azonosított hibás elemzéseket. Ezenkívül elemeztük a kompchainok eloszlását 58 nem angol UD fákban, majd kompchainokat használtunk a CoNLL'18 Shared Task alapvető modelljének értékelésére mindegyik fákban. Elemzésünk azt mutatja, hogy a kompchain osztályozás teljesítménye csak gyengén korrelálódik a\nhivatalos értékelési mutatók (LAS, MLAS és BLEX). Azonosítjuk a kompchains elosztásában rejlő hiányosságokat több UD-fázisban, így útitervet készítünk arra vonatkozóan, hogyan lehet kiegészíteni ezeket a fázisokat. Végezetül megvitatjuk, hogy a kompchains hogyan nyújt új perspektívát az UD elemzők képzési adatainak ritkaságáról, valamint az eredményekből eredő UD elemzések pontosságáról.", 'ms': "Pemulihan tepat struktur argumen-predikat dari huraian Dependensi Universal (UD) adalah pusat ke tugas bawah seperti ekstraksi peranan semantik atau perwakilan peristiwa. kajian ini memperkenalkan compchains, kategorisasi hierarki hubungan dependensi predikat yang ada dalam huraian UD. Ketepatan klasifikasi compchain berkhidmat sebagai proksi untuk mengukur pemulihan tepat struktur argumen-predicate dari kalimat dengan penyembedding. Kami menganalisis distribusi kompchains dalam tiga batang pokok UD Inggeris, EWT, GUM dan LinES, mengungkapkan bahawa batang pokok ini jarang berkaitan dengan kalimat dengan struktur predicate-argumen yang termasuk penyambungan predicate-argumen. Kami menilai model dasar UDPipe Tugas Berkongsi CoNLL 2018 (v1.2) (penghuraian dependensi) sebagai klasifikasi kompchain untuk pangkalan pokok UD EWT, GUMS dan LinES. Keputusan kami menunjukkan bahawa tiga model asas ini menunjukkan prestasi yang lebih buruk pada kalimat dengan struktur argumen-predikat dengan lebih dari satu tahap penyambungan; kami menggunakan compchains untuk mengurai ralat yang dibuat oleh maklumat maklumat ini dan memperlihatkan contoh-contoh maklumat yang salah yang dibuat oleh maklumat maklumat yang dikenalpasti menggunakan compchains. Kami juga menganalisis distribusi kompchains dalam 58 batang pokok UD bukan Inggeris dan kemudian menggunakan batang untuk menilai model dasar Tugas Berkongsi CoNLL'18 untuk setiap batang pokok ini. Analisis kami menunjukkan bahawa prestasi terhadap klasifikasi compchain hanya berkorrelasi lemah dengan\nmetrik penilaian rasmi (LAS, MLAS dan BLEX). Kami mengenalpasti kekurangan dalam pengedaran komprantai di beberapa batang pokok UD, sehingga menyediakan peta laluan untuk bagaimana batang pokok ini boleh ditambah. Kami menyimpulkan dengan membincangkan bagaimana compchains menyediakan perspektif baru tentang kecepatan data latihan untuk penghurai UD, serta ketepatan hurai UD yang berasal.", 'mt': 'Accurate recovery of predicate-argument structure from a Universal Dependency (UD) parse is central to downstream tasks such as extraction of semantic roles or event representations.  Dan l-istudju jintroduċi kompchains, kategorizzazzjoni tal-ġerarkija tar-relazzjonijiet ta’ dipendenza predikata preżenti fi ħdan analiżi UD. L-akkuratezza tal-klassifikazzjoni compchain isservi bħala proxy għall-kejl tal-irkupru preċiż tal-istruttura predikata-argument minn sentenzi bl-inkorporazzjoni. Aħna analizzaw id-distribuzzjoni tal-kompchains fi tliet banek tas-siġar Ingliżi UD, EWT, GUM u LinES, u żvelajna li dawn il-banek tas-siġar huma ftit fir-rigward ta’ sentenzi bi struttura ta’ argument predikat li tinkludi inkorporazzjoni ta’ argument predikat. Ivvalutajna l-mudelli tal-linja bażi tal-UDPipe (v1.2) ta’ Kompitu Kondiviż CoNLL 2018 (dependency parsing) bħala klassifikaturi kompchain għall-banek tas-siġar EWT, GUMS u LinES UD. Ir-riżultati tagħna jindikaw li dawn it-tliet mudelli ta’ linja bażi juru prestazzjoni aktar fqira fuq sentenzi bi struttura ta’ argument predikat b’aktar minn livell wieħed ta’ inkorporazzjoni; użajna compchains biex jikkaratterizzaw l-iżbalji magħmula minn dawn il-parsers u ppreżentajna eżempji ta’ parsers żbaljati prodotti mill-parser li ġew identifikati bl-użu ta’ compchains. Analiżijna wkoll id-distribuzzjoni ta’ compchains f’58 bank tas-siġar UD mhux Ingliż u mbagħad użajna compchains biex jevalwaw il-mudell ta’ linja bażi ta’ ħidma kondiviża CoNLL’18 għal kull wieħed minn dawn il-bank tas-siġar. L-analiżi tagħna turi li l-prestazzjoni fir-rigward tal-klassifikazzjoni compchain hija biss b’mod dgħajjef korrelata mal-\nmetriċi uffiċjali ta’ evalwazzjoni (LAS, MLAS u BLEX). Aħna nidentifikaw nuqqasijiet fid-distribuzzjoni tal-kompchains f’bosta mill-banek tas-siġar tal-UD, u b’hekk nipprovdu pjan direzzjonali dwar kif dawn il-banek tas-siġar jistgħu jiġu ssupplimentati. Aħna nikkonkludu billi niddiskutu kif il-kumpchains jipprovdu perspettiva ġdida dwar l-iskarsezza tad-dejta tat-taħriġ għall-analizzaturi UD, kif ukoll il-preċiżjoni tal-analiżijiet UD li jirriżultaw.', 'lt': "Tikslis išankstinių argument ų struktūros atkūrimas iš universaliosios priklausomybės (UD) analizės yra pagrindinis ir tolesnių užduočių, pavyzdžiui, semantinių vaidmenų gavimas arba renginių atstovavimas. Šiame tyrime įdiegtos sąsajos, pagal kurias klasifikuojami išankstiniai priklausomybės santykiai UD analizėje. Komplaketinės grandinės klasifikacijos tikslumas naudojamas kaip nuoroda tiksliam išgavimui iš įterptų sakinių matuoti. We analyzed the distribution of compchains in three UD English treebanks, EWT, GUM and LinES, revealing that these treebanks are sparse with respect to sentences with predicate-argument structure that includes predicate-argument embedding.  Įvertinome CoNLL 2018 m. bendros užduoties UDPipe (v1.2) bazinius modelius (priklausomybės analizavimas), kaip EWT, GUMS ir LinES UD medžių sąrankų kompleksų klasifikatorius. Mūsų rezultatai rodo, kad šiuose trijuose pagrindiniuose modeliuose prastesnis rezultatas vertinant sakinius, turinčius sudėtingą argument ų struktūrą ir turinčius daugiau kaip vieną įterpimo lygį; we used compchains to characterize the errors made by these parsers and present examples of erroneous parses produced by the parser that were identified using compchains.  Taip pat analizavome kompgrandinių pasiskirstymą 58 ne anglų UD medžių dėžutėse ir tada panaudojome kompgrandines įvertinti CoNLL'18 bendros užduoties bazinį model į kiekvienam iš šių medžių dėžučių. Mūsų analizė rodo, kad sąsajos klasifikavimo rezultatai yra tik silpnai koreliuojami su\noficialūs vertinimo rodikliai (LAS, MLAS ir BLEX). We identify gaps in the distribution of compchains in several of the UD treebanks, thus providing a roadmap for how these treebanks may be supplemented.  Baigdami diskutuojame apie tai, kaip kompchains suteikia naują perspektyvą dėl UD analizatorių mokymo duomenų nedaug, taip pat dėl gautų UD analizatorių tikslumo.", 'mn': "Универсалд хамааралтай (UD) хуваалцааны алдартай аргументын бүтцийн шууд сэргээгдэх нь семантик дүр зураг эсвэл үйл явдлын төлөвлөлтийг гаргах төвөгтэй ажил юм. Энэ судалгаа UD хуваалцааны дотор байгаа хамааралтай хамааралтай харилцааны хэлбэрүүдийг бүрдүүлдэг. Compchain хуваалтын тодорхойлолт нь тодорхой аргументын бүтцийг өгүүлбэрээс тодорхойлохын тулд прокси болно. Бид гурван UD Англи хэлний дагуул, EWT, GUM болон LinES-д компцейнүүдийн хуваарилалтыг шинжилгээ хийсэн. Эдгээр дагуулын дагуул нь алдартай аргументын бүтцийг харуулж байгааг харуулсан. Бид 2018 оны CoNLL-ын хуваалтын Task UDPipe (v1.2) суурь шугам (dependency parsing) загварыг EWT, GUMS болон LinES UD загварын компцейны хуваалтын хуваалтын хуваалтын хуваалтын хэлбэрүүдийг үнэлгээд үзсэн. Бидний үр дүн нь эдгээр гурван суурь шугам загварууд нэгээс их хэмжээтэй аргументын бүтэц дээр илүү ядуу үйл ажиллагааг харуулж байна. Эдгээр ажиллагчид хийсэн алдаа нарийвчлахын тулд компцейнүүдийг ашиглаж, компцейнүүдийг ашиглан гаргасан алдаа алдаа ажиллах жишээ гаргасан. Бид мөн 58 Англи хэсгийг биш UD загварын хуваалцааны хуваалцааныг судалж, дараа нь CoNLL'18 хуваалцан ажлын суурь загварыг эдгээр загварын бүрт үнэлэх зорилго ашигласан. Бидний шинжилгээнд хэмжээний хэлбэртэй харьцуулах үйл ажиллагаа зөвхөн бага зэрэг холбоотой гэдгийг харуулж байна.\nалбан ёсны дүгнэлт метрик (LAS, MLAS, BLEX). Бид хэд хэдэн UD дагуулын зайн хуваарилалтын ялгааг тодорхойлдог. Иймээс эдгээр дагуулын зам газрын зураг хэрхэн нэмэгдүүлж болох вэ? Мөн бид UD ажиллаачидын сургалтын өгөгдлийг хэрхэн шинэ харагдах талаар ярилцсан юм. Мөн үр дүнтэй UD ажиллаачидын тодорхойлолт.", 'mk': "Точното обновување на структурата на предикативните аргументи од анализата на универзалната зависност (УД) е централно до понатамошни задачи, како што е извлекувањето семантични улоги или претставувањето на настаните. This study introduces compchains, a categorization of the hierarchy of predicate dependency relations present within a UD parse.  Точноста на класификацијата compchain служи како прокси за мерење на прецизното обновување на структурата predicate-argument од речениците со вградување. Ја анализиравме дистрибуцијата на комплајнови во три англиски дрвја на УД, ЕВТ, ГУМ и ЛИНЕС, откривајќи дека овие дрвја се мали во однос на речениците со структура на predicate-argument која вклучува вградување predicate-argument. Ги проценивме моделите на CoNLL 2018 поделена задача UDPipe (v1.2) во основа (анализирање зависност) како комплајн класификатори за EWT, GUMS и LinES UD дрвја. Нашите резултати укажуваат на тоа дека овие три основни модели покажуваат полоши резултати на речениците со структура на предикативни аргументи со повеќе од едно ниво на вградување; Користевме комплајни за да ги карактеризираме грешките направени од овие анализатори и да ги претставиме примерите на грешни анализатори произведени од анализаторот кои беа идентификувани користејќи комплајни. Ние, исто така, ја анализиравме дистрибуцијата на комплајнови во 58 неанглиски UD дрвја банки и потоа користевме комплајнови за да го процениме основниот модел на CoNLL'18 Shared Task за секоја од овие дрвја банки. Our analysis shows that performance with respect to compchain classification is only weakly correlated with the\nофицијални метрики за проценка (ЛАС, МЛАС и БЛЕКС). Ние ги идентификуваме празнините во дистрибуцијата на комплајнови во неколку од дрвјата на УД, со што ќе обезбедиме патоказ за тоа како овие дрвја може да бидат дополнителни. We conclude by discussing how compchains provide a new perspective on the sparsity of training data for UD parsers, as well as the accuracy of the resulting UD parses.", 'ro': "Recuperarea exactă a structurii argumentelor predicate dintr-o analiză de dependență universală (UD) este centrală pentru activitățile din aval, cum ar fi extragerea rolurilor semantice sau reprezentările evenimentelor. Acest studiu introduce compchains, o categorizare a ierarhiei relațiilor de dependență predicate prezente într-un parse UD. Precizia clasificării compchain servește ca un proxy pentru măsurarea recuperării precise a structurii predicat-argument din propoziții cu încorporare. Am analizat distribuția compchain-urilor în trei braebanks UD engleză, EWT, GUM și LinES, dezvăluind că aceste braebanks sunt rare în ceea ce privește propozițiile cu structură predicat-argument care include încorporarea predicat-argument. Am evaluat modelele CoNLL 2018 Shared Task UDPipe (v1.2) de referință (analizarea dependenței) ca clasificatoare compchain pentru treebanks EWT, GUMS și LinES UD. Rezultatele noastre indică faptul că aceste trei modele de bază prezintă performanțe mai slabe pe propoziții cu structură predicat-argument cu mai mult de un nivel de încorporare; Am folosit compchains pentru a caracteriza erorile făcute de acești parsers și prezenta exemple de parsers eronate produse de parser care au fost identificate folosind compchains. De asemenea, am analizat distribuția compchain-urilor în 58 de treebanks UD non-engleză și apoi am folosit compchains pentru a evalua modelul de bază CoNLL'18 Shared Task pentru fiecare dintre aceste treebanks. Analiza noastră arată că performanța în ceea ce privește clasificarea compchain este doar slab corelată cu\nmăsurători oficiale de evaluare (LAS, MLAS și BLEX). Identificăm lacunele în distribuția lanțurilor complantate în mai multe dintre brațele UD, oferind astfel o foaie de parcurs pentru modul în care aceste brațe pot fi completate. Încheiem discutând modul în care compchain-urile oferă o nouă perspectivă asupra spartității datelor de instruire pentru analizoarele UD, precum și asupra acurateții analizărilor UD rezultate.", 'ml': 'ഒരു യുഡി പാര്\u200dസില്\u200d നിന്നും പ്രധാനപ്പെടുത്തുന്ന ആര്\u200dഗ്യുമെന്\u200dറിയുടെ ഘട്ടത്തില്\u200d നിന്നും പൂര്\u200dണ്ണമായി വീണ്ടെടുക്കുന്നത് സെമാന്റിക ഈ പഠനത്തില്\u200d യുഡി പാര്\u200dസിന്\u200dറെ ഉള്ളിലുള്ള ആശ്രയ ബന്ധങ്ങളുടെ ഹിയേരാര്\u200dച്ചിയുടെ വിഭാഗങ്ങള്\u200d കൂടുതല്\u200d ചങ്ങലകളെ പരിചയപ് വാക്കുകളില്\u200d നിന്നും വാക്കുകളില്\u200d നിന്നും പൂര്\u200dണ്ണമായി വീണ്ടും നിര്\u200dണ്ണയിക്കുന്നതിനായി സജ്ജീകരിക്കുന്നതിനുള്ള ക്രോക മൂന്നു ഇംഗ്ലീഷ് ട്രീബാങ്കുകളിലും ഇംഗ്ലീഷ് ട്രീബാങ്കുകളിലും കോമ്പ്ഷന്\u200d വിതരണം ചെയ്യുന്നതിനെ ഞങ്ങള്\u200d അന്വേഷിച്ചു. പ്രഖ്യാപിക്കുന്ന വാക്കുകളില്\u200d ഈ ട്ര ഞങ്ങള്\u200d കോണ്\u200dഎല്\u200d 2018 പങ്കുചേര്\u200dത്ത ടാസ്ക് യുഡിപിപ്പി (v1. 2) ബെസ്റ്റലൈന്\u200d (ആശ്രയിക്കുന്ന പാര്\u200dസി) മോഡലുകള്\u200d യൂട്ടിയുടെയും ഗ്യുമിസും ലൈനെസ് യുഡി ട്രീബ നമ്മുടെ ഫലങ്ങള്\u200d വ്യക്തമാക്കുന്നു ഈ മൂന്നു ബെസ്ലൈന്\u200d മോഡലുകള്\u200d വാക്കുകളില്\u200d ഏറ്റവും കുറഞ്ഞ പ്രദര്\u200dശനം കാണിക്കുന്നു. ഒരു നിലയി ഈ പാര്\u200dസറുകള്\u200d ഉണ്ടാക്കിയ തെറ്റുകളെ ക്രമീകരിക്കാന്\u200d ഞങ്ങള്\u200d സങ്കീര്\u200dണ്ണചങ്ങലകള്\u200d ഉപയോഗിച്ചു കൊണ്ടിരുന്നു. സങ്കീര്\u200dണ് ഞങ്ങള്\u200d 58 ഇംഗ്ലീഷ് അല്ലാത്ത ഇംഗ്ലീഷ് യുഡി ട്രീബാങ്കുകളില്\u200d സങ്കീര്\u200dണ്ണമായി വിതരണം ചെയ്യുന്നതും അന്വേഷിച്ചു. പിന്നീട് നമ്മള്\u200d ഈ ട്രീബാങ് നമ്മുടെ അന്വേഷണം കാണിക്കുന്നത് കൊണ്ട് സങ്കീര്\u200dണ്ണമായ വ്യവസ്ഥയുടെ പ്രവര്\u200dത്തനത്തിന് മാത്രമേ ദുര്\u200dബ\nofficial evaluation metrics (LAS, MLAS and BLEX).  യുഡി ട്രീബാങ്കുകളില്\u200d കുറച്ച് കണക്കുകള്\u200d വിതരണം ചെയ്യുന്നതില്\u200d നമ്മള്\u200d വ്യത്യാസങ്ങള്\u200d തിരിച്ചറിയുന്നു. അതുകൊണ്ട് ഈ ത്രീബാ യുഡി പാര്\u200dസറുകള്\u200dക്കുള്ള പരിശീലനത്തിന്റെ സ്പെരിസ്റ്റിയില്\u200d പുതിയ കാഴ്ചപ്പെടുത്തുന്നതിനെക്കുറിച്ചും യുഡി പാര്\u200dസുകളുട', 'pl': "Dokładne odzyskiwanie struktury argumentów predykatów z parsy uniwersalnej zależności (UD) ma kluczowe znaczenie dla dalszych zadań, takich jak ekstrakcja ról semantycznych lub reprezentacji zdarzeń. W pracy wprowadzono kompchainy, kategoryzację hierarchii relacji zależności predykatów obecnych w parsie UD. Dokładność klasyfikacji compchain służy jako zastępca do pomiaru dokładnego odzyskania struktury predykatów-argumentów ze zdań z osadzeniem. Analizowaliśmy rozkład kompańców w trzech angielskich bankach UD, EWT, GUM i LinES, ujawniając, że te banki drzew są rzadkie w odniesieniu do zdań o strukturze predykat-argument, która zawiera osadzanie predykat-argument. Oceniliśmy modele bazowe (parsowanie zależności) CoNLL 2018 Shared Task UDPipe (v1.2) jako klasyfikatory kompchain dla banków drzew EWT, GUMS i LinES UD. Nasze wyniki wskazują, że te trzy modele bazowe wykazują słabsze wydajności w zdaniach o strukturze predykatów-argumentów z więcej niż jednym poziomem osadzenia; Użyliśmy komponentów do scharakteryzowania błędów popełnionych przez te parsery i przedstawiliśmy przykłady błędnych parserów wytworzonych przez parser, które zostały zidentyfikowane za pomocą komponentów. Analizowaliśmy również rozkład kompchainów w 58 nieangielskich drzewach UD, a następnie użyliśmy kompchainów do oceny modelu bazowego CoNLL'18 Shared Task dla każdego z tych drzew. Nasza analiza pokazuje, że wydajność w zakresie klasyfikacji kompchain jest tylko słabo skorelowana z\noficjalne wskaźniki oceny (LAS, MLAS i BLEX). Identyfikujemy luki w rozkładzie kompańcuchów w kilku drzewach UD, dostarczając tym samym mapę drogową dla tego, jak te drzewa mogą być uzupełniane. Na zakończenie omówimy, w jaki sposób kompchainy zapewniają nową perspektywę na słabość danych treningowych dla parserów UD, a także dokładność wynikowych parser UD.", 'no': "Akkurat gjenoppretting av predikativ argument-strukturen frå ein universell avhengighet (UD) er sentralt til nedtrekking av oppgåver som ekstrahering av semantiske rolar eller hendingssrepresentasjonar. Denne studien introduserer kompleksjonar, ein kategorisering av hierarkien av forandrande avhengighetsrelasjonar som finst i eit UD-tolking. Nøyaktighet for kompleksjonsklassifikasjon er ein mellomtenar for å måla nøyaktig gjenoppretting av predikat- argument- struktur frå setningar med innbygging. Vi analysere distribusjonen av kompleksjonar i tre UD-engelske treebanktar, EWT, GUM og LinES, som viser at desse treebankta er sparke med respekt til setningar med predikat-argument-struktur som inneheld predikat-argumentinnbygging. Vi evaluerte CoNLL 2018 delte oppgåva UDPipe (v1.2) baseline (avhengighetstolking) som komplekseringar for EWT, GUMS og LinES UD- treebanksane. Resultatet våre tyder på at desse tre baselinjemodelene viser dårlegare utføringar på setningar med predikat argument-struktur med fleire enn eitt innbyggingsnivå. vi brukte kompleksjonar for å karakterisera feilen gjeven av desse analyserane og gjeldande eksemplar av feil tolkingar produsert av tolkaren som vart identifisert med kompleksjonar. Vi analysere også distribusjonen av kompleksjonar i 58 treebanktar som ikkje er engelsk UD, og så brukte kompleksjonar for å evaluera baselinjesmodellen for CoNLL'18 delt oppgåver for kvar av desse treebankta. Analysen vårt viser at utviklinga med høve til kompleksjonsklassifikasjon er berre svakt korrelatert med den\noffisielle evalueringsmetrikar (LAS, MLAS og BLEX). Vi identifiserer mellomrom i distribusjonen av kompleksjonar i fleire av UD- treebankene, slik at det gjev ei veikart for korleis desse treebankene kan leggjast til. Vi avsluttar med å diskutera korleis kompleksjonar gjev ei ny perspektiv på sparsiteten av opplæringsdata for UD-tolkarar, og nøyaktigheten av resultatet UD-tolkarar.", 'sr': "Upravo oporavak predikatne strukture argument a iz analize univerzalne zavisnosti (UD) je centralno za smanjenje zadataka poput izvlačenja semantičkih uloga ili predstavljanja događaja. Ova studija predstavlja komplansiranje, kategorizaciju hijerarhije predikatnih odnosa zavisnosti koje su prisutne unutar UD analize. Točnost klasifikacije kompchaina služi kao proksi za mjerenje tačnog oporavka strukture predikata argument a iz rečenica sa integracijom. Analizirali smo distribuciju kompchaina na tri UD engleske trgovine, EWT, GUM i LinES, otkrivajući da su te trgovine rezervne u vezi rečenica sa predikatnem strukturom argumenta koja uključuje predikatne integracije argumenta. Procjenjivali smo modele podijeljenog zadatka UDPipe (v1.2) za početnu liniju (analizanje ovisnosti) CoNLL 2018 kao klasifikatore kompchaina za EWT, GUMS i LinES UD trgovine. Naši rezultati ukazuju na to da ove tri osnovne modela pokazuju siromašniju izvršnost rečenica sa predikatnim strukturom argumenta sa više od jedne nivoe ugrađenja; Koristili smo komplansiranje kako bi karakterizirali greške koje su napravili ovi parseri i predstavili primjere grešnih parsera proizvođenih od strane analizatora koji su identifikovani koristeći komplansiranje. Takođe smo analizirali distribuciju kompchaina na 58 ne-engleskim UD treebancima i onda smo koristili kompchaine za procjenu model podjele zadataka CoNLL'18 za svaku od ovih treebancija. Naša analiza pokazuje da je izvedba u pogledu klasifikacije komplekcija slaba povezana sa\nzvanična procjena metrika (LAS, MLAS i BLEX). Identificiramo praznine u distribuciji komplansa u nekoliko UD-ovih trgovačkih granica, tako pružajući putnu mapu kako bi se ovi treebani mogli dodati. Zaključili smo razgovoreći o tome kako komplanci pružaju novu perspektivu o isključivosti podataka obuke za UD parsere, kao i preciznosti rezultatnih UD analiza.", 'ta': "பொது சார்ந்த சார்பு (UD) பகுதியிலிருந்து முன்னிருப்பு தருமதிப்பு உருவமைப்பை சரியாக மீட்டெடுப்பது பெரிய இடைவெளிப்பட்ட பணிகளை போன்று  இந்த ஆராய்ச்சியின் முன்னிருப்பு சார்ந்த சார்பு தொடர்புகளை குறிப்பிடுகிறது, முன்னிருப்பு சார்பு தொடர்புகளி வாக்கியங்களில் இருந்து முன்னிருந்து வாக்கியங்களின் சரியான மீட்டு சரியான முன்னிருப்பு வாக்கியம் அமைப்பை அளவிடுவதற்கு கூ மூன்று UD ஆங்கிலத்தின் Treebanks, EWT, GUM மற்றும் LinES-ல் இந்த மூன்று முன்னிருப்பு தருமதிப்பு கட்டமைப்பில் வாக்கியங்கள் சேர்க்கப்பட்டது என்பதை அறிவித்தோம். We evaluated the CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) models as compchain classifiers for the EWT, GUMS and LinES UD treebanks.  நம்முடைய முடிவு இந்த பார்சர்கள் செய்யப்பட்ட பிழைகளை எழுதுவதற்காகவும் தற்போது பிழையான பார்ச்சர் உருவாக்கிய பிழைகளின் உதாரணங்களையும் க நாங்கள் 58 ஆங்கிலம் இல்லாத UD ட்ரீபாங்க்களில் கூட்டிய கட்டுப்பாட்டை விரிவாக்கத்தை ஆய்வு செய்தோம் மற்றும் ஒவ்வொரு treebanks க்கும் கோன்எல் ' நம்முடைய ஆய்வு காண்பிக்கிறது சங்கிலி வகைப்படுத்தல் பற்றிய செயல்பாடு மட்டும் பலவீனமாக இணைந்து கொண்ட\nOfficial evaluation methods (LAS, MLAS and BLEX). நாம் குறிப்புகளை விரிவாக்குதலில் குறிப்புகளை கண்டுபிடிக்கிறோம். இந்த முனைகள் எவ்வாறு சேர்க்க முடியும். நாம் முடிவு செய்து விளக்கம் எவ்வாறு புதிய கூட்டும் பார்வைகளை கொடுக்கும் பொழுது தெரியும் முடிவு, UD பார்ச்சர்களுக்கு பய", 'si': "සාමාන්\u200dය විශේෂතාව (UD) පරීක්ෂණයෙන් ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක සංස්ථානය සඳහා ප්\u200dරතික්\u200dරියාත්මක සංස්ථාන මේ පරීක්ෂණය සම්බන්ධ විශ්වාස කරනවා, UD පරීක්ෂණයෙන් ඉන්න තියෙන ප්\u200dරධානය සම්බන්ධ සම්බන්ධතාවක් වල Name අපි UD ඉංග්\u200dරීසි ට්\u200dරෙබැන්ක් තුන්දෙනුවෙන්, EWT, GUM හා Lines වලින් කම්පන්ස් විතරය විශ්ලේෂණය කරලා තියෙනවා, ප්\u200dරකාශ කරනවා මේ ට්\u200dරෙබැන්ක් වලින අපි CoNLL 2018 සාමාන්\u200dය වැඩක් UDPipe (v1.2) ප්\u200dරමාණය (සාමාන්\u200dය විශ්ලේෂණය) මොඩේල් වල EWT, GUMS සහ Lines UD ට්\u200dරෙබැන්ක්ස් වලට compchain classifiers විශේෂකයි. අපේ ප්\u200dරතිචාරය පෙන්වන්නේ මේ මූලික මොඩේල් තුන්දෙනුවෙන් ප්\u200dරතිචාරයක් පෙන්වන්නේ ප්\u200dරතිචාරයක් වගේ ප්\u200dරති අපි compchains භාවිතා කරනවා මේ පරිස්සර් වලින් කරපු වැරදි වලින් සැකසුම් වලින් පරිස්සර් වලින් පරිස්සර් වලින් පරිස්සර් වල අපි ඉංග්\u200dරීසි නොන් ඉංග්\u200dරීසි UD ට්\u200dරෙබෑන්ක් 58 දී කම්පචේන්ස් විතරය විශ්ලේෂණය කළා, ඊට පස්සේ CoNLL'18 කොටස් බේස් ලේන් මොඩේල්  අපේ විශ්ලේෂණය පෙන්වන්නවා කියලා කොම්ප්චේන්ස් විශේෂණය ගැන ප්\u200dරමාණය පෙන්වන්න පුළුවන්\nප්\u200dරධානික විශ්ලේෂණ මෙට්\u200dරික්ස් (LAS, MLAS සහ BLex). අපි UD ට්\u200dරීබෑන්ක් වලින් කොම්පචේන්ස් වලින් විතරයෙන් ප්\u200dරතිකාරයක් පරීක්ෂණය කරනවා, ඉතින් මේ ට්\u200dරීබෑන්ක් වලින් ප්\u200d අපි සම්පූර්ණය කරනවා කොහොමද අලුත් පරීක්ෂණයක් දෙන්නේ කොහොමද UD පරීක්ෂකයන්ට ප්\u200dරධාන දත්ත ගැන අවස්ථාවක් ගැන, සහ UD පරීක", 'so': 'Sida loo soo celiyo dhismo ku saabsan baarlamaanka ku saabsan qiimo-ku-xirfadeed (UD) waa u dhexe meelaha hoose laga sameeyo, sida ka soo bixinta qayb-qayb ama waxyaabaha dhacda. Waxbarashadan waxaa lagu soo bandhigaa silsilado, kooxo ku qoran hierarchy xiriir xiriir ku xiran ah oo ku jira baarlamaanka UD. Xirfada fasaxa shahaadada waxaa loo adeegaa jardiino si aad u qiyaasto cusboonaysiinta dhismaha rasmiga ah ee ku qoran qoraalka. Anagaa baaraynay qaybinta silsiladaha afka Ingiriiska, EWT, GUM iyo LinES, waxaynu muujinnay in looga baahan yahay dhibaatooyin ku saabsan qoraal muran ah oo ku qoran howlo-ku-qoran. We evaluated the CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) models as compchain classifiers for the EWT, GUMS and LinES UD treebanks.  Abaalkayaga waxaa loola jeedaa in saddexdan tusaale ee aasaasiga ah ay muujiyaan tababar ka liita oo ay ku qoran yihiin dhismo ka mid ah oo ka badan hal heer. waxaynu isticmaalnay silsilado aan ku saxeyno qaladyada baarlamahaas ay sameeyeen iyo tusaalooyin baaritaanka qaladka ah oo ay soo saareen Parser oo lagu aqoonsaday isticmaalka compsilado. Waxaannu kaloo analyeennay qaybinta compsilado ee 58-ka-Ingiriis-ka-Ingiriis-ka-Ingiriis-taariikhda, kadibna waxaynu u isticmaalnay silsilado lagu qiimeeyo modelka aasaaska shaqada ee CoNLL-18 ee loo sharciyey qoraalkaas oo dhan. Analyskayagu wuxuu muujiyaa in muuqashada fasalka koobsiga\nqeyminta rasmi ah (LAS, MLAS iyo BLEX). Sidaa darteed waxaynu baran nahay sidoo kale dariiqadahan lagu dari karo. Waxaynu ku dhamaystirnay baarlamaha UD iyo saxda baarlamaha UD ee uu soo jeedo sidoo kale sidoo kale baarlamaha UD-ka.', 'sv': "Exakt återställning av predikat-argumentstruktur från en UD-tolkning (Universal Dependency) är central för nedströmsuppgifter som extraktion av semantiska roller eller händelserepresentationer. Denna studie introducerar compchains, en kategorisering av hierarkin av predikatberoenderelationer som finns i en UD-parse. Noggrannheten i compchain klassificering fungerar som en proxy för att mäta exakt återställning av predikat-argumentstruktur från meningar med inbäddning. Vi analyserade fördelningen av kompchains i tre UD engelska trädbanker, EWT, GUM och LinES, vilket avslöjade att dessa trädbanker är glesa med avseende på meningar med predikat-argument struktur som inkluderar predikat-argument inbäddning. Vi utvärderade CoNLL 2018 Shared Task UDPipe (v1.2) baslinje (beroendetolkning) modellerna som compchain klassificerare för EWT, GUMS och LinES UD trädbanker. Våra resultat indikerar att dessa tre basmodeller uppvisar sämre prestanda på meningar med predikat-argumentstruktur med mer än en nivå av inbäddning; Vi använde kompchains för att karakterisera fel som gjorts av dessa parsers och presentera exempel på felaktiga tolkningar producerade av parsern som identifierades med kompchains. Vi analyserade även fördelningen av compchains i 58 icke-engelska UD-trädbanker och använde sedan compchains för att utvärdera CoNLL'18 Shared Task baslinjemodell för var och en av dessa trädbanker. Vår analys visar att prestationen med avseende på compchain klassificering endast är svagt korrelerad med\nofficiella utvärderingsmetoder (LAS, MLAS och BLEX). Vi identifierar luckor i distributionen av kompkedjor i flera av UD-trädbackarna och ger därmed en färdplan för hur dessa trädbackar kan kompletteras. Vi avslutar med att diskutera hur kompchains ger ett nytt perspektiv på sparheten i utbildningsdata för UD-tolkare, samt noggrannheten i de resulterande UD-tolkarna.", 'ur': "یونیورل ڈیفاندنستی (UD) پارس سے پیشڈیکٹ-آرگومیٹ کی ساختار کی دقیق بازیابی ہے اس طرح کہ سیمنٹی رول یا حادثہ نمایش کا اٹھانا ہے۔ This study introduces compchains, a category of predicate dependency relations present in a UD parse. کمپچین کلاسپیٹ کی دقیق مطابق باتوں کے ساتھ مطابق مطابق آرمونٹ ساختار کی مطابق مطابق پیروکسی کے طور پر ہے. ہم نے تین UD انگلیسی تریبانک، EWT, GUM اور LinES میں کمپچینٹوں کی تقسیم کی تحقیق کی ہے، جو ظاہر کر رہے ہیں کہ یہ تریبانک ان باتوں کے معاملہ میں پیشڈیکٹ-ارجمند ساختار کے ساتھ چھوڑ دیے جاتے ہیں جو پیشڈیکٹ-ارجمند میں شامل ہوتے ہیں. ہم نے CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) موڈل کو EWT, GUMS اور LinES UD Treebanks کے لئے کمپچینٹ کلاسیر کے طور پر ارزش کیا۔ ہمارے نتیجے نشان دیتے ہیں کہ یہ تین بنیاس لین موڈل ایک سطح سے زیادہ زیادہ مضبوط باتوں پر کمزور فعالیت دکھاتے ہیں۔ ہم نے کمپٹینز کو ان پارچر کے ذریعے خطا کی تعریف کرنے کے لئے استعمال کیا تھا اور پارچر کے ذریعے پیدا کئے ہوئے غلطی پارچز کی مثالیں پیش کئے گئے ہیں جو کمپٹینز کے ذریعے پہچان کئے گئے تھے۔ ہم نے 58 غیر انگلیسی UD تریبانک میں کمپچینڈ کے تقسیم کا تحلیل کیا اور پھر کمپچینڈ استعمال کیا کہ CoNLL'18 شریک ٹاکس بنیس لین مدل کو ان تریبانک کے لئے مطابق کریں. ہماری تحلیل دکھاتی ہے کہ کامپینچین کلاسیفوں کے معاملہ میں عمل صرف کمزور تعلق ہے\nرسمی evaluation metrics (LAS, MLAS اور BLEX). ہم نے کئی UD تریبانک میں کمپٹینک کے تقسیم میں فاصلہ پہچان لیا ہے، اسی طرح یہ تریبانک کس طرح اضافہ کیے جاتے ہیں، ایک راڈ نقشه کے ساتھ۔ ہم نے مشورہ کیا ہے کہ کمپچینڈ کس طرح نیا نظر دیتے ہیں UD پارس کے لئے تربیت ڈیٹ کی کمپچینڈ کے بارے میں اور نتیجہ UD پارس کے دقیق۔", 'uz': "Name Bu ta'qituvni UD парламентда мавжуд боғлиқлик алоқаларини кўрсатади. Name Biz uchta ingliz tilida komponentlarning tarjimalarini o'zgartirish, EWT, GUM va LinES bilan tarjima qildik. Bu uchta suhbatlarni predpredicate argumentlar tuzilishini qo'shish mumkin. Biz 2018 bilan birlashtirilgan Vazifa UDPip (v1.2) bazasi modellarini EWT, GUMS va LinES UD treebanklari uchun kompyutsen klassiflari sifatida qiymatdik. Our results indicate that these three baseline models exhibit poorer performance on sentences with predicate-argument structure with more than one level of embedding;  Biz bu parserlarning xatolarini ko'rsatishga foydalanamiz va komputer bilan aniqlangan parslarning notoʻgʻri misollarini ko'rsatuvchimiz. Biz 5-8 ingliz tilida komponentlarning tarjima qilishni nazar qildik va keyin buning har bir treeborning CoNLL'18 bilan bogʻlangan vazifa asosiy modelini qiymatga ishlatdik. Analytikizni ko'rsatishimiz mumkin, bunday bir bir necha darajada\nofficial evaluation metriclari (LAS, MLAS va BLEX). Biz komponentlarni bir nechta UD treeborning bir necha bogʻlarda ajratishni aniqlamiz, shunday qilib bu suhbatlarni qanday qo'shilishi mumkin. Biz kompyuterlar qanday foydalanishini va UD parserlarining tajribasining qismlarini va natijasida UD parserlarining imkoniyati haqida yangi ko'rinishini talab qilamiz.", 'vi': "Sự phục hồi chính xác cấu trúc khó khăn từ một phân tích sự phụ thuộc chung (UD) là trung tâm của các công việc theo cấp dưới như việc khai thác các vai trò theo ngữ nghĩa hoặc các biểu hiện sự kiện. This study introduced compchais, a classification of the priate dependence relationship present in a UD parre. Sự chính xác của việc phân loại compchain phục vụ như một ủy nhiệm cho việc đo lường phục hồi chính xác cấu trúc biện pháp chuẩn từ câu với sự nhúng. Chúng tôi phân tích sự phân phối hợp trong ba ba ba xâu bóng của Anh UD, EWT, GUM và Linus, tiết lộ rằng các xâu bóng này rất ít so với các câu với cấu trúc khó khăn-cãi mà bao gồm sự nhúng tạm thời. Chúng tôi đánh giá cơ sở tập tin hoạt động kép (v1.2) cơ sở cơ bản phân tích phụ thuộc) như những phân loại máy tính tổng hợp cho EWT, GUMS và Linney UD treebacks. Những kết quả của chúng tôi cho thấy ba mô hình cơ bản này có hiệu suất kém hơn về các câu với cấu trúc khó khăn với hơn một cấp độ tác nghiệp; Chúng tôi dùng các máy tính để phân tích lỗi của các phân viên này và trình bày các ví dụ của các phân viên lỗi được tạo ra bởi người phân tích được xác định bằng máy trộn. Chúng tôi cũng phân tích sự phân phối hợp trong 58 ngoài tiếng Anh ba lô UD và sau đó sử dụng các compxích để đánh giá mô hình nền tập tin (CONLL'18). Theo phân tích của chúng tôi, khả năng đạt được với mức độ phân hạng tổng hợp chỉ có liên quan nhẹ với...\nHệ thống đo đánh giá chính thức (LAS, MLAS và LEX). Chúng tôi xác định khoảng trống trong việc phân phối các công trình trong nhiều máy phát sóng UD, cung cấp bản đồ cho cách mà các chế độ phát sóng này có thể được bổ sung. Chúng tôi kết thúc bằng cách bàn bạc làm thế nào để tạo ra một viễn cảnh mới về khoảng trống của dữ liệu đào tạo cho các cha xứ UD, cũng như độ chính xác của các phân tách nó.", 'bg': "Точното възстановяване на структурата на предикат-аргумент от анализ на универсална зависимост (UD) е от основно значение за задачи надолу по веригата, като извличане на семантични роли или представяне на събития. Това изследване въвежда компхеинги, категоризация на йерархията на зависимостта на предикатите, присъстващи в анализа на UD. Точността на класификацията на компхейн служи като прокси за измерване на точното възстановяване на структурата на предикат-аргумент от изречения с вграждане. Анализирахме разпределението на компаньонките в три английски триленки, разкривайки, че тези триленки са оскъдни по отношение на изречения със структура на предикат-аргумент, която включва вграждане на предикат-аргумент. Оценихме базовите модели (анализ на зависимостта) за споделена задача на CoNLL 2018 като класификационни вериги за дървесните ленти. Нашите резултати показват, че тези три базови модела показват по-лошо представяне на изречения с предикатно-аргументна структура с повече от едно ниво на вграждане; Използвахме компверижни вериги, за да характеризираме грешките, направени от тези анализатори и да представим примери за грешни анализи, произведени от анализатора, които са идентифицирани с помощта на компверижни вериги. Анализирахме и разпределението на компаньонките в 58 неанглийски триленки и след това използвахме компаньонките, за да оценим базовия модел за споделена задача на CoNLL'18 за всеки от тези триленки. Нашият анализ показва, че ефективността по отношение на класификацията на компаньонките е слабо корелирана с\nофициални показатели за оценка (LAS, MLAS и BLEX). Идентифицираме пропуски в разпределението на веригите в няколко от дървесните ленти, като по този начин предоставяме пътна карта за това как тези ленти могат да бъдат допълнени. В заключение обсъждаме как компхеингите осигуряват нова перспектива за оскъдността на тренировъчните данни за анализаторите, както и точността на получените анализатори.", 'nl': "Nauwkeurig herstel van predicaat-argumentstructuur uit een UD parse (Universal Dependency) is centraal bij downstreamtaken zoals het extraheren van semantische rollen of gebeurtenisrepresentaties. Deze studie introduceert compchains, een categorisering van de hiërarchie van predicaat afhankelijkheidsrelaties die aanwezig zijn binnen een UD parse. Nauwkeurigheid van compchain classificatie dient als een proxy voor het meten van nauwkeurig herstel van predicaat-argument structuur uit zinnen met embedding. We analyseerden de verdeling van compchains in drie UD Engelse boombanken, EWT, GUM en LinES, waaruit bleek dat deze boombanken schaars zijn ten opzichte van zinnen met een predicaat-argumentstructuur die predicaat-argument embedding omvat. We hebben de CoNLL 2018 Shared Task UDPipe (v1.2) baseline (afhankelijkheidsparsing) modellen geëvalueerd als compchain classificatoren voor de EWT, GUMS en LinES UD boombanken. Onze resultaten geven aan dat deze drie basismodellen slechtere prestaties vertonen op zinnen met predicaat-argument structuur met meer dan één niveau van inbedding; We gebruikten compchains om de fouten van deze parsers te karakteriseren en voorbeelden te presenteren van foutieve parsers geproduceerd door de parser die geïdentificeerd werden met behulp van compchains. We hebben ook de verdeling van compchains geanalyseerd in 58-niet-Engelse UD boombanken en vervolgens compchains gebruikt om het CoNLL'18 Shared Task baseline model voor elk van deze boombanken te evalueren. Uit onze analyse blijkt dat de prestaties met betrekking tot compchain classificatie slechts zwak gecorreleerd zijn met de\nofficiële evaluatiestatistieken (LAS, MLAS en BLEX). We identificeren lacunes in de verdeling van compchains in verschillende UD boombanken, waardoor we een routekaart bieden voor hoe deze boombanken kunnen worden aangevuld. We sluiten af door te bespreken hoe compchains een nieuw perspectief bieden op de schaarse trainingsdata voor UD parsers, evenals de nauwkeurigheid van de resulterende UD parses.", 'da': "Nøjagtig gendannelse af prædikat-argumentstruktur fra en Universal Dependency (UD) parse er centralt for downstream opgaver som ekstraktion af semantiske roller eller hændelsesrepræsentationer. Denne undersøgelse introducerer compchains, en kategorisering af hierarkiet af prædikateafhængighedsrelationer til stede i en UD parse. Nøjagtigheden af compchain klassificering tjener som en proxy til måling af nøjagtig genopretning af prædikat-argumentstruktur fra sætninger med indlejring. Vi analyserede fordelingen af kompchains i tre UD engelske treebanks, EWT, GUM og LinES, og afslørede, at disse treebanks er sparsomme i forhold til sætninger med prædikat-argument struktur, der inkluderer prædikat-argument indlejring. Vi evaluerede CoNLL 2018 Shared Task UDPipe (v1.2) baseline-modellerne (afhængighedsparsing) som compchain klassifikationer for EWT, GUMS og LinES UD-træbanker. Vores resultater indikerer, at disse tre basismodeller udviser dårligere ydeevne på sætninger med prædikat-argumentstruktur med mere end ét niveau af indlejring; Vi brugte compchains til at karakterisere fejlene lavet af disse parsere og præsentere eksempler på fejlagtige parser produceret af parseren, der blev identificeret ved hjælp af compchains. Vi analyserede også fordelingen af compchains i 58 ikke-engelske UD treebanks og brugte derefter compchains til at evaluere CoNLL'18 Shared Task baseline model for hver af disse treebanks. Vores analyse viser, at præstation med hensyn til compchain klassificering kun er svagt korreleret med\nofficielle evalueringsmålinger (LAS, MLAS og BLEX). Vi identificerer huller i fordelingen af kompchains i flere af UD-træbankerne og giver dermed en køreplan for, hvordan disse træbanker kan suppleres. Vi afslutter med at diskutere, hvordan kompchains giver et nyt perspektiv på sparsommeligheden af træningsdata for UD-fortolkere, samt nøjagtigheden af de resulterende UD-fortolkninger.", 'id': "Pemulihan yang tepat dari struktur argumen-predikat dari analisis Dependensi Universal (UD) adalah pusat untuk tugas turun seperti ekstraksi peran semantis atau rappresentasi peristiwa. Studi ini memperkenalkan compchains, kategorisasi hierarki hubungan dependensi predikat yang ada dalam analisis UD. Accuracy of compchain classification serves as a proxy for measuring accurate recovery of predicate-argument structure from sentences with embedding.  Kami menganalisis distribusi kompchains dalam tiga batang pohon UD Inggris, EWT, GUM dan LinES, mengungkap bahwa batang pohon ini jarang berkaitan dengan kalimat dengan struktur predicate-argumen yang termasuk penyambungan predicate-argumen. Kami mengevaluasi model UDPipe (v1.2) dasar tugas berbagi CoNLL 2018 (dependency parsing) sebagai klasifikasi kompchain untuk batang pohon EWT, GUMS dan LinES UD. Hasil kami menunjukkan bahwa tiga model dasar ini menunjukkan prestasi yang lebih buruk pada kalimat dengan struktur predikat-argumen dengan lebih dari satu tingkat penerbangan; kami menggunakan compchains untuk mengkaraterisasikan kesalahan yang dibuat oleh parser ini dan mempersembahkan contoh dari parser yang salah yang dibuat oleh parser yang diidentifikasi menggunakan compchains. Kami juga menganalisis distribusi compchains di 58 batang pohon UD bukan Inggris dan kemudian menggunakan compchains untuk mengevaluasi model dasar CoNLL'18 Shared Task untuk setiap batang pohon ini. Analisi kami menunjukkan bahwa prestasi terhadap klasifikasi compchain hanya terkait dengan kelemahan\nmetrik evaluasi resmi (LAS, MLAS dan BLEX). We identify gaps in the distribution of compchains in several of the UD treebanks, thus providing a roadmap for how these treebanks may be supplemented.  Kami menyimpulkan dengan mendiskusikan bagaimana compchains menyediakan perspektif baru tentang kecepatan data pelatihan untuk pemeriksa UD, serta akurasi pemeriksaan UD hasilnya.", 'de': "Die genaue Wiederherstellung der Prädikat-Argument-Struktur aus einer Universal Dependency (UD)-Parse ist von zentraler Bedeutung für nachgelagerte Aufgaben wie die Extraktion semantischer Rollen oder Ereignisrepräsentationen. Diese Studie stellt Compchains vor, eine Kategorisierung der Hierarchie von Prädikatabhängigkeitsbeziehungen, die innerhalb einer UD Parse vorhanden sind. Die Genauigkeit der Compchain-Klassifizierung dient als Proxy für die genaue Wiederherstellung der Prädikat-Argument-Struktur aus Sätzen mit Einbettung. Wir analysierten die Verteilung von Compchains in drei UD-englischen Baumbänken, EWT, GUM und LinES, und zeigten, dass diese Baumbänke spärlich sind in Bezug auf Sätze mit Prädikat-Argument Struktur, die Prädikat-Argument Einbettung beinhaltet. Wir haben die CoNLL 2018 Shared Task UDPipe (v1.2) Baseline (Dependency Parsing) Modelle als Compchain Klassifikatoren für die EWT, GUMS und LinES UD Baumbänke evaluiert. Unsere Ergebnisse deuten darauf hin, dass diese drei Basismodelle schlechtere Leistungen bei Sätzen mit Prädikat-Argument-Struktur mit mehr als einer Ebene der Einbettung aufweisen; Wir haben Compchains verwendet, um die Fehler dieser Parser zu charakterisieren und Beispiele für fehlerhafte Parses zu präsentieren, die vom Parser erzeugt wurden und die mithilfe von Compchains identifiziert wurden. Wir analysierten auch die Verteilung von Compchains in 58-nicht-englischen UD-Baumbänken und nutzten dann Compchains, um das CoNLL'18 Shared Task Basismodell für jede dieser Baumbänke zu evaluieren. Unsere Analyse zeigt, dass die Performance hinsichtlich der Compchain-Klassifizierung nur schwach mit der\noffizielle Bewertungsmetriken (LAS, MLAS und BLEX). Wir identifizieren Lücken in der Verteilung von Compchains in mehreren UD-Baumbänken und liefern so eine Roadmap, wie diese Baumbänke ergänzt werden können. Abschließend diskutieren wir, wie Compchains eine neue Perspektive auf die Sparsamkeit von Trainingsdaten für UD-Parser sowie die Genauigkeit der resultierenden UD-Parses bieten.", 'tr': "Uniwersal Dependensiýa (UD) tarapyndan öň-öňkiň argüm strukturynyň ýeňlemesini takyklaşdyrmak semantik roller ýa-da çykyş täzeliklerini a çmak üçin merkezdir. Bu araşdyrma UD analyzasynda bolan öňki baglanylyk nişanlarynyň ýerarhiýasyny tanyşdyrýar. Syýallar arasyndaky gabdalyk sözleriň arasynda dogry bir arşiw bejermek üçin bir vekil döredir. Biz üç UD Iňlisiň baglançylary, EWT, GUM we LinES içinde süzmekler paýlaşypdyk, bu süzmekler öň-öňünden argüment daşarylýan sözleriň üçin boýun gaýşartypdyr. CoNLL 2018-nji ýylda Paýlaşylyş Taýgyny UDPipe (v1.2). Biziň netijelerimiz bu üç esasy nusgalaryň sözleriň öňki-argüm strukturasy bilen bir derejeden köp daşyrylygy bilen ýok täsirini tanaýarlar; Bu parsörler tarafından eden hatalary karakterize etmek üçin zıncıları kullandık. Şunlar şeklinde ayırt edilen yanlış parsallar örnekleri çözdük. Biz hem 58-nji iňlisçe UD süýşiklerinde süýşiklikler paýlaşypdyk we soňra CoNLL'18 Beýleki Görevler Baseline nusgasyny çykmak üçin süýşiklikleri ulandyk. Biziň analýusymyz çykyş klasifikasyyla baglanyşygy bilen diňe azajyk şekilde däldir.\nresmi deňlenme metrikleri (LAS, MLAS we BLEX). UD çyzgymlaryň birnäçe sany çyzgymlaryň paýlaşmagynda gaplary tanyýarys, şonuň üçin bu çyzgymlaryň nädip täze edip biljekleri üçin ýoluň haritasyny berip barýarys. UD parsileri üçin üýtgetmek üçin hasaplamalaryň nähili täze perspektivini nähili süýtgetmelidigini we netijeli UD parsallaryň dogrylygyny taryşarak çykyp çykyp çykyp çykyp başladyk.", 'sw': 'Kurudishwa kwa miundombinu ya mahojiano yanayotangulia kutoka bunge la Dunia la Kutegemea (UD) ni katikati ya kazi za chini ya mto kama vile kutengeneza jukumu la kimapenzi au uwakilishi wa matukio. This study introduces compchains, a categorization of the hierarchy of predicate dependency relations present within a UD parse.  Ukurahisi wa usambazaji wa mfumo unahudumia kama proksi kwa kupima upya sahihi wa muundo wa hoja uliopita kutoka kwenye hukumu zinazoingizwa. Tulichambua usambazaji wa viungo vitatu vya Uingereza vya Uingereza, EWT, GUM na LinES, kwa kuonyesha kuwa vifaa hivi vya mitatu vinavyopungua kuhusiana na sentensi yenye muundo wa hoja maalum ambao unajumuisha mjadala unaoendelea. Tulifuatilia mtindo wa msingi wa UDPipe wa CoNLL 2018 (v1.2) kama wataalamu wa uchimbaji wa kompyuta wa EWT, GUMS na LinES UD. Matokeo yetu yanaonyesha kuwa mifano hii mitatu ya msingi inaonyesha ufanisi wa hali mbaya zaidi kwenye sentensi zenye muundo wa hoja na zaidi ya kiwango kimoja cha kuingia; tulitumia viungo vya kompyuta kuhusiana na makosa yaliyofanywa na wabunge hawa na mifano ya mabango yaliyotokea yaliyotengenezwa na Parser yaliyotambuliwa kwa kutumia mfumo wa kompyuta. Pia tulichambua usambazaji wa mfumo wa kompyuta katika viwanja vya Uingereza 58 wasio na UD vya Uingereza na baadae tulitumia viungo vya kompyuta ili kutathmini modeli ya msingi wa kazi ya CoNLL ya 18 kwa kila mmoja wa viwanja hivi. Uchambuzi wetu unaonyesha kwamba utendaji wa utangazaji wa vikosi ni dhaifu tu unaohusishwa na\nmbinu rasmi za uchunguzi (LAS, MLAS na BLEX). Tunajua gaidi katika usambazaji wa viungo vya kompyuta katika baadhi ya viwanja vya UD, kwa hiyo tunatoa barabara kwa namna vigezo hivi vinavyoweza kuunganishwa. Tuhitimisha kwa kujadili jinsi viungo vya kompyuta vinavyotoa mtazamo mpya juu ya kuongezeka kwa taarifa za mafunzo kwa mabunge wa UDD, pamoja na uhalisia wa bunge la UDD.', 'fa': 'بازیابی دقیقا از ساختار ارجمند پیشدیک از یک تجزیه بستگی جهانی (UD) مرکزی به کار های پایین\u200cترین مانند استخراج از نقش\u200cهای semantic یا نمایش\u200cهای رویداد است. این مطالعه، مجموعه\u200cها را معرفی می\u200cکند، یک مجموعه\u200cای از مجموعه\u200cی رابطه\u200cهای بستگی پیشینیان در یک تجزیه UD وجود دارد. دقیقات گروه\u200cبندی مجموعه به عنوان پروکسی برای اندازه\u200cگیری بازیابی دقیقا از ساختار ارجمندی پیش\u200cفرض از جمله\u200cهای مجموعه\u200cای که دارند وارد می\u200cشوند خدمت می\u200cکند. ما توزیع مجموعه\u200cهای مجموعه\u200cها را در سه تخته\u200cهای انگلیسی UD، EWT, GUM و LinES تحلیل کردیم، که نشان می\u200cدهند که این تخته\u200cهای درخت\u200cها در مورد جمله\u200cها با ساختار مجموعه\u200cهای پیش\u200cدبینی که شامل جمله\u200cهای پیش\u200cدبینی\u200cهای مجموعه\u200cای است،  ما مدل\u200cهای پایه\u200cخط (پارش بستگی) مشترک کار CoNLL ۲۰۱۸ را به عنوان مجموعه\u200cکننده\u200cهای مجموعه\u200cبندی برای تختهای EWT, GUMS و LinES UD ارزیابی کردیم. نتیجه\u200cهای ما نشان می\u200cدهند که این سه مدل\u200cهای پایه\u200cخط ضعیف\u200cتر از جمله\u200cها با ساختار ارائه\u200cهای مختلف با بیشتر از یک سطح وارد شدن را نشان می\u200cدهند. ما از مجموعه\u200cزنجیرها استفاده کردیم تا اشتباهی که توسط این مجموعه\u200cکننده\u200cها انجام داده\u200cاند را تشخیص دهیم و مثال\u200cهایی از تجزیه\u200cهای اشتباهی که توسط مجموعه\u200cکننده\u200cها توسط مجموعه\u200cزنجیرها شناسایی شده ما همچنین تقسیم مجموعه\u200cها را در ۱۸ تخته\u200cهای UD غیر انگلیسی تحلیل کردیم و سپس از مجموعه\u200cهای مجموعه برای ارزیابی مدل پایین خط\u200cخط مشترک کوNLL ۱۸ برای هر یک از این تخته\u200cها استفاده کردیم. تحلیل ما نشان می دهد که عملکرد با ارتباط برقراری مجموعه فقط ضعیف ارتباط با\nمتریک ارزیابی رسمی (LAS, MLAS and BLEX). ما فاصله\u200cهایی را در تقسیم مجموعه\u200cها در چندین از مجموعه\u200cهای UD شناسایی می\u200cکنیم، بنابراین نقشه جاده\u200cای برای اینکه چگونه این مجموعه\u200cها ممکن است اضافه شود. ما با توجه به بحث کردن چگونه کمپین\u200cزنجیرها یک نگاه جدید در مورد کمپیوتری داده\u200cهای آموزش برای متخصص\u200cکنندگان UD، و دقیق تحلیل\u200cهای UD نتیجه را می\u200cدهیم.', 'hr': "Upravo je oporavak predikatne strukture argument a iz razmatranja univerzalne zavisnosti (UD) centralno za smanjenje zadataka poput izvlačenja semantičkih uloga ili predstavljanja događaja. U ovom ispitivanju predstavljaju komplansiranje, kategorizaciju hijerarhije predikatnih odnosa ovisnosti koje su predstavljene u razmatranju UD-a. Točnost klasifikacije kompchaina služi kao proizvođa č za mjerenje točnog oporavka strukture predikata argument a iz rečenica sa uključenjem. Analizirali smo distribuciju kompchainsa u tri UD engleske trgovine, EWT, GUM i LinES, otkrivajući da su te trgovine rezervne u odnosu na rečenice sa predikatnem strukturom argumenta koja uključuje predikatne integracije argumenta. Procjenili smo početne modele zajedničkog zadatka UDPipe (v1.2) CoNLL 2018 kao klasifikatore kompchaina za EWT, GUMS i LinES UD trgovine. Naši rezultati ukazuju na to da ove tri početne modela pokazuju siromašniju učinku na rečenicama sa predikatnim strukturom argumenta s više od jedne razine ugrađenja; Koristili smo compchains kako bi karakterizirali greške koje su napravili ovi parseri i predstavili primjere grešnih parsova proizvođenih od strane analizatora koji su identificirani koristeći kompchains. Također smo analizirali distribuciju kompchainsa u 58 ne-engleskim UD treebancima i onda smo koristili kompchains za procjenu početnog modela podjele zadataka CoNLL'18 za svaku od ovih treebancija. Naša analiza pokazuje da je učinkovito povezano sa klasifikacijom kompchaina samo slabo povezano s\nzvanična procjena metrika (LAS, MLAS i BLEX). Identificiramo praznine u distribuciji kompchainsa u nekoliko UD treebancija, tako pružajući putnu mapu kako bi se ovi treebanci mogli dodati. Zaključili smo razgovaranjem o tome kako komplanci pružaju novu perspektivu o isključivosti podataka obuke za UD analizatore, kao i preciznosti rezultatnih UD analiza.", 'af': "Akkuraat herstelling van predikaat-argument struktuur van 'n Universele Afhanklikheid (UD) verwerking is sentrale na onderstreem opdragte soos uitpakking van semantiese role of gebeurtenis voorstellings. Hierdie studie introduseer kompleksies, 'n kategorisasie van die hierarkie van vooraflikte afhanklikheidverhoudings wat binne 'n UD verwerking is. Nagtigheid van kompleksie klasifikasie bediener as 'n volmag vir die gemeet van presies herstelling van predikaat- argument struktuur van setinge met inbêring. Ons het die verspreiding van kompchains in drie UD Engelske treebanks, EWT, GUM en Lines analiseer, wat hierdie treebanks vertel het dat hierdie treebanks spanseer is met betrekking na setinge met predikaat-argument struktuur wat predikaat-argument ingesluit word. Ons het die CoNLL 2018 Gedeelde Opdrag UDPipe (v1.2) basisline (afhanklikheid verwerking) modele as kompchain klassifiseerders vir die EWT, GUMS en Lynes UD treebanks evalueer. Ons resultate wys dat hierdie drie basisline modele verminder uitwerking op setinge met predikaat-argument struktuur met meer as een vlak van inbêding; ons resultate wys dat hierdie drie basisline modele verminder is ons het kompchains gebruik om die foute wat deur hierdie verwerkers gemaak is te karakteriseer en voorneemde voorbeelde van foute verwerking wat deur die ontleerder geïdentifiseer is deur kompchains. Ons het ook die verspreiding van kompchains in 58 non- English UD treebanks analiseer en dan gebruik kompchains om die CoNLL' 18 Gedeelde taak baselyn model vir elke van hierdie treebanks te evalueer. Ons analisie wys dat die prestasie met respek na kompleksie klasifikasie slegs swak verbind is met die\noffisiele evalueringsmetries (LAS, MLAS en BLEX). Ons identifiseer spasies in die verspreiding van kompchains in verskeie van die UD treebanks, sodat verskaf 'n pad kaart vir hoe hierdie treebanks kan bygevoeg word. Ons sluit deur te bespreek hoe kompchains 'n nuwe perspektief verskaf op die sparsiteit van onderwerking data vir UD verwerkers, en die presisie van die resulteerde UD verwerking.", 'am': 'በዩንቨርስቲ ግንኙነት (ዩዲ) ፓርቲ ላይ የሚቆጠሩ አካባቢ ግንኙነት አካባቢ አካባቢ (UD) አካባቢ አካባቢ እንደምታወጣ የሴሜንቲክ ክፍል ወይም የሁኔታ ክፍሎች ማውጣት ማዕከል ነው፡፡ ይህ ትምህርት በዩዲ ፓርቲ ውስጥ ያሉትን የአፍሪካዊ ግንኙነት አካባቢ ግንኙነትን ያሳያል፡፡ ምርጫዎች በሦስት ኢንግሊዝኛ ግንኙነት፣ ኢዩተቲ፣ ጉዩም እና ሊኔስ የተካፈሉትን ሰንሰለቶች አካባቢ እና አፈላጊዎችን አስተያየን፡፡ የኮንጆል 2018 ስራውን UDPipe (v1.2) መደገፊያውን (የታሰረ ፓርቲ) ሞዴላዎችን ለEWT፣ GUMS እና LinES UD treebanks እንደተካፈሉ አካውንተናል፡፡ ፍሬዎቻችን እነዚህ ሦስት የደረጃ መተላለፊያዎች በአንድ ደረጃዎች ላይ የበለጠ የውይይት ግንኙነትን የሚያሳዩ ናቸው፡፡ እነዚህን ፓርስር የተደረጉትን ስህተት እና በሙሉ ሰንሰለት የተገኘውን የስሕተት ፓርቲዎች ምሳሌዎችን ለመግለጽ ተጠቃሚ ነበር፡፡ በ58 ያልኢንልዝላዊ ዩዲ ደራቦች ውስጥ የሰንሰለቱን አካባቢ እና በዚያን ጊዜም ለሁሉም የኮንLL 18 የተካፈሉት የስራ መሠረት ሞዴል ለማስተካከል ተጠቃሚ ሰንሰሮችን አሰራንተናል፡፡ ትምህርታችን የሰንሰለት ክፍል ማድረግ ብቻ ደካማ ነው፡፡\nየሥልጣን ማውጣት ማተሚያዎች (LAS, MLAS እና BLEX) በአሁኑ የዩድ አውታር እስራዊ ግንኙነትን በማካፈል ውጤቶች እናውቃለን፡፡ የዩዲ ፓርላር ዳታዎችን በጥቅምነት እና የዩዲ ፓርራርስ እና የዩዲ ፓርላማ ውስጥነት እንዴት አዲስ ስርዓት እንዳደረገ እናሳውቃለን፡፡', 'sq': "Rikthimi i saktë i strukturës predikate-argument nga një analizë e Varësisë Universale (UD) është qendrore në detyra poshtë të tilla si nxjerrja e rolit semantik apo përfaqësimet e ngjarjeve. Ky studim fut ndërlidhje, një kategorizim të hierarkisë së marrëdhënieve të varësisë të predikuara të pranishme brenda një analize UD. E saktësia e klasifikimit compchain shërben si një proxy për matjen e ripërtëritjes së saktë të strukturës predicate-argument nga fjalët me përfshirje. Ne analizuam shpërndarjen e kompçinat në tre baza druri angleze UD, EWT, GUM dhe LinES, duke zbuluar se këto baza druri janë të pakta lidhur me fjalët me strukturën predicate-argument që përfshin përfshirjen predicate-argument. Kemi vlerësuar modelet bazë (analiza e varësisë) të CoNLL 2018 të UDPipe Task Shared (v1.2) si klasifikues compchain për bazat e drurit EWT, GUMS dhe LinES UD. Rezultatet tona tregojnë se këto tre modele bazë tregojnë performancë më të dobët në fjalët me strukturë predikate-argumenti me më shumë se një nivel të përfshirjes; ne përdorëm kompçinat për të karakterizuar gabimet e bërë nga këta analizues dhe për të paraqitur shembuj të analizave të gabuara të prodhuara nga analizuesi që u identifikuan duke përdorur kompçinat. Ne analizuam gjithashtu shpërndarjen e kompçinat në 58 baza druri jo-angleze UD dhe pastaj përdorëm kompçinat për të vlerësuar model in bazë të CoNLL'18 Task Shared për secilin nga këto baza druri. Our analysis shows that performance with respect to compchain classification is only weakly correlated with the\nmetrika zyrtare e vlerësimit (LAS, MLAS dhe BLEX). Ne identifikojmë boshllëqet në shpërndarjen e ndërtesave në disa nga bazat e drurit të UD, duke ofruar kështu një hartë rrugës për mënyrën se si këto baza druri mund të shtohen. Ne përfundojmë duke diskutuar se si compchains ofrojnë një perspektivë të re mbi pakësinë e të dhënave të trajnimit për analizuesit UD si dhe saktësinë e analizave të UD që rezultojnë.", 'az': "Universel bağımlılıq (UD) ayırmasından öndək-arqümet quruluşunun yenilənməsi, semantik rollərin və olaraq göstərilmələrinin çıxarılması kimi mərkəzdir. Bu təhsil, UD analizi içində bulunan müxtəlif bağımlılıqların hierarhiyasının kategoriyasını göstərir. Kompcin klasifikasiyasının ədaləti, sözlərlə birlikdə dəyişiklik arqüd quruluşunu ölçürmək üçün proksi olar. Biz üç UD İngilizci çubuqlarda, EWT, GUM və LinES kompozicilərin dağıtılışını analiz etdik, bu çubuqların predikat-argument yapısıyla olan cümlələrə bağlı olduğunu göstərdik. Biz CoNLL 2018 paylaşılmış Task UDPipe (v1.2) baseline (dependency parsing) modellərini EWT, GUMS və LinES UD treebankları üçün kompchain klasifikatorları kimi değerlendirdik. Sonuçlarımız belə göstərir ki, bu üç sinyal modellərin bir səviyyədən daha çox səviyyədə olan cümlələr barəsində daha zəif performans göstərir; Biz bu ayırıcılar tarafından etdikləri hataları tanımlamaq üçün compchain və compchain vasitəsilə tanımlanan ayırış ayırıcıların məsəllərini istifadə etdik. Biz də 58 İngilizə olmayan UD treebanklarında compchains dağıtılışını analiz etdik və sonra CoNLL'18 paylaşılmış Task baseline modelini hər çubuğun üçün kompchains kullandıq. Bizim analizimiz göstərir ki, compchain klasifikasiyası haqqında performans ancaq zəif bir şəkildə\nresmi değerlendirmə metrikləri (LAS, MLAS və BLEX). Bizim UD tərəflərinin çoxlu tərəflərində kompozisyonların dağıtılmasında boşluqları tanıyırıq, buna görə də bu tərəflərin necə uyğunlaşdırılması üçün yol haritası təyin edirik. Və UD analizacıları üçün təhsil məlumatlarının çoxluğu və sonuçlarının UD analizacıların doğruluğu barəsində, kompchains necə yeni bir perspektivə təhsil edir?", 'bn': "বিশ্ববিদ্যালয়ের নির্ভরশীল (ইউডি) পার্স থেকে পূর্ববর্তী যুক্তির কাঠামো পুনরুদ্ধারের সঠিক পুনরুদ্ধার করা হচ্ছে, যেমন সেমেন্টিক ভূম এই গবেষণাটি ইউডি পার্জের মধ্যে উপস্থিত নির্ভরশীল সম্পর্কের একটি বিভাগের শ্রেণীবিভাগ উপস্থাপন করেছে। কমফেইন ক্লাস্ফিকেশনের গুরুত্বপূর্ণ প্রক্সি হিসেবে সার্ভার ব্যবহার করা হয়েছে যার ফলে বাক্য থেকে নির্ধারিত যুক্তিক্ত আর্ আমরা তিনটি ইউডি ইংরেজি ট্রিব্যাংক, ইউটি, জিউএম এবং লিনেসের মধ্যে কম্পিশেন বিতরণ বিশ্লেষণ করেছি, যেখানে আমরা প্রকাশ করেছি যে এই ত্রীব্যাংকেরা পূর্বাহিত যুক্তির কাঠা আমরা কএনএল ২০১৮ শেয়ার করা কাজ উডিপিপি (ভি১. ২) বেসাইন (নির্ভরশীল পার্সিং) মডেলের মূল্য মূল্যায়ন করেছি ইউডিউটি, জিউএমস এবং লিনেস ইউডি ট্রিব্যাংকের জন্য ক আমাদের ফলাফল নির্দেশ করা হয়েছে যে এই তিনটি বেস্লাইন মডেল প্রদর্শন করা হয়েছে বিশেষ করে যুক্তি প্রতিষ্ঠানের মাধ্যমে যুক্তি প্রতিষ্ঠ আমরা এই পার্সারের দ্বারা ত্রুটিকে চিহ্নিত করার জন্য কম্পিশেন ব্যবহার করেছিলাম এবং বর্তমানে পার্স তৈরি করা ভুল পার্সের উদাহ We also analyzed the distribution of compchains in 58 non-English UD treebanks and then used compchains to evaluate the CoNLL'18 Shared Task baseline model for each of these treebanks.  আমাদের বিশ্লেষণ দেখাচ্ছে যে কমচেইনের শ্রেণীতে প্রকাশ করা শুধুমাত্র দুর্বল সংশ্লিষ্ট\nঅফিসিয়াল মুল্যায়ন মেট্রিক (লাস, ম্যালেস এবং বিলেক্স)। আমরা বেশ কয়েকটি ইউডি ট্রিব্যাংকে কম্পিশেন বিতরণের মধ্যে বিভেদ চিহ্নিত করি, যার ফলে রাস্তা প্রদান করা হয় কিভাবে এই ত্রিব্যাংকের সাথে  আমরা শেষ করেছি যে কিভাবে কম্পিশেন নতুন দৃষ্টিভঙ্গি দিয়ে ইউডি পার্সারের জন্য প্রশিক্ষণের তথ্যের স্প্রাইজের ব্যাপারে আর ফলাফলের ই", 'ca': "La recuperació exacta de l'estructura predicat-argument d'una analisi de Dependencia Universal (UD) és central a tasques avall, com l'extracció de rols semàntics o representacions d'eventos. Aquest estudi introdueix compchains, una categorització de la jerarquia de les relacions predicates de dependencia presents dins un examen UD. La precisió de la classificació compchain serveix de proxy per mesurar la recuperació exacta de l'estructura predicat-argument a partir de frases amb incorporació. Vam analitzar la distribució de compchains en tres bancs d'arbres anglesos UD, EWT, GUM i LinES, revelant que aquestes bancs d'arbres són escases en relació a frases amb estructura predicate-argument que inclou incorporació predicate-argument. We evaluated the CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) models as compchain classifiers for the EWT, GUMS and LinES UD treebanks.  Els nostres resultats indican que aquests tres models de base mostran un rendiment més dolent en frases amb estructura de predicat-argument amb més d'un nivell d'integració; vam utilitzar compchains per caracteritzar els errors fets per aquests analitzadors i vam presentar exemples d'errors d'analitzadors produïts per l'analitzador que van ser identificats fent servir compchains. També vam analitzar la distribució de compchains en 58 bancs d'arbres UD no anglesos i vam utilitzar compchains per avaluar el model de base CoNLL'18 Shared Task per cada una d'aquestes bancs d'arbres. La nostra anàlisi mostra que el rendiment en relació a la classificació compchain només està debidament correlacionat amb\nmètriques oficials d'evaluació (LAS, MLAS i BLEX). We identify gaps in the distribution of compchains in several of the UD treebanks, thus providing a roadmap for how these treebanks may be supplemented.  Concluïm discutind com compchains proporcionen una nova perspectiva sobre la escassetat de dades d'entrenament dels analitzadors UD, i sobre la precisió dels analitzadors UD resultants.", 'ko': "통용 의존(UD) 해석에서 술어 파라미터 구조를 정확하게 회복하는 것은 하류 임무(예를 들어 의미 역할 추출이나 이벤트 표시)의 핵심이다.이 연구는compchains를 도입했는데 이것은 UD 해석에서 술어 의존 관계 차원의 분류이다.compchain 분류의 정확성은 술어 논원 구조가 문장에 삽입되어 정확하게 회복되는 지표로 삼을 수 있다.우리는 세 종류의 UD 영어 트리 라이브러리, EWT, GUM과 Lines 중의 복합 체인의 분포를 분석한 결과 이런 트리 라이브러리는 술어 파라미터가 삽입된 술어 파라미터 구조를 포함하는 문장에 대해 희소하다는 것을 발견했다.우리는 CoNLL 2018 공유 작업 UDPipe(v1.2) 기선(의존항 해석) 모델을 평가하여 EWT, GUM, UD 트리 라이브러리 줄의compchain 분류기로 삼았다.우리의 연구 결과에 의하면 이 세 가지 기선 모델은 1개 이상의 삽입 수준의 술어인 논원 구조를 가진 문장에서 비교적 나쁜 성능을 나타낸다.우리는 compchains를 사용하여 이 해석기에서 발생하는 오류를 설명하고,compchains를 사용하여 식별하는 해석기에서 발생하는 오류 해석의 예시를 제시합니다.우리는 58개의 비영어 UD 트리 라이브러리에 있는compchains의 분포를 분석한 다음에compchains를 사용하여 각 트리 라이브러리의CoNLL'18 공유 임무 기선 모델을 평가했다.우리의 분석에 의하면compchain 분류의 성능과\n공식 평가 지표(LAS, MLAS 및 BLEX).우리는 여러 개의 UD수상은행 중compchains분포의 차이를 확정하여 이러한 수상은행을 어떻게 보충하는지에 대해 노선도를 제공하였다.마지막으로, 우리는compchains가 UD해석기에 어떻게 데이터의 희소성을 훈련하는 새로운 시각을 제공하고, 이로 인해 발생하는 UD해석의 정확성을 토론할 것이다.", 'hy': 'Համաշխարհային կախվածության (UD) վերլուծությունից ստացված ճշգրիտ վերականգնումը կենտրոնական է դեպի ներքևի գործողությունները, ինչպիսիք են սեմանտիկ դերերի կամ իրադարձությունների ներկայացումների վերացումը: Այս ուսումնասիրությունը ներկայացնում է համաշխարհային շղթաներ, խմբավորում UD-ի վերլուծության մեջ գոյություն ունեցող բարդ կախվածության հարաբերությունների հիերարխիան: Կոմպլանտային դասակարգման ճշգրտությունը ծառայում է որպես պրոքսի, որպեսզի չափվի ճշգրիտ վերականգնումը նախադասություններից ներգրավման հետ: Մենք վերլուծեցինք կառուցվածքների տարածումը երեք անգլերենի անգլերենի ծառերի տախտակներում, Էութ, ԳուՄ և Լինեսում, բացահայտելով, որ այս ծառերի տախտակները քիչ են վերաբերյալ նախադասությունների հետ, որոնք ներառում են նախադասություններ և բանավեճեր: Մենք գնահատեցինք CONSL 2018-ի ընդհանուր հանձնարարությունների UDPipe (v1.2) հիմնական (կախվածության վերլուծում) մոդելները որպես համաշխարհային դասակարգեր, որոնք օգտագործվում են ԵՈւ-ի, ԳՈՄՍ-ի և Լինեսի UD-ի ծառերի վրա: Our results indicate that these three baseline models exhibit poorer performance on sentences with predicate-argument structure with more than one level of embedding;  we used compchains to characterize the errors made by these parsers and present examples of erroneous parses produced by the parser that were identified using compchains.  Մենք նաև վերլուծեցինք համաշխարհային շղթաների բաշխման 58 ոչ անգլերեն UD ծառերի տախտակներում և հետո օգտագործեցինք համաշխարհային շղթաներ, որպեսզի գնահատենք այս ծառերի տախտակներից յուրաքանչյուր մեկի կոնֆլենսի 18-ի ընդհանուր գործող Մեր վերլուծությունը ցույց է տալիս, որ կառուցվածքային դասակարգման արդյունքները միայն թույլ են կապված\nպաշտոնական գնահատման չափումները (LAS, MLAS և Blax). Մենք բացահայտում ենք բազմաթիվ ԱՄՆ-ի ծառերի բաշխման բաժանման բացառումները, այնպես որ առաջարկում ենք ճանապարհ, թե ինչպես են ծառերի բաշխման բաղադրիչները լրացվում: Մենք եզրակացնում ենք քննարկելով, թե ինչպես են կոմպշինտները նոր տեսանկյունից UD-ի վերլուծումների ուսումնասիրության տվյալների հազվադեպությունը, ինչպես նաև արդյունքում ստացված UD-ի վերլուծումների ճշգրտությունը:', 'et': "Preikaadi-argumendi struktuuri täpne taastamine universaalse sõltuvuse (UD) parsimisest on keskse tähtsusega järgnevates ülesannetes, näiteks semantiliste rollide või sündmuste esituste ekstraheerimisel. Käesolev uuring tutvustab kompchaineid, mis on UD parsis esinevate predikaatide sõltuvussuhete hierarhia kategoriseerimine. Komplikaatide klassifitseerimise täpsus on vahend eelkaadi-argumendi struktuuri täpse taastumise mõõtmiseks lausetest koos manustamisega. Analüüsisime kompchainide jaotust kolmes UD inglise keele puupangas EWT, GUM ja LinES, näidates, et need puupangad on hõredad seoses lausetega predikaadi-argumendi struktuuriga, mis sisaldab predikaadi-argumendi manustamist. Hindasime CoNLL 2018 Shared Task UDPipe (v1.2) baasmudeleid (sõltuvuse parsimine) EWT, GUMS ja LinES UD puupankade kompahelate klassifitseerijatena. Meie tulemused näitavad, et need kolm baasmudelit näitavad halvemat jõudlust lausete puhul, millel on predikaadi-argumendi struktuur, millel on rohkem kui üks manustamistase; kasutasime kompchaineid, et kirjeldada nende parserite tehtud vigu ja esitada näiteid parseri tehtud vigadest, mis tuvastati kompchainide abil. Analüüsisime ka kompahelate jaotumist 58 mitte-inglise UD puupangas ja seejärel kasutasime kompahelaid, et hinnata CoNLL'18 Shared Task baasmudelit iga puupanga jaoks. Meie analüüs näitab, et komplektide klassifitseerimise tulemuslikkus on ainult nõrgalt korrelatsioonis\nametlikud hindamismeetodid (LAS, MLAS ja BLEX). Me tuvastame lüngad komplektide jaotuses mitmes UD puupunktis, pakkudes seega tegevuskava, kuidas neid puupunkte täiendada. Lõpetuseks arutleme, kuidas komplektid pakuvad uut perspektiivi UD parserite treeningandmete vähesusele ning tulemusena saadud UD parsimiste täpsusele.", 'fi': "predikaatti-argumenttirakenteen tarkka palautuminen UD (Universal Dependency) -jäsentämisestä on keskeistä jatkovaiheen tehtävissä, kuten semanttisten roolien tai tapahtumaesitysten poimimisessa. Tämä tutkimus esittelee kompchaineja, jotka ovat UD-jäsennyksessä esiintyvien predikaattien riippuvuussuhteiden hierarkian kategorisointia. Komponenttiketjun luokittelun tarkkuus toimii proxynä predikaatti-argumenttirakenteen tarkan palautumisen mittaamiseen lauseista upotuksella. Analysoimme kompchainien jakautumista kolmessa UD English treebankissa, EWT, GUM ja LinES, ja paljastimme, että nämä puupankit ovat harvoja suhteessa lauseisiin, joissa predikaatti-argumentti rakenne sisältää predikaatti-argumentti upotuksen. Arvioimme CoNLL 2018 Shared Task UDPipe (v1.2) -perusmallin (riippuvuuden parsaus) kompchain luokittelijoina EWT-, GUMS- ja LinES UD -puupankeille. Tuloksemme osoittavat, että näillä kolmella perusmallilla on huonompi suorituskyky lauseilla, joissa predikaatti-argumenttirakenne on useampi kuin yksi upotustaso. Käytimme kompchaineja karakterisoimaan näiden jäsentäjien tekemiä virheitä ja esittämään esimerkkejä jäsentäjien tuottamista virheellisistä jäsentäjistä, jotka tunnistettiin kompchaineilla. Analysoimme myös kompchainien jakautumista 58:ssa ei-englantilaisessa UD-puupankissa ja käytimme kompchaineja arvioimaan CoNLL'18 Shared Task -perusmallia kullekin näistä puupankeista. Analyysimme osoittaa, että compchain-luokituksen suorituskyky korreloi vain heikosti\nviralliset arviointimittarit (LAS, MLAS ja BLEX). Havaitsemme puutteita komplekttiketjujen jakautumisessa useissa UD-puupankeissa, ja näin tarjoamme tiekartan siitä, miten näitä puita voidaan täydentää. Päätämme puheenvuoron keskustelemalla siitä, miten kompchainit tarjoavat uuden näkökulman UD-jäsentäjien harjoitustietojen niukkuuteen sekä tuloksena olevien UD-jäsentäjien tarkkuuteen.", 'bs': "Upravo je oporavak predikatne strukture argument a iz analize univerzalne zavisnosti (UD) centralno za smanjenje zadataka poput izvlačenja semantičkih uloga ili predstavljanja događaja. Ova studija predstavlja komplansiranje, kategoriju hijerarhije predikatnih odnosa ovisnosti koje su prisutne u analizu UD-a. Točnost klasifikacije kompchaina služi kao proksi za mjerenje tačnog oporavka strukture predikata argument a iz rečenica sa integracijom. Analizirali smo distribuciju kompchainsa na tri UD engleske trgovine, EWT, GUM i LinES, otkrivajući da su te trgovine rezervne u odnosu na rečenice sa predikatnem strukturom argumenta koja uključuje predikatne integracije argumenta. Procjenili smo modele podijeljenog zadatka UDPipe (v1.2) za početnu liniju (analizanje ovisnosti) CoNLL 2018 kao klasifikatore kompchaina za EWT, GUMS i LinES UD trgovine. Naši rezultati ukazuju na to da ove tri osnovne modela pokazuju siromašniju predstavu na rečenicama sa predikatnim strukturom argumenta sa više od jedne nivoe ugrađenja; Koristili smo komplansiranje kako bi karakterizirali greške koje su napravili ovi parseri i predstavili primjere grešnih parsera proizvođenih od strane analizatora koji su identifikovani koristeći komplansiranje. Također smo analizirali distribuciju kompchaina u 58 ne-engleskim UD treebancima i onda smo koristili kompchaine kako bi procijenili model podijeljenog zadatka CoNLL'18 za svaku od ovih treebancija. Naša analiza pokazuje da je izvedba u pogledu klasifikacije kompchaina slaba povezana sa\nzvanična procjena metrika (LAS, MLAS i BLEX). Identificiramo praznine u distribuciji kompchainsa u nekoliko UD-ovih trgovačkih granica, tako pružajući putnu mapu kako bi se ovi treebani mogli dodati. Zaključili smo razgovaranjem o tome kako komplanci pružaju novu perspektivu o isključivosti podataka obuke za UD analizatore, kao i preciznosti rezultatnih UD analiza.", 'cs': "Přesné obnovení struktury predikátů-argumentů z parsy univerzální závislosti (UD) je klíčové pro následné úlohy, jako je extrakce sémantických rolí nebo reprezentace událostí. Tato studie představuje kompchainy, kategorizaci hierarchie predikátových závislostních vztahů přítomných v UD parse. Přesnost klasifikace compchain slouží jako proxy pro měření přesného obnovení struktury predikátů-argumentů z vět s vložením. Analyzovali jsme distribuci kompchain ve třech UD anglických stromových bankách, EWT, GUM a LinES, a odhalili, že tyto stromové banky jsou řídké vzhledem k větám se strukturou predikátů, která zahrnuje vložení predikátů do argumentů. Vyhodnotili jsme základní modely CoNLL 2018 Shared Task UDPipe (v1.2) jako klasifikátory kompchain pro stromové banky EWT, GUMS a LinES UD. Naše výsledky ukazují, že tyto tři základní modely vykazují špatnější výkon u vět se strukturou predikátů argumentů s více než jednou úrovní vložení; K charakterizaci chyb těchto parserů jsme použili komponenty a prezentovali příklady chybných parserů vytvořených parserem, které byly identifikovány pomocí komponentů. Rovněž jsme analyzovali distribuci kompchainů v 58 neanglických UD stromových bázích a pak použili kompchainy k vyhodnocení základního modelu CoNLL'18 Shared Task pro každou z těchto stromových bází. Naše analýza ukazuje, že výkonnost s ohledem na klasifikaci kompchain je pouze slabě korelována s\noficiální hodnotící metriky (LAS, MLAS a BLEX). Identifikujeme mezery v distribuci kompchainů v několika UD stromových břehů, čímž poskytujeme plán pro doplnění těchto stromových břehů. Na závěr diskutujeme, jak kompchainy poskytují nový pohled na řídkost tréninkových dat pro UD parsery, stejně jako na přesnost výsledných UD parser.", 'jv': 'Print checkbox Genjer-Genjer Strikethrough Awak dhéwé éngleksi perusahaan tanggal winih karo perusahaan tanggal urip Uit dumateng, IWT, GIM lan Lines, menehi kowe ngupakan karo perusahaan karo perusahaan karo perusahaan sing dadi tanggal nggalakno karo perusahaan dumateng-atik dhéwé Awak dhéwé éntuk nggawe CoNLL 2008 shared task udPipe (V1.2) bazline (diphendisentasi aléntasi) model karo kompstring dipolesane nggo eWT, GIMP karo Lines udd traebangs Rejalaké awak dhéwé ngerti barang-barang telu model sing bisa ngomong gawe barang kelas barang kanggo kelas barang sampek karo perusahaan-argument sing wis luwih apik sing katya sampek sing luwih dumadhi; string" in "context_BAR_stringLink Awak dhéwé éntuk cara-cara kotak nggawe sapa tanggal ndherek wih-wih lan nganggo cara-cara kotak nggawe lan nambah wih-wih apik dhéwé nggawe model CoNLL\'18 Tarjamahan sing wis berarti barêng-barêng kuwi cara-barêng iki. Ndeleksyon awak dhéwé ngomong nik nggawe kesempatan kanggo kelas terakhir dhéwé kuwi duluran ngono', 'he': "התאוששות מדויקת של מבנה טיעון מוגדר ממחקר תלויות יוניברסליות (UD) היא מרכזית למשימות מתחתונות כמו החלץ של תפקידים סמנטיים או מייצג אירועים. This study introduces compchains, a categorization of the hierarchy of predicate dependency relations present within a UD parse.  Accuracy of compchain classification serves as a proxy for measuring accurate recovery of predicate-argument structure from sentences with embedding.  We analyzed the distribution of compchains in three UD English treebanks, EWT, GUM and LinES, revealing that these treebanks are sparse with respect to sentences with predicate-argument structure that includes predicate-argument embedding.  We evaluated the CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) models as compchain classifiers for the EWT, GUMS and LinES UD treebanks.  התוצאות שלנו מצביעות ששלושת הדוגמנים הבסיסיים האלה מראים ביצועים גרועים יותר על משפטים עם מבנה טיעון מוקדם השתמשנו בשרשרות כדי לתייצב את השגיאות שנעשו על ידי המעבדים האלה ולהציג דוגמאות של מעבדות שגויות שנוצרו על ידי המעבד שנזהו באמצעות השרשרות. We also analyzed the distribution of compchains in 58 non-English UD treebanks and then used compchains to evaluate the CoNLL'18 Shared Task baseline model for each of these treebanks.  הניתוח שלנו מראה שהביצועים בנוגע להקליזציה של compchain רק קשורים חלשים עם", 'ha': "Salon da shirin hagu na ɗabi'a daga parse na Universal Deƙaitacce (UD) na tsakiya zuwa taskõkin ƙarami kamar fitarwa na aikin semantic ko shiryoyin ayuka. Wannan littafin na ƙunsa da nauyi, wani category of the hierrchy of predefined dependanci wanda ke cikin wata parse na UD. Tilas na tsarin classifori na cikin shaƙƙi ya yi amfani da shi kamar wata proksi dõmin a ƙayyade kure na tsari mai daidaita na bakin-rubutu na-ɗabi'a daga cire da aka shigar da. Ba mu yi anayya da rabon sarƙoƙi uku na Ingiriya ta UD, EWT, GUM da LinES, kuma mun yi bayani da cewa waɗannan turbuɗe su yi sauri a cikin salon da ke ƙunsa da bakin rubutu wanda ke shiga Mun ƙaddara misãlai na CoNLL 2018 mai Shared Takar UD (v1.2) da suka zama samun samun samun sarƙoƙi wa EWT, GUM da LinES UD Treebanks. MatamayinMu na nũna cewa waɗannan misalin basalin mita uku sun nuna mafiya kwanza a kan sonar da bakin rubutun da ke ƙara daraja guda; we used compchains to characterize the errors made by these parsers and present examples of erroneous parses produced by the parser that were identified using compchains.  Mu yi anayyar da rabon sarƙoƙi a 58 na-Ingiriya na UD-Treebanks kuma muka yi amfani da sarƙoƙi dõmin an evaluce misalin babban aikin CoNLL'18 wanda aka Shara wa dukkan wannan Treebanks. AnayyayinMu yana nũna cewa aikin da aka yi wa fassarar sarƙoƙi kawai yana mai rauni da", 'sk': "Natančno obnovitev strukture predikatov-argumentov iz razčlenitve univerzalne odvisnosti (UD) je osrednjega pomena za nadaljnja opravila, kot je ekstrakcija semantičnih vlog ali predstavitev dogodkov. Ta študija uvaja kompchaine, kategorizacijo hierarhije predikatnih odvisnosti, prisotnih v razčlenitvi UD. Natančnost klasifikacije kompaktnih verig služi kot približek za merjenje natančnega obnovitve strukture predikatov-argumentov iz stavkov z vdelavo. Analizirali smo porazdelitev kompaktov v treh UD angleških treebanks, EWT, GUM in LinES, pri čemer smo razkrili, da so te dreebanke redke glede stavkov s strukturo predikat-argument, ki vključuje vdelavo predikat-argument. Ocenili smo osnovne modele CoNLL 2018 Shared Task UDPipe (v1.2) kot klasifikatorje kompozicijskih verig za drevesne zbirke EWT, GUMS in LinES UD. Naši rezultati kažejo, da so ti trije osnovni modeli slabši pri stavkih s strukturo predikatov-argumentov z več kot eno stopnjo vdelave; Za opredelitev napak, ki jih naredijo ti razčlenjevalniki, smo uporabili kompaktne verige in predstavili primere napačnih razčlenjevalnikov, ki jih je naredil razčlenjevalnik, ki so bile identificirane z uporabo kompaktnih verig. Analizirali smo tudi porazdelitev kompletnih verig v 58 ne-angleških UD treebanks in nato uporabili kompletne verige za oceno osnovnega modela CoNLL'18 Shared Task za vsako od teh treebanks. Naša analiza kaže, da je uspešnost pri klasifikaciji kompletnih verig le šibko korelacija z", 'bo': 'Accurate recovery of predicate-argument structure from a Universal Dependency (UD) parse is central to downstream tasks such as extraction of semantic roles or event representations. UD་ལྟ་ཞིབ་ཀྱི་ནང་དུ་ཡོད་པའི་སྒྲིག་རིམ་གྱི་དབྱེ་རིམ་གྱི་དབྱེ་སྟངས་དང་ཐོག་རིམ། Accuracy of compchain classification serves as a proxy for measuring accurate recovery of predicate-argument structure from sentences with embedding. We analyzed the distribution of compchains in three UD English treebanks, EWT, GUM and LinES, revealing that these treebanks are sparse with respect to sentences with predicate-argument structure that includes predicate-argument embedding. We evaluated the CoNLL 2018 Shared Task UDPipe (v1.2) baseline (dependency parsing) models as compchain classifiers for the EWT, GUMS and LinES UD treebanks. Our results indicate that these three baseline models exhibit poorer performance on sentences with predicate-argument structure with more than one level of embedding; and we used compchains to characterize the errors made by these parsers and present examples of erroneous parses produced by the parser that were identified using compchains. ང་ཚོས་དབྱིན་ཡིག་ཆ་མིན་པའི་བརྗོད་ཆེན་ཀྱི་བགོ་སྟངས་ཀྱང་58 རེད་ཅིག་གི་ནང་དུ་ཞིབ་དཔྱད་བྱས་ནས་བསྡུས་རི་(compchains)རྩིས་པ་འདི་རེ་རེར་བཞིན ང་ཚོའི་དབྱེ་ཞིབ་ཡིན་ན་མཛོད་ཁང་གི་དབྱེ་སྟངས་དང་མཐུན་རྐྱེན་འདྲེན་བྱེད་པའི་གོ་སྐབས་'}
{'en': 'Disentangling Online Chats with DAG-structured LSTMs', 'ar': 'فك تشابك الدردشات عبر الإنترنت باستخدام LSTMs المُنظَّمة من DAG', 'fr': 'Démêler les discussions en ligne avec les LSTM structurés par DAG', 'pt': 'Desembaraçar bate-papos online com LSTMs estruturados em DAG', 'es': 'Desenredar los chats en línea con LSTM estructurados por DAG', 'ja': 'DAG構造のLSTMによるオンラインチャットの分離', 'zh': '用 DAG 结构化 LSTM 解在线聊天', 'hi': 'DAG-संरचित LSTMs के साथ ऑनलाइन चैट को अलग करना', 'ru': 'Развязка онлайн-чатов со структурированными DAG LSTM', 'ga': 'Comhráite Ar Líne a Dhícheangal le LSTManna DAG-struchtúrtha', 'ka': 'DAG- სტრუქტურაციული LSTMs- თან ინლანეტიკური საუბარების გარეშე', 'el': 'Αποσύνδεση διαδικτυακών συνομιλιών με δομημένα LSTMs', 'hu': 'Az online csevegések eltávolítása DAG-strukturált LSTMekkel', 'it': 'Disentangling Chat Online con LSTMs strutturati DAG', 'mk': 'Name', 'lt': 'Disentangling Online Chats with DAG-structured LSTMs', 'kk': 'DAG- құрылған LSTMs арқылы онлайн сұхбаттарын шектеу', 'ml': 'Disentangling Online Chats with DAG-structured LSTMs', 'ms': 'Name', 'mt': 'Disentangling Online Chats ma’ LSTMs strutturati minn DAG', 'mn': 'DAG бүтээгдэхүүн LSTMs-тэй онлайн яриаг', 'pl': 'Rozdzielanie czatów online za pomocą LSTMów strukturalnych DAG', 'no': 'Name', 'ro': 'Descurajarea conversațiilor online cu LSTMs structurate DAG', 'si': 'DAG-සංවිධානය LSTMs සමඟ ඇන්ලයින් කතා කරනවා', 'sr': 'Razdvajanje Online Chats s DAG-structured LSTMs', 'so': 'Internetka Chats with DAG-structured LSTMs', 'sv': 'Avsluta onlinechattar med DAG-strukturerade LSTMs', 'ta': 'Name', 'ur': 'DAG-ساختہ LSTMs کے ساتھ آنلاین چیٹ ڈیٹانگل کر رہے ہیں', 'uz': 'Name', 'vi': 'Name=Liên kết nối kết nối với tập hợp DAG', 'bg': 'Разделяне на онлайн чатове с структурирани ЛСТМ', 'hr': 'Razdvajanje Online Chats s DAG-structured LSTMs', 'nl': 'Online chats ontkoppelen met LSTMs met DAG-structuur', 'da': 'Afbryde Online Chats med DAG-strukturerede LSTMs', 'de': 'Trennung von Online-Chats mit DAG-strukturierten LSTMs', 'ko': 'DAG 구조의 LSTM으로 온라인 채팅 분석', 'id': 'Disentangling Online Chats with DAG-structured LSTMs', 'fa': 'با ساخته شده LSTMs DAG صحبت\u200cهای آنلاین', 'tr': 'DAG-düzümlenmiş LSTMs bilen Online Chats goýulýar', 'af': 'Onbekende Onlinene geselste met DAG-struktureerde LSTMs', 'hy': 'Comment', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'sw': 'Kuzungumzia Mazungumzo ya Mtandaoni na Ujumbe wa LSTMs', 'bn': 'Name', 'az': 'DAG-qurulmuŇü LSTMs il…ô onlayn sohb…ôtl…ôrini √ß…ôkilir', 'bs': 'Razdvajanje Online Chats s DAG-structured LSTMs', 'sq': 'Disentangling Online Chats me DAG-structured LSTMs', 'cs': 'Odstranění online chatů s LSTMy strukturovanými DAG', 'et': 'Disentangling Online Vestlused DAG-struktureeritud LSTMs', 'fi': 'Disentangling Online Chats with DAG-structured LSTMs', 'ca': 'Disentangling Online Chats with DAG-structured LSTMs', 'ha': 'KCharselect unicode block name', 'sk': 'Disentangling Online Klepeti z DAG strukturiranimi LSTMs', 'jv': 'Gak-jejaring online conversations karo DaG-structural LA', 'he': 'שוחחים באינטרנט מתפרקים עם LSTM מבנה DAG', 'bo': 'DAG-structured LSTMs ཡི་གྲངས་སྤྱོད་མཁན་གྱི་གླེང་མོལ་སྒྲིག་འགོད་པ'}
{'en': 'Many modern messaging systems allow fast and synchronous textual communication among many users. The resulting sequence of messages hides a more complicated structure in which independent sub-conversations are interwoven with one another. This poses a challenge for any task aiming to understand the content of the chat logs or gather information from them. The ability to disentangle these conversations is then tantamount to the success of many downstream tasks such as summarization and question answering. Structured information accompanying the text such as user turn, user mentions, timestamps, is used as a cue by the participants themselves who need to follow the conversation and has been shown to be important for disentanglement. DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature. In this paper, we apply DAG-LSTMs to the conversation disentanglement task. We perform our experiments on the Ubuntu IRC dataset. We show that the novel model we propose achieves state of the art status on the task of recovering reply-to relations and it is competitive on other disentanglement metrics.', 'ar': 'تسمح العديد من أنظمة المراسلة الحديثة بالاتصال النصي السريع والمتزامن بين العديد من المستخدمين. يخفي تسلسل الرسائل الناتج بنية أكثر تعقيدًا حيث تتشابك المحادثات الفرعية المستقلة مع بعضها البعض. يشكل هذا تحديًا لأي مهمة تهدف إلى فهم محتوى سجلات الدردشة أو جمع المعلومات منها. إن القدرة على فصل هذه المحادثات هي إذن بمثابة نجاح للعديد من المهام النهائية مثل التلخيص والإجابة على الأسئلة. يتم استخدام المعلومات المنظمة المصاحبة للنص مثل دور المستخدم ، ويذكر المستخدم ، والطوابع الزمنية ، كإشارة من قبل المشاركين أنفسهم الذين يحتاجون إلى متابعة المحادثة وقد ثبت أنها مهمة لفك التشابك. تعد DAG-LSTMs ، وهي تعميم لـ Tree-LSTMs التي يمكنها التعامل مع التبعيات الحلقية الموجهة ، طريقة طبيعية لدمج هذه المعلومات وطبيعتها غير المتسلسلة. في هذه الورقة ، نطبق DAG-LSTMs على مهمة فك تشابك المحادثة. نجري تجاربنا على مجموعة بيانات Ubuntu IRC. نظهر أن النموذج الجديد الذي نقترحه يحقق حالة من الفن في مهمة استعادة علاقات الرد ، وهو تنافسي على مقاييس فك التشابك الأخرى.', 'es': 'Muchos sistemas de mensajería modernos permiten una comunicación textual rápida y sincrónica entre muchos usuarios. La secuencia de mensajes resultante esconde una estructura más complicada en la que las subconversaciones independientes se entretejen entre sí. Esto supone un desafío para cualquier tarea que pretenda comprender el contenido de los registros de chat o recopilar información de ellos. La capacidad de desenredar estas conversaciones equivale entonces al éxito de muchas tareas posteriores, como el resumen y la respuesta a preguntas. La información estructurada que acompaña al texto, como el turno del usuario, las menciones de los usuarios, las marcas de tiempo, es utilizada como una señal por los propios participantes que necesitan seguir la conversación y se ha demostrado que es importante para desenredar. Los DAG-LSTM, una generalización de Tree-LSTM que pueden manejar dependencias acíclicas dirigidas, son una forma natural de incorporar dicha información y su naturaleza no secuencial. En este artículo, aplicamos DAG-LSTM a la tarea de desenredar la conversación. Realizamos nuestros experimentos en el conjunto de datos IRC de Ubuntu. Demostramos que el nuevo modelo que proponemos alcanza un estado de vanguardia en la tarea de recuperar las relaciones de respuesta y es competitivo en otras métricas de desenredo.', 'pt': 'Muitos sistemas de mensagens modernos permitem comunicação textual rápida e síncrona entre muitos usuários. A sequência de mensagens resultante esconde uma estrutura mais complicada na qual subconversas independentes são entrelaçadas umas com as outras. Isso representa um desafio para qualquer tarefa com o objetivo de entender o conteúdo dos logs de bate-papo ou coletar informações deles. A capacidade de desembaraçar essas conversas equivale ao sucesso de muitas tarefas posteriores, como resumo e resposta a perguntas. Informações estruturadas que acompanham o texto, como turno do usuário, menções do usuário, timestamps, são usadas como uma dica pelos próprios participantes que precisam acompanhar a conversa e se mostraram importantes para o desembaraçamento. DAG-LSTMs, uma generalização de Tree-LSTMs que pode lidar com dependências acíclicas direcionadas, são uma maneira natural de incorporar essas informações e sua natureza não sequencial. Neste artigo, aplicamos DAG-LSTMs à tarefa de desemaranhamento de conversas. Realizamos nossos experimentos no conjunto de dados Ubuntu IRC. Mostramos que o novo modelo que propomos alcança status de estado da arte na tarefa de recuperar relações de resposta e é competitivo em outras métricas de desembaraço.', 'fr': "De nombreux systèmes de messagerie modernes permettent une communication textuelle rapide et synchrone entre de nombreux utilisateurs. La séquence de messages qui en résulte cache une structure plus complexe dans laquelle des sous-conversations indépendantes sont entrelacées les unes avec les autres. Cela pose un défi pour toute tâche visant à comprendre le contenu des journaux de discussion ou à recueillir des informations à partir de ceux-ci. La capacité à démêler ces conversations équivaut alors au succès de nombreuses tâches en aval telles que la synthèse et la réponse aux questions. Les informations structurées accompagnant le texte, telles que le tour de l'utilisateur, les mentions de l'utilisateur, les horodatages, sont utilisées comme signal par les participants eux-mêmes qui doivent suivre la conversation et se sont révélées importantes pour le démêlage. Les DAG-LSTM, une généralisation des Tree-LSTM qui peuvent gérer les dépendances acycliques dirigées, sont un moyen naturel d'incorporer de telles informations et leur nature non séquentielle. Dans cet article, nous appliquons les DAG-LSTM à la tâche de démêlage de conversation. Nous réalisons nos expériences sur le jeu de données IRC Ubuntu. Nous montrons que le nouveau modèle que nous proposons atteint un statut de pointe en matière de restauration des relations de réponse et qu'il est compétitif sur d'autres mesures de démêlage.", 'ru': 'Многие современные системы обмена сообщениями обеспечивают быструю и синхронную текстовую связь между многими пользователями. Результирующая последовательность сообщений скрывает более сложную структуру, в которой независимые подконференции переплетаются друг с другом. Это ставит под сомнение любую задачу, направленную на понимание содержания журналов чата или сбор информации из них. Способность распутать эти разговоры затем равносильна успеху многих последующих задач, таких как обобщение и ответы на вопросы. Структурированная информация, сопровождающая текст, такая как пользовательский поворот, упоминания пользователей, временные метки, используется в качестве сигнала самими участниками, которые должны следить за разговором, и, как было показано, имеет важное значение для отчуждения. DAG-LSTMs, обобщение Tree-LSTMs, которое может обрабатывать направленные ациклические зависимости, является естественным способом включения такой информации и ее непоследовательного характера. В этой статье мы применяем DAG-LSTM к задаче развязки разговора. Мы проводим эксперименты с набором данных Ubuntu IRC. Мы показываем, что предлагаемая нами новая модель достигает современного статуса по задаче восстановления ответных отношений и является конкурентоспособной по другим метрикам отчуждения.', 'ja': '多くの最新のメッセージングシステムは、多くのユーザ間の高速かつ同期的なテキスト通信を可能にする。 結果として生じる一連のメッセージは、独立したサブ会話が互いに織り交ぜられる、より複雑な構造を隠す。 これは、チャットログの内容を理解したり、チャットログから情報を収集したりすることを目的としたタスクにとって課題となります。 これらの会話の絡みを解く能力は、要約や質問への回答などの多くの下流タスクの成功に相当します。 ユーザーターン、ユーザーメンション、タイムスタンプなどのテキストに付随する構造化された情報は、会話をフォローする必要がある参加者自身によって手がかりとして使用され、解離に重要であることが示されています。 DAG - LSTMは、有向非巡回依存性を扱うことができるTree - LSTMの一般化であり、そのような情報とその非連続性を組み込むための自然な方法である。 本稿では、DAG - LSTMを会話解離タスクに適用する。 Ubuntu IRCデータセットで実験を行います。 私たちが提案する新規モデルは、返信関係を回復するタスクで最先端のステータスを達成し、他の解離指標で競争力があることを示しています。', 'zh': '诸见代消息传递系统许多用户间行速同步文本通信。 由是消息序隐更杂,独立相对相互交织。 此于知聊天记录、收信息者,皆挑战也。 故解此言之力,当众下之成功,如总而问之。 文本附结构化信息(如用户转,用户提及,时间)被须随对者参与者自用提示,且已证于解纠缠甚重。 DAG-LSTM 者, Tree-LSTM 之广也,可以处有向无环恃者,并此类而非顺序性之自然也。 本文,当用 DAG-LSTM 于会话离任。 于Ubuntu IRC数集上行实验。 吾言新颖形于复复之务为先进,而竞争力于他解缠指标。', 'hi': 'कई आधुनिक मैसेजिंग सिस्टम कई उपयोगकर्ताओं के बीच तेज और तुल्यकालिक पाठ्य संचार की अनुमति देते हैं। संदेशों का परिणामी अनुक्रम एक अधिक जटिल संरचना को छुपाता है जिसमें स्वतंत्र उप-वार्तालाप एक दूसरे के साथ जुड़े होते हैं। यह चैट लॉग की सामग्री को समझने या उनसे जानकारी एकत्र करने के उद्देश्य से किसी भी कार्य के लिए एक चुनौती है। इन वार्तालापों को अलग करने की क्षमता तब कई डाउनस्ट्रीम कार्यों की सफलता के समान है जैसे कि सारांश और प्रश्न उत्तर देना। उपयोगकर्ता बारी, उपयोगकर्ता उल्लेख, टाइमस्टैम्प जैसे पाठ के साथ संरचित जानकारी का उपयोग प्रतिभागियों द्वारा स्वयं एक क्यू के रूप में किया जाता है, जिन्हें वार्तालाप का पालन करने की आवश्यकता होती है और विघटन के लिए महत्वपूर्ण दिखाया गया है। DAG-LSTMs, ट्री-LSTMs का एक सामान्यीकरण जो निर्देशित acyclic निर्भरताओं को संभाल सकता है, ऐसी जानकारी और इसकी गैर-अनुक्रमिक प्रकृति को शामिल करने का एक प्राकृतिक तरीका है। इस पेपर में, हम वार्तालाप विघटन कार्य के लिए DAG-LSTMs लागू करते हैं। हम उबंटू आईआरसी डेटासेट पर अपने प्रयोग करते हैं। हम दिखाते हैं कि हम जिस उपन्यास मॉडल का प्रस्ताव करते हैं वह संबंधों के जवाब को पुनर्प्राप्त करने के कार्य पर कला की स्थिति प्राप्त करता है और यह अन्य विघटन मैट्रिक्स पर प्रतिस्पर्धी है।', 'ga': 'Ceadaíonn go leor córas teachtaireachtaí nua-aimseartha cumarsáid téacs tapa agus sioncronach i measc go leor úsáideoirí. Cuireann seicheamh na dteachtaireachtaí a bhíonn mar thoradh air sin struchtúr níos casta i bhfolach ina bhfuil fo-chomhrá neamhspleácha fite fuaite lena chéile. Cruthaíonn sé seo dúshlán d’aon tasc a bhfuil sé mar aidhm aige ábhar na logaí comhrá a thuiscint nó faisnéis a bhailiú uathu. Is ionann an cumas na comhráite seo a dhícheangal ansin agus an rath a bhí ar go leor tascanna iartheachtacha mar achoimre agus freagra ceisteanna. Úsáideann na rannpháirtithe féin, ar gá dóibh an comhrá a leanúint, faisnéis struchtúrtha a ghabhann leis an téacs ar nós seal an úsáideora, tagairtí úsáideora, stampaí ama, agus tá sé léirithe go bhfuil sé tábhachtach maidir le dícheangal. Is bealach nádúrtha iad DAG-LSTManna, ginearálú ar Chrann-LSTManna ar féidir leo spleáchais thimthriallach dhírithe a láimhseáil, chun faisnéis den sórt sin agus a nádúr neamhsheicheamhach a ionchorprú. Sa pháipéar seo, cuirimid DAG-LSTM i bhfeidhm ar an tasc dícheangail comhrá. Déanaimid ár dturgnaimh ar thacar sonraí Ubuntu IRC. Léirímid go mbaineann an tsamhail úrnua atá á mholadh againn stádas den scoth ar an tasc chun caidreamh freagra-ar-ais a ghnóthú agus go bhfuil sé iomaíoch ar mhéadrachtaí dícheangail eile.', 'ka': 'ბევრი მედინარე შეტყობინება სისტემისტის სისტემისტური კომუნიკაციას ძალიან ძალიან და სინქრონური მომხმარებელი. შემდეგ შეტყობინებების შემდეგ უფრო კომპლექტირებულია სტრუქტურა, რომელიც უფრო განსაზღვრებულია სტრუქტურაციები ერთმანეთისთვის შემდეგ ეს ყველა დავალებისთვის განსაზღვრება, რომელიც უნდა იცოდეთ საუბრალობა ლოგიების შესახებ, ან შეიძლება ისინი ინფორმაციას დაიყენოთ. ამ პარამეტრების შესაძლებლობა გადასრულება არის შემდეგ რამდენიმე დაკავშირებული საქმედების წარმატებით, როგორც კითხვა და გეგონის პარამეტრებით. სტრუქტურაციული ინფორმაცია, როგორც მომხმარებელი დაბრუნდება, მომხმარებელი ამოხსენება, დროის მონიშვნები, გამოიყენება, როგორც თავიდან მოთავსებელი, რომლებიც საჭირო პარამეტრების შემ DAG-LSTMs, სახე-LSTMs-ის გენერალიზაცია, რომელიც შეუძლიათ გადაწყენოთ მიერ აციკლიკური დასაწყვებულებები, არის სახელური გზა, რომელიც ასეთი ინფორმაცია და მისი არასწორი სახელს. ამ დოკუნტში, ჩვენ DAG-LSTMs დავყენებთ პარამეტრების გადაწყვეტილება. ჩვენ გავაკეთებთ ჩვენი ექსპერიმენტები Ubuntu IRC მონაცემების შესახებ. ჩვენ ჩვენ აჩვენებთ, რომ პრომენტის მოდელს, რომელიც ჩვენ მინდომა, სურათების სტატისტატისტატისტატისტატისტატისტატისტატისტატისტატისტატისტატისტა', 'el': 'Πολλά σύγχρονα συστήματα μηνυμάτων επιτρέπουν γρήγορη και συγχρονισμένη γραπτή επικοινωνία μεταξύ πολλών χρηστών. Η ακολουθία μηνυμάτων που προκύπτει κρύβει μια πιο περίπλοκη δομή στην οποία οι ανεξάρτητες υποσυνομιλίες συνυφαίνονται μεταξύ τους. Αυτό αποτελεί πρόκληση για κάθε εργασία που στοχεύει στην κατανόηση του περιεχομένου των αρχείων καταγραφής συνομιλίας ή τη συλλογή πληροφοριών από αυτά. Η ικανότητα να αποσυνδεθούν αυτές οι συζητήσεις ισοδυναμεί με την επιτυχία πολλών μεταγενέστερων εργασιών, όπως η σύνοψη και η απάντηση σε ερωτήσεις. Οι δομημένες πληροφορίες που συνοδεύουν το κείμενο, όπως η στροφή χρήστη, οι αναφορές χρηστών, οι χρονοσφραγίδες, χρησιμοποιούνται ως ένδειξη από τους ίδιους τους συμμετέχοντες που πρέπει να ακολουθήσουν τη συζήτηση και έχουν αποδειχθεί σημαντικές για την αποσύνδεση. Τα ΔΕΔ-ΔΕΔ, μια γενίκευση των Δέντρου-ΔΕΔ που μπορούν να χειριστούν κατευθυνόμενες ακυκλικές εξαρτήσεις, είναι ένας φυσικός τρόπος ενσωμάτωσης τέτοιων πληροφοριών και της μη διαδοχικής φύσης τους. Σε αυτή την εργασία, εφαρμόζουμε στην εργασία αποσύνδεσης συνομιλίας. Κάνουμε τα πειράματά μας στο σύνολο δεδομένων Ubuntu IRC. Αποδεικνύουμε ότι το νέο μοντέλο που προτείνουμε επιτυγχάνει κατάσταση τελευταίας τεχνολογίας όσον αφορά την ανάκτηση των σχέσεων ανταπόκρισης και είναι ανταγωνιστικό σε άλλες μετρήσεις αποσύνδεσης.', 'hu': 'Számos modern üzenetküldő rendszer lehetővé teszi a gyors és szinkron szöveges kommunikációt sok felhasználó között. Az így kapott üzenetek sorozata bonyolultabb struktúrát rejt el, amelyben a független albeszélgetések összefonódnak egymással. Ez kihívást jelent minden olyan feladatnál, amelynek célja a chat naplók tartalmának megértése vagy információgyűjtése. Az ilyen beszélgetések összekapcsolásának képessége ekkor sok downstream feladat sikerével egyenértékű, mint például az összefoglalás és a kérdések megválaszolása. A szöveget kísérő strukturált információkat, mint például a felhasználói fordulat, a felhasználói említések, időbélyegek, jelzésként használják azok a résztvevők, akiknek követniük kell a beszélgetést, és bizonyítottan fontosnak bizonyultak a megismertetés szempontjából. A DAG-LSTMs, a Tree-LSTMs általánosítása, amely képes kezelni az irányított aciklikus függőségeket, természetes módja az ilyen információk beépítésének és nem szekvenciális természetének. Ebben a tanulmányban DAG-LSTMeket alkalmazunk a beszélgetések megszüntetésére. Kísérleteinket Ubuntu IRC adatkészleten végezzük el. Megmutatjuk, hogy az általunk javasolt újszerű modell a válaszreakciós kapcsolatok visszaállításának feladatában a legkorszerűbb státuszt éri el, és versenyképes más szétosztási mutatókkal szemben.', 'kk': 'Көп қазіргі хабарлау жүйелері көп пайдаланушылардың арасында тез және қадамдастырылған мәтіндік байланыстарын мүмкіндік береді. Хаттардың соңындағы реті көптеген құрылымын жасыру үшін тәуелсіз ішкі сөйлемелер бір-бірімен біріктіріледі. Бұл сұхбат журналының мазмұнын түсінуге немесе олардан мәліметті жинау үшін кез келген тапсырма үшін мәселе береді. Бұл сұрақтарды бөліп тастауға мүмкіндік болады, содан кейінгі көпшілік тапсырмалардың сұрақтар және сұрақтар жауабына сәтті болады. Пайдаланушының ауыстыру, пайдаланушының атауы, уақыт белгілері секілді мәтіннің қосымша құрастырылған мәліметі, сұхбаттауын қарау керек және бұл белгілер үшін маңызды деп көрсетіледі. DAG-LSTMs, бұл мәліметті және оның келесі тәуелсіздіктерін басқаруға болатын ағаш- LSTMs жалпы түрлендіру - табиғи жолы. Бұл қағазда, DAG-LSTMs сұхбаттау тапсырмасына қолданып тұрмыз. Біз Ubuntu IRC деректер жиынында тәжірибелерімізді орындаймыз. Біз жауап қатынастарды қайталау тапсырмасының жаңа моделінің күйін жеткізу үшін қолданатын жаңа моделінің күйін көрсету үшін көрсетедік. Бұл басқа метрикалық күйінде әсер етеді.', 'mk': 'Многу модерни системи за пораки овозможуваат брза и синхронична текстуална комуникација меѓу многу корисници. Резултатната секвенца на пораки крие покомплицирана структура во која независните под-разговори се меѓусебно поврзани. This poses a challenge for any task aiming to understand the content of the chat logs or gather information from them.  The ability to disentangle these conversations is then tantamount to the success of many downstream tasks such as summarization and question answering.  Structured information accompanying the text such as user turn, user mentions, timestamps, is used as a cue by the participants themselves who need to follow the conversation and has been shown to be important for disentanglement.  DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature.  Во овој весник, применуваме DAG-LSTMs на задачата на разговорот за разделување. Ги спроведуваме нашите експерименти на Ubuntu IRC датотеките. We show that the novel model we propose achieves state of the art status on the task of recovering reply-to relations and it is competitive on other disentanglement metrics.', 'it': "Molti moderni sistemi di messaggistica consentono una comunicazione testuale veloce e sincrona tra molti utenti. La sequenza risultante di messaggi nasconde una struttura più complicata in cui sotto-conversazioni indipendenti si intrecciano tra loro. Ciò rappresenta una sfida per qualsiasi attività volta a comprendere il contenuto dei registri di chat o a raccogliere informazioni da essi. La capacità di districare queste conversazioni equivale quindi al successo di molti compiti a valle come la sintesi e la risposta alle domande. Le informazioni strutturate che accompagnano il testo, come user turn, user mentions, timestamp, sono utilizzate come spunto dai partecipanti stessi che hanno bisogno di seguire la conversazione e si sono rivelate importanti per lo sconvolgimento. DAG-LSTMs, una generalizzazione di Tree-LSTMs in grado di gestire dipendenze acicliche dirette, sono un modo naturale per incorporare tali informazioni e la sua natura non sequenziale. In questo articolo, applichiamo DAG-LSTMs al compito di disinvestimento della conversazione. Eseguiamo i nostri esperimenti sul set di dati IRC Ubuntu. Mostriamo che il nuovo modello che proponiamo raggiunge lo stato dell'arte sul compito di recuperare le relazioni di risposta ed è competitivo su altre metriche di disantanglement.", 'lt': 'Daugelis šiuolaikinių pranešimų sistemų leidžia greitą ir sinchroninį tekstinį ryšį tarp daugelio naudotojų. Atitinkama pranešimų seka slepia sudėtingesnę struktūrą, kurioje tarpusavyje sujungiami nepriklausomi pokalbiai. This poses a challenge for any task aiming to understand the content of the chat logs or gather information from them.  The ability to disentangle these conversations is then tantamount to the success of many downstream tasks such as summarization and question answering.  Tekstą lydinčią struktūrinę informaciją, pavyzdžiui, naudotojo apsisukimą, naudotojo paminėjimus, laiko ženklus, naudoja patys dalyviai, kurie turi sekti pokalbį ir įrodyta, kad jie yra svarbūs atsiejimui. DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature.  Šiame dokumente mes taikome DAG-LSTM pokalbio išskyrimo užduotį. Atliekame eksperimentus Ubuntu IRC duomenų rinkinyje. We show that the novel model we propose achieves state of the art status on the task of recovering reply-to relations and it is competitive on other disentanglement metrics.', 'ms': 'Many modern messaging systems allow fast and synchronous textual communication among many users.  Jujukan mesej yang menghasilkan menyembunyikan struktur yang lebih rumit di mana subperbualan independen saling berkaitan. Ini merupakan cabaran bagi setiap tugas yang bertujuan untuk memahami kandungan log sembang atau mengumpulkan maklumat daripadanya. Kemampuan untuk melepaskan perbualan ini kemudian bersamaan dengan kejayaan banyak tugas turun seperti ringkasan dan jawapan soalan. Maklumat struktur yang menyertai teks seperti putaran pengguna, sebutan pengguna, setem masa, digunakan sebagai isyarat oleh peserta sendiri yang perlu mengikut perbualan dan telah dipaparkan sebagai penting untuk pengeluaran. DAG-LSTMs, penerbangan pepohonan-LSTMs yang boleh mengendalikan dependensi aksiklik direksi, adalah cara biasa untuk menggabungkan maklumat seperti itu dan sifat bukan-sequential. Dalam kertas ini, kami melaksanakan DAG-LSTMs untuk tugas pembincangan. We perform our experiments on the Ubuntu IRC dataset.  Kami menunjukkan bahawa model novel yang kami cadangkan mencapai status seni pada tugas untuk mengembalikan jawapan-kepada hubungan dan ia adalah kompetitif pada metrik pelepasan lain.', 'mt': "Many modern messaging systems allow fast and synchronous textual communication among many users.  Is-sekwenza ta’ messaġġi li tirriżulta taħbi struttura aktar ikkumplikata li fiha s-sottokonverżjonijiet indipendenti huma interwoven ma’ xulxin. Dan joħloq sfida għal kwalunkwe kompitu bil-għan li jifhem il-kontenut tal-logs taċ-chat jew jiġbor informazzjoni minnhom. L-abbiltà li dawn il-konverżjonijiet jitneħħew imbagħad hija daqs is-suċċess ta’ ħafna kompiti downstream bħas-sommarju u t-tweġibiet għall-mistoqsijiet. L-informazzjoni strutturata li takkumpanja t-test bħalma huma d-dawra tal-utent, is-semmiet tal-utent, it-timbri taż-żmien, tintuża bħala sinjal mill-parteċipanti nfushom li jeħtieġu jsegwu l-konverżjoni u ntwera li hija importanti għa ż-żarmar. DAG-LSTMs, ġeneralizzazzjoni ta’ Tree-LSTMs li jistgħu jimmaniġġjaw dipendenzi a ċikliċi diretti, huma mod naturali biex tinkorpora tali informazzjoni u n-natura mhux sekwenzjali tagħha. F’dan id-dokument, aħna napplikaw DAG-LSTMs għall-kompitu ta’ diżantegrazzjoni tal-konverżjoni. Aħna nagħmlu l-esperimenti tagħna fuq is-sett tad-dejta tal-IRC tal-Ubuntu. Aħna nuru li l-mudell il-ġdid li qed nipproponu jikseb l-istatus l-aktar avvanzat fil-kompitu tal-irkupru tar-reazzjonijiet għar-relazzjonijiet u huwa kompetittiv fuq metriċi oħra ta' diżantegrazzjoni.", 'mn': 'Олон орчин үеийн захиргааны системүүд олон хэрэглэгчдийн хооронд хурдан, хурдан харилцааны холбоотой байдаг. Үүний үр дүнд захиргааны дарааллаар илүү төвөгтэй бүтэц нуугддаг. Тэнд хамааралтай суб-ярилцлагууд хоорондоо хоорондоо хоорондоо холбоотой. Энэ нь ямар нэгэн ажлын тухай сорилт бий болгодог бөгөөд тэднээс мэдээллийг цуглуулах боломжтой. Эдгээр ярилцлагуудыг тодорхойлж чадах чадвар нь тодорхойлолт, асуулт хариулт гэх мэт олон доорх үйл ажиллагуудын амжилтын адил. Хэрэглэгчийн эргэлтэй, хэрэглэгчийн хэлэлцээг, цаг хугацааны тэмдэглэгчид өөрсдөө яриаг дагах шаардлагатай хүмүүсийн тэмдэглэл болгон ашигладаг. DAG-LSTMs, салбарын хамааралтай байдлыг зохицуулж чадах мод-LSTMs-ийн ерөнхийлөгчийн хувьд ийм мэдээлэл болон эцсийн байдлыг нэгтгэх байгалийн арга юм. Энэ цаасан дээр бид DAG-LSTMs-г ярилцлаганд буруутгах үйл ажилд хэрэглэдэг. Бид Ubuntu IRC өгөгдлийн санд туршилтыг хийдэг. Бид шинэ загварын загвар нь харилцааны хариултыг сэргээх үйл явдалд урлагийн статусыг гаргаж чадна гэдгийг харуулж байна. Энэ нь бусад бусад зүйлсийн хэмжээнд өрсөлдөг.', 'ml': 'ധാരാളം ആധുനിക സന്ദേശ സിസ്റ്റത്തില്\u200d പെട്ടെന്നും സിന്ക്രോണിസ് ടെക്സ്കൂളില്\u200d വേഗത്തിലും സംയോജകം  സന്ദേശങ്ങളുടെ ഫലമായ സംവിധാനം കൂടുതല്\u200d സങ്കീര്\u200dണ്ണമായ ഒരു ഘടകം ഒളിപ്പിച്ചിരിക്കുന്നു. അതില്\u200d സ്വാതന്ത്ര്യ സംസാരം  ചാറ്റ് ലോഗിന്റെ ഉള്ളടക്കങ്ങള്\u200d മനസ്സിലാക്കുവാനോ അല്ലെങ്കില്\u200d അവയില്\u200d നിന്നും വിവരങ്ങള്\u200d സൂക്ഷിക്കാനോ ഉദ ഈ സംസാരം തടഞ്ഞുനിര്\u200dത്താനുള്ള കഴിവ് പിന്നീട് നദിയിലെ പല ജോലികളുടെയും വിജയത്തിന്റെയും വിജയത്തിന്റെയും കാരണമാണ്. ഉപയോക്താവിന്റെ തിരിച്ചറിയുന്നത്, ഉപയോക്താവിന്റെ പേരുകള്\u200d, സമയ സ്റ്റാമ്പുകള്\u200d എന്ന പങ്കാളികള്\u200d സ്വയം സംസാരിക്കേണ്ടതുണ്ട്. സംസാരം പിന്തുടര DAG-LSTMs, നേര്\u200dവഴിയിലുള്ള ആശ്രയം കൈകാര്യം ചെയ്യാന്\u200d സാധ്യതയാണ് ഈ വിവരങ്ങളെയും അതിന്റെ പ്രകൃതിയെയും ചേര്\u200dക്കാന്\u200d കഴിയുന്നത്. ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഡിജി-എല്\u200dസ്റ്റിമിസിനെ സംസാരിക്കുന്നത് സംസാരിക്കാന്\u200d പോകുന്നു. ഉബുണ്ടു ഐആര്\u200dസി ഡാറ്റാസെറ്റില്\u200d നമ്മുടെ പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. നമ്മള്\u200d കാണിക്കുന്നു നോവല്\u200d മോഡല്\u200d നമ്മുടെ പ്രോദേശിപ്പിക്കുന്ന കലാകാര്യത്തിന്റെ അവസ്ഥ പൂര്\u200dത്തിയാക്കുന്നത്, ബന്ധങ്ങള്\u200dക്ക് ഉത', 'pl': 'Wiele nowoczesnych systemów wiadomości umożliwia szybką i synchroniczną komunikację tekstową pomiędzy wieloma użytkownikami. Powstała sekwencja wiadomości ukrywa bardziej skomplikowaną strukturę, w której niezależne podrozmowy są ze sobą splecione. Stanowi to wyzwanie dla każdego zadania mającego na celu zrozumienie zawartości dzienników czatu lub zebranie z nich informacji. Możliwość rozłączenia tych rozmów jest zatem równoznaczna z sukcesem wielu dalszych zadań, takich jak podsumowanie i odpowiedź na pytania. Strukturalne informacje towarzyszące tekstowi, takie jak turn użytkownika, wzmianki użytkownika, znaczniki czasu, są używane jako wskazówki przez samych uczestników, którzy muszą śledzić rozmowę i okazały się ważne dla rozłączenia. DAG-LSTMs, uogólnienie Tree-LSTMs, które mogą obsługiwać ukierunkowane zależności acykliczne, są naturalnym sposobem na włączenie takich informacji i jej niesekwencyjnego charakteru. W niniejszym artykule stosujemy DAG-LSTMy do zadania rozłączania rozmowy. Wykonujemy nasze eksperymenty na zbiorze danych Ubuntu IRC. Pokazujemy, że proponowany przez nas nowatorski model osiąga status najnowocześniejszej jakości w zakresie odzyskiwania relacji odpowiedzi-na i jest konkurencyjny w stosunku do innych wskaźników rozłączenia.', 'ro': 'Multe sisteme moderne de mesagerie permit comunicarea textuală rapidă și sincronă între mulți utilizatori. Secvența de mesaje rezultată ascunde o structură mai complicată în care subconversațiile independente sunt interconectate unul cu altul. Acest lucru reprezintă o provocare pentru orice sarcină care urmărește să înțeleagă conținutul jurnalelor de chat sau să colecteze informații de la acestea. Abilitatea de a dezlega aceste conversații echivalează apoi cu succesul multor sarcini din aval, cum ar fi rezumarea și răspunsul la întrebări. Informațiile structurate care însoțesc textul, cum ar fi rândul utilizatorului, mențiunile utilizatorilor, timestamps, sunt folosite ca un indiciu de către participanții înșiși care au nevoie să urmeze conversația și s-a dovedit a fi importante pentru dezcunoaștere. DAG-LSTMs, o generalizare a Tree-LSTMs care poate gestiona dependențele aciclice direcționate, sunt o modalitate naturală de a încorpora astfel de informații și natura sa non-secvențială. În această lucrare, aplicăm DAG-LSTMs la sarcina de desprindere a conversației. Efectuăm experimentele noastre pe setul de date IRC Ubuntu. Aratăm că modelul nou pe care îl propunem atinge statutul de ultimă oră în ceea ce privește recuperarea relațiilor de răspuns și este competitiv în ceea ce privește alte măsuri de dezcunoaștere.', 'sr': 'Mnogi moderni sistemi poruke omogućavaju brzu i sinhronosnu tekstualnu komunikaciju među mnogim korisnicima. Rezultativna sekvencija poruka sakriva komplikovaniju strukturu u kojoj su nezavisniji podrazgovori međusobni. Ovo predstavlja izazov za svaki zadatak koji cilja razumeti sadržaj dnevnika razgovora ili skupljati informacije od njih. Sposobnost da se raskinemo tih razgovora je onda is to sa uspjehom mnogih donjeg zadataka kao što su sažetanje i odgovor na pitanje. Strukturirane informacije koje se pridružuju tekstu kao što je korisnik okrenuo, spominjao je korisnik, timestamp, koriste se kao znak samih sudionika koji moraju pratiti razgovor i pokazali su da je važno za raspuštanje. DAG-LSTMs, generalizacija drveta-LSTMs koja može podnijeti direktne akcikličke zavisnosti, su prirodan način da uključuje takve informacije i njenu neprekvenu prirodu. U ovom papiru, primjenjujemo DAG-LSTMs na zadatak razgovora o raspuštanju. Izvodimo eksperimente na setu podataka Ubuntu IRC-a. Pokazujemo da novi model koji predlažemo postiže stanje umjetnosti na zadatku oporavljanja odgovora na odnose i da je konkurentna na drugim metrikama rastajanja.', 'si': 'ගොඩක් අධ්\u200dයාත්මක පණිවිඩය පද්ධතිය පද්ධතිය ඉක්මනින් සහ සම්බන්ධ පද්ධතිය ප්\u200dරයෝජකයෙන පණිවිඩයේ ප්\u200dරතිචාර පණිවිඩය හැංගිලා තියෙන්නේ වඩා සංශ්\u200dය සංවිධානයක් තියෙන්නේ, ඒ වගේම ස්ව මේක ප්\u200dරශ්නයක් තියෙන්නේ කිසිම වැඩක් වෙනුවෙන් සම්බන්ධ වෙනුවෙන් ප්\u200dරශ්නයක් තියෙන්නේ කතාවාට මේ සංවාදයක් විනාශ කරන්න පුළුවන් තමයි පස්සේ ප්\u200dරශ්න ප්\u200dරතිච්චාරය සහ ප්\u200dරශ්න ප්\u200dරතිච්චාරය සමහර වි සම්බන්ධතා තොරතුරු සම්බන්ධ වෙනුවෙන් පාළුවෙන් පරිවර්තනය, ප්\u200dරයෝජකයෙන් පරිවර්තනය, වෙලාවක් කියවන්න, වෙලාවක් තොරතුරු වලින DAG-LSTMs, ගස් LSTMs ගේ සාමාන්\u200dය විශ්වාස කරන්න පුළුවන් සාමාන්\u200dය විශ්වාසයක්, ඒ වගේ තොරතුරු සම්බන්ධ කරගන්න ස්වභාවික විදියක්  මේ පැත්තට, අපි DAG-LSTMs වැඩ කරන්නේ කතාව විනාශ කරනවා කාර්යය. අපි ඔබුන්ටුන් IRC දත්ත සෙට් එකේ අපේ පරීක්ෂණය කරන්න. අපි පෙන්වන්නේ අපි ප්\u200dරශ්නයක් කලින් ස්ථිතියේ ක්\u200dරියාත්මක විදියට ප්\u200dරතිච්චාරය සම්බන්ධ වෙනුවෙන් ප්\u200dරතිචාරයක් ප', 'so': "Isticmaalayaal badan oo ka mid ah nidaamka xafiiska la soo diro waxay u ogolaan karaan macluumaad dhaqso ah oo la xiriira qoraalka. Suurka soo socda waxey qarisaa dhismo ka adag, kaas oo ay iskala xiriiraan hadal iskaa'aan ah. This poses a challenge for any task aiming to understand the content of the chat logs or gather information from them.  Awooyinka hadalladan waa suurtagalka shaqaalaha hoose badan, sida summarinta iyo jawaabta su'aalaha. Macluumaad dhisan oo ku jira qoraalka, tusaale ahaan dib u jeeda isticmaalayaasha, hadalka isticmaalayaasha, waqtiga, waxaa loo isticmaalaa kuwa ka qayb gala oo u baahan inay raacaan hadalka islamarkaasna loo muujiyey inay muhiim u tahay in ay jiraan. DAG-LSTMs, qori-LSTMs oo u dhaqan kara ku saabsan hagaajinta akykliska, waa qaab dabiicadda ah oo la soo gelin karo macluumaadkaas iyo dabiicadiisa aan ka dambeyn. Warqadan ayaannu DAG-LSTMs ugu codsanaynaa shaqada ka baaraandegista. Imtixaanadeena ayaannu ku sameynaa shabakada macluumaadka Ubuntu IRC. Waxaynu muujinnaa in qaababka warqadda ee aan soo jeedno uu dhamaado xaaladda farshaxanka oo ku saabsan in loo soo celiyo jawaabta xiriirka iyo in uu ku adag yahay qalabka kale.", 'sv': 'Många moderna meddelandesystem möjliggör snabb och synkron textkommunikation mellan många användare. Den resulterande sekvensen av meddelanden döljer en mer komplicerad struktur där oberoende underkonversationer vävs samman med varandra. Detta innebär en utmaning för alla uppgifter som syftar till att förstå innehållet i chattloggar eller samla in information från dem. Förmågan att lösa upp dessa samtal är då detsamma som framgången för många nedströmsuppgifter som sammanfattning och frågesvar. Strukturerad information som medföljer texten såsom användarsväng, användaromnämnanden, tidsstämplar används som signal av deltagarna själva som behöver följa samtalet och har visat sig vara viktig för att ta bort samtalet. DAG-LSTMs, en generalisering av Tree-LSTMs som kan hantera riktade acykliska beroenden, är ett naturligt sätt att införliva sådan information och dess icke-sekventiella natur. I den här uppsatsen tillämpar vi DAG-LSTMs på samtalsuppgiften. Vi utför våra experiment på Ubuntu IRC dataset. Vi visar att den nya modellen vi föreslår uppnår toppmodern status när det gäller uppgiften att återställa respons-to-relationer och den är konkurrenskraftig på andra disenglement metrics.', 'ta': 'Many modern messaging systems allow fast and synchronous text communication among many users. முடிவு செய்திகளின் வரிசையில் ஒரு சிக்கலான கட்டத்தை மறை இது அரட்டை பதிவுகளின் உள்ளடக்கத்தை புரிந்து கொள்ள எந்த செயலுக்கும் சவால் கொடுக்கிறது அல்லது அவற்றிலிருந் இந்த பேச்சுகளை தடுக்க முடியும் ஆற்றல் பின்னர் கீழே நீர் பணிகளின் வெற்றியை பார்த்துக் கொள்ளும் சுருக்குதல் மற்றும்  Structured information accompanying the text such as user turn, user mentions, timestamps, is used as a cue by the participants themselves who need to follow the conversation and has been shown to be important for disentanglement.  DAG-LSTMs, நேர்வழி acyclic சார்புகளை கையாள முடியும் மரத்தின் LSTMs ஒரு பொதுவாக்கம், இவ்வாறு தகவல் மற்றும் அதன் பின்வரும் இயற்கையில்லாத இயற்கையை ஒன இந்த காகிதத்தில், நாம் DAG-LSTMs பயன்படுத்துகிறோம் பேச்சு இடைமாற்றும் பணிக்கு. உபுண்டு ஐஆர்சி தரவுத்தளத்தில் எங்கள் சோதனைகளை நாம் செய்கிறோம். நாங்கள் பரிந்துரைக்கும் புதிய மாதிரி கலை நிலையை பெறுகிறது என்பதை காட்டுகிறோம் மற்றும் தொடர்புக்கு பதில் மீட்டும் பணியில் மற்ற', 'ur': 'بہت سی مدرنی پیغام رسانے سیسٹم بہت سی کارساز کے درمیان تیز اور سینکرون پیغام رسانے کی اجازت دیتے ہیں. پیغام کے نتیجے کی سفارش ایک پیچیدہ ساختار کو چھپاتا ہے جہاں ایک دوسرے کے ساتھ مستقل صحبت کرنے والی ہے. یہ ہر کام کے لئے ایک چال مقرر کرتا ہے جس کا مطابق ہے کہ چٹیٹ لاگ کے منصوبات کو سمجھ سکیں یا ان سے معلومات جمع کریں. یہ باتوں کو ٹیڑھا دینے کی قابلیت اس کے بعد بہت سی نیچے کاموں کی موفقیت کے برابر ہے جیسے جمع اور سوال جواب دینے کی۔ پیغام کے ساتھ ساختہ معلومات جیسے استعمال کرتا ہے، استعمال کرتا ہے، تایمٹمپ کرتا ہے، اپنے مشرکوں کی نشانی کے طور پر استعمال کئے جاتے ہیں جو بات کے پیچھے چلنے کی ضرورت رکھتے ہیں اور ان کے لئے اہم بات دکھائی جاتی ہے۔ DAG-LSTMs، درخت-LSTMs کی ایک عمومی تعلیم ہے جو سیرکٹی سیرکٹی اعتباری کا تحمل کر سکتا ہے، یہ ایک طبیعی طریقہ ہے کہ اس کی اطلاعات اور اس کی غیر تعریف کے طور پر شامل کرے۔ اس کاغذ میں ہم DAG-LSTMs کو مکالمانی غلطی کے کام پر لازم کرتے ہیں. ہم Ubuntu IRC ڈیٹ سٹ پر اپنی آزمائش کریں۔ ہم نشان دیتے ہیں کہ یہ نئی موڈل جو ہم پیشنهاد کرتے ہیں ان کے معاملہ میں جواب دینے کے لئے ارتباط کی موقعیت پہنچ جاتی ہے اور یہ دوسری غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر', 'no': 'Mange moderne meldingssystemer tillèt rask og synkronisert tekstkommunikasjon mellom mange brukarar. Det følgjande rekkjefølgja meldingar gøymmer ei meir komplisert struktur der uavhengige undersamtaler vert omvendt med ein annan. Dette viser eit utfordring for alle oppgåver som må forstå innhaldet i samtaleloggane eller samla informasjon frå dei. Kvittet for å forkasta desse samtalene er så mykje suksess på mange nedstrekkoppgåver som sammendrag og spørsmålssvar. Strukturerte informasjon som vedlegg til teksten som brukaren slår på, brukaramn, tidspunktar, vert brukt som eit markør av dei deltakarane sjølv som treng følgja samtalen og er vist som viktig for å forstørra. DAG-LSTMs, ein generellisering av tre-LSTMs som kan handtere direkte aksikliske avhengighet, er ein naturleg måte å inkludere slike informasjon og den ikkje-sekvensiske naturen. I denne papiret bruker vi DAG-LSTMs til samtale-disentasjonsoppgåva. Vi utfører eksperimentene våre på Ubuntu IRC-datasettet. Vi viser at den novele modellen vi foreslår er tilstand til kunststatusen på oppgåva for å gjenoppretta svar til forholdet og det er konkurrentivt på andre forsvingsmetrikar.', 'vi': 'Nhiều hệ thống tin nhắn hiện đại cho phép kết nối kết cấu nhanh và đồng bộ giữa nhiều người dùng. Kết quả của chuỗi các tin nhắn che dấu một cấu trúc phức tạp hơn nơi các cuộc trò chuyện riêng được đan vào nhau. Đây là thách thức cho bất kỳ nhiệm vụ nào nhằm mục đích hiểu nội dung của các bản ghi chat hoặc thu thập thông tin từ chúng. Khả năng tách rời những cuộc nói chuyện này là một thành công của nhiều công việc xuôi dòng như việc tổng kết và câu hỏi trả lời. Thông tin cấu trúc đi kèm theo văn bản như lượt người dùng, người dùng đề cập, nhãn thời gian, được sử dụng như một dấu hiệu của những người tham gia, những người cần đi theo cuộc đối thoại và đã được cho thấy là quan trọng cho sự tách rời. Mật độ DAG-LSTMs, một điều đàn nhận tất mà có thể xử lý tự trị nhiều trị hành mình, là một cách tự nhiên để thông bảo những thông tin này và một chúng. Trong tờ giấy này, chúng tôi áp dụng DAG-LSTMs cho nhiệm vụ chia rối cuộc đối thoại. Chúng tôi thực hiện thí nghiệm trên bộ dữ liệu Ubbe IRC. Chúng tôi cho thấy kiểu mẫu mới chúng tôi đề xuất đạt được trạng thái nghệ thuật hiện đại về nhiệm vụ phục hồi hồi hồi trả lời các mối quan hệ và nó đang cạnh tranh với các âm lượng chưa ràng buộc khác.', 'uz': "Name Name Name Bu suhbatlarni o'zgartirish imkoniyati keyin quyidagi narsalarning ko'pchilik muvaffaqiyatlariga ega bo'ladi. Masalan suhbat va savol javob beradi. Name DAG-LSTMs, acyklik ishlatuvchilarini boshqara oladigan daraxt-LSTMsning generalisiyasi, bu maʼlumot va keyingi xil tarkibini birlashtirish uchun asl usuli. Bu qogʻozda biz DG-LSTMsni talab qilish vazifasiga qo'llayapmiz. Biz Ubuntu IRC maʼlumotlarini bajaramiz. We show that the novel model we propose achieves state of the art status on the task of recovering reply-to relations and it is competitive on other disentanglement metrics.", 'hr': 'Mnogi moderni sustavi poruke omogućavaju brzu i sinhronosnu tekstualnu komunikaciju među mnogim korisnicima. Rezultativna sekvencija poruka krije komplikovaniju strukturu u kojoj se nezavisni podrazgovori međusobno povezuju. To predstavlja izazov za svaki zadatak koji cilja razumjeti sadržaj dnevnika razgovora ili skupljati informacije od njih. Sposobnost rasključavanja tih razgovora potom je is to čna uspjehu mnogih donjeg zadataka poput sažetka i odgovora na pitanje. Strukturirane informacije s tekstom poput korisnika okretanja, spominjanja korisnika, vremenskih znakova, koriste se kao znak samih učesnika koji moraju pratiti razgovor i pokazuju se da je važno za raspuštanje. DAG-LSTMs, generalizacija drveta-LSTMs-a koja može podnijeti direktne akcikličke zavisnosti, prirodan je način uključivanja takvih informacija i njegove ne-sekvenčne prirode. U ovom papiru, primjenjujemo DAG-LSTMs na zadatak razgovora o raspuštanju. Izvodimo eksperimente na setu podataka Ubuntu IRC-a. Pokazujemo da novi model koji predlažemo postigne stanje umjetnosti na zadatku povratka odgovora na odnose i da je konkurentna na drugim metrikama rastajanja.', 'bg': 'Много съвременни системи за съобщения позволяват бърза и синхронна текстова комуникация между много потребители. Получената последователност от съобщения крие по-сложна структура, в която независимите подразговори се преплитат помежду си. Това представлява предизвикателство за всяка задача, целяща да разбере съдържанието на чат логовете или да събере информация от тях. Способността за разгръщане на тези разговори след това се равнява на успеха на много задачи надолу по веригата, като обобщаване и отговор на въпроси. Структурираната информация, придружаваща текста, като потребителски ред, потребителски споменания, времеви марки, се използва като знак от самите участници, които трябва да следят разговора и е доказано, че е важна за отделянето. DAG-LSTMs, обобщаване на Tree-LSTMs, които могат да се справят с насочени ациклични зависимости, са естествен начин за включване на такава информация и нейната непоследователна природа. В тази статия ние прилагаме DAG-LSTMs към задачата за разгръщане на разговора. Изпълняваме експериментите си с Убунту IRC набора данни. Показваме, че новият модел, който предлагаме, постига най-съвременния статус на задачата за възстановяване на отговора на отношенията и е конкурентен на други показатели за разединяване.', 'nl': 'Veel moderne berichtensystemen maken snelle en synchrone tekstcommunicatie tussen veel gebruikers mogelijk. De resulterende opeenvolging van berichten verbergt een ingewikkeldere structuur waarin onafhankelijke subgesprekken met elkaar verweven zijn. Dit vormt een uitdaging voor elke taak die gericht is op het begrijpen van de inhoud van de chatlogs of het verzamelen van informatie uit hen. De mogelijkheid om deze gesprekken te ontkoppelen staat dan gelijk aan het succes van veel downstreamtaken zoals samenvatting en vragenantwoord. Gestructureerde informatie die bij de tekst hoort, zoals user turn, user names, timestamps, wordt gebruikt als een cue door de deelnemers zelf die het gesprek moeten volgen en is aangetoond belangrijk voor de ontkoppeling. DAG-LSTMs, een generalisatie van Tree-LSTMs die gerichte acyclische afhankelijkheden kunnen verwerken, zijn een natuurlijke manier om dergelijke informatie en de niet-sequentiële aard ervan op te nemen. In dit artikel passen we DAG-LSTMs toe op de gespreksontkoppeling taak. We voeren onze experimenten uit op de Ubuntu IRC dataset. We tonen aan dat het nieuwe model dat we voorstellen state-of-the-art status bereikt op het gebied van het herstellen van antwoord-op relaties en het concurrerend is ten opzichte van andere distanglement metrics.', 'da': 'Mange moderne messaging systemer tillader hurtig og synkron tekstkommunikation blandt mange brugere. Den resulterende sekvens af meddelelser skjuler en mere kompliceret struktur, hvor uafhængige undersamtaler er sammenflettet med hinanden. Dette udgør en udfordring for enhver opgave, der sigter mod at forstå indholdet af chat logs eller indsamle oplysninger fra dem. Evnen til at afbryde disse samtaler svarer derefter til succes for mange downstream opgaver såsom opsummering og spørgsmål besvarelse. Strukturerede oplysninger, der ledsager teksten, såsom brugertur, brugernævnelser, tidsstempler, bruges som signal af deltagerne selv, der har brug for at følge samtalen, og har vist sig at være vigtige for afsløring. DAG-LSTMs, en generalisering af Tree-LSTMs, der kan håndtere rettede acykliske afhængigheder, er en naturlig måde at indarbejde sådanne oplysninger og dens ikke-sekventielle karakter. I denne opgave anvender vi DAG-LSTMs til samtaleforbindelsesopgaven. Vi udfører vores eksperimenter på Ubuntu IRC datasæt. Vi viser, at den nye model, vi foreslår, opnår state of te art status på opgaven med at genvinde respons-to relationer, og den er konkurrencedygtig på andre disenglement metrics.', 'de': 'Viele moderne Messaging-Systeme ermöglichen eine schnelle und synchrone Textkommunikation zwischen vielen Nutzern. Die daraus resultierende Nachrichtensequenz verbirgt eine kompliziertere Struktur, in der unabhängige Untergespräche miteinander verwoben sind. Dies stellt eine Herausforderung für jede Aufgabe dar, die darauf abzielt, den Inhalt der Chat-Protokolle zu verstehen oder Informationen aus ihnen zu sammeln. Die Fähigkeit, diese Gespräche zu entkoppeln, ist dann gleichbedeutend mit dem Erfolg vieler nachgelagerter Aufgaben wie Zusammenfassung und Beantwortung von Fragen. Strukturierte Informationen, die den Text begleiten, wie User Turn, User Erwähnungen, Zeitstempel, werden von den Teilnehmern selbst verwendet, die dem Gespräch folgen müssen und haben sich als wichtig für die Entkoppelung erwiesen. DAG-LSTMs, eine Verallgemeinerung von Tree-LSTMs, die gerichtete azyklische Abhängigkeiten verarbeiten können, sind eine natürliche Möglichkeit, solche Informationen und ihre nicht-sequenzielle Natur zu integrieren. In diesem Beitrag wenden wir DAG-LSTMs auf die Aufgabe der Konversationsentkoppelung an. Wir führen unsere Experimente auf dem Ubuntu IRC Datensatz durch. Wir zeigen, dass das neue Modell, das wir vorschlagen, den Stand der Technik erreicht, was die Wiederherstellung von Antwortbeziehungen angeht, und dass es gegenüber anderen Entriegelungsmetriken wettbewerbsfähig ist.', 'id': 'Banyak sistem pesan modern memungkinkan komunikasi teks cepat dan sinkronis di antara banyak pengguna. Jujukan pesan yang menghasilkan menyembunyikan struktur yang lebih rumit di mana subkonversasi independen saling berhubungan. Ini merupakan tantangan untuk setiap tugas yang bertujuan untuk memahami isi log chat atau mengumpulkan informasi dari mereka. Kemampuan untuk melepaskan percakapan ini kemudian bersamaan dengan sukses banyak tugas turun seperti ringkasan dan jawaban pertanyaan. Informasi struktur yang menyertai teks seperti putaran pengguna, sebutan pengguna, timestamp, digunakan sebagai tanda oleh peserta sendiri yang perlu mengikuti percakapan dan telah menunjukkan penting untuk melepaskan diri. DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature.  In this paper, we apply DAG-LSTMs to the conversation disentanglement task.  Kami melakukan eksperimen kami pada set data IRC Ubuntu. Kami menunjukkan bahwa model novel yang kami sarankan mencapai status seni pada tugas untuk mengembalikan jawaban-hubungan dan itu kompetitif pada metrik pembukaan lainnya.', 'fa': 'بسیاری از سیستم پیغام\u200cرسانی مدرن اجازه می\u200cدهند ارتباط متن سریع و هماهنگ بین بسیاری از کاربر. نتیجه\u200cای از پیغام\u200cها یک ساختار پیچیده\u200cتر را پنهان می\u200cکند که در آن زیر گفتگوهای مستقل با یکدیگر متصل می\u200cشوند. این یک چالش برای هر کاری که هدف دارد محتوای یادداشت\u200cهای صحبت را درک کند یا اطلاعات را از آنها جمع کند. توانایی که این گفتگوها را نابود کند، سپس به موفقیت بسیاری از کارهای پایین مانند جمع کردن و جواب سوال یکسان است. اطلاعات ساخته شده با متن مثل تبدیل کردن کاربر ، یادآوری کردن ، نشانه\u200cهای زمانی ، توسط خودشان شرکتگران استفاده می\u200cشود که نیاز به پیروی کردن صحبت کردند و برای تبدیل کردن مهم است. DAG-LSTMs, a generalization of Tree-LSTMs that can handle direct acyclic dependencies, are a natural way to incorporate such information and its non-sequence nature. در این کاغذ، ما DAG-LSTMs را به وظیفه جدا کردن صحبت استفاده می کنیم. ما آزمایش\u200cهایمان را روی مجموعه\u200cی داده\u200cهای ایرک اوبونتو انجام می\u200cدهیم. ما نشان می دهیم که مدل رمانی که ما پیشنهاد می دهیم وضعیت هنری در مورد وضعیت بازیابی پاسخ به رابطه ها رسیده می شود و آن در متریک های دیگر رقابت کننده است.', 'ko': '많은 현대 메시지 전달 시스템은 많은 사용자들 사이에서 신속하고 동기화된 텍스트 통신을 허용한다.이로 인해 발생하는 메시지 서열은 더욱 복잡한 구조를 숨기고 그 중에서 독립된 하위 대화가 서로 교차한다.이것은 채팅 로그의 내용을 이해하거나 정보를 수집하기 위한 모든 임무에 도전이다.이러한 대화를 정리하는 능력은 많은 하류 임무의 성공, 예를 들어 문제를 정리하고 대답하는 것과 같다.텍스트에 수반되는 구조화된 정보, 예를 들어 사용자 차례, 사용자 언급, 시간 스탬프는 참여자 스스로 힌트로 사용되기 때문에 그들은 대화에 관심을 가져야 하고 문제 풀이에 매우 중요하다는 것이 증명되었다.DAG LSTMs는 트리 LSTMs의 일종의 범화로 고리에 의존하는 것을 처리할 수 있고 자연스러운 방식으로 이런 정보와 비순서적인 성격을 통합시킬 수 있다.이 문서에서 DAG LSTMs를 세션 해결 작업에 적용합니다.Ubuntu IRC 데이터 세트에서 실험했습니다.우리는 우리가 제시한 새로운 모델이 회복 관계를 회복하는 임무에서 가장 선진적인 수준에 이르렀고 다른 얽매임 해소 지표에서 경쟁력이 있음을 증명했다.', 'sw': 'Mifumo mingi ya ujumbe wa kisasa huruhusu mawasiliano kwa haraka na yenye ushirikiano wa simu za mkono miongoni mwa watumiaji wengi. Matokeo yake ya ujumbe yanaficha muundo mgumu zaidi ambapo mazungumzo huru ya subungumzo yanajadiliana. Hii inaleta changamoto kwa kazi yoyote ili kuelewa maudhui ya loga za mazungumzo au kukusanya taarifa kutoka kwao. Uwezo wa kuzuia mazungumzo haya ni kufuatia mafanikio ya kazi nyingi za mito ya chini kama vile upatikanaji wa muhtasari na majibu ya maswali. Taarifa zilizotengenezwa zinazohusiana na maandishi kama vile mtumiaji, tajwa za watumiaji, nyakati za muda, zinatumiwa kama kiungo na washiriki wenyewe wanaohitaji kufuatia mazungumzo hayo na wameonyesha kuwa ni muhimu kwa ajili ya kukabiliana na ugonjwa. DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature.  Katika karatasi hii, tunatumia DAG-LSTMs kwenye jukumu la mazungumzo ya utekaji. Tunafanya majaribio yetu kwenye seti ya data ya Ubuntu IRC. Tunaonyesha kuwa mtindo wa riwaya tunapendekeza kupata hali ya sanaa katika jukumu la kurejesha majibu ya mahusiano na ni ushindani kwa mitindo mingine ya ugonjwa wa magonjwa.', 'tr': 'Köp modern mesajlaşma sistemalary köp Ullançylar arasynda tiz we synkron metin iletişimi mümkin edýär. Sonuçta mesajlaryň ardysynda biraz karmaşık bir struktury gizləýär we bu ýerde bağlı söhbetler birbirine öňe tutylýar. Bu ähli zady üçin kynçylyk bar, soňra günlükleriň maksadyny düşünmek ýädä olaryň maglumatyny toplamak üçin. Bu gürrüňleri çykarmak başaryşlaryny çykarmak üçin, soňra aşak täsirli zadyň başaryşlaryna eşittir. Ullançy sözleri, wagtyň agzalary, zamanlyklary ýaly metin bilen birleşen strukturly maglumatlar, sözleşişi diňlemek üçin möhüm bolan adamlar tarapyndan bir cuer hökmünde ullanýar. DAG-LSTMs, dikilik baglary daşary çykyp biljek agaç-LSTMsiň döredilişi, bu şekilde maglumatlary we netijeli tebigatyny birleştirmek üçin tebigatly bir ýol. Bu kagyzda DAG-LSTMsini söhbetdeşlik boýunçylyga geçirip otyrys. Ubuntu IRC veri setinde deneylerimizi çykarýarys Biz özümiz teklip eden täze nusga sungat durumynyň ýagdaýynyň jogaplary almak üçin ýetmegini teklip edip bilýän nusgasymyzy görkeýäris we bu nusgasyzlyk başga metriklerde döwletlidir.', 'sq': 'Many modern messaging systems allow fast and synchronous textual communication among many users.  Sekuenca rezultuese e mesazheve fsheh një strukturë më të komplikuar në të cilën nënbisedimet e pavarura janë ndërlidhur njëri me tjetrin. Kjo përbën një sfidë për çdo detyrë që synon të kuptojë përmbajtjen e regjistrave të bisedës ose të mbledhë informacion nga a to. Aftësia për të hequr qafe këto bisedime është pastaj e barabartë me suksesin e shumë detyrave poshtë të tilla si përmbledhje dhe përgjigje pyetjesh. Informacioni strukturuar që shoqëron tekstin si kthesa e përdoruesit, përmendimet e përdoruesit, shenjat e kohës, përdoret si një shenjë nga vetë pjesëmarrësit që duhet të ndjekin bisedën dhe është treguar se është i rëndësishëm për çarjen. DAG-LSTMs, një gjeneralizatë e Tree-LSTMs që mund të trajtojnë varësitë aksiklike të drejtuara, janë një mënyrë natyrore për të përfshirë informacion të tillë dhe natyrën jo-sekuenciale të saj. Në këtë letër, ne aplikojmë DAG-LSTMs në detyrën e çrregullimit të bisedës. Ne bëjmë eksperimentet tona në dataset IRC Ubuntu. Ne tregojmë se modeli i ri që propozojmë arrin statusin më të mirë në detyrën e rimëkëmbjes së përgjigjes ndaj marrëdhënieve dhe është konkurrues në metrika të tjera të shpërndarjes.', 'hy': 'Շատ ժամանակակից հաղորդագրությունների համակարգերը հնարավորություն են տալիս արագ և սինկրոն տեքստային հաղորդակցման շատ օգտագործողների միջև: Ահաղորդագրությունների հետևյալ հաջորդականությունը թաքցնում է ավելի բարդ կառուցվածք, որտեղ անկախ ենթազրույցները փոխկապակցվում են միմյանց հետ: Սա մարտահրավեր է առաջացնում ցանկացած հանձնարարության համար, որի նպատակով է հասկանալ խոսակցության օրագիրների պարունակությունը կամ դրանցից տեղեկատվություն հավաքել: Այս զրույցների բաժանման ունակությունը հետո հավասար է հաջողությանը շատ հետագա խնդիրների, ինչպիսիք են համառոտագրությունը և հարցերի պատասխանը: Տեքստին ուղեկցող կառուցվածքային տեղեկատվությունը, ինչպիսիք են օգտագործողների շրջանը, օգտագործողների նշումները, ժամանակային նշումները, օգտագործվում են որպես նշան մասնակիցների կողմից, ովքեր պետք է հետևեն խոսակցությանը և ցույց է տալիս, որ DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature.  Այս թղթի մեջ մենք օգտագործում ենք DAG-LSMT-ները խոսակցության բաժանման խնդրի համար: Մենք կատարում ենք մեր փորձերը Ubuntu ինֆորմացիայի տվյալների համակարգի վրա: Մենք ցույց ենք տալիս, որ մեր առաջարկած նոր մոդելը հասնում է արվեստի կարգավիճակի վերականգնելու խնդիրը հարաբերություններին, և այն մրցակցում է այլ բաժանման չափով:', 'am': 'ብዙ የአሁኑን መልዕክት ስርዓቶች በብዙ ተጠቃሚዎች መካከል ፈጥኖ እና የጽሑፍ ግንኙነት እንዲቀበል ይችላሉ፡፡ የመልእክት ግንኙነት በተጨማሪው አካባቢ መሠረት ይሸሽጋል፡፡ ይህ የአካባቢው ቦታዎችን ለማስተዋል ወይም ከእነርሱ መረጃ ለመሰብሰብ ለማድረግ ለማንኛውም ስራ የሚችል ግንኙነት ነው፡፡ ይህንን ንግግር ማግኘት መቻል እንደዚህ አቁማሽ እና የመጠያቂያ መልስ ብዙዎችን የውኃ ፈሳሾች ድል ማግኘት ነው፡፡ በተጨማሪው ጽሑፍ፣ ተጠቃሚዎች፣ ማስታወሻ፣ ሰዓት ድምፅ፣ በተጨማሪዎች ራሳቸው ንግግርን ለመከተል ያስፈልጋሉ፡፡ DAG-LSTMs፣ የመቀናቀል የacyclic ተሟጋቾችን ለመቀበል የሚችል የዛፍ-LSTMs አቀማመጥ፣ እንደዚህ ያሉትን መረጃ እና ያልተከታታይ ሥርዓት ለመቀበል የፍጥረት መንገድ ነው፡፡ በዚህ ገጾች ውስጥ DAG-LSTMs ን ለንግግር ግንኙነት እናደርጋለን፡፡ በዑቡንቱ IRC ዳታተር ላይ ፈተናችንን እናደርጋለን፡፡ የመረጃ ዘይት የግንኙነትን ለመመለስ ስራትን እንዲያገኝ እናሳያቸዋለን፡፡', 'az': "Çox modern mesajlaşma sistemlərinin çoxlu istifadəçilərin arasında hızlı və sinkron textual iletişimi mümkün edir. Sonuçta ismarışların sıralaması daha karmaşık bir quruluşu gizlədir ki, orada bağımsız sub-söhbətlər bir-birinə qarıştırılır. Bu, söhbət günlüklərinin məlumatını anlamaq və ya onlardan məlumat toplamaq üçün hər hansı bir iş üçün çətinlik yaradır. Bu söhbətləri çəkmək bacarılığı, həmçinin təmizlənmək və sual cavab vermək kimi çoxlu aşağı işlərin başarısızlığına bənzəyir. İstifadəçi dönüşü, istifadəçi adlandırması, vaxtlıq dəymələri kimi mətn ilə birlikdə qurulmuş məlumat, söhbətə uymaq lazımdır və çəkilmək üçün möhüm olaraq göstərildi. DAG-LSTMs, tərəfindən aciklik bağlılıqları idarə edə bilən a ğac-LSTMs-lərin generalizasyonu, bu məlumatları və onun sonsuz təbiətini birləşdirmək təbiətli bir yoldur. Bu kağızda, biz DAG-LSTMs'ləri söhbətlərini dağıtmaq üçün istifadə edirik. Ubuntu IRC veri quruluğunda təcrübələrimizi idarə edirik. Biz göstəririk ki, təklif etdiyimiz yeni modellərin cavab vermək məqsədilə sanat durumunu başa çatdırmaq məqsədilə təklif edir və bu, digər təklif məqsədilə müqayisədir.", 'af': "Baie moderne boodskapstelsels laat vinnig en sinkroon teksverkommunikasie onder baie gebruikers toe. Die resulteerde volgorde van boodskappe verberg 'n meer kompliseerde struktuur waarin onafhanklike sub- gesprekke met mekaar onderwerp word. Hierdie stel 'n uitdrukking vir enige taak wat doel om die inhoud van die geselselslogge te verstaan of inligting van hulle versamel. Die moontlik om hierdie gesprekke te ontskakel is dan totaal tot die sukses van baie onderstreem taak soos opsomming en vraag antwoord. Struktuurde inligting met die teks soos gebruiker omskakel, gebruiker aanwys, tydsmarkte, word gebruik as 'n teks deur die deelnaders hulleself wat benodig na volg die gesprek en is vertoon om belangrik te wees vir ontskakeling. DAG-LSTMs, 'n generellisering van Boom-LSTMs wat direkte aksikliske afhanklikhede kan hanteer, is 'n natuurlike manier om sodanige inligting en sy nie-sekwensiele natuur te inkorpreer. In hierdie papier, ons wend DAG-LSTMs toe na die gesprekslyk ontskakeling taak. Ons uitvoer ons eksperimente op die Ubuntu IRC-datastel. Ons wys dat die nuwe model wat ons voorstel, staat van die kunsten status op die taak om antwoord tot verhouding te herstel en dit is medelykbaar op ander ontsondering metrike.", 'bs': 'Mnogi moderni sistemi poruke omogućavaju brzu i sinhronosnu tekstualnu komunikaciju među mnogim korisnicima. Rezultativna sekvencija poruka krije komplikovaniju strukturu u kojoj su nezavisniji podrazgovori međusobni. To predstavlja izazov za svaki zadatak koji cilja razumjeti sadržaj dnevnika razgovora ili skupljati informacije od njih. Sposobnost razotkrivanja tih razgovora je onda is to sa uspjehom mnogih donjeg zadataka kao što su sažetanje i odgovor na pitanje. Strukturirane informacije s tekstom kao što je korisnik okrenut, spominjao je korisnik, timestamp, koriste se kao znak samih učesnika koji moraju pratiti razgovor i pokazuju se da je važno za raspuštanje. DAG-LSTMs, generalizacija drveta-LSTMs-a koja može podnijeti direktne akcikličke zavisnosti, prirodan je način da uključuje takve informacije i njenu neprekvenu prirodu. U ovom papiru, primjenjujemo DAG-LSTMs na zadatak razgovora o raspuštanju. Izvodimo eksperimente na setu podataka Ubuntu IRC-a. Pokazujemo da novi model koji predlažemo postigne stanje umjetnosti na zadatku oporavljanja odgovora na odnose i da je konkurentna na drugim metrikama rastajanja.', 'bn': 'অনেক আধুনিক বার্তা সিস্টেম অনেক ব্যবহারকারীর মধ্যে দ্রুত এবং সিক্রোনিয়াল টেক্সচুয়াল যোগাযোগ অনুমোদন এর ফলে বার্তার সংক্রান্ত সংক্রান্ত এক জটিল কাঠামো লুকিয়ে রাখে, যেখানে স্বাধীন সাব-আলোচনা একে অপরের সাথে একে অপরকে সাথ এটি চ্যালেঞ্জের জন্য যে কোন কাজের জন্য চ্যালেঞ্জ রয়েছে যার উদ্দেশ্যে চ্যালেঞ্জ বুঝতে পারে চ্যালেঞ্জ এই আলোচনাগুলোকে বাতিল করার ক্ষমতা হলো নীচের কাজের সাফল্যের সাথে যেমন সংক্ষেপ এবং প্রশ্নের উত্তর। যে সমস্ত অংশগ্রহণকারীদের নিজেদের কথোপকথন অনুসরণ করতে হবে এবং তাদের ব্যবহার করা গুরুত্বপূর্ণ বিষয়বস্তু দেখা যাচ্ছে। ডাজি-এলস্টিম, গাছ-এলস্টিমের একটি জেনারেলিজেশন যা নির্দেশিত একাইক্লিকের নির্ভর করতে পারে, তারা এই তথ্য এবং এর পরবর্তী প্রকৃতির মধ্যে যোগাযোগ এই কাগজটিতে আমরা ডিজি-এলস্টিমিসকে কথোপকথনের বিভিন্ন কাজে প্রয়োগ করি। আমরা Ubuntu IRC ডাটাসেটে আমাদের পরীক্ষা করি। আমরা দেখাচ্ছি যে উপন্যাসের মডেল আমরা প্রস্তাব করছি যে শিল্পের অবস্থা পুনরায় প্রদান করার কাজে প্রস্তাব করা হয়েছে যে সম্পর্কের উত্তর পুনরুদ্ধার কর', 'ca': "Molts sistemes moderns de missatge permeten comunicació textual ràpida i sincronitzada entre molts usuaris. La seqüència resultant dels missatges amaga una estructura més complicada en la qual les subconsultacions independents s'intervinculen entre elles. Això representa un repte per a qualsevol tasca mirant a entendre el contingut dels registres de conversa o recollir informació d'ells. L'habilitat de desmantellar aquestes converses equivalen a l'èxit de moltes tasques avall, com la resumida i la resposta a preguntes. La informació estructurada que acompanya el text, com el gir de l'usuari, les mencions de l'usuari, els timbres de temps, es utilitza com una indicació pels participants mateixos que han de seguir la conversa i s'ha demostrat que és important per desbloquejar-se. DAG-LSTMs, una generalització de Tree-LSTMs que poden gestionar les dependències acíliques directes, són una manera natural d'incorporar aquesta informació i la seva naturalesa no seqüencial. In this paper, we apply DAG-LSTMs to the conversation disentanglement task.  Fem els nostres experiments en el conjunt de dades IRC d'Ubuntu. Mostrem que el nou model que proposem aconsegueix l'estatus d'última generació en la tasca de recuperar les relacions de resposta i és competitiu en altres mètriques de desenvolupament.", 'cs': 'Mnoho moderních systémů zpráv umožňuje rychlou a synchronní textovou komunikaci mezi mnoha uživateli. Výsledná sekvence zpráv skrývá složitější strukturu, ve které se vzájemně proplétají nezávislé subkonverzace. To představuje výzvu pro jakýkoliv úkol, jehož cílem je porozumět obsahu chatových protokolů nebo z nich shromažďovat informace. Schopnost rozpoznat tyto konverzace je pak rovnocenná úspěchu mnoha následných úkolů, jako je shrnutí a odpověď na otázky. Strukturované informace doprovázející text, jako například obrat uživatele, zmínky uživatelů, časová razítka, slouží jako nápověda samotnými účastníky, kteří potřebují konverzaci sledovat a ukázalo se, že jsou důležité pro rozpoznání. DAG-LSTMs, zobecnění stromových LSTMů, které dokáží zvládnout řízené acyklické závislosti, jsou přirozeným způsobem, jak začlenit tyto informace a jejich nesekvenční povahu. V tomto článku aplikujeme DAG-LSTMs na úkol rozvádění konverzace. Naše experimenty provádíme na datové sadě Ubuntu IRC. Ukazujeme, že nový model, který navrhujeme, dosahuje nejmodernějšího stavu v oblasti obnovy vztahů odpovědi na vztahy a je konkurenceschopný vůči ostatním metrikám rozpletení.', 'et': 'Paljud kaasaegsed sõnumisüsteemid võimaldavad kiiret ja sünkroonset tekstisidet paljude kasutajate vahel. Saadud sõnumite jada peidab keerulisemat struktuuri, kus sõltumatud alamvestlused on omavahel põimunud. See kujutab endast väljakutset igale ülesandele, mille eesmärk on mõista vestluslogide sisu või koguda neist teavet. Võime neid vestlusi lahti siduda on seejärel võrdne paljude järgnevate ülesannetega, nagu kokkuvõte ja küsimustele vastamine. Tekstiga kaasnevat struktureeritud teavet, nagu kasutaja pööre, kasutaja märkused, ajatemplid, kasutavad osavõtjad ise, kes peavad vestlust jälgima, ning on osutunud oluliseks lahtisidumiseks. DAG-LSTMd, puu-LSTMde generaliseerimine, mis suudab käsitleda suunatud atsüklilisi sõltuvusi, on loomulik viis sellise teabe ja selle mittesjärjestikuse olemuse kaasamiseks. Selles töös rakendame DAG-LSTMd vestluse lahutamise ülesandele. Me teeme oma katseid Ubuntu IRC andmekogumiga. Näitame, et meie poolt pakutav uus mudel saavutab vastusesuhete taastamise ülesandes kaasaegse staatuse ning on konkurentsivõimeline muude lahtisidumise mõõdikute suhtes.', 'fi': 'Monet nykyaikaiset viestijärjestelmät mahdollistavat nopean ja synkronisen tekstiviestinnän monien käyttäjien välillä. Tuloksena oleva viestisarja piilottaa monimutkaisemman rakenteen, jossa itsenäiset alakeskustelut kietoutuvat toisiinsa. Tämä on haaste jokaiselle tehtävälle, jonka tavoitteena on ymmärtää keskustelulokien sisältöä tai kerätä niistä tietoja. Kyky purkaa nämä keskustelut tarkoittaa monien jatkovaiheen tehtävien, kuten yhteenvedon ja kysymysten vastaamisen onnistumista. Tekstin mukana tulevat jäsennellyt tiedot, kuten käyttäjän vuoro, käyttäjämaininnat, aikaleimat, ovat merkkinä osallistujien itsensä, joiden on seurattava keskustelua, ja ne on osoitettu olevan tärkeitä kontaktien purkamisessa. DAG-LSTMs, Tree-LSTMs-yleistys, joka pystyy käsittelemään suunnattuja asyklisiä riippuvuuksia, ovat luonnollinen tapa sisällyttää tällainen tieto ja sen ei-sekvenssiaalinen luonne. Tässä artikkelissa sovellamme DAG-LSTMs-menetelmiä keskustelun purkamistehtävään. Teemme kokeita Ubuntu IRC -tietokannalla. Osoitamme, että ehdottamamme uusi malli saavuttaa viimeisintä tasoa vastaussuhteiden palauttamisessa ja on kilpailukykyinen muissa erottelumittareissa.', 'he': 'מערכות הודעות מודרניות רבות מאפשרות תקשורת טקסטלית מהירה וסינכרונית בין משתמשים רבים. הרצף הנוצא של הודעות מסתיר מבנה מסובך יותר שבו הת-שיחות עצמאות מתעסקות אחד עם השני. זה יוצר אתגר לכל משימה שמתכוונת להבין את התוכן של יומני השיחה או לאסוף מידע מהם. היכולת לפרוק את השיחות האלה שווה לאחר מכן להצלחה של משימות רבות לאורך הקרקע, כמו הסכם ולענות על שאלות. Structured information accompanying the text such as user turn, user mentions, timestamps, is used as a cue by the participants themselves who need to follow the conversation and has been shown to be important for disentanglement.  DAG-LSTMs, הגנרליזציה של עץ-LSTMs שיכולות להתמודד עם תלויות אקסיקליות מונחות, הם דרך טבעית להשתלב מידע כזה ואת טבעו הלא רצפי. בעיתון הזה, אנחנו מכניסים DAG-LSTMs למשימת הפרידה לשיחה. אנחנו מבצעים את הניסויים שלנו על קבוצת מידע IRC Ubuntu. אנחנו מראים שהמודל הרומני שאנחנו מציעים משיג את מצב האומנות במשימה של החזרה של תשובה למערכת יחסים והוא תחרותי במטריקות אחרות של הפרידה.', 'sk': 'Številni sodobni sistemi sporočanja omogočajo hitro in sinhrono besedilno komunikacijo med številnimi uporabniki. Nastalo zaporedje sporočil skriva bolj zapleteno strukturo, v kateri so neodvisni podpogovori prepleteni med seboj. To predstavlja izziv za vsako nalogo, katere cilj je razumevanje vsebine dnevnikov klepeta ali zbiranje informacij iz njih. Sposobnost ločevanja teh pogovorov je tako enaka uspehu številnih nadaljnjih opravil, kot sta povzetek in odgovor na vprašanja. Strukturirane informacije, ki spremljajo besedilo, kot so obrat uporabnika, omembe uporabnika, časovni žig, uporabljajo udeleženci sami, ki morajo slediti pogovoru, in so se pokazale, da so pomembne za ločitev. DAG-LSTMs, generalizacija drevesnih LSTMs, ki lahko obvladujejo usmerjene aciklične odvisnosti, so naraven način vključevanja takšnih informacij in njihove nezaporedne narave. V tem članku uporabljamo DAG-LSTMs za opravilo ločevanja pogovorov. Naše poskuse izvajamo na naboru podatkov IRC Ubuntu. Pokazujemo, da novi model, ki ga predlagamo, dosega najsodobnejši status pri nalogi obnovitve odgovornih odnosov in je konkurenčen pri drugih meritvah razvezanosti.', 'jv': 'Daftar sistem Messaging kang dipoleh akeh tur angel lan kelompok nggambar akeh banter MIME TypeCommentApplication, Iki iso nggawe perbudhakan kanggo saben nggawe Perintah mengko or a nggawe informasi ning acara Kapan kanggo ngbagakake tarjamahan iki dadi kapan kanggo luwih operasi dipun string" in "context_BAR_stringLink The number of paths that are sharing Nang pemilih iki, kita kang aplikasi DEG-LTT mruputang kanggo nggawe gerakan kanggo nggawe gerakan. Awak dhéwé ngejaraké perintasi nang dataset Ubuntu IRC Awak dhéwé éntuk model nganggo kuwi nggawe nyimpen urip kuwi status kanggo nggawe barang nggawe barang nggawe barang-barang karo ngono kuwi wis dipujaran kanggo nggawe barang maning.', 'ha': "@ info: whatsthis Fara-ƙaranci ga jumbe, yana ɓõye wata matsayi mai tsanani, inda za'a haɗa danganta masu da baka-mazaɓa da ɗayan. Wannan yana da wani yanki wa wani aikin da za'a iya fahimta wanda ke cikin mazaɓan mazaɓa ko kuma ya sami tsari daga gare su. Taimar da ya kange waɗannan mazaɓa na dabam yana da cin nasara ga masu aiki mãsu yawa na ƙarami, kamar sami'arin da jibin tambayi. An amfani da shirin ayukan mutane da ke sami matsayin kamar fuskar mai amfani da shi, misalin mai amfani da shi, da kuma tsumarni, za'a yi amfani da shi kamar wata nau'a na musamman da su canza su bi mazaɓan da kuma an nuna shi yana da muhimu wa canza yin husũma. DAG-LStM, wata jenalisation of Tree-LTRM which can take a way depression of acyclic, is a natura way to include in such information and its non-sequence. Ga wannan takardan da Muke amfani da DAG-LSM zuwa wani aikin da ke yin magana. We perform our experiments on the Ubuntu IRC dataset.  Tuna nũna cewa misalin nowaya da Muke buƙata, ya sami halin sanani a kan aikin da za'a iya sãka wa masu tsari da kuma yana yin ƙunci a kan wasu mitori.", 'bo': 'ད་ལྟོའི་འཕྲིན་དོན་རིམ་མ་ལག་པ་མང་པོ་ཞིག་སྤྱད་ནས་མགྱོགས་རིམ་དང་མཉམ་སྦྲེལ་མཐུད་ཡོད་པ དབྱངས་བསྐྱེད་པའི་ཆ་འཕྲིན་གྱི་གོ་རིམ་ནི་ཕན་ཚུན་ལས་སླ་གཏད་ཁང་ཆེ་བའི་སྒྲིག་རིམ་སྦྱར་ཡོད། འདིས་བྱ་འགུལ་གྱི་ནང་དོན་ཡོད་པ་གང་རུང་ལ་དཀའ་ངལ་ཞིག་ཡོད་པ་དང་གླེང་མོལ་གྱི་ནང་དོན་གསལ་བཤད་ཀྱི་ གཏམ་གླེང་འདི་དག་ཚོད་སྡུད་མེད་པར་ངེས་པར་དབང་གི་གཟའ་འགྲུལ་གྱི་བྱ་རིམ་མང་པོ་ཞིག་ཡིན་པས། Structured information accompanying the text such as user turn, user mentions, timestamps, is used as a cue by the participants themselves who need to follow the conversation and have been shown to be important for disentanglement. DAG-LSTMs, a generalization of Tree-LSTMs that can handle directed acyclic dependencies, are a natural way to incorporate such information and its non-sequential nature. ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་DAG-LSTMs ས་གཏམ་གླེང་སྒྲུང་གི་དོན་ལ་འཇུག་སྤྱོད་པ། ང་ཚོས་Ubuntu IRC གནད་སྡུད་གཞི་སྒྲིག་གི་ལག་ལེན་འཚོལ་བྱེད་པ ང་ཚོས་མཐུན་བཟོ་བའི་མ་དབུགས་དེ་ལ་སྔོན་འཆར་བཀོད་ཡོད་པ་ནི་ང་ཚོས་རྩལ་གནས་སྟངས་དང་མཐུན'}
{'en': 'Toward Diverse Precondition Generation', 'ar': 'نحو جيل متنوع الشروط المسبقة', 'fr': 'Vers une génération diversifiée de conditions préalables', 'es': 'Hacia una generación diversa de condiciones previas', 'pt': 'Em direção à geração de pré-condições diversas', 'zh': '就多样化之前提条件生', 'ja': '多様な前提条件の生成に向けて', 'ru': 'На пути к созданию разнообразных предпосылок', 'hi': 'विविध पूर्व शर्त पीढ़ी की ओर', 'ga': 'I dtreo Giniúint Réamhchoinníoll Éagsúla', 'hu': 'A különböző előfeltételek generálása felé', 'ka': 'განსხვავებული პრეკონდიციოს შექმნა', 'el': 'Προς τη δημιουργία διαφορετικών προϋποθέσεων', 'it': 'Verso una generazione di precondizioni diverse', 'mk': 'Toward Diverse Precondition Generation', 'lt': 'Įvairių išankstinių sąlygų kūrimo link', 'kk': 'Түрлі қадамдастыру', 'ms': 'Ke Penjanaan Precondition Berberbeza', 'mt': 'Lejn Ġenerazzjoni Diversa ta’ Prekundizzjoni', 'mn': 'Өөр төрлийн шагналын төлөө', 'ml': 'മുകളിലുള്ള വ്യത്യാസങ്ങള്\u200dPrecondition Generation', 'no': 'Gå mot forskjellige førehandsvising', 'pl': 'W kierunku różnorodnego generowania warunków wstępnych', 'ro': 'Către o generare diversă a precondiţiilor', 'sr': 'Prema generaciji različitih predstava', 'si': 'විවිධ ප්\u200dරධානයක් සිද්ධානයට', 'so': 'Horizontal Generation', 'sv': 'Mot olika förutsättningar', 'ur': 'مختلف مقدمات کی طرف', 'ta': 'மேலே முன்னுரிமை உருவாக்குதல்', 'uz': '@ info: whatsthis', 'vi': 'Thế hệ tiêu chuẩn từ chiều...', 'da': 'På vej mod forskellig forudsætningsgenerering', 'bg': 'Към многообразно генериране на предпоставки', 'nl': 'Naar een divers genereren van voorcondities', 'hr': 'Prema generaciji različitih predstava', 'de': 'Auf dem Weg zu einer vielfältigen Vorbedingungen-Generierung', 'id': 'Menuju Generasi Perkondisi Berbeda', 'fa': 'به سوی نسل پیش\u200cفرض مختلف', 'ko': '다원화된 세대로 나아가다', 'sw': 'Precondition Generation', 'tr': 'Çeşitli Taryhdan Döredişi', 'af': 'Gaan na Verskeie voorstelling Genereer', 'az': 'M칲xt톛lif 톛vv톛lkil톛r M톛xluqat캼na', 'am': 'Toward Diverse Precondition Generation', 'sq': 'Për gjenerimin e parakushteve të ndryshme', 'hy': 'Toward Diverse Precondition Generation', 'ca': 'Vers la generació de condicions previes diverses', 'bs': 'Prema generaciji različitih predstava', 'bn': 'সার্ভারের বিভিন্ন প্রেসিডেন্ট জেনারেশন', 'cs': 'Směrem k různorodému generování předběžných podmínek', 'et': 'Mitmekesise eeltingimuste loomise suunas', 'fi': 'Kohti monimuotoista esiolosuhteiden luomista', 'jv': 'Multiple', 'sk': 'K raznolikemu ustvarjanju predpogojev', 'ha': 'KCharselect unicode block name', 'bo': 'འགྱུར་བའི་སྔོན་འཛུགས་ཀྱི་བཟོ་བཅོས་ལ།', 'he': 'לעבר יצירת תנאי קדום שונה'}
{'en': 'A typical goal for language understanding is to logically connect the events of a discourse, but often connective events are not described due to their commonsense nature. In order to address this deficit, we focus here on generating precondition events. Precondition generation can be framed as a sequence-to-sequence problem : given a target event, generate a possible precondition. However, in most real-world scenarios, an event can have several preconditions, which is not always suitable for standard seq2seq frameworks. We propose DiP, the Diverse Precondition generation system that can generate unique and diverse preconditions. DiP consists of three stages of the generative process   an event sampler, a candidate generator, and a post-processor. The event sampler provides control codes (precondition triggers) which the candidate generator uses to focus its generation. Post-processing further improves the results through re-ranking and filtering. Unlike other conditional generation systems, DiP automatically generates control codes without training on diverse examples. Analysis reveals that DiP improves the diversity of preconditions significantly compared to a beam search baseline. Also, manual evaluation shows that DiP generates more preconditions than a strong nucleus sampling baseline.', 'es': 'Un objetivo típico para la comprensión del lenguaje es conectar lógicamente los eventos de un discurso, pero a menudo los eventos conectivos no se describen debido a su naturaleza de sentido común. Para abordar este déficit, nos centramos aquí en generar eventos de condición previa. La generación de condiciones previas se puede encuadrar como un problema de secuencia a secuencia: dado un evento objetivo, se genera una posible condición previa. Sin embargo, en la mayoría de los escenarios del mundo real, un evento puede tener varias condiciones previas, lo que no siempre es adecuado para los marcos seq2seq estándar. Proponemos DiP, el sistema de generación de precondiciones diversas que puede generar condiciones previas únicas y diversas. El DiP consta de tres etapas del proceso generativo: un muestreador de eventos, un generador de candidatos y un postprocesador. El muestreador de eventos proporciona códigos de control (activadores de condición previa) que el generador de candidatos utiliza para centrar su generación. El procesamiento posterior mejora aún más los resultados mediante el cambio de clasificación y el filtrado. A diferencia de otros sistemas de generación condicional, DiP genera automáticamente códigos de control sin capacitación en diversos ejemplos. El análisis revela que DiP mejora significativamente la diversidad de condiciones previas en comparación con una línea de base de búsqueda de haces. Además, la evaluación manual muestra que el DiP genera más condiciones previas que una base sólida de muestreo del núcleo.', 'pt': 'Um objetivo típico para a compreensão da linguagem é conectar logicamente os eventos de um discurso, mas muitas vezes os eventos conectivos não são descritos devido à sua natureza de senso comum. Para resolver esse déficit, nos concentramos aqui na geração de eventos de pré-condição. A geração de pré-condições pode ser enquadrada como um problema de sequência a sequência: dado um evento alvo, gere uma possível pré-condição. No entanto, na maioria dos cenários do mundo real, um evento pode ter várias pré-condições, o que nem sempre é adequado para estruturas seq2seq padrão. Propomos o DiP, o sistema de geração de diversas pré-condições que pode gerar pré-condições únicas e diversas. O DiP consiste em três estágios do processo generativo – um amostrador de eventos, um gerador de candidatos e um pós-processador. O amostrador de eventos fornece códigos de controle (gatilhos de pré-condição) que o gerador candidato usa para focar sua geração. O pós-processamento melhora ainda mais os resultados por meio de reclassificação e filtragem. Ao contrário de outros sistemas de geração condicional, o DiP gera automaticamente códigos de controle sem treinamento em diversos exemplos. A análise revela que o DiP melhora significativamente a diversidade de pré-condições em comparação com uma linha de base de busca de feixe. Além disso, a avaliação manual mostra que o DiP gera mais pré-condições do que uma linha de base de amostragem de núcleo forte.', 'ar': 'الهدف النموذجي لفهم اللغة هو الربط المنطقي بأحداث الخطاب ، ولكن غالبًا لا يتم وصف الأحداث الرابطة بسبب طبيعتها المنطقية. من أجل معالجة هذا العجز ، نركز هنا على توليد أحداث الشروط المسبقة. يمكن تأطير توليد الشرط المسبق كمسألة تسلسل إلى تسلسل: عند إعطاء حدث مستهدف ، قم بإنشاء شرط مسبق محتمل. ومع ذلك ، في معظم سيناريوهات العالم الحقيقي ، يمكن أن يكون للحدث عدة شروط مسبقة ، وهي ليست مناسبة دائمًا لأطر عمل seq2seq القياسية. نقترح DiP ، نظام التوليد المتنوع الذي يمكن أن يولد شروطًا مسبقة فريدة ومتنوعة. يتكون DiP من ثلاث مراحل من العملية التوليدية - جهاز أخذ عينات الأحداث ، والمولد المرشح ، والمعالج اللاحق. يوفر جهاز أخذ عينات الأحداث رموز تحكم (مشغلات شرط مسبق) يستخدمها منشئ المرشح لتركيز توليدها. تعمل المعالجة اللاحقة على تحسين النتائج من خلال إعادة الترتيب والتصفية. على عكس أنظمة التوليد الشرطية الأخرى ، ينشئ DiP تلقائيًا أكواد التحكم دون تدريب على أمثلة متنوعة. يكشف التحليل أن DiP يحسن تنوع الشروط المسبقة بشكل كبير مقارنة بخط أساس بحث الحزمة. أيضًا ، يُظهر التقييم اليدوي أن DiP يولد شروطًا مسبقة أكثر من خط الأساس القوي لأخذ عينات النواة.', 'zh': '语言之典,系于逻上,而常识性连事不叙。 为此缺陷,专注生前提条件事。 前提条件生而序之:给定事,可前提条件也。 然多实之中,事可数前提条件,非度seq2seq框架也。 臣等建DiP,多样化前提条件生统,可以生特前提条件。 DiP 三成 - 事采样器、候生成器、后处理器。 事采样器制代码(前提条件触发器),候选生成器用此代码以集其成。 后处理因重序及漉更善。 与他生统不同,DiP 自生制代码,无待于示例。 分析表明,比波束搜索基线,DiP著前提条件之多样性。 此外手动评估,DiP多于强核采样基线前提条件。', 'fr': "Un objectif typique de la compréhension d'une langue est de relier logiquement les événements d'un discours, mais souvent les événements conjonctifs ne sont pas décrits en raison de leur nature de bon sens. Afin de remédier à ce déficit, nous nous concentrons ici sur la génération d'événements préconditionnels. La génération de préconditions peut être définie comme un problème séquence à séquence\xa0: en fonction d'un événement cible, générez une éventuelle précondition. Cependant, dans la plupart des scénarios réels, un événement peut avoir plusieurs conditions préalables, ce qui n'est pas toujours adapté aux frameworks seq2seq standard. Nous proposons DiP, le système de génération de préconditions diverses qui peut générer des conditions préalables uniques et diverses. DiP comprend trois étapes du processus de génération\xa0: un échantillonneur d'événements, un générateur de candidats et un post-processeur. L'échantillonneur d'événements fournit des codes de contrôle (déclencheurs de précondition) que le générateur de candidats utilise pour focaliser sa génération. Le post-traitement améliore encore les résultats grâce à un nouveau classement et à un filtrage. Contrairement aux autres systèmes de génération conditionnelle, DiP génère automatiquement des codes de contrôle sans formation sur divers exemples. L'analyse révèle que le DiP améliore considérablement la diversité des conditions préalables par rapport à une ligne de base de recherche de faisceau. De plus, l'évaluation manuelle montre que le dIP génère plus de conditions préalables qu'une base solide d'échantillonnage du noyau.", 'hi': 'भाषा की समझ के लिए एक विशिष्ट लक्ष्य एक प्रवचन की घटनाओं को तार्किक रूप से जोड़ना है, लेकिन अक्सर संयोजी घटनाओं को उनकी सामान्य ज्ञान प्रकृति के कारण वर्णित नहीं किया जाता है। इस घाटे को संबोधित करने के लिए, हम यहां पूर्व शर्त घटनाओं को उत्पन्न करने पर ध्यान केंद्रित करते हैं। पूर्व शर्त पीढ़ी को अनुक्रम-से-अनुक्रम समस्या के रूप में तैयार किया जा सकता है: एक लक्ष्य घटना को देखते हुए, एक संभावित पूर्व शर्त उत्पन्न करें। हालांकि, अधिकांश वास्तविक दुनिया के परिदृश्यों में, एक घटना में कई पूर्व शर्तें हो सकती हैं, जो हमेशा मानक seq2seq ढांचे के लिए उपयुक्त नहीं होती हैं। हम डीआईपी का प्रस्ताव करते हैं, विविध पूर्वशर्त पीढ़ी प्रणाली जो अद्वितीय और विविध पूर्व शर्तें उत्पन्न कर सकती है। डीआईपी में उत्पादक प्रक्रिया के तीन चरण होते हैं - एक ईवेंट सैंपलर, एक उम्मीदवार जनरेटर और एक पोस्ट-प्रोसेसर। ईवेंट सैंपलर नियंत्रण कोड (पूर्व शर्त ट्रिगर) प्रदान करता है जो उम्मीदवार जनरेटर अपनी पीढ़ी पर ध्यान केंद्रित करने के लिए उपयोग करता है। पोस्ट-प्रोसेसिंग फिर से रैंकिंग और फ़िल्टरिंग के माध्यम से परिणामों में और सुधार करती है। अन्य सशर्त पीढ़ी प्रणालियों के विपरीत, डीआईपी स्वचालित रूप से विविध उदाहरणों पर प्रशिक्षण के बिना नियंत्रण कोड उत्पन्न करता है। विश्लेषण से पता चलता है कि डीआईपी बीम खोज बेसलाइन की तुलना में पूर्व शर्तों की विविधता में काफी सुधार करता है। इसके अलावा, मैनुअल मूल्यांकन से पता चलता है कि डीआईपी एक मजबूत नाभिक नमूना आधार रेखा की तुलना में अधिक पूर्व शर्तें उत्पन्न करता है।', 'ru': 'Типичная цель для понимания языка - логически связать события дискурса, но часто соединяющие события не описываются из-за их здравого смысла. Для того чтобы устранить этот дефицит, мы сосредоточимся здесь на создании предпосылок. Формирование предварительных условий может быть обрамлено как задача последовательности: при заданном целевом событии, сгенерируйте возможное предварительное условие. Однако в большинстве реальных сценариев событие может иметь несколько предварительных условий, что не всегда подходит для стандартных фреймворков seq2seq. Мы предлагаем DiP, систему создания разнообразных предварительных условий, которая может создавать уникальные и разнообразные предварительные условия. DiP состоит из трех этапов генерирующего процесса – пробоотборник событий, генератор-кандидат и пост-процессор. Пробоотборник событий предоставляет контрольные коды (триггеры предварительных условий), которые генератор-кандидат использует для фокусировки своей генерации. Пост-обработка дополнительно улучшает результаты за счет повторного ранжирования и фильтрации. В отличие от других систем условной генерации, DiP автоматически генерирует управляющие коды без обучения на различных примерах. Анализ показывает, что DiP значительно улучшает разнообразие предварительных условий по сравнению с базовой линией поиска луча. Кроме того, ручная оценка показывает, что DiP создает больше предварительных условий, чем сильный базовый уровень выборки ядер.', 'ja': '言語理解の典型的な目標は、話題の事象を論理的につなぐことであるが、多くの場合、つながりのある事象はその常識的な性質のために説明されない。 この赤字に対処するために、ここでは前提条件イベントの生成に焦点を当てています。 前提条件の生成は、シーケンス間の問題としてフレーム化することができます：ターゲットイベントを与えられた場合、可能な前提条件を生成します。 しかしながら、ほとんどの現実世界のシナリオでは、イベントはいくつかの前提条件を持つことができ、これは常に標準的なseq 2 seqフレームワークに適しているとは限らない。 独自の多様な前提条件を生み出すことができる多様な前提条件生成システムであるDiPを提案します。 DiPは、生成プロセスの3つの段階（イベントサンプラー、候補ジェネレータ、ポストプロセッサ）から構成されています。 イベントサンプラーは、候補ジェネレータが生成に焦点を合わせるために使用する制御コード（前提条件トリガ）を提供します。 後処理は、再ランク付けとフィルタリングを通じて結果をさらに向上させます。 他の条件付き生成システムとは異なり、DiPは多様な例に関するトレーニングなしに制御コードを自動的に生成します。 分析により、DiPは、ビームサーチベースラインと比較して、前提条件の多様性を著しく向上させることが明らかになった。 また、手動評価では、DiPは強い核サンプリングベースラインよりも多くの前提条件を生成することが示されている。', 'ga': 'Sprioc tipiciúil le haghaidh tuiscint teanga ná imeachtaí dioscúrsa a nascadh go loighciúil, ach is minic nach gcuirtear síos ar imeachtaí nascacha mar gheall ar a nádúr ciallmhar. Chun aghaidh a thabhairt ar an easnamh seo, dírímid anseo ar imeachtaí réamhchoinníollacha a ghiniúint. Is féidir giniúint réamhchoinníoll a chumadh mar fhadhb seicheamh-go-seicheamh: má thugtar sprioc-imeacht, gin réamhchoinníoll féideartha. I bhformhór na gcásanna sa saol fíor, áfach, is féidir go mbeadh roinnt réamhchoinníollacha ag imeacht, nach mbíonn oiriúnach i gcónaí do chreataí caighdeánacha seq2seq. Molaimid DiP, an córas giniúna Réamhchoinníoll Éagsúla ar féidir leis réamhchoinníollacha uathúla agus éagsúla a ghiniúint. Tá trí chéim den phróiseas giniúna i gceist le DiP – samplóir imeachtaí, gineadóir iarrthóra, agus iarphróiseálaí. Soláthraíonn an samplóir teagmhais cóid rialaithe (truicear réamhchoinníollacha) a úsáideann an gineadóir iarrthóra chun a ghiniúint a dhíriú. Feabhsaíonn iar-phróiseáil na torthaí tuilleadh trí athrangú agus scagadh. Murab ionann agus córais giniúna coinníollach eile, gineann DiP cóid rialaithe go huathoibríoch gan oiliúint ar shamplaí éagsúla. Léiríonn anailís go bhfeabhsaíonn DiP éagsúlacht na réamhchoinníollacha go suntasach i gcomparáid le bunlíne cuardaigh bhíoma. Chomh maith leis sin, léiríonn meastóireacht láimhe go ngineann DiP níos mó réamhchoinníollacha ná bunlíne láidir samplála núicléas.', 'ka': 'ტიპური მიზეზი ენათების გაგრძნობისთვის არის ლოგიკურად დაკავშირება დისკურისთვის მოვლენების, მაგრამ ზოგჯერ დაკავშირებული მოვლენების შესახებ არ აღწერა მათ ამ დეფიქტის შესახებ, ჩვენ აქ წინასწორებული მოვლენების შექმნაზე დავუყენებთ. პრეკონდეციის შექმნა შესაძლებელია შესაძლებელია სეკონდეციის პრობლემა: მინიშვნელოვანი მოვლენა, შესაძლებელი პრეკონდეციის შექმნა. მაგრამ, უფრო მსოფლიო სინარიოში, მოვლენა შეიძლება აქვს რამდენიმე პრეკონდიციები, რომელიც არ ყოველთვის საჭირო სტანდარული seq2seq ფრამებისთვის. ჩვენ შეგიძლიათ DiP, განსხვავებული პრეკონდიციო განვითარების სისტემა, რომელიც შეუძლია განსხვავებული და განსხვავებული პრეკონდიციოს შექმნა. DiP იყო სამი ფაესების გენერაციური პროცესის - მოვლენების გამოყენებელი, კანდიდენტის გენერატორი და პოსპროცესორი. მოვლენის ჩვენებელი კონტროლური კოდეები (პრეკონდიციო გამოყენებელია) რომელიც კანდიდენტის ģeneraტორის გამოყენება თავის წარმოქმებას. შემდეგ პროცესის შემდეგ შემდეგ შემდეგ შემდეგი შემდეგი შემდეგი შემდეგი რედაქტირება და ფილტრირება. DiP ავტომატურად კონტროლური კოდეები განსხვავებულ მაგალითად განსხვავებული მაგალითად განსხვავებულ შემდეგ განსხვავებული შემდეგების გარეშე. ანალიზია, რომ DiP-ს განსხვავება პრეკონდიციების განსხვავებას მნიშვნელოვანად გადამყვერდება, რომელიც სინამდვილეების ძირითადი სინამდვილეებით ასევე, პირადი განსაზღვრება ჩვენებს, რომ DiP იქნება უფრო მეტი პირველ განსაზღვრება, ვიდრე ძალიან ნუკულის გამოიყენება ბაზი ხაზი.', 'it': "Un obiettivo tipico per la comprensione del linguaggio è quello di collegare logicamente gli eventi di un discorso, ma spesso gli eventi connettivi non sono descritti a causa della loro natura comune. Per affrontare questo deficit, ci concentriamo qui sulla creazione di eventi precondizionali. La generazione di precondizioni può essere inquadrata come un problema sequenza-sequenza: dato un evento target, generare una possibile precondizione. Tuttavia, nella maggior parte degli scenari del mondo reale, un evento può avere diverse precondizioni, che non è sempre adatto per framework seq2seq standard. Proponiamo Dip, il sistema di generazione Diverse Precondition in grado di generare precondizioni uniche e diversificate. Dip consiste in tre fasi del processo generativo - un campionatore di eventi, un generatore candidato e un post-processore. Il campionatore di eventi fornisce codici di controllo (trigger precondizionali) che il generatore candidato utilizza per focalizzare la sua generazione. La post-elaborazione migliora ulteriormente i risultati attraverso il riordino e il filtraggio. A differenza di altri sistemi di generazione condizionale, DiP genera automaticamente codici di controllo senza formazione su diversi esempi. L'analisi rivela che Dip migliora significativamente la diversità delle precondizioni rispetto a una base di ricerca del fascio. Inoltre, la valutazione manuale mostra che Dip genera più precondizioni di una base di campionamento del nucleo forte.", 'kk': 'Тілді түсіндіру үшін әдетті мақсат - дискурстың оқиғаларын логикалық түрде қосылу, бірақ көбінде қосылған оқиғалар олардың көпшілік сезімінен түсінбейді. Бұл дефицитті өзгерту үшін біз осы жерде алдындағы оқиғаларды құру үшін көздейміз. Алдын- ала құру кезінде реттеу- мен реттеу мәселесі ретінде фреймдеу болады: мақсатты оқиға берілген, мүмкін алдын- ала құру мүмкін. Бірақ ең шын әлемдегі сценарияларда, оқиға бірнеше бұрыштық шарттар болуы мүмкін, бұл әрқашанда стандартты seq2seq фреймворлар үшін жарамсыз емес. Біз ДиП- ді, әртүрлі бағдарламаларды құру жүйесі, бірнеше және әртүрлі бағдарламаларды құруға болады. ДиП генерациялық процестің үш этапы - оқиға үлгісі, кандидатты генераторы және соңғы процессоры. Оқиға үлгісі кандидатты генераторының жасау үшін басқару кодтарын береді. Орындау кейін нәтижелерді қайта реттеу және сүзгілеу арқылы жақсы жасайды. Басқа шарттарды құру жүйелеріне сәйкес, DiP автоматты түрде әртүрлі мысалдар бойынша бақылау кодтарын құрады. Анализ дегені ДиП- тің алдындағы шарттардың түрлігін жақсы салыстырады. Сонымен қатар, қолмен оқу дегені көрсетеді, ДиП ядролық түрлендіру негізгі жолынан артық шарттарды құрады.', 'lt': 'A typical goal for language understanding is to logically connect the events of a discourse, but often connective events are not described due to their commonsense nature.  Siekiant išspręsti šį deficit ą, daugiausia dėmesio skiriame išankstinių sąlygų sukūrimui. Atsižvelgiant į tikslinį įvykį, galima sukurti galimą išankstinę sąlygą. Tačiau daugumoje realaus pasaulio scenarijų renginys gali turėti keletą išankstinių sąlygų, kurios ne visada tinka standartinėms seq2seq sistemoms. We propose DiP, the Diverse Precondition generation system that can generate unique and diverse preconditions.  DiP sudaro trys generacinio proceso etapai – įvykio mėginių ėmėjas, kandidatas ir pakartotinis perdirbėjas. Įvykių mėginių ėmėjas pateikia valdymo kodus (išankstinius įjungiklius), kuriuos gamintojas kandidatas naudoja savo gamybai sutelkti. Po perdirbimo rezultatai toliau gerinami perskirstant ir filtruojant. Unlike other conditional generation systems, DiP automatically generates control codes without training on diverse examples.  Analizė rodo, kad DiP gerokai pagerina išankstinių sąlygų įvairovę, palyginti su pradine šviesos paieška. Be to, atlikus rankinį vertinimą paaiškėjo, kad DiP sukuria daugiau išankstinių sąlygų nei stiprių branduolinių mėginių ėmimo pradinė vertė.', 'el': 'Ένας τυπικός στόχος για την κατανόηση της γλώσσας είναι να συνδέσει λογικά τα γεγονότα ενός λόγου, αλλά συχνά τα συνδετικά γεγονότα δεν περιγράφονται λόγω της κοινής λογικής τους φύσης. Για να αντιμετωπιστεί αυτό το έλλειμμα, επικεντρωνόμαστε εδώ στη δημιουργία γεγονότων προϋπόθεσης. Η δημιουργία προϋποθέσεων μπορεί να πλαισιωθεί ως ένα πρόβλημα αλληλουχίας προς αλληλουχίας: δεδομένου ενός γεγονότος στόχου, δημιουργήστε μια πιθανή προϋπόθεση. Ωστόσο, στα περισσότερα σενάρια πραγματικού κόσμου, ένα γεγονός μπορεί να έχει αρκετές προϋποθέσεις, κάτι που δεν είναι πάντα κατάλληλο για τα τυποποιημένα πλαίσια seq2seq. Προτείνουμε το σύστημα δημιουργίας ποικίλων προϋποθέσεων που μπορεί να δημιουργήσει μοναδικές και ποικίλες προϋποθέσεις. Το diP αποτελείται από τρία στάδια της παραγωγικής διαδικασίας από έναν δειγματολήπτη συμβάντων, μια υποψήφια γεννήτρια και έναν μετα-επεξεργαστή. Ο δειγματολήπτης συμβάντων παρέχει κωδικούς ελέγχου (ενεργοποιητές προϋπόθεσης) τους οποίους χρησιμοποιεί η υποψήφια γεννήτρια για να εστιάσει την παραγωγή της. Η μετεπεξεργασία βελτιώνει περαιτέρω τα αποτελέσματα μέσω της επανακατάταξης και του φιλτραρίσματος. Σε αντίθεση με άλλα συστήματα παραγωγής υπό όρους, το παράγει αυτόματα κωδικούς ελέγχου χωρίς εκπαίδευση σε διάφορα παραδείγματα. Η ανάλυση αποκαλύπτει ότι η διP βελτιώνει σημαντικά την ποικιλομορφία των προϋποθέσεων σε σύγκριση με μια γραμμή αναζήτησης ακτίνων. Επίσης, η χειρωνακτική αξιολόγηση δείχνει ότι η διP παράγει περισσότερες προϋποθέσεις από μια ισχυρή βάση δειγματοληψίας πυρήνων.', 'hu': 'A nyelv megértésének tipikus célja, hogy logikailag összekapcsolja a diskurzus eseményeit, de a közérzetük miatt gyakran nem írják le a kötő eseményeket. Ennek a hiánynak a kezelése érdekében itt az előfeltételek kialakítására összpontosítunk. Az előfeltételek generálása sorozat-sorozat problémaként keretezhető fel: adott célesemény esetén lehetséges előfeltételeket kell létrehozni. A legtöbb valós forgatókönyvben azonban egy eseménynek több előfeltétele lehet, ami nem mindig alkalmas standard seq2seq keretrendszerekhez. Javasoljuk a Dip-t, a Diverse Precondition generációs rendszert, amely egyedi és változatos előfeltételeket generál. A Dip a generációs folyamat három szakaszából áll - egy eseménymintavevőből, egy jelölt generátorból és egy utóprocesszorból. Az eseménymintavevő olyan vezérlőkódokat (előfeltételek kiváltók), amelyeket a jelölt generátor használ a generáció fókuszálására. Az utófeldolgozás tovább javítja az eredményeket az átrendezés és a szűrés révén. Más feltételes generációs rendszerekkel ellentétben a Dip automatikusan generál vezérlőkódokat anélkül, hogy különböző példákat képzett volna. Az elemzés azt mutatja, hogy a Dip jelentősen javítja az előfeltételek sokféleségét a sugárkeresési alaphoz képest. A kézi értékelés azt is mutatja, hogy a Dip több előfeltételt generál, mint egy erős mag mintavételi alap.', 'ms': 'Tujuan biasa untuk pemahaman bahasa adalah untuk secara logik menyambungkan peristiwa dari sebuah ucapan, tetapi peristiwa sambungan sering tidak diterangkan kerana sifat umum mereka. In order to address this deficit, we focus here on generating precondition events.  Jenerasi prasyarat boleh bingkai sebagai masalah urutan-ke-urutan: diberi peristiwa sasaran, menghasilkan prasyarat yang mungkin. Bagaimanapun, dalam kebanyakan skenario dunia nyata, peristiwa boleh mempunyai beberapa syarat awal, yang tidak sentiasa sesuai untuk bingkai seq2seq piawai. Kami cadangkan DiP, sistem generasi Preconditions Berberbeza yang boleh menghasilkan preconditions unik dan berbeza. DiP terdiri dari tiga tahap proses generatif - pengumpul peristiwa, penjana calon, dan pos-pemproses. Penampil peristiwa menyediakan kod kawalan (pemicu preandisi) yang mana penjana calon guna untuk fokus generasinya. Pos-proses lebih meningkatkan keputusan melalui rangkaian semula dan penapisan. Tidak seperti sistem generasi syarat lain, DiP secara automatik menghasilkan kod kawalan tanpa latihan pada contoh berbeza. Analisi menunjukkan bahawa DiP meningkatkan pelbagai syarat awal secara signifikan dibandingkan dengan dasar carian cahaya. Also, manual evaluation shows that DiP generates more preconditions than a strong nucleus sampling baseline.', 'mk': 'A typical goal for language understanding is to logically connect the events of a discourse, but often connective events are not described due to their commonsense nature.  За да го решиме дефицитот, се фокусираме на генерирање предусловни настани. Генерацијата на предуслови може да се нацрта како проблем од секвенца до секвенца: со оглед на целниот настан, генерира можна предуслов. Сепак, во повеќето сценарија на реалниот свет, настанот може да има неколку предуслови, кои не секогаш се соодветни за стандардните рамки seq2seq. Предложуваме ДиП, системот за генерација на различни предуслови кој може да генерира уникатни и различни предуслови. ДиП се состои од три фази на генеративниот процес - примерувач на настаните, кандидатски генератор и постпроцесор. Примерувачот на настаните обезбедува контролни кодови (предусловни активатори) кои кандидатскиот генератор ги користи за да ја фокусира својата генерација. По процесорот понатаму ги подобрува резултатите преку рерангирање и филтрирање. За разлика од другите системи на условна генерација, DiP автоматски генерира контролни кодови без обука на различни примери. Анализата покажува дека ДиП ја подобрува различноста на предусловите значително во споредба со основата на пребарувањето по прозорец. Also, manual evaluation shows that DiP generates more preconditions than a strong nucleus sampling baseline.', 'ml': 'ഭാഷ മനസ്സിലാക്കാനുള്ള ഒരു സാധാരണ ലക്ഷ്യം ഒരു സംസാര സംഭാഷണത്തിന്\u200dറെ സംഭവങ്ങള്\u200d ലോഗിക്കല്\u200d ബന്ധപ്പെടുത്തുന്നതാണ്, പക്ഷെ പലപ ഈ അസാധാരണയെ സംസാരിക്കാന്\u200d വേണ്ടി, മുന്നോട്ടുള്ള സംഭവങ്ങള്\u200d ഉണ്ടാക്കുന്നതിന് ഞങ്ങള്\u200d ഇവിടെ ശ്രദ് മുന്നിലുള്ള തലമുറന്നു് സെക്കന്\u200dസ്- ട്രെയിന്\u200dസ് പ്രശ്നമായി ഫ്രെയിമെന്\u200dറ് ചെയ്യാം: ലക്ഷ്യം നല്\u200dകിയിരിക്കുന എന്നാലും, ഏറ്റവും യഥാര്\u200dത്ഥ ലോകത്തിലെ സാധാരണകളില്\u200d ഒരു സംഭവത്തിന് പല മുന്\u200dഗണങ്ങള്\u200d ഉണ്ടാക്കാം, അത് എപ്പോഴും സാധാരണ സെക്ക്2seq ഫ നമ്മള്\u200d ഡിപിയെ പ്രിസ്റ്റേഷന്\u200d തലമുറയ്ക്കുന്ന വ്യത്യസ്ത തലമുറന്ന സിസ്റ്റമാണ് പ്രൊദ്ദേശിക്കുന് ഡിപിയില്\u200d ജനറല്\u200d പ്രക്രിയയുടെ മൂന്ന് സ്റ്റേജ് ഉണ്ട്- ഒരു സംഭവത്തിന്റെ മാമ്പ്പിള്\u200d, ഒരു പ്രാര്\u200dട്ടിഡറ്റ് ജെനററെ @ info Post-processing further improves the results through re-ranking and filtering.  വ്യത്യസ്ത തലമുറതലമുറയുടെ സിസ്റ്റം വ്യത്യസ്തമായി ഡിപി നിയന്ത്രണ കോഡുകള്\u200d സൃഷ്ടിക്കുന്നു. പല ഉദാഹരണങ് ഒരു ബീമ് തെരച്ചില്\u200d ബേസ്റ്റ് ലൈനിനോട് മാത്രം ഡിപി മുന്\u200dഗണങ്ങളുടെ വ്യത്യസ്ത വ്യത്യാസം മുന്\u200dകൂട്ടുന്നതാണ കൈയ്യൂണല്\u200d വിലാസങ്ങള്\u200d കാണിക്കുന്നു, ഡിപി ശക്തിയുള്ള നൂക്ലിയസ് മാമ്പിള്\u200d ലൈനിനെക്കാള്\u200d മുന്\u200dഗണന സൃഷ', 'mt': 'Għan tipiku għall-fehim tal-lingwa huwa li loġikament jiġu konnessi l-avvenimenti ta’ diskors, iżda ta’ spiss avvenimenti konnettivi mhumiex deskritti minħabba n-natura komuni tagħhom. Sabiex nindirizzaw dan id-defiċit, hawnhekk niffokaw fuq il-ġenerazzjoni ta’ avvenimenti ta’ prekondizzjoni. Il-ġenerazzjoni ta’ prekondizzjoni tista’ titfassal bħala problem a minn sekwenza għal sekwenza: meta jingħata avveniment fil-mira, tiġġenera prekondizzjoni possibbli. Madankollu, fil-biċċa l-kbira tax-xenarji tad-dinja reali, avveniment jista’ jkollu diversi prekundizzjonijiet, li mhux dejjem huwa adattat għal oqfsa standard seq2seq. Aħna nipproponu d-DiP, is-sistema ta’ ġenerazzjoni ta’ prekondizzjonijiet Diversi li tista’ tiġġenera prekondizzjonijiet uniċi u diversi. DiP jikkonsisti fi tliet stadji tal-proċess ġenerattiv - kampjunatur tal-avvenimenti, ġeneratur kandidat, u post-proċessur. Il-kampjunatur tal-avvenimenti jipprovdi kodiċijiet ta’ kontroll (attivaturi ta’ prekondizzjoni) li l-ġeneratur kandidat juża biex jiffoka l-ġenerazzjoni tiegħu. Wara l-ipproċessar ikompli jtejjeb ir-riżultati permezz ta’ klassifikazzjoni mill-ġdid u filtrazzjoni. Unlike other conditional generation systems, DiP automatically generates control codes without training on diverse examples.  L-analiżi turi li DiP itejjeb id-diversità tal-prekondizzjonijiet b’mod sinifikanti meta mqabbel mal-linja bażi tat-tiftix tar-raġġ. Also, manual evaluation shows that DiP generates more preconditions than a strong nucleus sampling baseline.', 'mn': 'Холын ойлголтын ерөнхий зорилго бол ярианы үйл явдлыг логикийн хувьд холбох, гэхдээ ихэвчлэн холбоотой үйл явдлыг тэдний ихэвчлэн ойлголтын байгалиас тайлбарлахгүй. Эдгээр хүчирхийллийг зогсоохын тулд бид энд анхны үйл явдлыг бий болгохын тулд анхаарлаа төвлөрүүлнэ. Дараагийн төгсгөл нь дарааллаас дарааллаар бодлого болгож чадна: зорилготой үйл явдал өгсөн, боломжтой алдын шалтгаан гаргаж чадна. Гэхдээ ихэнх бодит ертөнцийн хувилбарт нэг үйл явдал хэд хэдэн арга хэмжээнд байж болно. Энэ нь үргэлж стандарт seq2seq хэмжээсүүдэд хэрэгтэй биш. Бид ДиП-г, өөр өөр төрлийн шалтгааныг бүтээж чадах олон төрлийн шалтгаан төрүүлэх системийг санал болгож байна. ДиП нь бүтээлч үйлдвэрлэлийн гурван хэмжээсүүдийн бүтэц, үйл явдлын sampler, кандидатын генератор, дараа нь процессор юм. Ийм үйл явдлын sampler нь удирдлага кодыг (анхны шалтгаан үйлдвэрлэх шалтгаан) ашигладаг бөгөөд тэдний үеийнхөө төвлөрөх зорилго ашигладаг. Дараа ажиллах нь үр дүнг дахин цуврал болон сүзүүлэхээр улам сайжруулдаг. Өөр нөхцөл байдал үеийн системээс ялгаатай, DiP өөр өөр жишээ дээр суралцахгүй контрол кодыг автоматаар үүсгэдэг. ДиП-ын шинжилгээ нь галзуу хайлтын суурь шугамын харьцуулахад илүү олон нөхцөл байдлыг сайжруулдаг гэдгийг харуулдаг. Мөн гарын дүгнэлт нь ДиП нь хүчирхэг ядролын зарцуулах суурь шугамнаас илүү нөхцөл байдлыг бий болгодог.', 'ro': 'Un scop tipic pentru înțelegerea limbii este de a conecta logic evenimentele unui discurs, dar adesea evenimentele conjunctive nu sunt descrise din cauza naturii lor comune. Pentru a aborda acest deficit, ne concentrăm aici pe generarea de evenimente precondiționale. Generarea precondiției poate fi încadrată ca o problemă secvență-la-secvență: dată fiind un eveniment țintă, generați o posibilă precondiție. Cu toate acestea, în majoritatea scenariilor din lumea reală, un eveniment poate avea mai multe precondiții, ceea ce nu este întotdeauna potrivit pentru cadrele standard seq2seq. Propunem Dip, sistemul de generare a preconditiilor diverse care poate genera conditii preliminare unice si diverse. Dip constă în trei etape ale procesului generativ - un eșantior de evenimente, un generator candidat și un post-procesor. Eșantiorul de evenimente furnizează coduri de control (declanșatori precondiționați) pe care generatorul candidat le utilizează pentru a-și concentra generarea. Post-procesarea îmbunătățește în continuare rezultatele prin re-ranking și filtrare. Spre deosebire de alte sisteme de generare condiționată, DiP generează automat coduri de control fără instruire pe diferite exemple. Analiza arată că Dip îmbunătățește în mod semnificativ diversitatea precondițiilor comparativ cu o bază de căutare a fasciculului. De asemenea, evaluarea manuală arată că Dip generează mai multe precondiții decât o bază puternică de eșantionare nucleară.', 'pl': 'Typowym celem rozumienia języka jest logiczne połączenie wydarzeń dyskursu, ale często zdarzenia łączne nie są opisywane ze względu na ich zdrowy rozsądek charakter. Aby rozwiązać ten deficyt, skupiamy się tutaj na generowaniu zdarzeń warunkowych. Generowanie warunków wstępnych może być oprawione jako problem sekwencji do sekwencji: biorąc pod uwagę zdarzenie docelowe, wygeneruj ewentualny warunek wstępny. Jednak w większości scenariuszy realnych zdarzenie może mieć kilka warunków wstępnych, co nie zawsze jest odpowiednie dla standardowych frameworków seq2seq. Proponujemy DiP, różnorodny system generowania wstępnych warunków, który może generować unikalne i zróżnicowane warunki wstępne. DiP składa się z trzech etapów procesu generacyjnego: próbkownika zdarzeń, generatora kandydatów i postprocesora. Próbkownik zdarzeń dostarcza kody sterujące (wyzwalacze warunków wstępnych), które generator kandydatów używa do skupienia swojego generowania. Post-processing jeszcze bardziej poprawia wyniki poprzez zmianę rankingu i filtrowanie. W przeciwieństwie do innych systemów generacji warunkowej, Dip automatycznie generuje kody sterowania bez szkolenia na różnych przykładach. Analiza ujawnia, że DiP znacznie poprawia różnorodność warunków wstępnych w porównaniu z bazą wyszukiwania wiązki. Również ręczna ocena pokazuje, że DiP generuje więcej warunków wstępnych niż silna baza pobierania próbek jądra.', 'no': 'Eit typisk mål for språk forståking er å kopla til hendingane til ein diskurs logisk, men ofte tilkoplingar er ikkje beskriven av sine vanleg natur. For å adressa denne defikten, fokuserer vi her på å laga førehandsvisningar. Førehandsvising kan framvisast som eit problem med sekvens- til- sekvens: gitt ei mål- hending, lager ein mogleg førehandsvising. I dei fleste verdsscenarioane kan imidlertid ein hending ha fleire førehandsvising, som ikkje alltid er passande for standard seq2seq-rammeverk. Vi foreslår DiP, den forskjellige førehandsvisingssystemet som kan laga unike og forskjellige førehandsvising. DiP inneheld tre stader av den genererige prosessen – eit hendingssprøver, ein kandidatgenerator og ein postprosesser. Hendingssprøver tilbyr kontrollkode (førehandsvising utløysar) som kandidatgeneratoren brukar for å fokusera genereringen sin. På prosessering forbetrar resultatet gjennom rekreasering og filtrering. I motsetjing til andre kondicionale genereringssystemar, vil DiP automatisk laga kontrollkode utan trening på ulike eksemplar. Analyser viser at DiP forbedrar mangfolda av førehandsvising betydelig samanlikna med ein straumsøkingsbaseline. Manuell evaluering viser også at DiP lagar fleire førehandsvising enn ein sterk kjerneprøvebaseline.', 'sr': 'Tipični cilj za razumevanje jezika je logički povezati događaje diskursa, ali često povezivanje događaja se ne opisuje zbog njihove prirode uobičajenosti. Da bi se riješili deficit, fokusiramo se ovde na stvaranje preduvjeta. Generacija predkondicija se može okrenuti kao problem sekvence do sekvence: s obzirom na ciljni događaj, stvoriti moguće predkondicije. Međutim, u većini scenarija stvarnog svijeta događaj može imati nekoliko preduvjeta, koji nije uvek odgovarajući standardnim okvirama seq2seq. Predlažemo DiP, sistem generacije različitih predstava koji može stvoriti jedinstvene i različite predstave. DiP se sastoji od tri faze generativnog procesa - uzorak događaja, generator kandidata i postprocesor. Uzorak događaja pruža kontrolne kodove (pokreće predstavu) koje kandidat generator koristi da fokusira svoju generaciju. Poslije obrade dalje poboljšava rezultate ponovnog reda i filtriranja. Za razliku od drugih uvjetnih sistema generacije, DiP automatski proizvodi kontrolne kodove bez obuke na različitim primjerima. Analiza pokazuje da DiP poboljšava raznolikost predstava u usporedbi s početnom linijom pretraživanja zraka. Takoðe, ruèna procjena pokazuje da DiP stvara više preduvjeta nego jaku osnovnu liniju uzorka nuklearnih uzorka.', 'si': 'භාෂාව තේරුම්ගන්න සාමාන්\u200dය අරක්ෂාවක් තමයි කතාවක් ගැන සැකසුම් සම්බන්ධ කරන්න, ඒත් සාමාන්\u200dය සම්බන්ධ වැඩක මේ අවස්ථාවක් විදිහට පරීක්ෂා කරන්න, අපි මෙතන ප්\u200dරධාන සැකසුම් සිද්ධ වෙනුවෙන් සිද්ධ වෙන ප්\u200dරතිස්ථානයක් ප්\u200dරශ්නයක් නිර්මාණය කරන්න පුළුවන්: ලක්ෂණ අවස්ථානයක් දෙන්න, පුළුවන් ප්\u200dරතිස්ථා නමුත්, ගොඩක් ඇත්ත ලෝකය සිනාරියෝ වලින්, සිද්ධ වෙන්න පුළුවන් වෙන්න පුළුවන්, ඒක හැමවෙලේම ප්\u200dරමාණිත seq2seq අපි DiP ප්\u200dරශ්නයක් කරනවා, විවිධ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් නිර්මාණය කරන්න පුළුවන් විවිධ සහ විවිධ ප්\u200dර DiP සම්පූර්ණයෙන් ප්\u200dරවෘත්තියක් තුන් ස්ථානයක් තියෙනවා - සැම්පුර්ණ සැම්පර්, ප්\u200dරවෘත්තියක් ජෙනරේ සම්ප්\u200dරේෂණය සැම්පර් පාලනය කෝඩ් ප්\u200dරවර්තනය (ප්\u200dරිකෝන්ඩිෂ්ටිෂ්ටිෂ්ටිෂ්ටිෂ්ටිෂ්ටිෂ පස්සේ ප්\u200dරක්\u200dරියාස කරන්න ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර අනිත් සාමාන්\u200dය පද්ධතියක් වෙනුවෙන්, DiP ස්වයංක්\u200dරියාවිතයෙන් පාලනය කරනවා විවිධ උදාහරණ වලට ප්\u200d විශ්ලේෂණය ප්\u200dරකාශ කරනවා ඩිපී ප්\u200dරධාන විවිධ විවිධියක් වැඩි කරනවා කියලා. ඒවගේම, පුද්ගලික විශ්ලේෂණය පෙන්වන්නේ DiP වලින් වඩා පුද්ගලික විශ්ලේෂණයක් නිර්මාණය කරනවා කියලා.', 'so': 'Goobaha caadiga ah ee waxgarashada luuqadu waa in lagu xiriiro dhacdooyinka hadalka, laakiin inta badan lama qorayo dhacdooyinka xiriirka ah, sababtoo ah dabeecada xirfadda. Si aan u baaraandegista, halkan waxaynu ku kalsoonaynaa dhaqdhaqaalaha dhacdooyinka hore. Muuqashada xaaladaha hore waxaa loo soo bandhigi karaa dhibaato soo socda, marka la sameeyo dhacdo goal ah, wuxuu dhali karaa horumar suurtagal ah. Si kastaba ha ahaatee, dhacdooyinku waxay heli karaan qaar ka hor-socda, taasoo aan mar walba ku habboonayn qashinka hoose-2seq ee standard. Waxaan soo jeedaynaa DiP, nidaamka muuqashada kala duduwan ee kala duduwan, kaas oo soo saari kara horumar kala duduwan oo kala duduwan. DiP wuxuu ka mid yahay sadex marxaladood oo ah sameynta dhacdooyinka, dhaqdhaqaalaha kandidada iyo shaqo-bixiyaha ka dambeeya. The event sampler provides control codes (precondition triggers) which the candidate generator uses to focus its generation.  Ka dib baaraandegista kadibna wuu sii kordhiyaa midhihiisa marka lagu sameynayo baaritaanka iyo baaritaanka. Sidoo kale nidaamka qarniga kale ee shuruudaha ah DiP wuxuu si gaar ah u dhashaa codyo kontroll ah oo aan tababar ku lahayn tusaalooyin kala duduwan. Analysis wuxuu muujiyaa in DiP hagaajiyo kala duduwan horumarinta, si muhiim ah loogu barbarbarto saldhigga raadinta beam. Waxaa sidoo kale qiimeynta qofka gacanta ah ka muuqata in DiP uu sameeyo horumar ka badan sameynta sameynta nukleus.', 'sv': 'Ett typiskt mål för språkförståelse är att logiskt koppla samman händelserna i en diskurs, men ofta beskrivs inte sammanhängande händelser på grund av sin allmännyttiga natur. För att åtgärda detta underskott fokuserar vi här på att skapa förutsättningar. Förutsättningsgenerering kan inramas som ett sekvens-till-sekvensproblem: givet en målhändelse, generera en möjlig förutsättning. Men i de flesta verkliga scenarier kan en händelse ha flera förutsättningar, vilket inte alltid är lämpligt för standard sek2seq ramverk. Vi föreslår Dip, Diverse Precondition generation system som kan generera unika och mångsidiga förutsättningar. Dip består av tre steg i den generativa processen - en händelsesampler, en kandidatgenerator och en efterprocessor. Eventprovtagaren tillhandahåller kontrollkoder (förhandsutlösare) som kandidatgeneratorn använder för att fokusera sin produktion. Efterbehandling förbättrar resultaten ytterligare genom omräkning och filtrering. Till skillnad från andra system för villkorlig generering genererar DiP automatiskt kontrollkoder utan utbildning på olika exempel. Analysen visar att Dip förbättrar mångfalden av förutsättningar avsevärt jämfört med en strålsökning baslinje. Manuell utvärdering visar också att Dip genererar fler förutsättningar än en stark kärnprovtagning baslinje.', 'ta': 'மொழிப் புரிந்து கொள்ளும் பேச்சின் நிகழ்வுகளை தொடர்புடன் இணைக்க ஒரு இயல்பான கோள், ஆனால் பெரும்பாலாக இணைப்பு நிகழ்வுகள்  இந்த எதிர்பார்ப்பை விளக்க, முன்னோட்ட நிகழ்வுகளை உருவாக்க இங்கே நாம் கவனம் செலுத்துகிறோம். முன்னிருப்பு உருவாக்கத்தை தொடர்ந்து வரிசையில் பிரச்சனையாக வடிவமைக்கலாம்: இலக்கு நிகழ்வு கொடுக்கப்பட்டுள்ளது,  ஆனால், பெரும்பாலும் உண்மையான உலக விளைவுகளில், நிகழ்வு முன்னுரிமைகள் இருக்க முடியும், அது எப்போதும் இயல்பான நிலையான வி நாம் DiP, வேறு முன்நிலைமை உருவாக்கும் முன்னுரிமை அமைப்பை பரிந்துரைக்கிறோம். அது தனிப்பட்ட மற்றும் பல மு DiP பொதுவான செயல்பாட்டின் மூன்று நிலையில் உள்ளது - நிகழ்வு மாதிரியாளர், சார்ந்திருப்பு உருவாக்கி, பின் செயல்பா @ info: whatsthis பின்செயல்படுத்தல் முடிவுகளை மீண்டும் திரும்பச் செய்து மற்றும் வடிகட்டியின் மூலம் முடிவுகள வேறு நிபந்தனை உருவாக்கும் அமைப்புகளை வித்தியாசமாக, DiP தானாகவே கட்டுப்பாட்டு குறியீடுகளை உருவாக்குக விளக்கம் DiP முன்னுரிமைகளின் பல்வேறு முன்னுரிமைகளை மேம்படுத்துகிறது ஒரு beam தேடுதல் அடிப்படையில் ஒப்பிடுவதை  கைமுறை evaluation shows that DiP generates more preconditions than strong nucleus sampling baseline.', 'ur': 'زبان سمجھنے کے لئے عادت کا موقع یہ ہے کہ ایک صحبت کے اتباع کو لایقی طور پر اتباع کرنا ہے لیکن اکثر اتباع کرنے والی اتباع کی وجہ سے ان کی عادت کی وجہ سے توصیف نہیں کی جاتی۔ ہم یہاں پیش وضع حادثوں کی پیدائش پر تمرکز کرتے ہیں۔ پیش کرم کی نسل کو سفارش-تا-سفارش مشکل کے طور پر فرم کر سکتا ہے: ایک موقع ایڈینٹ دیا گیا ہے، ایک امکان پیش کرم پیدا کر سکتا ہے. However, in most real-world scenarios, an event can have several preconditions, which is not always suitable for standard seq2seq frameworks. ہم ڈیپی کو پیشنهاد کرتے ہیں، مختلف پیشنهاد نسل سیستم جو ایک اور مختلف پیشنهاد پیدا کر سکتا ہے۔ ڈیپی کے تین مرحلے میں ہیں جنرائیٹ پرسس کی - ایک ایڈینٹ نمبر، ایک کاندینٹ جنرائیٹ اور ایک پوسٹ پرسسور. ایڈینٹ نمپٹر نے کنٹرول کوڈ (پیش آنڈیسی ٹریگر) کو پیش کرتا ہے جسے کاندینٹ جینراٹر اپنے نسل کو فوकस کرنے کے لئے استعمال کرتا ہے. پوسٹ پرسس کرنے کے ذریعے نتیجے دوبارہ رینگ اور فلٹرینگ کے ذریعے اضافہ کر دیتے ہیں. اور دوسری کنڈیسی نسل سیسٹم کے بغیر، DiP اپنے طور پر مختلف مثالوں پر آموزش بغیر کنٹرول کوڈ پیدا کرتا ہے. تحقیقات ظاہر کرتا ہے کہ DiP نے پیش موقعیت کی مختلف باتوں کو مزید مزید ترقی کی ہے۔ اور مہنیل ارزیابی دکھاتا ہے کہ DiP ایک طاقتور نیکلیوس نماذلینگ بنیس لین سے زیادہ پیش موقعیت پیدا کرتا ہے.', 'vi': 'Một mục tiêu tiêu điển hình cho sự hiểu biết ngôn ngữ là kết nối các sự kiện của cuộc nói chuyện, nhưng thường thì các sự kiện liên kết không được mô tả vì bản chất bình thường của họ. Để giải quyết thiếu hụt này, chúng ta tập trung vào việc tạo ra những tình huống cấp bách. Thế hệ tình trạng sẵn có thể được cấu hình như một vấn đề lặp lại: với một sự kiện đích, tạo ra một điều kiện có thể. Tuy nhiên, trong hầu hết các viễn cảnh thế giới thực, một sự kiện có thể có nhiều tình huống, mà không phải lúc nào cũng phù hợp với cấu trúc... Chúng tôi đề xuất DiP, hệ thống sản sinh mặc định đa dạng mà có thể tạo ra những điều kiện độc đáo và đa dạng. DiP bao gồm ba giai đoạn của quá trình tạo ra: một bản đo sự kiện, một máy phát hành ứng cử viên, và một bộ xử lý sau. Sự kiện thử nghiệm cung cấp mã điều khiển (nguyên tố hạt nhân) mà nhà máy ứng cử viên dùng để tập trung sản lượng của mình. Sau khi xử lý sẽ cải thiện kết quả bằng việc xếp lại và lọc. Không giống các hệ thống cấp độ khác, DiP tự động tạo ra mã điều khiển mà không dựa vào các trường hợp khác nhau. Phân tích cho thấy DiP cải thiện sự khác biệt của giới hạn đáng kể so với một đường hầm tìm tia. Theo đánh giá tay thì DiP tạo ra nhiều điều kiện hơn so với một cơ sở mẫu rắn chắc.', 'uz': "Tilni o'rganish uchun oddiy maqsad, suhbatning hodisalarini bogʻlash, lekin ko'p bogʻ'liq hodisalar ularning bogʻlanishi mumkin. Bu manbalarni boshqarish uchun, biz bu yerda oldingi hodisalarni yaratishga foydalanamiz. @ info: whatsthis Lekin, ko'pchilik dunyoda, hodisa bir necha darajalar bo'lishi mumkin. Bu har doim andoza seq2seq freymlariga yetarli emas. Biz DiP, muloqat precondition generation tizimi, uning va har xil darajalarni yaratish mumkin. Name @ info: whatsthis Name @ info Analysi koʻrsatish mumkin, DiP chegara qidirish bazasining tarkibini juda ham oshirish mumkin. Ko'pchilikni qoʻlbola qoʻlbola qiymati qoʻlbola qoʻlbola qiladi, DiP bir qanchalik nukleus sampli asosiy bazasini yaratadi.", 'nl': "Een typisch doel voor taalbegrip is om de gebeurtenissen van een discours logisch te verbinden, maar vaak worden verbindende gebeurtenissen niet beschreven vanwege hun gezonde aard. Om dit tekort aan te pakken, richten we ons hier op het genereren van randvoorwaarden gebeurtenissen. Het genereren van voorcondities kan worden geraamd als een sequentie-to-sequence probleem: als je een doelgebeurtenis hebt, genereer je een mogelijke randvoorwaarde. In de meeste real-world scenario's kan een evenement echter meerdere randvoorwaarden hebben, wat niet altijd geschikt is voor standaard seq2seq frameworks. We stellen DiP voor, het Diverse Precondition generatiesysteem dat unieke en diverse randvoorwaarden kan genereren. DiP bestaat uit drie fasen van het generatieve proces bestaande uit een event sampler, een kandidaat generator en een post-processor. De gebeurtenissampler levert controlecodes (precondition triggers) die de kandidaat generator gebruikt om zijn generatie te focussen. Post-processing verbetert de resultaten verder door re-ranking en filtering. In tegenstelling tot andere conditionele generatiesystemen genereert Dip automatisch besturingscodes zonder training op diverse voorbeelden. Uit analyse blijkt dat diP de diversiteit van randvoorwaarden aanzienlijk verbetert ten opzichte van een straalzoekbaseline. Ook toont de handmatige evaluatie aan dat diP meer randvoorwaarden genereert dan een sterke nucleus sampling baseline.", 'da': 'Et typisk mål for sprogforståelse er logisk at forbinde begivenhederne i en diskurs, men ofte beskrives bindende begivenheder ikke på grund af deres almindelige natur. For at afhjælpe dette underskud fokuserer vi her på at skabe forudsætningshændelser. Forudsætningsgenerering kan indrammes som et sekvens-til-sekvensproblem: Givet en målbegivenhed, generere en mulig forudsætning. Men i de fleste virkelige scenarier kan en begivenhed have flere forudsætninger, hvilket ikke altid er egnet til standard seq2seq framework. Vi foreslår Dip, Diverse Precondition generation systemet, der kan skabe unikke og forskellige forudsætninger. Dip består af tre faser af den generative proces - en begivenhedssampler, en kandidatgenerator og en post-processor. Begivenhedsprøveudløseren leverer kontrolkoder (forudsætningsudløsere), som kandidatgeneratoren bruger til at fokusere sin produktion. Efterbehandling forbedrer resultaterne yderligere gennem re-ranking og filtrering. I modsætning til andre betinget generationssystemer genererer DiP automatisk kontrolkoder uden træning i forskellige eksempler. Analyse afslører, at Dip forbedrer mangfoldigheden af forudsætninger betydeligt sammenlignet med en strålesøgning baseline. Manuel evaluering viser også, at Dip genererer flere forudsætninger end en stærk kerneprøveudtagning baseline.', 'bg': 'Типична цел за разбирането на езика е логично да се свържат събитията на дискурса, но често съединителните събития не се описват поради тяхната благоразумна природа. За да се справим с този дефицит, ние се фокусираме тук върху генерирането на събития за предварителни условия. Генерирането на предварително условие може да бъде оформено като проблем последователност към последователност: дадено целево събитие, генерира възможно предварително условие. Въпреки това, в повечето реални сценарии, събитието може да има няколко предпоставки, което не винаги е подходящо за стандартни рамки. Предлагаме система за генериране на разнообразни предпоставки, която може да генерира уникални и разнообразни предпоставки. ДиП се състои от три етапа на генеративния процес - проба за събития, кандидат генератор и постпроцесор. Пробвачът на събития предоставя контролни кодове (предварителни задействания), които кандидатът генератор използва, за да фокусира генерирането си. Последващата обработка допълнително подобрява резултатите чрез повторно класиране и филтриране. За разлика от други системи за условно генериране, автоматично генерира контролни кодове без обучение по различни примери. Анализът показва, че подобрява значително разнообразието от предпоставки в сравнение с базовата линия за търсене на лъч. Също така, ръчната оценка показва, че DiP генерира повече предпоставки, отколкото силна база за вземане на проби от ядро.', 'hr': 'Tipičan cilj za razumijevanje jezika je logički povezati događaje diskursa, ali često povezivanje događaja se ne opisuje zbog njihove prirode češće osjećaja. Da bi se riješili taj deficit, fokusiramo se ovdje na stvaranje preduvjetnih događaja. Generacija predmeta može se okrenuti kao problem sekvence do sekvence: s obzirom na ciljni događaj, stvoriti mogući predstav. Međutim, u većini scenarija stvarnog svijeta događaj može imati nekoliko preduvjeta, koji nije uvijek odgovarajući standardnim okvirama seq2seq. Predlažemo DiP, sistem generacije različitih predstava koji može stvoriti jedinstvene i različite predstave. DiP se sastoji od tri faze generativnog procesa - uzorak događaja, generator kandidata i postprocesora. Uzorak događaja pruža kontrolne kodove (pokreće preduvjete) koje kandidat generator koristi za fokusiranje svoje generacije. Poslije obrade dalje poboljšava rezultate ponovnog reda i filtriranja. Za razliku od drugih uvjetnih sustava generacije, DiP automatski proizvodi kontrolne kodove bez obuke na različitim primjerima. Analiza pokazuje da DiP poboljšava raznolikost preduvjeta u usporedbi s početnom linijom pretraživanja zraka. Također, ručna procjena pokazuje da DiP stvara više preduvjeta nego jaku početnu liniju uzorka nuklearnih uzorka.', 'fa': 'هدف معمولی برای فهمیدن زبان این است که رویدادهای یک گفتگو را منطقی ارتباط دهد، ولی اغلب رویدادهای ارتباطی به دلیل طبیعت معمولی آنها توصیف نمی شوند. برای حل این کمبود، ما اینجا روی تولید اتفاقات پیش\u200cاندازی تمرکز می\u200cکنیم. نسل پیش\u200cاندازی می\u200cتواند به عنوان یک مشکل پیش\u200cاندازی به رد\u200cاندازی قالب شود: به عنوان یک رویداد هدف داده شده، یک پیش\u200cاندازی ممکن ایجاد کنید. ولی در بیشترین سیناریو\u200cهای جهان واقعی، یک رویداد می\u200cتواند چندین شرایط پیش\u200cبینی داشته باشد، که همیشه برای فرم\u200cهای سq2seq استاندارد مناسب نیست. ما پیشنهاد می کنیم DiP، سیستم نسل مختلف پیشنهاد که می تواند شرایط مختلف و متفاوت را تولید کند. DiP consists of three stages of the generative process - an event sampler, a candidate generator, and a post-processor. نمونه\u200cساز رویداد کدهای کنترل (پیش\u200cاندازه\u200cهای آغاز) را می\u200cدهد که ژنراتور کاندیدا برای تمرکز نسل خود استفاده می\u200cکند. بعد از پردازش بیشتر نتیجه\u200cها را از طریق دوباره رشته\u200cبندی و فیلتر\u200cبندی بهتر می\u200cکند. برخلاف سیستم\u200cهای نسل شرایط دیگر، DiP به طور خودکار کدهای کنترل بدون آموزش در نمونه\u200cهای مختلف تولید می\u200cکند. تحلیل نشان می\u200cدهد که DiP مختلف شرایط پیش\u200cبینی را به طور کلی در مقایسه با یک خط پایین جستجو سیاه برق بهتر می\u200cکند. همچنین، ارزیابی دستی نشان می دهد که DiP شرایط پیش\u200cبینی بیشتر از یک خط پایین نمونه\u200cبندی هسته\u200cهای قوی تولید می\u200cکند.', 'id': 'Tujuan tipis untuk pemahaman bahasa adalah secara logis menghubungkan peristiwa dari sebuah pidato, tetapi sering peristiwa konektif tidak dijelaskan karena sifat umum mereka. Untuk mengatasi defisit ini, kita fokus di sini pada menghasilkan peristiwa awal syarat. Generasi predkondisi dapat dijangkau sebagai masalah urutan-ke-urutan: diberikan peristiwa sasaran, menghasilkan predkondisi yang mungkin. However, in most real-world scenarios, an event can have several preconditions, which is not always suitable for standard seq2seq frameworks.  Kami mengusulkan DiP, sistem generasi Preconditions Berbeda yang dapat menghasilkan kondisi preconditions unik dan berbeda. DiP terdiri dari tiga tahap dari proses generatif - pengumpul acara, generator kandidat, dan post-prosesor. Penampil peristiwa menyediakan kode kontrol (pemicu prekundisi) yang digunakan oleh generator kandidat untuk fokus generasinya. Pos-proses lebih memperbaiki hasilnya melalui rangkaian ulang dan penapisan. Tidak seperti sistem generasi kondisional lainnya, DiP secara otomatis menghasilkan kode kontrol tanpa latihan pada contoh-contoh berbeda. Analisi menunjukkan bahwa DiP meningkatkan kebanyakan kondisi awal secara signifikan dibandingkan dengan dasar pencarian sinar. Juga, evaluasi manual menunjukkan bahwa DiP menghasilkan lebih banyak kondisi awal daripada dasar pengumpulan nukleus yang kuat.', 'ko': '언어 이해의 전형적인 목표는 논리적으로 문장 속의 사건을 연결하는 것이지만 상식성 때문에 통상적으로 연결 사건을 묘사하지 않는다.이 결함을 해결하기 위해서 우리는 선결 조건 사건의 생성에 중점을 두고 있다.선결 조건 생성은 하나의 서열에서 서열까지의 문제로 볼 수 있다. 목표 이벤트를 정하고 가능한 선결 조건을 생성한다.그러나 대부분의 실제 장면에서 하나의 사건은 몇 가지 선결 조건이 있을 수 있는데 이것은 항상 표준적인 seq2seq 프레임워크에 적용되는 것이 아니다.고유하고 다양한 전제를 생성할 수 있는 다양성 전제 생성 시스템인 DiP를 제안했습니다.DiP는 생성 과정의 세 단계로 구성되어 있는데 그것이 바로 이벤트 샘플러, 후보 생성기, 후처리기이다.이벤트 샘플러는 제어 코드(전제 조건 트리거)를 제공하고 후보 생성기는 이 코드를 사용하여 이벤트를 집중적으로 생성합니다.후처리는 순서재정리와 필터링을 통해 결과를 더욱 개선합니다.다른 조건 생성 시스템과 달리 DiP는 다양한 예제에 대한 교육 없이 자동으로 제어 코드를 생성합니다.DiP는 빔 검색 기준선에 비해 전제조건의 다양성을 현저히 개선한 것으로 분석됐다.또한 수동 평가는 강력한 nucleus 샘플링 베이스라인보다 DiP가 생성하는 전제조건이 많다는 것을 보여준다.', 'de': 'Ein typisches Ziel des Sprachverständnisses ist es, die Ereignisse eines Diskurses logisch zu verknüpfen, aber oft werden verbindende Ereignisse aufgrund ihrer gesunden Natur nicht beschrieben. Um dieses Defizit zu beheben, konzentrieren wir uns hier auf die Generierung von Vorbedingungsereignissen. Die Erzeugung von Vorbedingungen kann als Sequenz-zu-Sequenz-Problem gerahmt werden: Erzeugen Sie bei einem Zielereignis eine mögliche Vorbedingung. In den meisten realen Szenarien kann ein Event jedoch mehrere Voraussetzungen haben, was für Standard-seq2seq-Frameworks nicht immer geeignet ist. Wir schlagen DiP vor, das Diverse Precondition Generierungssystem, das einzigartige und vielfältige Voraussetzungen generieren kann. DiP besteht aus drei Stufen des generativen Prozesses, bestehend aus einem Ereignissampler, einem Kandidatengenerator und einem Postprozessor. Der Ereignissampler liefert Steuercodes (Vorbedingungen-Trigger), mit denen der Kandidatengenerator seine Generierung fokussiert. Die Nachbearbeitung verbessert die Ergebnisse durch Re-Ranking und Filterung weiter. Im Gegensatz zu anderen Systemen zur bedingten Erzeugung generiert Dip automatisch Steuercodes ohne Schulung an verschiedenen Beispielen. Die Analyse zeigt, dass DiP die Vielfalt der Voraussetzungen im Vergleich zu einer Strahlsuche Baseline signifikant verbessert. Auch zeigt die manuelle Auswertung, dass DiP mehr Voraussetzungen erzeugt als eine starke Kernprobennahme Baseline.', 'tr': "Diller düşünmek üçin adatça maksady bolsa diskusiň wajyplaryny logik bilen baglaşdyrmak, ýöne köplenç baglaşyk wajyplary olaryň munuñ duýgularynyň sebäbi üýtgedilmedi. Bu hassyzlyk çözmek üçin, bu ýerde ön bellenen çykyşlary döretmäge üns beriyoruz. _BAR_ Ýöne, hakyky dünýäde birnäçe möhüm möhüm bolup biler. Bu ýerde hemişe standart seq2seq frameworklaryň üçin ýeterli däl. DiP'i, beýleki we beýleki kararlar döredijilik sistemini teklip edip bilýäris. DiP jenerativ prosesin üç taýýarlandyr - bir taýdan örnekleyici, kandidat jeneratöri we bir soňra işleýji. Vasiýa namaýyşçysy kontrol ködleri (öň bellenen taýýarlar) kandidýa jeneratöri öz generasiýasyny fokus etmek üçin ullanýar. Iň soňra işlem netijeleri ýene düzenleme we filtreleme bilen gelişmektedir. DiP mümkin görnöş sistemalary ýaly, dürli mysal bilen öwrenmeden kontrol ködlerini öz-özüne üretýär. Analyz çözümleri DiP'iň ön şartlaryň näçeşitligini baglaýyşlyk arama baselinine görä has gowurandyrýandygyny görkezýär. Ayrıca, el değerlendirme, DiP'nin güçlü nükleer örneklerinin basit çizgisinden daha ön şartları oluşturduğunu gösterir.", 'af': "'n Tipe doel vir taal verstanding is om die gebeurtenis van 'n diskursie te verbind, maar dikwels verbinding gebeurtenis word nie beskrywe vanweë hulle gemeenskaplike natuur nie. In order to address this deficit, we focus here on generating precondition events. Voorskou generasie kan wees raamd as 'n volgorde- na- volgorde probleem: gegewe 'n doel gebeurtenis, genereer 'n moontlik voorskou. Maar, in mees regte wêreld scenarios, kan 'n gebeurtenis veelvuldige voorkondisies hê, wat nie altyd geskikbaar is vir standaard seq2seq raamwerke nie. Ons stel DiP voorstel, die Verskeie voorstellings generasie stelsel wat unieke en verskeie voorstellings kan genereer. DiP bestaan van drie stadige van die genereerder proses -  'n gebeurtenis uitvanger, ' n kandidate genereerder en 'n post- prosesser. @ info: whatsthis Pos- prosessering verder verbeter die resultate deur herrangering en filtering. Ongelyks van ander voorwaardige generasie stelsels, DiP automaties genereer beheer kodes sonder onderwerp op verskeie voorbeelde. Analisie openbaar dat DiP die verskeidigheid van voorkondisies beter betekeurig vergelyk met 'n beam soektog basisline. Ook, manuele evaluering vertoon dat DiP meer voorstellings genereer as 'n sterk nukleus versameling basislien.", 'sq': 'Një qëllim tipik për kuptimin e gjuhës është të lidhin logjikisht ngjarjet e një diskursi, por shpesh ngjarjet lidhëse nuk janë përshkruar për shkak të natyrës së tyre të përbashkët. Për të trajtuar këtë defiçit, ne përqëndrohemi këtu në krijimin e ngjarjeve parakushtetuese. Gjenerimi i parakushteve mund të krijohet si një problem sekuencë në sekuencë: duke dhënë një ngjarje objektive, gjeneron një parakusht të mundshëm. Megjithatë, në shumicën e skenarëve të botës reale, një ngjarje mund të ketë disa parakushte, të cilat nuk janë gjithmonë të përshtatshme për kuadrin standard seq2seq. Ne propozojmë DiP, sistemin e gjenerimit të parakushteve të ndryshme që mund të gjenerojë parakushte unike dhe të ndryshme. DiP përbëhet nga tre faza të procesit gjenerativ - një mosmarrës veprimtari, një gjenerator kandidat dhe një post-procesor. Muzikuesi i ngjarjes ofron kodet e kontrollit (shkakton parakushtet) që gjeneratori kandidat përdor për të përqëndruar gjeneratën e tij. Pas procesit përmirëson më tej rezultatet nëpërmjet rindërtimit dhe filtrimit. Ndryshe nga sistemet e tjera të gjenerimit të kushtueshëm, DiP automatikisht gjeneron kode kontrolli pa stërvitje për shembuj të ndryshëm. Analiza zbulon se DiP përmirëson shumëllojshmërinë e parakushteve krahasuar ndjeshëm me një bazë kërkimi në rreze. Gjithashtu, vlerësimi manual tregon se DiP gjeneron më shumë parakushte sesa një bazë të fortë mosmarrëveshjeje bërthamore.', 'sw': 'Lengo la kawaida kwa kuelewa lugha ni kuwaunganisha matukio ya mazungumzo, lakini mara nyingi matukio yanayohusiana hayajaelezwa kutokana na asili yao ya umma. Ili kuzungumzia upinzani huu, tunajikita hapa katika kutengeneza matukio ya awali. Kizazi cha mazingira kinaweza kutengenezwa kama tatizo la mfululizo wa mfululizo: kutokana na tukio la lengo, kutengeneza kipaumbele kinachowezekana. Hata hivyo, katika hali halisi ya dunia, tukio hilo linaweza kuwa na vipaumbele kadhaa, ambavyo si sahihi kwa mfumo wa sekta 2seq wa kawaida. Tunazipendekeza DiP, mfumo wa uzalishaji wa hali tofauti unaoweza kutengeneza vipengele vya kipekee na tofauti. DiP ina hatua tatu ya mchakato wa jenerali - sampuli wa tukio, mtengenezaji wa mgombea, na mchakato baada ya mfululizo. Mfano wa tukio hilo unatoa kanuni za kudhibiti (mwanzo wa awali) ambazo mtengenezaji wa mgombea anatumia kuvutia kizazi chake. Baada ya kuchukua hatua hiyo inaboresha matokeo hayo kwa njia ya kuchuja tena na kuchuja filamu. Tofauti na mifumo mingine ya kizazi cha mazingira, DiP inatengeneza kanuni za kudhibiti bila mafunzo ya mifano mbalimbali. Analysis reveals that DiP improves the diversity of preconditions significantly compared to a beam search baseline.  Also, manual evaluation shows that DiP generates more preconditions than a strong nucleus sampling baseline.', 'am': 'የቋንቋ ማስተዋል የግንኙነት ግንኙነቶችን በመግኘት ማቀናቀል ነው፣ ነገር ግን ብዙ ጊዜ ግንኙነት ጉዳዮች ከግንኙነታቸው ግንኙነት ምክንያት አይዘረጉም፡፡ ይህንን አካላቢ ለመቀበል እናስቸጋለን፡፡ ምርጫዎች ነገር ግን አብዛኛዎቹ በዓለም ላይ በተመሳሳይ፣ ጉዳዩ ሁልጊዜ ለደካማዊ የseq2seq ፍሬም የማይገባ ብዙዎች የፊደል ጉዳይ ይኖራል፡፡ We propose DiP, the Diverse Precondition generation system that can generate unique and diverse preconditions.  ዲP በሦስት ደረጃዎች ውስጥ የጠቅላላ ፕሮጀክት - ጉዳዩ ምሳሌ፣ ምናዳሪ አዲስ እና በፖስታ ፕሮጀክር ነው፡፡ The event sampler provides control codes (precondition triggers) which the candidate generator uses to focus its generation.  ሁኔታ በሌላ ትውልድ ስርዓቶች በተለየ፣ ዲP በተለየ ምሳሌዎች በተለያዩ የሥልጣን ኮዶችን ማግኘት በራስነት ያስጀምራል፡፡ Analysis DiP የፊደል ልዩ ልዩነትን በሚያሳድግ በአበባ መረጃ መቀመጫዎች ላይ በማስተካከል ይገልጣል፡፡ በጅራዊ ማስታወቂያ ዲP ከብርቱ nucleus ምሳሌ መሳሳይ ይልቅ የበለጠ ጥንቃቄዎችን እንዲሠራ ያሳያል፡፡', 'hy': 'Լեզու հասկանալու բնորոշ նպատակն է տրամաբանական կապել խոսակցության իրադարձությունները, բայց հաճախ կապված իրադարձությունները չեն նկարագրվում իրենց ընդհանուր բնույթի պատճառով: Այս բացակայությունը լուծելու համար մենք կենտրոնանում ենք նախապայման իրադարձությունների ստեղծման վրա: Precondition generation can be framed as a sequence-to-sequence problem: given a target event, generate a possible precondition.  Այնուամենայնիվ, իրական աշխարհի մեծամասնության սցենարներում մի իրադարձություն կարող է ունենալ մի քանի նախապայմաններ, որոնք միշտ չեն համապատասխանում ստանդարտ Sex2Sef-ի շրջանակներին: We propose DiP, the Diverse Precondition generation system that can generate unique and diverse preconditions.  DiP-ը կազմված է սերունդային գործընթացի երեք փուլում՝ իրադարձությունների նմուշներ ընդունող, թեկնածու գեներատոր և պրոցեսոր: Այս իրադարձությունների նմուշների մասնակիչը ապահովում է վերահսկողական կոդներ (նախապայմանները), որոնք թեկնածու գեներատորը օգտագործում է իր սերունդը կենտրոնանալու համար: Post-processing further improves the results through re-ranking and filtering.  Ի տարբերություն այլ պայմանավոր սերունդների համակարգերից, DiP-ը ինքնաբերաբար ստեղծում է վերահսկողական կոդներ առանց հարցում տարբեր օրինակների վրա: Հետազոտությունը ցույց է տալիս, որ DiP-ը նշանակալիորեն բարելավում է նախապայմանների բազմազանությունը համեմատած ճառագայթի որոնման հիմքի հետ: Նաև ձեռքի գնահատումը ցույց է տալիս, որ DiP-ը ստեղծում է ավելի շատ նախապայմաններ, քան ուժեղ միջուկային նմուշների վերցման հիմքը:', 'bn': 'ভাষা বুঝার জন্য একটি সাধারণ লক্ষ্য হচ্ছে একটি কথোপকথনের ঘটনার সাথে যুক্ত করার জন্য, কিন্তু প্রায়শই সংযোগের ঘটনা তাদের কমিউনিসেন্ এই বিরুদ্ধে কথা বলার জন্য আমরা এখানে মনোযোগ দিচ্ছি পূর্ববর্তী ঘটনা তৈরি করার জন্য। পূর্বনির্ধারিত প্রজন্ম একটি সেকেন্স- থেকে সেকেন্সের সমস্যা হিসেবে ফ্রেম করা যাবে: টার্গেট অনুষ্ঠান দিয়ে সম্ভাব তবে বেশীরভাগ বিশ্বের দৃশ্যের মধ্যে একটি অনুষ্ঠানের বেশ কিছু পূর্বাবস্থা থাকতে পারে, যা স্ট্যান্ডার্ড সেক্ট২সেক ফ্রে We propose DiP, the Diverse Precondition generation system that can generate unique and diverse preconditions.  ডিপি জেনারেটিভ প্রক্রিয়ার তিন পর্যায়ের মধ্যে রয়েছে - একটি অনুষ্ঠানের Sampler, একটি প্রার্থী জেনারেটর এবং একটি পোস্ট প্রক্র এই অনুষ্ঠানের সাম্প্লায়ার নিয়ন্ত্রণ কোড প্রদান করে (প্রার্থী প্রার্থী জেনারেটর তার প্রজন্মের উপর মনোযোগ দিতে  পুনরায় র\u200d্যাঙ্কিং এবং ফিল্টারিং মাধ্যমে ফলাফল আরো উন্নত করে। অন্যান্য পরিস্থিতি প্রজন্মের সিস্টেম অনুরূপ, ডিপি স্বয়ংক্রিয়ভাবে নিয়ন্ত্রণ কোড তৈরি করে বিভিন্ন উদাহ বিশ্লেষণ প্রকাশ করেছে যে ডিপি বিমান অনুসন্ধানের বেসার লাইনের তুলনায় বৈচিত্র্যমগুলোর বৈচিত্র্য বৃদ্ধি প্রদ এছাড়াও মানুষের মূল্য দেখাচ্ছে যে ডিপি একটি শক্তিশালী নিউক্লিয়াস টাম্পলাইনের চেয়ে বেশি অগ্রগতি তৈরি করে।', 'cs': 'Typickým cílem pro porozumění jazyků je logické propojení událostí diskurzu, ale často spojivé události nejsou popsány kvůli jejich zdravému rozumu. Abychom tento deficit řešili, zaměřujeme se zde na generování předpokladných událostí. Generování předpodmínek může být rámováno jako problém sekvence k sekvenci: vzhledem k cílové události vygenerujte možný předpoklad. Ve většině reálných scénářů však může mít událost několik předpokladů, což není vždy vhodné pro standardní seq2seq frameworky. Navrhujeme DiP, systém pro generování různých představ, který může generovat jedinečné a různorodé předpoklady. DiP se skládá ze tří fází generačního procesu – vzorkovač událostí, generátor kandidátů a postprocesor. Vzorkovač událostí poskytuje řídicí kódy (triggery precondition), které kandidátský generátor používá k zaměření své generace. Post-processing dále zlepšuje výsledky prostřednictvím přehodnocení a filtrování. Na rozdíl od jiných systémů podmíněné generace, DiP automaticky generuje řídicí kódy bez školení na různých příkladech. Analýza ukazuje, že diP významně zlepšuje rozmanitost předpokladů ve srovnání s vyhledávací linií paprsku. Ruční vyhodnocení rovněž ukazuje, že diP generuje více předpokladů než silný základní vzorek jádra.', 'et': 'Keele mõistmise tüüpiline eesmärk on loogiliselt siduda diskursuse sündmusi, kuid sageli ei kirjeldata sidesündmusi nende mõistliku olemuse tõttu. Selle puudujäägi kõrvaldamiseks keskendume siin eeltingimuste sündmuste loomisele. Eeltingimuste genereerimist võib kujundada järjestuse-järjestuse probleemina: sihtsündmuse korral luuakse võimalik eeltingimus. Enamikus reaalmaailma stsenaariumides võib sündmusel siiski olla mitu eeltingimust, mis ei sobi alati standardsete seq2seq raamistike jaoks. Pakume välja DiP, mitmekesiste eeltingimuste tootmissüsteemi, mis suudab luua unikaalseid ja mitmekesiseid eeltingimusi. DiP koosneb generatiivse protsessi kolmest etapist - sündmuste proovivõtjast, kandidaadigeneraatorist ja järelprotsessorist. Sündmuste proovivõtja annab kontrollkoodid (eeltingimuse käivitajad), mida kandidaadigeneraator kasutab oma tootmise keskendumiseks. Järeltöötlus parandab tulemusi veelgi ümberhindamise ja filtreerimise kaudu. Erinevalt teistest tingimusliku generatsiooni süsteemidest genereerib DiP automaatselt kontrollkoode ilma erinevate näidete koolitamata. Analüüs näitab, et DiP parandab oluliselt eeltingimuste mitmekesisust võrreldes kiirte otsingu algväärtusega. Samuti näitab käsitsi hindamine, et DiP tekitab rohkem eeltingimusi kui tugeva tuumaproovivõtu algväärtus.', 'ca': "Un objectiu típic de la comprensió del llenguatge és connectar lògicament els esdeveniments d'un discurs, però sovint els esdeveniments conectivs no són descrits per la seva naturalesa comú. In order to address this deficit, we focus here on generating precondition events.  La generació de precondicions pot ser encarxada com un problem a de seqüència a seqüència: donant-se un esdeveniment objectiu, generar una possible precondició. However, in most real-world scenarios, an event can have several preconditions, which is not always suitable for standard seq2seq frameworks.  Proposem DiP, el sistema de generació de diverses condicions previes que pot generar condicions previes únices i diverses. DiP consists of three stages of the generative process - an event sampler, a candidate generator, and a post-processor.  El mostrador d'esdeveniments proporciona codis de control (desencadenadors de precondició) que el generador candidat utilitza per centrar la seva generació. El post-processament millora més els resultats a través de la redistribució i filtració. A diferència d'altres sistemes de generació condicional, DiP genera automàticament codis de control sense formació en diversos exemples. L'anàlisi revela que el DiP millora significativament la diversitat de les condicions precondicionales en comparació amb la base de recerca del raig. També, l'evaluació manual mostra que el DiP genera més precondicions que una base de mostració del nucli forta.", 'fi': 'Kielen ymmärtämisen tyypillinen tavoite on loogisesti yhdistää diskurssin tapahtumat, mutta usein kytkeviä tapahtumia ei kuvata niiden järkevän luonteen vuoksi. Tämän alijäämän korjaamiseksi keskitymme tässä edellytyksiä koskevien tapahtumien luomiseen. Edellytysten luominen voidaan kehystää sekvenssi-sekvenssiin ongelmana: kohdetapahtumassa luodaan mahdollinen ennakkoehto. Useimmissa reaalimaailman skenaarioissa tapahtumalla voi kuitenkin olla useita ennakkoehtoja, mikä ei aina sovellu standardiin seq2seq-kehyksiin. Ehdotamme DiP:tä, Diverse Precondition -järjestelmää, joka voi luoda ainutlaatuisia ja monipuolisia edellytyksiä. DiP koostuu kolmesta generatiivisen prosessin vaiheesta - tapahtumanäytteenottimesta, ehdokasgeneraattorista ja jälkiprosessorista. Tapahtumanäytteenottolaite tarjoaa ohjauskoodit (ennakkoehtolaukaisimet), joita ehdokasgeneraattori käyttää keskittääkseen tuotantonsa. Jälkikäsittely parantaa tuloksia entisestään uudelleenluokittelun ja suodatuksen avulla. Toisin kuin muut ehdollisen tuotannon järjestelmät, DiP luo automaattisesti ohjauskoodit kouluttamatta erilaisia esimerkkejä. Analyysi osoittaa, että DiP parantaa olosuhteiden monimuotoisuutta merkittävästi verrattuna säteen etsinnän lähtötilanteeseen. Manuaalinen arviointi osoittaa myös, että DiP luo enemmän edellytyksiä kuin vahva ydinnäytteenotto lähtötilanteessa.', 'az': "Dil anlayışının tipik məqsədi, diskusiyanın olaraqlarını logik olaraq bağlamaqdır, amma çox zaman bağlantılı olaraq olaraq olaraq olaraq tanımlanmaqdır. Bu zəifliyi çəkmək üçün, biz burada ön təsiri olaraq təşkil etmək üçün odaqlanırıq. Əvvəlcə təhsil nəsili sıralama-sıralama problemi olaraq çevirə bilər: məqsəd vaxtı verilən, mümkün bir əvvəlcə təhsil yarat. Ən çox dünya senaryosunda, bir olay bir neçə əvvəlkilər olar ki, bu həmişə standart seq2seq frameworkları üçün uyğun deyil. Biz DiP'i, müxtəlif əvvəlkilər nəsil sistemini təklif edirik ki, bənzər və müxtəlif əvvəlkilər yarada bilər. DiP generativ prosesinin üç dəfələrindən olub - vaxt örneçəsi, kandidat generator və post-processor. Vaxt örneçəsi nəsillərini fokus etmək üçün istifadə edən kontrol kodlarını (ön tərzdə təşkil edir). Sonra işləmə sonuçlarını yenidən sıralamaq və filtrləmək vasitəsilə daha yaxşılaşdırır. DiP başqa müxtəlif nəsil sistemlərinin bənzərinə baxmayaraq, müxtəlif məsəllərdə təhsil etmədən kontrol kodlarını avtomatik olaraq yaradır. Analizi göstərir ki, DiP'nin ön təkliflərin müxtəlif müxtəlif tərzlərini nütfədə xüsusiyyətləşdirir. Ayrıca, əlavə təcrübə göstərir ki, DiP qüvvətli nükleyin nükleer nükleer çəkməsi səhifəsindən daha çox əvvəlki təklif yaradır.", 'bs': 'Tipičan cilj za razumijevanje jezika je logički povezati događaje diskursa, ali često povezivački događaji se ne opisuju zbog njihove prirode uobičajenosti. Da bi se riješili taj deficit, fokusiramo se ovdje na stvaranje predstavnih događaja. Generacija predstave može biti okvirana kao problem sekvence do sekvence: s obzirom na ciljni događaj, stvoriti moguće predstave. Međutim, u većini scenarija stvarnog svijeta događaj može imati nekoliko preduvjeta, koji nije uvijek odgovarajući standardnim okvirama seq2seq. Predlažemo DiP, sistem generacije različitih predstava koji može stvoriti jedinstvene i različite predstave. DiP se sastoji od tri faze generativnog procesa - uzorka događaja, generator a kandidata i postprocesora. Uzorak događaja pruža kontrolne kodove (pokreće predstavu) koje kandidat generator koristi da fokusira svoju generaciju. Poslije obrade dalje poboljšava rezultate preko ponovnog reda i filtriranja. Za razliku od drugih uvjetnih sustava generacije, DiP automatski proizvodi kontrolne kodove bez obuke na različitim primjerima. Analiza pokazuje da DiP poboljšava raznolikost predstava u usporedbi s početnom linijom pretraživanja zraka. Također, ručna procjena pokazuje da DiP stvara više preduvjeta nego jaku početnu liniju uzorka nuklearnih uzorka.', 'jv': 'Awak dhéwé kanggo ngerasakno langkung rawuh akeh luwih dumadhi kapan pangan ning acara awak dhéwé, maca akèh dumadhining kanggo ngerasakno sing ora ngerasakno kanggo awak dhéwé. politenessoffpolite"), and when there is a change ("assertivepoliteness Language Nanging, iso nggo langgar-langgar seneng pisan-kanggo langgar, eventune iso mulai akeh liyo sing di antara awak, sing ora sembarang nggo awak dhéwé seq2seq frame. Awak dhéwé nggunakake DiP, akeh Dawisan Rasané Pangan barang nggawe sistem sing iso nggawe barang akeh dumadhil karo akeh podho akeh basa. DiP mlakuné karo telu pating ng panganan ning genetik - sampuran eventne, panganan elengkat, lan mulai perusahaan Sampur eventune mungkun kode dadi nggawe barang (suarti dadi tanggal). politenessoffpolite"), and when the re is a change ("assertive DiP kang dipoleh sistem sing paling kondkondision, DiP kang dipoleh kuwi nggawe kode kuwi wis mulasar seneng pisan sing sampeyan. Ndelengke dipoleh barang DiP kuwi nggawe barang kanggo kalagayaan karo perusahaan sing dibutuhke tarjamahan karo perusahaan bukal Manculine', 'ha': "Wata jigo na daidaita wa fahimtar harshen shine ana haɗi da halin bayani na wani magana, kuma amma ba za'a bayyana abun da ke da haɗuwa da yawa ba don a sabo da tsarin su. Dõmin a yi amfani da wannan ciri, za mu yi zura fokus a nan kan ka sami bakin ayuka na gabata. An iya ƙiƙiro halin sharri kamar wata mataimaki mai sauri-biyu-sequence: idan an motsa wani abu na goal, ya ƙãga wani matsayi mai yiwuwa. Amma, cikin masu ƙayyade duniya masu hushi, wani abu ya iya sami daidai, wanda bai daidai ba ga firam masu daidaita seq2seq. Tuna goyyar da DiP, na'urar danne da aka Divers Alƙibla, wanda za ta iya ƙiƙiro zaɓen wata na'awa da dabam-daban. DiP na ƙunsa da jujjuya uku na aikin aiki na daban-daban. @ info: whatsthis @ info: whatsthis DiP na ƙiƙiro wasu na'urar zabur masu hushi, yana ƙiƙiro kodi na kanana farat ɗaya kuma bã da wani shirin ba masu misãlai daban. Analyya ya bayyana cewa DiP ya improve variant wa masu gabatar da alƙalami mai significant sammenliki da wani basin search-line. Kayya, hakarin hannun na manual yana nuna cewa DiP yana samun zaɓa ɓo mafi ƙarfi daga samfanin nucleus.", 'he': 'מטרה טיפוסית להבנת שפה היא לחבר באופן הגיוני את האירועים של דיבור, אך לעתים קרובות האירועים הקשר לא מתארים בגלל הטבע המפורסם שלהם. כדי להתמודד עם ההפסד הזה, אנחנו מתמקדים כאן על ליצור אירועים מראשיים. דור התנאים מראש יכול להיות מסגר כבעיה רצף לרצף: בהתחשב באירוע מטרה, ליצור תנאי מראש אפשרי. However, in most real-world scenarios, an event can have several preconditions, which is not always suitable for standard seq2seq frameworks.  אנחנו מציעים דיפ, מערכת הדור של התנאים הקדמיים המוזרים שיכולה ליצור תנאים קדמיים מיוחדים ומשונים. DiP מורכב משלושה שלבים של תהליך הדור - מדגים אירועים, גנרטור מועמד, ואחרי מעבד. The event sampler provides control codes (precondition triggers) which the candidate generator uses to focus its generation.  לאחר העבודה משפר עוד את התוצאות באמצעות שינוי הדרגה וסנן. בניגוד למערכות דור תנאי אחרות, DiP מייצר אוטומטית קודים שליטה ללא אימון על דוגמאות רבות. Analysis reveals that DiP improves the diversity of preconditions significantly compared to a beam search baseline. בנוסף, הערכה ידנית מראה שדיפ יוצר יותר תנאים קדומים מאשר רמז חזק של דגימה גרעינית.', 'sk': 'Tipičen cilj razumevanja jezika je logično povezati dogodke diskurza, vendar vezivni dogodki pogosto niso opisani zaradi njihove splošne narave. Da bi odpravili ta primanjkljaj, se tukaj osredotočamo na ustvarjanje dogodkov o predpogojih. Ustvarjanje predpogojev se lahko oblikuje kot problem zaporedja do zaporedja: glede na ciljni dogodek ustvari možen predpogoj. Vendar ima lahko dogodek v večini realnih scenarijev več predpogojev, kar ni vedno primerno za standardne okvire seq2seq. Predlagamo DiP, sistem za proizvodnjo raznolikih predpogojev, ki lahko ustvari edinstvene in raznolike predpogoje. DiP sestavljajo tri faze generativnega procesa - vzorčevalnik dogodkov, kandidat generator in post-procesor. Vzorčevalnik dogodkov zagotavlja kontrolne kode (sprožilci predpogojev), ki jih kandidat generator uporablja za usmerjanje svoje proizvodnje. Naknadna obdelava dodatno izboljša rezultate s ponovno razvrstitvijo in filtriranjem. Za razliko od drugih sistemov pogojne generacije DiP samodejno ustvarja kontrolne kode brez usposabljanja o različnih primerih. Analiza kaže, da DiP bistveno izboljšuje raznolikost predpogojev v primerjavi z osnovnim izhodiščem iskanja snopa. Ročno ocenjevanje kaže tudi, da DiP ustvarja več predpogojev kot izhodišče za vzorčenje močnega jedra.', 'bo': 'སྐད་ཡིག་ཆ་རྟོགས་པའི་དམིགས་ཡུལ་ནི་ཁྱད་པར་བྱ་ཚིག་དང་འགྲེལ་བཤད་ཀྱི་བྱ་འགུལ་དང་ཡང་རྒྱུན་ལྡན ང་ཚོས་དུས་ཡོད་ཚད་ཆེན་པོ་འདིའི་ཐོག་ལས་ང་ཚོས་འདིར་སྔོན་འཛུགས་བྱ་འགུལ་གྱི་བཟོ་བཅོས་བྱེད་པར་བ Precondition generation can be framed as a sequence-to-sequence problem: given a target event, generate a possible precondition. Precondition ཡིན་ནའང་། ངོ་མ་རང་གི་འཇིག་རྟེན་འདི་ལྟ་བུའི་ནང་དུ་བྱ་འགུལ་གྱི་སྔོན་སྒྲིག་ཆས་གཞན་ཅིག་ཡོད་པ་མིན་པར་མཐུན་པ་གྱུར་བ་ཞིག་ ང་ཚོས་DiP(DiP)ལ་སྔོན་དང་མི་འདྲ་བའི་རྣམ་པ་གྲངས་ཀྱི་མ་དངུལ་རྒྱུན་ལྡན་མ་མཐུན་པ་དེ་གསར་གཏོང་ཐུབ་པའི་གསལ་གཞ DiP consists of three stages of the generative process - an event sampler, a candidate generator, and a post-processor. The event sampler provides control codes (precondition triggers) which the candidate generator uses to focus its generation. རྒྱབ་ལས་ཀ་ལས་སྦྱོར་མྱོང་གི་གནད་སྡུད་དེ་ལ་གྲལ་རིམ་དང་ཚགས་མ་གཉིས་ཀྱིས་མཐུན་གཏོང་། སྔོན་འཛུགས་ཀྱི་མ་ལག་གཞན་དང་མིན་པར། DiP་ལ་རང་འགུལ་གྱིས་འཛུལ་སྤྱོད་པའི་དཔེར་བརྗོད་དག་གི་མིང་ཚད་འཛིན་གྱི་ཨང དབྱེ་ཞིབ་ནི་DiP་གིས་སྔོན་སྒྲིག་འགོད་ཀྱི་དབྱེ་རིམ་དང་མཐོང་བའི་རྣམ་པ་ཞིག་ཉེན་ཁ་ཡོད་པ། ད་དུས། ལག་བཟོས་ཁང་གིས་ཞིབ་དཔྱད་བྱས་ན། DiP ནི་ཉེན་རིས་ཀྱིས་གཟུགས་རིས་གཞི་རྩལ་ལས་སྔོན་སྒྲིག'}
{'en': 'Incorporating EDS Graph for AMR Parsing', 'es': 'Incorporación de EDS Graph para el análisis AMR', 'ar': 'دمج الرسم البياني EDS لتحليل AMR', 'fr': "Incorporation d'EDS Graph pour l'analyse AMR", 'pt': 'Incorporando o EDS Graph para AMR Parsing', 'zh': '合 EDS 图 AMR 解析', 'hi': 'AMR पार्सिंग के लिए EDS ग्राफ़ को शामिल करना', 'ru': 'Включение графика EDS для анализа AMR', 'ja': 'AMR銉戙兗銈枫兂銈般伄銇熴倎銇瓻DS銈般儵銉曘伄绲勩伩杈笺伩', 'ga': 'Ionchorpraítear Graf EDS le haghaidh Parsáil AMR', 'hu': 'EDS grafikon beépítése az AMR-értelmezéshez', 'el': 'Συμπερίληψη γραφήματος EDS για ανάλυση AMR', 'it': "Incorporare il grafico EDS per l'analisi AMR", 'lt': 'Įterpiamas AMR analizavimo EDS grafikas', 'ka': 'AMR წარმოწმება', 'mk': 'Incorporating EDS Graph for AMR Parsing', 'ml': 'AMR പാര്\u200dസിങ്ങിനുള്ള EDS ഗ്രാഫ്', 'mn': 'AMR шинжилгээний EDS график', 'ms': 'Mengangkut Graf EDS untuk Menghurai AMR', 'kk': 'AMR талдау үшін EDS графигін ендіру', 'no': 'Inkorporarer EDS- graf for AMR- tolking', 'pl': 'Zawiera wykres EDS do analizy AMR', 'mt': 'Inkorporazzjoni ta’ Grafika EDS għall-Analiżi tal-AMR', 'sr': 'Uključujući EDS grafiku za AMR analizu', 'si': 'AMR විශ්ලේෂණය සඳහා EDS ග්\u200dරාෆ් සංවිධානය කරන්න', 'sv': 'Inbegripande av EDS-diagram för AMR-tolkning', 'ro': 'Incorporarea graficului EDS pentru analizarea AMR', 'ur': 'AMR پارچینگ کے لئے EDS گراف شامل کیا جاتا ہے', 'so': 'Xirfaha EDS ee jardiinada AMR', 'ta': 'AMR பாசிங்குக்கான EDS வரைப்படம்', 'uz': 'AMR parsing uchun EDS grafik yuklanmoqda', 'vi': 'Bộ đồ vẽ đế chế Phát triển AMR', 'bg': 'Включване на EDS графика за анализ на AMR', 'da': 'Integrering af EDS-diagram for AMR-fortolkning', 'nl': 'Met EDS Graph voor AMR Parsing', 'ko': 'AMR 해결을 위한 EDS 그림 결합', 'id': 'Menginkorporasi Graf EDS untuk Analis AMR', 'hr': 'Uključujući EDS grafiku za AMR analizu', 'fa': 'شامل گراف EDS برای تحلیل AMR', 'de': 'Integration von EDS Graph für AMR Parsing', 'sw': 'Nafsiri ya EDS kwa ajili ya Uchaguzi wa AMR', 'af': 'Inkorporeer EDS Graaf vir AMR verwerking', 'hy': 'ԱՄՌ-ի վերլուծության համար տեղադրված ԷԴՍ գրաֆը', 'az': 'AMR analizi üçün EDS Grafikini inkorporat edir', 'sq': 'Duke përfshirë grafikun EDS për analizimin AMR', 'bn': 'AMR পার্সিং এর জন্য EDS গ্রাফ অন্তর্ভুক্ত করা হচ্ছে', 'bs': 'Uključujući EDS grafiku za AMR analizu', 'ca': 'Incorporant EDS Graph for AMR Parsing', 'cs': 'Zahrnuje EDS graf pro analýzu AMR', 'et': 'EDS graafika lisamine AMR parsimiseks', 'fi': 'EDS-kaavion sisällyttäminen AMR-analyysiin', 'am': 'undo-type', 'tr': 'AMR Taýýarlama üçin EDS Grafiky girdirilýär', 'jv': 'Ombudhakan kelompok', 'ha': 'KCharselect unicode block name', 'he': 'מכיל גרף EDS עבור בדיקת AMR', 'sk': 'Vključitev EDS Graph za razčlenitev AMR', 'bo': 'AMR འཆར་བཤེར་གྱི་EDS་རིས་སྒྲིག་འགོད་པ'}
{'en': 'AMR (Abstract Meaning Representation) and EDS (Elementary Dependency Structures) are two popular meaning representations in NLP / NLU. AMR is more abstract and conceptual, while EDS is more low level, closer to the lexical structures of the given sentences. It is thus not surprising that EDS parsing is easier than AMR parsing. In this work, we consider using information from EDS parsing to help improve the performance of AMR parsing. We adopt a transition-based parser and propose to add EDS graphs as additional semantic features using a graph encoder composed of LSTM layer and GCN layer. Our experimental results show that the additional information from EDS parsing indeed gives a boost to the performance of the base AMR parser used in our experiments.', 'ar': 'AMR (تمثيل المعنى المجرد) و EDS (هياكل التبعية الأولية) هما تمثيلان شائعان للمعنى في NLP / NLU. تعتبر AMR أكثر تجريدًا وتصوريًا ، في حين أن EDS أقل مستوى ، وأقرب إلى الهياكل المعجمية للجمل المعطاة. وبالتالي فليس من المستغرب أن يكون تحليل EDS أسهل من تحليل AMR. في هذا العمل ، نأخذ في الاعتبار استخدام المعلومات من تحليل EDS للمساعدة في تحسين أداء تحليل AMR. نعتمد محللًا قائمًا على الانتقال ونقترح إضافة الرسوم البيانية EDS كميزات دلالية إضافية باستخدام مشفر الرسم البياني المكون من طبقة LSTM وطبقة GCN. تظهر نتائجنا التجريبية أن المعلومات الإضافية من تحليل EDS تعطي بالفعل دفعة لأداء محلل AMR الأساسي المستخدم في تجاربنا.', 'fr': "AMR (Abstract Meaning Representation) et EDS (Elementary Dependency Structures) sont deux représentations de signification populaires dans NLP/NLU. La RAM est plus abstraite et conceptuelle, tandis que l'EDS est plus bas, plus proche des structures lexicales des phrases données. Il n'est donc pas surprenant que l'analyse EDS soit plus facile que l'analyse AMR. Dans ce travail, nous envisageons d'utiliser les informations issues de l'analyse EDS pour améliorer les performances de l'analyse AMR. Nous adoptons un analyseur basé sur la transition et proposons d'ajouter des graphes EDS en tant que caractéristiques sémantiques supplémentaires à l'aide d'un encodeur de graphe composé d'une couche LSTM et d'une couche GCN. Nos résultats expérimentaux montrent que les informations supplémentaires provenant de l'analyse EDS donnent effectivement un coup de pouce aux performances de l'analyseur AMR de base utilisé dans nos expériences.", 'es': 'AMR (Abstract Meaning Representation) y EDS (Elementary Dependency Structures) son dos representaciones de significados populares en NLP/NLU. La AMR es más abstracta y conceptual, mientras que la EDS es de nivel más bajo, más cercana a las estructuras léxicas de las oraciones dadas. Por lo tanto, no es sorprendente que el análisis de EDS sea más fácil que el análisis de AMR. En este trabajo, consideramos el uso de la información del análisis de EDS para ayudar a mejorar el rendimiento del análisis de AMR. Adoptamos un analizador basado en transiciones y proponemos agregar gráficos EDS como características semánticas adicionales utilizando un codificador de gráficos compuesto por una capa LSTM y una capa GCN. Nuestros resultados experimentales muestran que la información adicional del análisis EDS realmente mejora el rendimiento del analizador AMR base utilizado en nuestros experimentos.', 'pt': 'AMR (Representação de Significado Abstrato) e EDS (Estruturas de Dependência Elementar) são duas representações de significado populares em NLP/NLU. O AMR é mais abstrato e conceitual, enquanto o EDS é de nível mais baixo, mais próximo das estruturas lexicais das sentenças dadas. Portanto, não é surpreendente que a análise de EDS seja mais fácil do que a análise de AMR. Neste trabalho, consideramos o uso de informações da análise EDS para ajudar a melhorar o desempenho da análise AMR. Adotamos um analisador baseado em transição e propomos adicionar grafos EDS como recursos semânticos adicionais usando um codificador de grafos composto de camada LSTM e camada GCN. Nossos resultados experimentais mostram que as informações adicionais da análise EDS realmente aumentam o desempenho do analisador AMR básico usado em nossos experimentos.', 'ja': 'AMR (Abstract Meaning Representation)およびEDS (Elementary Dependency Structures)は、NLP/NLUにおける2つの一般的な意味表現である。AMRはより抽象的で概念的であり、EDSはより低レベルであり、与えられた文の語彙構造に近い。したがって、EDS構文解析がAMR構文解析よりも容易であることは不思議ではない。この作業では、EDS構文解析からの情報を使用して、AMR構文解析のパフォーマンスを向上させることを検討します。遷移ベースの構文解析器を採用し、LSTMレイヤとGCNレイヤで構成されたグラフエンコーダを使用して、追加のセマンティック機能としてEDSグラフを追加することを提案します。実験結果は、EDS解析から得られた追加情報が、実験で使用されたベースAMRパーサーのパフォーマンスを向上させることを示しています。', 'zh': 'AMR(象义)与EDS(本赖)NLP / NLU中二义也。 AMR更抽象概念化,而EDS更卑级,更近给定句词汇结构。 故EDS 解析易于 AMR 解析,不足奇也。 于此之事,思用 EDS 解析以助 AMR 解析之能。 用转换之解析器,议用LSTM重GCN图编码器添EDS图为附语义特征。 吾实验结果表明者,EDS解析之附加信息实重实验用之本AMR解析器也。', 'hi': 'एएमआर (सार अर्थ प्रतिनिधित्व) और ईडीएस (प्राथमिक निर्भरता संरचनाएं) एनएलपी / एनएलयू में दो लोकप्रिय अर्थ प्रतिनिधित्व हैं। एएमआर अधिक अमूर्त और वैचारिक है, जबकि ईडीएस अधिक निम्न स्तर का है, जो दिए गए वाक्यों की लेक्सिकल संरचनाओं के करीब है। इस प्रकार यह आश्चर्य की बात नहीं है कि ईडीएस पार्सिंग एएमआर पार्सिंग की तुलना में आसान है। इस काम में, हम एएमआर पार्सिंग के प्रदर्शन को बेहतर बनाने में मदद करने के लिए ईडीएस पार्सिंग से जानकारी का उपयोग करने पर विचार करते हैं। हम एक संक्रमण-आधारित पार्सर को अपनाते हैं और एलएसटीएम परत और जीसीएन परत से बने ग्राफ एन्कोडर का उपयोग करके अतिरिक्त शब्दार्थ सुविधाओं के रूप में ईडीएस ग्राफ जोड़ने का प्रस्ताव करते हैं। हमारे प्रयोगात्मक परिणामों से पता चलता है कि ईडीएस पार्सिंग से अतिरिक्त जानकारी वास्तव में हमारे प्रयोगों में उपयोग किए जाने वाले आधार एएमआर पार्सर के प्रदर्शन को बढ़ावा देती है।', 'ru': 'AMR (Abstract Meaning Representation) и EDS (Elementary Dependency Structures) являются двумя популярными представлениями значений в NLP/NLU. АМР более абстрактна и концептуальна, в то время как ЭЦП более низкого уровня, ближе к лексическим структурам данных предложений. Таким образом, неудивительно, что синтаксический анализ EDS проще, чем синтаксический анализ AMR. В этой работе мы рассматриваем использование информации из анализа EDS, чтобы помочь улучшить производительность анализа AMR. Мы принимаем синтаксический анализатор на основе перехода и предлагаем добавить графики EDS в качестве дополнительных семантических признаков с помощью кодера графов, состоящего из уровня LSTM и уровня GCN. Наши экспериментальные результаты показывают, что дополнительная информация, полученная при анализе EDS, действительно повышает производительность базового анализатора AMR, используемого в наших экспериментах.', 'ga': 'Is dhá léiriú brí coitianta iad AMR (Léiriú Teibí Brí) agus EDS (Bunstruchtúir Spleáchais) in NLP/NLU. Tá AMR níos teibí agus níos coincheapúla, agus tá EDS níos ísle ar an leibhéal, níos gaire do struchtúir foclóireachta na n-abairtí tugtha. Ní haon ionadh mar sin go bhfuil parsáil EDS níos éasca ná parsáil AMR. San obair seo, breithnímid ar fhaisnéis ó pharsáil EDS a úsáid chun cabhrú le feidhmíocht pharsála AMR a fheabhsú. Glacaimid parsálaí atá bunaithe ar an trasdul agus molaimid graif EDS a chur leis mar ghnéithe séimeantacha breise ag baint úsáide as ionchódóir graf comhdhéanta de chiseal LSTM agus de chiseal GCN. Léiríonn ár dtorthaí turgnamhacha go dtugann an fhaisnéis bhreise ó pharsáil EDS treisiú ar fheidhmíocht an bhunpharsálaí AMR a úsáideadh inár dturgnaimh.', 'ka': 'AMR (Abstract Meaning Representation) და EDS (Elementary Dependency Structures) არიან ორი პოლიპური სანიშვნელობის გამოსახულებები NLP/NLU-ში. AMR არის უფრო აბსტრაქტური და კონცექტური, მაგრამ EDS უფრო ცოტა დონე, უფრო დამატებული სიტყვების ლექსიკალური სტრუქტურებისთვის. ამიტომ არ იცის, რომ EDS პარასტირება უფრო მარტივია AMR პარასტირებაზე. ამ სამუშაოში ჩვენ ვფიქრობთ, რომ EDS-ის პანსტირებადან ინფორმაციის გამოყენება AMR პანსტირების მუშაობის შესაძლებლობად. ჩვენ გავაკეთებთ გადავიწყებთ გადავიწყებული პროცენტორი და გავაკეთებთ EDS გრაფიკების დამატება როგორც დამატებული სიმენტიკური ფუნქციები, როგორც LSTM გრაფიკის და GCN გრაფიკის გამ ჩვენი ექსპერიმენტიური წარმოდგენა, რომ EDS პარასტიდან დამატებული ინფორმაცია ჩვენი ექსპერიმენტებში გამოყენებული AMR პარასტის გამოყენებას უფრო მეტია.', 'hu': 'Az AMR (Absztrakt Meaning Representation) és az EDS (Elementary Dependency Structures) két népszerű jelentési reprezentáció az NLP/NLU-ban. Az AMR absztraktabb és konceptuálisabb, míg az EDS alacsonyabb szintű, közelebb az adott mondatok lexikai struktúrájához. Ezért nem meglepő, hogy az EDS elemzés könnyebb, mint az AMR elemzés. Ebben a munkában fontolóra vesszük az EDS elemzéséből származó információk felhasználását az AMR elemzés teljesítményének javítására. Átmeneti alapú elemzőt alkalmazunk, és javasoljuk, hogy EDS grafikonokat adjunk hozzá további szemantikai funkciókként egy LSTM rétegből és GCN rétegből álló gráf kódoló segítségével. Kísérleti eredményeink azt mutatják, hogy az EDS elemzéséből származó további információk valóban fokozzák a kísérleteinkben használt alap AMR elemző teljesítményét.', 'el': 'Η ΑΜR (αφηρημένη εννοιολογική αναπαράσταση) και η EDS (στοιχειώδεις δομές εξάρτησης) είναι δύο δημοφιλείς αναπαραστάσεις εννοιών στο NLP/NLU. Η ΑΜR είναι πιο αφηρημένη και εννοιολογική, ενώ η ΕΔS είναι πιο χαμηλό επίπεδο, πιο κοντά στις λεξικές δομές των συγκεκριμένων προτάσεων. Επομένως, δεν αποτελεί έκπληξη το γεγονός ότι η ανάλυση EDS είναι ευκολότερη από την ανάλυση AMR. Σε αυτή την εργασία, εξετάζουμε τη χρήση πληροφοριών από την ανάλυση για να βοηθήσουμε στη βελτίωση της απόδοσης της ανάλυσης AMR. Υιοθετούμε έναν αναλυτή με βάση τη μετάβαση και προτείνουμε να προσθέσουμε γραφήματα ως πρόσθετα σημασιολογικά χαρακτηριστικά χρησιμοποιώντας έναν κωδικοποιητή γραφήματος που αποτελείται από στρώμα και στρώμα GCN. Τα πειραματικά μας αποτελέσματα δείχνουν ότι οι πρόσθετες πληροφορίες από την ανάλυση δίνει πράγματι ώθηση στην απόδοση του βασικού αναλυτή AMR που χρησιμοποιείται στα πειράματά μας.', 'kk': 'AMR (Abstract Meaning Representation) және EDS (Elementary Dependency Structures) NLP/NLU дегенде екі таңдау мәліметі. AMR - абстракты және концептуалды, ЕДС деңгейі төмен деңгейі, келтірілген сөздердің лексикалық құрылымына жақын. Бұл үшін EDS талдау AMR талдауынан оңай емес. Бұл жұмыс ішінде біз EDS талдауынан мәліметті қолдану үшін AMR талдауын жақсарту үшін көмектесеміз. Біз ауыстыру негізінде талдаушы қолданып, LSTM қабатты және GCN қабатты құрылған график кодерін қолдану үшін EDS графиктерін қосымша semantiкалық мүмкіндіктері ретінде қосу керек. Тәжірибелік нәтижелеріміз EDS талдауындағы қосымша мәліметтер өзімізде қолданылатын AMR талдаушының негізгі жұмысын көтереді.', 'it': "AMR (Abstract Meaning Representation) e EDS (Elementary Dependency Structures) sono due rappresentazioni popolari di significato in NLP/NLU. AMR è più astratto e concettuale, mentre EDS è di livello più basso, più vicino alle strutture lessicali delle frasi date. Non sorprende quindi che l'analisi EDS sia più facile dell'analisi AMR. In questo lavoro, consideriamo l'utilizzo di informazioni dall'analisi EDS per aiutare a migliorare le prestazioni dell'analisi AMR. Adottiamo un parser basato sulla transizione e proponiamo di aggiungere grafici EDS come funzionalità semantiche aggiuntive utilizzando un codificatore grafico composto da layer LSTM e layer GCN. I nostri risultati sperimentali mostrano che le informazioni aggiuntive dal parsing EDS danno effettivamente un impulso alle prestazioni del parser di base AMR utilizzato nei nostri esperimenti.", 'lt': 'AMR (Abstract Meaning Representation) ir EDS (Elementary Dependency Structures) yra dvi populiarios reikšmės atstovybės NLP/NLU. AMR is more abstract and conceptual, while EDS is more low level, closer to the lexical structures of the given sentences.  Todėl neįtikėtina, kad EDS analizavimas yra lengviau nei AMR analizavimas. Šiame darbe svarstome galimybę naudoti EDS analizavimo informaciją, kad pagerintume AMR analizavimo rezultatus. We adopt a transition-based parser and propose to add EDS graphs as additional semantic features using a graph encoder composed of LSTM layer and GCN layer.  Mūsų eksperimentiniai rezultatai rodo, kad papildoma EDS analizavimo informacija iš tiesų skatina mūsų eksperimentuose naudojamo bazinio AMR analizatoriaus veiksmingumą.', 'mk': 'АБР (Апстрактна претстава на значењето) и ЕДС (елементарни структури на зависност) се две популарни претстави на значење во НЛП/НЛУ. AMR is more abstract and conceptual, while EDS is more low level, closer to the lexical structures of the given sentences.  It is thus not surprising that EDS parsing is easier than AMR parsing.  Во оваа работа, размислуваме да користиме информации од анализирањето на ЕДС за да помогнеме во подобрувањето на перформансата на анализирањето на АМР. We adopt a transition-based parser and propose to add EDS graphs as additional semantic features using a graph encoder composed of LSTM layer and GCN layer.  Нашите експериментални резултати покажуваат дека дополнителните информации од анализирањето на ЕДС навистина даваат поттик на изведувањето на базата АМР анализатор користен во нашите експерименти.', 'ms': 'AMR (Perwakilan Arti Abstrakt) dan EDS (Struktur Dependensi Elementari) adalah dua perwakilan arti populer dalam NLP/NLU. AMR lebih abstrak dan konseptual, sementara EDS lebih rendah aras, lebih dekat dengan struktur leksikal kalimat yang diberikan. Ia tidak mengejutkan bahawa penghuraian EDS lebih mudah daripada penghuraian AMR. In this work, we consider using information from EDS parsing to help improve the performance of AMR parsing.  We adopt a transition-based parser and propose to add EDS graphs as additional semantic features using a graph encoder composed of LSTM layer and GCN layer.  Hasil percubaan kami menunjukkan bahawa maklumat tambahan dari penghuraian EDS benar-benar memberikan tumpuan kepada prestasi penghuraian AMR asas yang digunakan dalam percubaan kami.', 'ml': 'AMR (അസ്ട്രാക്റ്റ് റിപ്പോര്\u200dട്ട്രാക്റ്റ് റിപ്പോര്\u200dട്ടെന്\u200dറ് ചെയ്യുന്നത്) എഡിഎസും (മെന്റിമെന്ററി ഡിപ്പെന്\u200dസി സ്ട്രാക AMR കൂടുതല്\u200d ഉപേക്ഷിക്കപ്പെടുന്നതും കൂടുതല്\u200d ആശയവുമാകുന്നു. എഡിഎസ് കുറഞ്ഞതായിരിക്കുമ്പോള്\u200d കൊടുത്ത വാക്കുകളുട അതുകൊണ്ട് എംആര്\u200d പാര്\u200dജിങ്ങിനെക്കാള്\u200d എളുപ്പമാണെന്ന് EDS പാര്\u200dജിങ്ങ് അത്ഭുതമല്ല. ഈ ജോലിയില്\u200d, എംഎർ പാർജിങ്ങിന്റെ പ്രകടനം മെച്ചപ്പെടുത്താന്\u200d ഞങ്ങള്\u200d എഡിഎസ് പാർജിങ്ങില്\u200d നിന്നും വിവരങ ഞങ്ങള്\u200d ഒരു ട്രാന്\u200dസ്റ്റാന്\u200dസ് അടിസ്ഥാനമായ ഒരു പരാജയപ്രകാരം ഉപയോഗിക്കുകയും, എഡിഎസ് ഗ്രാഫുകള്\u200d കൂടുതല്\u200d സെമാന്റിക്ക് വിശേഷങ്ങളായി ചേര്\u200dക Our experimental results show that the additional information from EDS parsing indeed gives a boost to the performance of the base AMR parser used in our experiments.', 'mt': 'L-AMR (Rappreżentazzjoni tat-tifsira assoluta) u l-EDS (Strutturi ta’ Dipendenza Elementari) huma żewġ rappreżentazzjonijiet tat-tifsira popolari f’NLP/NLU. L-AMR hija aktar astratta u kunċettwali, filwaqt li l-EDS hija aktar livell baxx, eqreb lejn l-istrutturi lexiċi tas-sentenzi mogħtija. Għalhekk mhuwiex sorprendenti li l-analiżi tal-EDS hija eħfef mill-analiżi tal-AMR. F’dan ix-xogħol, qed nikkunsidraw l-użu ta’ informazzjoni mill-analiżi tal-EDS biex jgħinu fit-titjib tal-prestazzjoni tal-analiżi tal-AMR. Aħna niddottaw analizzatur ibbażat fuq it-tranżizzjoni u nipproponu li jiżdiedu grafiċi tal-EDS bħala karatteristiċi semantiċi addizzjonali bl-użu ta’ kodifikatur tal-grafika magħmul minn saff LSTM u saff GCN. Ir-riżultati sperimentali tagħna juru li l-informazzjoni addizzjonali mill-analiżi tal-EDS tabilħaqq tagħti spinta lill-prestazzjoni tal-analizzatur AMR bażiku użat fl-esperimenti tagħna.', 'mn': 'AMR (Abstract Meaning Representation) and EDS (Elementary Dependency Structures) are two popular meaning representations in NLP/NLU. АМР нь илүү абстракт болон ойлголттой, харин EDS нь илүү бага хэмжээтэй, өгсөн өгүүлбэрийн лексикийн бүтээгдэхүүнтэй ойрхон байдаг. Иймээс EDS хуваалцах нь AMR хуваалцаас илүү амархан гэдгийг гайхалтай биш. Энэ ажлын тулд бид EDS хуваалцааны мэдээллийг ашиглаж AMR хуваалцааны үйл ажиллагааг сайжруулахын тулд тусалдаг. Бид шилжилт дээр суурилсан хуваарч болон EDS графикийг LSTM давхар болон GCN давхараас бүрдүүлсэн график коддогч болон нэмэлт semantic боломжтой болгохыг санал болгож байна. Бидний туршилтын үр дүнд EDS хуваалцааны нэмэлт мэдээлэл бидний туршилтанд хэрэглэгдсэн AMR хуваалцагчийн ажиллагааг нэмэгдүүлдэг.', 'no': 'AMR (abstrakt gjennomsnittstav) og EDS (elementære avhengighetsstrukturer) er to populære meningsrepresentasjonar i NLP/NLU. AMR er meir abstrakt og konseptuelt, mens EDS er meir låg nivå, nærare dei leksiske strukturene av dei gitte setningane. Det er derfor ikkje overraska at EDS-tolking er lettere enn AMR-tolking. I dette arbeidet ser vi på å bruka informasjon frå EDS-tolking for å hjelpa til å forbetra utviklinga av AMR-tolking. Vi adopterer ein oversjånadsbasert tolkar og foreslår å leggja til EDS-grafikk som fleire semantiske funksjonar ved å bruka eit grafikkkoder som er lagt av LSTM-laget og GCN-laget. Eksperimentale resultatet våre viser at tilleggsinformasjonen frå EDS-tolkinga vere sikker på at utviklinga av AMR-tolkinga som er brukt i eksperimentet våre er større.', 'pl': 'AMR (Abstract Meaning Representation) i EDS (Elementary Dependency Structures) to dwie popularne reprezentacje znaczenia w NLP/NLU. AMR jest bardziej abstrakcyjny i koncepcyjny, natomiast EDS jest bardziej niski, bliżej struktury leksykalnej danych zdań. Nic więc dziwnego, że parsowanie EDS jest łatwiejsze niż parsowanie AMR. W niniejszej pracy rozważamy wykorzystanie informacji z parsowania EDS w celu poprawy wydajności parsowania AMR. Przyjmujemy parser oparty na przejściach i proponujemy dodanie wykresów EDS jako dodatkowych cech semantycznych za pomocą kodera wykresu złożonego z warstwy LSTM i warstwy GCN. Nasze wyniki eksperymentalne pokazują, że dodatkowe informacje z parsowania EDS rzeczywiście zwiększają wydajność bazowego parsera AMR stosowanego w naszych eksperymentach.', 'ro': 'AMR (Abstract Meaning Representation) și EDS (Elementary Dependency Structures) sunt două reprezentări populare ale semnificației în NLP/NLU. AMR este mai abstract și conceptual, în timp ce EDS este un nivel mai scăzut, mai aproape de structurile lexicale ale propozițiilor date. Prin urmare, nu este surprinzător faptul că analizarea EDS este mai ușoară decât analizarea AMR. În această lucrare, luăm în considerare utilizarea informațiilor de la analizarea EDS pentru a ajuta la îmbunătățirea performanței analizării AMR. Adoptăm un parser bazat pe tranziție și propunem să adăugăm grafice EDS ca caracteristici semantice suplimentare folosind un codificator de grafice compus din stratul LSTM și stratul GCN. Rezultatele noastre experimentale arată că informațiile suplimentare din analizarea EDS oferă într-adevăr un impuls performanței parserului AMR de bază utilizat în experimentele noastre.', 'sr': 'AMR (abstraktivni značajni predstavnik) i EDS (elementarne strukture ovisnosti) su dve popularne predstave u NLP/NLU. AMR je više abstraktivna i konceptualna, dok je EDS niska nivo, bliže leksičkim strukturama određenih rečenica. Zato nije iznenađujuće da je EDS parsing lakše nego AMR parsing. U ovom poslu razmišljamo o korištenju informacija iz analize EDS-a kako bi pomogli poboljšati učinkovitost analize AMR-a. Usvojimo prelazni analizator i predlažemo dodati EDS grafike kao dodatne semantične funkcije koristeći koder grafika koji se sastoji od LSTM sloja i GCN sloja. Naši eksperimentalni rezultati pokazuju da dodatne informacije iz EDS analize stvarno daju pojačanje učinkovitosti baznog AMR analizatora koji se koristi u našim eksperimentima.', 'si': 'AMR (අභිස්ථානය අභිවිධානය) සහ EDS (අභිවිධානය නිර්මාණය ස්ථානය) ලෝකයික අදහස් දෙකක් තමයි NLP/NLU වල ප්\u200dර AMR තරම් ප්\u200dරශ්නය සහ ප්\u200dරශ්නය, EDS තරම් අඩු ස්ථානය, දෙන්න ප්\u200dරශ්නයේ ලෙක්සිකාලික ස්ථානය සමඟ ලඟින්. ඉතින් ඒක පුදුම වෙන්නේ නෑ EDS විශ්ලේෂණය AMR විශ්ලේෂණය වඩා ලේසියි. මේ වැඩේ අපි හිතන්නේ EDS විශ්ලේෂණයෙන් තොරතුරු භාවිතා කරන්න AMR විශ්ලේෂණය වැඩ කරන්න උදව් කරන්න. අපි ප්\u200dරවර්තනය අධාරිත විශේෂකයක් ගන්නවා ඒ වගේම EDS ග්\u200dරාෆ් එක් එකතු කරන්න ප්\u200dරයෝජනය කරනවා LSTM ස්තරය සහ GCN ස්තරයෙන් සම්පූ අපේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ EDS පරීක්ෂණයෙන් ඉතින් අඩු තොරතුරු ඇත්තටම අපේ පරීක්ෂණාවට', 'so': 'AMR (Abstract meaning Representation) and EDS (Elementary Dependence Structures) are two popular meanings representations in NLP/NLU. AMR waa mid aad u dhaqdhaqaaq ah iyo fekero, inta EDS ay ka yar tahay darajada, waxay u dhawdahay dhismaha leksikada ee xukunka la siiyey. Sida darteed lama yaabo in jardiinada EDS ay ka fudud tahay baarlamaanka AMR. Markaas waxan waxaynu ka fiirsanaynaa isticmaalka macluumaadka baarlamaanka EDS si aan ugu caawinno hagaajinta baarlamaanka AMR. Waxaynu qaadannaa baaritaanka soo wareegashada, waxaana soo jeedaynaa in lagu daro sawirada EDS sida xariijiyo kale oo semantic ah, waxaana isticmaalaynaa xaraf kooxer ka kooban LSTM layer iyo GCN layer. Imtixaanka jirrabaadka ah waxay muuqataa in macluumaad dheeraad ah oo ka soo baxay baaritaanka EDS waxay si dhab ah u caawinaysaa sameynta baaritaanka asalka AMR ee lagu isticmaalay jirrabadeenna.', 'sv': 'AMR (Abstract Meaning Representation) och EDS (Elementary Dependency Structures) är två populära betydelserepresentationer i NLP/NLU. AMR är mer abstrakt och konceptuellt, medan EDS är mer låg nivå, närmare de lexikala strukturerna i givna meningar. Det är därför inte förvånande att EDS-tolkning är enklare än AMR-tolkning. I detta arbete överväger vi att använda information från EDS-tolkning för att förbättra prestandan för AMR-tolkning. Vi antar en övergångsbaserad parser och föreslår att lägga till EDS-grafer som ytterligare semantiska funktioner med hjälp av en grafkodare bestående av LSTM-lager och GCN-lager. Våra experimentella resultat visar att den ytterligare informationen från EDS-tolkning verkligen ger en boost till prestandan hos basen AMR-parser som används i våra experiment.', 'ta': 'AMR (குறுக்கீடு பொருள் என்று அர்த்தம்) மற்றும் EDS (முதல் சார்ந்த அமைப்புகள்) NLP/NLU யில் இருந்து பெரிய பிரதிநிதிகள் ஆகும். AMR என்பது மற்றும் கருத்து மற்றும் அதிகமாக இருக்கும், EDS என்பது குறைந்த நிலையில், கொடுக்கப்பட்ட வாக்கியங்களின் லெக்சிக EDS பாடல் எம்ஆர் பாடலை விட எளிதாக இருக்கும் என்பது அதனால் ஆச்சரியமாக இல்லை. இந்த வேலையில், நாம் EDS காட்சியிலிருந்து தகவல்களை பயன்படுத்தி AMR பாடலின் செயலை மேம்படுத்த உதவுகிறோம். நாம் ஒரு மாற்று அடிப்படையில் சேர்த்து EDS வரைபடங்களை கூடுதல் semantic தன்மைகளாக சேர்க்க பரிந்துரைக்கிறோம் LSTM அடுக்கு மற்றும் GCN அடுக்க Our experimental results show that the additional information from EDS parsing indeed gives a boost to the performance of the base AMR parser used in our experiments.', 'ur': 'AMR (Abstract Meaning Representation) and EDS (Elementary Dependency Structures) are two popular meaning representations in NLP/NLU. AMR بہت اچھا اور منظور ہے، حالانکہ EDS بہت کم سطح ہے، جسے دی ہوئی جماعت کے لکسیکل ساختاروں سے زیادہ قریب ہے. اس طرح یہ تعجب نہیں کہ EDS پارسینگ AMR پارسینگ سے آسان ہے۔ اس کام میں ہم نے EDS پارسینگ سے اطلاعات کا استعمال کرنا سمجھا ہے کہ AMR پارسینگ کے کامیابی کو بہتر کرنے کے لئے مدد کریں۔ ہم ایک تغییر پر بنیاد پارچر کو قبول کرتے ہیں اور EDS گراف کو اضافہ کرنے کے لئے پیشنهاد کرتے ہیں LSTM لائر اور GCN لائر کے مطابق ایک گراف کوڈر کے استعمال کرتے ہیں. ہمارے آزمائش نتیجے دکھاتے ہیں کہ EDS پارسینگ سے اضافہ معلومات یقیناً ہمارے آزمائش میں استعمال کیا جاتا ہے AMR پارسینٹر کے عملکرد کے لئے اضافہ کرتا ہے.', 'uz': "Name AMR ko'proq abstrakt va g'oya, va EDS darajada ko'proq, gapiradigan soʻzlarning leksikal tuzuvlariga яқин. Шундай қилиб, EDS парламент AMR парламайдиган осон эмас. In this work, we consider using information from EDS parsing to help improve the performance of AMR parsing.  Biz transition asosida parametrlarni qoʻshish va EDS grafikni qoʻshish talab qilamiz LSTM qatlam va GCN qatlam yaratilgan grafik kodlash imkoniyatini qoʻshish. Bizning tajriba natijalarimiz EDS parking uchun qoʻshimcha maʼlumot, bizning imtiyozlarimizda foydalanilgan AMR parametrlarining asosiy bazasini bajarishga yordam beradi.", 'vi': 'AMR (Abstract meaning Representation) và ES (Sơ đồ thuộc phụ thuộc tiểu học) là hai nơi biểu tượng về tiêu nghĩa phổ biến tại NLP/Ntrường. The AMR is more trừu tượng và contưởng, while EBS is more low level, close to the lexical structures of the inititave. Không có gì ngạc nhiên khi phải phân tích ECS dễ hơn là phân tích AMR. Trong công việc này, chúng tôi cân nhắc việc sử dụng thông tin từ EDS phân tích để giúp cải thiện thành quả phân tích AMR. Chúng tôi chọn một nhà phân tích chuyển đổi và đề xuất thêm đồ thị EDS như một tính năng theo chữ nghĩa khác dùng bộ mã hóa đồ thị gồm lớp HTTM và lớp GCN. Những kết quả thử nghiệm của chúng ta cho thấy thông tin thêm từ phân tích EDS thật sự giúp kích thích hiệu quả của căn cứ bố thí nghiệm AMR.', 'bg': 'АМР (Абстрактна представа на значението) и ЕДС (Елементарни структури на зависимост) са две популярни представления на значението в НЛП/НЛУ. АМР е по-абстрактна и концептуална, докато EDS е по-ниско ниво, по-близо до лексикалните структури на дадените изречения. Следователно не е изненадващо, че EDS анализирането е по-лесно от AMR анализирането. В тази работа разглеждаме използването на информация от анализа за подобряване на ефективността на анализа на АМР. Приемаме базиран на преход анализатор и предлагаме добавянето на графики като допълнителни семантични функции, използвайки графичен кодер, съставен от слой LSTM и слой GCN. Нашите експериментални резултати показват, че допълнителната информация от анализа наистина дава тласък на производителността на базовия анализатор на АМР, използван в нашите експерименти.', 'da': 'AMR (Abstrakt Meaning Representation) og EDS (Elementary Dependency Structures) er to populære betydningsrepræsentationer i NLP/NLU. AMR er mere abstrakt og konceptuel, mens EDS er mere lavt niveau, tættere på de leksikalske strukturer i de givne sætninger. Det er derfor ikke overraskende, at EDS parsing er lettere end AMR parsing. I dette arbejde overvejer vi at bruge oplysninger fra EDS parsing til at hjælpe med at forbedre ydeevnen af AMR parsing. Vi vedtager en overgangsbaseret parser og foreslår at tilføje EDS grafer som yderligere semantiske funktioner ved hjælp af en grafkoder bestående af LSTM lag og GCN lag. Vores eksperimentelle resultater viser, at den yderligere information fra EDS parsing faktisk giver et boost til ydeevnen af den base AMR parser, der anvendes i vores eksperimenter.', 'nl': 'AMR (Abstract Meaning Representation) en EDS (Elementary Dependency Structures) zijn twee populaire betekenisrepresentaties in NLP/NLU. AMR is meer abstract en conceptueel, terwijl EDS meer laag niveau is, dichter bij de lexicale structuren van de gegeven zinnen. Het is dus niet verwonderlijk dat EDS parsen gemakkelijker is dan AMR parsen. In dit werk overwegen we het gebruik van informatie uit EDS parsing om de prestaties van AMR parsing te verbeteren. We gebruiken een transitie-gebaseerde parser en stellen voor om EDS-grafieken toe te voegen als extra semantische kenmerken met behulp van een grafiekencoder bestaande uit LSTM-laag en GCN-laag. Onze experimentele resultaten tonen aan dat de aanvullende informatie van EDS parsing inderdaad een boost geeft aan de prestaties van de basis AMR parser die in onze experimenten wordt gebruikt.', 'hr': 'AMR (abstraktivni značajni predstavnik) i EDS (elementarne strukture ovisnosti) su dvije popularne predstave značaja u NLP/NLU. AMR je više abstraktivna i konceptualna, dok je EDS niska razina, bliže leksičkim strukturama određenih rečenica. Stoga nije iznenađujuće da je EDS analiza lakša nego AMR analiza. U ovom poslu razmišljamo o korištenju informacija iz analize EDS-a kako bi pomogli poboljšati učinkovitost analize AMR-a. Usvojimo prelazni analizator i predlažemo dodati EDS grafike kao dodatne semantične funkcije koristeći koder grafika koji se sastoji od LSTM sloja i GCN sloja. Naši eksperimentalni rezultati pokazuju da dodatne informacije iz analize EDS-a stvarno daju pojačanje učinkovitosti baznog analizatora AMR-a koji se koristi u našim eksperimentima.', 'de': 'AMR (Abstract Meaning Representation) und EDS (Elementary Dependency Structures) sind zwei populﾃ､re Bedeutungsreprﾃ､sentationen in NLP/NLU. AMR ist abstrakter und konzeptueller, wﾃ､hrend EDS eher auf niedrigem Niveau ist, nﾃ､her an den lexikalischen Strukturen der gegebenen Sﾃ､tze. Daher ist es nicht verwunderlich, dass EDS Parsing einfacher ist als AMR Parsing. In dieser Arbeit betrachten wir die Verwendung von Informationen aus EDS Parsing, um die Leistung von AMR Parsing zu verbessern. Wir verwenden einen ﾃ彙ergangs-basierten Parser und schlagen vor, EDS-Graphen als zusﾃ､tzliche semantische Features mit einem Graph-Encoder hinzuzufﾃｼgen, der aus LSTM-Schicht und GCN-Schicht besteht. Unsere experimentellen Ergebnisse zeigen, dass die zusﾃ､tzlichen Informationen aus EDS Parsing tatsﾃ､chlich die Leistung des Basis AMR Parsers erhﾃｶhen, der in unseren Experimenten verwendet wird.', 'ko': 'AMR(추상적 의미 표현)과 EDS(기본 의존 구조)는 NLP/NLU에서 두 가지 유행하는 의미 표현이다.AMR은 추상적이고 개념적이며 EDS는 더 저급하고 주어진 문장의 어휘 구조에 가깝다.따라서 EDS 해석이 AMR 해석보다 더 쉽다는 것은 이상할 게 없다.이 작업에서는 AMR 구문 분석 성능을 향상시키기 위해 EDS 구문 분석 정보를 사용하는 것이 좋습니다.우리는 변환을 기반으로 하는 해석기를 사용하고 LSTM층과 GCN층으로 구성된 도형 인코더를 사용하여 EDS 도형을 추가 의미 특징으로 추가하는 것을 권장합니다.EDS 해석에 대한 추가 정보가 실험에 사용된 기본 AMR 해석기의 성능을 확실히 향상시켰음을 보여주는 실험 결과입니다.', 'fa': 'AMR (Representation Abstract Meaning) and EDS (Structures Elementary Dependency) are two popular meaning representations in NLP/NLU. AMR مثبت\u200cتر و مفهوم\u200cتر است، در حالی که EDS سطح پایین\u200cتر است، نزدیکتر به ساختارهای زبان\u200cشناسی از جمله\u200cهای داده شده است. به همین دلیل تعجب نمی\u200cکند که تحلیل EDS از تحلیل AMR آسانتر است. در این کار، ما با استفاده از اطلاعات از تجزیه کردن EDS برای کمک به بهترین فعالیت تجزیه آمریکا فکر می کنیم. ما یک بازیگر بر اساس تغییر استفاده می\u200cکنیم و پیشنهاد می\u200cدهیم که گرافیک EDS را به عنوان ویژه\u200cهای semantic اضافه از استفاده از یک رمزگراف گراف ساخته از لایه LSTM و لایه GCN اضافه کنیم. نتیجه آزمایشی ما نشان می دهد که اطلاعات اضافه\u200cای از تجزیه\u200cهای EDS واقعاً به فعالیت پایه\u200cهای تجزیه\u200cکننده\u200cی AMR استفاده شده در آزمایشات ما افزایش می\u200cدهد.', 'sw': 'AMR (Maandamano yanayomaanisha kuhakikishwa) na EDS (Miundombinu ya Utegemea wa Element) ni wawili maarufu katika NLP/NLU. AMR is more abstract and conceptual, while EDS is more low level, closer to the lexical structures of the given sentences.  Kwa hiyo haishangaa kwamba wimbo wa EDS ni rahisi zaidi ya wimbo wa AMR. Katika kazi hii, tunafikiria kutumia taarifa kutoka kwenye wimbo wa EDS ili kusaidia kuboresha utendaji wa wimbo wa AMR. Tunachukua mchambuzi wa mpito na tunapendekeza kuongeza picha za EDS kama sifa za ziada za semantic kwa kutumia kodi ya picha iliyoandaliwa na daraja la LSTM na GCN. Matokeo yetu ya majaribio yanaonyesha kwamba taarifa za ziada kutoka kwenye parge ya EDS kwa hakika inaongezea ufanisi wa mazoezi ya msingi wa chama cha AMR kilichotumiwa katika majaribio yetu.', 'tr': 'AMR (Abstract Meaning Representation) and EDS (Elementary Dependency Structures) are two popular meaning representations in NLP/NLU. AMR has abstrakt we düşünjükli bolsa, EDS düşük derejede, berilen sözlerin lektikal strukturalarynyň ýakynda. EDS parslemesi AMR parslamasyndan has aňsat däldir. Bu işde, biz EDS analýusinden informasiýa ulanyp AMR analýşiniň etkinlik täzelenmesine kömek etmek üçin pikir edýäris. Biz geçişik tabanly bir täzeleçi kabul edip EDS grafiklerini LSTM we GCN katyryndan oluşan bir grafik ködlemeni ullanarak täze teklip etmek üçin teklip edýäris. Deneymeli netijelerimiz EDS analýşinden ekli maglumatyň biziň deneylerimizde ulanylan temel AMR tanyçysynyň etkinleşigine kömek edip barýandygyny görkezýär.', 'am': 'AMR (የግንኙነት መልዕክት) እና EDS (የአሜላቲካዊ ደጋፊነት ቅድሚያ) በNLP/NLU ውስጥ የሚታወቁ ሁለት የውጤቶች ማህበረሰብ ናቸው። አ.አ.አ.አ. የውጤት እና አእምሮው የበለጠ ነው፡፡ እንደዚህም EDS ማጋራት ከAMR ማዘጋጀት ይልቅ ቀላል እንደሆነ አይደነቅም፡፡ In this work, we consider using information from EDS parsing to help improve the performance of AMR parsing.  We adopt a transition-based parser and propose to add EDS graphs as additional semantic features using a graph encoder composed of LSTM layer and GCN layer.  ፈተና ፍሬዎቻችን ከEDS ፓርቲ የመጨመር መረጃዎች በፈተናዎቻችን ውስጥ የተጠቃውን የAMR ተቃውሞ መደምደሚያን ያሳያል፡፡', 'af': "AMR (abstrakte betekening voorstel) en EDS (Elementêre afhanklikheid strukture) is twee populêre betekening voorstellings in NLP/NLU. AMR is meer abstrakte en konseptieële, terwyl EDS meer lae vlak is, naby aan die leksiese strukture van die gegewe setinge. Dit is dus nie verwonderbaar dat EDS verwerking makliker is as AMR verwerking. In hierdie werk, ons besluit om inligting te gebruik van EDS-verwerking te help om die prestasie van AMR-verwerking te verbeter. Ons aanvaar 'n oorgang-gebaseerde ontleerder en voorstel om EDS grafieke as ekstra semantiese funksies te voeg by te gebruik met 'n graaf enkoder gemaak van LSTM laag en GCN laag. Ons eksperimentele resultate wys dat die addisionele inligting van EDS verwerking werklik 'n booster gee aan die prestasie van die basis AMR ontwerker wat in ons eksperimente gebruik word.", 'sq': 'AMR (Representation Abstract Meaning) and EDS (Elementary Dependency Structures) are two popular meaning representations in NLP/NLU. AMR is more abstract and conceptual, while EDS is more low level, closer to the lexical structures of the given sentences.  Kështu nuk është befasuese që analizimi i EDS është më i lehtë se analizimi i AMR. Në këtë punë, ne konsiderojmë përdorimin e informacionit nga analizimi EDS për të ndihmuar përmirësimin e performancës së analizimit AMR. Ne miratojmë një analizues të bazuar në tranzicion dhe propozojmë të shtojmë grafikë EDS si karakteristika shtesë semantike duke përdorur një kodues grafik të përbërë nga shtresa LSTM dhe shtresa GCN. Rezultatet tona eksperimentale tregojnë se informacioni shtesë nga analizimi EDS me të vërtetë jep një nxitje në performancën e analizuesit bazë AMR të përdorur në eksperimentet tona.', 'hy': 'ԱՄՌ և ԷԴՍ երկու հայտնի նշանակալի ներկայացումներ են ՆԼՊ-ում: ԱՄՌ-ն ավելի վերացական և գաղափարական է, մինչդեռ ԷԴՍը ավելի ցածր մակարդակ է, ավելի մոտ տվյալ նախադասությունների լեքսիկական կառուցվածքին: Այսպիսով, զարմանալի չէ, որ ԷԴՍ-ի վերլուծումը ավելի հեշտ է, քան ԱՄՌ-ի վերլուծումը: In this work, we consider using information from EDS parsing to help improve the performance of AMR parsing.  Մենք ընդունում ենք անցումային հիմքով վերլուծողի և առաջարկում ենք ավելացնել ԷԴՍ գրաֆիկները որպես ավելին սեմանտիկ հատկություններ, օգտագործելով գծագրային կոդեր, որը կազմված է LSMT շերտից և GNC շերտից: Our experimental results show that the additional information from EDS parsing indeed gives a boost to the performance of the base AMR parser used in our experiments.', 'bn': 'এএমআর (আবশ্যক প্রতিনিধি) এবং এডিএস (মাত্রিক নির্ভরশীল কাঠামোর) এনএলপি/এনএলইউ-এ দুই জনপ্রিয় মানে প্রতিনিধিত্ব। এএমআর আর আরো বেশী অস্বীকৃতি এবং ধারণা, যদিও ইডিএস আরো কম স্তর, কিন্তু প্রদত্ত বাক্যের লেক্সিকাল কাঠামোর কাছাকাছি। এমআর পার্গিং থেকে সহজেই ইডিএস পার্গিং বিস্ময়কর নয়। এই কাজে আমরা ইডিএস পার্গিং থেকে তথ্য ব্যবহার করার বিবেচনা করি এএমআর পার্গিং এর প্রভাব উন্নত করার জন্য। আমরা একটি পরিবর্তন-ভিত্তিক প্যালেজার নির্বাচন করি এবং এডিএস-এর গ্রাফ যোগ করার প্রস্তাব করি এলসিএম স্টেম স্তর এবং জিসিনি স্তরের তৈরি করা একটি গ্র আমাদের পরীক্ষার ফলাফল দেখা যাচ্ছে যে ইডিএস পার্গিং থেকে আরো তথ্য আসলেই আমাদের পরীক্ষায় ব্যবহৃত একাম্পারের বেস প্যারাসের প্', 'bs': 'AMR (abstraktivni značajni predstavnik) i EDS (elementarne strukture ovisnosti) su dva popularna značaja predstavljanja u NLP/NLU. AMR je više abstraktivna i konceptualna, dok je EDS niska nivo, bliže leksičkim strukturama određenih rečenica. Zato nije iznenađujuće da je EDS analiza lakša od analize AMR-a. U ovom poslu razmišljamo o korištenju informacija iz analize EDS-a kako bi pomogli poboljšati učinkovitost analize AMR-a. Usvojimo prelazni analizator i predlažemo dodati EDS grafike kao dodatne semantične funkcije koristeći koder grafika koji se sastoji od LSTM sloja i GCN sloja. Naši eksperimentalni rezultati pokazuju da dodatne informacije iz EDS analize stvarno daju pojačanje učinkovitosti baznog AMR analizatora koji se koristi u našim eksperimentima.', 'ca': "AMR (Representation Abstract Meaning) i EDS (Elementary Dependence Structures) són dues representacions de significat popular a NLP/NLU. AMR is more abstract and conceptual, while EDS is more low level, closer to the lexical structures of the given sentences.  Per tant, no és sorprenent que l'analització EDS sigui més fàcil que l'analització AMR. En aquest treball, considerem utilitzar informació de l'analització EDS per ajudar a millorar el rendiment de l'analització AMR. Adopem un analitzador basat en transició i proposem afegir gràfics EDS com característiques semàntiques adicionals utilitzant un codificador de gràfics compost de capa LSTM i capa GCN. Els nostres resultats experimentals mostren que la informació adicional de l'analització EDS dóna un impuls al rendiment del analitzador AMR bàsic utilitzat en els nostres experiments.", 'cs': 'AMR (Abstract Meaning Representation) a EDS (Elementary Dependency Structures) jsou dvě populární reprezentace významu v NLP/NLU. AMR je abstraktnější a konceptuálnější, zatímco EDS je nízká úroveň, blíže lexikálním strukturám daných vět. Není tedy překvapující, že EDS parsing je jednodušší než AMR parsing. V této práci zvažujeme využití informací z EDS parsing pro zlepšení výkonu AMR parsing. Přijímáme parser založený na přechodu a navrhujeme přidat EDS grafy jako další sémantické prvky pomocí grafového kodéru složeného z LSTM vrstvy a GCN vrstvy. Naše experimentální výsledky ukazují, že doplňkové informace z EDS parsování skutečně zvyšují výkon základního AMR parseru používaného v našich experimentech.', 'et': 'AMR (Abstract Meaning Representation) ja EDS (Elementary Dependency Structures) on kaks populaarset t瓣hendusrepresentatsiooni NLP/NLP-s. AMR on abstraktsem ja kontseptuaalsem, samas EDS madalam tase, l瓣hemal antud lausete leksikaalsele struktuurile. Seega ei ole 羹llatav, et EDS parsimine on lihtsam kui AMR parsimine. Selles t繹繹s kaalume EDS parsimise informatsiooni kasutamist AMR parsimise j繭udluse parandamiseks. V繭tame kasutusele 羹leminekup繭hise parseri ja teeme ettepaneku lisada EDS graafikud t瓣iendavate semantiliste funktsioonidena, kasutades graafikodeerijat, mis koosneb LSTM kihist ja GCN kihist. Meie eksperimentaalsed tulemused n瓣itavad, et t瓣iendav info EDS parsimisest t繭epoolest suurendab meie katsetes kasutatava AMR parseri j繭udlust.', 'id': 'AMR (Perwakilan Arti Abstrakt) dan EDS (Struktur Dependensi Elementari) adalah dua perwakilan arti populer di NLP/NLU. AMR lebih abstrak dan konseptual, sementara EDS lebih rendah tingkat, lebih dekat dengan struktur lexik kalimat yang diberikan. Jadi tidak mengejutkan bahwa penghuraian EDS lebih mudah daripada penghuraian AMR. Dalam pekerjaan ini, kami mempertimbangkan menggunakan informasi dari penghuraian EDS untuk membantu memperbaiki prestasi penghuraian AMR. Kami mengadopsi parser berdasarkan transisi dan mengusulkan untuk menambahkan grafik EDS sebagai fitur semantis tambahan menggunakan pengekoder grafik yang terdiri dari lapisan LSTM dan lapisan GCN. Hasil percobaan kami menunjukkan bahwa informasi tambahan dari penghuraian EDS benar-benar memberikan dorongan untuk prestasi dari penghuraian AMR dasar yang digunakan dalam percobaan kami.', 'az': 'AMR (Abstrakt Meaning Representation) və EDS (Elementary Dependency Structures) NLP/NLU içində iki məşhur məsələdir. AMR daha abstrakt və konsept idi, EDS daha düşük seviyyətdir, verilən sözlərin leksik qurularına daha yaxın. Buna görə də EDS ayırması AMR ayırmasından daha asandır. Bu işdə, biz EDS analizindən məlumatları istifadə etmək üçün AMR analizi yaxşılaşdırmağa kömək edirik. Biz keçiş-tabanlı ayırıcı götürür və EDS grafiklərini LSTM və GCN katından oluşan grafik kodlayıcısı ilə əlavə semantik xüsusiyyətlər olaraq əlavə etmək üçün təklif edirik. Bizim təcrübəmiz sonuçlarımız EDS ayırılmasından artıq məlumatların həqiqətən, bizim təcrübələrimizdə istifadə edilən AMR analizacının təcrübəsini artırar.', 'fi': 'AMR (Abstract Meaning Representation) ja EDS (Elementary Dependency Structures) ovat kaksi suosittua merkitysesitystä NLP/NLU:ssa. AMR on abstraktimpi ja käsitteellisempi, kun taas EDS on matalampi taso, lähempänä annettujen lauseiden sanastorakenteita. Ei siis ole yllättävää, että EDS-jäsentäminen on helpompaa kuin AMR-jäsentäminen. Tässä työssä pohdimme EDS-parsauksen tietojen käyttöä AMR-parsauksen suorituskyvyn parantamiseksi. Otamme käyttöön siirtymäpohjaisen jäsentäjän ja ehdotamme EDS-graafien lisäämistä semantiikkaominaisuuksiksi käyttäen LSTM- ja GCN-tasosta koostuvaa graafikooderia. Kokeelliset tulokset osoittavat, että EDS-parsauksesta saatu lisätieto todella parantaa kokeissamme käytetyn AMR-perusparsaurin suorituskykyä.', 'jv': 'AM R (absolute means representation) and ESSS (Itemary dependance structural) are 2 populary means representations in NLP/NLU. OptionsWithin Yo bener yö ora luwih apik tenan kanggo kelas dipunangke punika dipunangke dipunangke punika dipunangke punika dipunangke punika dipunangke punika dipunangke punika dipunangke punika. Nang iki trabah, kita isih ngubah kelas informasi ning sesilhan seneng nggawe barang kelas nggawe barang kanggo ngilangno barang dumadhi OPR We Awakdhéwé éntuk sing paling nggawe barang kelas informasi tambah nggawe ing nggawe cara nggawe barang nggawe barang kelas nggawe barang kelas PAR dumadhi kanggo nggawe Perintah dumadhi kita.', 'ha': "AMR (Mai fassarar muhimmin Reposition) da EDS (Elemental Deputy Factory) are both popular elements in NLP/NLU. AMR yana da mafi rajista da zato, alhãli EDS yana da mafi ƙasƙanci, kuma mafi kusanta matsayin leksisi na da aka yi musu. Ina baƙanta da cẽwa parkin EDS ne mafi sauƙi daga parsin AMR. Daga wannan aikin, munã ƙayyade amfani da information daga parkin EDS dõmin ya ƙara gyaranin parsin AMR. Tuna zãɓi wani Paramer a kan-mai maras da aka samu kuma Muke goyyade su ƙara EDS kamar wasu shiryoyi na semantic da ke amfani da wani kode na grafi wanda aka sammenyu na LStM ƙanshi da GCtlayen. Matarinmu na jarrabi ya nuna cewa wasu information daga parkin EDS za'a ƙara zuwa cikakken mabaratan AMR wanda aka yi amfani da cikin jarrabamarmu.", 'he': 'AMR (Abstract Meaning Representation) ו EDS (Elementary Dependency Structures) הם שתי מייצגים של משמעות פופולריות ב-NLP/NLU. AMR הוא יותר אוסטרקטי וקפוטאולי, בעוד EDS הוא רמה נמוכה יותר, קרוב למבנים הלקסיים של המשפטים הנתונים. It is thus not surprising that EDS parsing is easier than AMR parsing.  בעבודה הזו, אנו שוקלים להשתמש במידע מהמחקר EDS כדי לעזור לשפר את ההפעלה של מחקר AMR. אנו מאמצים מעבד מבוסס במעבר ומציעים להוסיף גרפים EDS כתכונות סמנטיות נוספות באמצעות קודד גרפים מורכב משכבת LSTM ושכבת GCN. התוצאות הניסיוניות שלנו מראות שהמידע הנוסף מהחקירת EDS באמת נותן דחף להופעה של המחקר הבסיסי AMR השתמש בניסויים שלנו.', 'sk': 'AMR (Abstract Meaning Representation) in EDS (Elementary Dependency Structures) sta dve priljubljeni pomenski predstavitvi v NLP/NLP. AMR je bolj abstraktna in konceptualna, medtem ko je EDS bolj nizka stopnja, bližje leksikalnim strukturam danih stavkov. Zato ni presenetljivo, da je EDS razčlenitev lažje kot AMR razčlenitev. V tem delu razmišljamo o uporabi informacij iz EDS parsing za izboljšanje učinkovitosti AMR parsing. Sprejmemo razčlenjevalnik, ki temelji na prehodu in predlagamo dodajanje EDS grafov kot dodatnih semantičnih funkcij z uporabo grafskega kodirja, sestavljenega iz plasti LSTM in plasti GCN. Naši eksperimentalni rezultati kažejo, da dodatne informacije iz EDS parsing dejansko povečujejo zmogljivost osnovnega AMR parser, uporabljenega v naših eksperimentih.', 'bo': 'AMR (Abstract Meaning Representation) and EDS (Elementary Dependency Structures) are two popular meaning representations in NLP/NLU. AMR ནི་ཚུར་ཕན་ཚུན་དང་ལྟ་བུའི་ལམ་ལུགས་ཕན་ཐོགས་པ་རེད། གཟུགས་རིས་འདི་ལྟ་བུའི་མཐོ་རིམ་དང་ཉེ་བར། EDS མིག་སྒྲིག་ཞིབ་དཔྱད་བར་ལས་སླ་མོ་རྗེས་མེད། In this work, we consider using information from EDS parsing to help improve the performance of AMR parsing. We adopt a transition-based parser and propose to add EDS graphs as additional semantic features using a graph encoder composed of LSTM layer and GCN layer. ང་ཚོའི་བརྟག་འཕྲུལ་གྱི་གྲུབ་འབྲས་བློ་གཏོང་ན་EDS་ལས་བརྟག་བཤད་ཀྱི་གསལ་བཤད་མང་ཙམ་བྱེད་ཐུབ་པ་དེ་དང་ང་ཚོའི་བརྟག་ཞི'}
{'en': 'Neural Metaphor Detection with Visibility Embeddings', 'fr': 'Détection de métaphore neuronale avec intégration de visibilité', 'pt': 'Detecção de metáfora neural com incorporação de visibilidade', 'es': 'Detección de metáforas neuronales con incrustaciones de visibilidad', 'ja': '可視性埋め込みによる神経メタファー検出', 'ar': 'كشف الاستعارة العصبية مع تطعيمات الرؤية', 'ga': 'Brath Meafar Néaraigh le Leabú Infheictheachta', 'ru': 'Обнаружение нейронной метафоры с вставками видимости', 'zh': '用可见性嵌神经隐喻检测', 'hi': 'दृश्यता एम्बेडिंग के साथ तंत्रिका रूपक का पता लगाना', 'el': 'Ανίχνευση Νευρικών Μεταφορών με Ενσωματώσεις Ορατότητας', 'ka': 'Name', 'hu': 'Neurális metafór felismerés láthatósági beágyazásokkal', 'it': 'Rilevamento della metafora neurale con incorporazioni di visibilità', 'kk': 'Көрінетін ендірулермен нейрондық метафорды анықтау', 'lt': 'Neuralinių metaforų aptikimas su matomumo įranga', 'mk': 'Детектирање на неврална метафора со вградувања на видливост', 'ml': 'കാഴ്ചപ്പെടുത്തുന്നതിനൊപ്പം നെയുറല്\u200d മെറ്റാപ്പോര്\u200d കണ്ടുപിടിക്കുക', 'ms': 'Pengesanan Metafora Neural dengan Penjelmaan Kelihatan', 'mt': 'Sejbien ta’ Metafori Newrali b’Embeddings ta’ Viżibilità', 'pl': 'Wykrywanie metaforów nerwowych z osadzeniami widoczności', 'no': 'Neuralmetaforoppdaging med synleg innbygging', 'ro': 'Detectarea metaforelor neurale cu încorporarea vizibilității', 'mn': 'Цөмийн метафорын мэдрэмж', 'sr': 'Neuralno detekcije metafora sa uključenjem vidljivosti', 'si': 'දකින්න පුළුවන් සම්බන්ධයක් තියෙන න්\u200dයූරාල මෙටාෆර් හොයාගන්න', 'so': 'Ku baaraandegista qalabka aragshada', 'sv': 'Neural Metaphor Detection med synlighetsinbäddningar', 'ta': 'தெரியும் உட்பொதிகளுடன் நெருக்கி முறை கண்டுபிடிப்பு', 'ur': 'دکھانے کے ساتھ نیورال میٹافور پتچا', 'uz': 'Neural Metaphor Detection with Visibility Embeddings', 'vi': 'Phát hiện thiết bị thần kinh với ống nhòm', 'nl': 'Detectie van neurale metaforen met zichtbare insluitingen', 'da': 'Neural Metaphor Detection med synlighedsindlejringer', 'bg': 'Откриване на неврална метафора с вграждания за видимост', 'hr': 'Neuralna metafora otkrivanje s uključenjem vidljivosti', 'id': 'Deteksi Metafora Neural dengan Embeddings Visibility', 'de': 'Erkennung von neuronalen Metaphern mit Sichtbarkeitseinbettungen', 'ko': '가시성 삽입에 기반한 신경 은유 검출', 'fa': 'شناسایی متاثر عصبی با پیوند\u200cهای دیده\u200cای', 'sw': 'Utafiti wa Mtandao wa Neural With Visibility', 'af': 'Name', 'tr': 'Görkezilişi Aňlamak bilen Näral Metaforo Aňlamak', 'sq': 'Detektimi i Metaforës Neurale me përfshirje të dukshme', 'am': 'የኩነቶች መረጃ', 'hy': 'Նյարդային մետաֆորների հայտնաբերումը տեսանելիության ներգրավման միջոցով', 'az': 'Görünüşlük İfadələri ilə Nöral Metaforlar Keşfeti', 'bn': 'দৃশ্যমান অবস্থানের সাথে নিউরেল মেটাপোর সনাক্ত', 'bs': 'Neuralna metafora otkrivanje sa uključenjem vidljivosti', 'ca': 'Detecció de metàfores neuronals amb incorporacions de visibilitat', 'fi': 'Neuramuodon tunnistus ja näkyvyyden upotukset', 'et': 'Nähtavuse manustamisega neurometafoori tuvastamine', 'cs': 'Detekce neuronových metaforem s vložením viditelnosti', 'jv': 'drawable-action', 'sk': 'Zaznavanje živčne metafore z vdelavami vidljivosti', 'ha': 'KCharselect unicode block name', 'he': 'גילוי מטאפורה עצבית עם תוכניות ראייה', 'bo': 'མཐོང་ནུས་ཀྱིས་མཐོང་ནུས་ཀྱི་མཚུངས་སྐུལ་རྙེད་པ'}
{'en': 'We present new results for the problem of sequence metaphor labeling, using the recently developed Visibility Embeddings. We show that concatenating such embeddings to the input of a BiLSTM obtains consistent and significant improvements at almost no cost, and we present further improved results when visibility embeddings are combined with BERT.', 'pt': 'Apresentamos novos resultados para o problema de rotulagem de metáforas de sequências, usando os recém-desenvolvidos Visibility Embeddings. Mostramos que a concatenação de tais embeddings à entrada de um BiLSTM obtém melhorias consistentes e significativas quase sem custo, e apresentamos resultados ainda melhores quando os embeddings de visibilidade são combinados com BERT.', 'es': 'Presentamos nuevos resultados para el problema del etiquetado de metáforas de secuencias, utilizando las incrustaciones de visibilidad recientemente desarrolladas. Demostramos que la concatenación de tales incrustaciones con la entrada de un BILSTM obtiene mejoras consistentes y significativas casi sin costo alguno, y presentamos resultados aún mejores cuando las incrustaciones de visibilidad se combinan con BERT.', 'ja': '最近開発されたVisibility Embeddingsを使用して、シーケンスのメタファーラベリングの問題に関する新しい結果を提示します。このような埋め込みをBiLSTMの入力に連結すると、ほとんど費用なしで一貫した有意な改善が得られ、可視性埋め込みをBERTと組み合わせるとさらに改善された結果が得られることを示しています。', 'ar': 'نقدم نتائج جديدة لمشكلة وضع العلامات على الاستعارة المتسلسلة باستخدام Visibility Embeddings التي تم تطويرها مؤخرًا. نظهر أن ربط مثل هذه الزخارف بمدخلات BiLSTM يحصل على تحسينات متسقة وهامة دون أي تكلفة تقريبًا ، ونقدم المزيد من النتائج المحسّنة عندما يتم دمج حفلات الزفاف المرئية مع BERT.', 'fr': "Nous présentons de nouveaux résultats pour le problème de l'étiquetage de métaphore de séquence, à l'aide des Visibility Embeddings récemment développés. Nous montrons que la concaténation de telles intégrations à l'entrée d'un BilsTM permet d'obtenir des améliorations cohérentes et significatives à peu près gratuitement, et nous présentons des résultats encore améliorés lorsque les intégrations de visibilité sont combinées avec BERT.", 'ru': 'Представляем новые результаты по проблеме разметки метафор последовательностей, используя недавно разработанные Visibility Embeddings. Мы показываем, что объединение таких вложений на входе BiLSTM получает последовательные и значительные улучшения практически без затрат, и мы представляем дополнительные улучшенные результаты, когда вложения видимости комбинируются с BERT.', 'zh': '用近者见性嵌,为序隐喻表者新之。 吾明以嵌属BiLSTM输几可免费得一而显进,且见性嵌与BERT合用,吾资其更进也。', 'hi': 'हम हाल ही में विकसित दृश्यता एम्बेडिंग का उपयोग करके, अनुक्रम रूपक लेबलिंग की समस्या के लिए नए परिणाम प्रस्तुत करते हैं। हम दिखाते हैं कि एक BiLSTM के इनपुट के लिए इस तरह के एम्बेडिंग concatenating लगभग कोई लागत पर लगातार और महत्वपूर्ण सुधार प्राप्त करता है, और जब दृश्यता एम्बेडिंग BERT के साथ संयुक्त कर रहे हैं हम आगे बेहतर परिणाम प्रस्तुत करते हैं।', 'ga': 'Cuirimid torthaí nua i láthair don fhadhb a bhaineann le lipéadú meafar seichimh, ag baint úsáide as na Leabaithe Infheictheachta a forbraíodh le déanaí. Léirímid go bhfaightear feabhsuithe comhsheasmhacha agus suntasacha ar bheagnach aon chostas trí leabuithe den sórt sin a chomhchaitheamh le hionchur BiLSTM, agus cuirimid torthaí feabhsaithe breise i láthair nuair a chomhcheanglaítear leabaithe infheictheachta le BERT.', 'ka': 'ჩვენ ახალი შედეგების შედეგების მეტაფორის მარტილის პრობლემების შესახებ გამოყენებთ ახალი შედეგები. ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ ასეთი ინტებიზიზიციები BiLSTM-ის შემოწყვეტის შემდეგი და მნიშვნელოვანი უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო', 'hu': 'Új eredményeket mutatunk be a szekvencia metafora címkézés problémájára, a nemrégiben kidolgozott Visibility Embeddings segítségével. Megmutatjuk, hogy az ilyen beágyazások BiLSTM bemenetével történő összekapcsolása következetes és jelentős javulást eredményez szinte költségmentesen, és további javítási eredményeket mutatunk be, ha a láthatósági beágyazásokat a BERT-vel kombináljuk.', 'el': 'Παρουσιάζουμε νέα αποτελέσματα για το πρόβλημα της μεταγραφικής σήμανσης ακολουθίας, χρησιμοποιώντας τις πρόσφατα αναπτυγμένες Ενσωματώσεις Ορατότητας. Αποδεικνύουμε ότι η συσχέτιση τέτοιων ενσωματώσεων με την εισαγωγή ενός επιτυγχάνει συνεπείς και σημαντικές βελτιώσεις σχεδόν χωρίς κόστος και παρουσιάζουμε περαιτέρω βελτιωμένα αποτελέσματα όταν ενσωματώσεις ορατότητας συνδυάζονται με BERT.', 'it': "Presentiamo nuovi risultati per il problema dell'etichettatura delle metafore di sequenza, utilizzando i Visibility Embeddings recentemente sviluppati. Dimostriamo che la concatenazione di tali incorporazioni con l'input di un BiLSTM ottiene miglioramenti costanti e significativi quasi senza costi, e presentiamo ulteriori risultati migliorati quando gli incorporamenti di visibilità sono combinati con BERT.", 'lt': 'We present new results for the problem of sequence metaphor labeling, using the recently developed Visibility Embeddings.  Mes parodome, kad tokių įdėjimų suderinimas su BiLSTM įnašu užtikrina nuoseklius ir reikšmingus patobulinimus beveik be jokių sąnaudų, ir pateiksime tolesnius patobulintus rezultatus, kai matomumo įdėjimai derinami su BERT.', 'mk': 'Презентираме нови резултати за проблемот со метафорското означување на секвенцата, користејќи ги неодамна развиените Вградувања за Визибилност. Ние покажуваме дека концентрирањето на ваквите внесувања во внесувањето на БиЛСТМ добива константни и значителни подобрувања скоро без цена, и ние претставуваме понатамошни подобрени резултати кога концентрирањето на видливоста е комбинирано со БЕРТ.', 'kk': 'Біз жаңа нәтижелерді таңдаймыз, жаңа жасалған Көрінетін Көрінетін Емірлерді қолданатын метафор мәселесінің жазуының жаңа нәтижелерін. Біз BiLSTM кірісіне бұл құрылғыларды біріктіру дегенді көрсетедік. Бұл құрылғылардың біріктіріміз тұрақты және маңызды жақсартылығын біріктіреді. Біз BERT- мен біріктірілген кезде көрінетін көріністе', 'ms': 'Kami memperkenalkan keputusan baru untuk masalah pengetikkan metafora urutan, menggunakan Pencampuran Kelihatan yang baru-baru ini dikembangkan. Kami menunjukkan bahawa penutupan seperti ini kepada input BiLSTM mendapat peningkatan konsisten dan signifikan dengan hampir tiada kos, dan kami memperkenalkan keputusan yang lebih baik apabila penutupan kelihatan digabung dengan BERT.', 'ml': 'പുതിയ ഫലങ്ങള്\u200d ഞങ്ങള്\u200d കൊണ്ടുവരുന്നു, സെക്കന്\u200dസ് മെത്തോഫോര്\u200d ലേബിളിന്\u200dറെ പ്രശ്നത്തിന്, അടുത്തുതന്നെ വികസിച്ച കാഴ ബിഎല്\u200dസ്റ്റിംഗിന്റെ ഇന്\u200dപുട്ടിലേക്ക് ഇങ്ങനെയുള്ള മുന്\u200dഗണങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നത് നമ്മള്\u200d കാണിക്കുന്നു. ഒരു ബിഎല്\u200dസ്റ്റിംഗിന്റെ ഉള്\u200dപ്പാടില', 'mn': 'Бид саяхан хөгжсөн Дөрвөлжингийн Нэгдлийг ашиглан дарааллын метафор лакетингийн асуудалд шинэ үр дүнг үзүүлнэ. Бид BiLSTM-ын орлуулалтын төвшинд ийм тохиромжтой тохиромжтой байдлыг ойролцоогоор үнэ цэнэтэй, үнэ цэнэтэй сайжруулалт гаргадаг гэдгийг харуулж байна. Бид харагдах харагдах үйл ажиллагааны орлуулалтыг BERT-', 'no': 'Vi presenterer nye resultat for problemet med metaformerking av sekvens, ved hjelp av dei nyleg utvikla synlege innbygginga. Vi viser at samsvaring av slike innbygging til inndata av ein BiLSTM får konsistent og signifikant forbedringar med nesten ingen kostnad, og vi viser meir forbetra resultat når synlegheitsinnbygging er kombinert med BERT.', 'pl': 'Przedstawiamy nowe wyniki dotyczące problemu etykietowania metafor sekwencyjnych, wykorzystując niedawno opracowane Embeddings Visibility. Pokazujemy, że łączenie takich osadzeń z wejściem BiLSTM uzyskuje spójne i znaczące ulepszenia niemal bez kosztów, a przedstawiamy dalsze ulepszone wyniki, gdy osadzenia widoczności są połączone z BERT.', 'ro': 'Prezentăm noi rezultate pentru problema etichetării metaforelor secvențiale, folosind recent dezvoltate Vizibility Embeddings. Noi arătăm că concatenarea unor astfel de încorporări la intrarea unui BiLSTM obține îmbunătățiri consistente și semnificative, aproape fără costuri, și prezentăm rezultate suplimentare îmbunătățite atunci când încorporările de vizibilitate sunt combinate cu BERT.', 'sr': 'Predstavljamo nove rezultate za problem označavanja metafora sekvence, koristeći nedavno razvijene integracije vidljivosti. Pokazujemo da potvrđivanje takvih integracija na ulaz BiLSTM dobija konsekventne i značajne poboljšanje skoro bez cijene, i predstavljamo još poboljšane rezultate kada se pojave vidljivosti kombiniraju sa BERT-om.', 'so': 'Waxaynu keennaa resultooyin cusub ee dhibaatada labeecada simaalka kala duduwan, isticmaalka qalabka muuqashada ee ugu dhowaad la horumariyey. Waxaynu muujinnaa in la mid dhigo qalabka BiLSTM uu helaa hagaajinta aad u adag iyo aad u fiican si aan kharash u lahayn, waxaana keenaynaa resultooyin sii kordhaya marka muuqashada la soo bandhigayo BERT.', 'si': 'අපි අලුත් ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරශ්නයක් ප්\u200dරවේශනය කරනවා, අලුත් ප්\u200dරවේශනය ප්\u200dරවේශනය කරනව අපි පෙන්වන්නේ බිල්ස්ටිම් එක්ක ඇතුලට එහෙම සංවිධානය කරන්න බිල්ස්ටිම් එක්ක සාමාන්\u200dය සහ විශේෂ විශාලනයක් ලැබෙනවා කියලා, ඒ වගේම', 'sv': 'Vi presenterar nya resultat för problemet med sekvensmetaformärkning, med hjälp av de nyligen utvecklade Visibility Embeddings. Vi visar att sammanfogning av sådana inbäddningar till inmatningen av en BiLSTM ger konsekventa och betydande förbättringar nästan utan kostnad, och vi presenterar ytterligare förbättrade resultat när synlighetsinbäddningar kombineras med BERT.', 'ta': 'நாம் புதிய முடிவுகளை கொண்டுவருகிறோம், சமீபத்தில் உருவாக்கப்பட்ட தெரியும் பார்வைகளை பயன்படுத்துகிறோம். We show that concatenating such embeddings to the input of a BiLSTM obtains consistent and significant improvements at almost no cost, and we present further improved results when visibility embeddings are combined with BERT.', 'ur': 'ہم نئی نتیجے پیش کریں گے، اچھی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طر ہم دکھاتے ہیں کہ ایک BiLSTM کے داخل ہونے کے لئے اس طرح کی مہربانی کا مہربانی کرنا تقریباً کوئی قیمت کے مطابق ثابت ہوتا ہے اور ہم اس کے مطابق بہتر نتیجے پیش کرتے ہیں جب دیکھنے والی ایمبڈینگ BERT کے ساتھ ملے جاتے ہیں۔', 'mt': 'Aħna nippreżentaw riżultati ġodda għall-problema tat-tikkettar tal-metafori tas-sekwenza, bl-użu tal-Embeddings tal-Viżibbiltà żviluppati reċentement. Aħna nuru li l-konċinazzjoni ta’ dawn l-inkorporazzjonijiet mal-input ta’ BiLSTM tikseb titjib konsistenti u sinifikanti bi kważi l-ebda spiża, u nippreżentaw aktar riżultati mtejba meta l-inkorporazzjonijiet tal-viżibbiltà jiġu kkombinati mal-BERT.', 'uz': "Biz yangi natijalarni ko'rib chiqindilar quyidagi koʻpaytirilgan Koʻrinlik Emblemalari yordamida qo'llanmiz. Biz buni BiLSTM tarkibini birlashtirayotganimizni ko'rsatamiz, birinchi qiymatda bir qanchalik o'zgarishni ko'rsatganimiz mumkin, va biz ko'rinishi BERT bilan birlashtirilganda ko'proq yaxshi natijalarini ko'rsamiz.", 'vi': 'Chúng tôi đưa ra kết quả mới cho vấn đề mô tả ẩn dụ của dãy, sử dụng những khung chiếu được phát triển gần đây. Chúng tôi cho thấy nếu kết hợp được sự nhúng vào của tổ chức BiLSTM thì sẽ có nhiều cải tiến liên tục và đáng kể với hầu như không có chi phí, và chúng tôi cung cấp thêm nhiều kết quả tốt hơn khi sự nhúng vào trong tầm quan sát được kết hợp với BERT.', 'bg': 'Представяме нови резултати по проблема с етикетирането на последователни метафори, използвайки наскоро разработените Вградения за видимост. Показваме, че свързването на такива вграждания с входа на БиЛСТМ постига последователни и значителни подобрения почти без разходи и представяме допълнително подобрени резултати, когато вгражданията за видимост се комбинират с BERT.', 'nl': 'We presenteren nieuwe resultaten voor het probleem van sequentiemetaforen labeling, met behulp van de recent ontwikkelde Visibility Embeddings. We laten zien dat het koppelen van dergelijke embeddings aan de input van een BiLSTM consistente en significante verbeteringen oplevert zonder kosten, en we presenteren verder verbeterde resultaten wanneer zichtbaarheidsembeddings worden gecombineerd met BERT.', 'de': 'Wir präsentieren neue Ergebnisse für das Problem der Sequenz-Metaphern-Beschriftung unter Verwendung der kürzlich entwickelten Visibility Embeddings. Wir zeigen, dass die Verkettung solcher Einbettungen mit der Eingabe eines BiLSTM konsistente und signifikante Verbesserungen nahezu kostenlos erzielt, und wir präsentieren weitere verbesserte Ergebnisse, wenn Sichtbarkeitseinbettungen mit BERT kombiniert werden.', 'id': 'Kami mempersembahkan hasil baru untuk masalah pengetiketan metafora urutan, menggunakan Pemasangan Visibility yang baru-baru ini dikembangkan. Kami menunjukkan bahwa menyatukan penerbangan tersebut pada input BiLSTM mendapatkan peningkatan konsisten dan signifikan dengan hampir tidak ada biaya, dan kami menunjukkan hasil yang lebih baik ketika penerbangan visibilitas digabung dengan BERT.', 'hr': 'Predstavljamo nove rezultate za problem označavanja metafora u sekvenciji, koristeći nedavno razvijene integracije vidljivosti. Pokazujemo da potvrđivanje takvih uključenja u ulaz BiLSTM dobiva konsekvente i značajne poboljšanje skoro bez cijene, i predstavljamo daljnje poboljšane rezultate kada se uključuju vidljivost u kombinaciju s BERT-om.', 'ko': '우리는 최근에 개발된 가시적 삽입을 사용하여 서열 은유 표기 문제의 새로운 결과를 제시했다.우리는 이러한 삽입을 BilSTM의 입력에 연결하면 어떠한 대가를 치르지 않아도 일치하고 현저한 개선을 얻을 수 있으며, 가시적 삽입이 BERT와 결합될 때 더욱 개선된 결과를 얻었다는 것을 증명했다.', 'da': 'Vi præsenterer nye resultater for problemet med sekvensmetaformærkning ved hjælp af de nyligt udviklede Visibility Embeddings. Vi viser, at sammenkobling af sådanne indlejringer med input fra en BiLSTM opnår konsekvente og betydelige forbedringer uden omkostninger, og vi præsenterer yderligere forbedrede resultater, når synlighedsindlejringer kombineres med BERT.', 'sw': 'Tunatoa matokeo mapya ya tatizo la utambulisho wa mifano, kwa kutumia Mazingira ya Kuonekana hivi karibuni. Tunaonyesha kwamba kuunganisha mabadiliko kama hayo kwenye kituo cha BiLSTM kina maendeleo makubwa na yenye mabadiliko makubwa kwa kadri ya gharama zisizo na gharama, na tunaonyesha matokeo yanayoendelea zaidi pale yanapounganishwa na BERT.', 'af': "Ons stel nuwe resultate voor die probleem van volgorde metaforetiketting, gebruik die onlangs ontwikkelde Sichtbaarheid Inbeeldings. Ons wys dat die samelewing van sodanige inbettings tot die invoer van 'n BiLSTM bestaan konsistente en betaling verbeteringe by amper geen koste, en ons voorsien verdere verbeterde resultate wanneer sigbaarheid inbettings gekombineer word met BERT.", 'fa': 'ما نتایج جدید برای مشکل برچسب\u200cهای متافره\u200cای را با استفاده از انجمن\u200cهای دیده\u200cای اخیرا توسعه می\u200cکنیم. ما نشان می دهیم که هماهنگی چنین وسیله\u200cها به ورودی یک BiLSTM به تقریباً هزینه\u200cای قابل توسعه و اضافه\u200cای ارائه می\u200cدهد، و ما نتیجه\u200cهای بیشتری بهتر را پیش می\u200cدهیم زمانی که وسیله\u200cهای دیده\u200cایی با BERT ترکیب می\u200cشوند.', 'am': 'አዲስ ፍሬዎችን አቀረብን፡፡ እንደዚህ የቢልSTM አካሄዱን ለመቀበል እናሳየዋለን፤ በዋጋው አንዳች ዋጋም ሳይሆን ትክክለኛ እናደርጋለን፤ እናም ከBERT ጋር በተቀማጠለበት ጊዜ የራእይ ፍሬዎችን አብልጠን እናደርጋለን፡፡', 'tr': 'Ýakynda Ullanylan Görkezilişini Aňlamak üçin täze netijeleri görkezip. Biz BiLSTM girişiniň beýleki düzümlerini bir şekilde çykarmak üçin diýen ýagdaýda möhüm gelişmeler bolup getirilýäris we biz BERT bilen görünüşenlik düzümlerini gowurarak netijeleri getirilýäris.', 'sq': 'Ne paraqesim rezultate të reja për problemin e etiketave të metaforave të sekuencës, duke përdorur Embeddings të dukshëm të zhvilluar kohët e fundit. We show that concatenating such embeddings to the input of a BiLSTM obtains consistent and significant improvements at almost no cost, and we present further improved results when visibility embeddings are combined with BERT.', 'hy': 'Մենք ներկայացնում ենք նոր արդյունքներ հաջորդականության փոխաբերական պիտակումների խնդիրը, օգտագործելով վերջերս զարգացած տեսանելիության ներգրավումները: We show that concatenating such embeddings to the input of a BiLSTM obtains consistent and significant improvements at almost no cost, and we present further improved results when visibility embeddings are combined with BERT.', 'az': 'Biz seçmə metaforların etiketlərinin problemlərinə yeni sonuçlarını göstəririk, son keçirilmiş Görünüşlük İfadələrini istifadə edirik. Belə bir BiLSTM girişinə birləşdirmək müəyyən və möhkəm düzəltmələri az qala qiymətsiz olaraq əlavə edər və görünüşlük inşalları BERT ilə birləşdikdə daha yaxşılaşdırılmış sonuçları göstəririk.', 'bn': 'আমরা সাম্প্রতিক উন্নয়নশীল দৃশ্যমান দৃষ্টিভঙ্গি ব্যবহার করে নতুন ফলাফল উপস্থাপন করছি। We show that concatenating such embeddings to the input of a BiLSTM obtains consistent and significant improvements at almost no cost, and we present further improved results when visibility embeddings are combined with BERT.', 'bs': 'Predstavljamo nove rezultate za problem označavanja metafora u sekvenciji, koristeći nedavno razvijene integracije vidljivosti. Pokazujemo da potvrđivanje takvih integracija u ulaz BiLSTM dobija konsekvente i značajne poboljšanje skoro bez troškova, i predstavljamo daljnje poboljšane rezultate kada se pojave vidljivosti kombiniraju sa BERT-om.', 'ca': "We present new results for the problem of sequence metaphor labeling, using the recently developed Visibility Embeddings.  Mostrem que concatenar aquestes incorporacions a la entrada d'un BiLSTM obté millores consistents i significatives gairebé sense cost, i presentem resultats més millorats quan les incorporacions de visibilitat es combinan amb BERT.", 'cs': 'Představujeme nové výsledky pro problematiku popisování sekvenčních metaforem s využitím nedávno vyvinutých Visibility Embeddings. Ukazujeme, že spojení takových vložení se vstupem BiLSTM dosahuje konzistentních a významných zlepšení téměř bez nákladů, a při kombinaci viditelnosti s BERT prezentujeme další zlepšení výsledků.', 'fi': 'Esittelemme uusia tuloksia sekvenssimäärien merkitsemisen ongelmaan käyttäen äskettäin kehitettyjä Visibility Embeddings -upotuksia. Osoitamme, että tällaisten upotusten yhdistäminen BiLSTM:n syöttöön tuottaa johdonmukaisia ja merkittäviä parannuksia lähes ilman kustannuksia, ja esittelemme edelleen parempia tuloksia, kun näkyvyyden upotukset yhdistetään BERT:n kanssa.', 'et': 'Esitleme uusi tulemusi järjestuse metafooride märgistamise probleemi kohta, kasutades hiljuti välja töötatud nähtavuse manustamist. Näitame, et selliste manustamiste sidumine BiLSTM sisendiga toob kaasa järjepidevad ja märkimisväärsed parandused peaaegu ilma kuludeta ning esitame veelgi paremaid tulemusi nähtavuse manustamise kombineerimisel BERTiga.', 'jv': 'label Awak dhéwé éntukno akeh sampeyan ngono akeh lani dianggawe lan ingkang BiLTM sing luwih dumadhi lan akeh barang nggawe layang sampeyan katimbang kelas gak dhéwé, lan akeh dumadhi dianggap sing luwih dumadhi kanggo kebutuhan seneng cah dumadhi winih (sedhaya ingkang BERT).', 'he': 'אנו מציגים תוצאות חדשות לבעיה של תיקון מטאפורות רצף, בשימוש באמצעות התקפות ראייה המפותחות לאחרונה. אנו מראים ששיפור כזה של תוכניות לתכנית של BILSTM מקבל שיפורים קבועים וממשמעותיים כמעט ללא עלות, ואנחנו מציגים תוצאות משתפרות נוספות כאשר תוכניות ראיות משולבות עם BERT.', 'ha': "Tuna gabatar da matsalar masu matsalar misãlai na sauri, da amfani da Ƙaramihin da aka buɗe na Gani na yanzu. Tuna nũna cewa, sambaƙãwa na wannan da ke cikin an shigar da BiLSM na sami da gyãra mai girma a ƙidãya ko wani ma'anar kyauta ba, kuma munã gabatar da ƙari mafi kyãwo idan an haɗa bayani da BERT.", 'sk': 'Predstavljamo nove rezultate za problem označevanja zaporednih metaforov z uporabo nedavno razvitih vidljivostnih vdelav. Pokazujemo, da povezovanje takšnih vdelav z vložkom BiLSTM dosega dosledne in znatne izboljšave skoraj brez stroškov, in predstavljamo dodatne izboljšane rezultate, ko so vdelave vidljivosti kombinirane z BERT.', 'bo': 'ང་ཚོས་ཉེ་ཆར་གྱིས་མཐོང་ནུས་ཀྱི་རྣམ་གྲངས་གསརཔ་གི་བྱ་ཚུལ་གསརཔ་སྟོན་པ ང་ཚོས་BiLSTM་གི་འཇུག'}
{'en': 'Inducing Language-Agnostic Multilingual Representations', 'ar': 'تحفيز التمثيل متعدد اللغات الملحد للغة', 'es': 'Inducción de representaciones multilingües independientes del idioma', 'pt': 'Induzindo Representações Multilíngues Independentes de Idioma', 'fr': 'Induire des représentations multilingues indépendantes de la langue', 'ja': '言語-認知的多言語表現の誘導', 'zh': '诱语不可知多言', 'ru': 'Индуцирование языково-агностических многоязычных представлений', 'hi': 'उत्प्रेरण भाषा-अज्ञेयवादी बहुभाषी प्रतिनिधित्व', 'ga': 'Léirithe Ilteangacha Teanga-Agnóiseacha a spreagadh', 'ka': 'ენის- ადნოსტიკური მრავალური გამოსახულებების ინდექცია', 'el': 'Προκίνηση γλωσσικών-αγνωστικών πολυγλωσσικών αναπαραστάσεων', 'hu': 'Nyelv-Agnostika többnyelvű képviseletek indukálása', 'kk': 'Тіл- агностикалық көптілік таңбаларын көтеру', 'mk': 'Индуцирање на јазик- агностички мултијазични претставувања', 'it': 'Indurre le rappresentanze multilingue linguistiche Agnostiche', 'lt': 'Inducing Language-Agnostic Multilingual Representations', 'mt': 'L-Induzzjoni ta’ Rappreżentazzjonijiet Multilingwi Lingwistiċi-Agnostiċi', 'mn': 'Хол-агностик олон хэл төлөвлөгөөг', 'ms': 'Meminduksi Perwakilan Berbahasa-Agnostik', 'ro': 'Inducerea reprezentărilor lingvistice multilingve', 'ml': 'ഭാഷ- അഗ്നോസ്റ്റിക്ക് പല ഭാഷ പ്രതിനിധികള്\u200d കാണിക്കുന്നു', 'pl': 'Indukcja językowo-agnostycznych reprezentacji wielojęzycznych', 'no': 'Induksjonar språk- agnostiske fleirspråk- representasjonar', 'si': 'භාෂාව- අග්නෝස්ටික් බොහොම භාෂාව ප්\u200dරතිනිධාන', 'sr': 'Podsticajući jezik-Agnostičke višejezičke predstave', 'so': 'Inducing Language-Agnostic Multilingual Representations', 'sv': 'Främja språkAgnostiska flerspråkiga representationer', 'ur': 'زبان-اگنیسی Multilingual Representations Inducing Language-Agnostic Multilingual Representations', 'ta': 'Inducing Language-Agnostic Multilingual Representations', 'uz': 'Language- Agnostic Multilingua representations', 'vi': 'Giới thiệu Ngôn ngữ-Tình Nhận diện đa ngôn ngữ', 'bg': 'Индуктиране на езиково-агностични многоезични представяния', 'hr': 'Indiciranje jezika-Agnostičkih višejezičkih predstavljanja', 'de': 'Induzierende sprachAgnostische Mehrsprachige Repräsentationen', 'nl': 'Induceren van taal-agnostische meertalige vertegenwoordigingen', 'ko': '유도언어 알 수 없는 다언어 표징', 'id': 'Meminduksi Perwakilan Berbahasa-Agnostik', 'da': 'Fremme af sprog-Agnostiske flersprogede repræsentationer', 'sw': 'Kuonyesha Representation of Language-Agnostic Multilingua', 'af': 'Voorskou Taal- Agnostiese Multilingual Representations', 'fa': 'تحریک نمایش\u200cهای زبان- اگنستیک چندین زبان', 'tr': 'Dil-agnostik köp dil temsilleri', 'hy': 'Inducing Language-Agnostic Multilingual Representations', 'am': 'ቋንቋ-Agnostic Multilingual References', 'az': 'Dil-Agnostik 칞oxlu dil temsill톛ri', 'bs': 'Indiciranje jezika-Agnostičkih višejezičkih predstavljanja', 'ca': 'Inducing Language-Agnostic Multilingual Representations', 'bn': 'Inducing Language-Agnostic Multilingual Representations', 'cs': 'Vyvolávání jazykově-agnostické vícejazyčné reprezentace', 'fi': 'Kieliagnostiset monikieliset edustustot', 'et': 'Keeleagnostiliste mitmekeelsete esinduste indutseerimine', 'sq': 'Duke induktuar përfaqësime shumëgjuhëse gjuhë-agnostike', 'sk': 'Spodbujanje jezikovno-agnostičnih večjezičnih predstavništev', 'jv': 'gagal', 'ha': 'Nuna Repositori na Lugha- Agnostic', 'bo': 'སྐད་ཡིག་དང་རྒྱལ་སྤྱིར་བཏང་བའི་སྐད་རིགས་ཀྱི་རྣམ་པ', 'he': 'מייצגים רבים שפתיים-אגנוסטיים'}
{'en': 'Cross-lingual representations have the potential to make NLP techniques available to the vast majority of languages in the world. However, they currently require large pretraining corpora or access to typologically similar languages. In this work, we address these obstacles by removing language identity signals from multilingual embeddings. We examine three approaches for this : (i) re-aligning the vector spaces of target languages (all together) to a pivot source language ; (ii) removing language-specific means and variances, which yields better discriminativeness of embeddings as a by-product ; and (iii) increasing input similarity across languages by removing morphological contractions and sentence reordering. We evaluate on XNLI and reference-free MT evaluation across 19 typologically diverse languages. Our findings expose the limitations of these approachesunlike vector normalization, vector space re-alignment and text normalization do not achieve consistent gains across encoders and languages. Due to the approaches’ additive effects, their combination decreases the cross-lingual transfer gap by 8.9 points (m-BERT) and 18.2 points (XLM-R) on average across all tasks and languages, however.', 'ar': 'العروض عبر اللغات لديها القدرة على جعل تقنيات البرمجة اللغوية العصبية متاحة للغالبية العظمى من اللغات في العالم. ومع ذلك ، فإنهم يحتاجون حاليًا إلى مجموعات كبيرة قبل التدريب أو الوصول إلى لغات مشابهة من حيث التصنيف. في هذا العمل ، نتعامل مع هذه العقبات عن طريق إزالة إشارات الهوية اللغوية من حفلات الزفاف متعددة اللغات. نقوم بفحص ثلاث طرق لهذا: (1) إعادة محاذاة مسافات المتجهات للغات الهدف (كلها معًا) إلى لغة مصدر محورية ؛ (2) إزالة الوسائل والاختلافات الخاصة باللغة ، والتي تؤدي إلى تمييز أفضل لحفلات الزفاف كمنتج ثانوي ؛ و (3) زيادة تشابه المدخلات عبر اللغات عن طريق إزالة الانقباضات الصرفية وإعادة ترتيب الجملة. نقوم بتقييم XNLI وتقييم الترجمة الآلية الخالية من المراجع عبر 19 لغة متنوعة نسبيًا. تكشف النتائج التي توصلنا إليها عن قيود هذه الأساليب - على عكس تطبيع المتجهات ، لا تحقق إعادة محاذاة مساحة المتجه وتطبيع النص مكاسب متسقة عبر أجهزة التشفير واللغات. نظرًا للتأثيرات الإضافية للطرق ، فإن توليفتها تقلل فجوة النقل عبر اللغات بمقدار 8.9 نقطة (m-BERT) و 18.2 نقطة (XLM-R) في المتوسط عبر جميع المهام واللغات.', 'es': 'Las representaciones multilingües tienen el potencial de hacer que las técnicas de PNL estén disponibles para la gran mayoría de los idiomas del mundo. Sin embargo, actualmente requieren grandes corpus de preentrenamiento o acceso a lenguajes tipológicamente similares. En este trabajo, abordamos estos obstáculos eliminando las señales de identidad lingüística de las incorporaciones multilingües. Examinamos tres enfoques para esto: (i) realinear los espacios vectoriales de los idiomas de destino (todos juntos) con un idioma de origen pivotante; (ii) eliminar los medios y las variaciones específicos del idioma, lo que produce una mejor discriminación de las incorporaciones como subproducto; y (iii) aumentar la similitud de entrada entre idiomas eliminando las contracciones morfológicas y el reordenamiento de las oraciones. Evaluamos la evaluación de XNLI y MT sin referencias en 19 idiomas tipológicamente diversos. Nuestros hallazgos exponen las limitaciones de estos enfoques; a diferencia de la normalización vectorial, la realineación del espacio vectorial y la normalización del texto no logran ganancias consistentes en codificadores e idiomas. Sin embargo, debido a los efectos aditivos de los enfoques, su combinación reduce la brecha de transferencia entre idiomas en 8,9 puntos (M-bert) y 18,2 puntos (XLM-R) de media en todas las tareas e idiomas.', 'pt': 'As representações multilíngues têm o potencial de tornar as técnicas de PNL disponíveis para a grande maioria das línguas do mundo. No entanto, atualmente exigem grandes corpora de pré-treinamento ou acesso a linguagens tipologicamente semelhantes. Neste trabalho, abordamos esses obstáculos removendo os sinais de identidade linguística de embeddings multilíngues. Examinamos três abordagens para isso: (i) realinhar os espaços vetoriais das línguas-alvo (todos juntos) para uma língua-fonte pivô; (ii) remoção de meios e variações específicas do idioma, o que resulta em melhor discriminação de embeddings como subproduto; e (iii) aumentar a similaridade de entrada entre os idiomas, removendo as contrações morfológicas e a reordenação das frases. Avaliamos em XNLI e avaliação MT sem referência em 19 idiomas tipologicamente diversos. Nossas descobertas expõem as limitações dessas abordagens – ao contrário da normalização vetorial, o realinhamento do espaço vetorial e a normalização de texto não alcançam ganhos consistentes em codificadores e idiomas. No entanto, devido aos efeitos aditivos das abordagens, sua combinação diminui a lacuna de transferência entre línguas em 8,9 pontos (m-BERT) e 18,2 pontos (XLM-R) em média em todas as tarefas e idiomas.', 'fr': "Les représentations multilingues ont le potentiel de rendre les techniques de PNL accessibles à la grande majorité des langues du monde. Cependant, ils nécessitent actuellement de grands corpus de pré-formation ou un accès à des langues typologiquement similaires. Dans ce travail, nous nous attaquons à ces obstacles en supprimant les signaux d'identité linguistique des intégrations multilingues. Pour ce faire, nous examinons trois approches\xa0: (i) réalignement des espaces vectoriels des langues cibles (ensemble) sur une langue source pivot\xa0; (ii) suppression des moyennes et des variances spécifiques à la langue, ce qui permet une meilleure discrimination des intégrations en tant que sous-produit\xa0; et (iii) augmentation de la similarité des entrées entre les langues en supprimant les contractions morphologiques et en réordonnant les phrases. Nous évaluons sur XNLI et l'évaluation MT sans référence dans 19 langues typologiquement différentes. Nos résultats révèlent les limites de ces approches\xa0: contrairement à la normalisation vectorielle, le réalignement de l'espace vectoriel et la normalisation du texte ne permettent pas d'obtenir des gains cohérents entre les encodeurs et les langages. En raison des effets additifs des approches, leur combinaison réduit l'écart de transfert entre les langues de 8,9 points (M-bert) et de 18,2 points (XLM-R) en moyenne pour toutes les tâches et toutes les langues.", 'ja': 'クロスリンガル表現は、NLPテクニックを世界の大多数の言語に利用可能にする可能性を秘めている。 しかしながら、これらは現在、大規模な事前訓練または類型的に類似した言語へのアクセスを必要としています。 この作業では、多言語埋め込みから言語アイデンティティシグナルを削除することで、これらの障害に対処します。 このための3つのアプローチを検討します。（ i ）ターゲット言語のベクトル空間を（すべて合わせて）ピボットソース言語に再配置する。（ ii ）言語固有の手段と分散を削除することで、副産物としての埋め込みの識別性が向上する。（ iii ）形態的縮小と文の並べ替えを削除することによって、言語間の入力の類似性を向上させる。 私たちは、類型的に多様な19の言語にわたるXNLIおよび参照なしのMT評価について評価します。 我々の知見は、ベクトル正規化、ベクトル空間再整列、およびテキスト正規化とは異なり、エンコーダと言語間で一貫した利得を達成しない、これらのアプローチの制限を明らかにする。 しかしながら、アプローチの加算効果により、それらの組み合わせは、すべてのタスクと言語にわたって、クロスリンガル転送ギャップを平均8.9ポイント（ m - BERT ）および18.2ポイント（ XLM - R ）減少させる。', 'zh': '语言有可使NLP术可使世绝大多数言。 然其目前须大预训练语料库访类相似之语。 于此,我们从多言语嵌入中删除语言信号以解此障。 为此三法:(i)将向量间(悉置)更为枢轴源语。 (二) 消特定言语异同,以别副产品嵌。 (iii)消形缩句重序以益言语之相似性。 吾于XNLI与免参考MT评19异类而言者也。 见暴其术者局限性- 与矢量规范化不同,矢量空复对齐文本规范化无以成编码器言语之益。 然其法相效,其组使诸务语移差减8.9点(m-BERT)、18.2点(XLM-R)。', 'ru': 'Межязычные представления могут сделать методы NLP доступными для подавляющего большинства языков в мире. Однако в настоящее время они требуют прохождения крупными органами предварительной подготовки или доступа к типологически схожим языкам. В этой работе мы устраняем эти препятствия, удаляя языковые сигналы идентичности из многоязычных вложений. Для этого мы изучаем три подхода: (i) повторное выравнивание векторных пространств целевых языков (все вместе) к сводному исходному языку; (ii) удаление языковых средств и дисперсий, что дает лучшую дискриминируемость вложений как побочного продукта; и (iii) увеличение входного сходства между языками путем удаления морфологических сокращений и переупорядочения предложений. Мы оцениваем XNLI и бесконтактную оценку MT на 19 типологически разнообразных языках. Наши выводы раскрывают ограничения этих подходов - в отличие от нормализации векторного пространства, повторного выравнивания векторного пространства и нормализации текста не достигают последовательных улучшений между кодировщиками и языками. Однако благодаря аддитивным эффектам подходов их комбинация уменьшает межъязыковой разрыв в переносе на 8,9 пункта (m-BERT) и 18,2 пункта (XLM-R) в среднем по всем задачам и языкам.', 'hi': 'क्रॉस-भाषी अभ्यावेदन में एनएलपी तकनीकों को दुनिया की अधिकांश भाषाओं के लिए उपलब्ध कराने की क्षमता है। हालांकि, उन्हें वर्तमान में बड़े प्रीट्रेनिंग कॉर्पोरेट या टाइपोलॉजिकल रूप से समान भाषाओं तक पहुंच की आवश्यकता होती है। इस काम में, हम बहुभाषी एम्बेडिंग से भाषा पहचान संकेतों को हटाकर इन बाधाओं को संबोधित करते हैं। हम इसके लिए तीन दृष्टिकोणों की जांच करते हैं: (i) लक्ष्य भाषाओं के वेक्टर रिक्त स्थान (सभी एक साथ) को एक धुरी स्रोत भाषा में फिर से संरेखित करना; (ii) भाषा-विशिष्ट साधनों और प्रसरणों को हटाना, जो एक उप-उत्पाद के रूप में एम्बेडिंग की बेहतर भेदभावपूर्णता उत्पन्न करता है; और (iii) रूपात्मक संकुचन और वाक्य पुन: क्रमबद्धता को हटाकर भाषाओं में इनपुट समानता में वृद्धि करना। हम XNLI और 19 typologically विविध भाषाओं में संदर्भ मुक्त एमटी मूल्यांकन पर मूल्यांकन करते हैं। हमारे निष्कर्ष इन दृष्टिकोणों की सीमाओं को उजागर करते हैं- वेक्टर सामान्यीकरण के विपरीत, वेक्टर स्पेस री-अलाइनमेंट और टेक्स्ट सामान्यीकरण एनकोडर और भाषाओं में लगातार लाभ प्राप्त नहीं करते हैं। दृष्टिकोण के additive प्रभावों के कारण, उनका संयोजन सभी कार्यों और भाषाओं में औसतन 8.9 अंक (m-BERT) और 18.2 अंक (XLM-R) द्वारा क्रॉस-लिंगुअल ट्रांसफर गैप को कम कर देता है।', 'ga': 'Tá an poitéinseal ag léirithe tras-teangacha teicnící NLP a chur ar fáil d’fhormhór mór theangacha an domhain. Mar sin féin, teastaíonn corpora réamhoiliúint mór uathu faoi láthair nó rochtain ar theangacha atá cosúil leis an tíopeolaíocht. Sa obair seo, tugaimid aghaidh ar na constaicí sin trí chomharthaí féiniúlachta teanga a bhaint de neadacha ilteangacha. Scrúdaímid trí chur chuige ina leith seo: (i) spásanna veicteoireacha na sprioctheanga (ar fad le chéile) a athailíniú go teanga foinse mhaighdeog; (ii) deireadh a chur le modhanna agus éagsúlachtaí teanga-shonracha, as a n-eascraíonn idirdhealaitheacht níos fearr ar leabaithe mar sheachtháirge; agus (iii) cosúlacht ionchuir a mhéadú trasna teangacha trí chrapadh moirfeolaíocha agus athordú abairtí a bhaint. Déanaimid meastóireacht ar XNLI agus ar mheastóireacht MT gan tagairt thar 19 dteanga atá éagsúil ó thaobh na clódóireachta de. Nochtann ár dtorthaí teorainneacha na gcur chuige seo - murab ionann agus normalú veicteora, ní ghnóthaíonn ath-ailíniú spás veicteora agus normalú téacs gnóthachain chomhsheasmhacha trasna ionchódóirí agus teangacha. Mar gheall ar éifeachtaí breisitheacha na gcur chuige, laghdaítear an bhearna aistrithe tras-teanga 8.9 pointe (m-BERT) agus 18.2 pointe (XLM-R) ar an meán thar na tascanna agus na teangacha go léir, áfach.', 'hu': 'A nyelvek közötti reprezentációk lehetőséget biztosítanak arra, hogy a világ nyelveinek túlnyomó többsége számára elérhetővé tegyék az NLP technikákat. Jelenleg azonban szükségük van nagy előkészítő corporákra vagy tipológiailag hasonló nyelvekhez való hozzáférésre. Ebben a munkában a többnyelvű beágyazásokból származó nyelvi azonosító jelek eltávolításával kezeljük ezeket az akadályokat. Ennek érdekében három megközelítést vizsgálunk: (i) a célnyelvek vektortereinek újraigazítása (összesen) egy pivot forrásnyelvre; ii. a nyelvspecifikus eszközök és eltérések eltávolítása, amelyek a beágyazások mint melléktermék jobb diszkriminációját eredményezik; és iii. a nyelvek közötti hasonlóság növelése a morfológiai összehúzódások eltávolításával és a mondatok átrendezésével. Az XNLI és referencia-mentes MT értékelést 19 tipológiailag különböző nyelven értékeljük. Eredményeink feltárják ezeknek a megközelítéseknek a korlátait – ellentétben a vektorok normalizálásával, a vektortér újraigazításával és a szöveg normalizálásával nem érnek el következetes nyereséget a kódolók és nyelvek között. A megközelítések additív hatásainak köszönhetően azonban kombinációjuk átlagosan 8,9 ponttal (m-BERT) és 18,2 ponttal (XLM-R) csökkenti az összes feladat és nyelv esetében.', 'el': 'Οι γλωσσικές αναπαραστάσεις έχουν τη δυνατότητα να καταστήσουν τις τεχνικές του ΝLP διαθέσιμες στη συντριπτική πλειοψηφία των γλωσσών του κόσμου. Ωστόσο, αυτή τη στιγμή απαιτούν μεγάλα σώματα προετοιμασίας ή πρόσβαση σε τυπολογικά παρόμοιες γλώσσες. Σε αυτή την εργασία, αντιμετωπίζουμε αυτά τα εμπόδια αφαιρώντας σήματα γλωσσικής ταυτότητας από πολυγλωσσικές ενσωματώσεις. Εξετάζουμε τρεις προσεγγίσεις για αυτό: (i) επαναευθυγράμμιση των διανυσματικών χώρων των γλωσσών-στόχων (όλες μαζί) σε μια γλώσσα πηγής περιστροφής. (ii) κατάργηση των μέσων και των αποκλίσεων που αφορούν τη γλώσσα, γεγονός που επιφέρει καλύτερη διακριτικότητα των ενσωμάτωσης ως υποπροϊόντων· και iii) αύξηση της ομοιότητας εισαγωγής μεταξύ των γλωσσών με την κατάργηση των μορφολογικών συστολών και την αναδιοργάνωση των προτάσεων. Αξιολογούμε με την αξιολόγηση χωρίς αναφορά σε 19 τυπολογικά διαφορετικές γλώσσες. Τα ευρήματά μας εκθέτουν τους περιορισμούς αυτών των προσεγγίσεων – σε αντίθεση με τη διανυσματική ομαλοποίηση, η επαναευθυγράμμιση του διανυσματικού χώρου και η ομαλοποίηση κειμένου δεν επιτυγχάνουν συνεπή κέρδη μεταξύ κωδικοποιητών και γλωσσών. Λόγω των πρόσθετων επιπτώσεων των προσεγγίσεων, ο συνδυασμός τους μειώνει το χάσμα μεταξύ γλωσσών κατά 8.9 σημεία (m-BERT) και 18.2 σημεία (XLM-R) κατά μέσο όρο σε όλες τις εργασίες και γλώσσες.', 'ka': 'სამყაროში უფრო დიდი ენებისთვის შესაძლებლობად NLP ტექნოგიების გამოყენება. მაგრამ, ისინი ახლა უფრო დიდი კოპორაციას ან ტიპოლოგიურად მსგავსი ენებისთვის მიყვარდება. ამ სამუშაოში, ჩვენ ამ ბრძანებების შესახებ მრავალენგური ინტერტიფიკაციის სიგნალების წაშლად. ჩვენ ამისთვის სამი მიღება შევხედავთ: i) მიღებული ენების გვეკტორის სივრცე (ყველაფერი ერთად) pivot მსოფლიო ენისთვის გადაწყენება; ii) ენის განსაკუთრებული სისტემა და გარიანციების წაშლა, რომლებიც უფრო დისკრიმინატიურად გამოიყენება, როგორც პროდისტის განსაკუთრებული სისტემა; iii) მოპოროლოგიური კონტრექციები და სიტყვების რეორდირების გამოყენებით იქნება სიტყვების განსხვავება. ჩვენ XNLI და განსხვავებული MT განსხვავებაში 19 ტიპოლოგიურად განსხვავებული ენაში გავამუშავებთ. ჩვენი შესაძლებლობები გამოიყენებენ ამ გვექტორის ნორმალიზაციის განსხვავებული მიღებების განსხვავება, გვექტორის სივრცე განსხვავება და ტექსტის ნორმალიზაცია არ მიიღებენ კოდერების და ენა მაგრამ მიღებს დამატებული ეფექტების შესახებ, მათი კომბიუნციაცია უფრო სიგრძნელი გადატანსების განსხვავებას 8,9 წუთით (m-BERT) და 18,2 წუთით (XLM-R) განსხვავებული ყველა დავალების და ენაზე', 'it': "Le rappresentazioni multilingue hanno il potenziale di rendere disponibili le tecniche PNL alla stragrande maggioranza delle lingue del mondo. Tuttavia, attualmente richiedono grandi corpora di pre-formazione o l'accesso a linguaggi tipologicamente simili. In questo lavoro, affrontiamo questi ostacoli rimuovendo i segnali di identità linguistica dalle incorporazioni multilingue. Esaminiamo tre approcci per questo: (i) riallineare gli spazi vettoriali delle lingue di destinazione (tutti insieme) a una lingua sorgente pivot; ii) eliminare i mezzi e le varianze specifici della lingua, che consentono una migliore discriminabilità delle incorporazioni come sottoprodotto; e (iii) aumentare la somiglianza degli input tra le lingue rimuovendo le contrazioni morfologiche e il riordino delle frasi. Valutiamo su XNLI e valutazione MT senza riferimento in 19 lingue tipologicamente diverse. I nostri risultati espongono i limiti di questi approcci: a differenza della normalizzazione vettoriale, il riallineamento dello spazio vettoriale e la normalizzazione del testo non raggiungono guadagni coerenti tra encoder e linguaggi. A causa degli effetti additivi degli approcci, la loro combinazione riduce il divario di trasferimento translinguale di 8,9 punti (m-BERT) e 18,2 punti (XLM-R) in media per tutte le attività e le lingue, tuttavia.", 'kk': 'Тілі тілдердің көпшілігіне NLP техникаларын әлемдегі тілдердің көпшілігіне қол жеткізу мүмкіндігі бар. Бірақ олар қазіргі уақытта үлкен корпора не типтологиялық ұқсас тілдерге қатынау керек. Бұл жұмыс ішінде, бірнеше тіл идентификациясын көп тілді ендіру сигналдарынан алып тастап, бұл бұл бұлдарды шешуіміз керек. Біз бұл үш қатынасын тексереміз: i) мақсатты тілдердің векторлық бос орындарын (барлығы біріктірілген) pivot көзінің тіліне қайта түрлендіреміз; ii) тілді арнаулы мәліметтерді және айырмашылықтарды өшіру, бұл құрылғының жақсы дискриминациялығын өзгертеді; және iii) морфологиялық сұлбаларды және сұлбаларды қайта реттеу арқылы тілдерге ұқсастығын көтеру үшін. Біз XNLI және сілтеме бос MT бағалауын 19 типтологиялық тілдерде бағалаймыз. Біздің іздегеніміз бұл келесінің шектеулері вектор нормализациясы, вектор бос орын қайта теңдеу және мәтін нормализациясы кодерлер мен тілдердің арасында тәуелсіз жеткізбейді. Олардың қосымша эффекттерінен біріктіру үшін оның біріктірімі барлық тапсырмалар мен тілдер арасында 8,9 нүкте (m-BERT) және 18,2 нүкте (XLM-R) арасындағы біріктірілген ауыстыру аралығын өзгертеді.', 'mk': 'Многу јазички претставувања имаат потенцијал да ги обезбедат техниките на НЛП на располагање на големото мнозинство јазици во светот. Сепак, тие моментално бараат големи предобуки или пристап до типологички слични јазици. In this work, we address these obstacles by removing language identity signals from multilingual embeddings.  We examine three approaches for this: (i) re-aligning the vector spaces of target languages (all together) to a pivot source language;  (ii) отстранување на средствата и варијанциите специфични за јазикот, кои предизвикуваат подобра дискриминативност на вградувањата како помошни производи; и (iii) зголемување на сличноста на влезот во јазиците со отстранување на морфолошките контракции и реорганизација на речениците. Ние проценуваме на XNLI и безреферентна MT проценка низ 19 типологички различни јазици. Нашите откритија ги изложуваат ограничувањата на овие пристапи за разлика од нормализацијата на векторите, реализацијата на векторите и нормализацијата на текстот не постигнуваат константни добивки во кодерите и јазиците. Поради додативните ефекти на пристапите, нивната комбинација ја намалува прекујазичната трансференција за 8,9 поени (m-BERT) и 18,2 поени (XLM-R) во просек на сите задачи и јазици.', 'ms': 'Perwakilan saling bahasa mempunyai potensi untuk membuat teknik NLP tersedia untuk kebanyakan bahasa di dunia. Namun, mereka kini memerlukan corpora pretraining besar atau akses ke bahasa tipologi yang sama. Dalam kerja ini, kita mengatasi halangan-halangan ini dengan menghapuskan isyarat identiti bahasa dari penyambungan berbilang bahasa. Kami memeriksa tiga pendekatan untuk ini: (i) menyesuaikan semula ruang vektor bahasa sasaran (semua bersama-sama) kepada bahasa sumber pivot; (ii) menghapuskan cara dan variasi khusus bahasa, yang menghasilkan diskriminasi yang lebih baik bagi penyampaian sebagai produk sampingan; dan (iii) meningkatkan kesamaan input melalui bahasa dengan menghapuskan kontraksi morfologik dan penyesuaian kalimat. Kami menilai pada XNLI dan penilaian MT bebas rujukan melalui 19 bahasa yang berbeza secara tipologi. Penemuan kami mengekspos keterangan pendekatan ini-tidak seperti normalisasi vektor, penyesuaian semula ruang vektor dan normalisasi teks tidak mencapai keuntungan konsisten melalui pengekod dan bahasa. Sebab kesan tambahan pendekatan, kombinasi mereka menurunkan jarak pemindahan saling bahasa dengan 8.9 titik (m-BERT) dan 18.2 titik (XLM-R) secara rata-rata dalam semua tugas dan bahasa, bagaimanapun.', 'lt': 'Dauguma kalbų pasaulyje gali naudotis NLP metodais, kurie gali būti naudojami įvairiomis kalbomis. Tačiau šiuo metu jiems reikalingas didelis išankstinis mokymas arba prieiga prie tipiškai panašių kalbų. Šiame darbe sprendžiame šias kliūtis pašalinant kalbos tapatybės signalus iš daugiakalbių įrangų. Nagrinėjame tris metodus: i) tikslinių kalbų vektorių erdvių (visi kartu) suderinimą su pagrindiniu šaltiniu; ii) pašalinti kalbai būdingas priemones ir skirtumus, dėl kurių būtų labiau diskriminuojama kaip šalutinis produktas; ir iii) didinti panašumą tarp kalbų, pašalinant morfologinius sutrikimus ir perskirstant sakinius. Vertiname XNLI ir nenurodyto MT vertinimą 19 tipologiškai įvairaus pobūdžio kalbų. Mūsų rezultatai atskleidžia šių metodų apribojimus, skirtingai nuo vektorių normalizavimo, vektorių erdvės perskirstymo ir teksto normalizavimo, nesudaro nuoseklaus naudos įvairiuose koduotojuose ir kalbose. Tačiau dėl metodų papildomo poveikio jų derinys mažina tarpkalbinio perdavimo spragą 8,9 punktu (m-BERT) ir 18,2 punktu (XLM-R) vidutiniškai visomis užduotimis ir kalbomis.', 'mt': 'Ir-rappreżentazzjonijiet translingwi għandhom il-potenzjal li jagħmlu t-tekniki NLP disponibbli għall-maġġoranza vasta tal-lingwi fid-dinja. Madankollu, bħalissa jeħtieġu korpura kbira ta’ taħriġ minn qabel jew aċċess għal lingwi tipikament simili. F’dan ix-xogħol, nindirizzaw dawn l-ostakli billi neħħew is-sinjali tal-identità lingwistika minn inkorporazzjonijiet multilingwi. Eżaminaw tliet approċċi għal dan: (i) l-allinjament mill-ġdid tal-ispazji tal-vetturi tal-lingwi fil-mira (kollha flimkien) għal lingwa tas-sors pivot; (ii) it-tneħħija ta’ mezzi u varjazzjonijiet speċifiċi għall-lingwa, li jwasslu għal diskriminazzjoni a ħjar tal-inkorporazzjonijiet bħala prodott sekondarju; u (iii) tiżdied is-similarità tal-input fil-lingwi kollha billi jitneħħew il-kontrazzjonijiet morfoloġiċi u r-riorganizzazzjoni tas-sentenzi. Aħna jevalwaw fuq XNLI u evalwazzjoni ta’ MT mingħajr referenza f’19-il lingwa tipikament differenti. Is-sejbiet tagħna jesponu l-limitazzjonijiet ta’ dawn l-approċċi li mhumiex simili għan-normalizzazzjoni tal-vetturi, l-allinjament mill-ġdid tal-ispazju tal-vetturi u n-normalizzazzjoni tat-test ma jiksbux kisbiet konsistenti bejn l-kodifikaturi u l-lingwi. Minħabba l-effetti addittivi tal-approċċi, il-kombinazzjoni tagħhom tnaqqas id-differenza fit-trasferiment translingwi b’8.9 punti (m-BERT) u 18.2 punti (XLM-R) bħala medja fil-kompiti u l-lingwi kollha, madankollu.', 'ml': 'ക്രോസ്-ലാങ്കുകളുടെ പ്രതിനിധികള്\u200dക്ക് ലോകത്തിലെ ഏറ്റവും വിശാലമായ ഭാഷകള്\u200dക്ക് NLP ടെക്നിക്കുകള്\u200d ലഭ്യമാക്കാനുള എന്നാലും, ഇപ്പോള്\u200d അവര്\u200dക്ക് ഒരു വലിയ പ്രചരിപ്പിക്കുന്നത് കോര്\u200dപ്പോരിയിലോ സാധാരണ ഭാഷകളില്\u200d ഒരേ പോലെയുള് ഈ ജോലിയില്\u200d, ഞങ്ങള്\u200d ഈ തടസ്സങ്ങള്\u200d വിശദീകരിക്കുന്നു. ഭാഷ അടയാളങ്ങള്\u200d മാറ്റുന്നതില്\u200d നിന്നും പല ഭാഷ അകത്തുള്ള അ We examine three approaches for this: (i) re-aligning the vector spaces of target languages (all together) to a pivot source language;  (ii) ഭാഷ- പ്രത്യേക വ്യത്യാസങ്ങളും മാറ്റങ്ങളും നീക്കം ചെയ്യുന്നു. അത് ഒരു പ്രൊട്ടിനുള്ള വ്യത്യാസങ്ങളായി മാറ്റുന്ന (ഐ) ഭാഷകളില്\u200d എല്ലാ ഭാഷകളിലും ഉള്ള ഇന്\u200dപുട്ടിന്റെയും തുല്യമാണ് വര്\u200dദ്ധിപ്പിക്കുന്നത്, മോര്\u200dഫോളിക്കല്\u200d കണക്ടണ നമ്മള്\u200d എക്സ്നെന്\u200dലിയില്\u200d വ്യത്യസ്തമായി 19 ഭാഷകളില്\u200d വ്യത്യസ്തമായി എംടി വിലയിക്കുന്നതും വിലയിക്കുന്നു. നമ്മുടെ കണ്ടുപിടികള്\u200d വെക്റ്റര്\u200d സാധാരണ സ്വാഭാവികമാക്കുന്നതിന്റെ പരിധികള്\u200d വെളിപ്പെടുത്തുന്നു, വെക്റ്റര്\u200d സ്പെയിന്\u200dറ് വീണ്ടും ചേര അടുത്തുവരുന്നതിന്റെ കൂടുതല്\u200d പ്രഭാവങ്ങള്\u200d കാരണം അവരുടെ കൂട്ടത്തില്\u200d ക്രിസ്ലിങ്ക്ലാന്\u200dസ്റ്റ്രാന്\u200dസ്സിന്റെ സ്ഥാനത്ത് 8. 9 പോയിന്റുകള്\u200d കുറയ്ക്കുന്നു.', 'pl': 'Reprezentacje wielojęzyczne mają potencjał udostępnić techniki NLP zdecydowanej większości języków na świecie. Obecnie jednak wymagają one dużych korpusów wstępnego treningu lub dostępu do typologicznie podobnych języków. W niniejszej pracy rozwiązujemy te przeszkody poprzez usuwanie sygnałów tożsamości językowej z wielojęzycznych osadzeń. Badamy trzy podejścia do tego celu: (i) ponowne wyrównanie przestrzeni wektorowej języków docelowych (wszystkich razem) do języka źródłowego pivot; (ii) usunięcie środków i różnic specyficznych dla języka, co przynosi lepszą dyskryminację osadzeń jako produktu ubocznego; oraz (iii) zwiększenie podobieństwa wejściowego między językami poprzez usunięcie skurczy morfologicznych i zmianę porządku zdań. Oceniamy na XNLI i bezreferencyjnej ocenie MT w 19 typologicznie zróżnicowanych językach. Nasze wyniki ujawniają ograniczenia tych podejść – w przeciwieństwie do normalizacji wektorów, ponownego wyrównania przestrzeni wektorowej i normalizacji tekstu nie osiągają spójnych zysków w koderze i językach. Ze względu na dodatkowe efekty tych metod, ich połączenie zmniejsza jednak lukę transferową między językami o 8,9 punkty (m-BERT) i 18,2 punkty (XLM-R) średnio we wszystkich zadaniach i językach.', 'no': 'Krysspråk-representasjonar har potensialen for å gjera NLP-teknikk tilgjengeleg for dei store fleste språk i verden. Dei krev likevel store korpora eller tilgang til typologisk liknande språk. I denne arbeida adresserer vi desse hindringane ved å fjerna språk- identitetsignalar frå fleirspråk innbygging. Vi undersøker tre tilnærmingar for dette: i) justerer vektormellomrommet til målspråk (alle saman) til ein pivotkjeldespråk på nytt; i ii) fjerna språkspesifikerte måtar og varianser, som fører betre diskriminasjon av innbygging som eit etterprodukt; og og iii) øker inndata liknande på språk ved å fjerna morfologiske kontraksjonar og setningar om ordning. Vi evaluerer på XNLI- og referansfri MT- evaluering på 19 typologisk ulike språk. Finningane våre eksponerer grensene for desse tilnærmingane som ikkje er tilgjengelege vektornormalisering, vektormellomrom på nytt justering og tekstnormalisering. Dette gjer ikkje konsistent forståking over kodar og språk. På grunn av tilnærmingane til additive effektar, kombinasjonen deres reduserer mellomrommet på krysspråk med 8,9 punkt (m-BERT) og 18,2 punkt (XLM-R) gjennomsnittlig på alle oppgåver og språk.', 'ro': 'Reprezentările translingvistice au potențialul de a pune tehnicile PNL la dispoziția majorității limbilor din lume. Cu toate acestea, acestea necesită în prezent corpuri mari de pre-formare sau acces la limbi tipologic similare. În această lucrare, abordăm aceste obstacole prin eliminarea semnalelor de identitate lingvistică din încorporările multilingve. Examinăm trei abordări pentru acest lucru: (i) re-alinierea spațiilor vectoriale ale limbilor țintă (toate împreună) la o limbă sursă pivot; (ii) eliminarea mijloacelor și variațiilor specifice limbii, ceea ce duce la o mai bună discriminare a încorporărilor ca produs secundar; și (iii) creșterea similitudinii intrărilor între limbi prin eliminarea contracțiilor morfologice și reordonarea propozițiilor. Evaluăm pe XNLI și evaluarea MT fără referință în 19 limbi tipologice diverse. Rezultatele noastre expun limitările acestor abordări - spre deosebire de normalizarea vectorială, re-alinierea spațiului vectorial și normalizarea textului nu obțin câștiguri consistente în encodere și limbi. Datorită efectelor aditive ale abordărilor, combinația acestora reduce însă decalajul translingvistic cu 8,9 puncte (m-BERT) și 18,2 puncte (XLM-R) în medie pentru toate sarcinile și limbile.', 'si': 'විශාල භාෂාත්මක ප්\u200dරතිනිධානය කරන්න පුළුවන් NLP තාක්ෂණය ලෝකයේ විශාල භාෂාත්මක භාෂාවට ප්\u200dර නමුත්, ඔවුන් දැන් ලොකු ප්\u200dරීට්\u200dරේන්ස් කොර්පෝරාව අවශ්\u200dය වෙනවා නැත්නම් වර්ණ භාෂාවික ව මේ වැඩේ අපි මේ ප්\u200dරතික්\u200dරියාවට ප්\u200dරතික්\u200dරියා කරන්නේ භාෂාව අනතුරු සංඥාවක් ගොඩක් භාෂාවික සංඥ අපි මේකට ප්\u200dරවේශනය තුනක් පරීක්ෂා කරනවා: i) ලක්ෂණ භාෂාව (හැම දෙයක්ම එකට) පිවෝට් මුළු භාෂාවට වෙක්ටර් ක්\u200dෂ (i) භාෂාව විශේෂ අවශ්\u200dය සහ වෙනස් අතිරික්ෂා කරනවා, ඒකෙන් හොඳ විශේෂ විශේෂතාවක් පිළිබඳ විශේෂ ඒ වගේම (Ii) භාෂාවල් වලින් ඇතුළු සමාන්\u200dයතාවක් වැඩ කරනවා මොර්ෆෝලෝජික සමාන්\u200dයතාවක් සහ වාක අපි XNLI විශ්වාස කරනවා සහ විශ්වාසික විවිධ භාෂාවක් 19 වලින් ප්\u200dරතිශ්වාසිකව MT විශ්වාස කරනව අපේ හොයාගන්න සීමාව ප්\u200dරකාශ කරනවා මේ වෙක්ටර් සාමාන්\u200dය වෙනුවෙන් වෙක්ටර් සාමාන්\u200dය වෙනුවෙන්, වෙක්ටර් අවසාන සහ පාළු සාමාන්\u200dය ව ඒ වගේම අනිවාර්යෙන්ගේ අනිවාර්ය ප්\u200dරභාවන් නිසා, ඔවුන්ගේ සම්බන්ධය 8.9 පින්තුවන් (m-BERT) සහ 18.2 පින්තුවන් (XLM-R) සාමාන්\u200dය වැඩේ හා භා', 'sr': 'Prejezičke predstave imaju potencijal da se NLP tehnike dostupne većini jezika na svijetu. Međutim, trenutno zahtevaju veliku predivnu korporaciju ili pristup tipološki sličnim jezicima. U ovom poslu, rješavamo te prepreke uklanjanjem signala jezika identiteta iz višejezičkih integracija. Ispitujemo tri pristupa za ovo: i) ponovo usklađivanje vektorskih prostora ciljnih jezika (sve zajedno) na jezik izvora pivot a; ii) uklanjanje sredstava i varijacija jezika, koje daje bolju diskriminaciju ugrađenja kao proizvod; i iii) povećanje sličnosti ulaza na jezike uklanjanjem morfoloških kontrakcija i reorderinga rečenica. Procjenjujemo XNLI i procjenu MT bez referencije na 19 tipološki različitih jezika. Naši nalazi otkrivaju ograničenja tih pristupa, različitih normalizacije vektora, ponovno usklađivanje vektora i normalizacija teksta, ne postižu konsekventne dobitke preko kodera i jezika. Zbog dodatnih efekta pristupa, njihova kombinacija smanjuje razinu preko jezika za 8,9 bodova (m-BERT) i 18,2 bodova (XLM-R) u prosjeku u svim zadacima i jezicima.', 'so': "Dhaqaalaha luuqadaha iskuulka ah waxay leeyihiin suurtagal in ay sameeyaan qalabka NLP oo ay u helaan luuqadaha badan oo aduunka. Si kastaba ha ahaatee waxay haatan u baahan yihiin shirkad badan oo soo daayay ama u isticmaalaya luqado u eg. Shuqulkaas ayaannu ka sheekeysanaynaa qalabkan si aan uga qaadno sawirada aqoonsiga luuqada oo kala duduwan. Waxan ku baaraynaa saddex qaab oo ay u timaadaan: (i) meelaha wadista ah oo luqadaha la jiiday (dhammaantood) oo lagu beddelayo luqada pivot; dhaqaajinta midhaha cayiman iyo isbedelashada luuqada, taas oo ka soo bixinaya takoorida ka wanaagsan dhaqaalaha midhaha; iyo si isku mid ah oo ku kordhiya luuqadaha oo dhan, marka la qaado heshiiska muuqashada iyo hagitaanka xukunka. Waxaannu qiimeynaynaa XNLI iyo qiimeynta MT lacag la’aan ah oo ku qoran 19 luuqado kala duduwan. Faahritaankeenu waxay muujiyaan xadhigyada qaababkan oo aan la mid ahayn wadooyinka, isbedelinta goobta wadooyinka iyo isbedelinta qoraalka, ma gaadhaan faa'iido la mid ah oo ku qoran qoraalka iyo luuqadaha. Si kastaba ha ahaatee, saameyn dheeraad ah oo ay leedahay sababtoo ah, iskutallaabtoodu wuxuu ku hoosaysiiyaa wareejinta luqada oo dhan 8.9 points (m-BERT) iyo 18.2 points (XLM-R) oo dhan shaqooyinka iyo luuqadaha oo dhan.", 'sv': 'Tvärspråkiga representationer har potential att göra NLP-tekniker tillgängliga för de allra flesta språk i världen. De kräver dock för närvarande stora förkortningskorpora eller tillgång till typologiskt liknande språk. I detta arbete tar vi itu med dessa hinder genom att ta bort språkidentitetssignaler från flerspråkiga inbäddningar. Vi undersöker tre tillvägagångssätt för detta: (i) omriktning av vektorrymderna för målspråk (alla tillsammans) till ett pivot källspråk; ii) undanröja språkspecifika medel och variationer, vilket ger bättre diskriminering av inbäddningar som biprodukt. och (iii) öka indatalikheten mellan språk genom att avlägsna morfologiska sammandragningar och ordningsfördelning av meningar. Vi utvärderar på XNLI och referensfri MT utvärdering över 19 typologiskt olika språk. Våra resultat avslöjar begränsningarna för dessa metoder – till skillnad från vektornormalisering, omriktning av vektorrymd och textnormalisering uppnår inte konsekventa vinster mellan kodare och språk. På grund av tillvägagångssättens additiva effekter minskar deras kombination skillnaderna mellan språköverföring med 8,9 poäng (m-BERT) och 18,2 poäng (XLM-R) i genomsnitt för alla uppgifter och språk.', 'ta': 'கிராஸ்- மொழி பிரதிநிதிகள் உலகின் பெரும்பாலான மொழிகளுக்கு NLP தொழில்நுட்பங்கள் கிடைக்கும். ஆனால், தற்போது அவர்கள் நிறுவனத்திற்கு பெரிய முன்னோட்டம் வேண்டும் அல்லது வழக்கமாக ஒத்த மொழிகளை அணுகும இந்த வேலையில், நாம் இந்த தடைகளை மொழியின் அடையாளத்தை நீக்கி பல மொழிகளில் இருந்து குறியீடுகளை நீக்கும் மூலம்  நாம் இந்த மூன்று வழிகளை பரிசோதிக்கிறோம்: (i) இலக்கு மொழிகளின் வெக்டார் இடைவெளியை மீண்டும் ஒத்திசைக்கிறது (அனைத்தும (ii) மொழி- குறிப்பிட்ட மாறுபாடுகள் மற்றும் மாறுபாடுகளை நீக்கி, அது ஒரு பொருளால் உள்ளிடும் வித்தியாசமான வேறுபாட (iii) மொழிகளில் உள்ளீட்டு ஒத்திசையை அதிகரித்து மருத்துவகையான தொடர்புகளை நீக்கி விட்டது மற்றும் வாக்கியத்தை  நாம் XNLI மற்றும் குறிப்பு இலவச MT மதிப்பினை 19 வழக்கமான வித்தியாசமான மொழிகளில் மதிப்பிடுகிறோம். எங்கள் கண்டுபிடிப்புகள் இந்த முன்னேற்றங்களின் எல்லைகளை வெக்டார் சாதாரண செய்யும், வெக்டர் இடைவெளி மீண்டும் ஒழுங்குபடுத்தல் மற்றும் உரை  அடுக்குகளின் கூடுதல் விளைவுகள் காரணமாக, இவ்விருவருடைய இணைப்பு 8. 9 புள்ளிகள் (m- BERT) மற்றும் 18. 2 புள்ளிகள் (XLM- R) எல்லா பணிகளும் மொழிகளும் சராசரியாக க குறைக', 'mn': 'Дэлхийн ихэнх хэл дээр NLP технологийг ашиглах боломжтой байдаг. Гэвч одоогийн үед тэд маш их хөгжлийн корпора эсвэл типтологийн төстэй хэл рүү хүртэл хэрэгтэй. Энэ ажлын тулд бид хэл мэдээллийг олон хэлний нэвтрүүлэлтийн сигналуудыг устгаж эдгээр саад чаддаг. Бид үүний тулд гурван арга барилгыг шалгаж байна: i) зориулагдсан хэлний векторын орон зайг (бүгд нэгдэж) pivot эх үүсвэрийн хэл рүү дахин шулуун болгож байна. ii) хэлний тодорхойлолтой арга болон өөрчлөлтийг устгах нь илүү сайхан бүтээгдэхүүний хувьд нэмэгдүүлэлт гаргадаг. (iii) хэл дээр орж ирсэн төстэй тэнцүү байдлыг нэмэгдүүлж морфологик халдвар болон өгүүлбэрийг дахин эргүүлэхээр хасаж байна. Бид XNLI болон санал тавьсангүй MT үнэлгээ 19 хэл дээр үнэлдэг. Бидний ололтууд энэхүү ойлголтын хязгаарлалтыг тодорхойлж, вектор орон зай дахин тодорхойлж, мөн текст нормализацийн хязгаарлалтыг хэлж чадахгүй. Харин ойлголтын нэмэлт эффектүүдийн тулд тэдний холбогдол нь хэл болон хэл дээр дунджаар бүх үйл ажиллагаа болон дунджаар 8.9 цэг (m-BERT) болон 18.2 цэг (XLM-R) хуваагдаж байна.', 'ur': 'کروس زبان کی تعلیمات میں NLP ٹیکنالوں کو دنیا کی اکثریت زبانوں کے لئے موجود بنانے کے قابل ہے. لیکن ان کے لئے اکثر بہت زیادہ پرٹرینڈ کورپورا یا تایپولوژیکی جیسی زبانوں کی دسترسی ضرورت ہے. اس کام میں ہم ان روکنوں کو مزید زبان کی شناسی سیگنالوں سے ہٹا دیتے ہیں۔ ہم اس کے لئے تین طریقے کی تحقیق کرتے ہیں: (ii) زبان کے مطابق مختلف وسائل اور متفاوت کو ہٹا دیتے ہیں، جسے اچھی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طر اور (iii) زبانوں میں داخل کی مثالی زیادہ زیادہ کرتا ہے کہ مورفولوژیکی کنٹرونٹیوں اور جماعت دوبارہ اٹھانے کے ذریعے۔ ہم XNLI اور رابطہ بغیر منفی MT ارزیابی پر 19 تایپولوژیک طرح طرح طرح طرح کی زبانوں میں ارزیابی کرتے ہیں. ہمارے نتیجے ان کے تقریبا کی حدود ظاہر کرتے ہیں -ویکتور نارومیزی جیسی، ویکتور فضا دوبارہ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ الٹ ال تقریبا کے اضافی اثرات کے سبب ان کی ترکیب کی مختلف زبان کی ترکیب فاصلہ 8.9 پوینٹ (m-BERT) اور 18.2 پوینٹ (XLM-R) کے متوسط تمام کاموں اور زبانوں میں کمی کرتی ہے۔', 'uz': "Kors tillar taʼminlovchilari dunyodagi ko'pchilik tillarda NLP teknikalarni qo'shish mumkin. Lekin hozirda, ularning ko'pchilik kompaniya yoki o'xshash tilga murojaat qilish kerak. Bu ishda, biz bu usullarni bir necha tildan foydalanuvchi shaxsiyatlarni olib tashlashimiz mumkin. We examine three approaches for this: (i) re-aligning the vector spaces of target languages (all together) to a pivot source language;  (ii) Tilni koʻrsatilgan usulni olib tashlash va varianlarni o'zgartirish, bu narsalar sifatida ajratishni bajaradi; (iii) o'z tilda o'xshash natijalarni o'zgartirish orqali o'zgartirish va bir so'zni qayta order qilish orqali o'zgartirish mumkin. Biz XNLI haqida qiymatmiz va 19 oddiy har xil tillardan MT qiymatlarini o'qiymatimiz. Bizning murojaatlarimiz bu murakkablarni o'xshash vektor normalisiyatlarining chegaralarini ko'rsatadi, vector фазsidan qayta oʻzgarishni va matn normalisiyatsizligini bir necha kodlash va tillar yordamida yetarli muvaffaqiyatlarni amalga oshirib boʻlmaydi. Ularning qoʻshimcha effektlari sababi, ularning bir necha tillar tarkibini 8.9 point (m-BERT) va 18.2 point (XLM-R) har bir vazifalar va tillar bilan bir qismini kamaytadi.", 'vi': 'Các biểu hiện xuyên ngôn ngữ có khả năng làm cho độc lập lập lập độc quyền được phát triển với hầu hết các ngôn ngữ trên thế giới. Tuy nhiên, hiện tại, họ cần có cơ quan hạ đẳng lớn hay quyền truy cập vào các ngôn ngữ khác nhau. Trong công việc này, chúng ta giải quyết những cản trở này bằng cách xóa dấu hiệu nhận dạng ngôn ngữ từ sự tác giả đa dạng. Chúng tôi kiểm tra ba phương phán cho việc này: i) giải chỉnh chính độ của ngôn ngữ mục tiêu (tất cả là một ngôn ngữ pivot; Sự thay đổi ngôn ngữ sẽ làm giảm khả năng phân biệt của sự nhúng vào như một sản phẩm phụ và (III) làm tăng nét giống nhau trong các ngôn ngữ bằng cách loại bỏ các co thắt lịch sự và câu sắp đặt. Chúng tôi đánh giá cao ngôn ngữ MTV và hoàn toàn không liên quan tới Bước Bước Bước Bước Bước... Những kết quả của chúng ta vạch trần giới hạn của những phương pháp này- không giống như sự bình thường vector, sự định vị vũ trụ và tổng hợp văn bản không đạt được lợi nhuận liên quan giữa mã hóa và ngôn ngữ. Do tác dụng phụ của các phương pháp, sự kết hợp của chúng sẽ giảm khoảng cách truyền học qua ngôn ngữ bằng 8.9 (m-BERT) và 18.2 điểm (XLM-R) trên trung bình trong tất cả các công việc và ngôn ngữ.', 'nl': 'Meertalige representaties hebben het potentieel om NLP-technieken beschikbaar te maken voor de overgrote meerderheid van de talen in de wereld. Momenteel vereisen ze echter grote pretraining corpora of toegang tot typologisch vergelijkbare talen. In dit werk pakken we deze obstakels aan door taalidentiteitssignalen uit meertalige embeddings te verwijderen. We onderzoeken hiervoor drie benaderingen: (i) het opnieuw uitlijnen van de vectorruimten van doeltalen (allemaal samen) op een pivot brontaal; (ii) het verwijderen van taalspecifieke middelen en afwijkingen, wat resulteert in een betere discriminatie van embeddings als bijproduct; en iii) toename van de gelijkenis tussen de invoer tussen talen door morfologische samentrekkingen en zinsherschikking te verwijderen. We evalueren op XNLI en referentievrije MT evaluatie in 19 typologisch diverse talen. Onze bevindingen onthullen de beperkingen van deze benaderingen – in tegenstelling tot vectornormalisatie bereiken vectorruimteaanpassingen en tekstnormalisatie geen consistente winsten tussen encoders en talen. Door de additieve effecten van de benaderingen vermindert hun combinatie de transferkloof tussen talen en taken gemiddeld met 8,9 punten (m-BERT) en 18.2 punten (XLM-R).', 'hr': 'Prejezički predstavnici imaju potencijal učiniti tehnike NLP dostupnim za većinu jezika na svijetu. Međutim, trenutno zahtijevaju veliku pretkišnu tijelu ili pristup tipološki sličnim jezicima. U ovom poslu rješavamo te prepreke uklanjanjem signala jezika identiteta iz višejezičkih integracija. Ispitujemo tri pristupa za to: i) ponovno usklađivanje vektorskih prostora ciljnih jezika (sve zajedno) na jezik izvora pivot a; ii) uklanjanje sredstava i varijacija za jezik, koje pružaju bolju diskriminaciju ugrađenja kao proizvod; i iii) povećanje sličnosti ulaza na jezike uklanjanjem morfoloških kontrakcija i reorderinga rečenica. Procjenjujemo XNLI i procjenu MT-a bez referencije na 19 tipološki različitih jezika. Naši nalazi otkrivaju ograničenje tih pristupa, različitih normalizacije vektora, ponovno usklađivanje vektora i normalizacija teksta, ne postižu konsekventne dobiće preko kodera i jezika. Zbog dodatnih učinka pristupa, njihova kombinacija smanjuje razinu preko jezika na 8,9 bodova (m-BERT) i 18,2 bodova (XLM-R) u prosjeku u svim zadacima i jezicima.', 'da': 'Tværsprogede repræsentationer har potentiale til at gøre NLP-teknikker tilgængelige for langt de fleste sprog i verden. Men de kræver i øjeblikket store forudgående corpora eller adgang til typologisk lignende sprog. I dette arbejde tackler vi disse forhindringer ved at fjerne sprogidentitetssignaler fra flersprogede indlejringer. Vi undersøger tre tilgange til dette: (i) re-justere vektorrummet i målsprog (alle sammen) til et pivot kildesprog; ii) fjernelse af sprogspecifikke midler og afvigelser, hvilket giver bedre forskelsbehandling af indlejringer som biprodukt og iii) øge input lighed på tværs af sprog ved at fjerne morfologiske sammentrækninger og sætningsretning. Vi evaluerer på XNLI og referencefri MT evaluering på tværs af 19 typologisk forskellige sprog. Vores resultater afslører begrænsningerne af disse tilgange – i modsætning til vektornormalisering, vektorrum re-justering og tekst normalisering opnår ikke konsekvente gevinster på tværs af kodere og sprog. På grund af tilgangenes additive virkninger reducerer kombinationen af dem imidlertid den tværsprogede overførselsafstand med 8,9 point (m-BERT) og 18,2 point (XLM-R) i gennemsnit på tværs af alle opgaver og sprog.', 'bg': 'Междуезичните представяния имат потенциала да направят техниките на НЛП достъпни за по-голямата част от езиците по света. Понастоящем обаче те изискват големи корпуси за предварително обучение или достъп до типологично подобни езици. В тази работа се справяме с тези пречки чрез премахване на сигналите за идентичност на езика от многоезични вграждания. Разглеждаме три подхода за това: (и) пренасочване на векторните пространства на целевите езици (всички заедно) към основен изходен език; премахване на специфичните за езика средства и отклонения, което дава по-добра дискриминация на вгражданията като страничен продукт; и iii) увеличаване на сходството на входящите данни между езиците чрез премахване на морфологичните контракции и пренареждането на изреченията. Ние оценяваме по ХНЛИ и без референции МТ оценка на 19 типологично различни езика. Нашите открития разкриват ограниченията на тези подходи – за разлика от нормализирането на векторите, пренастройването на векторното пространство и нормализирането на текста не постигат последователни печалби в кодерите и езиците. Поради допълнителните ефекти на подходите, комбинацията им намалява междуезичния трансфер средно с 8,9 точки (м-BERT) и 18,2 точки (XLM-R) при всички задачи и езици.', 'de': 'Mehrsprachige Repräsentationen haben das Potenzial, NLP-Techniken für die überwiegende Mehrheit der Sprachen der Welt verfügbar zu machen. Allerdings benötigen sie derzeit große Pretraining-Korpora oder Zugriff auf typologisch ähnliche Sprachen. In dieser Arbeit adressieren wir diese Hindernisse, indem wir Sprachidentitätssignale aus mehrsprachigen Einbettungen entfernen. Dazu untersuchen wir drei Ansätze: (i) Neuausrichtung der Vektorräume von Zielsprachen (alle zusammen) auf eine Pivot-Quellsprache; ii) die Beseitigung sprachspezifischer Mittel und Abweichungen, was zu einer besseren Diskriminierung von Einbettungen als Nebenprodukt führt; und (iii) Erhöhung der Input-Ähnlichkeit zwischen den Sprachen durch Beseitigung morphologischer Kontraktionen und Satzunordnungen. Wir evaluieren auf XNLI- und referenzfreier MT-Auswertung in 19-typologisch unterschiedlichen Sprachen. Unsere Ergebnisse zeigen die Grenzen dieser Ansätze auf – im Gegensatz zur Vektornormalisierung erzielen Vektorraum-Neuausrichtung und Textnormalisierung keine konsistenten Gewinne zwischen Encodern und Sprachen. Aufgrund der additiven Effekte der Ansätze verringert ihre Kombination die translinguale Transferlücke um 8,9 Punkte (m-BERT) und 18,2 Punkte (XLM-R) im Durchschnitt über alle Aufgaben und Sprachen hinweg.', 'ko': '다중 언어 표현은 세계 대부분의 언어에 NLP 기술을 적용할 수 있습니다.그러나 이들은 현재 훈련 전 자료 라이브러리나 비슷한 유형의 언어를 방문해야 한다.이 작업에서, 우리는 다중 언어 삽입에서 언어 신분 신호를 제거함으로써 이러한 장애를 해결한다.이를 위해 우리는 세 가지 방법을 연구했다. (i) 목표 언어의 벡터 공간(전부)을 추축원 언어에 다시 맞추는 것이다.(ii) 특정 언어의 평균치와 차이를 없애고 삽입이 부산물로서의 구분성을 높인다.(iii) 문법의 수축과 문장의 순서를 없애고 언어 간의 입력 유사도를 증가시킨다.우리는 19가지 유형의 다양한 언어의 XNLI와 무참고 기계 번역 평가를 평가했다.우리의 발견은 이러한 방법의 한계성을 보여 주었다. 벡터 규범화와 달리 벡터 공간을 다시 맞추고 텍스트를 규범화하는 것은 인코더와 언어에서 일치된 이익을 실현할 수 없다.그러나 이러한 방법의 가성 효과 때문에 그들의 조합은 모든 임무와 언어에서 평균 8.9점(m-BERT)과 18.2점(XLM-R) 감소했다.', 'sw': 'Wawakilishi wa lugha za Cross wana uwezekano wa kufanya mbinu za NLP zinazopatikana kwa lugha nyingi duniani. However, they currently require large pretraining corpora or access to typologically similar languages.  Katika kazi hii, tunazungumzia vikwazo hivi kwa kuondoa alama za utambulisho wa lugha kutoka kwenye viungo vya lugha mbalimbali. Tunajaribu mbinu tatu kwa ajili ya hili: (i) kupata upya upya nafasi za vector za lugha za malengo (wote) kwa lugha ya pivot; (ii) removing language-specific means and variances, which yields better discriminativeness of embeddings as a by-product;  na (iii) kuongeza input sawa katika lugha mbalimbali kwa kuondoa makubaliano ya kifolojia na amri ya kifungo. Tutathmini kwenye utafiti wa XNLI na utafiti wa MT huru wa maoni katika lugha 19 mbalimbali. Matokeo yetu yanaonyesha vizuizi vya mbinu hizi tofauti na utaratibu wa vector, jukumu la upya wa barabara na utaratibu wa maandishi haufanikiwa kupata mafanikio kamili katika lugha na lugha. Kutokana na athari za ziada za mbio hizo, muunganiko wao hupunguza kiwango cha usafirishaji wa lugha kwa pointi 8.9 (m-BERT) na pointi 18.2 (XLM-R) kwa wastani katika kazi zote na lugha zote, hata hivyo.', 'af': "Kruistale voorstellings het die potensiele om NLP-teknike beskikbaar te maak vir die groot meeste tale in die wêreld. Maar hulle nodig huidiglik groot pretraining corpora of toegang tot tipologies gelyke tale. In hierdie werk, ons adres hierdie hinders deur die verwyder van taal identiteitssinjaale van multilingse inbêding. Ons ondersoek drie toegang vir hierdie: i) herlyn die vektorspasies van doelgemaak (almal saam) na 'n pivot bron taal; (ii) die verwyder van taal-spesifieke betekenis en variasies wat beter diskriminasie van inbêdings as 'n by-produkt gee; en (iii) verhoog toevoer gelykenis oor tale deur morfologiese kontraksies en sentence reordering te verwyder. Ons evalueer op XNLI en verwysing-vry MT evaluering oor 19 tipologies verskillende tale. Ons gevinde verduidelik die beperkinge van hierdie toegangs - ongelukkige vektornormalisering, vektorruimte herlyn en teks normalisering doen nie konsistente verkrywings oor koders en tale bereik nie. Dus die toegang se additive effekte, verklein hulle kombinasie die kruistale oordragspans deur 8.9 punte (m-BERT) en 18.2 punte (XLM-R) op gemiddelde oor alle taak en tale.", 'tr': 'Çaprly diller NLP tehnikalaryny dünýäde köp dillere ulaşabilmek mümkinçiligi bar. Ýöne häzirki wagtlar uly öňünde ýakyn ýakyn ýakyn dillere gollaşmak gerek. Bu işde, biz bu engelleri çoxli dil işaretlerinden çykaryp çykaryp barýarys. Biz bunun üçin üç gollanmasyny barýarys: i) maksadyň ýerlerini pivot çeşme diline ýene çykarýarys. (ii) Diller takykly hasaplanjak we üýtgeşmeleri çykarýar, hem içine gatnaşmalaryň gowy diskriminçylygyny bir produkt ýaly täsir edýär; we iii) morfolojik sözleri we sözleriň täzeliklerini çykaryp dillerden daşyklaşýar. Biz XNLI we suçsuz MT çykyşyny 19 tikalojik dillerinde deňleýäris Çalıştırmalarımız bu yaklaştırmaların sınırlarını vektör normalizasyona benzemez, vektör uzay yeniden dizilimlendirmesi ve metin normalizasyona göre hiç bir sürekli kodeçiler ve diller arasında gazanmaz. Yaklaştıkların toplam etkileri yüzünden, olaryň birleşmeleri tüm görevler ve diller arasında ortalama noktaları 8.9 noktalara (m-BERT) ve 18.2 noktalara (XLM-R) düşürür.', 'fa': 'نمایش\u200cدهندگان زبان\u200cهای متوسط توانایی دارند که تکنیک\u200cهای NLP را برای بیشتر زبان\u200cهای جهان فراهم کنند. ولی در حال حاضر به زبان\u200cهای مشابه\u200cی تایپولوژیکی نیاز دارند. در این کار، ما با حذف سیگنال شناسایی زبان از جمع کردن زبان\u200cهای زیادی این مانع\u200cها را حل می\u200cکنیم. ما سه دسترسی برای این را تحقیق می\u200cکنیم: (i) فضای ویکتوری از زبانهای هدف (همگی) به زبان منبع pivot دوباره تنظیم می\u200cکنیم. (ii) حذف کردن وسیله\u200cهای ویژه\u200cای و تفاوت\u200cهای زبانی که به عنوان یک محصول به عنوان یک محصول تقسیم بهتر می\u200cکند; و (iii) افزایش شبیه ورودی در زبان\u200cها با حذف کنترل\u200cهای مورفولوژیکی و تغییر دادن جمله\u200cها. ما در ارزش XNLI و ارزش MT بی ارزش را در ۱۹ زبان گونه\u200cشناسی ارزش می\u200cدهیم. نتیجه\u200cهای ما محدودیت\u200cهای این دسترسی\u200cها را نشان می\u200cدهند، غیر مانند نورمینل\u200cسازی ویکتور، دوباره\u200cسازی فضای ویکتور و نورمینل\u200cسازی متن به پیروزی هماهنگی در کودرها و زبانها نمی\u200cرسند. به دلیل اثرات اضافه\u200cای از نزدیک\u200cها، ترکیبش آنها فاصله انتقال متوسط زبان را با 8.9 نقطه (m-BERT) و 18.2 نقطه (XLM-R) در متوسط در تمام وظیفه\u200cها و زبانها کاهش می\u200cدهد.', 'am': 'Cross-lingual representations have the potential to make NLP techniques available to the vast majority of languages in the world.  ነገር ግን አሁን ብዙ የኮርፖርት ማፍሰስ ወይም በተለያዩ ቋንቋዎች ለመግባት ያስፈልጋል፡፡ በዚህ ሥራ፣ እነዚህን ግንኙነቶች ቋንቋዎች የቋንቋ identification signaሎችን ከብዙ ቋንቋ አካባቢዎች በማውጣት እናስረዳለን፡፡ ስለዚህ ሦስት ደረጃዎችን እንሞክራለን:: የቋንቋ-ቋንቋ-የተለየ ሀብት እና ልዩነትን ለማስወግድ፣ የፍጥረት ውጤት በሀብት እንደሚያሳየው ትክክል ነው፡፡ (iii) እና በቋንቋዎች ላይ የሚተካከለውን ጥያቄ እና የሞፎሎጂ ግንኙነት እና የፍርድ ግንኙነት በማስወግድ ሲያሳድጋል፡፡ በ19ኛ በተለያዩ ቋንቋዎች ላይ የXNLI እና የግል ነጻ MT ማስታወቂያውን እናዋርዳለን፡፡ Our findings expose the limitations of these approaches-unlike vector normalization, vector space re-alignment and text normalization do not achieve consistent gains across encoders and languages.  ከግንኙነት አካባቢ ጥያቄዎች ምክንያት የቋንቋ ቋንቋ መተላለፊያውን 8.9 points (m-BERT) እና 18.2 points (XLM-R) በመተካከለኛ ስራ እና ቋንቋዎች ሁሉ ያጎድላል፡፡', 'id': 'Perwakilan saling bahasa memiliki potensi untuk membuat teknik NLP tersedia untuk kebanyakan bahasa di dunia. Namun, saat ini mereka membutuhkan corpora yang besar atau akses ke bahasa tipologi yang sama. In this work, we address these obstacles by removing language identity signals from multilingual embeddings.  Kami memeriksa tiga pendekatan untuk ini: (i) menyesuaikan kembali ruang vektor dari bahasa sasaran (semua bersama-sama) ke bahasa sumber pivot; (ii) menghapuskan cara dan variasi yang spesifik bahasa, yang menyebabkan diskriminasi yang lebih baik bagi penyampilan sebagai produk samping; dan (iii) meningkatkan kesamaan masukan di dalam bahasa dengan menghapus kontraksi morfologi dan mengubah kalimat. We evaluate on XNLI and reference-free MT evaluation across 19 typologically diverse languages.  Penemuan kami mengekspos batasan pendekatan ini-tidak seperti normalisasi vektor, penyesuaian ruang vektor dan normalisasi teks tidak mencapai keuntungan konsisten di antara pengekode dan bahasa. Karena efek aditif pendekatan, kombinasi mereka menurunkan ruang transfer saling bahasa dengan 8,9 poin (m-BERT) dan 18,2 poin (XLM-R) pada rata-rata di seluruh tugas dan bahasa, bagaimanapun.', 'bn': 'ক্রস-ভাষার প্রতিনিধিত্ব আছে বিশ্বের বেশীরভাগ ভাষায় এনএলপি প্রযুক্তি প্রদান করতে। However, they currently require large pretraining corpora or access to typologically similar languages.  এই কাজে আমরা ভাষার পরিচয় সরিয়ে ফেলার মাধ্যমে এই ধরনের বাধা দিচ্ছি। আমরা এই বিষয়টির জন্য তিনটি পদক্ষেপ পরীক্ষা করি: (i) টার্গেট ভাষার ভেক্টর স্থান (সবাই) পিভোট সোর্স ভাষায় পুনরায় সংযোগ করা হচ (ii) ভাষার নির্দিষ্ট মান এবং পার্থক্য সরিয়ে নেয়, যার ফলে প্রযুক্তি হিসেবে বৈষম্যের সৃষ্টি করে; এবং মোরফোলিক্যাল চুক্তি এবং শাস্তি পুনরায় নির্দেশ দেয়ার মাধ্যমে সারা ভাষায় ইনপুট বাড়তে থাকে। We evaluate on XNLI and reference-free MT evaluation across 19 typologically diverse languages.  আমাদের খুঁজে পাওয়া যাচ্ছে যে এই প্রতিক্রিয়ার সীমাবদ্ধ ভেক্টর স্বাভাবিক, ভেক্টরের স্পেস পুনঃস্বাভাবিক এবং লেখা স্বাভাবিকভাবে স কিন্তু তাদের ক্ষেত্রে অতিরিক্ত প্রভাবের কারণে তাদের সংযোগ ৮. ৯ পয়েন্ট (m-BERT) এবং ১৮.', 'sq': 'Përfaqësuesit ndërgjuhësore kanë potencialin për të bërë teknikat NLP të disponueshme për shumicën e madhe të gjuhëve në botë. Megjithatë, ato aktualisht kërkojnë korpra të mëdha paratrajnuese apo akses në gjuhë tipologjike të ngjashme. In this work, we address these obstacles by removing language identity signals from multilingual embeddings.  Ne shqyrtojmë tre metoda për këtë: (i) rishikimin e hapësirave vektore të gjuhëve objektive (të gjitha së bashku) në një gjuhë burimi pivot; (ii) heqja e mjeteve dhe varianteve specifike gjuhës, që sjell diskriminim më të mirë të përfshirjeve si një subprodukt; dhe (iii) rritja e ngjashmërisë së input nëpër gjuhë duke hequr kontraksionet morfologjike dhe rregullimin e fjalëve. Ne vlerësojmë në XNLI dhe vlerësimin e MT pa referencë në 19 gjuhë tipologjike të ndryshme. Zbulimet tona ekspozojnë kufizimet e këtyre qasjeve në ndryshim nga normalizimi i vektorëve, ristruktimi i hapësirës së vektorëve dhe normalizimi i tekstit nuk arrijnë fitime konsistente nëpërmjet koduesve dhe gjuhëve. Për shkak të efekteve shtesë të qasjeve, kombinimi i tyre zvogëlon dallimin e transferit ndërgjuhësor me 8.9 pikë (m-BERT) dhe 18.2 pikë (XLM-R) mesatarisht në të gjitha detyrat dhe gjuhët, megjithatë.', 'hy': 'Խոսքերի միջև ներկայացումներն ունեն պոտենցիալ, որպեսզի ՆԼՊ-ի տեխնիկաները հասանելի դարձնեն աշխարհի լեզուների մեծ մասի համար: Այնուամենայնիվ, նրանք ներկայումս պահանջում են մեծ նախադասական մարմնի կամ տիպոլոգիապես նման լեզուների հասանելիության: Այս աշխատանքի ընթացքում մենք լուծում ենք այս խոչընդոտները՝ վերացնելով լեզվի ինքնության ազդանշանները բազլեզու ներդրումներից: Մենք ուսումնասիրում ենք սրա համար երեք մոտեցումներ. i) վերադառնում ենք նպատակային լեզուների (բոլորը միասին) վեկտոր տարածքները պտտվող աղբյուր լեզվին: (II) վերացնել լեզվի մասնավոր միջոցները և տարբերակները, որոնք ավելի լավ տարբերակում են ներդրումները որպես կողմնակի ապրանք: և (երևի) լեզուների միջև ներմուծի նմանությունների աճը՝ վերացնելով մորֆոլոգիական հակադրումները և նախադասությունների վերադասավորումը: We evaluate on XNLI and reference-free MT evaluation across 19 typologically diverse languages.  Our findings expose the limitations of these approaches-unlike vector normalization, vector space re-alignment and text normalization do not achieve consistent gains across encoders and languages.  Հետևաբար մոտեցումների ավելացիվ ազդեցությունների շնորհիվ, նրանց համադրությունը կրճատում է լեզվի միջև փոխանցվող տարբերությունը 8.9 միավորով (m-BER) և 18.2 միավորով (XLM-R), այնուամենայնիվ, բոլոր աշխատանքներում և լեզուներում:', 'az': 'Dünyadakı çox dillərə NLP tekniklərini faydalandırmaq üçün çox dillərə sahib olar. Halbuki, onlar həmin vaxt böyük təmiz korpora və ya tipolojik kimi dillərə istifadə etmək istəyirlər. Bu işdə, dil kimlik sinyallərini çoxlu dil içərisindən silerek bu çətinləri çəkirik. Biz bu üçün üç tərəflər çəkirik: ii) dil müxtəlif vasitələrini və dəyişiklikləri silmək üçün daha yaxşı müxtəlif məhsul olaraq istifadə edir; (iii) Morfolojik sözlərin və cümlələrin yenidən düzəltməsini silib dillərin arasında giriş similiğini artırar. Biz XNLI və sıxıntısız MT değerlendirməsini 19 tipolojik müxtəlif dillərin arasında değerlendiririk. Bizim tapındıqlarımız bu yaxınlıqların sınırlarını göstərir, vektör kosmosu yenidən tərəfləndirir və metin normalizasyonu kodlayıcılar və dillər arasında müəyyən bir qənimətə nail olmaz. Yaxınlıqların əlavə etkisi üzündən, onların birləşdirilməsi hər işin və dillərin ortalamasında 8,9 pünkt (m-BERT) və 18,2 pünkt (XLM-R) ilə birləşdirildi.', 'cs': 'Mezijazyčné reprezentace mají potenciál zpřístupnit NLP techniky drtivé většině jazyků na světě. V současné době však vyžadují velké předškolení korpusů nebo přístup k typologicky podobným jazykům. V této práci řešíme tyto překážky odstraněním signálů jazykové identity z vícejazyčných vložení. Zkoumáme tři přístupy k tomu: (i) znovu zarovnání vektorových prostorů cílových jazyků (všechny dohromady) na pivotový zdrojový jazyk; ii) odstranění jazykově specifických prostředků a odchylek, což přináší lepší diskriminaci vložení jako vedlejšího produktu; a iii) zvýšení podobnosti vstupů mezi jazyky odstraněním morfologických kontrakcí a změnou uspořádání vět. Hodnotíme na XNLI a bezreferenční MT hodnocení v 19 typologicky různých jazycích. Naše zjištění odhalují omezení těchto přístupů – na rozdíl od vektorové normalizace, opětovné zarovnání vektorového prostoru a normalizace textu nedosahují konzistentních zisků mezi kodéry a jazyky. Vzhledem k aditivním účinkům těchto přístupů však jejich kombinace snižuje mezeru mezi jazyky v průměru o 8,9 body (m-BERT) a 18,2 body (XLM-R) ve všech úkolech a jazycích.', 'fi': 'Monikieliset esitykset voivat tarjota NLP-tekniikoita useimpien maailman kielten käyttöön. Ne vaativat kuitenkin tällä hetkellä suuria esikoulutuskorpusia tai pääsyä typologisesti samankaltaisiin kieliin. Tässä työssä puutumme näihin esteisiin poistamalla kielitunnistusmerkkejä monikielisistä upotuksista. Tutkimme kolmea lähestymistapaa: (i) kohdekielten vektoriavaruuksien uudelleenkohdistaminen (kaikki yhdessä) pivot-lähdekieleen; ii) poistetaan kielikohtaiset keinot ja poikkeamat, mikä parantaa upotusten erottelua sivutuotteena; ja (iii) lisäämällä syötteiden samankaltaisuutta eri kielillä poistamalla morfologisia supistuksia ja lauseiden uudelleenjärjestystä. Arvioimme XNLI- ja referenssivapaan MT-arvioinnin 19 typologisesti erilaisella kielellä. Löydöksemme paljastavat näiden lähestymistapojen rajoitukset – toisin kuin vektorin normalisointi, vektoriavaruuden uudelleenkohdistaminen ja tekstin normalisointi eivät saavuta johdonmukaisia hyötyjä koodereissa ja kielissä. Lähestymistapojen additiivisten vaikutusten vuoksi niiden yhdistelmä pienentää kielienvälistä siirtoeroa keskimäärin 8,9 pisteellä (m-BERT) ja 18,2 pisteellä (XLM-R) kaikissa tehtävissä ja kielissä.', 'et': 'Keeleülesed esindused võivad teha uue õppekava tehnikad kättesaadavaks enamikule maailma keeltele. Praegu nõuavad nad siiski suuri koolituseelseid korpuseid või juurdepääsu tüpoloogiliselt sarnastele keeltele. Käesolevas töös käsitleme neid takistusi, eemaldades keele identiteedi signaale mitmekeelsetest manustamistest. Selleks uurime kolme lähenemisviisi: i) sihtkeelte vektoriruumide (kõik kokku) ümbersuunamine pöördekeelega; ii) keelespetsiifiliste vahendite ja erinevuste kõrvaldamine, mis annab kaasatuste kui kõrvalsaaduse parema diskrimineerimise; ja iii) sisendite sarnasuse suurendamine keelte vahel, eemaldades morfoloogilised kokkutõmbed ja lausete ümberkorraldamine. Hindame XNLI ja viitevaba MT hindamist 19 tüpoloogiliselt mitmekesises keeles. Meie tulemused paljastavad nende lähenemisviiside piirangud – erinevalt vektori normaliseerimisest ei saavuta vektoriruumi ümberkorraldamine ja teksti normaliseerimine kodeerijate ja keelte vahel järjepidevat kasu. Tänu lähenemisviiside lisanduvale mõjule vähendab nende kombinatsioon keeleülekande lõhet keskmiselt 8,9 punkti võrra (m-BERT) ja 18,2 punkti võrra (XLM-R) kõigis ülesannetes ja keeltes.', 'bs': 'Prejezičke predstave imaju potencijal da se NLP tehnike dostupne većini jezika na svijetu. Međutim, trenutno zahtijevaju veliku predivnu korporaciju ili pristup tipološki sličnim jezicima. U ovom poslu rješavamo te prepreke uklanjanjem signala jezika identiteta iz višejezičkih integracija. Ispitujemo tri pristupa za ovo: i) ponovno usklađivanje vektorskih prostora ciljnih jezika (sve zajedno) na jezik izvora pivot a; ii) uklanjanje sredstava i varijacija jezika koje daje bolju diskriminaciju ugrađenja kao proizvod; i iii) povećanje sličnosti ulaza na jezike uklanjanjem morfoloških kontrakcija i reorderinga rečenica. Procjenjujemo XNLI i procjenu MT bez referencije na 19 tipološki različitih jezika. Naši nalazi otkrivaju ograničenje tih pristupa, različitih normalizacije vektora, ponovno usklađivanje vektora i normalizacija teksta, ne postižu konsekventne dobiće preko kodera i jezika. Zbog dodatnih učinka pristupa njihova kombinacija smanjuje razinu preko jezika za 8,9 bodova (m-BERT) i 18,2 bodova (XLM-R) u prosjeku u svim zadacima i jezicima.', 'ca': "Cross-lingual representations have the potential to make NLP techniques available to the vast majority of languages in the world.  Però actualment requereixen grans corpores de pré-formació o accés a llengües tipològicament similars. En aquesta feina, ens ocupem d'aquests obstacles eliminant els senyals d'identitat lingüística d'incorporacions multilingües. We examine three approaches for this: (i) re-aligning the vector spaces of target languages (all together) to a pivot source language;  (ii) removing language-specific means and variances, which yields better discriminativeness of embeddings as a by-product;  i iii) augmentant la similitud d'entrada entre les llengües eliminant les contraccions morfològiques i la reorganització de frases. Evaluarem la XNLI i la MT sense referència en 19 llengües tipològicament diverses. Our findings expose the limitations of these approaches-unlike vector normalization, vector space re-alignment and text normalization do not achieve consistent gains across encoders and languages.  Gràcies als efectes aditivs dels enfocaments, la seva combinació redueix la diferència de transfer ència translingüística en 8,9 punts (m-BERT) i 18,2 punts (XLM-R), en mitjana, en totes les tasques i llengües.", 'jv': 'Awakdhéwé-pisan langkang dipunangé iso nggawe teknik NLP kanggo meh bantuan kanggo langa ning dunya. politenessoffpolite, "), and when there is a change ("assertivepoliteness Nang barêng-barêng iki, kéné dadi kapan kanggo ngilanggar sampeyan urip kanggo ngilangno langkang sampeyan luwih basa. politenessoffpolite"), and when the re is a change ("assertivepoliteness (ii) nggolakno langkung-pernik lan cah-pernik, sing wis ngomong nik pakan-pernik sing luwih apik lan sampeyan sing luwih apik; 1 We assess on XNLI and reference-free MT assertion Global Tungkol nggawe efekat nambah nambah, kok piwong liyane mungkur karo perusahaan langkung penting nggawe 8.9 points (m-BERT) lan 18.2 points (XLM-R) supayano sakjane sedhaya ing sakjane gawan lan langsane.', 'sk': 'Medjezične predstavitve lahko omogočajo dostop do tehnik NLP veliki večini jezikov na svetu. Vendar pa trenutno potrebujejo velike predšolske korpuse ali dostop do tipološko podobnih jezikov. V tem delu obravnavamo te ovire z odstranjevanjem jezikovnih identitetnih signalov iz večjezičnih vdelav. Proučujemo tri pristope: (i) ponovno uskladitev vektorskih prostorov ciljnih jezikov (vsi skupaj) z vrtljivim izvornim jezikom; (ii) odstranitev jezikovno specifičnih sredstev in odstopanj, kar omogoča boljšo diskriminacijo vgradnje kot stranskega proizvoda; in (iii) povečanje podobnosti vnosov med jeziki z odpravo morfoloških krčenj in preurejanjem stavkov. Ocenjujemo na podlagi XNLI in brez referenc MT evalvacije v 19 tipološko različnih jezikih. Naše ugotovitve razkrivajo omejitve teh pristopov – za razliko od normalizacije vektorjev, preporavnava vektorskega prostora in normalizacija besedila ne dosežeta doslednih dobičkov med kodirniki in jeziki. Zaradi dodatnih učinkov pristopov pa njihova kombinacija zmanjšuje medjezično vrzel pri prenosu v povprečju za 8,9 točke (m-BERT) in 18,2 točke (XLM-R) pri vseh nalogah in jezikih.', 'ha': "Repositorin-linguin-na'asar yana da awon ya sami masu kamfata na NLP-kungiya zuwa masu yawa na lugha cikin dũniya. A lokacin da ake so, yanzu, suna da matsayi mai girma ga ruwan sama ko kuma sunã samun lugha masu daidaita. Daga wannan aikin, Munã tambayar waɗannan hanyoyin bayani da za'a tafiyar da shaidar harshe daga filin-bakin mulki. Tuna jarraba hanyõyi uku wa wannan: (i) ke yin tsohakin filayen shiryarwa na lugha masu amfani da (duka) zuwa harshen pivot; To, za'a tafiyar da hanyõyin-ƙayyade cikin harshe da variants, wanda ke ƙara da baƙa ƙƙe mai kyau kamar wata-manushi; kuma ya ƙara cikin shirin ayuka da ke daidaita a cikin harshen kowane da za'a tafiyar da salon mutfologi da re-ordana. Tuna ƙaddara a kan XNLI da tunkuɗe MT da ba'a karatun wata ba'a karatun a cikin harshen 19. FantayinMu na bayyana tsarin waɗannan hanyõyin hanyõyin da ke daidaita na shiryarwa, mai yin sauri ga filin aiki na hanya da kuma mai daidaita matsayin ba su sãmu babban rabo kode da harshen ba. Dukan da masu ƙaranci na hanyarsu, komai da su ƙara gaura transfer cikin linguin na yi nau'i 8.9 points (m-BERT) da point 18.2 (XLM-R) mai tsakanin dukkan aikin da harshen.", 'he': 'למציגות שפותיות יש את הפוטנציאל להפעיל טכניקות NLP זמינות לרוב השפות העצומות בעולם. בכל אופן, כרגע הם דורשים גופורה גדולה של אימון לפני או גישה לשפות דומות טיפולוגית. בעבודה הזו, אנו מתמודדים עם המכשולים האלה על ידי הסירה של אותות זהות שפה ממערכות רבות שפות. אנו בודקים שלושה גישות לזה: (i) מחדש את המקומות הקטורים של שפות המטרה (כולם יחד) לשפה מקור פיוט; (ii) removing language-specific means and variances, which yields better discriminativeness of embeddings as a by-product;  ולiii) הגבירה של דמיון הכניסה בין שפות על ידי הסירה של התכווצות מורפולוגיות ושינוי משפטים. אנחנו מעריכים על XNLI וערכת MT ללא התייחסות ברחבי 19 שפות מגוונות טיפולוגית. הממצאים שלנו חושפים את הגבלות של גישות אלה-לא כמו נורמליזציה ווקטורית, התאמה מחדש של חלל ווקטורים ונורמליזציה טקסטית לא מגיעים להשיגות קבועות ברחבי קודים ושפות. בגלל השפעות המשותפות של הגישויים, השילוב שלהם מפחיד את הפער של העברה השפתית על ידי 8.9 נקודות (m-BERT) ו-18.2 נקודות (XLM-R) בממוצע בכל המשימות והשפות.', 'bo': 'སྐད་རིགས་ཀྱི་གསལ་བརྗོད་པ་མང་ཆེ་ཤོས་ཡོད་པས། NLP ལག་རྩལ་གྱི་ཐབས་ལམ་ལུགས་ནི་འཛམ་གླིང་གི་ཡོད་ཆེས་ཤིག ད་ལྟ་མིན་ན། ད་ལྟ་བུའི་སྒོ་འབྱེད་པ་ཆེ་བའི་དབུས་པ་ཞིག་དང་བཟོ་རྣམ་གྲངས་སྒྲིག་སྐད་རིགས་དང་མཐུན་ས ལས་ཀ་འདིའི་ནང་དུ་ང་ཚོས་སྐད་ཡིག་ཆ་མཚོན་རྟགས་འདི་རྩིས་གཏོང་བའི་བར་ཆད་འདི་དག་གཏོང་བྱེད་ཀྱི་ཡོད། ང་ཚོས་འདིའི་གཟུགས་གཟུགས་གསུམ་ལ་བརྟག་ཞིབ་བྱེད། (ii) སྐད་ཡིག and (iii) increasing input similarity across languages by removing morphological contractions and sentence reordering. We evaluate on XNLI and reference-free MT evaluation across 19 typologically diverse languages. ང་ཚོའི་མཐོང་སྣང་གིས་ཕན་ཚུན་ལྡན་བཟོ་བྱེད་མི་འདྲ་བའི་གྲངས་ཚད་དང་ཕན་ཚུན་སྐྱེས་པའི་བར་སྟོང་དང་རྣམ་གྲངས་སྒྲིག ཡིན་ནའང་། གནད་དོན་གྱི་ཁ་སྐོང་ཚོའི་མཉམ་སྦྲེལ་མཐུད་དུ་ཡོད་པའི་སྐད་རིགས་ཀྱི་གནས་ས།'}
{'en': 'Spurious Correlations in Cross-Topic Argument Mining', 'es': 'Correlaciones espurias en la minería de argumentos entre temas', 'fr': "Corrélations fallacieuses dans l'exploration d'arguments entre sujets", 'ar': 'الارتباطات الزائفة في تعدين الحجج عبر الموضوعات', 'pt': 'Correlações espúrias na mineração de argumentos entre tópicos', 'zh': '跨主题参数掘中虚联', 'ja': 'クロストピック論点採掘における偽の相関関係', 'ru': 'Ложные корреляции в межтематическом майнинге аргументов', 'hi': 'क्रॉस-टॉपिक तर्क खनन में नकली सहसंबंध', 'ga': 'Comhghaolta Spéireacha i Mianadóireacht Argóintí Tras-Ábhar', 'hu': 'Spurious korrelációk a cross-topic argument bányászatban', 'el': 'Ανιχνευτικές συσχετίσεις στην υπερθεματική εξόρυξη επιχειρημάτων', 'it': "Correlazioni spurie nell'estrazione di argomenti trasversali", 'ka': 'ძალიან განსაზღვრებული კოლექციები კრისტრუმენტური აპდუმენტის მინიღებაში', 'mk': 'Спурозни корелации во минирање на расправии', 'lt': 'Įspūdingos tarpteminės argumentų gavybos koreliacijos', 'kk': 'Қосымша нақышты аргументтің балауындағы көңіл түзетулері', 'ms': 'Korelasi Berlebihan dalam Menyembah Argumen Salib Topik', 'mt': 'Korelazzjonijiet Spuriużi fit-Tħaffir ta’ Argumenti Cross-Topiki', 'no': 'Kjørne korreksjonar i minning av kryss- emne- argumentet', 'mn': 'Олон-сэдэв аргументын багасгалын цэвэрхэн зөвшөөрүүлэлт', 'pl': 'Niestabilne korelacje w górnictwie argumentów międzyotematowych', 'ml': 'ക്രോസ്- സംവിധാനത്തിലെ സുന്ദരിയായ കോര്\u200dബന്ധങ്ങള്\u200d', 'ro': 'Corelații spurioase în mineritul de argumente cross-topic', 'si': 'ක්\u200dරොස්- ප්\u200dරශ්ණ විද්\u200dයාත්මක ප්\u200dරශ්ණයක් ප්\u200dරශ්ණය', 'sv': 'Spurious Correlations in Cross-Topic Argument Mining', 'sr': 'Špijunske korekcije u rudarstvu međutemnih argumenta', 'ur': 'Cross-Topic Argument Mining میں سفارشی اصلاح', 'so': 'Xiriirka furan ee suurtagal ah ee suurtagalka', 'ta': 'கிருஸ்- தலைப்பு அருமையில் விருப்பமான தொடர்புகள்', 'vi': 'Liên hoàn hảo trong tranh luận xuyên chủ đề', 'uz': 'Name', 'bg': 'Спуриозни корелации в междутематичното аргументно минно дело', 'hr': 'Špijunske korekcije u rudarstvu međutemskih argumenta', 'nl': 'Sporige correlaties in cross-topic argument mining', 'da': 'Spurious Correlations in Cross-Topic Argument Minedrift', 'id': 'Korelasi Spurious dalam Perangunan Argumen Selata Topik', 'de': 'Spuröse Korrelationen im themenübergreifenden Argument Mining', 'fa': 'تغییرات فشار در کمینگ آرژومتهای زیادی عنوان', 'ko': '주제를 뛰어넘는 논점 발굴 중의 허위 관련', 'sq': 'Korelacione të mëdha në minierën e argumenteve ndër-tematike', 'tr': 'Çot-Tema Argument Ködleme', 'hy': 'Spurious Correlations in Cross-Topic Argument Mining', 'am': 'ምርጫዎች', 'sw': 'Mahusiano mazuri katika masuala ya Kusini', 'af': 'Speurde Korreksies in Cross- Theme Argument Mining', 'bn': 'ক্রস-বিষয়বস্তু আর্গামেন্ট মিনিং-এর সুন্দর সংশ্লিষ্ট সম্পর্ক', 'cs': 'Špatné korelace v těžbě argumentů mezi tématy', 'et': 'Ründavad korrelatsioonid valdkondadevahelises argumentide kaevandamises', 'az': '칖st칲nl칲k Mevzu Argument Miniyas캼ndak캼 S톛f칲r D칲z톛ltm톛l톛r', 'fi': 'Röyhkeät korrelaatiot monialaisessa argumentin louhintaan', 'ca': "Correlacions espurioses en la mineria d'arguments intertòpics", 'bs': 'Špijunske korekcije u rudarstvu međutemskih argumenta', 'ha': 'KCharselect unicode block name', 'he': 'קישורים מרושעים במכרת טיעונים מסביבים', 'sk': 'Spurious korelacije v medtematskem rudarstvu argumentov', 'bo': 'Cross-Theme་གི་སྒྲུབ་རྟགས་ཀྱི་ཚོར་བ་སྒྲུབ་གཏོང་ནང་སྟོང་པ', 'jv': 'structural navigation'}
{'en': 'Recent work in cross-topic argument mining attempts to learn models that generalise across topics rather than merely relying on within-topic spurious correlations. We examine the effectiveness of this approach by analysing the output of single-task and multi-task models for cross-topic argument mining, through a combination of linear approximations of their decision boundaries, manual feature grouping, challenge examples, and ablations across the input vocabulary. Surprisingly, we show that cross-topic models still rely mostly on spurious correlations and only generalise within closely related topics, e.g., a model trained only on closed-class words and a few common open-class words outperforms a state-of-the-art cross-topic model on distant target topics.', 'es': 'Un trabajo reciente en la minería de argumentos entre temas intenta aprender modelos que generalicen a través de los temas en lugar de basarse simplemente en correlaciones espurias dentro del tema. Examinamos la eficacia de este enfoque analizando el resultado de modelos de una sola tarea y multitarea para la minería de argumentos entre temas, a través de una combinación de aproximaciones lineales de sus límites de decisión, agrupación manual de características, ejemplos de desafíos y ablaciones en todo el vocabulario de entrada. Sorprendentemente, mostramos que los modelos de temas cruzados todavía se basan principalmente en correlaciones espurias y solo se generalizan dentro de temas estrechamente relacionados, por ejemplo, un modelo entrenado solo en palabras de clase cerrada y unas pocas palabras comunes de clase abierta supera a un modelo de temas cruzados de última generación en temas lejanos.', 'fr': "Des travaux récents sur l'exploration d'arguments interthématiques tentent d'apprendre des modèles qui généralisent entre les sujets plutôt que de simplement s'appuyer sur des corrélations fallacieuses au sein d'un même sujet. Nous examinons l'efficacité de cette approche en analysant la sortie de modèles à tâche unique et multitâche pour l'exploration d'arguments multisujets, grâce à une combinaison d'approximations linéaires de leurs limites de décision, de regroupement manuel de caractéristiques, d'exemples de défis et d'ablations dans le vocabulaire d'entrée. Étonnamment, nous montrons que les modèles interthématiques reposent encore principalement sur des corrélations fallacieuses et ne généralisent que dans le cadre de sujets étroitement liés, par exemple, un modèle formé uniquement sur des mots de classe fermée et quelques mots courants de classe ouverte surpasse un modèle inter-sujets de pointe sur des sujets cibles éloignés.", 'ar': 'يحاول العمل الأخير في التنقيب عن الجدل متعدد الموضوعات تعلم النماذج التي تعمم عبر الموضوعات بدلاً من مجرد الاعتماد على الارتباطات الزائفة داخل الموضوع. ندرس فعالية هذا النهج من خلال تحليل ناتج النماذج أحادية المهمة ومتعددة المهام لتعدين الحجة عبر الموضوعات ، من خلال مجموعة من التقريبات الخطية لحدود قراراتهم ، وتجميع الميزات اليدوية ، وأمثلة التحدي ، والاختفاءات عبر المدخلات كلمات. من المثير للدهشة أننا نظهر أن النماذج متعددة الموضوعات لا تزال تعتمد في الغالب على الارتباطات الزائفة وتعمم فقط في الموضوعات وثيقة الصلة بالموضوع ، على سبيل المثال ، نموذج تم تدريبه فقط على كلمات الطبقة المغلقة وعدد قليل من الكلمات المفتوحة الشائعة التي تتفوق على حالة من - نموذج فني متعدد الموضوعات في موضوعات مستهدفة بعيدة.', 'pt': 'Trabalhos recentes em mineração de argumentos entre tópicos tentam aprender modelos que generalizam entre tópicos, em vez de simplesmente confiar em correlações espúrias dentro do tópico. Examinamos a eficácia dessa abordagem analisando a saída de modelos de tarefa única e multitarefa para mineração de argumentos entre tópicos, por meio de uma combinação de aproximações lineares de seus limites de decisão, agrupamento manual de recursos, exemplos de desafio e ablações na entrada vocabulário. Surpreendentemente, mostramos que os modelos de tópicos cruzados ainda dependem principalmente de correlações espúrias e generalizam apenas dentro de tópicos intimamente relacionados, por exemplo, um modelo treinado apenas em palavras de classe fechada e algumas palavras comuns de classe aberta supera um estado-da- modelo de arte cruzada em tópicos de destino distantes.', 'zh': '近于跨题论掘之工,欲学跨题之泛化,非徒恃其虚相关性。 臣等因论跨题参数掘单务及多任务模形者输之,合其决界之线性近似,手动特徵分朋,挑战示例与跨输词汇表消融,以验其有效性。 令人讶之,则跨题犹赖虚相关性,而但推广于密题,如封闭之类单词与常见之开类单词练模形于远者,优于先进之跨题。', 'ja': 'クロストピックの議論マイニングにおける最近の研究は、トピック内の偽の相関関係に依存するだけではなく、トピック全体を一般化するモデルを学習しようと試みている。私たちは、クロストピック引数マイニングのためのシングルタスクモデルとマルチタスクモデルの出力を分析することによって、決定境界の線形近似、手動機能グループ化、チャレンジ例、および入力語彙全体のアブレーションの組み合わせを通じて、このアプローチの有効性を検討します。驚くべきことに、クロストピックモデルは依然としてほとんどが偽の相関に依存しており、密接に関連するトピック内でのみ一般化していることが示されている。例えば、クローズドクラスの単語といくつかの一般的なオープンクラスの単語でのみトレーニングされたモデルは、遠隔ターゲットトピックで最先端のクロストピックモデルよりも優れている。', 'hi': 'क्रॉस-टॉपिक तर्क खनन में हाल का काम उन मॉडलों को सीखने का प्रयास करता है जो केवल विषय के भीतर नकली सहसंबंधों पर भरोसा करने के बजाय विषयों में सामान्यीकरण करते हैं। हम क्रॉस-टॉपिक तर्क खनन के लिए एकल-कार्य और बहु-कार्य मॉडल के आउटपुट का विश्लेषण करके इस दृष्टिकोण की प्रभावशीलता की जांच करते हैं, उनके निर्णय सीमाओं के रैखिक सन्निकटन, मैनुअल फीचर ग्रुपिंग, चुनौती उदाहरण, और इनपुट शब्दावली में एब्लेशन के संयोजन के माध्यम से। हैरानी की बात है, हम दिखाते हैं कि क्रॉस-टॉपिक मॉडल अभी भी ज्यादातर नकली सहसंबंधों पर भरोसा करते हैं और केवल निकटता से संबंधित विषयों के भीतर सामान्यीकरण करते हैं, उदाहरण के लिए, केवल बंद-वर्ग के शब्दों पर प्रशिक्षित एक मॉडल और कुछ सामान्य खुले वर्ग के शब्द दूर के लक्ष्य विषयों पर एक अत्याधुनिक क्रॉस-टॉपिक मॉडल को मात देते हैं।', 'ru': 'Недавняя работа в области кросс-тематической аргументации старается выучить модели, которые обобщают темы, а не просто полагаются на внутритематические ложные корреляции. Мы изучаем эффективность этого подхода, анализируя выходные данные однозадачных и многозадачных моделей для кросс-тематического анализа аргументов, с помощью комбинации линейных приближений их границ принятия решений, ручной группировки признаков, примеров вызовов и абляций по всему входному словарю. Удивительно, но мы показываем, что кросс-тематические модели по-прежнему в основном опираются на ложные корреляции и только обобщают в рамках тесно связанных тем, например, модель, обученная только словам закрытого класса, и несколько общих слов открытого класса превосходят современную кросс-тематическую модель по отдаленным целевым темам.', 'ga': 'Déanann obair a rinneadh le déanaí i mianadóireacht argóintí tras-ábhair iarracht samhlacha a fhoghlaim a dhéanann ginearálú trasna topaicí seachas a bheith ag brath ar chomhghaolta bréagacha laistigh d’ábhar amháin. Scrúdaímid éifeachtacht an chur chuige seo trí anailís a dhéanamh ar aschur samhlacha aontasc agus ilthasc le haghaidh mianadóireacht argóintí tras-ábhair, trí mheascán de mheastacháin líneacha ar theorainneacha a gcinntí, grúpáil láimhe ar ghnéithe, samplaí dúshláin, agus díbleachtaí trasna an ionchuir. Foclóir. Is ionadh é, léirímid go bhfuil samhlacha tras-ábhair fós ag brath go príomha ar chomhghaolta bréagacha agus nach ndéantar iad a ghinearálú ach amháin laistigh de thopaicí dlúthghaolmhara, m.sh., múnla atá oilte ar fhocail ranga dúnta amháin agus cúpla focal aicme oscailte comónta a sháraíonn staid na coitiantachta. múnla tras-ábhar ealaíne ar thopaicí i bhfad i gcéin.', 'hu': 'A témák közötti argumentumbányászatban végzett közelmúltbeli munkák megpróbálják megtanulni a témák közötti általánosító modelleket, ahelyett, hogy pusztán a témán belüli hamis korrelációkra támaszkodnának. Ennek a megközelítésnek a hatékonyságát úgy vizsgáljuk, hogy elemezzük az egyfeladatos és többfeladatos modellek kimenetét a témaközi argumentumbányászathoz, a döntési határok lineáris közelítésének kombinációjával, a manuális funkciócsoportosítással, a kihívási példákkal és ablációkkal a bemeneti szókincsen. Meglepő módon megmutatjuk, hogy a témaközi modellek még mindig nagyrészt hamis korrelációkra támaszkodnak, és csak szorosan kapcsolódó témákon belül általánosítanak, például egy modell, amely csak zárt osztályú szavakra és néhány közös nyílt osztályú szó felülmúlja a korszerű témaközi modellt távoli céltémákon.', 'el': 'Πρόσφατες εργασίες στην εξόρυξη επιχειρημάτων μεταξύ θεμάτων επιχειρούν να μάθουν μοντέλα που γενικεύονται σε διάφορα θέματα αντί να βασίζονται απλώς σε ψευδείς συσχετισμούς εντός θέματος. Εξετάζουμε την αποτελεσματικότητα αυτής της προσέγγισης αναλύοντας την παραγωγή μοντέλων ενιαίας εργασίας και πολλαπλών εργασιών για υπερθεματική εξόρυξη επιχειρημάτων, μέσω ενός συνδυασμού γραμμικών προσεγγίσεων των ορίων αποφάσεων τους, χειροκίνητης ομαδοποίησης χαρακτηριστικών, παραδειγμάτων αμφισβήτησης και αφηγήσεων σε όλο το λεξιλόγιο εισαγωγής. Παραδόξως, δείχνουμε ότι τα μοντέλα μεταξύ θεμάτων εξακολουθούν να βασίζονται κυρίως σε ψευδείς συσχετισμούς και γενικεύονται μόνο σε στενά συνδεδεμένα θέματα, π.χ. ένα μοντέλο εκπαιδευμένο μόνο σε λέξεις κλειστής τάξης και μερικές κοινές λέξεις ανοικτής τάξης ξεπερνά ένα υπερσύγχρονο μοντέλο για θέματα απομακρυσμένου στόχου.', 'lt': 'Neseniai atliktas įvairių temų argument ų kūrimo darbas kasybos srityje bando išmokti įvairių temų modelius, kurie apskritai paplitę, o ne tik pasikliauti įvairių temų prieštaringomis koreliacijomis. Nagrinėdami šio metodo veiksmingumą analizuojame vienos užduoties ir kelių užduočių modelių, skirtų tarpteminiam argument ų gavybai, rezultatus, derindami linijinius jų sprendimų ribų suderinimus, rankinę savybių grupavimą, iššūkių pavyzdžius ir abliacijas visoje įvestinėje žodyne. Įspūdingai rodome, kad daugiausia įvairių temų modelių yra grindžiami neigiamomis koreliacijomis ir tik glaudžiai susijusiomis temomis, pavyzdžiui, modelis, mokomas tik uždaros klasės žodžiais ir keli bendri atviros klasės žodžiai, viršija moderniausią įvairių temų model į tolimomis tikslinėmis temomis.', 'it': "Il recente lavoro nel cross-topic argument mining tenta di apprendere modelli che generalizzano tra argomenti piuttosto che affidarsi semplicemente a false correlazioni all'interno dell'argomento. Esaminiamo l'efficacia di questo approccio analizzando l'output di modelli single-task e multi-task per il mining di argomenti cross-topic, attraverso una combinazione di approssimazioni lineari dei loro confini decisionali, raggruppamento manuale delle funzionalità, esempi di sfida e ablazioni attraverso il vocabolario di input. Sorprendentemente, mostriamo che i modelli cross-topic si basano ancora principalmente su correlazioni false e si generalizzano solo all'interno di argomenti strettamente correlati, ad esempio, un modello addestrato solo su parole di classe chiusa e poche parole comuni di classe aperta supera un modello cross-topic all'avanguardia su argomenti target lontani.", 'kk': 'Жаңа тақырыпты аргументтердің көпшілік аргументтерінде жұмыс істеу әрекеттері тақырыптарды жалпы түрлендіретін үлгілерді оқыту әрекеттері, тек тақырыпты көпшілікті түрлендірудің Біз бір тапсырма мен бірнеше тапсырма үлгілерінің шығысын анализ көп тапсырма үлгілерін аргументті бағалау үшін, шешім шектерінің сызықты түрлендіру шектерін, қолмен қасиеттерді топтастыру, мәселелер және кіріс сөздерінің ішінде жасау үші Біз әлі көпшілік нақыштар үлгілері әлі көпшілік қатынастарына тұрып жатқан нақыштардың ішінде жалғастырылып, мысалы, тек жабылған класс сөздеріне оқылған үлгілер мен бірнеше жалғастырылып жатқан нақыштар үлгілерінен шығарылады.', 'ms': 'Kerja baru-baru ini dalam argumen melintas-topik perlombongan cubaan untuk belajar model yang menyebarkan seluruh topik daripada hanya bergantung pada korelasi yang mengganggu dalam topik. We examine the effectiveness of this approach by analysing the output of single-task and multi-task models for cross-topic argument mining, through a combination of linear approximations of their decision boundaries, manual feature grouping, challenge examples, and ablations across the input vocabulary.  Yang mengejutkan, kami menunjukkan bahawa model salib-topik masih bergantung kebanyakan pada korelasi yang menggerunkan dan hanya menyebarkan dalam topik yang berkaitan rapat, misalnya, model yang dilatih hanya pada kata-kata kelas tertutup dan beberapa kata-kata kelas terbuka umum melampaui model salib-topik state-of-the-art pada topik sasaran jauh.', 'mk': 'Неодамнешната работа во крстотемските аргументи минирање се обидува да научи модели кои се генерализираат преку теми наместо само да се потпираат на меѓутемските непријатни корелации. Ние ја испитуваме ефикасноста на овој пристап со анализирање на излезот на модели од една задача и мултизадачи за минирање на растечки аргументи, преку комбинација на линијарни приближувања на нивните граници на одлуките, рачни групирања на карактеристики, примери на предизвики и аблации низ влезниот вокал Изненадувачки, покажуваме дека крстотемските модели сé уште се потпираат претежно на незгодни корелации и генерализираат само во блиски поврзани теми, на пример, модел обучен само на зборови од затворена класа и неколку обични зборови од отворена класа го надминува најсовремениот крстотемски модел на оддалечени теми на целта.', 'ml': 'പ്രധാനപൂര്\u200dണ്ണമായ ബന്ധങ്ങളില്\u200d ആശ്രയിക്കുന്നതിനെക്കാള്\u200d മോഡലുകള്\u200d പഠിക്കാന്\u200d ശ്രമിക്കുന്നതിനുള്ള അടുത്ത പ്രവര്\u200dത്തിക്കുന ക്രിസ്റ്റേപ്പിന്റെ ആര്\u200dഗ്യുമെന്റ് മൈനിങ്ങിന്റെ ഫലം പരിശോധിക്കുന്നതിനാല്\u200d നമ്മള്\u200d ഈ പ്രായോഗ്യത്തിന്റെ പ്രഭാവം പരിശോധിക്കുന്നു. അവയുടെ തീരുമാനത്തിന്റെ അടുത് അത്ഭുതപ്പെടുന്നു, നമ്മള്\u200d കാണിക്കുന്നു, ക്രിസ്റ്റേപ്പിന്റെ മോഡലുകള്\u200d പ്രധാനപ്പെട്ട സംബന്ധങ്ങളില്\u200d ആശ്രയിച്ചിരിക്കുന്നു. അടുത്തുള്ള വിഷയങ്ങളില്\u200d മാത്രമേ ഒരു മോഡല്\u200d പരിശീലിക്', 'ka': 'მიმდინარე სამუშაო სამუშაო არგემენტის მინიერების მოცდილებები, რომლებიც სამუშაო ტემენტის განმავლობაში გენერალიზებულია, არა მხოლოდ სამუშაო ტემენტის შესა ჩვენ ამ პროგრამის ეფექტიურობას შევხედავთ, ერთადერთი დავალების და მრავალური დავალების მოდელების გამოყენებას ანალიზაციას გავაკეთებთ მრავალური განსაზღვრების არგუმენტების მიღებას, მათი განსაზღვრებული დრინეების კომბუნციაზე,  სხვადასხვა, ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ კრისი ტემების მოდელები უფრო მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ დაკავშირებული ტემების შესახებ, მაგალითად მხოლოდ მხოლოდ დახურებული კლასის სიტყვებზე და რამდენიმე საერთო საერთო კლასი', 'mt': 'Ħidma reċenti fl-argument trans-tematiku tat-tħaffir fil-minjieri tipprova titgħallem mudelli li jiġġeneralizzaw fost is-suġġetti aktar milli sempliċement jiddependu fuq korrelazzjonijiet spurjużi fi ħdan is-suġġett. Aħna teżamina l-effettività ta’ dan l-approċċ billi tanalizza l-output ta’ mudelli ta’ kompitu wieħed u multikompitu għat-tħaffir fil-minjieri tal-argumenti transsuġġetti, permezz ta’ kombinazzjoni ta’ approssimazzjonijiet lineari tal-konfini tad-deċiżjonijiet tagħhom, raggruppament manwali tal-karatteristiċi, eżempji ta’ sfida, u ablazzjonijiet fil-vokabulari tal-input. Bħala sorpriża, nuru li l-mudelli trans-suġġetti g ħadhom jiddependu l-aktar fuq korrelazzjonijiet spurjużi u jiġġeneralizzaw biss f’suġġetti relatati mill-qrib, pereżempju mudell imħarreġ biss fuq kliem ta’ klassi magħluqa u ftit kliem komuni ta’ klassi miftuħa jaqbeż mudell trans-suġġett l-aktar avvanzat fuq suġġetti fil-mira distanti.', 'mn': 'Сүүлийн үед олон сэдвийн аргументуудын сүлжээний ажиллагаа, сэдвийн дотор зөвхөн тулгардаг холбоотой загваруудыг суралцахын оролдлого юм. Бид энэ арга хэмжээний үр дүнг шийдвэрлэлийн хил хязгаарын хоорондоо шулуун ойролцоогоор шийдвэрлэлийн хил хязгаарын нэгдэл, гар чадварын бүлэг, сорилтын жишээлүүд, өгөгдлийн сөрөг сөрөг дээр дамжуулах боломжтой олон ажил загварын үр дүнг шинжил Гайхалтай нь бид олон сэдвийн загварууд ихэнхдээ хамааралтай холбоотой, ойролцоогоор холбоотой сэдвийн дотор зөвхөн ихэнхдээ хамааралтай загварууд дээр байдаг. Жишээлбэл, зөвхөн хамгийн ойролцоогоор сургалтын үг дээр сургалтын загвар, хэд хэдэн нээлттэй', 'ro': 'Lucrările recente în mining de argumente cross-topic încearcă să învețe modele care generalizează peste subiecte, mai degrabă decât să se bazeze doar pe corelații false în interiorul subiectului. Examinăm eficacitatea acestei abordări prin analizarea rezultatelor modelelor single-task și multi-task pentru mining de argumente cross-topic, printr-o combinație de aproximări liniare ale limitelor deciziei lor, gruparea manuală a caracteristicilor, exemple de provocare și ablații în cadrul vocabularului de intrare. În mod surprinzător, arătăm că modelele cross-topic se bazează încă în mare parte pe corelații false și generalizează doar în cadrul subiectelor strâns legate, de exemplu, un model instruit numai pe cuvinte de clasă închisă și câteva cuvinte comune de clasă deschisă depășește un model cross-topic de ultimă generație pe subiecte țintă îndepărtate.', 'sr': 'Nedavni rad u raskrsnom argumentu u rudarskoj rudarstvu pokušava naučiti modele koje generalizuju u raznim temama umjesto da se pouzdavaju na sumnjive korelacije unutar teme. Provjeravamo učinkovitost ovog pristupa analizirajući izlaz jednozadataka i multizadatačnih modela za rudarstvo međutemnih argumenata, kroz kombinaciju linearnih približavanja njihovih granica odluke, grupiranje ručnih karakteristika, primjere izazova i aktivacije u proizvodnjoj rečnici. Iznenađujuće, pokazujemo da prekretne modele još uvek oslanjaju uglavnom na spore korelacije i samo generalizuju u bliskom odnosu na temu, npr. model koji je obučen samo na zatvorenih razrednih reči i nekoliko zajedničkih riječi otvorenih razreda iznosi model stanja umjetnosti prekretnih tema na dalekim ciljnim temama.', 'no': 'Nyleg arbeid i gjennomsiktige argument mining prøver å lære modeller som genereliserer gjennomsiktige tema i staden for berre å levera på inni emne spørre korrelasjonar. Vi undersøker effektiviteten av denne tilnærminga ved å analysera utdata av enkelt oppgåve- og fleire oppgåve- modeller for minning av kryss- emne- argument, gjennom ein kombinasjon av lineære tilnærmingar av dei avgjøringsgrensene sine, handbokgruppering av funksjonar, utfordringseksemplar og aktivering over inndataordboka. Overraska viser vi at kryssemodeller fremdeles ligg på fleire korrelasjonar og berre generelliserer i nærare relaterte emne, f.eks. ein modell som berre treng på lukka klasseord og ein par vanlege åpne klasseord utfører eit modell for kryssemodellen på distant målsemne.', 'pl': 'Ostatnie prace w cross-topic argument mining próbują nauczyć się modeli, które uogólniają się między tematami, a nie polegają tylko na fałszywych korelacjach wewnątrz-topic. Analizujemy efektywność tego podejścia poprzez analizę wyników modeli jednozadaniowych i wielozadaniowych dla transtematycznego eksploracji argumentów, poprzez połączenie liniowych przybliżeń granic decyzji, ręcznego grupowania cech, przykładów wyzwań i ablacji w słownictwie wejściowym. Co zaskakujące, pokazujemy, że modele międzyotematowe wciąż opierają się głównie na fałszywych korelacjach i uogólniają się tylko w ściśle powiązanych tematach, np. model trenowany tylko na słowach klasy zamkniętej i kilku powszechnych słów klasy otwartej przewyższa najnowocześniejszy model międzyotematowy w odległych tematach docelowych.', 'so': "Shaqo la soo dhowaaday arimaha ku saabsan oo lagu sameynayo tusaalooyin ay ku soo bandhigaan maadooyinka, taasoo aan ku kalsoonaanin xiriir kala duduwan. Waxaannu baaraynaa qaababkan waxqabadka, baaritaanka midowga shaqo oo kaliya iyo tusaalaha shaqaalaha oo kala duduwan ee laga baaraandegayo baaritaanka arimaha kala duduwan, marka lagu soo bandhigayo xiliga soohdimaha go'aankooda, kooxa qofka gacanta ah, masaallo qalloocan, iyo qalabka macluumaadka qoriga ah oo dhan. Waan la yaab leh, waxaynu tusnaynaa in tusaalaha iskala xiriira aad u badan ay ku kalsoonaadaan xiriirka kala duduwan oo kaliya mada la xiriira, tusaale ahaan model lagu baray kaliya hadalka fasalka xidhiidhka ah oo kaliya iyo qaar hadal furan oo aad u furan karto waxay ka samaysaa sameynta saqafka farshaxanka ah oo ku saabsan mada fog.", 'si': 'ප්\u200dරශ්න විදිහට ප්\u200dරශ්න විදිහට පරිස්සම් විදිහට ප්\u200dරශ්න විදිහට සාමාන්\u200dය විදිහට ප්\u200dරශ්න විදිහට පරිස්සම් විදිහට ප අපි පරීක්ෂා කරනවා මේ විධානයේ ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණයෙන් ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණයෙන් ප්\u200dරතික්\u200dරියාත්මක විශ්ලේෂණයෙන් ප්\u200dරතික්\u200dරියාත්මක ව පුදුම විදිහට, අපි පෙන්වන්නේ ක්\u200dරිස්ට් විද්\u200dයාපාර මොඩල් තාමත් විශේෂයෙන් සාමාන්\u200dය සම්බන්ධ විද්\u200dයාපාරය සහ සම්බන්ධ විද්\u200dයාපාරිත විද්\u200dයාපාරිත විද්\u200dයාපාරිත විදිහ', 'ta': 'சமீபத்தில் வேலை குறைந்த தருமத்தின் குறைந்த முயற்சிகளில் மட்டுமே உள்ள பிரச்சினையான இணைப்புகளை நம்புவதில்லை என்று மாதிரிகளை கற் இந்த செயல்பாட்டின் வெளியீட்டை ஒற்றைச் செயல் மற்றும் பல- பணி மாதிரிகளை பரிசோதிக்க நாம் செய்கிறோம் மூலம், முழு உள்ளீட்டு சொல்வளத்தின் சொற்கோவையும் கூட்டு வரிசையில ஆச்சரியமாக, நாம் காண்பிக்கிறோம் மாதிரிகள் இன்னும் பெரும்பாலாகவே பிரச்சனையான இணைப்புகள் மீது நம்பிக்கை கொண்டிருக்கிறது மற்றும் அருகில் தொடர்புடைய தலைப்புகளில் மட்டுமே பொது', 'ur': 'اچھا کام کرس-ٹوپ ارڈمنٹ میں جو مدل سیکھنے کی کوشش کرتا ہے جو موضوعوں میں متحد کرتی ہیں بغیر اس کے کہ صرف موضوعوں کے اندر بغیر بغیر بغیر بغیر بغیر بغیر بغیر بغیر بغیر ہم اس طریقے کی تابعداری کا تحقیق کریں گے کہ ایک ٹاکس اور بہت سی ٹاکس موڈل کے نتائج کا تحقیق کریں، ان کے فیصلے کے حدوں کی linear نزدیکتوں کے ذریعہ، ہاتھی فرصت گروپ کریں، چال مثالیں، اور اینٹ ویکوبلری کے درمیان آزاد کریں. ہم تعجب کرتے ہیں کہ کرسٹ ٹیپ موڈل یہاں تک بھی بہت زیادہ مختلف تعلقات پر بھروسہ رکھتے ہیں اور صرف نزدیک تعلقات کے موضوع میں متولد ہوتے ہیں، جیسے ایک موڈل جو صرف بند کلاس لکھوں پر آموزش کی گئی ہے اور بہت سے معمول آغاز کلاس لکھوں سے دور ترین موضوع پر متولد ہوتا ہے۔', 'sv': 'Nyligen utförda arbeten med argumentbrytning över ämnen försöker lära sig modeller som generaliserar över ämnen snarare än att bara förlita sig på falska korrelationer inom ämnet. Vi undersöker effektiviteten av detta tillvägagångssätt genom att analysera resultatet av single-task och multi-task modeller för cross-topic argument mining, genom en kombination av linjära approximationer av deras beslutsgränser, manuell funktionsgruppering, utmaningsexempel och ablationer över input ordförråd. Överraskande nog visar vi att ämnesöverskridande modeller fortfarande mest förlitar sig på falska korrelationer och endast generaliserar inom närbesläktade ämnen, t.ex. en modell tränad endast på slutna klassord och några vanliga ord i öppen klass överträffar en state-of-the-art tvärgående modell på avlägsna målämnen.', 'uz': "Yaqinda mavzu haqida ishni o'rganish uchun modellarni o'rganish jarayonlarida o'rganish jarayonlarida o'rganadi. Bu mavzularni faqat mavzu bilan bog'liq aloqalarni ishlashni o'rganadi. Biz bu usulning effektini bir vazifa va bir necha vazifa modellarini o'rganish uchun bir necha vazifaning natijasini aniqlash mumkin, ularning xususiyatlarining chegarasini birlashtirish va qoʻlbola moslamalarini guruhlash mumkin, masalan, va yozuvchi vositalarni ko'rsatish mumkin. Ko'rib chiqindiki, biz juda ko'pchilik mavzu modellari hozirga bog'liqlar bilan ishlatadi va faqat yaxshi bog'langan mavzularga generalisiz, masalan, faqat yopilgan ma'lumot so'zlari bilan o'rganish modeli va bir necha ochiq sinf so'zlari bilan bir necha bir necha ortiq-ochiq maqsadi shaxsiy suhbat mavzu model", 'vi': 'Công việc gần đây trong các cuộc tranh luận về mặt khác nhau của khai thác nỗ lực học các mô hình phổ biến trên các chủ đề chứ không chỉ dựa vào các mối tương quan giả tạo. Chúng tôi kiểm tra tính hiệu quả của phương pháp này bằng cách phân tích kết quả của các mô hình đơn nhiệm và đa nhiệm vụ cho khai thác các vấn đề khác nhau, qua một kết hợp các phân tích tuyến định giới tính của họ, tập hợp các tính năng bằng tay, ví dụ thách thức, và bắn xuyên qua các từ nhập. Thật ngạc nhiên là, chúng tôi cho thấy các mô hình giao tiếp chủ đề vẫn thường dựa trên các mối liên hệ giả tạo và chỉ phổ biến trong các chủ đề liên quan, ví dụ, một mô hình được rèn luyện chỉ với những từ cao cấp và vài từ phổ biến rộng hơn thực hiện mô hình giao tiếp nghệ thuật về các chủ đề xa xôi.', 'nl': 'Recent werk in cross-topic argument mining probeert modellen te leren die generaliseren over onderwerpen in plaats van alleen te vertrouwen op binnen-topic nepcorrelaties. We onderzoeken de effectiviteit van deze aanpak door de output te analyseren van single-task en multitask modellen voor cross-topic argument mining, door middel van een combinatie van lineaire benaderingen van hun beslissingsgrenzen, handmatige feature groepering, challenge voorbeelden en ablaties over de invoerwoordenschat. Verrassend genoeg laten we zien dat topic-cross-topic modellen nog steeds grotendeels gebaseerd zijn op valse correlaties en alleen generaliseren binnen nauw verwante onderwerpen, bijvoorbeeld een model dat alleen getraind is op gesloten-class woorden en een paar gemeenschappelijke open-class woorden overtreft een state-of-the-art cross-topic model op verre doelonderwerpen.', 'de': 'Aktuelle Arbeiten im themenübergreifenden Argument Mining versuchen, Modelle zu lernen, die themenübergreifend verallgemeinern, anstatt sich nur auf gefälschte Korrelationen innerhalb des Themas zu verlassen. Wir untersuchen die Effektivität dieses Ansatzes, indem wir die Ergebnisse von Einzel- und Mehraufgabenmodellen für das themenübergreifende Argument Mining analysieren, indem wir lineare Annäherungen ihrer Entscheidungsgrenzen, manuelle Merkmalsgruppen, Herausforderungsbeispiele und Ablationen über das Eingabevokabular hinweg kombinieren. Überraschenderweise zeigen wir, dass themenübergreifende Modelle immer noch überwiegend auf falschen Korrelationen beruhen und nur in eng verwandten Themen verallgemeinern, z.B. ein Modell, das nur auf geschlossenen Wörtern trainiert ist und ein paar gängige offene Wörter verwendet, übertrifft ein topenübergreifendes Modell auf entfernten Zielthemen.', 'hr': 'Nedavni rad u razmjernim argumentima rudarstva pokušava naučiti modele koje generalizuju u raznim temama, a ne samo na teme oslanjajući se na teške korelacije unutar teme. Provjeravamo učinkovitost ovog pristupa analiziranjem ishoda jednozadatačnih i multizadatačnih modela za rudarstvo međutemnih argumenata, kroz kombinaciju linearnih približavanja njihovih granica odluke, skupljanjem ručnih karakteristika, primjere izazova i uključenja kroz ulazni riječi. Iznenađujuće, pokazujemo da prekretni modeli još uvijek oslanjaju uglavnom na spore korelacije i samo generaliziraju u bliskom odnosu na teme, na primjer, model obučen samo na zatvorenih razrednih riječi i nekoliko zajedničkih riječi otvorenih razreda iznosi stanje umjetničkog prekretničkog model a na dalekim ciljnim temama.', 'bg': 'Последната работа в областта на междутематичните аргументи се опитва да научи модели, които обобщават темите, вместо просто да разчита на фалшиви корелации в рамките на темата. Проучваме ефективността на този подход, като анализираме резултатите от модели с една и няколко задачи за междутематично аргументиране, чрез комбинация от линейни приблизителни граници на техните решения, ръчно групиране на функции, примери за предизвикателства и аблации в входния речник. Изненадващо показваме, че междутематичните модели все още разчитат предимно на фалшиви корелации и се обобщават само в тясно свързани теми, например модел, обучен само на думи от затворен клас и няколко често срещани думи от отворен клас, превъзхожда най-съвременния междутематичен модел по далечни целеви теми.', 'da': 'Nyligt arbejde i cross-topic argument mining forsøger at lære modeller, der generaliserer på tværs af emner snarere end blot at stole på inden-topic falske korrelationer. Vi undersøger effektiviteten af denne tilgang ved at analysere output af single-task og multi-task modeller til cross-topic argument mining, gennem en kombination af lineære tilnærmelser af deres beslutningsgrænser, manuel funktionsgruppering, udfordringseksempler og ablationer på tværs af input ordforråd. Overraskende nok viser vi, at tværgående modeller stadig hovedsageligt er afhængige af falske korrelationer og kun generaliserer inden for tæt beslægtede emner, f.eks. en model trænet udelukkende på lukkede klasse ord og et par almindelige åbne klasse ord overgår en state-of-the-art tværgående model på fjerntliggende målemner.', 'id': 'Pekerjaan baru-baru ini dalam argumen intertopik pertambangan percobaan untuk mempelajari model yang menyebarkan seluruh topik daripada hanya bergantung pada korelasi berbahaya dalam topik. Kami memeriksa efektivitas pendekatan ini dengan menganalisis output dari model tugas tunggal dan multi-tugas untuk penambangan argumen topik salib, melalui kombinasi penghamparan linear dari batas keputusan mereka, pengumpulan karakteristik manual, contoh tantangan, dan ablasi di seluruh vocabulari input. Yang mengejutkan, kami menunjukkan bahwa model topik salib masih bergantung kebanyakan pada korelasi yang menggerunkan dan hanya menyebarkan dalam topik yang terhubung dekat, misalnya, model yang dilatih hanya pada kata-kata kelas tertutup dan beberapa kata-kata kelas terbuka umum melebihi model topik salib state-of-the-art pada topik target jauh.', 'sw': 'Kazi za hivi karibuni katika majadiliano ya uchimbaji wa mada kwa ajili ya kujifunza mifano yanayotengeneza mada badala ya kutegemea mahusiano yanayohusiana na mada. Tunajaribu ufanisi wa hatua hii kwa uchambuzi wa matokeo ya mifano ya kazi moja na kazi nyingine kwa ajili ya uchimbaji wa mijadala yenye maudhui, kwa pamoja na takribani mipaka ya msingi ya uamuzi wao, makusanyiko wa manufaa, changamoto, na mabadiliko katika lugha ya input. Inashangaza, tunaonyesha kuwa mifano ya mada inayovuka bado hutegemea zaidi ya mahusiano makubwa na kuzalisha tu katika mada yanayohusiana na karibu zaidi, kwa mfano, mtindo ulioelekezwa tu kwa maneno ya kufungwa darasa na maneno machache yanayofanana yanaonyesha mfano wa mada ya kuvuka sanaa kwenye mada ya mbali.', 'fa': 'کارهای اخیرا در مجموعه\u200cهای مختلف موضوع خریدن تلاش برای یاد گرفتن مدل\u200cهایی که در سراسر موضوع ژنرالی می\u200cکنند، به جای تنها بر ارتباطات مختلف درون موضوع اعتماد می\u200cکنند. ما موثرت این روش را با تحلیل نتیجه مدلهای یک کار و چندین کار برای خریدن مجموعه\u200cهای متفاوت، از طریق ترکیبی از نزدیک\u200cهای خطی مرزهای تصمیم\u200cگیری آنها، گروه\u200cهای ویژه\u200cهای دستی، نمونه\u200cهای چالش و فعالیت\u200cها در کلمات ورودی تحلیل می\u200cکنیم. متعجب است که ما نشان می دهیم که مدل های مختلف موضوع هنوز بیشتر بر ارتباط های مختلف و تنها در موضوع های نزدیک ارتباط دارند، مثال یک مدل فقط بر کلمات کلاس بسته و چند کلمات معمولی باز در کلاس معمولی بیشتر از یک مدل موضوع مختلف هنری بر موضوع موضوع هدف دور انجام می دهد.', 'tr': 'Ýakynda çarpan temalarda işlenýän guramlar meňzeş temalarda ýagdaýlaşdyran örän nusgalary öwrenmek üçin synanyşýar. Biz bu ýagdaýyň etkinliýetini ýekeje-täblik we çoklu-täblik nusgalarynyň çikgini çykaryp, çyzgylyk sözleriniň çyzgylyklarynyň birleşmesi bilen çyzgylyk taýýarlanmasy bilen analyzarlar. Gurhal ýagdaýda, çarpak nusgalaryň halda hem çapda ýakyn temalarda daşary ýagdaýda ynamly we diňe ýapyn synp sözlerine düzülen bir nusga we birnäçe orta-synp sözlerine daşary bir nusga çykarýan nusga g örnüşi ýok.', 'af': "Onlangse werk in kruis-onderwerp-argument mining probeer om modele te leer wat genereliseer oor onderwerpe in plaas as net vertrou op binne-onderwerp onderwerp afspraaklike korrelasies. Ons ondersoek die effektiviteit van hierdie toegang deur die uitvoer van enkele-taak en multi-taak-modele te analiseer vir kruis-onderwerp argument mining deur 'n kombinasie van lineêre aanbiedings van hul besluit grense, manuele funksiegroeping, uitdrukkingsvoorbeelde, en ablasies oor die invoer woordeboek. Ons vertoon wonderbaar dat kruis-onderwerp model e nog meeste vertrou op spesifieke korrelasies en slegs genereliseer binne naby verwante onderwerpe, bv. 'n model wat slegs onderwerp word op sluit-klas woorde en 'n paar gemeenskaplike open-klas woorde uitvoer 'n staat-van-die-kunsten kruis-onderwerp model op afgeleë doel onderwerpe.", 'hy': 'Վերջերս աշխատում են միջթեմային բանավեճերի մեջ, որոնք փորձում են սովորել մոդելներ, որոնք ընդհանրացվում են թեմաների միջև, և ոչ միայն հույս են տալիս թեմաների միջև բարդ հաղորդակցման վրա: Մենք ուսումնասիրում ենք այս մոտեցության արդյունավետությունը վերլուծում ենք միջատեմային բանավեճերի հանքահանման մեկ խնդրի և բազմախնդրի մոդելների արդյունավետությունը, որոշումների սահմանների գծային մոտեցումների, ձեռքի հատկությունների խմբավորումների, մարտահրավերի օրինակների և բալացիաների միջոցով: Զարմանալի է, որ մենք ցույց ենք տալիս, որ խաչված թեմային մոդելները դեռևս հիմնականում հիմնականում հիմնականում հիմնականում կախված են խիստ կապված թեմաների վրա և ընդհանուր են ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր', 'sq': 'Puna e fundit në argumentet ndërtematike miniere përpjekjet për të mësuar modele që gjeneralizohen nëpërmjet temave në vend se thjesht të mbështeten në korrelacione të përçara brenda temës. Ne e shqyrtojmë efektshmërinë e kësaj qasje duke analizuar daljen e modeleve me një detyrë të vetme dhe me shumë detyra për minierën e argumenteve ndërtematike, nëpërmjet një kombinimi të përafërsisë lineare të kufijve të tyre të vendimit, grupimit manual të karakteristikave, shembujve sfidash dhe ablacioneve nëpër fjalorin e hyrjes. Për çudi, ne tregojmë se modelet ndër-temë ende mbështeten kryesisht në korrelacione të shqetësuara dhe gjeneralizohen vetëm brenda temave të lidhura me afërsi, për shembull, një model i trajnuar vetëm me fjalë të klasës së mbyllur dhe disa fjalë të përbashkëta të klasës së hapur paraqet një model ndër-temë më të lartë në temë objektive të largëta.', 'am': 'በተለይ ጉዳይ ላይ ያሉ አካባቢ ግንኙነትን በመጠቀም የሚችሉትን ምሳሌዎች ማወቅ የሚችሉትን አካባቢዎች ማወቅ ነው፡፡ የዚህን ሥርዓት ጥያቄን እና የስራ ውጤት እና የብዙ ሥርዓት ሞዴላዎችን በማስተዋል እናደርጋለን፡፡ በተደነቀቀ ነገር፣ የሥልጣን አካባቢ ምሳሌዎች አብዛኛውን በተጨማሪው ግንኙነት ላይ እንዲታመኑ እና በተቃራኒ ጉዳዮች ውስጥ ብቻ እንዲያስተምሩ እና በቆርጠው ቋንቋ ቃላት ብቻ ሲያስተምሩ እና ጥቂቶች የተከፈቱ ክፍተት ቃላት የራቁ ጉዳዩ ጉዳዮች ላይ የክፍተኛ የሆኑት የራቀ ጉዳይ ግንኙነት ምሳሌ ያሳያል፡፡', 'bn': 'সাম্প্রতিক বিষয়বস্তু যুক্তির মধ্যে কাজ শেখার চেষ্টা করছে যে মডেল শেখার চেষ্টা করছে যা বিষয়গুলোকে জেনারেলিয়ে দেয়া হয়েছে বিষয়ে এই পদ্ধতির কার্যকলাপ পরীক্ষা করা হচ্ছে বিষয়বস্তু খনির জন্য এক কাজ এবং অনেক কাজের মডেল বিশ্লেষণ করার মাধ্যমে, তাদের সিদ্ধান্তের সীমানার ক্ষেত্রে লাইনির কাছাকাছি সীমানা, হাত বিস্ময়কর ভাবে আমরা দেখাচ্ছি যে ক্রিস্ট-বিষয়ের মডেল এখনো বেশীরভাগ বিদ্রোহী সম্পর্কের উপর নির্ভর করে এবং কাছাকাছি সংশ্লিষ্ট বিষয়ের মধ্যে শুধুমাত্র একটি মডেল শুধুমাত্র বন্ধ-শ্রেণীর কথায়', 'az': '∆Źvv…ôlki m…ôs…ôl…ôl…ôr arasńĪnda √ßoxlu m…ôs…ôl…ôl…ôr arasńĪnda olan modell…ôri √∂yr…ônm…ôy…ô √ßalńĪŇüńĪrlar, yalnńĪz m…ôs…ôl…ôl…ôrin i√ßind…ô √ßoxlu t…ôsirli bańülantńĪlara t…ôv…ôkk√ľl etm…ôkd…ôn baŇüqa. Biz bu metodlarńĪn etkinlińüini t…ôk-iŇü v…ô √ßoxlu-iŇü modell…ôrin √ßńĪxńĪŇüńĪnńĪ analiz…ô ed…ôr…ôk, √ß…ôtinlikl…ôrinin s…ôrh…ôl…ôrinin linear yaxńĪnlńĪqlarńĪnńĪ birl…ôŇüdirib, …ôlli f…ôaliyy…ôtl…ôrin qoŇüulmasńĪ, √ß…ôtinlikl…ôri √∂rn…ôkl…ôri v…ô giriŇü s√∂zl…ôrinin qarŇüńĪsńĪndaki f…ôaliyy…ôtl…ôrini analiz…ô ed…ôrik. Biz t…ô…ôcc√ľbl…ônirik ki, √ßox m√∂vzu modell…ôrin √ßox d…ôyiŇüiklik bańülantńĪlara t…ôv…ôkk√ľl edir v…ô yalnńĪz yaxńĪn bańülantńĪ m…ôs…ôl…ôl…ôrin i√ßind…ô generalizat edir, m…ôs…ôl…ôn, yalnńĪz kapalńĪ sńĪnńĪf s√∂zl…ôrind…ô t…ôhsil edilmiŇü modell…ôr v…ô bir ne√ß…ô ortaq a √ßńĪq sńĪnńĪf s√∂zl…ôrin uzaq m…ôqs…ôd m…ôs…ôl…ôl…ôrind…ô m√ľxt…ôlif m√∂vzu modell…ôrini g √∂st…ôrir.', 'ca': "Treballs recents en arguments intertòpics miners intenten aprendre models que generalitzan-se a través de temes en comptes de confiar en correlacions espulsives entre temes. Examinem l'eficacia d'aquest enfocament analitzant la producció de models de tarefa única i multitasca per a la mineria d'arguments intertòpics, a través d'una combinació d'aproximacions linears dels seus límits de decisions, agrupament manual de característiques, exemples de desafiament i ablacions a través del vocabulari d'entrada. Sorprenentment, demostram que els models intertòpics encara confien principalment en correlacions espirituals i només s'generalitzen en temes estretament relacionats, per exemple, un model entrenat només en paraules de class e tancada i unes quantes paraules comunes de classe oberta supera un model intertòpic d'última generació en temes d'objectiu remots.", 'bs': 'Nedavni rad u raznim argumentima rudarskih pokušaja naučiti modele koje generalizuju u raznim temama umjesto da se pouzdavaju samo na teške korelacije unutar teme. Provjeravamo učinkovitost ovog pristupa analizirajući proizvod jednozadataka i multizadatačnih modela za rudarstvo međutemnih argumenata, kroz kombinaciju linearnih približavanja njihovih granica odluke, skupinu ručnih karakteristika, primjere izazova i uključenja u proizvodnju rečnika. Iznenađujuće, pokazujemo da prekretni modeli još uvijek oslanjaju uglavnom na spore korelacije i samo generaliziraju u bliskom odnosu na temu, na primjer, model obučen samo na zatvorenih razrednih riječi i nekoliko zajedničkih riječi otvorenih razreda iznosi model stanja umjetnosti prekretnih tema na dalekim ciljnim temama.', 'ko': '최근 주제별 논점 발굴에 있어 주제별 범주화 모델을 배우려 하고 주제별 허위 관련에만 의존하는 것이 아니다.우리는 주제별 논점 발굴에 사용되는 단일 임무와 다중 임무 모델의 출력을 분석하고 의사결정 경계의 선형 근사, 수동 특징 그룹, 도전 예시와 어휘표에 입력된 ABLATION을 조합하여 이러한 방법의 유효성을 검증한다.놀랍게도 크로스 테마 모델은 허위의 관련성에 의존하고 밀접한 관련 주제에서만 범화되는 것을 발견했다. 예를 들어 폐쇄적인 단어와 소수의 흔한 개방적인 단어만 훈련하는 모델이 원거리 목표 주제에서 가장 선진적인 크로스 테마 모델보다 우수하다는 것이다.', 'et': 'Hiljutine töö teemadevaheliste argumentide kaevandamisel püüab õppida mudeleid, mis üldistavad teemasid, mitte ainult toetuda teemasisestele võltsitud korrelatsioonidele. Uurime selle lähenemisviisi efektiivsust, analüüsides ühe- ja mitme-ülesandega mudelite väljundit teemaüleseks argumentide kaevandamiseks, kombineerides nende otsustamispiiride lineaarseid lähenemisi, käsitsi funktsioonide rühmitamist, väljakutsete näiteid ja ablatsioone sisendsõnavaras. Üllataval kombel näitame, et teemadevahelised mudelid tuginevad endiselt enamasti võltsitud korrelatsioonidele ja üldistavad ainult tihedalt seotud teemadel, nt ainult suletud klassi sõnadele koolitatud mudel ja mõned tavalised avatud klassi sõnad ületavad kaugetel sihtteemadel kaasaegset teemadevahelist mudelit.', 'fi': 'Viimeaikaiset työt eri aihepiirien argumenttien louhintaan pyrkivät oppimaan malleja, jotka yleistyvät eri aihepiirien välillä sen sijaan, että vain luottaisivat aiheeseen liittyviin valheellisiin korrelaatioihin. Tarkastelemme tämän lähestymistavan tehokkuutta analysoimalla yhden ja useamman tehtävän mallien tuotosta aihepiirien välisen argumentin louhintaan yhdistämällä lineaarisia approksimaatioita päätösrajoista, manuaalista ominaisuusryhmittelyä, haasteesimerkkejä ja ablaatioita syöttösanastossa. Yllättäen osoitamme, että aihepiirikohtaiset mallit perustuvat edelleen enimmäkseen vääriin korrelaatioihin ja yleistyvät vain läheisesti toisiinsa liittyvien aiheiden sisällä, esimerkiksi vain suljetun luokan sanoihin koulutettu malli ja muutamat yleiset avoimen luokan sanat ylittävät huipputason aihekohtaisen mallin kaukaisissa kohdeaiheissa.', 'cs': 'Nedávná práce v těžbě argumentů mezi tématy se snaží naučit modely, které generalizují napříč tématy spíše než pouze spoléhat na falešné korelace uvnitř tématu. Účinnost tohoto přístupu zkoumáme analýzou výstupu jednotlivých a víceúlohových modelů pro cross-tématické dolování argumentů, kombinací lineárních aproximací jejich rozhodovacích hranic, ručního seskupování prvků, příkladů výzvy a ablací napříč vstupní slovní zásobou. Překvapivě ukazujeme, že modely mezi tématy stále spoléhají převážně na falešné korelace a generalizují se pouze v rámci úzce souvisejících témat, např. model trénovaný pouze na slovech uzavřené třídy a několik běžných slov otevřené třídy předčí nejmodernější model mezi tématy na vzdálených cílových tématech.', 'jv': 'Gujaring We test the effectness of this method by testing the output of single-task and multi-task modes for inter-tema argument mineng, throng a combining of linear conflications of their Resolution limits, Manu option group up, shock example, and enabled against the input Vocationary. Awakmuyiné, kita ngomong nik akeh model sing paling-temalan lagi mulai ngono pak dumadhi iki, nik kabèh dumadhi iki dadi sakjane kudu digambut', 'sk': 'Nedavno delo v medtematskem rudarjenju argumentov poskuša učiti modele, ki se posplošijo po temah, namesto da bi se zanašali zgolj na lažne korelacije znotraj teme. Učinkovitost tega pristopa preučujemo z analizo rezultatov enoopravilnih in večopravilnih modelov za medtematsko rudarjenje argumentov s kombinacijo linearnih približkov meja odločanja, ročnega združevanja funkcij, primerov izzivov in ablacij v vhodnem besedišču. Presenetljivo pokažemo, da se medtematski modeli še vedno večinoma zanašajo na lažne korelacije in se samo posplošujejo znotraj tesno povezanih tem, npr. model, ki se uči samo na besedah zaprtega razreda in nekaj običajnih besed odprtega razreda, presega najsodobnejši medtematski model na oddaljenih ciljnih temah.', 'ha': "A yanzu aikin aiki da ke ƙara cikin muhimmada masu basu da kure da aka yi amfani da misãlai wanda ke ƙarfafa a cikin maɓalli, kuma bã ya dõgara kawai a kan danganta masu bastarwa. Za jarraba mafi amfani da wannan hanyarwa, a yi anayyar ƙarshen misãlai na aiki guda da multi-aikin da za'a yi amfani da kunnuwa masu buƙata-madaidaici, cikin koma guda masu kusantar danganta masu tsari, kuma masu tsari cikin tsarin rubutun da ke haɗa, misãlai na musamman da zane-zane. Ina mãmãki, Munã nũna wa misãlai masu sarki yana dõgara mafiya yawa a kan ma'anar-sarki, kuma kawai masu haɗi a cikin masu muhimmai masu kusanta kawai, misali, wani misali wanda aka sanar da shi kawai kan maganar-rufe-daraja kuma wasu kalmõmi masu jama'a da ɗabi'a, yana sami wani misali na-mai sanar-sarki kan muhimman muhimmada mai nĩsa.", 'bo': 'Recently work in cross-topic argument mining attempts to learn models that generalise across topics rather than just relying on within-topic spurious correlations. We examine the effectiveness of this approach by analysing the output of single-task and multi-task models for cross-topic argument mining, through a combination of linear approximations of their decision boundaries, manual feature grouping, challenge examples, and ablations across the input vocabulary. མཚམས་མ་འཕགས་པའི་བརྗོད་ཁག', 'he': 'העבודה האחרונה בתוך טיעון חולבי ניסיונות למצוא דוגמנים שגנרליזמו ברחבי נושאים במקום פשוט לסמוך על קשרים בתוך נושא מעוררים. We examine the effectiveness of this approach by analysing the output of single-task and multi-task models for cross-topic argument mining, through a combination of linear approximations of their decision boundaries, manual feature grouping, challenge examples, and ablations across the input vocabulary.  Surprisingly, we show that cross-topic models still rely mostly on spurious correlations and only generalise within closely related topics, e.g., a model trained only on closed-class words and a few common open-class words outperforms a state-of-the-art cross-topic model on distant target topics.'}
{'en': 'Overcoming Poor Word Embeddings with Word Definitions', 'es': 'Superar la mala incrustación de palabras con definiciones de palabras', 'pt': 'Superando incorporações de palavras ruins com definições de palavras', 'ar': 'التغلب على التعاريف السيئة للكلمات بتعريفات الكلمات', 'zh': '用单词定义克不良词嵌之', 'hi': 'Word परिभाषाओं के साथ खराब Word एम्बेडिंग पर काबू पाना', 'ja': 'ワード定義による不適切なワード埋め込みの克服', 'ga': 'A Shárú Leabú Focal Droch le Sainmhínithe Focal', 'fr': 'Surmonter les mauvaises intégrations de mots grâce aux définitions de mots', 'ru': 'Преодоление плохих вложений слов с определениями слов', 'el': 'Αντιμετώπιση κακής ενσωμάτωσης λέξεων με ορισμούς λέξεων', 'ka': 'სიტყვების განსაზღვრებით დაკავშირებული სიტყვები', 'hu': 'A rossz szóbeágyazások leküzdése a szódefiníciókkal', 'lt': 'Pašalinti blogų žodžių įdėjimus su žodžių apibrėžtimis', 'mk': 'Преминување на вградувањата на лоши зборови со дефиниции на зборови', 'ms': 'Melewati Penjelmaan Kata Miskin dengan Definisi Kata', 'it': 'Superare le incorporazioni di parole povere con definizioni di parole', 'mt': 'Li jingħelbu l-inkorporazzjonijiet tal-kliem fqir b’Definizzjonijiet tal-kliem', 'mn': 'Үг тодорхойлолтой ядуу үг нэмж', 'no': 'Overkommande små ord- innbygging med orddefinisjonar', 'pl': 'Przezwyciężanie złych osadzeń słowa za pomocą definicji słowa', 'ro': 'Depășirea încorporărilor de cuvinte slabe cu definiții de cuvinte', 'ml': 'വാക്ക് വിശദീകരണങ്ങളുമായി പാവപ്പെട്ട വാക്കുകള്\u200d എംബെഡിങ്ങുകള്\u200d വരുന്നു', 'sr': 'Prevladavanje siromašnih reèi sa definicijama reèi', 'si': 'වචන විශ්වාස සඳහා අනතුරු වචන සම්බන්ධය', 'so': 'Isku imaanshaha Ereyga Faqiirka ah ee ku qoran', 'kk': 'Сөздің анықтамасының кейбір сөздерді ендіру', 'sv': 'Att övervinna inbäddningar av dåliga ord med orddefinitioner', 'ta': 'Overcoming Poor Word Embeddings with Word Definitions', 'ur': 'Word definitions', 'uz': 'Name', 'vi': 'Vượt qua ranh giới lời tội nghiệp với sự xác định từ', 'bg': 'Преодоляване на лошите вграждания на думи с дефиниции на думи', 'da': 'Overvinde indlejringer af dårlige ord med orddefinitioner', 'hr': 'Prevladavanje siromašnih riječi sa definicijama riječi', 'nl': 'Slechte woordinsluitingen overwinnen met woorddefinities', 'de': 'Überwindung schlechter Word-Einbettungen mit Word-Definitionen', 'id': 'Mengatasi Pencampuran Kata Miskin dengan Definisi Kata', 'fa': 'وارد کردن کلمات بیچاره با تعریف کلمات', 'ko': '단어 정의로 나쁜 단어 삽입 극복', 'sw': 'Neno masikini inaingia na Tafsiri za Neno', 'tr': 'Kelimi Kelimi bilen Gadyr Kelimi', 'af': 'Oorkom Poor Woord Inbetering met Woord Definitieë', 'sq': 'Mbështetja e përfshirjeve të fjalëve të këqija me përcaktimin e fjalëve', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'Բառերի սահմանափակումներով աղքատ բառերի ներգրավումների հաղթահարելը', 'az': 'Kelimi N칬vb톛l톛ri il톛 Zay캼f Kelimi 캻fad톛l톛ri', 'bn': 'শব্দ সংক্রান্ত বর্ণনা সহযোগে দরিদ্র শব্দের বিভিন্ন আগমন', 'ca': 'Superar les incorporacions de paraules pobres amb definicions de paraules', 'bs': 'Prevladavanje siromašnih riječi sa definicijama riječi', 'cs': 'Překonání špatných vložení slov s definicemi slov', 'et': 'Halbade sõnade manustamine sõnade definitsioonidega', 'fi': 'Huonojen sanaupotusten voittaminen sanamääritelmillä', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'להתגבר על התקפיצות מילים מסכנות עם הגדרות מילים', 'sk': 'Premaganje slabih vdelav besed z definicijami besed', 'bo': 'ཡི་གེའི་ངོས་འཛིན་དང་བསྟུན་ནས་འབྱུང་བའི་ཡིག་གེ་མཚུངས་རྟགས་', 'ha': 'KCharselect unicode block name'}
{'en': 'Modern natural language understanding models depend on pretrained subword embeddings, but applications may need to reason about words that were never or rarely seen during pretraining. We show that examples that depend critically on a rarer word are more challenging for natural language inference models. Then we explore how a model could learn to use definitions, provided in natural text, to overcome this handicap. Our model’s understanding of a definition is usually weaker than a well-modeled word embedding, but it recovers most of the performance gap from using a completely untrained word.', 'ar': 'تعتمد نماذج فهم اللغة الطبيعية الحديثة على تضمين كلمات فرعية مُدرَّبة مسبقًا ، ولكن قد تحتاج التطبيقات إلى التفكير في الكلمات التي لم تُشاهد مطلقًا أو نادرًا أثناء التدريب المسبق. نظهر أن الأمثلة التي تعتمد بشكل حاسم على كلمة نادرة أكثر تحديًا لنماذج استدلال اللغة الطبيعية. ثم نستكشف كيف يمكن للنموذج أن يتعلم استخدام التعريفات الواردة في النص الطبيعي للتغلب على هذه الإعاقة. عادةً ما يكون فهم نموذجنا للتعريف أضعف من تضمين الكلمة المصممة جيدًا ، ولكنه يستعيد معظم فجوة الأداء من استخدام كلمة غير مدربة تمامًا.', 'fr': "Les modèles modernes de compréhension du langage naturel dépendent de l'intégration de sous-mots préentraînés, mais les applications peuvent avoir besoin de raisonner sur des mots qui n'ont jamais ou rarement été vus pendant la pré-formation. Nous montrons que les exemples qui dépendent de manière critique d'un mot plus rare sont plus difficiles pour les modèles d'inférence en langage naturel. Ensuite, nous explorons comment un modèle pourrait apprendre à utiliser des définitions, fournies en texte naturel, pour surmonter ce handicap. La compréhension d'une définition par notre modèle est généralement plus faible qu'une intégration de mots bien modélisée, mais elle permet de combler la majeure partie de l'écart de performance dû à l'utilisation d'un mot complètement non formé.", 'es': 'Los modelos modernos de comprensión del lenguaje natural dependen de incrustaciones de subpalabras previamente entrenadas, pero es posible que las aplicaciones necesiten razonar por palabras que nunca o rara vez se vieron durante la capacitación previa. Mostramos que los ejemplos que dependen críticamente de una palabra rara son más desafiantes para los modelos de inferencia de lenguaje natural. Luego exploramos cómo un modelo podría aprender a usar definiciones, proporcionadas en texto natural, para superar esta desventaja. La comprensión que tiene nuestro modelo de una definición suele ser más débil que la incrustación de palabras bien modelada, pero recupera la mayor parte de la brecha de rendimiento al usar una palabra completamente inexperta.', 'pt': 'Os modelos modernos de compreensão de linguagem natural dependem de embeddings de subpalavras pré-treinadas, mas os aplicativos podem precisar raciocinar sobre palavras que nunca ou raramente foram vistas durante o pré-treinamento. Mostramos que exemplos que dependem criticamente de uma palavra mais rara são mais desafiadores para modelos de inferência de linguagem natural. Em seguida, exploramos como um modelo poderia aprender a usar definições, fornecidas em texto natural, para superar essa desvantagem. A compreensão do nosso modelo de uma definição é geralmente mais fraca do que uma incorporação de palavras bem modelada, mas recupera a maior parte da lacuna de desempenho usando uma palavra completamente não treinada.', 'zh': '今世自然语言解依于先训子词嵌,然应用程序或须对预练之间,未见单词推理。 吾明大赖于单词者示例自然语言推理模型更具挑战性也。 然后,我们探索模样怎么学习自然文本中供给的定义来克服这一障碍。 凡诸定义,常比建模良单词嵌要弱,然其用全未练者单词可复大分。', 'hi': 'आधुनिक प्राकृतिक भाषा समझने वाले मॉडल प्रीट्रेन्ड सबवर्ड एम्बेडिंग पर निर्भर करते हैं, लेकिन अनुप्रयोगों को उन शब्दों के बारे में तर्क करने की आवश्यकता हो सकती है जो प्रीट्रेनिंग के दौरान कभी या शायद ही कभी देखे गए थे। हम दिखाते हैं कि उदाहरण जो एक दुर्लभ शब्द पर गंभीर रूप से निर्भर करते हैं, प्राकृतिक भाषा अनुमान मॉडल के लिए अधिक चुनौतीपूर्ण हैं। फिर हम यह पता लगाते हैं कि एक मॉडल इस बाधा को दूर करने के लिए प्राकृतिक पाठ में प्रदान की गई परिभाषाओं का उपयोग करना कैसे सीख सकता है। एक परिभाषा के बारे में हमारे मॉडल की समझ आमतौर पर एक अच्छी तरह से मॉडलिंग शब्द एम्बेडिंग की तुलना में कमजोर होती है, लेकिन यह पूरी तरह से अप्रशिक्षित शब्द का उपयोग करने से अधिकांश प्रदर्शन अंतर को पुनर्प्राप्त करती है।', 'ja': '現代の自然言語理解モデルは、事前に訓練されたサブワードの埋め込みに依存していますが、アプリケーションは、事前訓練中に見られなかった、またはほとんど見られなかった単語について推論する必要があるかもしれません。私たちは、より希少な単語に批判的に依存する例は、自然言語推論モデルにとってより困難であることを示しています。次に、モデルがこのハンディキャップを克服するために、自然なテキストで提供される定義をどのように使用することができるかを探ります。私たちのモデルの定義に対する理解は、通常、モデル化された単語の埋め込みよりも弱いですが、完全に訓練されていない単語の使用からパフォーマンスギャップのほとんどを回復します。', 'ga': 'Braitheann samhlacha nádúrtha tuisceana teanga nua-aimseartha ar leabú fofhocail réamhoilte, ach b’fhéidir go gcaithfeadh feidhmchláir réasúnaíocht a dhéanamh faoi fhocail nach bhfacthas riamh nó nach bhfacthas go hannamh le linn réamhoiliúint. Léirímid go bhfuil samplaí a bhraitheann go criticiúil ar fhocal níos annamha níos dúshlánaí do shamhlacha tátal teanga nádúrtha. Ansin déanaimid iniúchadh ar conas a d’fhéadfadh samhail foghlaim conas sainmhínithe a úsáid, a chuirtear ar fáil i dtéacs nádúrtha, chun an bac seo a shárú. Is gnách go mbíonn tuiscint ár múnla ar shainmhíniú níos laige ná leabú focal dea-mhúnlaithe, ach aisghabhann sé an chuid is mó den bhearna feidhmíochta ó úsáid a bhaint as focal atá go hiomlán neamhoilte.', 'ru': 'Современные модели понимания естественного языка зависят от предварительно обученных вложений подслова, но приложениям может потребоваться рассуждать о словах, которые никогда или редко встречались во время предварительного обучения. Мы показываем, что примеры, которые критически зависят от более редкого слова, более сложны для моделей вывода на естественном языке. Затем мы исследуем, как модель может научиться использовать определения, представленные в естественном тексте, чтобы преодолеть этот недостаток. Понимание определения в нашей модели обычно слабее, чем встраивание хорошо смоделированного слова, но оно восстанавливает большую часть разрыва в производительности при использовании совершенно неподготовленного слова.', 'hu': 'A modern természetes nyelvértési modellek az előkészített alszó beágyazásoktól függnek, de lehet, hogy az alkalmazásoknak érvelniük kell azokat a szavakat, amelyeket soha vagy ritkán láttak az előkészítés során. Megmutatjuk, hogy a ritkább szótól kritikusan függő példák nagyobb kihívást jelentenek a természetes nyelvi következtetési modellek számára. Ezután megvizsgáljuk, hogyan tanulhatja meg egy modell a természetes szövegben megadott definíciókat a hátrány leküzdésére. Modellünk megértése egy definícióról általában gyengébb, mint egy jól modellezett szó beágyazása, de a teljesítményhiány nagy részét egy teljesen kiképzett szó használatából helyreállítja.', 'el': 'Τα σύγχρονα μοντέλα κατανόησης φυσικής γλώσσας εξαρτώνται από προκαθορισμένες ενσωματώσεις υπολέξεων, αλλά οι εφαρμογές μπορεί να χρειαστεί να συλλογιστούν για λέξεις που δεν εμφανίστηκαν ποτέ ή σπάνια κατά την προετοιμασία. Δείχνουμε ότι παραδείγματα που εξαρτώνται κρίσιμα από μια σπανιότερη λέξη είναι πιο προκλητικά για μοντέλα συμπερασμάτων φυσικής γλώσσας. Στη συνέχεια διερευνούμε πώς ένα μοντέλο θα μπορούσε να μάθει να χρησιμοποιεί ορισμούς, που παρέχονται στο φυσικό κείμενο, για να ξεπεράσει αυτό το μειονέκτημα. Η κατανόηση ενός ορισμού από το μοντέλο μας είναι συνήθως ασθενέστερη από την ενσωμάτωση μιας καλά μοντελοποιημένης λέξης, αλλά ανακτά το μεγαλύτερο μέρος του χάσματος απόδοσης από τη χρήση μιας εντελώς ανεκπαίδευτης λέξης.', 'it': "I moderni modelli di comprensione del linguaggio naturale dipendono da incorporazioni di sottoparole pre-addestrate, ma le applicazioni possono aver bisogno di ragionare su parole che non sono mai state o raramente viste durante il pre-training. Mostriamo che esempi che dipendono criticamente da una parola più rara sono più impegnativi per i modelli di inferenza del linguaggio naturale. Poi esploriamo come un modello potrebbe imparare ad utilizzare definizioni, fornite nel testo naturale, per superare questo handicap. La comprensione di una definizione da parte del nostro modello è solitamente più debole di un embedding di parole ben modellato, ma recupera la maggior parte del gap prestazionale dall'uso di una parola completamente non addestrata.", 'lt': 'Moderni natūralūs kalbų supratimo modeliai priklauso nuo iš anksto apmokytų subžodžių įterpimo, tačiau gali prireikti pagrįsti žodžius, kurie niekada ar retai nebuvo pastebėti išankstinio apmokymo metu. Mes rodome, kad pavyzdžiai, kurie kritiškai priklauso nuo retesnio žodžio, yra sunkesni gamtinių kalbų išvadų modeliams. Tuomet ištiriame, kaip modelis galėtų išmokti naudotis natūralause tekste pateiktomis apibrėžtimis, kad įveiktų šią kliūtį. Mūs ų modelio supratimas apibrėžimui paprastai yra silpnesnis nei gerai modeliuotas žodis įterpimas, bet jis atgauna didžiąją veiklos spragą naudojant visiškai neišmokytą žodį.', 'kk': 'Қазіргі табиғи тілді түсініш үлгілері өзгертілген ішкі сөздерді ендіруде тәуелді, бірақ қолданбалар өзгерту кезінде ешқашан не кейбірде көрінбеген сөздер туралы себептер Біз мәселелерді тәуелді сөздерге тәуелді тәуелді деп көрсетедік. Тәуелді тілдердің инференциялық үлгілерінде тәуелді. Содан кейін біз үлгі табиғи мәтінде келтірілген анықтамаларды қалай үйренуге үйрене аламыз. Бұл қарсылықты көтеру үшін. Біздің моделіміздің анықтамасының түсінігі кәдімгі үлгілі сөздерді ендіру арқылы, бірақ оның көпшілігінің көпшілігі өзгертілмеген сөзді қолдануға болады.', 'mk': 'Модерните природни модели за разбирање на јазикот зависат од претренирани внесувања на подзборови, но апликациите можеби ќе мора да размислуваат за зборови кои никогаш не се видени или ретко се гледаат за време на претренирање. Ние покажуваме дека примерите кои критично зависат од поредок збор се попредизвикувачки за природните модели на инференција на јазикот. Потоа истражуваме како моделот може да научи да користи дефиниции, обезбедени во природен текст, за да го надмине овој хендикеп. Разбирањето на дефиницијата на нашиот модел е обично послабоко од добро моделираното вградување на зборови, но го обновува поголемиот дел од празнината во изведувањето од користењето на сосема необучен збор.', 'ml': 'ഇപ്പോഴത്തെ സ്വാഭാവികമായ ഭാഷയിലെ ബുദ്ധിമുട്ടികളുടെ മോഡലുകള്\u200d പ്രത്യേകിച്ചുകൊണ്ടിരിക്കുന്നു. പക്ഷെ മഴ പെയ്യുന്ന സമയത് നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്ന ഉദാഹരണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു, ഒരു ചെറിയ വാക്കിനെ ആശ്രയിക്കു പിന്നെ നമ്മള്\u200d പരിശോധിക്കുന്നത് എങ്ങനെയാണ് ഒരു മോഡല്\u200d ഉപയോഗിക്കാന്\u200d പഠിക്കുന്നത്, സ്വാഭാവിക വാചകത്തില നമ്മുടെ മോഡലിന്റെ വിശദീകരണത്തിന്റെ മനസ്സിലാകുന്നത് സാധാരണയായി നല്ല മാതൃകയുള്ള വാക്കിനെക്കാള്\u200d ദുര്\u200dബലമാണ്. പക്ഷെ അത് പ്രകടന വേ', 'mn': 'Орчин үеийн байгалийн хэл ойлголтын загварууд нь өмнө нь хэлбэртэй үгнээс хамааралтай. Гэхдээ хэрэглэгчид хэзээ ч өмнө нь хэзээ ч харагдахгүй, ховор харагдахгүй үгнүүдийн тухай ойлг Байгалийн хэл халдварын загвараас илүү төвөгтэй байдаг жишээг харуулж байна. Дараа нь бид загвар хэрхэн тодорхойлолтыг хэрхэн ашиглаж, байгалийн текст ашиглаж, үүнийг даван авч чадна гэдгийг судалж байна. Бидний загварын тодорхойлолтын тухай ойлголтын тухай ихэвчлэн сайн загвартай үгнээс илүү бага байдаг. Гэхдээ энэ бүтээлтийн загварын ихэнх нь бүтэлгүйтгэлгүй үгнээс ашиглах боломжтой.', 'ka': 'მოდინარე ნახვა ენერგიის მოდელების შესაძლებლობა დაახლოებია, მაგრამ პროგრამები შეიძლება უნდა მივიღოთ სიტყვების შესახებ, რომლებიც არასდროს ან წარმოდგენა საშუალო ჩვენ ჩვენ აჩვენებთ, რომ მაგალითები, რომელიც კრიტიკურად კონტაქტიურად დააყენებენ უფრო ძალიან შესაძლებელია ჩვენი ენის ინფრენციის მოდელებისთვის შემდეგ ჩვენ ვხედავთ, როგორ მოდელის შესაძლებლობა გამოყენება განსაზღვრებების გამოყენება, როგორ მოდელის შესაძლებლობა, როგორ მოდელის ტექსტის გადა ჩვენი მოდელეში განსაზღვრების შესახებ უფრო ცოტა ვიდრე კარგი მოდელური სიტყვის, მაგრამ ის უფრო მეტი განსაზღვრების განსხვავება გამოიყენება ყველაფერად უფრო უფრო', 'ms': 'Model pemahaman bahasa semulajadi modern bergantung pada penyambungan subkata yang dilatih dahulu, tetapi aplikasi mungkin perlu alasan mengenai perkataan yang tidak pernah atau jarang dilihat semasa berlatih dahulu. Kami menunjukkan bahawa contoh-contoh yang bergantung secara kritikal pada perkataan yang lebih jarang adalah lebih menantang untuk model kesimpulan bahasa alam. Kemudian kita mengeksplorasi bagaimana model boleh belajar untuk menggunakan definisi, diberikan dalam teks semulajadi, untuk mengatasi cacat ini. Pemahaman model kita mengenai definisi biasanya lebih lemah daripada penyampaian kata yang dipodel dengan baik, tetapi ia pulihkan sebahagian besar ruang prestasi daripada menggunakan perkataan yang sama sekali tidak dilatih.', 'mt': 'Il-mudelli moderni ta’ fehim tal-lingwa naturali jiddependu fuq l-inkorporazzjonijiet ta’ subkelma mħarrġa minn qabel, iżda l-applikazzjonijiet jista’ jkollhom bżonn jirrinunzjaw għal kliem li qatt ma dehru jew rarament waqt it-taħriġ minn qabel. Aħna nuru li eżempji li jiddependu b’mod kritiku fuq kelma aktar rari huma aktar ta’ sfida għall-mudelli ta’ inferenza lingwistika naturali. Imbagħad nistudjaw kif mudell jista’ jitgħallem juża definizzjonijiet, ipprovduti fit-test naturali, biex jingħeleb dan l-iżvantaġġ. Il-fehim tal-mudell tagħna ta’ definizzjoni huwa ġeneralment aktar dgħajjef mill-inkorporazzjoni ta’ kelma mmudellata tajjeb, iżda jirkupra l-biċċa l-kbira tad-distakk fil-prestazzjoni mill-użu ta’ kelma kompletament mhux imħarrġa.', 'ro': 'Modelele moderne de înțelegere a limbajului natural depind de încorporarea subcuvintelor pre-instruite, dar aplicațiile pot trebui să discute despre cuvinte care nu au fost niciodată sau rareori văzute în timpul pre-instruirii. Arătăm că exemplele care depind critic de un cuvânt mai rar sunt mai provocatoare pentru modelele de inferență a limbajului natural. Apoi explorăm modul în care un model ar putea învăța să folosească definițiile, furnizate în text natural, pentru a depăși acest handicap. Înțelegerea unei definiții de către modelul nostru este de obicei mai slabă decât încorporarea unui cuvânt bine modelat, dar recuperează cea mai mare parte a decalajului de performanță din utilizarea unui cuvânt complet netransat.', 'si': 'අධ්\u200dයාත්මක භාෂාව තේරුම් මොඩේල්ස් ප්\u200dරීට්\u200dරීන් විදියට අවශ්\u200dය විදියට, නමුත් විදියට ප්\u200dරයෝජනය කවදාවත් ප්\u200dරී අපි පෙන්වන්නේ උදාහරණ වචනයක් විශේෂයෙන් විශේෂයෙන් අවශ්\u200dය වෙන්නේ ස්වාභාවික භාෂාව අන්තිමත් ම ඊට පස්සේ අපි පරීක්ෂණය කරනවා මොඩොල්ලෙක්ගේ විශ්වාස භාවිත කරන්න පුළුවන් කොහොමද කියලා, ස්වභාවික ප අපේ මෝඩල් එකේ විශ්වාසයක් ගැන තේරුම් ගන්න සාමාන්\u200dයයෙන්ම නිර්මාණය කරපු වචනයක් වඩා වඩා දුර්වලයි, ඒත් ඒක සම්පූර්ණ', 'no': 'Moderne naturspråk-forstørringsmodular avhengig av underordinnbygging, men programmet kan må forstørra om ord som aldri eller rart vart sett under trekking. Vi viser at eksemplar som er kritisk avhengig av ein rågare ord er meir vanskeleg for naturspråk-infeksjonsmodular. Så vi utforskar korleis ein modell kunne lære å bruka definisjonar, levert i naturtekst, for å overføra denne handikapen. Modellen vårt forståelse av ein definisjon er vanlegvis tyggere enn ein godt modelte ord innebygging, men det gjer dei fleste av utgangspunktet frå å bruka eit fullstendig ikkje regna ord.', 'so': 'Tusaalada waxgarashada afka asalka ah ee hore waxay ku xiran tahay mid ku habboon qoraal hoose ah, laakiin codsigu waxay u baahan tahay inay sababto ku saabsan hadallada aan weligood arag ama aan yarayn marka lagu soo daayay. Waxaynu tusnaynaa tusaalooyin ay ku xiran tahay hadal qiimo yar oo ay ka adag tahay tusaalaha cudurada afka dabiicadda. Markaas waxaynu baarinaynaa sida tusaale ay u baran karto in lagu isticmaalo fasaxyo, oo lagu qoray qoraalka dabiicadda ah, si aan uga adkaado dhaqaalahan. Tilmaankayaga garashada qoraalka sida caadiga ah waa ka itaal yar tahay hadal aad u sameyn karto, laakiin waxay dib u celisaa goobaha sameynta si uusan ugu isticmaalin hadal aan dhamaan.', 'ta': 'தற்போதைய இயற்கையான மொழி புரிந்து கொள்ளும் மாதிரிகள் மாதிரியும் துணை சொல்லும் பொருட்களை சார்ந்து கொள்ளும், ஆனால் பயன் ஒரு சிறிய வார்த்தையின் மீது சார்ந்து கொள்ளும் உதாரணங்களை நாம் காட்டுகிறோம் என்றால் இயற்கையான மொ பிறகு நாம் ஒரு மாதிரி எப்படி விளக்கங்களை பயன்படுத்த கற்று கொள்ள முடியும் என்பதை கண்டுபிடிக்க வேண்டும். இயற்க எங்கள் மாதிரி வரையறை புரிந்து கொள்வது வழக்கமாக நல்ல மாதிரியான வார்த்தையை விட பலவீனமாக இருக்கிறது, ஆனால் அது முழுமையான மறையாத வார்த்', 'pl': 'Współczesne modele rozumienia języka naturalnego zależą od wstępnie trenowanych osadzeń podsłów, ale aplikacje mogą wymagać uzasadnienia słów, które nigdy lub rzadko nie były widoczne podczas treningu wstępnego. Pokazujemy, że przykłady, które zależą krytycznie od rzadszego słowa, są bardziej wyzwaniem dla modeli wnioskowania języka naturalnego. Następnie badamy, w jaki sposób model mógłby nauczyć się używać definicji, dostarczonych w tekście naturalnym, aby przezwyciężyć tę utrudnienie. Zrozumienie definicji przez nasz model jest zwykle słabsze niż dobrze zamodelowane osadzenie słów, ale odzyskuje większość luki w wydajności dzięki użyciu zupełnie nieprzeszkolonego słowa.', 'sv': 'Moderna modeller för förståelse av naturligt språk beror på förklädda underordsbäddningar, men applikationer kan behöva resonera om ord som aldrig eller sällan sågs under förklädningen. Vi visar att exempel som är kritiskt beroende av ett sällsynt ord är mer utmanande för naturliga språkinferensmodeller. Sedan undersöker vi hur en modell kan lära sig att använda definitioner, som finns i naturlig text, för att övervinna detta handikapp. Vår modells förståelse för en definition är oftast svagare än en väl modellerad ordinbäddning, men den återställer det mesta av prestandakravet från att använda ett helt otränat ord.', 'sr': 'Moderna prirodna jezika razumevanja modela zavise od ugrađenih podriječja, ali aplikacije mogu morati razumjeti o rečima koje nikada nisu videle ili rijetko tijekom pretkivanja. Pokazujemo da su primjeri koji kritično zavise od retke reči izazovni za model infekcije prirodnog jezika. Onda istražujemo kako bi model mogao naučiti da koristi definicije, pružene u prirodnom tekstu, da prevaziđemo ovaj handikap. Razumevanje našeg model a definicije je obično slabije od dobro modelirane reči uključujući, ali većina praznina performanstva se oporavlja od upotrebe potpuno neodređene reči.', 'ur': 'مدرنی طبیعی زبان سمجھنے کی مدلکوں پر اپنا اعتماد ہے، لیکن اپنا کاروبار شاید ایسے کلمات کے بارے میں دلیل حاصل کرنا ضرورت ہو سکتا ہے جن کو دھوپ کی حالت میں کبھی یا کم دھوپ نہیں دیکھا گیا۔ ہم دکھاتے ہیں کہ مثالیں جو کم کم کلمہ پر اضطراری کرتے ہیں ان سے زیادہ مشکل ہیں طبیعی زبان انفورنس موڈل کے لئے۔ پھر ہم دیکھتے ہیں کہ ایک مدل کس طرح معلومات کا استعمال کرنا سکتا ہے، جو طبیعی متن میں پیش کیا گیا ہے، اس ہندکیپ پر غالب رہنے کے لئے۔ ہمارے مدل کی تعریف کی تعریف معمولاً ایک بہترین مدل کی بات سے کمزور ہے، لیکن یہ اکثر عملکرد فاصلہ کو کامل غلط بات کے مطابق دور کرتا ہے.', 'vi': 'Các mô hình hiểu ngôn ngữ tự nhiên hiện đại phụ thuộc vào sự nhúng đầu từ trước, nhưng ứng dụng có thể cần phải lý lẽ về những từ chưa bao giờ hay hiếm khi được thấy trong quá trình đào tạo. Chúng tôi cho thấy những ví dụ dựa trên những từ hiếm hơn mới là đầy thử thách với các mô hình nhận biết ngôn ngữ tự nhiên. Sau đó chúng ta sẽ tìm hiểu làm thế nào để học cách dùng định nghĩa, được cung cấp trong văn bản tự nhiên, để vượt qua tật xấu này. Sự hiểu biết của mô- đun của chúng tôi về một định nghĩa thường yếu hơn so với việc ghép từ được mô hình hóa, nhưng nó thu hồi hầu hết các lỗ hiệu suất bằng một từ hoàn toàn chưa được đào tạo.', 'uz': "Name Biz misollarni ko'rsatganimiz, qisqa so'z bilan qisqa so'zga ishlatadigan misollarni o'rganamiz, tabiiy tilning kasalliklari modellari uchun juda qiyin edi. Keyin biz model qanday o'rganishni o'rganish mumkin, aslida matnni o'rganish mumkin, bu qo'llanmalarni ushlab chiqarish uchun. Bizning modelimizning aniqlashni oddiy o'xshash modeldagi so'zdan yoqtirgan so'zni tushunishimiz mumkin, lekin buning ko'pchiligi o'zgarishni butunlay o'zgartiradi.", 'bg': 'Модерните модели за разбиране на естествения език зависят от предварително тренирани вграждания на поддуми, но приложенията може да се наложи да разсъждават за думи, които никога или рядко не са били виждани по време на предтрениране. Показваме, че примерите, които зависят критично от по-рядка дума, са по-предизвикателни за моделите на естествени езикови изводи. След това изследваме как един модел може да се научи да използва дефиниции, предоставени в естествен текст, за да преодолее този недостатък. Разбирането на дефиницията на нашия модел обикновено е по-слабо от добре моделирана дума вграждане, но възстановява по-голямата част от разликата в ефективността от използването на напълно необучени думи.', 'nl': 'Moderne modellen voor het begrijpen van natuurlijke taal zijn afhankelijk van vooraf getrainde subwoordinsluitingen, maar toepassingen moeten mogelijk redeneren over woorden die nooit of zelden werden gezien tijdens pretraining. We laten zien dat voorbeelden die kritisch afhankelijk zijn van een zeldzamer woord uitdagender zijn voor natuurlijke taalinferentiemodellen. Vervolgens onderzoeken we hoe een model kan leren om definities in natuurlijke tekst te gebruiken om deze handicap te overwinnen. Ons model begrijpt een definitie meestal zwakker dan een goed gemodelleerd woord embedding, maar het herstelt het grootste deel van de prestatiekloof door het gebruik van een volledig ongetraind woord.', 'da': 'Moderne modeller for forståelse af naturlige sprog afhænger af forudtrænede underordsindlejringer, men programmer kan være nødt til at tænke over ord, der aldrig eller sjældent blev set under forudtræningen. Vi viser, at eksempler, der afhænger kritisk af et sjældent ord, er mere udfordrende for natursprogets inference modeller. Derefter undersøger vi, hvordan en model kunne lære at bruge definitioner, der findes i naturlig tekst, til at overvinde dette handicap. Vores models forståelse af en definition er normalt svagere end en velmodelleret ordindlejring, men det genopretter det meste af præstationshullet ved at bruge et helt utrænet ord.', 'hr': 'Moderni modeli razumijevanja prirodnog jezika zavise od ugrađenih podriječja, ali primjene mogu morati razumjeti o riječima koje nisu nikada ili rijetko vidjeli tijekom pretkivanja. Pokazujemo da su primjeri koji kritično zavise od riječi riječi izazovniji za model infekcije prirodnog jezika. Onda istražujemo kako bi model mogao naučiti koristiti definicije, pružene u prirodnom tekstu, kako bi prevazili ovaj handikap. Razumijevanje našeg model a o definiciji obično je slabije od dobro modelirane riječi uključujući, ali većina praznina učinkovitosti se povlači od upotrebe potpuno neodređene riječi.', 'id': "Model pemahaman bahasa alami modern bergantung pada embedding subword yang dilatih sebelumnya, tetapi aplikasi mungkin perlu alasan tentang kata-kata yang tidak pernah atau jarang terlihat selama berlatih. Kami menunjukkan bahwa contoh-contoh yang bergantung kritis pada kata yang lebih langka adalah lebih menantang untuk model bahasa alam inferensi. Lalu kita menjelajahi bagaimana model bisa belajar menggunakan definisi, disediakan dalam teks alami, untuk mengatasi cacat ini. Our model's understanding of a definition is usually weaker than a well-modeled word embedding, but it recovers most of the performance gap from using a completely untrained word.", 'de': 'Moderne Modelle für das Verständnis natürlicher Sprache hängen von vortrainierten Unterworteinbettungen ab, aber Anwendungen müssen möglicherweise über Wörter nachdenken, die während des Vortrainings nie oder selten gesehen wurden. Wir zeigen, dass Beispiele, die kritisch von einem selteneren Wort abhängen, für natursprachliche Inferenzmodelle eine größere Herausforderung darstellen. Dann untersuchen wir, wie ein Modell lernen könnte, Definitionen, die im natürlichen Text bereitgestellt werden, zu verwenden, um dieses Handicap zu überwinden. Das Verständnis einer Definition in unserem Modell ist normalerweise schwächer als ein gut modelliertes Wort Einbettung, aber es behebt den größten Teil der Leistungslücke durch die Verwendung eines völlig ungeübten Wortes.', 'fa': 'مدل\u200cهای درک زبان طبیعی مدرن بستگی دارند از جمله\u200cهای زیر کلمه\u200cهای پیش\u200cفرض شده، ولی برنامه\u200cها ممکن است به دلیل\u200cهای کلمه\u200cهایی که در طول پیش\u200cفرض هرگز یا نادر دیده نشده باشند دلیل بگیرند. ما نشان می دهیم که مثالهایی که به ریاضی بر یک کلمه کمتر بستگی دارند برای مدل آلودگی زبان طبیعی بیشتر مشکل کنند. سپس ما کشف می\u200cکنیم که چگونه یک مدل می\u200cتواند از تعریف\u200cها استفاده کند، که در متن طبیعی ارائه می\u200cشود، برای تغییر دادن این بدبختی. درک یک تعریف مدل ما معمولاً ضعیف تر از یک کلمه بسیار قابل مدل است، ولی بیشترین فاصله عملکرد را از استفاده از کلمه کاملا بی پایه بازیافت می کند.', 'sw': 'Mradi wa kuelewa lugha za asili wa sasa unategemea kutegemea matumizi ya neno la chini, lakini matumizi yanaweza kuhitaji maana kuhusu maneno ambayo hayakuwahi kuonekana na wakati wa mvua. Tunaonyesha kuwa mifano ambayo yanategemea kwa muhimu kwa neno nadra zaidi ni changamoto zaidi kwa mifano ya maambukizi ya lugha asilia. Kisha tunagundua jinsi mifano inavyoweza kujifunza kutumia ufafanuzi, ambao umetolewa kwa ujumbe wa asili, ili kushinda mkono huu. Kuelewa kwa mifano yetu kwa ufafanuzi mara nyingi ni dhaifu kuliko neno lililopandishwa vizuri, lakini inarudisha upepo wa utendaji kutoka kwa kutumia neno lisiloeleweka kabisa.', 'tr': 'Modern tebigy dil düşünme modelleri öňünden ýakyn sözler içinde baglanýar, ýöne uygulamalar ýakyn ýakyn sözler barada hiç haçan görülmeýän sözler barada sebäbi gerek. Biz esaslaryň täsirli dilleriň azaltylyk nusgalaryna näbelli däldigini görkeýäris. Sonra bir nusga tebigy metinde berilen definisyony nädip öwrenip biljekdigini gözləýäris. Biziň nusgamyzyň definisyonyň düşünmesi adatça gowy modellen s özlerden puç bolýar, ýöne bu ýerde ýagşyrmaýan söz ulanmakdan köp bölegi ýeterlik edip bilýär.', 'af': "Moderne natuurlike taal verstaan modele afhang van voorreine subwoord inbêdings, maar toepassings mag dalk nodig om rede te doen oor woorde wat nooit of selfs gesien word tydens voorrekening nie. Ons wys dat voorbeelde wat kritiese afhang van 'n rarer woord is meer challenging vir natuurlike taal inferensie modele. Toe ondersoek ons hoe 'n model kan leer om definisies te gebruik, verskaf in natuurlike teks, om hierdie handikap te oorwin. Ons model se verstanding van 'n definisie is gewoonlik swakker a s 'n goed modelleerde woord ingesluit, maar dit herstel die meeste van die prestasie afstand van die gebruik van 'n heeltemal ongereënde woord.", 'sq': 'Modelet moderne të kuptimit të gjuhës natyrore varen nga përfshirjet e paramësuara të nënfjalëve, por aplikimet mund të kenë nevojë të arsyetojnë për fjalë që nuk janë parë kurrë apo rrallë gjatë paramësimit. Ne tregojmë se shembujt që varen kritikisht nga një fjalë më e rrallë janë më të sfidueshëm për modelet e përfundimit natyror të gjuhës. Then we explore how a model could learn to use definitions, provided in natural text, to overcome this handicap.  Përkuptimi i model it tonë i një përcaktimi është zakonisht më i dobët se një fjalë e modeluar mirë, por ajo rikuperon shumicën e daljes s ë paraqitjes nga përdorimi i një fjale krejtësisht të pakrainuar.', 'am': 'የአሁኑ የፍጥረት ቋንቋ ማስተዋል ምሳሌዎች የደብዳቤ ቃላት መግለጫ ነው፤ ነገር ግን በዝናብ ጊዜ ያልታዩት ወይም በጥቂት ጊዜ ያልታዩት ቃላት ያስፈልጋል፡፡ ምሳሌዎችን እናሳያቸዋለን፣ በአካባቢ ቃላት ላይ የሚታመሙ ለፍጥረት ቋንቋ ደካማነት ምሳሌዎች የሚጠቃቀሙ ናቸው፡፡ ከዚህም በኋላ ምሳሌ እንዴት መግለጫ ለመጠቀም፣ በፍጥረት ጽሑፍ ለመጠቀም፣ ይህንን እጃን ለማሸንፍ ይችላል፡፡ የዓይነታችን ምሳሌ መግለጫ በተለየ መልካም ቃላት ከመጠቀም ይልቅ ደካማ ነው፤ ነገር ግን በሙሉ ያልታወቀ ቃልን ከመጠቀም የበዛውን የሥርዓት ክፍል ይመልሳል፡፡', 'az': 'Şimdiki təbiətli dil anlama modelləri əvvəlcə belə yazılmış sözlərə bağlı olar, amma proqramların əvvəlki sözlər haqqında heç vaxt görmədikləri və ya az görünmədikləri sözlər haqqında düşünməsi lazımdır. Biz müxtəlif sözlərə daha az bağlı nümunələrin təbiətli dil infeksiya modellərinə daha çətin olduğunu göstəririk. Sonra bir modeli təbiətli mətndə təşkil edilmiş tanımlamaları necə öyrənə biləcəyini keşfetirik, bu çətinlikləri üstün etmək üçün. Bizim modelimizin tanımlaması genellikle modelləşdirilmiş s özdən daha zəif idi, amma bu, tamamilə müəyyən edilməmiş sözlərdən istifadə etməkdən çox performans boşluğunu geri qaytarır.', 'hy': 'Հիմա ժամանակակից բնական լեզվի հասկանալու մոդելները կախված են նախօրինակված ենթաբառերի ներդրումից, բայց ծրագրերը կարող են պետք է մտածեն բառերի մասին, որոնք երբեք կամ հազվադեպ չեն տեսել նախօրինակման ժամանակ: Մենք ցույց ենք տալիս, որ օրինակները, որոնք կարևորաբար կախված են ավելի հազվադեպ բառից, ավելի դժվար են բնական լեզվի եզրակացության մոդելների համար: Հետո մենք ուսումնասիրում ենք, թե ինչպես կարող է մոդելը սովորել օգտագործել բնական տեքստում ներկայացված սահմանափակումներ, որպեսզի հաղթահարի այս խնդիրը: Մեր մոդելի սահմանման հասկացությունը սովորաբար ավելի թույլ է, քան լավ մոդելավորված բառը, բայց այն վերականգնում է արդյունավետության տարբերությունների մեծ մասը միանգամայն անփորձարկված բառից օգտագործելով:', 'ko': '현대 자연 언어 이해 모델은 예비 훈련의 자어 삽입에 의존하지만 응용 프로그램은 예비 훈련 기간에 본 적이 없거나 드문 단어를 추리해야 할 수도 있다.우리는 자연 언어 추리 모델에 있어 더욱 희귀한 단어에 엄격하게 의존하는 예가 더욱 도전적이라는 것을 발견했다.그리고 우리는 모델이 자연 텍스트에서 제공한 정의를 어떻게 사용해서 이 장애를 극복하는지 탐색한다.우리의 모델은 정의에 대한 이해가 일반적으로 모델에 좋은 단어보다 약하지만, 완전히 훈련되지 않은 단어를 사용하는 대부분의 성능 차이를 보완한다.', 'bn': 'আধুনিক প্রাকৃতিক ভাষায় বুঝতে পারার মডেলের উপর নির্ভর করে, কিন্তু প্রাকৃতিক ভাষার প্রাকৃতিক ভাষার ব্যাখ্যা নির্ভর করে  We show that examples that depend critically on a rarer word are more challenging for natural language inference models.  তারপর আমরা খুঁজে বের করি কিভাবে একটি মডেল ব্যবহার করতে পারে, যা প্রাকৃতিক লেখায় প্রদান করা হয়েছে, এই হাতিয়ার উপর জয় করতে। আমাদের মডেলের বোঝা সাধারণত ভালো মডেলের চেয়ে দুর্বল, কিন্তু এটা পুরোপুরি অশ্লীল শব্দ ব্যবহার থেকে প্রদর্শনের বেশীরভাগ পার্থক্য প', 'ca': "Modern natural language understanding models depend of pre-trained subword embeddings, but applications may need to reason about words that were never or rarely seen during pre-training. Mostrem que els exemples que depenen críticament d'una paraula més rara són més desafiants per als models de inferència de llenguatges naturals. Després explorem com un model podria aprendre a utilitzar definicions, proporcionades en text natural, per superar aquest handicap. La comprensió del nostre model d'una definició és normalment més dèbil que l'incorporació d'una paraula ben modelada, però recupera la majoria de la diferència de rendiment fent servir una paraula completament no entrenada.", 'bs': 'Moderni modeli razumijevanja prirodnog jezika zavise od ugrađenih podriječja, ali aplikacije mogu morati razumjeti o riječima koje nisu nikada ili rijetko vidjele tijekom pretkivanja. Pokazujemo da su primjeri koji kritično zavise od riječi riječi izazovniji za model infekcije prirodnog jezika. Onda istražujemo kako bi model mogao naučiti da koristi definicije, pružene u prirodnom tekstu, kako bi prevazili ovaj handikap. Razumijevanje našeg model a o definiciji obično je slabije od dobro modelirane riječi uključujući, ali se povlači većina praznika performanstva od upotrebe potpuno neodređene riječi.', 'cs': 'Moderní modely porozumění přirozenému jazyku závisí na předtrénovaných vloženích podslov, ale aplikace mohou potřebovat uvažovat o slovech, která nebyla nikdy nebo zřídka viděna během předtrénování. Ukazujeme, že příklady, které kriticky závisí na vzácnějším slovu, jsou pro modely inference přirozeného jazyka náročnější. Dále zkoumáme, jak by se model mohl naučit používat definice uvedené v přirozeném textu k překonání tohoto handicapu. Porozumění definici našeho modelu je obvykle slabší než dobře modelované vložení slov, ale obnoví většinu výkonnostních mezer z použití zcela netrénovaného slova.', 'et': 'Kaasaegsed looduskeele mõistmise mudelid sõltuvad eeltreenitud alamsõna manustamisest, kuid rakendustel võib olla vaja mõelda sõnu, mida ei nähtud kunagi või harva eeltreeningu ajal. Näitame, et näited, mis sõltuvad kriitiliselt haruldasest sõnast, on looduskeele järeldusmudelite jaoks keerulisemad. Seejärel uurime, kuidas mudel võiks õppida kasutama looduslikus tekstis esitatud määratlusi selle puuduse ületamiseks. Meie mudeli arusaam definitsioonist on tavaliselt nõrgem kui hästi modelleeritud sõna manustamine, kuid see taastab enamiku jõudluslüngast täiesti treenimata sõna kasutamisest.', 'fi': 'Nykyaikaiset luonnollisen kielen ymmärtämismallit riippuvat esikoulutetuista alasanojen upotuksista, mutta sovellusten on ehkä pohdittava sanoja, joita ei koskaan tai harvoin nähty esikoulutuksen aikana. Osoitamme, että harvinaisemmasta sanasta kriittisesti riippuvaiset esimerkit ovat haastavampia luonnollisen kielen päättelymalleille. Sitten tutkimme, miten malli voisi oppia käyttämään luonnollisessa tekstissä annettuja määritelmiä tämän haitan voittamiseksi. Mallimme käsitys määritelmästä on yleensä heikompi kuin hyvin mallinnettu sana upotus, mutta se palauttaa suurimman osan suoritusvajeesta täysin kouluttamattoman sanan käytöstä.', 'ha': "Ana ƙayyade misãlai masu hankali da harshen yanzu a yanzu, masu ƙayyade a kan late-faɗi masu ƙaranci, kuma amma yana son shiryoyin ayukan ayuka da ba'a gane su ba a lokacin da ake yi wa lõkaci ba. We show that examples that depend critically on a rarer word are more challenging for natural language inference models.  Sa'an nan kuma muna gane yadda misalin ya iya amfani da fassarar, wanda aka bai wa a cikin littãfin ne, dõmin ya rinjãye wannan hannayen. Jami'anin misalinmu ya fi rauni ko da maganar da aka faɗa mai kyau, kuma amma yana sami mafi yawan gaura na aikin kada ya yi amfani da wani magana wanda ba'a yi bango ba.", 'he': 'מודלים מודרניים להבנת שפת טבעית תלויים בתכניות מתחת למילות מתאימות מראש, אך ייתכן שהתכניסים צריכים להסביר על מילים שלא נראו מעולם או לעיתים נדירות במהלך התכנית. אנו מראים שדוגמאות שמתלויות ביקורתית במילה נדירה יותר מאתגרות לדוגמאות ההנחה של שפה טבעית. ואז אנו חוקרים איך דוגמנית יכולה ללמוד להשתמש בהגדרות, מוספקות בטקסט טבעי, כדי להתגבר על הנכון הזה. ההבנה של המודל שלנו של הגדרה בדרך כלל חלשה ממילה מודל היטב, אבל היא מחזיקה את רוב הפער ביצועים משימוש במילה בלתי מאומנת לחלוטין.', 'jv': 'Model sing perusahaan anyar, kuwi nggunakake sistem kuwi mau, dadi akeh basa isuk tentang kanggo awak dhéwé kuwi mau, ngono aplikasi iso disimpen awak dhéwé durung apik dhéwé, ora bisa ngejarakake sing apik dhéwé. Awak dhéwé éntuk akeh kudu akeh pisan neng akeh yèn dhéwé kuwi duluran gambar nggawe modèl kuwi tarjamahan. Amargi kapan kelas kuwi model iso nggambar nggawe Ketoken, nggawe Ketoken Pribadi, nggawe barang manut iki. Awakdhéwé model sing paling ngregani uwis kuwi adalah sing ngomong nik awak dhéwé model sing bisa basa, nanguwis kuwi tindakan kesempatan awak dhéwé kuwi bisa pasar awak dhéwé.', 'sk': 'Sodobni modeli razumevanja naravnih jezikov so odvisni od predtreniranih vdelav podbesed, vendar bodo aplikacije morda morale razumeti besede, ki niso bile nikoli ali redko videne med predtreniranjem. Pokazali smo, da so primeri, ki so kritično odvisni od redkejše besede, bolj izzivni za modele sklepanja naravnega jezika. Nato raziskujemo, kako bi se model lahko naučil uporabljati definicije iz naravnega besedila za premagovanje te ovire. Razumevanje definicije našega modela je običajno šibkejše od dobro modelirane besede vključevanja, vendar večino vrzeli v učinkovitosti ob uporabi popolnoma neizurjene besede.', 'bo': 'ད་ལྟོའི་རང་བཞིན་པའི་སྐད་ཡིག་གཟུགས་འགྱུར་བའི་རྣམ་པ་ཚིག་མཐུན་གྱིས་ཕན་ཚུན་ཡོད་པའི་ཁྱད་པར་རྟེན་ཏེ། འུ་ཅག་གིས་དཔེར་བརྗོད་དག་དེ་དག་ནི་སྐད་ཆ་ཉུང་བའི་ཐ་སྙད་ཅིག འོན་ཀྱང་། ང་ཚོས་མིག ང་ཚོའི་མ་དབྱིབས་བཀོད་པའི་ངོ་བོ་ལ་དམིགས་འཛུགས་ཀྱི་གནད་དོན་དག་ནི་རྒྱུན་ལྡན་མེད་པའི་ཐ་སྙད་ཅིག་ལས་ཉུང་པོ་ཞིག་ཡིན།'}
