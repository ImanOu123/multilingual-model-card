{'en': 'Embedded-State Latent Conditional Random Fields for Sequence Labeling', 'ar': 'الحقول العشوائية الشرطية الكامنة المضمنة في الحالة المدمجة لتوسيم التسلسل', 'fr': "Champs aléatoires conditionnels latents à l'état intégré pour l'étiquetage des séquences", 'es': 'Campos aleatorios condicionales latentes de estado incrustado para el etiquetado de secuencias', 'pt': 'Campos aleatórios condicionais latentes de estado incorporado para rotulagem de sequência', 'ja': 'シーケンスラベリングの埋め込み状態の潜在的な条件付きランダムフィールド', 'hi': 'अनुक्रम लेबलिंग के लिए एम्बेडेड-स्थिति अव्यक्त सशर्त यादृच्छिक फ़ील्ड', 'zh': '以序标记者,随机字段', 'ru': 'Встроенные скрытые условные случайные поля для маркировки последовательностей', 'ga': 'Réimsí Randamach Coinníollacha Folaigh Leabaithe le haghaidh Lipéadú Seicheamh', 'ka': 'შებეჭირებული სტატის შემდეგ კონდიციონალური პანელები', 'it': "Campi casuali condizionali latenti incorporati per l'etichettatura di sequenza", 'hu': 'Beágyazott állapotú későbbi feltételes véletlenszerű mezők a sorozatcímkézéshez', 'el': 'Ενσωματωμένα λανθάνοντα τυχαία πεδία υπό όρους για επισήμανση ακολουθίας', 'ms': 'Medan Rawak Kebelakangan-Keadaan Terisi untuk Label Kelajuan', 'ml': 'സെക്കന്\u200dസ് ലാബിലിങ്ങിനുള്ള ഇംബെഡ്ഡ് സ്റ്റേറ്റ് സ്റ്റേറ്റ് ലാറ്റിങ്ങിന്റെ അവസാനത്തെ അവസ', 'kk': 'Ендірілген күй- жай реттеу жарлығының кейінгі шарттар кездейсоқ өрістері', 'lt': 'Įterptos valstybės vėlesnės sąlygos atsitiktiniai sekos ženklinimo laukai', 'mk': 'Вградено- државно последно условно случајно поле за означување на секвенција', 'mn': 'Дараагийн лаборатор дамжуулагдсан хамгийн дараагийн шаардлагатай санамсаргүй талбар', 'no': 'Innebygd tilstand seinare vilkårleg felter for sekvensetiketting', 'pl': 'Latentne warunkowe pola losowe w stanie wbudowanym do etykietowania sekwencji', 'ro': 'Câmpuri aleatorii condiționate latente încorporate pentru etichetarea secvențelor', 'si': 'සම්බන්ධ- තාත්තා පස්සේ සාමාන්\u200dය ස්ථානයක් ලේබෙලින් වෙනුවෙන් සිදුවීම් ක්\u200dෂේත්\u200dරය', 'so': 'Halkan ugu dambeeyay', 'mt': 'Qasam Random Kondizzjonali Latenti tal-Istat Integrat għat-Tikkettar tas-Sekwenza', 'ur': 'سکوئنس لابلینگ کے لئے انڈیڈ- سٹیٹ لیٹ لیٹ', 'sr': 'Uključeni državni kasni uslovni slučajni polji za označavanje sekvence', 'ta': 'உட்பொதிந்த நாட்டின் தற்போதைய நிலையில் குறிப்பில்லாத புலம்', 'sv': 'Inbyggda latenta villkorliga slumpmässiga fält för sekvensmärkning', 'uz': '@ info: whatsthis', 'vi': 'Các trường ngẫu nhiên đặt chế tạo biểu tượng dãy', 'bg': 'Вградено състояние Latent Conditional Random Fields for Sequence Labeling', 'hr': 'Sljedeće uvjetne slučajne polje za označavanje sekvence', 'nl': 'Latente voorwaardelijke willekeurige velden in ingesloten toestand voor sequentielabeling', 'da': 'Indlejret tilstand Latent betinget tilfældige felter til sekvensmærkning', 'de': 'Latente bedingte Random Fields im eingebetteten Zustand für die Sequenzbeschreibung', 'id': 'Embedded-State Latent Conditional Random Fields for Sequence Labeling', 'fa': 'پایگاه\u200cهای تصادفی در حالت تاریخی در وضعیت وارد شده\u200c', 'ko': '시퀀스 표시에 사용되는 삽입 상태 잠재 조건 랜덤 필드', 'sw': 'Maeneo ya Hali ya Nchi Zinazoishi', 'tr': 'Indiki Durum Zolaky', 'af': 'Inbêer- staat Latent kondisionale Lukrake Velde vir Volgorde Etiket', 'sq': 'Fushat e rastësishme me kushte të mëvonshme të shtetit të integruar për etiketën e sekuencës', 'am': 'undo-type', 'hy': 'Comment', 'az': 'S캼radan Etilm톛si 칲칞칲n S캼radan S캼radan S캼radan 쿮lav톛 Sah톛l톛ri', 'bs': 'Sljedeći slučajni slučajni polji za označavanje sekvence', 'ca': "Camps aleatoris condicionals posteriors d'estat incorporat per etiquetar la seqüència", 'bn': 'সেকেন্ড ল্যাবিং এর জন্য আবদ্ধ রাষ্ট্রের সাম্প্রতিক পরিস্থিতির ক্ষেত্র', 'cs': 'Vložená latentní podmíněná náhodná pole pro popisování sekvencí', 'et': 'Põimitud oleku latentsed tingimuslikud juhusväljad järjestuse märgistamiseks', 'fi': 'Sulautetut tilaviiveelliset ehdolliset satunnaiskentät sekvenssimerkintöjä varten', 'sk': 'Vgrajena pogojna naključna polja za označevanje zaporedja', 'ha': '@ label: listbox', 'he': 'שדות אקראיות במדינה מוכנות לאחרונה לתווית', 'jv': 'politenessoffpolite"), and when there is a change ("assertive', 'bo': 'ནང་འདྲེན་པའི་གནས་སྟངས་ཁྱད་པར་རྗེས་མའི་སྣང་ཚུལ་གྱིས་རྗེས་ཀྱི་འཇུག་སྟངས་སྔོན་སྒྲིག'}
{'en': 'Complex textual information extraction tasks are often posed as ', 'ar': 'غالبًا ما يتم طرح مهام استخراج المعلومات النصية المعقدة كتوسيم تسلسلي أو تحليل ضحل ، حيث يتم استخراج الحقول باستخدام تسميات محلية متسقة من خلال الاستدلال الاحتمالي في نموذج رسومي مع انتقالات مقيدة. في الآونة الأخيرة ، أصبح من الشائع تحديد هذه النماذج محليًا باستخدام ميزات غنية مستخرجة من الشبكات العصبية المتكررة (مثل LSTM) ، مع فرض مخرجات متسقة من خلال نموذج سلسلة خطية بسيط ، يمثل تبعيات ماركوفيان بين التسميات المتتالية. ومع ذلك ، فإن بنية النموذج الرسومي البسيط تتناقض مع القيود غير المحلية المعقدة في كثير من الأحيان بين تسميات الإخراج. على سبيل المثال ، يمكن أن تظهر العديد من الحقول ، مثل الاسم الأول فقط لعدد ثابت من المرات ، أو في وجود حقول أخرى. في حين أن RNNs قد وفرت ميزات محلية مدركة للسياق قوية بشكل متزايد لوضع علامات التسلسل ، إلا أنها لم يتم دمجها مع نموذج رسومي عالمي للتعبير المماثل في توزيع المخرجات. يتجاوز نموذجنا السلسلة الخطية CRF لدمج حالات مخفية متعددة لكل تسمية مخرجات ، ولكن يقوم بتجميعها بشكل شحيح مع مصفوفات تسجيل ذات إمكانات تسجيل منخفضة الرتبة ، مما يؤدي إلى تعلم مساحة التضمين للحالات المخفية بشكل فعال. تكمل هذه المساحة الكامنة المتزايدة لمتغيرات الاستدلال تمثيل الميزات الغنية لـ RNN ، وتسمح بالاستدلال الشامل الدقيق الذي يخضع لقيود الإخراج غير المحلية المعقدة والمكتسبة. نجرب مع العديد من مجموعات البيانات ونوضح أن النموذج يتفوق على خط الأساس\nنماذج CRF + RNN عندما تكون قيود الإخراج العالمية ضرورية في وقت الاستدلال ، واستكشاف البنية الكامنة القابلة للتفسير.', 'pt': 'Tarefas complexas de extração de informações textuais geralmente são colocadas como rotulagem de sequência ou análise superficial, onde os campos são extraídos usando rótulos locais consistentes por meio de inferência probabilística em um modelo gráfico com transições restritas. Recentemente, tornou-se comum parametrizar localmente esses modelos usando recursos ricos extraídos por redes neurais recorrentes (como LSTM), enquanto reforçam saídas consistentes por meio de um modelo de cadeia linear simples, representando dependências markovianas entre rótulos sucessivos. No entanto, a estrutura do modelo gráfico simples desmente as restrições não locais muitas vezes complexas entre os rótulos de saída. Por exemplo, muitos campos, como um primeiro nome, podem ocorrer apenas um número fixo de vezes ou na presença de outros campos. Embora as RNNs tenham fornecido recursos locais com reconhecimento de contexto cada vez mais poderosos para marcação de sequência, elas ainda precisam ser integradas a um modelo gráfico global de expressividade semelhante na distribuição de saída. Nosso modelo vai além do CRF de cadeia linear para incorporar vários estados ocultos por rótulo de saída, mas os parametriza com parcimônia com matrizes de pontuação de potencial logarítmico de baixa classificação, aprendendo efetivamente um espaço de incorporação para estados ocultos. Esse espaço latente aumentado de variáveis de inferência complementa a rica representação de recursos do RNN e permite inferência global exata obedecendo a restrições de saída não locais complexas e aprendidas. Experimentamos vários conjuntos de dados e mostramos que o modelo supera a linha de base\nModelos CRF+RNN quando restrições globais de saída são necessárias no momento da inferência e exploram a estrutura latente interpretável.', 'ja': '複雑なテキスト情報抽出タスクは、多くの場合、シーケンスラベルまたは浅い解析として提示され、フィールドは、制約された遷移を有するグラフィカルモデルで確率的推論を通じて一貫して行われるローカルラベルを使用して抽出される。 最近では、連続するラベル間のマルコフ依存性を表す単純な線形鎖モデルを通じて一貫した出力を強制しながら、再帰的ニューラルネットワーク（ ＬＳＴＭなど）によって抽出された豊富な特徴を使用してこれらのモデルをローカルにパラメータ化することが一般的になってきている。 しかし、単純なグラフィカルモデル構造はしばしば出力ラベル間の複雑な非局所的制約を嘘つきにする。 たとえば、ファーストネームなどの多くのフィールドは、一定回数、または他のフィールドの存在下でのみ発生することができます。 RNNは、シーケンスタグ付けのためにますます強力なコンテキスト認識ローカル機能を提供してきたが、それらは、出力分布における同様の表現性のグローバルグラフィックモデルと統合されていない。 私たちのモデルは、線形連鎖CRFを超えて、出力ラベルごとに複数の隠れた状態を組み込んでいますが、低ランクの対数電位スコアリングマトリクスでパラメータ化し、隠れた状態の埋め込み空間を効果的に学習します。 推論変数のこの拡張潜在空間は、RNNの豊富な特徴表現を補完し、複雑で学習された非局所的な出力制約に従う正確なグローバル推論を可能にする。 いくつかのデータセットで実験を行い、モデルがベースラインを上回っていることを示します\n推論時間でグローバルな出力制約が必要な場合にCRF + RNNモデルを作成し、解釈可能な潜在構造を探る。', 'fr': "Les tâches d'extraction d'informations textuelles complexes se présentent souvent sous la forme d'un étiquetage de séquence ou d'une analyse superficielle, où les champs sont extraits à l'aide d'étiquettes locales rendues cohérentes par inférence probabiliste dans un modèle graphique avec des transitions contraintes. Récemment, il est devenu courant de paramétrer localement ces modèles à l'aide de riches caractéristiques extraites par des réseaux neuronaux récurrents (tels que LSTM), tout en imposant des sorties cohérentes via un modèle de chaîne linéaire simple, représentant les dépendances markoviennes entre les étiquettes successives. Cependant, la structure graphique simple du modèle ne tient pas compte des contraintes non locales souvent complexes entre les étiquettes de sortie. Par exemple, de nombreux champs, tels qu'un prénom, ne peuvent apparaître qu'un certain nombre de fois ou en présence d'autres champs. Alors que les RNN ont fourni des fonctionnalités locales sensibles au contexte de plus en plus puissantes pour le marquage de séquences, ils n'ont pas encore été intégrés à un modèle graphique global d'expressivité similaire dans la distribution de sortie. Notre modèle va au-delà de la CRF de chaîne linéaire pour intégrer plusieurs états cachés par étiquette de sortie, mais les paramétrise de manière parcimonieuse avec des matrices de notation de potentiel logarithmique de bas rang, apprenant ainsi efficacement un espace d'intégration pour les états cachés. Cet espace latent augmenté de variables d'inférence complète la représentation riche en caractéristiques du RNN et permet une inférence globale exacte obéissant à des contraintes de sortie non locales complexes apprises. Nous expérimentons plusieurs ensembles de données et montrons que le modèle surpasse la valeur de référence\nLes modèles CRF+RNN lorsque des contraintes de sortie globales sont nécessaires au moment de l'inférence, et explorent la structure latente interprétable.", 'es': 'Las tareas complejas de extracción de información textual a menudo se plantean como etiquetado de secuencia o análisis superficial, donde los campos se extraen mediante etiquetas locales que se hacen consistentes mediante la inferencia probabilística en un modelo gráfico con transiciones restringidas. Recientemente, se ha vuelto común parametrizar localmente estos modelos utilizando características enriquecidas extraídas por redes neuronales recurrentes (como LSTM), al tiempo que se aplican resultados consistentes a través de un modelo simple de cadena lineal, que representa las dependencias markovianas entre etiquetas sucesivas. Sin embargo, la estructura del modelo gráfico simple contradice las restricciones no locales, a menudo complejas, entre las etiquetas de salida. Por ejemplo, muchos campos, como el nombre, solo pueden aparecer un número fijo de veces o en presencia de otros campos. Si bien las RNN han proporcionado características locales sensibles al contexto cada vez más potentes para el etiquetado de secuencias, aún no se han integrado con un modelo gráfico global de expresividad similar en la distribución de salida. Nuestro modelo va más allá de la cadena lineal CRF para incorporar múltiples estados ocultos por etiqueta de salida, pero los parametriza parsimoniosamente con matrices de puntuación de potencial logarítmico de bajo rango, aprendiendo efectivamente un espacio de incrustación para estados ocultos. Este espacio latente aumentado de variables de inferencia complementa la rica representación de características de la RNN y permite la inferencia global exacta obedeciendo restricciones de salida no locales complejas y aprendidas. Experimentamos con varios conjuntos de datos y demostramos que el modelo supera el rendimiento de la línea base\nCRF+RNN modela cuando las restricciones de producción global son necesarias en el momento de la inferencia y exploran la estructura latente interpretable.', 'zh': '杂文本信息提取职常呈为序浅层解析,其字段用有约束转换图形模型中概率推理成一者标签提取。 近者,用递归神经网络(如LSTM)取多参数常见,兼以简线性强制执行一者输之,表连表之马尔可夫也。 然简图结构,非局束也。 如诸字段(如名)但有定数,或在他字段。 虽 RNN 为序表益强上下文感知本地功能,然未与输出布中相似表现力全局图形集成。 吾模越线性CRF,为输标并数藏,而用卑秩对数电位评分矩阵参数化之,效学嵌空。 推理变量者,空补RNN之丰,并许精确全局推理从杂者,学非局输约束。 试之数集,形胜基线\nCRF+RNN 推理须全局输出约束时建模,并探可解之潜在结构。', 'hi': 'जटिल पाठ्य जानकारी निष्कर्षण कार्यों को अक्सर अनुक्रम लेबलिंग या उथले पार्सिंग के रूप में प्रस्तुत किया जाता है, जहां क्षेत्रों को स्थानीय लेबल का उपयोग करके निकाला जाता है, जो सीमित संक्रमण के साथ एक ग्राफिकल मॉडल में संभाव्य अनुमान के माध्यम से सुसंगत होते हैं। हाल ही में, आवर्तक तंत्रिका नेटवर्क (जैसे एलएसटीएम) द्वारा निकाली गई समृद्ध सुविधाओं का उपयोग करके इन मॉडलों को स्थानीय रूप से पैरामेट्रिज़ करना आम हो गया है, जबकि एक साधारण रैखिक-श्रृंखला मॉडल के माध्यम से लगातार आउटपुट को लागू करना, क्रमिक लेबल के बीच मार्कोवियन निर्भरताओं का प्रतिनिधित्व करता है। हालांकि, सरल ग्राफिकल मॉडल संरचना आउटपुट लेबल के बीच अक्सर जटिल गैर-स्थानीय बाधाओं को झुठलाती है। उदाहरण के लिए, कई फ़ील्ड, जैसे कि पहला नाम, केवल एक निश्चित संख्या में, या अन्य फ़ील्ड की उपस्थिति में हो सकता है। जबकि RNNs ने अनुक्रम टैगिंग के लिए तेजी से शक्तिशाली संदर्भ-जागरूक स्थानीय विशेषताएं प्रदान की हैं, उन्हें अभी तक आउटपुट वितरण में समान अभिव्यक्ति के वैश्विक ग्राफिकल मॉडल के साथ एकीकृत नहीं किया गया है। हमारा मॉडल आउटपुट लेबल प्रति कई छिपे हुए राज्यों को शामिल करने के लिए रैखिक श्रृंखला सीआरएफ से परे जाता है, लेकिन उन्हें कम रैंक लॉग-संभावित स्कोरिंग मैट्रिक्स के साथ पारमेट्रिज़ करता है, प्रभावी रूप से छिपे हुए राज्यों के लिए एक एम्बेडिंग स्पेस सीखता है। अनुमान चर का यह संवर्धित अव्यक्त स्थान आरएनएन के समृद्ध विशेषता प्रतिनिधित्व को पूरक करता है, और जटिल, सीखा गैर-स्थानीय आउटपुट बाधाओं का पालन करने वाले सटीक वैश्विक अनुमान की अनुमति देता है। हम कई डेटासेट के साथ प्रयोग करते हैं और दिखाते हैं कि मॉडल बेसलाइन को मात देता है\nCRF + RNN मॉडल जब वैश्विक आउटपुट बाधाएं अनुमान-समय पर आवश्यक होती हैं, और व्याख्यायोग्य अव्यक्त संरचना का पता लगाती हैं।', 'ga': 'Is minic a dhéantar tascanna casta astarraingthe faisnéise téacsúla mar lipéadú seichimh nó parsáil éadomhain, áit a mbaintear réimsí trí úsáid a bhaint as lipéid áitiúla atá comhsheasmhach trí thátal dóchúlachta i múnla grafach le haistrithe srianta. Le déanaí, tá sé coitianta paraiméadracht áitiúil a dhéanamh ar na samhlacha seo ag baint úsáide as gnéithe saibhre a bhaintear as líonraí néaracha athfhillteacha (amhail LSTM), agus aschuir chomhsheasmhacha á bhforfheidhmiú trí shamhail shlabhra líneach shimplí, a léiríonn spleáchais Markovian idir lipéid chomhleanúnacha. Mar sin féin, déanann struchtúr simplí an mhúnla grafach na srianta neamh-áitiúla idir lipéid aschuir a chasta go minic. Mar shampla, ní féidir le go leor réimsí, cosúil le céadainm, tarlú ach roinnt uaireanta seasta, nó i láthair réimsí eile. Cé go bhfuil gnéithe áitiúla atá feasach ar chomhthéacs ag éirí níos cumhachtaí curtha ar fáil ag RNNanna le haghaidh clibeáil seichimh, tá siad fós le comhtháthú le samhail ghrafach dhomhanda de shloinneadh comhchosúil sa dáileadh aschuir. Téann ár múnla níos faide ná an slabhra líneach CRF chun stáit fholaithe iolracha a ionchorprú in aghaidh an lipéid aschuir, ach déanann sé paraiméadracht iad go parsimoniously le maitrísí scórála féideartha loga íseal-ranga, ag foghlaim spás leabaithe do stáit fholaithe go héifeachtach. Comhlánaíonn an spás méadaithe folaigh seo d’athróga tátail an léiriú saibhir gné den RNN, agus ceadaíonn sé tátal cruinne cruinne ag cloí le srianta aschuir neamh-áitiúla casta, foghlamtha. Déanaimid trialacha le roinnt tacar sonraí agus léirímid go sáraíonn an tsamhail an bonnlíne\nMúnlaíonn CRF+RNN nuair a bhíonn gá le srianta aschuir dhomhanda ag am tátail, agus scrúdaíonn siad an struchtúr folaigh inléirmhínithe.', 'ru': 'Задачи извлечения сложной текстовой информации часто ставятся как маркировка последовательности или неглубокий разбор, где поля извлекаются с использованием локальных меток, сделанных согласованными посредством вероятностного вывода в графической модели с ограниченными переходами. В последнее время стало общепринятым локальное параметрирование этих моделей с использованием богатых функций, извлеченных рекуррентными нейронными сетями (такими как LSTM), в то же время обеспечивая согласованные выходы с помощью простой линейно-цепочечной модели, представляющей марковские зависимости между последовательными метками. Однако простая структура графической модели опровергает зачастую сложные нелокальные ограничения между выходными метками. Например, многие поля, такие как имя, могут встречаться только фиксированное количество раз или в присутствии других полей. Хотя RNN предоставляют все более мощные контекстно-зависимые локальные функции для маркировки последовательностей, их еще предстоит интегрировать с глобальной графической моделью аналогичной экспрессивности в распределении выходных данных. Наша модель выходит за рамки линейной цепочки ИРК, чтобы включить несколько скрытых состояний на метку выхода, но параметризует их сравнительно с матрицами оценки логарифмического потенциала низкого ранга, эффективно изучая пространство вложений для скрытых состояний. Это расширенное латентное пространство переменных вывода дополняет богатое представление признаков RNN и позволяет делать точные глобальные выводы, подчиняясь сложным, изученным нелокальным ограничениям выхода. Мы экспериментируем с несколькими наборами данных и показываем, что модель превосходит базовую\nМодели CRF+RNN, когда глобальные ограничения выхода необходимы во время вывода, и исследуют интерпретируемую скрытую структуру.', 'el': 'Οι σύνθετες εργασίες εξαγωγής πληροφοριών κειμένου συχνά τίθενται ως επισήμανση ακολουθίας ή ρηχή ανάλυση, όπου τα πεδία εξάγονται χρησιμοποιώντας τοπικές ετικέτες που γίνονται συνεπείς μέσω πιθανολογικού συμπεράσματος σε ένα γραφικό μοντέλο με περιορισμένες μεταβάσεις. Πρόσφατα, είναι συνηθισμένο να παραμετροποιούνται τοπικά αυτά τα μοντέλα χρησιμοποιώντας πλούσια χαρακτηριστικά που εξάγονται από επαναλαμβανόμενα νευρωνικά δίκτυα (όπως η LSTM), ενώ επιβάλλονται συνεπείς εξόδους μέσω ενός απλού μοντέλου γραμμικής αλυσίδας, που αντιπροσωπεύει τις Μαρκοβιανές εξαρτήσεις μεταξύ διαδοχικών ετικετών. Ωστόσο, η απλή δομή γραφικού μοντέλου αναιρεί τους συχνά σύνθετους μη τοπικούς περιορισμούς μεταξύ ετικετών εξόδου. Για παράδειγμα, πολλά πεδία, όπως ένα όνομα, μπορούν να εμφανιστούν μόνο για καθορισμένο αριθμό φορές ή με την παρουσία άλλων πεδίων. Ενώ τα RNN έχουν παράσχει όλο και πιο ισχυρά τοπικά χαρακτηριστικά για τη σήμανση ακολουθίας, δεν έχουν ακόμη ενσωματωθεί με ένα παγκόσμιο γραφικό μοντέλο παρόμοιας εκφραστικότητας στη διανομή εξόδου. Το μοντέλο μας πηγαίνει πέρα από τη γραμμική αλυσίδα για να ενσωματώσει πολλαπλές κρυφές καταστάσεις ανά ετικέτα εξόδου, αλλά τις παραμετροποιεί με πίνακες βαθμολόγησης δυναμικών καταγραφής χαμηλής κατάταξης, μαθαίνοντας αποτελεσματικά ένα χώρο ενσωμάτωσης για κρυφές καταστάσεις. Αυτός ο ενισχυμένος λανθάνοντας χώρος μεταβλητών συμπερασμάτων συμπληρώνει την πλούσια αναπαράσταση χαρακτηριστικών του και επιτρέπει ακριβή παγκόσμια συμπέρασμα υπακούοντας σύνθετους, μαθημένους μη τοπικούς περιορισμούς εξόδου. Πειραματιζόμαστε με διάφορα σύνολα δεδομένων και δείχνουμε ότι το μοντέλο ξεπερνά τη γραμμή βάσης', 'kk': 'Қосымша мәтіндік мәліметті тарқату тапсырмалары көбінесе реттеу жарлығы немесе қалқымалы талдау ретінде, жергілікті жарлық жарлықтарды қолданып, графикалық үлгісінде шектелген ауыстыру үшін, мүмкінді Жуырда бұл үлгілерді қайталанатын невралдық желілер (LSTM секілді) арқылы жергілікті параметрлерді қолдануға көпшілік болды. Бұл үлгілерді қайталанатын невралдық желілерден (қайталанатын невралдық желілер секілді) сызық ті Бірақ қарапайым графикалық модель құрылымы шығыс жарлықтарының арасындағы көпшілік жергілікті емес шектеулерді сенеді. Мысалы, бірінші атау секілді көптеген өрістер тек бірнеше рет немесе басқа өрістер бар болуы мүмкін. Бірақ RNN реттегілеу үшін жергілікті контексті таңдау мүмкіндіктерін күштеп бергенде, олар шығыс үлестірімінде ұқсас графикалық үлгісінің жалпы графикалық моделіне ендірілмейді. Біздің үлгіміз сызық тізбегінің CRF артында бірнеше жасырын күйлерін шығару жарлығында қосу үшін бірнеше жасырын күйлерін біріктіреді, бірақ оларды жасырын күйлерінің ішінде бағытталған журналдық журналдық Бұл инференциялық айнымалылықтардың көтерілген latent кеңістігі RNN- нің баға мүмкіндігін қолдануға мүмкіндік береді, жүйелік жүйелік инференциялық комплексті, жергілікті шығыс Біз бірнеше деректер қорларына тәжірибе жасап, үлгі негізгі жолдардың', 'mk': '袣芯屑锌谢械泻褋薪懈褌械 蟹邪写邪褔懈 蟹邪 懈蟹胁谢械泻褍胁邪褮械 薪邪 褌械泻褋褌褍邪谢薪懈 懈薪褎芯褉屑邪褑懈懈 褔械褋褌芯锌邪褌懈 褋械 锌芯褋褌邪胁褍胁邪邪褌 泻邪泻芯 褋械褉械泻胁械薪褌薪芯 芯蟹薪邪褔褍胁邪褮械 懈谢懈 薪懈褋泻芯 邪薪邪谢懈蟹懈褉邪褮械, 泻邪写械 锌芯谢懈褮邪褌邪 褋械 懈蟹胁谢械泻褍胁邪邪褌 泻芯褉懈褋褌械褬褱懈 谢芯泻邪谢薪懈 芯蟹薪邪褔褍胁邪褮邪 薪邪锌褉邪胁械薪懈 泻芯薪褋褌邪薪褌薪芯 锌褉械泻褍 胁械褉芯褬邪褌薪邪 懈薪褎械褉械薪褑懈褬邪 胁芯 谐褉邪褎懈褔泻懈 屑芯写械谢 褋芯 芯谐褉邪薪懈褔械薪懈 褌褉邪薪蟹懈 袧械芯写邪屑薪邪 褋褌邪薪邪 褔械褋褌芯 谢芯泻邪谢薪芯 写邪 褋械 锌邪褉邪屑械褌褉懈蟹懈褉邪邪褌 芯胁懈械 屑芯写械谢懈 泻芯褉懈褋褌械褬褱懈 斜芯谐邪褌懈 泻邪褉邪泻褌械褉懈褋褌懈泻懈 懈蟹胁邪写械薪懈 芯写 褉械褑懈写械薪褌薪懈 薪械褉胁薪懈 屑褉械卸懈 (泻邪泻芯 褕褌芯 械 袥小孝袦), 锌褉懈 褕褌芯 褋械 褋锌褉芯胁械写褍胁邪邪褌 泻芯薪褋褌邪薪褌薪懈 懈蟹谢械蟹懈 锌褉械泻褍 械写薪芯褋褌邪胁械薪 屑芯写械谢 褋芯 谢懈薪懈褬邪褉械薪 谢邪薪械褑, 泻芯褬 锌褉械褌褋褌邪胁褍胁邪 蟹邪胁懈褋薪芯褋褌懈 薪邪 袦邪褉泻芯胁懈褬邪薪 锌芯屑械褤褍 小械锌邪泻, 械写薪芯褋褌邪胁薪邪褌邪 谐褉邪褎懈褔泻邪 褋褌褉褍泻褌褍褉邪 薪邪 屑芯写械谢芯褌 谐懈 芯写斜懈胁邪 褔械褋褌芯 泻芯屑锌谢械泻褋薪懈褌械 薪械谢芯泻邪谢薪懈 芯谐褉邪薪懈褔褍胁邪褮邪 锌芯屑械褤褍 懈蟹谢械蟹薪懈褌械 械褌懈泻械褌懈. 袧邪 锌褉懈屑械褉, 屑薪芯谐褍 锌芯谢懈褮邪, 泻邪泻芯 褕褌芯 械 锌褉械蟹懈屑械, 屑芯卸邪褌 写邪 褋械 褋谢褍褔邪褌 褋邪屑芯 褎懈泻褋械薪 斜褉芯褬 锌邪褌懈, 懈谢懈 胁芯 锌褉懈褋褍褋褌胁芯 薪邪 写褉褍谐懈 锌芯谢懈褮邪. 袠 锌芯泻褉邪褬 褌芯邪 褕褌芯 袪袧袧 芯斜械蟹斜械写懈褬邪 褋茅 锌芯谐芯谢械屑懈 谢芯泻邪谢薪懈 泻邪褉邪泻褌械褉懈褋褌懈泻懈 褋芯 褋茅 锌芯谐芯谢械屑 泻芯薪褌械泻褋褌-褋胁械褋薪芯褋褌 蟹邪 芯蟹薪邪褔褍胁邪褮械 薪邪 褋械泻胁械薪褑邪, 褌懈械 褋茅 褍褕褌械 薪械 褋械 懈薪褌械谐褉懈褉邪薪懈 褋芯 谐谢芯斜邪谢械薪 谐褉邪褎懈褔泻懈 屑芯写械谢 薪邪 褋谢懈褔薪邪 械泻褋锌褉械褋懈胁薪芯褋褌 胁芯 写懈褋褌褉懈斜褍褑懈褬邪褌邪 薪邪 懈蟹谢械蟹芯褌. 袧邪褕懈芯褌 屑芯写械谢 芯写懈 薪邪写胁芯褉 芯写 谢懈薪懈褬邪褉薪懈芯褌 谢邪薪械褑 CRF 蟹邪 写邪 胁泻谢褍褔懈 薪械泻芯谢泻褍 褋泻褉懈械薪懈 褋芯褋褌芯褬斜懈 蟹邪 褋械泻芯褬邪 懈蟹谢械蟹薪邪 械褌懈泻械褌邪, 薪芯 谐懈 锌邪褉懈屑械褌褉懈蟹懈褉邪 锌邪褉懈屑械褌褉懈芯蟹薪芯 褋芯 薪懈褋泻芯褉邪薪谐 谢芯谐-锌芯褌械薪褑懈褬邪谢薪懈 屑邪褌褉懈褑懈 蟹邪 芯褑械薪泻邪, 械褎懈泻邪褋薪芯 褍褔械褬褱懈 屑械褋褌芯 蟹邪 胁泻谢褍褔褍胁邪褮械 薪邪 褋泻褉懈械薪懈 褋芯褋褌芯褬斜懈. 袨胁芯褬 蟹谐芯谢械屑械薪 谢邪薪褌械薪 锌褉芯褋褌芯褉 薪邪 懈薪褎械褉械薪褑懈褋泻懈褌械 锌褉芯屑械薪谢懈胁懈 谐芯 泻芯屑锌谢懈屑械薪褌懈褉邪 斜芯谐邪褌芯褌芯 锌褉械褌褋褌邪胁褍胁邪褮械 薪邪 袪袧袧, 懈 芯胁芯蟹屑芯卸褍胁邪 褌芯褔薪懈 谐谢芯斜邪谢薪懈 懈薪褎械褉械薪褑懈懈 泻芯懈 谐懈 锌芯褔懈褌褍胁邪邪褌 泻芯屑锌谢械泻褋薪懈褌械, 薪邪褍褔械薪懈 薪械谢芯泻邪谢薪懈 懈蟹谢械蟹薪懈 芯谐褉邪薪懈褔褍胁邪褮邪. 袝泻褋锌械褉懈屑械薪褌懈褉邪屑械 褋芯 薪械泻芯谢泻褍 锌芯写邪褌芯褑懈 懈 锌芯泻邪卸褍胁邪屑械 写械泻邪 屑芯写械谢芯褌 谐芯 薪邪写屑懈薪褍胁邪 芯褋薪芯胁薪芯褌芯', 'it': "Le attività complesse di estrazione delle informazioni testuali sono spesso poste come etichettatura di sequenza o analisi superficiale, in cui i campi vengono estratti utilizzando etichette locali rese coerenti attraverso inferenza probabilistica in un modello grafico con transizioni vincolate. Recentemente, è diventato comune parametrizzare localmente questi modelli utilizzando funzionalità ricche estratte da reti neurali ricorrenti (come LSTM), mentre impone output coerenti attraverso un semplice modello a catena lineare, che rappresenta dipendenze markoviane tra etichette successive. Tuttavia, la semplice struttura del modello grafico smentisce i vincoli spesso complessi non locali tra etichette di output. Ad esempio, molti campi, ad esempio un nome, possono verificarsi solo un numero fisso di volte o in presenza di altri campi. Mentre gli RNN hanno fornito funzionalità locali sempre più potenti per il tag di sequenza, devono ancora essere integrati con un modello grafico globale di espressività simile nella distribuzione di output. Il nostro modello va oltre la catena lineare CRF per incorporare più stati nascosti per etichetta di output, ma li parametrizza parsimoniosamente con matrici di punteggio log-potenziale basso, imparando efficacemente uno spazio di incorporazione per stati nascosti. Questo spazio latente aumentato di variabili di inferenza integra la rappresentazione ricca di funzionalità dell'RNN, e consente l'esatta inferenza globale obbedendo complessi vincoli di output non locali appresi. Sperimentiamo con diversi set di dati e mostriamo che il modello supera la linea di base", 'ka': 'კომპლექტური ტექსტური ინფორმაციის ექსტრექციის პარამეტრები ხშირად იყენება როგორც წერტილის მართლა ან ცოტა პარამეტრება, სადაც პარამეტრები გამოყენებულია ლოკალური ლაბეტრების გამოყენ მიმდინარე, ეს მოდელების ლოკალურად პარამეტრიზაცია, რომლებიც რეკურენტური ნეიროლური ქსელები (როგორც LSTM) გამოყენებული ბედნიერი ფუნქციების გამოყენება, რომლებიც კონსტენტური გამოყენებების მოდელზე, რომლებიც მა მაგრამ მარტივი გრაფიკალური მოდელის სტრუქტურაცია იფიქრობს, რომ ზოგიერთად კომპლექსიკური არ-ლოკალური ზომილებები გამოყენება etiket მაგალითად, რამდენიმე ფერები, როგორც პირველი სახელი, შეიძლება მხოლოდ მოხდება განსაზღვრებული რამდენიმე ჯერ, ან სხვა ფერების სახელში. როცა RNN-ები უფრო ძალიან ძალიან კონტექსტური მონაცემების ლოკალური ფუნქციები, რომლებიც კონტექსტურის მონაცემებისთვის, ისინი არ უნდა იყოს გლობალური გრაფიკურ ჩვენი მოდელი უფრო ხაზის CRF-ის გარეშე, რომ გამოყენება ერთ-ერთი მრავალ დაკლედ სტატურებული სტატუსების გარეშე, მაგრამ პარამეტრიზება მათი მარტირებით მარტირებით მარტირებით მარტირებით, ე ეს ინფრენციის ცვლილებების აზრუმენტირებული სივრცე პროგრამის ბედნიერი ფუნქციების გამოსახულებას დამუშაობს, და შეუძლება მხოლოდ გლობალური ინფრენცია, რომელიც კომპლექ ჩვენ ექსპერიმენტი მონაცემებით ექსპერიმენტირებით და ჩვენ აჩვენებთ, რომ მოდელი მუშაობა', 'hu': 'Az összetett szöveges információkitermelési feladatokat gyakran sorozatcímkézésnek vagy sekély elemzésnek nevezik, ahol a mezőket a korlátozott átmenetekkel rendelkező grafikus modellben valószínűsíthető következtetés révén konzisztens helyi címkékkel bontják ki. A közelmúltban gyakori, hogy ezeket a modelleket helyileg paraméterezzük a visszatérő neurális hálózatok által kivont gazdag funkciókkal (mint például LSTM), miközben konzisztens kimeneteket kényszerítünk egy egyszerű lineáris láncú modell segítségével, amely a markoviai függőségeket képviseli egymást követő címkék között. Az egyszerű grafikus modellszerkezet azonban tagadja a kimeneti címkék közötti gyakran összetett, nem helyi korlátozásokat. Például számos mező, például a keresztnév, csak rögzített számú alkalommal vagy más mezők jelenlétében jelenhet meg. Bár az RNN-ek egyre erőteljesebb környezettudatos helyi funkciókat biztosítottak a szekvencia-címkézéshez, még nem integrálták őket egy olyan globális grafikai modellbe, amely hasonló expresszivitást mutat a kimeneti eloszlásban. Modellünk túlmutat a lineáris CRF-láncon, hogy kimeneti címkénként több rejtett állapotot is beépítsen, de alacsony rangú log-potenciális pontozási mátrixokkal paraméterezi őket, hatékonyan megtanulva a rejtett állapotok beágyazási területét. Ez a kiterjesztett látens következtetési tér kiegészíti az RNN gazdag jellemzői ábrázolását, és lehetővé teszi a komplex, tanult, nem helyi kimeneti korlátozásoknak való megfelelést. Több adatkészlettel kísérletezünk, és megmutatjuk, hogy a modell meghaladja az alapvető teljesítményt', 'mt': 'Kompiti kumplessi ta’ estrazzjoni ta’ informazzjoni testwali ta’ spiss jiġu ppreżentati bħala tikkettar ta’ sekwenza jew parzjar baxx, fejn l-oqsma jiġu estratti bl-użu ta’ tikketti lokali magħmula konsistenti permezz ta’ inferenza probabilistika f’mudell grafiku bi tranżizzjonijiet ristretti. Dan l-a ħħar, sar komuni li dawn il-mudelli jiġu parametrizzati lokalment bl-użu ta’ karatteristiċi rikki estratti minn netwerks newrali rikorrenti (bħal LSTM), filwaqt li jiġu infurzati riżultati konsistenti permezz ta’ mudell sempliċi ta’ katina lineari, li jirrappreżenta dipendenzi Markoviani bejn tikketti suċċessivi. Madankollu, l-istruttura sempliċi tal-mudell grafiku tfixkel ir-restrizzjonijiet mhux lokali ta’ spiss kumplessi bejn it-tikketti tal-output. Pereżempju, ħafna oqsma, bħal isem, jistgħu jseħħu biss numru fiss ta’ darbiet, jew fil-preżenza ta’ oqsma oħra. Filwaqt li l-RNNs ipprovdew karatteristiċi lokali dejjem aktar qawwija u konxji mill-kuntest għat-tikkettar tas-sekwenzi, għadhom ma ġewx integrati ma’ mudell grafiku globali ta’ espressività simili fid-distribuzzjoni tal-output. Il-mudell tagħna jmur lil hinn mill-katina lineari CRF biex jinkorpora diversi stati moħbija għal kull tikketta ta’ ħruġ, iżda jimmetrizzahom parsimonikament b’matriċi ta’ punteġġ log-potenzjali ta’ grad baxx, b’mod effettiv jitgħallem spazju ta’ inkorporazzjoni għal stati moħbija. Dan l-ispazju latenti miżjud ta’ varjabbli ta’ inferenza jikkumplimenta r-rappreżentanza tal-karatteristiċi rikki tal-RNN, u jippermetti restrizzjonijiet ta’ ħruġ kumplessi u mhux lokali ta’ inferenza globali eżatti. Aħna ninsperimentaw b’diversi settijiet ta’ dejta u nuru li l-mudell jirriżulta mil-linja bażi', 'ml': 'സെക്കന്റ് ലേബിള്\u200d ചെയ്യുന്നതോ തണുത്ത പാര്\u200dസിംഗ് എന്നോ കോമ്പ്ലെക്സ് ടെക്സ്ചുള്\u200d വിവരങ്ങള്\u200d എടുത്തുകൊണ്ടിരിക്കുന്നു. നിര്\u200dബന്ധിതമായ ഒരു ഗ്രാഫിക്കല്\u200d മ അടുത്തുകഴിഞ്ഞപ്പോള്\u200d മാര്\u200dക്കോവിയന്\u200d വിജയകരമായ ലേബലുകള്\u200dക്കിടയില്\u200d പ്രതിനിധികള്\u200d നടത്തുന്ന സമ്പത്തുള്ള നെയൂറല്\u200d നെറുല്\u200d നെറുല്\u200d വര്\u200dക്കുകള്\u200d ഉപയോഗിച്ച് ഈ മോഡലുകള്\u200d ലോക്കല്\u200d ചങ എങ്കിലും ലളിതമായ ഗ്രാഫിക്കല്\u200d മാതൃകയുടെ ഘടനയില്\u200d പ്രധാനപ്പെട്ട പുറത്തുള്ള ലേബലുകള്\u200dക്കിടയില്\u200d പരിക്രമങ് For example, many fields, such as a first name, can only occur a fixed number of times, or in the presence of other fields.  RNNs കൂടുതല്\u200d ശക്തിയുള്ള പ്രാദേശിക വിവരങ്ങള്\u200d സെക്കന്\u200dസ് ടാഗിങ്ങിനുള്ള പ്രാദേശിക വിവരങ്ങള്\u200d കൊടുത്തിരിക്കുമ്പോള്\u200d, അവയൊക്കെ പൂട്ട്  നമ്മുടെ മോഡല്\u200d പുറത്ത് പോകുന്നതിനു വേണ്ടി ഒരുപാട് മറഞ്ഞിരിക്കുന്ന രാജ്യങ്ങള്\u200d ഒളിഞ്ഞിരിക്കുന്നതിനായി നമ്മുടെ രീതിയിലെ ചങ്ങലയ്ക്ക് മുകളില്\u200d പോകുന ഈ കൂട്ടിച്ചേര്\u200dത്തിരിക്കുന്ന സ്ഥലം പരിഗണിക്കുന്നത് RNN-ന്റെ സമ്പന്നതയുടെ പ്രതിനിധിയെ പൂര്\u200dണ്ണമാക്കുന്നു. പ്രധാനപൂര്\u200dണ്ണമായ ഗ്ലോ കുറച്ച് ഡാറ്റാസറ്റുകള്\u200d കൊണ്ട് പരീക്ഷിക്കുന്നു', 'lt': 'Sudėtingos tekstinės informacijos gavimo užduotys dažnai atliekamos kaip sekos ženklinimas arba plokščias analizavimas, kai laukai išimami naudojant vietines etiketes, kurios yra nuoseklios dėl tikėtinos išvados grafiniame modelyje su ribotais perėjimais. Pastaruoju metu tapo įprasta vietos lygmeniu parametrizuoti šiuos modelius naudojant turtingas savybes, gautas iš pasikartojančių nervų tinklų (pvz., LSTM), kartu užtikrinant nuoseklius rezultatus naudojant paprastą linijinę grandinę model į, kuris rodo Markovian priklausomybę tarp eilinių ženklų. Tačiau paprasta grafinio modelio struktūra atmeta dažnai sudėtingus ne vietinius išėjimo etikečių apribojimus. Pavyzdžiui, daugelis laukų, pavyzdžiui, pavardė, gali atsirasti tik nustatytu skaičiumi kartų arba esant kitiems laukams. Nors RNN sukūrė vis stipresnes aplinkybes suprantamas vietos charakteristikas sekos žymėjimui, jie dar neturi būti integruoti į panašaus išraiškos pasiskirstymo pasaulinį grafinį model į. Mūsų modelis viršija linijinę grandinę CRF, kad būtų įtrauktos kelios paslėptos būklės kiekvienoje išėjimo etiketėje, tačiau parametrizuoja jas parsimoniškai su mažo lygio log potencialiais taškų matricos, veiksmingai išmokant įdėjimo erdvę paslėptoms būklėms. Ši padidinta latenti išvadų kintamųjų erdvė papildo turtingą RNN charakteristikų rodymą ir leidžia tiksliai visuotinę išvadą laikytis sudėtingų, išmoktų ne vietinių išėjimo apribojimų. Eksperimentuojame su keliais duomenų rinkiniais ir rodome, kad modelis yra didesnis už pradinį', 'pl': 'Złożone zadania ekstrakcji informacji tekstowych są często postawione jako etykietowanie sekwencji lub płytkie parsowanie, gdzie pola są ekstraktowane za pomocą lokalnych etykiet, które są spójne poprzez wnioskowanie probabilistyczne w modelu graficznym z ograniczonymi przejściami. Ostatnio powszechne stało się parametryzowanie tych modeli lokalnie za pomocą bogatych funkcji ekstrahowanych przez powtarzające się sieci neuronowe (takie jak LSTM), przy jednoczesnym wymuszaniu spójnych wyjść za pomocą prostego modelu łańcucha liniowego, reprezentującego markowskie zależności między kolejnymi etykietami. Jednak prosta struktura modelu graficznego zaprzecza często złożonym nielokalnym ograniczeniom pomiędzy etykietami wyjściowymi. Na przykład wiele pól, takich jak imię, może występować tylko określoną liczbę razy lub w obecności innych pól. Podczas gdy RNN dostarczały coraz bardziej potężnych kontekstowych funkcji lokalnych do tagowania sekwencji, nie zostały jeszcze zintegrowane z globalnym modelem graficznym o podobnej ekspresywności w dystrybucji wyjściowej. Nasz model wykracza poza liniowy łańcuch CRF, aby włączyć wiele ukrytych stanów na etykietę wyjściową, ale parametryzuje je parsimonijnie za pomocą niskiej rangi matryc punktowania potencjału log, skutecznie ucząc się przestrzeni osadzania dla ukrytych stanów. Ta rozszerzona utajona przestrzeń zmiennych wnioskowania uzupełnia bogatą reprezentację funkcji RNN i umożliwia dokładne wnioskowanie globalne przestrzegając złożonych, nauczonych nielokalnych ograniczeń wyjściowych. Eksperymentujemy z kilkoma zbiorami danych i pokazujemy, że model przewyższa wyniki bazowe', 'no': 'Kompleksige tekstinformasjonsekstraksjonsoppgåver vert ofte plasserte som sekvensmerkelapp eller slått tolking, der felta vert pakka ut med lokale merkelappar som er konsistent gjennom sannsynlige infeksjon i eit grafisk modell med begrensede overgangar. Nyleg har det blitt vanleg å parameterera desse modelane lokalt ved å bruka rikke funksjonar utpakka av rekurserte neuralnettverk (som LSTM), mens det gjer konsistente utgåver gjennom ein enkel lineær kjede- modell, som representerer Markovianske avhengighet mellom rekursive etikettar. Den enkle grafiske modellestrukturen tomt imidlertid at dei ofte komplekse ikkje- lokale begrensningane mellom utdata- merkelappar. For eksempel, mange felt, som eit først namn, kan berre skje eit fast tal gangar, eller i tilstand til andre felt. Mens RNN har tilgjengeleg større kraftige kontekstsverkt lokale funksjonar for merking av sekvensar, må dei enno integrerast med eit globalt grafisk modell med liknande uttrykk i utdatafordelinga. Modellen vårt går over den lineære kjeden CRF-en for å inkludere fleire gøymde tilstandar per utskriftsmerkelapp, men parametrerer dei med lågare loggpotensielle scoring-matriser, og lærer effektivt eit innbyggingsplass for gøymde tilstandar. Denne økte latent plassen av infeksjonssvariabelane complementerer den rike funksjonen representasjonen av RNN, og tillater nøyaktig global infeksjon som gjer komplekse, lærte ikkje- lokale utgangssgrenser. Vi eksperimenterer med fleire datasett og viser at modellen utfører baselinja', 'ms': 'Tugas ekstraksi maklumat teks kompleks sering diposisikan sebagai label urutan atau penghuraian rendah, di mana medan ekstrak menggunakan label setempat yang dibuat konsisten melalui kesimpulan kemungkinan dalam model grafik dengan transisi terhalang. Baru-baru ini, ia telah menjadi biasa untuk parametrisasi setempat model ini menggunakan ciri-ciri kaya yang dikekstrak oleh rangkaian saraf berkurang (seperti LSTM), sementara memaksa output konsisten melalui model rantai linear mudah, mewakili dependensi Markovian diantara label berturut-turut. Namun, struktur model grafik sederhana mendustakan kebanyakan keterangan bukan-lokal kompleks diantara label output. Contohnya, banyak medan, seperti nama depan, hanya boleh berlaku berapa kali tertentu, atau di hadapan medan lain. Sementara RNN telah menyediakan ciri-ciri setempat yang lebih berkuasa yang sedar-konteks untuk tag urutan, mereka belum disertai dengan model grafik global yang sama dalam distribusi output. Model kita melampaui CRF rantai linear untuk memasukkan beberapa keadaan tersembunyi per label output, tetapi mengarahkannya secara parsimonik dengan matriks skor log-potensi rendah rangka, mempelajari ruang penyembedding untuk keadaan tersembunyi secara efektif. Ruang laten bertambah pembolehubah kesimpulan ini menyempurnakan persembahan ciri kaya RNN, dan membolehkan kesimpulan global tepat mematuhi kompleks, ketat output bukan setempat belajar. Kami eksperimen dengan beberapa set data dan menunjukkan bahawa model melampaui dasar', 'sr': 'Kompleksne izvlačenje tekstualnih informacija često se postavljaju kao etiketiranje sekvencija ili plitko parsiranje, gdje se polja izvlače koristeći lokalne etikete koje su u skladu sa verovatnošću infekcije u grafičkom modelu sa ograničenim tranzicijama. Nedavno je postalo uobičajeno lokalno parametrirati te modele koristeći bogate karakteristike izvlačene repertovanim neuralnim mrežama (kao što je LSTM), dok provođuju konsekventne ishode kroz jednostavan linearni lanac model koji predstavlja Markovijsku zavisnost između nasljednih etiketa. Međutim, jednostavna grafska modelska struktura veruje da često kompleksna ne lokalna ograničenja između etiketa izlaza. Na primer, mnoge polja, poput prvog imena, mogu se pojaviti samo određen broj puta, ili u prisustvu drugih polja. Iako su RNN pružili sve moćne lokalne karakteristike koje su svjesne konteksta za označavanje sekvencija, još uvek se ne moraju integrirati sa globalnim grafičkim modelom slične izrazitosti u distribuciji proizvoda. Naš model prolazi preko linearnog lanca CRF-a da uključuje više skrivenih država po etiketi izvešća, ali ih parametrira parsimonično sa matricijama niskog reda potencijalnog loga-izveštaja, učeći učenje prostora za uključenje skrivenih država. Ovaj povećani latentni prostor varijanta infekcije dopunjava bogatim predstavljanjem RNN-a i omogućava taènu globalnu infekciju koja se sluša kompleksnom, naučenom neolokalnom ograničenju izlaza. Eksperimentiramo sa nekoliko seta podataka i pokažemo da model nadmaže početnu liniju', 'so': 'Shaqooyinka soo saaridda macluumaadka ee qoraalka waxaa inta badan loo isticmaalaa jardiinada labka ama jardiinada shallow, meesha lagu isticmaalo alaabta deegaanka lagu soo bandhigi karo oo lagu sameyn karo tusaale sawir ah oo lagu baaraandegay. Mudankii ugu dhowaaday, waxay caadi ahaan u noqotay inay noocyadan ku isticmaalaan tayooyin hodan ah oo ay ka soo saaraan shabakada neurada ee soo socda (sida LSTM), iyadoo lagu qasbayo qalabka siman oo fudud qoriga ah, kaasoo ka mid ah midiidinnada Markovian dhexe ku xiran baararka liibaanka ah. Si kastaba ha ahaatee dhismaha muusikada ee fudud ee tusaale ahaan waxay inta badan ka muuqataa qasab adag oo aan degmada ahayn oo ka dhexeeya alaabta soo baxa. Tusaale ahaan beero badan, tusaale ahaan magac hore, waxay ku dhici karaan wakhti cayiman oo kaliya ama beero kale hortooda. Inta lagu jiro RNNs waxay si xoog badan u fidiyeen xeerarka deegaanka oo aad u yaqaan, waxay weli u baahan yihiin in lagu soo wada ururiyo model caalami ah oo u eg expressivity, qaybinta soo baxa. Our model goes beyond the linear chain CRF to incorporate multiple hidden states per output label, but parametrizes them parsimoniously with low-rank log-potential scoring matrices, effectively learning an embedding space for hidden states.  Tan ayaa kordhisay goobta ugu dambeeya ee isbedelka ah oo dhamaystiraya taajirka ah oo ku representaya RNN, wuxuuna fasaxaa cudurka caalamiga ah oo addeecidda complex ah, waxayna bartay xaduudaha dibadda ee aan degmada ahayn. waxaynu tijaabinaynaa koobo macluumaad ah, waxaana tusinaynaa in modelku uu ka samaysto basaaska', 'sv': 'Komplexa uppgifter för extraktion av textinformation framställs ofta som sekvensmärkning eller ytlig tolkning, där fält extraheras med hjälp av lokala etiketter som görs konsekventa genom sannolik inferens i en grafisk modell med begränsade övergångar. Nyligen har det blivit vanligt att lokalt parametera dessa modeller med hjälp av rika funktioner extraherade av återkommande neurala nätverk (som LSTM), samtidigt som konsekventa utgångar upprätthålls genom en enkel linjär kedjemodell, som representerar markoviska beroenden mellan varandra följande etiketter. Den enkla grafiska modellstrukturen förnekar dock de ofta komplexa icke-lokala begränsningarna mellan utmatningsetiketterna. Många fält, till exempel ett förnamn, kan till exempel bara förekomma ett fast antal gånger eller i närvaro av andra fält. Medan RNN har tillhandahållit alltmer kraftfulla sammanhangsberoende lokala funktioner för sekvensmärkning, har de ännu inte integrerats med en global grafisk modell av liknande uttryck i utdatadistributionen. Vår modell går bortom den linjära kedjan CRF för att införliva flera dolda tillstånd per utdataetikett, men parametriserar dem parsimoniöst med lågrankiga loggpotentiella scoring matriser, vilket effektivt lär sig ett inbäddningsutrymme för dolda tillstånd. Detta utökade latenta utrymme av inferensvariabler kompletterar RNN:s rika funktionsrepresentation och möjliggör exakt global inferens som lyder komplexa, lärda icke-lokala outputbegränsningar. Vi experimenterar med flera datauppsättningar och visar att modellen överträffar baslinjen', 'mn': 'Мөн комплекс мөнгө мэдээлэл хадгалах үйл ажиллагаа ихэвчлэн дарааллын маркинг эсвэл гүнзгий хуваалцлага гэж байдаг. Хязгаарлагдсан шилжилт дээр график загварын магадлал халдварын аргаар тохируулагдсан газар нутгийн маркингуудыг Сүүлийн үед эдгээр загваруудыг газрын тойргийн хэлбэрээр дахин дахин дахин сэтгэл зүйн сүлжээнд (LSTM) авсан баян чанарыг ашиглаж, энгийн шугам хэлбэрийн загвараар үр дүнтэй үр дүнг ашиглаж, амжилттай тэмдэглэл хоорондын Марковин хамааралтай бай Гэхдээ энгийн график загварын бүтэц нь үржүүлэх жагсаалтын хоорондох хэмжээсүүд биш байдаг гэдэгт итгэдэг. Жишээлбэл, анхны нэр шиг олон салбарууд зөвхөн тодорхой хэдэн удаа, эсвэл бусад салбарууд байдаг. ДНХ нь дарааллын тагжуулах үед илүү хүчирхэг орчин тойронд мэдрэгдсэн байдлаар илүү хүчирхэг боломж олгосон ч тэд үржүүлэлтийн хуваарилалтын төстэй илэрхийлэл дэлхийн график загвартай холбогдох хэр Бидний загвар нь шулуун хэлхээгээс гадна олон нууцлаг орнуудыг бүрдүүлэх гэсэн үг. Гэхдээ үүнийг нууцлаг орнуудын орон зайгаар бага хэлбэрээр хуваалцдаг. Энэ нэмэгдсэн халдвар шинжлэх ухааны орон зай нь RNN-ийн баян чанарыг нэмэгдүүлдэг. Тэгээд дэлхийн халдвар нь комплекс, орчин нутгийн биш боловсруулагдсан бүтээгдэхүүний хязгаарлах боломжтой болгодог. Бид олон өгөгдлийн хэлбэрээр туршилт хийж, загвар нь', 'ro': 'Activitățile complexe de extragere a informațiilor textuale sunt adesea prezentate ca etichetare secvențială sau analizare superficială, în cazul în care câmpurile sunt extrase folosind etichete locale făcute coerente prin inferență probabilistică într-un model grafic cu tranziții restricționate. Recent, a devenit obișnuit parametrizarea locală a acestor modele folosind caracteristici bogate extrase de rețelele neurale recurente (cum ar fi LSTM), impunând în același timp ieșiri consistente printr-un model simplu cu lanț liniar, reprezentând dependențele markoviene între etichetele succesive. Cu toate acestea, structura simplă a modelului grafic contrazice constrângerile adesea complexe non-locale dintre etichetele de ieșire. De exemplu, multe câmpuri, cum ar fi un prenume, pot apărea numai de un număr fix de ori sau în prezența altor câmpuri. În timp ce RNN-urile au furnizat caracteristici locale din ce în ce mai puternice conștiente de context pentru etichetarea secvențelor, ele nu au fost încă integrate cu un model grafic global de expresivitate similară în distribuția ieșirii. Modelul nostru depășește lanțul liniar CRF pentru a încorpora mai multe stări ascunse pe etichetă de ieșire, dar le parametrizează parsimonios cu matrici de scoring cu potențial log de rang scăzut, învățând eficient un spațiu de încorporare pentru stările ascunse. Acest spațiu latent augmentat al variabilelor de inferență completează reprezentarea bogată a caracteristicilor RNN și permite inferența globală exactă respectând constrângerile de ieșire non-locale complexe, învățate. Experimentăm cu mai multe seturi de date și arătăm că modelul depășește valoarea de referință', 'si': 'සම්පූර්ණ පැත්තක් තොරතුරු ප්\u200dරතික්\u200dරියාත්මක ක්\u200dරියාත්මක විසින් පරික්ෂණය විසින් විසින් ප්\u200dරතික්\u200dරියාත්මක විසින් ප්\u200dරතික්\u200dරියාත් අවසානයෙන්, ඒක ස්ථානික විශේෂයෙන් ප්\u200dරමාණය කරන්න පුළුවන් විශේෂතාවක් භාවිත කරන්න සාමාන්\u200dය විශේෂය (LSTM) වෙනුවෙන්, සමාන්\u200dය linear- chain මොඩේලයෙන් ප්\u200dරම නමුත්, සාමාන්\u200dය ග්\u200dරාෆිකල් මොඩල් සැකසුම් විශ්වාස කරනවා නොස්ථානික නොස්ථානික සීමාවක් ප්\u200dර උදාහරණයෙන්, පළමු නමක් වගේ, ගොඩක් ක්\u200dෂේත්\u200dරයක් විතරයි, නැත්තම් අනිත් ක්\u200dෂේත්රයක් තියෙන්න පුළුවන RNNs වඩා ශක්තිමත් සම්බන්ධතාවක් දැනගන්නේ ස්ථානික අවශ්\u200dයතාවක් ටැග් කරන්න, ඔවුන් තවමත් ප්\u200dරශ්ණ විශ්වාසයේ සාමාන්\u200dය අපේ මෝඩල් ලිනියර් චේන්ස් CRF වලින් යනවා ඇතුළුම් ලේබල් වෙනුවෙන් ගොඩක් හැංගුණු ස්ථානය සම්බන්ධ කරන්න, නමුත් ප්\u200dරමාණයෙන් ඔවුන් පරි මේ විශේෂ විශේෂ විශේෂ විශේෂයෙන් විශේෂ ක්\u200dරියාත්මක විශේෂ විශේෂ විශේෂ විශේෂය සම්පූර්ණය කරනවා RNN, සහ ස අපි දත්ත සැට් විතරයි පරීක්ෂණය කරලා පෙන්වන්නේ මොඩේල් අධාරණ ප්\u200dරතික්\u200dරමය', 'ta': 'Complex textual information extraction tasks are often posed as sequence labeling or shallow parsing, where fields are extracted using local labels made consistent through probabilistic inference in a graphical model with constrained transitions.  சமீபத்தில், மார்கோவியன் சார்புகளை வெற்றிகரமான சிட்டைகளுக்கு இடையே குறிப்பிடும் செயல்பாடுகளை பயன்படுத்தி செல்லும் பணக்கூடிய பண்புகளை பயன்படுத்தி உள்ளூர் அளபுருவாக்கு ஆனால், எளிய வரைகலை மாதிரி அமைப்பு வெளியீட்டு சிட்டைகளுக்கு இடையே சிக்கலான கட்டுப்பாடுகளை நம்புகிறது. உதாரணத்திற்கு, முதல் பெயர் போன்ற பல புலங்கள், குறிப்பிட்ட எண்ணிக்கையின் முறை மட்டும் நிகழ முடியும், அல்லது மற் பின்வரிசை ஒட்டுதலுக்கான RNNs அதிகமாக வலிமையுள்ள சூழல் தெரியும் உள்ள தன்மைகளை வழங்கியுள்ளார் எங்கள் மாதிரி CRF சங்கிலியை வெளியீட்டு விளக்கச்சீட்டுக்கு பல மறைந்த நாடுகளை ஒன்றாக சேர்க்க முடியும், ஆனால் சிறிய நாடுகளுக்கு மறைந்துள்ளது வெளியீட்ட இந்த தேர்ந்தெடுக்கப்பட்ட பாதிப்பு மாறிகளின் தற்போதைய இடத்தை ஆர்என்னின் பணக்கூடிய பண்புகள் குறிப்பிடுதலை முழுமையாக்குகிறது, மற்றும் சர நாம் பல தரவுத்தளங்களைக் கொண்டு சோதனைப்படுத்தி மாதிரி அடிப்படையில் வெளியேறும்', 'ur': 'پیچیدہ تفصیل معلومات اخراج ٹاکسٹ ٹاکسٹ کیسٹ کیسٹ لیبلینگ یا گہرے پارسینگ کے طور پر رکھے جاتے ہیں، جہاں کھیتیاں محلی لیبل کے مطابق اخراج کی جاتی ہیں جو ایک گرافیکل موڈل میں محدودہ تغییرات کے مطابق قابل اگلے، یہ موڈل کو محلی طور پر پارامتریز کرنا عام ہو گیا ہے، جو دوبارہ نیورل نیورل نیٹورک (جیسے LSTM) کے ذریعہ اضافہ کئے جاتے ہیں، اور موجود اضافہ کو ایک ساده linear-chain موڈل کے ذریعہ مضبوط کرتا ہے، جو مارکووین کی نیویورل نیٹورک (جیسے LSTM) کے ذری However, the simple graphical model structure believes the often complex non-local constraints between output labels. مثال، بہت سی کھیتیاں، جیسے پہلی نام، صرف ایک مقررہ تعداد مرتبہ ہو سکتے ہیں، یا دوسرے کھیتیوں کے حضور. While RNN has provided increasingly powerful context-aware local features for sequence tagging, they still need to be integrated with a global graphical model of similar expressivity in the output distribution. ہمارا موڈل linear chain CRF سے زیادہ زیادہ جاتا ہے کہ ایک آوٹ لیبل کے بارے میں بہت سی مخفی حالت شامل کریں، لیکن ان کو پارامیٹریس کے ساتھ پارامیٹریس کرتا ہے کم رقم لاگ-پوشنل اسکورینگ ماٹریس کے ساتھ، پوشیدہ حالت کے لئے ایک انڈینگ یہ بڑھایا گیا لاٹینٹ جگہ ہے جن کے بدلنے پھیرے ہوئے بدلنے ہیں RNN کی ثروتمند فکرت کی تعریف کرتی ہیں اور بالکل گلوبی ایفارنس کی پیچیدہ پیچیدہ پیچیدہ، غیر محلی ایفوٹ پیچیدہ محدودیت کی اجازت دیتی ہے ہم بہت سی ڈاٹ سٹ کے ساتھ آزمائش کرتے ہیں اور دکھاتے ہیں کہ موڈل بنسٹ لین سے زیادہ اضافہ کرتا ہے', 'uz': "Name Yaqinda, bu modellarni lokal parametrlash mumkin, davom etilgan neyrolik tarmoqlari (masalan LSTM) tomonidan foydalanadigan rich imkoniyatlarni ishlatish mumkin, va muvaffaqiyatli tugmalar orasidan oddiy liner modelini ishlatish mumkin. Lekin, oddiy grafik modeli tuzuvlari natijada murakkab boʻlmagan tarkiblarni ishlatadi. Masalan, ko'p maydonlar, birinchi nom sifatida faqat koʻrsatilgan sonlar yoki boshqa maydonlar mavjud boʻlishi mumkin. @ info: whatsthis Bizning modelimiz CRF chegarasining bir necha bekitilgan davlatlarni bir necha bo'lgan holatga qo'yish uchun boshlanadi, lekin ularni bir xil darajada qo'yish mumkin matrikalarni o'rganish mumkin. Name Biz bir necha maʼlumotlar tarkibini sinab ko'rib chiqaramiz va model asosiy uslubini bajaradi", 'vi': 'Nhiệm vụ khai thác thông tin phức tạp thường được đặt như hiệu số hoặc phân tích nông, nơi các trường được chiết xuất bằng các nhãn địa phương được cấu hình phù hợp qua ngụ ý xác suất trong mô hình đồ họa với các sự chuyển tiếp bị hạn. Gần đây, nó đã trở nên phổ biến để đo đạc các mô hình này bằng cách sử dụng các tính chất giàu có được chiết xuất từ các mạng thần kinh thường xuyên (v. d. HTTM), và thực hiện kết quả liên tục qua mô hình chuỗi tuyến đơn giản, đại diện cho sự phụ thuộc Markov giữa các nhãn tiếp theo. Tuy nhiên, cấu trúc đồ họa đơn giản phủ nhận giới hạn thường phức tạp không phải địa phương giữa các nhãn xuất. Ví dụ, nhiều trường, như tên gọi, chỉ có thể xuất hiện một số lần cố định, hoặc có mặt các trường khác. Trong khi RNN đã cung cấp các tính năng nhận diện ngữ cảnh ngày càng mạnh cho việc định vị chuỗi, nhưng chúng vẫn chưa được tổng hợp với mô hình đồ họa to àn cầu có tính biểu tượng tương tự trong phân phối xuất. Kiểu mẫu của chúng ta vượt xa các chuỗi CRF tuyến tính để có thêm nhiều trạng thái ẩn cho mỗi nhãn xuất, nhưng thiết lập chúng theo điệu phân cách khác nhau với các tấm có tiềm năng ghi thấp, thực tế học một khoảng cách cho các trạng thái bị giấu. This incredited lated space of infectionce variables hoàn thiện tính năng giàu có của RNN, và allows exactly globally infections vâng lệ phức tạp, learned không-local. Chúng tôi thử nghiệm với nhiều bộ dữ liệu và cho thấy rằng mẫu hoàn thiện hoàn toàn', 'de': 'Komplexe Textinformationsextraktionsaufgaben werden oft als Sequenz-Beschriftung oder flaches Parsen dargestellt, wobei Felder mithilfe lokaler Beschriftungen extrahiert werden, die durch probabilistische Inferenz in einem grafischen Modell mit eingeschränkten Übergängen konsistent sind. In letzter Zeit ist es üblich geworden, diese Modelle lokal zu parametrisieren, indem umfangreiche Features verwendet werden, die von wiederkehrenden neuronalen Netzwerken (wie LSTM) extrahiert werden, während konsistente Outputs durch ein einfaches lineares Kettenmodell erzwungen werden, das markovische Abhängigkeiten zwischen aufeinanderfolgenden Labels repräsentiert. Die einfache grafische Modellstruktur leugnet jedoch die oft komplexen nicht-lokalen Einschränkungen zwischen Ausgabeetiketten. Beispielsweise können viele Felder, wie z.B. ein Vorname, nur eine feste Anzahl von Fällen oder in Anwesenheit anderer Felder vorkommen. Während RNNs zunehmend leistungsfähige kontextbezogene lokale Funktionen für Sequenz-Tagging bereitgestellt haben, müssen sie noch in ein globales grafisches Modell mit ähnlicher Expressivität in der Ausgabeverteilung integriert werden. Unser Modell geht über die lineare CRF-Kette hinaus, um mehrere versteckte Zustände pro Ausgabelabel zu integrieren, parametrisiert sie jedoch parsimonisch mit niedrig rangigen Log-Potential-Scoring-Matrizen und lernt effektiv einen Einbettungsraum für versteckte Zustände. Dieser erweiterte latente Raum von Inferenzvariablen ergänzt die reichhaltige Funktionsdarstellung des RNN und ermöglicht exakte globale Inferenz unter Beachtung komplexer, erlernter nicht-lokaler Ausgabebeschränkungen. Wir experimentieren mit mehreren Datensätzen und zeigen, dass das Modell die Baseline übertrifft', 'nl': "Complexe tekstuele informatie extractie taken worden vaak voorgesteld als sequentie labeling of ondiepe parsing, waarbij velden worden geëxtraheerd met behulp van lokale labels die consistent zijn gemaakt door probabilistische inferentie in een grafisch model met beperkte overgangen. Onlangs is het gebruikelijk geworden om deze modellen lokaal te parametriseren met behulp van rijke functies die worden geëxtraheerd door terugkerende neurale netwerken (zoals LSTM), terwijl consistente outputs worden afgedwongen via een eenvoudig lineair-chain model, dat Markoviaanse afhankelijkheden tussen opeenvolgende labels vertegenwoordigt. De eenvoudige grafische modelstructuur weerlegt echter de vaak complexe niet-lokale beperkingen tussen uitvoerlabels. Veel velden, zoals een voornaam, kunnen bijvoorbeeld slechts een vast aantal keren voorkomen, of in aanwezigheid van andere velden. Hoewel RNN's steeds krachtigere context-bewuste lokale functies voor sequentie tagging hebben verstrekt, moeten ze nog worden geïntegreerd met een globaal grafisch model van vergelijkbare expressiviteit in de uitvoerdistributie. Ons model gaat verder dan de lineaire keten CRF om meerdere verborgen toestanden per uitvoerlabel op te nemen, maar parametriseert ze parsimonius met lage rang log-potential scorematrices, waardoor effectief een insluitingsruimte voor verborgen toestanden wordt geleerd. Deze uitgebreide latente ruimte van inferentievariabelen vult de rijke functie-representatie van de RNN aan en maakt nauwkeurige globale inferentie mogelijk door complexe, geleerd niet-lokale outputbeperkingen te gehoorzamen. We experimenteren met verschillende datasets en laten zien dat het model beter presteert dan baseline", 'hr': 'Zapovijedi izvlačenja kompleksnih tekstualnih informacija često se postavljaju kao etiketiranje sekvencija ili plitko analiziranje, gdje se polja izvlače koristeći lokalne etikete koje su u skladu s vjerojatnošću infekcijom u grafičkom modelu s ograničenim tranzicijama. Nedavno je postalo često lokalno parametrirati te modele s bogatim karakteristikama izvlačenim recidivnim neuralnim mrežama (kao što je LSTM), dok primjenjuju konsekventne ishode kroz jednostavan linearni lanac model koji predstavlja Markovijsku zavisnost između nasljednih etiketa. Međutim, jednostavna grafska modelska struktura vjeruje da često kompleksna ne lokalna ograničenja između etiketa izlaza. Na primjer, mnoge polja, poput imena, mogu se pojaviti samo određen broj puta, ili u prisustvu drugih polja. Iako su RNN-ovi pružili sve moćnije lokalne karakteristike koje su svjesne konteksta za označavanje sekvencije, još uvijek moraju biti integrirani s globalnim grafičkim modelom slične izrazitosti u distribuciji izlaza. Naš model ide preko linearnog lanca CRF-a da uključuje više skrivenih stanja po etiketi izlaza, ali ih parametrira parsimonički sa niskim potencijalnim matricama izvlačenja logora, učeći učenje prostora za uključenje skrivenih država. Ovaj povećani latentni prostor promjena infekcije dopunjava bogatim predstavljanjem RNN-a i omogućava točnu globalnu infekciju koja se posluša kompleksnom, naučenom neolokalnom ograničenju izlaza. Eksperimentiramo s nekoliko podataka i pokazujemo da je model nadmašio početnu liniju', 'da': "Komplekse tekstinformationsudvindingsopgaver stilles ofte som sekvensmærkning eller overfladisk fortolkning, hvor felter udvindes ved hjælp af lokale etiketter, der gøres ensartede gennem sandsynlig inferens i en grafisk model med begrænsede overgange. For nylig er det blevet almindeligt lokalt at parametrisere disse modeller ved hjælp af rige funktioner udvundet af tilbagevendende neurale netværk (såsom LSTM), samtidig med at der gennemtvinges ensartede output gennem en simpel lineær kædemadel, der repræsenterer markovianske afhængigheder mellem hinanden følgende etiketter. Men den enkle grafiske modelstruktur afviser de ofte komplekse ikke-lokale begrænsninger mellem outputetiketter. Mange felter, f.eks. et fornavn, kan f.eks. kun forekomme et fast antal gange eller i tilstedeværelse af andre felter. Mens RNN'er har leveret stadig stærkere kontekstbevidste lokale funktioner til sekvensmærkning, er de endnu ikke integreret med en global grafisk model af lignende udtryksevne i outputfordelingen. Vores model går ud over den lineære CRF-kæde for at indarbejde flere skjulte tilstande pr. output etiket, men parametrerer dem parsimoniøst med lav rang logpotentiale scoring matricer, hvilket effektivt lærer et indlejringsrum for skjulte tilstande. Dette forstærkede latente rum af inferensvariabler supplerer RNN's rige egenskabsrepræsentation og tillader nøjagtig global inference, der adlyder komplekse, lærte ikke-lokale outputbegrænsninger. Vi eksperimenterer med flere datasæt og viser, at modellen overstiger baseline", 'bg': 'Сложните задачи за извличане на текстова информация често се представят като етикетиране на последователност или плитко анализиране, където полетата се извличат с помощта на местни етикети, направени последователни чрез вероятностно заключение в графичен модел с ограничени преходи. Напоследък е станало често локално параметризиране на тези модели, използвайки богати функции, извлечени от повтарящи се невронни мрежи (като ЛСТМ), като същевременно се налагат последователни изходи чрез прост модел с линейна верига, представляващ марковианските зависимости между последователните етикети. Въпреки това, простата структура на графичния модел отрича често сложните нелокални ограничения между изходните етикети. Например много полета, като например малко име, могат да се появят само фиксиран брой пъти или в присъствието на други полета. Докато RNN осигуряват все по-мощни локални функции за маркиране на последователността, те все още не са интегрирани с глобален графичен модел с подобна експресивност в изходното разпределение. Нашият модел излиза отвъд линейната верига за включване на множество скрити състояния на изходен етикет, но параметризира ги сдържано с матрици за оценка с нисък ранг логов потенциал, ефективно научавайки вграждащо пространство за скрити състояния. Това увеличено латентно пространство на променливите за заключение допълва богатото представяне на характеристиките на RNN и позволява точно глобално заключение, подчинявайки се на сложни, научени нелокални изходни ограничения. Експериментираме с няколко набора данни и показваме, че моделът превъзхожда базовата база', 'id': 'Tugas ekstraksi informasi tekstual kompleks sering diposisikan sebagai label urutan atau penghuraian rendah, di mana medan ekstraksi menggunakan label lokal yang dibuat konsisten melalui inferensi probabilistik dalam model grafis dengan transisi terbatas. Baru-baru ini, telah menjadi umum untuk lokal parametris model ini menggunakan karakteristik kaya yang diekstraksi oleh jaringan neural rekuren (seperti LSTM), sementara memaksa output konsisten melalui model rantai linear sederhana, mewakili dependensi Markovian antara label berturut-turut. Namun, struktur model grafis sederhana mendustakan kebarangan yang sering rumit bukan lokal antara label output. Contohnya, banyak medan, seperti nama depan, hanya dapat terjadi sejumlah tetap kali, atau di hadapan medan lain. Sementara RNN telah menyediakan karakteristik lokal yang semakin kuat yang menyadari konteks untuk penandaian urutan, mereka belum terintegrasi dengan model grafis global dengan ekspresivitas yang sama dalam distribusi output. Model kita melebihi rantai linear CRF untuk mengikorporasi beberapa keadaan tersembunyi per label output, tetapi parametris mereka parsimoniously dengan matris skor log-potensi rendah rangka, secara efektif belajar ruang embedding untuk keadaan tersembunyi. Ruang latent yang bertambah dari variabel inferensi ini menambah penggambaran karakteristik kaya dari RNN, dan memungkinkan inferensi global tepat mematuhi kompleks, batasan keluaran non-lokal belajar. Kami eksperimen dengan beberapa set data dan menunjukkan bahwa model melampaui batas dasar', 'ko': '복잡한 텍스트 정보 추출 작업은 보통 서열 표시나 얕은 해석으로 설정된다. 그 중에서 필드는 국부 라벨로 추출되고 국부 라벨은 제약이 있는 도형 모델에서의 확률 추리를 통해 일치한다.최근에는 역귀신경 네트워크(예를 들어 LSTM)에서 추출한 풍부한 특징을 이용하여 이 모델들을 국부적으로 매개 변수화하는 것이 흔해졌고, 간단한 선형 체인 모델(연속 라벨 간의 마르코프 의존 관계를 표시)을 통해 일치된 출력을 강제로 집행했다.그러나 간단한 도형 모델 구조는 출력 탭 사이의 일반적인 복잡한 비부분적인 제약을 덮어 준다.예를 들어 많은 필드(예를 들어 이름)는 고정된 횟수만 나타나거나 다른 필드가 존재하는 경우에만 나타난다.RNN은 시퀀스 태그에 대한 강력한 컨텍스트 인식 로컬 기능을 제공하지만 아직 출력 분포에서 표현력이 유사한 글로벌 그래픽 모델과 통합되지 않았습니다.우리의 모델은 선형 체인 CRF를 초월하고 출력 라벨마다 여러 개의 숨겨진 상태를 포함하지만 저질 대수 평점 행렬을 사용하여 이를 매개 변수화하여 숨겨진 상태의 삽입 공간을 효과적으로 학습했다.이런 추리 변수의 확장 잠재 공간은 RNN의 풍부한 특징 표시를 보충하고 정확한 전역 추리가 복잡하고 학습적인 비국부적인 출력 제약에 복종하도록 허용한다.우리는 몇 개의 데이터 집합에 대해 실험을 진행하였는데, 그 결과 이 모델의 성능이 기선보다 우수하다는 것을 나타냈다', 'sw': 'Kazi za utekelezaji wa taarifa za msingi za kompleksi mara nyingi huwekwa kama alama ya mfululizo au uchambuzi mdogo, ambapo maeneo yanatengenezwa kwa kutumia mabango ya maeneo yanayotokana na uwezekano wa kupunguzwa kwa mifano ya picha yenye mabadiliko yanayolazimika. Recently, it has become common to locally parametrize these models using rich features extracted by recurrent neural networks (such as LSTM), while enforcing consistent outputs through a simple linear-chain model, representing Markovian dependencies between successive labels.  Hata hivyo, muundo wa picha rahisi unaamini kuwa vizuizi vingi vidogo vinavyojitokeza mara nyingi vinginevyo vigumu kati ya alama za utoaji. Kwa mfano, maeneo mengi, kama vile jina la kwanza, yanaweza kutokea mara kadhaa tu, au kwa uwepo wa mashamba mengine. Wakati raia wa RNNN wametoa sifa za maeneo yenye ufahamu mkubwa kwa ajili ya viungo vya mfululizo, bado bado hawajaunganishwa na mtindo wa picha za kidunia wa kujieleza kama hizo katika usambazaji wa matokeo. Mfano wetu unakwenda zaidi ya mfumo wa msingi wa CRF ili kuingiza nchi nyingi zilizofichikwa kwa kila alama ya utoaji, lakini hufananisha kwa pamoja na matoleo yenye uwezekano wa kublogu kwa kiwango cha chini, kwa ufanisi wa kujifunza nafasi ya kuingia kwa nchi zilizofichikana. Hii inaongezeka nafasi ya hivi karibuni ya mabadiliko ya maambukizi yanachanganya utajiri wa uwakilishi wa RNN, na inaruhusu kuongezeka kwa ugonjwa wa kimataifa kusikiliza tatizo, kujifunza vikwazo visivyotokana na matokeo yasiyo ya wenyeji. tunajaribu kwa seti kadhaa za taarifa na kuonyesha kwamba mifano inafanya msingi', 'fa': 'وظیفه\u200cهای اخراج اطلاعات پیچیده\u200cای متن اغلب به عنوان برچسب\u200cهای برچسب\u200cهای برچسب یا برچسب\u200cهای پیچیده\u200cای قرار می\u200cگیرند، جایی که زمینه\u200cها با استفاده از برچسب\u200cهای محلی که از طریق آلوده\u200cهای احتمالات پیچیده\u200cای در یک مدل گرافیک با اخیرا، این مدلها را با استفاده از ویژه\u200cهای ثروتمند که توسط شبکه\u200cهای عصبی (مثل LSTM) بازگشت می\u200cکنند، با استفاده از ویژه\u200cهای شبکه\u200cهای عصبی (مثل LSTM) معمول می\u200cشود، در حالی که اجرای نتیجه\u200cهای هماهنگی با یک مدل\u200cهای زنجیر خطی ساده، نمایش می\u200cدهد ولی ساختار مدل گرافیک ساده اعتقاد می\u200cکند که محدودیت غیر محلی بین برچسب\u200cهای خروج اغلب پیچیده است. برای مثال، بسیاری از زمینه\u200cها، مثل نام اول، می\u200cتوانند فقط چند بار ثابت باشند، یا در حضور دیگر زمینه\u200cها. در حالی که RNN\u200cها ویژگی\u200cهای محلی که به محیط اطلاعات کنترل قوی\u200cتر می\u200cدانند برای نشان\u200cگذاری\u200cهای ترکیب، هنوز باید با یک مدل گرافیک جهانی از ویژه\u200cهای مشابه در توزیع نتیجه کنترل شوند. مدل ما فراتر از زنجیر خطی CRF می\u200cرود تا در هر نقاشی نتیجه چندین وضعیت مخفی را جمع کند، ولی آنها را با ماتریس\u200cهای اسکور کردن لاگ-پتانسیل پایینده\u200cای متخصص می\u200cکند، به طور موثرت فضای وارد کردن برای وضعیت مخفی یاد بگیرد این فضای تاریخی افزایش از تغییرات آلودگی به عنوان نمایش ثروتمند RNN اضافه می\u200cکند و اجازه می\u200cدهد که آلودگی جهانی دقیقاً پیچیده شده، محدودیت خروجی غیر محلی یاد گرفته باشد. ما با چند تنظیم داده آزمایش می کنیم و نشان می دهیم که مدل از خط پایین', 'tr': "Komplik metin maglumaty tapmaky görevleri köplenç sıralanjak etitlendirmek ýa-da puça parslamak üçin bellenilýär. Bu ýerde sowgatlar, süýtgeli geçişmeler bilen grafik modde mümkin bir näbelli hasaplanjak bilen ýerleşýän etitler ullanylýar. Soňky wagtlarda, bu nusgalary ýerleşdirilýän nusgalar (LSTM ýaly) tarapyndan çykarylýan baý özelliklerden ullanýan, ýerleşdirilýän nusgalary ýerleşdirilýändir we bu nusgalary ýerleşdirilýän basit çyzgyly-zincir modelinin aralygy bilen süýtgedýändir. Ýöne basit grafik nusgasy çykyş etiketleriň arasynda gaty bir ýerli döwletleri ynanýar. Mesela, ilkinji ad ýaly köp sahypa diňe takyk sany ýagdaýda bolup biler. RNN köpräk taýýarlamak üçin ýerleşdirim tanyşlary üçin güýçli kontekst-tanyşlaryny temin etdiler bolsa, Çikgi daýratynda ýaly bir grafik modeli bilen üýtgedilmelidir. Bizim modelimiz çizgi çizgi CRF'den fazla gizli durumları çizgi etiketlerde dahil etmek için çizgi çizgi şeklinde geçiyor fakat bu durumları gizli durumlar için çizgi bir yer öğrenmek için dayanabilir. Bu gelişmiş aşağılık değişikliklerinin tükettiği laten alanı RNN'in zengin özelliklerini aştırır ve tam küresel aşağılık karmaşıklı ve yerel çıkış içeriklerini öğrenir. Biz birnäçe veri setirleri bilen synanyşýarys we nusganyň baseçiliki ýok bolmagyny görkez", 'am': 'የጽሑፍ መረጃ ማውጣት ስራዎች በብዛት ጊዜ የጽሑፍ ማህበረሰብ ወይም የጥቁር ማህበረሰብ እንደሚያሳየፉ ናቸው፡፡ Recently, it has become common to locally parametrize these models using rich features extracted by recurrent neural networks (such as LSTM), while enforcing consistent outputs through a simple linear-chain model, representing Markovian dependencies between successive labels.  ምንም እንኳን፣ ቀላል የግራፊካል ዓይነቶች መሠረት በውጤት ምልክቶች መካከል ብዙ ጊዜ ያልሆነውን ግንኙነት ይክዳል፡፡ ለምሳሌ፥ ብዙ እርሻዎች እንደ ፊተኛው ስም ቁጥር ብቻ ወይም በሌላ እርሻ ፊት ሊሆን ይችላል። RNNs በተጨማሪው አካባቢ እና የአካባቢ ምርጫዎች ለግንኙነት ማሰናከል ሲያሳየቁ፣ በውጤት አካባቢ እና በሚመስል የዓለምአቀፍ ግልጾች ምሳሌ ጋር ገና አይጠቅሙም፡፡ ሞዴሌያችን በክፍለ ውጤት መለያ ላይ የተሰወረውን የአውጤት ግንኙነትን ለመግለጥ በሥርዓት ሰንሰለት ላይ ይሄዳል፡፡ ግን በተሰወረ ሀገሮች ላይ የተሰወረውን ስፍራን ለመማር ይችላል፡፡ ይህ የአካባቢው መሠረት አካባቢ ቦታ የRNN ባለጠጋ ምርጫዎችን ማሳየት ይጨምርበታል፤ የዓለምአቀፍ ማቀናቀል በተጨማሪው ውጤት፣ የአገር ውጤት ግንኙነትን ያልተማረ ግንኙነት ይጨምርበታል፡፡ ብዙዎች ዳታዎችን እናሳየናለን እና ምሳሌው መሳሪያውን እንደሚያሳየው', 'sq': 'Complex textual information extraction tasks are often posed as sequence labeling or shallow parsing, where fields are extracted using local labels made consistent through probabilistic inference in a graphical model with constrained transitions.  Kohët e fundit, është bërë e zakonshme të parametrizohen lokalisht këto modele duke përdorur karakteristika të pasura të nxjerra nga rrjetet neurale të përsëritura (të tilla si LSTM), duke zbatuar daljet e konsistenta nëpërmjet një modeli të thjeshtë rrjeti linear, që përfaqëson varësitë e Markovian midis etiketave pasuese. Megjithatë, struktura e thjeshtë e modelit grafik mohon kufizimet shpesh komplekse jo-lokale midis etiketave të daljes. Për shembull, shumë fusha, si emri i parë, mund të ndodhin vetëm një numër të caktuar herë, ose në praninë e fushave të tjera. Ndërsa RNN-të kanë dhënë gjithnjë e më të fuqishme karakteristika lokale të ndërgjegjshme në kontekst për shënimin e sekuencës, a to ende nuk duhet të integrohen me një model grafik global të ekspresivitetit të ngjashëm në shpërndarjen e daljes. Modeli ynë shkon përtej zinxhirit linear CRF për të përfshirë shumë shtete të fshehura për etiketën e daljes, por i parametrizon ato parsimonikisht me matricë të rendit të ulët log-potencial, duke mësuar efektivisht një hapësirë të përfshirë për shtete të fshehura. Ky hapësirë i shtuar latent i ndryshuesve të inferencës komplementon përfaqësimin e pasur të funksioneve të RNN dhe lejon inferencën ekzakte globale që respekton kufizimet e daljes së mësuara jo-lokale. Ne eksperimentojmë me disa grupe të dhënash dhe tregojmë se modeli ekziston në bazë', 'af': "Kompleks tekstuele inligting uitvoer taak word dikwels as volgorde etiketting of slag verwerking posisieer, waar velde word uitgevoer deur plaaslike etikette wat gemaak word konsistent deur waarskynliklike inferensie in 'n grafiese model met beperkte transisies. Onlangs het dit gemeenskap geword om hierdie modele te parametrieer deur ryke funksies wat deur rekursiewe neuralnetwerke (soos LSTM) uitgevoer word, terwyl dit konsistente uitgevoerdes deur 'n eenvoudige lineêre ketting model te verskyn, wat Markovian afhanklikhede tussen suksesiewe etikette verteenwoordig word. Maar die eenvoudige grafiese model struktuur verlief die dikwels komplekse nie- plaaslike beheinings tussen uitset etikette. Byvoorbeeld, baie velde, soos 'n eerste naam, kan slegs 'n vaste aantal maal voorkom of in die voorsiening van ander velde. Terwyl RNN het verminder kragtige konteks bewys plaaslike funksies vir sekwensiemerking verskaf, het hulle nog integreer met 'n globale grafiese model van gelyke uitdrukking in die uitvoer verspreiding. Ons model gaan buite die lineêre ketting CRF om veelvuldige weggesteekte staatste per uitset etiket te inkorpreer, maar parametriseer hulle parsimonies met lae- rank log- potensiele skoring matrikse, effektief leer 'n inbêring spasie vir verborge staatste. Hierdie vergroot latente ruimte van inferensie veranderlikes complementeer die ryk funksie voorstelling van die RNN, en laat toe presies globale inferensie wat volgens kompleks, leer nie- plaaslike uitset beheinings. Ons eksperimenteer met verskeie datastelle en wys dat die model uitvoer baselyn", 'hy': 'Հաճախ բարդ տեքստային ինֆորմացիայի վերացման խնդիրները դիտարկում են որպես հաջորդականության պիտակ կամ մակերեսային վերլուծում, որտեղ դաշտերը վերացվում են օգտագործելով տեղական պիտակներ, որոնք համապատասխան են հավանականության հետևանքների միջոցով գրաֆիկ մոդելի մեջ,  Վերջերս այս մոդելները տարածվել են տեղական պարամետրիզացիայի միջոցով, օգտագործելով հարուստ հատկություններ, որոնք ստացվում են կրկնօրինակ նյարդային ցանցերով (ինչպիսիք են ԼՍԹՄ), միաժամանակ պաշտպանելով համապատասխան արտադրությունները պարզ գծային շղթային մոդելի միջոցով, որը Այնուամենայնիվ, պարզ գրաֆիկ մոդելի կառուցվածքը հավատում է արտադրման պիտակների միջև հաճախ բարդ ոչ տեղական սահմանափակումներին: Օրինակ, շատ դաշտեր, ինչպիսիք են նախաանունը, կարող են տեղի ունենալ միայն որոշակի անգամ կամ այլ դաշտերի առկայության դեպքում: While RNNs have provided increasingly powerful context-aware local features for sequence tagging, they have yet to be integrated with a global graphical model of similar expressivity in the output distribution.  Մեր մոդելը գնում է գծային շղթայից դուրս, որպեսզի ներառի բազմաթիվ թաքնված վիճակներ յուրաքանչյուր արտադրողական պիտակ, բայց պարամետրիմացնում է դրանք միանգամայն ցածր աստիճանի լոգ-պոտենցիալ գնահատման մաթերիսներով, արդյունավետ Այս ավելացված հետեւանքների փոփոխականների թաքնված տարածքը համալրացնում է ՌՆԹ-ի հարուստ հատկանիշների ներկայացումը և թույլ է տալիս համընդհանուր հետեւանքները լսել բարդ, սովորված ոչ տեղական արտադրման սահմանափակումները: Մենք փորձում ենք բազմաթիվ տվյալների համակարգերով և ցույց ենք տալիս, որ մոդելը հաջողվում է', 'az': "Müxtəlif məlumat çıxarma işləri çox sıralar etiketləməsi və yaxud çəkilməsi olaraq, yerli etiketlər vasitəsilə müəyyən edilmiş bir grafik modeli ilə müəyyən keçişləri ilə müəyyən edilmiş olaraq müxtəlif etiketlərlə istifadə edilən yerli etiketlərlə çıxarılır. Son zamanlarda, bu modelləri təkrarlanan nöral a ğları (LSTM kimi) ilə təkrarlanan zengin fəaliyyətlərdən istifadə edərək yerli parametrize etmək ortaq oldu, sadəcə linear-zincir modeli ilə müəyyən edilən, Markoviya təkrarları etiketlərin arasındakı təkrarları göstərir. Lakin basit grafik modellərin quruluşu, çıxış etiketlərinin arasındakı çox kompleks olmayan quruluşlarını iddia edir. Misal olaraq, ilk adı kimi çoxlu sahələr yalnız müəyyən sayı dəfə və ya başqa sahələrin yanında olar. RNN-lər seçmək məqsədilə çox qüvvətli məlumatlardan xəbərdarlıq edən yerli fəaliyyətlər təyin etdikləri halda, onlar hələ də cürbəcür grafik modellərlə bənzər ifadə dağıtılışında birləşdirilməsi lazımdır. Bizim modellərimiz çizgi CRF-dən çox gizli durumları çıxış etiketində birləşdirmək üçün, amma onları düşük dərəcə log-potensialı scoring matrikləri ilə parçalayır, gizli durumların içində bir yer öyrənir. Bu küçük küçük dəyişikliklərin latent alanı RNN'in zəngin tərzini tamamlayır və qlobal tərzini kompleks, öyrənməmiş yerli çıxış müəyyənləşdirmələrinə müvəffəq edər. Biz bir neçə verilən qurğu ilə təcrübə edirik və modellərin səhifələri", 'bn': 'Complex textual information extraction tasks are often posed as sequence labeling or shallow parsing, where fields are extracted using local labels made consistent through probabilistic inference in a graphical model with constrained transitions.  সম্প্রতি স্থানীয় মোডেলগুলোকে সমৃদ্ধ বৈশিষ্ট্য ব্যবহার করে স্থানীয় প্যারামেটারিজ ব্যবহার করা হয়েছে এবং সাফল্য লেবেলের মধ্যে প্রতিনিধিত্ব করে মার্কোভিয়ার নির্ভরিত বৈশিষ তবে সাধারণ গ্রাফিক্যাল মডেল কাঠামো প্রায়শই আউটপুট লেবেলের মধ্যে জটিল বৈধ বিশ্বাস করে। উদাহরণস্বরূপ, অনেক ক্ষেত্র, যেমন প্রথম নাম, শুধুমাত্র নির্ধারিত সংখ্যা বার ঘটতে পারে, অথবা অন্য ক্ষেত্রের এদিকে আরএনএন বাড়তে পারে ক্ষমতাশালী স্থানীয় বৈশিষ্ট্য-সচেতনতা স্থানীয় বৈশিষ্ট্যাগ ট্যাগিং এর জন্য, কিন্তু আউটপুট বিতরণে একই ধরনের বিশ আমাদের মডেল প্রতি আউটপুট লেবেলেটের প্রতি অনেক লুকিয়ে রাখার জন্য কিছু লুকিয়ে রাখা চেইনের বাইরে যায়, কিন্তু সেগুলোকে একই সাথে প্যারামিটারিটির সাথে নীচ এনএন-এর সমৃদ্ধ বৈশিষ্ট্য প্রতিনিধিত্বের সাম্প্রতিক স্থান বাড়িয়ে দিয়েছে এবং স্থানীয় আউটপুট নিয়ন্ত্রণের শিক্ষা প্রদান করা হয়েছে। আমরা বেশ কয়েকটি ডাটাসেট দিয়ে পরীক্ষা করছি এবং দেখাচ্ছি যে মডেল বেসেলাইনের আউটলাইন', 'cs': 'Komplexní úlohy extrakce textových informací jsou často předkládány jako sekvenční popisování nebo mělké analýzy, kde jsou pole extrahována pomocí lokálních štítků, které jsou konzistentní prostřednictvím pravděpodobnostní inference v grafickém modelu s omezenými přechody. V poslední době je běžné tyto modely lokálně parametrizovat pomocí bohatých funkcí extrahovaných rekurentními neuronovými sítěmi (například LSTM) a vynucovat konzistentní výstupy prostřednictvím jednoduchého lineárního řetězcového modelu, reprezentujícího markovovy závislosti mezi následujícími štítky. Nicméně jednoduchá grafická struktura modelu popírá často složitá nekomístní omezení mezi výstupními štítky. Například mnoho polí, jako je křestní jméno, se může objevit pouze pevný počet nebo v přítomnosti jiných polí. Zatímco RNN poskytovaly stále výkonnější kontextově orientované lokální funkce pro sekvenční tagování, ještě nebyly integrovány s globálním grafickým modelem podobné expresivity v distribuci výstupu. Náš model překračuje rámec lineárního řetězce CRF a zahrnuje více skrytých stavů na výstupní štítek, ale parametrizuje je parsimoniózně pomocí nízké hodnoty log-potenciál bodování matic, což efektivně učí vkládací prostor pro skryté stavy. Tento rozšířený latentní prostor inferenčních proměnných doplňuje bohatou reprezentaci funkcí RNN a umožňuje přesnou globální inferenci podle komplexních, naučených nekomístních výstupních omezení. Experimentujeme s několika datovými sadami a ukážeme, že model překonává základní hodnotu', 'fi': 'Monimutkaiset tekstitiedon uuttamistehtävät esitetään usein sekvenssimerkinnöinä tai matalana jäsentämisenä, jossa kentät poimitaan käyttämällä paikallisia tunnisteita, jotka on tehty yhdenmukaisiksi todennäköisen päättelyn avulla graafisessa mallissa, jossa on rajoitettuja siirtymiä. Viime aikoina on yleistynyt parametrisoida nämä mallit paikallisesti käyttämällä toistuvien hermoverkkojen (kuten LSTM) tuottamia rikkaita ominaisuuksia samalla kun ne vahvistavat johdonmukaisia lähtöjä yksinkertaisella lineaarisella ketjumallilla, joka edustaa markovialaisia riippuvuuksia peräkkäisten tunnisteiden välillä. Yksinkertainen graafinen mallirakenne kuitenkin kumoaa usein monimutkaiset ei-paikalliset rajoitukset tulostuslaitteiden välillä. Esimerkiksi monet kentät, kuten etunimi, voivat esiintyä vain kiinteän määrän kertoja tai muiden kenttien läsnä ollessa. Vaikka RNN:t ovat tarjonneet yhä tehokkaampia kontekstitietoisia paikallisia ominaisuuksia sekvenssimerkkaukseen, niitä ei ole vielä integroitu globaaliin graafiseen malliin, jolla on samanlainen ekspressiivisyys tulosjakelussa. Mallimme ulottuu lineaarisen ketjun CRF:n ulkopuolelle sisällyttääkseen useita piilotettuja tiloja tulosetikettiä kohden, mutta parametrisoi ne vähävaraisesti matalan tason log-potentiaalin pisteytysmatriiseilla, oppien tehokkaasti upotustilan piilotetuille tiloille. Tämä laajennettu latentti tila päättelymuuttujia täydentää RNN:n rikkaita ominaisuuksia ja mahdollistaa tarkan globaalin päättelyn, joka noudattaa monimutkaisia, opittuja ei-paikallisia tuotosrajoituksia. Kokeilemme useita aineistoja ja osoitamme, että malli ylittää lähtötilanteen', 'bs': 'Kompleksi izvlačenje tekstualnih informacija često se postavljaju kao etiketiranje sekvence ili plitko analiziranje, gdje se polja izvlače koristeći lokalne etikete koje su u skladu s vjerojatnošću infekcijom u grafičkom modelu s ograničenim tranzicijama. Nedavno je postalo često lokalno parametriranje tih model a koristeći bogate karakteristike izvlačene repertovanim neuralnim mrežama (kao što je LSTM), dok provođuju konsekventne ishode kroz jednostavan linearni lanac model koji predstavlja Markovijsku zavisnost između nasljednih etiketa. Međutim, jednostavna grafska modelska struktura vjeruje da često kompleksna ne lokalna ograničenja između etiketa izlaza. Na primjer, mnoge polja, poput imena, mogu se pojaviti samo određen broj puta, ili u prisustvu drugih polja. Iako su RNN pružili sve moćne lokalne karakteristike koje su svjesne konteksta za označavanje sekvence, još uvijek se ne moraju integrirati sa globalnim grafičkim modelom slične izrazitosti u distribuciji izlaza. Naš model prolazi preko linearnog lanca CRF-a da uključuje više skrivenih država po etiketi izlaza, ali ih parametrira parsimonički sa matricijama niskog reda log-potencijalnog skretanja, učeći učenje prostora za uključenje skrivenih država. Ovaj povećani latentni prostor varijanta infekcije dopunjava bogatim predstavljanjem RNN-a i omogućava tačno globalnu infekciju koja se sluša kompleksnom, naučenim ograničenjima neolokalnog izlaza. Eksperimentiramo sa nekoliko podataka i pokazujemo da je model nadmašio početnu liniju', 'et': 'Keerulised tekstiteabe ekstraheerimise ülesanded kujutatakse sageli järjestuse märgistamiseks või madalaks parsimiseks, kus väljad ekstraheeritakse kohalike siltide abil, mis on kooskõlas tõenäolise järeldusega piiratud üleminekutega graafilises mudelis. Viimasel ajal on muutunud tavaliseks nende mudelite kohalik parametreerimine, kasutades rikkalikke funktsioone, mida ekstraheerivad korduvad närvivõrgud (nt LSTM), samal ajal jõustades järjepidevaid väljundeid lihtsa lineaarahelaga mudeli kaudu, mis esindab Markovia sõltuvusi järjestikuste siltide vahel. Kuid lihtne graafilise mudeli struktuur varjab sageli keerulisi mittekohalisi piiranguid väljundsiltide vahel. Näiteks võivad paljud väljad (nt eesnimi) esineda ainult kindlaksmääratud arvu kordi või muude väljade juuresolekul. Kuigi RNN-id on pakkunud järjestuste märgistamiseks järjest võimsamaid kontekstiteadlikke kohalikke funktsioone, ei ole neid veel integreeritud globaalse graafilise mudeliga, millel on sarnane väljendusjaotus. Meie mudel läheb lineaarsest ahelast CRF kaugemale, et sisaldada mitmeid peidetud olekuid väljundsildi kohta, kuid parametriseerib neid väheselt madala astme logipotentsiaali skoorimise maatriksidega, õppides tõhusalt varjatud olekute manustamisruumi. See laiendatud latentne ruum järelduste muutujatest täiendab RNN-i rikkalikku funktsiooni ja võimaldab täpset globaalset järeldust, järgides keerukaid, õppitud mittekohalisi väljundpiiranguid. Me eksperimenteerime mitmete andmekogumitega ja näitame, et mudel ületab algväärtuse', 'ca': "Les tasques complexes d'extracció d'informació textual sovint es posen com etiquetes de seqüència o analitzacions baixes, on els camps s'extraeixen fent servir etiquetes locals consistents a través de la inferència probabilística d'un model gràfic amb transicions restringides. Recentment, ha esdevingut comú parametritzar localment aquests models utilitzant característiques riques extraïdes per xarxes neurals recurrents (com LSTM), mentre aplicant productes consistents a través d'un simple model de cadena linear, representant les dependencies Markovianes entre etiquetes sucesives. However, the simple graphical model structure belies the often complex non-local constraints between output labels.  Per exemple, molts camps, com un primer nom, només poden produir un nombre fixe de vegades, o en presencia d'altres camps. While RNNs have provided increasingly powerful context-aware local features for sequence tagging, they have yet to be integrated with a global graphical model of similar expressivity in the output distribution.  El nostre model va més enllà de la cadena linear CRF per incorporar múltiples estats ocults per etiqueta de sortida, per ò els parametritza parsimoniosament amb matrices de puntuació log-potencial de baix rangs, aprenent efectivament un espai d'incorporació per estats ocults. Aquest espai latent augmentat de variables de inferència complementa la ricíssima representació del RNN, i permet que la inferència global exacta obeï a restriccions de producció complexes i descobertes no locals. Experimentem amb diversos conjunts de dades i demostrem que el model supera la base", 'he': 'משימות חיפוש מידע טקסטלי מורכבות לעתים קרובות מועמדות כתווית רצף או בדיקת שטחית, שבו שדות יוצאים באמצעות תוויות מקומיות שנעשו תואמות באמצעות ההנחה הסבירותית במודל גרפי עם העברות מוגבלות. לאחרונה, הפך לפרמטריה מקומית של הדוגמנים האלה באמצעות תכונות עשירות שנוצאות על ידי רשתות עצביות מתחזרות (כמו LSTM), בזמן שהוצאות קבועות מודל שורשרת לינרית פשוטה, מייצגת תלויות מרקובית בין תוויות קבועות. עם זאת, מבנה הדוגמנית הגרפית הפשוט משקר את ההגבלות המורכבות לעתים קרובות לא מקומיות בין תוויות יציאה. לדוגמה, שדות רבים, כמו שם פרטי, יכולים להתרחש רק מספר קבוע פעמים, או בנוכחות שדות אחרים. בעוד RNN סיפקו תכונות מקומיות חזקות יותר ויותר מודעות לקונקסט לתג רצף, הם עדיין לא מושלמים עם מודל גרפי גלובלי של ביטוי דומה בהפצה יציאה. המודל שלנו עובר מעבר לשרשרת הקרין לינרית כדי להכיל מדינות מסתורות רבות לכל תווית יציאה, אבל מפרמיטרי אותם באופן פרסימוני עם מטריסי ניקוי לוג-פוטנציאל נמוך, ללמוד בעובדה מרחב ניקוי למדינות מסתורות. This augmented latent space of inference variables complements the rich feature representation of the RNN, and allows exact global inference obeying complex, learned non-local output constraints.  אנו מנסים עם מספר קבוצות נתונים ולהראות שהדוגמנית מתגברת על ביצוע ראשון', 'ha': "Complex textual information extraction tasks are often posed as sequence labeling or shallow parsing, where fields are extracted using local labels made consistent through probabilistic inference in a graphical model with constrained transitions.  A yanzu, ya zama ɗabi'a wa kafarita waɗannan misalin a lokal, ta yi amfani da wasu mistakardu masu riki da aka fitar da su na masu tarakin tarakin neural (kamar misãlin LSSM), a lokacin da za'a lazimta masu adadi a tsakanin misalin linjeri mai sauƙi, kuma yana gaya masu ƙayyade Marokoyan a tsakanin tagogi masu cin nasara. A lokacin da, tsarin misalin grafi mai sauƙi na gaskata, yana yin ĩmãni, ƙuduro masu kambu masu adadi ne masu lokal a tsakanin alama masu fitarwa. Misali, misali masu yawa kamar sunan farko, za'a iya sãmu ƙidãyar kwãnukan da aka ƙayyade, ko kuwa a cikin wurãren dabam. Waka da RNNS suka bãyar da wasu tayari na ƙaranci mai ƙarfi na context-award wa tagning sequence, ba za'a iya haɗa su ba da wani misali na global grafi na daidaita maganar ajiya cikin rabin fitarwa. @ info: whatsthis Wannan na ƙari da aka ƙãra wa filin na variablewa na kasa, yana cikakken tsarin sha'awa na rubutun da shirin RNN, kuma yana yarda ya ƙayyade lissafi na global da za'a yi ɗabi'a masu kamfata, an sanar da tsarin ajiya na lokal. Kana jarraba da wasu database kuma ke nuna misalin zafi", 'sk': 'Kompleksna naloga ekstrakcije besedilnih informacij se pogosto predstavljajo kot označevanje zaporedja ali plitvo razčlenitev, kjer se polja ekstraktirajo z lokalnimi oznakami, ki so skladne z verjetnostno sklepanjem v grafičnem modelu z omejenimi prehodi. V zadnjem času je postalo običajno lokalno parametrizirati te modele z uporabo bogatih funkcij, pridobljenih s ponavljajočimi se nevronskimi omrežji (kot je LSTM), hkrati pa uveljavljati konsistentne izhode prek preprostega modela linearne verige, ki predstavlja markovijske odvisnosti med zaporednimi oznakami. Vendar pa preprosta struktura grafičnega modela zakriva pogosto zapletene ne-lokalne omejitve med izhodnimi oznakami. Na primer, veliko polj, na primer ime, se lahko pojavi le določeno število krat ali v prisotnosti drugih polj. Čeprav so RNN zagotavljali vse močnejše lokalne funkcije za označevanje zaporedja, jih še ni treba integrirati z globalnim grafičnim modelom podobne ekspresivnosti v izhodni distribuciji. Naš model presega linearno verigo CRF in vključuje več skritih stanj na izhodno oznako, vendar jih parametrizira z nizkimi ocenjevalnimi matricami log potenciala in učinkovito uči vgradni prostor za skrite stanja. Ta povečan latentni prostor sklepnih spremenljivk dopolnjuje bogato predstavitev značilnosti RNN in omogoča natančno globalno sklepanje, ki upošteva kompleksne, naučene ne-lokalne izhodne omejitve. Eksperimentiramo z več nabori podatkov in pokažemo, da model presega osnovno vrednost', 'bo': 'Complex textual information extraction tasks are often posed as sequence labeling or shallow parsing, where fields are extracted using local labels made consistent through probabilistic inference in a graphical model with constrained transitions. Recently, it has become common to locally parametrize these models using rich features extracted by recurrent neural networks (such as LSTM), while enforcing consistent outputs through a simple linear-chain model, representing Markovian dependencies between successive labels. However, the simple graphical model structure belies the often complex non-local constraints between output labels. དཔེར་ན། མིང་དང་པོ་ཞིག While RNNs have provided increasingly powerful context-aware local features for sequence tagging, they have yet to be integrated with a global graphical model of similar expressivity in the output distribution. Our model goes beyond the linear chain CRF to incorporate multiple hidden states per output label, but parametrizes them parsimoniously with low-rank log-potential scoring matrices, effectively learning an embedding space for hidden states. This augmented latent space of inference variables complements the rich feature representation of the RNN, and allows exact global inference obeying complex, learned non-local output constraints. ང་ཚོས་གནད་སྡུད་ཚན་མང་པོ་ཞིག་གིས་ལག་ལེན་བྱེད་ཀྱི་མིག་གཟུགས་རིས་གཞི་རྩལ་བ་ནི་', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness biasane politenessoffpolite"), and when there is a change ("assertivepoliteness Sampeyan, akeh pengguna liyane, nganggo jeneng pangan, iso disebarke nambah sing wis kana, o nganggo dilawake sing wis ana. Mengko karo DNN wis nambah luwih-luwih akeh kontext-Awar bukene kanggo ditambah sekondirno, dhewe isih iso nguasai nggo ndelok model global grafne soko kesalakno sing mungkin sekondirno neng output model string" in "context_BAR_stringLink Awak dhéwé éntuk karo akeh dadi-akeh lan ngonngono kuwi model kuwi ora bisa ditambah'}
{'en': 'Continuous Word Embedding Fusion via ', 'ar': 'دمج الكلمة المستمر من خلال التحلل الطيفي', 'ja': 'スペクトル分解による連続的なワード埋め込み融合', 'hi': 'निरंतर शब्द एम्बेडिंग फ्यूजन वर्णक्रमीय अपघटन के माध्यम से', 'fr': "Fusion continue d'intégration de mots via la décomposition spectrale", 'es': 'Fusión continua de incrustación de palabras mediante descomposición espectral', 'pt': 'Fusão de incorporação contínua de palavras via decomposição espectral', 'ga': 'Comhleá Leabú Leanúnach Focal trí Dhianscaoileadh Speictrim', 'zh': '因光谱分解连词嵌融合', 'ru': 'Непрерывное слияние при встраивании слов через спектральное разложение', 'ka': 'Name', 'hu': 'Folyamatos szó beágyazása spektrális bontással', 'el': 'Συνεχής ενσωμάτωση λέξεων μέσω φασματικής αποσύνθεσης', 'it': 'Fusione continua di incorporazione di parole tramite scomposizione spettrale', 'kk': 'Спектрондық бөлімі арқылы сөзді ендіру Fusion', 'lt': 'Nuolatinė žodžių įterpimo jungtis per spektrinę dekompoziciją', 'mk': 'Континуирана фузија за внесување на зборови преку спектрална декомпозиција', 'ms': 'Name', 'ml': 'സ്പെക്ട്രെക്ട്രാല്\u200d ഡികോമ്പോസിഷന്\u200d മുഖാനുപയോഗിച്ചുള്ള വാക്ക് എംബെഡിങ് ഫ്യൂഷ', 'mt': 'Fużjoni kontinwa tal-Inkorporazzjoni tal-Kliem permezz tad-Dekompożizzjoni Spettrali', 'mn': 'Үндсэн үг нэвтрэх Fusion-г Spectral Decomposition аргаар', 'no': 'Kontinuerleg tekstinnbygging av fusjon via spektraldekomposisjon', 'pl': 'Ciągłe osadzanie słów Fusion za pomocą dekompozycji spektralnej', 'ro': 'Fuziunea continuă a cuvintelor prin decompoziție spectrală', 'sr': 'Neprestano ukljuèujuæi fuziju reèi preko spektralne dekompozicije', 'si': 'ස්පෙක්ටරල් සංකරණය මධ්\u200dයමයෙන් සම්බන්ධ වචනය සම්බන්ධ කරනවා', 'so': 'Heshiiska degista ee hadalka sii socda', 'sv': 'Kontinuerlig sammanfogning av ord via spektral nedbrytning', 'ta': 'Continuous Word Embedding Fusion via Spectral Decomposition', 'ur': 'Name', 'uz': 'Continuous Word Embedding Fusion via Spectral Decomposition', 'vi': 'Liên tục nhúng cầu chì qua bộ phân phối nhiệt.', 'bg': 'Непрекъснато вграждане на думи чрез спектрално разлагане', 'hr': 'Kontinuirano uključujuće fuzije riječi preko spektralne dekompozicije', 'da': 'Kontinuerlig ordindlejring fusion via spektral nedbrydning', 'nl': 'Continue Word Embedded Fusion via Spectrale Decompositie', 'de': 'Continuous Word Embedded Fusion über Spectral Decomposition', 'id': 'Fusi Pencampuran Kata Terus melalui Dekomposisi Spektral', 'fa': 'Name', 'sw': 'Mfuko wa neno linaloendelea kupitia Makala ya Uzungumzo', 'tr': 'Kontrol Beýikmegi Aramlary Metini Dolamak Fusiýasy', 'af': 'Kontinueerde Woord Inbêer Fusion deur Spektral Dekomposisie', 'am': 'ቦታ፦', 'sq': 'Fusion i vazhdueshëm i përfshirjes së fjalëve nëpërmjet dekompozimit spektral', 'hy': 'Շարունակ բառերի ներգրավման ֆուզիան սպեկտրալ բաժանման միջոցով', 'bn': 'স্পেক্ট্রেল ডিসোম্পেশনের মাধ্যমে চলতে থাকা শব্দ এমবেডিং ফিশন', 'az': 'Spektral Dekompozisyonu vasit톛sil톛 daxil edil톛n S칬zl칲k Fusion', 'ca': 'Continuous Word Embedding Fusion via Spectral Decomposition', 'cs': 'Kontinuální vkládání slov Fusion pomocí spektrální dekompozice', 'ko': '스펙트럼 분해를 바탕으로 하는 연속어 삽입 융합', 'bs': 'Kontinuirano uključujuće Fuziju riječi preko spektralne dekompozicije', 'et': 'Sõnade pidev põimimine spektraalse lagunemise kaudu', 'fi': 'Jatkuva Word Embedding Fusion spektraalisen hajoamisen kautta', 'sk': 'Neprekinjeno vdelavo besed prek spektralnega razpadanja', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'Continuous Word Embedding Fusion via Spectral Decomposition', 'ha': '@ action', 'bo': 'Continuous Word Embedding Fusion via Spectral Decomposition'}
{'en': 'Word embeddings have become a mainstream tool in ', 'ar': 'لقد أصبح تضمين الكلمة أداة رئيسية في معالجة اللغة الطبيعية الإحصائية. غالبًا ما يستخدم الممارسون ناقلات الكلمات المدربة مسبقًا ، والتي تم تدريبها على مجموعة نصية عامة كبيرة ، وهي متاحة بسهولة على الويب. ومع ذلك ، غالبًا ما تفتقر ناقلات الكلمات المدربة مسبقًا إلى كلمات مهمة من مجالات محددة. لذلك من المستحسن في كثير من الأحيان توسيع المفردات وتضمين كلمات جديدة في مجموعة من متجهات الكلمات المدربة مسبقًا. في هذه الورقة ، نقدم طريقة فعالة لتضمين كلمات جديدة من مجموعة متخصصة ، تحتوي على كلمات جديدة ، في زخارف الكلمات العامة المدربة مسبقًا. نحن نبني على وجهة النظر الراسخة لتضمينات الكلمات كعوامل مصفوفة لتقديم خوارزمية طيفية لهذه المهمة. توضح التجارب التي أجريت على العديد من المجموعات الخاصة بالمجال مع المفردات المتخصصة أن طريقتنا قادرة على تضمين الكلمات الجديدة بكفاءة في مساحة التضمين الأصلية. مقارنة بالطرق المنافسة ، فإن طريقتنا أسرع وخالية من المعلمات وحتمية.', 'es': 'La incrustación de palabras se ha convertido en una herramienta principal en el procesamiento estadístico del lenguaje natural. Los profesionales a menudo utilizan vectores de palabras previamente entrenados, que se capacitaron en grandes cuerpos de texto genéricos y que están fácilmente disponibles en la web. Sin embargo, los vectores de palabras previamente entrenados a menudo carecen de palabras importantes de dominios específicos. Por lo tanto, a menudo es deseable ampliar el vocabulario e incorporar nuevas palabras en un conjunto de vectores de palabras previamente entrenados. En este artículo, presentamos un método eficiente para incluir palabras nuevas de un corpus especializado, que contiene palabras nuevas, en incrustaciones de palabras genéricas previamente entrenadas. Nos basamos en la visión establecida de incrustaciones de palabras como factorizaciones de matrices para presentar un algoritmo espectral para esta tarea. Los experimentos en varios corpus de dominio específico con vocabularios especializados demuestran que nuestro método es capaz de integrar las nuevas palabras de manera eficiente en el espacio de inserción original. En comparación con los métodos de la competencia, nuestro método es más rápido, sin parámetros y determinista.', 'fr': "L'intégration de mots est devenue un outil courant dans le traitement statistique du langage naturel. Les praticiens utilisent souvent des vecteurs de mots pré-entraînés, qui ont été formés sur de grands corpus de texte génériques et qui sont facilement disponibles sur le Web. Cependant, les vecteurs de mots pré-entraînés manquent souvent de mots importants provenant de domaines spécifiques. Il est donc souvent souhaitable d'étendre le vocabulaire et d'intégrer de nouveaux mots dans un ensemble de vecteurs de mots pré-entraînés. Dans cet article, nous présentons une méthode efficace pour inclure de nouveaux mots issus d'un corpus spécialisé, contenant de nouveaux mots, dans des intégrations de mots génériques pré-entraînées. Nous nous appuyons sur la vision établie des intégrations de mots en tant que factorisations matricielles pour présenter un algorithme spectral pour cette tâche. Des expériences sur plusieurs corpus spécifiques à un domaine avec des vocabulaires spécialisés démontrent que notre méthode est capable d'intégrer efficacement les nouveaux mots dans l'espace d'intégration d'origine. Comparée aux méthodes concurrentes, notre méthode est plus rapide, sans paramètre et déterministe.", 'pt': 'Embeddings de palavras tornaram-se uma ferramenta dominante no processamento estatístico de linguagem natural. Os praticantes costumam usar vetores de palavras pré-treinados, que foram treinados em grandes corpora de texto genérico e que estão prontamente disponíveis na web. No entanto, vetores de palavras pré-treinados muitas vezes não possuem palavras importantes de domínios específicos. Portanto, muitas vezes é desejável estender o vocabulário e incorporar novas palavras em um conjunto de vetores de palavras pré-treinados. Neste artigo, apresentamos um método eficiente para incluir novas palavras de um corpus especializado, contendo novas palavras, em embeddings de palavras genéricas pré-treinadas. Construímos a visão estabelecida de incorporação de palavras como fatoração de matrizes para apresentar um algoritmo espectral para esta tarefa. Experimentos em vários corpora específicos de domínio com vocabulários especializados demonstram que nosso método é capaz de incorporar as novas palavras de forma eficiente no espaço de incorporação original. Comparado aos métodos concorrentes, nosso método é mais rápido, sem parâmetros e determinístico.', 'ja': 'ワード埋め込みは、統計的自然言語処理における主流のツールとなっている。実践者は、事前に訓練された単語ベクトルを使用することが多く、これらは大規模な汎用テキストコーラで訓練され、ウェブ上で容易に利用可能である。しかしながら、事前に訓練された単語ベクトルは、しばしば特定のドメインからの重要な単語を欠く。したがって、語彙を拡張し、事前に訓練された単語ベクトルのセットに新しい単語を埋め込むことがしばしば望ましい。本稿では、事前に訓練された一般的な単語の埋め込みに、新しい単語を含む専門的なコーパスから新しい単語を含めるための効率的な方法を提示する。私たちは、このタスクのスペクトルアルゴリズムを提示するために、行列の因数分解としての単語埋め込みの確立されたビューに基づいて構築します。専門的な語彙を持ついくつかのドメイン固有のコーパスでの実験は、当社の方法が新しい単語を元の埋め込み空間に効率的に埋め込むことができることを示しています。競合するメソッドと比較して、私たちのメソッドはより速く、パラメータフリーで、決定論的です。', 'zh': '词嵌已为计自然语言主流之具。 从业者常用豫练之词向量,此词向量大通文本语料库上所习,而轻于网络也。 然预训者词向量常乏特定域要词。 故常须广词汇量销新单词于预练之词向量。 于本文中,立一效,以包新单词专用语料库新单词包预练通用单词嵌之。 以已立之词嵌视图为基,为矩阵分解,供一光谱算法。 特定词汇表数域特定语料库实验,新单词嵌空。 比之竞法,吾道愈速,无参数而有确定性。', 'hi': 'शब्द एम्बेडिंग सांख्यिकीय प्राकृतिक भाषा प्रसंस्करण में एक मुख्यधारा का उपकरण बन गया है। चिकित्सक अक्सर पूर्व-प्रशिक्षित शब्द वैक्टर का उपयोग करते हैं, जिन्हें बड़े जेनेरिक टेक्स्ट कार्पोरा पर प्रशिक्षित किया गया था, और जो वेब पर आसानी से उपलब्ध हैं। हालांकि, पूर्व-प्रशिक्षित शब्द वैक्टर अक्सर विशिष्ट डोमेन से महत्वपूर्ण शब्दों की कमी होती है। इसलिए शब्दावली का विस्तार करना और नए शब्दों को पूर्व-प्रशिक्षित शब्द वैक्टर के एक सेट में एम्बेड करना अक्सर वांछनीय होता है। इस पेपर में, हम एक विशेष कॉर्पस से नए शब्दों को शामिल करने के लिए एक कुशल विधि प्रस्तुत करते हैं, जिसमें नए शब्द होते हैं, पूर्व-प्रशिक्षित जेनेरिक शब्द एम्बेडिंग में। हम इस कार्य के लिए एक वर्णक्रमीय एल्गोरिथ्म प्रस्तुत करने के लिए मैट्रिक्स फ़ैक्टराइजेशन के रूप में शब्द एम्बेडिंग के स्थापित दृश्य पर निर्माण करते हैं। विशेष शब्दावली के साथ कई डोमेन-विशिष्ट कॉर्पोरेट पर प्रयोगों से पता चलता है कि हमारी विधि नए शब्दों को मूल एम्बेडिंग स्पेस में कुशलतापूर्वक एम्बेड करने में सक्षम है। प्रतिस्पर्धी तरीकों की तुलना में, हमारी विधि तेज, पैरामीटर-मुक्त और नियतात्मक है।', 'ru': 'Встраивание слов стало одним из основных инструментов статистической обработки естественного языка. Практикующие специалисты часто используют предварительно обученные векторы слов, которые были обучены на больших общих текстовых корпусах и которые легко доступны в Интернете. Тем не менее, предварительно обученные векторы слов часто не хватает важных слов из определенных областей. Поэтому часто желательно расширить словарный запас и вставить новые слова в набор предварительно обученных векторов слов. В данной работе мы представляем эффективный метод включения новых слов из специализированного корпуса, содержащего новые слова, в предварительно обученные обобщенные вложения слов. Мы основываемся на установившемся представлении о вложениях слов как матричных факторизациях, чтобы представить спектральный алгоритм для этой задачи. Эксперименты на нескольких доменных корпусах со специализированными словарями показывают, что наш метод способен эффективно встраивать новые слова в исходное пространство вложений. По сравнению с конкурирующими методами, наш метод быстрее, без параметров и детерминирован.', 'ga': 'Is uirlis phríomhshrutha anois iad neadú focal i bpróiseáil staidrimh nádúrtha teanga. Is minic a úsáideann cleachtóirí veicteoirí focal réamhoilte, a cuireadh oiliúint orthu ar chorpas mór téacs cineálach, agus atá ar fáil go héasca ar an ngréasán. Mar sin féin, is minic go mbíonn focail thábhachtacha ó réimsí ar leith in easnamh ar veicteoirí focal réamhoilte. Is minic mar sin go bhfuil sé inmhianaithe an stór focal a leathnú agus focail nua a leabú i sraith veicteoirí focal réamhoilte. Sa pháipéar seo, cuirimid i láthair modh éifeachtach chun focail nua ó chorpas speisialaithe, ina bhfuil focail nua, a chur san áireamh i leabú focal cineálach réamh-oilte. Tógaimid ar an dearcadh seanbhunaithe ar leabú focal mar fhachtóirí maitrís chun algartam speictreach a chur i láthair don tasc seo. Léiríonn turgnaimh ar roinnt corpora a bhaineann go sonrach leis an bhfearann le stór focal speisialaithe go bhfuil ár modh in ann na focail nua a leabú go héifeachtach sa bhunspás leabaithe. I gcomparáid le modhanna iomaíochta, tá ár modh níos tapúla, saor ó pharaiméadar, agus cinntitheach.', 'ka': 'სიტყვების შებრუნება სტატისტიკური ენის პროცესისში გახდება. პრექტიციონტები ძალიან გამოყენებენ წინასწარმოქმებული სიტყვების გვექტორები, რომელიც დიდი გენერიკური ტექსტის კოპორაზე განსწავლებულია, და რომელიც სახით მაგრამ, საკუთარი საკუთარი დომენეებიდან მნიშვნელოვანი სიტყვები უნდა არსებობს. ამიტომ ძალიან უნდა გავაკეთოთ სიტყვებულის და ახალი სიტყვებულების შესაბამისად წინ გავაკეთებული სიტყვებულების ვექტორებში. ამ წიგნიში ჩვენ გამოყენებთ ახალი სიტყვები სპეციალური კორპუსის განმავლობაში, რომელსაც ახალი სიტყვები, წინ განმავლებული საერთო სიტყვებში. ჩვენ შევქმნით სიტყვების შესახებ, როგორც მარტიკის ფაქტორიზაციები, რომ ამ დავალებისთვის სპექტრალური ალგორიტიმს გაჩვენოთ. ექსპერიმენტის განსაზღვრებული კოპორაზე სპეციალური სიტყვებულებით გამოცდილება, რომ ჩვენი მეთოდი შეუძლია ახალი სიტყვებს ეფექტიურად დავყენოთ ორიგინალური და ჩვენი მეთოდი უფრო ბრძელია, პარამეტრებით უფრო ბრძელია და განსაზღვრული.', 'el': 'Η ενσωμάτωση λέξεων έχει γίνει ένα βασικό εργαλείο στη στατιστική επεξεργασία φυσικής γλώσσας. Οι επαγγελματίες χρησιμοποιούν συχνά προ-εκπαιδευμένα διανύσματα λέξεων, τα οποία εκπαιδεύτηκαν σε μεγάλα γενικά σώματα κειμένου, και τα οποία είναι άμεσα διαθέσιμα στο διαδίκτυο. Ωστόσο, τα προ-εκπαιδευμένα διανύσματα λέξεων συχνά στερούνται σημαντικές λέξεις από συγκεκριμένους τομείς. Ως εκ τούτου, είναι συχνά επιθυμητό να επεκτείνετε το λεξιλόγιο και να ενσωματώσετε νέες λέξεις σε ένα σύνολο προ-εκπαιδευμένων διανυσμάτων λέξεων. Στην παρούσα εργασία, παρουσιάζουμε μια αποτελεσματική μέθοδο για τη συμπερίληψη νέων λέξεων από ένα εξειδικευμένο σώμα, που περιέχουν νέες λέξεις, σε προ-εκπαιδευμένες γενικές ενσωματώσεις λέξεων. Βασιζόμαστε στην καθιερωμένη άποψη των ενσωμάτωσης λέξεων ως παράγωγων μήτρας για να παρουσιάσουμε έναν φασματικό αλγόριθμο για αυτό το έργο. Πειράματα σε διάφορα σώματα ειδικού τομέα με εξειδικευμένα λεξικά δείχνουν ότι η μέθοδος μας είναι σε θέση να ενσωματώσει αποτελεσματικά τις νέες λέξεις στον αρχικό χώρο ενσωμάτωσης. Σε σύγκριση με τις ανταγωνιστικές μεθόδους, η μέθοδος μας είναι ταχύτερη, χωρίς παραμέτρους και ντετερμινιστική.', 'hu': 'A szóbeágyazások a statisztikai természetes nyelvfeldolgozás általános eszközévé váltak. A gyakorlók gyakran előre képzett szóvektorokat használnak, amelyeket nagy generikus szövegcorporákra képzettek, és amelyek könnyen elérhetőek az interneten. Azonban az előre képzett szóvektorok gyakran hiányoznak fontos szavak bizonyos tartományokból. Ezért gyakran kívánatos a szókincs kiterjesztése és új szavak beágyazása előre képzett szóvektorokba. Ebben a tanulmányban hatékony módszert mutatunk be egy speciális korpuszból származó új szavak beépítésére, amelyek új szavakat tartalmaznak, előre képzett általános szóbeágyazásokba. A szóbeágyazások megalapozott nézetére építünk, mint mátrix faktorizációkra, hogy bemutassuk a feladathoz egy spektrális algoritmust. Számos domain-specifikus korpuszon végzett kísérletek speciális szókincsekkel bizonyítják, hogy módszerünk képes hatékonyan beágyazni az új szavakat az eredeti beágyazási térbe. A versengő módszerekkel összehasonlítva a módszerünk gyorsabb, paramétermentes és determinisztikus.', 'it': "Le incorporazioni di parole sono diventate uno strumento principale nell'elaborazione statistica del linguaggio naturale. I praticanti spesso usano vettori di parole pre-addestrati, che sono stati addestrati su grandi corpora di testo generico, e che sono facilmente disponibili sul web. Tuttavia, i vettori di parole pre-addestrati spesso mancano di parole importanti da domini specifici. È quindi spesso auspicabile estendere il vocabolario e incorporare nuove parole in un insieme di vettori di parole pre-addestrati. In questo articolo, presentiamo un metodo efficiente per includere nuove parole da un corpus specializzato, contenenti nuove parole, in incorporazioni generiche pre-addestrate di parole. Costruiamo sulla vista stabilita delle incorporazioni di parole come fattorizzazioni di matrice per presentare un algoritmo spettrale per questo compito. Esperimenti su diversi corpora specifici del dominio con vocabolari specializzati dimostrano che il nostro metodo è in grado di incorporare le nuove parole in modo efficiente nello spazio di incorporazione originale. Rispetto ai metodi concorrenti, il nostro metodo è più veloce, privo di parametri e deterministico.", 'lt': 'žodžių įtraukimas tapo pagrindine statistikos gamtos kalbų apdorojimo priemone. Praktikantys dažnai naudoja iš anksto apmokytus žodžių vektorius, kurie buvo apmokyti didelio generinio teksto korporais ir kurie yra lengvai prieinami internete. Tačiau iš anksto apmokytiems žodžių vektoriams dažnai trūksta svarbių konkrečių sričių žodžių. Todėl dažnai pageidautina išplėsti žodyną ir įtraukti naujus žodžius į iš anksto parengtus žodžių vektorius. Šiame dokumente pateikiame veiksmingą metodą, kaip į iš anksto parengtus bendruosius žodžius įtraukti naujus žodžius iš specializuoto korpuso, kuriuose yra naujų žodžių. Mes remiamės nusistovėjusiu žodžių įterpimo kaip matricos faktorizacijų požiūriu, kad pristatytume spektrinį algoritmą šiam uždaviniui. Eksperimentai su keliomis konkrečios srities korporais su specializuotais žodynais rodo, kad mūsų metodas gali veiksmingai įdėti naujus žodžius į pradinę įdėjimo erdvę. Palyginti su konkuruojančiais metodais, mūsų metodas yra greitesnis, be parametrų ir deterministinis.', 'kk': 'Сөздерді ендіру статистикалық табиғи тілдерді өңдеу үшін негізгі құралы болды. Орындаушылар көбінесе бұл үлкен жалпы мәтін корпорасында оқылған, веб- сайтында оқылған сөздер векторларын қолданады. Бірақ кейбірде алдындағы сөздердің векторлары керек домендерден маңызды сөздер жоқ. Сондықтан сөздерді көптеген және жаңа сөздерді алдын- ала оқылған сөздер векторына ендіру керек. Бұл қағазда біз өзгертілген корпустың жаңа сөздерін, жаңа сөздерді, алдын- ала оқылған жалпы сөздерді ендіру үшін әсер ететін әдісін таңдаймыз. Біз осы тапсырманың спектралық алгоритмін таңдау үшін матрицалық факторизациялары ретінде сөздерді ендіру көрінісін құрамыз. Бірнеше доменге арнаулы сөздердің корпорасының тәжірибесі, әдіміздің жаңа сөздерді бастапқы ендіру орынға әсер етеді дегенді көрсетеді. Сәйкес әдістерімізге салыстырып, әдіміздің әдіміміз жылдам, параметрлерден артық, дефицистикалық.', 'mk': 'Вклучувањето на зборови стана главна алатка во статистичкото обработување на природен јазик. Практичарите често користат предобучени вектори за зборови, кои беа обучени на големи генерални текстови корпора, и кои се лесно достапни на интернет. Сепак, предобучените вектори на зборови честопати немаат важни зборови од специфични домени. Затоа често е посакувано да се прошири речникот и да се вградат нови зборови во сет предобучени вектори на зборови. Во овој весник претставуваме ефикасен метод за вклучување на нови зборови од специјализиран корпус, кои содржат нови зборови, во предобучени генерални зборови вградени. Ние изградуваме на поставениот поглед на зборовите вградени како матрични факторизации за да претставиме спектрален алгоритм за оваа задача. Експериментите на неколку корпора специфични за домен со специјализирани речници покажуваат дека нашиот метод е способен да ги внесе новите зборови ефикасно во оригиналниот простор за внесување. Во споредба со конкурентните методи, нашиот метод е побрз, без параметри и децентристички.', 'ms': 'Word embeddings have become a mainstream tool in statistical natural language processing.  Pelatih sering menggunakan vektor perkataan terlatih-terlatih, yang dilatih pada korpra teks generik besar, dan yang mudah tersedia di web. Namun, vektor perkataan terlatih sebelum sering kekurangan perkataan penting dari domain tertentu. Oleh itu, ia sering diinginkan untuk memperluas kamus dan memasukkan perkataan baru ke dalam set vektor perkataan yang dilatih dahulu. Dalam kertas ini, kami memperkenalkan kaedah efisien untuk termasuk kata-kata baru dari korpus khusus, yang mengandungi kata-kata baru, ke dalam kandungan perkataan generik terlatih. Kami membangun pada pandangan yang ditetapkan untuk penyelesaian perkataan sebagai faktor matriks untuk memperkenalkan algoritma spektral untuk tugas ini. Eksperimen pada beberapa korpra domain-spesifik dengan vokbulari khusus menunjukkan bahawa kaedah kita mampu memasukkan kata-kata baru secara efisien ke ruang penerbangan asal. Berbanding dengan kaedah yang bersaing, kaedah kita lebih cepat, tanpa parameter, dan menentukan.', 'mt': 'L-inkorporazzjoni tal-kliem saret għodda ewlenija fl-ipproċessar statistiku tal-lingwi naturali. Il-prattikanti ta’ spiss jużaw vetturi bil-kliem imħarrġa minn qabel, li ġew imħarrġa fuq korpra tat-test ġeneriku kbir, u li huma faċilment disponibbli fuq l-internet. Madankollu, vectors tal-kliem imħarrġa minn qabel spiss ma jkollhomx kliem importanti minn oqsma speċifiċi. Għalhekk ta’ spiss huwa mixtieq li jiġi estiż il-vokabulari u jiġu inkorporati kliem ġdid f’sett ta’ vetturi tal-kliem imħarrġa minn qabel. F’dan id-dokument, qed nippreżentaw metodu effiċjenti għall-inklużjoni ta’ kliem ġdid minn korpus speċjalizzat, li fih kliem ġdid, f’inkorporazzjonijiet ta’ kliem ġeneriku mħarrġa minn qabel. We build on the established view of word embeddings as matrix factorizations to present a spectral algorithm for this task.  Experiments on several domain-specific corpora with specialized vocabularies demonstrate that our method is able to embed the new words efficiently into the original embedding space.  Meta mqabbel mal-metodi kompetittivi, il-metodu tagħna huwa aktar mgħaġġel, mingħajr parametri, u determinanti.', 'mn': 'Статистикийн байгалийн хэл үйлдвэрлэлд үг нэвтрүүлэх нь үндсэн хэрэгсэл болсон. Сургуульчид ихэвчлэн сургалтын өмнө сургалтын үгний векторуудыг ашигладаг. Тэдгээр нь том ерөнхий текст корпора дээр сургалтын ажиллагаатай, вэб дээр амархан байдаг. Гэхдээ урьд сургалтын үг векторууд заримдаа тодорхой хэсэгт чухал үг байхгүй. Тиймээс илүү ихэвчлэн үгийг нэмэгдүүлж, шинэ үгийг сургалтын өмнө сургалтын үгийг вектор болгох нь хүсэлтэй. Энэ цаасан дээр бид мэргэжлийн корпусын шинэ үгүүдийг нэмэгдүүлэх, шинэ үгүүдийг дамжуулан сургалтын аль хэдийн үгүүдийг нэмэгдүүлэх бүтээмжтэй аргыг тайлбарлаж байна. Бид энэ ажил дээр спектрал алгоритмыг тайлбарлахын тулд матриц үржвэрлэлүүд гэж нэрлэж өгсөн үгийг бий болгосон. Хэдэн хэдэн тодорхой корпора дахь туршилтууд нь мэргэжлийн үг хэлэлцдэг нь бидний арга нь шинэ үгсийг үндсэн орон зайд эффективно оруулж чадна гэдгийг харуулдаг. Дөрсөлдөг аргын харьцуулахад бидний арга нь илүү хурдан, параметрлүй, deterministic.', 'no': 'Tekstinnbygging er blitt ein hovudverktøy i statistisk naturspråkshandtering. Praktiseringar brukar ofte før- trengte ord- vektorar, som er trengte på stor generiske tekstkorpora, og som er lett tilgjengeleg på nettet. Vektorar med først treng ordet manglar ofte viktige ord frå spesifikke domene. Det er derfor ofte ønskjer å utvida ordboka og innebygge nye ord i eit sett av føretrainerte ordvektorar. I denne papiret presenterer vi ein effektiv metode for å inkludere nye ord frå ei spesialisert korpus, som inneheld nye ord, i føretrainerte generiske ordinnbygging. Vi bygger på den oppretta visinga av ordinnbygginga som matrisefaktoriseringar for å oppgje ein spektralalgoritme for denne oppgåva. Eksperimentar på fleire domenespesifikke korpora med spesialiserte ordsamlingar viser at metoden vårt kan innebygge dei nye ord effektivt i den opprinnelige innbyggingsrommet. Sammenlignet med konkurransmetoder er metoden vårt raskare, parametrafri og deterministisk.', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയഭാഷയുടെ പ്രക്രിയശ്ചിത്രത്തില്\u200d വാക്കുകള്\u200d പ്രധാനപ്പെട്ട ഉപകരണങ്ങളാ പരിശീലിക്കുന്നവര്\u200d പലപ്പോഴും പഠിപ്പിക്കപ്പെട്ട വാക്ക് വെക്റ്റര്\u200d ഉപയോഗിക്കുന്നു. അത് വലിയ സാധാരണ വാക്ക് കോര്\u200dപ്പോരിയില എന്നാലും പ്രധാനപ്പെട്ട വാക്ക് വെക്റ്റര്\u200d എപ്പോഴും പ്രത്യേകിച്ചുള്ള ഡോമെന്\u200dസില്\u200d നിന്നും പ്രധാ അതുകൊണ്ട് പലപ്പോഴും പദാവലിയെ വികസിപ്പിക്കുകയും പുതിയ വാക്കുകള്\u200d ഒരു കൂട്ടം പഠിപ്പിക്കപ്പെട്ട വാക്ക് വെക്റ് ഈ പത്രത്തില്\u200d, പുതിയ വാക്കുകള്\u200d കൊര്\u200dപ്പാസില്\u200d നിന്നും പുതിയ വാക്കുകള്\u200d ഉള്\u200dപ്പെടുത്തുന്നതിനുള്ള ഒരു സാധാരണ രീതി ഈ പ്രവര്\u200dത്തിക്കുവേണ്ടി ഒരു സ്പെക്ട്രല്\u200d ആല്\u200dഗോരിത്മം കൊടുക്കുവാന്\u200d വാക്കുകളുടെ സ്ഥിരപ്പെട്ട കാഴ്ചകളില്\u200d ന പ്രത്യേക വാക്കുകളുള്ള പല ഡൊമെയിന്\u200d പ്രത്യേകിച്ച് കോര്\u200dപ്പോരയിലുള്ള പരീക്ഷണങ്ങള്\u200d നമ്മുടെ രീതിയില്\u200d പുതിയ വാക്കുകള്\u200d പ്രധാനപ്പെ മത്സരിക്കുന്ന രീതികളെക്കുറിച്ച് എതിര്\u200dപ്പിടിച്ച്, നമ്മുടെ രീതിയില്\u200d വേഗത്തില്\u200d, പരാമീറ്റര്\u200d സ്വതന്ത്ര', 'pl': 'osadzenia tekstów stały się głównym narzędziem w statystycznym przetwarzaniu języka naturalnego. Praktykujący często używają wstępnie przeszkolonych wektorów słów, które zostały przeszkolone na dużych ogólnych korpusach tekstowych i które są łatwo dostępne w sieci. Jednak wstępnie przeszkolone wektory słów często brakuje ważnych słów z określonych domen. Dlatego często pożądane jest rozszerzenie słownictwa i osadzenie nowych słów w zestawie wstępnie przeszkolonych wektorów słowa. W artykule przedstawiamy skuteczną metodę włączania nowych słów ze specjalistycznego korpusu, zawierającego nowe słowa, do wstępnie przeszkolonych osadzeń słów generycznych. Opieramy się na ugruntowanym widoku osadzeń słów jako czynników macierzowych, aby przedstawić algorytm widmowy dla tego zadania. Eksperymenty na kilku korpusach specyficznych dla domeny ze specjalistycznymi słownikami pokazują, że nasza metoda jest w stanie skutecznie osadzić nowe słowa w oryginalnej przestrzeni osadzania. W porównaniu z konkurencyjnymi metodami nasza metoda jest szybsza, wolna od parametrów i deterministyczna.', 'ro': 'Încorporările de cuvinte au devenit un instrument principal în procesarea statistică a limbajului natural. Practicanții folosesc adesea vectori de cuvinte pre-instruiți, care au fost instruiți pe corpuri de text generice mari și care sunt ușor disponibile pe web. Cu toate acestea, vectorii de cuvinte pre-instruiți adesea lipsesc cuvinte importante din domenii specifice. Prin urmare, este adesea de dorit să extindeți vocabularul și să încorporați cuvinte noi într-un set de vectori de cuvinte pre-instruiți. În această lucrare, prezentăm o metodă eficientă pentru includerea de cuvinte noi dintr-un corpus specializat, conținând cuvinte noi, în încorporarea de cuvinte generice pre-instruite. Construim pe viziunea stabilită a încorporărilor de cuvinte ca factorizări matrice pentru a prezenta un algoritm spectral pentru această sarcină. Experimentele pe mai multe corpuri specifice domeniului cu vocabulare specializate demonstrează că metoda noastră este capabilă să încorporeze eficient noile cuvinte în spațiul original de încorporare. Comparativ cu metodele concurente, metoda noastră este mai rapidă, fără parametri și deterministă.', 'so': "Hadalka ku soo guurista waxay noqotay qalabka asalka ah oo ka baaraandegista luqada asalka ah. Waxbarashada waxaa inta badan isticmaala vector hadal horay loo tababaray, kuwaas oo lagu tababariyey shirkad qoraal ah oo badan, kuwaas oo si fudud looga helo bogga internetka. Si kastaba ha ahaatee wado hadal horay loo tababaray inta badan waa u baahan yihiin erayo muhiim ah oo laga helaa meelaha gaar ah. Sidaa darteed waxaa habboon in mar badan la sii fidiyo hadalka cusub oo loo soo bandhigaa qaabilaad hadal horay loo baray. Qoraalkan waxaynu ku qornaa qaab faa’iido ah oo ku saabsan erayo cusub oo ka soo baxa koroos gaar ah, kaasoo ku jira erayo cusub oo ku qoran hadalka hore ee wax lagu baray. Waxaynu dhisaynaa aragtida la dhisay hadalka oo la soo dirayo sida farshaxan oo kale, si aan u soo saarno algorithm kalgorithm ah ee shaqadan. Experiments on several domain-specific corpora with specialized vocabularies demonstrate that our method is able to embed the new words efficiently into the original embedding space.  Isbarbardhigta qaababka iskutallaabta ah, qaabkanagu waa dhaqso, parameter-aan-lacag la’aan iyo go'aan.", 'sv': 'Ordinbäddningar har blivit ett vanligt verktyg i statistisk bearbetning av naturligt språk. Utövare använder ofta förklädda ordvektorer, som tränats på stora generiska textkorpor, och som är lätt tillgängliga på webben. Förtränade ordvektorer saknar dock ofta viktiga ord från specifika domäner. Därför är det ofta önskvärt att utöka ordförrådet och bädda in nya ord i en uppsättning förkunskaperade ordvektorer. I denna uppsats presenterar vi en effektiv metod för att inkludera nya ord från en specialiserad korpus, innehållande nya ord, i pre-utbildade generiska ordinbäddningar. Vi bygger på den etablerade bilden av ordinbäddningar som matrisfaktoriseringar för att presentera en spektral algoritm för denna uppgift. Experiment på flera domänspecifika korpor med specialiserade vokabulär visar att vår metod kan bädda in de nya orden effektivt i det ursprungliga inbäddningsutrymmet. Jämfört med konkurrerande metoder är vår metod snabbare, parameterfri och deterministisk.', 'sr': 'Uključenje reči postalo je glavni alat u procesu statističkog prirodnog jezika. Praktičnici često koriste predobučene rečne vektore, koje su obučene na velikoj generičnoj tekstskoj korpori, i koje su lako dostupne na internetu. Međutim, predobučeni vektori reči često nedostaju važne reči iz specifičnih domena. Stoga je često poželjno proširiti rečnik i uključiti nove reči u set predobučenih rečnih vektora. U ovom papiru predstavljamo efikasnu metodu uključujući nove reči iz specijalizovanog korpusa, sadržajući nove reči, u predobučene generične reči. Izgradili smo na ustanovljenom pogledu ugraðenja reèi kao faktorizacije matrice da predstavimo spektralni algoritam za ovaj zadatak. Eksperimenti na nekoliko domena specifičnih korporacija sa specijalizovanim rečnicima pokazuju da naš metod može učinkovito uključiti nove reči u originalni integracijski prostor. U usporedbi sa takmičenim metodama, naš metod je brži, bez parametara i determinističan.', 'ta': 'வார்த்தை உள்ளடக்கம் புள்ளிவிவரமான இயல்பான மொழி செயல்படுத்தலில் ஒரு முக்கிய கருவியாகி விட்டது. பயிற்சியாளர்கள் பெரிய பொதுவான உரை நிறுவனத்தில் பயிற்சி செய்யப்பட்ட முன் பயிற்சி வார்த்தை வெக்டர்களை பயன்படுத்துகின்றன,  ஆனால், முன் பயிற்சி செய்யப்பட்ட வார்த்தை நெறிமுறையாக குறிப்பிட்ட களங்களிலிருந்து முக்கியமான சொல்வளத்தை நீட்ட வேண்டும் மற்றும் புதிய வார்த்தைகளை முன் பயிற்சிக்கப்பட்ட வார்த்தை நெறிக்குள் சேர்க்க வ இந்த காகிதத்தில், நாம் ஒரு புதிய வார்த்தைகளை சேர்க்க ஒரு சிறப்பு கார்புஸிலிருந்து புதிய வார்த்தைகளை கொண்டு வருகிறோம், முன் இந்த செயலுக்கான ஒரு குறிப்பிட்ட ஆல்ஜிரியம் கொடுக்க வார்த்தை உள்ளடக்கும் பார்வையில் நாம் உருவாக்குகிறோம். குறிப்பிட்ட சொல்வளங்கள் கொண்ட பல களம் குறிப்பிட்ட நிறுவனத்தில் சோதனைகள் காண்பிக்கிறது நம் முறைமை பங்கீட்டு முறைகளை ஒப்பிட்டு, எங்கள் முறைமை விரைவாக, அளபுரு இல்லாத, மற்றும் தீர்மானிக்கும்.', 'si': 'වචන සම්බන්ධ විදිහට ප්\u200dරධාන උපකරණයක් වෙලා තියෙන්නේ ස්ථානික භාෂාව ප්\u200dරක්\u200dරියාස කර ප්\u200dරේක්ටමන් කරුණාකරුවන් වෙක්ටර් වලින් ප්\u200dරේක්ටන් කරුණාකරලා ප්\u200dරයෝජනය කරනවා, ඒ වගේම ලොකු සාමාන්\u200dය පාළ නමුත්, ප්\u200dරධානය කරපු වචන වෙක්ටර්ස් වලට ප්\u200dරශ්ණ වචන අවශ්\u200dයයි. ඉතින් ඒක සාමාන්\u200dයයෙන් අවශ්\u200dය වචනය විස්තර කරන්න සහ අළුත් වචනයක් ප්\u200dරීක්ෂිත වචනය වෙක්ටර්ස් වලට ඇතුළත මේ පත්තරයේ අපි විශේෂ කර්පස් වලින් අලුත් වචන් සම්බන්ධ කරන්න ප්\u200dරයෝජනයක් තියෙනවා, අලුත් වචන් සම්බන්ධ කරනවා, ප අපි මේ වැඩේ ස්පෙක්ටරල් ඇල්ගෝරිතම් එකක් පෙන්වන්න පුළුවන් වචන ස්ථාපනය කරලා වචන ස්ථාපනය කරනවා. විශේෂ ශබ්ද භාෂාවක් තියෙන විශේෂ විශේෂ සඳහා විශේෂ විශේෂ ක්\u200dරියාකාරයෙන් පරීක්ෂණය පෙන්වන්නේ අපේ ව අපේ විධානය වේගයෙන් සම්බන්ධ විදියට, අපේ විධානය වේගයෙන්, පැරැමිටර් නිදහස් සහ නිර්දේශික', 'ur': 'ورڈ امبرڈینگ ایستٹیسٹی طبیعی زبان پرسس میں ایک اصلی تولیل ہو گئی ہے۔ آزمائش کرنے والوں نے کثرت سے پہلے تدریس کی لکھی ویکتروں کو استعمال کرتے ہیں، جو بڑے جسمانی لکھی کورپور پر تعلیم کی گئی تھی، اور جو ویب میں آسانی طرح موجود ہیں۔ However, pre-trained word vectors often lack important words from specific domains. لہٰذا اکثر کلمات کو پھیلانا اور نئی کلمات کو پہلے تعلیم کی کلمات ویکتروں میں داخل کرنا چاہتا ہے. اس کاغذ میں، ہم نے ایک مخصوص کرپوس سے نوی کلمات شامل کرنے کے لئے ایک مفید طریقہ پیش آموزش کی جسمانی کلمات میں پیش آموزش کی۔ ہم اس کام کے لئے ایک اسپٹرال الگوریتم کو پیش کرنے کے لئے ایک ماٹریکس فاکتوریزٹ کے طور پر استعمال کیا گیا ہے. مخصوص صحبت کے ساتھ بہت سی ڈومین کے مخصوص کورپورا کے تجربے دکھاتے ہیں کہ ہماری طریقہ نئی کلمات کو اصلی انڈینگ جگہ میں اضافہ کرسکتی ہے۔ مقابلہ طریقوں کے مقابلہ میں، ہمارا طریقہ بہت تیز ہے، پارامیٹ بے نیاز ہے، اور فیصلہ کرنے والی ہے.', 'uz': "Word embeddings have become a mainstream tool in statistical natural language processing.  Name Lekin, oldin o'rganilgan so'zlar vektorlari ko'pincha foydalanuvchilardan muhim so'zlar mavjud emas. Шундай қилиб, oddiy soʻzni ajratish va yangi so'zlarni bir marta o'rganilgan so'zlar vektoriga qo'yish kerak. Bu qogʻozda, biz tashkilotlar bilan yangi so'zlarni qo'shish uchun foydalanuvchi usulni hozir qilamiz, yangi so'zlarni oldin o'rgangan genetikal so'zlar ichida o'zgartirish mumkin. Biz bu vazifa uchun spektral algoritni koʻrsatish uchun matrix fabrikalari sifatida qo'llanmiz. Bir nechta domen-specific kompaniyadagi imtiyozlar bilan foydalanish imtiyozlarini koʻrsatish mumkin, bizning usulida yangi so'zlarni asl bo'lgan joyga qo'yish mumkin. Ko'rib chiqarish usullarini kamaytirish mumkin, bizning usuli tez, parametr boʻsh va tayyorlik.", 'vi': 'Sự gắn kết từ đã trở thành công cụ chính thống trong việc xử lý ngôn ngữ tự nhiên thống kê. Các chuyên gia thường sử dụng các cỗ máy có từ được huấn luyện trước, được đào tạo trên cơ thể chữ chung lớn, và sẵn sàng có trên mạng. Tuy nhiên, vốn từ ngữ được huấn luyện thường thiếu những từ quan trọng từ lĩnh vực cụ thể. Do đó, tốt nhất là nên mở rộng ngôn ngữ và thêm từ mới vào một tập hợp các véc- tơ từ được huấn luyện trước. Trong tờ giấy này, chúng tôi có một phương pháp hiệu quả để thêm vào những từ mới của một tập đoàn chuyên nghiệp, chứa những từ mới, vào những từ ngữ được huấn luyện. Chúng tôi xây dựng dựa trên quan điểm xác định của sự nhúng vào từ như dữ liệu ma trận để đưa ra thuật to án quang phổ cho nhiệm vụ này. Các thí nghiệm trên nhiều tập đoàn đặc trưng với các ca sĩ chuyên môn cho thấy phương pháp của chúng ta có thể nhúng những từ mới một cách hiệu quả vào không gian ghép nguyên bản. So với các phương pháp cạnh tranh, phương pháp của chúng ta nhanh hơn, tham số tự do và quyết định.', 'bg': 'Вградените думи се превърнаха в основен инструмент в статистическата обработка на естествени езици. Практикуващите често използват предварително обучени текстови вектори, които са обучени върху големи генерични текстови корпуси и които са лесно достъпни в интернет. Въпреки това, предварително обучените вектори на думи често липсват важни думи от конкретни области. Поради това често е желателно да се разшири речника и да се включат нови думи в набор от предварително обучени вектори на думи. В настоящата статия е представен ефективен метод за включване на нови думи от специализиран корпус, съдържащ нови думи, в предварително обучени генерични вграждания на думи. Ние изграждаме върху установения изглед на вграждането на думи като матрични факторизации, за да представим спектрален алгоритъм за тази задача. Експерименти върху няколко специфични за домейн корпора със специализирани речници показват, че нашият метод е в състояние ефективно да вгради новите думи в оригиналното вградено пространство. В сравнение с конкурентните методи, нашият метод е по-бърз, без параметри и детерминистичен.', 'nl': "Word embeddings zijn uitgegroeid tot een mainstream tool in statistische natuurlijke taalverwerking. Practitioners gebruiken vaak vooraf getrainde woordvectoren, die zijn getraind op grote generieke tekstcorpora's, en die gemakkelijk beschikbaar zijn op het web. Vooropgeleide woordvectoren missen echter vaak belangrijke woorden uit specifieke domeinen. Het is daarom vaak wenselijk om de woordenschat uit te breiden en nieuwe woorden in te sluiten in een set voorgetrainde woordvectoren. In dit artikel presenteren we een efficiënte methode voor het opnemen van nieuwe woorden uit een gespecialiseerd corpus, die nieuwe woorden bevatten, in voorgetrainde generieke woordembeddingen. We bouwen voort op de gevestigde weergave van woord embeddings als matrix factorizaties om een spectraal algoritme voor deze taak te presenteren. Experimenten op verschillende domeinspecifieke corpora's met gespecialiseerde woordenschaten tonen aan dat onze methode in staat is om de nieuwe woorden efficiënt in de oorspronkelijke inbeddingsruimte te integreren. Vergeleken met concurrerende methoden is onze methode sneller, parametervrij en deterministisch.", 'da': 'Ordindlejringer er blevet et mainstream værktøj i statistisk naturlig sprogbehandling. Praktiserende bruger ofte forududdannede ordvektorer, som blev trænet på store generiske tekstkorpora, og som er let tilgængelige på nettet. Men forududdannede ordvektorer mangler ofte vigtige ord fra bestemte domæner. Det er derfor ofte ønskeligt at udvide ordforrådet og integrere nye ord i et sæt forududdannede ordvektorer. I denne artikel præsenterer vi en effektiv metode til at inkludere nye ord fra et specialiseret korpus, der indeholder nye ord, i prætrænede generiske ordindlejringer. Vi bygger på det etablerede syn på ordindlejringer som matrix factorizations for at præsentere en spektral algoritme til denne opgave. Eksperimenter på flere domænespecifikke korpora med specialiserede ordforråd viser, at vores metode er i stand til at integrere de nye ord effektivt i det oprindelige indlejringsrum. Sammenlignet med konkurrerende metoder er vores metode hurtigere, parameterfri og deterministisk.', 'hr': 'Uključenje riječi postalo je glavni alat u procesu statističkog prirodnog jezika. Praktičnici često koriste predobučeni vektori riječi, koji su obučeni na velikom generičkom tekstu tijelu i koji su lako dostupni na internetu. Međutim, predobučeni vektori riječi često nedostaju važne riječi iz specifičnih domena. Stoga je često poželjno proširiti riječ i uključiti nove riječi u set predobučenih vektora riječi. U ovom papiru predstavljamo efikasnu metodu uključujući nove riječi iz specijalizovanog korpusa, sadržavajući nove riječi, u predobučene generične riječi. Na uspostavljenom pogledu ugrađenih riječi kao faktorizacija matrice kako bi predstavili spektralni algoritam za ovaj zadatak. Eksperimenti na nekoliko domena specifičnih korporacija s specijaliziranim riječnicima pokazuju da naš metod može učinkovito uključiti nove riječi u originalni integracijski prostor. U usporedbi s takmičenim metodama, naš metod je brži, bez parametara i determinističan.', 'de': 'Worteinbettungen sind zu einem Mainstream-Tool in der statistischen Verarbeitung natürlicher Sprache geworden. Praktiker verwenden oft vorgetrainierte Wortvektoren, die auf großen generischen Textkorpora trainiert wurden und die im Web leicht verfügbar sind. Allerdings fehlen vortrainierten Wortvektoren oft wichtige Wörter aus bestimmten Bereichen. Daher ist es oft wünschenswert, den Wortschatz zu erweitern und neue Wörter in eine Reihe von vorgetrainierten Wortvektoren einzubetten. In diesem Beitrag stellen wir eine effiziente Methode vor, um neue Wörter aus einem spezialisierten Korpus, die neue Wörter enthalten, in vortrainierte generische Worteinbettungen einzubinden. Wir bauen auf der etablierten Sichtweise von Worteinbettungen als Matrixfaktorisierungen auf, um einen spektralen Algorithmus für diese Aufgabe zu präsentieren. Experimente an mehreren domänenspezifischen Korpora mit spezialisierten Vokabeln zeigen, dass unsere Methode in der Lage ist, die neuen Wörter effizient in den ursprünglichen Einbettungsraum einzubetten. Im Vergleich zu konkurrierenden Methoden ist unsere Methode schneller, parameterfrei und deterministisch.', 'id': 'Penampilan kata telah menjadi alat utama dalam proses statistik bahasa alami. Para praktek sering menggunakan vektor kata yang dilatih-dilatih, yang dilatih pada korpora teks generik besar, dan yang mudah tersedia di web. Namun, vektor kata terlatih sering kekurangan kata penting dari domain spesifik. Oleh karena itu sering diinginkan untuk memperluas vocabulari dan memasukkan kata-kata baru ke dalam set vektor kata yang terlatih-terlatih. Dalam kertas ini, kami mempersembahkan metode efisien untuk termasuk kata-kata baru dari korpus khusus, yang mengandung kata-kata baru, ke dalam kata generik yang terlatih sebelumnya. Kami membangun pada pandangan yang ditetapkan dari penyembedding kata sebagai faktorisasi matriks untuk memperlihatkan algoritma spektral untuk tugas ini. Eksperimen pada beberapa korpora domain-spesifik dengan vokbulari khusus menunjukkan bahwa metode kita mampu memasukkan kata-kata baru secara efisien ke ruang penerbangan asli. Compared to competing methods, our method is faster, parameter-free, and deterministic.', 'ko': '단어 삽입은 이미 통계 자연 언어 처리의 주류 도구가 되었다.종사자들은 사전에 훈련된 어향량을 자주 사용하는데 이런 어향량은 대형 통용 텍스트 자료 라이브러리에서 훈련된 것이며 인터넷에서 수시로 얻을 수 있다.그러나 사전에 훈련된 어향량은 특정 분야의 중요한 단어가 부족한 경우가 많다.따라서 어휘표를 확장하고 미리 훈련된 단어의 양에 새 단어를 삽입해야 한다.본고에서 우리는 새로운 단어를 포함하는 전문 어료 라이브러리에 있는 새로운 단어를 미리 훈련된 통용어에 삽입하는 효과적인 방법을 제시했다.우리는 단어 삽입을 매트릭스 분해로 하는 이미 정해진 관점을 토대로 이 임무에 사용되는 스펙트럼 알고리즘을 제시했다.여러 개의 전문 어휘를 가진 분야의 특정 어료 라이브러리에서의 실험에 의하면 우리의 방법은 신조어를 원시 삽입 공간에 효과적으로 삽입할 수 있다.다른 방법에 비해 우리의 방법은 속도가 더 빠르고 파라미터가 없으며 확실성을 가지고 있다.', 'fa': 'جمع کردن کلمات یک ابزار اصلی در پرداخت زبان طبیعی آمار شده است. تمرین\u200cکنندگان اغلب از ویکتورهای کلمه پیش آموزش استفاده می\u200cکنند، که در شرکت متن ژنرالی بزرگ آموزش داده می\u200cشوند و در وب آسان موجود می\u200cشوند. ولی ویکتورهای کلمه پیش آموزش داده شده اغلب کلمات مهم از دامنهای خاص کمک می کنند. بنابراین اغلب می\u200cخواهد کلمه\u200cها را گسترش دهد و کلمه\u200cهای جدید را در مجموعه ویکتورهای کلمه پیش آموزش دهد. در این کاغذ، ما یک روش موثرتی برای شامل کلمات جدید از یک کورپوس متخصص، که شامل کلمات جدید است، به عنوان ابتدایی کلمات متخصص پیش آموزش داده می\u200cشویم. ما بر روی دید ساخته شده\u200cای از جمع کردن کلمات به عنوان فاکتوریزم ماتریکس ساختیم تا یک الگوریتم مخصوص برای این کار را نشان دهیم. تجربه\u200cهایی در شرکت\u200cهای مخصوص چندین دامنه با کلمات متخصص نشان می\u200cدهند که روش ما قادر است کلمات جدید را به طور موثرت در فضای انجمن اصلی وارد کند. در مقایسه با روش مسابقه، روش ما سریعتر، آزاد پارامتر، و تصمیم گیری است.', 'sw': 'Neno imekuwa chombo kikuu katika utaratibu wa lugha asili. Mafunzo mara nyingi hutumia vectors wa maneno yaliyofunzwa kabla, ambazo zilifundishwa kwenye makampuni makubwa ya ujumla, na ambazo zinapatikana kwa urahisi kwenye mtandao wa intaneti. Hata hivyo, vectors wa maneno yaliyo na mafunzo mara nyingi hukosa maneno muhimu kutoka kwenye maeneo maalum. Kwa hiyo mara nyingi inapendelea kuongeza lugha na kuingiza maneno mapya katika mfululizo wa vectors wa maneno ya awali. Katika karatasi hii, tunaweka mbinu yenye ufanisi wa kuwajumuisha maneno mpya kutoka kwenye makampuni maalumu, yenye maneno mapya, katika maneno ya kawaida yaliyojifunza. Tunajenga kwenye mtazamo ulioanzishwa wa maneno yanayoingizwa kama kiwanda cha viwanda ili kuweka utambulisho wa kidini kwa kazi hii. Majaribio kwenye makampuni mbalimbali yenye maneno maalumu yanaonyesha kuwa mbinu yetu inaweza kuingiza maneno mapya kwa ufanisi katika nafasi ya asili. Kulinganishwa na mbinu za kushindana, mbinu yetu ni haraka, parameter bure na yenye uhakika.', 'sq': 'Word embeddings have become a mainstream tool in statistical natural language processing.  Praktikantët shpesh përdorin vektorë fjalësh të trajnuar para, të cilët u trajnuan në korpra të mëdha teksti gjeneral dhe të cilat janë të lehtë në dispozicion në internet. Megjithatë, vektorët e fjalëve të paratrajnuar shpesh mungojnë fjalë të rëndësishme nga fusha specifike. Prandaj është shpesh e dëshirueshme të zgjerohet fjalorin dhe të përfshihen fjalë të reja në një sërë vektorësh të paratrajnuar fjalësh. Në këtë letër, ne paraqesim një metodë të efektshme për përfshirjen e fjalëve të reja nga një korpus i specializuar, që përmban fjalë të reja, në përfshirjen e fjalëve të paratrajnuara gjenerale. Ne ndërtojmë në pamjen e vendosur të përfshirjeve të fjalëve si faktorizime matrice për të paraqitur një algoritëm spektral për këtë detyrë. Experiments on several domain-specific corpora with specialized vocabularies demonstrate that our method is able to embed the new words efficiently into the original embedding space.  Në krahasim me metodat konkuruese, metoda jonë është më e shpejtë, pa parametra dhe përcaktuese.', 'tr': 'Kelimler tebigy diller işleýän statistik dilinde adatça bir esbap boldy. Çalıştyranlar köplenç öňünden öňünden bilinmeli kelime vektörlerini ulanýarlar. Bu büyük jeneral metin korporasynda eğitilýär we olaryň internetde readily ulaşılýarlar. Fakat eğitimli söz vektörleri bazen belli alanlardan önemli sözler yoktur. Bu nedenle sözleri köplenç öňünden eğlenen söz vektörlerine uzatmak ve täze sözleri girmek isleýär. Bu kagyzda, we täze sözleri spesialistik korpusdan dahil etmek üçin täze sözleri taýýarlapdyk, öňünden bilinmeli cäreler sözleri girdirilýän täze sözleri taýýarlapdyk. Bu görev için bir spektral algoritmi sunmak için matris faktörlerini oluşturduğumuz görünümüne göre inşa ediyoruz. Özellikle sözler bilen birnäçe domeny spesifik korporasynda örnekler, biziň täze sözlerimizin original girişim alanına etkinleşendigini kanıtlaýar. Ýaşyp çykyş yönlerimize görä, biziň yöntemimiz çalt, parametresiz we deterministik.', 'hy': 'Բառերի ներառումը դարձավ հիմնական գործիք վիճակագրական բնական լեզվի վերաբերյալ: Պատրաստիչները հաճախ օգտագործում են նախապատրաստված բառերի վեկտորներ, որոնք պատրաստված են մեծ ընդհանուր տեքստի կոպորա վրա և որոնք հեշտությամբ հասանելի են ցանցում: Այնուամենայնիվ, նախապատրաստված բառերի վեկտորները հաճախ կարևոր բառեր պակասում են որոշակի բնագավառներից: Հետևաբար հաճախ ցանկանալի է ընդլայնել բառարանը և ներառել նոր բառեր նախապատրաստված բառային վեկտորների մի շարք: Այս թղթի մեջ մենք ներկայացնում ենք արդյունավետ մեթոդ ներառելու նոր բառերը մասնագիտական մարմնից, որոնք ներառում են նոր բառեր, նախապատրաստված ընդհանուր բառերի ներգրավման մեջ: Մենք կառուցում ենք բառերի ներգրավման հաստատուն տեսանկյունից որպես մատրիքսի գործոնացումներ, որպեսզի ներկայացնենք սպեկտրալ ալգորիթմ այս խնդրի համար: Հասկացած բառարաններով մի քանի բնագավառի մասնավոր մարմնի փորձարկումները ցույց են տալիս, որ մեր մեթոդը կարողանում է արդյունավետ ներգրավել նոր բառերը սկզբնական ներգրավման տարածքում: Համեմատելով մրցակցության մեթոդների հետ, մեր մեթոդը ավելի արագ է, առանց պարամետրերի և որոշիչ:', 'af': "Woord inbêding het 'n onderstreem hulpmiddel geword in statistiese natuurlike taal verwerking. Gepraktiseerders gebruik dikwels voor- onderwerp woord vektore, wat op groot generieke teks korpora onderwerp is, en wat leeg beskikbaar is op die web. Alhoewel, voorafgeleerde woord vektores het ofte belangrike woorde van spesifieke domeine ontbreek. Dit is daarom dikwels wil hê om die woordeboek te uitbrei en nuwe woorde in 'n stel van voorafgevorderde woord vekteurs te binne. In hierdie papier, voorsien ons 'n effektief metode vir insluitering nuwe woorde van 'n spesialiseerde korpus, bevat nuwe woorde, in vooraf gevorderde generieke woord inbêding. Ons bou op die gestel aansig van woord inbêring as matriks faktoriseerings om 'n spektrale algoritme vir hierdie taak te voorsien. Eksperimente op verskeie domein-spesifieke korpora met spesialiseerde woordeboeke bevestig dat ons metode kan die nuwe woorde effektief in die oorspronklike inbêring ruimte inbêer. Vergelyk met mededingsmetodes, is ons metode vinniger, parameter vry en deterministiese.", 'am': 'የቃላት አቀማመጥ የፖለቲካዊ ቋንቋ ማቀናጃ ሀብት ሆነዋል፡፡ ፈተናዎች ብዙ ጊዜ በፊት ተማሪ የቃላት vectors ይጠይቃሉ፣ እነዚህም በታላቅ የውይይት ጽሑፍ ኮርፖራ የተማሩ፣ በመረብ ላይ ቀላል የተገኙ ናቸው፡፡ ነገር ግን አስቀድሞ የተጠቃሚ ቃላት vector ብዙ ጊዜ ከታዋቂው ውጤቶች የተጠቃሚ ቃላት አያገኙም፡፡ እንግዲህ ብዙ ጊዜ ቃላትን ለመዘርጋት እና አዲስ ቃላትን ለመጠቀም ለቀድሞ ተማሪ ቃላት vectors ማቅረብ ያስፈልጋል፡፡ በዚህ ፕሮግራም አዲስ ቃላትን በተለየ አዲስ ቃላት እናስቀምጣለን፣ አዲስ ቃላትን ለቀድሞ በተማረ የgeneric ቃላት እናስገድዳለን፡፡ ለዚህ ስራ የተለየ አሌጎሪትምን ለማሳየት የቃላት ግንኙነትን የማትሪክክ ክፍተቶችን እናደርጋለን፡፡ በተለየ ቋንቋዎች ያሉት የዶሜን-አካባቢ ካርፓር ምርመራዎች አዲሱን ቃላትን በመጀመሪያው አካባቢ ስፍራን በጥቅም ለመግባት ይችላል፡፡ ለመዋጋት ማድረጊያውን በተተካፈለ፣ method ፈጥኖ ነው፣ ባርራሮች ነጻ እና ፍጥረት ነው፡፡', 'bn': 'পরিসংখ্যান প্রাকৃতিক ভাষা প্রক্রিয়ায় শব্দের প্রধান টুল পরিণত হয়েছে। প্রশিক্ষকারীরা প্রায়শ প্রশিক্ষিত শব্দ ভেক্টর ব্যবহার করে, যা বিশাল সাধারণ টেক্সট কর্পোরায় প্রশিক্ষণ প্রদান করা হয় এবং যা ওয়েবে সহজ তবে পূর্ব প্রশিক্ষিত শব্দ ভেক্টর প্রায়শই নির্দিষ্ট ডোমেইন থেকে গুরুত্বপূর্ণ শব্দ পায়। তাই প্রায়শই শব্দভাণ্ডার বাড়িয়ে নতুন শব্দগুলোকে প্রশিক্ষিত শব্দ ভেক্টরে প্রবেশ করা যায়। এই কাগজটিতে আমরা একটি কার্যকর পদ্ধতি উপস্থাপন করছি বিশেষ করে কোর্পাস থেকে নতুন শব্দ, যার মধ্যে নতুন শব্দ রয়েছে পূর্ব প্রশিক্ষিত সাধারণ শব্ এই কাজের জন্য একটি স্পেক্ট্রাল অ্যালগরিদম উপস্থাপন করার জন্য আমরা শব্দের প্রতিষ্ঠিত দৃষ্টিভঙ্গি হিসেবে বানাই। বেশ কয়েকটি ডোমেইন-নির্দিষ্ট কোর্পোরায় পরীক্ষা প্রদর্শন করেছে যে আমাদের পদ্ধতি প্রকাশ করেছে যে আমাদের নতুন শব্দগুলো কার্যকর ভাবে প্রথম Compared to competing methods, our method is faster, parameter-free, and deterministic.', 'ca': "L'integració de paraules s'ha convertit en una eina principal en el processament estadístic de llenguatges naturals. Els practicadors sovint utilitzen vectors de paraules pré-entrenats, que van ser entrenats en grans corpores de text genèric i que estan fàcilment disponibles a la Web. However, pre-trained word vectors oftentimes lack important words from specific domains.  Per tant, sovint és desitjable estendre el vocabulari i incorporar noves paraules en un conjunt de vectors de paraules pré-entrenats. En aquest article, presentem un mètode eficient per incloure noves paraules d'un corpus especialitzat, que contenen noves paraules, en les integracions de paraules genèriques pré-entrenades. Construim sobre la visió estabelecida de l'incorporació de paraules com a factoritzacions de matrius per presentar un algoritme espectral per a aquesta tasca. Experiments on several domain-specific corpora with specialized vocabularies demonstrate that our method is able to embed the new words efficiently into the original embedding space.  Comparat amb mètodes competidors, el nostre mètode és més ràpid, sense paràmetres i determinista.", 'cs': 'Vložení slov se stalo hlavním nástrojem statistického zpracování přirozeného jazyka. Cvičící často používají předem trénované slovní vektory, které byly trénovány na velkých obecných textových korpusech a které jsou snadno dostupné na webu. Nicméně předškolené slovní vektory často chybí důležitá slova z konkrétních domén. Proto je často žádoucí rozšířit slovní zásobu a vložit nová slova do sady předškolených slovních vektorů. V tomto článku představujeme efektivní metodu začlenění nových slov ze specializovaného korpusu obsahujících nová slova do předškolených generických slovních vložení. Navazujeme na zavedený pohled na vkládání slov jako maticové faktorizace, abychom prezentovali spektrální algoritmus pro tento úkol. Experimenty na několika doménově specifických korpusech se specializovanými slovníky ukazují, že naše metoda je schopna efektivně vložit nová slova do původního vkládacího prostoru. Ve srovnání s konkurenčními metodami je naše metoda rychlejší, bez parametrů a deterministická.', 'et': 'Sõnade manustamisest on saanud loodusliku statistilise keele töötlemise peamine vahend. Praktikud kasutavad sageli eelnevalt väljaõpetatud sõnavaktoreid, mis on koolitatud suurte üldiste tekstikorpustega ja mis on kergesti kättesaadavad veebis. Siiski puuduvad eelnevalt väljaõpetatud sõnavaktoritel sageli konkreetsetest valdkondadest pärit olulised sõnad. Seetõttu on sageli soovitav laiendada sõnavara ja lisada uusi sõnu eelnevalt koolitatud sõnavaktoritesse. Käesolevas töös tutvustame tõhusat meetodit uute sõnade lisamiseks spetsialiseeritud korpusest, mis sisaldavad uusi sõnu, eelnevalt koolitatud üldistesse sõnadesse. Tugineme väljakujunenud vaatele sõna manustamisest maatriksi faktorisatsioonidena, et esitada spektraalalgoritm selle ülesande jaoks. Eksperimentid mitmete domeenispetsiifiliste korpustega spetsialiseerunud sõnavara näitavad, et meie meetod suudab uued sõnad tõhusalt manustada algsesse manustamisruumi. Võrreldes konkureerivate meetoditega on meie meetod kiirem, parameetritevaba ja deterministlik.', 'fi': 'Sanaupotuksista on tullut valtavirtalähde luonnollisen kielen tilastollisessa käsittelyssä. Harjoittajat käyttävät usein ennalta koulutettuja sanavektoreita, jotka on koulutettu suuriin yleisiin tekstikorpusiin ja jotka ovat helposti saatavilla verkossa. Esikoulutetuista sanavektoreista puuttuu kuitenkin usein tärkeitä sanoja tietyiltä toimialoilta. Siksi on usein toivottavaa laajentaa sanastoa ja upottaa uusia sanoja ennalta koulutetuihin sanavektoreihin. Tässä työssä esitellään tehokas menetelmä uusien sanojen sisällyttämiseksi erikoiskorpuseen, joka sisältää uusia sanoja, ennalta koulutettuihin yleisten sanojen upotuksiin. Rakennamme vakiintuneen kuvan sanaupotuksista matriisifaktorizaatioina esittääksemme spektrialgoritmin tähän tehtävään. Kokeet useilla toimialueekohtaisilla korpusilla erikoissanastoilla osoittavat, että menetelmämme pystyy upottamaan uudet sanat tehokkaasti alkuperäiseen upotustilaan. Kilpaileviin menetelmiin verrattuna menetelmämme on nopeampi, parametriton ja deterministinen.', 'az': 'Sözlər içərisində Statistik təbiətli dil işləməsində ən böyük bir vasitə oldu. Müştəqilər çox əvvəl təhsil edilmiş söz vektörlərini istifadə edirlər, böyük nümunəlik mətn korporasında təhsil edilmiş və internetdə asanlıqla faydalanırlar. Lakin, əvvəl təhsil edilmiş söz vektörləri çox vaxtlarda məqsədil domenalardan möhüm sözlər yoxdur. Buna görə də sözləri çox uzatmaq və yeni sözləri öyrənmək üçün təhsil edilmiş söz vektörlərinin bir qoşuna qoymaq istəyir. Bu kağızda yeni sözləri, yeni sözləri içərik, əvvəlcə təhsil edilmiş cümləli sözlərə daxil olmaq üçün müvəffəqiyyətli bir metod göstəririk. Biz bu işin spektral algoritmi göstərmək üçün matriks faktorizasyonu olaraq yazılmış kəlmələrin görünüşünə görə inşa edirik. Xüsusiyyətli sözlər olan bir neçə domain-specific korpora təcrübələri təşkil edir ki, metodumuzun yeni sözləri orijinal içərisində təşkil olaraq daxil edə bilər. Yarışmaq metodları ilə qarşılaşdığımız tərzimiz daha hızlı, parametresiz və deterministik.', 'bs': 'Uključenje riječi postalo je glavni alat u procesu statističkog prirodnog jezika. Praktičnici često koriste predobučeni vektori riječi, koji su obučeni na velikoj generičnoj tekstskoj korpori i koji su lako dostupni na internetu. Međutim, predobučeni vektori riječi često nedostaju važne riječi iz specifičnih domena. Stoga je često poželjno proširiti riječ i uključiti nove riječi u set predobučenih vektora riječi. U ovom papiru predstavljamo efikasnu metodu uključujući nove riječi iz specijalizovanog korpusa, sadržavajući nove riječi, u predobučene generične reči. Na osnovu uspostavljenog pogleda ugrađenja riječi kao faktorizacija matrice da predstavimo spektralni algoritam za ovaj zadatak. Eksperimenti na nekoliko domena specifičnih korporacija sa specijaliziranim rečenicama pokazuju da naš metod može učinkovito uključiti nove riječi u originalni integracijski prostor. U usporedbi sa takmičenim metodama, naš metod je brži, bez parametara i determinističan.', 'jv': 'embedding Awakdhéwan politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé, ning basa iki, awak dhéwé nggawe sistem sing luwih nggawe ujaran karo perusahaan karo perusahaan Anyone Export... Dijaraké karo perangkamus yênêmên, awakdhéwé wis luwih, dadi wis munggo karo nggo disinteksi.', 'ha': "@ info: whatsthis @ info: whatsthis Haƙĩƙa, masu shirya masu amfani da magana a gaba ɗaya ko da yawa bã su da magana masu muhimu daga cikin kewayi. Daga wannan, ana buka yin faɗa maganar zaman shawara kuma a shigar da magana na yanzu zuwa wani set of shiryoyi masu da aka amfani da shi gaba ɗaya. Ga wannan takardan, munã gabatar da wata hanyoyi mai amfani da su haɗi wasu kalmõmi na dabar-nau'in da ke ƙunsa da wasu kalmõmi da aka yi wa zaman tsari. Tuna samar da kalmar da aka shigar da shi kamar matrix, dõmin a nuna wani algoritm na spectrum wa wannan aikin. Tajararin da ke kan wasu firma masu ƙayyade guda da tsarin masu da aka ƙayyade, sun nuna cewa metoden mu na iya iya iya shigar da wasu kalmõmi masu fasahan cikin filin na farko. Aka sami da metodin yin gaura, metoden mu na da gaggawa, wata parameter ba da komai ba.", 'he': 'תוספת מילים הפכו כלי ראשי בעבודת שפת טבעית סטטיסטית. מתאמנים לעתים קרובות משתמשים בוקטורים מילים מאומנים מראש, שאומנים על גופורה טקסט גנרלית גדולה, והם זמינים בקלות באינטרנט. עם זאת, ווקטורי מילים מאומנים מראש לעתים קרובות חסרות מילים חשובות מתחומים מסוימים. לכן לעתים קרובות רצוי להאריך את המילים ולקבל מילים חדשות לתוך קבוצה של ווקטורי מילים מאומנים מראש. בעיתון הזה, אנחנו מציגים שיטה יעילה לשלול מילים חדשות מקופוס מיוחד, שמכיל מילים חדשות, לתוך מילים גנרליות מאומנות מראש. אנו בונים על הנוף המבוסס של קיצוב מילים כפעילות מטריקס כדי להציג אלגוריתם ספקטרלי למשימה זו. ניסויים על כמה גופות ספציפיות לתחום עם מילים מיוחדים מראים שהשיטה שלנו מסוגלת להכניס את המילים החדשות באופן יעיל לחלל ההכניסה המקורי. בהשוואה לשיטות מתחרות, השיטה שלנו מהירה יותר, ללא פרמטרים, וקלטנית.', 'sk': 'Vgradnje besedil je postalo glavno orodje v statistični obdelavi naravnega jezika. Praktiki pogosto uporabljajo vnaprej usposobljene besedne vektorje, ki so bili usposobljeni za velike generične besedilne korpuse in so na voljo na spletu. Vendar pa predhodno usposobljenim besednim vektorjem pogosto primanjkuje pomembnih besed iz določenih področij. Zato je pogosto zaželeno razširiti besedišče in vključiti nove besede v nabor vnaprej usposobljenih besednih vektorjev. V prispevku predstavljamo učinkovito metodo vključevanja novih besed iz specializiranega korpusa, ki vsebuje nove besede, v vnaprej usposobljene generične vgradnje besed. Gradimo na uveljavljenem pogledu vgradnje besed kot matrične faktorizacije, da predstavimo spektralni algoritem za to nalogo. Eksperimenti na več domensko specifičnih korpusih s specializiranimi besedniki kažejo, da je naša metoda sposobna učinkovito vdelati nove besede v prvotni prostor za vdelavo. V primerjavi s konkurenčnimi metodami je naša metoda hitrejša, brez parametrov in deterministična.', 'bo': 'གནས་སྟངས་ཀྱི་ཆ་ཁོངས་ནང་དུ་ཚད་རྩིས་ཅན་གྱི་སྐད་རིགས་ལས་སྦྲེལ་མཐུད་ནུས་པ་ཞིག་ཆགས་ཡོད། Practitioners often use pre-trained word vectors, which are trained on large generic text corporations, and which are readily available on the web. ཡིན་ནའང་། སྔོན་གྲངས་སྔོན་འཛིན་གྱི་ཐབས་ལམ་ལ་རྒྱུན་དུ་ཁག་ཆེ་བའི་ཚིག་ཚུ་དམིགས་བསལ་བ་ཡོད། དེར་བརྟེན། འབྲེལ་ས་ཚིག་འདི་རྒྱུན་ལྡན་གྱི་ཐ་སྙད་ཚིག་དང་སྔོན་གྱི་སྔོན་གྲངས་བསྒྲིག་པའི་བརྗོད་ཀྱི་སྒྲིག་སྟངས་ལ ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་དམིགས་འཛུགས་ཅན་གྱི་སྒེར་གྱི་ཚིག་ལས་གཞན་ཚིག་ནང་དུ་འཇུག ང་ཚོས་རྣམ་གྲངས་སྟོན་པའི་ལྟ་སྟངས་ལ་སྒྲིག་འཛུགས་པའི་གྲངས་ཀ་དེ་ཆ་རྐྱེན་གྱིས་མཐོང་སྣང་བྱེད་དགོས Experiments on several domain-specific corpora with specialized vocabularies demonstrate that our method is able to embed the new words efficiently into the original embedding space. Compared to competing methods, our method is faster, parameter-free, and deterministic.'}
{'en': 'A Trio Neural Model for Dynamic Entity Relatedness Ranking', 'ar': 'نموذج ثلاثي عصبي لترتيب ارتباط الكيان الديناميكي', 'pt': 'Um modelo neural trio para classificação de relação de entidade dinâmica', 'fr': 'Un modèle neuronal en trio pour le classement dynamique de la parenté des entités', 'es': 'Un modelo neuronal triple para la clasificación dinámica de relaciones entre entidades', 'ja': '動的エンティティ関連性ランキングのための三重ニューラルモデル', 'zh': '用动实体相关性三重神经模', 'hi': 'गतिशील इकाई संबंधितता रैंकिंग के लिए एक तिकड़ी तंत्रिका मॉडल', 'ru': 'Тройная нейронная модель для динамического ранжирования родства сущностей', 'ga': 'Samhail Néaránach Tríréadaithe le haghaidh Rangú Dinimiciúla Aonáin Dhinimiciúil', 'ka': 'Name', 'hu': 'Három neurális modell a dinamikus entitás kapcsolattartási rangsoroláshoz', 'el': 'Ένα τρίο Νευρικό Μοντέλο για τη Δυναμική Κατάταξη Σχετικότητας Οντότητας', 'it': 'Un modello neurale Trio per il ranking della relazione tra entità dinamiche', 'lt': 'Dinaminio subjekto ryšio klasifikavimo trijų nervų modelis', 'kk': 'Динамикалық нысандарды қатынау үшін трио невралдық модель', 'mk': 'Name', 'ms': 'Model Neural Trio untuk Rangkaian Hubungan Entiti Dinamik', 'ml': 'Dynamic Entity Relations Ranking for Trio Neural Model', 'mt': 'Mudell Newrali Trio għall-Klassifikazzjoni tar-Relazzjoni ma’ Entità Dinamika', 'mn': 'Динамикийн элементийн харилцааны түвшингийн трио мэдрэлийн загвар', 'no': 'Name', 'pl': 'Model neuronowy Trio dla rankingu związków dynamicznych podmiotów', 'ro': 'Un model neural trio pentru clasificarea relației dinamice a entităților', 'sr': 'Trio Neuralni model za dinamičku povezanost sa entitetom', 'si': 'Name', 'so': 'Muuqashada aragtida dhimirka ee danaha ganacsiga', 'sv': 'En Trioneural Modell för Dynamisk Entity Relatedness Ranking', 'ta': 'Name', 'ur': 'Name', 'uz': 'A Trio Neural Model for Dynamic Entity Relatedness Ranking', 'vi': 'Mô hình thần kinh ba cho đơn vị chuyển động động', 'bg': 'Трио неврален модел за класиране на динамичната свързаност на същността', 'da': 'En Trio Neural Model for Dynamic Entity Relatedness Ranking', 'nl': 'Een Trio Neural Model voor Dynamische Entiteit Relatedness Ranking', 'hr': 'Trio neuronski model za snimanje povezanosti s dinamičkim podacima', 'de': 'Ein Trio Neural Modell für das dynamische Entity Relatedness Ranking', 'fa': 'Name', 'id': 'Model Neural Trio untuk Ranking Hubungan Entitas Dinamik', 'ko': '동적 실체 연관도 정렬의 삼원 신경 네트워크 모델', 'sw': 'Modeli ya Neural ya Trio kwa ajili ya Kuhusiana na Ujadala wa Kidynami', 'af': 'Name', 'tr': 'Dinamik bir taýýarlaryň derejesi üçin bir üç näral nusgasy', 'sq': 'Një model neuronal trio për renditjen e njësisë dinamike', 'am': 'dynamics-output-type', 'hy': 'Դինամական միավորների հարաբերության դասակարգման տրիո նյարդային մոդելը', 'bn': 'Name', 'az': 'Dinamik Entity Relativity Ranking üçün Trio Nöral Modeli', 'bs': 'Trio neuronski model za snimanje povezanosti sa dinamičnim entitetima', 'et': 'Dünaamilise olemiga seotud järjestuse kolmikmudel', 'ca': 'Un model trio neuronal per a classificar la relació entre entitats dinàmiques', 'cs': 'Trio Neurální model pro dynamické hodnocení souvislosti entit', 'fi': 'Dynaamisen entiteetin suhdeluokituksen kolmio-hermomalli', 'jv': 'File', 'ha': 'KCharselect unicode block name', 'sk': 'Trio nevralni model za razvrščanje dinamične povezanosti entitete', 'he': 'Name', 'bo': 'Dynamic Entity Relatedness Ranking için 3D Neural Model'}
{'en': 'Measuring entity relatedness is a fundamental task for many natural language processing and information retrieval applications. Prior work often studies ', 'ar': 'يعد قياس ارتباط الكيانات مهمة أساسية للعديد من تطبيقات معالجة اللغة الطبيعية واسترجاع المعلومات. غالبًا ما يدرس العمل السابق علاقة الكيان في بيئة ثابتة وبطريقة غير خاضعة للإشراف. ومع ذلك ، غالبًا ما تشارك الكيانات في العالم الحقيقي في العديد من العلاقات المختلفة ، وبالتالي فإن علاقات الكيانات ديناميكية للغاية بمرور الوقت. في هذا العمل ، نقترح نهجًا قائمًا على الشبكة العصبية يزيد من اهتمام الجمهور كإشراف. نموذجنا قادر على تعلم تمثيلات كيانات غنية ومختلفة في إطار عمل مشترك. من خلال تجارب مكثفة على مجموعات بيانات واسعة النطاق ، نثبت أن طريقتنا تحقق نتائج أفضل من خطوط الأساس التنافسية.', 'pt': 'Medir o parentesco entre entidades é uma tarefa fundamental para muitos aplicativos de processamento de linguagem natural e recuperação de informações. O trabalho anterior geralmente estuda o relacionamento entre entidades em um ambiente estático e não supervisionado. No entanto, as entidades no mundo real estão frequentemente envolvidas em muitos relacionamentos diferentes, consequentemente, as relações entre entidades são muito dinâmicas ao longo do tempo. Neste trabalho, propomos uma abordagem baseada em rede neural que alavanca a atenção do público como supervisão. Nosso modelo é capaz de aprender representações de entidades ricas e diferentes em uma estrutura conjunta. Por meio de extensos experimentos em conjuntos de dados de grande escala, demonstramos que nosso método alcança melhores resultados do que as linhas de base competitivas.', 'fr': "La mesure de la relation entre les entités est une tâche fondamentale pour de nombreuses applications de traitement du langage naturel et de récupération d'informations. Les travaux antérieurs étudient souvent la relation entre les entités dans un cadre statique et de manière non supervisée. Cependant, les entités du monde réel sont souvent impliquées dans de nombreuses relations différentes, par conséquent les relations entre entités sont très dynamiques au fil du temps. Dans ce travail, nous proposons une approche basée sur un réseau de neurones qui tire parti de l'attention du public en tant que supervision. Notre modèle est capable d'apprendre des représentations d'entités riches et différentes dans un cadre commun. Grâce à des expériences approfondies sur des ensembles de données à grande échelle, nous démontrons que notre méthode donne de meilleurs résultats que les bases de référence concurrentes.", 'es': 'Medir la relación entre entidades es una tarea fundamental para muchas aplicaciones de procesamiento de lenguaje natural y recuperación de información. El trabajo previo a menudo estudia la relación entre entidades de forma estática y sin supervisión. Sin embargo, las entidades del mundo real a menudo participan en muchas relaciones diferentes, por lo que las relaciones de las entidades son muy dinámicas a lo largo del tiempo. En este trabajo, proponemos un enfoque basado en redes neuronales que aprovecha la atención pública como supervisión. Nuestro modelo es capaz de aprender representaciones de entidades ricas y diferentes en un marco conjunto. A través de extensos experimentos en conjuntos de datos a gran escala, demostramos que nuestro método logra mejores resultados que las bases de referencia de la competencia.', 'ja': 'エンティティの関連性を測定することは、多くの自然言語処理および情報検索アプリケーションの基本的なタスクです。以前の仕事は、しばしば静的で監督されていない方法でエンティティの関連性を研究します。しかし、現実世界のエンティティは多くの異なる関係に関与することが多く、結果としてエンティティ関係は時間の経過とともに非常に動的になる。本作では、監督として国民の注目を集めるニューラルネットワークをベースとしたアプローチを提案している。私たちのモデルは、共同フレームワークで豊かで異なるエンティティ表現を学ぶことができます。大規模なデータセットに関する広範な実験を通じて、当社の方法が競合ベースラインよりも優れた結果を達成することを実証します。', 'zh': '量实体者相关性众自然语言治信息检索应用程序之大务也。 前事常以静设无监相关性。 然世界实体常涉多异,故随时推移,非常动也。 于是建一神经网络之法,以公众为督。 吾形能合框架而学博异之体。 博实验于大集,证吾道之善于争基线也。', 'hi': 'इकाई संबंधितता को मापना कई प्राकृतिक भाषा प्रसंस्करण और सूचना पुनर्प्राप्ति अनुप्रयोगों के लिए एक मौलिक कार्य है। पूर्व कार्य अक्सर एक स्थिर सेटिंग और असुरक्षित तरीके से इकाई संबंधितता का अध्ययन करता है। हालांकि, वास्तविक दुनिया में संस्थाएं अक्सर कई अलग-अलग रिश्तों में शामिल होती हैं, नतीजतन इकाई संबंध समय के साथ बहुत गतिशील होते हैं। इस काम में, हम एक तंत्रिका नेटवर्क-आधारित दृष्टिकोण का प्रस्ताव करते हैं जो पर्यवेक्षण के रूप में सार्वजनिक ध्यान का लाभ उठाता है। हमारा मॉडल एक संयुक्त ढांचे में समृद्ध और विभिन्न इकाई प्रतिनिधित्व सीखने में सक्षम है। बड़े पैमाने पर डेटासेट पर व्यापक प्रयोगों के माध्यम से, हम प्रदर्शित करते हैं कि हमारी विधि प्रतिस्पर्धी बेसलाइन की तुलना में बेहतर परिणाम प्राप्त करती है।', 'ru': 'Связь измеряемого объекта является фундаментальной задачей для многих приложений обработки и поиска информации на естественном языке. Предыдущая работа часто изучает связь сущности в статической обстановке и неконтролируемым образом. Тем не менее, сущности в реальном мире часто вовлечены во многие различные отношения, следовательно, отношения сущностей очень динамичны с течением времени. В этой работе мы предлагаем нейросетевой подход, который привлекает внимание общественности в качестве надзора. Наша модель способна изучать богатые и различные представления сущностей в совместной структуре. Проведя обширные эксперименты с крупномасштабными наборами данных, мы продемонстрировали, что наш метод дает лучшие результаты, чем конкурентные исходные данные.', 'ga': 'Is tasc bunúsach é gaolmhaireacht aonáin a thomhas do go leor feidhmeanna nádúrtha próiseála teanga agus aisghabhála faisnéise. Is minic a dhéanann réamhobair staidéar ar ghaolmhaireacht aonáin ar bhealach statach agus gan mhaoirseacht. Mar sin féin, is minic a bhíonn baint ag eintitis sa saol fíor le go leor caidrimh éagsúla, dá bhrí sin bíonn caidreamh eintitis an-dinimiciúil le himeacht ama. San obair seo, molaimid cur chuige néarbhunaithe líonra-bhunaithe a ghiaráil aird an phobail mar mhaoirseacht. Tá ár múnla in ann uiríll saibhir agus éagsúil aonáin a fhoghlaim i gcomhchreat. Trí thurgnaimh fhairsing ar thacair sonraí ar scála mór, léirímid go mbaineann ár modh torthaí níos fearr ná bunlínte iomaíocha.', 'hu': 'Az entitások kapcsolatának mérése alapvető feladat számos természetes nyelvfeldolgozó és információvisszakereső alkalmazás számára. Az előzetes munka gyakran statikus környezetben és felügyelet nélkül vizsgálja az entitások kapcsolatát. A valós világban lévő entitások azonban gyakran számos különböző kapcsolatban vesznek részt, így az entitási kapcsolatok idővel nagyon dinamikusak. Ebben a munkában olyan neurális hálózat alapú megközelítést javasolunk, amely felügyeletként felhasználja a közönség figyelmét. Modellünk képes gazdag és különböző entitási reprezentációkat tanulni egy közös keretben. A nagyszabású adatkészleteken végzett kiterjedt kísérletek révén bizonyítjuk, hogy módszerünk jobb eredményeket ér el, mint a versenyképes alapkészletek.', 'ka': 'ელექტის შესახებ განსაზღვრება არის ფუნდამენტური რაოდენობა რაოდენობითი ენის პროცესი და ინფორმაციის მიღება პროგრამებისთვის. პირველი სამუშაო სამუშაო მუშაოდ განსხვავება ინტერტიკის შესახებ სტატიკალური დაწყებაში და არ განსხვავებული გზით. მაგრამ, რეალური მსოფლიოში ინტერტიკები ზოგიერთად განსხვავებული პრობლემებში დაკავშირებულია, შემდეგ ინტერტიკური პრობლემები ძალიან დინამიკური ამ სამუშაოში ჩვენ მინდომა ნეიროლური ქსელის მიღება, რომელიც საშუალო დაახლოების შესახებ. ჩვენი მოდელი შესაძლებელია ბედნიერი და განსხვავებული ინტერტიკის გამოსახულებების შესაძლებლობა ერთადერთი ფრამეტში. უფრო დიდი მონაცემების განსაზღვრების გამოყენებით, ჩვენ გამოჩვენებთ, რომ ჩვენი მეტი უფრო დიდი მონაცემების გამოყენება, ვიდრე კონკრენტებული ბაზ', 'el': 'Η μέτρηση της σχέσης με οντότητες αποτελεί θεμελιώδη εργασία για πολλές εφαρμογές επεξεργασίας φυσικής γλώσσας και ανάκτησης πληροφοριών. Η προηγούμενη εργασία συχνά μελετά τη σχέση οντότητας με στατικό περιβάλλον και χωρίς επίβλεψη. Ωστόσο, οι οντότητες στον πραγματικό κόσμο συχνά εμπλέκονται σε πολλές διαφορετικές σχέσεις, επομένως οι σχέσεις οντότητας είναι πολύ δυναμικές με την πάροδο του χρόνου. Στην εργασία αυτή, προτείνουμε μια προσέγγιση βασισμένη σε νευρωνικό δίκτυο που αξιοποιεί την προσοχή του κοινού ως εποπτεία. Το μοντέλο μας είναι ικανό να μάθει πλούσιες και διαφορετικές αναπαραστάσεις οντοτήτων σε ένα κοινό πλαίσιο. Μέσα από εκτεταμένα πειράματα σε σύνολα δεδομένων μεγάλης κλίμακας, αποδεικνύουμε ότι η μέθοδος μας επιτυγχάνει καλύτερα αποτελέσματα από τις ανταγωνιστικές βάσεις.', 'it': "Misurare la relazione tra entità è un compito fondamentale per molte applicazioni di elaborazione del linguaggio naturale e di recupero delle informazioni. Il lavoro precedente studia spesso la relazione tra entità in un ambiente statico e non supervisionato. Tuttavia, le entità nel mondo reale sono spesso coinvolte in molte relazioni diverse, di conseguenza le relazioni di entità sono molto dinamiche nel tempo. In questo lavoro, proponiamo un approccio basato sulla rete neurale che sfrutta l'attenzione pubblica come supervisione. Il nostro modello è in grado di apprendere rappresentazioni di entità ricche e diverse in un quadro comune. Attraverso ampi esperimenti su set di dati su larga scala, dimostriamo che il nostro metodo raggiunge risultati migliori rispetto alle linee di base competitive.", 'lt': 'Matavimo subjekto ryšys yra pagrindinė daugelio gamtinių kalbų apdorojimo ir informacijos gavimo paraiškų užduotis. Ankstesnis darbas dažnai tiria subjekto ryšį statinėmis sąlygomis ir nepastebimu būdu. Tačiau realiojo pasaulio subjektai dažnai dalyvauja daugelyje skirtingų santykių, todėl ilgainiui subjektų santykiai yra labai dinamiški. Šiame darbe siūlome nerviniu tinklu grindžiamą požiūrį, kuris sutelkia visuomenės dėmesį kaip priežiūrą. Mūsų model is gali mokytis turtingų ir skirtingų subjektų atstovavimų bendroje sistemoje. Atlikus išsamius didelio masto duomenų rinkinių eksperimentus, įrodome, kad mūsų metodas gauna geresnių rezultatų nei konkurencingos bazės.', 'mk': 'Мерањето на поврзаноста на ентитетот е фундаментална задача за многу природни апликации за обработување јазик и преземање информации. Претходната работа честопати ја проучува поврзаноста на ентитетот во статичко поставување и ненадгледуван начин. Сепак, ентитетите во реалниот свет честопати се вклучени во многу различни односи, со што односите на ентитетите се многу динамични со текот на времето. Во оваа работа, предложуваме пристап базиран на нервната мрежа кој го привлекува вниманието на јавноста како надзор. Нашиот модел е способен да учи богати и различни претставувања на ентитетите во заедничка рамка. Со експерименти на големи податоци, демонстрираме дека нашиот метод постигнува подобри резултати од конкурентните бази.', 'kk': 'Өлшеу нысандарының қатынасы - көпшілік тілді өңдеу және мәліметті алу қолданбаларының негізгі тапсырмасы. Алдыңғы жұмыс бағдарламалардың статикалық параметрлерінде және бағдарламалардың қатынасын зерттейді. Бірақ шын әлемдегі бағдарламалар көптеген қатынастарда қатынайды, сондықтан бұл бағдарламалар уақытта өте динамикалық. Бұл жұмыстың көпшілігін бақылау үшін көпшілік қатынасын көмектесетін невралдық желінің негіздеген тәсілдігін таңдаймыз. Біздің моделіміз баяны және әртүрлі бірлік қоршау бағдарламаларды үйренуге мүмкіндік береді. Үлкен масштабтағы деректер жиындарындағы кеңейтілген тәжірибелер арқылы, әдіміздің тәжірибелі негізгі жолдардан артық нәтижелерді жеткізетін деп көрсе', 'ms': 'Kekaitan entiti mengukur adalah tugas dasar bagi banyak pemprosesan bahasa alam dan aplikasi pemulihan maklumat. Kerja terdahulu sering mempelajari hubungan entiti dalam tetapan statik dan cara tidak diawasi. Namun, entiti di dunia nyata sering terlibat dalam banyak hubungan yang berbeza, oleh itu hubungan entiti sangat dinamik pada masa. Dalam kerja ini, kami cadangkan pendekatan berasaskan rangkaian saraf yang menggunakan perhatian awam sebagai pengawasan. Our model is capable of learning rich and different entity representations in a joint framework.  Melalui eksperimen luas pada set data skala besar, kami menunjukkan bahawa kaedah kami mencapai keputusan yang lebih baik daripada garis dasar kompetitif.', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയഭാഷയുടെയും വിവരങ്ങളുടെ വിവരങ്ങളുടെയും പ്രയോഗങ്ങള്\u200dക്കും അളന്നുകൊടുക്കുന്നത്  സ്റ്റാറ്റിക്ക് സജ്ജീകരണങ്ങളിലും സൂക്ഷിക്കാത്ത രീതിയിലും സാധാരണയില്ലാത്ത വസ്തുവിന്റെ ബന്ധപ എന്നാലും, യഥാര്\u200dത്ഥ ലോകത്തുള്ള വസ്തുക്കള്\u200d പലപ്പോഴും വ്യത്യസ്ത ബന്ധങ്ങളില്\u200d പങ്കുചേര്\u200dന്നിരിക്കുന്നു. അതുകൊണ്ട്  ഈ ജോലിയില്\u200d, നമ്മള്\u200d ഒരു ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റ്\u200cവര്\u200dക്ക് അടിസ്ഥാനത്തിലുള്ള പ്രായോഗ്യം പ്രായശ്ച നമ്മുടെ മോഡല്\u200d സമ്പന്നരും വ്യത്യസ്തമായ വസ്തുക്കളുടെ പ്രതിനിധികളും പഠിപ്പിക്കാന്\u200d കഴിയുന്നു. വലിയ ഡാറ്റാസറ്റുകളിലെ വിശാലമായ പരീക്ഷണങ്ങളിലൂടെ, നമ്മുടെ രീതിയില്\u200d മത്സരിക്കുന്ന അടിസ്ഥാനങ്ങളെക്കാള്\u200d നല്ല ഫലങ്ങള്\u200d ന', 'mt': 'Il-kejl tar-rabta tal-entità huwa kompitu fundamentali għal ħafna applikazzjonijiet għall-ipproċessar tal-lingwi naturali u għall-irkupru tal-informazzjoni. Xogħol preċedenti spiss jistudja r-relazzjoni tal-entità f’ambjent statiku u b’mod mhux sorveljat. Madankollu, entitajiet fid-dinja reali spiss ikunu involuti f’ħafna relazzjonijiet differenti, konsegwentement ir-relazzjonijiet tal-entitajiet huma dinamiċi ħafna maż-żmien. F’din il-ħidma, nipproponu approċċ ibbażat fuq in-netwerk newrali li jagħti spinta lill-attenzjoni pubblika bħala superviżjoni. Il-mudell tagħna huwa kapaċi jitgħallem rappreżentazzjonijiet ta’ entitajiet rikki u differenti f’qafas konġunt. Permezz ta’ esperimenti estensivi fuq settijiet ta’ dejta fuq skala kbira, aħna nuru li l-metodu tagħna jikseb riżultati aħjar mil-linji bażi kompetittivi.', 'mn': 'Объектын хамааралтай байдал нь байгалийн хэл үйлдвэрлэх болон мэдээллийн хэрэглээний үндсэн ажил юм. Өмнөх ажлын тухай байгууллага байгууллага болон баталгаагүй байдлыг ихэвчлэн судалдаг. Гэхдээ бодит ертөнцийн биетүүд ихэвчлэн олон өөр харилцаанд оролцдог. Иймээс биетийн харилцаа цаг хугацаанд маш хөдөлгөөнтэй. Энэ ажлын тулд бид мэдрэлийн сүлжээнд суурилсан ойлголт нь олон нийтийн анхаарлыг удирдлага болгон нөлөөлдөг. Бидний загварын загвар нь баян болон өөр нэг загварын үзүүлэлт сурах боломжтой. Маш их хэмжээний өгөгдлийн сангийн олон туршилтаар бидний арга нь өрсөлдөг суурь шугамнаас илүү сайн үр дүнг гаргадаг гэдгийг харуулж байна.', 'no': 'Måling av entitetsrelateten er ein grunnleggjande oppgåve for mange naturspråkprocessingar og informasjonshenting. Førre arbeid studerer ofte entitetsrelateten på ein statisk innstilling og ikkje-oppretta måte. Men einingar i verkeleg er ofte involvert i mange forskjellige forhold, slik at einingsforhold er svært dynamisk over tid. I denne arbeiden foreslår vi ein neuralnettverksbasert tilnærming som leverer offentlig oppmerksomhet som oversikt. Modellen vårt er i stand til å lære rike og ulike entitetsrepresentasjonar i eit saman ramme. Gjennom utvida eksperimenter på store skala datasett, viser vi at metoden vårt når det gjer bedre resultat enn konkurentære baselinjer.', 'sr': 'Obveznost mjerenja entiteta je osnovni zadatak za mnoge prirodne obrade jezika i aplikacije za prikupljanje informacija. Prije posla često proučavaju povezanost subjekta na statičkom stanju i neodređenom naèinu. Međutim, entiteti u stvarnom svijetu često su uključeni u mnoge različite odnose, stoga su odnosi entiteta veoma dinamični tokom vremena. U ovom poslu predlažemo neuralnu mrežu bazirani pristup koji utiče na javnu pažnju kao nadzor. Naš model je sposoban učiti bogate i različite predstave entiteta u zajedničkom okviru. Kroz široke eksperimente na velikim podacima, pokazujemo da naš metod postiže bolji rezultat od konkurentnih osnovnih linija.', 'pl': 'Pomiar powiązania z jednostkami jest podstawowym zadaniem dla wielu aplikacji przetwarzania języków naturalnych i pozyskiwania informacji. Wcześniejsza praca często bada związek z jednostkami w ustawieniu statycznym i bez nadzoru. Jednak podmioty w świecie rzeczywistym często są zaangażowane w wiele różnych relacji, w konsekwencji relacje jednostek są bardzo dynamiczne z biegiem czasu. W niniejszej pracy proponujemy podejście oparte na sieci neuronowej, które wykorzystuje uwagę publiczną jako nadzór. Nasz model jest w stanie uczyć się bogatych i różnych reprezentacji podmiotów we wspólnych ramach. Poprzez szerokie eksperymenty na dużej skali zbiorach danych pokazujemy, że nasza metoda osiąga lepsze wyniki niż konkurencyjne linie bazowe.', 'si': 'ස්වභාවික භාෂාව ප්\u200dරවේශනය සහ තොරතුරු ප්\u200dරවේශනය ලබාගන්න පුළුවන් වෙනුවෙන් මූලික වැඩක්. ප්\u200dරධාන වැඩේ හැමවෙලාවට ප්\u200dරධාන විදියට අධ්\u200dයාපනය කරන්න පුළුවන් විදියට ස්ථිර සැකසුම් සහ න නමුත්, ඇත්ත ලෝකයේ සංවිධාන සම්බන්ධතාවන් ගොඩක් වෙනස් සම්බන්ධතාවන් වලට සම්බන්ධ වෙනවා, ඉතින් සං මේ වැඩේ අපි ප්\u200dරශ්නයක් කරන්නේ න්\u200dයූරල් ජාලයේ අධාරිත විදිහට ප්\u200dරශ්නයක් තියෙන්නේ ජාතික අවධ අපේ මොඩල් එක්ක සම්බන්ධයෙන් සහ වෙනස් ප්\u200dරදේශයක් ඉගෙන ගන්න පුළුවන්. ලොකු ප්\u200dරමාණයේ දත්ත සේට් වල විශාල ප්\u200dරයෝජනයෙන් අපි පෙන්වන්නම් අපේ විදියට ප්\u200dරයෝජනය කරනවා අපේ විදියට ප', 'ro': 'Măsurarea relației entităților este o sarcină fundamentală pentru multe aplicații de prelucrare a limbajului natural și recuperare a informațiilor. Lucrările anterioare studiază adesea relația entităților într-un cadru static și nesupravegheat. Cu toate acestea, entitățile din lumea reală sunt adesea implicate în multe relații diferite, prin urmare relațiile entităților sunt foarte dinamice în timp. În această lucrare, propunem o abordare bazată pe rețele neurale care valorifică atenția publică ca supraveghere. Modelul nostru este capabil să învețe reprezentări de entități bogate și diferite într-un cadru comun. Prin experimente extinse pe seturi de date la scară largă, demonstrăm că metoda noastră obține rezultate mai bune decât liniile de bază competitive.', 'so': 'Heshiiska la xiriira waa shaqada aasaasiga ah ee baaraandegista luqada asalka ah iyo codsiga helitaanka macluumaadka. Shaqo horaadka ah waxey inta badan wax ka baraan yihiin xiriir la xiriira bogga shahaadada iyo qaab aan la ilaalin karin. Si kastaba ha ahaatee xuquuqda caalamiga ah inta badan waxay ku qeyb galaan xiriir kala duduwan, sababtoo darteed xiriirka xuquuqda ayaa aad u dhaqdhaqaaqsan waqti dheer. Markaas waxan, waxaynu soo jeedaynaa qaab ku saleysan shabakadda neurada ah oo u soo jeeda ilaaliya dadweynaha. Tusaale ahaan ayaa awoodi kara in aad barto noocyo hodan ah iyo noocyo kala duduwan oo aad ka barto noocyada wadajirka ah. Imtixaano dheeraad ah oo ku qoran sawirada macluumaadka waaweyn ayaannu caddaynaynaa in qaababkayagu uu ka heli karo midho ka wanaagsan sameynta saldhigyada tartanka.', 'sv': 'Att mäta relationen mellan entiteter är en grundläggande uppgift för många program för behandling av naturligt språk och informationssökning. Tidigare arbete studerar ofta personlighetsrelation i en statisk miljö och obevakat sätt. Men entiteter i den verkliga världen är ofta involverade i många olika relationer, följaktligen entiteters relationer är mycket dynamiska över tid. I detta arbete föreslår vi ett neuralt nätverksbaserat tillvägagångssätt som utnyttjar allmänhetens uppmärksamhet som övervakning. Vår modell är kapabel att lära sig rika och olika entitetsrepresentationer i en gemensam ram. Genom omfattande experiment på storskaliga datauppsättningar visar vi att vår metod ger bättre resultat än konkurrenskraftiga baslinjer.', 'ta': 'பல இயல்பான மொழி செயல்படுத்தல் மற்றும் தகவல் பெறுதல் பயன்பாடுகளுக்கு ஒரு முக்கியமான செயல். முன்னிருப்பு வேலை பெரும்பாலாவது பொருள் தொடர்பு மற்றும் பாதுகாப்பாக்கப்படாத வகையில் இணைப்புகள ஆனால், உண்மையான உலகில் உள்ள பொருள்கள் பெரும்பாலாகவே பல்வேறு வித்தியாசமான உறவுகளில் சேர்க்கப்படுகின்றன, அதனால் உண்ம இந்த வேலையில், நாம் ஒரு புதிய வலைப்பின்னல் அடிப்படையிலான செயல்பாட்டை நினைவூட்டுகிறோம் என்று பொது  எங்கள் மாதிரி பணக்கத்தை மற்றும் வேறு வித்தியாசமான உண்மையின் பங்கீடுகளை கற்றுக்கொள்ள முடியும். Through extensive experiments on large-scale datasets, we demonstrate that our method achieves better results than competitive baselines.', 'ur': 'انٹیٹ کے معاملہ کا اندازہ بہت سی طبیعی زبان پردازش اور اطلاعات اٹھانے کے لئے ایک بنیادی تابع ہے. اگلے کام اکثر ایست کی تعلقات کی تعلقات کی تلاش کرتی ہے ایک ایست کے ساتھ اور غیر قابل تعلقات کی طرح۔ لیکن حقیقی دنیا میں موجودات اکثر مختلف رابطہ میں شامل ہوتے ہیں، یہاں تک کہ موجودات کے بارے میں بہت سی موجودات ہیں. اس کام میں ہم ایک نیورال نیٹ ورک کی بنیادی طریقے سے پیشنهاد کرتے ہیں جو عمومی توجه کو نظر کے طور پر دکھاتا ہے۔ ہمارا موڈل ایک جوڑے فرم میں ثروت اور مختلف انٹیٹیٹ کی تعلیم سکھانے کے قابل ہے. بڑے اسکیل ڈاٹ سٹ پر بڑے آزمائش کے ذریعہ، ہم نشان دیتے ہیں کہ ہماری طریقہ مسابقات بیس لین سے بہتر نتائج حاصل کرتی ہے.', 'uz': "Name Birinchi ishni ko'pincha o'rganadi, statistik moslamalari va saqlanmagan usullarda ma'lumotni o'rganadi. Lekin dunyodagi obʼektlar ko'pincha boshqa munosabatlar bilan bog'liqdir, shunday qilib quyidagi narsalar vaqtda juda dynamik. Bu ishda biz neyrolik tarmoqning asosiy tilini taqdim qilamiz. Bu narsalarni taqdim qilish uchun umumiy taqdim qiladi. Bizning modelimiz bir birlashtirish frameidagi taxminan va har xil ma'lumot tashkilotlarini o'rganish mumkin. Butun katta maʼlumotlar tarkibida katta taʼminlovchi tajribalar orqali biz usuli rivojlanadigan asboblardan yaxshi natijalarni ko'rsatdik.", 'vi': 'Quan hệ về thước đo thực thể là một nhiệm vụ cơ bản cho nhiều chương trình xử lý ngôn ngữ tự nhiên và thu thập thông tin. Trước công việc thường nghiên cứu về liên hệ thực thể theo một cách tĩnh lặng và không giám sát. Tuy nhiên, thực thể trong thế giới thực thường tham gia vào nhiều mối quan hệ khác nhau, vì thế các mối quan hệ thực thể rất sôi động qua thời gian. Trong công việc này, chúng tôi đề xuất một phương pháp mạng thần kinh hỗ trợ sự quan tâm của công chúng. Cơ chế của chúng tôi có khả năng học những cử tri giàu có và khác nhau trong một bộ phận chung. Bằng các thí nghiệm đầy đủ trên các nhà dữ liệu quy mô lớn, chúng tôi chứng minh rằng phương pháp đạt được kết quả tốt hơn so với các nền tảng cạnh tranh.', 'bg': 'Измерването на свързаността на субектите е основна задача за много приложения за обработка на естествени езици и извличане на информация. Предишната работа често изучава връзката с субектите в статична обстановка и без надзор. Въпреки това, субектите в реалния свят често участват в много различни взаимоотношения, следователно отношенията между субектите са много динамични с течение на времето. В тази работа предлагаме подход, базиран на невронна мрежа, който привлича общественото внимание като надзор. Нашият модел е способен да изучава богати и различни представяния на субектите в съвместна рамка. Чрез обширни експерименти с мащабни набори от данни ние демонстрираме, че нашият метод постига по-добри резултати от конкурентните базови линии.', 'nl': 'Het meten van entiteitsverwantschap is een fundamentele taak voor veel toepassingen voor natuurlijke taalverwerking en informatieterugwinning. Eerder werk bestudeert vaak entiteitsverwantschap in een statische setting en zonder toezicht. Echter, entiteiten in de echte wereld zijn vaak betrokken bij veel verschillende relaties, waardoor entiteitsrelaties in de loop van de tijd zeer dynamisch zijn. In dit werk stellen we een neurale netwerkgebaseerde aanpak voor die publieke aandacht als supervisie benut. Ons model is in staat om rijke en verschillende entiteitsrepresentaties in een gezamenlijk kader te leren. Door uitgebreide experimenten met grootschalige datasets laten we zien dat onze methode betere resultaten behaalt dan concurrerende baselines.', 'da': 'Måling af enhedsrelaterethed er en grundlæggende opgave for mange programmer til behandling af naturligt sprog og informationssøgning. Tidligere arbejde studerer ofte entitetsrelaterethed i en statisk indstilling og uden opsyn. Men enheder i den virkelige verden er ofte involveret i mange forskellige relationer, derfor enhedsrelationer er meget dynamiske over tid. I dette arbejde foreslår vi en neural netværksbaseret tilgang, der udnytter offentlighedens opmærksomhed som overvågning. Vores model er i stand til at lære rige og forskellige enhedsrepræsentationer i en fælles ramme. Gennem omfattende eksperimenter med store datasæt viser vi, at vores metode opnår bedre resultater end konkurrencedygtige basislinjer.', 'hr': 'Relativnost mjerenja subjekta je temeljni zadatak za mnoge prirodne obrade jezika i primjene prikupljanja informacija. Prije posla često ispitiva povezanost subjekta na statičkom stanju i neodređenom načinu. Međutim, subjekti u stvarnom svijetu često se uključuju u mnoge različite odnose, stoga su odnosi entiteta veoma dinamični tijekom vremena. U ovom poslu predlažemo pristup na neuralnoj mreži koji utiče na javnu pažnju kao nadzor. Naš model je sposoban učiti bogate i različite predstave entiteta u zajedničkom okviru. Kroz široke eksperimente na velikim podacima, pokazujemo da naš metod postigne bolji rezultat od konkurentnih osnovnih linija.', 'ko': '실체의 관련성을 측정하는 것은 많은 자연 언어 처리와 정보 검색 응용의 기본적인 임무이다.이전의 작업은 통상적으로 정태적이고 감독이 없는 방식으로 실체의 관련성을 연구했다.그러나 현실 세계의 실체는 왕왕 많은 서로 다른 관계와 관련되기 때문에 실체 관계는 시간의 추이에 따라 매우 동태적이다.이 업무에서 우리는 신경 네트워크를 바탕으로 하는 방법을 제시하여 대중의 관심을 감독으로 삼았다.우리의 모델은 하나의 연합 틀에서 풍부하고 서로 다른 실체 표현을 배울 수 있다.대규모 데이터 집합에서의 대량의 실험을 통해 우리는 우리의 방법이 경쟁적인 기선보다 더 좋은 결과를 얻었다는 것을 증명하였다.', 'de': 'Die Messung der Entitätsbeziehung ist eine fundamentale Aufgabe für viele Anwendungen zur Verarbeitung natürlicher Sprache und zum Informationsabruf. Frühere Arbeiten untersuchen oft Entitätenbeziehungen in statischer Umgebung und unbeaufsichtigter Weise. Jedoch sind Entitäten in der realen Welt oft in viele verschiedene Beziehungen involviert, folglich Entitätenbeziehungen im Laufe der Zeit sehr dynamisch sind. In dieser Arbeit schlagen wir einen neuronalen Netzwerk-basierten Ansatz vor, der öffentliche Aufmerksamkeit als Aufsicht nutzt. Unser Modell ist in der Lage, reiche und verschiedene Entitätsrepräsentationen in einem gemeinsamen Rahmen zu lernen. Durch umfangreiche Experimente an großen Datensätzen zeigen wir, dass unsere Methode bessere Ergebnisse erzielt als konkurrierende Baselines.', 'id': 'Mengukur hubungan entitas adalah tugas dasar bagi banyak proyeksi bahasa alam dan aplikasi penulisan informasi. Pekerjaan sebelumnya sering mempelajari hubungan entitas dalam pengaturan statis dan cara tidak diawasi. Namun, entitas di dunia nyata sering terlibat dalam banyak hubungan yang berbeda, konsekuensinya hubungan entitas sangat dinamik dengan waktu. Dalam pekerjaan ini, kami mengusulkan pendekatan saraf berdasarkan jaringan yang menggunakan perhatian publik sebagai pengawasan. Our model is capable of learning rich and different entity representations in a joint framework.  Melalui eksperimen ekstensif pada set data skala besar, kami menunjukkan bahwa metode kami mencapai hasil yang lebih baik daripada garis dasar kompetitif.', 'fa': 'ارتباط ارتباط برقراری واحد یک کار بنیادی برای پرداخت زبان طبیعی و کاربرد گیری اطلاعات است. کارهای پیشینه اغلب تعلق ارتباط با یک تنظیم ثابت و غیرقابل تحقیق می\u200cکند. با این حال، شرکت\u200cها در دنیای واقعی اغلب در بسیاری از رابطه\u200cهای مختلف درگیر می\u200cشوند، بنابراین رابطه\u200cهای شرکت\u200cها در طول زمان بسیار دینامیک هستند. در این کار، ما پیشنهاد می\u200cکنیم یک روش روزنامه\u200cی شبکه عصبی که توجه عمومی را به عنوان مراقبت تأثیر می\u200cدهد. مدل ما قادر است از یاد گرفتن نمایش\u200cهای شرکت پولدار و متفاوت در یک چهارچوب مشترک باشد. از طریق آزمایشات وسیع در مجموعه\u200cهای داده\u200cهای مقیاس بزرگ، نشان می\u200cدهیم که روش ما نتیجه\u200cهای بهتر از خط\u200cهای پایگاه رقابت می\u200cرسد.', 'af': "Maating van entiteit verligting is 'n fundamentele taak vir baie natuurlike taal verwerking en inligting ontvang toepassings. Vorige werk studeer dikwels entiteit verwantigheid in 'n statiese instelling en ononderwerp manier. Maar entiteite in werklike wêreld word dikwels in baie verskillende verwantings ingesluit, sodat entiteite verwantings is baie dinamies oor tyd. In hierdie werk voorstel ons 'n neurale netwerk-gebaseerde toegang wat publieke aandag as supervisie verwyder. Ons model is in staat om ryk en verskillende entiteit-voorstellings te leer in 'n saamste raamwerk. Deur uitbreidige eksperimente op groot skaal datastelle, wys ons dat ons metode beter resultate bereik as mededingslige basisline.", 'sw': 'Kupima uhusiano wa taasisi ni kazi ya msingi kwa ajili ya utaratibu wa lugha za asili na matumizi ya kupata taarifa. Kazi ya awali mara nyingi husoma masomo yanayohusiana na mazingira ya takwimu na namna isiyohifadhiwa. Hata hivyo, vyombo katika dunia halisi mara nyingi hujihusisha na mahusiano mengi tofauti, kwa hiyo mahusiano ya viwanda yanakuwa na nguvu sana kwa muda. Katika kazi hii, tunapendekeza mbinu inayotumika na mtandao wa neura ambazo zinaleta mitazamo ya umma kama ufuatiliaji. Mfano wetu una uwezo wa kujifunza uwakilishi tajiri na tofauti katika mfumo wa pamoja. Kwa kupitia majaribio mengi kwenye seti kubwa ya data, tunaonyesha kuwa mbinu zetu hufanikiwa matokeo bora kuliko misingi ya ushindani.', 'sq': 'Mësimi i lidhjes me njësinë është një detyrë thelbësore për shumë aplikime të përdorimit natyror të gjuhës dhe marrjes së informacionit. Puna e mëparshme shpesh studion lidhjen e njësisë në një qëndrim statik dhe mënyrë jo të mbikqyrur. Megjithatë, njësitë në botën reale janë shpesh të përfshira në shumë marrëdhënie të ndryshme, kështu që marrëdhëniet e njësisë janë shumë dinamike gjatë kohës. Në këtë punë, propozojmë një qasje të bazuar në rrjetin nervor që nxjerr vëmendjen publike si mbikqyrje. Modeli ynë është i aftë për të mësuar përfaqësime të pasura dhe të ndryshme të njësive në një kuadër të përbashkët. Nëpërmjet eksperimenteve të gjerë në grupe të dhënash në shkallë të madhe, ne demonstrojmë se metoda jonë arrin rezultate më të mira se linjat bazë konkurruese.', 'am': 'የአካባቢው ግንኙነት የሚያስፈልግ ብዙዎች የፍጥረት ቋንቋዎች ማቀናቀል እና መረጃ ማግኘት ፕሮግራሞች መሠረት ነው፡፡ አስቀድሞ ሥራ ብዙ ጊዜ አካሄዱን በተስታወቀው እና በተጠበቀው ቋንቋ ተማርካል፡፡ However, entities in real-world are often involved in many different relationships, consequently entity relations are very dynamic over time.  በዚህ ሥራ፣ የናውሬው መረብ የተደረገውን የህዝቡን ትኩረት እንደ ተጠቃሚነት ያሳልፋል፡፡ ሞዴሌያችን ባለጠጋ እና ልዩ አካል መልዕክቶችን በመማር ይችላል፡፡ በታላቅ ዳታ-ሰርተሮች ላይ በተጨማሪው ፈተናዎች፣ የሥርዓታችን ፍሬዎችን ከመዋጋት መሠረት የሚሻል እንዲያገኝ እናሳያቸዋለን፡፡', 'tr': 'Barlık baglanylygyny ölçümek tebigat dillerini işlemek we maglumat almak uygulamalary üçin esasy täblikdir. Öňki işiň kän bir zatlary statik düzümleri we suytlanmaýan şekilde barlygyny öwrenýär. Ýöne, hakyky dünýäde birnäçe dürli baglaşyklaryň içine alyp barýar, soňra birnäçe dürli baglaşyklaryň wagtynda örän dinamikdyr. Bu işde, halkara ünsüni gözezden çykarmak üçin näyral şebeke tabanly bir ýalaýyşy teklip edýäris. Biziň modelimiz baý we farklı bir zatlary üýtgetmegimize mümkin edip bilýär. Uly ölçekli datawatlaryň üstünde örän uly deneylerden ukyp edýän çykyşlarymyň täsirli baseliniň üstünden gowy netijelerini ýetip biljekdigini görkezýäris.', 'az': 'Ölçüləmə məlumatı təbiətli dil işləməsi və məlumat alma proqramları üçün fundamental bir işdir. Əvvəlki işlər çox dəyişiklik tərzlərini statik tərzlərində və dəyişiklik tərzlərində təhsil edir. Ancaq həqiqət dünyadakı məlumatlar çox fərqli ilişkilərdə məşğul olur, buna görə də məlumatlar zamanında çox dinamikdir. Bu işdə, nürol a ğ tərəfindən təklif edirik ki, halkı dikkatini gözətçi olaraq təsirləndirir. Bizim modellərimiz zəngin və farklı bir entitə göstəricilərini birlikdə öyrənə bilər. Büyük ölçüdə veri qurularında böyük təcrübələr vasitəsilə, metodumuzun münafiqli baz çətinlərdən daha yaxşı sonuçlarını tapacağını göstəririk.', 'hy': 'Ինքնության կապը չափելը շատ բնական լեզուների վերամշակման և տեղեկատվության վերաբերյալ ծրագրերի հիմնական խնդիր է: Prior work often studies entity relatedness in a static setting and unsupervised manner.  Այնուամենայնիվ, իրական աշխարհի կազմակերպությունները հաճախ ներգրավված են տարբեր հարաբերություններում, հետևաբար կազմակերպությունները շատ դինամիկ են ժամանակի ընթացքում: Այս աշխատանքի ընթացքում մենք առաջարկում ենք նյարդային ցանցի հիմնված մոտեցում, որը օգնում է հանրային ուշադրությունը որպես վերահսկողություն: Մեր մոդելը կարողանում է սովորել հարուստ և տարբեր էության ներկայացումներ միասին շրջանակներում: Մեր մեթոդը ավելի լավ արդյունքներ է ստանում, քան մրցակցության հիմքերը:', 'bn': 'অনেক প্রাকৃতিক ভাষা প্রক্রিয়া এবং তথ্য পুনরুদ্ধার অ্যাপ্লিকেশনের জন্য বৈশিষ্ট্যের সম্পর্ক মাপ পরিমাপ। প্রাথমিক কাজ প্রায়শই স্টেটিক বৈশিষ্ট্য এবং সংরক্ষিত ভাবে বস্তুর সম্পর্ক গবেষণা করে। তবে বাস্তব বিশ্বের বস্তুগুলো প্রায়শ বিভিন্ন সম্পর্কে জড়িত, যার ফলে সত্যিকার সম্পর্ক বেশ কিছু সময় ধরে খুব বেশী বাস্তবি এই কাজে আমরা একটি নিউরুল নেটওয়ার্ক ভিত্তিক উপায়ের প্রস্তাব করছি যা জনগণের দৃষ্টিভঙ্গি হিসেবে মনোযোগ দেয়। আমাদের মডেল সমৃদ্ধ এবং বিভিন্ন বস্তুর প্রতিনিধিত্ব শিখতে সক্ষম। বিশাল পর্যায়ের পরীক্ষার মাধ্যমে আমরা প্রমাণ করি যে আমাদের পদ্ধতি প্রতিযোগিতা বেসাইনের চেয়ে ভাল ফলাফল অর্জন করে।', 'ca': "La mesura de la relació entre les entitats és una tasca fonamental per a moltes aplicacions naturals de processament de llenguatges i recuperació d'informació. La feina anterior sovint estudia la relació entre les entitats en un entorn estàtic i no supervisada. Tot i així, les entitats del món real sovint estan involucradas en moltes relacions diferents, i conseqüentment les relacions de l'entitat són molt dinàmices al llarg del temps. En aquesta feina, proposem un enfocament basat en la xarxa neural que aprofiti l'atenció pública com a supervisió. El nostre model és capaç d'aprendre representacions rics i diferents d'entitats en un marc conjunt. Amb experiments extensos en conjunts de dades a gran escala, demostrem que el nostre mètode aconsegueix millors resultats que línies de base competitives.", 'cs': 'Měření souvislosti entit je základním úkolem mnoha aplikací pro zpracování přirozeného jazyka a vyhledávání informací. Předchozí práce často studuje souvislost entit v statickém prostředí a bez dohledu. Nicméně entity v reálném světě jsou často zapojeny do mnoha různých vztahů, proto entity vztahy jsou v průběhu času velmi dynamické. V této práci navrhujeme přístup založený na neuronové síti, který využívá pozornost veřejnosti jako dohled. Náš model je schopen učit se bohaté a různé reprezentace entit ve společném rámci. Prostřednictvím rozsáhlých experimentů na rozsáhlých datových sadách ukazujeme, že naše metoda dosahuje lepších výsledků než konkurenční základní linie.', 'bs': 'Obveznost mjerenja subjekta je osnovni zadatak za mnoge prirodne obrade jezika i prijave prikupljanja informacija. Prije posla često proučavaju povezanost subjekta na statičkom stanju i neodređenom načinu. Međutim, entiteti u stvarnom svijetu često se uključuju u mnoge različite odnose, stoga su odnosi entiteta veoma dinamični tijekom vremena. U ovom poslu predlažemo pristup na neuralnoj mreži koji utiče na javnu pažnju kao nadzor. Naš model je sposoban učiti bogate i različite predstave entiteta u zajedničkom okviru. Kroz široke eksperimente na velikim podacima, pokazujemo da naš metod postigne bolji rezultat od konkurentnih osnovnih linija.', 'et': 'Üksuste seotuse mõõtmine on paljude looduskeelte töötlemise ja teabe hankimise rakenduste põhiülesanne. Eelnev töö uurib sageli olemusega seotust staatiliselt ja järelevalveta viisil. Kuid reaalmaailma üksused on sageli seotud paljude erinevate suhetega, seetõttu on üksuste suhted aja jooksul väga dünaamilised. Selles töös pakume välja närvivõrgupõhise lähenemisviisi, mis võimendab avalikku tähelepanu järelevalvena. Meie mudel on võimeline õppima rikkalikke ja erinevaid üksuste esindusi ühises raamistikus. Suuremahuliste andmekogumitega tehtavate laiaulatuslike katsete kaudu näitame, et meie meetod saavutab paremaid tulemusi kui konkurentsivõimelised lähtejooned.', 'fi': 'Yksikön läheisyyden mittaaminen on perustavanlaatuinen tehtävä monissa luonnollisen kielen käsittely- ja tiedonhakusovelluksissa. Aiemmassa työssä tutkitaan usein entiteettisuhdetta staattisesti ja valvomattomasti. Reaalimaailman entiteetit ovat kuitenkin usein mukana monissa erilaisissa suhteissa, joten entiteettisuhteet ovat hyvin dynaamisia ajan mittaan. Tässä työssä ehdotamme neuroverkkopohjaista lähestymistapaa, joka hyödyntää yleistä huomiota valvontana. Mallimme pystyy oppimaan rikkaita ja erilaisia kokonaisuuksia yhteisessä kehyksessä. Suurilla tietoaineistoilla tehtyjen laajojen kokeilujen avulla osoitamme, että menetelmämme tuottaa parempia tuloksia kuin kilpailukykyiset lähtökohdat.', 'sk': 'Merjenje povezanosti subjektov je temeljna naloga za številne aplikacije za obdelavo naravnega jezika in pridobivanje informacij. Predhodno delo pogosto preučuje povezanost z entitetami v statičnem okolju in brez nadzora. Vendar pa so subjekti v realnem svetu pogosto vključeni v različne odnose, zato so odnosi subjektov skozi čas zelo dinamični. V tem delu predlagamo pristop, ki temelji na nevronskem omrežju, ki izkorišča javno pozornost kot nadzor. Naš model je sposoben učiti bogate in različne predstavitve entitet v skupnem okviru. Z obsežnimi eksperimenti na obsežnih naborih podatkov dokazujemo, da naša metoda dosega boljše rezultate od konkurenčnih osnovnih linij.', 'jv': 'Ngubah Entèji Awak dhéwé éntuk digawe hukum saiki, akeh dumadhi kapan-kapan kanggo nguasai perusahaan kuwi mau. Nanging, cah-cah sing karo perusahaan-uwong sing dikondisikno ning akeh liyane karo perusahaan sampeyan, dadi mengko perusahaan kelas dhimik sampek ning aku. Nang barêng-barêng iki, kéné supoyo balêng ngênêmêr kuwi wis ana dadi, nik awak dhéwé kuwi nggawe gerakan kanggo ngilanggar sampek. model kita iso ngejaraké kelas pengguna barêng-barêng lan ngawehi sistem sing sampeyan karo koyok barang. Daftar winih dhéwé éntuk éntuk sistem sing gak nggawe dataset dadi-scale', 'he': 'מידוד יחסיות היחידות הוא משימה יסודית עבור שיעור טבעי רבים ויישומים להחזיר מידע. העבודה הקודמת לעתים קרובות לומדת יחסיות יחסים במצב סטטי ובדרך לא משגיחה. בכל אופן, יחסים בעולם האמיתי לעתים קרובות מעורבים במערכת יחסים שונות רבות, לכן יחסים יחסים של יחסים הם מאוד דינמיים במהלך הזמן. בעבודה הזו, אנו מציעים גישה מבוססת ברשת עצבית שמגבירה תשומת לב ציבורית בתור פיקוח. המודל שלנו מסוגל ללמוד מייצגים של ישויות עשירים ושונים במסגרת משותפת. באמצעות ניסויים רחבים על קבוצות נתונים בקנה מידה גדולה, אנחנו מראים שהשיטה שלנו משיגה תוצאות טובות יותר מאשר קווי בסיס תחרותיים.', 'ha': "Tsarin da aka girmama halin yana da aikin muhimmi wa masu shiryarwa da shiryoyin shiryoyin ayuka masu natsi da masu motsa. Kayyar aikin da aka karɓi karɓi karatun karatun halin a matsayin static da ba'a tsare shi ba. A'aha, da haka, ma'abubuwa masu cikin duniya gaskiyar ko da yawa suke cikin mazaunin dabam-dabam, sabõda haka, mazaunin abubuwa sun kasance mai fara a tsakanin lokaci. A cikin wannan aikin, Munã buɗa wata hanyoyi a kan jerin neural wanda ke samar da umarni kamar makini. MisalinMu yana iya iya iya iya sanar da masu matajiri da wasu abubuwa dabam cikin wani firam mai haɗa. Ga jarrabai masu faɗi a kan database masu girma, za mu nuna cewa hanyonmu za'a sãmu mafiya alhẽri ga matsayi daga misalin basin da ke yin ta'ana.", 'bo': 'དང་འབྲེལ་མཐུད་ཚད་གཅིག་མཚུངས་ནི་རང་རུང་སྐད་སྒྲིག་འགོད་དང་ཆ་འཕྲིན་ལེན་པའི་ཉེར་སྤྱོད སྔོན་ལྗོངས་ཀྱི་ལས་འགུལ་རྒྱུན་ལྟར་སྒྲིག་འཛུགས་དང་མི་རྣམས་ཀྱི་བཟོ་བརྟན་པར་མཐུན་འབྲེལ་བ་ཡིན་པ། འོན་ཀྱང་། འཇིག་རྟེན་དང་མི་འདྲ་བའི་རྒྱུ་མཚན་ནི་འབྲེལ་བ་སོ་སོ་སོ་སོའི་ནང་དུ་འབྲེལ་བ་མང་པོ་ཞིག་ཡིན། དབུལ་དང་འབྲེལ་བ འུ་ཅག་གིས་ལས་ཀ་འདིའི་ནང་དུ་ང་ཚོས་རང་ཉིད་དྲ་རྒྱ་སྤྲོད་ཀྱི་ཐབས་ལམ་ལ་བསམ་བློ་གཏོང་དང་། ང་ཚོའི་མ་དབྱིབས་གཞུང་གིས་མཐུན་སྒྲིག་གཞུང་གཅིག་གི་མཐུན་རྐྱེན་དང་དབུགས་མ་འདྲ་བ་ཤེས་ཀྱི་ཡོད། ང་ཚོའི་ཐབས་ལམ་གྱིས་རྐྱེན་འབྲེལ་བ་མང་ཆེ་བའི་བརྟག་ཞིག་བྱས་ནས་མཐུན་རྐྱེན་གྱི་གཞི་རྟེན་འདི་ལས་ཉེན'}
{'en': 'A Unified Neural Network Model for Geolocating Twitter Users', 'es': 'Un modelo de red neuronal unificada para geolocalizar a los usuarios de Twitter', 'pt': 'Um modelo de rede neural unificada para geolocalização de usuários do Twitter', 'fr': 'Un modèle de réseau neuronal unifié pour géolocaliser les utilisateurs de Twitter', 'ar': 'نموذج شبكة عصبية موحدة لتحديد الموقع الجغرافي لمستخدمي تويتر', 'ja': 'Twitterユーザーをジオロケーションするための統一されたニューラルネットワークモデル', 'zh': '以 Twitter 用户地理定位神经网络一', 'hi': 'Geolocating चहचहाना उपयोगकर्ताओं के लिए एक एकीकृत तंत्रिका नेटवर्क मॉडल', 'ru': 'Унифицированная модель нейронной сети для геолокации пользователей Twitter', 'ga': 'Samhail Líonra Néarach Aontaithe chun Úsáideoirí Twitter a Gheolonnú', 'ka': 'Name', 'el': 'Ένα ενοποιημένο μοντέλο νευρωνικού δικτύου για τον γεωεντοπισμό χρηστών του Twitter', 'hu': 'Egységes neurális hálózati modell a Twitter felhasználók geolokalizálásához', 'kk': 'Name', 'it': 'Un modello di rete neurale unificato per geolocalizzare gli utenti Twitter', 'lt': 'Name', 'mk': 'Унифициран модел на неурална мрежа за геолокација на корисниците на Твитер', 'ms': 'Name', 'ml': 'Name', 'mn': 'Geolocating Twitter хэрэглэгчдийн нэгдсэн мэдрэлийн сүлжээний загвар', 'no': 'Name', 'pl': 'Ujednolicony model sieci neuronowej do geolokalizacji użytkowników Twittera', 'ro': 'Un model unificat de rețea neurală pentru geolocalizarea utilizatorilor Twitter', 'sr': 'Jednostavni model Neuralne mreže za geolokaciju korisnika Twitter-a', 'si': 'Name', 'so': 'Model of the Unified Neural Network for Geolocating Twitter Users', 'sv': 'En enhetlig neural nätverksmodell för geolokalisering av Twitter-användare', 'ta': 'Name', 'ur': 'Name', 'mt': 'Mudell Unifikat tan-Netwerk Newrali għall-Ġeolokazzjoni tal-Utenti tat-Twitter', 'uz': 'Name', 'vi': 'Mô hình mạng thần kinh bất hợp cho người dùng định vị Twitter', 'bg': 'Унифициран модел на неврална мрежа за геолокализиране на потребителите в Туитър', 'nl': 'Een uniform neuronaal netwerkmodel voor het geolokaliseren van Twitter-gebruikers', 'hr': 'Jediničan model neuromreže za geolokaciju korisnika Twitter-a', 'da': 'En forenet neural netværksmodel til geolokalisering af Twitter-brugere', 'de': 'Ein einheitliches neuronales Netzwerkmodell zur Geolokalisierung von Twitter-Nutzern', 'id': 'Model Jaringan Neural Unified untuk Pengguna Twitter Geolokasi', 'fa': 'Name', 'ko': '트위터 사용자 지리적 포지셔닝의 통일 신경 네트워크 모델', 'sw': 'Mtandao wa Mtandao wa Neural wa Utumiaji wa Twita wa Geolocating', 'af': 'Name', 'sq': 'Name', 'tr': 'Twitter Ullançylary üçin Birleşik Närally A ç Modeli', 'am': 'Name', 'hy': 'Comment', 'bn': 'টুইটার ব্যবহারকারীদের জন্য একটি একত্রিত নিউরাল নেটওয়ার্ক মডেল', 'bs': 'Jediničan model Neuralne mreže za geolokaciju korisnika Twitter-a', 'ca': 'Un model unificat de xarxa neuronal per localitzar geolàsticament els usuaris de Twitter', 'az': 'Twitter istifadəçiləri Geolocation üçün Birleşik Nöral A ğ Modeli', 'cs': 'Jednotný model neuronové sítě pro geolokaci uživatelů Twitteru', 'fi': 'Yhtenäinen hermoverkkomalli Twitter-käyttäjien paikantamiseen', 'et': 'Ühtne neurovõrgu mudel Twitteri kasutajate asukoha määramiseks', 'jv': 'Sambol Néural Network Unify kanggo Kebebasan pengguna Google', 'he': 'Name', 'ha': '@ action', 'sk': 'Enotni model nevralnega omrežja za geolokacijo uporabnikov Twitterja', 'bo': 'Twitter ལག་ལེན་པ་སྤྱོད་མཁན་ལ་སྤྱད་ནས་དབུགས་མཐུན་གྱི་མ་དབུགས'}
{'en': 'Locations of social media users are important to many applications such as rapid disaster response, ', 'es': 'La ubicación de los usuarios de redes sociales es importante para muchas aplicaciones, como la respuesta rápida ante desastres, la publicidad dirigida y la recomendación de noticias. Sin embargo, muchos usuarios no comparten sus coordenadas geográficas exactas por motivos tales como problemas de privacidad. La falta de información de ubicación explícita ha motivado un creciente número de investigaciones en los últimos años que buscan diferentes formas automáticas de determinar la ubicación principal del usuario. En este artículo, proponemos un método de geolocalización de usuarios unificado que se basa en una fusión de redes neuronales. Nuestro modelo conjunto incorpora diferentes tipos de información disponible, incluidos el texto del tweet, la red de usuarios y los metadatos para predecir la ubicación de los usuarios. Además, utilizamos una red LSTM bidireccional aumentada con un mecanismo de atención para identificar las palabras más indicativas de ubicación en el contenido textual de los tuits. Los experimentos demuestran que nuestro enfoque logra un rendimiento de vanguardia en dos conjuntos de datos de geolocalización de referencia de Twitter. También realizamos un estudio de ablación para evaluar la contribución de cada tipo de información en el rendimiento de la geolocalización de los usuarios.', 'ar': 'تعد مواقع مستخدمي الوسائط الاجتماعية مهمة للعديد من التطبيقات مثل الاستجابة السريعة للكوارث والإعلان المستهدف والتوصية الإخبارية. ومع ذلك ، لا يشارك العديد من المستخدمين إحداثياتهم الجغرافية الدقيقة لأسباب مثل مخاوف الخصوصية. حفز الافتقار إلى معلومات واضحة عن الموقع مجموعة متزايدة من الأبحاث في السنوات الأخيرة تبحث في طرق تلقائية مختلفة لتحديد الموقع الأساسي للمستخدم. في هذا البحث ، نقترح طريقة موحدة لتحديد الموقع الجغرافي للمستخدم تعتمد على اندماج الشبكات العصبية. يشتمل نموذجنا المشترك على أنواع مختلفة من المعلومات المتاحة بما في ذلك نص التغريدة وشبكة المستخدم والبيانات الوصفية للتنبؤ بمواقع المستخدمين. علاوة على ذلك ، نحن نستخدم شبكة LSTM ثنائية الاتجاه معززة بآلية انتباه لتحديد الكلمات الأكثر دلالة للموقع في المحتوى النصي للتغريدات. توضح التجارب أن نهجنا يحقق أداءً متطورًا على مجموعتي بيانات معياريتين لتحديد الموقع الجغرافي على تويتر. نجري أيضًا دراسة اجتثاث لتقييم مساهمة كل نوع من المعلومات في أداء تحديد الموقع الجغرافي للمستخدم.', 'fr': "L'emplacement des utilisateurs des réseaux sociaux est important pour de nombreuses applications, telles que la réponse rapide aux catastrophes, la publicité ciblée et les recommandations d'actualités. Cependant, de nombreux utilisateurs ne partagent pas leurs coordonnées géographiques exactes pour des raisons telles que des problèmes de confidentialité. Le manque d'informations de localisation explicites a motivé un nombre croissant de recherches au cours des dernières années sur différentes méthodes automatiques de détermination de l'emplacement principal de l'utilisateur. Dans cet article, nous proposons une méthode unifiée de géolocalisation des utilisateurs qui repose sur une fusion de réseaux neuronaux. Notre modèle commun intègre différents types d'informations disponibles, y compris le texte des tweets, le réseau utilisateur et les métadonnées pour prédire l'emplacement des utilisateurs. De plus, nous utilisons un réseau LSTM bidirectionnel augmenté d'un mécanisme d'attention pour identifier les mots les plus indicatifs de localisation dans le contenu textuel des tweets. Les expériences démontrent que notre approche atteint des performances de pointe sur deux ensembles de données de géolocalisation de référence Twitter. Nous menons également une étude d'ablation afin d'évaluer la contribution de chaque type d'information aux performances de géolocalisation des utilisateurs.", 'pt': 'As localizações dos usuários de mídia social são importantes para muitas aplicações, como resposta rápida a desastres, propaganda direcionada e recomendação de notícias. No entanto, muitos usuários não compartilham suas coordenadas geográficas exatas devido a motivos como preocupações com a privacidade. A falta de informações de localização explícitas motivou um crescente corpo de pesquisas nos últimos anos, procurando diferentes formas automáticas de determinar a localização primária do usuário. Neste artigo, propomos um método unificado de geolocalização de usuários que se baseia em uma fusão de redes neurais. Nosso modelo conjunto incorpora diferentes tipos de informações disponíveis, incluindo texto de tweets, rede de usuários e metadados para prever a localização dos usuários. Além disso, utilizamos uma rede LSTM bidirecional aumentada com um mecanismo de atenção para identificar as palavras mais indicativas de localização no conteúdo textual dos tweets. Os experimentos demonstram que nossa abordagem alcança desempenho de última geração em dois conjuntos de dados de geolocalização de referência do Twitter. Também realizamos um estudo de ablação para avaliar a contribuição de cada tipo de informação no desempenho da geolocalização do usuário.', 'ja': 'ソーシャルメディアユーザーの位置は、迅速な災害対応、ターゲット広告、ニュース推奨などの多くのアプリケーションにとって重要です。 ただし、プライバシー上の懸念などの理由により、正確な地理座標を共有していないユーザーも多い。 明確な位置情報の欠如は、近年、ユーザーの主要な位置を決定するさまざまな自動方法を調べる研究の機会を増やしている。 本稿では、ニューラルネットワークの融合に依存した統一されたユーザジオロケーション法を提案する。 当社の共同モデルには、ツイートテキスト、ユーザーネットワーク、ユーザーの位置を予測するためのメタデータなど、さまざまな種類の利用可能な情報が組み込まれています。 さらに、注意メカニズムで拡張された双方向LSTMネットワークを利用して、ツイートのテキストコンテンツ内の最も位置を示す単語を識別する。 実験は、当社のアプローチが2つのTwitterベンチマークの地理的位置データセットで最先端のパフォーマンスを達成していることを示しています。 また、ユーザーの地理的位置情報パフォーマンスにおける各種情報の寄与を評価するためのアブレーション調査も実施しています。', 'ru': 'Расположение пользователей социальных сетей важно для многих приложений, таких как быстрое реагирование на стихийные бедствия, целевая реклама и рекомендации по новостям. Однако многие пользователи не сообщают свои точные географические координаты по таким причинам, как соображения конфиденциальности. Отсутствие четкой информации о местонахождении побудило в последние годы все большее число исследователей искать различные автоматические способы определения основного местонахождения пользователя. В этой статье мы предлагаем унифицированный пользовательский метод геолокации, который основан на слиянии нейронных сетей. Наша совместная модель включает в себя различные типы доступной информации, включая текст твита, пользовательскую сеть и метаданные для прогнозирования местоположения пользователей. Кроме того, мы используем двунаправленную сеть LSTM, дополненную механизмом внимания, чтобы определить наиболее ориентировочные слова местоположения в текстовом содержании твитов. Эксперименты показывают, что наш подход достигает самых современных показателей в двух базовых наборах данных геолокации Twitter. Мы также проводим исследование абляции для оценки вклада каждого типа информации в производительность геолокации пользователя.', 'zh': '社交媒体用户位多应用程序(速难响应,有针对性告新闻荐)甚重。 然以隐私之故,多用户不共其理坐标。 阙明位而促近岁,求定用户之要术。 于本文中,立一赖于神经网络融用户地理之术。 吾合而信之,推文本、用户网络、元数,以占用户位。 此外因双向LSTM网络增强注意机以识推文本最为位指性之单词。 实验明两Twitter准地理数集上致先进之性。 又加研究,以质用户地之献。', 'hi': 'सोशल मीडिया उपयोगकर्ताओं के स्थान कई अनुप्रयोगों के लिए महत्वपूर्ण हैं जैसे कि तेजी से आपदा प्रतिक्रिया, लक्षित विज्ञापन और समाचार सिफारिश। हालांकि, कई उपयोगकर्ता गोपनीयता चिंताओं जैसे कारणों के कारण अपने सटीक भौगोलिक निर्देशांक साझा नहीं करते हैं। स्पष्ट स्थान जानकारी की कमी ने हाल के वर्षों में उपयोगकर्ता के प्राथमिक स्थान को निर्धारित करने के विभिन्न स्वचालित तरीकों को देखते हुए अनुसंधान के बढ़ते शरीर को प्रेरित किया है। इस पेपर में, हम एक एकीकृत उपयोगकर्ता जियोलोकेशन विधि का प्रस्ताव करते हैं जो तंत्रिका नेटवर्क के संलयन पर निर्भर करता है। हमारे संयुक्त मॉडल में उपयोगकर्ताओं के स्थानों की भविष्यवाणी करने के लिए ट्वीट टेक्स्ट, उपयोगकर्ता नेटवर्क और मेटाडेटा सहित विभिन्न प्रकार की उपलब्ध जानकारी शामिल है। इसके अलावा, हम tweets की पाठ्य सामग्री में सबसे अधिक स्थान संकेतक शब्दों की पहचान करने के लिए एक ध्यान तंत्र के साथ संवर्धित एक द्विदिश LSTM नेटवर्क का उपयोग करते हैं। प्रयोगों से पता चलता है कि हमारा दृष्टिकोण दो ट्विटर बेंचमार्क जियोलोकेशन डेटासेट पर अत्याधुनिक प्रदर्शन प्राप्त करता है। हम उपयोगकर्ता जियोलोकेशन प्रदर्शन में प्रत्येक प्रकार की जानकारी के योगदान का मूल्यांकन करने के लिए एक एब्लेशन अध्ययन भी करते हैं।', 'ga': 'Tá suíomhanna úsáideoirí meán sóisialta tábhachtach do go leor feidhmchlár ar nós freagairt tapa ar thubaistí, fógra spriocdhírithe, agus moladh nuachta. Mar sin féin, ní roinneann go leor úsáideoirí a gcuid comhordanáidí geografacha cruinne mar gheall ar chúiseanna ar nós imní príobháideachta. Tá an easpa faisnéise sainráite faoi shuíomh tar éis fás a spreagadh le taighde a dhéanamh le blianta beaga anuas chun féachaint ar bhealaí éagsúla uathoibríocha chun suíomh príomhúil an úsáideora a chinneadh. Sa pháipéar seo, molaimid modh geolocation aontaithe úsáideora a bhraitheann ar chomhcheangal de líonraí néaracha. Ionchorpraíonn ár gcomhshamhail cineálacha éagsúla faisnéise atá ar fáil lena n-áirítear téacs tweet, líonra úsáideoirí, agus meiteashonraí chun suíomhanna úsáideoirí a thuar. Ina theannta sin, bainimid úsáid as líonra déthreorach LSTM arna bhreisiú le meicníocht aird chun na focail is mó a léiríonn suímh in ábhar téacs tweets a shainaithint. Léiríonn na turgnaimh go mbaineann ár gcur chuige feidhmíocht den scoth amach thar dhá thacar sonraí geolocation tagarmhairc Twitter. Déanaimid staidéar eisláithriúcháin freisin chun an méid a chuireann gach cineál faisnéise le feidhmíocht geolocation an úsáideora a mheas.', 'ka': 'სოციალური მედია მომხმარების ადგილებები მნიშვნელოვანია მრავალური პროგრამებისთვის, როგორც ძალიან ბრძნელი განახლება, მინიშვნელოვანი reklaმისთვის და ახა მაგრამ, ბევრი მომხმარებელი მათი გეგოგოფიკალური კოორდინაციების განმავლობაში არ გაყოფილი, რადგან საკუთარი მიზეზები, როგორც პირადიურ მხოლოდ წლის განსხვავებული ადგილური ინფორმაციის არსებობა მოტივირთეთ გავაკეთებული სხვა ავტომატიკური გზები, რომელიც მომხმარებლის პირველი ადგილური ადგილზე განსაზღვრე ჩვენ ამ წიგნაში ერთადერთი მომხმარებელი გეოლოკაციის მეტი, რომელიც ნეიროლური ქსელების ფუზიციაზე დარწმდება. ჩვენი ერთადერთი მოდელში განსხვავებული ხელსაწყობინებული ინფორმაციის ტიპები, როგორც tweet ტექსტი, გამოყენებელი ქსელი და მეტადატატატატატატატი. დამატებით, ჩვენ გამოვიყენებთ ბიდერექციონალური LSTM ქსელი, რომელიც აღმოქმენტირებულია აღმოქმენტირებული აღმოქმენტირებულია, რომ ტექსტულური შემდგომარებულ ექსპერიმენტები გამოჩვენებენ, რომ ჩვენი პროგრამის შესაძლებლობა გავაკეთებს სახელსაწყისი სახელსაწყისი ექსპერიმენტის ეზოლოკაციის სახელსაწყის ჩვენ ასევე გავაკეთებთ წარმოდგენის სწავლა, რომ ყველა ტიპის ინფორმაციის დამატებით გამოყენებელი გეოლოკაციის მუშაობაში.', 'hu': 'A közösségi média felhasználóinak helye fontos számos alkalmazás számára, mint például a gyors katasztrófaválasz, a célzott hirdetés és a hírek ajánlása. Sok felhasználó azonban nem osztja meg pontos földrajzi koordinátáit olyan okok miatt, mint az adatvédelmi aggályok. A kifejezett helyszíni információk hiánya az elmúlt években egyre növekvő kutatásokat indított, amelyek különböző automatikus módszereket vizsgálnak a felhasználó elsődleges helyszínének meghatározására. Ebben a tanulmányban egy egységes felhasználói geolokációs módszert javasolunk, amely a neurális hálózatok fúzióján alapul. Közös modellünk különböző típusú rendelkezésre álló információkat tartalmaz, beleértve a tweet szöveget, a felhasználói hálózatot és a metaadatokat a felhasználók helyének előrejelzéséhez. Továbbá egy kétirányú LSTM hálózatot használunk figyelemmel kiegészített mechanizmussal, hogy azonosítsuk a tweetek szöveges tartalmában a legtöbb helyszínindikatív szavakat. A kísérletek azt mutatják, hogy megközelítésünk a legkorszerűbb teljesítményt ér el két Twitter referenciaadatkészlet felett. Egy ablációs tanulmányt is végezünk annak érdekében, hogy értékeljük az egyes típusú információk hozzájárulását a felhasználók földrajzi helymeghatározási teljesítményében.', 'el': 'Οι τοποθεσίες των χρηστών των μέσων κοινωνικής δικτύωσης είναι σημαντικές για πολλές εφαρμογές, όπως η ταχεία αντιμετώπιση καταστροφών, η στοχευμένη διαφήμιση και η σύσταση ειδήσεων. Ωστόσο, πολλοί χρήστες δεν μοιράζονται τις ακριβείς γεωγραφικές τους συντεταγμένες για λόγους όπως ανησυχίες για το απόρρητο. Η έλλειψη σαφών πληροφοριών τοποθεσίας έχει παρακινήσει ένα αυξανόμενο σώμα έρευνας τα τελευταία χρόνια εξετάζοντας διαφορετικούς αυτόματους τρόπους προσδιορισμού της αρχικής θέσης του χρήστη. Στην παρούσα εργασία, προτείνουμε μια ενοποιημένη μέθοδο γεωεντοπισμού χρηστών που βασίζεται στη συγχώνευση νευρωνικών δικτύων. Το κοινό μας μοντέλο ενσωματώνει διαφορετικούς τύπους διαθέσιμων πληροφοριών, όπως κείμενο tweet, δίκτυο χρηστών και μεταδεδομένα για να προβλέψει τις τοποθεσίες των χρηστών. Επιπλέον, χρησιμοποιούμε ένα αμφίδρομο δίκτυο εμπλουτισμένο με έναν μηχανισμό προσοχής για να εντοπίσουμε τις πιο ενδεικτικές λέξεις θέσης στο κείμενο των tweets. Τα πειράματα καταδεικνύουν ότι η προσέγγισή μας επιτυγχάνει υπερσύγχρονες επιδόσεις πάνω από δύο σύνολα γεωεντοπισμού αναφοράς του Twitter. Επίσης διεξάγουμε μια μελέτη αφαίρεσης για να αξιολογήσουμε τη συμβολή κάθε τύπου πληροφοριών στην απόδοση γεωεντοπισμού χρηστών.', 'lt': 'Socialinės žiniasklaidos naudotojų vietos yra svarbios daugeliui taikomųjų programų, pavyzdžiui, greitai reaguojant į nelaimes, tikslinė reklama ir naujienų rekomendacijos. Tačiau daugelis naudotojų dėl tokių priežas čių kaip privatumo klausimai nesutinka su tiksliomis geografinėmis koordinatėmis. Nesant aiškios informacijos apie vietą, pastaraisiais metais vis daugiau mokslinių tyrimų ėmėsi nagrinėti skirtingus automatinius būdus, kaip nustatyti pagrindinę naudotojo vietą. Šiame dokumente siūlome vieningą naudotojo geolokacijos metodą, kuris grindžiamas nervinių tinklų sinteze. Mūsų bendrame modelyje pateikiama įvairių tipų turima informacija, įskaitant tweeto tekstą, naudotojų tinklą ir metaduomenis naudotojų vietoms prognozuoti. Be to, mes naudojame dvikryptį LSTM tinklą, papildytą dėmesio mechanizmu, siekiant nustatyti labiausiai orientacinius žodžius, esančius tekstiniame tweetų turinyje. Eksperimentai rodo, kad mūsų požiūris pasiekia naujausius rezultatus per du Twitter lyginamuosius geolokacijos duomenų rinkinius. We also conduct an ablation study to evaluate the contribution of each type of information in user geolocation performance.', 'it': "Le posizioni degli utenti dei social media sono importanti per molte applicazioni come risposta rapida alle catastrofi, pubblicità mirata e raccomandazioni di notizie. Tuttavia, molti utenti non condividono le loro coordinate geografiche esatte a causa di motivi come problemi di privacy. La mancanza di informazioni esplicite sulla posizione ha motivato un crescente corpus di ricerca negli ultimi anni guardando a diversi modi automatici di determinare la posizione primaria dell'utente. In questo articolo, proponiamo un metodo unificato di geolocalizzazione degli utenti che si basa su una fusione di reti neurali. Il nostro modello comune incorpora diversi tipi di informazioni disponibili tra cui testo di tweet, rete utente e metadati per prevedere la posizione degli utenti. Inoltre, utilizziamo una rete LSTM bidirezionale arricchita da un meccanismo di attenzione per identificare le parole indicative più localizzate nei contenuti testuali dei tweet. Gli esperimenti dimostrano che il nostro approccio raggiunge prestazioni all'avanguardia su due set di dati di geolocalizzazione di riferimento Twitter. Conduciamo anche uno studio di ablazione per valutare il contributo di ogni tipo di informazione nelle prestazioni di geolocalizzazione degli utenti.", 'mk': 'Локациите на корисниците на социјалните медиуми се важни за многу апликации, како што се брзиот одговор на катастрофите, насочена реклама и препорака за вести. Сепак, многу корисници не ги делат нивните точни географски координати поради причини како што се загриженоста за приватноста. Недостатокот на експлицитни информации за локацијата мотивираше растечко тело на истражување во последниве години, барајќи различни автоматски начини за одредување на примарната локација на корисникот. Во овој весник предлагаме единствен метод на геолокација на корисникот кој се потпира на фузија на невровните мрежи. Нашиот заеднички модел вклучува различни видови на достапни информации вклучувајќи твит текст, корисничка мрежа и метададани за предвидување на локациите на корисниците. Покрај тоа, употребуваме дворечна мрежа на ЛСТМ зголемена со механизам на внимание за идентификување на најлокационалните индикативни зборови во текстуалната содржина на твитови. Експериментите демонстрираат дека нашиот пристап постигнува најдобра резултат преку два геолокациски набори на Твитер. Ние, исто така, спроведуваме аплациска студија за проценка на придонесот на секој вид информации во резултатите на геолокацијата на корисникот.', 'ms': 'Lokasi pengguna media sosial penting untuk banyak aplikasi seperti balas bencana cepat, iklan sasaran, dan rekomendasi berita. Namun, banyak pengguna tidak berkongsi koordinat geografik tepat mereka disebabkan sebab seperti masalah privasi. Kekurangan maklumat lokasi eksplicit telah mendorong tubuh penelitian yang meningkat dalam tahun-tahun terakhir melihat cara-cara automatik berbeza untuk menentukan lokasi utama pengguna. In this paper, we propose a unified user geolocation method which relies on a fusion of neural networks.  Model kongsi kami mengandungi jenis-jenis maklumat yang tersedia termasuk teks tweet, rangkaian pengguna, dan metadata untuk meramalkan lokasi pengguna. Selain itu, kami menggunakan rangkaian LSTM bidireksi ditambah dengan mekanisme perhatian untuk mengenalpasti perkataan yang paling menunjukkan lokasi dalam kandungan teks tweet. Eksperimen menunjukkan bahawa pendekatan kita mencapai prestasi state-of-the-art melalui dua set data geolokasi tanda referensi Twitter. Kami juga melakukan kajian ablasi untuk menilai kontribusi setiap jenis maklumat dalam prestasi geolokasi pengguna.', 'kk': 'Социалдық медиа пайдаланушыларының орналасуы көптеген қолданбаларға, мысалы, жылдам жағдайлардың жауап беру, мақсатты reklam және жаңалық рекомендациясы. Бірақ көпшілік пайдаланушылар өзінің географиялық координаттарын өзінің жалпы қатынасы сияқты себептерінің себептеріне бөлмейді. Түсінікті мәлімет жоқ, соңғы жылдарда, пайдаланушының негізгі орналасуын анықтау әртүрлі автоматты түрде қарастыру үшін зерттеулердің денесін түсіндіреді. Бұл қағаздың біріктірілген пайдаланушылардың географиялық әдісін таңдаймыз. Бұл невралдық желілерді біріктіру әдісі. Біздің жалпы моделіміз пайдаланушылардың орналасуын таңдау үшін tweet мәтіні, пайдаланушылардың желі және мета деректерін басқа түрлері бар. Сонымен қатар, жазулардың текстік мазмұнындағы ең көрсетілетін орналасатын сөздерді таңдау үшін қолданатын LSTM желігін қолданып қолданамыз. Твиттердің екі бағдарламалардың географиялық деректер қорларына қатынасыз керек дегенді көрсетеді. Сонымен қатар, пайдаланушылардың географиялық жұмысындағы әрбір түрлі мәліметтердің қатынасын бағалау үшін жұмыс істеу зерттеуді істейміз.', 'ml': 'സാമൂഹ്യ മീഡിയ ഉപയോക്താക്കളുടെ സ്ഥലങ്ങള്\u200d പ്രയോഗങ്ങള്\u200dക്ക് പ്രധാനപ്പെട്ട പ്രയോഗങ്ങള്\u200dക്ക്, വേഗം ദുരിതവിപത്ത എന്നാലും സ്വകാര്യ വിചാരങ്ങള്\u200d പോലുള്ള കാരണങ്ങള്\u200dക്കായി പല ഉപയോക്താക്കളും അവരുടെ ഗ്രോഗ്രാഫിക്കല്\u200d കൂട്ടത്തില്\u200d  പ്രത്യക്ഷമായ സ്ഥലത്തിന്റെ വിവരങ്ങളുടെ കുറവ്, അടുത്ത വര്\u200dഷങ്ങളില്\u200d വ്യത്യസ്ത സ്വയം നിര്\u200dണയിക്കുന്ന ഉപയോക്താവിന്റെ പ്രധാനസ്ഥാന ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഒരു യൂണിക്കപ്പെട്ട ഉപയോക്താവിന്റെ ജോയിസ്റ്റേഷന്\u200d രീതിയില്\u200d ആശ്രയിക്കുന്ന പുരുഷന്\u200d ന ഞങ്ങളുടെ യൂട്ട് മോഡല്\u200d വ്യത്യസ്ത തരം വിവരങ്ങള്\u200d ലഭ്യമാക്കുന്നു. ട്രെയിറ്റ് ടെക്സ്റ്റ്, ഉപയോക്താവിന്റെ സ്ഥലങ്ങള്\u200d പ് Moreover, we utilize a bidirectional LSTM network augmented with an attention mechanism to identify the most location indicative words in textual content of tweets.  ഈ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ സമ്പാദ്യം രണ്ടു ട്രൂട്ടര്\u200d ബെങ്ക്മാര്\u200dക്ക് ജോവിസ്റ്റേഷന്\u200d ഡാറ്റാസെറ് ഉപയോക്താവിന്റെ ജോയിസ്റ്റേഷന്\u200d പ്രവര്\u200dത്തനത്തിലുള്ള എല്ലാ തരം വിവരങ്ങളുടെയും ഭാഗത്തിന്റെയും വിവരങ്ങള്\u200d വി', 'mt': 'Il-postijiet tal-utenti tal-midja soċjali huma importanti għal ħafna applikazzjonijiet bħal reazzjoni rapida għad-diżastri, reklamar immirat, u rakkomandazzjoni għall-aħbarijiet. Madankollu, ħafna utenti ma jaqsmux il-koordinati ġeografiċi eżatti tagħhom minħabba raġunijiet bħal tħassib dwar il-privatezza. In-nuqqas ta’ informazzjoni espliċita dwar il-post immotivat korp dejjem jikber ta’ riċerka f’dawn l-a ħħar snin li ħares lejn modi awtomatiċi differenti biex jiġi ddeterminat il-post primarju tal-utent. F’dan id-dokument, qed nipproponu metodu unifikat tal-ġeolokazzjoni tal-utenti li jiddependi fuq fużjoni ta’ netwerks newrali. Il-mudell konġunt tagħna jinkorpora tipi differenti ta’ informazzjoni disponibbli inkluż it-test fuq it-tweet, in-netwerk tal-utenti, u l-metadejta biex jipprevedu l-postijiet tal-utenti. Barra minn hekk, a ħna nużaw netwerk ta’ LSTM bidirezzjonali miżjud b’mekkaniżmu ta’ attenzjoni biex nidentifikaw l-aktar kliem indikattiv fil-post fil-kontenut testwali tat-tweets. L-esperimenti juru li l-approċċ tagħna jikseb prestazzjoni l-aktar avvanzata fuq żewġ settijiet ta’ dejta ta’ referenza ta’ Twitter dwar il-ġeolokazzjoni. Sar ukoll studju dwar l-abblazzjoni biex tiġi evalwata l-kontribuzzjoni ta’ kull tip ta’ informazzjoni fil-prestazzjoni tal-ġeolokazzjoni tal-utent.', 'mn': 'Нийгмийн мэдээллийн хэрэглэгчдийн байр суурь нь маш олон хэрэглэгчдэд чухал. Яг олон хэрэглэгчдэд маш хурдан гамшгийн хариу үйлдэл, зориулсан реклам, мэдээллийн зөвлөл. Гэхдээ ихэнх хэрэглэгчид өөрсдийн газрын координатуудыг хуваалцахгүй. Хувь амьдралын асуудал шиг шалтгаан учраас. Тодорхой байр суурь мэдээлэл байхгүй байдал сүүлийн жилүүдэд хэрэглэгчийн анхны байр суурь тодорхойлох өөр өөр өөр арга замаар ажиллаж байгааг урам зориулсан. Энэ цаасан дээр бид мэдрэлийн сүлжээнд хамааралтай нэгдсэн хэрэглэгчийн географийн байрлал загварыг сануулдаг. Бидний холбоотой загвар нь хэрэглэгчийн байрлалыг таамаглах үед tweet текст, хэрэглэгчийн сүлжээ, мета өгөгдлийг олон төрлийн мэдээллүүдийг бүрдүүлдэг. Үүнээс гадна бид бичлэгийн бичлэгийн бүтээгдэхүүний хамгийн илэрхийлэлтэй үгийг тайлбарлах боломжтой анхаарлын механизмээр нэмэгдүүлсэн LSTM сүлжээг ашиглаж байна. Тэдгээр туршилтууд бидний арга хэмжээний үйл ажиллагааг Твиттерийн хоёр банкны географийн өгөгдлийн санд гаргадаг гэдгийг харуулдаг. Бид мөн хэрэглэгчийн географийн үйл ажиллагаанд хэрэглэгчийн географийн үйл ажиллагааны үр дүнг үнэлэх боломжтой судалгаа хийдэг.', 'no': 'Plasseringar av sosiale mediabrukarar er viktig for mange program, slik som rask katastrofisk reaksjon, målt reklame og nyhetsverking. Men mange brukarar deler ikkje dei nøyaktige geografiske koordinatene på grunn av grunnene som privatspørsmål. Manglansen av eksplisitt plasseringsinformasjon har motivert ein økende forskningskropp i løpet av dei siste åra å sjå på ulike automatiske måtar å avgjera primærplasseringa til brukaren. I denne papiret foreslår vi ein einaste brukergeoplasseringsmetode som dependerer på ein fusjon av neiralnettverk. Det samlede modellet vår inneheld ulike typar tilgjengelege informasjon, inkludert tweetetekst, brukarnettverk og metadata for å forhåndsvisa stader for brukarar. I tillegg bruker vi eit bidireksjonal LSTM-nettverk som er auka med ein oppmerksmekanisme for å identifisera dei mest plasseringsordene i tekstinnhaldet av tweeter. Eksperimentane viser at tilnærminga vårt når det gjer tilstanden til kunsten over to datasett for Twitter-benchmark geoplassering. Vi gjer også ein aktiveringsstudie for å evaluera bidragen av kvar type informasjon i brukargeoplasseringsfunksjonen.', 'pl': 'Lokalizacje użytkowników mediów społecznościowych są ważne dla wielu aplikacji, takich jak szybkie reagowanie na katastrofy, ukierunkowane reklamy i rekomendacje wiadomości. Jednak wielu użytkowników nie udostępnia dokładnych współrzędnych geograficznych ze względów takich jak obawy o prywatność. Brak wyraźnych informacji o lokalizacji zmotywował w ostatnich latach coraz większą liczbę badań nad różnymi automatycznymi sposobami określenia głównej lokalizacji użytkownika. W niniejszym artykule proponujemy ujednoliconą metodę geolokalizacji użytkowników, która opiera się na fuzji sieci neuronowych. Nasz wspólny model obejmuje różne rodzaje dostępnych informacji, w tym tekst tweeta, sieć użytkowników i metadane, aby przewidzieć lokalizację użytkowników. Ponadto wykorzystujemy dwukierunkową sieć LSTM rozszerzoną o mechanizm uwagi, aby zidentyfikować najbardziej lokalizacyjne słowa orientacyjne w treści tekstowej tweetów. Eksperymenty pokazują, że nasze podejście osiąga najnowocześniejszą wydajność w stosunku do dwóch zestawów danych geolokalizacyjnych Twittera. Przeprowadzamy również badanie ablacji w celu oceny wkładu każdego rodzaju informacji w wydajność geolokalizacji użytkowników.', 'ro': 'Locațiile utilizatorilor rețelelor de socializare sunt importante pentru multe aplicații, cum ar fi răspunsul rapid la dezastre, publicitatea direcționată și recomandările de știri. Cu toate acestea, mulți utilizatori nu își împărtășesc coordonatele geografice exacte din motive precum preocupările legate de confidențialitate. Lipsa informațiilor explicite privind locația a motivat un corp tot mai mare de cercetări în ultimii ani privind diferitele modalități automate de a determina locația principală a utilizatorului. În această lucrare, propunem o metodă unificată de geolocalizare a utilizatorilor care se bazează pe fuziunea rețelelor neurale. Modelul nostru comun încorporează diferite tipuri de informații disponibile, inclusiv text tweet, rețea de utilizatori și metadate pentru a prezice locațiile utilizatorilor. Mai mult decât atât, utilizăm o rețea LSTM bidirecțională amplificată cu un mecanism de atenție pentru a identifica cele mai indicatoare cuvinte de localizare în conținutul textual al tweeturilor. Experimentele demonstrează că abordarea noastră obține performanțe de ultimă generație prin intermediul a două seturi de date de geolocație de referință Twitter. De asemenea, efectuăm un studiu de ablație pentru a evalua contribuția fiecărui tip de informație în performanța geolocalizării utilizatorilor.', 'sr': 'Lokacije korisnika društvenih medija važne su za mnoge aplikacije kao što su brzi reagovanje katastrofa, ciljana reklama i preporuka novina. Međutim, mnogi korisnici ne dijele taène geografske koordinate zbog razloga poput pitanja privatnosti. Nedostatak jasnih informacija o lokaciji motivirao je rastuće tijelo istraživanja u poslednjih godina gledajući na različite automatske načine da odredi primjernu lokaciju korisnika. U ovom papiru predlažemo jedinstvenu geolokaciju korisnika koja se oslanja na fuziju neuralnih mreža. Naš zajednički model uključuje različite vrste dostupnih informacija uključujući tekst tweet, mrežu korisnika i metadata za predviđanje lokacija korisnika. Osim toga, koristimo dvodirektivnu mrežu LSTM povećanu pažnjom mehanizmom da identifikujemo najindikativnije reči lokacije u tekstualnom sadržaju tweeta. Eksperimenti pokazuju da naš pristup postiže izvršnost umetnosti preko dva seta geolokacije podataka o tviterskoj referenciji. Takođe vodimo studiju ablacije kako bi procenili doprinos svake vrste informacija u provedbi geolokacije korisnika.', 'so': 'Locations of social media users are important to many applications such as rapid disaster response, targeted advertisement, and news recommendation.  Si kastaba ha ahaatee kuwa badan isticmaalayaal kuma qeybeeyaan kooxahooda saxda ah ee jiografiga sababtoo ah sababo tusaale ahaan fikrada gaarka loo leeyahay. Ma’aanta macluumaadka degmada caddeynta ah waxay sababtay jidh kordhisan waxbarasho, sanadkii ugu dhowaaday, iyadoo fiirinaya qaabab kala duduwan oo ku saabsan goobta asalka ah ee isticmaalaha. Qoraalkan waxaynu horumarinaynaa qaab ay isticmaaleyso goob ah, kaasoo ku xiran fuulashada shabakada neurada. Tusaalada wadajirka ah waxaa ku qoran macluumaad kala duduwan oo la heli karo, kuwaas oo ka mid ah Twitteet, shabakadda isticmaalaha, iyo macluumaad metadata si loo sii sheego meelaha ay isticmaalaan. Sidoo kale waxaynu isticmaalnaa shabakadda LSTM oo lagu kordhiyey, taasoo ay u baahan tahay macluumaad ku qoran oo ku qoran waxyaabaha qoraalka ah. Imtixaanka waxay muujiyaan in qaababkayagu ay sameyn karto xaalada farshaxanka labada kooban oo xafiiska meelaha lagu heli karo ee Twitterka. Sidoo kale waxaynu sameynaa waxbarasho dalbashada, si aan u qiimeeyo faa’iido kasta oo macluumaad ah oo ku saabsan sameynta goobta isticmaalaha.', 'sv': 'Platser för användare av sociala medier är viktiga för många applikationer såsom snabb katastrofhantering, riktad reklam och nyhetsrekommendationer. Många användare delar dock inte sina exakta geografiska koordinater på grund av skäl som integritetsfrågor. Bristen på explicit platsinformation har motiverat en växande mängd forskning under de senaste åren som tittar på olika automatiska sätt att bestämma användarens primära plats. I denna uppsats föreslår vi en enhetlig användargeolokaliseringsmetod som bygger på en fusion av neurala nätverk. Vår gemensamma modell innehåller olika typer av tillgänglig information, inklusive tweettext, användarnätverk och metadata för att förutsäga användares platser. Dessutom använder vi ett dubbelriktat LSTM-nätverk förstärkt med en uppmärksamhetsmekanism för att identifiera de mest platsvägledande orden i textinnehållet i tweets. Experimenten visar att vårt tillvägagångssätt uppnår toppmoderna prestanda över två Twitter benchmark geolokaliseringsdata. Vi genomför också en ablationsstudie för att utvärdera bidraget av varje typ av information i användarnas geolokalisering.', 'si': 'සාමාජික මිඩියාව ප්\u200dරයෝජකයේ ස්ථානයක් වැදගත් වෙන්නේ වේගයෙන් ප්\u200dරතික්\u200dරියාවට වැදගත් වෙන්න, ඉලක්ෂ නමුත්, ගොඩක් ප්\u200dරයෝජකයෙන් ඔවුන්ගේ හරියටම භාවිත්\u200dයාත්මක සංවිධානයක් සම්බන්ධ වෙන්නේ නෑ පැහැදිලි ස්ථානය තොරතුරු අවස්ථාවක් අවස්ථාවක් නැති විසින් පරීක්ෂණයක් පරීක්ෂණය අවුරුද්ධ වලින් විසි මේ පත්තරේ අපි ප්\u200dරයෝජනය කරන්නේ එකම ප්\u200dරයෝජනය භූතිකාරය විධානයක් ප්\u200dරයෝජනය කරනවා ඒක නිර්මාණ ජා අපේ සම්බන්ධ මෝඩල් එක්ක වෙනස් ප්\u200dරතිපත්ති තොරතුරු සම්බන්ධ කරනවා Tweet පාළුවක්, භාවිතා ජාලය, සහ ප්\u200dරත තවත්, අපි අවශ්\u200dය LSTM ජාලයෙක් පාවිච්චි කරනවා සඳහා අවධානය පද්ධතියෙන් අවශ්\u200dය ස්ථානයක් තියෙන්න ප්\u200dරමාණය කරනවා  පරීක්ෂණය පෙන්වන්නේ අපේ ප්\u200dරවේශනය තත්වයේ ස්ථානයක් ප්\u200dරවේශනය තියෙන්නේ ට්විටර් බෙන්ච්මාර්ක් ජෝ අපි ප්\u200dරයෝජනය භාවිත්\u200dයාත්මක ප්\u200dරමාණයේ හැම තොරතුරු වර්ගයක්ම අවශ්\u200dය කරගන්න සම්බන්ධයක් කරනවා.', 'ta': "சமூக ஊடக பயனர்களின் இடங்கள் பல பயன்பாடுகளுக்கு முக்கியமானது, வேகமான தீங்கு பதில், இலக்கப்பட்ட அறிவிப்பு, மற்றும் செய்தி பரிந However, many users do not share their exact geographical coordinates due to reasons such as privacy concerns.  வெளிப்படையான இடத்தில் தகவல் குறைந்தது சமீபத்தில் பயனரின் முதல் இடத்தை தீர்மானிக்கும் வேறு தானாக தானியங்கி பார்க்கும் ஒரு வளர்ந் இந்த காகிதத்தில், நாம் ஒருங்கிணைக்கப்பட்ட பயனர் புவியியல் முறைமையை பரிந்துரைக்கிறோம். அது புதிய பிணைய வலைப் எங்கள் இணைய மாதிரி கிடைக்கும் வேறு வகையான தகவல்களை உள்ளிடுகிறது tweet text, user network, and metadata to predict users' locations. மேலும், நாம் மிகவும் உள்ள இடத்தை குறிப்பிடும் வார்த்தைகளை உரை உள்ளடக்கத்தில் குறிப்பிடும் இடத்தில் குறிப்பிடும் உள்ளடக்கத்தில இந்த சோதனைகள் என்று காண்பிக்கிறது நம்முடைய அணுகும் நிலையையும் கலை செயல்படுத்தும் என்று தெரிவிக்கிறது என்று இரு  நாம் பயனர் புவியியல் செயல்பாட்டில் ஒவ்வொரு வகையான தகவலின் பங்கை மதிப்பிடுவதற்கு ஒரு மூட்டும் படிப்பாட்டை", 'ur': 'سوسیلی میڈیا کارساز کی موقعیت بہت سی کارسازیوں کے لئے اہم ہے جیسے تیز مصیبت کی جواب، موجود advertisement اور خبریں کی تعلیم. لیکن بہت سے کارساز اپنے جغرافی کوئڈینٹوں کو بھی شریک نہیں کرتے۔ صریح موقعیت معلومات کی ناکامی نے اگلے سالوں میں تحقیقات کی جسم کی اضافہ کی ہے کہ کارساز کی اولین موقعیت کا مقرر کرنے کی مختلف طریقے کو دیکھتے ہیں. اس کاغذ میں، ہم ایک متحدہ کارساز جئوٹ اکسیٹ طریقہ پیشنهاد کرتے ہیں جو نیورال نیٹ ورک کے پیوستنے پر اعتماد رکھتا ہے. ہمارے جولنٹ موڈل میں ٹویٹ ٹیکسٹ، یوسٹر نیٹ ورک اور مٹا ڈیٹا کے لئے مختلف طریقے موجود معلومات شامل ہوتے ہیں۔ اور اس کے علاوہ ہم ایک دوسری مسئلہ LSTM نیٹ ورک کو استعمال کرتے ہیں جو توئیٹوں کے متنوع میں سب سے زیادہ سیدھی موقعیت کی باتوں کو پہچان کرنے کے لئے اضافہ کیا گیا ہے۔ آزمائش دکھاتے ہیں کہ ہمارا طریقہ دو ٹویٹر بنچم مارک جئوٹیسیٹ ڈیٹ سٹ پر موجود ہوتا ہے. ہم نے بھی ایک آبلیٹ پڑھنے کی تحقیق کرتا ہے کہ ہر طرح کی اطلاعات کا انصاف کریں۔', 'uz': "Name Lekin, ko'pchilik foydalanuvchilari shaxsiy g'oyalarning sabablari sababini eng g'oyalar geografisk koordinatoriga ega emas. @ info Bu hujjatda, biz neyrol tarmoqlarining fuqarishga ishlatadigan bir birinchi foydalanuvchi joylashtirish usulini talab qilamiz. Bizning birlashtirish modeli foydalanuvchilar manzilini koʻrsatish uchun boshqa maʼlumot turlariga kiritiladi. Ko'rib, biz Twittlarning matn tarkibidagi eng mahalliy so'zlarni aniqlash uchun qo'shilgan LSTM tarmoqdan foydalanamiz. Imtiyotlarni ko'rsatish mumkin, bizning qismimiz haqida xabar bajarish holatini ikkita Twitter benchmark geo-location maʼlumot tarkibini bajaradi. Biz foydalanuvchi joylashtirish uchun har bir turdagi maʼlumot bajarishni qiymatlashni bajaramiz.", 'vi': 'Vị trí của người dùng trong truyền thông xã hội là quan trọng đối với nhiều ứng dụng như là phản ứng thảm họa nhanh, mục tiêu quảng cáo, và giới thiệu tin. Tuy nhiên, nhiều người dùng không chia sẻ tọa độ địa lý chính xác vì lý do như vấn đề về sự riêng tư. Sự thiếu thông tin địa điểm rõ ràng đã thúc đẩy việc nghiên cứu ngày càng nhiều trong những năm gần đây, xem xét các cách tự động khác nhau để xác định vị trí chính của người dùng. Trong tờ giấy này, chúng tôi đề xuất một phương pháp định vị người dùng thống nhất dựa trên sự kết hợp các mạng thần kinh. Trong mô hình chung của chúng tôi có những loại thông tin có sẵn, gồm cả chữ viết trên Twitter, mạng người dùng và siêu dữ liệu để dự đoán vị trí người dùng. Hơn nữa, chúng tôi sử dụng một mạng dịch bệnh LSD được tăng thêm với một cơ chế chú ý để xác định các từ chỉ dẫn nhiều nhất trong nội dung thư trên Twitter. Các thí nghiệm cho thấy phương pháp của chúng ta đạt đến trình độ tối tân hơn hai nhà dữ liệu địa điểm trên Twitter. Chúng tôi cũng tiến hành một nghiên cứu phù phép để đánh giá sự đóng góp của mỗi loại thông tin trong khả năng địa điểm người dùng.', 'bg': 'Местоположенията на потребителите на социалните медии са важни за много приложения като бърза реакция при бедствия, целева реклама и препоръки за новини. Въпреки това, много потребители не споделят точните си географски координати поради причини като опасения за поверителност. Липсата на изрична информация за местоположението мотивира нарастващ брой изследвания през последните години, разглеждащи различни автоматични начини за определяне на основното местоположение на потребителя. В настоящата статия предлагаме унифициран потребителски метод за геолокация, който разчита на сливане на невронни мрежи. Нашият съвместен модел включва различни видове налична информация, включително текст в Туитър, потребителска мрежа и метаданни, за да се предскаже местоположението на потребителите. Освен това използваме двупосочна мрежа, разширена с механизъм за внимание, за да идентифицираме най-локалните индикативни думи в текстовото съдържание на туитове. Експериментите показват, че нашият подход постига най-съвременно представяне върху два сравнителни набора от данни за геолокация в Туитър. Също така провеждаме аблационно проучване, за да оценим приноса на всеки тип информация в ефективността на геолокацията на потребителите.', 'hr': 'Lokacije korisnika društvenih medija važne su za mnoge aplikacije poput brze reakcije na katastrofe, ciljne reklame i preporuke novina. Međutim, mnogi korisnici ne dijele to čne geografske koordinate zbog razloga poput zabrinutosti privatnosti. Nedostatak jasnih informacija o lokaciji motivirao je rastuće tijelo istraživanja u posljednjih godina gledajući različite automatske načine za određivanje primjerne lokacije korisnika. U ovom papiru predlažemo jedinstvenu geolokaciju korisnika koja se oslanja na fuziju neuralnih mreža. Naš zajednički model uključuje različite vrste dostupnih informacija uključujući tekst tweet, mrežu korisnika i metapodataka za predviđanje lokacija korisnika. Osim toga, koristimo dvoričnu mrežu LSTM povećanu pažnjom za identifikaciju najindikativnijih riječi lokacije u tekstualnom sadržaju tweeta. Eksperimenti pokazuju da naš pristup postigne postupak umjetnosti iznad dvije baze podataka o geolokaciji tvitera. Također provodimo ispitivanje ablacije kako bi procijenili doprinos svake vrste informacija u provedbi geolokacije korisnika.', 'da': 'Placeringer af brugere af sociale medier er vigtige for mange applikationer såsom hurtig katastrofeberedning, målrettet reklame og nyhedsanbefalinger. Mange brugere deler imidlertid ikke deres nøjagtige geografiske koordinater af årsager som privatlivets bekymringer. Manglen på eksplicitte lokaliseringsoplysninger har motiveret en voksende samling af forskning i de seneste år, hvor man undersøger forskellige automatiske måder at bestemme brugerens primære placering på. I denne artikel foreslår vi en samlet brugergeolocation metode, der er afhængig af en fusion af neurale netværk. Vores fælles model omfatter forskellige typer af tilgængelige oplysninger, herunder tweet tekst, brugernetværk og metadata for at forudsige brugernes placeringer. Desuden anvender vi et bidirektionelt LSTM-netværk forstærket med en opmærksomhedsmekanisme til at identificere de mest lokationsvejledende ord i tekstindhold i tweets. Eksperimenterne viser, at vores tilgang opnår state-of-the-art performance over to Twitter benchmark geolocation datasæt. Vi gennemfører også en ablationsundersøgelse for at evaluere bidraget af hver type information til brugerens geolocation ydeevne.', 'nl': 'Locaties van social media gebruikers zijn belangrijk voor veel toepassingen, zoals snelle rampenreactie, gerichte reclame en nieuwsberichten. Veel gebruikers delen echter hun exacte geografische coördinaten niet vanwege redenen zoals privacyproblemen. Het gebrek aan expliciete locatiegegevens heeft de afgelopen jaren een groeiende hoeveelheid onderzoek gemotiveerd naar verschillende automatische manieren om de primaire locatie van de gebruiker te bepalen. In dit artikel stellen we een unified user geolocation methode voor die gebaseerd is op een fusie van neurale netwerken. Ons gezamenlijk model omvat verschillende soorten beschikbare informatie, waaronder tweettekst, gebruikersnetwerk en metadata om de locatie van gebruikers te voorspellen. Bovendien maken we gebruik van een bidirectioneel LSTM-netwerk, aangevuld met een aandachtsmechanisme om de meest locatie indicatieve woorden in tekstuele inhoud van tweets te identificeren. De experimenten tonen aan dat onze aanpak state-of-the-art prestaties bereikt over twee Twitter benchmark geolocatie datasets. We voeren ook een ablatieonderzoek uit om de bijdrage van elk type informatie aan de geolocatie van gebruikers te evalueren.', 'de': 'Standorte von Social-Media-Nutzern sind für viele Anwendungen wichtig, wie schnelle Katastrophenschutz, gezielte Werbung und Nachrichtenempfehlung. Viele Nutzer teilen ihre genauen geografischen Koordinaten jedoch aus Gründen wie Datenschutzgründen nicht mit. Der Mangel an expliziten Standortinformationen hat in den letzten Jahren eine wachsende Anzahl von Forschungen motiviert, die verschiedene automatische Möglichkeiten zur Bestimmung des primären Standorts des Benutzers untersucht haben. In diesem Beitrag schlagen wir eine einheitliche Geolokalisierungsmethode vor, die auf einer Fusion neuronaler Netze beruht. Unser gemeinsames Modell umfasst verschiedene Arten von verfügbaren Informationen, einschließlich Tweet-Text, Benutzernetzwerk und Metadaten, um den Standort der Benutzer vorherzusagen. Darüber hinaus verwenden wir ein bidirektionales LSTM-Netzwerk, das um einen Aufmerksamkeitsmechanismus erweitert wird, um die meisten lokal indikativen Wörter im Textinhalt von Tweets zu identifizieren. Die Experimente zeigen, dass unser Ansatz über zwei Twitter Benchmark-Geolocation-Datensätze modernste Performance erzielt. Wir führen auch eine Ablationsstudie durch, um den Beitrag jeder Art von Informationen zur Geolokalisierung der Benutzer zu bewerten.', 'id': 'Lokasi pengguna media sosial penting untuk banyak aplikasi seperti respon kecelakaan cepat, iklan tertarik, dan rekomendasi berita. Namun, banyak pengguna tidak berbagi koordinat geografi tepat mereka karena alasan seperti kepentingan privasi. Kekurangan informasi lokasi eksplicit telah mendorong tubuh penelitian yang tumbuh selama bertahun-tahun terakhir melihat cara otomatis berbeda untuk menentukan lokasi utama pengguna. Dalam kertas ini, kami mengusulkan metode geolokasi pengguna yang bersatu yang bergantung pada fusi jaringan saraf. Model kongsi kami mengangkut tipe-tipe informasi yang tersedia termasuk teks tweet, jaringan pengguna, dan metadata untuk memprediksi lokasi pengguna. Selain itu, kami menggunakan jaringan LSTM bidireksi yang ditambah dengan mekanisme perhatian untuk mengidentifikasi kata-kata paling indikasif lokasi dalam konten teks dari tweet. Eksperimen menunjukkan bahwa pendekatan kita mencapai prestasi terbaik dalam dua set data geolokasi benchmark Twitter. Kami juga melakukan studi ablasi untuk mengevaluasi kontribusi setiap jenis informasi dalam prestasi geolokasi pengguna.', 'ko': '소셜 미디어 사용자의 위치는 많은 응용 프로그램에 매우 중요하다. 예를 들어 신속한 재난 응답, 맞춤형 광고, 뉴스 추천 등이다.그러나 프라이버시 등의 이유로 많은 사용자들이 정확한 지리 좌표를 공유하지 않는다.최근 몇 년 동안 명확한 위치 정보가 부족하기 때문에 점점 더 많은 연구들이 사용자의 주요 위치를 자동으로 확정하는 다른 방법을 찾기 시작했다.본고는 신경 네트워크 융합을 바탕으로 하는 통일된 사용자 지리적 포지셔닝 방법을 제시했다.우리의 연합 모델은 서로 다른 유형의 사용 가능한 정보를 결합시켜 추문 텍스트, 사용자 네트워크와 메타데이터를 포함하여 사용자의 위치를 예측한다.그 밖에 우리는 쌍방향 LSTM 네트워크와 주의 메커니즘을 이용하여 추문 텍스트 내용 중 가장 많은 위치 지시어를 식별한다.실험에 따르면 우리의 방법은 두 개의 트위터 기준 지리적 위치 데이터 집합에서 가장 선진적인 성능을 실현했다.우리는 또한 모든 유형의 정보가 사용자의 지리적 포지셔닝 성능에 기여한 바를 평가하기 위해 융해 연구를 진행했다.', 'fa': 'موقعیت کاربران رسانه\u200cهای اجتماعی برای بسیاری از کاربردهای مثل واکنش سریع فاجعه\u200cای، تبلیغات هدف و پیشنهاد اخبار مهم است. ولی بسیاری از کاربران به دلیل\u200cهایی مانند نگرانی خصوصی شریک نمیکنند. ناتوانی اطلاعات مکان مشخص در سالهای اخیر یک جسد تحقیقات بزرگ را تحقیق کرده است که به راه\u200cهای خودکار متفاوتی برای تعیین موقعیت اصلی کاربر نگاه می\u200cکند. در این کاغذ، ما پیشنهاد می\u200cکنیم یک روش جامعه\u200cای از استفاده\u200cها متحده که بر ترکیب شبکه\u200cهای عصبی بستگی دارد. مدل مشترک ما نوع اطلاعات متفاوت را شامل می\u200cکند که شامل متن توئیت، شبکه کاربر و متداده\u200cها برای پیش\u200cبینی موقعیت کاربر است. به علاوه، ما از شبکه LSTM دوباره استفاده می کنیم که با یک مکانیسم توجه افزایش یافته شده برای شناسایی بیشترین کلمات موقعیت نشان دهنده در محتوای متن Tweets است. آزمایش ها نشان می دهند که دستور ما اجرای موقعیت هنری را بر دو مجموعه داده\u200cهای جامعه\u200cای توئیتر می\u200cرساند. ما همچنین یک مطالعه توانایی برای ارزیابی تولید هر نوع اطلاعات در اجرای جغرافی کاربر انجام می دهیم.', 'sw': 'Maeneo ya watumiaji wa mitandao ya kijamii ni muhimu kwa matumizi mengi kama vile majibu ya haraka, matangazo yanayolengwa na mapendekezo ya habari. Hata hivyo, watumiaji wengi hawashiriki uratibu wao wa kisiografia kutokana na sababu kama vile wasiwasi wa faragha. Ukosefu wa taarifa za maeneo wazi imehamasisha mwili wa utafiti katika miaka ya hivi karibuni kuangalia njia tofauti za kujitegemea maeneo ya msingi ya mtumiaji. In this paper, we propose a unified user geolocation method which relies on a fusion of neural networks.  Mradi wetu wa pamoja unajumuisha aina mbalimbali za taarifa zinazopatikana ikiwa ni pamoja na ujumbe wa twita, mtandao wa mtumiaji, na taarifa za metadata za kutabiri maeneo ya watumiaji. Zaidi ya hayo, tunatumia mtandao wa LSTM ulioongezwa na mfumo wa kutambua maeneo mengi yanayoonyesha maneno katika maudhui ya twiti. Majaribio hayo yanaonyesha kwamba mbinu zetu zinafanikiwa utendaji wa hali ya sanaa zaidi ya seti za maeneo ya maeneo mawili ya twita. Pia tunafanya utafiti wa mafuta ili kutathmini mchango wa kila aina ya taarifa katika utendaji wa eneo la watumiaji.', 'tr': 'Sosial mediýa ullançylaryň ýerleri birnäçe uygulamalar üçin wajypdyr, täsirli jogap etmek, maksady reklam we täzelikler maslahat ýaly. Ýöne köp ulananlar özleriniň gyzykly aladalary ýaly sebäpleri üçin gyzykly geografiki koordinatlaryny paýlamaýarlar. Tussag ýer maglumaty ýok bolmady soňky ýyllar içinde ullanýan ýeri özüniň başlygy ýerini tanamak üçin üýtgeden araştyrmalaryň bedeni näçe köp ýoly üýtgedi. Bu kagyzda, nural şebekeleriň birleşigine ynamly bir ýerleşdirişligi teklip edip bilýäris. Biziň kop modelimiz ullançylaryň ýerlerini öňden çykarmak üçin beýleki hilli maglumatlary bar. Biz ýene-de tweets içerisinde iň köp görkezilýän ýerleri tanamak üçin iň köp görkezilýän LSTM şebekesini ullanýarys. Denminatlar biziň ýaryşymyz Twitter benchmarklaryň geolokalizasy düzümleriniň durumynda ýetip barýandygyny görkeýärler. Biz hem brûkerçy geolokalizasynda her hili maglumatyň täsirini çykarmak üçin etkinlik studiyny etdik.', 'sq': 'Vendet e përdoruesve të medias shoqërore janë të rëndësishme për shumë aplikime të tilla si reagimi i shpejtë i fatkeqësive, reklamat e synuar dhe rekomandimi i lajmeve. Megjithatë, shumë përdorues nuk ndajnë koordinatat e tyre të sakta gjeografike për shkak të arsyeve të tilla si shqetësimet e privatësisë. Mungesa e informacionit eksplicit të vendndodhjes ka motivuar një trup në rritje të kërkimeve në vitet e fundit duke kërkuar mënyra të ndryshme automatike për të përcaktuar vendndodhjen kryesore të përdoruesit. Në këtë letër, propozojmë një metodë të unifikuar gjeolokalimi të përdoruesit që mbështetet në një fuzion të rrjeteve nervore. Modeli ynë i përbashkët përfshin lloje të ndryshme informacioni në dispozicion duke përfshirë tekstin e tweetit, rrjetin e përdoruesve dhe metatë për të parashikuar vendet e përdoruesve. Përveç kësaj, ne përdorim një rrjet LSTM dy-drejtues të shtuar me një mekanizëm vëmendje për të identifikuar fjalët më treguese në përmbajtjen tekstuale të tweeteve. The experiments demonstrate that our approach achieves state-of-the-art performance over two Twitter benchmark geolocation datasets.  Ne kryejmë gjithashtu një studim ablacioni për të vlerësuar kontributin e çdo lloji informacioni në performancën e gjeolokalimit të përdoruesve.', 'am': 'የማኅበራዊ ሚዲያ ተጠቃሚዎች ቦታዎች ለብዙ ፕሮግራሞች፣ ፈጥኖ የጥፋት መልስ፣ የጉዳዩ አዋቂነት እና ዜና ጉዳይ እንዲሆን ያስፈልጋሉ፡፡ ነገር ግን ብዙዎች የተጠቃሚዎች የግዮግራፊ ኮርማኖቻቸውን እንደprivacy ምክንያት አይካፈሉትም፡፡ የአካባቢ ቦታ መረጃ ግንኙነት የተጠቃሚውን የመጀመሪያ ቦታ ለመፍጠር በተለየ ዓመታት ውስጥ የፍጥረት አካል አነሳሳሳይ በማድረግ የራሳቸውን አስተያየት አቆመ፡፡ በዚህ ፕሮግራም፣ የደዌብ መረብ መደገፊያ የሚታመን የተጠቃሚ የቦታ ቦታ ማድረግ እናሳልጋለን፡፡ የአካባቢው ሞዴላታችን የጣቢያ ጽሑፍ፣ ተጠቃሚ መረብ እና የተጠቃሚዎችን ቦታ ለመጠየቅ የሚችሉትን የልዩ ዓይነት መረጃ ይጨመርበታል፡፡ በተጨማሪም፣ የትዊተር ጥያቄ የሚታወቀውን ቃላት በመስመር ውስጥ የሚታወቀውን እናሳውቃለን፡፡ ፈተናዎቹ የሁለተኛውን የዓላማ ሥርዓት ማግኘት እና በሁለቱ የኢትዮጵያ የኢትዮጵያ ቦታ ዳታዎችን እንዲያገኝ ያሳያል፡፡ በተጠቃሚ ቦታ ላይ የኢትዮጵያ ቦታ አካሄዱን ለማስተዋል የሁሉንም ዓይነት መረጃዎች አካሄድን እናደርጋለን፡፡', 'af': "Plasies van sosiale media gebruikers is belangrik vir baie toepassings, soos vinnige katastrofsreaksie, doelgemaakte reklame en nuusrekening. Maar baie gebruikers doen nie hul egte geografiese koordinate deel nie vanweë rede soos privateitsbekommerings nie. Die ontbreek van eksplisiese ligging inligting het 'n groei liggaam van ondersoek in onlangse jaar wat op verskillende automatiese maniere kyk om die gebruiker se primêre ligging te bepaal. In hierdie papier, voorstel ons 'n eenvoudige gebruiker geoligging metode wat op 'n fusie van neuralnetwerke aflyk. Ons joint model inkluit verskillende tipes beskikbaar inligting insluitend tweet teks, gebruikernetwerk en metadata om gebruikers se ligging te voorskou. Ook, ons gebruik 'n bidireksjonale LSTM netwerk wat met 'n aandag mekanisme vergroot is om die mees ligging indikasiewe woorde te identifiseer in tektuele inhoud van tweets. Die eksperimente wys dat ons toegang tot staat van die kunstenaar uitvoer oor twee Twitter benchmark geoligging datastelle. Ons het ook 'n ablasie studie gedoen om die bydraag van elke tipe inligting in gebruiker geoligasie-prestasie te evalueer.", 'hy': 'Locations of social media users are important to many applications such as rapid disaster response, targeted advertisement, and news recommendation.  Այնուամենայնիվ, շատ օգտագործողներ չեն կիսում իրենց ճշգրիտ գերագրական կոորդինատները, ինչպիսիք են օրինակ գաղտնիության խնդիրները: Բացատրական տեղեկատվության բացակայությունը վերջին տարիների ընթացքում հետազոտությունների աճող մարմինը հետազոտում է օգտագործողի հիմնական տեղակայության որոշումների տարբեր ավտոմատիկ ձևեր: Այս թղթի մեջ մենք առաջարկում ենք միավոր օգտագործողի երկրագծի մեթոդ, որը հիմնված է նյարդային ցանցերի համալսարանի վրա: Մեր միավոր մոդելը ներառում է տարբեր տեսակի հասանելի տեղեկատվություն, ներառյալ թվիթի տեքստը, օգտագործողների ցանցը և մետատվյալները օգտագործողների տեղադրությունների կանխատեսելու համար: Ավելին, մենք օգտագործում ենք երկու ուղղությամբ LSMT ցանց, որը աճեցված է ուշադրության մեխանիզմի միջոցով, որպեսզի բացահայտենք թվիթերի տեքստային պարունակության ամենակարևոր նշանակալի բառերը: Փորձարկումները ցույց են տալիս, որ մեր մոտեցումը հասնում է լավագույն արդյունքներին Թվիթերի երկու համեմատական տվյալների համակարգերի միջոցով: Մենք նաև կատարում ենք աբլացիայի ուսումնասիրություն, որպեսզի գնահատենք օգտագործողների երկրագծի գործունեության յուրաքանչյուր տեսակի ինֆորմացիայի ներդրումը:', 'az': 'Sosyal mediya istifadəçilərinin məskəni tez fəsad reaksiyonu, məqsədilə reklam və xəbər təbliğləri kimi çoxlu istifadəçilər üçün vacibdir. Lakin çoxlu istifadəçilər özlərinin gizli məxluqatı kimi həqiqi geografik koordinatlarını paylaşmazlar. Görünüşlü məlumat yoxdur ki, son illərdə təşkil edilən təşkil vücudunu təşkil edir, istifadəçin in ilk məlumatını təyin etmək üçün fərqli təşkil yollarına baxırlar. Bu kağızda, birləşdirilmiş istifadəçinin geolokasyonu metodu təklif edirik ki, nöral a ğlarının fəsasiyasına dayanılır. Bizim birləşdirilmiş modelimiz müxtəlif məlumat, istifadəçilərin məlumatlarını öyrənmək üçün tweet məlumatları, istifadəçilərin şəbəkələrini və meta məlumatlarını daxil edir. Daha sonra, Tövtlərin məlumatının ən çox göstərici sözlərini tanıtmaq məqsədilə artırılmış LSTM a ğını istifadə edirik. Həqiqətən, təcrübələrimiz Twitter benchmark geolokasyon verilənlərin iki dəstədən müəyyən edilməsini göstərir. Biz də istifadəçilərin geolokasyon performansındakı hər növ məlumatın səbəbi müəyyən etmək üçün səbəb təhsil edirik.', 'bn': 'সামাজিক মিডিয়া ব্যবহারকারীদের স্থান অনেক অ্যাপ্লিকেশনের জন্য গুরুত্বপূর্ণ, যেমন দ্রুত দুর্ঘটনার প্রতিক্রিয়া,  তবে অনেক ব্যবহারকারীরা তাদের সঠিক ভূগ্রাফিক্যাল সংক্রান্ত সংক্রান্ত ব্যক্তিগত উদ্বেগের কারণে শেয়ার করে না। সাম্প্রতিক বছরগুলোতে ব্যবহারকারীর প্রধান অবস্থান নির্ধারণের বিভিন্ন উপায়ের দিকে তাকিয়ে ব্যবহারকারীর প্রাথমিক অবস্থান নির্ধা এই কাগজটিতে আমরা একটি একত্রিত ব্যবহারকারী জ্যোতিস্থানের পদ্ধতি প্রস্তাব করি যা নিউরেল নেটওয়ার্কের ফ্লিশনের উপর নির আমাদের যুক্ত মডেল ব্যবহারকারীদের অবস্থান ভবিষ্যদ্বাণী করার জন্য টুইট, ব্যবহারকারী নেটওয়ার্ক এবং মেটেডাটা বিভিন্ন ধরনের তথ এছাড়াও, টুইটের টুইটের টেক্সচুয়াল বিষয়বস্তুতে সবচেয়ে বেশি স্থানীয় শব্দ চিহ্নিত করার জন্য আমরা বিদ্যুত এলসিএম নেটওয়ার্ক ব্ এই পরীক্ষাগুলো দেখাচ্ছে যে আমাদের প্রতিক্রিয়া দুই টুইটার ব্যাংম্যার্ক ভূমিকম্যার্কের ভূমিকা ডাটাসেটের উপরে  আমরা ব্যবহারকারীদের জ্যোতিস্থানের প্রদর্শনের প্রত্যেকটি ধরনের তথ্যের অবদান মূল্যায়নের জন্য একটি আগুনের গবেষণা কর', 'bs': 'Lokacije korisnika društvenih medija važne su za mnoge aplikacije poput brze reakcije na katastrofe, ciljne reklame i preporuke novina. Međutim, mnogi korisnici ne dijele tačne geografske koordinate zbog razloga poput zabrinutosti privatnosti. Nedostatak pojasnih informacija o lokaciji motivirao je rastuće tijelo istraživanja u poslednjih godina gledajući različite automatske načine za određivanje primjerne lokacije korisnika. U ovom papiru predlažemo jedinstvenu geolokaciju korisnika koja se oslanja na fuziju neuralnih mreža. Naš zajednički model uključuje različite vrste dostupnih informacija uključujući tweet tekst, mrežu korisnika i metadata kako bi predvidjeli lokacije korisnika. Osim toga, koristimo dvodirektivnu mrežu LSTM povećanu pažnjom mehanizam za identifikaciju najindikativnijih riječi lokacije u tekstualnom sadržaju tweeta. Eksperimenti pokazuju da naš pristup postigne postupak umjetnosti iznad dvije baze podataka o geolokaciji tvitera. Također provodimo studiju ablacije kako bi procenili doprinos svake vrste informacija u provedbi geolokacije korisnika.', 'ca': "Llocalizacions dels usuaris dels mitjans socials són importants per a moltes aplicacions com la ràpida resposta a desastres, anuncis mirats i recomanacions de notícies. Però molts usuaris no comparteixen les seves coordenadas geogràfiques exactes per raons com les preocupacions de la privacitat. La falta d'informació explícita sobre la localització ha motivat un cos creixent de recerca en els últims anys mirant diferents maneres automàtiques de determinar la localització primària del usuari. En aquest paper, proposem un mètode unificat de geolocalització de l'usuari que es basa en una fusió de xarxes neurals. El nostre model conjunt incorpora diferents tipus de informació disponible, incloent el text de tweet, la xarxa d'usuaris i les metadades per predir llocs d'usuaris. A més, utilitzem una xarxa LSTM bidireccional augmentata amb un mecanisme d'atenció per identificar les paraules més indicadores en el contingut textual dels tweets. Els experiments demostren que el nostre enfocament aconsegueix un rendiment més avançat a través de dos conjunts de dades de geolocalització de Twitter. També fem un estudi d'ablació per avaluar la contribució de cada tipus d'informació en el rendiment de la geolocalització de l'usuari.", 'fi': 'Sosiaalisen median käyttäjien sijainnit ovat tärkeitä monille sovelluksille, kuten nopealle katastrofille, kohdennetulle mainonnalle ja uutissuositukselle. Monet käyttäjät eivät kuitenkaan jaa tarkkoja maantieteellisiä koordinaatteja esimerkiksi tietosuojan vuoksi. Selkeän sijaintitiedon puute on motivoinut viime vuosina kasvavaa tutkimusta, jossa tarkastellaan erilaisia automaattisia tapoja määrittää käyttäjän ensisijainen sijainti. Tässä työssä ehdotamme yhtenäistä käyttäjägeolokaatiomenetelmää, joka perustuu neuroverkkojen fuusioon. Yhteinen mallimme sisältää erilaisia saatavilla olevia tietoja, kuten twiittitekstiä, käyttäjäverkostoa ja metatietoja käyttäjien sijainnin ennustamiseksi. Lisäksi käytämme kaksisuuntaista LSTM-verkostoa, jota on täydennetty huomiomekanismilla tunnistamaan eniten sijaintia osoittavia sanoja twiittien tekstisisällössä. Kokeet osoittavat, että lähestymistapamme saavuttaa huipputason suorituskyvyn kahden Twitter-vertailudatan avulla. Teemme myös ablaatiotutkimuksen, jossa arvioidaan kunkin tiedon vaikutusta käyttäjän geolokaation suorituskykyyn.', 'cs': 'Umístění uživatelů sociálních médií je důležité pro mnoho aplikací, jako je rychlá reakce na katastrofy, cílená reklama a doporučení zpráv. Mnoho uživatelů však nesdílí své přesné zeměpisné souřadnice z důvodů, jako jsou obavy o ochranu soukromí. Nedostatek explicitních informací o poloze motivoval v posledních letech rostoucí soubor výzkumů hledajících různé automatické způsoby určení primární polohy uživatele. V tomto článku navrhujeme jednotnou geolokační metodu uživatelů, která se opírá o fúzi neuronových sítí. Náš společný model zahrnuje různé typy dostupných informací, včetně tweetového textu, uživatelské sítě a metadat pro předpověď umístění uživatelů. Navíc využíváme obousměrnou LSTM síť rozšířenou o mechanismus pozornosti pro identifikaci nejvíce orientačních slov v textovém obsahu tweetů. Experimenty ukazují, že náš přístup dosahuje nejmodernějšího výkonu na základě dvou referenčních datových sad Twitteru. Dále provádíme ablační studii, abychom vyhodnotili přínos každého typu informací ve výkonnosti geolokace uživatelů.', 'et': 'Sotsiaalmeedia kasutajate asukohad on olulised paljude rakenduste jaoks, nagu kiire katastroofile reageerimine, suunatud reklaam ja uudiste soovitused. Paljud kasutajad ei jaga siiski oma täpseid geograafilisi koordinaate sellistel põhjustel nagu privaatsusprobleemid. Sõnaselge asukohateabe puudumine on viimastel aastatel motiveerinud järjest rohkem uuringuid, milles uuritakse erinevaid automaatseid viise kasutaja esmase asukoha kindlaksmääramiseks. Käesolevas töös pakume välja ühtse kasutaja geolokatsiooni meetodi, mis tugineb neurovõrkude sulandumisele. Meie ühine mudel sisaldab erinevat tüüpi kättesaadavat teavet, sealhulgas säutsuteksti, kasutajate võrgustikku ja metaandmeid kasutajate asukohtade prognoosimiseks. Lisaks kasutame kahesuunalist LSTM-võrku, mis on täiendatud tähelepanumehhanismiga, et tuvastada kõige rohkem asukoha soovituslikke sõnu säutsude tekstisisus. Katsed näitavad, et meie lähenemisviis saavutab kaasaegse jõudluse kahe Twitteri võrdlusaluse geolokatsiooni andmekogumi kaudu. Samuti teostame ablatsiooniuuringu, et hinnata iga tüüpi teabe panust kasutaja geolokatsiooni jõudlusesse.', 'sk': 'Lokacije uporabnikov družbenih omrežij so pomembne za številne aplikacije, kot so hitro odzivanje na nesreče, ciljno oglaševanje in priporočilo novic. Vendar pa mnogi uporabniki ne delijo natančnih geografskih koordinat zaradi razlogov, kot so pomisleki glede zasebnosti. Pomanjkanje eksplicitnih informacij o lokaciji je v zadnjih letih spodbudilo naraščajoče število raziskav, ki proučujejo različne avtomatske načine določanja primarne lokacije uporabnika. V prispevku predlagamo enotno metodo geolokacije uporabnikov, ki temelji na fuziji nevronskih omrežij. Naš skupni model vključuje različne vrste razpoložljivih informacij, vključno z besedilom tweeta, uporabniškim omrežjem in metapodatki za predvidevanje lokacij uporabnikov. Poleg tega uporabljamo dvosmerno LSTM omrežje z mehanizmom pozornosti za prepoznavanje največ lokacijskih indikativnih besed v besedilni vsebini tweetov. Poskusi dokazujejo, da naš pristop dosega najsodobnejšo zmogljivost na podlagi dveh referenčnih geolokacijskih naborov Twitterja. Izvajamo tudi ablacijsko študijo, da ocenimo prispevek vsake vrste informacij k uspešnosti geolokacije uporabnikov.', 'ha': "Wurin masu muhimu na amfani da masu amfani da mitandai na jamii kamar majiɓinta mai gaggãwa, da zance da shirin da aka yi amfani da shi da kuma da shawara na lãbãri. A lokacin da, mãsu yawa mãsu amfani da shi ba su raba manyan ajiya masu hakki ga geographical ko sababi ne kamar matsayin farat ɗaya. Ba'a s ãmu da information na wuri mai bayyanãwa ba ya motsar wani jiki mai ƙara research cikin shekara na farko a shekara ta taƙaita hanyõyi daban-farat farat ɗaya da za'a bayyana wurin na mai amfani da shi. Ga wannan takardan, Munã buɗa wata metode na shirin mai amfani da shi na haɗi, wanda yana dõgara a fusar zuwa zanen neural. @ info: whatsthis Moreover, we utilize a bidirectional LSTM network augmented with an attention mechanism to identify the most location indicative words in textual content of tweets.  Kayan jarrabai sun nuna cewa hanyoyinmu yana sami halin-sanar ko duk taki biyu na Twitter bangbang geo-mazaɓa. Tuna tafiyar da wani littãfi na rubutu dõmin a evaluate ƙarami ga duk nau'i na takardar wurin da ake amfani da shi.", 'he': 'מקומות משתמשים בתקשורת חברתית חשובים ליישומים רבים כמו תגובת אסון מהירה, פרסום ממוקד, ומלצת חדשות. עם זאת, משתמשים רבים לא חולקים את הקורדינטים הגאוגרפיים המדויקים שלהם בגלל סיבות כמו דאגות פרטיות. חוסר מידע מיקום ברור מוטיבציה גוף גדול של מחקר בשנים האחרונות שמסתכל על דרכים אוטומטיות שונות לקבוע את המיקום העיקרי של המשתמש. בעיתון הזה, אנו מציעים שיטת גיאולוקציה משתמשת מאוחדת שמסומכת על פיזוציה של רשתות עצביות. המודל המשותף שלנו מכיל סוגים שונים של מידע זמין כולל טקסט טוויט, רשת משתמשים, ומטאדיטות כדי לחזות אתרי המשתמשים. חוץ מזה, אנו משתמשים ברשת LSTM bidirectional מוצדפת עם מנגנון תשומת לב לזהות את המילים המיידות ביותר בתוכן טקסטלי של טוויטים. הניסויים מראים שהגישה שלנו משיגה ביצועים מוקדמים במהלך שתי קבוצות מידע גיאומיקוציה של טוויטר. אנחנו גם מבצעים מחקר ניתוח כדי להעריך את התרומה של כל סוג של מידע בתפקיד הגיאומיקציה של המשתמשים.', 'jv': 'Awak dhéwé éntukno media sotiki sing dikarepaké kanggo akeh aplikasi kaya ngono rewolèh langgar, kijane awak dhéwé, lan basa anjutan tambah. politenessoffpolite, "), and when there is a change ("assertivepoliteness offline Nang pemilih iki, kita supoyata sistem jeogras nang ngawehi sistem sing wis ana sak batasan di netwisan neral model sing dibutuhke Laptop" and "Desktop Name Awak dhéwé éntuk nglebokake ing pisan kanggo nggunakake tarjamahan kanggo nggawe informasi ning jeogras barang pengguna', 'bo': "སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བ་སྤྱོད་མཁན་གྱི་གནས་ཡུལ་དེ་ཉེར་སྤྱོད་མཁན་ལ་གལ་ཆེ་བ་ཡིན། ཡིན་ནའང་། སྤྱོད་མཁན་མང་པོ་ཞིག་ནི་སྒེར་དབང་གི་བསམ་བློ་གཏོང་གི་མཐོ་རིམ་སྟོན་པར། གསལ་བཤད་ཀྱི་གནས In this paper, we propose a unified user geolocation method which relies on a fusion of neural networks. Our joint model incorporates different types of available information including tweet text, user network, and metadata to predict users' locations. འོན་ཀྱང་། ང་ཚོས་ཡིག The experiments demonstrate that our approach achieves state-of-the-art performance over two Twitter benchmark geolocation datasets. We also conduct an ablation study to evaluate the contribution of each type of information in user geolocation performance."}
{'en': 'From Strings to Other Things : Linking the Neighborhood and Transposition Effects in Word Reading', 'ar': 'من الأوتار إلى أشياء أخرى: ربط الجوار وتأثيرات التحويل في قراءة الكلمات', 'pt': 'Das cordas às outras coisas: vinculando a vizinhança e efeitos de transposição na leitura de palavras', 'es': 'De las cadenas a otras cosas: vincular los efectos de vecindad y transposición en la lectura de palabras', 'fr': "Des chaînes de caractères à d'autres choses\xa0: lier les effets de voisinage et de transposition dans la lecture de mots", 'ja': '文字列から他のものへ：単語の読み取りにおける近隣と転置の効果を結びつける', 'hi': 'स्ट्रिंग्स से अन्य चीजों के लिए: वर्ड रीडिंग में पड़ोस और ट्रांसपोज़िशन प्रभावों को जोड़ना', 'zh': '自字符串至他物:链接单词读中邻域转置效', 'ru': 'От струн к другим вещам: увязка эффектов соседства и транспозиции в чтении слов', 'ga': 'Ó Teaghráin go Rudaí Eile: Na hÉifeachtaí Comharsanachta a Nascadh agus Trasuíomh i Léitheoireacht Focal', 'hu': 'A karakterláncoktól más dolgokig: A szomszédsági és átültetési hatások összekapcsolása a szövegolvasásban', 'el': 'Από συμβολοσειρές σε άλλα πράγματα: Σύνδεση των εφέ γειτονίας και μετάθεσης στην ανάγνωση λέξεων', 'it': 'Dalle stringhe ad altre cose: collegare gli effetti di vicinato e trasposizione nella lettura delle parole', 'lt': 'Nuo eilučių prie kitų dalykų: Susieti kaimynystės ir perkėlimo efektus skaitant žodžius', 'mk': 'Од линии на други работи: поврзување на ефектите на соседството и транспозицијата во читањето на зборови', 'ms': 'Dari Rangkaian ke Perkara Lain: Pautan Kesan Kejiranan dan Kesan Transposisi dalam Pembacaan Perkataan', 'ka': 'სიტყვებისგან სხვა საქმედებისგან: საზოგადოებო და ტრანპოზოციაციის ეფექტის დაკავშირება სიტყვების კითხვაში', 'ml': 'സ്ട്രിങ്ങില്\u200d നിന്നും മറ്റു കാര്യങ്ങളിലേക്കും: വാക്ക് വായിക്കുന്നതിലേക്കുള്ള പ്രഭാവങ്ങള്\u200d ലിങ്ങ', 'mt': 'Mill-Linji għal Oħrajn: Ir-rabta bejn l-Effetti tal-Viċinat u t-Traspożizzjoni fil-Qara tal-kliem', 'pl': 'Od ciągów do innych rzeczy: Połączenie efektów sąsiedztwa i transpozycji w czytaniu słowa', 'ro': 'De la șiruri la alte lucruri: conectarea efectelor de vecinătate și transpunere în citirea cuvintelor', 'sr': 'Od Strings do drugih stvari: povezanje susjedstva i Transpozicijskih efekta u čitanju reči', 'mn': 'Мэдээллээс бусад зүйлээс: хөршүүн болон Төмөр Эффектүүдийг Word Reading-д холбох', 'kk': 'Жолдардан басқа нәрселерге: Көңіл және мөлдірлік эффекттерді сөздерді оқу үшін сілтемелеу', 'no': 'Fra strengar til andre ting: Linkar nabolaffektane og gjennomsikt i ordlesing', 'so': 'Strings to other things: Linking the Neighborhood and Transposition Effects in Word Reading', 'sv': 'Från strängar till andra saker: Koppla samman grannskaps- och införlivandeeffekter i ordläsning', 'ta': 'சரங்களிலிருந்து மற்ற விஷயங்களுக்கு: வார்த்தை படிப்பதில் இணைப்பு மற்றும் இடம் விளைவுகள்', 'si': 'ස්ට්\u200dරින්ස්ට් වල අනිත් දේවල් වලට: සමාජය සහ ප්\u200dරවේශනය ප්\u200dරභාවිත වචනයට සම්බන්ධ කරන්න', 'ur': 'استرینگ سے اور دوسری چیزوں تک: اپنا رشتہ داری اور روشنی اثرات بات پڑھنے میں', 'uz': 'Ustunlardan boshqa narsalarga: Linking the Neighborhood and Transport Effects in Word Reading', 'vi': 'Từ dây dợ tới những thứ khác: Liên kết kết các hiệu ứng láng giềng và vận chuyển trong việc đọc chữ.', 'da': 'Fra strenge til andre ting: Sammenkædning af naboskabs- og transponeringseffekter i ordlæsning', 'bg': 'От низове към други неща: свързване на съседските ефекти и транспонирането в четенето на думи', 'nl': 'Van tekenreeksen naar andere dingen: de buurt- en transpositieeffecten koppelen in woordlezen', 'hr': 'Od žica do drugih stvari: povezanje utjecaja susjedstva i prijenosnosti u čitanju riječi', 'id': 'Dari Garis ke Hal Lain: Menghubung Ekset Tetangga dan Transposisi dalam Pembacaan Perkataan', 'ko': '문자열에서 다른 사물로: 단어 읽기에서의 이웃 연결과 변위 효과', 'sw': 'Kutoka Mitando hadi mambo mengine: Kuunganisha Umoja wa Kiraia na Mitandao ya Uhamiaji katika Kusoma Neno', 'de': 'Von Zeichenfolgen zu anderen Dingen: Verknüpfen der Nachbarschafts- und Transposition-Effekte beim Lesen von Wörtern', 'fa': 'از صفحه\u200cها به چیزهای دیگر: ارتباط اثرات محله\u200cها و انتقال در خواندن کلمه\u200cها', 'sq': 'Nga rreshta në gjëra të tjera: Lidhja e efekteve të fqinjësisë dhe transpozimit në leximin e fjalëve', 'am': 'ከStrings to Other Things: Linking the Neigborhood and Transposition Effects in Word Reading', 'tr': 'miter", "round" or "bevel', 'az': 'S…ôtirl…ôrd…ôn BaŇüqa Ňüeyl…ôr…ô: QonŇüuluqlarńĪ v…ô T…ôr…ôfl…ôt Efektl…ôrini S…ôfl…ôt oxumasńĪna bańülayńĪr', 'af': 'Van Strings na Ander dinge: Links die Naamskap en Transposisie Effekte in Woord Lees', 'bs': 'Od strega do drugih stvari: povezanje utjecaja susjedstva i Transpozicije u čitanje riječi', 'hy': 'Օրինակ՝ կապել հարևանության և տեղափոխման էֆեկտները բառերի ընթերցման մեջ', 'cs': 'Od řetězců k jiným věcem: Propojení efektů sousedství a transpozice ve čtení slov', 'bn': 'স্ট্রিং থেকে অন্যান্য বস্তু থেকে: শব্দ পাঠের প্রভাবে লিঙ্ক করা হচ্ছে', 'fi': 'Merkkijonoista muihin asioihin: Naapuruusvaikutusten linkittäminen ja siirtämisen vaikutukset sanalukemisessa', 'ca': 'From Strings to Other Things: Linking the Neighborhood and Transposition Effects in Word Reading', 'et': 'Stringidest muudeni: naabrus- ja ülevõtmisefektide sidumine sõna lugemisel', 'sk': 'Od nizov do drugih stvari: povezovanje sosedskih učinkov in učinkov prenosa v branju besed', 'bo': 'ཡི་གེའི་ནང་ལས་ཡི་གེ་དང་གཞན་ཞིག་ལ་སྦྲེལ་མཐུད་བྱེད་པ།', 'ha': 'KCharselect unicode block name', 'he': 'משרשרות לדברים אחרים: הקשר השכונה וההשפעות ההעברה בקריאה מילים', 'jv': 'text-editor-action'}
{'en': 'We investigate the relation between the transposition and deletion effects in word reading, i.e., the finding that readers can successfully read SLAT as SALT, or WRK as WORK, and the ', 'ar': 'نحن نتحرى العلاقة بين تأثيرات التحويل والحذف في قراءة الكلمات ، أي اكتشاف أن القراء يمكنهم قراءة "SLAT" بنجاح كـ "SALT" أو "WRK" كـ "WORK" ، وتأثير الجوار. على وجه الخصوص ، نتحرى ما إذا كانت الأحياء الهجائية المعجمية تأخذ في الاعتبار التحويل والحذف عند تحديد الجيران. إذا كانت هذه هي الحالة ، فمن الأرجح أن يحدث تأثير الجوار مبكرًا أثناء المعالجة ، ولا يعتمد فقط على تشابه التمثيلات الداخلية. نقدم مقياسًا حيًا جديدًا ، rd20 ، والذي يمكن استخدامه لتحديد تأثيرات الجوار على مساحات الميزات العشوائية. نحسب rd20 على مجموعات كبيرة من الكلمات بثلاث لغات باستخدام مجموعات ميزات مختلفة ونبين أن مجموعات الميزات التي لا تسمح بالتبديل أو الحذف تشرح المزيد من التباين في قياسات وقت رد الفعل (RT). نوضح أيضًا أنه يمكن حساب rd20 باستخدام تمثيلات الحالة المخفية لـ Multi-Layer Perceptron ، ونبين أن هذه تفسر تباينًا أقل من الميزات الأولية. نستنتج أن تأثير الجوار من غير المرجح أن يكون له أساس إدراكي ، ولكن من المرجح أن يكون نتيجة لتفعيل العناصر بشكل مشترك بعد التعرف عليها. جميع الأكواد متاحة على: <www.github.com/clips/conll2018>', 'fr': "Nous étudions la relation entre les effets de transposition et de suppression dans la lecture de mots, c'est-à-dire la découverte que les lecteurs peuvent lire «\xa0SLAT\xa0» comme «\xa0SALT\xa0» ou «\xa0WRK\xa0» comme «\xa0TRAVAIL\xa0», et l'effet de voisinage. En particulier, nous étudions si les voisinages orthographiques lexicaux tiennent compte de la transposition et de la suppression dans la détermination des voisins. Si tel est le cas, il est plus probable que l'effet de voisinage se produise tôt au cours du traitement, et ne repose pas uniquement sur la similitude des représentations internes. Nous introduisons une nouvelle mesure de voisinage, rd20, qui peut être utilisée pour quantifier les effets de voisinage sur des espaces d'entités arbitraires. Nous calculons le rd20 sur de grands ensembles de mots en trois langues à l'aide de différents ensembles de caractéristiques et montrons que les ensembles de caractéristiques qui ne permettent pas la transposition ou la suppression expliquent plus de variance dans les mesures du temps de réaction (RT). Nous montrons également que le rd20 peut être calculé à l'aide des représentations d'état cachées d'un perceptron multicouche, et montrons que celles-ci expliquent moins de variance que les entités brutes. Nous concluons qu'il est peu probable que l'effet de voisinage ait une base perceptuelle, mais qu'il est plus susceptible d'être le résultat de la co-activation d'objets après la reconnaissance. Tous les codes sont disponibles à l'adresse suivante\xa0: <www.github.com/clips/conll2018>", 'pt': 'Investigamos a relação entre os efeitos de transposição e exclusão na leitura de palavras, ou seja, a descoberta de que os leitores podem ler com sucesso “SLAT” como “SALT”, ou “WRK” como “WORK”, e o efeito de vizinhança. Em particular, investigamos se as vizinhanças ortográficas lexicais levam em conta a transposição e a exclusão na determinação de vizinhos. Se este for o caso, é mais provável que o efeito de vizinhança ocorra no início do processamento e não dependa apenas da similaridade das representações internas. Introduzimos uma nova medida de vizinhança, rd20, que pode ser usada para quantificar efeitos de vizinhança sobre espaços de características arbitrárias. Calculamos o rd20 em grandes conjuntos de palavras em três idiomas usando vários conjuntos de recursos e mostramos que conjuntos de recursos que não permitem transposição ou exclusão explicam mais variação nas medições do Tempo de Reação (RT). Também mostramos que o rd20 pode ser calculado usando as representações de estado oculto de um Multi-Layer Perceptron, e mostramos que elas explicam menos variância do que os recursos brutos. Concluímos que é improvável que o efeito de vizinhança tenha uma base perceptiva, mas é mais provável que seja o resultado de itens co-ativados após o reconhecimento. Todo o código está disponível em: <www.github.com/clips/conll2018>', 'es': 'Investigamos la relación entre los efectos de transposición y eliminación en la lectura de palabras, es decir, el hallazgo de que los lectores pueden leer con éxito «SLAT» como «SAL», o «WRK» como «TRABAJO», y el efecto vecindad. En particular, investigamos si los barrios ortográficos léxicos tienen en cuenta la transposición y la eliminación al determinar los vecinos. Si este es el caso, es más probable que el efecto vecindad se produzca al principio del procesamiento y no se base únicamente en la similitud de las representaciones internas. Presentamos una nueva medida de vecindad, rd20, que se puede utilizar para cuantificar los efectos de vecindad sobre espacios de entidades arbitrarios. Calculamos el rd20 sobre grandes conjuntos de palabras en tres idiomas utilizando varios conjuntos de características y mostramos que los conjuntos de características que no permiten la transposición o eliminación explican más la varianza en las mediciones del tiempo de reacción (RT). También mostramos que el rd20 se puede calcular utilizando las representaciones de estado ocultas de un perceptrón multicapa, y demostramos que estas explican menos varianza que las entidades sin procesar. Concluimos que es poco probable que el efecto vecindad tenga una base perceptiva, pero es más probable que sea el resultado de la coactivación de los elementos después del reconocimiento. Todos los códigos están disponibles en: <www.github.com/clips/conll2018>', 'ja': '我々は、単語読解における転置効果と欠失効果、すなわち、読者が「スラット」を「塩」、または「WRK」を「作業」として正常に読むことができるという知見と、近傍効果との関係を調査する。 特に、語彙的正書法の近傍が、近傍を決定する際に転置と削除を考慮しているかどうかを調査する。 この場合、近隣効果は処理中に早期に発生する可能性が高く、内部表現の類似性にのみ依存しない。 任意の特徴空間上の近傍効果を定量化するために使用できる新しい近傍メジャー、rd 20を導入します。 我々は、様々な特徴セットを使用して、３つの言語の大規模な単語セットにわたるrd 20を計算し、転置または欠失を許さない特徴セットが、反応時間（ RT ）測定におけるより多くの分散を説明することを示している。 また、rd 20は多層パーセプトロンの隠れた状態表現を使用して計算することができ、これらは生の特徴よりも分散が少ないことを説明することが示されています。 近傍効果は知覚的根拠を持つ可能性は低いが、認識後に共活性化された項目の結果である可能性が高いと結論づけた。 すべてのコードは次の場所で利用できます。 <www.github.com/clips/conll2018>', 'hi': 'हम शब्द पढ़ने में ट्रांसपोज़िशन और विलोपन प्रभावों के बीच संबंध की जांच करते हैं, यानी, यह पता लगाना कि पाठक सफलतापूर्वक "एसएलएटी" को "SALT" के रूप में पढ़ सकते हैं, या "WRK" को "WORK" के रूप में, और पड़ोस प्रभाव। विशेष रूप से, हम जांच करते हैं कि क्या लेक्सिकल ऑर्थोग्राफिक पड़ोस पड़ोसियों को निर्धारित करने में स्थानांतरण और विलोपन को ध्यान में रखते हैं। यदि यह मामला है, तो यह अधिक संभावना है कि पड़ोस का प्रभाव प्रसंस्करण के दौरान जल्दी होता है, और केवल आंतरिक प्रतिनिधित्व की समानता पर भरोसा नहीं करता है। हम एक नया पड़ोस उपाय, rd20 पेश करते हैं, जिसका उपयोग मनमाने ढंग से सुविधा रिक्त स्थान पर पड़ोस के प्रभावों को मापने के लिए किया जा सकता है। हम विभिन्न सुविधा सेटों का उपयोग करके तीन भाषाओं में शब्दों के बड़े सेटों पर rd20 की गणना करते हैं और दिखाते हैं कि फीचर सेट जो ट्रांसपोज़िशन या विलोपन की अनुमति नहीं देते हैं, प्रतिक्रिया समय (आरटी) माप में अधिक विचरण की व्याख्या करते हैं। हम यह भी दिखाते हैं कि rd20 की गणना एक मल्टी-लेयर परसेप्ट्रॉन के छिपे हुए राज्य प्रतिनिधित्व का उपयोग करके की जा सकती है, और दिखाती है कि ये कच्ची सुविधाओं की तुलना में कम विचरण की व्याख्या करते हैं। हम निष्कर्ष निकालते हैं कि पड़ोस प्रभाव में अवधारणात्मक आधार होने की संभावना नहीं है, लेकिन मान्यता के बाद सह-सक्रिय होने वाली वस्तुओं का परिणाम होने की अधिक संभावना है। सभी कोड पर उपलब्ध है: <www.github.com/clips/conll2018>', 'ru': 'Мы исследуем взаимосвязь между эффектами транспозиции и делеции при чтении слов, то есть вывод о том, что читатели могут успешно читать “SLAT” как “SALT”, или “WRK” как “WORK”, и эффектом соседства. В частности, мы исследуем, учитывают ли лексические орфографические окружения транспозицию и делецию при определении соседей. Если это так, то более вероятно, что эффект соседства происходит на ранней стадии обработки и не основывается исключительно на сходстве внутренних представлений. Мы вводим новую меру соседства, rd20, которая может быть использована для количественной оценки эффектов соседства для произвольных пространств признаков. Мы вычисляем rd20 для больших наборов слов на трех языках, используя различные наборы признаков, и показываем, что наборы признаков, которые не позволяют транспонировать или удалить, объясняют большую дисперсию в измерениях времени реакции (RT). Мы также показываем, что rd20 может быть рассчитан с использованием скрытых представлений состояния многослойного перцептрона, и показываем, что они объясняют меньшую дисперсию, чем необработанные признаки. Мы пришли к выводу, что эффект соседства вряд ли будет иметь перцептивную основу, но, скорее всего, будет результатом коактивации элементов после распознавания. Весь код доступен по адресу: <www.github.com/clips/conll2018>', 'zh': '臣等考单词读中转置、删效应之际,即读者可以成SLAT读作"SALT",或"WRK"读作"WORK",及邻域效应。 然则论词法正交邻域定邻域时虑转位阙失也。 如此,则更有处理过程早期之邻域,非独内相似性也。 引入新邻域 rd20,量化任素邻域应。 余以诸特征集计三语大单词集之rd20,并明不许转置删者反应时间(RT)测量更多方差。 又明rd20可以重感知器隐数,明小于方差也。 吾论之,邻域不太可能有感知之基,而物在知激活也。 凡代码皆在<www.github.com/clips/conll2018>', 'ga': 'Déanaimid imscrúdú ar an ngaol idir na héifeachtaí trasuímh agus scriosta sa léitheoireacht focal, i.e., an cinneadh gur féidir le léitheoirí “SLAT” a léamh go rathúil mar “SALT”, nó “WRK” mar “OBAIR”, agus an éifeacht chomharsanachta. Go háirithe, déanaimid imscrúdú an gcuireann comharsanachtaí ortagrafacha foclóireachta trasuí agus scriosadh san áireamh agus comharsana á gcinneadh. Más é seo an cás, is dóichí go dtarlaíonn an éifeacht comharsanachta go luath le linn na próiseála, agus nach mbraitheann sé go hiomlán ar chomhchosúlacht na n-uiríll inmheánacha. Tugaimid isteach beart comharsanachta nua, rd20, ar féidir a úsáid chun éifeachtaí comharsanachta thar spásanna gné treallach a chainníochtú. Ríomhaimid an rd20 thar thacair mhóra focal i dtrí theanga ag baint úsáide as tacair gnéithe éagsúla agus léirímid go míníonn tacair gnéithe nach gceadaíonn trasuí nó scriosadh níos mó éagsúlachta i dtomhais Am Frithghníomhaithe (RT). Léirímid freisin gur féidir an rd20 a ríomh trí úsáid a bhaint as léirithe stáit fholaithe Perceptron Ilshraith, agus léirímid go míníonn siad seo níos lú éagsúlachta ná na gnéithe amh. Bainimid de thátal as nach dócha go mbeidh bunús aireachtála leis an éifeacht chomharsanachta, ach gur dóichí go mbeidh sé mar thoradh ar mhíreanna a chomhghníomhaíonn tar éis aitheantais. Tá gach cód ar fáil ag: <www.github.com/clips/conll2018>', 'ka': "ჩვენ განსხვავებთ ტრანსპოზაციის და წაშლა ეფექტის შესახებ სიტყვების წაშლაში, რაც იგივეა, რომ საკითხველი შეუძლიათ წაშლა 'SLAT' როგორც 'SALT', ან 'WRK' როგორც 'WORK', და გაზრუნობის ეფე განსაკუთრებულია, ჩვენ განსხვავებთ თუ ლექსიკალური ორტოგრაფიკური საზოგადოებში ტრანსპოზაცია და წაშლა საზოგადოებში. თუ ეს არის შემთხვევაში, უფრო შესაძლებელია, რომ საზოგადოებო ეფექტი იქნება წინ პროცესის განმავლობაში, და არა მხოლოდ მხოლოდ იქნება ინტერესტრაციების სხვადასხვ ჩვენ შევაჩვენეთ ახალი საზოგადოებო განზომილება, rd20, რომელიც შეიძლება გამოყენება საზოგადოებო ეფექტის კვანტიფიკაციისთვის განზომილებელი განზომილებ ჩვენ rd20-ს გამოყენებთ სამი ენაში სიტყვის ძალიან დიდი სიტყვის გამოყენებული განსხვავებული ფუნქციების კონფიგურაციაში და ჩვენ ჩვენებთ, რომ ფუნქციების კონფიგურაციის კონფიგურაციის ჩვენ ასევე ჩვენ აჩვენებთ, რომ rd20-ს შეიძლება გამოყენება მრავალ-Layer პერსექტრონის დახურებილი სტატუსების გამოყენებით და გამოჩვენება, რომ ეს განსხვავება უფრო ცოტა განსხვ ჩვენ გავაკეთებთ, რომ საზოგადოებო ეფექტი არ შეიძლება აღმოჩენოთ აღმოჩენების ბაზა, მაგრამ უფრო შესაძლებელია იყოს საზოგადოებო ელემენტების შედეგი, რო ყველა კოდის შესაძლებელია: <www.github. com/clips/conll2018>", 'el': 'Ερευνούμε τη σχέση μεταξύ των επιπτώσεων μεταφοράς και διαγραφής στην ανάγνωση λέξεων, δηλαδή της διαπίστωσης ότι οι αναγνώστες μπορούν να διαβάσουν επιτυχώς το "SLAT" ως "SALT", ή το "WRK" ως "εργασία", και το φαινόμενο γειτονιάς. Ειδικότερα, διερευνούμε εάν οι λεξικές ορθογραφικές γειτονιές λαμβάνουν υπόψη τη μεταφορά και διαγραφή στον προσδιορισμό γειτόνων. Εάν αυτό συμβαίνει, είναι πιο πιθανό ότι η επίδραση γειτονιάς λαμβάνει χώρα νωρίς κατά τη διάρκεια της επεξεργασίας και δεν βασίζεται αποκλειστικά στην ομοιότητα των εσωτερικών αναπαραστάσεων. Εισάγουμε ένα νέο μέτρο γειτονιάς, το οποίο μπορεί να χρησιμοποιηθεί για να ποσοτικοποιήσει τις επιπτώσεις γειτονιάς σε αυθαίρετους χώρους χαρακτηριστικών. Υπολογίζουμε το RD20 σε μεγάλα σύνολα λέξεων σε τρεις γλώσσες χρησιμοποιώντας διάφορα σύνολα χαρακτηριστικών και δείχνουν ότι τα σύνολα χαρακτηριστικών που δεν επιτρέπουν μεταφορά ή διαγραφή εξηγούν μεγαλύτερη διακύμανση στις μετρήσεις του χρόνου αντίδρασης (RT). Δείχνουμε επίσης ότι το rd20 μπορεί να υπολογιστεί χρησιμοποιώντας τις κρυφές αναπαραστάσεις κατάστασης ενός πολυστρωματικού Perceptron, και δείχνουν ότι αυτές εξηγούν λιγότερη διακύμανση από τα ακατέργαστα χαρακτηριστικά. Συμπεραίνουμε ότι το φαινόμενο της γειτονιάς είναι απίθανο να έχει αντιληπτική βάση, αλλά είναι πιο πιθανό να είναι αποτέλεσμα της συνανεργοποίησης αντικειμένων μετά την αναγνώριση. Όλος ο κώδικας είναι διαθέσιμος στο: <www.github. com/clips/conll2018>', 'hu': 'Vizsgáljuk a szóolvasás átültetési és törlési hatásai közötti kapcsolatot, azaz azt a megállapítást, hogy az olvasók sikeresen olvashatják a "SLAT" mint "SALT", vagy a "WRK" mint "WORK", valamint a környéki hatást. Különösen azt vizsgáljuk, hogy a lexikai ortográfiai környékek figyelembe veszik-e az átültetést és törlést a szomszédok meghatározásakor. Ebben az esetben valószínűbb, hogy a szomszédsági hatás a feldolgozás során korán bekövetkezik, és nem kizárólag a belső ábrázolások hasonlóságára támaszkodik. Bevezetünk egy új szomszédsági intézkedést, az rd20-at, amelynek segítségével számszerűsíthető a környéki hatások tetszőleges funkcióterületeken. Az rd20-at három nyelven számítjuk ki nagy szavakészletekkel, különböző funkciókészletekkel, és megmutatjuk, hogy az átültetést vagy törlést nem engedélyező funkciókészletek nagyobb eltérést magyaráznak a reakcióidő (RT) méréseiben. Azt is megmutatjuk, hogy az rd20 kiszámítható egy többrétegű perceptron rejtett állapotábrázolásával, és megmutatjuk, hogy ezek kisebb eltérést magyaráznak, mint a nyers funkciók. Arra a következtetésre jutunk, hogy a szomszédsági hatás valószínűleg nem lesz észlelési alapja, de valószínűbb, hogy a felismerés után együtt aktiválódó elemek eredménye. Minden kód elérhető a következő címen: <www.github. com/clips/conll2018>', 'it': "Investighiamo la relazione tra gli effetti di trasposizione e cancellazione nella lettura di parole, cioè la scoperta che i lettori possono leggere con successo 'SLAT' come 'SALT', o 'WRK' come 'WORK', e l'effetto di vicinato. In particolare, esaminiamo se i quartieri ortografici lessicali tengano conto della trasposizione e della cancellazione nel determinare i vicini. Se questo è il caso, è più probabile che l'effetto di prossimità si verifichi presto durante l'elaborazione e non si basi esclusivamente sulla somiglianza delle rappresentazioni interne. Introducemo una nuova misura di quartiere, rd20, che può essere utilizzata per quantificare gli effetti di quartiere su spazi di funzionalità arbitrari. Calcoliamo l'rd20 su grandi set di parole in tre lingue utilizzando vari set di funzionalità e mostriamo che i set di funzionalità che non consentono la trasposizione o la cancellazione spiegano una maggiore varianza nelle misurazioni del Tempo di Reazione (RT). Mostriamo anche che l'rd20 può essere calcolato utilizzando le rappresentazioni di stato nascoste di un Perceptron Multi-Layer, e mostriamo che queste spiegano meno varianza rispetto alle caratteristiche raw. Concludiamo che è improbabile che l'effetto di quartiere abbia una base percettiva, ma è più probabile che sia il risultato di elementi che si attivano dopo il riconoscimento. Tutto il codice è disponibile all'indirizzo: <www.github. com/clips/conll2018>", 'kk': "Біз сөздерді оқу үшін транспозиция және өшіру эффекттерінің арасындағы қатынасын зерттейміз, яғни оқу оқушылары сәтті 'SLAT' деп 'SALT' деп 'WRK' деп 'WORK' деп және айырмалы эффект деп оқуға болады Әрине, біз лексикалық ортографикалық айырмаларының ауырмаларының транспозициясы мен өшірілгенін тексереміз. Егер бұл жағдай болса, көңіл эффекті өзгерту кезінде бастап жатқан болуы мүмкін, және тек ішкі келтірулердің ұқсастығына сенбейді. Біз жаңа айырмалық өлшемі, rd20 дегенді таңдаймыз. Бұл айырмалық қасиеттер бос орындарына көбейту үшін қолданылады. Біз rd20- ді үш тілде үлкен сөздерді есептеп, әртүрлі мүмкіндіктерді қолданып, транспорттау не өшіруге рұқсат етпейтін мүмкіндіктердің баптауларын көрсетуге болады. Реакциялау уақыты (RT)  Біз сондай-ақ rd20 дегенді көптеген қабатты перспектрондың жасырын күйін есептеп бере аламыз. Бұл көптеген қабатты өзгерістерінен аз түсіндіре аламыз. Біз айырмашылық эффектінің түсінікті негізі болмауы мүмкін емес, бірақ түсініктен кейінгі нәтижелердің нәтижесі болуы мүмкін. Барлық код: <www.github. com/clips/conll2018>", 'ms': "Kami menyelidiki hubungan antara kesan penerbangan dan pemadaman dalam pembacaan perkataan, iaitu penemuan bahawa pembaca boleh membaca 'SLAT' dengan sukses sebagai 'SALT', atau 'WRK' sebagai 'WORK', dan kesan lingkungan. Secara khususnya, kita menyelidiki sama ada lingkungan ortografik leksikal mempertimbangkan penerbangan dan pemadaman dalam menentukan jiran. If this is the case, it is more likely that the neighborhood effect takes place early during processing, and does not solely rely on similarity of internal representations.  Kami memperkenalkan ukuran kejiranan baru, rd20, yang boleh digunakan untuk kuantifikasi kesan kejiranan atas ruang ciri-ciri arbitrari. Kami menghitung rd20 atas set perkataan besar dalam tiga bahasa menggunakan set ciri-ciri berbeza dan menunjukkan set ciri-ciri yang tidak membenarkan penerbangan atau pemadaman menjelaskan lebih banyak variasi dalam pengukuran Masa Reaksi (RT). Kami juga menunjukkan bahawa rd20 boleh dihitung dengan menggunakan perwakilan keadaan tersembunyi bagi Perceptron Berlipat Lapisan, dan menunjukkan bahawa ini menjelaskan kurang variasi daripada ciri-ciri mentah. Kami menyimpulkan bahawa kesan lingkungan tidak mungkin mempunyai asas persepsi, tetapi lebih kemungkinan menjadi hasil item yang menyaktifkan selepas pengenalan. Semua kod tersedia di: <www.github. com/clips/conll2018>", 'lt': 'Mes tiriame santykį tarp perkėlimo į nacionalinę teisę ir i šbraukimo poveikio skaitant žodžius, t. y. išvados, kad skaitytojai sėkmingai gali skaityti "SLAT" kaip "SALT" arba "WRK" kaip "WORK" ir kaimynystės poveikį. Visų pirma mes tiriame, ar nustatant kaimynus atsižvelgiama į perkėlimą į nacionalinę teisę ir išbraukimą. Tokiu atveju labiau tikėtina, kad apdorojimo metu kaimynystės poveikis vyks anksti, o ne tik priklauso nuo vidaus atstovų panašumo. Įvedame naują kaimynystės priemonę, rd20, kuri gali būti naudojama kaimynystės poveikiui įvertinti savavališkose savivaldybės erdvėse. Apskaičiuojame rd20 per didelius žodžių rinkinius trimis kalbomis naudojant įvairius savybių rinkinius ir rodome, kad savybių rinkinius, kurie neleidžia perkelti į nacionalinę teisę arba išbraukti, paaiškina daugiau reakcijos laiko (RT) matavimų skirtumų. Taip pat rodome, kad rd20 galima apskaičiuoti naudojant slaptą daugiasluoksnio Perceptrono pavidalą, ir rodome, kad tai paaiškina mažiau skirtumo nei žaliavinės savybės. Mes darome išvadą, kad kaimynystės poveikis greičiausiai neturės apčiuopiamo pagrindo, bet greičiausiai bus rezultatas, kai po pripažinimo elementai bendrai aktyvuojami. Visi kodai pateikiami: <www.github. com/clips/conll2018>', 'mk': 'Ние ја истражуваме врската помеѓу преносот и ефектите на избришување во читањето на зборови, односно откритието дека читателите успешно можат да го читаат „СЛАТ“ како „САЛТ“ или „ВРК“ како „РАБА“ и ефектот на соседството. Особено, истражуваме дали лексикалните ортографски соседи земаат предвид транспирање и бришење во одредувањето на соседите. If this is the case, it is more likely that the neighborhood effect takes place early during processing, and does not solely rely on similarity of internal representations.  Ние воведуваме нова соседска мерка, rd20, која може да се користи за квантификување на соседските ефекти над арбитралните простори. Го пресметаме rd20 над големите групи зборови на три јазици користејќи различни групи карактеристики и покажуваме дека групите карактеристики кои не дозволуваат транспорција или бришење објаснуваат повеќе варијанци во мерувањата на времето на реакција (РТ). We also show that the rd20 can be calculated using the hidden state representations of an Multi-Layer Perceptron, and show that these explain less variance than the raw features.  Завршуваме дека ефектот на соседството најверојатно нема да има перцептуална основа, но најверојатно ќе биде резултат на коактивирање на предметите по препознавањето. Сите кодови се достапни на: <www.github. com/clips/conll2018>', 'ml': "വാക്ക് വായിക്കുന്നതില്\u200d നിന്നും നീക്കം ചെയ്യുന്ന ബന്ധങ്ങള്\u200dക്കും തമ്മിലുള്ള ബന്ധം നാം അന്വേഷിക്കുന്നു. അതായത് വായിക്കുന്നവര്\u200dക്ക് 'സാലാറ്റ്' എന്നോ  പ്രത്യേകിച്ച്, നമ്മള്\u200d അന്വേഷിക്കുന്നത് ലെക്സിക്കല്\u200d ഓര്\u200dട്ടോഗ്രാഫിക് അയല്\u200dക്കാരുടെ നിര്\u200dണ്ണയിക്കുന്നതില ഇതാണെങ്കില്\u200d അയല്\u200dവാസികളുടെ പ്രഭാവം പ്രക്രിയയില്\u200d നേരത്തെ സംഭവിക്കുമെന്ന് സാധ്യതയുണ്ടെങ്കില്\u200d അകത്തുള്ള പ്രതിനിധ നമ്മള്\u200d ഒരു പുതിയ അയല്\u200dക്കാരുടെ അളവുകള്\u200d പരിചയപ്പെടുത്തിയിരിക്കുന്നു, ആര്\u200dട്ടി20, അത് അയല്\u200dക്കാരുടെ പ്രഭാവികങ്ങള വിവിധ വിശേഷസജ്ജീകരണങ്ങള്\u200d ഉപയോഗിച്ച് മൂന്നു ഭാഷകളില്\u200d കൂടുതല്\u200d വാക്കുകള്\u200d എടുക്കുന്നുണ്ടാക്കുന്നതിനായി ഞങ്ങള്\u200d എടുക്കുന്നു. റിക്ഷന നമ്മളും കാണിക്കുന്നുണ്ടെന്ന് നമ്മള്\u200d കാണിച്ചിരിക്കുന്നു, മറഞ്ഞ രാജ്യത്തിന്റെ പ്രതിനിധികള്\u200d ഉപയോഗിച്ച് മറഞ്ഞിരിക്കുന്ന ര അയല്\u200dക്കാരുടെ പ്രഭാവം കാണാന്\u200d സാധ്യതയില്ലെന്ന് നമ്മള്\u200d തീരുമാനിക്കുന്നു. പക്ഷെ തിരിച്ചറിയുന്നതിനു ശേഷം ഇനങ്ങള്\u200d സഹ All code is available at: <www.github. com/clips/conll2018>", 'mt': "Aħna ninvestigaw ir-relazzjoni bejn l-effetti tat-traspożizzjoni u t-tħassir fil-qari tal-kliem, jiġifieri s-sejba li l-qarrejja jistgħu jaqraw b'suċċess 'SLAT' bħala 'SALT', jew 'WRK' bħala 'XOGĦOL', u l-effett tal-viċinat. In particular, we investigate whether lexical orthographic neighborhoods take into account transposition and deletion in determining neighbors.  Jekk dan ikun il-każ, huwa aktar probabbli li l-effett tal-viċinat iseħħ kmieni matul l-ipproċessar, u ma jiddependix biss fuq similarità tar-rappreżentazzjonijiet interni. Aħna nintroduċu miżura ġdida tal-viċinat, rd20, li tista’ tintuża biex jiġu kkwantifikati l-effetti tal-viċinat fuq spazji b’karatteristiċi arbitrarji. Ikkalkulaw l-rd20 fuq settijiet kbar ta’ kliem fi tliet lingwi bl-użu ta’ settijiet varji ta’ karatteristiċi u nuru li settijiet ta’ karatteristiċi li ma jippermettux traspożizzjoni jew tħassir jispjegaw aktar varjanza fil-kejl tal-Ħin tar-Reazzjoni (RT). Aħna nuru wkoll li l-rd20 jista’ jiġi kkalkulat bl-użu tar-rappreżentazzjonijiet moħbija tal-istat ta’ Perċettur Multisaff, u nuru li dawn jispjegaw inqas varjanza mill-karatteristiċi mhux ipproċessati. Aħna kkonkludew li x’aktarx li l-effett tal-viċinat mhux se jkollu bażi perċettwali, iżda x’aktarx li jkun ir-riżultat ta’ oġġetti li jikkoattivaw wara r-rikonoxximent. Il-kodiċi kollu huwa disponibbli fuq: <www.github. com/clips/conll2018>", 'pl': 'Badamy związek pomiędzy efektami transpozycji i usuwania w odczycie słów, tj. stwierdzeniem, że czytelnicy mogą z powodzeniem odczytać "SLAT" jako "SALT", lub "WRK" jako "WORK", a efektem sąsiedztwa. W szczególności badamy, czy leksykalne sąsiedztwa ortograficzne uwzględniają transpozycję i usuwanie w określaniu sąsiadów. W takim przypadku jest bardziej prawdopodobne, że efekt sąsiedztwa następuje na wczesnym etapie przetwarzania i nie polega wyłącznie na podobieństwie wewnętrznych reprezentacji. Wprowadzamy nową miarę sąsiedztwa rd20, która może być wykorzystana do ilościowego określenia efektów sąsiedztwa na dowolnych przestrzeniach cech. Obliczamy rd20 na dużych zestawach słów w trzech językach przy użyciu różnych zestawów funkcji i pokazujemy, że zestawy cech, które nie pozwalają na transpozycję lub usunięcie, wyjaśniają większą wariancję w pomiarach czasu reakcji (RT). Pokazujemy również, że rd20 można obliczyć za pomocą ukrytych reprezentacji stanu Perceptrona wielowarstwowego i pokazujemy, że wyjaśniają one mniejszą wariancję niż cechy surowe. Wnioskujemy, że efekt sąsiedztwa jest mało prawdopodobne, aby miał podstawę percepcyjną, ale jest bardziej prawdopodobne, że będzie wynikiem współaktywacji przedmiotów po rozpoznaniu. Cały kod jest dostępny pod adresem: <www.github. com/clips/conll2018>', 'ro': 'Investigăm relația dintre efectele de transpunere și ștergere în citirea cuvintelor, adică constatarea că cititorii pot citi cu succes "SLAT" ca "SALT", sau "WRK" ca "WORK", și efectul de vecinătate. În special, investigăm dacă cartierele ortografice lexicale iau în considerare transpunerea și ștergerea în determinarea vecinilor. În acest caz, este mai probabil ca efectul de vecinătate să aibă loc devreme în timpul procesării și nu se bazează numai pe similaritatea reprezentărilor interne. Introducem o nouă măsură de cartier, rd20, care poate fi folosită pentru a cuantifica efectele de cartier asupra spațiilor caracteristici arbitrare. Calculăm rd20 pe seturi mari de cuvinte în trei limbi folosind diferite seturi de caracteristici și arătăm că seturile de caracteristici care nu permit transpunerea sau ștergerea explică mai multe variații în măsurătorile timpului de reacție (RT). De asemenea, arătăm că rd20 poate fi calculat folosind reprezentările ascunse ale stării unui Perceptron Multi-Layer și arătăm că acestea explică mai puțină varianță decât caracteristicile raw. Concluzionăm că este puțin probabil ca efectul de vecinătate să aibă o bază perceptuală, dar este mai probabil să fie rezultatul unei activări a elementelor după recunoaștere. Tot codul este disponibil la: <www.github. com/clips/conll2018>', 'no': 'Vi undersøker forholdet mellom transposisjonen og slettingseffektane i ordlesing, t.d. oppdaginga at lesarar kan lesa « SLAT » som « SALT », eller « WRK » som « WORK », og nærleiken. I særskilt er vi undersøk om leksiske ortografiske nabolar tar inn i kontoen transposisjon og sletting i avgjering av nabolar. Dersom dette er tilfellet, er det mest sannsynleg at naboeeffekten går tidlegare under handlinga, og ikkje berre rely på liknande interne representasjonar. Vi introduserer eit nytt nabootsmål, rd20, som kan brukast til å kvantisera nabootseffektar over tilfeldige funksjonsmellomrom. Vi reknar ut rd20 over store ord i tre språk med ulike funksjonssett og viser at funksjonssett som ikkje tillater å transposera eller sletta forklarer meir varianse i målingar av reaksjonstid (RT). Vi viser også at rd20 kan rekna ut med dei gøymde representasjonane av eit fleire lag prosentron, og viser at desse forklarer mindre varianse enn dei råeigenskapane. Vi avsluttar at naboeeffekten er ikkje sannsynlegvis å ha ein oppfattig grunnlag, men er sannsynleg at det er resultatet av elementa som samarbeider etter gjenkjenning. Alle kodar er tilgjengeleg på: <www.github. com/clips/conll2018>', 'mn': "Бид үг унших болон устгах нөлөөний хоорондын харилцааныг судалж, яг л уншигчид амжилттай 'SLAT', 'SALT', 'WRK', 'WORK' болон хөршүүн нөлөө гэж уншиж чадна. Ялангуяа бид хэлэлцэх ортографик хөршүүд хөршүүдийг тодорхойлох болон устгах эсэхийг судалж байна. Хэрвээ ийм байвал, хөршүүн нөлөө үйлдвэрлэлийн үед эрт үргэлжлүүлж, дотоод харилцааны төстэй адилхан байх боломжгүй. Бид хөршүүн шинэ хэмжээг, rd20 гэдгийг танилцуулдаг. Энэ нь хөршүүн нөлөөлөлийг өөрсдийгөө өөрсдийгөө өөрсдийгөө тодорхойлж чадна. Бид rd20-г гурван хэл дээр олон тоо хэлбэрээр тооцоолж, өөр өөр өөр өөрчлөлтийг ашиглаж, транспорт эсвэл устгах боломжгүй өөрчлөлтийг харуулж байна. Мөн бид rd20-г олон давхар хувилбарын нууцтай байдал ашиглан тооцоолж болох бөгөөд эдгээр нь бага өөрчлөлт гэдгийг харуулж байна. Бид хөршүүн нөлөө нь ойлголтын үндсэн байж магадгүй гэхдээ илүү ойлголтын үр дүн нь ойлголтын дараа холбоотой байж магадгүй. Бүх код: <www.github. com/clips/conll2018>", 'so': "Waxaan baaraynaa xiriirka u dhexeeya gaadiidka iyo dhaqaalaha waxyaabaha lagu akhriyo hadalka, tusaale ahaan baaritaanka kuwa akhriyaya waxay succeeded u akhriyi karaan 'SLAT' ama 'WRK' sida'WORK', iyo saamaynta deriska ah. Si gaar ah, waxaynu baaraynaa in degmooyinka jimicsiga ah ay xisaabiyaan gaadiidka iyo baaritaanka derisyada go’aanka. Haddii ay xaaladdu tahay, waxaa suurtagal ah in saameyn ugu horeysa marka lagu baaraandegayo qofka deriska ah uusan ku kalsoonaanin siman wakiilada gudaha. Waxaynu soo bandhignaa qiyaastii cusub ee degmada, rd20, kaas oo loo isticmaali karo si loo qiyaaso saamaynta degmada ee meelaha la sharciyeeyo. Waxaynu xisaabinaynaa rd20 oo ka badan hadal badan oo saddex luqadood ku qoran isticmaalka koonfureed oo kala duduwan, waxaana tusaynaa in gaar ah oo aan u oggolaan in lagu qaado ama la deleto ay faa'iido ka sii bedelaan qiyaastii wakhtiga Reaction (RT). Sidoo kale waxaynu tusnaynaa in rd20 lagu xisaabin karo wadamada qarsoon ee la isticmaali karo xarunta Perceptron oo badan, waxaana tusinaynaa in ay caddayso kala duwanaansho ka yar yihiin xuquuqda khaas ah. Waxaynu ka heshiinnay in saamaynta deriska looma suurtowdo inuu haysto qof arag leh, laakiin waxaa suurtagal ah inay ahaato arimaha la wada shaqeeya marka la aqoonsado kadib. Qorada oo dhan waxaa laga helaa: <www.github. com/clips/conll2018>", 'sv': 'Vi undersöker relationen mellan transponerings- och raderingseffekterna vid ordläsning, dvs. upptäckten att läsarna framgångsrikt kan läsa SLAT som SALT, eller WRK som ARBETE, och grannskapseffekten. I synnerhet undersöker vi om lexikala ortografiska kvarter tar hänsyn till transponering och radering vid bestämning av grannar. Om så är fallet är det mer sannolikt att grannskapseffekten inträffar tidigt under behandlingen och inte enbart bygger på likheter mellan interna representationer. Vi introducerar en ny grannskapsåtgärd, rd20, som kan användas för att kvantifiera grannskapseffekter över godtyckliga funktionsutrymmen. Vi beräknar rd20 över stora orduppsättningar på tre språk med hjälp av olika funktionsuppsättningar och visar att funktionsuppsättningar som inte tillåter transponering eller radering förklarar mer varians i reaktionstidsmätningar (RT). Vi visar också att rd20 kan beräknas med hjälp av dolda tillståndsrepresentationer av en Multi-Layer Perceptron, och visar att dessa förklarar mindre varians än de råa funktionerna. Vi drar slutsatsen att grannskapseffekten är osannolikt att ha en perceptuell grund, men är mer sannolikt att vara resultatet av objekt som samaktiveras efter erkännande. All kod finns tillgänglig på: <www.github. com/clips/conll2018>', 'sr': "Istražujemo odnos između transpozicije i izbrisanja efekta u èitanju reèi, to je pronalaženje da čitači mogu uspešno čitati 'SLAT' kao 'SALT', ili 'WRK' kao 'WORK', i učinak susjedstva. Posebno, istražujemo da li leksički ortografski susjedi uzimaju u obzir transpoziciju i izbrisanje u određivanju susjeda. Ako je to slučaj, verovatnije se učinak susjedstva događa ranije tokom obrade, i ne oslanja se samo na sličnost unutrašnjih predstavljanja. Predstavljamo novu mjeru susjedstva, rd20, koja se može koristiti za kvantifikaciju efekta susjedstva na proizvodnim prostorijama. Izračunamo rd20 preko velikih seta reči na tri jezika koristeći različite setove karakteristike i pokazujemo da setovi koje ne dozvoljavaju da se transponišu ili dele objašnjavaju više varijansa u mjerenjima reakcijnog vremena (RT). Takođe pokazujemo da se rd20 može izračunati uz skriveno stanje predstavljanja višeslojnog proceptra, i pokazujemo da se to objašnjava manje varijansa od sirovih karakteristika. Zaključili smo da učinak susjedstva nije vjerojatno da ima perceptualnu osnovu, ali vjerojatno će biti rezultat predmeta koji sarađuju nakon priznanja. Svi kod su dostupni na: <www.github. com/clips/conll2018>", 'si': "අපි පරීක්ෂණය කරන්නේ වාර්තාව කියවන අතර සම්බන්ධය අතර සම්බන්ධය, ඉතින්, කියවන්නේ කියවන්නේ කියවන්නේ සමහරවිට 'SLAT' කියවන්න පුළුවන් 'SALT', නැ විශේෂයෙන්, අපි පරීක්ෂණය කරන්නේ ලෙක්සිකාල් වර්තෝග්\u200dරාෆික් පාර්ශික පාර්ශික වලින් පරීක්ෂණය සහ මර මේක ප්\u200dරශ්නයක් තියෙනවනම්, ඒක තරම් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පටන් ගන්න පුළුවන් වෙනවා, ඒ වගේම ඇතුළු ප්\u200dරශ්නයක අපි අළුත් අයිතුරු මාර්ගයක් පෙනුම් කරනවා, rd20, ඒක ප්\u200dරයෝජනය කරන්න පුළුවන් අයිතුරු ප්\u200dරතිකාරයක් සාමාන්\u200dය අපි භාෂාව තුනක් භාෂාවේ විශේෂ සෙට් භාවිත කරලා rd20 විශේෂ කරනවා සහ පෙන්වන්න පුළුවන් විශේෂ සෙට් සඳහා පෙන්වන්න පුළ අපිට පෙන්වන්න පුළුවන් විදිහට rd20 විශේෂ කරන්න පුළුවන් විදිහට වඩා වර්ගයක් තියෙන්නේ වර්ගයක් තියෙන ස්ථානය ප්\u200dරති අපි අවස්ථාව කරනවා කියලා පිටිපස්සේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ නැහැ, ඒත් ප්\u200dරශ්නයක් තියෙන්න පස්සේ සම්බන සියළුම කෝඩ් අවස්ථාවක් තියෙනවා: <www.guiHu. com/clips/Conll2018>", 'ur': "ہم کلمات پڑھنے میں ترنسپوسیٹ اور حذف کے اثرات کے درمیان رابطہ کی تحقیق کرتے ہیں، یعنی پیدا کرتے ہیں کہ پڑھنے والے موفق طور پر 'SLAT' کو 'SALT' یا 'WRK' کے طور پر 'WORK' اور محیط اثرات کے طور پر پڑھ سکتے ہیں. مخصوصا، ہم تحقیق کرتے ہیں کہ لکسیکل اورٹوگرافیک محله کا انتخاب کرنا اور حذف کرنا شروع کرتا ہے. اگر یہ موقع ہے، اس سے زیادہ احتمال ہے کہ گھر والوں کی اثرات پردازی کے وقت پہلے ہو جاتی ہے، اور صرف داخلی نمونات کے برابر نہیں ہے. ہم نے ایک نوی محله کی اندازہ پیش کریں، rd20، جس کو محله کے اثرات کے ذریعہ مقدار کرنے کے لئے استعمال کر سکتے ہیں۔ ہم نے rd20 کو تین زبانوں میں بہت بڑے کلمات کے ساتھ شمار کر رکھا ہے جو مختلف فائدہ سٹ کے استعمال کرتے ہیں اور دکھا دیتے ہیں کہ فائدہ سٹ کرتا ہے جو ٹرنسپوسیٹ یا حذف کے لئے زیادہ متفاوت کی توضیح نہیں دیتا۔ ہم نے بھی دکھائی ہے کہ rd20 کو ایک Multi-Layer Perceptron کے مخفی موقعیت کے مطابق محاسبہ کر سکتا ہے اور دکھائی جاتی ہے کہ یہ کم متفاوت کرتی ہیں ہم نے تصمیم لیا ہے کہ محله کے اثر کا احساس نہیں ہے، لیکن اس سے زیادہ احساس ہے کہ پہچان جانے کے بعد موجود موجود موجود موجود موجود موجود موجود موجودات کا نتیجہ ہو جائے۔ تمام کوڈ موجود ہیں: <www.github. com/clips/conll2018>", 'ta': "We investigate the relation between the transposition and deletion effects in word reading, i.e., the finding that readers can successfully read 'SLAT' as 'SALT', or 'WRK' as 'WORK', and the neighborhood effect.  குறிப்பிட்டு, நாம் குறிப்பாக, லெக்சிக்சியல் நிறுவனம் அணுகுகள் கணக்கில் எடுத்து மற்றும் நீக்கம் தீர்மானிப இது நிகழ்ச்சியாக இருந்தால், அண்டை விளைவு செயல்படுத்தலில் முன்னதாக நடக்கும், மற்றும் உள்ளார்ந்த பகுதிகளின் ஒத்திசையை மட நாம் ஒரு புதிய அண்டை அளவை குறிப்பிடுகிறோம், ஆர்டி20, அது அண்டைய விளைவுகளை அணுகும் இடைவெளிகளை அளவிட பயன்படுத்தலாம். மூன்று மொழிகளில் மேல் பெரிய வார்த்தைகளை நாம் கணக்கிடுகிறோம் பல பண்புகள் அமைப்புகளை பயன்படுத்தி மற்றும் காட்டுகிறோம் மாற்று அல்லது நீக்க மேலும் நாம் காட்டுகிறோம் R20 மறைந்த நிலையை பயன்படுத்தி பல அடுக்கு பெர்செப்ட்ரானின் மறைந்த நிலையை கணக்கிட முடியும் என்பதை மறைக்கலா அண்டை விளைவு ஒரு பார்வையான அடிப்படையில் இருக்க முடியாது என்று நாம் முடிவு செய்கிறோம், ஆனால் அடையாளம் கொண்ட பிறகு உருப் அனைத்து குறியீடுகளும் கிடைக்கும்: <www.github. com/clips/conll2018>", 'uz': 'Biz so\'zni o\'qish va o\'chirib chiqish natijalarining orasidagi aloqalarni o\'rganamiz. Masalan, o\'quvchilar muvaffaqiyatli "SALT" deb o\'qish mumkin, yoki "WRK" deb o\'qish mumkin. Ko\'pchilik, lektikal ortografik atroflarini ko\'rib chiqishimiz va ko\'pchilikni o\'zgartiradi. Agar bu narsa bo\'lsa, murojaat natijasi davomida ishlatiladi va faqat internal representatorlarga ishlatmaydi. Biz yangi taqdimot tarkibini anglatamiz, rd20, bu murakkab xossalari joylarini aniqlash uchun ishlatiladi. Biz har xil imkoniyatlarni ishlatish mumkin va olib tashlash imkoniyatlarini koʻrsatish mumkin. Ko\'rsatganimiz, D20\'ning bir necha qatlam Perceptronning bekitilgan holatning xususiyatlarini hisoblash mumkin, va bu ko\'rsatish qo\'rq imkoniyatlaridan kamaytirish mumkin. Biz murojaat effekti ko\'rinishi mumkin emas, lekin tashkilotlarni tasdiqlashdan keyin birlashtirish natijasi bo\'lishi mumkin. Hamma kodlash mavjud: <www.github. com/clips/conll2018>', 'vi': "Chúng tôi đi ều tra mối quan hệ giữa hiệu ứng chuyển nhượng và xoá trong việc đọc chữ, tức là phát hiện ra người đọc có thể đọc được (SLAT) là'rao giảng', hoặc'WRK'là'làm việc' và hiệu ứng hàng xóm. Đặc biệt, chúng tôi điều tra liệu các khu vực văn học có tính dung dịch và xoá trong việc xác định hàng xóm. Nếu đúng như vậy, có nhiều khả năng là hiệu ứng khu vực xảy ra sớm trong quá trình xử lý, và không chỉ dựa vào sự giống nhau của các biểu tượng nội bộ. Chúng tôi giới thiệu một biện pháp mới cho khu vực, d20, nó có thể được dùng để đo lượng hiệu ứng khu vực xung quanh hơn các khu vực ngẫu nhiên. Chúng tôi tính lý giải cái d20 trên một số chữ lớn bằng ba ngôn ngữ khác nhau bằng các bộ cài đặt này và cho thấy các bộ hàm không cho phép chuyển nhượng hay xoá giải thích nhiều biến đổi trong số đo thời gian phản ứng (RT) hơn. Chúng tôi cũng cho thấy rằng d20 có thể được tính bằng cách dùng các biểu tượng kiểu ẩn của một phần trăm đa lớp, và cho thấy rằng nó giải thích sự thay đổi nhỏ hơn các tính năng thô. Chúng tôi kết luận rằng hiệu ứng khu vực không có cơ sở chấp nhận, nhưng có khả năng là kết quả của việc đồng bộ kích hoạt sau khi nhận dạng. Tất cả các mã đều có sẵn ở: www.Gitmo. com/kẹp/conll138)", 'bg': 'Проучваме връзката между ефектите на транспониране и изтриване при четенето на думи, т.е. констатацията, че читателите могат успешно да четат "СЛАТ" като "СОЛ", или "СРК" като "РАБОТА", и ефекта на съседство. По-специално, изследваме дали лексикалните ортографски квартали вземат предвид транспонирането и изтриването при определянето на съседите. Ако случаят е такъв, по-вероятно е ефектът на съседство да се осъществи рано по време на обработката и не разчита единствено на сходството на вътрешните представяния. Въвеждаме нова мярка за съседство, която може да се използва за количествено определяне на ефектите на съседство върху произволни пространства. Изчисляваме рд20 върху големи групи думи на три езика, използвайки различни набор от функции и показваме, че набор от функции, които не позволяват транспониране или изтриване, обясняват повече вариация в измерванията на времето за реакция (РТ). Показваме също, че rd20 може да се изчисли с помощта на скритите състояния на многослоен перцептрон и показваме, че те обясняват по-малко вариация от суровите характеристики. Заключваме, че съседският ефект е малко вероятно да има възприемчива основа, но е по-вероятно да бъде резултат от съвместно активиране на елементи след разпознаване. Целият код е достъпен на: <www.github. com/clips/conll2018>', 'da': "Vi undersøger forholdet mellem transponerings- og sletningseffekterne i ordlæsning, dvs. konstateringen af, at læsere med succes kan læse 'SLAT' som 'SALT', eller 'WRK' som 'ARBEJDE', og naboeffekten. Især undersøger vi, om lexikale ortografiske kvarterer tager hensyn til transponering og sletning i bestemmelsen af naboer. Hvis dette er tilfældet, er det mere sandsynligt, at naboeffekten finder sted tidligt under behandlingen og ikke udelukkende er afhængig af lighed mellem interne repræsentationer. Vi introducerer en ny naboskabsmåling, rd20, som kan bruges til at kvantificere naboskabseffekter over vilkårlige funktionsrum. Vi beregner rd20 over store sæt ord på tre sprog ved hjælp af forskellige funktionssæt og viser, at funktionssæt, der ikke tillader transponering eller sletning, forklarer mere varians i Reaction Time (RT)-målinger. Vi viser også, at rd20 kan beregnes ved hjælp af de skjulte tilstandsrepræsentationer af en Multi-Layer Perceptron, og viser, at disse forklarer mindre varians end de rå funktioner. Vi konkluderer, at naboeffekten er usandsynlig at have et perceptuelt grundlag, men er mere sandsynligt at være resultatet af genstande, der aktiveres sammen efter anerkendelse. Al kode er tilgængelig på: <www.github. com/clips/conll2018>", 'nl': "We onderzoeken de relatie tussen de transponatie- en deletieeffecten in woordlezen, d.w.z. de bevinding dat lezers succesvol 'SLAT' kunnen lezen als 'SALT', of 'WRK' als 'WERK', en het buurteffect. In het bijzonder onderzoeken we of lexicale orthografische buurten rekening houden met transponatie en deletie bij het bepalen van buren. Als dit het geval is, is het waarschijnlijker dat het buurteffect vroeg tijdens de verwerking plaatsvindt en niet alleen afhankelijk is van overeenkomsten tussen interne representaties. We introduceren een nieuwe buurtmaat, rd20, die gebruikt kan worden om buurteffecten te kwantificeren over willekeurige kenmerkruimten. We berekenen de rd20 over grote groepen woorden in drie talen met behulp van verschillende feature sets en laten zien dat feature sets die geen transponatie of verwijdering toestaan meer variatie verklaren in Reactie Time (RT) metingen. We laten ook zien dat de rd20 kan worden berekend met behulp van de verborgen statusrekeningen van een meerlaags perceptron, en laten zien dat deze minder variatie verklaren dan de ruwe eigenschappen. We concluderen dat het buurteffect waarschijnlijk geen perceptuele basis zal hebben, maar eerder het gevolg is van co-activatie van items na herkenning. Alle code is beschikbaar op: <www.github. com/clips/conll2018>", 'hr': "Istražujemo odnos između transpozicije i izbrisanja učinka u čitanju riječi, tj. otkrivanje da čitači mogu uspješno čitati 'SLAT' kao 'SALT', ili 'WRK' kao 'WORK', i učinak susjedstva. Posebno, istražujemo da li leksički ortografski susjedi uzimaju u obzir transpoziciju i izbrisanje u određivanju susjeda. Ako je to slučaj, vjerojatno se učinak susjedstva događa ranije tijekom obrade i ne oslanja se samo na sličnost unutrašnjih predstavljanja. Predstavljamo novu mjeru susjedstva, rd20, koja se može koristiti za kvantificiranje učinka susjedstva na proizvodnim prostorima. Izračunamo rd20 preko velikih seta riječi na tri jezika koristeći različite setove karakteristika i pokazujemo da setovi karakteristika koje ne omogućavaju transpoziciju ili uklanjanje objašnjavaju više varijancije u mjerenjima reakcijnog vremena (RT). Također pokazujemo da se rd20 može izračunati uz skriveno stanje predstavljanja višeslojnog proceptra i pokazati da se to objašnjava manje varijancije od sirovih karakteristika. Zaključili smo da učinak susjedstva nije vjerojatno imati perceptualnu osnovu, ali vjerojatno će biti rezultat objekata koji se sarađuju nakon priznanja. Svi kod su dostupni na: <www.github. com/clips/conll2018>", 'de': 'Wir untersuchen den Zusammenhang zwischen den Transposition- und Deletionseffekten beim Wortlesen, d.h. der Erkenntnis, dass Leser "SLAT" als "SALT" oder "WRK" als "WORK" erfolgreich lesen können, und dem Nachbarschaftseffekt. Insbesondere untersuchen wir, ob lexikalisch-orthographische Nachbarschaften Transposition und Deletion bei der Bestimmung von Nachbarn berücksichtigen. Ist dies der Fall, ist es wahrscheinlicher, dass der Nachbarschaftseffekt frühzeitig während der Verarbeitung auftritt und nicht allein auf Ähnlichkeit interner Darstellungen beruht. Wir stellen eine neue Nachbarschaftsmessung vor, rd20, mit der Nachbarschaftseffekte über beliebige Merkmalsräume quantifiziert werden können. Wir berechnen den rd20 über große Wortsätze in drei Sprachen mit verschiedenen Feature-Sets und zeigen, dass Feature-Sets, die keine Transponierung oder Löschung zulassen, mehr Varianz bei Reaktionszeitmessungen erklären. Wir zeigen auch, dass der rd20 mit den versteckten Zustandsdarstellungen eines mehrschichtigen Perzeptrons berechnet werden kann, und zeigen, dass diese weniger Varianz erklären als die rohen Features. Wir schlussfolgern, dass der Nachbarschaftseffekt wahrscheinlich keine Wahrnehmungsbasis hat, sondern eher das Ergebnis einer Koaktivierung von Gegenständen nach Erkennung ist. Der gesamte Code ist verfügbar unter: <www.github. de/clips/conll2018>', 'ko': "우리는 단어 읽기에서의 전환과 삭제 효과 간의 관계를 연구했다. 즉, 독자가'SLAT'를'SALT'로 성공적으로 읽거나'WRK'를'WORK'로 읽거나 이웃 효과로 읽을 수 있음을 발견했다.특히 우리는 어휘 정교 이웃이 이웃을 확정할 때 전환과 삭제를 고려했는지 연구했다.만약 이런 상황이라면 이웃 효과는 내부 표시의 유사성에만 의존하는 것이 아니라 처리 과정의 초기에 발생할 가능성이 더 높다.우리는 임의의 특징 공간의 이웃 효과를 계량화하는 데 사용할 수 있는 새로운 이웃 측정 rd20을 도입했다.우리는 서로 다른 특징집을 사용하여 세 언어 중 대형 단어집의 rd20을 계산하였으며, 위치를 바꾸거나 삭제하는 것을 허용하지 않는 특징집은 반응시(RT) 측정에서의 더 많은 차이를 설명하였다.우리는 또한 다중 감지기의 숨겨진 상태 표시를 사용하여 rd20을 계산할 수 있으며 이러한 표시는 원시적 특징 해석의 방차보다 작다는 것을 나타낸다.우리는 이웃 효과가 감지의 기초가 있을 수 없지만 프로젝트가 식별된 후에 공동으로 활성화된 결과일 수 있다는 결론을 얻었다.모든 코드는 <www.github.com/clips/conll2018>", 'id': "Kami menyelidiki hubungan antara efek transposisi dan penghapusan dalam pembacaan kata, i.e., penemuan bahwa pembaca dapat berhasil membaca 'SLAT' sebagai 'SALT', atau 'WRK' sebagai 'WORK', dan efek lingkungan. In particular, we investigate whether lexical orthographic neighborhoods take into account transposition and deletion in determining neighbors.  Jika ini terjadi, lebih mungkin efek lingkungan terjadi lebih awal selama proses, dan tidak hanya bergantung pada persamaan dari representation interna. Kami memperkenalkan ukuran lingkungan baru, rd20, yang dapat digunakan untuk mengurangi efek lingkungan atas ruang karakteristik secara arbitrar. Kami menghitung rd20 atas set besar kata dalam tiga bahasa menggunakan berbagai set fitur dan menunjukkan bahwa set fitur yang tidak memungkinkan transposisi atau hapusan menjelaskan lebih banyak variasi dalam pengukuran Waktu Reaksi (RT). Kami juga menunjukkan bahwa rd20 dapat dihitung menggunakan representation negara tersembunyi dari Perceptron Multi-Lapisan, dan menunjukkan bahwa ini menjelaskan kurang variasi dari ciri-ciri raw. Kami menyimpulkan bahwa efek lingkungan tidak mungkin memiliki dasar persepsi, tetapi lebih mungkin menjadi hasil dari objek yang koaktif setelah pengakuan. Semua kode tersedia di: <www.github. com/clips/conll2018>", 'fa': 'ما ارتباط بین تغییر جایگاهی و پاک کردن اثرات خواندن کلمات را تحقیق می\u200cکنیم، یعنی پیدا کردن که خواندگان می\u200cتوانند با موفقیت "SLAT" به عنوان "SALT" یا "WRK" به عنوان "WORK" و اثرات محله بخوانند. مخصوصا، ما تحقیق می\u200cکنیم که آیا محله\u200cهای زبان\u200cشناسی در تعیین همسایه\u200cها به تغییر و حذف حساب می\u200cگیرند یا نه. اگر این موضوع باشد، احتمال بیشتری است که اثر محله در حالی پردازش زودتر اتفاق می افته و تنها بر شبیه نمایش داخلی اعتماد نمی کند. ما یک اندازه محله جدید را معرفی می\u200cکنیم، rd20، که می\u200cتواند برای تعداد تاثیرات محله\u200cای بر فضای\u200cهای ویژه\u200cهای منحصری استفاده شود. ما rd20 را بر مجموعه کلمات بزرگ در سه زبان با استفاده از مجموعه\u200cهای ویژه\u200cهای مختلف محاسبه می\u200cکنیم و نشان می\u200cدهیم که مجموعه\u200cهای ویژه\u200cای که اجازه نمی\u200cدهند برای تغییر یا حذف کردن تغییرات بیشتری در اندازه\u200cهای زما ما همچنین نشان می دهیم که rd20 می تواند با استفاده از نمایش\u200cهای موقعیت مخفی یک پرچترون لایه\u200cهای زیادی محاسبه شود و نشان می دهیم که این تغییرات کمتر از ویژگی\u200cهای خالی توضیح می\u200cدهد. ما تصمیم می\u200cگیریم که اثر محله احتمالاً بنیادی معلوم نیست، ولی احتمالاً نتیجه\u200cی موارد بعد از شناختن همکاری است. همه رمز در: <www.github. com/clips/conll2018>', 'sw': "Tunafahamu uhusiano kati ya usafirishaji na uharibifu katika kusoma maneno, yaani kutafuta kwamba wasomaji wanaweza kusoma 'SLAT' kama 'SALT', au 'WARK' kama 'WORK', na athari ya jirani. In particular, we investigate whether lexical orthographic neighborhoods take into account transposition and deletion in determining neighbors.  Kama hivi ndivyo, inawezekana kwamba madhara ya jirani yanafanyika mapema wakati wa utaratibu wa upasuaji, na haitegemea pekee ya uwakilishi wa ndani. Tunaweza kuanzisha hatua mpya ya jirani, rd20, ambayo inaweza kutumika kuhakikisha athari za jirani juu ya maeneo ya kiholela. Tunakadiria seti kubwa ya maneno ya rd20 kwa lugha tatu kwa kutumia seti mbalimbali za utaalam na kuonyesha kwamba vipengele vinavyoruhusu usafirishaji au kuondolewa inaelezea tofauti zaidi katika kipimo cha muda wa Reaction (RT). Tunaonyesha pia kuwa idadi ya R20 inaweza kuchukuliwa kwa kutumia wakilishi wa serikali zilizofichikana ya Perceptron ya Layer Multi-Layer, na kuonyesha kuwa tofauti hizi hazina tofauti kuliko tabia za mabaya. We conclude that the neighborhood effect is unlikely to have a perceptual basis, but is more likely to be the result of items co-activating after recognition.  Kodi zote zinapatikana kwenye: <www.github. com/clips/conll2018>", 'tr': 'Biz sözleriň okamakda terjime we ýitirme etkinleri arasyndaky baglaýyşyny barlaýarys, oňa okaanlaryň \'SLAT\'i \'SALT\' ýaly \'WRK\'i \'WORK\' we mahaly eseri ýaly okap biljekdigini tapylýarys. Özellikle, biz öz goňşulary belirleýän mektuplaryň transpozisyona ve silmesine göz almagyny soruşuyoruz. Eğer bu durumda, mahallenin etkisi işleme sırasında erken oluşabilir ve sadece iç ifadelerin benzeri olmasına dayanabilir. Biz yeni bir mahallenin ölçüsü ve rd20\'i tanıtıyoruz ki, mahallenin etkisini arbiyon alanlarda ölçülemek için kullanılabilir Biz rd20\'i üç dilde örän uly sözler ullanýan we çykyş düzümlerni ullanýan we çykyş üçin ruzilemeýän düzümlerni tanyşdyrýan ýa-da çykyş etmeýän düzümlerni Reasiýan Zamany (RT) ölçümlerinde köpräk üýtgedir Biz de "rd20" köp katlı bir şekilde gizli durumlar kullanarak hesap edilebilir ve bu şekilde hatlı özelliklerden az farklı olduğunu gösteririz. Biz çöplük etkisinin düşünüp düşünmesi mümkin däldir, ýöne tanınmakdan soň işbirleşen zatlaryň netijesi bolup biler. Ehli köd: <www.github.de bar. com/clips/conll2018>', 'af': "Ons ondersoek die verwanting tussen die transposisie en uitvee effekte in woord lees, i.e. die soek dat lesers suksesvol 'slaat' as 'slaat', of 'WRK' as 'WORK', en die naboodskapeffek kan lees. Spesifieke, ons ondersoek of leksiese orthografiese nabygenote in rekening transposisie en uitvee in die bepaal van nabygenote neem. As dit die geval is, is dit meer waarskynlik dat die naaste effek vroeg plaas tydens verwerking, en nie alleen vertrou op gelykenis van interne voorstellings. Ons introduseer 'n nuwe naboosheid maat, rd20, wat kan gebruik word om naboosheid effekte te quantifiseer oor willekeurige funksie spasies. Ons bereken die rd20 oor groot stel woorde in drie tale gebruik verskeie funksie stel en wys dat funksie stel wat nie toelaat vir transposisie of uitvee verduidelik meer variasie in reaksie Tyd (RT) measurements. Ons wys ook dat die rd20 kan bereken word deur die verborge staat voorstellings van 'n Multi- Layer Perceptron, en wys dat hierdie verduidelik minder verandering as die rooi funksies. Ons sluit dat die naaste effek nie waarskynlik 'n perceptual basis het nie, maar is meer waarskynlik die resultaat van items wat saam-aktiveer na herkening. Alle kode is beskikbaar by: <www.github. com/clips/conll2018>", 'sq': "We investigate the relation between the transposition and deletion effects in word reading, i.e., the finding that readers can successfully read 'SLAT' as 'SALT', or 'WRK' as 'WORK', and the neighborhood effect.  In particular, we investigate whether lexical orthographic neighborhoods take into account transposition and deletion in determining neighbors.  Në qoftë se ky është rasti, ka më shumë gjasa që efekti i lagjes të bëhet herët gjatë përpunimit dhe nuk mbështetet vetëm në ngjashmërinë e përfaqësimeve të brendshme. We introduce a new neighborhood measure, rd20, which can be used to quantify neighborhood effects over arbitrary feature spaces.  Ne llogarisim rd20 mbi grupe të mëdha fjalësh në tre gjuhë duke përdorur grupe të ndryshme funksionesh dhe tregojmë se grupet e funksioneve që nuk lejojnë transpozimin apo eleminimin shpjegojnë më shumë variancë në matjet e Kohës së Reaksionit (RT). Ne gjithashtu tregojmë se rd20 mund të llogaritet duke përdorur përfaqësimet e fshehta të shtetit të një Perceptroni Multi-Layer, dhe tregojmë se këto shpjegojnë më pak variancë se karakteristikat e papërpunuara. Ne përfundojmë se efekti i lagjes nuk ka gjasa të ketë një bazë perceptive, por ka më shumë gjasa të jetë rezultati i objekteve që bashkëaktivizohen pas njohjes. Të gjithë kodet janë në dispozicion në: <www.github. com/clips/conll2018>", 'hy': 'Մենք ուսումնասիրում ենք բառերի կարդալու վերաբերյալ վերածման և ջնջման ազդեցությունների հարաբերությունը, այսինքն, այն եզրակացությունը, որ կարդացողները հաջողությամբ կարող են կարդալ «ՍԼԱT» որպես «ՍԱLT», կամ «ՈւՌK» որպես «Աշխատանք» և հարևանքի ազդեցություն In particular, we investigate whether lexical orthographic neighborhoods take into account transposition and deletion in determining neighbors.  If this is the case, it is more likely that the neighborhood effect takes place early during processing, and does not solely rely on similarity of internal representations.  We introduce a new neighborhood measure, rd20, which can be used to quantify neighborhood effects over arbitrary feature spaces.  Մենք հաշվարկում ենք արդի 20 բառերի մեծ հավաքածուները երեք լեզուներում օգտագործելով տարբեր հատկանիշների հավաքածուներ և ցույց ենք տալիս, որ հատկանիշների հավաքածուները, որոնք թույլ չեն տալիս վերածել կամ ջնջել, բացատրում են ավելի շատ տարբերություն արձագանքային Մենք նաև ցույց ենք տալիս, որ r-20-ը կարելի է հաշվարկել օգտագործելով բազմաշերտ պրոցեպտոնի թաքնված վիճակի ներկայացումները, և ցույց ենք տալիս, որ դրանք բացատրում են ավելի քիչ տարբերակություն, քան պարզ հատկությունները: We conclude that the neighborhood effect is unlikely to have a perceptual basis, but is more likely to be the result of items co-activating after recognition.  Բոլոր կոդները հասանելի են ։ com/clips/conll2018>', 'am': 'በንግግር በማንበብ እና በማጥፋት የግንኙነት ግንኙነት እና በማጥፋት ላይ እናምርመራለን፤ አናባቢው ‘SLAT’ እንደ ‘SALT’ ወይም ‘WRK’ እንደ ‘WORK’ እና የአካባቢው ውጤት እንዲያነብ ማግኘት ይችላል፡፡ በተለይም፣ የሌክሲካዊ የፖሮግራፊ ጎረቤቶች የጎረቤቶችን ማሳየት እና ማጥፋት እንደሆነ እናመርመራለን፡፡ ይህ ጉዳዩ ቢሆን፣ የጎረቤቱ ውጤት ለመጀመሪያ ሲደርስ፣ በአውራዊ መልዕክቶች ብጤ በማይታመን ብቻ ነው፡፡ We introduce a new neighborhood measure, rd20, which can be used to quantify neighborhood effects over arbitrary feature spaces.  በሦስት ቋንቋዎች ላይ የ.ஆர.ሀ.አ እናሳየዋለን፣ የ.ሀ.አ.ሀ.አ.20 የተሰወረውን የሀገር መልዕክቶች በብዙ ደረጃ ፕሬስፕሮን በመቀበል ይቆጥራል፡፡ የጎረቤቱን ፍቃድ ማሳየት አይቻልም፣ ነገር ግን ከታወቀው በኋላ የተሰበሰቡ ፍጻሜ ሊሆን ይችላል፡፡ <www.github. com/clips/conll2018>', 'az': 'Biz sözləri oxumaq və silmə effektlərinin arasındakı bağlantını araşdırırıq, məsələn oxuyanların "SLAT" səbəbi "SALT" və ya "WRK" kimi "WORK" və mahallenin etkisi olaraq oxuyabilirlər. Özellikle, biz təşkil edirik ki, leksik ortografik məmləkətlərin qonşularını tanımayaraq transponsiyaya və silinməyə müvəffəq edir. Əgər bu olarsa, qonşuluq etkisi işləmə vaxtı erkən başlar və sadəcə iç təsirlərin bənzərinə təvəkkül etməz. Biz yeni məmləkət ölçüsünü, rd20 ilə təşkil edirik ki, bu məmləkət etkisini müəyyən vaxtlarda hesablamaq üçün istifadə edə bilər. Biz rd20\'i üç dildə çox böyük sözlərlə hesablayırıq, müxtəlif özellik qurğularını istifadə edərək və transponsiyaya və silməyə izin verməyən fərqli qurğularını daha çox reaksiya zamanı (RT) ölçülərində açıqlayır. Biz də göstəririk ki, rd20-i çoxlu-Layer Perseptronun gizli durum göstəricisi ilə hesablanır və bunların həmçinin həmçinin özelliklərindən az dəyişiklik göstərir. Biz çəkirik ki, məmləkət etkisinin hissəsi olmaması mümkün deyil, amma tanıdıqdan sonra şəkildə eyni olaraq hərəkət edən məmləkətlərin sonucu olar. Bütün kodlar: <www.github\'da faydalanır. com/clips/conll2018>', 'bn': "We investigate the relation between the transposition and deletion effects in word reading, i.e., the finding that readers can successfully read 'SLAT' as 'SALT', or 'WRK' as 'WORK', and the neighborhood effect.  বিশেষ করে, আমরা অনুসন্ধান করি লেক্সিক্যাল অর্থোগ্রাফিক এলাকাগুলো প্রতিবেশীদের সিদ্ধান্ত নিয়ে যাওয়া এবং মুছে ফেল যদি এই ঘটনা হয়, তবে সম্ভবত প্রক্রিয়ার সময় প্রতিবেশীর প্রভাব শুরু হয় এবং সেটা শুধুমাত্র অভ্যন্তরীণ প্রতিনিধিদের একই ধরনের উপর নির্ভর করে ন আমরা একটি নতুন প্রতিবেশী মাপের পরিমাপ, আর২০, যা প্রতিবেশীর প্রভাব ব্যবহার করা যায় যাতে পারে নির্যাতন বৈশিষ্ট্যের স্থা আমরা বিভিন্ন বৈশিষ্ট্যাবলী সেট ব্যবহার করে আর২০ এর বেশী বিশাল শব্দ হিসেবে গণনা করি এবং দেখাই যে বৈশিষ্ট্যাবলী নির্ধারণ করা হবে যা রিকেশন টাইম (R আমরা একই সাথে দেখাচ্ছি যে এড২০ গোপন রাষ্ট্রের প্রতিনিধি ব্যবহার করে গোপন রাষ্ট্রের প্রতিনিধিত্ব হিসেবে গণনা করতে পারি, আর দেখাচ্ছি যে এই আমরা উপসংহার প্রদান করেছি যে প্রতিবেশীর প্রভাব দৃষ্টিভঙ্গী ভিত্তিতে পারে না, কিন্তু স্বীকৃতি স্বীকারের পরে জিনিসপত্রে সব কোড উপস্থিত: <www.github. com/clips/conll2018>", 'ca': "We investigate the relation between the transposition and deletion effects in word reading, i.e., the finding that readers can successfully read 'SLAT' as 'SALT', or 'WRK' as 'WORK', and the neighborhood effect.  En particular, investigam si els barris ortogràfics lèxics tenen en compte la transposició i la supresió en determinar els veïns. If this is the case, it is more likely that the neighborhood effect takes place early during processing, and does not solely rely on similarity of internal representations.  Introduïm una nova mesura del barri, rd20, que es pot utilitzar per quantificar els efectes del barri sobre espais arbitràries de característiques. Calculem el rd20 sobre grans conjunts de paraules en tres llengües utilitzant diversos conjunts de característiques i demostram que els conjunts de característiques que no permeten transposició o eliminació explicen més variació en les mesures del temps de reacció (RT). We also show that the rd20 can be calculated using the hidden state representations of an Multi-Layer Perceptron, and show that these explain less variance than the raw features.  Conclouem que és poc probable que l'efecte del barri tingui una base perceptual, però és més probable que sigui el resultat dels objectes que s'activen en conjunt després del reconeixement. Tot el codi està disponible a: <www.github. com/clips/conll2018>", 'cs': 'Zkoumáme vztah mezi transpozičními a delečními efekty při čtení slov, tj. zjištěním, že čtenáři mohou úspěšně číst "SLAT" jako "SALT", nebo "WRK" jako "PRÁCE", a efektem sousedství. Konkrétně zkoumáme, zda lexikální ortografické čtvrti berou v úvahu transpozici a deleci při určování sousedů. Pokud tomu tak je, je pravděpodobnější, že účinek sousedství nastává brzy během zpracování a nespoléhá pouze na podobnosti interních reprezentací. Představujeme nové měřítko sousedství rd20, které lze použít k kvantifikaci efektů sousedství nad libovolnými funkčními prostory. Vypočítáme rd20 u velkých sad slov ve třech jazycích pomocí různých sad funkcí a ukazujeme, že sady funkcí, které neumožňují transpozici nebo smazání, vysvětlují větší rozptyl v měření reakční doby (RT). Ukázali jsme také, že rd20 lze vypočítat pomocí skrytých reprezentací stavu vícevrstvého Perceptronu, a ukázali jsme, že tyto vysvětlují menší rozptyl než surové vlastnosti. Dospěli jsme k závěru, že efekt sousedství pravděpodobně nebude mít perceptuální základ, ale je pravděpodobnější, že bude výsledkem spoluaktivace položek po rozpoznání. Veškerý kód je k dispozici na: <www.github. com/clips/conll2018>', 'et': 'Uurime ülevõtmise ja kustutamise mõju seost sõnalugemisel, st leida, et lugejad suudavad edukalt lugeda "SLAT" kui "SALT" või "WRK" kui "TÖÖ" ning naabrusmõju vahel. Eelkõige uurime, kas leksikaalsed ortograafilised naabrid võtavad naabrite määramisel arvesse transportimist ja kustutamist. Sellisel juhul on tõenäolisem, et naabrusmõju toimub töötlemise ajal varakult ja see ei tugine üksnes sisemiste esinduste sarnasusele. Tutvustame uut naabruskonna mõõdet rd20, mida saab kasutada naabruskonna efektide kvantifitseerimiseks suvaliste funktsiooniruumide suhtes. Arvutame rd20 suurte sõnakomplektide üle kolmes keeles, kasutades erinevaid funktsioonikomplekte ja näitame, et funktsioonikomplektid, mis ei võimalda ülevõtmist või kustutamist, selgitavad reaktsiooniaja (RT) mõõtmiste suuremat variatsiooni. Samuti näitame, et rd20 saab arvutada mitmekihilise perceptroni varjatud oleku esituste abil ja näitame, et need seletavad vähem erinevusi kui toorfunktsioonid. Järeldame, et naabruspoliitika efekt ei ole tõenäoliselt tajutav, kuid on tõenäolisemalt tingitud esemete kaasaktiveerimisest pärast tuvastamist. Kogu kood on kättesaadav aadressil: <www.github. com/clips/conll2018>', 'fi': 'Tutkimme sanalukemisen transpositio- ja poistovaikutusten välistä suhdetta eli havaintoa siitä, että lukijat pystyvät lukemaan SLAT:n nimellä SALT tai WRK:n nimellä TYÖ, ja naapuruusvaikutuksen. Erityisesti tutkimme, ottavatko lexikaaliset ortografiset naapurustot huomioon transposition ja poiston naapurien määrittämisessä. Jos näin on, on todennäköisempää, että naapuruusvaikutus tapahtuu varhaisessa vaiheessa käsittelyn, eikä se perustu pelkästään sisäisten esitysten samankaltaisuuteen. Esittelemme uuden naapuruusmittarin, rd20, jota voidaan käyttää mittaamaan naapuruusvaikutuksia mielivaltaisten ominaisuusavaruuksien yli. Laskemme rd20:n suurille sanajoukoille kolmella kielellä käyttäen erilaisia ominaisuuksia ja osoitamme, että ominaisuusjoukot, jotka eivät salli transportiota tai poistamista, selittävät enemmän vaihtelua Reaktioaika (RT) -mittauksissa. Osoitamme myös, että rd20 voidaan laskea käyttämällä monikerroksisen perceptronin piilotettuja tilaesityksiä, ja osoitamme, että nämä selittävät vähemmän varianssia kuin raakaominaisuudet. Päätämme, että lähiöilmiöllä ei todennäköisesti ole havaintoperustetta, mutta se on todennäköisempää seurausta esineiden samanaikaisesta aktivoitumisesta tunnistamisen jälkeen. Kaikki koodi on saatavilla osoitteessa: <www.github. com/clips/conll2018>', 'bs': "Istražujemo odnos između transpozicije i izbrisanja efekta u čitanju riječi, tj. otkrivanje da čitači mogu uspješno čitati 'SLAT' kao 'SALT', ili 'WRK' kao 'WORK', i učinak susjedstva. Posebno, istražujemo da li leksički ortografski susjedi uzimaju u obzir transpoziciju i izbrisanje u određivanju susjeda. Ako je to slučaj, vjerojatnije je da se učinak susjedstva održava ranije tijekom obrade i ne oslanja se samo na sličnost unutrašnjih predstavljanja. Predstavljamo novu mjeru susjedstva, rd20, koja se može koristiti za kvantificiranje učinka susjedstva na proizvodnim prostorijama. Izračunamo rd20 preko velikih seta riječi na tri jezika koristeći različite setove karakteristike i pokazujemo da setovi koje ne dozvoljavaju da transponišu ili uklanjaju objašnjavaju više varijansa u mjerenjima reakcijnog vremena (RT). Također pokazujemo da se rd20 može izračunati uz skriveno stanje predstavljanja višeslojnog proceptra, i pokazujemo da to objašnjava manje varijante od sirovih karakteristika. Zaključujemo da će učinak susjedstva vjerojatno imati perceptualnu osnovu, ali vjerojatno će biti rezultat objekata koji se sarađuju nakon priznanja. Svi kod su dostupni na: <www.github. com/clips/conll2018>", 'ha': "Tuna jãyayya da mazaunin tsakanin shirin da aka kashe mai amfani da ake karanta maganar, misali, an gane cewa karatun karatun karatun karatun 'SMAT' kamar 'SALT' ko 'WRK' kamar 'WORK', da mai amfani da matsayin jiran. Kuma da ƙayyade, Munã tambaya, ma'anar sauri na kasar ortografiki na lissafa ko da za'a iya lissafa da cire a cikin garwaya. In da wannan, shi ne mafi yiwuwa an fara wani matsayin jiran ta fara a lokacin da za'a yi amfani da shi, kuma bã ya dõgara kawai ga daidaita misãlan wakin guda. Tuna gaurar da gwargwadon gari, rd20, wanda za'a iya amfani da shi dõmin a ƙayyade matsayin jirarsu kan filayen arbitati. Ana ƙaddara rd20 kodi cikin tsarin magana masu girma cikin lingui uku idan ana yi amfani da tsaro masu buƙata ko kuma Muke nuna cewa tsarin tsari waɗanda bã ya yarda da shirin shige ko cire ba, yana bayyana variance mafi yawa cikin tsarin lokacin da ake yi wa Rabi'a (RT). Tuna nuna cewa, an iya lissafa rd20 da za'a yi amfani da tsarin halin da aka ɓõye wa wani Layer Mai yawa, kuma za'a nuna cewa, waɗannan suna bayyana varianci ƙaranci daga sifatin raw. Munã ƙara cewa halin jiran na kasancẽwa yana da wani abu mai gani, amma yana kasancẽwa mafi kusa su kasance matsaran samura da abubuwa bayan an gane su. @ info: whatsthis com/klips/conll2018>", 'sk': 'Preučujemo povezavo med prenosom in brisanjem učinkov pri branju besed, tj. ugotovitvijo, da bralci uspešno berejo "SLAT" kot "SOLT" ali "WRK" kot "DELO", in sosednjim učinkom. Predvsem raziskujemo, ali leksikalna ortografska soseska pri določanju sosedov upošteva prenos in brisanje. Če je to tako, je bolj verjetno, da se sosedski učinek pojavi zgodaj med obdelavo in se ne zanaša zgolj na podobnost notranjih predstavitev. Uvedli smo nov sosedski ukrep, rd20, ki ga lahko uporabimo za kvantificiranje sosedskih učinkov nad poljubnimi funkcijskimi prostori. Izračunamo rd20 na velikih naborih besed v treh jezikih z uporabo različnih naborov funkcij in pokažemo, da nabori funkcij, ki ne omogočajo prenosa ali brisanja, pojasnjujejo več variacij meritev reakcijskega časa (RT). Pokazali smo tudi, da je rd20 mogoče izračunati s skritimi predstavitvami stanja večplastnega perceptrona in da ti pojasnjujejo manj variance kot neobdelane funkcije. Sklepamo, da sosedski učinek verjetno ne bo imel zaznavne osnove, vendar je bolj verjetno rezultat sooktiviranja elementov po prepoznavanju. Vsa koda je na voljo na: <www.github. com/clips/conll2018>', 'jv': 'Anyone Genjer-Genjer buddy string" in "context_BAR_stringLink We kalkula Monday Awak dhéwé éntuk ning alih-alih sing paling dadi, kuwi mau ngerasah basa sing luwih apik, njuk kesempatan luwih apik dhéwé iso nguasai perusahaan anyar mèh sabané. politenessoffpolite"), and when there is a change ("assertivepoliteness com/Clip/conll2008>', 'bo': "We investigate the relation between the transposition and deletion effects in word reading, i.e., the finding that readers can successfully read 'SLAT' as 'SALT', or 'WRK' as 'WORK', and the neighborhood effect. The དམིགས་བསལ་ན། ང་ཚོས་ཁྱིམ་མཚེས་གཡས་གཡོན་གཡས་གཡོན་གཡས་གཡོན གལ་སྲིད། ང་ཚོས་ཁྱིམ་མཚེས་གཡས་གཡོན་པའི་ཚད་ལྡན་གྱི་སྒོ་སྒྲིག་གསར་བ་ཞིག་སྟོན་དགོས་པ། rd20 We calculate the rd20 over large sets of words in three languages using various feature sets and show that feature sets that do not allow for transposition or deletion explain more variance in Reaction Time (RT) measurements. འུ་ཅག་གིས་ཀྱང་སྔོན་རིམ་པ་སྣ་མང་ཆེ་རིམ་པ་ཅིག་གི་ཡིབ་རྣམས་ཀྱི་རྣམ་པ་ལ་རྩིས་བ་བཏུབ་པའི་རྣམ་པ་༢༠་ཙམ་མངོན་འ ང་ཚོས་ཁྱིམ་གྱི་གདོང་འབྲེལ་གྱི་ཉེན་བརྗོད་དེ་ལ་ཤེས་ཀྱི་གཞི་རྟེན་ཞིག་ཡོད་མིན་པས། བྱས་ན་ཕལ་ཆེར་ཤེས་ཀྱི་རྣམ་གྲངས་ཀྱི་ All code is available at: <www.github. com/clips/conll2018>", 'he': 'אנו חוקרים את היחסים בין השפעות ההעברה והמחיקה בקריאת מילים, כלומר, המצאה שקוראים יכולים לקרוא "SLAT" בהצלחה כ"SALT", או "WRK" כ"WORK", ואת השפעות השכונה. במיוחד, אנו חוקרים אם שכונות אורטוגרפיות לקסיות לוקחות בחשבון את ההעברה והמחיקה בכדי לקבוע שכנים. If this is the case, it is more likely that the neighborhood effect takes place early during processing, and does not solely rely on similarity of internal representations.  We introduce a new neighborhood measure, rd20, which can be used to quantify neighborhood effects over arbitrary feature spaces.  אנחנו מחשבים את rd20 על קבוצות גדולות של מילים בשלושה שפות באמצעות קבוצות תכונות שונות ולהראות כי קבוצות תכונות שלא מאפשרים להעברה או למחקר מסבירים יותר שונות במדידות זמן הגיבה (RT). אנחנו גם מראים שהrd20 יכול להיחשב באמצעות מייצגי המצב המוסתרים של פרספקטרון ממספר שכבות, ולהראות שהם מסבירים פחות שונות מהתכונות החומרים. אנחנו מסכימים שאפיקס השכונה לא סביר שיש בסיס התפיסה, אך סביר יותר להיות תוצאה של פריטים שמפעילים יחד לאחר זיהוי. כל הקוד זמין ב: <www.github. com/clips/conll2018>'}
{'en': 'Global Attention for Name Tagging', 'fr': 'Attention mondiale pour le balisage de nom', 'ar': 'الاهتمام العالمي بعلامات الاسم', 'es': 'Atención global para el etiquetado de nombres', 'pt': 'Atenção global para marcação de nomes', 'ja': '名前タグのグローバル注目度', 'hi': 'नाम टैगिंग के लिए वैश्विक ध्यान', 'zh': '全球注名标记', 'ru': 'Глобальное внимание к маркировке имен', 'ga': 'Aird Dhomhanda ar Chlibeáil Ainmneacha', 'ka': 'Name', 'hu': 'Globális figyelem a névcímkézésre', 'el': 'Παγκόσμια προσοχή για τη σήμανση ονομάτων', 'it': "Attenzione globale per l'etichettatura dei nomi", 'kk': 'Атауын тегтерге жалпы назар', 'lt': 'Pasaulinis dėmesys pavadinimų žymėjimui', 'mk': 'Глобално внимание за означување на името', 'ms': 'Perhatian Global untuk Tagging Nama', 'ml': 'പേര് ടാഗിങ്ങിനുള്ള ഗ്ലോബല്\u200d ശ്രദ്ധ', 'mt': 'Attenzjoni Globali għat-Tagging tal-Ismijiet', 'mn': 'Нэр тэмдэглэх дэлхийн анхаарал', 'no': 'Globalt merking på namn', 'sr': 'Globalna pažnja za označavanje imena', 'pl': 'Ogólna uwaga na tagowanie imion', 'ro': 'Atenție globală pentru etichetarea numelui', 'si': 'Name', 'ta': 'பெயர் ஒட்டுதலுக்கான பொதுவான கவனிப்பு', 'so': 'Dhaqaalaha caalamiga ah ee magaca tagging', 'sv': 'Global uppmärksamhet för namnmärkning', 'ur': 'Name', 'uz': 'Name', 'vi': 'Chú ý toàn cầu về đánh dấu', 'bg': 'Глобално внимание за маркиране на имената', 'da': 'Global opmærksomhed på navnmærkning', 'id': 'Perhatian Global untuk Tagging Nama', 'hr': 'Globalna pažnja za označavanje imena', 'nl': 'Algemene aandacht voor naamlabeling', 'ko': '글로벌 관심 성명 표시', 'fa': 'توجه جهانی برای برچسب نام', 'af': 'Globale waarskuwing vir naam etiket', 'de': 'Globale Aufmerksamkeit für Name Tagging', 'sw': 'Kimataifa cha Ujumbe kwa ajili ya Ujumbe wa Jina', 'am': 'ቦታ፦', 'hy': 'Համաշխարհային ուշադրություն անունների նշանների համար', 'tr': 'Ady Tägleme üçin Umumy Unsur', 'sq': 'Vëmendje globale për etiketën e emrit', 'az': 'İsim etiketi', 'bs': 'Globalna pažnja za označavanje imena', 'ca': "Atenció global a l'etiqueta de noms", 'bn': 'নাম ট্যাগিং এর জন্য গ্লোবাল মনোযোগ', 'cs': 'Globální pozornost pro označování jmen', 'et': 'Üldine tähelepanu nimede märgistamisele', 'fi': 'Nimimerkintöjen yleinen huomio', 'jv': 'AllProgressBar', 'sk': 'Globalna pozornost za označevanje imen', 'ha': '@ action', 'he': 'תשומת לב גלובלית לטייג שם', 'bo': 'མིང་རྟགས་བཀོད་པའི་སྤྱི་ཁོར་ཡུག་ཆ་ལ་རྟོགས'}
{'en': 'Many name tagging approaches use ', 'ar': 'تستخدم العديد من أساليب تمييز الأسماء المعلومات السياقية المحلية بنجاح كبير ، ولكنها قد تفشل عندما يكون السياق المحلي غامضًا أو محدودًا. نقدم إطار عمل جديدًا لتحسين وضع علامات على الأسماء من خلال الاستفادة من المعلومات السياقية المحلية وعلى مستوى المستند وعلى مستوى المجموعة. لكل كلمة ، نسترجع سياق مستوى المستند من جمل أخرى داخل نفس المستند وسياق على مستوى المجموعة من الجمل في المستندات الأخرى. نقترح نموذجًا يتعلم دمج المعلومات السياقية على مستوى المستند ومستوى المجموعة جنبًا إلى جنب مع المعلومات السياقية المحلية من خلال الاهتمام على مستوى المستند ومستوى المجموعة ، والذي يزن المعلومات السياقية الخاصة بكل منهما ديناميكيًا ويحدد تأثير هذه المعلومات من خلال آليات البوابة. تُظهِر التجارب على مجموعات البيانات المعيارية فعالية نهجنا ، والذي يحقق أحدث النتائج للهولندية والألمانية والإسبانية على مجموعتي بيانات CoNLL-2002 و CoNLL-2003. سنجعل الكود الخاص بنا والنماذج المدربة مسبقًا متاحة للجمهور لأغراض البحث.', 'fr': "De nombreuses approches de balisage de nom utilisent les informations contextuelles locales avec beaucoup de succès, mais peuvent échouer lorsque le contexte local est ambigu ou limité. Nous présentons un nouveau cadre pour améliorer le balisage des noms en utilisant des informations contextuelles locales, au niveau du document et au niveau du corpus. Pour chaque mot, nous récupérons le contexte au niveau du document à partir d'autres phrases du même document et le contexte au niveau du corpus à partir de phrases d'autres documents. Nous proposons un modèle qui apprend à intégrer des informations contextuelles au niveau du document et du corpus aux informations contextuelles locales via des attentions au niveau du document et du corpus, qui pondèrent dynamiquement leurs informations contextuelles respectives et déterminent l'influence de ces informations via mécanismes de portillonnage. Des expériences sur des ensembles de données de référence montrent l'efficacité de notre approche, qui permet d'obtenir des résultats de pointe pour le néerlandais, l'allemand et l'espagnol sur les ensembles de données ConLL-2002 et ConLL-2003. Nous rendrons notre code et nos modèles pré-entraînés accessibles au public à des fins de recherche.", 'pt': 'Muitas abordagens de identificação de nomes usam informações contextuais locais com muito sucesso, mas podem falhar quando o contexto local é ambíguo ou limitado. Apresentamos uma nova estrutura para melhorar a marcação de nomes utilizando informações contextuais locais, em nível de documento e em nível de corpus. Para cada palavra, recuperamos o contexto em nível de documento de outras sentenças dentro do mesmo documento e o contexto em nível de corpus de sentenças em outros documentos. Propomos um modelo que aprende a incorporar informações contextuais em nível de documento e nível de corpus juntamente com informações contextuais locais por meio de atenções em nível de documento e nível de corpus, que pesam dinamicamente suas respectivas informações contextuais e determinam a influência dessas informações por meio de mecanismos de gating. Experimentos em conjuntos de dados de referência mostram a eficácia de nossa abordagem, que alcança resultados de última geração para holandês, alemão e espanhol nos conjuntos de dados CoNLL-2002 e CoNLL-2003. Disponibilizaremos publicamente nosso código e modelos pré-treinados para fins de pesquisa.', 'es': 'Muchos enfoques de etiquetado de nombres utilizan información contextual local con mucho éxito, pero pueden fallar cuando el contexto local es ambiguo o limitado. Presentamos un nuevo marco para mejorar el etiquetado de nombres mediante el uso de información contextual local, a nivel de documento y a nivel de corpus. Para cada palabra, recuperamos el contexto de nivel de documento de otras oraciones dentro del mismo documento y el contexto de nivel de cuerpo de oraciones de otros documentos. Proponemos un modelo que aprende a incorporar información contextual a nivel de documento y a nivel de corpus junto con la información contextual local a través de atenciones a nivel de documento y a nivel de corpus, que ponderan dinámicamente su información contextual respectiva y determinan la influencia de esta información a través de mecanismos de compuerta. Los experimentos sobre conjuntos de datos de referencia muestran la eficacia de nuestro enfoque, que logra resultados de vanguardia para el holandés, el alemán y el español en los conjuntos de datos ConLL-2002 y ConLL-2003. Pondremos nuestro código y modelos previamente entrenados a disposición del público con fines de investigación.', 'ja': '多くの名前タグ付けアプローチは、ローカルコンテキスト情報を使用して大変成功していますが、ローカルコンテキストが曖昧または制限されている場合は失敗する可能性があります。 ローカル、ドキュメントレベル、およびコーパスレベルのコンテキスト情報を活用して、名前タグ付けを改善する新しいフレームワークを提示します。 各単語について、同じドキュメント内の他の文からドキュメントレベルのコンテキストを取得し、他のドキュメント内の文からコーパスレベルのコンテキストを取得します。 ドキュメントレベルとコーパスレベルの注意を介して、ドキュメントレベルとコーパスレベルのコンテキスト情報をローカルのコンテキスト情報とともに組み込むことを学ぶモデルを提案します。これは、それぞれのコンテキスト情報を動的に重み付けし、ゲーティングメカニズムを介してこの情報の影響を決定します。 ベンチマークデータセットの実験は、CoNLL -2002およびCoNLL -2003データセットのオランダ語、ドイツ語、およびスペイン語の最先端の結果を達成する当社のアプローチの有効性を示しています。 私たちは、コードと事前トレーニング済みモデルを研究目的で一般に公開します。', 'zh': '诸名标用本地上下文信息大成,然上下文不明受限,可败也。 建一新框架,因本地、文档级、语料库级上下文信息以改其名。 凡单词,同文档之他句,文档文档级上下文,而从他文档之句,索语料库之上下文。 吾为法者,因文档级与语料库级以学文档级、语料库级上下文息与地上下文合,其动也加权其上下文息也,因门控而定之。 准数之实验见吾法之有效性,当于CoNLL-2002、CoNLL-2003数集上得荷兰语,德语、西班牙语之最新也。 吾将明吾代码与豫练之形以究其志。', 'hi': 'कई नाम टैगिंग दृष्टिकोण बहुत सफलता के साथ स्थानीय प्रासंगिक जानकारी का उपयोग करते हैं, लेकिन जब स्थानीय संदर्भ अस्पष्ट या सीमित होता है तो विफल हो सकता है। हम स्थानीय, दस्तावेज़-स्तर और कॉर्पस-स्तर की प्रासंगिक जानकारी का उपयोग करके नाम टैगिंग में सुधार करने के लिए एक नया ढांचा प्रस्तुत करते हैं। प्रत्येक शब्द के लिए, हम एक ही दस्तावेज़ के भीतर अन्य वाक्यों से दस्तावेज़-स्तर के संदर्भ और अन्य दस्तावेज़ों में वाक्यों से कॉर्पस-स्तर के संदर्भ को पुनर्प्राप्त करते हैं। हम एक मॉडल का प्रस्ताव करते हैं जो दस्तावेज़-स्तर और कॉर्पस-स्तर की प्रासंगिक जानकारी के माध्यम से स्थानीय प्रासंगिक जानकारी के साथ दस्तावेज़-स्तर और कॉर्पस-स्तर की प्रासंगिक जानकारी को शामिल करना सीखता है, जो गतिशील रूप से उनकी संबंधित प्रासंगिक जानकारी का वजन करता है और गेटिंग तंत्र के माध्यम से इस जानकारी के प्रभाव को निर्धारित करता है। बेंचमार्क डेटासेट पर प्रयोग हमारे दृष्टिकोण की प्रभावशीलता को दिखाते हैं, जो CoNLL-2002 और CoNLL-2003 डेटासेट पर डच, जर्मन और स्पेनिश के लिए अत्याधुनिक परिणाम प्राप्त करता है। हम अपने कोड और पूर्व-प्रशिक्षित मॉडल को अनुसंधान उद्देश्यों के लिए सार्वजनिक रूप से उपलब्ध कराएंगे।', 'ru': 'Многие подходы к присвоению имен используют локальную контекстную информацию с большим успехом, но могут потерпеть неудачу, когда локальный контекст неоднозначен или ограничен. Мы представляем новую структуру для улучшения маркировки имен с использованием контекстной информации на местном уровне, уровне документов и уровне корпусов. Для каждого слова мы извлекаем контекст на уровне документа из других предложений в рамках одного документа и контекст на уровне корпуса из предложений в других документах. Мы предлагаем модель, которая учится включать контекстную информацию на уровне документа и на уровне корпуса наряду с локальной контекстной информацией через внимание на уровне документа и на уровне корпуса, которая динамически взвешивает их соответствующую контекстную информацию и определяет влияние этой информации через механизмы стробирования. Эксперименты с базовыми наборами данных показывают эффективность нашего подхода, который достигает самых современных результатов для голландских, немецких и испанских наборов данных CoNLL-2002 и CoNLL-2003. Мы сделаем наш код и предварительно обученные модели общедоступными для исследовательских целей.', 'ga': 'Úsáideann go leor cineálacha cur chuige clibeála ainm faisnéis chomhthéacsúil áitiúil go rathúil, ach is féidir go dteipeann orthu nuair a bhíonn an comhthéacs áitiúil débhríoch nó teoranta. Cuirimid creat nua i láthair chun feabhas a chur ar chlibeáil ainmneacha trí úsáid a bhaint as faisnéis chomhthéacsúil áitiúil, doiciméad-leibhéil agus corpais. I gcás gach focal, aisghabhaimid comhthéacs leibhéal doiciméid ó abairtí eile laistigh den doiciméad céanna agus comhthéacs leibhéal corpais ó abairtí i ndoiciméid eile. Molaimid múnla a fhoghlaimíonn conas faisnéis chomhthéacsúil ar leibhéal doiciméad agus ar leibhéal corpais a ionchorprú in éineacht le faisnéis chomhthéacsúil áitiúil trí airdí ar leibhéal doiciméad agus ar leibhéal corpais, a mheáchan go dinimiciúil a gcuid faisnéise comhthéacsúla faoi seach agus a chinneann tionchar na faisnéise seo trí mheicníochtaí geataithe. Léiríonn turgnaimh ar thacair sonraí tagarmhairc éifeachtacht ár gcur chuige, a ghnóthaíonn torthaí den scoth don Ollainnis, don Ghearmáinis agus don Spáinnis ar thacair sonraí CoNLL-2002 agus CoNLL-2003. Cuirfimid ár gcód agus ár múnlaí réamhoilte ar fáil go poiblí chun críocha taighde.', 'ka': 'მნიშვნელოვანი სახელის შესაძლებლობა ლოკალური კონტექსტური ინფორმაციას ძალიან წარმატებით გამოყენება, მაგრამ შეუძლებელია შეუძლებელია, როცა ლოკალურ ჩვენ ჩვენ ახალი ფრამეტრის ჩვენებათ, რომ დავიწყებთ სახელის მონიშნული სახელის შესახებ ლოკალური, დოკუმენტის დონე და კონტექსტური ინფორმაცია. ყოველ სიტყვის, ჩვენ კონტექსტის დოკუმენტის კონტექსტის სხვა სიტყვილებიდან ერთი დოკუმენტის და corpus-level კონტექსტის კონტექსტიდან სხვა დოკ ჩვენ მოვიწყებთ მოდელს, რომელიც ვისწავლის კონტექსტური ინფორმაცია დოკუმენტის დოკუმენტის და კონტექსტური დოკუმენტის კონტექსტური ინფორმაციას, რომელიც დოკუმენტის დოკუმენტის და კოპუუსს დოკუმენტის ბენქმარკის მონაცემების გამოცდილებები ჩვენი მონაცემების ეფექტიურობა, რომელიც ჰონქმანეთის, გერმანეთის და სპანელის მონაცემებისთვის მიიღებს მონაცემები CoNLL-2002 და CoNLL-2003. ჩვენ ჩვენი კოდის და პრეტრექტირებული მოდელების სახელსაწყისთვის გავაკეთებთ.', 'el': 'Πολλές προσεγγίσεις σήμανσης ονομάτων χρησιμοποιούν τοπικές πληροφορίες περιβάλλοντος με μεγάλη επιτυχία, αλλά μπορεί να αποτύχουν όταν το τοπικό πλαίσιο είναι διφορούμενο ή περιορισμένο. Παρουσιάζουμε ένα νέο πλαίσιο για τη βελτίωση της επισήμανσης ονομάτων χρησιμοποιώντας πληροφορίες περιβάλλοντος σε τοπικό επίπεδο, σε επίπεδο εγγράφου και σε επίπεδο σώματος. Για κάθε λέξη, ανακτούμε περιεχόμενο σε επίπεδο εγγράφου από άλλες προτάσεις εντός του ίδιου εγγράφου και πλαίσιο σε επίπεδο σώματος από προτάσεις σε άλλα έγγραφα. Προτείνουμε ένα μοντέλο που μαθαίνει να ενσωματώνει πληροφορίες σε επίπεδο εγγράφου και σε επίπεδο σώματος παράλληλα με τοπικές πληροφορίες περιβάλλοντος μέσω προσοχής σε επίπεδο εγγράφου και σώματος, οι οποίες ζυγίζουν δυναμικά τις αντίστοιχες πληροφορίες περιβάλλοντος και καθορίζουν την επιρροή αυτών των πληροφοριών μέσω μηχανισμών πύλης. Τα πειράματα σε σύνολα δεδομένων αναφοράς δείχνουν την αποτελεσματικότητα της προσέγγισής μας, η οποία επιτυγχάνει αποτελέσματα τελευταίας τεχνολογίας για τα ολλανδικά, γερμανικά και ισπανικά στα σύνολα δεδομένων CoNLL-2002 και CoNLL-2003. Θα καταστήσουμε τον κώδικα και τα προ-εκπαιδευμένα μοντέλα μας δημόσια διαθέσιμα για ερευνητικούς σκοπούς.', 'hu': 'Számos névcímkézési megközelítés nagy sikerrel használja a helyi kontextuális információkat, de sikertelen lehet, ha a helyi kontextus kétértelmű vagy korlátozott. Új keretrendszert mutatunk be a névcímkézés javítására helyi, dokumentumszintű és korpusz szintű kontextuális információk felhasználásával. Minden szó esetében dokumentumszintű kontextust nyerünk le ugyanazon dokumentumon belüli más mondatokból és corpus szintű kontextust más dokumentumokból. Olyan modellt javaslunk, amely megtanulja a dokumentumszintű és korpusz szintű kontextuális információkat a helyi kontextuális információk mellett dokumentumszintű és korpusz szintű figyelmeztetéseken keresztül beépíteni, amelyek dinamikusan súlyozzák a kontextuális információkat, és ezen információk hatását a gating mechanizmusok segítségével határozzák meg. A benchmark adatkészletekkel végzett kísérletek megmutatják a megközelítés hatékonyságát, amely holland, német és spanyol számára a CoNLL-2002 és CoNLL-2003 adatkészletek legkorszerűbb eredményeket ér el. Kutatási célokra nyilvánosan hozzáférhetővé tesszük kódunkat és előre képzett modelleinket.', 'it': "Molti approcci di tag dei nomi utilizzano informazioni contestuali locali con molto successo, ma possono fallire quando il contesto locale è ambiguo o limitato. Presentiamo un nuovo framework per migliorare il tag dei nomi utilizzando informazioni contestuali locali, a livello di documento e a livello di corpus. Per ogni parola, recuperiamo contesto a livello di documento da altre frasi all'interno dello stesso documento e contesto a livello di corpus da frasi in altri documenti. Proponiamo un modello che impara a incorporare informazioni contestuali a livello di documento e corpus insieme a informazioni contestuali locali attraverso attenzioni a livello di documento e corpus, che pesano dinamicamente le rispettive informazioni contestuali e determinano l'influenza di queste informazioni attraverso meccanismi di gating. Esperimenti su set di dati di benchmark mostrano l'efficacia del nostro approccio, che raggiunge risultati all'avanguardia per olandese, tedesco e spagnolo sui set di dati CoNLL-2002 e CoNLL-2003. Renderemo pubblici i nostri codici e modelli pre-formati per scopi di ricerca.", 'kk': 'Көпшілік атау тегтерінің көпшілігі жергілікті контексті мәліметті көп сәтті болып қолданады, бірақ жергілікті контексті шектелгенде немесе шектелгенде қа Біз жергілікті, құжат деңгейі және корпус деңгейіндегі контексті мәліметті қолдану үшін атау тегтерін жақсарту үшін жаңа фреймін келтірік. Әрбір сөз үшін бір құжат деңгейіндегі контексті бір құжаттың және корпус деңгейіндегі мәтіндерінен басқа сөздерден алдық. Біз құжат деңгейінде және корпус деңгейіндегі контексті мәліметті құжат деңгейінде және корпус деңгейінде қарай мәліметті құжат деңгейінде және корпус деңгейіндегі қатынау арқылы бірге үйренген үлгі ұсынамыз. Бұл қ Деректер бағдарламаларының тәжірибелері біздің тәжірибеміздің эффективнігін көрсетеді. Бұл Нидерландық, неміс және Испан деректер бағдарламаларының CoNLL- 2002 және CoNLL- 2003 деректер бағдарламаларының Біз кодты және алдыңғы оқыту үлгілерімізді зерттеу мақсаттары үшін көпшілік жеткіземіз.', 'lt': 'Daugelis pavadinimų ženklinimo metodų sėkmingai naudoja vietinę kontekstinę informaciją, tačiau gali nepavykti, kai vietinis kontekstas yra dviprasmiškas arba ribotas. Pateikiame naują sistemą pavadinimų ženklinimo gerinimui naudojant vietos, dokumentų ir korpuso lygmens kontekstinę informaciją. Kiekvienam žodžiui iš kitų to paties dokumento ir korpuso lygio sakinių gauname dokumentų kontekstą. Siūlome model į, kuriame pasimokoma kartu su vietos kontekstine informacija įtraukti dokumentų ir korpuso lygmens kontekstinę informaciją per dokumentų ir korpuso lygmens dėmesį, kuris dinamiškai svarsto atitinkamą kontekstinę informaciją ir nustato šios informacijos įtaką naudojant gating mechanizmus. Eksperimentai, susiję su lyginamųjų duomenų rinkiniais, rodo mūsų požiūrio veiksmingumą, kuris Dutch, German ir Spanish duomenų rinkiniams duoda naujausius rezultatus CoNLL-2002 ir CoNLL-2003. Mes viešai paskelbsime savo kodeksą ir parengtus modelius mokslinių tyrimų tikslais.', 'mk': 'Многу пристапи за означување на имиња користат локални контекстни информации со голем успех, но можат да пропаднат кога локалниот контекст е нејасен или ограничен. Презентираме нова рамка за подобрување на означувањето на името со користење локални, документални и корпусни контекстни информации. За секој збор, добиваме контекст на документно ниво од други реченици во истиот документ и контекст на корпус ниво од речениците во други документи. Ние предложуваме модел кој научи да информира контекстуални информации на ниво на документ и корпус заедно со локалните контекстуални информации преку внимание на ниво на документ и корпус, кои динамично ги тежат нивните контекстуални информации и го одредуваат влијанието на овие информации преку механи Експериментите на базите на податоци покажуваат ефикасност на нашиот пристап, кој постигнува најдобри резултати за холандските, германските и шпанските бази на податоци CoNLL-2002 и CoNLL-2003. Ќе го направиме нашиот код и предобучени модели јавно достапни за истражувачки цели.', 'ms': 'Banyak pendekatan tag nama menggunakan maklumat kontekstual setempat dengan banyak kesuksesan, tetapi boleh gagal bila konteks setempat adalah ambiguh atau terbatas. Kami perkenalkan kerangka baru untuk memperbaiki tag nama dengan menggunakan maklumat kontekstual setempat, aras dokumen, dan aras-corpus. Untuk setiap perkataan, kita mendapatkan konteks aras dokumen dari kalimat lain dalam dokumen yang sama dan konteks aras corpus dari kalimat dalam dokumen lain. Kami cadangkan model yang belajar untuk memasukkan maklumat kontekstual aras dokumen dan aras corpus bersama maklumat kontekstual setempat melalui perhatian aras dokumen dan aras corpus, yang dinamik berat maklumat kontekstual sesuai mereka dan menentukan pengaruh maklumat ini melalui mekanisme gating. Eksperimen pada set data benchmark menunjukkan keefektivitas pendekatan kita, yang mencapai keputusan terbaik untuk Dutch, German, dan Spanish pada set data CoNLL-2002 dan CoNLL-2003. Kita akan membuat kod kita dan model terlatih tersedia secara awam untuk tujuan kajian.', 'ml': 'ഒരുപാട് പേര് ടാഗ്ഗിങ്ങിന്റെ അടുത്തുള്ള അടുത്തുചെല്ലുന്ന പേരുകള്\u200d വിജയത്തോടൊപ്പം സ്ഥാനമായി വിവരങ്ങള്\u200d ഉപയ നാമൊരു പുതിയ ഫ്രെയിമാര്\u200dക്ക് കൊടുക്കുന്നു. ലോക്കല്\u200d, രേഖകള്\u200d നില, കോര്\u200dപ്പസ് നില വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനാ ഓരോ വാക്കിനും വേണ്ടി, ഒരേ രേഖയില്\u200d നിന്നും കോര്\u200dപ്പസ് നില വാക്കുകളില്\u200d നിന്നും മറ്റു വാക്കുകളില്\u200d നിന്നും രേഖകളില്\u200d നി നമ്മള്\u200d ഒരു മോഡല്\u200d പഠിക്കുന്നു, രേഖയുടെ നിലവും കോര്\u200dപ്പസ് നില വിവരങ്ങളും പ്രാദേശിക വിവരങ്ങളോടൊപ്പം ഉള്\u200dപെടുത്താന്\u200d പഠിക്കുന്നു. രേഖയുടെ നില വിവരങ്ങളും കോര്\u200dപ്പിസ് നില വ ബെങ്ക്മാര്\u200dക്ക് ഡേറ്റാസറ്റുകളിലെ പരീക്ഷണങ്ങള്\u200d നമ്മുടെ നടപടിയുടെ പ്രഭാവം കാണിച്ചുകൊടുക്കുന്നു. അത് ഡച്ച്, ജര്\u200dമ്മന്\u200d, സ്പാനിഷ് എന്\u200dഎല്\u200d- 2002, കോണ്\u200dഎല ഞങ്ങള്\u200d നമ്മുടെ കോഡും പരിശീലിക്കപ്പെട്ട മോഡലുകളും പഠിപ്പിക്കുന്നതിനുവേണ്ടിയാണ്.', 'mt': "Ħafna approċċi ta’ tikkettar tal-ismijiet jużaw informazzjoni kuntestwali lokali b’ħafna suċċess, iżda jistgħu jfallu meta l-kuntest lokali jkun ambigwu jew limitat. Aħna nippreżentaw qafas ġdid għat-titjib tat-tikkettar tal-ismijiet billi nużaw informazzjoni kuntestwali lokali, fil-livell tad-dokumenti u fil-livell tal-korpus. Għal kull kelma, niġbru l-kuntest fil-livell tad-dokument minn sentenzi oħra fl-istess dokument u fil-kuntest fil-livell tal-korpus minn sentenzi f’dokumenti oħra. Aħna nipproponu mudell li jitgħallem jinkorpora informazzjoni kuntestwali fil-livell tad-dokument u fil-livell tal-korpus flimkien ma’ informazzjoni kuntestwali lokali permezz ta’ attenzjoni fil-livell tad-dokument u fil-livell tal-korpus, li b’mod dinamiku jqis l-informazzjoni kuntestwali rispettiva tagħhom u jiddetermina l-influwenza ta’ din l-informazzjoni permezz ta’ mekkaniżmi ta’ gating. L-esperimenti dwar settijiet ta’ dejta ta’ referenza juru l-effettività tal-approċċ tagħna, li jikseb riżultati l-aktar avvanzati għall-Olandiżi, il-Ġermaniżi u Spanjoli dwar settijiet ta’ dejta CoNLL-2002 u CoNLL-2003. Ser nagħmlu l-kodiċi tagħna u l-mudelli mħarrġa minn qabel disponibbli għall-pubbliku għal skopijiet ta' riċerka.", 'mn': 'Ихэнх нэр тэгшитгэлийн арга баримтууд орон нутгийн contextual мэдээллийг маш их амжилттай ашигладаг. Гэхдээ орон нутгийн нөхцөл байдал нь тохиромжтой эсвэл хязгаарлагддаг үед ал Бид орон нутгийн, баримт-түвшин, корпус-түвшин орчин үеийн мэдээллийг ашиглаж нэрлэлтийг сайжруулахын тулд шинэ хэлбэрийг тайлбарлаж байна. Өөрөөр хэлбэл бид баримтын түвшинд нэг баримт болон корпус түвшинд бусад баримт бичсэн үгийг өөр өгүүлбэлээс авдаг. Бид баримтын түвшин болон корпус түвшин орчин үеийн мэдээллийн хамтран баримтын түвшин болон корпус түвшин хандлагатай мэдээллийг бүрдүүлэхийг суралцах загварын загварыг суралцаж байна. Энэ нь баримтын түвшин болон корпус түвшин хандлагатай байдаг. Энэ нь тэдний харьцааны Банкмарк өгөгдлийн сангийн туршилтын туршилт нь бидний арга хэмжээний үр дүнг харуулдаг. Энэ нь Далланд, Герман, Испан, CoNLL-2002 болон CoNLL-2003 өгөгдлийн сангийн уламжлалтын үр дүнг гаргадаг. Бид судалгааны зорилго дээр код болон урьд сургалтын загварыг олон нийтэд ашиглах болно.', 'no': 'Mange tilnærmingar for merking av namn brukar lokale kontekstinformasjon med mykje suksess, men kan mislukkast når lokale konteksten er ugyldig eller begrenset. Vi presenterer eit nytt rammeverk for å forbetra namnet ved å bruka lokal, dokumentnivå og kontekstinformasjon om korpusnivå. For kvar ord, hentar vi dokumentnivåkontekst frå andre setningar i samme dokument og korpusnivåkontekst frå setningar i andre dokument. Vi foreslår eit modell som lærer å inkludere kontekstinformasjon om dokumentnivå og korpusnivå blant lokale kontekstinformasjon ved hjelp av dokumentnivå og korpusnivå, som dynamisk vekt sine respektive kontekstinformasjon og bestemmer påvirkninga av denne informasjonen gjennom samlingsmekanisasjonar. Eksperimentar på benchmarkdatasett viser effektiviteten av tilnærminga vårt, som oppnår kunstige resultat for nederlandsk, tysk og spansk datasett CoNLL-2002 og CoNLL-2003. Vi vil gjera våre kode og føretrainerte modeller offentlig tilgjengeleg for forskningsmål.', 'pl': 'Wiele podejść do tagowania nazw wykorzystuje lokalne informacje kontekstowe z dużym powodzeniem, ale może się nie udać, gdy kontekst lokalny jest niejednoznaczny lub ograniczony. Prezentujemy nowe ramy usprawniające tagowanie nazw poprzez wykorzystanie lokalnych, dokumentowych i korpusowych informacji kontekstowych. Dla każdego słowa pobieramy kontekst na poziomie dokumentu z innych zdań w tym samym dokumencie i kontekst na poziomie korpusu ze zdań w innych dokumentach. Proponujemy model, który uczy się łączyć informacje kontekstowe na poziomie dokumentu i korpusu wraz z lokalnymi informacjami kontekstowymi poprzez uwagi na poziomie dokumentu i korpusu, które dynamicznie ważą odpowiednie informacje kontekstowe i określają wpływ tych informacji poprzez mechanizmy gating. Eksperymenty na zbiorach danych referencyjnych pokazują skuteczność naszego podejścia, które osiąga najnowocześniejsze wyniki dla holenderskich, niemieckich i hiszpańskich zbiorów danych CoNLL-2002 i CoNLL-2003. Nasz kod i wstępnie przeszkolone modele udostępniamy publicznie do celów badawczych.', 'ro': 'Multe abordări de etichetare a numelor utilizează informații contextuale locale cu mult succes, dar pot eșua atunci când contextul local este ambiguu sau limitat. Vă prezentăm un nou cadru pentru a îmbunătăți etichetarea numelui utilizând informații contextuale locale, la nivel de document și la nivel de corpus. Pentru fiecare cuvânt, preluăm contextul la nivel de document din alte propoziții din același document și contextul la nivel de corpus din propoziții din alte documente. Propunem un model care învață să încorporeze informații contextuale la nivel de document și corpus alături de informațiile contextuale locale prin atenții la nivel de document și corpus, care ponderează dinamic informațiile contextuale respective și determină influența acestor informații prin mecanisme de gating. Experimentele pe seturi de date de referință arată eficacitatea abordării noastre, care obține rezultate de ultimă oră pentru olandezi, germani și spanioli pe seturile de date CoNLL-2002 și CoNLL-2003. Vom pune la dispoziția publicului codul și modelele pre-instruite în scopuri de cercetare.', 'so': 'Inta badan magaca lagugu baahdo waxay isticmaalaan macluumaad joogto ah oo ku saabsan guulaysta, laakiin waxay suurtagal noqon karaan marka ay xaaladda deegaanka ku haysato ama ay ku xadgudbaan. Waxaynu soo bandhignaynaa shirkad cusub si aan u hagaajinno magaca tagsiga, isticmaalka macluumaadka joogtada ah ee degmada, heerka wargeyska iyo heerka qoyska. Hadal kastaba waxaan ka soo celinaynaa qoraal-heerka wargeyska oo kale oo ku qoran qoraal isku mid ah iyo qoraal isku mid ah oo ku qoran qoraalo kale. Tusaale ah oo baranaya in lagu soo qoro heerka wargeyska iyo heerka qofka iyo macluumaadka joogtada ah oo la xiriira macluumaadka joogtada ee deegaanka, taas oo si fiican ugu miisaamaya macluumaadka joogtada ah ee warqada qoraalka iyo heerka qoyska, wuxuuna ku qeexayaa saameynta macluumaadkaas si gaar ah ugu saameysashada macluumaadka. Imtixaan ku saabsan taariikhda benchmarkiga waxay muujiyaan waxyaabaha ay leedahay qaabeeneeneena, taas oo gaadha dhacdooyinka farshaxanka ee Dutch, Jarmal, iyo Isbanish oo ku qoran CoNLL-2002 iyo CoNLL-2003. Waxaannu ka samaynaynaa sumaddeena iyo modelalka horay loo tababaray oo si bayaan ah loo heli karo baaritaanka.', 'sr': 'Mnogi pristupi označavanja imena koriste lokalne kontekstske informacije sa mnogo uspeha, ali mogu propasti kada je lokalni kontekst ambigujan ili ograničen. Predstavljamo novi okvir za poboljšanje oznake imena korištenjem lokalnih, nivoa dokumenta i kontekstnih informacija na nivou korpusa. Za svaku reč, dobijamo kontekst na nivou dokumenta iz drugih rečenica u istom dokumentu i kontekstu na nivou korpusa iz rečenica u drugim dokumentima. Predlažemo model koji nauči da uključuje kontekstne informacije na nivou dokumenta i razini korpusa uz lokalne kontekstne informacije putem pažnje na nivo dokumenta i razine korpusa, koji dinamično teži njihove odgovarajuće kontekstne informacije i određuje uticaj te informacije putem prikupljanja mehanizma. Eksperimenti o standardnim podacima pokazuju učinkovitost našeg pristupa, koji postiže rezultate države umjetnosti nizozemskih, nemačkih i španjolskih podataka na CoNLL-2002 i CoNLL-2003. Naši kod i predobučeni modeli ćemo javno biti dostupni za istraživačke svrhe.', 'si': 'Name අපි අළුත් පරීක්ෂණයක් පෙන්වන්නේ ස්ථානික, විස්තාරය සහ කොර්පස් ලේවල් පරීක්ෂණ තොරතුරු ප්\u200dරයෝජනය හැම වචනයක්ම වෙනුවෙන්, අපි වෙනුවෙන් ලිපින්ත වචනයක් වලින් අනිත් වචනයක් වලින් ලැබෙනවා. අපි ප්\u200dරශ්නයක් කරනවා මොඩල් එකක් ඉගෙන ගන්නේ ලේඛන-ලේවල් සහ කෝපස් ලේවල් සංස්ථානය තොරතුරු සමඟ ස්ථානික සංස්ථානය තොරතුරු සමඟ ලේඛන-ලේවල් සහ කෝපස් ල බෙන්ච්මාර්ක් දත්ත සෙට්ටුවේ පරීක්ෂණය පෙන්වන්නේ අපේ විදියට ප්\u200dරශ්නයක් පෙන්වන්න, ඒකෙන් ඩොච්ච්, ජර්මන්, සහ ස්පැනිස් දේත අපි අපේ කෝඩ් එක සහ ප්\u200dරධානය කරලා තියෙන්නේ සාමාන්\u200dය විදියට පරීක්ෂණ අරමුදාවට.', 'sv': 'Många metoder för namnmärkning använder lokal kontextuell information med stor framgång, men kan misslyckas när det lokala sammanhanget är tvetydigt eller begränsat. Vi presenterar ett nytt ramverk för att förbättra namnmärkning genom att använda kontextuell information på lokal, dokumentnivå och corpusnivå. För varje ord hämtar vi dokument-nivå kontext från andra meningar inom samma dokument och corpusnivå kontext från meningar i andra dokument. Vi föreslår en modell som lär sig att införliva kontextuell information på dokumentnivå och corpusnivå tillsammans med lokal kontextuell information via dokumentnivå och corpusnivå uppmärksamheter, som dynamiskt väger deras respektive kontextuella information och bestämmer påverkan av denna information genom gatingmekanismer. Experiment på benchmarkdatauppsättningar visar effektiviteten i vår strategi, som uppnår toppmoderna resultat för nederländska, tyska och spanska på datauppsättningarna CoNLL-2002 och CoNLL-2003. Vi kommer att göra vår kod och förklädda modeller offentligt tillgängliga för forskningsändamål.', 'ta': 'நிறைய பெயர் குறிப்பு அடையாளங்கள் உள்ளார்ந்த தற்காலிக தகவல் மிக வெற்றியுடன் பயன்படுத்துகிறது, ஆனால் உள்ளூர் சூழல உள்ளமைப்பு, ஆவண நிலையை பயன்படுத்தி புதிய சட்டத்தை மேம்படுத்துவதற்கு, மற்றும் கார்ப்ஸ்- நிலை தற்காலிக தகவலை பயன்படுத்த @ info நாம் ஒரு மாதிரி கற்றுக் கொண்டிருக்கும் ஆவண- மட்டத்தில் மற்றும் கார்ப்ஸ்- மட்டத்தில் உள்ள தற்காலிக தகவலுடன் உள்ளமைப்பு தகவலுடன் மற்றும் ஆவண- மட்டத்தில் மற்றும் கார்ப்ஸ்- நிலை கவனம்  பெங்க்மேக் தரவுத்தளங்களின் சோதனைகள் எங்கள் செயல்பாட்டின் வெளிப்பாட்டை காட்டுகிறது, இது டேச்சு, ஜெர்மன் மற்றும் ஸ்பானிஷ் தகவல் அமைப்புகளின் நிலைய நாம் எங்கள் குறியீடு மற்றும் முன் பயிற்சி மாதிரிகளை பொதுவாக கிடைக்கும் ஆராய்ச்சி இலக்குகளுக', 'ur': 'بہت سی نام ٹاگ کے مطابق محلی کنٹکسٹیول معلومات کو بہت موفقیت کے ساتھ استعمال کر سکتے ہیں، لیکن جب محلی کنٹکسٹ غیر مشکل یا محدودہ ہوتی ہے وہ غلطی کر سکتا ہے. ہم نے ایک نوی فرمود پیش کیا ہے کہ نام ٹاگ کو ترجیح دینے کے لئے محلی، دفتر سطح، اور corpus-level contextual معلومات کے مطابق استعمال کریں. ہر کلمہ کے لئے، ہم ایک دوسرے کلمز کے درمیان دوسرے کلمز سے دوسرے کلمز سے اور دوسرے دفتروں میں سے کلمز سے دوسرے کلمز سے اٹھاتے ہیں۔ ہم ایک موڈل کو پیشنهاد کرتے ہیں جو سند-سطح اور کورپوس-سطح متوسط معلومات کے ساتھ سند-سطح اور کورپوس-سطح توجه کے ذریعہ سے سکھاتا ہے اور اس معلومات کا تأثیر مقرر کرتا ہے بنچم مارک ڈیٹ سٹ کے تجربے ہمارے طریقے کے اثرات کو دکھاتے ہیں، جو ڈچ، جرمن اور اسپانیایی کے لئے ڈیٹ سٹ کے لئے موجود ہے، CoNLL-2002 اور CoNLL-2003 کے ڈیٹ سٹ پر. ہم اپنے کوڈ اور پیش آموزش کی موڈل کو محلی طور پر تحقیق کے مطابق موجود بنائیں گے.', 'uz': "@ info Name Har bir so'z uchun biz bitta hujjat va corpus- darajada boshqa hujjatdagi bir so'zlardan foydalanish mumkin. Биз ҳужжат даражасини ва ҳужжат даражасини мувофиқ маълумотларни ҳужжат даражаси ва ҳужжат даражаси билан ҳужжат даражаси ва ҳужжат даражаси маълумотларга қўшилишини ўргатаётган model ни таржима этамиз, у ўз қонун турли маълумотлар тўғрисида ўзгартириш маълумотларини тўсиш ва ушбу маълумотларни тўсиш манзиллари билан таъсирларини аниқлайди. Benchmark maʼlumotlar tarkibida tajribalarimizni ko'rsatish mumkin. Bu Dutch, Olmon va Ispanchaga CoNLL-2002 va CoNLL-2003 maʼlumotlar satrlarining holatini amalga oshirish mumkin. Biz kodlash va oldingi taʼminlovchi modellarimizni taʼminlovchi qanday qilish uchun topilamiz.", 'vi': 'Nhiều phương pháp đánh dấu tên dùng các thông tin ngữ cảnh địa phương với nhiều thành công, nhưng có thể thất bại khi bối cảnh địa phương mơ hồ hoặc hạn chế. Chúng tôi giới thiệu một cơ sở mới để cải thiện danh hiệu bằng cách sử dụng thông tin ngữ cảnh địa phương, công nghệ và thông tin nội bộ. Mỗi từ, chúng tôi lấy bối cảnh cấp tài liệu từ các câu khác trong cùng một tài liệu và ngữ cảnh tập thể từ câu trong các tài liệu khác. Chúng tôi đề xuất một kiểu mẫu học cách kết hợp các thông tin ngữ cảnh bằng các thông tin ngữ cảnh ở địa phương thông qua các phương trình tài liệu và tập thể, để ý đến các thông tin ngữ cảnh liên quan, và xác định các tác động của thông tin này qua các máy lọc. Thử nghiệm trên các bộ dữ liệu tiêu chuẩn cho thấy hiệu quả của phương pháp này, đạt được kết quả tối tân nhất của Dutch, Đức và Tây Ban Nha trong bộ dữ liệu CoNll-2001 và CoNll-2001. Chúng tôi sẽ công khai mã hóa và các mẫu được đào tạo để nghiên cứu.', 'bg': 'Много подходи за етикетиране на имена използват локална контекстуална информация с много успех, но могат да се провалят, когато локалният контекст е двусмислен или ограничен. Представяме нова рамка за подобряване на етикетирането на имената чрез използване на локална, документална и корпусна контекстуална информация. За всяка дума извличаме контекст на ниво документ от други изречения в същия документ и контекст на ниво корпус от изречения в други документи. Предлагаме модел, който се научава да включва контекстуална информация на ниво документ и корпус заедно с локална контекстуална информация чрез вниманието на ниво документ и корпус, което динамично претегля съответната контекстуална информация и определя влиянието на тази информация чрез механизми за свързване. Експериментите с референтни набори от данни показват ефективността на нашия подход, който постига най-съвременни резултати за нидерландски, немски и испански за наборите от данни CoNLL-2002 и CoNLL-2003. Ние ще направим нашия код и предварително обучени модели публично достъпни за изследователски цели.', 'da': 'Mange tilgange til navngivning bruger lokale kontekstuelle oplysninger med stor succes, men kan mislykkes, når den lokale kontekst er tvetydig eller begrænset. Vi præsenterer en ny ramme for at forbedre navnetegning ved at bruge lokale, dokumentniveau og korpusniveau kontekstuelle oplysninger. For hvert ord henter vi dokumentniveau kontekst fra andre sætninger inden for samme dokument og corpusniveau kontekst fra sætninger i andre dokumenter. Vi foreslår en model, der lærer at indarbejde kontekstuelle oplysninger på dokumentniveau og korpusniveau sammen med lokale kontekstuelle oplysninger via opmærksomheder på dokumentniveau og korpusniveau, som dynamisk vægter deres respektive kontekstuelle oplysninger og bestemmer indflydelsen af disse oplysninger gennem gating mekanismer. Eksperimenter med benchmark datasæt viser effektiviteten af vores tilgang, som opnår state-of-the-art resultater for hollandsk, tysk og spansk på CoNLL-2002 og CoNLL-2003 datasæt. Vi vil gøre vores kode og forududdannede modeller offentligt tilgængelige til forskningsformål.', 'nl': 'Veel naamlabelbenaderingen gebruiken lokale contextuele informatie met veel succes, maar kunnen mislukken wanneer de lokale context dubbelzinnig of beperkt is. We presenteren een nieuw framework om naamlabeling te verbeteren door gebruik te maken van lokale, documentniveau en corpusniveau contextuele informatie. Voor elk woord halen we context op documentniveau op uit andere zinnen binnen hetzelfde document en corpus-niveau context uit zinnen in andere documenten. We stellen een model voor dat leert om contextuele informatie op documentniveau en corpusniveau te integreren naast lokale contextuele informatie via attenties op documentniveau en corpusniveau, die hun respectieve contextuele informatie dynamisch wegen en de invloed van deze informatie bepalen via gating mechanismen. Experimenten met benchmark datasets tonen de effectiviteit van onze aanpak aan, die state-of-the-art resultaten oplevert voor Nederlands, Duits en Spaans op de CoNLL-2002 en CoNLL-2003 datasets. We zullen onze code en voorgetrainde modellen openbaar beschikbaar maken voor onderzoeksdoeleinden.', 'de': 'Viele Ansätze zur Namenstagung verwenden lokale Kontextinformationen mit großem Erfolg, können aber scheitern, wenn der lokale Kontext mehrdeutig oder begrenzt ist. Wir präsentieren ein neues Framework zur Verbesserung der Namenstagung durch die Nutzung lokaler, dokument- und korpusbezogener Kontextinformationen. Für jedes Wort rufen wir Kontext auf Dokumentenebene aus anderen Sätzen innerhalb desselben Dokuments und Kontext auf Korpusebene aus Sätzen in anderen Dokumenten ab. Wir schlagen ein Modell vor, das lernt, kontextbezogene Informationen auf Dokumenten- und Korpusebene neben lokalen Kontextinformationen über Aufmerksamkeiten auf Dokumenten- und Korpusebene zu integrieren, die ihre jeweiligen Kontextinformationen dynamisch gewichten und den Einfluss dieser Informationen durch Gating-Mechanismen bestimmen. Experimente mit Benchmark-Datensätzen zeigen die Effektivität unseres Ansatzes, der State-of-the-Art Ergebnisse für Niederländisch, Deutsch und Spanisch auf den CoNLL-2002 und CoNLL-2003 Datensätzen erzielt. Wir werden unseren Code und vortrainierte Modelle für Forschungszwecke öffentlich zugänglich machen.', 'hr': 'Mnogi pristupi označavanja imena koriste lokalne kontekstske informacije s puno uspjeha, ali mogu propasti kada je lokalni kontekst ambigujan ili ograničen. Predstavljamo novi okvir za poboljšanje oznake imena koristeći lokalne, razine dokumenta i kontekstske informacije na razini korpusa. Za svaku riječ dobijamo kontekst razine dokumenta iz drugih rečenica u istom dokumentu i kontekstu razine tijela iz rečenica u drugim dokumentima. Predlažemo model koji nauči uključiti kontekstne informacije na razini dokumenta i razini korpusa zajedno s lokalnim kontekstskim informacijama putem pažnje na razini dokumenta i razini korpusa, koji dinamički teži njihove odgovarajuće kontekstske informacije i određuje utjecaj te informacije putem prikupljanja mehanizama. Eksperimenti na temeljnim podacima pokazuju učinkovitost našeg pristupa, koji postigne rezultate umjetnosti za nizozemske, njemačke i španjolske podatke CoNLL-2002 i CoNLL-2003. Učinit ćemo naš kod i predobučeni modeli javno dostupnim za istraživačke svrhe.', 'id': 'Banyak pendekatan tagging nama menggunakan informasi kontekstual lokal dengan banyak sukses, tetapi dapat gagal ketika konteks lokal adalah ambiguh atau terbatas. Kami mempersembahkan rangka baru untuk meningkatkan penandaan nama dengan menggunakan informasi kontekstual lokal, tingkat dokumen, dan tingkat corpus. Untuk setiap kata, kita mendapatkan konteks tingkat dokumen dari kalimat lain dalam dokumen yang sama dan konteks tingkat corpus dari kalimat dalam dokumen lain. Kami mengusulkan model yang belajar untuk memasukkan informasi kontekstual tingkat dokumen dan tingkat corpus bersama informasi kontekstual lokal melalui perhatian tingkat dokumen dan tingkat corpus, yang dinamik berat informasi kontekstual mereka dan menentukan pengaruh informasi ini melalui mekanisme gating. Eksperimen pada set data benchmark menunjukkan efektivitas pendekatan kita, yang mencapai hasil terbaik bagi Belanda, Jerman, dan Spanyol pada set data CoNLL-2002 dan CoNLL-2003. Kita akan membuat kode kita dan model pre-terlatih tersedia publik untuk tujuan penelitian.', 'sw': 'Matokeo mengi ya kutumia taarifa za kimataifa kwa mafanikio mengi, lakini yanaweza kushindwa pale muktadha wa eneo hilo ni usiotarajiwa au ukomo. Tunaweza kutengeneza mfumo mpya wa kuboresha ujumbe wa jina kwa kutumia taarifa za kitaifa, kiwango cha dokumentari na viwango vya makampuni. Kwa kila neno, tunaweza kupata muktadha wa kiwango cha dokumentari kutoka kwenye sentensi nyingine ndani ya nyaraka hiyo na muktadha wa ngazi za makampuni kutoka hukumu katika nyaraka nyingine. We propose a model that learns to incorporate document-level and corpus-level contextual information alongside local contextual information via document-level and corpus-level attentions, which dynamically weight their respective contextual information and determines the influence of this information through gating mechanisms.  Jaribio la taarifa za bendera zinaonyesha ufanisi wa hatua yetu, ambazo zinafanikiwa matokeo ya hali ya sanaa kwa Uholanzi, Ujerumani na Uhispania katika seti za data za CoNLL-2002 na CoNLL-2003. Tutakufanya sheria zetu na mifano ya zamani iliyoendeshwa kwa umma kwa ajili ya malengo ya utafiti.', 'ko': '많은 이름 표기 방법은 로컬 상하문 정보를 사용하는 데 매우 성공하지만, 로컬 상하문이 명확하지 않거나 제한되어 있을 때 실패할 수 있습니다.우리는 로컬, 문서, 자료 라이브러리의 상하문 정보를 이용하여 명칭 표시를 개선하는 새로운 프레임워크를 제시했다.모든 단어에 대해 우리는 같은 문서의 다른 문장에서 문서급 상하문을 검색하고, 다른 문서의 문장에서 자료 라이브러리급 상하문을 검색한다.우리는 하나의 모델을 제시했다. 이 모델은 문서급과 자료 라이브러리급의 주의를 통해 문서급과 자료 라이브러리급의 상하문 정보를 로컬 상하문 정보와 결합시켜 각자의 상하문 정보를 동태적으로 가중시키고 선택 메커니즘을 통해 이러한 정보의 영향을 확정한다.기준 데이터 집합에서의 실험은 우리의 방법의 유효성을 나타냈고, 코넬-2002와 코넬-2003 데이터 집합에서 네덜란드, 독일, 스페인의 최신 결과를 얻었다.우리는 연구 목적으로 우리의 코드와 사전 교육을 받은 모델을 공개할 것이다.', 'fa': 'بسیاری از برچسب\u200cهای نام\u200cگذاری از اطلاعات موقعیت محلی با موفقیت زیادی استفاده می\u200cکند، اما می\u200cتواند شکست بخورد زمانی که موقعیت محلی مشکل یا محدود است. ما یک چهارچوب جدید را برای بهتر کردن نقاشی نام با استفاده از اطلاعات محلی، سطح سند و سطح شرکت را پیشنهاد می کنیم. برای هر کلمه، ما از جمله\u200cهای دیگر در یک سند و مرحله\u200cی سطح جسد از جمله\u200cهای دیگر محکوم می\u200cکنیم. ما یک مدل پیشنهاد می\u200cکنیم که یاد می\u200cگیرد که اطلاعات متوسط سطح سند و سطح شرکت را در کنار اطلاعات متوسط محلی با توجه به سطح سند و سطح شرکت، با توجه به سند و سطح شرکت، اطلاعات متوسط خود را به طور طبیعی وزن می\u200cدهد و تاثیر این اطلاعات را با طریق محموله\u200c تجربه\u200cهایی روی مجموعه\u200cهای داده\u200cهای صندوق نشان می\u200cدهند که موفقیت روش ما را نشان می\u200cدهد، که نتیجه\u200cهای صندوق هنری برای هلندی، آلمان و اسپانیایی در مجموعه\u200cهای داده\u200cهای CoNLL-2002 و CoNLL-2003 می\u200cرسد. ما کد و مدل های پیش آموزش ما را برای هدف تحقیقات به طور عمومی در دسترس خواهیم داد.', 'af': "Baie naam merking toegange gebruik plaaslike konteksual inligting met baie sukses, maar kan misluk wanneer die plaaslike konteks onbeperk of beperk is. Ons stel 'n nuwe raamwerk om naam merking te verbeter deur plaaslike, dokumentvlak en corpus-vlak konteksual inligting te gebruik. Vir elke woord, kry ons dokumentvlak konteks uit ander setings binne dieselfde dokument en corpus-vlak konteks uit setings in ander dokumente. Ons voorstel 'n model wat leer om dokumentvlak en corpus-vlak contextual inligting te inkorpreer tussen plaaslike contextual inligting deur dokumentvlak en corpus-vlak aandag, wat dinamies gewig hulle respektiewe contextual inligting en bepaal die influens van hierdie inligting deur versameling mekanisme. Eksperimente op benchmarkdatastelle vertoon die effektiviteit van ons toegang, wat die staat van die kunstens resultate vir Dutch, Duits en Spaanse bereik word op die CoNLL-2002 en CoNLL-2003 datastelle. Ons sal ons kode en vooraf-onderwerp modele openlik beskikbaar maak vir onderwerp doels.", 'tr': 'Aýry ýazmak üçin köp ad tägleri ýerleşdirilip modinde senediň maglumaty örän başarmady, ýöne ýerleşdirilip başarmady çünki ol beter möhüm/beýik harpa eser edip biler. Biz ýerli, sened derejesi we korpus derejesi näçe meseleleri ulanarak ady etitlendirmek üçin täze bir fram görkeýäris Her söz üçin, bir sened we jemgyýet derejesi başga sözleriň içinden sözleriň içinden gatnaýarys. Biz desktap derejesi we korpus derejesi duran informasiýasyny ýerleşdirip görkezmek üçin öwrenen bir nusga teklip edip görýäris. Bu şekilde dynamik görnöşikli informasiýasyny çykarýar we bu maglumatyň täsirini ýygnaýar. Benchmark veri sahypalarynda örän barlag biziň golaýymyzyň etkinlik bardygyny görkezýär. Bu Dutch, German we Spanish data sets için CoNLL-2002 we CoNLL-2003 sanat çykyşlaryna ulaşýar. Biz öz kodymyzy we öňünden öňünden öňünden gelen nusgalarymyzy araştyrma amaçlary üçin publika ulaşarys.', 'am': 'ብዙዎች የስሞች ማተሚያ ማቀናቀል በመጠቀም የአገሪው መረጃ በብዙ ስህተት ተጠቃሚ ሆኖ ይጠቅማል፤ ግን የአገሪው ግንኙነት ስህተት ውስጥነት ወይም ስህተት ቢሆን ይጎድልበታል፡፡ በአካባቢ፣ የሰነድ ደረጃ እና የኮፕስ-ደረጃ መረጃዎችን በመጠቀም የስሜን ምልክት ማድረግ አዲስ ፍሬም እናደርጋለን፡፡ ለማንኛውም ቃል፣ የሰነድ ደረጃን አስተካክል ከሌሎች አካላት ውስጥ ከsame ሰነድ እና የኮፕስ-ደረጃ context ከሌሎች ሰነዶች ከፍርድ እናስገድዳለን፡፡ ሰነድ-ደረጃ እና የኮፕስ-ደረጃ መረጃዎችን በመጠቀም የሚማር ሞዴል እና ሰነድ-ደረጃ እና የኮፕስ-ደረጃ መረጃዎችን በመጠቀም እና የግንኙነት መረጃዎችን በመጠቀም እና የሥልጣን መረጃዎችን በመጠቀም የሚችል እና የዚህን መረጃዎች በአካባቢ አካላት በመጠቀም የሚችሉትን ጥያቄ እናደርጋለን፡፡ የbenchmark ዳታተሮች ፈተናዎች የሥርዓታችንን አካባቢ ያሳያል፣ የዳርቻ፣ ጀርመን እና ስፓኒሽ አካል-2002 እና CoNLL-2003 ዳታተር ማድረጊያውን የሀብት የዓላማ ውጤት አግኝቷል፡፡ ቀድሞችንን እና የፊተኛውን ተማሪዎችን ለመፍጠር ጉዳይ እናደርጋለን፡፡', 'sq': 'Shumë qasje të etiketave të emrave përdorin informacion kontekstual lokal me shumë sukses, por mund të dështojnë kur konteksti lokal është i qartë apo i kufizuar. Ne paraqesim një kuadër të ri për të përmirësuar etiketat e emrave duke përdorur informacionin kontekstual lokal, të nivelit të dokumentit dhe të nivelit të korpusit. Për çdo fjalë, ne marrim kontekstin e nivelit të dokumentit nga fjalë të tjera brenda të njëjtit dokumenti dhe kontekstin e nivelit të korpusit nga fjalë në dokumente të tjera. Ne propozojmë një model që mëson të përfshijë informacionin kontekstual të nivelit të dokumentit dhe të nivelit të korpusit së bashku me informacionin kontekstual lokal nëpërmjet vëmendjeve të nivelit të dokumentit dhe të nivelit të korpusit, që dinamikisht peshojnë informacionin kontekstual të tyre respektiv dhe përcaktojnë ndikimin e këtij informacioni nëpërmjet mekanizmave gating. Eksperimentet në bazat e të dhënave të referuara tregojnë efektshmërinë e qasjes sonë, e cila arrin rezultate moderne për hollandezët, gjermanët dhe spanjollët në bazat e të dhënave CoNLL-2002 dhe CoNLL-2003. Ne do të bëjmë kodin tonë dhe modelet tona të paratrajnuar publikisht në dispozicion për qëllime kërkimi.', 'hy': 'Շատ անվանների նշանակման մոտեցումներ օգտագործում են տեղական կոնտեքստային տեղեկատվություն շատ հաջողությամբ, բայց կարող են ձախողվել, երբ տեղական կոնտեքստը բացահայտ է կամ սահմանափակ է: Մենք ներկայացնում ենք նոր շրջանակ, որպեսզի բարելավենք անունների նշանները՝ օգտագործելով տեղական, փաստաթղթի և կորպոս մակարդակի կոնտեքստային տեղեկատվություն: For each word, we retrieve document-level context from other sentences within the same document and corpus-level context from sentences in other documents.  Մենք առաջարկում ենք մի մոդել, որը սովորում է ներառել փաստաթղթի և կորպոս մակարդակի կոնտեքստալ ինֆորմացիա տեղական կոնտեքստալ ինֆորմացիայի հետ միասին փաստաթղթի և կորպոս մակարդակի ուշադրության միջոցով, որը դինամիկ կերպով կշռում է իրենց կոնտեք Համեմարկ տվյալների համակարգերի փորձարկումները ցույց են տալիս մեր մոտեցումների արդյունավետությունը, որը հասնում է հոլանդացի, գերմանացի և իսպաներենի ամենահետաքրքիր արդյունքներին ԿոՆԼ-2002 և ԿոՆԼ-2003 տվյալների համակարգերի վրա: Մենք մեր կոդը և նախապատրաստված մոդելները հանրային հասանելի կդարձնենք հետազոտության նպատակների համար:', 'ca': "Molts enfocaments d'etiquetar noms utilitzen informació contextual local amb molt èxit, però poden fracassar quan el context local és ambigu o limitat. Presentam un nou marc per millorar l'etiqueta de noms utilitzant informació contextual local, a nivell de documents i a nivell de corpus. Per cada paraula, obtenim el context a nivell de document d'altres frases dins el mateix document i el context a nivell de corpus d'altres frases. Proposem un model que aprenga a incorporar informació contextual a nivell documental i corpus juntament amb informació contextual local a través de atenció a nivell documental i corpus, que pesa dinàmicament la seva informació contextual respectiva i determina l'influència d'aquesta informació a través de mecanismes de gating. Els experiments en conjunts de dades de referència demostren l'eficacia del nostre enfocament, que aconsegueix resultats més avançats per als holandeses, alemans i espanyols en els conjunts de dades CoNLL-2002 i CoNLL-2003. Fem públic el nostre codi i els models pré-entrenats a fins de recerca.", 'az': 'Birçox adı etiketləmə metodları yerli müxtəlif məlumatları çox başarılı olaraq istifadə edə bilər, amma yerli məlumat səhv və ya sınırlı olduğu zaman başarısız olar. Biz yerli, belə səviyyəsi və corpus səviyyəsi müxtəlif məlumatları istifadə etmək üçün yeni bir framework ə göstəririk. Hər kəlmə üçün belə cümlələrdən digər cümlələrdən və corpus-level cümlələrdən başqa cümlələrdən alırıq. Biz belə bir modeli təklif edirik ki, belədir səviyyə və korpus səviyyəsi müxtəlif məlumatları ilə yerel müxtəlif məlumatları ilə birləşdirməki öyrənir, bu məlumatların müxtəlif məlumatlarını dinamik olaraq yükləyir və bu məlumatların müxtəlif məlumatları ilə birləşdirir. Benchmark veri qurğularının təcrübələri bizim təcrübəmizin etkinliğini göstərir. Bu, Hollandi, Almanca və İspanyolca veri qurğularının CoNLL-2002 və CoNLL-2003 veri qurğuları ilə mümkün olaraq gəlir. Biz kodumuz və əvvəlcə təhsil edilmiş modellərimizi araşdırma məqsədilə yayınlaşdıracağıq.', 'et': 'Paljud nimesildistamise lähenemisviisid kasutavad kohalikku kontekstiteavet edukalt, kuid võivad ebaõnnestuda, kui kohalik kontekst on ebaselge või piiratud. Tutvustame uut raamistikku nimede sildistamise parandamiseks, kasutades kohalikku, dokumendi- ja korpusetasandi kontekstiteavet. Iga sõna puhul toome dokumenditaseme konteksti teistest samas dokumendis olevatest lausetest ja korpustaseme konteksti teistes dokumentides olevatest lausetest. Pakume välja mudeli, mis õpib lisama dokumendi- ja korpusetasandi kontekstiteavet koos kohaliku kontekstiteabega dokumendi- ja korpusetasandi tähelepanu kaudu, mis dünaamiliselt kaalub nende vastavat kontekstiteavet ja määrab selle teabe mõju värvimismehhanismide kaudu. Võrdlusandmekogumitega tehtud katsed näitavad meie lähenemisviisi tõhusust, millega saavutatakse Hollandi, saksa ja hispaania puhul tipptasemel tulemused CoNLL-2002 ja CoNLL-2003 andmekogumite puhul. Teeme oma koodi ja eelkoolitud mudelid teadusuuringute eesmärgil avalikult kättesaadavaks.', 'bn': 'Many name tagging approaches use local contextual information with much success, but can fail when the local context is ambiguous or limited.  স্থানীয়, নথিপত্র-স্তর এবং কোর্পাস-পর্যায়ের তথ্য ব্যবহার করে নাম ট্যাগিং ব্যবহার করে আমরা একটি নতুন ফ্রেমে উপস্থাপন করি। প্রত্যেকটি শব্দের জন্য আমরা একই নথির মধ্যে থেকে অন্যান্য বাক্য থেকে নথিপত্র-স্তরের প্রতিবেদন পুনরুদ্ধার করি। আমরা একটি মডেল প্রস্তাব করি যা নথিপত্র-স্তর এবং কোর্পাস-পর্যায়ে স্থানীয় তথ্যের সাথে স্থানীয় তথ্য অন্তর্ভুক্ত করার শিক্ষা প্রদান করতে শিখতে পারে, যা ডকুমেন্ট-স্তর এবং করপাস-স্তরের বেনম্যার্ক ডাটাসেটের পরীক্ষা দেখাচ্ছে আমাদের পদক্ষেপের কার্যক্রম, যা ডাচ, জার্মান এবং স্প্যানিশের রাষ্ট্রের ফলাফল অর্জন করেছে কএনএল-২০০২ এবং কন আমরা আমাদের কোড এবং পূর্ব প্রশিক্ষিত মডেল প্রকাশ্যে গবেষণার উদ্দেশ্যে পাওয়া যাব।', 'bs': 'Mnogi pristupi označavanja imena koriste lokalne kontekstske informacije sa puno uspjeha, ali mogu propasti kada je lokalni kontekst ambigujan ili ograničen. Predstavljamo novi okvir za poboljšanje oznake imena korištenjem lokalnih, nivoa dokumenta i kontekstnih informacija na nivou korpusa. Za svaku riječ dobijamo kontekst na nivou dokumenta iz drugih rečenica u istom dokumentu i kontekstu na nivou korpusa iz rečenica u drugim dokumentima. Predlažemo model koji nauči da uključuje kontekstne informacije na nivou dokumenta i razini korpusa zajedno s lokalnim kontekstualnim informacijama putem pažnje na nivou dokumenta i razini korpusa, koji dinamički teži njihove odgovarajuće kontekstne informacije i određuje utjecaj te informacije putem prikupljanja mehanizama. Eksperimenti o standardnim podacima pokazuju učinkovitost našeg pristupa, koji postiže rezultate države umjetnosti nizozemskih, nemačkih i španjolskih podataka na CoNLL-2002 i CoNLL-2003. Učinit ćemo naš kod i predobučeni modeli javno dostupnim za istraživačke svrhe.', 'cs': 'Mnoho přístupů k označování jmen používá lokální kontextové informace s velkým úspěchem, ale může selhat, pokud je místní kontext nejednoznačný nebo omezený. Představujeme nový rámec pro zlepšení tagování jmen pomocí kontextových informací na úrovni místních dokumentů a korpusů. Pro každé slovo načítáme kontext na úrovni dokumentu z jiných vět ve stejném dokumentu a kontext na úrovni korpusu z vět v jiných dokumentech. Navrhujeme model, který se naučí začlenit kontextové informace na úrovni dokumentu a korpusu vedle lokálních kontextových informací prostřednictvím pozornosti na úrovni dokumentu a korpusu, které dynamicky váží jejich příslušné kontextové informace a určují vliv těchto informací pomocí gatingových mechanismů. Experimenty na referenčních datových sadách ukazují efektivitu našeho přístupu, který dosahuje nejmodernějších výsledků pro nizozemské, německé a španělské datové sady CoNLL-2002 a CoNLL-2003. Náš kód a předškolené modely zpřístupníme veřejně pro výzkumné účely.', 'fi': 'Monet nimimerkintämenetelmät käyttävät paikallista kontekstitietoa menestyksekkäästi, mutta voivat epäonnistua, kun paikallinen konteksti on epäselvä tai rajallinen. Esittelemme uuden kehyksen, jolla parannetaan nimikoodausta hyödyntämällä paikallista, dokumenttitasoa ja korpustason kontekstitietoa. Jokaiselle sanalle haemme dokumenttitason kontekstin muista saman asiakirjan lauseista ja korpustason kontekstin muiden asiakirjojen lauseista. Ehdotamme mallia, joka oppii sisällyttämään dokumenttitason ja korpustason kontekstitietoa paikallisen kontekstitieton rinnalle dokumenttitason ja korpustason huomion avulla, jotka dynaamisesti punnitsevat kontekstitietojaan ja määrittävät tämän tiedon vaikutuksen porttimekanismien avulla. Vertailutietoaineistojen kokeilut osoittavat toimintamme tehokkuuden, sillä se tuottaa alankomaalaisille, saksalaisille ja espanjalaisille huipputason tuloksia CoNLL-2002- ja CoNLL-2003-aineistoista. Julkaisemme koodimme ja esikoulutetut mallit julkisesti saataville tutkimustarkoituksiin.', 'jv': 'text-tool-action @title:window Sampeyan awak, awak dhéwé nglanggar-sampeyan dokumen-sampeyan kanggo kelas barang kotak nang dokumen sampeyan karo perangkat oleh dumadhi kanggo Ketokumen sing berarti Awak dhéwé ngerasai model sing lemuran kanggo nggawe informasi contextual -evel karo pakek bodoh, lan basa gambar informasi contextual (contextual) nganggep kuwi nggawe dokumen-evel lan langgar -evel karo cara-evel sing dirakno, sing berarti Dinamno langgar informasi contextual karo iso nggawe informasi iki dadi nggawe informasi iki ngono nggawe mekanisati iki. Isoporsya karo dataset bench menyang paling nggambar obahan kanggo ndelok dhéwé, sing wis ngerasai perusahaan status-of-the-arts kanggo didasakno alaman, aleman karo Spanyola sak dataset CoNLL-2002lan CoNLL-2003. Awak dhéwé bakal ngejaraké kode lan model sing wis mulasar ampungan kanggo ngilanggar nggawe', 'he': 'הגישויים רבים של תגים בשמות משתמשים במידע קונטוקטואלי מקומי עם הצלחה רבה, אך יכולים להיכשל כאשר הקשר מקומי הוא סביר או מוגבל. אנחנו מציגים מסגרת חדשה לשפר את התג השם על ידי השימוש במידע מקומי, רמת מסמכים, וקורפוס רמת מידע קונטקסטי. For each word, we retrieve document-level context from other sentences within the same document and corpus-level context from sentences in other documents.  אנו מציעים מודל שלמד להכיל מידע קונטוקטואלי רמה מסמכים ורמה קופוס לצד מידע קונטוקטואלי מקומי דרך תשומת לב רמה מסמכים ורמה קופוס, אשר דינמית משקלת את מידע הקונקטואלי שלהם ולקבע את השפעה של המידע הזה דרך מכונות גייט. ניסויים על קבוצות נתונים רמזים מראים את היעילות של הגישה שלנו, אשר משיג תוצאות חדשות למידע ההולנדי, הגרמני והספרדי על קבוצות נתונים CoNLL-2002 ו CoNLL-2003. We will make our code and pre-trained models publicly available for research purposes.', 'ha': "@ info Tuna gabatar da wani firam mai kyau ga sunan tagogi da za'a yi amfani da lokal, takardar-daraja da maɓallin littafin-daraja. For each word, we retrieve document-level context from other sentences within the same document and corpus-level context from sentences in other documents.  Tuna goyyar da wani motsi wanda yake iya amfani da in shigar da takardar-daraja da nau'in-nau'in-rubutu da zane-zane-zane-zane-zane-zane-zane-zane da zane-zane-zane-zane-zane-zane da zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane, kuma yana ƙayyade muhimmin maɓallin wannan maɓalli a Fijaroyi na danne-bangon ayuka na nuna mafiya amfani da hanyarmu, wanda ke sãmun state-of-the-art matsalar wa Duch, Jarman, kuma Isbanish on the CoNLL-2002 and CoNLL-2003 data set. Za sami kodinmu da misãlai waɗanda aka yi wa zaman shirin da ake samu zuwa ga tafarki.", 'sk': 'Številni pristopi označevanja imen z veliko uspešnostjo uporabljajo lokalne kontekstne informacije, vendar lahko neuspešno, če je lokalni kontekst dvoumen ali omejen. Predstavljamo nov okvir za izboljšanje označevanja imen z uporabo lokalnih kontekstnih informacij na ravni dokumenta in korpusa. Za vsako besedo pridobimo kontekst na ravni dokumenta iz drugih stavkov znotraj istega dokumenta in kontekst na ravni korpusa iz stavkov v drugih dokumentih. Predlagamo model, ki se uči vključevati kontekstualne informacije na ravni dokumenta in korpusa skupaj z lokalnimi kontekstualnimi informacijami prek pozornosti na ravni dokumenta in korpusa, ki dinamično težijo njihove kontekstualne informacije in določajo vpliv teh informacij prek mehanizmov za povezovanje. Eksperimenti na referenčnih naborih podatkov kažejo učinkovitost našega pristopa, ki dosega najsodobnejše rezultate za nizozemsko, nemško in špansko v zbirkah podatkov CoNLL-2002 in CoNLL-2003. Našo kodo in vnaprej usposobljeni modeli bomo javno dostopni za raziskovalne namene.', 'bo': 'Many name tagging approaches use local contextual information with much success, but can fail when the local context is ambiguous or limited. ང་ཚོས་རང་ཁུལ་གྱི་གནས་ཡུལ་དང་ཐོག་མའི་རིམ་པ་ཞིག་གིས་སྤྱོད་པ་ལས་མིང་ཤོག་བྱང་གསར་པ་ཞིག་འཆར་ཡོད། ཐ་སྙད་རེ་རེར་ང་ཚོས་ཡིག་ཆ་གཅིག་གི་ནང་དུ་ཡིག་གེའི་ཁུངས་ལ་ཡིག་ཆ་གཞན་ཞིག་ནས་ཡིག We propose a model that learns to incorporate document-level and corpus-level contextual information alongside local contextual information via document-level and corpus-level attentions, which dynamically weight their respective contextual information and determines the influence of this information through gating mechanisms. ངལ་རྟགས་བཀོད་པའི་ཐབས་ལམ་ལ་བརྟག་སྤྱོད་བྱས་ན་ང་ཚོའི་གཟུགས་སྐོར་གྱི་ནུས་ཡོད་ཚད་མངོན་འཆར་བྱེད་ཀྱི་ཡོད། ང་ཚོས་མིའི་རྩིས་འཁོར་དང་སྔོན་གྲངས་བསྒྲིག་པའི་དཔེ་གཞི་རྣམས་ཡོད་ཚད་ལྟ་རྟོག་བྱེད་དགོས།'}
{'en': 'Uncovering Code-Mixed Challenges : A Framework for Linguistically Driven Question Generation and Neural Based Question Answering', 'ar': 'الكشف عن تحديات الشفرات المختلطة: إطار عمل لتوليد الأسئلة بدافع لغوي والإجابة العصبية للأسئلة', 'fr': 'Découvrir les défis mixtes de code\xa0: un cadre pour la génération de questions axées sur la linguistique et la réponse aux questions basée sur les neurones', 'pt': 'Descobrindo desafios mistos de código: uma estrutura para geração de perguntas orientadas linguísticamente e respostas a perguntas com base neural', 'es': 'Descubriendo desafíos de código mixto: un marco para la generación de preguntas impulsada por el lenguaje y la respuesta a preguntas basada en neuronas', 'ja': 'コードミックスチャレンジの発見：言語主導型の質問生成と神経ベースの質問回答のためのフレームワーク', 'hi': 'कोड-मिश्रित चुनौतियों को उजागर करना: भाषाई रूप से संचालित प्रश्न पीढ़ी और तंत्रिका आधारित प्रश्न उत्तर के लिए एक फ्रेमवर्क', 'zh': '揭代码混以挑战,言动而神经对之框架', 'ru': 'Открытие кодосмешанных вызовов: рамки для генерации лингвистически управляемых вопросов и ответов на вопросы на основе нейронов', 'ga': 'Dúshláin Chódmheasctha a Nochtadh: Creat le haghaidh Giniúint Ceisteanna Teangeolaíoch agus Freagairt Cheisteanna Néarbhunaithe', 'el': 'Αποκάλυψη Μεικτών Προκλήσεων Κώδικα: Ένα Πλαίσιο για Γλωσσολογικά Οδηγημένη Δημιουργία Ερωτήσεων και Απαντήσεις Νευρικών Ερωτήσεων', 'hu': 'Kódkevert kihívások felfedése: a nyelvtudományosan vezérelt kérdések generálásának és a neurális kérdések megválaszolásának keretrendszere', 'ka': 'კოდის შემთხვევაში გარეშე: Linguistically Drived Question Generation and Neural Based Question Answering', 'it': 'Scoprire le sfide miste di codice: un quadro per la generazione linguistica delle domande e la risposta neurale alle domande', 'lt': 'Iššūkių, susijusių su derintais kodais, atskleidimas: lingvistiškai pagrįstų klausimų generavimo ir atsakymo į nervinius klausimus sistema', 'kk': 'Код араластырылмаған шақырулар: Лингистикалық драйвер сұрақтарын жасау және нейралық негіздеген сұрақтар жауап беру', 'mk': 'Откривање на измешани предизвици со код: Рамка за генерација на јазички водени прашања и одговори на неврални прашања', 'ms': 'Menyambungkan cabaran-campuran Kod: Sebuah kerangka untuk Jenerasi soalan Digerak secara Bahasa dan Jawapan soalan Berasas Neural', 'ml': 'കോഡ്- മിക്സഡ് ചെല്ലുകള്\u200d അടയാളപ്പെടുത്തുന്നില്ല: ലിങ്ഗിസ്റ്റിക്കല്\u200d ഡ്രൈവ് ചോദ്യത്തിനുള്ള ഫ്രെമ്മെയിക്ക് പ്', 'mn': 'Код-холбоотой сорилтууд: Linguistically Driven Question Generation and Neural Based Question Response Framework for a Linguistically Driven Question Generation and a Neural Based Question Response', 'pl': 'Odkrywanie wyzwań mieszanych kodem: ramy dla językowo kierowanego generowania pytań i odpowiadania na pytania oparte na nerwach', 'no': 'Utdekkende kodefølgjande utfordringar: Eit rammeverk for oppretting av spørsmål og nøyralbasert spørsmål', 'mt': 'L-iskoperta ta’ Sfidi Mħallta mal-Kodiċi: Qafas għall-Ġenerazzjoni ta’ Mistoqsijiet Imħaddma Lingwistikament u Tweġiba għal Mistoqsijiet Ibbażati fuq in-Newrali', 'ro': 'Descoperirea provocărilor combinate de coduri: un cadru pentru generarea de întrebări bazate pe limbaj lingvistic și răspunsul la întrebări bazate pe neuri', 'si': 'කෝඩ් මික්ස් වෙනුවෙන් ප්\u200dරශ්නයක් නොකවරන්න: ලින්ග්විස්ටිකියෙන් ඩ්\u200dරායිවින් ප්\u200dරශ්නයක් නිර්මාණය සහ න්\u200d', 'sr': 'Непокривајући прозорци смесени код: Рамок за генерацију лингвистично водене питања и одговор на невралном проблеме', 'sv': 'Att upptäcka kodblandade utmaningar: ett ramverk för språkligt driven frågegenerering och neuralt besvarande av frågor', 'so': 'Uncovering Code-Mixed Challenges: A Framework for Linguistically Drived Question Generation and Neural Based Question answers', 'ur': 'Uncovering Code-Mixed Challenges: A Framework for Linguistically Driven Question Generation and Neural Based Question Answering', 'ta': 'குறியீடு- கலக்கப்பட்ட சவால்கள்: Linguistically Drived Query Generation and Neural Based Query answers', 'uz': 'Name', 'vi': 'Việc vạch ra các thử thách giữa mã tổng hợp: Một bộ khung cho các câu hỏi được trục trặc ngôn ngữ và trả lời câu hỏi thần kinh', 'bg': 'Разкриване на смесени с кодове предизвикателства: рамка за лингвистично насочено генериране на въпроси и невронно базирано отговор на въпроси', 'hr': 'Neobuhvaćeni izazovi između kodeksa: okvir za generaciju Lingistički vožnje pitanja i odgovor na neurološka temelja pitanja', 'nl': 'Codegemengde uitdagingen ontdekken: een kader voor taalkundig gedreven vragengeneratie en neurale vragenantwoorden', 'da': 'Afdækning af kodeblandede udfordringer: En ramme for sprogligt drevet spørgsmålsgenerering og neural baseret spørgsmålsbesvarelse', 'id': 'Menemukan tantangan campuran Kode: Sebuah Framework untuk Generasi Pertanyaan Bergerak Linguistik dan Jawaban Pertanyaan Berdasarkan Neural', 'fa': 'چالش\u200cهای مختلف قانونی: یک چشمه\u200cسازی برای تولید سوال\u200cهای رانندگی به زبان و پاسخ\u200cدادن سوال\u200cهای عصبی', 'de': 'Code-Mixed Challenges aufdecken: Ein Framework für sprachlich gesteuerte Fragegenerierung und neuronale Fragebeantwortung', 'ko': '코드 혼합 도전 제시: 언어 구동 문제 생성과 신경 기반 문제 응답 프레임워크', 'af': "Ondekkende Kode-gemengde Opdragte: ' n Raamwerk vir Linguistically Driiwer Vrag Genereer en Neurale Baseerde Vrag Antwoord", 'sq': 'Zbulimi i sfidave të përziera me kod: Një kuadër për gjenerimin e pyetjeve të drejtuara gjuhësisht dhe përgjigjen e pyetjeve të bazuara në nerva', 'sw': 'Vita vinavyotokana na sheria: Miundombi kwa ajili ya Uzalishaji wa swali linaloendeshwa kwa lugha na swali la msingi', 'tr': 'Taýşartmaksyz Kod Karışmış Çözümler: Linguistically Driven Sorag Generasy we Nöral tabanly Sorag Cevap', 'am': 'የጽሑፉ ቀለም', 'hy': 'Բացահայտել կոդի խառնված մարտահրավերները. լեզվաբանորեն առաջացված հարցերի ստեղծման և նյարդային հիմնված հարցերի պատասխանների մի շրջանակ', 'az': 'Còd karışıqlı çətinlər: Linguistically Driven Question Generation və Neural Based Question Cevap', 'bn': 'কোড- মিক্সেড চ্যালেঞ্জ: লিঙ্গিস্টিক্যাল ড্রাইভেন প্রশ্ন জেনারেশন এবং নিউরেল ভিত্তিক প্রশ্নের উত্তর', 'bs': 'Neobuhvaćeni izazovi između kodeksa: okvir za generaciju Lingistički vožnje pitanja i odgovor na neurološka temelja pitanja', 'cs': 'Odhalení kódově smíšených výzev: Rámec pro jazykově řízené generování otázek a nervově založené odpovědi na otázky', 'et': 'Koodidega segatud väljakutsete avastamine: raamistik keeleliselt juhitud küsimuste loomiseks ja neuroalsetele küsimustele vastamiseks', 'fi': 'Koodien sekoitettujen haasteiden selvittäminen: Kehys kielellisesti ohjatulle kysymysteknologialle ja hermopohjaiselle kysymysteknologialle', 'ca': 'Descobrir els reptes combinats amb codis: Un marc per a generar preguntes dirigides lingüísticament i respondre a preguntes basades en neurones', 'jv': 'ProgressBarUpdates', 'sk': 'Odkrivanje izzivov mešanih kod: okvir za jezikovno usmerjeno ustvarjanje vprašanj in odgovarjanje na živčna vprašanja', 'ha': 'KCharselect unicode block name', 'he': 'גילוי אתגרים מעורבים בקוד: מסגר ליצירת שאלות מונעות בשפתיים', 'bo': 'Uncovering Code-Mixed Challenges: A Framework for Linguistically Driven Question Generation and Neural Based Question Answering'}
{'en': 'Existing research on question answering (QA) and comprehension reading (RC) are mainly focused on the resource-rich language like ', 'ar': 'تركز الأبحاث الحالية حول الإجابة على الأسئلة (QA) وقراءة الفهم (RC) بشكل أساسي على اللغة الغنية بالموارد مثل اللغة الإنجليزية. في الآونة الأخيرة ، طرح النمو السريع لمحتوى الويب متعدد اللغات العديد من التحديات لأنظمة ضمان الجودة الحالية. يعد خلط الشفرات أحد التحديات التي تجعل المهمة أكثر تعقيدًا. في هذا البحث ، نقترح تقنية ذات دوافع لغوية لتوليد الأسئلة المختلطة بالشفرات (CMQG) وبنية قائمة على الشبكة العصبية للإجابة على الأسئلة المختلطة بالشفرات (CMQA). للتقييم ، نقوم يدويًا بإنشاء الأسئلة ذات الأكواد المختلطة لزوج اللغتين الهندية والإنجليزية. من أجل إظهار فعالية تقنية CMQA القائمة على الشبكة العصبية ، فإننا نستخدم مجموعتي بيانات معياريتين ، SQuAD و MMQA. تظهر التجارب أن نموذجنا المقترح يحقق أداءً مشجعًا على CMQG و CMQA.', 'fr': "Les recherches existantes sur la réponse aux questions (AQ) et la compréhension de la lecture (RC) sont principalement axées sur la langue riche en ressources comme l'anglais. Ces derniers temps, la croissance rapide du contenu Web multilingue a posé plusieurs défis aux systèmes d'assurance qualité existants. Le mélange de codes est l'un de ces défis qui rend la tâche plus complexe. Dans cet article, nous proposons une technique motivée par la langue pour la génération de questions mixtes de code (CMQG) et une architecture basée sur un réseau de neurones pour la réponse aux questions mixtes de code (CMQA). Pour l'évaluation, nous créons manuellement les questions mixtes de code pour la paire de langues Hindi-Anglais. Afin de démontrer l'efficacité de notre technique CMQA basée sur un réseau de neurones, nous utilisons deux ensembles de données de référence, SQuad et MMQA. Les expériences montrent que notre modèle proposé atteint des performances encourageantes sur CMQG et CMQA.", 'pt': 'As pesquisas existentes sobre resposta a perguntas (QA) e leitura de compreensão (RC) estão focadas principalmente na linguagem rica em recursos, como o inglês. Nos últimos tempos, o rápido crescimento do conteúdo da web multilíngue colocou vários desafios aos sistemas de controle de qualidade existentes. A mistura de códigos é um desses desafios que torna a tarefa mais complexa. Neste artigo, propomos uma técnica de motivação linguística para geração de perguntas mistas de código (CMQG) e uma arquitetura baseada em rede neural para resposta a perguntas mistas de código (CMQA). Para avaliação, criamos manualmente as perguntas de código misto para o par de idiomas hindi-inglês. Para mostrar a eficácia de nossa técnica CMQA baseada em rede neural, utilizamos dois conjuntos de dados de referência, SQuAD e MMQA. Experimentos mostram que nosso modelo proposto alcança desempenho encorajador em CMQG e CMQA.', 'es': 'Las investigaciones existentes sobre respuestas a preguntas (QA) y lectura de comprensión (RC) se centran principalmente en el idioma rico en recursos como el inglés. En los últimos tiempos, el rápido crecimiento del contenido web multilingüe ha planteado varios desafíos a los sistemas de control de calidad existentes. La mezcla de códigos es uno de esos desafíos que hace que la tarea sea más compleja. En este artículo, proponemos una técnica de motivación lingüística para la generación de preguntas de código mixto (CMQG) y una arquitectura basada en redes neuronales para la respuesta a preguntas de código mixto (CMQA). Para la evaluación, creamos manualmente las preguntas con código mixto para la combinación de idiomas hindi-inglés. Para demostrar la eficacia de nuestra técnica de CMQA basada en redes neuronales, utilizamos dos conjuntos de datos de referencia, sQuad y MMQA. Los experimentos muestran que nuestro modelo propuesto logra un rendimiento alentador en CMQG y CMQA.', 'ja': '質問回答（ QA ）と理解読解（ RC ）に関する既存の研究は、主に英語のようなリソースの豊富な言語に焦点を当てています。近年、多言語ウェブコンテンツの急速な成長は、既存のQAシステムにいくつかの課題をもたらしている。コードミキシングは、タスクをより複雑にするこのような課題の1つです。本稿では，コードミックスクエスチョン生成（ CMQG ）のための言語的動機づけの手法と，コードミックスクエスチョンアンサー（ CMQA ）のためのニューラルネットワークベースのアーキテクチャを提案する．評価のために、ヒンディー語と英語のペアのコードミックスされた質問を手動で作成します。当社のニューラルネットワークベースのCMQA技術の有効性を示すために、SQuADとMMQAの2つのベンチマークデータセットを利用しています。実験によると、提案されたモデルはCMQGとCMQAで優れたパフォーマンスを達成しています。', 'hi': 'प्रश्न उत्तर (क्यूए) और समझ पढ़ने (आरसी) पर मौजूदा शोध मुख्य रूप से अंग्रेजी जैसी संसाधन-समृद्ध भाषा पर केंद्रित हैं। हाल के दिनों में, बहुभाषी वेब सामग्री की तेजी से वृद्धि ने मौजूदा क्यूए प्रणालियों के लिए कई चुनौतियां पैदा की हैं। कोड-मिक्सिंग एक ऐसी चुनौती है जो कार्य को अधिक जटिल बनाती है। इस पेपर में, हम कोड-मिश्रित प्रश्न पीढ़ी (सीएमक्यूजी) के लिए एक भाषाई रूप से प्रेरित तकनीक और कोड-मिश्रित प्रश्न उत्तर (सीएमक्यूए) के लिए एक तंत्रिका नेटवर्क आधारित वास्तुकला का प्रस्ताव करते हैं। मूल्यांकन के लिए, हम मैन्युअल रूप से हिंदी-अंग्रेजी भाषा जोड़ी के लिए कोड-मिश्रित प्रश्न बनाते हैं। हमारे तंत्रिका नेटवर्क आधारित सीएमक्यूए तकनीक की प्रभावशीलता दिखाने के लिए, हम दो बेंचमार्क डेटासेट, SQuAD और MMQA का उपयोग करते हैं। प्रयोगों से पता चलता है कि हमारा प्रस्तावित मॉडल CMQG और CMQA पर उत्साहजनक प्रदर्शन प्राप्त करता है।', 'ru': 'Существующие исследования по ответам на вопросы (QA) и чтению понимания (RC) в основном сосредоточены на богатом ресурсами языке, таком как английский. В последнее время быстрый рост многоязычного веб-контента поставил ряд задач перед существующими системами обеспечения качества. Смешивание кода является одной из таких проблем, которая делает задачу более сложной. В этой статье мы предлагаем лингвистически мотивированную методику генерации кодовых вопросов (CMQG) и архитектуру на основе нейронной сети для ответов на кодовые вопросы (CMQA). Для оценки мы вручную создаем вопросы со смешанным кодом для языковой пары хинди и английского языка. Чтобы показать эффективность нашего метода CMQA на основе нейронной сети, мы используем два эталонных набора данных, SQuAD и MMQA. Эксперименты показывают, что наша предлагаемая модель обеспечивает обнадеживающую производительность на CMQG и CMQA.', 'zh': '今问答(QA)解读(RC)要在英语等语言。 近者,多言 Web 者快速增长以挑战于今 QA 。 代码混合如此,其任转杂。 本文以代码合问生(CMQG)语动机术,及一以代码混问答(CMQA)基于神经网络架构。 为评估,手动为印地语-英语言代码混。 为证吾神经网络CMQA术之有效性,吾用二准数集,SQuADMMQA。 实验者,取令人鼓舞于CMQG、CMQA也。', 'ga': 'Tá taighde reatha ar fhreagairt ceisteanna (QA) agus léamhthuiscint (RC) dírithe go príomha ar an teanga shaibhir acmhainní ar nós an Bhéarla. Le blianta beaga anuas, tá roinnt dúshlán ag baint leis na córais QA atá ann faoi láthair mar gheall ar fhás tapa an ábhair ghréasáin ilteangach. Dúshlán amháin dá leithéid is ea códmheascadh a dhéanann an tasc níos casta. Sa pháipéar seo, molaimid teicníocht spreagtha teanga chun ceisteanna cód-mheasctha a ghiniúint (CMQG) agus ailtireacht néarghréasán-bhunaithe le haghaidh freagra ceisteanna cód-mheasctha (CMQA). Le haghaidh meastóireachta, cruthaímid de láimh na ceisteanna cód-mheasctha don phéire Hiondúis-Bhéarla. Chun éifeachtacht ár dteicníc CMQA líonra néarbhunaithe a thaispeáint, úsáidimid dhá thacar sonraí tagarmharcála, SQuAD agus MMQA. Léiríonn turgnaimh go mbaineann ár múnla molta feidhmíocht spreagúil amach ar CMQG agus CMQA.', 'el': 'Η υπάρχουσα έρευνα για την απάντηση σε ερωτήσεις (QA) και την ανάγνωση κατανόησης (RC) επικεντρώνεται κυρίως στην πλούσια σε πόρους γλώσσα όπως τα αγγλικά. Τον τελευταίο καιρό, η ταχεία ανάπτυξη του πολυγλωσσικού διαδικτυακού περιεχομένου έχει θέσει αρκετές προκλήσεις στα υπάρχοντα συστήματα QS. Η ανάμειξη κώδικα είναι μια τέτοια πρόκληση που καθιστά την εργασία πιο περίπλοκη. Στην παρούσα εργασία, προτείνουμε μια γλωσσικά υποκινούμενη τεχνική για τη δημιουργία μεικτής ερώτησης κώδικα (και μια αρχιτεκτονική βασισμένη σε νευρωνικό δίκτυο για την απάντηση μεικτής ερώτησης κώδικα (CMQA). Για αξιολόγηση, δημιουργούμε χειροκίνητα τις ερωτήσεις μικτού κώδικα για το ζεύγος γλωσσών Χίντι-Αγγλικών. Για να δείξουμε την αποτελεσματικότητα της τεχνικής που βασίζεται στο νευρωνικό δίκτυο, χρησιμοποιούμε δύο σύνολα δεδομένων αναφοράς, SQuAD και MMQA. Τα πειράματα δείχνουν ότι το προτεινόμενο μοντέλο επιτυγχάνει ενθαρρυντικές επιδόσεις σε CMQG και CMQA.', 'hu': 'A meglévő kutatások a kérdésválaszolással (QA) és a megértési olvasással (RC) kapcsolatban elsősorban az erőforrásokban gazdag nyelvre összpontosítanak, mint például az angol. Az utóbbi időkben a többnyelvű webes tartalom gyors növekedése számos kihívást jelentett a meglévő minőségi felügyeleti rendszerek számára. A kódkeverés egyik olyan kihívás, amely bonyolultabbá teszi a feladatot. Jelen tanulmányban egy nyelvi motivációs technikát javasolunk a kódkevert kérdések generálására (CMQG) és egy neurális hálózat alapú architektúrát a kódkevert kérdések megválaszolására (CMQA). Az értékelés céljából manuálisan készítjük el a hindi-angol nyelvpár kódkeverékes kérdéseit. Neurális hálózat alapú CMQA technikánk hatékonyságának bemutatása érdekében két benchmark adatkészletet használunk, az SQAD és az MMQA. A kísérletek azt mutatják, hogy javasolt modellünk ösztönző teljesítményt ér el CMQG és CMQA esetén.', 'it': "Le ricerche esistenti sulla risposta alle domande (QA) e sulla lettura della comprensione (RC) sono focalizzate principalmente sulla lingua ricca di risorse come l'inglese. Negli ultimi tempi, la rapida crescita dei contenuti web multilingue ha posto diverse sfide ai sistemi di QA esistenti. La miscelazione del codice è una di queste sfide che rende il compito più complesso. In questo articolo proponiamo una tecnica motivata dal punto di vista linguistico per la generazione di domande miste (CMQG) e un'architettura basata su reti neurali per la risposta alle domande miste (CMQA). Per la valutazione, creiamo manualmente le domande miste di codice per la coppia di lingue hindi-inglese. Per dimostrare l'efficacia della nostra tecnica CMQA basata sulla rete neurale, utilizziamo due set di dati di riferimento, SQUAD e MMQA. Gli esperimenti dimostrano che il nostro modello proposto raggiunge prestazioni incoraggianti su CMQG e CMQA.", 'kk': 'Сұрақтар жауап беру (QA) және оқу (RC) түсініктері туралы зерттеу негізінде ағылшын тілінің ресурстар баяны тіліне назар аударылады. Соңғы уақытта, көптеген тілді интернет мазмұның тез өсімі бар QA жүйелеріне бірнеше өзгерістер болды. Код араластыру - тапсырманы көптеген жағдайды. Бұл қағазда, код араластырылған сұрақтарды құру (CMQG) және код араластырылған сұрақтарды (CMQA) жауап беру үшін невралдық желінің архитектурасын қолданамыз. Бағалау үшін, біз хинди-ағылшын тілінің қолмен айналысқан сұрақтарды құрамыз. Невралдық желіміздің CMQA техникалығын көрсету үшін, екі бақылау деректер қорларын, SQuAD және MMQA қолдану үшін қолданамыз. Тәжірибелер CMQG және CMQA үлгісінің көмектесу үлгісін көрсетеді.', 'ka': 'მხოლოდ კითხვების გასაგების (QA) და კითხვების შესახებ (RC) კითხვების შესახებ უფრო მნიშვნელოვანია, როგორც ინგლისური მხარდაჭირებული ენაზე. მიმდინარე დროში, მრავალენგური საბოლოო ინტერნეტის წარმოდგენის ბრძნელი წარმოდგენა რამდენიმე წარმოდგენების QA სისტემაში. კოდის შემთხვევა არის ერთი რაც უფრო კომპლექსია. ჩვენ ამ წიგნაში ინგულისტიკურად მოტივირებული ტექნოგია კითხვების შესახებ (CMQG) და ნეიროლური ქსელის დაბათი არქტიქტურა კითხვების შესახებ (CMQA). გავამუშაოთ, ჩვენ ხელსახურად შევქმნით კოდის შემთხვევითი კითხვები ჰინდი-ინგლისური ენის ზოგებისთვის. ჩვენი ნეიროლური ქსელის გამოსახულებული CMQA ტექნექტიკის ეფექტიურობას ჩვენ გამოყენებთ ორი ბენქმარკის მონაცემები, SQuAD და MMQA. ექსპერიმენტები გამოჩვენება, რომ ჩვენი მოდელის მონაცემები მიიღება CMQG და CMQA-ზე მუშაობას.', 'mk': 'Постојаните истражувања за одговори на прашања (QA) и читање на разбирање (RC) се фокусирани главно на јазикот богат со ресурси, како што е англискиот. In recent times, the rapid growth of multi-lingual web content has posed several challenges to the existing QA systems.  Мешањето на кодовите е еден предизвик кој ја прави задачата покомплексна. In this paper, we propose a linguistically motivated technique for code-mixed question generation (CMQG) and a neural network based architecture for code-mixed question answering (CMQA).  За проценка, рачно ги создаваме прашањата за кодови за пар хинди-англиски јазик. За да ја покажеме ефективноста на техниката на нашата нервна мрежа на CMQA, користиме два бази на податоци, SQuAD и MMQA. Експериментите покажуваат дека нашиот предложен модел постигнува охрабрувачки резултати на CMQG и CMQA.', 'ms': 'Penelitian yang wujud mengenai jawapan soalan (QA) dan pembacaan pemahaman (RC) terutama fokus pada bahasa kaya sumber seperti bahasa Inggeris. In recent times, the rapid growth of multi-lingual web content has posed several challenges to the existing QA systems.  Pengcampuran kod adalah satu cabaran yang membuat tugas lebih kompleks. Dalam kertas ini, kami cadangkan teknik motivasi secara bahasa untuk generasi soalan-campuran kod (CMQG) dan arkitektur berasaskan rangkaian saraf untuk menjawab soalan-campuran kod (CMQA). Untuk penilaian, kita cipta secara manual soalan-kod bercampur untuk pasangan bahasa Hindi-Inggeris. Untuk menunjukkan kegunaan teknik CMQA berasaskan rangkaian saraf kami, kami menggunakan dua set data benchmark, SQuAD dan MMQA. Eksperimen menunjukkan bahawa model kami diusulkan mencapai prestasi yang menguatkan pada CMQG dan CMQA.', 'ml': 'ചോദ്യത്തിന്റെ ഉത്തരം നല്\u200dകുന്നതിനെപ്പറ്റിയും പരിശോധന വായിക്കുന്നതിനെപ്പറ്റിയും നിലവിലുള്ള പരിശോധനം ഇംഗ്ലീഷിലെ വി In recent times, the rapid growth of multi-lingual web content has posed several challenges to the existing QA systems.  കോഡ് മിഷിങ്ങ് ചെയ്യുന്നത് ഒരു വ്യാല്\u200dക്കെല്ലാം കൂടുതല്\u200d സങ്കല്\u200dപ്പിക്കുന്നു. ഈ പത്രത്തില്\u200d, നമ്മള്\u200d കോഡ്-mixed ചോദ്യ തലമുറയ്ക്കുവേണ്ടി ഭാഷകങ്ങളില്\u200d നിര്\u200dദ്ദേശിക്കുന്ന സാങ്കേതികവിദ്യയുടെ പ്രാദേശിക്കുന്നു. സിഎം വിലയ്ക്കുവേണ്ടി, നമ്മള്\u200d കൈയ്യില്\u200d ഹിന്ദി-ഇംഗ്ലീഷ് ഭാഷ ജോടിയുടെ കോഡ് മിഷ്ടപ്പെട്ട ചോദ്യങ്ങള്\u200d ഉണ നമ്മുടെ ന്യൂറല്\u200d വര്\u200dക്കെറ്റിന്റെ പ്രകൃതിയെ കാണിക്കാന്\u200d വേണ്ടി സിഎം ക്യൂഎ സ് ടെക്നിക്ക് ബെന്\u200dമാര്\u200dക്ക് ഡാറ്റാസറ്റ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ പ്രൊദ്ദേശിച്ച മോഡല്\u200d സിഎംക്യൂജിയിലും സിഎംക്യ', 'lt': 'Dabartiniai moksliniai tyrimai, susiję su klausimų atsakymu ir supratimo skaitymu, daugiausia susiję su išteklius turinčia kalba, pavyzdžiui, anglų kalba. Pastaruoju metu spartus daugiakalbio interneto turinio augimas sukėlkeletą iššūkių esamoms QA sistemoms. Code-mixing is one such challenge that makes the task more complex.  Šiame dokumente siūlome kalbiniu būdu pagrįstą mišrių klausimų generavimo metodą (CMQG) ir neurologinio tinklo architektūrą, skirtą mišrių klausimų atsakymui (CMQA). Vertinimui mes rankiniu būdu sukuriame kodų mišrius klausimus Hindi ir anglų kalbų porai. Siekiant parodyti mūsų nervų tinklu pagrįsto CMQA metodo veiksmingumą, naudojame du lyginamuosius duomenų rinkinius, SQuAD ir MMQA. Eksperimentai rodo, kad mūsų siūlomas modelis pasiekia skatinančių rezultatų CMQG ir CMQA srityje.', 'mt': 'Ir-riċerka eżistenti dwar it-tweġiba għall-mistoqsijiet (QA) u l-qari tal-komprensjoni (RC) huma ffukati prinċipalment fuq il-lingwa rikka fir-riżorsi bħall-Ingliż. F’dawn l-aħħar żminijiet, it-tkabbir mgħaġġel tal-kontenut multilingwi tal-internet ippreżenta diversi sfidi għas-sistemi eżistenti tal-QA. It-taħlit tal-kodiċi huwa sfida waħda bħal din li tagħmel il-kompitu aktar kumpless. F’dan id-dokument, nipproponu teknika motivata lingwistikament għall-ġenerazzjoni ta’ mistoqsijiet imħallta bil-kodiċi (CMQG) u arkitettura bbażata fuq netwerk newrali għat-tweġiba ta’ mistoqsijiet imħallta bil-kodiċi (CMQA). Għall-evalwazzjoni, aħna nħolqu manwalment mistoqsijiet imħallta bil-kodiċi għall-par lingwistiku Indjan-Ingliż. Sabiex tintwera l-effettività tat-teknika tas-CMQA bbażata fuq in-netwerk newrali tagħna, aħna nużaw żewġ settijiet ta’ dejta referenzjarji, SQuAD u MMQA. L-esperimenti juru li l-mudell propost tagħna jikseb prestazzjoni inkoraġġanti dwar is-CMQG u s-CMQA.', 'mn': 'Хариулт (QA) болон унших ойлголтын тухай суралцах судалгаа (RC) нь ихэвчлэн Англи хэл шиг ресурс баян хэл дээр анхаарлаа хандуулдаг. Сүүлийн үед олон хэл хэлний веб-содержимуудын хурдан өсөлт нь суурилсан QA системд олон сорилтуудыг бий болгодог. Код холбогдох нь ажлыг илүү төвөгтэй болгодог. Энэ цаасан дээр бид код холбогдсон асуулт (CMQG) болон код холбогдсон асуулт (CMQA) асуултын хариултын тулд мэдрэлийн сүлжээний суурь барилгуудын архитектурыг санал дэвшүүлнэ. Дэлхийн тулд бид Хинди-Англи хэлний хоёр хоёрын кодын хоорондоо холбогдсон асуултуудыг гараар бий болгодог. CMQA техникийн үндсэн мэдрэлийн сүлжээний үр дүнг харуулахын тулд бид хоёр салбарын өгөгдлийн санг, SQuAD болон MMQA ашиглаж байна. Түүх туршилтууд бидний санал өгсөн загвар нь CMQG болон CMQA дээрх үйл ажиллагааг дэмжиж чадна.', 'no': 'Det eksisterande forskning om spørsmålssvar (QA) og forståelse for lesing (RC) er hovudsakelig fokusert på ressursrykka språket som engelsk. I tidlegare har raskt vekst av fleire språk nettinnhaldet lagt fleire utfordringar til dei eksisterande QA-systema. Kodefeksing er ein slik utfordring som gjer oppgåva meir komplekse. I denne papiret foreslår vi ein lingvisk motivert teknikk for oppretting av spørsmål med kodeflikt (CMQG) og ein neuralnettverk basert arkitektur for svaring av spørsmål med kodeflikt (CMQA). For evaluering, lager vi manuelt kodeflikte spørsmål for hindisk språk par. For å visa effektiviteten av vår neuralnettverk basert CMQA-teknikk, bruker vi to benchmarkdatasett, SQuAD og MMQA. Eksperimentar viser at vårt foreslått modell når det gjer oppretting av utviklingar på CMQG og CMQA.', 'sr': 'Postoje istraživanja na odgovoru na pitanje (QA) i čitanje razumijevanja (RC) uglavnom se fokusiraju na bogat jezik resursa kao što je engleski. U poslednje vreme, brz rast multijezičkog sadržaja mreže izazvao je nekoliko izazova postojećim QA sistemima. Mešanje kodova je jedan takvi izazov koji čini zadatak kompleksnijim. U ovom papiru predlažemo lingvistički motivisanu tehniku za generaciju izmešane pitanja (CMQG) i arhitekturu na osnovu neuralne mreže za odgovor na pitanja između kodova (CMQA). Za procjenu, ruèno stvorimo brojna pitanja za parove hinda-engleskog jezika. Da bismo pokazali efikasnost naše neuralne mreže bazirane na CMQA tehnici, iskoristili smo dve baze podataka, SQuAD i MMQA. Eksperimenti pokazuju da naš predloženi model postigne ohrabrujuće učinke na CMQG i CMQA.', 'ro': 'Cercetările existente privind răspunsul la întrebări (QA) și citirea înțelegerii (RC) se concentrează în principal pe limba bogată în resurse precum engleza. În ultimul timp, creșterea rapidă a conținutului web multilingv a pus mai multe provocări sistemelor de asigurare a calității existente. Mixarea codurilor este o astfel de provocare care face sarcina mai complexă. În această lucrare, propunem o tehnică motivată lingvistic pentru generarea de întrebări mixte de cod (CMQG) și o arhitectură bazată pe rețea neurală pentru răspunsul la întrebări mixte de cod (CMQA). Pentru evaluare, creăm manual întrebările combinate de coduri pentru perechea de limbi hindi-engleză. Pentru a arăta eficacitatea tehnicii noastre CMQA bazate pe rețeaua neurală, utilizăm două seturi de date de referință, SQAD și MMQA. Experimentele arată că modelul nostru propus atinge performanțe încurajatoare pe CMQG și CMQA.', 'pl': 'Istniejące badania dotyczące odpowiedzi na pytania (QA) i czytania zrozumienia (RC) koncentrują się głównie na bogatym w zasoby języku, takim jak angielski. W ostatnim czasie gwałtowny rozwój wielojęzycznych treści internetowych stawiał kilka wyzwań dla istniejących systemów jakości. Mieszanie kodu jest jednym z takich wyzwań, które sprawia, że zadanie jest bardziej skomplikowane. W niniejszym artykule proponujemy językowo motywowaną technikę generowania pytań mieszanych kodem (CMQG) oraz architekturę opartą na sieci neuronowej do odpowiedzi na pytania mieszane kodem (CMQA). Do oceny ręcznie tworzymy pytania mieszane kodem dla pary językowej hindi-angielskiej. Aby pokazać skuteczność naszej techniki CMQA opartej na sieci neuronowej, wykorzystujemy dwa zbiory danych referencyjnych, SQuAD i MMQA. Eksperymenty pokazują, że proponowany przez nas model osiąga zachęcające wyniki na CMQG i CMQA.', 'si': 'ප්\u200dරශ්න ප්\u200dරතිච්චාරය (QA) සහ ප්\u200dරශ්නයක් කියවන්න (RC) ගැන පරීක්ෂණය ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ඉංග්\u200dරීසි ව අලුත් වෙලාවට, විශාල භාෂාවික වැඩේ විශාල විශාල විශාලයක් තියෙනවා තියෙන්න තියෙන්නේ QA පද්ධතිය කෝඩ් මික්ස් එක තමයි ඒ වගේම ප්\u200dරශ්නයක් තමයි වැඩ කරන්නේ. මේ පත්තරේ අපි භාෂාවික ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් නිර්මාණය (CMQG) සහ කෝඩ් මිශ්ණ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් භාෂාව විශ්වාස කරන්න, අපි හින්දි-ඉංග්\u200dරීසි භාෂා ජෝඩාව සඳහා කෝඩ් මික්ස් ප්\u200dරශ්නයක් හදනවා. අපේ න්\u200dයූරල් ජාලයේ අධාරිත CMQA තාක්ෂණය පෙන්වන්න, අපි බෙන්ච්මාර්ක් දත්ත සෙට් දෙකක් භාවිතා කරනවා, SQuAD සහ MMQA පරීක්ෂණය පෙන්වන්නේ අපේ ප්\u200dරයෝජනය කරපු මොඩල් එක CMQG සහ CMQA වලින් ප්\u200dරයෝජනය කරන්න පුළුවන්.', 'so': "Waxbarashada ku jira jawaabta su'aalaha (QA) iyo akhriska aasaasiga ah (RC) waxaa ugu horeyn loogu talagalay luqada nolosha-hodan sida Ingiriis oo kale. Muddo ugu dhowaad, koritaanka internetka oo ku qoran luuqado badan waxay sababtay dhibaatooyin badan oo ay ku leeyihiin nidaamka QA ee joogta. Code-mixing is one such challenge that makes the task more complex.  Qoraalkan waxan ku qoran, waxaynu soo jeedaynaa tekniko si luqada ah u dhaqaaqsan karo wax ku saabsan cod-mixed su'aal (CMQG) iyo shabakad neural ah oo ku saleysan dhismaha ku saabsan koox-mixed jawaabta su'aalaha (CMQA). Qiimeynta, waxaynu si rasmi ah u sameynaa su'aalo isku qasnaan oo ah labada luqada Hindi-Ingiriis. Si aan u muujinno shaqaalaha shabakadda neurada ee ku saleysan CMQA, waxaynu isticmaalaynaa laba sawirada benchmark, SQuAD iyo MMQA. Imtixaanka waxaa muuqda in modelkeeni la soo jeeday uu soo gaadho dhiirranaanta ku kordhiya CMQG iyo CMQA.", 'sv': 'Befintlig forskning om frågesvar (QA) och förståelse läsning (RC) är främst inriktad på det resursrika språket som engelska. På senare tid har den snabba tillväxten av flerspråkigt webbinnehåll inneburit flera utmaningar för de befintliga kvalitetssäkringssystemen. Kodblandning är en sådan utmaning som gör uppgiften mer komplex. I denna uppsats föreslår vi en språkligt motiverad teknik för kodblandad frågegenerering (CMQG) och en neuralt nätverksbaserad arkitektur för kodblandad frågebesvarande (CMQA). För utvärdering skapar vi manuellt kodblandade frågor för hindi-engelska språkparet. För att visa effektiviteten av vår neurala nätverksbaserade CMQA-teknik använder vi två benchmarkdatauppsättningar, SQUAD och MMQA. Experiment visar att vår föreslagna modell uppnår uppmuntrande prestanda på CMQG och CMQA.', 'ur': 'سوال جواب (QA) اور سمجھ پڑھنے (RC) کے بارے میں موجود تحقیقات کے ذریعہ اکثر انگلیسی کی طرح سرمایہ دار زبان پر تمرکز کیا جاتا ہے۔ اچھے وقت میں، بہت سی زبان ویب منصوبات کی تیز بڑھائی نے موجود QA سیستموں کے لئے بہت سی چال پیدا کی ہے۔ Code-mixing ایک ایسی چال ہے جو کام کو زیادہ پیچیدہ بناتا ہے۔ اس کاغذ میں، ہم ایک زبان کے ذریعہ منفجر کی تکنیک کی پیشنهاد کرتے ہیں کوڈ میکس سؤال پیدا کرنے کے لئے (CMQG) اور کوڈ میکس سؤال جواب کے لئے نیورال نیٹ ورک کی بنیادی معماری (CMQA) کے لئے۔ ارزیابی کے لئے، ہم ہینڈی-انگلیسی زبان جوڑوں کے لئے کوڈ مmixed سوال بناتے ہیں. ہمارے نیورل نیٹ ورک کی عملی دکھانے کے لئے CMQA ٹیکنیک کی بنیاد ہے، ہم دو بنچم مارک ڈیٹ سٹ، SQuAD اور MMQA کو استعمال کرتے ہیں. تجربے دکھاتے ہیں کہ ہماری پیشنهاد مدل CMQG اور CMQA کے ذریعے کامیابی کی تحقیق کرتی ہے.', 'ta': '@ info: status சமீபத்தில், பல மொழிகளின் உள்ளடக்கங்களின் வேகமான வளர்ச்சி தற்போதைய QA அமைப்புகளுக்கு பல சவால்கள் ஏற்பட்டுள்ளது. குறியீடு கலந்து என்பது செயலை மிகவும் சிக்கலாக்குகிறது. இந்த காக்கியத்தில், நாம் குறியீடு கலக்கப்பட்ட கேள்வி உருவாக்குவதற்கான மொழியில் ஊக்கும் தொழில்நுட்பம் மற்றும் குறியீடு கலக்கப்பட்ட கேள்வி மதிப்பிடுவதற்கு, நாம் கைமுறையாக குறியீடு கலக்கப்பட்ட கேள்விகளை உருவாக்குகிறோம். CMQA தொழில்நுட்பத்தை காண்பிக்க எங்கள் புதிய வலைப்பின்னல் செயல்பாடு Experiments show that our proposed model achieves encouraging performance on CMQG and CMQA.', 'vi': 'Nghiên cứu hiện tại về việc trả lời câu hỏi (QA) và đọc thấu hiểu (RC) tập trung chủ yếu vào ngôn ngữ giàu tài nguyên như tiếng Anh. Trong thời gian gần đây, sự phát triển nhanh của nội dung mạng đa ngôn ngữ đã tạo ra nhiều thử thách với hệ thống QA hiện tại. Mã pha trộn là một thử thách khiến nhiệm vụ phức tạp hơn. Trong tờ giấy này, chúng tôi đề xuất một phương pháp ngôn ngữ học cho việc sản xuất câu hỏi hỗn hợp mã (CMQG) và một kiến trúc dựa vào mạng thần kinh để trả lời câu hỏi hỗn hợp mã (CMQA). Để đánh giá, chúng tôi sẽ tự tạo câu hỏi trộn mã cho cặp ngôn ngữ tiếng Hindi. Để thể hiện hiệu quả của kỹ thuật CMYK dựa vào mạng thần kinh, chúng tôi sử dụng hai bộ dữ liệu hiển thị, SQurAD và MMQA. Thí nghiệm cho thấy mẫu thử của chúng ta đạt được hiệu quả khuyến khích về CMQG và CMQA.', 'uz': "Name Yaqinda ko'pchilik tilning tarkibini ko'p tillar tarkibi tez o'zgartirish, mavjud QA tizimlariga bir necha qiymatlar beradi. Kodlash usuli vazifani murakkab qiladi. Bu qogʻozda, biz qodviy mix soʻrov yaratish (CMQG) va kodmix savol javobi uchun neyrol tarmoqni yaratish uchun ishlatiladimiz. Kodlash uchun, biz Hindi- Ingliz tili ikkita qoidagi qoiday minglab savollarni yaramiz. Name Tekshirish modellarimiz CMQG va CMQA bilan ishni amalga oshirishni ko'rsatadi.", 'bg': 'Съществуващите изследвания в областта на отговора на въпроси и разбирането на четенето са фокусирани главно върху богатия на ресурси език като английския. В последно време бързият растеж на многоезичното уеб съдържание постави няколко предизвикателства пред съществуващите системи за контрол на качеството. Смесването на кодове е едно такова предизвикателство, което прави задачата по-сложна. В настоящата статия предлагаме лингвистично мотивирана техника за генериране на кодово смесени въпроси (CMQG) и базирана на невронна мрежа архитектура за кодово смесени въпроси (CMQA). За оценка ние ръчно създаваме кодово смесени въпроси за двойката хинди-английски език. За да покажем ефективността на нашата технология базирана на невронна мрежа, ние използваме два сравнителни набора данни, SQuAD и MMQA. Експериментите показват, че нашият предложен модел постига окуражаващо представяне на CMQG и CMQA.', 'hr': 'Postoje istraživanja na odgovoru na pitanje (QA) i čitanje razumijevanja (RC) uglavnom se fokusiraju na bogat jezik resursa poput engleskog jezika. U zadnje vrijeme, brz rast multijezičkog sadržaja mreže izazvao je nekoliko izazova postojećim QA sustavima. Mješanje kodova je jedan takvi izazov koji čini zadatak kompleksnijim. U ovom papiru predlažemo lingvistički motiviranu tehniku za generaciju izmiješanih pitanja kod (CMQG) i arhitekturu na osnovu neuralne mreže za odgovor na pitanja izmiješanih kod (CMQA). Za procjenu, ručno stvorimo brojna pitanja za indijanski-engleski parov. Da bismo pokazali učinkovitost naše neuralne mreže bazirane na CMQA tehnici, iskoristili smo dvije baze podataka, SQuAD i MMQA. Eksperimenti pokazuju da naš predloženi model postigne ohrabrujuće učinke na CMQG i CMQA.', 'nl': "Bestaand onderzoek naar vragen beantwoorden (QA) en begrip lezen (RC) zijn voornamelijk gericht op de hulpbronnenrijke taal zoals Engels. De snelle groei van meertalige webcontent heeft de bestaande QA-systemen de afgelopen tijd voor verschillende uitdagingen gesteld. Code-mixen is zo'n uitdaging die de taak complexer maakt. In dit artikel stellen we een linguïstisch gemotiveerde techniek voor code-mixed question generation (CMQG) en een neuronale netwerk gebaseerde architectuur voor code-mixed question responsing (CMQA) voor. Voor evaluatie maken we handmatig de code-gemengde vragen voor Hindi-Engels taalpaar. Om de effectiviteit van onze neurale netwerk gebaseerde CMQA techniek aan te tonen, gebruiken we twee benchmark datasets, SQuAD en MMQA. Experimenten tonen aan dat ons voorgestelde model bemoedigende prestaties behaalt op CMQG en CMQA.", 'id': 'Penelitian yang ada tentang jawaban pertanyaan (QA) dan pembacaan pemahaman (RC) terutama fokus pada bahasa kaya sumber daya seperti bahasa Inggris. Pada saat-saat terakhir, pertumbuhan cepat dari konten web multibahasa telah menimbulkan beberapa tantangan untuk sistem QA yang ada. Pengcampuran kode adalah satu tantangan yang membuat tugas lebih rumit. Dalam kertas ini, kami mengusulkan teknik berbasis bahasa untuk generasi pertanyaan campuran kode (CMQG) dan arsitektur jaringan saraf untuk menjawab pertanyaan campuran kode (CMQA). Untuk evaluasi, kita secara manual menciptakan pertanyaan-kode campuran untuk pasangan bahasa Hindi-Inggris. Untuk menunjukkan efektivitas dari teknik CMQA berdasarkan jaringan saraf kami, kami menggunakan dua set data benchmark, SQuAD dan MMQA. Eksperimen menunjukkan bahwa model kami diusulkan mencapai prestasi yang mendorong pada CMQG dan CMQA.', 'de': 'Die bisherige Forschung zu Fragen beantworten (QA) und Verstehen Lesen (RC) konzentriert sich hauptsächlich auf die ressourcenreiche Sprache wie Englisch. Das rasante Wachstum mehrsprachiger Webinhalte stellt die bestehenden Qualitätssicherungssysteme in jüngster Zeit vor mehrere Herausforderungen. Code-Mischen ist eine solche Herausforderung, die die Aufgabe komplexer macht. In diesem Beitrag schlagen wir eine linguistisch motivierte Technik zur Code-Mixed Question Generation (CMQG) und eine neuronale Netzwerk basierte Architektur für Code-Mixed Question Beantwortung (CMQA) vor. Zur Auswertung erstellen wir manuell die Code-Mixed-Fragen für Hindi-Englisch Sprachpaar. Um die Effektivität unserer neuronalen Netzwerk-basierten CMQA-Technik zu zeigen, verwenden wir zwei Benchmark-Datensätze, SQuAD und MMQA. Experimente zeigen, dass unser vorgeschlagenes Modell ermutigende Leistungen auf CMQG und CMQA erzielt.', 'ko': '기존 질의응답(QA)과 이해독해(RC) 연구는 주로 영어 등 자원이 풍부한 언어에 집중됐다.최근 몇 년 동안 다국어 웹 콘텐츠의 급속한 증가는 기존의QA시스템에 도전을 가져왔다.코드 혼합은 임무를 더욱 복잡하게 만드는 도전이다.본고에서 우리는 언어 기반의 코드 혼합 문제 생성 기술(CMQG)과 신경 네트워크 기반의 코드 혼합 문제 응답 체계 구조(CMQA)를 제시했다.평가를 위해 우리는 수동으로 인디언-영어 언어를 위해 코드 혼합 문제를 만들었다.우리는 신경 네트워크를 기반으로 한 CMQA 기술의 유효성을 증명하기 위해 STAND와 MMQA 두 가지 기준 데이터 집합을 사용했다.실험에 따르면 우리가 제시한 모델은 CMQG와 CMQA에서 고무적인 성능을 얻었다.', 'da': 'Eksisterende forskning i spørgsmål besvarelse (QA) og forståelse læsning (RC) er primært fokuseret på det ressourcerige sprog som engelsk. Den hurtige vækst i flersproget webindhold har i den seneste tid udgjort flere udfordringer for de eksisterende kvalitetssikringssystemer. Kodeblanding er en sådan udfordring, der gør opgaven mere kompleks. I denne artikel foreslår vi en sprogligt motiveret teknik til kode-blandet spørgsmål generering (CMQG) og en neural netværksbaseret arkitektur til kode-blandet spørgsmål besvarelse (CMQA). Til evaluering opretter vi manuelt kodeblandede spørgsmål til hindi-engelsk sprogpar. For at vise effektiviteten af vores neurale netværksbaserede CMQA teknik anvender vi to benchmark datasæt, SQUAD og MMQA. Eksperimenter viser, at vores foreslåede model opnår opmuntrende resultater på CMQG og CMQA.', 'sw': 'Utafiti unaoendelea kuhusu majibu ya maswali (QA) na kusoma kompyuta (RC) umejikita zaidi kwenye lugha ya rasilimali kama vile Kiingereza. Katika nyakati za hivi karibuni, ongezeko la haraka la maudhui ya lugha mbalimbali limesababisha changamoto kadhaa za mifumo ya QA. Kuchanganyika kwa sheria ni changamoto kama hiyo inafanya kazi kuwa tatizo zaidi. Katika karatasi hii, tunapendekeza teknolojia inayohamasishwa kwa lugha kwa ajili ya kizazi kinachochanganyika kwa maswali (CMQG) na ujenzi wa mitandao ya kijamii kwa ajili ya kujibu swali linalochanganyika na kodi (CMQA). Kwa uchunguzi, tunatengeneza maswali yanayochanganyika kwa mikononi kwa ajili ya wawili wa lugha ya Kiingereza. Ili kuonyesha ufanisi wa Mtandao wetu wa neura unaotumia teknolojia ya CMQA, tunatumia seti mbili za bendera, SQuAD na MMQA. Majaribio yanaonyesha kuwa muundo wetu unapendekezwa unafanikiwa kutekeleza ufanisi wa CMQG na CMQA.', 'tr': 'Jagap bermek we düşünmek (RC) barada bar soraglary barada barlap ýöne baý dillere iñlis dilinde görkezilýär. Soňky wagtlarda, köp dilli web mazmunlarynyň tiz ösümlisi bolan QA sistemalara birnäçe kynçylyklar çykdy. Köd karıştırmak işi karmaşık eden bir kynçylykdyr. Bu kagyzda, biz dili karışyk soragy döretmek üçin bir tekniki (CMQG) we näyral şebeke karışyk soragy jogaplamak üçin bir arhitektura tekniýet berýäris. Ýaglamak üçin biz Hindi dil çift üçin kelläpli karışyk soraglary elimizden bejerdik. Nöral ağlamızın CMQA tekniklerinin etkinliğini göstermek için, iki benchmark veri setleri, SQuAD ve MMQA kullanırız. Testler biziň teklip eden nusgamyzyň CMQG we CMQA-da arzuw etmäge başarýandygyny görkezýär.', 'af': "Bestaande ondersoek op vraag antwoord (QA) en verstanding lees (RC) word heeltemal gefokus op die hulpbron- ryk taal soos Engels. In onlangse tyde het die vinnige groei van multi-tale web inhoud verskeie uitdagings aan die bestaande QA stelsels gestel. Code-mixing is een sodanige uitdaging wat die taak meer kompleks maak. In hierdie papier, voorstel ons 'n lingwisiese motiveerde teknike vir kode gemengde vraag generasie (CMQG) en 'n neuralnetwerk gebaseerde arkitektuur vir kode gemengde vraag antwoord (CMQA). Vir evaluasie skep ons die kode gemengde vrae hand vir Hindi-Engels taal paar. Om die effektiviteit van ons neuralnetwerk gebaseerde CMQA-teknik te wys, gebruik ons twee benchmark datastelle, SQuAD en MMQA. Eksperimente wys dat ons voorgestelde model bereik die versterking van prestasie op CMQG en CMQA.", 'sq': 'Existing research on question answering (QA) and comprehension reading (RC) are mainly focused on the resource-rich language like English.  Në kohët e fundit, rritja e shpejtë e përmbajtjes multigjuhësore të internetit ka paraqitur disa sfida ndaj sistemeve ekzistuese QA. Përzierja e kodeve është një sfidë e tillë që e bën detyrën më komplekse. Në këtë letër, propozojmë një teknikë gjuhësore të motivuar për gjenerimin e pyetjeve të përziera me kod (CMQG) dhe një arkitekturë të bazuar në rrjetin nervor për përgjigjen e pyetjeve të përziera me kod (CMQA). Për vlerësim, ne krijojmë me dorë pyetjet e përziera me kode për çiftin gjuhë Hindi-Anglisht. Për të treguar efektshmërinë e teknikës CMQA të rrjetit tonë nervor, ne përdorim dy baza të dhënash, SQuAD dhe MMQA. Eksperimentet tregojnë se modeli ynë i propozuar arrin performancë inkurajuese në CMQG dhe CMQA.', 'fa': 'تحقیقات موجود در پاسخ سوال (QA) و خواندن درک (RC) اصلاً روی زبان ثروت منبع مانند انگلیسی تمرکز می\u200cشوند. در طول اخیر، رشد سریع محتوای وب چند زبان برای سیستم QA موجود چند چالش قرار داده است. پیوند کد یک چالش چنین است که کار را پیچیده\u200cتر می\u200cکند. در این کاغذ، ما پیشنهاد می\u200cکنیم یک تکنیک انگیز زبان برای نسل سوال\u200cهای مختلف (CMQG) و یک معماری بنیاد شبکه عصبی برای جواب سوال\u200cهای مختلف (CMQA) با کد پیوند داده شده. برای ارزیابی، ما به دستی سوال\u200cهای مختلف کد برای جفت زبان هندی-انگلیسی را ایجاد می\u200cکنیم. برای نشان دادن فناوری شبکه عصبی ما بر اساس فناوری CMQA استفاده می کنیم، دو مجموعه داده\u200cهای سنجیر، SQuAD و MMQA را استفاده می کنیم. تجربه\u200cها نشان می\u200cدهند که مدل پیشنهاد ما به تحریک اجرای CMQG و CMQA رسیده است.', 'az': 'QA cavab vermək və anlama oxumaq (RC) barəsindəki araştırma məqsədilə İngilizce kimi çox qüvvətli ressurs-zengin dilinə odaqlanır. Son zamanlarda, çoxlu dilli web məlumatının tez artıqlığı mevcut QA sistemlərinə çoxlu çətinliklər yaratdı. Kod-karışması işləri daha kompleks edir. Bu kağızda, kodla karışmış sual nəzəriyyəti (CMQG) və kodla karışmış sual cevapı üçün nöral a ğ tabanlı arhitektura təklif edirik. Vəziyyət üçün biz Hindi dili çift üçün kodla karışmış suallar yaratdıq. Nöral şəbəkəmizin CMQA tehnikasının etkinliğini göstərmək üçün, iki benchmark veri qurularını, SQuAD və MMQA istifadə edirik. Tərəbələr təklif etdiyimiz modellərin CMQG və CMQA təsirlərinə təsirlənməsini göstərir.', 'bn': 'প্রশ্নের উত্তর (কিউএ) এবং সম্পূর্ণ পাঠক (আরসি) সম্পর্কে বিদ্যমান গবেষণা মূলত ইংরেজীর মতো সম্পদ-সমৃদ্ধ ভাষার উপর মনোযোগ প্রদান করা  সাম্প্রতিক সময়ে বহুভাষী ওয়েব বিষয়বস্তুর দ্রুত বৃদ্ধির ব্যবস্থা বেশ কয়েকটি চ্যালেঞ্জ তৈরি করেছে বিদ্যমান কিউএ সি কোড মিশ্রণ একটি চ্যালেঞ্জ যা কাজের জন্য আরো জটিল করে। এই কাগজটিতে আমরা কোড মিশ্রিত প্রশ্ন প্রজন্ম (সিএমকিজি) এবং কোড মিশ্রিত প্রশ্নের উত্তরের জন্য নিউরেল নেটওয়ার্ক ভিত্তিক ক কাঠামো প্রস্তাব করি। মূল্যায়নের জন্য আমরা হিন্দি-ইংরেজি ভাষার জোড়ার জন্য কোড মিশ্রিত প্রশ্ন তৈরি করি। আমাদের নিউরেল নেটওয়ার্ক ভিত্তিক সিএমকিয়া প্রযুক্তির কার্যক্রম দেখানোর জন্য আমরা দুটি বেনম্যার্ক ডাটাসেট, এসকুয়েড এবং এম পরীক্ষাগুলো দেখাচ্ছে যে আমাদের প্রস্তাবিত মডেল সিএমকিউজি এবং সিএমকিউএ-এর উপর উৎসাহিত করার কাজ অর্জন করে।', 'am': 'የጥያቄ መልስ (QA) እና የድምፅ አነብብ (RC) በመጀመሪያው በመድረክ-ሀብታም ቋንቋ እንደ እንግሊዘኛ ነው፡፡ በቅርብ ዘመን፣ የበዛ ቋንቋ ቋንቋዎች የውይይት ድጋፍ የአገኘውን የQA ሲስተም ብዙዎችን ጥላቻዎች አቀረበ፡፡ የኮድ መቀላቀል ትክክለኛ ነው የስራውን ትክክለኛ የሚያደርግ:: በዚህ ፕሮግራም፣ ለቋንቋ-ቋንቋ የተቀላቀለ የጥያቄ ትውልድ (CMQG) እና የናውራዊ መረብ መሠረት የኮድ-mixed ጥያቄ መልስ (CMQA) መሠረት እናስመክራለን፡፡ ለማስተዋል፣ የኮድ-የተለየ ጥያቄዎችን ለHindi-እንግሊዘኛ ቋንቋ ሁለትን እናደርጋለን፡፡ በCMQA ስህተት የተደረገውን የናውሬል መረብ ጥቅም ለማሳየት፣ ሁለት benchmark ዳታዎችን፣ SQuAD እና MMQA እናጠቀም፡፡ ፈተናዎች በCMQG እና CMQA ላይ የሞክራችን ሞዴል የሚያሳየው ነው፡፡', 'ca': "La recerca actual sobre resposta a preguntes (QA) i lectura de comprensió (RC) es centra principalment en un llenguatge ric en recursos com l'anglès. En els últims temps, el ràpid creixement del contingut web multilingüe ha plantejat varis reptes als sistemes existents de QA. La combinació de codis és un desafiament que complica la tasca. En aquest paper, proposem una tècnica lingüísticament motivada per la generació de preguntes combinades amb codi (CMQG) i una arquitectura basada en xarxa neural per respondre preguntes combinades amb codi (CMQA). Per a l'evaluació, creem manualment les preguntes combinades amb codi per a un parell de llenguatge hindí-anglès. In order to show the effectiveness of our neural network based CMQA technique, we utilize two benchmark datasets, SQuAD and MMQA.  Els experiments demostren que el nostre model proposat aconsegueix un rendiment encorajador en CMQG i CMQA.", 'hy': 'Գոյություն ունեցող հետազոտությունները հարցերին պատասխանելու և ընկալումների կարդալու մասին հիմնականում կենտրոնանում են ռեսուրսներով հարուստ լեզուն, ինչպիսին է անգլերենը: Վերջերս բազմալեզու վեբ պարունակության արագ աճը առաջացրել է մի քանի մարտահրավեր գոյություն ունեցող QA համակարգերին: Կոդի խառնուրդը նման մարտահրավեր է, որը հանձնարարությունը դարձնում է ավելի բարդ: Այս թղթի մեջ մենք առաջարկում ենք լեզվաբանական մոտիվացված տեխնիկան կոդի-խառնված հարցերի ստեղծման համար (CQG) և նյարդային ցանցի հիմնված ճարտարապետություն կոդի-խառնված հարցերի պատասխանելու համար (CQA). Հինդի-անգլերենի զույգի համար մենք ձեռքով ստեղծում ենք կոդի խառնված հարցեր: Որպեսզի ցույց տանք մեր նյարդային ցանցի արդյունավետությունը հիմնված ԿՄԿ տեխնիկայի համար, մենք օգտագործում ենք երկու համեմատային տվյալների համակարգեր, SQUADը և ՄՄԿԿ: Փորձարկումները ցույց են տալիս, որ մեր առաջարկած մոդելը հասնում է խրախուսափելի արտադրողությունների ԿՄԿ-ի և ԿՄԿ-ի դեպքում:', 'cs': 'Stávající výzkum v oblasti odpovědi na otázky (QA) a porozumění čtení (RC) se zaměřuje především na jazyk bohatý na zdroje, jako je angličtina. Rychlý růst vícejazyčného webového obsahu v poslední době představoval několik výzev pro stávající systémy QA. Míchání kódu je jednou z takových výzev, která činí úkol složitější. V tomto článku navrhujeme lingvisticky motivovanou techniku pro generování kódových smíšených otázek (CMQG) a architekturu založenou na neuronové síti pro odpověď na kódové smíšené otázky (CMQA). Pro vyhodnocení ručně vytvoříme otázky smíšené kódem pro jazykový pár hindsky-anglicky. Abychom ukázali efektivitu naší techniky CMQA založené na neuronové síti, využíváme dva referenční datové sady, SQuAD a MMQA. Experimenty ukazují, že náš navržený model dosahuje povzbuzujících výkonů na CMQG a CMQA.', 'bs': 'Postoje istraživanja na odgovoru na pitanje (QA) i čitanje razumijevanja (RC) uglavnom se fokusiraju na bogat jezik resursa kao što je engleski. U zadnje vrijeme, brz rast multijezičkog sadržaja mreže izazvao je nekoliko izazova postojećim QA sistemima. Mešanje kodova je jedan takvi izazov koji čini zadatak kompleksnijim. U ovom papiru predlažemo lingvistički motiviranu tehniku za generaciju izmiješanih pitanja (CMQG) i arhitekturu na osnovu neuralne mreže za odgovor na pitanja izmiješanih kod (CMQA). Za procjenu, ručno stvorimo brojna pitanja za parove hindskih-engleskih jezika. Da bismo pokazali učinkovitost naše neuralne mreže bazirane na CMQA tehnici, iskoristili smo dvije baze podataka o referenciji, SQuAD i MMQA. Eksperimenti pokazuju da naš predloženi model postigne ohrabrujuće učinke na CMQG i CMQA.', 'et': 'Olemasolevad uuringud küsimustele vastamise (QA) ja arusaamise (RC) kohta keskenduvad peamiselt ressursirikkale keelele, nagu inglise keel. Viimasel ajal on mitmekeelse veebisisu kiire kasv põhjustanud mitmeid probleeme olemasolevatele kvaliteedi tagamise süsteemidele. Koodide segamine on üks selline väljakutse, mis muudab ülesande keerukamaks. Käesolevas töös pakume välja keeleliselt motiveeritud tehnika koodisegaküsimuste genereerimiseks (CMQG) ja neurovõrgupõhise arhitektuuri koodisegaküsimustele vastamiseks (CMQA). Hindamiseks loome käsitsi koodisegatud küsimused hindi-inglise keele paari jaoks. Selleks et näidata oma närvivõrgul põhineva CMQA tehnika efektiivsust, kasutame kahte võrdlusandmekogumit, SQuAD ja MMQA. Eksperimentid näitavad, et meie pakutud mudel saavutab julgustavaid tulemusi CMQG ja CMQA puhul.', 'fi': 'Kysymysten vastaamista ja ymmärtämistä käsittelevä tutkimus keskittyy pääasiassa englannin kaltaisiin resursseihin. Monikielisen verkkosisällön nopea kasvu on viime aikoina asettanut useita haasteita nykyisille laadunvarmistusjärjestelmille. Koodien sekoittaminen on yksi tällainen haaste, joka tekee tehtävästä monimutkaisemman. Tässä työssä ehdotamme kielellisesti motivoitua tekniikkaa koodisekoitettujen kysymysten generointiin (CMQG) ja neuroverkkopohjaista arkkitehtuuria koodisekoitettujen kysymysten vastaamiseen (CMQA). Arviointia varten luomme manuaalisesti koodisekoitetut kysymykset hindi-englanti kieliparille. Neuroverkkoon perustuvan CMQA-tekniikan tehokkuuden osoittamiseksi käytämme kahta vertailuaineistoa, SQuAD ja MMQA. Kokeet osoittavat, että ehdotetulla mallilla saavutetaan kannustava suorituskyky CMQG:ssä ja CMQA:ssa.', 'sk': 'Obstoječe raziskave o odgovarjanju na vprašanja (QA) in branju razumevanja (RC) se osredotočajo predvsem na jezik, bogat z viri, kot je angleščina. V zadnjem času je hitra rast večjezičnih spletnih vsebin predstavljala več izzivov obstoječim sistemom zagotavljanja kakovosti. Mešanje kod je eden takšnih izzivov, ki naredi nalogo bolj zapleteno. V prispevku predlagamo jezikovno motivirano tehniko za generiranje vprašanj z mešanimi kodami (CMQG) in arhitekturo nevronskega omrežja za odgovarjanje na vprašanja z mešanimi kodami (CMQA). Za vrednotenje ročno ustvarimo vprašanja z mešanimi kodami za jezikovni par hindi-angleščina. Da bi pokazali učinkovitost naše tehnike CMQA na podlagi nevronskega omrežja, uporabljamo dva referenčna nabora podatkov, SQuAD in MMQA. Eksperimenti kažejo, da naš predlagani model dosega spodbudno učinkovitost pri CMQG in CMQA.', 'ha': "@ info: whatsthis A cikin watan da suka sani, faras ya ƙara wa maɓallin abõkan multi-lingui sun ƙayyade wasu tsõratar zuwa na tsarin QA da ke gaba. Code-Mijinta yana da wata kanal ta zama mai kamfata aiki. Ga wannan takardan, Munã buɗa wani na'urar da aka yi wa kodi-da-haɗe masu tambayar (CMQG) da kuma an sami tsarin bakin tarakiki na neural dõmin ya karɓa wa tambayar kodi-buga (CMQA). Ko iya ƙaddara, za mu sami kodi-da-haɗi cikin harshen Hidi-Ingiriya. Dõmin ya nuna aikin shawarar neural na'urar tarakinmu a kan CMQA, za mu yi amfani da tsarin danne biyu, SQuAD da MMQA. Tajarakin na nuna cewa misalinmu da aka buƙata yana sãmun mai farin ciki a kan CMQG da CMQA.", 'jv': "Where's that Awak dhéwé, akeh sing paling-sistem sing luwih akeh pengguna web sing sampeyan ngono perbudhakan sing sampeyan nggawe sistèm yang kedhangguna dhéwé. Name Nang pepulan iki, kita supoyo teknik nggawe barang kelangan karo akeh panjur-barêng nggawe barang nggawe barang kelangan (color-frame) lan nganggo sistem sing basa oleh nggawe sistem sing isine gambar akeh panjur (color-frame). Ngawe Perintah-perintah, kéné paling manut kanggo kelas pangan lan nganggo barang pangan ingkang. Mbok kanggo ngomong efekasi tambah netengan sing gambar SMKA teknik Gewat ujaran ngomong nik akeh model sing paling nggawe sawalih iki dadi nggawe barang kelangan cara-cara sing aléh SMqG karo SMqA.", 'bo': 'Existing research on question answering (QA)and comprehension reading (RC)are mainly focused on the resource-rich language like English. ཉེ་ཆར་མཚམས་དུ་ཕལ་ཆེན་སྐད་ཡིག་ཆ་ནང་དུ་འཕེལ་རིམ་གྱི་འཕེལ་རིམ་འདིས་གནས་ཡོད་པའི་QA་ལག་གི་ལ་གདོང་ལེན་དགོ སྒྲིག་ཨང་mixing་འདི་ལྟ་བུའི་གདོང་ལེན་དགོས་པ་ཞིག་ནི་ལས་འགུལ་གྱི་དཀའ་གདོང་ལེན་ཏེ། འུ་ཅག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་སྐད་རིགས་ལ་སྤྲོད་ཀྱི་ཐབས་ལམ་གནང་བ་འདྲ་བ་ཞིག་བཤད་ཀྱི་ཡོད། དཔྱད་པར་ནི། ང་ཚོས་རྒྱ་གར་དབྱིན་ཡིག་གི་སྐད་ཆ་གཉིས་ཀྱི་ལས་སྒྲིག་ཆ་འདྲི་ཚིག་ལག་ནས་གསར་འཛུགས། In order to show the effectiveness of our neural network based CMQA technique, we utilize two benchmark datasets, SQuAD and MMQA. Experiments show that our proposed model achieves promoting performance on CMQG and CMQA.', 'he': 'מחקר קיים על תשובות לשאלות (QA) וקריאת הבנה (RC) מתמקדים בעיקר בשפה עשירה במשאבים כמו אנגלית. בזמנים האחרונים, הגידול המהיר של תוכן רשת רב-שפתי העלה כמה אתגרים למערכות QA קיימות. שילוב קודים הוא אתגר אחד כזה שעושה את המשימה יותר מורכבת. In this paper, we propose a linguistically motivated technique for code-mixed question generation (CMQG) and a neural network based architecture for code-mixed question answering (CMQA).  For evaluation, we manually create the code-mixed questions for Hindi-English language pair.  In order to show the effectiveness of our neural network based CMQA technique, we utilize two benchmark datasets, SQuAD and MMQA.  ניסויים מראים שהמודל המוצע שלנו משיג ביצועים מעודדים על CMQG ו CMQA.'}
{'en': 'Commonsense Knowledge Base Completion and Generation', 'ar': 'كومونسنس إتمام قاعدة المعارف وتوليدها', 'fr': 'Achèvement et génération de la base de connaissances Commonsense', 'es': 'Finalización y generación de la base de conocimientos de sentido', 'pt': 'Conclusão e geração da base de conhecimento do Commonsense', 'ja': 'コモンセンスナレッジベースの完成と生成', 'zh': '常识性知识库成生成', 'ru': 'Завершение создания и формирование базы знаний Commonsense', 'hi': 'Commonsense Knowledge Base Completion and Generation', 'ga': 'Críochnú agus Giniúint Bhonn Eolais Commonsense', 'hu': 'Commonsense Knowledge Base befejezése és generálása', 'el': 'Ολοκλήρωση και δημιουργία βάσης γνώσης κοινής λογικής', 'ka': 'Comment', 'mk': 'Commonsense Knowledge Base Completion and Generation', 'lt': 'Bendros žinių bazės užbaigimas ir sukūrimas', 'kk': 'Comment', 'it': 'Completamento e generazione della base di conoscenze comuni', 'ms': 'Penyempurnaan dan Jenerasi Pangkalan Pengetahuan Komunis', 'ml': 'കമോണ്\u200dസണ്\u200dസെന്\u200dസ് അറിവ് അടിസ്ഥാനം പൂര്\u200dത്തിയും ജനിപ്പിക്കുക', 'mt': 'Tlestija u Ġenerazzjoni ta’ Bażi ta’ Għarfien Komuni', 'mn': 'Commonsense Knowledge Base Completion and Generation', 'no': 'Comment', 'pl': 'Zakończenie i generowanie bazy wiedzy Commonsense', 'ro': 'Finalizarea și generarea bazei de cunoștințe Commonsense', 'sr': 'Komunikacijska baza znanja Završenja i generacija', 'si': 'Comment', 'sv': 'Fullbordande och generering av Commonsense Knowledge Base', 'ta': 'Comment', 'so': 'Heshiiska aqoonta aasaasiga ah', 'ur': 'کمنسنسس علم بنیاد کامل اور پیدائش', 'uz': 'Comment', 'vi': 'Thiết lập và Thế Hệ Kiến thức phổ thông', 'bg': 'Приключване и генериране на базата данни от познания', 'nl': 'Completie en Generatie van de Commonsense Knowledge Base', 'da': 'Fuldførelse og generering af Commonsense Knowledge Base', 'hr': 'Završenje i generacija baze znanja Commonsense', 'de': 'Vervollständigung und Generierung der Commonsense Knowledge Base', 'id': 'Penyempurnaan dan Generasi Pangkalan Pengetahuan Komunis', 'fa': 'تولید و تولید بنیاد دانش کمپنس', 'ko': '상식지식고의 완성과 생성', 'sw': 'Ujuzi wa Mawasiliano', 'tr': 'Bilim Esasy Tamamlama we Däpli', 'af': 'Kommunikasie kennis Basis Voltooiïng en Generasie', 'sq': 'Commonsense Knowledge Base Completion and Generation', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Commonsense Knowledge Base Completion and Generation', 'az': 'Commonsense Bilim Basi Tamamlama v…ô D√ºz…ôltm…ô', 'bn': 'কমান্সনসেন্সের জ্ঞান বেস সম্পূর্ণ এবং প্রজন্ম', 'bs': 'Završenje i generacija baze znanja zajednice', 'ca': 'Completació i generació de bases de coneixements comunes', 'cs': 'Dokončení a generování znalostní báze Commonsense', 'et': 'Üldmõistliku teabebaasi lõpetamine ja loomine', 'fi': 'Yleisen järkevyyden tietokannan täydentäminen ja luominen', 'jv': 'Komplikasyon Panjenengan Bilih Basa Komplikasyon lan Generasi', 'sk': 'Dopolnjevanje in ustvarjanje splošne zbirke znanja', 'he': 'סיום ומוציא בסיס ידע משותף', 'ha': '@ action', 'bo': 'Commonsense Knowledge Base Completion and Generation'}
{'en': 'This study focuses on acquisition of commonsense knowledge. A previous study proposed a commonsense knowledge base completion (CKB completion) method that predicts a confidence score of for triplet-style knowledge for improving the coverage of CKBs. To improve the accuracy of CKB completion and expand the size of CKBs, we formulate a new commonsense knowledge base generation task (CKB generation) and propose a joint learning method that incorporates both CKB completion and CKB generation. Experimental results show that the joint learning method improved completion accuracy and the generation model created reasonable knowledge. Our generation model could also be used to augment data and improve the accuracy of completion.', 'fr': "Cette étude met l'accent sur l'acquisition de connaissances de bon sens. Une étude précédente proposait une méthode de complétion de base de connaissances de bon sens (achèvement CKB) qui prédit un score de confiance pour les connaissances de type triplet afin d'améliorer la couverture des CKB. Pour améliorer la précision de l'achèvement des CKB et augmenter la taille des CKB, nous formulons une nouvelle tâche de génération de base de connaissances de bon sens (génération CKB) et proposons une méthode d'apprentissage conjointe qui intègre à la fois l'achèvement CKB et la génération des CKB. Les résultats expérimentaux montrent que la méthode d'apprentissage conjoint a amélioré la précision d'achèvement et que le modèle de génération a créé des connaissances raisonnables. Notre modèle de génération pourrait également être utilisé pour augmenter les données et améliorer la précision de l'achèvement.", 'es': 'Este estudio se centra en la adquisición de conocimientos de sentido común. Un estudio anterior propuso un método de finalización de la base de conocimientos de sentido común (finalización de CKB) que predice una puntuación de confianza para el conocimiento de estilo triplete para mejorar la cobertura de los CKB. Para mejorar la precisión de la finalización de CKB y ampliar el tamaño de los CKB, formulamos una nueva tarea de generación de base de conocimiento de sentido común (generación de CKB) y proponemos un método de aprendizaje conjunto que incorpore tanto la finalización de CKB como la generación de CKB. Los resultados experimentales muestran que el método de aprendizaje conjunto mejoró la precisión de finalización y que el modelo de generación creó un conocimiento razonable. Nuestro modelo de generación también podría usarse para aumentar los datos y mejorar la precisión de la finalización.', 'ar': 'تركز هذه الدراسة على اكتساب المعرفة المنطقية. اقترحت دراسة سابقة طريقة إكمال قاعدة المعرفة المنطقية (إكمال CKB) التي تتنبأ بدرجة ثقة للمعرفة ثلاثية النمط لتحسين تغطية CKBs. لتحسين دقة إكمال CKB وتوسيع حجم CKBs ، نقوم بصياغة مهمة جديدة لتوليد قاعدة المعرفة المنطقية (إنشاء CKB) ونقترح طريقة تعلم مشتركة تتضمن إكمال CKB وتوليد CKB. تظهر النتائج التجريبية أن طريقة التعلم المشتركة حسنت دقة الإكمال وأن نموذج التوليد خلق معرفة معقولة. يمكن أيضًا استخدام نموذج الجيل الخاص بنا لزيادة البيانات وتحسين دقة الإنجاز.', 'ja': 'この研究は、常識的知識の獲得に焦点を当てている。以前の研究では、CKBのカバレッジを向上させるための三重スタイルの知識に対する信頼スコアを予測する共通知識ベース完了（ CKB完了）法が提案された。CKB完了の精度を向上させ、CKBの規模を拡大するために、新しい常識的な知識ベース生成タスク（ CKB生成）を策定し、CKB完了とCKB生成の両方を組み込んだ共同学習法を提案します。実験結果は，共同学習法が完了精度を向上させ，生成モデルが妥当な知識を生み出したことを示している．当社の生成モデルは、データの拡張や完了精度の向上にも使用できます。', 'pt': 'Este estudo se concentra na aquisição de conhecimento de senso comum. Um estudo anterior propôs um método de preenchimento de base de conhecimento de senso comum (complemento de CKB) que prevê uma pontuação de confiança para conhecimento no estilo tripleto para melhorar a cobertura de CKBs. Para melhorar a precisão da conclusão de CKB e expandir o tamanho dos CKBs, formulamos uma nova tarefa de geração de base de conhecimento de senso comum (geração de CKB) e propomos um método de aprendizado conjunto que incorpora a conclusão de CKB e a geração de CKB. Os resultados experimentais mostram que o método de aprendizado conjunto melhorou a precisão da conclusão e o modelo de geração criou um conhecimento razoável. Nosso modelo de geração também pode ser usado para aumentar os dados e melhorar a precisão da conclusão.', 'ru': 'Это исследование сосредоточено на приобретении здравого смысла. В предыдущем исследовании был предложен метод завершения базы знаний общего смысла (CKB completion), который прогнозирует балл достоверности для знаний в триплетном стиле для улучшения охвата CKB. Чтобы повысить точность завершения CKB и расширить размер CKB, мы формулируем новую задачу генерации базы знаний здравого смысла (генерация CKB) и предлагаем совместный метод обучения, который включает как завершение CKB, так и генерацию CKB. Экспериментальные результаты показывают, что метод совместного обучения улучшил точность завершения, а модель генерации создала разумные знания. Наша модель генерации также может быть использована для дополнения данных и повышения точности заканчивания.', 'hi': 'यह अध्ययन सामान्य ज्ञान के अधिग्रहण पर केंद्रित है। पिछले एक अध्ययन ने एक कॉमनसेंस नॉलेज बेस कंप्लीशन (सीकेबी पूर्णता) विधि का प्रस्ताव दिया था जो सीकेबी के कवरेज में सुधार के लिए ट्रिपल-शैली के ज्ञान के लिए आत्मविश्वास स्कोर की भविष्यवाणी करता है। सीकेबी पूरा होने की सटीकता में सुधार करने और सीकेबी के आकार का विस्तार करने के लिए, हम एक नया कॉमनसेंस नॉलेज बेस जनरेशन टास्क (सीकेबी पीढ़ी) तैयार करते हैं और एक संयुक्त सीखने की विधि का प्रस्ताव करते हैं जिसमें सीकेबी पूर्णता और सीकेबी पीढ़ी दोनों शामिल हैं। प्रयोगात्मक परिणामों से पता चलता है कि संयुक्त सीखने की विधि ने पूर्णता सटीकता में सुधार किया और पीढ़ी मॉडल ने उचित ज्ञान बनाया। हमारे पीढ़ी मॉडल का उपयोग डेटा को बढ़ाने और पूरा होने की सटीकता में सुधार करने के लिए भी किया जा सकता है।', 'zh': '本治之重,取常识性知也。 先论一常识性知识库成(CKB成)法,当占三重式知置信度分数为增CKB之覆盖率。 CKB成之准确性,广CKB之规模,制常识知识库成务(CKB成),合CKBCKB之合学。 实验结果表明,合学成精,成形造理。 吾之生成,亦可以益数而成准确性。', 'ga': 'Díríonn an staidéar seo ar shealbhú eolais chiallmhar. Mhol staidéar a rinneadh roimhe seo modh comhlánaithe bonn eolais ciallmhar (CKB) a thuar scór muiníne d’eolas ar stíl thríréid chun clúdach na CKBanna a fheabhsú. Chun cruinneas críochnú CKB a fheabhsú agus méid na CKBanna a leathnú, foirmímid tasc giniúna bonn eolais ciallmhar nua (giniúint CKB) agus molaimid modh foghlama comhpháirteach a chuimsíonn críochnú CKB agus giniúint CKB araon. Léiríonn torthaí turgnamhacha gur fheabhsaigh an modh foghlama comhpháirteach cruinneas críochnaithe agus chruthaigh an tsamhail giniúna eolas réasúnta. D’fhéadfaí ár múnla giniúna a úsáid freisin chun cur le sonraí agus chun cruinneas críochnaithe a fheabhsú.', 'hu': 'Ez a tanulmány a közérzeti ismeretek megszerzésére összpontosít. Egy korábbi tanulmány egy közértelmű tudásbázis kiegészítési módszert javasolt, amely előrejelzi a hármas stílusú ismeretek konfidencia pontszámát a CKB lefedettségének javítása érdekében. A CKB befejezés pontosságának javítása és a CKB méretének bővítése érdekében új, közértelmes tudásbázis generációs feladatot dolgozunk ki (CKB generáció), és egy közös tanulási módszert javasolunk, amely magában foglalja a CKB befejezést és CKB generációt. A kísérleti eredmények azt mutatják, hogy a közös tanulási módszer javította a teljesítés pontosságát és a generációs modell ésszerű ismereteket teremtett. A generációs modellünk az adatok növelésére és a teljesítés pontosságának javítására is használható.', 'el': 'Η μελέτη αυτή επικεντρώνεται στην απόκτηση γνώσεων κοινής λογικής. Μια προηγούμενη μελέτη πρότεινε μια μέθοδο ολοκλήρωσης της βάσης γνώσεων κοινής λογικής (συμπλήρωση CKB), η οποία προβλέπει μια βαθμολογία εμπιστοσύνης για τριπλή γνώση για τη βελτίωση της κάλυψης των CKB. Για να βελτιώσουμε την ακρίβεια της ολοκλήρωσης και να επεκτείνουμε το μέγεθος των ΚΕΒ, διαμορφώνουμε μια νέα εργασία δημιουργίας βάσεων γνώσης κοινής λογικής (γενιά ΚΕΒ) και προτείνουμε μια κοινή μέθοδο μάθησης που ενσωματώνει τόσο την ολοκλήρωση όσο και τη δημιουργία ΚΕΒ. Τα πειραματικά αποτελέσματα δείχνουν ότι η κοινή μέθοδος μάθησης βελτίωσε την ακρίβεια ολοκλήρωσης και το μοντέλο παραγωγής δημιούργησε λογική γνώση. Το μοντέλο παραγωγής μας θα μπορούσε επίσης να χρησιμοποιηθεί για να αυξήσει τα δεδομένα και να βελτιώσει την ακρίβεια της ολοκλήρωσης.', 'it': "Questo studio si concentra sull'acquisizione di conoscenze di senso comune. Uno studio precedente ha proposto un metodo di completamento della base di conoscenza comune (completamento CKB) che prevede un punteggio di confidenza per la conoscenza in stile tripletta per migliorare la copertura dei CKB. Per migliorare l'accuratezza del completamento del CKB e ampliare le dimensioni dei CKB, formuliamo un nuovo compito di generazione della base di conoscenza comune (generazione CKB) e proponiamo un metodo di apprendimento congiunto che incorpora sia il completamento del CKB che la generazione CKB. I risultati sperimentali mostrano che il metodo di apprendimento congiunto ha migliorato l'accuratezza del completamento e il modello di generazione ha creato conoscenze ragionevoli. Il nostro modello di generazione potrebbe anche essere utilizzato per aumentare i dati e migliorare l'accuratezza del completamento.", 'lt': 'Šiame tyrime daugiausia dėmesio skiriama bendrų žinių įgijimui. Ankstesniame tyrime pasiūlytas bendras nuoseklaus žinių bazės užbaigimo metodas, pagal kurį numatomas trijų rūšių žinių pasitikėjimo rodiklis siekiant pagerinti CKB aprėptį. Siekiant pagerinti CKB užbaigimo tikslumą ir išplėsti CKB dydį, parengiame naują bendrą žinių bazės kūrimo užduotį (CKB karta) ir siūlome bendrą mokymosi metodą, apimantį ir CKB užbaigimą, ir CKB kartą. Eksperimentiniai rezultatai rodo, kad bendras mokymosi metodas pagerino užbaigimo tikslumą, o gamybos modelis sukūrė pagrįstas žinias. Our generation model could also be used to augment data and improve the accuracy of completion.', 'kk': 'Бұл зерттеу көпшілік мәліметті алу үшін көпшілік береді. Алдыңғы зерттеу көпшілікті білім негізінің толтыру (CKB толтыру) әдісін ұсынды. Бұл CKB мәліметін жақсарту үшін үш стилді білім үшін сенімділік нәтижесін көрсетеді. CKB толтыру және CKB өлшемін кеңейту үшін жаңа көпшілікті білім негізгі тапсырманы (CKB құру) жасап, CKB толтыру және CKB құрылуын біріктіру әдісін қолданатын біріктіру әдісін ұсындық. Эксперименталдық нәтижелер біріктіру әдісінің толтыру дұрыстығын жақсартып, құру үлгісінің маңызды білім құрылған. Біздің құрылған моделіміз мәліметтерді көбейту үшін қолданылады және толтырудың дұрыстығын жақсарту үшін.', 'ka': 'ეს სწავლება იყენებს საზოგადოებო ცნობილების მიღებაზე. პირველი სწავლის შესახებ საერთო სტულის ცნობიერების დასრულება (CKB დასრულება) მეტი, რომელიც საერთო სტულის ცნობიერების შესახებ CKB-ის დასრულებაზე გადაუწყება. CKB დასრულება და CKB-ის ზომის გაფართება, ჩვენ განვითარებთ ახალი მეცნიერების დასრულება (CKB დასრულება) და შეგიძლიათ ერთადერთი მეცნიერება, რომელიც CKB დასრულება და CKB დასრულება. ექსპერიმენტიური წარმოდგენები ჩვენებს, რომ ერთადერთი სწავლების მეტი დასრულება წარმოდგენების წარმოდგენების წარმოდგენების მარტივის და მოდელის მოდე ჩვენი წარმოდგენის მოდელი შეიძლება გამოიყენება მონაცემებისთვის და უფრო მუშაობისთვის დასრულება.', 'mk': 'Оваа студија се фокусира на набавувањето на заедничко знаење. Претходната студија предложи заеднички метод за комплетирање на базата на знаење (ЦКБ комплетирање) кој предвидува оценка на доверба за знаење во три стили за подобрување на покривањето на ЦКБ. За да ја подобриме точноста на комплетирањето на ККБ и да ја прошириме големината на ККБ, формулираме нова заедничка задача за генерација на база на знаење (генерација ККБ) и предложиме заеднички метод на учење кој вклучува и комплетирање на ККБ и генерација КК Експерименталните резултати покажуваат дека заедничкиот метод на учење ја подобри точноста на завршувањето и моделот на генерацијата создаде разумно знаење. Our generation model could also be used to augment data and improve the accuracy of completion.', 'ms': 'Ujian ini fokus pada peningkatan pengetahuan yang sama. A previous study proposed a commonsense knowledge base completion (CKB completion) method that predicts a confidence score of for triplet-style knowledge for improving the coverage of CKBs.  To improve the accuracy of CKB completion and expand the size of CKBs, we formulate a new commonsense knowledge base generation task (CKB generation) and propose a joint learning method that incorporates both CKB completion and CKB generation.  Keputusan percubaan menunjukkan bahawa kaedah pembelajaran kongsi meningkatkan ketepatan penyelesaian dan model generasi mencipta pengetahuan yang masuk akal. Model generasi kami juga boleh digunakan untuk menambah data dan meningkatkan ketepatan pelengkapan.', 'ml': 'This study focuses on acquisition of commonsense knowledge.  മുമ്പുള്ള ഒരു പഠനത്തില്\u200d സികെബികളുടെ പൂര്\u200dത്തിയാക്കുന്ന വിശ്വാസത്തിന്റെ സ്കോര്\u200dട്ട് സ്കോര്\u200dണ്ണന്\u200dസ് അറിവുകള്\u200dക്ക് മുന്\u200dകൂട്ടുന് സികെബി പൂര്\u200dത്തിയാക്കുകയും സികെബികളുടെ വലിപ്പം വികസിപ്പിക്കുകയും ചെയ്യുന്നതിനായി നമ്മള്\u200d ഒരു പുതിയ കമോണ്\u200dസണ്\u200dസെന്\u200dസ് അറിവ് ബേസ് തലമുറയുടെ (സികെബി തലമുറയ പരീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു യൂട്ട് പഠിക്കുന്ന രീതിയില്\u200d പൂര്\u200dത്തിയാക്കുന് നമ്മുടെ തലമുറയുടെ മാതൃകയും വിവരങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കാനും പൂര്\u200dത്തിയാക്കാനും ഉപയോഗിക്കാം.', 'mt': 'Dan l-istudju jiffoka fuq l-akkwist ta’ għarfien komuni. Studju preċedenti ppropona metodu ta’ tlestija ta’ bażi ta’ għarfien komuni (tlestija ta’ CKB) li jipprevedi punteġġ ta’ kunfidenza ta’ għarfien bi stil triplet għat-titjib tal-kopertura ta’ CKBs. Sabiex tittejjeb il-preċiżjoni tat-tlestija tas-CKB u jiġi estiż id-daqs tas-CKBs, a ħna nħejju kompitu ġdid komuni ta’ ġenerazzjoni tal-bażi tal-għarfien (ġenerazzjoni tas-CKB) u nipproponu metodu konġunt ta’ tagħlim li jinkorpora kemm it-tlestija tas-CKB kif ukoll il-ġenerazzjoni tas-CKB. Ir-riżultati esperimentali juru li l-metodu konġunt ta’ tagħlim tejjeb il-preċiżjoni tat-tlestija u l-mudell ta’ ġenerazzjoni ħoloq għarfien raġonevoli. Il-mudell ta’ ġenerazzjoni tagħna jista’ jintuża wkoll biex iżid id-dejta u jtejjeb il-preċiżjoni tat-tlestija.', 'pl': 'Niniejsze opracowanie skupia się na nabywaniu wiedzy zdrowego rozsądku. W poprzednim badaniu zaproponowano metodę uzupełniania bazy wiedzy zdrowego rozsądku (CKB completion), która przewiduje wynik zaufania dla wiedzy w stylu trójkątów w celu poprawy zasięgu CKB. Aby poprawić dokładność ukończenia CKB i zwiększyć wielkość CKB, formułujemy nowe zadanie generowania bazy wiedzy zdrowego sensu (generacja CKB) i proponujemy wspólną metodę uczenia się, która obejmuje zarówno ukończenie CKB, jak i generację CKB. Wyniki eksperymentalne pokazują, że wspólna metoda uczenia się poprawiła dokładność ukończenia, a model generacji stworzył rozsądną wiedzę. Nasz model generacji może być również wykorzystywany do powiększania danych i poprawy dokładności wykonania.', 'mn': 'Энэ судалгаа ерөнхий мэдрэмжтэй мэдлэгийг авч үзэхэд анхаарна. Өмнөх судалгаа нь мэдлэг суурь дуусгах (CKB дуусгах) аргыг санал болгосон юм. Энэ нь CKB-ийн мэдээллийг сайжруулахын тулд гурван хэлбэрийн мэдлэг дээр итгэх итгэл үнэ цэнэтэй хэмжээ. CKB-ийн төгсгөлийн зөв байдлыг сайжруулахын тулд бид CKB-ын төгсгөлийн хэмжээ нэмэгдүүлэх, мэдлэг суурь үйлдвэрлэлийн ажил (CKB-ын төгсгөл) болон CKB-ын төгсгөлийн хоёр нэг нийлбэртэй суралцах арга загварыг санал бол Эмчилгээний үр дүнд хамтдаа суралцах арга нь бүтээлтийн тодорхойлолтыг сайжруулсан бөгөөд үеийн загвар нь ойлголттой мэдлэг бий болгосон. Бидний үеийн загвар мөн өгөгдлийг нэмэгдүүлж, дуусгах зөв байдлыг сайжруулахын тулд ашиглаж болно.', 'no': 'Denne studien fokuserer på henting av vanlege kunnskap. Eit tidlegare studie foreslår ein felles kunnskapsbasefullføring (CKB- fullføring) metode som foreslår eit tillit- poeng for å forstørra omdekninga av CKB i treflettstilstil. For å forbetra nøyaktighet på fullføring av CKB og utvida storleiken på CKB, formerer vi eit nytt vanleg kunnskapsbaseoppgåve (CKB-generering) og foreslår ein kopla læringsmetode som inkluderer både fullføring av CKB og generering av CKB. Eksperimentale resultat viser at den samanlige læringsmetoden forbetra fullføringsakkuratet og modellen for generering laga raskt kunnskap. Genereringsmodellen vårt kan også brukast til å auka data og forbedra nøyaktighet for fullføring.', 'ro': 'Acest studiu se concentrează pe dobândirea de cunoștințe de bun simț. Un studiu anterior a propus o metodă de completare a bazei de cunoștințe de sens comun (completarea CKB) care prezice un scor de încredere pentru cunoștințe de tip triplet pentru îmbunătățirea acoperirii CKB. Pentru a îmbunătăți acuratețea finalizării CKB și a extinde dimensiunea CKB, formulăm o nouă sarcină de generare a bazei de cunoștințe de bun sens (generația CKB) și propunem o metodă comună de învățare care încorporează atât finalizarea CKB, cât și generarea CKB. Rezultatele experimentale arată că metoda comună de învățare a îmbunătățit acuratețea finalizării, iar modelul de generație a creat cunoștințe rezonabile. Modelul nostru de generație ar putea fi, de asemenea, utilizat pentru a spori datele și pentru a îmbunătăți acuratețea finalizării.', 'sr': 'Ova studija se fokusira na usvajanje znanja zajedničkog smisla. Prethodno ispitivanje predložilo je metodu završetka baze znanja zajedničkog smisla (završetka CKB) koja predviđa rezultat povjerenja za znanje trostrukog stila za poboljšanje pokrivanja CKB-a. Da bi poboljšali tačnost završetka CKB i proširili veličinu CKB-a, formulirali smo novi zadatak generacije baze znanja (generacija CKB) i predložili zajedničku metodu učenja koja uključuje i kompletnost CKB-a i generaciju CKB-a. Eksperimentalni rezultati pokazuju da je zajednička metoda učenja poboljšala preciznost završetka i model generacije stvorio razumno znanje. Naš model generacije bi se takođe mogao koristiti za povećanje podataka i poboljšavanje tačnosti završetka.', 'so': 'This study focuses on acquisition of commonsense knowledge.  Waxbarashada hore waxaa soo jeeday dhamaystirka aasaaska aqoonta ee shirkadda (CKB dhamaystirka) oo ah qaab uu horumarinayo qoraalka aqoonta ku kalsoonaanta ee aqoonta saddex meelood loo dhigay. Si loo hagaajiyo saxda CKB dhamaystirka iyo kordhiyo tirada CKBs, waxaynu u sameynaa shaqo cusub oo ah abuurista aasaasiga aqoonta (CKB generation), waxaana horumarinaynaa qaab waxbarashada wadajir ah oo ku qoraya dhamaystirka CKB iyo CKB generation. Imtixaanka waxaa ka muuqda in qaababka iskuulka wadajirka ah uu kordhiyey saxda dhamaanka iyo tusaalaha qarniga ayaa abuuray aqoonta saqliga ah. Tusaale ahaan qarnigeena waxaa sidoo kale loo isticmaali karaa in lagu kordhiyo macluumaad iyo hagaajiyo saxda dhamaanka.', 'sv': 'Denna studie fokuserar på förvärv av allmännyttig kunskap. I en tidigare studie föreslogs en gemensam kunskapsbas komplettering (CKB komplettering) metod som förutspår en konfidenspoäng för triplet-stil kunskap för att förbättra täckningen av CKB. För att förbättra noggrannheten i CKB komplettering och utöka storleken på CKB formulerar vi en ny gemensam kunskapsbas generation uppgift (CKB generation) och föreslår en gemensam inlärningsmetod som innefattar både CKB komplettering och CKB generation. Experimentella resultat visar att den gemensamma inlärningsmetoden förbättrade fullbordandenoggrannheten och att generationsmodellen skapade rimlig kunskap. Vår generationsmodell kan också användas för att öka data och förbättra noggrannheten i slutförandet.', 'si': 'මේ පරීක්ෂණය සාමාන්\u200dය දැනගන්න පුළුවන් වෙනවා. Name CKB සම්පූර්ණය සහ CKB ප්\u200dරමාණය විස්තර කරන්න, අපි අළුත් සාමාන්\u200dය දන්න අධ්\u200dයතාවක් පරීක්ෂණය (CKB පරීක්ෂණය) ක්\u200dරියාවක් සූදානම් කරනවා සහ CKB පරීක් පරීක්ෂණාත්මක ප්\u200dරතිචාර ප්\u200dරතිචාරය පෙන්වන්නේ එක්ක ඉගෙන ගන්න ප්\u200dරතිචාරය සම්පූර්ණය සම්පූ අපේ පරීක්ෂණ මොඩල් එක්කත් පාවිච්චි කරන්න පුළුවන් දත්ත වැඩ කරන්න සහ සම්පූර්ණත්වය වැඩ කරන්න', 'ta': 'இந்த படிப்பாடு தொழில்நுட்பமான அறிவை பெறுவதை கவனம் செலுத்துகிறது. ஒரு முந்தைய ஆய்வு CKB முடிவு (CKB முடிவு) முறைமையை முன்னோட்டு அறிவிப்பு முறைமையை முடிவு செய்துள்ளது, அது CKBs மறைப்பை மேம்படுத்துவதற CKB நிறைவேற்றத்தை மேம்படுத்த மற்றும் CKB களின் அளவை விரிவாக்க, நாம் புதிய தொழில்நுட்பமான அறிவிப்பு அடிப்படை பணியை உருவாக்கி CKB உருவாக்குகிறது. CKB முடிவும சோதனை முடிவு நம் தலைமுறை மாதிரி தரவை சேர்த்து முடிவின் சரியை மேம்படுத்த முடியும்.', 'ur': 'یہ مطالعہ عام سمجھ کے علم حاصل کرنے پر تمرکز ہے۔ ایک پہلے تحقیقات نے ایک معمولی علم بنسس کامل (CKB کامل) طریقہ پیش کیا ہے جو سی کیب کی پورٹ کی عمدہ کرنے کے لئے تین طریقے کے علم کے لئے مطمئن ہونے کے لئے ایک مطمئن سی اسکور کا امتیاز ہے. CKB کامل کی دقیقیت کے لئے اور CKB کی سایز کو گھیرنے کے لئے، ہم نے ایک نئی معمولی علم base generation task (CKB generation) کو فرمول کیا ہے اور ایک جوڑی آموزش طریقہ کی پیشنهاد کریں جو CKB کامل اور CKB پیدائش میں شامل ہوتی ہے۔ تجربے کے نتائج دکھاتے ہیں کہ joint learning method improved completion accuracy اور generation model created reasonable knowledge. ہماری نسل موڈل بھی ڈیٹا اضافہ کرنے اور کامیابی کا دقیق اضافہ کرنے کے لئے استعمال کیا جاتا ہے.', 'uz': "Bu o'qituvchisi faqat ta'limni olishga foydalanadi. Oldingi o'rganishni CKB tugatishi (CKB toʻxtatish) usulini ishlatish mumkin. Bu CKBs sohasini yaxshi ko'paytirish uchun ikki marta ta'minlovchi darajani koʻrsatish mumkin. Name Tajriba natijalari ko'rsatadi, birlashtirilgan o'rganish usulini toʻxtatish imkoniyatini oshirish va avval modeli haqiqiqiy maʼlumot yaratadi. Bizning umumiy modelimiz maʼlumotni qoʻshish uchun foydalanishi mumkin va tugatish imkoniyatini oshirish mumkin.", 'vi': 'Nghiên cứu này tập trung vào việc kiếm được kiến thức phổ thông. Một nghiên cứu trước đã đề nghị một phương pháp hoàn thành căn cứ kiến thức thông thường (Việc hoàn thành CB) dự đoán được tỉ số niềm tin của các loại kiến thức kiểu ba bộ để nâng cao các ckB. Để nâng cao độ chính xác của việc hoàn thành ckB và mở rộng kích thước của các ckB, chúng tôi sẽ phát triển một nhiệm vụ sản xuất kiến thức cơ bản mới (sản xuất của ckB) và đề xuất một phương pháp học chung gồm cả việc hoàn thành và sản xuất ckB. Kết quả thí nghiệm cho thấy phương pháp học chung đã cải thiện độ chính xác hoàn hảo và mô hình tạo ra một kiến thức hợp lý. Mẫu thế hệ của chúng ta cũng có thể dùng để tăng cường dữ liệu và cải thiện độ chính xác của việc hoàn thành.', 'bg': 'Това изследване се фокусира върху придобиването на разумни знания. Предишно проучване предлага метод за завършване на базата от знания (завършване на КББ), който прогнозира доверителен скор за трикратно познание за подобряване на покритието на КББ. За да подобрим точността на завършването на КББ и да разширим размера на КББ, ние формулираме нова задача за генериране на база от знания (генериране на КББ) и предлагаме съвместен метод на обучение, който включва както завършване на КББ, така и генериране на КББ. Експерименталните резултати показват, че методът на съвместно обучение подобрява точността на завършването, а моделът на генериране създава разумни знания. Нашият модел на поколение може да се използва и за увеличаване на данните и подобряване на точността на завършването.', 'hr': 'Ova studija se fokusira na usvajanje znanja zajedničkog smisla. Prethodno ispitivanje predložilo je metodu završetka baze znanja zajedničkog smisla (završetka CKB) koja predviđa rezultat povjerenja znanja trostrukog stila za poboljšanje pokrivanja CKB-a. Da bi poboljšali preciznost završetka CKB-a i proširili veličinu CKB-a, formulirali smo novi zadatak generacije baze znanja (generacija CKB-a) i predložili zajedničku metodu učenja koja uključuje i završetka CKB-a i generaciju CKB-a. Eksperimentalni rezultati pokazuju da je zajednička metoda učenja poboljšala preciznost završetka i model generacije stvorio razumno znanje. Naš model generacije može se također koristiti za povećanje podataka i poboljšavanje preciznosti završetka.', 'nl': "Deze studie richt zich op het verwerven van gezond verstand kennis. Een eerder onderzoek stelde een methode voor voor het voltooien van de Commonsense Knowledge Base (CKB completion) die een vertrouwensscore voorspelt voor triplet-stijl kennis om de dekking van CKB's te verbeteren. Om de nauwkeurigheid van CKB voltooiing te verbeteren en de grootte van CKB's uit te breiden, formuleren we een nieuwe commonsense kennisbasis generatie taak (CKB generatie) en stellen we een gezamenlijke leermethode voor die zowel CKB voltooiing als CKB generatie omvat. Experimentele resultaten tonen aan dat de gezamenlijke leermethode de voltooiingsnauwkeurigheid verbeterde en het generatiemodel redelijke kennis creëerde. Ons generatiemodel kan ook worden gebruikt om gegevens te verbeteren en de nauwkeurigheid van de voltooiing te verbeteren.", 'da': 'Dette studie fokuserer på erhvervelse af almindelig viden. En tidligere undersøgelse foreslog en almindelig vidensbase fuldførelse (CKB fuldførelse) metode, der forudsiger en konfidensscore på for triplet-stil viden til forbedring af dækningen af CKB. For at forbedre nøjagtigheden af CKB færdiggørelse og udvide størrelsen af CKB formulerer vi en ny almindelig vidensbase generationsopgave (CKB generation) og foreslår en fælles læringsmetode, der omfatter både CKB færdiggørelse og CKB generation. Eksperimentelle resultater viser, at den fælles læringsmetode forbedrede fuldførelsesnøjagtigheden og genereringsmodellen skabte rimelig viden. Vores generationsmodel kunne også bruges til at øge data og forbedre nøjagtigheden af færdiggørelsen.', 'id': 'Studi ini fokus pada pengakuan pengetahuan umum. A previous study proposed a commonsense knowledge base completion (CKB completion) method that predicts a confidence score of for triplet-style knowledge for improving the coverage of CKBs.  Untuk meningkatkan akurasi penyelesaian CKB dan memperluas ukuran CKB, kami menyiformulasi tugas generasi pangkalan pengetahuan (generasi CKB) yang baru dan mengusulkan metode pembelajaran kongsi yang mengangkut penyelesaian CKB dan generasi CKB. Hasil eksperimen menunjukkan bahwa metode belajar kongsi meningkatkan akurasi penyelesaian dan model generasi menciptakan pengetahuan yang masuk akal. Model generasi kita juga dapat digunakan untuk meningkatkan data dan meningkatkan akurasi penyelesaian.', 'de': 'Diese Studie konzentriert sich auf den Erwerb von gesundem Wissen. Eine frühere Studie schlug eine Commonsense Knowledge Base Completion (CKB Completion) Methode vor, die einen Konfidenzscore für Triplet-Style Wissen vorhersagt, um die Abdeckung von CKB zu verbessern. Um die Genauigkeit der CKB-Vervollständigung zu verbessern und die Größe der CKBs zu erweitern, formulieren wir eine neue Commonsense-Wissensdatenbank-Generierungsaufgabe (CKB-Generation) und schlagen eine gemeinsame Lernmethode vor, die sowohl die CKB-Vervollständigung als auch die CKB-Generierung umfasst. Experimentelle Ergebnisse zeigen, dass die gemeinsame Lernmethode die Abschlussgenauigkeit verbesserte und das Generierungsmodell sinnvolles Wissen erzeugte. Unser Generierungsmodell könnte auch verwendet werden, um Daten zu erweitern und die Genauigkeit der Fertigstellung zu verbessern.', 'ko': '본 연구는 상식 지식의 획득에 중심을 두었다.앞서 한 연구는 삼중태 지식의 신뢰도를 예측해 CKB의 커버율을 높일 수 있는 상식적 지식라이브러리 완성(CKB completion) 방법을 제시했다.CKB 완성의 정확성을 높이고 CKB의 규모를 확장하기 위해 우리는 새로운 상식지식고 생성 임무(CKB 생성)를 제시했고 CKB 완성과 CKB 생성을 결합한 공동 학습 방법을 제시했다.실험 결과에 따르면 연합 학습 방법은 완성 정밀도를 높였고 생성 모델은 합리적인 지식을 생성했다.우리의 생성 모델은 데이터를 확충하고 완성의 정확성을 높이는 데도 쓰일 수 있다.', 'sw': 'Utafiti huu unajikita kupata maarifa ya biashara. Utafiti uliopita ulipendekeza ufumbuzi wa msingi wa maarifa ya umma (CKB Completion) njia ambayo inatabiri score ya imani kwa ufahamu wa mitatu kwa kuboresha habari za CKBs. Ili kuongeza uhakika wa kamili ya CKB na kuongeza ukubwa wa CKBs, tunatengeneza kazi mpya ya uzalishaji wa maarifa ya umma (kizazi cha CKB) na pendekeza njia ya kujifunza pamoja inayojumuisha kamili ya CKB na kizazi cha CKB. Matokeo ya majaribio yanaonyesha kuwa mbinu ya kujifunza pamoja iliboresha uhakika wa kuuliza na mtindo wa kizazi umetengeneza maarifa sahihi. Mfano wetu wa kizazi pia unaweza kutumika kuongeza taarifa na kuboresha uhakika wa kuumiza.', 'fa': 'این مطالعه روی دریافت دانش معمولی تمرکز می\u200cکند. یک مطالعه قبلی پیشنهاد داد یک روش کامل کردن بنیاد علم معمولی (کامل CKB) که یک امتیاز اطمینان برای دانش\u200cهای سبک سه\u200cگانه برای improving coverage of CKB را پیش\u200cبینی می\u200cکند. برای تدبیر دقیق کامل CKB و اندازه CKB را گسترش دهیم، ما یک کار جدید نسل معنی علم (نسل CKB) را فرمول می\u200cکنیم و یک روش آموزش مشترک پیشنهاد می\u200cکنیم که هر دو نسل کامل CKB و CKB را شامل می\u200cکند. نتیجه\u200cهای تجربه نشان می\u200cدهد که روش یادگیری مشترک دقیق کامل را بهتر کرد و مدل نسل دانش منطقی را ایجاد کرد. مدل نسل ما هم می\u200cتواند برای افزایش داده\u200cها استفاده شود و دقیق کامل را بهبود دهد.', 'tr': 'Bu araşdyrma umumy duýdury bilgi almaga odaklanýar. Öňki araşdyrma, umumy bilgi bazynyň tamamlamasyny (KKB tamamlamasyny) täze bir nusgasyny üçin 3-ýoly bilim üçin güýçli bilimi täzelleýär. CKB tamamlamanyň dogrudylygyny geliştirmek we CKB tamamlamanyň ölçüsini öňdirmek üçin, biz nusgala bilgi bazy döretmek täblisini (CKB döretmek üçin) we bellenen bir öwrenmek täblisini hem CKB tamamlamanyň we CKB döretmegini dahil etmek üçin teklip edýäris. Aramanyň netijeleri bilen birleşik öwrenmek yönteminiň tamamlama dogrudylygyny we döwlet nusgasyny ukyply bilgi ýüze çykardygyny görkezýär. Biziñ döwletimiz nusgasymyz hem maglumatlary geliştirmek we tamamlamanyň dogrylygyny geliştirmek üçin ulanylyp bilerdi.', 'af': "Hierdie studie fokus op die verskaffing van gemeenskaplike kennis. Name Om die presies van Ckb voltooiing te verbeter en die grootte van Ckbs te uitbrei, formuleer ons 'n nuwe gemeenskaplike kennis basis generasie taak (Ckb generasie) en voorstel 'n joint leermeetode wat beide Ckb voltooiing en Ckb generasie inkorpreer. Eksperimentale resultate wys dat die joint leer metode verbeter volledige presisie en die generasiemodel het redelike kennis geskep. Ons generasie model kon ook gebruik word om data te vergroot en die presisie van voltooiing te verbeter.", 'sq': 'Ky studim përqëndrohet në fitimin e njohurive të zakonshme. Një studim i mëparshëm propozoi një metodë kompletimi të bazës së njohurive të përbashkët (kompletimi i CKB) që parashikon një pikë besimi për njohuritë e stilit të trefishtë për përmirësimin e mbulimit të CKB-ve. Për të përmirësuar saktësinë e kompletimit të CKB-së dhe zgjeruar madhësinë e CKB-ve, ne formojmë një detyrë të re të përbashkët të gjenerimit të bazës së njohurive (gjenerata CKB-së) dhe propozojmë një metodë të përbashkët mësimi që përfshin si kompletimin e CKB-së dhe gjeneratën CKB-së. Rezultatet eksperimentale tregojnë se metoda e përbashkët e mësimit përmirësoi saktësinë e përfundimit dhe modeli i gjeneratës krijoi njohuri të arsyeshme. Modeli ynë i gjeneratës mund të përdoret gjithashtu për të rritur të dhënat dhe për të përmirësuar saktësinë e përfundimit.', 'am': 'ይህ ትምህርት የድጋፍ እውቀትን ለማግኘት ነው፡፡ የቀድሞው ትምህርት የCKB መደምደሚያ (CKB መደምደሚያ) ሥርዓት ለCKBs ክፍተትን ለማሻሻል የሦስት በጥቅረት እውቀት የሚታመን የድምፅ እውቀትን ለመጠየቅ ያሳያል፡፡ የCKB ፍጻሜውን ለማሻሻል የCKBs መጠን ለማስፋት አዲስ የካምፓኒስ እውቀት መቀመጫን (CKB ትውልድ) እና CKB ፍጻሜ እና CKB ትውልድ እና ትክክለኛውን ለመማር ጥረት እና ለCKB ትውልድ መግለጫ እና መግለጫ እናደርጋለን፡፡ ፈተና ውጤቶች የተጠቃሚ ትምህርት ማድረግ ማድረግ ትክክልን ማድረግ እና ትውልድ ምሳሌ አስተዋይ እውቀትን መፍጠር ነው፡፡ ትውልዳችን ሞዴል ዳታዎችን ለመጨመር እና ማስረጃውን ለመሻል ይችላል፡፡', 'hy': 'Այս ուսումնասիրությունը կենտրոնանում է ընդհանուր գիտելիքների ձեռք բերման վրա: Անցյալ ուսումնասիրությունը առաջարկեց ընդհանուր գիտելիքի հիմքի ավարտելու (CKB ավարտելու) մեթոդ, որը կանխատեսում է CKB-ի ծավալը բարելավելու համար տրամաբանական գիտելիքների եռաչափ ոճի վստահության գնահատականը: Որպեսզի բարելավենք CKB-ի կատարման ճշգրիտությունը և ընդլայնենք CKB-ի չափսերը, մենք ձևավորում ենք նոր ընդհանուր գիտելիքի հիմքի ստեղծման առաջադրանք (CKB-ի սերունդ) և առաջարկում ենք մի միասին ուսուցման մեթոդ, որը ներառում է CKB-ի կատար Փորձարկման արդյունքները ցույց են տալիս, որ ընդհանուր ուսուցման մեթոդը բարելավեց ավարտական ճշգրտությունը, իսկ սերնդի մոդելը ստեղծեց խելամիտ գիտելիք: Մեր սերնդի մոդելը կարող է նաև օգտագործվել տվյալների աճի և կատարման ճշգրիտության բարելավման համար:', 'az': 'Bu təhsil çox hiss elmi almaqda odaqlanır. Əvvəlki təhsil təhsil etdi, CKB-lərin gizlənməsini yaxşılaşdırmaq üçün üç türlü bilgi üçün güvenilir nöqtəsini təmin edir. CKB tamamlama və CKB böyüklüyünü genişləmək üçün yeni sıradan bilgi bazı nəsil işini (CKB nəsili) formüləyirik və CKB tamamlama və CKB nəsili ilə birləşdirən bir öyrənmə metodu təklif edirik. Müvəffəqiyyət sonuçları birlikdə öyrənmə metodunun tamamlama tamamlama doğruluğunu və nəsil modelinin razıllıq bilgi yaratdığını göstərir. Növbətimiz modeli də məlumatları artırmaq və tamamlamaq üçün istifadə edilə bilər.', 'ca': "Aquest estudi es centra en l'adquisició de coneixements comuns. Un estudi anterior va proposar un mètode comú de completació de la base de coneixements (completació de CKB) que prediu una puntuació de confiança del coneixement d'estil triplet per millorar la cobertura de CKB. Per millorar la precisió de la completació de CKB i ampliar la mida de CKB, formulem una nova tasca comú de generació de bases de coneixement (generació de CKB) i proposem un mètode d'aprenentatge comú que incorpore tant la completació de CKB com la generació de CKB. Els resultats experimentals mostren que el mètode d'aprenentatge conjunt va millorar la precisió de la completació i el model de generació va crear coneixements raonables. El nostre model de generació també podria ser utilitzat per augmentar les dades i millorar la precisió de la completació.", 'bs': 'Ova studija se fokusira na usvajanje znanja zajedničkog smisla. Prethodno ispitivanje predložilo je metodu završetka baze znanja zajedničkog smisla (završetka CKB) koja predviđa rezultat povjerenja znanja trostrukog stila za poboljšanje pokrivanja CKB-a. Da bi poboljšali preciznost završetka CKB-a i proširili veličinu CKB-a, formulirali smo novi zadatak generacije baze znanja (generacija CKB-a) i predložili zajedničku metodu učenja koja uključuje i završetka CKB-a i generaciju CKB-a. Eksperimentalni rezultati pokazuju da je zajednička metoda učenja poboljšala preciznost završetka i model generacije stvorio razumno znanje. Naš model generacije bi se također mogao koristiti za povećanje podataka i poboljšavanje preciznosti završetka.', 'bn': 'এই গবেষণা কমিউনিসেন্সের জ্ঞান নিয়ে মনোযোগ প্রদান করে। পূর্ববর্তী গবেষণা একটি কমিউনিসেন্সেন্সের জ্ঞানের বেস সম্পূর্ণ (সিকেবি সম্পূর্ণ) পদ্ধতি প্রস্তাব করেছে যা সিকেবিসের কাভারেজ উন্নতির জন্য সিকেবি সম্পূর্ণ এবং সিকেবির আকার বৃদ্ধি করার জন্য আমরা একটি নতুন কমিউনেন্সেন্সের জ্ঞান বেস প্রজন্ম (সিকেবি প্রজন্ম) কাজ তৈরি করি এবং একটি যৌথ শিক্ষার পদ্ধতি প্রস্তাব করি  পরীক্ষার ফলাফল দেখাচ্ছে যে যৌথ শিক্ষার পদ্ধতি সম্পূর্ণ সঠিকভাবে উন্নত করেছে এবং প্রজন্মের মডেল যুক্ত জ্ঞান তৈ আমাদের প্রজন্মের মডেল ব্যবহার করা যাবে তথ্য যোগ করতে এবং সম্পূর্ণ সঠিকভাবে উন্নত করতে।', 'cs': 'Tato studie se zaměřuje na získávání znalostí zdravého rozumu. V předchozí studii byla navržena metoda doplňování zdravého rozumu znalostní báze (CKB completion), která předpovídá skóre důvěry pro trojité znalosti pro zlepšení pokrytí CKB. Pro zlepšení přesnosti dokončení CKB a rozšíření velikosti CKB formulujeme nový úkol generování zdravého rozumu znalostní báze (generace CKB) a navrhujeme společnou metodu učení, která zahrnuje jak dokončení CKB, tak generování CKB. Experimentální výsledky ukazují, že metoda společného učení zlepšila přesnost dokončení a generační model vytvořil přiměřené znalosti. Náš generační model by mohl být také použit k rozšíření dat a zlepšení přesnosti dokončení.', 'et': 'Käesolev uuring keskendub mõistlike teadmiste omandamisele. Varasemas uuringus pakuti välja üldise mõttega teadmistebaasi lõpetamise meetod (CKB lõpetamine), mis prognoosib kolmekordse stiiliga teadmiste usaldusskoori, et parandada CKB katvust. CKB lõpetamise täpsuse parandamiseks ja CKB suuruse laiendamiseks sõnastame uue üldise mõistuse teadmistebaasi genereerimise ülesande (CKB generatsioon) ja pakume välja ühise õppemeetodi, mis hõlmab nii CKB lõpetamist kui ka CKB generatsiooni. Eksperimentaalsed tulemused näitavad, et ühisõppemeetod parandas lõpetamise täpsust ja generatsioonimudeliga loodi mõistlikud teadmised. Meie põlvkonna mudelit saab kasutada ka andmete täiendamiseks ja valmimise täpsuse parandamiseks.', 'fi': 'Tässä tutkimuksessa keskitytään järkevän tiedon hankkimiseen. Aiemmassa tutkimuksessa ehdotettiin yleistä tietopohjan täydentämistä (CKB-täydennys), joka ennustaa kolminkertaisen tietämyksen luottamuspisteen CKB-tautien kattavuuden parantamiseksi. Parantaaksemme CKB:n suorittamisen tarkkuutta ja laajentaaksemme CKB:n kokoa laadimme uuden yleisen järkevyyden tietopohjan luomisen tehtävän (CKB-sukupolvi) ja ehdotamme yhteistä oppimismenetelmää, joka sisältää sekä CKB:n suorittamisen että CKB:n tuottamisen. Kokeelliset tulokset osoittavat, että yhteinen oppimismenetelmä paransi suoritustarkkuutta ja sukupolvimalli loi kohtuullista tietoa. Tuotantomalliamme voitaisiin käyttää myös tiedon lisäämiseen ja viimeistelyn tarkkuuden parantamiseen.', 'sk': 'Ta študija se osredotoča na pridobivanje dobrega smisla znanja. V prejšnji študiji je bila predlagana metoda dokončanja baze znanja (dokončanje CKB), ki napoveduje oceno zaupanja za trikratno znanje za izboljšanje pokritosti CKB. Za izboljšanje natančnosti dokončanja CKB in razširitev velikosti CKB smo oblikovali novo nalogo generacije baze znanja (generacija CKB) in predlagali skupno metodo učenja, ki vključuje dokončanje CKB in generacijo CKB. Eksperimentalni rezultati kažejo, da je metoda skupnega učenja izboljšala natančnost dokončanja, generacijski model pa ustvaril razumno znanje. Naš generacijski model se lahko uporablja tudi za povečanje podatkov in izboljšanje natančnosti dokončanja.', 'he': 'המחקר הזה מתמקד ברכישת ידע משמעותי. מחקר קודם הציע שיטת השלמת בסיס ידע משמעותי (סיום CKB) שמחזיקה נקודת אמון של ידע בסגנון שלושה לשיפור הכיסוי של CKB. כדי לשפר את מדויקת השלמות של CKB ולהרחיב את הגודל של CKB, אנו מתייצבים משימה חדשה של מיוצר בסיס ידע (דור CKB) ומציע שיטת לימוד משותפת שמכילה גם השלמות של CKB וגם דור CKB. תוצאות ניסויים מראות ששיטת הלימוד המשותפת השתפרה בדיקת השלמות והדוגמן הדור יצר ידע סביר. דוגמנית הדור שלנו יכולה להשתמש גם כדי לגדל נתונים ולשיפר את מדויקת השלים.', 'ha': "Wannan littafin yana muhimmin da za'a sami wani ilmi na wajen aiki. Wata fitina na farko ya bububuɗe wani cikakken baza saniya (CKB cikakken) metode wanda ya yi bashirin wata sifar da aminci wa fassarar-sali uku-dufu wa ya kyautata rufaffiyar CKBs. To, domin improve tsarin cikakken CKB kuma za'a faɗa ɗa girma na CKBs, za'a ƙayyade wani zance na danne na danne na danne da ilmi (CKB-danne) kuma Mu goyyar da shirin laƙin da za'a haɗa ta komai da cikakken CKB da kuma za'a ƙara CKB. Matarin jarrabawa na nuna cewa metoden da za'a ƙara shirin lõkaci na samar da cikakken tsari da kuma motel na samu'ar da ya sami ilmi mai inganci. Ana iya amfani da misalin kizayenmu dõmin a ƙara data kuma ya kyautata tsarin cikakken.", 'jv': 'Genjer-ingkang iki dipun macem kuwi nggawe kesempatan pangan. Name Genjer-genjer saiki nggawe aturan CK soale nggawe aturan CK lan tambah nggawe kamu nggawe sistem sing nyimpen podho nggawe saben nggawe sistem saé nesaturan tapi nggawe task (CK Generation) lan jewise sistem sing wis japanjuré nggawe nguasai sistem sing dumadhakan CK soale nggawe Ketok lan CK Generation . Laptop" and "Desktop Genjer-genjer model sing wis digawe iso nggambar nggawe dadi, ngono iso nggawe barang-barang kanggo mulai.', 'bo': 'ལྟ་བ་འདིས་མཐོང་ཐབས་ཤེས་ཡོད་པའི་ཆ་རྐྱེན་གྱི་སྐོར་ལ་དམིགས་བསལ་བྱེད་ཀྱི་ཡོད། སྔོན་གྱི་ལྟ་བ་ཞིག་གིས་མཐུན་རྒྱུན་ལྡན་གྱི་གནས་ཚུལ་གཞི་རྗེས་སྟངས་ཀྱི་ཐབས་ལམ་སྟོན་འདུག། CKB མཇུག་གི་བདེ་འཇགས་དང་ཞེང་ཚད་CKBs ་གི་ཆེ་ཆུང་དུ་ཡར་རྒྱས་གཏོང་དགོས། ང་ཚོས་ཀྱིས་མཐུན་འཐབ་པའི་ཤེས་ཡུལ་base generation task (CKB generation)དང་མཉམ་དུ་བསྡུས་པའི་ཐབས་ལམ་ཞིག Experimental results show that the joint learning method improved completion accuracy and the generation model created reasonable knowledge. ང་ཚོའི་མི་འབྲུག་གི་མ་དབུགས་དེ་ལས་ཀྱང་ཆེ་རུ་སྐྱེད་པའི་ཆ་འཕྲིན་ཡིག་ཆ་དང་མཇུག་རྫས་ལ་བདེ་སྐྱོང་'}
{'en': 'Active Learning for Interactive Neural Machine Translation of Data Streams', 'ar': 'التعلم النشط للترجمة الآلية العصبية التفاعلية لتدفقات البيانات', 'fr': 'Apprentissage actif pour la traduction automatique neuronale interactive de flux de données', 'pt': 'Aprendizado ativo para tradução automática neural interativa de fluxos de dados', 'es': 'Aprendizaje activo para la traducción automática neuronal interactiva de flujos de datos', 'ja': 'データストリームの対話型ニューラルマシン翻訳のためのアクティブラーニング', 'zh': '数据流之交互式神经机器翻译者自学', 'hi': 'इंटरैक्टिव न्यूरल मशीन डेटा स्ट्रीम के अनुवाद के लिए सक्रिय सीखना', 'ru': 'Активное обучение интерактивному нейронному машинному переводу потоков данных', 'ga': 'Foghlaim Ghníomhach le haghaidh Aistriú Inneall Néarach Idirghníomhach ar Shruthanna Sonraí', 'ka': 'Name', 'el': 'Ενεργή μάθηση για τη διαδραστική νευρωνική μηχανική μετάφραση ροών δεδομένων', 'hu': 'Aktív tanulás az adatfolyamok interaktív neurális gépi fordításához', 'it': 'Apprendimento attivo per la traduzione automatica neurale interattiva dei flussi di dati', 'kk': 'Деректер көздерінің интерактивті невралдық машинаның аудармасының белсенді үйрену', 'lt': 'Aktyvus mokymasis interaktyviai nervinių mašinų duomenų srautų vertimui', 'ml': 'Name', 'mt': 'Active Learning for Interactive Neural Machine Translation of Data Streams', 'mk': 'Активно учење за интерактивно превод на неврални машини на податоци', 'ms': 'Pembelajaran Aktif untuk Terjemahan Mesin Neural Interaktif Streams Data', 'no': 'Aktivt læring for interaktiv neuralmaskinsomsetjing av datastrømmer', 'mn': 'Өгөгдлийн урсгалын интерактив мэдрэлийн машин хөгжүүлэх үйлдэл', 'sr': 'Aktivno učenje za interaktivno neurološki prevod struja podataka', 'si': 'Name', 'ro': 'Învățare activă pentru traducerea automată neurală interactivă a fluxurilor de date', 'pl': 'Aktywne uczenie się dla interaktywnego neuronalnego tłumaczenia maszynowego strumienia danych', 'so': 'Wax Active Learning for Interactive Neural machine Translation of Data Streams', 'sv': 'Aktivt lärande för interaktiv neural maskinöversättning av dataströmmar', 'ta': 'தகவல் மொழிபெயர்ப்புகளின் உள்ளடக்க நெருக்கி இயந்திர மொழிபெயர்ப்புக்கான கற்றுக்கொடுப்பு', 'ur': 'ڈاٹا سیٹریم کے مطابقت نیورال ماشین ترجمہ کے لئے فعال سیکھنا', 'uz': 'Tarjima qilish vositasiName', 'vi': 'Học hành cho máy thần kinh tương tác dịch luồng dữ liệu', 'nl': 'Actief leren voor interactieve neurale machinevertaling van datastromen', 'hr': 'Aktivno učenje za interaktivno neurološki prevod struja podataka', 'bg': 'Активно обучение за интерактивен неврален машинен превод на потоци от данни', 'da': 'Aktiv læring til interaktiv neural maskinoversættelse af datastrømme', 'de': 'Aktives Lernen für die interaktive neuronale maschinelle Übersetzung von Datenströmen', 'id': 'Active Learning for Interactive Neural Machine Translation of Data Streams', 'ko': '데이터 흐름 상호작용 신경 기계 번역의 능동 학습', 'fa': 'یادگیری فعال برای ترجمه ماشین عصبی مصاحبه از استرام داده\u200cها', 'tr': 'Veri Streamlaryň Interaktiv Näraly Maşynyň terjime edilmesi üçin janlaşdyr öwrenmek', 'sw': 'Tafsiri ya Mitari ya Data', 'sq': 'Mësimi aktiv për Trakthimin Interaktiv të Stromave të të dhënave nga Makina Neurale', 'af': 'Aktiewe leer vir Interaktiewe Neurale Masjien Vertaling van Data Streams', 'am': 'ትርጉም', 'hy': 'Տեղեկատվական հոսքերի ինտերակտիվ նեյրոնային մեքենայի թարգմանման ակտիվ սովորելը', 'az': 'Veri Streamların Interaktiv Nöral Makinesi Çeviri üçün Etkinlik Öyrənmə', 'bn': 'Name', 'ca': 'Aprendiment actiu per a la traducció interactiva de fluxos de dades', 'cs': 'Aktivní učení pro interaktivní neuronový strojový překlad datových toků', 'et': 'Aktiivne õpe andmevoogude interaktiivseks neuraalseks masintõlkeks', 'bs': 'Aktivno učenje za interaktivno neurološki prevod struja podataka', 'fi': 'Aktiivinen oppiminen tietovirtojen interaktiiviseen neurokääntämiseen', 'jv': 'Aksi Ngerti kanggo Tulungan interactive Neral Masine Terjamahan ng data Striams', 'ha': '@ action', 'he': 'Active Learning for Interactive Neural Machine Translation of Data Streams', 'sk': 'Aktivno učenje za interaktivno nevralno strojno prevajanje podatkovnih tokov', 'bo': 'Interactive Neural Machine Translation of Data Streams for Active Learning for Interactive Learning'}
{'en': 'We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation. The main idea is to select, from an unbounded stream of source sentences, those worth to be supervised by a human agent. The user will interactively translate those samples. Once validated, these ', 'ar': 'ندرس تطبيق تقنيات التعلم النشط على ترجمة تدفقات البيانات غير المحدودة عبر الترجمة الآلية العصبية التفاعلية. الفكرة الرئيسية هي أن تختار ، من دفق غير محدود من الجمل المصدر ، تلك التي تستحق أن يشرف عليها عامل بشري. سيقوم المستخدم بترجمة هذه العينات بشكل تفاعلي. بمجرد التحقق من صحة هذه البيانات ، تكون مفيدة لتكييف نموذج الترجمة الآلية العصبية. نقترح طريقتين جديدتين لاختيار العينات التي سيتم التحقق من صحتها. نحن نستغل المعلومات من آلية الانتباه لنظام الترجمة الآلية العصبية. تُظهر تجاربنا أن إدراج تقنيات التعلم النشط في خط الأنابيب هذا يسمح بتقليل الجهد المطلوب أثناء العملية ، مع زيادة جودة نظام الترجمة. علاوة على ذلك ، فهي تمكن من تحقيق التوازن بين الجهد البشري المطلوب لتحقيق جودة ترجمة معينة. علاوة على ذلك ، يتفوق نظامنا العصبي على الأساليب الكلاسيكية بهامش كبير.', 'pt': 'Estudamos a aplicação de técnicas de aprendizado ativo para a tradução de fluxos de dados ilimitados por meio de tradução automática neural interativa. A ideia principal é selecionar, de um fluxo ilimitado de sentenças fonte, aquelas que valem a pena serem supervisionadas por um agente humano. O usuário traduzirá interativamente essas amostras. Uma vez validados, esses dados são úteis para adaptar o modelo de tradução automática neural. Propomos dois novos métodos para selecionar as amostras a serem validadas. Exploramos as informações do mecanismo de atenção de um sistema de tradução automática neural. Nossos experimentos mostram que a inclusão de técnicas de aprendizado ativo nesse pipeline permite reduzir o esforço necessário durante o processo, ao mesmo tempo em que aumenta a qualidade do sistema de tradução. Além disso, permite equilibrar o esforço humano necessário para alcançar uma determinada qualidade de tradução. Além disso, nosso sistema neural supera as abordagens clássicas por uma grande margem.', 'fr': "Nous étudions l'application de techniques d'apprentissage actif à la traduction de flux de données illimités via la traduction automatique neuronale interactive. L'idée principale est de sélectionner, parmi un flot illimité de phrases sources, celles qui méritent d'être supervisées par un agent humain. L'utilisateur traduira ces échantillons de manière interactive. Une fois validées, ces données sont utiles pour adapter le modèle de traduction automatique neuronale. Nous proposons deux nouvelles méthodes pour sélectionner les échantillons à valider. Nous exploitons les informations provenant du mécanisme d'attention d'un système de traduction automatique neuronale. Nos expériences montrent que l'inclusion de techniques d'apprentissage actif dans ce pipeline permet de réduire les efforts nécessaires au cours du processus, tout en augmentant la qualité du système de traduction. De plus, il permet d'équilibrer les efforts humains nécessaires pour atteindre une certaine qualité de traduction. De plus, notre système neuronal surpasse largement les approches classiques.", 'es': 'Estudiamos la aplicación de técnicas de aprendizaje activo a la traducción de flujos de datos ilimitados a través de la traducción automática neuronal interactiva. La idea principal es seleccionar, de un flujo ilimitado de oraciones fuente, aquellas que valgan la pena ser supervisadas por un agente humano. El usuario traducirá de forma interactiva esas muestras. Una vez validados, estos datos son útiles para adaptar el modelo de traducción automática neuronal. Proponemos dos métodos novedosos para seleccionar las muestras que se van a validar. Aprovechamos la información del mecanismo de atención de un sistema de traducción automática neuronal. Nuestros experimentos muestran que la inclusión de técnicas de aprendizaje activo en este proceso permite reducir el esfuerzo necesario durante el proceso, al tiempo que aumenta la calidad del sistema de traducción. Además, permite equilibrar el esfuerzo humano necesario para lograr una determinada calidad de traducción. Además, nuestro sistema neuronal supera ampliamente a los enfoques clásicos.', 'ja': '私たちは、対話型ニューラル機械翻訳を介した無制限のデータストリームの翻訳へのアクティブラーニング技術の適用を研究しています。主なアイデアは、ソース文の無制限のストリームから、人間のエージェントが監督する価値のあるものを選択することです。ユーザーはこれらのサンプルをインタラクティブに翻訳します。検証されると、これらのデータは、ニューラル機械翻訳モデルを適応させるのに有用である。検証するサンプルを選択するための2つの新規の方法を提案します。神経機械翻訳システムの注意メカニズムから情報を活用しています。私たちの実験は、このパイプラインにアクティブラーニング技術を含めることで、翻訳システムの品質を向上させながら、プロセス中に必要な労力を削減できることを示しています。さらに、特定の翻訳品質を達成するために必要な人間の努力のバランスを取ることができます。さらに、私たちの神経系は、古典的なアプローチを大幅に上回っています。', 'hi': 'हम इंटरैक्टिव न्यूरल मशीन अनुवाद के माध्यम से असीमित डेटा धाराओं के अनुवाद के लिए सक्रिय सीखने की तकनीकों के आवेदन का अध्ययन करते हैं। मुख्य विचार का चयन करना है, स्रोत वाक्यों की एक असीम धारा से, जो मानव एजेंट द्वारा पर्यवेक्षण किए जाने के लायक हैं। उपयोगकर्ता इंटरैक्टिव रूप से उन नमूनों का अनुवाद करेगा। एक बार मान्य होने के बाद, ये डेटा तंत्रिका मशीन अनुवाद मॉडल को अनुकूलित करने के लिए उपयोगी है। हम सत्यापित किए जाने वाले नमूनों का चयन करने के लिए दो उपन्यास विधियों का प्रस्ताव करते हैं। हम एक तंत्रिका मशीन अनुवाद प्रणाली के ध्यान तंत्र से जानकारी का दोहन करते हैं। हमारे प्रयोगों से पता चलता है कि इस पाइपलाइन में सक्रिय सीखने की तकनीकों को शामिल करने से प्रक्रिया के दौरान आवश्यक प्रयास को कम करने की अनुमति मिलती है, जबकि अनुवाद प्रणाली की गुणवत्ता में वृद्धि होती है। इसके अलावा, यह एक निश्चित अनुवाद गुणवत्ता प्राप्त करने के लिए आवश्यक मानव प्रयास को संतुलित करने में सक्षम बनाता है। इसके अलावा, हमारी तंत्रिका प्रणाली एक बड़े मार्जिन से शास्त्रीय दृष्टिकोण ों को मात देती है।', 'zh': '吾等究其学术,于交互式神经机器翻译译无界数流中应用。 大抵心从无限源流中择其可代者。 用户将以交互方式译示例。 一旦得验,其于应神经机器翻译甚有用。 二新之法,以验其样品。 用自神经机器翻译系统注意机制。 吾实验明入管道可减事力,重译系统之量。 此外,平行必译人力也。 此外,吾神经系统优于经术。', 'ru': 'Мы изучаем применение методов активного обучения к переводу неограниченных потоков данных с помощью интерактивного нейронного машинного перевода. Основная идея состоит в том, чтобы выбрать из неограниченного потока исходных предложений тех, за которыми стоит наблюдать человеческий агент. Пользователь будет переводить эти образцы в интерактивном режиме. После проверки эти данные полезны для адаптации модели нейронного машинного перевода. Мы предлагаем два новых метода отбора образцов для валидации. Мы используем информацию из механизма внимания нейронной системы машинного перевода. Наши эксперименты показывают, что включение в этот конвейер активных методов обучения позволяет сократить усилия, необходимые в процессе, при одновременном повышении качества системы перевода. Кроме того, это позволяет сбалансировать человеческие усилия, необходимые для достижения определенного качества перевода. Более того, наша нейронная система значительно превосходит классические подходы.', 'ga': 'Déanaimid staidéar ar fheidhmiú teicnící gníomhacha foghlama le haistriú sruthanna sonraí gan teorainn trí mheaisínaistriúchán idirghníomhach néareolaíoch. Is é an príomh-smaoineamh ná na cinn ar fiú iad a bheith maoirsithe ag gníomhaire daonna a roghnú as sruth abairtí foinse gan teorainn. Déanfaidh an t-úsáideoir na samplaí sin a aistriú go hidirghníomhach. Nuair a bhíonn siad bailíochtaithe, beidh na sonraí seo úsáideach chun an tsamhail néaraistriúcháin meaisín a oiriúnú. Molaimid dhá mhodh nua chun na samplaí atá le bailíochtú a roghnú. Bainimid leas as an bhfaisnéis ó mheicníocht aire chórais néar-aistriúcháin meaisín. Léiríonn ár dturgnaimh go gceadaíonn cuimsiú teicnící gníomhacha foghlama sa phíblíne seo an iarracht a theastaíonn le linn an phróisis a laghdú, agus cáilíocht an chórais aistriúcháin a mhéadú ag an am céanna. Ina theannta sin, cuireann sé ar chumas iarracht an duine a theastaíonn chun cáilíocht aistriúcháin áirithe a bhaint amach a chothromú. Ina theannta sin, sáraíonn ár gcóras néarchóras cur chuige clasaiceach go mór.', 'el': 'Μελετάμε την εφαρμογή τεχνικών ενεργού μάθησης στη μετάφραση απεριόριστων ροών δεδομένων μέσω διαδραστικής νευρολογικής μηχανικής μετάφρασης. Η κύρια ιδέα είναι να επιλέξετε, από μια απεριόριστη ροή προτάσεων πηγής, εκείνες που αξίζουν να εποπτεύονται από έναν ανθρώπινο παράγοντα. Ο χρήστης θα μεταφράσει διαδραστικά αυτά τα δείγματα. Μόλις επικυρωθούν, αυτά τα δεδομένα είναι χρήσιμα για την προσαρμογή του μοντέλου νευρολογικής μηχανικής μετάφρασης. Προτείνουμε δύο νέες μεθόδους επιλογής των δειγμάτων προς επικύρωση. Εκμεταλλευόμαστε τις πληροφορίες από τον μηχανισμό προσοχής ενός νευρικού συστήματος μηχανικής μετάφρασης. Τα πειράματά μας δείχνουν ότι η συμπερίληψη τεχνικών ενεργού μάθησης σε αυτόν τον αγωγό επιτρέπει να μειωθεί η προσπάθεια που απαιτείται κατά τη διάρκεια της διαδικασίας, αυξάνοντας παράλληλα την ποιότητα του μεταφραστικού συστήματος. Επιπλέον, επιτρέπει την εξισορρόπηση της ανθρώπινης προσπάθειας που απαιτείται για την επίτευξη μιας συγκεκριμένης ποιότητας μετάφρασης. Επιπλέον, το νευρικό μας σύστημα ξεπερνά κατά μεγάλο βαθμό τις κλασικές προσεγγίσεις.', 'hu': 'Tanulmányozzuk az aktív tanulási technikák alkalmazását a korlátlan adatfolyamok interaktív neurális gépi fordítással történő fordítására. A fő ötlet az, hogy a forrásbüntetések határozatlan áramából válasszuk ki azokat, amelyeket érdemes felügyelni egy emberi ügynök. A felhasználó interaktív módon fordítja le ezeket a mintákat. A validálás után ezek az adatok hasznosak az idegi gépi fordítási modell adaptálásához. Két új módszert javasolunk a validálandó minták kiválasztására. Kihasználjuk az információkat egy idegi gépi fordító rendszer figyelemmechanizmusából. Kísérleteink azt mutatják, hogy az aktív tanulási technikák bevonása ebben a csatornában lehetővé teszi a folyamat során igényelt erőfeszítések csökkentését, miközben növeli a fordítási rendszer minőségét. Ezenkívül lehetővé teszi a bizonyos fordítási minőség eléréséhez szükséges emberi erőfeszítések egyensúlyát. Ezenkívül az idegrendszerünk nagy mértékben felülmúlja a klasszikus megközelítéseket.', 'it': "Studiamo l'applicazione di tecniche di apprendimento attivo alla traduzione di flussi di dati illimitati tramite traduzione automatica neurale interattiva. L'idea principale è quella di selezionare, da un flusso illimitato di frasi sorgente, quelle che vale la pena di essere supervisionate da un agente umano. L'utente tradurrà interattivamente tali campioni. Una volta convalidati, questi dati sono utili per adattare il modello di traduzione automatica neurale. Proponiamo due nuovi metodi per selezionare i campioni da convalidare. Sfruttamo le informazioni provenienti dal meccanismo di attenzione di un sistema neurale di traduzione automatica. I nostri esperimenti dimostrano che l'inclusione di tecniche di apprendimento attivo in questa pipeline consente di ridurre lo sforzo richiesto durante il processo, aumentando al contempo la qualità del sistema di traduzione. Inoltre, consente di bilanciare lo sforzo umano necessario per raggiungere una certa qualità di traduzione. Inoltre, il nostro sistema neurale supera di gran lunga gli approcci classici.", 'ka': 'ჩვენ აქტიური სწავლის ტექნოგიების გამოყენებას ინტერრაქტიური ნეიროლის მაქანის გადაგრძელების გადაგრძელებისთვის. მნიშვნელოვანი იდეა იყო, რომ სახელის ადვნენტის შესახებ გადარჩენა, სახელის ბოლო წესების სახელიდან. მომხმარებელი ინტერქექტიურად ამ მონაცემების შეცვლა. როდესაც გადაწყენებული, ეს მონაცემები გამოსახულებელია ნეიროლური მაქინის გადაწყენების მოდელს. ჩვენ მუშაობთ ორი პრომენტის მეტი, რომელიც მონიშნავს ჩამოყენებას, რომელიც გადაწყენება. ჩვენ ინფორმაციას ნეიროლური მანქანის გაგრძელება სისტემის აღმოჩენება. ჩვენი ექსპერიმენტები გამოჩვენება, რომ აკეთებული სწავლების ტექნოგიების შეყვარება ამ პროცესში შეუძლებელია გავაკეთოთ პროცესის განმავლობაში, როდესაც გავაკეთება სისტემის დამატებით, ის შესაძლებელია, რომ ადამიანის წარმოადგენისთვის განსაკუთრებული წარმოგენისთვის განსაკუთრებული წარმოადგენისთვის ბალანქცია. დამატებით, ჩვენი ნეიროლური სისტემა კლასიკური დახმარებას დიდი მარტინზე.', 'lt': 'Mes tiriame aktyvaus mokymosi metodų taikymą neribotų duomenų srautų vertimui per interaktyvų neurologinį vertimą. Pagrindinė idėja – iš neribotų pradinių sakinių pasirinkti tuos, kuriuos verta prižiūrėti žmogaus atstovas. Naudotojas interaktyviai verts šiuos mėginius. Patvirtinus šiuos duomenis galima pritaikyti nervinės mašinos vertimo model į. Siūlome du naujus mėginių, kurie turi būti patvirtinti, atrankos metodus. Mes naudojame informaciją iš nervinės mašinos vertimo sistemos dėmesio mechanizmo. Mūsų eksperimentai rodo, kad aktyvaus mokymosi metodų įtraukimas į šį vamzdį leidžia sumažinti procese reikalingas pastangas, kartu didinant vertimo sistemos kokybę. Be to, ji leidžia subalansuoti žmogiškąsias pastangas, reikalingas tam tikrai vertimo kokybei pasiekti. Be to, mūsų nervų sistema didele marža viršija klasikinius metodus.', 'ms': 'Kami mempelajari aplikasi teknik pembelajaran aktif untuk terjemahan aliran data tanpa batas melalui terjemahan mesin saraf interaktif. Idea utama ialah memilih, dari aliran tidak terbatas kalimat sumber, yang bernilai untuk diawasi oleh ejen manusia. Pengguna akan terjemahkan sampel tersebut secara interaktif. Setelah disahkan, data ini berguna untuk menyesuaikan model terjemahan mesin saraf. Kami cadangkan dua kaedah baru untuk memilih sampel untuk disahkan. We exploit the information from the attention mechanism of a neural machine translation system.  Eksperimen kami menunjukkan bahawa penyambungan teknik pembelajaran aktif ke dalam saluran paip ini membolehkan mengurangi usaha yang diperlukan semasa proses, sementara meningkatkan kualiti sistem terjemahan. Selain itu, ia memungkinkan untuk seimbang usaha manusia yang diperlukan untuk mencapai kualiti terjemahan tertentu. Selain itu, sistem saraf kita melebihi pendekatan klasik dengan margin besar.', 'kk': 'Біз белсенді оқыту техникаларының қолданбаны шектелмеген деректер көзінің аударуына интерактивті невралдық компьютерді аудару арқылы зерттейміз. Негізгі идея - көзінің шектелмеген сөйлемелердің көзінен, адамдар агентінің басқаруының дұрысын таңдау. Пайдаланушы бұл үлгілерді интерактивті аударады. Тексерілген кезде, бұл деректер невралдық компьютердің аудару үлгісін адаптау үшін пайдалы. Біз тексеру үшін үлгілерді таңдау үшін екі романдық әдістерді таңдаймыз. Біз невралдық компьютердің аудару жүйесінің механизмінен мәліметті қолданып тұрмыз. Біздің тәжірибеміз белсенді үйрену техникаларын осы жолға қосуға мүмкіндік береді. Жүйені аудару жүйесінің сапатын көтеріп, қажетті жұмысын көтеруге мүмкіндік береді. Сонымен қатар, бұл адамдардың бір аудармалардың сапасына жеткізу үшін қажетті жұмысын балансируға мүмкіндік береді. Сонымен қатар, невралдық жүйеміз үлкен шегінен классикалық жағдайларды жасайды.', 'mk': 'We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation.  Главната идеја е да изберете, од неограничен потег на изворни реченици, оние вредни да бидат надгледувани од човек агент. Корисникот интерактивно ќе ги преведе овие примероци. Откако ќе бидат валидирани, овие податоци се корисни за адаптација на моделот на превод на невралната машина. Предложуваме два нови методи за избор на примероците кои ќе бидат валидирани. Ги искористуваме информациите од механизмот на вниманието на нервниот систем на превод на машина. Нашите експерименти покажуваат дека вклучувањето на активните техники на учење во овој гасовод овозможува намалување на напорите потребни за време на процесот, истовремено зголемувајќи го квалитетот на преводниот систем. Moreover, it enables to balance the human effort required for achieving a certain translation quality.  Покрај тоа, нашиот нервен систем ги надминува класичните пристапи со голема маргина.', 'no': 'Vi studerer programmet på aktive læringsteknikk til omsetjinga av ukrende datastrømmer via interaktiv neuralmaskinsomsetjing. Hovudsideen er å velja, frå ein ugjennområde kjeldesetningar, dei verdiane som skal overstyrast av ein menneske agent. Brukaren vil interaktivt oversette dei prøva. Når verdien er validert, er desse data nyttig for å tilpassa omsetjingsmodulen for neuralmaskin. Vi foreslår to novelmetodar for å velja prøver som skal validerast. Vi bruker informasjonen frå oppmerksmekanismen for eit neuralmaskinsomsetjingssystem. Eksperimentane våre viser at inkluderinga av aktive læringsteknikkar i denne rørslinja kan redusera forsøket som krevst i prosessen, medan du øker kvaliteten på omsetjingssystemet. Det kan også balansere menneskelige forsøk nødvendig for å oppnå ein bestemt omsetjingskvalitet. I tillegg kan det vårt neuralsystemet utføre klassiske tilnærmingar med ein stor margin.', 'ml': 'സജീവമായ പഠിപ്പിക്കുന്ന സാങ്കേതികവിദ്യകളുടെ പ്രയോഗത്തിന് നിര്\u200dബന്ധമില്ലാത്ത ഡേറ്റാ നദികളുടെ പരിഭാഷപ അതിരുകളില്ലാത്ത ഒരു സോര്\u200dസ് വാക്കുകളില്\u200d നിന്ന്, പ്രധാനപ്പെട്ട ഐഡിയ തെരഞ്ഞെടുക്കണമെന്നാണ് മനുഷ്യന്\u200d ഏജന്\u200dറി ഉപയോക്താവ് ആ ടാമ്പുകള്\u200d നിര്\u200dബന്ധിതമായി അനുവാദം ചെയ്യും. തെരഞ്ഞെടുത്തതിനു ശേഷം, ഈ ഡേറ്റാ പ്രയോജനപ്പെടുന്നത് ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ മോഡല്\u200d മാറ്റുന്നതിനായി  തെരഞ്ഞെടുക്കുന്നതിനുള്ള രണ്ട് നോവല്\u200d രീതികള്\u200d ഞങ്ങള്\u200d പ്രൊദ്ദേശിക്കുന്നു. ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ സിസ്റ്റത്തിന്റെ ശ്രദ്ധ വിവരങ്ങള്\u200d ഞങ്ങള്\u200d ഉപയോഗിക്കുന്നു. നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു സജീവമായ പഠിപ്പിക്കുന്ന സാങ്കേതികവിദ്യകളില്\u200d ചേര്\u200dക്കുന്നത്, പ്രക്രിയയില്\u200d ആവശ്യമുള്ള അതുകൊണ്ടും, അത് മനുഷ്യരുടെ പ്രയത്നത്തിന് തുല്യമാക്കാന്\u200d സാധിക്കുന്നു. ഒരു കുറിച്ച് പരിഭാഷത്തിന്\u200d അതുകൊണ്ടും, നമ്മുടെ ന്യൂറല്\u200d സിസ്റ്റം ഒരു വലിയ മാര്\u200dഗിനിലൂടെ ക്ലാസിക്കല്\u200d വഴികള്\u200d പ്രവര്\u200dത്തിപ്പിക്', 'mn': 'Бид актив суралцах техникуудын хэрэглээ интерактив мэдрэлийн механизмын хөрөнгө оруулахын аргаар хил хязгааргүй өгөгдлийн урсгал хөрөнгө оруулах боломжтой. Хамгийн гол санаа нь, эх үүсвэрээс хязгааргүй өгүүлбэрээс хүний агент удирдах үнэ цэнийг сонгох юм. Хэрэглэгч эдгээр жишээг интерактивээр орлуулна. Дараагийн дараа эдгээр мэдээллүүд нь мэдрэлийн машины хөгжлийн загварыг адаптын тулд хэрэгтэй. Бид хоёр шинэ арга замыг шалгахын тулд дүгнэх шаардлагатай. Бид мэдээллийг мэдрэлийн механизмээс ашигладаг. Бидний туршилтууд энэ хоолойн шугам руу актив суралцах техникуудыг нэгтгэх нь үйл явцын үед хэрэгтэй хүч чадлыг багасгах боломжтой болгодог гэдгийг харуулдаг. Дараа нь, энэ нь хүн төрөлхтний хичээлийг баланслах боломжтой болгодог. Мөн бидний мэдрэлийн систем маш том хязгаар дамжуулагддаг.', 'mt': 'Aħna nistudjaw l-applikazzjoni ta’ tekniki attivi ta’ tagħlim għat-traduzzjoni ta’ flussi ta’ dejta mingħajr limiti permezz ta’ traduzzjoni interattiva ta’ magni newrali. L-idea ewlenija hija li wieħed jagħżel, minn fluss bla limitu ta’ sentenzi tas-sors, dawk li għandhom jiġu ssorveljati minn a ġent uman. The user will interactively translate those samples.  Ladarba tiġi vvalidata, din id-dejta hija utli biex jiġi adattat il-mudell tat-traduzzjoni tal-magna newrali. Aħna nipproponu żewġ metodi ġodda għall-għażla tal-kampjuni li għandhom jiġu vvalidati. Aħna nisfruttaw l-informazzjoni mill-mekkaniżmu ta’ attenzjoni ta’ sistema ta’ traduzzjoni ta’ magni newrali. L-esperimenti tagħna juru li l-inklużjoni ta’ tekniki attivi ta’ tagħlim f’dan il-pipeline tippermetti li jitnaqqas l-isforz meħtieġ matul il-proċess, filwaqt li tiżdied il-kwalità tas-sistema ta’ traduzzjoni. Barra minn hekk, dan jippermetti li jiġi bbilanċjat l-isforz uman meħtieġ biex tinkiseb ċerta kwalità tat-traduzzjoni. Barra minn hekk, is-sistema newrali tagħna tippreżenta approċċi klassiċi b’marġini kbir.', 'ro': 'Studiem aplicarea tehnicilor de învățare activă la traducerea fluxurilor de date nelimitate prin traducerea automată neurală interactivă. Ideea principală este de a selecta, dintr-un flux nelimitat de sentințe sursă, cele care merită să fie supravegheate de un agent uman. Utilizatorul va traduce interactiv aceste mostre. Odată validate, aceste date sunt utile pentru adaptarea modelului de traducere automată neurală. Propunem două metode noi pentru selectarea probelor care urmează să fie validate. Exploatăm informațiile din mecanismul de atenție al unui sistem neuronal de traducere automată. Experimentele noastre arată că includerea tehnicilor de învățare activă în această conductă permite reducerea efortului necesar în timpul procesului, sporind în același timp calitatea sistemului de traducere. În plus, permite echilibrarea efortului uman necesar pentru atingerea unei anumite calități a traducerii. Mai mult decât atât, sistemul nostru neural depășește abordările clasice cu o marjă mare.', 'si': 'අපි සක්\u200dරිය ඉගෙන ඉගෙනීමේ තාක්ෂණාත්මක ප්\u200dරවේශනය අභිවේශනය කරනවා සම්බන්ධ න්\u200dයූරාල් මැෂින් අවවා ප්\u200dරධාන අදහසක් තමයි මිනිස් නියෝජිතයෙක් බලන්න ප්\u200dරවේශයක් නැති ප්\u200dරවේශයෙන් තෝරාගන්න. ප්\u200dරයෝජකයා ඒ නිර්මාණය අවවාද කරයි. විශ්වාස කරපු වෙලාවට, මේ තොරතුරු ප්\u200dරයෝජනයක් න්\u200dයූරාල් මැෂින් වාර්ථාව මදුල් එක් සඳ අපි ප්\u200dරශ්නයක් විශ්වාස කරන්න ප්\u200dරශ්නයක් දෙකක් ප්\u200dරශ්නයක් කරනවා. අපි තොරතුරු ප්\u200dරයෝජනය කරනවා න්\u200dයූරාල් මැෂින් වාර්තාව පද්ධතියේ අවධාන පද්ධතියෙන්. අපේ පරීක්ෂණය පෙන්වන්නේ සක්\u200dරිය ඉගෙන ඉගෙනීමේ තාක්ෂණය මේ පායිප්ලයින් වලට පරීක්ෂණයෙන් අවශ්\u200dය කරනවා කියලා, පරීක්ෂණ ඒවගේම, ඒකෙන් මිනිස්සුන්ගේ ප්\u200dරයෝජනය සම්බන්ධ වෙන්න පුළුවන් වෙන්න පුළුවන්. තවත්, අපේ න්\u200dයුරෝල් පද්ධතිය ප්\u200dරශ්නයක් ලොකු මාර්ජින් වලින් ප්\u200dරශ්නයක් නැති වෙනවා.', 'so': 'Waxbarashada iskuulaadka waxqabadka ah ayaannu ku baranaynaa tarjumaadda jaamacadaha aan xadeyn, sida lagu turjumayo tarjumaadda guud ee machadka neurada. Fikirada muhiimka ah waa in laga doortaa durdur a an xadayn xukunka noocyada, kuwaas oo istaahila in lagu ilaaliyo qof dhaqaale ah. Isticmaaluhu wuxuu si rasmi ah u tarjumayaa samooyinka. Markii la xaqiijiyey, macluumaadkaas waxey faa’iido u leedahay in lagu beddelo modelka turjumista maskinada cudurka. Waxaan soo jeedaynaa laba qaab oo saxda ah si aan u dooranno samooyinka in la xaqiijiyo. Waxaynu macluumaadka ka isticmaalnaa machine turjumista neurada. Imtixaankayada waxay muuqataa in lagu soo galo qalabka waxbarashada waxqabadka ah ee baaritaankan waxaa suurtogal ah in uu hoos u dhigo hawlaha lagu baahan yahay marka lagu jiro, isagoo kordhiya qiimaha nidaamka turjumaadda. Waxaa sidoo kale suurtagal ah in ay u sameyn karto dadaalka dadka oo loo baahan yahay in ay gaadho qiimo turjumista cayiman. Sidoo kale nidaamkayaga neurada ayaa ka muuqata qaabab kaliya oo aad u weyn.', 'sv': 'Vi studerar tillämpningen av aktiva inlärningstekniker för översättning av obegränsade dataströmmar via interaktiv neural maskinöversättning. Huvudidén är att välja, från en obegränsad ström av källdomar, de som är värda att övervakas av en mänsklig agent. Användaren kommer att översätta dessa prover interaktivt. Efter validering är dessa data användbara för att anpassa den neurala maskinöversättningsmodellen. Vi föreslår två nya metoder för urval av prover som ska valideras. Vi utnyttjar informationen från uppmärksamhetsmekanismen i ett neuralt maskinöversättningssystem. Våra experiment visar att inkluderandet av aktiva inlärningstekniker i denna pipeline gör det möjligt att minska den ansträngning som krävs under processen, samtidigt som kvaliteten på översättningssystemet ökar. Dessutom gör det möjligt att balansera den mänskliga ansträngning som krävs för att uppnå en viss översättningskvalitet. Dessutom överträffar vårt neurala system klassiska tillvägagångssätt med stor marginal.', 'pl': 'Badamy zastosowanie technik aktywnego uczenia się do tłumaczenia nieograniczonych strumieni danych za pomocą interaktywnego neuronowego tłumaczenia maszynowego. Główną ideą jest wybór, spośród nieograniczonego strumienia zdań źródłowych, tych wartych być nadzorowanych przez człowieka. Użytkownik interaktywnie przetłumaczy te próbki. Po zweryfikowaniu dane te są przydatne do adaptacji neuronowego modelu tłumaczenia maszynowego. Proponujemy dwie nowe metody doboru próbek do walidacji. Wykorzystujemy informacje z mechanizmu uwagi neuronowego systemu tłumaczenia maszynowego. Nasze eksperymenty pokazują, że włączenie technik aktywnego uczenia się do tego rurociągu pozwala zmniejszyć nakład wymagany podczas procesu, przy jednoczesnym zwiększeniu jakości systemu tłumaczeniowego. Ponadto pozwala na zrównoważenie wysiłku ludzkiego niezbędnego do osiągnięcia określonej jakości tłumaczenia. Ponadto nasz układ neuronowy znacznie przewyższa klasyczne podejścia.', 'ta': 'நாங்கள் செயலில் கற்றுக் கொள்ளும் தொழில்நுட்பத்தின் பயன்பாட்டை மொழிபெயர்ப்பில்லாத தகவல் துறைகளை மொழிபெயர் முக்கிய ய யோசனை ஒரு வரம்பு மூல வாக்கியங்களிலிருந்து, தேர்ந்தெடுக்க வேண்டும் என்பது, ஒரு மனித செயலாளர் கண்காணிக்கப பயனர் செயல்படுத்தி அந்த மாதிரிகளை மொழிமாற்றுவார். @ info மாதிரிகளை தேர்ந்தெடுக்க இரண்டு புதிய முறைமைகளை நாம் பரிந்துரைக்கிறோம். நாம் புதிய கணினி மொழிபெயர்ப்பு அமைப்பின் கவனம் முறைமையிலிருந்து தகவல்களை பயன்படுத்துகிறோம். எங்கள் சோதனைகள் செயலில் கற்றுக்கொள்ளும் தொழில்நுட்பத்தை சேர்த்துக் காட்டுகிறது இந்த கைப்பேலின் முயற்சி குறைக்க அனுமதிக்க மேலும், அது ஒரு குறிப்பிட்ட மொழிபெயர்ப்பு தரம் அடைவதற்கான மனித முயற்சியை நிறைவேற்ற முயற்சியை செயல Moreover, our neural system outperforms classical approaches by a large margin.', 'ur': 'ہم فعال سیکھنے کی تکنیک کی کاربرد کی تعلیم کی تحقیق کررہے ہیں بغیر محدود ڈیٹا سی ریموں کی ترجمہ کے ذریعہ بینافعال نیورال ماشین کی ترجمہ کے ذریعہ۔ اصلی نظر یہ ہے کہ ایک منزل جماعت کے غیر محدودہ نہریں سے انتخاب کریں، جو ایک انسان اگنٹ کے ذریعے نظارت کریں۔ کارساز ان نمونوں کی تعبیر کرے گا۔ Once validated, these data are useful for adapting the neural machine translation model. ہم دونوں نومین طریقے پیشنهاد کرتے ہیں کہ نمونے کا انتخاب کریں۔ ہم نے نئورل ماشین ترجمہ سیسٹم کے ذریعہ سے اطلاعات کو استعمال کرتے ہیں۔ ہماری آزمائش دکھاتی ہے کہ فعال سیکھنے کی تکنیک اس پیپ لین میں شامل ہونے کی اجازت دیتی ہے کہ پرسس میں ضرورت کی کوشش کم کرتی ہے اور ترجمہ سیستم کی کیفیت بڑھتی ہے۔ اور اس نے انسان کی کوشش کی تعادل کرنے کی امکان دی ہے کہ ایک مقررہ ترجمہ کیفیت تک پہنچ سکے۔ اور ہماری نیورل سیستم ایک بڑی مرز سے کلاسیک طریقے سے کام لیتا ہے۔', 'sr': 'Proučavamo primjenu aktivnih tehnika učenja na prevod neograničenih potoka podataka preko interaktivnog prevoda neuralne mašine. Glavna ideja je da odaberemo, iz neograničenog potoka izvornih rečenica, one koje vrijede da nadziru ljudski agent. Korisnik će interaktivno prevoditi te uzorke. Kada je potvrđeno, ovi podaci su korisni za prilagodbu modela prevoda neuralne mašine. Predlažemo dve nove metode da izaberemo uzorke da budu potvrđene. Koristimo informacije iz pažnje mehanizma neuralnog prevodnog sistema. Naši eksperimenti pokazuju da uključivanje aktivnih tehnika učenja u ovu kanalizaciju omogućava smanjiti potrebne napore tokom procesa, dok povećava kvalitet prevodnog sistema. Osim toga, omogućava se ravnotežu ljudskih napora potrebnih za ostvarivanje određene kvalitete prevoda. Osim toga, naš nervni sistem iznosi klasične pristupe velikom marginom.', 'uz': "We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation.  Mavzu g'oyasi, manba maxfiy soʻzlarning chegara tarkibini tanlash uchun ularni inson agentidan boshqarish kerak. Name @ info @ info Biz neyron maskina tarjima tizimining qismlarini o'rganamiz. Bizning tajribalarimiz shu pipelining aktiv o'rganish teknikalarni qo'shish imkoniyatini ko'rsatadi va tarjima tizimning sifatini oshirish mumkin. Ko'pchilik, bu bir necha tarjima sifatini bajarish uchun odamning harakatini balandlashga yordam beradi. Ko'rib, bizning neyrolik tizimimiz katta harfning bir darajada o'zgartiradi.", 'vi': 'Chúng tôi nghiên cứu sử dụng các kỹ thuật học hoạt động để dịch chuyển các dòng dữ liệu không được sáng tạo bằng cách dịch chuyển cỗ máy thần kinh. Quan trọng là phải chọn, từ một dòng chữ nguyên bản, những câu đáng để được giám sát bởi một đặc vụ con người. Người dùng sẽ dịch các mẫu đó tương tác. Một khi xác nhận, dữ liệu này có ích để sửa đổi mô hình dịch cỗ máy thần kinh. Chúng tôi đề xuất hai phương pháp mới để chọn các mẫu cần xác định. Chúng tôi khai thác thông tin từ cơ chế tập trung của hệ thống dịch chuyển cỗ máy thần kinh. Những thí nghiệm của chúng tôi cho thấy rằng việc thêm vào đường ống các kỹ thuật học hoạt động có thể làm giảm các nỗ lực cần thiết trong quá trình, nhưng vẫn tăng chất lượng của hệ thống dịch chuyển. Hơn nữa, nó có thể cân bằng nỗ lực con người cần thiết để đạt được một chất lượng dịch nhất định. Hơn nữa hệ thần kinh của chúng ta vượt trội các tiếp cận cổ điển.', 'da': 'Vi studerer anvendelsen af aktive læringsteknikker til oversættelse af ubegrænsede datastrømme via interaktiv neural maskinoversættelse. Hovedideen er at udvælge fra en ubegrænset strøm af kildesætninger dem, der er værd at blive overvåget af en menneskelig agent. Brugeren vil interaktivt oversætte disse prøver. Når disse data er valideret, er nyttige til at tilpasse den neurale maskinoversættelsesmodel. Vi foreslår to nye metoder til udvælgelse af de prøver, der skal valideres. Vi udnytter oplysningerne fra opmærksomhedsmekanismen i et neuralt maskinoversættelsessystem. Vores eksperimenter viser, at inkluderingen af aktive læringsteknikker i denne pipeline gør det muligt at reducere den krævede indsats under processen, samtidig med at kvaliteten af oversættelsessystemet øges. Desuden gør det muligt at afbalancere den menneskelige indsats, der kræves for at opnå en vis oversættelseskvalitet. Desuden overgår vores neurale system klassiske tilgange med stor margin.', 'nl': 'We bestuderen de toepassing van actieve leertechnieken op de vertaling van onbegrensde datastromen via interactieve neurale machinevertaling. Het belangrijkste idee is om, uit een onbegrensde stroom van bronzinnen, degenen te selecteren die het waard zijn om onder toezicht te staan door een menselijke agent. De gebruiker zal deze voorbeelden interactief vertalen. Eenmaal gevalideerd, zijn deze gegevens nuttig voor het aanpassen van het neurale machine translation model. We stellen twee nieuwe methoden voor het selecteren van de te valideren monsters voor. We benutten de informatie van het aandachtsmechanisme van een neuraal machinevertaalsysteem. Onze experimenten tonen aan dat de integratie van actieve leertechnieken in deze pijplijn het mogelijk maakt om de inspanning die nodig is tijdens het proces te verminderen en tegelijkertijd de kwaliteit van het vertaalsysteem te verhogen. Bovendien is het mogelijk om de menselijke inspanning die nodig is om een bepaalde vertaalkwaliteit te bereiken in evenwicht te brengen. Bovendien overtreft ons neurale systeem klassieke benaderingen met een grote marge.', 'bg': 'Изследваме прилагането на техники за активно обучение при превода на неограничени потоци от данни чрез интерактивен невронен машинен превод. Основната идея е да се изберат, от неограничен поток от изходни изречения, тези, които си струват да бъдат наблюдавани от човешки агент. Потребителят интерактивно ще превежда тези мостри. Веднъж валидирани, тези данни са полезни за адаптиране на модела на невронен машинен превод. Предлагаме два нови метода за избор на пробите, които ще бъдат валидирани. Ние използваме информацията от механизма на вниманието на невронната система за машинен превод. Нашите експерименти показват, че включването на активни техники за обучение в този канал позволява да се намалят усилията, необходими по време на процеса, като същевременно се повиши качеството на преводната система. Освен това тя позволява да се балансират човешките усилия, необходими за постигане на определено качество на превода. Нещо повече, нашата невронна система надминава класическите подходи с голям марж.', 'hr': 'Proučavamo primjenu aktivnih tehnika učenja na prevod neograničenih potoka podataka preko interaktivnog prevoda neuralnih strojeva. Glavna ideja je izabrati, iz neograničenog potoka izvornih rečenica, one koje vrijede nadzirati ljudski agent. Korisnik će interaktivno prevoditi te uzorke. Nakon potvrđenja, ovi podaci su korisni za prilagodbu modela prevoda neuralnih strojeva. Predlažemo dvije nove metode da izaberemo uzorke koje treba potvrditi. Koristimo informacije iz pažnje mehanizma sustava prevoda neuroloških strojeva. Naši eksperimenti pokazuju da uključivanje aktivnih tehnika učenja u ovu cijev omogućava smanjiti potrebne napore tijekom procesa, dok povećava kvalitet prevodnog sustava. Osim toga, omogućuje ravnotežu ljudskih napora potrebnih za postizanje određene kvalitete prevoda. Osim toga, naš nervni sustav iznosi klasične pristupe velikom marginom.', 'de': 'Wir untersuchen die Anwendung von aktiven Lerntechniken zur Übersetzung von unbegrenzten Datenströmen mittels interaktiver neuronaler maschineller Übersetzung. Die Hauptidee ist, aus einem unbegrenzten Strom von Quellsätzen diejenigen auszuwählen, die es wert sind, von einem menschlichen Agenten überwacht zu werden. Der Benutzer wird diese Beispiele interaktiv übersetzen. Nach der Validierung sind diese Daten für die Anpassung des neuronalen maschinellen Übersetzungsmodells nützlich. Wir schlagen zwei neue Methoden zur Auswahl der zu validierenden Proben vor. Wir nutzen die Informationen aus dem Aufmerksamkeitsmechanismus eines neuronalen maschinellen Übersetzungssystems. Unsere Experimente zeigen, dass die Einbeziehung aktiver Lerntechniken in diese Pipeline den Aufwand während des Prozesses reduziert und gleichzeitig die Qualität des Übersetzungssystems erhöht. Darüber hinaus ermöglicht es, den menschlichen Aufwand für eine bestimmte Übersetzungsqualität auszugleichen. Darüber hinaus übertrifft unser Nervensystem klassische Ansätze mit großem Abstand.', 'id': 'Kami mempelajari aplikasi teknik pembelajaran aktif untuk terjemahan aliran data tanpa batas melalui terjemahan mesin saraf interaktif. Ide utama adalah memilih, dari aliran tidak terbatas kalimat sumber, yang layak diawasi oleh agen manusia. Pengguna akan secara interaktif menerjemahkan sampel tersebut. Setelah dipvalidasi, data ini berguna untuk mengadaptasi model terjemahan mesin saraf. Kami mengusulkan dua metode baru untuk memilih sampel untuk dipvalidasi. Kami mengeksploitasi informasi dari mekanisme perhatian sistem terjemahan mesin saraf. Our experiments show that the inclusion of active learning techniques into this pipeline allows to reduce the effort required during the process, while increasing the quality of the translation system.  Selain itu, itu memungkinkan untuk menyeimbangkan usaha manusia yang diperlukan untuk mencapai kualitas terjemahan tertentu. Selain itu, sistem saraf kita melebihi pendekatan klasik dengan margin besar.', 'sw': 'We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation.  Wazo kuu ni kuchagua, kutokana na mito isiyo na mipaka ya hukumu za vyanzo, wale wanastahili kuangaliwa na mtumiaji wa binadamu. Mtumiaji atatafsiri sampuli hizo. Baada ya kuthibitishwa, takwimu hizi zinafaa kubadilisha muundo wa kutafsiri mashine ya ujasiri. Tunazipendekeza njia mbili za riwaya kwa kuchagua sampuli zitakazothibitishwa. Tunatumia taarifa kutoka mfumo wa kutafsiri mashine ya ubongo. Majaribio yetu yanaonyesha kuwa muingizaji wa mbinu za kujifunza za haraka katika mfumo huu unaruhusu kupunguza juhudi zinazohitajika wakati wa mchakato huo, na kuongeza kiwango cha mfumo wa tafsiri. Zaidi ya hayo, inawezesha kulinganisha juhudi za binadamu zinazohitajika kwa kufikia kiwango fulani cha tafsiri. Zaidi ya hayo, mfumo wetu wa ubongo unaonyesha mbinu za kiganjani na sehemu kubwa.', 'tr': "Biz janlaş öwrenmek teknikleriniň uygulamasyny çykarylyşyrlyk bilen geçirilmeýän maglumat aklanynyň terjimesine täsirli näral maşynyň terjimesini ýüze çykarýarys. Esasy ideýa, çeşme sözleriniñ arasyndaky daşyrmadykdan, adam ajaýyp tarapyndan gözleýän zady saýlamakdyr. Ullançy bu nusgalary täsirli terjime eder Taryhdan soňra, bu maglumatlar neural maşynyň terjime nusgasyny üýtgetmek üçin peýdalydyr. Biz nusgalary taýýarlamak üçin iki roman yöntemi teklip edýäris. Biz näyral maşynyň terjime sistemasynyň üns mekanizmasyndan maglumatlary ulanýarys. Biziň deneylerimiz bu pipeline'a aktiw öwrenmek teknikleriniň ahyrmasynyň proses wagtynda gerekli çabalaryny azaltyp, terjime sistemanyň keyfiýetini artýar. Ynsanlaryň beýleki terjime kwalitesini ýetmek üçin gerekli çabalaryny çözmeke mümkin edýär. We ýene-de, neural sistemamyz uly gabadan klasik ýagdaýlaryny çykarýar.", 'ko': '우리는 상호작용식 신경기계 번역을 통해 능동 학습 기술이 무계 데이터 흐름 번역에서의 응용을 연구했다.그 주요 사상은 끊임없는 원문 중에서 인류가 대리하여 감독할 만한 문구를 선택하는 것이다.사용자는 이 예들을 상호작용으로 번역할 것이다.일단 검증되면 이런 데이터는 신경기계 번역 모델에 적응하는 데 유용하다.우리는 검증을 기다리는 견본을 선택하는 두 가지 새로운 방법을 제시했다.우리는 신경 기계 번역 시스템을 이용하여 메커니즘의 정보를 주의한다.우리의 실험은 주동적인 학습 기술을 이 파이프라인에 포함시키면 번역 과정에서 필요한 작업량을 줄일 수 있을 뿐만 아니라 번역 시스템의 질도 향상시킬 수 있음을 나타냈다.그 밖에 일정한 번역 품질에 필요한 인력의 균형을 맞출 수 있다.그 밖에 우리의 신경계는 고전적인 방법보다 훨씬 우수하다.', 'af': "Ons studeer die toepassing van aktiewe leer teknike na die vertaling van ongebrende data strome deur interaktiewe neurale masjien vertaling. Die hoofde idee is om te kies, van 'n ongegrense stroom van bron setings, die waardes om deur 'n menslike agent te ondersoek. Die gebruiker sal interaktief vertaal dié voorbeelde. Wanneer geldige is, is hierdie data nuttig vir aanpassing van die neurale masjien vertaling model. Ons voorstel twee roman metodes om die voorbeelde te kies om te geldiseer. Ons gebruik die inligting van die aandagmekanisme van 'n neurale masjien vertalingsstelsel. Ons eksperimente wys dat die inklusie van aktiewe leer teknike in hierdie pyplyn laat toe om die versoening wat nodig is in die proses te verminder, terwyl die kwaliteit van die vertaling stelsel verhoog word. Dit kan ook die menslike versoek wat benodig is om 'n sekere vertalingskwaliteit te bereik. Ook, ons neural stelsel uitvoer klassieke toegang deur 'n groot marge.", 'fa': 'ما کاربرد تکنیک یادگیری فعالی را به ترجمه رودهای اطلاعات غیرمحدود با توسط ترجمه ماشین عصبی متفاوت مطالعه می کنیم. ایده اصلی این است که از یک رودخانه غیرمحدود از جمله\u200cهای منبع انتخاب کنیم، آن\u200cها که ارزش دارند که توسط یک مامور انسان کنترل شوند. کاربر این نمونه\u200cها را ترجمه می\u200cکند. Once validated, these data is useful for adapting the neural machine translation model. ما دو روش رمانی برای انتخاب نمونه\u200cها را پیشنهاد می\u200cکنیم که باید تایید شوند. ما اطلاعات را از مکانیسم توجه یک سیستم ترجمه ماشین عصبی استفاده می کنیم. آزمایشات ما نشان می دهند که شامل تکنیک یادگیری فعال در این لوله اجازه می دهد تلاش را در طول فرایند کاهش دهد، در حالی که کیفیت سیستم ترجمه را افزایش می دهد. علاوه بر این، این اجازه می دهد که تلاش انسان را برای رسیدن کیفیت ترجمه معین تعمیر کند. علاوه بر این، سیستم عصبی ما با یک مرز بزرگ نزدیک کلاسیک را انجام می دهد.', 'hy': 'Մենք ուսումնասիրում ենք ակտիվ ուսումնասիրության մեթոդների կիրառումը անսահմանափակ տվյալների հոսքերի թարգմանման համար ինտերակտիվ նյարդային մեքենայի թարգմանման միջոցով: Հիմնական գաղափարն այն է, որ անսահմանափակ նախադասությունների հոսանքից ընտրենք մարդկային գործակալի կողմից վերահսկվող նախադասությունները: Օգտագործողը ինտերակտիվ կթարգմանի այդ նմուշները: Հենց ստուգելը, այս տվյալները օգտակար են նյարդային մեքենայի թարգմանման մոդելի հարմարեցման համար: Մենք առաջարկում ենք երկու նոր մեթոդ, որպեսզի ընտրենք ճշգրիտ նմուշները: We exploit the information from the attention mechanism of a neural machine translation system.  Մեր փորձարկումները ցույց են տալիս, որ ակտիվ ուսումնասիրության մեթոդների ներառումը այս խողովակաշարի մեջ թույլ է տալիս նվազեցնել գործընթացի ընթացքում պահանջված ջանքերը, միաժամանակ բարձրացնելով թարգմանման համակար Ավելին, այն հնարավորություն է տալիս հավասարակշռել մարդկային ջանքերը, որոնք անհրաժեշտ են թարգմանության որոշակի որակի հասնելու համար: Ավելին, մեր նյարդային համակարգը շատ ավելի լավ է ընդունում դասական մոտեցումները:', 'sq': "Ne studiojmë aplikimin e teknikave aktive të mësimit në përkthimin e rrjedhëve të të dhënave të pakufizuara nëpërmjet përkthimit interaktiv të makinave nervore. Ideja kryesore është të zgjedhësh, nga një rrjedhë e papërkufizuar fjalësh burimi, a to që vlen të mbikqyren nga një agjent njeriu. Përdoruesi do t'i përkthejë këto mostra interaktivisht. Pasi të vlerësohen, këto të dhëna janë të dobishme për të përshtatur modelin e përkthimit të makinave nervore. We propose two novel methods for selecting the samples to be validated.  Ne shfrytëzojmë informacionin nga mekanizmi i vëmendjes së një sistemi përkthimi i makinave nervore. Eksperimentet tona tregojnë se përfshirja e teknikave aktive të mësimit në këtë tubacion lejon të reduktojë përpjekjet e kërkuara gjatë procesit, duke rritur cilësinë e sistemit të përkthimit. Përveç kësaj, kjo lejon të ekuilibrojë përpjekjet njerëzore të kërkuara për arritjen e një cilësie të caktuar përkthimi. Përveç kësaj, sistemi ynë nervor ekziston më tepër se metodat klasike me një margin të madh.", 'bn': 'আমরা সক্রিয় শিক্ষা প্রযুক্তির অ্যাপ্লিকেশন ইন্টারেক্টিভ নিউরেল মেশিন অনুবাদের মাধ্যমে সীমাবদ্ধ তথ্য প্রব প্রধান চিন্তা হচ্ছে সীমাবদ্ধ সূত্রের বাক্য থেকে, যাদের মানুষ এজেন্ট দ্বারা পর্যবেক্ষণ করা যায়। The user will interactively translate those samples.  একবার বৈধ করা হলে, এই তথ্য নিউরেল মেশিন অনুবাদ মডেল আপডেট করার জন্য উপযুক্ত। আমরা বৈধ নমুনা নির্বাচনের জন্য দুটি নোভেল পদ্ধতি প্রস্তাব করি। আমরা একটি নিউরুল মেশিন অনুবাদ সিস্টেমের মনোযোগ ব্যবস্থার তথ্য ব্যবহার করি। আমাদের পরীক্ষাগুলো দেখাচ্ছে যে এই পাইপেলাইনে সক্রিয় শিক্ষা প্রযুক্তির মধ্যে যোগাযোগ করা প্রচেষ্টাকে কমিয়ে দেওয়া যায়, যখন অনুবাদ এছাড়াও এটি মানুষের প্রচেষ্টাকে মানুষের প্রতি সমানের সুযোগ দিতে সক্ষম হবে নির্দিষ্ট অনুবাদের মান এছাড়াও, আমাদের নিউরেল ব্যবস্থা একটি বিশাল মার্গিনের মাধ্যমে ক্লাসিক ক্ষেত্রে ব্যবহার করে।', 'am': "የጥያቄ ትምህርት ጥያቄዎችን ለመግለጽ በተቃውሞ የዳታ ወንዞችን በመግለጽ እናስተምራለን፡፡ የዋነቱ አሳብ፣ በሌላው የኩነቶች ፍርድ ወንዝ፣ በሰው አካባቢ በመጠበቅ የሚገባቸው ናቸው፡፡ ተጠቃሚ እነዚህን ምሳሌዎች በተለየ ይዘጋጃል። ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s ምሳሌዎቹን ለመምረጥ ሁለት አዲስ መንገድ እናስፈልጋለን፡፡ የናቡር መሣሪያን ትርጉም ሲስተካከል የሚጠይቅ መረጃዎችን እንፈልጋለን፡፡ ፈተናዎቻችን የዚህ ፕሮግራም ውስጥ የተማረ ትምህርት መግለጫ እንዲያስተካክሉ፣ በተርጓሚው ስርዓት ጥያቄን ሲጨምር ይችላል፡፡ በተጨማሪም የግል ትርጓሜ ጥሩ ለማግኘት የሚፈልገውን የሰው ድጋፍ በትክክል ይችላል፡፡ ደግሞም የናቡር ስርዓታችን በታላቅ ስርዓት የክላሲ ደረጃዎችን ያሳርፋል፡፡", 'ca': "We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation.  La idea principal és seleccionar, d'un flux indefinit de frases fonts, aquelles que val la pena ser supervisades per un agent humà. L'usuari traduirà interactivament aquestes mostres. Una vegada validada, aquestes dades són útils per adaptar el model de traducció neuronal. Proposem dos mètodes noves per seleccionar les mostres a validar. Exploitem la informació del mecanisme d'atenció d'un sistema de traducció neuronal. Els nostres experiments demostren que l'inclusió de tècniques d'aprenentatge actives en aquest tub permet reduir l'esforç requerit durant el procés, alhora que augmenta la qualitat del sistema de traducció. A més, permet equilibrar l'esforç humà requerit per aconseguir una certa qualitat de traducció. A més, el nostre sistema neural supera els enfocaments clàssics amb un gran marge.", 'az': 'Biz fəaliyyətli öyrənmə tekniklərinin uyğulanmasını müəyyən edilməmiş məlumat akışlarının çevirilməsini interaktif nöral maşına çevirilməsi vasitəsilə öyrənirik. Ən böyük fikir insan ajanının gözətçiliyindən seçməkdir. İstifadəçi bu nümunələri interaktif tərcümə edəcək. Qeyd edildikdə, bu məlumatlar nöral maşına çevirim modelini uyğunlaşdırmaq üçün faydalandır. Biz nümunələri təsdiqlənmək üçün iki yeni metod təklif edirik. Biz nöral maşın çeviriş sisteminin məlumatını istifadə edirik. Bizim təcrübələrimiz bu bor çizgisinə fəaliyyət öyrənmə tekniklərinin istifadə edilməsi procesdə lazım olan çabaları azaltmağa imkan verir, tercümə sisteminin keyfiyyətini artırmağa imkan verir. Əksinə, bu insanların tərəfindən bəzi tərcümə keyfiyyətini yetirmək üçün ehtiyacı olan çabalarını çəkir. Əksinə, nöral sistemimiz böyük bir margin ilə klasik yaxınlıqları a şkar edir.', 'cs': 'Studujeme aplikaci technik aktivního učení na překlad neomezených datových toků prostřednictvím interaktivního neuronového strojového překladu. Hlavní myšlenkou je vybrat z neomezeného proudu zdrojových vět ty, které stojí za to, aby pod dohledem lidského agenta. Uživatel interaktivně přeloží tyto vzorky. Po validaci jsou tato data užitečná pro adaptaci neuronového strojového překladu modelu. Navrhujeme dvě nové metody výběru vzorků, které mají být validovány. Využíváme informace z pozornostního mechanismu neuronového strojového překladu. Naše experimenty ukazují, že začlenění technik aktivního učení do tohoto potrubí umožňuje snížit námahu potřebnou během procesu a zároveň zvyšovat kvalitu překladatelského systému. Navíc umožňuje vyvážit lidské úsilí potřebné k dosažení určité kvality překladu. Navíc náš nervový systém výrazně překonává klasické přístupy.', 'et': 'Uurime aktiivsete õppemeetodite rakendamist piiramatute andmevoogude tõlkimisel interaktiivse neuromasintõlke kaudu. Põhieesmärk on valida piiramatu lähtelausete voolu hulgast need, mis on väärt inimese järelevalvet. Kasutaja tõlgib need näidised interaktiivselt. Pärast valideerimist on need andmed kasulikud neuraalse masintõlke mudeli kohandamiseks. Valideeritavate proovide valimiseks pakume välja kaks uut meetodit. Me kasutame ära informatsiooni neurotõlkesüsteemi tähelepanumehhanismist. Meie eksperimendid näitavad, et aktiivsete õppemeetodite kaasamine sellesse juhtmesse võimaldab vähendada protsessi käigus vajalikku pingutust, suurendades samal ajal tõlkesüsteemi kvaliteeti. Lisaks võimaldab see tasakaalustada inimjõupingutusi, mis on vajalikud teatud tõlkekvaliteedi saavutamiseks. Veelgi enam, meie närvisüsteem ületab klassikalisi lähenemisviise suurel määral.', 'bs': 'Proučavamo primjenu aktivnih tehnika učenja na prevod neograničenih potoka podataka preko interaktivnog prevoda neuralnih strojeva. Glavna ideja je izabrati, iz neograničenog potoka izvornih kazna, one koje vrijede da nadziru ljudski agent. Korisnik će interaktivno prevoditi te uzorke. Nakon potvrđenja, ovi podaci su korisni za prilagodbu modela prevoda neuronskih strojeva. Predlažemo dva novog metoda da izaberemo uzorke koje treba potvrditi. Koristimo informacije iz pažnje mehanizma neuronskog sustava prevoda mašine. Naši eksperimenti pokazuju da uključenje aktivnih tehnika učenja u ovu cijev omogućava smanjiti potrebne napore tokom procesa, dok povećava kvalitet prevodnog sistema. Osim toga, to omogućava ravnotežu ljudskih napora potrebnih za ostvarivanje određene kvalitete prevoda. Osim toga, naš nervni sistem iznosi klasične pristupe velikom marginom.', 'fi': 'Tutkimme aktiivisten oppimistekniikoiden soveltamista rajattomien tietovirtojen k채채nt채miseen interaktiivisen neurokonek채채nn철ksen avulla. P채채ajatuksena on valita rajattomasta l채hdelausevirrasta ne, jotka ovat ihmisagentin valvonnan arvoisia. K채ytt채j채 k채채nt채채 n채m채 n채ytteet vuorovaikutteisesti. Validoituaan n채m채 tiedot ovat hy철dyllisi채 neurokonek채채nn철smallin mukauttamisessa. Ehdotamme kahta uutta menetelm채채 validoitavien n채ytteiden valintaan. Hy철dynn채mme tietoa neurokonek채채nn철sj채rjestelm채n huomiomekanismista. Kokeet osoittavat, ett채 aktiivisten oppimistekniikoiden sis채llytt채minen t채h채n putkistoon v채hent채채 prosessin aikana tarvittavaa ty철t채 ja parantaa k채채nn철sj채rjestelm채n laatua. Lis채ksi sen avulla voidaan tasapainottaa inhimillisi채 ponnisteluja tietyn k채채nn철slaadun saavuttamiseksi. Lis채ksi hermoj채rjestelm채mme suoriutuu klassisista l채hestymistavoista suurella marginaalilla.', 'jv': 'Awak dhéwé ngerti aplikasi karo teknik sing nggambar aturan kanggo tarjamahan karo perusahaan data sing gak nggawe tarjamahan lidé sing dipunangé, dadi uwong, dadi mbuluk obah-obahan sing paling, kuwi arep nggawe nguasakno karo ajan sing nguasakno. Sample Defs Awak dhéwé ngerasah sistem sing dibutuhke batir Awak dhéwé nggawe informasi ning titik karo sistem penting nggambar apakno. Awak dhéwé éntuk wong-wong kuwi, ngubah akeh tékno sing paling nggawe lan sistem sing bisa nyelehake nggawe barang nggawe barang nggawe sistem itoleh bantuan. Laptop" and "Desktop Nyong, sistem Nurasan sing paling nggambar kapan pawarane sakjane pancen ning murah sing apik.', 'he': 'We study the application of active learning techniques to the translation of unbounded data streams via interactive neural machine translation.  הרעיון העיקרי הוא לבחור, מתוך זרם לא מוגבל של משפטים מקורים, אלה ששווים להישגיח על ידי סוכן אנושי. המשתמש יתרגם את הדגימות האלה באופן אינטראקטיבי. ברגע שאושר, המידע הזה מועיל להסתגל למודל התרגום המכונה העצבית. אנו מציעים שתי שיטות חדשות לבחירה של הדגימות שנאמנות. אנו מנצלים את המידע מהמנגנון תשומת לב של מערכת תרגום מכונת עצבית. הניסויים שלנו מראים שהשילום של טכניקות לימוד פעילות לתוך צינור זה מאפשר להפחית את המאמץ הנדרש במהלך התהליך, בזמן שיעלה את איכות מערכת התרגום. חוץ מזה, זה מאפשר לאזן את המאמץ האנושי הנדרש כדי להשיג איכות התרגום מסוימת. חוץ מזה, מערכת העצבים שלנו מגבילה גישות קלאסיות על ידי גבול גדול.', 'ha': "Tuna karanta shirin ayuka na masu karatun masu karanta masu yiwuwa zuwa fassarar shirin ayuka na danne da ba'a bounci ba, a tsakanin tarjima masu tsakanin neural. Maɓan idãnar ta zama a zãɓe su daga wani marmaro wanda ba ta taɓa ba na da cire-marufu, wanda yana kasancẽwa a tsare su daga wani ajali na mutum. @ action: button @ info: whatsthis Tuna goyyar da hanyoyin biyu na node don mu zãɓi misali da za'a gaskata. Munã amfani da information daga ma'anar aikin muhalli na tsari na masu fassarar mashine na'ura. Our experiments show that the inclusion of active learning techniques into this pipeline allows to reduce the effort required during the process, while increasing the quality of the translation system.  Za iya iya cika kafin aikin mutum da aka buɗa wani sifar fassarar. Kayya, na'anar neuranmu na sami matsayi mai girma.", 'sk': 'Preučujemo uporabo tehnik aktivnega učenja pri prevajanju neomejenih podatkovnih tokov prek interaktivnega nevronskega strojnega prevajanja. Glavna ideja je, da izberemo iz neomejenega toka izvornih stavkov tiste, vredne nadzora človeškega agenta. Uporabnik bo interaktivno prevedel te vzorce. Ko so ti podatki potrjeni, so koristni za prilagoditev modela nevronskega strojnega prevajanja. Predlagamo dve novi metodi za izbiro vzorcev, ki jih je treba validirati. Izkoriščamo informacije iz mehanizma pozornosti nevronskega strojnega prevajanja. Naši eksperimenti kažejo, da vključitev tehnik aktivnega učenja v ta način omogoča zmanjšanje napora, potrebnega med procesom, hkrati pa povečanje kakovosti prevajalskega sistema. Poleg tega omogoča uravnoteženje človeškega truda, potrebnega za doseganje določene kakovosti prevajanja. Poleg tega naš živčni sistem veliko presega klasične pristope.', 'bo': 'ང་ཚོས་ལག་ལེན་འཐབ་པའི་ཤེས་འཇུག་ཐབས་ལམ་ལ་ལག་ལེན་འཐབ་བྱེད་ཀྱི་ཡོད་མེད་པའི་ཡིག་ཆ་འགྲུལ་བཙུགས་ཀྱི་སྤྱོད་ རྩ་བའི་བསམ་བློ་འདི་ནི་ཁྱད་ནས་འབྱུང་ཁུངས་ཀྱི་མིང་ཐང་ཆོས་ཀྱི་འགྱུར་བ་ཞིག་ནས་ལྟ་ཀློག་བྱེད་དགོས། སྤྱོད་མཁན་གྱི་དཔེར་བརྗོད་འདི་དག་ཚོས་འགོ་སློང་བྱེད་སྐབས དངོས་འཛུགས་བྱས་ཚར་བ་དང་ཐོག་ལས་ཆ་འཕྲིན་འདི་དག་གི་ལག་ལེན་འཐབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དཔེ་དབྱིབས་ཞིབ་དཔྱད་བྱེད་པར་གསར་བ་ཐབས་ལམ་གཉིས་བསམ་བྱེད། ང་ཚོས་རང་ཉིད་ཀྱི་མ་དངུལ་ལག་འཁྱེར་གྱི་སྒེར་གྱི་ལག་ཆས་གསལ་བཤད་ཀྱི་ལག་ལེན་འཐབ་ཡོད། Our experiments show that the inclusion of active learning techniques into this pipeline allows to reduce the effort required during the process, while increasing the quality of the translation system. ད་དུང་། འདིས་མིའི་སྐྱེས་ཆེན་ཉིད་ལ་ཉེན་མཁན་གྱི་ཐབས་ལམ་ཞིག་བདེ་འཇལ་རྒྱུ་དང་། ད་དུང་། ང་ཚོའི་ནུས་ཤུལ་མ་ལག་གིས་རྒྱུན་ལྡན་གྱི་གཟུགས་རིས་ཆེ་ཆུང'}
{'en': 'Churn Intent Detection in Multilingual Chatbot Conversations and ', 'ar': 'اكتشاف النية المتضخم في محادثات Chatbot متعددة اللغات ووسائل التواصل الاجتماعي', 'es': 'Detección de intención de abandono en conversaciones de chatbot multilingües y redes sociales', 'fr': "Détection de l'intention de désabonnement dans les conversations chatbot multilingues et les réseaux sociaux", 'pt': 'Detecção de intenção de churn em conversas multilíngues de chatbot e mídias sociais', 'hi': 'बहुभाषी चैटबॉट वार्तालापों और सामाजिक मीडिया में मंथन इरादा का पता लगाने', 'ja': '多言語チャットボット会話とソーシャルメディアでのチャーンインテント検出', 'zh': '多言聊天机器人对社交媒体流失意检', 'ru': 'Обнаружение оттока в многоязычных чат-ботах и социальных сетях', 'ga': 'Brath Intinn Churn i gComhrá Multilingual Chatbot agus ar na Meáin Shóisialta', 'hu': 'Churn Intent Detection többnyelvű chatbot beszélgetésekben és közösségi médiában', 'ka': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media', 'kk': 'Көптілік чатботтар және социаллық медиақтардағы Черн қажетті анықтау', 'el': 'Ανίχνευση προθέσεων σε πολυγλωσσικές συνομιλίες και μέσα κοινωνικής δικτύωσης', 'mk': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media', 'it': 'Rilevamento delle intenzioni di Churn nelle conversazioni Chatbot multilingue e nei social media', 'ml': 'Multilingual Chatbot Conversations and Social Media', 'mt': 'L-iskoperta tal-Intenzjoni tal-Knisja fil-Konverżjonijiet Multilingwi tal-Biċċiet ta’ Qattada u l-Midja Soċjali', 'lt': 'Bažnyčių ketinimų aptikimas daugiakalbėse kalbose ir socialinėje žiniasklaidoje', 'ms': 'Pengesanan niat Churn dalam perbualan berbincang berbilang bahasa dan Media Sosial', 'no': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media', 'pl': 'Wykrywanie intencji zmiany w wielojęzycznych rozmowach chatbotów i mediach społecznościowych', 'ro': 'Detectarea intenției Churn în conversațiile multilingve Chatbot și rețelele sociale', 'sr': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media', 'mn': 'Үүний олон хэлний Чатбот ярилцлагууд болон Нийгмийн Мэдээлэл', 'so': 'Shaqo xiriir ku saabsan luqadaha kala duduwan ee Chatbot iyo macluumaadka bulshada', 'ta': 'பல மொழி சாட்போட் பேச்சுகள் மற்றும் சமூக ஊடகங்களில் உள்ள கண்டுபிடிப்பு', 'si': 'Churn Intent Detection in Multilanguage ChatBot Conversations and Public Media', 'sv': 'Churn Intent Detection i flerspråkiga Chatbotkonversationer och sociala medier', 'ur': 'چند زبان کی چاٹ بوٹ کی باتوں اور سوسیل میڈیا میں چارن ایٹینٹ تلاش', 'uz': 'Name', 'vi': 'Mục đích dùng nhà thờ tại trò chat đa ngôn ngữ và phương tiện xã hội', 'bg': 'Откриване на намеренията на Чърн в многоезични чат ботове разговори и социални медии', 'nl': 'Detectie van churn intentie in meertalige chatbot gesprekken en sociale media', 'hr': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media', 'da': 'Churn Intent Detection i flersprogede Chatbot samtaler og sociale medier', 'id': 'Deteksi Ingatan Gereja dalam Bicara Bicara Berbahasa dan Media Sosial', 'de': 'Erkennung von Churn Intent in mehrsprachigen Chatbot-Konversationen und Social Media', 'ko': '다국어 채팅 로봇 대화와 소셜미디어에서의 유실 의도 검출', 'tr': 'Çoklu dilli Çatbot gürleşmelerinde we sosial Maglumaty', 'fa': 'کشف هوشمندانه چارن در صحبت های چند زبان و رسانه های اجتماعی', 'sw': 'Kuchunguza Kitaarifa katika mazungumzo ya lugha mbalimbali na vyombo vya habari vya kijamii', 'af': 'Churn Intent Deteksie in Multilingual Chatbot Conversations and Social Media', 'sq': 'Zbulimi i synimeve të kishës në bisedimet e bisedës shumëgjuhëse dhe mediat sociale', 'am': 'ብዙ ቋንቋ ቻጥቦት ንግግር እና ማኅበራዊ ሚዲያ', 'az': 'Çoxlu dilli Chatbot Konuşmalarında və Sosyal Mediyalarında Churn Intent Detection', 'hy': 'Չեկեղեցիների մտադրությունը բազլեզու խոսակցություններում և սոցիալական լրատվամիջոցներում', 'bn': 'বহুভাষী চ্যাটবট আলোচনা এবং সামাজিক মিডিয়ায় চার্ন ইন্টেন্ট সন্ধান', 'bs': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media', 'cs': 'Detekce záměrů Churn ve vícejazyčných chatbotových konverzacích a sociálních médiích', 'et': 'Churn kavatsuse tuvastamine mitmekeelsetes jutubotide vestlustes ja sotsiaalmeedias', 'fi': 'Churn Intent Detection monikielisissä chatbot-keskusteluissa ja sosiaalisessa mediassa', 'ca': "Detecció de l'intenció de Churn en converses multilingües de conversa i mitjans socials", 'jv': 'Al-Nah Kasama Delah Karo Multi-Linguke Talkbot karo Multi-Linguke Media', 'he': 'גילוי כוונה של הכנסייה בשיחות שיחה רבות שפות ומדיה חברתית', 'sk': 'Zaznavanje namena Churn v večjezičnih klepetalnih pogovorih in socialnih medijih', 'ha': '@ item Text character set', 'bo': 'Churn Intent Detection in Multilingual Chatbot Conversations and Social Media'}
{'en': 'We propose a new method to detect when users express the intent to leave a service, also known as churn. While previous work focuses solely on ', 'ar': 'نقترح طريقة جديدة لاكتشاف الوقت الذي يعبر فيه المستخدمون عن نية ترك خدمة ما ، تُعرف أيضًا باسم churn. بينما يركز العمل السابق فقط على وسائل التواصل الاجتماعي ، نظهر أنه يمكن اكتشاف هذه النية في محادثات chatbot. نظرًا لأن الشركات تعتمد بشكل متزايد على روبوتات المحادثة ، فإنها تحتاج إلى نظرة عامة على المستخدمين الذين يحتمل أن يكونوا مزعجين. تحقيقا لهذه الغاية ، نحن نجمع وننشر مجموعة بيانات من تعبيرات النية المتضاربة في تفاعلات chatbot باللغتين الألمانية والإنجليزية. نظهر أن المصنفين المدربين على بيانات الوسائط الاجتماعية يمكنهم اكتشاف نفس الهدف في سياق روبوتات المحادثة. نقدم بنية تصنيف تتفوق في الأداء على العمل الحالي في الكشف عن نية الزخم في وسائل التواصل الاجتماعي. علاوة على ذلك ، نظهر أنه باستخدام حفلات الزفاف ثنائية اللغة ، يتفوق نظام تم تدريبه على البيانات الإنجليزية والألمانية مجتمعة على الأساليب أحادية اللغة. نظرًا لأن مجموعة البيانات الوحيدة الموجودة باللغة الإنجليزية ، فإننا نجمع المصادر وننشر مجموعة بيانات جديدة من التغريدات الألمانية. وبالتالي فإننا نؤكد على الجانب العام للمشكلة ، حيث تساعدنا الأمثلة على النية المتضاربة في اللغة الإنجليزية في تحديد الاضطراب في التغريدات الألمانية ومحادثات chatbot.', 'es': 'Proponemos un nuevo método para detectar cuándo los usuarios expresan la intención de abandonar un servicio, también conocido como abandono. Si bien el trabajo anterior se centra únicamente en las redes sociales, demostramos que esta intención se puede detectar en las conversaciones de los chatbots. A medida que las empresas confían cada vez más en los chatbots, necesitan una visión general de los usuarios potencialmente abandonados. Con este fin, hacemos crowdsourcing y publicamos un conjunto de datos de expresiones de intención de abandono en las interacciones de chatbot en alemán e inglés. Demostramos que los clasificadores entrenados en datos de redes sociales pueden detectar la misma intención en el contexto de los chatbots. Presentamos una arquitectura de clasificación que supera el trabajo existente sobre la detección de intención de abandono en las redes sociales. Además, demostramos que, al usar incrustaciones de palabras bilingües, un sistema entrenado en datos combinados en inglés y alemán supera a los enfoques monolingües. Como el único conjunto de datos existente está en inglés, hacemos crowdsourcing y publicamos un conjunto de datos novedoso de tuits alemanes. Por lo tanto, subrayamos el aspecto universal del problema, ya que los ejemplos de intención de abandono en inglés nos ayudan a identificar el abandono en tuits y conversaciones de chatbots alemanes.', 'fr': "Nous proposons une nouvelle méthode pour détecter le moment où les utilisateurs expriment leur intention de quitter un service, également appelée désabonnement. Alors que les travaux précédents se concentraient uniquement sur les réseaux sociaux, nous montrons que cette intention peut être détectée dans les conversations avec les chatbots. Alors que les entreprises font de plus en plus appel aux chatbots, elles ont besoin d'une vue d'ensemble des utilisateurs potentiellement dés À cette fin, nous soutenons et publions un ensemble de données d'expressions d'intention de désabonnement dans les interactions avec les chatbots en allemand et en anglais. Nous montrons que les classificateurs formés sur les données des réseaux sociaux peuvent détecter la même intention dans le contexte des chatbots. Nous introduisons une architecture de classification qui surpasse les travaux existants sur la détection des intentions de désabonnement sur les réseaux sociaux. De plus, nous montrons qu'en utilisant des intégrations de mots bilingues, un système formé sur des données combinées en anglais et en allemand surpasse les approches monolingues. Comme le seul jeu de données existant est en anglais, nous publions un nouveau jeu de données de tweets allemands. Nous soulignons donc l'aspect universel du problème, car des exemples d'intention de désabonnement en anglais nous aident à identifier le taux de désabonnement dans les tweets allemands et les conversations avec des chatbots.", 'pt': 'Propomos um novo método para detectar quando os usuários expressam a intenção de deixar um serviço, também conhecido como churn. Embora os trabalhos anteriores se concentrem apenas nas mídias sociais, mostramos que essa intenção pode ser detectada nas conversas do chatbot. À medida que as empresas confiam cada vez mais nos chatbots, elas precisam de uma visão geral dos usuários potencialmente agitados. Para isso, fazemos crowdsourcing e publicamos um conjunto de dados de expressões de intenção de churn em interações de chatbot em alemão e inglês. Mostramos que classificadores treinados em dados de mídias sociais podem detectar a mesma intenção no contexto de chatbots. Apresentamos uma arquitetura de classificação que supera o trabalho existente na detecção de intenção de churn nas mídias sociais. Além disso, mostramos que, usando embeddings de palavras bilíngues, um sistema treinado em dados combinados de inglês e alemão supera abordagens monolíngues. Como o único conjunto de dados existente está em inglês, fazemos crowdsourcing e publicamos um novo conjunto de dados de tweets alemães. Destacamos, assim, o aspecto universal do problema, pois exemplos de intenção de churn em inglês nos ajudam a identificar o churn em tweets alemães e conversas de chatbot.', 'ja': 'Churnとも呼ばれる、ユーザーがサービスを終了する意図を表明したときに検出する新しい方法を提案します。 以前の作業はソーシャルメディアのみに焦点を当てていましたが、この意図はチャットボットの会話で検出できることを示しています。 企業がますますチャットボットに依存するようになるにつれて、潜在的にチャーニーユーザーの概要が必要になります。 そのために、ドイツ語と英語のチャットボットインタラクションにおけるチャーンインテント表現のデータセットをクラウドソーシングして公開しています。 ソーシャルメディアデータに関する訓練を受けた分類子が、チャットボットのコンテキストで同じ意図を検出できることを示しています。 ソーシャルメディアでのチャーンインテント検出に関する既存の作業を上回る分類アーキテクチャを紹介します。 さらに、私たちは、バイリンガルの単語埋め込みを使用して、英語とドイツ語のデータの組み合わせでトレーニングされたシステムが、単一言語のアプローチよりも優れていることを示しています。 現存する唯一のデータセットは英語であるため、ドイツ語のツイートの新規データセットをクラウドソーシングして公開しています。 したがって、英語のチャーンインテントの例は、ドイツ語のツイートやチャットボットの会話でチャーンを識別するのに役立つため、問題の普遍的な側面を強調しています。', 'zh': '新法以检之用户何时致去就之意,亦谓之流失。 虽前事惟社交媒体,此意聊机器人检。 随公司益赖聊天机器人,须概述于潜用户。 为此众包发一德语英语聊天机器人交失意图表达式数集。 臣等明社交媒体数训练之类器可以聊天机器人上下文中检测同意。 引入一架构,其性优于社交媒体中流检。 此外,明双语词嵌入,英语德语数组,优于单语法。 唯一见数集是英文,众包发一新德国推文数集。 是以强其普遍性,英语其流失意图示例有助于识德语推文聊天机器人语之失也。', 'hi': 'हम यह पता लगाने के लिए एक नई विधि का प्रस्ताव करते हैं कि उपयोगकर्ता किसी सेवा को छोड़ने के इरादे को व्यक्त करते हैं, जिसे मंथन के रूप में भी जाना जाता है। जबकि पिछला काम पूरी तरह से सोशल मीडिया पर केंद्रित है, हम दिखाते हैं कि इस इरादे को चैटबॉट वार्तालापों में पता लगाया जा सकता है। जैसा कि कंपनियां तेजी से चैटबॉट्स पर भरोसा करती हैं, उन्हें संभावित मंथन उपयोगकर्ताओं के अवलोकन की आवश्यकता होती है। इस अंत के लिए, हम crowdsource और जर्मन और अंग्रेजी में chatbot इंटरैक्शन में मंथन इरादा अभिव्यक्तियों का एक डेटासेट प्रकाशित करते हैं। हम दिखाते हैं कि सोशल मीडिया डेटा पर प्रशिक्षित क्लासिफायर चैटबॉट्स के संदर्भ में एक ही इरादे का पता लगा सकते हैं। हम एक वर्गीकरण वास्तुकला पेश करते हैं जो सोशल मीडिया में मंथन इरादे का पता लगाने पर मौजूदा काम को मात देता है। इसके अलावा, हम दिखाते हैं कि, द्विभाषी शब्द एम्बेडिंग का उपयोग करके, संयुक्त अंग्रेजी और जर्मन डेटा पर प्रशिक्षित एक प्रणाली मोनोलिंगुअल दृष्टिकोण से बेहतर प्रदर्शन करती है। चूंकि एकमात्र मौजूदा डेटासेट अंग्रेजी में है, इसलिए हम जर्मन ट्वीट्स का एक उपन्यास डेटासेट क्राउडसोर्स और प्रकाशित करते हैं। इस प्रकार हम समस्या के सार्वभौमिक पहलू को रेखांकित करते हैं, क्योंकि अंग्रेजी में मंथन के इरादे के उदाहरण हमें जर्मन ट्वीट्स और चैटबॉट वार्तालापों में मंथन की पहचान करने में मदद करते हैं।', 'ru': 'Мы предлагаем новый метод обнаружения, когда пользователи выражают намерение выйти из сервиса, также известный как отток. В то время как предыдущая работа сосредоточена исключительно на социальных сетях, мы показываем, что это намерение может быть обнаружено в разговорах чат-ботов. По мере того, как компании все больше полагаются на чат-ботов, им необходим обзор потенциально отторгаемых пользователей. С этой целью мы краудсорсинг и публикуем набор данных о намерениях оттока в взаимодействии с чат-ботами на немецком и английском языках. Мы показываем, что классификаторы, обученные данным социальных сетей, могут обнаружить такое же намерение в контексте чат-ботов. Мы вводим классификационную архитектуру, которая превосходит существующую работу по обнаружению намерений оттока в социальных сетях. Более того, мы показываем, что, используя двуязычные вложения слов, система, обученная комбинированным английским и немецким данным, превосходит одноязычные подходы. Поскольку единственный существующий набор данных на английском языке, мы краудсорсинг и опубликовать новый набор данных немецких твитов. Таким образом, мы подчеркиваем универсальный аспект проблемы, поскольку примеры намерения оттока на английском языке помогают нам идентифицировать отток в немецких твитах и разговорах чат-ботов.', 'ga': 'Molaimid modh nua chun a bhrath nuair a chuireann úsáideoirí in iúl go bhfuil siad ar intinn acu seirbhís a fhágáil, ar a dtugtar churn freisin. Cé go ndíríonn obair roimhe seo ar na meáin shóisialta amháin, léirímid gur féidir an rún seo a bhrath i gcomhráite chatbot. De réir mar a bhíonn cuideachtaí ag brath níos mó ar chatbots tá forbhreathnú de dhíth orthu ar úsáideoirí a d’fhéadfadh a bheith maolaithe. Chuige sin, déanaimid sluafhoinsiú agus foilseoimid tacar sonraí de nathanna rúin chun cinn in idirghníomhaíochtaí chatbot i nGearmáinis agus i mBéarla. Léirímid gur féidir le haicmitheoirí atá oilte ar shonraí meán sóisialta an rún céanna a bhrath i gcomhthéacs chatbots. Tugaimid isteach ailtireacht aicmithe a sháraíonn an obair atá ar bun faoi láthair ar bhrath rún maisteoige sna meáin shóisialta. Ina theannta sin, léirímid, agus úsáid á baint againn as leabú focal dátheangach, go sáraíonn córas atá oilte ar shonraí comhcheangailte Béarla agus Gearmáinise cur chuige aonteangach. Toisc gur i mBéarla atá an t-aon tacar sonraí atá ann cheana féin, déanaimid sluafhoinsiú agus foilsímid tacar sonraí nua de thvuíteanna Gearmánacha. Mar sin leagaimid béim ar ghné uilíoch na faidhbe, mar go gcabhraíonn samplaí de rún churn i mBéarla linn churn i tweets Gearmánacha agus comhráite chatbot a aithint.', 'el': 'Προτείνουμε μια νέα μέθοδο για τον εντοπισμό πότε οι χρήστες εκφράζουν την πρόθεση να εγκαταλείψουν μια υπηρεσία, γνωστή και ως ανατροπή. Ενώ η προηγούμενη εργασία επικεντρώνεται αποκλειστικά στα μέσα κοινωνικής δικτύωσης, δείχνουμε ότι αυτή η πρόθεση μπορεί να ανιχνευθεί σε συζητήσεις chatbot. Καθώς οι εταιρείες όλο και περισσότερο βασίζονται στα χρειάζονται μια επισκόπηση των δυνητικά μεταβαλλόμενων χρηστών. Για το σκοπό αυτό, δημοσιεύουμε ένα σύνολο δεδομένων εκφράσεων προθέσεων ανατροπής σε αλληλεπιδράσεις στα γερμανικά και τα αγγλικά. Δείχνουμε ότι οι ταξινομητές εκπαιδευμένοι σε δεδομένα κοινωνικών μέσων μπορούν να εντοπίσουν την ίδια πρόθεση στο πλαίσιο των chatbots. Εισάγουμε μια αρχιτεκτονική ταξινόμησης που ξεπερνά την υπάρχουσα εργασία σχετικά με την ανίχνευση προθέσεων ανατροπής στα μέσα κοινωνικής δικτύωσης. Επιπλέον, καταδεικνύουμε ότι, χρησιμοποιώντας δίγλωσσες ενσωματώσεις λέξεων, ένα σύστημα εκπαιδευμένο σε συνδυασμένα αγγλικά και γερμανικά δεδομένα ξεπερνά τις μονογλωσσικές προσεγγίσεις. Καθώς το μόνο υπάρχον σύνολο δεδομένων είναι στα αγγλικά, δημοσιεύουμε ένα νέο σύνολο δεδομένων γερμανικών tweets. Έτσι υπογραμμίζουμε την καθολική πτυχή του προβλήματος, καθώς παραδείγματα προθέσεων ανατροπής στα αγγλικά μας βοηθούν να εντοπίσουμε την ανατροπή σε γερμανικά tweets και συζητήσεις chatbot.', 'ka': 'ჩვენ ახალი მეთოდი დავიწყებთ, როდესაც მომხმარებელი გამოსახულებენ სერვისის გადატოვება, რომელსაც უკეთესია. წინა სამუშაო სამუშაო მხოლოდ სოციალური მედიაზე, ჩვენ აჩვენებთ, რომ ეს სამუშაო შესაძლებელია გააკვირთოთ კატბოტის პარაუხში. როგორც კომპონიაციები უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად მომხმარებისთვის იჭირდება. ამ მიზეზით, ჩვენ მსოფლიოს გამოსახულება და დავწერეთ მონაცემების საზოგადო გამოსახულება გერმანეთში და ინგლისში. ჩვენ ჩვენ აჩვენებთ, რომ სოციალური მედია მონაცემების კლასიფიკაციები შეიძლება იგივე საზოგადომის შესაძლებლობა ჩაღმოჩენა. ჩვენ კლასიფიკაციის არქტიქტურაციას ჩვენ ჩვენ გავაჩვენებთ, რომელიც სოციალური მედიაში არსებობს მუშაობაში მუშაობაში მუშაობაში საქმე სა დამატებით, ჩვენ ჩვენ აჩვენებთ, რომ ორიენგური სიტყვების გამოყენება, სისტემა, რომელიც კომბიცირებული ანგლისური და გერმანური მონაცემების შესახებ მონოლენგ როგორც ერთადერთი მსგავსი მონაცემები ინგლისურად არიან, ჩვენ მუშაობით და პოგლიკურად გერმანეთის რვიტების პრომენტური მონაცემების კონ ამიტომ ჩვენ პრობლემის универсаლური აპექტიკის გამოსახულებით, როგორც ჩვენ ინგლისური საზოგადოების გამოსახულებით დაგვეხმარებთ ჩვენ უფროს გერმანური რვიტებში და სა', 'it': "Proponiamo un nuovo metodo per rilevare quando gli utenti esprimono l'intenzione di lasciare un servizio, noto anche come churn. Mentre i lavori precedenti si concentrano esclusivamente sui social media, mostriamo che questo intento può essere rilevato nelle conversazioni chatbot. Poiché le aziende si affidano sempre più ai chatbot, hanno bisogno di una panoramica degli utenti potenzialmente churny. A tal fine, crowdsource e pubblichiamo un dataset di espressioni di intenti churn nelle interazioni chatbot in tedesco e inglese. Mostriamo che i classificatori formati sui dati dei social media possono rilevare lo stesso intento nel contesto dei chatbot. Introducemo un'architettura di classificazione che supera il lavoro esistente sul rilevamento degli intenti churn nei social media. Inoltre, mostriamo che, utilizzando l'incorporazione bilingue di parole, un sistema addestrato su dati combinati inglese e tedesco supera gli approcci monolingue. Poiché l'unico set di dati esistente è in inglese, crowdsource e pubblichiamo un nuovo set di dati di tweet tedeschi. Sottolineiamo quindi l'aspetto universale del problema, come esempi di churn intent in inglese ci aiutano a identificare churn nei tweet tedeschi e nelle conversazioni chatbot.", 'hu': 'Javasolunk egy új módszert annak felismerésére, hogy a felhasználók mikor fejezik ki a szolgáltatás elhagyására irányuló szándékot, más néven churn. Míg a korábbi munkák kizárólag a közösségi médiára összpontosítanak, megmutatjuk, hogy ez a szándék észlelhető a chatbot beszélgetésekben. Mivel a vállalatok egyre inkább a chatbotokra támaszkodnak, áttekintésre van szükségük a potenciálisan barátságos felhasználókról. Ennek érdekében német és angol nyelven közösen forrásként és közzéteszünk egy adatkészletet a chatbot interakciókban. Megmutatjuk, hogy a közösségi média adataira képzett osztályozók ugyanazt a szándékot észlelik a chatbotok kontextusában. Bevezetünk egy olyan osztályozási architektúrát, amely felülmúlja a meglévő munkát a közösségi médiában. Ezenkívül azt is mutatjuk, hogy a kétnyelvű szóbeágyazások használatával egy kombinált angol és német adatokra képzett rendszer felülmúlja az egynyelvű megközelítéseket. Mivel az egyetlen meglévő adatkészlet angol nyelvű, közösségi forrásként és publikálunk egy új adatkészletet német tweetekből. Ezért hangsúlyozzuk a probléma univerzális aspektusát, mivel az angol nyelvű churn intention példái segítenek felismerni a churnt a német tweetekben és chatbot beszélgetésekben.', 'kk': 'Біз пайдаланушылардың қызметті қайта қалдыру мақсатын көрсету үшін жаңа әдісін таңдаймыз. Алдыңғы жұмыс жалғыз социалдық медиаға аударып тұрғанда, бұл мақсатты сөйлейтінде табу мүмкіндігін көрсетеді. Компаниялардың шатботтарына сенімді болғанда, олар мүмкіндік пайдаланушылардың көзі қажет. Бұл үшін біз неміс және ағылшын тіліндегі шатботтың интерфейсінде деректер жиынын көпшілік және көпшіліктерді жасап шығармыз. Біз социалдық медиақпарат деректерінде оқылған классификациялардың шатботтардың контексті бірдей мақсатты анықтауға болады. Біз социалдық медиақтарды табу үшін барлық жұмыс істейтін классификациялық архитектурасын таңдаймыз. Қосымша, біз екі тілі сөздерді ендіру үшін ағылшын және неміс деректерінің біріктірілген жүйесі біріктірілген мәліметтерінің бірнеше тілік жағдайларына арналған. Бұл жалғыз деректер жиыны ағылшын тілінде тұрғанда, біз неміс tweets тілінің романдық деректер жиынын басып шығармыз. Біз бұл мәселедің әлемдік аспектін түсіндіреміз, ағылшын тіліндегі мәселелердің мысалдар болып, неміс tweets мен шатбот сөйлесуді анықтауға көмектеседі.', 'mk': 'Предложуваме нов метод за детектирање кога корисниците ја изразуваат намерата да ја напуштат услугата, позната и како Чарн. Додека претходната работа се фокусира само на социјалните медиуми, покажуваме дека оваа намера може да се детектира во разговорите со chatbot. Со оглед на тоа што компаниите сé повеќе се потпираат на чатботи им треба преглед на потенцијално црните корисници. За оваа цел, ние пулсорсираме и објавуваме податоци за изрази на црни намери во интеракциите на chatbot на германски и англиски. Ние покажуваме дека класификаторите обучени на податоци од социјалните медиуми можат да ја откријат истата намера во контекст на chatbots. Ние воведуваме класификациска архитектура која ја надминува постоечката работа на детективирање на црни намери во социјалните медиуми. Покрај тоа, покажуваме дека со користење на двојјазични зборови, системот обучен на комбинирани англиски и германски податоци ги надминува монојазичните пристапи. Бидејќи единствениот постоечки датотек е на англиски, ние пулсорсираме и објавуваме нов датотек на германски твитови. Така го истакнуваме универзалниот аспект на проблемот, бидејќи примерите на црни намери на англиски ни помагаат да го идентификуваме црниот на германски твитови и разговори со чатботи.', 'lt': 'Siūlome naują metodą nustatyti, kada naudotojai išreiškia ketinimą palikti paslaugą, taip pat žinomą kaip churn. Nors ankstesniame darbe daugiausia dėmesio skiriama tik socialinei žiniasklaidai, mes rodome, kad šį ketinimą galima aptikti pokalbiuose su chatbotais. Kadangi bendrovės vis labiau pasikliauja chatbotais, joms reikia apžvalgos apie potencialiai apskritus naudotojus. Šiuo tikslu mes sukuriame ir skelbiame duomenų rinkinį, kuriame pateikiami švenčiamųjų ketinimų išraiškos kalbant vokiečių ir anglų kalbomis. Mes rodome, kad social in ės žiniasklaidos duomenimis apmokyti klasifikatoriai gali aptikti tą patį ketinimą kalbant apie chatbotus. Įdiegiame klasifikavimo architektūrą, kuri yra didesnė už dabartinį darbą, susijusią su sąmoningumo nustatymu social in ėje žiniasklaidoje. Be to, mes rodome, kad naudojant dvikalbį žodžių įterpimą, sistema, mokoma bendrais anglų ir vokiečių duomenimis, yra didesnė už vienkalbį metodą. Kadangi vienintelis esamas duomenų rinkinys yra anglų kalba, mes crowdsource ir skelbiame naują duomenų rinkinį vokiečių tweetų. Taigi mes pabrėžiame visuotinį problemos aspektą, nes anglų kalba skirtų mėšlų pavyzdžiai padeda mums nustatyti mėšlą vokiečių tweetuose ir pokalbiuose su chatbotais.', 'ms': 'Kami cadangkan cara baru untuk mengesan apabila pengguna mengekspresikan niat untuk meninggalkan perkhidmatan, juga dikenali sebagai churn. Sementara kerja terdahulu hanya fokus pada media sosial, kami menunjukkan bahawa niat ini boleh dikesan dalam perbualan chatbot. Sebagai syarikat semakin bergantung pada chatbot mereka memerlukan pandangan ringkasan pengguna yang berpotensi churny. Untuk ini, kami crowdsource dan menerbitkan set data ungkapan niat churn dalam interaksi chatbot dalam bahasa Jerman dan Inggeris. Kami menunjukkan bahawa pengklasifikasi dilatih pada data media sosial boleh mengesan niat yang sama dalam konteks chatbot. We introduce a classification architecture that outperforms existing work on churn intent detection in social media.  Selain itu, kami menunjukkan bahawa, menggunakan penyembedding perkataan dua bahasa, sistem dilatih pada data Inggeris dan Jerman bergabung melampaui pendekatan monobahasa. Sebab satu-satunya set data yang wujud adalah dalam bahasa Inggeris, kami crowdsource dan menerbitkan set data novel dari tweet Jerman. Oleh itu, kita menandakan aspek universal masalah ini, sebagai contoh niat keras dalam bahasa Inggeris membantu kita mengenali keras dalam tweet Jerman dan perbualan chatbot.', 'no': 'Vi foreslår ein ny metode å oppdaga når brukarar uttrykker vilkåret å lagra ein tenest, også kjent som kirk. Mens det førre arbeidet fokuserer berre på sosiale media, viser vi at dette målet kan oppdagast i samtaler med samtaler. Som selskapene større betre på pratbottar treng dei ei oversikt over potensielt kirke brukarar. I denne slutten publiserer vi ein dataset med mørke uttrykk i samtale med samtaler i tysk og engelsk. Vi viser at klassifikatorane trengte på sosiale media-data kan oppdaga det same intensjonen i sambandet med samtaler. Vi introduserer ein klassifikasjonsarkitektur som utfører eksisterande arbeid på mørk-utforming i sosiale medier. I tillegg viser vi at, ved bruk av bilinguelt ordinnbygging, er eit systemet trent på kombinerte engelsk og tysk data utført monospråk. Som det eneste eksisterande datasettet er i engelsk, er vi tilfelle og publiserer ei roman datasett av tyske tweeter. Vi understrekar derfor den universelle aspekten av problemet, som eksemplar for mørke i engelsk hjelper oss å identifisera mørke i tyske tweeter og samtaler.', 'ml': 'ഉപയോക്താക്കള്\u200d ഒരു സേവനത്തെ വിട്ടുപോകാനുള്ള ഉദ്ദേശം പ്രസ്താവിക്കുമ്പോള്\u200d പുതിയ ഒരു രീതി മുമ്പുള്ള ജോലി മാത്രം സാമൂഹിക മീഡിയില്\u200d മാത്രം ശ്രദ്ധിക്കുമ്പോള്\u200d നമ്മള്\u200d കാണിക്കുന്നു ഈ ലക്ഷ്യം ചട കമ്പനികള്\u200d കൂടുതല്\u200d ആശ്രയിച്ചുകൊണ്ടിരിക്കുന്ന ചട്ട്ബോട്ടുകളില്\u200d അവര്\u200dക്ക് സാധ്യതയുള്ള ഉപയോക്താക്കളുടെ ഒരു  ഈ അവസാനത്തിനു വേണ്ടി നമ്മള്\u200d പ്രധാന വിവരങ്ങള്\u200d പ്രസിദ്ധീകരിക്കുന്നു. ജര്\u200dമ്മനിലെയും ഇംഗ്ലീഷിലെയും ചാട്ട്ബോട We show that classifiers trained on social media data can detect the same intent in the context of chatbots.  നിലവിലുള്ള ജോലി പ്രവര്\u200dത്തിപ്പിക്കുന്ന ഒരു ക്ലാസ്ഫിക്കല്\u200d ആര്\u200dക്കറ്റിക്കേറ്റര്\u200d നാം പരിചയപ്പെടുത്തുന്നു. സ അതുകൊണ്ട്, നമ്മള്\u200d കാണിക്കുന്നു, രണ്ടു ഭാഷ വാക്കുകള്\u200d ഉപയോഗിച്ച്, ഇംഗ്ലീഷിലും ജര്\u200dമ്മന്\u200d വിവരങ്ങളിലും കൂട്ടിചേര്\u200dത്ത് ഒര നിലവിലുള്ള ഡാറ്റാസെറ്റ് ഇംഗ്ലീഷില്\u200d മാത്രമാണെങ്കില്\u200d, നമ്മള്\u200d പ്രധാനസ്സോര്\u200dസ് പ്രസിദ്ധീകരിക്കു അതുകൊണ്ട് നമ്മള്\u200d പ്രശ്നത്തിന്\u200dറെ പ്രപഞ്ചത്തിന്\u200dറെ പ്രപഞ്ച ഭാഗങ്ങളിലേക്ക് താഴ്ത്തുന്നു. ഇംഗ്ലീഷിലെ കഠിനമായ ഉദാഹരണങ്', 'mn': 'Бид хэрэглэгчид хэрэглэгчдийн үйл ажиллагаагаа үлдээх зорилго хэрэглэх шинэ арга зам зааж өгдөг. Өмнөх ажил нь нийгмийн мэдээлэл дээр зөвхөн төвлөрсөн ч, бид энэ зорилго нь ярилцлаганд олох боломжтой гэдгийг харуулж байна. Компаниуд чадвар дээр нэмэгдэж байгаа учраас тэд магадгүй цөмийн хэрэглэгчдийн талаар ойлгох хэрэгтэй. Үүний тулд бид Герман болон Англи хэлний харилцааны тухай өгөгдлийн санаануудыг олон нийтэд хэвлэж байна. Бид нийгмийн хэвлэлийн мэдээлэл дээр сургалтын классификаторууд яг ижил зорилго шалгалтын тухай олж чадна гэдгийг харуулж байна. Бид нийгмийн мэдээллийн хэрэглээнд сууж байгаа ажлыг нээлттэй болгодог ангилалын архитектурыг танилцуулдаг. Мөн бид хоёр хэл хэлний нэвтрүүлэлтийг ашиглан Англи болон Германы мэдээллийн тухай сургалтын систем нь ганц хэлний аргачлалуудыг дамжуулдаг. Бид цорын ганц өгөгдлийн санг Англи хэлний хэлний хувьд Германы tweets-ийн шинэ өгөгдлийн санг нийлүүлж байна. Иймээс бид асуудлын ерөнхийлөгчийн асуудлыг, Англи хэлний шинжлэх ухааны жишээ болгон Германы tweets болон ярилцлагуудыг тодорхойлох тулд тусалдаг.', 'mt': 'We propose a new method to detect when users express the intent to leave a service, also known as churn.  Filwaqt li x-xogħol preċedenti jiffoka biss fuq il-mezzi tax-xandir soċjali, nagħmlu evidenza li dan l-intenzjoni tista’ tinstab fi konverżjonijiet chatbot. Hekk kif il-kumpaniji qed jiddependu dejjem aktar fuq chatbots, jeħtieġu ħarsa ġenerali lejn utenti potenzjalment qarrieqa. Għal dan il-għan, nagħmlu crowdsource u nippubblikaw sett ta’ dejta ta’ espressjonijiet ta’ intenzjoni churn f’interazzjonijiet chatbot bil-Ġermaniż u bl-Ingliż. Aħna nuru li klassifikaturi mħarrġa fuq dejta tal-midja soċjali jistgħu jidentifikaw l-istess intenzjoni fil-kuntest tal-chatbots. Aħna nintroduċu arkitettura ta’ klassifikazzjoni li twettaq ħidma eżistenti dwar l-iskoperta tal-intenzjoni ta’ churn fil-midja soċjali. Barra minn hekk, nuru li, bl-użu ta’ inkorporazzjonijiet billingwi ta’ kliem, sistema mħarrġa fuq dejta kkombinata Ingliża u Ġermaniża tirriżulta minn approċċi monolingwi. Billi l-uniku sett ta’ dejta eżistenti huwa bl-Ingliż, a ħna niġbru flimkien u nippubblikaw sett ta’ dejta ġdid ta’ tweets Ġermaniżi. Għaldaqstant, aħna ninfasizzaw l-aspett universali tal-problema, bħala eżempji ta’ intenzjoni ta’ churn bl-Ingliż jgħinuna nidentifikaw churn fit-tweets Ġermaniżi u l-konversazzjonijiet chatbot.', 'pl': 'Proponujemy nową metodę wykrywania, kiedy użytkownicy wyrażają zamiar opuszczenia usługi, znaną również jako churn. Podczas gdy poprzednie prace koncentrują się wyłącznie na mediach społecznościowych, pokazujemy, że intencja ta można wykryć w rozmowach chatbotów. Ponieważ firmy coraz częściej polegają na chatbotach, potrzebują przeglądu potencjalnie zmiennych użytkowników. W tym celu publikujemy zbiór danych wyrażeń intencji zmiany w interakcjach chatbotów w języku niemieckim i angielskim. Pokazujemy, że klasyfikatory przeszkolone na danych mediów społecznościowych potrafią wykryć ten sam zamiar w kontekście chatbotów. Wprowadzamy architekturę klasyfikacji, która przewyższa istniejące prace nad wykrywaniem intencji zmiany w mediach społecznościowych. Ponadto pokazujemy, że przy użyciu dwujęzycznych osadzeń słów system przeszkolony na połączeniu danych angielskich i niemieckich przewyższa podejścia jednojęzyczne. Ponieważ jedyny istniejący zbiór danych jest w języku angielskim, publikujemy crowdsource i publikujemy nowy zestaw danych niemieckich tweetów. Podkreślamy zatem uniwersalny aspekt problemu, ponieważ przykłady intencji zmiany w języku angielskim pomagają nam zidentyfikować zmiany w niemieckich tweetach i rozmowach chatbotów.', 'ro': 'Propunem o nouă metodă de detectare a momentului în care utilizatorii își exprimă intenția de a părăsi un serviciu, cunoscută și sub numele de churn. În timp ce lucrările anterioare se concentrează exclusiv pe social media, arătăm că această intenție poate fi detectată în conversațiile chatbot. Deoarece companiile se bazează din ce în ce mai mult pe chatbots, au nevoie de o imagine de ansamblu asupra utilizatorilor potențial churny. În acest scop, colectăm și publicăm un set de date de expresii de intenție churn în interacțiunile chatbot în germană și engleză. Noi arătăm că clasificatorii instruiți pe datele rețelelor de socializare pot detecta aceeași intenție în contextul chatboților. Introducem o arhitectură de clasificare care depășește lucrările existente privind detectarea intențiilor churn în rețelele sociale. Mai mult decât atât, demonstrăm că, utilizând încorporări bilingve de cuvinte, un sistem instruit pe date combinate în limba engleză și germană depășește abordările monolingve. Deoarece singurul set de date existent este în limba engleză, publicăm un set de date nou de tweet-uri germane. Astfel, subliniem aspectul universal al problemei, deoarece exemplele de intenție churn în limba engleză ne ajută să identificăm churn în tweeturile germane și conversațiile chatbot.', 'si': 'අපි අලුත් විධානයක් හොයාගන්න ප්\u200dරයෝජකයෝ සර්වේශයක් නිදහස් කරනවා කියලා, චර්න් කියලා දන්නවා. මුලින් වැඩේ සාමාජික මාධ්\u200dයමයේ විතරයි, අපි පෙන්වන්නේ මේ අදහස් විතරයි චැට්බෝට් කතාවක් වලින් හො සමාගම් විශ්වාස කරන්නේ චැට්බෝට් වලින් ඔවුන්ට ප්\u200dරශ්නයක් විශ්වාස කරන්න ඕනි. මේ අවසානයෙන්, අපි ජර්මන් සහ ඉංග්\u200dරීසි වලට චැට්බෝට් සම්බන්ධයක් ප්\u200dරකාශ කරනවා. අපි පෙන්වන්නේ සාමාජික මධ්\u200dයමාධ්\u200dයම දත්තේ පරීක්ෂණාකරුවන්ට පුළුවන් එකම අදහස් හොයාගන්න. අපි සාමාජික මාධ්\u200dයමාණ්\u200dයයේදී විශ්වාස කරන වැඩක් ප්\u200dරතිචාර කරනවා. තවත්, අපි පෙන්වන්නේ, දෙවල් භාෂාවක් වචනය භාවිත කරන්න, ඉංග්\u200dරීසි සහ ජර්මන් දත්තේ එක්ක භාෂාවක් වගේ පද්ධත ඉංග්\u200dරීසියේ තියෙන එකම තියෙන්නේ තොරතුරු සෙට් එක්ක, අපි ජර්මන් ට්විට් වලින් ප්\u200dරකාශ කරනවා. අපි ඉංග්\u200dරීසියේ සාමාන්\u200dය ප්\u200dරශ්නයේ සාමාන්\u200dය ප්\u200dරශ්නය අධාරණය කරනවා, ජර්මන් ට්විට් වල සහ චැට්බෝට් කතාවක් වලි', 'so': 'Waxaynu soo jeedaynaa qaab cusub oo aad ogaato marka isticmaalayaashu ay ku muuqato qasabka ka taga adeegga, kaasoo lagu magacaabaa burbur. Markii shaqada hore ay kaliya ku cusbooneyso shabakada bulshada, waxaynu muujinnaa in arrintan lagu ogaan karo hadalka chatbot. Markii shirkaduhu ay si sii daran u isku halleeyaan jabsamada, waxay u baahan yihiin warbixinta isticmaalayaasha caadiga ah. Taas darteed, waxaynu soo bandhignaynaa koox macluumaad ah oo ku qoran jarmal iyo Ingiriis. Waxaynu tusnaynaa in fasaxyada lagu baray macluumaadka shabakada bulshada ay ku ogaan karaan isku qasnaan marka lagu jiro macluumaadka. Waxaynu soo bandhignaynaa taariikhda fasaxda oo shaqada ku jira oo ku saabsan baaritaanka caafimaadka bulshada. Sidoo kale waxaynu muujinnaa in, isticmaalka hadalka labada luqadood ah, nidaam lagu baro ingiriisiga iyo macluumaadka Jarmalka ah ayaa soo bandhigaya habab luqad ah. Sida loo qorayo macluumaadka oo kaliya ee uu ku qorayo Ingiriis, waxaynu soo bandhignaa taariikhda warqada ah oo ku qoran Twitteetka Jarmalka. Sidaa darteed waxaynu hoos uga dhignaa dhinaca caalamiga ah ee dhibaatada, tusaale ahaan noogu jeeda afka Ingiriiska, waxaynu na caawinnaa in aan ku ogaano qoraalka jarmalka ah oo ku qoran twitter iyo hadalka jarmalka ah.', 'sr': 'Predlažemo novu metodu da otkrijemo kada korisnici izražavaju nameru da napuste uslugu, takođe poznatu kao crn. Dok se prethodni rad fokusira samo na društvene medije, pokazujemo da ova namjera može biti otkrivena u razgovorima o šatbotima. Dok se kompanije sve više oslanjaju na chatbots, trebaju pregled potencijalnih crnkih korisnika. Za taj cilj, mi smo gužva izvori i objavljujemo skup podataka o crkvenim namjerama izražavanja u interakcijama šatbota na njemačkom i engleskom jeziku. Pokazujemo da klasifikatori obučeni na podacima društvenih medija mogu otkriti istu namjeru u kontekstu razgovora. Predstavljamo klasifikaciju arhitekture koja iznosi postojeći rad na otkrivanju crkvenih namera u društvenim medijima. Osim toga, pokazujemo da, koristeći dvojezičke reči, sistem obučen na kombinovanim engleskim i nemačkim podacima iznosi monojezičke pristupe. Kao što je jedina postojeća kompleta podataka na engleskom jeziku, mi publikujemo i objavljujemo novu kompletu podataka njemačkih tweeta. Zato potcenjujemo univerzalni aspekt problema, kao primjer crkvene namjere na engleskom, pomognemo nam da identifikujemo crkvu na njemačkim tweetima i razgovorima o govoru.', 'ur': 'ہم نے ایک نئی طریقہ پیش کرتا ہے کہ جب کارساز ایک سرویس چھوڑنے کا ارادہ کریں، جبکہ چرن کا نام بھی معلوم ہوتا ہے۔ اگلے کام صرف سوسیل میڈیا پر تمرکز کرتی ہے، ہم نشان دیتے ہیں کہ یہ مطلب چاٹبوٹ کی باتوں میں آگاہ ہو سکتا ہے۔ کیونکہ کمپانیاں چٹبوٹ پر زیادہ اعتماد رکھتے ہیں ان کے لئے امکان داری کارساز کی نظر کی ضرورت ہے۔ یہاں تک، ہم جرمن اور انگلیسی میں چاٹبوٹ کی تعاملات میں ایک ڈیٹ سٹ کے منظور ظاہر کرتے ہیں۔ ہم دکھاتے ہیں کہ سوسیل میڈیا ڈیٹا پر آموزش دیے گئے کلیسٹر بھی ایک ہی قصد کو چاٹبوٹ کے متعلق پہچان سکتے ہیں۔ ہم ایک کلاسپیٹ معماری معماری پیش کریں جو موجود کام کو سوسیل میڈیا میں چلنے کے مطابق اظہار کرتی ہے۔ اور ہم دکھاتے ہیں کہ، دو زبان کلمات کے مطابق انگلیسی اور جرمانی ڈیٹا پر ایک سیستم کی آموزش کی جاتی ہے، ایک زبان کے مطابق ایک طریقے سے زیادہ مطابق ہے۔ جیسے ایک موجود ڈاٹ سٹ انگلیسی میں ہے، ہم جرمن ٹویٹ کے ایک نئی ڈاٹ سٹ کو پیغام دیتے ہیں۔ ہم اسی طرح مشکل کے سارے سارے بحث کے ذریعہ مثالیں بناتے ہیں، انگلیسی میں جرمانی ٹیوٹ اور چاٹبوٹ کی باتوں میں چلنے کی مدد کرتے ہیں۔', 'sv': 'Vi föreslår en ny metod för att upptäcka när användare uttrycker avsikten att lämna en tjänst, även känd som churn. Medan tidigare arbete enbart fokuserar på sociala medier visar vi att denna avsikt kan upptäckas i chattbotkonversationer. Eftersom företag i allt högre grad förlitar sig på chatbots behöver de en överblick över potentiellt chutny användare. För detta ändamål crowdsource och publicerar vi en dataset av churn intent uttryck i chattbot interaktioner på tyska och engelska. Vi visar att klassificerare som är utbildade på sociala medier kan upptäcka samma avsikt i samband med chattbots. Vi introducerar en klassificeringsarkitektur som överträffar befintligt arbete med avkänningsavsikt i sociala medier. Dessutom visar vi att ett system som utbildats på kombinerade engelska och tyska data med tvåspråkiga ord överträffar enspråkiga metoder. Eftersom den enda befintliga datauppsättningen finns på engelska crowdsource och publicerar vi en ny datauppsättning tyska tweets. Vi understryker därför problemets universella aspekt, eftersom exempel på churn intention på engelska hjälper oss att identifiera churn i tyska tweets och chattbotssamtal.', 'ta': 'பயனர்கள் சேவையை விட்டு வெளியேறுவதற்கான நிலையை கூறும்போது கண்டறிய ஒரு புதிய முறையை நாம் பரிந்துரைக்கிறோ முந்தைய வேலை மட்டும் சமூக ஊடகங்களில் மட்டுமே கவனம் செலுத்தும் போது, இந்த அரட்டை உரையாடலில் கண்டறியப்படும் என்ற நிறுவனங்கள் அதிகமாக அரட்டையின் மீது நம்பிக்கை கொண்டிருக்கும் போது அவர்களுக்கு சாத்தியமான பயனர்கள் மீது ஒரு  இந்த முடிவிற்கு, நாங்கள் கூட்டத்தார் மூலம் மற்றும் நாங்கள் ஒரு தகவல் அமைப்பை வெளியிடுகிறோம் ஜெர்மன் மற்றும் ஆங்க சமூக ஊடக தரவுகளில் பயிற்சி செய்யப்பட்ட வகுப்பாட்டார்கள் அரட்டைப்பாட்டுகளின் மூலம் அதே இலக்கத்தை கண்டறிய முட நாம் ஒரு வகுப்பாட்டு உருவாக்கத்தை குறிப்பிடுகிறோம். அது தற்போதைய வேலை செய்கிறது சமூக ஊடகங்களில் கடுமையான தெர மேலும், நாம் அதை காண்பிக்கிறோம், இரு மொழி வார்த்தைகளை பயன்படுத்தி, ஒரு அமைப்பு ஆங்கிலம் மற்றும் ஜெர்மன் தரவு சேர்க்கப்பட்ட இருக்கும் தகவல் அமைப்பு ஆங்கிலத்தில் மட்டுமே இருக்கும் போது, நாம் கூட்டத்தார் மூலம் மற்றும் நாம் ஜெர்மன் த எனவே நாம் பிரச்சனையின் பொதுவான பகுதியை குறைவாக்கி விடுகிறோம், மேலும் ஆங்கிலத்தில் கடுமையான நிலையின் உதாரணங்கள் என்றா', 'uz': "Biz foydalanuvchilar xizmatni chiqarishni anglatayotganda ishlatish uchun yangi usulni aniqlash kerak. Oldingi ishlar faqat jamiyatli media'da foydalanadi, biz bu qanday talabatlarni topish mumkin. Kampanlar qachon chatbotlarga ishonadi, ularga juda katta foydalanuvchilarga ko'rinishi kerak. Bu hozirda, biz ko'pchilik manbasi va Olmon va Ingliz tilidagi chatbot interfeyslarida bir ko'plab ma'lumotlar tarkibini bajaramiz. Biz jamiyat media maʼlumotida o'rganilgan darajalarni ko'rsatganimiz, chatbotlar davrida bir qanday g'oyani aniqlash mumkin. Biz shaxsiy tashkilotni ishlab chiqarishimiz, jamiyat media'da juda qattiq ishni aniqlashni anglatadi. Moreover, we show that, using bilingual word embeddings, a system trained on combined English and German data outperforms monolingual approaches.  Faqat mavjud maʼlumot seti ingliz tilida, biz jamoatlar manbasi va Olmoncha Twitterdan novel maʼlumotlar tarkibini publish qilamiz. Шундай қилиб, биз мушкилнинг умумий қисмини таркиб этамиз, мисоли ingliz tilida eng kichkina maqsadning misollari, bizga Olmoncha Twitterda bir narsa va chat bilan muloqotlarni aniqlash imkoniyatini yordam beramiz.", 'vi': 'Chúng tôi đề xuất một phương pháp mới để phát hiện khi người dùng biểu lộ ý định rời khỏi dịch vụ, còn được gọi là church. Trong khi công việc trước chỉ tập trung vào các phương tiện truyền thông xã hội, chúng tôi cho thấy mục đích này có thể phát hiện trong cuộc trò chuyện của Chatur. Khi các công ty ngày càng dựa vào chat họ cần một thông tin về những người dùng có khả năng thờ ơ. Với mục đích này, chúng tôi tụ họp và công bố một tập tin về biểu hiện ý thức của nhà thờ trong tương tác của Chatur bằng tiếng Đức và Anh. Chúng tôi cho thấy những người phân loại được đào tạo trên dữ liệu mạng xã hội có thể phát hiện cùng mục đích trong ngữ cảnh chat bot. Chúng tôi giới thiệu một kiến trúc phân loại hơn những công trình có sẵn trên các phương tiện truyền thông. Hơn nữa, chúng tôi cho thấy, sử dụng sự nhúng tay hai chữ, một hệ thống được huấn luyện về dữ liệu tổng hợp Anh và Đức vượt qua phương pháp ngôn ngữ. Bởi vì bộ dữ liệu tồn tại duy nhất là ở tiếng Anh, chúng tôi tụ họp và xuất bản một tập tin mới về các tweet của Đức. Chúng tôi luôn nhấn mạnh khía cạnh phổ biến của vấn đề, ví dụ về ý đồ giáo dục ở Anh giúp chúng tôi nhận diện church trên Twitter và chat chatbot.', 'hr': 'Predlažemo novu metodu da otkrijemo kada korisnici izražavaju namjeru napustiti uslugu, također poznatu kao crn. Dok se prethodni rad fokusira samo na društvene medije, pokazujemo da se ova namjera može otkriti u razgovorima o šatbotima. Dok se kompanije sve više oslanjaju na chatbotke, trebaju pregled potencijalnih crkvenih korisnika. Za taj cilj, mi smo gužva izvori i objavljujemo skup podataka o crkvenim namjerama izražavanja u interakcijama šatbota na njemačkom i engleskom jeziku. Pokazujemo da klasifikatori obučeni na podacima društvenih medija mogu otkriti istu namjeru u kontekstu razgovora. Predstavljamo klasifikacijsku arhitekturu koja iznosi postojeći rad na otkrivanju crkvenih namjera u društvenim medijima. Osim toga, pokazujemo da, koristeći dvojezičke riječi, sustav obučen za kombinirane engleske i njemačke podatke iznosi monojezičke pristupe. Pošto je jedina postojeća kompleta podataka na engleskom jeziku, mi objavljujemo novi komplet njemačkih tweeta. Stoga potvrđujemo univerzalni aspekt problema, kao primjere crkvene namjere na engleskom jeziku, pomoći nam da identificiramo crkvu na njemačkim tweetima i razgovorima o govoru.', 'da': 'Vi foreslår en ny metode til at registrere, hvornår brugerne udtrykker hensigten om at forlade en tjeneste, også kendt som churn. Mens tidligere arbejde udelukkende fokuserer på sociale medier, viser vi, at denne hensigt kan registreres i chatbot samtaler. Da virksomheder i stigende grad er afhængige af chatbots, har de brug for et overblik over potentielt kloge brugere. Til dette formål crowdsource og offentliggør vi et datasæt af churn intent expressions i chatbot interaktioner på tysk og engelsk. Vi viser, at annoncører, der er trænet i data fra sociale medier, kan registrere den samme hensigt i forbindelse med chatbots. Vi introducerer en klassifikationsarkitektur, der overgår eksisterende arbejde med opdagelse af forstyrrelser i sociale medier. Desuden viser vi, at ved hjælp af tosprogede ordindlejringer, et system, der er uddannet i kombinerede engelske og tyske data, overgår ensprogede tilgange. Da det eneste eksisterende datasæt er på engelsk, crowdsource og publicerer vi et nyt datasæt af tyske tweets. Vi understreger derfor det universelle aspekt af problemet, da eksempler på churn intention på engelsk hjælper os med at identificere churn i tyske tweets og chatbot samtaler.', 'id': 'Kami mengusulkan metode baru untuk mendeteksi ketika pengguna mengekspresikan niat untuk meninggalkan layanan, juga dikenal sebagai churn. Sementara pekerjaan sebelumnya fokus hanya pada media sosial, kami menunjukkan bahwa tujuan ini dapat dideteksi dalam percakapan chatbot. Karena perusahaan semakin bergantung pada chatbot mereka membutuhkan pandangan panjang dari pengguna yang berpotensi churny. To this end, we crowdsource and publish a dataset of churn intent expressions in chatbot interactions in German and English.  Kami menunjukkan bahwa klasifikasi yang dilatih pada data media sosial dapat mendeteksi tujuan yang sama dalam konteks chatbot. Kami memperkenalkan arsitektur klasifikasi yang melampaui pekerjaan yang ada pada deteksi tujuan churn di media sosial. Selain itu, kami menunjukkan bahwa, menggunakan pembangunan kata dua bahasa, sistem yang dilatih pada data berbahasa Inggris dan Jerman melebihi pendekatan monobahasa. Karena satu-satunya set data yang ada dalam bahasa Inggris, kami crowdsource dan mempublikasikan set data novel dari tweet Jerman. Dengan demikian, kami menyatakan aspek universal dari masalah ini, sebagai contoh niat churn dalam bahasa Inggris membantu kami mengidentifikasi churn dalam tweet Jerman dan percakapan chatbot.', 'de': 'Wir schlagen eine neue Methode vor, um zu erkennen, wann Benutzer die Absicht äußern, einen Dienst zu verlassen, auch bekannt als Churn. Während sich bisherige Arbeiten ausschließlich auf Social Media konzentrieren, zeigen wir, dass diese Absicht in Chatbot-Konversationen erkannt werden kann. Da Unternehmen zunehmend auf Chatbots setzen, brauchen sie einen Überblick über potentiell abwandernde Nutzer. Zu diesem Zweck crowdsourcen und veröffentlichen wir einen Datensatz von Churn Intent Expressions in Chatbot Interaktionen in Deutsch und Englisch. Wir zeigen, dass Klassifikatoren, die auf Social-Media-Daten trainiert sind, die gleiche Absicht im Kontext von Chatbots erkennen können. Wir führen eine Klassifizierungsarchitektur ein, die bestehende Arbeiten zur Erkennung von Abwanderungsabsichten in sozialen Medien übertrifft. Darüber hinaus zeigen wir, dass ein System, das auf kombinierten englischen und deutschen Daten trainiert wird, durch zweisprachige Worteinbettungen monolinguale Ansätze übertrifft. Da der einzige Datensatz in englischer Sprache vorliegt, veröffentlichen wir einen neuen Datensatz deutscher Tweets. Damit unterstreichen wir den universellen Aspekt des Problems, denn Beispiele für Churn Intent in Englisch helfen uns, Churn in deutschen Tweets und Chatbot-Gesprächen zu identifizieren.', 'bg': 'Предлагаме нов метод за откриване, когато потребителите изразяват намерението си да напуснат услуга, известен още като churn. Докато предишната работа се фокусира единствено върху социалните медии, ние показваме, че това намерение може да бъде открито в чатбот разговори. Тъй като компаниите все повече разчитат на чатботи, те се нуждаят от преглед на потенциално раздразнените потребители. За тази цел ние събираме и публикуваме набор от данни от изрази на намерение за чурн в чат-бот взаимодействията на немски и английски език. Показваме, че класификаторите, обучени по данни от социалните медии, могат да открият същото намерение в контекста на чатботите. Въвеждаме класификационна архитектура, която превъзхожда съществуващата работа по откриване на намерения в социалните медии. Освен това показваме, че с помощта на двуезични вграждания на думи система, обучена на комбинирани английски и немски данни, превъзхожда едноезичните подходи. Тъй като единственият съществуващ набор от данни е на английски език, ние събираме и публикуваме нов набор от данни от немски туитове. По този начин подчертаваме универсалния аспект на проблема, тъй като примерите за намерение за бурн на английски ни помагат да идентифицираме бурн в немски туитове и чатбот разговори.', 'ko': '우리는 사용자가 언제 서비스를 떠나려는 의도를 나타냈는지 측정하는 새로운 방법을 제시했는데 이를 고객 유실이라고도 부른다.그동안 업무는 소셜미디어에만 집중했지만 이런 의도는 챗봇 대화에서 감지될 수 있다는 것을 발견했다.회사가 갈수록 채팅 로봇에 의존하면서 잠재적인 빈번한 사용자에 대한 개술이 필요하다.이를 위해 우리는 독일어와 영어 패키지로 채팅 로봇 상호작용에서의 유실 의도 표현 데이터 집합을 발표했다.채팅 로봇의 환경에서 소셜미디어 데이터 훈련을 거친 분류기가 같은 의도를 감지할 수 있다는 것을 발견했다.우리는 소셜 미디어에서 유실 의도를 측정하는 기존 작업보다 성능이 우수한 분류 체계 구조를 소개했다.그 밖에 우리는 이중 언어 단어를 사용하여 삽입하면 영어와 독일어의 조합 데이터를 바탕으로 하는 시스템이 단어 방법보다 우수하다는 것을 나타냈다.기존의 데이터 집합은 영어밖에 없기 때문에, 우리는 모두 새로운 독일어 추문 데이터 집합을 발표하였다.따라서 영어의 유실 의도 예시가 독일어 트위터와 채팅 로봇 대화의 유실을 식별하는 데 도움이 되기 때문에 이 문제의 보편성을 강조했다.', 'nl': 'We stellen een nieuwe methode voor om te detecteren wanneer gebruikers de intentie uitdrukken om een dienst te verlaten, ook wel churn genoemd. Terwijl vorig werk zich uitsluitend richt op sociale media, laten we zien dat deze intentie kan worden gedetecteerd in chatbot gesprekken. Omdat bedrijven steeds meer vertrouwen op chatbots, hebben ze een overzicht nodig van potentieel churny gebruikers. Hiervoor crowdsourcen en publiceren we een dataset van churn intent expressies in chatbot interacties in het Duits en Engels. We laten zien dat classificatoren getraind op social media data dezelfde intentie kunnen detecteren in de context van chatbots. We introduceren een classificatiearchitectuur die beter presteert dan bestaand werk op het gebied van detectie van churn intent in sociale media. Bovendien tonen we aan dat, met behulp van tweetalige woord embeddings, een systeem dat getraind is op gecombineerde Engelse en Duitse data, eentalige benaderingen overtreft. Omdat de enige bestaande dataset in het Engels is, crowdsourcen en publiceren we een nieuwe dataset van Duitse tweets. Zo onderstrepen we het universele aspect van het probleem, omdat voorbeelden van churn intent in het Engels ons helpen om churn te identificeren in Duitse tweets en chatbot gesprekken.', 'sw': 'Tunazipendekeza njia mpya ya kutambua pale watumiaji wakionyesha nia ya kuacha huduma hiyo, inayofahamika kama chungu. Wakati kazi zilizopita inajikita kwenye mitandao ya kijamii pekee, tunaonyesha kuwa lengo hili linaweza kutambuliwa katika mazungumzo ya mazungumzo ya mazungumzo. Kama makampuni yanavyotegemea mazungumzo yanavyohitaji kuangalia watumiaji wenye uwezekano mkubwa. Kwa mwisho huu, tunatumia vyanzo vya umma na kuchapisha seti ya taarifa za maoni yenye lengo kubwa katika mahusiano ya mazungumzo ya lugha ya Kijerumani na Kiingereza. Tunaonyesha kuwa wataalamu waliofundishwa kwenye taarifa za mitandao ya kijamii wanaweza kugundua lengo hilo katika muktadha wa mazungumzo. Tunaonyesha ujenzi wa usafi unaofanya kazi zilizopo kwenye mitandao ya kijamii kwa lengo la kugundua. Zaidi ya hayo, tunaonyesha kwamba, kwa kutumia maneno ya lugha mbili, mfumo uliojifundishwa kwa pamoja na takwimu za Kiingereza na Ujerumani unafanya mbinu za lugha za kimapenzi. Kama seti pekee ya taarifa zinazopo kwa lugha ya Kiingereza, tunatuma vyanzo vya umma na kuchapisha seti ya taarifa za twita za Kijerumani. Hivi ndivyo tunavyoelezea upande wa kimataifa wa tatizo, kama mfano wa lengo lenye makali kwa lugha ya Kiingereza kutusaidia kututambua chungu katika twiti za Ujerumani na mazungumzo ya mazungumzo.', 'tr': 'Ullançylar häzirden hem häzirden çykmak niýetini bejerjekdigini tanamak üçin täze bir ýol teklip edýäris. Öňki işiň ýöne sosyal medýýatlara üns berýändigini görkeýän bolsa, biz bu maksadyň çykyş gürrüňlerde tapylýandygyny görkeýän. Kompaniýalary çätbotlara hem güýçli bolup bilýärler. Olaryň beýleki möhüm uly ulanylaryna bir görnüş gerek. Şonuň üçin biz nemes we iňlis dilinde çätbot etmäge meňzeş maksadlaryň bardygyny jemgyýet edýäris. Biz sosyal medýdança maglumatlarda bilinmeli klasifikatçylar şol bir maksadyň bardygyny görüp biler. Biz sosial mediýalarda tapylmak niýetlerinde bolan bir klasifikasyýa arhitektura üýtgedýäris. Mundan hem, biz iki dilli söz taýýarlamak üçin Iňlisçe we Almança maglumatlary bilen bilim taýýarlanan sistemasyň mono dil taýýarlaryny üstün edýäris diýip görkeýäris. Iňlisçe diňe bar maglumat setigi bolsa, biz nemesçe tweetleriniň roman setigini basýarys. Şol sebäpli meseläniň uniwersaly meseläni gurlaýarys, iňlisçe kil niýetleriniň eserleri biziň nemesçe tweetlerde kilidini we çöpüş gürrüňleri tanamagymyza kömek edip bileris.', 'hy': 'Մենք առաջարկում ենք նոր մեթոդ հայտնաբերելու համար, երբ օգտագործողները արտահայտում են մտադրությունը թողնել ծառայություն, որը նաև հայտնի է որպես շրն: Մինչդեռ նախորդ աշխատանքը կենտրոնանում է միայն սոցիալական լրատվամիջոցների վրա, մենք ցույց ենք տալիս, որ այս նպատակը կարող է հայտնաբերվել շտաբոտ զրույցներում: Քանի որ ընկերությունները ավելի ու ավելի հույս են տալիս շտաբոտների վրա, նրանք պոտենցիալ թափանցիկ օգտագործողների վերաբերյալ կարիք ունեն: Այսպիսով, մենք ժողովրդավարում ենք և հրատարակում ենք գերմաներեն և անգլերեն ժողովրդավար մտադրության արտահայտումների տվյալներ: Մենք ցույց ենք տալիս, որ սոցիալական լրատվամիջոցների վրա վարժեցված դասակարգիչները կարող են հայտնաբերել նույն նպատակը շտաբոտների կոնտեքստում: We introduce a classification architecture that outperforms existing work on churn intent detection in social media.  Ավելին, մենք ցույց ենք տալիս, որ երկլեզու բառերի ներդրման միջոցով համակարգը, որը պատրաստված է անգլերեն և գերմանացի համադրված տվյալների վրա, արտադրում է միալեզու մոտեցումներ: Որովհետև միակ տեղեկատվական համակարգը գոյություն ունի անգլերենում, մենք հանդիսանում ենք և հրատարակում ենք գերմանացի թվիթերի նոր տվյալներ: Այսպիսով, մենք ենթադրում ենք խնդրի համընդհանուր ասպեկտը, որպես անգլերենի լեզվով շրջանակի մտադրության օրինակներ օգնում են մեզ ճանաչել շրջանակի մասին գերմանական թվիթերում և շտաբոտ զրույցներում:', 'af': "Ons voorstel 'n nuwe metode om te ontdek wanneer gebruikers die doel uitdruk om 'n diens te laat, ook bekend as kern. Terwyl die vorige werk alleen op sosiale media fokus, wys ons dat hierdie doel in gesprek gesprekke kan ontdek word. Soos maatskappye wat verhoog word op chatbots vertrou, het hulle 'n oorskou nodig van potensielle kerne gebruikers. Tot hierdie einde, ons skakelbron en publiseer 'n datastel van skakeluitdrukkings in chatbot interaksies in Duits en Engels. Ons wys dat klassifiseerders wat op sosiale media data opgelei is, dieselfde doel in die konteks van gesprekslyn kan ontdek. Ons introduseer 'n klasifikasie-arkitektuur wat bestaande werk uitvoer op skermdoel-opdekking in sosiale media. Ook, ons wys dat, gebruik van twee tale woord inbêdings, 'n stelsel onderwerp op gekombineerde Engels en Duitse data, monolinglike toegang uitvoer. Soos die enigste bestaande datastel in Engels is, is ons skakelbron en publiseer 'n nuwe datastel van Duitse tweets. Ons onderstreek daarom die universele aspekt van die probleem, as voorbeelde van kern doel in Engels help ons die kern in Duitse tweets en gesprekslys identifiseer.", 'fa': 'ما یک روش جدید پیشنهاد می\u200cکنیم که وقتی کاربران قصد ترک خدمت را نشان دهند، به عنوان چرن شناخته می\u200cشوند. در حالی که کار قبلی تنها روی رسانه\u200cهای اجتماعی تمرکز می\u200cکند، ما نشان می\u200cدهیم که این هدف می\u200cتواند در گفتگوهای صحبت کند. همانطور که شرکت\u200cهایی که بیش از حد زیادی بر صحبت\u200cهای صحبت اعتماد می\u200cکنند، آنها نیاز دارند به تغییر نظر از استفاده\u200cهای محتمل کلینی باشند. برای این قسمت، ما منبع جمعیت می\u200cکنیم و یک مجموعه داده\u200cای از نشانه\u200cهای هدف جمعیت در ارتباطات کلابت در آلمان و انگلیسی منتشر می\u200cکنیم. ما نشان می دهیم که راهنمایی که روی داده های رسانه های اجتماعی آموزش داده شده\u200cاند می\u200cتوانند همان هدف را در محیط صحبت کنند. ما یک معماری محرمانه را معرفی می\u200cکنیم که کار موجود را بر روی شناسایی هدف\u200cهای محرمانه در رسانه\u200cهای اجتماعی انجام می\u200cدهد. در ضمن، ما نشان می دهیم که با استفاده از ابتدایی کلمه دو زبان، یک سیستم آموزش یافته در داده های انگلیسی و آلمانی متحده شده، از یک دستور یک زبان بیشتر انجام می دهد. همانطور که تنها مجموعه داده\u200cهای موجود در انگلیسی است، ما منبع جمعیت می\u200cکنیم و یک مجموعه داده\u200cهای رمانی از tweets آلمانی منتشر می\u200cکنیم. بنابراین ما به عنوان مثالهای قصد کلینی در انگلیسی به ما کمک می\u200cکنیم که کلینی را در tweets آلمانی شناسایی کنیم و صحبت کردن صحبت کنند.', 'bn': 'আমরা একটি নতুন পদ্ধতি প্রস্তাব করি যখন ব্যবহারকারীরা একটি সেবা ছেড়ে যাওয়ার উদ্দেশ্য প্রকাশ করে, যা চার্ন নামে পরিচিত। পূর্ববর্তী কাজ শুধুমাত্র সামাজিক মিডিয়ায় মনোযোগ দিচ্ছে, আমরা দেখাচ্ছি যে এই উদ্দেশ্য চ্যাটব্যাট আলোচনায় সন কোম্পানিগুলো বাড়তে থাকে চ্যাটবোটের উপর নির্ভর করে তাদের সম্ভাব্য ব্যবহারকারীদের একটি পর্যবেক্ষণ প্রয়োজন। এই শেষ পর্যন্ত আমরা জনসংখ্যার উৎস এবং জার্মান এবং ইংরেজিতে চ্যাটবোট ইন্টারজেক্টেশনে একটি গুরুত্বপূর্ণ তথ্য প্রকাশ কর আমরা দেখাচ্ছি যে সামাজিক প্রচার মাধ্যমের তথ্যে প্রশিক্ষিত শ্রেণীদের চ্যাটবোটের প্রেক্ষাপটে একই উদ্দেশ আমরা সামাজিক প্রচার মাধ্যমগুলোতে বিদ্যমান কাজ চালানোর জন্য একটি ক্লাস্ফিকেশন কাঠামো পরিচয় করিয়ে দিচ্ছি। এছাড়াও, আমরা দেখাচ্ছি যে, দুই ভাষার শব্দ ব্যবহার করে একটি সিস্টেম ইংরেজি এবং জার্মান তথ্য সম্মিলিত ভাষায় প্রশিক্ষিত। যেহেতু মাত্র বিদ্যমান ডাটাসেট ইংরেজী ভাষায়, আমরা জনস্থিতি উৎস এবং জার্মান টুইটের একটি নvel ডাটাসেট প্রকাশ করি। এভাবে আমরা এই সমস্যার বিশ্ববিদ্যালয়ের প্রতিক্রিয়া চিহ্নিত করি, যেমন ইংরেজী ভাষায় গুরুত্বপূর্ণ উদাহরণের উদাহরণ হিসেবে আমরা জার্ম', 'sq': 'Ne propozojmë një metodë të re për të zbuluar kur përdoruesit shprehin qëllimin për të lënë një shërbim, të njohur gjithashtu si churn. Ndërsa puna e mëparshme përqëndrohet vetëm në media sociale, ne tregojmë se kjo qëllim mund të zbulohet në bisedimet chatbot. Ndërsa kompanitë gjithnjë e më tepër mbështeten në chatbots ata kanë nevojë për një përmbledhje të përdoruesve potencialisht të trashë. Për këtë qëllim, ne mbledhim dhe publikojmë një grup të dhënash të shprehjeve të qëllimeve të turpshme në ndërveprimet chatbot në gjermani dhe anglisht. Ne tregojmë se klasifikuesit e trajnuar në të dhënat e medias sociale mund të zbulojnë të njëjtin qëllim në kontekstin e chatbots. Ne paraqesim një arkitekturë klasifikimi që kryen punën ekzistuese mbi zbulimin e qëllimeve të Çurnit në mediat shoqërore. Përveç kësaj, ne tregojmë se, duke përdorur përfshirjen e fjalëve dygjuhëse, një sistem i trajnuar në të dhënat e kombinuara angleze dhe gjermane ekziston në mënyrë monogjuhëse. As the only existing dataset is in English, we crowdsource and publish a novel dataset of German tweets.  Kështu ne theksojmë aspektin universal të problemit, si shembuj i qëllimit të turpshëm në anglisht na ndihmojnë të identifikojmë turpshëm në tweetet gjermane dhe bisedimet chatbot.', 'am': 'የተጠቃሚ ግልግሎትን ለመውጣት እና የተጠቃሚ ስልጣን ለመውጣት አዲስ ስርዓት እናሳውቃለን፡፡ የቀድሞው ስራ በማኅበራዊ አውታር ላይ ብቻ ሲያሳየው እንኳን ይህ አሳብ በአካባቢት ንግግር ውስጥ እንዲገኘው እናሳየዋለን፡፡ የኮምፒውተሮች በጨማሪነት በአካባቢዎች ላይ የሚታመኑ የቻይሎቹ ተጠቃሚዎች ላይ ማየት ያስፈልጋሉ፡፡ ለዚህ ምክንያት፣ የድምፅ ምንጭ እና በጀርመን እና እንግሊዘኛ በተቃራኒ ግንኙነት ላይ የቆርጠው የድምፅ ጉዳይ እናሳውቃለን፡፡ ማኅበራዊ ሚዲያ ዳታዎችን የተጠቃሚዎቹን በአካባቢት ውጤት የተጠቃሚዎችን እናሳያቸዋለን፡፡ ማኅበራዊ አውታር ውስጥ ስልጣንን ለማግኘት የሚችለውን የግንኙነቱን ሥራ እናሳውቃለን፡፡ ከዚህም ጋር በሁለት ቋንቋ ቃላት በመጠቀም፣ የንግግሊዝና እና የጀርመን ዳታዎችን በተጠቃሚ የፖለቲካዊ ቋንቋ ግንኙነትን የሚያደርግ ስርዓት ነው፡፡ የአሁኑን ዳታተር በንግግሊዝኛ እንደሆነ፣ የድምፅ ምንጭ እና የጀርመን ትዊተሮች የዳታተር ጽሑፍ እናሳብቃለን፡፡ We thus underline the universal aspect of the problem, as examples of churn intent in English help us identify churn in German tweets and chatbot conversations.', 'cs': 'Navrhujeme novou metodu zjištění, kdy uživatelé vyjadřují záměr opustit službu, známou také jako churn. Zatímco předchozí práce se zaměřuje pouze na sociální média, ukazujeme, že tento záměr lze detekovat v chatbotových konverzacích. Vzhledem k tomu, že společnosti stále více spoléhají na chatboty, potřebují přehled o potenciálně změněných uživatelích. Za tímto účelem crowdsource a publikujeme datovou sadu výrazů záměru odchylky v interakcích chatbotů v němčině a angličtině. Ukazujeme, že klasifikátoři trénovaní na sociálních sítích dokáží zjistit stejný záměr v kontextu chatbotů. Představujeme klasifikační architekturu, která překonává stávající práci na detekci záměru změny v sociálních médiích. Kromě toho ukazujeme, že pomocí dvojjazyčných vložení slov systém trénovaný na kombinovaných anglických a německých datech překonává monojazyčné přístupy. Vzhledem k tomu, že jediný existující datový soubor je v angličtině, crowdsource a publikujeme nový datový soubor německých tweetů. Zdůrazňujeme tak univerzální aspekt problému, protože příklady záměru churn v angličtině nám pomáhají identifikovat churn v německých tweetech a chatbotových konverzacích.', 'az': 'İstifadəçilər istifadə etmək niyyətini təşkil etmək üçün yeni bir yol təklif edirik. Əvvəlki işin yalnız sosyal media üzərində tərəfindən tərəfindən danışdığını göstərdik ki, bu niyyətin sohbətlərdə keçirilə bilər. Şirketlər daha çox chatbotlara təvəkkül edirlər ki, mümkün olaraq kirli istifadəçilər barəsində ehtiyacı vardır. Bu məqsədilə, Almanca və İngilizce danışmalarında çək-bot əlaqələrində bir veri qurmaq və yayınlıq edirik. Biz sosyal media məlumatlarında təhsil edilmiş klasifikatçıların bir niyyəti çəkmək məqsədilə keşf edə biləcəyini göstəririk. Biz sosyal mediyalarda mövcuddur işi keşfetmək məqsədilə sadiq bir arhitektir təşkil edirik. Daha sonra, biz iki dil sözlərini istifadə edirik ki, birləşdirilmiş İngilizce və Alman məlumatlarına təhsil edilən bir sistem monodil təhsil edilməsindən daha çox yaxşıdır. Yalnız məlumat quruluğu İngilizce dilində olduğu kimi, biz Alman tweetlərinin yeni məlumat quruluğunu yayındırırıq. Beləliklə, bu problem in universal aspektini, İngilizce dilində kiln niyyətinin məsəlləri olaraq Alman twetlərində kiln və çəkidə danışmaqlarında tanıtmağımıza kömək edirik.', 'bs': 'Predlažemo novu metodu da otkrijemo kada korisnici izražavaju namjeru napustiti uslugu, također poznatu kao crn. Dok se prethodni rad fokusira samo na društvene medije, pokazujemo da se ova namjera može otkriti u razgovorima o šatbotima. Dok se kompanije sve više oslanjaju na chatbots, trebaju pregled potencijalnih crnkih korisnika. Za taj cilj, mi smo publikovani i objavljujemo skup podataka o crkvenim namjerama izražavanja u interakcijama sa chatbotom na njemačkom i engleskom jeziku. Pokazujemo da klasifikatori obučeni na podacima društvenih medija mogu otkriti istu namjeru u kontekstu razgovora. Predstavljamo klasifikaciju arhitekture koja iznosi postojeći rad na otkrivanju crkvenih namjera u društvenim medijima. Osim toga, pokazujemo da, koristeći dvojezičke riječi, sistem obučen na kombiniranim engleskim i njemačkim podacima iznosi monojezičke pristupe. Kao što je jedina postojeća kompleta podataka na engleskom jeziku, mi publikujemo i objavljujemo novu kompletu podataka njemačkih tweeta. Stoga potcenjujemo univerzalni aspekt problema, kao primjere crkvene namjere na engleskom jeziku, pomoći nam da identifikujemo crkvu na njemačkim tweetima i razgovorima o govoru.', 'ca': "We propose a new method to detect when users express the intent to leave a service, also known as churn.  Mentre el treball anterior es centra només en els mitjans socials, demostram que aquesta intenció es pot detectar en converses de chatbot. A mesura que les empreses confien cada cop més en robots de chat, necessiten una visió general dels usuaris potencialment churny. Per això, recollim i publicam un conjunt de dades d'expressions d'intenció en interaccions de chatbots en alemany i anglès. Mostrem que els classificadors entrenats en dades dels mitjans socials poden detectar la mateixa intenció en el context dels chatbots. Introduïm una arquitectura de classificació que supera la feina existent en la detecció d'intencions en els mitjans socials. A més, demostram que, utilitzant l'incorporació de paraules bilingües, un sistema entrenat en dades combinades anglesa i alemana supera els enfocaments monolingües. Com que l'únic conjunt de dades existents és en anglès, recollim i publicam un conjunt de dades noves de tweets alemanys. Així doncs subrayem l'aspecte universal del problema, com exemples d'intenció en anglès ens ajuden a identificar l'aspecte en tweets alemans i converses de chatbot.", 'et': 'Pakume välja uue meetodi tuvastamiseks, kui kasutajad väljendavad kavatsust lahkuda teenusest, mida tuntakse ka kui churn. Kuigi varasemad tööd keskenduvad ainult sotsiaalmeediale, näitame, et seda kavatsust saab tuvastada jutubotide vestlustes. Kuna ettevõtted tuginevad üha enam chatbotidele, vajavad nad ülevaadet potentsiaalselt kirglikest kasutajatest. Sel eesmärgil hangime ja avaldame jutubotide interaktsioonide churn-kavatsuse avaldiste andmekogumi saksa ja inglise keeles. Näitame, et sotsiaalmeedia andmetel koolitatud klassifitseerijad suudavad sama kavatsust chatbotide kontekstis tuvastada. Tutvustame klassifitseerimisarhitektuuri, mis ületab sotsiaalmeedias olemasolevaid tööd kokkupõrkekavatsuste tuvastamisel. Lisaks näitame, et kahekeelsete sõnade manustamise abil on inglise ja saksa keele kombineeritud andmetel koolitatud süsteem ühekeelsetest lähenemisviisidest parem. Kuna ainus olemasolev andmekogum on inglise keeles, siis avaldame uudse saksa säutsude andmekogumi. Seega rõhutame probleemi universaalset aspekti, sest ingliskeelse keele näited aitavad meil tuvastada saksa säutsudes ja jutubotide vestlustes kirjutamist.', 'fi': 'Ehdotamme uutta tapaa havaita, milloin käyttäjät ilmaisevat aikomuksensa poistua palvelusta, joka tunnetaan myös nimellä churn. Vaikka aikaisemmat työt keskittyvät yksinomaan sosiaaliseen mediaan, osoitamme, että tämä tarkoitus voidaan havaita chatbot-keskusteluissa. Koska yritykset luottavat yhä enemmän chatbotteihin, ne tarvitsevat yleiskuvan potentiaalisesti kirpeistä käyttäjistä. Tätä varten joukkoistamme ja julkaisemme datajoukon churn intent -lausekkeita chatbottien vuorovaikutuksessa saksaksi ja englanniksi. Osoitamme, että sosiaalisen median dataan koulutetut luokittelijat voivat havaita saman tarkoituksen chatbottien yhteydessä. Esittelemme luokitteluarkkitehtuurin, joka päihittää sosiaalisen median churn intent detection -työn. Lisäksi osoitamme, että kaksikielisten sanaupotusten avulla yhdistettyyn englannin ja saksan dataan koulutettu järjestelmä on monikielisiä lähestymistapoja parempi. Koska ainoa olemassa oleva aineisto on englanniksi, joukkoistamme ja julkaisemme uuden aineiston saksalaisista tweeteistä. Korostamme siis ongelman yleismaailmallista puolta, sillä englanninkieliset churn-aikomukset auttavat meitä tunnistamaan churn saksankielisissä tweeteissä ja chatbot-keskusteluissa.', 'jv': 'Awak dhéwé ngerasah sistem sing dibutuhke nungsa nguasai perbudhakan kanggo ngilangno sênêmên, dadi dianggalakno kanggo mbanjêng. Nanging ora jalang ginar sing dipun-ingkang sampeyan ing media sotiki, kita ngomatngon kuwi iki apa kanggo nggawe tarjamahan karo ingkang bab Punika-kompanie lakusun akeh luwih dumadhi kanggo nganggo barang Saiki iki, awak dhéwé kesempok lan mbengok dhéwé éntuk mulasah karo pernik-pernik nik nganggo pernik kuwi barang kelas karo Inggris Awak dhéwé ngerasakno karo hal-hal sing luwih digaweni gambaran ning data media sotiki iki iso alé awak nggawe barang iki banget kanggo nguasakno Awak dhéwé nyenggunaké architecture sing paling-alik dhéwé nggawe barang nggawe barang nggawe barang nggawe media sotiki. Nambah, awak dhéwé ngomong nik, gambar akeh gambar obang-obang, sistem sing ditambakno Perancis lan alam kuwi kapan kuwi nggambar barang langgar. Drongen wong dhéwé éntuk dataset sing ana ing Inggris, awak dhéwé kesempatan lan ngubah dhéwé ngetik dadi batir barang alam Awak dhéwé éngleki nggalakno karo hal-hal sing universel karo perbudhakan kanggo ngilanggar wijane kanggo nglanggar wijane kuwi nggambar obah-obahan kanggo ngerasakno tuwit sing aleman karo perkara sing karo nganggep kuwi.', 'sk': 'Predlagamo novo metodo za zaznavanje, kdaj uporabniki izrazijo namen zapustiti storitev, znano tudi kot churn. Medtem ko se predhodno delo osredotoča izključno na družbena omrežja, pokažemo, da je ta namen mogoče zaznati v klepetalnih pogovorih. Ker se podjetja vedno bolj zanašajo na chatbote, potrebujejo pregled potencialno polnih uporabnikov. V ta namen množično nabiramo in objavljamo nabor podatkov izrazov churn intent v interakcijah chatbotov v nemščini in angleščini. Pokazali smo, da lahko klasifikatorji, usposobljeni za podatke na družbenih omrežjih, zaznajo enak namen v kontekstu chatbotov. Predstavljamo klasifikacijsko arhitekturo, ki presega obstoječe delo na področju zaznavanja namena churn v družbenih omrežjih. Poleg tega pokažemo, da sistem, usposobljen za kombinirane angleške in nemške podatke, z uporabo dvojezičnih besednih vdelav presega enojezične pristope. Ker je edini obstoječi nabor podatkov v angleščini, množično nabiramo in objavljamo nov nabor podatkov nemških tweetov. Tako poudarjamo univerzalni vidik problema, saj nam primeri namena churn v angleščini pomagajo prepoznati churn v nemških tweetih in klepetalnih pogovorih.', 'ha': "Tuna goyyar da wata hanyowa na daban su gane idan mai amfani da shi ke nuna zaɓen su bar wani aikin, kamar da aka sanar da shi murakke. A lokacin da aikin da ya gabãta yana fokusar a kan mitandai da jamii kawai, Munã nuna cewa za'a gane wannan da za'a iya cikin mazaɓa na mazaɓa. Ga da makampuni suke dõgara a kan sauri ga mazaɓa, sai sun yi amfani da wasu mãsu amfani da mataimaki. Haƙĩƙa, zuwa ga wannan, muna nuna ko wani set na'ura da ke cikin hoton cikin shirin chatbot cikin jeruman da Ingiriya. Muna nũna wa fasalla waɗanda aka tsare shi a kan data na jamii, su iya gane maganar da ke cikin muhimman mazaɓa. Tuna fara wani matsayi mai fassari wanda ke samar da aikin wanda ke gaba a kan gane cikin mitandai da jamii. Kayya, Munã nũna cewa, da za'a yi amfani da maganar da ke cikin lugha biyu, wata na'ura wanda aka yi wa shirin da shi na Ingiriya da data na jerumani, yana aikata hanyoyin wata na'ura. Kama da ɗayan mutane da ke gaba kawai, yana cikin Ingiriya, za'a nuna umarni da kuma ke bayyana wani matsalar da aka rubũta na jerunan. Kamar wannan ne Muke ƙara ƙarani ga kalma na cikin mãkirci, kamar misãlai na cikin Ingiriya, sai mu taimake mu gane karatu cikin littattafan Jamanci da mazaɓa.", 'he': "אנחנו מציעים שיטה חדשה לגלות מתי משתמשים מבטאים את הכוונה לעזוב שירות, הידוע גם כצ'ארן. בעוד העבודה הקודמת מתמקדת רק בתקשורת חברתית, אנחנו מראים שהכוונה הזו יכולה להיגלות בשיחות chatbot. כפי שהחברות סומכות יותר ויותר על צ'אטבוטים, הן זקוקות לתצוגה של משתמשים פוטנציאלי גאוני. למטרה זו, אנו משתמשים במקור קהל ופרסמים קבוצת נתונים של ביטויים בכוונה של צ'ארן באינטראקציות של צ'אטבוט בגרמנית ואנגלית. אנחנו מראים שהקלאסיפורים מאומנים על נתונים של התקשורת החברתית יכולים לזהות את אותה כוונה בקשר לשטבוטים. אנחנו מציגים ארכיטקטורה מסווג שמוציאה מעבודה קיימת על גילוי כוונות צ'ארן בתקשורת חברתית. חוץ מזה, אנו מראים כי, בשימוש בתכניות מילים שתיים לשונות, מערכת מאומנת על נתונים אנגליים וגרמניים משותפים על גישות מונולשונות. כיוון שהמסד הנוכחי היחיד הוא באנגלית, אנו פורסמים מסד נתונים של טוויטים גרמניים. We thus underline the universal aspect of the problem, as examples of churn intent in English help us identify churn in German tweets and chatbot conversations.", 'bo': 'ང་ཚོས་སྤྱོད་མཁན་གྱི་དམིགས་ཡུལ་དེ་རང་ཉིད་ཀྱིས་ཞབས་ཞུལ་ཞིག་བཞག་པ་ལ་རྟོགས་ན་ཐབས་གསར་བ་ཞིག་བསམ་དགོས སྔོན་གྱི་ལས་འགན་དེ་ཚོས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ལ་དམིགས་ཡུལ་འདི་རྟོགས་ཐུབ་པ་ལས་ སྡེར་མོའི་གོ་སྡེའི་ནང་གི་གླེང་མོལ་ཆེ་རུ་གཏོང་མཁན་ལ་ཆེ་མཐོང་ཁང་ཞིག་དགོས་པ་ཡིན། མཐའ་མ་དེར་བརྟེན། ང་ཚོས་རྒྱ་ནག་གི་མི་དང་དབྱིན་ཡིག་གི་ནང་གི་གླེང་སྒྲུང་གི་གནད་སྡུད་ཚན་བཙུགས་སྟེ། ང་ཚོས་སྤྱི་ཚོགས འུ་ཅག་གིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དུ་འཇུག་སྣོད་ནང་ལས་གནས་ཡུལ་གྱི་ལས་འཆར་བྱེད་མཁན་གྱི་བཟོ་བཀོད་དམ། འོན་ཀྱང་། གནས་ཡོད་པའི་ཆ་འཕྲིན་ཡིག་ཆ་གཅིག་གི་ནང་དུ་དབྱིན་ཡིག་གི་ནང་དུ་ཡིན་ནའང་། ང་ཚོ་མང་པོ་ཞིག་ནས་སྒྲུབ་གཏོང་ཆེ འུ་ཅག་གི་དཀའ་ངལ་གྱི་སྤྱི་ཚོགས་ཆེན་དག་ལ་བགོ་སྟེ། དཔེར་ན། དབྱིན་ཡིག་གི་དཔེར་ན། དབྱིན་ཡིག་གི་འཛམ་གླིང་ཐོག་ནས་དབྱིན་'}
{'en': 'Latent Entities Extraction : How to Extract Entities that Do Not Appear in the Text?', 'ar': 'استخراج الكيانات الكامنة: كيفية استخراج الكيانات التي لا تظهر في النص؟', 'pt': 'Extração de entidades latentes: como extrair entidades que não aparecem no texto?', 'fr': "Extraction d'entités latentes\xa0: comment extraire des entités qui n'apparaissent pas dans le texte\xa0?", 'es': 'Extracción de entidades latentes: ¿cómo extraer entidades que no aparecen en el texto?', 'ja': '潜在エンティティ抽出:テキストに表示されないエンティティを抽出する方法', 'zh': '潜于实体提取:如何提取文本中未见之实体?', 'hi': 'अव्यक्त एंटिटी निष्कर्षण: पाठ में प्रकट नहीं होने वाली संस्थाओं को कैसे निकालें?', 'ru': 'Извлечение скрытых сущностей: как извлечь сущности, которые не отображаются в тексте?', 'ga': 'Eastóscadh Aonán Folaigh: Conas Aonáin Nach Láithnítear sa Téacs a Bhaint as?', 'ka': 'შემდეგი ელექტრების გამოყენება: როგორ გამოყენება ელექტრები, რომელიც ტექსტიში არ გამოყენება?', 'el': 'Εξαγωγή λανθάνουσας οντότητας: Πώς να εξαγάγετε οντότητες που δεν εμφανίζονται στο κείμενο;', 'kk': 'Кейінгі нысандарды тарқату: Мәтінде көрінбейтін нысандарды қалай тарқату?', 'hu': 'Latent Entities Extraction: Hogyan lehet kivonni azokat a entitásokat, amelyek nem jelennek meg a szövegben?', 'it': 'Estrazione di entità latenti: come estrarre entità che non vengono visualizzate nel testo?', 'ms': 'Ekstraksi Entiti Terkini: Bagaimana mengekstrak Entiti yang tidak muncul dalam Teks?', 'mk': 'Екстракција на последните ентитети: Како да се извадат ентитети кои не се појавуваат во текстот?', 'mt': 'Estrazzjoni tal-Entitajiet Latenti: Kif jiġu Estratti Entitajiet li ma jidhrux fit-Test?', 'lt': 'Naujausių subjektų ekstraktas: kaip ekstraktuoti subjektus, kurie tekste nenurodyti?', 'no': 'Nyleg utpakking av einingar: Korleis å pakka ut einingar som ikkje viser i teksten?', 'mn': "Сүүлийн Entities Extraction: How to Extract Entities that Don't appear in the Text?", 'ro': 'Extragerea entităților latente: Cum se extrage entități care nu apar în text?', 'pl': 'Ekstrakcja podmiotów latent: Jak wyodrębnić podmioty, które nie pojawiają się w tekście?', 'sr': 'Ekstrakcija poslednjih subjekta: Kako da izvučemo subjekte koje se ne pojavljuju u tekstu?', 'si': 'පස්සේ අන්තිත්වය නිර්මාණය: කොහොමද පාළුවට පෙන්වන්නේ නැති අන්තිත්වය නිකිරීමට?', 'so': 'Waxyaabaha soo saarista ee ugu dambeeyay: Sidee looga soo bixinayaa shirkadaha aan ku dhegaysan qoraalka?', 'ml': 'അടുത്ത എന്റിറ്റുകള്\u200d പുറത്താക്കുക: പദാവലിയില്\u200d കേള്\u200dക്കാത്ത എന്റിറ്റുകള്\u200d എങ്ങനെ പുറത്താക്കുക?', 'sv': 'Extraktion av latenta entiteter: Hur extraherar du entiteter som inte visas i texten?', 'ur': "Latent Entities Extraction: How to Extract Entities that Don't appear in the Text?", 'ta': 'சமீபத்தில் உள்ளீடுகள் வெளியேறுதல்: உரையில் கேட்காத உள்ளீடுகளை எப்படி வெளியேற்ற வேண்டும்?', 'vi': 'Ngoại trừ các thực thể gần đây: Làm thế nào để tách các loài không xuất hiện trong văn bản?', 'uz': '@ info: whatsthis', 'bg': 'Извличане на латентни субекти: Как да извлечете субекти, които не се появяват в текста?', 'nl': 'Extractie van latente entiteiten: Hoe extraheren van entiteiten die niet in de tekst voorkomen?', 'hr': 'Izvuk kasnih subjekta: Kako izvući subjekte koje se ne pojavljuju u tekstu?', 'da': 'Uddrag af Latent Entities: Hvordan udtrækkes enheder, der ikke vises i teksten?', 'fa': 'اخراج اولیات اخیر: چگونه باعث استخراج اولیات که در متن ظاهر نمی شوند؟', 'de': 'Extraktion latenter Entitäten: Wie extrahiere ich Entitäten, die nicht im Text erscheinen?', 'id': 'Latent Entities Extraction: How to Extract Entities that Do Not Appear in the Text?', 'af': 'Laat Entiteit Uitpak: Hoe om Entiteit uit te pak wat Moet nie in die Teks voorkom nie?', 'ko': '잠재적 실체 추출: 텍스트에 나타나지 않은 실체를 어떻게 추출합니까?', 'am': 'ለ... መርጠህ አውጣ', 'sw': 'Hivi karibuni Utoa: Inawezaje Kutoa Hifadhi ambazo hazitasikiliza kwenye maandishi?', 'tr': 'Saýlaw Aç: Metinde Görkezilmedik Saýlawy Nädip Aç?', 'sq': 'Ekstrakti i njësive të mëvonshme: Si të nxjerrim njësitë që nuk shfaqen në tekst?', 'az': 'Sonrak캼 Entitl톛r Extraction: M톛tnd톛 G칬r칲nm톛y톛n Entitl톛r nec톛 칞캼xar캼l캼r?', 'ca': 'Latent Entities Extraction: How to Extract Entities that Do Not Appear in the Text?', 'bn': 'সাম্প্রতিক এন্টিটি এক্সট্র্যাক্ট্র্যাক্ট্র্যাকশন: টেক্সটের মধ্যে কিভাবে অংশগ্রহণ করা হবে না?', 'hy': 'Վերջին հաստատությունների դուրս բերումը. Ինչպե՞ս դուրս բերել այն հաստատությունները, որոնք չեն հայտնվում տեքստում:', 'fi': 'Latent entities Extraction: Miten poistaa entiteettejä, jotka eivät näy tekstissä?', 'bs': 'Izvuk kasnih subjekta: Kako izvući subjekte koje se ne pojavljuju u tekstu?', 'cs': 'Extrakce latentních entit: Jak extrahovat entity, které se v textu neobjevují?', 'et': 'Viimased olemid ekstraheerimine: kuidas ekstraheerida olemid, mis tekstis ei kuvata?', 'jv': 'Layout Anyar', 'ha': '@ action: button', 'he': 'הוצאת יחידות מאוחרות: איך להוציא יחידות שלא מופיעות בטקסט?', 'sk': 'Izvleček zadnjih entitet: Kako izvleči entitete, ki se ne pojavljajo v besedilu?', 'bo': 'ཤུལ་མའི་སྒེར་ཆོས་འཚོལ་བཤེར་བྱེད་: ཡི་གེའི་ནང་དུ་སྟོན་མི་སྣང་ཚུལ་ཇི་ལྟར་ཕྱིར་འདོན་དགོས་སམ'}
{'en': 'Named-entity Recognition (NER) is an important task in the NLP field, and is widely used to solve many challenges. However, in many scenarios, not all of the entities are explicitly mentioned in the text. Sometimes they could be inferred from the context or from other indicative words. Consider the following sentence : CMA can easily hydrolyze into free acetic acid. Although water is not mentioned explicitly, one can infer that ', 'ar': 'يعد التعرف على الكيان المحدد (NER) مهمة مهمة في مجال البرمجة اللغوية العصبية ، ويستخدم على نطاق واسع لحل العديد من التحديات. ومع ذلك ، في العديد من السيناريوهات ، لم يتم ذكر جميع الكيانات صراحة في النص. في بعض الأحيان يمكن الاستدلال عليها من السياق أو من الكلمات الإرشادية الأخرى. ضع في اعتبارك الجملة التالية: "يمكن أن يتحلل CMA بسهولة إلى حمض أسيتيك حر." على الرغم من عدم ذكر الماء صراحة ، يمكن للمرء أن يستنتج أن H2O هو كيان مشارك في العملية. في هذا العمل ، نقدم مشكلة استخراج الكيانات الكامنة (LEE). نقدم عدة طرق لتحديد ما إذا كانت الكيانات ستتم مناقشتها في النص ، على الرغم من أنه من المحتمل أنها غير مكتوبة بشكل صريح. على وجه التحديد ، نصمم نموذجًا عصبيًا يتعامل مع استخراج كيانات متعددة بشكل مشترك. نظهر أن نموذجنا ، جنبًا إلى جنب مع نهج التعلم متعدد المهام وخوارزمية تجميع المهام الجديدة ، يصل إلى أداء عالٍ في تحديد الكيانات الكامنة. تُجرى تجاربنا على مجموعة بيانات بيولوجية كبيرة من مجال الكيمياء الحيوية. تحتوي مجموعة البيانات على أوصاف نصية للعمليات البيولوجية ، ولكل عملية ، يتم تصنيف جميع الكيانات المشاركة في العملية ، بما في ذلك الكيانات المذكورة ضمنيًا. نعتقد أن LEE مهمة ستعمل على تحسين العديد من تطبيقات NER والتطبيقات اللاحقة وتحسين فهم النص والاستدلال.', 'fr': "La reconnaissance des entités nommées (NER) est une tâche importante dans le domaine de la PNL et est largement utilisée pour résoudre de nombreux défis. Cependant, dans de nombreux scénarios, toutes les entités ne sont pas explicitement mentionnées dans le texte. Parfois, ils peuvent être déduits du contexte ou d'autres mots indicatifs. Considérez la phrase suivante\xa0: «\xa0Le CMA peut facilement s'hydrolyser en acide acétique libre.\xa0» Bien que l'eau ne soit pas mentionnée explicitement, on peut en déduire que H2O est une entité impliquée dans le processus. Dans ce travail, nous présentons le problème de l'extraction d'entités latentes (LEE). Nous présentons plusieurs méthodes pour déterminer si les entités sont abordées dans un texte, même si, potentiellement, elles ne sont pas écrites explicitement. Plus précisément, nous concevons un modèle neuronal qui gère l'extraction conjointe de plusieurs entités. Nous montrons que notre modèle, associé à une approche d'apprentissage multitâche et à un nouvel algorithme de regroupement de tâches, atteint des performances élevées dans l'identification des entités latentes. Nos expériences sont menées sur un vaste ensemble de données biologiques issues du domaine biochimique. L'ensemble de données contient des descriptions textuelles des processus biologiques, et pour chaque processus, toutes les entités impliquées dans le processus sont étiquetées, y compris celles mentionnées implicitement. Nous pensons que LEE est une tâche qui améliorera de manière significative de nombreuses applications NER et ultérieures et améliorera la compréhension et l'inférence de texte.", 'es': 'El reconocimiento de entidades nombradas (NER) es una tarea importante en el campo de la PNL y se usa ampliamente para resolver muchos desafíos. Sin embargo, en muchos escenarios, no todas las entidades se mencionan explícitamente en el texto. A veces pueden inferirse del contexto o de otras palabras indicativas. Considera la siguiente frase: «El CMA puede hidrolizarse fácilmente en ácido acético libre». Aunque el agua no se menciona explícitamente, se puede deducir que el H2O es una entidad involucrada en el proceso. En este trabajo, presentamos el problema de la Extracción de Entidades Latentes (LEE). Presentamos varios métodos para determinar si las entidades se discuten en un texto, aunque, potencialmente, no estén escritas explícitamente. Específicamente, diseñamos un modelo neuronal que maneja la extracción de múltiples entidades de forma conjunta. Demostramos que nuestro modelo, junto con el enfoque de aprendizaje multitarea y un novedoso algoritmo de agrupación de tareas, alcanza un alto rendimiento en la identificación de entidades latentes. Nuestros experimentos se llevan a cabo en un gran conjunto de datos biológicos del campo bioquímico. El conjunto de datos contiene descripciones textuales de procesos biológicos y, para cada proceso, se etiquetan todas las entidades involucradas en el proceso, incluidas las mencionadas implícitamente. Creemos que LEE es una tarea que mejorará significativamente muchas aplicaciones de NER y posteriores, y mejorará la comprensión e inferencia de textos.', 'pt': 'O Reconhecimento de Entidades Nomeadas (NER) é uma tarefa importante no campo da PNL e é amplamente utilizada para resolver muitos desafios. No entanto, em muitos cenários, nem todas as entidades são explicitamente mencionadas no texto. Às vezes, eles podem ser inferidos a partir do contexto ou de outras palavras indicativas. Considere a seguinte frase: “CMA pode facilmente hidrolisar em ácido acético livre”. Embora a água não seja mencionada explicitamente, pode-se inferir que H2O é uma entidade envolvida no processo. Neste trabalho, apresentamos o problema de Extração de Entidades Latentes (LEE). Apresentamos vários métodos para determinar se as entidades são discutidas em um texto, mesmo que, potencialmente, elas não sejam explicitamente escritas. Especificamente, projetamos um modelo neural que lida com a extração de várias entidades em conjunto. Mostramos que nosso modelo, juntamente com a abordagem de aprendizado multitarefa e um novo algoritmo de agrupamento de tarefas, alcança alto desempenho na identificação de entidades latentes. Nossos experimentos são conduzidos em um grande conjunto de dados biológicos do campo bioquímico. O conjunto de dados contém descrições textuais de processos biológicos e, para cada processo, todas as entidades envolvidas no processo são rotuladas, incluindo aquelas implicitamente mencionadas. Acreditamos que o LEE é uma tarefa que melhorará significativamente muitos aplicativos NER e subsequentes e melhorará a compreensão e a inferência de texto.', 'ja': '名前付きエンティティ認識（ NER ）は、NLP分野の重要なタスクであり、多くの課題を解決するために広く使用されています。 しかし、多くのシナリオでは、すべてのエンティティがテキストで明示的に言及されているわけではありません。 文脈や他の指示的な言葉から推論されることもある。 「CMAは容易に遊離酢酸に加水分解されます。「水は明示的には言及されていませんが、H 2 Oはプロセスに関与する実体であると推測することができます。 この研究では、潜在的実体抽出（ LEE ）の問題を提示する。 潜在的には、エンティティが明示的に書かれていないにもかかわらず、エンティティがテキストで議論されているかどうかを決定するためのいくつかの方法を提示します。 具体的には、複数のエンティティの抽出を共同で処理するニューラルモデルを設計します。 私たちのモデルは、マルチタスク学習アプローチと新規のタスクグルーピングアルゴリズムとともに、潜在的な実体を識別する上で高いパフォーマンスに達することを示しています。 私たちの実験は、生化学分野からの大きな生物学的データセット上で行われます。 データセットには、生物学的プロセスのテキスト説明が含まれており、各プロセスについて、プロセスに関与するすべてのエンティティに、暗黙的に言及されたものを含むラベルが付けられています。 LEEは、多くのNERおよびその後のアプリケーションを大幅に改善し、テキストの理解と推論を改善するタスクであると考えています。', 'zh': '名实识(NER)NLP一任也,博以挑战。 然众情者,非一体皆明于文本也。 或从上下文及他指示性词语中推出。 思下句云:"CMA可易水解成游离乙酸。 虽未明言水,而人可推H2O其事之实体也。 于是潜体取(LEE)。 建数定体,虽非明编。 具体来说,设一神经模形,共理数实。 吾示吾模样及多任务学法与新颖之任分朋算法,于识潜于实体高性能矣。 吾实验者,生化之大集上也。 文集生物之本,凡诸实体,隐式及实体。 信LEE一将显改NER续应用程序改文推理。', 'hi': 'नामित-इकाई मान्यता (एनईआर) एनएलपी क्षेत्र में एक महत्वपूर्ण कार्य है, और व्यापक रूप से कई चुनौतियों को हल करने के लिए उपयोग किया जाता है। हालांकि, कई परिदृश्यों में, सभी निकायों को पाठ में स्पष्ट रूप से उल्लेख नहीं किया गया है। कभी-कभी उन्हें संदर्भ से या अन्य संकेतक शब्दों से अनुमान लगाया जा सकता है। निम्नलिखित वाक्य पर विचार करें: "सीएमए आसानी से मुक्त एसिटिक एसिड में हाइड्रोलाइज़ कर सकता है। यद्यपि पानी का स्पष्ट रूप से उल्लेख नहीं किया गया है, कोई भी अनुमान लगा सकता है कि एच 2 ओ प्रक्रिया में शामिल एक इकाई है। इस काम में, हम अव्यक्त संस्थाओं निष्कर्षण (LEE) की समस्या प्रस्तुत करते हैं। हम यह निर्धारित करने के लिए कई तरीके प्रस्तुत करते हैं कि क्या किसी पाठ में संस्थाओं पर चर्चा की जाती है, भले ही, संभावित रूप से, वे स्पष्ट रूप से लिखे नहीं गए हैं। विशेष रूप से, हम एक तंत्रिका मॉडल डिजाइन करते हैं जो संयुक्त रूप से कई संस्थाओं के निष्कर्षण को संभालता है। हम दिखाते हैं कि हमारा मॉडल, बहु-कार्य सीखने के दृष्टिकोण और एक उपन्यास कार्य समूहीकरण एल्गोरिथ्म के साथ, अव्यक्त संस्थाओं की पहचान करने में उच्च प्रदर्शन तक पहुंचता है। हमारे प्रयोगों को जैव रासायनिक क्षेत्र से एक बड़े जैविक डेटासेट पर आयोजित किया जाता है। डेटासेट में जैविक प्रक्रियाओं का पाठ विवरण होता है, और प्रत्येक प्रक्रिया के लिए, प्रक्रिया में शामिल सभी संस्थाओं को लेबल किया जाता है, जिसमें निहित रूप से उल्लिखित शामिल होते हैं। हमारा मानना है कि LEE एक ऐसा कार्य है जो कई एनईआर और बाद के अनुप्रयोगों में काफी सुधार करेगा और पाठ समझ और अनुमान में सुधार करेगा।', 'ru': 'Распознавание именованных сущностей (NER) является важной задачей в области NLP и широко используется для решения многих проблем. Однако во многих сценариях не все субъекты прямо упоминаются в тексте. Иногда они могут быть выведены из контекста или из других ориентировочных слов. Рассмотрим следующее предложение: «CMA может легко гидролизоваться до свободной уксусной кислоты." Хотя вода прямо не упоминается, можно сделать вывод о том, что H2O является субъектом, участвующим в процессе. В этой работе мы представляем проблему извлечения скрытых сущностей (LEE). Мы предлагаем несколько методов определения того, обсуждаются ли сущности в тексте, даже если, возможно, они не написаны в явном виде. В частности, мы разрабатываем нейронную модель, которая совместно обрабатывает извлечение нескольких сущностей. Мы показываем, что наша модель, наряду с многозадачным подходом к обучению и новым алгоритмом группировки задач, достигает высокой производительности в идентификации скрытых сущностей. Наши эксперименты проводятся на большом наборе биологических данных из биохимического поля. Набор данных содержит текстовые описания биологических процессов, и для каждого процесса все вовлеченные в процесс объекты помечены, в том числе неявно упомянутые. Мы считаем, что LEE - это задача, которая значительно улучшит многие NER и последующие приложения, а также улучшит понимание текста и вывод.', 'ga': 'Is tasc tábhachtach i réimse an NLP é Aitheantas Aonáin Ainmnithe (NER), agus úsáidtear go forleathan é chun go leor dúshlán a réiteach. I go leor cásanna, áfach, ní luaitear na heintitis go léir go sainráite sa téacs. Uaireanta d’fhéadfaí tátal a bhaint astu ón gcomhthéacs nó ó fhocail táscacha eile. Smaoinigh ar an abairt seo a leanas: "Is féidir le CMA hidrealú go héasca isteach i saor-aigéad aicéiteach." Cé nach luaitear uisce go sainráite, is féidir tátal a bhaint as gur eintiteas é H2O a bhfuil baint aige leis an bpróiseas. Sa saothar seo, cuirimid i láthair an fhadhb a bhaineann le Eastóscadh Aonán Folaigh (LEE). Cuirimid roinnt modhanna i láthair chun a chinneadh an bpléitear eintitis i dtéacs, cé go bhféadfadh sé nach bhfuil siad scríofa go sainráite. Go sonrach, déanaimid múnla néarúil a dhearadh a láimhseálann eastóscadh aonán iolrach i gcomhpháirt. Léirímid go sroicheann ár múnla, mar aon le cur chuige foghlama il-tasc agus algartam núíosach tasc-ghrúpála, ardfheidhmíocht maidir le heintitis folaigh a shainaithint. Déantar ár dturgnaimh ar thacar sonraí mór bitheolaíochta ón réimse bithcheimiceach. Tá tuairiscí téacs ar phróisis bhitheolaíocha sa tacar sonraí, agus do gach próiseas, déantar na heintitis go léir a bhfuil baint acu leis an bpróiseas a lipéadú, lena n-áirítear na heintitis a luaitear go hintuigthe. Creidimid gur tasc é LEE a fheabhsóidh go mór go leor feidhmeanna NER agus ina dhiaidh sin agus a fheabhsóidh tuiscint agus tátal téacs.', 'ka': 'NLP პანელში მნიშვნელოვანი ინტერტის განაცნობა (NER) არის მნიშვნელოვანი დავალება, რომელიც ძალიან გამოყენებულია ბევრი გამოცნობა. მაგრამ, ბევრი სინარიოში, არა ყველა ინტერნეტიები ტექსტში განსხვავებულია. ზოგჯერ ისინი შეიძლება იყოს კონტექსტიდან ან სხვა ინდექტიური სიტყვიდან. შემდეგი სიტყვას გადაფიქრობთ: ‘CMA შეუძლია ადვილად ჰიდროლიზება თავისუფალი აციტიკური კვიდიში.’ თუმცა წყალი არ განსხვავებულია, ერთი შეუძლია შეიძლება დააწყალოთ, რომ H2O არის პროცესში ინტერტიკა. ამ სამუშაოში, ჩვენ შემდეგ ინტერნეტიტების ექსტრაქციის პრობლემა (LEE). ჩვენ ვიყვანეთ რამდენიმე მეტი განსაზღვრებისთვის თუ არა ინტერტიები ტექსტის განსაზღვრებულია, თუმცა, პოტენციალურად, ისინი არა გადაწერული. განსაკუთრებულად, ჩვენ ნეიროლური მოდელი დავყენებთ, რომელიც მრავალური ინტერქციების გამოყენება ერთად. ჩვენ აჩვენებთ, რომ ჩვენი მოდელი, რამდენიმე რაოდენობის სწავლების მიზეზეზი და პრომენტური რაოდენობის ალგორიტიმი, გავაკეთებთ უფრო დიდი გამოსახულება ლატენტური ინტერ ჩვენი ექსპერიმენტები დიდი ბიოლოგიური მონაცემების კონფიგურაციაში იქნება. მონაცემების შესახებ ბოლოგიური პროცესის ტექსტის აღწერები, და ყოველ პროცესისთვის ყველა შესახებ პროცესისთვის ყველა შესახებ ინტერტიკები იყენება, რო ჩვენ ვფიქრობთ, რომ LEE არის დავალება, რომელიც მნიშვნელოვანად უფრო მეტი NER და შემდეგ პროგრამები და ტექსტის გაგრძელება და ინფრენცია.', 'hu': 'A nevezett entitások felismerése (NER) fontos feladat az NLP területén , és széles körben használják számos kihívás megoldására. Számos forgatókönyvben azonban nem minden entitást említenek kifejezetten a szövegben. Néha a kontextusból vagy más indikatív szavakból következtethetők le. Vegyük figyelembe a következő mondatot: "A CMA könnyen hidrolizálódik szabad ecetsavvá." Bár a vizet nem említik kifejezetten, következtethetünk arra, hogy a H2O a folyamatban részt vevő entitás. Ebben a munkában bemutatjuk a Latent Entities Extraction (LEE) problémáját. Számos módszert mutatunk be annak meghatározására, hogy az entitásokat egy szövegben tárgyalják-e, még akkor is, ha potenciálisan nem kifejezetten írják-e őket. Konkrétan egy neurális modellt tervezünk, amely több entitás kitermelését együttesen kezeli. Megmutatjuk, hogy modellünk a többfeladatos tanulási megközelítéssel és egy új feladatcsoportosító algoritmussal együtt nagy teljesítményt ér el a látens entitások azonosításában. Kísérleteinket biokémiai mezőből származó nagy biológiai adatkészleten végezzük. Az adatkészlet a biológiai folyamatok szöveges leírásait tartalmazza, és minden folyamat esetében a folyamatban részt vevő valamennyi entitás címkézésre kerül, beleértve az implicit módon említetteket is. Hisszük, hogy a LEE egy olyan feladat, amely jelentősen javítja a NER és az azt követő alkalmazásokat, és javítja a szöveg megértését és következtetését.', 'el': 'Η αναγνώριση ονομαστικής οντότητας (ΝΕΡ) είναι ένα σημαντικό έργο στον τομέα και χρησιμοποιείται ευρέως για την επίλυση πολλών προκλήσεων. Ωστόσο, σε πολλά σενάρια, δεν αναφέρονται ρητά όλες οι οντότητες στο κείμενο. Μερικές φορές θα μπορούσαν να συναχθούν από το πλαίσιο ή από άλλες ενδεικτικές λέξεις. Εξετάστε την ακόλουθη πρόταση: "Η CMA μπορεί εύκολα να υδρολύσει σε ελεύθερο οξικό οξύ." Αν και το νερό δεν αναφέρεται ρητά, μπορεί κανείς να συμπεράνει ότι το H2O είναι μια οντότητα που εμπλέκεται στη διαδικασία. Στην παρούσα εργασία, παρουσιάζουμε το πρόβλημα της εξαγωγής λανθάνουσας οντότητας. Παρουσιάζουμε διάφορες μεθόδους για τον προσδιορισμό του αν οι οντότητες συζητούνται σε ένα κείμενο, αν και, ενδεχομένως, δεν είναι ρητά γραμμένες. Συγκεκριμένα, σχεδιάζουμε ένα νευρωνικό μοντέλο που χειρίζεται την εξαγωγή πολλαπλών οντοτήτων από κοινού. Δείχνουμε ότι το μοντέλο μας, μαζί με την προσέγγιση εκμάθησης πολλαπλών εργασιών και έναν νέο αλγόριθμο ομαδοποίησης εργασιών, επιτυγχάνει υψηλές επιδόσεις στον εντοπισμό λανθάνοντων οντοτήτων. Τα πειράματά μας διεξάγονται σε ένα μεγάλο βιολογικό σύνολο δεδομένων από το βιοχημικό πεδίο. Το σύνολο δεδομένων περιέχει περιγραφές κειμένων βιολογικών διεργασιών και για κάθε διεργασία επισημαίνονται όλες οι εμπλεκόμενες οντότητες στη διαδικασία, συμπεριλαμβανομένων των σιωπηρών αναφερόμενων. Πιστεύουμε ότι είναι ένα έργο που θα βελτιώσει σημαντικά πολλές εφαρμογές και θα βελτιώσει την κατανόηση και συναγωγή κειμένου.', 'it': 'Il riconoscimento delle entità denominate (NER) è un compito importante nel campo della PNL ed è ampiamente usato per risolvere molte sfide. Tuttavia, in molti scenari, non tutte le entità sono esplicitamente menzionate nel testo. A volte potrebbero essere dedotti dal contesto o da altre parole indicative. Considera la seguente frase: "La CMA può facilmente idrolizzarsi in acido acetico libero". Sebbene l\'acqua non sia menzionata esplicitamente, si può dedurre che l\'H2O sia un\'entità coinvolta nel processo. In questo lavoro presentiamo il problema dell\'estrazione di entità latenti (LEE). Presentiamo diversi metodi per determinare se le entità sono discusse in un testo, anche se, potenzialmente, non sono scritte esplicitamente. Nello specifico, progettiamo un modello neurale che gestisce l\'estrazione di più entità congiuntamente. Mostriamo che il nostro modello, insieme all\'approccio di apprendimento multi-task e ad un nuovo algoritmo di raggruppamento delle attività, raggiunge elevate prestazioni nell\'identificazione delle entità latenti. I nostri esperimenti sono condotti su un ampio set di dati biologici provenienti dal campo biochimico. Il dataset contiene descrizioni testuali dei processi biologici, e per ogni processo vengono etichettate tutte le entità coinvolte nel processo, comprese quelle implicitamente menzionate. Crediamo che LEE sia un compito che migliorerà significativamente molte applicazioni NER e successive e migliorerà la comprensione e l\'inferenza del testo.', 'kk': 'Аталған нысандарды анықтау (NER) NLP өрісінде маңызды тапсырма, бірақ көп мәселелерді шешу үшін көп қолданылады. Бірақ көп сценарияларда барлық нысандар мәтінде таңдамайды. Кейбірде олар контекстіктен немесе басқа көрсетілетін сөздерден қалдырылуы мүмкін. Келесі мәліметті қараңыз: "CMA бос ацетикалық кисетіне оңай гидролизацияланады". Сулы таңдамаған сияқты айтылмаса да, H2O процестің бір бөлігі екенін анықтай алады. Бұл жұмыстың соңғы нысандарды тарқату (LEE) мәселесін таңдаймыз. Біз бірнеше әдістерді мәтінде сөйлесу үшін бірнеше әдістерді таңдаймыз. Бірақ бұл әдістер жазылмайды. Ескерілі, біз бірнеше нысандарды тарқату үлгісін құрамыз. Біз моделімізді, көп тапсырмаларды оқыту арқылы және романдық тапсырмаларды топтастыру алгоритмімізді көрсету арқылы, жаңа тапсырмаларды анықтау арқылы жоғары істеу арқылы Біздің эксперименттеріміз биохимиялық өрістердің үлкен биологиялық деректер жиынында тұрады. Деректер жиында биологиялық процестердің мәтін түсініктемелері бар, және әрбір процес үшін, процестің барлық бөліктері жарлық, мәтін түсініктемелері бар. LEE - көптеген NER және кейінгі қолданбаларды жақсарту және мәтінді түсініктерді және көпшіліктерді жасайтын тапсырма деп ойлаймыз.', 'mk': 'Признавањето на именуваниот ентитет (НЕР) е важна задача во полето НЛП и широко се користи за решавање на многу предизвици. Сепак, во многу сценарија, не сите ентитети се експлицитно споменати во текстот. Понекогаш може да се заклучат од контекст или од други индикативни зборови. Размислете за следната реченица: „CMA може лесно да се хидролизира во слободна оцетна киселина.“ Although water is not mentioned explicitly, one can infer that H2O is an entity involved in the process.  Во оваа работа го претставуваме проблемот со извлекувањето на последните ентитети (LEE). Презентираме неколку методи за одредување дали ентитетите се дискутирани во текст, иако, потенцијално, тие не се експлицитно напишани. Специфично, дизајнираме нервен модел кој се справува со екстракција на повеќе ентитети заедно. Ние покажуваме дека нашиот модел, заедно со пристапот на учење со мултизадачи и нов алгоритм за групирање задачи, достигнува висока резултат во идентификувањето на latent ентитети. Нашите експерименти се спроведуваат на големи биолошки податоци од биохемиското поле. Податоците содржат текстови описи на биолошките процеси, и за секој процес, сите вклучени ентитети во процесот се означени, вклучувајќи ги и имплицитно споменетите. Веруваме дека ЛИ е задача која значително ќе ги подобри многумина НЕР и последните апликации и ќе го подобри разбирањето на текстот и конференцијата.', 'ms': 'Pengenalan-entiti bernama (NER) adalah tugas penting dalam medan NLP, dan digunakan secara luas untuk menyelesaikan banyak cabaran. Namun, dalam banyak skenario, tidak semua entiti disebut secara eksplicit dalam teks. Kadang-kadang mereka boleh dicatat dari konteks atau dari kata-kata indikasif lain. Pertimbangkan kalimat berikut: "CMA boleh mudah hidrolis menjadi asid aset bebas." Walaupun air tidak disebut secara eksplicit, anda boleh menyimpulkan bahawa H2O adalah entiti yang terlibat dalam proses. Dalam kerja ini, kita memperkenalkan masalah ekstraksi Entiti Terlambat (LEE). Kami memperkenalkan beberapa kaedah untuk menentukan sama ada entiti dibahas dalam teks, walaupun, mungkin, ia tidak ditulis secara eksplicit. Secara khusus, kita merancang model saraf yang mengendalikan ekstraksi entiti berbilang bersama-sama. We show that our model, along with multi-task learning approach and a novel task grouping algorithm, reaches high performance in identifying latent entities.  Eksperimen kami dilakukan pada set data biologi besar dari medan biokimia. Set data mengandungi deskripsi teks proses biologi, dan untuk setiap proses, semua entiti yang terlibat dalam proses ditabel, termasuk yang disebut secara implicit. Kami percaya LEE adalah tugas yang akan meningkatkan kebanyakan aplikasi NER dan aplikasi berikutnya dan meningkatkan pemahaman teks dan kesimpulan.', 'ml': 'പേരു് പേരു് സാധാരണ തിരിച്ചറിയുന്നതു് (NER) NLP ഫീള്\u200dഡില്\u200d ഒരു പ്രധാനപ്പെട്ട ജോലിയാണു്, പിന്നെ പല വിലാസങ്ങളും പരി എന്നാലും, പലതും കാഴ്ചകളില്\u200d എല്ലാ വസ്തുക്കളും പദാവലിയില്\u200d വ്യക്തമായി പ്രസ്താവിക്കുന്നില്ല. ചിലപ്പോള്\u200d അവര്\u200dക്ക് സംസ്ഥാനത്തില്\u200d നിന്നോ മറ്റു ചില വാക്കുകളില്\u200d നിന്നോ ബാധിക്കാന്\u200d കഴിയും. താഴെയുള്ള വാക്കുകള്\u200d ആലോചിച്ച് നോക്കൂ: "സിഎം എളുപ്പമായി ഹൈഡ്രോളൈസ് സ്വാതന്ത്ര്യ ഏസിഡിലേക് വെള്ളം വ്യക്തമായി പ്രസ്താവിക്കുന്നില്ലെങ്കിലും, H2O പ്രക്രിയയില്\u200d പങ്കുള്ള ഒരു വസ്തുവാണെന്ന് ആര്\u200dക്കും  ഈ ജോലിയില്\u200d നമ്മള്\u200d ലാറ്റിന്\u200dറെ എന്റിറ്റികളുടെ പ്രശ്നത്തെ കാണിക്കുന്നു. ഒരു ടെക്സ്റ്റില്\u200d വസ്തുക്കള്\u200d സംസാരിക്കപ്പെടുന്നുണ്ടോ എന്ന് നിരീക്ഷിക്കാന്\u200d ഞങ്ങള്\u200d പല രീതികളും കൊണ്ടുവന്നിട്ട പ്രത്യേകിച്ച്, നമ്മള്\u200d ഒരു നെയൂറല്\u200d മോഡല്\u200d നിര്\u200dമ്മിക്കുന്നു. അത് ഒരുമിച്ച് പല വസ്തുക്കളുടെ പുറത്തെടുക്ക ഞങ്ങള്\u200d കാണിച്ചു കൊടുക്കുന്നു നമ്മുടെ മോഡല്\u200d, പലിപ്പണികള്\u200d പഠിക്കുന്ന പ്രായോഗ്രൂപ്പ് ചെയ്യുന്ന ഒരു നോവല്\u200d ജോലി ഗ്രൂപ നമ്മുടെ പരീക്ഷണങ്ങള്\u200d ജീവിയോളജിക്ക് ഡാറ്റാസെറ്റില്\u200d നിന്നും നടത്തിയിരിക്കുന്നു. ഡാറ്റാസെറ്റില്\u200d ജീവിയോളജിക്കല്\u200d പ്രക്രിയകളുടെ പദാവലികള്\u200d വിശദീകരിക്കുന്നു. പ്രക്രിയയില്\u200d ഉള്\u200dപ്പെട്ട എല്ലാ വസ്തുക്കളും പ്രക നമ്മള്\u200d വിശ്വസിക്കുന്നത് ലീം ഒരു ജോലിയാണെന്നും, പിന്നീട് പ്രയോഗങ്ങള്\u200d വളരെ മെച്ചപ്പെടുത്തുന്നതും, പദാവലിയുടെ ബുദ', 'lt': 'Pavadintų subjektų pripažinimas (NER) yra svarbi užduotis NLP srityje ir plačiai naudojamas daugeliui iššūkių išspręsti. Tačiau daugeliu scenarijų tekste aiškiai paminėti ne visi subjektai. Kartais jie gali būti daromi remiantis kontekstu arba kitais orientaciniais žodžiais. Apsvarstykite šį sakinį: "CMA gali lengvai hidrolizuoti į laisvą acto rūgštį." Nors vandens aiškiai nenurodyta, galima daryti išvadą, kad H2O yra procese dalyvaujantis subjektas. Šiame darbe pristatome Latent Entities Extraction (LEE) problem ą. Mes pateikiame keletą metodų, kaip nustatyti, ar subjektai aptariami tekste, nors jie potencialiai nėra aiškiai rašomi. Konkrečiai, mes sukuriame nervinį model į, kuris bendrai tvarko kelių subjektų gavybą. We show that our model, along with multi-task learning approach and a novel task grouping algorithm, reaches high performance in identifying latent entities.  Our experiments are conducted on a large biological dataset from the biochemical field.  Duomenų rinkinyje pateikiami biologinių procesų tekstiniai aprašymai, o kiekvienam procesui ženklinami visi procese dalyvaujantys subjektai, įskaitant netiesiogiai minėtus. Manome, kad LEE yra užduotis, kuri gerokai pagerins daugelį NER ir vėlesnių programų bei pagerins tekstų supratimą ir išvadas.', 'mn': 'Нэр нэрлэгдсэн entity Recognition (NER) нь NLP салбарт чухал ажил юм. Мөн олон сорилтуудыг шийдэхэд маш их хэрэглэгддэг. Гэхдээ олон тохиолдолд бүх үйл ажиллагаанууд биш л дээ. Заримдаа эдгээр хүмүүс нөхцөл байдлаас эсвэл бусад илэрхийлэлтэй үгнээс халдварлах боломжтой. Дараагийн өгүүлбэрийг ойлгоод үзээрэй: "CMA нь үнэгүй асетик хүчилтөрөгчид амархан устөрөгчилж чадна" гэсэн үг. Ус тодорхой хэлж чадахгүй ч, нэг нь H2O үйлдвэрлэлд оролцсон нэг зүйл гэдгийг ойлгож чадна. Энэ ажлын дараа бид Сүүлийн Объектын хайлтын асуудлыг харуулж байна. Бид хэд хэдэн арга зам бичиж байгааг тодорхой бичиж чадахгүй байгааг тодорхойлдог. Ялангуяа бид олон бүтээгдэхүүнийг хамтдаа татах мэдрэлийн загварын загвар бүтээж байна. Бид загварын загвар, олон ажлын суралцах арга болон шинэ ажлын алгоритм хэмжээний алгоритмыг харуулж байгааг харуулж байна. Биохимийн салбарын том биологийн өгөгдлийн санд туршилт хийгдсэн. Өгөгдлийн санд биологийн процессийн текст тодорхойлолт бий. Бүх процессийн хувьд бүх үйл явцдаа холбогдсон бүх үйл явцдаа нэрлэгддэг. LEE бол олон НЕР болон дараагийн хэрэглэгүүдийг сайжруулж, текст ойлголт болон халдварыг сайжруулж чадна гэдэгт бид итгэдэг.', 'pl': 'Rozpoznawanie nazwanych podmiotów (NER) jest ważnym zadaniem w dziedzinie NLP i jest szeroko stosowane do rozwiązywania wielu wyzwań. Jednak w wielu scenariuszach nie wszystkie podmioty są wyraźnie wymienione w tekście. Czasami można je wywnioskować z kontekstu lub z innych orientacyjnych słów. Rozważmy następujące zdanie: "CMA może łatwo hydrolizować się w wolny kwas octowy." Chociaż woda nie jest wyraźnie wymieniona, można wnioskować, że H2O jest podmiotem zaangażowanym w proces. W niniejszej pracy przedstawiamy problem ekstrakcji Latent Entities Extraction (LEE). Przedstawiamy kilka metod określania, czy podmioty są omawiane w tekście, chociaż potencjalnie nie są one pisane wyraźnie. W szczególności projektujemy model neuronowy, który wspólnie obsługuje ekstrakcję wielu jednostek. Pokazujemy, że nasz model wraz z wielozadaniowym podejściem uczenia się i nowym algorytmem grupowania zadań osiąga wysoką wydajność w identyfikacji utajonych podmiotów. Nasze eksperymenty prowadzone są na dużym zbiorze danych biologicznych z pola biochemicznego. Zestaw danych zawiera opisy tekstowe procesów biologicznych, a dla każdego procesu etykietowane są wszystkie zaangażowane w proces podmioty, w tym te wymienione domyślnie. Wierzymy, że LEE jest zadaniem, które znacząco poprawi wiele NER i kolejnych aplikacji oraz poprawi zrozumienie i wnioskowanie tekstu.', 'no': 'Namnet entitetskjenning (NER) er ein viktig oppgåve i NLP- feltet, og blir brukt for å løysa mange utfordringar. I mange scenarioar er imidlertid ikkje alle einingane eksplisivt gjeven i teksten. Noen ganger kan dei bli inferrert frå konteksten eller frå andre indikative ord. Tenk på følgjande setninga: « CMA kan lett hydrolysera til fri etiske acid ». Selv om vann ikkje er spesifisert, kan det gjere at H2O er eit entitet som er involvert i prosessen. I denne arbeida viser vi problemet med det siste utpakkinga av einingar (LEE). Vi presenterer fleire metodar for å bestemme om einingar vert diskutert i eit tekst, selv om det er mogleg at dei ikkje er eksplisisert skriven. Dette er spesielt eit neuralmodell som handterar ekstrahering av fleire einingar. Vi viser at modellen vår, saman med fleire oppgåver-læringstilnærming og ein novel oppgåvegrupperingsalgoritme, når det gjer høg utvikling i identifisering av latente einingar. Eksperimentane våre er gjennomført på ein stor biologisk dataset frå biokjemisk feltet. Datasettet inneheld tekstskildringar av biologiske prosesser, og for kvar prosess vert alle dei involverte einingane i prosessen merket, inkludert implisitt gjeven. Vi tror at LEE er ei oppgåve som vil forbetra mange NER og etternamne program og forbedra tekstforståelse og infeksjon.', 'ro': 'Recunoașterea entităților denumite (NER) este o sarcină importantă în domeniul PNL și este utilizată pe scară largă pentru a rezolva numeroase provocări. Cu toate acestea, în multe scenarii, nu toate entitățile sunt menționate în mod explicit în text. Uneori, acestea pot fi deduse din context sau din alte cuvinte indicative. Luați în considerare următoarea propoziție: "CMA se poate hidroliza cu ușurință în acid acetic liber." Deși apa nu este menționată în mod explicit, se poate deduce că H2O este o entitate implicată în proces. În această lucrare, prezentăm problema extracției entităților latente (LEE). Prezentăm mai multe metode pentru a determina dacă entitățile sunt discutate într-un text, chiar dacă, potențial, ele nu sunt scrise în mod explicit. Mai exact, proiectăm un model neural care gestionează extracția mai multor entități în comun. Aratăm că modelul nostru, împreună cu abordarea de învățare multi-sarcini și un algoritm nou de grupare a sarcinilor, atinge performanțe ridicate în identificarea entităților latente. Experimentele noastre sunt efectuate pe un set mare de date biologice din câmpul biochimic. Setul de date conține descrieri text ale proceselor biologice, iar pentru fiecare proces, toate entitățile implicate în proces sunt etichetate, inclusiv cele menționate implicit. Credem că LEE este o sarcină care va îmbunătăți semnificativ multe aplicații NER și ulterioare și va îmbunătăți înțelegerea și inferența textului.', 'mt': "Ir-Rikonoxximent tal-Entità Ismija (NER) huwa kompitu importanti fil-qasam tal-NLP, u jintuża b’mod wiesa’ biex isolvi ħafna sfidi. Madankollu, f’ħafna xenarji, mhux l-entitajiet kollha jissemmew espliċitament fit-test. Xi kultant jistgħu jiġu inferiti mill-kuntest jew minn kliem indikattiv ieħor. Ikkunsidra s-sentenza li ġejja: 'CMA tista' faċilment issir idrolizzata f'aċidu aċetiku ħieles.' Għalkemm l-ilma mhuwiex imsemmi espliċitament, wieħed jista’ jikkonkludi li l-H2O huwa entità involuta fil-proċess. F’din il-ħidma, qed nippreżentaw il-problema tal-Estrazzjoni tal-Entitajiet Latenti (LEE). We present several methods for determining whether entities are discussed in a text, even though, potentially, they are not explicitly written.  Speċifikament, niddisinjaw mudell newrali li jimmaniġġja l-estrazzjoni ta’ diversi entitajiet b’mod konġunt. Aħna nuru li l-mudell tagħna, flimkien ma’ approċċ ta’ tagħlim multikompiti u algoritmu ġdid ta’ raggruppament ta’ kompiti, jilħaq prestazzjoni għolja fl-identifikazzjoni ta’ entitajiet moħbija. L-esperimenti tagħna jitwettqu fuq sett kbir ta’ dejta bijoloġika mill-qasam bijokimiku. Is-sett tad-dejta fih deskrizzjonijiet tat-test tal-proċessi bijoloġiċi, u għal kull proċess, l-entitajiet kollha involuti fil-proċess huma ttikkettati, inklużi dawk imsemmija impliċitament. Aħna nemmnu li LEE huwa kompitu li se jtejjeb b’mod sinifikanti ħafna applikazzjonijiet NER u sussegwenti u jtejjeb il-fehim u l-inferenza tat-test.", 'so': 'Aqoonsashada magaca (NER) waa shaqa muhiim ah oo ku jira beerta NLP, waxaana loo isticmaalaa in aad u xajiso dhibaatooyin badan. Si kastaba ha ahaatee marxalado badan waxyaabaha dhamaantood si cad looma sheego qoraalka. Mararka qaarkood waxaa laga yaabaa in lagu dhibo mukhtarka ama hadalo kale oo la jeedo. Ka fikir hadalka soo socda: "CMA si fudud ayuu si fudud u hydrolyze karo acid kaliya ah. Although water is not mentioned explicitly, one can infer that H2O is an entity involved in the process.  Shaqadan, waxaynu keenaynaa dhibaatada soo bixinta ganacsiga ugu dambeeya (LEE). Waxaannu soo saaraynaa qaabooyin badan oo ku saabsan in entities looga hadlo qoraal, in kastoo ay suurtowda aysan si cad u qornayn. Si gaar ah, waxaynu sameynaa model neurada ah oo isku daryeela soo bixinta alaabta badan. Waxaynu muujinnaa in qaababkayaga, sameynta qaabab waxbarasho badan oo shaqo badan iyo kooxa shaqo kooxaha saxda ah, waxay gaadhaa shaqo aad u dheer si ay u aqoonsadaan waxyaabaha ugu dambeeya. Imtixaankayada waxaa lagu sameeyaa sawir badan oo biological ah oo ka yimid beerta biokemika. Taariikhda waxaa ku qoran qoraal qoraal ah oo ku qoran baaritaanka biologiyiga ah, dhamaantoodna waxaa lagu qoraa dhamaan waxyaabaha la xiriira marka lagu sameeyo, kuwaas oo ku qoran qoraal. Waxaynu aaminsanahay in LEE waa shaqa aad u bedelan karta NEA iyo codsiyada ka dambeeya oo horumarinaya waxgarashada qoraalka iyo baahida.', 'si': 'NLP ක්\u200dෂේත්\u200dරයේ නමක් තියෙන්න ප්\u200dරශ්නයක් (NER) තමයි ලොකු වැදගත් වැඩක්, ඒ වගේම ප්\u200dරශ්නයක් ගොඩක් අභ්\u200dයාසය නමුත්, ගොඩක් සිද්ධානයක් තියෙන්නේ, සියළුම සියළුම් පාළුවට පැහැදිලිවෙන්නේ නැහැ. සමහර වෙලාවට ඔවුන්ට සම්බන්ධයෙන් ප්\u200dරතිකාරයෙන් වෙන්න පුළුවන් වෙන්න පුළුවන්. පස්සේ වාක්ය බලන්න: CMA පුළුවන් පස්සෙන් ඇසිටික් ඇසිටික් වලට හයිඩ්\u200dරොලිස් කරන්න පුළුවන්. වතුර පැහැදිලිවම කියන්නේ නැත්නම්, කිසිම කෙනෙක්ට පුළුවන් H2O කියලා ප්\u200dරවෘත්තියේදී ඇතුළත් අයි මේ වැඩේ අපි ප්\u200dරශ්නයක් පෙන්වන්නේ අන්තිම අන්තිමේත්තු ප්\u200dරශ්නයක් (LEE). අපි ප්\u200dරවේශනයක් තීරණය කරන්න විධානයක් තීරණය කරන්න ප්\u200dරවේශනයක් තියෙනවා පාළුවක් තියෙන්නේ නැද්ද කියලා, ඒත්,  විශේෂයෙන්ම, අපි න්\u200dයූරාල් මොඩේලයක් සැකසුම් කරනවා ඒ වගේම විශේෂයක් සම්බන්ධ වෙනුවෙන් ප අපි පෙන්වන්නේ අපේ මොඩේල්, ගොඩක් වැඩි වැඩක් ඉගෙන ගන්න පුළුවන් එක්ක, නියම වැඩක් අල්ගෝරිතම් එක්ක, පුළුවන් වැඩක්  අපේ පරීක්ෂණයක් ජීවිත්\u200dයාත්මක දත්ත සූදානයක් පරීක්ෂණය කරනවා. දත්ත සම්බන්ධයේ ජීවිත පරීක්ෂණයේ පාළු විස්තර, හැම ප්\u200dරක්\u200dරියාව සඳහා හැම ප්\u200dරක්\u200dරියාව සම්බන්ධ විස්තාරයක්ම ලේ අපි විශ්වාස කරනවා LEE තමයි ගොඩක් NER සහ පස්සේ ප්\u200dරයෝගයක් වඩා වැඩි වෙන්න පුළුවන් වෙන්න පුළුවන් වැඩි', 'sv': 'Named-entity Recognition (NER) är en viktig uppgift inom NLP-området och används ofta för att lösa många utmaningar. I många scenarier nämns dock inte alla entiteter uttryckligen i texten. Ibland kunde de härledas från sammanhanget eller från andra vägledande ord. Tänk på följande mening: "CMA kan lätt hydrolyseras till fri ättiksyra." Även om vatten inte nämns uttryckligen kan man dra slutsatsen att H2O är en enhet som är involverad i processen. I detta arbete presenterar vi problemet med Latent Entities Extraction (LEE). Vi presenterar flera metoder för att avgöra om entiteter diskuteras i en text, även om de potentiellt inte är uttryckligen skrivna. Specifikt utformar vi en neural modell som hanterar extraktion av flera entiteter gemensamt. Vi visar att vår modell, tillsammans med multi-task learning approach och en ny uppgiftsgrupperingsalgoritm, uppnår hög prestanda när det gäller att identifiera latenta entiteter. Våra experiment utförs på en stor biologisk datamängd från det biokemiska fältet. Datauppsättningen innehåller textbeskrivningar av biologiska processer, och för varje process märks alla inblandade enheter i processen, inklusive underförstått nämnda. Vi tror att LEE är en uppgift som avsevärt kommer att förbättra många NER och efterföljande applikationer och förbättra textförståelsen och slutresultatet.', 'ta': 'பெயரிடப்பட்ட பொருள் அடையாளம் (NER) NLP புலத்தில் ஒரு முக்கியமான செயல் However, in many scenarios, not all of the entities are explicitly mentioned in the text.  சில நேரங்களில் அவர்கள் சூழலிலிருந்து அல்லது மற்ற சுட்டிக்காட்சி வார்த்தைகளிலிருந்து பாதி பின்வரும் வாக்கியத்தை கவனி எனினும் நீர் வெளிப்படையாக குறிப்பிடப்படவில்லையானாலும், H2O என்பது செயல்பாட்டில் சேர்க்கப்பட்ட ஒரு உறுதி இந்த வேலையில், நாம் சமீபத்தில் உள்ள வெளியேற்றத்தின் பிரச்சனையை காண்பிக்கிறோம். பொருள்கள் உரையில் விவாதம் செய்யப்பட்டுள்ளதா என்று தீர்மானிக்க பல முறைகளை நாம் கொண்டுள்ளோம். குறிப்பிட்டு, நாம் காண்பிக்கிறோம் எங்கள் மாதிரி, பல பணிகள் கற்றுக்கொள்ளும் முறைமையுடன் மற்றும் ஒரு புதிய செயல் குழுவாக்கம் குழுவாக்கம்,  உயிரியல் நிலையிலிருந்து ஒரு பெரிய உயிரியல் தரவுத்தளத்தில் எங்கள் சோதனைகள் செயல்படுத்தப்பட்டது. தரவுத்தளத்தில் உயிரியல் செயல்களின் உரை விவரிப்புகள் உள்ளது, ஒவ்வொரு செயலுக்கும், செயல்பாட்டில் உள்ள அனைத்து உட்பொருள்களும் குறி LEE என்பது ஒரு செயலாகும் அது பெரும்பாலாக நிறைய NER மற்றும் பின்னர் பயன்பாடுகளை மேம்படுத்தும் மற்றும் உரை புரிந்து பு', 'ur': 'NLP میدان میں نام لیا گیا انٹیٹی پکارنا (NER) ایک اہم کام ہے، اور بہت سی چالوں کو حل کرنے کے لئے وسیع استعمال کیا جاتا ہے. اگرچہ بہت سی نظریوں میں، تمام اتحادیوں کو متن میں واضح طور پر بیان نہیں کیا جاتا۔ بعض اوقات یہ متصلہ سے یا دوسری نشانیاں باتوں سے نازل ہوسکتے ہیں۔ نیچے مطلب کو دیکھو کہ CMA آسان آسانی میں آسان ہو سکتا ہے۔ اگرچہ پانی واضح طور پر ذکر نہیں کی جاتی ہے، ایک شخص یہ بتا سکتا ہے کہ H2O پردازش میں ایک چیز ہے۔ ہم اس کام میں اچھی ایٹیوٹیٹیوں کے اٹھانے کے مشکل کو پیش کرتے ہیں۔ ہم بہت سی طریقے پیش کرتے ہیں کہ مقرر کرنے کے لئے ایک متن میں بحث کیا جاتا ہے، اگرچہ شاید یہ صریح طور پر لکھی نہیں جاتی۔ خاص طور پر، ہم ایک نئورل موڈل طراحی کرتے ہیں جو بہت سی ایٹینٹیوں کے اخراج کا مشترک طراحی کرتا ہے۔ ہم دکھاتے ہیں کہ ہماری مدل، بہت سے کاموں کی تعلیم کی طریقہ کے ساتھ اور ایک نئی کام کی گروپ الگوریتم کے ساتھ، لوٹینٹ ایٹنیٹوں کی شناسایی میں اچھی کام پہنچتی ہے۔ ہماری آزمائش بیولوژیکی فیلڈ سے ایک بڑے زیست بیولوژیکی ڈاٹ سٹ پر چلتی ہے۔ ڈاٹ سٹ میں بیولوژیکوں پرسس کی متن کی تعریف ہے، اور ہر پرسس کے لئے، تمام پرسس میں شامل ہونے والی ایٹنیٹیوں کو لابلوٹ کر دیا جاتا ہے، یہاں تک کہ ذکر کیا جاتا ہے. ہم سمجھتے ہیں کہ LEE ایک کام ہے جو بہت سی NER اور اس کے بعد بہت سی کاریالوں کو اچھی طرح اچھی طرح کرے گا اور پیغام سمجھنے اور کمزوری کو اچھی طرح اچھی طرح کرے گا۔', 'sr': 'Prepoznavanje imenovanih entiteta (NER) je važan zadatak u polju NLP-a, koji se široko koristi za rješavanje mnogih izazova. Međutim, u mnogim scenarijama, ne svi entiteti se pojasno spominju u tekstu. Ponekad bi mogli biti inficirani iz konteksta ili iz drugih indikativnih reèi. Smatrajte sljedeću rečenicu: "CMA može lako hidrolizirati u besplatnu acetsku kiselinu." Iako se voda ne spominje jasno, može inferirati da je H2O entitet uključen u taj proces. U ovom poslu predstavljamo problem izvlačenja poslednjih subjekta (LEE). Predstavljamo nekoliko metoda da odredimo da li se entiteti raspravljaju u tekstu, iako, potencijalno, nisu napisani jasno. Posebno, mi dizajniramo neuralni model koji zajedno vodi ekstrakciju višestrukih entiteta. Pokazujemo da naš model, zajedno s pristupom multi task učenja i novim algoritmom skupine zadataka, dostigne visoke funkcije u identifikaciji latentnih entitata. Naši eksperimenti su provedeni na velikom biološkom setu podataka iz biohemijskog polja. Podaci sadrže tekst opisa bioloških procesa, a za svaki proces, svi uključeni entiteti u proces su označeni, uključujući implicitno spominjane. Vjerujemo da je LEE zadatak koji će značajno poboljšati mnoge NER i poslednje aplikacije i poboljšati razumijevanje teksta i infekciju.', 'uz': "Name Lekin, ko'pchilik aniqlarida, hamma narsalar matnning oddiy emas. Ba'zida ularning tarkibini yoki boshqa nishonchalar so'zlaridan qo'shiladi. Quyidagi so'zlarni tasavvur qiling: “CMA бўйинсундириб ўтувчи acetik acid bo'lishi mumkin”. Ko'pchilik suv notoʻgʻri emas, biri oddiy holatda ishlab chiqarishi mumkin. Bu ishda, biz Keyingi narsalarni chiqarish (LEE) muammolarini ko'raymiz. Biz obʼektlar matn bilan murojaat qilayotganligini aniqlash uchun bir necha metodalarni hozir qilamiz, ammo ular faqat yozilmaydi. Koʻrsatilgan, biz bir necha narsalarni bir necha obʼektlarni birlashtirishni boshqaruvchi neyrol modelini yaratib olamiz. Biz bir necha vazifa o'rganish muvaffaqiyatli va novel vazifa guruhini guruhlashimizni ko'rsatishimiz mumkin. Yaqinda tashkilotlarni aniqlash uchun eng yuqori bajarishimizni ko'rsatdik. Biologik davlatdan katta biological maʼlumotlarimiz bajarildi. Name Bizlarga ishonamiz, LEE juda ham ko'p NER va keyingi dasturlarni yaxshi ko'proq o'zgartiradi va matn imkoniyatini va oqinligini bajaradi.", 'vi': 'Nhận dạng khối có tên (NER) là một nhiệm vụ quan trọng trong lĩnh vực N/P, và được sử dụng rộng rãi để giải quyết nhiều thử thách. Tuy nhiên, trong nhiều viễn cảnh, không phải tất cả các thực thể được ghi rõ trong văn bản. Đôi khi họ có thể được kết luận từ ngữ cảnh hoặc từ những từ chỉ dẫn khác. Hãy nghĩ tới câu sau: "CMA có thể dễ dàng hydrolyze thành axit acetic free." Mặc dù nước không được đề cập trực tiếp, nhưng có thể kết luận rằng H2O là một thực thể liên quan đến quá trình này. Trong công việc này, chúng tôi đưa ra vấn đề về các loài mới có mặt (LEE). Chúng tôi đưa ra nhiều phương pháp để xác định xem các thực thể được thảo luận trong một văn bản, mặc dù, có khả năng, chúng không được viết rõ ràng. Cụ thể, chúng tôi thiết kế một mô hình thần kinh chuyên giải quyết nhiều thực thể cùng nhau. Chúng tôi cho thấy mẫu của chúng tôi, cùng với phương pháp học tập đa nhiệm vụ và thuật toán mới, đạt hiệu quả cao để xác định các thực thể tiềm ẩn. Các thí nghiệm của chúng tôi được tiến hành trên một bộ dữ liệu sinh học lớn từ trường sinh học. Bộ dữ liệu chứa mô tả văn bản về các tiến trình sinh học, và cho mỗi tiến trình, tất cả các thực thể liên quan trong quá trình được đánh dấu, kể cả những tiến trình có ghi rõ. Chúng tôi tin rằng LEE là một nhiệm vụ có thể cải thiện nhiều môi trường bất động sản và các ứng dụng sau đó và cải thiện hiểu biết và luận văn bản.', 'hr': 'Prepoznavanje imenovanih entitata (NER) je važan zadatak na polju NLP-a i široko se koristi za rješavanje mnogih izazova. Međutim, u mnogim scenarijama, ne sve subjekte se pojasno spominju u tekstu. Ponekad bi se mogli zaraziti iz konteksta ili iz drugih indikativnih riječi. Smatrajte sljedeću rečenicu: "CMA može lako hidrolizirati u besplatnu acetsku kiselinu." Iako se voda ne spominje jasno, može uvjeriti da je H2O subjekt uključen u proces. U ovom poslu predstavljamo problem izvlačenja posljednjih subjekta (LEE). Predstavljamo nekoliko metoda za određivanje da li se entiteti raspravljaju u tekstu, iako, potencijalno, nisu jasno napisani. Posebno, mi dizajniramo neuralni model koji zajedno vodi ekstrakciju višestrukih entitata. Pokazujemo da naš model, zajedno s pristupom multi task učenja i novom algoritmom skupine zadataka, dostigne visoke funkcije u identifikaciji latentnih entitata. Naši eksperimenti su provedeni na velikom biološkom setu podataka iz biokemijskog polja. Podaci sadrže tekstualne opise bioloških procesa, a za svaki proces se označavaju svi uključeni subjekti u procesu, uključujući implicitno spomenute. Vjerujemo da je LEE zadatak koji će značajno poboljšati mnoge NER i sljedeće primjene i poboljšati razumijevanje teksta i infekciju.', 'da': 'Named-entity Recognition (NER) er en vigtig opgave på NLP-området og bruges i vid udstrækning til at løse mange udfordringer. Men i mange scenarier er ikke alle enheder udtrykkeligt nævnt i teksten. Nogle gange kunne de udledes af sammenhængen eller af andre vejledende ord. Overvej følgende sætning:"CMA kan let hydrolysere til fri eddikesyre." Selvom vand ikke nævnes eksplicit, kan man udlede, at H2O er en enhed involveret i processen. I dette arbejde præsenterer vi problemet med Latent Entities Extraction (LEE). Vi præsenterer flere metoder til at afgøre, om enheder diskuteres i en tekst, selvom de potentielt ikke udtrykkeligt er skrevet. Specielt designer vi en neural model, der håndterer udvinding af flere enheder i fællesskab. Vi viser, at vores model, sammen med multi-task learning tilgang og en ny opgavegrupperingsalgoritme, når høj ydeevne til at identificere latente enheder. Vores eksperimenter udføres på et stort biologisk datasæt fra det biokemiske felt. Datasættet indeholder tekstbeskrivelser af biologiske processer, og for hver proces er alle involverede enheder i processen mærket, herunder implicit nævnte. Vi mener, at LEE er en opgave, der vil forbedre mange NER og efterfølgende applikationer betydeligt og forbedre tekstforståelse og slutning.', 'bg': 'Разпознаването на наименовани субекти (НР) е важна задача в областта на НПП и се използва широко за решаване на много предизвикателства. В много сценарии обаче не всички субекти са изрично посочени в текста. Понякога те могат да бъдат изведени от контекста или от други индикативни думи. Помислете за следното изречение: "CMA може лесно да се хидролизира в свободна оцетна киселина." Въпреки че водата не се споменава изрично, може да се заключи, че H2O е образувание, участващо в процеса. В тази работа представяме проблема с извличането на латентни същества (ЛЕЕ). Представяме няколко метода за определяне дали субектите се обсъждат в текста, въпреки че потенциално те не са изрично написани. По-конкретно, ние проектираме невронен модел, който обработва извличането на множество единици съвместно. Показваме, че нашият модел, заедно с подхода за обучение с множество задачи и нов алгоритъм за групиране на задачи, достига висока производителност при идентифициране на латентни обекти. Нашите експерименти се провеждат върху голям биологичен набор от данни от биохимичното поле. Наборът от данни съдържа текстови описания на биологичните процеси, като за всеки процес всички участващи субекти в процеса са етикетирани, включително имплицитно споменати такива. Вярваме, че е задача, която значително ще подобри много НЕР и последващи приложения и ще подобри разбирането и заключението на текста.', 'id': 'Pengenalan Entitas Nama (NER) adalah tugas penting dalam bidang NLP, dan digunakan secara luas untuk memecahkan banyak tantangan. Namun, dalam banyak skenario, tidak semua entitas disebut secara eksplicit dalam teks. Kadang-kadang mereka bisa diperkirakan dari konteks atau dari kata-kata indikasif lainnya. Pertimbangkan kalimat berikut: "CMA dapat mudah hidrolis menjadi asam aset bebas." Meskipun air tidak disebutkan secara eksplisit, salah satu dapat menyimpulkan bahwa H2O adalah entitas yang terlibat dalam proses. Dalam pekerjaan ini, kami memperkenalkan masalah ekstraksi Latent Entities (LEE). We present several methods for determining whether entities are discussed in a text, even though, potentially, they are not explicitly written.  Specifically, we design a neural model that handles extraction of multiple entities jointly.  Kami menunjukkan bahwa model kami, bersama pendekatan belajar multi-tugas dan algoritma kelompok tugas baru, mencapai prestasi tinggi dalam mengidentifikasi entitas tersembunyi. Our experiments are conducted on a large biological dataset from the biochemical field.  The dataset contains text descriptions of biological processes, and for each process, all of the involved entities in the process are labeled, including implicitly mentioned ones.  We believe LEE is a task that will significantly improve many NER and subsequent applications and improve text understanding and inference.', 'ko': '명명 실체 식별은 자연 언어 처리 분야의 중요한 임무로 많은 도전을 해결하는 데 널리 사용된다.그러나 많은 상황에서 텍스트에 모든 실체가 명확하게 언급되지 않았다.때때로, 그것들은 상하문이나 다른 지시적인 단어에서 추단해 낼 수 있다."CMA는 쉽게 물에 분해되어 유리초산으로 변한다."물을 명시적으로 언급하지는 않았지만, H2O가 이 과정에 관여한 실체로 추정된다.이 작업에서 우리는 잠재적 실체 추출(LEE)에 대한 문제를 제기했다.우리는 텍스트에서 실체를 논의했는지 아닌지를 확인하기 위해 몇 가지 방법을 제시했다. 비록 그것이 명확하게 쓰여 있지 않을지라도.구체적으로 말하면 우리는 여러 실체의 추출을 연합하여 처리할 수 있는 신경 모형을 설계했다.우리는 우리의 모델과 다중 임무 학습 방법과 새로운 임무 그룹 알고리즘이 잠재적 실체를 식별하는 데 높은 성능을 달성했다는 것을 증명했다.우리의 실험은 생물화학 분야의 대형 생물 데이터 집합에서 진행되었다.데이터 집합은 생물 과정의 텍스트 설명을 포함하고 모든 과정에 관련된 모든 실체는 은밀하게 언급된 실체를 포함하여 표시된다.우리는 LEE의 임무가 많은 NER와 후속 응용을 현저하게 개선하고 텍스트의 이해와 추리력을 향상시킬 것이라고 믿는다.', 'de': 'Named-Entity Recognition (NER) ist eine wichtige Aufgabe im NLP-Bereich und wird häufig zur Lösung vieler Herausforderungen eingesetzt. In vielen Szenarien werden jedoch nicht alle Entitäten explizit im Text erwähnt. Manchmal konnten sie aus dem Kontext oder aus anderen indikativen Wörtern abgeleitet werden. Betrachten Sie den folgenden Satz: "CMA kann leicht zu freier Essigsäure hydrolysieren." Obwohl Wasser nicht explizit erwähnt wird, kann man daraus schließen, dass H2O eine Einheit ist, die am Prozess beteiligt ist. In dieser Arbeit stellen wir das Problem der Latent Entities Extraction (LEE) vor. Wir stellen verschiedene Methoden vor, um festzustellen, ob Entitäten in einem Text diskutiert werden, obwohl sie möglicherweise nicht explizit geschrieben sind. Konkret entwerfen wir ein neuronales Modell, das die Extraktion mehrerer Entitäten gemeinsam handhabt. Wir zeigen, dass unser Modell zusammen mit einem Multi-Task-Lernansatz und einem neuartigen Task-Gruppierungsalgorithmus eine hohe Leistung bei der Identifizierung latenter Entitäten erreicht. Unsere Experimente werden auf einem großen biologischen Datensatz aus dem biochemischen Bereich durchgeführt. Der Datensatz enthält Textbeschreibungen biologischer Prozesse, und für jeden Prozess werden alle beteiligten Einheiten markiert, einschließlich implizit erwähnter. Wir glauben, dass LEE eine Aufgabe ist, die viele NER und nachfolgende Anwendungen erheblich verbessern und das Textverständnis und die Schlussfolgerung verbessern wird.', 'nl': "Named-entity Recognition (NER) is een belangrijke taak op het gebied van NLP en wordt veel gebruikt om veel uitdagingen op te lossen. In veel scenario's worden echter niet alle entiteiten expliciet vermeld in de tekst. Soms kunnen ze worden afgeleid uit de context of uit andere indicatieve woorden. Denk aan de volgende zin: 'CMA kan gemakkelijk hydrolyseren tot vrij azijnzuur.' Hoewel water niet expliciet wordt genoemd, kan men concluderen dat H2O een entiteit is die betrokken is bij het proces. In dit werk presenteren we het probleem van Latent Entities Extraction (LEE). We presenteren verschillende methoden om te bepalen of entiteiten in een tekst worden besproken, ook al zijn ze mogelijk niet expliciet geschreven. Specifiek ontwerpen we een neuraal model dat de extractie van meerdere entiteiten gezamenlijk afhandelt. We laten zien dat ons model, samen met multitask learning aanpak en een nieuw taakgroeperingsalgoritme, hoge prestaties bereikt in het identificeren van latente entiteiten. Onze experimenten worden uitgevoerd op een grote biologische dataset uit het biochemische veld. De dataset bevat tekstbeschrijvingen van biologische processen, en voor elk proces worden alle betrokken entiteiten in het proces gelabeld, inclusief impliciet genoemde entiteiten. Wij geloven dat LEE een taak is die veel NER en latere toepassingen aanzienlijk zal verbeteren en het begrip en de conclusie van tekst zal verbeteren.", 'fa': 'شناسایی واحد نامیده (NER) یک کار مهم در زمینه NLP است و برای حل چالش\u200cهای بسیاری استفاده می\u200cشود. ولی در بسیاری از صحنه\u200cها، همه\u200cی صحنه\u200cها در متن مشخص نیستند. گاهی اوقات می\u200cتوانند از محیط یا از کلمات دیگر نشان\u200cدهنده آلوده شوند. این جمله را در نظر بگیرید: CMA می تواند به آسانی آسیتی آزاد هیدرولیز کند. اگرچه آب به طور واضح اشاره نکرده شود، یک نفر می تواند تشخیص دهد که H2O یک شرکت است که در این فرایند درگیر شده است. در این کار، مشکل اخراج اولین شرکت (LEE) را نشان می\u200cدهیم. ما چندین روش برای تعیین کردن که آیا شرکت ها در یک متن بحث می شوند، با وجود این که، احتمالاً آنها به طور واضح نوشته نمی شوند. دقیقاً ما یک مدل عصبی طراحی می کنیم که با همدیگر از استخراج چندین عناصر را کنترل می کند. ما نشان می دهیم که مدل ما، همراه با دستور یادگیری بسیاری از کارها و یک کار جدید گروه الگوریتم، به عملکرد بالا در شناسایی شرکتهای latent رسیده است. آزمایشات ما روی یک مجموعه داده های بیولوژیکی بزرگ از میدان بیولوژیکی انجام می شود. مجموعه داده\u200cها توضیح\u200cهای متن از فرایندهای بیولوژیکی وجود دارد، و برای هر فرایند، همه\u200cی مجموعه\u200cهای مشترک در فرایند، شامل ذکر\u200cهای مشترک، برچسب می\u200cشوند. ما فکر می\u200cکنیم LEE یک کار است که بسیاری از کاربردهای NER و بعدی را بهتر می\u200cکند و درک متن و آلودگی را بهتر می\u200cکند.', 'af': 'Genaamde entiteit herkenning (NER) is \'n belangrike taak in die NLP veld, en word heeltemal gebruik om baie uitdagings te los. Maar in baie scenarios word nie al die entiteite uitduidelik in die teks ingemenem nie. Soms kan hulle van die konteks of van ander indikasiewe woorde uitgevoer word. Ondersoek die volgende seting: "Cma kan maklik hydrolys in vry acetic asie." Alhoewel water nie uitsinklik genoem word nie, kan een infeer dat H2O \'n entiteit in die proses is. In hierdie werk stel ons die probleem van Latent Entities Extraction (LEE). Ons stel verskeie metodes voor om te bepaal of entiteite in \'n teks gespreek word, selfs, potensieel, hulle is nie uitskryf nie. Spesifieke, ons ontwerp \'n neurale model wat uittrek van veelvuldige entiteite saamgevoeg. Ons wys dat ons model, saam met multi-taak leer toegang en \'n nuwe taak groep algoritme, het hoë prestasie bereik in die identifiseer van latente entiteite. Ons eksperimente is gedoen op \'n groot biologiese datastel van die biochemiese veld. Die datastel bevat teks beskrywings van biologiese prosesse, en vir elke proses is al die insluiteerde entiteite in die proses etiketeerd, insluitend inplisite genoem. Ons glo LEE is \'n taak wat baie NER en volgende toepassings beter sal word en teks verstanding en inferensie verbeter.', 'sw': 'Tambulisho la entity (NER) ni kazi muhimu katika uwanja wa NLP , na inatumika sana kutatua changamoto nyingi. Hata hivyo, katika mitazamo mengi, siyo vyote viwili vyote vinavyotajwa wazi katika maandishi. Wakati mwingine wanaweza kuathirika na muktadha au kwa maneno mengine yanayoonyesha. Fikiria hukumu ifuatayo: “CMA anaweza kirahisi kupata hydrolyse kuwa mzunguko wa amani.” Ingawa maji haitajwa wazi, mtu anaweza kuathiri kuwa H2O ni entity involved in this process. Katika kazi hii, tunaonyesha tatizo la Ufukuzo wa Habari za hivi karibuni (LEE). Tunaweka mbinu kadhaa za kuamua ikiwa vyombo vinavyojadiliwa katika maandishi, ingawa, pengine, haziandikwi kwa uwazi. Kwa hakika, tunaunda muundo wa neura unaohusika kutengeneza vifaa vingi pamoja. Tunaonyesha kuwa mtindo wetu, pamoja na mbinu za kujifunza kwa kazi nyingi na utaratibu wa kazi za asili, unafikia ufanisi mkubwa katika kutambua vitu vya hivi karibuni. Majaribio yetu yanafanywa katika takwimu kubwa za biolojia kutoka kwenye uwanja wa kemikali wa biokemia. Taarifa hiyo ina maelezo ya maandishi ya michakato ya kibaiolojia, na kwa kila mchakato, vyombo vyote vinavyohusiana katika mchakato huwekwa maarufu, ikiwa ni pamoja na zile zinazotajwa. Tunaamini LEE ni jukumu ambalo linaweza kuboresha matumizi mengi ya NEW na baadaye na kuboresha uelewa wa maandishi na udhaifu.', 'tr': "Adly sany tanamak (NER) NLP sahyda möhüm zady, we köp kynçylyklary çözmek üçin ullanýar. Ýöne köp senaryýada, bütün guramlar tekstde aýdylanmaýar. Käwagt-de olar kontekstden ýa-da başga görkezilişi sözlerinden daşyrlanabilir. Aşağıdaki sözlemi düşün: 'CMA boş etik acid'a kolayca suwurlup biler.' Suw takykly aýdylanmaýan bolsa-da, ol prosesde H2O-yň bir zatdyr diýip bilýär. Bu işde, Soňky Entiteler Açmak (LEE) problemasyny çykýarys. Biz birnäçe yöntemi bir metin içinde çykyp bilmeýändigini kararylaşdyrýarys. Adatça, birnäçe birnäçe birnäçe birnäçe birnäçe birnäçe birnäçe taýýarlamak üçin nural nusgasyny tasarlýarys. Biz nusgamyzyň, köp-täbli öwrenmek approach we roman täblisasynyň algoritmy bilen, soňky zatlary tanamak üçin ýokary ukyplygyny görünýärdik. Biziň deneylerimiz biohemiýaly sahadan uly bir biologiýaly veri setinde çykylýar. Maglumat setirinde biyolojik prosellerniň hatlary bardyr we her proses üçin hemme edilen meňzeşli zatlary etitlenýär. LEE-iň köp NER we soňrak uygulamalaryny gowurarak we metin düşünmesini we çykyşyny gowurarak täsirleýän işidir diýip pikir edýäris.", 'sq': 'Njohja e emëruar e njësisë (NER) është një detyrë e rëndësishme në fushën NLP dhe përdoret gjerësisht për të zgjidhur shumë sfida. Megjithatë, në shumë skenarë, jo të gjitha njësitë përmenden shprehësisht në tekst. Ndonjëherë mund të përfundojnë nga konteksti apo nga fjalë të tjera treguese. Merrni parasysh fjalën e ardhshme: "CMA mund të hidrolizohet lehtë në acidin çetik të lirë." Although water is not mentioned explicitly, one can infer that H2O is an entity involved in the process.  Në këtë punë, ne paraqesim problemin e nxjerrjes së njësive të mëvonshme (LEE). Ne paraqesim disa metoda për të përcaktuar nëse njësitë diskutohen në një tekst, edhe pse, potencialisht, ato nuk janë shprehur eksplicitisht. Veçanërisht, ne dizajnojmë një model neuronal që trajton nxjerrjen e njësive të shumta së bashku. Ne tregojmë se modeli ynë, së bashku me metodën e mësimit me shumë detyra dhe një algoritëm të ri për grupimin e detyrave, arrin performancë të lartë në identifikimin e njësive të fshehta. Eksperimentet tona janë kryer në një grup të madh të të dhënash biologjike nga fusha biokimike. Të dhënat përmbajnë përshkrime teksti të proceseve biologjike dhe për çdo proces, të gjitha njësitë e përfshira në proces janë etiketuar, duke përfshirë ato të përmendura implicitisht. We believe LEE is a task that will significantly improve many NER and subsequent applications and improve text understanding and inference.', 'am': 'ስሜ-አካል ማውቀት (NER) በNLP መሬት ውስጥ አስቸጋሪ ስራ ነው፣ እናም በብዙ ችግሮች ለመፍታት በተስፋት ተጠቃሚ ነው፡፡ However, in many scenarios, not all of the entities are explicitly mentioned in the text.  አንዳንድ ጊዜ ከግንኙነቱ ወይም ከሌሎች ማሳየት ቃላት እንዲወስዱ ይችላል፡፡ "CMA ለነፃ የኤስቲክ acid ለቀላል hydrolyze ሊገልጥ ይችላል" የሚለውን ቃል ተመልከቱ፡፡ ምንም እንኳን ውሃ በግልጽ ሳይታወቅ፣ አ.2O በጉዳዩ ውስጥ የተጠቃሚ አካል መሆኑን የሚያስጨንቅ ይችላል፡፡ በዚህ ስራ ውስጥ የቀድሞው የኢንተርኔት መውጣት (LEE) ጉዳይ እናሳየዋለን፡፡ አካባቢዎች በጽሑፍ የተነጋገሩ መሆኑን እናውቃለን፡፡ በተለየ ጊዜ የናቡር ሞዴል እናሳውቃለን፡፡ ምሳሌያችን በብዙ ስራ ትምህርት እና የአሁኑን አድራሻ ጉዳይ አጎርጂም፣ የአሁኑን አካባቢዎች ማረጋገጥ ከፍተኛ ስርዓት እንዲደርስ እናሳያቸዋለን፡፡ ፈተናዎቻችን ከbiochemical እርሻ በታላቅ የbiological ዳታተር ውስጥ ነው፡፡ የዳታ setup ጽሑፍ የbiological ፕሮግራሞች ጽሑፎች እና ለሁሉም ክፍል፣ በጉዳዩ ውስጥ ያሉት አካባቢዎች ሁሉ፣ በተገኘው ነገር እና የተጠቃሚ ነው፡፡ እናምናለን LEE ብዙዎችን የNER እና ከዚያም በኋላ ያሉትን ፕሮግራሞች እና የጽሑፍ ማስተዋል እና ግጭት ማሻሻል የሚል ስራ ነው፡፡', 'bs': 'Prepoznavanje imenovanih entitata (NER) je važan zadatak na polju NLP-a, koji se široko koristi za rješavanje mnogih izazova. Međutim, u mnogim scenarijama, ne svi entiteti se pojasno spominju u tekstu. Ponekad bi mogli biti inficirani iz konteksta ili iz drugih indikativnih riječi. Smatrajte sljedeću rečenicu: "CMA može lako hidrolizirati u besplatnu acetsku kiselinu." Iako se voda ne spominje jasno, može uvjeriti da je H2O entitet uključen u taj proces. U ovom poslu predstavljamo problem izvlačenja poslednjih subjekta (LEE). Predstavljamo nekoliko metoda za određivanje da li se entiteti raspravljaju u tekstu, iako, potencijalno, nisu jasno napisani. Posebno, mi dizajniramo neuralni model koji zajedno vodi izvlačenje višestrukih entiteta. Pokazujemo da naš model, zajedno s pristupom multi task učenja i novim algoritmom skupine zadataka, dostigne visoke funkcije u identifikaciji latentnih entitata. Naši eksperimenti su provedeni na velikom biološkom setu podataka iz biokemijskog polja. Podaci sadrže tekst opisa bioloških procesa, a za svaki proces, svi uključeni subjekti u procesu su označeni, uključujući implicitno spominjane. Vjerujemo da je LEE zadatak koji će značajno poboljšati mnoge NER i sljedeće aplikacije i poboljšati razumijevanje teksta i infekciju.', 'az': 'İsmim-entity Recognition (NER) NLP sahəsində möhkəm bir işdir və çox çətinlikləri çəkmək üçün genişliyinə istifadə edilir. Ancaq çoxlu scenariolərdə, bütün məlumatlar mətndə açıq-aydın deyil. Bazen onlar məlumatdan və ya başqa ifadə edən sözlərdən dəyişə bilərlər. Aşağıdakı cümləyi düşünün: CMA sərbəst etik asitdə hidrolizi asanlaşdıra bilər. Su açıq-aydın deyil olsa da, bir insan H2O proses içində bir məlumat olduğunu anlayabilir. Bu işdə, son Entities Extraction (LEE) problemini göstəririk. Biz bir neçə yol göstəririk ki, mətndə mübahisə ediləcəyini təyin etmək üçün bir neçə yol göstəririk. Halbuki mümkün olaraq, onlar a çıq-aydın yazılmırlar. Biz müəyyən olaraq çoxlu maddələrin çıxarılmasını müdafiə edən nürol modeli tasarlayırıq. Biz modellərimizi, çoxlu işin öyrənməsi və yeni işin gruplaması algoritmi ilə birlikdə çoxlu işin çoxluğunu təsdiq edirik. Bizim eksperimentlərimiz biokimyasal sahədən böyük biyolojik verilər qurulmuşdur. Veri qurğuları biyolojik proseslərin mətn tanımlamaları barəsindədir, və hər proses üçün, proseslərdə olan bütün mətnlər etiketlənir. Biz inanırıq ki, LEE çoxlu NER və sonrakı uygulamalarını daha yaxşılaşdırar və məktub anlayışını və a şağılığı daha yaxşılaşdırar.', 'cs': 'Rozpoznávání jmenovaných entit (NER) je důležitým úkolem v oblasti NLP a je široce používáno k řešení mnoha problémů. V mnoha scénářích však ne všechny subjekty jsou v textu výslovně zmíněny. Někdy mohou být odvozeny z kontextu nebo z jiných orientačních slov. Zvažte následující větu: "CMA se může snadno hydrolyzovat na volnou kyselinu octovou." I když voda není výslovně zmíněna, lze vyvodit, že H2O je subjektem zapojeným do procesu. V této práci se zabýváme problematikou extrakce latentních entit (LEE). Představujeme několik metod určení, zda jsou entity v textu diskutovány, i když potenciálně nejsou explicitně napsány. Konkrétně navrhujeme neuronový model, který zpracovává extrakci více entit společně. Ukazujeme, že náš model spolu s víceúlohovým učením a novým algoritmem seskupování úloh dosahuje vysokého výkonu při identifikaci latentních entit. Naše experimenty jsou prováděny na velkém biologickém datovém souboru z biochemického pole. Datová sada obsahuje textové popisy biologických procesů a pro každý proces jsou označeny všechny zapojené entity procesu, včetně implicitně zmíněných. Věříme, že LEE je úkol, který výrazně zlepší mnoho NER a následných aplikací a zlepší porozumění textu a odvození.', 'bn': 'নাম-বস্তু স্বীকার (NER) এনএলপি ক্ষেত্রে একটি গুরুত্বপূর্ণ কাজ এবং অনেক চ্যালেঞ্জ সমাধানের জন্য ব্যবহৃত। তবে অনেক দৃশ্যের মধ্যে সকল বস্তুই লেখায় স্পষ্টভাবে উল্লেখ করা হয়নি। মাঝে মাঝে মাঝে তাদের প্রচণ্ড থেকে আক্রান্ত হতে পারে অথবা অন্যান্য নির্দেশিত শব্দ থেকে। নীচের বাক্য বিবেচনা করুন: “সিএমএ খুব সহজে হাইড্রোলাইজ করতে পারে মুক্ত সিস্টিক এসিডে। যদিও পানি স্পষ্টভাবে উল্লেখ করা হয়নি, তবে কেউ আক্রান্ত হতে পারে যে এইচ২ও প্রক্রিয়ায় জড়িত একটি বস্তু। এই কাজে আমরা ল্যাটেন্ট এন্টিটি বিদেশের সমস্যা উপস্থাপন করি। আমরা বেশ কয়েকটি পদ্ধতি উপস্থাপন করছি যাতে বিষয়গুলো একটি টেক্সটে আলোচনা করা হচ্ছে কিনা, যদিও সম্ভবত তারা স্পষ্ট লিখিত নয়। বিশেষ করে, আমরা একটি নিউরেল মডেল ডিজাইন করি যা একাউন্টে বিভিন্ন বস্তুর বিনিময়ে নিয়ে যায়। আমরা দেখাচ্ছি যে আমাদের মডেল, বহুক্ষেত্রের শিক্ষা পদক্ষেপ এবং একটি নবনের কাজ গ্রুপিং অ্যালগরিদমের সাথে সাম্প্রতিক বস্তুক আমাদের পরীক্ষা বায়োকেমিকাল ক্ষেত্র থেকে বিশাল বায়োলজিক্যাল ডাটাসেটে অনুষ্ঠিত হয়েছে। ডাটাসেটের মধ্যে বায়োলজিক্যাল প্রক্রিয়ার লেখার বর্ণনা রয়েছে এবং প্রত্যেক প্রক্রিয়ার জন্য, প্রক্রিয়ার সকল অংশগ্রহণকারী বস্ত আমরা বিশ্বাস করি লিই একটি কাজ যা অনেক নেটর আর পরের অ্যাপ্লিকেশন উন্নত করবে এবং লেখা বুঝতে পারবে এবং সংক্রান্ত বিষয়টি উন্নত করবে।', 'ca': 'El reconeixement d\'entitats anomenades (NER) és una tasca important en el camp del NLP, i s\'utilitza ampliament per resoldre molts reptes. No obstant això, en molts escenaris, no totes les entitats es mencionen explícitament en el text. A vegades es poden deduir del context o d\'altres paraules indicatives. Considereu la següent frase: "CMA pot hidrolitzar fàcilment en àcid acètic lliure". Encara que l\'aigua no es menciona explícitament, es pot deduir que H2O és una entitat involucrada en el procés. En aquest treball, presentem el problema de l\'Extracció de Latent Entities (LEE). We present several methods for determining whether entities are discussed in a text, even though, potentially, they are not explicitly written.  Concretament, dissenyem un model neuronal que gestiona l\'extracció de múltiples entitats conjuntament. Mostrem que el nostre model, juntament amb l\'enfocament d\'aprenentatge multitasca i un nou algoritme d\'agrupament de tasques, aconsegueix un alt rendiment en la identificació d\'entitats latents. Els nostres experiments es fan en un gran conjunt de dades biològiques del camp bioquímic. The dataset contains text descriptions of biological processes, and for each process, all of the involved entities in the process are labeled, including implicitly mentioned ones.  Creiem que LEE és una tasca que millorarà significativament moltes aplicacions NER i posteriors i millorarà la comprensió i la inferència dels textos.', 'hy': "Նվանված-անհատականության ճանաչման (ՆԵՌ) նշանակալի խնդիր է ՆԼՊ-ի ոլորտում և լայնորեն օգտագործվում է բազմաթիվ մարտահրավերների լուծման համար: Այնուամենայնիվ, շատ սցենարներում ոչ բոլոր կազմակերպությունները բացահայտորեն նշում են տեքստում: Երբեմն դրանք կարելի է ենթադրել կոնտեքստից կամ այլ նշանակալի բառերից: Consider the following sentence: 'CMA can easily hydrolyze into free acetic acid.'  Although water is not mentioned explicitly, one can infer that H2O is an entity involved in the process.  Այս աշխատանքի ընթացքում մենք ներկայացնում ենք Վերջին Համակարգման Համակարգման (LEE) խնդիրը: Մենք ներկայացնում ենք մի քանի մեթոդներ, որպեսզի որոշենք, թե արդյոք միավորները քննարկվում են տեքստում, չնայած, որ պոտենցիալ, դրանք բացահայտորեն չեն գրված: Specifically, we design a neural model that handles extraction of multiple entities jointly.  Մենք ցույց ենք տալիս, որ մեր մոդելը, միասին բազմաթիվ խնդիրների սովորելու մոտեցումների և նոր խնդիրների խմբավորումների հետ միասին, հասնում է բարձր արդյունքներին՝ բացահայտելով թաքնված էակներ: Մեր փորձարկումները կատարվում են կենսաքիմիական դաշտից բազմաթիվ կենսաբանական տվյալների վրա: Տեղեկատվական համակարգը պարունակում է կենսաբանական գործընթացների տեքստի նկարագրություններ, և յուրաքանչյուր գործընթացի համար բոլոր գործընթացի մասնակիցները պիտակում են, ներառյալ անխուսափելի նշված: We believe LEE is a task that will significantly improve many NER and subsequent applications and improve text understanding and inference.", 'et': 'Nimetatud üksuste tunnustamine (NER) on uue õppekava valdkonnas oluline ülesanne ja seda kasutatakse laialdaselt paljude probleemide lahendamiseks. Paljude stsenaariumide puhul ei ole tekstis selgesõnaliselt nimetatud kõiki üksusi. Mõnikord võib neid järeldada kontekstist või muudest soovituslikest sõnadest. Võtke arvesse järgmist lauset: "CMA võib hüdrolüüsida vabaks äädikhappeks." Kuigi vett ei nimetata selgesõnaliselt, võib järeldada, et H2O on protsessi kaasatud olemus. Käesolevas töös tutvustame Latent Entities Extraction (LEE) probleemi. Esitame mitmeid meetodeid selle kindlaksmääramiseks, kas üksusi käsitletakse tekstis, kuigi potentsiaalselt ei ole need sõnaselgelt kirjutatud. Täpsemalt disainime närvimudeli, mis käsitleb mitme olemi ekstraheerimist ühiselt. Näitame, et meie mudel koos mitme ülesandega õppimise lähenemisviisiga ja uudse ülesannete rühmitamise algoritmiga saavutab varjatud olemite tuvastamisel suure jõudluse. Meie katsed viiakse läbi suure bioloogilise andmekogumiga biokeemilisest valdkonnast. Andmekogum sisaldab bioloogiliste protsesside tekstikirjeldusi ning iga protsessi puhul märgistatakse kõik protsessis osalevad üksused, sealhulgas kaudselt nimetatud. Usume, et LEE on ülesanne, mis parandab märkimisväärselt paljusid NER-i ja järgnevaid rakendusi ning parandab teksti mõistmist ja järeldust.', 'fi': 'Nimettyjen yksiköiden tunnistaminen (NER) on tärkeä tehtävä NLP-alalla, ja sitä käytetään laajalti monien haasteiden ratkaisemiseen. Monissa tilanteissa kaikkia kokonaisuuksia ei kuitenkaan mainita nimenomaisesti tekstissä. Joskus ne voidaan päätellä kontekstista tai muista ohjeellisista sanoista. Tarkastellaan seuraavaa lausetta: "CMA voi helposti hydrolysoida vapaaksi etikkahappoksi." Vaikka vettä ei mainita nimenomaisesti, voidaan päätellä, että H2O on prosessiin osallistuva kokonaisuus. Tässä työssä esitellään Latent Entities Extraction (LEE) -ongelmaa. Esitämme useita menetelmiä sen määrittämiseksi, käsitelläänkö kokonaisuuksia tekstissä, vaikka niitä ei mahdollisesti ole nimenomaisesti kirjoitettu. Suunnittelemme neuromallin, joka käsittelee useiden entiteettien uuttamista yhdessä. Osoitamme, että mallimme yhdessä monitehtäväoppimisen lähestymistavan ja uuden tehtäväryhmittelyalgoritmin kanssa saavuttaa korkean suorituskyvyn piilevien entiteettien tunnistamisessa. Kokeet tehdään suurella biokemiallisen kentän biologisella aineistolla. Aineisto sisältää tekstikuvaukset biologisista prosesseista, ja jokaisesta prosessista kaikki prosessiin osallistuvat tahot on merkitty, myös implisiittisesti mainitut. Uskomme, että LEE on tehtävä, joka parantaa merkittävästi monia NER-sovelluksia ja myöhempiä sovelluksia sekä parantaa tekstin ymmärtämistä ja päättelyä.', 'jv': 'Named-Enty Nanging, akeh sing sampeyan luwih seneng pisan, ora sampeyan panjenengan kelas nang teks. Mungkin-wong, wong yo iso nglanggar sapa kontèks mengkin yo koyo ngono kelas sing mengkin. Tarjamahan seneng kabèh mengko: \'SMA iso dianggo gampang kanggo acetik sing lunak. Nanging ketoke aman ora dadi nglarang langgar, sampeyan iso ngebah nyang H2O kuwi jenis sing kelas nang perusahaan. Nang barêng-barêng iki, kéné iso nggawe kesemplan ning rabi tanggal Kebebasan Entité (LeE). Awak dhéwé éntuk sistem sing dipun string" in "context_BAR_stringLink Awake dhewe nambah model kita, sampeyan ngono diangkat multi-task Learn sampeyan ngono kelebuturan task group-ingkang Algorithm, jewelasakno sing wis bantuan kanggo ngilangno sistem sing berarti Awak dhéwé éntuk éntuk ning larang dataset biyomonggé sakjane kanggo sakjane biyomonggé. Sampeyan dataset nduwe akeh kelangan kelangan sampeyan biyogra, lan sabên proces, hak sampeyan ingkang sampeyan ingkang sampeyan nèng kelangan mruput. Awak dhéwé pisan nglanggar leE kuwi buat sira nggambar luwih saben nggambar apa neré karo aplikasi sing beraksi lan basa luwih nggambar Text lan ijol-ijolan.', 'ha': 'Sunan Sanna-abun (NER) yana da wani aikin muhimma cikin filin NLP, kuma yana amfani da yin solar masu yawa. Amma, a cikin masu yawa, ba duk abubuwa ba su bayyana ba cikin matsayin. Akwai da wani abu, za\'a iya shafe su daga mazaɓa ko daga wasu kalmõmi masu yiwuwa. Ka yi bincike da maganar da ke jẽre: "CMA mai iya sauƙi kan diolyze zuwa acid baka cetacce." Kuma kõ da ba a ambaci ruwa da bayyane ba, wani yana iya ƙaranci cẽwa H2O wata gaskiyar da yake cikin wannan aikin. Daga wannan aikin, Munã halatar da matsalar da Cikakken Bayani (LEU). Kuma Munã iyar da wasu hanyõyi dõmin ka ƙayyade ko an yi musu magana a cikin wani littãfi, kuma kõ da yaushe, ba za su iya rubũta su da bayyani ba. A ƙayyade, Munã ƙayyade wani motsi na neural wanda ke yi amfani da cire-abun wasu masu haɗi. Tuna nũna cewa misalinmu, sami da mazaɓa wa masu sanar da aiki mãsu yawa da kuma wani algoritm na yanzu, yana isa mafiya sauri cikin gane abubuwa masu ƙaranci. Ana tafiyar jarrabõyinmu a kan wani database mai girma na\'asa daga filin biyama. The dataset contains text descriptions of biological processes, and for each process, all of the involved entities in the process are labeled, including implicitly mentioned ones.  Tuni amince LEET yana wani aikin wanda zai kyautata masu yawa na NER da shiryoyin ayuka masu ƙaranci kuma ya improve fahimtar matsayi da kasar kwamfyuta.', 'he': 'Named-entity Recognition (NER) is an important task in the NLP field , and is widely used to solve many challenges.  בכל אופן, במקרים רבים, לא כל היחידות נזכרות באופן ברור בטקסט. לפעמים הם יכולים להוציא מהקשר או ממילים מדעיות אחרות. תשקול את המשפט הבא: "CMA יכול בקלות להידרוליז לחמצה חמצנית חופשית". למרות שמים לא מוזכרים באופן ברור, אפשר למצוא שהH2O הוא יחידה מעורבת בתהליך. In this work, we present the problem of Latent Entities Extraction (LEE).  אנחנו מציגים כמה שיטות להחליט אם יחידות נדון בטקסט, למרות, פוטנציאלית, שהן לא נכתבות באופן ברור. במיוחד, אנחנו מעצבים מודל עצבי שמטפל בחטיפה של יחידות רבות ביחד. אנחנו מראים שהמודל שלנו, יחד עם גישה ללמוד במשימות רבות ואלגוריתם קבוצת משימות חדשה, מגיע להופעה גבוהה בזיהוי יחידות מוסתרות. הניסויים שלנו נעשים על קבוצת נתונים ביולוגיים גדולה מהשדה הביוקימי. קבוצת הנתונים מכילה תיאורים טקסטים של תהליכים ביולוגיים, וכל תהליך, כל היחידות המעורבות בתהליך מוטבעות, כולל היחידות שמזכירות באופן לא מוכר. אנו מאמינים שלאי היא משימה שתשיפר באופן משמעותי הרבה שימושים NER ואחרי מכן ותשיפר את הבנה הטקסטית והתוצאה.', 'bo': 'མིང་བཏགས་པའི་entity Recognition (NER)ནི་NLP Field ནང་གི་བྱ་སྤྱོད་གལ་ཆེན་པོ་ཞིག་རེད། གདོང་ལེན་མང་པོ་ཞིག་ལ་སྤྱོད་ཐུབ་པ ཡིན་ནའང་། དོན་ཚན་མང་པོ་ནང་དུ་དབུལ་ཆ་ཡོངས་ཀྱི་ཡིག་གི་ནང་དུ་གཏོང་ཚང་མ་རེད། མཚམས་རེར་དུ་ཁོང་ཚོས་ཡུལ་context་ལས་ནི་གསལ་བཤད་པ་གཞན་ཞིག་ནས་སྙིང་འཛུགས་བྱེད་ཐུབ། གཤམ་གྱི་ཚིག སྐུ་འདི་གསལ་བཤད་བྱས་མིན་ནའང་། ཆ་གཅིག་གིས་ H2O ནི་ལས་སྦྱོར་ནང་གི་ཨ་ཆ་ཞིག་རྟོགས་ཐུབ་པ་ཡིན། འོན་ཀྱང་། ང་ཚོས་དུས་ཡོད་དོན་ལྗོངས་ཀྱི་ཨིན་ཡུལ་ཕྱིར་འདོན་པའི་དཀའ་ངལ་བཤད་ཀྱི་རྐྱེན་བ་ཞ ང་ཚོས་དབྱིབས་ཡུལ་གྱི་ཡིག་གེ་ནང་དུ་གཏོང་བ་མིན་འདུག Specifically, we design a neural model that handles extraction of multiple entities jointly. ང་ཚོས་རང་གི་མ་དབུགས་སྟོན་བྱས་ན། མི་མང་ལས་འགུལ་གྱི་སྐོར་དང་མཐུན་སྣེ་མང་པོ་ཞིག་གི་མཐུན་སྣེ་ཚུལ་གསུམ་སྟོན་པ་ཡིན་པས། ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་མཐུད་སྐྱེས་པའི་གྲངས་སྒྲིག་ཆེན་པོ་ཞིག་ལས་རྐྱེན་བྱས་ཡོད། The dataset contains text descriptions of biological processes, and for each process, all of the involved entities in the process are labeled, including implicitly mentioned ones. ང་ཚོས་LEE་ནི་ལས་འགན་ཞིག་ཡིད་ཆ་ཉེན་དང་རྗེས་སུ་ཉེན་རིས་མང་པོ་ཞིག་ཏུ་ཡར་རྒྱས་གཏོང་བྱེད་རྒྱུ་དང་། ཡིག', 'sk': 'Prepoznavanje imenovanih subjektov (NER) je pomembna naloga na področju NLP in se pogosto uporablja za reševanje številnih izzivov. Vendar v mnogih scenarijih vsi subjekti niso izrecno omenjeni v besedilu. Včasih jih je mogoče sklepati iz konteksta ali iz drugih okvirnih besed. Upoštevajte naslednji stavek: "CMA se lahko zlahka hidrolizira v prosto ocetno kislino." Čeprav voda ni izrecno omenjena, lahko sklepamo, da je H2O subjekt, ki je vključen v proces. V tem delu predstavljamo problem ekstrakcije latentnih entitet (LEE). Predstavljamo več metod za ugotavljanje, ali so entitete obravnavane v besedilu, čeprav potencialno niso izrecno napisane. Natančneje, oblikujemo nevronski model, ki skupaj obravnava ekstrakcijo več entitet. Pokazali smo, da naš model skupaj s pristopom večopravilnega učenja in novim algoritmom za združevanje nalog doseže visoko zmogljivost pri identifikaciji latentnih entitet. Naši poskusi potekajo na velikem biološkem naboru podatkov iz biokemičnega polja. Zbirka podatkov vsebuje besedilne opise bioloških procesov, za vsak proces pa so označeni vsi vključeni subjekti v proces, vključno z implicitno omenjenimi. Verjamemo, da je LEE naloga, ki bo znatno izboljšala številne NER in nadaljnje aplikacije ter izboljšala razumevanje besedila in sklepanje besedila.'}
{'en': 'Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition', 'ar': 'دمج تسلسل متعدد الوسائط عبر الانتباه المتكرر للتعرف على المشاعر', 'fr': "Fusion de séquences multimodales via l'attention récursive pour la reconnaissance des émotions", 'pt': 'Fusão de sequência multimodal via atenção recursiva para reconhecimento de emoções', 'es': 'Fusión de secuencias multimodales mediante atención recursiva para el reconocimiento de emociones', 'ja': '感情認識のための再帰的注意を介したマルチモーダルシーケンス融合', 'zh': '盖递归情识多模态序融也', 'hi': 'बहु मॉडल अनुक्रम संलयन भावना पहचान के लिए पुनरावर्ती ध्यान के माध्यम से', 'ru': 'Мультимодальное слияние последовательностей через рекурсивное внимание к распознаванию эмоций', 'ga': "Comhleá Seicheamh Ilmhódúil trí Aird Athfhillteach d'Aithint Mothúchán", 'hu': 'Multi-Modális Szekvencia Fúzió az érzelmek felismerésére irányuló visszatérő figyelem segítségével', 'kk': 'Көптеген модельді түсініктемелерді қайталау үшін көптеген қадамдастыру', 'ka': 'მრავალური მოდიალური წერტილის ფუქცია რეკურსიური დაახლოებით ემოციონის განახლოებისთვის', 'el': 'Πολυμορφική συγχώνευση διαδοχής μέσω της αναδρομικής προσοχής για την αναγνώριση συναισθημάτων', 'it': 'Fusione di Sequenza Multi-Modale tramite Attenzione Recursiva per il Riconoscimento Emozionale', 'mk': 'Мултимодална секвенциска фузија преку рекурсивно внимание за препознавање на емоции', 'ml': 'അഭിപ്രായം തിരിച്ചറിയുന്നതിനുള്ള ശ്രദ്ധ കൊണ്ട് ഒരുപാട് മോഡല്\u200d സെക്കന്\u200dസ് ഫ്യൂഷന്\u200d', 'lt': 'Daugumos modulių sekos jungimas atkuriant dėmesį emocijų pripažinimui', 'ms': 'Fusi Sekuensi Berberbilang-Modal melalui Perhatian Rekursif untuk Pengenalan Emosi', 'mt': 'Fużjoni ta’ Sekwenza Multimodali permezz ta’ Attenzjoni Rikorsiva għar-Rikonoxximent tal-Emozzjoni', 'mn': 'Олон загварын дарааллаар дахин сэтгэл хөдлөл ойлгохын тулд', 'no': 'Multimodal sekvensfusjon via rekursivt merking for følelseskjenning', 'sr': 'Multimodalna sekvenčna fuzija putem rekursivne pažnje za prepoznavanje emocija', 'si': 'ගොඩක් මෝඩාල් ක්\u200dරමාවිකරණය සඳහා ප්\u200dරතික්\u200dරියාත්මක අවධානය සඳහා', 'so': 'Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition', 'sv': 'Multi-Modal Sequence Fusion via rekursiv uppmärksamhet för känsloigenkänning', 'pl': 'Multimodalna fuzja sekwencji poprzez rekursywną uwagę na rozpoznawanie emocji', 'ur': 'Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition', 'ro': 'Fuziunea secvențelor multimodale prin atenția recursivă pentru recunoașterea emoțiilor', 'ta': 'உணர்வு அறியப்படுத்தலுக்கு மூலம் திரும்பும் கவனத்தின் மூலம் பல- மாலி தொடர்ச்சி முடிவு', 'uz': 'Name', 'vi': 'Truyền nhanh nhanh chóng kết nối hệ thống cảm xúc', 'bg': 'Многомодална последователност чрез рекурсивно внимание за разпознаване на емоциите', 'nl': 'Multimodale opeenvolgende fusie via recursieve aandacht voor emotionele herkenning', 'hr': 'Multimodalna sekvenčna fuzija putem rekursivne pažnje za prepoznavanje emocija', 'da': 'Multi-Modal Sequence Fusion via rekursiv opmærksomhed på følelsesgenkendelse', 'de': 'Multi-Modale Sequenz Fusion durch rekursive Aufmerksamkeit für Emotionserkennung', 'fa': 'فشار تعداد چندین مدل از طریق توجه دوباره برای شناختن احساسات', 'sw': 'Ufumbuzi wa mfululizo wa mitandao kadhaa kupitia Attention for Recognition of Emotion', 'id': 'Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition', 'ko': '귀속 주의를 바탕으로 하는 다중모드 서열 융합은 감정 식별에 사용된다', 'tr': 'Emotik tanımlamak üçin Çoklu-Modal Diňe Fusiýa (rekursive Attention for Emotion Recognition)', 'sq': 'Fuzioni i Sekuencës Multi-Modale nëpërmjet vëmendjes rekursive për njohjen e emocioneve', 'af': 'Multi-Modaal Sequence Fusion deur rekursief aandag vir Emotie Herkenning', 'am': 'ምርጫዎች', 'bn': 'ইমোটেশন স্বীকারের জন্য পুনরায় মনোযোগের মাধ্যমে বহুমোডেল সেকেন্স ফুশন', 'bs': 'Multimodalna sekvenčna fuzija putem rekursivne pažnje za prepoznavanje emocija', 'hy': 'Բազմամոդել հաջորդականության ֆուզիան զգացմունքների ճանաչման ռեսուրսիվ ուշադրության միջոցով', 'az': 'Çoxlu Modal Sequence Fusion Emotion Recognition üçün Rekursive Attention', 'ca': "Fusió multimòdica de seqüències a través de l'atenció recursiva a la reconeixement emocional", 'et': 'Mitmemodaalse järjestuse fusioon rekursiivse tähelepanu kaudu emotsioonide äratundmisele', 'fi': 'Monimodaalinen sekvenssi fuusio rekursiivisen huomion kautta tunteiden tunnistamiseen', 'cs': 'Multimodální fúze sekvencí prostřednictvím rekurzivní pozornosti pro rozpoznávání emocí', 'jv': 'Multi-modal Seyense Fsiyon ngegambar recurrsve Attention for EMosion Learning', 'sk': 'Združitev večmodalnih sekvenc prek rekursivne pozornosti za prepoznavanje čustev', 'he': 'מיזון רצף רב-מודיאלי באמצעות תשומת לב מחדשת לזהות רגשות', 'ha': 'Phonon:: MMF:: EffectFactory', 'bo': 'Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition'}
{'en': 'Natural human communication is nuanced and inherently multi-modal. Humans possess specialised sensoria for processing vocal, visual, and linguistic, and para-linguistic information, but form an intricately fused percept of the multi-modal data stream to provide a holistic representation. Analysis of emotional content in ', 'ar': 'التواصل البشري الطبيعي دقيق ومتعدد الوسائط بطبيعته. يمتلك البشر حسًا متخصصًا لمعالجة المعلومات الصوتية والمرئية واللغوية وشبه اللغوية ، لكنهم يشكلون مفهومًا مدمجًا بشكل معقد لتيار البيانات متعدد الوسائط لتوفير تمثيل شامل. يعد تحليل المحتوى العاطفي في التواصل وجهاً لوجه مهمة معرفية يتواءم معها البشر بشكل خاص ، نظرًا لأهميتها الاجتماعية ، ويشكل تحديًا صعبًا لمحاكاة الآلة بسبب الدقة والتنوع التعبري للإشارات عبر الوسائط. مستوحى من النجاح التجريبي لما يسمى بشبكات الذاكرة الطرفية الأخيرة والأعمال ذات الصلة ، نقترح نهجًا يعتمد على الانتباه المتعدد المتكرر مع ذاكرة خارجية مشتركة محدثة عبر تكرارات متعددة من التحليل. نقوم بتقييم نموذجنا عبر العديد من مجموعات البيانات الكبيرة متعددة الوسائط ونبين أن الذاكرة السياقية العالمية مع تحديث الذاكرة المسورة يمكن أن تحقق بشكل فعال التعرف على المشاعر.', 'fr': "La communication humaine naturelle est nuancée et intrinsèquement multimodale. Les humains possèdent des capteurs spécialisés pour traiter les informations vocales, visuelles, linguistiques et paralinguistiques, mais ils forment une perception fusionnée complexe du flux de données multimodal pour fournir une représentation holistique. L'analyse du contenu émotionnel dans la communication en face à face est une tâche cognitive à laquelle les humains sont particulièrement sensibles, compte tenu de son importance sociologique, et pose un défi difficile pour l'émulation automatique en raison de la subtilité et de la variabilité expressive des signaux intermodaux. Inspirés par le succès empirique des récents réseaux de mémoire de bout en bout et des travaux connexes, nous proposons une approche basée sur la multi-attention récursive avec une mémoire externe partagée mise à jour au cours de plusieurs itérations d'analyse déclenchées. Nous évaluons notre modèle à travers plusieurs grands ensembles de données multimodaux et montrons que la mémoire contextualisée globale avec mise à jour de la mémoire déclenchée peut efficacement permettre la reconnaissance des émotions.", 'es': 'La comunicación humana natural es matizada e inherentemente multimodal. Los seres humanos poseen sensoriales especializados para procesar información vocal, visual, lingüística y para-lingüística, pero forman una percepción intrincadamente fusionada del flujo de datos multimodal para proporcionar una representación holística. El análisis del contenido emocional en la comunicación cara a cara es una tarea cognitiva con la que los humanos están particularmente en sintonía, dada su importancia sociológica, y plantea un desafío difícil para la emulación de máquinas debido a la sutileza y variabilidad expresiva de las señales intermodales. Inspirados en el éxito empírico de las llamadas redes de memoria de extremo a extremo recientes y trabajos relacionados, proponemos un enfoque basado en la multiatención recursiva con una memoria externa compartida actualizada a través de múltiples iteraciones de análisis cerradas. Evaluamos nuestro modelo en varios conjuntos de datos multimodales de gran tamaño y demostramos que la memoria contextualizada global con actualización de memoria cerrada puede lograr el reconocimiento de emociones de manera efectiva.', 'pt': 'A comunicação humana natural é matizada e inerentemente multimodal. Os seres humanos possuem sensores especializados para processar informações vocais, visuais, linguísticas e paralinguísticas, mas formam uma percepção intrincadamente fundida do fluxo de dados multimodal para fornecer uma representação holística. A análise do conteúdo emocional na comunicação face a face é uma tarefa cognitiva à qual os humanos estão particularmente sintonizados, dada a sua importância sociológica, e representa um difícil desafio para a emulação da máquina devido à sutileza e variabilidade expressiva das pistas multimodais. Inspirado pelo sucesso empírico das recentes redes de memória de ponta a ponta e trabalhos relacionados, propomos uma abordagem baseada em multi-atenção recursiva com uma memória externa compartilhada atualizada em várias iterações de análise fechadas. Avaliamos nosso modelo em vários grandes conjuntos de dados multimodais e mostramos que a memória contextualizada global com atualização de memória fechada pode efetivamente alcançar o reconhecimento de emoções.', 'ja': '自然な人間のコミュニケーションは微妙で、本質的にマルチモーダルです。人間は、声、視覚、言語、および準言語情報を処理するための専門的な感覚を持っているが、複雑に融合したマルチモーダルデータストリームの知覚を形成して、全体的な表現を提供する。対面コミュニケーションにおける感情的内容の分析は、その社会学的重要性を考慮して、人間が特に調節する認知的課題であり、クロスモーダルキューの微妙さと表現的変動性により、機械エミュレーションにとって困難な課題となっている。最近のいわゆるエンドツーエンドメモリネットワークと関連する研究の実証的成功に触発されて、複数のゲート化された分析の反復で更新された共有外部メモリを使用した再帰的マルチアテンションに基づくアプローチを提案します。私たちは、いくつかの大規模なマルチモーダルデータセットにわたって私たちのモデルを評価し、ゲート化されたメモリ更新を備えたグローバルなコンテキスト化されたメモリが感情認識を効果的に達成できることを示します。', 'zh': '自然之人,交流微妙,质多模样。 夫人之有治声也,视也,言语、言语、信息之官也,而为多模态数据流之感知,以资一体。 鉴其社会学要,对流情析,人之所宜,而跨模态线之微妙性,可变性于机器仿真。 受近所谓端到端记网络与相关成功,立一基于递归多注意之法,数门控迭代析更新共享外存储器。 数大模态集评,门控记新全球情。', 'ru': 'Естественное общение человека является нюансированным и по своей сути мультимодальным. Люди обладают специализированными сенсорами для обработки голосовой, визуальной, лингвистической и паралингвистической информации, но формируют сложное объединенное восприятие мультимодального потока данных, чтобы обеспечить целостное представление. Анализ эмоционального контента в очном общении является когнитивной задачей, к которой люди особенно настроены, учитывая ее социологическую важность, и ставит сложную задачу для машинной эмуляции из-за тонкости и экспрессивной вариативности кросс-модальных сигналов. Вдохновленные эмпирическим успехом недавних так называемых End-To-End Memory Networks и связанных с ними работ, мы предлагаем подход, основанный на рекурсивном мульти-аттентировании с общей внешней памятью, обновляемой в течение нескольких стробированных итераций анализа. Мы оцениваем нашу модель по нескольким большим мультимодальным наборам данных и показываем, что глобальная контекстуализированная память с синхронным обновлением памяти может эффективно достичь распознавания эмоций.', 'hi': 'प्राकृतिक मानव संचार सूक्ष्म और स्वाभाविक रूप से बहु-मोडल है। मनुष्यके पास मुखर, दृश्य, और भाषाई, और पैरा-भाषाई जानकारी के प्रसंस्करण के लिए विशेष संवेदीता है, लेकिन एक समग्र प्रतिनिधित्व प्रदान करने के लिए बहु-मोडल डेटा स्ट्रीम का एक जटिल रूप से फ्यूज्ड परसेप्ट बनाता है। आमने-सामने संचार में भावनात्मक सामग्री का विश्लेषण एक संज्ञानात्मक कार्य है जिसके लिए मनुष्य विशेष रूप से अभ्यस्त होते हैं, इसके समाजशास्त्रीय महत्व को देखते हुए, और क्रॉस-मोडल संकेतों की सूक्ष्मता और अभिव्यंजक परिवर्तनशीलता के कारण मशीन अनुकरण के लिए एक कठिन चुनौती पैदा करता है। हाल ही में तथाकथित एंड-टू-एंड मेमोरी नेटवर्क और संबंधित कार्यों की अनुभवजन्य सफलता से प्रेरित होकर, हम विश्लेषण के कई गेटेड पुनरावृत्तियों पर अपडेट की गई साझा बाहरी स्मृति के साथ पुनरावर्ती बहु-ध्यान के आधार पर एक दृष्टिकोण का प्रस्ताव करते हैं। हम कई बड़े मल्टी-मोडल डेटासेट में अपने मॉडल का मूल्यांकन करते हैं और दिखाते हैं कि गेटेड मेमोरी अपडेट के साथ वैश्विक प्रासंगिक स्मृति प्रभावी रूप से भावना पहचान प्राप्त कर सकती है।', 'ga': 'Tá cumarsáid nádúrtha daonna níos nuaí agus ilmhódúil ó dhúchas. Tá braiteoirí speisialaithe ag daoine chun faisnéis ghutha, amhairc, theangeolaíoch agus paratheangeolaíoch a phróiseáil, ach cruthaíonn siad dearcadh casta ar an sruth sonraí ilmhódúil chun léiriú iomlánaíoch a sholáthar. Is tasc cognaíocha é anailís a dhéanamh ar ábhar mothúchánach sa chumarsáid duine le duine a mbíonn daoine faoi réir ag an aird go háirithe, ag cur a thábhachtaí socheolaíocha san áireamh, agus cruthaíonn sé dúshlán deacair d’aithrise meaisíní de bharr subtlety agus inathraitheacht léiritheach leideanna trasmhódúla. Arna spreagadh ag rath eimpíreach Líonraí Cuimhne Deireadh le Deireadh mar a thugtar orthu le déanaí agus oibreacha gaolmhara, molaimid cur chuige bunaithe ar ilaird athfhillteach le cuimhne sheachtrach roinnte nuashonraithe thar atriallta anailíse iolracha. Déanaimid luacháil ar ár múnla thar roinnt tacar sonraí móra ilmhódacha agus léirímid gur féidir le cuimhne comhthéacsaithe domhanda le nuashonrú cuimhne gated aitheantas mothúcháin a bhaint amach go héifeachtach.', 'ka': 'ჩემი ადამიანის კომუნიკაცია არიან და მრავალური მოდიალურია. ადამიანები სპეციალური სენსორია სიტყვა, ვიზუალური და ლუნგური ინფორმაციისთვის და პერ-ლუნგური ინფორმაციისთვის, მაგრამ მრავალური მონაცემების სიტყვას ინტერექტიურად დაკავშირებული ინფორმაცია ემოციონალური შემდგომარების ანალიზაცია, რომელიც ადამიანები განსაკუთრებულად აღმოჩნდება, რომელიც სოციოლოგიური მნიშვნელობა იყო და მაქსინური эმულაციის ძალიან რთული გამოცდილება, რომელიც ძალიან ძალიან ძალიან მიმდინარე მხოლოდ დასრულებული მეხსიერების და შესაბამისი სამუშაო სამუშაო სამუშაო მქონელი მქონელი წარმატებით, ჩვენ მივიღებთ რეკურსიგური მრავალური დაახლოებით გარეშე მეხსიერების განსა ჩვენ ჩვენი მოდელის შესახებ მრავალური მოდინარების მონაცემებით გავამუშავებთ და ჩვენ ჩვენ ჩვენი მოდელის შესახებ, რომ გლობალური კონტექსტუალური მეხსიერებით დაახლებ', 'el': 'Η φυσική ανθρώπινη επικοινωνία είναι διαφοροποιημένη και εγγενώς πολυμορφική. Οι άνθρωποι διαθέτουν εξειδικευμένη αισθητήρια για την επεξεργασία φωνητικών, οπτικών, γλωσσικών και παραγλωσσικών πληροφοριών, αλλά σχηματίζουν μια περίπλοκα συγχωνευμένη αντίληψη της ροής δεδομένων πολλαπλών τρόπων για να παρέχουν μια ολιστική αναπαράσταση. Η ανάλυση του συναισθηματικού περιεχομένου στην προσωπική επικοινωνία είναι ένα γνωστικό έργο στο οποίο οι άνθρωποι είναι ιδιαίτερα συντονισμένοι, δεδομένης της κοινωνιολογικής της σημασίας, και αποτελεί δύσκολη πρόκληση για τη μηχανική εξομοίωση λόγω της λεπτότητας και της εκφραστικής μεταβλητότητας των διαστροπικών ενδείξεων. Εμπνευσμένοι από την εμπειρική επιτυχία των πρόσφατων αποκαλούμενων Δικτύων Μνήμης Τέλος σε Τέλος και συναφών έργων, προτείνουμε μια προσέγγιση βασισμένη στην αναδρομική πολλαπλή προσοχή με κοινή εξωτερική μνήμη που ενημερώνεται σε πολλαπλές επαναλήψεις ανάλυσης. Αξιολογούμε το μοντέλο μας σε πολλά μεγάλα πολυμορφικά σύνολα δεδομένων και καταδεικνύουμε ότι η παγκόσμια περιεκτική μνήμη με την ενημερωμένη πύλη μνήμης μπορεί να επιτύχει αποτελεσματικά την αναγνώριση συναισθημάτων.', 'hu': 'A természetes emberi kommunikáció árnyalt és természetesen multimodális. Az emberek rendelkeznek speciális szenzoriával a vokális, vizuális, nyelvi és para-nyelvi információk feldolgozására, de bonyolultan összefonódó érzékelést alkotnak a multimodális adatfolyamról, hogy holisztikus reprezentációt nyújtsanak. Az érzelmi tartalom elemzése a személyes kommunikációban olyan kognitív feladat, amelyhez az emberek különösen hangolódnak, tekintettel annak szociológiai jelentőségére, és nehéz kihívást jelent a gépi emuláció számára a keresztmodális jelek finomsága és expresszív változékonysága miatt. A közelmúltbeli, úgynevezett End-to-End Memóriahálózatok és a kapcsolódó munkák empirikus sikeréből inspirálva egy rekurzív többfigyelemre épülő megközelítést javasolunk, amely egy közös külső memóriával frissítve többszörös gated iterációkon keresztül. Modellünket számos nagyméretű multimodális adatkészleten értékeljük, és megmutatjuk, hogy a globális kontextuális memória zárt memóriafrissítéssel hatékonyan elérhető az érzelmek felismerése.', 'kk': 'Табиғи адамдар коммуникациясы көп модалдық және көп модалдық. Адамдар дыбыс, визуалды, лингвистикалық және пара-лингвистикалық мәліметтерді өзгерту үшін көптеген сенсория бар, бірақ бірнеше модалдық деректердің көпшілікті түсіндіру үшін көпшілікті мәліметтік түсінд Эмоциялық мазмұнын қарай-қарай байланыстыруда талдау - адамдар өзінің социологиялық маңыздылығына арналған күнделікті тапсырмасы. Социологиялық маңыздылығын беріп, машина эмуляциясының көпшілікті және көпшілікті м Жуырдағы "End-To-End" жады жұмысының жұмысының эмпирикалық сәттілігі жұмысын жұмыс істеп, қайталанатын көптеген көптеген бірнеше анализ қайталануларында жаңартылған сыртқы жады бойынша қайталанатын қадамды Біз моделімізді бірнеше үлкен көп модельді деректер жиындарына бағалап, жадын жаңарту үшін жүйелік жадындағы көптеген жадын жаңарту мүмкіндіктері эмоциялық түсініктерді', 'it': "La comunicazione umana naturale è sfumata e intrinsecamente multimodale. Gli esseri umani possiedono sensorie specializzate per l'elaborazione di informazioni vocali, visive, linguistiche e para-linguistiche, ma formano una percezione intricata del flusso di dati multimodali per fornire una rappresentazione olistica. L'analisi del contenuto emotivo nella comunicazione faccia a faccia è un compito cognitivo a cui l'uomo è particolarmente sintonizzato, data la sua importanza sociologica, e pone una sfida difficile per l'emulazione automatica a causa della sottigliezza e variabilità espressiva degli indizi cross-modali. Ispirati dal successo empirico delle recenti reti di memoria end-to-end e dei relativi lavori, proponiamo un approccio basato sulla multi-attenzione ricorsiva con una memoria esterna condivisa aggiornata su più gated iterations di analisi. Valutiamo il nostro modello su diversi grandi set di dati multimodali e mostriamo che la memoria contestualizzata globale con aggiornamento della memoria gated può raggiungere efficacemente il riconoscimento delle emozioni.", 'ms': 'Komunikasi manusia semulajadi berwarna-warna dan secara beragama-modal. Manusia mempunyai sensori khusus untuk memproses maklumat vokal, visual, dan bahasa, dan para-bahasa, tetapi membentuk persepsi terhubung rumit dari aliran data multi modal untuk menyediakan perwakilan holistik. Analisis kandungan emosional dalam komunikasi muka ke muka adalah tugas kognitif yang mana manusia terutama disertai, mengingat kepentingan sosiologi, dan menghasilkan tantangan sukar untuk emulasi mesin disebabkan variabiliti halus dan ekspresif tanda-tanda transmodal. Inspired by the empirical success of recent so-called End-To-End Memory Networks and related works, we propose an approach based on recursive multi-attention with a shared external memory updated over multiple gated iterations of analysis.  Kami menilai model kami melalui beberapa set data multi modal besar dan menunjukkan bahawa memori kontekstualisasi global dengan kemaskini memori gerbang dapat mencapai pengenalan emosi secara efektif.', 'lt': 'Gamtinis žmogaus ryšys yra nuodugnis ir iš esmės daugiarūšis. Žmonės turi specializuotą jutiklį, skirtą balsinei, vizualinei, kalbinei ir parakalbinei informacijai apdoroti, tačiau sukuria sudėtingą įvairiarūšio duomenų srauto suvokimą, kad būtų užtikrintas holistinis atstovavimas. Emocinio turinio analizė tiesioginiame ryšyje yra pažintinė užduotis, prie kurios žmonės, atsižvelgiant į jų socialinę svarbą, yra ypač prisijungę, ir sukuria sunkų iššūkį mašin ų emuliacijai dėl įvairiarūšio režimo signalų subtilumo ir aiškio kintamumo. Įkvėptas empiriniu pastarųjų vadinamųjų „End-To-End“ atminties tinklų ir susijusių darbų sėkmingumu, mes siūlome metodą, pagrįstą atkuriamu daugiapusiu dėmesiu su bendra išorine atmintimi, atnaujinta per daugelį vartų atliekamų analizių kartojimų. Vertiname savo model į keliuose dideliuose daugiarūšiuose duomenų rinkiniuose ir parodome, kad pasaulinė kontekstinė atmintis su įjungta atminties atnaujinimu gali veiksmingai pasiekti emocijų pripažinimą.', 'mk': 'Природната човечка комуникација е нианцирана и природно мултимодилна. Луѓето поседуваат специјализирани сензории за обработување на гласни, визуелни и лингвистички и паралингвистички информации, но формираат сложено збунет перцепт на мултимодалниот поток на податоци за да обезбедат холистичка претстава. Анализата на емоционалната содржина во комуникацијата лице на лице е когнитивна задача на која луѓето се особено приклучени, со оглед на својата социолошка важност, и претставува тежок предизвик за машинска емулација поради суптилноста и експресивната варијабилност на крстомодалните знаци. Инспириран од емпиричкиот успех на неодамнешните т.н. Мемориски мрежи на крај до крај и поврзани работи, предложуваме пристап базиран на рекурсивно мултивние внимание со заедничка надворешна меморија обновена во текот на неколку вратни итерации на анализа. Го проценуваме нашиот модел преку неколку големи мултимодилни податоци и покажуваме дека глобалната контекстуална меморија со обновување на вратната меморија може ефикасно да постигне емоционално препознавање.', 'ml': 'സ്വാഭാവികമായ മനുഷ്യരുടെ ബന്ധപ്പെടുത്തിയിരിക്കുന്നു മനുഷ്യര്\u200dക്ക് വോക്കല്\u200d, കാഴ്ചകള്\u200d, ഭാഷ, വിവരങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d പ്രത്യേക വിവരങ്ങളുണ്ട്. പക്ഷെ ഒരു വിശിഷ്ടമായ പ്രതിനിധിയ്ക്കാനുള്ള പല മോഡാല്\u200d ഡാറ് മുഖം മുഖം വായിച്ചുകൊണ്ടിരിക്കുന്ന വികാരങ്ങളുടെ ഉള്ളടക്കം അന്വേഷിക്കുന്നത് മനുഷ്യര്\u200d പ്രത്യേകിച്ച് ഉള്ള ജോലിയാണ്. അതിന്റെ സാമൂഹിക പ്രാധാന്യം കൊണ്ട്, മെഷ അടുത്തിടെയുള്ള അവസാനത്തെ അവസാന മെമ്മറി നെറ്റ്\u200cവര്\u200dക്കുകളും ബന്ധപ്പെട്ട പ്രവൃത്തികളുമായി വിജയത്തിന്റെ ശാസ്ത്ര വിജയത്താല്\u200d നമ്മള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു. ഒരു  നമ്മുടെ മോഡല്\u200d നമ്മുടെ മോഡല്\u200d വിലാസപ്പെടുത്തുന്നത് പല വലിയ മോഡല്\u200d ഡാറ്റാസറ്റുകളിലൂടെയാണ്. കാണിക്കുന്നതിനാല്\u200d ഗ്ലോബല്\u200d മെമ്', 'mt': 'Il-komunikazzjoni umana naturali hija nuanzata u b’mod inerenti multimodali. Il-bnedmin għandhom sensorji speċjalizzati għall-ipproċessar ta’ informazzjoni vokali, viżwali, u lingwistika u para-lingwistika, iżda jiffurmaw perċezzjoni mħallta b’mod kumplikat tal-fluss ta’ dejta multimodali biex jipprovdu rappreżentanza olistika. L-analiżi tal-kontenut emozzjonali fil-komunikazzjoni wiċċ imb’wiċċ hija kompitu konjittiv li l-bniedem huwa partikolarment marbut magħu, minħabba l-importanza soċjoloġika tiegħu, u to ħloq sfida diffiċli għall-emulazzjoni tal-magna minħabba l-varjabilità sottili u espressiva tal-indikazzjonijiet transmodali. Inspirat mis-suċċess empiriku tal-hekk imsejħa Netwerks tal-Memorja ta’ tmiem sa tmiem reċenti u xogħlijiet relatati, qed nipproponu approċċ ibbażat fuq attenzjoni multipla rikorrenti b’memorja esterna kondiviża a ġġornata fuq iterazzjonijiet multipli ta’ analiżi. Aħna jevalwaw il-mudell tagħna f’diversi settijiet ta’ dejta multimodali kbar u nuru li l-memorja kuntestwalizzata globali b’aġġornament tal-memorja miftuħa tista’ tikseb rikonoxximent tal-emozzjonijiet b’mod effettiv.', 'pl': 'Naturalna komunikacja człowieka jest niuansowana i z natury multimodalna. Ludzie posiadają specjalistyczną sensorię do przetwarzania informacji wokalnych, wizualnych, językowych i paralingwistycznych, ale tworzą skomplikowaną percepcję multimodalnego strumienia danych, aby zapewnić holistyczną reprezentację. Analiza treści emocjonalnych w komunikacji twarzą w twarz jest zadaniem poznawczym, do którego ludzie są szczególnie dostrojeni, biorąc pod uwagę swoje znaczenie socjologiczne, i stanowi trudne wyzwanie dla emulacji maszynowej ze względu na subtelność i wyrazistą zmienność sygnałów crossmodalnych. Zainspirowani empirycznym sukcesem najnowszych tzw. sieci pamięci end-to-end i powiązanych z nimi prac, proponujemy podejście oparte na rekursywnej multi-attence ze wspólną pamięcią zewnętrzną aktualizowaną w wielu gated iteracjach analizy. Oceniamy nasz model w kilku dużych multimodalnych zbiorach danych i pokazujemy, że globalna pamięć kontekstowa z aktualizacją pamięci gated może skutecznie osiągnąć rozpoznawanie emocji.', 'ro': 'Comunicarea umană naturală este nuanțată și inerent multimodală. Oamenii posedă senzoria specializată pentru prelucrarea informațiilor vocale, vizuale și lingvistice și para-lingvistice, dar formează o percepție complet fuzionată a fluxului de date multimodal pentru a oferi o reprezentare holistică. Analiza conținutului emoțional în comunicarea față în față este o sarcină cognitivă la care oamenii sunt deosebit de adaptați, dată fiind importanța sa sociologică, și reprezintă o provocare dificilă pentru emularea mașinilor datorită subtilității și variabilității expresive a indiciilor cross-modale. Inspirat de succesul empiric al așa-numitelor rețele de memorie end-to-end recente și lucrări conexe, propunem o abordare bazată pe multi-atenție recursivă cu o memorie externă partajată actualizată pe multiple iterații gated de analiză. Evaluăm modelul nostru pe mai multe seturi de date multimodale mari și arătăm că memoria contextualizată globală cu actualizarea memoriei gated poate obține în mod eficient recunoașterea emoțiilor.', 'no': 'Natural human communication is nuanced and inherently multi modal. Menneske har spesialisert sensorikk for å handsama vokal, visuell, og lingvisk og para-lingvisk informasjon, men formar ein intrikativt fokusert oppfatting av multi modal datastrømmet for å gi ein holistisk representasjon. Analysering av emosjonell innhald i ansikt-motsetjing er ein kognitiv oppgåve som mennesker er spesielt tilgjengeleg, gjeven sosialogiske viktighet, og poserer ein vanskeleg utfordring for maskineemulating på grunn av subtilte og uttrykkelig variabilitet av krysmodale teikn. Inspirert av den empiriske suksessen av den siste såkalla ende-til-slutt minnet og tilhøyrande arbeid, fører vi ein tilgang basert på rekursiv fleire oppmerksomhetar med ei delt ekstern minne oppdatert over fleire gated gjentakingar av analyse. Vi evaluerer modellen vårt over fleire store multi modal datasett og viser at globalt kontekstualisert minne med oppdatering av gated minne kan effektivt oppnå følelseskjenning.', 'mn': 'Байгалийн хүн төрөлхтний холбоотой холбоотой бөгөөд эдгээр нь олон төрлийн холбоотой. Хүн төрөлхтөн дуу, үзэл, хэлний болон пара-хэлний мэдээллийг ажиллах мэргэжлийн мэдрэмж байдаг. Гэхдээ олон төрлийн мэдээллийн урсгалыг бүтээж буй олон төрлийн мэдээллийн урсгалыг бүтээж байдаг. Хүн төрөлхтний харилцааны сэтгэл хөдлөлийн тодорхойлолтын шинжилгээ нь хүн төрөлхтний ялангуяа хүлээн зөвшөөрөгдсөн, нийгмийн социаллогийн чухал ач холбогдолтой учраас, машины эмулацийн тулд хэцүү асуудал болгодог. Саяхан "End-To-End Memory Networks" гэдэг нэртэй "End-To-End Memory Networks" болон хамааралтай ажиллуудын эмзэг амжилтын тулд бид олон анхаарал дээр дахин олон анхаарлын үндсэн арга замыг сануулж байна. Бид өөрсдийн загварыг олон том хэмжээний өгөгдлийн сан дээр үнэлгээд дэлхийн дурсамжтай санах санамж нь сэтгэл хөдлөлийн хүлээн зөвшөөрөх боломжтой гэдгийг харуулж байна.', 'so': 'Wargelinta dabiicadda ah ee dadku waxay ku baahan yihiin noocyo badan. Dadku waxay leeyihiin sensoriyo gaar ah oo ay ka baaraandegaan macluumaadka codka, aragga, luuqadda iyo afka kala duwan, laakiin waxay sameeyaan dareecada macluumaadka kala duduwan si ay u fidiyaan qaab daahir ah. Analyska wax ku saabsan iskuulka wejiga ka soo jeeda waa shaqa aad u yaqaan dadka si gaar ah loo qabanayo, iyadoo ay muhiim u leedahay bulshada, waxayna leedahay dhibaatooyin adag oo ku saabsan qaniinka maskinada, sababtoo ah caqliga iyo muuqashada kala duwan kooxaha kala duduwan. Dhab ahaan waxaa la soo dhiibay suuradda ugu dhawaaqda dhamaan-To-End Memory Network iyo shaqaalaha la xiriira, waxaynu soo jeedaynaa qaab ku saabsan dib-u-jeedid badan oo xafiiska dibadda ah oo la qaybsaday oo la cusboonaysiiyey wax badan oo baaritaan ah. Tusaalkayaga ayaannu ku qiimeynaynaa sawirada macluumaadyo badan oo kala duduwan, waxaana tusnaynaa in xasuusta la soo qabtay oo la cusboonaysiiyey xusuusta la soo bandhigay uu si faa’iido ah u gaadhi karo aqoonsiga xisaabta.', 'sr': 'Prirodna ljudska komunikacija je nuancirana i inherentno multimodalna. Ljudi posjeduju specijalizovanu senzoriju za obrađivanje glasova, vizualnih i lingvističkih informacija i para-lingvističkih informacija, ali formiraju intrikalno zajedničku percepciju multimodalnog podataka kako bi pružili holističku predstavu. Analiza emocionalnog sadržaja u komunikaciji licem na lice je kognitivan zadatak kojem su ljudi posebno privedeni, s obzirom na sociološku važnost, i predstavlja težak izazov za emulaciju mašine zbog suptilnosti i ekspresivne variabilnosti cross-modalnih znakova. Inspirirani empiričkim uspjehom nedavnog takozvanog "End-to-End Memory Networks" i povezanih radova, predlažemo pristup baziran na rekursivnoj multi-pažnji sa zajedničkom spoljnom pamćenju updatiranom preko višestrukih gatovanih iteracija analize. Procjenjujemo naš model u nekoliko velikih multimodalnih podataka i pokazujemo da globalno kontekstualizovano pamćenje sa aktualizacijom prikupljenih pamćenja može efektivno postići priznanje emocija.', 'sv': 'Naturlig mänsklig kommunikation är nyanserad och i sig multimodal. Människor har specialiserade sensorier för att bearbeta sång, visuell och språklig och para-språklig information, men bildar en intrikat sammansmält uppfattning av det multimodala dataströmmen för att ge en holistisk representation. Analys av emotionellt innehåll i ansikte mot ansikte kommunikation är en kognitiv uppgift som människan är särskilt anpassad till, med tanke på dess sociologiska betydelse, och utgör en svår utmaning för maskinemulering på grund av den subtilitet och uttrycksfulla variabiliteten hos tvärmodala ledtrådar. Inspirerad av den empiriska framgången av de senaste så kallade End-To-End Memory Networks och relaterade arbeten, föreslår vi ett tillvägagångssätt baserat på rekursiv multi-uppmärksamhet med ett delat externt minne uppdaterat över flera gated iterationer av analys. Vi utvärderar vår modell över flera stora multimodala datauppsättningar och visar att globalt kontextualiserat minne med gated memory update effektivt kan uppnå känsloigenkänning.', 'si': 'ස්වභාවික මිනිස්සුන් සම්බන්ධතාවය නැවත් වෙලා තියෙනවා. මිනිස්සුන්ට විශේෂ සංවේදනය තියෙන්නේ ශ්\u200dරේෂ, දිහාන්\u200dය, භාෂාත්මක, සහ භාෂාත්මක තොරතුරු සඳහා විශේෂ සංවේදනය, ඒත් විශේෂ මිනිස්සුන් විශේෂයෙන් සාමාජික විශේෂණය සම්බන්ධයෙන් මුහුණට සම්බන්ධයෙන් ඉන්න අවශ්\u200dය විශ්ලේෂණය තමයි මිනිස්සුන් විශේෂයෙන් අවශ්\u200dය වි අවස්ථානයෙන් අවස්ථානයේ අවස්ථානය සහ සම්බන්ධ ව්\u200dයාපාරයෙන් අවස්ථානය කරලා තියෙන්නේ අවස්ථානයේ අවස්ථානයේ අවස්ථාව, අපි ප්\u200dරතික අපි අපේ මොඩල් විශාල විශාල විශාල විශාල දත්ත සේට් වලින් විශේෂ කරනවා ඒ වගේම පෙන්වන්නේ ජාතික සාමාන්\u200dය විශාල ම', 'ur': 'طبیعی انسان کی ارتباط ہٹی جاتی ہے اور اس میں بہت سی موڈل ہیں۔ انسانوں کے پاس آواز، نظریہ، اور زبان شناسی اور پارزبان شناسی معلومات کے لئے مخصوص سنسوریا ہے، لیکن بہت سی موڈال ڈیٹ سیڑھی کی نظریہ پیدا کرتا ہے کہ ایک تعلیم نمایش دے۔ مخالف سمجھ کے مطابق احساسات کی تحلیل یہ ہے کہ انسانوں کو مختلف سمجھ لیا گیا ہے، اس کی اجتماعی اثبات کے ذریعہ سے، اور ماشین ایمولیشن کے لئے ایک مشکل چال بنا رہا ہے، اس کے ذریعہ سے کمزور اور مختلف متفاوت کی وجہ سے۔ اگلے نامی End-To-End Memory Networks اور رابطہ دار کاموں کے مطابق مغلوب موفقیت کے ذریعے ہمیں ایک طریقہ پیش کرتا ہے جو دوبارہ multi-attention پر بنیاد ہے ایک شریک خارجی مہمانی کے ذریعے سے بہت سی ٹیٹ کے بارے میں آغاز کی گئی ہے۔ ہم نے اپنے مدل کو چند بڑے بہت بڑے مالک ڈیٹ سٹ میں مطالعہ کر لیا ہے اور دکھا دیتے ہیں کہ گٹ ڈیٹ یاد کے ساتھ global contextualized یاد حاصل کر سکتا ہے', 'ta': 'இயல்பான மனித தொடர்பு குறைக்கப்பட்டுள்ளது மற்றும் உள்ளமைந்த பல-மாதிரி உள்ளது. மனிதர்கள் செயல்படுத்துவதற்கான குறிப்பிட்ட உணர்வு, காட்சி மற்றும் மொழி மற்றும் அடர்த்தி மொழி தகவல்களை செயல்படுத்துவதற்கான சிறப்பு உணர்வு கொண்டுள்ளது, ஆனால் ஒரு  முகத்துக்கு தொடர்புகளில் உணர்வு உள்ளடக்கத்தை ஆராய்வு என்பது ஒரு குறிப்பான செயலாகும், அது மனிதர்கள் சிறப்பாக அலங்கரிக்கப்பட்டுள்ளது, அதன் சமூக முக்கியமானது, மற்றும் குறைந்த சமீபத்தில் அழைக்கப்பட்ட முடிவு நினைவகம் முடிவு வலைப்பின்னல் மற்றும் தொடர்புடைய செயல்களின் வெற்றிக்கான வெற்றியால் நாம் திரும்பச் செய்து பல பிரிவுகள் பு பல பெரிய மாதிரி தகவல் அமைப்புகளில் நாம் எங்கள் மாதிரியை மதிப்பிடுகிறோம் மற்றும் காட்டுகிறோம் பொதுவான நினைவகத்தில் புதுப்பி', 'uz': "Asosiy inson aloqa bir necha modal bilan ishlab chiqaradi. Одамлар овозлар, кўзлар, тилинглар ва парагингча маълумотларни ишлатиш учун махсус санжорий эгалари бор, аммо аниқ маълумотларни кўрсатиш учун кўп модем маълумотлар қаторида кўриб чиқиши мумкин. Ko'pchilik taʼminotlarida hissiyot tarkibini analyzer, odamlar buning ijodkorlik muhimligini anglatadi, va o'zimning jamoallik muhimligini anglatadi va o'zgarishning kichkina va ko'paytirish muvaffaqiyatlariga qiyin tarqaladi. Yaqinda oʻrnatilgan oxirgi- To- End- To- End Tarmoqning muvaffaqiyatli imkoniyatlariga imkoniyatli beradi va boshqa ishlarni boshqarish mumkin, biz bir nechta tartib boʻlgan tashqi xotira bilan qayta ishlatilgan bir necha tartiblarga yangilangan narsalar bilan qayta tartib boshqarish muvaffaqiyatlarini Biz bir necha ko'plab modal maʼlumotlar tarkibida modelimizni qiymatimiz va o'ylab qo'yilgan xotira yozib qo'yilgan xotira qo'shilgan xotira hissiyotni tasdiqlashni ishga tayyorlaydi.", 'vi': 'Giao tiếp của con người phân biệt và đa phương. Loài người sở hữu sư đoàn chuyên môn để xử lý thông tin ngôn ngữ, giọng nói, thị giác và ngôn ngữ, và dù-ngôn ngữ, nhưng tạo ra một phần nhận thức phức tạp của dòng dữ liệu đa phương để mô tả tổng thể. Phân tích tâm lý trong giao tiếp mặt đối mặt là một nhiệm vụ nhận thức mà con người đặc biệt thích ứng, vì quan trọng xã hội của nó, và gây ra một thử thách khó khăn cho mô phỏng máy do sự thay đổi khéo léo và biểu cảm của các hành vi khác nhau. Nguồn cảm hứng từ thành công của các công nghệ gần đây được gọi là End-End-End (Mạng nhớ) và các công trình liên quan, chúng tôi đề xuất một phương pháp dựa trên các tập trung các tập trung nổi loạn với trí nhớ bên ngoài chia sẻ được cập nhật qua nhiều phiên bản phân tích. Chúng tôi đánh giá mẫu của chúng tôi qua nhiều tập tin đa phương vi lớn và cho thấy rằng trí nhớ tương ứng trên toàn cầu với việc cập nhật bộ nhớ', 'da': 'Naturlig menneskelig kommunikation er nuanceret og i sig selv multimodal. Mennesker besidder specialiserede sensorier til behandling af vokal, visuel, sproglig og para-lingvistisk information, men danner en indviklet opfattelse af den multimodale datastrøm for at give en holistisk repræsentation. Analyse af følelsesmæssigt indhold i ansigt til ansigt kommunikation er en kognitiv opgave, som mennesker er særligt tilpasset på grund af dens sociologiske betydning, og udgør en vanskelig udfordring for maskinemulering på grund af den subtilitet og udtryksfulde variation af tværmodale signaler. Inspireret af den empiriske succes af nyere såkaldte End-To-End hukommelsesnetværk og relaterede værker, foreslår vi en tilgang baseret på rekursiv multi-opmærksomhed med en delt ekstern hukommelse opdateret over flere gated iterationer af analyse. Vi evaluerer vores model på tværs af flere store multimodale datasæt og viser, at global kontekstualiseret hukommelse med gated hukommelse opdatering effektivt kan opnå følelsesgenkendelse.', 'nl': 'Natuurlijke menselijke communicatie is genuanceerd en inherent multimodaal. Mensen beschikken over gespecialiseerde sensoria voor het verwerken van vocale, visuele, linguïstische en paralinguïstische informatie, maar vormen een ingewikkeld samengevoegd percept van de multimodale datastroom om een holistische weergave te bieden. De analyse van emotionele inhoud in face-to-face communicatie is een cognitieve taak waarop mensen vooral zijn afgestemd, gezien het sociologische belang ervan, en vormt een moeilijke uitdaging voor machineemulatie vanwege de subtiliteit en expressieve variabiliteit van crossmodale signalen. Geïnspireerd door het empirische succes van recente zogenaamde end-to-end geheugennetwerken en aanverwante werken, stellen we een aanpak voor die gebaseerd is op recursieve multi-attentie met een gedeeld extern geheugen dat wordt bijgewerkt over meerdere gated iteraties van analyse. We evalueren ons model op verschillende grote multimodale datasets en tonen aan dat wereldwijd contextualiseerd geheugen met gated memory update effectief emotie herkenning kan bereiken.', 'hr': 'Prirodna ljudska komunikacija je nuancirana i inherentno multimodalna. Ljudi posjeduju specijaliziranu senzoriju za obrađivanje glasova, vizualnih i jezičkih informacija i para-jezičkih informacija, ali formiraju intrikalno zajedničku percepciju multimodalnog potoka podataka kako bi pružili holističku predstavu. Analiza emocionalnog sadržaja u komunikaciji licem na lice je kognitivan zadatak kojem su ljudi posebno pristupljeni, s obzirom na sociološku važnost, i predstavlja težak izazov za emulaciju strojeva zbog suptilnosti i izrazivne varijancije krsnomodalnih znakova. Inspirirani empiričkim uspjehom nedavnih takozvanih mreža End-to-End Memory i povezanih radova, predlažemo pristup na temelju rekursivnog multipažnje s zajedničkom vanjskom pamćenju updatiranom preko višestrukih otkrivenih ponovnih analiza. Procjenjujemo naš model u nekoliko velikih multimodalnih podataka i pokazujemo da globalno kontekstualizirano sjećanje s obnovljenim uspomenama može učinkovito postići priznanje emocija.', 'id': 'Natural human communication is nuanced and inherently multi-modal.  Manusia memiliki sensori khusus untuk memproses informasi vokal, visual, dan bahasa, dan para-bahasa, tapi membentuk persepsi yang rumit dari aliran data multi modal untuk menyediakan representation holistik. Analisi isi isi emosional dalam komunikasi wajah-wajah adalah tugas kognitif yang mana manusia terutama disesuaikan, mengingat pentingnya sosiologis, dan menghasilkan tantangan sulit untuk emulasi mesin karena variabilitas halus dan ekspresif tanda-tanda transmodal. Terinspirasi oleh sukses empirik yang baru-baru ini disebut Jaringan Memori End-To-End dan pekerjaan yang berhubungan, kami mengusulkan pendekatan berdasarkan multi-perhatian rekursif dengan memori eksternal berbagi yang diperbaiki atas banyak iterasi analisis gerbang. Kami mengevaluasi model kami melalui beberapa set data multi modal besar dan menunjukkan bahwa memori kontekstualisasi global dengan kemaskini memori gerbang dapat secara efektif mencapai pengenalan emosi.', 'ko': '인류의 자연 교류는 미묘하고 고유한 다모태이다.인류는 소리, 시각, 언어와 준언어 정보를 처리하는 전문적인 감각을 가지고 있지만 다중모드 데이터 흐름에 대해 복잡한 융합 감지를 형성하여 전체적인 표현을 제공한다.대면 교류에서 감정 내용에 대한 분석은 인지적 임무로 그 사회학적 중요성을 감안하여 인류는 이 임무에 특히 적응했다. 또한 다중모드적 단서의 미묘성과 표현 가변성 때문에 기계 시뮬레이션에 어려운 도전을 제기했다.최근의 이른바 단말기부터 단말기까지의 기억 네트워크와 관련 업무의 경험적 성공의 계발을 받아 우리는 여러 개의 문 제어 분석을 통해 외부 기억을 교체하고 공유하는 방법을 제시했다.우리는 여러 개의 대형 다중모드 데이터 집합에서 우리의 모델을 평가한 결과 문 제어 기억이 갱신된 전역 상황화 기억이 정서 식별을 효과적으로 실현할 수 있음을 나타냈다.', 'sw': 'Mawasiliano ya asili ya binadamu yanapungua na kwa namna nyingi. Watu wanamiliki sensori maalumu kwa ajili ya kuchukua kura, kuona, na lugha, na taarifa za upinzani, lakini wanatengeneza mtazamo wa mitandao ya data yenye utaratibu wa kutoa uwakilishi wa kitaalamu. Uchambuzi wa maudhui ya hisia katika mawasiliano ya uso wa uso ni kazi yenye ujuzi ambazo binadamu hujigubika hasa, kwa sababu ya umuhimu wake wa kijamii, na inaleta changamoto ngumu kwa ajili ya kutengeneza mashine kutokana na utofauti wa a in a ndogo na yenye ufanisi wa mabadiliko yanayotokana na makundi yanayovuka. Inspired by the empirical success of recent so-called End-To-End Memory Networks and related works, we propose an approach based on recursive multi-attention with a shared external memory updated over multiple gated iterations of analysis.  Tunatathmini mifano yetu katika seti mbalimbali za takwimu za aina mbalimbali na kuonyesha kuwa kumbukumbu iliyoendeshwa duniani kwa upya wa kumbukumbu zilizotumwa inaweza kupata tamaa kwa ufanisi.', 'bg': 'Естествената човешка комуникация е нюансирана и същевременно мултимодална. Хората притежават специализирана сензория за обработка на вокална, визуална, лингвистична и паралингвистична информация, но образуват сложно слето възприятие на мултимодалния поток от данни, за да осигурят холистично представяне. Анализът на емоционалното съдържание в комуникацията лице в лице е когнитивна задача, към която хората са особено настроени, имайки предвид нейното социологическо значение, и представлява трудно предизвикателство за машинната емулация поради тънкостта и изразителната променливост на междумодалните знаци. Вдъхновени от емпиричния успех на неотдавнашните т.нар. мрежи от памет от край до край и сродни работи, ние предлагаме подход, базиран на рекурсивно мулти-внимание с споделена външна памет, актуализирана чрез множество затворени итерации на анализ. Ние оценяваме нашия модел в няколко големи мултимодални набора от данни и показваме, че глобалната контекстуализирана памет с актуализация на затворената памет може ефективно да постигне разпознаване на емоциите.', 'de': 'Natürliche menschliche Kommunikation ist nuanciert und inhärent multimodal. Der Mensch verfügt über spezialisierte Sensorien für die Verarbeitung von vokalen, visuellen, sprachlichen und paralinguistischen Informationen, bildet aber eine kompliziert verschmolzene Wahrnehmung des multimodalen Datenstroms zu einer ganzheitlichen Darstellung. Die Analyse emotionaler Inhalte in der Face-to-Face Kommunikation ist eine kognitive Aufgabe, auf die der Mensch angesichts seiner soziologischen Bedeutung besonders eingestellt ist und stellt aufgrund der Subtilität und expressiven Variabilität crossmodaler Signale eine schwierige Herausforderung für die maschinelle Emulation dar. Inspiriert durch den empirischen Erfolg von sogenannten End-to-End Memory Networks und verwandten Arbeiten schlagen wir einen Ansatz vor, der auf rekursiver Multi-Aufmerksamkeit mit einem gemeinsamen externen Speicher basiert, der über mehrere gated Iterationen der Analyse aktualisiert wird. Wir evaluieren unser Modell über mehrere große multimodale Datensätze und zeigen, dass globaler kontextualisierter Speicher mit gated memory update effektiv Emotionserkennung erreichen kann.', 'af': "Natuurlike menslike kommunikasie is nuanced en inherent multi modal. Mense het spesialiseerde sensorie vir die verwerking van vokal, visuele en lingvisiese en para-lingvisiese inligting, maar vorm 'n intrikaal verbondige aansoek van die multimodale data stroom om 'n holistiese voorstelling te verskaf. Analisie van emosionele inhoud in gesig-na-gesig kommunikasie is 'n kognitiewe taak waarmee mense besonderlik aangekom is, gegee sy sosiale belangrikheid, en stel 'n moeilike uitdrukking vir masjien emulaasie vanweë die ondersteunde en uitdrukklike veranderlike veranderlike van kruismodale tekens. Inspireer deur die empiriese sukses van onlangse so-genoem End-to-End Geheue Netwerke en verwante werke, ons voorstel 'n toegang gebaseer op rekursief multi-aandag met 'n gedeelde eksterne geheue opgedateer oor veelvuldige gated iterasies van analisie. Ons evalueer ons model oor verskeie groot multimodale datastelle en wys dat globale contextualiseerde geheue met gated geheue opdatering effektief emosie herkening kan bereik.", 'tr': 'Tebiýal adam habarlaşyky daşyrdyr we olaryň içinde birnäçe modal bolup geçirilýär. İnsanlar sesli, görsel ve dil bilgisini işlemek için özellikli bir sensorya sahip, fakat holistik bir şekilde çoklu modal veri akışını sağlamak için elimden gelen bir şekilde birleştirildir. Adamlar üçin görnüş-görnüşlerde duýgymlyk mazmunlaryň çözümlenmesi, adamlaryň özellikle tanyş edilen bilim görevi, sosyalogiýalygy möhümüne berilýär we maşynyň öňündeki görnüşleri üçin çözümlenmesi üçin kyn kynçylyk döwüregi bar. Soňky "End-to-End Memory Networks" we "End-to-End Memory Networks" adlanylaryň empirik başarylygynyň üstüne gollanan, birnäçe gatlanan analýzyň üstünde gaýtalanany bir gollanan we gollanan teklip etmegini teklip edip görýäris. Biz modelimizi birnäçe uly modal veri setirlerinde deňleýäris we dünýädäki contextualizalýan yada täzelikleri bilen duýgularyň tanamasyny etkinleýäris.', 'hy': 'Natural human communication is nuanced and inherently multi-modal.  Humans possess specialised sensoria for processing vocal, visual, and linguistic, and para-linguistic information, but form an intricately fused percept of the multi-modal data stream to provide a holistic representation.  Էմոցիոնալ պարունակության վերլուծությունը դեմ առ դեմ հաղորդակցման մեջ ճանաչողական խնդիր է, որին մարդիկ հատկապես հարմարված են, հաշվի առնելով իրենց սոցիալոլոգիական կարևորությունը, և առաջացնում է դժվար մարտահրավեր մեքենայի էմուլացիայի համար, քանի որ խաչմոդային նշանների նր Inspired by the empirical success of recent so-called End-To-End Memory Networks and related works, we propose an approach based on recursive multi-attention with a shared external memory updated over multiple gated iterations of analysis.  We evaluate our model across several large multi-modal datasets and show that global contextualised memory with gated memory update can effectively achieve emotion recognition.', 'fa': 'ارتباط انسان طبیعی بی\u200cنیاز و بی\u200cنیاز متفاوت است. انسان\u200cها حسوری متخصص برای پرداخت کردن اطلاعات صوتی، دید و زبان\u200cشناسی و پور-زبان\u200cشناسی دارند، ولی یک احساس متصل شدنی از سیم داده\u200cهای چندین مدال برای تهیه نمایش تعلیم\u200cشناسی ساخته می\u200cشوند. تحلیل محتوای احساساتی در ارتباط با چهره و چهره\u200cای یک کار شناخته است که انسان به خصوصاً به آن رسیده می\u200cشود، با توجه به اهمیت اجتماعی آن، و یک چالش سختی برای emulation ماشین به دلیل تغییر زیادی و نشانه\u200cهای متفاوتی از نشانه\u200cهای متفاوتی قرار می\u200cدهد. توسط موفقیت امپراتیکی از شبکه\u200cهای خاطرات پایان و کارهای مربوط به نام پایان یادآوری و کارهای مربوط به تازگی اخیر، ما یک روش پیشنهاد می\u200cکنیم که بر روی توجه چندین بار با یک حافظه خارجی مشترک در مورد چندین بار تحلیل آغاز شده است. ما مدل خود را در چند مجموعه\u200cهای داده\u200cهای بسیار بزرگ ارزیابی می\u200cکنیم و نشان می\u200cدهیم که حافظه\u200cی موقعیت\u200cهای جهانی با توضیح حافظه\u200cهای جمع شده می\u200cتواند به طور موثرت تشخیص احساسات را به دست آورد.', 'sq': 'Natural human communication is nuanced and inherently multi-modal.  Humans possess specialised sensoria for processing vocal, visual, and linguistic, and para-linguistic information, but form an intricately fused percept of the multi-modal data stream to provide a holistic representation.  Analiza e përmbajtjes emocionale në komunikimin fytyrë në fytyrë është një detyrë kognitive me të cilën njerëzit janë veçanërisht të lidhur, duke marrë parasysh rëndësinë e saj sociologjike dhe paraqet një sfidë të vështirë për emulacionin e makinave për shkak të subtilitetit dhe variabilitetit shprehës të shenjave ndërmodali. Inspired by the empirical success of recent so-called End-To-End Memory Networks and related works, we propose an approach based on recursive multi-attention with a shared external memory updated over multiple gated iterations of analysis.  We evaluate our model across several large multi-modal datasets and show that global contextualised memory with gated memory update can effectively achieve emotion recognition.', 'bn': 'স্বাভাবিক মানুষের যোগাযোগ বাড়িয়ে দেয়া হয়েছে এবং অনেক মোডাল। ভোল, দৃষ্টিভঙ্গি এবং ভাষার তথ্য প্রক্রিয়ার জন্য মানুষের বিশেষ সেন্সরিয়ার অধিকার রয়েছে, কিন্তু একটি পবিত্র প্রতিনিধিত্ব দেয়ার জন্য বহুমোডাল ডাটা নদীর ব মুখের মুখোমুখি যোগাযোগের মুখোমুখি বিষয়বস্তুর বিশ্লেষণ হচ্ছে একটি জ্ঞানীয় কাজ যার জন্য মানুষ বিশেষ করে তাদের সামাজিক গুরুত্বপূর্ণ, আর মেশিনের বিরুদ্ধে প্রকা সাম্প্রতিক তথাকথিত তথাকথিত শেষ-টো মেমোরি নেটওয়ার্ক এবং সংশ্লিষ্ট কাজের সাম্প্রতিক সাফল্যের অনুপ্রাণিত করে আমরা প্রস্তাব করি বিশ্লেষণের বিভিন্ন বিভিন্ন বিভ আমরা বেশ কয়েকটি বিশাল মোডাল ডাটাসেটে আমাদের মডেল মুল্যায়ন করি এবং দেখাচ্ছি যে বিশ্বব্যাপী প্রতিযোগিতার স্মৃতির স্মৃতির সাথে য', 'az': 'Təbiətli insan iletişimi nuanca və içində çoxlu modal idir. İnsanların səs, görsel, dil və para dil məlumatlarını işləmək üçün xüsusiyyətli sensorya sahibi var, amma çoxlu modal məlumatlar akışının müəyyən edilməsi üçün çoxlu məlumatlar arasındakı görünüş yaradılır. İnsanların özlərinə müəyyən edildiyi, sosyolojik möhümlüyünə görə, və maşın emulasiyası üçün çətin bir çətinlikdir. Bu, çoxlu modal işarələrin dəyişiklik və ifadə edilən müxtəlif müxtəlifliyinə görə. Sonrakı "End-to-End Memory Networks" və bağlı işlərin empirik başarısından təşkil edilmişdir. Biz çoxlu çəkilən analizi dəyişdirilməsi üzərində paylaşılan daşarı yaddaşları ilə təşkil edilmişik. Biz modellərimizi çox böyük çoxlu modal veri qurularında değerləşdiririk və dünya müxtəlif məlumatı ilə qeyd edilmiş yaddaşların yenilənməsi mümkün olaraq emosyon tanımasını təşkil edir.', 'cs': 'Přirozená lidská komunikace je nuancovaná a z podstaty multimodální. Lidé disponují specializovanou senzorií pro zpracování vokálních, vizuálních a lingvistických a paralingvistických informací, ale tvoří složitě splynutý vnímek multimodálního datového toku, aby poskytl holistickou reprezentaci. Analýza emočního obsahu v osobní komunikaci je kognitivním úkolem, na který jsou lidé vzhledem ke svému sociologickému významu zvláště naladěni, a představuje pro strojovou emulaci obtížnou výzvu kvůli jemnosti a expresivní variabilitě crossmodálních signálů. Inspirováni empirickým úspěchem nedávných tzv. End-to-End paměťových sítí a souvisejících prací navrhujeme přístup založený na rekurzivní multi-pozornosti se sdílenou externí pamětí aktualizovanou v rámci několika gated iterací analýzy. Hodnotíme náš model napříč několika velkými multimodálními datovými sadami a ukazujeme, že globální kontextualizovaná paměť s uzavřenou aktualizací paměti může efektivně dosáhnout rozpoznání emocí.', 'am': 'ባሕላዊ የሰው ግንኙነት ብዙዎች ተቋርጦአል፡፡ ሰዎች የድምፅ፣ ዓይነት፣ ቋንቋ እና የቋንቋዊ መረጃዎችን ለመሥራት የተለየ ስsensoria ይኖራሉ፤ ነገር ግን የተቀደሰ መልዕክት ለመስጠት በብዙ-ሞዴል ዳታ ፈሳሾችን የሚያስፈልገውን ግልፅ ይሠራሉ፡፡ አካባቢ ማኅበራዊ ግንኙነት ለመቀላቀል የሚደረገው የስህተት ማህበራዊ ግንኙነት፣ ማኅበራዊ ግንኙነት በተመሳሳይ እና የመኪና አካባቢ ግንኙነት በተቃወመ እና በክፍለ መልዕክት የተለየ ጥላቻ ነው፡፡ በአሁኑ ጊዜ በተባለው የመጨረሻ-To-End-To-End Memory Network እና በሚያስተማሩበት ሥራ ላይ በተካፈለ የውጭ ማስታወስ በተካፈለ በርካታ በተለያዩ ተሳታፊ አካላት በማሳመር ላይ የተመሳሰለውን የውጭ ማስታወሻ በመጠቀም አቅራቢያ እናስባለን፡፡ ሞዴላዎቻችንን በብዙ ብዙዎች በሞዴል ዳታዎችን እናሳውቃለን፣ የተጠቃሚ ማስታሰቢያ ማሳሰቢያ በተደረገ ማስታወስ የስብሰባውን ማውቀት በጥቅም እንዲያገኝ እናሳያቸዋለን፡፡', 'ca': "La comunicació humana natural està nuansada i inherentment multi modal. Els humans tenen sensoris especialitzats per processar informació vocal, visual, lingüística i paralingüística, però formen una percepció complexament fusionada del flux de dades multimodals per proporcionar una representació holística. L'anàlisi del contingut emocional en la comunicació cara a cara és una tasca cognitiva a la que els humans estan particularment afectats, dada la seva importància sociològica, i representa un difícil repte per la emulació de màquines degut a la subtilitat i la variabilitat expressiva de les indicacions transmodals. Inspirat per l'èxit empíric de les recents anomenades xarxes de memòria final a final i treballs relacionats, proposem un enfocament basat en una multiatenció recursiva amb una memòria externa compartida actualitzada a través de múltiples iteracions d'an àlisi. Evaluam el nostre model a través de diversos grans conjunts de dades multimodals i demostrem que la memòria contextualitzada global amb una actualització de la memòria portada pot aconseguir efectivament el reconeixement emocional.", 'fi': 'Luonnollinen ihmisen viestintä on monivivahteista ja luonnostaan multimodaalista. Ihmisillä on erikoistunut sensorio äänen, visuaalisen, kielellisen ja parakielellisen tiedon käsittelyyn, mutta ne muodostavat monimutkaisen käsityksen multimodaalisesta datavirrasta tarjotakseen kokonaisvaltaisen edustuksen. Emotionaalisen sisällön analysointi kasvokkain tapahtuvassa viestinnässä on kognitiivinen tehtävä, johon ihmiset ovat erityisen sopusoinnussa sosiologisen merkityksensä vuoksi, ja se asettaa vaikean haasteen koneemulaatiolle, koska multimodaalit vihjeet ovat hienovaraisia ja ilmeikkäitä. Äskettäisten ns. end-to-end-muistiverkkojen ja niihin liittyvien töiden empiirisen menestyksen innoittamana ehdotamme lähestymistapaa, joka perustuu rekursiiviseen monihuomioon jaetulla ulkoisella muistilla, joka päivitetään useiden suljettujen analyysiiteraatioiden kautta. Arvioimme malliamme useissa suurissa multimodaalisissa tietosarjoissa ja osoitamme, että globaali kontekstualisoitu muisti gated memory -päivityksellä voi tehokkaasti tunnistaa tunteet.', 'et': 'Loomulik inimese suhtlus on nüanssidega ja olemuslikult mitmeliigiline. Inimestel on spetsialiseerunud sensooria hääle-, visuaalse, keelelise ja parakeelelise teabe töötlemiseks, kuid moodustavad keeruliselt ühendatud taju multimodaalsest andmevoost, et pakkuda terviklikku esitust. Emotsionaalse sisu analüüs näost-näkku suhtluses on kognitiivne ülesanne, millega inimesed on eriti häälestatud, arvestades selle sotsioloogilist tähtsust, ning kujutab endast keerulist väljakutset masinaemulatsioonile, kuna multimodaalsed vihjed on peened ja väljendusväärsed. Inspireerituna hiljutiste nn otsast otsani mäluvõrkude ja nendega seotud tööde empiirilisest edust, pakume välja lähenemisviisi, mis põhineb rekursiivsel multitähelepanul jagatud välise mäluga, mida uuendatakse mitme suletud analüüsiteratsiooni jooksul. Hindame oma mudelit mitmetes suurtes multimodaalsetes andmekogumites ja näitame, et globaalne kontekstiline mälu koos suletud mälu värskendamisega suudab efektiivselt saavutada emotsioonide tuvastamise.', 'bs': 'Prirodna ljudska komunikacija je nuancirana i inherentno multimodalna. Ljudi posjeduju specijalizovanu senzoriju za obrađivanje glasova, vizualnih i jezičkih informacija i para-jezičkih informacija, ali formiraju intrikalno zajedničku percepciju multimodalnog podataka kako bi pružili holističku predstavu. Analiza emocionalnog sadržaja u komunikaciji licem na lice je kognitivan zadatak kojim se ljudi posebno privlače, s obzirom na sociološku važnost, i predstavlja težak izazov za emulaciju mašine zbog suptilnosti i izrazivne varijabilnosti cross-modalnih znakova. Inspirirani empiričkim uspjehom nedavnih takozvanih mreža End-to-End Memory i povezanih radova, predlažemo pristup na temelju rekursivne multipažnje sa zajedničkom spoljnom pamćenju updatiranom preko višestrukih gatovanih iteracija analize. Procjenjujemo naš model preko nekoliko velikih multimodalnih podataka i pokazujemo da globalno kontekstualizovano sjećanje sa aktualizacijom prikupljenih sjećanja može efektivno postići priznanje emocija.', 'jv': 'Komunikasun anyar nglanggar wigatik apakno lan akeh dumadhi multi modal Awak dhèwèké an a luwih perusahaan Sensiti kanggo ngilanggar langgar, iso nggambar, lan kelangan langgar, lan informasi para-langgar, ngregani kuwi nggambar perusahaan langgar sampeyan operasi sing dikarepaké awak dhéwé multi-modal sing dibutuhke bataran kanggo ngilanggar sampeyan kawulé. Ndeleksyon pernganggo alam sing sampeyan nganggo sampeyan karo urip-sampeyan sing nguasai pernganggo kuwi kesempatan sing nggawe nguasai pernganggo kuwi dudu nggawe barang sampeyan sampeyan, lan nambah kuwi susahe sak dudu akeh nguasai pernganggo sampeyan sampeyan karo akeh modal Awak dhéwé sing perbudhakan karo perbudhakan sing gak nyenggawe End-To-End Awak dhéwé éntuk model sing ngenggo akèh akeh gambar dadi multi modal karo iso ngbagian supayano contextual', 'sk': 'Naravna človeška komunikacija je niansirana in po sebi multimodalna. Ljudje imajo specializirano senzorijo za obdelavo vokalnih, vizualnih, jezikovnih in parajezikovnih informacij, vendar tvorijo zapleteno združen percept multimodalnega podatkovnega toka, da zagotovijo celostno reprezentacijo. Analiza čustvene vsebine v komunikaciji iz oči v oči je kognitivna naloga, na katero so ljudje še posebej prilagojeni zaradi njenega sociološkega pomena, in predstavlja težak izziv za strojno emulacijo zaradi subtilnosti in izrazne variabilnosti medmodalnih namigov. V navdihu empiričnega uspeha nedavnih t.i. celovitih pomnilniških omrežij in sorodnih del predlagamo pristop, ki temelji na rekurzivni večpozornosti s skupnim zunanjim pomnilnikom, posodobljenim preko več zaprtih iteracij analize. Naš model ocenjujemo v več velikih multimodalnih naborih podatkov in pokažemo, da lahko globalni kontekstualni pomnilnik s posodobitvijo zaprtega pomnilnika učinkovito doseže prepoznavanje čustev.', 'ha': "An samu maganar mutane na natura da ke cikin multi-modal. Mutane suna da hisori wanda aka ƙayyade wa aikin mutane na sauri, mai gani, da linguistic, da kuma masu fassarar-linguistic, kuma suna sami wani na'ura da aka samu da shi da shirin bayani na danganta masu multi-modal dõmin ya bãyar da wani mai tsari. Ana yi analyi ga maɓallin hisia a kan fuskar-face - wani aikin na kognitive ne wanda mutum ke rufe shi da haske, da kuma ana ƙara wa muhimmin sosialojiki, kuma yana da muhamako mai nauyi wa muhimmin da za'a yi kiyaye wa muhimmin kifushin da aka kiyaye shi da kuma ana buƙata varianin nau'i na fara-faɗi. Inspired by the empirical achievement of the lately called End-To-End Notes Networks and related works, we are forming a move based on retrursive multi-action with a share of memory External data updated over several categories of garnered itements of analyza. Kana ƙaddara misalinmu a kowaci kowace tsarin bayani masu yawa masu motsi, kuma munã nuna cewa, kumbar duniya da kwamfyutan lokacin da za'a iya amfani da sunan aikin lokaci.", 'he': 'התקשורת האנושית הטבעית היא ניאונציה ובטבע מורדואלית. בני אדם יש חושים מיוחדים לעבוד מידע קולי, ויזואלי, ולשפתי, ופאר-שפתי, אך הם נוצרים תחושה מסובכת של זרם הנתונים המולט-מודאלי כדי לספק מייצג הוליסטי. ניתוח התוכן הרגשי בתקשורת פנים אל פנים הוא משימה קוגניטיבית שבן בני אדם מחוברים במיוחד, בהתחשב בחשוב הסוציולוגי שלה, ומעמיד אתגר קשה לאימולציה של מכונות בגלל העדינות והביטוי של סימנים דרך-מודליים. בהשראה מההצלחה האמפרית של רשתות הזיכרון האחרונות שנקראות סוף-לסוף ועבודות קשורות, אנו מציעים גישה מבוססת על תשומת לב רבה מתחזרת עם זיכרון חיצוני משותף מעודכן על ידי שיטות ניתוח רבות שעורים. אנו מעריכים את המודל שלנו בכל כמה קבוצות נתונים רבים-מודליים גדולות ולהראות שזיכרון קונטוקטואלי גלובלי עם עדכון זיכרון שער יכול להשיג בעובדה זיהוי רגשות.', 'bo': 'སྤྱིར་བཏང་གི་མི་འབྲེལ་མཐུད་དེ་ལ་རྒྱུན་ལྡན་དང་ནང་འདྲེན་པའི་ཐབས་ལམ་སྣ་མང་པོ་ཞིག་ཡིན། Humans have specialized sensoria for processing vocal, visual, and linguistic, and para-linguistic information, but form an intricately fused perception of the multi-modal data stream to provide a holistic representation. རང་ཉིད་ཀྱི་སྤྱི་ཚོགས་དང་གདོང་རིས་འབྲེལ་བའི་ནང་དོན་ཡིག་གི་དབྱེ་ཞིབ་ནི་མི་རྣམས་ལས་རྟོགས་པའི་བྱ་སྤྱོད་ཞིག་ཡིན་པས་རང་ཉིད་ཀྱི་སྤྱི་ཚོགས་འབྲེལ་གལ་ཅན་ཡོད་པ་ Inspired by the empirical success of recent so-called End-To-End Memory Networks and related works, we propose an approach based on recursive multi-attention with a shared external memory updated over multiple gated iterations of analysis. ང་ཚོའི་མིག'}
{'en': 'Using Sparse Semantic Embeddings Learned from Multimodal Text and Image Data to Model Human Conceptual Knowledge', 'ar': 'استخدام الزخارف الدلالية المتفرقة المستفادة من بيانات النص والصورة متعددة الوسائط لنمذجة المعرفة المفاهيمية البشرية', 'fr': "Utilisation d'intégrations sémantiques éparses apprises à partir de données textuelles et d'images multimodales pour modéliser les connaissances conceptuelles humaines", 'pt': 'Usando Embeddings Semânticos Esparsos Aprendidos de Texto Multimodal e Dados de Imagem para Modelar o Conhecimento Conceitual Humano', 'es': 'Uso de incrustaciones semánticas dispersas aprendidas de datos de texto e imágenes multimodales para modelar el conocimiento conceptual humano', 'ja': 'マルチモーダルテキストと画像データから学んだまばらなセマンティック埋め込みを使用して、人間の概念的知識をモデル化する', 'hi': 'मॉडल मानव वैचारिक ज्ञान के लिए मल्टीमॉडल टेक्स्ट और छवि डेटा से सीखे गए विरल सिमेंटिक एम्बेडिंग का उपयोग करना', 'zh': '用从多模态文本及图形数中学至疏语义嵌以拟人名', 'ru': 'Использование редких семантических вложений, извлеченных из мультимодальных текстовых и графических данных, для моделирования концептуальных знаний человека', 'ga': 'Leabú Séimeantach Gann a Úsáid a Foghlaimíodh as Téacs Ilmhódach agus Sonraí Íomhánna chun Eolas Coincheapúil Daonna a Shamhaltú', 'ka': 'მრავალმოდიალური ტექსტიდან და გამოსახულების მონაცემების მოდელი ადამიანის კონუტეუალური ცნობიერების მოდულისთვის გამოყენება', 'hu': 'A multimodális szöveg- és képadatokból tanult szemantikus beágyazások használata az emberi fogalmi tudás modellezésére', 'el': 'Χρήση σπανιών σημασιολογικών ενσωματώσεων που μαθαίνονται από τα πολυμodale δεδομένα κειμένου και εικόνας για να μοντελοποιήσουν την ανθρώπινη εννοιολογική γνώση', 'it': 'Utilizzo di incorporazioni semantiche sparse apprese dai dati di testo e immagine multimodali per modellare la conoscenza concettuale umana', 'kk': 'КөпModal мәтін және кескіндер деректерін адамдардың концептуалды білім үлгісіне ұқсас білу үлгісін қолдану', 'mk': 'Користење мали семантични вградувања научени од мултимодилни текстови и слични податоци до модел на човечко концептуално знаење', 'lt': 'Iš daugiarūšio teksto ir vaizdo duomenų įgytų nedidelių Semantinių įrangų naudojimas žmogaus koncepcinių žinių modeliui', 'ml': 'Multimodal Text and Image Data from Model Human Conceptual Knowledge', 'ms': 'Menggunakan Embedding Semantik Terkadang Dipelajari Dari Data Teks dan Imej Berberbilang ke Model Pengetahuan Konseptual Manusia', 'mn': 'Sparse Semantic Embeddings Learned from Multimodal Text and Image Data to Model Human Conceptual Knowledge', 'mt': 'L-użu ta’ Embeddings Semantiċi Mgħallma minn Dejta Multimodali tat-Test u l-Immaġni għall-Mudell ta’ Għarfien Kunċettwali tal-Bniedem', 'no': 'Bruk mellomromsemantiske innbygging lært frå multimodal tekst og biletdata til modell menneskelige konseptuelle kjenning', 'pl': 'Wykorzystanie oszczędnych osadzeń semantycznych uczonych z multimodalnych danych tekstowych i obrazowych do modelowania wiedzy koncepcyjnej człowieka', 'ro': 'Utilizarea încorporărilor semantice rare învățate din date multimodale de text și imagine pentru a modela cunoștințele conceptuale umane', 'sr': 'Koristeći semantičke integracije iz multimodalnog teksta i podataka slika do modela ljudske konceptualne znanja', 'si': 'Name', 'so': 'Isticmaalka Ispanic Semantic Embeddings Learned from Text and Image Data to Model Human Conceptual Knowledge', 'sv': 'Använda sparsamma semantiska inbäddningar som lärts sig från multimodala text- och bilddata för att modellera mänsklig konceptuell kunskap', 'ta': 'பல மாற்று உரையில் இருந்து மற்றும் பிம்பத்தின் தகவல் மாதிரி மனித மாதிரி வாக்கியம் அறிவிப்பை பயன்படுத்துகிறது', 'ur': 'Multimodal Text and Image Data to Model Human Conceptual Knowledge', 'uz': 'Name', 'vi': 'Sử dụng các nền trộn tinh khiết tinh khiết tinh khiết tinh khiết tinh khiết tinh khiết được học từ các phương trình văn bản và dữ liệu ảnh.', 'bg': 'Използване на оскъдни семантични вграждания, научени от мултимодални текстови и изображения данни за моделиране на човешкото концептуално знание', 'hr': 'Koristeći semantičke uključenje iz multimodalnog teksta i podataka slike do modela ljudske konceptualne znanja', 'de': 'Verwendung von sparsamen semantischen Einbettungen, die aus multimodalen Text- und Bilddaten gelernt wurden, um menschliches Konzeptwissen zu modellieren', 'nl': 'Gebruiken van schaarse semantische embeddings geleerd van multimodale tekst- en beeldgegevens om menselijke conceptuele kennis te modelleren', 'id': 'Menggunakan Embeddings Semantik Terbelajar dari Data Teks dan Gambar Multimodal ke Model Pengetahuan Koncepsi Manusia', 'da': 'Brug af sparsomme semantiske indlejringer lært fra multimodale tekst- og billeddata til at modellere menneskelig konceptuel viden', 'ko': '다중모드 텍스트와 이미지 데이터에서 배운 희소한 의미를 사용하여 인류 개념 지식을 모델링하다', 'fa': 'استفاده از استفاده از انجمن\u200cسازی\u200cهای سطح استفاده از متن و داده\u200cهای تصویر به مدل دانش\u200cهای منطقی انسان یاد گرفته شده است', 'sw': 'Kwa kutumia Mazingira ya Kihispania yaliyofundishwa kutoka Makala ya Mitandao na Takwimu ya Picha kwa ajili ya Ujuzi wa Kiasidamu', 'af': 'Name', 'sq': 'Përdorimi i përfshirjeve të shpejta Semantike të mësuara nga teksti multimodal dhe të dhënat e imazhit në modelin e njohurive konceptuale njerëzore', 'hy': 'Օգտագործելով բազմամոդալ տեքստի և պատկերի տվյալներից սովորված փոքրիկ սեմատիկ ներգրավումներ Մոդելի մարդկային գաղափարական գիտելիք', 'tr': 'Ullanyş', 'bn': 'মাল্টিমোডাল লেখা এবং ছবি তথ্য থেকে মোডেল মানব কনসেপ্টুয়াল জ্ঞান থেকে শিক্ষিত স্পের্স সেম্যান্টিক এমবেডিং ব', 'bs': 'Koristeći semantičke integracije iz multimodalnog teksta i podataka slika do modela ljudskog konceptualnog znanja', 'am': 'Using Sparse Semantic Embeddings Learned from Multimodal Text and Image Data to Model Human Conceptual Knowledge', 'ca': 'Utilitzant incorporacions Semàtiques ràpids aprenguts des de dades multimodals de text i imatge al model de coneixement conceptual humà', 'az': '칂oxlu modal Metin v톛 R톛sm M톛lumat캼ndan 캻nsanl캼q Bilm톛si Modelin톛 칐yr톛nildi', 'et': 'Multimodaalsetest teksti- ja pildiandmetest õppitud harvade semantiliste manustamiste kasutamine inimese kontseptuaalsete teadmiste modelleerimiseks', 'fi': 'Multimodaalisista teksti- ja kuvatiedoista opittujen harvojen semanttisten upotusten käyttäminen ihmisen käsitteellisen tiedon mallintamiseen', 'cs': 'Použití řídkých sémantických vložení učených z multimodálních textových a obrazových dat k modelování lidských koncepčních znalostí', 'jv': 'tutorial_basic', 'he': 'השימוש בתכניות סמנטיות נמוכות ללמודות מידע מושג אנושי', 'ha': '@ item Text character set', 'sk': 'Uporaba redkih semantičnih vdelav, naučenih iz multimodalnih besedilnih in slikovnih podatkov, za modeliranje človeškega konceptualnega znanja', 'bo': 'Using Sparse Semantic Embedding Learned from Multimodal Text and Image Data to Model Human Conceptual Knowledge'}
{'en': 'Distributional models provide a convenient way to model ', 'ar': 'توفر النماذج التوزيعية طريقة ملائمة لنمذجة الدلالات باستخدام مساحات التضمين الكثيفة المشتقة من خوارزميات التعلم غير الخاضعة للإشراف. ومع ذلك ، فإن أبعاد مساحات التضمين الكثيفة ليست مصممة لتشبه المعرفة الدلالية البشرية. علاوة على ذلك ، غالبًا ما تُبنى حفلات الزفاف من مصدر واحد للمعلومات (عادةً بيانات نصية) ، على الرغم من أن الأبحاث المعرفية العصبية تشير إلى أن الدلالات مرتبطة ارتباطًا وثيقًا بكل من اللغة والإدراك. في هذا البحث ، نقوم بدمج المعلومات متعددة الوسائط من كل من التمثيلات النصية والقائمة على الصور المشتقة من أحدث نماذج التوزيع لإنتاج متجهات متفرقة وقابلة للتفسير باستخدام التضمين المتناثر المشترك غير السلبي. من خلال التحليلات المتعمقة التي تقارن هذه النماذج المتناثرة ببيانات السلوك والتصوير العصبي المشتقة من الإنسان ، نظهر قدرتها على التنبؤ بالأوصاف اللغوية القابلة للتفسير للمعرفة الدلالية لحقيقة الأرض البشرية.', 'es': 'Los modelos de distribución proporcionan una forma cómoda de modelar la semántica mediante espacios de incrustación densos derivados de algoritmos de aprendizaje no supervisados. Sin embargo, las dimensiones de los espacios densos de incrustación no están diseñadas para parecerse al conocimiento semántico humano. Además, las incorporaciones a menudo se crean a partir de una única fuente de información (normalmente datos de texto), aunque la investigación neurocognitiva sugiere que la semántica está profundamente vinculada tanto al lenguaje como a la percepción. En este artículo, combinamos información multimodal de representaciones de texto e imágenes derivadas de modelos distribucionales de última generación para producir vectores dispersos e interpretables utilizando la incrustación dispersa no negativa conjunta. A través de análisis en profundidad que comparan estos modelos dispersos con datos de neuroimagen y comportamiento derivados de humanos, demostramos su capacidad para predecir descripciones lingüísticas interpretables del conocimiento semántico de la verdad fundamental humana.', 'pt': 'Os modelos distribucionais fornecem uma maneira conveniente de modelar a semântica usando espaços de incorporação densos derivados de algoritmos de aprendizado não supervisionados. No entanto, as dimensões dos espaços de embutimento densos não são projetadas para se assemelhar ao conhecimento semântico humano. Além disso, os embeddings geralmente são construídos a partir de uma única fonte de informação (normalmente dados de texto), embora a pesquisa neurocognitiva sugira que a semântica está profundamente ligada à linguagem e à percepção. Neste artigo, combinamos informações multimodais de representações baseadas em texto e imagens derivadas de modelos de distribuição de última geração para produzir vetores esparsos e interpretáveis usando Joint Non-Negative Sparse Embedding. Por meio de análises aprofundadas comparando esses modelos esparsos com dados comportamentais e de neuroimagem derivados de humanos, demonstramos sua capacidade de prever descrições linguísticas interpretáveis do conhecimento semântico humano de verdade.', 'fr': "Les modèles distributionnels constituent un moyen pratique de modéliser la sémantique à l'aide d'espaces d'intégration denses dérivés d'algorithmes d'apprentissage non supervisés. Cependant, les dimensions des espaces d'intégration denses ne sont pas conçues pour ressembler à la connaissance sémantique humaine. De plus, les intégrations sont souvent construites à partir d'une seule source d'information (généralement des données textuelles), même si les recherches neurocognitives suggèrent que la sémantique est profondément liée au langage et à la perception. Dans cet article, nous combinons des informations multimodales provenant de représentations basées sur le texte et l'image dérivées de modèles de distribution de pointe afin de produire des vecteurs clairsemés et interprétables à l'aide de l'intégration fragmentée non négative conjointe. Grâce à des analyses approfondies comparant ces modèles clairsemés à des données comportementales et de neuroimagerie d'origine humaine, nous démontrons leur capacité à prédire des descriptions linguistiques interprétables de la connaissance sémantique de la vérité de base humaine.", 'ja': '分布モデルは、監視されていない学習アルゴリズムから導出された濃密な埋め込み空間を使用して意味論をモデル化する便利な方法を提供する。しかし、稠密な埋め込み空間の次元は、人間の意味論的知識に似せて設計されていない。さらに、神経認知研究は、意味論が言語と知覚の両方に深く関連していることを示唆しているにもかかわらず、埋め込みはしばしば単一の情報源（典型的にはテキストデータ）から構築される。本稿では，最先端の分布モデルから導出されたテキスト表現と画像ベース表現の両方からのマルチモーダル情報を組み合わせ，関節非負のスパース埋め込みを用いてスパース解釈可能なベクトルを生成する．これらのまばらなモデルを人間由来の行動および神経イメージングデータと比較する詳細な分析を通じて、我々は、人間の真実の意味論的知識の解釈可能な言語学的記述を予測する能力を示します。', 'zh': '分布模形一种用从无监督学算法派生的密集嵌入空间对语义建模的便捷法。 然密嵌空间维度非为人语义计也。 此外嵌常从单一信息源(常以文本数)构之,虽神经识究明语义与言语感知相关。 其在本文,将自文本与图像之多模态信息相合,此先进之分形,以合非负疏嵌生疏,可解向量也。 因深入分析,比之行神经景象,验其占地语义知者能言之。', 'hi': 'वितरण मॉडल unsupervised सीखने एल्गोरिदम से व्युत्पन्न घने एम्बेडिंग रिक्त स्थान का उपयोग कर शब्दार्थ मॉडल करने के लिए एक सुविधाजनक तरीका प्रदान करते हैं। हालांकि, घने एम्बेडिंग रिक्त स्थान के आयामों को मानव शब्दार्थ ज्ञान के समान होने के लिए डिज़ाइन नहीं किया गया है। इसके अलावा, एम्बेडिंग अक्सर जानकारी के एक स्रोत (आमतौर पर पाठ डेटा) से बनाए जाते हैं, भले ही न्यूरोकॉग्निटिव शोध से पता चलता है कि शब्दार्थ भाषा और धारणा दोनों से गहराई से जुड़ा हुआ है। इस पेपर में, हम संयुक्त गैर-नकारात्मक विरल एम्बेडिंग का उपयोग करके विरल, व्याख्यायोग्य वैक्टर का उत्पादन करने के लिए अत्याधुनिक वितरण मॉडल से व्युत्पन्न पाठ और छवि-आधारित अभ्यावेदन दोनों से मल्टीमॉडल जानकारी को जोड़ते हैं। इन विरल मॉडलों की तुलना मानव-व्युत्पन्न व्यवहार और न्यूरोइमेजिंग डेटा से करने वाले गहन विश्लेषणों के माध्यम से, हम मानव भूमि-सत्य शब्दार्थ ज्ञान के व्याख्यायोग्य भाषाई विवरणों की भविष्यवाणी करने की उनकी क्षमता का प्रदर्शन करते हैं।', 'ru': 'Дистрибутивные модели обеспечивают удобный способ моделирования семантики с использованием плотных пространств вложений, полученных из неконтролируемых алгоритмов обучения. Однако размеры плотных пространств вложений не предназначены для того, чтобы напоминать человеческие семантические знания. Более того, вложения часто строятся из одного источника информации (обычно текстовых данных), даже несмотря на то, что нейрокогнитивные исследования предполагают, что семантика глубоко связана как с языком, так и с восприятием. В этой статье мы объединяем мультимодальную информацию из текстовых и графических представлений, полученных из современных дистрибутивных моделей, для получения разреженных, интерпретируемых векторов с использованием совместного неотрицательного разреженного встраивания. Глубоким анализом, сравнивающим эти редкие модели с поведенческими данными человека и данными нейровизуализации, мы демонстрируем их способность предсказывать интерпретируемые лингвистические описания семантических знаний, основанных на истине.', 'ga': 'Soláthraíonn samhlacha dáileacháin bealach áisiúil chun séimeantaic a shamhaltú ag baint úsáide as spásanna dlúth leabaithe a dhíorthaítear ó halgartaim foghlama gan mhaoirseacht. Mar sin féin, níl toisí spásanna dlúth leabaithe deartha le bheith cosúil le heolas séimeantach daonna. Ina theannta sin, is minic go dtógtar leabaithe ó fhoinse amháin faisnéise (sonraí téacs go hiondúil), cé go dtugann taighde néar-chognaíoch le fios go bhfuil nasc domhain ag an tséimeantaic le teanga agus le tuiscint. Sa pháipéar seo, comhcheanglaímid faisnéis ilmhódach ó léiriúcháin téacs-bhunaithe agus íomhá-bhunaithe araon a dhíorthaítear ó mhúnlaí dáileacháin den scoth chun veicteoirí tanaí inmhínithe a tháirgeadh ag baint úsáide as Leabú Comhpháirteach Neamhdhiúltach Gann. Trí mhionanailísí a dhéanann comparáid idir na mionsamhlacha seo agus sonraí iompraíochta agus néaríomhánna díorthaithe ag an duine, léirímid a gcumas cur síos teangeolaíoch inmhínithe ar eolas séimeantach an duine ar an talamh a thuar.', 'el': 'Τα μοντέλα διανομής παρέχουν έναν βολικό τρόπο μοντελοποίησης σημασιολογίας χρησιμοποιώντας πυκνούς χώρους ενσωμάτωσης που προέρχονται από αλγόριθμους μάθησης χωρίς επίβλεψη. Ωστόσο, οι διαστάσεις των πυκνών χώρων ενσωμάτωσης δεν έχουν σχεδιαστεί για να μοιάζουν με ανθρώπινη σημασιολογική γνώση. Επιπλέον, οι ενσωματώσεις συχνά κατασκευάζονται από μια ενιαία πηγή πληροφοριών (συνήθως δεδομένα κειμένου), παρόλο που η νευρογνωστική έρευνα δείχνει ότι η σημασιολογία συνδέεται βαθιά τόσο με τη γλώσσα όσο και με την αντίληψη. Σε αυτή την εργασία, συνδυάζουμε πολυμορφικές πληροφορίες τόσο από αναπαραστάσεις κειμένου όσο και από εικόνες που προέρχονται από σύγχρονα μοντέλα διανομής για να παράγουμε αραιά, ερμηνευτά διανύσματα χρησιμοποιώντας κοινή μη αρνητική ενσωμάτωση σπανιών. Μέσα από εμπεριστατωμένες αναλύσεις που συγκρίνουν αυτά τα σπάνια μοντέλα με δεδομένα συμπεριφοράς και νευροαπεικόνισης που προέρχονται από τον άνθρωπο, καταδεικνύουμε την ικανότητά τους να προβλέπουν ερμηνευτές γλωσσικές περιγραφές της ανθρώπινης σημασιολογικής γνώσης βάσης-αλήθειας.', 'hu': 'Az elosztási modellek kényelmes módot biztosítanak a szemantika modellezésére felügyelet nélküli tanulási algoritmusokból származó sűrű beágyazási terek segítségével. A sűrű beágyazó terek dimenzióit azonban nem úgy tervezték, hogy hasonlítsanak az emberi szemantikai tudásra. Ezenkívül a beágyazások gyakran egyetlen információforrásból (jellemzően szöveges adatokból) épülnek, bár a neurokognitív kutatások arra utalnak, hogy a szemantika mélyen kapcsolódik mind a nyelvhez, mind az észleléshez. Ebben a tanulmányban a legkorszerűbb disztribúciós modellekből származó szöveg- és képalapú reprezentációk multimodális információit kombináljuk, hogy ritka, értelmezhető vektorokat állítsunk elő a Joint Non-Negative Sparse Embedding használatával. Ezeket a ritka modelleket az emberi eredetű viselkedés- és neuroképalkotási adatokkal összehasonlító mélyreható elemzések segítségével bizonyítjuk, hogy képesek az emberi alap-igazság szemantikai ismereteinek értelmezhető nyelvi leírásainak előrejelzésére.', 'ka': 'Name მაგრამ განზომილებები სამყარო სივმანტიკური ცოცხლის განზომილებები არიან განზომილებული ადამიანის სივმანტიკური ცოცხლის განზომილებისთვის. დამატებით, ინფორმაციის ერთი მხოლოდ შექმნილი ინფორმაცია (ტექსტის მონაცემებით), თუმცა ნეიროკონოკონციგური განსწავლება იტყვებს, რომ სმენტიკები ძალიან დაკავშირებული ენ ამ გვერდიში, ჩვენ მულტიმოდიალური ინფორმაცია ტექსტიდან და გამოსახულებიდან გამოიყენებული რესპეცენტაციებიდან გამოიყენებული განსახულების მოდელებიდან გამოიყენებთ, რომლებიც გამოყენება წარმოადგილი, ინტერუქტური მაგალითად განსაზღვრებული ანალიზებით, რომლებიც ამ ნაკლები მოდელების შესაბამისად ადამიანის განსაზღვრებული ქცევის და ნეირომიზაციის მონაცემების შესაბამისად, ჩვენ გამოჩვენებთ მათი შესაძლებლობა გადავიწყენოთ ად', 'it': "I modelli distributivi forniscono un modo conveniente per modellare la semantica utilizzando densi spazi di embedding derivati da algoritmi di apprendimento non supervisionati. Tuttavia, le dimensioni degli spazi densi di incorporazione non sono progettate per assomigliare alla conoscenza semantica umana. Inoltre, gli embedding sono spesso costruiti da un'unica fonte di informazioni (tipicamente dati testuali), anche se la ricerca neurocognitiva suggerisce che la semantica è profondamente legata sia al linguaggio che alla percezione. In questo articolo, combiniamo informazioni multimodali provenienti sia da rappresentazioni testuali che da immagini derivate da modelli distributivi all'avanguardia per produrre vettori sparsi e interpretabili utilizzando Joint Non-Negative Sparse Embedding. Attraverso analisi approfondite che confrontano questi modelli scarsi con i dati comportamentali e neuroimaging derivati dall'uomo, dimostriamo la loro capacità di prevedere descrizioni linguistiche interpretabili della conoscenza semantica della verità di base umana.", 'kk': 'Үлестірілген үлгілер сабаттау алгоритмдерден шығарылмаған тұрақты ендіру орындарын қолданатын semantics үлгілерін үлгілеу мүмкіндігін келтіреді. Бірақ тұтық ендіру бос орындарының өлшемдері адамның семантикалық біліміне сәйкес келмейді. Сонымен қатар, ендіру көбірек бір мәліметтің көзінен құрылады (әдетте мәтін деректері), нейрокопиталық зерттеулердің семантикалық тілдер мен түсініктердің екеуіне тең байланысты деп ойлайды Бұл қағазда біз мәтін мен кескіндерді негіздеген кескіндерден бірнеше мәліметті біріктіреміз. Бірлескен негізі емес орын ендіру үшін күй- жай дистрибутив үлгілерінен шығарылған көп мәліметті біріктіреміз Адамдық тәртіпке және нейрокездеу деректеріне салыстыратын бұл кеңістік моделдерді анализ арқылы, адамдардың тәртіпке және земінің семантикалық білімінің түсінікті лингвистикалық түсініктерін көрсету мү', 'mk': 'Distributional models provide a convenient way to model semantics using dense embedding spaces derived from unsupervised learning algorithms.  Сепак, димензиите на густите вселенски простори не се дизајнирани за да личат на човечко семантично знаење. Покрај тоа, вградувањата честопати се градат од еден извор на информации (обично текстови податоци), иако неврокоњитивните истражувања покажуваат дека семантиката е длабоко поврзана со јазикот и перцепцијата. Во овој документ, комбинираме мултимодилни информации од текстовите и сличните претставувања кои се извлечени од најсовремените дистрибуционални модели за да произведуваме мали, интерпретабилни вектори користејќи заедничко ненегативно мало вградување. Преку длабоки анализи во кои се споредуваат овие ретки модели со податоците за однесување и невросликање од човек, ние ја демонстрираме нивната способност да предвидат интерпретабилни лингвистички описи на семантичното знаење од човечката земја-вистина.', 'lt': 'Pasiskirstymo modeliai yra patogus būdas modeliuoti semantiką naudojant tankias įdėjimo erdves, gautas iš nepastebimų mokymosi algoritmų. Tačiau tankių įdėjimo erdvių matmenys nėra suprojektuoti taip, kad būtų panašūs į žmogaus semantines žinias. Moreover, embeddings are often built from a single source of information (typically text data), even though neurocognitive research suggests that semantics is deeply linked to both language and perception.  Šiame dokumente sujungiame daugiarūšio pobūdžio informaciją, gautą tiek iš teksto, tiek iš vaizdo, gautą iš moderniausių paskirstymo modelių, siekiant sukurti nedidelius, aiškinamuosius vektorius naudojant bendrą nedidelį nedidelį įdėjimą. Atliekant nuodugnias analizes, palyginančias šiuos retais modelius su žmogaus sukeltais elgesio ir neurovaizdo duomenimis, įrodome jų gebėjimą nuspėti aiškinamus žmogaus žeminės tiesos semantinių žinių kalbinius aprašymus.', 'ms': 'Model distribusi menyediakan cara yang sesuai untuk model semantik menggunakan ruang penyambungan padat yang berasal dari algoritma pembelajaran tidak diawasi. Namun, dimensi ruang penerbangan yang padat tidak direka untuk mirip pengetahuan semantik manusia. Selain itu, penerbangan sering dibina dari sumber maklumat tunggal (biasanya data teks), walaupun kajian neurokognitif menunjukkan bahawa semantik sangat terhubung dengan kedua-dua bahasa dan perasaan. Dalam kertas ini, kita menggabungkan maklumat multimodal dari kedua-dua perwakilan berdasarkan teks dan imej yang berasal dari model distribusi state-of-the-art untuk menghasilkan vektor yang jarang, boleh diterjemahkan menggunakan Persamaan Non-Negative Sparse Embedding. Melalui analisis dalam-dalam yang membandingkan model kecil ini dengan data perilaku dan imaj saraf yang berasal dari manusia, kami menunjukkan kemampuan mereka untuk meramalkan deskripsi bahasa yang boleh diterangkan mengenai pengetahuan semantik dasar-kebenaran manusia.', 'mt': 'Il-mudelli ta’ distribuzzjoni jipprovdu mod konvenjenti biex tiġi mudellata s-semantika bl-użu ta’ spazji ta’ inkorporazzjoni densi derivati minn algoritmi ta’ tagħlim mhux sorveljati. Madankollu, id-dimensjonijiet ta’ spazji densi ta’ inkorporazzjoni mhumiex iddisinjati biex jixbħu l-għarfien semantiku uman. Barra minn hekk, l-inkorporazzjonijiet ta’ spiss jinbnew minn sors wieħed ta’ informazzjoni (tipikament dejta tat-test), anke jekk ir-riċerka newrokonjittiva tissuġġerixxi li s-semantika hija marbuta sew mal-lingwa kif ukoll mal-perċezzjoni. F’dan id-dokument, aħna ngħaqdu informazzjoni multimodali kemm minn rappreżentazzjonijiet ibbażati fuq it-test kif ukoll minn rappreżentazzjonijiet ibbażati fuq l-immaġni derivati minn mudelli ta’ distribuzzjoni l-aktar avvanzati biex jipproduċu vetturi rari u interpretabbli bl-użu ta’ Embedding Sparse Konġunt Mhux Negattiv. Permezz ta’ analiżi fil-fond li tqabblu dawn il-mudelli rari mad-dejta dwar l-imġiba u n-newro-immaġini derivata mill-bniedem, nistgħu nippruvaw il-kapaċità tagħhom li jipprevedu deskrizzjonijiet lingwistiċi interpretabbli tal-għarfien semantiku tal-bniedem tal-verità tal-art.', 'ml': 'വിതരണ മോഡലുകള്\u200d സേമാന്റിക്സിന്റെ മാതൃകയില്\u200d നിന്നും സൂക്ഷിക്കപ്പെടാത്ത ആല്\u200dഗോരിത്മുകളില്\u200d നിന്നും ലഭ്യമായ സ്പെയിന്\u200d എന്നിട്ടും മനുഷ്യന്റെ സെമാന്റിക്ക് അറിവിനെ തുല്യമാക്കാനുള്ള ഇടങ്ങളുടെ ദൃഷ്ടാന്തമല്ല. വിവരങ്ങളുടെ വിവരങ്ങളില്\u200d നിന്നും പ്രാവശ്യം വിവരങ്ങള്\u200d ഉണ്ടാക്കുന്നു ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d വിവരം കൂട്ടിക്കൊണ്ടിരിക്കുന്നു. യോണ്ട് നെഗേറ്റീവ് അല്ലാത്ത സ്പേഴ്സ് എംബെഡിങ്ങ് ഉപയോഗിക്കുന്നതിനായി സ്പാസ് സ്പാര്\u200dസ്  ആഴത്തിലുള്ള അന്വേഷണങ്ങളിലൂടെ ഈ സ്പെസ്സ് മോഡലുകള്\u200d മനുഷ്യരുടെ പ്രകൃതിയിലുള്ള സ്വഭാവിതവും ന്യൂറോയിപ്പിങ്ങിങ്ങ് ഡേറ്റാകളോടൊപ്പം ചേര്\u200dക്കു', 'no': 'Name Men dimensjonane av tett innbyggingsmellomrom er ikkje utforma for å tilpassa menneskelig semantisk kunnskap. I tillegg er innbygginga ofte bygd frå ei enkelt kjelde av informasjon (vanlegvis tekstdata), selv om neurokognitivt forskning tyder på at semantikk er dypt lenka til både språk og oppfatning. I denne papiret kombinerer vi multimodal informasjon frå både tekstbaserte og biletbaserte representasjonar ut frå distribusjonsmodeller for å produsere sparse, tolkbare vektorar med Joint Non-Negative Sparse Embedding. Gjennom dybde analyser som samanliknar desse sparse modelane med menneskelige atferdsdata og neuroimagineringsdata, viser vi at dei kan foregå tolkbare språkstiske skildringar av semantisk kunnskap av menneskelige grunnsannhet.', 'mn': 'Тайлбарлалтын загварууд суралцахгүй алгоритмыг ашиглан зэрэгцээ загварын загварын загварын загварын загвар хангалттай болгодог. Гэвч хүн төрөлхтний шинжлэх ухаан шиг төсөөлөх жингийн орон зайн хэмжээсүүд биш. Мөн мэдээллийн нэг эх үүсвэрээс (ихэвчлэн текст өгөгдлийн мэдээлэл), мэдрэлийн мэдээллийн судалгаагаар семантик нь хэл болон ойлголтын хоорондоо гүн зэрэг холбоотой гэсэн үг юм. Энэ цаасан дээр бид олон моделийн мэдээллийг хоёуланг нь хуваарьсан хуваарьсан загвараас гарч ирсэн зураг болон зураг дээр суурилсан илэрхийлэл хоёуланг нийлүүлнэ. Нэгдсэн сөрөг биш сөрөг орон загвар нэмж ашиглан жижиг, толгойлж болох Гүн гүнзгий судалгаагаар эдгээр жижиг загваруудыг хүн төрөлхтний зан чанартай харьцуулахад бид хүн төрөлхтний үйл явдал болон сэтгэл санааны мэдээллээр илэрхийлж чаддаг хэлний хэлний тодорхойлолтыг үзүүлдэг.', 'pl': 'Modele dystrybucyjne zapewniają wygodny sposób modelowania semantyki przy użyciu gęstych przestrzeni osadzania pochodzących z algorytmów uczenia się bez nadzoru. Jednak wymiary gęstych przestrzeni osadzania nie są zaprojektowane tak, aby przypominały ludzką wiedzę semantyczną. Ponadto osadzenia są często zbudowane z jednego źródła informacji (zazwyczaj danych tekstowych), chociaż badania neurokognitywne sugerują, że semantyka jest głęboko powiązana zarówno z językiem, jak i percepcją. W niniejszym artykule łączymy multimodalne informacje z reprezentacji tekstowych i obrazowych pochodzące z najnowocześniejszych modeli dystrybucyjnych w celu wytworzenia rzadkich, interpretowalnych wektorów przy użyciu Joint Non-Negative Sparse Embedding. Poprzez dogłębne analizy porównujące te rzadkie modele z danymi behawioralnymi i neuroobrazowymi pochodzącymi od człowieka, wykazujemy ich zdolność do przewidywania interpretowalnych opisów językowych ludzkiej wiedzy semantycznej podstawowej prawdy.', 'sr': 'Distribucioni modeli pružaju prikladan naèin da modeliraju semantike koristeći guste ugrađene prostore iz neodređenih algoritma učenja. Međutim, dimenzije gustih prostora za ugrađenje nisu dizajnirane kako bi slične ljudskim semantičkim znanjem. Osim toga, ugrađenje se često izgradi iz jednog izvora informacija (obično tekstualnih podataka), iako neurokognitivno istraživanje ukazuje na to da je semantika duboko povezana sa jezikom i percepcijom. U ovom papiru, kombinujemo multimodalne informacije iz teksta i predstavljanja na slikama koji se nalaze iz modela distribucije umjetnosti kako bi proizveli rezervne, interpretabilne vektore koristeći zajedničko ne-negativno uključenje prostora. Kroz duboke analize u usporedbi ovih rezervnih modela sa ljudskim ponašanjem i neuroimaginiranim podacima, pokazujemo njihovu sposobnost da predviđaju interpretabilne jezičke opise semantičkih znanja ljudskih zemaljskih istina.', 'ro': 'Modelele distribuționale oferă o modalitate convenabilă de a modela semantica folosind spații dense de încorporare derivate din algoritmi de învățare nesupravegheați. Cu toate acestea, dimensiunile spațiilor dense de încorporare nu sunt concepute să seamănă cu cunoștințele semantice umane. În plus, încorporările sunt adesea construite dintr-o singură sursă de informații (de obicei date text), chiar dacă cercetările neurocognitive sugerează că semantica este profund legată atât de limbaj, cât și de percepție. În această lucrare, combinăm informații multimodale din reprezentări bazate pe text și imagini derivate din modele distribuționale de ultimă generație pentru a produce vectori slabi, interpretabili folosind Joint Non-Negative Sparse Embedding. Prin analize aprofundate care compară aceste modele rare cu datele comportamentale și neuroimagistice derivate din om, demonstrăm capacitatea acestora de a prezice descrieri lingvistice interpretabile ale cunoștințelor semantice ale solului uman-adevăr.', 'si': 'විදුලි මොඩේල් සෙමැන්ටික්ස් මොඩේල් කරන්න පුළුවන් විදියට ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරනවා සෙමැන්ටික්ස් විදි නමුත්, මිනිස්සුන්ගේ සාමාන්තික දැනගැනීමට සිද්ධ වෙන්න බැහැ. ඉතින්, ඇම්බෙන්ඩින්ග් සාමාන්\u200dය විදියට තොරතුරු ස්ථානයක් නිර්මාණය කරනවා (සාමාන්\u200dය විදියටම පාළුවක් තොරතුරු), නිර්මාණ මේ පැත්තේ, අපි පැත්ත සහ පින්තූරය අධිරූපය පින්තූරණයෙන් ගොඩක් මොඩල් සම්බන්ධ කරන්න පුළුවන් පින්තූරණය සඳහා පින්තූරණය සඳහා පින් අපි මිනිස්සුන්ගේ ප්\u200dරතිචාරය සහ න්\u200dයුරෝමේජ් දත්ත සඳහා මේවා ප්\u200dරතිචාරයක් විශ්ලේෂණය කරන්න පුළුවන් භාෂාවික විශ්ලේෂණය ප්\u200dරතිච', 'sv': 'Distributionsmodeller ger ett bekvämt sätt att modellera semantik med hjälp av täta inbäddningsområden som härrör från oövervakade inlärningsalgoritmer. Dimensionerna av täta inbäddningsutrymmen är dock inte utformade för att likna mänsklig semantisk kunskap. Dessutom bygger inbäddningar ofta från en enda informationskälla (vanligtvis textdata), även om neurokognitiv forskning tyder på att semantik är djupt kopplad till både språk och perception. I denna uppsats kombinerar vi multimodal information från både text- och bildbaserade representationer härledda från state-of-the-art distributionsmodeller för att producera glesa, tolkningsbara vektorer med Joint Non-Negative Sparse Embedding. Genom djupgående analyser som jämför dessa glesa modeller med mänskligt härledda beteendedata och neuroavbildningsdata visar vi deras förmåga att förutsäga tolkningsbara språkliga beskrivningar av mänsklig grundsanning semantisk kunskap.', 'so': 'Tusaalooyinka qaybsiga waxay sameyn karaan qaab sax ah oo lagu isticmaali karo meelo ay ka soo baxaan qoraalka waxbarashada oo aan la ilaalinayn. Si kastaba ha ahaatee dareemaha meelaha qarsoon ee daboola looma sameeyo si loo ekaysiiyo aqoonta hoose ee dadka. Sidoo kale qalabka waxaa inta badan laga dhisaa macluumaad kaliya (sida caadiga ah macluumaadka qoraalka), xitaa haddii cilmiga neurogniyadu ay ka muuqato in semantika aad ugu xiran luqada iyo aragtida. Qoraalkan waxaan ka soo ururinaa macluumaad badan oo ku saabsan qoraal iyo sawir, kaas oo ka soo saaray noocyada qaybsiga farshaxanka, si aan u soo saarno hiwaayad, turjubaan wadooyin lagu turjumo isticmaalaya qalabka Joint-Non-Negative Sparse. Analyadaas mool dheer oo u barbarooranaya modelladan dabeecada dadka oo la soo saaray dabeecada iyo sawirada neurosawirada, waxaynu muujinnaa awooddooda ay ku hor sheegi karto qoraalka afka ah ee aqoonta runta ah ee dadka.', 'ta': 'பங்கீட்டு மாதிரிகள் பாதுகாப்பாக்கப்படாத கல்வி வரிப்புகளிலிருந்து கொண்டுள்ள தூரமான இடைவெளிகளை பயன்படுத்தி மாதிரியும ஆயினும், கனமான இடைவெளிகளின் பரிமாணங்கள் மனித ஒப்பிடுவதற்கு வடிவமைக்கப்படவில்லை. மேலும், பொதுவாக தகவல் மூலத்திலிருந்து உள்ளிடப்பட்டுள்ளது (பொதுவாக உரை தகவல்கள்) பெரும்பாலாகவே உருவாக்கப்படுகிறது, ஆனாலும் புதிய அறிவிப்பு  இந்த காக்கத்தில், நாம் உரையில் இருந்து மற்றும் பிம்பத்திற்கு அடிப்படையான பிம்பங்களில் இருந்தும் உரையிலிருந்தும் பல்வேறு தகவல்களை ஒன்று சேர்க்கிறோ Through in-depth analyses comparing these sparse models to human-derived behavioural and neuroimaging data, we demonstrate their ability to predict interpretable linguistic descriptions of human ground-truth semantic knowledge.', 'ur': 'تقسیم نمڈلوں نے مہمانتیک کی مدل کے لئے ایک مناسب طریقہ پیش کرتا ہے کہ مہمانتیک مہمانتیک مہمانتیک کے مطابق مہمانتیک مہمانتیک مہمانتیک مہمانتیک مہمانتیک مہمانتیک مہمانتیک مہ However, the dimensions of dense embedding spaces are not designed to reset human semantic knowledge. اور اگرچہ نیروشناسی تحقیقات یہ معلوم ہے کہ سیمانٹیکس دونوں زبانوں اور احساساتوں کے ساتھ عمیق سے متصلہ ہے۔ اس کاغذ میں ہم مختلف معلومات کو متن اور تصویر کی بنیادی معلومات سے ترکیب کرتے ہیں جو استیٹ کی تقسیم الٹ موڈل سے آئے ہیں کہ اسپرس پیدا کریں، مفصل کے قابل تفصیل ویکتوروں کو جوٹ غیر منفی اسپرس انڈینگ کے مطابق استعمال کریں۔ عمیق تحقیقات کے ذریعہ سے یہ مہربانی موڈل انسان کے پیدا ہوئے رفتار اور نیروتصویر ڈاٹے کے مطابق مطابق ان کی قابلیت کو دکھاتی ہے کہ انسان کی زمین-حقیقت کے سیمنٹی علم کی تعبیر کے قابل تعبیر کرسکیں۔', 'uz': "Tarqatish modellari haqida saqlab boʻlmaydi algorithlardan foydalanilgan chegara boʻsh joylarni ishlatish mumkin. Lekin, chegara bo'lgan joylarning chegaralari inson semantik bilimni o'xshash uchun yaratilmaydi. Ko'pchiliklar bir necha maʼlumot manbasiga (oddiy matn maʼlumotidan) yaratiladi, ammo neyronkognitiv talablar esa, semantika tilda va fikrlarning ikkita bog'liq bo'lganligini anglatadi. Ushbu qogʻozda biz bir necha multimodal maʼlumotni birlashtiramiz, rasm va rasm asosidagi tarjima modellardan bir xil taʼlumotni birlashtiramiz. Joriy Negativ Ispan Orollaridan foydalanish uchun saqlash, tarjima qilinadigan vectorlar yaratish uchun. Biz inson tabiiy va neyron rasmlar maʼlumotiga o'xshash o'xshash modellarni qo'shish mumkin, biz inson asbob-asosiy semantik ta'sirini o'rganish imkoniyatini o'rganish imkoniyatini ko'rsatdik.", 'vi': 'Các mô hình chia sẻ cung cấp một cách tiện lợi để mô phỏng ngữ pháp bằng cách sử dụng các khoảng đất gắn bó mật tạo từ thuật to án học không giám sát. Tuy nhiên, kích thước của khoảng đất gắn bó đặc biệt không được thiết kế để giống với kiến thức ngữ pháp của loài người. Những sự ghép nối thường được xây dựng từ một nguồn thông tin duy nhất (thường là dữ liệu văn bản) mặc dù nghiên cứu về nhận thức thần kinh cho thấy ngữ pháp liên quan sâu sắc đến ngôn ngữ và nhận thức. Trong tờ giấy này, chúng tôi kết hợp thông tin đa phương từ cả văn bản và các biểu tượng hình ảnh lấy từ các mô hình phân phối thời đại hiện đại để sản xuất tỉ lệ, dịch chuyển thoáng qua, sử dụng tham nhũng Không phải tiêu cực. Qua các phân tích sâu sắc so sánh những mô hình hẹp này với dữ liệu hành vi và thần kinh của con người, chúng tôi cho thấy khả năng dự đoán miêu tả ngôn ngữ ngữ của kiến-địa-chân-của con người.', 'nl': 'Distributionele modellen bieden een handige manier om semantiek te modelleren met behulp van dichte insluitingsruimtes die zijn afgeleid van niet-begeleide leeralgoritmen. De dimensies van dichte insluitruimten zijn echter niet ontworpen om op menselijke semantische kennis te lijken. Bovendien worden embeddings vaak opgebouwd uit één enkele bron van informatie (meestal tekstgegevens), hoewel neurocognitief onderzoek suggereert dat semantiek nauw verbonden is met zowel taal als perceptie. In dit artikel combineren we multimodale informatie van zowel tekst- als beeldgebaseerde representaties afgeleid van state-of-the-art distributiemodellen om schaarse, interpreteerbare vectoren te produceren met behulp van Joint Non-Negative Sparse Embedding. Door diepgaande analyses die deze schaarse modellen vergelijken met menselijke gedrags- en neuroimaging-gegevens, demonstreren we hun vermogen om interpreteerbare linguïstische beschrijvingen van menselijke grond-waarheid semantische kennis te voorspellen.', 'hr': 'Distribucioni modeli pružaju prikladan način za model semantika koristeći guste prostore ugrađene iz neodređenih algoritma učenja. Međutim, dimenzije gustih ugrađenih prostora nisu dizajnirane kako bi slične ljudskim semantičkim znanjem. Osim toga, ugrađenje se često izgrađuje iz jednog izvora informacija (obično tekstualnih podataka), iako neurokognitivno istraživanje sugerira da je semantika duboko povezana s jezikom i percepcijom. U ovom papiru kombiniramo multimodalne informacije iz teksta i predstavljanja na temelju slike iz modela distribucije umjetnosti kako bi proizveli rezervne, interpretabilne vektore koristeći zajedničko ne-negativno uključenje prostora. Kroz duboke analize uspoređujući te rezervne modele s ljudskim ponašanjem i neuroimaginirajućim podacima, pokazujemo njihovu sposobnost predvidjeti interpretabilne jezičke opise semantičkih znanja ljudskih zemaljskih istina.', 'da': 'Distributionsmodeller giver en praktisk måde at modellere semantik på ved hjælp af tætte indlejringsrum afledt af uautoriserede læringsalgoritmer. Dimensionerne af tætte indlejringsrum er imidlertid ikke designet til at ligne menneskelig semantisk viden. Desuden er indlejringer ofte bygget ud fra en enkelt kilde til information (typisk tekstdata), selvom neurokognitiv forskning tyder på, at semantik er dybt forbundet med både sprog og opfattelse. I denne artikel kombinerer vi multimodale oplysninger fra både tekst- og billedbaserede repræsentationer afledt fra state-of-the-art distributionsmodeller til at producere sparsomme, fortolkningsable vektorer ved hjælp af Joint Non-Negative Sparse Embedding. Gennem dybdegående analyser, der sammenligner disse sparsomme modeller med menneskelige afledte adfærds- og neurobilleddata, demonstrerer vi deres evne til at forudsige fortolkende sproglige beskrivelser af menneskelig jordsandheds semantisk viden.', 'bg': 'Дистрибуционните модели осигуряват удобен начин за моделиране на семантика, използвайки гъсти вградени пространства, получени от ненадзорни учебни алгоритми. Въпреки това, размерите на плътните вградени пространства не са предназначени да наподобяват човешкото семантично знание. Нещо повече, вграждането често се изгражда от един източник на информация (обикновено текстови данни), въпреки че неврогнитивните изследвания показват, че семантиката е дълбоко свързана както с езика, така и с възприятието. В тази статия комбинираме мултимодална информация както от текстови, така и от изображения, получени от най-съвременни дистрибуционни модели, за да създадем редки, интерпретируеми вектори, използващи съвместно неотрицателно частично вграждане. Чрез задълбочени анализи, сравняващи тези редки модели с извлечени от човека поведенчески и неврообразни данни, ние демонстрираме тяхната способност да предвиждат интерпретирани лингвистични описания на семантичното знание на човешката основа-истина.', 'de': 'Verteilungsmodelle bieten eine bequeme Möglichkeit, Semantik mit dichten Einbettungsräumen zu modellieren, die von unbeaufsichtigten Lernalgorithmen abgeleitet werden. Die Dimensionen dichter Einbettungsräume sind jedoch nicht so gestaltet, dass sie menschlichem semantischem Wissen ähneln. Darüber hinaus werden Einbettungen oft aus einer einzigen Informationsquelle (typischerweise Textdaten) aufgebaut, obwohl neurokognitive Forschung nahelegt, dass Semantik sowohl mit Sprache als auch mit Wahrnehmung eng verknüpft ist. In diesem Beitrag kombinieren wir multimodale Informationen sowohl aus Text- als auch bildbasierten Darstellungen, die aus modernen Verteilungsmodellen abgeleitet wurden, um dünne, interpretierbare Vektoren mithilfe von Joint Non-Negative Sparse Embedding zu erzeugen. Durch eingehende Analysen, die diese spärlichen Modelle mit humanen Verhaltens- und Neuroimaging-Daten vergleichen, zeigen wir ihre Fähigkeit, interpretierbare linguistische Beschreibungen menschlicher Grundlagen-Wahrheits-semantischer Kenntnisse vorherzusagen.', 'id': 'Model distribusi menyediakan cara yang nyaman untuk model semantik menggunakan ruang penerbangan padat yang berasal dari algoritma belajar yang tidak diawasi. However, the dimensions of dense embedding spaces are not designed to resemble human semantic knowledge.  Selain itu, embedding sering dibangun dari sumber informasi tunggal (biasanya data teks), meskipun penelitian neurokognitif menunjukkan bahwa semantik terhubung dalam-dalam dengan bahasa dan persepsi. Dalam kertas ini, kita menggabungkan informasi multimodal dari berdasarkan teks dan gambar dari model distribusi terbaik untuk menghasilkan vektor yang sedikit dan dapat diterjemahkan menggunakan Joint Non-Negative Sparse Embedding. Melalui analisis mendalam yang membandingkan model kecil ini dengan data perilaku dan gambar saraf berasal dari manusia, kami menunjukkan kemampuan mereka untuk memprediksi deskripsi bahasa yang dapat diterjemahkan dari pengetahuan semantis dari manusia dasar-kebenaran.', 'sw': 'Mradi wa usambazaji unaweka njia nzuri ya kutengeneza miambo kwa kutumia maeneo makubwa yanayotoka kwenye algorithi za kujifunza zisizo sahihi. Hata hivyo, upeo wa maeneo yenye uchungu hauna lengo la kulinganisha maarifa ya kimapenzi ya binadamu. Zaidi ya hayo, mabango yanajengwa mara nyingi kutoka chanzo cha taarifa moja (takwimu za maandishi kwa kawaida), ingawa utafiti wa neurocognitive unaonyesha kuwa dawa zinaunganishwa sana na lugha na mtazamo. Katika gazeti hili, tunaunganisha taarifa mbalimbali kutoka kwa wawili wa maandishi na picha zilizotokana na mifano ya usambazaji wa sanaa ili kutengeneza vector zenye ufafanuzi kwa kutumia makazi ya Hifadhi isiyo na maana. Kupitia uchambuzi wa kina ukilinganisha mifano hii ya uchimbaji na taarifa za tabia za binadamu na picha za neuro, tunaonyesha uwezo wao wa kutabiri tafsiri za lugha zinazoelezea maelezo ya ukweli wa hali ya juu ya binadamu.', 'af': "Verspreidisionele modele verskaf 'n goeie manier om semantieke te model deur te gebruik dens inbinneste spasies afgelei van onondersteunde leer algoritme. Maar die dimensies van dens inbetering spasies is nie ontwerp om menslike semantiese kennis te lyk nie. Ook, inbêding word dikwels gebou van 'n enkele bron van inligting (tipies teks data), selfs al die neurokognitiewe ondersoek beveel dat semantieke diep verbind is met albei taal en ondersoek. In hierdie papier, ons kombinieer multimodale inligting van beide teks en beeldgebaseerde verteenwoordelings wat van staat van die kunste verspreidingsmodele afgelei word om sparse, interpretabele vekteurs te produseer met Gesameleid Non- Negatiewe Sparse Inbetering. Deur in-diepte analiseerdes wat hierdie sparse modele vergelyk het met mens afgeleide gedrag en neuroimagineerde data, wys ons hul moontlik om uitgelykbare lingwisiese beskrywings van menslike grond-waarheid semantiese kennis te voorskou.", 'fa': 'مدل های تقسیم راهی مناسب برای مدل سیمانتیک با استفاده از فضای داخل شدن داخلی که از الگوریتم یادگیری غیرقابل استفاده می\u200cشود، پیشنهاد می\u200cدهد. با این حال، اندازه\u200cهای فضایی\u200cهای داغ\u200cشده\u200cای برای شبیه دانش\u200cهای طبیعی انسان طراحی نمی\u200cشوند. علاوه بر این، اغلب از یک منبع اطلاعات (معمولاً اطلاعات متن) ساخته می شوند، حتی اگر تحقیقات عصبی شناسایی پیشنهاد می دهد که سیمانتیک عمیقاً با زبان و احساسات ارتباط دارد. در این کاغذ، ما اطلاعات multimodal را از متن و نمایش\u200cهای بنیاد تصویر از مدل\u200cهای تقسیم هنر برای تولید جستجو، ویکتورهای قابل تعبیر با استفاده از انجمن جستجو غیرمنفی جستجو ترکیب می\u200cکنیم. از طریق تحلیل عمیقی که این مدل\u200cها را با داده\u200cهای رفتاری و عصبی\u200cتصاویری از انسان مقایسه می\u200cکنیم، توانایی آنها را نشان می\u200cدهیم که توضیح\u200cهای زبان\u200cشناسی قابل تعبیر کننده از دانش\u200cهای semantic و حقیقت انسان را پیش بینی کنند.', 'tr': 'Daýratma modeller semantikleri gözlemezlik algoritmalardan gelen çöplük ýerlerini ullanýan ýerli bir şekilde öredir. Ýöne, gizlin semantik bilgiňe meňzeş ýerlerin ölçüleri düzenlenmedi. Munuň ýene-de, süzmeler köplenç malümatyň ýeke çeşmesinden inşa edilýär (adatça metin maglumatyndan), näuskognik barlamasynyň hem dilleriň hem düşünüşine gaty baglanmasyny maslahat berýär. Bu kağıtda, iki metin ve surat tabanlı temsillerden gelen çoklumodal bilgi birleştirip, çizgi bölümlerden oluşan, terjime edilebilir vektörleri birleştirerek birleştirýäris Derňlikde analyzlaryň içinde bu ýaraman nusgalary adam tarapyndan taýýarlanan davranışlary we neuroimaging maglumatlaryna karşılaşýan, adam ýerlik-dogrylyk bilen terjime edilebilir lingwistiki tassymlaryny öňündürmek üçin ukyplaryny görkeýäris.', 'am': 'የአካባቢ ሞዴላዎች በተጠበቀው ትምህርት መምህርት ማድረጊያውን በመጠቀም የሚችሉትን አካባቢ ቦታዎች በመጠቀም የሚያስቸግል መንገድ ያሳያል፡፡ ነገር ግን የሰው ምሳሌ እውቀትን ለመምሰል የጥልቅ ስፍራዎች አካባቢ ነው፡፡ ከዚህም በላይ የነዌብ ምርጫዎች በተለየ ቋንቋ እና አስተያየት ውስጥ ጥልቅ ተያያይቷል፡፡ በዚህ ፕሮግራም፣ የጽሑፍ እና ምስል-መሠረት እና የክፍለ-አርእስት አካባቢ ምርጫዎችን ለመፍጠር፣ ትርጓሜዎችን ለመፍጠር፣ ተርጓሚዎች እናስቀማታለን፡፡ በጥልቅ አስተያየት፣ እነዚህን ተቃራፊዎች ከሰው አካባቢ እና የነዌብ imaging ዳታዎችን በማሳየት እናሳያልን፤ የሰው መሬት-እውነት እውቀትን ለመቀበል የሚችለውን ቋንቋዊ ጽሑፎችን እናሳያልን፡፡', 'sq': 'Modelet shpërndarëse ofrojnë një mënyrë të përshtatshme për të modeluar semantikën duke përdorur hapësira të dendura të përfshira të nxjerra nga algoritmet e mësimit të pa mbikqyrur. Megjithatë, dimensionet e hapësirave të dendura të përfshirjes nuk janë projektuar për të ngjasur me njohurinë semantike njerëzore. Përveç kësaj, përfshirjet shpesh ndërtohen nga një burim i vetëm informacioni (tipikisht të dhëna teksti), edhe pse kërkimi neurokognitiv sugjeron se semantika është thellësisht e lidhur si me gjuhën ashtu edhe me perceptimin. Në këtë letër, ne kombinojmë informacion multimodal si nga teksti, ashtu edhe nga përfaqësimet bazuar në imazh të nxjerra nga modelet shpërndarëse moderne për të prodhuar vektorë të vogla, të interpretueshëm duke përdorur Embedding të Përbashkët jo negativ të shpejtë. Nëpërmjet analizave të thella që krahasojnë këto modele të vogla me të dhënat e sjelljes dhe neuroimazhit të nxjerrë nga njeriu, ne demonstrojmë aftësinë e tyre për të parashikuar përshkrimet gjuhësore të interpretueshme të njohurive semantike njerëzore tokë-të vërtetë.', 'hy': 'Տեղաբաշխման մոդելները հնարավոր միջոց են տալիս սեմանտիկայի մոդելը օգտագործելով խիստ ներգրավված տարածքներ, որոնք ստացվում են անվերահսկված ուսումնական ալգորիթմներից: Այնուամենայնիվ, խտուն ներդրող տարածքների չափերը չեն նախագծված մարդկային սեմանտիկ գիտելիքների նմանման: Ավելին, ներդրումները հաճախ կառուցվում են ինֆորմացիայի միակ աղբյուրից (սովորաբար տեքստի տվյալներ), չնայած որ նեյրոկոգնիտիվ հետազոտությունները ցույց են տալիս, որ սեմանտիկան խորապես կապված է լեզվի և ընկալության հետ: In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding.  Խաղր վերլուծությունների միջոցով, համեմատելով այս հազվադեպ մոդելները մարդկային կողմից առաջացած վարքագծային և նյարդապատկերացման տվյալների հետ, մենք ցույց ենք տալիս նրանց կարողությունը կանխատեսել մարդկային հիմնական-ճշմարտության սեմանտիկ գիտելիքի լեզվաբանական նկարագրությունները:', 'bn': 'বিতরণ মডেল অনরক্ষিত শিক্ষা অ্যালগরিদম থেকে প্রাপ্ত স্থান ব্যবহার করে সেমেন্টিক্স মডেল করার একটি সুবিধাজনক উপায় প্রদান করে। তবে গভীর বিভিন্ন স্থানের ধারণা মানুষের সেম্পেন্টিক জ্ঞানের সমতুল্যের জন্য নকশা করা হয় না। এছাড়াও, প্রায়শ তথ্যের একটি উৎস থেকে (সাধারণত টেক্সট ডাটা) বানানো হয়, যদিও নিউরোকোনিভাবে গবেষণা পরামর্শ দেয় যে সেমেন্টিক্স উভয় ভাষা  এই কাগজটিতে আমরা লেখা এবং ছবির ভিত্তিক প্রতিনিধিদের উভয় থেকে মাল্টিমোডাল তথ্য সংযুক্ত করি যেখানে স্প্যাস, ব্যাখ্যায়যোগ্য ভেক্টর সংযুক্ত নে গভীরভাবে বিশ্লেষণের মাধ্যমে মানুষের আচরণ এবং নিউরোভিমেজিং তথ্যের সাথে তুলনা করা এই স্প্যাস মডেলের মাধ্যমে আমরা তাদের ক্ষমতা প্রদর্শন করি মানুষের ভূমির', 'ko': '분포식 모델은 무감독 학습 알고리즘에서 파생된 밀집된 삽입 공간을 이용하여 의미를 구축하는 편리한 방법을 제공했다.그러나 공간에 밀집되어 있는 비트는 인류의 의미 지식과 유사하게 설계된 것이 아니다.그 밖에 삽입은 보통 단일 정보원(보통 텍스트 데이터)에서 온다. 비록 신경인지 연구에 의하면 의미와 언어와 감지는 깊은 관계를 가진다고 한다.본고에서 우리는 가장 선진적인 분포 모델의 텍스트와 이미지를 바탕으로 하는 다중모드 정보를 결합시켜 비부희소 삽입을 이용하여 희소한 해석 가능한 벡터를 생성한다.깊이 있는 분석을 통해 이러한 희소 모델과 인류가 파생된 행위와 신경 영상 데이터를 비교함으로써 우리는 인류의 기본적인 진리와 의미 지식을 예측하는 해석 가능한 언어 묘사 능력을 보여 주었다.', 'bs': 'Distribucioni modeli pružaju prikladan način da modeliraju semantike koristeći guste ugrađene prostore iz neodređenih algoritma učenja. Međutim, dimenzije gustih prostora za ugrađenje nisu dizajnirane kako bi slične ljudskim semantičkim znanjem. Osim toga, ugrađenje se često izgrađuje iz jednog izvora informacija (tipično tekstualnih podataka), iako neurokognitivno istraživanje ukazuje na to da je semantika duboko povezana sa jezikom i percepcijom. U ovom papiru kombiniramo multimodalne informacije iz teksta i predstavljanja na osnovu slike iz modela distribucije umjetnosti kako bi proizveli rezervne, interpretabilne vektore koristeći zajedničko ne-negativno uključenje prostora. Kroz duboke analize uspoređujući ove rezervne modele sa ljudskim ponašanjem i neuroimaginirajućim podacima, pokazujemo njihovu sposobnost predviđanja interpretabilnih jezičkih opisa semantičkih znanja ljudskih zemaljskih istina.', 'az': 'Dağıtılma modelləri semantik modellərinə uyğun yol göstərir, müəyyən edilməmiş öyrənmə algoritmlərindən çıxarılan sıxıntılı içəri boşluqlarını istifadə edir. Ancaq, gizli yerlərin ölçüləri insan semantik elmi kimi məşğul edilməz. Daha sonra, inşallar sık-sık bir məlumat mənbəsindən inşa edilir (sık-sık məlumat məlumatlarından), nörobyocognitiv araştırmaların məlumatların həmçinin semantik dillərin və baxışların həmçinin derin bir bağlı olduğunu iddia edir. Bu kağızda, hər iki metin və surat tabanlı göstəricilərdən çoxlu modal məlumatları birləşdiririk ki, sünbül və yoxlu vektörlər birləşdirilmək üçün sünbül-sünbül modellərdən yaradılır. Bu küçük modelləri insan təşkil edilmiş davranışlar və nörovlaşdırma məlumatları ilə qarşılaşdırmaq vasitəsilə, insanların yerdə-gerçəklik semantik bilgisinin yorumlaşdırılabilir dil təşkillərini təşkil edən qabiliyyətini göstərdik.', 'cs': 'Distribuční modely poskytují pohodlný způsob modelování sémantiky pomocí hustých vkládacích prostorů odvozených z algoritmů učení bez dohledu. Rozměry hustých vkládacích prostorů však nejsou navrženy tak, aby připomínaly lidské sémantické znalosti. Navíc jsou vkládány často z jediného zdroje informací (typicky textových dat), i když neurokognitivní výzkum naznačuje, že sémantika je hluboce propojena jak s jazykem, tak s vnímáním. V tomto článku kombinujeme multimodální informace z textových i obrazových reprezentací odvozených z nejmodernějších distribučních modelů a vytváříme řídké, interpretovatelné vektory pomocí Joint Non-Negative Sparse Embedding. Prostřednictvím hloubkových analýz porovnávání těchto řídkých modelů s lidskými behaviorálními a neurozobrazovacími daty demonstrujeme jejich schopnost předpovídat interpretovatelné jazykové popisy lidských základních pravdových sémantických znalostí.', 'ca': "Distributional models provide a convenient way to model semantics using dense embedding spaces derived from unsupervised learning algorithms.  No obstant això, les dimensions dels espais densos d'incorporació no estan dissenyades per semblar el coneixement semàntic humà. A més, sovint es construeixen incorporacions d'una sola font d'informació (normalment dades de text), encara que la investigació neurocognitiva suggereix que la semàntica està profundament vinculada a la llengua i la percepció. En aquest article, combinam informació multimodal de representacions basades tant en text com en imatges derivades de models de distribució més moderns per a produir vectors escassos i interpretables fent servir la Joint Non-Negative Sparse Embedding. Through in-depth analyses comparing these sparse models to human-derived behavioural and neuroimaging data, we demonstrate their ability to predict interpretable linguistic descriptions of human ground-truth semantic knowledge.", 'et': 'Jaotusmudelid pakuvad mugavat viisi semantika modelleerimiseks, kasutades tihedaid manustamisruume, mis tulenevad järelevalveta õppealgoritmidest. Siiski ei ole tihedate manustamisruumide mõõtmed loodud inimese semantiliste teadmiste sarnaseks. Lisaks ehitatakse manustamine sageli ühest teabeallikast (tavaliselt tekstiandmetest), kuigi neurokognitiivsed uuringud näitavad, et semantika on sügavalt seotud nii keele kui tajumisega. Käesolevas töös kombineerime mitmeliigilist informatsiooni nii teksti- kui pildipõhistest esitustest, mis on saadud kaasaegsetest distributsioonimudelitest, et luua hõredaid ja tõlgendatavaid vektoreid, kasutades ühist mitte-negatiivset lõpppõimimist. Põhjalike analüüside kaudu, mis võrdlevad neid hõredaid mudeleid inimese käitumis- ja neuropildistamisandmetega, näitame nende võimet ennustada tõlgendatavaid keelelisi kirjeldusi inimese alustõde semantilistest teadmistest.', 'fi': 'Jakelumallit tarjoavat kätevän tavan mallintaa semantiikkaa käyttämällä valvomattomista oppimisalgoritmeista johdettuja tiheitä upotustiloja. Tiivien upotustilojen ulottuvuuksia ei kuitenkaan ole suunniteltu muistuttamaan ihmisen semanttista tietoa. Lisäksi upotukset rakentuvat usein yhdestä tietolähteestä (tyypillisesti tekstitiedosta), vaikka neurokognitiiviset tutkimukset viittaavat siihen, että semantiikka liittyy syvästi sekä kieleen että havaintoon. Tässä artikkelissa yhdistämme multimodaalisia tietoja sekä teksti- että kuvapohjaisista esityksistä, jotka on johdettu uusimmista jakelumalleista, tuottaaksemme harvoja, tulkittavissa olevia vektoreita käyttämällä Joint Non-Negative Sparse Embeding -sovellusta. Syvällä analyysillä, jossa näitä harvoja malleja verrataan ihmisen käyttäytymiseen ja neurokuvantamiseen, osoitetaan niiden kyky ennustaa tulkittavissa olevia kielellisiä kuvauksia ihmisen pohjatotuuden semanttisesta tiedosta.', 'jv': 'Distribution modeles Nanging, kalih berarti punika dipunangkapan anyar tentang dipunangkapan karo semanti kuwi nggawe barang sampek. politenessoffpolite"), and when there is a change ("assertivepoliteness In this paper, we combine multimodal information from the text and image-supported representations from state-of-the-arts Distribubution modes to make spase, tolable vectors use Joint Not-Nerative Sparsi embedding. Dino deep-profondi maneh pisan kelas kuwi nggawe layanan model sing dumadhi iki ngono perbudhakan langkung sami tindakan tentang kuwi mau, kita nguasai kapan kanggo ngerasai perbudhakan langkung sami usul sing ngerasakno dumadhi sing paling dhuwur.', 'ha': "@ info: whatsthis A lokacin da, ba za'a design girgije na filayen bakwai mai ƙunci ba dõmin a yi kama da ilmi na mutane. Za da haka, an samar da embargo ko da yawa daga wani zane na tsari (mai amfani da matsayin na rubutu), kuma kõ dã research na neurokognitive yana son cẽwa, ana girmama mutane da tsakanin da duk harshe da gane. In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding.  Ina yi ƙidãya ga-depth, sammeni da waɗannan misãlai masu sami zuwa data na masu motsi da ke danna aikin mutum da ke danne-zane-neuro, za mu nuna awon su iya gabatar da fassarar fassarar linguin da ke fassarar fassarar fassarar da fassarar kunyar mutane na gaskiya.", 'sk': 'Distribucijski modeli zagotavljajo priročen način modeliranja semantike z uporabo gostih vgradnih prostorov, ki izhajajo iz algoritmov nenadzorovanega učenja. Vendar pa dimenzije gostih vgradnih prostorov niso zasnovane tako, da bi spominjale na človeško semantično znanje. Poleg tega so vdelave pogosto zgrajene iz enega samega vira informacij (običajno besedilnih podatkov), čeprav nevrokognitivne raziskave kažejo, da je semantika globoko povezana z jezikom in percepcijo. V tem prispevku združujemo multimodalne informacije iz besedilnih in slikovnih predstavitev, pridobljenih iz najsodobnejših distribucijskih modelov, da ustvarimo redke, razložljive vektorje z uporabo skupne nenegativne sparne vdelave. S pomočjo poglobljenih analiz primerjave teh redkih modelov z vedenjskimi podatki in podatki, ki jih pridobimo iz človeka, dokazujemo njihovo sposobnost napovedati razložljive jezikovne opise semantičnega znanja človeške osnovne resnice.', 'bo': 'Distributional models provide a convenient way to model semantics using dense embedding spaces derived from unsupervised learning algorithms. ཡིན་ནའང་། ཉམས་འཇུག་པའི་བར་སྟོང་ཚོའི་ཆེ་ཆུང་དེ་མིན་པ་ལྟར་མི་འདྲ་ཞིག་བྱེད་ཀྱི་ཡོད། རྒྱལ་ཁབ་ཀྱིས་སྦྱར་རུང་བའི་ཆ་འཕྲིན་ཡིག་ལས་རྒྱུན་དུ་བཙུགས་ཡོད། In this paper, we combine multimodal information from both text and image-based representations derived from state-of-the-art distributional models to produce sparse, interpretable vectors using Joint Non-Negative Sparse Embedding. Through in-depth analyzes comparing these sparse models to human-derived behavior and neuroimaging data, we demonstrate their ability to predict interpretable linguistic descriptions of human ground-truth semantic knowledge.', 'he': 'דוגמנים פיצועים מספקים דרך נוחה לדוגמא סמנטיקה בשימוש בחלומות פיצועים צפופים שנוצרו מאלגוריתמים ללמוד לא מעוקבים. בכל אופן, המימדים של מרחבי פיתוח צפופים לא מעוצבים כדי לדמיין ידע סמנטי אנושי. Moreover, embeddings are often built from a single source of information (typically text data), even though neurocognitive research suggests that semantics is deeply linked to both language and perception.  בעיתון הזה, אנחנו משלבים מידע רב-מודיאלי משני מייצגים טקסטים ומבוססים על תמונות שנוצרים מדוגמנים פיצועים חדשים ביותר כדי לייצר ווקטורים נדירים, אפשריים לפרשנות באמצעות פיצועים משותפים לא שליליים. באמצעות ניתוחים עמוקים בהשוואה של דוגמנים נדירים אלה למידע התנהגות ומדמיון נוירוגי שנוצר מאדם אנושי, אנחנו מראים את היכולת שלהם לחזות תיאורים שפתיים אפשריים לפרש של ידע סמנטי האדם-האמת האדם.'}
{'en': 'Sentence-Level Fluency Evaluation : References Help, But Can Be Spared !', 'ar': 'تقييم الطلاقة على مستوى الجملة: المراجع تساعد ، لكن يمكن تجنبها!', 'es': 'Evaluación de fluidez a nivel de oración: ¡Las referencias ayudan, pero se pueden ahorrar!', 'fr': 'Évaluation de la fluidité au niveau de la phrase\xa0: les références aident, mais peuvent être épargnées\xa0!', 'pt': 'Avaliação da fluência no nível da sentença: as referências ajudam, mas podem ser poupadas!', 'ja': '文章レベルの流暢性評価：参考文献はヘルプですが、免除することができます！', 'zh': '句级流利度评估:参考文献有助,但可幸免!', 'hi': 'वाक्य-स्तर प्रवाह मूल्यांकन: संदर्भ मदद करते हैं, लेकिन बख्शा जा सकता है!', 'ru': 'Оценка беглости на уровне предложения: рекомендации помогают, но могут быть сохранены!', 'ga': 'Measúnú Líofachta ar Leibhéal Pianbhreithe: Tagairtí Cabhraíonn, Ach Is Féidir A Chosc!', 'ka': 'ჟყჲბღვნთვრჲ ნა ჟლსფაინჲჟრ ვ ოჲმჲღჲ, ნჲ მჲზვ ეა ბყევ ჟოაჟვნჲ!', 'hu': 'Ítélet-szintű folyamatos értékelés: Referenciák segítség, de megkímélhető!', 'el': 'Αξιολόγηση ρευστότητας σε επίπεδο φράσεων: Οι αναφορές βοηθούν, αλλά μπορούν να σωθούν!', 'it': 'Valutazione della fluidità a livello di frase: i riferimenti aiutano, ma possono essere risparmiati!', 'kk': 'Сөздік деңгейінің жылдамдығын бағалау: сілтемелер көмегі, бірақ қалдыруға болады!', 'mk': 'Оценка на течност на нивото на реченици: Референциите помогнаа, но може да се заштеди!', 'lt': 'Nuorodos padeda, bet gali būti sutaupyta!', 'ml': 'ശിക്ഷ- നില വിമാനത്തിന്റെ പരിശോധന: പ്രഖ്യാപിക്കുന്ന സഹായം, പക്ഷെ സ്പെയിന്\u200dറ് ചെയ്യാന്\u200d കഴിയും!', 'ms': 'Penilaian Kecairan Aras-Hukuman: Rujukan Bantuan, Tetapi Boleh Disimpan!', 'mn': 'Хэрэглэгч-түвшин давхар шингээлийн үнэлгээ: References Help, Гэхдээ Сургуулж чадна!', 'mt': "Evalwazzjoni tal-Fluwenza fil-Livell tas-Sentenza: Referenzi Għajnuna, Iżda Jista' jiġi ffrankat!", 'no': 'Uttrykk-nivå flytande evaluering: referanse Hjelp, men kan vera spart!', 'ro': 'Evaluarea fluenței la nivel de sentință: Referințele ajută, dar pot fi scutite!', 'pl': 'Ocena płynności zdań na poziomie: referencje pomagają, ale mogą być oszczędzone!', 'sr': 'Procjenjivanje tekućine na nivou kazne: Pomoć, ali može biti spašen!', 'so': 'Heyminta heerka heerka ee Heeganka: Caawimaadda reference, laakiin waa la badbaadin karaa!', 'si': 'වාර්තාව-ප්\u200dරමාණය අවශ්\u200dයය: ප්\u200dරමාණය උදව්, ඒත් පුළුවන් බේරගන්න!', 'sv': 'Utvärdering av meningsnivå: Referenser hjälper, men kan besparas!', 'ta': 'வாக்குறுப்பு- நிலை வாய்ப்பு மதிப்பு: குறிப்புகள் உதவி, ஆனால் சேமிக்க முடியும்!', 'ur': 'Sentence-Level Fluency Evaluation: References Help, But Can be Spared!', 'uz': 'Sensor- darajasi muvaffaqiyatsiz: References Help, Lekin Spanish mumkin!', 'vi': 'Bài đánh giá chất lượng án: Tham khảo trợ giúp, nhưng có thể be bé!', 'bg': 'Оценка на плавността на присъдата: Референции помагат, но могат да бъдат пощадени!', 'nl': 'Vloeiende evaluatie op zinsniveau: Referenties helpen, maar kunnen gespaard worden!', 'hr': 'Procjenjivanje tekućine na razini kazne: Odvještajna pomoć, ali može biti spašena!', 'da': 'Sætningsniveau Fluency Evaluering: Referencer hjælper, men kan spares!', 'id': 'Evaluasi Kecairan Tingkat-hukuman: Referensi Bantuan, Tapi Bisa Disimpan!', 'ko': '문장 유창도 평가: 참고 문헌은 도움이 되지만 생략할 수 있습니다!', 'de': 'Fluency Evaluation auf Satz-Ebene: Referenzen helfen, können aber verschont werden!', 'fa': 'ارزیابی فعالیت طبقه\u200cی عبارت: کمک سرنوشت، ولی می\u200cتواند محافظت شود!', 'sw': 'Sentence-Level Fluency Evaluation: References Help, But Can Be Spared!', 'af': 'Sentence- Vlak vloeienheid Evaluering: Verwysings Hulp, Maar Kan Verlos word!', 'tr': 'Sözler Derjesi Taýýarlama: Referanslar kömegi, ýöne Spasiýaly bolar!', 'sq': 'Vlerësimi i lehtësisë së nivelit të dënimit: Referencat ndihmojnë, por mund të kursihen!', 'am': 'የስርዓት-ደረጃው የኩነቶች መረጃ', 'hy': 'Արտահայտության մակարդակի հեղության գնահատումը. Արտահայտությունները օգնում են, բայց կարող են խնայվել:', 'az': 'Sözüm-Seviye Fluency Assessment: References Help, But Can be Spaded!', 'bn': 'Sentence-Level Fluency Evaluation: References Help, But Can Be Spared!', 'ca': 'Evaluació de la fluència del nivell de frases: Referències Ajuda, però pot ser estalviat!', 'cs': 'Hodnocení plynulosti vět na úrovni: Reference pomáhají, ale mohou být ušetřeny!', 'et': 'Sentence-Level Fluency Hindamine: Viited Abi, kuid saab säästa!', 'bs': 'Procjenjivanje tekućine na razini kazne: Odvještajna pomoć, ali može biti spašena!', 'fi': 'Lausumistason Fluency Evaluation: Referenssit auttavat, mutta voidaan säästää!', 'jv': 'Cwanger', 'sk': 'Ocenjevanje fluentnosti na ravni kazni: Reference Pomagajo, vendar jih je mogoče prihraniti!', 'ha': 'Taimar Aiki na Kwanan Hazara-Tsarawa: Aka iya iya samar da!', 'he': 'הערכה ברמה של גזר הדין: התייחסות עזרה, אבל אפשר לחסוך!', 'bo': 'Sentence-Level Fluency Evaluation: References Help, But Can be Spared!'}
{'en': 'Motivated by recent findings on the probabilistic modeling of acceptability judgments, we propose syntactic log-odds ratio (SLOR), a normalized language model score, as a metric for referenceless fluency evaluation of natural language generation output at the sentence level. We further introduce WPSLOR, a novel WordPiece-based version, which harnesses a more compact ', 'ar': 'بدافع من النتائج الأخيرة حول النمذجة الاحتمالية لأحكام المقبولية ، نقترح نسبة الأرجحية اللغوية النحوية (SLOR) ، درجة نموذج اللغة المعيارية ، كمقياس لتقييم الطلاقة غير المرجعية لمخرجات توليد اللغة الطبيعية على مستوى الجملة. نقدم كذلك WPSLOR ، وهو إصدار جديد قائم على WordPiece ، والذي يستخدم نموذج لغة أكثر إحكاما. على الرغم من أن مقاييس تداخل الكلمات مثل ROUGE تُحسب بمساعدة المراجع المكتوبة بخط اليد ، فإن طرقنا التي لا مرجعية تحصل على ارتباط أعلى بكثير مع درجات الطلاقة البشرية في مجموعة بيانات معيارية من الجمل المضغوطة. أخيرًا ، نقدم ROUGE-LM ، مقياس قائم على المرجع والذي يعد امتدادًا طبيعيًا لـ WPSLOR في حالة المراجع المتاحة. نظهر أن ROUGE-LM ينتج ارتباطًا أعلى بكثير مع الأحكام البشرية مقارنة بجميع المقاييس الأساسية ، بما في ذلك WPSLOR بمفرده.', 'pt': 'Motivados por descobertas recentes sobre a modelagem probabilística de julgamentos de aceitabilidade, propomos a razão log-odds sintática (SLOR), uma pontuação de modelo de linguagem normalizada, como uma métrica para avaliação de fluência sem referência da saída de geração de linguagem natural no nível da sentença. Apresentamos ainda o WPSLOR, uma nova versão baseada no WordPiece, que aproveita um modelo de linguagem mais compacto. Embora as métricas de sobreposição de palavras, como ROUGE, sejam calculadas com a ajuda de referências escritas à mão, nossos métodos sem referência obtêm uma correlação significativamente maior com as pontuações de fluência humana em um conjunto de dados de referência de frases compactadas. Por fim, apresentamos o ROUGE-LM, uma métrica baseada em referências que é uma extensão natural do WPSLOR para o caso de referências disponíveis. Mostramos que o ROUGE-LM produz uma correlação significativamente maior com julgamentos humanos do que todas as métricas de linha de base, incluindo o WPSLOR por conta própria.', 'es': 'Motivados por los hallazgos recientes sobre el modelo probabilístico de los juicios de aceptabilidad, proponemos la relación logarítmica sintáctica de probabilidades (SLOR), una puntuación del modelo de lenguaje normalizado, como una métrica para la evaluación de la fluidez sin referencia de la producción de generación de lenguaje natural a nivel de oración. Además, presentamos WPSLOR, una novedosa versión basada en WordPiece, que aprovecha un modelo de lenguaje más compacto. A pesar de que las métricas de superposición de palabras como ROUGE se calculan con la ayuda de referencias escritas a mano, nuestros métodos sin referencia obtienen una correlación significativamente mayor con las puntuaciones de fluidez humana en un conjunto de datos de referencia de oraciones comprimidas. Finalmente, presentamos ROUGE-LM, una métrica basada en referencias que es una extensión natural de WPSLOR para el caso de las referencias disponibles. Mostramos que ROUGE-LM produce una correlación significativamente mayor con los juicios humanos que todas las métricas de referencia, incluida WPSLOR por sí sola.', 'fr': "Motivés par des découvertes récentes sur la modélisation probabiliste des jugements d'acceptabilité, nous proposons le rapport syntaxique log-cotes (SLOR), un score normalisé du modèle de langage, comme métrique pour l'évaluation de la fluidité sans référence de la sortie de génération de langage naturel au niveau de la phrase. Nous présentons également WPSLOR, une nouvelle version basée sur Wordpiece, qui exploite un modèle de langage plus compact. Même si les mesures de chevauchement de mots comme ROUGE sont calculées à l'aide de références manuscrites, nos méthodes sans référence obtiennent une corrélation nettement plus élevée avec les scores de fluidité humaine sur un ensemble de données de référence de phrases compressées. Enfin, nous présentons ROUGE-LM, une métrique basée sur des références qui est une extension naturelle de WPSLOR au cas des références disponibles. Nous montrons que ROUGE-LM produit une corrélation significativement plus élevée avec les jugements humains que toutes les mesures de base, y compris WPSLOR seul.", 'ja': '許容性判断の確率的モデリングに関する最近の知見に動機づけられ、文レベルでの自然言語生成出力の無参照流動性評価のための指標として、正規化された言語モデルスコアである構文log - ods比（ SLOR ）を提案する。さらに、よりコンパクトな言語モデルを活用した斬新なWordPieceベースのバージョンであるWPSLORをご紹介します。ROUGEのようなワードオーバーラップ指標は、手書きの参照を使用して計算されていますが、当社の参照なしの方法は、圧縮された文章のベンチマークデータセットの人間の流暢性スコアと有意に高い相関性を得ます。最後に、利用可能な参照の場合へのWPSLORの自然な拡張である参照ベースのメトリックであるROUGE - LMを提示します。ROUGE - LMは、WPSLORを含むすべてのベースラインメトリクスよりも、人間の判断との相関が有意に高いことを示しています。', 'zh': '近可接受性之概率建模,发句法对数比值比(SLOR),一归一化之言,以为句自然语言无参流畅性评指标。 进言WPSLOR,WordPiece新版也,因益凑之言也。 虽复如ROUGE之单词指标手参考文献之助,吾无参术与压缩句准数集上人伦流度分数之相关性明矣。 最后,我们介绍ROUGE-LM,这是一个基于引用的指标,他是WPSLOR对可用的自然扩展。 吾明与凡基线指标(WPSLOR身)比,ROUGE-LM与人决者相关性多矣。', 'hi': 'स्वीकार्यता निर्णयों के संभाव्य मॉडलिंग पर हाल के निष्कर्षों से प्रेरित होकर, हम वाक्य स्तर पर प्राकृतिक भाषा पीढ़ी के आउटपुट के संदर्भहीन प्रवाह मूल्यांकन के लिए एक मीट्रिक के रूप में वाक्यात्मक लॉग-ऑड्स अनुपात (SLOR), एक सामान्यीकृत भाषा मॉडल स्कोर का प्रस्ताव करते हैं। हम आगे WPSLOR, एक उपन्यास WordPiece-आधारित संस्करण, जो एक और अधिक कॉम्पैक्ट भाषा मॉडल का दोहन करता है परिचय. भले ही रूज जैसे शब्द-ओवरलैप मैट्रिक्स की गणना हाथ से लिखे गए संदर्भों की मदद से की जाती है, लेकिन हमारे संदर्भहीन तरीके संपीड़ित वाक्यों के बेंचमार्क डेटासेट पर मानव प्रवाह स्कोर के साथ काफी अधिक सहसंबंध प्राप्त करते हैं। अंत में, हम रूज-एलएम, एक संदर्भ-आधारित मीट्रिक प्रस्तुत करते हैं जो उपलब्ध संदर्भों के मामले में WPSLOR का एक प्राकृतिक विस्तार है। हम दिखाते हैं कि रूज-एलएम सभी बेसलाइन मैट्रिक्स की तुलना में मानव निर्णयों के साथ काफी अधिक सहसंबंध पैदा करता है, जिसमें WPSLOR भी शामिल है।', 'ru': 'Основываясь на недавних результатах вероятностного моделирования оценок приемлемости, мы предлагаем синтаксическое соотношение log-odds (SLOR), нормализованную оценку языковой модели, в качестве метрики для оценки беглости естественного языка на уровне предложения. Мы также представляем WPSLOR, новую версию на основе WordPiece, которая использует более компактную языковую модель. Несмотря на то, что метрики наложения слов, такие как ROUGE, вычисляются с помощью рукописных ссылок, наши безреферентные методы получают значительно более высокую корреляцию с показателями беглости человека на эталонном наборе данных сжатых предложений. Наконец, мы представляем ROUGE-LM, эталонную метрику, которая является естественным продолжением WPSLOR в случае доступных ссылок. Мы показываем, что ROUGE-LM дает значительно более высокую корреляцию с человеческими суждениями, чем все базовые показатели, включая WPSLOR самостоятельно.', 'ga': 'Spreagtha ag torthaí le déanaí ar shamhaltú dóchúlachta breithiúnais inghlacthachta, molaimid cóimheas comhréire log- corrlaigh (SLOR), scór samhail teanga normalaithe, mar mhéadrach do mheasúnú líofachta gan tagairt ar aschur giniúna teanga nádúrtha ag leibhéal na habairte. Tugaimid isteach freisin WPSLOR, leagan úrnua atá bunaithe ar WordPiece, a bhaineann leas as samhail teanga níos dlúithe. Cé go ríomhtar méadracht forluí focal cosúil le ROUGE le cabhair ó thagairtí lámhscríofa, faigheann ár modhanna gan tagairt comhghaolú i bhfad níos airde le scóir líofachta daonna ar thacar sonraí tagarmharcála d’abairtí comhbhrúite. Ar deireadh, cuirimid i láthair ROUGE-LM, méadrach atá bunaithe ar thagairtí atá mar shíneadh nádúrtha de WPSLOR do chás na dtagairtí atá ar fáil. Léirímid go bhfuil comhghaol i bhfad níos airde ag ROUGE-LM le breithiúnais dhaonna ná le gach méadracht bonnlíne, lena n-áirítear WPSLOR ina aonar.', 'ka': 'მოტივირებულია ახალი მონაცემებით მივიღებელების შესაბამისი მოდელისტიკური მოდელირებაზე, ჩვენ მივიღებთ სინტაქტიკური log-odds ratio (SLOR), ნორმალურად ენის მოდელის მოდელის მონაცემებით, როგორც მეტრიკურად მივიღებთ ჩემი ენის ჩვენ უფრო მეტად WPSLOR, რომელიც WordPiece-based ვერსია, რომელიც უფრო კომპექტური ენის მოდელის გამოყენება. მაგრამ როგორც ROUGE სიტყვების მეტრიკების შესაძლებლობით, ჩვენი რეფერენციულ მეტრიკების შესაძლებლობით გამოიყენება, ჩვენი რეფერენციულ მეტრიკების შესაძლებლობით უფრო მეტი კოლექცია ადამიანის ფუნქცი საბოლოოდ, ჩვენ ვამხსენებთ ROUGE-LM, რეფერენციის მეტრიკი, რომელიც WPSLOR-ის ნახევალური გაფართლება შესაძლებელი რეფერენციების შემთხვევაში. ჩვენ ჩვენ აჩვენებთ, რომ ROUGE-LM იქნება მნიშვნელოვანად უფრო მეტი კორელაციას, რომელიც ადამიანის სწორებებისთვის, ვიდრე ყველა ფესვილური მეტრიკის, რომელიც WPS', 'hu': 'Az elfogadhatósági ítéletek valószínűsíthetőségi modellezésével kapcsolatos közelmúltbeli eredmények alapján javasoljuk a szintaktikus log-odds ratio (SLOR), egy normalizált nyelvmodell pontszámot, amely a természetes nyelv generálásának kimeneteinek referencia nélküli folyékonysági értékelésére szolgál mondatszinten. Bemutatjuk továbbá a WPSLOR-t, egy új WordPiece alapú változatot, amely egy kompakt nyelvi modellt használ. Annak ellenére, hogy a ROUGE-hoz hasonló szóátfedési mutatókat kézzel írt referenciák segítségével számítjuk ki, referencia nélküli módszereink jelentősen magasabb korrelációt érnek el a humán fluencia pontszámokkal egy tömörített mondatokból álló referenciaadatkészleten. Végül bemutatjuk a ROUGE-LM-et, egy referencia alapú metrikát, amely a WPSLOR természetes kiterjesztése a rendelkezésre álló referenciákra. Megmutatjuk, hogy a ROUGE-LM jelentősen nagyobb korrelációt eredményez az emberi ítéletekkel, mint minden alapvető mutató, beleértve a WPSLOR-t is.', 'el': 'Με κίνητρο από πρόσφατα ευρήματα σχετικά με την πιθανολογική μοντελοποίηση κρίσεων αποδοχής, προτείνουμε τη συντακτική αναλογία καταγραφής-αποδόσεων (μια κανονική βαθμολογία γλωσσικού μοντέλου, ως μετρική για την αξιολόγηση της ρευστότητας της παραγωγής φυσικής γλώσσας σε επίπεδο πρότασης. Παρουσιάζουμε περαιτέρω μια νέα έκδοση βασισμένη σε ένα πιο συμπαγές γλωσσικό μοντέλο. Παρά το γεγονός ότι οι μετρήσεις επικάλυψης λέξεων, όπως το ROUGE υπολογίζονται με τη βοήθεια χειρόγραφων αναφορών, οι μέθοδοι μας χωρίς αναφορά επιτυγχάνουν σημαντικά υψηλότερη συσχέτιση με τις βαθμολογίες ανθρώπινης ρευστότητας σε ένα σύνολο δεδομένων αναφοράς συμπιεσμένων προτάσεων. Τέλος, παρουσιάζουμε μια μετρική βασισμένη σε αναφορές που αποτελεί φυσική επέκταση του στην περίπτωση των διαθέσιμων αναφορών. Δείχνουμε ότι το ROUGE-LM αποδίδει μια σημαντικά υψηλότερη συσχέτιση με τις ανθρώπινες κρίσεις από όλες τις βασικές μετρήσεις, συμπεριλαμβανομένης της WPSLOR από μόνη της.', 'it': "Motivati da recenti scoperte sulla modellazione probabilistica dei giudizi di accettabilità, proponiamo il log-odds ratio sintattico (SLOR), un punteggio normalizzato del modello linguistico, come metrica per la valutazione della fluenza senza riferimento dell'output di generazione del linguaggio naturale a livello di frase. Presentiamo inoltre WPSLOR, una nuova versione basata su WordPiece, che sfrutta un modello linguistico più compatto. Anche se le metriche di sovrapposizione di parole come ROUGE sono calcolate con l'aiuto di riferimenti scritti a mano, i nostri metodi senza riferimento ottengono una correlazione significativamente più elevata con i punteggi di fluenza umana su un set di dati di benchmark di frasi compresse. Infine, presentiamo ROUGE-LM, una metrica basata su riferimento che è un'estensione naturale di WPSLOR al caso dei riferimenti disponibili. Mostriamo che ROUGE-LM produce una correlazione significativamente più elevata con i giudizi umani rispetto a tutte le metriche di base, incluso WPSLOR da solo.", 'lt': 'Motivated by recent findings on the probabilistic modeling of acceptability judgments, we propose syntactic log-odds ratio (SLOR), a normalized language model score, as a metric for referenceless fluency evaluation of natural language generation output at the sentence level.  Be to, pristatysime WPSLOR, naują WordPiece versiją, kurioje naudojamas kompaktesnis kalbos modelis. Nors žodžių dubliavimosi metrijos, pvz., ROUGE, apskaičiuojamos naudojant rankinius nuorodas, mūsų be nuorodų metodai gauna gerokai didesnę koreliaciją su žmogaus skysčio taškais pagal suspaustų sakinių duomenų rinkinį. Galiausiai pristatome ROUGE-LM, atskaitos pagrindu grindžiamą metriką, kuris yra natūralus WPSLOR išplėtimas, atsižvelgiant į turimas nuorodas. Mes rodome, kad ROUGE-LM sukuria gerokai didesnę koreliaciją su žmogaus sprendimais nei visi pradiniai rodikliai, įskaitant WPSLOR.', 'kk': 'Соңғы тапсырмаларды қабылдауға мүмкіндік үлгілердің моделі үшін қолданылатын синтактикалық журналдық тапсырмалар (SLOR) деңгейінде синтактикалық журналдық тапсырмалардың қасиеті (SLOR) деңгейінде, қалыпты тіл үлгілерінің нөмір Біз сондай-ақ WPSLOR- ды, WordPiece- негіздеген романдық нұсқасын таңдап береміз. Бұл тіл үлгісін көптеген. ROUGE секілді мәтірлерді сөздердің көмегімен есептеу үшін, біздің сілтемелік тәсілдеріміз көмегімен адамдардың жыныстық нөмірлерімен көмегімен көмектесілген сәйкестіктеріміз көмектесілген сәйкестікт Соңында, біз ROUGE-LM дегенді, сілтеме негіздеген метрикалық, WPSLOR дегеннің табиғи кеңейтуі бар сілтемелер үшін келтірік. Біз ROUGE-LM адамдардың түсініктерімен барлық негізгі метрикалық метрикалық, WPSLOR және оның өзіміздің түсініктерімен көп жоғары қатынасын көрсетедік.', 'mk': 'Мотивирани од неодамнешните откритија за веројатното моделирање на пресудите за прифатливост, предложуваме синтактички однос на логични веројатности (СЛОР), нормализиран резултат на јазичкиот модел, како метрика за безреференциска проценка на течноста на природната генерација на јазик на ниво на Понатаму претставуваме WPSLOR, нова верзија базирана на WordPiece, која користи покомпактен јазички модел. И покрај тоа што метриките за преплавување на зборови како ROUGE се компјутирани со помош на рачно напишани референции, нашите безреференциски методи добиваат значително повисока корелација со резултатите на човечката течност на групата на податоци на компресирани реченици. Конечно, претставуваме ROUGE-LM, метрика базирана на референција која е природно продолжување на WPSLOR на случајот на достапни референции. We show that ROUGE-LM yields a significantly higher correlation with human judgments than all baseline metrics, including WPSLOR on its own.', 'ml': 'സ്വാഭാവിക വിധികളുടെ സാധ്യതകളുടെ മോഡല്\u200d മാതൃകയില്\u200d അടുത്തുള്ള കണ്ടുപിടികള്\u200d പ്രാവര്\u200dത്തികമാക്കിയിരിക്കുന്നു. സാധാരണ ഭാഷ മോഡല്\u200d സ്കോര്\u200dട്രിക്ക് സ്വാഭാവികമായ വിവരങ് നമ്മള്\u200d വിപിസ്ലോറിനെ കൂടുതല്\u200d പരിചയപ്പെടുത്തുന്നു. ഒരു നോവല്\u200d വാര്\u200dഡ് പൈസ് അടിസ്ഥാനമായ പതിപ്പ്, അത് കൂടുതല്\u200d ചേര്\u200dത്ത ഭാ രൂജെയിനെപ്പോലുള്ള വാക്ക് മേട്രിക്കുകള്\u200d കൈഎഴുതിയ വിവരങ്ങളുടെ സഹായത്തോട് കണക്കാക്കുന്നുവെങ്കിലും നമ്മുടെ രീതികളില്ലാത്ത മാര്\u200dഗ്ഗങ്ങള്\u200d മുഴുവന്\u200d  Finally, we present ROUGE-LM, a reference-based metric which is a natural extension of WPSLOR to the case of available references.  നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് റൂജ്-LM മനുഷ്യരുടെ വിധികള്\u200d മെറ്റ്രിക്കുകളെക്കാള്\u200d മികച്ച ബന്ധമുള്ളതാണെന്നാണ്. വിപ്സ', 'ms': 'Motivated by recent findings on the probabilistic modeling of acceptability judgments, we propose syntactic log-odds ratio (SLOR), a normalized language model score, as a metric for reference fluency evaluation of natural language generation output at the sentence level. Kami memperkenalkan WPSLOR, versi berasaskan WordPiece yang baru, yang menggunakan model bahasa yang lebih kompak. Walaupun metrik perkataan-meliputi seperti ROUGE dikira dengan bantuan rujukan ditulis-tangan, kaedah kita tanpa rujukan mendapat korelasi yang jauh lebih tinggi dengan skor kelemahan manusia pada set data benchmark kalimat termampat. Akhirnya, kami memperkenalkan ROUGE-LM, metrik berdasarkan rujukan yang merupakan sambungan semulajadi WPSLOR kepada kes rujukan yang tersedia. Kami menunjukkan bahawa ROUGE-LM memberikan korelasi yang lebih tinggi dengan penilaian manusia daripada semua metrik asas, termasuk WPSLOR sendiri.', 'mt': 'Motivat minn sejbiet reċenti dwar l-immudellar probabilistiku tas-sentenzi ta’ a ċċettabbiltà, qed nipproponu proporzjon sintetiku ta’ log-odds (SLOR), punteġġ normalizzat tal-mudell lingwistiku, bħala metriku għall-evalwazzjoni ta’ fluwenza mingħajr referenza tal-produzzjoni tal-ġenerazzjoni naturali tal-lingwa fil-livell tas-sentenza. Aħna nintroduċu wkoll WPSLOR, verżjoni ġdida bbażata fuq WordPiece, li tuża mudell lingwistiku aktar kompatt. Minkejja li l-metriċi li jikkoinċidu l-kliem bħal ROUGE jiġu kkalkulati bl-għajnuna ta’ referenzi miktuba bl-idejn, il-metodi mingħajr referenza tagħna jiksbu korrelazzjoni sinifikament ogħla mal-punteġġi tal-fluwenza umana fuq sett ta’ dejta ta’ referenza ta’ sentenzi kkumpressati. Fl-a ħħar nett, qed nippreżentaw ROUGE-LM, metrika bbażata fuq referenza li hija estensjoni naturali tad-WPSLOR għall-każ ta’ referenzi disponibbli. Aħna nuru li ROUGE-LM jagħti korrelazzjoni ogħla b’mod sinifikanti mas-sentenzi umani mill-metriċi tal-linja bażi kollha, inkluż WPSLOR waħdu.', 'ro': 'Motivat de constatările recente privind modelarea probabilistică a judecăților de acceptabilitate, propunem raportul log-odds sintactic (SLOR), un scor model de limbă normalizat, ca metrică pentru evaluarea fluenței fără referință a ieșirii generației limbajului natural la nivelul propoziției. Mai mult, introducem WPSLOR, o versiune nouă bazată pe WordPiece, care valorifică un model de limbaj mai compact. Chiar dacă măsurătorile de suprapunere a cuvintelor precum ROUGE sunt calculate cu ajutorul referințelor scrise manual, metodele noastre fără referință obțin o corelație semnificativ mai mare cu scorurile fluenței umane pe un set de date de referință de propoziții comprimate. În cele din urmă, prezentăm ROUGE-LM, o metrică bazată pe referință care este o extensie naturală a WPSLOR la cazul referințelor disponibile. Aratăm că ROUGE-LM produce o corelație semnificativ mai mare cu judecățile umane decât toate măsurătorile de bază, inclusiv WPSLOR pe cont propriu.', 'mn': 'Шинэ үед хүлээн зөвшөөрөлтийн магадлалын модель хийх боломжтой зүйлсийн тухай хөдөлгөөндөө бид синтактик лог-odds харьцаа (SLOR), энгийн хэл загварын тоо, байгалийн хэл үйлдвэрлэлийн үржүүлэлтийн тоо хэмжээний хэмжээнд тодорхойлолтгүй шингэний үн Бид дараа нь WPSLOR, WordPiece-д суурилсан шинэ хувилбарыг танилцуулж байна. Энэ нь илүү нарийн хэл загварыг ашигладаг. ROUGE шиг үг дутагдаж байгаа метрикийг гараар бичсэн шуудан тусламжтайгаар тооцоолж байгаа ч, бидний шуудан дутагдалгүй арга нь хүний шингэний хэмжээсүүдтэй илүү өндөр холбоотой болно. Эцэст нь бид ROUGE-LM-г харуулж байна. Энэ нь WPSLOR-ын байгалийн нэмэлт хэмжээний тохиолдлын тохиолдлыг харуулж байна. Бид ROUGE-LM нь хүн төрөлхтний шийдвэрлэлээс илүү өндөр холбоотой гэдгийг харуулж байна.', 'no': 'Forskyving av nyleg oppdagingar om sannsynlige modellering av tilgjengelege sprøytebruk, foreslår vi syntaksisk loggodds- forholdet (SLOR), eit normalisert språk- modellescore, som ein metrisk for å evaluera tilgjengelege flukt på naturspråk- utdata på setningsnivået. Vi introduserer meir WPSLOR, eit romant versjon med WordPiece-basert, som brukar ein meir komprimert språk-modell. Selv om ordoverlapping av metrikar som ROUGE vert rekna ut med hjelp av handskrivne referanser, vil våre referanselese metodar få ein betydelig høgare korrelasjon med menneske fluenspoeng på ein benchmark dataset med komprimerte setningar. I slutt presenterer vi ROUGE-LM, ein referansbasert metrik som er eit naturleg utviding av WPSLOR til tilgjengelege referanser. Vi viser at ROUGE-LM gjev ein betydelig høgare korrelasjon med menneske sprøytebrukar enn alle baseline metrikar, inkludert WPSLOR selv.', 'pl': 'Motywowany ostatnimi wynikami dotyczącymi prawdopodobieństwa modelowania ocen akceptowalności, proponujemy składniowy współczynnik log-odds (SLOR), znormalizowany wynik modelu językowego, jako wskaźnik bezreferencyjnej oceny płynności wyników generowania języka naturalnego na poziomie zdań. Wprowadzamy również WPSLOR, nową wersję opartą na WordPiece, która wykorzystuje bardziej kompaktowy model językowy. Mimo że wskaźniki nakładania się słów, takie jak ROUGE, obliczane są za pomocą ręcznie pisanych referencji, nasze metody bezreferencyjne uzyskują znacznie wyższą korelację z wynikami płynności ludzkiej na zestawie danych referencyjnych skompresowanych zdań. Na koniec przedstawiamy ROUGE-LM, metrykę opartą na referencjach, która jest naturalnym rozszerzeniem WPSLOR do przypadku dostępnych referencji. Pokazujemy, że ROUGE-LM daje znacznie większą korelację z osądami ludzkimi niż wszystkie wskaźniki bazowe, w tym WPSLOR samodzielnie.', 'sr': 'Motivirani nedavnim nalazima o verovatnoj modeliranju osuđivanja prihvatljivosti, predlažemo odnos sintaktičnih log-odds a (SLOR), normalizovan rezultat jezičkog modela, kao metričku za procjenu neposredne tekućine proizvoda prirodnog jezika na nivou rečenice. Dalje predstavljamo WPSLOR, novu verziju baziranu na WordPiece, koja koristi kompaktniji jezički model. Iako su reèi preplavljene metrike poput ROUGE raèunali pomoći rukopisanih referencija, naši bezreferentni metodi dobijaju značajno veæu korelaciju sa rezultatima ljudske teènosti na setu podataka o skloništima kompresivnih rečenica. Konačno predstavljamo ROUGE-LM, na referenciji baziranu metriku koja je prirodna produženja WPSLOR na slučaj dostupnih referencija. Pokazujemo da ROUGE-LM pruža značajno veću korelaciju sa ljudskim osuđivanjem od svih početnih metrika, uključujući i WPSLOR samog.', 'so': "Dhaqdhaqaaqa ugu dambeeyey oo ku saabsan tusaale-sameynta xukunka aqbalka, waxaynu soo jeedaynaa tartanka log odds (SLOR), taasoo ah kooxda qaababka luuqada ee caadiga ah, sida metric u ah qiimeynta faa'iidada dhalashada afka dabiicadda ah. WPSLOR, warqad warqad ah oo WordPiece ku saleysan, kaas oo sameynaya model luuqadeed oo kala duduwan. In kastoo lagu xisaabiyay caawimaadda qoraalka gacanta lagu qoro hadal-overlap-metricooyinka sida ROUGE oo kale, qaababkayaga aan la aqoon lahaynu waxay helaan xiriir aad u weyn oo la xiriira kooxda aqoonta dadku ku qoran kooxda xafiiska qoran. Ugu dambaysta, waxaynu keenaynaa ROUGE-LM, metric ku saleysan reference, kaas oo ah wadista dabiicadda WPSLOR si loo diro xaaladda loo soo jeedo. Waxaynu muujinnaa in ROUGE-LM uu soo saaraa xiriir aad u weyn oo la xiriira xukunnada dadku ka badan dhammaan metric hoose, kuwaas oo ah WPSLOR.", 'sv': 'Mot bakgrund av de senaste rönen om sannolikhetsmodellering av acceptability assessments föreslår vi syntaktiskt log-odds ratio (SLOR), en normaliserad språkmodellpoäng, som ett mått för referenslös flytande utvärdering av naturligt språk generation output på meningsnivå. Vi introducerar vidare WPSLOR, en ny WordPiece-baserad version, som utnyttjar en mer kompakt språkmodell. Även om ord-överlappning mätvärden som ROUGE beräknas med hjälp av handskrivna referenser, erhåller våra referenslösa metoder en betydligt högre korrelation med human fluency scores på en benchmark datauppsättning komprimerade meningar. Slutligen presenterar vi ROUGE-LM, ett referensbaserat mått som är en naturlig förlängning av WPSLOR till fallet med tillgängliga referenser. Vi visar att ROUGE-LM ger en signifikant högre korrelation med mänskliga bedömningar än alla basvärden, inklusive WPSLOR på egen hand.', 'ta': 'அண்மையில் கண்டுபிடிப்புகள் ஏற்றுக் கொள்ளும் தீர்ப்புகளின் மாதிரி முறைமையாக மாற்றியமைக்கப்பட்டது, நாம் ஒத்திசைப்படுத்தும் பதிவுகள் விகிதம் (SLOR), ஒரு சாதாரண மொழி மா நாம் WPSLOR, ஒரு புதிய வார்த்தை பைக் அடிப்படையில் உள்ள பதிப்பு, அது மிகவும் ஒப்பிட்ட மொழி மாதிரியை கொண்டுள்ளது. ROUGE போன்ற வார்த்தை மேல் மேற்கோள்கள் கையில் எழுதப்பட்ட குறிப்புகள் உதவியாலும் கணக்கிடப்பட்டாலும், எங்கள் குறிப்பிடாத முறைகள் சுருக்கப்பட்ட வாக்குகள் மே இறுதியில், நாம் ரூஜ்-LM காண்பிக்கிறோம், ஒரு குறிப்பு அடிப்படையில் உள்ள மெட்ரிக் அது WPSLOR விரிவாக்கம் இருக்கும் குறிப We show that ROUGE-LM yields a significantly higher correlation with human judgments than all baseline metrics, including WPSLOR on its own.', 'si': 'සාමාන්\u200dය භාෂාව මඩෝල් ක්\u200dරියාත්මක විශ්වාසයේ ප්\u200dරතිභාවිත භාෂාව ප්\u200dරතිභාවිත විශ්වාසයේ සංවර්ධනය මඩෝල් ක්\u200dරියාත්මක විශ්වාසයේ සංවර්ධ අපි වැඩියෙන් WPSLOR විදිහට අදහස් කරනවා, WordPiece-අධාරිත සංවිධානයක්, ඒක තව සම්පූර්ණ භාෂාවක් නිර්මා ROUGE වගේ වාර්තාවක් වගේ මෙට්\u200dරික්ස් පරික්ෂා කරලා තියෙනවා නමුත් අපේ වාර්තාවක් ලියපු වාර්තාවක් සඳහා අපේ වාර්තාවක් විශේෂ විදියට මිනිස්සු  අන්තිමේදී, අපි ROUGE-LM වෙනුවෙන්, පිළිබඳින් පිළිබඳ පිළිබඳ ප්\u200dරතිචාරයක් වෙනුවෙන් ප්\u200dරතිචාරිත විස් අපි පෙන්වන්නේ ROUGE-LM එකේ මිනිස්සුන් විශ්වාසයෙන් විශේෂයෙන් වඩා විශේෂයෙන් වඩා විශේෂයෙන් වඩා විශේෂයෙන් වි', 'ur': 'اچھی موجودات کے ذریعے قبول کرنے کے قابل موڈلیس کی موجودات کے ذریعے چلنے والی موجودات کے ذریعے، ہم سینٹکتیک لاگ-اڈس نسبت (SLOR) کو پیشنهاد کرتے ہیں، ایک معمولی زبان موڈل اسکور کے ذریعے ایک متریک ہے، جسم کے سطح میں طبیعی زبان کے پیدا کرنے والوں کی ہم اس سے بھی WPSLOR کو معرفی کرتے ہیں، ایک نوم WordPiece-based ویرجن، جو ایک زیادہ کمپیٹ زبان مدل کرتا ہے۔ اگرچہ روگ جیسی کلمات اورلپ میٹریک کے مطابق ہاتھ لکھی ہوئی ارتباط کے مطابق کمپیوتر کیے جاتے ہیں، ہمارے ارتباط منصوب طریقے انسان کے فلنسیٹ اسکور کے ساتھ بہت زیادہ ارتباط حاصل کرتی ہیں ایک بنچم مارک ڈیٹ سٹ کے مطابق کم بالآخر، ہم روGE-LM کو پیش کرتے ہیں، ایک منطقی منطقی جو WPSLOR کے منطقی منطقی منطقی ہے۔ ہم نشان دیتے ہیں کہ ROUGE-LM نے انسان کے فیصلے سے بہت زیادہ ارتباط حاصل کرتا ہے ہر بنیادی لین متریک سے، جس میں WPSLOR کے ساتھ ہے۔', 'uz': "Yaqinda tasavvur qilingan muvaffaqiyatlarni qabul qilish muvaffaqiyatli modelidagi natijasi modellar bilan ishga tushirilgan imkoniyatlar, biz soʻzning darajada foydalanilgan sintaktik log-oddiy ratio (SLOR), oddiy tillar modeli scorida foydalanuvchi modeli sifatida o'zgarishga ega bo'lgan tizim. Biz yordamchi WordPiece asosida WPSLOR (WordPiece) versiyasini ko'proq bir qiyin tilning modelini ko'rsatamiz. Agar ROUGE kabi so'zlar qoʻllanilgan parametrlar yordam bilan hisoblanadi, bizning umumiy usullarning imkoniyatlarimiz juda katta bogʻ'liq bo'lishi mumkin. Oxirgi, biz RUGE-LM, ma'lumot asosiy metrik, bu WPSLOR asosiy kengaytmasi mavjud boʻlgan parametrlar davomida. Biz ROUGE-LM oddiy xudding hamma baseline metriklarga juda katta munosabatlarini ko'rsatishimiz mumkin, va WPSLOR o'zimdan ham o'zimga ega.", 'vi': 'Động từ những phát hiện gần đây về mô hình xác định của những phán quyết xác nhận được, chúng tôi đề nghị tỉ lệ ghi ghi chép theo hỗn hợp (SLOR), một số mô hình ngôn ngữ bình thường, như một thước đo để đánh giá ngẫu nhiên sản phẩm sản xuất ra ngôn ngữ tự nhiên ở mức án. Chúng tôi xin giới thiệu WSLOR, một phiên bản mới căn cứ WordStuff, đã khai thác một mô hình ngôn ngữ gọn hơn. Mặc dù các âm lượng chữ trộn với nhiều từ như ROLạ được tính bằng sự trợ giúp của các chỉ dẫn viết tay, các phương pháp không liên quan của chúng tôi đạt được mối tương quan cao hơn với điểm lưu của con người trên một tập tin tập tin tập trung bằng tiêu chuẩn. Cuối cùng, chúng tôi xin giới thiệu ROCE-LM, một hệ số dựa vào tham khảo, một phiên bản tự nhiên mở rộng WSLOR vào trường hợp có tài liệu. Chúng tôi cho thấy rằng ROCE-LM cung cấp một mối tương quan lớn với các phán xét con người hơn tất cả các âm lượng cơ bản, bao gồm WSLOR một mình.', 'nl': 'Gemotiveerd door recente bevindingen over de probabilistische modellering van acceptabiliteitsoordelen, stellen we syntactische log-odds ratio (SLOR) voor, een genormaliseerde taalmodel score, als maatstaf voor referentieloze vloeiende evaluatie van natuurlijke taalgeneratie output op zinsniveau. We introduceren verder WPSLOR, een nieuwe WordPiece-gebaseerde versie, die gebruik maakt van een compacter taalmodel. Hoewel woordoverlappingsmetrieken zoals ROUGE worden berekend met behulp van handgeschreven referenties, verkrijgen onze referentieloze methoden een significant hogere correlatie met menselijke vloeibaarheidsscores op een benchmark dataset van gecomprimeerde zinnen. Tot slot presenteren we ROUGE-LM, een referentie-gebaseerde metric die een natuurlijke uitbreiding van WPSLOR is naar het geval van beschikbare referenties. We tonen aan dat ROUGE-LM een significant hogere correlatie met menselijke oordelen oplevert dan alle baseline metrics, inclusief WPSLOR op zichzelf.', 'bg': 'Мотивирани от последните открития за вероятностното моделиране на присъдите за приемливост, ние предлагаме синтактично лого-коефициентно съотношение (СЛОР), нормализиран езиков модел, като метричен показател за оценка на безпрепятствеността на изхода от генерирането на естествен език на ниво изречение. Освен това представяме нова версия, базирана на която се възползва от по-компактен езиков модел. Въпреки че показателите за припокриване на думата като се изчисляват с помощта на ръчно написани препратки, нашите методи без препратки получават значително по-висока корелация с оценките на човешката плавност на сравнителен набор от данни от компресирани изречения. На последно място, представяме референтен метрик, който е естествено разширение на WPSLOR към случая на налични референции. Показваме, че дава значително по-висока корелация с човешките преценки, отколкото всички базови показатели, включително самостоятелно.', 'hr': 'Motivirani nedavnim nalazima o vjerojatnom modelizaciji osuđivanja prihvatljivosti, predlažemo odnos sintaktičkih log-odds a (SLOR), normalizirani rezultat jezičkog modela, kao metričku za procjenu neposredne tekućine proizvoda prirodnog jezika na razini rečenice. Dalje predstavljamo WPSLOR, novu verziju baziranu na WordPiece, koja koristi kompaktniji jezički model. Iako su riječi preklapanje metrika poput ROUGE računali pomoći rukopisanih referencija, naši bezreferensni metodi dobivaju značajno veću korelaciju sa rezultatima ljudske tekućine na setu podataka o sklopnici kompresivnih rečenica. Konačno predstavljamo ROUGE-LM, na referenciji baziranu metriku koja je prirodno produženje WPSLOR u slučaju dostupnih referencija. Pokazujemo da ROUGE-LM pruža značajno veću korelaciju s ljudskim osuđivanjem od svih početnih metrika, uključujući i WPSLOR samog.', 'id': 'Motivated by recent findings on the probabilistic modeling of acceptability judgments, we propose syntactic log-odds ratio (SLOR), a normalized language model score, as a metric for irreferential fluency evaluation of natural language generation output at the sentence level. Kami lebih lanjut memperkenalkan WPSLOR, versi baru berdasarkan WordPiece, yang menggunakan model bahasa yang lebih kompak. Meskipun metrik kata-overlap seperti ROUGE dihitung dengan bantuan referensi tulis tangan, metode kita tanpa referensi mendapatkan korelasi yang jauh lebih tinggi dengan skor fluency manusia pada set data benchmark kalimat kompresi. Akhirnya, kami mempersembahkan ROUGE-LM, metrik berdasarkan referensi yang merupakan ekstensi alami WPSLOR untuk kasus referensi yang tersedia. Kami menunjukkan bahwa ROUGE-LM memberikan korelasi yang lebih tinggi dengan penilaian manusia daripada semua metrik dasar, termasuk WPSLOR sendiri.', 'da': 'Motiveret af nylige fund på den sandsynlighedsmæssige modellering af acceptability domme, foreslår vi syntaktisk log-odds ratio (SLOR), en normaliseret sprogmodel score, som en metric for referenceløs flydende evaluering af naturligt sprog generering output på sætningsniveau. Vi introducerer endvidere WPSLOR, en ny WordPiece-baseret version, som udnytter en mere kompakt sprogmodel. Selvom ord-overlapning metrics som ROUGE beregnes ved hjælp af håndskrevne referencer, opnår vores referenceløse metoder en betydeligt højere korrelation med menneskelige fluency scores på et benchmark datasæt af komprimerede sætninger. Endelig præsenterer vi ROUGE-LM, en referencebaseret metric, som er en naturlig udvidelse af WPSLOR til tilfælde af tilgængelige referencer. Vi viser, at ROUGE-LM giver en betydeligt højere korrelation med menneskelige vurderinger end alle baseline metrics, herunder WPSLOR alene.', 'ko': '최근 수용성 판단 확률 모델링에 대한 연구 결과를 토대로 우리는 문법 대수 우위비(SLOR), 규범화된 언어 모델 점수를 제시하여 문장 차원의 자연 언어 생성 출력에 참고할 수 없는 유창성 평가 지표로 삼았다.우리는 WPSLOR를 한층 더 소개했는데, 이것은 문자를 바탕으로 한 새로운 버전으로, 더욱 치밀한 언어 모델을 이용했다.비록 연지와 같은 단어 중첩 지표는 손으로 쓴 참고 문헌을 통해 계산된 것이지만 우리의 무참고 방법은 문장을 압축하는 기준 데이터 집합에서 인류의 유창도 득점과 관련성이 현저히 높다.마지막으로 우리는 참고를 바탕으로 하는 도량인 ROUGE-LM을 제시했는데 이것은 WPSLOR가 참고할 수 있는 상황에서 자연적으로 확장된 것이다.ROUGE-LM은 모든 베이스라인 지표(WPSLOR 포함)에 비해 인간 판단과 관련성이 현저히 높다는 것을 알 수 있습니다.', 'de': 'Motiviert durch aktuelle Erkenntnisse zur probabilistischen Modellierung von Akzeptabilitätsurteilen, schlagen wir syntaktisches Log-Odds Ratio (SLOR) vor, einen normalisierten Sprachmodellscore, als Metrik zur referenzlosen Fluenzbewertung natürlicher Sprachgenerierungsausgaben auf Satzebene. Wir stellen außerdem WPSLOR vor, eine neuartige WordPiece-basierte Version, die ein kompakteres Sprachmodell nutzt. Obwohl Wortüberlappungsmetriken wie ROUGE mit Hilfe von handschriftlichen Referenzen berechnet werden, erhalten unsere referenzlosen Methoden eine deutlich höhere Korrelation mit menschlichen Fluency Scores auf einem Benchmark-Datensatz komprimierter Sätze. Abschließend stellen wir ROUGE-LM vor, eine referenzbasierte Metrik, die eine natürliche Erweiterung von WPSLOR auf den Fall verfügbarer Referenzen darstellt. Wir zeigen, dass ROUGE-LM eine signifikant höhere Korrelation mit menschlichen Urteilen aufweist als alle Basismetriken, einschließlich WPSLOR allein.', 'sw': 'Hatua ya matokeo ya hivi karibuni kuhusiana na uwezekano wa kuonyesha maamuzi yanayoweza kukubalika, tunapendekeza kiwango cha uamuzi wa kujilogu (SLOR), kipimo cha model ya lugha ya kawaida, kama mtindo wa uchunguzi wa ufahamu wa uchunguzi wa uzalishaji wa lugha asilia katika kiwango cha hukumu. Tunaonyesha zaidi WPSLOR, toleo la riwaya la WordPiece, ambalo lina mtindo wa lugha yenye makubaliano zaidi. Ingawa mitindo ya upana wa maneno kama vile ROUGE inakadiriwa kwa msaada wa maoni yaliyoandikwa mikononi, mbinu zetu zisizo na maana yanaweza kupata uhusiano mkubwa zaidi na vipimo vya usafiri vya binadamu kwenye seti ya taarifa za benchmark yenye seti za hukumu zilizotengwa. Finally, we present ROUGE-LM, a reference-based metric which is a natural extension of WPSLOR to the case of available references.  Tunaonyesha kuwa ROUGE-LM hutoa uhusiano mkubwa na maamuzi ya binadamu kuliko mitindo yote ya msingi, ikiwa ni pamoja na WPSLOR yenyewe.', 'sq': 'Motivuar nga gjetjet e fundit mbi modelimin probabilist të gjykimeve të pranueshmërisë, ne propozojmë raportin sintaktik log-odds (SLOR), një rezultat i modelit të gjuhës normalizuar, si një metrik për vlerësimin e fluencës pa referencë të prodhimit natyror të gjenerimit të gjuhës në nivelin e fjalimit. Ne prezantojmë më tej WPSLOR, një version i ri me bazë në WordPiece, që përdorë një model gjuhësh më kompakt. Edhe pse metrikat e përmbysjes së fjalëve si ROUGE janë llogaritur me ndihmën e referimeve të shkruara me dorë, metodat tona të pa referim marrin një korrelacion më të lartë me rezultatet e fluencës njerëzore në një bazë të dhënash të paraqitjeve të shtypura. Më në fund, ne prezantojmë ROUGE-LM, një metrik bazuar në referim që është një zgjerim natyror i WPSLOR në rastin e referimeve të disponueshme. Ne tregojmë se ROUGE-LM jep një korrelacion më të lartë me gjykimet njerëzore se të gjitha metrikat bazë, duke përfshirë WPSLOR vetëm.', 'am': 'በቅርብ ዘመን በተቀናቀው የድምፅ ፍርድ ማሳየት በተቻለኝነት የፍላጎት የቋንቋ ትውልድ ፍጥረት ማሳየት የሚችሉትን ፍጥረት እናሳውቃለን፡፡ አዲስ የቋንቋ ምሳሌ የሚደረገውን የዋና ቃላት አዲስ ፊሌክን እናሳየዋለን፡፡ ምንም እንኳን ቃላት-ላይ-overlap-metric እንደ ROUGE በእጅ-ጽሑፍ መልዕክቶች በተቆጠሩ ቢሆንም እንኳ የግልፅ ሥርዓታችን ከህዝብ ውጤት ጋር በሰው ፍጥረት ነጥቦች ላይ በbenchmark ዳርቻ በተጨማሪው ክፍሎች ላይ ትልቅ ግንኙነት ያገኛል፡፡ በመጨረሻም፣ የውይይት ግንኙነት የWPSLOR የፍጥረት ስፋት ነው፡፡ ROUGE-LM ከሰው ፍርድ ሁሉ ይልቅ የበለጠ ግንኙነት እንዲያሳየው እናሳየዋለን፤ የWPSLOR በራሱ ነው።', 'af': "Gebeweging deur onlangse bevestings op die waarskynlike modellering van aanvaarbaardige oordelings, voorstel ons sintaktiële log-odds verhouding (SLOR), â\x80\x99n normaliseerde taal model telling, as 'n metriek vir verwysing van verwysing van natuurlike taal generasie uitset op die voorwerp vlak. Ons introduseer WPSLOR verder, 'n novele WordPiece-gebaseerde weergawe, wat 'n meer kompakte taal model gebruik. Selfs al is woord-oorvloei metries soos ROUGE bereken word met die hulp van hand-skryfe verwysings, ons verwysing-metodes kry 'n betekenlik hoër korrelasie met menslike fluiditeitstelling op 'n benchmark datastel van komprimeerde setings. Eindelik, ons voorsien ROUGE-LM, 'n verwysing-gebaseerde metrie wat is 'n natuurlike uitbreiding van WPSLOR na die geval van beskikbare verwysing. Ons wys dat ROUGE-LM 'n betekeurige hoër korrelasie verkry met menslike oordelings as al die basisline metries, insluitend WPSLOR op sy eie.", 'tr': "Ýakynda kabul etmek ahyrlamasynyň mümkinçilik modinde görkezilen tapylar, sözlemde syntaktik log-oddaklaryň (SLOR) tersini teklip edip, diňe düzümlenmiş dil modinde baýramçylygyň netijesi ýüklemesi üçin bir metrik. Biz WPSLOR'a daşykdan belleýäris, WordPiece tabanly bir nowelladyr we ol kän bir dil nusgasyny ulanýar. ROUGE ýaly sözlerniň üstünden geçmesi üçin elimize ýazylan sözlerin kömegi bilen hasaplanýar. Referanslarymyz adamlaryň flukans notlarynyň üstünde bir şekilde ýokary bir correlasyon berir. Soňunda, ROUGE-LM'i, daşary tabanly metriýa görkez. Bu WPSLOR'yň daşary çykyşlaryň hasaplarynyň daşary bir döwletini görkez. ROUGE-LM'nin insan hakkıyla bütün temel metriklerden, WPSLOR'yň özi bilen ylalaşyklaryndan daha yüksek bir bağlantısını etýändigini gösteriyoruz.", 'fa': 'توسط نتیجه\u200cهای اخیر در مورد مولد احتمالات قابلیت تصمیم پذیرفتگی حرکت شده، نسبت لاگ-شانس سنتاکتیک (SLOR) پیشنهاد می\u200cکنیم، یک امتیاز مدل زبان معمولی، به عنوان یک متریک برای ارزیابی آلودگی آلودگی نسبت زبان طبیعی در سطح جمله. ما دیگر WPSLOR را معرفی می کنیم، یک نسخه نویسی بر اساس WordPiece که یک مدل زبان پیچیده\u200cتر را استفاده می\u200cکند. با وجود اینکه متریک\u200cهای کلمه\u200cای مثل ROUGE با کمک ارتباط\u200cهای دست نوشته شده\u200cاند، روش\u200cهای بی\u200cارتباط ما ارتباط بسیار بالاتر با امتیاز آلودگی انسان در مجموعه\u200cهای داده\u200cهای صندوق\u200cبندی از جمله\u200cهای زلزله می\u200cیابند. بالاخره، ما روج-LM را نشان می دهیم، متریک بر اساس مربوط به مربوط به مربوط به آن که یک طول طبیعی از WPSLOR به پرونده مربوط به موضوع موجود است. ما نشان می دهیم که ROUGE-LM یک ارتباط بسیار بالاتر با قضاوت انسان از تمام متریک\u200cهای پایه\u200cخط، شامل WPSLOR تنها است.', 'hy': 'Հրաշարժված ընդունակության դատողությունների հավանական մոդելավորման վերջին հայտնաբերություններից, մենք առաջարկում ենք սինտակտիկ լոգ-հավանականության հարաբերակցություն (SIOR), նորմալ լեզվի մոդելի գնահատականը, որպես մետրիկ նախադասության մակարդակում բնական լեզվի ստեղծման արտադրության անհաղորդակ We further introduce WPSLOR, a novel WordPiece-based version, which harnesses a more compact language model.  Չնայած, որ ROUGe-ի նման բառերի հատուկ չափումները հաշվարկվում են ձեռքով գրված հաղորդակցությունների օգնությամբ, մեր անհաղորդակցության մեթոդները հասնում են նշանակաբար ավելի բարձր կապ մարդկային հեղության գնահատականների հետ ճնշված նախադասությունների համեմատային տվյալ Վերջապես, մենք ներկայացնում ենք ROUGe-LM-ը, հաղորդակցման հիմնված մետրիկ, որը ՀԱՊՍԼՕրի բնական ընդլայնումն է հասանելի հաղորդակցման դեպքում: Մենք ցույց ենք տալիս, որ ROUGe-LM-ը նշանակաբար ավելի բարձր կապ է տալիս մարդկային դատողությունների հետ, քան բոլոր հիմնական չափումները, ներառյալ միայնակ ՎՊՍԼՕրը:', 'az': "Qəbul edilmə mümkünlüyü təsdiqlərinin mümkün modelləşdirməsi haqqında son keçənlər tərəfindən, sintaktik log-odds ratio (SLOR) təklif edirik, normalizə dil modellərin nöqtəsi olaraq, təbiətli dil ürəklərinin çıxarılması üçün metrik olaraq. Biz artıq WPSLOR'i, WordPiece-ə dayanan yeni versiyonu təşkil edirik ki, daha kompakt dil modeli ilə istifadə edir. ROUGE kimi söz-a şağılıq metriklərinin əl yazılmış referans ilə hesablanılmasına rağmen, bizim referansız metodlarımız sıkıştırılmış cümlələrin benchmark verilənlərin dəyişiklik dəyişiklikləri ilə daha yüksək bir bağlantı elde edər. Sonunda, biz ROUGE-LM'i, referans-tabanlı metrik göstəririk ki, WPSLOR'ın doğal uzantısı mümkün referans olaraq. Biz ROUGE-LM'nin insan hökmünü bütün baseline metriklərindən daha yüksək bir bağlantısı yaratdığını göstəririk, WPSLOR'u da yalnız özlərinə daxil edir.", 'bn': 'সম্প্রতি সম্ভবত গ্রহণযোগ্য বিচারের সম্ভাব্য মডেলিং সম্পর্কে সাম্প্রতিক খুঁজে প্রস্তাব করেছি, আমরা সাধারণ ভাষার মডেল স্কোর প্রস্তাব করছি, যা প্রাকৃতিক ভাষার প্রজন্মের প্রজন্ আমরা আরো ওয়ার্ডপিইজ ভিত্তিক সংস্করণ উইপিসলোর পরিচয় করিয়ে দিচ্ছি, যা আরো কম্পিকেট ভাষার মডেলের সাথে আছে। যদিও রুজের মত শব্দ-আপ্লেপ মেট্রিক হাতে লেখা রেফারেশনের সাহায্যে হিসেবে হিসেবে গণনা করা হয়, তবুও আমাদের গণহীন পদ্ধতি মানুষের ফ্লুইসি স্কোরের সাথে মান শেষ পর্যন্ত আমরা রুজের-এলএম উপস্থাপন করছি, একটি রেফারেন্স ভিত্তিক মেট্রিক যা প্রাকৃতিক বিস্তারিত বিস্তারিত বিস্তারিত বি আমরা দেখাচ্ছি যে রুজের-এলএম মানুষের বিচারের সাথে মানুষের সম্পর্ক বেশী বেশী উচ্চতা প্রদান করে, যার মধ্যে উইপিসলোর নিজের মধ্', 'cs': 'Na základě nedávných poznatků o pravděpodobnostním modelování hodnocení akceptability navrhujeme syntaktický log-odds ratio (SLOR), normalizovaný jazykový model skóre, jako metriku pro bezreferenční hodnocení plynulosti výstupu generace přirozeného jazyka na úrovni věty. Dále představujeme WPSLOR, novou verzi založenou na WordPiece, která využívá kompaktnější jazykový model. I když jsou metriky překrývání slov jako ROUGE vypočítány pomocí ručně psaných referencí, naše bezreferenční metody dosahují výrazně vyšší korelace s lidským skórem plynulosti na referenční sadě komprimovaných vět. Na závěr představujeme ROUGE-LM, referenční metriku založenou na referencích, která je přirozeným rozšířením WPSLOR na případ dostupných referencí. Ukazujeme, že ROUGE-LM přináší výrazně vyšší korelaci s lidskými úsudky než všechny základní metriky, včetně WPSLOR samotného.', 'bs': 'Motivirani nedavnim nalazima o verovatnoj modeliranju osuđivanja prihvatljivosti, predlažemo odnos sintaktičnih log-odds a (SLOR), normalizirani rezultat jezičkog modela, kao metričku za procjenu neposredne tekućine proizvodnje prirodnog jezika na nivou rečenice. Dalje predstavljamo WPSLOR, novu verziju baziranu na WordPiece, koja koristi kompaktniji jezički model. Iako se riječi preoklapaju metrike poput ROUGE računaju pomoći rukopisanih referencija, naši bezreferentni metodi dobijaju značajno veću korelaciju sa rezultatima ljudske tekućine na setu podataka o sklopnici kompresivnih rečenica. Konačno predstavljamo ROUGE-LM, na referenciji baziranu metriku koja je prirodna produženja WPSLOR na slučaj dostupnih referencija. Pokazujemo da ROUGE-LM pruža značajno veću korelaciju sa ljudskim osuđivanjem od svih početnih metrika, uključujući i WPSLOR samog.', 'ca': "Motivat pels descobriments recents sobre el modelatge probabilístic dels judicis d'acceptabilitat, proposem una proporció sinàctica de probabilitats de rexistru (SLOR), una puntuació normalitzada del model de llenguatge, com a mètrica per a l'evaluació de la fluència sense referència de la producció natural de la generació de llenguatges a nivell de frases. Anem a introduir WPSLOR, una nova versió basada en WordPiece, que utilitza un model de llenguatge més compacte. Encara que les metètriques de sobreposició de paraules com ROUGE es calculen amb l'ajuda de referències escrites a mà, els nostres mètodes sense referències obtenen una correlació significativament més alta amb els punts de fluència humana en un conjunt de dades de referència de frases comprimides. Finalment, presentem ROUGE-LM, una mètrica basada en referència que és una extensió natural de WPSLOR al cas de referències disponibles. Mostrem que ROUGE-LM produeix una correlació significativament més alta amb els judicis humans que tots els mètrics de base, incloent WPSLOR sol.", 'et': 'Soovitatud hiljutistest leidudest aktsepteeritavuse otsuste tõenäosusliku modelleerimise kohta, pakume välja süntaktilise log-odds ratio (SLOR), normaliseeritud keelemudeli skoori, mis on mõõdik looduskeele genereerimise väljundi viiteta sujuvuse hindamiseks lausetasemel. Lisaks tutvustame WPSLOR-i, uudset WordPiece-põhist versiooni, mis kasutab kompaktsemat keelemudelit. Kuigi sõna kattuvuse mõõdikuid, nagu ROUGE, arvutatakse käsitsi kirjutatud viitete abil, saavutavad meie viiteta meetodid oluliselt suurema korrelatsiooni inimese voolavuse skooridega tihendatud lausete võrdlusandmekogumil. Lõpuks esitame ROUGE-LM, viitepõhine mõõdik, mis on WPSLOR loomulik laiendus olemasolevate viitete puhul. Näitame, et ROUGE-LM annab oluliselt suurema korrelatsiooni inimeste hinnangutega kui kõik baasmõõdikud, sealhulgas WPSLOR eraldi.', 'fi': 'Tuoreimpien hyvﾃ､ksyttﾃ､vyyskatsausten todennﾃ､kﾃｶisyysmallinnuksen lﾃｶydﾃｶsten pohjalta ehdotamme syntaktista log-odds ratiota (SLOR), normalisoitua kielimallin pisteytystﾃ､, mittarina luonnollisen kielen tuottamisen tuloksen viitearvon arviointiin lausetasolla. Lisﾃ､ksi esittelemme WPSLORin, uuden WordPiece-pohjaisen version, joka valjastaa kompaktimman kielimallin. Vaikka sanapﾃ､ﾃ､llekkﾃ､isyysmittarit, kuten ROUGE, lasketaan kﾃ､sin kirjoitettujen viitteiden avulla, viittauksettomat menetelmﾃ､mme saavat huomattavasti suuremman korrelaation ihmisen sujuvuuspisteiden kanssa tiivistettyjen lauseiden vertailuaineistossa. Lopuksi esittelemme ROUGE-LM:n, referenssipohjaisen mittarin, joka on WPSLOR:n luonnollinen laajennus saatavilla olevien viitteiden tapauksessa. Osoitamme, ettﾃ､ ROUGE-LM:llﾃ､ on huomattavasti suurempi korrelaatio inhimillisten arviointien kanssa kuin kaikilla perusmittareilla, mukaan lukien WPSLOR yksinﾃ､ﾃ､n.', 'jv': 'Ngubah yakunh dumadhi sing paling nggawe barang nggawe modalistik bukal gawe ngubah perusahaan, kita supoyo nggawe log-ahes (SLAR), dadi model sing usul, dadi metir kanggo Kemerdekaan kang nglangbar uwong sing paling maneh dumadhi. Awak dhéwé nglanggar wih-wih nggawe WPALOR, dadi versi sing sembarang kelas word-Pêse, sing ngewat ujaran modèl luwih apik. Nombo tresnane mengko perusahaan maneh dumateng manut karo nggawe barang manut Ero, kita nambah LOUGE Awak dhéwé éntukno LOUGE-LM kuwi wis nggawe gerakan luwih dumadhi karo hal-hal sing luwih dumadhi kuwi nggawe barang kelas kuwi nggawe barang iki luwih dumadhi, karo WPALOR uwong sing wis ana.', 'ha': "Motsar da fassaran kwanan da suka samu a kan mai yiwuwa ya samu'ar motsi ga masu yarda da hukuncin, tuna bubuɗar da fasarin logogi-odd (SLR), wata nau'in misalin harshe mai daidaita, kamar metric wa ƙidãya na ƙidãya ga masu ƙarshen zafi na cikin salon da ke cikin muhalli. Za iya ƙara da WPSLR, wani version na nan da aka rubũta wordPiece, wanda yana sami wani misali da ke ƙaranci. Haƙĩƙa, kuma kõ da aka lissafa kalmar-rufe metric kamar RuUGE da taimakon yin rubũtãwa da hannayen rubũtãwa, za'a sami hanyar da ba'a rubutu ba, da hanyoyinmu za'a sami wata significant mafi girma da danganci na fassarar mutane a kan danne-danne na fassarar azãba. Haƙĩƙa, Munã halatar da RUGE-LM, wata metric mai fassara da aka ƙayyade ta, wanda ke samar da watannin WPSLR zuwa masu takarda misãlai. Tuna nũna wa, RUGE-LM yana ƙara wata muhimmanci da ma'abũcin hukuncin mutane ne mafi girma daga duk metric bakwai, da kuma WPSLR na kansa.", 'sk': 'Na podlagi nedavnih ugotovitev verjetnostnega modeliranja sodb o sprejemljivosti predlagamo sintaktično razmerje log-odds ratio (SLOR), normalizirano rezultat jezikovnega modela, kot metrično mero za brezreferenčno vrednotenje tekočosti produkcije naravnega jezika na ravni stavka. Predstavljamo vam tudi WPSLOR, novo različico WordPiece, ki izkorišča bolj kompakten jezikovni model. Čeprav so meritve prekrivanja besed, kot je ROUGE, izračunane s pomočjo ročno napisanih referenc, naše brezreferenčne metode dosežejo bistveno višjo korelacijo z ocenami tekočine človeka na referenčnem naboru stisnjenih stavkov. Na koncu predstavljamo ROUGE-LM, referenčno merilo, ki je naravna razširitev WPSLOR za primer razpoložljivih referenc. Pokazali smo, da ROUGE-LM prinaša bistveno višjo korelacijo s človeškimi presojami kot vse osnovne meritve, vključno z WPSLOR samostojno.', 'he': 'מוטיבציה על ידי הממצאים האחרונים על הדוגמה הסבירוליסטית של שיפוטים קבילים, אנו מציעים יחסי לוג-סיכוי סינטקטי (SLOR), נקודת דוגמנית שפה נורמלית, כמטריקה לערכת נוזלות ללא קשר של יציאה של יוצר שפה טבעית ברמה המשפט. אנחנו מכירים עוד WPSLOR, גרסה חדשה מבוססת WordPiece, שמשתמשת במודל שפה יותר kompact. למרות שמטריקות כפולות מילים כמו ROUGE מחשבות עם עזרה של התייחסות כתובות יד, השיטות הלא-התייחסות שלנו מקבלים תקשורת גבוהה יותר משמעותית עם נקודות נוזלות אנושית על קבוצת נתונים של משפטים דחוסים. סוף סוף, אנו מציגים ROUGE-LM, מטריקה מבוססת על התייחסות שהיא התרחבות טבעית של WPSLOR למקרה של התייחסות זמינות. אנו מראים כי ROUGE-LM מוביל תקשורת גבוהה יותר משמעותית עם השיפוטים האנושיים מכל המטריקות הבסיסיות, כולל WPSLOR בעצמו.', 'bo': 'Motivated by recent findings on the probabilistic modeling of acceptability judgments, we propose syntactic log-odds ratio (SLOR), a normalized language model score, as a metric for referenceless fluency evaluation of natural language generation output at the sentence level. We further introduce WPSLOR, a novel WordPiece-based version, which harnesses a more compact language model. Even though word-overlap metrics like ROUGE are computed with the help of hand-written references, our referenceless methods obtain a significantly higher correlation with human fluency scores on a benchmark dataset of compressed sentences. Finally, we present ROUGE-LM, a reference-based metric which is a natural extension of WPSLOR to the case of available references. We show that ROUGE-LM yields a significantly higher correlation with human judgments than all baseline metrics, including WPSLOR on its own.'}
{'en': 'Predefined Sparseness in Recurrent Sequence Models', 'ar': 'تناثر محدد مسبقًا في نماذج التسلسل المتكرر', 'es': 'Disparidad predefinida en modelos de secuencias recurrentes', 'fr': 'Intensité prédéfinie dans les modèles de séquences récurrentes', 'pt': 'Esparsidade predefinida em modelos de sequência recorrente', 'ja': '反復配列モデルにおける事前定義されたまばらさ', 'zh': '循环序模中预定义疏性', 'hi': 'आवर्तक अनुक्रम मॉडल में पूर्वनिर्धारित विरलता', 'ru': 'Заранее определенная разреженность в моделях с рекуррентной последовательностью', 'ga': 'Ganntanas Réamhshainithe i Múnlaí Seichimh Athfhillteacha', 'ka': 'მხოლოდ განსაზღვრული სივრცე მოდელში', 'hu': 'Előre definiált gyengeség az ismétlődő szekvencia modellekben', 'el': 'Προκαθορισμένη σπανιότητα σε μοντέλα επαναλαμβανόμενης ακολουθίας', 'it': 'Sparacia predefinita nei modelli di sequenza ricorrente', 'kk': 'Қайталанған реттеу үлгілерінде алдында анықталған кеңістігі', 'mk': 'Predefined Sparseness in Recurrent Sequence Models', 'lt': 'Predefined Sparseness in Recurrent Sequence Models', 'ms': 'Keputusan Ditakrifkan Dalam Model Sekuensi Berulang', 'ml': 'Predefined Sparseness in Recurrent Sequence Models', 'mt': 'Ħafna definita minn qabel f’Mudelli ta’ Sekwenza Rikorrenti', 'mn': 'Өмнө тодорхойлсон хэмжээний загвар', 'pl': 'Wcześniej zdefiniowana oszczędność w modelach sekwencji powtarzającej się', 'sr': 'Предефинирана пространство у моделима повторног поредности', 'no': 'Førehandsdefinert mellomrom i gjentakelige sekvensmodeller', 'ro': 'Sparsență predefinită în modelele de secvență recurentă', 'si': 'ප්\u200dරතිනිර්ධාරිත විශේෂ විශේෂ විශේෂතා', 'so': 'Iswidhish horay u defined in Recurrence Models', 'ta': 'Predefined Sparseness in Recurrent Sequence Models', 'sv': 'Fördefinierad sparsamhet i återkommande sekvensmodeller', 'ur': 'دوبارہ سکوئنس موڈل میں پیش دکھائی ہوئی فاصلہ', 'uz': 'Davom etish', 'vi': 'Hiệu ứng trước trong chế độ lặp lại', 'nl': 'Vooraf gedefinieerde schaarste in Recurrent Sequence Modellen', 'bg': 'Предварително дефинирана оскъдност в повтарящи се последователни модели', 'da': 'Foruddefineret sparsomhed i tilbagevendende sekvensmodeller', 'hr': 'Predefinirana širenost u modelima povratne sekvence', 'de': 'Vordefinierte Sparseness in Recurrent Sequence Modellen', 'id': 'Keputusan Predefinisi dalam Model Sekuensi Berulang', 'fa': 'فاصله پیش\u200cتعریف در مدل\u200cهای دوباره\u200c', 'tr': 'Geditiň Girişi nusgala', 'af': 'Vooraf gedefinieerde spasiëring in Herhaling Volgorde Modelle', 'sq': 'Shpejtësia e paracaktuar në modelet e sekuencës së përsëritur', 'sw': 'Uhispania wa Tayari', 'am': 'ምርጫዎች', 'hy': 'Վերջին հաջորդականության մոդելներում', 'ko': '귀속 시퀀스 모델의 미리 정의된 희소성', 'bs': 'Predefinirana širenost u modelima povratne sekvence', 'az': 'GediŇüan sńĪralama modell…ôrind…ô …ôvv…ôl t…ôyin edilmiŇü boŇüluq', 'bn': 'পুনরাবৃত্ত সেকেন্স মোডেলের মধ্যে স্পের্সের সূচনা', 'ca': "L'escassetat predefinida en models de seqüència recurrent", 'et': 'Eelnevalt määratletud vähesus korduvate jadade mudelites', 'fi': 'Ennalta määritetty niukkuus toistuvissa sekvenssimalleissa', 'cs': 'Předem definovaná omezenost v modelech opakovaných sekvencí', 'jv': 'echoH e l l o space w o r l d periodHelloworldHello worldkey echo', 'ha': '@ action', 'sk': 'Vnaprej določena pomanjkljivost v modelih ponavljajočih se zaporedj', 'he': 'ספירות מוגדרת מראש במדלים רצף מתחזרים', 'bo': 'སྔོན་སྒྲིག་འཛུགས་པའི་བར་སྟོང་རུང་བསྐྱར་གསོག་པའི་མ་དབྱིབས'}
{'en': 'Inducing sparseness while training ', 'ar': 'لقد ثبت أن إحداث تناثر أثناء تدريب الشبكات العصبية ينتج نماذج ذات بصمة ذاكرة أقل ولكن فعالية مماثلة للنماذج الكثيفة. ومع ذلك ، عادةً ما يتم تحفيز التباعد بدءًا من نموذج كثيف ، وبالتالي لا تصمد هذه الميزة أثناء التدريب. نقترح تقنيات لفرض التباين مقدمًا في نماذج التسلسل المتكرر لتطبيقات البرمجة اللغوية العصبية ، للاستفادة أيضًا من التدريب. أولاً ، في نمذجة اللغة ، نعرض كيفية زيادة أحجام الحالة المخفية في الطبقات المتكررة دون زيادة عدد المعلمات ، مما يؤدي إلى نماذج أكثر تعبيرًا. ثانيًا ، بالنسبة إلى وضع العلامات على التسلسل ، نوضح أن عمليات دمج الكلمات ذات التباين المحدد مسبقًا تؤدي إلى أداء مشابه لأداء الزخارف الكثيفة ، بجزء صغير من عدد المعلمات القابلة للتدريب.', 'fr': "Il a été démontré que le fait d'induire une faible densité lors de l'entraînement des réseaux de neurones donne des modèles avec une empreinte mémoire moindre mais une efficacité similaire à celle des modèles denses. Cependant, la dispersion est généralement induite à partir d'un modèle dense, et cet avantage ne tient donc pas pendant l'entraînement. Nous proposons des techniques pour appliquer la dispersion dès le départ dans les modèles de séquences récurrentes pour les applications de PNL, afin de bénéficier également à la formation. Tout d'abord, dans la modélisation du langage, nous montrons comment augmenter la taille des états cachés dans les couches récurrentes sans augmenter le nombre de paramètres, ce qui conduit à des modèles plus expressifs. Deuxièmement, pour l'étiquetage de séquence, nous montrons que les intégrations de mots avec une dispersion prédéfinie conduisent à des performances similaires à celles des intégrations denses, pour une fraction du nombre de paramètres pouvant être entraînés.", 'es': 'Se ha demostrado que inducir escasez durante el entrenamiento de redes neuronales produce modelos con una huella de memoria más baja pero una eficacia similar a los modelos densos. Sin embargo, la escasez generalmente se induce a partir de un modelo denso y, por lo tanto, esta ventaja no se mantiene durante el entrenamiento. Proponemos técnicas para imponer la escasez por adelantado en los modelos de secuencia recurrente para aplicaciones de PNL, para beneficiar también la capacitación. Primero, en el modelado del lenguaje, mostramos cómo aumentar los tamaños de estados ocultos en capas recurrentes sin aumentar el número de parámetros, lo que lleva a modelos más expresivos. En segundo lugar, para el etiquetado de secuencias, mostramos que las incrustaciones de palabras con dispersión predefinida conducen a un rendimiento similar al de las incrustaciones densas, en una fracción del número de parámetros entrenables.', 'pt': 'A indução de esparsidade durante o treinamento de redes neurais mostrou produzir modelos com menor pegada de memória, mas eficácia semelhante a modelos densos. No entanto, a esparsidade é tipicamente induzida a partir de um modelo denso e, portanto, essa vantagem não se mantém durante o treinamento. Propomos técnicas para impor a esparsidade antecipadamente em modelos de sequência recorrentes para aplicações de PNL, para beneficiar também o treinamento. Primeiro, na modelagem de linguagem, mostramos como aumentar o tamanho dos estados ocultos em camadas recorrentes sem aumentar o número de parâmetros, levando a modelos mais expressivos. Em segundo lugar, para rotulagem de sequências, mostramos que os word embeddings com esparsidade predefinida levam a um desempenho semelhante ao de embeddings densos, em uma fração do número de parâmetros treináveis.', 'ja': 'ニューラルネットワークを訓練しながら希薄さを誘発することは、より低いメモリフットプリントを有するが、密度の高いモデルと同様の有効性を有するモデルをもたらすことが示されている。しかしながら、希薄性は典型的には、密度の高いモデルから開始することによって誘発されるため、この利点は、訓練中に保持されない。私たちは、NLPアプリケーションのための反復シーケンスモデルで希少性を前もって強制する技術を提案し、トレーニングにも利益をもたらします。まず、言語モデリングでは、パラメータの数を増やすことなく、繰り返しレイヤーで隠された状態サイズを増やし、より表現力のあるモデルを作成する方法を示します。第二に、シーケンスラベリングについて、あらかじめ定義されたまばらさを持つ単語埋め込みは、トレーニング可能なパラメータの数のほんの一部で、密度の高い埋め込みと同様のパフォーマンスにつながることを示している。', 'ru': 'Было показано, что индуцирование редкости при обучении нейронных сетей дает модели с меньшим объемом памяти, но сходной эффективностью с плотными моделями. Однако редкость обычно индуцируется, начиная с плотной модели, и, таким образом, это преимущество не сохраняется во время тренировки. Мы предлагаем методы для обеспечения редкости в моделях рекуррентной последовательности для приложений NLP, чтобы также принести пользу обучению. Во-первых, в языковом моделировании мы показываем, как увеличить скрытые размеры состояний в рекуррентных слоях без увеличения количества параметров, что приводит к более выразительным моделям. Во-вторых, для маркировки последовательностей мы показываем, что вложения слов с предопределенной разреженностью приводят к такой же производительности, как и плотные вложения, на части количества обучаемых параметров.', 'hi': 'प्रशिक्षण तंत्रिका नेटवर्क के दौरान विरलता को प्रेरित करने के लिए कम स्मृति पदचिह्न के साथ मॉडल उत्पन्न करने के लिए दिखाया गया है, लेकिन घने मॉडल के समान प्रभावशीलता। हालांकि, विरलता आमतौर पर घने मॉडल से शुरू होने के लिए प्रेरित होती है, और इस प्रकार यह लाभ प्रशिक्षण के दौरान नहीं होता है। हम एनएलपी अनुप्रयोगों के लिए आवर्तक अनुक्रम मॉडल में विरलता को लागू करने के लिए तकनीकों का प्रस्ताव करते हैं, ताकि प्रशिक्षण को भी लाभ मिल सके। सबसे पहले, भाषा मॉडलिंग में, हम दिखाते हैं कि पैरामीटर की संख्या में वृद्धि के बिना आवर्तक परतों में छिपे हुए राज्य के आकार को कैसे बढ़ाया जाए, जिससे अधिक अभिव्यंजक मॉडल हो सकें। दूसरा, अनुक्रम लेबलिंग के लिए, हम दिखाते हैं कि पूर्वनिर्धारित विरलता के साथ शब्द एम्बेडिंग घने एम्बेडिंग के समान प्रदर्शन का कारण बनता है, जो ट्रेन करने योग्य मापदंडों की संख्या के एक अंश पर होता है।', 'zh': '教神经网络诱疏有卑内存占有似密。 然疏性常自密模诱导,故其胜不立。 设NLP之循环,先制疏疏之术,利于训练。 先言建模,示不加参数,循环层小大,以成更具表现力形。 其次,于序列标记,明有预定义疏性之词嵌之性,但可练参数数之一小耳。', 'ga': 'Tá sé léirithe go n-eascraíonn tanaí agus a bhíonn líonraí néaracha á dtraenáil samhlacha a bhfuil lorg cuimhne níos ísle acu ach éifeachtacht cosúil le samhlacha dlúth. Mar sin féin, is gnách go gcothaítear tearcacht ag tosú ó mhúnla dlúth, agus mar sin ní thagann an buntáiste seo le linn na hoiliúna. Molaimid teicníochtaí chun ganntanas a fhorfheidhmiú roimh ré i múnlaí seichimh athfhillteacha d’fheidhmchláir NLP, chun leas na hoiliúna freisin. Gcéad dul síos, i samhaltú teanga, léirímid conas méideanna stáit fholaithe a mhéadú i sraitheanna athfhillteacha gan líon na bparaiméadar a mhéadú, rud a fhágann go mbeidh samhlacha níos sainráiteach ann. Ar an dara dul síos, maidir le lipéadú seicheamh, léirímid go n-eascraíonn leabú focal le tearcacht réamhshainithe feidhmíocht chomhchosúil le leabú dlúth, ag codán de líon na bparaiméadar in oiliúint.', 'ka': 'ჩვენ აჩვენებულია, რომ ნეიროლური ქსელების შემწყვება მოდელების შემწყვება, მაგრამ განსხვავებული ეფექტიკური მოდელების შემწყვება. მაგრამ, სიცოცხლე ტიპოლურად იქნება დაიწყება სიცოცხლე მოდელიდან, და ამიტომ ეს გამოსახულება არ იქნება სარცოცხლეში. ჩვენ განვითარებთ ტექნოგიები, რომლებიც NLP პროგრამებისთვის რეკურენტური სექნემების მოდელში გაუმუშავებას, რომლებიც გამოიყენებას. პირველი, ენის მოდელირებაში, ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ როგორ უფრო გამოიყენება დახმარებული სტატური ზომის რეკურენტური ზომის განმავლობაში, პარამეტრის რაოდენობა მეორე, ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენი სიტყვას, რომელიც წინ განსაზღვრებულია სიტყვა, რომელიც წინ განსაზღვრებულია სიტყვა, იქნება მსგავსი გამოსახულებ', 'hu': 'Az ideghálózatok edzése közben a ritkaság előidézése során kimutatták, hogy alacsonyabb memórialábnyomú modelleket hoz létre, de hasonló hatékonyságot a sűrű modellekhez. A ritkaság azonban jellemzően sűrű modellből indukálódik, így ez az előny nem tart fenn edzés közben. Olyan technikákat javasolunk, amelyek előre erősítik a ritkaságot az NLP alkalmazások visszatérő szekvencia modelljeiben, hogy előnyös legyen a képzés. Először is, a nyelvi modellezésben megmutatjuk, hogyan lehet növelni a rejtett állapotméreteket visszatérő rétegekben anélkül, hogy növelnénk a paraméterek számát, ami kifejezőbb modellekhez vezet. Másodszor, a sorozatcímkézésnél megmutatjuk, hogy az előre meghatározott ritkasággal rendelkező szóbeágyazások hasonló teljesítményt eredményeznek, mint a sűrű beágyazások, a képezhető paraméterek számának töredéke.', 'el': 'Η πρόκληση σπανιότητας κατά την εκπαίδευση νευρωνικών δικτύων έχει αποδειχθεί ότι αποδίδει μοντέλα με χαμηλότερο αποτύπωμα μνήμης αλλά παρόμοια αποτελεσματικότητα με πυκνά μοντέλα. Ωστόσο, η σπανιότητα προκαλείται συνήθως ξεκινώντας από ένα πυκνό μοντέλο, και έτσι αυτό το πλεονέκτημα δεν ισχύει κατά τη διάρκεια της προπόνησης. Προτείνουμε τεχνικές για την επιβολή της σπανιότητας εκ των προτέρων σε επαναλαμβανόμενα μοντέλα ακολουθίας για εφαρμογές για να ωφεληθούν επίσης η εκπαίδευση. Πρώτον, στη μοντελοποίηση γλωσσών, παρουσιάζουμε πώς να αυξήσουμε τα μεγέθη κρυφών καταστάσεων σε επαναλαμβανόμενα στρώματα χωρίς να αυξήσουμε τον αριθμό παραμέτρων, οδηγώντας σε πιο εκφραστικά μοντέλα. Δεύτερον, για την επισήμανση ακολουθίας, δείχνουμε ότι οι ενσωμάτωση λέξεων με προκαθορισμένη σπανιότητα οδηγούν σε παρόμοια απόδοση με τις πυκνές ενσωμάτωση, σε κλάσμα του αριθμού των εκπαιδευόμενων παραμέτρων.', 'it': "Indurre scarsità durante l'allenamento delle reti neurali ha dimostrato di produrre modelli con un'impronta di memoria inferiore ma con efficacia simile a modelli densi. Tuttavia, la scarsità è tipicamente indotta a partire da un modello denso, e quindi questo vantaggio non regge durante l'allenamento. Proponiamo tecniche per rafforzare la scarsità in anticipo nei modelli di sequenza ricorrente per applicazioni NLP, a beneficio anche della formazione. In primo luogo, nella modellazione linguistica, mostriamo come aumentare le dimensioni dello stato nascosto in strati ricorrenti senza aumentare il numero di parametri, portando a modelli più espressivi. In secondo luogo, per l'etichettatura delle sequenze, mostriamo che le incorporazioni di parole con scarsa precisione predefinita portano a prestazioni simili a quelle degli incorporamenti densi, ad una frazione del numero di parametri addestrabili.", 'kk': 'Невралдық желілерді оқыту үшін жадын төмен басып шығару үлгілерін көрсетілген, бірақ тұтас үлгілерде ұқсас істеу үлгілеріне ұқсас болады. Бірақ бұл әдеттегі қалыптық үлгіден басталып тұрады, сондықтан бұл артықшылық оқыту кезінде болмайды. Біз NLP қолданбаларының қайталанатын реттеу үлгілерін көтеру техникаларын жұмыс істейміз, сондай-ақ оқыту үшін. Біріншіден, тіл модельдегі қайталанатын қабаттарда жасырылған күй өлшемдерін қайталанатын қабаттарда қайталанатын параметрлердің санын көтеріп, көтерілген үлгілерді көтеріп, қайталанат Екіншіден, реттеу жарлығы үшін, бұл сөздерді алдын- ала анықталған сәйкестіктермен ендіру үшін тұтас ендіру ретінде ұқсас істеу үшін көрсетеді.', 'ms': 'Meminduksi kecepatan semasa latihan rangkaian saraf telah dipaparkan untuk memberikan model dengan jejak kaki memori yang lebih rendah tetapi efektivitas yang sama dengan model yang padat. Namun, kecelakaan biasanya disebabkan bermula dari model yang padat, dan oleh itu keuntungan ini tidak memegang semasa latihan. Kami cadangkan teknik untuk memaksa kecepatan ke depan dalam model urutan berulang untuk aplikasi NLP, untuk juga melatih manfaat. Pertama, dalam pemodelan bahasa, kita menunjukkan bagaimana untuk meningkatkan saiz keadaan tersembunyi dalam lapisan berulang tanpa meningkatkan bilangan parameter, yang membawa kepada model yang lebih ekspresif. Second, for sequence labeling, we show that word embeddings with predefined sparseness lead to similar performance as dense embeddings, at a fraction of the number of trainable parameters.', 'mk': 'Inducing sparseness while training neural networks has been shown to yield models with a lower memory footprint but similar effectiveness to dense models.  Сепак, нејасноста е обично индуцирана почнувајќи од густ модел, и затоа оваа предност не се одржува за време на обуката. Ние предложуваме техники за спроведување на рецидентноста напред во рецидентните модели на секвенца за апликациите на НЛП, за да имаат и корист од обуката. Прво, во моделирањето на јазиците, покажуваме како да се зголеми големината на скриената состојба во рецидентни слоеви без зголемување на бројот на параметри, што води до поекспресни модели. Второ, за етикетирање на секвенца, покажуваме дека зборовите вградени со преддефинирана скратност водат до слична перформанса како густи вградени, во дел од бројот на возливи параметри.', 'ml': 'ന്യൂറല്\u200d വര്\u200dക്കുകള്\u200d പരിശീലിപ്പിക്കുമ്പോള്\u200d മോഡലുകള്\u200d കുറഞ്ഞ മെമ്മറി ഫുട്ടിന്\u200dറ് പ്രിന്റ് കൊണ്ട് മാതൃകങ്ങള്\u200d ഉല്\u200dപാ എന്നാലും സ്പാന്\u200dസെന്\u200dസ് സാധാരണയായി ഒരു മോഡലില്\u200d നിന്ന് തുടങ്ങുന്നതാണ്. അതുകൊണ്ട് ഈ ഉപകാരം പരിശീലനത്തിനുള്ള സമയത പ്രയോഗങ്ങള്\u200dക്ക് ആവര്\u200dത്തിക്കുന്ന സെക്കന്\u200dസ് മോഡലുകളില്\u200d സ്പെസെന്\u200dസെന്\u200dസ് മുന്\u200dപില്\u200d പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d ഞങ്ങള്\u200d  ആദ്യം, ഭാഷയുടെ മാതൃകയില്\u200d നമ്മള്\u200d കാണിക്കുന്നത് എങ്ങനെയാണ് രഹസ്യമായ രാജ്യത്തിന്റെ വലിപ്പം വീണ്ടും വര്\u200dദ്ധിപ്പിക്കുന്നതെന് രണ്ടാമത്, സെക്കന്\u200dസ് ലേബിള്\u200d ചെയ്യാന്\u200d വേണ്ടി, മുമ്പ് നിര്\u200dണ്ണയിക്കപ്പെട്ട വാക്കുകളുടെ അകത്തേക്കുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200d കാണിച്ചു തരുന്നു. അത്', 'no': 'Dette er vist å indusera sparseness mens opplæring av nøyralnettverk har blitt vist til å gje modeller med mindre minnettrykk, men liknande effektivitet til tette modeller. Men sparseness er vanlegvis indusert frå ein tett modell, og derfor denne fordelen inneheld ikkje under opplæring. Vi foreslår teknikke for å køyra sparseness opp i rekursekombinasjonsmodular for NLP-program, for å også forbetra opplæring. Først viser vi korleis gøymde tilstandsstorleikar skal aukast i gjentakingslag utan å auka talet på parametrar, som fører til fleire uttrykk modeller. Andre, for sekvensetiketting viser vi at ordinnbygging med føredefinerte sparseness fører til liknande utviklingar som tett innbygging, ved ein brøk av antallet trykkbare parametrar.', 'mn': 'Сургуулийн мэдрэлийн сүлжээний сургалтыг багасгах санамж багасгах хөдлөлтэй моделуудыг дамжуулах боломжтой. Гэхдээ жингийн загвартай адилхан үр дүнтэй. Гэхдээ жинхэнэ загвараас эхлэхээс үүсгэдэг. Иймээс энэ давуу тал нь сургалтын үед байхгүй. Бид NLP хэрэглээний дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин хөгжүүлэх техникуудыг санал болгож байна. Эхлээд, хэл загварчлалын хувьд бид хэрхэн нуугдсан байр суурь хэмжээг дахин дахин дахин нэмэгдүүлэхийг харуулж байна. Параметрын тоо нэмэгдэхгүй, илүү илүү илэрхийлэлтэй загвар руу хүргэ Хоёрдугаар, дарааллын маркингийн хувьд бид аль хэдийн тодорхойлогдсон хэмжээний хэсгийг дасгал хийх боломжтой параметрын хэсгийг харуулж байна.', 'lt': 'Nustatyta, kad švirkščiant nervinius tinklus spartumas skatina modelius, kurių atminties pėdsakas mažesnis, tačiau veiksmingumas panašus į tankius modelius. Tačiau mažumas paprastai sukeliamas remiantis tankiu modeliu, taigi šis pranašumas mokymo metu nėra naudingas. Mes siūlome metodus, kuriais būtų užtikrintas spartumas iš anksto taikant pakartotinių sekų modelius NLP programoms, taip pat siekiant naudos mokymui. Pirma, kalbų modeliavimo metu parodomi, kaip padidinti paslėptų būklės dydžius pakartotiniuose sluoksniuose, nesudidinant parametrų skaičiaus, dėl to atsiranda labiau išraiškūs modeliai. Antra, sekos ženklinimui parodomi, kad žodžių įdėjimas su iš anksto apibrėžtu trūkumu lemia panašius rezultatus kaip ir tankių įdėjimų, kai dalis traukinių parametrų.', 'pl': 'Wykazano, że wywoływanie oszczędności podczas treningu sieci neuronowych daje modele o mniejszym śladie pamięci, ale podobnej skuteczności do gęstych modeli. Jednak rzadkość jest zazwyczaj indukowana od gęstego modelu, a zatem ta zaleta nie utrzymuje się podczas treningu. Proponujemy techniki wymuszania rzadkości z góry w modelach sekwencji powtarzających się dla aplikacji NLP, co również przynosi korzyści szkoleniom. Po pierwsze, w modelowaniu językowym pokazujemy, jak zwiększyć rozmiary ukrytych stanów w powtarzających się warstwach bez zwiększania liczby parametrów, prowadząc do bardziej ekspresyjnych modeli. Po drugie, w przypadku etykietowania sekwencji pokazujemy, że osadzenia słów o predefiniowanej rzadkości prowadzą do podobnej wydajności jak osadzenia gęste, przy ułameku liczby parametrów treningowych.', 'ro': 'S-a demonstrat că inducerea slabiciunii în timpul antrenamentului rețelelor neurale produce modele cu o amprentă de memorie mai mică, dar cu eficiență similară modelelor dense. Cu toate acestea, slabiciunea este indusă de obicei pornind de la un model dens, și astfel acest avantaj nu se menține în timpul antrenamentului. Propunem tehnici pentru a impune lipsa în avans în modelele de secvență recurente pentru aplicațiile PNL, pentru a beneficia, de asemenea, de formare. În primul rând, în modelarea limbajului, arătăm cum să creștem dimensiunile stărilor ascunse în straturile recurente fără a crește numărul de parametri, conducând la modele mai expresive. În al doilea rând, pentru etichetarea secvențelor, arătăm că încorporările de cuvinte cu caracter slab predefinit duc la performanțe similare cu încorporările dense, la o fracțiune din numărul de parametri instruibili.', 'sr': 'Pokazano je da se pojavljuje iskrenost dok je obuka neuronskih mreža podizala modele sa nižim otisakom pamćenja, ali slična učinkovitost gustih modela. Međutim, iskrenost se obično inducira od gustog model a, i tako se ova prednost ne drži tokom treninga. Mi predlažemo tehnike za primjenu rezervnosti naprijed u rekonstruacijskim modelima sekvence za aplikacije NLP-a, kako bi takođe imali koristi za obuku. Prvo, u modeliranju jezika, pokazujemo kako povećati skrivene veličine države u recirenim slojevima bez povećanja broja parametara, što vodi do ekspresivnijih modela. Drugo, za označavanje sekvencije, pokazujemo da reč ugrađena sa predodređenom iskrenošću dovede do slične izvedbe kao guste ugrađenje, u delu broja treniralih parametara.', 'si': 'ප්\u200dරධාන න්\u200dයූරාල ජාලය ප්\u200dරධානය කරමින් ප්\u200dරධානය කරමින් ප්\u200dරධානය කරන්න ප්\u200dරධානයක් පෙන්වන්න පුළුවන් පහත නමුත්, සාමාන්\u200dයයෙන්ම ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පටන් ගන්න පුළුවන් වෙනවා, ඒ වගේම මේ ප්\u200dරයෝජනයක් ප්\u200dර අපි පරීක්ෂණය සඳහා ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය ප්\u200dරයෝජනය කරන් මුලින්, භාෂාව මොඩල් කරනවා, අපි පෙන්වන්නේ කොහොමද හැංගුණු ස්ථිතිය ප්\u200dරමාණය ප්\u200dරමාණය වැඩි කරන්නේ කියලා පෙන්ව දෙවෙනි වෙනුවෙන්, ක්\u200dරමය ලේබිල් එක්ක, අපි පෙන්වන්නේ ඒ වචනය ප්\u200dරධාන විශ්වාස කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් විශ්වා', 'so': "Markii la barto shabakada neurada waxaa lagu muujiyey tusaale ka soo saara suurad xubnaha hoos ah, laakiin faa’iido u eg samooyin daboolan. Si kastaba ha ahaatee cayilnaanta waxaa inta badan laga bilaabo model qarsoon, sidaas darteed faa'iidadanu ma jirto xilliga waxbarashada. Waxaynu soo bandhignaynaa qalabka lagu soo bandhigi karo tusaalooyinka soo socota ee codsiga NLP-da, si loo helo waxbarashada. Marka ugu horeysa, tusaale ahaan afka, waxaynu tusnaynaa sida loo kordhiyo tirada dowladda qarsoon oo aan kordhin tirada lambarka ah, waxaana sababtaa tusaalooyin aad u muuqata. Second, waxaynu tusaynaa in ereyga lagu barto oo ay ka mid tahay wax la mid ah oo la mid ah tababaro xilli ah, tiro tiro ah oo la tababaray.", 'sv': 'Att framkalla sparsamhet vid träning av neurala nätverk har visat sig ge modeller med lägre minnesavtryck men liknande effektivitet som täta modeller. Men sparsamhet induceras vanligtvis med utgångspunkt i en tät modell, och därför håller denna fördel inte under träning. Vi föreslår tekniker för att genomdriva sparsamhet på förhand i återkommande sekvensmodeller för NLP-applikationer, för att också gynna utbildning. För det första, i språkmodellering, visar vi hur man ökar dolda tillståndsstorlekar i återkommande lager utan att öka antalet parametrar, vilket leder till mer uttrycksfulla modeller. För det andra, för sekvensmärkning, visar vi att ordinbäddningar med fördefinierad sparsamhet leder till liknande prestanda som täta inbäddningar, vid en bråkdel av antalet träningsbara parametrar.', 'ur': 'نیورل نیٹورک کی تعلیم کے موقع اسپرنسنس کے ذریعہ مہربانی کے ذریعہ مہربانی کے ذریعہ نمڈلوں کو دکھایا جاتا ہے لیکن مہربانی نمڈلوں کے ساتھ برابر مہربانی ہے. لیکن آہستگی معمولاً ایک گہرے موڈل سے شروع ہوتی ہے، اور اسی طرح یہ فائدہ تعلیم کے وقت تکلیف نہیں دیتی۔ ہم نے تکنیک پیش کرتا ہے کہ NLP کاربریوں کے لئے دوبارہ ریکنٹ سیکس موڈل میں اسپانسنسنس کو مضبوط کرنے کے لئے، اور تدریس کے لئے بھی فائدہ پہنچانے کے لئے۔ پہلے، زبان نمادلینگ میں، ہم دکھاتے ہیں کہ کیسے مخفی حالت سازوں کو دوبارہ دکھانے لہروں میں اضافہ کریں بغیر پارامیٹروں کی تعداد اضافہ کریں، اور زیادہ مثالیں اضافہ کریں۔ دوسرا، سطح لیبلینگ کے لئے، ہم اسے دکھاتے ہیں کہ کلمات کی ابڈینگ پہلے دکھائی ہوئی سطح کے ساتھ ایک طرح کی عملکرد کی طرح گہرے انڈینگ کے ساتھ، ایک قسم کی تعداد پر آموزش دینے والی پارامیٹروں کی۔', 'mt': "L-induzzjoni tal-iskarsezza waqt it-taħriġ tan-netwerks newrali ntweriet li tagħti mudelli b’impronta tal-memorja aktar baxxa iżda effettività simili għal mudelli densi. Madankollu, l-iskarsezza hija tipikament indotta billi tibda minn mudell dens, u għalhekk dan il-vantaġġ ma jżommx waqt it-taħriġ. Aħna nipproponu tekniki biex ninfurzaw l-iskarsezza 'l quddiem f'mudelli ta' sekwenza rikorrenti għall-applikazzjonijiet NLP, biex jibbenefikaw ukoll mit-taħriġ. L-ewwel nett, fl-immudellar tal-lingwi, nuru kif għandna nżidu d-daqsijiet ta’ stat moħbi f’saffi rikorrenti mingħajr ma nżidu n-numru ta’ parametri, li jwasslu għal mudelli aktar espressivi. It-tieni nett, għat-tikkettar tas-sekwenza, nuru li l-inkorporazzjonijiet tal-kliem b’sparsenza predefinita jwasslu għal prestazzjoni simili għal inkorporazzjonijiet densi, fi frazzjoni tan-numru ta’ parametri li jistgħu jinħarġu.", 'ta': 'புதிய பிணைய வலைப்பின்னல்களை பயிற்சி செய்யும் போது சிறிய வெறுமையை குறைவாக்குகிறது ஆனால் அடர்ந்த மாதிரிகளுக்கு அத ஆயினும், வெளிப்பாடுகள் வழக்கமாக ஒரு சூழ்நிலை மாதிரியிலிருந்து துவங்கப்படுகிறது, ஆகையால் பயிற்சியில் இந்த நாம் மீண்டும் தொழில்நுட்ப முறைமையில் செயல்படுத்த தொழில்நுட்பத்தை நிகழ்ந்து NLP பயன்பாடுகளுக்கான மாதிரிகளி முதலில், மொழி மாதிரியில், மறைந்த நிலையின் அளவுகளை நிகழ்ந்த அடுக்குகளில் எவ்வாறு அதிகப்படுத்த வேண்டும் என்பதை காட்டுகிறோம், அத இரண்டாவது, தொடர் விளக்கச்சீட்டிற்கு, நாம் முன்னால் குறிப்பிட்ட வார்த்தையின் உள்ளடக்கங்களை காட்டுகிறோம் முன்னால் குறிப்பிட்ட வெளிய', 'uz': "Name Lekin, cheksizlik odatda yuqori modeldan boshlanadi, va shunday qilib bu imkoniyat tajriba sohasida emas. @ info: whatsthis Birinchi, tilni modellashda, qayta qanday bekitilgan holat oʻlchamini ko'paytirishni koʻrsatishimiz, qayta qanday parametrlarning soni ko'paytirish mumkin, va ko'proq modellarni oshirish mumkin. Ikkinchi so'zning chegarasi taʼminlovchi darajada, biz bir so'zlar oldin kichkina parametrlar soni ko'rsatumiz.", 'vi': 'Gây ra sơ sài trong khi huấn luyện các mạng thần kinh đã được cho thấy khả năng cung cấp các mô hình có ít kí ức nhưng hiệu quả tương tự với mô hình dày. Tuy nhiên, xu hướng phân tán do một mô hình dày đặc bắt đầu nên lợi thế này không có trong khi huấn luyện. Chúng tôi đề xuất các kỹ thuật để áp dụng sơ suất trong các mô hình lập thường xuyên cho ứng dụng NLP, cũng có lợi cho việc huấn luyện. Đầu tiên, trong việc tạo mẫu ngôn ngữ, chúng tôi cho thấy cách để tăng kích cỡ trạng thái ẩn trong các lớp thường xuyên, mà không tăng số tham số, dẫn đến các mô hình biểu cảm hơn. Thứ hai, để mô tả các chuỗi, chúng tôi cho thấy rằng sự nhúng vào từ với sơ sài xác định trước có hiệu quả tương tự như sự nhúng vào mật độ, với một phần nhỏ số các tham số huấn luyện.', 'hr': 'Pokazano je da se pojavljuje iskrenost tijekom obuke neuronskih mreža donosi modele s nižim otisakom pamćenja, ali slična učinkovitost gustih modela. Međutim, sparseness se obično inducira od gustog model a, i stoga ova prednost ne drži tijekom treninga. Mi predlažemo tehnike za primjenu sparseness naprijed u rekonstruiranim modelima sekvencije za primjene NLP-a, kako bi također imali koristi za obuku. Prvo, u modelima jezika, pokazujemo kako povećati skrivene veličine države u rekonstruiranim slojevima bez povećanja broja parametara, što vodi do ekspresivnijih modela. Drugo, za označavanje sekvencije, pokazujemo da se riječ ugrađena sa predodređenom iskrenošću dovede do sličnih učinka kao gusta ugrađenja, na dio broja tržišnih parametara.', 'nl': 'Het induceren van schaarste tijdens het trainen van neurale netwerken is aangetoond dat het modellen oplevert met een lagere geheugenvoetafdruk maar vergelijkbaar met dichte modellen. Echter, spaarzaamheid wordt meestal geïnduceerd vanaf een dicht model, en dus dit voordeel geldt niet tijdens de training. We stellen technieken voor om spaarzaamheid vooraf af te dwingen in terugkerende sequentiemodellen voor NLP-toepassingen, om ook training ten goede te komen. Ten eerste laten we in taalmodellering zien hoe je verborgen statusgrooten in terugkerende lagen kunt vergroten zonder het aantal parameters te verhogen, wat leidt tot expressievere modellen. Ten tweede laten we voor sequence labeling zien dat woord embeddings met vooraf gedefinieerde schaarste leiden tot vergelijkbare prestaties als dichte embeddings, met een fractie van het aantal trainable parameters.', 'bg': 'Доказано е, че предизвикването на рядкост по време на тренировка на невронни мрежи дава модели с по-нисък отпечатък на паметта, но подобна на плътните модели. Въпреки това, рядкостта обикновено се индуцира като се започне от плътен модел и по този начин това предимство не се задържа по време на тренировка. Предлагаме техники за налагане на оскъдност в повтарящи се последователни модели за приложения за НЛП, за да се възползват и от обучението. Първо, в езиковото моделиране показваме как да увеличим размерите на скритите състояния в повтарящи се слоеве, без да увеличаваме броя на параметрите, което води до по-изразителни модели. Второ, за етикетиране на последователността показваме, че вгражданията на думи с предварително дефинирана рядкост водят до сходни показатели като гъсти вграждания, при малка част от броя на обучаващите се параметри.', 'de': 'Die Induktion von Sparseness beim Training neuronaler Netzwerke hat gezeigt, dass Modelle mit einem geringeren Speicherbedarf, aber ähnlicher Effektivität zu dichten Modellen führen. Allerdings wird Sparseness typischerweise von einem dichten Modell ausgehend induziert, und so bleibt dieser Vorteil während des Trainings nicht bestehen. Wir schlagen Techniken vor, um Sparseness im Vorfeld in wiederkehrenden Sequenzmodellen für NLP-Anwendungen zu erzwingen, was auch dem Training zugute kommt. Zunächst zeigen wir in der Sprachmodellierung, wie versteckte Zustandsgrößen in wiederkehrenden Ebenen erhöht werden können, ohne die Anzahl der Parameter zu erhöhen, was zu expressiveren Modellen führt. Zweitens zeigen wir für die Sequenz-Beschriftung, dass Wort-Einbettungen mit vordefinierter Sparseness zu einer ähnlichen Leistung wie dichte Einbettungen führen, bei einem Bruchteil der Anzahl der trainierbaren Parameter.', 'da': 'At fremkalde sparsomhed under træning af neurale netværk har vist sig at give modeller med et lavere hukommelsesmæssigt fodaftryk, men lignende effektivitet som tætte modeller. Men sparsomhed induceres typisk ud fra en tæt model, og denne fordel holder således ikke under træning. Vi foreslår teknikker til at håndhæve sparsomhed på forhånd i tilbagevendende sekvensmodeller til NLP applikationer, for også at gavne træning. For det første viser vi i sprogmodellering, hvordan man øger skjulte tilstandsstørrelser i tilbagevendende lag uden at øge antallet af parametre, hvilket fører til mere udtryksfulde modeller. For det andet viser vi for sekvensmærkning, at ordindlejringer med foruddefineret sparsomhed fører til lignende ydeevne som tætte indlejringer, ved en brøkdel af antallet af træningsdygtige parametre.', 'id': 'Meminduksi kecepatan sementara melatih jaringan saraf telah menunjukkan untuk menghasilkan model dengan jejak ingatan yang lebih rendah tetapi efektif yang sama dengan model tebal. Namun, kecelakaan biasanya diinduksi mulai dari model tebal, dan oleh itu keuntungan ini tidak bertahan selama latihan. Kami mengusulkan teknik untuk memaksa kecepatan ke depan dalam model urutan rekuren untuk aplikasi NLP, untuk juga menguntungkan pelatihan. Pertama, dalam model bahasa, kita menunjukkan bagaimana untuk meningkatkan ukuran keadaan tersembunyi dalam lapisan berkurang tanpa meningkatkan jumlah parameter, yang menyebabkan model yang lebih ekspresif. Kedua, untuk label urutan, kita menunjukkan bahawa kata embedding dengan kelemahan terdefinisi memimpin ke prestasi yang sama seperti embedding padat, pada sebagian dari jumlah parameter yang dapat dilatih.', 'tr': 'Näyral şebekeleri eğitilýan wagtlar ýagtylyga süýtgetmek üçin hatyň düşük futboly bilen modelleri taýýarlamak üçin görkezildi. ýöne durmuş modellere meňzeş täsirlik bar. Ýöne, a ýyryşlyk adatça ýigrenç nusgadan başlamak üçin täsirlenýär we şonuň üçin bu baýramçylyk eğitim wagtynda durmaz. NLP uygulamalary üçin ýene-täsirli sequence modellerinde, ýöne bir hereket etmek üçin teknikleri teklip berýäris. Ilkinji, dil modellerinde, tekrarly kalamlar içinde gizli durum ölçülerini nähili artabileceğini görkezýäris. Bu hat da ýene bir nähili möhüm modellere gidirýär. Ikinjisi, sıralama etiketleri için, öntanımlı sıralama bilen sözlerin içinde sıcak sıralama şeklinde, eğitilebilir parametrlerin bir kısmında benzer etkinliği gösteriyoruz.', 'af': "Inhindering sparseness terwyl oefening van neurale netwerke is vertoon om modele te gee met 'n minder geheue voetskrif maar soortgelyk effektiviteit aan diepste modele. Maar sparseness is tipies geïndig van 'n dens model, en daarom hou hierdie voordeel nie tydens onderwerp nie. Ons voorstel teknologies om spansensies voor te vervul in herhaalde sekwensiemodele vir NLP toepassings, om ook voorwerp te doen. Eerste, in taal modellering, wys ons hoe om versteekte staat grootte in herhaalde laagte te vermeerder sonder om die nommer van parameters te vermeerder, wat na meer uitdrukking modele te lei. Tweede, vir volgorde etiketting, wys ons daardie woord inbêring met vooraf definieerde sparseness lei na soortgelyke prestasie as dens inbêding, by 'n fraksie van die nommer van ontvangbare parameters.", 'fa': 'در حالی که تمرین شبکه\u200cهای عصبی به مدل\u200cهای پای پای پایین حافظه\u200cی پایین\u200cتر و موثرت مشابه\u200cای با مدل\u200cهای مغز نشان داده می\u200cشود. با این حال، اسپرنسنس معمولاً از یک مدل گسترده تحت تاثیر قرار می گیرد، و این سودها در طول آموزش تحت تاثیر قرار نمی گیرد. ما تکنیک\u200cها را پیشنهاد می\u200cکنیم که در مدل\u200cهای ردیابی دوباره برای کاربردهای NLP، برای آموزش سود استفاده کنیم. اول، در مدل زبانی، ما نشان می دهیم چگونه اندازه\u200cهای موقعیت مخفی را در طبقه\u200cهای دوباره افزایش دهیم بدون افزایش تعداد پارامتر، که به مدل\u200cهای بیشتری منظور می\u200cکند. دوم، برای برچسب برچسب\u200cهای برچسب، ما این کلمه را نشان می\u200cدهیم که برچسب\u200cهای برچسب\u200cهای پیش\u200cتعریف شده با برچسب\u200cهای برچسب\u200cهای مشابه به عنوان برچسب\u200cهای داغ\u200cهای داغ، در بخشی از تعداد پارامترهای آموزشی است.', 'sw': 'Kuonyesha ukosefu wa kuongezeka wakati wa mafunzo ya mitandao ya neura imeonyesha kuonyesha mifano yenye nyanja za chini za kumbukumbu lakini ufanisi kama huo kwa mifano mizito. Hata hivyo, unyanyasaji unaanzishwa kwa kawaida kuanzia kwa mtindo mzito, na kwa hiyo faida hii haijaishi wakati wa mafunzo. Tunazipendekeza mbinu za kutekeleza uwezekano wa kuongezeka mbele kwa mifano inayoendelea kwa matumizi ya NLP, pia kwa ajili ya mafunzo. Kwanza, kwa mifano ya lugha, tunaonyesha jinsi ya kuongeza ukubwa wa hali ya kujificha katika vipande vinavyoendelea bila kuongeza idadi ya parameters, na kuongeza mifano yenye kuongezeka zaidi. Pili, kwa ajili ya maabara ya mfululizo, tunaonyesha kwamba maneno yanayoingia kwa ghafla zilizotanguliwa yanasababisha utendaji wa aina hiyo kama vile vifaa vinavyochanganyika, katika baadhi ya vipimo vya vifaa vya mafunzo.', 'sq': 'Duke nxitur pakësinë ndërsa trajnimi i rrjeteve nervore është treguar se jep modele me një gjurmë më të ulët kujtese por efektshmëri të ngjashme me modele të dendura. Megjithatë, pakësia tipikisht indukohet duke filluar nga një model i dendur dhe kështu ky avantazh nuk mban gjatë trajnimit. Ne propozojmë teknika për të zbatuar shkurtësinë përpara në modele të përsëritur sekuencë për aplikimet NLP, për të përfituar gjithashtu trajnimin. Së pari, në modelimin gjuhësor, ne tregojmë se si të rritemi madhësitë e gjendjes së fshehur në shtresa të përsëritura pa rritur numrin e parametrave, duke çuar në modele më ekspresive. Së dyti, për etiketën e sekuencës, ne tregojmë se përfshirjet e fjalëve me pakësinë e paracaktuar çojnë në performancë të ngjashme me përfshirjet e dendura, në një pjesë të numrit të parametrave të trajnuar.', 'hy': 'Նյարդային ցանցերի ուսումնասիրության ընթացքում հազվադեպ արտադրելը ցույց է տալիս, որ նյարդային ցանցերը նվազեցնում են մոդելներ, որոնք ավելի ցածր հիշողության ազդեցություն ունեն, բայց նման արդյունավետություն Այնուամենայնիվ, փոքրությունը սովորաբար արտադրվում է խիտ մոդելի սկզբից, և այսպիսով այս առավելությունը չի պահում ուսուցման ընթացքում: Մենք առաջարկում ենք տեխնիկաներ, որոնք օգտագործում են նորից տեղադրվող հաջորդականության մոդելներ, որպեսզի օգտագործեն նաև սովորելը: First, in language modeling, we show how to increase hidden state sizes in recurrent layers without increasing the number of parameters, leading to more expressive models.  Second, for sequence labeling, we show that word embeddings with predefined sparseness lead to similar performance as dense embeddings, at a fraction of the number of trainable parameters.', 'az': 'Nöral a ğlarını təhsil etmək üçün küçük yada izləri ilə modelləri təhsil etmək göstərildi, amma yoxlu modellərə bənzər etkinlik göstərildi. Ancaq, təsirlik sıxıntıdan başlamaq üçün genellikle təsirlik edir və bu mənfəət təhsil sırasında saxlanmır. NLP uyğulamaları üçün yenidən seçmə modellərdə, həmçin in təhsil göstərmək üçün fərqli təhsil etmək üçün teknikləri təklif edirik. Əvvəlcə, dil modellərində gizli durum ölçülərini yenidən uzatmadan parametrlərin sayını artırmağı göstəririk, daha çox ifadə modellərə yol göstəririk. İkincisi, seçmə etiketi üçün, əvvəlcə beləliklə beləliklə beləliklə müəyyən edilmiş hissələrlə birləşdirilən sözləri yoxlu inşallar kimi bənzər performansı göstəririk.', 'ko': '신경 네트워크를 훈련하는 동시에 희소성을 유도하는 것은 낮은 메모리 점용 모델을 만들 수 있다는 것이 증명되었지만 밀집 모델의 효과와 유사하다.그러나 희소성은 일반적으로 밀집 모델로부터 유도되기 때문에 이런 장점은 훈련 기간에 성립되지 않는다.우리는 NLP 응용 프로그램의 순환 서열 모델에서 희소성을 미리 강화하는 기술을 제시했는데 이것도 훈련에 유리하다.우선, 언어 모델링에서 우리는 매개 변수의 수량을 증가하지 않은 상황에서 중복층의 숨겨진 상태 크기를 증가시켜 더욱 표현력 있는 모델을 만드는 방법을 보여 준다.둘째, 서열 표기에 대해 우리는 미리 정의된 희소성을 가진 단어 삽입과 밀집 삽입은 비슷한 성능을 가지고 훈련 가능한 파라미터의 수량은 훈련 가능한 파라미터의 일부분에 불과하다는 것을 증명했다.', 'bn': 'নিউরাল নেটওয়ার্ক প্রশিক্ষণের সময় স্প্যাসেন্স প্রদর্শন করা হচ্ছে যখন একটি কম মেমরি ফুটপ্রিন্ট দিয়ে মডেল উৎপাদন করা হয়, কিন্তু গভীর ম However, sparseness is typically induced starting from a dense model, and thus this advantage does not hold during training.  এনএলপি অ্যাপ্লিকেশনের জন্য প্রত্যাবর্তনের সেকেন্স মডেলে প্রযুক্তি বাধ্য করার জন্য আমরা প্রস্তাব করি প্রযুক্তি যাত প্রথমত, ভাষার মডেলিং ভাষায় আমরা দেখাচ্ছি কিভাবে প্রত্যাবর্তন স্তরে লুকিয়ে থাকা রাষ্ট্রের আকার বৃদ্ধি করতে পারে কিন্তু প্য দ্বিতীয়, সেকেন্ড ল্যাবেলের জন্য আমরা দেখাচ্ছি যে শব্দটি পূর্ববর্তী স্প্যারেন্সেসের সাথে প্রদর্শন করা হয়েছে তার ফলে গভীর প্রতিষ্ঠানের মতো ক', 'ca': "S'ha demostrat que induir l'escassetat mentre treinem xarxes neurals produeixen models amb una petjada menor de memòria però eficacia similar a models densos. However, sparseness is typically induced starting from a dense model, and thus this advantage does not hold during training.  Proposem tècniques per aplicar els models de seqüència recurrents a l'avançat de l'escassetat per a aplicacions NLP, per a beneficiar també l'entrenament. En primer lloc, en la modelació de llenguatges, mostram com augmentar les mida d'estat ocultes en capes recurrents sense augmentar el nombre de paràmetres, portant a models més expressius. Segon, per etiquetar seqüències, demostram que l'incorporació de paraules amb escassetat predefinida condueix a un rendiment similar a l'incorporació densa, en una fracció del nombre de paràmetres entrenables.", 'am': 'የነጥብ መረብ ማጠቃለያ ሲታየቅ ማስታወስ እግር በተለየ ነገር ግን ለጥቁር ሞዴላዎችን በመጠቀም እና በሚያየው ጥያቄ ነው፡፡ ምንም እንኳን፣ ጥቅረት በጥልቅ ሞዴል መጀመሪያ ነው፡፡ We propose techniques to enforce sparseness upfront in recurrent sequence models for NLP applications, to also benefit training.  በመጀመሪያ፣ በቋንቋ ምሳሌ፣ የተሰወረውን የግዛት መጠን እንዴት እንዲያበዛ እናሳየዋለን፡፡ በሁለተኛው፣ ለሥርዓት ማሳየት፣ ይህንን ቃል አስቀድሞ በተለየ ቁጥር እንደሚያሳየው አካባቢ እናሳየዋለን፡፡', 'bs': 'Pokazano je da se pojavljuje iskrenost dok je obuka neuronskih mreža pružala modele s nižim otisakom pamćenja, ali slična učinkovitost gustih modela. Međutim, iskrenost se obično inducira od gustog model a, i stoga ova prednost ne drži tijekom treninga. Mi predlažemo tehnike za primjenu sparseness naprijed u rekonstruacijskim modelima sekvence za aplikacije NLP-a, kako bi također imali koristi za obuku. Prvo, u modeliranju jezika, pokazujemo kako povećati skrivene veličine države u recirenim slojevima bez povećanja broja parametara, što vodi do ekspresivnijih modela. Drugo, za označavanje sekvencije, pokazujemo da riječ ugrađena sa predodređenom iskrenošću dovede do slične učinke kao guste ugrađenje, na dio broja treniralih parametara.', 'et': 'Närvivõrkude treenimise ajal on näidatud, et hõreduse tekitamine annab mudeleid, millel on väiksem mälujälg, kuid sarnane efektiivsus tihedate mudelitega. Kuid hõredus tekitatakse tavaliselt tihedast mudelist, mistõttu see eelis treeningu ajal ei ole. Pakume välja tehnikaid, et jõustada hõredus korduvate järjestusmudelite puhul NLP rakenduste jaoks, et kasutada ka koolitust. Esiteks näitame keele modelleerimises, kuidas suurendada varjatud oleku suurust korduvates kihtides ilma parameetrite arvu suurendamata, mis viib väljendusväärsemate mudeliteni. Teiseks näitame järjestuse märgistamise puhul, et eelnevalt määratletud hõredusega sõnade manustamine toob kaasa sarnase jõudluse kui tihedad manustamised, murdosaga treenitavate parameetrite arvust.', 'cs': 'Bylo prokázáno, že indukce řídkosti při tréninku neuronových sítí přináší modely s nižší paměťovou stopou, ale podobnou efektivitou jako husté modely. Nicméně, řídkost je obvykle indukována od hustého modelu, a tudíž tato výhoda během tréninku nevydrží. Navrhujeme techniky vynucování řídkosti předem v recidivujících sekvenčních modelech pro aplikace NLP, což rovněž přináší prospěch školení. Nejprve v jazykovém modelování ukazujeme, jak zvětšit velikost skrytých stavů v opakujících se vrstvách bez zvýšení počtu parametrů, což vede k expresivnějším modelům. Za druhé, pro sekvenční značení ukazujeme, že slovní vložení s předem definovanou řídkostí vedou k podobnému výkonu jako husté vložení, při zlomeku počtu trénovatelných parametrů.', 'fi': 'Harjoituksen aikaansaaminen neuroverkkoja harjoitettaessa on osoitettu tuottavan malleja, joilla on pienempi muistijalanjälki mutta samanlainen tehokkuus kuin tiheät mallit. Harjoitus on kuitenkin tyypillistä tiheästä mallista alkaen, joten tämä etu ei säily harjoittelun aikana. Ehdotamme tekniikoita, joilla lisätään niukkuutta NLP-sovellusten toistuvissa sekvenssimalleissa myös koulutuksen edistämiseksi. Ensinnäkin kielimallinnuksessa näytämme, miten piilotettujen tilojen kokoa voidaan lisätä toistuvissa kerroksissa lisäämällä parametrien määrää, mikä johtaa ilmaisuvoimaisempiin malleihin. Toiseksi, sekvenssimerkinnässä osoitamme, että ennalta määritellyllä harvaluudella varustetut sanaupotukset johtavat samanlaiseen suorituskykyyn kuin tiheät upotukset murto-osalla koulutettavien parametrien määrästä.', 'jv': 'Genjer Nanging, pirsak-pirsak wae ngomong nik sakjane mulai model sing dewan, lan ngono bener iki iso nguasai tarjamahan. Awak dhéwé ngerasah teknik kanggo nggawe barang seneng pisan nang model sing berarti kanggo aplikasi NLP, kanggo ngilangno njukke tresnaning. Sample rate wis 2', 'he': 'הוכח שהתחילה של דלקות בזמן שאימון רשתות עצביות מובילה דוגמנים עם עקבות זכרון נמוכות יותר, אך יעילות דומה לדוגמנים צפופים. בכל אופן, נדירות בדרך כלל מתחילה מדגם צפוף, ולכן יתרון זה לא מחזיק במהלך האימונים. אנו מציעים טכניקות להכריח חוסר דרכות קדימה בדוגמנים רצפים חוזרים לתוכניות NLP, כדי גם להשתמש באימונים. ראשית, בנוגע לדוגמה לשפה, אנחנו מראים איך לגדל את גודלים המצב המסתורים בשכבות חוזרות בלי לגדל את מספר הפרמטרים, מה שמוביל לדוגמאות מבטאות יותר. שנית, בשביל תיקון רצף, אנחנו מראים את המילה הזאת עם דלקות מוגדרת מראש מובילה לביצוע דומה כמו דלקות צפופופות, בחלק ממספר הפרמטרים המתאימים.', 'ha': "Yi nuna masĩfa a lokacin da aka sanar da tsarin zanen neural zuwa ya nuna motel da wani ƙaranci na kumbura, amma yana da amfani da kwamfyutan misali masu ƙaranci. However, sparseness is typically induced starting from a dense model, and thus this advantage does not hold during training.  Tuna goyya kodi masu yin amfani da shiryoyin ayuka na zaman kwanan da aka dace cewa masu shiryoyin ayuka na NLP, don haka. Kayyan, cikin shirin harshe, muna nuna yadda za'a ƙara girma wa halin da aka ɓõye cikin duffai da aka sake sauya bila ya ƙara ƙidãyar parameteri, kuma yana ƙara wa misãlai masu bayyanawa. Dukkan, za'a nuna maganar da za'a iya lissafa kwance, za'a sami da sauran da za'a yi kama da aikin mai sauri, a cikin rabin ƙidãyar parameteri wanda za'a iya lissafa.", 'sk': 'Dokazano je, da povzročanje redkosti med vadbo nevronskih omrežij prinaša modele z manjšim pomnilniškim odtisom, vendar podobno učinkovitostjo kot gosti modeli. Vendar pa se redkost običajno sproži na začetku gostega modela, zato ta prednost med vadbo ne velja. Predlagamo tehnike za vnaprejšnje uveljavljanje redkosti pri modelih ponavljajočih se zaporedj za aplikacije NLP, da bi koristili tudi usposabljanju. Najprej pri jezikovnem modeliranju pokažemo, kako povečati velikost skritih stanj v ponavljajočih se plasteh brez povečanja števila parametrov, kar vodi do bolj izrazitih modelov. Drugič, pri označevanju zaporedja pokažemo, da besedne vdelave z vnaprej določeno redkostjo vodijo do podobne zmogljivosti kot goste vdelave, pri delčku števila treniranih parametrov.', 'bo': 'Inducing sparseness while training neural networks have been shown to yield models with a lower memory footprint but similar effectiveness to dense models. ཡིན་ནའང་། sparseness is typically induced from a dense model, and thus this advantage does not hold during training. NLP ཉེར་སྤྱོད་མཁན་གྱི་རྣམ་པ་ལ་གསལ་བཤད་ཀྱི་མིག་ལམ་ལུགས་དང་མཐུན་སྐྱོང་བྱེད་དགོས། First, in language modeling, we show how to increase hidden state sizes in recurrent layers without increasing the number of parameters, leading to more expressive models. Second, for sequence labeling, we show that word embeddings with predefined sparseness lead to similar performance as dense embeddings, at a fraction of the number of trainable parameters.'}
{'en': 'Learning to Actively Learn Neural Machine Translation', 'ar': 'تعلم التعلّم النشط للترجمة الآلية العصبية', 'fr': 'Apprendre à apprendre activement la traduction automatique neuronale', 'pt': 'Aprendendo a aprender ativamente a tradução automática neural', 'es': 'Aprender a aprender activamente la traducción automática neuronal', 'ja': '神経機械翻訳を積極的に学ぶ', 'zh': '学自学神经机器翻译', 'hi': 'सीखना सक्रिय रूप से जानने के लिए तंत्रिका मशीन अनुवाद', 'ru': 'Учимся активно учиться нейронному машинному переводу', 'ga': 'Aistriúchán Meaisín Néarthach a Fhoghlaim go Gníomhach', 'hu': 'A neurális gépi fordítás aktív tanulásának megtanulása', 'el': 'Μάθετε να μαθαίνετε ενεργά Νευρική Μηχανική Μετάφραση', 'ka': 'Name', 'it': 'Imparare a imparare attivamente la traduzione automatica neurale', 'kk': 'Нейрондық машинаның аудармасын белсенді үйрену', 'mk': 'Научи активно да научиш превод на неврални машини', 'lt': 'Mokymasis aktyviai išmokti nervinių mašinų vertimą', 'ms': 'Belajar untuk Mempelajari Terjemahan Mesin Neural secara Aktif', 'mt': 'It-tagħlim biex titgħallem b’mod attiv it-traduzzjoni tal-makkinarju newrali', 'mn': 'Тархины машин хөгжүүлэхийг сурах нь', 'ml': 'ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ പഠിപ്പിക്കുക', 'pl': 'Nauka aktywnego uczenia się neuronalnego tłumaczenia maszynowego', 'ro': 'Învățați să învățați activ traducerea automată neurală', 'no': 'Læring på å lære å aktivt lære neuralmaskinovertering', 'sr': 'Naučenje aktivno naučiti neuronski prevod mašine', 'so': 'Learning to Actively Learn Neural Machine Translation', 'sv': 'Att aktivt lära sig Neural Machine Translation', 'ta': 'செயற்படுத்தப்பட்ட நெயுரல் இயந்திரத்தின் மொழிபெயர்ப்பு கற்றுக்கொள்ளும்', 'ur': 'نیورال ماشین ترجمہ کو فعال سے سیکھنا', 'si': 'ක්\u200dරියාත්මක විද්\u200dයාපනය ඉගෙන ගන්න', 'uz': 'Name', 'vi': 'Học cách Tự động học dịch máy thần kinh', 'nl': 'Leren om actief neuronale machinevertaling te leren', 'bg': 'Научете се активно да учите неврален машинен превод', 'da': 'Lære aktivt at lære Neural Machine Translation', 'hr': 'Naučenje aktivno naučiti neuronski prevod stroja', 'id': 'Learning to Actively Learn Neural Machine Translation', 'ko': '학습 적극 학습 신경 기계 번역', 'de': 'Lernen, neuronale maschinelle Übersetzung aktiv zu lernen', 'fa': 'یاد گرفتن به فعال یاد گرفتن ترجمه ماشین عصبی', 'sw': 'Kujifunza kwa Kiharakati Kujifunza Tafsiri ya Mashine ya Neural', 'af': 'Leer na Aktief Leer Neurale Masjien Vertaling', 'tr': 'Neural Maşynyň terjimesini öwrenmek üçin öwrenmek', 'sq': 'Mësimi për të mësuar aktivisht përkthimin e makinës nervore', 'hy': 'Ակտիվ սովորելու նյարդային մեքենայի թարգմանություն', 'am': 'ትርጉም', 'az': 'N칬ral Makina 칂eviri 칐yr톛nm톛k', 'bn': 'সক্রিয় ভাবে নিউরাল মেশিন অনুবাদ শিখানো', 'bs': 'Naučenje aktivno naučiti neuronski prevod mašine', 'ca': 'Learning to Actively Learn Neural Machine Translation', 'et': 'Neuraalse masintõlke aktiivse õppimise õppimine', 'cs': 'Naučit se aktivně učit neurální strojový překlad', 'fi': 'Oppiminen aktiiviseen neurokääntämiseen', 'jv': 'Jejaring', 'sk': 'Učenje aktivnega učenja nevralnega strojnega prevajanja', 'ha': 'KCharselect unicode block name', 'he': 'ללמוד ללמוד באופן פעיל תרגום מכונת נוירולית', 'bo': 'Neural Machine Translation'}
{'en': 'Traditional active learning (AL) methods for machine translation (MT) rely on ', 'fr': "Les méthodes traditionnelles d'apprentissage actif (AL) pour la traduction automatique (TA) reposent sur l'heuristique. Cependant, ces heuristiques sont limitées lorsque les caractéristiques du problème de TA changent en raison, par exemple, de la paire de langues ou de la quantité du bitexte initial. Dans cet article, nous présentons un cadre pour apprendre les stratégies de sélection de phrases pour la magnétoscopie neuronale. Nous entraînons la stratégie de requête AL à l'aide d'une paire de langues à ressources élevées basée sur des simulations AL, puis nous la transférons à la paire de langues à faible ressource qui vous intéresse. La stratégie de requête apprise capitalise sur les caractéristiques partagées entre les paires de langues pour utiliser efficacement le budget AL. Nos expériences sur trois paires de langues confirment que notre méthode est plus efficace que les méthodes basées sur l'heuristique forte dans diverses conditions, y compris le démarrage à froid et le démarrage à chaud ainsi que dans des conditions de données petites et extrêmement petites.", 'pt': 'Os métodos tradicionais de aprendizado ativo (AL) para tradução automática (MT) dependem de heurísticas. No entanto, essas heurísticas são limitadas quando as características do problema de MT mudam devido a, e. o par de idiomas ou a quantidade do bitexto inicial. Neste artigo, apresentamos uma estrutura para aprender estratégias de seleção de sentenças para MT neural. Treinamos a estratégia de consulta AL usando um par de linguagens de alto recurso com base em simulações de AL e, em seguida, transferimos para o par de linguagem de baixo recurso de interesse. A estratégia de consulta aprendida capitaliza as características compartilhadas entre os pares de idiomas para fazer um uso eficaz do orçamento do AL. Nossos experimentos em três pares de idiomas confirmam que nosso método é mais eficaz do que métodos baseados em heurísticas fortes em várias condições, incluindo partida a frio e partida a quente, bem como condições de dados pequenos e extremamente pequenos.', 'ar': 'تعتمد أساليب التعلم النشط التقليدية (AL) للترجمة الآلية (MT) على الاستدلال. ومع ذلك ، فإن هذه الأساليب التجريبية محدودة عندما تتغير خصائص مشكلة مسرح ماجنت بسبب على سبيل المثال زوج اللغة أو مقدار نص البت الأولي. في هذه الورقة ، نقدم إطارًا لتعلم استراتيجيات اختيار الجملة في الترجمة الآلية العصبية. نقوم بتدريب استراتيجية استعلام AL باستخدام زوج لغوي عالي الموارد استنادًا إلى محاكاة AL ، ثم نقوم بنقلها إلى الزوج اللغوي ذي الموارد المنخفضة محل الاهتمام. تستفيد استراتيجية الاستعلام المكتسب من الخصائص المشتركة بين أزواج اللغات لتحقيق استخدام فعال لميزانية AL. تؤكد تجاربنا على ثلاثة أزواج لغوية أن طريقتنا أكثر فاعلية من الأساليب القوية القائمة على الاستدلال في ظروف مختلفة ، بما في ذلك البداية الباردة والبدء الدافئ وكذلك ظروف البيانات الصغيرة والصغيرة للغاية.', 'es': 'Los métodos tradicionales de aprendizaje activo (AL) para la traducción automática (MT) se basan en la heurística. Sin embargo, estas heurísticas son limitadas cuando las características del problema de MT cambian debido, por ejemplo, al par de idiomas o a la cantidad del bitexto inicial. En este artículo, presentamos un marco para aprender estrategias de selección de oraciones para la MT neuronal. Entrenamos la estrategia de consulta de AL utilizando un par de idiomas de alto recurso basado en simulaciones de AL y, a continuación, lo transferimos al par de idiomas de bajo recurso de interés. La estrategia de consulta aprendida capitaliza las características compartidas entre los pares de idiomas para hacer un uso efectivo del presupuesto AL. Nuestros experimentos con tres pares de idiomas confirman que nuestro método es más eficaz que los métodos basados en heurística sólida en diversas condiciones, incluidos el arranque en frío y el arranque en caliente, así como en condiciones de datos pequeños y extremadamente pequeños.', 'ja': '機械翻訳（ MT ）のための従来のアクティブラーニング（ AL ）方法は、ヒューリスティックに依存しています。しかしながら、これらのヒューリスティックは、例えば言語ペアまたは初期ビットテキストの量によってMT問題の特性が変化する場合に限定される。本稿では，ニューラルMTの文選択戦略を学習するためのフレームワークを提示する． ALシミュレーションに基づいた高リソース言語ペアを使用してALクエリ戦略をトレーニングし、対象の低リソース言語ペアに転送します。学習したクエリ戦略は、言語ペア間の共有特性を利用して、AL予算を有効に活用します。私たちの3つの言語ペアの実験は、コールドスタートやウォームスタート、そして小さくて極めて小さなデータ条件を含むさまざまな条件で、私たちの方法が強力なヒューリスティックベースの方法よりも効果的であることを確認しています。', 'zh': '古机器翻译 (MT) 自学 (AL) 法赖于启发式。 然 MT 言变于初双文本,启发式法有限。 本文中,发一学神经机器翻译句择策之框架。 以 AL 拟之高资言 AL 询之以策,而后移之感兴之低资源语。 学者问策用言语之所同AL。 吾三言之实验证,吾道之于强启发式,冷启动热启动小数也。', 'ru': 'Традиционные методы активного обучения (AL) для машинного перевода (MT) основаны на эвристике. Однако эти эвристические характеристики ограничены, когда характеристики проблемы MT изменяются, например, из-за языковой пары или количества исходного битового текста. В этой статье мы представляем структуру для изучения стратегий выбора предложений для нейронного MT. Мы обучаем стратегию запросов AL, используя высокоресурсную языковую пару, основанную на моделировании AL, а затем переносим ее в представляющую интерес малоресурсную языковую пару. Изученная стратегия запросов опирается на общие характеристики между языковыми парами, чтобы эффективно использовать бюджет AL. Наши эксперименты по трем языковым парам подтверждают, что наш метод более эффективен, чем сильные эвристические методы в различных условиях, включая холодный и теплый запуск, а также малые и крайне малые условия данных.', 'hi': 'मशीन अनुवाद (एमटी) के लिए पारंपरिक सक्रिय सीखने (एएल) विधियां ह्यूरिस्टिक्स पर निर्भर करती हैं। हालांकि, ये ह्यूरिस्टिक्स सीमित होते हैं जब एमटी समस्या की विशेषताएं भाषा जोड़ी या प्रारंभिक बाइटेक्स्ट की मात्रा के कारण बदलती हैं। इस पेपर में, हम तंत्रिका एमटी के लिए वाक्य चयन रणनीतियों को सीखने के लिए एक रूपरेखा प्रस्तुत करते हैं। हम AL सिमुलेशन के आधार पर एक उच्च-संसाधन भाषा-जोड़ी का उपयोग करके AL क्वेरी रणनीति को प्रशिक्षित करते हैं, और फिर इसे कम-संसाधन भाषा-ब्याज की जोड़ी में स्थानांतरित करते हैं। सीखी गई क्वेरी रणनीति AL बजट का प्रभावी उपयोग करने के लिए भाषा जोड़े के बीच साझा विशेषताओं पर कैपिटलाइज़ करती है। तीन भाषा-जोड़े पर हमारे प्रयोग इस बात की पुष्टि करते हैं कि हमारी विधि विभिन्न स्थितियों में मजबूत ह्यूरिस्टिक-आधारित तरीकों की तुलना में अधिक प्रभावी है, जिसमें कोल्ड-स्टार्ट और वार्म-स्टार्ट के साथ-साथ छोटे और बेहद छोटे डेटा की स्थिति भी शामिल है।', 'ga': 'Braitheann modhanna traidisiúnta foghlama gníomhaí (AL) le haghaidh aistriúchán meaisín (MT) ar heuristics. Mar sin féin, tá na heuristics seo teoranta nuair a athraíonn tréithe na faidhbe MT de bharr e.g. an péire teanga nó méid an bhiotéacs tosaigh. Sa pháipéar seo, cuirimid creat i láthair chun straitéisí roghnaithe pianbhreithe a fhoghlaim le haghaidh MT neural. Déanaimid oiliúint ar an straitéis fiosrúcháin AL ag baint úsáide as péire teanga ard-acmhainní bunaithe ar ionsamhlúcháin AL, agus ansin aistrímid chuig an bpéire spéise teanga íseal-acmhainní í. Baineann straitéis na gceisteanna foghlamtha leas as na tréithe comhroinnte idir na péirí teangacha chun úsáid éifeachtach a bhaint as buiséad AL. Deimhníonn ár dturgnaimh ar thrí phéire teanga go bhfuil ár modh níos éifeachtaí ná modhanna láidre heorastúla-bhunaithe i gcoinníollacha éagsúla, lena n-áirítear fuar-tús agus te-tús chomh maith le coinníollacha sonraí beaga agus fíorbheaga.', 'el': 'Οι παραδοσιακές μέθοδοι ενεργού μάθησης (AL) για τη μηχανική μετάφραση (MT) βασίζονται στην Heuristik. Ωστόσο, αυτές οι heuristics είναι περιορισμένες όταν τα χαρακτηριστικά του προβλήματος ΜΤ αλλάζουν λόγω π.χ. του γλωσσικού ζεύγους ή του ποσού του αρχικού bitext. Σε αυτή την εργασία, παρουσιάζουμε ένα πλαίσιο για την εκμάθηση στρατηγικών επιλογής προτάσεων για το νευρωνικό Εκπαιδεύουμε τη στρατηγική ερωτήματος χρησιμοποιώντας ένα γλωσσικό ζεύγος υψηλού πόρου βασισμένο σε προσομοιώσεις και στη συνέχεια τη μεταφέρουμε στο γλωσσικό ζεύγος χαμηλού πόρου ενδιαφέροντος. Η μαθημένη στρατηγική ερωτήματος κεφαλαιοποιεί τα κοινά χαρακτηριστικά μεταξύ των γλωσσικών ζευγαριών για να κάνει αποτελεσματική χρήση του προϋπολογισμού ΑΛ. Τα πειράματά μας σε τρία ζεύγη γλωσσών επιβεβαιώνουν ότι η μέθοδος μας είναι πιο αποτελεσματική από τις ισχυρές heuristische μεθόδους σε διάφορες συνθήκες, συμπεριλαμβανομένων ψυχρής εκκίνησης και θερμής εκκίνησης καθώς και μικρών και εξαιρετικά μικρών συνθηκών δεδομένων.', 'ka': 'ტრადიციონალური აქტიური სწავლების (AL) მეტოვები მანქანის გარგულისხმებისთვის (MT) დააყენება ჰერისტიკზე. მაგრამ, ეს ჰერისტიკა უდრის, როდესაც MT პრობლემის პრობლემის პრობლემის პრობლემის პრობლემის პრობლემის პრობლემები ცვლილება, მაგალითად ენის ზოგი ან ამ დომენტში ჩვენ ვიყავით ფრამეტრი, რომელიც შევისწავლოთ სიტყვების მონიშნული სტრატეგიები ნეიროლ MT-ს. ჩვენ აკითხვის სტრატეგიგია, რომელიც ალური სიმულაციებიდან ბაზიან მეტი რესურსისურსის სახე ნასწავლილი კითხვის სტრატიგია კაპოთრალიზებს ალური ბიზეტის ეფექტიური გამოყენება. ჩვენი ექსპერიმენტები სამუშაო ენახური ორივეზე დარწმუნდება, რომ ჩვენი მედიოდი უფრო ეფექტიურია, ვიდრე ძალიან ჰერისტიკური მედიოდი განსხვავებულ სხვადასხვადასხვადასხვადას', 'hu': 'A gépi fordítás hagyományos aktív tanulási (AL) módszerei heurisztikára épülnek. Ezek a heurisztikák azonban korlátozottak, amikor az MT probléma jellemzői megváltoznak például a nyelvpár vagy a kezdeti bitext mennyisége miatt. Ebben a tanulmányban bemutatjuk a neurális MT mondatválasztási stratégiáinak megtanulását. Az AL lekérdezési stratégiát egy AL szimulációkon alapuló, nagy erőforrású nyelvpár segítségével képezzük, majd átadjuk az alacsony erőforrású nyelvpárba. A megtanult lekérdezési stratégia kihasználja a nyelvpárok közötti megosztott jellemzőket az AL költségvetés hatékony felhasználása érdekében. Három nyelvpáron végzett kísérleteink megerősítik, hogy módszerünk hatékonyabb, mint az erős heurisztikai alapú módszerek különböző körülmények között, beleértve a hidegindítást és a melegindítást, valamint a kis és rendkívül kis adatokat.', 'lt': 'Tradicinis aktyvus mokymasis mašinų vertimo metodai (MT) grindžiami heuristika. Tačiau šios heuristikos yra ribotos, kai MT problemos charakteristikos pasikeičia, pvz., dėl kalbos poros arba pradinio įkandimo kiekio. Šiame dokumente pristatome sistemą, pagal kurią išmoksime rengti sakinius neuraliniam MT. Mokome JL paklausos strategiją naudojant aukšto išteklio kalbų porą, pagrįstą JL modeliavimais, ir tada perduodame ją mažo išteklio kalbų porai interesų. Išmokytų klausimų strategijoje naudojamos bendros kalbų poros savybės, kad būtų veiksmingai panaudotas JL biudžetas. Mūsų eksperimentai su trimis kalbų poromis patvirtina, kad mūsų metodas įvairiomis sąlygomis yra veiksmingesnis nei tvirtesni heuristiniais metodais, įskaitant šaltą pradžią ir šiltą pradžią, taip pat mažas ir labai mažas duomenų sąlygas.', 'mk': 'Традиционално активно учење (АЛ) методи за машински превод (МТ) зависат од хеористика. Сепак, овие хеористики се ограничени кога карактеристиките на проблемот со МТ се менуваат поради, на пример, јазичниот пар или количината на првичниот гриз. Во овој документ, претставуваме рамка за учење стратегии за селекција на реченици за невралниот МТ. Ја обучуваме стратегијата за прашање на АЛ користејќи пар јазик со високи ресурси базиран на симулации на АЛ, а потоа ја префрлиме на пар јазик со ниски ресурс Стратегијата за научено прашање ги користи заедничките карактеристики помеѓу паровите на јазици за ефикасна употреба на буџетот на АЛ. Нашите експерименти на три пара јазици потврдуваат дека нашиот метод е поефикасен од силните методи базирани на хеористика во различни услови, вклучително и ладниот и топлиот почеток, како и мали и екстремно мали податочни услови.', 'it': "I metodi tradizionali di apprendimento attivo (AL) per la traduzione automatica (MT) si basano sull'euristica. Tuttavia, queste euristiche sono limitate quando le caratteristiche del problema MT cambiano a causa, ad esempio, della coppia linguistica o della quantità del bitest iniziale. In questo articolo, presentiamo un framework per imparare le strategie di selezione delle frasi per MT neurale. Alleniamo la strategia di query AL utilizzando una coppia di lingue ad alta risorsa basata su simulazioni AL, e poi la trasferiamo alla coppia di lingue a bassa risorsa di interesse. La strategia di query appresa capitalizza le caratteristiche condivise tra le coppie linguistiche per fare un uso efficace del budget AL. I nostri esperimenti su tre coppie linguistiche confermano che il nostro metodo è più efficace di metodi euristici forti in varie condizioni, tra cui avviamento a freddo e avvio a caldo, nonché condizioni di dati di piccole dimensioni ed estremamente piccole.", 'ml': 'മെഷിന്\u200d പരിഭാഷയ്ക്കുള്ള പാഠമായ സജ്ജീവമായ പഠിക്കുന്നതിനുള്ള (AL) രീതികള്\u200d എന്നാലും എംടി പ്രശ്നത്തിന്റെ സ്വഭാവം മാറുമ്പോള്\u200d ഈ ഹൂരിസ്റ്റിക്കുകള്\u200d പരിധിയിലാകുന്നു. ഉദാഹരണമായ ഭാഷ ജോട്ടിയോ ആദ്യ കട ഈ പത്രത്തില്\u200d നമ്മള്\u200d വാക്ക് തെരഞ്ഞെടുക്കുന്ന സ്ട്രാക്രേജ്ജികള്\u200d പഠിപ്പിക്കാന്\u200d ഒരു ഫ്രെയിമെയില്\u200d കൊണ്ടുവരുന്നു. ന്യൂറല്\u200d എംടിക്ക് വേണ്ടി നമ്മള്\u200d എല്\u200d ചോദ്യ പഠിച്ചുകൊണ്ടിരിക്കുന്ന സ്ട്രായ്ട്രിക്റ്റിജി എല്\u200d ബാഗ്റ്റ് ഉപയോഗിക്കാന്\u200d ഭാഷ ജോടികള്\u200dക്കിടയില്\u200d പങ്കുച മൂന്നു ഭാഷയിലെ ഇണകളില്\u200d നമ്മുടെ പരീക്ഷണങ്ങള്\u200d ഉറപ്പ് വരുത്തുന്നു നമ്മുടെ രീതിയില്\u200d ശക്തമായ ഹൂരിസ്റ്റിക്ക് അടിസ്ഥാനമായ രീതികളെക്കാള്\u200d പ്രാ', 'ms': 'Kaedah pembelajaran aktif tradisional (AL) untuk terjemahan mesin (MT) bergantung pada heuristik. Namun, heuristik ini terbatas bila ciri-ciri masalah MT berubah kerana contoh pasangan bahasa atau jumlah gigitan awal. Dalam kertas ini, kami memperkenalkan kerangka untuk belajar strategi pemilihan kalimat untuk MT saraf. Kami melatih strategi pertanyaan AL menggunakan pasangan bahasa-sumber tinggi berdasarkan simulasi AL, dan kemudian memindahkannya ke pasangan bahasa-sumber rendah kepentingan. Strategi pertanyaan belajar menggunakan ciri-ciri terkongsi antara pasangan bahasa untuk menggunakan anggaran AL secara efektif. Eksperimen kami pada tiga pasangan bahasa mengesahkan bahawa kaedah kami lebih berkesan daripada kaedah kuat berdasarkan heuristik dalam berbagai keadaan, termasuk permulaan sejuk dan permulaan hangat serta keadaan data kecil dan sangat kecil.', 'kk': 'Құрылғының аудару (MT) әдетті белсенді үйрену (AL) әдістері геуристикаға тәуелді. Бірақ, MT мәселесінің қасиеттері өзгертілген кезде, мысалы тіл екі не бастапқы бит мәтінінің қасиеттері шектелген. Бұл қағазда, сөздерді таңдау стратегияларын невралдық MT үшін үйрену үшін фреймін таңдаймыз. AL симулацияларына негізделген жоғары ресурстар тілді қолдану арқылы AL сұраныс стратегиясын үйренеміз. Оқылған сұраныс стратегиясы AL бюджетінің эффективні қолдану үшін тіл екеуінің ортақтастырылған қасиеттеріне көлемді. Үш тіл екі тәжірибелеріміздің тәжірибелеріміз әртүрлі шарттарда жұмыс бастау және жылу бастау және кішкентай және өте кішкентай деректер шарттарында тәжірибелеріміздің күшті геуристік тәж', 'mt': 'Il-metodi tradizzjonali tat-tagħlim attiv (AL) għat-traduzzjoni bil-magna (MT) jiddependu fuq il-ħewristiċi. Madankollu, dawn il-ħewristiċi huma limitati meta l-karatteristiċi tal-problema MT jinbidlu minħabba pereżempju l-pari tal-lingwa jew l-ammont tat-test inizjali. F’dan id-dokument, qed nippreżentaw qafas biex nitgħallmu l-istrateġiji tal-għa żla tas-sentenzi għall-MT newrali. L-istrateġija ta’ mistoqsija miksuba tikkapitalizza fuq il-karatteristiċi kondiviżi bejn il-pari lingwistiċi biex tagħmel użu effettiv mill-baġit tal-AL. Our experiments on three language-pairs confirms that our method is more effective than strong heuristic-based methods in various conditions, including cold-start and warm-start as well as small and extremely small data conditions.', 'no': 'Tradisjonale aktive læring (AL) metodar for maskinsomsetjing (MT) er på heuristikk. Desse heuristica er imidlertid begrenset når karakteristika av MT- problemet endrar på grunn av, for eksempel, språkopla eller kva mykje av startteksten. I denne papiret viser vi eit rammeverk for å lære setningsstrategiar for neural MT. Vi treng AL- spørringsstrategien ved å bruka eit høg- ressursspråk- par basert på AL simulasjonar, og så overføra det til den låg- ressursspråk- par interesse. The learned query strategy capitalises on the shared characteristics between the language pairs to make an effective use of the AL budget. Eksperimentane våre på tre språkopar stadfestar at metoden vårt er meir effektiv enn sterke heuristiske metodar i ulike vilkår, inkludert kald-start og varm-start, og små og ekstremt lite dataforhold.', 'pl': 'Tradycyjne metody aktywnego uczenia się (AL) dla tłumaczenia maszynowego (MT) opierają się na heurystyce. Jednakże heurystyka ta jest ograniczona, gdy charakterystyka problemu MT zmienia się np. z powodu pary językowej lub ilości początkowego bitekstu. W niniejszym artykule przedstawiamy ramy do nauki strategii selekcji zdań dla neuronowego MT. Trenujemy strategię zapytania AL za pomocą pary językowej o wysokich zasobach opartej na symulacjach AL, a następnie przenosimy ją do pary językowej o niskich zasobach. Uczona strategia zapytań wykorzystuje wspólne cechy pomiędzy parami językowymi, aby skutecznie wykorzystać budżet AL. Nasze eksperymenty na trzech parach językowych potwierdzają, że nasza metoda jest bardziej skuteczna niż silne metody heurystyczne w różnych warunkach, w tym zimny start i ciepły start oraz małe i niezwykle małe warunki danych.', 'si': 'පරාමාන්\u200dය සක්\u200dරිය ඉගෙනීම (AL) විධානය පද්ධතිය (MT) හෙයුරිස්ටික් වලට විශ්වාස කරන්න. නමුත්, මේ හෙයුරිස්ටික්ස්ටික් සීමාවිත වෙනවා MT ප්\u200dරශ්නයේ අවශ්\u200dය වෙනස් වෙන්න, උදාහරණයෙන් භාෂා ජෝඩා නැත් මේ පැත්තේ අපි පෙන්වන්නේ වාක්ය තෝරණාත්මක ඉගෙන ගන්න ප්\u200dරශ්ණයක්. අපි AL සැකසුම් භාෂාත්මක භාෂාත්මක භාෂාවක් භාවිත කරන්න AL ප්\u200dරශ්ණ ඉගෙන ගත්ත ප්\u200dරශ්න සංයෝජනය විශේෂය ඇල් බිජිට්ටුවේ ප්\u200dරයෝජනයක් කරන්න භාෂාවක් සමාගත විශේෂය අපේ පරීක්ෂණය භාෂාව තුනක් දෙන්න තියෙනවා අපේ පරීක්ෂණය ප්\u200dරශ්නයක් විවිධ අවස්ථාවට වඩා ශක්තිමත් හෙයුරිස්ටික් අධාරිත විදි', 'sr': 'Tradicionalne aktivne metode učenja (AL) za prevod mašine (MT) oslanjaju se na heuristiku. Međutim, ove heuristike su ograničene kada se karakteristike problema MT-a promene zbog primjerice jezičkog parova ili količine početnog ugriza. U ovom papiru predstavljamo okvir da naučimo strategiju selekcije rečenica za neuralni MT. Treniramo strategiju AL pitanja koristeći par jezika visokog resursa baziranog na simulaciji AL, a zatim ga prebacimo na par interesa s niskim resursima. Naučena strategija pitanja kapitalizira se na zajedničke karakteristike između jezičkih parova kako bi se učinkovito iskoristila AL budžet. Naši eksperimenti na tri parova jezika potvrđuju da je naš metod efikasniji od jakih heurističkih metoda u različitim uvjetima, uključujući hladno početak i toplo početak, kao i male i ekstremno male podatke.', 'so': 'Waxbarashada caadiga ah (AL) qaababka lagu turjumo machine (MT) waxay ku xiran tahay heuristics. Si kastaba ha ahaatee xilliyadaasu waa xad, marka ay takhasuska dhibaatada MT u beddelaan tusaale ahaan labada luqada ama tirada qaniinka hore. Qoraalkan waxaynu qoraal ka dhigaynaa qoraal doorasho oo loo baro qoraalka doorashada ee neurada MT. Waxaynu ku tababarinnaa qoraalka wax weydiinta AL, oo ku isticmaalaynaa qoraalka luqada sare-resource-labo oo ku saleysan AL similar, kadibna waxaynu u u beddelinaynaa noocyada hoos-resource-nooc oo xiiso ah. The learned query strategy capitalizes on the shared characteristics between the language pairs to make an effective use of the AL budget.  Imtixaankayada ku qoran saddex luqadood waxay xaqiijiyaan in qaababkayagu ay ka shaqeeyaan qaabab xoog leh oo ku saabsan hablada kala duduwan, kuwaas oo ah qabowga iyo bilowga kulaylka iyo shuruudaha macluumaadka yar iyo aad u yar.', 'mn': 'Машин хөрөнгө оруулах (MT) аргын уламжлалт идэвхитэй суралцах (AL) арга нь хюристик дээр байдаг. Гэвч энэ хюристик нь MT асуудлын харилцаа өөрчлөгдөхөд хязгаарлагддаг. Жишээлбэл хэл хоёр эсвэл анхны үеийн хэмжээ. Энэ цаасан дээр бид мэдрэлийн MT-ийн өгүүлбэр сонголтын стратегийг суралцахын тулд нэг хэлбэрийг суралцаж байна. Сургуулсан query стратеги нь хэл хоёр хоёр хоорондын хуваалцаагүй харьцааг ашиглах боломжтой болно. Гурван хэл хоёрын туршилтууд бидний арга нь олон нөхцөлд хүйтэн, дулаан эхлэл, жижиг, маш жижиг мэдээллийн нөхцөл байдлаас илүү үр дүнтэй гэдгийг баталдаг.', 'sv': 'Traditionella metoder för aktivt lärande (AL) för maskinöversättning (MT) är beroende av heuristik. Dessa heuristiker är dock begränsade när egenskaperna hos MT-problemet ändras på grund av t.ex. språkparet eller mängden av den ursprungliga bitexten. I den här uppsatsen presenterar vi ett ramverk för att lära oss frasurvalsstrategier för neuralt MT. Vi tränar AL-frågestrategin med hjälp av ett högresursspråkpar baserat på AL-simuleringar, och överför den sedan till intresset för lågresursspråk. Den lärda frågestrategin utnyttjar de gemensamma egenskaperna mellan språkparen för att effektivt utnyttja AL-budgeten. Våra experiment på tre språkpar bekräftar att vår metod är effektivare än starka heuristiska baserade metoder under olika förhållanden, inklusive kallstart och varmstart samt små och extremt små dataförhållanden.', 'ro': 'Metodele tradiționale de învățare activă (AL) pentru traducerea automată (MT) se bazează pe euristică. Cu toate acestea, aceste euristice sunt limitate atunci când caracteristicile problemei MT se schimbă din cauza perechii de limbi sau a cantității bitextului inițial. În această lucrare, prezentăm un cadru pentru a învăța strategiile de selecție a frazelor pentru MT neural. Antrenăm strategia de interogare AL folosind o pereche de limbi cu resurse ridicate bazată pe simulări AL, și apoi o transferăm la perechea de limbi cu resurse reduse de interes. Strategia de interogare învățată valorifică caracteristicile comune între perechile de limbi pentru a utiliza eficient bugetul AL. Experimentele noastre pe trei perechi de limbi confirmă că metoda noastră este mai eficientă decât metodele euristice puternice în diferite condiții, inclusiv pornirea la rece și pornirea la cald, precum și condiții de date mici și extrem de mici.', 'ta': 'இயந்திரத்தின் மொழிபெயர்ப்பு (MT) முறைமைகளை பாரம்பரியமான செயல்பாடு கற்றல் (AL) முறைமைகளை முழுமையாக நம்பு எனினும், எம்டி பிரச்சினையின் தன்மைகள் மாறும்போது, இந்த உதாரணமாக மொழி ஜோடி அல்லது ஆரம்ப ப பிட்டின் கூட்டத்திற்கு வரையறையும். இந்த காகிதத்தில், நாம் ஒரு வாக்கிய தேர்வு தேர்ந்தெடுப்பு திட்டங்களை கற்றுக்கொள்ள ஒரு சட்டத்தை கொண்டு வருகிறோம். நாம் AL கேள்வி திட்டத்தை பயிற்சி செய்து AL பாவன மொழி ஜோடிகளுக்கிடையில் பங்கிடப்பட்ட கேள்வி திட்டத்திற்கு மதிப்பிடும் மொழி ஜோடிகளுக்கு இடையே கூடிய தன்மைகளை  மூன்று மொழி ஜோடிகள் மீது எங்கள் சோதனைகளை உறுதிப்படுத்துகிறது என்று நம் முறையில் முறையில் வலுவான ஹூரிஸ்டிக் அடிப்படையான முறைகளை விட அதிகமாக த', 'ur': 'مشین ترجمہ (MT) کے لئے پیدائمی فعال یادگیری (AL) طریقے پر اعتماد رکھتے ہیں. However, these heuristics are limited when the characteristics of the MT problem change for example the language pair or the amount of the initial bitetext. اس کاغذ میں ہم نے ایک فرمود پیش کیا ہے کہ کلمات انتخاب استراتژی کو سکونت سکونت دیں. ہم نے AL سیمولیشن پر بنیاد رکھی ایک عالی-منبع زبان-جوڑ کے استعمال سے AL کیورس استراتژی کو تربیت دیتے ہیں اور پھر اسے کم منبع زبان-جوڑ کی طرف تربیت کریں سکھایا گیا کیوری استراتژی آل بوجٹ کے مطابق استعمال کرنے کے لئے زبان جوڑوں کے درمیان مشترک خصوصیات کے ذریعے کاپیٹ کرتی ہے. ہمارے تین زبان جوڑوں کی آزمائش کی تصدیق کرتی ہے کہ ہمارا طریقہ مختلف شرایطوں میں مضبوط ہوریستیک بنیاد رکھنے والی روش سے زیادہ اثر ہے، یہاں تک کہ ٹھنڈ شروع اور گرم شروع اور بہت چھوٹی اور بہت چھوٹی ڈیٹا شرایط میں', 'uz': "Name Lekin, bu heuristika MT muammolarning xususiyatlarini oʻzgartirishda chegara boʻladi, masalan tilning ikki xil yoki birinchi qismning soni. Bu qogʻozda, biz bir so'zni tanlash strategiyasini o'rganish uchun o'zgarishni o'rganamiz. Biz AL simuliyatlari asosida juda yuqori resource tili ikkita so'z strategiyasini o'rganamiz va keyin ularni qiziqarish uchun juda qiziqarish mumkin. @ info: status Bizning uchta tildagi tajribalarimiz, bizning usuli har xil holatdagi kuchli heuristika asosida ishlaydigan usullarda ishlatiladi. Bu holatdagi sariq boshlash va issiq boshlash va kichkina va juda kichkina maʼlumot holatida.", 'vi': 'Phương pháp giáo dục hoạt động truyền thống (Al) cho dịch chuyển máy (MTV) dựa vào thần kinh. Tuy nhiên, các thần kinh này bị giới hạn khi các đặc trưng của vấn đề MTV thay đổi do ví dụ như là cặp ngôn ngữ hay con số của thực phẩm ban đầu. Trong tờ giấy này, chúng tôi giới thiệu một cơ sở để học các chiến lược chọn câu cho tập đoàn sóng thần kinh. Chúng tôi đào tạo chiến lược truy vấn ALA bằng một đôi ngôn ngữ với nguồn cao dựa trên giả lập ALl, và chuyển nó sang một cặp ngôn ngữ ít tài nguyên. Các chiến lược tìm kiếm học sử dụng các đặc tính chia sẻ giữa các cặp ngôn ngữ để thực hiện hiệu quả sử dụng ngân sách L. Những thí nghiệm trên ba cặp ngôn ngữ xác nhận phương pháp của chúng ta hiệu quả hơn các phương pháp thần kinh mạnh mẽ trong nhiều điều kiện khác nhau, bao gồm bắt đầu lạnh, bắt đầu nóng, cũng như các điều kiện dữ liệu nhỏ và cực nhỏ.', 'bg': 'Традиционните методи за активно обучение (АЛ) за машинен превод (МТ) разчитат на евристиката. Тези евристика обаче са ограничени, когато характеристиките на задачата МТ се променят поради например езиковата двойка или размера на първоначалния биттекст. В тази статия представяме рамка за изучаване на стратегии за подбор на изречения за неврален Обучаваме стратегията за запитване с помощта на езикова двойка с висок ресурс, базирана на симулации и след това я прехвърляме към езиковата двойка с нисък ресурс. Научената стратегия за заявка се възползва от споделените характеристики между езиковите двойки, за да се възползва ефективно от бюджета на АЛ. Експериментите ни с три езикови двойки потвърждават, че методът ни е по-ефективен от силните евристични методи при различни условия, включително при студен и топъл старт, както и при малки и изключително малки условия на данни.', 'da': 'Traditionelle metoder til aktiv læring (AL) til maskinoversættelse (MT) er afhængige af heuristik. Disse heuristikker er imidlertid begrænsede, når karakteristika ved MT-problemet ændrer sig på grund af f.eks. sprogparret eller mængden af den oprindelige bitekst. I denne artikel præsenterer vi en ramme til at lære sætningsudvælgelsesstrategier for neural MT. Vi træner AL forespørgselsstrategien ved hjælp af et høj ressource sprogpar baseret på AL simuleringer, og derefter overfører den til lav ressource sprogpar af interesse. Den lærte forespørgselsstrategi udnytter de fælles karakteristika mellem sprogparrene for at gøre en effektiv brug af AL-budgettet. Vores eksperimenter på tre sprogpar bekræfter, at vores metode er mere effektiv end stærke heuristiske baserede metoder under forskellige forhold, herunder koldstart og varmstart samt små og ekstremt små dataforhold.', 'nl': 'Traditionele actieve leermethoden (AL) voor machinevertaling (MT) zijn gebaseerd op heuristiek. Deze heuristieken zijn echter beperkt wanneer de kenmerken van het MT-probleem veranderen door bijvoorbeeld het taalpaar of de hoeveelheid van de initiële bitext. In dit artikel presenteren we een raamwerk om zinnenselectiestrategieën voor neurale MT te leren. We trainen de AL query strategie met behulp van een hoog-resource taalpaar op basis van AL simulaties, en brengen deze over naar het low-resource taalpaar van belang. De geleerde query strategie maakt gebruik van de gedeelde kenmerken tussen de taalparen om effectief gebruik te maken van het AL budget. Onze experimenten met drie taalparen bevestigen dat onze methode effectiever is dan sterke heuristische methoden in verschillende omstandigheden, waaronder koude en warme start evenals kleine en extreem kleine data omstandigheden.', 'hr': 'Tradicionalne aktivne metode učenja (AL) za prevod strojeva (MT) oslanjaju se na heuristiku. Međutim, ove heuristike su ograničene kada se karakteristike MT problema promjene zbog primjerice jezičkog parova ili količine početnog ugriza. U ovom papiru predstavljamo okvir da naučimo strategiju izbora rečenica za neuralni MT. Uvježbamo strategiju AL pitanja koristeći par visokih resursa na temelju simulacije AL, a zatim ga prebacimo na par interesa s niskim resursima. Naučena strategija pitanja kapitalizira se na zajedničke karakteristike između jezičkih parova kako bi se učinkovito iskoristila proračun AL. Naši eksperimenti na tri jezička parova potvrđuju da je naš metod učinkovitiji od jakih heurističkih metoda u različitim uvjetima, uključujući hladno početak i toplo početak, kao i male i izuzetno male podatke.', 'de': 'Traditionelle Methoden des aktiven Lernens (AL) für maschinelle Übersetzung (MT) basieren auf Heuristiken. Diese Heuristiken sind jedoch begrenzt, wenn sich die Eigenschaften des MT-Problems durch z.B. das Sprachpaar oder die Menge des anfänglichen Bitexts ändern. In diesem Beitrag stellen wir ein Framework vor, um Satzselektionsstrategien für neuronale MT zu erlernen. Wir trainieren die AL-Abfragestrategie mit Hilfe eines High-Resource-Sprachpaares basierend auf AL-Simulationen und übertragen sie dann auf das Low-Resource-Sprachpaar von Interesse. Die erlernte Abfragestrategie nutzt die gemeinsamen Merkmale zwischen den Sprachpaaren, um das AL-Budget effektiv zu nutzen. Unsere Experimente an drei Sprachpaaren bestätigen, dass unsere Methode effektiver ist als starke heuristische Methoden unter verschiedenen Bedingungen, einschließlich Kaltstart und Warmstart sowie kleinen und extrem kleinen Datenbedingungen.', 'id': 'Metode tradisional belajar aktif (AL) untuk terjemahan mesin (MT) bergantung pada heuristik. Namun, heuristik ini terbatas ketika karakteristik masalah MT berubah karena contoh pasangan bahasa atau jumlah gigitan awal. Dalam kertas ini, kami mempersembahkan rangkaian untuk belajar strategi seleksi kalimat untuk MT saraf. kami melatih strategi pertanyaan AL menggunakan pasangan bahasa sumber daya tinggi berdasarkan simulasi AL, dan kemudian memindahkannya ke pasangan bahasa sumber daya rendah yang tertarik. The learned query strategy capitalizes on the shared characteristics between the language pairs to make an effective use of the AL budget.  Eksperimen kami pada tiga pasangan bahasa mengkonfirmasi bahwa metode kami lebih efektif daripada metode kuat berdasarkan heuristik dalam berbagai kondisi, termasuk awal dingin dan awal hangat serta kondisi data kecil dan sangat kecil.', 'fa': 'روش\u200cهای یادگیری فعال سنتی (AL) برای ترجمه ماشین (MT) بر هوریستیک اعتماد دارند. با این حال، این حوریستیک محدود می\u200cشوند وقتی ویژگی\u200cهای مشکل MT تغییر می\u200cدهند، به عنوان مثال جفت زبان یا مقدار متن آغاز. در این کاغذ، ما یک چهارچوب برای یاد گرفتن استراتژی انتخاب جمله برای MT عصبی را پیشنهاد می\u200cکنیم. ما استراتژی AL سوال را با استفاده از یک جفت زبان بالا منبع بر اساس شبیه\u200cسازی AL آموزش می\u200cدهیم، سپس آن را به جفت زبان کم منبع انتقال می\u200cده استراتژی پرسیدن یاد گرفته روی ویژگی\u200cهای مشترک بین جفت زبان\u200cها سرمایه گذاری می\u200cکند تا یک استفاده موثر از بودجه AL را انجام دهد. آزمایشات ما در سه جفت زبان تایید می\u200cکند که روش ما بیشتر از روش\u200cهای بسیار سخت در شرایط مختلف است، شامل شروع سرد و گرم و شرایط داده\u200cهای کوچک و بسیار کوچک.', 'tr': 'Däpli faýly öwrenmek (AL) yöntemleri maşynyň terjime etmek üçin heuristiklere ynanýar. Ýöne bu heuristik MT meseläniň karakterleriniň üýtgetmesi sebäbi, myselýe dil çift ýada başlangyş bitkiniň habarynyň barlanmasynda çarpylýar. Bu kagyzda, biz sözlem saýlamak strategiýasyny neural MT üçin öwrenmek üçin bir çerçewçiliki görkeýäris. Biz AL simulasyýasyna daýanýan AL soragy strategiýasyny we soňra ol işi iň az resurslar dilinde gyzyklanýan iki üçin süýtgedýäris. Öwrenmeli soragy strategiýasy AL budžetynyň etkinlik ulanmak üçin dil çiftleriň arasyndaky paylaşyk karakterleriň üstine kapitalizýar. Biziň 3 dil çift deneylerimiz biziň metodamyzyň, dürli şertlerde, sowuk we ısı başlangyç we kiçi we örän kiçi hereket şertleri ýok bolandygyny tassyklaýar.', 'ko': '기계번역(MT)의 전통적인 능동학습(AL) 방법은 계발식에 의존한다.그러나 기계 번역 문제의 특징이 언어가 맞거나 초기 텍스트의 수량에 따라 바뀔 때 이러한 계발식 방법은 유한하다.본고에서 우리는 신경기계 번역 문장 선택 전략을 학습하는 구조를 제시했다. 우리는 인공지능 시뮬레이션을 바탕으로 하는 고자원 언어를 사용하여 인공지능 조회 전략을 훈련한 다음에 이를 관심 있는 저자원 언어로 전환시켰다.학습의 조회 전략은 언어 대 간의 공유 특징을 이용하여 AL 예산을 효과적으로 이용한다.우리는 세 쌍의 언어에서의 실험을 통해 각종 조건하에서 냉가동과 열가동, 그리고 작은 데이터와 극소 데이터 조건에서 우리의 방법이 강한 계발식에 기초한 방법보다 더욱 효과적임을 증명하였다.', 'af': "Tradisjoneel aktiewe leer (AL) metodes vir masjien vertaling (MT) vertrou op heuristics. Maar hierdie heuristieke is beperk wanneer die karakteristieke van die MT problem e verander vanweë die taal paar of die hoeveelheid van die aanvanklike bitteks. In hierdie papier, ons stel 'n raamwerk voor te leer setseleksie strategies vir neurale MT. Ons tref die AL navraag strategie met 'n hoë-hulpbron taal-paar gebaseer op AL simulasies, en dan oordra dit na die lae-hulpbron taal-paar belang. Die geleer navraag strategie kapitaliseer op die gedeelde karakteristieke tussen die taal paar om 'n effektief gebruik van die AL budžet te maak. Ons eksperimente op drie taal-pare bevestig dat ons metode meer effektief is as sterk heuristiese-gebaseerde metodes in verskillende voorwaardes, insluitend koud-begin en warm-begin as ook klein en ekstrem klein data-voorwaardes.", 'sw': 'mbinu za kujifunza za kitamaduni (AL) za kutafsiri mashine (MT) zinategemea vizuri. Hata hivyo, takwimu hizi zimepungua wakati utaalamu wa tatizo la MT unapobadilika kwa sababu ya mfano, wawili wa lugha au kiasi cha biti ya mwanzo. Katika karatasi hii, tunaweka mfumo wa kujifunza mikakati ya uchaguzi wa hukumu kwa ajili ya MT ya asili. Tunafundisha mkakati wa utafiti wa AL kwa kutumia mbinu za lugha za juu kwa kutumia mifano ya AL, na kisha kuibadilisha kwenye lugha ya chini ya rasilimali yenye maslahi. Mkakati wa utafiti uliojifunza umejikita kwenye utaalam ulioenekana kati ya wanaume wa lugha ili kutengeneza matumizi ya bajeti ya AL. Majaribio yetu katika lugha tatu yanathibitisha kuwa mbinu yetu ni yenye ufanisi zaidi ya mbinu zilizoko kwa utulivu wa heuristi katika hali mbalimbali, ikiwa ni pamoja na mwanzo wa baridi na mwanzo wa joto pamoja na hali ndogo na madogo ya taarifa.', 'hy': 'Մեքենայի թարգմանման ավանդական ակտիվ ուսումնասիրության (ԱԼ) մեթոդները հիմնված են հորիստիկայի վրա: Այնուամենայնիվ, այս հորիստիկան սահմանափակ է, երբ MT խնդրի հատկությունները փոխվում են օրինակ լեզվի զույգի կամ սկզբնական կծության չափի պատճառով: In this paper, we present a framework to learn sentence selection strategies for neural MT. We train the AL query strategy using a high-resource language-pair based on AL simulations, and then transfer it to the low-resource language-pair of interest.  The learned query strategy capitalizes on the shared characteristics between the language pairs to make an effective use of the AL budget.  Մեր փորձարկումները երեք լեզվի զույգերի վրա հաստատում են, որ մեր մեթոդը ավելի արդյունավետ է, քան ուժեղ հորիստիկ հիմնված մեթոդները տարբեր պայմաններում, ներառյալ սառը սկիզբը և տաք սկիզբը, ինչպես նաև փոքր և չափազանց փոքր', 'az': 'Makinatın çevirilməsi (MT) üçün ehirstik işlənmə metodları heyristik üstündə təvəkkül edir. Ancaq bu heuristik MT probleminin xüsusiyyətləri, məsələn dil çift və ya başlangıç yazıcının dəyişikliyinə g örə dəyişiklikdə sınırlanır. Bu kağıtda, cümlələr seçmək üçün nöral MT stratejilərini öyrənmək üçün bir framework ü göstəririk. AL simulasiyalarına dayanan yüksək ressurs dili çift vasitəsilə AL query stratejisini təhsil edirik və sonra onu düşük ressurs dili çift təhsil edərik. Öyrənmiş query stratejisi AL budžetinin faydalı istifadə etmək üçün dil çiftlərinin arasındakı paylaşılmış xüsusiyyətlərə kapitalizat edir. Üç dil çift təcrübələrimiz təşkil edir ki, metodumuzun müxtəlif şərtlərdə, soğuq başlatma və sıcak başlatma və küçük və çox kiçik məlumat şartları içərisində güclü heuristik vasitələrindən daha etkilidir.', 'sq': 'Metodat tradicionale të mësimit aktiv (AL) për përkthimin e makinave (MT) mbështeten në heuristikë. Megjithatë, këto heuristikë janë të kufizuara kur karakteristikat e problemit MT ndryshojnë për shkak të, për shembull, çiftit gjuhësor apo sasisë së kafshimit fillestar. Në këtë letër, ne paraqesim një kuadër për të mësuar strategjitë e zgjedhjes së fjalëve për MT neuronale. ne trajnojmë strategjinë e pyetjes AL duke përdorur një çift gjuhësh me burime të larta bazuar në simulimet AL, dhe pastaj e transferojmë në çiftin gjuhësh me burime të ulëta të interesit. Strategjia e pyetjes së mësuar përfiton nga karakteristikat e përbashkëta midis çifteve gjuhësh për të bërë një përdorim efektiv të buxhetit të AL. Eksperimentet tona në tre palë gjuhësh konfirmojnë se metoda jonë është më e efektshme se metodat e forta të bazuara në heuristik në kushte të ndryshme, duke përfshirë fillimin e ftohtë dhe fillimin e ngrohtë si dhe kushtet e vogla dhe ekstremisht të vogla të të dhënave.', 'bs': 'Tradicionalne aktivne metode učenja (AL) za prevod mašine (MT) oslanjaju se na heuristiku. Međutim, ove heuristike su ograničene kada se karakteristike problema MT-a promene zbog primjerice jezičkog parova ili količine početnog ugriza. U ovom papiru predstavljamo okvir da naučimo strategiju selekcije rečenica za neuralni MT. Treniramo strategiju AL pitanja koristeći par jezika visokih resursa baziranog na simulaciji AL, a zatim ga prebacimo na par interesa s niskim resursima. Naučena strategija pitanja kapitalizira se na zajedničke karakteristike između parova jezika kako bi se učinkovito iskoristila AL budžet. Naši eksperimenti na tri parova jezika potvrđuju da je naš metod efikasniji od jakih heurističkih metoda u različitim uvjetima, uključujući hladno početak i toplo početak, kao i male i ekstremno male podatke.', 'am': 'የባሕላዊው ተማርክ (AL) methods for machine translation (MT) በheuristics ምንም እንኳን፣ እነዚህ ሀውራሲዎች የMT ጉዳይ ግንኙነት በተለወጡ ጊዜ ወይም ቋንቋው ሁለት ወይም የመጀመሪያው ቁጥር ቁጥር ነው፡፡ In this paper, we present a framework to learn sentence selection strategies for neural MT. We train the AL query strategy using a high-resource language-pair based on AL simulations, and then transfer it to the low-resource language-pair of interest.  የተማሩት የጥያቄ ስርዓት በቋንቋው ሁለት መካከል በተካፈሉት የአልፍ ቡድስቲ በጥያቄ ለመጠቀም ነው፡፡ በሦስት ቋንቋ ዓይነቶች ላይ ፈተናችንን እና የጥቁር መጀመሪያ እና ትኩሳት ጀምሮ እና በጣም ትንሽ እና በጣም ትንሽ የዳታ አካላት ክፍተቶችን ከጠነከረ አካባቢ ሥርዓታችን እንዲያረጋግጣል፡፡', 'ca': "Els mètodes tradicionals d'aprenentatge actiu (AL) per traducció màquina (MT) depenen d'heurística. No obstant això, aquestes heurístiques estan limitades quan les característiques del problema MT canvien degut, per exemple, al parell de llenguatges o a la quantitat del text inicial. En aquest article presentem un marc per aprendre estratègies de selecció de frases per a MT neural. Aprenem l'estratègia de consulta AL fent servir un parell de llenguatges amb alt recurso basat en simulacions AL, i després la transferim al parell de llenguatges amb baix recursos d'interès. L'estratègia de preguntes aprenguts aprofita les característiques compartides entre els parells de llengües per fer un ús efectiu del pressupost AL. Els nostres experiments en tres parelles de llengües confirmen que el nostre mètode és més eficaç que els forts mètodes basats en heurístics en diverses condicions, incloent el començament fred i el començament calent, així com les petites i extremament petites condicions de dades.", 'bn': 'মেশিন অনুবাদের (এমটি) প্রথাগত সক্রিয় শিক্ষা পদ্ধতি হিউরিস্টিক্সের উপর নির্ভর করে। তবে এমটি সমস্যার বৈশিষ্ট্য পরিবর্তনের কারণে এই সমস্ত হিউরিস্টিক সীমাবদ্ধ হয়েছে, যেমন ভাষার জোড়া অথবা প্রাথমিক ক্ষেত্রের পরিমাণ। এই কাগজটিতে আমরা নিউরেল এমটির জন্য বাক্য নির্বাচন কৌশল শিখতে একটি ফ্রেম উপস্থাপন করি, আমরা AL-এর সিমুলেশনের ভিত্তিতে এক উচ্চ সম্পদের ভাষার জোড়া প্রশিক্ষণ প্রশিক্ষণ দিয়েছি এবং তারপর শিক্ষা প্রশ্নের কৌশলের মাধ্যমে ভাষার জোড়ার মধ্যে ভাষার জোড়া বাজেটের কার্যকর ব্যবহার করার জন্য প্রযুক্তিতে প্রধ তিন ভাষার জোড়ার উপর আমাদের পরীক্ষা নিশ্চিত করে যে আমাদের পদ্ধতি বিভিন্ন পরিস্থিতিতে শক্তিশালী হিউরিস্টিক ভিত্তিক পদ্ধতির চেয়ে বেশী কার্য', 'fi': 'Perinteiset aktiivisen oppimisen menetelmät konekäännöksessä (MT) perustuvat heuristiikkaan. Nämä heuristikot ovat kuitenkin rajallisia, kun MT-ongelman ominaisuudet muuttuvat esimerkiksi kieliparin tai alkuperäisen bitekstin määrän vuoksi. Tässä artikkelissa esitellään viitekehys lausevalintastrategioiden oppimiseen neurologisessa MT:ssä. Koulutamme AL-kyselystrategiaa käyttämällä korkean resurssin kieliparia, joka perustuu AL-simulaatioihin, ja siirrämme sen sitten matalaresurssisen kielipariin. Oppitussa kyselystrategiassa hyödynnetään kieliparien yhteisiä ominaisuuksia AL-budjetin tehokkaaksi hyödyntämiseksi. Kokeet kolmella kieliparilla vahvistavat, että menetelmämme on tehokkaampi kuin vahvat heuristiset menetelmät erilaisissa olosuhteissa, kuten kylmäkäynnistyksessä ja lämpimässä käynnistyksessä sekä pienissä ja erittäin pienissä tietoolosuhteissa.', 'cs': 'Tradiční metody aktivního učení (AL) pro strojový překlad (MT) spoléhají na heuristiku. Tyto heuristiky jsou však omezeny, pokud se charakteristiky MT problému změní např. v důsledku jazykového páru nebo množství počátečního bitextu. V tomto článku představujeme rámec pro naučení strategií výběru vět pro neuronovou MT. Trénujeme strategii dotazu AL pomocí jazykového páru s vysokými zdroji založeného na AL simulacích a poté ji přenášíme na jazykový pár s nízkými zdroji. Naučená strategie dotazů využívá sdílené charakteristiky mezi jazykovými páry a efektivně využívá rozpočet AL. Naše experimenty na třech jazykových párech potvrzují, že naše metoda je efektivnější než silné heuristické metody v různých podmínkách, včetně studeného startu a teplého startu, stejně jako malých a extrémně malých datových podmínek.', 'et': 'Traditsioonilised aktiivse õppe (AL) meetodid masintõlke (MT) toetuvad heuristikale. Need heuristikad on siiski piiratud, kui MT probleemi omadused muutuvad näiteks keelepaari või algse biteksti suuruse tõttu. Käesolevas töös tutvustame raamistikku lausevaliku strateegiate õppimiseks neuraalse MT jaoks. Koolitame AL päringustrateegiat, kasutades AL simulatsioonidel põhinevat suure ressursiga keelepaari ja edastame selle seejärel madala ressursiga keelepaari. Õppitud päringustrateegia kasutab ära keelepaaride jagatud omadused, et AL eelarvet tõhusalt ära kasutada. Meie eksperimendid kolme keelepaariga kinnitavad, et meie meetod on efektiivsem kui tugevad heuristilised meetodid erinevates tingimustes, sealhulgas külmkäivitusel ja soojal käivitusel ning väikestel ja äärmiselt väikestel andmetel.', 'jv': 'Alternate Nanging, trus iki dadi nêmêr, iso nggawe gerangkat cara-cara sing wong liyane MT perbudhakan langkung sampek banget nggawe gerangkat dhéwé. Nang pepulan iki, kita mulai perusahaan kanggo ngerti dadi nggunakake dolangkat nggo MT, dadi sing karbote AL pangutan nggawe gerangkat sistem sing wis ana gambar nggo sistem AL, tambah njuk nggawe gerangkat langkung diangkat dhéwé. Nalika mbukak-ingkang dipunangé kuwi nggawe alat-ingkang karo hal-alat sing nganggo barang nggawe barang nggawe barang AL budhet. Awak dhéwé éntuk karo telu nggawe barang-barang, dadi sing ngendalikne awak dhéwé kuwi basa manut sing dadi manit sing kalalah, tambah bantêt sampek mulai lan tambah bantêt sampek kaya data sing apik lan tambah bantêt.', 'ha': "KCharselect unicode block name Amma, za'a ƙayyade waɗannan heuristics idan taki masu canza matsayin MT ta sabo da misali, nau'i biyu ko nau'in bitan farko. Daga wannan takardan, muna gabatar da firam dõmin mu sanar da takardar zãɓen maganar kwamfyuta wa MT. Tuna sanar da kimar tambayar Allah game da wani nau'i-nau'in lugha'in-nau'i biyu baka kan misalin AI, sa'an nan kuma Mu musanya shi zuwa ƙasan-resource-language-biyu na riba. @ action: button Kayan jarrabayanmu kan nau'i uku cikin harshen, yana gaskata cewa hanyoyinmu yana mafiya amfani ga mafiya ƙarfi daga hanyoyin heuristic a cikin mazaɓa dabam-dabam, ikin fara-rayi da fara mai kulfi da kuma da halin ƙarami da kuma ƙarami masu ƙaranci da mazaunin data.", 'he': 'שיטות לימוד פעיל מסורתיות (AL) לתרגום מכונות (MT) תלויות בהוריסטיקה. בכל אופן, ההוריסטיקה הזאת מוגבלת כאשר האופיינים של בעיית MT משתנים בגלל, למשל, זוג השפה או כמות הנשיכה הראשונה. בעיתון הזה, אנו מציגים מסגרת ללמוד אסטרטגיות בחירת משפטים עבור MT עצבי. אנו מאמן את אסטרטגיה של חקירה אל-אל באמצעות זוג שפת משאבים גבוהים מבוסס על סימולציות אל-אל, ואז להעביר אותו לזוג שפת משאבים נמוכים של עניין. אסטרטגיית השאלות המלמדת משתמשת בהתאימות המשותפות בין זוגות השפה כדי לעשות שימוש יעיל בתקציב של אל.איי. הניסויים שלנו על שלושה זוגות שפות מאשר שהשיטה שלנו יעילה יותר משיטות חזקות מבוססות בהוריסטיקה במצבים שונים, כולל התחלה קרה ותחלה חמה, כמו גם תנאי נתונים קטנים וקטנים ביותר.', 'sk': 'Tradicionalne metode aktivnega učenja (AL) za strojno prevajanje (MT) temeljijo na heuristiki. Vendar pa so te heuristike omejene, kadar se značilnosti problema MT spremenijo zaradi npr. jezikovnega pare ali količine začetnega biteksta. V prispevku predstavljamo okvir za učenje strategij izbire stavkov za nevronsko MT, izobražujemo strategijo poizvedbe AL z uporabo jezikovnega pare z visokimi viri, ki temelji na simulacijah AL, nato pa jo prenesemo na jezikovni par z nizkimi viri. Naučena strategija poizvedbe izkoristi skupne značilnosti med jezikovnimi pari, da učinkovito izkoristi proračun AL. Naši eksperimenti na treh jezikovnih parih potrjujejo, da je naša metoda učinkovitejša od močnih heurističnih metod v različnih pogojih, vključno s hladnim in toplim zagonom ter majhnimi in izjemno majhnimi podatkovnimi pogoji.', 'bo': 'Traditional active learning (AL) methods for machine translation (MT) rely on heuristics. ཡིན་ནའང་། རྩིས་འབྲས་འདི་དག་ནི་MT དཀའ་ངལ་གྱི་ཁྱད་ཆོས་ཀྱི་འགྱུར་བའི་སྐབས་སུ་ཚད་limited. དཔེར་ན། སྐད་རིགས་གཉིས་ཀྱི་དང་འགོ་འཛུགས་པའི་ཚ འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་ཚིག་འདེམས་པའི་ཐབས་ལམ་ཞིག་སྟོན་བྱེད་ཀྱི་ཡོད། སྟོན་རྩོལ་བ་གྱི་ཐབས་ལམ་དེ་ནི་སྐད་ཡིག་གཉིས་ཀྱི་དབར་གྱི་ཁྱད་ཆོས་རྣམས་གྲངས་སུ་འཇུག་པ་ཡིན། ང་ཚོའི་སྐྱེས་ཚོགས་ཆ་གསུམ་ཀྱི་བརྟག་ཞིབ་པས་ང་ཚོའི་ལམ་ལུགས་འདི་ རྩ་བ་ནས་དབྱིབས་བཀོད་པའི་ཐབས་ལམ་སྟངས་འདྲ་མིའི་ནང་ལས་ལྡན་པ་ཞིག་ཡོད།'}
{'en': 'Upcycle Your OCR : Reusing OCRs for Post-OCR Text Correction in Romanised Sanskrit', 'pt': 'Atualize seu OCR: Reutilizando OCRs para correção de texto pós-OCR em sânscrito romanizado', 'fr': 'Upcycle votre ROC\xa0: réutilisation des OCR pour la correction de texte post-OCR en sanskrit romanisé', 'ar': 'إعادة استخدام OCR الخاص بك: إعادة استخدام OCR لتصحيح النص بعد OCR باللغة السنسكريتية الرومانية', 'es': 'Reciclar el OCR: reutilización de OCR para la corrección de texto posterior al OCR en sánscrito romanizado', 'ja': 'OCRのアップサイクル： OCR後のテキスト修正のためのOCRのローマ字化の再利用', 'hi': 'Upcycle आपका OCR: रोमनीकृत संस्कृत में पोस्ट-OCR पाठ सुधार के लिए OCRs का पुन: उपयोग करना', 'zh': '升 OCR:用 OCR 罗马化梵文后 OCR 文本校正', 'ru': 'Апциклирование КЛСД: повторное использование КЛСД для коррекции текста после КЛСД на латинице и санскрите', 'ga': 'Uaschúrsáil Do OCR: OCRanna a Athúsáid le haghaidh Ceartúchán Téacs Iar-OCR i Sanscrait Rómhánaithe', 'ka': 'თქვენი OCR- ის გადასრულება: OCR- ის გადასრულება ტექსტის რეკორექციისთვის პრომინაციული SanskritName', 'kk': 'OCR мәтінді түзету үшін OCR- ты қайта қолдану', 'el': 'Αναβαθμίστε την OCR σας: Επαναχρησιμοποίηση των OCR για τη διόρθωση κειμένου μετά την OCR στα Ρομαντικά Σανσκριτικά', 'hu': 'Az OCR frissítése: OCR újrahasználata az OCR utáni szövegjavításhoz román szanszkrit nyelven', 'it': 'Aggiorna il tuo OCR: riutilizzare gli OCR per la correzione del testo post-OCR in sanscrito romanizzato', 'lt': 'Perkelkite Jūsų UŠT: UŠT pakartotinai naudojami teksto korekcijai po UŠT rumunų kalba', 'mk': 'Upcycle Your OCR: Reusing OCRs for Post-OCR Text Correction in Romanised Sanskrit', 'mt': 'Iċċekkja l-OCR tiegħek: Użu mill-ġdid tal-OCRs għal Korrezzjoni tat-Test wara l-OCR f’Sanskrit Rumanizzat', 'ml': 'നിങ്ങളുടെ ഓക്സിക്കിള്\u200d: റോമാനിസ്റ്റ് സാന്\u200dസ്ക്രിറ്റില്\u200d പിന്നീട് OCR പദാവലിയുടെ വിവരങ്ങള്\u200dക്ക് വീണ്', 'ms': 'Upcycle OCR anda: Mengguna semula OCR untuk Pembetulan Teks Post-OCR dalam Sanskrit Romanised', 'mn': 'ОКР: Ромын санскрит дээр OCRs-г өөрчлөх', 'pl': 'Upcycle OCR: ponowne wykorzystanie OCR do korekcji tekstu po OCR w sanskrycie romanizowanym', 'ro': 'Upcycle OCR: reutilizarea OCR-urilor pentru corectarea textului post-OCR în sanscrită romanizată', 'sr': 'Upcycle Vaš OCR: ponovo iskoristiti OCR za ispravu teksta nakon OCR-a u Romaniziranom Sanskritu', 'no': 'Oppkytt OCR- en din: Bruk OCRs på nytt for post- OCR- tekstkorreksjon i romanisert sanskrit', 'si': 'Name', 'sv': 'Uppgradera ditt OCR: återanvända OCR för textkorrigering efter OCR på romaniserad sanskrit', 'so': 'Rugtaada OCR:', 'ta': '@ info: status', 'ur': 'اپنا OCR آپسایکل: رومانی سنسکرٹ میں OCRs کو دوبارہ استعمال کرنا', 'uz': 'Name', 'vi': 'Nâng vòng lên OCR: tái hợp OCR để sửa lại văn bản bưu điện bằng tiếng Phạn.', 'bg': 'Повторно използване на ОКР за корекция на текста след ОКР на романизиран санскрит', 'nl': 'Upcycle uw OCR: hergebruik van OCR voor post-OCR tekstcorrectie in geromaniseerd sanskriet', 'da': 'Upcycle din OCR: Genbrug OCR til post-OCR tekstkorrektion på romaniseret sanskrit', 'de': 'Verbessern Sie Ihre OCR: Wiederverwendung von OCR zur Post-OCR-Textkorrektur in romanisiertem Sanskrit', 'ko': 'OCR 업그레이드: 로마 산스크리트에서 OCR을 반복하여 OCR 이후 텍스트 수정', 'id': 'Upcycle OCR Anda: Menggunakan ulang OCR untuk Koreksi Teks Post-OCR dalam Sanskrit Romanised', 'fa': 'OCR: استفاده از OCRs برای اصلاح متن بعد OCR در سانسکریت رومانی', 'sw': 'Mpito wako wa OCR: Kutumia OCR kwa ajili ya kurekebisha maandishi ya baada ya OCR katika Sanskrit ya Romanised Sanskrit', 'tr': 'OCR', 'af': 'Upcycle Jou OCR: Hergebruik OCR vir Post- OCR Teks Korreksie in Romaniseerde Sanskrit', 'sq': 'Upcycle Your OCR: Reusing OCRs for Post-OCR Text Correction in Romanised Sanskrit', 'am': 'CRs', 'hr': 'Upcycle Vaš OCR: ponovno iskoristiti OCR za ispravu teksta nakon OCR-a u Romaniziranom sanskritu', 'hy': 'Հաշվի առնել ձեր OCR-ը: Կրկին օգտագործել OCR-ները ռոմանիզացված սանկրիտով տեքստի ուղղելու համար', 'bn': 'Upcycle Your OCR: Reusing OCRs for Post-OCR Text Correction in Romanised Sanskrit', 'az': "OCR-lərinizi bağlayın: Romanizləndirilmiş Sanskrit'də OCR mətn düzəltməsi üçün yenidən OCR-ləri istifadə edir", 'bs': 'Upcycle Vaš OCR: ponovno iskoristiti OCR za ispravu teksta nakon OCR-a u Romaniziranom sanskritu', 'ca': 'Upcycle your OCR: Reuse OCR for Post-OCR Text Correction in Romanised Sanskrit', 'et': 'Üleslaadimine oma OCR: OCR-ide taaskasutamine OCR-järgseks tekstiparanduseks romaniseeritud sanskriti keeles', 'cs': 'Upcycle OCR: Opětovné použití OCR pro korekci textu po OCR v romském sanskrtu', 'fi': 'Päivitä OCR: OCR:ien uudelleenkäyttö OCR:n jälkeiseen tekstikorjaukseen romanisoituun sanskritiin', 'jv': 'OCR', 'sk': 'Posodobite svoj OCR: Ponovna uporaba OCR-jev za popravke besedila po OCR v romaniziranem sanskrtu', 'he': 'מעביר את OCR שלך: משתמש מחדש OCR לתקן טקסט לאחר OCR בסנסקריט רומניזם', 'ha': '@ action', 'bo': 'Upcycle Your OCR: Reuse OCRs for Post-OCR Text Correction in Romanized Sanskrit'}
{'en': 'We propose a post-OCR text correction approach for digitising texts in ', 'ar': 'نقترح نهج تصحيح النص بعد التعرف الضوئي على الحروف لرقمنة النصوص باللغة السنسكريتية الرومانية. نظرًا لقلة الموارد ، يستخدم نهجنا نماذج التعرف الضوئي على الحروف المدربة على لغات أخرى مكتوبة باللغة الرومانية. حاليًا ، لا توجد مجموعة بيانات متاحة لـ Romanized Sanskrit OCR. لذلك ، نقوم بتشغيل مجموعة بيانات من 430 صورة ، تم مسحها ضوئيًا في إعدادين مختلفين والحقيقة الأساسية المقابلة لها. للتدريب ، نقوم بشكل صناعي بإنشاء صور تدريب لكلا الإعدادين. وجدنا أن استخدام آلية النسخ (Gu et al. ، 2016) يؤدي إلى زيادة بنسبة 7.69 في معدل التعرف على الأحرف (CRR) مقارنة بالحالة الحالية للنموذج الفني في حل مهام التسلسل إلى التسلسل أحادية اللون (Schnober et al. . ، 2016). وجدنا أن نظامنا قوي في مكافحة الأخطاء المعرضة لـ OCR ، حيث يحصل على CRR بنسبة 87.01٪ من إخراج OCR مع CRR بنسبة 35.76٪ لأحد إعدادات مجموعة البيانات. يُظهر مسح الحكم البشري الذي تم إجراؤه على النماذج أن نموذجنا المقترح ينتج عنه تنبؤات أسرع في الفهم وأسرع في التحسين للإنسان مقارنة بالأنظمة الأخرى.', 'pt': 'Propomos uma abordagem de correção de texto pós-OCR para digitalização de textos em sânscrito romanizado. Devido à falta de recursos, nossa abordagem usa modelos de OCR treinados para outras línguas escritas em romano. Atualmente, não existe nenhum conjunto de dados disponível para OCR em sânscrito romanizado. Então, inicializamos um conjunto de dados de 430 imagens, digitalizadas em duas configurações diferentes e suas informações de base correspondentes. Para treinamento, geramos sinteticamente imagens de treinamento para ambas as configurações. Descobrimos que o uso do mecanismo de cópia (Gu et al., 2016) produz um aumento percentual de 7,69 na Taxa de Reconhecimento de Caracteres (CRR) do que o modelo atual de estado da arte na resolução de tarefas monótonas de sequência a sequência (Schnober et al. ., 2016). Descobrimos que nosso sistema é robusto no combate a erros propensos ao OCR, pois obtém um CRR de 87,01% de uma saída de OCR com CRR de 35,76% para uma das configurações do conjunto de dados. Uma pesquisa de julgamento humano realizada nos modelos mostra que nosso modelo proposto resulta em previsões que são mais rápidas de compreender e mais rápidas de melhorar para um humano do que os outros sistemas.', 'fr': "Nous proposons une approche de correction de texte post-OCR pour numériser des textes en sanskrit romanisé. En raison du manque de ressources, notre approche utilise des modèles d'OCR formés pour d'autres langues écrites en romain. Il n'existe actuellement aucun jeu de données disponible pour l'OCR sanskrit romanisé. Nous avons donc amorcé un ensemble de données de 430 images, scannées dans deux configurations différentes et leur vérité de terrain correspondante. Pour l'entraînement, nous générons synthétiquement des images d'entraînement pour les deux paramètres. Nous avons constaté que l'utilisation du mécanisme de copie (Gu et al., 2016) produit une augmentation en pourcentage du taux de reconnaissance de caractères (CRR) de 7,69 par rapport au modèle actuel de pointe dans la résolution de tâches monotones séquence à séquence (Schnober et al., 2016). Nous trouvons que notre système est robuste dans la lutte contre les erreurs sujettes à l'OCR, puisqu'il obtient un CRR de 87,01\xa0% à partir d'une sortie d'OCR avec un CRR de 35,76\xa0% pour l'un des paramètres de l'ensemble de données. Une enquête sur le jugement humain réalisée sur les modèles montre que le modèle que nous proposons produit des prévisions qui sont plus rapides à comprendre et à améliorer plus rapidement pour un humain que les autres systèmes.", 'es': 'Proponemos un enfoque de corrección de texto post-OCR para digitalizar textos en sánscrito romanizado. Debido a la falta de recursos, nuestro enfoque utiliza modelos de OCR entrenados para otros idiomas escritos en romano. Actualmente, no existe ningún conjunto de datos disponible para el OCR sánscrito romanizado. Por lo tanto, iniciamos un conjunto de datos de 430 imágenes, escaneadas en dos configuraciones diferentes y su correspondiente verdad en el terreno. Para el entrenamiento, generamos de forma sintética imágenes de entrenamiento para ambos escenarios. Encontramos que el uso del mecanismo de copia (Gu et al., 2016) produce un aumento porcentual de 7,69 en la tasa de reconocimiento de caracteres (CRR) que el modelo actual de vanguardia en la resolución de tareas monótonas de secuencia a secuencia (Schnober et al., 2016). Descubrimos que nuestro sistema es sólido para combatir los errores propensos a OCR, ya que obtiene un CRR del 87,01% de una salida de OCR con un CRR del 35,76% para una de las configuraciones del conjunto de datos. Una encuesta de juicio humano realizada en los modelos muestra que nuestro modelo propuesto da como resultado predicciones que son más rápidas de comprender y de mejorar para un ser humano que para los demás sistemas.', 'ja': 'ローマ字化されたサンスクリットでテキストをデジタル化するためのOCR後のテキスト修正アプローチを提案します。 リソースが不足しているため、当社のアプローチでは、ローマ字で書かれた他の言語のために訓練されたOCRモデルを使用しています。 現在、ローマ字化されたサンスクリットOCRで利用可能なデータセットはありません。 2つの異なる設定でスキャンされた430枚の画像とそれに対応するグラウンドトゥルースのデータセットをブートストラップします トレーニングでは、両方の設定のトレーニング画像を合成的に生成します。 我々は、コピーメカニズム（ Gu et al., 2016 ）の使用は、モノトーン配列間タスクを解決する際の現状の最先端モデルよりも、文字認識率（ CRR ）において7.69のパーセンテージ増加をもたらすことを見出す（ Schnober et al., 2016 ）。 当社のシステムは、データセット設定の1つについて、OCR出力から87.01 ％のCRRを取得し、35.76 ％のCRRを取得するため、OCRが起こりやすいエラーに対処するために堅牢であることがわかります。 モデルに対して実施された人間の判断調査によると、提案されたモデルは、他のシステムよりも人間のために理解するのが速く、改善するのが速い予測をもたらすことが示されています。', 'ru': 'Мы предлагаем подход к коррекции текста пост-OCR для оцифровки текстов на латинице и санскрите. Из-за нехватки ресурсов наш подход использует модели OCR, подготовленные для других языков, написанных на римском языке. В настоящее время не существует набора данных для латинизированного КЛСД на санскрите. Таким образом, мы загружаем набор данных из 430 изображений, отсканированных в двух разных настройках и их соответствующей истине. Для обучения мы синтетически генерируем обучающие образы для обеих настроек. Мы обнаружили, что использование механизма копирования (Gu et al., 2016) дает процентное увеличение на 7,69 в скорости распознавания символов (CRR) по сравнению с современной моделью при решении задач монотонной последовательности (Schnober et al., 2016). Мы обнаружили, что наша система надежна в борьбе с ошибками, склонными к распознаванию текста, поскольку она получает CRR 87,01% от вывода OCR с CRR 35,76% для одной из настроек набора данных. Исследование человеческого суждения, проведенное на моделях, показывает, что предлагаемая нами модель приводит к прогнозам, которые быстрее воспринимаются и быстрее улучшаются для человека, чем другие системы.', 'hi': 'हम रोमनीकृत संस्कृत में ग्रंथों को डिजिटाइज करने के लिए एक पोस्ट-ओसीआर पाठ सुधार दृष्टिकोण का प्रस्ताव करते हैं। संसाधनों की कमी के कारण हमारा दृष्टिकोण रोमन में लिखी गई अन्य भाषाओं के लिए प्रशिक्षित ओसीआर मॉडल का उपयोग करता है। वर्तमान में, रोमनीकृत संस्कृत ओसीआर के लिए कोई डेटासेट उपलब्ध नहीं है। इसलिए, हम 430 छवियों के डेटासेट को बूटस्ट्रैप करते हैं, जो दो अलग-अलग सेटिंग्स और उनके संबंधित जमीनी सच्चाई में स्कैन किया जाता है। प्रशिक्षण के लिए, हम सिंथेटिक रूप से दोनों सेटिंग्स के लिए प्रशिक्षण छवियों को उत्पन्न करते हैं। हम पाते हैं कि नकल तंत्र (Gu et al., 2016) का उपयोग मोनोटोन अनुक्रम-से-अनुक्रम कार्यों (Schnober et al., 2016) को हल करने में कला मॉडल की वर्तमान स्थिति की तुलना में चरित्र पहचान दर (CRR) में 7.69 की प्रतिशत वृद्धि करता है। हम पाते हैं कि हमारा सिस्टम ओसीआर-प्रवण त्रुटियों का मुकाबला करने में मजबूत है, क्योंकि यह डेटासेट सेटिंग्स में से एक के लिए 35.76% के सीआरआर के साथ ओसीआर आउटपुट से 87.01% का सीआरआर प्राप्त करता है। मॉडल पर किए गए एक मानव निर्णय सर्वेक्षण से पता चलता है कि हमारे प्रस्तावित मॉडल के परिणामस्वरूप भविष्यवाणियां होती हैं जो समझने में तेज होती हैं और अन्य प्रणालियों की तुलना में मानव के लिए सुधार करने के लिए तेज होती हैं।', 'zh': '立后OCR文本校正,以罗马化梵文本数字化。 无资,吾法用罗马语他语OCR模形。 今无可施于罗马化梵文OCR之数集。 故引一430张像之数集,二者设中扫描,以应其实。 其于训练,合成此二者。 臣等见用复制机(Gu等,2016)于单调序职,字符识别率(CRR)增于前7.69百分点(Schnober等,2016)。 臣伏见系统于抗敌易 OCR 之过甚强,盖得 87.01% 于 OCR 输之 CRR,其一据集置者 CRR 为 35.76%也。 对模型人之所察者,疾于他统更快。', 'ga': 'Molaimid cur chuige iar-OCR ceartaithe téacs chun téacsanna a dhigitiú i Sanscrait Rómhánaithe. Mar gheall ar an easpa acmhainní úsáideann ár gcur chuige samhlacha OCR atá oilte do theangacha eile a scríobhtar sa Rómhánach. Faoi láthair, níl aon tacar sonraí ar fáil le haghaidh Sanscrait Rómhánaithe OCR. Mar sin, déanaimid bootstrap ar thacar sonraí de 430 íomhá, a scanadh in dhá shuíomh éagsúla agus a bhfírinne talún comhfhreagrach. Le haghaidh oiliúna, ginimid íomhánna oiliúna go sintéiseach don dá shuíomh. Faighimid amach go dtugann úsáid meicníochta cóipeála (Gu et al., 2016) méadú céatadáin de 7.69 ar an Ráta Aitheantais Carachtair (CRR) ná an tsamhail úrscothach faoi láthair maidir le tascanna seicheamh-go-seicheamh monatóin a réiteach (Schnober et al. ., 2016). Faighimid amach go bhfuil ár gcóras láidir maidir le dul i ngleic le hearráidí atá seans maith le OCR, toisc go bhfaigheann sé CRR de 87.01% ó aschur OCR le CRR de 35.76% do cheann de na socruithe tacar sonraí. Léiríonn suirbhé ar bhreithiúnas daonna a rinneadh ar na samhlacha go mbíonn tuar níos gasta le tuiscint agus níos tapúla le feabhsú don duine ná na córais eile mar thoradh ar ár múnla molta.', 'ka': 'ჩვენ პრომინაციული სანსკრიტში ტექსტის დიზიტრიზაციისთვის OCR ტექსტის კონფიგურაციის მიღება. ჩვენი პროგრამის არსებობის რესურსების გამოყენება OCR მოდელების გამოყენება, რომლებიც პრომინში დაწერული სხვა ენებისთვის. სინამდვილეში არსებობს მონაცემების კონფიგურაცია პრომინალიზებული Sanskrit OCR- ისთვის. 430 გამოსახულებების მონაცემების სექნენტი, ორი განსხვავებული პარამეტრებში და მათი შესაძლებელი მსოფლიო სინამდვილეში. ჩვენ სინტეტიკურად განვიყენებთ განვიყენებული გამოსახულების ორივე პარამეტრებისთვის. ჩვენ აღმოჩნეთ, რომ კოპირაციის მექანიზმის გამოყენება (Gu et al., 2016) 7.69 პროცენტის გამოვიყენება სიმბოლოების განახლების სიმბოლოების სიმბოლოების სიმბოლოების სიმბოლოებისგან (CRR) უფრო მექანიზმის სიმბოლოებისგან მონოტო ჩვენ ვიფიქრობთ, რომ ჩვენი სისტემა ძალიან ძალიან OCR-prone შეცდომების გაბრძელებაში, რადგან ის 87.01% CRR-ს მიიღებს OCR-ის გამოსვლა 35.76% CRR-ის ერთი მონაცემებისთვის. ადამიანის შესახებ, რომელიც მოდელზე გავაკეთებული მოდელზე, ჩვენი მოდელს გადაუწყება პროგრამებში, რომელიც უფრო ბრძელია გაგრძელება და უფრო ბრძელია გავიგებთ ადამიანისთ', 'el': 'Προτείνουμε μια προσέγγιση διόρθωσης κειμένου μετά την OCR για την ψηφιοποίηση κειμένων στα Ρομανικά Σανσκριτικά. Λόγω της έλλειψης πόρων η προσέγγισή μας χρησιμοποιεί μοντέλα OCR εκπαιδευμένα για άλλες γλώσσες γραμμένες στα ρωμαϊκά. Επί του παρόντος, δεν υπάρχει διαθέσιμο σύνολο δεδομένων για τα Ρομανικά Σανσκριτικά OCR. Έτσι, εκκινούμε ένα σύνολο δεδομένων 430 εικόνων, σαρωμένες σε δύο διαφορετικές ρυθμίσεις και την αντίστοιχη επίγεια αλήθεια τους. Για την εκπαίδευση, δημιουργούμε συνθετικά εικόνες εκπαίδευσης και για τις δύο ρυθμίσεις. Διαπιστώνουμε ότι η χρήση του μηχανισμού αντιγραφής (κ.α., 2016) αποδίδει ποσοστιαία αύξηση 7.69 στον ρυθμό αναγνώρισης χαρακτήρων (σε σχέση με το σημερινό μοντέλο τελευταίας τεχνολογίας στην επίλυση μονοτονικών εργασιών ακολουθίας-ακολουθίας (κ.α., 2016). Διαπιστώνουμε ότι το σύστημά μας είναι ανθεκτικό στην καταπολέμηση των επιρρεπών σφαλμάτων OCR, καθώς λαμβάνει ένα CRR 87.01% από μια έξοδο OCR με CRR 35.76% για μια από τις ρυθμίσεις συνόλου δεδομένων. Μια έρευνα ανθρώπινης κρίσης που πραγματοποιήθηκε στα μοντέλα δείχνει ότι το προτεινόμενο μοντέλο οδηγεί σε προβλέψεις που είναι ταχύτερες να κατανοηθούν και ταχύτερα να βελτιωθούν για έναν άνθρωπο από τα άλλα συστήματα.', 'it': "Proponiamo un approccio post-OCR per la correzione del testo per la digitalizzazione dei testi in sanscrito romanizzato. A causa della mancanza di risorse il nostro approccio utilizza modelli OCR formati per altre lingue scritte in romano. Attualmente, non esistono set di dati disponibili per Romanised Sanscrit OCR. Quindi, abbiamo avviato un set di dati di 430 immagini, scansionate in due impostazioni diverse e la loro corrispondente verità di base. Per la formazione, generiamo sinteticamente immagini di allenamento per entrambe le impostazioni. Troviamo che l'uso del meccanismo di copia (Gu et al., 2016) produce un aumento percentuale di 7,69 in Character Recognition Rate (CRR) rispetto al modello attuale allo stato dell'arte nella risoluzione di compiti monotoni sequenza-sequenza (Schnober et al., 2016). Troviamo che il nostro sistema è robusto nel combattere gli errori a rischio di OCR, in quanto ottiene un CRR dell'87,01% da un output OCR con CRR del 35,76% per una delle impostazioni del set di dati. Un sondaggio sul giudizio umano eseguito sui modelli mostra che il nostro modello proposto porta a previsioni che sono più veloci da comprendere e più veloci da migliorare per un umano rispetto agli altri sistemi.", 'hu': 'Javasoljuk az OCR utáni szövegkorrekciós megközelítést a román szanszkrit szövegek digitalizálására. Az erőforrások hiánya miatt megközelítésünk más nyelvekre képzett OCR modelleket használ, római nyelven írt. Jelenleg nincs elérhető adatkészlet a Romanized Sanskrit OCR-hez. Tehát elindítunk egy 430 képből álló adatkészletet, amelyeket két különböző beállításban szkenneltünk és a megfelelő alapvető igazsággal. A képzéshez szintetikusan készítünk képeket mindkét beállításhoz. Megállapítottuk, hogy a másolási mechanizmus használata (Gu et al., 2016) 7,69 százalékos növekedést eredményez a karakterfelismerési arány (CRR), mint a jelenlegi korszerű modell monoton szekvencia-szekvencia feladatok megoldásában (Schnober et al., 2016). Úgy találjuk, hogy rendszerünk robusztus az OCR-hajlamos hibák elleni küzdelemben, mivel 87,01%-os CRR-t kap egy OCR kimenetből 35,76%-os CRR-t az egyik adatkészlet beállítása esetén. A modelleken végzett emberi ítélőképességi felmérés azt mutatja, hogy javasolt modellünk olyan előrejelzéseket eredményez, amelyek gyorsabban megérthetők és gyorsabban fejlődnek egy ember számára, mint a többi rendszer.', 'kk': 'Біз Романизацияланған санскритте мәтінді цифрлау үшін OCR- ден кейін мәтінді түзету тәсілігін ұсынамыз. Ресурстың жоқ болмаса, Романда жазылған басқа тілдер үшін OCR үлгілерін қолданады. Қазір Романизацияланған санскрит OCR үшін деректер жиыны жоқ. Сондықтан біз 430 кескіндердің деректер жиынын жүктеп, екі түрлі параметрлерде сканерледі және олардың сәйкес жергілікті шындығы. Оқыту үшін, екі баптаулар үшін оқыту кескіндерін синтетикалық түрде құрамыз. Біз көшірмелеу механизмінің (Gu et al., 2016) пайдалануы таңбаларды таңдау жиілігінен 7,69 пайызын өзгертеді (CRR) монотон ретінде келесі тапсырмаларды (Schnober et al., 2016). Біз жүйеміздің OCR-дағы қателерді құрастыру үшін қуатты деп ойлаймыз, өйткені ол деректер жинақтарының біреуіне 35,76% CRR-мен 87,01% CRR шығысынан алады. Бұл үлгілерде жасалған адамдардың оқиғаларының бақылауы көрсетілген үлгілеріміздің басқа жүйелерден қарай адамдардың оқиғаларын түсінуге тез және тез түсінуге тез және жақсы түсіну', 'lt': 'Siūlome, kad tekstai būtų skaitmeninami rumunų kalba po UŠR. Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman.  Šiuo metu nėra duomenų rinkinio apie Rumunijos sanskrito UŠR. Taigi, mes įjungiame 430 vaizdų duomenų rinkinį, skenuojamą dviem skirtingomis aplinkybėmis ir atitinkamą antžeminę tiesą. Mokymui mes sintetiškai sukuriame mokymo vaizdus abiems nustatymams. Nustatome, kad taikant kopijavimo mechanizmą (Gu et al., 2016 m.) Character Recognition Rate (CRR) padidėja 7,69 proc., palyginti su dabartiniu pažangiausiu modeliu sprendžiant monotono sekos užduotis (Schnober et al., 2016 m.). Mes manome, kad mūsų sistema yra tvirta kovojant su UŠR sukeltomis klaidomis, nes ji gauna 87,01 % UŠR iš UŠR išėjimo ir 35,76 % UŠR vienoje iš duomenų rinkinio nustatymų. Žmogaus vertinimo tyrimas, atliktas remiantis modeliais, rodo, kad mūsų siūlomas modelis sukuria prognozes, kurios yra greitesnės suprantamos ir greitesnės gerinamos žmogui nei kitoms sistemoms.', 'mk': 'We propose a post-OCR text correction approach for digitising texts in Romanised Sanskrit.  Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman.  Моментно, нема достапни датотеки за романизираниот санскритски ОКР. Така да, ние ги поврзуваме податоците од 430 слики, скенирани во две различни поставувања и нивната соодветна земјска вистина. За тренинг, синтетички генерираме слики за тренинг за двете поставувања. Најдовме дека употребата на механизмот за копирање (Гу и ал., 2016) предизвикува процентно зголемување на стапката за признавање на знаци (ЦРР) од сегашниот најсовремен модел во решавањето на задачите од монотон до секвенца (Шнобер и ал., 2016). Нашиот систем е силен во борбата против грешките кои се поврзани со ОЦР, бидејќи добива ЦРР од 87,01 отсто од излезот на ОЦР со ЦРР од 35,76 отсто за една од поставувањата на податоците. Истражувањето на човечките проценки спроведено на моделите покажува дека нашиот предложен модел резултира со предвидувања кои се побрзи за разбирање и побрзи за подобрување за човек отколку за другите системи.', 'ms': 'Kami cadangkan pendekatan pembetulan teks post-OCR untuk digitalisasi teks dalam Sanskrit Romanised. Kerana kekurangan sumber pendekatan kita menggunakan model OCR dilatih untuk bahasa lain yang ditulis dalam bahasa Roman. Semasa, tiada set data yang tersedia untuk OCR Sanskrit Romanised. Jadi, kita bootstrap set data 430 imej, dipindai dalam dua tetapan yang berbeza dan kebenaran tanah yang sepadan. Untuk latihan, kita secara sintetik menghasilkan imej latihan untuk kedua-dua tetapan. Kami mendapati bahawa penggunaan mekanisme penyalinan (Gu et al., 2016) menghasilkan peningkatan peratus 7.69 dalam Kadar Pengenalan Aksara (CRR) daripada keadaan model seni semasa dalam menyelesaikan tugas urutan-ke-urutan monoton (Schnober et al., 2016). Kami mendapati bahawa sistem kami adalah kuat dalam melawan ralat OCR-susah, kerana ia mendapat CRR 87.01% dari output OCR dengan CRR 35.76% untuk salah satu tetapan set data. Survei penghakiman manusia yang dilakukan pada model menunjukkan bahawa model kami diusulkan mengakibatkan ramalan yang lebih cepat untuk memahami dan lebih cepat untuk memperbaiki bagi manusia daripada sistem lain.', 'mt': "Aħna nipproponu approċċ ta' korrezzjoni tat-test wara l-OCR għad-diġitalizzazzjoni tat-testi fis-Sanskrit Rumanizzat. Minħabba n-nuqqas ta’ riżorsi l-approċċ tagħna juża mudelli OCR imħarrġa għal lingwi oħra miktuba bir-Rumen. Bħalissa, ma jeżisti l-ebda sett ta’ dejta disponibbli għall-OCR Sanskrit Rumanizzat. Għalhekk, a ħna nibdew sett ta’ dejta ta’ 430 immaġni, skenati f’żewġ ambjenti differenti u l-verità tal-art korrispondenti tagħhom. Għat-taħriġ, niġġeneraw b’mod sintetiku immaġni ta’ taħriġ għaż-żewġ settijiet. Aħna nsibu li l-użu tal-mekkaniżmu tal-ikkupjar (Gu et al., 2016) jirriżulta f’żieda perċentwali ta’ 7.69 fir-Rata tar-Rikonoxximent tal-Karatteri (CRR) mill-mudell attwali tal-aktar avvanzat fis-soluzzjoni tal-kompiti ta’ sekwenza għal sekwenza ta’ monoton (Schnober et al., 2016). Aħna nsibu li s-sistema tagħna hija b’saħħitha fil-ġlieda kontra żbalji suxxettibbli għall-OCR, billi tikseb CRR ta’ 87.01% minn produzzjoni tal-OCR b’CRR ta’ 35.76% għal wieħed mis-settijiet tad-dejta. Stħarriġ dwar il-ġudizzju uman imwettaq fuq il-mudelli juri li l-mudell propost tagħna jirriżulta fi tbassir li huwa aktar mgħa ġġel biex wieħed jifhem u aktar mgħaġġel biex jittejjeb għal bniedem mis-sistemi l-oħra.", 'ml': 'റോമാനിസ്റ്റ് സാന്\u200dസ്ക്രിറ്റിലെ ഡിജിറ്റിസ്റ്റ് ടെക്സ്റ്റുകള്\u200d ചെയ്യുന്നതിനുള്ള ഒരു പോസ്റ്റ് ഓ റോമനില്\u200d എഴുതിയ മറ്റു ഭാഷകള്\u200dക്ക് പഠിപ്പിക്കപ്പെട്ട ഓസിആര്\u200d മോഡലുകള്\u200d ഉപയോഗിക്കുന്നതിനാല്\u200d നമ്മുടെ സാ ഇപ്പോള്\u200d റോമാനിസ്റ്റ് സാന്\u200dസ്ക്രിറ്റ് ഓസിറ്റിനുള്ള ഡാറ്റാസറ്റ് ലഭ്യമല്ല. അതുകൊണ്ട്, നമ്മള്\u200d 430 ചിത്രങ്ങളുടെ ഡാറ്റാസ്ട്രാക്ക് ചെയ്യുന്നു. രണ്ട് വ്യത്യസ്ത സജ്ജീകരണങ്ങളില്\u200d സ്ക്നാന For training, we synthetically generate training images for both the settings.  മോണോട്ടോണിന്റെ സെക്കന്\u200dസ് സെക്കന്\u200dസ് രണ്ട് സെക്കന്\u200dസ് ജോലികള്\u200d പരിഹരിക്കുന്നതിനെക്കാള്\u200d ഇപ്പോഴത്തെ കലാകാരത്തിന്\u200dറെ രീതിയില്\u200d 7. 69 ശതമാനം വര്\u200dദ്ധിപ്പിക്കുന്നു ഞങ്ങള്\u200d കണ്ടെത്തുന്നു ഞങ്ങളുടെ സിസ്റ്റത്തില്\u200d ഒക്സിര്\u200d പ്രോണ്\u200d പിശകുകളുമായി പോരാടുന്നുണ്ടെന്ന്. അതില്\u200d ഒരു ഡാറ്റാസറ്റിന്റെ സജ്ജീകരണങ്ങളില്\u200d ഒരു ഓ മോഡലില്\u200d പ്രവര്\u200dത്തിക്കപ്പെട്ട ഒരു മനുഷ്യന്റെ വിധി പരിശോധനം കാണിക്കുന്നു നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്\u200d പ്രവചിക്കുന്നത്', 'no': 'Vi foreslår ein postkorrigeringstilnærming for å digitalisera tekstar i romanisert sanskrit. Ved mangling av ressursar, brukar OCR-modeller som er trengte for andre språk skriven i romsk. Det finst ingen datasett tilgjengeleg for Romanisert Sanskrit OCR. Så vi startar ei dataset med 430 bilete, skannert i to ulike innstillingar og deres tilsvarande grunnsannheten. For opplæring lager vi syntetisk opplæringsbilete for begge innstillingane. Vi finn at bruken av kopieringsmekanismen (Gu et al., 2016) gir prosentøkning av 7,69 i teiknkogningsrate (CRR) enn den gjeldande tilstanden av kunstmodellen i løysing av monotonesekvens- til- sekvensoppgåver (Schnober et al., 2016). Vi finn at systemet vårt er sterkt i kombinasjon av OCR-prone feil, fordi det får ein CRR med 87,01% frå ein OCR-utdata med CRR med 35,76% for ein av datasettinnstillingane. Ein undersøking av menneske sprøytebruk utført på modelane viser at vår foreslått modell resulterer i forhåndsvising som er raskare for å forstå og raskare for å forbetra menneske enn andre systemer.', 'pl': 'Proponujemy podejście korekcji tekstu post-OCR do digitalizacji tekstów w sanskrycie romańskim. Ze względu na brak zasobów nasze podejście wykorzystuje modele OCR przeszkolone dla innych języków pisanych w języku rzymskim. Obecnie nie istnieje zbiór danych dotyczący romanizowanego sanskrytu OCR. Tak więc uruchamiamy zestaw danych 430 obrazów, zeskanowanych w dwóch różnych ustawieniach i odpowiadających im prawdzie podstawowej. Do treningów syntetycznie generujemy obrazy treningowe dla obu ustawień. Stwierdzono, że zastosowanie mechanizmu kopiowania (Gu et al., 2016) przynosi procentowy wzrost współczynnika rozpoznawania znaków (CRR) niż obecny model techniki w rozwiązywaniu zadań monotonnych sekwencji-sekwencji (Schnober et al., 2016). Uważamy, że nasz system jest solidny w zwalczaniu błędów podatnych na OCR, ponieważ uzyskuje CRR 87,01% z wyjścia OCR z CRR 35,76% dla jednego z ustawień zbioru danych. Badanie oceny ludzkiej przeprowadzone na modelach pokazuje, że nasz proponowany model skutkuje prognozami, które są szybsze do zrozumienia i szybsze do poprawy dla człowieka niż inne systemy.', 'mn': 'ОКР-ын дараагийн текст зөвшөөрүүлэх арга зам руу Ромын санскрит дэх текстүүдийг тооцоолох боломжтой. Бидний арга хэмжээний баялаг бус байдлаар Романд бичигдсэн өөр хэл дээр сургалтын OCR загварыг ашигладаг. Одоогоор Ромын Санскрит ОКР-д өгөгдлийн сангийн сангууд байхгүй. Тэгэхээр бид 430 зургийн өгөгдлийн хэлбэрийг хуваалцаж, хоёр өөр хэлбэрээр шалгаж, тэдний харьцангуй газрын үнэн. Боловсролын тулд бид хоёр дасгал зураг боловсруулдаг. Бид хуулийн хуулийн механизмийн хэрэглээ (Гу et al., 2016) харьцааны танихын түвшинд 7.69 хувийг нэмэгдүүлж байгааг олж мэднэ. Монотон дарааллаар дарааллаар ажлыг шийдэхэд урлагийн загварын орчин үеэс (Schnober et al., 2016). Бидний систем OCR-ын алдаа тулгарч чаддаг гэдгийг ойлгож байна. Учир нь OCR-ын гаралтаас 87.01% CRR авдаг болохоор өгөгдлийн сангийн нэг хэмжээнд 35.76% CRR авдаг. Хүн төрөлхтний шийдвэрлэлийн судалгаа загвар дээр хийгдсэн нь бидний санал дэвшүүлсэн загвар бусад системээс илүү хурдан ойлгох, хурдан хөгжүүлэхэд илүү хурдан тодорхойлж байгааг харуулдаг.', 'ro': 'Propunem o abordare post-OCR de corectare a textelor pentru digitalizarea textelor în sanscrită romanizată. Datorită lipsei de resurse abordarea noastră folosește modele OCR instruite pentru alte limbi scrise în limba romana. În prezent, nu există niciun set de date disponibil pentru OCR sanscrită romanizată. Deci, am pornit un set de date de 430 de imagini, scanate în două setări diferite și adevărul lor de bază corespunzător. Pentru antrenament, generăm sintetic imagini de antrenament pentru ambele setări. Considerăm că utilizarea mecanismului de copiere (Gu et al., 2016) determină o creștere procentuală de 7,69 în Rata de recunoaștere a caracterelor (CRR) față de modelul actual de ultimă generație în rezolvarea sarcinilor monotone secvență-la-secvență (Schnober et al., 2016). Considerăm că sistemul nostru este robust în combaterea erorilor predispuse la OCR, deoarece obține un CRR de 87,01% dintr-o ieșire OCR cu CRR de 35,76% pentru una dintre seturile de date. Un studiu de judecată umană efectuat pe modele arată că modelul nostru propus are ca rezultat predicții care sunt mai rapide de înțeles și mai rapide de îmbunătățit pentru un om decât celelalte sisteme.', 'sr': 'Predlažemo pristup isprave teksta nakon OCR-a za digitalizaciju teksta u Romaniziranom Sanskritu. Zbog nedostatka resursa naš pristup koristi modele OCR obučene za druge jezike napisane na rimskom jeziku. Trenutno nema podataka dostupne za Romanizirani Sanskrit OCR. Dakle, bacimo podatke sa 430 slika, skenirane u dva različita nastava i njihova odgovarajuća zemlja istina. Za obuku, sintetièki stvaramo slike obuke za obje postavke. Nalazimo da korištenje mehanizma kopiranja (Gu et al., 2016) pruža povećanje od 7,69 u stopi prepoznavanja znakova (CRR) od trenutnog stanja umjetničkog modela u rješavanju zadataka monotonskih sekvencija do sekvencije (Schnober et al., 2016). Naš sistem je jačan u borbi protiv grešaka iz OCR-a, jer dobija CRR od 87,01% iz OCR-a sa CRR od 35,76% za jednu od postavki podataka. Ljudsko istraživanje osuđenja provedeno na modelima pokazuje da naš predloženi model rezultira predviđanja koje su brže da shvatimo i brže da poboljšamo ljude od drugih sistema.', 'sv': 'Vi föreslår en metod för textkorrigering efter OCR för digitalisering av texter på romaniserad sanskrit. På grund av bristen på resurser använder vårt tillvägagångssätt OCR-modeller utbildade för andra språk skrivna på romerska. För närvarande finns det ingen datamängd tillgänglig för Romanised Sanskrit OCR. Så, vi bootstrap en datauppsättning av 430 bilder, skannade i två olika inställningar och deras motsvarande grundsanning. För träning genererar vi syntetiskt träningsbilder för båda inställningarna. Vi finner att användningen av kopieringsmekanism (Gu et al., 2016) ger en procentuell ökning med 7,69 i Character Recognition Rate (CRR) än den nuvarande toppmoderna modellen för att lösa monoton sekvens-to-sekvensuppgifter (Schnober et al., 2016). Vi finner att vårt system är robust för att bekämpa OCR-benägna fel, eftersom det erhåller en CRR på 87,01% från en OCR-utgång med CRR på 35,76% för en av datauppsättningsinställningarna. En mänsklig bedömning undersökning utförd på modellerna visar att vår föreslagna modell resulterar i förutsägelser som är snabbare att förstå och snabbare att förbättra för en människa än de andra systemen.', 'si': 'අපි රෝමානිස් සැන්ස්ක්\u200dරිට් වල ලිපිය අංකිත කරන්න පිටිපස්සේ OCR ලිපිය සඳහා ප්\u200dරවේශනයක් ප්\u200dරවේශන අපේ අවස්ථාවක් නැති අවස්ථාවක් නිසා අපේ අවස්ථාවක් නිසා රෝමන් වල ලියපු අනිත් භාෂාවට ප්\u200dරශ දැනටමත්, රෝමානිස්ක්\u200dරිට් සැන්ස්ක්\u200dරිට් OCR වෙනුවෙන් දත්ත සැකසුම් නෑ. ඉතින්, අපි පින්තූර 430ක් තොරතුරු සූදානයක් බුට්ස්ට්\u200dරැප් කරනවා, වෙනස් සැකසුම් දෙකක් සහ ඔවුන්ගේ ස ප්\u200dරශ්නයක් වෙනුවෙන්, අපි සැකසුම් දෙන්නටම පින්තූර පින්තූර නිර්මාණය කරනවා. අපිට හොයාගන්න පුළුවන් විදියට ප්\u200dරතිලිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළ අපි හොයාගන්නවා අපේ පද්ධතිය OCR-ප්\u200dරධාන වැරදිලි සටන් කරනවා කියලා, ඒක 87.01% CRR කියලා තියෙන්නේ තොරතුරු සැකසුම් එක සඳහා CRR 35.76% කියලා. මිනිස්සු විශ්වාස පරීක්ෂණයක් පෙන්වන්නේ මොඩේල් වලින් අපේ ප්\u200dරතිචාරණය ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ ප', 'so': 'Waxaynu horumarinaynaa qaab hagaajin karo post-OCR-ka-post-OCR oo loogu talogalay qoraalka digixinta ee Romanised Sanskrit. Sababta ay u baahan tahay manfacyada dhaqaalahayagu wuxuu isticmaalaa modelal OCR oo lagu baro luqado kale oo lagu qoray Rooma. Hada la joogo, ma jirto sawir macluumaad ah oo loo heli karo Romanised Sanskrit OCR. Marka waxaynu bilownay sawir 430 ah oo macluumaad ah, waxaana lagu soo sawiray laba meelood oo kala duduwan iyo runtooda ah. For training, we synthetically generate training images for both the settings.  Waxaynu helnaa in isticmaalka koobsashada (Gu et al., 2016) ay bixisaa boqolkiiba korodha aqoonsashada xarafka (CRR) oo ka badan xaaladda muusikada farshaxanka ee ay xalli ka dhigto hawlaha dugaagga monotone (Schnober et al., 2016). Waxaynu aragnaa in nidaamkayagu la dagaalamayo qaladyada OCR, sababtoo ah waxay ka helaysaa CRR 87.01% oo ka soo baxa OCR oo CRR ah 35.76% ka mid ah xarunta macluumaadka. baaritaanka xukunka biniaadamka ee samooyinka lagu sameeyo wuxuu tusiyaa in qaababkayaga la soo jeeday uu ka soo bixiyo warqado dhaqso u baahan karo iyo dhaqso u kordhinta biniaadamka kale.', 'ta': 'நாங்கள் ஒரு பின் OCR உரை திருத்தம் செயல்பாட்டை ஆரம்பிக்கிறோம் ரோமானிஸ்கிரிட்டில் இலக்கங்களை உருவாக்க Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman.  தற்போது, ரோமானிசெய்யப்பட்ட சான்ஸ்கிரிட் OCR க்கு தகவல் அமைப்பு இல்லை. 430 பிம்பங்களின் தரவு அமைப்புகளை தொடங்குகிறோம், இரண்டு வேறு வித்தியாசமான அமைப்புகளில் வருடப்பட்டது, மற்றும் அவர்களு பயிற்சிக்கு, நாம் இரண்டு அமைப்புகளுக்கும் பயிற்சி பிம்பங்களை உருவாக்குகிறோம். நாம் கண்டுபிடிக்கிறோம் மோனோடோனின் வரிசையில் தொடர்ந்து செயல்களை தீர்வு செய்யும் தற்போதைய கலைமாதிரி மாதிரியை விட 7. 69 சதவிகிதத்தை கொடுக்கும் சதவிகிதத்தில் 7. 69 வ நாங்கள் கணினி OCR-பிழைகளை போராடும் போது திருப்பப்பட்டுள்ளது என்று கண்டுபிடிக்கிறோம். இது OCR வெளியீட்டிலிருந்து 87. 01% கிடைக்கும் என்பதால மாதிரிகளில் செயல்படுத்தப்பட்ட ஒரு மனித த தீர்ப்பு பரிசோதிக்கப்பட்டுள்ளது என்று காட்டுகிறது எங்கள் பரிந்துரைக்கப்பட்ட மாதிரி முடிவு', 'ur': 'ہم رومانیز سانسکریت میں تفصیل دیجیٹ کرنے کے لئے ایک پیچھے OCR ٹیکسٹ اصلاح کا طریقہ پیشنهاد کرتے ہیں. ہماری دستور کے غیر منصفات کے باعث OCR موڈل کو رومین میں لکھی ہوئی دوسری زبانوں کے لئے آموزش کی جاتی ہے۔ اکنون، رومانی سنسکریت OCR کے لئے کوئی ڈیٹ سٹ موجود نہیں ہے. تو ہم نے 430 تصویروں کے ڈاٹ سٹ کو ڈال دیا، دو مختلف تنظیمات میں اسکن کیا اور ان کے مطابق زمینی حقیقت میں۔ تعلیم کے لئے، ہم دونوں سیٹیوں کے لئے تدریس تصاویر بناتے ہیں۔ ہم دیکھتے ہیں کہ کاپین مکانیسم (Gu et al., 2016) کا استعمال کرتا ہے کہ کریٹر پتپذیر رچم (CRR) میں 7.69 فیصد اضافہ کرتا ہے جو موٹن کے موجود موڈل کے موجود موجود موجود موجود ہے (Schnober et al., 2016). ہم دیکھتے ہیں کہ ہماری سیستم OCR-prone errors سے جہاد کرنے میں مضبوط ہے، کیونکہ اس نے 87.01% کی CRR سے 35.76% کی CRR کے ساتھ ایک ڈیٹسٹ سیٹیوں کے لئے حاصل کیا ہے. ایک انسان کا فیصلہ تحقیق جو مدل پر عمل کیا گیا ہے دکھاتا ہے کہ ہماری پیشنهاد کی مدل پیش بینی کے نتیجے ہیں جو دوسرے سیستم سے انسان کے لئے بہتر سمجھنے اور بہتر سمجھنے کے لئے بہتر ہیں۔', 'uz': "Biz Romaniz Sanskritdagi raqamli matnlarni toʻgʻrilash uchun keyin OCR matnni tahrirlash usulini tahrirlash talab qilamiz. Mavzularning manbalari yo'q boʻlishi sababda, Romandagi boshqa tillarda yozilgan OCR modellaridan foydalanadi. Joriy Romanised Sanskrit OCR uchun maʼlumot seti mavjud emas. Shunday qilib, biz 430 rasmning maʼlumotlarini boshlab boshlamiz, ikkita boshqa moslamalarda skan qilamiz va ularning qisqarli holat haqida. Tashqi uchun biz ikkita moslamalar uchun ta'lim rasmlarini yaratib olamiz. Biz bildikki, nusxa olish mechanisining foydalanishini (Gu et al., 2016) harf Tasdiqlash Rate (CRR) da 7. 69 foizga 7. 69 dan foiz ko'payadi. Monotone sequence to'xtatish vazifalarini (Schnober et al., 2016) ishlab chiqarishidan foydalanadi. Biz o'ylaymiz, bizning tizimmiz OCR-tizim notoʻgʻri bilan boshlanadi, chunki u maʼlumot moslamalaridan biri OCR natijasidan 87.01% CRR'ga ega bo'ladi. Modellarda qo'yish muvaffaqiyatli o'zgarishni ko'rsatadi. Bu o'ylagan modelimizning oldini tushunish va boshqa tizimlardan o'zgartirishga tez keladi va tez o'zgartirish natijalariga ega bo'ladi.", 'vi': 'Chúng tôi đề nghị một phương pháp sửa chữa văn bản sau-OCR để số hóa văn bản trong chữ Phạn. Do thiếu nguồn lực, phương pháp của chúng tôi sử dụng các mô hình OCR được đào tạo cho những ngôn ngữ khác được viết bằng tiếng La Mã. Hiện tại, không có bộ dữ liệu nào có sẵn cho Romed Sanskrit OCR. Vậy, chúng ta khởi động một tập tin chứa ảnh 430, đã quét trong hai thiết lập khác nhau và tạo ra sự thật đối diện của chúng. Để được huấn luyện, chúng tôi tạo ảnh huấn luyện tổng hợp cho cả hai thiết lập. Chúng tôi thấy rằng sử dụng cơ chế bắt chước (Cố vấn và thẩm quyền) sẽ làm tăng tỷ lệ 7.69 ở mức ký tự nhận biết (CRR) hơn mức hiện thời của mô hình nghệ thuật để giải quyết các công việc độc nhất từng dãy một (Schneider et al., 206). Chúng tôi thấy hệ thống của chúng tôi mạnh mẽ trong việc chống lại lỗi dễ bị gây ra OCR, vì nó có được một bộ vi xử lí CRR với giá trị 35.06. cho một trong những thiết lập tập tin. Một cuộc nghiên cứu con người thực hiện trên các mô hình cho thấy mẫu của chúng ta kết quả là những dự đoán nhanh hơn để nhận thức và nhanh hơn để cải thiện cho con người hơn những hệ thống khác.', 'da': 'Vi foreslår en post-OCR tekstkorrektion tilgang til digitalisering af tekster på romaniseret sanskrit. På grund af manglen på ressourcer bruger vores tilgang OCR modeller uddannet til andre sprog skrevet på romersk. I øjeblikket findes der ikke noget datasæt tilgængeligt for Romanised Sanskrit OCR. Så vi bootstrap et datasæt på 430 billeder, scannet i to forskellige indstillinger og deres tilsvarende grundsandhed. Til træning genererer vi syntetisk træningsbilleder til begge indstillinger. Vi konstaterer, at brugen af kopieringsmekanisme (Gu et al., 2016) giver en procentvis stigning på 7,69 i karakterkendelsesrate (CRR) end den nuværende state of te art model til løsning af monotone sekvens-to-sekvens opgaver (Schnober et al., 2016). Vi finder ud af, at vores system er robust til at bekæmpe OCR-udsatte fejl, da det opnår en CRR på 87,01% fra en OCR-udgang med CRR på 35,76% for en af datasætteindstillingerne. En menneskelig vurderingsundersøgelse udført på modellerne viser, at vores foreslåede model resulterer i forudsigelser, som er hurtigere at forstå og hurtigere at forbedre for et menneske end de andre systemer.', 'nl': 'We stellen een post-OCR tekstcorrectiebenadering voor voor het digitaliseren van teksten in het geromaniseerd Sanskriet. Vanwege het gebrek aan middelen maakt onze aanpak gebruik van OCR modellen die zijn getraind voor andere talen geschreven in het Romeins. Momenteel is er geen dataset beschikbaar voor Romanised Sanskriet OCR. Dus, we bootstrappen een dataset van 430 beelden, gescand in twee verschillende instellingen en hun overeenkomstige grond waarheid. Voor de training genereren we synthetisch trainingsbeelden voor beide instellingen. We vinden dat het gebruik van kopieermechanisme (Gu et al., 2016) een procentuele toename van 7,69 in karakterherkenningsrate (CRR) oplevert dan het huidige state-of-the-art model bij het oplossen van monotone sequence-to-sequence taken (Schnober et al., 2016). We vinden dat ons systeem robuust is in het bestrijden van OCR-gevoelige fouten, omdat het een CRR van 87.01% verkrijgt van een OCR-uitvoer met CRR van 35.76% voor een van de dataset-instellingen. Uit een onderzoek naar menselijk oordeel op de modellen blijkt dat ons voorgestelde model resulteert in voorspellingen die sneller te begrijpen en sneller te verbeteren zijn voor een mens dan de andere systemen.', 'bg': 'Предлагаме подход за корекция на текста след ОКР за дигитализиране на текстове на романизиран санскрит. Поради липсата на ресурси нашият подход използва модели, обучени за други езици, написани на римски език. Понастоящем няма наличен набор от данни за романизиран санскрит OCR. Така че, ние стартираме набор от данни от 430 изображения, сканирани в две различни настройки и съответстващата им основна истина. За обучение синтетично генерираме тренировъчни изображения и за двете настройки. Установяваме, че използването на копиращ механизъм (Гу и др., 2016) води до процентно увеличение от 7,69 в скоростта на разпознаване на знаци (КРР) в сравнение с текущия модел на съвременно ниво при решаване на задачи от монотонни последователности към последователност (Шнобер и др., 2016). Намираме, че нашата система е здрава в борбата с предразположени към грешки, тъй като тя получава КР от 87.01% от изход с КР от 35.76% за една от настройките на набора от данни. Изследване на човешката преценка, извършено върху моделите, показва, че предложеният модел води до прогнози, които са по-бързи за разбиране и по-бързи за подобряване за човек, отколкото за другите системи.', 'hr': 'Predlažemo pristup isprave teksta nakon OCR-a za digitalizaciju teksta u Romaniziranom sanskritu. Zbog nedostatka resursa naš pristup koristi modele OCR obučene za drugi jezici napisani na rimskom jeziku. Trenutno nema podataka dostupne za Romanizirani Sanskrit OCR. Dakle, prebacimo podatke od 430 slika, skenirane u dvije različite nastave i njihovu odgovarajuću zemlju istinu. Za obuku, sintetički stvaramo slike obuke za obje postavke. Nalazimo da korištenje mehanizma kopiranja (Gu et al., 2016) pruža postotni povećanje od 7,69 u stopi prepoznavanja znakova (CRR) od trenutnog stanja umjetničkog modela u rješavanju zadataka monotonskih sekvencija do sekvencije (Schnober et al., 2016). Pronašli smo da je naš sustav jak u borbi protiv grešaka iz OCR-a, jer dobija CRR od 87,01% iz OCR-a sa CRR-om od 35,76% za jednu od postavki podataka. Ljudsko istraživanje procjene provedeno na modelima pokazuje da naš predloženi model rezultira predviđanja koje su brže shvatiti i brže poboljšati ljudima od drugih sustava.', 'de': 'Wir schlagen einen post-OCR Textkorrekturansatz für die Digitalisierung von Texten in romanisiertem Sanskrit vor. Aufgrund des Mangels an Ressourcen verwendet unser Ansatz OCR-Modelle, die für andere Sprachen in römischer Sprache trainiert wurden. Derzeit gibt es keinen Datensatz für Romanised Sanskrit OCR. Also bootstrap wir einen Datensatz von 430 Bildern, gescannt in zwei verschiedenen Einstellungen und der entsprechenden Ground Truth. Für das Training generieren wir für beide Einstellungen synthetisch Trainingsbilder. Wir stellen fest, dass die Verwendung von Kopiermechanismen (Gu et al., 2016) eine prozentuale Erhöhung der Zeichenerkennungsrate (CRR) von 7,69 als das derzeitige Modell zur Lösung monotoner Sequenz-zu-Sequenz Aufgaben (Schnober et al., 2016) ergibt. Wir finden, dass unser System robust ist, um OCR-anfällige Fehler zu bekämpfen, da es einen CRR von 87.01% von einem OCR-Ausgang mit CRR von 35.76% für eine der Datensatzeinstellungen erhält. Eine menschliche Beurteilung der Modelle zeigt, dass unser vorgeschlagenes Modell zu Vorhersagen führt, die für einen Menschen schneller zu verstehen und schneller zu verbessern sind als die anderen Systeme.', 'id': 'Kami mengusulkan pendekatan koreksi teks post-OCR untuk digitalisasi teks dalam bahasa Romanis Sanskrit. Karena kekurangan sumber daya pendekatan kita menggunakan model OCR yang dilatih untuk bahasa lain ditulis dalam bahasa Roman. Saat ini, tidak ada set data yang tersedia untuk OCR Sanskrit Romanised. Jadi, kita bootstrap dataset 430 gambar, dipindai dalam dua pengaturan yang berbeda dan kebenaran tanah yang sesuai dengan mereka. Untuk pelatihan, kami secara sintetis menghasilkan gambar pelatihan untuk kedua pengaturan. Kami menemukan bahwa penggunaan mekanisme penyalinan (Gu et al., 2016) menghasilkan persentase meningkat dari 7,69 dalam Rata Pengenalan Karakter (CRR) daripada model seni saat ini dalam memecahkan tugas urutan-urutan monoton (Schnober et al., 2016). Kami menemukan bahwa sistem kami kuat dalam melawan kesalahan OCR-susah, karena ia mendapatkan CRR 87,01% dari output OCR dengan CRR 35,76% untuk salah satu pengaturan set data. Survei penilaian manusia yang dilakukan pada model menunjukkan bahwa model kami diusulkan hasil dalam prediksi yang lebih cepat untuk memahami dan lebih cepat untuk memperbaiki bagi manusia daripada sistem lain.', 'ko': '우리는 로마 범어 텍스트의 디지털화에 사용되는 OCR 후 텍스트 교정 방법을 제시했다.자원이 부족하기 때문에, 우리의 방법은 로마에서 쓴 다른 언어 교육을 위한 OCR 모델을 사용합니다.아직 로마 산스크리트어 OCR에 사용할 수 있는 데이터 세트는 없다.따라서 우리는 430폭의 이미지를 포함하는 데이터 집합을 유도하여 두 가지 다른 설정에서 스캐닝을 하고 해당하는 기본적인 사실을 얻었다.훈련에 대해 우리는 두 가지 설정된 훈련 이미지를 종합적으로 생성한다.우리는 단조로운 서열부터 서열 임무까지 해결할 때 복제 메커니즘(Gu 등, 2016년)을 사용하여 문자인식률(CRR)을 현재 가장 선진적인 모델보다 7.69%포인트(Schnober 등, 2016년) 높인 것을 발견했다.우리는 우리 시스템이 OCR 오류가 발생하기 쉬운 것에 대항하는 데 매우 안정적이라는 것을 발견했다. 왜냐하면 그 중의 데이터 집합 설정에 대해 OCR 출력에서 87.01%의 CRR을 얻었고 CRR은 35.76% 이기 때문이다.모델에 대한 인류 판단 조사에 따르면 우리가 제시한 모델이 얻은 예측은 다른 시스템이 인류에 대한 이해와 개선보다 빠르다.', 'fa': 'ما پیشنهاد می\u200cکنیم یک روش اصلاح متن بعد از OCR برای دیجیتال کردن متن در سنسکریت رومانی. به دلیل lack of resources our approach uses OCR models trained for other languages written in Roman. در حال حاضر، مجموعه داده ای برای OCR رومانیز وجود ندارد. بنابراین، ما مجموعه داده\u200cهای 430 تصویر را می\u200cبندیم، در دو تنظیمات متفاوت و حقیقت زمینی که مربوط به آنها می\u200cشود اسکن می\u200cکنیم. برای تمرین، ما تصاویر آموزش را برای هر دو تنظیمات ساختیم. ما پیدا می\u200cکنیم که استفاده از مکانیسم کپی کردن (Gu et al., 2016) درصد افزایش 7.69 درصد در میزان شناسایی شخصیت (CRR) از موقعیت فعلی مدل هنری در حل کارهای تکنولوژی\u200cها (Schnober et al., 2016) می\u200cشود. ما فهمیدیم که سیستم ما در مبارزه با اشتباهی\u200cهای OCR-prone سخت است، زیرا این سیستم 87.01 درصد از یک خروج OCR با CRR 35.76 درصد برای یکی از تنظیم\u200cهای مجموعه\u200cهای داده می\u200cگیرد. یک تحقیقات قضاوت انسانی که روی مدل\u200cها انجام شده، نشان می\u200cدهد که مدل پیشنهاد ما به پیش\u200cبینی\u200cها نتیجه می\u200cدهد که سریع\u200cتر برای درک و سریع\u200cتر از سیستم\u200cهای دیگر برای یک انسان بهتر می\u200cشود.', 'sw': 'Tunazipendekeza mbinu za kurekebisha maandishi ya posti ya OCR kwa ajili ya kuandika ujumbe wa kidigitali katika Sanskrit ya Romanised Sanskrit. Kutokana na kukosekana kwa rasilimali zetu mbinu zetu hutumia mifano ya OCR inayofundishwa kwa lugha nyingine zilizoandikwa nchini Romani. Kwa sasa, hakuna seti ya taarifa zinazopatikana kwa ajili ya OCR ya Romanized Sanskrit OCR. Kwa hiyo, tunaanzisha seti ya takwimu ya picha 430, zilizosambazwa katika mazingira mawili tofauti na ukweli wa ardhi inayofanana. Kwa mafunzo, kwa pamoja tunatengeneza picha za mafunzo kwa mipango yote. Tunapata kwamba matumizi ya mfumo wa nakala (Gu et al., 2016) yanasababisha ongezeko la asilimia 7.69 katika kiwango cha Kutambua Kanuni (CRR) kuliko hali ya sasa ya sanaa katika kutatua kazi za mfumo wa mfululizo wa mfululizo wa nyakati (Schnober et al., 2016). Tunapata kwamba mfumo wetu unavamia makosa yanayotokana na OCR, kwa sababu inapata CRR asilimia 87.01 kutoka kwenye matokeo ya OCR yenye CRR ya asilimia 35.76 kwa moja ya seti za data. Tafiti la uamuzi wa binadamu uliofanywa katika mifano inaonyesha kwamba mtindo wetu unapendekezwa utabiri ambao ni haraka kuelewa na haraka kuboresha kwa binadamu kuliko mifumo mingine.', 'sq': 'We propose a post-OCR text correction approach for digitising texts in Romanised Sanskrit.  Për shkak të mungesës së burimeve metoda jonë përdor modele OCR të trajnuar për gjuhë të tjera të shkruara në romak. Aktualisht, nuk ekziston asnjë komplet i të dhënave në dispozicion për OCR Sanskrit të Rumanisuar. Kështu që, ne vendosim një grup të dhënash prej 430 imazhesh, skanuar në dy rregullime të ndryshme dhe të vërtetën e tyre të përkatshme në tokë. Për stërvitje, ne sintetikisht gjenerojmë imazhe stërvitjeje për të dy rregullimet. Ne zbulojmë se përdorimi i mekanizmit kopjimi (Gu et al., 2016) jep një rritje përqindjesore prej 7.69 në Ratën e njohjes së Karaktereve (CRR) sesa gjendja aktuale e modelit më të mirë në zgjidhjen e detyrave monotone-to-sequence (Schnober et al., 2016). Ne zbulojmë se sistemi ynë është i fortë në luftën kundër gabimeve të propozuara për OCR, pasi ai merr një CRR prej 87.01% nga një output OCR me CRR prej 35.76% për një nga rregullimet e dataset. Një sondazh i gjykimit njerëzor i kryer mbi modelet tregon se modeli ynë i propozuar rezulton në parashikime që janë më të shpejtë për të kuptuar dhe më të shpejtë për të përmirësuar për një njeri sesa për sistemet e tjera.', 'af': "Ons voorstel 'n post- OCR teksredigeringstoegang vir digitalisering van teks in Romaniseerde Sanskrit. Om die ontbreek van hulpbronne, gebruik ons toegang OCR-modele wat opgelei is vir ander tale wat in Romeine geskrywe is. Opstuur bestaan geen datastel beskikbaar vir Romaniseerde Sanskrit OCR nie. So, ons boot 'n datastel van 430 beelde, skenner in twee verskillende instellings en hul ooreenstemmende grondwaarheid. Vir onderwerp genereer ons sinteties onderwerp beelde vir beide die instellings. Ons vind dat die gebruik van kopiëringsmekanisme (Gu et al., 2016) gee 'n persentasie vergroot van 7.69 in Karakter Herkening Rate (CRR) as die huidige staat van die kuns model in die oplossing van monotone sekvensie-na-sekvensie taak (Schnober et al., 2016). Ons vind dat ons stelsel is kragtig in oorlog van OCR-prone foute, want dit kry 'n CRR van 87.01% van 'n OCR uitset met CRR van 35.76% vir een van die datastel instellings. 'n Mense oordeelsondersoek wat op die modele uitgevoer is, wys dat ons voorgestelde model resultate in voorsoeke wat vinniger is om te verstaan en vinniger om vir 'n mens te verbeter as die ander stelsels.", 'tr': 'Biz Romanized Sanskritde metinleri digital etmek üçin OCR üçin metin düzeltmek üçin bir teklip teklip berýäris. Nähili çeşmelerimiz ýok bolmagyna sebäbi biz Roma dilinde ýazylan OCR modellerini ulanýarys. Şu wagt Romanizýän Sanskrit OCR üçin hiç hili maglumaty tapylmady. Bu yüzden, 430 resim veri takımını başlatırız ve iki farklı ayarlar içine taranmıştık. Okuw üçin, iki düzümler üçin okuw suratlary sintetik edip bilýäris Biz Nusgala Mazmunlaryň ullanyşyny (Gu et al., 2016) Karakter tanyşmasynyň häzirki durumyndan 7.69 sany artdyrylýar. Sistemimiz OCR pron hatalarynda ýüzleýän ýüzünde robust hasaplanýarys, sebäbi ol 87.01% OCR çizgisinden 35.76% halta edip bolýar. Adamlar hökmünde nusgalar çykylýan pikirimçe nusgalarymyzyň başga sistemalardan ýokary adama gelişmek we çalt düşünmek üçin çalt däldigini görkezýär.', 'hy': 'Մենք առաջարկում ենք OCR-ից հետո ստացված տեքստի կարգավորման մոտեցում ռոմանիզացված սանկրիտ տեքստների թվայնացման համար: Քանի որ ռեսուրսների պակաս է, մեր մոտեցումը օգտագործում է OCR մոդելներ, որոնք պատրաստված են ռոմաներեն լեզուների համար: Հիմա ոչ մի տվյալների համակարգ չկա Ռոմանիզացված սանդկրատական OCR-ի համար: So, we bootstrap a dataset of 430 images, scanned in two different settings and their corresponding ground truth.  Արժեքի համար մենք սինթետիկ կերպով ստեղծում ենք ուսուցման պատկերներ երկու միջոցների համար: Մենք հայտնաբերում ենք, որ հեղինակային մեխանիզմի օգտագործումը (Գյու և այլն., 2016) 7.69 տոկոսով աճ է հանդիսանում հեղինակային ճանաչության մակարդակի (ԿՌ) մեջ, քան ներկայիս արվեստի մոդելը մեկ տոկոսով հաջորդականության խնդիրների լուծման մեջ (Շնոբեր և այլն., 2016). Մենք հայտնաբերում ենք, որ մեր համակարգը ուժեղ է OCR-ի պատճառ ունեցող սխալների դեմ պայքարելու համար, քանի որ այն ստանում է OCR-ի արտադրությունից 87.01 տոկոսը, որն ունի 35.76 տոկոսը տվյալների համակարգից մեկի համար: Մարդկային դատողության հետազոտությունը, որը կատարվել է մոդելների վրա, ցույց է տալիս, որ մեր առաջարկված մոդելը արդյունքում է կանխատեսումների, որոնք ավելի արագ են հասկանալու և ավելի արագ բարելավելու մարդկանց համար, քան մյուս համակարգերը:', 'am': 'በሮማኒሳዊው ሳንስክሪት የጽሑፎችን ዲጂጂትስ ጽሑፎችን ለመቀበል የፖስታ ኦኮር ጽሑፍ ማቀናጃ እናሳልጋለን፡፡ በሮማውያን ለሌሎች ቋንቋዎች የተጠቃሚ የኦCR ሞዴላዎችን ይጠቅማል፡፡ በአሁኑ ጊዜ ለሮማኒሳዊው ሳንስክሮት OCR ዳታ setup አልተገኘም። አዲስ የ430 ምስሎችን የዳታ አካባቢ እና የሁለት ልዩ አካላት እና የመሬት አካላዊ መሬት እና ነጥቀዋለን፡፡ For training, we synthetically generate training images for both the settings.  የቅጂ አካል (Gu et al., 2016) የሚጠቀም የሥርዓት ማውቀት ቁጥር 7.69 በሚያበዛ በመቶው ያሳድጋል (CRR) በዓላማዊ ሞዴል በሁለተኛው ክፍል በሞናቶን ድርጅት ላይ ለክፍለ ሥርዓት (Schnober et al., 2016) እንዲፈጸም እናገኛለን፡፡ የOCR ስህተት ለመቀላቀል ስርዓታችንን እንደቀረበ እና ከኦCR ውጤት ጋር 35.76 በመቶ ለዳታ ማዘጋጀት ከክሮፕ ውጤት 87.01 በመቶ ሰርቨርስቲ እንዲያገኝ ነው፡፡ በዓይነቶች ላይ የተፈጸመ የሰው ፍርድ ምርመራ የሞዴል ዓይነታችን ከሌሎች ስርዓቶች ይልቅ ለማስተዋል ፍጥረት ፈጥኖ እና ለመሻለል ፈጥኖ የሚችል ፍጻሜ ይመልሳል፡፡', 'bn': 'We propose a post-OCR text correction approach for digitising texts in Romanised Sanskrit.  রোমানে লেখা অন্যান্য ভাষায় প্রশিক্ষিত ওসিআর মডেল ব্যবহার করেছে। বর্তমানে রোমানিস্ট স্যান্স্ক্রিট ওসির জন্য কোনো ডাটাসেট উপস্থিত নেই। তাই আমরা ৪৩০ ছবির একটি ডাটা সেট বুটস্ট্র্যাক করি, দুটি বিভিন্ন বৈশিষ্ট্যে স্ক্যান করা হয়েছে এবং তাদের সাথে যোগা প্রশিক্ষণের জন্য আমরা দুটো বৈশিষ্ট্যের জন্য প্রশিক্ষণের ছবি তৈরি করি। আমরা খুঁজে পাচ্ছি যে ক্যান্টারের স্বীকৃতি হারে ৭. ৬৯ শতাংশ বৃদ্ধি প্রদান করেছে এই শিল্প মডেলের বর্তমান পরিস্থিতির চেয়ে মোনোটোনেন সেকেন্সেকেন্স-দ্বিতীয় কাজ সমাধান আমরা খুঁজে পাচ্ছি যে আমাদের সিস্টেম OCR-প্রক্রিয়া ত্রুটির বিরুদ্ধে লড়াই করা হয়েছে, যেহেতু এটি একটি OCR আউটপুট থেকে ৮৭. 01% পাওয়া যাচ্ছে যার সাথে সি মডেলে একটি মানুষের বিচারের জরিপ দেখা যাচ্ছে যে আমাদের প্রস্তাবিত মডেলের ফলে ভবিষ্যৎবাণীর ফলে যা অন্যান্য সিস্টেমের চেয়ে মানুষ', 'az': 'Biz Romanizləndirilmiş Sanskritdə metinləri digitalizə etmək üçün OCR-dən sonra metin düzəltmə yolunu təklif edirik. Qaynaqların yoxduğuna görə bizim tərzimiz Romadan yazılmış başqa dillər üçün təhsil edilmiş OCR modelləri istifadə edir. Şu anda Romanizlənmiş Sanskrit OCR üçün verilən quruluş yoxdur. Beləliklə, biz 430 görüntülərin verilənlərin quruluşunu çəkirik, iki müxtəlif quruluş və onların müəyyən yerdə olduğu həqiqətə görə skenirik. Əlavə etmək üçün, hər iki ayarlar üçün təhsil görüntüləri sintetik olaraq yaradırıq. İşləmə mehanizmisinin istifadəsi (Gu et al., 2016) qarşılıq tanıması dərəcəsində 7,69%-in art ıqlığı artıqlığı, monotone sequence-to-sequence işlərini çəkməkdə (Schnober et al., 2016). Sistemimiz OCR-prone hatalarını döyüşə çıxarmaq üçün güclüdür, çünki verilən quruluş quruluşlarından birinin 35,76% CRR ilə OCR çıxışından 87,01% CRR alır. Modellərdə işlədiyimiz insan hökmünün araştırması göstərir ki, təklif etdiyimiz modellərin başqa sistemlərdən daha hızlı və daha hızlı bir insan üçün daha yaxşılaşdırmaq üçün nəticə etdiyimiz tədbirlərə nəticə edir.', 'ca': "We propose a post-OCR text correction approach for digitising texts in Romanised Sanskrit.  A causa de la falta de recursos el nostre enfocament utilitza models OCR entrenats per altres llengües escrites en roman. Actualment, no existeix un conjunt de dades disponible per a l'OCR sànscrit romanitzat. Així que vam arrancar un conjunt de dades de 430 imatges, escanejats en dues configuracions diferents i la seva veritat fonamental correspondent. Per a formar-nos, sintèticament generem imatges d'entrenament per a les dues configuracions. Trobem que l'ús del mecanisme de còpia (Gu et al., 2016) produeix un augment en un percentatge de 7,69 en Rata de Recognició de Caracters (CRR) que el model actual d'última generació en resoldre tasques de seqüència a seqüència de monotones (Schnober et al., 2016). Trobem que el nostre sistema és robust en combatre els errors propensos a OCR, com obté un CRR del 87,01% d'una producció OCR amb un CRR del 35,76% per una de les configuracions del conjunt de dades. Un estudi de judici humà fet sobre els models mostra que el nostre model proposat resulta en prediccions que són més ràpids per entendre i millorar més ràpidament per a un humà que per als altres sistemes.", 'cs': 'Pro digitalizaci textů v romském sanskrtu navrhujeme postOCR korekci textů. Vzhledem k nedostatku zdrojů náš přístup používá OCR modely trénované pro jiné jazyky psané v římském jazyce. V současné době neexistuje žádný datový soubor pro romský sanskrt OCR. Takže spouštíme datovou sadu 430 obrázků, naskenovanou ve dvou různých nastaveních a odpovídající pozemní pravdě. Pro trénink synteticky generujeme tréninkové obrázky pro obě nastavení. Zjišťujeme, že použití kopírovacího mechanismu (Gu et al., 2016) přináší procentní zvýšení rychlosti rozpoznávání znaků o 7,69 než současný model při řešení monotónních úloh sekvence na sekvenci (Schnober et al., 2016). Zjišťujeme, že náš systém je robustní v boji proti chybám náchylným k OCR, protože získává CRR 87,01% z OCR výstupu s CRR 35,76% pro jedno z nastavení datové sady. Průzkum lidského úsudku provedený na těchto modelech ukazuje, že náš navržený model vede k předpovědím, které jsou rychleji pochopitelné a rychleji zlepšovatelné pro člověka než ostatní systémy.', 'et': 'Pakume välja OCR-järgse teksti parandamise lähenemisviisi romaniseeritud sanskriti keeles tekstide digiteerimiseks. Ressursside puudumise tõttu kasutab meie lähenemisviis OCR mudeleid, mis on koolitatud teiste rooma keeles kirjutatud keelte jaoks. Praegu ei ole romaniseeritud sanskriti OCR-i andmekogumit kättesaadav. Nii et me alustame 430 pildist koosneva andmekogumi, skaneeritud kahes erinevas seadistuses ja nende vastav tõde. Koolituseks genereerime sünteetiliselt treeningpilte mõlema seadistuse jaoks. Leiame, et kopeerimismehhanismi (Gu et al., 2016) kasutamine annab märgituvastuse määra (CRR) protsendimäära 7,69 protsendimäära kasvu kui praegune tehnika mudel monotoonsete järjestuste lahendamisel (Schnober et al., 2016). Leiame, et meie süsteem on tugev OCR-ile kalduvate vigade vastu võitlemisel, kuna see saab OCR-i väljundist 87,01% CRR-i ja ühe andmekogumi seadete CRR-i 35,76%. Mudelite põhjal läbi viidud inimese hinnangu uuring näitab, et meie kavandatud mudeli tulemuseks on prognoosid, mida on kiirem mõista ja kiirem parandada inimese jaoks kui teised süsteemid.', 'bs': 'Predlažemo pristup isprave teksta nakon OCR-a za digitalizaciju teksta u Romaniziranom sanskritu. Zbog nedostatka resursa naš pristup koristi modele OCR obučene za drugi jezici napisani na rimskom jeziku. Trenutno nema podataka dostupne za Romanizirani Sanskrit OCR. Dakle, bacimo podatke sa 430 slika, skenirane u dva različita postavka i njihova odgovarajuća zemlja istina. Za obuku, sintetično stvorimo slike obuke za obje postavke. Nalazimo da korištenje mehanizma kopiranja (Gu et al., 2016) pruža procentni povećanje od 7,69 u stopi prepoznavanja znakova (CRR) od trenutnog stanja modela umjetnosti u rješavanju zadataka monotonskih sekvencija do sekvence (Schnober et al., 2016). Naš sistem je jačan u borbi protiv grešaka iz OCR-a, jer dobija CRR od 87,01% iz OCR-a sa CRR od 35,76% za jednu od postavki podataka. Ljudsko istraživanje osuđenja provedeno na modelima pokazuje da naš predloženi model rezultira predviđanja koje su brže da shvatimo i brže da poboljšamo ljude od drugih sustava.', 'fi': 'Ehdotamme OCR:n jälkeistä tekstin korjausta romanisoidun sanskritin tekstien digitointiin. Resurssien puutteen vuoksi lähestymistapamme käyttää OCR-malleja, jotka on koulutettu muille roomalaisille kielille. Romanised Sanskrit OCR:stä ei tällä hetkellä ole saatavilla aineistoa. Käynnistämme siis 430 kuvan datajoukon, jotka on skannattu kahdessa eri paikassa ja vastaavat totuudet. Harjoittelua varten luomme synteettisesti harjoituskuvia molempiin asetuksiin. Havaitsemme, että kopiointimekanismin käyttö (Gu et al., 2016) tuottaa 7,69 prosentin nousun Character Recognition Rate (CRR) verrattuna nykyiseen moderniin malliin monotone sequence-to-sequence -tehtävien ratkaisemisessa (Schnober et al., 2016). Järjestelmämme on vankka torjumaan OCR-alttiita virheitä, sillä se saa OCR-tuotoksesta 87,01% CRR-arvon ja 35,76% CRR-arvon yhdelle datajoukon asetuksista. Mallien perusteella tehty ihmisen arviointitutkimus osoittaa, että ehdotettu malli tuottaa ennusteita, jotka ovat nopeampia ymmärtää ja nopeampia parantaa ihmiselle kuin muut järjestelmät.', 'jv': 'We proposal a mail-OCR text justification method for digitisation of texts in romisated Sankrit. Tanggang ono langkung karo akeh penggunaké awakdhéwé dadi model OCR sing ditambah nggo langgambaran sing rumangsa barang maning. Sankrit OCR So, we sistem dadi sing dibutuhke alaman karo 480 gambar, dino ning acara sampeyan bingi lan nganggo sampeyan sing wis barang kelas barang. Genjer-genjer saiki, kita seneng sistem sing gawe nggawe gambar aturan kanggo wong iki dadi. Awak dhéwé nglanggar nggambar sistem sing nggambar (Gu et al, 2011) sumelan karo perusahaan ning 7.9 kanggo Kemerdekaan Karakter (CR) seneng kalagayut nguasai sistem sing berarti kanggo nambah lanjut maneh lanjut ning sekondirne seneng dadi Moneton-to-sekondirne tasks (XNoer et al, 2011). Awakdhéwé éntuk sistememuk perkoro sing nggawe barang-perkoro kanggo ngilangno OCR perkoro, dadi kapan tanggap tanggap palet depatené kapan tanggap palet: dolanan sing perkoro kapan tanggap (OCR) sing paling-perkoro sing perkoro kapan tanggap (OCR) Rasané hukum sing berarti dipunangé uwong ing model kuwi bisa ngomong nik awak dhéwé model sing supoyo supoyatan kanggo masalah sing luwih apik dhéwé, lan susahé awak dhéwé sing luwih apik kanggo nik sistem sing oleh.', 'sk': 'Predlagamo pristop popravka besedila po OCR za digitalizacijo besedil v romaniziranem sanskrtu. Zaradi pomanjkanja virov naš pristop uporablja modele OCR, usposobljene za druge jezike, napisane v rimskem jeziku. Trenutno ni na voljo nobenega nabora podatkov za romanizirani sanskritski OCR. Zato zaženemo nabor podatkov 430 slik, skeniranih v dveh različnih nastavitvah in njihovo ustrezno osnovno resnico. Za vadbo sintetično ustvarimo slike vadbe za obe nastavitvi. Ugotavljamo, da uporaba kopirnega mehanizma (Gu et al., 2016) prinaša odstotno povečanje stopnje prepoznavanja znakov (CRR) za 7,69 odstotka kot trenutni najsodobnejši model pri reševanju nalog monotonskega zaporedja do zaporedja (Schnober et al., 2016). Ugotavljamo, da je naš sistem robusten pri boju proti napakam, nagnjenim k OCR, saj pridobi CRR 87,01% iz izhoda OCR s CRR 35,76% za eno od nastavitev nabora podatkov. Raziskava človeške presoje na modelih kaže, da je naš predlagani model rezultat napovedi, ki so hitreje razumljive in hitreje izboljšane za človeka kot ostali sistemi.', 'ha': "Tuna goyyar da wata matsayin hagarin matsayin bayan OCR wa littãfin digitising cikin Sanscrit wanda aka rubũta. Dukan da bã da mataimaki na hanyarmu, misãlai na amfani da OCR wanda aka sanar da wa harshen wasu harshe na Rome. Aka yanzu, ba da wani tsari na zaluman aiki wanda aka iya samar da shi na SanScript OCR. Kayya, za'a sami tsarin zanen mutane 430, an yi kiyaye cikin tsari biyu ko da gaskiyar ƙasa da ke daidaita. Ga kõre, za'a sami zanen tsari dukansu. Tuna gane cewa amfani da amfani da nakasarsa na kofi (Gu et al., 2016) yana ƙara wani fomat na ƙari cikin Rarranin Bayanci na Character 7.69 (CRR) ko da halin sanar da ke kai yanzu cikin masu yin rabo ga aikin monotone-sequence-to-sequence (Schnober et al., 2016). Tuna gane cewa tsarin mu an yi karo zuwa yãƙi ga makorari na OCR, kamar yana sami wata CRR ya kasa 87.01% daga gabatar OCR da CRR na 35.76% wa ɗayan daidaita maɓallin database. A human judgement survey performed on the models shows that our proposed model results in predictions which are faster to comprehend and faster to improve for a human than the other systems.", 'he': 'אנחנו מציעים גישה לתיקון טקסט לאחר OCR עבור דיגיטציה טקסטים בסנסקריט רומניזם. Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman.  כרגע, אין קבוצת נתונים זמינה עבור OCR סנסקריט רומניזם. אז, אנו מעבירים קבוצת נתונים של 430 תמונות, סורקים בשני מסדרים שונים ואמת הקרקע המתאימה שלהם. לאימון, אנו מייצרים תמונות אימונים באופן סינטטי לשני ההגדרות. אנו מוצאים שהשימוש במנגנון העתק (Gu et al., 2016) מוביל עלייה אחוזית של 7.69 בקצב זיהוי אופיינים (CRR) מאשר המצב הנוכחי של המודל האמנותי בפתרון משימות רצף-לרצף מונוטון (Schnober et al., 2016). אנו מוצאים שהמערכת שלנו חזקה בלהילחם בשגיאות שנושאות לאוקר, כיוון שהיא מקבלת CRR של 87.01% מהיציאה של OCR עם CRR של 35.76% לאחד מהסדרות של קבוצת הנתונים. סקר שיפוט אנושי שעשה על הדוגמנים מראה שהדוגמנית המוצעת שלנו תוצאות בחזויות שהן מהירות יותר להבין ומהירות יותר לשפר עבור אדם מהמערכות האחרות.', 'bo': 'ང་ཚོས་རོལ་མ་ཡིག་གི་Sanskrit ནང་ཡི་གེ་རྩིས་ཅན་བཟོ་བྱེད་པའི་ཡིག་གེ་ལུས་འགྱུར་བ་ཞིག་བཤད་ཀྱི་ཡོད། ང་ཚོའི་ཐབས་ལམ་ལུགས་བྱས་མེད་པའི་རྒྱུ་ཆས་ཀྱི་དམིགས་བསལ་ནི་རྣམ་གྲངས་ཀྱི་སྣང་ཚུལ་གྱི་རྣམ་པ་ལྟར་སྤྱོད་ ད་ལྟའི་ནང་དུ་རོམ་མིའི་སྒྲིག་འཛུགས་ཀྱི་ཆ་འཕྲིན་ཡིག་ཆ་སྒྲིག་འཇུག་བྱས་མི་འདུག བྱས་ན་ང་ཚོས་430གཟུགས་རིས་ཀྱི་སྒྲིག་སྟངས་འདི་གཉིས་ལས་སྒྲིག་འགོད་བྱས་པ་དང་ཁོང་ཚོའི་མཐུན་སྒྲིག་དངོས་ཡོད འདྲ་སྒྲིག་ཐད་ནས་བཟོ་བྱེད་པར་ང་ཚོས་སྒྲིག་འཛུགས་གཉིས་ལས་གཟུགས་རིས་ལ་བཟོ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་འདྲ་བཤུས་ཀྱི་གནས་སྟངས་ལ་བྱ་བ་སྤྱོད་བཞིན་ཡོད། We find that our system is robust in combating OCR-prone errors, as it obtains a CRR of 87.01% from an OCR output with CRR of 35.76% for one of the dataset settings. མིག'}
{'en': 'Lessons Learned in Multilingual Grounded Language Learning', 'pt': 'Lições Aprendidas em Aprendizagem Multilíngue de Línguas Fundamentadas', 'ar': 'الدروس المستفادة في تعلم اللغة متعدد اللغات', 'fr': "Leçons apprises dans l'apprentissage multilingue des langues fondées", 'es': 'Lecciones aprendidas en el aprendizaje multilingüe de idiomas', 'ja': '多言語基盤型言語学習で学んだ教訓', 'zh': '多言本语学经验', 'hi': 'बहुभाषी आधारित भाषा सीखने में सीखे गए सबक', 'ru': 'Уроки, извлеченные из изучения многоязычного языка', 'ga': 'Ceachtanna Foghlamtha i bhFoghlaim Teanga Ilteangacha Bhunaithe', 'ka': 'Multilingual Ground Language Learning', 'hu': 'A többnyelvű alapozott nyelvtanulás során elsajátított leckék', 'el': 'Μαθήματα που μαθαίνονται στην πολύγλωσση επίγεια εκμάθηση γλωσσών', 'it': "Lezioni apprese nell'apprendimento multilingue fondato", 'kk': 'Көптеген тіл оқу үшін оқылған сыныптар', 'ml': 'Lessons Learned in Multilingual Grounded Language Learning', 'ms': 'Pelajaran Dibelajar dalam Belajar Bahasa Berbahasa', 'lt': 'Mokymasis daugiakalbėmis pagrįsta kalba', 'mn': 'Олон хэлний сургалтын суралцах хичээл', 'mk': 'Учења научени на мултијазички основан јазик', 'mt': 'Tagħlim Tagħlim f’Tagħlim Multilingwi ta’ Lingwa Mhux Armonizzat', 'no': 'Leksjonar lært i fleirspråksprøver', 'pl': 'Lekcje uczone w wielojęzycznej nauce języków uziemionych', 'si': 'ගොඩක් භාෂාවක් භාෂාවක් ඉගෙනගන්න ඉගෙනගන්න', 'ro': 'Lecții învățate în învățarea limbilor străine multilingve bazate', 'so': 'Waxbarashada afka luuqadaha la dhigay', 'sv': 'Lärdomar i flerspråkigt grundat språkinlärning', 'ta': 'பல மொழி மொழியில் கற்றுக் கொண்டுள்ள படிப்புகள்', 'sr': 'Lekcije naučene u multijezičkom učenju jezika', 'ur': 'Multilingual Grounded Language Learning میں سکھائی جاتی ہے', 'uz': 'Lessons Learned in Multilingual Grounded Language Learning', 'vi': 'Bài học về đa ngôn ngữ học', 'bg': 'Научени уроци по многоезично базирано езиково обучение', 'hr': 'Lekcije naučene u multijezičkom učenju jezika', 'da': 'Lektioner i flersproget grundlagt sproglæring', 'nl': 'Lessen geleerd in meertalig gegrond taalleren', 'de': 'Lektionen im mehrsprachigen Grounded Language Learning', 'id': 'Pelajaran Dipelajari dalam Bahasa Berbahasa', 'ko': '다언어 기초 언어 학습의 경험과 교훈', 'sw': 'Mafunzo yaliyofundishwa kwa lugha mbalimbali', 'fa': 'درس\u200cهایی که در یادگیری زبان\u200cهای زیادی یاد گرفته\u200cاند', 'tr': 'Çoklu dilli ýeterli diller öwrenmek üçin öwrenmeli ders', 'hy': 'Բազլեզու հիմնված լեզու սովորելը սովորված դասերը', 'af': 'Lessons geleer in Multilingual Grounded Language Learning', 'sq': 'Mësimet e mësuara në Mësimin e Gjuhave Mëshirues', 'am': 'ቋንቋዎች ተማሩ', 'bn': 'বহুভাষী ভাষায় শিক্ষিত ভাষা শিক্ষা', 'bs': 'Lekcije naučene u multijezičkom učenju jezika', 'ca': 'Ensenys aprenguts en aprenentatge multilingüe de llenguatges fundamentats', 'cs': 'Lekce učené ve vícejazyčném uzavřeném jazykovém učení', 'az': '칂oxlu dil 칬yr톛nm톛sind톛 칬yr톛n톛n S캼n캼f', 'fi': 'Monikielisessä pohjautuvassa kieltenoppimisessa opitut oppitunnit', 'et': 'Mitmekeelse põhjaliku keeleõppe õppetunnid', 'jv': 'Lisanjur layang-layang lan bangkat Pamira', 'he': 'הלימודים ללמוד שפות רבות שפות', 'ha': 'KCharselect unicode block name', 'bo': 'སྐད་རིགས་ཀྱི་སྨྱུག་ཚད་མང་ཆེ་ཤོས་ཅན་གྱི་སྐད་རིགས་ཤེས་ཀྱི་ནང་དུ་བསླབས་བྱུང་།', 'sk': 'Učenje večjezičnega jezikovnega učenja'}
{'en': 'Recent work has shown how to learn better visual-semantic embeddings by leveraging image descriptions in more than one language. Here, we investigate in detail which conditions affect the performance of this type of grounded language learning model. We show that multilingual training improves over bilingual training, and that low-resource languages benefit from training with higher-resource languages. We demonstrate that a multilingual model can be trained equally well on either translations or comparable sentence pairs, and that annotating the same set of images in multiple language enables further improvements via an additional caption-caption ranking objective.', 'ar': 'أظهر العمل الأخير كيفية تعلم الزخارف المرئية الدلالية بشكل أفضل من خلال الاستفادة من أوصاف الصور بأكثر من لغة واحدة. هنا ، نتحرى بالتفصيل الشروط التي تؤثر على أداء هذا النوع من نموذج تعلم اللغة القائم على أسس. نظهر أن التدريب متعدد اللغات يتحسن أكثر من التدريب ثنائي اللغة ، وأن اللغات منخفضة الموارد تستفيد من التدريب على اللغات عالية الموارد. نبرهن على أنه يمكن تدريب نموذج متعدد اللغات جيدًا على قدم المساواة سواء على الترجمات أو أزواج الجمل القابلة للمقارنة ، وأن التعليق التوضيحي على نفس مجموعة الصور بلغات متعددة يتيح مزيدًا من التحسينات من خلال هدف تصنيف التسمية التوضيحية الإضافي.', 'pt': 'Trabalhos recentes mostraram como aprender melhores incorporações visual-semânticas, aproveitando as descrições de imagens em mais de um idioma. Aqui, investigamos em detalhes quais condições afetam o desempenho desse tipo de modelo de aprendizagem de línguas fundamentado. Mostramos que o treinamento multilíngue melhora em relação ao treinamento bilíngue e que os idiomas com poucos recursos se beneficiam do treinamento com idiomas com recursos mais altos. Demonstramos que um modelo multilíngue pode ser treinado igualmente bem em traduções ou pares de frases comparáveis, e que anotar o mesmo conjunto de imagens em vários idiomas permite melhorias adicionais por meio de um objetivo de classificação legenda-legenda adicional.', 'es': 'Un trabajo reciente ha demostrado cómo aprender mejores incrustaciones visual-semánticas aprovechando las descripciones de imágenes en más de un idioma. Aquí, investigamos en detalle qué condiciones afectan al rendimiento de este tipo de modelo de aprendizaje de idiomas basado en la base. Demostramos que la capacitación multilingüe mejora con respecto a la bilingüe, y que los idiomas de bajos recursos se benefician de la capacitación con idiomas de recursos más altos. Demostramos que un modelo multilingüe se puede entrenar igual de bien en traducciones o pares de oraciones comparables, y que anotar el mismo conjunto de imágenes en varios idiomas permite mejoras adicionales mediante un objetivo adicional de clasificación de subtítulos y subtítulos.', 'fr': "Des travaux récents ont montré comment apprendre de meilleures intégrations sémantiques visuelles en exploitant les descriptions d'images dans plusieurs langues. Nous étudions ici en détail les conditions qui affectent les performances de ce type de modèle d'apprentissage linguistique ancré. Nous montrons que la formation multilingue s'améliore par rapport à la formation bilingue et que les langues à faibles ressources bénéficient d'une formation avec des langues à ressources plus élevées. Nous démontrons qu'un modèle multilingue peut être entraîné aussi bien sur des traductions que sur des paires de phrases comparables, et que l'annotation du même ensemble d'images dans plusieurs langues permet d'autres améliorations via un objectif supplémentaire de classement légende-légende.", 'ja': '最近の研究では、複数の言語の画像記述を活用して、視覚的-セマンティックな埋め込みをより良く学ぶ方法が示されています。ここでは，どのような条件がこの種の基礎言語学習モデルのパフォーマンスに影響を与えるかを詳細に調査する．多言語トレーニングはバイリンガルトレーニングよりも改善され、低資源言語はより高い資源言語を使用したトレーニングの恩恵を受けることが示されています。私たちは、多言語モデルが翻訳または同等の文章ペアのいずれかで同等に訓練されることができ、複数の言語で同じセットの画像に注釈を付けることで、追加のキャプションキャプションランキング目標を介してさらなる改善を可能にすることを実証します。', 'zh': '近事展多种语言图,以学善视语义嵌。 于此详究接地气之言。 吾言多言培训改于双语培训,且低资源言受益于高言之培训。 余证多言模可于译类句对上同好,并以多种语言注同组图像可因额外标题 - 标题排名更进。', 'ru': 'Недавние работы показали, как лучше изучить визуально-семантические вставки, используя описания изображений более чем на одном языке. Здесь мы подробно исследуем, какие условия влияют на производительность этого типа модели изучения языка. Мы показываем, что многоязычная подготовка улучшается по сравнению с двуязычной подготовкой и что языки с низким уровнем ресурсов выигрывают от обучения языкам с более высоким уровнем ресурсов. Мы демонстрируем, что многоязычная модель может быть одинаково хорошо обучена переводам или сопоставимым парам предложений, и что аннотирование одного и того же набора изображений на нескольких языках обеспечивает дальнейшие улучшения с помощью дополнительной цели ранжирования подписей.', 'hi': 'हाल के काम ने दिखाया है कि एक से अधिक भाषाओं में छवि विवरण का लाभ उठाकर बेहतर दृश्य-शब्दार्थ एम्बेडिंग कैसे सीखें। यहां, हम विस्तार से जांच करते हैं कि कौन सी स्थितियां इस प्रकार के ग्राउंडेड भाषा सीखने के मॉडल के प्रदर्शन को प्रभावित करती हैं। हम दिखाते हैं कि बहुभाषी प्रशिक्षण द्विभाषी प्रशिक्षण पर सुधार करता है, और यह कि कम-संसाधन भाषाओं को उच्च-संसाधन भाषाओं के साथ प्रशिक्षण से लाभ होता है। हम प्रदर्शित करते हैं कि एक बहुभाषी मॉडल को या तो अनुवाद या तुलनीय वाक्य जोड़े पर समान रूप से अच्छी तरह से प्रशिक्षित किया जा सकता है, और यह कि एकाधिक भाषा में छवियों के एक ही सेट को एनोटेट करना एक अतिरिक्त कैप्शन-कैप्शन रैंकिंग उद्देश्य के माध्यम से आगे के सुधार को सक्षम बनाता है।', 'ga': 'Léiríodh in obair a rinneadh le déanaí conas leabaithe amhairc-shéimeantacha níos fearr a fhoghlaim trí chur síos ar íomhánna a ghiaráil i níos mó ná teanga amháin. Anseo, déanaimid imscrúdú mion ar na coinníollacha a théann i bhfeidhm ar fheidhmíocht an chineáil seo de shamhail bhunaithe foghlama teanga. Léirímid go dtagann feabhas ar oiliúint ilteangach thar oiliúint dhátheangach, agus go mbaineann teangacha íseal-acmhainne leas as oiliúint le teangacha ard-acmhainne. Léirímid gur féidir múnla ilteangach a thraenáil chomh maith céanna ar aistriúcháin nó ar phéirí abairtí inchomparáide, agus go bhféadfar tuilleadh feabhsuithe a dhéanamh trí an tsraith chéanna d’íomhánna i dteanga iolracha a anótáil trí chuspóir breise rangaithe fortheideal.', 'el': 'Πρόσφατες εργασίες έχουν δείξει πώς μπορείτε να μάθετε καλύτερες οπτικές-σημασιολογικές ενσωματώσεις χρησιμοποιώντας περιγραφές εικόνων σε περισσότερες από μία γλώσσες. Εδώ, διερευνούμε λεπτομερώς ποιες συνθήκες επηρεάζουν την απόδοση αυτού του τύπου της γειωμένης εκμάθησης γλωσσών. Αποδεικνύουμε ότι η πολύγλωσση κατάρτιση βελτιώνεται σε σχέση με τη δίγλωσση κατάρτιση και ότι οι γλώσσες χαμηλού πόρου επωφελούνται από την κατάρτιση με γλώσσες υψηλότερων πόρων. Αποδεικνύουμε ότι ένα πολύγλωσσο μοντέλο μπορεί να εκπαιδευτεί εξίσου καλά είτε σε μεταφράσεις είτε σε συγκρίσιμα ζεύγη προτάσεων, και ότι η παρατήρηση του ίδιου συνόλου εικόνων σε πολλαπλές γλώσσες επιτρέπει περαιτέρω βελτιώσεις μέσω ενός πρόσθετου στόχου ταξινόμησης λεζάντας-λεζάντας.', 'hu': 'A legutóbbi munkák megmutatták, hogyan lehet jobb vizuális-szemantikai beágyazásokat tanulni egynél több nyelven történő felhasználásával. Itt részletesen megvizsgáljuk, hogy milyen körülmények befolyásolják az ilyen típusú alapozott nyelvtanulási modell teljesítményét. Megmutatjuk, hogy a többnyelvű képzés javul a kétnyelvű képzéssel szemben, és hogy az alacsony erőforrásokkal rendelkező nyelvek profitálnak a magasabb erőforrásokkal rendelkező nyelveken végzett képzésből. Bemutatjuk, hogy egy többnyelvű modell akár fordításokra, akár hasonló mondatpárokra egyaránt jól képzett, és hogy ugyanazon képek többnyelvű jegyzetelése további fejlesztéseket tesz lehetővé egy további felirat-felirat rangsorolási célkitűzés révén.', 'ka': 'მიმდინარე სამუშაო მუშაო დააჩვენება როგორ უკეთესი ვიზუალურ- სმენტიკური ინბიზნეციების შესახებ გამოსახულების გამოსახულების გამოსახულება აქ, ჩვენ განსაკუთრებით განსაკუთრებით, რომლებიც შესახებ ამ ფონტური ენის სწავლების მოდელის შესახებ. ჩვენ ჩვენ აჩვენებთ, რომ მრავალენგური განსწავლება ორიენგური განსწავლების შემდეგ უფრო მეტად მეტად მეტად მეტად მეტად მეტად მეტად მეტად მეტად ჩვენ გამოჩვენებთ, რომ მრავალენგური მოდელი შეიძლება იგივე სწორად გარგება თუ გარგება ან შემდგომარებელი წიგნის ზოგი, და რომელიც გამოჩვენება იგივე სწორედ გამოსახულებების მრავალ ენაში უფრო', 'it': 'Recenti lavori hanno dimostrato come imparare meglio le incorporazioni visual-semantic sfruttando le descrizioni delle immagini in più di una lingua. Qui, esaminiamo in dettaglio quali condizioni influenzano le prestazioni di questo tipo di modello di apprendimento basato delle lingue. Dimostriamo che la formazione multilingue migliora rispetto alla formazione bilingue e che le lingue a basso contenuto di risorse traggono vantaggio dalla formazione con lingue ad alto contenuto di risorse. Dimostriamo che un modello multilingue può essere addestrato altrettanto bene sia sulle traduzioni che sulle coppie di frasi comparabili, e che annotare lo stesso set di immagini in più lingue consente ulteriori miglioramenti attraverso un ulteriore obiettivo di classificazione didascalia-didascalia.', 'kk': 'Жуырдағы жұмыс бірнеше тілде кескінді сипаттамасын көмектесу арқылы визуалдық- семантикалық ендіруді қалай оқытуды көрсетеді. Мұнда, біз бұл түрлі тіл оқыту үлгісінің қандай жағдайларына әсер ететін егжей- тегжейін зерттеп көрдік. Біз көптеген тілдердің оқытуы екі тілдердің оқытуынан жақсы және көп ресурстар тілдерінің көптеген оқытуынан шығар деп көрсетедік. Біз көптілік үлгісін бірнеше түрлендіру не салыстыруға мүмкіндік беруге болады деп көрсетедік. Бірнеше тілде бірнеше кескіндердің жинағын белгілеу қосымша айдарлық айдарлау жолдары арқылы қосымша жақсарт', 'ml': 'അടുത്ത പ്രവര്\u200dത്തിക്കുന്നത് ഒരു ഭാഷയില്\u200d കൂടുതല്\u200d ചിത്ര വിശദീകരണങ്ങള്\u200d ഉപയോഗിക്കുന്നത് എങ്ങനെയാണെന്ന് കാണിച്ചിരി Here, we investigate in detail which conditions affect the performance of this type of grounded language learning model.  നമ്മള്\u200d കാണിക്കുന്നു പല ഭാഷ പരിശീലനം രണ്ടു ഭാഷ പരിശീലനത്തിനെക്കാളും മെച്ചപ്പെടുത്തുന്നു. അതില്\u200d നിന്നും കൂടുതല്\u200d  പല ഭാഷയിലുള്ള ഒരു മോഡല്\u200d പരിശീലിപ്പിക്കാന്\u200d സാധിക്കുന്നത് ഒന്നുമില്ലെങ്കില്\u200d പരിശീലിപ്പിക്കാന്\u200d സാധിക്കുന്നതാണെന്ന് നമ്മള്\u200d കാണിക്കുന്നു. അത് പല', 'lt': 'Neseniai atliktas darbas parodė, kaip geriau mokytis vizualinių ir semantinių įdėjimų naudojant vaizdo aprašymus daugiau kaip viena kalba. Čia išsamiai tiriame, kokios sąlygos turi įtakos tokio tipo pagrįsto kalbų mokymosi modelio veiksmingumui. Mes rodome, kad daugiakalbis mokymas geresnis nei dvikalbis mokymas, o mažai išteklių turinčios kalbos gauna naudos iš mokymo aukštesniais ištekliais turinčiomis kalbomis. Mes įrodome, kad daugiakalbis modelis gali būti taip pat gerai mokomas vertimuose arba palyginamose sakinių porose ir kad to paties vaizdo rinkinio annotavimas daugiakalbėmis leidžia toliau tobulinti taikant papildomą antraštinės dalies klasifikavimo tikslą.', 'pl': 'Ostatnie prace pokazały, jak nauczyć się lepszych osadzeń wizualno-semantycznych poprzez wykorzystanie opisów obrazów w więcej niż jednym języku. Tutaj szczegółowo badamy, jakie warunki wpływają na wydajność tego typu uziemionego modelu nauki języków. Pokazujemy, że szkolenia wielojęzyczne poprawiają się w porównaniu z szkoleniami dwujęzycznymi, a języki o niskich zasobach korzystają z szkolenia z językami o wyższym zasobie. Pokazujemy, że wielojęzyczny model może być równie dobrze trenowany zarówno na tłumaczeniach, jak i porównywalnych parach zdań, a adnotacja tego samego zestawu obrazów w wielu językach umożliwia dalsze ulepszenia poprzez dodatkowy cel rankingu napisów-napisów.', 'ro': 'Lucrările recente au arătat cum să învățați încorporări vizual-semantice mai bune prin utilizarea descrierilor imaginilor în mai multe limbi. Aici, investigăm în detaliu ce condiții afectează performanța acestui tip de model de învățare bazată a limbilor străine. Noi arătăm că formarea multilingvă se îmbunătățește față de formarea bilingvă și că limbile cu resurse reduse beneficiază de formarea cu limbi cu resurse superioare. Demonstrăm că un model multilingv poate fi instruit la fel de bine cu privire la traduceri sau perechi de propoziții comparabile și că adnotarea aceluiași set de imagini în mai multe limbi permite îmbunătățiri suplimentare printr-un obiectiv suplimentar de clasificare a subtitrării-subtitrării.', 'mn': 'Саяхан ажил нэгээс илүү олон хэл дээр зураг тайлбарлахад хэрхэн илүү сайхан харагдаж байгааг харуулсан. Энд бид энэ төрлийн үндсэн хэл суралцах загварын үр дүнд нөлөөлдөг нөхцөлийг нарийвчлан судалж байна. Бид олон хэл суралцах нь хоёр хэл суралцах дасгал дээр улам хөгжүүлдэг ба бага боловсролын хэл нь өндөр боловсролын хэл дээр суралцах хэрэгтэй. Бид олон хэл загварын загварыг илүү сайн хөгжүүлж чадна гэдгийг харуулж байна. Энэ нь олон хэл дээр адилхан зурагтай хэлбэрээр илүү сайн хөгжүүлж чадна.', 'no': 'Nyleg har arbeidet vist korleis å lære betre visualsemantiske innbygging ved å levera biletskrifter i meir enn eitt språk. Her undersøker vi i detalj kva vilkår påvirkar utviklinga av denne typen bakgrunnsfarge språk-læringsmodellen. Vi viser at fleirspråk opplæring forbetrar over bilingspråk opplæring, og at låg ressursspråk nyttar frå opplæring med høgare ressursspråk. Vi viser at ein fleirspråk modell kan trenjast like godt på anten omsetjingar eller sammenlignbar setningar, og at merkinga av samme sett av bilete i fleirspråk kan gjere fleire forbetringar gjennom ein ekstra tittel-tittel-ranking mål.', 'sv': 'Det senaste arbetet har visat hur man lär sig bättre visuell-semantisk inbäddning genom att utnyttja bildbeskrivningar på mer än ett språk. Här undersöker vi i detalj vilka förutsättningar som påverkar prestandan av denna typ av grundad språkinlärningsmodell. Vi visar att flerspråkig utbildning förbättras jämfört med tvåspråkig utbildning och att lågresursspråk gynnas av utbildning med språk med högre resurs. Vi visar att en flerspråkig modell kan tränas lika bra på antingen översättningar eller jämförbara meningspar, och att kommentering av samma uppsättning bilder på flera språk möjliggör ytterligare förbättringar via ett ytterligare mål för bildtext-bildtext ranking.', 'si': 'පින්තූර විස්තරණය එකට වඩා වඩා භාෂාවක් වලින් පින්තූර විස්තරණය සඳහා හොඳ විස්තර- සෙමැන්ටික් සංවේ මෙතන, අපි පරීක්ෂණය කරන්නේ විස්තරයෙන් මේ වර්ගයේ භාෂාව ඉගෙන ගන්න ප්\u200dරශ්නයක් තියෙන්නේ කියලා. අපි පෙන්වන්නේ බොහොම භාෂාවක් ප්\u200dරශ්නයක් දෙකක් භාෂාවක් ප්\u200dරශ්නයක් වැඩියි, ඒ වගේම අඩුම භාෂාව අපි ප්\u200dරකාශ කරනවා විශාල භාෂාවක් මොඩල් එකක් සාමාන්\u200dය විදියට පුළුවන් වෙන්න පුළුවන් කියලා, වාර්තාවක් නැත්නම් සමාන්\u200dය වාර්තාවක් නැත', 'mt': 'Xogħol reċenti wera kif jitgħallmu inkorporazzjonijiet viżwali-semantiċi aħjar billi jiġu sfruttati d-deskrizzjonijiet tal-immaġni f’aktar minn lingwa waħda. Hawnhekk, ninvestigaw fid-dettall liema kundizzjonijiet jaffettwaw il-prestazzjoni ta’ dan it-tip ta’ mudell ta’ tagħlim tal-lingwi bbażat. Aħna nuru li t-taħriġ multilingwi jtejjeb fuq it-taħriġ bilingwi, u li l-lingwi b’riżorsi baxxi jibbenefikaw mit-taħriġ b’lingwi b’riżorsi ogħla. Aħna nuru li mudell multilingwi jista’ jitħarreġ bl-istess mod tajjeb jew fuq traduzzjonijiet jew pari ta’ sentenzi komparabbli, u li l-annotazzjoni tal-istess sett ta’ immaġni f’lingwa multipla tippermetti aktar titjib permezz ta’ objettiv addizzjonali ta’ klassifikazzjoni tal-intestatura-intestatura.', 'ms': 'Kerja baru-baru ini telah menunjukkan bagaimana untuk belajar penyambungan visual-semantik yang lebih baik dengan menggunakan deskripsi imej dalam lebih dari satu bahasa. Di sini, kita menyelidiki secara terperinci keadaan yang mempengaruhi prestasi jenis ini model pembelajaran bahasa. Kami menunjukkan bahawa latihan berbilang bahasa meningkat melalui latihan dua bahasa, dan bahasa sumber rendah berguna dari latihan dengan bahasa sumber yang lebih tinggi. Kami menunjukkan bahawa model berbilang bahasa boleh dilatih dengan baik sama ada dalam terjemahan atau pasangan kalimat yang boleh dibandingkan, dan bahawa anotasi set imej yang sama dalam bahasa berbilang memungkinkan peningkatan lanjut melalui objektif peringkat tajuk-tajuk tambahan.', 'mk': 'Неодамнешната работа покажа како да се научи подобро визуелно-семантично вградување со користење на описите на слики на повеќе од еден јазик. Овде, детално истражуваме кои услови влијаат врз изведувањето на овој тип на модел за учење на јазик. Покажуваме дека мултијазичната обука се подобрува преку двојјазичната обука и дека јазиците со ниски ресурси имаат корист од обуката со јазици со повисоки ресурси. We demonstrate that a multilingual model can be trained equally well on either translations or comparable sentence pairs, and that annotating the same set of images in multiple language enables further improvements via an additional caption-caption ranking objective.', 'sr': 'Skorašnji rad pokazuje kako naučiti bolje vizualne semantičke integracije uključivanjem opisa slika na više od jednog jezika. Ovde istražujemo detaljno koje uvjete utiču na provedbu ovakvog modela osnovnog jezika. Pokazujemo da se multijezička obuka poboljšava preko dvojezičke obuke i da jezici niskih resursa koriste od obuke sa višim jezicima resursa. Pokazujemo da se multijezički model može obučiti jednako dobro na prevodu ili usporedbljivim parovima rečenica, i da navodimo istu skupinu slika na višestrukom jeziku omogućava dodatno poboljšanje putem dodatnog cilja imenovanja navođenja.', 'so': 'Shaqoda la soo dhowaaday waxey muuqatay sida aad u barto wax ka wanaagsan oo arag-iyo-semantic ah, sida loo soo diro qoraalka sawirka oo lagu qoro luuqad ka badan. Halkan, waxaynu ka baaraynaa sharciga ay saameyn ku yeelan karaan tusaale ahaan barashada luqada aasaaska ah. Waxaynu muujinnaa in waxbarashada luuqadaha kala duduwan uu horumariyo waxbarashada labada luqadood, luuqadaha hoose ee rasmiguna waxey ka faa’iido badan yihiin waxbarashada luuqadaha sare. Waxaynu muujinnaa in Tusaale luuqado kala duduwan si isku mid ah looga baran karo turjumaadda ama labo isku mid ah, isla markaasna in la dhibaateeyo sawirro isku mid ah oo luuqado kala duduwan, waxay ku socon karaan hagaajinta kororsashada kordhiska kordhiska kordhiska loogu talagalay goal dheeraad ah.', 'ta': 'சமீபத்தில் வேலை ஒரு மொழிக்கு மேற்பட்ட பிம்பத்தின் விளக்கங்களை வழங்கும் மூலம் எப்படி சிறந்த பார்வையான- பெம்பென இங்கு, நாம் விவரமாக எந்த நிபந்தனைகள் இந்த வகையான மொழி கற்றல் மாதிரியின் செயல்பாட்டை பாதிக்கும். நாம் காண்பிக்கிறோம் பல மொழி பயிற்சி இரு மொழி பயிற்சியை மேம்படுத்துகிறது, மற்றும் அதிக மூலத்தின் மொழிகள் பயிற்ச பல மொழி மாதிரி மாதிரி மொழிபெயர்ப்பு அல்லது ஒப்பிடும் வாக்கு ஜோடியை சரியாக பயிற்சிக்க முடியும் என்பதை நாம் குறிப்பிடுகிறோம். அது பல மொழிகளில் அதே அமைப', 'ur': 'اچھے کام نے دکھایا ہے کہ کس طرح بہتر visual-semantic embedding سکھائے جائیں، ایک زبان سے زیادہ زیادہ تصویر کی توصیف کے ذریعہ۔ یہاں، ہم تفصیل میں تحقیق کر رہے ہیں کہ کس شرایطوں نے اس طرح کی زبان سکھانے کی مدل پر اثر رکھی ہے. ہم دکھاتے ہیں کہ بہت سی زبان کی تعلیم دو زبان کی تعلیم پر بہتر ہوتی ہے اور یہ کم سرمایہ کی زبانیں بالا سرمایہ کی زبانوں سے استعمال کرتی ہیں۔ ہم دکھاتے ہیں کہ ایک بہت سی زبان موڈل برابر تعلیم کی جاتی ہے یا ترجمہ یا برابر جوڑوں پر، اور یہ ہے کہ بہت سی زبانوں میں ایسی تصاویروں کا ایک مجموعہ دکھاتے ہیں اور ایک اضافہ کپٹ-کپٹ رنگ موضوع کے ذریعے اضافہ کی ترجمہ کرتی ہے.', 'uz': "Yaqinda ishni bir tildan ortiq rasm taʼriflarini qoʻllash uchun yaxshi ko'rinishni o'rganishni ko'rsatadi. Bu yerda, biz qanday holat o'rganish modelini o'zgartiradi. Biz ko'pchilik tili o'rganishni ikkita tillar o'rganishga bajarishimizni ko'rsatdik, va kamaytan rasm tillari eng yuqori rasmlar tilida o'rganishdan foydalanadi. Biz ko'p tillar modeli bir xil tarjima qilish yoki bir xil so'zlar uchun o'rganish mumkin, va bir necha tillarda bitta rasmlarni taʼminlovchi bo'lishi mumkin va bir necha tilda bir necha rasmlarning bir tarjima sarlavhasini ko'proq obʼekt orqali oshirish imkoniyatini oshirish mumkin.", 'vi': 'Công việc gần đây đã cho thấy làm thế nào để học sự gắn kết hình ảnh tốt hơn? Ở đây, chúng tôi tìm hiểu chi tiết những điều kiện có thể ảnh hưởng đến hiệu quả của loại mô hình học ngôn ngữ ngữ được dạy. Chúng tôi cho thấy việc đào tạo đa dạng cải thiện đào tạo hai chiều, và những ngôn ngữ ít tài nguyên được hưởng từ việc đào tạo các ngôn ngữ cao cấp. Chúng tôi chứng minh rằng một mô hình ngôn ngữ đa dạng có thể được huấn luyện tương đối tốt về một bản dịch hoặc một cặp câu tương tự, và việc ghi chú cùng một bộ ảnh bằng nhiều ngôn ngữ cho phép cải tiến thêm bằng một mục tiêu có hàm phụ.', 'bg': 'Последната работа показа как да научите по-добри визуално-семантични вграждания чрез използване на описания на изображения на повече от един език. Тук изследваме подробно кои условия влияят върху изпълнението на този тип базиран модел на езиково обучение. Показваме, че многоезичното обучение се подобрява в сравнение с двуезичното обучение и че езиците с нисък ресурс се възползват от обучението с езици с по-висок ресурс. Ние демонстрираме, че многоезичен модел може да бъде обучен еднакво добре за преводи или сравними двойки изречения и че анотирането на един и същ набор от изображения на няколко езика позволява допълнителни подобрения чрез допълнителна цел за класиране на надпис-надпис.', 'da': 'Seneste arbejde har vist, hvordan man lærer bedre visuel-semantiske indlejringer ved at udnytte billedbeskrivelser på mere end ét sprog. Her undersøger vi detaljeret, hvilke forhold der påvirker præstationen af denne type grundlagt sproglæringsmodel. Vi viser, at flersproget uddannelse forbedres i forhold til tosproget uddannelse, og at sprog med lav ressource drager fordel af uddannelse med sprog med højere ressourcer. Vi demonstrerer, at en flersproget model kan trænes lige så godt i enten oversættelser eller sammenlignelige sætningspar, og at anmærkning af det samme sæt billeder på flere sprog muliggør yderligere forbedringer via et ekstra billedtekst-billedtekst rangeringsmål.', 'nl': 'Recent werk heeft aangetoond hoe je betere visueel-semantische embeddings kunt leren door beeldbeschrijvingen in meer dan één taal te gebruiken. Hier onderzoeken we in detail welke voorwaarden van invloed zijn op de prestaties van dit type geaard taalleermodel. We laten zien dat meertalige training verbetert ten opzichte van tweetalige training, en dat low-resource talen baat hebben bij training met hogere resources talen. We tonen aan dat een meertalig model even goed getraind kan worden op vertalingen of vergelijkbare zinsparen, en dat het annoteren van dezelfde set afbeeldingen in meerdere talen verdere verbeteringen mogelijk maakt via een extra titel-titel ranking doelstelling.', 'hr': 'Skorašnji rad pokazuje kako naučiti bolje vizualno-semantičke ugrađenje s primjenom opisa slika na više od jednog jezika. Ovdje istražujemo detaljno koje uvjete utječu na provedbu ovakvog tipa temeljnog modela učenja jezika. Pokazujemo da se multijezička obuka poboljšava preko dvojezičke obuke i da jezici niskih resursa koriste od obuke sa višim jezicima resursa. Pokazujemo da se multijezički model može obučavati jednako dobro na ili prevoditeljima ili usporedbenim parovima rečenica, te da navodimo istu skupu slika na višestrukom jeziku omogućava daljnje poboljšanje putem dodatnog cilja postavljanja navedenja.', 'id': 'Pekerjaan baru-baru ini menunjukkan bagaimana untuk belajar lebih baik penerbangan visual-semantis dengan menggunakan deskripsi gambar dalam lebih dari satu bahasa. Di sini, kami menyelidiki secara rinci kondisi yang mempengaruhi prestasi dari tipe ini model belajar bahasa berdasarkan dasar. Kami menunjukkan bahwa pelatihan multibahasa meningkat melalui pelatihan dua bahasa, dan bahasa sumber daya rendah berguna dari pelatihan dengan bahasa sumber daya yang lebih tinggi. Kami menunjukkan bahwa model berbagai bahasa dapat dilatih dengan baik baik pada baik terjemahan atau pasangan kalimat yang dapat dibandingkan, dan bahwa anotasi set gambar yang sama dalam berbagai bahasa memungkinkan perkembangan lanjut melalui tujuan peringkat caption-caption tambahan.', 'de': 'Neuere Arbeiten haben gezeigt, wie man bessere visuell-semantische Einbettungen lernt, indem man Bildbeschreibungen in mehr als einer Sprache nutzt. Hier untersuchen wir im Detail, welche Bedingungen die Leistungsfähigkeit dieser Art des geerdeten Sprachlernmodells beeinflussen. Wir zeigen, dass sich mehrsprachiges Training gegenüber zweisprachigem Training verbessert und dass ressourcenarme Sprachen von Schulungen mit Sprachen mit höheren Ressourcen profitieren. Wir zeigen, dass ein mehrsprachiges Modell sowohl auf Übersetzungen als auch auf vergleichbaren Satzpaaren gleichermaßen gut trainiert werden kann und dass die Annotation desselben Bildsatzes in mehreren Sprachen weitere Verbesserungen durch ein zusätzliches Untertitel-Untertitel-Ranking-Ziel ermöglicht.', 'sw': 'Kazi ya hivi karibuni imeonyesha jinsi ya kujifunza vizuri vya kuonekana kwa kutuma maelezo ya picha kwa zaidi ya lugha moja. Hapa, tunachunguza kwa kina hali gani yanaathiri ufanisi wa aina hii ya kujifunza lugha yenye msingi. Tunaonyesha kuwa mafunzo ya lugha mbalimbali yanaboresha mafunzo ya lugha mbili, na lugha ndogo ya rasilimali zinafaidika na mafunzo ya lugha za juu. Tunaonyesha kuwa mtindo wa lugha nyingi unaweza kufundishwa vizuri kwa ama tafsiri au hukumu inayolinganisha, na kwamba kuchochea seti sawa na picha katika lugha mbalimbali inawezesha maendeleo zaidi kwa kupitia lengo la maoni yenye lengo la kuongeza.', 'tr': 'Ýakynda görsel-semantik gabdalyklary bir dilden köp düşündirip görkezilýän işi görkezildi. Bu ýerde, biz esasy detaylar bilen maslahat edip bilýäris nähili şertleriň bu şekilde ýerli dil öwrenmek nusgynyň täsirini täsirleýär. Biz köp dilli bilim eğitimi ikinji dilden gowurak edýändigini görkeýäris we ol köp diller ýokary ressurs dilleri bilen okuwçylamakdan faydalandyrýarlar. Biz köp dilli nusga täze bir terjime edilen ýa-da hoñlaýyn sözler çizgisinde täze bir şekilde bilip biljek bolandygyny görkeýäris we şol bir nusga görkezilen suratlaryň birnäçe dilde birnäçe köpşen käpşen düzümlerini bozmagy mümkin edip bilýäris.', 'af': "Onlangse werk het vertoon hoe om beter visuale- semantiese inbêdings te leer deur beeldbeskrywings in meer as een taal te verwyder. Hier, ons ondersoek in detaljes wat voorwaardes effekteer die prestasie van hierdie tipe gegrónde taal leermemodel. Ons wys dat multitaalse onderwerp verbeter oor twee tale onderwerp, en dat lae hulpbron tale voordeel van onderwerp met hoër hulpbron tale. Ons wys dat 'n multitaal model gelyk gelyk kan onderwerp word op of vertaling of vergelykbare setpaar, en dat die selfde stel beelde in veelvuldige taal aanwys verdere verbeteringe deur 'n addisionele titel-titel-reëling doel.", 'ko': '최근의 연구에 따르면 다양한 언어의 이미지 묘사를 어떻게 활용하여 더욱 좋은 시각적 의미 삽입을 배울 수 있는지 한다.여기서 우리는 이런 뿌리 깊은 언어 학습 모델의 표현에 어떤 조건이 영향을 미치는지 상세하게 연구했다.우리는 다중 언어 교육이 이중 언어 교육보다 효과적이고 낮은 자원 언어가 높은 자원 언어 교육에서 이득을 본다는 것을 보여준다.우리는 다중 언어 모델이 번역이나 비교 가능한 문장에 대해 똑같은 훈련을 받을 수 있고 다양한 언어로 같은 이미지를 주석하면 추가 제목 랭킹 목표를 통해 더욱 개선할 수 있음을 증명했다.', 'fa': 'کارهای اخیرا نشان داده است که چگونه استفاده از توضیح تصویر در بیشتر از یک زبان یاد بگیرید. در اینجا، ما به جزئیات تحقیق می کنیم که شرایطی برای انجام این نوع مدل یادگیری زبان پایین تأثیر می دهند. ما نشان می دهیم که آموزش های زیادی زبان بر روی آموزش دو زبان بهتر می شود و این زبان های کم منابع از آموزش با زبان های منابع بالاتر سود می دهد. ما نشان می دهیم که یک مدل زیادی زبان می تواند به طور مساوی در مورد ترجمه یا جفت جمله قابل مقایسه آموزش داده شود، و این نشان دادن همان مجموعه تصاویر در زبان\u200cهای زیادی با یک هدف مقایسه\u200cی عنوان عنوان جمله\u200cهای زیادی بیشتری بهتر شود.', 'am': 'የአሁኑ ስራ ላይ እንዴት እንደሚሻል እየራእይ-semantic ድምፅ እንዲማር በአንድ ቋንቋ የሚበልጥ ምስል ጽሑፎችን በመጠቀም አሳየ፡፡ እዚህ፣ ይህ ዓይነት የቋንቋ ትምህርት ምሳሌ የሚደርስበት አካባቢ ምን እንደሆነ እናሳውቃለን፡፡ በሁለት ቋንቋ ተማሪዎች ላይ የሚሻለውን እናሳያቸዋለን፣ የዋነቶች ቋንቋዎችም ከፍተኛ የክፍለ ምዕራፍ ቋንቋዎች መግለጫ ይጠቅማሉ፡፡ ብዙ ቋንቋዎች ምሳሌ በመተርጓም ወይም በተስተያየት የንግግር ዓይነት ሁለትን እንዲያስተምር እናስታውቃለን፤ በተለያዩ ቋንቋም የተሰናከረውን ምስሎች በጨማሪው አካባቢ አካባቢ አካባቢ አካሄዱን እንዲያስተምር ይችላል፡፡', 'bn': 'সম্প্রতি কাজ দেখা যাচ্ছে কিভাবে দৃশ্যমান-সেম্যান্টিক বিভিন্ন বিভিন্ন বিভিন্ন ভাষায় ছবির বর্ণনা প্রদান করে ভ এখানে আমরা বিস্তারিত তদন্ত করি কোন অবস্থা এই ধরনের ভাষা শিক্ষা মডেলের প্রভাব ফেলেছে। We show that multilingual training improves over bilingual training, and that low-resource languages benefit from training with higher-resource languages.  আমরা দেখাচ্ছি যে অনুবাদ অথবা তুলনামূলক বাণী জোড়ায় একটি বহুভাষায় মডেল একই ভাবে প্রশিক্ষণ প্রদান করা যাবে এবং অনেক ভাষায় একই ধরনের ছবিকে বিরক্ত করা যায়, যা আরো ক্যাপ্টেশন', 'az': 'Görüntü tanımlamalarını bir dildən daha çox dəyişdirən daha yaxşı görsel-semantik in şallarını öyrənməyi göstərdi. Burada, biz ayrıntılıqlardan xəbərdarlıq edirik ki, bu cür dil öyrənmə model in in təsirini etmişdir. Biz çoxlu dil təhsilinin ikili dil təhsilinin üstündə yaxşılaşdığını və çoxlu ressurs dillərinin yüksək ressurs dilləri ilə təhsilinin faydalandığını göstəririk. Biz çoxlu dil model in in təhsil edilməsini göstəririk ki, ya tercümələr, ya da salşılabilir cümlələr çiftində istifadə edilə bilər, və bu, çoxlu dildə aynı şəkillərin təhsil edilməsini daha çox başlıq-başlıq səviyyəsi ilə daha yaxşı təhsil edər.', 'sq': 'Recent work has shown how to learn better visual-semantic embeddings by leveraging image descriptions in more than one language.  Këtu, ne hetojmë në hollësi se cilat kushte ndikojnë në performancën e këtij lloji modeli të mësimit të gjuhës. Ne tregojmë se trajnimi shumëgjuhës përmirësohet lidhur me trajnimin dygjuhës dhe se gjuhët me burime të ulëta përfitojnë nga trajnimi me gjuhë me burime më të larta. Ne demonstrojmë se një model shumëgjuhës mund të trajnohet në mënyrë të barabartë në përkthime ose çifte fjalësh të krahasueshme dhe se anotimi i të njëjtit set imazhesh në gjuhë të shumëgjuhës lejon përmirësime të mëtejshme nëpërmjet një objektivi shtesë të renditjes së titullit-titullit.', 'bs': 'Skorašnji rad pokazuje kako naučiti bolje vizualno-semantičke integracije, uključujući opise slika na više od jednog jezika. Ovdje istražujemo detaljno koje uvjete utiču na izvođenje ovakvog tipa osnovnog modela učenja jezika. Pokazujemo da se multijezička obuka poboljšava preko dvojezičke obuke i da jezici niskih resursa koriste od obuke sa višim jezicima resursa. Pokazujemo da se multijezički model može obučavati jednako dobro na prevodima ili usporedbljivim parovima rečenica, i da annotacija iste skupine slika na višestrukom jeziku omogućava daljnje poboljšanje putem dodatnog cilja za redovnu kategoriju.', 'hy': 'Վերջին աշխատանքը ցույց է տալիս, թե ինչպես ավելի լավ տեսողական-սեմանտիկ ներդրումներ սովորել՝ օգտագործելով պատկերի նկարագրությունները մեկ լեզվով: Here, we investigate in detail which conditions affect the performance of this type of grounded language learning model.  Մենք ցույց ենք տալիս, որ բազմալեզու ուսումնասիրությունը բարելավվում է երկլեզու ուսումնասիրության մեջ, և որ ցածր ռեսուրսների լեզուները շահում են ուսումնասիրությունից ավելի բարձր ռեսուրսների լեզուներով: Մենք ցույց ենք տալիս, որ բազլեզու մոդելը նույնքան լավ կարող է ուսուցանվել կամ թարգմանությունների կամ համեմատական նախադասությունների զույգերի վրա, և որ նկարների նույն համակարգը բազլեզու լեզվով գրելը հնարավորություն է տալիս ավելի լավ զարգացումներ ավելացնելու միջոցով ավելացված վեր', 'cs': 'Nedávná práce ukázala, jak se naučit lepší vizuálně-sémantické vložení pomocí popisů obrázků ve více než jednom jazyce. Zde podrobně zkoumáme, jaké podmínky ovlivňují výkon tohoto typu uzemněného modelu výuky jazyků. Ukazujeme, že vícejazyčné školení se zlepšuje oproti dvojjazyčnému školení a že jazyky s nízkými zdroji mají prospěch ze školení s jazyky s vyššími zdroji. Dokazujeme, že vícejazyčný model lze stejně dobře trénovat buď na překladech nebo srovnatelných párech vět, a že anotace stejné sady obrázků ve více jazycích umožňuje další zlepšení prostřednictvím dalšího cíle pořadí titulků a titulků.', 'et': 'Hiljutised tööd on näidanud, kuidas õppida paremaid visuaalsemantilisi manustamisi, kasutades pildikirjeldusi rohkem kui ühes keeles. Siin uurime üksikasjalikult, millised tingimused mõjutavad seda tüüpi põhjaliku keeleõppe mudeli tulemuslikkust. Me näitame, et mitmekeelne koolitus paraneb kahekeelse koolitusega võrreldes ning et vähese ressursiga keeled saavad kasu kõrgema ressursiga keeltega koolitusest. Näitame, et mitmekeelset mudelit saab võrdselt hästi koolitada kas tõlkete või võrreldavate lausepaaride puhul ning et sama piltide komplekti märgistamine mitmes keeles võimaldab täiendavaid parandusi täiendava pealdise-pealdise järjestuse eesmärgi kaudu.', 'fi': 'Viimeaikaiset työt ovat osoittaneet, miten visuaalis-semanttisia upotuksia voidaan oppia hyödyntämällä kuvakuvauksia useammalla kuin yhdellä kielellä. Tässä selvitämme yksityiskohtaisesti, mitkä olosuhteet vaikuttavat tämäntyyppisen pohjautuvan kielen oppimismallin suorituskykyyn. Osoitamme, että monikielinen koulutus paranee kaksikieliseen koulutukseen verrattuna ja että vähävaraiset kielet hyötyvät enemmän resursseja käyttävien kielten koulutuksesta. Osoitamme, että monikielinen malli voidaan kouluttaa yhtä hyvin joko käännöksiin tai vastaaviin lausepareihin ja että saman kuvajoukon merkitseminen useilla kielillä mahdollistaa lisäparannuksia tekstitys-tekstitys-ranking-tavoitteen avulla.', 'ca': "La feina recent ha demostrat com aprendre millors incorporacions visual-semàntiques utilitzant descripcions d'imatges en més d'un llenguatge. Aquí investigam en detall quines condicions afecten al rendiment d'aquest tipus de model d'aprenentatge de llenguatges basat. Mostrem que la formació multilingüe millora amb la formació bilingüe, i que les llengües amb baix recursos beneficien d'una formació amb llengües amb més recursos. Demostram que un model multillenguatge pot ser entrenat igualment bé en traduccions o parells de frases comparables, i que anotar el mateix conjunt d'imatges en múltiples llengües permet millorar-se més a través d'un objectiu adicional de classement de títol-títol.", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness Punika, awak dhéwé ngertuakake podho akeh sing nggawe gerakan kanggo ngerasakno karo model sing apik banget. Awak dhéwé ngerasakno karo akeh langgar luwih akeh bantuan, lan akeh langgar kuwi wis ana sak bantuan kanggo tukang nggawe langgar bantuan. Awak dhéwé éntuk akeh sistem sing sampeyan akeh luwih akeh dikenalke, dadi pirsak, winih, lan akeh nyong nggawe gerakan akeh sistem sing wisata luwih apik dhéwé.', 'sk': 'Nedavno delo je pokazalo, kako se naučiti boljše vizualno-semantične vdelave z uporabo opisov slik v več kot enem jeziku. Tukaj podrobno raziskujemo, kateri pogoji vplivajo na uspešnost te vrste osnovnega modela učenja jezikov. Pokazujemo, da se večjezično usposabljanje izboljša v primerjavi z dvojezičnim usposabljanjem in da imajo jeziki z nizkimi viri koristi od usposabljanja z jeziki z višjimi viri. Dokazujemo, da je večjezični model mogoče enako dobro usposobiti za prevode ali primerljive pare stavkov in da oponašanje istega nabora slik v več jezikih omogoča nadaljnje izboljšave z dodatnim ciljem razvrščanja napisov-napisov.', 'he': 'העבודה האחרונה הראה כיצד ללמוד תוספות ויזואליות-סמנטיות טובות יותר על ידי השימוש בתיאורי תמונות ביותר משפה אחת. כאן, אנו חוקרים בפרטים אילו תנאים משפיעים על ביצועים של סוג זה של מודל לימוד שפות מקורקע. אנחנו מראים שהאימונים רבות שפות משתפרים על ידי אימונים שתיים שפות, ושפות נמוכות משאבים מרוויחים מהאימונים עם שפות משאבים גבוהות יותר. אנו מראים שמודל רב-שפתי יכול להיות מאומן היטב באותה מידה על תרגומות או זוגות משפטים שווים, ושציונים באותה קבוצה של תמונות בשפה רבה מאפשרים שיפורים נוספים באמצעות אובייקטיבי מעמד תואר-כותר נוסף.', 'ha': "Yin aikin da aka nuna yadda za'a sanar da mafi alhẽri da masu gani na-semantic da za'a iya samar da fassarar zane cikin harshen guda. Wannan, Munã yin ƙidãya a cikin bayan wanne mazaɓa sun yi amfani da aikin wannan misalin maganar harshen bakin. Tuna nũna wa mafarin mulki-lugha masu ƙaranci ga mafarin aiki na lugha biyu, kuma da ƙananan-resource na amfani daga mafarin da harshen sarki. Tuna nuna cewa an sanar da wani misalin mulki-lingui mai amfani da shi daidai a kan fassarori ko kuma ma'abun biyu da ke daidaita, kuma idan an zartar da tsarin zane masu cikin zane-zane masu yawa, yana iya amfani da improvements masu ƙaranci da zane-zane-zane-zane-zane-zane-zane-zane-zane mai sauna.", 'bo': 'འཕྲལ་གསོག་ཀྱི་ལས་ཀ་དེ་ལ་སྟངས་པར་ཆས་འགྲེལ་བཤད་པ་ལས་མཐོང་ནུས་པ་ཅིག་མང་ཙམ་སྟོན་དགོས་པ་ཡིན། འོན་ཀྱང་། ང་ཚོས་རྒྱབ་ལྗོངས་ཀྱི་སྐད་ཡིག་གནས་ཚུལ་གང་འདྲ་ཡིན་པ་ལྟར་ཞིབ་བྱས་ནས་ ང་ཚོས་སྐད་ཡིག ང་ཚོས་སྐད་ཡིག་གཟུགས་རིས་གཅིག་གི་མིང་དཔེ་དབྱིབས་ཡིག་ཚད་དང་མཐུན་རྟགས་པར་སྦྱར་བ་ཡིན་པ་དང་། སྐད་ཡིག་ནང་གི་བརྙན་རིས'}
{'en': 'Unsupervised Sentence Compression using Denoising Auto-Encoders', 'ar': 'ضغط الجملة غير الخاضع للرقابة باستخدام تقليل التشويش التلقائي', 'es': 'Compresión de oraciones no supervisada mediante codificadores automáticos de eliminación de ruido', 'fr': "Compression de phrase non supervisée à l'aide de codeurs automatiques de réduction de", 'pt': 'Compressão de sentença não supervisionada usando codificadores automáticos de redução de ruído', 'ja': 'デノイジングオートエンコーダを使用した監視なしの文章圧縮', 'ru': 'Неконтролируемое сжатие предложения с использованием шумоподавляющих автокодеров', 'zh': '用去噪自编码器无监句压缩', 'hi': 'Denoising ऑटो-एनकोडर का उपयोग कर असुरक्षित वाक्य संपीड़न', 'ga': 'Comhbhrú Pianbhreithe Gan Maoirseacht ag úsáid Ionchódóirí Uathoibríoch Denoising', 'el': 'Μη εποπτευόμενη συμπίεση προτάσεων με χρήση αυτόματων κωδικοποιητών αποκωδικοποίησης', 'hu': 'Felügyelet nélküli mondattömörítés az automatikus kódolókkal', 'ka': 'სიტყვების კომპრესია Denoising ავტოკოდერების გამოყენება', 'it': 'Compressione delle frasi non sorvegliata utilizzando codificatori automatici di denominazione', 'lt': 'Neprižiūrimas sakinių spaudimas naudojant automatinius kodatorius', 'kk': 'Denoising автокодері қолданатын сөздерді сақтау құрылмаған компрессиясы', 'ml': 'സ്വയം എന്\u200dകോഡെറുകള്\u200d ഉപയോഗിച്ച് നിരീക്ഷിക്കപ്പെടാത്ത വാക്കുകള്\u200d പൊട്ടിപ്പിക്കുക', 'mk': 'Ненадгледувано компресирање на речениците со користење на одложување на автоматски кодери', 'ms': 'Pemampatan Hukuman Tidak Dikawal menggunakan Penyulitan Pengekod-Auto', 'no': 'Ukomprimering av uttrykk med automatisk kodar', 'mt': 'Kompressjoni tas-Sentenza Mhux Sorveljata bl-użu ta’ Denoising Auto-Encoders', 'sr': 'Nepotrebna kompresija rečenica koristeći autokodere Denoising', 'mn': 'Denoising Auto-Encoder', 'si': 'Denoising ස්වයංකේතකය භාවිත වාක්ය සංකීර්ණය නොපුරුද්ධිත වාක්ය', 'so': 'Xarunta daryeelka aan la ilaalinayn isticmaalka codsiga', 'ro': 'Comprimarea sentințelor nesupravegheate utilizând codoarele automate denunțate', 'sv': 'Obehandlad meningskompression med angivande av autokodare', 'pl': 'Nienadzorowana kompresja zdań przy użyciu automatycznych koderów denoisingu', 'ta': 'Unsupervised Sentence Compression using Denoising Auto-Encoders', 'ur': 'دِنویسینگ اٹو-اکڈر کے مطابق غیر محافظت سنس کمپرس', 'uz': 'Name', 'vi': 'Name=Nén giọng nói tự động) Name', 'bg': 'Неконтролирано компресиране на изречения с използване на автоматични кодери за определяне', 'nl': 'Niet-gecontroleerde zinscompressie met behulp van Denoising Auto-Encoders', 'da': 'Ikke-overvåget sætningskompression ved hjælp af angivende auto- kodere', 'hr': 'Nepotrebna kompresija izraza koristeći autokodere Denoising', 'de': 'Nicht überwachte Satzkomprimierung mit Denoising Auto-Encoder', 'ko': '소음 제거 자동 인코더를 사용하는 무감독 문장 압축', 'id': 'Unsupervised Sentence Compression using Denoising Auto-Encoders', 'fa': 'زلزله\u200cی عبارت غیرقابل حفاظت با استفاده از زلزل\u200cدهندگان خودکار', 'sw': 'Kushinikiza Hukumu isiyotazama kwa kutumia Kujitenga', 'af': 'Onondersteunde Sentence Kompresie gebruik Denoising Outo- Encoders', 'tr': 'Denoýsing Otomatik Ködlemeleri ullanýan Sened Sykmasyny', 'sq': 'Unsupervised Sentence Compression using Denoising Auto-Encoders', 'am': 'Unsupervised Sentence Compression using Denoising Auto-Encoders', 'az': '䑥湯楳楮朠佴潭慴楫⁋潤污秄녣쒱污狄넠歵汬慮慲慫⁴즙桬쎼毉饳楺汩欠敤楬淉饭槅鼠參뙺쎼⁋潭灲業敳椊', 'hy': 'Օգտագործելով անվերահսկվող նախադասությունների կոդավորումը', 'bn': 'ডেনোজিং স্বয়ংক্রিয়ভাবে এনকোডার ব্যবহার করে শাস্তি সম্পাদক', 'ca': 'La compressió de sentences sense supervisió fent servir els autorcodificadors', 'cs': 'Nekontrolovaná komprese vět pomocí denoisačních automatických kódérů', 'bs': 'Nepotrebna kompresija kazne koristeći autokodere Denoising', 'et': 'Järelevalveta lause tihendamine denoiseerivate automaatkodeerijate abil', 'fi': 'Valvontaton lauseen pakkaaminen käyttäen Denoising Auto-Encoders', 'jv': 'StringReplyForward', 'sk': 'Nenadzorovano stiskanje stavkov z uporabo samodejnih kodirnikov za zaznavanje', 'ha': 'KCharselect unicode block name', 'he': 'לחיצת משפטים ללא השגחה באמצעות דנויסת קודים אוטומטיים', 'bo': 'Denoising རང་འགུལ་གྱིས་གསང་རྟགས་སྤྱོད་སྤྱད་ནས་སྲུང་མེད་པའི་ཚིག་རྟགས་མཆོར་བཤེར'}
{'en': 'In sentence compression, the task of shortening sentences while retaining the original meaning, ', 'ar': 'في ضغط الجملة ، مهمة تقصير الجمل مع الاحتفاظ بالمعنى الأصلي ، تميل النماذج إلى التدريب على مجموعات كبيرة تحتوي على أزواج من الجمل المطولة والمضغوطة. لإزالة الحاجة إلى مجموعات مقترنة ، نقوم بمحاكاة مهمة تلخيص وإضافة ضوضاء لتمديد الجمل وتدريب مشفر تلقائي لتقليل الضوضاء لاستعادة الأصلي ، وإنشاء نظام تدريب شامل دون الحاجة إلى أي أمثلة للجمل المضغوطة. نجري تقييمًا بشريًا لنموذجنا على مجموعة بيانات قياسية لتلخيص النص ونبين أنه يؤدي أداءً مشابهًا لخط الأساس الخاضع للإشراف استنادًا إلى الصحة النحوية والاحتفاظ بالمعنى. على الرغم من عدم تعرضها لبيانات مستهدفة ، فإن نماذجنا غير الخاضعة للإشراف تتعلم إنشاء ملخصات جمل غير كاملة ولكن يمكن قراءتها بشكل معقول. على الرغم من أننا لا نؤدي النماذج الخاضعة للإشراف بناءً على درجات ROUGE ، إلا أن نماذجنا تنافسية مع خط أساس خاضع للإشراف يعتمد على التقييم البشري للصحة النحوية والاحتفاظ بالمعنى.', 'es': 'En la compresión de oraciones, la tarea de acortar las oraciones manteniendo el significado original, los modelos tienden a entrenarse en cuerpos grandes que contienen pares de oraciones verbosas y comprimidas. Para eliminar la necesidad de cuerpos emparejados, emulamos una tarea de resumen y agregamos ruido para extender las oraciones y entrenamos un codificador automático de eliminación de ruido para recuperar el original, construyendo un régimen de entrenamiento de extremo a extremo sin la necesidad de ningún ejemplo de oraciones comprimidas. Llevamos a cabo una evaluación humana de nuestro modelo en un conjunto de datos de resumen de texto estándar y demostramos que funciona de manera comparable a una línea de base supervisada basada en la corrección gramatical y la retención del significado. A pesar de no estar expuestos a ningún dato objetivo, nuestros modelos no supervisados aprenden a generar resúmenes de oraciones imperfectos pero razonablemente legibles. Aunque tenemos un rendimiento inferior al de los modelos supervisados basados en las puntuaciones ROUGE, nuestros modelos son competitivos con una línea de base supervisada basada en la evaluación humana para la corrección gramatical y la retención del significado.', 'pt': 'Na compressão de sentenças, a tarefa de encurtar sentenças mantendo o significado original, os modelos tendem a ser treinados em corpora grandes contendo pares de sentenças verbosas e comprimidas. Para eliminar a necessidade de corpora pareados, emulamos uma tarefa de sumarização e adicionamos ruído para estender frases e treinamos um auto-encoder denoising para recuperar o original, construindo um regime de treinamento de ponta a ponta sem a necessidade de exemplos de frases compactadas. Conduzimos uma avaliação humana de nosso modelo em um conjunto de dados de resumo de texto padrão e mostramos que ele tem um desempenho comparável a uma linha de base supervisionada com base na correção gramatical e na retenção de significado. Apesar de não serem expostos a dados de destino, nossos modelos não supervisionados aprendem a gerar resumos de frases imperfeitos, mas razoavelmente legíveis. Embora tenhamos um desempenho inferior aos modelos supervisionados com base nas pontuações do ROUGE, nossos modelos são competitivos com uma linha de base supervisionada baseada na avaliação humana para correção gramatical e retenção de significado.', 'fr': "Dans la compression de phrase, qui consiste à raccourcir les phrases tout en conservant le sens original, les modèles ont tendance à être entraînés sur de grands corpus contenant des paires de phrases verbeuses et compressées. Pour supprimer le besoin de corpus appariés, nous émulons une tâche de synthèse et ajoutons du bruit pour étendre les phrases et entraîner un encodeur automatique de débruitage pour récupérer l'original, créant ainsi un programme d'entraînement de bout en bout sans avoir besoin d'exemples de phrases compressées. Nous effectuons une évaluation humaine de notre modèle sur un ensemble de données de synthèse de texte standard et montrons qu'il fonctionne de manière comparable à une base de référence supervisée basée sur l'exactitude grammaticale et la conservation du sens. Bien qu'ils ne soient exposés à aucune donnée cible, nos modèles non supervisés apprennent à générer des résumés de phrases imparfaits mais raisonnablement lisibles. Bien que nous subissions les performances des modèles supervisés basés sur les scores ROUGE, nos modèles sont compétitifs par rapport à une base supervisée basée sur l'évaluation humaine de l'exactitude grammaticale et de la conservation du sens.", 'ja': '文圧縮では、元の意味を保持したまま文を短縮する作業で、モデルは冗長な文と圧縮された文のペアを含む大きなコーパでトレーニングされる傾向があります。 ペアになったコーパの必要性を排除するために、まとめタスクをエミュレートし、ノイズを追加して文章を延長し、オリジナルを回復するために脱騒音オートエンコーダをトレーニングし、圧縮された文章の例を必要とせずにエンドツーエンドのトレーニング体制を構築します。 標準的なテキストサマリデータセットでモデルのヒト評価を行い、文法的正しさと意味の保持に基づいて、監視下のベースラインと同等のパフォーマンスを発揮することを示します。 ターゲットデータにさらされていないにもかかわらず、当社の監督下にないモデルは、不完全だが合理的に読みやすい文章サマリーを生成することを学びます。 ROUGEのスコアに基づいて監督されたモデルのパフォーマンスは低下していますが、文法的正しさと意味の保持に関する人間の評価に基づいて監督されたベースラインと競合しています。', 'hi': 'वाक्य संपीड़न में, मूल अर्थ को बनाए रखते हुए वाक्यों को छोटा करने का कार्य, मॉडल को वर्बोज़ और संकुचित वाक्यों के जोड़े वाले बड़े कॉर्पोरेट पर प्रशिक्षित किया जाता है। युग्मित कॉर्पोरेट की आवश्यकता को दूर करने के लिए, हम एक सारांशीकरण कार्य का अनुकरण करते हैं और वाक्यों का विस्तार करने के लिए शोर जोड़ते हैं और मूल को पुनर्प्राप्त करने के लिए एक डिनोइज़िंग ऑटो-एन्कोडर को प्रशिक्षित करते हैं, संपीड़ित वाक्यों के किसी भी उदाहरण की आवश्यकता के बिना एक एंड-टू-एंड प्रशिक्षण शासन का निर्माण करते हैं। हम एक मानक पाठ सारांश डेटासेट पर हमारे मॉडल का एक मानव मूल्यांकन करते हैं और दिखाते हैं कि यह व्याकरणिक शुद्धता और अर्थ के प्रतिधारण के आधार पर एक पर्यवेक्षित आधार रेखा के लिए तुलनात्मक रूप से प्रदर्शन करता है। कोई लक्ष्य डेटा के संपर्क में आने के बावजूद, हमारे असुरक्षित मॉडल अपूर्ण लेकिन यथोचित पठनीय वाक्य सारांश उत्पन्न करना सीखते हैं। यद्यपि हम रूज स्कोर के आधार पर पर्यवेक्षित मॉडल को कम करते हैं, हमारे मॉडल व्याकरणिक शुद्धता और अर्थ के प्रतिधारण के लिए मानव मूल्यांकन के आधार पर एक पर्यवेक्षित आधार रेखा के साथ प्रतिस्पर्धी हैं।', 'zh': '句之压缩也,存其义而缩其句,向其详而压缩其语料库也。 以消配对语料库之需,拟一总结,增噪声以广句,练噪自编码器以复语料库,构一端到端之制,不须压缩句之例。 文本摘要数集上质于人工,而明其性与语法正确性义存者相基线也。 虽无所触,则吾无监模而成不美,可读性理之句摘要。 虽监于ROUGE,而监于人语法正确性义基线有竞争力。', 'ru': 'В сжатии предложений, задача сокращения предложений при сохранении первоначального значения, модели, как правило, обучаются на больших корпусах, содержащих пары подробных и сжатых предложений. Чтобы устранить потребность в парных корпусах, мы эмулируем задачу обобщения и добавляем шум для расширения предложений и обучаем шумоподавляющий автокодер для восстановления оригинала, создавая сквозной режим обучения без необходимости каких-либо примеров сжатых предложений. Мы проводим оценку нашей модели человеком на стандартном наборе данных для обобщения текста и показываем, что она работает сравнительно с контролируемым исходным уровнем на основе грамматической правильности и сохранения значения. Несмотря на отсутствие целевых данных, наши неконтролируемые модели учатся генерировать несовершенные, но разумно читаемые резюме предложений. Несмотря на то, что модели с контролем, основанные на баллах по шкале РУЖА, недостаточно эффективны, наши модели конкурируют с контролируемым исходным уровнем, основанным на оценке человеком грамматической корректности и сохранения смысла.', 'ga': 'I gcomhbhrú abairtí, arb é an tasc a bhaineann le habairtí a ghiorrú agus an bhunchiall a choinneáil, is gnách go gcuirtear oiliúint ar mhúnlaí ar chorpas mór ina bhfuil péirí abairtí briathartha agus comhbhrúite. Chun deireadh a chur leis an ngá atá le corpóra péireáilte, déanaimid aithris ar thasc achoimrithe agus cuirimid torann leis chun abairtí a shíneadh agus chun ionchódóir uathdhéanach a oiliúint chun an bunchóip a aisghabháil, ag tógáil réimeas oiliúna ceann go ceann gan gá le haon samplaí d’abairtí comhbhrúite. Déanaimid meastóireacht dhaonna ar ár múnla ar thacar sonraí caighdeánach achoimrithe téacs agus léirímid go bhfeidhmíonn sé ar bhealach inchomparáide le bunlíne maoirsithe bunaithe ar chruinneas gramadaí agus coinneáil brí. In ainneoin nach bhfuil aon sprioc-shonraí againn, foghlaimíonn ár múnlaí gan mhaoirseacht achoimrí pianbhreithe atá neamhfhoirfe ach atá inléite go réasúnta. Cé go ndéanaimid tearcfheidhmíocht ar shamhlacha maoirsithe bunaithe ar scóir ROUGE, tá ár gcuid samhlacha iomaíoch le bunlíne maoirsithe bunaithe ar mheastóireacht dhaonna maidir le cruinneas gramadaí agus coinneáil brí.', 'ka': 'სიტყვების კომპრექციაში, სიტყვების კომპრექცია, როცა ორიგინალური სიტყვების გადარჩენა, მოდელები უნდა იყოს დიდი კომპორაში, რომელიც გვერბოზის და კომპრექტირებ ჩვენ კომპორაციის საჭირო დასრულებას გადასრულებთ, ჩვენ ვუმუშაობთ სიტყვას და გადასრულებთ სიტყვას, რომლებიც ავტოკოდერის გადასრულებას და დასრულებას გადასრულებას, დასრულებას დასრულებას რეზიმის შექმ ჩვენ ჩვენი მოდელის ადამიანის გავამუშავება სტანდარტული ტექსტის გავამუშავებული მონაცემების შესახებ და ჩვენ ჩვენ გავამუშავებთ, რომ ის გავამუშავება დავამუშავებული ფესტური ხაზი, რო ჩვენი არაფერი მოდელების შექმნა უკეთესი, მაგრამ არაფერი, მაგრამ არაფერი საკუთარი სიმბოლოების შექმნა. მაგრამ ჩვენ ვაკეთებთ მოდელები, რომელიც ROUGE წერტილების ბაზაზე, ჩვენი მოდელები კონპექტიურია, რომელიც დავაკეთებული ბაზილინზე, რომელიც ადამიანის გაუმუშავებაზე გრამიკური მართლად', 'hu': 'A mondattömörítésben, a mondatok rövidítésének feladata, miközben megtartják az eredeti jelentést, a modelleket általában nagy korpuszokra képezik, amelyek részletes és tömörített mondatokat tartalmaznak. A párosított korpuszok szükségességének eltávolítása érdekében emulálunk egy összefoglaló feladatot, és zajt adunk hozzá a mondatok kiterjesztéséhez, és egy denoising automatikus kódolót képzünk az eredeti helyreállításához, végpontos képzési rendszert építünk ki anélkül, hogy tömörített mondatokra lenne szükség. Modellünket egy szabványos szövegösszefoglaló adatkészleten végezzük emberi értékeléssel, és bebizonyítjuk, hogy a nyelvtani helyességen és jelentéstároláson alapuló felügyelt alapkészlethez hasonlóan teljesít. Annak ellenére, hogy nincsenek kitéve céladatoknak, felügyelet nélküli modelleink megtanulják tökéletlen, de ésszerűen olvasható mondatok összefoglalását. Bár a ROUGE pontszámokon alapuló felügyelt modelleket alulteljesítjük, modelleink versenyképesek a nyelvtani helyesség és a jelentés megtartása szempontjából emberi értékelésen alapuló felügyelt alapképzéssel.', 'el': 'Στη συμπίεση προτάσεων, το καθήκον της συντόμευσης προτάσεων διατηρώντας παράλληλα το αρχικό νόημα, τα μοντέλα τείνουν να εκπαιδεύονται σε μεγάλα σώματα που περιέχουν ζεύγη περιεκτικών και συμπιεσμένων προτάσεων. Για να καταργήσουμε την ανάγκη για ζευγαρισμένα σώματα, μιμούμαστε μια εργασία σύνοψης και προσθέτουμε θόρυβο για να επεκτείνουμε τις προτάσεις και εκπαιδεύουμε έναν αυτόματο κωδικοποιητή αποκωδικοποίησης για να ανακτήσει το πρωτότυπο, κατασκευάζοντας ένα σύστημα εκπαίδευσης από τέλος σε τέλος χωρίς την ανάγκη για οποιαδήποτε παραδείγματα συμπιεσμένων προτάσεων. Διεξάγουμε μια ανθρώπινη αξιολόγηση του μοντέλου μας σε ένα τυποποιημένο σύνολο δεδομένων σύνοψης κειμένου και αποδεικνύουμε ότι αποδίδει συγκριτικά με μια εποπτευόμενη βάση βάσης βασισμένη στη γραμματική ορθότητα και διατήρηση της έννοιας. Παρά το γεγονός ότι δεν εκτίθενται σε δεδομένα στόχου, τα μοντέλα μας χωρίς επίβλεψη μαθαίνουν να δημιουργούν ατελείς αλλά λογικά αναγνώσιμες περιλήψεις προτάσεων. Αν και δεν αποδίδουμε τα εποπτευόμενα μοντέλα που βασίζονται σε βαθμολογίες, τα μοντέλα μας είναι ανταγωνιστικά με μια εποπτευόμενη βάση βασισμένη στην ανθρώπινη αξιολόγηση για γραμματική ορθότητα και διατήρηση της έννοιας.', 'it': "Nella compressione delle frasi, il compito di abbreviare le frasi pur mantenendo il significato originale, i modelli tendono ad essere addestrati su grandi corpi contenenti coppie di frasi verbose e compresse. Per rimuovere la necessità di corpora accoppiata, emulamo un compito di riepilogo e aggiungiamo rumore per estendere le frasi e addestriamo un codificatore automatico di denoising per recuperare l'originale, costruendo un regime di allenamento end-to-end senza la necessità di alcun esempio di frasi compresse. Conduciamo una valutazione umana del nostro modello su un set di dati standard di sintesi del testo e mostriamo che esso funziona in modo comparabile a una base di base supervisionata basata sulla correttezza grammaticale e sulla conservazione del significato. Nonostante non siano esposti a dati target, i nostri modelli non supervisionati imparano a generare riassunti di frasi imperfetti ma ragionevolmente leggibili. Anche se sottoperformiamo modelli supervisionati basati sui punteggi ROUGE, i nostri modelli sono competitivi con una base di riferimento supervisionata basata sulla valutazione umana per la correttezza grammaticale e la conservazione del significato.", 'lt': 'Laikantis sakinių spaudimo uždavinio sutrumpinti sakinius ir išlaikyti pradinę reikšmę, modeliai paprastai mokomi ant didelių korprų, kuriuose yra dviejų žodžių ir suspaustų sakinių porų. Norėdami pašalinti poreikį parinti korprą, imituojame santraukos užduotį ir pridėsime triukšmą, kad išplėstų sakinius ir apmokytume denoziuojantį automatinį koduotoją, kad susigrąžintų original ą, sukuriant mokymo režimą nuo pabaigos iki pabaigos, nereikalaujant jokių suspaustų sakinių pavyzdžių. Atliekame žmogiškąjį mūsų modelio vertinimą pagal standartinį teksto santraukos duomenų rinkinį ir parodome, kad jis veikia palyginti su prižiūrima baze, pagrįsta gramatiniu tikslumu ir reikšmės išsaugojimu. Nepaisant to, kad nėra tikslinių duomenų, mūsų nepastebimi modeliai mokosi sukurti nepakankamas, bet pagrįstai skaitomas sakinių santraukas. Nors nepakankamai veiksmingi prižiūrimi modeliai, pagrįsti ROUGE rezultatais, mūsų modeliai yra konkurencingi su prižiūrima baze, pagrįsta žmogaus vertinimu dėl gramatinio tikslumo ir reikšmės išsaugojimo.', 'kk': 'Сөздерді сығу үшін, бастапқы мәліметті сақтау үшін, үлгілер үлкен корпорасында бірнеше вербоз және сығылған сөздердің екі жиілігі бар. Жоғарылған корпора қажеттігін өшіру үшін, біз тапсырманы таңдап, сөйлемелерді кеңейту үшін дыбысты қосу және автокодерді түсіргендіру үшін, бастапқы сөйлемелерді қалпына келтіру үшін, аяқтау мен аяқтау тәжірибесін құр Біз үлгімізді стандартты мәтін тұжырымдамасының деректерін бағалап, грамматикалық дұрыс және мәліметті сақтау негізгі жолымен салыстырып тұрады. Мақсатты деректерге байланысты болмаса, біздің үлгілеріміз дұрыс емес, бірақ дұрыс оқылмайтын мәліметтерді жасау үшін үйренеді. Біз ROUGE нәтижелеріне негізделген бақылау үлгілерін жасаймыз, біздің үлгілеріміз грамматикалық дұрыстығын және мәліметті сақтау үшін адамдардың бағалауына негізделген негізгі жолдарымызды ба', 'mk': 'Во компресијата на речениците, задачата на кратење на речениците додека се задржува оригиналното значење, моделите се тренирани на големи корпора кои содржат пари вербозни и компресирани реченици. За да ја отстраниме потребата од парирана копора, емулираме резултат за резултат и додаваме бука за продолжување на речениците и обука на одбивачки автоматски кодер за обнова на оригиналот, конструкција на режим на обука од крај до крај без потреба од примери на компресирани реченици. Правиме човечка проценка на нашиот модел на стандардниот набор на податоци за резултат на текстот и покажуваме дека тој функционира во споредба со надгледуваната основа базирана на граматска коректност и задржување на значењето. И покрај тоа што не се изложени на никакви метни податоци, нашите ненадгледувани модели научија да генерираат несовршени, но разумно читливи реченици. Иако ние недостасуваме надгледувани модели базирани на ROUGE резултати, нашите модели се конкурентни со надгледувана основа базирана на човечката оценка за граматска коректност и задржување на значењето.', 'mt': 'Fil-kompressjoni tas-sentenza, il-kompitu li jitqassru s-sentenzi filwaqt li jinżamm it-tifsira oriġinali, il-mudelli għandhom it-tendenza li jiġu mħarrġa fuq korpra kbira li fiha par ta’ sentenzi verbużi u kompressi. Biex titneħħa l-ħtieġa għal korpora miżjuda, a ħna nimmulaw kompitu ta’ sommarju u nżidu l-istorbju biex jestendu s-sentenzi u nħarrġu awto-kodifikatur li jiċħad biex jirkupra l-oriġinali, u nibnu reġim ta’ taħriġ minn tarf sa tarf mingħajr il-ħtieġa għal eżempji ta’ sentenzi kompressati. We conduct a human evaluation of our model on a standard text summarization dataset and show that it performs comparably to a supervised baseline based on grammatical correctness and retention of meaning.  Minkejja li mhumiex esposti għal dejta fil-mira, il-mudelli mhux sorveljati tagħna jitgħallmu jiġġeneraw sommarji tas-sentenzi imperfetti iżda raġonevolment leġibbli. Għalkemm nieqsu fil-prestazzjoni tal-mudelli sorveljati bbażati fuq il-punteġġi ROUGE, il-mudelli tagħna huma kompetittivi b’linja bażi sorveljata bbażata fuq evalwazzjoni umana għall-korrettezza grammatika u ż-żamma tat-tifsira.', 'ml': 'വാക്കിന്റെ ചുരുക്കുമ്പോള്\u200d, യഥാര്\u200dത്ഥ അര്\u200dത്ഥം സൂക്ഷിക്കുമ്പോള്\u200d വാക്കുകള്\u200d ചുരുക്കുന്നതിന്റെ ജോലിയാണ്, വലിയ കോര്\u200dപ്പോരിയില്\u200d മ ഇണക്കിയ കോർപ്പോറ്റയ്ക്കുള്ള ആവശ്യം നീക്കം ചെയ്യാനും, വാക്കുകള്\u200d വീണ്ടെടുക്കാനും ശബ്ദം കൂട്ടിച്ചേര്\u200dക്കുന്നു. ആദ്യസ്ഥാനത്തെ തിരിച്ചടിക്കാനും ഒരു ഡെനോയ നമ്മുടെ മോഡലിന്റെ ഒരു മനുഷ്യന്\u200d വിലാസപ്രകാരം നമ്മള്\u200d ചെയ്യുന്നു. ഒരു സാധാരണ ടെക്സ്റ്റാര്\u200dഷന്\u200d ഡാറ്റാസ്റ്റാര്\u200dഷന്\u200d സെറ്റ് ചെയ്യുന്നതില്\u200d അത ലക്ഷ്യത്തിന് വേണ്ടി വെളിപ്പെടുത്തിയിരിക്കുന്നില്ലെങ്കിലും, നമ്മുടെ സംരക്ഷിക്കാത്ത മോഡലുകള്\u200d പരിഗണിക്കുന്നത്  Although we underperform supervised models based on ROUGE scores, our models are competitive with a supervised baseline based on human evaluation for grammatical correctness and retention of meaning.', 'ms': 'Dalam pemampatan kalimat, tugas pendek kalimat semasa menyimpan makna asal, model cenderung dilatih pada korpra besar yang mengandungi pasangan kalimat bertutur dan dipampat. Untuk menghapuskan keperluan untuk korpra berpasangan, kita emulasi tugas ringkasan dan tambah bunyi untuk melanjutkan kalimat dan melatih pengekod-sendiri yang menyangkal untuk pulihkan asal, membina režim latihan akhir-akhir tanpa perlukan sebarang contoh kalimat termampat. Kami melakukan penilaian manusia tentang model kami pada set data penghuraian teks piawai dan menunjukkan bahawa ia berkembang dengan asas yang diawasi berdasarkan persamaan grammatik dan penyimpanan makna. Walaupun terdedah kepada tiada data sasaran, model kita yang tidak diawasi belajar untuk menghasilkan ringkasan kalimat yang tidak sempurna tetapi boleh dibaca secara rasional. Although we underperform supervised models based on ROUGE scores, our models are competitive with a supervised baseline based on human evaluation for grammatical correctness and retention of meaning.', 'no': 'I setningskomprimering er oppgåva til å korta setningar ved å lagra det opprinnelige betydninga. Modellane treng på stor korpora som inneheld par av verbose og komprimerte setningar. For å fjerna nødvendighet for pare korpora, emulerer vi ei samanseringsverktøy og legg til støy for å utvide setningar og trenga eit automatisk koder for å gjenoppretta originalen, og byrja ein øvingsregime for slutt-til-slutt utan nødvendighet for eksemplar av komprimerte setningar. Vi gjer eit menneskelig evaluering av modellen vårt på eit standardtekstsamanseringsdata og viser at det utfører sammenlignbare med ein oversikt baseline basert på grammatisk rettighet og retning av mening. Til tross å vera eksponert til ingen måldata, lærer våre uverkjende modeller å laga uverkjende, men rettferdig lesbare setningsamandringar. Selv om vi underfører superviserte modeller basert på ROUGE-poeng, våre modeller er konkurrente med ein oversikt baseline basert på menneske evaluering for gramatisk rettighet og retning av mening.', 'ro': 'În compresia propozițiilor, sarcina de a scurta propozițiile păstrând în același timp sensul original, modelele tind să fie antrenate pe corpuri mari care conțin perechi de propoziții verboase și comprimate. Pentru a elimina nevoia de corpore asociate, emulăm o sarcină de rezumare și adăugăm zgomot pentru a extinde propozițiile și antrenăm un codor auto denoising pentru a recupera originalul, construind un regim de formare end-to-end fără a fi nevoie de niciun exemplu de propoziții comprimate. Realizăm o evaluare umană a modelului nostru pe baza unui set standard de date de rezumare a textelor și arătăm că acesta funcționează comparabil cu o bază de referință supravegheată bazată pe corectitudinea gramaticală și păstrarea semnificației. În ciuda faptului că nu sunt expuse la date țintă, modelele noastre nesupravegheate învață să genereze rezumate imperfecte, dar rezonabil de citit. Deși nu performăm modele supravegheate bazate pe scorurile ROUGE, modelele noastre sunt competitive cu o bază supravegheată bazată pe evaluarea umană pentru corectitudinea gramaticală și păstrarea semnificației.', 'sr': 'U kompresiji rečenice, zadatak kratkog rečenica dok zadržavaju originalno značenje, modeli se obično obučavaju na velikoj korpori koja sadrži parove verbose i kompresivne rečenice. Da bismo uklonili potrebu za parom korporama, emulirali smo sažetak i dodali buku da proširimo rečenice i treniramo automatski koder da bi se vratio originalni režim treninga do kraja bez potrebe za bilo kakvim primjerima kompresiranih rečenica. Vodimo ljudsku procjenu našeg model a na standardnom setu sažetanja podataka o tekstu i pokazujemo da se uspoređuje s nadziranom početnom linijom baziranom na gramatičkoj ispravnosti i zadržavanju značenja. Uprkos što nisu izloženi ciljnim podacima, naši neodređeni modeli naučili su da stvaraju nepoštene, ali razumno čitane sažetke rečenice. Iako podržavamo nadzorne modele na temelju rezultata ROUGE-a, naši modeli su konkurentni sa nadziranom početnom linijom baziranim na ljudskoj procjeni za gramatičku ispravnost i zadržavanje smisla.', 'mn': 'Үүний дараа нь өгүүлбэрийг багасгах үйл ажиллагаа нь эхний утгыг хадгалах үед, загвар нь том корпора дээр хоёр хэлбэртэй, жижигхэн өгүүлбэрийг агуулдаг. Хоёр хоёр корпора шаардлагатай хэрэгтэй зүйлийг устгахын тулд бид цуглуулах ажил, өгүүлбэр нэмэгдүүлэх, автокодчуудыг тодорхойлох, эхний жишээг эргүүлэх, төгсгөлийн дасгал хөтөлбөрийн засгийн газрыг бүтээх хэрэггүй. Бид хүн төрөлхтний загварын үнэлгээг стандарт текст хэвлэлийн өгөгдлийн багц дээр хийж, грамматикийн зөв болон хадгалах үндсэн суурь шулуунтай харьцуулж байгааг харуулж байна. Хэрэв зорилготой өгөгдлийн хувьд харагдахгүй ч, бидний зорилготой загварууд бүтэлгүйтгэл боловсруулахыг суралцдаг. Хэдийгээр бид ROUGE тоонуудын үндсэн удирдлагатай загваруудыг багасгаж байгаа ч, бидний загварууд нь хүн төрөлхтний грамматикийн зөв болон утгыг хадгалахын тулд удирдлагатай суурь шугам шугам шалгалтын үндсэн үн', 'pl': 'W kompresji zdań, czyli zadaniu skracania zdań przy zachowaniu oryginalnego znaczenia, modele są trenowane na dużych korpusach zawierających pary zdań słownych i skompresowanych. Aby usunąć konieczność stosowania parowanych korpusów, emulujemy zadanie podsumowujące i dodajemy szum, aby rozszerzyć zdania i trenujemy automatyczny koder denoisujący, aby odzyskać oryginał, budując kompleksowy reżim treningowy bez konieczności stosowania żadnych przykładów skompresowanych zdań. Przeprowadzamy ludzką ocenę naszego modelu na standardowym zestawie danych podsumowujących tekst i pokazujemy, że działa on porównywalnie do nadzorowanej bazy bazowej w oparciu o poprawność gramatyczną i zachowanie znaczenia. Pomimo braku danych docelowych, nasze modele bez nadzoru uczą się generować niedoskonałe, ale racjonalnie czytelne podsumowania zdań. Chociaż nadzorowane modele oparte na wynikach ROUGE są nisko wydajne, nasze modele są konkurencyjne z nadzorowaną bazą bazą bazową opartą na ludzkiej ocenie poprawności gramatycznej i zachowania znaczenia.', 'so': 'Qorshaha u gaaban, goortii lagu haysto micnihiisa asalka ah waxaa inta badan lagu baraa shirkadda waaweyn oo ku yaala laba nooc oo ka mid ah verbos iyo qeybo hooseeya. Si a an u qaadno baahida shirkadaha labada nooc ah, waxaynu sameynaa shaqada koorsooyinka, waxaynu ku dareynaa cod si aan u sii fidinno ciqaabta, waxaana baranaynaa cod aad u baahan karto si uu u bogsado asalka ah, oo aan u dhisno dowladda waxbarashada ugu dhammaadka dhamaadka, mana u baahnid tusaale ahaan ciqaabaha hoos u dhigay. Tusaalka biniaadaha waxaan ku sameynaa taariikhda qoraalka ee caadiga ah, waxaana muujinaynaa inay u sameynayso si u eg sameynta qoraalka lagu ilaaliyo oo ku saleysan saxda grammatika iyo dib u dhigista micnaha. Inta kastoo aan loo helin macluumaad waxqabad, modelalkayaga aan la ilaalinaynu waxay bartaan in ay soo dhashaan dhamaan, laakiin si fiican u akhriso xagaaga ereyga. In kastoo aan sameyno modello la ilaaliyo oo lagu saleynayo scorada ROUGE, modelalkayagu waxay ku dadaalaan tartanka hoose la ilaaliyo qiimeynta dadka ee saxda grammatika iyo dib u dhigista micnaha.', 'ta': 'வாக்கு சுருக்கும் போது, மூல அர்த்தத்தை வைத்துக் கொண்டு சுருக்கும் வாக்கியங்களின் பணி ஜோடி நிறுவனத்தின் தேவை நாம் ஒரு நிலையான உரை சுருக்கும் தகவல் அமைப்பில் எங்கள் மாதிரியின் ஒரு மனித மதிப்பீடு செய்கிறோம் மற்றும் அது சிறந்த சரிபார்த்தல் மற்றும் பொருள இலக்கு தரவு எதுவும் தெரியாதாலும், எங்கள் காப்பாற்றப்படாத மாதிரிகள் குறைவில்லாத முறைமையை உருவாக்குவதற்கு கற்று கொள்ள ROUGE மதிப்புகளை அடிப்படையில் நாம் கண்காணிக்கப்பட்ட மாதிரிகளை செயல்படுத்த வேண்டுமானாலும், எங்கள் மாதிரிகள் பாதுகாப்பாக்கப்பட்ட மேல்கோடுகள', 'si': 'වාක්ය සම්පූර්ණයෙන්, වාක්ය සම්පූර්ණය සහ සම්පූර්ණ වාක්ය සම්පූර්ණයෙන් තියාගන්න වෙලාවේ වාක්ය සම්පූර්ණය සඳහ සම්පූර්ණ කාර්පෝරාව සඳහා අවශ්\u200dයය පිටවන්න, අපි සම්පූර්ණ කාර්යයක් සම්පූර්ණ කරනවා සම්පූර්ණයක් සම්පූර්ණ කරනවා සහ ස්වයංකේතකය සම්පූර් අපි මිනිස්සු විශ්වාස කරනවා අපේ මනුස්සයේ මනුස්සයේ විශ්වාස කරනවා ප්\u200dරමාණ පාළුවක් සංවේදනය සඳහා පෙන්වනවා ඒක විශ්වාස කරනවා  ඉලක්කම් දත්තේ නැති විදිහට පිළිබඳින්න බැරිවුනොත්, අපේ නිරීක්ෂා විදිහට ප්\u200dරමාණයක් නිර්මාණය කරන්න බැරිවු අපි පරීක්ෂණය කරලා තියෙන්නේ ROUGE ස්කෝර්ට් වල අධිරූපයේ පරීක්ෂණය කරලා තියෙනවා නමුත් අපේ මෝඩේල් සාධාරණය කරලා තියෙනවා මිනි', 'ur': 'جماعت کی کمپانی میں، کلمات کی کمپانی کی کوشش کرتی ہے اور اصلی معنی کو روک رہی ہے، مدل بڑے کمپانی پر آموزش کی جاتی ہیں جو کلمات اور کمپار کلمات کے جوڑے ہیں. جو جوڑا کرپورا کی ضرورت ہٹانے کے لئے، ہم ایک سامنے کے کام کو اضافہ کرتے ہیں اور کلمات کو اضافہ کرنے کے لئے صدا اضافہ کرتے ہیں اور ایک آواز اضافہ کرنے کے لئے آواز اضافہ کرتے ہیں اور ایک آواز کوڈر کو اضافہ کرنے کے لئے استعمال کرتے ہیں کہ اصلی بات کو اٹھانے کے لئے اضافہ کریں، ایک آخر-to- ہم اپنی مدل کا ایک انسان کا ارزش کررہے ہیں ایک استاندارد ٹیکسٹ سکونٹ ڈیٹ سٹ پر اور دکھاتے ہیں کہ یہ ایک نظارت والی بنسٹ لین کے مطابق کرتا ہے جو گرامٹیک سیدھی اور معنی کی حفاظت پر بنیاد رکھتا ہے۔ اگرچہ کوئی موقع ڈیٹا کے ساتھ کھولا جاتا ہے، ہمارے غیرقابل مدلکوں کو غلطی پیدا کرنے کی سیکھتے ہیں لیکن منطقی طور پر پڑھ سکتے ہیں. اگرچہ ہم روئج سکوٹوں پر بنیاد رکھتے ہیں، ہمارے مدلے ایک نظارت کی بنیاس لین کے ساتھ مسابقات ہیں جو انسان کی ارزیابی پر گرامٹیکی سیدھی اور معنی کی حفاظت کے لئے بنیاد ہے.', 'sv': 'I meningskompression, uppgiften att förkorta meningar samtidigt som de behåller den ursprungliga innebörden, tenderar modeller att tränas på stora korpor som innehåller par verbosa och komprimerade meningar. För att ta bort behovet av ihopkopplade korpora emulerar vi en sammanfattningsuppgift och lägger till brus för att förlänga meningar och tränar en denoising auto-kodare för att återställa originalet, konstruerar en end-to-end träningsregim utan behov av några exempel på komprimerade meningar. Vi genomför en mänsklig utvärdering av vår modell på ett standardtextsammanfattningsdataset och visar att den fungerar jämförbart med en övervakad baslinje baserad på grammatisk korrekthet och bevarande av mening. Trots att de inte exponeras för några måldata lär våra oövervakade modeller sig att generera ofullständiga men rimligt läsbara meningssammanfattningar. Även om vi underpresterar övervakade modeller baserade på ROUGE poäng, är våra modeller konkurrenskraftiga med en övervakad baslinje baserad på mänsklig utvärdering för grammatisk korrekthet och bibehållande av mening.', 'uz': "Name To remove the need for paired corpora, we emulate a summarization task and add noise to extend sentences and train a denoising auto-encoder to recover the original, constructing an end-to-end training regime without the need for any examples of compressed sentences.  Biz modelimizning andoza matn muhitiyat maʼlumotlarni qiymatimizni bajaramiz va bu grammatik to ʻgʻri va ma'nosiga qaramalgan asoslangan asosiy satrlariga mos keladi. Shaxsiy maʼlumot yoʻq boʻlmasa ham, saqlanmagan modellarimiz muvaffaqiyatli yaratishni o'rganadi, ammo juda sodda oʻqib boʻladigan soʻzning muhitilarini yaratishni o'rganadi. Agar biz ROUGE scorlari asosida taʼminlovchi modellarni bajarishimiz mumkin, bizning modellarimiz grammatikal toʻgʻri va ma'nosini qiymatga qo'yilgan asoslangan asboblar asosida ishlab chiqaruvchimiz.", 'vi': 'Trong trường hợp nén, nhiệm vụ cắt ngắn các câu trong khi giữ lại ý nghĩa gốc, các mẫu thường được huấn luyện trên cơ thể lớn chứa các cặp dài và các câu nén. Để loại bỏ nhu cầu ghép với nhóm, chúng tôi mô phỏng một nhiệm vụ tổng kết và thêm âm thanh để kéo dài các câu và huấn luyện một kẻ tự mã hóa để xác định lại bản gốc, thiết lập một chế độ huấn luyện cuối cùng mà không cần phải có bất kỳ ví dụ nào về các câu đã bị nén. Chúng tôi thực hiện một đánh giá con người về mô hình của chúng tôi dựa trên một tập tin tổng hợp văn bản tiêu chuẩn và cho thấy nó thực hiện tương xứng với một cơ sở được giám sát dựa trên sửa sai ngữ pháp và giữ ý nghĩa. Mặc dù không có dữ liệu về mục tiêu, những mô hình không giám sát của chúng ta học tạo ra những bản tóm tắt không hoàn hảo nhưng dễ đọc. Mặc dù chúng tôi không thực hiện được các mô hình giám sát dựa trên các điểm ROCE, các mô hình của chúng tôi vẫn được thi đấu với một cơ sở cơ bản được giám sát dựa trên người đánh giá độ hiệu quả và ý nghĩa.', 'bg': 'При компресирането на изречения, задачата за съкращаване на изреченията, като същевременно запазват първоначалното значение, моделите са склонни да се обучават върху големи корпуси, съдържащи двойки вербални и компресирани изречения. За да премахнем необходимостта от сдвоени корпуси, ние емулираме задача за обобщаване и добавяме шум, за да удължим изреченията и обучаваме автоматичен кодер за обобщаване, за да възстановим оригинала, конструирайки режим на обучение от край до край, без да е необходимо никакви примери за компресирани изречения. Ние извършваме човешка оценка на нашия модел въз основа на стандартен набор от данни за обобщаване на текста и показваме, че той работи сравнимо с надзорена базова база въз основа на граматическа коректност и запазване на смисъла. Въпреки че не са изложени на целеви данни, нашите модели без надзор се научават да генерират несъвършени, но разумно четими резюмета на изреченията. Въпреки че ние не изпълняваме надзорни модели въз основа на оценките на нашите модели са конкурентни с надзорни базови данни въз основа на човешка оценка за граматическа коректност и запазване на смисъла.', 'nl': "Bij zinscompressie, de taak van het verkorten van zinnen met behoud van de oorspronkelijke betekenis, worden modellen meestal getraind op grote corpora's met paren van uitgebreide en gecomprimeerde zinnen. Om de noodzaak van gekoppelde corpora te elimineren, emuleren we een samenvattingstaak en voegen we ruis toe om zinnen uit te breiden en trainen we een ontkennende auto-encoder om het origineel te herstellen, waarbij we een end-to-end trainingsregime opbouwen zonder de noodzaak van enige voorbeelden van gecomprimeerde zinnen. We voeren een menselijke evaluatie van ons model uit op basis van een standaard tekstsamenvattingsdataset en laten zien dat het vergelijkbaar presteert met een begeleide baseline gebaseerd op grammaticale correctheid en betekenisbehoud. Ondanks dat onze modellen zonder toezicht worden blootgesteld aan geen doeldata, leren ze onvolmaakte maar redelijk leesbare zinssamenvattingen te genereren. Hoewel we onderpresteren supervised modellen gebaseerd op ROUGE scores, zijn onze modellen concurrerend met een supervised baseline gebaseerd op menselijke evaluatie voor grammaticale correctheid en betekenisbehoud.", 'da': 'I sætningskompression, opgaven med at forkorte sætninger samtidig med at bevare den oprindelige betydning, modeller har tendens til at blive trænet på store korpora indeholdende par af verbose og komprimerede sætninger. For at fjerne behovet for parrede korpora, efterligner vi en opsummeringsopgave og tilføjer støj for at udvide sætninger og træne en denoising auto-encoder til at gendanne originalen, og konstruerer en end-to-end træning regime uden behov for nogen eksempler på komprimerede sætninger. Vi gennemfører en menneskelig evaluering af vores model på et standard tekst resumé datasæt og viser, at den fungerer sammenligneligt med en overvåget baseline baseret på grammatisk korrekthed og bevarelse af mening. På trods af at de ikke er udsat for måldata, lærer vores uautoriserede modeller at generere ufuldstændige, men rimeligt læselige sætningsoversigter. Selvom vi underpræsterer overvågede modeller baseret på ROUGE scores, er vores modeller konkurrencedygtige med en overvåget baseline baseret på menneskelig evaluering for grammatisk korrekthed og fastholdelse af mening.', 'hr': 'U kompresiji rečenice, zadatak kratkog rečenica dok zadržavaju originalno značenje, modeli se obično obučavaju na velikoj tijelu koja sadrži parove verbozne i kompresivne rečenice. Da bismo uklonili potrebu za parom tijelom, emulirali smo sažetak i dodali buku kako bi proširili rečenice i obučili automatski koder kako bi se vratili originalni režim treninga do kraja bez potrebe za bilo kakvim primjerima kompresiranih rečenica. Vodimo ljudsku procjenu našeg model a na standardnoj skupini sažetke podataka o tekstu i pokazujemo da se uspoređuje s nadziranom početnom linijom na temelju gramatičke ispravnosti i zadržavanja značenja. Uprkos izloženom ničim ciljnim podacima, naši neodređeni modeli naučili su proizvesti nesposobne, ali razumno čitajuće sažetke kazne. Iako podcjenjujemo nadzorne modele na temelju rezultata ROUGE-a, naši modeli su konkurentni s nadziranom početnom linijom na temelju ljudske procjene za gramatičku ispravnost i zadržavanje značenja.', 'id': 'Dalam kompresi kalimat, tugas untuk memperpendek kalimat sementara memelihara arti asli, model cenderung dilatih pada korpra besar yang mengandung sepasang kalimat berjelas dan kompresi. Untuk menghilangkan kebutuhan untuk berpasangan corpora, kita emulasi tugas ringkasan dan menambahkan suara untuk memperpanjang kalimat dan melatih pengekode-otomatis menolak untuk memulihkan asli, membangun regim latihan akhir-akhir tanpa kebutuhan untuk contoh-contoh kalimat kompresi. Kami melakukan evaluasi manusia dari model kami pada set data penghasilan teks standar dan menunjukkan bahwa ia berhasil dibandingkan dengan dasar dasar yang diawasi berdasarkan persis grammatik dan pemeliharaan arti. Meskipun tidak terdedah pada data sasaran, model kita yang tidak diawasi belajar untuk menghasilkan ringkasan kalimat yang tidak sempurna tapi cukup dapat dibaca. Meskipun kita melampaui batas model yang diawasi berdasarkan skor ROUGE, model kita kompetitif dengan dasar yang diawasi berdasarkan evaluasi manusia untuk persis gramatika dan pemeliharaan arti.', 'de': 'Bei der Satzkomprimierung, der Aufgabe, Sätze unter Beibehaltung der ursprünglichen Bedeutung zu verkürzen, werden Modelle tendenziell auf großen Korpora trainiert, die Paare von verbalen und komprimierten Sätzen enthalten. Um die Notwendigkeit für gepaarte Korpora zu beseitigen, emulieren wir eine Zusammenfassungsaufgabe und fügen Rauschen hinzu, um Sätze zu verlängern und trainieren einen denoisierenden Auto-Encoder, um das Original wiederherzustellen, indem wir ein Ende-zu-Ende-Trainingsregime konstruieren, ohne dass Beispiele für komprimierte Sätze benötigt werden. Wir führen eine menschliche Bewertung unseres Modells anhand eines Standard-Textzusammenfassungsdatensatzes durch und zeigen, dass es vergleichbar mit einer überwachten Baseline funktioniert, basierend auf grammatikalischer Korrektheit und Bedeutungsbehalt. Obwohl sie keinen Zieldaten ausgesetzt sind, lernen unsere unbeaufsichtigten Modelle, unvollkommene, aber vernünftigerweise lesbare Satzsummen zu erzeugen. Obwohl wir überwachte Modelle, die auf ROUGE-Scores basieren, unterperformen, sind unsere Modelle mit einer überwachten Baseline konkurrieren, die auf menschlicher Bewertung hinsichtlich grammatischer Korrektheit und Bedeutungserhaltung basiert.', 'ko': '문장 압축(즉 원시적인 의미를 보존하는 동시에 문장을 단축하는 것)에서 모델은 장황하고 압축된 문장을 포함하는 대형 어료 라이브러리에서 훈련을 한다.언어 자료 라이브러리에 대한 수요를 없애기 위해 우리는 요약 임무를 모의하고 소음을 추가하여 문장을 확장하며 소음 제거 자동 인코더를 훈련하여 원시 문장을 복원하고 문장을 압축하는 예시가 필요하지 않게 한다.우리는 표준적인 텍스트 요약 데이터 집합에서 우리의 모델을 인공적으로 평가한 결과 문법의 정확성과 의미 보존을 바탕으로 그의 성능은 감독 기선과 비슷하다는 것을 알 수 있다.비록 목표 데이터가 없지만 우리의 무감독모델 학습은 완벽하지 않지만 읽을 수 있는 합리적인 문장 요약을 생성한다.비록 우리의 모델은 연지 평가를 바탕으로 하는 감독 모델에서 좋지 않지만 우리의 모델은 문법의 정확성과 의미 보존에 있어 인류 평가를 바탕으로 하는 감독 기선과 경쟁력이 있다.', 'fa': 'در مجبور کردن جمله، وظیفه کوتاه کردن جمله\u200cها در حالی که معنی اصلی را نگه داشته باشند، مدل\u200cها در شرکت بزرگ آموزش داده می\u200cشوند که دارند جفت جمله\u200cهای زبان و مجبور شده\u200cاند. برای حذف نیازی برای جفت شرکت، ما یک وظیفه جمع کردن را تبدیل می\u200cکنیم و صدا را برای افزایش جمله\u200cها افزایش می\u200cکنیم و یک رمز\u200cدهنده\u200cی خودکار را آموزش می\u200cدهیم تا اصلی را بازیافت کند، و یک روزنامه آموزش پایان و پایان را بدون نیازی به مثال\u200cهای جمله\u200cهای زخمی ساخت ما یک ارزیابی انسانی از مدل خود را روی یک مجموعه جمع کردن داده\u200cهای متن استاندارد انجام می\u200cدهیم و نشان می\u200cدهیم که آن به مقایسه با یک خط بنیادی تحت نظر بر اساس درستی گراماتیک و نگه داشتن معنی انجام می\u200cدهد. با وجود اینکه به هیچ داده هدف نشان داده نشده باشیم، مدل\u200cهای غیرقابل استفاده از ما یاد می\u200cگیرند که جمعیت\u200cهای جمعیت\u200cهای غیر کامل ولی منطقی قابل خواندن جمعیت\u200cها را تولید کنند. اگرچه ما مدل های تحت نظر بر اساس امتیاز ROUGE را تحت نظر قرار می دهیم، مدل های ما با یک خط بنیادی تحت نظر بر اساس ارزیابی انسان برای درستی گراماتیک و نگه داشتن معنی رقابت دارند.', 'sw': 'Katika shinikizo la hukumu, jukumu la kupunguza hukumu wakati wa kuendelea maana ya asili, mifano mara nyingi hufundishwa kwenye kampuni kubwa yenye viwili vya verbose na hukumu zilizotengenezwa. Ili kuondoa mahitaji ya kampuni mbili, tunaweka jukumu la muhtasari na kuongeza sauti kwa kuongeza hukumu na kufundisha kodi ya kujibu kwa ajili ya kurejesha asili ya msingi, kujenga utawala wa mafunzo ya mwisho bila haja ya mifano yoyote ya hukumu zilizotengwa. Tunafanya uchunguzi wa mwanadamu wa mifano yetu kwenye seti ya taarifa za muhtasari wa maandishi ya kawaida na kuonyesha kwamba inafanya kama inavyolinganisha na msingi uliothibitiwa kwa msingi unaofanywa na uhakika na kusikiliza maana yake. Despite being exposed to no target data, our unsupervised models learn to generate imperfect but reasonably readable sentence summaries.  Ingawa tunafanya mifano yanayofuatiliwa kwa kutumia vipindi vya ROUGE, mifano yetu inashindana na msingi unaothibitiwa kwa ajili ya uchunguzi wa binadamu kwa ajili ya usahihi wa taratibu na kusikiliza maana.', 'tr': 'Sözler içerisinde, başlangıçy ifaden saklamak üçin azaltmak üçin sözleriň görevi, nusgalar uly korpora sözleriň çift we sykylan sözleri bar. Zinji korpora gerekli gerekli zady çykarmak üçin, jümlerden uzaklaşdyrmak we sözlerini ulanmak üçin ses ekleýäris we başlangyç sözlerini almak üçin awtomatik kodeçi gollaşdyrmak üçin, soňra soňra soňra bir eğitim rejimini düzenlemeýäris. Biz adamlarymyzyň nusgasyny standart metin toplanty datajyla çykaryp etdik we munyň gramatik dogrylygyna we maýdanyň saglanmasyna daýan edilen üýtgeýän basit çyzygyna daýanýandygyny görkez. Hiç maksadyň maglumaty gaýd edilmegine rağmen, tassyklanmadyk nusgalarymyz bolmady ýöne makul bir sözlem toparyny döretmäge öwrenýär. Biziň modellerimiz ROUGE şartlaryna daýanýan gözetli nusgalarymyz, adamlaryň gramatika dogrylygyny we meniň saýlamagyna daýanýan çykyşlygyna döredişi.', 'sq': 'Në shtypjen e fjalëve, detyra e shkurtimit të fjalëve ndërsa mban kuptimin origjinal, modelet tenderojnë të trajnohen në korpra të mëdha që përmban dy fjalë të verboze dhe të shtypura. Për të hequr nevojën për korporë të çiftuar, ne emulojmë një detyrë të përmbledhjes dhe shtojmë zhurmë për të zgjeruar fjalët dhe trajnuar një autokodues që mohon për të rikuperuar origjinalin, duke ndërtuar një regjim trajnimi nga fundi në fund pa nevojën për ndonjë shembull të fjalëve të shtypura. Ne kryejmë një vlerësim njerëzor të model it tonë në një sërë të dhënash standarte të përmbledhjes së tekstit dhe tregojmë se ajo funksionon në krahasim me një bazë të mbikqyrur bazuar në saktësinë grammatike dhe mbajtjen e kuptimit. Pavarësisht se jemi të ekspozuar në asnjë të dhënë objektive, modelet tona të pazgjidhur mësojnë të gjenerojnë përmbledhje të pakufektshme por të lexueshme të fjalëve. Megjithëse ne nuk kryejmë modele të mbikqyrur bazuar në rezultatet ROUGE, modelet tona janë konkurrues me një bazë të mbikqyrur bazuar në vlerësimin njerëzor për korrektësinë grammatike dhe mbajtjen e kuptimit.', 'af': "In sentence compression, die taak van kortpaaie setnings terwyl die oorspronklike betekening hou, moet modele op groot korpora opgelei word wat paar verbose en komprimeerde setnings bevat. Om die behoefte vir paar korpora te verwyder, emuleer ons 'n opsomming taak en voeg ruis by om te uitbrei setinge en trein 'n belangrik outomaties-koder om die oorspronklike te herstel, te konstrukteer 'n einde-na-einde onderwerking reëls sonder die nodig vir enige voorbeelde van komprimeerde setinge. Ons doen 'n menslike evaluering van ons model op 'n standaard teks opsomming datastel en wys dat dit vergelykbaar uitvoer met 'n ondersoekte basisline gebaseer op grammatiese korrekheid en onderhou van betekenis. Ons onverondersteunde modele leer om onvolledige maar redelik leesbare setingesamekoms te genereer. Alhoewel ons onderwerp onderwerp onderwerp gemaakte modele gebaseer op ROUGE telling, is ons modele kompetief met 'n onderwerp basis gebaseer op menslike evaluering vir grammatiese korrektheid en onderwerp van betekening.", 'bn': 'কারাদণ্ডের সম্পাদনায়, মূল মানে সংক্ষিপ্ত বাক্য সংক্রান্ত করার কাজ, বিশাল কোর্পোরায় মডেল প্রশিক্ষণ প্রদান করা হয়, যার মধ্যে দুটো জোড়া  জোড়া কোর্পোরার প্রয়োজন মুছে ফেলার জন্য আমরা একটি সার্মিজেশন কাজ নির্ধারণ করি এবং কণ্ঠস্বর বাড়িয়ে দেই এবং স্বয়ংক্রিয় স্বয়ংক্রিয়ভাবে এনকোডার প্রশিক্ষণ প্রশিক্ষণ দেই, যাত আমরা আমাদের মডেলের একটি সাধারণ টেক্সট সার্মিজেশন ডাটাসেটে মানুষের মূল্য চালাচ্ছি এবং দেখাচ্ছি যে এটি গ্রামান্টিকেল সংশোধন এবং এর অর্থের গুণগ লক্ষ্যবস্তুতে কোনো তথ্য প্রকাশ করা সত্ত্বেও, আমাদের অরক্ষিত মডেল অসম্পূর্ণ কিন্তু যোগ্য যোগ্য বাক্যের সারিম সংক্ষে যদিও আমরা রুজের স্কোরের ভিত্তিতে পর্যবেক্ষণের মডেল চালু করি, তবুও আমাদের মডেল মানুষের মূল্যের ভিত্তিতে মানুষের গ্রামাত্রিক সংশোধন এবং অর্থের', 'hy': 'Փաստորերի ընդգծման ժամանակ, նախադասությունների կարճման խնդիրը, մինչդեռ պահպանվում է սկզբնական իմաստը, մոդելները սովորաբար պատրաստվում են մեծ մարմնի վրա, որը պարունակում է բայեր և ընդգծված նախադասություններ: Հեռացնելու զույգ մարմնի կարիքը, մենք էմուլյում ենք համառոտագրման խնդիր և ավելացնում աղմուկ, որպեսզի երկարացնենք նախադասությունները և վարժեցնենք մերժող ավտոկոդեր վերականգնելու համար, կառուցելով վերջ-վերջ վարժման ռեժիմ, առանց խիստ նախադասությունների որևէ օրինակի Մենք կատարում ենք մեր մոդելի մարդկային գնահատումը ստանդարտ տեքստի համառոտագրման տվյալների համակարգի վրա և ցույց ենք տալիս, որ այն կատարվում է համեմատաբար վերահսկվող հիմքի հետ, հիմնված գրամատիկական ճշմարտության և իմաստի պահպանության վրա: Despite being exposed to no target data, our unsupervised models learn to generate imperfect but reasonably readable sentence summaries.  Չնայած մենք թերագործում ենք ROUGe-ի արդյունքների վրա հիմնված վերահսկված մոդելները, մեր մոդելները մրցակցում են վերահսկված հիմքի հետ, հիմնված մարդկային գնահատման վրա գրամատիկ ճշմարտության և իմաստի պահպանության համար:', 'am': 'በቁጥጥር አካባቢ፣ የመጀመሪያውን አዋጅ በመጠበቅ የቃላት ማድረግ ማድረግ፣ ሞዴላዎች በዋነኛ ኮሬፖርት ላይ ሁለት ዓይነቶች እና ተጨማሪ ቃላት ይማራሉ፡፡ የሁለት ኮርፖርት ያስፈልጋቸውን ለማስወግድ፣ ማጠቃለያ ስራ እና ድምፅን ለማሰናከል እና የድምፅ ድምፅ ማሳየት እና ማሳየት የራሱ ኮድዶችን ማድረግ እና የመጀመሪያውን ፍጻሜ ማድረግ እናደርጋለን፣ ማንኛውም ምሳሌ ሳይያስፈልጋቸው የክስ ክፍሎች ማቅረብ ነው፡፡ በጽሑፍ ማቀናጃ ዳታዎችን በሚያሳየው እና በgrammatik ትክክለኛ እና በአሳማሪነት ላይ በተደረገው መደገፊያውን በሚያሳየው መደገፊያውን እና ማሳየው፡፡ ምንም እንኳን አካላቢ ዳታዎች ቢሆን፣ ያልጠበቀው ሞዴላዎቻችን ንጹሕ ነገር ግን የሚያስተባብል የንግግር አዳራሽ ማድረግ ይማራሉ፡፡ ምንም እንኳን በሮዩጂ ደረጃዎች ላይ የተጠበቀውን ሞዴላዎችን እንሠራለን፣ ሞዴላዎቻችን በሰው አካሄድ አካሄድ እና አእምሮውን ለመቀበል በተመሳሳይ መሠረት ላይ የተዘጋጁ መሠረት ይቻላል፡፡', 'az': 'Cümlələr sıkıştırılmasında, ilk məsələni saxlamaq üçün cümlələri azaltmaq məqsədilə, modellər böyük korpora sözlər və sıkıştırılmış cümlələr barəsində təhsil edilərlər. Çiftli korpora ehtiyacını silmək üçün, bir qeyri-qiymətli işi görürük, sözləri genişləmək üçün səs eklərik və təkrar-qiymətli cümlələrin məsəlləri olmadan, təkrar-qiymətli təhsil rejimini inşa edirik. Biz modelimizi standart metin qurğulaması verilənlərin üstündə insan değerlendirməsini təyin edirik və anlamının qrammatik doğruluğuna və qorumasına dayandığını göstəririk. Heç bir məlumat verilməyə baxmayaraq, müəyyən edilməmiş modellərimiz tamamlanmış, lakin dəyişiklik oxuyabilən cümlələr təmizlənməyi öyrənir. Əgər biz ROUGE nöqtələrinə dayanan gözətli modelləri yerinə yetirsək belə, modellərimiz gramatik doğruluqların və məsələlərin qorumasına dayanan insan değerlendirmələrinə dayanılır.', 'ca': "En la compressió de frases, la tasca d'acortar frases mentre conserven el significat original, els models tendeixen a ser entrenats en grans corpores que contenen parells de frases verboses i compreses. To remove the need for paired corpora, we emulate a summarization task and add noise to extend sentences and train a denoising auto-encoder to recover the original, constructing an end-to-end training regime without the need for any examples of compressed sentences.  Fem una evaluació human a del nostre model en un conjunt de dades de resum de textos estàndard i demostram que funciona comparablement amb una base supervisada basada en la correctesa gramàtica i la retenció del sentit. Malgrat estar exposats a cap data d'objectiu, els nostres models no supervisats aprenen a generar resumes de frases imperfects però raonablement llegibles. Although we underperform supervised models based on ROUGE scores, our models are competitive with a supervised baseline based on human evaluation for grammatical correctness and retention of meaning.", 'cs': 'Při kompresi vět, úkolu zkrácení vět při zachování původního významu, modely bývají trénovány na velkých korpusech obsahujících páry slovesných a komprimovaných vět. Abychom odstranili potřebu spárovaných korpusů, emulujeme souhrnnou úlohu a přidáme šum pro rozšíření vět a trénujeme denoisující auto-kodér k obnovení originálu, vytváříme komplexní tréninkový režim bez nutnosti používat jakékoliv příklady komprimovaných vět. Provádíme lidské hodnocení našeho modelu na standardní souhrnné datové sadě textu a ukazujeme, že funguje srovnatelně s dohledem na základě gramatické správnosti a zachování významu. Navzdory tomu, že nejsou vystaveny žádným cílovým datům, se naše modely bez dohledu naučí generovat nedokonalé, ale přiměřeně čitelné shrnutí vět. Přestože pod dohledem vycházíme z ROUGE skóre, naše modely jsou konkurenční s dohledem založeným na lidském hodnocení gramatické správnosti a zachování významu.', 'et': 'Lause tihendamisel, lausete lühendamise ülesandeks, säilitades samal ajal algse tähenduse, harjutatakse mudeleid suurte korpustega, mis sisaldavad sõnalisi ja tihendatud lauseid. Et kõrvaldada vajadus paaritud korpuste järele, emuleerime kokkuvõtliku ülesande ja lisame müra lausete pikendamiseks ning treenime denoiseerivat automaatset kodeerijat originaali taastamiseks, luues lõpust lõpuni treeningrežiimi ilma, et oleks vaja ühtegi näidet tihendatud lausetest. Me teostame oma mudeli inimliku hindamise standardse teksti kokkuvõtliku andmekogumi põhjal ja näitame, et see toimib võrreldavalt grammatilisel õigsusel ja tähenduse säilitamisel põhineva järelevalvealusega. Vaatamata sellele, et nad ei puutu kokku sihtandmetega, õpivad meie järelevalveta mudelid looma ebatäiuslikke, kuid mõistlikult loetavaid lausekokkuvõtteid. Kuigi me ei saavuta ROUGE skooridel põhinevaid järelevalvemudeleid, on meie mudelid konkurentsivõimelised järelevalvealusega, mis põhineb inimeste grammatilise õigsuse ja tähenduse säilitamise hindamisel.', 'bs': 'U kompresiji rečenice, zadatak kratkosti rečenica dok zadržavaju originalno značenje, modeli se obično obučavaju na velikoj korpori koja sadrži parove verbozne i kompresivne rečenice. Da bismo uklonili potrebu za parom korporama, emulirali smo zadatak za sažetak i dodali buku da proširimo rečenice i treniramo automatski koder da bi se vratio originalni, izgradili režim treninga kraja do kraja bez potrebe za bilo kakvim primjerima kompresiranih rečenica. Vodimo ljudsku procjenu našeg model a na standardnoj skupini rezimetiranja podataka teksta i pokazujemo da radi usporedno s nadziranom početnom linijom baziranom na gramatičkoj ispravnosti i zadržavanju značenja. Uprkos što nisu izloženi ciljnim podacima, naši neodređeni modeli naučili da stvaraju nesposobne, ali razumno čitane sažetke kazne. Iako podnosimo nadzorne modele na temelju rezultata ROUGE-a, naši modeli su konkurentni sa nadziranom početnom linijom baziranim na ljudskoj procjeni za gramatičku ispravnost i zadržavanje značenja.', 'fi': 'Lausekompressiossa, jossa lyhennetään lauseita alkuperäisen merkityksen säilyttäen, malleja harjoitetaan yleensä suurilla korpusilla, jotka sisältävät verbooseja ja tiivistettyjä lauseita. Paritettujen korpusten tarpeen poistamiseksi emuloimme yhteenvetotehtävän ja lisäämme kohinaa lauseiden pidentämiseksi ja koulutamme denoisoivan automaattisen koodaajan palauttamaan alkuperäisen, rakentaen päästä päähän -harjoitusohjelman ilman, että tarvitaan esimerkkejä tiivistetyistä lauseista. Teemme mallimme inhimillisen arvioinnin vakiomuotoisen tekstitiivistelmäaineiston pohjalta ja osoitamme, että se toimii verrannollisesti kieliopilliseen oikeellisuuteen ja merkityksen säilyttämiseen perustuvaan valvottuun perusaikatauluun. Vaikka emme altistu kohdetiedoille, valvomattomat mallit oppivat tuottamaan epätäydellisiä mutta kohtuullisesti luettavia lauseyhteenvetoja. Vaikka suoriudumme huonosti ROUGE-pisteisiin perustuvista valvotuista malleista, mallimme ovat kilpailukykyisiä ihmisen kieliopillisen oikeellisuuden ja merkityksen säilyttämisen arviointiin perustuvan valvotun lähtötilanteen kanssa.', 'jv': 'echoH e l l o space w o r l d periodHelloworldHello world Mbok kepengin nggawe kelompok nggawe kelompok nggawe Monday politenessoffpolite"), and when there is a change ("assertive Awak dhéwé éntuk éné perusahaan model sing bisalai nggawe barang nggawe tarjamahan, model kita sampek dadi sing perusahaan karo perusahaan basa sing isiné perusahaan karo perusahaan nggambar uwong sing dirampa nggawe barang nggawe barang dumadhi uwong.', 'ha': "In danna maganar da aka ƙara, aikin kalma masu ƙaranci a lokacin da za'a tsare muhalin na farko, misalin za'a yi amfani da shi a kan koma mai girma wanda ke ƙunsa da nau'i biyu na verbose da cire-gaske. Ji tafiyar da amfani da kwamfyutan firma guda biyu, za mu ƙayyade wani aikin tsarinta kuma Mu ƙara sauti dõmin ka ƙãra, kuma Mu kõre kode kodi na kanana farat ɗaya dõmin ya kõma wa asalin, kuma Mu sami wata na tsarin wa-ƙari zuwa-ƙari, kuma bã da wani misali na da misãlai ga sonar-ƙaranci. Kana tafiyar da kimar shawarar misalinmu a kan tsarin matsayin da aka daidaita kuma munã nuna cewa, shi yana sami daidai da wani salon da aka yi bincike a kan karatun tsarin grammati da kuma yana yin riƙon muhimmin. Despite being exposed to no target data, our unsupervised models learn to generate imperfect but reasonably readable sentence summaries.  Ingawa lalle ne muna samun misãlai da aka tsare shi a kan karatun-nau'in RUGE, ko da kuma misãlai masu yin ta'ada da tsari a kan bincike a kan bincike-bincike, a kan muhalli wa mutum ga gyaranta grammati da kuma ana riƙe muhimmin.", 'he': 'בתוך לחיצת משפטים, המשימה של קיצור משפטים בזמן שמירת המשמעות המקורית, דוגמנים נוטים להיות מאומנים על גופורה גדולה שמכילה זוגות משפטים מופרים ומדחפים. כדי להסיר את הצורך של קבורה זווגת, אנו משפילים משימה של סאמריזציה ולהוסיף רעש כדי להאריך משפטים ולאימון קודם אוטומטי מתכחש כדי לחזור על המקורי, לבנות משטר אימון סוף-סוף ללא הצורך לכל דוגמאות של משפטים דחוסים. אנו מבצעים עריכה אנושית של הדוגמא שלנו על קבוצת נתונים של רשימת טקסט סטנדרטית ומראים שהוא מבצע בהשוואה לבסיס מבוסס על תקנות גרמטית ושימור המשמעות. למרות שנחשוף ללא מידע מטרה, הדוגמנים שלנו ללא השגחה לומדים ליצור סדרות משפטים לא מושלמות, אבל ניתן לקרוא בהסבירות. Although we underperform supervised models based on ROUGE scores, our models are competitive with a supervised baseline based on human evaluation for grammatical correctness and retention of meaning.', 'sk': 'Pri stiskanju stavkov, nalogi skrajšanja stavkov ob ohranjanju prvotnega pomena, se modeli običajno trenirajo na velikih korpusih, ki vsebujejo pare dobesednih in stisnjenih stavkov. Da bi odpravili potrebo po združenih korpusih, posnemamo nalogo povzetka in dodamo hrup za podaljšanje stavkov in usposabljamo samokodirnik za označevanje izvirnika, s čimer oblikujemo režim usposabljanja od konca do konca brez potrebe po primerih stisnjenih stavkov. Naš model ocenjujemo na podlagi standardnega nabora podatkov za povzetek besedila in pokažemo, da deluje primerljivo z nadzorovano osnovno osnovo, ki temelji na slovnični pravilnosti in ohranjanju pomena. Kljub temu, da niso izpostavljeni ciljnim podatkom, se naši nenadzorovani modeli naučijo ustvariti nepopolne, vendar razumno berljive povzetke stavkov. Čeprav smo premalo uspešni nadzorovani modeli, ki temeljijo na ROUGE ocenah, so naši modeli konkurenčni z nadzorovanim osnovnim načrtom, ki temelji na človeški oceni slovnične pravilnosti in ohranjanja pomena.', 'bo': 'ཚིག་ཚིག་མཆོང་ཆུང་ནང་དུ་ཚིག་རྟགས་སྔོན་སྒྲིག་ཀྱི་ཚིག་རྟགས་ཉར་བཞིན་པའི་ལས་འགུལ་སུ། ང་ཚོས་མཛུབ་ཀྱི་སྐོར་འདོར་དགོས་པ་དེ་བསུབ་པར་ངེད་ཚོའི་ལས་འཕར་རིས་ཀྱི་བྱ་ཚིག་དང་། ང་ཚོས་མིའི་རྣམ་གྲངས་ཀྱི་མིག་དཔྱད་ཡིག་གི་ཚད་རྩོམ་འབྲེལ་བ་ཅིག་གི་ཐོག་གཟུགས་རིས་ལྟ་བུ་དང་མཐུན་སྒྲིག་ཡོད་པའི་རྩོམ་འབྲེལ་བ་དང་ཉ ང་ཚོའི་དམིགས་ཡུལ་ཡིག ང་ཚོས་རྣམས་མཐོང་བཟོ་བྱེད་པའི་མིག་གཟུགས་རིས་ལྟར་མཁན་མཐོང་མེད་ནའང་། ང་ཚོའི་མིག'}
{'en': 'Linguistically-Based Deep Unstructured Question Answering', 'ar': 'إجابة أسئلة عميقة وغير منظمة لغويًا', 'pt': 'Resposta a perguntas não estruturadas profundas com base linguística', 'es': 'Respuestas a preguntas profundas no estructuradas basadas en el lenguaje', 'fr': 'Réponse aux questions profondément non structurées basée sur la langue', 'ja': '言語に基づく深層非構造化質問の回答', 'zh': '盖言语之深非结构化问答也', 'ru': 'Лингвистически обоснованный глубокий неструктурированный ответ на вопрос', 'hi': 'भाषाई-आधारित गहरी असंरचित प्रश्न का उत्तर देना', 'ga': 'Doimhneacht Neamhstruchtúrtha Teangeolaíoch Ag Freagairt na gCeisteanna', 'ka': 'Linguistically-Based Deep Unstructured Question Answering', 'it': 'Risposta linguistica a domande profonde non strutturate', 'el': 'Γλωσσολογικά βασισμένη βαθιά ασταθοποιημένη απάντηση ερωτήσεων', 'hu': 'Nyelvi alapú, mély strukturálatlan kérdések megválaszolása', 'kk': 'Лингистикалық негіздеген derin құрылмаған сұрақ жауап беру', 'ms': 'Jawapan soalan tidak terstruktur mendalam berdasarkan bahasa', 'lt': 'Kalbų požiūriu pagrįstas gilus nesustruktūruotas atsakymas į klausimus', 'mt': 'Tweġiba għal mistoqsijiet profondi mhux strutturati bbażati fuq il-lingwa', 'no': 'Linguistically-Based Deep Unstructured Question Ansvar', 'pl': 'Głębokie nieustrukturyzowane odpowiedzi na pytania oparte na języku', 'mk': 'Лингвистички базирано длабоко неструктурирано одговорување на прашања', 'ml': 'ലിങ്ഗിസ്റ്റിക്കല്\u200d അടിസ്ഥാനമാക്കിയ ആഴത്തില്\u200d നിര്\u200dമ്മിക്കപ്പെടാത്ത ചോദ്യം ഉത്തരം', 'si': 'ලින්ග්යුසිටික් ස්ථානයෙන් අස්ථාවිත ප්\u200dරශ්න ප්\u200dරතිච්චාරය', 'mn': 'Лингистикийн үндсэн гүн гүнзгий бус асуулт хариулт', 'ro': 'Răspunsuri profunde nestructurate bazate pe limbaj lingvistic', 'sv': 'Språkbaserat djupt ostrukturerat frågesvar', 'sr': 'Lingistički bazirano duboko neostrukturirano pitanje', 'so': 'Linguistically-Based Deep Unstructured Question Answering', 'ta': 'வரிசைப்படுத்தப்படாத ஆழமான கேள்வி பதில்', 'ur': 'Linguistically-Based Deep Unstructured Question Answering', 'uz': 'Linguistically-Based Deep Unstructured Question Answering', 'vi': 'Câu hỏi được trả lời', 'bg': 'Лингвистично базирано дълбоко неструктурирано отговаряне на въпроси', 'hr': 'Lingistički temeljena duboka neostrukturna odgovor na pitanja', 'da': 'Besvarelse af sprogligt baseret dybt ustruktureret spørgsmål', 'nl': 'Taalkundig gebaseerd diep ongestructureerd antwoord op vragen', 'id': 'Jawaban Pertanyaan Dalam Tangkap Berdasarkan Bahasa', 'de': 'Linguistisch fundierte unstrukturierte Beantwortung von Fragen', 'ko': '언어학에 기초한 심도 있는 비구조화 문답', 'fa': 'پاسخ سؤال عمیق غیرساخته\u200cشده بر اساس زبان', 'tr': 'Hatlaryň gijä daýan gaty struktursyz soragy jogap', 'sw': 'Linguistically-Based Deep Unstructured Question Answering', 'af': 'Linguistically- Based Deep Onstruktureerde Vrag Antwoord', 'sq': 'Përgjigja e thellë e jo strukturuar e pyetjeve bazuar në gjuhë', 'am': 'ጥያቄ', 'hy': 'Լեզվաբանական հիմնված խորը անկառուցվածքային հարցերի պատասխանը', 'bn': 'লিঙ্গিস্টিক- ভিত্তিক গভীর প্রশ্নের উত্তর', 'bs': 'Lingistički bazirano duboko neostrukturirano pitanje', 'ca': 'Linguistically-Based Deep Unstructured Question Answering', 'cs': 'Jazykově založené hluboké nestrukturované odpovědi na otázky', 'et': 'Keeleliselt põhinev struktureerimata küsimustele vastamine', 'fi': 'Kielellisesti pohjautuva syvä rakenteeton kysymysvastaus', 'az': 'Linguistically-Based Deep Unstructured Question Cevap', 'sk': 'Jezikovno temelječe globoko nestrukturirano odgovarjanje na vprašanja', 'jv': 'deep', 'ha': '@ action', 'he': 'תשובת שאלות עמוקה ולא מבוססת בשפה', 'bo': 'Linguistically-Based Deep Unstructured Question Answering'}
{'en': 'In this paper, we propose a new linguistically-based approach to answering non-factoid open-domain questions from ', 'ar': 'في هذه الورقة ، نقترح نهجًا جديدًا قائمًا على اللغة للإجابة على أسئلة المجال المفتوح غير الواقعية من البيانات غير المنظمة. أولاً ، نتوسع في بنية التشفير النصي بناءً على تقديم نموذج عصبي عميق من طرف إلى طرف. تستفيد هذه البنية من آلية الانتباه الثنائية التي تساعد النموذج على التركيز على السؤال وجمل الإجابة في نفس الوقت لاستخراج الإجابات الجملية. ثانيًا ، نقوم بتغذية ناتج محلل الدائرة الانتخابية في النموذج مباشرةً ودمج المكونات اللغوية في الشبكة لمساعدتها على التركيز على أجزاء من الإجابة بدلاً من كلماتها الفردية لتوليد المزيد من المخرجات الطبيعية. من خلال تحسين هذه البنية ، تمكنا من الحصول على نتائج أداء شبه بشرية وتنافسية لنظام حديث في مجموعات بيانات SQuAD و MS-MARCO على التوالي.', 'fr': "Dans cet article, nous proposons une nouvelle approche linguistique pour répondre à des questions ouvertes non factuelles à partir de données non structurées. Tout d'abord, nous développons une architecture de codage textuel basée sur laquelle nous introduisons un modèle neuronal profond de bout en bout. Cette architecture bénéficie d'un mécanisme d'attention bilatérale qui aide le modèle à se concentrer sur une question et sur la phrase de réponse en même temps pour l'extraction de la réponse phrasale. Deuxièmement, nous introduisons directement la sortie d'un analyseur de circonscription dans le modèle et intégrons les constituants linguistiques dans le réseau pour l'aider à se concentrer sur des segments de réponse plutôt que sur ses mots uniques afin de générer une sortie plus naturelle. En optimisant cette architecture, nous sommes parvenus à obtenir des résultats de performance proches de l'humain et à être compétitifs par rapport à un système de pointe sur des ensembles de données SQuad et MS-MARCO respectivement.", 'pt': 'Neste artigo, propomos uma nova abordagem linguística para responder a questões de domínio aberto não factóides a partir de dados não estruturados. Primeiro, elaboramos uma arquitetura para codificação textual com base na qual introduzimos um modelo neural profundo de ponta a ponta. Essa arquitetura se beneficia de um mecanismo de atenção bilateral que ajuda o modelo a se concentrar em uma pergunta e na frase de resposta ao mesmo tempo para extração de resposta frasal. Em segundo lugar, alimentamos a saída de um analisador de constituintes diretamente no modelo e integramos os constituintes linguísticos na rede para ajudá-la a se concentrar em partes de uma resposta em vez de em suas palavras únicas para gerar uma saída mais natural. Ao otimizar essa arquitetura, conseguimos obter resultados de desempenho próximo ao humano e competitivos para um sistema de última geração nos conjuntos de dados SQuAD e MS-MARCO, respectivamente.', 'es': 'En este artículo, proponemos un nuevo enfoque lingüístico para responder preguntas no factoides de dominio abierto a partir de datos no estructurados. Primero, elaboramos una arquitectura para la codificación textual basada en la cual introducimos un modelo neuronal profundo de extremo a extremo. Esta arquitectura se beneficia de un mecanismo de atención bilateral que ayuda al modelo a centrarse en una pregunta y la oración de respuesta al mismo tiempo para la extracción de la respuesta frasal. En segundo lugar, introducimos el resultado de un analizador de circunscripciones en el modelo directamente e integramos los componentes lingüísticos en la red para ayudarla a concentrarse en partes de una respuesta en lugar de en sus palabras individuales para generar resultados más naturales. Al optimizar esta arquitectura, logramos obtener resultados de rendimiento cercano al humano y competir con un sistema de vanguardia en los conjuntos de datos sQuad y MS-MARCO, respectivamente.', 'ja': 'この論文では、非構造化データからの非機能的なオープンドメインの質問に答えるための言語ベースの新しいアプローチを提案します。まず、深いエンドツーエンドのニューラルモデルを導入するためのテキストエンコーディングのアーキテクチャについて説明します。このアーキテクチャは、両側注意メカニズムの恩恵を受けます。このメカニズムは、モデルが質問と回答文に同時に焦点を当てるのに役立ちます。第二に、選挙区パーサーの出力をモデルに直接フィードし、言語的な構成要素をネットワークに統合して、より自然な出力を生成するための単一の単語ではなく、答えの塊に集中するのに役立ちます。このアーキテクチャを最適化することで、SQuADとMS - MARCOのそれぞれのデータセット上の最先端のシステムと比較して、ほぼ人間に近いパフォーマンスの結果と競争力を得ることができました。', 'hi': 'इस पेपर में, हम असंरचित डेटा से गैर-तथ्यात्मक ओपन-डोमेन प्रश्नों का उत्तर देने के लिए एक नए भाषाई-आधारित दृष्टिकोण का प्रस्ताव करते हैं। सबसे पहले, हम पाठ्य एन्कोडिंग के लिए एक वास्तुकला पर विस्तार से बताते हैं जिसके आधार पर हम एक गहरे अंत-से-अंत तंत्रिका मॉडल पेश करते हैं। यह वास्तुकला एक द्विपक्षीय ध्यान तंत्र से लाभान्वित होती है जो मॉडल को एक प्रश्न पर ध्यान केंद्रित करने में मदद करती है और एक ही समय में उत्तर वाक्य के लिए phrasal उत्तर निष्कर्षण के लिए। दूसरा, हम एक निर्वाचन क्षेत्र पार्सर के आउटपुट को सीधे मॉडल में खिलाते हैं और नेटवर्क में भाषाई घटकों को एकीकृत करते हैं ताकि इसे अधिक प्राकृतिक आउटपुट उत्पन्न करने के लिए अपने एकल शब्दों के बजाय एक उत्तर के टुकड़ों पर ध्यान केंद्रित करने में मदद मिल सके। इस वास्तुकला को अनुकूलित करके, हम क्रमशः SQuAD और MS-MARCO डेटासेट पर एक अत्याधुनिक प्रणाली के लिए निकट-से-मानव-प्रदर्शन परिणाम और प्रतिस्पर्धी प्राप्त करने में कामयाब रहे।', 'zh': '于本文中,立一本于语言学新法以对结构化数非实开域问。 先备述本编码之架构,引入一端神经端。 此架构益双边注意机,有助于模形兼注、对案句以短语之。 其次,则输解析器于模形之中,而集言于网络,以助其专于答案之块,非独单词也,以成自然之输。 以优化架构之,得近人之性,各以SQuAD与MS-MARCO数集上与先进之统争。', 'ru': 'В данной работе мы предлагаем новый лингвистически обоснованный подход к ответам на не фактоидные вопросы открытого домена из неструктурированных данных. Во-первых, мы подробно рассмотрим архитектуру для текстового кодирования, на основе которой мы вводим глубокую сквозную нейронную модель. Эта архитектура извлекает выгоду из двустороннего механизма внимания, который помогает модели сосредоточиться на вопросе и предложении ответа одновременно для извлечения фразового ответа. Во-вторых, мы загружаем результаты анализа избирательных округов в модель напрямую и интегрируем лингвистические составляющие в сеть, чтобы помочь ей сконцентрироваться на частях ответа, а не на его отдельных словах для получения более естественного результата. Оптимизируя эту архитектуру, мы смогли получить результаты, близкие к человеческим, и конкурирующие с современной системой на наборах данных SQuAD и MS-MARCO соответственно.', 'ga': 'Sa pháipéar seo, molaimid cur chuige nua atá bunaithe ar theangeolaíocht maidir le freagraí a thabhairt ar cheisteanna fearainn oscailte neamh-factoid ó shonraí neamhstruchtúrtha. Ar an gcéad dul síos, déanaimid mionsaothrú ar ailtireacht le haghaidh ionchódú téacsach bunaithe ar a dtugaimid isteach múnla néaránach domhain ceann go ceann. Baineann an ailtireacht seo leas as meicníocht dhéthaobhach aird a chuidíonn leis an tsamhail díriú ar cheist agus ar an abairt fhreagra ag an am céanna le haghaidh eastóscadh freagraí frása. Ar an dara dul síos, cuirimid aschur parsálaí toghlaigh isteach sa mhúnla go díreach agus comhtháthaimid comhábhair theangeolaíocha isteach sa líonra chun cabhrú leis díriú ar phíosaí freagraí seachas ar a chuid focal aonair chun aschur níos nádúrtha a ghiniúint. Trí bharrfheabhsú a dhéanamh ar an ailtireacht seo, d’éirigh linn torthaí a bhaint amach gar don duine agus iomaíoch le córas den scoth ar thacair sonraí SQuAD agus MS-MARCO faoi seach.', 'hu': 'Jelen tanulmányban új nyelvi alapú megközelítést javasolunk a nem tényleges, nyílt domain kérdések megválaszolására strukturálatlan adatokból. Először is kidolgozunk egy szöveges kódolási architektúrát, amely alapján bemutatunk egy mély end-to-end neurális modellt. Ez az architektúra részesül egy kétoldalú figyelemmel kísérő mechanizmusnak, amely segít a modell abban, hogy egy kérdésre és a válaszmondatra is összpontosítson a frázisos válaszok kivonásához. Másodszor, egy választókerületi elemző kimenetét közvetlenül a modellbe tápláljuk, és integráljuk a nyelvi alkotóelemeket a hálózatba, hogy segítsünk abban, hogy egy válasz darabjaira koncentráljon, nem pedig egyetlen szavaira, hogy természetesebb kimenetet generáljon. Az architektúra optimalizálásával sikerült emberhez közeli teljesítményű eredményeket elérnünk, és versenyképesek vagyunk egy korszerű rendszerrel az SQUAD és MS-MARCO adatkészleteken.', 'ka': 'ამ დომენტში ჩვენ ახალი ენგურისტიკურად დავიწყებთ განახლებელი დიომენტის კითხვების შესახებ, რომლებიც არაფექტიკურად დავიწყებთ. პირველი, ჩვენ ტექსტულ კოდირების აქტიქტიქტურის შესახებ განვითარებთ, რომელიც ჩვენ განვითარებთ ნეიროლური მოდელს ძალიან დასაწყებული. ეს არქტიქტიკური გამოიყენება ბოლატერალური დაახლოების მექანსიდან, რომელიც მოდელს კითხვის და გასახლოების სიტყვებისთვის გამოყენება. მეორე, ჩვენ კონსტისტუტენტის პასუტერის გამოყენებას მოდელში დირექტურად და ინტერგურაცით ლენგურისტიკური კონსტისტუტენტები ქსელში, რომელიც მისი პასუხის ნაწილაზე კონცენტურაციას ამ აქტიქტიკურის ოპტიმიზაციით, ჩვენ შევაძლია მივიღოთ ადამიანის გამოსახულების შედეგი და კონპექტიური სისტემაში SQuAD და MS-MARCO მონაცემების შედეგი.', 'el': 'Στην παρούσα εργασία, προτείνουμε μια νέα γλωσσικά βασισμένη προσέγγιση για την απάντηση μη πραγματικών ανοικτών ερωτήσεων από μη δομημένα δεδομένα. Αρχικά, αναλύουμε μια αρχιτεκτονική κωδικοποίησης κειμένου με βάση την οποία εισάγουμε ένα βαθύ νευρωνικό μοντέλο. Αυτή η αρχιτεκτονική επωφελείται από έναν διμερή μηχανισμό προσοχής που βοηθά το μοντέλο να επικεντρωθεί σε μια ερώτηση και την πρόταση απάντησης ταυτόχρονα για εξαγωγή φράσεων. Δεύτερον, τροφοδοτούμε άμεσα την παραγωγή ενός αναλυτή εκλογικής περιφέρειας στο μοντέλο και ενσωματώνουμε γλωσσικά συστατικά στο δίκτυο για να το βοηθήσουμε να επικεντρωθεί σε κομμάτια μιας απάντησης και όχι στις μεμονωμένες λέξεις του για την παραγωγή πιο φυσικής παραγωγής. Με τη βελτιστοποίηση αυτής της αρχιτεκτονικής, καταφέραμε να επιτύχουμε αποτελέσματα σχεδόν ανθρώπινων επιδόσεων και ανταγωνιστικά σε ένα σύστημα τελευταίας τεχνολογίας σε σύνολα δεδομένων SQuAD και MS-MARCO αντίστοιχα.', 'it': "In questo articolo, proponiamo un nuovo approccio linguistico per rispondere a domande non-factoid open-domain da dati non strutturati. In primo luogo, elaboriamo un'architettura per la codifica testuale basata sulla quale introduciamo un profondo modello neurale end-to-end. Questa architettura beneficia di un meccanismo di attenzione bilaterale che aiuta il modello a concentrarsi su una domanda e la frase di risposta allo stesso tempo per l'estrazione della risposta frasale. In secondo luogo, inseriamo direttamente l'output di un parser elettorale nel modello e integriamo i costituenti linguistici nella rete per aiutarlo a concentrarsi su pezzi di una risposta piuttosto che sulle sue singole parole per generare un output più naturale. Ottimizzando questa architettura, siamo riusciti ad ottenere risultati quasi umani e competitivi rispetto a un sistema all'avanguardia rispettivamente su set di dati SQUAD e MS-MARCO.", 'lt': 'Šiame dokumente siūlome naują kalbomis pagrįstą požiūrį į neatskleistų atviros srities klausimų atsakymą iš nesustruktūruotų duomenų. Pirma, parengiame tekstinio kodavimo architektūrą, kuria grindžiamas gilus nuo galo iki galo neuralinis modelis. Ši architektūra naudojasi dvišaliu dėmesio mechanizmu, kuris padeda modeliui sutelkti dėmesį į klausimą ir atsakymo sakinį tuo pačiu metu frazės atsakymo išrašymui. Antra, mes tiesiogiai įtraukiame rinkimų apygardos analizatoriaus produkciją į model į ir integruojame kalbines sudedamąsias dalis į tinklą, kad padėtume jam sutelkti dėmesį į atsakymo dalis, o ne į vienus žodžius, kad būtų galima sukurti natūralesnę produkciją. Optimizuodami šią architektūrą, mums pavyko pasiekti beveik žmogaus veiklos rezultatus ir konkurencingai įgyvendinti naujausią SQuAD ir MS-MARCO duomenų rinkinių sistemą.', 'kk': 'Бұл қағазда, құрылмаған деректерден фактоид ашылмаған домен сұрақтарын жауап беру үшін жаңа лингвистикалық негізінде негізделген тәсілді ұсынамыз. Біріншіден, біз мәтін кодтамасының архитектурасын түсіндіреміз, оның негізінде түсіндірілген невралдық үлгісін түсіндіреміз. Бұл архитектура үлгісіне сұрақ мен жауап сөйлемесін бір-бір уақытта жауап беру үшін көмектесетін екі теріс қатынас механизмінен ашықтайды. Екіншіден, бұл үлгі үлгілерінің шығысын тікелей және лингвистикалық конституттарды желіне енгізіп, жауап бөлшектерінің бір сөздеріне көмектесу үшін, жауап бөлшектеріне көмектесу үшін, бір сөздер Бұл архитектураны оптимизациялау арқылы, адамға жақын жылдамдық нәтижелерін және SQuAD және MS-MARCO деректер қорларындағы әртүрлі жүйесіне әсер етеді.', 'ms': 'In this paper, we propose a new linguistically-based approach to answering non-factoid open-domain questions from unstructured data.  Pertama, kita mengeksploitasikan arkitektur untuk pengekodan teks yang berdasarkan mana kita memperkenalkan model saraf dari hujung ke hujung. Arkitektur ini berguna dari mekanisme perhatian dua belas yang membantu model untuk fokus pada soalan dan kalimat jawapan pada masa yang sama untuk ekstraksi jawapan frasa. Kedua, kami memberi makan output penghurai kumpulan ke dalam model secara langsung dan mengintegrasikan kumpulan bahasa ke dalam rangkaian untuk membantunya berkonsentrasi pada potongan jawapan daripada pada kata tunggal untuk menghasilkan output yang lebih alami. Dengan memperbaiki arkitektur ini, kami berjaya mendapatkan keputusan hampir-kepada-manusia-prestasi dan kompetitif kepada sistem terbaik pada set data SQuAD dan MS-MARCO respectively.', 'mk': 'Во овој весник предложуваме нов јазички базиран пристап за одговори на нефактоидни прашања на отворен домен од неструктурирани податоци. Прво, развиваме архитектура за текстуално кодирање базирана на која воведуваме длабок нервен модел од крај до крај. Оваа архитектура има корист од билатерален механизам на внимание кој му помага на моделот да се фокусира на прашањето и реченицата на одговорот во исто време за извлекување на фразален одговор. Второ, го внесуваме излезот на анализаторот на изборниот округ во моделот директно и ги интегрираме јазичните конститунти во мрежата за да му помогнеме да се концентрира на парчиња од одговорот наместо на неговите единствени зборови за генерирање на поприроден излез. By optimizing this architecture, we managed to obtain near-to-human-performance results and competitive to a state-of-the-art system on SQuAD and MS-MARCO datasets respectively.', 'mn': 'Энэ цаасан дээр бид хэлний үндсэн шинэ арга зам нь бүтээгдэхүүний мэдээллээс асуудлыг хариулах боломжтой. Эхлээд бид текстур кодлогын архитектурын тухай ярилцаж байна. Үүнээс үндсэн гүнзгий төгсгөл-төгсгөл мэдрэлийн загварыг тайлбарлаж байна. Энэ архитектур нь асуулт болон хариултын өгүүлбэрээс хоёр дахь анхаарлын механизмээс ашигладаг. Хоёрдугаарт, бид загварын шинжилгээний үр дүнг загварт шууд хангаж, хэлний хэмжээсүүдийг сүлжээнд нь холбогдож, хариултын хэсэг дээр анхаарлаа төвлөрүүлэхээс илүү байгалийн үр дүнг бүтээхээс илүү төвлөрүүлэхээс Энэ архитектурыг сайжруулахад бид хүн төрөлхтний үйл ажиллагааны үр дүнг, SQuAD болон MS-MARCO өгөгдлийн сан дээрх урлагийн системтэй өрсөлдөх боломжтой.', 'ml': 'ഈ പത്രത്തില്\u200d, നിര്\u200dമ്മിക്കപ്പെട്ട ഡേറ്റായില്\u200d നിന്നും തുറന്ന ഡൊമെയിന്\u200d ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകാന്\u200d പുതിയ ഭാഷക് ആദ്യം, ടെക്സ്കൂള്\u200d കോഡിങിന്റെ അടിസ്ഥാനത്തുള്ള ഒരു ആര്\u200dക്കിട്ടറില്\u200d ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. അതിന്റെ ആഴത്തെ അവസാനത്തേ ഈ ആര്\u200dക്കിച്ചറിക്കേറ്റര്\u200d ഒരു ബാറ്റററല്\u200d ശ്രദ്ധ മെനിസ്റ്റമില്\u200d നിന്നും ഉപകരിക്കുന്നു. അത് ഒരു ചോദ്യത്തില്\u200d ശ്രദ്ധിക്കുന്നതിനും  രണ്ടാമതായി, നമ്മള്\u200d ഒരു കോണ്\u200dട്ടെസ്റ്റെന്\u200dസിയുടെ ഫലം മോഡലിലേക്ക് നേരിട്ട് നിര്\u200dത്തി നിര്\u200dണ്ണയിക്കുകയും നിര്\u200dമ്മിക്കുകയും ചെയ്യുന്നു. അതിന് അതിനെ  ഈ ആര്\u200dക്കിച്ചറിറ്ററിനെ മാന്യമാക്കുകയാണെങ്കില്\u200d നമ്മള്\u200d മനുഷ്യരുടെ പ്രവര്\u200dത്തനങ്ങള്\u200dക്ക് അടുത്തുചെല്ലുന്ന ഫലങ്ങള്\u200d കിട്ടിയെടുക്കാന്\u200d സാധിച്ച', 'mt': 'F’dan id-dokument, qed nipproponu approċċ ġdid ibbażat fuq il-lingwi biex iwieġbu mistoqsijiet mhux fattojdi ta’ dominju miftuħ minn dejta mhux strutturata. L-ewwel nett, a ħna nidelaboraw fuq arkitettura għall-kodifikazzjoni testwali bbażata fuq li nintroduċu mudell newrali minn tarf għal tarf. Din l-arkitettura tibbenefika minn mekkaniżmu ta’ attenzjoni bilaterali li jgħin lill-mudell jiffoka fuq mistoqsija u s-sentenza tat-tweġiba fl-istess ħin għall-estrazzjoni tat-tweġiba frażali. Second, we feed the output of a constituency parser into the model directly and integrate linguistic constituents into the network to help it concentrate on chunks of an answer rather than on its single words for generating more natural output.  Permezz tal-ottimizzazzjoni ta’ din l-arkitettura rnexxielna niksbu riżultati ta’ prestazzjoni qrib il-bniedem u kompetittivi għal sistema l-aktar avvanzata fuq settijiet ta’ dejta SQuAD u MS-MARCO rispettivament.', 'sr': 'U ovom papiru predlažemo novi jezički pristup na odgovoru na ne-faktoidne pitanja otvorenog domena iz neostrukturnih podataka. Prvo, razvijamo arhitekturu tekstualnog kodiranja na temelju kojeg predstavljamo duboki neuralni model kraja do kraja. Ova arhitektura koristi od bilateralnog mehanizma pažnje koji pomaže modelu da se fokusira na pitanje i odgovornu rečenicu istovremeno za izvlačenje frazalnog odgovora. Drugo, hranimo rezultat analizatora konstitucija u model direktno i integriramo lingvističke konstitucije u mrežu kako bi mu pomogli da se koncentriše na komadiće odgovora umjesto na jedine reči za stvaranje prirodne izlaze. Optimalizirajući ovu arhitekturu, uspeli smo da dobijemo rezultate blizu ljudskog učinka i konkurentne sa državnim umjetničkim sistemom na SQuAD i MS-MARCO datasetima.', 'no': 'I denne papiret foreslår vi ein ny språkbasert tilnærming til å svara på ikkje-fakoid open-domenespørsmål frå ikkje-strukturerte data. Først utviklar vi eit arkitektur for tekst-koding basert på som vi introduserer ein dyp neuralmodell til slutt til slutt. Denne arkitekturen nyttar frå ein bilateral oppmerksmekanisme som hjelper modellen til å fokusera på eit spørsmål og svarsetninga samtidig for utpakking av frasalsvar. Andre, vi får utdata av ein konstitusjonsanalyser inn i modellen direkte og integrerer lingviske konstitusjonar i nettverket for å hjelpa det å koncentrere på deler av ein svar i staden for enkelte ord for å laga meir naturleg utdata. Ved å optimalisera denne arkitekturen, kunne vi få nær menneskelige resultat og konkurentivt til eit kunstsystemet på SQuAD og MS-MARCO-datasett.', 'si': 'මේ පත්තරේ අපි අළුත් භාෂාවික විදිහට ආධාරිත විදිහක් ප්\u200dරශ්නයක් ප්\u200dරතිචාර කරන්න පුළුවන් මුලින්ම, අපි පැත්තක් සංකේතනය සඳහා ස්ථාපනයක් විශ්වාස කරනවා ඒ වගේම අපි ගොඩක් අන්තිම අන්තිම අංතිම අ මේ ස්ථාපනය ප්\u200dරයෝජනය සහ ප්\u200dරතිචාරයක් එකම වෙලාවේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් විතරයි. දෙවෙනි වෙනුවෙන්, අපි ප්\u200dරතිචාරයක් ප්\u200dරතිචාරකයේ ප්\u200dරතිචාරයක් ප්\u200dරතිචාරකයෙන් ප්\u200dරතිචාරකයෙන් ප්\u200dරතිචාරකයෙන් භාෂාවික වි මේ විද්\u200dයාපත්තිය හොඳයි, අපි පරිස්සම් වුනා SQuAD සහ MS-MARCO දත්ත සේට් වලින් මිනිස්සුන්ගේ ප්\u200dරතිචාරයක් සහ ප්\u200dරතිචාරයක් ගන්න.', 'pl': 'W niniejszym artykule proponujemy nowe podejście oparte na języku do odpowiedzi na niefaktyczne pytania otwarte domeny z danych nieustrukturyzowanych. Najpierw opracowujemy architekturę kodowania tekstowego, na podstawie której wprowadzamy głęboki, kompleksowy model neuronowy. Architektura ta korzysta z dwustronnego mechanizmu uwagi, który pomaga modelowi skupić się jednocześnie na pytaniu i zdaniu odpowiedzi w celu ekstrakcji odpowiedzi frazowej. Po drugie, wprowadzamy wyniki parsera okręgu wyborczego bezpośrednio do modelu i integrujemy składniki językowe do sieci, aby pomóc mu skoncentrować się na kawałkach odpowiedzi, a nie na jej pojedynczych słowach, aby generować bardziej naturalne wyniki. Optymalizując tę architekturę, udało nam się uzyskać wyniki bliskie wydajności i konkurencyjne w stosunku do najnowocześniejszego systemu na zbiorach danych SQuAD i MS-MARCO.', 'ta': 'இந்த காகிதத்தில், நாம் ஒரு புதிய மொழியில் அடிப்படையான முறைமையை பரிந்துரைக்கிறோம் அடிப்படையிலிருந்து காரணி இல்லா முதலில், நாம் நிரல் குறியீட்டின் அடிப்படையில் ஒரு அடிப்படையில் விவரிப்போம். அதை நாம் ஒரு ஆழமான முடிவில் இருந்து முடிவ இந்த உருவாக்கி ஒரு இருநிலை கவனம் முறைமையிலிருந்து பயன்படுத்துகிறது அது மாதிரியை ஒரு கேள்வி மீது கவனம் செலுத்த உதவுகிறது மற்றும் ஒரே ந இரண்டாவது, இந்த உருவாக்கத்தை மேம்படுத்தினால், நாங்கள் நெருங்கி மனித செயல் முடிவுகளை பெற முடியவில்லை மற்றும் SQuAD மற்றும் MS- MARCO தகவல் அமைப்புகளில் தானாகவ', 'ro': 'În această lucrare, propunem o nouă abordare bazată pe lingvistică pentru a răspunde la întrebări non-factoide de domeniu deschis din date nestructurate. În primul rând, elaborăm o arhitectură pentru codificarea textuală bazată pe care introducem un model neural profund end-to-end. Această arhitectură beneficiază de un mecanism bilateral de atenție care ajută modelul să se concentreze pe o întrebare și propoziția de răspuns în același timp pentru extragerea răspunsurilor frazale. În al doilea rând, introducem direct rezultatele unui parser de circumscripție și integrăm constituenții lingvistici în rețea pentru a-l ajuta să se concentreze pe bucăți dintr-un răspuns mai degrabă decât pe cuvintele sale unice pentru a genera o rezultate mai naturală. Optimizând această arhitectură, am reușit să obținem rezultate aproape de performanță umană și competitive pentru un sistem de ultimă generație pe seturile de date SQUAD și MS-MARCO.', 'so': "Warqadan waxaynu ka soo jeedaynaa qaab cusub oo luuqad ku saleysan si aan uga jawaabno su'aalo aan aheyn suuqsiyo furan oo aan ka soo jawaabno macluumaad la dhisay. Marka ugu horeysa, waxaynu ku qornaa dhismo qoraal ah oo ku saleysan qoraal kooban, taasoo a an ku soo bandhignaa model aad u dheer dhammaadka neurada. Tirkirkan waxey ka faa’iidaysan meymisyo labaad oo labaad ah oo ka caawinaya tusaale uu ku kalsooneeyo su'aal iyo jawaabta isla waqtiga la soo saaro jawaabta afka. Second, waxaynu quudinnaa midhaha sameynta baaritaanka si toos ah u soo saarnaa samooyinka luuqadda si a an ugu caawino inay ku kalsoonaadaan meelaha jawaabta oo keliya, si aan ugu sameynno wax ka soo baxa dabiicadda ah. Barbaarinta dhismahan, waxaynu awoodnay inaannu helno arimaha sameynta ee u dhow dadka, waxaana kaloo u khilaafsanaynay nidaamka farshaxanka ee SQuAD iyo MS-MARCO si kala mid ah.", 'sv': 'I denna uppsats föreslår vi ett nytt språkbaserat tillvägagångssätt för att besvara icke-faktiska öppna domänfrågor från ostrukturerad data. Först utvecklar vi en arkitektur för textkodning baserad på vilken vi introducerar en djup end-to-end neural modell. Denna arkitektur drar nytta av en bilateral uppmärksamhetsmekanism som hjälper modellen att fokusera på en fråga och svaret på samma gång för frasalt svar utvinning. För det andra matar vi in resultatet från en valkretstolkare direkt i modellen och integrerar språkliga beståndsdelar i nätverket för att hjälpa den att koncentrera sig på delar av ett svar snarare än på sina enskilda ord för att generera mer naturlig produktion. Genom att optimera den här arkitekturen lyckades vi uppnå nästan mänskliga resultat och konkurrenskraftiga mot ett toppmodernt system på SQUAD respektive MS-MARCO dataset.', 'ur': 'اس کاغذ میں ہم ایک نئی زبان کی بنیادی طریقہ پیشنهاد کرتے ہیں کہ غیر فکتوئیڈ اوپن ڈومین سؤال کی جواب دینے کے لئے ایک نئی زبان کی بنیادی طریقہ ہے۔ پہلی بار، ہم ایک معماری کے بارے میں تخصیص اکڈینڈ کے لئے مفصل بیان کرتے ہیں جس پر ہم ایک عمیق انتہا-انتہا-انتہا نیورال موڈل کو معلوم کرتے ہیں. یہ معماری ایک دوسری توجه مکانیسم سے فائدہ دیتی ہے جو مدل کو ایک سوال پر تمرکز کرنے کی مدد کرتا ہے اور ایک دوسرے موقع جواب دینے کے لئے جواب دینے کا فیصلہ کرتا ہے. دوسرا، ہم ایک مقامات پارچٹر کے نتائج کو مدل میں مستقیماً کھلاتے ہیں اور زبان انجمن کو نیٹورک میں جمع کرتے ہیں کہ اس کو ایک جواب کے ٹکڑوں پر کنٹر کریں اس کے ایک کلمات کے سوا اس کے زیادہ طبیعی نتائج پیدا کرنے کے لئے۔ ہم نے اس معماری کو اچھی طرح ترجیح دینے کے ذریعہ اس طرح کام لیا تھا کہ انسان کے نزدیک عمل کا نتیجہ حاصل کریں اور SQuAD اور MS-MARCO ڈیٹ سٹم کے ساتھ ایک ایست کی نظام پر مساوی کریں۔', 'uz': "Bu hujjatda, biz yaratilgan maʼlumotdan ochiq domen savollariga javob berish uchun yangi lingʻlik asosida yangi usulni talab qilamiz. Birinchi, biz texnologiya kodlash asosida ishlab chiqaramiz. Bu asosida, biz eng oxirgi neyrolik modelini ko'rganamiz. This architecture benefits from a bilateral attention mechanism which helps the model to focus on a question and the answer sentence at the same time for phrasal answer extraction.  Ikkinchi so'zda, biz kompyuterning natijasining natijasi modeliga to ʻgʻri soʻzlashiz va tarmoqda tillar taʼminlovchilarini birlashtiramiz va uni bir necha so'zlardan foydalanishimiz uchun bir so'zlardan foydalanishimiz mumkin. Bu arxituvni moslash bilan biz inson jarayon natijalarini olishni boshlab, SQuAD va MS-MARCO maʼlumotlar tarkibini boshqa holat tizimga rivojlanishga tayyorlamiz.", 'vi': 'Trong tờ giấy này, chúng tôi đề nghị một phương pháp ngôn ngữ mới để trả lời các câu hỏi mở miền không nhân tạo từ dữ liệu không xây dựng. Đầu tiên, chúng tôi đề cập đến kiến trúc cấu trúc cấu trúc kết cấu tạo dựa trên đó chúng tôi giới thiệu một mô hình thần kinh tối đa. Kiến trúc này được hưởng lợi từ một cơ cấu chú ý hai bên giúp mô hình tập trung vào một câu hỏi và câu trả lời đồng thời cho việc trích các câu trả lời từ ngữ. Thứ hai, chúng tôi nhập trực tiếp sản xuất của một phân tích bầu cử viên vào mô hình và hòa nhập các cử tri ngôn ngữ vào mạng lưới để giúp nó tập trung vào một phần câu trả lời chứ không phải chỉ một từ để tạo ra sản phẩm tự nhiên hơn. Bằng cách tăng cường kiến trúc này, chúng tôi có thể đạt được kết quả siêu năng lượng gần với con người và cạnh tranh với hệ thống dữ liệu sốtay trong... Hệ thống dữ liệu SQurAD và M-MACO.', 'bg': 'В настоящата статия предлагаме нов лингвистично базиран подход за отговор на нефактоидни въпроси с отворен домейн от неструктурирани данни. Първо, разработваме архитектура за текстово кодиране, въз основа на която въвеждаме дълбок невронен модел от край до край. Тази архитектура се ползва от двустранен механизъм за внимание, който помага на модела да се фокусира върху въпрос и изречение за отговор едновременно при извличане на фразов отговор. Второ, директно вкарваме резултата от анализатора на избирателните райони в модела и интегрираме езикови съставни елементи в мрежата, за да му помогнем да се концентрира върху парчета от отговора, а не върху единичните си думи за генериране на по-естествена продукция. Чрез оптимизирането на тази архитектура успяхме да получим почти човешки резултати и конкурентни на най-съвременната система съответно на наборите от данни.', 'da': 'I denne artikel foreslår vi en ny sprogbaseret tilgang til at besvare ikke-faktiske open-domain spørgsmål fra ustrukturerede data. For det første uddyber vi en arkitektur for tekstkodning baseret på hvilken vi introducerer en dyb end-to-end neural model. Denne arkitektur drager fordel af en bilateral opmærksomhedsmekanisme, der hjælper modellen med at fokusere på et spørgsmål og svaresætningen på samme tid til frasalsk svar ekstraktion. For det andet indfører vi resultatet fra en valgkreds fortolker direkte i modellen og integrerer sproglige vælgere i netværket for at hjælpe den med at koncentrere sig om dele af et svar snarere end på dens enkelte ord for at skabe mere naturlig output. Ved at optimere denne arkitektur lykkedes det os at opnå nær-til-menneskelige ydeevne resultater og konkurrencedygtige over for et state-of-the-art system på henholdsvis SQUAD og MS-MARCO datasæt.', 'nl': 'In dit artikel stellen we een nieuwe taalkundige benadering voor voor het beantwoorden van niet-factoïde open-domein vragen vanuit ongestructureerde data. Eerst werken we uit op een architectuur voor tekstuele codering op basis waarvan we een diep end-to-end neuraal model introduceren. Deze architectuur profiteert van een bilateraal aandachtsmechanisme dat het model helpt om zich tegelijkertijd te concentreren op een vraag en de antwoordzin voor het extraheren van fraseriële antwoorden. Ten tweede voeden we de output van een kiesdistrict parser rechtstreeks in het model en integreren we taalkundige componenten in het netwerk om het te helpen zich te concentreren op stukjes van een antwoord in plaats van op de afzonderlijke woorden om meer natuurlijke output te genereren. Door deze architectuur te optimaliseren, zijn we erin geslaagd om bijna-menselijke resultaten te behalen en concurrerend te zijn voor een state-of-the-art systeem op respectievelijk SQuAD en MS-MARCO datasets.', 'hr': 'U ovom papiru predlažemo novi jezički pristup na odgovoru na ne-faktoidne pitanja otvorenog domena iz neostrukturnih podataka. Prvo, razvijamo arhitekturu tekstualnog kodiranja na temelju kojeg predstavljamo duboki neuralni model kraja do kraja. Ova arhitektura koristi od bilateralnog mehanizma pažnje koji pomaže modelu da se fokusira na pitanje i odgovornu rečenicu istovremeno za izvlačenje frazalnog odgovora. Drugo, hranimo izlaz razrednika sastavnosti u model direktno i integriramo jezičke sastavnike u mrežu kako bi se usredotočili na dijelove odgovora umjesto na jedine riječi za stvaranje prirodnog izlaza. Optimalizirajući ovu arhitekturu, uspjeli smo dobiti rezultate blizu ljudskog učinka i konkurentne na državni sustav umjetnosti na SQuAD i MS-MARCO datasetima.', 'id': 'Dalam kertas ini, kami mengusulkan pendekatan berbasis bahasa baru untuk menjawab pertanyaan domain terbuka bukan faktoid dari data yang tidak terstrukturasi. Pertama, kita mengeksploitasi arsitektur untuk pengekodan teks yang berdasarkan yang kita perkenalkan model saraf yang mendalam. Arkitektur ini berguna dari mekanisme perhatian bilateral yang membantu model untuk fokus pada pertanyaan dan kalimat jawaban pada saat yang sama untuk ekstraksi jawaban frasa. Kedua, kami memberi makan output dari parser konstitusi ke dalam model secara langsung dan mengintegrasikan konstitusi bahasa ke dalam jaringan untuk membantunya berkonsentrasi pada potongan jawaban daripada pada kata tunggal untuk menghasilkan output yang lebih alami. Dengan optimisasi arsitektur ini, kami berhasil mendapatkan hasil pertunjukan dekat dengan manusia dan kompetitif untuk sistem terbaik pada SQuAD dan MS-MARCO dataset secara sesuai.', 'de': 'In diesem Beitrag schlagen wir einen neuen linguistisch basierten Ansatz vor, um nicht-faktoide offene Fragen aus unstrukturierten Daten zu beantworten. Zunächst erarbeiten wir eine Architektur zur textuellen Kodierung, auf der wir ein tiefes neuronales Modell einführen. Diese Architektur profitiert von einem bilateralen Aufmerksamkeitsmechanismus, der dem Modell hilft, sich gleichzeitig auf eine Frage und den Antwortsatz für die Extraktion phrasaler Antworten zu konzentrieren. Zweitens speisen wir die Ausgabe eines Wahlkreisparsers direkt in das Modell ein und integrieren linguistische Bestandteile in das Netzwerk, um es zu helfen, sich auf Fragmente einer Antwort anstatt auf einzelne Wörter zu konzentrieren, um natürlichere Ergebnisse zu generieren. Durch die Optimierung dieser Architektur haben wir es geschafft, nahezu menschennahe Ergebnisse zu erzielen und mit einem hochmodernen System auf SQuAD- bzw. MS-MARCO-Datensätzen konkurrenzfähig zu sein.', 'fa': 'در این کاغذ، ما پیشنهاد می\u200cکنیم یک روش جدید بر اساس زبان\u200cشناسی برای پاسخ دادن سوال\u200cهای غیر فاکتوئید از داده\u200cهای غیر ساخته\u200cشده\u200cاند. اول، ما روی یک معماری برای رمزبندی متن بر اساس آن یک مدل عصبی عمیق به پایان معرفی می کنیم. این معماری از یک مکانیسم توجه دوبرابر سود می\u200cدهد که مدل را کمک می\u200cکند که روی یک سوال تمرکز کند و جمله پاسخ را در آن زمان برای اخراج جواب\u200cهای عبارت. دوم، ما نتیجه\u200cی یک متخصص محیطی را به مدل مستقیم تغذیه می\u200cکنیم و متخصص زبان\u200cشناسی را به شبکه تغذیه می\u200cکنیم تا به آن کمک کنترل کنترل کنترل بر قطعه\u200cهای یک جواب به جای تنها کلمات خود برای تولید نتیجه طبیعی بیشتری با optimization of this architecture, we managed to obtain near-human performance results and competitive to a state-of-the-art system on SQuAD and MS-MARCO datasets respectively.', 'sw': 'Katika gazeti hili, tunapendekeza mbinu mpya ya lugha ili kujibu maswali yasiyo ya wazi ya ndani kutoka kwa taarifa zilizojengwa. Kwanza, tunaelezea katika ujenzi wa kodi za uhalisia kwa kutumia mifano ya kina ya mwisho wa mwisho. This architecture benefits from a bilateral attention mechanism which helps the model to focus on a question and the answer sentence at the same time for phrasal answer extraction.  Pili, tunalisha matokeo ya uchambuzi katika mtindo wa moja kwa moja na kuwaunganisha watengenezaji wa lugha kwenye mtandao ili kuisaidia kuingia kwenye viungo vya majibu badala ya maneno yake ya moja kwa ajili ya kutengeneza matokeo ya asili. Kwa kuimarisha ujenzi huu, tuliweza kupata matokeo ya karibu na utendaji wa binadamu na kushindana na mfumo wa sanaa wa SQuAD na taarifa za MS-MARCO kwa namna fulani.', 'sq': 'Në këtë letër, ne propozojmë një metodë të re bazuar në gjuhë për të përgjigjur pyetjeve jo-faktoide të dominit të hapur nga të dhënat e paistrukturuara. Së pari, ne shpjegojmë një arkitekturë për kodimin tekstual bazuar në të cilën ne prezantojmë një model nervor të thellë nga fundi në fund. Kjo arkitekturë përfiton nga një mekanizëm dypalësh vëmendjeje që ndihmon modelin të përqëndrohet në një pyetje dhe fjalë përgjigjeje në të njëjtën kohë për nxjerrjen e përgjigjes frazële. Së dyti, ne ushqejmë prodhimin e një analizuesi të qarkut zgjedhor në modelin drejtpërdrejt dhe integrojmë përbërësit gjuhësor në rrjetin për të ndihmuar atë të përqëndrohet në pjesë të një përgjigje në vend të fjalëve të vetme të saj për të krijuar më shumë prodhime natyrore. Duke optimizuar këtë arkitekturë, ne arritëm të fitojmë rezultate pranë performancës njerëzore dhe konkurruese ndaj një sistemi të modernit në SQuAD dhe MS-MARCO respektivisht.', 'af': "In hierdie papier, voorstel ons 'n nuwe lingwisies-gebaseerde toegang na antwoord van nie-faktoide open-domein vrae van onstruktureerde data. Eerste, ons onderskryf op 'n arkitektuur vir tekstuele enkodering gebaseer waarop ons 'n diep end-to-end neural model voorsien. Hierdie arkitektuur het voordeel van 'n tweetste aandag mekanisme wat die model help om op 'n vraag te fokus en die antwoord saam op dieselfde tyd vir frasaal antwoord uittrek. Tweede, ons voer die uitvoer van 'n constituency parser in die model direk en integreer lingwisiese constituents in die netwerk om dit te help om te konsentreer op stukke van 'n antwoord in plaas van sy enkele woorde vir meer natuurlike uitvoer te genereer. Deur hierdie arkitektuur te optimaliseer, het ons gestuur om naby-na-menslike-prestasie-resultate te kry en kompetief te kry aan 'n staat-van-kunstenstelsel op SQuAD en MS-MARCO-datastelle respektief.", 'am': 'በዚህ ካላት አዲስ ቋንቋ-ቋንቋ-ቋንቋ-ቋንቋ-ቋንቋ-ቋንቋ-ቋንቋ ለመመልስ አዲስ ጥያቄን ከመሠረቱ ዳታዎች ለመመልስ እናስባለን፡፡ በመጀመሪያ፣ የጽሑፍ ኮድ መሠረት ላይ እናሳውቃለን፡፡ ይህ የመዝገብ ግንኙነት በሁለት ብሔራዊ የጥያቄ ማሰናከል የሚጠቅመው ሞዴል በጥያቄ ላይ እና በመስጠት ጊዜ ለንግግር መልስ ለመውጣት ይረዳል፡፡ በሁለተኛው፣ የአካባቢው ምርጫዎች ውጤቱን ወደ ምሳሌ እናበላዋለን እና የቋንቋዊ ጉዳዮችን ወደ መረብ እናስገባለን፡፡ ይህንን የመዝገብ ግንኙነት በመሻለል፣ ወደ ሰው ፍሬዎችን ለማግኘት እና በSquaAD እና የMS-MARCO ዳታተሮች ላይ የሀገር-አርእስት ስርዓት እና ትጋት ለመታገል አግኝተናል፡፡', 'hy': 'Այս թղթի մեջ մենք առաջարկում ենք նոր լեզվաբանական հիմնված մոտեցում, որպեսզի պատասխանենք անկառուցված տվյալներից բաց բնագավառի ոչ փակտոիդ հարցերին: Առաջինը, մենք զարգացնում ենք տեքստալ կոդավորման ճարտարապետությունը, որը հիմնված է նյարդային մոդելի խորը վերջում: Այս ճարտարապետությունը շահույթ ունի երկուսական ուշադրության մեխանիզմից, որը օգնում է մոդելը կենտրոնանալ հարցի և պատասխանի նախադասության վրա միաժամանակ արտահայտվելու համար: Երկրորդ, մենք անմիջապես տեղադրում ենք ընտրական շրջանի վերլուծության արդյունքը մոդելի մեջ և ինտեգրում ենք լեզվաբանական բաղադրիչները ցանցի մեջ, որպեսզի օգնենք նրան կենտրոնանալ պատասխանի մասերի վրա, ոչ թե նրա միակ բառերի վրա, որպեսզի ավելի բնական արդյունք Օպտիմացնելով այս ճարտարապետությունը, մենք կարողացանք ստանալ մարդկային արդյունքները մոտ և մրցակցություն SQUADի և SM-MARCO ի տվյալների համակարգերի ամենաբարձր համակարգերի հետ:', 'ko': '본고에서 우리는 언어를 바탕으로 하는 새로운 방법을 제시하여 비구조화된 데이터 중의 비요소 개방역 문제를 대답했다.먼저 우리는 텍스트 인코딩의 체계 구조를 상세하게 소개했고 이를 바탕으로 심층적인 끝에서 끝까지의 신경 모델을 도입했다.이런 구조는 쌍방의 주의 메커니즘 덕분이다. 이것은 모델이 한 문제와 답안 문장을 동시에 주목하여 짧은 말의 답안을 추출하는 데 도움이 된다.그 다음에 우리는 선택 영역 분석기의 출력을 모델에 직접 입력하고 언어 성분을 네트워크에 집적하여 하나의 단어에 집중하지 않고 답안의 블록에 집중하여 더욱 자연스러운 출력을 낼 수 있도록 돕는다.이 아키텍처를 최적화하여 EMC는 팀과 MS-MARCO 데이터 세트에서 최첨단 시스템과 경쟁하는 데 성공했습니다.', 'bn': 'এই কাগজটিতে আমরা একটি নতুন ভাষাভিত্তিক ভিত্তিক উপায় প্রস্তাব করি যেটি অফাক্টোয়াড ওপেন-ডোমেইনের প্রশ্নের উত্তর দেয়ার জন্ প্রথমত, আমরা টেক্সুয়াল এনকোডিং এর জন্য একটি আর্কিটেক্টারের উপর বিস্তারিত ব্যাখ্যা করি যেটি ভিত্তিতে আমরা গভীর শেষ পর্যন্ত নিউ এই প্রতিষ্ঠানগুলো ব্যাটারেল মনোযোগ মেক্সিমেন্ট থেকে সুবিধা প্রদান করে যা মডেলটি একটি প্রশ্নের উপর মনোযোগ দিতে সাহায্য করে এবং একই সময় দ্বিতীয়, আমরা একটি প্রতিনিধি প্রতিষ্ঠানের ফলাফল মোডেলের মধ্যে সরাসরি খাওয়া এবং নেটওয়ার্কে ভাষাগত ভাষার প্রতিষ্ঠানকে একত্রিত করে সাহায্য করি যাতে এটি একটি উত্তরের এই আর্কিটেক্টারের মাধ্যমে আমরা কাছাকাছি মানুষ-প্রদর্শনের ফলাফল পেতে সক্ষম হয়েছি এবং স্কোয়াড এবং এমএস-মার্কো ডাটাসেটের রাষ্ট্রীয় শিল্পের সাথে প্রত', 'az': 'Bu kağızda, biz qurulmadığımız məlumatlardan fəqnoidsuz a çıq domena suallarına cavab vermək üçün yeni dilli tərzdə təklif edirik. İlk dəfə, textual kodlama üçün bir arhitektura bəyan edirik ki, buna dayanan derin sonun-sonun nöral modeli təşkil edirik. Bu arhitektura, bir sual və cavab sözlərini bir-birindən uzaqlaşdırmağa kömək edən iki tərəfli təsirlik mehanizmasından fayda verər. İkincisi, biz səhifələr parçacısının çıxışını modellərə doğrudan daxil edirik və dil köməkçilərini a ğ içində birləşdiririk ki, onun təkcə təbiətli sözlərini daha çox təbiətli çıxışı yaratmaq üçün bir cevap parçalarına təsirlənməsinə kömək edək. Bu arhitektürünü optimizləndirək, insan performansı sonuçlarını və SQuAD və MS-MARCO veri setlərinin durumu ilə müqayisədə müqayisədə elde etdik.', 'tr': 'Bu kagyzda, biz düzensiz verilerden fäksit-a ç-domeny soraglary jogaplamak üçin täze dil tabanly bir yaklaşma teklif ediyoruz. Ilkinji gezek, tekstal ködleme üçin bir arhitektura düşünýäris we nural nusgasyna daýan ýarlar. Bu arhitektura, bir sorag we jogabat sözlerini bir gezek çykarmak üçin nusgasyna kömek edip, iki dereje üns meýdançasyndan fayda edýär. Ikinjisi, biz bir bölegi parçacısynyň netijesini moda düz we lingwistiki constituentlerini a ňa üýtgetmek üçin bir jogabyň bir bölegine jogaby täze sözlerini beýleki sözlerine üýtgetmek üçin üns berýäris. Bu arhitektura gözleýşerek, adamlaryň üstüne ýakyn netijelerini we SQuAD we MS-MARCO veri setirlerinde bir sanat sistemine müşteri bolup başardyk.', 'ca': "En aquest paper, proposem un nou enfocament lingüístic per respondre preguntes de domini obert no factoides a partir de dades no estructuradas. En primer lloc, elaboram una arquitectura de codificació textual basada en la qual introduïm un model neuronal profund. Aquesta arquitectura beneficia d'un mecanisme bilateral d'atenció que ajuda al model a centrar-se en una pregunta i la frase de resposta al mateix temps per l'extracció de resposta frasica. Segon, alimentam la producció d'un analitzador electoral al model directament i integram els components lingüístics a la xarxa per ajudar a concentrar-se en trossos d'una resposta en comptes de les seves paraules únices per generar més producció natural. Amb l'optimització d'aquesta arquitectura, vam aconseguir resultats gairebé al rendiment humà i competitius a un sistema més avançat dels conjunts de dades SQuAD i MS-MARCO respectivament.", 'cs': 'V tomto článku navrhujeme nový lingvisticky založený přístup k odpovědi na non-factoidní otázky otevřené domény z nestrukturovaných dat. Nejprve se zabýváme architekturou textového kódování, na jehož základě představujeme hluboký end-to-end neuronový model. Tato architektura těží z bilaterálního mechanismu pozornosti, který pomáhá modelu současně soustředit se na otázku a větu odpovědi pro extrakci frázové odpovědi. Za druhé, vkládáme výstup volebního obvodu přímo do modelu a integrujeme jazykové složky do sítě, abychom jí pomohli soustředit se spíše na kusy odpovědi než na jednotlivá slova pro generování přirozenějšího výstupu. Optimalizací této architektury se nám podařilo dosáhnout výsledků téměř lidského výkonu a konkurenceschopných vůči nejmodernějšímu systému na datových sadách SQuAD a MS-MARCO.', 'bs': 'U ovom papiru predlažemo novi jezički pristup na odgovoru na ne-faktoidne pitanja otvorenog domena iz neostrukturnih podataka. Prvo, razvijamo arhitekturu tekstualnog kodiranja na temelju kojeg predstavljamo duboki neuralni model kraja do kraja. Ova arhitektura koristi od dvostranog mehanizma pažnje koji pomaže modelu da se fokusira na pitanje i odgovornu rečenicu istovremeno za izvlačenje frazalnog odgovora. Drugo, hranimo rezultat analizatora konstitucija u model direktno i integriramo lingvističke konstitucije u mrežu kako bi mu pomogli da se koncentriše na komadiće odgovora umjesto na jedine riječi za stvaranje prirodnih izlaza. Optimalizirajući ovu arhitekturu, uspjeli smo dobiti rezultate blizu ljudskog učinka i konkurentne na državni sistem umjetnosti na SQuAD i MS-MARCO datasetima.', 'et': 'Käesolevas dokumendis pakume välja uut keeleliselt põhinevat lähenemisviisi mittefaktilistele avatud domeeniküsimustele vastamiseks struktureerimata andmetest. Esiteks töötame välja tekstikodeerimise arhitektuuri, mille põhjal tutvustame sügavat otsast otsani neuromudelit. See arhitektuur kasutab kahepoolset tähelepanumehhanismi, mis aitab mudelil keskenduda küsimusele ja vastuselausele samal ajal fraasivastuse ekstraheerimisel. Teiseks lisame valimisringkonna parseri väljundi mudelisse otse ja integreerime keelelised komponendid võrgustikku, et aidata tal keskenduda vastuse tükkidele, mitte üksikutele sõnadele loomulikuma väljundi loomiseks. Selle arhitektuuri optimeerimisega õnnestus meil saavutada peaaegu inimese jõudluse tulemusi ja konkureerida vastavalt SQuAD ja MS-MARCO andmekogumite tipptasemel süsteemiga.', 'fi': 'Tässä artikkelissa ehdotamme uutta kielellisesti perustuvaa lähestymistapaa ei-faktoisiin avoimiin kysymyksiin vastaamiseen strukturoimattomasta datasta. Ensin kehitämme tekstikoodauksen arkkitehtuurin, jonka pohjalta esittelemme syvän päästä päähän -neuromallin. Tämä arkkitehtuuri hyötyy kahdenvälisestä huomiomekanismista, joka auttaa mallia keskittymään kysymykseen ja vastauslauseeseen samaan aikaan fraasivastauksen poimimisessa. Toiseksi syötämme vaalipiirin jäsentäjän tuotoksen suoraan malliin ja integroimme kielelliset osatekijät verkostoon auttaaksemme sitä keskittymään vastauksen osiin eikä yksittäisiin sanoihin luonnollisemman tuotoksen tuottamiseksi. Optimoimalla tätä arkkitehtuuria onnistuimme saavuttamaan lähes ihmisen suorituskykyisiä tuloksia ja kilpailemaan SQuAD- ja MS-MARCO-datasarjojen uusimman järjestelmän kanssa.', 'jv': 'In this paper, we proposal a new language-supported method to responsing nonevectual open-domain question from untructued data. Awak dhéwé, awak dhéwé ngeralakno ning architecture kanggo kode textual basa ning awak dhéwé nambah sekang nambah dumadhi end-to-end Neral. architecture Awak dhéwé, kita nyimpen njeneng macem kegangalakno Ngawe Perintake architecture iki, kita nguasai nggawe Perintake bukane dadi kapan-kapan gambar uwong lan ijol-ijolan sing dirangkamu sistem sing wis antara sabên seneng dataset sêmên karo sêmên bakal terus marito.', 'he': 'בעיתון הזה, אנו מציעים גישה חדשה מבוססת שפתיים לענות על שאלות פתוחות לא פקטואידיות ממידע לא מבושל. ראשית, אנו מתייחסים על ארכיטקטורה לקוד טקסטולי מבוססת בה אנו מכירים מודל עצבי עמוק סוף-סוף. הארכיטקטורה הזו תועלת ממנגנון תשומת לב משני שמעזר לדוגמא להתמקד בשאלה ובמשפט התשובה באותו זמן לחלץ תשובה מבטא. שנית, אנו מאכילים את יציאת מחלקת הבחירות לתוך הדוגמא ישירות ולהפוך את המרכיבים הלשוניים לרשת כדי לעזור לה להתרכז בחלקות של תשובה במקום על המילים היחידות שלה לייצור יציאה טבעית יותר. על ידי אופטימיזם הארכיטקטורה הזו, הצלחנו להשיג תוצאות ביצועים קרובות לאדם ומתחרות למערכת מוקדמת במערכת מידע SQuAD ו-MS-MARCO בהתאם.', 'ha': "Ga wannan takardan, Munã buɗe wata hanyoyi na daban-linguistic zuwa a karɓa wa masu tambayar waɗanda bã-factoid ne-buɗe-Domen daga data wanda ba'a saɓa ba. Kayyan da, muna bayyana wani matsayi na kodi na matsayi a kan kwamfyutan da Muke nuna wata misãlin ƙari-zuwa-ƙari. Wannan arkin yana amfani da shi daga wani mekanin muhalli na biyu, wanda yana taimakon motsi da ya zura zura zura zura kan wani tambayi da cewa a sami lokacin da za'a zartar da ajin na magana. Second, we feed the output of a constituency parser into the model directly and integrate linguistic constituents into the network to help it concentrate on chunks of an answer rather than on its single words for generating more natural output.  Ga mafiya amfani da wannan arkin, mun buɗa ta sami matsalar-mafarin-mutane, kuma muka yi gauraya zuwa a halin-sanar-na-SQuAD da matsayin maɓallin-MARCO.", 'sk': 'V prispevku predlagamo nov jezikosloško osnovan pristop k odgovarjanju na nedejanska odprta vprašanja iz nestrukturiranih podatkov. Najprej smo izdelali arhitekturo besedilnega kodiranja, na podlagi katere smo uvedli globok nevronski model od konca do konca. Ta arhitektura ima koristi od dvostranskega mehanizma pozornosti, ki pomaga modelu, da se osredotoči na vprašanje in odgovorni stavek hkrati pri ekstrakciji frazalnih odgovorov. Drugič, rezultat razčlenjevalca volilnega okrožja neposredno vključimo v model in jezikovne sestavine vključimo v mrežo, da bi se lahko osredotočili na dele odgovora in ne na njene enojne besede za ustvarjanje bolj naravnega rezultata. Z optimizacijo te arhitekture smo uspeli doseči skoraj človeške rezultate in konkurenčni najsodobnejšemu sistemu na podatkovnih nizih SQuAD oziroma MS-MARCO.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་སྐད་ཡིག་གཟུགས་ལས་གཞི་རྟེན་བའི་ཐབས་ལམ་གསར་བ་ཞིག་སྤྲོད་ཀྱི་ཡོད། དང་པོ་ན། ང་ཚོས་ཡིག་ཡུལ་གྱི་སྒྲིག་འགོད་ཀྱི་སྒྲིག་འགོད་ཅིག་ལ་གཏོང་བྱེད་ཀྱི་ཡོད། སྒྲིག་གཞུང་འདིས་གཞུང་གིས་གནད་དོན་གཉིས་གཞི་ལུགས་ཀྱི་ཐབས་ལམ་ཞིག་ལས་ཕན་ཐོགས Second, we feed the output of a constituency parser into the model directly and integrate linguistic constituents into the network to help it concentrate on chunks of an answer rather than on its single words for generating more natural output. By optimizing this architecture, we managed to obtain near-to-human-performance results and competitive to a state-of-the-art system on SQuAD and MS-MARCO datasets respectively.'}
{'en': 'Challenge or Empower : Revisiting Argumentation Quality in a News Editorial Corpus', 'ar': 'التحدي أو التمكين: إعادة النظر في جودة الجدال في مجموعة افتتاحية الأخبار', 'es': 'Desafiar o potenciar: Revisando la calidad de la argumentación en un corpus editorial de noticias', 'fr': "Défier ou responsabiliser\xa0: Revisiter la qualité de l'argumentation dans un corpus éditorial d'actualités", 'pt': 'Desafiar ou Empoderar: Revisitando a Qualidade da Argumentação em um Corpus Editorial de Notícias', 'ja': 'チャレンジまたはエンパワーメント：ニュース編集コーパスの議論の質を再検討する', 'zh': '挑战或授权:重审新闻编辑语料库中论质', 'ru': 'Вызов или полномочия: пересмотр качества аргументации в редакционном корпусе новостей', 'hi': 'चुनौती या सशक्तीकरण: एक समाचार संपादकीय कॉर्पस में तर्क गुणवत्ता revisiting', 'ga': 'Dúshlán nó Cumhachtú: Cáilíocht Argóintí a Athchuairt i gCorpas Eagarthóireachta Nuachta', 'hu': 'Kihívás vagy erősítés: Az érvelés minőségének felülvizsgálata egy hírszerkesztő testületben', 'el': 'Πρόκληση ή ενδυνάμωση: Επανεξέταση της ποιότητας επιχειρημάτων σε ένα συντακτικό σώμα ειδήσεων', 'it': "Sfida o potenziamento: rivedere la qualità dell'argomentazione in un corpus editoriale di notizie", 'lt': 'Iššūkis arba įgaliojimas: Argumentacijos kokybės persvarstymas naujienų redakcijos korpuse', 'ms': 'Challenge or Empower: Mengubah semula Kualiti Argumentation dalam Korpus Editorial Berita', 'ka': 'განსაზღვრება ან გასაზღვრება: აპგუმენტაციის გასაზღვრება', 'ml': 'ചല്ലേജ് അല്ലെങ്കില്\u200d അധികാരം: ഒരു വാര്\u200dത്ത എഡിറ്ററിയല്\u200d കൊര്\u200dപ്പുസില്\u200d അര്\u200dഗ്മെന്റേഷന്\u200dറെ ഗുണവും വീണ', 'kk': 'Жаңалық редакторлық корпус аргументациялық сапасы', 'mt': 'Sfida jew Setgħa: Reviżjoni tal-Kwalità tal-Argumentazzjoni f’Korp Editorjali tal-Aħbarijiet', 'mn': 'Төрсөлдөөн эсвэл хүчирхэг чадвар: Аргументацийн качестыг шинэчлэх', 'mk': 'Предизвик или овластувач: Ревизирање на квалитетот на аргументација во корпус за уредување вести', 'no': 'Challenge or Empower: Revising Argumentation Quality in a News Editorial Corpus', 'pl': 'Wyzwanie lub wzmocnienie: Przegląd jakości argumentacji w redakcji wiadomości', 'si': 'චාලන්ජ් නැත්තම් කාර්යාවක්: වාර්තාව සමාවකාරීය කොර්පුස් වලට ප්\u200dරතික්\u200dරියාත්මක විශේෂ', 'ro': 'Provocare sau împuternicire: Revizuirea calității argumentării într-un corp editorial de știri', 'sr': 'Izazov ili moć: Revizija kvalitete argumentacije u novinskom redaktorijskom korpusu', 'so': 'Challenge or Empower: Revisiting Argumentation Quality in a News Editorial Corpus', 'ta': 'சவால் அல்லது சக்தியாளர்: செய்தி தொகுப்பு கார்புஸில் திரும்ப திரும்புகிறது', 'sv': 'Utmaning eller makt: Revidering av argumentationskvalitet i en redaktionell nyhetskår', 'ur': 'Challenge or Empower: Revisiting Argumentation Quality in a News Editor Corpus', 'uz': 'Name', 'vi': 'Thi thách đấu hay làm thuê: Kiểm tra chất lượng tranh luận trong một ban mới', 'nl': 'Uitdaging of Empower: De kwaliteit van argumenten herzien in een redactioneel korpus', 'hr': 'Izazov ili nadmoć: Revizija kvalitete argumentacije u novinskom uredničkom korpusu', 'de': 'Herausforderung oder Befähigung: Revising Argumentation Quality in a News Editorial Corpus', 'bg': 'Предизвикателство или овластяване: преразглеждане на качеството на аргументирането в редакционен корпус на новините', 'da': 'Udfordring eller styrkelse: Revidering af argumentationskvaliteten i et nyhedskorpus', 'fa': 'Challenge or Empower: Revisiting Argumentation Quality in a News Editorial Corpus', 'ko': '도전 또는 권한 수여: 뉴스 편집 자료 라이브러리의 논변의 질을 재검토', 'sw': 'Changamoto au Muwezeshaji: Kubadili Uwango wa Ujadala wa Ujadala katika Corpus ya Mhariri wa Habari', 'af': "Opdrag of Krag: Hersiening van Argumentasie Kwaliteit in 'n Nuusredigeerder Korpus", 'tr': 'Challenge or Empower: Revisiting Argumentation Quality in a News Editor Corpus', 'sq': 'Sfida apo Mbështetësi: Rivizioni i cilësisë së argumentimit në një korpus editorial të lajmeve', 'hy': 'Հարտահրավեր կամ իշխանություն: Արգեմենտացիայի որակը նորությունների խմբագրական կորպուսում վերանայելը', 'bn': 'চ্যালেঞ্জ বা ক্ষমতাবান: সংবাদ সম্পাদক কোর্পাসে আর্গুমেন্টেশনের মান পুনরায় সংস্কার করা হচ্ছে', 'id': 'Tantangan atau Penguasa: Menyesuaikan Kualitas Argumentasi dalam Korpus Editorial Berita', 'az': 'challenge or empower: Revising Argumentation Quality in a News Editorial Corpus', 'bs': 'Izazov ili nadmoć: Revizija kvalitete argumentacije u novinskom uredničkom korpusu', 'cs': 'Výzva nebo posílení: Revitalizace kvality argumentů v redakčním sboru zpráv', 'am': 'የዜና አቀማመጥ ኮርፓስ ውስጥ አርማምኖት ጥሩ በማሻሻል ላይ', 'fi': 'Haaste tai voimaannuttaminen: Argumentaation laadun tarkistaminen uutistoimituksessa', 'et': 'Väljakutse või mõjuvõime: argumentide kvaliteedi läbivaatamine uudiste toimetamise korpuses', 'ca': "repte o empoderador: revisar la qualitat de l'argumentació en un Corpus editorial de notícies", 'jv': 'Delenge Uto emppower: Refsiting argument Quality nang Haji editorial corpus', 'ha': '@ action', 'he': 'אתגר או כוח: שינוי איכות התווכחות בקורפוס עיתונאי חדשות', 'sk': 'Izziv ali opolnomočenje: revidiranje kakovosti argumentacije v novinarskem uredniškem korpusu', 'bo': 'Challenge or Empower: Revisiting Argumentation Quality in a News Editorial Corpus'}
{'en': 'News editorials are said to shape public opinion, which makes them a powerful tool and an important source of political argumentation. However, rarely do ', 'ar': 'يقال أن المقالات الافتتاحية للأخبار تشكل الرأي العام ، مما يجعلها أداة قوية ومصدرًا مهمًا للجدل السياسي. ومع ذلك ، نادرًا ما تغير المقالات الافتتاحية موقف أي شخص من قضية ما تمامًا ، كما أنها لا تميل إلى المجادلة بشكل صريح (بل تتبع استراتيجية بلاغية خفية). إذن ، ماذا تعني جودة النقاش بالنسبة للافتتاحيات إذن؟ نحن نطور الفكرة القائلة بأن التحرير الفعال يتحدى القراء بموقف متعارض ، وفي نفس الوقت يعزز مهارات الجدل للقراء الذين يشاركون موقف التحرير - أو حتى يتحدى كلا الجانبين. لدراسة جودة الجدل بناءً على هذه الفكرة ، نقدم مجموعة جديدة من 1000 افتتاحية من New York Times ، مشروحة لتأثيرها الملحوظ جنبًا إلى جنب مع التوجهات السياسية للمضيفين. عند تحليل المجموعة ، وجدنا أن المعلقين ذوي التوجهات المختلفة يختلفون حول التأثير بشكل كبير. في حين أن 1٪ فقط من الافتتاحيات غيّرت موقف أي شخص ، فإن أكثر من 5٪ تفي بفكرتنا. نستنتج أن مجموعتنا تعمل كمورد مناسب لدراسة جودة الجدل في افتتاحيات الأخبار.', 'fr': "Les éditoriaux d'actualité façonnent l'opinion publique, ce qui en fait un outil puissant et une source importante d'argumentation politique. Cependant, il est rare que les éditoriaux modifient complètement la position de quelqu'un sur une question, et ils n'ont pas tendance à argumenter explicitement (mais suivent plutôt une stratégie rhétorique subtile). Alors, que signifie la qualité de l'argumentation pour les éditoriaux\xa0? Nous développons l'idée qu'un éditorial efficace défie les lecteurs ayant des positions opposées, tout en renforçant les capacités d'argumentation des lecteurs qui partagent la même position éditoriale, voire défient les deux parties. Pour étudier la qualité de l'argumentation basée sur cette notion, nous introduisons un nouveau corpus de 1000 éditoriaux du New York Times, annotés en fonction de leur effet perçu ainsi que des orientations politiques des commentateurs. En analysant le corpus, nous constatons que les annotateurs ayant une orientation différente sont en désaccord significatif sur l'effet. Alors que seulement 1\xa0% de tous les éditoriaux ont changé de position, plus de 5\xa0% répondent à notre idée. Nous concluons que notre corpus constitue une ressource appropriée pour étudier la qualité argumentative des éditoriaux d'actualité.", 'es': 'Se dice que los editoriales de noticias dan forma a la opinión pública, lo que los convierte en una herramienta poderosa y una fuente importante de argumentación política. Sin embargo, rara vez los editoriales cambian completamente la postura de alguien sobre un tema, ni tienden a argumentar explícitamente (sino que siguen una estrategia retórica sutil). Entonces, ¿qué significa la calidad de la argumentación para los editoriales? Desarrollamos la noción de que un editorial eficaz desafía a los lectores con posturas opuestas y, al mismo tiempo, fortalece las habilidades de argumentación de los lectores que comparten la postura del editorial, o incluso desafían a ambas partes. Para estudiar la calidad de la argumentación basada en esta noción, presentamos un nuevo corpus con 1000 editoriales del New York Times, anotados por su efecto percibido junto con las orientaciones políticas de los anotadores. Al analizar el corpus, encontramos que los anotadores con orientación diferente no están de acuerdo con el efecto de manera significativa. Si bien solo el 1% de todos los editoriales cambiaron la postura de cualquiera, más del 5% cumple con nuestra idea. Concluimos que nuestro corpus sirve como un recurso adecuado para estudiar la calidad de la argumentación de los editoriales de noticias.', 'pt': 'Diz-se que os editoriais de notícias moldam a opinião pública, o que os torna uma ferramenta poderosa e uma importante fonte de argumentação política. No entanto, raramente os editoriais mudam completamente a posição de alguém sobre um assunto, nem tendem a argumentar explicitamente (mas seguem uma estratégia retórica sutil). Então, o que a qualidade da argumentação significa para os editoriais então? Desenvolvemos a noção de que um editorial eficaz desafia os leitores com posições opostas e, ao mesmo tempo, fortalece as habilidades de argumentação dos leitores que compartilham a posição do editorial – ou mesmo desafiam os dois lados. Para estudar a qualidade da argumentação com base nessa noção, apresentamos um novo corpus com 1000 editoriais do New York Times, anotados por seu efeito percebido junto com as orientações políticas dos anotadores. Analisando o corpus, descobrimos que anotadores com diferentes orientações discordam significativamente do efeito. Enquanto apenas 1% de todos os editoriais mudaram a postura de alguém, mais de 5% atendem à nossa noção. Concluímos que nosso corpus serve como um recurso adequado para estudar a qualidade argumentativa de editoriais de notícias.', 'ja': 'ニュース論説は世論を形成すると言われており、強力なツールであり、政治的議論の重要な源泉となっている。 しかし、社説は問題に対する誰のスタンスをも完全に変えることはほとんどなく、明確に議論する傾向もありません（むしろ微妙な言い回しの戦略に従います）。 では、議論の質は社説にとってどういう意味があるのでしょうか。 私たちは、効果的な編集が反対のスタンスで読者に挑戦すると同時に、編集のスタンスを共有する読者の議論スキルを強化するという考え方を展開します。 この概念に基づく議論の質を研究するために、私たちは、注釈者の政治的方向性と共に、その認識された効果について注釈された、ニューヨーク・タイムズの1000の社説を含む新しいコーパスを紹介します。 コーパスを分析すると、異なる方向を持つ注釈者が効果について有意に意見が合わないことがわかります。 すべての社説のわずか1%が誰のスタンスも変えましたが、5%以上が私たちの考えを満たしています。 私たちのコーパスは、ニュース編集部の議論の質を研究するのに適したリソースとして機能していると結論付けます。', 'zh': '盖闻新闻社论造公论,此为强大之具,亦政论之要源也。 然社论少变易,不向明争(循微修辞策)。 然则论质于社论者何也? 有效者社论反之,与社论同者争巧 。 考其大概,引入一新语料库,包《纽约时报》1000篇社论,社论因其感知效及注者之政取向而注之。 论语料库,见异方注者显异。 虽有1%之社论,变易何人,甚于5%合吾心。 吾之所论,吾语料库是论新闻社之宜也。', 'ru': 'Редакционные статьи, как утверждается, формируют общественное мнение, что делает их мощным инструментом и важным источником политической аргументации. Тем не менее, редко редакционные статьи полностью меняют чью-либо позицию по вопросу, и они не склонны открыто спорить (а скорее следуют тонкой риторической стратегии). Итак, что же значит качество аргументации для редакции? Мы развиваем представление о том, что эффективная редакция бросает вызов читателям с противоположной позицией, и в то же время расширяет спорные навыки читателей, которые разделяют позицию редакции — или даже бросают вызов обеим сторонам. Чтобы изучить качество аргументации, основанной на этом понятии, мы вводим новый корпус с 1000 редакционных статей из Нью-Йорк Таймс, аннотированных для их воспринимаемого эффекта вместе с политическими ориентациями аннотаторов. Анализируя корпус, мы обнаруживаем, что аннотаторы с разной ориентацией существенно расходятся во мнениях по поводу эффекта. В то время как только 1% всех редакционных статей изменили чью-либо позицию, более 5% соответствуют нашему представлению. Мы делаем вывод, что наш корпус служит подходящим ресурсом для изучения качества аргументации редакционных статей.', 'hi': 'समाचार संपादकीय को जनता की राय को आकार देने के लिए कहा जाता है, जो उन्हें एक शक्तिशाली उपकरण और राजनीतिक तर्क का एक महत्वपूर्ण स्रोत बनाता है। हालांकि, शायद ही कभी संपादकीय किसी मुद्दे पर किसी के रुख को पूरी तरह से बदलते हैं, न ही वे स्पष्ट रूप से बहस करते हैं (बल्कि एक सूक्ष्म बयानबाजी रणनीति का पालन करते हैं)। तो, तो संपादकीय के लिए तर्क गुणवत्ता का क्या मतलब है? हम इस धारणा को विकसित करते हैं कि एक प्रभावी संपादकीय पाठकों को विरोधी रुख के साथ चुनौती देता है, और एक ही समय में पाठकों के तर्क कौशल को सशक्त बनाता है जो संपादकीय के रुख को साझा करते हैं - या यहां तक कि दोनों पक्षों को भी चुनौती देते हैं। इस धारणा के आधार पर तर्क गुणवत्ता का अध्ययन करने के लिए, हम न्यूयॉर्क टाइम्स से 1000 संपादकीय के साथ एक नया कॉर्पस पेश करते हैं, जो एनोटेटरों के राजनीतिक झुकाव के साथ-साथ उनके कथित प्रभाव के लिए एनोटेट किया गया है। कॉर्पस का विश्लेषण करते हुए, हम पाते हैं कि विभिन्न अभिविन्यास वाले एनोटेटर प्रभाव पर काफी असहमत हैं। जबकि सभी संपादकीय के केवल 1% ने किसी के रुख को बदल दिया, 5% से अधिक हमारी धारणा को पूरा करते हैं। हम निष्कर्ष निकालते हैं कि हमारा कॉर्पस समाचार संपादकीय की तर्क गुणवत्ता का अध्ययन करने के लिए एक उपयुक्त संसाधन के रूप में कार्य करता है।', 'ga': "Deirtear go múnlaíonn eagarthóireachta nuachta tuairim an phobail, rud a fhágann gur uirlis chumhachtach iad agus gur foinse thábhachtach argóinte polaitiúla iad. Mar sin féin, is annamh a athraíonn eagarthóireachta seasamh aon duine ar cheist go hiomlán, agus ní gnách leo argóint go sonrach a dhéanamh (ach straitéis reitriciúil subtle a leanúint). Mar sin, cad a chiallaíonn cáilíocht argóinte d'eagarthóireacht mar sin? Forbraíonn muid an nóisean go dtugann eagarthóireacht éifeachtach dúshlán do léitheoirí seasamh codarsnachta, agus ag an am céanna cumhacht a thabhairt do scileanna argóinte na léitheoirí a roinneann seasamh na heagarthóireachta — nó fiú dúshlán an dá thaobh. Chun staidéar a dhéanamh ar cháilíocht na hargóintí atá bunaithe ar an nóisean seo, tugaimid isteach corpas nua ina bhfuil 1000 eagrán ón New York Times, a bhfuil anót déanta orthu mar gheall ar a n-éifeacht braite mar aon le treoshuíomh polaitíochta na naótairí. Agus anailís á déanamh againn ar an gcorpas, feicimid nach n-aontaíonn go mór le nótaíoirí a bhfuil treoshuíomh éagsúil acu maidir leis an éifeacht. Cé nár athraigh ach 1% de na heagarthóireacht ar fad seasamh duine ar bith, comhlíonann níos mó ná 5% ár nóisean. Bainimid de thátal as go bhfeidhmíonn ár gcorpas mar acmhainn oiriúnach chun staidéar a dhéanamh ar cháilíocht argóinte na n-eagarthóireacht nuachta.", 'el': 'Τα άρθρα ειδήσεων λένε ότι διαμορφώνουν την κοινή γνώμη, γεγονός που τα καθιστά ισχυρό εργαλείο και σημαντική πηγή πολιτικής επιχειρηματολογίας. Ωστόσο, σπάνια τα άρθρα αλλάζουν εντελώς τη στάση κάποιου σε ένα θέμα, ούτε τείνουν να διαφωνούν ρητά (αλλά μάλλον ακολουθούν μια λεπτή ρητορική στρατηγική). Τι σημαίνει λοιπόν η ποιότητα επιχειρηματολογίας για τα άρθρα; Αναπτύσσουμε την ιδέα ότι μια αποτελεσματική σύνταξη προκαλεί τους αναγνώστες με αντίθετη στάση, και ταυτόχρονα ενδυναμώνει τις δεξιότητες επιχειρηματολογίας των αναγνωστών που μοιράζονται τη στάση του συντάκτη ή ακόμη και τις δύο πλευρές. Για να μελετήσουμε την ποιότητα της επιχειρηματολογίας με βάση αυτή την έννοια, εισάγουμε ένα νέο σώμα με χιλιάδες άρθρα από τους New York Times, σχολιασμένα για την αντιληπτή τους επίδραση μαζί με τους πολιτικούς προσανατολισμούς των σχολιαστών. Αναλύοντας το σώμα, διαπιστώνουμε ότι σχολιαστές με διαφορετικό προσανατολισμό διαφωνούν σημαντικά για το αποτέλεσμα. Ενώ μόνο ένα% όλων των εκδόσεων άλλαξε τη στάση κάποιου, περισσότερο από 5% ανταποκρίνονται στην ιδέα μας. Συμπεραίνουμε ότι το σώμα μας χρησιμεύει ως κατάλληλος πόρος για τη μελέτη της ποιότητας επιχειρηματολογίας των εκδόσεων ειδήσεων.', 'hu': 'A hírszerkesztők állítólag alakítják a közvéleményt, ami hatékony eszközzé és fontos politikai érvelési forrássá teszi őket. Azonban ritkán változtatják meg bárki álláspontját egy kérdésben, és nem hajlamosak kifejezetten vitatkozni (hanem finom retorikai stratégiát követni). Tehát mit jelent az érvelés minősége a szerkesztők számára? Kifejlesztjük azt az elképzelést, hogy egy hatékony szerkesztőség ellentétes állásponttal hívja fel az olvasókat, ugyanakkor erősíti a szerkesztőség álláspontját osztó olvasók vitatkozó képességeit, sőt akár mindkét oldalt kihívja. Az érvelés minőségének tanulmányozására ezen elképzelésen alapuló új korpuszt vezetünk be a New York Times 1000 szerkesztőjéből, amelyeket az érzékelt hatásukról és a kommentátorok politikai iránymutatásairól jegyzetelünk fel. A korpusz elemzésével úgy találjuk, hogy a különböző orientációjú kommentátorok jelentősen nem értenek egyet a hatással kapcsolatban. Míg a szerkesztők mindössze 1%-a változtatta meg bárki álláspontját, több mint 5% felel meg elképzelésünknek. Arra a következtetésre jutunk, hogy korpuszunk megfelelő forrásként szolgál a hírszerkesztők érvelési minőségének tanulmányozására.', 'it': "Si dice che gli editoriali di notizie formino l'opinione pubblica, il che li rende un potente strumento e un'importante fonte di argomentazione politica. Tuttavia, raramente gli editoriali cambiano completamente la posizione di qualcuno su un argomento, né tendono a discutere esplicitamente (ma piuttosto a seguire una sottile strategia retorica). Quindi, cosa significa la qualità dell'argomentazione per gli editoriali? Sviluppiamo l'idea che un editoriale efficace sfida i lettori con posizioni opposte, e allo stesso tempo potenzia le capacità argomentative dei lettori che condividono la posizione dell'editoriale - o addirittura sfida entrambe le parti. Per studiare la qualità dell'argomentazione basata su questa nozione, introduciamo un nuovo corpus con 1000 editoriali del New York Times, annotati per il loro effetto percepito insieme agli orientamenti politici degli commentatori. Analizzando il corpus, scopriamo che gli annotatori con orientamento diverso non sono d'accordo sull'effetto in modo significativo. Mentre solo l'1% di tutti gli editoriali ha cambiato la posizione di qualcuno, più del 5% soddisfa la nostra idea. Concludiamo che il nostro corpus serve come una risorsa adatta per studiare la qualità dell'argomentazione degli editoriali di notizie.", 'kk': 'Жаңалық редакторлары көпшілік ойларды түрлендіру деп айтылады, бұл оларды күшті құрал мен саяси аргументтерінің маңызды көзі болады. Бірақ редакторлар кез-келген мәселеге қатынасын өзгертпейді. Олар өзгертілмейді (бірақ әдімгі реторикалық стратегиясына қарай қарайды). Сондықтан өңдеу үшін аргументациялық сапасы не деген? Біз оқушылардың оқушыларының қарсы жағдайда оқушыларының әсері көмегімен оқушыларының көмегімен, сондай-ақ оқушылардың көмегімен бөлінген оқушыларының көмегімен, немесе екі жағынан қарсы көме Бұл ойымен негізделген аргументациялық сапатын зерттеу үшін, New York Times-тың 1000 редакторлық корпус келтіріп, олардың түсініктерінің саяси бағыттаулары мен бірге жаңа корпус береді. Корпусты анализ ету үшін біз айырмалы бағыттауларының эффектіне көбірек емес деп ойлаймыз. Бүкіл редакторлардың тек 1% ғана адамдардың нәтижесін өзгертіп тұрғанда, 5% ден артық біздің ойымызға сәйкес келеді. Біз корпус жаңалық редакторлардың аргументациялық сапатын оқу үшін жақсы ресурс ретінде жұмыс істейді.', 'lt': 'Pasakyta, kad naujienų redakciniai leidiniai formuoja viešąją nuomonę, todėl jie tampa galinga priemone ir svarbiu politinių argumentų šaltiniu. Vis dėlto redakciniai leidiniai retai visiškai keičia bet kurio požiūrį į šį klausimą, jie taip pat nėra linkę aiškiai argumentuoti (bet labiau laikytis subtilesnės retorinės strategijos). Taigi, ką reiškia argumentų kokybė redakciniams leidiniams? Mes plėtojame koncepciją, kad veiksmingas redakcinis iššūkis kelia priešingą poziciją turintiems skaitytojams ir tuo pat metu suteikia galimybę ginčytis skaitytojų, kurie dalijasi redakcinio požiūrio pozicija, įgūdžius arba net iššūkius abiem pusėms. Siekdami išnagrinėti argumentų kokybę, pagrįstą šia sąvoka, įvedame naują korpusą su 1000 New York Times redakcinių leidinių, anotuotų dėl jų suvokimo poveikio kartu su anotatorių politinėmis orientacijomis. Analizuojant korpusą, matome, kad skirtingos orientacijos anotatoriai labai nesutinka su poveikiu. Nors tik 1 proc. visų redaktorių pakeitė bet kurio poziciją, daugiau kaip 5 proc. atitinka mūs ų idėją. Mes darome išvadą, kad mūsų korpusas yra tinkamas išteklius naujienų redakcinių leidinių argumentavimo kokybei studijuoti.', 'mk': 'Вестинските уредници се вели дека формираат јавно мислење, што ги прави моќни алатки и важен извор на политички аргументи. Сепак, редакторите ретко го менуваат ставот на некој во врска со прашањето целосно, ниту тие имаат тенденција да се расправаат експлицитно (туку да следат суптилна реторичка стратегија). Што значи квалитетот на аргументацијата за уредниците тогаш? Ние ја развиваме идејата дека ефикасниот уреднички предизвик ги предизвикува читателите со спротивен став, а истовремено ги поттикнува расправните вештини на читателите кои го делат ставот на уредничкиот - или дури и предизвикуваат двете страни. За да го проучуваме квалитетот на аргументацијата базиран на оваа идеја, воведуваме нов корпус со 1000 уредници од Њујорк Тајмс, анотирани за нивниот перцептиран ефект заедно со политичките ориентации на анотаторите. Analyzing the corpus, we find that annotators with different orientation disagree on the effect significantly.  Иако само 1% од сите уредници го променија ставот на било кој, повеќе од 5% го исполнуваат нашето мислење. Завршуваме дека нашиот корпус служи како соодветен ресурс за проучување на квалитетот на аргументацијата на новинските уредници.', 'ka': 'ახალგაზომის რედაქტორიალების შესახებ, რომელიც ისინი ძალიან ხელსაწყო და პოლიტიკური არგუმენტიის მნიშვნელოვანი გამოიყენება. მაგრამ რედაქტორიალები წარმოდგენიან, რომელიც ყველას პრობლემაზე სრულად ცვლილება, და ისინი არ უნდა გააკეთება მხოლოდ (მაგრამ უფრო გააკეთება სტრუქტური რეტორიკალ ამიტომ, რას ნიშნავს არგუმენტაციის კალგატი რედაქტორიებისთვის? ჩვენ განვითარებით, რომ ეფექტიური რედაქტიური გამოცდილება კითხველებს, რომლებიც შეცდომარებული სტანციაში, და ერთადერთი დროში უფრო ძლიერებს კითხველების განსხვავებული სტანციაზე, რომლებიც რედაქტიურის სტან აპროგმენტის კალეტის შესახებ ამ წარმოდგენისთვის, ჩვენ ახალი კორპუსს ჩვენ ჩვენ შევცვალოთ ნუ იორკო რაიმსგან 1000 რედატორიალების შესახებ, რომელსაც ჩვენი აღმოჩენა ეფექტის კორპუსს ანალიზაციას, ჩვენ აღმოჩნეთ, რომ ანალიზაციები განსხვავებული ორიზაციაციაზე მნიშვნელოვანია ეფექტზე. მაგრამ მხოლოდ 1% ყველა რედაქტორიების სტანციას შეცვლა, 5% უფრო მეტი ჩვენი წარმოდგენა. ჩვენ დავაკეთებთ, რომ ჩვენი კორპუსი იყენება საჭირო რესურსის შესახებ ახალგაზრულების კოლექტურის გასწავლებისთვის.', 'ms': 'Editorial berita dikatakan membentuk pendapat awam, yang menjadikannya alat yang kuat dan sumber penting argumen politik. Bagaimanapun, jarang editorial mengubah pendapat sesiapa mengenai isu sepenuhnya, dan mereka tidak cenderung untuk berdebat secara eksplicit (tetapi lebih suka mengikut strategi retorik halus). So, what does argumentation quality mean for editorials then?  Kami mengembangkan gagasan bahawa pembaca cabaran editorial yang berkesan dengan kedudukan lawan, dan pada masa yang sama memberikan kuasa berjuang kemampuan pembaca yang berkongsi kedudukan editorial - atau bahkan cabaran kedua-dua pihak. Untuk mempelajari kualiti argumen berdasarkan gagasan ini, kami memperkenalkan korpus baru dengan 1000 editorial dari New York Times, ditandai untuk kesan yang mereka perhatikan bersama dengan orientasi politik annotator. Menganalisis korpus, kami mendapati bahawa annotator dengan orientasi berbeza tidak setuju pada kesan yang signifikan. Sementara hanya 1% dari semua editorial mengubah posisi sesiapa pun, lebih dari 5% memenuhi gagasan kita. We conclude that our corpus serves as a suitable resource for studying the argumentation quality of news editorials.', 'ml': "വാര്\u200dത്ത എഡിറ്ററിയലുകള്\u200d പൊതുവായ അഭിപ്രായത്തെ രൂപിക്കാന്\u200d പറയുന്നു. അത് അവരെ ശക്തിയുള്ള ഉപകരണവും രാഷ്ട്രീയ എങ്കിലും ഒരു കാര്യത്തില്\u200d ആരുടെയും സ്ഥിതി പൂര്\u200dണ്ണമായും മാറ്റുന്നത് വളരെ കുറച്ച് പ്രധാനപ്പെട്ടാണ്, അവര്\u200d വ്യക്തമായി വാദിക്കുന്നതു അതുകൊണ്ട്, എന്താണ് വാദ്യാഭ്യാസത്തിന്റെ ഗുണത്തിന്റെ അര്\u200dഥം? ഒരു സ്ഥിതിയുമായി വായിക്കുന്നവര്\u200dക്ക് വിരോധമുണ്ടാക്കുന്ന സ്ഥിതിയില്\u200d പ്രധാനപ്പെട്ട വിലാസങ്ങള്\u200d വായിക്കുന്നത് നമ്മള്\u200d നിര്\u200dമ്മിക്കുന് ഈ ആശയത്തിന്\u200dറെ അടിസ്ഥാനമായി വാദിക്കുന്നതിന് വേണ്ടി നമ്മള്\u200d ന്യൂയോര്\u200dക്ക് ടൈമില്\u200d നിന്നും 1000 എഡിറ്ററിയലുകളുമായ ഒരു പുതിയ കോര്\u200dപ്പസ് പരി കോര്\u200dപ്പുസിനെ അന്വേഷിക്കുന്നു, വ്യത്യസ്ത ഭാഗത്തിലുള്ള അഭിപ്രായമുള്ളവര്\u200dക്ക് വ്യത്യസ്തമായ ഭിന്നതയില്\u200d വ While only 1% of all editorials changed anyone's stance, more than 5% meet our notion.  ഞങ്ങള്\u200d തീരുമാനിക്കുന്നത് നമ്മുടെ കോര്\u200dപ്പുസ് വിഭവങ്ങളായി സേവിക്കുന്നു വാര്\u200dത്തകള്\u200d എഡിറ്ററിയലുകളുടെ വ്യ", 'no': 'Dette blir sagt at nye redigeringar skal formere offentlig tanke, som gjer dei ein kraftig verktøy og ein viktig kjelde for politiske argumentasjon. Men ofte endrar redigeringar noen stasjon på eit problem fullstendig, og vanskeleg ikkje å argumentere ekspliskt (men følgjer heller ein subtil retorisk strategi). Så kva betyr argumentasjonskvalitet for redigeringar så? Vi utviklar oppmerkinga på at ein effektiv redigeringsutfordring av lesarar med motstanden, og samtidig styrer argumentasjonen av lesarar som deler redigeringsstasjonen - eller til og med utfordring av begge sider. For å studera argumentasjonskvalitet basert på denne merkinga, introdusere vi ein ny korpus med 1000 redigeringar frå New York Times, merket på at dei oppfatte effekten saman med politiske orientasjonar av annotatorar. Dersom vi analyserer korpusen, finn vi at annotatorar med ulike orientasjonar ikkje er samsvar med effekten. Mens berre 1% av alle redigeringar endra noen sin stasjon, må fleire enn 5% oppfylle vårt noe. Vi avsluttar at korpusen vårt tjener som eit passende ressurs for å studera argumentasjonskvaliteten på nyhetsgradiorer.', 'pl': 'Redakcje informacyjne mają kształtować opinię publiczną, co czyni je potężnym narzędziem i ważnym źródłem argumentacji politycznych. Rzadko jednak artykuły redakcyjne zmieniają całkowicie czyjeś stanowisko w danej sprawie, ani nie mają tendencji do wyraźnego argumentowania (a raczej podążają za subtelną strategią retoryczną). Co więc oznacza jakość argumentacji dla artykułów redakcyjnych? Rozwijamy pojęcie, że efektywna redakcja wyzwania czytelników przeciwnym stanowiskiem, a jednocześnie wzmacnia umiejętności argumentowania czytelników, którzy podzielają stanowisko redakcji, a nawet wyzwania obie strony. Aby zbadać jakość argumentacji opartą na tym pojęciu, wprowadzamy nowy korpus zawierający tysiące artykułów redakcyjnych z New York Times, adnotacji pod kątem ich postrzeganego efektu wraz z orientacjami politycznymi adnotatorów. Analizując korpus, stwierdzimy, że adnotatory o różnej orientacji znacząco się nie zgadzają co do efektu. Podczas gdy tylko 1% wszystkich artykułów zmieniło stanowisko, ponad 5% spełniają naszą ideę. Stwierdzamy, że nasz korpus służy jako odpowiedni źródło do badania jakości argumentacji artykułów wiadomościowych.', 'mn': 'Шинэ мэдээллийн захирагчид олон нийтийн үзэл санааг үүсгэдэг. Энэ нь тэднийг хүчирхэг хэрэгсэл болон улс төрийн тухай чухал эх үүсвэр болгодог. Гэхдээ хэн нэгний асуудал дээр тулгарч байгаа захирагчид ямар нэгэн бодит байдлыг бүрэн өөрчилж чадахгүй. Эсвэл тэд тодорхой хэлэлцдэггүй. Тэгэхээр захирагчид ямар утгатай вэ? Бид өөрсдийгөө эсрэг байдалтай уншигчдын үр дүнтэй редакцион сорилт уншигчдын тухай ойлголт гаргаж, мөн адил зохиолын байр суурь хуваалцах уншигчдын чадварыг хүчээр зориулдаг. Энэ ойлголтын үндсэн аргументын сайн талаар судлах үед бид Нью Йорк Таймс дахь 1000 зохиолчдын шинэ корпус танилцуулж, тэдний ойлголтын нөлөө нь тэдний сэтгэл хөдлөл, сэтгэл хөдлөлийн улс төрийн байрлал Корпусын шинжилгээнд бид өөр чиглэлтэй анзаарагчид нөлөөнд маш чухал биш гэдгийг олж мэднэ. Бүх захирагчийн 1% нь хүний нөхцөл байдлыг өөрчилсөн ч 5% нь илүү бидний бодлоор танилцдаг. Бид корпус мэдээллийн захирагчийн аргументын сайн талаар судлах боломжтой баялаг болсон.', 'ro': 'Se spune că editorialele de știri modelează opinia publică, ceea ce le face un instrument puternic și o sursă importantă de argumentare politică. Cu toate acestea, rareori editorialele schimbă complet poziția cuiva asupra unei probleme și nici nu tind să argumenteze explicit (ci mai degrabă să urmeze o strategie retorică subtilă). Deci, ce înseamnă calitatea argumentării pentru editorialii atunci? Dezvoltăm ideea că un editorial eficient provoacă cititorii cu poziție opusă și, în același timp, împuternicește abilitățile de argumentare ale cititorilor care împărtășesc poziția editorialului - sau chiar provoacă ambele părți. Pentru a studia calitatea argumentației bazată pe această noțiune, introducem un nou corpus cu 1000 de editoriale de la New York Times, adnotate pentru efectul lor perceput împreună cu orientările politice ale adnotatorilor. Analizând corpul, constatăm că adnotatorii cu orientare diferită nu sunt de acord cu efectul în mod semnificativ. În timp ce doar 1% din toate editorialele au schimbat poziția cuiva, mai mult de 5% îndeplinesc noțiunea noastră. Concluzionăm că corpul nostru servește ca o resursă adecvată pentru studierea calității argumentației editorialelor de știri.', 'so': 'News editorials are said to shape public opinion, which makes them a powerful tool and an important source of political argumentation.  Si kastaba ha ahaatee tahririyiintu waxey si yaraan u bedeshaan qofna aragtidiisa si buuxda ah, mana ay leeyihiin inay si cad ula doodaan (laakiin raaca qoraal cilmi ah). marka, maxay micneheeda qiimaha hadalka looga jeedaa sawirida? Waxaynu horumarinaynaa fikrada saqli ah in kuwa akhriya is-akhriyaya ay is-hor-jeedaan, isla markaasna wuxuu awoodaa xirfadaha warqadda u dooda ee akhriyada sharciya xaaladda hagitaanka- ama xataa dhibaatooyinka labada dhinac. Si aan u barano takhasuska dooda ee fikradan darteed, waxaynu soo bandhignaynaa qof cusub oo ay ka yimaadaan 1000 tahririyaal oo ka yimid New York Times, taas oo lagu caddeeyey waxyaabahooda la gartay iyo hagitaanka siyaasadeeda ee macaamilooda. Anaalbaarinta qoyska, waxaynu aragnaa in qofka ku takhasusay hagitaanka kala duduwan ay si muhiim ah u kala duwan yihiin saamaynta. Inta lagu jiro boqolkiiba 1 boqolkiiba oo dhan ayaa beddelay xaalada qof, waxaa ka badan 5 % oo ka tirsan fikradayaga. Waxaynu ku dhamaynaynaa in korpuskeenu uu u adeego sida nolol haboon in lagu barayo takhasuska hagitaanka warbixinta.', 'sv': 'Nyhetsreditioner sägs forma den allmänna opinionen, vilket gör dem till ett kraftfullt verktyg och en viktig källa till politisk argumentation. Men sällan ändrar redaktionerna någons ståndpunkt i en fråga helt och hållet, inte heller tenderar de att argumentera uttryckligen (utan snarare följa en subtil retorisk strategi). Så, vad betyder argumentationskvalitet för redaktörer då? Vi utvecklar uppfattningen att en effektiv redaktion utmanar läsarna med motsatt ställningstagande, och samtidigt stärker argumenterande färdigheter hos läsare som delar redaktionens ställningstagande - eller till och med utmanar båda sidor. För att studera argumentationskvaliteten utifrån detta begrepp introducerar vi en ny korpus med 1000 redaktörer från New York Times, kommenterade för deras upplevda effekt tillsammans med kommentatorernas politiska riktlinjer. Genom att analysera korpusen finner vi att kommentatorer med olika inriktning är oense om effekten avsevärt. Medan bara 1% av alla redaktioner ändrade någons ståndpunkt, uppfyller mer än 5% vår uppfattning. Vi drar slutsatsen att vår korpus fungerar som en lämplig resurs för att studera argumentationskvaliteten hos nyhetsredaktörer.', 'ta': "செய்தி தொகுப்பாளர்கள் பொது கருத்தை உருவாக்க கூறுகிறார் However, rarely do editorials change anyone's stance on an issue completely, nor do they tend to argue explicitly (but rather follow a subtle rhetorical strategy).  பின்னர் தொகுப்பாளர்களுக்கான தர்க்கம் தரம் என்ன? நாம் ஒரு விருப்பமான தொகுப்பு சவால்களை படிப்பவர்களுக்கு எதிரான நிலையுடன் உருவாக்குகிறோம் என்று நினைப்பை உருவாக்குகிறோம், அதே நேரத்தில் தொகுப் இந்த கருத்தை அடிப்படையிலான தருக்கூறு தரம் படிப்பதற்கு, நியூயார்க் டைமாஸில் இருந்து 1000 தொகுப்பாளர்களை நாம் ஒரு புதிய குறியீட்டை அறிவிக்க கோர்பாஸ் ஆய்வு செய்து, வேறு திசையில் வித்தியாசமான விளைவுக்கு வித்தியாசம் இல்லை என்று நாம் கண்டுபிடி அனைத்து தொகுப்பாளர்களில் மட்டும் 1% மட்டுமே யாருடைய நிலையை மாற்றினால், 5% க்கு மேற்பட்ட நினைவுகளை  நாங்கள் முடிவு என்று நம் கோர்ப்ஸ் செய்தி தொகுப்பாளர்களின் தருமதிப்பு தரம் படிக்க ஒரு பொருத்தமான மூலமாக சேவைக்", 'mt': "L-editorjali tal-a ħbarijiet jgħidu li jiffurmaw l-opinjoni pubblika, li tagħmlilhom għodda b’saħħitha u sors importanti ta’ argumentazzjoni politika. Madankollu, rarament l-editorjali jibdlu l-pożizzjoni ta’ xi ħadd dwar kwistjoni kompletament, u lanqas ma għandhom it-tendenza li jargumentaw b’mod espliċitu (iżda pjuttost isegwu strateġija retorika subtili). Għalhekk, x’tfisser il-kwalità tal-argumentazzjoni għall-editorjali? Aħna niżviluppaw il-kunċett li kunċett editorjali effettiv jisfida lill-qarrejja b'pożizzjoni opposta, u fl-istess ħin jagħti s-setgħa lill-ħiliet argumentattivi tal-qarrejja li jaqsmu l-pożizzjoni editorjali - jew saħansitra jisfidaw iż-żewġ naħat. To study argumentation quality based on this notion, we introduce a new corpus with 1000 editorials from the New York Times, annotated for their perceived effect along with the annotators' political orientations.  Fl-analiżi tal-korpus, isibu li l-annotaturi b’orjentazzjoni differenti ma jaqblux b’mod sinifikanti dwar l-effett. Filwaqt li 1% biss tal-editorjali kollha biddlu l-pożizzjoni ta' ħadd, aktar minn 5% jilħqu l-kunċett tagħna. Aħna kkonkludew li l-korpus tagħna jservi bħala riżorsa xierqa għall-istudju tal-kwalità tal-argumentazzjoni tal-editorjali tal-a ħbarijiet.", 'sr': 'Rečeno je da novinski urednici oblikuju javno mišljenje, što ih čini moćnim alatom i važnim izvorom političke argumentacije. Međutim, rijetko se editoriali menjaju stav bilo koga na pitanje u potpunosti, niti se uopšte raspravljaju jasno (ali radije prate suptilnu retoričku strategiju). Dakle, šta znači kvalitet argumentacije za editorije? Razvijamo ideju da učinkoviti editorialni izazovi čitača sa suprotnim stavom, i istovremeno omogućavaju svađujuće vještine čitača koji dijele stav editoriala ili čak izazivaju obje strane. Da bi studirali kvalitet argumentacije na osnovu ovog pojma, predstavili smo novog korpusa sa 1000 editora iz Njujorka Tajmsa, annotiranog za njihov percepcioni efekat zajedno sa političkim orijentacijom annotatora. Analizirajući korpus, našli smo da annotatori sa različitim orijentacijom se značajno ne slažu na efekt. Iako je samo 1% editora promijenilo stanje bilo koga, više od 5% ispunjavalo našu ideju. Zaključili smo da naš korpus služi kao odgovarajući resurs za proučavanje kvalitete argumentacije novinskih editoriala.', 'si': 'වාර්තාවක් සංපාදනය කරන්න කියලා කියලා සාමාජික විශ්වාස කරන්න, ඒකෙන් ඔවුන්ට ශක්තිමත් උපකරණයක් වග නමුත්, කිසිම විදියට සම්පූර්ණයෙන් කවුරුහරි ප්\u200dරශ්නයක් වෙනස් කරනවා කිසිම විදියට, ඒවගේම එයාලා ප්\u200dරශ්නයක් විදියට ක ඉතින්, මොකද්ද වාර්තාවක් තේරුම් ගන්නේ? අපි ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් සංපාදනය කරනවා කියලා ප්\u200dරශ්නයක් විරුද්ධ වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන අපි නිව්යෝර්ක් ටායිම්ස් වලින් ප්\u200dරශ්නයක් තියෙන අලුත් කොර්පස් එක්ක ප්\u200dරශ්නයක් තියෙනවා, ඔවුන්ගේ දැනගන්න ප්\u200dරශ්නයක් සමග කොර්පස් එක විශ්ලේෂණය කරනවා, අපි හොයාගන්නවා වෙනස් ප්\u200dරමාණයක් තියෙන අනතුරු වෙනුවෙන් ප්\u200dරතිකාර විශ සියලුම සංපාදනයේ 1% විතරයි කවුරුහරි ස්ථානය වෙනස් කරලා තියෙන්නේ, 5% විතරයි අපේ අදහසට හමුවෙන් අපි අවස්ථාව කරනවා අපේ කෝර්පුස් සේවා වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් විශේෂය', 'ur': 'اخبار اداریٹوریلیاں کہی جاتی ہیں کہ لوگوں کی نظر کی شکل کریں، جو ان کو ایک طاقتور ابزار بناتا ہے اور سیاسی اختلاف کا ایک اہم سراسر بناتا ہے۔ لیکن اصلاح بہت ہی کم ہے کہ کسی شخص کی موضوع پر پوری طرح تغییر دیتے ہیں اور نہ وہ صریح بحث کرنے والے ہیں تو، اس کے بعد اصلاح کیفیت کا معنی کیا ہے؟ ہم نے سمجھ رکھا ہے کہ ایک اثر اثر سمجھانے والی چالیں پڑھنے والوں کو مخالف موقعیت کے ساتھ پڑھنے والوں کو اور ایک دوسرے سے پڑھنے والوں کے جھگڑنے کی طاقتوں کو مضبوط کرتا ہے جو سمجھانے والی موقعیت کے ساتھ شریک ہیں - یا حتی دونوں جانوں کو چالیں بھی ہم نے نیویورک تایمز سے 1000 ایڈیٹوریل کے ساتھ ایک نوی کورپوس کو پہنچا دیا، جو ان کی نظر آئی اثر کے ساتھ ان کی سیاسی منظور کے ساتھ مشورہ کی۔ کورپوس کا تحقیق کرتا ہے، ہم دیکھتے ہیں کہ مختلف طریقے کے مطابق اثرات کے بارے میں مختلف ہیں. حالانکہ صرف سارے سمجھانے والوں میں سے ایک فیصد کس کی موقعیت بدل دی گئی ہے، پنج فیصد سے زیادہ ہماری نظر سے ملے گی۔ ہم نے فیصلہ کر دیا کہ ہمارا کورپوس اخبار ادٹوریل کے معاملہ کا مطالعہ کرنے کے لئے مناسب سرمایہ کے طور پر عمل کرتا ہے.', 'uz': "Yangi tahrirchalar, public opinion shaklini shaklga aytadi. Bu ularni kuchli asboblar va xavfsiz talabatlarining muhim manbasi qiladi. Lekin tahrirchalar hamma muammoni butunlay o'zgartirib o'zgartiradi va ular очиқ-ойдин ҳужжат bilan javob bermaydi (balki kichkina retorik strategiga эргашang). Ho'sh, ma'lumot tahrirchalarning qiymati nima? Biz tasavvur qilamiz, tahrirchik muammolari o'quvchilarini boshqarish istalgan ta'minlovchi qiymatlar bilan o'quvchiga ega bo'ladimiz, va shu paytida tahrirlarning holatini qayta qiladigan o'quvchilarning qidirish imkoniyatini amalga oshirishingiz mumkin. Bu g'oya asosida o'rganish uchun, New York Times bilan 1000 tahrirchalar bilan yangi kompyuterni ishlab chiqaramiz. Bu tashkilotlarning qiziyatlari qo'shiyatlari bilan boshqarishni anglatdik. Korpusni taʼminlashtirish, biz har xil bir xil aniqlik bilan taʼminlovchilarni o'zgarishga juda muhim qiymatdir. Agar barcha tahrirchalardan faqat 1% odamning holatini o'zgartiradi, bizning fikrlarimizni 5% dan ortiq ko'proq ko'p ko'proq ko'rinadi. Biz murakkab qilamiz, bizning korpusiz yangiliklar tahrirchini o'rganish qiymatning sifatini o'rganish uchun juda yetarli manba deb hisoblanadi.", 'vi': 'Tin tức biên tập hình thành công luận, khiến họ trở thành một công cụ quyền lực và là một nguồn thuyết trình chính trị quan trọng. Tuy nhiên, hiếm khi các tạp chí thay đổi hoàn to àn quan điểm của người khác về vấn đề này, họ cũng không có xu hướng tranh luận trực tiếp (nhưng phải theo một chiến lược tu từ âm thầm kín). Vậy phẩm chất tranh luận có ý nghĩa gì với biên bản? Chúng tôi phát triển khái niệm rằng một bài biên tập hiệu quả thách thức những người đọc có tư thế đối lập, và đồng thời trao quyền cho những người đọc có cùng quan điểm hay thậm chí thách thức cả hai bên. Để nghiên cứu chất lượng luận dựa trên khái niệm này, chúng tôi giới thiệu một tập thể mới với hàng ngàn tạp chí xuất bản từ New York Times, được ghi chú cho kết quả nhận thức của họ cùng với các hướng dẫn chính trị gia. Phân tích tập thể, chúng tôi thấy rằng các nhà biên bản có hướng dẫn khác nhau bất đồng về hiệu quả. Trong khi đó chỉ một phần trăm các tạp chí thay đổi quan điểm của mọi người. Chúng tôi kết luận rằng tập đoàn chúng tôi là nguồn lực thích hợp để nghiên cứu chất lượng tranh luận của biên bản tin.', 'bg': 'Според журналистите оформят общественото мнение, което ги прави мощен инструмент и важен източник на политически аргументи. Въпреки това, рядко редакториалите променят напълно позицията на някого по даден въпрос, нито са склонни да спорят изрично (а по-скоро да следват фина реторична стратегия). Какво значи качеството на аргументацията за редакторите? Развиваме идеята, че ефективната редакция предизвиква читателите с противоположна позиция и същевременно овластява аргументиращите умения на читателите, които споделят позицията на редакцията - или дори предизвиква и двете страни. За да проучим качеството на аргументацията въз основа на това понятие, въвеждаме нов корпус с 1000 редактори от Ню Йорк Таймс, анотирани за възприемания им ефект заедно с политическите ориентации на анотаторите. Анализирайки корпуса, откриваме, че анотаторите с различна ориентация значително не са съгласни с ефекта. Докато само 1% от всички редактори са променили позицията на някого, повече от 5% отговарят на нашата представа. Заключваме, че нашият корпус служи като подходящ ресурс за изучаване качеството на аргументацията на редакторите на новините.', 'nl': 'Er wordt gezegd dat nieuwsberichten de publieke opinie vormgeven, waardoor ze een krachtig instrument en een belangrijke bron van politieke argumentatie zijn. Echter, zelden veranderen editorials iemands standpunt over een kwestie volledig, noch hebben ze de neiging om expliciet te discussiëren (maar eerder een subtiele retorische strategie te volgen). Wat betekent argumentatiekwaliteit dan voor editorials? We ontwikkelen het idee dat een effectieve redactie lezers uitdaagt met een tegengestelde houding, en tegelijkertijd de argumenterende vaardigheden versterkt van lezers die het standpunt van de redactie delen of zelfs beide kanten uitdagen. Om de kwaliteit van argumentatie op basis van dit idee te bestuderen, introduceren we een nieuw corpus met duizenden editorials van de New York Times, geannoteerd om hun waargenomen effect samen met de politieke oriëntaties van de annotators. Door het corpus te analyseren, blijkt dat annotatoren met verschillende oriëntatie het significant oneens zijn over het effect. Hoewel slechts 1% van alle editorials iemands standpunt veranderde, voldoet meer dan 5% aan onze opvatting. We concluderen dat ons corpus dient als een geschikte bron voor het bestuderen van de argumentatiekwaliteit van nieuwsberichten.', 'da': 'Nyhedsreditorier siges at forme den offentlige mening, hvilket gør dem til et kraftfuldt redskab og en vigtig kilde til politisk argumentation. Men sjældent ændrer redaktionerne nogens holdning til et emne fuldstændigt, og de har heller ikke tendens til at argumentere eksplicit (men følger snarere en subtil retorisk strategi). Så hvad betyder argumentationskvalitet for redaktører så? Vi udvikler tanken om, at en effektiv redaktion udfordrer læserne med modsat holdning, og samtidig styrker argumentfærdighederne hos læsere, der deler redaktionens holdning - eller endda udfordrer begge sider. For at studere argumentationskvalitet baseret på denne begreb introducerer vi et nyt korpus med 1000 redaktører fra New York Times, kommenteret for deres opfattede effekt sammen med kommentatorernes politiske orienteringer. Ved at analysere korpuset finder vi, at kommentatorer med forskellig orientering er uenige om effekten væsentligt. Mens kun 1% af alle redaktører ændrede nogens holdning, opfylder mere end 5% vores opfattelse. Vi konkluderer, at vores korpus tjener som en passende ressource til at studere argumentationskvaliteten af nyhedsreditorier.', 'de': 'Nachrichtenredaktionen sollen die öffentliche Meinung prägen, was sie zu einem mächtigen Werkzeug und einer wichtigen Quelle politischer Argumentation macht. Allerdings ändern Editorials selten die Haltung von jemandem zu einem Thema vollständig, noch tendieren sie dazu, explizit zu argumentieren (sondern folgen eher einer subtilen rhetorischen Strategie). Was bedeutet also Argumentationsqualität für Editorials? Wir entwickeln die Vorstellung, dass ein effektives Editorial Leser mit gegensätzlicher Haltung herausfordert und gleichzeitig die Argumentationsfähigkeiten von Lesern stärkt, die die Haltung des Editorials teilen oder sogar beide Seiten herausfordern. Um die Qualität der Argumentation auf dieser Grundlage zu untersuchen, führen wir ein neues Korpus mit 1000-Editorials der New York Times ein, das auf ihre wahrgenommene Wirkung und die politischen Orientierungen der Annotatoren hinweist. Bei der Analyse des Korpus stellen wir fest, dass Annotatoren mit unterschiedlicher Orientierung über den Effekt signifikant uneinig sind. Während nur ein Prozent aller Editorials die Haltung eines jeden veränderten, entsprechen mehr als 5% unserer Vorstellung. Wir schließen daraus, dass unser Korpus als geeignete Ressource für die Untersuchung der Argumentationsqualität von Nachrichtenartikeln dient.', 'fa': 'اداره\u200cهای خبری گفته می\u200cشود که نظر عمومی را شکل دهند، که آنها را یک ابزار قدرتمند و یک منبع مهم از بحث سیاسی می\u200cسازد. با این وجود، اصلاح\u200cها به سختی\u200cها وضعیت کسی را کاملاً در یک مسئله تغییر می\u200cدهند، و نمی\u200cتوانند به صورت مشخص بحث کنند (بلکه از طریق استراتژی\u200cهای مثبت پیروی کنید). پس کیفیت توضیح برای ویرایشگران چه معنی دارد؟ ما این نظر را توسعه می\u200cکنیم که یک چالش\u200cهای ویدئاتوری موثر برای خوانندگان با وضعیت مخالف، و در همین زمان توانایی\u200cهای مخالف خوانندگان را که وضعیت ویدئاتوری را شریک می\u200cکنند، یا حتی چالش\u200cهای هر دو طرف می\u200cکنند. برای مطالعه کیفیت بحث بر اساس این نظر، ما یک کورپوس جدید با 1000 ویدئاتوری از نیویورک تایمز معرفی می کنیم، که برای تاثیر مشاهده ایشان در کنار ارائه سیاسی آشنا شده است. تحلیل کردن کورپوس، ما پیدا می\u200cکنیم که آگاهی\u200cکننده\u200cها با ارتفاع مختلف بر اثر بسیار مخالف هستند. در حالی که فقط ۱ درصد از تمام اداره\u200cکننده\u200cها وضعیت هر کس را تغییر دادند، بیشتر از ۵ درصد از نظر ما را ملاقات می\u200cکنند. ما نتیجه می دهیم که کورپوس ما به عنوان یک منابع مناسب برای مطالعه کیفیت اختلاف ویدئاتوری های خبری خدمت می کند.', 'ko': '신문 사설은 대중 여론을 부각시켜 강력한 도구와 정치 변론의 중요한 원천이 된다고 한다.그러나 사설은 어떤 문제에 대한 누구의 입장도 완전히 바꿀 수 없고 명확하게 논쟁하는 경향이 없다(미묘한 수사 전략을 따르는 것이다).그렇다면 변론의 질은 사설에 무엇을 의미하는가?우리는 효과적인 사설이 상반된 입장으로 독자에게 도전하는 동시에 사설의 입장과 같은 독자의 변론 기교, 심지어 쌍방에 도전하는 것을 강화했다.이 개념을 바탕으로 한 논변의 질을 연구하기 위해 우리는 뉴욕타임스에서 나온 1000편의 사설을 포함하고 그들의 감지 효과와 주석자의 정치적 취향에 대해 주석을 달았다.어료 라이브러리에 대한 분석을 통해 우리는 서로 다른 취향의 주석자가 효과에 현저한 차이가 있음을 발견했다.단 1%의 사설만이 누구의 입장을 바꿨지만, 5%가 넘는 사설은 우리의 견해에 부합한다.우리의 결론은 우리의 어료고는 신문 사설 논변의 질을 연구하는 데 적합한 자원이라는 것이다.', 'sw': "Wahariri wa habari wanasemekana kuunda maoni ya umma, ambayo inawafanya kuwa nyenzo yenye nguvu na chanzo muhimu cha mazungumzo ya kisiasa. Hata hivyo, ni nadra mno wa wahariri hubadilisha msimamo wa mtu mwingine kwenye suala hili, wala hawajadili wazi (bali fuata mkakati mdogo wa maneno). Hivyo, ubora wa hoja unamaanisha nini kwa wahariri? Tunaendeleza dhana kwamba changamoto za kihariri yenye upinzani, na wakati huo huo tunawezesha ujuzi wa wasomaji ambao wanaelezea msimamo wa wahariri - au hata changamoto zote mbili. To study argumentation quality based on this notion, we introduce a new corpus with 1000 editorials from the New York Times, annotated for their perceived effect along with the annotators' political orientations.  Anachambua makampuni hayo, tunagundua kuwa wachochezaji wenye mtazamo tofauti hawana tofauti na athari kubwa. Wakati ni asilimia 1 tu ya wahariri wote walibadilisha msimamo wa mtu yeyote, zaidi ya asilimia 5 wanakutana na dhana yetu. Tunahitimisha kuwa makampuni yetu inahudumia kama rasilimali sahihi kwa kusoma ubora wa mazungumzo ya wahariri wa habari.", 'hr': 'Rečeno je da se novinski urednici oblikuju javno mišljenje, što ih čini moćnim alatom i važnim izvorom političke argumentacije. Međutim, rijetko se editoriali mijenjaju stav bilo koga na pitanje u potpunosti, niti se često raspravljaju (ali radije slijedite suptilnu retoričku strategiju). Dakle, što znači kvalitet argumentacije za urednike? Mi razvijamo pojam da učinkoviti urednički izazovi čitača sa suprotnim stavom, a istovremeno omogućavaju svađajuće vještine čitača koji dijele stav urednika ili čak izazivaju obje strane. Za proučavanje kvalitete argumentacije na temelju ovog pojma, predstavljamo novi korpus s 1000 editora iz New York Times-a, koji je navodio za njihov percepcioni učinak zajedno s političkim orientacijama annotatora. Analizirajući korpus, smatramo da se annotatori s različitim orijentacijom značajno ne slažu na učinak. Iako je samo 1% svih urednika promijenilo stanje bilo koga, više od 5% ispunjavalo našu ideju. Zaključili smo da naš korpus služi kao odgovarajući resurs za proučavanje kvalitete argumentacije novinskih urednika.', 'tr': "Täzelikler düzenleyici halk pikirini bejermek üçin a ýdylýar, bu olary güýçli bir araç we syýasy tartışmanyň wajyp çeşmesi bolýar. Ýöne editorialar birnäçeniň meselede nähili adamyň durumyny tamamlap üýtgetmeýärler, ýöne olar a çık-aydın tartışmagyna göz ýetirmezler (ýöne alçak bir retorial stratejiýany yzarlamak üçin). Peki, düzenlemek kalitesinden näme diýjek bolýar? Muny düşünýän bir düzenlemeli düzenlemeli kynçylyklar okuwçylaryň garşy kynçylyklaryny öwredýäris we şol wagtda Editorialyň durumyny paýlaşýan okuwçylaryň ukyplaryny üýtgedýäris - ýa-da hatta ikisiniň hem kynçylyklaryny üýtgedýäris. Bu düşünjege daýanýan tartışma kalitesini öwrenmek üçin New York Times'dan 1000 sany editorial bilen täze korpus bilen tanyşdyrýarys, nusgalanlaryň syýasy orjentasy bilen birlikde olaryň düşünleýän täsirini duýýarlar. Korpusu çözümlendirmek, farklı yöntem bilen sözleştiriciler etkisine hiç bir anlama düşmüyor. Diňe 1% hemme edişiniň durumyny üýtgetseň, 5% köp pikirimizi görüp biler. Biziň korpusymyz täzelikler editorialaryň a ýratyny öwrenmek üçin gowy bir çeşme hökmünde hökman edýäris diýip pikir edýäris.", 'af': "Nuusredigeerders word gesê om publieke opisie te vorm, wat hulle 'n kragtige hulpmiddel en 'n belangrike bron van politieke argumentasie maak. Maar selfs het redigeerders selfs enige se staanse op 'n probleem heeltemal verander, en hulle het nie gevolg om uitsonderlik te argumenteer nie (maar eerder volg 'n subtel retoriese strategie). So, wat beteken argumentasiekwaliteit vir redigeerders dan? Ons ontwikkel die nodiging dat 'n effektief redigeerdere uitdrukkings leesers met teenstandigheid, en op dieselfde tyd verkry die argumenteerde kunstensies van leesers wat die redigeerdere se staanse deel - of selfs uitdrukking beide kante. Om die argumentasie-kwaliteit te studeer gebaseer op hierdie noisie, introduseer ons 'n nuwe korpus met 1000 redigeerders van die New York Times, aangeteken vir hul aandagte effek saam met die politieke oriëntasies van die annotators. As ons die korpus analiseer, vind ons dat annotators met verskillende oriëntasie nie ooreenkomstig op die effek. Terwyl slegs 1% van alle redigeerders enige se staanse verander het, meer as 5% ontmoet ons nodiging. Ons sluit dat ons korpus as 'n geskikte hulpbron dien om die argumentasiekwaliteit van nuusredigeerders te studeer.", 'id': 'News editorials are said to shape public opinion, which makes them a powerful tool and an important source of political argumentation.  Namun, jarang editorial mengubah pendapat siapa pun pada sebuah isu sepenuhnya, dan mereka tidak cenderung untuk berdebat secara eksplicit (tetapi lebih baik mengikuti strategi retorik halus). Jadi, apa artinya kualitas argumen untuk editorial? Kami mengembangkan gagasan bahwa pembaca tantangan editorial yang efektif dengan posisi yang bertentangan, dan pada saat yang sama memberikan kekuatan untuk membantah pembaca yang berbagi posisi editorial - atau bahkan tantangan kedua sisi. Untuk mempelajari kualitas argumen berdasarkan gagasan ini, kami memperkenalkan sebuah korpus baru dengan 1000 editorial dari New York Times, yang dicatat untuk efek yang mereka perhatikan bersama dengan orientasi politik annotator. Analyzing the corpus, we find that annotators with different orientation disagree on the effect significantly.  Sementara hanya 1% dari semua editorial mengubah posisi siapa pun, lebih dari 5% memenuhi gagasan kita. We conclude that our corpus serves as a suitable resource for studying the argumentation quality of news editorials.', 'am': "የዜና አቀማሚዎች የህዝባዊ አስተያየትን በመፍጠር እና የፖለቲካ ጉዳይ የፖለቲካ ጉዳይ መሆኑን የሚያደርጋቸው ናቸው፡፡ ምንም እንኳን፣ የሚያስተማሪዎቹ ማንኛውንም የሥርዓት ጉዳይ ሙሉ ይለውጣሉ፣ እነርሱም በግልጽ ይዋጋሉ (ነገር ግን በትክክል የሐሳብ ትርጉም ተከተሉ)፡ እንግዲህ አካባቢ ጥያቄ ማድረግ ምንድር ነው? የአስተራሪካዊ ጥያቄ አንባቢዎችን በተቃዋሚ ሁኔታ እንዲያሳየው እናሳውቃለን፡፡ በዚህም ሰዓት የማስተካከለኛውን የአስተራሪካዊ ሁኔታ ወይም ሁለቱን ወገን የሚቃወሙ የጥያቄዎችን አስተያየት ያበረታታል፡፡ ይህንን አሳብ በማስተካከል የአውራዊ ጥያቄን ለማስተምር፣ ከኒው ዮርክ ቲሜን 1000 አስተዳሪዎች ጋር አዲስ ካርፓስ እናሳውቃለን፡፡ የቆርፓስ አካባቢዎች በማስተዋል፣ በተለየ መልዕክት የሚያስጨንቁት በጥያቄው ላይ በጣም ትልቅ ነገር እንደተካፈሉ እናገኛለን፡፡ While only 1% of all editorials changed anyone's stance, more than 5% meet our notion.  We conclude that our corpus serves as a suitable resource for studying the argumentation quality of news editorials.", 'bn': "সংবাদ সম্পাদকদের বলা হচ্ছে জনগণের মতামত গঠন করার জন্য, যা তাদের শক্তিশালী টুল এবং রাজনৈতিক যুক্তির গুরুত্বপূর্ তবে সম্পাদকরা খুব কমই কারো বিষয়ে কারো অবস্থান পুরোপুরি পরিবর্তন করে এবং তারা স্পষ্ট ভাবে বিতর্ক করে না (কিন্তু তাদের পরিবর্তে একটি সামান তাহলে যুক্তির মান সম্পাদকদের জন্য কি মানে? আমরা এই ধারণা উন্নয়ন করি যে কার্যকর সম্পাদকীয় চ্যালেঞ্জ পাঠকদের বিরুদ্ধে বিরোধী অবস্থান নিয়ে পাঠকদের কাছে চ্যালেঞ্জ তৈরি করা হয়, এবং একই সাথে পাঠকদের যুক এই ধারণার উপর ভিত্তিক যুক্তির মান গবেষণার জন্য আমরা নিউ ইয়র্ক টাইমস থেকে ১০০০ সম্পাদকদের একটি নতুন কোর্পাসের সাথে পরিচয় করিয়ে দিচ্ছি, যার ফলে তারা ব কোর্পাস বিশ্লেষণ করে, আমরা দেখতে পাচ্ছি যে বিভিন্ন দৃষ্টিভঙ্গিকারীদের বিভিন্ন দৃষ্টিভঙ্গি নিয়ে প্রভাব While only 1% of all editorials changed anyone's stance, more than 5% meet our notion.  আমরা শেষ করেছি যে আমাদের কোর্পাস সেবা সংবাদ সম্পাদকদের যুক্তির মান পড়ার জন্য যথেষ্ট সম্পদ হিসেবে সেবা করে।", 'az': "Haqq editorialları halkı fikirləri şəklinə çevirmək üçün belə deyildir ki, bu onları güclü bir araç və siyasi argumentasyonun möhkəm mənbəsi edər. Lakin editoriallar hər kəsin vəziyyətini tamamilə dəyişdirirlər və onlar a çıq-aydın mübahisə etməyə çalışmırlar (lakin çox az bir retorik strateji uyub getirlər). Beləliklə, dəyişikliklər üçün dəyişiklik kaliteti nədir? Biz fikirləri düzəltdik ki, düzəltənin durumunu paylaşan və ya hətta iki tərəfdən çəkinənlərin mübahisə edən oxuyanların mübahisələrini gücləndirir. Bu fikirlə dayanan argumentasyon keyfiyyətini təhsil etmək üçün New York Times'dan 1000 editorial olan yeni korpusu təşkil edirik. Nəhayət, onların fikirləşdikləri təsirlərin siyasi təsirləri ilə birlikdə təşkil edilmişdir. Korpusu analiz edib, fərqli tərəflər ilə danışanlar etkisi üzərində müəyyən edirlər. Bütün editorialların %1 kişinin durumunu dəyişdirdikdə, 5%-dən artıq fikrimizlə tanışır. Bizim korpusumuz xəbər editoriallarının argumentasyon kalitetini öyrənmək üçün uyğun bir resurs olaraq çalışır.", 'bs': 'Rečeno je da se novinski urednici oblikuju javno mišljenje, što ih čini moćnim alatom i važnim izvorom političke argumentacije. Međutim, rijetko se editoriali mijenjaju stav bilo koga na pitanje u potpunosti, niti se oni često raspravljaju (ali radije slijedite suptilnu retoričku strategiju). Dakle, šta znači kvalitet argumentacije za urednike? Razvijamo pojam da učinkoviti urednički izazovi čitača sa suprotnim stavom, a istovremeno omogućavaju svađajuće vještine čitača koji dijele stav editoriala ili čak izazivaju obje strane. Da bi studirali kvalitet argumentacije na temelju ovog pojma, predstavili smo novog korpusa sa 1000 editora iz New York Times-a, koji je navodio za njihov percepcioni učinak zajedno sa političkim orijentacijom annotatora. Analizirajući korpus, našli smo da annotatori sa različitim orijentacijom se značajno ne slažu na učinak. Iako je samo 1% svih urednika promijenilo stanje bilo koga, više od 5% ispunjavalo našu ideju. Zaključili smo da naš korpus služi kao odgovarajući resurs za proučavanje kvalitete argumentacije novinskih editoriala.', 'cs': 'Zpravodajské editorialy tvoří veřejné mínění, což z nich dělá mocný nástroj a důležitý zdroj politické argumentace. Nicméně zřídka editorialy úplně nezmění něčí postoj k tématu, ani mají tendenci explicitně argumentovat (ale spíše se řídí jemnou rétorickou strategií). Co tedy znamená kvalita argumentace pro editorialy? Rozvíjíme představu, že efektivní redakce vyzývá čtenáře s protikladným postojem a zároveň posiluje argumentační dovednosti čtenářů, kteří sdílejí postoj redakce nebo dokonce zpochybňují obě strany. Abychom mohli studovat kvalitu argumentace založenou na této představě, představujeme nový korpus s tisíci editoriály New York Times, anotovanými pro jejich vnímaný efekt spolu s politickou orientací anotátorů. Při analýze korpusu jsme zjistili, že anotátory s odlišnou orientací se na efektu výrazně nesouhlasí. Zatímco pouze jedno% všech editorialů změnilo postoj někoho, více než 5% splňuje naši představu. Dospěli jsme k závěru, že náš korpus slouží jako vhodný zdroj pro studium argumentační kvality zpravodajských editoriálů.', 'et': 'Väidetakse, et ajakirjandused kujundavad avalikku arvamust, mis teeb neist võimsa vahendi ja olulise poliitilise argumenteerimise allika. Harva muudavad redaktorid aga kellegi seisukohta küsimuses täielikult, samuti ei kaldu nad selgesõnaliselt vaidlema (vaid pigem järgima peent retoorilist strateegiat). Mida tähendab argumentide kvaliteet kirjastuste jaoks? Arendame arusaama, et tõhus toimetus väljakutseb lugejatele vastupidise seisukoha ning samal ajal võimaldab lugejate aruteluoskusi, kes jagavad toimetuse seisukohta - või isegi mõlemat poolt. Selle mõiste põhjal põhineva argumentide kvaliteedi uurimiseks tutvustame uut korpust, mis sisaldab 1000 New York Timesi ajakirjanikku, milles on märgitud nende tajutavat mõju koos kommentaatorite poliitiliste suundumustega. Korpuse analüüsides leiame, et erineva orientatsiooniga annotatorid ei ole mõjus oluliselt nõus. Kuigi vaid 1% kõigist ajakirjandustest muutis kellegi seisukohta, vastab üle 5% meie arusaamale. Järeldame, et meie korpus on sobiv ressurss uudiskirjade argumenteerimise kvaliteedi uurimiseks.', 'hy': "Ասում են, որ նորությունների խմբագիրները ձևավորում են հանրային կարծիքը, ինչը դարձնում է նրանց հզոր գործիք և քաղաքական բանավեճերի կարևոր աղբյուր: However, rarely do editorials change anyone's stance on an issue completely, nor do they tend to argue explicitly (but rather follow a subtle rhetorical strategy).  Այսպիսով, ի՞նչ է նշանակում բանավեճի որակը խմբագիրների համար: Մենք զարգանում ենք այն գաղափարը, որ արդյունավետ խմբագրական մարտահրավերներ են տալիս ընթերցողներին հակառակ դիրքով, և միևնույն ժամանակ հնարավորություն է տալիս ընթերցողների, ովքեր կիսում են խմբագրական դիրքով, բանավեճ հմտությունները, կամ նույնիսկ երկ Այս գաղափարի վրա հիմնված բանավեճերի որակը ուսումնասիրելու համար մենք ներկայացնում ենք նոր կորպոս, որը ունի 1000 խմբագիր Նյու Յորք Թայմսից, որոնք գրված են իրենց ընկալում ազդեցության համար, միասին նամակների քաղաքական ուղղությունների հետ: Analyzing the corpus, we find that annotators with different orientation disagree on the effect significantly.  While only 1% of all editorials changed anyone's stance, more than 5% meet our notion.  Մենք եզրակացում ենք, որ մեր կորպոսը ծառայում է որպես հարմար ռեսուրս նորությունների խմբագիրների բանավեճի որակի ուսումնասիրելու համար:", 'fi': 'Uutislehtien sanotaan muokkaavan yleistä mielipidettä, mikä tekee niistä voimakkaan välineen ja tärkeän poliittisen argumentoinnin lähteen. Kuitenkin harvoin editoriaalit muuttavat kenenkään kantaa asiaan kokonaan, eivätkä ne yleensä väittele nimenomaisesti (vaan pikemminkin noudattavat hienovaraista retorista strategiaa). Mitä argumentoinnin laatu tarkoittaa editoriaaleille? Kehitämme käsityksen, että tehokas toimituksellinen haastaa lukijat vastakkaisella asenteella ja samalla vahvistaa lukijoiden väittelytaitoja, jotka jakavat toimituksen kannan - tai jopa haastavat molempia osapuolia. Tutkiaksemme argumentoinnin laatua tämän käsitteen pohjalta esittelemme uuden korpusen, jossa on 1000 New York Timesin julkaisua, joissa on huomautuksia niiden havaitusta vaikutuksesta sekä kommentoijien poliittisista suuntauksista. Korpusta analysoitaessa huomaamme, että eri orientaatiolla olevat selittäjät ovat eri mieltä vaikutuksesta merkittävästi. Vaikka vain 1% kaikista editoriaaleista muutti kenenkään kantaa, yli 5% vastaa käsitystämme. Päätämme, että korpus toimii sopivana resurssina uutislehtien argumentoinnin laadun tutkimiseen.', 'ca': "Se diu que els editorials de notícies formen l'opinió pública, que els fa una eina poderosa i una font important d'arguments polítics. However, rarely do editorials change anyone's stance on an issue completely, nor do they tend to argue explicitly (but rather follow a subtle rhetorical strategy).  Així doncs, què significa la qualitat de l'argumentació per als editorials? Desenvolvem la noció de que un editorial efectiu desafia als lectors amb posició oposta, i al mateix temps empodera les habilitats argumentadores dels lectors que comparteixen la posició editorial - o fins i tot desafia ambdues parts. Per estudiar la qualitat de l'argumentació basada en aquesta noció, introduïm un nou corpus amb 1000 editorials del New York Times, anotats pel seu efecte perceptiu juntament amb les orientacions polítices dels anotators. Analyzing the corpus, we find that annotators with different orientation disagree on the effect significantly.  Mentre que només un 1% de tots els editorials van canviar la posició de ningú, més del 5% satisfen la nostra noció. Conclouem que el nostre cos serveix com un recurso adequat per estudiar la qualitat d'argumentació dels editorials de notícies.", 'sq': 'Editorialet e lajmeve thuhet se formojnë opinionin publik, i cili i bën a to një mjet të fuqishëm dhe një burim të rëndësishëm të argumenteve politike. Megjithatë, rrallë redaktorët ndryshojnë qëndrimin e dikujt në lidhje me një çështje krejtësisht, dhe a s ata nuk kanë tendencë të argumentojnë shprehësisht (por më tepër të ndjekin një strategji retorike të but ë). Pra, çfarë do të thotë cilësia e argumentit për redaktorët atëherë? Ne zhvillojmë konceptin se një sfidë redaktorale efektive shfaq lexuesit me qëndrim të kundërt dhe në të njëjtën kohë fuqizon aftësitë e diskutueshme të lexuesve që ndajnë qëndrimin e redaktoralit - apo madje sfidon të dy palët. Për të studiuar cilësinë e argumenteve bazuar në këtë koncept, ne paraqesim një korpus të ri me 1000 redaktorë nga New York Times, të shënuar për efektin e tyre të perceptuar së bashku me orientimet politike të anotatorëve. Analyzing the corpus, we find that annotators with different orientation disagree on the effect significantly.  Ndërsa vetëm 1% e të gjithë redaktorëve ndryshuan qëndrimin e dikujt, më shumë se 5% përmbushin konceptin tonë. Ne përfundojmë se korpusi ynë shërben si një burim i përshtatshëm për studimin e cilësisë së argumenteve të redaktoraleve të lajmeve.', 'jv': 'Awak dhéwé éntuk pernik sing nyimpen kanggo ngerasakno pêmulasakno, sing ngendalikne dhéwé kuwi alat sing gagasakno lan sekondhak dhéwé politik sing apik dhéwé. Nanging, alah-alah, ditambah kuwi cah-alah sing ngubah gerakan sampeyan luwih nêmên, lan ora mbok dhèwèké nggawe akeh luwih-luwih (mangkat dhèwèké beraksi luwih akeh tértika sing apik). Delok, opo sing dikarepaké argument kalité kanggo editorial lan ora? Awak dhéwé nggawe ngerti sing beraksi perusahaan editorial sing menyang karo nguasal sing nguasai, lan neng sampek sing nguasai perusahaan karo perusahaan karo perusahaan sing nguasai iki dadi sing beraksi nguasai perusahaan Ngawe kudu segala macem sing cuwih dumadhi sing basa ning unasaben iki, awake dhéwé nyebuturan karo perusahaan anyar sing katya karo 1,000 sing perusahaan seneng gawe New jok Time, janeng sing ngerasakno karo perusahaan langutan nganggo perusahaan politik sing apik dhéwé Ngawe politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé éntuk karo hal-hal karo perusahaan-perusahaan nganggep petani sing nyimpen kanggo ngilangno kuwi tindakan kedhaftar wigatahan', 'sk': 'Novični uredniki naj bi oblikovali javno mnenje, zaradi česar so močno orodje in pomemben vir političnih argumentov. Vendar redko uredniki popolnoma spremenijo stališče kogarkoli glede vprašanja, prav tako pa ne razpravljajo izrecno (temveč sledijo subtilni retorični strategiji). Torej, kaj pomeni kakovost argumentacije za urednike? Razvijamo idejo, da učinkovito uredništvo izziva bralce z nasprotnim stališčem, hkrati pa krepi sposobnosti argumentov bralcev, ki si delijo stališče uredništva – ali celo izziva obe strani. Za proučevanje kakovosti argumentacije na podlagi tega pojma predstavljamo nov korpus s 1000 uredniki New York Timesa, ki so označeni za njihov zaznani učinek skupaj s političnimi usmeritvami označevalcev. Z analizo korpusa ugotavljamo, da se opozorilci z različno usmerjenostjo glede učinka bistveno ne strinjajo. Medtem ko je le 1% vseh urednikov spremenilo stališče kogarkoli, več kot 5% ustreza našemu pojmu. Zaključimo, da naš korpus služi kot primeren vir za preučevanje kakovosti argumentacije novinarskih urednikov.', 'he': "עורכי חדשות אומרים לעצב את דעת הציבור, מה שעושה אותם כלי חזק ומקור חשוב של ויכוח פוליטי. אך לעיתים נדירות העורכים משנים את עמדתו של אף אחד בנושא לחלוטין, ולא הם נוטים להתווכח באופן ברור (אלא לעקוב אחר אסטרטגיה רטורית עדינה). אז מה איכות התווכחות מתכוונת לעורקים? אנחנו מפתחים את הרעיון שאתגר עורך יעיל לקוראים עם עמדה נגידה, ובאותו הזמן מאשר את כישורי הטיעון של הקוראים שחלקים את עמדתו של העורך - או אפילו מאתגרים את שני הצדדים. To study argumentation quality based on this notion, we introduce a new corpus with 1000 editorials from the New York Times, annotated for their perceived effect along with the annotators' political orientations.  בניתוח של הקורפוס, אנחנו מוצאים שמציונים עם כיוון שונה לא מסכימים על ההשפעה באופן משמעותי. בעוד רק 1% מכל העורקים שינו את עמדתו של כל אחד, יותר מ-5% פוגשים את הרעיון שלנו. אנחנו מסכם שהקורפוס שלנו משמש כמשאב מתאים ללמוד את איכות הטיעון של עורכי חדשות.", 'ha': "Ana ce da waharinta na lãbãri za'a sami gannai ga mutane, ta sanya su wani zance mai ƙarfi da wani yanzu muhimu wa masu husũma na kisasa. Haƙĩƙa, haƙiƙa suna musanya matsayin wanda yake a kan al'amarin, kuma bã su yin jidãli da bayyane (kuma amma suna biyar wani takwai mai rauni). Kayya, mene ne ma'anar nauyi da mazaɓa wa editorial? Tuna kiyaye idãnun da ma'abũcin karatun masu sha'ani da masu motsi, kuma a sami waɗancan, yana ƙarar da abincin ma'abũta musamman da ke share istanin editori - ko kuma kõ dã sun yi musamman duk biyu. To, dõmin ka karanta sifar da muhimmada a kan wannan idãnun, sai mu introduce wani makampi na da taƙaitori 1000 daga New York Times, da aka sanar da musamman su sami da juyin sihirin matalauta. Ana yi anayya ga nau'in, za'a gane cewa matangare da shirin dabam-dabam bã su sãɓa a kan amfani mai girma. A lõkacin da kawai %1 ne daga duk editori suka musanya halin wani, sai zaɓa 5% su haɗi zato. Tuna ƙaranta cewa makarubutunmu yana da amfani mai daidai wa karatun sifar da aka yi wa taƙaitori masu husũma.", 'bo': "གསར་འགྱུར་གྱི་ཞུན་དག་པ་ཚོས་མི་མང་གི་བསམ་འཆར་གཞུང་བཟོ་བྱེད་འདུག། དེ་ནི་ཁོང་ཚོ་ནི་སྟོབས་ཤུགས་ཅན་དང་། ཆབ་སྲིད ཡིན་ནའང་། བསྒྱུར་བཅོས་ཀྱི་རྣམ་པ་ཚོས་གནས་ཚུལ་གང་འདྲ་ཡིན་མིན་ན་གསལ་བཤད་བྱས་མེད། འོན་ཀྱང་། ཞུན་དག་པ་ལ་སྔོན་སྒྲིག་འཇུག་གམ་གཤིས་གང་ཞིག་ཡིན་ནམ། ང་ཚོས་ལྟ་བུའི་དོན་ལྟར་བཟོ་བཅོས་ནུས་ཡོད་པའི་བཟོ་བཅོས་ཀློག་པ་ཚོའི་ལས་འཆར་བ་སྤྲོད་ཀྱི་གནས་ཚུལ་དང་ཕྱོགས་ཡོད་པའི་ཐབས་ལམ་དེ་མཉམ་དུ་གཏོང་བྱེད་པའ To study argumentation quality based on this notion, we introduce a new corpse with 1000 editorials from the New York Times, annotated for their perceived effect along with the annotators' political orientations. དབུལ ཞུན་དག་པ་ཚོའི་གནས་བབ་གཅིག་ལས་ཁོ་ན་གཅིག་གི་འགྱུར་བ་ཡིན་ནའང་། ང་ཚོའི་ཕྱོགས་སྔ་ལས་མེད། ང་ཚོས་འབྲེལ་བ་ནི་གསར་འགུལ་ཞུགས་པ་གི་སྔོན་སྒྲིག་གི་མཐུན་རྐྱེན་གྱི་ཐོན་ཁུངས་དང་མཐུན་པོ་ཞིག་ཡིན་ན་ཏེ།"}
{'en': 'Improving Response Selection in Multi-Turn Dialogue Systems by Incorporating Domain Knowledge', 'ar': 'تحسين اختيار الاستجابة في أنظمة الحوار متعدد الأدوار من خلال دمج معرفة المجال', 'fr': 'Améliorer la sélection des réponses dans les systèmes de dialogue multitours en intégrant les connaissances du domaine', 'es': 'Mejorar la selección de respuestas en los sistemas de diálogo multivuelta mediante la incorporación del conocimiento', 'pt': 'Melhorando a Seleção de Respostas em Sistemas de Diálogo Multi-Turn, Incorporando o Conhecimento do Domínio', 'ja': 'ドメイン知識の取り入れによるマルチターンダイアログシステムにおける応答選択の改善', 'hi': 'डोमेन ज्ञान को शामिल करके मल्टी-टर्न संवाद प्रणालियों में प्रतिक्रिया चयन में सुधार करना', 'zh': '因整合领域,改进多回合对话系统中的应选', 'ru': 'Улучшение выбора ответов в системах многооборотного диалога путем включения знаний о доменах', 'ga': 'Roghnú Freagra a Fheabhsú i gCórais Idirphlé Il-Cas trí Eolas Fearainn a Ionchorprú', 'ka': 'დიალოგის სისტემებში გამოყენება პასუხის მონიშნულება', 'hu': 'A válaszok kiválasztásának javítása a többfordulós párbeszédrendszerekben a tartományismeret beépítésével', 'el': 'Βελτίωση της επιλογής απόκρισης σε συστήματα διαλόγου πολλαπλών στροφών με ενσωμάτωση της γνώσης τομέα', 'it': 'Migliorare la selezione delle risposte nei sistemi di dialogo multi-turno incorporando la conoscenza del dominio', 'kk': 'Қосымша аудару диалог жүйелерінде жауапты таңдау', 'lt': 'Padidinti atsako pasirinkimą kelių pusių dialogo sistemose įtraukiant žinias apie sritį', 'mk': 'Подобрување на изборот на одговор во системите за дијалог со повеќе свртувања со вклучување на знаење за доменот', 'ml': 'പല- തിരിച്ചുമാറ്റുന്ന ഡയലോഗ് സിസ്റ്റത്തില്\u200d ഉത്തരം തെരഞ്ഞെടുക്കുന്നത് മുന്\u200dകൂട്ടുന്നതാണു് ഡൊമെയി', 'ms': 'Menyambungkan Pemilihan Balasan dalam Sistem Dialog Berputar-Berlipat dengan Memasukkan Pengetahuan Domain', 'mt': 'It-titjib fl-għażla tar-rispons fis-sistemi ta’ djalogu b’diversi dawriet billi jinkorpora l-għarfien tad-dominju', 'mn': 'Хариулт сонголтыг олон эргүүл диалог системд сайжруулах нь Доминийн мэдлэг', 'no': 'Å forbetra utval av svar i fleirturndialogsystemet ved å inkorporare domenekjenning', 'pl': 'Poprawa wyboru odpowiedzi w systemach dialogowych wielokrotnie poprzez włączenie wiedzy domeny', 'ro': 'Îmbunătățirea selecției răspunsurilor în sistemele de dialog cu mai multe rânduri prin încorporarea cunoștințelor de domeniu', 'sr': 'Poboljšanje izbora odgovora u sistemima multiokrenog dijaloga uključujući znanje domena', 'so': 'Horumarinta doorashada jawaabta ee nidaamka kala leexda ee lagu kordhiyo aqoonta domain', 'si': 'ප්\u200dරතික්\u200dරියාත්මක තෝරණය විශේෂය කරනවා ගොඩක් වර්ණ සංවාදය පද්ධතියේ', 'sv': 'Förbättra svarsval i flerskiftsdialogsystem genom att införliva domänkunskap', 'ur': 'ڈومین علم کے ذریعے بہت سی ٹرینگ ڈیلوگ سیستموں میں جواب کا انتخاب بہتر کر رہا ہے', 'ta': 'பல- திரும்பும் உரையாடல் முறைமைகளில் பதில் தேர்வு மேம்படுத்துதல் தளம் அறிவு மூலம்', 'uz': 'Name', 'vi': 'Tăng cường phần chọn đáp ứng trong hệ thống đối thoại đa chiều bằng việc lắp ghép kiến thức miền', 'da': 'Forbedring af svarvalg i dialogsystemer med flere ture ved at indarbejde domænevindskab', 'bg': 'Подобряване на избора на отговор в диалоговите системи с няколко завъртания чрез включване на познания за домейна', 'nl': 'Verbetering van responsselectie in multi-turn dialogsystemen door integratie van domeinkennis', 'hr': 'Poboljšanje izbora odgovora u multiokrenim dijalogskim sustavima uključujući znanje domena', 'de': 'Verbesserung der Antwortauswahl in Multi-Turn Dialogsystemen durch Einbeziehung von Domänenwissen', 'id': 'Menembak Pemilihan Respon dalam Sistem Dialog Berputar-Berputar Dengan Memasukkan Pengetahuan Domain', 'sw': 'Kuboresha Uchaguzi wa Jibu katika Mfumo wa Mfumo wa Mitandao ya Kupitia Ujuzi wa Domain', 'fa': 'بهترین انتخاب پاسخ در سیستم\u200cهای محاورۀ مجدد گردش توسط اطلاعات دامنی', 'ko': '분야 지식을 결합하여 다중 대화 시스템에서의 반응 선택을 개선하다', 'tr': 'Çokdan Jeli Bilim sistemlerinde jogap saýlawy gowylaşdyr', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Արձագանքի ընտրության բարելավումը բազմապտտվող դասախոսների համակարգերում՝ ներառելով բնագավառի գիտելիքներ', 'af': 'Verbeter Antwoord Keuse in Multi- Turn Dialog Systeme deur Inkorporering Domein kennis', 'bs': 'Poboljšanje izbora odgovora u multiokrenim dijalogskim sistemima uključujući znanje domena', 'sq': 'Përmirësimi i zgjedhjes së përgjigjes në sistemet e dialogut me shumë kthesa duke përfshirë njohuritë e domenit', 'ca': 'millorar la selecció de resposta als sistemes de diàleg multigiratori incorporant coneixements de domini', 'az': 'Daha çox dönüş Dialoog Sistemlərində cavab seçimlərini yaxşılaşdırma', 'bn': 'ডোমেইনের জ্ঞান অন্তর্ভুক্ত করে প্রতিক্রিয়া নির্বাচন ব্যবস্থায় প্রতিক্রিয়া সংশোধন করা হচ্ছে', 'fi': 'Parannetaan vastausten valintaa monimutkaisissa dialogijärjestelmissä sisällyttämällä verkkotunnustietoa', 'et': 'Vastuste valiku parandamine mitmekäigulistes dialoogisüsteemides domeeniteadmiste kaasamise abil', 'cs': 'Zlepšení výběru odezvy v dialogových systémech s více otáčkami začleněním znalostí domény', 'jv': 'Ngawe Perintah sing langkung Rayongi ning Multi-spin Dialog System nang Incomporation domain knowknownMonitor vendor', 'he': 'שיפור בחירת תגובה במערכות שיחות דיאלוג מסובכים רבים על ידי הכנסת מידע של שטח', 'sk': 'Izboljšanje izbire odzivov v sistemih dialogov z več obrati z vključevanjem domenskega znanja', 'ha': '@ action', 'bo': 'རྒྱབ་སྐྱོར་མེད་པའི་གནས་ཚུལ་འབྲེལ་གྱི་མ་ལག་ཚོགས་ནང་ལ་ལན་གསལ་འཆར་འདེམས་པ་ལ་ཡར་རྒྱས་གཏོང་བ'}
{'en': 'Building systems that can communicate with humans is a core problem in ', 'ar': 'يعد بناء الأنظمة التي يمكنها التواصل مع البشر مشكلة أساسية في الذكاء الاصطناعي. يقترح هذا العمل بنية شبكة عصبية جديدة لاختيار الاستجابة في إعداد حوار محادثة متعدد الأدوار من طرف إلى طرف. يطبق الهيكل الاهتمام على مستوى السياق ويدمج المعرفة الخارجية الإضافية التي توفرها أوصاف الكلمات الخاصة بالمجال. يستخدم وحدة بوابات متكررة ثنائية الاتجاه (GRU) لتشفير السياق والاستجابات ويتعلم الحضور عبر كلمات السياق بالنظر إلى تمثيل الاستجابة الكامنة والعكس صحيح. بالإضافة إلى ذلك ، فإنه يدمج معلومات خاصة بالمجال الخارجي باستخدام GRU آخر لتشفير أوصاف الكلمات الأساسية للمجال. هذا يسمح بتمثيل أفضل للكلمات الرئيسية الخاصة بالمجال في الردود وبالتالي يحسن الأداء العام. تظهر النتائج التجريبية أن نموذجنا يتفوق في الأداء على جميع الأساليب الحديثة الأخرى لاختيار الاستجابة في المحادثات متعددة الأدوار.', 'pt': 'Construir sistemas que podem se comunicar com humanos é um problema central em Inteligência Artificial. Este trabalho propõe uma nova arquitetura de rede neural para seleção de resposta em uma configuração de diálogo de conversação multi-turn de ponta a ponta. A arquitetura aplica atenção em nível de contexto e incorpora conhecimento externo adicional fornecido por descrições de palavras específicas de domínio. Ele usa uma GRU (Gated Recurrent Unit) bidirecional para codificar contexto e respostas e aprende a atender sobre as palavras de contexto dada a representação da resposta latente e vice-versa. Além disso, ele incorpora informações específicas de domínio externo usando outra GRU para codificar as descrições de palavras-chave do domínio. Isso permite uma melhor representação de palavras-chave específicas do domínio nas respostas e, portanto, melhora o desempenho geral. Resultados experimentais mostram que nosso modelo supera todos os outros métodos de última geração para seleção de resposta em conversas multi-turn.', 'es': 'Construir sistemas que puedan comunicarse con los humanos es un problema fundamental en la Inteligencia Artificial. Este trabajo propone una arquitectura de red neuronal novedosa para la selección de respuestas en un entorno de diálogo conversacional de múltiples giros de extremo a extremo. La arquitectura aplica la atención a nivel de contexto e incorpora conocimientos externos adicionales proporcionados por las descripciones de palabras específicas del dominio. Utiliza una unidad recurrente cerrada (GRU) bidireccional para codificar el contexto y las respuestas y aprende a atender las palabras de contexto dada la representación de la respuesta latente y viceversa. Además, incorpora información específica del dominio externo mediante otra GRU para codificar las descripciones de las palabras clave del dominio. Esto permite una mejor representación de las palabras clave específicas del dominio en las respuestas y, por lo tanto, mejora el rendimiento general. Los resultados experimentales muestran que nuestro modelo supera a todos los demás métodos de última generación para la selección de respuestas en conversaciones de varios turnos.', 'fr': "Construire des systèmes capables de communiquer avec les humains est un problème fondamental de l'intelligence artificielle. Ce travail propose une nouvelle architecture de réseau neuronal pour la sélection des réponses dans un environnement de dialogue conversationnel multi-tours de bout en bout. L'architecture applique une attention au niveau du contexte et intègre des connaissances externes supplémentaires fournies par des descriptions de mots spécifiques au domaine. Il utilise une unité récurrente fermée bidirectionnelle (GRU) pour coder le contexte et les réponses et apprend à étudier les mots contextuels en fonction de la représentation de la réponse latente et vice versa. En outre, il intègre des informations spécifiques au domaine externe à l'aide d'un autre GRU pour coder les descriptions de mots-clés de domaine. Cela permet une meilleure représentation des mots clés spécifiques au domaine dans les réponses et améliore ainsi les performances globales. Les résultats expérimentaux montrent que notre modèle surpasse toutes les autres méthodes de pointe pour la sélection des réponses dans les conversations à tours multiples.", 'ja': '人間と通信できるシステムを構築することは、人工知能の中核的な問題です。本作は、エンドツーエンドのマルチターン会話設定における応答選択のための斬新なニューラルネットワークアーキテクチャを提案している。このアーキテクチャは、文脈レベルの注意を適用し、ドメイン固有の単語の説明によって提供される追加の外部知識を組み込んでいます。コンテキスト及び応答を符号化するために双方向ゲーテッドリカレントユニット（ ＧＲＵ ）を使用し、潜在的な応答表現が与えられたコンテキスト単語上に参加することを学習し、その逆も同様である。さらに、ドメインキーワードの説明をエンコードするための別のGRUを使用して、外部ドメイン固有の情報を組み込んでいます。これにより、応答でドメイン固有のキーワードをよりよく表現できるため、全体的なパフォーマンスが向上します。実験結果は、当社のモデルが、マルチターン会話における応答選択のための他のすべての最先端の方法よりも優れていることを示しています。', 'ru': 'Построение систем, которые могут общаться с людьми, является ключевой проблемой в искусственном интеллекте. Эта работа предлагает новую архитектуру нейронной сети для выбора ответа в настройке сквозного многополосного разговорного диалога. Архитектура применяет внимание на уровне контекста и включает дополнительные внешние знания, предоставляемые описаниями специфических для домена слов. Он использует двунаправленный Gated Recurrent Unit (GRU) для кодирования контекста и ответов и учится присутствовать поверх контекстных слов, учитывая представление скрытого ответа, и наоборот. Кроме того, он включает в себя информацию, относящуюся к внешнему домену, используя другой GRU для кодирования описаний ключевых слов домена. Это позволяет лучше отображать в ответах ключевые слова, относящиеся к конкретным доменам, и, следовательно, повышает общую производительность. Экспериментальные результаты показывают, что наша модель превосходит все другие современные методы выбора ответов в многооборотных беседах.', 'zh': '构可与通信者,人工智能之稽也。 其事建一新神经网络架构,施于端到端多回合对设中之应。 宜体系结构上下文级之意,而包特定于域之单词于外。 用双向门控循环单元(GRU)编码于上下文和,学于给定潜上下文单词,反之亦然。 此外用一GRU并外域特定信息,施于对域关键字编码。 可以应特定于域之关键字,以崇其性也。 实验结果表明,我的模样在多轮次对话中优于所有最先进的应择。', 'hi': 'बिल्डिंग सिस्टम जो मनुष्यों के साथ संवाद कर सकते हैं, आर्टिफिशियल इंटेलिजेंस में एक मुख्य समस्या है। यह काम एक एंड-टू-एंड मल्टी-टर्न संवादी संवाद सेटिंग में प्रतिक्रिया चयन के लिए एक उपन्यास तंत्रिका नेटवर्क आर्किटेक्चर का प्रस्ताव करता है। आर्किटेक्चर संदर्भ स्तर पर ध्यान लागू करता है और डोमेन-विशिष्ट शब्दों के विवरण द्वारा प्रदान किए गए अतिरिक्त बाहरी ज्ञान को शामिल करता है। यह संदर्भ और प्रतिक्रियाओं को एन्कोडिंग करने के लिए एक द्वि-दिशात्मक गेटेड आवर्तक इकाई (जीआरयू) का उपयोग करता है और अव्यक्त प्रतिक्रिया प्रतिनिधित्व और इसके विपरीत दिए गए संदर्भ शब्दों पर भाग लेना सीखता है। इसके अलावा, यह डोमेन कीवर्ड विवरण एन्कोडिंग के लिए किसी अन्य GRU का उपयोग करके बाहरी डोमेन विशिष्ट जानकारी को शामिल करता है। यह प्रतिक्रियाओं में डोमेन-विशिष्ट कीवर्ड के बेहतर प्रतिनिधित्व की अनुमति देता है और इसलिए समग्र प्रदर्शन में सुधार करता है। प्रयोगात्मक परिणामों से पता चलता है कि हमारा मॉडल बहु-बारी वार्तालापों में प्रतिक्रिया चयन के लिए अन्य सभी अत्याधुनिक तरीकों से बेहतर प्रदर्शन करता है।', 'ga': 'Is croífhadhb san Intleacht Shaorga é córais tógála ar féidir leo cumarsáid a dhéanamh le daoine. Molann an saothar seo ailtireacht líonra néarúil nua le haghaidh roghnú freagraí i suíomh comhphlé il-casaidh ó cheann ceann go ceann. Baineann an ailtireacht aird ar leibhéal an chomhthéacs agus ionchorpraítear ann eolas seachtrach breise a chuirtear ar fáil trí chur síos ar fhocail a bhaineann go sonrach leis an bhfearann. Úsáideann sé Aonad Athfhillteach Geata déthreorach (GRU) chun comhthéacs agus freagraí a ionchódú agus foghlaimíonn sé freastal thar na focail comhthéacs i bhfianaise ionadaíocht na bhfreagraí folaigh agus vice versa. Ina theannta sin, ionchorpraíonn sé faisnéis shainfhearainn sheachtrach ag baint úsáide as GRU eile chun na tuairiscí eochairfhocal fearainn a ionchódú. Ligeann sé seo léiriú níos fearr ar eochairfhocail a bhaineann go sonrach leis an bhfearann i bhfreagraí agus mar sin feabhsaíonn sé an fheidhmíocht iomlán. Léiríonn torthaí turgnamhacha go sáraíonn ár múnla gach modh úrscothach eile chun freagairtí a roghnú i gcomhráite iluaine.', 'ka': 'შექმნა სისტემები, რომელიც ადამიანებთან კომუნიკაცია შესაძლებელია, არის კულტური ინტელექტიური ინტელექტიური პრობლემა. ეს სამუშაო ახალი ნეიროლური ქსელის აქტიქტიქტურაცია განახლებისთვის მრავალური დაბრუნების დიალოგის პარამეტრებისთვის. არქტიქტიკური კონტექსტური მნიშვნელობის დააყენება და დამატებული გარეშე მეცნიერება, რომლებიც დიომინის განსაკუთრებული სიტყვების გამოსახულებით და ის გამოყენებს ორგანრიგებული განხორციული განხორციელი ერთეული (GRU) კონტექსტი და განსხვავებებისთვის და სწავლის, რომ კონტექსტური სიტყვების შესახებ, რომელიც განხორციელია განხორციელი პასუხი და გან დამატებით, ექსპერი დიომინის განსაკუთრებული ინფორმაცია შეიყენება სხვა GRU გამოყენებით დიომინის გასაკუთრებელი სიტყვის კოდიფიკაციისთვის. ეს უფრო მეტი დიომინის სპექტიფიკური კლავიფერი სიტყვების გამოსახულებას შეუძლებელია და ამიტომ უფრო მეტი გამოსახულება. ექსპერიმენტიური შედეგები ჩვენი მოდელი გავაკეთება ყველა სხვა განსხვავებული განსხვავებული განსხვავება განსხვავებაში.', 'hu': 'Az emberekkel kommunikáló rendszerek építése alapvető probléma a mesterséges intelligenciában. Ez a munka egy új neurális hálózati architektúrát javasol a válasz kiválasztására egy end-to-end multi-turn beszélgetési párbeszéd beállításban. Az architektúra kontextusszintű figyelmet fordít elő, és további külső ismereteket tartalmaz a domain-specifikus szavak leírásával. Kétirányú Gated Recurrent Unit (GRU) segítségével kódolja a kontextust és a válaszokat, és megtanulja a kontextusszavakat a látens válasz reprezentációjával és fordítva. Ezenkívül külső tartományspecifikus információkat is magában foglal egy másik GRU segítségével a tartományi kulcsszó leírásainak kódolására. Ez lehetővé teszi a tartományspecifikus kulcsszavak jobb megjelenítését a válaszokban, és ezáltal javítja az általános teljesítményt. A kísérleti eredmények azt mutatják, hogy modellünk felülmúlja a többfordulós beszélgetések válaszkiválasztásának minden más korszerű módszerét.', 'el': 'Η κατασκευή συστημάτων που μπορούν να επικοινωνούν με τους ανθρώπους είναι ένα βασικό πρόβλημα στην Τεχνητή Νοημοσύνη. Η παρούσα εργασία προτείνει μια νέα αρχιτεκτονική νευρωνικών δικτύων για την επιλογή απόκρισης σε ένα πλαίσιο διαλόγου πολλαπλών στροφών από τέλος σε τέλος. Η αρχιτεκτονική εφαρμόζει προσοχή σε επίπεδο περιβάλλοντος και ενσωματώνει πρόσθετες εξωτερικές γνώσεις που παρέχονται από περιγραφές συγκεκριμένων λέξεων. Χρησιμοποιεί μια αμφίδρομη Gated Recurrent Unit (GRU) για την κωδικοποίηση του πλαισίου και των απαντήσεων και μαθαίνει να παρακολουθεί πάνω από τις λέξεις του πλαισίου δεδομένης της λανθάνουσας αναπαράστασης απόκρισης και το αντίστροφο. Επιπλέον, ενσωματώνει εξωτερικές πληροφορίες ειδικά για τον τομέα χρησιμοποιώντας μια άλλη για την κωδικοποίηση των περιγραφών λέξεων-κλειδιών τομέα. Αυτό επιτρέπει την καλύτερη αναπαράσταση των λέξεων-κλειδιών σε απαντήσεις και ως εκ τούτου βελτιώνει τη συνολική απόδοση. Τα πειραματικά αποτελέσματα δείχνουν ότι το μοντέλο μας ξεπερνά όλες τις άλλες προηγμένες μεθόδους επιλογής απόκρισης σε συζητήσεις πολλαπλών στροφών.', 'lt': 'Statybos sistemos, galinčios bendrauti su žmonėmis, yra pagrindinė problem a dirbtinės žvalgybos srityje. This work proposes a novel neural network architecture for response selection in an end-to-end multi-turn conversational dialogue setting.  Arhitektūra atkreipia dėmesį į kontekstą ir apima papildomas išorės žinias, pateiktas konkrečiai sričiai skirtų žodžių aprašymuose. Jame naudojamas dvikryptis Gated Recurrent Unit (GRU) kontekstui ir atsakams koduoti ir mokomas dalyvauti kontekstiniuose žodžiuose atsižvelgiant į latentinį atsaką ir atvirkščiai. Be to, jame pateikiama išorės domeno specifinė informacija, naudojant kitą GRU koduojant domeno rakto žodžių aprašymus. Tai leidžia geriau atspindėti konkrečiai sričiai skirtus pagrindinius žodžius atsakymuose ir taip pagerina bendrą veiksmingumą. Eksperimentiniai rezultatai rodo, kad mūsų modelis pasiekia visus kitus moderniausius atsako atrankos metodus daugkartiniais pokalbiais.', 'it': "Costruire sistemi in grado di comunicare con gli esseri umani è un problema fondamentale nell'Intelligenza Artificiale. Questo lavoro propone una nuova architettura di rete neurale per la selezione della risposta in un'impostazione di dialogo conversazionale end-to-end multi-turn. L'architettura applica attenzione a livello di contesto e incorpora ulteriori conoscenze esterne fornite da descrizioni di parole specifiche del dominio. Utilizza un'unità bidirezionale Gated Recurrent Unit (GRU) per codificare contesto e risposte e impara a frequentare le parole contestuali data la rappresentazione della risposta latente e viceversa. Inoltre, incorpora informazioni specifiche di dominio esterno utilizzando un altro GRU per codificare le descrizioni delle parole chiave di dominio. Ciò consente una migliore rappresentazione delle parole chiave specifiche del dominio nelle risposte e quindi migliora le prestazioni complessive. I risultati sperimentali mostrano che il nostro modello supera tutti gli altri metodi all'avanguardia per la selezione delle risposte nelle conversazioni a più turni.", 'mk': 'Градењето системи кои можат да комуницираат со луѓето е главен проблем во уметничката интелигенција. Оваа работа предложува нова архитектура на нервната мрежа за избор на одговор во поставување на мултиобратен дијалог од крај до крај. Архитектурата применува внимание на контекстно ниво и вклучува дополнително надворешно знаење обезбедено со описи на зборови специфични за домен. Истиот користи двојно-насокен Портен Повторен Единица (GRU) за кодирање на контекст и одговори и научи да присуствува во контекстните зборови со оглед на latent response representation и обратно. Покрај тоа, вклучува информации специфични за надворешниот домен користејќи друга GRU за кодирање на описите на клучните зборови на доменот. Ова овозможува подобра претстава на клучните зборови специфични за домен во одговорите и со тоа ја подобрува целокупната резултатност. Експерименталните резултати покажуваат дека нашиот модел ги надминува сите други најдобри методи за избор на одговор во повеќето разговори.', 'kk': 'Адамдармен байланыс бере алатын құрылғы жүйелері - Мақсатты интеллектердің негізгі мәселесі. Бұл жұмыс бірнеше аудару диалог параметрлерінде жауап таңдау үшін романдық неврал желінің архитектурасын ұсынады. Архитектура контекстік деңгейіне қатынау және доменге арнаулы сөздердің сипаттамасы бойынша қосымша сыртқы білімдерді қолданады. Ол кодтамасы мен жауап беру үшін екі бағытты қайталану бірлігін (GRU) қолданады және соңғы жауап көрсетілген контексті сөздеріне қатынау үшін. Қосымша, доменнің кілттің сөздерін кодтамасыз үшін басқа GRU қолданатын сыртқы доменнің ерекше мәліметін қолданады. Бұл доменге ерекше кілттің сөздерін жауап беру үшін жақсы көрсетуге мүмкіндік береді, сондықтан бұл жалпы ықтималдығын жасайды. Эксперименталдық нәтижелері біздің моделіміз көп айналысқанда жауап таңдау әдістерін өзгертеді.', 'ms': 'Bina sistem yang boleh berkomunikasi dengan manusia adalah masalah utama dalam Inteligence Artificial. Kerja ini mencadangkan arkitektur rangkaian saraf baru untuk pemilihan balas dalam tetapan dialog berbincang berbilang-putaran akhir-akhir. The architecture applies context level attention and incorporates additional external knowledge provided by descriptions of domain-specific words.  Ia menggunakan Unit Sekali Ulang Gated dua arah (GRU) untuk mengekod konteks dan balasan dan belajar untuk menghadiri perkataan konteks yang diberikan mewakili balasan tersembunyi dan sebaliknya. Selain itu, ia memasukkan maklumat khusus domain luar menggunakan GRU lain untuk mengekod deskripsi kata kunci domain. Ini membolehkan perwakilan lebih baik kata kunci spesifik domain dalam balasan dan oleh itu meningkatkan prestasi umum. Hasil eksperimen menunjukkan bahawa model kita melampaui semua kaedah-kaedah-state-of-the-art lain untuk pemilihan balas dalam perbualan berbilang-pusingan.', 'mt': 'Is-sistemi tal-bini li jistgħu jikkomunikaw mal-bnedmin huma problem a ewlenija fl-Intelliġenza Artifika. Din il-ħidma tipproponi arkitettura ġdida tan-netwerk newrali għall-għa żla tar-rispons f’kuntest ta’ djalogu ta’ konverżjoni b’diversi dawriet minn tarf għal tarf. L-arkitettura tapplika attenzjoni fil-livell ta’ kuntest u tinkorpora għarfien estern addizzjonali pprovdut minn deskrizzjonijiet ta’ kliem speċifiku għad-dominju. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context and responses and learns to attend over the context words given the latent response representation and vice versa.  Barra minn hekk, tinkorpora informazzjoni speċifika għad-dominju estern bl-użu ta’ GRU ieħor għall-kodifikazzjoni tad-deskrizzjonijiet tal-kelma ewlenija tad-dominju. Dan jippermetti rappreżentazzjoni aħjar ta’ kliem ewlieni speċifiċi għad-dominju fir-risposti u għalhekk itejjeb il-prestazzjoni globali. Riżultati sperimentali juru li l-mudell tagħna jwettaq il-metodi l-aktar avvanzati l-oħra kollha għall-għażla tar-rispons f’konverżjonijiet b’diversi dawriet.', 'ml': 'മനുഷ്യരോടൊപ്പം ബന്ധപ്പെടാന്\u200d കഴിയുന്ന സിസ്റ്റത്തില്\u200d നിര്\u200dമ്മിക്കുന്നത് ആര്\u200dട്ടിഫിക്കല്\u200d ഇന്\u200dറിലെന്\u200dസ ഈ ജോലി ഒരു നോവല്\u200d നെയുറല്\u200d നെറ്റര്\u200d നെറ്റര്\u200d നെറ്റാള്\u200d ശൃംഖലയുടെ ആര്\u200dക്കിട്ടേര്\u200dക്ക് പ്രായശ്ചിത്തമാക്കുന്നു. മറ്റൊരു  ഈ സ്ഥാനം കൂടുതല്\u200d കൂടുതല്\u200d ശ്രദ്ധ പ്രയോഗിക്കുന്നു. ഡൊമൈന്\u200d - പ്രത്യേക വാക്കുകള്\u200d വിശദീകരിച്ചുകൊണ്ട് കൂടുതല്\u200d പുറമ അവസാനത്തെ പ്രതിനിധിക്കുന്ന വാക്കുകളില്\u200d ചേര്\u200dക്കാനും ഉത്തരം പഠിക്കാനും അത് രണ്ട് നേരിട്ട് ഗേറ്റ് ആവര്\u200dത്തിക്കുന്ന യൂണിറ്റിനും ഉപയ കൂടാതെ, അത് പുറത്തുള്ള ഡൊമെയിനില്\u200d മറ്റൊരു GRU ഉപയോഗിച്ച് പ്രത്യേക വിവരങ്ങള്\u200d ഡോമെയിന്\u200d കീവോര്\u200dഡ് വിവരങ്ങള്\u200d കോഡി പ്രതികരണങ്ങളില്\u200d ഡൊമെയിന്\u200d - പ്രത്യേക ക കീ വാക്കുകളുടെ പ്രതിനിധിയ്ക്ക് ഇത് നല്ല പ്രദര്\u200dശിപ്പിക്കാന്\u200d അനുവദി പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ മോഡല്\u200d മറ്റൊരു രാജ്യത്തിന്റെ രീതിയില്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്', 'no': 'Byggingssystemet som kan kommunisera med mennesker er ein kjerneproblem i kunstiske intelligens. Dette arbeidet foreslår eit nytart neuralnettverksarkitektur for utval av svar i ein dialogvindauge for fleire omvendingar. Arkitekturen brukar kontekstnivåoppmerksomheten og inkluderer eksterne kunnskap som er tilgjengeleg ved skildringar av domenespesifikke ord. Det brukar ein divretning gated gjentaande eining (GRU) for kodingskontekst og svar og lærer å delta på kontekstord som gjev representasjonen av latent svar og motsatt. I tillegg inkluderer det eksterne domenespesifikke informasjon med ein annan GRU for koding av domenenøkkelordskildringa. Dette tillèt bedre representasjon av nøkkelord for domenespesifikke i svar og derfor forbedrar overalt utvikling. Eksperimentale resultat viser at modellen vårt utfører alle andre metodane for utval av svar i fleire omsetjingar.', 'mn': 'Хүмүүстэй харилцаж чадах бүтээлч систем бол уран бүтээлч ухааны үндсэн асуудал юм. Энэ ажлын шинэ мэдрэлийн сүлжээний архитектур нь олон өөрчлөлт диалог дээр хариулт сонголтын тулд шинэ санал өгдөг. Архитектур нь харьцааны төвшин анхаарлыг хэрэглэдэг бөгөөд холбооны тодорхойлолтой үгнүүдийн тайлбарлалтаар нэмэлт гадаад мэдлэг бүрдүүлдэг. Энэ нь хоёр багын хаалтын дахин дахин дахин нэгж (GRU) хэрэглэдэг. Хариулт, хариулт, хариултын тулд хамгийн сүүлийн хариулт илэрхийлэл болон эсрэг хариултын үгсийн тулд оролцохыг сурсан. Үүнээс гадна холбооны тодорхойлолтын тодорхойлолтыг кодлохын тулд өөр GRU ашиглан гадна холбооны тодорхойлолтой мэдээллийг нэгтгэдэг. Энэ нь холбоотой тодорхой түлхүүр үгнүүдийг хариултын тулд илүү сайн илэрхийлэх боломж олгодог. Иймээс бүх үйл ажиллагааг сайжруулдаг. Эмчилгээний үр дүнд бидний загвар олон өөрчлөлт ярилцлаганд хариу үйлдэл сонголтын бусад бүх урлагийн арга загварыг дамжуулдаг.', 'ro': 'Construirea de sisteme care pot comunica cu oamenii este o problemă esențială în Inteligența Artificială. Această lucrare propune o arhitectură nouă de rețea neurală pentru selectarea răspunsului într-o setare de dialog conversațional end-to-end multi-turn. Arhitectura aplică atenția la nivel de context și încorporează cunoștințe externe suplimentare furnizate de descrieri de cuvinte specifice domeniului. Utilizează o unitate recurentă bidirecțională Gated Recurrent Unit (GRU) pentru codificarea contextului și a răspunsurilor și învață să participe la cuvintele contextului dat fiind reprezentarea răspunsului latent și vice versa. În plus, încorporează informații specifice domeniului extern utilizând un alt GRU pentru codificarea descrierilor cuvintelor cheie de domeniu. Acest lucru permite o mai bună reprezentare a cuvintelor cheie specifice domeniului în răspunsuri și, prin urmare, îmbunătățește performanța generală. Rezultatele experimentale arată că modelul nostru depășește toate celelalte metode de ultimă generație pentru selectarea răspunsurilor în conversațiile cu mai multe rânduri.', 'pl': 'Budowanie systemów, które mogą komunikować się z ludźmi jest kluczowym problemem sztucznej inteligencji. Niniejsza praca proponuje nową architekturę sieci neuronowej do selekcji odpowiedzi w kompleksowym, wielokrotnym dialogu konwersacyjnym. Architektura stosuje uwagę na poziomie kontekstu i uwzględnia dodatkową wiedzę zewnętrzną dostarczaną przez opisy słów specyficznych dla danej dziedziny. Wykorzystuje dwukierunkową Gated Recurrent Unit (GRU) do kodowania kontekstu i odpowiedzi i uczy się obsługiwać słowa kontekstowe, biorąc pod uwagę ukrytą reprezentację odpowiedzi i odwrotnie. Ponadto zawiera zewnętrzne informacje specyficzne dla domeny przy użyciu innego GRU do kodowania opisów słów kluczowych domeny. Pozwala to na lepszą reprezentację słów kluczowych specyficznych dla domeny w odpowiedziach, a tym samym poprawia ogólną wydajność. Wyniki eksperymentalne pokazują, że nasz model przewyższa wszystkie inne najnowocześniejsze metody selekcji odpowiedzi w rozmowach wielokrotnych.', 'sr': 'Građevinski sistem koji mogu komunicirati sa ljudima je glavni problem u umjetnoj obavještajnosti. Ovaj rad predlaže novu arhitekturu neuralne mreže za izbor odgovora u okviru razgovornog dijaloga na kraju do kraja. Arhitektura primjenjuje pažnju na nivou konteksta i uključuje dodatne vanjske znanje koje se pružaju opisima specifičnih reči domena. Koristi dvosmjernu povratnu jedinicu (GRU) za kontekst kodiranja i odgovore i uči da prisustvuje kontekstske reči s obzirom na zastupanje latentne odgovore i suprotno. Osim toga, uključuje specifične informacije o vanjskom domenu koristeći drugu GRU za kodiranje ključnih reči domena. To omogućava bolje predstavljanje ključnih reèi na domenu u odgovorima i zato poboljšava ukupnu izvršnost. Eksperimentalni rezultati pokazuju da naš model iznosi sve ostale metode umetnosti za izbor reakcija u višestrukim razgovorima.', 'si': 'මිනිස්සු එක්ක සම්බන්ධ වෙන්න පුළුවන් පද්ධතිය නිර්මාණය කරන්න පුළුවන් පද්ධතිය ප්\u200dරශ්නයක මේ වැඩේ ප්\u200dරතික්\u200dරියාත්මක වාර්තාව සංවාද සැකසුමේදී ප්\u200dරතික්\u200dරියාත්මක වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක විස ස්ථාපනය සම්බන්ධතා ස්ථානය අවධානය අවශ්\u200dය කරනවා ඒ වගේම ප්\u200dරමාණය සම්බන්ධ විශේෂ වචන වලින් ප්\u200d ඒක ප්\u200dරතිචාරය සහ ප්\u200dරතිචාරය සඳහා ප්\u200dරතිචාරය සඳහා ප්\u200dරතිචාරය සඳහා ප්\u200dරතිචාරය සඳහා ප්\u200dරතිචාරය සඳහා ප්\u200dරතිචාරය සඳහා ප්\u200dරති ඒ වගේම, ඒකෙන් ප්\u200dරතිශේෂ ප්\u200dරතිශීල තොරතුරු සම්බන්ධ කරනවා ඩොමේන් යතුරු වචන විස්තරණය සඳහා වෙන මේක ප්\u200dරතික්\u200dරියාත්මක විශේෂ ප්\u200dරතික්\u200dරියාත්මක විශේෂ ප්\u200dරතික්\u200dරියාත්මක වෙන්න පුළුවන් වෙනව පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ මොඩේල් එක අනිත් ස්ථානයක් ප්\u200dරතිචාරයක් වෙනුවෙන් ප්\u200d', 'sv': 'Att bygga system som kan kommunicera med människor är ett kärnproblem inom artificiell intelligens. Detta arbete föreslår en ny neural nätverksarkitektur för svarsval i en end-to-end konversationsdialoginställning. Arkitekturen tillämpar kontextnivå uppmärksamhet och innefattar ytterligare extern kunskap som tillhandahålls av beskrivningar av domänspecifika ord. Den använder en dubbelriktad Gated Recurrent Unit (GRU) för kodning av kontext och svar och lär sig att närvara över kontextorden givet latent svar representation och vice versa. Dessutom innehåller den extern domänspecifik information med hjälp av en annan GRU för kodning av domänsökordsbeskrivningarna. Detta möjliggör bättre representation av domänspecifika sökord i svaren och förbättrar därmed den övergripande prestandan. Experimentella resultat visar att vår modell överträffar alla andra toppmoderna metoder för svarsval i konversationer med flera varv.', 'so': 'Isticmaalka la xiriiri karo dadka waa dhibaato ku saabsan cilmiga farshaxanka. Shaqadaasu wuxuu soo jeedaa dhismaha shabakadda neurada ee warqada ah oo loo doorto doorashada jawaabta marka loo dhamaado dhammaadka dialog-dialog kala leexdo badan. Tirkirku wuxuu qabanqaabiyaa qalabka hoose, wuxuuna ku qoraa aqoonta dibadda ah oo lagu qorayo qoraalka hadalka gaarka ah ee gudaha. Waxay isticmaaltaa qaybta dib u soo kireysashada (GRU) ee ku qoran qorsheynta iyo jawaabaha, waxayna bartaa inay ka qeybqaadato hadallada kooxaha ah ee lagu soo jeeday jawaabta ugu dambeysay iyo xuquuqda. In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions.  Markaas waxaa suurtogal u yeelan kara in ka mid ah hadalka afka cayimanta ee domain, markaasna horumarinta tababarka guud. Imtixaanka waxaa laga muujiyaa in modellkayagu uu soo saaraa qaabab kale oo uu ku qorayo habka farshaxanka oo dhan ee doorashada jawaabta ee hadalka kala leexda oo kala duduwan.', 'ta': 'மனிதர்களுடன் தொடர்பு கொள்ள முடியும் அமைப்புகளை கட்டுதல் கலைஞர் அறிவிப்பில் ஒரு மூல பிரச்சனை. இந்த வேலை ஒரு புதிய புதிய புதிய பிணையத்தின் உருவாக்கத்தை பரிந்துரைக்கும் முடிவில் இருந்து முடிவு உரையாடல் அமைப்பில அட்டவணை சூழல் நிலை கவனத்தை பயன்படுத்துகிறது மற்றும் கூடுதல் வெளி அறிவை உள்ளிடுகிறது டோமைன்- குறிப்பிட்ட வார்த்தை இது ஒரு இரு திசைதேர்ந்தெடுக்கப்பட்ட மீண்டும் நிகழ்வு அலகு (GRU) மற்றும் குறியீட்டு சூழல் மற்றும் பதில் மற்றும் கொடுக்கப்பட்ட சொற்களின கூடுதலாக, அது வெளி களம் குறிப்பிட்ட விவரங்களை மற்றொரு GRU பயன்படுத்தி சேர்க்கும். Name முயற்சி முடிவுகள் தெரியும் பல திரும்ப உரையாடல்களில் எங்கள் மாதிரி அனைத்து நிலையில் கலை முறைகளையும் வெளியேற்றும்.', 'ur': 'انسانوں کے ساتھ رابطہ بنانے کی سیستموں کی تعلیم کرسکتی ہے، یہ مصنوعی اطلاعات میں ایک اصلی مشکل ہے. یہ کام ایک نور نیورل نیٹ ورک آرکیٹ کی پیشنهاد کرتا ہے جو ایک پاسخ انتخاب کے لئے بہت سی انتخاب کی مخلوقات ڈالیلوگر کے سامنے ہے. معماری کائنات سطح کی توجه پر لازم کرتی ہے اور ڈومین خاص کلمات کی توصیف کے ذریعے اضافہ خارجی علم میں شامل ہوتی ہے. اس کے لئے ایک دوسری دکھانے والی جمع ہوئی دوبارہ یونیٹ (GRU) کا استعمال کرتا ہے کہ اکنوڈینڈ کنٹکس اور جواب کے لئے اور کنٹکس کلمات کے بارے میں حاضر ہونا سکھاتا ہے جو لٹینٹ جواب کی نمایش اور مخالفت کے بارے میں ہے. اس کے علاوہ، یہ دومین کلید ویڈیوں کی سفارش کے لئے دوسرے GRU کے مطابق بیرونی ڈومین کے خاص معلومات میں شامل ہوتا ہے. یہ ڈومین کے مطابق صاف کلید کلیدوں کی بہترین نمایش کی اجازت دیتا ہے اور اس کے بعد کل عملکرد کو بہتر کر دیتا ہے. آزمائش کے نتائج دکھاتے ہیں کہ ہمارا موڈل بہت سی باتوں میں جواب کے انتخاب کے لئے تمام دوسرے ایٹیٹ کی طریقے کام کرتا ہے.', 'uz': "Одамлар билан алоқалаш мумкин бўлган системни яратиш Арзизик маълумотларда қизиқ мушкилдир. Name Name @ info: whatsthis @ info This allows better representation of domain-specific keywords in responses and hence improves the overall performance.  Tekshirish natijalari ko'rsatadi, modelmiz muloqat muloqat talabatlarida javob tanlash uchun boshqa holat usullarni bajaradi.", 'vi': 'Các hệ thống xây dựng có thể giao tiếp với con người là vấn đề cốt lõi của trí thông minh nhân tạo. Công trình này đề xuất một kiến trúc dây thần kinh mới để chọn phản ứng trong một thiết lập đối thoại nhiều lần kết thúc. Kiến trúc áp dụng sự chú ý cấp độ ngữ cảnh và áp dụng kiến thức bên ngoài bổ sung từ mô tả những từ đặc trưng miền. Nó sử dụng một đơn vị liên tục hai hướng (GRU) để mã hóa bối cảnh và các phản ứng và học cách tham dự vào các từ ngữ ngữ cảnh dựa trên các phản ứng phụ và ngược lại. Thêm vào đó, nó chứa các thông tin đặc trưng miền bên ngoài, sử dụng một GRU khác để mã hóa mô tả từ khoá miền. Việc này cho phép mô tả các từ khoá cụ thể miền trong các phản ứng và do đó cải thiện khả năng tổng hợp. Kết quả thí nghiệm cho thấy mô hình của chúng ta hoàn thiện tất cả các phương pháp hiện đại để chọn đáp trong các cuộc nói chuyện nhiều lần.', 'nl': 'Het bouwen van systemen die kunnen communiceren met mensen is een kernprobleem in Artificial Intelligence. Dit werk stelt een nieuwe neurale netwerkarchitectuur voor voor responsselectie in een end-to-end multi-turn conversationele dialoog setting. De architectuur past aandacht op contextniveau toe en bevat extra externe kennis die wordt geleverd door beschrijvingen van domeinspecifieke woorden. Het gebruikt een bi-directionele Gated Recurrent Unit (GRU) voor het coderen van context en reacties en leert de contextwoorden te observeren gezien de latente responsrepresentatie en vice versa. Daarnaast bevat het externe domein specifieke informatie met behulp van een andere GRU voor het coderen van de domeintrefwoordbeschrijvingen. Dit maakt een betere weergave van domeinspecifieke zoekwoorden mogelijk in reacties en verbetert daarmee de algehele prestaties. Experimentele resultaten tonen aan dat ons model beter presteert dan alle andere state-of-the-art methoden voor responsselectie in gesprekken met meerdere keren.', 'bg': 'Строителните системи, които могат да комуникират с хората, са основен проблем в изкуствения интелект. Тази работа предлага нова архитектура на невронната мрежа за избор на отговор в диалогов диалог от край до край. Архитектурата прилага внимание на ниво контекст и включва допълнителни външни знания, предоставени от описания на специфични за домейна думи. Той използва двупосочна вратена повтаряща се единица (GRU) за кодиране на контекст и отговори и се научава да присъства над контекстните думи, като се има предвид представянето на латентния отговор и обратно. В допълнение, той включва външна специфична информация за домейна, като използва друг GRU за кодиране на описанията на ключовите думи на домейна. Това позволява по-добро представяне на специфичните за домейна ключови думи в отговорите и по този начин подобрява цялостното представяне. Експерименталните резултати показват, че нашият модел превъзхожда всички други съвременни методи за избор на отговор в разговори с няколко завъртания.', 'da': 'Opbygning af systemer, der kan kommunikere med mennesker, er et kerneproblem i kunstig intelligens. Dette arbejde foreslår en ny neural netværksarkitektur til responsvalg i en end-to-end multi-turn samtale dialog indstilling. Arkitekturen anvender kontekst niveau opmærksomhed og inkorporerer yderligere ekstern viden leveret af beskrivelser af domænespecifikke ord. Den bruger en tovejsende Gated Recurrent Unit (GRU) til kodning af kontekst og svar og lærer at deltage over kontekst ord givet latent svar repræsentation og omvendt. Desuden indeholder den eksterne domænespecifikke oplysninger ved hjælp af en anden GRU til kodning af domænenøglebeskrivelserne. Dette giver bedre repræsentation af domænespecifikke søgeord i svar og forbedrer dermed den samlede ydeevne. Eksperimentelle resultater viser, at vores model overgår alle andre state-of-the-art metoder til svarvalg i flere-turn samtaler.', 'hr': 'Građevinski sustavi koji mogu komunicirati s ljudima su glavni problem u umjetnoj obavještajnosti. Ovaj rad predlaže novu arhitekturu neuralne mreže za izbor odgovora u okviru multiokrenog razgovornog dijaloga. Arhitektura primjenjuje pažnju na razini konteksta i uključuje dodatne vanjske znanje koje se pružaju opisima specifičnih riječi domena. Koristi dvosmjernu povratnu jedinicu (GRU) za kontekst kodiranja i odgovore i uči prisustvovati kontekstskim riječima s obzirom na zastupanje latentne odgovore i suprotno. Osim toga, uključuje specifične informacije o vanjskom domenu koristeći drugu GRU za kodiranje ključnih riječi domena. To omogućava bolje predstavljanje ključnih riječi na domenu u odgovorima i zato poboljšava cjelokupnu funkciju. Eksperimentalni rezultati pokazuju da naš model iznosi sve ostale metode umjetnosti za izbor odgovora u višestrukim razgovorima.', 'id': 'Membangun sistem yang dapat berkomunikasi dengan manusia adalah masalah utama dalam Intelijen Sendiri. This work proposes a novel neural network architecture for response selection in an end-to-end multi-turn conversational dialogue setting.  Arkitektur menerapkan perhatian tingkat konteks dan memasukkan pengetahuan eksternal tambahan yang diberikan oleh deskripsi kata-kata khusus domain. Ini menggunakan Unit Recurrent Gated bidireksi (GRU) untuk mengkode konteks dan respon dan belajar untuk menghadiri kata-kata konteks yang diberikan representation respon rahasia dan sebaliknya. Selain itu, ia memasukkan informasi khusus domain luar menggunakan GRU lain untuk mengekodikan deskripsi kata kunci domain. Ini memungkinkan persembahan lebih baik dari kata kunci spesifik domain dalam respon dan oleh itu meningkatkan prestasi umum. Hasil eksperimen menunjukkan bahwa model kita melampaui semua metode terbaik lainnya untuk seleksi respon dalam konversasi berbilang putaran.', 'de': 'Der Aufbau von Systemen, die mit Menschen kommunizieren können, ist ein Kernproblem der Künstlichen Intelligenz. Diese Arbeit schlägt eine neuartige neuronale Netzwerkarchitektur für die Antwortauswahl in einem End-to-End-Gesprächsdialog vor. Die Architektur wendet Aufmerksamkeit auf Kontextebene an und integriert zusätzliches externes Wissen durch Beschreibungen von domänenspezifischen Wörtern. Es verwendet eine bidirektionale Gated Recurrent Unit (GRU) zur Codierung von Kontext und Antworten und lernt, über die Kontextwörter bei der latenten Antwortdarstellung zu sprechen und umgekehrt. Darüber hinaus enthält es externe domänenspezifische Informationen unter Verwendung einer anderen GRU zur Codierung der Domain-Keyword-Beschreibungen. Dies ermöglicht eine bessere Darstellung domänenspezifischer Keywords in Antworten und verbessert somit die Gesamtleistung. Experimentelle Ergebnisse zeigen, dass unser Modell alle anderen State-of-the-Art Methoden zur Antwortauswahl in Multi-Turn-Gesprächen übertrifft.', 'sw': 'Mfumo wa kujenga unaoweza kuwasiliana na binadamu ni tatizo la msingi katika Intelliti ya Kisanaa. Kazi hii inapendekeza ujenzi wa mtandao wa kisasa wa neura kwa ajili ya uchaguzi wa majibu katika mjadala wa majadiliano ya mwisho wa mwisho. Ujengo huo unatumia mwangaza wa kiwango cha muktadha na unajumuisha maarifa zaidi ya nje yanayotolewa na maelezo maalum ya maneno ya ndani. Inatumia kituo cha kurejea kwa njia mbili (GRU) kwa ajili ya kuandika muktadha na miitikio na kujifunza kushiriki katika maneno yaliyotolewa kwa uwakilishi wa hivi karibuni na vibaya zaidi. In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions.  Hii inaruhusu uwakilizaji mzuri wa maneno maalumu ya ndani katika majibu na hivyo kuboresha utendaji wa jumla. Matokeo ya majaribio yanaonyesha kuwa mtindo wetu unaonyesha njia nyingine za hali ya sanaa kwa ajili ya uchaguzi wa majibu katika mazungumzo mbalimbali.', 'fa': 'سیستم ساختن که می تواند با انسان ارتباط برقرار کند، یک مشکل اصلی در اطلاعات مصنوعی است. این کار یک معماری نور شبکه عصبی برای انتخاب پاسخ در تنظیمات صحبت\u200cهای متفاوتی از پایان به پایان پیشنهاد می\u200cکند. معماری توجه سطح محیط را تأثیر می\u200cدهد و علم خارجی بیشتری را با توصیف کلمات مخصوص دامنه شامل می\u200cکند. این واحد یک واحد دوراهی جمع شده دوراهی (GRU) را برای محیط رمزبندی و جواب\u200cها استفاده می\u200cکند و یاد می\u200cگیرد که در کلمات\u200cهای محیط با نمایش پاسخ latent و بر خلاف آن حاضر شوند. در addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions. این اجازه می\u200cدهد بهتر نمایش کلمات مخصوص دامنه را در پاسخ\u200cها بهتر کند و بنابراین عملکرد عمومی را بهتر می\u200cکند. نتیجه\u200cهای تجربه\u200cی ما نشان می\u200cدهند که مدل ما تمام روش\u200cهای دولتی هنر را برای انتخاب پاسخ در گفتگوهای مختلف تبدیل می\u200cکند.', 'ko': '인간과 통신할 수 있는 시스템을 구축하는 것은 인공지능의 핵심 문제다.이 작업은 끝에서 끝까지의 다륜 대화 환경에서의 반응 선택에 사용되는 새로운 신경 네트워크 구조를 제시했다.이 체계 구조는 상하문 단계의 주의를 응용하고 특정 분야의 어휘 묘사가 제공하는 추가 외부 지식을 결합시켰다.이는 쌍방향 선택 순환 단원(GRU)을 사용하여 상하문과 응답을 인코딩하고 잠재적 응답 표현을 지정한 상하문어에 참여하는 것을 배운다. 반대로도 마찬가지다.또한 다른 GRU를 사용하여 도메인 키워드 설명을 인코딩하여 도메인별 외부 정보를 결합합니다.이것은 응답에서 특정한 영역의 키워드를 더욱 잘 표시하여 전체 성능을 향상시킬 수 있다.실험 결과에 의하면 여러 차례의 대화에서 우리의 모델은 모든 다른 가장 선진적인 반응 선택 방법보다 우수하다는 것을 알 수 있다.', 'am': 'ከሰው ጋር ማግኘት የሚችል ስርዓቶች መሠረት በአርስተኛዊ Intelligence ዋና ነው፡፡ ቦታ የመዝገብ ግንኙነት አካባቢ ትኩረትን ይጠቅማል፡፡ አዲስ የጥያቄ መልዕክት እና ክስተት እና ድምፅ ማድረግ ይችላል፡፡ በተጨማሪም፣ የውጭ ዶሜን መረጃ በሌላ GRU በመጠቀም የዶሜን የቁልፍ ቃላት መግለጫ ያስገባል፡፡ ይህም የዶሜን-የተለየ የቁልፍ ቃላትን በመመለስ ይሻላል፡፡ ፈተና ፍሬዎች ሞዴሌዎቻችን በብዙ መለያየት ለመምረጥ የሥርዓት ሥርዓት ሁሉ እንዲያሳየው ነው፡፡', 'sq': 'Ndërtimi i sistemeve që mund të komunikojnë me njerëzit është një problem thelbësor në Inteligjencën Artistike. Ky punë propozon një arkitekturë të re të rrjetit nervor për zgjedhjen e përgjigjes në një vendosje dialogu bisedimesh me shumë kthesa nga fundi në fund. Arkitektura aplikon vëmendjen e nivelit të kontekstit dhe përfshin njohuri shtesë të jashtme të ofruara nga përshkrimet e fjalëve specifike për domenin. Ajo përdor një njësi të përsëritur të dydrejtuar të Portës (GRU) për kodimin e kontekstit dhe përgjigjeve dhe mëson të ndjekë lidhur me fjalët e kontekstit duke dhënë përfaqësimin e përgjigjes së fshehtë dhe vice versa. Përveç kësaj, ajo përfshin informacion specifik të domain it të jashtëm duke përdorur një GRU tjetër për kodimin e përshkrimit të fjalës kyçe të domainit. Kjo lejon përfaqësim më të mirë të fjalëve kyçe specifike në domeni në përgjigje dhe kështu përmirëson performancën e përgjithshme. Rezultatet eksperimentale tregojnë se modeli ynë ekziston në të gjitha metodat e tjera më të larta për zgjedhjen e përgjigjeve në bisedime me shumë kthesa.', 'hy': 'Կառուցման համակարգերը, որոնք կարող են հաղորդակցվել մարդկանց հետ, արվեստական ինտելեկտության հիմնական խնդիրն է: Այս աշխատանքը առաջարկում է նոր նյարդային ցանցի ճարտարապետություն պատասխանների ընտրության համար վերջ-վերջ բազմահատուկ հաղորդակցման միջոցով: Ճապետական կառուցվածքը կիրառում է կոնտեքստի մակարդակի ուշադրություն և ներառում է արտաքին գիտելիքներ, որոնք տրամադրվում են բնագավառի մասնավոր բառերի նկարագրման միջոցով: Այն օգտագործում է երկու ուղղությամբ արտադրված կրկնօրինակ միավոր (GRU) կոնտեքստի և արձագանքների կոդավորման համար և սովորում է մասնակցել կոնտեքստի բառերի վրա, հաշվի առնելով թաքնված արձագանքի ներկայացումը և հակառակը: Ավելին, այն ներառում է արտաքին բնագավառի կոնկրետ տեղեկատվություն՝ օգտագործելով մեկ այլ GRU բնագավառի բառերի կոդավորման համար: Սա հնարավորություն է տալիս ավելի լավ ներկայացնել բնագավառի կոնկրետ բառերը պատասխաններում և հետևաբար բարելավում է ընդհանուր արդյունքը: Փորձարկման արդյունքները ցույց են տալիս, որ մեր մոդելը արտադրում է պատասխանի ընտրության բոլոր այլ ամենահետաքրքիր մեթոդները բազմահատված զրույցներում:', 'bn': 'মানুষের সাথে যোগাযোগ করতে পারে সিস্টেম হচ্ছে শৈল্পিক তথ্যের মূল সমস্যা। এই কাজের একটি নোভেল নেটওয়ার্ক কার্যক্রমের প্রস্তাব করা হচ্ছে যে প্রতিক্রিয়া নির্বাচনের জন্য প্রস্তাব প্রস্তাব করা হচ্ছে বহুব আর্কিস্টেক্টারের মাধ্যমে কন্ট্রেক্ট স্তরের দৃষ্টিভঙ্গি প্রয়োগ করে এবং ডোমেইন-নির্দিষ্ট শব্দের বর্ণনা দিয়ে ব সাম্প্রতিক প্রতিক্রিয়ার প্রতিনিধিত্ব এবং ভাইসের প্রতিনিধিত্ব এবং প্রতিক্রিয়ার জন্য এটি ব্যবহার করে দ্বিধান গেট পুনরাবার্তা ইউনিট (GRU এছাড়াও, এটি ডোমেইন কী ওয়ার্ড বিবরণের জন্য বাইরের ডোমেইন বিশেষ তথ্য অন্য জিআরউ ব্যবহার করে বিশেষ তথ্য অন্তর্ভুক্ত করে। এই প্রতিক্রিয়ায় ডোমেইন-নির্দিষ্ট কী শব্দের প্রতিনিধিত্বের সুযোগ দেয় এবং এর ফলে সাধারণ কর্মসূচি উন্নত করে। পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের মডেল অন্যান্য রাষ্ট্র-অফ-শিল্পের প্রতিক্রিয়া নির্বাচনের জন্য প্রতিক্রিয়া বে', 'az': 'İnsanlarla iletişim edə biləcək in şaat sistemləri Yaxşı İstihbarat içində əsas problemidir. Bu işin çoxlu dönüş danışma dialoglarında cavab seçmək üçün yeni nöral a ğ arhitektarını təbliğ edir. Bu arhitektura kontekst seviyyəti dikkatini istifadə edir və domain-specific sözlərin tanımlarıyla bəxş edilən ekstra bilgiləri daxil edir. O, kodlama məlumatı və cavab vermək üçün iki yönəlli Gated Recurrent Unit (GRU) istifadə edir və sonrakı cavab göstəricisi və digər yönəltməkdə olan məlumatı sözlərinə katılmağı öyrənir. Daha sonra, domena anahtar sözlərinin tanımlaması üçün başqa GRU vasitəsilə dış domena xüsusi məlumatları daxil edir. Bu, domain-specific anahtar sözlərinin cavablarında daha yaxşı göstərilməsinə imkan verir və buna görə də bütün işləri daha yaxşılaşdırır. Müvəffəqiyyət sonuçları göstərir ki, modellərimiz çoxlu dönüş müzakirələrində reaksiya seçmək üçün bütün başqa mövcuddur.', 'af': "Buitstelsels wat met mense kan kommunikasieer is 'n nuwe probleem in kunstensielike intelligensie. Hierdie werk voorstel 'n roman neurale netwerk arkitektuur vir antwoord keuse in' n end- to- end multi- turn omskakelingsdialoog instelling. Die arkitektuur wend aan konteksvlak aandag en inkorpreer addisionele eksterne kennis wat deur beskrywings van domein-spesifieke woorde verskaf word. Dit gebruik 'n twee- rigting versamel Herhaling Eenheid (GRU) vir enkodering konteks en antwoorde en leer om by te bied oor die konteks woorde gegee het die latente antwoord verteenwoording en weerskynlik. In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions. Hierdie laat beter voorsien van domein-spesifieke sleutelwoorde in antwoordes toe en daarom verbeter die hele prestasie. Eksperimentale resultate wys dat ons model uitvoer alle ander staat-van-kuns-metodes vir reakskiesing in multi-draai gespreksies.", 'ca': 'La construcció de sistemes que poden comunicar-se amb els humans és un problem a central de la Intelligencia Artificial. Aquesta feina propon una nova arquitectura de xarxa neural per a seleccionar resposta en un diàleg de conversa de final a final. The architecture applies context level attention and incorporates additional external knowledge provided by descriptions of domain-specific words.  Utilitza una Unitat Recurrent Gated bidireccional (GRU) per codificar el context i les respostes i aprenen a participar en les paraules contextuals dadas la representació de la resposta latent i vice versa. A més, incorpora informació específica del domini extern utilitzant un altre GRU per codificar les descripcions de paraules clau del domini. Això permet una millor representació de paraules clau específices per domini en respostes i, per tant, millora el rendiment global. Els resultats experimentals mostren que el nostre model supera tots els altres mètodes més avançats per a seleccionar resposta en converses múltiples.', 'tr': 'Adamlar bilen habarlaşyp biljek sistemalary in şa etmek isleýän nusgadyr. Bu işe multi-söz sözleşişi dýalogdan soňra jogap saýlamak üçin bir täze näurul şebeke arhitektegi teklip edip bilýär. Arhitektura kontekst derejesi barada üns berir we domain hili sözleri tarapyndan berilýän daşarydaky daşarydaky bilim bilen üýtgedýär. [GRU] Ayrıca, domena kelime tasvir üçin başga GRU ullanýan daşarky domena hasaplamalary barlaýar. Bu, jogaplar içinde domain özel kelimelerinin daha iyi temsilleştirmesine izin verir ve bu yüzden bütün işlemleri geliştirir. Aramanyň netijesi biziň nusgamyzyň köp gezek çykyşlarda jogap saýlamak üçin beýleki möhüm taýýarlaryny çykarýandygyny görkez.', 'bs': 'Građevinski sistem koji mogu komunicirati sa ljudima je glavni problem u umjetnoj obavještajnosti. Ovaj rad predlaže novu arhitekturu neuralne mreže za izbor odgovora u okviru razgovornog dijaloga na kraju do kraja. Arhitektura primjenjuje pažnju na nivou konteksta i uključuje dodatne vanjske znanje koje se pružaju opisivanjem specifičnih riječi domena. Koristi dvosmjernu skupljenu povratnu jedinicu (GRU) za kontekst kodiranja i odgovore i uči se prisustvovati kontekstskim riječima s obzirom na zastupanje latentnog odgovora i suprotno. Osim toga, uključuje specifične informacije o vanjskom domenu koristeći drugu GRU za kodiranje ključnih riječi domena. To omogućava bolje predstavljanje ključnih riječi na domenu u odgovorima i zato poboljšava cjelokupnu funkciju. Eksperimentalni rezultati pokazuju da naš model iznosi sve ostale metode umjetnosti za izbor odgovora u višestrukim razgovorima.', 'fi': 'Rakentaminen, joka pystyy kommunikoimaan ihmisten kanssa, on keskeinen ongelma tekoälyssä. Tässä työssä ehdotetaan uutta neuroverkkoarkkitehtuuria vasteen valintaan päästä päähän monimutkaisessa keskustelussa. Arkkitehtuuri soveltaa kontekstitason huomiota ja sisältää ulkoista lisätietoa, joka saadaan toimialuekohtaisten sanojen kuvauksista. Se käyttää kaksisuuntaista Gated Recorrent Unit (GRU) kontekstin ja vastausten koodaamiseen ja oppii osallistumaan kontekstin sanojen yli piilevän vasteen esittämisen ja päinvastoin. Lisäksi se sisältää ulkoiset verkkotunnuskohtaiset tiedot käyttämällä toista GRU-yksikköä verkkotunnuksen avainsanojen kuvausten koodaamiseen. Tämä mahdollistaa verkkotunnuskohtaisten avainsanojen paremman edustuksen vastauksissa ja parantaa siten yleistä suorituskykyä. Kokeelliset tulokset osoittavat, että mallimme suoriutuu paremmin kuin kaikki muut huipputason menetelmät vastausvalintaan monimutkaisissa keskusteluissa.', 'cs': 'Budování systémů, které dokáží komunikovat s lidmi, je klíčovým problémem umělé inteligence. Tato práce navrhuje novou architekturu neuronové sítě pro výběr odezvy v komplexním dialogovém prostředí. Architektura aplikuje pozornost kontextové úrovně a zahrnuje další externí znalosti poskytované popisem slov specifických pro doménu. Používá obousměrnou Gated Recurrent Unit (GRU) pro kódování kontextu a odpovědí a učí se sledovat kontextová slova vzhledem k reprezentaci latentní odpovědi a naopak. Kromě toho obsahuje externí informace specifické pro doménu pomocí jiné GRU pro kódování popisů klíčových slov domény. To umožňuje lepší reprezentaci klíčových slov specifických pro doménu v odpovědích, a tím zlepšuje celkový výkon. Experimentální výsledky ukazují, že náš model překonává všechny ostatní nejmodernější metody pro výběr odezvy v konverzacích s více otáčkami.', 'et': 'Ehitussüsteemid, mis suudavad inimestega suhelda, on tehisintellekti põhiprobleem. Käesolev töö pakub välja uudse neurovõrgu arhitektuuri reaktsiooni valimiseks otsast otsani mitmekäigulise vestlusdialoogi seadistuses. Arhitektuur rakendab kontekstitaseme tähelepanu ja sisaldab täiendavaid väliseid teadmisi, mida annavad domeenispetsiifiliste sõnade kirjeldused. See kasutab konteksti ja vastuste kodeerimiseks kahesuunalist värvitud korduvühikut (GRU) ning õpib osalema üle kontekstisõnade, mis annavad latentse vastuse esituse ja vastupidi. Lisaks sisaldab see väliseid domeenispetsiifilisi andmeid, kasutades domeeni märksõnade kirjelduste kodeerimiseks teist GRU-d. See võimaldab paremini esindada domeenipõhiseid märksõnu vastustes ja parandab seega üldist tulemuslikkust. Eksperimentaalsed tulemused näitavad, et meie mudel ületab kõiki teisi kaasaegseid meetodeid vastuse valimiseks mitmekäigulistes vestlustes.', 'ha': "Builurin tsari da za'a iya yi wasiyya da mutum, yana da wata matabbata mai ƙaranci a cikin Intifar Hakima. Wannan aikin yana ƙayyade wani matsayin tsarin jerin neural na yanzu wa zaɓen ajibu cikin tsarin zauren akwatin bayani na daban-daban-daban-daban mai haɗuwa. An amfani da muhallin daraja na cikin muhalli kuma yana shigar da wani ilmi na ƙarƙashin da aka azurta su da fassarar-faɗi-don-Domen. Ina amfani da Unit na Takin da Akwai na Taked Duk-Directive (GRU) wa kodi context- duration and karɓars and leare to attend over the context words that the latest part of the Reposition and versa. Da wannan, yana shigar da bayani na guda masu ƙayyade maɓalli da zai yi amfani da wani GRU don ya kodi tsarin maɓallin ayuka ɗin Domen. Wannan yana yarda da mafi kyau ga wakilishi kalmõmi na-Domin-ƙayyade cikin majibu, kuma yana ƙara gaba ga aikin da shi gaba ɗaya. Matarin jarrabai ke nuna cewa misalinmu yana samar da duk hanyõyin-halin-sanar wa zaɓen ajibu cikin majuyawan-turu.", 'sk': 'Gradbeni sistemi, ki lahko komunicirajo z ljudmi, so osrednji problem v umetni inteligenci. To delo predlaga novo arhitekturo nevronskega omrežja za izbiro odzivov v nastavitvi pogovornega dialoga od konca do konca. Arhitektura uporablja kontekstno pozornost in vključuje dodatno zunanje znanje, ki ga zagotavljajo opisi domenskih besed. Za kodiranje konteksta in odzivov uporablja dvosmerno Gated Recorrent Unit (GRU) za kodiranje konteksta in odzivov ter se nauči udeležiti nad kontekstnimi besedami glede na latentno predstavitev odziva in obratno. Poleg tega vključuje zunanje podatke, specifične za domeno, z drugim GRU za kodiranje opisov domenskih ključnih besed. To omogoča boljšo predstavitev ključnih besed, specifičnih za domeno, v odgovorih in s tem izboljša splošno uspešnost. Eksperimentalni rezultati kažejo, da naš model presega vse ostale najsodobnejše metode za izbiro odzivov v večobratnih pogovorih.', 'he': 'בניית מערכות שיכולות לתקשר עם בני האדם היא בעיה בעיקרית במידע מלאכותי. העבודה הזו מציעה ארכיטקטורת רשת עצבית חדשה לבחירה של תגובה בסוף-לסוף בתערוכת דיאלוג שיחה רבה-פנים. הארכיטקטורה מפעילה תשומת לב רמת הקשר ומכילה ידע חיצוני נוסף שנספק על ידי תיאורים של מילים ספציפיות לתחום. הוא משתמש ביחידה דו-כיוונית משערת מתחזרת (GRU) כדי לקוד הקשר והתגובות ולמד להשתתף במילים הקשר בהתחשב ביציגת התגובה המוסתרת והפך. In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions.  זה מאפשר לייצג טוב יותר של מילים מפתחות ספציפיות לתחום בתגובות ולכן משפר את ההופעה הכללית. תוצאות ניסויים מראות שהדוגמא שלנו מובילה את כל השיטות האחרות המאודמות לבחירת תגובה בשיחות רבות.', 'jv': 'Daerah-sistem sing bisa komunikasi karo perbudhakan iki sak susahe perbudhakan ning artifil sing apik. Awak iki mbukak ngebahsa akeh penyane tambahan Neral kanggo langgar nggambar respon ning mulai end-to-end multi-convert conversations dialog. The architecture section In Addition, it inserts externe domain special information use a second gruU for koding the domain keyword descriptions. This enables the melter representation of domain-special keywords in responses and hende compromises the total output. Perintah sing paling nggambar na modelu sing gawe akeh banter state-of-the-arts banjur gambar nggambar barang kanggo langgar banter', 'bo': 'མི་དང་མི་དང་འབྲེལ་འདྲེན་བྱེད་ཆོས་བའི་ཐབས་ལམ་སྒྲིག་ནི་ཚོར་རྩིས་གཞུང་གི་དཀའ་ངལ་ཞིག་རེད། This work proposes a new neural network architecture for response selection in an end-to-end multi-turn conversational dialog setting. The architecture applies context level attention and incorporates additional external knowledge provided by descriptions of domain-specific words. It uses a two-directional Gated Recurrent Unit (GRU)for encoding context and responses and learns to attend over the context words given the latent response representation and the vice versa. In addition, it incorporates external domain specific information using another GRU for encoding the domain keyword descriptions. འདིས་ལན་ཚུལ་ཐོབ་པའི་དྲ་རྒྱ་སྟངས་དམིགས་འཛུགས་པའི་གཙོ་ཚིག་གི་རྟོགས་པ་ལ་ཕར་རྒྱས་ཐུབ་པ་ཡིན། ལག་ལེན་འཐབ་པའི་གནད་སྡུད་གྱིས་ང་ཚོའི་མ་དབྱིབས་གནད་སྡུད་མིན་འདུག'}
{'en': 'The Lifted Matrix-Space Model for Semantic Composition', 'ar': 'نموذج المصفوفة المرتفعة للفضاء للتكوين الدلالي', 'es': 'El modelo matriz-espacio elevado para la composición semántica', 'fr': 'Le modèle spatio-matriciel levé pour la composition sémantique', 'pt': 'O Modelo Matriz-Espaço Elevado para Composição Semântica', 'ja': 'セマンティック構成のための持ち上げられた行列空間モデル', 'hi': 'शब्दार्थ संरचना के लिए उठाया मैट्रिक्स-अंतरिक्ष मॉडल', 'zh': '语义合擢矩阵空间模样', 'ru': 'Подъемная матрично-пространственная модель для семантической композиции', 'ga': 'An Múnla Ardaithe Maitrís-Spáis don Chomhdhéanamh Séimeantach', 'ka': 'Name', 'hu': 'A felemelt mátrix-térmodell a szemantikus összetételhez', 'kk': 'Semantic Composition үшін жоғарылған матрикс- бос үлгісі', 'el': 'Το ανυψωμένο μοντέλο μήτρας-χώρου για τη σημαντική σύνθεση', 'it': 'Il modello spaziale-matrice sollevato per la composizione semantica', 'mk': 'Name', 'ms': 'Model Ruang-Matriks Angkat untuk Komposisi Semantik', 'mt': 'Il-Mudell tal-Ispazju tal-Matrix Lifted għall-Kompożizzjoni Semantika', 'lt': 'Semantinės sudėties pakilimo matricos ir kosmoso modelis', 'mn': 'Савантик бүтцийн өндөр матрикс-орон загвар', 'no': 'Modellen for fleire matriserom for semiantisk samansetting', 'pl': 'Podnoszony model macierzy-przestrzeni dla kompozycji semantycznej', 'si': 'Name', 'ml': 'സെമാന്റിക് കോമ്പോഷനിനുള്ള മാറ്റിക്സ്- സ്പെയിസ് മോഡല്\u200d', 'so': 'Model for Semantic Composition', 'sv': 'Den lyftade matris-rymdmodellen för semantisk sammansättning', 'ta': 'செமாண்டிக் கூட்டத்திற்கான உயர்ந்த பொருள்- இடைவெளி மாதிரி', 'ur': 'سیمنٹی کمپیشن کے لئے لائیٹ میٹریکس-فضا موڈل', 'ro': 'Modelul spațial-matrix ridicat pentru compoziția semantică', 'sr': 'Uzvišeni matriks-svemirski model za semantičku kompoziciju', 'uz': 'Name', 'vi': 'The Lifted ma trận-Space Model for Semantin Composition', 'nl': 'Het opgeheven matrix-ruimtemodel voor semantische compositie', 'da': 'Den løftede matrix-rum model for semantisk sammensætning', 'bg': 'Повдигнат матрично-пространствен модел за семантична композиция', 'hr': 'Uzvišeni matriks-svemirski model za semantičku kompoziciju', 'de': 'Das angehobene Matrix-Raum-Modell für die semantische Komposition', 'id': 'Model Ruang Matriks Lift untuk Komposisi Semantik', 'ko': '의미 합성의 향상 매트릭스 공간 모델', 'fa': 'مدل فضای ماتریکس بالا برای ترکیب سیمانتیک', 'sw': 'Modeli ya Matrix-Space kwa ajili ya Composition of Semantic', 'tr': 'Saýlaw Renki', 'af': 'Die Ligte Matrix- Space Model vir Semantiese Komposisie', 'sq': 'Modeli i hapësirës së matricës së ngritur për përbërjen Semantike', 'am': 'undo-type', 'hy': 'Comment', 'az': 'Semantik Komposisyon üçün Yükselmiş Matrix-Boşluq Modeli', 'bs': 'Uzvišeni matriks-svemirski model za semantičku kompoziciju', 'bn': 'The Lifted Matrix-Space Model for Semantic Composition', 'cs': 'Zvednutý matričový a prostorový model pro sémantickou kompozici', 'ca': "El model d'espai-matrix elevada per a la composició Semàtica", 'fi': 'Nostettu matriisi-avaruusmalli semanttiselle kokoonpanolle', 'et': 'Tõstetud maatriks-ruumi mudel semantilise koostise jaoks', 'jv': 'structural navigation', 'ha': 'The Lifted Matrix-Space Model for Semantic Composition', 'sk': 'Dvignjeni matrični prostor model za semantično sestavo', 'he': 'מודל חלל המטריקס העלה למערכת סמנטית', 'bo': 'རྒྱ་མཚོན་པའི་ཆ་རྐྱེན་སྟངས་ཀྱི་ཆ་རྐྱེན་གྱི་མ་དབྱིབས'}
{'en': 'Tree-structured neural network architectures for sentence encoding draw inspiration from the approach to semantic composition generally seen in ', 'ar': 'تستمد معماريات الشبكة العصبية المهيكلة بالشجرة لترميز الجملة الإلهام من نهج التركيب الدلالي الذي يُنظر إليه عمومًا في اللغويات الرسمية ، وقد أظهرت تحسينات تجريبية على نماذج التسلسل المماثلة من خلال القيام بذلك. علاوة على ذلك ، يمكن أن تؤدي إضافة مصطلحات التفاعل المضاعف إلى وظائف التكوين في هذه النماذج إلى تحسينات إضافية كبيرة. ومع ذلك ، فإن الأساليب التركيبية الحالية التي تتبنى مثل هذا المقياس القوي لوظيفة التكوين ضعيف ، مع تفجر أعداد المعلمات مع نمو أبعاد النموذج أو حجم المفردات. نقدم نموذج Lifted Matrix-Space ، الذي يستخدم تحولًا عالميًا لرسم خريطة لزخارف الكلمات المتجهة إلى المصفوفات ، والتي يمكن بعد ذلك تكوينها عبر عملية تعتمد على مضاعفة المصفوفة. تنقل وظيفة التكوين الخاصة به بشكل فعال عددًا أكبر من عمليات التنشيط عبر الطبقات مع عدد قليل نسبيًا من معلمات النموذج. نقوم بتقييم نموذجنا على مجموعة Stanford NLI ، و Multi-Genre NLI corpus ، و Stanford Sentiment Treebank ووجدنا أنه يتفوق باستمرار على TreeLSTM (Tai et al. ، 2015) ، أفضل وظيفة تكوين معروفة للنماذج الهيكلية الشجرية.', 'fr': "Les architectures de réseaux neuronaux structurés en arbre pour le codage de phrases s'inspirent de l'approche de la composition sémantique généralement utilisée en linguistique formelle et ont ainsi montré des améliorations empiriques par rapport à des modèles de séquences comparables. De plus, l'ajout de termes d'interaction multiplicatifs aux fonctions de composition dans ces modèles peut apporter d'autres améliorations significatives. Cependant, les approches compositionnelles existantes qui adoptent une fonction de composition aussi puissante sont mal mises à l'échelle, le nombre de paramètres explosant à mesure que la dimension du modèle ou la taille du vocabulaire augmente. Nous présentons le modèle Lifted Matrix-Space, qui utilise une transformation globale pour mapper les incorporations de mots vectoriels à des matrices, qui peuvent ensuite être composées via une opération basée sur la multiplication matricielle. Sa fonction de composition transmet efficacement un plus grand nombre d'activations entre les couches avec relativement peu de paramètres de modèle. Nous évaluons notre modèle sur le corpus Stanford NLI, le corpus Multi-Genre NLI et le Stanford Sentiment Treebank et constatons qu'il surpasse constamment TreelsTM (Tai et al., 2015), la fonction de composition la plus connue pour les modèles structurés par arbre.", 'es': 'Las arquitecturas de redes neuronales estructuradas en árbol para la codificación de oraciones se inspiran en el enfoque de la composición semántica que generalmente se ve en la lingüística formal, y han demostrado mejoras empíricas con respecto a modelos de secuencia comparables al hacerlo. Además, la adición de términos de interacción multiplicativa a las funciones de composición en estos modelos puede producir mejoras adicionales significativas. Sin embargo, los enfoques composicionales existentes que adoptan una función de composición tan poderosa se escalan mal, con recuentos de parámetros que se disparan a medida que aumenta la dimensión del modelo o el tamaño Presentamos el modelo Lifted Matrix-Space, que utiliza una transformación global para mapear incrustaciones de palabras vectoriales a matrices, que luego se pueden componer mediante una operación basada en la multiplicación matriz-matriz. Su función de composición transmite eficazmente un mayor número de activaciones a través de las capas con relativamente pocos parámetros del modelo. Evaluamos nuestro modelo en el corpus de NLI de Stanford, el corpus de NLI de múltiples géneros y el Stanford Sentiment Treebank y descubrimos que supera consistentemente a TreelsTM (Tai et al., 2015), la función de composición anterior más conocida para los modelos estructurados en árbol.', 'pt': 'As arquiteturas de rede neural estruturadas em árvore para codificação de frases inspiram-se na abordagem da composição semântica geralmente vista na linguística formal e mostraram melhorias empíricas em modelos de sequência comparáveis ao fazê-lo. Além disso, adicionar termos de interação multiplicativa às funções de composição nesses modelos pode gerar melhorias adicionais significativas. No entanto, as abordagens de composição existentes que adotam uma função de composição tão poderosa escalam mal, com contagens de parâmetros explodindo à medida que a dimensão do modelo ou o tamanho do vocabulário aumentam. Apresentamos o modelo Lifted Matrix-Space, que usa uma transformação global para mapear embeddings de palavras vetoriais para matrizes, que podem então ser compostas por meio de uma operação baseada na multiplicação matriz-matriz. Sua função de composição transmite efetivamente um número maior de ativações entre camadas com relativamente poucos parâmetros de modelo. Avaliamos nosso modelo no corpus Stanford NLI, no corpus Multi-Genre NLI e no Stanford Sentiment Treebank e descobrimos que ele supera consistentemente o TreeLSTM (Tai et al., 2015), a função de composição anterior mais conhecida para modelos estruturados em árvore.', 'ja': '文を符号化するための木構造化されたニューラルネットワークアーキテクチャは、形式言語学で一般的に見られる意味構成へのアプローチからインスピレーションを引き出し、そうすることによって同等のシーケンスモデルよりも経験的な改善を示している。 さらに、これらのモデルにおける組成物機能に乗算相互作用用語を追加することで、有意なさらなる改善をもたらすことができる。 しかしながら、このような強力な構成関数スケールを採用する既存の構成的アプローチは、モデルの次元または語彙サイズが大きくなるにつれてパラメータカウントが爆発的に増加するため、不十分である。 ベクトルワード埋め込みを行列にマッピングするためにグローバル変換を使用し、行列-行列の乗算に基づく演算を介して構成することができる、リフトされた行列-空間モデルを紹介します。 その組成機能は、比較的少ないモデルパラメータで、より多くの活性化を層にわたって効果的に伝達する。 私たちは、スタンフォードNLIコーパス、マルチジェンレNLIコーパス、およびスタンフォードセンチメントツリーバンクに関するモデルを評価し、それがツリー構造モデルのための以前に最もよく知られている構成関数であるTreeLSTM （ Tai et al., 2015 ）を一貫して上回っていることを発見しました。', 'hi': 'वाक्य एन्कोडिंग के लिए पेड़-संरचित तंत्रिका नेटवर्क आर्किटेक्चर आमतौर पर औपचारिक भाषाविज्ञान में देखे जाने वाले शब्दार्थ संरचना के दृष्टिकोण से प्रेरणा लेते हैं, और ऐसा करके तुलनीय अनुक्रम मॉडल पर अनुभवजन्य सुधार दिखाया गया है। इसके अलावा, इन मॉडलों में संरचना कार्यों में गुणात्मक बातचीत की शर्तों को जोड़ने से महत्वपूर्ण और सुधार हो सकते हैं। हालांकि, मौजूदा रचनात्मक दृष्टिकोण जो इस तरह के एक शक्तिशाली रचना फ़ंक्शन स्केल को खराब तरीके से अपनाते हैं, पैरामीटर गिनती के साथ मॉडल आयाम या शब्दावली आकार बढ़ने के रूप में विस्फोट होता है। हम लिफ्टेड मैट्रिक्स-स्पेस मॉडल पेश करते हैं, जो मैट्रिक्स को वेक्टर शब्द एम्बेडिंग को मैप करने के लिए एक वैश्विक परिवर्तन का उपयोग करता है, जिसे तब मैट्रिक्स-मैट्रिक्स गुणा के आधार पर एक ऑपरेशन के माध्यम से बनाया जा सकता है। इसकी संरचना समारोह प्रभावी रूप से अपेक्षाकृत कुछ मॉडल मापदंडों के साथ परतों में सक्रियणों की एक बड़ी संख्या को प्रसारित करता है। हम स्टैनफोर्ड एनएलआई कॉर्पस, मल्टी-शैली एनएलआई कॉर्पस और स्टैनफोर्ड सेंटिमेंट ट्रीबैंक पर अपने मॉडल का मूल्यांकन करते हैं और पाते हैं कि यह लगातार ट्रीएलएसटीएम (ताई एट अल।', 'zh': '句编码之树结构神经网络架构取灵感于语言学语义,而见出对可校序模形之验。 合函数乘法交互作用项益明。 然用此强合函数今为法甚劣,参数随其维度词汇大小而爆炸式长。 引入矩阵间,以全局易将向量词嵌映射于矩阵,然后可以矩阵 - 矩阵乘之运为矩阵。 其合函数以对少者参数有效跨层传输大激活。 于斯坦福NLI语料库,多流NLI语料库与斯坦福情树库估其形势,见其终始优于TreeLSTM(Tai等,2015),此前最着名之复合函数。', 'ru': 'Структурированные по дереву нейронные сетевые архитектуры для кодирования предложений черпают вдохновение из подхода к семантической композиции, обычно наблюдаемого в формальной лингвистике, и показали эмпирические улучшения по сравнению с сопоставимыми моделями последовательностей, делая это. Кроме того, добавление мультипликативных условий взаимодействия к функциям композиции в этих моделях может привести к значительному дальнейшему улучшению. Тем не менее, существующие композиционные подходы, которые принимают такую мощную шкалу функций композиций, плохо, с параметрами, которые растут по мере роста размера модели или размера словарного запаса. Мы представляем модель Lifted Matrix-Space, которая использует глобальное преобразование для отображения вложений векторных слов в матрицы, которые затем могут быть составлены с помощью операции, основанной на умножении матрица-матрица. Его композиционная функция эффективно передает большее количество активаций по слоям с относительно небольшим количеством параметров модели. Мы оцениваем нашу модель на корпусе Stanford NLI, корпусе Multi-Genre NLI и банке Stanford Sentiment Treebank и обнаруживаем, что она последовательно превосходит TreeLSTM (Tai et al., 2015), предыдущую наиболее известную композиционную функцию для моделей с деревьями.', 'ga': 'Tarraingíonn ailtireachtaí líonra néar-struchtúrtha crann le haghaidh ionchódú pianbhreithe inspioráid ón gcur chuige maidir le comhdhéanamh séimeantach a fheictear go ginearálta sa teangeolaíocht fhoirmiúil, agus tá feabhsuithe eimpíreacha léirithe acu ar mhúnlaí seichimh inchomparáide trína dhéanamh. Ina theannta sin, má chuirtear téarmaí idirghníomhaíochta iolracha leis na feidhmeanna comhdhéanamh sna samhlacha seo, féadfar feabhsuithe suntasacha breise a bhaint amach. Mar sin féin, ní fheidhmíonn cineálacha cur chuige cumadóireachta atá ann cheana féin a ghlacann scála chomh cumhachtach comhdhéanamh go dona, le háirimh na bparaiméadar ag méadú de réir mar a thagann méadú ar thoise an mhúnla nó ar mhéid an stór focal. Tugaimid isteach an tsamhail Lifted Maitrís-Spáis, a úsáideann claochlú domhanda chun leabaithe focal veicteoir a mhapáil go maitrísí, ar féidir a chomhdhéanamh ansin trí oibríocht bunaithe ar iolrú maitrís-maitrís. Tarchuireann a fheidhm chomhdhéanaimh go héifeachtach líon níos mó gníomhachtaithe thar sraitheanna le paraiméadair mhúnla sách beag. Déanaimid measúnú ar ár múnla ar chorpas Stanford LNLI, ar chorpas NLI Ilchineálach, agus ar Stanford Sentiment Treebank agus feicimid go sáraíonn sé go comhsheasmhach TreeLSTM (Tai et al., 2015), an fheidhm chomhdhéanaimh is fearr aithne roimhe seo le haghaidh samhlacha crann-struchtúrtha.', 'ka': 'სტრუქტურაციული ნეიროლური ქსელის აქტიქტიქტურები სიტყვების კოდიქტურაციისთვის გამოყენება სემონტიკური კომპოზიციისთვის, რომელიც სემონტიკური კომპოზიციისთვის ჩვენებულია და ამ დამატებით, გამრავლებული კომპოზიციონის ფუნქციების დამატება ამ მოდელში შესაძლებელია უფრო მნიშვნელოვანი უფრო მეტადება. მაგრამ მსგავსი კომპოზიციონიური გადახმარება, რომელიც ასეთი ძალიან კომპოზიციონის ფუნქციის სკონციონის სკონციონის სკონციონის სკონციონის გადახ ჩვენ მოვიყენებთ მარტიქსი-სიმრცე მოდელს, რომელიც გლობალური გარცნობა გამოყენებს გვექტორის სიტყვას მარტიქებისთვის, რომელიც შემდეგ შეიძლება შექმნა მარტიქსი-მარტიქსის გამრავლება მისი კომპოზიციის ფუნქცია ეფექტიურად უფრო დიდი რაოდენობა აქტივიციების მონაცემებით, რომლებიც პარამეტრებით პარამეტრებით მ ჩვენ მოდელს სტანფორდის NLI კორპუსში, მრავალგენერი NLI კორპუსში და სტანფორდის Sentiment Treebank-ზე გავუმუშავებთ, რომ ეს მუშაობელად უფრო გავაკეთებს TreeLSTM (Tai et al., 2015), პირველი უცნობილი კომპოზიციის ფუნქცია, რომელიც ხე', 'hu': 'A mondatkódoláshoz szükséges, fa strukturált neurális hálózati architektúrák inspirációt nyújtanak a formai nyelvészetben általában tapasztalt szemantikai összetétel megközelítéséből, és ezzel tapasztalati javulást mutattak a hasonló szekvencia modellekhez képest. Továbbá, ha ezekben a modellekben a kompozíciós funkciókhoz multiplikatív interakciós kifejezéseket adnak hozzá, jelentős további javulást eredményezhet. Azonban a meglévő kompozíciós megközelítések, amelyek ilyen erőteljes kompozíciós függvényt alkalmaznak, rosszul skáláznak, a paraméterek száma pedig robban a modell dimenziójával vagy a szókincs méretével. Bemutatjuk a Lifted Matrix-Space modellt, amely globális transzformációt használ a vektorszóbeágyazások mátrixokra történő leképezésére, amelyeket ezután egy mátrix-mátrix szorzáson alapuló művelet segítségével lehet összeállítani. Kompozíciós funkciója hatékonyan továbbít nagyobb számú aktivációt a rétegek között viszonylag kevés modellparaméterrel. Modellünket a Stanford NLI korpuszon, a Multi-Genre NLI korpuszon és a Stanford Sentiment Treebankon értékeljük, és úgy találjuk, hogy következetesen felülmúlja a TreeLTM (Tai et al., 2015), amely a korábbi legismertebb kompozíciós funkció a fa strukturált modellek esetében.', 'el': 'Οι αρχιτεκτονικές νευρωνικών δικτύων με δομή δέντρου για την κωδικοποίηση προτάσεων αντλούν έμπνευση από την προσέγγιση της σημασιολογικής σύνθεσης που παρατηρείται γενικά στην τυπική γλωσσολογία, και έχουν δείξει εμπειρικές βελτιώσεις σε σχέση με συγκρίσιμα μοντέλα ακολουθίας με αυτό τον τρόπο. Επιπλέον, η προσθήκη όρων πολλαπλής αλληλεπίδρασης στις λειτουργίες σύνθεσης σε αυτά τα μοντέλα μπορεί να επιφέρει σημαντικές περαιτέρω βελτιώσεις. Ωστόσο, οι υπάρχουσες συνθετικές προσεγγίσεις που υιοθετούν μια τόσο ισχυρή λειτουργία σύνθεσης κλιμακώνονται ανεπαρκώς, με τους αριθμούς παραμέτρων να εκρήγνυνται καθώς αυξάνεται η διάσταση του μοντέλου ή το μέγεθος του λεξιλογίου. Παρουσιάζουμε το μοντέλο Ανυψωμένο Μάτριξ-Χώρο, το οποίο χρησιμοποιεί έναν παγκόσμιο μετασχηματισμό για να χαρτογραφήσει διανυσματικές ενσωμάτωσεις λέξεων σε πίνακες, οι οποίοι στη συνέχεια μπορούν να συνθεθούν μέσω μιας λειτουργίας βασισμένης στον πολλαπλασιασμό μήτρας-μήτρας. Η λειτουργία σύνθεσής του μεταδίδει αποτελεσματικά μεγαλύτερο αριθμό ενεργοποιήσεων σε στρώματα με σχετικά λίγες παραμέτρους μοντέλου. Αξιολογούμε το μοντέλο μας στο σώμα του Στάνφορντ, στο σώμα πολλαπλών ειδών και στην τράπεζα συναισθημάτων του Στάνφορντ και διαπιστώνουμε ότι ξεπερνά σταθερά το TreeLSTM (Tai et al., 2015), την προηγούμενη πιο γνωστή λειτουργία σύνθεσης για μοντέλα με δομή δέντρων.', 'mk': 'Архитектурите на структурирана дрво на нервната мрежа за кодирање на речениците привлекуваат инспирација од пристапот кон семантичната композиција генерално гледана во формалната лингвистика, и покажаа емпириски подобрувања во однос на споредливите модели на секвенца со тоа што Покрај тоа, додавањето на множителните термини на интеракција на функциите на композицијата во овие модели може да предизвика значителни понатамошни подобрувања. Сепак, постоечките композициски пристапи кои усвојуваат ваква моќна скала на функционална композиција лошо, со бројот на параметри експлодирајќи со зголемување на димензијата на моделот или големината на речникот. Ние го претставуваме моделот на подигната матрица-простор, кој користи глобална трансформација за да ги мапира вградувањата на векторните зборови во матрици, кои потоа можат да бидат составени преку операција базирана на множењето на матрица-матрица. Нејзината композициска функција ефикасно пренесува поголем број активации преку слоеви со релативно малку параметри на моделот. Го проценуваме нашиот модел на корпусот на Стенфорд НЛИ, корпусот на Мулти-генер НЛИ и Стенфорд Сентимент Treebank и откриваме дека константно го надминува TreeLSTM (Tai et al., 2015), претходната најдобро позната функција на композиција за дрвени модели.', 'it': "Le architetture di rete neurale strutturate ad albero per la codifica delle frasi traggono ispirazione dall'approccio alla composizione semantica generalmente visto nella linguistica formale, e hanno mostrato miglioramenti empirici rispetto a modelli di sequenza comparabili. Inoltre, l'aggiunta di termini di interazione moltiplicativa alle funzioni di composizione in questi modelli può produrre ulteriori miglioramenti significativi. Tuttavia, gli approcci compositivi esistenti che adottano una funzione di composizione così potente scala male, con i conteggi dei parametri che esplodono man mano che la dimensione del modello o la dimensione del vocabolario cresce. Introducemo il modello Lifted Matrix-Space, che utilizza una trasformazione globale per mappare le incorporazioni di parole vettoriali alle matrici, che possono poi essere composte tramite un'operazione basata sulla moltiplicazione matrice-matrice. La sua funzione di composizione trasmette efficacemente un maggior numero di attivazioni attraverso strati con relativamente pochi parametri di modello. Valutiamo il nostro modello sul corpo Stanford NLI, sul corpo Multi-Genre NLI e sulla Stanford Sentiment Treebank e scopriamo che supera costantemente TreeLSTM (Tai et al., 2015), la precedente funzione compositiva più conosciuta per i modelli strutturati ad albero.", 'ms': 'Arkitektur rangkaian saraf struktur pokok untuk pengekodan kalimat menarik inspirasi dari pendekatan ke komposisi semantik yang biasanya dilihat dalam bahasa formal, dan telah menunjukkan peningkatan empirik atas model urutan yang sama dengan melakukannya. Lagipun, menambah terma interaksi pendaraban ke fungsi komposisi dalam model ini boleh memberikan peningkatan yang lebih penting. Namun, pendekatan komposisi yang wujud yang mengadopsi skala fungsi komposisi yang kuat seperti ini tidak baik, dengan kiraan parameter meletup sebagai dimensi model atau saiz vokbulari tumbuh. Kami memperkenalkan model Matriks-Ruang Tinggi, yang menggunakan transformasi global untuk peta penyampaian perkataan vektor ke matriks, yang kemudian boleh dikomposisikan melalui operasi berdasarkan pendaraban matriks-matriks. Fungsi komposisinya secara efektif menghantar bilangan aktivasi yang lebih besar melalui lapisan dengan parameter model relatif sedikit. Kami menilai model kami pada korpus NLI Stanford, korpus NLI Multi-Genre, dan Treebank Sentiment Stanford dan mendapati bahawa ia secara konsisten melebihi TreeLSTM (Tai et al., 2015), fungsi komposisi terbaik terdahulu untuk model struktur pokok.', 'ml': 'വാക്കുകൊടുക്കുന്നതിനുള്ള വൃക്ഷത്തിലേക്കുള്ള ന്യൂറല്\u200d നെറ്റൂറല്\u200d ശൃംഖല ആര്\u200dക്ടിക്കറ്റുകള്\u200d സാധാരണ ഭാഷകങ്ങളിലേക്കുള്ള സംഘടനയിലേക്കുള്ള സ്വാ പിന്നീട്, ഈ മോഡലിലെ സജ്ജീകരണത്തിന്റെ ഫങ്ഷനുകള്\u200dക്ക് ഇരട്ടിക്കൂട്ടുന്ന ഇടപാടുകള്\u200d ചേര്\u200dക്കുന്നതിന് കൂട However, existing compositional approaches that adopt such a powerful composition function scale poorly, with parameter counts exploding as model dimension or vocabulary size grows.  ലിഫ്റ്റ് മാറ്റ്രിക്സ്-സ്പെയിസ് മോഡലിനെ ഞങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു. അത് ഗ്ലോബല്\u200d മാറ്റിമാറ്റങ്ങള്\u200d ഉപയോഗിക്കുന്നു വെക്റ്റര്\u200d വാക്ക് മാറ്റ അതിന്റെ സജ്ജീകരണങ്ങളുടെ ഫങ്ഷന്\u200d പ്രാവര്\u200dത്ഥ്യമായി സജ്ജീകരണങ്ങളുടെ കൂടുതല്\u200d വലിയ സംഖ്യകള്\u200d തടുകളിലൂടെ മാറ്റുന ഞങ്ങള്\u200d സ്റ്റാന്\u200dഫോര്\u200dഡ് NLI കോര്\u200dപ്പുസിന്\u200dറെ മോഡലിനെ വിലാസപ്പെടുത്തുന്നു, മരത്തെ നിര്\u200dമ്മിക്കപ്പെട്ട മോഡലുകള്\u200d', 'mt': 'L-arkitetturi tan-netwerk newrali strutturati mis-siġar għall-kodifikazzjoni tas-sentenzi jieħdu ispirazzjoni mill-approċċ għall-kompożizzjoni semantika ġeneralment osservata fil-lingwistika formali, u wrew titjib empiriku fuq mudelli ta’ sekwenza komparabbli billi għamlu dan. Moreover, adding multiplicative interaction terms to the composition functions in these models can yield significant further improvements.  Madankollu, approċċi kompożittivi eżistenti li jadottaw skala tal-funzjoni tal-kompożizzjoni b’saħħitha bħal din b’mod ħa żin, bl-għadd ta’ parametri jisplodi hekk kif id-dimensjoni tal-mudell jew id-daqs vokabulari jikber. Aħna nintroduċu l-mudell tal-Matrix-Space Lifted, li juża trasformazzjoni globali biex jimmappa l-inkorporazzjonijiet tal-kelma tal-vettur f’matriċi, li mbagħad tista’ tiġi komposta permezz ta’ operazzjoni bbażata fuq multiplikazzjoni tal-matriċi-matriċi. Il-funzjoni tal-kompożizzjoni tagħha effettivament tittrażmetti numru akbar ta’ attivazzjonijiet minn saffi għal oħra b’parametri tal-mudell relattivament ftit. Aħna jevalwaw il-mudell tagħna fuq il-korpus NLI ta’ Stanford, il-korpus NLI Multi-Genre, u s-Sentiment Treebank ta’ Stanford u nsibu li dan b’mod konsistenti jeċċedi TreeLSTM (Tai et al., 2015), il-funzjoni ta’ kompożizzjoni preċedenti l-aħjar magħrufa għal mudelli strutturati minn siġar.', 'mn': 'Мод бүтээгдэхүүний мэдрэлийн сүлжээний архитектурууд нь өгүүлбэр кодлох архитектуруудын урам зориулалтын архитектурууд нь ихэвчлэн официальны хэлний хэлний хэлбэрээр харагдаж байгаа семантик бүтээгдэхүүнээс урам зориулж, харьцуулагдах Мөн эдгээр загваруудын бүтээлтийн функцүүдэд үржүүлэх харилцааны томъёог нэмэх нь илүү их сайжруулах боломжтой. Гэхдээ хэзээ ч, хэмжээст хэмжээсүүд эсвэл үгийн хэмжээсүүд нэмэгддэг хэмжээсүүдийг бага зэрэг хүчирхэг зохион байгуулах арга зам нь бага зэрэг хүчирхэг байдаг. Бид өндөр өндөр Матрикс-Сайн загварыг танилцуулдаг. Энэ нь матрикс-матрикс үржүүлэхээр үндсэн үйл ажиллагааны аргаар вектор үгийг матрицууд руу газрын зураг зурах болно. Үүний бүтээлтийн функц нь харьцангуй цөөн загварын параметрлүүдтэй илүү их хэмжээний ажиллагааг дамжуулдаг. Бид Стэнфорд NLI корпус, олон төрлийн NLI корпус, Стэнфорд Sentiment Treebank-ын загварын загварыг үнэлдэг. Энэ загвар нь модны бүтээгдэхүүний хамгийн сайн мэдэгдсэн бүтээгдэхүүний TreeLSTM (Tai et al., 2015) дээр үргэлж үргэлжилдэг.', 'no': 'Trestrukturerte neuralnettverksarkitekturar for setningskodingar teikn inspirasjon frå tilnærminga til semantisk samling som oftast ser i formelt språk, og har vist empiriske forbedringar over sammenlignbare sekvensmodeller ved å gjera det. I tillegg kan du leggja til multiplikativ samarbeidsfunksjonar i samlingsfunksjonane i desse modelane føre signifikante forbetringar. Det finst imidlertid samansettingstilnærmingar som godtar slik kraftig samansettingsfunksjonsskala slik ugyldig, med parametrar teller eksplodering som modelldimensjon eller ordbokstørrelse aukar. Vi introduserer den leve matriserommodellen, som brukar eit globalt transformasjon for å kartera vektorordinnbygging til matriser. Dette kan derfor lagrast via ein operasjon basert på matrisematrisemultiplikasjon. Den samlingsfunksjonen gjev effektivt eit større tal aktivering over lag med relativt få modellparametrar. Vi evaluerer modellen vårt på Stanford NLI corpus, Multi-Genre NLI corpus, og Stanford Sentiment Treebank og finn at den konsistent utfører TreeLSTM (Tai et al., 2015), den førre beste kjente komposisjonsfunksjonen for tre-strukturerte modeller.', 'kk': 'Бұтақ құрылған невралдық желі архитектуралары сәйкестік кодтамасының қасиетінен семантикалық тілдіктерде көрінетін симпатикалық құрылымына көмектеседі, және бұл көмектесілік үлгілерден салыстырылатын м Қосымша, бұл үлгілердегі композициялық функцияларына көптеген әріптерді қосу үшін көптеген әріптерді жақсарту үшін көптеген. Бірақ мұндай қуатты композициялық функциялардың масштабын келтіріп, параметрлердің өлшемі немесе сөздік өлшемі ретінде бұл параметрлердің саны өзгертілген. Біз Жоғарылған Матрикс- Бос орын үлгісін келтіреміз. Бұл вектор сөздерді матрицаларға ендіру үшін әлемді түрлендіру үшін матрицаларға картасын қолданады. Содан кейін матрица- матрица көбейту негізін Осы композициялық функциясы қабаттардың арасындағы кейбір үлгі параметрлері арқылы үлкен белсенділік санын жібереді. Біз Стэнфорд NLI корпус, көптеген NLI корпус және Стэнфорд Сентиментті Бұтабанкы үлгісімізді оқу үшін ол TreeLSTM (Tai et al., 2015) деген алдыңғы белгілі құрылған моделдердің ең жақсы композициялық функциясын таптық.', 'lt': 'Tree-structured neural network architectures for sentence encoding draw inspiration from the approach to semantic composition generally seen in formal linguistics, and have shown empirical improvements over comparable sequence models by doing so. Be to, prie šių modelių sudėties funkcijų pridedant dauginamąją sąveiką gali būti gerokai patobulinta. Vis dėlto esami sudėties metodai, kuriais taikoma tokia galinga sudėties funkcijos skalė, mažai, o parametrų skaičius sprogia, nes didėja modelio matmuo arba žodyno dydis. Mes pristatome kilusios matricos-kosmoso model į, kuris naudoja pasaulinę transformaciją, kad paveikslėlėtų vektoriaus žodžių įterpimus į matrizes, kurios gali būti sudarytos per operaciją, pagrįstą matricos-matricos dauginimu. Jos sudėties funkcija veiksmingai perduoda didesnį aktyvavimo skaičių įvairiuose sluoksniuose su palyginti nedaug modelio parametrų. Vertiname savo model į Stanford NLI corpus, Multi-Genre NLI corpus ir Stanford Sentiment Treebank ir nustatome, kad jis nuosekliai viršija TreeLSTM (Tai et al., 2015 m.), ankstesnę geriausiai žinomą medžio struktūruotų modelių sudėties funkciją.', 'ro': 'Arhitecturile de rețele neurale structurate în copaci pentru codificarea propozițiilor se inspiră din abordarea compoziției semantice văzută în general în lingvistica formală și au arătat îmbunătățiri empirice față de modele de secvență comparabile prin acest lucru. Mai mult decât atât, adăugarea de termeni de interacțiune multiplicativă la funcțiile de compoziție din aceste modele poate duce la îmbunătățiri semnificative suplimentare. Cu toate acestea, abordările compoziționale existente care adoptă o funcție de compoziție atât de puternică scalează slab, numărul parametrilor explodează pe măsură ce dimensiunea modelului sau dimensiunea vocabularului crește. Introducem modelul Lifted Matrix-Space, care utilizează o transformare globală pentru a cartografia încorporările de cuvinte vectoriale în matrici, care pot fi apoi compuse printr-o operație bazată pe multiplicarea matrice-matrice. Funcția sa de compoziție transmite eficient un număr mai mare de activări pe straturi cu relativ puțini parametri de model. Evaluăm modelul nostru pe corpul Stanford NLI, corpul Multi-Genre NLI și Stanford Sentiment Treebank și constatăm că acesta depășește în mod constant TreeLSTM (Tai et al., 2015), cea mai cunoscută funcție de compoziție anterioară pentru modelele structurate în arbori.', 'pl': 'Strukturowane drzewa architektury sieci neuronowych do kodowania zdań czerpią inspirację z podejścia do kompozycji semantycznej ogólnie widzianego w językoznawstwie formalnym i wykazały poprawę empiryczną w porównywalnych modelach sekwencji. Ponadto dodanie mnożytnych terminów interakcji do funkcji kompozycji w tych modelach może przynieść znaczące dalsze ulepszenia. Jednak istniejące podejścia kompozycyjne, które przyjmują tak potężną funkcję kompozycji, słabo skalują się, a liczba parametrów eksploduje wraz ze wzrostem wymiaru modelu lub rozmiaru słownictwa. Przedstawiamy model Lifted Matrix-Space, który wykorzystuje globalną transformację do mapowania wektorowych osadzeń słów do macierzy, które można następnie skomponować poprzez operację opartą na mnożeniu macierzy-macierzy. Jego funkcja składu skutecznie przekazuje większą liczbę aktywacji przez warstwy o stosunkowo niewielkich parametrach modelu. Oceniamy nasz model na korpusie Stanford NLI, korpusie Multi-Genre NLI i Stanford Sentiment Treebank i stwierdzamy, że konsekwentnie przewyższa TreeLSTM (Tai et al., 2015), poprzednią najbardziej znaną funkcję kompozycji modeli strukturalnych drzew.', 'sr': 'Strukturirane neuralne mreže arhitekture za kodiranje rečenica privlače inspiraciju od pristupa semantičkoj kompoziciji obično viđenoj u formalnoj lingvistiki i pokazale su empiričke poboljšanje u usporedbenim modelima sekvencije tako. Osim toga, dodanje višestrukog interakcije funkcijama kompozicije u ovim modelima može donijeti značajne daljnje poboljšanje. Međutim, postojeći kompozicijski pristupi koji usvoje takvu moćnu skalu funkcije kompozicije loše, a parametri se računaju eksplozijom kao model dimenzija ili veličina rečenika. Predstavljamo uzvišeni matriks-svemirski model, koji koristi globalnu transformaciju da mapiraju vektorske reči ugrađene na matrice, koja se onda može sastaviti putem operacije bazirane na multiplikaciji matriksa. Njena funkcija kompozicije efikasno prenosi veći broj aktivacija preko slojeva sa relativno malo modelnih parametara. Procjenjujemo naš model na Stanford NLI korpusu, multi-Genre NLI korpusu, i Stanford Sentiment Treebank i saznajemo da to stalno iznosi TreeLSTM (Tai et al., 2015), prethodnu najpoznatu funkciju kompozicije za modele strukturirane na drvetu.', 'so': 'Dhirta-dhismaha shabakadda neurada ee qoriga ah ayaa ka soo baxa waxyaabaha uu ku qorayo qoraalka qoriga ah, waxaana tusay hagaajinta qaabka ah oo u eg qaabka qoraalka semantika ah. Sidoo kale, ku daro shuruudaha isku xiriirka oo kala duduwan oo ku saabsan shuqullada sameynta waxay soo bixi karaan beddelmo aad u weyn. Si kastaba ha ahaatee, waxaa jira hababka hoose ee ku jira, taas oo qaadata heerka shaqada oo xoogga leh, oo ay tirada parameterku ka baxaan sida daboolka ama sida qiyaastii hadalka. Tusaale-Lifted Matrix-Space, kaas oo isticmaalaya bedelka caalamiga ah si uu u karo sawirida word vector which is embedded into matrix, taas kadibna waxaa lagu sameyn karaa qeyb ku saleysan barashada matrix-matrix. Shaqooyinkeedu waxey si faa’iido leh u dirtaa waxqabad aad u weyn oo ku yaala saqafka aad u badan, waxayna leedahay parameter model. Tusaalka aan ku qiimeynaynaa kooxda Stanford NLI, kooxda badan ee NLI, iyo Stanford Sentiment Treebank, waxaynu ogaannaa in si joogto ah loo sameeyo TreeLSTM (Tai et al., 2015), qaabkii ugu horeeyay ee loo yaqaan kooxaha dhismaha qoriga ah.', 'si': 'වාක්ය සංකේතනය සඳහා වාක්ය සංකේතනය සඳහා ගස් සංකෘතිය නිර්මාණ ජාලය සංකෘතිය සංකේතනය සාමාන්\u200dය භාෂාවිකාරයෙන් පෙනුම් පෙනු ඒවගේම, මේ මොඩේල් වල සංවිධානයේ සංවිධානය සම්බන්ධ විධානය සම්බන්ධ විධානය කරන්න පුළුවන්. නමුත්, විශ්වාසිත සංවිධානය ප්\u200dරමාණයක් වර්ධනය කරනවා ඒ වගේම ශක්තිමත් සංවිධානයක් වර්ධනයක් වර්ධනය කරනවා වගේම Name ඒකේ සංවිධානය වැඩසටහන් විශේෂයෙන් ස්ථානයෙන් සංවිධානයක් ස්ථානයෙන් සංවිධානය කරන්නේ  අපි ස්ටෑන්ෆෝර්ඩ් NLI කොර්පුස් වල අපේ මොඩල් විශ්වාස කරනවා, Multi-Genre NLI කොර්පුස් වල, ස්ටෑන්ෆෝර්ඩ් සෙන්ටිම්ට් ට්\u200dරීබෑක් වලින්, හොයාගන්නවා ඒක සාමාන්ය', 'ta': 'வாக்குறியீட்டிற்கான மரத்தில் அமைக்கப்பட்ட புதிய பிணைய வலைப்பின்னல் உருவாக்கியங்கள் பொதுவாக வடிவமைப்பு மொழிகளில் பார்க்கப்பட்ட மொழிகளிலிருந்து த மேலும், இந்த மாதிரிகளில் பெருக்கல் இடைவெளிப்பாட்டை செயல்பாடுகளுக்கு சேர்த்தால் முக்கியமான முன்னேற்றங ஆயினும், இருக்கும் கூட்டு வழிகள், அது போன்ற ஒரு வலிமையான உறுப்புச் செயல்பாடு அளவு தவறாக எடுத்துக் கொள்ளும், அளபுருக்கள் எண்ணிக்கையில்  நாம் முன்னிருப்பு பொருள்-வெக்ஸ் மாதிரிக்ஸ் மாதிரியை குறிப்பிடுகிறோம், அது ஒரு உலக மாற்றத்தை பயன்படுத்தி வெக்டர் வார்த்தை பொருள்களுக்கு பொர அதன் செயல்பாடு செயல்படுத்தல் சிறிய மாதிரி அளவுருக்களை அடுக்கு முழுவதும் பெரிய செயல்பாடுகளை மாற்றுகிறது. நாங்கள் ஸ்டான்போர்ட் NLI கார்புஸ், பல ஜென்டர் NLI குறிப்புகள் மற்றும் ஸ்டான்போர்ட் சென்டிமென்ட் ட்ரீபாங்க் முடிந்து தெரியும் மரங்கள் அமைப்பு மாதிரிகளுக்கு முந்தைய அற', 'ur': 'درخت کی ساختہ نیورل نیٹ ورک معماری ساختاریوں کے لئے فیصلہ اکنوڈینگ کے لئے تقریبا سے سیمانٹی پیدائش کی طرف سے الفظ ڈالا گیا ہے جو عمومی زبان شناسی میں دیکھی جاتی ہے، اور اس کے ذریعہ مثالی سیمانٹ موڈل پر مثالی اضافہ دکھائی اور اس کے علاوہ، ان نمڈلوں میں کثرت سے اضافہ کرنے کے مطابق اضافہ کرنے کے مطابق اضافہ کرنا بہت اضافہ کرسکتا ہے۔ However, existing compositional approaches that adopt such a powerful composition function scale poorly, with parameter counts exploding as model dimension or vocabulary size grows. ہم نے ماٹریکس-اسپیس موڈل کو معرفی کیا ہے، جس نے ماٹریکس-ماٹریکس کثرت پر بنیاد رکھی ہوئی عملیات کے ذریعہ ایک گلوبی تبدیل کا استعمال کرتا ہے. اس کی کمپیوٹ فونسل عمدہ طور پر لہروں میں بہت بڑی فعالیت کی تعداد کو نسبت کم موڈل پارامیٹر کے ساتھ پیغام دیتا ہے. ہم نے استنفورد NLI کورپوس کے ذریعے اپنی مدل کا ارزش کیا ہے، Multi-Genre NLI کورپوس، اور استنفورد سنٹیمنٹ تری بانک اور یہ دیکھ رہے ہیں کہ یہ درخت ساختہ موڈل کے لئے پہلے بہترین معلوم کامپیوتر کا کامپیوتر ہے۔', 'sv': 'Trästrukturerade neurala nätverksarkitekturer för meningskodning hämtar inspiration från det förhållningssätt till semantisk sammansättning som allmänt ses inom formell lingvistik, och har visat empiriska förbättringar jämfört med jämförbara sekvensmodeller genom att göra det. Att lägga till multiplikativa interaktionsbeteckningar till kompositionsfunktionerna i dessa modeller kan dessutom ge betydande ytterligare förbättringar. Dock skalas befintliga kompositionsmetoder som antar en så kraftfull kompositionsfunktion dåligt, med parameterantal exploderar i takt med att modelldimensionen eller ordförrådsstorleken växer. Vi introducerar modellen Lifted Matrix-Space, som använder en global transformation för att kartlägga vektorordinbäddningar till matriser, som sedan kan komponeras via en operation baserad på matris-matrismultiplikation. Dess sammansättningsfunktion överför effektivt ett större antal aktiveringar över lager med relativt få modellparametrar. Vi utvärderar vår modell på Stanford NLI corpus, Multi-Genre NLI corpus och Stanford Sentiment Treebank och finner att den konsekvent överträffar TreeLSTM (Tai et al., 2015), den tidigare mest kända kompositionsfunktionen för trädstrukturerade modeller.', 'uz': "Tree-structured neural network architectures for sentence encoding draw inspiration from the approach to semantic composition generally seen in formal linguistics, and have shown empirical improvements over comparable sequence models by doing so.  Ko'pchilik, bu modeldagi kompyuterning funksiyatlariga ko'plab interfektlarni qoʻshish mumkin, juda katta yaxshi o'zgarishga ega bo'ladi. Ammo, ma'lumot modelning kengaytmasi yoki vositalar oʻlchamini ko'paytirish mumkin. Biz Matrix-Space modelini ko'rib chiqaramiz. Ularning global transformations used to draw vektor so'zlarini matrikalarga qo'yish mumkin. Ushbu kompyuterning funksiyati juda katta amalga almashtiriladi. Biz Stanford NLI corpusida modelimizni qiymatimiz, ko'pgina Jane NLI Korpus va Stanford Sentiment Treebank (Stanford Sentiment Treebank) bilan o'ylaymiz, bu TreeLSTM (Tai et, 2015), daraxt tuzilgan modellar uchun eng yaxshi taʼminlovchi kompyuterning funksiyati.", 'vi': 'Cấu trúc kết cấu trúc thần kinh của mạng lưới thần kinh để mã hóa bản án lấy nguồn cảm hứng từ phương pháp kết hợp theo ngữ pháp cơ bản thông thường thấy trong ngôn ngữ học chính thức, và đã cho thấy cải tiến thực tế hơn các mô hình phân biệt tương đối bằng cách làm vậy. Thêm các thuật ngữ tác động nhân tạo vào các hàm cấu tạo trong các mô-đun này có thể tạo thêm nhiều cải tiến khác. Tuy nhiên, các phương pháp phối hợp có thể sử dụng chức năng tổng hợp mạnh đến mức thấp, với mức tham số phát nổ khi chiều lượng mô hình hoặc kích thước ngôn ngữ phát triển. Chúng tôi giới thiệu mô hình ma trận Lifted ma trận không gian, nó dùng một sự chuyển đổi to àn cầu để vẽ những từ vector vào các hình mẫu, mà sau đó có thể được tạo ra qua một thao tác dựa trên đa số ma trận. Thành phần của nó truyền truyền một số lượng lớn kích hoạt qua các lớp với chỉ số lượng mô hình nhỏ. Chúng tôi đánh giá mẫu của chúng tôi trên Tập Đoàn Stanford, Nhân loại NLl Corpus, và Stanford tình cảm cây cối và thấy rằng nó hoàn toàn vượt trội hơn hẳn TreeLSTM (Thái et al., 205), hàm cấu tạo được biết trước nhất cho các mô hình cây được cấu trúc.', 'bg': 'Архитектурите на дървесни структурирани невронни мрежи за кодиране на изречения черпят вдъхновение от подхода към семантичната композиция, който обикновено се вижда във формалната лингвистика, и показват емпирични подобрения спрямо сравнимите модели на последователност. Освен това добавянето на мултипликативни термини за взаимодействие към съставните функции в тези модели може да доведе до значителни допълнителни подобрения. Съществуващите композиционни подходи, които приемат такава мощна композиционна функция, се скалират слабо, като броят на параметрите експлодира с увеличаване на размера на модела или размера на речника. Представяме модела "Повдигната матрица-пространство", който използва глобална трансформация, за да картографира вградените векторни думи към матрици, които след това могат да бъдат съставени чрез операция, базирана на матрично-матрично умножение. Неговата композиционна функция ефективно предава по-голям брой активирания през слоевете с относително малко параметри на модела. Ние оценяваме нашия модел на Станфорд НЛИ корпус, Многожанровия НЛИ корпус и Станфорд Сентимент Treebank и откриваме, че той последователно надминава TreeLSTM (Тай и др., 2015), предишната най-известна композиционна функция за дървесни структурирани модели.', 'hr': 'Strukturirane neuromrežne arhitekture za kodiranje rečenica privlače inspiraciju iz pristupa semantičkoj sastavi obično viđenoj u formalnoj lingvistiki i pokazali su empiričke poboljšanje nad usporedbenim modelima sekvencije tako. Osim toga, dodanje višestrukog interakcije funkcijama kompozicije u ovim modelima može donijeti značajne daljnje poboljšanje. Međutim, postojeći kompozicijski pristupi koji usvoje takvu moćnu skalu funkcije kompozicije loše, s obzirom na parameter eksplodiraju kao model dimenzija ili riječna veličina raste. Predstavljamo uzvišeni matriks-svemirski model, koji koristi globalnu transformaciju kako bi mapirali ugrađenje riječi vektora na matrice, koja se onda može sastaviti putem operacije bazirane na multiplikaciji matriksa. Njena funkcija kompozicije učinkovito prenosi veći broj aktivacija preko slojeva sa relativno malo modelnih parametara. Procjenjujemo naš model na Stanford NLI korpusu, multi-Genre NLI korpusu i Stanford Sentiment Treebank i saznajemo da je stalno iznosi TreeLSTM (Tai et al., 2015), prethodnu najpoznatu funkciju kompozicije za modele strukturirane na drvetu.', 'nl': "Boomstructureerde neurale netwerkarchitecturen voor zinscodering halen inspiratie uit de benadering van semantische compositie die algemeen wordt gezien in de formele taalkunde, en hebben daarmee empirische verbeteringen laten zien ten opzichte van vergelijkbare sequentiemodellen. Bovendien kan het toevoegen van multiplicatieve interactietermen aan de compositiefuncties in deze modellen aanzienlijke verdere verbeteringen opleveren. Bestaande compositionele benaderingen die zo'n krachtige compositiefunctie aannemen schalen echter slecht, waarbij het aantal parameters explodeert naarmate de modeldimensie of de woordenschat groeit. We introduceren het Lifted Matrix-Space model, dat gebruikmaakt van een globale transformatie om vectorwoordembeddingen in kaart te brengen aan matrices, die vervolgens kunnen worden samengesteld via een bewerking gebaseerd op matrix-matrix vermenigvuldiging. De compositiefunctie zendt effectief een groter aantal activaties over lagen met relatief weinig modelparameters. We evalueren ons model op het Stanford NLI corpus, het Multi-Genre NLI corpus en de Stanford Sentiment Treebank en vinden dat het consistent beter presteert dan TreeLSTM (Tai et al., 2015), de eerder bekende compositiefunctie voor boomgestructureerde modellen.", 'da': 'Træstrukturerede neurale netværksarkitekturer til sætningskodning henter inspiration fra tilgangen til semantisk sammensætning generelt set i formel lingvistik, og har ved at gøre det vist empiriske forbedringer i forhold til sammenlignelige sekvensmodeller. Desuden kan tilføjelse af multiplikative interaktionsbetingelser til sammensætningsfunktionerne i disse modeller give betydelige yderligere forbedringer. Men eksisterende kompositionstilgange, der anvender en så kraftfuld kompositionsfunktion, skalerer dårligt, med parametertællinger eksploderer, efterhånden som modeldimensionen eller ordforrådsstørrelsen vokser. Vi introducerer Lifted Matrix-Space modellen, som bruger en global transformation til at kortlægge vektorordindlejringer til matricer, som derefter kan sammensættes via en operation baseret på matrix-matrix multiplikation. Dens sammensætningsfunktion overfører effektivt et større antal aktiveringer på tværs af lag med relativt få modelparametre. Vi evaluerer vores model på Stanford NLI corpus, Multi-Genre NLI corpus og Stanford Sentiment Treebank og finder ud af, at den konsekvent overgår TreeLSTM (Tai et al., 2015), den tidligere mest kendte kompositionsfunktion for træstrukturerede modeller.', 'de': 'Baumstrukturierte neuronale Netzwerkarchitekturen für die Satzkodierung lassen sich von dem Ansatz der semantischen Komposition inspirieren, der in der formalen Linguistik allgemein gesehen wird und haben damit empirische Verbesserungen gegenüber vergleichbaren Sequenzmodellen gezeigt. Darüber hinaus kann das Hinzufügen multiplikativer Interaktionsbegriffe zu den Kompositionsfunktionen in diesen Modellen zu signifikanten weiteren Verbesserungen führen. Allerdings skalieren bestehende kompositorische Ansätze, die eine derart leistungsfähige Kompositionsfunktion übernehmen, schlecht, wobei die Parameteranzahl explodiert, wenn die Modelldimension oder die Vokabelgröße zunimmt. Wir stellen das Lifted Matrix-Space Modell vor, das eine globale Transformation verwendet, um Vektorworteinbettungen auf Matrizen abzubilden, die dann über eine Operation basierend auf Matrix-Matrix-Multiplikation zusammengesetzt werden können. Seine Kompositionsfunktion überträgt effektiv eine größere Anzahl von Aktivierungen über Schichten mit relativ wenigen Modellparametern. Wir evaluieren unser Modell auf dem Stanford NLI-Korpus, dem Multi-Genre NLI-Korpus und der Stanford Sentiment Treebank und stellen fest, dass es TreeLSTM (Tai et al., 2015), der bisher bekanntesten Kompositionsfunktion für baumstrukturierte Modelle, durchweg übertrifft.', 'id': 'Arkitektur jaringan saraf struktur pohon untuk pengekodan kalimat menarik inspirasi dari pendekatan ke komposisi semantis yang biasanya terlihat dalam bahasa formal, dan telah menunjukkan perbaikan empirik atas model urutan yang bisa dibandingkan dengan melakukannya. Selain itu, menambahkan istilah interaksi multiplikatif ke fungsi komposisi dalam model ini dapat memberikan perkembangan yang lebih signifikan. Namun, pendekatan komposisi yang ada yang mengadopsi skala fungsi komposisi yang kuat semacam buruk, dengan jumlah parameter meledak sebagai dimensi model atau ukuran vokal tumbuh. Kami memperkenalkan model Matriks-Ruang Angkat, yang menggunakan transformasi global untuk memetakan penyampilan kata vektor ke matriks, yang kemudian dapat dikomposisikan melalui operasi berdasarkan multiplikasi matriks-matriks. Fungsi komposisinya secara efektif mengirim jumlah aktivasi yang lebih besar melalui lapisan dengan relatif sedikit parameter model. Kami mengevaluasi model kami pada korpus NLI Stanford, korpus NLI Multi-Genre, dan Treebank Sentiment Stanford dan menemukan bahwa secara konsisten melebihi TreeLSTM (Tai et al., 2015), fungsi komposisi terbaik terdahulu untuk model strukturasi pohon.', 'ko': '문장 인코딩에 사용되는 트리 구조 신경 네트워크 구조는 형식언어학에서 흔히 볼 수 있는 의미 구성 방법에서 시사점을 얻었고 이를 통해 비교할 수 있는 서열 모델보다 경험적으로 개선되었다.그 밖에 이런 모델의 합성 함수에 곱셈 상호작용 항목을 넣으면 현저한 개선이 있을 수 있다.그러나 이렇게 강력한 합성 함수를 사용하는 기존의 합성 방법은 신축성이 비교적 떨어지고 모델 차원이나 어휘량이 증가함에 따라 매개 변수 계수는 폭발적으로 증가한다.우리는 향상 매트릭스 공간 모델을 소개했다. 이 모델은 전역 변환을 사용하여 벡터 단어를 매트릭스에 끼워 넣은 다음에 매트릭스 곱셈을 바탕으로 하는 조작 조합 매트릭스를 사용할 수 있다.그것의 합성 기능은 모델 파라미터가 상대적으로 적은 상황에서 크로스 레이어 전송을 대량으로 활성화시키는 데 효과적이다.우리는 스탠퍼드 NLI 자료 라이브러리, 다장르 NLI 자료 라이브러리와 스탠퍼드 감정 트리 라이브러리에서 우리의 모델을 평가한 결과 트리 구조 모델 이전에 가장 유명한 합성 함수인 TreelSTM(Tai 등, 2015)보다 우수하다는 것을 발견했다.', 'fa': 'معماری شبکه عصبی ساخته شده از درخت برای رمزبندی کردن جمله الهام از نزدیک به ترکیب سیمانتیک که عمومی در زبان\u200cشناسی دیده می\u200cشود، می\u200cکشند، و بر روی مدل\u200cهای قابل مقایسه\u200cای از طریق این کار، بهترین ترکیب امپرتیک را نشان می\u200cدهند. علاوه بر این، اضافه کردن شرایط تعاملات متعدد به عملکرد ترکیب در این مدل می تواند بهترین بیشتری را به ارائه دهد. با این حال، نزدیک\u200cهای ترکیب موجود است که به اندازه\u200cی اندازه\u200cی مدل یا اندازه\u200cی صفحه\u200cی صفحه\u200cی صفحه\u200cای قدرتمند را بد قبول می\u200cکند. ما مدل ماتریکس-فضای بلند را معرفی می\u200cکنیم، که از تغییر جهانی برای نقشه\u200cبندی کلمات ویکتور به ماتریس استفاده می\u200cکند، که می\u200cتواند از طریق یک عملیات بر اساس تعداد ماتریکس-ماتریکس ساخته شود. عملکرد ترکیب آن به طور تاثیر تعداد فعالیت بیشتری را در طبقه\u200cها با نسبتا کم پارامتر مدل انتقال می\u200cدهد. ما مدل خود را روی کورپوس NLI استنفورد، کورپوس NLI Multi-Genre، و درخت سنتیمتی استنفورد ارزیابی می کنیم و می یابیم که آن همیشه درخت LSTM (Tai et al., 2015) را برتری می کند، عملکرد بهترین ترکیبی برای مدل ساختار درخت شناخته شده است.', 'tr': 'Çözümler ködlemeleri üçin agaç strukturlarynda näral şebek arhitekterikleri formal lingwistiklerde görünýän ýagdaýdan semantik bilen alymy çekýär we muny edip ýakynlaşylan hatlaryň üstünde empirik gelişmeleri görkezilýärler. Ayrıca, bu modellerde birleşme fonksiyonlarını çoklu etkileşimli tercihleri eklemek daha önemli gelişmelere yaratabilir. Ýöne, bu şekilde güçlü bir compositional fonksiyonun ölçüsini kötü kabul eden biçimli bir şekilde yaklaşýar. Parametreler modal ölçü ýa-da sözlük ölçüsi ýaly patlayan hasaplar. Yükselmiş Matrix-Uzay modelini tanıtıyoruz ki, bu küresel bir şekilde matris çarpmasına dayanan bir operasyon üzerinde matris çarpma şeklinde oluşturulabilir. Ýarlanjak faýllary gaýd edip görkezilýän kalamlar arasynda gaty bir näçe mod parametrleri bilen ullanýar. Biziň nusgymyzy Stanford NLI korpusynda, Birnäçe nusga NLI korpusynda we Stanford Sentiment agaç bankynda deňleýäris we bu nusga agaç ýaly nusga üçin edilen iň gowy bilinen kompozisyonyň üstüne ýok diýip pikir edýäris.', 'sw': 'Majengo ya mtandao wa neura yaliyotengenezwa na miti kwa ajili ya kuongeza hukumu hiyo yanatoa hamasa kutoka mbinu ya ujenzi wa sekini kwa ujumla unaoonekana katika lugha rasmi, na imeonyesha maendeleo ya msimamo zaidi ya mifano inayofanana kwa kufanya hivyo. Zaidi ya hayo, kuongeza makubaliano makubwa kwa shughuli za ubunifu katika mifano hii inaweza kusababisha maboresho mengi. Hata hivyo, mbinu zilizopo za pamoja zinazochukua kiwango kikubwa cha ufanisi wa ubunifu si vibaya, na idadi ya parameter inalipuka kama ukubwa wa model au ukubwa wa lugha unaongezeka. Tunawasilisha muundo wa Matrix-Space ambao unatumia mabadiliko ya kimataifa kwa ajili ya ramani ya neno la vector linalopangwa kwenye viwanda, ambalo linaweza kutengenezwa kwa njia ya operesheni inayohusiana na ongezeko la matrix-matrix. Kitengenezaji chake kinasambaza kwa ufanisi na kusambaza idadi kubwa ya shughuli katika vipande vya juu na kipimo kidogo cha mifano. Tunatathmini modeli yetu kwenye makampuni ya Stanford NLI, makampuni ya NLI ya Vijana kadhaa, na Timu ya Stanford Treebank na kutambua kuwa inaendesha mtindo wa LSTM (Tai et al., 2015), kazi bora ya ujenzi uliofahamika zaidi kwa mifano iliyotengenezwa na miti.', 'af': "Boom-structureerde neuralnetwerk arkitektuure vir setkodering teken inspirasie van die toegang na semantiese komposisie generel gesien in formeel lingwisies en het empiriese verbeteringe vertoon oor vergelykbare volgorde modele deur dit te doen. Maar by die byvoeg van veelvuldige interaksie terme aan die opstelling funksies in hierdie modele kan betekende verdere verbeteringe gee. Maar, bestaande samenskaplike toegang wat so 'n kragtige samenskap funksie skaal verkeerd aanvaar, met parameter tel eksplodering as model dimensie of woordeboekgrootte groei. Ons introduseer die Ligte Matrix- Space model, wat gebruik 'n globale transformasie na kaart vektor woord inbetting na matrikse, wat dan kan wees geskep deur 'n operasie gebaseer op matriks- matriks vermenigvuldiging. Sy opstelling funksie effektief oordra 'n groter aantal aktivasies oor laagte met relativief paar model parameters. Ons evalueer ons model op die Stanford NLI corpus, die Multi-Genre NLI corpus en die Stanford Sentiment Treebank en vind dat dit konsistentlik uitvoer TreeLSTM (Tai et al., 2015), die vorige beste bekende komposisie funksie vir boom-struktureerde modele.", 'sq': 'Arkitekturat e rrjetit neural të strukturuar nga pemët për kodimin e fjalëve tërheqin frymëzim nga qasja ndaj përbërjes semantike që gjeneralisht shihet në gjuhën zyrtare dhe kanë treguar përmirësime empirike mbi modelet e sekuencës së krahasueshme duke e bërë këtë. Përveç kësaj, shtimi i termave të ndërveprimit shumëfishues në funksionet e përbërjes në këto modele mund të sjellë përmirësime të mëtejshme të rëndësishme. However, existing compositional approaches that adopt such a powerful composition function scale poorly, with parameter counts exploding as model dimension or vocabulary size grows.  Ne prezantojmë modelin e Matrix-Space të Ngjitur, i cili përdor një transformim global për të hartuar përfshirjet e fjalëve vektorë në matricë, që pastaj mund të përbëhet nëpërmjet një operacioni bazuar në shumëzimin e matricës-matricës. Funksioni i përbërjes së tij transmeton efektivisht një numër më të madh aktivitetesh nëpër shtresa me relativisht pak parametra modeli. Ne vlerësojmë modelin tonë në korpusin Stanford NLI, korpusin Multi-Genre NLI dhe Treebank Sentiment Stanford dhe zbulojmë se ai vazhdimisht mbivlerëson TreeLSTM (Tai et al., 2015), funksionin më të njohur të përbërë më të mëparshëm për modelet e strukturuar nga pemët.', 'hy': 'Փայրի կառուցվածքով նյարդային ցանցի ճարտարապետությունները նախադասությունների կոդավորման համար ոգեշնչում են սեմանտիկ կառուցվածքի մոտեցումից, որը սովորաբար տեսնում է ֆորմալ լեզվաբանության մեջ, և ցույց են տալիս էմպիրիկական բարելավումներ համեմատական հա Ավելին, այս մոդելների բազմապատկվող փոխազդեցության տերմինների ավելացումը բազմապատկվող ֆունկցիաներին կարող է նշանակալի զարգացումներ առաջացնել: Այնուամենայնիվ, գոյություն ունի կառուցվածքային մոտեցումներ, որոնք օգտագործում են այնպիսի հզոր կառուցվածքային ֆունկցիոնալ աստիճան վատ, և պարամետրերի հաշվարկները պայթյունում են, երբ մոդելի չափերը կամ բառարան We introduce the Lifted Matrix-Space model, which uses a global transformation to map vector word embeddings to matrices, which can then be composed via an operation based on matrix-matrix multiplication.  Նրա կառուցվածքային ֆունկցիան արդյունավետ փոխանցում է ավելի շատ ակտիվացիաներ շերտերում, որոնք ունեն համեմատաբար քիչ մոդելի պարամետրեր: Մենք գնահատում ենք մեր մոդելը Ստենֆորդ ՆԼԻ կորպոսի, բազմագենդերային ՆԼԻ կորպոսի և Ստենֆորդ Սենթմենտ Սենթմենտ Տրեբանկի վրա և հայտնաբերում ենք, որ այն մշտապես գերազանցում է TreeLSMT (Թայ և այլն., 2015), ծառի կառուցվածքով կա', 'am': 'Tree-structured neural network architecture for sentence encoding inspiration from the approach to semantic component generally seen in formal ቋንቋstics, and the empirical improvements in comparative sequence models by doing so. በተጨማሪም፣ በተጨማሪው የግንኙነት ግንኙነት ለመጨመር በተጨማሪው ፕሮጀክቶች ውስጥ በተለየ አካባቢ ክፍተቶችን ማድረግ ይችላል፡፡ ምንም እንኳን፣ እንደነዚህ የበረታች አካባቢ የክፍለ ሥርዓት ክፍል ክፍል ሲወስድ፣ በተለያዩ ቁጥር እንደምሳሌ አካባቢ ወይም የልግሎት መጠን ሲያድጋል፡፡ የደረጃ ማትሪክስ-ስፋት ሞዴል እናስጠጋለን፡፡ አዲስ ዶሴ ፍጠር የስቴንፎርድ NLI ኮርፓስ፣ ብዙ የ.አ.ሊ ኮርፓስ እና የስቴንፎር ሰናትክልት ቴብባን እናስተዋልታለን፣ ይህም የዛፍ አካባቢ ክፍል መሆኑን (Tai et.2015) በመጀመሪያው የተታወቀ ትክክለኛውን ክፍል እናገኘዋለን፡፡', 'az': "Cümlələr kodlaması üçün ağac-strukturlı nöral ağ arhitektarı formal dil sistemində görünən semantik kompozisyonun tərəfindən ilham çəkir və bu işi ilə müqayisəli sequence modellərin üstündə empirik düzəltmələri göstərdilər. Daha sonra, bu modellərdə kompozisyon fonksiyonlarına çoxlu müxtəlif müxtəlif müxtəlif müxtəlif müxtəlif şəkillər əlavə edə bilər. Halbuki, böyük güclü bir kompozisyon funksiyası ölçüsünü çox dəyişdirən müxtəlif şəkildə olan müxtəlif tərəflərə bənzəyir. Parametri modeli ölçü və sözlü ölçü olaraq dağılır. Biz yüksək matriks-matriks çarpımına dayanan bir operasyon vasitəsilə yaradıla biləcəyik. Onun kompoziciyası funksiyası, səviyyələr arasında daha çox fəaliyyətli bir neçə model parametrləri ilə istifadə edir. Bizim modelimizi Stanford NLI korpusu, Multi-Genre NLI korpusu və Stanford Sentiment Treebank'da değerləşdiririk və bu, ağac-strukturlı modellərin əvvəlkilərin ən yaxşı bilinmiş kompozisyon funksiyasını sürəklə dəyişdirir.", 'bn': 'বাক্য এনকোডিং এর জন্য গাছের কাঠামো নিউরেল নেটওয়ার্ক কাঠামো সংক্রান্ত প্রতিষ্ঠান থেকে সাধারণত ফার্মিক ভাষায় দেখা যায় সাধারণত ভাষায় অনুপ্রাণিত করে  এছাড়াও, এই মডেলের সংগঠনের ফাংশনের সাথে বৃদ্ধিকারের মাধ্যমে যোগ করা শর্ত যোগ করা যায়, তারা আরো বেশী উন্নতি পাবে। তবে বিদ্যমান বৈশিষ্ট্যের উপায় যা এমন শক্তিশালী সংগঠনের ফাংশন স্কেল খারাপ ব্যবহার করে, যার সাথে মাত্রার সংখ্যা মডেলের মাত্রা বা শব্দভ আমরা লিফটেড ম্যাট্রিক্স-স্পেস মডেল পরিচয় করিয়ে দেই, যা বিশ্বব্যাপী পরিবর্তন ব্যবহার করে ম্যাট্রিক্সের মাধ্যমে ভেক্টরের শব্দের মানচিত্রে প্রবেশ করা Its composition function effectively transmits a larger number of activations across layers with relatively few model parameters.  আমরা স্ট্যান্ফোর্ড এনলি কোর্পাস, মাল্টিজেন্র এনলি কোর্পাস এবং স্ট্যানফোর্ড সেন্টিমেন্ট ট ট্রিবাঙ্কের মূল্যায়ন করি এবং আমরা খুঁজে পাই যে এটা সবসময় ট্রিএলস্টিএম (তাই এল ২০১৫) এর', 'ca': "Les arquitectures de xarxa neural estructuradas per codificar frases treuen inspiració de l'enfocament a la composició semàntica generalment vist en la lingüística formal, i han demostrat millors empíriques sobre models de seqüència comparables fent-ho. A més, afegir termes multiplicatius d'interacció a les funcions de composició d'aquests models pot produir millores significatives més. However, existing compositional approaches that adopt such a powerful composition function scale poorly, with parameter counts exploding as model dimension or vocabulary size grows.  Introduïm el model de Matrix-Espai Levantat, que utilitza una transformació global per mapejar les integracions de les paraules vectorials en matrices, que després es poden composir a través d'una operació basada en la multiplicació de matrix-matrix. La seva funció de composició transmet efectivament un nombre més gran d'activacions a través de capes amb relativament pocs paràmetres de model. We evaluate our model on the Stanford NLI corpus, the Multi-Genre NLI corpus, and the Stanford Sentiment Treebank and find that it consistently outperforms TreeLSTM (Tai et al., 2015), the previous best known composition function for tree-structured models.", 'et': 'Lausete kodeerimiseks kasutatavad puustruktureeritud neuraalvõrgu arhitektuurid on inspireeritud semantilise kompositsiooni lähenemisviisist, mida tavaliselt kasutatakse formaalses lingvistikas, ning on näidanud empiirilisi arenguid võrreldes võrreldavate jadamudelitega. Lisaks võib nende mudelite kompositsioonifunktsioonidele lisada multiplikatiivseid vastastikuseid mõisteid märkimisväärselt parandada. Kuid olemasolevad kompositsioonilised lähenemisviisid, mis kasutavad nii võimsat kompositsioonifunktsiooni, skaalavad halvasti, parameetrite arv plahvatab mudeli dimensiooni või sõnavara suuruse kasvades. Tutvustame Lifted Matrix-Space mudelit, mis kasutab globaalset transformatsiooni vektorsõnade põimimise kaardistamiseks maatriksidesse, mida saab seejärel koostada maatriksi-maatriksi korrutamisel põhineva operatsiooni abil. Selle koostise funktsioon edastab tõhusalt suurema arvu aktiveerimisi kihtide vahel suhteliselt väheste mudeliparameetritega. Hindame oma mudelit Stanfordi NLI korpuse, Multi-Genre NLI korpuse ja Stanfordi Sentiment Treebanki põhjal ning leiame, et see on järjekindlalt parem kui TreeLSTM (Tai et al., 2015), eelmine tuntum kompositsioonifunktsioon puustruktureeritud mudelite puhul.', 'cs': 'Architektury stromově strukturovaných neuronových sítí pro kódování vět čerpají inspiraci z přístupu ke sémantickému složení obecně pozorovaného ve formální lingvistice a tím prokázaly empirické zlepšení oproti srovnatelným sekvenčním modelům. Navíc přidání multiplikativních interakčních termínů do kompozičních funkcí v těchto modelech může přinést významné další zlepšení. Stávající kompoziční přístupy, které přijímají tak silnou kompoziční funkci, se však špatně škálou, přičemž počet parametrů exploduje s rostoucí dimenzí modelu nebo slovní zásoby. Představujeme model Lifted Matrix-Space, který využívá globální transformaci k mapování vektorových vložení slov do matic, které pak lze složit operací založených na násobení matic-matic. Jeho složení efektivně přenáší větší počet aktivací napříč vrstvami s relativně málo modelových parametrů. Hodnotíme náš model na stanfordském NLI korpusu, multi-žánrovém NLI korpusu a Stanford Sentiment Treebank a zjišťujeme, že konzistentně překonává TreeLSTM (Tai et al., 2015), předchozí nejznámější kompoziční funkci pro stromově strukturované modely.', 'bs': 'Strukturirane neuromrežne arhitekture za kodiranje rečenica privlače inspiraciju od pristupa semantičkoj kompoziciji obično viđenoj u formalnoj lingvistiki i pokazale su empiričke poboljšanje nad usporedbenim modelima sekvencije tako. Osim toga, dodanje višestrukog interakcije funkcijama kompozicije u ovim modelima može donijeti značajne daljnje poboljšanje. Međutim, postojeći kompozicijski pristupi koji usvoje takvu moćnu skalu funkcije kompozicije loše, a parametri se računaju eksplozijom kao model dimenzija ili veličina riječnika. Predstavljamo uzvišeni matriks-svemirski model, koji koristi globalnu transformaciju kako bi mapirali uključenje vektorskih riječi na matrice, koja se onda može sastaviti putem operacije bazirane na multiplikaciji matriksa. Njena funkcija kompozicije učinkovito prenosi veći broj aktivacija preko slojeva sa relativno malo modelnih parametara. Procjenjujemo naš model na Stanford NLI korpusu, multi-Genre NLI korpusu, i Stanford Sentiment Treebank i otkrijemo da to stalno iznosi TreeLSTM (Tai et al., 2015), prethodnu najpoznatu funkciju kompozicije za modele strukturirane na drvetu.', 'fi': 'Lausekoodaukseen käytettävät puurakenteiset neuroverkkoarkkitehtuurit ammentavat inspiraatiota semanttisen sommittelun lähestymistavasta, jota käytetään yleisesti muodollisessa kielitieteessä, ja ovat osoittaneet empiirisiä parannuksia vastaaviin sekvenssimalleihin verrattuna. Lisäksi monistavan vuorovaikutuksen termien lisääminen näiden mallien koostumustoimintoihin voi tuottaa merkittäviä lisäparannuksia. Kuitenkin olemassa olevat sävellysmenetelmät, jotka omaksuvat näin tehokkaan sävellysfunktion skaalautuvat huonosti, ja parametrien määrä räjähtää mallin ulottuvuuden tai sanaston koon kasvaessa. Esittelemme Lifted Matrix-Space -mallin, joka käyttää globaalia muunnosta vektorisanaupotusten kartoittamiseen matriiseihin, jotka voidaan sitten koostaa matriisi-matriisi-kertoimeen perustuvalla operaatiolla. Sen koostumustoiminto välittää tehokkaasti suuremman määrän aktivointeja kerrosten yli suhteellisen vähän malliparametreja. Arvioimme malliamme Stanford NLI -korpusesta, Multi-Genre NLI -korpusesta ja Stanford Sentiment Treebankista ja toteamme, että se on johdonmukaisesti parempi kuin TreeLSTM (Tai et al., 2015), joka on aiemmin tunnettu puurakenteisten mallien sommittelufunktio.', 'jv': 'Kernel-structural network architectures politenessoffpolite"), and when there is a change ("assertive politenessoffpolite"), and when there is a change ("assertivepoliteness We present the Lifted MAtrix-space model, that use a global transformation to map vector word embedding to parentices, that can be compred by an operation supported on = Awak dhéwé nggunakake model sing nLI kuwi nggawe lan seneng coro Multi-Genve NLI, lan lan saiki stabol pun sentiment, nggawe sawetara dhéwé iso nggawe gantawak dhéwé. Layout kuwi etik dhéwé nggawe sawetara Layout (Tam et al), lan akeh langgar sampeyan wong liyane sing dumadhi diwong kuwi nggawe gedhé. Awak dhéwé', 'ha': "Ana nuna aikin muhalli na jerin neural wanda aka samar da shi na rubutu wa kode na cewa ya ƙara aikin muhimmi daga matsayin zuwa composition wa semantic wanda aka gane shi a cikin linguistic masu formal, kuma ya nuna gyarata masu amfani da misãlai masu sami da shi. Da haka, idan an ƙara wasu mutane da interaction zuwa funkin composition cikin waɗannan misalin za'a ƙara kyautatawa mai girma. A lokacin da ke da, hanyoyin wanda ke samar da shi mai ƙarfi ga ajiya na composition, yana da ƙidãyar parameteri sunã faɗa kamar girmar motel ko kuma yana ƙara girma ga maganar. Tuna ƙara motel na Lifted Matrix-Space, wanda ke amfani da wata shifotto a cikin dũniya dõmin ya yi amfani da zane-zane cikin zane-ƙanshi zuwa matricikin, da kuma za'a samo shi da wani shirin a kan kwamfyuta wa multiplin matrix-matrix. Fara aiki da kwamfyuta mai amfani da shi yana transmit ƙidãyar aiki masu girma a kan abubuwa, da parameteri masu ƙaranci motel. Tuna ƙaddara misalinmu a kan karatun Stanford NLI, ƙarshen multi-jama'a na NLI, da na Stanford mai zaman shawara Treebank, kuma munã gane cewa shi yana samar da shi daidai a TreeLstanM (Tai et al., 2015), da mafi kyaun samuratan da aka sani na samun koma wa misumarnin da aka rubuta na mite.", 'sk': 'Drevestrukturirane nevronske mrežne arhitekture za kodiranje stavkov črpajo navdih iz pristopa semantične kompozicije, ki ga običajno vidimo v formalnem jezikoslovju, in so s tem pokazale empirične izboljšave v primerjavi s primerljivimi modeli zaporedja. Poleg tega lahko dodajanje multiplikativnih interakcijskih pojmov funkcijam sestave v teh modelih prinese znatne nadaljnje izboljšave. Vendar pa obstoječi kompozicijski pristopi, ki sprejmejo tako močno kompozicijsko funkcijo, slabo merijo, število parametrov pa eksplodira, ko dimenzija modela ali velikost besedišča raste. Predstavljamo model Lifted Matrix-Space, ki uporablja globalno transformacijo za mapiranje vgradnje vektorskih besed v matrike, ki jih nato lahko sestavimo preko operacije, ki temelji na matričnem množenju matrice-matrice. Njegova funkcija sestave učinkovito prenaša večje število aktivacij skozi plasti z relativno malo modelnih parametrov. Naš model ocenjujemo na korpusu Stanford NLI, korpusu Multi-Genre NLI in Stanford Sentiment Treebank in ugotovimo, da dosledno presega TreeLSTM (Tai et al., 2015), prejšnjo najbolj znano kompozicijsko funkcijo za drevesno strukturirane modele.', 'bo': 'སྡོང་བོའི་དབྱིབས་གཞུང་དང་མིའི་དྲ་རྒྱ་སྟངས་ལ་ཚིག་གྲངས་སྒྲིག་འཛིན་གྱི་ཐབས་ལམ་ལས་ སྔོན་སྒྲིག མ་དབྱིབས་འདི་དག་གི་སྒྲིག However, existing compositional approaches that adopt such a powerful composition function scale poorly, with parameter counts exploding as model dimension or vocabulary size grows. ང་ཚོས་ཀྱི་Lifted Matrix-Space་གི་མ་དབྱིབས་སྤྲོད་ཡོད། Its composition function effectively transmits a larger number of activations across layers with relatively few model parameters. ང་ཚོའི་མིག', 'he': 'ארכיטקטורות רשת עצבית מבוססת עץ לקוד משפטים שורפות השראה מהגישה למערכת סמנטית בדרך כלל נראית בשפה רשמית, והראו שיפורים אמפיריים על דוגמני רצף שווים על ידי כך. חוץ מזה, להוסיף תנאי אינטראקציה כפולה לפונקציות המרכיבות בדוגמנים האלה יכולים להביא שיפורים נוספים משמעותיים. However, existing compositional approaches that adopt such a powerful composition function scale poorly, with parameter counts exploding as model dimension or vocabulary size grows.  אנחנו מציגים את מודל המטריקס-חלל העליון, אשר משתמש בשינוי גלובלי כדי למפות מילים ווקטוריות מוקמות למטריקסים, אשר לאחר מכן יכול להיות מורכב באמצעות מבצע מבוסס על כפול מטריקס-מטריקס. הפונקציה המרכיבת שלה משדרת מספר גדול יותר של פעילות ברחבי שכבות עם פרמטרים דוגמנים מעט יחסית. אנו מעריכים את המודל שלנו על הקורפוס של סטנפורד NLI, הקורפוס של NLI Multi-Genre, ו"סטנפורד Sentiment Treebank" ומציאים שהיא מתאימה באופן קבוע יותר מ-TreeLSTM (Tai et al., 2015), הפונקציה הידועה הקודמת ביותר של הפונקציה של מודלים מבוססים עצים.'}
{'en': 'End-to-End Neural Entity Linking', 'ar': 'ربط الكيان العصبي الشامل', 'fr': "Liaison d'entités neuronales de bout en", 'es': 'Enlace de entidades neuronales de extremo', 'pt': 'Vinculação de entidades neurais de ponta a ponta', 'ja': 'エンドツーエンドのニューラルエンティティリンク', 'zh': '端到端神经实体链接', 'hi': 'एंड-टू-एंड तंत्रिका एंटिटी लिंकिंग', 'ru': 'Сквозная привязка нейронной сущности', 'ga': 'Nascáil Aonáin Néarúil ó cheann go ceann', 'ka': 'ბოლოდან დასრულებული ნეიროლური ელეტიტის დაკავშირება', 'hu': 'End-to-end idegi entitások összekapcsolása', 'el': 'Ολοκληρωμένη σύνδεση νευρωνικής οντότητας', 'it': 'Collegamento end-to-end delle entità neurali', 'kk': 'Невралдық нысандарды сілтемелеу', 'mk': 'Врска од крај до крај на неврален ентитет', 'lt': 'Nuo galo iki galo sujungtas neurologinis subjektas', 'ms': 'Pautan Entiti Neural Akhir-Akhir', 'mn': 'Эцэст дуусах мэдрэлийн элементийн холбоо', 'ml': 'അവസാന- മുതല്\u200d നെയുറല്\u200d എന്റിറ്റി ലിങ്ങിങ്ങ്', 'no': 'Slutt til slutt- linking på neirale eining', 'mt': 'Ir-rabta bejn l-Entità Newrali tat-tmiem u t-tmiem', 'pl': 'Końcowe łączenie neuronalnych jednostek', 'sr': 'Kraj do kraja povezanja neuronskih entiteta', 'ro': 'Conectarea entităților neurale end-to-end', 'sv': 'Koppling av neurala entiteter från början till slut', 'si': 'අවසානයෙන් අවසානය කරන්න', 'ur': 'نائرل ایٹنی لینک', 'so': 'Heshiiska naafada ee dhamaadka', 'ta': 'முடிவுக்கு முடிவு', 'uz': 'Umumiy bogĘ»lamasi', 'vi': 'Kết nối thần kinh', 'bg': 'Свързване край до край на невралната същност', 'da': 'End-to-End Neural Entity Linking', 'nl': 'End-to-End neuronale entiteitenkoppeling', 'de': 'End-to-End-Verknüpfung von neuronalen Entitäten', 'hr': 'Povezivanje neuronskih podataka do kraja', 'fa': 'ارتباط واحد عصبی به پایان', 'id': 'Hubungan Entitas Neural Akhir-Akhir', 'sw': 'Kiungo cha Ujumbe wa Neural', 'tr': 'Neuraly Otomatik Saýlaw', 'ko': '끝에서 끝까지 신경 실체 링크', 'af': 'Einde na- einde Neurale Entiteit Linking', 'am': 'gradient-editor-blending', 'hy': 'Վերջից մինչև վեր նյարդային միավորի կապը', 'bs': 'Kraj do kraja povezanja neuronskih entiteta', 'sq': 'Lidhja e njësisë nervore nga fundi në fund', 'az': 'Nöral Entity Bağlantısı', 'cs': 'Koncové propojení neuronových entit', 'bn': 'End-to-End Neural Entity Linking', 'et': 'Otsest lõpuni seotud neuraalsed olemid', 'fi': 'End to End Neural Entity Linkitys', 'ca': 'Enlaçament entre la entitat neuronal final i final', 'jv': 'echoH e l l o space w o r l d periodHelloworldHello world', 'sk': 'Povezovanje nevronskih entitet od konca do konca', 'he': 'קישור בין סוף עד סוף', 'ha': 'Linkin Naural', 'bo': 'Neural Entity Linking'}
{'en': 'Entity Linking (EL) is an essential task for ', 'ar': 'ارتباط الكيانات (EL) هو مهمة أساسية لفهم النص الدلالي واستخراج المعلومات. تتناول الأساليب الشائعة بشكل منفصل مرحلتي اكتشاف الإشارة (MD) وإلغاء غموض الكيان (ED) في EL ، دون الاستفادة من اعتمادهما المتبادل. نقترح هنا أول نظام عصبي لتعلم اللغة الإنجليزية يكتشف بشكل مشترك الكيانات ويربطها في مستند نصي. الفكرة الرئيسية هي النظر في جميع الفترات الممكنة كإشارات محتملة وتعلم درجات التشابه السياقي على مرشحي الكيانات الخاصة بهم والتي تكون مفيدة لقرارات MD و ED. المكونات الرئيسية هي الضمانات التي تذكر السياق ، وحفلات الزفاف في الكيانات ، والإشارة الاحتمالية - خريطة الكيان ، دون المطالبة بميزات هندسية أخرى. من الناحية التجريبية ، نظهر أن طريقتنا الشاملة تتفوق بشكل كبير على الأنظمة الشائعة على منصة Gerbil عندما تتوفر بيانات تدريب كافية. على العكس من ذلك ، إذا كانت مجموعات البيانات الاختبارية تتبع اصطلاحات تعليقات توضيحية مختلفة مقارنة بمجموعة التدريب (مثل الاستعلامات / التغريدات مقابل المستندات الإخبارية) ، فإن نموذج ED الخاص بنا إلى جانب نظام NER التقليدي يقدم أفضل أو ثاني أفضل دقة EL.', 'pt': 'Entity Linking (EL) é uma tarefa essencial para a compreensão do texto semântico e extração de informações. Os métodos populares abordam separadamente os estágios Mention Detection (MD) e Entity Disambiguation (ED) do EL, sem alavancar sua dependência mútua. Propomos aqui o primeiro sistema EL de ponta a ponta neural que descobre e vincula entidades em um documento de texto em conjunto. A ideia principal é considerar todos os intervalos possíveis como menções potenciais e aprender pontuações de similaridade contextual sobre seus candidatos de entidade que são úteis para decisões de MD e ED. Os principais componentes são menções embeddings sensíveis ao contexto, embeddings de entidades e uma menção probabilística - mapa de entidades, sem exigir outros recursos de engenharia. Empiricamente, mostramos que nosso método de ponta a ponta supera significativamente os sistemas populares na plataforma Gerbil quando dados de treinamento suficientes estão disponíveis. Por outro lado, se os conjuntos de dados de teste seguem convenções de anotação diferentes em comparação com o conjunto de treinamento (por exemplo, consultas/tweets vs documentos de notícias), nosso modelo ED acoplado a um sistema NER tradicional oferece a melhor ou a segunda melhor precisão de EL.', 'fr': "Entity Linking (EL) est une tâche essentielle pour la compréhension du texte sémantique et l'extraction d'informations. Les méthodes courantes traitent séparément les étapes de détection de mention (MD) et de désambiguïsation d'entité (ED) de EL, sans tirer parti de leur dépendance mutuelle. Nous proposons ici le premier système EL de bout en bout neuronal qui découvre et relie conjointement des entités dans un document texte. L'idée principale est de considérer toutes les portées possibles comme des mentions potentielles et d'apprendre des scores de similitude contextuels sur leurs candidats d'entité qui sont utiles pour les décisions MD et ED. Les composants clés sont les intégrations de mentions sensibles au contexte, les intégrations d'entités et une mention probabiliste - carte d'entité, sans exiger d'autres fonctionnalités techniques. De manière empirique, nous montrons que notre méthode de bout en bout surpasse largement les systèmes populaires sur la plateforme Gerbil lorsque suffisamment de données d'entraînement sont disponibles. Inversement, si les ensembles de données de test suivent des conventions d'annotation différentes par rapport à l'ensemble de formation (par exemple, requêtes/tweets ou documents d'actualités), notre modèle ED associé à un système NER traditionnel offre la meilleure ou la deuxième meilleure précision EL.", 'es': 'Entity Linking (EL) es una tarea esencial para la comprensión semántica del texto y la extracción de información. Los métodos populares abordan por separado las etapas de detección de menciones (MD) y desambiguación de entidades (ED) de EL, sin aprovechar su dependencia mutua. Aquí proponemos el primer sistema EL neuronal de extremo a extremo que descubre y vincula conjuntamente entidades en un documento de texto. La idea principal es considerar todos los intervalos posibles como posibles menciones y aprender puntuaciones de similitud contextual sobre sus candidatos de entidad que son útiles para las decisiones de MD y ED. Los componentes clave son las incorporaciones de menciones sensibles al contexto, las incrustaciones de entidades y una mención probabilística: el mapa de entidades, sin exigir otras funciones de ingeniería. Empíricamente, demostramos que nuestro método integral supera significativamente a los sistemas populares de la plataforma Gerbil cuando hay suficientes datos de entrenamiento disponibles. Por el contrario, si los conjuntos de datos de prueba siguen convenciones de anotación diferentes en comparación con el conjunto de entrenamiento (por ejemplo, consultas/tuits frente a documentos de noticias), nuestro modelo de ED junto con un sistema NER tradicional ofrece la mejor o la segunda mejor precisión de EL.', 'ja': 'エンティティリンク（ EL ）は、セマンティックテキストの理解と情報抽出に不可欠なタスクです。 人気のある方法は、相互依存性を活用することなく、ELのメンション検出（ MD ）段階とエンティティ曖昧化（ ED ）段階に個別に対処します。 ここでは、テキストドキュメント内のエンティティを共同で発見し、リンクする最初のニューラルエンドツーエンドELシステムを提案します。 主なアイデアは、すべての可能性のあるスパンを潜在的な言及と見なし、MDとEDの両方の意思決定に役立つエンティティ候補に対するコンテキストの類似性スコアを学習することです。 主要なコンポーネントは、コンテキストを意識したメンション埋め込み、エンティティ埋め込み、および確率的メンション（エンティティマップ）であり、他のエンジニアリングされた機能を要求することはありません。 経験的に、十分なトレーニングデータが利用可能な場合、当社のエンドツーエンドの方法がGerbilプラットフォーム上の人気のあるシステムを大幅に上回っていることを示しています。 逆に、テストデータセットがトレーニングセットと比較して異なる注釈規則（例：クエリ/ツイートvsニュースドキュメント）に従っている場合、従来のNERシステムと組み合わせた当社のEDモデルは、最高または2番目に優れたEL精度を提供します。', 'zh': '实体链接 (EL) 者,语义文本解取之本也。 流行之法,分 EL 检 (MD) ,消息歧义 (ED) 端,而不因其相赖。 首建神经端到端EL系统,当共见链接本文档中实体。 盖心者,以所有之跨度为潜提,而知其实候选者之上下文相似性分,此MD、ED之策皆有用也。 要组件者,上下文感提嵌、实体嵌、概率提及 - 实映射,而不须他功也。 以经验言之,当足练数可用之时,其端到端法显优沙鼠平台之流行系统。 若测试数据集遵训集异注(如询/推文与新闻文档),ED古NER统,最为佳或次优之EL准确性。', 'hi': 'एंटिटी लिंकिंग (ईएल) शब्दार्थ पाठ समझ और जानकारी निष्कर्षण के लिए एक आवश्यक कार्य है। लोकप्रिय तरीके अलग से उल्लेख का पता लगाने (एमडी) और इकाई Disambiguation (ईडी) ईएल के चरणों को संबोधित करते हैं, उनकी पारस्परिक निर्भरता का लाभ उठाए बिना। हम यहां पहले तंत्रिका अंत-से-अंत ईएल सिस्टम का प्रस्ताव करते हैं जो संयुक्त रूप से एक पाठ दस्तावेज़ में संस्थाओं की खोज और लिंक करता है। मुख्य विचार संभावित उल्लेखों के रूप में सभी संभावित स्पैन पर विचार करना है और अपनी इकाई के उम्मीदवारों पर प्रासंगिक समानता स्कोर सीखना है जो एमडी और ईडी दोनों निर्णयों के लिए उपयोगी हैं। प्रमुख घटक संदर्भ-जागरूक उल्लेख एम्बेडिंग, इकाई एम्बेडिंग और एक संभाव्य उल्लेख हैं - इकाई मानचित्र, अन्य इंजीनियर सुविधाओं की मांग के बिना। अनुभवजन्य रूप से, हम दिखाते हैं कि हमारी एंड-टू-एंड विधि पर्याप्त प्रशिक्षण डेटा उपलब्ध होने पर गेरबिल प्लेटफ़ॉर्म पर लोकप्रिय प्रणालियों को काफी बेहतर बनाती है। इसके विपरीत, यदि परीक्षण डेटासेट प्रशिक्षण सेट (जैसे क्वेरी / ट्वीट्स बनाम समाचार दस्तावेज) की तुलना में विभिन्न एनोटेशन सम्मेलनों का पालन करते हैं, तो पारंपरिक एनईआर सिस्टम के साथ युग्मित हमारा ईडी मॉडल सबसे अच्छा या दूसरा सबसे अच्छा ईएल सटीकता प्रदान करता है।', 'ru': 'Связь сущностей (EL) является важной задачей для понимания семантического текста и извлечения информации. Популярные методы отдельно рассматривают стадии обнаружения упоминания (MD) и раздвоения сущностей (ED) EL, не используя их взаимную зависимость. Здесь мы предлагаем первую нейронную сквозную систему EL, которая совместно обнаруживает и связывает сущности в текстовом документе. Основная идея состоит в том, чтобы рассматривать все возможные диапазоны как потенциальные упоминания и изучать баллы контекстуального сходства по их кандидатам в субъекты, которые полезны как для решений MD, так и для решений ED. Ключевыми компонентами являются контекстно-зависимые вложения упоминания, вложения сущностей и вероятностное упоминание - карта сущностей, не требуя других инженерных особенностей. Эмпирически мы показываем, что наш сквозной метод значительно превосходит популярные системы на платформе Gerbil при наличии достаточного количества обучающих данных. И наоборот, если тестовые наборы данных соответствуют различным соглашениям об аннотациях по сравнению с обучающим набором (например, запросы/ твиты по сравнению с новостными документами), наша модель ED в сочетании с традиционной системой NER предлагает лучшую или вторую лучшую точность EL.', 'ga': 'Is tasc riachtanach é Nascadh Aonán (EL) chun téacs shéimeantach a thuiscint agus chun faisnéis a bhaint amach. Tugann modhanna coitianta aghaidh ar leithligh ar na céimeanna Braite Lua (MD) agus Dídhébhríocht Aonáin (ED) de chuid EL, gan a spleáchas frithpháirteach a ghiaráil. Molaimid anseo an chéad chóras néarach EL ó cheann ceann go ceann a aimsíonn agus a nascann eintitis i ndoiciméad téacs i gcomhpháirt. Is é an príomh-smaoineamh gach réimse féideartha a mheas mar lua féideartha agus scóir chosúlachta comhthéacsúla a fhoghlaim thar a n-iarrthóirí aonáin atá úsáideach le haghaidh cinntí MD agus ED araon. Is iad na príomh-chomhpháirteanna ná leabú lua atá feasach ar an gcomhthéacs, leabú aonáin agus lua dóchúil - léarscáil aonáin, gan gnéithe eile a ndearnadh innealtóireacht orthu a éileamh. Go heimpíreach, léirímid go sáraíonn ár modh ceann-go-deireadh na córais mhóréilimh ar ardán Gerbil nuair a bhíonn dóthain sonraí oiliúna ar fáil. Os a choinne sin, má leanann tacair shonraí tástála coinbhinsiúin nótaí éagsúla i gcomparáid leis an tacar oiliúna (m.sh. ceisteanna / tweets vs doiciméid nuachta), cuireann ár múnla ED in éineacht le córas NER traidisiúnta an cruinneas EL is fearr nó an dara ceann is fearr.', 'hu': 'Az Entity Linking (EL) elengedhetetlen feladat a szemantikai szövegmegértéshez és az információkinyeréshez. A népszerű módszerek külön-külön foglalkoznak az EL Mention Detection (MD) és Entity Disambiguation (ED) szakaszaival, anélkül, hogy kihasználnák kölcsönös függőségüket. Itt javasoljuk az első neurális end-to-end EL rendszert, amely együttesen felfedezi és összekapcsolja az entitásokat egy szöveges dokumentumban. A fő ötlet az, hogy minden lehetséges területet potenciális említésként vegyünk figyelembe, és megtanuljuk a kontextuális hasonlósági pontszámokat entitási jelöltjük felett, amelyek hasznosak mind az MD, mind az ED döntésekhez. A kulcsfontosságú összetevők a kontextustudatos említési beágyazások, entitási beágyazások és egy valószínűsíthető említés - entitástérkép, anélkül, hogy más tervezett funkciókat igényelne. Empirikusan megmutatjuk, hogy végpontos módszerünk jelentősen felülmúlja a Gerbil platform népszerű rendszereit, ha elegendő edzési adat áll rendelkezésre. Ezzel szemben, ha a tesztelési adatkészletek eltérő jegyzetelési szabályokat követnek az edzéskészlethez képest (például lekérdezések/tweetek vagy híradokumentumok), ED modellünk hagyományos NER rendszerrel párosítva a legjobb vagy a második legjobb EL pontosságot kínálja.', 'ka': 'Entity Linking (EL) არის მნიშვნელოვანი რაოდენობა სიმენტიკური ტექსტის გაგრძნობისთვის და ინფორმაციის ექსტრექციისთვის. EL-ის მოსახულებული მეტი განსახულებით მენციოს განახლება (MD) და Entity Disambiguation (ED) ფაეზების განსახულებით, საერთო დასახულებელობას არ გამოიყენება. ჩვენ აქ ჩვენ მინდა პირველი ნეიროლური დასრულებული EL სისტემა, რომელიც ტექსტის დოკუმენტში ერთად აღმოჩენა და დაკავშირება ინტერტიები. მნიშვნელოვანი იდეა, რომ ყველა შესაძლებელი განსხვავება როგორც პონტექსტური განსხვავება და შესწავლობა კონტექსტური განსხვავება განსხვავებული განსხვავებების შესახებ, რომელიც კონტექსტური კომპონენტები არის კონტექსტური შეცდომა შესახებ ინტექსტურები, ინტექსტური ინტექსტურები და შესაბამისი შესახებ - ინტექტის კაპონტი, სხვა ჩვენ ჩვენი დასასრულებელი მეტი უფრო მნიშვნელოვანია პოლიპური სისტემები გერბილის პლატატურაში, როდესაც საჭირო მონაცემები იქნება. შემდეგ, თუ მონაცემების ტესტირება განსხვავებული მონაცემების კონტაქციების შემდეგ განსხვავებული მონაცემების კონტაქციების შემდეგ (მაგალითად, კითხვები/ tweets vs ნუტუმენტის დოკუმენტებით), ჩვენი ED მოდელ', 'el': 'Η σύνδεση οντοτήτων (EL) αποτελεί ουσιαστικό έργο για την κατανόηση σημασιολογικών κειμένων και την εξαγωγή πληροφοριών. Οι δημοφιλείς μέθοδοι ασχολούνται ξεχωριστά με τα στάδια Ανίχνευσης Παραμνήσεων και Αποκάλυψης Οντότητας (ΕΔ) της ΕΛ, χωρίς να αξιοποιούν την αμοιβαία εξάρτησή τους. Προτείνουμε εδώ το πρώτο νευρικό σύστημα που από κοινού ανακαλύπτει και συνδέει οντότητες σε ένα κείμενο. Η κύρια ιδέα είναι να εξετάσουμε όλα τα πιθανά διαστήματα ως πιθανές αναφορές και να μάθουμε συγκριτικές βαθμολογίες σχετικά με τους υποψηφίους οντότητας τους που είναι χρήσιμες τόσο για τις αποφάσεις MD όσο και για τις αποφάσεις ED. Βασικά συστατικά είναι οι ενσωματωμένες αναφορές με γνώμονα το περιβάλλον, οι ενσωματώσεις οντότητας και ένας πιθανολογικός χάρτης αναφοράς οντότητας, χωρίς να απαιτούν άλλα σχεδιασμένα χαρακτηριστικά. Εμπειρικά, αποδεικνύουμε ότι η ολοκληρωμένη μέθοδος μας ξεπερνά σημαντικά τα δημοφιλή συστήματα στην πλατφόρμα όταν υπάρχουν αρκετά δεδομένα κατάρτισης. Αντίθετα, αν τα δοκιμαστικά σύνολα δεδομένων ακολουθούν διαφορετικές συμβάσεις σχολιασμού σε σύγκριση με το εκπαιδευτικό σύνολο (π.χ. ερωτήματα/ tweets vs. ειδησεογραφικά έγγραφα), το μοντέλο μας σε συνδυασμό με ένα παραδοσιακό σύστημα προσφέρει την καλύτερη ή δεύτερη καλύτερη ακρίβεια ΕΛ.', 'it': "Entity Linking (EL) è un compito essenziale per la comprensione semantica del testo e l'estrazione di informazioni. I metodi popolari affrontano separatamente le fasi di Rilevamento delle Menzioni (MD) e Disambiguazione delle Entità (ED) di EL, senza sfruttare la loro reciproca dipendenza. Proponiamo qui il primo sistema neurale end-to-end EL che scopre e collega insieme entità in un documento di testo. L'idea principale è quella di considerare tutti i possibili intervalli come potenziali menzioni e imparare punteggi di somiglianza contestuale sui loro candidati entità che sono utili sia per le decisioni MD che ED. Componenti chiave sono incorporazioni di menzioni consapevoli del contesto, incorporazioni di entità e una menzioni probabilistiche - mappa delle entità, senza richiedere altre funzionalità ingegnerizzate. Empiricamente, dimostriamo che il nostro metodo end-to-end supera significativamente i sistemi più diffusi sulla piattaforma Gerbil quando sono disponibili sufficienti dati di allenamento. Al contrario, se i set di dati di test seguono convenzioni di annotazione diverse rispetto al set di allenamento (ad esempio query/tweet vs news documents), il nostro modello ED abbinato a un sistema NER tradizionale offre la migliore o la seconda migliore precisione EL.", 'kk': 'Бөліктерді сілтемелеу (EL) семантикалық мәтін түсінімін және мәліметті тарқату үшін негізгі тапсырма. Көпшілікті әдістер Мәзірлерді анықтау (MD) және электрондық бірліктік тәуелсіздіктерін көмектеспей EL (ED) деңгейінде көмектеседі. Біз мәтін құжаттың бірінші невралдық соңындағы EL жүйесін біріктіру және сілтемелерді біріктіру жүйесін ұсынамыз. Негізгі идея - барлық мүмкін меңзерлерді мүмкін мәліметтер деп ойлау және мәліметтердің мәліметтерінің мәліметтерінің мәліметтерінің мәліметтерінің мәліметтерінің көмегімен бі Кілттер компоненттері - контексті түсініктірілген ендіру, нысандар ендіру және маңызды мәлімет - нысандар картасы, басқа инженерлікті мүмкіндіктерді талап етпейді. Аяқтау әдіміміздің Gerbil платформасындағы мәліметтеріміз жеткілікті оқыту мәліметтері бар болғанда көптеген жүйелерді жасайды. Егер деректер қорларын сынап көрсеткенде, оқыту бағдарламасына (мысалы, сұрақтар/ tweets vs жаңалық құжаттары) салыстырылған түрлі жаңалықтар конвенциясына сәйкес келсе, біздің ED моделіміз дәстүрлі NER жүйесімен бірге бі', 'lt': 'Subjekto ryšiai (EL) yra esminė semantinio teksto supratimo ir informacijos gavimo užduotis. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency.  Mes čia siūlome pirmąją neural in ę nuo vienos iki kitos ELS sistemą, kuri kartu aptinka ir susieja subjektus teksto dokumente. Pagrindinė idėja yra apsvarstyti visas galimas sritis kaip galimas paminėjimas ir sužinoti kontekstinius panašumo rezultatus, palyginti su jų subjekto kandidatais, kurie yra naudingi tiek MD, tiek ED sprendimams. Pagrindinės sudedamosios dalys – tai kontekste žinomi įrašai, subjekto įrašai ir tikimybė – subjekto žemėlapis, nereikalaujant kitų inžinerinių savybių. Empiriškai mes rodome, kad mūsų metodas nuo pabaigos gerbilio platformoje gerokai viršija populiarias sistemas, kai turima pakankamai mokymo duomenų. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.', 'ms': 'Pempautan Entiti (EL) adalah tugas penting untuk pemahaman teks semantik dan ekstraksi maklumat. Kaedah popular secara terpisah menghadapi tahap Pengesanan Mention (MD) dan Entity Disambiguation (ED) EL, tanpa mengambil alih dependensi mereka. Kami di sini melamar sistem EL yang pertama akhir-akhir saraf yang bersama-sama menemukan dan paut entiti dalam dokumen teks. Idea utama ialah mempertimbangkan semua jangkauan mungkin sebagai sebutan potensi dan belajar skor persamaan kontekstual atas calon entiti mereka yang berguna untuk keputusan MD dan ED. Komponen kunci ialah penyelesaian penyelesaian konteks-sedar, penyelesaian entiti dan penyelesaian kemungkinan - peta entiti, tanpa memerlukan ciri-ciri reka lain. Empirikal, kita menunjukkan bahawa kaedah akhir-akhir kita jauh lebih melampaui sistem populer di platform Gerbil apabila data latihan cukup tersedia. Sebaliknya, jika set data ujian mengikut konvensi anotasi yang berbeza dibandingkan dengan set latihan (cth. tanya/ tweet vs dokumen berita), model ED kami ditambah dengan sistem NER tradisional menawarkan kepekatan EL yang terbaik atau kedua yang terbaik.', 'mt': 'L-Entità Linking (EL) hija kompitu essenzjali għall-fehim u l-estrazzjoni tat-test semantiku. Il-metodi popolari jindirizzaw separatament l-istadji tad-Detezzjoni tal-Menzjoni (MD) u d-Diżambigwarazzjoni tal-Entità (ED) tal-EL, mingħajr ma jinfluwenzaw id-dipendenza reċiproka tagħhom. Hawnhekk nipproponu l-ewwel sistema tal-EL minn tarf sa tarf li b’mod konġunt tiskopri u tgħaqqad entitajiet f’dokument tat-test. L-idea ewlenija hija li jitqiesu l-firxiet possibbli kollha bħala msemmija potenzjali u jitgħallmu punteġġi ta’ similarità kuntestwali fuq il-kandidati tal-entità tagħhom li huma utli kemm għad-deċiżjonijiet tal-MD kif ukoll għad-deċiżjonijiet tal-ED. Il-komponenti ewlenin huma inkorporazzjonijiet ta’ referenza konxji mill-kuntest, inkorporazzjonijiet ta’ entitajiet u referenza probabilistika – mappa ta’ entitajiet, mingħajr ma jitolbu karatteristiċi inġinerizzati oħra. Empirikament, nagħmlu evidenza li l-metodu tagħna minn tarf sa tarf iwassal b’mod sinifikanti għal sistemi popolari fuq il-pjattaforma Gerbil meta tkun disponibbli biżżejjed dejta dwar it-taħriġ. Għall-kuntrarju, jekk is-settijiet tad-dejta tal-ittestjar isegwu konvenzjonijiet differenti ta’ annotazzjoni meta mqabbla mas-sett tat-taħriġ (e ż. mistoqsijiet/ tweets vs dokumenti tal-a ħbarijiet), il-mudell tad-dejta tagħna flimkien ma’ sistema NER tradizzjonali joffri l-aħjar jew it-tieni l-aħjar preċiżjoni tal-EL.', 'mn': 'Entity Linking (EL) нь semantic text ойлголт болон мэдээллийн гаргалтын чухал ажил юм. Харин олон хүн төрөлхтний арга зам нь ЕЛ-ын санааны нээлт (MD) болон Entity Disambiguation (ED) хэмжээсүүдийг тусгаарлаж, харилцааны хамааралтай байдлыг нөлөөлөхгүй. Энд бид анхны мэдрэлийн төгсгөл-төгсгөл EL системийг санал болгож байна. Энэ нь текст баримтын нэгдлийг нээлттэй, холбоотой. Эхний гол санаа бол бүх боломжтой огторгуудыг боломжтой хэлэлцэл гэж үзэх, мөн адилхан тоонуудыг судлах, MD болон ED шийдвэрлэхэд хэрэглэгддэг орнуудын захирагчид дээр хэрэглэгддэг. Товчтой компонентүүд нь контекст-мэдээлэл дээр бусад инженерчлэн чадваруудыг шаардахгүйгээр нэрлэж, бүтээгдэхүүний нэвтрүүлэлт, магадгүй нэвтрүүлэлт юм. Харин үнэндээ бидний төгсгөлийн арга нь Гербил платформад хангалттай суралцах өгөгдлийн хангалттай үед олон хүн төрөлхтний системээс илүү илүү үр дүнтэй гэдгийг харуулж байна. Ерөнхийдөө, хэрвээ өгөгдлийн сангуудыг шалгаж байвал сургалтын багтаагаас харьцуулахад өөр өөр анзаарлын байгууллагуудыг дагах (жишээ нь queries/ tweets vs news documents), бидний ED загвар нь уламжлалт NER системтэй хамтдаа хамгийн сайн эсвэл хоёр дах', 'mk': 'Поврзувањето на ентитетите (ЕЛ) е суштинска задача за семантичко разбирање на текстот и извлекување на информации. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency.  Овде го предложуваме првиот нервен ЕЛ систем кој заедно открива и врзува ентитети во текст документ. Главната идеја е да се сметаат сите можни области како потенцијални спомени и да се научат контекстни оценки на сличност во врска со нивните кандидати за ентитет кои се корисни за одлуките на МД и ЕД. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features.  Импирски, покажуваме дека нашиот метод од крај до крај значително ги надминува популарните системи на платформата Гербил кога се достапни доволни податоци за обука. Наспротивно, ако тестирањето на податоците следи различни конвенции за анотација во споредба со наборот на обуки (на пример, прашања/ твитови против новинските документи), нашиот модел ЕД, поврзан со традиционален систем НЕР, нуди најдобра или втора најдобра преци', 'no': 'Entitetslenking (EL) er ein viktig oppgåve for semantisk forståelse av tekst og utpakking av informasjon. Opphavlege metodar adresserer individuelt menytteringsoppdaginga (MD) og Entity Disambiguation (ED) stadene til EL, utan å levera sine mutual avhengighet. Vi foreslår den første neirale sluttesystemet EL som kopla oppdagar og lenkjer einingar i eit tekstdokument. Hovudsideen er å vurdere alle moglege mellomrom som potensielle minningar og lære kontekstiske liknandige poeng over dei einingskandidatane som er nyttig for både MD og ED-avgjøringar. Nøkkelkomponentar er kontekst-oppmerkingar, innbygging av einingar og eit sannsynlig oppmerking – einingskart utan å kreva andre ingeniar funksjonar. I tidspunktet viser vi at sluttmetoden vår utfører populære systemar på Gerbil-plattformat når nok treningsdata er tilgjengeleg. Omsetjinga av datasett følgjer ulike notasjonskonvensjonar sammenlignet med opplæringsinnstillingane (f.eks. spørjingar/ tweets vs nytt- dokument), vår ED- modell kopla med ein tradisjonell NER- systemet tilbyr den best e eller andre beste nøyaktigheten til EL.', 'ml': 'സെമാന്റിക് ടെക്സ്റ്റ് ബുദ്ധിമുട്ടിയും വിവരങ്ങള്\u200d പുറത്തെടുക്കുന്നതിനും എന്റിറ്റി ലിങ്ങിംഗ് (E പ്രധാനപ്പെട്ട രീതികള്\u200d വേര്\u200dതിരിച്ച് മെന്\u200dഷന്\u200d ഡിറ്റീഷന്\u200d (എംഡി) എന്നിവയുടെ സ്ഥിതിയും (ED) സ്റ്റേഷന്\u200d വിലാസപ്പെടുത്ത നമ്മളിവിടെ ഒരു ടെക്സ്റ്റ് രേഖയില്\u200d ഒന്നാമത്തെ ന്യൂറല്\u200d അവസാനിപ്പിക്കുന്ന എല്\u200d സിസ്റ്റം പ്രായശ്ചിത്തമാകുന് The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions.  കീ ഘടകം പ്രധാനപൂര്\u200dണ്ണമായും നമ്മുടെ അവസാനത്തേക്കുള്ള അവസാന രീതിയില്\u200d ജെര്\u200dബില്\u200d പ്ലാറ്റ്ഫോമില്\u200d പ്രധാനപ്പെട്ട സിസ്റ്റം പ്രകട അതായത്, പരീക്ഷിക്കുന്ന ഡാറ്റാസറ്റുകള്\u200d പരിശോധിക്കുന്നത് പരിശോധിപ്പിക്കുന്നതിനെക്കുറിച്ച് വ്യത്യസ്തമായ വിവരങ്ങള്\u200d പിന്തുടരുന്നുണ്ടെങ്കില്\u200d( ഉദാഹരണ', 'sr': 'Povezanje podataka (EL) je ključni zadatak za semantičko razumevanje teksta i izvlačenje informacija. Narodne metode odvojeno se obraćaju na faze EL-a za detekciju spomenika (MD) i disambiguaciju (ED), bez uticaja na njihovu zajedničku zavisnost. Ovde predlažemo prvi nervni sistem koji zajedno otkriva i povezuje entitete u tekstu. Glavna ideja je razmotriti sve moguće prostore kao potencijalne spomena i naučiti kontekstualne rezultate sličnosti nad svojim kandidatima entiteta koji su korisni i za MD i ED odluke. Ključni komponenti su svesni konteksta spominjanja integracija, integracija entiteta i verovatno spominjanja - map a entiteta, bez zahteva drugih inženjerskih karakteristika. U praksi, pokazujemo da naš metod kraja do kraja značajno iznosi popularne sisteme na Gerbilskoj platformi kada su dostupni dovoljno podataka za obuku. U suprotnom, ako testiranje podataka slijedi različite konvencije za annotaciju u usporedbi sa setom obuke (npr. ispitivanja/ tweets protiv novinskih dokumenta), naš ED model zajedno s tradicionalnim sistemom NER nudi najbolju ili drugu najbolju tačnost EL-a.', 'pl': 'Entity Linking (EL) jest niezbędnym zadaniem dla zrozumienia tekstu semantycznego i ekstrakcji informacji. Popularne metody oddzielnie odnoszą się do etapów wykrywania wspomnień (MD) i rozjasnienia podmiotów (ED), bez wykorzystania ich wzajemnej zależności. Proponujemy pierwszy neuronowy kompleksowy system EL, który wspólnie odkrywa i łączy podmioty w dokumencie tekstowym. Główną ideą jest uwzględnienie wszystkich możliwych zakresów jako potencjalnych wzmianek i poznanie kontekstowych punktów podobieństwa kandydatów podmiotów, które są przydatne zarówno dla decyzji MD, jak i ED. Kluczowymi składnikami są kontekstowe osadzenia wspomnień, osadzenia jednostek i prawdopodobna mapa wspomnień wspomnień wspomnień, bez wymagania innych funkcji inżynieryjnych. Empirycznie pokazujemy, że nasza metoda end-to-end znacznie przewyższa popularne systemy na platformie Gerbil, gdy dostępna jest wystarczająca ilość danych treningowych. Z drugiej strony, jeśli testowane zestawy danych spełniają różne konwencje adnotacyjne w porównaniu do zestawu szkoleniowego (np. zapytania/ tweety vs dokumenty wiadomościowe), nasz model ED w połączeniu z tradycyjnym systemem NER oferuje najlepszą lub drugą najlepszą dokładność EL.', 'ro': 'Entity Linking (EL) este o sarcină esențială pentru înțelegerea textului semantic și extragerea informațiilor. Metodele populare abordează separat etapele de detectare a mențiunilor (MD) și dezambiguizare a entităților (ED), fără a valorifica dependența lor reciprocă. Propunem aici primul sistem neural end-to-end EL care descoperă și leagă împreună entitățile într-un document text. Ideea principală este de a lua în considerare toate intervalele posibile ca mențiuni potențiale și de a învăța scoruri de similitudine contextuală peste candidații entității lor, care sunt utile atât pentru deciziile MD, cât și ED. Componentele cheie sunt încorporarea mențiunilor conștiente de context, încorporarea entităților și o mențiune probabilistică - harta entității, fără a solicita alte caracteristici proiectate. Din punct de vedere empiric, arătăm că metoda noastră end-to-end depășește semnificativ sistemele populare de pe platforma Gerbil atunci când sunt disponibile suficiente date de antrenament. Dimpotrivă, dacă seturile de date de testare urmează convenții diferite de adnotare comparativ cu setul de instruire (de exemplu interogări / tweets vs documente de știri), modelul nostru ED cuplat cu un sistem NER tradițional oferă cea mai bună sau a doua cea mai bună precizie EL.', 'sv': 'Entity Linking (EL) är en viktig uppgift för semantisk textförståelse och informationsutvinning. Populära metoder behandlar separat stadierna Mention Detection (MD) och Entity Disambiguation (ED) av EL, utan att utnyttja deras ömsesidiga beroende. Vi föreslår här det första neurala end-to-end EL-systemet som tillsammans upptäcker och länkar entiteter i ett textdokument. Huvudidén är att betrakta alla möjliga spännvidder som potentiella omnämnanden och lära sig kontextuella likhetspoäng över deras entitetskandidater som är användbara för både MD och ED beslut. Viktiga komponenter är kontextmedvetna omnämningsinbäddningar, entitetsinbäddningar och en sannolik omnämning - entitetskarta, utan att kräva andra konstruerade funktioner. Empiriskt visar vi att vår end-to-end-metod avsevärt överträffar populära system på Gerbilplattformen när tillräckligt med träningsdata finns tillgänglig. Omvänt, om testdatauppsättningar följer olika noteringskonventioner jämfört med träningsuppsättningen (t.ex. frågor/tweets vs nyhetsdokument), erbjuder vår ED-modell tillsammans med ett traditionellt NER-system den bästa eller näst bästa EL-noggrannheten.', 'si': 'ඉන්තිත්වය සම්බන්ධය (EL) ක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක වෙනුවෙන් සැමැන්තික පාළුව සහ ප්\u200dරජාතික විදේශ පරීක්ෂණය (MD) සහ ඉන්තිත් අවස්ථාවය (ED) පරීක්ෂණය (EL) පරීක්ෂණය වෙනුවෙන් පරීක්ෂණය කරනවා, ඔවුන් අපි මෙතන ප්\u200dරථම න්\u200dයූරල් අවසානයෙන් අවසානය කරනවා EL පද්ධතිය, සම්බන්ධයෙන් හොයාගන්න සහ ලිපින්ත ලිපින්ත ප්\u200dරධාන අදහසය තමයි ඔක්කොම පුළුවන් වෙන්න පුළුවන් ස්ථානයක් කියලා හිතන්න, සම්බන්ධතාවක් සමාන්\u200dයතාවක් ප්\u200dරතිකා යතුරු අංශාවක් තමයි සංවේදනය සඳහා අංශ්\u200dය සංවේදනය සහ අංශ්\u200dය සංවේදනය සඳහා අංශ්\u200dය සංවේදනය සඳහා අං අපි පෙන්වන්නේ අපේ අවසානයෙන් අවසානයෙන් අවසානය විදියට ජර්බිල් ප්ලේටප් එකේ ප්\u200dරජාත පද්ධතිය පුළුවන් වෙන්න වෙනස් වෙනස්, දත්ත සැට පරීක්ෂණය කරන්නේ වෙනස් ප්\u200dරශ්නයක් සම්බන්ධයෙන් පරීක්ෂණය කරනවා නම් (උදාහරණයෙන්, querys/ tweets vs news papers), අපේ ED මොඩේල් සම්බන්ධයෙන', 'so': 'Isku xiriirka ganacsiga (EL) waa shaqa muhiim ah oo ay u baahan tahay waxgarashada saxda iyo soo bixinta macluumaadka. Qaadooyinka dadweynaha gooni ahaantooda waxaa loogu yeeraa qeybta xuquuqda (MD) iyo jardiinada naafada (ED) ee EL, iyadoon u dhiibin xiriirkooda dhexe. Halkan waxaan soo jeedaynaa nidaamka ugu horeeya ee ugu dambaysta neurada ee EL, kaas oo si wada jir ah u baaqanaya islamarkaasna ku xiriira alaabta ku qoran warqad qoraal ah. Fikirada ugu muhiimsan waa inuu ka fikiraa dhammaan boosaska suurtagalka ah oo ay ka bartaan qiimaha isku mid ah oo ay ka faa’iideeyaan go’aanka MD iyo ED. Qaybaha furayaashu waa qoraalka ku qoran ee ku qoran qoraalka, qalabka jidhka iyo warqada suurtagalka ah - karta aqoonta, iyadoon u baahnayn tayooyin kale oo la qoray. Si fiican ayaan u muujinnaa in qaababka ugu dhammaadka ee ugu dambaysta ah uu si weyn ugu muujiyaa nidaamka maamulka ah ee Gerbil marka lagu helo macluumaad waxbarasho ku filan. Inta kale, haddii tijaabinta macluumaadku ay raacaan shirkado kala duduwan oo la barbardhiga qoraalka waxbarashada (tusaale ahaan queries/ tweetis vs. dukumentiyada warbixinta), midowgeen ED wuxuu ku xiran yahay nidaamka caadiga ah e e NER wuxuu bixiyaa saxda EL ee ugu wanaagsan ama labaad.', 'ur': 'انٹیٹی لینک (EL) سیمانٹی ٹیکسٹ سمجھنے اور اطلاعات اٹھانے کے لئے ایک ضروری کام ہے. مہمانٹ شناسایت (MD) اور ایٹنی ڈاممبیوٹ (ED) مرحلے سے مختلف طریقے لگاتے ہیں، بغیر ان کے ایک دوسرے کے اعتباری کے مطابق۔ ہم یہاں پہلی نئورل پائن-پائن-پائن الی سیستم کی پیشنهاد کریں جو ایک ٹکسٹ دکھانٹ میں اتنی پیدا کرتا ہے اور لینک کرتا ہے. اصلی نظر یہ ہے کہ تمام امکان جگہ کو امکان کے ذریعے سمجھنا اور ان کے اختیار کاندینٹوں پر متوسط سیکھنا جو MD اور ED فیصلے کے لئے فائدہ دار ہیں. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. ہم نشان دیتے ہیں کہ ہماری پایان و پایان کا طریقہ جربیل پلٹورم پر مشهور سیستموں سے زیادہ اضافہ کرتا ہے جب کافی تربین ڈیٹا موجود ہوتا ہے۔ بغیر، اگر ڈیٹ سٹوں کی آزمائش مختلف آزمائش کی تعلیم سٹ کے مقابلہ میں مختلف آزمائش کا اتباع کرتی ہے (جیسے queries/ tweets vs news documents), ہمارے ED مدل ایک سنتی NER سیسٹم کے ساتھ ملے ہوئے ایک بہترین یا دوسری بہترین EL دقیق پیش کرتا ہے.', 'ta': 'பாதிப்பு உரை புரிந்து கொள்ளும் தகவல் பெறுவதற்கான முக்கியமான செயல் பொதுவான முறைமைகள் தனிப்பட்ட முறைகளில் மென்பொருள் கண்டுபிடிப்பு (MD) மற்றும் செயற்பாடு முறைமையில் (ED) நிலைகளை முகவரிக்கவு நாங்கள் இங்கே முதல் புதிய முடிவு முடிவு EL அமைப்பை பரிந்துரைக்கிறோம். அது ஒன்றாக கண்டுபிடிக்கும் மற்றும் இணைப் முக்கிய ய கருத்து என்னவென்றால் அனைத்து சாத்தியமான வேலைகளையும் சிந்திக்கவும் மற்றும் தற்காலிக போன்ற மதிப்பெண்களை கற்றுக் கொள் விசை பொருள்கள் சூழல் அறிந்து கொள்ளப்படும் உள்ளடக்கங்கள், பொருள் உள்ளிடுதல் மற்றும் ஒரு சாத்தியமான குறிப்பு- பொருள் வரைபடம், மற்றொ வெற்றிகரமாக, நாம் காண்பிக்கிறோம் போதுமான பயிற்சி தரவு கிடைக்கும் போது ஜெர்பில் முழுமையான முறைமையில் பெரிய முற மாறாக, பரிசோதிப்பு தகவல் அமைப்புகள் பயிற்சி அமைப்புகளை ஒப்பிடும் வேறு வித்தியாசமான அறிவிப்பு செய்திகளை பின்பற்றினால் (உதாரணமாக கேள்விகள்/ tweets vs செய்த', 'uz': "Name Name Bu yerda biz matn hujjatda birinchi neyron oxirigi EL tizimni birinchi darajada ko'rib chiqaramiz. Mavjud fikr shunday qilib, hamma imkoniyatlarni qo'llashga ega bo'lish va ma'lumotning bir xil qismini o'rganish mumkin, bu MD va ED xususiyatlariga foydalanishi mumkin. @ info Biz shunday qilamiz, bizning oxirimiz usuli Gerbil platformidagi muammiy tizimlarni ishlab chiqaradi. Taʼminlovchi maʼlumot mavjud boʻlganda. Ikkinchi darajada, agar maʼlumotlar tizimi taʼminlovchi soʻzlardan bir xil taʼminlovchi qoʻllanmalar (masalan soʻrovlar/ tweetilar vs. news hujjatlari) bilan bog'liq boʻlsa, bizning ED modelimizning taʼminlovchi NER tizimi eng yaxshi yoki ikkinchi eng eng yaxshi EL tashkilligini ber", 'vi': 'Việc liên kết chi tiết là một nhiệm vụ thiết yếu cho việc hiểu nghĩa chữ và khai thác thông tin. Các phương pháp ưa thích được thảo luận riêng về các giai đoạn trinh sát tâm lý (MD) và biến đổi thực thể (ED) của el, mà không nhờ cậy vào nhau. Chúng tôi đề xuất hệ thống thần kinh đầu tiên, từ đầu đến cuối, phát hiện và liên kết các thực thể trong một tài liệu văn bản. Chủ đề chính là xem xét tất cả các bước mở rộng có thể như là các khả năng đề cập và học các điểm tương đồng trên các ứng cử viên thực thể có ích cho cả các quyết định MD và ED. Các thành phần chính là sự nhúng vào nhận dạng ngữ cảnh, sự cấy ghép thực thể và một bản đồ thực thể hiển nhiên được nhắc đến Đầy năng lực, chúng tôi cho thấy phương pháp cuối cùng của chúng tôi khả năng vượt trội các hệ thống phổ biến trên bục Gerbil khi có đủ dữ liệu đào tạo. Ngược lại, nếu các tập tin thử nghiệm theo các lệ chuẩn ghi chú khác nhau so với các tập tin (v.d. các câu hỏi/ tweet v. các tài liệu thời sự kiện thời sự) của chúng tôi, mô hình ED kết hợp với một hệ thống giao khẩu cay truyền thống cung cấp độ chính xác tốt nhất hoặc thứ hai.', 'bg': 'Свързването на обекти (EL) е основна задача за семантичното разбиране на текста и извличане на информация. Популярните методи поотделно разглеждат етапите за откриване на споменаване (MD) и за разграничаване на субектите (ED) на EL, без да използват взаимната им зависимост. Тук предлагаме първата невронна система от край до край, която съвместно открива и свързва обекти в текстов документ. Основната идея е да се разгледат всички възможни интервали като потенциални споменания и да се научат контекстуални оценки за сходство над техните кандидати за юридически лица, които са полезни както за решения за медицина, така и за ЕД. Ключови компоненти са вграждания с контекст, вграждания на обекти и вероятностно споменаване - карта на обекти, без да се изискват други инженерни функции. Емпирично показваме, че нашият метод от край до край значително превъзхожда популярните системи на платформата, когато има достатъчно данни за обучение. Обратно, ако тестовите набори от данни следват различни конвенции за анотация в сравнение с набора от обучения (например запитвания / туитове срещу новинарски документи), нашият модел в комбинация с традиционна система предлага най-добрата или втора най-добра точност на ЕЛ.', 'da': 'Entity Linking (EL) er en vigtig opgave for semantisk tekstforståelse og informationsudvinding. Populære metoder behandler separat stadierne Mention Detection (MD) og Entity Disambiguation (ED) i EL, uden at udnytte deres gensidige afhængighed. Vi foreslår her det første neurale end-to-end EL-system, der i fællesskab opdager og linker enheder i et tekstdokument. Hovedideen er at overveje alle mulige spænder som potentielle omtaler og lære kontekstuelle lighedsscorer over deres enhedskandidater, der er nyttige for både MD og ED beslutninger. Nøglekomponenter er kontekstbevidste nævnelsesindlejringer, enhedsindlejringer og en sandsynligvis nævnelse - enhedskort, uden at kræve andre konstruerede funktioner. Empirisk viser vi, at vores end-to-end metode betydeligt overgår populære systemer på Gerbil platformen, når der er tilstrækkelige træningsdata til rådighed. Omvendt, hvis testdatasæt følger forskellige anmærkningskonventioner i forhold til træningssættet (f.eks. forespørgsler/tweets vs. nyhedsdokumenter), giver vores ED-model kombineret med et traditionelt NER-system den bedste eller næstbedste EL-nøjagtighed.', 'de': 'Entity Linking (EL) ist eine wesentliche Aufgabe für semantisches Textverständnis und Informationsextraktion. Beliebte Methoden befassen sich separat mit den Stufen Mention Detection (MD) und Entity Disambiguation (ED) von EL, ohne deren gegenseitige Abhängigkeit zu nutzen. Wir schlagen hier das erste neuronale End-to-End EL-System vor, das Entitäten in einem Textdokument gemeinsam entdeckt und verknüpft. Die Hauptidee ist, alle möglichen Spanns als potenzielle Erwähnungen zu betrachten und kontextbezogene Ähnlichkeitsbewertungen über ihre Entitätskandidaten zu lernen, die sowohl für MD- als auch ED-Entscheidungen nützlich sind. Schlüsselkomponenten sind kontextbezogene Erwähnungs-Einbettungen, Entity-Einbettungen und eine probabilistische Erwähnungs-Entity-Map, ohne dass andere technische Funktionen erforderlich sind. Empirisch zeigen wir, dass unsere End-to-End-Methode beliebte Systeme auf der Gerbil-Plattform deutlich übertrifft, wenn genügend Trainingsdaten verfügbar sind. Wenn Testdatensätze im Vergleich zum Trainingsset anderen Annotationskonventionen folgen (z.B. Abfragen/Tweets vs. Nachrichtendokumente), bietet unser ED-Modell in Verbindung mit einem traditionellen NER-System die beste oder zweitbeste EL-Genauigkeit.', 'nl': "Entity Linking (EL) is een essentiële taak voor semantisch tekstbegrip en informatieextractie. Populaire methoden behandelen afzonderlijk de stadia Mention Detection (MD) en Entity Disambiguation (ED) van EL, zonder gebruik te maken van hun onderlinge afhankelijkheid. We stellen hier het eerste neurale end-to-end EL-systeem voor dat entiteiten gezamenlijk ontdekt en verbindt in een tekstdocument. Het belangrijkste idee is om alle mogelijke spans als potentiële vermeldingen te beschouwen en contextuele vergelijkingsscore's te leren over hun entiteitskandidaten die nuttig zijn voor zowel MD- als ED-beslissingen. Belangrijke componenten zijn contextbewuste vermeldingsinsluitingen, entiteitsinsluitingen en een probabilistische vermelding-entiteitskaart, zonder andere technische functies te vereisen. Empirisch laten we zien dat onze end-to-end methode veel beter presteert dan populaire systemen op het Gerbil platform wanneer er voldoende trainingsgegevens beschikbaar zijn. Omgekeerd, als testdatasets verschillende annotatieconventies volgen in vergelijking met de trainingsset (bijvoorbeeld query's/tweets vs. nieuwsberichten), biedt ons ED-model in combinatie met een traditioneel NER-systeem de beste of op een na beste EL-nauwkeurigheid.", 'id': 'Entity Linking (EL) adalah tugas penting untuk pemahaman teks semantis dan ekstraksi informasi. Metode popular secara terpisah mengatasi tahap Deteksi Menisi (MD) dan Entity Disambiguation (ED) dari EL, tanpa mengakibatkan ketergantuan mereka. Kami di sini mengusulkan sistem EL neural akhir-akhir pertama yang bersama-sama menemukan dan menghubungkan entitas dalam dokumen teks. Ide utama adalah mempertimbangkan semua jangkauan mungkin sebagai potensi sebutan dan belajar skor persamaan kontekstual atas calon entitas mereka yang berguna untuk keputusan MD dan ED. Komponen kunci adalah konteks-conscious mention embedding, entity embedding dan sebuah probabilis mention - entity map, tanpa menuntut fitur rekayasa lain. Empiris, kita menunjukkan bahwa metode akhir-akhir kita jauh lebih besar dari sistem populer di platform Gerbil ketika cukup data latihan tersedia. Sebaliknya, jika tes dataset mengikuti konvensi annotasi yang berbeda dibandingkan dengan set latihan (contohnya queries/ tweets vs dokumen berita), model ED kami ditambah dengan sistem NER tradisional menawarkan akurasi EL terbaik atau kedua terbaik.', 'hr': 'Obvezivanje objekata (EL) je ključni zadatak za semantičko razumijevanje teksta i izvlačenje informacija. Narodne metode odvojeno se obraćaju na faze EL-a za detekciju spomenika (MD) i disambigaciju entiteta (ED), bez utjecaja na njihovu zajedničku zavisnost. Ovdje predlažemo prvi nervni sustav koji zajedno otkriva i povezuje entitete u tekstnom dokumentu. Glavna ideja je razmotriti sve moguće mjesta kao potencijalne spominjanje i naučiti kontekstualne rezultate sličnosti nad kandidatima entiteta koji su korisni za odluke MD i ED. Ključni komponenti su kontekstski svjesni spominjanja integracija, integracija entiteta i vjerojatno spominjanja - map a entiteta, bez zahtjeva drugih inženjerenih karakteristika. Empirički, pokazujemo da naša metoda kraja do kraja značajno iznosi popularne sustave na platformi Gerbil kada su dostupni dovoljno podataka za obuku. U suprotnom, ako testiranje podataka slijedi različite konvencije o annotaciji u usporedbi s setom obuke (npr. pitanja/ tweets vs novinskim dokumentima), naš ED model zajedno s tradicionalnim sustavom NER nudi najbolju ili drugu najbolju to čnost EL-a.', 'fa': 'واحد ارتباط (EL) یک وظیفه مهمی برای درک متن سنتی و استخراج اطلاعات است. روش\u200cهای محبوب جداً به مرحله\u200cهای شناسایی یادآوری (MD) و ناپدید کردن واحدی (ED) از EL address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. ما اینجا اولین سیستم پایان\u200cپایان\u200cهای عصبی EL را پیشنهاد می\u200cکنیم که با همدیگر entities را در یک سند متن کشف می\u200cکند و ارتباط می\u200cدهد. ایده اصلی این است که همه فضای ممکن را به عنوان یادآوری پتانسیل و دریافت امتیاز مشابه\u200cای در مورد کاندیداتی\u200cهای اجتماعی خود که برای تصمیم\u200cهای MD و ED استفاده می\u200cکنند. بخش\u200cهای کلیدی در مورد آگاهی آگاهی آگاهی است که در مورد آگاهی آگاهی آگاهی باشند، بخش\u200cهای شرکت\u200cها و یک ذکر احتمالاتی است - نقشه\u200cی شرکت، بدون نیازی به ویژه\u200cهای مهندسی دیگر. در حقیقت، ما نشان می دهیم که روش پایان و پایان ما در حالی که داده های آموزش کافی موجود است، سیستم\u200cهای محبوب را در Plataforma جربیل بیشتر انجام می دهد. بر خلاف این، اگر آزمایش مجموعه\u200cهای داده\u200cها در مقایسه با مجموعه آموزش متفاوت پیروی کنند (مثال سوال/ توئیت vs سند\u200cهای خبری) مدل ED ما با یک سیستم NER سنتی بهترین یا دومین بهترین دقیق EL را پیشنهاد می\u200cدهد.', 'sw': 'Kuunganisha Ujumbe (EL) ni jukumu la muhimu la kuelewa maandishi ya sekunde na utoaji wa habari. Utawala maarufu huzungumzia tofauti kuhusu Kutambua Kutajwa (MD) na Ukosefu wa Ujasiri (ED) katika hatua za EL, bila kuitumia kutegemea. Hapa tunapendekeza mfumo wa kwanza wa mwisho wa neura wa mwisho wa mwisho wa EL ambao kwa pamoja hugundua na kuunganisha vifaa katika nyaraka ya maandishi. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions.  Vifaa muhimu ni kutaja vifaa vinavyoeleweka kwa muktadha, vifaa vinavyoingiliwa na kutaja vizuri - ramani ya vifaa, bila kudai vipengenezo vingine vilivyoandikwa. Kwa ujumla, tunaonyesha kuwa mbinu yetu ya mwisho kwa kiasi kikubwa inafanya mifumo maarufu kwenye jukwaa la Gerbil pale taarifa za mafunzo yanapotosha. Kwa tofauti, kama seti za taarifa zinafuata mikataba tofauti ya matangazo yanayolinganisha na seti ya mafunzo (kwa mfano, maswali/ twita na nyaraka za habari), mtindo wetu wa ED umeunganishwa na mfumo wa kitamaduni wa NER unatoa uhakika bora au wa pili wa EL.', 'ko': '실체 링크는 의미 텍스트 이해와 정보 추출의 중요한 임무이다.유행하는 방법은 EL의 언급 검출(MD)과 실체 분리(ED) 단계를 각각 처리하고 그들의 상호 의존성을 이용하지 않는다.우리는 여기서 첫 번째 신경단에서 단까지의 EL 시스템을 제기했는데, 이것은 텍스트 문서의 실체를 연합하여 발견하고 연결할 수 있다.모든 가능한 경계를 잠재적인 언급으로 고려하고 그 실체 후보의 상하문 유사성 점수를 파악하는 것이 MD와 ED 결정에 유용하다는 것이 주요 사상이다.관건적인 구성 요소는 상하문 감지 언급 삽입, 실체 삽입과 확률 언급 실체 맵이며 다른 공사 특성이 필요하지 않습니다.경험적으로 볼 때 충분한 훈련 데이터를 사용할 수 있을 때 우리의 끝에서 끝까지의 방법은 다람쥐 플랫폼에서 유행하는 시스템보다 현저히 우수하다.반대로 훈련집에 비해 테스트 데이터 집합이 서로 다른 주석 약정(예를 들어 조회/추문과 뉴스 문서)을 따른다면 우리의 ED모델과 전통적인 NER시스템은 최상의 EL 정확도를 제공할 수 있다.', 'sq': 'Entity Linking (EL) është një detyrë thelbësore për kuptimin semantik të tekstit dhe nxjerrjen e informacionit. Metodat popullore trajtojnë veçanërisht fazat e zbulimit të përmendimeve (MD) dhe zhdukjes së njësisë (ED) të EL, pa përdorur varësinë e tyre të ndërsjelltë. Këtu propozojmë sistemin e parë të EL-së që zbulon dhe lidh njësitë në një dokument teksti. Ideja kryesore është të konsiderohen të gjitha fushat e mundshme si përmendime të mundshme dhe të mësohen rezultate të ngjashmërisë kontekstuale mbi kandidatët e njësisë së tyre që janë të dobishme si për vendimet e MD-së ashtu dhe të ED-së. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features.  Empirikisht, ne tregojmë se metoda jonë nga fundi në fund ekziston në mënyrë të konsiderueshme mbi sistemet popullore në platform ën Gerbil kur të dhënat e mjaftueshme të trajnimit janë në dispozicion. Përkundrazi, në qoftë se testimi i grupeve të të dhënave ndjek konventa të ndryshme të anotacionit krahasuar me grupin e stërvitjeve (për shembull pyetjet/ tweetet vs dokumentet e lajmeve), modeli ynë ED bashkuar me një sistem tradicional NER ofron saktësinë më të mirë apo të dytën më të mirë të EL.', 'tr': 'Baglaýyş Baglaýyş (EL) semantik metin düşünmesi we maglumat gaýşartmaky üçin esasy zadyr. Menu Detection (MD) we Entity Disambiguation Biz bu ýerde bir metin senediň birinji neural niýeti we soňunda çykan EL sistemini teklip ederis. Esasy ideýa hemme mümkin sahypalary potensial aýdymlar diýip pikir etmekdir we özüniň durum meňzeşliklerini hem MD we ED kararlaryna üçin faydaly bolan guramlary üçin öwrenmelidir. Açan komponentler kontekst bilen habarlanýan içerikler, enti ködlemeleri we olaryň bir görkezmesi - enti mapi, beýleki injiner edip özellikleri islemeýän. Iň görä, biz iň soňky taryhymyzyň Gerbil platformasynda ýeterlik okuwçylyk maglumatlaryň bardygynda meşhur sistemalaryň üstüne ýok bolandygyny görkeýäris. Munuň ýagdaýynda, eger veri düzümlerini barlamak üçin deňleýän duýdurma düzümlerini diňleýän duýdurma düzümlerini diňleýän bolsa (meselm. queries/ tweets vs täzelikler ýa-da täzelikler senediň ýaly), biziň ED modelimiz däpli bir NER sistemi bilen birleşen', 'af': "Entiteit Linking (EL) is 'n nuwe taak vir semantiese teks verstanding en inligting uitvoer. Pobleerde metodes skakelik adres die Kieslysverking (MD) en Entity Disambiguation (ED) stadige van EL, sonder om hul gemeenskaplike afhanklikheid te verwyder. Ons hier voorstel die eerste neurale end- to- end EL stelsel wat jointly ontdek en skakel entiteite in 'n teksdokument. Die hoofde idee is om alle moontlike spans as potensiele bemenging te beskou en om kontekstlike gelykenis aantal te leer oor hul entiteit-kandidate wat bruikbaar is vir beide MD en ED-besluite. Sleutel komponente is konteks-bekende bepaalde inbêdings, entiteitinbêdings en 'n waarskynlik nommer - entiteitkaart, sonder ander inbineerde funksies te vra. Regtig, ons wys dat ons einde-tot-einde metode betekenlik populêre stelsels op die Gerbil-platforma uitvoer wanneer genoeg onderwerp data beskikbaar is. Omgeskakel, as toets datastelle volg verskillende annotasie konvensies vergelyk met die opvoering stel (bv. vrae/ tweets vs nuusdokumente), ons ED model gekoppel met 'n tradisionele NER stelsel offer die best e of tweede beste EL presies.", 'hy': 'Միության կապը (ԷԼ) սեմանտիկ տեքստի հասկանալու և տեղեկատվության վերացման կարևոր խնդիր է: Բնակչության մեթոդները առանձին վերաբերում են ԷԼ-ի հիշողության հայտնաբերման (MD) և անհատականության (ED) փուլերին, առանց օգտագործելու նրանց փոխկապակցված կախվածությունը: Այստեղ մենք առաջարկում ենք առաջին նյարդային վերջ-վերջ ԷԼ համակարգը, որը միասին հայտնաբերում է և կապում է էլեկտներ տեքստի փաստաթղթի մեջ: Հիմնական գաղափարն այն է, որ բոլոր հնարավոր տարածքները դիտարկենք որպես պոտենցիալ հիշողություններ և սովորենք կոնտեքստալ նմանության գնահատականներ իրենց էության թեկնածուների վրա, որոնք օգտակար են և MD-ի, և ED-ի Հիմնական բաղադրիչներն են կոնտեքստի գիտակցությունը նշելու ներդրումները, էության ներդրումները և հավանական նշելը՝ էության քարտեզը, առանց պահանջելու այլ ճարտարագիտական հատկություններ: Իմպերիկապես, մենք ցույց ենք տալիս, որ մեր վերջ-վերջ մեթոդը նշանակալիորեն գերբիլի հարթակի հայտնի համակարգերից դուրս է գալիս, երբ բավարար պատրաստման տվյալներ կան: Ի հակառակ կողմ, եթե տվյալների համակարգերը փորձարկումները հետևում են տարբեր annoտացիոն համակարգերին, համեմատած փորձարկումների համակարգին (օրինակ հարցեր և թվիթեր համեմատած նորությունների փաստաթղթերին), մեր ED մոդելը, միասին ավանդական ՆԵՌ', 'am': 'የጽሑፍ ማስታወቂያ እና የመረጃ ምርጫዎች ማቀናጃ ያስፈልጋል፡፡ የሆኑት ዘዴዎች በተለየ የሆኑት ማሰናከያ (MD) እና የስህተት ግንኙነት (ED) ደረጃዎች (ED) በተለየ የአየር ግንኙነት መጠቀም ሳይሰጥ. በጽሑፍ ሰነድ እና አካላትን በመጠቀም እና በመጠቀም እና በመጠቀም የፊተኛውን የneyሮral መጨረሻ የEL ስርዓት እናሳውቃለን፡፡ የዋነኛው አሳብ የሚችሉትን ሁሉ የቻይና ማስታወቂያ እና የግንኙነት ብጤነት ነጥቦች በሚያስተምሩ አካባቢዎች ላይ የሚጠቅሙትን MD እና ED ማስታወቂያዎች እንዲጠቀሙ ነው፡፡ የቁልፍ ክፍተቶችን የግንኙነት ማወቅ፣ አካባቢ ግንኙነት እና የስልጣን ማውሳት - አካባቢ ካርታ ካርታ፣ ሌሎችን የኢንተርኔት ግንኙነት ሳያስፈልጋቸው፡፡ በመፍታት፣ የፍጻሜ መጨረሻ ሥርዓታችን የጌርቢል መድረክ ላይ የፍጥረት ማህበረሰብ ዳታዎችን በተገኘ ጊዜ በሞላው ሲታወቅ እናሳየዋለን፡፡ በተለይም፣ የዳታተር መስኮቶች በተለየ ትምህርት ክፍተቶችን (ምሳሌ ጠያቂዎች/ Tweets vs. ዜና ሰነድ ሰነዶች) በተለየ፣ የED ሞዴሌያችን ባሕላዊ NER ስርዓት የተሻለ ወይም ሁለተኛ የበለጠ EL እርግጠኛ ያቀርባል፡፡', 'bs': 'Obvezivanje objekata (EL) je ključni zadatak za semantičko razumijevanje teksta i izvlačenje informacija. Narodne metode odvojeno se obraćaju na faze EL-a za detekciju spomenika (MD) i disambigaciju entiteta (ED), bez utjecaja na njihovu zajedničku zavisnost. Ovdje predlažemo prvi nervni sistem koji zajedno otkriva i povezuje entitete u tekstu. Glavna ideja je razmotriti sve moguće mjesta kao potencijalne spominjanje i naučiti kontekstualne rezultate sličnosti nad kandidatima entiteta koji su korisni za odluke MD i ED. Ključni komponenti su kontekstski svjesni spominjanja integracija, integracija entiteta i vjerojatno spominjanja - map a entiteta, bez zahtjeva drugih inženjerenih karakteristika. Empirički, pokazujemo da naša metoda kraja do kraja značajno iznosi popularne sisteme na platformi Gerbil kada su dostupni dovoljno podataka za obuku. U suprotnom, ako testiranje podataka slijedi različite konvencije o annotaciji u usporedbi sa setom obuke (npr. pitanja/ tweets vs novinskim dokumentima), naš ED model zajedno s tradicionalnim sistemom NER nudi najbolju ili drugu najbolju tačnost EL-a.', 'bn': 'সেম্পেন্টিক টেক্সট বুঝতে এবং তথ্য বের করার জন্য এন্টিটি লিঙ্কিং (EL) একটি গুরুত্বপূর্ণ কাজ। জনপ্রিয় পদ্ধতি বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন মেনেন্টিকেশন (এমডি) এবং ইমেনি আমরা এখানে প্রথম নিউরেল শেষ পর্যন্ত ইএল সিস্টেমের প্রস্তাব করছি যা একটি টেক্সট নথিতে বিষয়বস্তুকে একত্রিত আবিষ্কার করে এব প্রধান ধারণা হচ্ছে সকল সম্ভাব্য স্পেন সম্ভাব্য উল্লেখ হিসেবে বিবেচনা করা এবং তাদের বস্তুর প্রার্থীদের বিরুদ্ধে প্রতিযোগিতার সা কী (Key) অংশগ্রহণকারীরা কন্টেক্সট- সচেতনতার উল্লেখ করে, বস্তুর প্রবেশ এবং সম্ভবত একটি উল্লেখ- বস্তুর মানচিত্র, অন্যান্য ইঞ্জিনি সম্মানজনকভাবে আমরা দেখাচ্ছি যে আমাদের শেষ-শেষ-শেষ পদ্ধতি গেরবিল প্ল্যাটফর্মে জনপ্রিয় সিস্টেম প্রকাশ করে যখন যথেষ্ট প্রশিক্ষণ পরীক্ষা করা ডাটাসেট যদি প্রশিক্ষণের সেটের তুলনায় বিভিন্ন বিজ্ঞাপন কনভেন্ট অনুসরণ করে (উদাহরণস্বরূপ প প্রশ্ন/ টুইট বা সংবাদ নথি) আমাদের ইডি মডেল যুক্ত হয়েছে ঐত', 'az': 'Entity Linking (EL) semantik metin anlaşılması və məlumat çıxartması üçün əsas bir işdir. İnsanlı metodlar, bir-birinə bağımlılıq göstərmədən, Mention Detection (MD) və Entity Disambiguation (ED) səviyyələrini ayrı-ayrı EL tərəfindən çəkinirlər. Biz burada ilk nöral sona gələn EL sistemini təbliğ edirik ki, bir mətn dökümündə məlumatları keşfetir və bağlayır. Ana fikir, bütün mümkün mövcud uzaqları mümkün hissələr olaraq istifadə etmək və müxtəlif məsələlər istifadə etmək və həmçinin MD və ED kararları üçün faydalandırmaq üçün istifadə edən məsələlərini öyrənmək idi. Anahtar komponentlər kontekst-bilikli məlumatları, məlumatları və mümkün olaraq məlumatları - məlumatlar haritasıdır, başqa inženjerli fəaliyyətlər istəmədən. İmparatorlıq olaraq, bizim son-son metodumuzun Gerbil platform ündə çox məşhur sistemlərdən çox yüksək göstərir ki, yeterli təhsil verilən məlumatların faydalanır. Dərgahca, əg ər veri qurğuları sınamaq təhsil qurğuları ilə müxtəlif təhsil qurğuları ilə dəyişdirsə (məsələlər, queries/ tweets vs news qurğuları ilə dəyişdirsə), bizim ED modelimiz təhsil edilən NER sistemi ilə birlikdə ən yaxşı və ikinci ən yaxşı EL dəyişdirir.', 'ca': "Entity Linking (EL) és una tasca essencial per a la comprensió semàntica del text i l'extracció d'informació. Els mètodes populars aborden separadament les etapes de la detecció de la menció (MD) i de la desambiguació de l'entitat (ED), sense aprofitar la seva dependència mutua. Aquí proposem el primer sistema neural del final al final EL que descobre i enllaça conjuntament entitats en un document de text. La idea principal és considerar tots els espais possibles com mentions potencials i aprendre puntuacions de similitud contextual sobre els seus candidats d'entitat que són útils tant per a les decisions de MD com d'ED. Els components clau són les integracions de mencions conscients del context, les integracions d'entitats i una menció probabilista - map a d'entitats, sense exigir altres característiques enginyeries. Empiricament, demostram que el nostre mètode final a final supera significativament els sistemes populars de la plataforma Gerbil quan hi ha prou dades d'entrenament disponibles. Per altra banda, si els conjunts de dades de prova segueixen diferents convencions d'anotació comparats amb el conjunt de capacitació (per exemple, preguntes/ tweets vs documents de notícies), el nostre model ED acoplat amb un sistema NER tradicional ofereix la millor o la segona millor precisió EL.", 'cs': 'Entity Linking (EL) je základním úkolem pro porozumění sémantického textu a extrakci informací. Populární metody se samostatně zabývají fází detekcí zmínek (MD) a disambiguací entit (ED), aniž by využívaly jejich vzájemné závislosti. Zde navrhujeme první neuronový end-to-end EL systém, který společně objevuje a propojuje entity v textovém dokumentu. Hlavní myšlenkou je zvážit všechny možné rozpětí jako potenciální zmínky a naučit se kontextové skóre podobnosti u jejich kandidátů entity, které jsou užitečné jak pro MD, tak ED rozhodnutí. Klíčovými komponenty jsou kontextově orientované vložení zmínek, vložení entit a pravděpodobnostní mapa zmínek mezi entitami, aniž by vyžadovaly další inženýrské funkce. Empiricky ukazujeme, že naše end-to-end metoda výrazně překoná populární systémy na platformě Gerbil, pokud je k dispozici dostatek tréninkových dat. Naopak, pokud testovací datové sady dodržují různé anotace ve srovnání se školicí sadou (např. dotazy/ tweety vs zpravodajské dokumenty), náš model ED v kombinaci s tradičním NER systémem nabízí nejlepší nebo druhou nejlepší EL přesnost.', 'fi': 'Entiteettilinkitys (EL) on olennainen tehtävä semanttisen tekstin ymmärtämisessä ja tiedonhankinnassa. Suositut menetelmät käsittelevät erikseen EL:n Mention Detection (MD) ja Entity Disambiguation (ED) -vaiheita hyödyntämättä niiden keskinäistä riippuvuutta. Tässä ehdotamme ensimmäistä neurologista päästä päähän -EL-järjestelmää, joka yhdessä löytää ja linkittää entiteettejä tekstidokumentissa. Pääajatuksena on ottaa kaikki mahdolliset alueet huomioon mahdollisina mainintoina ja oppia kontekstuaalisia samankaltaisuuspisteitä niiden entiteettiehdokkaista, jotka ovat hyödyllisiä sekä MD- että ED-päätöksissä. Tärkeimmät komponentit ovat kontekstitietoinen maininnan upotus, entiteetin upotus ja todennäköisyysmaininnan – entiteetin kartta, ilman muita suunniteltuja ominaisuuksia. Empiirisesti osoitamme, että end-to-end-menetelmämme suoriutuu merkittävästi suosituista järjestelmistä Gerbil-alustalla, kun käytettävissä on riittävästi harjoitusdataa. Toisaalta, jos testausaineistot noudattavat erilaisia annotointikäytäntöjä kuin harjoitusaineistot (esim. kyselyt/twiitit vs. uutisasiakirjat), ED-mallimme yhdistettynä perinteiseen NER-järjestelmään tarjoaa parhaan tai toiseksi parhaan EL-tarkkuuden.', 'et': 'Olendite linkimine (EL) on oluline ülesanne semantilise teksti mõistmiseks ja teabe eraldamiseks. Populaarsed meetodid käsitlevad eraldi EL märkimise tuvastamise (MD) ja olemi disambiguatsiooni (ED) etappe, kasutamata nende vastastikust sõltuvust. Siinkohal pakume välja esimese neurootstarbelise EL-süsteemi, mis ühiselt avastab ja ühendab tekstidokumendis olemeid. Põhieesmärk on kaaluda kõiki võimalikke ulatusi potentsiaalsete mainimistena ja õppida kontekstilise sarnasuse skoorid nende üksuse kandidaatide kohta, mis on kasulikud nii MD kui ED otsuste jaoks. Põhikomponendid on kontekstiteadlikud märkide manustamised, olemi manustamised ja tõenäosuslik mainimine - olemi kaart, nõudmata muid projekteeritud funktsioone. Empiiriliselt näitame, et meie end-to-end meetod ületab oluliselt populaarseid Gerbili platvormi süsteeme, kui on olemas piisavalt treeninguandmeid. Kui testimise andmekogumid järgivad erinevaid annotatsioonitavasid võrreldes koolituskogumiga (nt päringud/säutsud vs uudistedokumendid), pakub meie ED mudel koos traditsioonilise NER-süsteemiga parimat või teist parimat EL-täpsust.', 'jv': 'Entty Linking (el) iku singular task kanggo semanti teks seneng pisan karo extraksi informasi ProgressBarUpdates Awak dhéwé nggunakake sistem sing sampeyan mrah-sampek anyar luwih-sampek anyar tentang karo nganggo kuwi nggawe lan tambah kuwi nggawe dokumen teks Piyambak kenal iku disimbane gambar gak nguasai iki bakal kelangan anyar sampeyan karo mengkar sampeyan contextual Validity Gujaring Ngerti wih-wih, nek ujian dataset sing beraksi perusahaan kelas keleterangan karo nganggep nggawe aturan sing paling nggawe geratan karo nggawe aturan sing perusahaan (adil nambah query/tuet karo keleterangan karo balêr), model sing nggawe ED kuwi nggawe sistem Tradisyonal NeR kang dadi sing paling apik dhéwé, per', 'ha': "@ item: inmenu Text Completion Shiryoyin da aka ƙayyade wajen bayani da shirin Shaidar da aka canza (MD) da Cire Bayanta da Shirin Ayuka (ED) da fassaran EL, idan ba su gaurar da ɗayan ayuka ba. Bu yera, muna buƙata na farkon neural ƙari-zuwa-ƙari na EL da ke haɗi da gane da abubuwa cikin wani takardar rubutu. Maɓani ni'ani kawai, ka yi bincike duk matsayi masu iya amfani da su kamar an ambaci masu yiwuwa da za'a sanar da score masu daidaita a matsayin da suka zama masu amfani da dukansu masu iya amfani da daman MD da ED. Eskilogi na maɓalli sunan faɗin da aka sani game da mazaɓa, da sunayen abun da mai yiwuwa - karwatin abun da ba'a tambayar da wasu zaɓalli wanda aka yi inganci ba. Ina iya amfani da shi, za mu nuna cewa metoden ƙari zuwa ƙarami yana fara tsari mai girma a kan platformn Gerbil idan ana iya amfani da data masu tsari. In da maganar, idan masu jarraba danne-danne za'a bi'anar zane-zane-zane-zane wasu (misali koyaure/ wato-wato versan takardar lãbãri), misalin ED ya sami da wata na'urar na NER na bãyar da tsarin EL na fi kyaun ko na sauki.", 'he': 'קישור יחסים (EL) הוא משימה חיונית להבין טקסט סמנטי ולחפש מידע. שיטות פופולריות מתייחסות באופן נפרד לשלבי גילוי הזיכרון (MD) ושלבי הפרעה של איי.אל, בלי להשתמש בהתלויה הדדית שלהם. אנחנו כאן מציעים את מערכת EL הראשונה סוף-סוף שמגלה ומקשרת יחד יחידות במסמך טקסט. הרעיון העיקרי הוא לשקול את כל המרחקים האפשריים כזיכרונות פוטנציאליים וללמד נקודות דומות קונטקסטיות על מועמדים היחידות שלהם שימושיים גם בהחלטות MD וגם ED. מרכיבים מפתחים הם תוכניות מזכירות קונטקסט, תוכניות ישויות וזכירה סבירה - מפת ישויות, בלי לדרוש תכונות הנדסה אחרות. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available.  Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.', 'sk': 'Povezovanje entitet (EL) je bistvena naloga za semantično razumevanje besedila in pridobivanje informacij. Priljubljene metode ločeno obravnavajo stopnje zaznavanja omenjanja (MD) in razjasnitve entitet (ED) EL, ne da bi izkoristile njihovo medsebojno odvisnost. Predlagamo prvi nevronski sistem EL od konca do konca, ki skupaj odkriva in povezuje entitete v besedilnem dokumentu. Glavna ideja je upoštevati vse možne razpone kot potencialne omembe in se naučiti kontekstualnih podobnih ocen pri kandidatih subjektov, ki so koristni za odločitve MD in ED. Ključne komponente so vgradnje omemb, ki se zavedajo konteksta, vgradnje entitet in verjetnostna omemba - zemljevid entitet, ne da bi zahtevali druge inženirske funkcije. Empirično dokazujemo, da naša metoda od konca do konca znatno presega priljubljene sisteme na platformi Gerbil, ko je na voljo dovolj podatkov o usposabljanju. Nasprotno, če testiranje podatkovnih nizov sledi različnim konvencijam opombe v primerjavi z naborom usposabljanja (npr. poizvedbe/tweeti v primerjavi z novicami), naš ED model skupaj s tradicionalnim NER sistemom zagotavlja najboljšo ali drugo najboljšo točnost EL.', 'bo': 'Entity Linking (EL) is an essential task for semantic text understanding and information extraction. སྔོན་མེད་པའི་ཐབས་ལམ་དེ་འདྲ་ཞིག་པས་འདེམས་རྟོགས་བསམ་བློ་གཏོང་ནི་དང་ཨིན་ཕུད་སྒྲིག་གམ། ང་ཚོས་འདིར་ཡིག་གི་ཡིག་ཆ་ནང་དུ་མཐུན་སྒྲིག་དང་མཐུད་པའི་རྣམ་གྲངས་དང་མཐའ་མཇུག་གི་EL་རིམ རྩ་བའི་བསམ་བློ་གཏད་འདི་ནི་ཆེས་ཤུགས་ཀྱི་སྒོ་སྒྲིག་ཡོངས་ཚད་འཛིན་པའམ་ཚད་ལྟ་བུ་ཞིབ་པ་དང་ཞིབ་འཇུག་སྟངས་ལ་ཕན་ཚུལ་ཆེན་པོ་ཞིག Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. དངོས་འབྲེལ་བྱས་ན། ང་ཚོས་ང་ཚོའི་མཐའ་མཇུག་གི་ཐབས་ལམ་ལུགས་སྐབས་འཛམ་གླིང་གི་འཛམ་གླིང་གི་ལག་ཁྱེར་གྱི་མ་ལག Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.'}
{'en': 'Model Transfer with Explicit Knowledge of the Relation between Class Definitions', 'ar': 'نقل النموذج بمعرفة صريحة للعلاقة بين تعريفات الصنف', 'fr': 'Transfert de modèle avec connaissance explicite de la relation entre les définitions de classe', 'es': 'Transferencia de modelos con conocimiento explícito de la relación entre las definiciones de clase', 'pt': 'Transferência de Modelo com Conhecimento Explícito da Relação entre Definições de Classe', 'ja': 'クラス定義間の関係の明示的な知識を有するモデル転送', 'zh': '明知类定义之形传输', 'hi': 'कक्षा परिभाषाओं के बीच संबंध के स्पष्ट ज्ञान के साथ मॉडल स्थानांतरण', 'ru': 'Передача модели с явным знанием взаимосвязи между определениями классов', 'ga': 'Aistriú Múnla le hEolas Soiléir ar an gCaol idir Sainmhínithe Aicme', 'el': 'Μεταφορά μοντέλου με ρητή γνώση της σχέσης μεταξύ των ορισμών κλάσης', 'hu': 'Modellátvitel az osztályfogalmazások közötti kapcsolat kifejezett ismeretével', 'it': 'Trasferimento di modelli con conoscenza esplicita della relazione tra definizioni di classe', 'ka': 'კლასის განსაზღვრების განსაზღვრებისთვის მოდელური გადატანა', 'lt': 'Model Transfer with Explicit Knowledge of the Relation between Class Definitions', 'mk': 'Пренос на модел со јасно знаење за односот помеѓу дефинициите на класата', 'ml': 'ക്ലാസ് വിശദീകരണങ്ങള്\u200dക്കിടയിലുള്ള ബന്ധത്തിന്റെ എക്സ്പ്ലിക്റ്റ് അറിവുമായി മോഡല്\u200d മാറ്റുക', 'kk': 'Класс анықтамалары арасындағы қатынастың түсінікті мәліметі үлгісін тасымалдау', 'mn': 'Классын тодорхойлолтын хоорондын харилцааны тодорхойлолтой мэдлэгтэй загвар дамжуулах', 'no': 'Name', 'ms': 'Pemindahan Model dengan Pengetahuan Jelas Hubungan antara Definisi Kelas', 'mt': 'Mudell ta’ Trasferiment b’Għarfien Espliċitu tar-Relazzjoni bejn Definizzjonijiet tal-Klassi', 'ro': 'Transfer de model cu cunoștințe explicite despre relația dintre definițiile clasei', 'sr': 'Modelni prijenos sa eksplozivnim znanjem odnosa između definicija klase', 'si': 'Name', 'pl': 'Transfer modeli z wyraźną znajomością relacji między definicjami klas', 'so': 'Ka wareejinta Model with Explicit Ogaanshaha xiriirka fasalka', 'ta': 'வகுப்பு வரையறைப்புகளுக்கிடையில் தொடர்பு தெரியும் மாதிரி மாற்றம்', 'ur': 'کلاس معلومات کے درمیان رابطہ کا مفصل معلومات کے ساتھ مدل انتقال', 'sv': 'Modellöverföring med explicit kunskap om förhållandet mellan klassdefinitioner', 'uz': 'Name', 'vi': 'Mô hình truyền đạt theo khả năng rõ ràng về liên quan giữa quyết định hạng', 'bg': 'Трансфер на модела с изрични познания за връзката между определенията на класовете', 'da': 'Model Transfer med eksplicit viden om forholdet mellem klassefinitioner', 'nl': 'Modeloverdracht met expliciete kennis van de relatie tussen klassendefinities', 'hr': 'Modelni prijenos sa eksplicitnom znanjem odnosa između definicija klase', 'de': 'Modelltransfer mit expliziter Kenntnis des Verhältnisses zwischen Klassendefinitionen', 'ko': '클래스 정의 간의 관계를 명확하게 이해하는 모델 전환', 'id': 'Transfer Model dengan Pengetahuan Jelas Hubungan antara Definisi Kelas', 'fa': 'انتقال مدل با شناسایی مشخص ارتباط بین تعریف کلاس', 'sw': 'Uhamasishaji wa Model kwa ufahamu wa Uhusiano kati ya Tafsiri', 'tr': 'Klas definisyonlary arasyndaky düşünnç bilen nusgala', 'af': 'Name', 'sq': 'Model Transfer with Explicit Knowledge of the Relation between Class Definitions', 'am': 'ምርጫዎች', 'hy': 'Մոդելի փոխանցումը դասարանի սահմանափակումների միջև կապի բացահայտ գիտելիքով', 'bn': 'ক্লাস সংক্রান্ত সংক্রান্ত সংক্রান্ত সম্পর্কের সাথে এক্সপ্লিকিট জ্ঞানের মোডেল পরিবর্তন করুন', 'az': 'SńĪnńĪf Definikl…ôri arasńĪndakńĪ ńįliŇükil…ôrin Explicit Bilgisi il…ô Model Transfer', 'bs': 'Modelni prijenos sa eksplicitnim znanjem odnosa između definicija klase', 'cs': 'Přenos modelu s výslovnou znalostí vztahu mezi definicemi tříd', 'et': 'Mudeliülekanne klassimääratluste vahelise seose selgete teadmistega', 'ca': 'Model Transfer with Explicit Knowledge of the Relation between Class Definitions', 'fi': 'Mallinsiirto ja selkeä tietämys luokkamääritelmien välisestä suhteesta', 'he': 'העברת מודל עם ידע ברור על היחסים בין הגדרות של כיתה', 'sk': 'Prenos modela z eksplicitnim znanjem razmerja med definicijami razredov', 'ha': '@ action', 'jv': 'structural navigation', 'bo': 'དབྱེ་བ་གྲངས་འཛིན་གྱི་འབྲེལ་བ་དང་འཕགས་རིས་སྐྱེལ་འདྲེན་པ'}
{'en': 'This paper investigates learning methods for multi-class classification using labeled data for the target classification scheme and another labeled data for a similar but different classification scheme (support scheme). We show that if we have prior knowledge about the relation between support and target classification schemes in the form of a class correspondence table, we can use it to improve the model performance further than the simple multi-task learning approach. Instead of learning the individual classification layers for the support and target schemes, the proposed method converts the class label of each example on the support scheme into a set of candidate class labels on the target scheme via the class correspondence table, and then uses the candidate labels to learn the classification layer for the target scheme. We evaluate the proposed ', 'ar': 'تبحث هذه الورقة في طرق التعلم الخاصة بالتصنيف متعدد الفئات باستخدام البيانات المسمى لمخطط التصنيف المستهدف وبيانات أخرى معنونة لنظام تصنيف مشابه ولكنه مختلف (مخطط الدعم). نوضح أنه إذا كانت لدينا معرفة مسبقة بالعلاقة بين مخططات الدعم والتصنيف المستهدف في شكل جدول مراسلات الفصل ، فيمكننا استخدامه لتحسين أداء النموذج بشكل أكبر من نهج التعلم البسيط متعدد المهام. بدلاً من تعلم طبقات التصنيف الفردية لمخططات الدعم والهدف ، تقوم الطريقة المقترحة بتحويل تسمية الفصل لكل مثال على مخطط الدعم إلى مجموعة من تسميات فئة المرشح على المخطط الهدف عبر جدول مراسلات الفصل ، ثم تستخدم المرشح تسميات لمعرفة طبقة التصنيف للمخطط الهدف. نقوم بتقييم الطريقة المقترحة في مهمتين في البرمجة اللغوية العصبية. تظهر النتائج التجريبية أن طريقتنا تتعلم بشكل فعال المخططات المستهدفة خاصة للفئات التي لها اتصال وثيق بفئات دعم معينة.', 'es': 'Este artículo investiga los métodos de aprendizaje para la clasificación de múltiples clases utilizando datos etiquetados para el esquema de clasificación objetivo y otros datos etiquetados para un esquema de clasificación similar pero diferente (esquema de apoyo). Demostramos que si tenemos conocimiento previo sobre la relación entre los esquemas de clasificación de objetivos y de soporte en forma de tabla de correspondencia de clases, podemos utilizarla para mejorar el rendimiento del modelo más que el simple enfoque de aprendizaje multitarea. En lugar de aprender las capas de clasificación individuales para los esquemas de soporte y objetivo, el método propuesto convierte la etiqueta de clase de cada ejemplo del esquema de soporte en un conjunto de etiquetas de clase candidata en el esquema de destino a través de la tabla de correspondencia de clases y, a continuación, utiliza las etiquetas de candidatos para aprender la capa de clasificación del esquema de destino. Evaluamos el método propuesto en dos tareas en PNL. Los resultados experimentales muestran que nuestro método aprende eficazmente los esquemas objetivo, especialmente para las clases que tienen una estrecha conexión con ciertas clases de apoyo.', 'pt': 'Este artigo investiga métodos de aprendizado para classificação multiclasse usando dados rotulados para o esquema de classificação de destino e outros dados rotulados para um esquema de classificação semelhante, mas diferente (esquema de suporte). Mostramos que se tivermos conhecimento prévio sobre a relação entre os esquemas de classificação de suporte e alvo na forma de uma tabela de correspondência de classe, podemos usá-lo para melhorar o desempenho do modelo além da abordagem simples de aprendizado multitarefa. Em vez de aprender as camadas de classificação individuais para os esquemas de suporte e destino, o método proposto converte o rótulo de classe de cada exemplo no esquema de suporte em um conjunto de rótulos de classe candidatos no esquema de destino por meio da tabela de correspondência de classe e, em seguida, usa o rótulo de classe candidato rótulos para aprender a camada de classificação para o esquema de destino. Avaliamos o método proposto em duas tarefas em PNL. Os resultados experimentais mostram que nosso método aprende efetivamente os esquemas de destino, especialmente para as classes que têm uma conexão estreita com determinadas classes de suporte.', 'fr': "Cet article étudie les méthodes d'apprentissage pour la classification multi-classes en utilisant des données étiquetées pour le schéma de classification cible et d'autres données étiquetées pour un schéma de classification similaire mais différent (schéma de support). Nous montrons que si nous avons une connaissance préalable de la relation entre le support et les systèmes de classification cible sous la forme d'une table de correspondance de classe, nous pouvons l'utiliser pour améliorer les performances du modèle au-delà de la simple approche d'apprentissage multitâche. Au lieu d'apprendre les couches de classification individuelles pour les programmes de soutien et cibles, le procédé proposé convertit l'étiquette de classe de chaque exemple du schéma de soutien en un ensemble d'étiquettes de classe candidates sur le schéma cible via la table de correspondance de classe, puis utilise les étiquettes candidates pour apprendre la couche de classification pour le schéma cible. Nous évaluons la méthode proposée sur deux tâches en PNL. Les résultats expérimentaux montrent que notre méthode apprend efficacement les programmes cibles, en particulier pour les classes qui ont un lien étroit avec certaines classes de soutien.", 'ja': '本論文では，対象分類スキームのラベル付きデータと類似しているが異なる分類スキーム（サポートスキーム）の別のラベル付きデータを用いて，マルチクラス分類のための学習方法を検討した。 クラス対応表の形でサポートとターゲット分類スキームの関係について事前に知識があれば、単純なマルチタスク学習アプローチよりもモデルのパフォーマンスを向上させることができることを示している。 提案された方法は、サポートスキーム及びターゲットスキームの個々の分類層を学習する代わりに、サポートスキーム上の各例のクラスラベルを、クラス対応テーブルを介してターゲットスキーム上の候補クラスラベルのセットに変換し、次いで候補ラベルを使用してターゲットスキームの分類層を学習する。 NLPの2つのタスクについて提案された方法を評価します。 実験結果は、特に特定のサポートクラスと緊密につながっているクラスのために、私たちの方法がターゲットスキームを効果的に学習することを示しています。', 'zh': '本文究多类分类之学,用标数为的分类方案,另一标记数用相似而不同者(支方案)。 吾以类有先验知,可使进一步提高形,非多任务学也。 其法以类应表将主方案者,每示例之类转换为的方案上一组候选类标签,不是学支方案的各类,然后用候选标签来学习方案的分类图层。 论于NLP之二务。 实验结果表明,有效于学,尤有关于支类者。', 'hi': 'यह पेपर लक्ष्य वर्गीकरण योजना के लिए लेबल किए गए डेटा का उपयोग करके बहु-वर्ग वर्गीकरण के लिए सीखने के तरीकों की जांच करता है और एक समान लेकिन अलग वर्गीकरण योजना (समर्थन योजना) के लिए एक और लेबल किए गए डेटा की जांच करता है। हम दिखाते हैं कि यदि हमारे पास कक्षा पत्राचार तालिका के रूप में समर्थन और लक्ष्य वर्गीकरण योजनाओं के बीच संबंध के बारे में पूर्व ज्ञान है, तो हम इसका उपयोग सरल बहु-कार्य सीखने के दृष्टिकोण की तुलना में मॉडल प्रदर्शन में सुधार करने के लिए कर सकते हैं। समर्थन और लक्ष्य योजनाओं के लिए व्यक्तिगत वर्गीकरण परतों को सीखने के बजाय, प्रस्तावित विधि समर्थन योजना पर प्रत्येक उदाहरण के वर्ग लेबल को कक्षा पत्राचार तालिका के माध्यम से लक्ष्य योजना पर उम्मीदवार वर्ग लेबल के सेट में परिवर्तित करती है, और फिर लक्ष्य योजना के लिए वर्गीकरण परत सीखने के लिए उम्मीदवार लेबल का उपयोग करती है। हम एनएलपी में दो कार्यों पर प्रस्तावित विधि का मूल्यांकन करते हैं। प्रयोगात्मक परिणामों से पता चलता है कि हमारी विधि प्रभावी रूप से लक्ष्य योजनाओं को सीखती है, विशेष रूप से उन कक्षाओं के लिए जिनके पास कुछ समर्थन वर्गों के लिए एक तंग कनेक्शन है।', 'ru': 'В настоящем документе изучаются методы обучения для многоклассовой классификации с использованием маркированных данных для целевой схемы классификации и других маркированных данных для аналогичной, но другой схемы классификации (вспомогательной схемы). Показано, что если у нас есть предварительные знания о связи между схемами поддержки и целевой классификацией в виде таблицы соответствия классов, мы можем использовать их для улучшения эффективности модели дальше, чем простой многозадачный подход к обучению. Вместо изучения отдельных уровней классификации для схем поддержки и целевых схем, предлагаемый метод преобразует метку класса каждого примера на схеме поддержки в набор меток классов-кандидатов на целевой схеме через таблицу соответствия классов, а затем использует метки-кандидаты для изучения уровня классификации для целевой схемы. Мы оцениваем предлагаемый метод по двум задачам в NLP. Экспериментальные результаты показывают, что наш метод эффективно изучает целевые схемы, особенно для классов, которые имеют тесную связь с определенными классами поддержки.', 'ga': 'Imscrúdaíonn an páipéar seo modhanna foghlama le haghaidh aicmiú ilranga ag baint úsáide as sonraí lipéadaithe don scéim sprioc-aicmithe agus sonraí lipéadaithe eile do scéim aicmithe comhchosúil ach éagsúil (scéim tacaíochta). Léirímid má tá réamheolas againn ar an ngaol idir scéimeanna tacaíochta agus sprioc-aicmithe i bhfoirm tábla comhfhreagrais ranga, gur féidir linn é a úsáid chun feidhmíocht na samhla a fheabhsú níos faide ná an cur chuige simplí foghlama il-tasc. In ionad na sraitheanna aonair aicmithe a fhoghlaim do na scéimeanna tacaíochta agus sprice, déanann an modh molta lipéad ranga gach sampla ar an scéim tacaíochta a thiontú ina thacar de lipéid ranga iarrthóra ar an spriocscéim tríd an tábla comhfhreagrais ranga, agus ansin úsáideann an t-iarrthóir. lipéid chun ciseal aicmithe na sprice a fhoghlaim. Déanaimid measúnú ar an modh atá beartaithe ar dhá thasc sa NLP. Léiríonn torthaí na dturgnamh go bhfoghlaimíonn ár modh na spriocscéimeanna go héifeachtach go háirithe do na ranganna a bhfuil ceangal daingean acu le ranganna tacaíochta áirithe.', 'hu': 'Jelen tanulmány a többosztályos osztályozás tanulási módszereit vizsgálja a célosztályozási rendszer címkézett adataival és egy hasonló, de eltérő osztályozási rendszer címkézett adataival (támogatási rendszer). Megmutatjuk, hogy ha előzetes ismeretekkel rendelkezünk a támogatási és célosztályozási rendszerek kapcsolatáról osztály levelezési táblázat formájában, akkor azt az egyszerű többfeladatos tanulási megközelítés mellett tovább tudjuk javítani a modell teljesítményét. A támogatási és célrendszerek egyes osztályozási rétegeinek elsajátítása helyett a javasolt módszer a támogatási rendszerben szereplő egyes példák osztálycímkéjét a célrendszerben szereplő jelöltcímkék sorozatává alakítja át, majd a jelöltcímkéket használja a célrendszer osztályozási rétegének elsajátítására. A javasolt módszert két feladatra értékeljük az NLP-ben. A kísérleti eredmények azt mutatják, hogy módszerünk hatékonyan megtanulja a célrendszereket, különösen azon osztályok esetében, amelyek szorosan kapcsolódnak bizonyos támogatási osztályokhoz.', 'ka': 'ამ დოკუფიკაციის განსხვავება მრავალკლასის კლასიფიკაციის მეტოვების გამოყენება მართლა კლასიფიკაციის სქემისთვის და სხვა მართლა კლასიფიკაციის სქემისთვისთვის მართლა ჩვენ ჩვენ აჩვენებთ, რომ თუ გვაქვს წინასწარმოადგილი ცნობიერება, რომელიც კლასის კონსპორტენციის მაგილის ფორმაში მივიღეთ კონსპორტენციის სქემების შესახებ და მივიღეთ კონსპორტენციის განსაზღვრებული კლასიფიკაციის ჩატვირთვის და მიზეზი ქემებისთვის გასწავლების ნაცვლად, მიზეზი სქემების კლასის ჩატვირთვის კლასიფიკაციის ჩატვირთვის ჩატვირთვის კლასიფიკაციის ჩატვირთვის კლასიფიკაციის ჩატვირთვის ჩვენ NLP-ში ორი სამუშაო დავამუშაობით გავამუშაობით მინდომის მეტი. ექსპერიმენტიური წარმოდგენები აჩვენებს, რომ ჩვენი მეტი ეფექტიურად სწავლის მიზეზი სქემების განსაკუთრებით კლასებისთვის, რომლებიც კონფიგურაციას', 'el': 'Η παρούσα εργασία διερευνά μεθόδους εκμάθησης για την ταξινόμηση πολλαπλών τάξεων χρησιμοποιώντας επισημασμένα δεδομένα για το σύστημα ταξινόμησης στόχων και άλλα επισημασμένα δεδομένα για ένα παρόμοιο αλλά διαφορετικό σύστημα ταξινόμησης (σύστημα υποστήριξης). Δείχνουμε ότι αν έχουμε προηγούμενες γνώσεις σχετικά με τη σχέση μεταξύ συστημάτων υποστήριξης και στοχευμένης ταξινόμησης με τη μορφή πίνακα αντιστοιχίας τάξεων, μπορούμε να το χρησιμοποιήσουμε για να βελτιώσουμε την απόδοση του μοντέλου πέρα από την απλή προσέγγιση εκμάθησης πολλαπλών εργασιών. Αντί να μάθει τα μεμονωμένα στρώματα ταξινόμησης για τα συστήματα υποστήριξης και στόχου, η προτεινόμενη μέθοδος μετατρέπει την ετικέτα κλάσης κάθε παραδείγματος στο σύστημα υποστήριξης σε ένα σύνολο ετικετών υποψήφιων κλάσεων στο σύστημα προορισμού μέσω του πίνακα αντιστοιχίας κλάσης και στη συνέχεια χρησιμοποιεί τις ετικέτες υποψήφιων για να μάθει το επίπεδο ταξινόμησης για το σύστημα προορισμού. Αξιολογούμε την προτεινόμενη μέθοδο σε δύο εργασίες στο ΝΛΠ. Τα πειραματικά αποτελέσματα δείχνουν ότι η μέθοδος μας μαθαίνει αποτελεσματικά τα στοχευμένα σχήματα ειδικά για τις τάξεις που έχουν στενή σύνδεση με ορισμένες κατηγορίες στήριξης.', 'it': "Questo articolo indaga i metodi di apprendimento per la classificazione multi-classe utilizzando dati etichettati per lo schema di classificazione target e altri dati etichettati per uno schema di classificazione simile ma diverso (schema di supporto). Dimostriamo che se abbiamo una conoscenza preliminare della relazione tra schemi di supporto e classificazione target sotto forma di una tabella di corrispondenza di classe, possiamo utilizzarla per migliorare le prestazioni del modello oltre al semplice approccio di apprendimento multi-task. Invece di imparare i singoli livelli di classificazione per gli schemi di supporto e di destinazione, il metodo proposto converte l'etichetta di classe di ciascun esempio sullo schema di supporto in un insieme di etichette di classe candidate sullo schema di destinazione tramite la tabella di corrispondenza della classe, e quindi utilizza le etichette candidate per imparare il livello di classificazione per lo schema di destinazione. Valutiamo il metodo proposto su due compiti nel PNL. I risultati sperimentali dimostrano che il nostro metodo apprende efficacemente gli schemi target soprattutto per le classi che hanno una stretta connessione con determinate classi di supporto.", 'lt': 'This paper investigates learning methods for multi-class classification using labeled data for the target classification scheme and another labeled data for a similar but different classification scheme (support scheme).  Mes rodome, kad jei turime išankstinių žinių apie paramos ir tikslinių klasifikavimo sistemų santykį klasės korespondencijos lentelės form a, galime ją naudoti modelio veiklos rezultatams gerinti toliau nei paprastas daugiafunkcinis mokymosi metodas. Užuot išmokę atskirus klasifikavimo sluoksnius paramos ir tikslinėms schemoms, siūlomu metodu kiekvieno paramos schemos pavyzdžio klasės etiketė paverčiama tikslinės schemos kandidatų klasės etiketėmis pagal klasės korespondencijų lentelę, o paskui naudojamos kandidatų etiketės tikslinės schemos klasifikavimo sluoksniui išmokti. We evaluate the proposed method on two tasks in NLP.  Eksperimentiniai rezultatai rodo, kad mūsų metodas veiksmingai išmoko tikslines sistemas, ypač klasėms, kurios yra glaudžiai susijusios su tam tikromis paramos klasėmis.', 'ms': 'Kertas ini menyelidiki kaedah belajar untuk klasifikasi kelas berbilang menggunakan data labeled untuk skema klasifikasi sasaran dan data labeled lain untuk skema klasifikasi yang sama tetapi berbeza (skema sokongan). Kami menunjukkan bahawa jika kita mempunyai pengetahuan sebelumnya mengenai hubungan antara sokongan dan skema kelasukan sasaran dalam bentuk jadual korespondenci kelas, kita boleh menggunakannya untuk meningkatkan prestasi model lebih jauh daripada pendekatan pembelajaran multi-tugas sederhana. Daripada belajar lapisan klasifikasi individu untuk skema sokongan dan sasaran, kaedah yang diusulkan mengubah label kelas setiap contoh pada skema sokongan ke set label kelas calon pada skema sasaran melalui jadual korespondenci kelas, dan kemudian menggunakan label calon untuk belajar lapisan klasifikasi untuk skema sasaran. Kami menilai kaedah yang diusulkan pada dua tugas di NLP. Hasil percubaan menunjukkan bahawa kaedah kita secara efektif mempelajari skema sasaran terutama untuk kelas yang mempunyai sambungan ketat dengan kelas sokongan tertentu.', 'kk': 'Бұл қағаз бірнеше класс класс классификациясының оқыту әдістерін, мақсатты классификациялау сұлбасының жарлық деректерін және бірнеше бірнеше класс сұлбасының жарлық мә Егер біз класс сәйкестік кестесінің түрінде қолдау мен мақсаттау сұлбаларының қатынасын алдындағы білім бар болса, оны қарапайым көп тапсырманың оқыту көмегінен артық үлгілерді жақсарту үшін Қолдау және мақсатты сұлбалар үшін бөлек шектеу қабаттарды оқыту орнына, келтірілген әрбір мысал сұлбаның клас жарлығын мақсатты сұлбаның клас жарлығының қолдау сұлбасында қандайды клас сұлбасының кестесімен аударып, кей Біз NLP-де екі тапсырма туралы ұсынған әдісті бағалаймыз. Тәжірибелі нәтижелер біздің әдіміміз мақсатты сұлбаларды оқытып береді, осылақ кейбір қолдау класстарымен қатты байланысты класстар үшін.', 'ml': 'ലക്ഷ്യം ക്ലാസ്ഫിക്ക് പദ്ധതിക്കുള്ള ലേബെല്\u200dഡ് ഉപയോഗിച്ച് പല-ക്ലാസ്സില്\u200d ക്ലാസ്ഫിക്കല്\u200d ഉപയോഗിച്ച് പഠിക്കുന്ന രീതികള്\u200d പരിശോധ ഞങ്ങള്\u200d കാണിച്ചു കൊടുക്കുന്നുണ്ടെങ്കില്\u200d പിന്തുണയ്ക്കുന്നതിനെക്കുറിച്ചും ലക്ഷ്യത്തിന്റെ പരിചയത്തെക്കുറിച്ചും മുമ്പ് അറിവുണ്ടെങ്കില പിന്തുണയ്ക്കും ലക്ഷ്യ പദ്ധതിയ്ക്കും വേണ്ടി വ്യക്തിപരമാക്കുന്ന തടാകങ്ങള്\u200d പഠിക്കാന്\u200d പകരം, പ്രൊദ്ദേശിച്ച രീതിയില്\u200d, പിന്തുണയ്ക്കുന്ന പദ്ധതിയില്\u200d ഓരോ ഉദാഹരണത്തിന്റെയും ലേബിള്\u200d  നമ്മള്\u200d നിര്\u200dദേശിച്ച രണ്ട് ജോലികളുടെ രീതിയില്\u200d വിലയിക്കുന്നു. പരീക്ഷണത്തിന്റെ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ രീതിയില്\u200d പ്രത്യേകിച്ച് ലക്ഷ്യം പഠിക്കുന്നത് പ്രത്', 'mt': 'Dan id-dokument jinvestiga metodi ta’ tagħlim għall-klassifikazzjoni ta’ diversi klassijiet bl-użu ta’ dejta ttikkettata għall-iskema ta’ klassifikazzjoni fil-mira u dejta ttikkettata oħra għal skema ta’ klassifikazzjoni simili iżda differenti (skema ta’ appoġġ). Aħna nuru li jekk għandna għarfien minn qabel dwar ir-relazzjoni bejn l-iskemi ta’ appoġġ u l-klassifikazzjoni fil-mira fil-form a ta’ tabella ta’ korrispondenza tal-klassi, nistgħu nużaw din biex itejbu l-prestazzjoni tal-mudell aktar mill-approċċ sempliċi ta’ tagħlim b’diversi kompiti. Minflok ma jitgħallmu s-saffi ta’ klassifikazzjoni individwali għall-iskemi ta’ appoġġ u mmirati, il-metodu propost jikkonverti t-tikketta tal-klassi ta’ kull eżempju fuq l-iskema ta’ appoġġ f’sett ta’ tikketti tal-klassi kandidata fuq l-iskema ta’ mira permezz tat-tabella ta’ korrispondenza tal-klassi, u mbagħad juża t-tikketti kandidati biex jitgħallmu s-saf Nivvalutaw il-metodu propost dwar żewġ kompiti fil-NLP. Ir-riżultati sperimentali juru li l-metodu tagħna effettivament jitgħallem l-iskemi fil-mira speċjalment għall-klassijiet li għandhom konnessjoni stretta ma’ ċerti klassijiet ta’ appoġġ.', 'mk': 'Овој документ ги испитува методите на учење за мултикласификација користејќи обележани податоци за шемата на класификација на целта и други обележани податоци за слична, но различна, класификациска шема (поддршка шема). Ние покажуваме дека ако имаме претходно знаење за односот помеѓу поддршката и шемите за класификација на целите во форма на табела за класична кореспонденција, можеме да ја искористиме за подобрување на моделот на резултатите понатаму отколку едноставниот пристап на учење со Наместо да ги научи индивидуалните слоеви на класификација за поддршката и шемите на целта, предложениот метод ја конвертира класификацијата на секој пример на шемата на поддршка во сет на кандидатски класификации на шемата на целта преку табелата за класификација, а потоа ги користи кандидатските табели за научи класи Го проценуваме предложениот метод за две задачи во НЛП. Експерименталните резултати покажуваат дека нашиот метод ефикасно ги научи целните шеми особено за класите кои имаат тесна врска со одредени класи на поддршка.', 'ro': 'Această lucrare investighează metodele de învățare pentru clasificarea mai multor clase utilizând date etichetate pentru schema de clasificare țintă și alte date etichetate pentru o schemă de clasificare similară, dar diferită (schema de sprijin). Aratăm că dacă avem cunoștințe prealabile despre relația dintre schemele de suport și clasificare țintă sub forma unui tabel de corespondență de clasă, îl putem folosi pentru a îmbunătăți performanța modelului mai mult decât abordarea simplă de învățare multi-sarcină. În loc să învețe straturile individuale de clasificare pentru schemele de sprijin și țintă, metoda propusă convertește eticheta clasei fiecărui exemplu din schema de sprijin într-un set de etichete clasei candidate pe schema țintă prin intermediul tabelului de corespondență a clasei și apoi utilizează etichetele candidate pentru a afla stratul de clasificare pentru schema țintă. Evaluăm metoda propusă pe două sarcini în PNL. Rezultatele experimentale arată că metoda noastră învață eficient schemele țintă în special pentru clasele care au o conexiune strânsă la anumite clase de suport.', 'mn': 'Энэ цаас нь олон класс ангилалын суралцах аргыг судалдаг. Загварын ангилалын схемийн жагсаалттай өгөгдлийг ашиглаж, мөн адилхан ч өөр ангилалын схемийн жагсаалттай өгөгдлийг ашигладаг. Хэрвээ бидэнд дэмжлэх болон зорилготой хуваалцах схемийн хоорондын харилцааны тухай өмнө мэдлэг байвал бид үүнийг хичээл холбоотой хүснэгтийн хэлбэрээр ашиглаж болно. Бид үүнийг загварын үйл ажиллагааг олон ажил сура Хэрэв дэмжих болон зорилготой схемүүдийн тусламжтайгаар хуваалцах загварыг сурахын оронд, санал өгсөн арга нь жишээ бүрийн классын загварын загварын загварын загварын загварын загварын загварын загварын загварын загварын загварын загварын загварын загварын загварын за Бид NLP-ийн хоёр даалгаварын талаар санал өгсөн аргыг үнэлдэг. Үүний туршилтын үр дүнд бидний арга нь зарим дэмжлэх хичээлийн холбоотой хичээлийн зорилготой схемүүдийг эффективно суралцаж байна.', 'sr': 'Ovaj papir istražuje metode učenja za klasifikaciju više klasa koristeći označene podatke za ciljnu klasifikaciju i druge označene podatke za sličnu ali različitu klasifikaciju (šemu podrške). Pokazujemo da ako imamo ranije znanje o vezi između schema podrške i ciljne klasifikacije u obliku stola klasične dopisnice, možemo ga iskoristiti da poboljšamo model izvršnost više od jednostavnog pristupa multi task učenja. Umesto da uče individualne klasifikacijske slojeve za podršku i ciljne šeme, predložena metoda pretvara etiketu klase svakog primjera na šemu podrške u setu etiketa klase kandidata na ciljnoj šemi kroz tablu predstave klase, a zatim koristi etikete kandidata kako bi naučili klasifikacijski sloj za ciljnu šemu. Procjenjujemo predloženu metodu o dva zadatka u NLP-u. Eksperimentalni rezultati pokazuju da naša metoda uči metne šeme posebno za časove koje imaju tešku vezu sa određenim časovima podrške.', 'no': 'Denne papiret undersøker læringsmetodar for multiklassesklassifikasjon med merkelige data for målklassifikasjonskoma og andre merkelige data for ein liknande, men ulike klassifikasjonskoma (støtte skjema). Vi viser at dersom vi har førre kunnskap om forholdet mellom støtte og målklassifikasjonsskema i form av ei klassisk korespondenctabell, kan vi bruka det for å forbetra modellen for utviklinga meir enn den enkle fleire oppgåver læringstilnærming. I staden for å lære individuelle klassifikasjonslag for støtte og målskjema, vil den foreslåde metoden konvertera klassifikasjonslaget for kvar eksempel på støtteoppsettet til eit sett av kandidatklassifikasjonslag på målskjema gjennom klassifikasjonstabelen, og så bruker kandidatetiketta for å lære klassifikasjonslaget for målskjema. Vi evaluerer den foreslåde metoden på to oppgåver i NLP. Eksperimentale resultatet viser at metoden vårt lærer målklassene spesielt for klassene som har ein sterk tilkopling til nokre støtteklasser.', 'pl': 'W artykule zbadano metody uczenia się klasyfikacji wieloklasowej z wykorzystaniem etykietowanych danych dla docelowego schematu klasyfikacji oraz innych etykietowanych danych dla podobnego, ale różnego schematu klasyfikacji (schematu wsparcia). Pokazujemy, że jeśli posiadamy wcześniejszą wiedzę na temat związku pomiędzy systemami klasyfikacji wsparcia i docelowej w formie tabeli korespondencji klas, możemy ją wykorzystać do poprawy wydajności modelu dalej niż proste podejście do wielozadaniowego uczenia się. Zamiast uczyć się poszczególnych warstw klasyfikacji dla schematów wsparcia i docelowych, proponowana metoda konwertuje etykietę klas każdego przykładu w schemacie wsparcia na zestaw etykiet klas kandydatów w schemacie docelowym za pośrednictwem tabeli korespondencji klas, a następnie używa etykiet kandydatów do nauki warstwy klasyfikacji dla schematu docelowego. Oceniamy proponowaną metodę na dwóch zadaniach w NLP. Wyniki eksperymentalne pokazują, że nasza metoda skutecznie uczy się docelowych schematów szczególnie dla klas, które mają ścisłe powiązanie z określonymi klasami wsparcia.', 'si': 'Name අපි පෙන්වන්නම් අපිට ප්\u200dරධානය සහ ඉලක්කම් පරීක්ෂණා පරීක්ෂණා පරීක්ෂණයක් වලින් සම්බන්ධයක් තියෙනවා නම්, අපිට ප්\u200dරධානය සම්බන්ධ සහය සහ ලක්ෂණ පද්ධතිය සඳහා ප්\u200dරතිකෘති පද්ධති පද්ධති පද්ධතිය සඳහා ප්\u200dරතිකෘති පද්ධතිය පද්ධතිය පද්ධතියේ පද්ධතිය පද්ධතියේ පද්ධතිය පද්ධතිය පද්ධතියේ  අපි NLP වල ප්\u200dරතිචාරණ විධානය අවශ්\u200dය කරන්නේ. පරීක්ෂණයේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ විදියට අවස්ථාවක් විශේෂයෙන් ලක්ෂණ පරීක්ෂණය ඉගෙන ගන', 'sv': 'Denna uppsats undersöker inlärningsmetoder för flerklassklassificering med hjälp av märkta data för målklassificeringssystemet och andra märkta data för ett liknande men annorlunda klassificeringssystem (stödsystem). Vi visar att om vi har förkunskaper om relationen mellan stöd och målklassificeringsscheman i form av en klasskorrespondenstabell kan vi använda den för att förbättra modellprestandan ytterligare än den enkla multi-task inlärningsmetoden. Istället för att lära sig de enskilda klassificeringsskikten för stöd- och målscheman omvandlar den föreslagna metoden klassetiketten för varje exempel i stödsystemet till en uppsättning klassetiketter på målscheman via klasskorrespondenstabellen och använder sedan kandidatetiketterna för att lära sig klassificeringsskiktet för målscheman. Vi utvärderar den föreslagna metoden på två uppgifter i NLP. De experimentella resultaten visar att vår metod effektivt lär sig målscheman speciellt för de klasser som har en nära koppling till vissa stödklasser.', 'ur': 'This paper investigates learning methods for multi-class classification using labeled data for the target classification scheme and another labeled data for a similar but different classification scheme (support scheme). ہم نشان دیتے ہیں کہ اگر ہمارے پاس پہلے سے علم ہے کہ مدد اور تابع کلاسپی سیکٹ کے درمیان رابطہ ہے تو ہم اسے کلاسپینٹ ٹیبل کے شکل میں استعمال کر سکتے ہیں کہ موڈل کی عملکرد اس سے زیادہ ساده multi-task سیکٹ کی طریقہ سے زیادہ استعمال کریں۔ حمایت اور موجود سکیموں کے لئے فرقہ فرقہ لہروں کو سیکھنے کے بدلے، پیشنهاد کی طریقہ ہر مثال کے کلاس لہروں کو مدد سکیموں پر موجود کلاس لہروں کے مجموعہ میں موجود لہروں کی سیٹ میں تبدیل کرتا ہے، اور پھر موجود لہروں کے ذریعہ کاندیٹ لہروں کو استعمال کرتا ہے تابع ہم NLP میں دو کاموں پر پیشنهاد کی طریقہ کا ارزش کرتے ہیں. آزمائش نتائج دکھاتے ہیں کہ ہمارا طریقہ عمدہ طور پر موجود طریقوں کو سکھاتا ہے مخصوصاً کلاس کے لئے جو کچھ مدد کلاس کے ساتھ سخت تعلق رکھتے ہیں۔', 'so': 'Kanu wuxuu baaraandegaa qaababka barashada fasalka kala duduwan, kaasoo lagu isticmaalaa macluumaad la xiriira qorshaha fasalka ee loogu talagalay iyo macluumaad kale oo lagu qoray qorshaha fasalka kala duduwan ee la mid ah ee la mid dhigay (qorshaha kaalmada). Waxaynu muujinnaa, haddii aynu hayno aqoon horay ah oo ku saabsan xiriirka kaalmada iyo qorshaha fasalka, nooca oo ah miiska wax u dhigista fasalka, waxaynu u isticmaali karnaa si aynu u u hagaajinno tababarka muusikada oo ka sii kordhin karno qaababka waxbarashada ee fudud. Taariikhda fasalka gaarka ah ee loo baranayo qorshaha kaalmada iyo qorshaha hagitaanka, qaababka la soo jeeday ayaa qorshaha kaalmada ku beddelinaya calaamadda fasalka, wuxuuna u beddeliyaa qorshaha waxqabadka kandidada ku qoran qorshaha waxqabadka, sidoo kale wuxuu u isticmaalaa calaamada wax lagu baranayo qorshaha waxqabadka. We evaluate the proposed method on two tasks in NLP.  Imtixaanka waxaa ka muuqda in qaababkayagu uu si fiican u barto qorshaha waxqabadka, si gaar ah fasalka ay ku xiriiraan fasalka taageerada qaarkood.', 'ta': 'இந்த தாள் பல வகுப்பு வகுப்பு வகுப்புகளுக்கான கற்றல் முறைமைகளை சோதிக்கிறது இலக்கு வகுப்பு வகுப்பு முறைமைக்கு மற்றும் மற்றொரு அடையாளம் தரவுகள நாம் காண்பிக்கிறோம் ஒரு வகுப்பு சார்ந்த அட்டவணையின் வடிவத்தில் ஆதரவு மற்றும் வகுப்பு வகுப்பு முறைமையில் தொடர்பு பற்றி முன்னால் அறிவு இருந்தால ஆதரவு மற்றும் இலக்கு முறைமைக்கான தனிப்பட்ட வகுப்பு அடுக்குகளை கற்றுக் கொள்வதற்கு பதிலாக, பரிந்துரைக்கப்பட்ட முறைமையாக, ஆதரவு முறைமையில் ஒவ்வொரு உதாரணத்தின் வகுப்பு விளக்கச்சீட்டை ச நாம் NLP-ல் இரண்டு பணிகளில் முன்னோக்கப்பட்ட முறையை மதிப்பிடுகிறோம். சோதனை முடிவு', 'uz': "This paper investigates learning methods for multi-class classification using labeled data for the target classification scheme and another labeled data for a similar but different classification scheme (support scheme).  Biz buni ko'rsatishimiz mumkin, agar bizda birinchi oldin qoʻllash va qanday darajadagi darajadagi murojaat darajada bog'liq maʼlumot bo'lsa, biz buni bir necha vazifa o'rganish muvaffaqiyatlaridan foydalanishimiz mumkin. Name Biz NLP'da ikkita vazifalarni qiymatimiz. Tasavvur natijalari shunday ko'rsatadi, bizning usuli foydalanuvchi qoliplarni ishlatadi, hususan bir necha qoʻllanmalar sinfga bogʻ'langan sinflari uchun juda qisqa.", 'vi': 'Tờ giấy này nghiên cứu các phương pháp học về phân hạng đa, sử dụng các dữ liệu được đánh dấu cho chế độ phân hạng mục đích và một dữ liệu khác được đánh dấu cho một chế độ phân hạng tương tự nhưng khác nhau (bộ hỗ trợ). Chúng tôi cho thấy nếu chúng tôi có thông tin về mối quan hệ giữa các quy trình phân bổ hỗ trợ và các mục tiêu dưới hình thức một cái bảng thư ký hạng nhất, chúng tôi có thể sử dụng nó để nâng cao khả năng của mô hình hơn phương thức học tập đa nhiệm đơn giản. Thay vì học các lớp phân loại cá nhân cho các dự án hỗ trợ và mục tiêu, phương pháp đã đề xuất chuyển nhãn hạng của mỗi ví dụ trong chương trình hỗ trợ thành một tập hợp các nhãn hạng ứng cử viên trên bảng hiệu đối với mục tiêu qua bảng hiệu thư ký lớp, rồi dùng nhãn ứng cử viên để học lớp phân loại cho mục tiêu. Chúng tôi đánh giá phương pháp đề xuất về hai việc ở Njala. Các kết quả thử nghiệm cho thấy phương pháp của chúng ta thực sự học được các dự án đặc biệt cho các lớp có mối liên hệ chặt chẽ với các lớp hỗ trợ.', 'bg': 'Настоящата статия изследва учебните методи за многокласна класификация, използвайки етикетирани данни за целевата класификационна схема и други етикетирани данни за подобна, но различна класификационна схема (схема за подкрепа). Показваме, че ако имаме предварителни познания за връзката между схемите за подпомагане и целева класификация под формата на таблица за кореспонденция на класове, можем да я използваме за подобряване на производителността на модела по-нататък, отколкото простия подход за обучение с множество задачи. Вместо да изучава отделните слоеве на класификация за схемите за подпомагане и целеви схеми, предложеният метод преобразува етикета на класа на всеки пример от схемата за подпомагане в набор от етикети на класа кандидат в целевата схема чрез таблицата за кореспонденция на класа и след това използва етикетите на кандидат, за да научи слоя на класификация за целевата схема. Оценяваме предложения метод по две задачи в НЛО. Експерименталните резултати показват, че методът ни ефективно научава целевите схеми, особено за класовете, които имат тясна връзка с определени класове за подкрепа.', 'nl': "Deze paper onderzoekt leermethoden voor multi-class classificatie met behulp van gelabelde gegevens voor het doelclassificatieschema en andere gelabelde gegevens voor een vergelijkbaar maar verschillend classificatieschema (ondersteuningssysteem). We laten zien dat als we voorkennis hebben over de relatie tussen ondersteuning en doelclassificatieschema's in de vorm van een klassencorrespondentietabel, we deze kunnen gebruiken om de modelprestaties verder te verbeteren dan de eenvoudige multi-task leeraanpak. In plaats van de afzonderlijke classificatielagen voor de ondersteunings- en doelschema's te leren, converteert de voorgestelde methode het klassenlabel van elk voorbeeld op het ondersteuningsschema in een set van kandidaatklassenlabels op het doelschema via de klassencorrespondentietabel en gebruikt vervolgens de kandidaatlabels om de classificatielaag voor het doelschema te leren. We evalueren de voorgestelde methode op twee taken in NLP. De experimentele resultaten tonen aan dat onze methode effectief de doelschema's leert, vooral voor de klassen die een nauwe verbinding hebben met bepaalde ondersteunende klassen.", 'da': 'Denne artikel undersøger læringsmetoder til klassificering af flere klasser ved hjælp af mærkede data til målklassificeringssystemet og andre mærkede data til et lignende, men anderledes klassificeringssystem (støtteordning). Vi viser, at hvis vi har forudgående kendskab til forholdet mellem support- og målklassificeringssystemer i form af en klassekonventionstabel, kan vi bruge den til at forbedre modellens ydeevne yderligere end den simple multi-task learning tilgang. I stedet for at lære de enkelte klassifikationslag for støtte- og målordningerne konverterer den foreslåede metode klassemærket for hvert eksempel på støtteordningen til et sæt kandidatklassemærker på målordningen via klassekorespondenttabellen og bruger derefter kandidatetiketterne til at lære klassifikationslaget for målordningen. Vi evaluerer den foreslåede metode på to opgaver i NLP. De eksperimentelle resultater viser, at vores metode effektivt lærer målordningerne specielt for de klasser, der har en tæt forbindelse til bestemte supportklasser.', 'hr': 'Ovaj papir istražuje metode učenja za klasifikaciju više klasa koristeći označene podatke za ciljnu klasifikaciju i druge označene podatke za sličnu ali različitu klasifikaciju (šemu podrške). Pokazujemo da ako imamo ranije znanje o odnosu između podrške i ciljnih klasifikacijskih shēma u obliku stola klasične dopisnosti, možemo ga iskoristiti kako bi poboljšali uspješnost model a dalje od jednostavnog pristupa multizadatačnog učenja. Umjesto učenja pojedinačnih klasifikacijskih slojeva za podršku i ciljne šeme, predložena metoda pretvara etiketu klase svakog primjera na programu podrške u skup etiketa klase kandidata na ciljnom programu kroz tablu podrške klase, a zatim koristi etikete kandidata kako bi naučili klasifikacijski sloj za ciljni plan. Procjenjujemo predloženu metodu o dva zadatka u NLP-u. Eksperimentalni rezultati pokazuju da naša metoda uči ciljne šeme posebno za klase koje imaju čvrstu vezu sa određenim časovima podrške.', 'de': 'Dieser Beitrag untersucht Lernmethoden für die Mehrklassenklassifikation unter Verwendung von markierten Daten für das Zielklassifizierungsschema und anderen markierten Daten für ein ähnliches, aber anderes Klassifizierungsschema (Unterstützungsschema). Wir zeigen, dass wir, wenn wir Vorkenntnisse über den Zusammenhang zwischen Unterstützungs- und Zielklassifizierungsschemata in Form einer Klassenkorrespondenztabelle haben, die Modellleistung weiter verbessern können als den einfachen Multi-Task-Lernansatz. Anstatt die einzelnen Klassifizierungsebenen für die Unterstützungs- und Zielschemata zu erlernen, konvertiert die vorgeschlagene Methode die Klassenbezeichnung jedes Beispiels auf dem Unterstützungsschema über die Klassenkorrespondenztabelle in eine Reihe von Kandidatenklassebeschriften auf dem Zielschema und verwendet dann die Kandidatenbezeichnungen, um die Klassifizierungsebene für das Zielschema zu lernen. Wir evaluieren die vorgeschlagene Methode auf zwei Aufgaben in NLP. Die experimentellen Ergebnisse zeigen, dass unsere Methode die Zielschemata besonders für die Klassen, die eine enge Verbindung zu bestimmten Unterstützungsklassen haben, effektiv lernt.', 'ko': '본고는 여러 가지 분류의 학습 방법을 연구하고 목표 분류 방안의 표기 데이터와 비슷하지만 서로 다른 분류 방안(지원 방안)의 또 다른 표기 데이터를 사용했다.만약에 우리가 지원과 목표 분류 방안 간의 관계에 대한 선험 지식을 가지고 유형대응표의 형식으로 한다면 우리는 간단한 다중 임무 학습 방법이 아니라 모델의 성능을 더욱 향상시킬 수 있다.이 방법은 지원 방안과 목표 방안의 각 분류 층을 배우지 않고 클래스 대응 표를 통해 지원 방안의 각 예시된 클래스 라벨을 목표 방안의 후보 클래스 라벨로 변환한 다음에 후보 라벨을 사용하여 목표 방안의 분류 층을 학습한다.NLP의 두 가지 임무에서 제시된 방법을 평가했습니다.실험 결과에 의하면 우리의 방법은 목표 방안을 효과적으로 학습할 수 있으며 특히 특정 지원 클래스와 밀접한 관계를 가진 클래스에 대해 더욱 효과적이다.', 'id': 'Kertas ini menyelidiki metode belajar untuk klasifikasi multikelas menggunakan data yang ditabel untuk skema klasifikasi sasaran dan data yang ditabel lain untuk skema klasifikasi yang sama tetapi berbeda (skema dukungan). Kami menunjukkan bahwa jika kita memiliki pengetahuan sebelumnya tentang hubungan antara dukungan dan skema klasifikasi sasaran dalam bentuk tabel korespondensi kelas, kita dapat menggunakannya untuk meningkatkan prestasi model lebih jauh dari pendekatan belajar multi-tugas sederhana. Daripada belajar lapisan klasifikasi individu untuk skema dukungan dan sasaran, metode yang diusulkan mengubah label kelas setiap contoh pada skema dukungan menjadi set label kelas kandidat pada skema sasaran melalui tabel korespondensi kelas, dan kemudian menggunakan label kandidat untuk belajar lapisan klasifikasi untuk skema sasaran. Kami mengevaluasi metode yang diusulkan pada dua tugas di NLP. Hasil eksperimen menunjukkan bahwa metode kita secara efektif mempelajari skema sasaran khususnya untuk kelas yang memiliki koneksi ketat dengan kelas dukungan tertentu.', 'sw': 'Papa hii inachunguza mbinu za kujifunza kwa ajili ya kutafsiri darasa nyingi kwa kutumia taarifa zilizoonyesha kwa ajili ya mpango wa usambazaji na taarifa nyingine zinazoonyesha kwa mpango uliofanana lakini tofauti wa kutafsiri (mpango wa kuunga mkono). Tunaonyesha kwamba kama tuna ufahamu wa kabla kuhusu uhusiano kati ya mipango ya usambazaji na lengo la kuangalia katika namna ya meza ya mawasiliano ya darasa, tunaweza kutumia ili kuboresha utendaji wa mifano zaidi ya mbinu rahisi za kujifunza kwa kazi nyingi. Badala ya kujifunza vipande vya kutangaza binafsi kwa ajili ya mipango ya kuunga mkono na lengo, mbinu zilizopendekezwa hubadilisha alama ya darasa la kila mfano katika mpango wa kuunga mkono katika seti ya tabaka la wagombea kupitia meza ya mawasiliano ya darasa, na kisha inatumia alama za wagombea kujifunza daraja kwa ajili ya mpango wa lengo. Tunatathmini mbinu zilizopendekezwa katika kazi mbili za NLP. Matokeo ya majaribio yanaonyesha kuwa mbinu yetu kwa ufanisi unajifunza mpango wa lengo hasa kwa darasa ambazo zina uhusiano mkali kwa darasa fulani za uungaji mkono.', 'fa': 'این کاغذ با استفاده از داده\u200cهای برچسب\u200cشده برای برچسب\u200cبندی هدف و داده\u200cهای برچسب\u200cبندی دیگر برای برچسب\u200cبندی مشابه\u200cای اما برچسب\u200cبندی متفاوت تحقیق می\u200cکند. ما نشان می دهیم که اگر ما دانش قبلی درباره ارتباط بین برنامه\u200cهای پشتیبانی و برنامه\u200cهای برنامه\u200cهای برنامه\u200cبندی هدف داشته باشیم در شکل میز برنامه\u200cبندی کلاس، می\u200cتوانیم از آن استفاده کنیم تا عملکرد مدل بیشتر از دستور یادگیری بسیار ساده انجام دهیم. به جای یاد گرفتن لایه\u200cهای جدیدی جدیدی برای برنامه\u200cهای پشتیبانی و هدف، روش پیشنهاد برنامه\u200cهای کلاس هر مثال را روی برنامه پشتیبانی به مجموعه برنامه\u200cهای کلاس کاندیدا روی برنامه\u200cهای هدف از طریق برنامه\u200cهای متفاوتی کلاس تبدیل می\u200cکند، و سپس از برنامه\u200cهای کاندیدا برای یاد گرفتن لا ما روش پیشنهاد را بر دو کار در NLP ارزیابی می کنیم. نتایج آزمایشی نشان می دهد که روش ما به طور موثر برنامه های هدف را یاد می گیرد مخصوصا برای کلاس هایی که ارتباط سخت با کلاس های پشتیبانی دارند.', 'tr': "Bu kagyz multi-klas klasifikasiýasy üçin etitlenýän maglumatlary we beýleki klasifikasiýasy üçin etitlenýän maglumatlary ullanýar. Biz eger bir klas meňzeşlikli täblisin şeklinde destek we maksady taslamalaryň arasynda öňki bilgilerimiz bar bolsa, onda muny nusgasyny birnäçe-täbli öwrenmek üçin ýüze gowurabileris. Mazmunlar we maksadat şemalary üçin beýleki klasifikasyň katlaryny öwrenmegiň ýerine, teklip etitleri her mysal taýýarlaryň klas etiketlerini maksadyň täblisasi görä üýtget we soňra maksadyň düzümlerini öwrenmek üçin kandidat etiketlerden ullanyr. NLP'de iki işde teklip eden yöntemi çykýarys. Deneymeli netijeler biziň metodamyzyň belli klaslaryň üstünde gaty bir baglaýyşyk bolan maksadyň şemalaryny iň özellikle öwrenýändigini görkezýär.", 'sq': 'Ky dokument heton metodat e mësimit për klasifikimin e shumë klasave duke përdorur të dhënat e etiketuara për skemën e klasifikimit të objektivit dhe të dhënat e tjera të etiketuara për një skemë klasifikimi të ngjashme por të ndryshme (skemë mbështetjeje). Ne tregojmë se nëse kemi njohuri të mëparshme rreth lidhjes midis sistemeve të mbështetjes dhe klasifikimit të objektivëve në form ën e tabelës së korrispondencës së klasës, ne mund ta përdorim atë për të përmirësuar performancën e model it më tej se metoda e thjeshtë e mësimit me shumë detyra. Në vend të mësimit të niveleve individuale të klasifikimit për skemat e mbështetjes dhe objektivit, metoda e propozuar konverton etiketën e klasës së çdo shembulli në skemën e mbështetjes në një sërë etiketash kandidate të klasës në skemën e objektivit nëpërmjet tabelës së korrispondencës së klasës dhe pastaj përdor etiketat kandidate për të mësuar nivelin e klasifikimit për skemën e objektivit. Ne vlerësojmë metodën e propozuar për dy detyra në NLP. Rezultatet eksperimentale tregojnë se metoda jonë mëson efektivisht skemat objektive veçanërisht për klasat që kanë një lidhje të ngushtë me disa klasa mbështetëse.', 'af': "Hierdie papier ondersoek leer metodes vir multiklas klassifikasie deur te gebruik etiketeerde data vir die doel klassifikasie skema en 'n ander etiketeerde data vir' n gelyklike maar ander klassifikasie skema (ondersteun skema). Ons wys dat as ons voorheen kennis het oor die verwanting tussen ondersteun en doel klassifikasie skeme in die vorm van 'n klas ooreenstemmende tabel, kan ons dit gebruik om die model uitvoerding verder te verbeter as die eenvoudige multi-taak leer toegang te verkry. In plaas van leer van die individuele klasifikasie lagte vir die ondersteun en doel skema, die voorgestelde metode omskakel die klas etiket van elke voorbeeld op die ondersteun skema in 'n stel van kandidate klas etikette op die doel skema deur die klas ooreenstemmingstabel, en dan gebruik die kandidate etikette om die klasifikasie laag vir die doel skema te leer. Ons evalueer die voorgestelde metode op twee taak in NLP. Die eksperimentele resultate vertoon dat ons metode effektief leer die doel skeme spesiaal vir die klasse wat 'n tig verbinding het met sekere ondersteunde klasse.", 'am': 'ይህ ፕሮግራም በተለያዩ ነገር ግን በተለያዩ የክፍል ሥርዓት (support scheme) የተጠቃሚ ዳታ በመጠቀም የጨዋታ ክፍተት ማስተማርን ሥርዓት ይጠይቃል፡፡ በክፍለ ግንኙነት ገበታ ውስጥ የግንኙነት ግንኙነት እና የግንኙነት ግንኙነት እና የግንኙነት ፕሮግራሙን ማድረግ እንደሆነ እናሳየዋለን፡፡ የግንኙነት ክፍተት ደረጃዎችን ለመማር ፋንታ፣ በተዘጋጀው ሥርዓት የሁሉንም ምሳሌ የደረጃ ምልክት ምልክቶችን በጭብጥ ፕሮግራሙ ላይ ወደ ተቃውሞ የደረጃ ምልክቶችን በክፍሉ ግንኙነት ማሰናጃ ማድረግ እና በኋላም የአካላጆች ምልክቶችን ለመማር የክፍተት ደረጃውን ለመተማር ይዞራል፡፡ በNLP ውስጥ ያሉትን ሁለት ስራ ላይ የተዘጋጀውን ሥርዓት እናሳውቃለን፡፡ የፈተናው ውጤቶች የግንኙነታችንን ሥርዓት በተግባር ይማራሉ፣ በተለይም በተጨማሪው ደረጃዎች ላይ ግንኙነት አግኝቷል፡፡', 'hy': 'Այս հոդվածը ուսումնասիրում է բազմադասակարգչային դասակարգչային դասակարգչային մեթոդներ՝ օգտագործելով նշանակված տվյալներ նպատակային դասակարգչային սխեմայի համար և այլ նշանակալի, բայց տարբեր դասակարգչային We show that if we have prior knowledge about the relation between support and target classification schemes in the form of a class correspondence table, we can use it to improve the model performance further than the simple multi-task learning approach.  Հաջակցության և նպատակային ծրագրերի անհատական դասակարգման շերտերը սովորելու փոխարեն, առաջարկված մեթոդը փոխակերպում է աջակցության ծրագրի յուրաքանչյուր օրինակի դասակարգման պիտակները նպատակային ծրագրի մասնակիցների դասակարգման պիտակների մի շարք դասակարգման աղյուսակի միջոցով,  Մենք գնահատում ենք նախագծված մեթոդը երկու հանձնարարության համար ՆԼՊ-ում: Փորձարկման արդյունքները ցույց են տալիս, որ մեր մեթոդը արդյունավետ սովորում է նպատակային ծրագրերը հատկապես այն դասերի համար, որոնք ուժեղ կապ ունեն որոշ աջակցության դասերի հետ:', 'az': "Bu kağıt çoxlu sınıf klasifikasyonu öyrənmək metodlarını məqsədilə klasifikasyon taslağı üçün etiketli məlumatları və bənzər, müxtəlif klasifikasyon taslağı üçün başqa etiketli məlumatları istifadə edir. Biz göstəririk ki, əvvəlki bilgilərimiz dəstək və məqsəd klasifikasiya schemları arasındakı ilişkisi dəstək kompleksiyası masası kimi olsaydı, bunu çoxlu iş öyrənməsindən daha çox modeli performansını yaxşılaşdırmaq üçün istifadə edə bilərik. Üstəlik və məqsəd şemaları üçün indir klasifikasiya düzümləri öyrənmək yerine, təklif edilən metod, hər nümunə dəstək şemalarının sınıf etiketini məqsəd şemaları ilə məqsəd şemaları ilə dəstək etiketlərinin dəstəsinə çevirir, sonra da məqsəd şemaları üçün klasifikasiya düzümləri öyrənir. NLP'deki iki iş barəsində təklif etdiyimiz metodları değerləşdiririk. Eksperiment sonuçları göstərir ki, metodumuzun bəzi dəstələrə sıxıntılı bir bağlantı olan dəstələr üçün məqsədil schemları etkili olaraq öyrənir.", 'bn': 'এই পত্রিকা অনুসন্ধান করে টার্গেট শ্রেণীবিন্যাস পরিকল্পনার জন্য লেবেল ডাটা ব্যবহার করে বহু শ্রেণীর বিভিন্ন শ্রেণীবিভাগের জন্য শিক্ষা পদ্ধ আমরা দেখাচ্ছি যে যদি আমাদের সমর্থন এবং লক্ষ্য পরিকল্পনার পরিকল্পনার সম্পর্কের পূর্বে জ্ঞান আছে তাহলে ক্লাসের সংস্কার টেবিলের মাধ্যমে আমরা এটি ব্যবহার করতে পারি  সমর্থন ও লক্ষ্য পরিকল্পনার জন্য ব্যক্তিগত শ্রেণীবিভাগের ক্লাসের লেবেল শিখতে পারার পরিবর্তে প্রস্তাবিত পদ্ধতি সমর্থন পরিকল্পনায় প্রার্থীদের ক্লাসের ক্লাসের লেবেল পরিবর্তন করে ক্লাস সের সংস আমরা এনএলপিতে প্রস্তাবিত পদ্ধতিকে মূল্যায়ন করি। পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের পদ্ধতি কার্যকর ভাবে লক্ষ্য পরিকল্পনা শিখতে পাচ্ছে, বিশেষ করে ক্লাসের জন্য যাদের কিছু সম', 'ca': "Aquest paper investiga mètodes d'aprenentatge per a classificar múltiples classes utilitzant dades etiquetades per l'esquema de classificació alvo i altres dades etiquetades per un esquema de classificació similar però diferent (esquema de suport). Mostrem que si tenim coneixement previ sobre la relació entre els esquemes de suport i classificació d'objectiu en form a de taula de corresponència de classe, el podem utilitzar per millorar el rendiment del model més enllà d'un simple enfocament d'aprenentatge multitasca. En comptes d'aprendre les capes individuals de classificació dels esquemes de suport i de mira, el mètode proposat converteix la etiqueta de classe de cada exemple del esquema de suport en un conjunt d'etiquetes de classe candidata del esquema de mira a través de la taula de correspondència de classe, i després utilitza les etiquetes candidates per aprendre la capa de classificació del esquema de mira. Evaluam el mètode proposat en dues tasques a NLP. Els resultats experimentals mostren que el nostre mètode aprene efectivament els esquemes d'objectiu especialment per a les classes que tenen una estreta connexió amb certes classes de suport.", 'bs': 'Ovaj papir istražuje metode učenja za klasifikaciju više klasa koristeći označene podatke za ciljnu klasifikaciju i druge označene podatke za sličnu ali različitu klasifikaciju (šemu podrške). Pokazujemo da ako imamo ranije znanje o vezi između schema podrške i ciljne klasifikacije u obliku stola klasične dopisnosti, možemo ga iskoristiti kako bi poboljšali model izvršnost više od jednostavnog pristupa multi task učenja. Umjesto učenja individualnih klasifikacijskih slojeva za podršku i ciljne šeme, predložena metoda pretvara etiketu klase svakog primjera na šemu podrške u setu etiketa klase kandidata na ciljnoj šemi kroz tablu dopisnika klase, a zatim koristi etikete kandidata kako bi naučili klasifikacijski sloj za ciljnu šemu. Procjenjujemo predloženu metodu o dva zadatka u NLP-u. Eksperimentalni rezultati pokazuju da naša metoda uči ciljne šeme posebno za časove koje imaju tešku vezu sa određenim časovima podrške.', 'cs': 'Tento článek zkoumá učební metody pro vícetřídní klasifikaci s využitím označených dat pro cílový klasifikační schéma a dalších označených dat pro podobný, ale odlišný klasifikační schéma (podpůrný schéma). Ukazujeme, že pokud máme předchozí znalosti o vztahu mezi podpůrnými a cílovými klasifikačními schématy ve formě korespondenční tabulky tříd, můžeme ji využít k zlepšení výkonnosti modelu dále než jednoduchý multi-tasking učení přístup. Místo toho, aby se učila jednotlivé klasifikační vrstvy pro podpůrné a cílové schémata, navrhovaná metoda převádí štítek každého příkladu v podpůrném schématu na sadu štítků kandidátů v cílovém schématu prostřednictvím korespondenční tabulky tříd a pak používá štítky kandidátů k naučení klasifikační vrstvy pro cílové schéma. Navrhovanou metodu hodnotíme na dvou úkolech v NLP. Experimentální výsledky ukazují, že naše metoda se efektivně učí cílová schémata zejména pro třídy, které mají úzké spojení s určitými podpůrnými třídami.', 'fi': 'Tﾃ､ssﾃ､ tyﾃｶssﾃ､ tutkitaan moniluokkaisen luokittelun oppimismenetelmiﾃ､ kﾃ､yttﾃ､en kohdeluokitusjﾃ､rjestelmﾃ､n merkittyﾃ､ tietoa ja toista samanlaisen mutta erilaisen luokittelujﾃ､rjestelmﾃ､n merkittyﾃ､ tietoa (tukijﾃ､rjestelmﾃ､). Osoitamme, ettﾃ､ jos meillﾃ､ on aikaisempaa tietoa tuki- ja kohdeluokitusjﾃ､rjestelmien vﾃ､lisestﾃ､ suhteesta luokkavastaavuustaulukon muodossa, voimme sen avulla parantaa mallin suorituskykyﾃ､ yksinkertaisen monitehtﾃ､vﾃ､oppimisen lisﾃ､ksi. Tuki- ja kohdejﾃ､rjestelmien yksittﾃ､isten luokitustasojen oppimisen sijaan ehdotettu menetelmﾃ､ muuntaa kunkin tukijﾃ､rjestelmﾃ､n esimerkin luokkamerkinnﾃ､t kohdejﾃ､rjestelmﾃ､n ehdokasluokan tunnuksiksi luokkavastaavuustaulukon kautta ja kﾃ､yttﾃ､ﾃ､ sitten kohdejﾃ､rjestelmﾃ､n luokitustasoja. Arvioimme ehdotettua menetelmﾃ､ﾃ､ kahdessa tehtﾃ､vﾃ､ssﾃ､ NLP:ssﾃ､. Kokeelliset tulokset osoittavat, ettﾃ､ menetelmﾃ､mme oppii tehokkaasti kohdeohjelmat erityisesti kursseille, joilla on tiivis yhteys tiettyihin tukiluokkiin.', 'et': 'Käesolevas töös uuritakse mitmeklassilise klassifitseerimise õppemeetodeid, kasutades märgistatud andmeid sihtklassifitseerimisskeemi jaoks ja teisi märgistatud andmeid sarnase, kuid erineva klassifitseerimisskeemi jaoks (toetuskava). Näitame, et kui meil on eelnevad teadmised toetuse- ja sihtklassifikatsiooniskeemide vahelisest seosest klasside vastavustabeli kujul, saame seda kasutada mudeli tulemuslikkuse parandamiseks rohkem kui lihtne mitmeülesandeline õppimine. Toetus- ja sihtkavade individuaalsete klassifitseerimiskihtide õppimise asemel muundab kavandatud meetod iga toetuskava näite klassimärgi sihtkava kandidaadiklassimärgisteks klasside vastavustabeli kaudu ning kasutab seejärel sihtkava klassifitseerimiskihi õppimiseks kandidaadimärgisteid. Hindame kavandatud meetodit kahe ülesande puhul NLP-s. Eksperimentaalsed tulemused näitavad, et meie meetod õpib tõhusalt sihtskeeme, eriti klasside jaoks, mis on tihedalt seotud teatud tugiklassidega.', 'jv': 'Workspace Awak dhéwé ngerasakno kanggo awak dhéwé nang ngerasakno karo perusahaan karo nggawe barang nggawe seketeksi barêng-barêng, kita iso ngubah dhéwé ngerasakno pararamid sing bakal terus tambah karo akeh multi-task layers-action We assess the proposal method on double tasks in NLP. Rejilan sing paling nggawe bener kuwi nggawe Perintah dhéwé iso nggambar tarjamahan kanggo kelas sing ngejaraké aturan sing nggawe kudu kelas sing apik.', 'ha': "Wannan littafi yana tambaya shiryoyin su da aka sanar wa fasalar-daraja wa multi-daraja, kuma yana amfani da data da aka rubutu wa shirin classified wa shirin aimakin da kuma wani data na yin rubutu wa shirin kwamfyutan wani daidai da kuma daban-daban-daban (shirin shiryarwa). Tuna nũna cewa idan munã da wani ilmi a gabãni game da danganci masu ƙaranci da shiryoyin sigarin da ake amfani da shi cikin tsarin wani tabar da kuma ma'anar mutane, za mu yi amfani da shi don mu ƙara amfani da aikin motalin su ko da hanyon da aka sauƙa ƙara wa-aikin multi-aikin. Babu zane da zane sanar zane-zanen sigarin kowace wa shirin ayuka na ƙaranci da ake amfani da shi, shirin da aka buƙata, yana mayar wa alama wa kõwane misali na ƙarƙashin kwamfyutan taimakon, kuma yana mayar da alama masu amfani da shi cikin zane-danne na ƙidida, kuma yana amfani da alama masu mayarwa dõmin ya sanar layin sifilafi wa shirin goan. Mu ƙaddara hanyon da aka faɗa a kan aikin biyu a cikin NLP. Matarin jarrabai na nũna cewa metodenmu yana sanar shirin ayuka na goani, hasa'a, wa fasalar da ke da wata haɗi mai ƙunci zuwa danganta masu ƙaranci.", 'he': 'העבודה הזו חוקרת שיטות לימוד לסיפור במעמדים רבים באמצעות נתונים מסומנים למערכת הסיפור המטרה ועוד נתונים מסומנים למערכת הסיפור דומה אך שונה (תכנית תמיכה). אנו מראים שאם יש לנו ידע קודם על היחסים בין התמיכה לבין מערכות סיווג המטרה בצורה של שולחן התכתבות בכיתה, אנחנו יכולים להשתמש בו כדי לשפר את ההופעה של המודל יותר מאשר גישת לימוד רב משימות פשוטה. Instead of learning the individual classification layers for the support and target schemes, the proposed method converts the class label of each example on the support scheme into a set of candidate class labels on the target scheme via the class correspondence table, and then uses the candidate labels to learn the classification layer for the target scheme.  אנחנו מעריכים את השיטה המוצעת על שתי משימות ב-NLP. התוצאות הניסיוניים מראות ששיטתנו לומדת בעובדה את תכניות המטרה במיוחד לכיתות שיש להן קשר צמוד לכיתות תמיכה מסוימות.', 'sk': 'V prispevku so preučene metode učenja za večrazredno klasifikacijo z uporabo označenih podatkov za ciljno klasifikacijsko shemo in drugih označenih podatkov za podobno, vendar drugačno klasifikacijsko shemo (podporna shema). Pokazujemo, da če imamo predhodno znanje o razmerju med podpornimi in ciljnimi klasifikacijskimi shemami v obliki tabele za korespondenco razredov, jo lahko uporabimo za izboljšanje uspešnosti modela še bolj kot preprost pristop večopravilnega učenja. Namesto učenja posameznih razvrstitvenih plasti za podporne in ciljne sheme predlagana metoda prek tabele korespondence razredov pretvori oznako razreda vsakega primera v shemi podpore v niz oznak razreda kandidatov na ciljni shemi, nato pa uporabi oznake kandidatov, da se nauči razvrstitveni sloj za ciljno shemo. Predlagano metodo ocenjujemo na dveh nalogah v NLP. Eksperimentalni rezultati kažejo, da se naša metoda učinkovito nauči ciljnih shem zlasti za razrede, ki so tesno povezani z določenimi podpornimi razredi.', 'bo': 'This paper investigates learning methods for multi-class classification using labeled data for the target classification scheme and another labeled data for a similar but different classification scheme (support scheme). ང་ཚོས་རྒྱབ་སྐྱོར་དང་དམིགས་ཡུལ་གྱི་དབྱེ་སྟངས་ཀྱི་འབྲེལ་བ་དེ་ཚོ་ང་ཚོར་ཡོད་པ་ཅིན་གྲྭར་མཐུན་གྱི་ཐིག་ཁྲམ་གྱི་དབྱེ་སྟངས་དང་འབྲེལ་བ་དེ་ས Instead of learning the individual classification layers for the support and target schemes, the proposed method converts the class label of each example on the support scheme into a set of candidate class labels on the target scheme via the class correspondence table, and then uses the candidate labels to learn the classification layer for the target scheme. NLP ནང་དུ་བྱ་འགུལ་གཉིས་ཀྱི་གྲོས་འཆར་བཀོད་པའི་ཐབས་ལམ་དེ་རིམ་དཔྱད་བྱེད་ཀྱི་ཡོད། experimental results show that our method effectively learns the target schemes especially for the classes that have a hard connection to certain support classes.'}
{'en': 'Neural Maximum Subgraph Parsing for Cross-Domain Semantic Dependency Analysis', 'es': 'Análisis de subgrafos máximos neuronales para el análisis de dependencia semántica entre dominios', 'fr': "Analyse du sous-graphe du maximum neuronal pour l'analyse des dépendances sémantiques interdomaines", 'ar': 'الحد الأقصى لتحليل الرسم البياني العصبي لتحليل التبعية الدلالية عبر المجال', 'pt': 'Análise de subgrafo de máximo neural para análise de dependência semântica entre domínios', 'ja': 'クロスドメインセマンティック依存分析のためのニューラルサブグラフの最大解析', 'hi': 'क्रॉस-डोमेन सिमेंटिक निर्भरता विश्लेषण के लिए तंत्रिका अधिकतम सबग्राफ पार्सिंग', 'ru': 'Анализ нейронных максимальных подграфов для междоменного семантического анализа зависимостей', 'zh': '所以跨域语义者神经最大子图解析', 'ga': 'Parsáil Foghraf Néarach Uasta le haghaidh Anailís ar Spleáchas Séimeantach Tras Fearainn', 'ka': 'ნეიროლური მაქსიმალური სპეგრაფის პანელიზაცია კრესომინური სემენტიური განსაკუთრება ანალიზაციისთვის', 'hu': 'Neurális maximális aládiagramértelmezés a tartományok közötti szemantikus függőségi elemzéshez', 'el': 'Νευρική μέγιστη ανάλυση υπογραφήματος για ανάλυση σημασματικής εξάρτησης μεταξύ τομέων', 'it': "Analisi dei sottografici neurali massima per l'analisi della dipendenza semantica tra domini", 'ms': 'Pengesahan Subgraf Maksimum Neural untuk Analisis Dependensi Semantik Salib Domain', 'ml': 'ക്രോസ്- ഡൊമെയിന്\u200d സെമാന്റിക് ആശ്രയിക്കുന്നതിനുള്ള ഏറ്റവും കൂടുതല്\u200d സബ്ഗ്രാഫ് പാര്\u200dസിങ്ങ്', 'kk': 'Көрсетілген домендің шемматикалық тәуелдік анализ үшін невралдық шемінің субграфикалық талдауы', 'mk': 'Анализа на семантична зависност', 'lt': 'Didžiausias neurologinis pografo analizavimas atliekant tarpdomeninę semeninės priklausomybės analizę', 'mn': 'Дөрвөлжин-домайн Semantic Dependency Шалингийн мэдрэлийн хамгийн их субграфик талбар', 'mt': 'Analiżi ta’ Dipendenza Semantika ta’ Subgrafu Massimu Newrali għal Analiżi ta’ Dipendenza Semantika Transdomestika', 'no': 'Neuralt maksimum undergraf- tolking for semiantisk avhengighetsanalyse av krysdomene', 'ro': 'Analiza maximă a subgrafiei neurale pentru analiza dependenței semantice între domenii', 'pl': 'Neuronalne maksymalne analizowanie podpisów dla analizy uzależnień semantycznych między domenami', 'sr': 'Neuralno maksimalno analizu podgrafa za semantičku analizu zavisnosti preko domena', 'si': 'ක්\u200dරොස්- ඩෝමේන් සෙමාන්ටික් විශේෂ විශ්ලේෂණ විශ්ලේෂණ විශ්ලේෂණය සඳහා නිර්මාණි', 'sv': 'Neural maximal undergraftolkning för semantisk beroendeanalys över domäner', 'so': 'Baaritaanka iskuulaadka ee iskuulka', 'ta': 'கிருஸ்- டோமைன் செமாண்டிக் சார்ந்த சார்ந்த ஆராய்ச்சி', 'ur': 'کروس-ڈومین سیمنٹی ڈیفاندنسی تحلیل کے لئے نیورال کی مزید زیربگراف پارسینگ', 'uz': 'Name', 'vi': 'Trình phân tích tối đa thần kinh cho phân loại tinh thần', 'hr': 'Neuralno maksimalno razmatranje podgrafa za analizu semantične zavisnosti preko domena', 'da': 'Neural maksimal undergraftolkning til semantisk afhængighedsanalyse på tværs af domæner', 'nl': 'Neural Maximum Subgraph Parsing voor Cross-Domain Semantische Afhankelijkheidsanalyse', 'id': 'Analisi Dependensi Semantik Selatan Domain', 'ko': '크로스 필드 의미 의존 분석의 신경 최대 서브맵 분석', 'bg': 'Неврологично максимален анализ на подграфите за анализ на междудомейнната семантична зависимост', 'de': 'Neuronale Maximum Subgraph Parsing für domänenübergreifende semantische Abhängigkeitsanalyse', 'sw': 'Neural Maximum Subgraph Parsing for Cross-Domain Semantic Dependency Analysis', 'tr': 'Çapraz-domain Semantik Bağlamlık Analizi üçin Niral Azimu Subgraf Çözümleme', 'fa': 'پاکستان بزرگترین زیر گراف عصبی برای تحلیل بستگی متوسط دامنه', 'sq': 'Analiza e nëngrafit maksimum neuronal për analizën e varësisë Semantike', 'az': 'Xərc-domen Semantik bağlılıq Analizi üçün nöral Maksimum Subgraf Analizi', 'af': 'Neurale Maksimum Subgraaf Ontlegging vir Kruisdomein Semantiese Afhanklikheid Analiseer', 'bn': 'ক্রস-ডোমেইন সেম্যান্ডিক নির্ভরিক বিশ্লেষণের জন্য নিউরেল সর্বোচ্চ সাবগ্রাফ পার্সিং', 'am': 'ምርጫዎች', 'hy': 'Նյարդային Մաքսիմալ սուբգրաֆի վերլուծությունը միջբևեռի սեմանտիկ կախվածության վերլուծության համար', 'ca': "Analís neuronal de subgràfics màxims per a l'anàlisi de dependencies semenàtiques transdomàniques", 'et': 'Neuraalse maksimaalse alamgraafi parsimine domeenidevahelise semantilise sõltuvuse analüüsi jaoks', 'cs': 'Nerální maximální analýza subgrafů pro analýzu sémantické závislosti mezi doménami', 'bs': 'Neuralno maksimalno razmatranje podgrafa za analizu semantične zavisnosti preko domena', 'fi': 'Hermojen maksimaalinen alakaavion parsaus toimialueiden välistä semanttista riippuvuutta varten', 'he': 'Neural Maximum Subgraph Parsing for Cross-Domain Semantic Dependency Analysis', 'jv': 'Neral maximum SubgraphParasing for Krot-domain semanti dependance Test', 'ha': 'KCharselect unicode block name', 'sk': 'Razčlenitev največje nevronske podgrafe za analizo meddomenske semantične odvisnosti', 'bo': 'Cross-Domain Semantic Dependency Analysis པར་དབྱིབས་ཆེ་ཤོས་མཐའ་གཟུགས་རིས་དབྱེ་ཞིབ'}
{'en': 'We present experiments for cross-domain semantic dependency analysis with a neural Maximum Subgraph parser. Our ', 'ar': 'نقدم تجارب لتحليل التبعية الدلالية عبر المجال باستخدام محلل الرسم البياني العصبي الأقصى. يستهدف محللنا الرسوم البيانية 1-endpoint-cross ، و pagenumber-2 التي تتناسب جيدًا مع الرسوم البيانية التبعية الدلالية ، وتستخدم خوارزمية برمجة ديناميكية فعالة لفك التشفير. من أجل توضيح الغموض ، يقوم المحلل اللغوي بربط الكلمات بمتجهات BiLSTM ويستخدم هذه المتجهات لتعيين درجات إلى تبعيات المرشح. نجري تجارب على مجموعات البيانات من SemEval 2015 وكذلك CCGBank الصيني. المحلل اللغوي لدينا يحقق نتائج تنافسية للغاية للغة الإنجليزية والصينية. لتحسين أداء التحليل للنصوص عبر المجالات ، نقترح طريقة موجهة نحو البيانات لاستكشاف العمومية اللغوية المشفرة في قواعد الموارد الإنجليزية ، وهي قواعد HPSG الموجهة بدقة ، والمصممة يدويًا ، بطريقة ضمنية. توضح التجارب فعالية طريقتنا الموجهة نحو البيانات عبر مجموعة واسعة من الظروف.', 'fr': "Nous présentons des expériences d'analyse des dépendances sémantiques interdomaines avec un analyseur neuronal Maximum Subgraph. Notre analyseur cible les graphiques de 1 point de terminaison et de numéro de page 2 qui conviennent parfaitement aux graphes de dépendance sémantique, et utilise un algorithme de programmation dynamique efficace pour le décodage. Pour la désambiguïsation, l'analyseur associe les mots aux vecteurs BilsTM et utilise ces vecteurs pour attribuer des scores aux dépendances de candidats. Nous menons des expériences sur les ensembles de données de SemEval 2015 ainsi que sur la CCGBank chinoise. Notre analyseur permet d'obtenir des résultats très compétitifs en anglais et en chinois. Pour améliorer les performances d'analyse de textes interdomaines, nous proposons une méthode orientée données pour explorer la généralité linguistique encodée dans English Resource Grammar, qui est une grammaire HPSG conçue à la main et orientée vers la précision, de manière implicite. Les expériences démontrent l'efficacité de notre méthode axée sur les données dans un large éventail de conditions.", 'pt': 'Apresentamos experimentos para análise de dependência semântica entre domínios com um analisador neural de Subgrafo Máximo. Nosso analisador tem como alvo gráficos de cruzamento de 1 ponto final, número de página 2, que são um bom ajuste para gráficos de dependência semântica e utiliza um algoritmo de programação dinâmica eficiente para decodificação. Para desambiguação, o analisador associa palavras a vetores BiLSTM e utiliza esses vetores para atribuir pontuações a dependências candidatas. Conduzimos experimentos nos conjuntos de dados do SemEval 2015, bem como do CCGBank chinês. Nosso analisador alcança resultados muito competitivos para inglês e chinês. Para melhorar o desempenho de análise em textos de domínio cruzado, propomos um método orientado a dados para explorar a generalidade linguística codificada em English Resource Grammar, que é uma gramática HPSG feita à mão e orientada para a precisão, de forma implícita. Os experimentos demonstram a eficácia do nosso método orientado a dados em uma ampla gama de condições.', 'es': 'Presentamos experimentos para el análisis de dependencia semántica entre dominios con un analizador neuronal de Maximum Subgraph. Nuestro analizador apunta a gráficos de cruce de 1 punto final y número de página 2 que se ajustan bien a los gráficos de dependencia semántica, y utiliza un algoritmo de programación dinámica eficiente para la decodificación. Para la desambiguación, el analizador asocia palabras con vectores BilsTM y utiliza estos vectores para asignar puntuaciones a las dependencias de los candidatos. Llevamos a cabo experimentos con los conjuntos de datos de SemEval 2015 y del CCGBank chino. Nuestro analizador logra resultados muy competitivos tanto en inglés como en chino. Para mejorar el rendimiento del análisis de textos entre dominios, proponemos un método orientado a datos para explorar la generalidad lingüística codificada en English Resource Grammar, que es una gramática HPSG hecha a mano y orientada a la precisión, de forma implícita. Los experimentos demuestran la eficacia de nuestro método orientado a datos en una amplia gama de condiciones.', 'ja': '私たちは、ニューラルマキシマムサブグラフ構文解析器を使用して、クロスドメインのセマンティック依存性分析の実験を提示します。当社の構文解析機は、意味依存グラフによく適合し、デコードに効率的な動的プログラミングアルゴリズムを利用する、1エンドポイント交差、ページ番号-2グラフをターゲットにしています。曖昧さを解消するために、構文解析器は、単語をＢｉＬＳＴＭベクトルに関連付け、これらのベクトルを利用してスコアを候補依存関係に割り当てる。SemEval 2015と中国CCGB Bankのデータセットの実験を行っています。当社のパーサーは、英語と中国語の両方で非常に競争力のある結果を実現します。クロスドメインテキストの構文解析パフォーマンスを向上させるために、データ指向の方法を提案し、英語リソース文法にコード化された言語学的一般性を探求します。これは、暗黙の方法で精密に指向され、手作りされたHPSG文法です。実験は、幅広い条件にわたる当社のデータ指向の方法の有効性を示しています。', 'zh': '臣等建用神经最大子图解析器跨域语义赖分析之实验。 吾解析器针1-端点交页码-2图,此图非常适合语义恃其关系,因效编程算法解码之。 除歧义,解析器以单词 BiLSTM 向量相关,因向量分数以给选赖。 SemEval 2015及中国CCGBank数集实验。 吾解析器于英语、中文,甚有竞争力焉。 所以崇跨域文本之解析,立向数之法,以隐式探英语资语法中编码言语通用性,此精导之HPSG语法也。 实验验吾数之有效性也。', 'ru': 'Представляем эксперименты по междоменному семантическому анализу зависимостей с нейронным парсером максимальных подграфов. Наш парсер нацелен на 1-пересечение точек, графы с номером 2, которые хорошо подходят для графов семантической зависимости, и использует эффективный алгоритм динамического программирования для декодирования. Для устранения неоднозначности, парсер связывает слова с векторами BiLSTM и использует эти векторы для присвоения оценок зависимостям-кандидатам. Мы проводим эксперименты на наборах данных SemEval 2015, а также китайского CCGBank. Наш парсер достигает очень конкурентоспособных результатов как для английского, так и для китайского языков. Чтобы улучшить производительность синтаксического анализа междоменных текстов, мы предлагаем метод, ориентированный на данные, чтобы исследовать лингвистическую общность, закодированную в английской ресурсной грамматике, которая является точной, ориентированной на ручную работу грамматикой HPSG, неявным образом. Эксперименты демонстрируют эффективность нашего метода, ориентированного на данные, в широком диапазоне условий.', 'hi': 'हम एक तंत्रिका अधिकतम सबग्राफ पार्सर के साथ क्रॉस-डोमेन शब्दार्थ निर्भरता विश्लेषण के लिए प्रयोग प्रस्तुत करते हैं। हमारे पार्सर लक्ष्य 1-समापन बिंदु-क्रॉसिंग, pagenumber-2 रेखांकन जो शब्दार्थ निर्भरता रेखांकन के लिए एक अच्छा फिट कर रहे हैं, और डिकोडिंग के लिए एक कुशल गतिशील प्रोग्रामिंग एल्गोरिथ्म का उपयोग करता है। disambiguation के लिए, पार्सर BiLSTM वैक्टर के साथ शब्दों को जोड़ता है और उम्मीदवार निर्भरताओं को स्कोर असाइन करने के लिए इन वैक्टरों का उपयोग करता है। हम SemEval 2015 के साथ-साथ चीनी CCGBank से डेटा सेट पर प्रयोग करते हैं। हमारे पार्सर दोनों अंग्रेजी और चीनी के लिए बहुत प्रतिस्पर्धी परिणाम प्राप्त करता है। क्रॉस-डोमेन ग्रंथों पर पार्सिंग प्रदर्शन में सुधार करने के लिए, हम अंग्रेजी संसाधन व्याकरण में एन्कोडेड भाषाई सामान्यता का पता लगाने के लिए एक डेटा-उन्मुख विधि का प्रस्ताव करते हैं, जो एक अंतर्निहित तरीके से एक परिशुद्धता उन्मुख, हाथ से तैयार किए गए एचपीएसजी व्याकरण है। प्रयोग स्थितियों की एक विस्तृत श्रृंखला में हमारे डेटा-उन्मुख विधि की प्रभावशीलता को प्रदर्शित करते हैं।', 'ga': 'Cuirimid turgnaimh i láthair maidir le hanailís spleáchais shéimeantach tras-fearainn le parsálaí néar-Uachtair Foghra. Díríonn ár parsálaí trasnú críochphointe 1, graif uimhir leathanaigh-2 atá oiriúnach go maith do ghraif spleáchais shéimeantaigh, agus úsáideann sé algartam ríomhchláraithe dinimiciúil éifeachtach le haghaidh díchódaithe. Chun é a athbhrí, nascann an parsálaí focail le veicteoirí BiLSTM agus úsáideann na veicteoirí seo chun scóir a shannadh do spleáchais iarrthóra. Déanaimid turgnaimh ar na tacair sonraí ó SemEval 2015 chomh maith le CCGBank na Síne. Baineann ár parsálaí torthaí an-iomaíoch amach don Bhéarla agus don tSínis. Chun an fheidhmíocht parsála ar théacsanna trasfhearainn a fheabhsú, molaimid modh atá dírithe ar shonraí chun iniúchadh a dhéanamh ar an ghinearáltacht theangeolaíoch atá ionchódaithe i nGramadach Acmhainní an Bhéarla, ar gramadach HPSG cruinneas-dhírithe, lámhcheardaithe é, ar bhealach intuigthe. Léiríonn turgnaimh éifeachtacht ár modh sonraí-dhírithe thar raon leathan coinníollacha.', 'hu': 'Tartományok közötti szemantikai függőség elemzésére irányuló kísérleteket mutatunk be egy neurális Maximum Subgraph elemzővel. Elemzőnk 1-végpont-keresztező, oldalszám-2 grafikonokat céloz meg, amelyek jól illeszkednek a szemantikai függőségi grafikonokhoz, és hatékony dinamikus programozási algoritmust használ a dekódoláshoz. Az érthetőség érdekében az elemző a szavakat BiLSTM vektorokkal társítja, és ezeket a vektorokat használja arra, hogy pontszámokat rendeljen a jelölt függőségekhez. Kísérleteket végzünk a SemEval 2015 és a kínai CCGBank adatkészletein. Elemzőnk nagyon versenyképes eredményeket ér el angolul és kínaiul egyaránt. A tartományok közötti szövegek elemzési teljesítményének javítása érdekében egy adatorientált módszert javasolunk az angol erőforrás nyelvtan által kódolt nyelvi általánosság feltárására, amely egy precízióorientált, kézzel készített HPSG nyelvtan, implicit módon. A kísérletek széles körben mutatják be adatközpontú módszerünk hatékonyságát.', 'el': 'Παρουσιάζουμε πειράματα για ανάλυση σημασιολογικής εξάρτησης μεταξύ τομέων με έναν νευρωνικό αναλυτή μέγιστου υπογραφήματος. Ο αναλυτής μας στοχεύει γραφήματα 1-τελικού σημείου-διασταύρωσης, αρίθμηση-2 σελίδων που ταιριάζουν καλά σε σημασιολογικά γραφήματα εξάρτησης, και χρησιμοποιεί έναν αποδοτικό δυναμικό αλγόριθμο προγραμματισμού για αποκωδικοποίηση. Για αποσαφήνιση, ο αναλυτής συσχετίζει λέξεις με διανύσματα και χρησιμοποιεί αυτά τα διανύσματα για να εκχωρήσει βαθμολογίες σε υποψήφιες εξαρτήσεις. Διεξάγουμε πειράματα στα σύνολα δεδομένων της καθώς και της κινεζικής CCGBank. Ο αναλυτής μας επιτυγχάνει πολύ ανταγωνιστικά αποτελέσματα τόσο στα αγγλικά όσο και στα κινέζικα. Για να βελτιωθεί η απόδοση ανάλυσης κειμένων μεταξύ τομέων, προτείνουμε μια μέθοδο προσανατολισμένη στα δεδομένα για την εξερεύνηση της γλωσσικής γενικότητας που κωδικοποιείται στην Αγγλική Γραμματική Πόρων, η οποία είναι μια ακριβής, χειροποίητη γραμματική με έμμεσο τρόπο. Τα πειράματα καταδεικνύουν την αποτελεσματικότητα της μεθόδου προσανατολισμένης στα δεδομένα μας σε ένα ευρύ φάσμα συνθηκών.', 'ka': 'ჩვენ გამოყვანეთ ექსპერიმენტები კრესომენტიკური სექსპერიმენტიკური განსახულებელობის ანალიზაციისთვის ნეიროლური მაქსიმიმური ს ჩვენი პანსერტის მიზეზი 1-დასრულ წერტილის გადაწყება, გვერდინუმერი-2 გრაფიკები, რომლებიც სემონტიკური დასამხრებელობის გრაფიკებისთვის მსგავსია და გამოყენება ეფექტიური დინამი განამბიგუაციისთვის, პასუტერი სიტყვების BiLSTM გვეკტერისთვის დაკავშირება და ამ გვეკტერისთვის გამოყენება, რომელიც კონდიდირების დასახულებელობისთვის მო ჩვენ ექსპერიმენტები ექსპერიმენტებით SemEval 2015-ის და ჩინეთი CCGBank-ის მონაცემებით. ჩვენი პანუზერი ძალიან კონპექტიური შედეგი ანგლისური და ჩინეთის შედეგი. ჩვენ განვითარებთ ინგლისური რესურსი გრამიმაში, რომელიც განსაზღვრებული, პროფექტირებული HPSG გრამიმაში პროფექტირებულია ინგლისური გენერალურობას, რომელიც განსაზღვრებულია. ექსპერიმენტები ჩვენი მონაცემების ორიენტირებული მეტის ეფექტიურობას გააჩვენებენ უფრო დიდი სურათი.', 'it': "Presentiamo esperimenti per analisi di dipendenza semantica cross-domain con un parser neurale Maximum Subgraph. Il nostro parser si rivolge a grafici 1-endpoint-crossing, pagenumber-2 che si adattano bene ai grafici di dipendenza semantica e utilizza un efficiente algoritmo di programmazione dinamica per la decodifica. Per disambiguazione, il parser associa parole ai vettori BiLSTM e utilizza questi vettori per assegnare punteggi alle dipendenze candidate. Conduciamo esperimenti sui set di dati di SemEval 2015 e CCGBank cinese. Il nostro parser raggiunge risultati molto competitivi sia per l'inglese che per il cinese. Per migliorare le prestazioni di analisi sui testi cross-domain, proponiamo un metodo orientato ai dati per esplorare la generalità linguistica codificata in English Resource Grammar, che è una grammatica HPSG orientata alla precisione e realizzata a mano, in modo implicito. Gli esperimenti dimostrano l'efficacia del nostro metodo orientato ai dati in un'ampia gamma di condizioni.", 'kk': 'Біз невралдық максималдық субграфик талдаушы үшін көпшілікті семантикалық тәуелсіздік анализ үшін тәжірибелерді таңдаймыз. Семантикалық тәуелсіздік графиктерге жақсы сәйкес келетін 1- аяқтау нүктесі, 2- парақтағы графиктерді сақтап, декодтау үшін эффективті динамикалық бағдарламалар алгоритмін қолданады. Бұғаттау үшін, талдаушы BiLSTM векторларымен сөздерді біріктіреді және бұл векторларды кандидаттардың тәуелдіктеріне нәтижелерді таңдау үшін қолданады. Біз 2015 жылы SemEval және Қытай CCGBank деректер жиындарының тәжірибелерін жасаймыз. Біздің парзеріміз ағылшын және қытайлық үшін өте жақсы нәтижелерді жеткізеді. Бірнеше доменнің мәтіндерінің талдау әрекетін жақсарту үшін, ағылшын ресурстар грамматтарында кодталған лингвистикалық жалпы жалпы мәтіндерді зерттеу әдісін қолданамыз. Бұл HPSG грамматтарының дұрыс бағытталған, қолмен құрылған грамматтары Тәжірибелер біздің деректердің бағытталған әдістеріміздің ең көпшілігін көптеген шарттар арасында көрсетеді.', 'ml': 'We present experiments for cross-domain semantic dependency analysis with a neural Maximum Subgraph parser.  നമ്മുടെ പരാജയപ്രകാരം 1-endpoint-crossing, pagenumber-2 ഗ്രാഫുകള്\u200dക്ക് ലക്ഷ്യമുണ്ട്. അത് സെമാന്റിക്ക് ആശ്രയിക്കുന്ന ഗ്രാഫുകള്\u200dക്ക് ഏറ്റവും നല്ലതാണ്. ഡോകോഡിങ്ങിന് ഒര ബിഎല്\u200dഎസ്റ്റം വെക്റ്റരുമായി പങ്കാളികള്\u200d വാക്കുകള്\u200d പങ്കുചേര്\u200dക്കുന്നതിനായി ഈ വെക്റ്ററുകള്\u200d ഉപയോഗിക്കുന്നു. പ്രാര്\u200d സെമ്എവാല്\u200d 2015 ല്\u200d നിന്നും ചൈനീസ് സിസിജിബാങ്കില്\u200d നിന്നും ഡേറ്റാ സജ്ജീകരണങ്ങളില്\u200d നിന്നും നമ്മള്\u200d പരീക് ഞങ്ങളുടെ പ്രശ്നം ഇംഗ്ലീഷിലും ചൈനീസിലും ഏറ്റവും മത്സരിക്കുന്ന ഫലങ്ങള്\u200d നേടിയെടുക്കുന്നു. ക്രിസ്റ്റോമെന്\u200d ടെക്സ്റ്റുകളില്\u200d പാര്\u200dസിങ് പ്രവര്\u200dത്തനങ്ങള്\u200d മുന്\u200dകൂട്ടുവാന്\u200d വേണ്ടി, ഇംഗ്ലീഷ് റിസോര്\u200dസ് ഗ്രാമാരില്\u200d എക്സോഡിറ്റിക്കുന്ന ഭാഷയുടെ ജനറലിറ്റിക് ര പരീക്ഷണങ്ങള്\u200d വിശാലമായ നിലങ്ങളിലൂടെ നമ്മുടെ ഡേറ്റാ മാര്\u200dഗ്ഗങ്ങളുടെ പ്രഭാവം കാണിച്ചിരിക്കുന്നു.', 'mt': 'Aħna nippreżentaw esperimenti għall-analiżi ta’ dipendenza semantika bejn id-dominji b’analizzatur tas-sottografu massimu newrali. Il-analizzatur tagħna jimmira graffi ta’ punt ta’ tmiem wieħed, paġna numru-2 li huma adattati tajjeb għal graffi ta’ dipendenza semantika, u juża algoritmu ta’ programmazzjoni dinamika effiċjenti għad-dekodifikazzjoni. Għad-diżambigwazzjoni, il-analizzatur jassoċja kliem mal-vetturi BiLSTM u juża dawn il-vetturi biex jassenja punteġġi lid-dipendenzi kandidati. Aħna nieħdu esperimenti fuq is-settijiet tad-dejta minn SemEval 2015 kif ukoll is-CCGBank Ċiniża. Il-parser tagħna jikseb riżultati kompetittivi ħafna kemm għall-Ingliż kif ukoll għaċ-Ċiniż. Biex tittejjeb il-prestazzjoni tal-analiżi tat-testi transdomestiċi, qed nipproponu metodu orjentat lejn id-dejta biex tiġi esplorata l-ġeneralità lingwistika kkodifikata fil-Grammar tar-Riżorsi Ingliż, li hija gramma HPSG orjentata lejn il-preċiżjoni, bl-idejn, b’mod impliċitu. L-esperimenti juru l-effettività tal-metodu tagħna orjentat lejn id-dejta f’firxa wiesgħa ta’ kundizzjonijiet.', 'ms': 'Kami perkenalkan eksperimen untuk analisis dependensi semantik cross-domain dengan penghurai Subgraf Maksimum saraf. Our parser targets 1-endpoint-crossing, pagenumber-2 graphs which are a good fit to semantic dependency graphs, and utilizes an efficient dynamic programming algorithm for decoding.  Untuk nyahambiguasi, penghurai berkaitan perkataan dengan vektor BiLSTM dan menggunakan vektor ini untuk menyerahkan skor kepada dependensi calon. Kami melakukan eksperimen pada set data dari SemEval 2015 dan CCGBank Cina. Penganalis kami mencapai keputusan yang sangat kompetitif untuk bahasa Inggeris dan Cina. Untuk meningkatkan prestasi penghuraian teks melintas-domain, kami cadangkan kaedah orient data untuk mengeksplorasi umum bahasa yang dikodifikasikan dalam Grammar Sumber Inggeris, yang merupakan gramatik HPSG yang direncanakan dengan tepatnya, secara implicit. Eksperimen menunjukkan kegunaan kaedah data-oriented kita melalui julat luas syarat.', 'lt': 'Pateikiame eksperimentus įvairių domenų semantinės priklausomybės analizei su neurologiniu maksimaliu pografo analizatoriumi. Our parser targets 1-endpoint-crossing, pagenumber-2 graphs which are a good fit to semantic dependency graphs, and utilizes an efficient dynamic programming algorithm for decoding.  For disambiguation, the parser associates words with BiLSTM vectors and utilizes these vectors to assign scores to candidate dependencies.  Atliekame eksperimentus su 2015 m. SemEval ir Kinijos CCGBank duomenų rinkiniais. Mūsų analizatorius gauna labai konkurencingus rezultatus anglų ir kinų kalbomis. Siekiant pagerinti įvairių sričių tekstų analizės rezultatus, siūlome į duomenis orientuotą metodą, skirtą netiesiogiai ištirti kalbinį bendrumą, koduotą anglų išteklių gramatikoje, kuri yra tiksliai orientuota rankiniu HPSG gramatika. Eksperimentai rodo mūsų į duomenis orientuoto metodo veiksmingumą įvairiomis sąlygomis.', 'mk': 'We present experiments for cross-domain semantic dependency analysis with a neural Maximum Subgraph parser.  Нашиот анализатор има за цел преминување на 1 крајна точка, страница број 2 графици кои се добри за семантички графики за зависност, и користи ефикасен динамички програмирачки алгоритм за декодирање. За дејамбигуација, анализаторот ги поврзува зборовите со векторите BiLSTM и ги користи овие вектори за да им додели оценки на зависностите на кандидатите. Ние спроведуваме експерименти на податоците од SemEval 2015, како и кинеската CCGBank. Нашиот анализатор постигнува многу конкурентни резултати за англиски и кинески. To improve the parsing performance on cross-domain texts, we propose a data-oriented method to explore the linguistic generality encoded in English Resource Grammar, which is a precisionoriented, hand-crafted HPSG grammar, in an implicit way.  Експериментите ја демонстрираат ефикасноста на нашиот метод ориентиран на податоци во широк опсег на услови.', 'mn': 'Бид шинжлэх ухааны шинжлэх ухааны шинжлэх ухааны туршилтуудыг мэдрэлийн хамгийн их субграфик хуваалцагч дээр үзүүлнэ. Бидний хуваарч нь 1-төгсгөл цэгийг давхарлах, хуудас номер-2 графикийг зориулдаг. Энэ нь semantic хамааралтай графикийн хувьд сайн хангалттай бөгөөд шийдвэрлэхэд үр дүнтэй динамик програмчлалын алгоритм ашигладаг. Бүтэлгүйтлэх үед хуваагч нь BiLSTM векторуудыг холбож, тэдгээр векторуудыг кандидатын хамааралтай оноо зарцуулахын тулд хэрэглэдэг. Бид 2015 оны SemEval болон Хятад CCGBank-ын өгөгдлийн сангийн туршилтын туршилтыг хийдэг. Бидний судлаач Англи, Хятадын хоёр дахин өрсөлдөг үр дүнг авдаг. Дөрвөлжингийн текстүүдийн талаар ажиллах үйл ажиллагааг сайжруулахын тулд бид Англи хэлний ресурсов граммат дээр шинэчлэгдсэн хэлний ерөнхийлөгчийг судлах боломжтой өгөгдлийн давхар аргыг санал болгож байна. Энэ нь тодорхой, гар бүтээгдэхүүний граммат юм. Эмчилгээний туршилт бидний өгөгдлийн ориентиролт аргын үр дүнг олон нөхцөлд харуулдаг.', 'no': 'Vi presenterer eksperimenter for semantisk avhengighetsanalyse av krysdomenet med ein neuralmaksimum undergraf- tolkar. Tolkaren vårt mål er å kryssa av 1-endepunkt, pagenumber-2-grafen som er ein god passend til semantiske avhengighetsgrafen, og bruka ein effektiv dynamisk programalgoritme for dekoding. For disambiguasjon tilkoplar tolkaren ord med BiLSTM-vektorar og brukar desse vektorane for å tilordna poeng til kandidatavhengighet. Vi gjev eksperimenter på datasettet frå semiEval 2015 og kinesisk CCGBank. Tolkaren vårt oppnår svært konkurrentivt resultat for både engelsk og kinesisk. For å forbetra tolkingsfunksjonen på krysdomenetekstar, foreslår vi ein dataorientert metode for å undersøke den lingviske genereliteten kodert i engelsk ressursgrammar, som er ein presisionalt HPSG-grammar med håndkryssa, på ein implisitt måte. Eksperimentar viser effektiviteten av dataorienterte metoden vår i eit brett rekke av vilkåra.', 'ro': 'Vă prezentăm experimente pentru analiza dependenței semantice cross-domain cu un parser neural Maximum Subgraph. Analizorul nostru vizează 1-endpoint-crossing, pagenumber-2 grafice care sunt o potrivire bună pentru graficele de dependență semantică și utilizează un algoritm eficient de programare dinamică pentru decodare. Pentru dezambiguizare, parserul asociază cuvintele cu vectorii BiLSTM și utilizează acești vectori pentru a atribui scoruri dependențelor candidate. Realizăm experimente pe seturile de date SemEval 2015, precum și pe CCGBank chinezesc. Parserul nostru obține rezultate foarte competitive atât pentru engleză, cât și pentru chineză. Pentru a îmbunătăți performanța de analizare a textelor cross-domeniu, propunem o metodă orientată spre date pentru a explora generalitatea lingvistică codificată în Engleză Resource Grammar, care este o gramatică HPSG orientată spre precizie, manuală, într-un mod implicit. Experimentele demonstrează eficiența metodei noastre orientate spre date într-o gamă largă de condiții.', 'pl': 'Przedstawiamy eksperymenty do analizy zależności semantycznej między domenami za pomocą neuronowego parsera maksymalnego podpisu. Nasz parser wykorzystuje wydajny algorytm programowania dynamicznego do dekodowania. W celu wyjaśnienia, parser kojarzy słowa z wektorami BiLSTM i wykorzystuje te wektory do przypisywania wyników do zależności kandydatów. Przeprowadzamy eksperymenty na zbiorach danych z SemEval 2015 oraz chińskiego CCGBanku. Nasz parser osiąga bardzo konkurencyjne wyniki zarówno w języku angielskim, jak i chińskim. Aby poprawić wydajność parsowania tekstów między domenami, proponujemy metodę zorientowaną na dane, aby w sposób domyślny zbadać ogólność językową zakodowaną w English Resource Grammar, będącą precyzyjną, ręcznie tworzoną gramatyką HPSG. Eksperymenty pokazują skuteczność naszej metody zorientowanej na dane w szerokim zakresie warunków.', 'so': 'Waxaynu sameynaa imtixaanka baaritaanka semantika ah oo lagu sameynayo baaritaanka koourada ugu badnaan subgraph baaritaanka. Parser wuxuu ku qoran yahay 1-endpoint-crossing, pagenumber-2 graphics oo u eg sawir semantic dependency, wuxuuna isticmaalaa algorithm faa’iido ah oo ku qoran kartid. Qayb-baaritaanka, parasarku wuxuu la wadaa hadal ay ku leedahay wadooyinka BiLSTM iyo wuxuu isticmaalaa wadooyinkaas si ay qiimaha u siiso qiimeyaasha ay ku xiran yihiin. Waxaynu sameynaa imtixaan ku saabsan sawirada ee SemEval 2015 iyo CCGBank Shiino. Parsareena wuxuu helaa matooyin aad u adag Ingiriis iyo Shiino. Si loo hagaajiyo fasaxa baaritaanka ee qoraalka gudaha ah, waxaynu u soo jeedaynaa qaab lagu soo jeedo macluumaadka si a an u baarayno dhalashada afka Ingiriiska Resource Grammar, kaas oo ah qaab muhiim ah oo HPSG gacanta lagu qabanayo. Imtixaanka waxaa muujiya waxyaabaha ay ku leedahay qaababka macluumaadkayaga oo ku qoran xaalado kala duduwan.', 'sv': 'Vi presenterar experiment för semantisk beroendeanalys över domäner med en neural Maximum Subgraph parser. Vår parser riktar sig till 1-endpoint-korsning, sidnummer-2 grafer som passar bra till semantiska beroendegrafer, och använder en effektiv dynamisk programmeringsalgoritm för avkodning. För tydlighet associerar parsern ord med BiLSTM-vektorer och använder dessa vektorer för att tilldela poäng till kandidatberoenden. Vi utför experiment på datauppsättningar från SemEval 2015 samt kinesiska CCGBank. Vår parser uppnår mycket konkurrenskraftiga resultat för både engelska och kinesiska. För att förbättra tolkningen av texter över domäner föreslår vi en dataorienterad metod för att utforska den språkliga generaliteten kodad i English Resource Grammar, som är en precisionsorienterad, handgjord HPSG grammatik, på ett implicit sätt. Experiment visar hur effektiv vår dataorienterade metod är för många olika förhållanden.', 'si': 'අපි ක්\u200dරීස් ඩෝමින් සෙමැන්ටික් විශ්වාස විශ්ලේෂණය සමඟ ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා. අපේ පරීක්ෂකයෙන් ඉලක්කය 1-endPoint-Crossing, pagNummber-2 Graphs, සෙමැන්ටික් විශේෂතාවක් ග්\u200dරාෆ් වලට හොඳ සම්බන්ධයක් තියෙනවා, ඒ වගේම ප්\u200dරයෝජන අසංක්\u200dරීය සඳහා, විශේෂකයා BiLSTM වෙක්ටර්ස් සමග වචන සම්බන්ධ කරනවා ඒ වෙක්ටර්ස් විශේෂකය සම්බන්ධ කරනවා සම අපි පරීක්ෂණය කරනවා සේම්වල් 2015 වල සෙම්වල් වල චීනි CCGBank වලින්. අපේ පරීක්ෂකයෙන් ඉංග්\u200dරීසි සහ චීනි දෙන්නටම ගොඩක් ප්\u200dරතිචාරයක් ලැබෙනවා. ප්\u200dරශ්නයක් විශාල විදිහට පරීක්ෂණය වැඩ කරන්න, අපි දත්ත ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරනවා ඉංග්\u200dරීසි ප්\u200dරශ්නයක් ග්\u200dරාම්මර් වල භාෂාවික සාමාන්\u200dය විදිහට ප පරීක්ෂණය පෙන්වන්නේ අපේ දත්ත ප්\u200dරමාණයේ පරීක්ෂණය ප්\u200dරතික්\u200dරියාත්මක විශේෂතාවක් වලින්.', 'ta': 'நாம் முக்கியமான அதிகபட்ச உப்வரைப்பரிசோதனைக்கான இடைமுறை சார்பு ஆராய்ச்சிக்கு பரிசோதனைகளை காண்பிக்கிறோ எங்கள் பரிசோதனை 1- முடிவு புள்ளியை கடக்கும், பக்கம்பர்- 2 வரைபடங்கள், பெமான்டிக் சார்ந்த சார்பு வரைபடங்களுக்கு பொருத்தமானது, மற்றும் குறியீட்டிற்கு  பில்எஸ்டிஎம் நெறிகளுடன் பகிர்ந்து பில்ஸ்டிஎம் வார்த்தைகளை பயன்படுத்தி மதிப்புகளை சார்ந்த சார்புகளுக்கு ஒப்பிடுவதற் நாங்கள் செம்வால் 2015 ல் இருந்து தரவு அமைப்புகள் மீது சோதனைகளை செய்கிறோம் மற்றும் சீனா CCGBank. எங்கள் பிரச்சினை மிகவும் போராடிய முடிவுகள் பெறுகிறது ஆங்கிலம் மற்றும் சீன்களுக்கும். கிடைமட்ட உரைகளில் பாடல் செயல்பாட்டை மேம்படுத்துவதற்கு, நாம் ஒரு தரவு சார்ந்த முறையாக பரிந்துரைக்கிறோம் ஆங்கிலத்தின் மூலத்தின் குறியீட்டு பொதுவான பொருளை கண்டறியு பரிசோதனைகள் விரிவான நிபந்தனைகளுக்கு முழுவதும் எங்கள் தரவு முறைமையின் விளைவை காண்பிக்கிறது.', 'ur': 'ہم کرس-ڈومین سیمانٹیک اعتباری تحلیل کے لئے آزمائش پیش کریں گے ایک نئورل کی مزید زیربگراف پارچر کے ساتھ. ہمارے پارچر نے 1-انڈنٹ پوینٹ-کروسنگ، پیجنومبر-2 گراف کا موقع لیا ہے جو سیمانٹی اعتماد گراف کے لئے بہترین فائدہ ہیں، اور ڈیکوڈ کرنے کے لئے ایک عمدہ ڈینمانیک پروگرامینگ الگوریتم استعمال کرتا ہے. بغلطی کے لئے، پارچر نے باتوں کو BiLSTM ویکتروں کے ساتھ شریک کرتا ہے اور یہ ویکتروں کو کاندینڈ ڈانڈیٹ ڈانڈیٹ کے لئے اسکور کا استعمال کرتا ہے. ہم نے سیم اول 2015 سے اور چینی سی جی بنک سے ڈیٹ سٹ پر آزمائش کی۔ ہمارا پارچر انگلیسی اور چینی کے لئے بہت مسابقه نتیجے حاصل کرتا ہے۔ کرسٹ ڈومین متکس کے بارے میں پارسینگ کی فعالیت کو بہتر کرنے کے لئے، ہم ایک ڈاٹ کی اصلی طریقہ کی پیشنهاد کرتے ہیں کہ انگلیسی رسسور گرامر میں کدھی ہوئی زبان کی ژنرالیتی کا تحقیق کریں، جو ایک مضبوط طریقہ ہے، ہاتھ کے پیدا ہوئے HPSG گرامر، ایک مثال طریقہ سے۔ آزمائش ہمارے ڈیٹا کی طرف متوجہ ہوئی طریقے کی عمدگی دکھاتی ہے ایک وسیع طریقے سے۔', 'sr': 'Predstavljamo eksperimente za semantičku analizu zavisnosti preko domena sa neuralnim maksimalnim podgrafom analizujem. Naš analizator cilja prelazak 1-krajnja tačka, grafike broja 2 koji su dobri odgovarajući graficima semantičke zavisnosti i koristi efikasni dinamički algoritam programiranja za dekodiranje. Za disambiguaciju, analizator povezuje reči sa vektorima BiLSTM i koristi ove vektore da dodaju rezultate zavisnosti kandidata. Vodimo eksperimente na setima podataka iz SemEval 2015, kao i Kineske CCGBank. Naš analizator postiže vrlo konkurentne rezultate za engleski i kineski. Da bi poboljšali učinkovitost analize na tekstima preko domena, predlažemo metodu orijentiranu na podatke da istražimo jezičku generalnost kodiranu na engleskom Grammaru resursa, koja je precizno orientisana, rukopisana gramatika HPSG, na implicitni način. Eksperimenti pokazuju učinkovitost našeg metoda orijentiranog na podatke u širokom nizu uslova.', 'uz': "Biz bir nechta maksimal subgraf parameter bilan cross-domen semantik ishlatuvchi analyzeri uchun imtiyozni hozir qilamiz. Parametrimizning 1-endpoint chegarasini, pagenumber-2 grammatika, semantik ishlatadigan grammatika juda yaxshi boʻlgan va kodlash uchun yetarli dynamik dastur algoritdan foydalanish mumkin. @ info Biz SemEval 2015 va Xitoycha CCGBank haqida maʼlumot satrlarini bajaramiz. Bizning tarkibiz ingliz va Xitoycha haqida juda rivojlanish natijalarini bajaradi. Koʻproq domen matnlarida parsing natijasini oshirish uchun, biz ingliz Resource Grammatika qo'llanilgan lingvistik generaligini aniqlash usulini tahrirlash imkoniyat qilamiz. Bu juda muhimiy qo'llangan HPSG grammatika. Tajribalar bir necha xil holatda ma'lumotga qarilgan usulning effektligini ko'rsatadi.", 'vi': 'Chúng tôi đưa ra thí nghiệm phân tích độ riêng biệt theo mẫu giáo lục địa với một phân tích tối đa thần kinh. Mục tiêu của chúng ta là Giao điểm 1-kết điểm, biểu đồ trên bảng số-2, phù hợp với biểu đồ phụ thuộc ngữ, và sử dụng thuật to án lập động hiệu quả để giải mã. Để phân dạng, phân tích cộng từ với các véc- tơ BiLSTM và dùng các véc- tơ này để giao điểm cho quan hệ phụ thuộc của ứng cử viên. Chúng tôi tiến hành thí nghiệm trên các bộ dữ liệu từ SemEvl 205 cũng như CCGBake Trung Quốc. Vị cha xứ của chúng tôi đạt được kết quả rất cạnh tranh cho cả Anh và Trung Quốc. Để cải thiện hiệu ứng phân tích trên các văn bản ngang miền, chúng tôi đề xuất một phương pháp định hướng dữ liệu để khám phá tính chung ngôn ngữ được mã hóa trong tổ chức Grammar của Tài nguyên Anh Quốc, theo cách riêng của nó. Thí nghiệm cho thấy hiệu quả của phương pháp bố trí dữ liệu của chúng ta trong nhiều trường hợp.', 'hr': 'Predstavljamo eksperimente za analizu semantičke zavisnosti preko domena sa neuralnim maksimalnim analizatorom podgrafa. Naš analizator cilja na prelazak 1-krajnjih to čka, grafike broja 2 koji su dobri odgovarajući graficima semantičke zavisnosti i koristi efikasni dinamički algoritam programiranja za dekodiranje. Za disambiguaciju, analizator povezuje riječi s vektorima BiLSTM i koristi ove vektore za dodavanje rezultata zavisnosti kandidata. Provodimo eksperimente o setima podataka iz SemEval 2015, kao i Kineskoj CCGBank. Naš analizator postigne vrlo konkurentne rezultate za engleski i kineski. Da bismo poboljšali učinkovitost analize na tekstima preko domena, predlažemo metodu orijentiranu na podatke da istražimo jezičku generalnost kodiranu na engleskom Grammaru resursa, koja je precizno orientirana, rukopisana gramatika HPSG-a na implicitni način. Eksperimenti pokazuju učinkovitost naše metode orijentirane na podatke u širokom nizu uvjeta.', 'bg': 'Представяме експерименти за междудомейнен семантичен анализ на зависимостта с неврален анализатор на максимум субграф. Нашият анализатор е насочен към 1-крайна точка-кръстосване, брой-2 графики, които са подходящи за семантични зависимости графики, и използва ефективен динамичен програмиращ алгоритъм за декодиране. За изясняване, анализаторът свързва думите с векторите и използва тези вектори, за да присвоява оценки на зависимостите на кандидатите. Провеждаме експерименти върху наборите от данни от СемЕвал 2015, както и Китайска Банка. Нашият анализатор постига много конкурентни резултати както за английски, така и за китайски. За да подобрим ефективността на анализиране на междудомейнни текстове, предлагаме ориентиран към данни метод за изследване на езиковата обобщеност, кодирана в английската ресурсна граматика, която е прецизно ориентирана, ръчно изработена граматика по имплицитен начин. Експериментите демонстрират ефективността на нашия ориентиран към данни метод при широк спектър от условия.', 'da': 'Vi præsenterer eksperimenter til semantisk afhængighedsanalyse på tværs af domæner med en neural Maximum Subgraph parser. Vores parser målretter 1-endpoint-krydsning, sidenumber-2 grafer, som er en god pasform til semantiske afhængighedsgrafer, og bruger en effektiv dynamisk programmeringsalgoritme til afkodning. Til forståelse associerer fortolkeren ord med BiLSTM vektorer og bruger disse vektorer til at tildele scores til kandidatafhængigheder. Vi udfører eksperimenter på datasættene fra SemEval 2015 samt kinesiske CCGBank. Vores fortolker opnår meget konkurrencedygtige resultater for både engelsk og kinesisk. For at forbedre fortolkningens ydeevne på tværs af domæner, foreslår vi en dataorienteret metode til at udforske den sproglige generalitet kodet i engelsk ressource grammatik, som er en præcisionsorienteret, håndlavet HPSG grammatik, på en implicit måde. Eksperimenter viser effektiviteten af vores dataorienterede metode på tværs af en lang række forhold.', 'de': 'Wir präsentieren Experimente zur domänenübergreifenden semantischen Abhängigkeitsanalyse mit einem neuronalen Maximum Subgraph Parser. Unser Parser zielt auf 1-endpoint-crossing, pagenumber-2 Graphen ab, die gut zu semantischen Abhängigkeitsdiagrammen passen, und verwendet einen effizienten dynamischen Programmieralgorithmus für die Dekodierung. Zur Begriffsklärung assoziiert der Parser Wörter mit BiLSTM-Vektoren und verwendet diese Vektoren, um Noten zu Kandidatenabhängigkeiten zuzuweisen. Wir führen Experimente an den Datensätzen der SemEval 2015 sowie der chinesischen CCGBank durch. Unser Parser erzielt sehr wettbewerbsfähige Ergebnisse für Englisch und Chinesisch. Um die Parsing-Performance von domänenübergreifenden Texten zu verbessern, schlagen wir eine datenorientierte Methode vor, um die linguistische Allgemeinheit, die in der englischen Ressourcengrammatik codiert ist, implizit zu untersuchen. Experimente belegen die Wirksamkeit unserer datenorientierten Methode unter unterschiedlichsten Bedingungen.', 'nl': 'We presenteren experimenten voor domeinoverschrijdende semantische afhankelijkheidsanalyse met een neurale Maximum Subgraph parser. Onze parser richt zich op 1-endpoint-crossing, paginanumber-2 grafieken die goed passen bij semantische afhankelijkheidsgrafieken, en maakt gebruik van een efficiënt dynamisch programmeeralgoritme voor decodering. De parser associeert woorden met BiLSTM-vectoren en gebruikt deze vectoren om scores toe te wijzen aan kandidaat-afhankelijkheden. We voeren experimenten uit op de datasets van SemEval 2015 en Chinese CCGBank. Onze parser behaalt zeer concurrerende resultaten voor zowel Engels als Chinees. Om de parseringsprestaties van domeinoverschrijdende teksten te verbeteren, stellen we een datagerichte methode voor om de linguïstische generaliteit die is gecodeerd in de Engelse brongrammatica, een precisionsgerichte, handgemaakte HPSG grammatica, op een impliciete manier te onderzoeken. Experimenten demonstreren de effectiviteit van onze datagerichte methode onder een breed scala aan omstandigheden.', 'fa': 'ما آزمایش\u200cهایی را برای تحلیل بستگی\u200cهای متوسط دامنی با یک جداکنده\u200cی بزرگترین زیر گراف عصبی پیشنهاد می\u200cکنیم. طراحی ما هدف عبور کردن یک نقطه پایان، نقطه شماره-۲ گرافیک را می\u200cگیرد که به نقطه\u200cهای بستگی semantic fit می\u200cکنند، و الگوریتم برنامه\u200cریزی دینامیک موثرت را برای دکوندن استفاده می\u200cکند. برای ناپدید کردن، ویکتور کلمات را با ویکتورهای BiLSTM ارتباط می\u200cدهد و این ویکتورها را برای تعیین امتیاز به وابستگی کاندیداتی استفاده می\u200cکند. ما آزمایش\u200cها را روی مجموعه\u200cهای داده\u200cها از SemEval 2015 و CCGBank چینی انجام می\u200cدهیم. بازیگر ما نتایج بسیار مسابقه\u200cای برای انگلیسی و چینی می\u200cرسد. برای تحلیل کردن عملکرد درباره متن های متوسط دامنه، ما یک روش مقرر به اطلاعات پیشنهاد می\u200cکنیم تا در یک طریق معمولی ژنرالی زبان\u200cشناسی که در گرامبر منابع انگلیسی رمز شده است، تحقیق کنیم، که یک گرامبر HPSG دقیق و دستی ساخته شده است. تجربه\u200cها نشان می\u200cدهند که موثرت روش\u200cهای مقرر به داده\u200cهای ما در مجموعه\u200cای از شرایط گسترده است.', 'ko': '우리는 신경의 가장 큰 서브그래프 해석기로 전역적 의미 의존 분석을 하는 실험을 제기했다.우리의 해석기는 1-단점 교차, 페이지number-2 그림을 목표로 하는데 이 그림들은 의미 의존도에 매우 적합하고 효율적인 동적 기획 알고리즘을 이용하여 디코딩을 한다.해석기는 잘못된 뜻을 없애기 위해 단어를 BilSTM 벡터와 연관시키고 이러한 벡터를 이용하여 후보 의존 항목에 점수를 분배한다.SemEval 2015와 중국 CCGBank의 데이터 세트에서 실험했습니다.우리의 해석기는 영어와 중국어 방면에서 매우 경쟁력 있는 결과를 얻었다.크로스오버 텍스트의 문법 분석 성능을 향상시키기 위해 우리는 데이터에 대한 방법을 제시했고 은밀한 방식으로 영어 자원 문법에서 인코딩된 언어의 공통성을 탐색했다. 이것은 정확한 수동 제작을 위한 HPSG 문법이다.실험은 우리가 데이터에 대한 방법이 각종 조건하에서의 유효성을 증명하였다.', 'id': 'Kami mempersembahkan eksperimen untuk analisis dependensi semantis cross-domain dengan parser Subgraph Maximum saraf. Our parser targets 1-endpoint-crossing, pagenumber-2 graphs which are a good fit to semantic dependency graphs, and utilizes an efficient dynamic programming algorithm for decoding.  Untuk tidak ambiguasi, parser mengassokasikan kata-kata dengan vektor BiLSTM dan menggunakan vektor ini untuk mengatur skor ke dependensi kandidat. Kami melakukan eksperimen pada set data dari SemEval 2015 dan CCGBank Cina. Parser kami mencapai hasil yang sangat kompetitif untuk Bahasa Inggris dan Cina. Untuk meningkatkan prestasi penghuraian pada teks-teks cross-domain, kami mengusulkan metode data-oriented untuk mengeksplorasi generalitas bahasa yang dikodifikasikan dalam Grammar Sumber Inggris, yang merupakan gramatika HPSG yang direncanakan dengan presisi, secara implicit. Eksperimen menunjukkan efektivitas dari metode data-oriented kita melalui jangkauan luas kondisi.', 'sw': 'Tunaonyesha majaribio kwa uchambuzi wa semantic wa kutegemea na uchambuzi wa ubora wa kipindi kikubwa. Mchangiaji wetu analenga kuvuka hatua ya mwisho 1, picha za pagenumber-2 ambazo zina sahihi sana ya kutegemea picha za kimapenzi, na inatumia algorithi yenye ufanisi wa programu za uchunguzi. Kwa kutofautisha, mchambuzi wanashirikiana na maneno na vectori za BiLSTM na hutumia vectori hizi ili kuweka vipimo vya mgombea kutegemea. Tunafanya majaribio kuhusu seti za data kutoka SemEval 2015 na CCGBank ya China. Mchangiaji wetu hufanikiwa matokeo makubwa kwa ajili ya Kiingereza na Kichina. Ili kuendeleza utendaji wa wimbo huo katika ujumbe wa maeneo mbalimbali, tunapendekeza njia ya data-oriented kuchunguza uzalishaji wa lugha iliyoandikwa kwa Kiingereza Mkutano wa rasilimali, ambayo ni mpango wa HPSG uliotumiwa na mkono, kwa njia yenye uhakika. Majaribio yanaonyesha ufanisi wa mbinu zetu zinazoelekezwa na taarifa katika hali mbalimbali.', 'af': "Ons voorsien eksperimente vir kruisdomein semantiese afhanklikheid analiseer met 'n neurale Maksimum Subgraaf ontwerker. Ons ontleerder doel doel 1-eindpunt-kruissing, pagenumber-2 grafieke wat 'n goeie pas tot semantiese afhanklikheidsgrafe, en gebruik 'n effektief dinamiese program algoritme vir dekodering. Vir disambiguasie, die analyseer assosieer woorde met BiLSTM vektore en gebruik hierdie vektore om telling te toewys na kandidate afhanklikhede. Ons uitvoer eksperimente op die data stelle van SemEval 2015 as ook Sjinese CCGBank. Ons ontleerder bereik baie mededingsresultate vir Engels en Sjinees. Om die verwerking van uitwerking op kruisdomein-teks te verbeter, voorstel ons 'n data-orienteerde metode om die lingwisiese generelheid wat in Engelske hulpbron Grammar gekodeer is, wat is 'n presisie orienteerde, hand-grafte HPSG grammatiek, op 'n inplisite manier. Eksperimente wys die effektiviteit van ons data-orienteerde metode oor 'n wyde reek van voorwaardes.", 'sq': "Ne paraqesim eksperimente për analizën e varësisë semantike me një analizues neuronal Maximum Subgraph. Analizatori ynë synon kalimin e 1-pikës së fundit, faqen numër-2 grafikë që janë të përshtatshëm për grafikët semantike të varësisë dhe përdorin një algoritëm të programimit dinamik të efektshëm për dekodimin. Për çambiguacion, analizuesi bashkon fjalët me vektorët BiLSTM dhe përdorë këto vektorë për t'u caktuar rezultate varësive të kandidatëve. Ne kryejmë eksperimente në grupet e të dhënave nga SemEval 2015 si dhe CCGBank kineze. Analizatori ynë arrin rezultate shumë konkurruese si për anglishtin ashtu edhe për kinezën. Për të përmirësuar paraqitjen e analizimit të teksteve transdomenale, ne propozojmë një metodë të orientuar në të dhëna për të eksploruar gjeneralitetin gjuhësore të koduar në Gramën Angleze të burimeve, e cila është një gramatikë HPSG të orientuar në preçizion, me dorë, në një mënyrë implicitete. Eksperimentet tregojnë efektshmërinë e metodës tonë të orientuar ndaj të dhënave nëpër një gamë të gjerë kushteve.", 'am': 'የዳሜን ስሜናዊ ጥያቄ መፍትሄ ማተሚያ እናደርጋለን፡፡ Our parser targets 1-endpoint-crossing, pagenumber-2 graphs which are a good fit to semantic dependency graphs, and utilizes an efficient dynamic programming algorithm for decoding.  ለመግለጫ፣ መተማሪ ቃላትን ከቢልSTM vector ጋር ያጋራል እናም እነዚህን vectors ለመናዳጆች ተሟጋቾችን እንዲሰጥ ይጠቅማል፡፡ ከሴmEval 2015 እና ከቻይና CCGBank የዳታ ሰርቨሮች ፈተናዎችን እናደርጋለን፡፡ በንግግሊዝና በቻይናዊ እና ተቃዋሚ ፍሬዎችን አግኝቷል፡፡ በኩል-ዶሜን ጽሑፎች ላይ የፓርቲውን ማስታወቂያ ለማድረግ፣ በንግግሊዝኛ resource گراማር የቋንቋዊ የቋንቋ አዳራሲነትን ለመፈለግ እናስመክራለን፡፡ ፈተናዎች የዳታ-አካሄዱን ሥርዓት በብዙ ሥርዓት ላይ የሚያሳየው ነው፡፡', 'tr': 'Biz çoklu domain semantik bağlılılık analizi için deneyleri nöral Maksimum Subgraf çözümleyicisi ile sunuyoruz. Biziň tansçymyz 1-endpoint-crossing, pagenumber-2 grafikleri semantik baglançylyk grafiklerine gowy ýazmak üçin hedef alýar we çykyş etmek üçin etkinlik dinamik programlama algoritmini ulanýar. Çevirmek üçin, tansçör BiLSTM vektörleri ile sözleri birleştirir ve bu vektörleri kandidat bağlılıklarına rakam almak için kullanır. Biz SemEval 2015-nji ýyldan we Çinçe CCGBank sahypalarynda surat çykýarys. Biziň çykyşymyz iňlisçe we Çinçe üçin örän ýaryşykly netijeleri ýetip bilýär. Çoklu-domenyň metinlerinde a ýdym şeklini geliştirmek üçin, Iňlisçe Ressours Grammarda kodlanan lingwistiki jemgyýetini gözlemek üçin, elimizden gelen HPSG gramatiýasy bar. Denminatlar biziň data yöntemimiziň etkinliýetimizi birnäçe şartlaryň daşyrylygyny görkez.', 'hy': "We present experiments for cross-domain semantic dependency analysis with a neural Maximum Subgraph parser.  Մեր խմբագրիչը նպատակում է 1-վերջնական կետի խաչը, էջի-2 գրաֆիկները, որոնք լավ համապատասխանում են սեմանտիկ կախվածության գրաֆիկներին և օգտագործում են արդյունավետ դինամիկ ծրագրավորումների ալգորիթմ կոդավորման համար: Բացատրելու համար վերլուծումը կապում է բառերը ԲիԼՍՏՄ վեկտորների հետ և օգտագործում է այս վեկտորները' գնահատելու համար թեկնածու կախվածություններին: Մենք կատարում ենք փորձարկումներ, որոնք տեղեկատվական համակարգերի վրա են կատարվել 2015 թվականին, ինչպես նաև Չինաստանի ԿԿԳԲՆ-ից: Մեր խմբագրողը շատ մրցակցության արդյունքներ է ստանում անգլերենի և չինարենի համար: Անգլերենի ռեսուրսների գրամարում կոդավորված լեզվաբանական ընդհանրությունը բացահայտելու համար մենք առաջարկում ենք տվյալներով հիմնված մեթոդ, որը պարզ ձևով հիմնված է ճշգրտությամբ, ձեռքով ստեղծված ՀՊՍԳ գրամարում: Փորձերը ցույց են տալիս մեր տվյալներով հիմնված մեթոդի արդյունավետությունը տարբեր պայմաններում:", 'az': 'Biz çox-domani semantik bağlılıq analizi üçün nöral Maksimum Subgraf analizi ilə təşviq edirik. Bizim parçacımız 1-endpoint-crossing, pagenumber-2 grafikləri, semantik bağlılıq grafiklərinə uyğun və dekodin üçün etkili dinamik programlama algoritmi istifadə edir. Dezambinasyon üçün, ayırıcı BiLSTM vektörləri ilə sözləri birləşdirir və bu vektörləri kandidat bağlılıqlarına nöqtələri vermək üçün istifadə edir. Biz 2015-ci SemEval tərəfindən və Çin CCGBank tərəfindən verilən tərəflər barəsində təcrübə edirik. Bizim ayırıcımız İngilizce və Çincə üçün çox müəllif sonuçlarını başarır. İngiliz Ressource Grammar vasitəsilə kodlanmış dillərin çoxluğunu keşfetmək üçün çoxluğu dəyişiklik məlumatlarında təmizlənmək üçün, əl-təmizlənmiş HPSG grammatik vasitəsilə, əl-təmizlənmiş dillərin çoxluğunu keşfetməsi üçün təklif edirik. Həqiqətən, təcrübələrimiz verilər tərəfindən tərəf yönəlmiş metodların müxtəlif bir səviyyədə təşkil edilməsini göstərir.', 'bn': 'নিউরেল সর্বোচ্চ সাব্রাগ্রাফ প্যারাসের সাথে ক্রাস্ট ডোমেইনের সেমান্টিক নির্ভরশীল বিশ্লেষণের পরীক্ষ আমাদের বিশ্লেষকের লক্ষ্য হচ্ছে ১-এনডেন্ট পয়েন্ট পার করা, প্যাগন্টাম্বার-২ গ্রাফ, যা সেম্যান্টিক নির্ভরিত গ্রাফের জন্য ভালো যোগ্য এবং ডি For disambiguation, the parser associates words with BiLSTM vectors and utilizes these vectors to assign scores to candidate dependencies.  আমরা সেমইভাল ২০১৫ সাল থেকে তথ্য সেট এবং চীনা সিসিজিব্যাংকের পরীক্ষার পরীক্ষা করছি। ইংরেজি এবং চীনা উভয়ের জন্য আমাদের প্রতিযোগিতার ফলাফল পেয়েছে। ক্রিডমেইন টেক্সট সম্পর্কে পার্সিং প্রদর্শনের প্রভাব উন্নত করার জন্য আমরা একটি তথ্য-দৃষ্টিভঙ্গিত পদ্ধতি প্রস্তাব করি ইংরেজি রিসোর্স গ্রামারে যে ভাষার জেনারেলিটিকেটি বিশে পরীক্ষাগুলো আমাদের তথ্য-দৃষ্টিপূর্ণ পদ্ধতির কার্যক্রম প্রদর্শন করেছে বিশেষ পরিস্থিতির মধ্যে।', 'bs': 'Predstavljamo eksperimente za semantičku analizu zavisnosti preko domena sa neuralnim maksimalnim podgrafom analizujem. Naš analizator cilja na prelazak 1-krajnja tačka, grafike broja 2 koji su dobri odgovarajući graficima semantičke zavisnosti i koristi efikasni dinamički algoritam programiranja za dekodiranje. Za disambiguaciju, analizator povezuje riječi sa vektorima BiLSTM i koristi ove vektore za dodavanje rezultata zavisnosti kandidata. Provodimo eksperimente o setima podataka iz SemEval 2015, kao i Kineskoj CCGBank. Naš analizator postiže vrlo konkurentne rezultate za engleski i kineski. Da bi poboljšali učinkovitost analize na tekstima preko domena, predlažemo metodu orijentiranu na podatke da istražimo jezičku generalnost kodiranu na engleskom Grammaru resursa, koja je precizno orijentirana gramatika HPSG-a na ruku, na implicitni način. Eksperimenti pokazuju učinkovitost našeg metoda orijentiranog na podatke u širokom nizu uvjeta.', 'ca': "Presentam experiments per a l'anàlisi de dependencia semàntica transdomínica amb un analitzador neuronal Maximum Subgraph. El nostre analitzador mira gràfics de cruzament d'un punt final, pàgina número-2 que són adequats a gràfics de dependencia semàntica, i utilitza un algoritme de programació dinàmica eficient per descodificar. Per desambiguació, l'analitzador associa paraules amb els vectors BiLSTM i utilitza aquests vectors per assenyar puntuacions a les dependencies candidates. Fem experiments en els conjunts de dades de SemEval 2015 i la CCGBank xinesa. El nostre analitzador aconsegueix resultats molt competitius tant per anglès com per xinès. Per millorar el rendiment d'analització dels textos transdomínics, proposem un mètode orientat a les dades per explorar la generalitat lingüística codificada en English Resource Grammar, una gramàtica HPSG orientada a la precisió, de manera implícita. Experiments demonstrate the effectiveness of our data-oriented method across a wide range of conditions.", 'et': 'Esitleme valdkondadevahelise semantilise sõltuvuse analüüsi eksperimente neuraalse maksimaalse alamgraafi parseriga. Meie parser sihib 1-lõpp-ristamise, leheküljenumbri-2 graafikuid, mis sobivad hästi semantilistele sõltuvusgraafidele ja kasutab dekodeerimiseks tõhusat dünaamilist programmeerimisalgoritmi. Selgitamiseks seostab parser sõnu BiLSTM vektoritega ja kasutab neid vektoreid kandidaadi sõltuvustele skooride määramiseks. Teostame katseid SemEval 2015 ja Hiina CCGBanki andmekogumitega. Meie parser saavutab väga konkurentsivõimelised tulemused nii inglise kui hiina keeles. Selleks et parandada domeenidevaheliste tekstide parsimist, pakume välja andmepõhise meetodi, et uurida inglise ressursigrammatikas kodeeritud keelelist üldisust, mis on täpsusele orienteeritud, käsitsi valmistatud HPSG grammatika kaudsel viisil. Katsed näitavad meie andmetele orienteeritud meetodi tõhusust paljudes tingimustes.', 'cs': 'Představujeme experimenty pro cross-doménovou sémantickou analýzu závislosti s neuronovým parserem Maximum Subgraph. Náš parser se zaměřuje na 1-koncové křížení, číslo-2 grafy, které jsou dobré pro sémantické grafy závislosti, a využívá efektivní dynamický programovací algoritmus pro dekódování. Pro rozšíření, parser spojuje slova s BiLSTM vektory a používá tyto vektory k přiřazení skóre kandidátovým závislostem. Provádíme experimenty na datových sadách SemEval 2015 a čínského CCGBanku. Náš parser dosahuje velmi konkurenčních výsledků pro angličtinu i čínštinu. Pro zlepšení analýzy textů mezi doménami navrhujeme datově orientovanou metodu pro implicitní zkoumání jazykové obecnosti kódované v anglické gramatice zdrojů, což je precizně orientovaná, ručně vytvořená HPSG gramatika. Experimenty demonstrují efektivitu naší datově orientované metody v široké škále podmínek.', 'fi': 'Esitämme kokeita eri toimialueiden semanttisen riippuvuuden analyysiin neurologisella Maximum Subgraph -parserilla. Analysoijamme kohdistaa 1-päätepisteen risteykseen, sivunumero-2-kaavioihin, jotka sopivat hyvin semanttisiin riippuvuusgraffeihin, ja käyttää tehokasta dynaamista ohjelmointialgoritmia dekoodaamiseen. Selitystä varten jäsentäjä yhdistää sanat BiLSTM-vektoreihin ja käyttää näitä vektoreita pisteiden antamiseen ehdokkaiden riippuvuuksille. Teemme kokeiluja SemEval 2015:n ja kiinalaisen CCGBankin aineistoilla. Analysoijamme tuottaa erittäin kilpailukykyisiä tuloksia sekä englanniksi että kiinaksi. Parantaaksemme eri toimialueiden tekstien jäsentämistä ehdotamme datalähtöistä menetelmää, jolla tutkitaan implisiittisesti englanninkieliseen resurssikirjaimeen koodattua kielellistä yleisyyttä, joka on tarkka, käsin valmistettu HPSG-kielioppi. Kokeet osoittavat datalähtöisen menetelmämme tehokkuuden monenlaisissa olosuhteissa.', 'jv': 'We present testing for inter-domain semanti-diphensible measurement with a Neral maximum Subgraphmeter meter. Anyone Ngubah Awak dhéwé éntuk éntuk perbudhakan kanggo nggawe data sethaya sak semebal 2013 lan tambah Chinese C GLine. Rasané awak dhéwé iso nglanggar tarjamahan kanggo ngwalé Inggris karo Cainan. To advance the PASSing success on inter Where am I', 'he': 'אנחנו מציגים ניסויים עבור ניתוח תלויות סמנטית בין תחומות עם מעבד התחתונים המקסימום העצבי. המחקר שלנו ממטרה לחצות נקודת סוף 1, גרפים עמוד מספר 2 שהם מתאימים טוב לגרפים של תלויות סמנטיות, ומשתמשים באלגוריתם תוכנית דינמית יעיל לפיתוח. For disambiguation, the parser associates words with BiLSTM vectors and utilizes these vectors to assign scores to candidate dependencies.  אנחנו מבצעים ניסויים על קבוצות הנתונים מ-SemEval 2015, כמו גם CCGBank סיני. המחקר שלנו משיג תוצאות תחרותיות מאוד לאנגלית וסינית. כדי לשפר את ביצועי המחקר על טקסטים מעבר לתחום, אנו מציעים שיטה ממוקדת על נתונים הניסויים מראים את היעילות של השיטה המאויינת למידע שלנו במרחק מגוון רחב של תנאים.', 'ha': "Tuna gabatar da jarrabo dõmin an yi anadi ga mai ƙaranci na semantic a tsakanin-Domen da wani neural da maximum Subgraph Parser. Parser ɗin Mu yi amfani da algoritm na shiryoyin ayuka da aka yi amfani da shi ga kodi. @ info: whatsthis Tuna samun jarrabãwa a kan data-set daga Semeval 2015 da kuma CCGBank na China. Babu fassararmu ta sami matsala mai ƙidido ga Ingiriya da China. To, dõmin ya kyautata fasalin paring kan mistakardar-mutane, Munã buɗe wata metode da aka danne-orientated zuwa-zane zuwa a ƙidãya ga littafin linguistic na'urar Kilimanci, wanda ya zama na ƙayyade, grammar HPSG da hannuwansa. Tajarakin sun nuna aikin hanyoyinmu da aka danne shi a cikin wasu mazaɓa mai tsawo.", 'sk': 'Predstavljamo poskuse za analizo meddomenske semantične odvisnosti z nevronskim razčlenjevalnikom Maksimum Subgraph. Naš razčlenjevalnik cilja na 1-končno križanje, število strani-2 grafe, ki se dobro prilegajo semantičnim grafom odvisnosti in uporablja učinkovit dinamični programski algoritem za dekodiranje. Za razjasnitev razčlenjevalnik povezuje besede z vektorji BiLSTM in uporablja te vektorje za dodeljevanje ocen kandidatnim odvisnostim. Izvajamo poskuse na naborih podatkov SemEval 2015 in kitajski CCGBank. Naš parser dosega zelo konkurenčne rezultate za angleščino in kitajščino. Za izboljšanje učinkovitosti razčlenitve meddomenskih besedil predlagamo podatkovno usmerjeno metodo za raziskovanje jezikovne splošnosti, kodirane v angleški slovnici virov, ki je natančno usmerjena, ročno izdelana slovnica HPSG, implicitno. Eksperimenti dokazujejo učinkovitost naše podatkovno usmerjene metode v številnih pogojih.', 'bo': 'We present experiments for cross-domain semantic dependency analysis with a neural Maximum Subgraph parser. Our parser targets 1-endpoint-crossing, pagenumber-2 graphs which are a good fit to semantic dependency graphs, and utilizes an efficient dynamic programming algorithm for decoding. For disambiguation, the parser associates words with BiLSTM vectors and utilizes these vectors to assign scores to candidate dependencies. ང་ཚོས་ས SemEval 2015 དང་རྒྱ་ནག་གི་CCGBank་ནས་གསལ་བཤད་བྱས་པའི་ཆ་འཕྲིན་ཡིག་ཆ་ལ་ལས་བརྟན་དཔྱད་བྱས་པ་ཡིན། ང་ཚོའི་དབྱིན་ཡིག་དང་རྒྱ་ནག་གཉིས་ཀྱིས་ཐོག་འཕྲུལ་རྒྱལ་ཁབ་ཆེན་པོ་རེད། To improve the parsing performance on cross-domain texts, we propose a data-oriented method to explore the linguistic generality encoded in English Resource Grammar, which is a precisionoriented, hand-crafted HPSG grammar, in an implicit way. Experiments demonstrate the effectiveness of our data-oriented method across a wide range of conditions.'}
{'en': 'CEA LIST : Processing Low-Resource Languages for CoNLL 2018', 'ar': 'CEA LIST: معالجة اللغات منخفضة الموارد لـ CoNLL 2018', 'fr': 'CEA LIST\xa0: Traitement des langues à faibles ressources pour ConLL 2018', 'es': 'LISTA CEA: Procesamiento de lenguajes de bajos recursos para CoNll 2018', 'pt': 'LISTA CEA: Processando linguagens de poucos recursos para CoNLL 2018', 'ja': 'CEAリスト： CoNLL 2018のための低リソース言語の処理', 'zh': 'CEA LIST: CoNLL 2018 低资源言', 'hi': 'सीईए सूची: CoNLL 2018 के लिए कम संसाधन भाषाओं को संसाधित करना', 'ru': 'ПЕРЕЧЕНЬ CEA: Обработка малоресурсных языков для CoNLL 2018', 'ga': 'LIOSTA CEA: Teangacha Ísle-Acmhainne a Phróiseáil le haghaidh CoNLL 2018', 'ka': 'CEA LIST: CoNLL 2018-ის მიმართ რესურსის ენების პროცესი', 'el': 'Κατάλογος CEA: Επεξεργασία γλωσσών χαμηλής περιεκτικότητας σε πόρους για το CoNLL 2018', 'hu': 'CEA LISTA: Alacsony erőforrású nyelvek feldolgozása a CoNLL 2018 számára', 'lt': 'CEA LIST: Processing Low-Resource Languages for CoNLL 2018', 'kk': 'CEA LIST: CoNLL 2018 үшін төмен ресурс тілдерін өңдеу', 'it': 'CEA LIST: Elaborazione di linguaggi a basso contenuto di risorse per CoNLL 2018', 'ml': 'CEA LIST: Processing Low-Resource Languages for CoNLL 2018', 'mt': 'CEA LIST: Processing Low-Resource Languages for CoNLL 2018', 'mn': 'CEA LIST: CoNLL 2018 оны CoNLL-ийн бага нөөцийн хэл', 'no': 'CEA LIST: Prosesserer låg ressursspråk for CoNLL 2018', 'mk': 'CEA LIST: Процесирање на јазици со ниски ресурси за CoNLL 2018', 'pl': 'LIST CEA: Przetwarzanie języków niskich zasobów dla CoNLL 2018', 'ro': 'Lista CEA: Procesarea limbilor cu resurse reduse pentru CoNLL 2018', 'sr': 'CEA LIST: Proveravanje jezika niskog resursa za CoNLL 2018.', 'so': 'CEA LIST: Processing Low-Resource Languages for CoNLL 2018', 'ms': 'Senarai CEA: Memproses Bahasa Sumber Terrendah untuk CoNLL 2018', 'sv': 'CEA LIST: Bearbetning av lågresursspråk för CoNLL 2018', 'ta': 'CEA LIST: CoNLL 2018க்கான குறைந்த மூலத்தின் மொழிகள்', 'ur': 'CEA LIST: CoNLL 2018 کے لئے کم-Resource زبانیں پرسس کرتی ہیں', 'si': 'CEA LIST: CoNLL 2018 වෙනුවෙන් අඩු සම්බන්ධ භාෂාව ප්\u200dරක්\u200dරියාපනය කරන්න', 'uz': 'CEA LIST: CoNLL 2018 uchun Qisqa manba tillar', 'vi': 'Thượng lộ Giao Dịch Công Nguyên Lão Lục Huyền Tâm', 'bg': 'Списък на ЦЕА: Обработка на нискоресурсни езици за CoNLL 2018', 'hr': 'CEA LIST: Proizvodnja jezika niskog resursa za CoNLL 2018.', 'nl': 'CEA LIST: Verwerking van talen met lage hulpbronnen voor CoNLL 2018', 'da': 'CEA LIST: Behandling af lav ressource sprog til CoNLL 2018', 'id': 'CEA LIST: memproses bahasa sumber daya rendah untuk CoNLL 2018', 'fa': 'CEA LIST: تحلیل کردن زبانهای کم منابع برای CoNLL 2018', 'de': 'CEA LIST: Verarbeitung ressourcenarmer Sprachen für CoNLL 2018', 'ko': 'CEA 목록: 2018년 CoNLL 대회용 저자원 언어 처리', 'sw': 'CEA LIST: Processing Low-Resource Languages for CoNLL 2018', 'tr': 'CEA LIST: CoNLL 2018 üçin Az-Ressurat Dilleri işleýär', 'sq': 'CEA LIST: Procesimi i gjuhëve me burime të ulta për CoNLL 2018', 'af': 'CEA LIST: Verwerking Lae- Hulpbron Taal vir CoNLL 2018', 'hy': 'CEA ԼԻՍՏ. Նվագ ռեսուրսների լեզուների վերաբերյալ CONSL 2018-ի համար', 'az': 'CEA LIST: CoNLL 2018 üçün Low-Resource Dilləri işləyir', 'am': 'CEA LIST: Processing Low-Resource Languages for CoNLL 2018', 'bn': 'সিয়া লিস্ট: কনএল ২০১৮-এর জন্য নিম্ন-সম্পদ ভাষা প্রক্রিয়া', 'ca': 'LISTA CEA: Procesar llengües de baix recursos per CoNLL 2018', 'bs': 'CEA LIST: Proveravanje jezika niskog resursa za CoNLL 2018.', 'cs': 'CEA LIST: Zpracování jazyků s nízkými zdroji pro CoNLL 2018', 'et': 'CEA nimekiri: madala ressursiga keelte töötlemine CoNLL 2018 jaoks', 'fi': 'CEA LIST: Vähävaraisten kielten käsittely CoNLL 2018', 'he': 'LIST CEA: מעבד שפות משאבים נמוכות עבור CoNLL 2018', 'ha': 'KCharselect unicode block name', 'sk': 'CEA SEZNAM: Obdelava jezikov z nizkimi viri za CoNLL 2018', 'jv': 'CeA LISTA: Gak Perusahaan langgambar Gak-Resolusi kanggo CoNLL 2008', 'bo': 'CEA LIST: CoNLL 2018 ཡི་སྤྱོད་ཀྱི་ཆ་རྐྱེན་ཆུང་བའི་སྐད་ཡིག་རེད'}
{'en': 'In this paper, we describe the ', 'fr': "Dans cet article, nous décrivons le système utilisé pour notre première participation à la tâche partagée ConLL 2018. Le système soumis a largement réutilisé l'analyseur de pointe de ConLL 2017 (< https://github.com/tdozat/Parser-v2 >). Nous avons amélioré ce système pour les prévisions des caractéristiques morphologiques et nous avons utilisé toutes les ressources disponibles pour fournir des modèles précis pour les langues à faibles ressources. Nous nous sommes classés 5e sur 27 participants au MLAS pour la création d'arbres de dépendance sensibles à la morphologie, 2e pour les caractéristiques morphologiques uniquement et 3e pour le balisage (UPOS) et l'analyse syntaxique (LAS) des langages à faible ressource.", 'es': 'En este artículo, describimos el sistema utilizado para nuestra primera participación en la tarea compartida de CoNll 2018. El sistema presentado reutilizó en gran medida el analizador avanzado de CoNll 2017 (< https://github.com/tdozat/Parser-v2 >). Mejoramos este sistema para las predicciones de características morfológicas y utilizamos todos los recursos disponibles para proporcionar modelos precisos para lenguajes de bajos recursos. Ocupamos el quinto lugar de 27 participantes en MLAS por la construcción de árboles de dependencias sensibles a la morfología, el segundo lugar solo para las características morfológicas y el tercero por el etiquetado (UPOS) y el análisis (LAS) de lenguajes de bajos recursos.', 'ar': 'في هذه الورقة ، نصف النظام المستخدم في مشاركتنا الأولى في المهمة المشتركة CoNLL 2018. أعاد النظام المقدم استخدام المحلل اللغوي الحديث من CoNLL 2017 (<https://github.com/tdozat/Parser-v2>). لقد عززنا هذا النظام لتنبؤات السمات المورفولوجية ، واستخدمنا جميع الموارد المتاحة لتقديم نماذج دقيقة للغات منخفضة الموارد. لقد احتلنا المرتبة الخامسة من بين 27 مشاركًا في MLAS لبناء أشجار تبعية مدركة للمورفولوجيا ، والثاني للسمات المورفولوجية فقط ، والثالث لوضع العلامات (UPOS) والتحليل (LAS) للغات منخفضة الموارد.', 'pt': 'Neste artigo, descrevemos o sistema usado para nossa primeira participação na tarefa compartilhada CoNLL 2018. O sistema enviado reutilizou amplamente o analisador de última geração do CoNLL 2017 (<https://github.com/tdozat/Parser-v2>). Aprimoramos esse sistema para previsões de características morfológicas e usamos todos os recursos disponíveis para fornecer modelos precisos para linguagens de poucos recursos. Classificamos em 5º de 27 participantes no MLAS para a construção de árvores de dependência com reconhecimento de morfologia, 2º apenas para recursos morfológicos e 3º para linguagens de baixo recurso de marcação (UPOS) e análise sintática (LAS).', 'hi': 'इस पेपर में, हम CoNLL 2018 साझा कार्य में हमारी पहली भागीदारी के लिए उपयोग की जाने वाली प्रणाली का वर्णन करते हैं। प्रस्तुत प्रणाली ने काफी हद तक CoNLL 2017 (<https://github.com/tdozat/Parser-v2>) से कला पार्सर की स्थिति का पुन: उपयोग किया। हमने रूपात्मक सुविधाओं की भविष्यवाणियों के लिए इस प्रणाली को बढ़ाया, और हमने कम संसाधन वाली भाषाओं के लिए सटीक मॉडल प्रदान करने के लिए सभी उपलब्ध संसाधनों का उपयोग किया। हमने आकारिकी जागरूक निर्भरता पेड़ों के निर्माण के लिए MLAS में 27 प्रतिभागियों में से 5 वें स्थान पर रखा, केवल रूपात्मक विशेषताओं के लिए दूसरा, और टैगिंग (UPOS) और पार्सिंग (एलएएस) कम संसाधन भाषाओं के लिए तीसरा स्थान दिया।', 'ja': '本稿では、CoNLL 2018の共有タスクへの初参加に使用されたシステムについて説明する。提出されたシステムは、CoNLL (2017<https://github.com/tdozat/Parser-v2>)からの最先端の構文解析器をほぼ再利用したものである。このシステムは形態学的特徴の予測のために強化され、利用可能なすべてのリソースを使用して、低リソース言語の正確なモデルを提供しました。我々は、形態学的に認識された依存関係ツリーを構築するためのMLAの27人の参加者のうち5位、形態学的特徴のみの2位、低リソース言語のタグ付け（ UPOS ）および解析（ LAS ）の3位にランク付けした。', 'zh': '于本文,述首参CoNLL 2018共享之统。 提交之统大用CoNLL 2017(<https://github.com/tdozat/Parser-v2>)之最先进者解析器。 增此以形,而用其所以为低资源言。 MLAS 之 27 名参与者,形之所恃者排名第 5 ,形之所排名第 2 者,记 (UPOS) 解析 (LAS) 卑资言者排名第 3 位。', 'ru': 'В этой статье мы описываем систему, используемую для нашего первого участия в совместной задаче CoNLL 2018. Представленная система в значительной степени повторно использовала современный парсер от CoNLL 2017 (<https://github.com/tdozat/Parser-v2>). Мы усовершенствовали эту систему для прогнозирования морфологических признаков и использовали все доступные ресурсы для предоставления точных моделей для языков с низким уровнем ресурсов. Мы заняли 5-е место из 27 участников MLA для построения деревьев зависимостей, осведомленных о морфологии, 2-е для только морфологических признаков и 3-е для тегов (UPOS) и синтаксического анализа (LAS) малоресурсных языков.', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar an gcóras a úsáideadh dár gcéad rannpháirtíocht i dtasc comhroinnte CoNLL 2018. D’athúsáid an córas a cuireadh isteach parsálaí úrscothach den chuid is mó ó CoNLL 2017 (<https://github.com/tdozat/Parser-v2>). Chuireamar feabhas ar an gcóras seo chun gnéithe moirfeolaíocha a thuar, agus d’úsáideamar na hacmhainní go léir a bhí ar fáil chun múnlaí cruinne a sholáthar do theangacha íseal-acmhainne. Rinneamar an 5ú háit as 27 rannpháirtí i MLAS maidir le crainn spleáchais atá feasach ar mhoirfeolaíocht a thógáil, sa 2ú háit maidir le gnéithe moirfeolaíocha amháin, agus sa 3ú háit maidir le teangacha íseal-acmhainne clibeála (UPOS) agus parsála (LAS).', 'el': 'Στην παρούσα εργασία περιγράφουμε το σύστημα που χρησιμοποιήθηκε για την πρώτη μας συμμετοχή στο κοινό έργο. Το υποβαλλόμενο σύστημα επαναχρησιμοποίησε σε μεγάλο βαθμό τον υπερσύγχρονο επεξεργαστή από το CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Βελτιώσαμε αυτό το σύστημα για προβλέψεις μορφολογικών χαρακτηριστικών και χρησιμοποιήσαμε όλους τους διαθέσιμους πόρους για να παρέχουμε ακριβή μοντέλα για γλώσσες χαμηλής περιεκτικότητας. Καταθέσαμε 5ους από τους 27 συμμετέχοντες στο MLAS για την οικοδόμηση δέντρων εξάρτησης με γνώμονα τη μορφολογία, δεύτερους για μορφολογικά χαρακτηριστικά μόνο και τρίτους για την επισήμανση (UPOS) και ανάλυση (LAS) γλωσσών χαμηλού πόρου.', 'hu': 'Ebben a tanulmányban ismertetjük a CoNLL 2018 közös feladatán való első részvételünkhöz használt rendszert. A benyújtott rendszer nagyrészt újra felhasználta a CoNLL 2017 legkorszerűbb elemzőjét (< https://github.com/tdozat/Parser-v2 >).  Ezt a rendszert továbbfejlesztettük a morfológiai jellemzők előrejelzésére, és minden rendelkezésre álló erőforrást felhasználtunk arra, hogy pontos modelleket biztosítsunk az alacsony erőforrású nyelvek számára. Az MLAS 27 résztvevője közül 5. helyezést kaptunk a morfológiai tudatos függőségi fák építésében, a 2. helyezést kizárólag morfológiai jellemzők tekintetében, a 3. helyezést pedig a címkézés (UPOS) és az alacsony erőforrású elemzési (LAS) nyelvek tekintetében.', 'ka': 'ამ დომენტში ჩვენ აღწერეთ სისტემა, რომელიც ჩვენი პირველი დაწყვეტილებაში გამოყენებულია CoNLL 2018-ში. შეტყობინებული სისტემა უფრო მეტად გამოიყენება ხელსაწყოთა პანუზერის სტატუსის 2017-დან (< https://github.com/tdozat/Parser-v2 >). ჩვენ ამ სისტემის მოპოროლოგიური ფუნქციების წარმოდგენებისთვის უფრო მეტივად გამოყენეთ, და ჩვენ ყველა ხელმისაწარმოდგენი რესურსების გამოყენეთ მარ ჩვენ მივიღეთ MLAS-ის 27-ის მონაცემულების 5მე წერტილი, რომელიც მორფოლოგიური განსაცემულობების ხელების შექმნა, მეორე მხოლოდ მორფოლოგიური განსაცემულობებისთვის, მეორე მხოლოდ მორფოლოგი', 'it': "In questo articolo descriviamo il sistema utilizzato per la nostra prima partecipazione al compito condiviso CoNLL 2018. Il sistema presentato ha ampiamente riutilizzato il parser all'avanguardia di CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Abbiamo migliorato questo sistema per le previsioni delle caratteristiche morfologiche e abbiamo utilizzato tutte le risorse disponibili per fornire modelli accurati per linguaggi a basso contenuto di risorse. Abbiamo classificato il quinto dei 27 partecipanti in MLAS per la costruzione di alberi di dipendenza consapevoli della morfologia, il secondo solo per le caratteristiche morfologiche e il terzo per i linguaggi di tagging (UPOS) e parsing (LAS) a basso contenuto di risorse.", 'kk': 'Бұл қағазда бірінші қатынасыз үшін бірінші қатынасыз үшін қолданылатын жүйеңізді баяндаймыз. Келтірілген жүйе 2017 CoNLL- ден орындаушы талдаушының күйін қайта қолданылады (< https://github.com/tdozat/Parser-v2 >). Бұл жүйені морфологиялық мүмкіндіктерді таңдау үшін көтеріп, барлық қол жеткізетін ресурстарды төмен ресурстар тілдеріне дұрыс үлгілер беру үшін қолдандық. Біз MLAS 27 қатысушыларының 5- ші ретінде морфологиялық тәуелсіздік ағаштарын құру үшін, 2- ші морфологиялық қасиеттері үшін, 3- ші ретінде мәліметтер (UPOS) және талдау (LAS) тілдері тө', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d നമ്മുടെ ആദ്യത്തെ പങ്കെടുക്കാന്\u200d ഉപയോഗിക്കുന്ന സിസ്റ്റം വിവരിച്ചുകൊടുക്കുന്നു. ക സമ്മാനിച്ച സിസ്റ്റം കോNLL 2017-ല്\u200d നിന്നും ആര്\u200dട്ട് പരാജയപ്രകാരം പൂര്\u200dണ്ണമായും ഉപയോഗിക്കുന്നു https://github.com/tdozat/Parser-v2 >). ഞങ്ങള്\u200d ഈ സിസ്റ്റം മോര്\u200dഫോളിക്കല്\u200d പ്രവചനങ്ങള്\u200dക്കുള്ള പ്രവചനങ്ങള്\u200dക്ക് വേണ്ടി വളര്\u200dത്തിയിരിക്കുന്നു. ഞങ്ങള്\u200d എല്ലാ വിഭവങ്ങള We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.', 'mk': 'Во овој весник го опишуваме системот кој се користи за нашето прво учество во заедничката задача на CoNLL 2018. Предложениот систем во голема мера го повторно употреби најдобриот анализатор од CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Го зајакнавме системот за предвидувања на морфолошки карактеристики, и ги искористивме сите достапни ресурси за да обезбедиме прецизни модели за јазици со ниски ресурси. We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.', 'ms': 'Dalam kertas ini, kami menggambarkan sistem yang digunakan untuk berpartisipasi pertama kami di tugas kongsi CoNLL 2018. Sistem yang dihantar kebanyakan menggunakan semula penghurai kemajuan dari CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Kami meningkatkan sistem ini untuk ramalan ciri-ciri morfologi, dan kami menggunakan semua sumber yang tersedia untuk menyediakan model yang tepat untuk bahasa sumber rendah. Kami menandakan ke-5 dari 27 peserta dalam MLAS untuk membina pokok dependensi sedar morfologi, ke-2 untuk ciri-ciri morfologi sahaja, dan ke-3 untuk menandai (UPOS) dan menghurai (LAS) bahasa sumber rendah.', 'mt': 'F’dan id-dokument, aħna niddeskrivu s-sistema użata għall-ewwel parteċipazzjoni tagħna fil-kompitu komuni CoNLL 2018. Is-sistema sottomessa fil-biċċa l-kbira użat mill-ġdid l-aktar parser tal-aħħar mill-CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Aħna tejbna din is-sistema għat-tbassir tal-karatteristiċi morfoloġiċi, u użajna r-riżorsi kollha disponibbli biex nipprovdu mudelli preċiżi għal lingwi b’riżorsi baxxi. Aħna kklassifikajna l-ħames mis-27 parteċipant fl-MLAS għall-bini ta’ siġar ta’ dipendenza konxji mill-morfoloġija, it-tieni għal karatteristiċi morfoloġiċi biss, u t-tielet għal-ittikkettjar (UPOS) u l-analiżi (LAS) ta’ lingwi b’riżorsi baxxi.', 'lt': 'Šiame dokumente apibūdinama sistema, naudojama pirmajam dalyvavimui bendroje CoNLL 2018 m. užduotyje. Pateikta sistema iš esmės pakartotinai naudojo naujausią CoNLL 2017 m. analizatorių (< https://github.com/tdozat/Parser-v2 >). Mes patobulinome šią morfologinių savybių prognozių sistemą ir panaudojome visus turimus išteklius, kad sukurtume tikslius mažai išteklių turinčių kalbų modelius. Mes klasifikuojame penktą iš 27 MLAS dalyvių kurdami morfologiją žinomus priklausomybės medžius, antrą – tik morfologines savybes ir trečią – žymėjimą (UPOS) ir analizavimą (LAS) mažai išteklių turinčiomis kalbomis.', 'mn': 'Энэ цаасан дээр бид 2018 оны CoNLL-ын хуваалцах ажлын анхны оролцоонд хэрэглэгдсэн системийг тайлбарлаж байна. Шинэ хэмжээний систем 2017 оны CoNLL-ын урлаг хуваарилагчийн байр суурь дахин ашиглаж байна (< https://github.com/tdozat/Parser-v2 >). Бид энэ системийг морфологик чанарын таамаглалтын тулд нэмэгдүүлсэн бөгөөд бид бүх боломжтой мөнгө ашиглаж бага боловсролын хэл дээр зөв загварыг хангахад ашигласан. Бид MLAS-ын 27 оролцогчдын 5-р ангид морфологид хамааралтай мод бүтээхэд, 2-р нь морфологикийн хувьд зөвхөн мөн 3-р нь бага боломжтой хэлнүүд (UPOS) болон хуваалцах (LAS) хэлнүүдийг бүтээхэд зо', 'pl': 'W niniejszym artykule opisujemy system wykorzystywany do naszego pierwszego udziału w wspólnym zadaniu CoNLL 2018. Przesłany system w dużej mierze wykorzystał ponownie najnowocześniejszy parser z CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Udoskonaliliśmy ten system pod kątem przewidywania cech morfologicznych i wykorzystaliśmy wszystkie dostępne zasoby, aby dostarczyć dokładne modele dla języków niskich zasobów. Zajęliśmy piąty z 27-tych uczestników MLAS dla budowania drzew zależności morfologicznych, drugi dla cech morfologicznych i trzeci dla tagowania (UPOS) i parsowania (LAS) języków niskich zasobów.', 'no': 'I denne papiren beskriver vi systemet som vert brukt for vår første deltakar på delt oppgåva CoNLL 2018. Den sendte systemet har mest nytt brukt tilstanden til kunsttolkaren frå CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Vi forbetra denne systemet for forhåndsvising av morfologiske funksjonar, og vi brukte alle tilgjengelege ressursar for å gjera nøyaktige modeller for låg ressursspråk. Vi rangerte 5. av 27 deltakarar i MLAS for å bygge morfologiske avhengighetstrær, 2. for berre morfologiske funksjonar, og 3. for å tagge (UPOS) og tolke (LAS) låg ressursspråk.', 'ro': 'În această lucrare, descriem sistemul utilizat pentru prima noastră participare la sarcina comună CoNLL 2018. Sistemul depus a reutilizat în mare măsură parserul de ultimă generație din CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Am îmbunătățit acest sistem pentru predicțiile caracteristicilor morfologice și am folosit toate resursele disponibile pentru a oferi modele precise pentru limbaje cu resurse reduse. Am clasat pe locul 5 din 27 de participanți la MLAS pentru construirea copacilor dependenți conștienți de morfologie, al 2-lea numai pentru caracteristicile morfologice și al 3-lea pentru etichetare (UPOS) și parsing (LAS) limbaje cu resurse reduse.', 'sr': 'U ovom papiru opisujemo sistem koji se koristi za naše prvo sudjelovanje u zajedničkom zadatku CoNLL 2018. Predloženi sistem je u velikoj mjeri ponovno iskoristio stanje umetničkog analizatora iz CoNLL 2017 (< https://github.com/tdozat/Parser-v2 > Povećali smo ovaj sistem za predviđanje morfoloških karakteristika, i koristili smo sve dostupne resurse kako bi pružili tačne modele za jezike niskih resursa. Postavili smo 5. od 27 učesnika u MLAS-u za izgradnju morfologije svjestnih drveća zavisnosti, 2. za samo morfologijske funkcije, i 3. za označavanje (UPOS) i parsiranje jezika niskih resursa.', 'sv': 'I denna uppsats beskriver vi systemet som användes för vårt första deltagande vid CoNLL 2018 delade uppdrag. Det inlämnade systemet återanvände till stor del den senaste tolkningen från CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Vi förbättrade detta system för prognoser av morfologiska egenskaper, och vi använde alla tillgängliga resurser för att tillhandahålla korrekta modeller för språk med låg resurs. Vi rankade 5:e av 27 deltagare i MLAS för att bygga morfologimedvetna beroendeträd, 2:a för endast morfologiska egenskaper och 3:e för taggande (UPOS) och parsning (LAS) lågresursspråk.', 'si': 'මේ පැත්තේ අපි පළමු ප්\u200dරධාන පද්ධතිය භාවිත කරන්න පුළුවන් පද්ධතිය CoNLL 2018 වැදගත් වැඩේ භාවිත කරනවා. පිළිබඳු පද්ධතිය බොහොම විශාල පද්ධතිය ආපහු භාවිත කරලා තියෙන්නේ CoNLL 2017 වලින් කාල්තාව පැ https://github.com/tdozat/Parser-v2 >). අපි මේ පද්ධතිය විශේෂ විශේෂ විශේෂතාවට වැඩි කරලා තියෙන්නේ, ඒ වගේම අපි හැම ප්\u200dරවේශ විශේෂ සම්පූ අපි මොර්ෆෝලෝජික විශ්වාස කරනවා මොර්ෆෝලෝජික විශ්වාස කරනවා කියලා මොර්ෆෝලෝජික විශ්වාස කරනවා, 2 විශ්වාසික විශ', 'ta': 'இந்த காகிதத்தில், நாம் எங்கள் முதல் பகிர்ந்த பணிக்கு பயன்படுத்தப்பட்ட அமைப்பை விவரிக்கிறோம். வழங்கப்பட்ட கணினி https://github.com/tdozat/Parser-v2 >). நாங்கள் இந்த முறைமையை மேம்படுத்தி முறைமையை முறைமைப்படுத்தி, அனைத்து கிடைக்கும் வளங்களையும் குறைந்த மூலத்திற்கு  நாங்கள் MLAS-ல் 27 பங்கீடாளர்களில் 5வது பங்கீடாளர்கள் உள்ளோம் சார்ந்த சார்பு மரங்களை உருவாக்க, இரண்டாவது தொழில்நுட்ப பண்புகள் மட்டும், மூன்றாவது ஒட்டுதல்', 'ur': 'اس کاغذ میں ہم نے اپنے پہلی مشارکت کے لئے استعمال کیا گیا تھا CoNLL 2018 کے شریک کام میں۔ پیغام دینے والی سیسٹم نے CoNLL 2017 سے آرت پارٹر کی حالت کو دوبارہ استعمال کیا ہے (< https://github.com/tdozat/Parser-v2 >). ہم نے اس سیسٹم کو مدرفولوژیکوں کی پیش بینی کے لئے بڑھایا، اور ہم نے تمام موجودات کے موجودات کو نیچے منبع زبانوں کے لئے دقیق نمونڈل کے لئے استعمال کیا۔ ہم نے MLAS میں 27 شرکت کرنے والوں میں پانچویں درخت بنانے کے لئے مارفولوژی کا علم رکھنے کے لئے، دوسرے درخت صرف مورفولوژیکوں کے لئے، اور تیسرے ٹاگ (UPOS) اور پارسینگ (LAS) کم منبع زبانوں کے لئے۔', 'so': 'Qoraalkan waxaynu ku qornaa nidaamka ee ugu horeeyay ka qeybqaadashada shaqada ee CoNLL 2018. nidaamka la soo dhiibay ayaa si badan u isticmaalay xaaladda farshaxanka ee CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). We enhanced this system for morphological features predictions, and we used all available resources to provide accurate models for low-resource languages.  Waxaannu ka sarraynay 5aad oo ka mid ah 27aad oo ka mid ah MLAS, si aan u dhisno geedaha morphology ee ku xiran, 2aad oo u gaarno maamulka morphologiga oo kaliya, saddexaadna u baarayno luqadaha hoose ee ay ku baarayaan (LAS).', 'uz': "Bu qogʻozda, biz CONLL 2018 bilan birinchi ishlash uchun ishlatilgan tizimni anglatamiz. The submitted system largely reused the state of the art parser from CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Biz bu tizimni morfologik foydalanuvchilarga ko'paydik, va biz hamma mavjud manbalarni qo'shimcha manbalar uchun foydalanamiz. Biz MLASdagi 27 participlarning 5 chi qismini o'zgartirdik, morfologiya ishlatuvchi daraxtni yaratish uchun, faqat morfologik xususiyatlariga ikkinchi bo'lgan, va UPOS (UPOS) uchun 3 chi qismini ko'paytirish uchun (LAS) yo'q Resource tillarini koʻchirish uchun.", 'vi': 'Trong tờ giấy này, chúng tôi mô tả hệ thống được dùng cho lần đầu tiên tham gia nhiệm vụ chia sẻ của chúng tôi tại Tòa Tháp đôi! Hệ thống được gửi đi đã hoàn toàn tái sử dụng nhà phân tích nghệ thuật thuộc CoNll 2007. https://github.com/tdozat/Parser-v2 -Vâng. Chúng tôi tăng cường hệ thống dự đoán các tính chất lịch sự, và chúng tôi sử dụng mọi nguồn lực có thể để cung cấp các mô hình chính xác cho ngôn ngữ ít nguồn. Chúng tôi xếp hạng thứ năm của hàng ngũ quốc nằm trong giải MLAS để xây nhiều vật có thể phụ thuộc thuộc, thứ hai chỉ với tính lịch sự, và thứ ba cho loại theo dấu (UPOS) và phân tích (LAS) ngôn ngữ ít tài nguyên.', 'bg': 'В настоящата статия описваме системата, използвана за първото ни участие в споделената задача на КоНЛ 2018. Предоставената система до голяма степен използва повторно най-съвременния анализатор от КоНЛ 2017 (< https://github.com/tdozat/Parser-v2 >).  Подобрихме тази система за предсказване на морфологични характеристики и използвахме всички налични ресурси, за да осигурим точни модели за езици с нисък ресурс. Ние се класирахме на 5-то място от 27 участници в МЛАС за изграждане на морфологични зависими дървета, второ само за морфологични характеристики и трето за етикетиране (UPOS) и анализиране (LAS) на езици с нисък ресурс.', 'nl': 'In dit artikel beschrijven we het systeem dat werd gebruikt voor onze eerste deelname aan de gezamenlijke taak van CoNLL 2018. Het ingediende systeem gebruikte grotendeels de state of the art parser van CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  We hebben dit systeem verbeterd voor voorspellingen van morfologische kenmerken, en we gebruikten alle beschikbare bronnen om nauwkeurige modellen te leveren voor talen met weinig bronnen. We rankden 5e van 27 deelnemers aan MLAS voor het bouwen van morfologische afhankelijkheidsbomen, 2e voor morfologische kenmerken alleen en 3e voor tagging (UPOS) en parsing (LAS) low-resource talen.', 'da': 'I denne artikel beskriver vi det system, der blev anvendt til vores første deltagelse i CoNLL 2018 delte opgave. Det indsendte system genbrugte stort set den nyeste fortolker fra CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Vi forbedrede dette system til forudsigelser af morfologiske egenskaber, og vi brugte alle tilgængelige ressourcer til at levere nøjagtige modeller for sprog med lav ressource. Vi rangerede 5. ud af 27 deltagere i MLAS til opbygning af morfologibevidste afhængighedstræer, 2. udelukkende for morfologiske funktioner og 3. til tagging (UPOS) og parsing (LAS) lav ressource sprog.', 'de': 'In diesem Beitrag beschreiben wir das System, das für unsere erste Teilnahme an der gemeinsamen Aufgabe CoNLL 2018 verwendet wurde. Das eingereichte System verwendete weitgehend den State of the Art Parser von CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Wir haben dieses System für Vorhersagen morphologischer Merkmale verbessert und alle verfügbaren Ressourcen verwendet, um genaue Modelle für ressourcenarme Sprachen bereitzustellen. Wir belegten den fünften von 27 Teilnehmern in MLAS für den Aufbau morphologisch bewusster Abhängigkeitsbäume, den zweiten Platz nur für morphologische Merkmale und den dritten Platz für Tagging (UPOS) und Parsing (LAS) ressourcenarme Sprachen.', 'id': 'Dalam kertas ini, kami menggambarkan sistem yang digunakan untuk berpartisipasi pertama kami di tugas kongsi CoNLL 2018. Sistem yang dikirim kebanyakan menggunakan ulang parser seni dari CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Kami meningkatkan sistem ini untuk prediksi fitur morfologi, dan kami menggunakan semua sumber daya yang tersedia untuk menyediakan model akurat untuk bahasa sumber daya rendah. Kami mendaftar ke-5 dari 27 peserta di MLAS untuk membangun pohon dependensi sadar morfologi, ke-2 hanya untuk fitur morfologi, dan ke-3 untuk tagging (UPOS) dan parsing (LAS) bahasa sumber daya rendah.', 'ko': '이 문서에서는 CoNLL 2018 공유 작업에 처음 참여할 때 사용한 시스템을 설명합니다.2017년에 CoNLL은 최첨단 해상도를 제출했습니다(<https://github.com/tdozat/Parser-v2>). 우리는 형태학적 특징 예측을 위해 이 시스템을 강화하고 모든 사용 가능한 자원을 사용하여 저자원 언어에 정확한 모델을 제공한다.MLAS 참가자 27명 중 형태 감지 의존트리 구축은 5위, 형태 특징만 2위, 마커(UPOS)와 해석(LAS) 저자원 언어는 3위를 차지했다.', 'sw': 'Katika karatasi hii, tunaelezea mfumo uliotumika kwa ushiriki wetu wa kwanza katika kazi ya CoNLL 2018 ilishirikisha. Mfumo uliotolewa umetumia tena hali ya mchambuzi wa sanaa kutoka CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Tumeongeza mfumo huu kwa utabiri wa kimaadilojia, na tulitumia rasilimali zote zinazopatikana ili kutoa mifano sahihi kwa lugha za chini za rasilimali. Tulifanya rangi ya 5 ya washiriki 27 nchini MLAS kwa ajili ya kujenga miti ya kifolojia yenye ufahamu wa kujitegemea, na ya pili kwa utambulisho wa kifolojia pekee, na ya tatu tu kwa ajili ya wimbo (UPOS) na kuimba lugha ndogo ya rasilimali.', 'fa': 'در این کاغذ، سیستم برای اولین مشارکت در کار مشترک CoNLL ۲۰۱۸ استفاده شده است. سیستم ارائه داده شده بسیار زیادی از وضعیت ویرایشگر هنری از CoNLL 2017 دوباره استفاده کرد (< https://github.com/tdozat/Parser-v2 >). ما این سیستم را برای پیش بینی\u200cهای ویژه\u200cهای مورفولوژیکی افزایش دادیم و از همه منابع\u200cهای موجود استفاده کردیم تا مدل\u200cهای دقیق برای زبان\u200cهای کم منابع دهیم. ما پنجمین از ۲۷ مشترک در MLAS برای ساختن درختان بستگی در مورفولوژی آگاه شدیم، ۲ برای ویژه های مورفولوژیک فقط، و سوم برای نشانگر (UPOS) و بررسی (LAS) زبانهای کم منبع.', 'tr': "Bu kagyzda, 2018-nji ýylda CoNLL işimizde ilkinji gezek goşulşymyz üçin ulanylýan sistemany tassymladyk. Sahypa edilen sistem 2017-nji ýylyň CoNLL-den gelen ýagtylaryň durumyny ýene ullanýar https://github.com/tdozat/Parser-v2 > Biz bu sistemi morfolojik karakterleriň önümlerini üçin geliştirdik we hemme bar resurslary iň az resurslar üçin dogry nusgalary temin etmek üçin ullandyk. Biz MLAS'da morfologiýanyň garyplaryny tanaýmak üçin 27-nji bölegi 5-nji derejä çykardyk, 2-nji diňe morfolojik möhümleriň üçin, we 3-nji derejä tägleme we paýlamak üçin (LAS) düşük resurslar dilinde çykardyk.", 'sq': 'Në këtë letër, ne përshkruajmë sistemin e përdorur për pjesëmarrjen tonë të parë në detyrën e përbashkët të CoNLL 2018. Sistemi i paraqitur përdori kryesisht analizuesin më të mirë nga CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Ne përmirësuam këtë sistem për parashikimet e karakteristikave morfologjike, dhe përdorëm të gjitha burimet në dispozicion për të ofruar modele të sakta për gjuhët me burime të ulëta. We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.', 'af': 'In hierdie papier beskrywe ons die stelsel wat gebruik word vir ons eerste deelnadering by die CoNLL 2018 deel taak. Die voorgestuurde stelsel het groot hergebruik die staat van die kunstenaars van CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Ons het hierdie stelsel verbeter vir morfologiese funksievoorskoue, en ons het alle beskikbare hulpbronne gebruik om beskikbaar modele te verskaf vir lae hulpbronne tale. Ons het 5de van 27 deelnimmers in MLAS gerankeer vir die bou van morfologie bewus afhanklikheidsboom, 2de vir slegs morfologiese funksies, en 3de vir tagging (UPOS) en verwerking (LAS) lae-hulpbron tales.', 'hr': 'U ovom papiru opisujemo sistem koji se koristi za naše prvo sudjelovanje u zajedničkom zadatku CoNLL 2018. Predloženi sustav u velikoj mjeri ponovno koristi stanje proizvođača umjetnosti iz CoNLL 2017 (< https://github.com/tdozat/Parser-v2 > Pojačali smo ovaj sistem za predviđanje morfoloških karakteristika i koristili smo sve dostupne resurse kako bi pružili precizne modele za jezike niskih resursa. Postavili smo 5. od 27 učesnika u MLAS-u za izgradnju morfologije svjesnih drveća zavisnosti, 2. za samo morfologijske funkcije, i 3. za označavanje (UPOS) i analiziranje jezika niskih resursa.', 'am': 'በዚህ ፕሮግራም፣ የፊተኛውን ተግባራችን በኮንLL 2018 የተካፈለውን ስራ እናሳውቃለን፡፡ የተገኘው ስርዓት ከCoNLL 2017 የተለየ የዐርድ ተርጓሚን ሁኔታ እንደገና ይጠቀማል (< https://github.com/tdozat/Parser-v2 >) ይህንን ስርዓት የሞሮፎሎጂ ምርጫዎች ለመፍጠር አበጅተናል፣ እናም የተገኘውን ሀብት ሁሉ የዝግታ ዓይነቶችን ለመስጠት እናስጠጋለን፡፡ በMLAS ውስጥ 27 ተጋሪዎችን 5ኛ የሞሮፎሎጂ ተቃዋሚ ዛፎችን ለመሥራት፣ ሁለተኛው ለሞሮፎሎጂ ግንኙነት ብቻ እና ሦስተኛውን ለመጋጠም (UPOS) እና ለማጋራት (LAS) ትንሹ የክፍለ ሀብት ቋንቋዎች ቋንቋዎችን ለመዘጋጀት ነው፡፡', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք համակարգը, որը օգտագործվում է մեր առաջին մասնակցության համար 2018 թվականի ԿՈՆԼ համայնքային խնդիրներում: Հաշվի առկա համակարգը հիմնականում վերաօգտագործեց 2017-ի ԿոՆԼ-ի վերջին վերլուծումը (~ https://github.com/tdozat/Parser-v2 ]). Մենք բարելավեցինք այս համակարգը մորֆոլոգիական հատկությունների կանխատեսման համար, և մենք օգտագործեցինք բոլոր հասանելի ռեսուրսները, որպեսզի ապահովենք ճշգրիտ մոդելներ ցածր ռեսուրսների լեզուների համար: Մենք դասակարգեցինք MLAS-ի 27 մասնակիցներից հինգերորդը, որպեսզի կառուցենք մորֆոլոգիա գիտակցած կախվածության ծառեր, երկրորդը միայն մորֆոլոգիական հատկանիշների համար, և երրորդը, որպեսզի դասակարգենք (UPO) և վերլուծենք (LAS', 'bn': 'In this paper, we describe the system used for our first participation at the CoNLL 2018 shared task.  জমা করা সিস্টেম বেশীরভাগ কোএনএল ২০১৭ থেকে শিল্প পার্সের অবস্থা পুনরায় ব্যবহার করা হয় (< https://github.com/tdozat/Parser-v2 >). আমরা এই সিস্টেম বৃদ্ধি করেছি মোরফোলিক্যাল বৈশিষ্ট্যের ভবিষ্যৎবাণীর জন্য এবং আমরা সকল প্রাপ্ত সম্পদ ব্যবহার করেছি নিম্ন সম্পদ আমরা এমএলএসে ২৭ জন অংশগ্রহণকারীদের ৫তম ভাগ করেছি নির্ভরশীল গাছ নির্মাণের জন্য, শুধুমাত্র মরোফোলজিক বৈশিষ্ট্যের দ্বিতীয় বৃক্ষ এবং ট্যাগিং (ইউএসপোস', 'bs': 'U ovom papiru opisujemo sistem koji se koristi za naše prvo sudjelovanje u zajedničkom zadatku CoNLL 2018. Predloženi sistem u velikoj mjeri ponovo koristi stanje umjetničkog analizatora iz CoNLL 2017 (< https://github.com/tdozat/Parser-v2 > Pojačali smo ovaj sistem za predviđanje morfoloških karakteristika, i iskoristili smo sve dostupne resurse za pružanje tačnih modela za jezike niskih resursa. Postavili smo 5. od 27 učesnika u MLAS-u za izgradnju morfologije svjesne drveće zavisnosti, 2. za samo morfologijske funkcije, i 3. za označavanje (UPOS) i analiziranje jezika niskih resursa.', 'ca': "En aquest paper, descrivim el sistema utilitzat per a la nostra primera participació a la tasca compartida CoNLL 2018. El sistema submetit va reutilitzar gran part l'aparell d'analització de CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). Vam millorar aquest sistema de prediccions de característiques morfològiques i vam utilitzar tots els recursos disponibles per proporcionar models precisos per a llengües amb baix recursos. We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.", 'az': "Bu kağızda, 2018-ci CoNLL işində ilk işimiz üçün istifadə edilən sistemi təsdiqləyirik. İmzalanmış sistem 2017-ci CoNLL şəklindəki sanat ayırıcının durumunu yenidən istifadə etdi (< https://github.com/tdozat/Parser-v2 >). Biz bu sistemi morfolojik xüsusiyyətlərin tədbirləri üçün artırdıq, və tüm mümkün kaynaqları düşük ressurs dillərinin düşük modelləri üçün istifadə etdik. Biz MLAS'da 27 hissəcilərdən 5. səf aldıq, morfolojik bağımlılıq ağaclarını in şa etmək üçün, 2. Morfolojik özellikləri üçün, 3. səf-səf-səf-səf-səf-səf-səf-səf-səf-səf-səf-səf-səf-səf-səf-səf dillərin", 'cs': 'V tomto článku popisujeme systém použitý pro naši první účast na sdíleném úkolu CoNLL 2018. Předložený systém znovu využil nejmodernější parser z CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Tento systém jsme vylepšili o předpovědi morfologických rysů a využili jsme všechny dostupné zdroje k poskytnutí přesných modelů pro jazyky s nízkými zdroji. Zařadili jsme pátého z 27 účastníků MLAS pro budování morfologických závislostních stromů, druhého pouze pro morfologické vlastnosti a třetího pro tagování (UPOS) a parsování (LAS) jazyků s nízkými zdroji.', 'et': 'Käesolevas töös kirjeldame süsteemi, mida kasutasime meie esimesel osalemisel CoNLL 2018 jagatud ülesandel. Esitatud süsteem kasutas suures osas uuesti CoNLL 2017 kaasaegset parserit (< https://github.com/tdozat/Parser-v2 >).  Täiustasime seda süsteemi morfoloogiliste omaduste prognoosimiseks ja kasutasime kõiki olemasolevaid ressursse, et pakkuda täpseid mudeleid vähese ressursiga keeltele. Olime MLAS-is 27 osalejast viiendal kohal morfoloogiateadlike sõltuvuspuude ehitamise osas, ainult morfoloogiliste omaduste osas teisel kohal ning vähese ressursiga keelte märgistamise (UPOS) ja parsimise (LAS) osas kolmandal kohal.', 'fi': 'Tässä artikkelissa kuvailemme järjestelmää, jota käytimme ensimmäisen kerran CoNLL 2018:n yhteiseen tehtävään osallistumisessa. Toimitettu järjestelmä käytti suurelta osin uusinta tekniikkaa CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Kehitimme tätä järjestelmää morfologisten ominaisuuksien ennustamiseksi ja hyödynsimme kaikkia käytettävissä olevia resursseja tuottaaksemme tarkkoja malleja vähäresurssisille kielille. Sijoitimme MLAS:n 27 osallistujasta viidenneksi morfologiatietoisten riippuvuuspuiden rakentamisessa, toiseksi vain morfologisten ominaisuuksien osalta ja kolmanneksi merkitsemisen (UPOS) ja jäsentämisen (LAS) vähäresurssisten kielten osalta.', 'jv': 'Nang mapun iki, kita rambarang sistem sing ditambah kanggo sampeyan tanggal dhéwé nang barêng nggawe barang CoNLL 2020 Sistem sing ngewasipun ditambah nganggo akeh dumadhi paten sing artis ditambah CoNLL 1997 (< https://github.com/tdozat/Parser-v2 > Awak dhéwé éntuk sistem iki banget kanggo ngerasahan mrolengkap aturan kanggo ngerasahan karo nggawe barang nggawe barang penggunan kanggo nggawe model sing wis arep kanggo langgar-Ressource sing bisa. We ranged 5 th of 31 partipartipartipartipartipartitions in MLAS for rebuking shapes', 'ha': "Ga wannan takardan, Munã bayyana na'anar tsarin da aka yi amfani da shi na farkon shirin nasara a CoNLL 2018. Ana amfani da halin da aka shimfiɗa shi girma ya zama halin parser mai art daga CoNLL 2017 (* https://github.com/tdozat/Parser-v2 >). Mun ƙara wannan na'urar wa misogi na mutfologi, kuma mun yi amfani da dukkan rasilim da za'a sami misãlai masu daidaita wa lugha masu ƙasƙanci. Mun ɗaukaka 5th daga abõkan 27 masu haɗi da MMAS dõmin an gina masu fahimta ga mutfolojiya masu inganci, tare 2 na masu amfani da masu mutfologi kawai, da na ukun wa tagogi (UPS) da yin parse da harshen wuri-resource.", 'sk': 'V prispevku opisujemo sistem, ki ga uporabljamo za prvo udeležbo na skupni nalogi CoNLL 2018. Predloženi sistem je v veliki meri ponovno uporabil najsodobnejši razčlenjevalnik iz CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >).  Ta sistem smo izboljšali za napovedovanje morfoloških značilnosti in uporabili vse razpoložljive vire za zagotavljanje natančnih modelov za jezike z nizkimi viri. Med 27 udeleženci MLAS smo se uvrstili na 5. mesto za gradnjo dreves odvisnosti, ki se zavedajo morfologije, 2. mesto samo morfoloških značilnosti in 3. mesto za označevanje (UPOS) in razčlenjevanje (LAS) jezikov z nizkimi viri.', 'he': 'בעיתון הזה, אנחנו מתארים את המערכת המשתמשת לשתתפות הראשונה שלנו במשימה המשותפת של CoNLL 2018. The submitted system largely reused the state of the art parser from CoNLL 2017 (< https://github.com/tdozat/Parser-v2 >). שיתפרנו את המערכת הזאת לתוכניות מורפולוגיות, והשתמשנו בכל המשאבים הנוכחים כדי לספק דוגמנים מדויקים לשפות משאבים נמוכות. We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.', 'bo': 'ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོའི་མ་ལག་གི་འདིར་ང་ཚོའི་མཉམ་སྤྱོད་དང་པོ་དེ་CoNLL 2018་ལ་མཉམ་དུ་འཇུག་སྤྱོད་པའི་རི དེ་འདོན་དགོས་པའི་མ་ལག་གིས་CoNLL 2017 ལས་སྒྱུ་རྩལ་དབྱེ་སྟངས་ཀྱི་གནས་སྟངས་ལ་བསྐྱར་སྤྱོད་པ https://github.com/tdozat/Parser-v2 >). ང་ཚོས་མ་ལག་འདི་ལ་བཟོ་བཅོས་པའི་ཆ་རྐྱེན་ཆ་དང་མཉམ་དུ་ཐོབ་པའི་རྒྱུ་དངོས་ཡོངས་རྫོགས་ལ་སྤྱོད་པའི་རྒྱུ་དངོས་ཐོག་ཆའི་ཆ་ We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.'}
{'en': 'Semi-Supervised Neural System for ', 'fr': "Système neuronal semi-supervisé pour le marquage, l'analyse et la lématisation", 'es': 'Sistema neuronal semisupervisado para etiquetado, análisis y lematización', 'pt': 'Sistema neural semi-supervisionado para marcação, análise e lematização', 'ar': 'نظام عصبي شبه خاضع للإشراف للعلامات ، الإعراب ، و lematization', 'hi': 'टैगिंग, पार्सिंग और लेमेटाइजेशन के लिए अर्ध-पर्यवेक्षित तंत्रिका प्रणाली', 'zh': '以表记、解析、术化之半监神经系统', 'ja': 'タグ付け、解析、およびレマティゼーションのための半監視神経システム', 'ru': 'Полунадзорная нейронная система для маркировки, анализа и лематизации', 'ga': 'Córas Néarach Leath-Maoirsithe le haghaidh Clibeála, Parsála agus Leamatú', 'ka': 'ნახევარწმუნებული ნეიროლური სისტემა', 'el': 'Ημι-Εποπτευόμενο Νευρικό Σύστημα για την Επισήμανση, την Ανάλυση και τη Λεματοποίηση', 'hu': 'Félig felügyelt idegrendszer címkézéshez, értelmezéshez és lematizáláshoz', 'it': 'Sistema Neurale Semisupervisionato per Tagging, Parsing e Lematizzazione', 'kk': 'Тегтерді, талдау және лемациялау үшін жарты бақылау нейрондық жүйесі', 'lt': 'Semi-Supervised Neural System for Tagging, Parsing and Lematization', 'mk': 'Половина надгледуван нервен систем за означување, анализирање и лематизација', 'ms': 'Sistem Neural Semi-Dijaga untuk Tagging, Menghurai dan Lematisasi', 'ml': 'ടാഗ്ഗിംഗ്, പാര്\u200dസിങ്ങ് പാര്\u200dജിങ്ങ് ലെമാറ്റിഷഷന്\u200d', 'mt': 'Sistema Newrali Semissorveljata għat-Tagging, l-Analiżi u l-Lematizzazzjoni', 'mn': 'Тагжинг, шинжилгээ болон лемжлэх мэдрэлийн тархины систем', 'no': 'Halvoversikt neuralsystem for merking, tolking og lesing', 'pl': 'Pół-nadzorowany system neuronowy do tagowania, analizy i lematyzacji', 'si': 'ටැග්, විශ්ලේෂණය සහ ලෙමාසිකරණය වෙනුවෙන් පරීක්ෂණ ප්\u200dරවෘත්තිය', 'ro': 'Sistem neural semi-supravegheat pentru etichetare, parsare și lematizare', 'sr': 'Polovicni nadzorni nervni sistem za oznake, analizu i lematizaciju', 'so': 'Semi-Supered Neural System of Tagging, Parsing and Lematization', 'sv': 'Semi-övervakat neuralt system för märkning, tolkning och lematisering', 'ur': 'ٹاگ، پارسینگ اور لیمیٹیزی کے لئے نصف-Supervised Neural System', 'ta': 'ஒட்டு, பாசம் மற்றும் தொகுப்புக்கான புதிய புதிய அமைப்பு', 'uz': 'Name', 'vi': 'Hệ thần kinh giám sát phần mềm', 'hr': 'Polovicni nadzorni nervni sustav za označavanje, ocjenjivanje i lematizaciju', 'da': 'Semi-overvåget neural system til mærkning, fortolkning og lematisering', 'bg': 'Полунадзорна неврална система за маркиране, анализ и лематизация', 'nl': 'Semi-Supervised Neural Systeem voor Tagging, Parsing en Lematisatie', 'fa': 'سیستم عصبی نیمه تحت نظر قرار گرفته برای برگزیدن, تحلیل و تغییرات', 'ko': '표기, 해석, 레몬화에 사용되는 반감독신경계', 'de': 'Semi-Supervised Neuronal System für Tagging, Parsing und Lematisierung', 'id': 'Sistem Neural Semi-Supervised untuk Tagging, Analisis dan Lematisasi', 'af': 'Semi- Superviseer Neurale Stelsel vir etiket, verwerking en lematiseering', 'sw': 'Semi-Supervised Neural System for Tagging, Parsing and Lematization', 'tr': 'Tag, Parmak we Lematlamak üçin Azylyk Gözlemli Neural Sistemi', 'am': 'ምርጫዎች', 'hy': 'Նյարդային համակարգը, որը կես-վերահսկված է', 'sq': 'Sistemi Neural gjysmë i mbikqyrur për etiketën, analizimin dhe lematizimin', 'az': 'İşaret, Parsing və Lematizasyon üçün yarı-gözləyirli Nöral Sistemi', 'bn': 'ট্যাগিং, পার্সিং এবং লেমেশনের জন্য সেমি- সাপার্ভিট নিউরাল সিস্টেম', 'ca': 'Sistema neuronal semisupervisat per etiquetar, analitzar i llematitzar', 'bs': 'Polovicni nadzorni nervni sistem za označavanje, razmatranje i lematizaciju', 'cs': 'Semi-Supervised Neurální systém pro značení, analýzu a lematizaci', 'fi': 'Puolivalvottu hermojärjestelmä merkintää, parsausta ja lematisointia varten', 'et': 'Pooljärelevalvega närvisüsteem märgistamiseks, parsimiseks ja Lematiseerimiseks', 'jv': 'System', 'sk': 'Polnadzorovan živčni sistem za označevanje, razčlenitev in Lematizacijo', 'ha': 'KCharselect unicode block name', 'he': 'מערכת נוירולית חצי-מושגת לתג, בדיקת ולימטיזציה', 'bo': 'ཤོག་བྱང་ལུགས་དང་བསུབ་པ་ལ་ལུགས་རྒྱུན་ལུགས་མ་ལག་'}
{'en': 'This paper describes the ICS PAS system which took part in CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. The system consists of jointly trained ', 'ar': 'تصف هذه الورقة نظام ICS PAS الذي شارك في مهمة CoNLL 2018 المشتركة حول التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. يتألف النظام من مُحلل توغل وليمماتيزر ومحلل تبعية مُدرَّب بشكل مشترك والتي تعتمد على الميزات المستخرجة بواسطة شبكة biLSTM. يستخدم النظام كلاً من البنى العصبية التلافيفية المتصلة بالكامل والمتوسعة. تتمثل حداثة نهجنا في استخدام وظيفة خسارة إضافية ، مما يقلل من عدد الدورات في الرسوم البيانية للتبعية المتوقعة ، واستخدام التدريب الذاتي لزيادة أداء النظام. النظام المقترح ، أي ICS PAS (وارسو) ، احتل المرتبة الثالثة / الرابعة في التقييم الرسمي وحصلت على النتائج الإجمالية التالية: 73.02 (LAS) ، 60.25 (MLAS) و 64.44 (BLEX).', 'fr': "Cet article décrit le système ICS PAS qui a participé à la tâche partagée ConLL 2018 sur l'analyse multilingue du texte brut aux dépendances universelles. Le système se compose d'un tagger, d'un lemmatiseur et d'un analyseur de dépendances formés conjointement qui sont basés sur des caractéristiques extraites par un réseau BilsTM. Le système utilise à la fois des architectures neuronales convolutives entièrement connectées et dilatées. La nouveauté de notre approche est l'utilisation d'une fonction de perte supplémentaire, qui réduit le nombre de cycles dans les graphes de dépendance prédits, et l'utilisation de l'auto-apprentissage pour augmenter les performances du système. Le système proposé, à savoir ICS PAS (Warszawa), s'est classé 3e/4e dans l'évaluation officielle, obtenant les résultats globaux suivants\xa0: 73,02 (LAS), 60,25 (MLAS) et 64,44 (BLEX).", 'es': 'Este artículo describe el sistema ICS PAS que participó en la tarea compartida de CoNll 2018 sobre el análisis multilingüe del texto sin procesar a las dependencias universales. El sistema consiste en un etiquetador, un lematizador y un analizador de dependencias entrenados conjuntamente que se basan en características extraídas por una red BilsTM. El sistema utiliza arquitecturas neuronales convolucionales dilatadas y completamente conectadas. La novedad de nuestro enfoque es el uso de una función de pérdida adicional, que reduce el número de ciclos en los gráficos de dependencia predichos, y el uso del autoaprendizaje para aumentar el rendimiento del sistema. El sistema propuesto, es decir, ICS PAS (Warszawa), ocupó el 3º/4º lugar en la evaluación oficial y obtuvo los siguientes resultados generales: 73.02 (LAS), 60.25 (MLAS) y 64.44 (BLEX).', 'pt': 'Este artigo descreve o sistema ICS PAS que participou da tarefa compartilhada CoNLL 2018 sobre análise multilíngue de texto bruto para dependências universais. O sistema consiste em um tagger, um lematizer e um analisador de dependências treinados em conjunto que são baseados em recursos extraídos por uma rede biLSTM. O sistema usa arquiteturas neurais convolucionais totalmente conectadas e dilatadas. A novidade de nossa abordagem é o uso de uma função de perda adicional, que reduz o número de ciclos nos gráficos de dependência previstos, e o uso de autotreinamento para aumentar o desempenho do sistema. O sistema proposto, ou seja, ICS PAS (Warszawa), ficou em 3º/4º na avaliação oficial, obtendo os seguintes resultados gerais: 73,02 (LAS), 60,25 (MLAS) e 64,44 (BLEX).', 'ja': '本稿では、生テキストから普遍的な依存関係への多言語構文解析に関するCoNLL 2018の共有タスクに参加したICS PASシステムについて説明する。システムは、biLSTMネットワークによって抽出された機能に基づいて共同トレーニングされたタグ、レマティザー、および依存パーサーで構成されています。このシステムは、完全に接続された畳み込みニューラルアーキテクチャと拡張された畳み込みニューラルアーキテクチャの両方を使用します。私たちのアプローチの新規性は、予測される依存関係グラフのサイクル数を減らす追加の損失関数の使用と、システムパフォーマンスを向上させるための自己訓練の使用です。提案されたシステム、すなわちICS PAS （ Warszawa ）は、公式評価で3/4位となり、73.02 （ LAS ）、60.25 （ MLA ）、および64.44 （ BLEX ）の全体的な結果が得られた。', 'zh': '本文引与 CoNLL 2018 ICS PAS 系统,当共享事涉原始文本至通用赖多言解析。 其统以合教之标记器、词形还原器、恃解析器成之,盖取诸 biLSTM 网络也。 其统用全接扩张之卷积神经架构。 新颖在用额外损函数,宜函数减测赖图之循环,而以训练增统性。 拟议之统,考绩制度(华沙.ICS)排名第3/4位于官,总体如下:73.02(LAS)、60.25(MLAS)、64.44(BLEX)。', 'hi': 'यह पेपर आईसीएस पीएएस सिस्टम का वर्णन करता है जिसने CoNLL 2018 में भाग लिया था, जो कि रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग पर साझा कार्य करता है। सिस्टम में संयुक्त रूप से प्रशिक्षित टैगर, लेमेटाइज़र और निर्भरता पार्सर शामिल हैं जो एक biLSTM नेटवर्क द्वारा निकाली गई सुविधाओं पर आधारित हैं। सिस्टम पूरी तरह से जुड़े और फैलाहुआ कनवल्शनल न्यूरल आर्किटेक्चर दोनों का उपयोग करता है। हमारे दृष्टिकोण की नवीनता एक अतिरिक्त हानि समारोह का उपयोग है, जो अनुमानित निर्भरता रेखांकन में चक्रों की संख्या को कम करता है, और सिस्टम के प्रदर्शन को बढ़ाने के लिए आत्म-प्रशिक्षण का उपयोग करता है। प्रस्तावित प्रणाली, यानी.ICS पीएएस (वार्सज़ावा), निम्नलिखित समग्र परिणाम प्राप्त करने वाले आधिकारिक मूल्यांकन में 3 वें / 4 वें स्थान पर है: 73.02 (एलएएस), 60.25 (एमएलएएस) और 64.44 (BLEX)।', 'ru': 'В этой статье описывается система ICS PAS, которая приняла участие в совместной задаче CoNLL 2018 по многоязычному парсингу от необработанного текста к универсальным зависимостям. Система состоит из совместно обученных тегера, лематизатора и анализатора зависимостей, которые основаны на функциях, извлеченных сетью biLSTM. Система использует как полностью связанные, так и расширенные сверточные нейронные архитектуры. Новизна нашего подхода заключается в использовании дополнительной функции потерь, которая уменьшает количество циклов в прогнозируемых графиках зависимостей, и использовании самообучения для повышения производительности системы. Предлагаемая система, а именно МПС ССА (Варшава), заняла 3-4-е место в официальной оценке, получив следующие общие результаты: 73,02 (ЛАГ), 60,25 (ВПП) и 64,44 (БЛЕКС).', 'ga': 'Déanann an páipéar seo cur síos ar an gcóras ICS PAS a ghlac páirt i dtasc comhroinnte CoNLL 2018 maidir le Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch. Tá an córas comhdhéanta de chlibeálaí comh-oilte, lemmatizer, agus parsálaí spleáchais atá bunaithe ar ghnéithe a bhaintear as líonra biLSTM. Úsáideann an córas ailtireachtaí néaracha comhraonta lánnasctha agus caolaithe araon. Is é úrnuacht ár gcur chuige ná feidhm chaillteanais bhreise a úsáid, rud a laghdaíonn líon na dtimthriallta sna graif spleáchais tuartha, agus úsáid féin-oiliúint chun feidhmíocht an chórais a mhéadú. Bhain an córas atá beartaithe, i.e. ICS PAS (Warszawa), an 3ú/4ú háit sa mheastóireacht oifigiúil agus fuair sé na torthaí foriomlána seo a leanas: 73.02 (LAS), 60.25 (MLAS) agus 64.44 (BLEX).', 'ka': 'ამ დოკუმენტის შესახებ ICS PAS სისტემა, რომელიც CoNLL 2018-ში გაყოფილი მრავალენგური პარამეტრების შესახებ მრავალენგური პარამეტრების შესახებ სხვა ტექსტიდან უნივერ Name Name ჩვენი პროგრამის ახალგაზრულობა არის ახალგაზრულ დასრულებული ფუნქციის გამოყენება, რომელიც წინასწარმოდგენენებული დასამხრებელობის გრაფიკაში სიკულების რაოდენობა და სისტემის გასამხრე პროგრამეტული სისტემა, ანუ ICS PAS (Warszawa), პროგრამეტული 3/4-ში პროგრამეტული оფიციალური განსაზღვრებაში, რომელიც მიიღებენ მიმდინარე სამყარო შედეგები: 73.02 (LAS), 60.25 (MLAS) და 64.44 (BLEX).', 'el': 'Η παρούσα εργασία περιγράφει το σύστημα που έλαβε μέρος στην κοινή εργασία για την Πολυγλωσσική Ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Το σύστημα αποτελείται από από κοινού εκπαιδευμένο μαρκαριστή, λεμmatizer και αναλυτή εξάρτησης που βασίζονται σε χαρακτηριστικά που εξάγονται από ένα δίκτυο. Το σύστημα χρησιμοποιεί τόσο πλήρως συνδεδεμένες όσο και διεσταλμένες νευρωνικές αρχιτεκτονικές. Η καινοτομία της προσέγγισής μας είναι η χρήση μιας πρόσθετης συνάρτησης απώλειας, η οποία μειώνει τον αριθμό των κύκλων στα προβλεπόμενα γραφήματα εξάρτησης, και η χρήση της αυτοκατάρτισης για την αύξηση της απόδοσης του συστήματος. Το προτεινόμενο σύστημα, δηλαδή το ICS PAS (Warszawa), κατατάχθηκε 3η/4η στην επίσημη αξιολόγηση με τα ακόλουθα συνολικά αποτελέσματα: 73.02 (LAS), 60.25 (MLAS) και 64.44 (BLEX).', 'hu': 'Ez a tanulmány ismerteti az ICS PAS rendszert, amely részt vett a CoNLL 2018 megosztott feladatában a többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig. A rendszer közösen képzett taggerből, lemmatizálóból és függőség elemzőből áll, amelyek a biLSTM hálózat által kivont funkciókon alapulnak. A rendszer teljesen összekapcsolt és tágult convolucionális neurális architektúrákat használ. Megközelítésünk újdonsága egy kiegészítő veszteségfunkció alkalmazása, amely csökkenti az előrejelzett függőségi grafikonok ciklusainak számát, valamint az önképzés alkalmazása a rendszer teljesítményének növelésére. A javasolt rendszer, azaz az ICS PAS (Warszawa), a hivatalos értékelésben a harmadik/negyedik helyen állt, és a következő összességes eredményeket érte el: 73,02 (LAS), 60,25 (MLAS) és 64,44 (BLEX).', 'it': "Questo articolo descrive il sistema ICS PAS che ha preso parte al compito condiviso CoNLL 2018 sull'analisi multilingue dal testo grezzo alle dipendenze universali. Il sistema è costituito da tagger, lemmatizer e parser di dipendenza formati congiuntamente, basati su funzionalità estratte da una rete biLSTM. Il sistema utilizza architetture neurali convoluzionali completamente connesse e dilatate. La novità del nostro approccio è l'uso di una funzione aggiuntiva di perdita, che riduce il numero di cicli nei grafici di dipendenza previsti, e l'uso di auto-allenamento per aumentare le prestazioni del sistema. Il sistema proposto, vale a dire ICS PAS (Warszawa), si è classificato al terzo/quarto posto nella valutazione ufficiale ottenendo i seguenti risultati complessivi: 73,02 (LAS), 60,25 (MLAS) e 64,44 (BLEX).", 'mk': 'Овој документ го опишува ICS PAS системот кој учествуваше во CoNLL 2018 споделена задача за множјазично анализирање од суров текст до универзални зависности. Системот се состои од заеднички обучен тагер, лематизер и анализатор на зависност кои се базирани на карактеристики извадени од биLSTM мрежа. The system uses both fully connected and dilated convolutional neural architectures.  The novelty of our approach is the use of an additional loss function, which reduces the number of cycles in the predicted dependency graphs, and the use of self-training to increase the system performance.  Предложениот систем, т.е. ИЦС ПАС (Варшава), се рангираше на 3-ти/4-ти место во официјалната оценка, добивајќи ги следните вкупни резултати: 73,02 (ЛАС), 60,25 (МЛАС) и 64,44 (БЛЕКС).', 'lt': 'Šiame dokumente aprašoma ICS PAS sistema, kuri dalyvavo CoNLL 2018 m. bendroje užduotyje daugiakalbio analizavimo nuo žaliavinio teksto iki universaliųjų priklausomybių srityje. Sistemą sudaro bendrai apmokytas žymeklis, limmatizatorius ir priklausomybės analizatorius, kurie grindžiami biLSTM tinklo išskirtomis savybėmis. Sistemoje naudojamos visiškai sujungtos ir išplėstos konvoliucinės neurologinės architektūros. Mūsų požiūrio naujovė yra papildomos nuostolių funkcijos, kuri sumažina numatomų priklausomybės grafikų ciklų skaičių, naudojimas ir savarankiško mokymo naudojimas siekiant padidinti sistemos veiksmingumą. Siūloma sistema, t. y. ICS PAS (Varšuva), oficialaus vertinimo 3–4 eilutėje buvo pasiekti ši e bendrieji rezultatai: 73.02 (LAS), 60.25 (MLAS) ir 64.44 (BLEX).', 'kk': 'Бұл қағаз CoNLL 2018 дегенде бірнеше тілді талдау жүйесінің ICS PAS жүйесін анықтайды. Бұл көп тілді талдау жүйесінен Көп тілді мәтіннен Universal Dependencies бойынша қатынау жүйесіне бөл Бұл жүйе biLSTM желінен тарқатын мүмкіндіктерге негізделген тегжерлер, лимматизатор және тәуелсіздік талдаушыларынан тұрады. Жүйе толық қосылған және таратылған невралдық архитектураларды қолданады. Біздің қарсымыздың жаңалығы - қосымша жоғалу функциясының қолдануы, бұл өзгертілген тәуелсіздік графиктерінде цикл санын азайтады, жүйелік жұмысын көтеру үшін өзіміздің Мысалы, ICS PAS (Warszawa) жүйесі, официалдық оқиғанда келесі жалпы нәтижелерді алу үшін 3/4-ші ретінде, 73,02 (LAS), 60,25 (MLAS) және 64,44 (BLEX).', 'ms': 'Kertas ini menggambarkan sistem PAS ICS yang mengambil bahagian dalam tugas kongsi CoNLL 2018 mengenai penghuraian berbilang bahasa dari Teks Raw ke Dependensi Universal. Sistem ini terdiri dari tag, lemmatizer, dan penghurai dependensi yang berdasarkan ciri-ciri yang dikekstrak oleh rangkaian biLSTM. Sistem menggunakan arkitektur saraf konvolusi yang sepenuhnya tersambung dan terbesar. Kebarusan pendekatan kita adalah penggunaan fungsi kehilangan tambahan, yang mengurangkan bilangan siklus dalam graf dependensi yang dijangka, dan penggunaan latihan diri untuk meningkatkan prestasi sistem. Sistem yang dicadangkan, iaitu ICS PAS (Warszawa), ditangkap ke-3/4 dalam penilaian rasmi yang memperoleh hasil keseluruhan berikut: 73.02 (LAS), 60.25 (MLAS) dan 64.44 (BLEX).', 'ml': 'ഈ പത്രത്തില്\u200d കോണ്\u200dഎല്\u200d 2018-ല്\u200d പങ്കെടുത്ത ഐസിഎസ് പാസ്സിന്റെ സിസ്റ്റം വിവരിച്ചുകൊടുക്കുന്നു സിസ്റ്റത്തില്\u200d ഒരുമിച്ച് പഠിപ്പിക്കപ്പെട്ട ട ടാഗ്ഗര്\u200d, ലെമ്മാറ്റര്\u200d, ആശ്രയിക്കുന്ന പാലറുകളുണ്ട്. ബിഎല്\u200dഎസ്റ്റം നെറ സിസ്റ്റത്തില്\u200d പൂര്\u200dണ്ണമായും ബന്ധപ്പെട്ടിരിക്കുന്ന പ്രധാനപ്പെട്ട നെയൂറല്\u200d ആര്\u200dക്കിട്ടുകള്\u200d  നമ്മുടെ പ്രവര്\u200dത്തനത്തിന്റെ പ്രാധാന്യം കൂടുതല്\u200d നഷ്ടപ്പെട്ട ഫങ്ഷന്\u200d ഉപയോഗിക്കുന്നതാണ്. അത് പ്രതീക്ഷിക്കപ്പെട്ട ആശ്രയിക്കുന്ന ഗ്രാ പ്രൊദ്ദേശിക്കപ്പെട്ട സിസ്റ്റത്തിന്റെ സിസ്റ്റമാണ് ഐസ് പാസ് (വാര്\u200dസ്സവാ) താഴെയുള്ള മൊത്തം ഫലങ്ങള്\u200d ലഭിക്കുന്നതിന്റെ മൂന്നാം /നാലാം വിലാസങ്ങളില്\u200d നിന്ന', 'mt': 'Dan id-dokument jiddeskrivi s-sistema tal-PAS tal-ICS li ħadet sehem fil-ħidma kondiviża CoNLL 2018 dwar l-Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali. Is-sistema tikkonsisti minn tagger imħarreġ b’mod konġunt, limmatizzatur, u analizzatur tad-dipendenza li huma bbażati fuq karatteristiċi estratti minn netwerk biLSTM. Is-sistema tuża kemm arkitetturi newrali konvoluzzjonali kompletament konnessi kif ukoll imwessra. Il-bidla fl-approċċ tagħna hija l-użu ta’ funzjoni addizzjonali ta’ telf, li tnaqqas in-numru ta’ ċikli fil-grafiċi tad-dipendenza mbassra, u l-użu ta’ taħriġ awtonomu biex tiżdied il-prestazzjoni tas-sistema. Is-sistema proposta, jiġifieri l-ICS PAS (Warszawa), ikklassifikat fit-3/4 fl-evalwazzjoni uffiċjali li kisbet ir-riżultati globali li ġejjin: 73.02 (LAS), 60.25 (MLAS) u 64.44 (BLEX).', 'mn': 'Энэ цаас CoNLL 2018 оны CoNLL-д олон хэлний шинжилгээний ажил дээр оролцсон ICS PAS системийг хэлж байна. Энэ систем нь биLSTM сүлжээнд гаргасан шинж тэмдэглэгч, лимматизер, хамааралтай байдлын ажиллагааны хуваарьтай байдаг. Энэ систем бүрэн холбоотой болон шингээгдсэн мэдрэлийн архитектуруудыг ашигладаг. Бидний ойлголтын шинэчлэл бол нэмэлт алдагдлын функцын хэрэглээ. Энэ нь таамаглалтын хамааралтай графикийн циклийг багасгаж, системийн үйл ажиллагааг нэмэгдүүлэхэд өөртөө сургалтын хэрэглээ. Шинэ санал өгсөн систем, т.е. ICS PAS (Warszawa), официальный оюутнуудын 3/4-р дүгнэлт нь 73.02 (LAS), 60.25 (MLAS) болон 64.44 (BLEX).', 'pl': 'Niniejszy artykuł opisuje system ICS PAS, który wziął udział w wspólnym zadaniu CoNLL 2018 w zakresie Wielojęzycznego Parsowania z tekstu surowego do zależności uniwersalnych. System składa się z wspólnie przeszkolonego tagera, lemmatizera i parsera zależności, które są oparte na funkcjach ekstraktowanych przez sieć biLSTM. System wykorzystuje zarówno w pełni połączone, jak i rozszerzone konwolucyjne architektury neuronowe. Nowością naszego podejścia jest zastosowanie dodatkowej funkcji strat, która zmniejsza liczbę cykli w przewidywanych wykresach zależności oraz wykorzystanie samostanowienia w celu zwiększenia wydajności systemu. Proponowany system, czyli ICS PAS (Warszawa), zajął trzeci/czwarty miejsce w oficjalnej ocenie uzyskując ogólne wyniki: 73.02 (LAS), 60.25 (MLAS) i 64.44 (BLEX).', 'no': 'Denne papiret beskriver ICS PAS- systemet som delt i CoNLL 2018 delt oppgåve om fleirspråk tolking frå Raw Text til universelle avhengighet. Systemet inneheld samanlig trengte merkelapp, limmatisering og avhengighetstolkar som er basert på funksjonar utpakka av ein biLSTM- nettverk. Systemet brukar både fullstendig tilkopla og utvida konvolusjonelle neuralarkitekturar. Det nye tilnærminga vårt er bruken av ein tilleggsfunksjon for tap, som reduserer talet på sykluser i forventa avhengighetsgrafikk, og bruken av selvøving for å økja systemutviklinga. Førehandsvis systemet, t.d. ICS PAS (Warszawa), rankert 3/4 i den offisielle evalueringa som får følgjande overalt resultatet: 73,02 (LAS), 60,25 (MLAS) og 64,44 (BLEX).', 'ro': 'Această lucrare descrie sistemul ICS PAS care a participat la sarcina comună CoNLL 2018 privind interpretarea multilingvă de la text brut la dependențe universale. Sistemul constă din etichetator, lemmatizator și parser de dependență instruit în comun, care se bazează pe caracteristici extrase de o rețea biLSTM. Sistemul foloseşte atât arhitecturi neuronale complet conectate cât şi dilatate. Noutatea abordării noastre este utilizarea unei funcții suplimentare de pierdere, care reduce numărul de cicluri în graficele de dependență preconizate, și utilizarea auto-antrenamentului pentru a crește performanța sistemului. Sistemul propus, adică ICS PAS (Warszawa), s-a clasat pe locul 3/4 în evaluarea oficială obținând următoarele rezultate generale: 73.02 (LAS), 60.25 (MLAS) și 64.44 (BLEX).', 'sr': 'Ovaj papir opisuje ICS PAS sistem koji je sudjelovao u CoNLL 2018. delu zajedničkog zadatka o multijezičkom razmatranju od Raw Text do univerzalnih zavisnosti. Sistem se sastoji od zajedničkog obučenog etiketera, limmatizatora i analizatora ovisnosti koji su zasnovani na karakteristikama izvlačenim biLSTM mrežom. Sistem koristi i potpuno povezane i proširene konvolucionalne neuralne arhitekture. Novost našeg pristupa je korištenje dodatne funkcije gubitka, koja smanjuje broj ciklusa u predviđenim graficima zavisnosti i korištenje samoupravnosti za povećanje funkcije sistema. Predloženi sistem, t.i. ICS PAS (Warszawa), u službenoj procjeni dobio je sljedeće ukupne rezultate: 73,02 (LAS), 60,25 (MLAS) i 64,44 (BLEX).', 'si': 'මේ පැත්තේ ICS PAS පද්ධතිය විස්තර කරනවා ඒක CoNLL 2018 වල භාෂාවික විශ්වාස කරලා තියෙන බොහොම භාෂාවික විශ්වාස කරනවා කි පද්ධතිය සම්බන්ධයෙන් ප්\u200dරේෂණිත ටැගර්, ලිම්මාසියර්, සහ අවශ්\u200dය විශ්වාසිත විශාලකයෙන් තියෙනවා. ඒක biLSTM ජ පද්ධතිය සම්පූර්ණයෙන් සම්පූර්ණයෙන් සහ විශේෂයෙන් සම්පූර්ණයෙන් න්\u200dයූරාල සිද් අපේ අවස්ථාවයේ අවස්ථාවක් තමයි අවස්ථාවක් නැති වැඩක් පාවිච්චි කරන්න, ඒකෙන් ප්\u200dරශ්න විශ්වාස විශ්වාසයේ සායික්ල් ස ප්\u200dරශ්ණාත පද්ධතිය, ඉතින් ICS PAS (වාර්ස්වාව), 3/4වෙනි ප්\u200dරශ්ණාත්මක විශ්ණාත්මක විශ්ණාත්මක විශ්වාස කරනවා: 73.02 (LAS), 60.25 (MLAS) සහ 64.', 'so': 'Kanu wuxuu ku qoran yahay nidaamka ICS PAS oo ka qayb galay CoNLL 2018 shaqo ku saabsan jardiinada luuqadaha kala duduwan ee Raw-Text-to Universal Dependences. nidaamka waxaa ka mid ah bandhig la tababaray oo wadajir ah, limmatizer, iyo baaritaanka ku xiran, kaas oo ku saleysan tayooyin lagu soo saaray shabakadda biLSTM. nidaamka wuxuu isticmaalaa meelo la xiriiro oo la burburiyay. Dhaqdhaqaaqa qaababkayagu waa isticmaalka waxqabadka khasaarada dheeraad ah, kaas oo hoos u dhigi kara tirada isbitaalada la ballanqaaday, iyo isticmaalka iskuulka si uu u kordhiyo tababarka nidaamka. Sirkaas la soo jeeday, waa ICS PAS (Warszawa), waxaa laga soo bandhigay qiimeynta rasmiga ah 3/4aad oo laga helay resultiyada soo socda oo dhan: 73.02 (LAS), 60.25 (MLAS) iyo 64.44 (BLEX).', 'sv': 'Denna uppsats beskriver ICS PAS-systemet som deltog i CoNLL 2018 delade uppgift om flerspråkig tolkning från råtext till universella beroende. Systemet består av gemensamt utbildade taggare, lemmatizer och beroendetolkare som är baserade på funktioner extraherade av ett biLSTM nätverk. Systemet använder både fullt anslutna och utvidgade konvulutionella neurala arkitekturer. Nytt med vårt tillvägagångssätt är användningen av en ytterligare förlustfunktion, som minskar antalet cykler i de förutspådda beroendegraferna, och användningen av självträning för att öka systemets prestanda. Det föreslagna systemet, dvs ICS PAS (Warszawa), rankades 3:e/4:e i den officiella utvärderingen och fick följande övergripande resultat: 73,02 (LAS), 60,25 (MLAS) och 64,44 (BLEX).', 'ur': 'This paper describes the ICS PAS system which took part in CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. سیسٹم کے ساتھ تطالب کیا گیا ٹاگر، لیمٹیزر، اور اعتمادی پارچر سے ہے جو ایک biLSTM نیٹ ورک کے ذریعے اٹھایے ہوئے فرصت پر بنیاد ہیں. سیسٹم ان دونوں کو پورے طور پر اتصال اور پھیلا ہوا نئورل معماری استعمال کرتا ہے۔ ہمارے تقریبا کی نوائی ایک اضافہ خسارہ فعالیت کا استعمال ہے جو پیش بینی اضافہ کے گراف میں چرخے کی تعداد کم کر دیتا ہے اور سیسٹم کی عملکرد زیادہ کرنے کے لئے خود تعلیم کا استعمال کرتا ہے. پیشنهاد کی سیستم، یعنی ICS PAS (Warszawa), رسمی ارزیابی میں 3م/4م درجہ تھا، یعنی نیچے کل نتیجے حاصل کئے گئے: 73.02 (LAS), 60.25 (MLAS) اور 64.44 (BLEX).', 'ta': 'இந்த காகிதத்தை குறிப்பிடுகிறது ICS PAS முறைமையை கோன்எல் 2018 ல் பகிர்ந்து கொண்ட பணியை குறிப்பிடுகிறது ரி உரையிலிருந்து உலகளாவ @ info அமைப்பு முழுமையாக இணைக்கப்பட்ட மற்றும் தீவிரமான புதிய அடைவுகளை பயன்படுத்துகிறது. The novelty of our approach is the use of an additional loss function, which reduces the number of cycles in the predicted dependency graphs, and the use of self-training to increase the system performance.  முந்திருக்கப்பட்ட அமைப்பு, அதாவது ICS PAS (வார்ஸாவா), கீழ்கண்ட மொத்த முடிவுகளை கிடைக்கும் தொழில்நுட்பமான மதிப்பில் 3வது/4வது வரிசையாக்கப்பட்டது: 73. 02 (LAS), 60.', 'uz': "Name Name Name Ko'rib chiqqamizning hayotimiz qoʻshimcha qoʻshish funksiyasining foydalanishi, bu kutilgan ishlayotgan, ishlatilgan qoidalarning soni kamaytirish, va tizim bajarishni oshirish uchun o'zimni o'zgartirish uchun o'zimni foydalanish. The proposed system, i.e. ICS PAS (Warszawa), ranked 3th/4th in the official evaluation obtaining the following overall results: 73.02 (LAS), 60.25 (MLAS) and 64.44 (BLEX).", 'vi': 'Tờ giấy này mô tả hệ thống ICS PAS, đã tham gia phần chia sẻ nhiệm vụ Colt 11.8. phân chia sẻ thao tác đa ngôn ngữ khai thác từ văn bản thô đến các cấp chung. The system consists of joint educated tagger, lemmatizer, and dependence parter which are based on tính năng extracted by a bialsTM network. Hệ thống sử dụng cấu trúc thần kinh rối loạn hoàn toàn kết nối. Sự mới lạ của phương pháp này là sử dụng một hàm thua thêm, nó giảm số chu kỳ trong các biểu đồ phụ thuộc dự đoán, và sử dụng tự đào tạo để tăng hiệu suất hệ thống. Hệ thống được đề xuất, tức là ICS PAS (Warszzawa), thứ ba/thứ tư trong cuộc đánh giá chính thức đạt được những kết quả tổng thể sau: 73.02 (LAS), 60.25 (MLAS) và 4X (bleX).', 'bg': 'Настоящата статия описва системата, която взе участие в споделената задача за многоезично анализиране от суров текст до универсални зависимости. Системата се състои от съвместно обучени маркери, лематизатори и анализатори на зависимости, които се основават на функции, извлечени от мрежата. Системата използва както напълно свързани, така и разширени конволюционни нервни архитектури. Новостта на нашия подход е използването на допълнителна функция за загуба, която намалява броя на циклите в прогнозираните графики на зависимост, както и използването на самообучение за повишаване на производителността на системата. Предложената система, т.е. ICS PAS (Варшава), се класира на 3-то/4-то място в официалната оценка, като получи следните общи резултати: 73.02 (LAS), 60.25 (MLAS) и 64.44 (BLEX).', 'nl': 'Dit artikel beschrijft het ICS PAS-systeem dat deelnam aan CoNLL 2018 gedeelde taak over meertalig parsen van ruwe tekst naar universele afhankelijkheden. Het systeem bestaat uit gezamenlijk getrainde tagger, lemmatizer en afhankelijkheidsparser die zijn gebaseerd op functies die worden geëxtraheerd door een biLSTM netwerk. Het systeem maakt gebruik van zowel volledig verbonden als verwijde convolutionele neurale architecturen. De nieuwigheid van onze aanpak is het gebruik van een extra verliesfunctie, die het aantal cycli in de voorspelde afhankelijkheidsgrafieken vermindert, en het gebruik van zelftraining om de systeemprestaties te verhogen. Het voorgestelde systeem, dat wil zeggen ICS PAS (Warszawa), werd 3e/4e in de officiële evaluatie en behaalde de volgende algemene resultaten: 73.02 (LAS), 60.25 (MLAS) en 64.44 (BLEX).', 'da': 'Denne artikel beskriver ICS PAS-systemet, som deltog i CoNLL 2018 delte opgave om flersproget tolkning fra rå tekst til universelle afhængigheder. Systemet består af fælles uddannede tagger, lemmatizer og afhængighedsfortolker, der er baseret på funktioner udvundet af et biLSTM netværk. Systemet bruger både fuldt forbundne og udvidede konvulutionelle neurale arkitekturer. Nyheden ved vores tilgang er brugen af en ekstra tabsfunktion, som reducerer antallet af cyklusser i de forudsigede afhængighedsgrafer, og brugen af selvtræning til at øge systemets ydeevne. Det foreslåede system, dvs. ICS PAS (Warszawa), rangerede 3./4. i den officielle evaluering og opnåede følgende samlede resultater: 73,02 (LAS), 60,25 (MLAS) og 64,44 (BLEX).', 'de': 'In diesem Beitrag wird das ICS PAS-System beschrieben, das an der gemeinsamen Aufgabe von CoNLL 2018 zum mehrsprachigen Parsing von Rohtext zu universellen Abhängigkeiten teilgenommen hat. Das System besteht aus gemeinsam trainiertem Tagger, Lemmatizer und Dependency Parser, die auf Features basieren, die von einem biLSTM Netzwerk extrahiert werden. Das System verwendet sowohl vollständig vernetzte als auch erweiterte convolutionale neuronale Architekturen. Die Neuheit unseres Ansatzes ist der Einsatz einer zusätzlichen Verlustfunktion, die die Anzahl der Zyklen in den prognostizierten Abhängigkeitsdiagrammen reduziert, und der Einsatz von Selbsttraining zur Steigerung der Systemleistung. Das vorgeschlagene System, d.h. ICS PAS (Warszawa), belegte den dritten/vierten Platz in der offiziellen Bewertung und erzielte folgende Gesamtergebnisse: 73.02 (LAS), 60.25 (MLAS) und 64.44 (BLEX).', 'id': 'This paper describes the ICS PAS system which took part in CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies.  Sistem ini terdiri dari tagger, lemmatizer, dan parser dependensi yang berdasarkan ciri-ciri yang dikekstraksi oleh jaringan biLSTM. The system uses both fully connected and dilated convolutional neural architectures.  Kebaru pendekatan kita adalah penggunaan fungsi kehilangan tambahan, yang mengurangi jumlah siklus dalam grafik dependensi yang diprediksi, dan penggunaan latihan diri untuk meningkatkan prestasi sistem. Sistem yang diusulkan, i.e. ICS PAS (Warszawa), berturut-turut ke-3/4 dalam evaluasi resmi memperoleh hasil keseluruhan berikut: 73.02 (LAS), 60.25 (MLAS) dan 64.44 (BLEX).', 'sw': 'Gazeti hili linaelezea mfumo wa ICS PAS ambao ulishiriki katika CoNLL 2018 ulishiriki kazi ya Uchaguzi wa lugha kutoka Maandishi ya Raw hadi Uingereza. Mfumo unajumuisha mabango yenye mafunzo ya pamoja, mabomu, na mchanganyiko wa kutegemea unaoanzishwa na mtandao wa biLSTM. Mfumo huo unatumia majengo yaliyohusiana na vifaa vinavyotengenezwa na makundi ya taratibu. Ukweli wa hatua yetu ni matumizi ya kazi ya ziada ya kupoteza, ambayo inapunguza idadi ya miunguko katika picha zinazotegemea, na matumizi ya mafunzo ya kujifunza kwa kuongeza utendaji wa mfumo. Mfumo huo ulipendekezwa, yaani ICS PAS (Warszawa), ulipandishwa na tatu/4 katika uchunguzi rasmi wa kupata matokeo yafuatayo jumla: 73.02 (LAS), 60.25 (MLAS) na 64.44 (BLEX).', 'fa': 'این کاغذ سیستم ICS PAS را توصیف می\u200cکند که در CoNLL 2018 وظیفه\u200cای مشترک شده در مورد تحلیل زیادی زبان از متن Raw به بستگی جهانی است. این سیستم از برچسب\u200cهای آموزشی با همدیگر آموزش داده شده\u200cاند، لیمپذیر و ویرایشگر بستگی که بر روی ویژگی\u200cهای توسط شبکه biLSTM خارج شده\u200cاند. سیستم از ساختار عصبی کاملا و کاملا متصل و گسترش استفاده می کند. تازه دسترسی ما استفاده از عملکرد زیادی است که تعداد دوره\u200cها در گرافهای بستگی پیش\u200cبینی می\u200cکند، و استفاده از آموزش خود برای افزایش عملکرد سیستم است. سیستم پیشنهاد، یعنی ICS PAS (Warszawa) درجه\u200cی ۳م/۴م در ارزیابی رسمی که نتیجه\u200cهای عمومی را دریافت می\u200cکند: 73.02 (LAS), 60.25 (MLAS) و 64.44 (BLEX).', 'tr': 'Bu kagyz CoNLL 2018-nji ýylda çoklu dilli Parlamak üzerinde Wagtlaýyn Metinden Üniversal Baýramlyklara bölen ICS PAS sistemini tassyklaýar. Bu sistem biLSTM şebekege tarapyndan çykarylýan tägler, lemmatizer we baglanyşyk tansçysynyň içine daýanýar. Bu sistem hem doly baglanýan hem döwletlenýän nüwiral arhitektarlaryny ulanýar. Biziň ýaryşymyzyň täze taýýarlanmasy boýunça işleýän işidir, bu sistem başarylygyny artmak üçin çarpan gyzyklaryň sanyny azaltýar. Görkezilýän sistem, ady ICS PAS (Warszawa), resmi deňlemede 3-nji/4-nji sany düzüldir: 73.02 (LAS), 60.25 (MLAS) we 64.44 (BLEX).', 'hr': 'Ovaj papir opisuje sustav ICS PAS-a koji je sudjelovao u CoNLL 2018-u zajedničkom zadatku o multijezičkom razmatranju od Raw Text-a do univerzalnih ovisnosti. Sistem se sastoji od zajedno obučenog znakovnika, limmatizača i analizača ovisnosti koji su temeljeni na funkcijama izvlačenoj biLSTM mreža. Sistem koristi i potpuno povezane i proširene konvolucionalne neuralne arhitekture. Novost našeg pristupa je upotreba dodatne funkcije gubitka, koja smanjuje broj ciklusa u predviđenim graficima zavisnosti i upotrebu samouvježbe za povećanje funkcije sustava. Predloženi sustav, tj. ICS PAS (Warszawa), u službenoj procjeni u redovima 3./4. u dobijanju sljedećih ukupnih rezultata: 73,02 (LAS), 60,25 (MLAS) i 64,44 (BLEX).', 'sq': 'Ky dokument përshkruan sistemin e ICS PAS që mori pjesë në detyrën e përbashkët të CoNLL 2018 mbi analizimin shumëgjuhës nga teksti i papërdorur në varësitë universale. Sistemi përbëhet nga tagger i trajnuar së bashku, limmatizer dhe analizues i varësisë që janë bazuar në karakteristikat e nxjerra nga një rrjet biLSTM. Sistemi përdor arkitektura nervore të lidhura plotësisht dhe të zgjeruara. The novelty of our approach is the use of an additional loss function, which reduces the number of cycles in the predicted dependency graphs, and the use of self-training to increase the system performance.  Sistemi i propozuar, jiġifieri ICS PAS (Warszawa), u rendit i treti/i katërti në vlerësimin zyrtar duke marrë rezultatet e përgjithshme të ardhshme: 73.02 (LAS), 60.25 (MLAS) dhe 64.44 (BLEX).', 'af': "Hierdie papier beskryf die ICS PAS stelsel wat deel in CoNLL 2018 gedeelde taak op veelvuldige verwerking van Roe Teks na Universele afhenigheide geneem het. Die stelsel bestaan van jointly trained tagger, lemmatizer en afhanklikheidspanser wat gebaseer word op funksies wat deur 'n biLSTM netwerk uitgevoer word. Die stelsel gebruik beide volledig verbind en verspreidige konvolusionele neurale arkitektuure. Die nuutskap van ons toegang is die gebruik van 'n addisionele verlies funksie, wat die nommer van sikkels in die voorskoude afhanklikheidsgrafe verklein, en die gebruik van self-onderwerp om die stelsel funksie te vergroot. Die voorgestelde stelsel, i.e. ICS PAS (Warszawa), rangeer 3de/4de in die offisiele evaluering wat die volgende oorspronklike resultate kry: 73.02 (Las), 60.25 (MLAS) en 64.44 (BLEX).", 'am': 'ይህ ገጽ ከረw ጽሑፍ ጀምሮ እስከ ዩንቨርስቲ ግንኙነት ላይ የተካፈለውን የICS PAS ስርዓት በኮንLL 2018 ላይ የተካፈለውን የብዙ ቋንቋዎች ማዘጋጃዎችን ያሳያል፡፡ በቢLSTM መረብ በተጠቃሚ የፊደል ምርጫዎች ላይ የተመሳሳይ የግንኙነት መጠቀሚያ፣ የኢሜያል ማህበረሰብ እና የግል ማተሚያ ነው፡፡ ሲስተምሩ ሁሉንም የተጠቃሚ የናቡር መሠረቶች ይጠቅማል፡፡ የመግቢያችን ቀውስ የጨማሪው የጥፋት ክፍል መጠቀም ነው፤ በተቀጠቀጠው የጽሑፎች ቁጥር እና የድምፅ ስርዓት ማድረግ እና የራሳቸውን ትምህርት ለመጠቀም ነው፡፡ የተዘጋጀው ሲስተም፣ እንዳለ የኢስጢስ PAS (Warszawa) እና የአሁኑን ሙሉ ውጤቶች ለማግኘት ባለሥልጣን ማውጣት ከ3/4 የተደረገ ነው፤ 73.02 (LAS), 60.25 (MLAS) እና 64.44 (BLEX).', 'az': "Bu kağıt, CoNLL 2018'nin çoxlu dil Parsing haqqında çoxlu mətndən Universal Dependenciyə bölünən ICS PAS sistemini təsdiq edir. Sistem biLSTM a ğ tarafından çıxarılan fəaliyyətlərə dayanan şəkillərdən birlikdə təhsil edilmiş etiketçi, limmatizer və bağlılıq ayırıcısıdır. Sistem tamamilə bağlı və genişlənmiş nöral arhitektarlarını istifadə edir. Yaxınlıqlarımızın yenilik, təmin edilmiş bağımlılıq grafiklərində ciklərin sayını azaltmaq və sistem performansını artırmaq üçün özü təhsil etmək üçün istifadəsidir. Təsdiq edilmiş sistem, yani ICS PAS (Warszawa), resmi değerlendirmədə 3/4 səf-səf düzəldi: 73.02 (LAS), 60.25 (MLAS) və 64.44 (BLEX).", 'ko': '본고는 ICS PAS 시스템을 묘사하는데 이 시스템은 CoNLL 2018 공유 임무에 참여했고 이 임무는 원시 텍스트부터 일반적인 의존의 다중 언어 해석에 이르기까지 관련된다.이 시스템은biLSTM 네트워크에서 추출한 특징을 바탕으로 연합 훈련된 태그기,lemmatizer,의존 해상도로 구성되어 있다.이 시스템은 완전히 연결되고 확장된 권적 신경 구조를 사용한다.우리의 방법의 새로운 점은 추가 손실 함수를 사용해서 예측 의존도의 순환수를 줄이고 자체 훈련을 사용하여 시스템 성능을 향상시키는 데 있다.제안된 시스템, 즉 ICS PAS(Warszawa)는 공식 평가에서 3/4위를 차지했고 다음과 같은 전체적인 결과를 얻었다. 73.02(LAS), 60.25(MLAS)와 64.44(BLEX).', 'bn': 'এই প্রবন্ধে আইসিএস প্যাস সিস্টেম ব্যাখ্যা করেছে যা কনএল ২০১৮ সালে অংশ নেয়া হয়েছে রাও টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করা  সিস্টেমের মধ্যে যুক্ত প্রশিক্ষিত ট্যাগার, লিম্যাটাজার এবং নির্ভরিত প্যালার রয়েছে যা বিএলস্টিএম নেটওয়ার্ক দ্বারা  এই সিস্টেম পুরোপুরি সংযুক্ত এবং সংঘর্ষিত নিউরেল প্রতিষ্ঠানগুলো ব্যবহার করে। আমাদের প্রতিক্রিয়ার নোভেল হচ্ছে একটি অতিরিক্ত ক্ষতি ফাংশনের ব্যবহার, যা ভবিষ্যদ্বাণী নির্ভরিত গ্রাফের সংখ্যা কমিয়ে দেয় এবং সিস্টেমের প প্রস্তাবিত সিস্টেম, যেমন আইসিস প্যাস (ওয়ারজাওয়ায়), নিম্নলিখিত সাধারণ ফলাফল পাওয়া সরকারি মূল্যের তৃতীয়/৪তম ভাগে পরিচালিত হয়েছে: ৭৩. ২ (লেস), ৬০. ২৫ (এমল', 'hy': 'Այս հոդվածը նկարագրում է այն համակարգը, որը մասնակցել է CONAL 2018 թվականին ընդհանուր հանձնարարության մեջ, որը վերաբերում է բազմալեզու վերլուծությանը՝ ոչ թղթից տեքստից մինչև համաշխարհային կախվածություններ: Համակարգը կազմված է միասին վարժեցված նշաններով, լեմմատիզերով և կախվածության վերլուծումներով, որոնք հիմնված են բիLSԹՄ ցանցի կողմից ստացված հատկանիշների վրա: Համակարգը օգտագործում է ամբողջովին կապված և ընդլայնված նյարդային ճարտարապետություններ: Մեր մոտեցումների նորությունն այն է, որ օգտագործվում է ավելին կորստի ֆունկցիա, որը նվազեցնում է կանխատեսված կախվածության գրաֆիկների ցիկլերի թիվը և ինքնավարժման օգտագործումը համակարգի արդյունավետության բարձրացման համար: Առաջարկված համակարգը, այսինքն, ԻՍՍ ՊԱՍ (Վարշավա), դասակարգված էր պաշտոնական գնահատման 3-րդ մասում, որի ընդհանուր արդյունքները ստացան 73.02 (ԼԱՍ), 60.25 (MLAS) և 64.44 (Բլեքս).', 'bs': 'Ovaj papir opisuje ICS PAS sistem koji je sudjelovao u CoNLL 2018-om zajedničkom zadatku o multijezičkom razmatranju od Raw Text-a do univerzalnih ovisnosti. Sistem se sastoji od zajedno obučenog znakovnika, limmatizača i analizača ovisnosti koji su temeljeni na funkcijama izvlačenoj biLSTM mreža. Sistem koristi i potpuno povezane i proširene konvolucionalne neuralne arhitekture. Novost našeg pristupa je korištenje dodatne funkcije gubitka, koja smanjuje broj ciklusa u predviđenim graficima zavisnosti i korištenje samouvježbe za povećanje funkcije sustava. Predloženi sistem, tj. ICS PAS (Warszawa), u službenoj procjeni u redovima 3. /4. u dobijanju sljedećih ukupnih rezultata: 73,02 (LAS), 60,25 (MLAS) i 64,44 (BLEX).', 'ca': "Aquest paper descriu el sistema de PAS de la CIS que va participar en la tasca compartida CoNLL 2018 sobre l'analització multilingüe des del text brut a les dependencies universals. El sistema està format conjuntament per etiquetadora, limmatitzador i analitzador de dependencies basats en característiques extraïdes per una xarxa biLSTM. El sistema utilitza arquitectures neurals convolutives completament connectades i dilatades. La novetat del nostre enfocament és l'ús d'una funció de pèrdua adicional, que redueix el nombre de cicles en els gràfics de dependencia predits, i l'ús d'autoentrenament per augmentar el rendiment del sistema. El sistema proposat, és a dir, ICS PAS (Warszawa), es va classificar en la tercera/quarta posició de l'evaluació oficial obtenint els següents resultats generals: 73,02 (LAS), 60,25 (MLAS) i 64,44 (BLEX).", 'fi': 'Tässä artikkelissa kuvataan ICS PAS -järjestelmää, joka osallistui CoNLL 2018:n yhteiseen tehtävään monikielisestä parsing from Raw Text to Universal Dependences. Järjestelmä koostuu yhteisesti koulutetuista tagger-, lemmatizer- ja dependence parser -työkaluista, jotka perustuvat biLSTM-verkoston poimimiin ominaisuuksiin. Järjestelmä käyttää sekä täysin yhdistettyjä että laajentuneita konvolutionaalisia hermorakenteita. Uutuutena lähestymistapamme on lisähäviöfunktion käyttö, joka vähentää syklien määrää ennustetuissa riippuvuuskaavioissa, sekä itseharjoittelun käyttö järjestelmän suorituskyvyn parantamiseksi. Ehdotettu järjestelmä eli ICS PAS (Varsova) sijoittui virallisessa arvioinnissa kolmanneksi/neljänneksi ja sai seuraavat kokonaistulokset: 73,02 (LAS), 60,25 (MLAS) ja 64,44 (BLEX).', 'et': 'Käesolevas artiklis kirjeldatakse ICS PAS süsteemi, mis osales CoNLL 2018 jagatud ülesandes mitmekeelse parsimise kohta toortekstist universaalseteni sõltuvusteni. Süsteem koosneb ühiselt koolitatud sildistajast, lemmatisaatorist ja sõltuvuse parserist, mis põhinevad biLSTM võrgu poolt ekstraheeritud funktsioonidel. Süsteem kasutab nii täielikult ühendatud kui ka laienenud konvolutsioonilisi neuraalarhitektuure. Meie lähenemisviisi uudsuseks on täiendava kaotusfunktsiooni kasutamine, mis vähendab tsüklite arvu prognoositavates sõltuvusgraafikates, ja enesetreeningu kasutamine süsteemi jõudluse suurendamiseks. Kavandatud süsteem, st ICS PAS (Varssava), oli ametlikus hindamises kolmandal ja neljandal kohal, saavutades järgmised üldtulemused: 73,02 (LAS), 60,25 (MLAS) ja 64,44 (BLEX).', 'cs': 'Tento článek popisuje systém ICS PAS, který se podílel na sdíleném úkolu CoNLL 2018 na vícejazyčném parsování od surového textu do univerzálních závislostí. Systém se skládá ze společně vyškoleného tageru, lemmatizéru a parseru závislostí, které jsou založeny na funkcích extrahovaných sítí biLSTM. Systém využívá jak plně propojené, tak rozšířené konvoluční neuronové architektury. Novinkou našeho přístupu je využití dodatečné ztrátové funkce, která snižuje počet cyklů v predikovaných grafech závislosti, a využití samotného tréninku ke zvýšení výkonu systému. Navržený systém, tj. ICS PAS (Warszawa), se v oficiálním hodnocení zařadil třetí/čtvrtý a získal následující celkové výsledky: 73.02 (LAS), 60.25 (MLAS) a 64.44 (BLEX).', 'ha': "Wannan takardan na bayyana the ICS PAS system which took part in CoNLL 2018 and share the job on Parse of multilanguages from Raw Text to Universal dependants. @ action: button The system uses both fully connected and dilated convolutional neural architectures.  Hanyar hanyarmu na amfani da wani aikin hasãra yana ƙara, wannan yana ƙarantar lissafa cikin grafyutan da aka yi ƙayyade, da kuma amfani da farat-aikin da ya ƙãra aikin na'ura. Tsarin da aka buɗa, misali, ICS PAS (Warszawa), na ranar ta 3/4th a cikin evaluci mai rasmi wanda ke samun matsalan da ke samu: 73.2 (LauS), 60.25 (MLES) da 64.44 (BLEX).", 'sk': 'V prispevku je opisan sistem ICS PAS, ki je sodeloval v skupni nalogi CoNLL 2018 o večjezičnem razčlenjanju od surovega besedila do univerzalnih odvisnosti. Sistem je sestavljen iz skupno usposobljenega označevalca, lemmatizerja in razčlenjevalnika odvisnosti, ki temeljijo na značilnostih, ki jih pridobi mreža biLSTM. Sistem uporablja tako popolnoma povezane kot razširjene konvolucijske nevronske arhitekture. Novica našega pristopa je uporaba dodatne funkcije izgube, ki zmanjšuje število ciklov v napovedanih grafih odvisnosti, in uporaba samousposabljanja za povečanje zmogljivosti sistema. Predlagani sistem, tj. ICS PAS (Varšava), se je uvrstil na 3. in 4. mesto v uradni oceni in dosegel naslednje splošne rezultate: 73,02 (LAS), 60,25 (MLAS) in 64,44 (BLEX).', 'jv': 'Ngawe Perintah iki rambaran kelompok ing IS PAS sistem sing wis pating nang CoNLL 2020 ngejaraké task nang Multilanguage Sistem sembarang karo tagger, lemmatizer, lan dipunangke dipunangke sing wis dipunangke karo perintah sing ditambah karo BiSLT network. Sistem sistem sistem digawe akeh mulai nang sampeyan akeh operasi jipakan karo ditambah dumadhi Perintah sing dibutuhke ditambahak dhéwé kuwi nggawe aturan tambah perusahaan kanggo ngerasai winih dhéwé, sing uwis kuwi nggawe gerakan kelas perusahaan anyar nggawe gerakan, lan uwis kuwi nggawe gerakan oleh operasi sistem sing bisa dianggap Siji perusahaan, t.i. IKS PAS', 'bo': 'ཤོག་བུ་འདིས་ICS PAS་མ་ལག་གི་དོན་ལ་CoNLL 2018་ནང་དུ་ཆ་འཕྲིན་ཡིག་གི་གནད་སྡུད་སྤྱོད་ཀྱི་ལས་འགུལ་བཤད་ཀྱི་ཡོད། The system consists of jointly trained tagger, lemmatizer, and dependency parser which are based on features extracted by a biLSTM network. མ་ལག་གིས་སྦྲེལ་མཐུད་དང་ཁྱད་ཡོད་པའི་ཆོས་ཉིད་སྒྲིག་འགོད་གཉིས་ལས་སྤྱོད་ཀྱི་ཡོད། ང་ཚོའི་ཐབས་ལམ་གྱི་གསར་བ་དེ་ནི་རྐྱེན་ལེན་བྱས་པར་ཉེན་ཁ་ཡོད་པའི་ལག་ལེན་འཐབ་སྟེ། དེ་ནི་འཚོལ་ཟིན་པའི་རྟེན་འབྲེལ་རྣམས་གྲངས་འབྲེལ་ནང གྲོས་འཆར་བཀོད་པའི་མ་ལག་(Warszawa)དེ་དག་ནི་ICS PAS(Warszawa)དང་། གཞུང་འབྲེལ་གྱི་དཔྱད་སྒྲུང་ཐོག་གི་གནད་སྡུད་གྲངས་མཇུག་བསྡུ་ཡོད། 73.02 (LAS), 60.25 (MLAS) དང་། 64.44', 'he': 'This paper describes the ICS PAS system which took part in CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies.  The system consists of jointly trained tagger, lemmatizer, and dependency parser which are based on features extracted by a biLSTM network.  המערכת משתמשת בארכיטקטורות עצביות מחוברות לחלוטין ומרחבות. החדשות של הגישה שלנו היא השימוש בתפקיד אובדן נוסף, אשר מפחיד את מספר המחזורים בגרפי התלויות הנצפויים, ושימוש באימונים עצמיים כדי להעלות את ההפעלה במערכת. המערכת המוצעת, כלומר ICS PAS (וורזאווה), התייצבה ב-3/4 בהערכה הרשמית, אשר קיבלה את התוצאות הכלליות הבאות: 73.02 (LAS), 60.25 (MLAS) ו-64.44 (BLEX).'}
{'en': 'Towards Better UD Parsing : Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation', 'ar': 'نحو تحليل أفضل في UD: تضمين سياق عميق للكلمات ، ومجموعة ، وتسلسل بنك الشجرة', 'es': 'Hacia un mejor análisis de UD: incrustaciones de palabras profundamente contextualizadas, ensamble y concatenación de bancos de árboles', 'fr': "Vers une meilleure analyse UD\xa0: intégration de mots contextualisés en profondeur, ensemble et concaténation de banques d'arbres", 'pt': 'Em direção a uma melhor análise de UD: incorporação profunda de palavras contextualizadas, conjunto e concatenação de banco de árvores', 'ja': 'より良いUD構文解析に向けて:深いコンテキスト化された単語の埋め込み、アンサンブル、ツリーバンクの連結', 'zh': '迈向善 UD 解析:上下文词嵌、集成、树库联', 'ru': 'На пути к лучшему анализу UD: глубокие контекстуализированные вставки слов, ансамбль и конкатенация Treebank', 'hi': 'बेहतर UD पार्सिंग की ओर: गहरी Contextualized Word एम्बेडिंग, Ensemble, और Treebank Concatenation', 'ga': 'I dTreo Parsála Níos Fearr UD: Leabú Focal domhain Comhthéacsaithe, Ensemble, agus Comhcheangail Bhruach na gCrann', 'el': 'Προς την καλύτερη ανάλυση: Ενσωματώσεις λέξεων σε βάθος περιβάλλοντος, σύνολα και συνέδεση δέντρων', 'hu': 'A jobb UD-értelmezés felé: mély kontextualizált szóbeágyazások, együttesek és fabank összefüggések', 'ka': 'სუფრო მეტი UD პანელიზაციაზე: ძალიან კონტექსტუალური სიტყვების შეყვარება, Ensemble და Treebank', 'it': 'Towards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble e Treebank Concatenation', 'lt': 'Geresnio UD analizavimo link: giliai kontekstualizuoti žodžių įterpimai, suvienodinimas ir medienos dėžės derinimas', 'kk': 'Ең жақсы UD талдау жолына: терең контекстуалды сөздерді ендіру, ұйымдастыру және Бұтабақ бағдарламасы', 'mk': 'За подобро анализирање на УД: длабоко контекстулизирано вградување на зборови, ансембл и концентрација на дрвената банка', 'ms': 'Ke arah penghuraian UD yang Lebih Baik: Penciptaan Kata Berkonteks Dalam Dalam Dalam, Ensemble, dan Kesuaian Pangkalan Pohon', 'mt': 'Lejn Analiżi Aħjar tal-UD: Inkorporazzjonijiet tal-kliem Kuntest Profond, Ensemble, u Konċentrazzjoni tal-Banek tas-Siġar', 'ml': 'മുകളില്\u200d ഉത്തമമായ യുഡി പാര്\u200dസിങ്ങ്: ആഴത്തില്\u200d കൂടിയ വാക്കിന്റെ ആഴത്തില്\u200d ആഴത്തില്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നു, ആ', 'mn': 'Үнэхээр сайхан UD талаар: гүн гүнзгий контекст үг нэмж, шинжилгээ, Treebank Concatenation', 'no': 'Til bedre UD- tolking: Djupne kontekstualiserte ord- innbygging, Ensemble og Treebank- konsatenasjon', 'pl': 'W kierunku lepszego parowania UD: głębokie kontekstualizowane osadzenia słów, zestawy i złączenie banków drzew', 'ro': 'Către o mai bună analiză UD: încorporarea profundă a textului contextualizat, ansamblul și concatenarea băncii copace', 'sr': 'Prema boljem analizu UD-a: duboko kontekstualizovano uključenje riječi, okupljanje i koncentracija Treebank-a', 'si': 'වඩා හොඳ UD විශ්ලේෂණය: ගොඩක් සම්බන්ධ වචන සම්බන්ධ වචන සම්බන්ධ විශ්ලේෂණය', 'sv': 'Mot bättre UD-tolkning: Djupa kontextualiserade ordinbäddningar, ensemble och trädbankssammanslutning', 'so': 'Kor waxaa ka wanaagsan jardiinada UD: Deep Contextualised Word Embedding, Ensemable, and Treebank Concatenation', 'ta': 'மேலே UD பாசிங்க்: ஆழமான சொல்லை உட்பொதித்தல், ஒதுக்கப்பட்டது, மற்றும் Treebank மாற்றம்', 'ur': 'اچھی UD پارسینگ کی طرف: عمیق کنٹکسٹیولیز کلمات ابڈینگ، انڈیمبل اور تری بانک کنٹینگ', 'uz': 'Yuqori UD chegarasi:', 'vi': 'Để đạt được mức độ phân tích Lời khai, Enslin, và kết luận cây ngân', 'bg': 'Към по-добро анализиране: дълбоко контекстуализирани словесни вграждания, ансамбъл и свързване на дървесни банки', 'nl': 'Naar een betere UD Parsing: diepe contextualiseerde Word Embeddings, ensemble en boombank concatenation', 'hr': 'Prema boljim analizacijama UD-a: duboko kontekstualizirano uključenje riječi, uključenje i zaključenje Treebank-a', 'da': 'På vej mod bedre UD Parsing: dyb kontekstualiseret ordindlejring, ensemble og træbank sammenkobling', 'de': 'Auf dem Weg zu besserem UD-Parsing: Deep Contextualized Word Embeddings, Ensemble und Treebank Concatenation', 'id': 'Menuju Penjelasan UD yang Lebih Baik: Penjelmaan Kata yang Dikontekstualisasi Dalam Dalam, Ensemble, dan Concatenation Treebank', 'fa': 'به سمت تحلیل UD بهتر: درجه متوسط کلمه\u200cهای عمیق، انجمن\u200cسازی، انجمن\u200cسازی و درخت\u200cبانک', 'sw': 'Hifadhi Bora ya UD: Mazungumzo ya Kwenye Mitandao ya Mazungumzo, Mazungumzo na Matukio ya Treebank', 'tr': 'UD Iň gowy Taýýarlama ýüzüne: Dereje Kontekstualized Kelimi Edilmeler, sowleme we Treebank Mazmunlar', 'af': 'Gaan na beter UD verwerking: Deep Konteksualiseerde Woord Inbeeldings, Ensemble en Boomsbank Konsolidasie', 'ko': '더 좋은 UD 해석: 심층 언어 환경화 단어 삽입, 통합 및 트리 라이브러리 연결', 'sq': 'Towards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation', 'am': 'ወደ ላይ የUD ማዘጋጀት ይሻላል፤ deep Contextualized Word Embedding, Ensemble and Treebank Concatenation', 'az': 'Daha yaxŇüńĪ UD analizi t…ôr…ôfind…ô: Deep Contextualized Word Embedding, Ensemble, and Treebank Concatenation', 'hy': 'Ավելի լավ UD-ի վերլուծությունը. խորը կոնտեքստալիզացված բառերի ներգրավումը, միավորումը և ծառի համեմատությունը', 'bn': 'উপরে উৎকৃষ্ট UD পার্সিং: গভীর কন্ট্রেস্টুয়েলিয়াল শব্দের বিস্তারিত, বিশেষ এবং ট্রেবাঙ্ক কন্টেন্টেশন', 'cs': 'Směrem k lepšímu parsování UD: hluboké kontextualizované vložení slov, soubory a řazení stromů', 'et': 'Parema UD-analüüsi suunas: sügav kontekstualiseeritud sõnade põimimine, ansambel ja puupanga ühendamine', 'ca': 'Vers una millor analització UD: Incorporació de paraules profundament contextualitzades, Ensemble i Concatenació', 'fi': 'Kohti parempaa UD-tulkintaa: Syvä kontekstualisoitu Word Embeddings, Ensemble ja Treebankin yhdistäminen', 'bs': 'Prema boljim analizacijama UD-a: duboko kontekstualizirano uključenje riječi, okupljanje i zaključenje Treebank-a', 'jv': 'ProgressBarUpdates', 'sk': 'K boljšemu razčlenjevanju UD: globoko kontekstualizirane besedne vdelave, ansambel in združevanje drevesnih bank', 'he': 'לכיוון בדיקת UD טובה יותר: פיצוי מילים עמוקים וקונקסטוליזציה', 'ha': '@ action', 'bo': 'UD འཕགས་རིས་སྐྱོང་བའི་དབྱེ་ཞིབ་ལ་བསྐྱོད། གནད་དོན་ཚུལ་ནང་འདྲེན་པ་(Deep Contextualized Word Embeddings), Ensemble, and Treebank Concatenation'}
{'en': 'This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We base our submission on Stanford’s winning system for the CoNLL 2017 shared task and make two effective extensions : 1) incorporating deep contextualized word embeddings into both the part of speech tagger and ', 'ar': 'تصف هذه الورقة نظامنا (HIT-SCIR) المقدم إلى مهمة CoNLL 2018 المشتركة حول التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. نحن نبني تقديمنا على نظام ستانفورد الفائز للمهمة المشتركة CoNLL 2017 ونقوم بعمل امتدادين فعالين: 1) دمج تضمين الكلمات السياقية العميقة في كل من جزء محدد الكلام والمحلل ؛ 2) تجميع موزعي المدربين مع تهيئة مختلفة. نستكشف أيضًا طرقًا مختلفة لربط ضفاف الأشجار لمزيد من التحسينات. تظهر النتائج التجريبية على بيانات التطوير فعالية أساليبنا. في التقييم النهائي ، حصل نظامنا على المرتبة الأولى وفقًا لـ LAS (75.84٪) وتفوق على الأنظمة الأخرى بهامش كبير.', 'fr': "Cet article décrit notre système (HIT-SCIR) soumis à la tâche partagée ConLL 2018 sur l'analyse multilingue du texte brut aux dépendances universelles. Nous basons notre soumission sur le système gagnant de Stanford pour la tâche partagée ConLL 2017 et proposons deux extensions efficaces\xa0: 1) intégrer des intégrations de mots contextualisées profondes à la fois dans la partie du tagger et de l'analyseur vocal\xa0; 2) assembler des analyseurs formés avec différentes initialisations. Nous explorons également différentes manières de concaténer des banques d'arbres pour des améliorations supplémentaires. Les résultats expérimentaux sur les données de développement montrent l'efficacité de nos méthodes. Lors de l'évaluation finale, notre système a été classé premier selon LAS (75,84\xa0%) et a largement surclassé les autres systèmes.", 'es': 'Este documento describe nuestro sistema (HIT-SCIR) presentado a la tarea compartida de CoNll 2018 sobre el análisis multilingüe del texto sin procesar a las dependencias universales. Basamos nuestra presentación en el sistema ganador de Stanford para la tarea compartida de CoNll 2017 y hacemos dos extensiones efectivas: 1) incorporar incrustaciones profundas de palabras contextualizadas tanto en la parte del etiquetador de voz como en el analizador sintáctico; 2) ensamblar analizadores capacitados con diferentes inicializaciones. También exploramos diferentes formas de concatenar bancos de árboles para mejorar aún más. Los resultados experimentales de los datos de desarrollo muestran la eficacia de nuestros métodos. En la evaluación final, nuestro sistema ocupó el primer lugar según LAS (75,84%) y superó al resto de sistemas por un amplio margen.', 'pt': 'Este artigo descreve nosso sistema (HIT-SCIR) submetido à tarefa compartilhada CoNLL 2018 sobre análise multilíngue de texto bruto para dependências universais. Baseamos nossa submissão no sistema vencedor de Stanford para a tarefa compartilhada CoNLL 2017 e fazemos duas extensões eficazes: 1) incorporando embeddings de palavras contextualizadas profundas tanto na parte do tagger quanto no parser de fala; 2) parsers ensembling treinados com inicialização diferente. Também exploramos diferentes maneiras de concatenar bancos de árvores para melhorias adicionais. Resultados experimentais nos dados de desenvolvimento mostram a eficácia de nossos métodos. Na avaliação final, nosso sistema ficou em primeiro lugar de acordo com o LAS (75,84%) e superou os outros sistemas por uma grande margem.', 'ja': '本稿では、生テキストから普遍的な依存関係への多言語構文解析に関する2018年のCoNLL共有タスクに提出された当社のシステム（ HIT - SCIR ）について説明します。私たちは、CoNLL 2017の共有タスクのためのスタンフォードの勝利システムに基づいて提出し、2つの効果的な拡張を行います。1 ）深いコンテキスト化された単語の埋め込みをスピーチタグとパーサーの両方の部分に組み込む。2 ）異なる初期化でトレーニングされたパーサーを組み立てる。さらに改善のためにツリーバンクを連結するさまざまな方法も模索しています。開発データの実験結果は、当社の方法の有効性を示しています。最終評価では、当社のシステムはLAS （ 75.84 ％ ）に従って1位となり、他のシステムを大きく上回りました。', 'zh': '本文言CoNLL 2018本至通用多言解析共享其统(HIT-SCIR)。 臣等以斯坦福大学CoNLL 2017共享之获奖系统为基,而两效之广:1)将深度上下文化之词嵌入词性标记器解析器中; 2)用初始化训练之解析器。 又寻连树库异术,以更进之。 开数实验结果表明之有效性. 终于评估,以LAS第一(75.84%),而优于他统。', 'hi': 'यह पेपर हमारे सिस्टम (HIT-SCIR) का वर्णन करता है जो CoNLL 2018 साझा कार्य में प्रस्तुत किया गया है, जो रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग पर है। हम CoNLL 2017 साझा कार्य के लिए स्टैनफोर्ड की जीतने की प्रणाली पर अपना सबमिशन आधार बनाते हैं और दो प्रभावी एक्सटेंशन बनाते हैं: 1) भाषण टैगर और पार्सर दोनों के हिस्से में गहरे प्रासंगिक शब्द एम्बेडिंग को शामिल करना; 2) विभिन्न प्रारंभिककरण के साथ प्रशिक्षित पार्सर ensembling. हम आगे के सुधारों के लिए ट्रीबैंक को संयोजित करने के विभिन्न तरीकों का भी पता लगाते हैं। विकास डेटा पर प्रयोगात्मक परिणाम हमारे तरीकों की प्रभावशीलता दिखाते हैं। अंतिम मूल्यांकन में, हमारे सिस्टम को एलएएस (75.84%) के अनुसार पहले स्थान पर रखा गया था और एक बड़े अंतर से अन्य प्रणालियों को पछाड़ दिया गया था।', 'ru': 'В этой статье описывается наша система (HIT-SCIR), представленная на совместную задачу CoNLL 2018 по многоязычному парсингу от необработанного текста к универсальным зависимостям. Мы основываем наше представление на выигрышной системе Стэнфорда для общей задачи CoNLL 2017 и делаем два эффективных расширения: 1) включение глубоких контекстуализированных вложений слов в обе части речевого тегера и парсера; 2) сборка парсеров, обученных с различной инициализацией. Мы также изучаем различные способы объединения берегов деревьев для дальнейших улучшений. Экспериментальные результаты по данным разработки показывают эффективность наших методов. В финальной оценке наша система заняла первое место по рейтингу LAS (75,84%) и превзошла другие системы с большим отрывом.', 'ga': 'Déanann an páipéar seo cur síos ar ár gcóras (HIT-SCIR) a cuireadh isteach chuig tasc comhroinnte CoNLL 2018 maidir le Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch. Bunaimid ár n-aighneacht ar chóras buaiteach Stanford do thasc roinnte CoNLL 2017 agus déanaimid dhá shíneadh éifeachtach: 1) leabaithe domhain comhthéacsaithe focal a ionchorprú sa chuid den chlibeáil cainte agus den pharsálaí; 2) parsers enembling oilte le inisealaithe éagsúla. Déanaimid iniúchadh freisin ar bhealaí éagsúla chun bainc crann a chomhchaitheamh le haghaidh feabhsuithe breise. Léiríonn torthaí turgnamhacha ar na sonraí forbartha éifeachtacht ár modhanna. Sa mheastóireacht deiridh, rangaíodh ár gcóras ar dtús de réir LAS (75.84%) agus d’fheidhmigh sé go mór níos fearr ná na córais eile.', 'hu': 'Ez a tanulmány bemutatja a CoNLL 2018-as megosztott feladatához benyújtott rendszerünket (HIT-SCIR) a nyers szövegtől az univerzális függőségekig. A benyújtásunkat a Stanford nyertes rendszerére alapozzuk a CoNLL 2017 megosztott feladathoz, és két hatékony kiterjesztést készítünk: 1) mély kontextuális szóbeágyazásokat beépítünk mind a beszédcímkéző, mind a parser részébe; 2) különböző inicializálással kiképzett elemzők összeállítása. A további fejlesztések érdekében különböző módszereket is feltárunk a fapadok összekapcsolásának. A fejlesztési adatok kísérleti eredményei mutatják módszereink hatékonyságát. A végső értékelés során rendszerünk a LAS szerint az első helyen (75,84%) szerepelt, és nagy mértékben felülmúlta a többi rendszert.', 'ka': 'ამ დოკუმენტი ჩვენი სისტემის (HIT-SCIR) შეტყობინება CoNLL 2018-ს გაყოფილი მრავალენგური პარამეტრების შესახებ მრავალენგური პარამეტრების შესახებ სისტემიდან უნივერსი და ჩვენ ჩვენი შემდეგ სტანფორდის მობიდნენი სისტემის შესახებ, რომელიც CoNLL 2017-ის გაყოფილი საქმე და გავაკეთებთ ორი ეფექტიური განზომილებები: 1) დავყენებთ ძალიან კონტექსუალური სიტყვების შე 2) განსხვავებული თნციალიზაციის გასწავლილი პარასერების შენახვა. ჩვენ ასევე განსხვავებული გზები, რომლებიც უფრო მეტად უფრო მეტირებისთვის გავაკეთებთ. განვითარების მონაცემების ექსპერიმენტიური შედეგი ჩვენი მეტისების ეფექტიურობას ჩვენებს. საბოლოო განსაზღვრებაში, ჩვენი სისტემა პირველად LAS (75,84%) სწორედ პირველი პერნექტირებულია და სხვა სისტემას დიდ მარტირებით გავაკეთეთ.', 'it': "Questo articolo descrive il nostro sistema (HIT-SCIR) presentato al compito condiviso CoNLL 2018 sull'analisi multilingue dal testo grezzo alle dipendenze universali. Basamo la nostra presentazione sul sistema vincente di Stanford per il compito condiviso CoNLL 2017 e creiamo due estensioni efficaci: 1) incorporando incorporazioni di parole contestualizzate profonde sia nella parte di word tagger che parser; 2) parser di assemblaggio addestrati con inizializzazione differente. Esploriamo anche diversi modi di concatenare le sponde degli alberi per ulteriori miglioramenti. I risultati sperimentali sui dati di sviluppo mostrano l'efficacia dei nostri metodi. Nella valutazione finale, il nostro sistema è stato classificato al primo posto secondo LAS (75,84%) e ha superato di gran lunga gli altri sistemi.", 'el': 'Αυτή η εργασία περιγράφει το σύστημά μας (HIT-SCIR) που υποβλήθηκε στην κοινή εργασία για την Πολυγλωσσική Ανάλυση από Ακατέργαστο Κείμενο σε Οικουμενικές Εξαρτήσεις. Βασίζουμε την υποβολή μας στο νικηφόρο σύστημα του Στάνφορντ για την κοινή εργασία και κάνουμε δύο αποτελεσματικές επεκτάσεις: 1) ενσωματώνοντας βαθιά ενσωμάτωση λέξεων στο πλαίσιο και στο μέρος του δείκτη ομιλίας και του αναλυτή. 2) συγκρότηση αναλυτών εκπαιδευμένων με διαφορετική αρχικοποίηση. Επίσης εξερευνούμε διαφορετικούς τρόπους σύνδεσης δέντρων για περαιτέρω βελτιώσεις. Τα πειραματικά αποτελέσματα στα δεδομένα ανάπτυξης δείχνουν την αποτελεσματικότητα των μεθόδων μας. Στην τελική αξιολόγηση, το σύστημά μας κατατάχθηκε πρώτος σύμφωνα με το LAS (75.84%) και ξεπερνούσε κατά μεγάλο βαθμό τα άλλα συστήματα.', 'ms': "Kertas ini menggambarkan sistem kami (HIT-SCIR) dihantar kepada tugas kongsi CoNLL 2018 mengenai penghuraian berbilang bahasa dari Teks Raw ke Dependenci Universal. We base our submission on Stanford's winning system for the CoNLL 2017 shared task and make two effective extensions: 1) incorporating deep contextualized word embeddings into both the part of speech tagger and parser;  2) mengumpulkan maklumat yang dilatih dengan inisialisasi yang berbeza. Kami juga mengeksplorasi cara-cara yang berbeza untuk menyatukan tiang pokok untuk perkembangan lanjut. Keputusan percubaan pada data pembangunan menunjukkan kegunaan kaedah kita. Dalam penilaian terakhir, sistem kami ditandai pertama menurut LAS (75.84%) dan melampaui sistem lain dengan margin besar.", 'lt': "Šiame dokumente aprašoma mūsų sistema (HIT-SCIR), pateikta CoNLL 2018 m. bendrai užduotims daugiakalbio analizavimo nuo žaliavinio teksto iki universaliųjų priklausomybių srityje. We base our submission on Stanford's winning system for the CoNLL 2017 shared task and make two effective extensions: 1) incorporating deep contextualized word embeddings into both the part of speech tagger and parser;  2) surinkti įvairiomis inicializacijomis apmokytus analizatorius. Taip pat ieškome įvairių būdų, kaip sujungti medžių ribas siekiant tolesnių patobulinimų. Eksperimentiniai vystymosi duomenų rezultatai rodo mūsų metodų veiksmingumą. Galutiniame vertinime mūsų sistema pirmą kartą buvo klasifikuojama pagal LAS (75,84 proc.), o kitos sistemos buvo gerokai didesnės.", 'mt': "Dan id-dokument jiddeskrivi s-sistema tagħna (HIT-SCIR) sottomessa lill-CoNLL 2018 kompitu kondiviż dwar l-Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali. Aħna nibbażaw is-sottomissjoni tagħna fuq is-sistema rebbieħa ta' Stanford għall-kompitu kondiviż CoNLL 2017 u nagħmlu żewġ estensjonijiet effettivi: 1) ninkorporaw inkorporazzjonijiet ta' kliem kuntestwalizzati profondi kemm fil-parti tat-tagger tad-diskors kif ukoll fil-parser; 2) ensembling parsers trained with different initialization.  Aħna nesploraw ukoll modi differenti ta’ konċinazzjoni tal-banek tas-siġar għal aktar titjib. Ir-riżultati esperimentali dwar id-dejta tal-iżvilupp juru l-effettività tal-metodi tagħna. Fl-evalwazzjoni finali, is-sistema tagħna kienet ikklassifikata l-ewwel skont l-LAS (75.84%) u qabżet is-sistemi l-oħra b’marġini kbir.", 'kk': 'Бұл қағаз біздің жүйемізді (HIT- SCIR) CoNLL 2018 жылы бірнеше тілді талдау жүйесіне ортақтастырылған тапсырмаңызды Көп тілді талдау мәтіннен Universal Dependencies деп таңдайды. Біз Станфордтың 2017 жылы CoNLL тапсырмасының жеңілікті жүйесіне қолданып, екі ең эффективні кеңейтулерді қолданып, 1) сөздердің тегжері мен талдаушысының екі бөлігіне қосып, терең контекстуалды сөздер 2) басқа инициализацияланған талдаушыларды ендіру. Мұндай-ақ біз басқа жақсы жақсартулар үшін бағытты бағыттау арқылы зерттейміз. Жасау деректерінің эксперименталдық нәтижелері әдістеріміздің эффективнігін көрсетеді. Соңғы оқиғанда, жүйеміз LAS (75,84%) дегенге сәйкес реттеп, басқа жүйелерді үлкен шегімен шектелген.', 'mk': 'Овој весник го опишува нашиот систем (ХИТ-СКИР) поднесен на CoNLL 2018 заедничката задача за множјазично анализирање од суров текст до универзални зависности. Ние го базираме нашето поднесување на победничкиот систем на Стенфорд за заедничката задача на CoNLL 2017 и направиме две ефикасни продолжувања: 1) вклучување на длабоко контекстуално вградување на зборови во делот на речникот и анализаторот; 2) собирање на анализатори обучени со различна иницијализација. Исто така, истражуваме различни начини за концентрација на дрвјата за понатамошни подобрувања. Експерименталните резултати на податоците за развој покажуваат ефективност на нашите методи. In the final evaluation, our system was ranked first according to LAS (75.84%) and outperformed the other systems by a large margin.', 'no': 'Denne papiret beskriver systemet vårt (HIT-SCIR) som er sendt til den delte oppgåva CoNLL 2018 om fleirspråk tolking frå Raw Text til universelle avhengighet. Vi baserer oppføringa vårt på Stanford sin vinningssystem for delt oppgåve i CoNLL 2017 og gjer to effektiv utvidingar: 1) inkluderer dype kontekstualiserte ordinnbygging i både del av taletagger og tolkar. Name Vi undersøker også ulike måtar å samsvara trekantar for meir forbedringar. Eksperimentale resultat på utviklingsdata viser effektiviteten av metodane våre. I det siste evalueringa var systemet vårt først rankert etter LAS (75,84%) og utført dei andre systemene med stor margin.', 'mn': 'Энэ цаас бидний системийг (HIT-SCIR) CoNLL 2018 онд олон хэлний шинжилгээний талаар олон хэлний талаар хэлж өгсөн ажлыг тайлбарладаг. Бид 2017 оны CoNLL-ийн хоёр даалгаварын тухай Стэнфордын ялагдах системийн тухай суурилуулж, хоёр үр дүнтэй нэмэгдүүлэлт хийдэг: 1) илтгэлийн тегжер болон хуваагдагчийн хоёр хэсэгт гүн гүнзгий тооны үгийг оруулж, 2) өөр хэлбэрээр сургалтын ажиллаачидыг нэгтгэх. Мөн бид өөр өөр арга замыг дахин сайжруулах арга замыг судалж байна. Хөгжлийн мэдээллийн туршилтын үр дүнд бидний арга замын үр дүнг харуулдаг. Эцсийн оюутнуудад бидний систем ЛАС (75.84%) дээр анхны дүрслэл авсан ба бусад системүүдийг маш том хугацаанд гаргасан.', 'pl': 'Niniejszy artykuł opisuje nasz system (HIT-SCIR) zgłoszony do wspólnego zadania CoNLL 2018 w zakresie analizy wielojęzycznej z tekstu surowego do zależności uniwersalnych. Opieramy naszą zgłoszenie na zwycięskim systemie Stanforda dla wspólnego zadania CoNLL 2017 i tworzymy dwa skuteczne rozszerzenia: 1) włączając głębokie kontekstualizowane osadzenia słów zarówno w części tagera mowy, jak i parsera; 2) zestaw parserów przeszkolonych z różną inicjalizacją. Badamy również różne sposoby łączenia brzegów drzew w celu dalszych ulepszeń. Wyniki eksperymentalne na danych rozwojowych pokazują skuteczność naszych metod. W końcowej ocenie nasz system został zajęty pierwszym miejscem według LAS (75.84%) i znacznie przewyższył pozostałe systemy.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ സിസ്റ്റത്തെ വിവരിക്കുന്നു (HIT-SCIR) കോണ്\u200dഎല്\u200d 2018 കൊടുത്തിരിക്കുന്നു. റോ ടെക്സ്റ്റില്\u200d നിന്നും യൂണിവര്\u200dണല ഞങ്ങള്\u200d സ്റ്റാന്\u200dഫോര്\u200dഡിന്\u200dറെ ജയിക്കുന്ന സിസ്റ്റാന്\u200dഫോര്\u200dഡിന്\u200dറെ സിസ്റ്റാന്\u200dഫോര്\u200dഡിന്\u200dറെ വിജയ സിസ്റ്റമില്\u200d നിന്ന് ഞങ്ങളുടെ സന്ദേശം അടിസ്ഥാനമ 2) വ്യത്യസ്തമായ തുടക്കത്തില്\u200d പരിശീലിക്കുന്ന പാര്\u200dസറുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. കൂടുതല്\u200d മെച്ചപ്പെടുത്താനുള്ള വ്യത്യസ്ത വഴികള്\u200d നമ്മള്\u200d പരിശോധിക്കുന്നു. വികസിപ്പിക്കുന്ന വിവരങ്ങളുടെ പരീക്ഷണ ഫലങ്ങള്\u200d നമ്മുടെ രീതികളുടെ പ്രഭാവം കാണിക്കുന്നു. അവസാനത്തെ വിലാസപ്രകാരം നമ്മുടെ സിസ്റ്റത്തെ ആദ്യം ലാസിന്\u200dറെ (75.84%) ഉപയോഗിച്ചു മറ്റുള്ള സിസ്റ്റമുകള്\u200d വലിയ മാര്\u200dഗിന', 'ro': 'Această lucrare descrie sistemul nostru (HIT-SCIR) prezentat la sarcina comună CoNLL 2018 privind interpretarea multilingvă de la text brut la dependențe universale. Ne bazăm depunerea pe sistemul câștigător al Stanford pentru sarcina partajată CoNLL 2017 și facem două extensii eficiente: 1) încorporând încorporări profunde contextualizate de cuvinte atât în partea de etichetare vocală, cât și în parser; 2) parsere de ansamblare instruite cu inițializare diferită. De asemenea, explorăm diferite modalități de concatenare a brazilor pentru îmbunătățiri suplimentare. Rezultatele experimentale privind datele de dezvoltare arată eficacitatea metodelor noastre. În evaluarea finală, sistemul nostru a fost clasat pe primul loc conform LAS (75,84%) și a depășit cu o marjă mare celelalte sisteme.', 'sr': 'Ovaj papir opisuje naš sistem (HIT-SCIR) podignut na CoNLL 2018 zajednièki zadatak o multijezičkom razmatranju sa sirovog teksta na univerzalne zavisnosti. Na osnovu podnošenja Stanfordskog pobedničkog sistema za zajednički zadatak CoNLL 2017 i činimo dve efikasne proširenje: 2) инсембирање парзера обучени са различним инициализацијом. Takoðe istražujemo razlièite naèine za usklađivanje treebancija za daljnje poboljšanje. Eksperimentalni rezultati podataka o razvoju pokazuju efikasnost naših metoda. U konačnoj procjeni, naš sistem je prvi bio rankiran prema LAS-u (75,84%) i nadmašio ostale sisteme velikom marginom.', 'si': 'මේ පැත්තේ අපේ පද්ධතිය (HIT-SCIR) විස්තර කරනවා CoNLL 2018 වලින් භාෂාවික විශ්වාසයෙන් ගොඩක් භාෂාවික විශ්වාසයෙන් විශ අපි ස්ටැන්ෆෝර්ඩ්ගේ ජයග්\u200dරහණ පද්ධතියේ පද්ධතිය CoNLL 2017 වැදගත් වැඩක් සඳහා ප්\u200dරභාවිත විස්තර දෙකක් කරනවා: 1) ගොඩක් සංවිධානය විස් 2) වෙනස් ආරම්භය සඳහා ප්\u200dරශ්නය කරපු පරීක්ෂකයන්ට පරීක්ෂණය කරන්න. අපි වඩා වෙනස් විදියට පරීක්ෂණය කරනවා විදියට විශේෂ විධානය සම්බන්ධ කරනවා. විකාශ දත්තයේ පරීක්ෂණ ප්\u200dරතිචාර පරීක්ෂණ ප්\u200dරතිචාරයක් පෙන්වනවා අපේ විදියට පරීක අන්තිම විශ්ලේෂණයේ අපේ පද්ධතිය LAS (75.84%) වලට පටන් ගත්තා, අනිත් පද්ධතිය ලොකු ප්\u200dරමාණයක් වලින් ප්\u200dරමාණය කරලා', 'so': 'Kanu wuxuu ku qoran yahay nidaamka (HIT-SCIR) oo loo soo dhiibay CoNLL 2018 shaqo lagu sharciyey baaritaanka luuqadaha badan ee Raw-SCIR-Suomiyada jaamacadda. Waxaannu hoos ugu soo dhiibnaa nidaamka guulaysashada Stanford ee CoNLL 2017 shaqada u qaybsan, waxaana sameynaa laba meelood oo faa’iido leh: 1) oo ku qoraya hadal aad u hoosaysay oo ku qoran labada qayb oo ka mid ah tagger iyo parser; 2) Baarlamayaasha lagu tababariyey bilowga kala duduwan. Sidoo kale waxaynu baaraynaa qaabooyin kala duduwan oo la xiriira dareemaha, si loo horumariyo. Imtixaanka ku saabsan macluumaadka horumarinta waxay muujiyaan effektada qaababkayaga. Qiimeyntii ugu dambaysay, nidaamkayaga waxaa marka ugu horeysa lagu qiyaasay LAS (75,84 boqolkiiba) wuxuuna sameynay nidaam kale oo aad u weyn.', 'sv': 'Denna uppsats beskriver vårt system (HIT-SCIR) som lämnats in till CoNLL 2018 delade uppgift om flerspråkig tolkning från råtext till universella beroende. Vi baserar vårt bidrag på Stanfords vinnande system för CoNLL 2017 delade uppgift och gör två effektiva tillägg: 1) införliva djupa kontextuella ordinbäddningar i både delen av taltaggare och parser; 2) ensemblering parsers utbildade med olika initialisering. Vi undersöker också olika sätt att sammanfoga trädbackar för ytterligare förbättringar. Experimentella resultat på utvecklingsdata visar hur effektiva våra metoder är. I den slutliga utvärderingen rankades vårt system först enligt LAS (75,84%) och överträffade de andra systemen med stor marginal.', 'ta': 'இந்த தாள் எங்கள் அமைப்பை (HIT-SCIR) கோன்எல் 2018 க்கு கொடுக்கப்பட்ட பணியை குறிப்பிடுகிறது ரு உரையிலிருந்து உலகளாவிய சார்புகளுக்கு பல ம நாம் ஸ்டான்போர்டின் வெற்றி அமைப்பின் மீது எங்கள் சரணங்களை அடிப்படைக்கிறோம் கோன்எல் 2017 பகிர்ந்த பணியில் பகிர்ந்து மற்றும் இரண்டு விரைவாக விரிவா 2) வெவ்வேறு துவக்கத்துடன் பயிற்சி செய்யப்பட்ட பார்சர்களை குறிப்பிடுகிறது. மேலும் முன்னேற்றங்களுக்கு நாம் வேறு வழிகளைத் தேடுகிறோம். முன்னேற்றத்தின் முடிவுகள் நமது முறைமைகளின் விளைவை காண்பிக்கிறது. இறுதியாக ஆராய்ச்சியில், எங்கள் அமைப்பு முதலில் LAS (75. 84%) வரிசைப்பட்டது மற்ற அமைப்புகளை பெரிய முறையில் செய்துள்ளது.', 'ur': 'This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. ہم نے استنفورد کے غالب سیسٹم کے ذریعہ بنیاد دی ہے CoNLL 2017 کے مشترک کام کے لئے اور دو اثر اثر اضافہ بناتے ہیں: 1) کلام ٹاگر اور پارچر کے دونوں حصے میں عمیق تفصیل لکھی ہوئی کلمات میں جمع کئے جاتے ہیں۔ 2) مختلف آغاز کے ساتھ تعلیم کی پارسروں کو انتشار کرنا۔ ہم نے بھی مختلف طریقوں کی تلاش کی ہے کہ آگے بڑھ جانے کے لئے ترکیب بندوں کو متصل کریں۔ ڈولیپٹ ڈیٹا پر تجربہ کا نتیجہ ہمارے طریقوں کا اثرات دکھاتا ہے۔ آخری ارزیابی میں، ہماری سیسٹم پہلے LAS (75.84%) کے مطابق رقم لیا گیا اور دوسری سیسٹم کو بڑی مرز سے زیادہ اضافہ کیا گیا۔', 'uz': "Бу саҳифа CONLL 2018 томонидан тақдим қилинган системамизга (HIT-SCIR) маълумотни билдиради. Qattiq matnning bir necha tillar парламентини универтарилган маълумотларга тақдим этилган вазифани. Biz Stanford'ning muvaffaqiyatli tizimga qaytadigan vazifani bajaramiz va ikkita effektiv kengaytmalarni bajaramiz: 1) gapiradigan so'zlarni qo'shishga qo'yish va gapiradigan soʻzlarni boshqa qismiga aytib kelamiz; 2) boshqa ishga tayyorlash bilan bog'langan parkerlarni ishga tushirish. Biz o'zida yaxshi yaxshi o'zlari uchun boshqa usullarni o'rganamiz. Taʼminlovchi maʼlumot bajarish natijalari usullarning effektligini ko'rsatadi. Oxirgi qiymatda, bizning tizimimizni LAS (75.84%) asosida birinchi darajada ajratilgan va boshqa tizimlarni katta margin orqali bajarishdi.", 'vi': 'Tờ giấy này mô tả hệ thống của chúng ta (HIT-SCRM) được gửi đến buổi chia sẻ của CO2 thậm chí còn về chế độ phát ngôn nhiều từ Chữ nguyên bản đến các cấp chung. Căn cứ vào hệ thống dành chiến thắng của Stanford cho việc chia s ẻ của CoNLL và tạo ra hai phần mở rộng có hiệu quả: 1) nhập vào cả phần của câu chuyện và của người phân giải; 2) bộ tinh hoà được huấn luyện bằng cách khởi tạo khác. Chúng tôi cũng nghiên cứu cách khác để kiểm soát được khác cầu khác. Kết quả thí nghiệm về dữ liệu phát triển cho thấy hiệu quả của phương pháp. Trong phần đánh giá cuối cùng, hệ thống của chúng tôi được xếp hạng đầu tiên theo LAS (7504=)) và hoàn thành các hệ thống khác với một khoảng cách lớn.', 'bg': 'Настоящата статия описва нашата система (ХИТ-СКИР), представена на споделената задача за многоезично анализиране от суров текст до универсални зависимости. Основаваме представянето си на печелившата система на Станфорд за споделената задача и правим две ефективни разширения: 1) включване на дълбоко контекстуализирани словесни вграждания както в частта на етикета на речта, така и в анализатора; 2) ансамблиращи анализатори, обучени с различна инициализация. Също така изследваме различни начини за конкатениране на дървесни лехи за по-нататъшни подобрения. Експерименталните резултати от данните за разработката показват ефективността на нашите методи. При окончателната оценка нашата система беше класирана на първо място според ЛАС (75.84%) и надмина останалите системи с голям марж.', 'nl': "Dit document beschrijft ons systeem (HIT-SCIR) dat is ingediend bij de gezamenlijke taak van CoNLL 2018 over meertalig parsen van ruwe tekst naar universele afhankelijkheden. We baseren onze inzending op Stanford's winnende systeem voor de gezamenlijke taak CoNLL 2017 en maken twee effectieve extensies: 1) het integreren van diepe contextualiseerde woord embeddings in zowel het deel van spraak tagger als parser; 2) ensembling parsers getraind met verschillende initialisatie. We onderzoeken ook verschillende manieren om boombanken aan elkaar te koppelen voor verdere verbeteringen. Experimentele resultaten op de ontwikkelingsgegevens tonen de effectiviteit van onze methoden aan. In de uiteindelijke evaluatie werd ons systeem als eerste gerangschikt volgens LAS (75.84%) en presteerde het met een grote marge beter dan de andere systemen.", 'da': 'Denne artikel beskriver vores system (HIT-SCIR), der blev indsendt til CoNLL 2018 delte opgave om flersproget tolkning fra rå tekst til universelle afhængigheder. Vi baserer vores indsendelse på Stanfords vindersystem til CoNLL 2017 delte opgave og laver to effektive udvidelser: 1) indarbejder dybe kontekstualiserede ord indlejringer i både den del af tale tagger og parser; 2) sammensætning parsere uddannet med forskellig initialisering. Vi undersøger også forskellige måder at sammenkoble træbakker på for yderligere forbedringer. Eksperimentelle resultater på udviklingsdata viser effektiviteten af vores metoder. I den endelige evaluering blev vores system rangeret første i henhold til LAS (75,84%) og bedre end de andre systemer med stor margin.', 'de': 'In diesem Beitrag wird unser System (HIT-SCIR) beschrieben, das an die gemeinsame Aufgabe CoNLL 2018 über Mehrsprachiges Parsing von Rohtext zu universellen Abhängigkeiten übermittelt wurde. Wir stützen unsere Einreichung auf Stanfords Siegersystem für die gemeinsame Aufgabe CoNLL 2017 und machen zwei effektive Erweiterungen: 1) Einbettung tiefgreifender kontextualisierter Wort-Einbettungen in den Teil von Sprachtagger und Parser; 2) Ensemble Parser trainiert mit unterschiedlicher Initialisierung. Wir erforschen auch verschiedene Möglichkeiten, Baumbänke für weitere Verbesserungen zu verketten. Experimentelle Ergebnisse auf den Entwicklungsdaten zeigen die Wirksamkeit unserer Methoden. In der abschließenden Bewertung wurde unser System nach LAS (75,84%) als Erster eingestuft und übertraf die anderen Systeme deutlich.', 'hr': 'Ovaj papir opisuje naš sustav (HIT-SCIR) koji je podijeljen zajedničkom zadatku CoNLL 2018 o multijezičkom razmatranju iz Raw Text na univerzalne zavisnosti. Podnožavamo podatke na Stanforovom pobjedničkom sustavu za zajednički zadatak CoNLL 2017-a i činimo dvije učinkovite proširenje: 1) uključujući duboko kontekstualizovane riječi uključujući uključenje u oba dijela etiketera govora i analizatora; 2) osiguranje parsera obučenih s različitim inicijalizacijom. Također istražujemo različite načine usklađivanja treebancija za daljnje poboljšanje. Eksperimentalni rezultati podataka o razvoju pokazuju učinkovitost naših metoda. U konačnoj procjeni, naš sustav je prvi bio rankiran prema LAS-u (75,84%) i nadmašio ostale sustave velikom marginom.', 'id': 'Kertas ini menjelaskan sistem kami (HIT-SCIR) yang dihantar ke CoNLL 2018 tugas berbagi tentang penganalisan berbagai bahasa dari teks mentah ke Dependensi Universal. Kami mendasarkan pengiriman kami pada sistem pemenang Stanford untuk tugas CoNLL 2017 berbagi dan membuat dua ekstensi efektif: 1) memasukkan isi kata kontekstualisasi dalam kedua bagian dari tagger pidato dan parser; dan 2) mengumpulkan parser terlatih dengan inisialisasi yang berbeda. Kami juga mengeksplorasi cara yang berbeda untuk menyatukan batang pohon untuk memperbaiki lebih lanjut. Hasil eksperimen pada data pengembangan menunjukkan efektif metode kita. In the final evaluation, our system was ranked first according to LAS (75.84%) and outperformed the other systems by a large margin.', 'fa': 'این کاغذ سیستم ما (HIT-SCIR) را توصیف می\u200cکند که به کار مشترک CoNLL ۲۰۱۸ در مورد تحلیل زیادی زبان از متن Raw به بستگی جهانی ارائه شده است. ما تحویل خود را بر سیستم برنده\u200cی استنفورد برای کار مشترک CoNLL ۲۰۱۷ بنیاد می\u200cدهیم و دو تفاوت موثر می\u200cسازیم: ۱) شامل تفاوت کلمات عمیق در هر قسمت از نقشه\u200cگر و بازیگر سخنرانی است. 2) تعلیم بازرسان با آغاز متفاوت آموزش داده شده است. ما همچنین راه های متفاوتی برای توسعه\u200cهای بیشتر کشف می\u200cکنیم. نتیجه\u200cهای تجربه روی داده\u200cهای توسعه\u200cها موثیت روش\u200cهای ما را نشان می\u200cدهند. در ارزیابی نهایی، سیستم ما اول بر اساس LAS (75.84%) درجه گرفته شد و سیستم های دیگر را با یک مرز بزرگ انجام داد.', 'sw': 'Gazeti hili linaelezea mfumo wetu (HIT-SCIR) uliotolewa kwa CoNLL 2018 ulishirikiana na kazi ya Uchaguzi wa lugha mbalimbali kutoka Maandishi ya Raw mpaka Utegemeo wa Ulimwengu. Tunaweza kuutumia ujumbe wetu kwenye mfumo wa kushinda Stanford kwa ajili ya kazi ya CoNLL 2017 na kufanya maendeleo mawili yenye ufanisi: 1) kuingiza maneno yaliyofanana na yanayoingia katika sehemu ya mabango ya mazungumzo na mchanganyiko; 2) kuwaweka mabunge wakifundishwa kwa kuanzishwa tofauti. Pia tunatafuta njia tofauti za kupambana na viungo vya miti kwa ajili ya maendeleo zaidi. Matokeo ya majaribio kuhusu takwimu za maendeleo yanaonyesha ufanisi wa njia zetu. In the final evaluation, our system was ranked first according to LAS (75.84%) and outperformed the other systems by a large margin.', 'tr': "Bu kagyz biziň sistemimizi (HIT-SCIR) CoNLL 2018-nji ýylda köp diller Parlamak üçin beýleki zada gönderdi. Biz Stanford'yň ýeňiji sistemasyna CoNLL 2017-nji ýyldaky zady üçin paýlaşýarys we iki etkinlik ýetişiklik ýetişiklik ýerini ýerleşdirip otyrdyk: 1) çykyş tenjesi we çykyş tägleriň hem bölegine girdirip daşarylýarys; 2) başga başlançylyk bilen bilinmedilen parsleriň gaýşartmaky üçin taýýarlanýar. Biz çäreleri ýeterlik gelişmeler üçin üýtgetmek üçin farklı yönlerimizi keşfetýäris. Işdeşim maglumatynyň netijeleri biziň ýolymyzyň täsirini görkezýär. Soňky çykyşymyzda sistemamyz LAS-a görä ilkinji derejä döredildi (75.84%) we başga sistemalary uly gabdaly bilen üstüne çykdy.", 'ko': '본고는 우리가 CoNLL 2018 공유 작업에 제출한 시스템(HIT-SCIR)을 설명하는데 이 작업은 원본 텍스트부터 일반적인 의존 항목까지의 다중 언어 해석을 포함한다.우리의 제출은 스탠퍼드대학의 2017년 CoNLL 공유 임무를 바탕으로 한 수상 시스템을 바탕으로 두 가지 효과적인 확장을 진행했다. 1) 어성 표기기와 문법 분석기에 심층 어경화된 단어를 삽입했다.2) 서로 다른 초기화 훈련을 사용하는 암호화 해상도.우리는 또한 나무 라이브러리를 연결하는 다른 방법을 모색하여 더욱 개선했다.데이터를 개발한 실험 결과는 우리 방법의 유효성을 나타냈다.최종 평가에서 우리 시스템은 LAS에 따라 1위(75.84%)를 차지했고 다른 시스템을 비교적 큰 폭으로 앞질렀다.', 'sq': 'Ky dokument përshkruan sistemin tonë (HIT-SCIR) të paraqitur në detyrën e përbashkët të CoNLL 2018 mbi analizimin shumëgjuhës nga teksti i parë në varësitë universale. Ne bazojmë paraqitjen tonë në sistemin fitues të Stanfordit për detyrën e përbashkët të CoNLL 2017 dhe bëjmë dy zgjatje efektive: 1) përfshirjen e përfshirjes s ë thellë kontekstuale të fjalëve në pjesën e shënuesit të fjalës dhe analizuesit; 2) mbledhjen e analizuesve të trajnuar me nisje të ndryshme. Ne gjithashtu eksplorojmë mënyra të ndryshme për përmirësime të mëtejshme. Rezultatet eksperimentale në të dhënat e zhvillimit tregojnë efektshmërinë e metodave tona. Në vlerësimin përfundimtar, sistemi ynë u rendit i pari sipas LAS (75.84%) dhe i tejkaloi sistemet e tjerë me një margin të madh.', 'am': 'ይህ ገጽ ከRaw Text ወደ Universal dependencies (HIT-SCIR) ወደ CoNLL 2018 ሰልፎችን ለብዙልቋንቋ ማዘጋጀት የስርዓታችንን (HIT-SCIR) ይናገራል፡፡ የካንጆርድ አካባቢ 2017 ስርዓቱን በማሸንፍ ላይ አዋጅ እና ሁለትን አካባቢ ስርዓት እናደርጋለን፡፡ 2) በተለየ መጀመሪያ የተማረ ፓርራር ተማርቷል፡፡ እና የዛፎችን አካባቢ ለመቀናቀል የተለየን መንገዶች እንፈልጋለን፡፡ የመፈተና ውጤቶች የድምፅ ዳታዎችን የሥርዓታችንን ጥቅም ያሳያል፡፡ በመጨረሻው ማስታወቂያው፣ ስርዓታችን በመጀመሪያ እንደ LAS (75.84 በመቶ) የተለየ ነበር፣ ሌሎችንም ስርዓቶች በተለየ ትልቅ ክፍል አፈረሱ፡፡', 'af': "Hierdie papier beskrywe ons stelsel (HIT-SCIR) wat na die CoNLL 2018 gedeelde taak aangestuur word op veelvuldige verwerking van Roë Teks na Universele afhangsels. Ons basiseer on s ondersteuning op Stanford se vinnige stelsel vir die CoNLL 2017 deel taak en maak twee effektief uitbreidings: 1) ingesluit diep contextualiseerde woord inbettings in beide die deel van spraak merker en ontwerker; 2) verwerkers wat met verskillende inisialisering opgelei word. Ons ondersoek ook verskillende maniere van samelewing van trappe vir verdere verbeteringe. Eksperimentale resultate op die ontwikkelingsdata vertoon die effektiviteit van ons metodes. In die eindelike evaluering is ons stelsel eerste rangeer volgens LAS (75.84%) en die ander stelsels uitgevoer deur 'n groot marge.", 'hy': 'Այս հոդվածը նկարագրում է մեր համակարգը (ՀԻT-ՍՔԻՌ), որը ներկայացվել է 2018 թվականի ԿՈՆԼ-ի համախմբված հանձնարարության մեջ բազմալեզու վերլուծության մասին, որը վերաբերում է ոչ-խորագրային տեքստից մինչև համաշխարհ Մենք հիմնում ենք մեր ներկայացումը Ստենֆորդի հաղթանակի համակարգի վրա 2017-ի կոնֆորդի հաղթանակի հանձնարարության համար և երկու արդյունավետ ընդլայնումներ ենք կատարում. 1) խորը կոնտեքստիալ բառերի ներգրավումը խոսքի թեգերի և վերլուծում: 2) համախմբելով տարբեր ինիցիալիզացիայի միջոցով վարժեցված խմբագրողներ: Մենք նաև ուսումնասիրում ենք տարբեր միջոցներ, որոնց միջոցով ծառերի սահմանները կարելի է համընդհանուր բարելավման համար: Զարգացման տվյալների փորձարկման արդյունքները ցույց են տալիս մեր մեթոդների արդյունավետությունը: Վերջնական գնահատման արդյունքում մեր համակարգը առաջինը դասակարգել է ըստ ԼԱՍ-ի (75.84 տոկոս), իսկ մյուս համակարգերը ավելի մեծ արժեքով արժեքավորվել են:', 'bn': 'এই পত্রিকা আমাদের সিস্টেম (এইচট-এসসিআর) কোনএল ২০১৮ সালে প্রদান করা হয়েছে রাও টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভরিত কাজের উপর মাল্ আমরা স্ট্যানফোর্ডের বিজয়ী ব্যবস্থার উপর আমাদের প্রতিষ্ঠান নির্ধারণ করি কনএল ২০১৭-এর কাজ শেয়ার করে এবং দুটি কার্যকর বিস্তারিত বিস্তারিত ব্যবস্থা করি:  ২) বিভিন্ন প্রাথমিকভাবে পার্সার প্রশিক্ষণ প্রদান করা হয়েছে। আমরা আরো উন্নতির জন্য বিভিন্ন উপায় খুঁজে বের করি। উন্নয়নের তথ্যের পরীক্ষার ফলাফল আমাদের পদ্ধতির কার্যকর প্রদর্শন করে। শেষ পর্যায়ে আমাদের সিস্টেম প্রথমে ল্যাস অনুসারে (৭৫.', 'az': 'Bu kağıt bizim sistemimizi (HIT-SCIR) CoNLL 2018-nin çoxlu dil Parsing haqqında çoxlu mətndən Universal Dependenciyə göndərilmiş işimizi təsdiqləyir. Biz Stanford 2017-ci CoNLL işinin qələbə sisteminə təsdiqliyimizi təsdiqləyirik və iki faydalı genişliyimizi təsdiqləyirik: 1) 2) müxtəlif başlanğıcılıqla təhsil edilmiş parsileri ensembling. Biz həmçinin daha yaxşılıqlar üçün çətinlikləri birləşdirmək üçün müxtəlif yolları keşfetiririk. Gelişdirmə məlumatının təcrübəsi sonuçları metodlarımızın etkinliğini göstərir. Son değerlendirmədə, sistemimiz ilk dərəcədə LAS (75,84%) ilə dərəcədə edildi və digər sistemləri böyük bir dərəcədən üstün etdi.', 'ca': "Aquest paper descriu el nostre sistema (HIT-SCIR) submetit a la tasca compartida CoNLL 2018 sobre l'analització multilingüe des del text brut a les dependencies universals. Basem la nostra presentació en el sistema de guanyada de Stanford per la tasca compartida CoNLL 2017 i fem dues extensions efectives: 1) incorporar profunds incorporacions de paraules contextualitzades tant en la part de l'etiquetador de discurs com en l'analitzador; 2) reunir analistes entrenats amb diferents inicialitzats. També explorem diferents maneres de concatenar les barres d'arbres per millorar més. Els resultats experimentals sobre les dades de desenvolupament mostren l'eficacia dels nostres mètodes. En l'avaluació final, el nostre sistema va ser classificat primer segons el LAS (75,84%) i va superar els altres sistemes per un gran marge.", 'bs': 'Ovaj papir opisuje naš sistem (HIT-SCIR) podignut na CoNLL 2018 zajednički zadatak o multijezičkom razmatranju iz Raw Text na univerzalne zavisnosti. Naše podnosenje baziramo na Stanfordski pobjednički sistem za zajednički zadatak CoNLL 2017 i činimo dvije efikasne proširenje: 2) osiguranje parsera obučenih različitim inicijalizacijama. Također istražujemo različite načine za usklađivanje sporazuma za daljnje poboljšanje. Eksperimentalni rezultati podataka o razvoju pokazuju učinkovitost naših metoda. U konačnoj procjeni, naš sistem je prvi bio rankiran prema LAS-u (75,84%) i nadmašio ostale sisteme velikom marginom.', 'cs': 'Tento příspěvek popisuje náš systém (HIT-SCIR) předložený ke sdílenému úkolu CoNLL 2018 na vícejazyčné analýze ze surového textu do univerzálních závislostí. Naše předložení vycházíme z vítězného systému Stanfordu pro sdílený úkol CoNLL 2017 a vytváříme dvě efektivní rozšíření: 1) zahrnující hluboké kontextualizované vložení slov do části tageru řeči a parser; 2) sestavování parserů trénovaných s různou inicializací. Také zkoumáme různé způsoby řazení stromových břehů pro další zlepšení. Experimentální výsledky na vývojových datech ukazují efektivitu našich metod. V závěrečném hodnocení byl náš systém na prvním místě podle LAS (75.84%) a výrazně předčil ostatní systémy.', 'fi': 'Tämä artikkeli kuvaa järjestelmäämme (HIT-SCIR), joka on lähetetty CoNLL 2018 jaettuun tehtävään monikielisestä parsing from Raw Text to Universal Dependences. Perustamme ehdotuksemme Stanfordin voittavaan järjestelmään CoNLL 2017 jaettuun tehtävään ja teemme kaksi tehokasta laajennusta: 1) sisällyttämällä syvällisiä kontekstualisoituja sanaupotuksia sekä puheentunnistajan että jäsentäjän osaan; 2) yhdistelevät parserit, jotka on koulutettu erilaisilla alustuksilla. Tutkimme myös erilaisia tapoja yhdistää puupenkkejä lisäparannuksia varten. Kokeelliset tulokset kehitysdatasta osoittavat menetelmien tehokkuuden. Lopullisessa arvioinnissa järjestelmämme sijoittui LAS:n mukaan ensimmäiseksi (75,84%) ja ylitti muut järjestelmät suurella marginaalilla.', 'et': 'Käesolevas artiklis kirjeldatakse meie süsteemi (HIT-SCIR), mis on esitatud CoNLL 2018 jagatud ülesandele mitmekeelse parsimise kohta toortekstist universaalseteni sõltuvusteni. Põhineme Stanfordi võidusüsteemil CoNLL 2017 jagatud ülesande jaoks ja teeme kaks tõhusat laiendust: 1) sügavate kontekstiliste sõnade manustamise lisamine nii kõne sildistaja kui parseri osasse; 2) erineva initsialiseerimisega koolitatud parserite ühendamine. Samuti uurime erinevaid võimalusi puuvardade ühendamiseks edasiste paranduste saavutamiseks. Arendusandmete eksperimentaalsed tulemused näitavad meie meetodite efektiivsust. Lõpphinnangus oli meie süsteem LAS-i järgi esimesel kohal (75,84%) ja ületas teiste süsteemide suure marginaali.', 'jv': "Perintah iki nggawe sistem (HIT-scIR) sampeyan nggawe CoNLL Kamu wis dipun nggawe task nang Multilenguang Parasing nang rawe Text sampeyan Universal dependancies. Awak dhéwé sistem sing gawe nggawe barêng-barêng nggawe iki bakal ning CoNLL, ndéwé sawar nggawe lan tambah iki luwih apik: 1) iso nggawe sistem sistem sing gawe kontinuatik dhéwé, sing berarti barêng-barêng langgambar gawe ngulinakake tarjamahan lan uga sawar 2) indentation Awak dhéwé éntukno wektu nggawe barang-barêng nggawe gerakan luwih dumadhi. Menu item to Open 'Search for Open Files' dialog Nyong kelelangan anyari kabèh sing ditambah, sistem dhéwé wis sakjane tualke tanggal LAS (75.4 %) lan nganggo sistem sing wis rangke grang.", 'sk': 'Ta prispevek opisuje naš sistem (HIT-SCIR), predložen skupni nalogi CoNLL 2018 o večjezičnem razčlenjanju iz surovega besedila v univerzalne odvisnosti. Naš prispevek temelji na Stanfordovem zmagovalnem sistemu za skupno nalogo CoNLL 2017 in naredi dve učinkoviti razširitvi: 1) vključitev globokih kontekstualnih besednih vdelav v del označevalnika govora in razčlenjevalnika govora; 2) sestavljanje razčlenjevalnikov, usposobljenih z različno inicializacijo. Za nadaljnje izboljšave raziskujemo tudi različne načine konkateniranja drevesnih plošč. Eksperimentalni rezultati razvojnih podatkov kažejo učinkovitost naših metod. V končni oceni je bil naš sistem na prvem mestu glede na LAS (75,84%) in je za veliko maržo presegel ostale sisteme.', 'ha': "Wannan karatun na bayyana tsarin na'urarmu (AIT-SCIR) wanda aka aika zuwa CoNLL 2018 mai shirin aikin da aka yi shi a kan Parse na Raw Text zuwa Universal Debugaris. Tuna bincike nasarinmu a kan cin nasara na Stanford na samun aikin CoNLL 2017 mai rabo kuma mu sami faɗi biyu masu amfani da aikin: 1) ya shigar da magana mai ƙaranci cikin shirin ayuka da kuma tsoron; 2) An sami parparser da aka yi wa fara-gabatarwa na daban. Kayya, Munã sami wasu hanyõyi dabam-dabam da ke samura sauri ga improve. Matarin jarrabo a kan data na buɗe zayen ayukanmu. Ga ƙarshen kalma, an ranar da system na farko da kwamfyutan Los'a (70.84%) kuma ya sami wasu na'ura da margin babba.", 'he': 'This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies.  אנחנו מבססים את ההצגה שלנו על מערכת הניצחון של סטנפורד עבור משימה משותפת CoNLL 2017 ולעשות שתי התרחשות יעילות: 1) הכילוי תוכניות מילים עמוקות קונטוקטואליזציה לשני החלק של Tagger הנאום ופרסר; 2) אסוף פרסמים מאומנים עם ניזליזציה שונה. אנו גם חוקרים דרכים שונות להצטנן עצים לשיפורים נוספים. תוצאות ניסויים על נתוני הפיתוח מראות את היעילות של השיטות שלנו. בהערכה הסופית, המערכת שלנו התייצבה ראשונה לפי LAS (75.84%) והעברה את המערכות האחרות על ידי שווה גדולה.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་གི (HIT-SCIR)ལ་CoNLL 2018་ཡི་ནང་དུ་སྤྲོད་ཀྱི་ལས་འགན་སྤྱོད་རྩོམ་པ་ཞིབ་ཀྱི་ནང་དུ་འཇུག་སྤྱོད་བཞིན་པ་ ང་ཚོའི་CoNLL ལོ་རྒྱལ་ཁབ་པ་གི་རྒྱལ་ཁབ་ཀྱི་མིང་ཚོའི་བཀྲམ་སྟོན་དགོས་པ་དེ་ ལྕགས་རིམ་གྱི་འཇུག་སྣོད་གཉིས་ལས་འཕར་རིམ་བཟོ་བྱེད། 2) ensembling parsers trained with different initialization. ང་ཚོས་དབུས་རིས་གཞན་དང་ཡར་རྒྱས་གཏོང་བའི་ཐབས་ལམ་མ་འདྲ་ཞིག་ཀྱང་བརྗོད་བྱས། ཡར་རྒྱས་གོང་ཕྱོགས་ཀྱི་ཕྱོགས་སྐྱེན་ཚད་ལ་ང་ཚོའི་ཐབས་ལམ་ལུགས་སྐྱོན་བྱེད་ཀྱི་ཡོད། མཐའ་མཇུག་གི་དཔྱད་འགན་ལྟར་ན། ང་ཚོའི་མ་ལག་གི་ཚད་LAS(75.84%) དང་མཉམ་དུ་ཚད་ཆེན་པོ་ཞིག་གིས་མཐུན་སྐྱེལ་བ་ཡིན་པ'}
{'en': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing', 'ar': 'التعلم المشترك لنقاط البيع والتوابع لتحليل التبعية العالمية متعدد اللغات', 'pt': 'Aprendizado conjunto de POS e dependências para análise de dependência universal multilíngue', 'fr': "Apprentissage conjoint des points de vente et des dépendances pour l'analyse des dépendances universelle multilingue", 'es': 'Aprendizaje conjunto de PDV y dependencias para el análisis de dependencias universal multilingüe', 'ja': '多言語ユニバーサル依存関係解析のためのPOSと依存関係の共同学習', 'zh': '多言通用恃解析者 POS 与恃以合学', 'ru': 'Совместное изучение POS и зависимостей для многоязычного универсального анализа зависимостей', 'hi': 'बहुभाषी यूनिवर्सल निर्भरता पार्सिंग के लिए पीओएस और निर्भरताओं का संयुक्त सीखना', 'ga': 'Comhfhoghlaim POS agus Spleáchais le haghaidh Parsála Ilteangacha um Spleáchas Uilíoch', 'hu': 'A POS és a függőségek közös tanulása a többnyelvű univerzális függőség értelmezéséhez', 'it': "Apprendimento congiunto di POS e dipendenze per l'analisi multilingue universale della dipendenza", 'ka': 'POS- ის და მრავალური უნივერსოლური განსაკუთრებულობის განსაკუთრების ერთადერთი სწავლება', 'el': 'Κοινή μάθηση των σημείων και των εξαρτήσεων για την ανάλυση της πολυγλωσσικής καθολικής εξάρτησης', 'kk': 'POS және көптеген тілдер көптеген әлемдік тәуелдіктерді талдау үшін біріктіру', 'ms': 'Pelajaran Berkongsi POS dan Dependensi untuk Menghurai Dependensi Universal Berbahasa', 'ml': 'പോസിന്റെയും ആശ്രയിക്കുന്നതിന്റെയും പഠിപ്പിക്കുക', 'mn': 'POS болон олон хэлний олон хэлний хамааралтай байдлын хамааралтай суралцах нь', 'no': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Analysing', 'lt': 'Bendras POS mokymasis ir daugiakalbės universalios priklausomybės analizės dependencijos', 'mk': 'Заедничко учење на POS и зависности за разгледување на мултијазични универзални зависности', 'pl': 'Wspólne uczenie się POS i zależności dla wielojęzycznego uniwersalnego parowania zależności', 'ro': 'Învățarea comună a POS și a dependențelor pentru analizarea dependenței universale multilingve', 'sr': 'Zajedničko učenje POS-a i zavisnosti za razmatranje multijezičke univerzalne zavisnosti', 'so': 'Waxbarashada wadajirka ah ee POS iyo mas’uuliyadda ku xiran baaritaanka dhamaadka luuqadaha badan', 'sv': 'Gemensamt lärande av POS och beroende för flerspråkig universell beroendetolkning', 'mt': 'Tagħlim Konġunt tal-POS u d-Dipendenzi għall-Analiżi tad-Dipendenza Universali Multilingwi', 'si': 'ගොඩක් භාෂාවික විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂය සහ විශේෂතාවක් ඉගෙනීම', 'ta': 'போஸ் மற்றும் சார்ந்த கற்றுக்கொள்ளும் பல மொழி பொருள் சார்ந்த பாசம்', 'ur': 'Multilingual Universal Dependency Parsing کے لئے POS اور Dependencies کی تعلیم ملی', 'uz': 'Name', 'vi': 'Học chung kết trường tiềm năng và phụ thuộc cho sự phân chia chung chung chung chung chung chung chung chung chung', 'bg': 'Съвместно обучение на ПОС и зависимости за многоезично универсално анализиране на зависимостта', 'hr': 'Zajedničko učenje POS-a i zavisnosti za razmatranje multijezičke univerzalne zavisnosti', 'da': 'Fælles læring af POS og afhængigheder for flersproget universel afhængighedsanalyse', 'nl': 'Gezamenlijk leren van POS en afhankelijkheden voor meertalige universele afhankelijkheidsparsing', 'de': 'Gemeinsames Lernen von POS und Abhängigkeiten für mehrsprachiges Universal Dependency Parsing', 'id': 'Pelajaran Bersama-sama POS dan Dependensi untuk Penganalisan Dependensi Universal Berbahasa', 'ko': '다중 언어 통용 의존 분석 중 어성과 의존항의 연합 학습', 'fa': 'Joint Learning of POS and Dependencies for Multilingual Dependency Universal Parsing', 'tr': 'POS we Halkara diller baglanyşyk üçin öwrenmek üçin gabdaly', 'sw': 'Ufunzi wa pamoja wa POS na kutegemea kwa ajili ya Kutegemea Uhuru wa Lugha Duniani', 'af': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing', 'sq': 'Mësimi i përbashkët i POS dhe varësive për analizimin e varësisë universale shumëgjuhëse', 'am': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing', 'az': 'Multilingual Universal Dependency Parsing üçün POS və bağlılıqların öyrənməsi', 'bn': 'বহুভাষী বিশ্ববিদ্যালয়ের নির্ভর পার্সিং এর জন্য POS এবং নির্ভরিত শিক্ষা যুক্ত করুন', 'hy': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing', 'bs': 'Zajedničko učenje POS-a i zavisnosti za razmatranje multijezičke univerzalne zavisnosti', 'ca': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing', 'cs': 'Společné učení POS a závislostí pro vícejazyčné univerzální analýzy závislosti', 'et': 'POSi ja sõltuvuste ühine õppimine mitmekeelse universaalse sõltuvuse parsimiseks', 'fi': 'POS- ja riippuvuussuhteiden yhteinen oppiminen monikielisessä yleismaailmallisessa riippuvuussuunnittelussa', 'jv': 'Join', 'he': 'למידה משותפת של POS והתלויות למחקר תלויות יוניברסליות רבות', 'sk': 'Skupno učenje POS in odvisnosti za večjezično univerzalno razvrščanje odvisnosti', 'ha': '@ action', 'bo': 'Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing'}
{'en': 'This paper describes the system of team LeisureX in the CoNLL 2018 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies. Our ', 'ar': 'تصف هذه الورقة نظام فريق LeisureX في المهمة المشتركة لـ CoNLL 2018: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. يتنبأ نظامنا بعلامة جزء من الكلام وشجرة التبعية معًا. بالنسبة للمهام الأساسية ، بما في ذلك الترميز والتنبؤ والتنبؤ بالمورفولوجيا ، فإننا نستخدم نموذج الأساس الرسمي (UDPipe). لتدريب اللغات منخفضة الموارد ، نعتمد طريقة أخذ العينات بناءً على لغات غنية بالموارد الأخرى. يحقق نظامنا متوسطًا ماكروًا قدره 68.31٪ من نقاط LAS F1 ، مع تحسن بنسبة 2.51٪ مقارنةً بـ UDPipe.', 'fr': "Cet article décrit le système de l'équipe LeisureX dans la tâche partagée ConLL 2018\xa0: Multilingual Parsing from Raw Text to Universal Dependencies. Notre système prédit conjointement la balise de partie du discours et l'arbre de dépendance. Pour les tâches de base, y compris la tokenisation, la lemmatisation et la prédiction morphologique, nous utilisons le modèle de référence officiel (UDPipe). Pour former les langues à faibles ressources, nous adoptons une méthode d'échantillonnage basée sur d'autres langues riches en ressources. Notre système atteint une macro-moyenne de 68,31\xa0% de score LAS F1, avec une amélioration de 2,51\xa0% par rapport à l'UDPipe.", 'es': 'Este artículo describe el sistema del equipo LeisureX en la tarea compartida de CoNll 2018: Análisis multilingüe del texto sin procesar a las dependencias universales. Nuestro sistema predice la etiqueta de la parte del discurso y el árbol de dependencias de forma conjunta. Para las tareas básicas, incluida la tokenización, la lematización y la predicción de morfología, utilizamos el modelo de referencia oficial (UDPipe). Para capacitar a los idiomas de bajos recursos, adoptamos un método de muestreo basado en otros lenguajes de recursos ricos. Nuestro sistema logra una macromedia de 68,31% de puntuación LAS F1, con una mejora del 2,51% en comparación con el UDPipe.', 'pt': 'Este artigo descreve o sistema da equipe LeisureX na tarefa compartilhada CoNLL 2018: análise multilíngue de texto bruto para dependências universais. Nosso sistema prevê a tag da parte do discurso e a árvore de dependência em conjunto. Para as tarefas básicas, incluindo tokenização, lematização e previsão de morfologia, empregamos o modelo de linha de base oficial (UDPipe). Para treinar as linguagens de poucos recursos, adotamos um método de amostragem baseado em outras linguagens de recursos ricos. Nosso sistema atinge uma macromédia de 68,31% de pontuação LAS F1, com uma melhoria de 2,51% em comparação com o UDPipe.', 'ja': '本稿では、CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal DependenciesにおけるチームLeisureXのシステムについて説明します。私たちのシステムは、発話部分タグと依存関係ツリーを共同で予測します。トークン化、レマティゼーション、形態予測を含む基本的なタスクには、公式のベースラインモデル（ UDPipe ）を使用します。低資源言語を訓練するために、他のリッチ資源言語に基づいたサンプリング方法を採用しています。当社のシステムは、UDPipeと比較して2.51 ％の改善で、68.31 ％のLAS F 1スコアのマクロ平均を達成しています。', 'hi': 'यह पेपर CoNLL 2018 साझा कार्य में टीम LeisureX की प्रणाली का वर्णन करता है: रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग। हमारी प्रणाली संयुक्त रूप से भाग-के-भाषण टैग और निर्भरता पेड़ की भविष्यवाणी करती है। टोकनाइजेशन, लेमेटाइजेशन और आकृति विज्ञान भविष्यवाणी सहित बुनियादी कार्यों के लिए, हम आधिकारिक बेसलाइन मॉडल (UDPipe) को नियोजित करते हैं। कम संसाधन भाषाओं को प्रशिक्षित करने के लिए, हम अन्य समृद्ध संसाधनों वाली भाषाओं के आधार पर एक नमूना विधि अपनाते हैं। हमारा सिस्टम UDPipe की तुलना में 2.51% के सुधार के साथ 68.31% LAS F1 स्कोर का मैक्रो-औसत प्राप्त करता है।', 'ru': 'В этой статье описывается система командного LeisureX в CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Наша система совместно предсказывает тег части речи и дерево зависимостей. Для основных задач, включая токенизацию, лемматизацию и прогнозирование морфологии, мы используем официальную базовую модель (UDPipe). Чтобы обучить языки с низкимиресурсами, мы принимаем метод выборки, основанный на других богатыхресурсных языках. Наша система достигает среднего макроуровня 68,31% балла по шкале LAS F1 с улучшением на 2,51% по сравнению с UDPipe.', 'zh': '本文引CoNLL 2018共享LeisureX团队统:自本至通用多言解析。 吾统共占词性标倚。 凡大务,包标记化,词形化形占候,官方基线(UDPipe)。 为训低资源语,用他富采样法。 吾统成68.31%LAS F1分之宏观平均值,与UDPipe为2.51%矣。', 'ga': 'Déanann an páipéar seo cur síos ar chóras na foirne LeisureX i dTasc Comhroinnte CoNLL 2018: Parsáil Ilteangach ó Théacs Raw go Spleáchas Uilíoch. Déanann ár gcóras an chlib chuid cainte agus an crann spleáchais a thuar go comhpháirteach. Le haghaidh na dtascanna bunúsacha, lena n-áirítear tokenization, lemmatization agus tuar moirfeolaíochta, bainimid úsáid as an múnla bonnlíne oifigiúil (UDPipe). Chun na teangacha íseal-acmhainne a oiliúint, glacaimid modh samplála bunaithe ar theangacha eile saibhris. Baineann ár gcóras macra-mheán scór 68.31% amach LAS F1, feabhas de 2.51% i gcomparáid leis an UDPipe.', 'ka': 'ამ დოკუნტის სისტემის შეტყობინება CoNLL 2018 საერთო დავალების სისტემის შესახებ: მრავალენგური გადაწყვება შესახებ ტექსტიდან უნივერსოლური განსახებებისთვის. ჩვენი სისტემა დაწყვეტის სიტყვების ნაწილად და დამხოლობას ხე. პირადი დავალებებისთვის, რომელიც ტოკენიზაცია, ლემომატიზაცია და მორფოლოგიის წინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწ ჩვენ მარტივი რესურსისების ენების გასწავლისთვის, ჩვენ სხვა რესურსისურსისურსისური ენების დაბაზედ გამოყენება. ჩვენი სისტემა მიიღება მაკრო-ცენტრი 68,31% LAS F1 წერტილი, რომელიც 2,51% წერტილის შესაბამისია UDPipe-ზე.', 'el': 'Η παρούσα εργασία περιγράφει το σύστημα της ομάδας στην Κοινή Εργασία Πολυγλωσσική Ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Το σύστημά μας προβλέπει την ετικέτα μέρους του λόγου και το δέντρο εξάρτησης από κοινού. Για τις βασικές εργασίες, συμπεριλαμβανομένης της επισήμανσης, της λεμματοποίησης και της μορφολογικής πρόβλεψης, χρησιμοποιούμε το επίσημο μοντέλο βάσης. Για να εκπαιδεύσουμε τις γλώσσες χαμηλής περιεκτικότητας σε πόρους, υιοθετούμε μια μέθοδο δειγματοληψίας βασισμένη σε άλλες γλώσσες πλούσιων πηγών. Το σύστημά μας επιτυγχάνει έναν μακρομέσο όρο 68,31% βαθμολογία με βελτίωση 2,51% σε σύγκριση με το UDPipe.', 'hu': 'Ez a tanulmány bemutatja a LeisureX csapat rendszerét a CoNLL 2018 megosztott feladatban: többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig. Rendszerünk közösen előrejelzi a beszédrész címkét és a függőség fáját. Az alapvető feladatokhoz, beleértve a tokenizációt, lemmatizációt és morfológiai előrejelzést, a hivatalos alapmodellt (UDPipe) alkalmazzuk. Az alacsony erőforrású nyelvek képzéséhez más richforrású nyelveken alapuló mintavételi módszert alkalmazunk. Rendszerünk 68,31%-os LAS F1 pontszámot ér el makróátlagban, az UDPipe-hez képest 2,51%-os javulással.', 'lt': 'Šiame dokumente aprašoma komandos LeisureX sistema CoNLL 2018 bendroje užduotyje: daugiakalbis analizavimas nuo žaliavinio teksto iki universaliųjų priklausomybių. Mūsų sistema kartu numato kalbos dalį ir priklausomybės medį. For the basic tasks, including tokenization, lemmatization and morphology prediction, we employ the official baseline model (UDPipe).  Kad mokytume mažai išteklių turinčias kalbas, imame mėginių ėmimo metodą, pagrįstą kitomis turtingomis kalbomis. Mūsų sistema pasiekia 68,31 % LAS F1 balo makroekonominį vidurkį ir 2,51 % pagerėjo, palyginti su UDPipe.', 'it': "Questo articolo descrive il sistema del team LeisureX nell'attività condivisa CoNLL 2018: analisi multilingue dal testo grezzo alle dipendenze universali. Il nostro sistema prevede congiuntamente il tag part-of-speech e l'albero delle dipendenze. Per le attività di base, tra cui tokenizzazione, lemmatizzazione e previsione morfologica, utilizziamo il modello di base ufficiale (UDPipe). Per formare le lingue a basso contenuto di risorse, adottiamo un metodo di campionamento basato su altre lingue richsource. Il nostro sistema raggiunge una macro-media del 68,31% LAS F1 score, con un miglioramento del 2,51% rispetto all'UDPipe.", 'kk': 'Бұл қағаз CoNLL 2018 ортақ тапсырмасында LeisureX тобының жүйесін таңдайды: Көптілік талдау мәтіннен әлемдік тәуелдіктерге дейін. Жүйеміз сөйлеу тегтің бөлігін және тәуелсіздік ағашын біріктіреді. Негізгі тапсырмалар үшін, токенизация, лемматизация және морфология бақылау үшін, официалдық негізгі үлгісін (UDPipe) қолданамыз. Төмен ресурс тілдерін оқыту үшін, басқа бағатты ресурс тілдеріне негізделген мәліметті қолданамыз. Біздің жүйеміз UDPipe дегенмен салыстырып, 68,31% LAS F1 деңгейіндегі макро орташасына жеткізеді.', 'ml': 'ഈ പത്രത്തില്\u200d കോണ്\u200dഎല്\u200d 2018 ലെ ലീസുറെക്സിന്റെ സിസ്റ്റം വിവരിച്ചുകൊടുക്കുന്നു: റോ ലെക്സ്റ്റില്\u200d നിന്നും യൂണിവര്\u200d ആധിപത്യം നമ്മുടെ സിസ്റ്റം സംസാരിക്കുന്നതിന്റെ ഭാഗവും ആശ്രയിക്കുന്നതും ഒരുമിച്ച് പ്രവചിക്കുന്നു. അടിസ്ഥാനത്തിലെ ജോലികള്\u200dക്ക് വേണ്ടി നമ്മള്\u200d ഓഫിക്കല്\u200d ബേസ്ലൈന്\u200d മോഡല്\u200d ഉപയോഗിക്കുന്നു. കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകള്\u200d പരിശീലിപ്പിക്കാന്\u200d, മറ്റു റിച്രീസോഴ്സ് ഭാഷകളില്\u200d അടിസ്ഥാനമായി ഒരു ടാമ്പിള്\u200d ര നമ്മുടെ സിസ്റ്റത്തില്\u200d 68.31% ലാസ് F1 സ്കോര്\u200d പ്രാപിക്കുന്നു. യുഡിപിപ്പിയോടൊപ്പം 2.51% മെച്ചപ്പെടുത്തുന്നു.', 'mt': 'Dan id-dokument jiddeskrivi s-sistema ta’ tim LeisureX fil-Kompitu Konġunt CoNLL 2018: Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali. Is-sistema tag ħna tipprevedi b’mod konġunt it-tikketta tal-parti tad-diskors u s-siġar tad-dipendenza. Għall-kompiti bażiċi, inkluż it-tokenizzazzjoni, il-lemmatizzazzjoni u t-tbassir tal-morfoloġija, aħna nużaw il-mudell uffiċjali tal-linja bażi (UDPipe). Biex inħarrġu l-lingwi b’riżorsi baxxi, niddottaw metodu ta’ teħid ta’ kampjuni bbażat fuq lingwi oħra ta’ riżorsi rikki. Is-sistema tagħna tilħaq makromedija ta’ 68.31% punteġġ LAS F1, b’titjib ta’ 2.51% meta mqabbel mal-UDPipe.', 'mn': 'Энэ цаас CoNLL 2018 оны хуваалтын ажил дээрх LeisureX багийн системийг тодорхойлж байна: Raw Text-ээс олон хэлний шинжилгээ ертөнцийн хамааралтай. Бидний систем ярианы нэг хэсэг болон хамааралтай модыг нийлүүлдэг. Үндсэн даалгаваруудын тулд бид үндсэн суурь шугам загварыг (UDPipe) ашигладаг. Бага боловсролын хэл суралцахын тулд бусад баян боловсролын хэл дээр зарцуулах арга хэрэглэдэг. Бидний систем UDPipe-тай харьцуулахад 2.51% дэвшилтэй макро дундаж 68.31% LAS F1 оноо гардаг.', 'no': 'Denne papiret beskriver systemet for gruppa LeisureX i CoNLL 2018 delt oppgåve: Multispråk tolking frå Raw Text til universelle avhengighet. Sistemet vårt foregår den delen av talemerket og avhengighetstrået saman. For grunnleggjande oppgåver, inkludert tokenisering, lemmatisering og forhåndsvising av morfologi, bruker vi den offisielle baseline-modellen (UDPipe). For å trene dei låge ressursspråka, bruker vi eit prøvemetode basert på andre rådgressursspråk. Sistemet vårt oppnår eit makro gjennomsnitt på 68,31% LAS F1- poeng, med forbetringa av 2,51% samanlikna med UDPipe.', 'mk': 'Овој весник го опишува системот на тимот LeisureX во Соделената задача CoNLL 2018: Мултијазично анализирање од суров текст до универзални зависности. Нашиот систем го предвидува делот од говорот и дрвото на зависноста заедно. За основните задачи, вклучувајќи ја и токенизацијата, лематизацијата и предвидувањето на морфологијата, го користиме официјалниот основен модел (UDPipe). To train the low-resource languages, we adopt a sampling method based on other richresource languages.  Нашиот систем постигнува макро-просечен резултат од 68,31 отсто од LAS F1, со подобрување од 2,51 отсто во споредба со UDPipe.', 'sr': 'Ovaj papir opisuje sistem tima LeisureX u zajedničkom zadatku CoNLL 2018: Multilingual Parsing from Raw Text to Universal Dependencies. Naš sistem predviđa dio govornog oznake i drvo zavisnosti zajedno. Za osnovne zadatke, uključujući tokenizaciju, lematizaciju i morfologiju, koristimo zvanični model početne linije (UDPipe). Da bi obučili jezike niskih resursa, usvojili smo metodu uzoraka na osnovu drugih jezika bogatstva. Naš sistem postiže makro prosječan rezultat od 68,31% LAS F1, uz poboljšanje od 2,51% u usporedbi s UDPipeom.', 'si': 'මේ පැත්තේ කණ්ඩායම LeisureX ගේ පද්ධතිය CoNLL 2018 සමාගත වැඩක් තියෙනවා: රාව් පාළුවෙන් පාළුවෙන් ජාතික විශේෂ විශේෂ ව අපේ පද්ධතිය ප්\u200dරශ්නයක් කතාවේ කොටස් ටැග් සහ අවශ්\u200dයතාවක් ගස් එක්ක ඉන්නේ. මූලික වැඩක් සඳහා, ටොකෙනිසයි, ලෙම්මාසියාව සහ මෝර්ෆෝලෝජික විශ්වාස කරනවා, අපි ප්\u200dරධානික අධ්\u200dයාත අඩුම සම්පූර්ණ භාෂාව ප්\u200dරධානය කරන්න, අපි අනිත් සම්පූර්ණ භාෂාව අධාරිත විදියට සැම්ප් අපේ පද්ධතියේ මැක්රෝ සාමාන්\u200dයය 68.31% LAS F1 ප්\u200dරමාණයක් ලැබෙනවා, UDPipe එක්ක 2.51% වැඩි වැඩි වෙනවා.', 'ro': 'Această lucrare descrie sistemul echipei LeisureX în CoNLL 2018 Shared Task: Parsing multilingv de la text brut la dependențe universale. Sistemul nostru prezice eticheta part-of-speech și arborele dependențelor împreună. Pentru sarcinile de bază, inclusiv tokenizarea, lemmatizarea și predicția morfologiei, utilizăm modelul oficial de bază (UDPipe). Pentru a instrui limbile cu resurse reduse, adoptăm o metodă de eșantionare bazată pe alte limbi richresource. Sistemul nostru atinge o medie macro de 68,31% LAS F1 scor, cu o îmbunătățire de 2,51% comparativ cu UDPipe.', 'pl': 'Niniejszy artykuł opisuje system zespołu LeisureX w ramach wspólnego zadania CoNLL 2018: Wielojęzyczna analiza tekstu surowego do zależności uniwersalnych. Nasz system wspólnie przewiduje tag części mowy i drzewo zależności. Do podstawowych zadań, w tym tokenizacji, lemmatyzacji i przewidywania morfologii, stosujemy oficjalny model bazowy (UDPipe). Aby szkolić języki niskich zasobów, przyjmujemy metodę próbkowania opartą na innych językach źródłowych. Nasz system osiąga makro średnią 68,31% wyniku LAS F1, z poprawą 2,51% w porównaniu z UDPipe.', 'so': 'Warqaddan waxaa ku qoran nidaamka LeisureX ee kooxda CoNLL 2018 ee lagu sharciyey shaqo: Jardiiska luuqadaha badan ee Raw-Text-to-Dependence Universal. nidaamkayaga wuxuu si wada jir ah u sheegayaa qeybta warqadda iyo geedka ku saabsan. Shaqooyinka aasaasiga ah, tusaale ahaan calaamadda, iskudhurinta iyo wixii la sii sheegay morphologka, waxaynu shaqaynaynaa modelka aasaasiga ah (UDPipe). Si aan ugu tababarino luqadaha hoose ee rasmiga, waxaynu u qaadanaa qaab sameynta oo ku saleysan luuqadaha kale ee afka afka ricricihiga ah. Systemkanagu wuxuu gaadhaa qiyaastii 68.31 boqolkiiba LAS F1, wuxuuna kordhisay boqolkiiba 2.51 oo isbarbardhigay UDPipe.', 'sv': 'Denna uppsats beskriver systemet för team LeisureX i CoNLL 2018 Shared Task: Flerspråkig tolkning från råtext till universella beroende. Vårt system förutspår deltalstaggen och beroendeträdet gemensamt. För de grundläggande uppgifterna, inklusive tokenisering, lemmatisering och morfologiprediktion, använder vi den officiella baslinjen modellen (UDPipe). För att utbilda lågresursspråk använder vi en samplingsmetod baserad på andra richsource språk. Vårt system uppnår ett makro-genomsnitt på 68,31% LAS F1 poäng, med en förbättring på 2,51% jämfört med UDPipe.', 'ta': 'இந்த தாள் கோன்எல் 2018 பகிர்ந்த பணியில் குழு LeisureX அமைப்பை விளக்குகிறது: ரி உரையிலிருந்து பல மொழி பாசிங்கள் பொதுவான சார்ந்தது. எங்கள் அமைப்பு பேச்சு ஒட்டியின் பகுதி மற்றும் சார்ந்த மரம் ஒன்றாக முன்வாக்குகிறது. அடிப்படையான பணிகளுக்கு, ஒளிப்புக்குறிப்பு, இம்மாதிரிப்பு மற்றும் மாதிரி முற்றிலும் உள்ள அடிப்படையான செயல்களுக்கு, நாம குறைந்த மூலத்தின் மொழிகளை பயிற்சி செய்ய, மற்ற richresource மொழிகளை அடிப்படையில் நாம் மாதிரி முறை எங்கள் கணினியில் 68.31% LAS F1 மதிப்பெண்ணின் மேக்ரோ சராசரி பெறுகிறது, UDPipe க்கு ஒப்பிட்ட 2.51% மேம்படுத்தப்பட்டது.', 'ur': 'This paper describes the system of team LeisureX in the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. ہمارا سیستم بات کا ٹاگ اور اعتمادی درخت کے ساتھ پیش بینی کرتا ہے۔ بنیادی کاموں کے لئے، ٹوکنیزی، لیمٹیزی اور مارفولوژی پیش بینی کے شامل، ہم رسمی بنیاس لین موڈل (UDPipe) کو استعمال کرتے ہیں۔ کم منبع زبانوں کی تعلیم کے لئے، ہم ایک نمونگ طریقہ قبول کرتے ہیں اور دوسری ثروت منبع زبانوں پر بنیاد رکھتے ہیں. ہماری سیسٹم نے UDPipe کے مقابلہ میں 2.51 درصد کا مکرو متوسط لیا ہے۔', 'ms': 'This paper describes the system of team LeisureX in the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.  Sistem kita meramalkan tag-bahagian-ucapan dan pokok dependensi bersama-sama. Untuk tugas asas, termasuk tokenization, lemmatization dan ramalan morfologi, kami menggunakan model asas rasmi (UDPipe). Untuk melatih bahasa sumber rendah, kami mengadopsi kaedah pengumpulan berdasarkan bahasa sumber kaya lain. Our system achieves a macro-average of 68.31% LAS F1 score, with an improvement of 2.51% compared with the UDPipe.', 'uz': "Bu qogʻoz CoNLL 2018 yilda boʻlishilgan vazifaning tizimini tahrirlaydi: Raw Matn bilan bir necha tillar parsing Universal dependencies. Our system predicts the part-of-speech tag and dependency tree jointly.  Bu asosiy vazifalar uchun, tashkilotni tasavvur qilish, taqdimlik va morfologi hisoblanishi mumkin, biz rasmiy asosiy asosiy modeli (UDPipe) bilan ishlaymiz. Qanchalik manbaning tillarini o'rganish uchun, biz boshqa richresource tillarida asosida misol usulni o'rganamiz. Bizning tizimmiz UDPip bilan birga bog'liq, 68.31% LAS F1 scori makro bo'ladi.", 'vi': 'Tờ giấy này mô tả hệ thống của đội LeiSuresh trong CLB Chia sẻ Coinb thẩm 8: phát ngôn ngữ khai thác từ văn bản thô đến các mối quan hệ chung. Hệ thống của chúng ta dự đoán từng phần của bài phát biểu và hệ thống phụ thuộc. Đối với các nhiệm vụ cơ bản, bao gồm khả năng đo ký, tỷ lệ và dự đoán của morphology, chúng tôi dùng phương pháp cơ bản chính thức (UDPipe). Để đào tạo ngôn ngữ ít nguồn, chúng tôi chọn một phương pháp lấy mẫu dựa trên các ngôn ngữ giàu khác. Hệ thống của chúng ta đạt được tổng số vi phạm vi vi vi vi quang phổ 6633.37.LAS F1 số lượng lớn hơn so với UDPipe.', 'bg': 'Настоящата статия описва системата на екипа в Споделена задача: Многоезично анализиране от суров текст до универсални зависимости. Нашата система прогнозира заедно маркера част от речта и дървото зависимост. За основните задачи, включително токенизация, лематизация и прогнозиране на морфологията, използваме официалния базов модел (ОДПП). За да обучим езиците с нисък ресурс, ние приемаме метод на извадка, базиран на други езици с богат произход. Нашата система постига макросредно 68.31% резултат с подобрение от 2.51% в сравнение с UDPipe.', 'nl': 'Dit artikel beschrijft het systeem van team LeisureX in de CoNLL 2018 Shared Task: Meertalige Parsing van Raw Text naar Universele Afhankelijkheden. Ons systeem voorspelt gezamenlijk de tag voor het deel van de spraak en de afhankelijkheidsboom. Voor de basistaken, waaronder tokenisering, lemmatisatie en morfologie voorspelling, gebruiken we het officiële baseline model (UDPipe). Om de low-resource talen te trainen, hanteren we een steekproefmethode gebaseerd op andere rijkbrontalen. Ons systeem bereikt een macro-gemiddelde van 68,31% LAS F1 score, met een verbetering van 2,51% ten opzichte van de UDPipe.', 'da': 'Denne artikel beskriver systemet for team LeisureX i CoNLL 2018 delt opgave: Flersproget tolkning fra rå tekst til universelle afhængigheder. Vores system forudsiger del-of-tale tagget og afhængighedstræet i fællesskab. Til de grundlæggende opgaver, herunder tokenisering, lemmatisering og morfologiforudsigelse, anvender vi den officielle baseline model (UDPipe). For at uddanne sprogene med lav ressource anvender vi en prøveudtagningsmetode baseret på andre forskellige sprog. Vores system opnår et makro-gennemsnit på 68,31% LAS F1 score, med en forbedring på 2,51% sammenlignet med UDPipe.', 'hr': 'Ovaj papir opisuje sustav tima LeisureX u zajedničkom zadatku CoNLL 2018. godine: Multilingual Parsing from Raw Text to Universal Dependencies. Naš sustav predviđa dio govornog oznake i drvo zavisnosti zajedno. Za osnovne zadatke, uključujući tokenizaciju, limmatizaciju i predviđanje morfologije, koristimo zvanični početni model (UDPipe). Da bi obučili jezike niskih resursa, usvojili smo metodu uzoraka na temelju drugih jezika bogatstva. Naš sustav postiže makro prosječan rezultat od 68,31% LAS F1, s poboljšanjem od 2,51% u usporedbi s UDPipeom.', 'de': 'Dieser Beitrag beschreibt das System des Teams LeisureX in der CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Unser System prognostiziert gemeinsam den Part-of-Speech-Tag und den Abhängigkeitsbaum. Für die grundlegenden Aufgaben, einschließlich Tokenisierung, Lemmatisierung und Morphologieprognition, verwenden wir das offizielle Baseline-Modell (UDPipe). Um die ressourcenarmen Sprachen zu trainieren, verwenden wir eine Sampling-Methode, die auf anderen Quellsprachen basiert. Unser System erreicht einen Makro-Durchschnitt von 68,31% LAS F1 Score, mit einer Verbesserung von 2,51% im Vergleich zur UDPipe.', 'id': 'Kertas ini menjelaskan sistem tim LeisureX dalam Tugas Berkongsi CoNLL 2018: Penganalisan Berbahasa Dari Teks Raw ke Dependensi Universal. Sistem kita memprediksi bagian dari pidato tag dan pohon dependensi bersama-sama. Untuk tugas dasar, termasuk tokenisasi, lemmatisasi dan prediksi morfologi, kami menggunakan model dasar resmi (UDPipe). Untuk melatih bahasa sumber daya rendah, kami mengadopsi metode sampel berdasarkan bahasa sumber daya kaya lainnya. Sistem kita mencapai makro-rata-rata 68,31% skor LAS F1, dengan peningkatan 2,51% dibandingkan dengan UDPipe.', 'fa': 'این کاغذ سیستم تیم LeisureX را در کار مشترک CoNLL 2018 توصیف می\u200cکند: تحلیل زیادی زبان از متن Raw به بستگی جهانی. سیستم ما قسمتی از نقاشی سخنرانی و درخت بستگی را با هم پیش بینی می\u200cکند. برای وظیفه\u200cهای بنیادی، شامل توکین\u200cسازی، لیماتیزی و پیش\u200cبینی مورفولوژی، ما مدل بنیادی رسمی (UDPipe) را استفاده می\u200cکنیم. برای آموزش زبانهای کمترین منابع، ما روش نمونه\u200cگیری را بر روی زبانهای دیگر منابع ثروتمند می\u200cگیریم. سیستم ما در مقایسه با UDPipe، میکرو متوسط 68.31 درصد نقاط LAS F1 را می رساند.', 'sw': 'Gazeti hili linaelezea mfumo wa timu ya LeisureX katika CoNLL 2018 Kushirikiana na kazi: Uchapishaji wa lugha mbalimbali kutoka Maandishi ya Raw hadi Uingereza. Mfumo wetu unatabiri sehemu ya alama ya hotuba na mti wa kutegemea pamoja. Kwa kazi za msingi, ikiwa ni pamoja na ushahidi, unyanyasaji na utabiri wa maadili, tunatumia muundo rasmi wa msingi (UDPipe). Ili kufundisha lugha hizi za rasilimali chini, tunachukua mbinu za sampuli kwa kutumia lugha nyingine za lugha za lugha. Mfumo wetu unapata wastani wa kiwango cha asilimia 68.31 cha LAS F1, na kuboreshwa kwa asilimia 2.51 ikilinganishwa na chama cha UDP.', 'tr': 'Bu kagyz CoNLL 2018 Mazmunlar Taýgynda LeisureX toparyň sistemini ýazylýar: Halkara diller Parsing From Raw Text to Universal Dependencies. Biziň sistemimiz çykyş tägleriniň bölegini we baglanyşlygyny bir arada çaklaýar. Temel görevler, tokenizasyon, limmatizasyon ve morfoloji tahmininde resmi tabanly modelini (UDPipe) kullanıyoruz. Içi resurslar dili öwrenmek üçin, başga baýramçylyk dillerine daýanýar ýazma yöntemini ulanýarys. Bizim sistemimiz UDPipe ile karşılaşykda 68,31% LAS F1 noktasynda bir macro ortalaması başarıyor.', 'af': "Hierdie papier beskryf die stelsel van team LeisureX in die CoNLL 2018 Gedeelde Opdrag: Multilingual Verwerking van Ro Teks tot Universele Afhanklikhede. Ons stelsel voorskou die deel van spraak etiket en afhanklikheid boom saam. Vir die basiese taak, insluitend tokenisasie, lemmatisasie en morfologie voorskou, gebruik ons die offisiele basisline model (UDPipe). Om die lae hulpbron taal te trein, aanvaar ons 'n versameling metode gebaseer op ander richressource tale. Ons stelsel bereik 'n makro-gemiddelde van 68.31% LAS F1 poeier, met 'n verbetering van 2.51% vergelyk met die UDPipe.", 'sq': 'Ky dokument përshkruan sistemin e ekipit LeisureX në Detyrën e Përbashkët CoNLL 2018: Analizë shumëgjuhëse nga teksti i papërdorur në Varësitë Universale. Our system predicts the part-of-speech tag and dependency tree jointly.  Për detyrat bazë, duke përfshirë tokenizimin, lemmatizimin dhe parashikimin e morfologjisë, ne përdorim modelin zyrtar bazë (UDPipe). Për të trajnuar gjuhët me burime të ulëta, ne miratojmë një metodë kampionati bazuar në gjuhët e tjera të burimeve të pasura. Sistemi ynë arrin një makro-mesatare prej 68.31% rezultati LAS F1, me një përmirësim prej 2.51% krahasuar me UDPipe.', 'am': 'ይህ ገጽ የኮንጆል 2018 ተሳታፊ ስራዎችን የብሔራዊ ደረጃ LeisureX ሲስተም ይናገራል: ከRaw Text ወደ Universal dependencies Multilingual Parsing. ሲስተምረታችን የንግግር መክፈቻ እና የታመነ ዛፍ በአንድነት ይናገራል፡፡ ለመቀናቀል ስራ፣ ማስታወቂያው፣ ማስታወቂያው እና የሞሮፎሎጂ ትንቢት፣ የሥልጣን መደገፊያ (UDPip) ሞዴል እናደርጋለን፡፡ የዝቅተኛ የኩነቶች ቋንቋዎች ለማስተማር፣ ሌሎችን የድሪክsource ቋንቋዎች በመሠረት ላይ የተመሳሳይን ምሳሌ እንወስዳለን፡፡ ሲስተካከላችን ከUDPip ጋር 2.51 በመቶ ማክሮን በመተካከለኛ 68.31 በመቶ LAS F1 score አግኝቷል፡፡', 'hy': 'Այս հոդվածը նկարագրում է թիմի Լիզերեքսի համակարգը 2018 թվականի ԿոնԼԼ ընդհանուր հանձնարարության մեջ՝ բազմալեզու վերլուծություն դատարկ տեքստից մինչև համաշխարհային կախվածություններ: Մեր համակարգը միասին կանխատեսում է խոսքի մասը և կախվածության ծառը: Հիմնական խնդիրների համար, ներառյալ թոկենիզացիայի, լեմմատիզացիայի և մորֆոլոգիայի կանխատեսումների համար, մենք օգտագործում ենք պաշտոնական հիմնական մոդելը (UDPipe). Նվագ ռեսուրսների լեզուների ուսուցանման համար մենք ընդունում ենք նմուշներ վերցնելու մեթոդ, որը հիմնված է այլ հարուստ ռեսուրսների լեզուների վրա: Մեր համակարգը հասնում է 68.31 տոկոսի մակրոմիջին LAS F1-ի գնահատականի, որի բարելավումը 2.51 տոկոսով է համեմատած UDPipe-ի հետ:', 'az': 'Bu kağıt CoNLL 2018 paylaşılmış Taskdə Takım LeisureX sistemini təsdiqləyir: Böyük Mətndən Universel bağlılıqlara çoxlu dil analizi. Sistemimiz sözlərin bir parçasını və bağlılıq ağacını birlikdə təmin edir. İlk işlər üçün, tokenizasyon, limmatizasyon və morfolojik tədbirli olaraq, resmi səviyyə modelini (UDPipe) istifadə edirik. Düşük ressurs dillərini təhsil etmək üçün digər zengin ressurs dillərinə dayanan nümunə çəkmə metodunu təhsil edirik. Sistemimiz UDPipe ilə qarşılaşdığı 2.51%-dən daha yaxşılaşdırılır.', 'bn': 'এই পত্রিকাটি কনএল ২০১৮ সালে লেইসুরেক্সের টিমের ব্যবস্থা বর্ণনা করেছে: রো টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করা মাল্টিভা আমাদের সিস্টেম ভাষণের ট্যাগ এবং নির্ভরশীল গাছ একত্রে ভবিষ্যদ্বাণী করে। মৌলিক কাজের জন্য, যার মধ্যে প্রতিষ্ঠান, লেম্যামেশন এবং মরোফোলজি ভবিষ্যৎবাণী রয়েছে, আমরা অফিসিয়াল বেস্লাইন মডেল (উডিপিপি)  নীচের সম্পদ ভাষাকে প্রশিক্ষণ দেয়ার জন্য আমরা অন্যান্য ভাষার ভিত্তিতে ভিত্তিক একটি নমুনা পদ্ধতি গ্রহণ করি। আমাদের সিস্টেম ম্যাক্রো গড়ে ৬৮. ৩১% ল্যাস এফ১ স্কোর অর্জন করে, যার সাথে ইউডিপিপির তুলনায় ২.', 'bs': 'Ovaj papir opisuje sistem tima LeisureX u zajedničkom zadatku CoNLL 2018: Multilingual Parsing from Raw Text to Universal Dependencies. Naš sistem predviđa dio govornog oznake i drvo zavisnosti zajedno. Za osnovne zadatke, uključujući tokenizaciju, limmatizaciju i predviđanje morfologije, koristimo zvanični početni model (UDPipe). Da bi obučili jezike niskih resursa, usvojili smo metodu uzorka na temelju drugih jezika bogatstva. Naš sistem postiže makro prosječan rezultat od 68,31% LAS F1, s poboljšanjem od 2,51% u usporedbi s UDPipeom.', 'ko': '본고는 CoNLL 2018 공유 작업 중의 팀 LeisureX 시스템: 원본 텍스트부터 일반적인 의존 항목까지의 다중 언어 해석을 묘사한다.우리 시스템은 단어 라벨과 의존 트리를 연합하여 예측한다.기본 임무에 대해 표기화, 레몬화, 형태 예측을 포함하여 우리는 공식 기선모델(UDPipe)을 채택했다.저자원 언어를 훈련시키기 위해 우리는 다른 풍부한 자원 언어를 바탕으로 표본을 추출하는 방법을 채택했다.우리 시스템은 68.31%의 LAS F1 성적의 거시적 평균치를 실현했고 UDPipe에 비해 2.51% 높아졌다.', 'ca': "Aquest article descriu el sistema d'equip LeisureX a la tasca compartida CoNLL 2018: Analització multilingüe des del text brut a les dependencies universals. El nostre sistema prediu juntament l'etiqueta de la part de la fala i l'arbre de dependencia. Per a les tasques bàsiques, incloent la tomenització, la lemmatització i la predicció morfològica, utilitzem el model oficial de base (UDPipe). Per formar les llengües de baix recursos, adoptem un mètode de recolliment de mostres basat en altres llengües de recursos rics. Our system achieves a macro-average of 68.31% LAS F1 score, with an improvement of 2.51% compared with the UDPipe.", 'cs': 'Tento článek popisuje systém týmu LeisureX v CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Náš systém společně předpovídá značku části řeči a strom závislosti. Pro základní úkoly, včetně tokenizace, lemmatizace a morfologické predikce, používáme oficiální základní model (UDPipe). Pro trénink jazyků s nízkými zdroji přijímáme metodu vzorkování založenou na jiných jazycích bohatých zdrojů. Náš systém dosahuje makro-průměru 68,31% LAS F1 skóre, se zlepšením o 2,51% ve srovnání s UDPipe.', 'et': "Käesolevas artiklis kirjeldatakse LeisureXi meeskonna süsteemi CoNLL 2018 Shared Task: Multikeelne parsing toortekstist universaalsetele sõltuvustele. Meie süsteem prognoosib kõneosa sildi ja sõltuvuse puu ühiselt. Põhiülesannete, sealhulgas tokeniseerimise, lemmatiseerimise ja morfoloogia prognoosimise jaoks kasutame ametlikku baasmudelit (UDPipe). Vähese ressursiga keelte koolitamiseks võtame kasutusele valimimeetodi, mis põhineb teistel Richre Source keeltel. Meie süsteem saavutab makrokeskmise 68,31% LAS F1 skoori, paranedes UDPipe'iga võrreldes 2,51%.", 'fi': 'Tässä artikkelissa kuvataan LeisureX-tiimin järjestelmää CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependences -sarjassa. Järjestelmämme ennustaa puheen osa-tagin ja riippuvuuspuun yhdessä. Perustehtäviin, kuten tokenisointiin, lemmatisointiin ja morfologian ennustamiseen, käytämme virallista perusmallia (UDPipe). Vähävaraisten kielten kouluttamiseksi otamme käyttöön näytteenottomenetelmän, joka perustuu muihin lähdekieliin. Järjestelmämme saavuttaa makrokeskiarvon 68,31% LAS F1 -pisteen ja 2,51% parannuksen UDPipeen verrattuna.', 'jv': 'This paper description the System of group LesureX in the CoNLL 2013 shared tasks: Multilanguage Parasing from rou Text to Universal dependncies. Click here to continue. Sistem awak dhéwé ngerti-nglanggar wicara-wicara ngono mêng langgar kuwi. Sampeyan pangan dumadhi, dumadhi tokenisaan, lematisaan karo preguntasi mroleh Ing luwih-luwih langgampun sing wis ana, kita sumungit sistem Sampling, kang basa saking langgampun liyane Sistem dhéwé éngawe barang macro-kalamlan kanggo kalagayaan karo sekondi 6.31% LAS F1, barêng langkung 2.31% nggawe gerarané karo udPipe.', 'ha': "Wannan karatun na describe the system of team LeisureX in the CoNLL 2018 Shared Takar: multilanguage Parsinging from Raw Text to Universal dependants. Ana gabatar da rabon tagon magana da itãcen da ake shige a haɗe. Ga sakamakon aikin muhimmada, kamar shirin ayuka, mutilation da littafan mutalogi, za'a yi amfani da misalin ayuka na rubutu (UDP). To, idan an sanar da harshen masu ƙasan-resource, sai mu zãɓi wani misali a kan baka harshen miski. Ubuntu na sami matsayin macro-babban nau'i na 68.31% ya MAS F1, da wani improve na 2.51% da aka sammenliki da UDevelopment.", 'sk': 'Ta prispevek opisuje sistem ekipe LeisureX v skupni nalogi CoNLL 2018: večjezično razporejanje od surovega besedila do univerzalnih odvisnosti. Naš sistem skupaj napoveduje oznako dela govora in drevo odvisnosti. Za osnovne naloge, vključno z žetonizacijo, lemmatizacijo in napovedovanjem morfologije, uporabljamo uradni osnovni model (UDPipe). Za usposabljanje jezikov z nizkimi viri uporabljamo metodo vzorčenja, ki temelji na drugih jezikih z bogatim izvorom. Naš sistem dosega makropovprečno 68,31% LAS F1 rezultat, z izboljšanjem za 2,51% v primerjavi z UDPipe.', 'bo': 'ཤོག ང་ཚོའི་མ་ལག་གིས་ཤུལ་བྱང་གི་ཆ་ཤས་དང་མཉམ་དུ་རྟེན་འབྲེལ་གྱི་དབྱིབས་མཐུན་སྔོན་འདོད་ཡོད། ང་ཚོས་གཞུང་ལུགས་ཀྱི་བྱ་འགུལ་ལ་དེ་དཔེར་བརྗོད་བྱས་པ་དང་། ཆི་རྣམ་པ་དང་དབྱེ་རིམ་རྟོགས་པའི་སྔོན་སྒྲིག་ཚོས་གཞུང་གཞ ང་ཚོས་རྒྱུ་དངོས་ཐོན་ཁུངས་ཀྱི་སྐད་རིགས་ཆ་ཉུང་བའི་དབྱེ་རིགས་ཅིག་ལྟ་བུ་འཇུག་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་མ་ལག་གིས་UDPipe་དང་མཉམ་དུ་རྒྱ་ཆེ་མཐོང་ཚད་68.31% དཔལ་འབོར་ཐུབ་པ་ཡིན།', 'he': 'העיתון הזה מתאר את מערכת הקבוצה LeisureX במשימה משותפת CoNLL 2018: בדיקת רבות שפות מהטקסט ראש לתלויות universal. המערכת שלנו חוששת את התג החלקי של הנאום ועץ התלויות ביחד. עבור המשימות הבסיסיות, כולל טוקניזציה, למטיזציה וחזוי מורפולוגיה, אנו משתמשים במודל הבסיס הרשמי (UDPipe). כדי לאמן את שפות משאבים נמוכות, אנו מאמצים שיטת דגימות מבוססת על שפות משאבים עשירות אחרות. Our system achieves a macro-average of 68.31% LAS F1 score, with an improvement of 2.51% compared with the UDPipe.'}
{'en': 'An Improved Neural Network Model for Joint POS Tagging and Dependency Parsing', 'ar': 'نموذج شبكة عصبية محسّن لعلامات نقاط البيع المشتركة وتحليل التبعية', 'es': 'Un modelo de red neuronal mejorado para el etiquetado conjunto de PDV y el análisis de dependencias', 'pt': 'Um modelo de rede neural aprimorado para marcação conjunta de POS e análise de dependência', 'fr': "Un modèle de réseau neuronal amélioré pour le marquage des points de vente conjoints et l'analyse des dépendances", 'ja': 'ジョイントPOSタグ付けと依存関係解析のための改善されたニューラルネットワークモデル', 'zh': '一以合POS志及恃解析者神经网络之', 'ru': 'Улучшенная модель нейронной сети для совместной маркировки POS и анализа зависимостей', 'hi': 'संयुक्त पीओएस टैगिंग और निर्भरता पार्सिंग के लिए एक बेहतर तंत्रिका नेटवर्क मॉडल', 'ga': 'Samhail Líonra Néarach Feabhsaithe le haghaidh Comhchlibeála POS agus Parsáil Spleáchais', 'ka': 'სხვადასხვა POS Tagging და Dependency Parsing', 'el': 'Ένα βελτιωμένο μοντέλο νευρωνικού δικτύου για κοινή σήμανση και ανάλυση εξάρτησης', 'it': "Un modello di rete neurale migliorato per l'etichettatura congiunta dei POS e l'analisi della dipendenza", 'hu': 'Javított neurális hálózati modell a közös POS címkézéshez és függőség-értelmezéshez', 'lt': 'Geresnis bendro POS ženklinimo ir priklausomybės analizavimo neurologinio tinklo modelis', 'kk': 'Joint POS тегтерін және тәуелдік талдау үшін жақсы түрлі желі моделі', 'mk': 'Name', 'ml': 'Joint POS Tagging and Dependency Parsing', 'ms': 'Name', 'mt': 'Mudell imtejjeb tan-Netwerk Newrali għat-Tagging Konġunt tal-POS u l-Analiżi tad-Dipendenza', 'no': 'Name', 'mn': 'Joint POS Tagging and Dependency Parsing for Improved Neural Network Model', 'ro': 'Un model de rețea neurală îmbunătățit pentru etichetarea comună a POS-urilor și analizarea dependenței', 'sr': 'Poboljšan model neuronske mreže za zajedničku oznake POS-a i razmatranje ovisnosti', 'pl': 'Ulepszony model sieci neuronowej dla wspólnego tagowania POS i parowania zależności', 'so': 'A Improved Neural Network Model for Joint POS Tagging and Dependence Parsing', 'si': 'සම්බන්ධ POS ටැග් එක්ක සහ විශේෂතාවක් විශාලනය සඳහා විශේෂතාවක් නිර්මාණ ජාලය මොඩේල්', 'ur': 'Joint POS Tagging and Dependency Parsing کے لئے ایک بہترین نیورال نیٹ ورک موڈل', 'sv': 'En förbättrad neural nätverksmodell för gemensam POS-märkning och beroendetolkning', 'ta': 'இணைப்பு POS ஒட்டுதல் மற்றும் சார்ந்த பாடலுக்கான மேம்படுத்தப்பட்ட நெயுரல் பிணையத்தின் மாதிரி', 'uz': 'Name', 'vi': 'Mô hình mạng thần kinh tốt hơn cho thẻ bài vị kết vị và độ quan hệ', 'nl': 'Een verbeterd neuraal netwerkmodel voor gezamenlijke POS-tagging en afhankelijkheidsparsing', 'bg': 'Подобрен модел на невралната мрежа за съвместно маркиране на ПОС и анализ на зависимостта', 'da': 'En forbedret neural netværksmodel for fælles POS-mærkning og afhængighedsanalyse', 'hr': 'Poboljšan model neurone mreže za zajedničku oznake POS-a i razmatranje ovisnosti', 'ko': '개선된 연합어성 표기와 의존 분석 신경 네트워크 모델', 'fa': 'Name', 'de': 'Ein verbessertes neuronales Netzwerkmodell für gemeinsames POS-Tagging und Dependency Parsing', 'sw': 'Utandao wa Mtandao wa Neural ulioboreshwa kwa Uchaguzi na Kutegemea', 'tr': "POS'i흫 birle힊en t채gleri we ba휓lylik Ta첵첵arlamak 체챌in Ewir Ta첵첵arlanan Network Modeli", 'id': 'Name', 'sq': 'An Improved Neural Network Model for Joint POS Tagging and Dependency Parsing', 'hy': 'Միացյալ POS-ի նշանների և կախվածության վերլուծության բարելավված նյարդային ցանցի մոդել', 'bn': 'Joint POS ট্যাগিং এবং নির্ভর পার্সিং এর জন্য একটি উন্নত নেউরাল নেটওয়ার্ক মডেল', 'af': 'Name', 'bs': 'Poboljšan model neuronske mreže za zajedničku oznake POS-a i razmatranje ovisnosti', 'am': 'አዲስ ዶሴ ፍጠር', 'az': 'Joint POS Tagging and Dependency Parsing üçün Improved Neural Network Model', 'et': 'Parandatud neuroaalse võrgu mudel ühise POS märgistamiseks ja sõltuvuse analüüsimiseks', 'fi': 'Parannettu hermoverkkomalli yhteisen kassajärjestelmän merkintää ja riippuvuuden analysointia varten', 'ca': 'Un model de xarxa neuronal millorat per a etiquetar conjuntament POS i analitzar dependencies', 'cs': 'Vylepšený model neuronové sítě pro společné značení POS a analýzu závislosti', 'jv': 'ProgressBarUpdated', 'ha': '@ action', 'he': 'Name', 'sk': 'Izboljšan model živčnih omrežij za označevanje skupnih prodajnih mest in analiziranje odvisnosti', 'bo': 'Joint POS Tagging and Dependency Parsing for Improved Neural Network Model for Joint POS Tagging and Dependency Parsing'}
{'en': 'We propose a novel neural network model for joint part-of-speech (POS) tagging and dependency parsing. Our model extends the well-known BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating a BiLSTM-based tagging component to produce automatically predicted POS tags for the ', 'ar': 'نقترح نموذجًا جديدًا للشبكة العصبية لوضع علامات مشتركة على جزء من الكلام (POS) وتحليل التبعية. يوسع نموذجنا محلل التبعية المعتمد على الرسم البياني BIST المعروف (Kiperwasser and Goldberg ، 2016) من خلال دمج مكون العلامات المستند إلى BiLSTM لإنتاج علامات نقاط البيع المتوقعة تلقائيًا للمحلل اللغوي. في بنك الشجرة الإنجليزي القياسي ، حصل نموذجنا على درجات قوية من UAS و LAS عند 94.51٪ و 92.87٪ على التوالي ، مما أدى إلى إنتاج 1.5 +٪ تحسينات مطلقة على المحلل اللغوي القائم على الرسم البياني BIST ، وكذلك الحصول على أحدث نقاط البيع. دقة وضع العلامات 97.97٪. علاوة على ذلك ، تُظهر النتائج التجريبية لتحليل 61 من بنوك التبعيات العالمية "الكبيرة" من النصوص الأولية أن نموذجنا يتفوق في الأداء على UDPipe الأساسي (Straka and Strakova ، 2017) بمتوسط درجات أعلى بنسبة 0.8٪ لمتوسط نقاط البيع و 3.6٪ أعلى من متوسط درجات LAS. بالإضافة إلى ذلك ، من خلال نموذجنا ، نحصل أيضًا على نتائج مهام متطورة للغاية لاستخراج الأحداث الطبية الحيوية وتطبيقات تحليل الرأي. الكود الخاص بنا متاح مع جميع الموديلات المدربة مسبقًا على: <https://github.com/datquocnguyen/jPTDP>', 'fr': "Nous proposons un nouveau modèle de réseau neuronal pour le marquage conjoint de parties du discours (POS) et l'analyse des dépendances. Notre modèle étend le célèbre analyseur de dépendances basé sur des graphes BIST (Kiperwasser et Goldberg, 2016) en incorporant un composant de balisage basé sur BILSTM afin de produire des balises POS prédites automatiquement pour l'analyseur. Sur la banque d'arbres de référence anglaise Penn, notre modèle obtient de solides scores UAS et LAS à 94,51\xa0% et 92,87\xa0%, respectivement, produisant des améliorations absolues de 1,5\xa0% et plus à l'analyseur basé sur les graphes BIST, et obtenant également une précision de balisage POS de pointe à 97,97\xa0%. En outre, les résultats expérimentaux sur l'analyse de 61 «\xa0grandes\xa0» banques d'arbres de dépendances universelles à partir de textes bruts montrent que notre modèle surpasse l'UDpipe de base (Straka et Strakova, 2017) avec un score moyen de marquage POS de 0,8\xa0% plus élevé et un score LAS moyen de 3,6\xa0% plus élevé. De plus, grâce à notre modèle, nous obtenons également des scores de tâches en aval de pointe pour les applications d'extraction d'événements biomédicaux et d'analyse d'opinion. Notre code est disponible avec tous les modèles pré-entraînés à l'adresse suivante\xa0: < https://github.com/datquocnguyen/jPTDP >", 'es': 'Proponemos un modelo de red neuronal novedoso para el etiquetado conjunto de partes del habla (POS) y el análisis de dependencias. Nuestro modelo amplía el conocido analizador de dependencias basado en gráficos BIST (Kiperwasser y Goldberg, 2016) mediante la incorporación de un componente de etiquetado basado en BISTM para producir etiquetas POS predichas automáticamente para el analizador. En el banco de árboles Penn inglés de referencia, nuestro modelo obtiene fuertes puntuaciones de UAS y LAS con un 94,51% y un 92,87%, respectivamente, lo que produce mejoras absolutas de más del 1,5% en el analizador basado en gráficos BIST, y también obtiene una precisión de etiquetado POS de última generación del 97,97%. Además, los resultados experimentales sobre el análisis de 61 bancos de árboles «grandes» de Dependencias Universales a partir de textos sin procesar muestran que nuestro modelo supera al UDPipe de referencia (Straka y Strakova, 2017) con un puntaje promedio de etiquetado POS un 0,8% más alto y un puntaje LAS promedio un 3,6% más alto. Además, con nuestro modelo, también obtenemos puntajes de tareas posteriores de última generación para aplicaciones de extracción de eventos biomédicos y análisis de opinión. Nuestro código está disponible junto con todos los modelos previamente entrenados en: < https://github.com/datquocnguyen/jPTDP >', 'pt': 'Propomos um novo modelo de rede neural para marcação de parte de fala (POS) conjunta e análise de dependência. Nosso modelo estende o conhecido analisador de dependência baseado em gráfico BIST (Kiperwasser e Goldberg, 2016) incorporando um componente de marcação baseado em BiLSTM para produzir tags POS previstas automaticamente para o analisador. No banco de árvores Penn inglês de referência, nosso modelo obtém pontuações fortes de UAS e LAS em 94,51% e 92,87%, respectivamente, produzindo 1,5+% de melhorias absolutas no analisador baseado em gráfico BIST e também obtendo um POS de última geração precisão de marcação em 97,97%. Além disso, resultados experimentais na análise de 61 “grandes” bancos de árvore de dependências universais de textos brutos mostram que nosso modelo supera o UDPipe de linha de base (Straka e Strakova, 2017) com pontuação média de marcação POS 0,8% maior e pontuação média LAS 3,6% maior. Além disso, com nosso modelo, também obtemos pontuações de tarefas downstream de última geração para aplicações de extração de eventos biomédicos e análise de opinião. Nosso código está disponível junto com todos os modelos pré-treinados em: <https://github.com/datquocnguyen/jPTDP>', 'ja': '私たちは、合同部分音声（ POS ）タグ付けおよび依存関係解析のための新規のニューラルネットワークモデルを提案します。 当社のモデルは、BiLSTMベースのタグコンポーネントを組み込むことによって、よく知られているBISTグラフベースの依存関係構文解析器（ Kiperwasser and Goldberg, 2016 ）を拡張し、構文解析器のために自動的に予測されるPOSタグを生成します。 ベンチマークのイングリッシュペンツリーバンクでは、当社のモデルは、それぞれ94.51 ％および92.87 ％の強力なUASおよびLASスコアを取得し、BISTグラフベースのパーサーに1.5+ ％の絶対的な改善をもたらし、また97.97 ％の最先端のPOSタグ付け精度を取得します。 さらに、RAWテキストから61の「BIG」ユニバーサル依存性ツリーバンクを解析する実験結果は、当社のモデルがベースラインUDPipe （ Straka and Strakova, 2017 ）を上回り、平均POSタグスコアが0.8%高く、平均LASスコアが3.6%高くなることを示しています。 さらに、当社のモデルでは、バイオメディカルイベント抽出および意見分析アプリケーションの最先端のダウンストリームタスクスコアも取得します。 当社のコードは、すべての事前トレーニング済みモデルと一緒に入手できます。 <https://github.com/datquocnguyen/jPTDP>', 'hi': 'हम संयुक्त भाग-भाषण (पीओएस) टैगिंग और निर्भरता पार्सिंग के लिए एक उपन्यास तंत्रिका नेटवर्क मॉडल का प्रस्ताव करते हैं। हमारा मॉडल पार्सर के लिए स्वचालित रूप से अनुमानित पीओएस टैग का उत्पादन करने के लिए एक BiLSTM-आधारित टैगिंग घटक को शामिल करके प्रसिद्ध BIST ग्राफ-आधारित निर्भरता पार्सर (किपरवासर और गोल्डबर्ग, 2016) का विस्तार करता है। बेंचमार्क अंग्रेजी पेन ट्रीबैंक पर, हमारा मॉडल क्रमशः 94.51% और 92.87% पर मजबूत यूएएस और एलएएस स्कोर प्राप्त करता है, जो बीआईएसटी ग्राफ-आधारित पार्सर में 1.5 + % पूर्ण सुधार का उत्पादन करता है, और 97.97% पर अत्याधुनिक पीओएस टैगिंग सटीकता भी प्राप्त करता है। इसके अलावा, कच्चे ग्रंथों से 61 "बड़े" यूनिवर्सल निर्भरता ट्रीबैंक को पार्स करने पर प्रयोगात्मक परिणाम बताते हैं कि हमारा मॉडल 0.8% उच्च औसत पीओएस टैगिंग स्कोर और 3.6% उच्च औसत एलएएस स्कोर के साथ बेसलाइन यूडीपाइप (स्ट्राका और स्ट्राकोवा, 2017) को मात देता है। इसके अलावा, हमारे मॉडल के साथ, हम बायोमेडिकल इवेंट निष्कर्षण और राय विश्लेषण अनुप्रयोगों के लिए अत्याधुनिक डाउनस्ट्रीम कार्य स्कोर भी प्राप्त करते हैं। हमारा कोड सभी पूर्व-प्रशिक्षित मॉडलों के साथ उपलब्ध है: <https://github.com/datquocnguyen/jPTDP>', 'zh': '建一以合词性(POS)志以解析新型神经网络。 广众所知于 BIST 图之所恃解析器(Kiperwasser 与 Goldberg,2016),因并于 BiLSTM 组件以为解析器 POS 。 于准English Penn树库之上,吾形得强大之UASLAS,分为94.51%92.87%,基于BIST图之解析器生1.5%以上绝而更进之,又得97.97%之先进POS准确率。 自始文本解析61大通赖树库之实验结果表明,形优于基线UDPipe(StrakaStrakova,2017)均POS标识分高出0.8%,均LAS得分高出3.6%。 此外因我模样,我们还得了生物医学事提和议论的最先进的下流职务分数。 吾代码与凡豫教者共之,网址曰<https://github.com/datquocnguyen/jPTDP>', 'ru': 'Предложена новая модель нейронной сети для совместной маркировки части речи (POS) и синтаксического анализа зависимостей. Наша модель расширяет широко известный парсер зависимостей на основе графов BIST (Kiperwasser and Goldberg, 2016) путем включения компонента тегирования на основе BiLSTM для получения автоматически предсказанных POS-тегов для парсера. На сравнительном английском Penn treebank, наша модель получает сильные баллы UAS и LAS на 94,51% и 92,87%, соответственно, что дает 1,5 +% абсолютных улучшений для BIST-анализатора на основе графов, а также получает самую современную точность POS-метки на 97,97%. Кроме того, экспериментальные результаты по анализу 61 «большого» древостоя универсальных зависимостей из необработанных текстов показывают, что наша модель превосходит базовую UDPipe (Straka and Strakova, 2017) с 0,8% более высоким средним баллом POS-метки и 3,6% более высоким средним баллом LAS. В добавлении, с нашей моделью, мы также получаем самые современные оценки задачи вниз по потоку для применений извлечения биомедицинского события и анализа мнения. Наш код доступен вместе со всеми предварительно обученными моделями по адресу: <https://github.com/datquocnguyen/jPTDP>', 'ga': 'Molaimid samhail líonra néarúil nua le haghaidh clibeáil chomhpháirteach de chuid cainte (POS) agus parsáil spleáchais. Leathnaíonn ár múnla an parsálaí spleáchais graf-bhunaithe BIST atá ar eolas go maith (Kiperwasser agus Goldberg, 2016) trí chomhpháirt clibeála bunaithe ar BiLSTM a ionchorprú chun clibeanna POS tuartha go huathoibríoch a tháirgeadh don pharsálaí. Ar bhruach crann tagarmharcála Béarla Penn, faigheann ár múnla scóir láidre UAS agus LAS ag 94.51% agus 92.87%, faoi seach, ag táirgeadh feabhsuithe iomlána 1.5+% ar pharsálaí graf-bhunaithe BIST, agus faigheann sé POS úrscothach freisin. cruinneas clibeála ag 97.97%. Ina theannta sin, léiríonn torthaí turgnamhacha ar pharsáil crann crann 61 “mór” um Spleáchas Uilíoch ó théacsanna amh go sáraíonn ár múnla an bunlíne UDPipe (Straka agus Strakova, 2017) le meánscór clibeála POS 0.8% níos airde agus meánscór LAS 3.6% níos airde. Ina theannta sin, lenár múnla, faightear scóir thascanna iartheachtacha den scoth le haghaidh feidhmeanna eastóscadh imeachtaí bithleighis agus anailíse tuairimí. Tá ár gcód ar fáil mar aon leis na samhlacha réamhoilte go léir ag: <https://github.com/datquocnguyen/jPTDP>', 'ka': "ჩვენ პრომენტის ნეიროლური ქსელის მოდელის შესაძლებლობად ერთმანეთი სიტყვების (POS) ჭდეების და დასაწყვებელობის პარალისთვის. ჩვენი მოდელმა უცნობიერი BIST გრაფიკური დასაწყებული დასაწყებელობის პანსერერი (Kiperwasser და Goldberg, 2016) გადაყენებით BiLSTM-ის დაბათებული მაგრაფიკური კომპონენტი, რომელიც ავტომატურად გადაწყენებული ჩვენი მოდელეში ძალიან UAS და LAS მონაცემები 94.51% და 92.87%, რომლებიც 1.5+% აბსოლუტური უფლება BIST გრაფიკური პანსერისთვის და ასევე მიიღება სწორი POS მონაცემები 97.97%. დამატებით, ექსპერიმენტიური წარმოდგენები 61 'დიდი' სამყარო განსაკუთრებულებები წარმოდგენება წარმოდგენებული ტექსტიდან, რომ ჩვენი მოდელი უფრო გავაკეთება UDPipe (Straka და Strakova, 2017) და 0.8% უფრო მეტი POS მონიშნული წარმოდგენება დამატებით, ჩვენი მოდელთან, ჩვენ ასევე მივიღეთ ბიომედიციო მოვლენების ექსტრაქცია და განსაზღვრების ანალიზაციის პროგრამებისთვის შესაძლებლობა. ჩვენი კოდის შესაძლებელია ყველა წინატვირთვის მოდელებით: https://github.com/datquocnguyen/jPTDP >", 'hu': 'Egy új neurális hálózati modellt javasolunk a közös beszédrész (POS) címkézéshez és a függőség elemzéséhez. Modellünk kibővíti a jól ismert BIST gráf alapú függőség-elemzőt (Kiperwasser és Goldberg, 2016) egy BiLSTM alapú címkéző komponens beépítésével, hogy automatikusan előrejelzett POS címkéket állítson elő az elemzőhöz. Az angol Penn treebank referenciaértékén modellünk erős UAS és LAS pontszámot ér el 94,51%, illetve 92,87%, ami 1,5%-os abszolút javítást eredményez a BIST gráf alapú elemzőjének, valamint 97,97%-os POS címkézési pontosságot is elér. Továbbá 61 "nagy" univerzális függőség fából történő elemzésével kapcsolatos kísérleti eredmények azt mutatják, hogy modellünk túllépi a kiindulási UDPipe-t (Straka és Strakova, 2017), 0,8%-kal magasabb átlagos POS címkézési pontszámmal és 3,6%-kal magasabb átlagos LAS pontszámmal. Ezenkívül modellünkkel korszerű downstream feladatpontszámokat is kapunk az orvosbiológiai események kitermeléséhez és véleményelemzési alkalmazásokhoz. Kódunk az összes előképzett modellel együtt elérhető: < https://github.com/datquocnguyen/jPTDP >', 'el': "Προτείνουμε ένα νέο μοντέλο νευρωνικού δικτύου για κοινή σήμανση μέρους ομιλίας και ανάλυση εξάρτησης. Το μοντέλο μας επεκτείνει τον γνωστό αναλυτή εξαρτήσεων βασισμένο σε γραφήματα ενσωματώνοντας ένα στοιχείο επισήμανσης βασισμένο στο BiLSTM για την παραγωγή αυτόματα προβλεπόμενων ετικετών για τον αναλυτή. Στην αγγλική τράπεζα δέντρων αναφοράς, το μοντέλο μας αποκτά ισχυρές βαθμολογίες UAS και LAS σε 94.51% και 92.87%, αντίστοιχα, παράγοντας 1.5+% απόλυτες βελτιώσεις στον αναλυτή βασισμένο σε γραφήματα και επίσης αποκτώντας μια υπερσύγχρονη ακρίβεια σήμανσης σε 97.97%. Επιπλέον, πειραματικά αποτελέσματα για την ανάλυση 61 'μεγάλων' δέντρων καθολικών εξαρτήσεων από ακατέργαστα κείμενα δείχνουν ότι το μοντέλο μας ξεπερνά τη βασική τιμή με 0,8% υψηλότερη μέση βαθμολογία και 3,6% υψηλότερη μέση βαθμολογία LAS. Επιπλέον, με το μοντέλο μας, αποκτούμε επίσης υπερσύγχρονες βαθμολογίες εργασιών για εφαρμογές εξαγωγής βιοϊατρικών συμβάντων και ανάλυσης γνώμης. Ο κώδικας μας είναι διαθέσιμος μαζί με όλα τα προ-εκπαιδευμένα μοντέλα στο: < https://github.com/datquocnguyen/jPTDP >", 'it': "Proponiamo un nuovo modello di rete neurale per il tagging congiunto della parte di parlato (POS) e l'analisi delle dipendenze. Il nostro modello estende il noto parser di dipendenza basato su grafico BIST (Kiperwasser e Goldberg, 2016) incorporando un componente di tagging basato su BiLSTM per produrre automaticamente i tag POS previsti per il parser. Sul benchmark inglese Penn Treebank, il nostro modello ottiene forti punteggi UAS e LAS rispettivamente al 94,51% e 92,87%, producendo miglioramenti assoluti dell'1,5% rispetto al parser basato su grafico BIST, e ottenendo anche una precisione di tagging POS all'avanguardia al 97,97%. Inoltre, i risultati sperimentali sull'analisi di 61 'big' Universal Dependences treebank da testi grezzi mostrano che il nostro modello supera il baseline UDPipe (Straka e Strakova, 2017) con un punteggio medio di tagging POS più alto dello 0,8% e un punteggio LAS medio più alto del 3,6%. Inoltre, con il nostro modello, otteniamo punteggi di attività downstream all'avanguardia per applicazioni di estrazione di eventi biomedici e analisi di opinione. Il nostro codice è disponibile insieme a tutti i modelli pre-addestrati a: < https://github.com/datquocnguyen/jPTDP >", 'lt': 'Siūlome naują nervinio tinklo model į, skirtą bendram kalbos dalies žymėjimui ir priklausomybės analizavimui. Mūsų modelis išplečia gerai žinomą BIST grafiniu pagrįstą priklausomybės analizatorių (Kiperwasser ir Goldberg, 2016 m.), įtraukdamas BiLSTM pagrįstą žymėjimo komponentą, kad būtų sukurti automatiškai numatyti POS žymėjimai analizatoriui. Atsižvelgiant į Anglijos Penn medžio bazę, mūsų modelis gauna stiprų UAS ir LAS rezultatus atitinkamai 94,51 % ir 92,87 %, o BIST grafikos analizatoriaus absoliutus pagerėjimas – 1,5 % ir naujausias POS ženklinimo tikslumas – 97,97 %. Be to, eksperimentiniai rezultatai, gauti analizuojant 61 „didelius“ universaliųjų priklausomybių medžių langelius iš žaliavinių tekstų, rodo, kad mūsų modelis viršija pradinį UDPipe (Straka ir Strakova, 2017 m.) su 0,8 % didesniu vidutiniu POS ženklinimo tašku ir 3,6 % didesniu vidutiniu LAS tašku. Be to, naudojant mūsų model į, taip pat gauname naujausius pažangiausius užduočių rezultatus biomedicinių įvykių gavimo ir nuomonės analizės paraiškoms. Mūsų kodas ir visi iš anksto parengti modeliai pateikiami: < https://github.com/datquocnguyen/jPTDP >', 'mk': 'Предложуваме нов модел на нервна мрежа за заедничко означување на дел од говорот (POS) и анализирање на зависноста. Нашиот модел го проширува познатиот анализатор на зависност базиран на графот БИСТ (Kiperwasser и Goldberg, 2016) со вклучување на компонент за обележување базиран на BiLSTM за автоматски да се произведуваат предвидени POS обележувања за анализаторот. Во споредба со англиската пенка, нашиот модел добива силни оценки на УАС и ЛАС на 94,51 отсто, односно 92,87 отсто, произведувајќи 1,5+отстоапсолутни подобрувања на анализаторот базиран на графикот БИСТ, како и добивајќи најсовремена точност на означувањето на POS на 97,97 отсто. Покрај тоа, експерименталните резултати на анализата на 61 „големи“ врски на дрвјата на универзалните зависности од сурови тексти покажуваат дека нашиот модел го надминува почетокот на UDPipe (Страка и Стракова, 2017) со 0,8 отсто повисока просечна оценка на POS и 3,6 отсто повисока просечна оценка на LAS. Покрај тоа, со нашиот модел, ние, исто така, добиваме најсовремени резултати на задачите надвор од текот за биомедицински настани извлекување и апликации за анализа на мислењето. Нашиот код е достапен заедно со сите предобучени модели на: < https://github.com/datquocnguyen/jPTDP >', 'kk': "Біз жалпы сөйлеу (POS) бөлігін тегтерді және тәуелдікті талдау үшін романдық невралдық желінің моделін ұсынамыз. Біздің үлгіміз BIST графикалық тәуелдік талдаушысын (Kiperwasser және Goldberg, 2016) бағытталған BiLSTM негіздеген тегтер компонентін бағдарламасына автоматты түрде бағытталған POS тегтерін құру үшін қолданып келеді. Ағылшын тілінің белгісінде, біздің үлгіміз күшті UAS мен LAS нөмірлерін 94,51% мен 92,87% деп алады, олар BIST графикалық талдаушына 1,5+% абсолютті жақсартылығын жасайды, сондай-ақ 97,97% деген POS тегтерінің дұрыстығын алады. Сонымен қатар, 61 'үлкен' Universal Dependencies treebanks талдау үшін тәжірибе нәтижелері мәтіндердің негізгі UDPipe (Страка және Стракова, 2017) деген моделіміздің орташа 0,8% жоғары POS тегтерінің нәтижесін және 3,6% орташа LAS нәтижесін жоғары Қосымша, өзіміздің моделімізде де биомедикалық оқиғаларды тарқату және оқиғаларды анализ қолданбаларының күй- жайындағы тапсырмаларын алдық. Біздің кодіміз барлық алдында оқылған моделдермен бірге қол жеткізеді: https://github.com/datquocnguyen/jPTDP >", 'ms': "Kami cadangkan model rangkaian saraf baru untuk tag bahagian-dalam-ucapan (POS) dan penghuraian dependensi. Model kami memperluas penghurai dependensi berdasarkan graf BIST yang diketahui (Kiperwasser dan Goldberg, 2016) dengan memasukkan komponen tag berdasarkan BiLSTM untuk menghasilkan tag POS yang dijangka secara automatik untuk penghurai. On the benchmark English Penn treebank, our model obtains strong UAS and LAS scores at 94.51% and 92.87%, respectively, producing 1.5+% absolute improvements to the BIST graph-based parser, and also obtaining a state-of-the-art POS tagging accuracy at 97.97%.  Lagipun, keputusan percubaan mengenai menghurai 61 batang pokok 'besar' Dependensi Universal dari teks mentah menunjukkan bahawa model kami melampaui batas dasar UDPipe (Straka dan Strakova, 2017) dengan skor POS rata-rata yang lebih tinggi 0.8% dan skor LAS rata-rata yang lebih tinggi 3.6%. Selain itu, dengan model kami, kami juga mendapat skor tugas terbaru turun untuk ekstraksi peristiwa biomedikal dan aplikasi analisis pendapat. Our code is available together with all pre-trained models at: < https://github.com/datquocnguyen/jPTDP >", 'mt': 'Aħna nipproponu mudell ġdid tan-netwerk newrali għat-tikkettar konġunt tal-parti tad-diskors (POS) u l-analiżi tad-dipendenza. Il-mudell tagħna jestendi l-analizzatur tad-dipendenza bbażat fuq il-grafika BIST magħruf sew (Kiperwasser u Goldberg, 2016) billi jinkorpora komponent tat-tikkettar ibbażat fuq BiLSTM biex jipproduċi tikketti POS imbassra awtomatikament għall-analizzatur. Fuq il-bażi tas-siġar tal-Pinna Ingliża, il-mudell tagħna jikseb punteġġi qawwija tal-UAS u tal-LAS ta’ 94.51% u 92.87%, rispettivament, u jipproduċi titjib assolut ta’ 1.5+% għall-analizzatur ibbażat fuq il-grafika BIST, u jikseb ukoll preċiżjoni tal-a ħjar tikkettar tal-POS ta’ 97.97%. Barra minn hekk, ir-riżultati sperimentali dwar l-analiżi ta’ 61 “big” Universal Dependencies tree banks minn testi mhux ipproċessati juru li l-mudell tagħna jaqbeż il-linja bażi UDPipe (Straka u Strakova, 2017) b’punteġġ medju ogħla tal-ittikkettjar POS ta’ 0.8% u punteġġ medju ogħla tal-LAS ta’ 3.6%. Barra minn hekk, bil-mudell tagħna, inkisbu wkoll l-aqwa punteġġi ta’ ħidma downstream għall-applikazzjonijiet għall-estrazzjoni ta’ avvenimenti bijomediċi u għall-analiżi tal-opinjoni. Our code is available together with all pre-trained models at: < https://github.com/datquocnguyen/jPTDP >', 'ml': "നമ്മള്\u200d ഒരു നോവല്\u200d ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റ്റര്\u200d മോഡല്\u200d പ്രൊദാന്\u200dസ് ചെയ്യുന്നു. കൂട്ടുകാര്\u200d സംസാരിക്കുന്ന ഭാഗ നമ്മുടെ മോഡല്\u200d ബിഎസ്റ്റ് ഗ്രാഫ് അടിസ്ഥാനമായ ബിസ്റ്റ് ആശ്രയിക്കുന്ന പ്രദര്\u200dശനം (കിപ്പര്\u200dവാസെരും ഗോള്\u200dഡ്ബെര്\u200dഗ്, 2016) ഒരു ബിഎല്\u200dസ്റ്റിംസ് അടിസ്ഥാനമായ ടാഗിങ ബെങ്ക്മാര്\u200dക്കില്\u200d ഇംഗ്ലീഷ് പെന്\u200d ട്രീബാങ്കില്\u200d നമ്മുടെ മോഡല്\u200d 94.51% യുഎസിന്റെയും ലാസിന്റെയും സ്കോര്\u200d ലഭ്യമാകുന്നു. 92.87%, ബിഎസ്റ്റ് ഗ്രാഫ് അടിസ്ഥാനമാക്കിയിരിക്കുന്ന ബിഎസ് ഗ് അതിനുമുമ്പ്, 61 'വലിയ' യൂണിവല്\u200d ഡിപ്പാങ്കുകളില്\u200d നിന്നും പാര്\u200dസ് ചെയ്യുന്നതിന്\u200dറെ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ മോഡല്\u200d ബെസ്റ്റലൈന്\u200d യുഡിപിപ്പി (സ്ട്രാക്കാക്കും സ്ട്ര കൂടാതെ, നമ്മുടെ മോഡലിന്\u200dറെ കൂടെയുള്ള പ്രയോഗങ്ങള്\u200dക്കും ബൈയോമിക്കല്\u200d സംഭവം പുറത്തെടുക്കുന്നതിനും അഭിപ്രായശ്ചിത്രത് ഞങ്ങളുടെ കോഡ് ഒരുമിച്ച് ലഭ്യമാകുന്നു https://github.com/datquocnguyen/jPTDP >", 'pl': "Proponujemy nowy model sieci neuronowej do wspólnego tagowania części mowy (POS) i parsowania zależności. Nasz model rozszerza dobrze znany analizator zależności BIST oparty na wykresie (Kiperwasser i Goldberg, 2016) o włączenie komponentu tagowania opartego na BiLSTM, aby produkować automatycznie przewidywane tagi POS dla parsera. W porównaniu z angielskim bankiem drzew Penn, nasz model uzyskuje silne wyniki UAS i LAS odpowiednio w 94.51% i 92.87% odpowiednio, generując 1.5+% absolutne ulepszenia parsera opartego na wykresie BIST, a także uzyskując najnowocześniejszą dokładność tagowania POS w 97,97%. Ponadto, wyniki eksperymentalne analizy 61 'dużych' bank drzew Universal Dependencies z tekstów surowych pokazują, że nasz model przewyższa bazową UDPipe (Straka i Strakova, 2017) z 0,8% wyższym średnim wynikiem tagowania POS i 3,6% wyższym średnim wynikiem LAS. Ponadto, dzięki naszemu modelowi uzyskujemy również najnowocześniejsze wyniki zadań w zakresie ekstrakcji zdarzeń biomedycznych i analizy opinii. Nasz kod jest dostępny wraz ze wszystkimi wstępnie przeszkolonymi modelami pod adresem: < https://github.com/datquocnguyen/jPTDP >", 'ro': 'Propunem un nou model de rețea neurală pentru etichetarea comună a părții de vorbire (POS) și analizarea dependenței. Modelul nostru extinde binecunoscutul parser de dependență bazat pe grafice BIST (Kiperwasser și Goldberg, 2016) prin încorporarea unei componente de etichetare bazate pe BiLSTM pentru a produce etichete POS anticipate automat pentru parser. Pe baza benchmark-ului Penn englezesc, modelul nostru obține scoruri UAS și LAS puternice la 94,51% și respectiv 92,87%, producând îmbunătățiri absolute de 1,5% la parserul bazat pe grafice BIST și obținând, de asemenea, o precizie de marcare POS de ultimă generație la 97,97%. Mai mult decât atât, rezultatele experimentale privind analizarea a 61 de brake "mari" Universal Dependences din texte brute arată că modelul nostru depășește UDPipe de bază (Straka și Strakova, 2017) cu 0,8% mai mare scor mediu de etichetare POS și cu 3,6% mai mare scor mediu LAS. În plus, cu modelul nostru, obținem, de asemenea, scoruri de sarcini de ultimă generație în aval pentru aplicații de extragere a evenimentelor biomedicale și analiză de opinie. Codul nostru este disponibil împreună cu toate modelele pre-instruite la: < https://github.com/datquocnguyen/jPTDP >', 'sr': "Predlažemo nov model neuralne mreže za zajedničku ulogu govora (POS) oznake i analizu zavisnosti. Naš model proširi poznati analizator ovisnosti na grafiku BIST (Kiperwasser i Goldberg, 2016) uključujući komponent oznake na BiLSTM-u kako bi proizveli automatski predviđene oznake POS za analizatora. Na benchmarku engleski Pen treebank, naš model dobija jake rezultate UAS i LAS na 94,51% i 92,87%, odnosno, proizvodi apsolutne poboljšanja u analizatoru na grafiku BIST-a, a takođe dobija tačnost u stanju umjetnog POS-a na 97,97%. Nadalje, eksperimentalni rezultati na analizu 61 'velikih' univerzalnih zavisnosti od sirovih tekstova pokazuju da naš model iznosi početnu UDPipe (Straka i Strakova, 2017) sa 0,8% višim prosječnim rezultatima označavanja POS-a i 3,6% višim prosječnim rezultatima LAS-a. Osim toga, sa našim modelom, dobijamo i rezultate rezultata za sniženje biomedicinskih događaja za izvlačenje i analizu mišljenja. Naš kod je dostupan zajedno sa svim predobučenim modelima na: https://github.com/datquocnguyen/jPTDP - Да.", 'si': "අපි ප්\u200dරශ්නයක් කරනවා න්\u200dයූරල් ජාල ප්\u200dරශ්නයක් සම්බන්ධ කතාව (POS) කොටස් කොටස් එක්ක ටැග් කරනවා සහ අවශ්\u200d අපේ මොඩල් හොඳින් දන්නේ BIST ග්\u200dරාෆ් අධාරිත විශ්වාසය (Kipervasserand Goldberg, 2016) බිල්ස්ටිම් අධාරිත ටැග් අංකයක් ස්වයංක්\u200dරියාවිතයෙන් ප්\u200dරව බෙන්ච්මාර්ක් ඉංග්\u200dරීසි පෙන් ට්\u200dරෙබැන්ක් වලින්, අපේ මොඩල් බලපු UAS සහ LAS ස්කෝර් 94.51% සහ 92.87% වලින්, සාමාන්\u200dය විශේෂයෙන්, 1.5+% නිර්මාණ විශේෂ විදියට BIST ග්\u200dරාෆ් ස ඉතින්, 61 'ලොක්' ජාතික විශ්වාසික විශ්වාසික විශ්වාස කරපු පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන් විදිහට අපේ මොඩේල් අ ඒ වගේම, අපේ මොඩේල් එක්ක, අපි ජීවිත වෛද්\u200dය සිද්ධ විශ්ලේෂණය සහ හිත විශ්ලේෂණය අවස්ථාවක් සඳහා ස්ථානයේ  අපේ කෝඩ් එක්ක පුළුවන් විදිහට පුළුවන් හැම ප්\u200dරධානයක් තියෙනවා: < https://github.com/datquocnguyen/jPTDP >", 'so': "Tusaale ahaan shabakadda neurada ee wadajirka ah ee ku hadla (POS) baaritaanka iyo jardiinada ku xiran. Tusaalkayagu wuxuu ku fidiyaa baaritaanka ku saabsan BIST (Kiperwasser iyo Goldberg, 2016) si uu u soo saaro qeyb ku qoran BiLSTM-based tagging si uu u soo saaro boostada POS oo si gaar ah loo sii sheego. Bogga afka Ingiriiska Penn treebank, modelkayagu wuxuu helaa qiyaastii aad u xoogaysan UAS iyo LAS oo u dhexeeya 94.51% iyo 92.87%, wuxuuna kordhiyaa 1.5+ oo dhamaan hagaajinta xarafka BIST, wuxuuna sidoo kale heli karaa saxda rasmiga ah ee farshaxanka POS ee ugu horeeya 97.97%. Furthermore, arimaha imtixaanka ee ku saabsan baaritaanka jaamacadda 61 'big' waxay ka muuqataa qoraalka raw ah, modelkayagu wuxuu ka samaysaa kooxda ugu sarreeya UDPipe (Straka and Strakova, 2017) iyo 0.8% oo ugu sarreeya scorada tagging ee POS iyo 3.6% oo ka sareeya darajada LAS. Sidoo kale, Tusaale ahaan, waxaynu heli karnaa kooxaha shaqada hoose-hoose ee xaaladaha baabuurta iyo baaritaanka fikirka. Qoidayadeena waxaa la jira dhammaan samooyin tababar-tababar ah:< https://github.com/datquocnguyen/jPTDP >", 'sv': 'Vi föreslår en ny neural nätverksmodell för gemensam del-of-speech (POS) taggning och beroendetolkning. Vår modell utökar den välkända BIST grafbaserade beroendetolkaren (Kiperwasser och Goldberg, 2016) genom att införliva en BiLSTM-baserad taggkomponent för att producera automatiskt förutspådda POS-taggar för tolkaren. På riktmärket engelska Penn treebank erhåller vår modell starka UAS- och LAS-poäng på 94,51% respektive 92,87%, vilket ger 1,5 +% absoluta förbättringar av BIST grafbaserade parser, och även erhåller en state-of-the-art POS taggning noggrannhet på 97,97%. Dessutom visar experimentella resultat på att tolka 61 "stora" Universal Dependences trädbanker från obehandlade texter att vår modell överträffar baseline UDPipe (Straka och Strakova, 2017) med 0,8% högre genomsnittlig POS tagging score och 3,6% högre genomsnittlig LAS score. Med vår modell erhåller vi dessutom toppmoderna resultaträkningar för biomedicinsk händelseutvinning och opinionsanalys. Vår kod finns tillgänglig tillsammans med alla färdigutbildade modeller på: < https://github.com/datquocnguyen/jPTDP >', 'mn': 'Бид шинэ сэтгэл зүйн сүлжээний загварын нэг хэсэг (POS) маркинг болон хамааралтай хуваалцааны шинэ загварыг санал болгож байна. Бидний загвар нь биST графикийн үндсэн хамааралтай хуваарч (Kiperwasser, Goldberg, 2016) болон BiLSTM-ын үндсэн тагжингийн компонентийг хуваарч автоматжуулсан POS тагжийг бүтээх боломжтой болгодог. Англи хэлний хэлний загвар дээр бидний загвар нь 94.51% болон 92.87% хүчирхэг UAS болон LAS оноо авдаг ба BIST график хуваагдагч дээр 1.5+% бүтээгдэхүүнийг бүтээж байна. Мөн 97.97% нь урлагийн POS-ийн зөв тохиолдол авдаг. Үүнээс гадна, 61 "том" универсал хамааралтай загваруудыг хуваалцах туршилтын үр дүн нь бидний загварын үндсэн шугам UDPipe (Страка болон Стракова, 2017) дээр 0.8% өндөр дундаж POS маркингийн оноо болон дундаж LAS оноо нь 3.6% өндөр байдаг. Мөн бидний загварын хувьд биологийн эмчилгээний үйл ажиллагааны төвшинд бид мөн биологийн эмчилгээний үйл ажиллагааг гаргаж, санааны шинжилгээний хэрэглээ гаргадаг. Бидний код бүх сургалтын өмнө сургалтын загвартай хамтдаа байдаг: https://github.com/datquocnguyen/jPTDP >', 'no': 'Vi foreslår eit nytart neuralnettverksmodell for å markera og tolka avhengighet. Modellen vårt utvidar den kjende BIST-baserte avhengighetsanalysen (Kiperwasser og Goldberg, 2016) ved å inkludere ein BiLSTM-basert merkingkomponent for å produsera automatisk forventa POS-taggar for tolkaren. On the benchmark English Penn treebank, our model obtains strong UAS and LAS scores at 94,51% and 92,87%, respectively, produces 1,5+% absolute improvements to the BIST graph-based analyser, and also obtains a state-of-the-art POS tagging accuracy at 97,97%. Eksperimentale resultat ved tolking av 61 « stor » Universell avhengighet Treebanks frå råtekstar viser at modellen vårt utfører UDPipe baseline (Straka og Strakova, 2017) med 0,8% høgare gjennomsnittlig POS- merkingskort og 3,6% høgare gjennomsnittlig LAS- poeng. I tillegg, med modellen vårt, får vi også tilstand for kunsten nedstrømme oppgåver for biomediske hendingar ekstraksjon og analyser. Koden vårt er tilgjengeleg saman med alle føretrengte modeller på: < https://github.com/datquocnguyen/jPTDP >', 'ta': "நாம் ஒரு புதிய புதிய பாதுகார பேச்சின் பகுதி குறிக்கும் மற்றும் சார்ந்த பாடலுக்கும் ஒரு புதிய பாதுகாரியல் வலை எங்கள் மாதிரி பிஎஸ்ட் வரைபடத்தின் சார்பு விளக்கம் (கிப்பர்வெஸ்டர் மற்றும் கோல்ட்பெர்க், 2016) ஒரு பில்எஸ்டிஎம் அடிப்படையான ஒட்டு கூற்றை சேர்த்து தானாகவே  பெங்குரு ஆங்கிலம் பென் ட்ரீபாங்கில், எங்கள் மாதிரி 94.51% மற்றும் LAS மதிப்புகளை 94.51% மற்றும் 92.87% கிடைக்கும், 1.5+ முழுமையான முன்னேற்றங்களை பிஎஸ் வரைப்படத்தில் அடிப்படையில் பிஎஸ்  அதற்கும் மேலும், சோதனையின் முடிவுகள் 61 'பெரிய' பொருள் சார்பில்லாத சேர்ப்பு முடிவுகள் காண்பிக்கிறது குறைந்த உரைகளிலிருந்து வெளியேறும் மாதிரி மூலம் UDPipe (ஸ்ட்ராக்காவா  மேலும், எங்கள் மாதிரியில், நாங்கள் மாதிரியில் இருந்து கலை கீழ்நோக்கி செயல் புள்ளிகளை பெறுகிறோம் உயிரியல் நிகழ்வு வெள எங்கள் குறியீடு அனைத்து முன் பயிற்சி மாதிரிகளுடனும் கிடைக்கும்: < https://github.com/datquocnguyen/jPTDP >", 'ur': "ہم ایک نور نیورل نیٹ ورک موڈل کی پیشنهاد کرتے ہیں جو ایک قسمت کی بات (POS) ٹاگ اور اعتمادی پارسینگ کے لئے۔ ہمارا موڈل بہتر معلوم BIST گراف بنیاد رکھا ہوا اعتمادی پارچر (Kiperwasser اور Goldberg, 2016) کو ایک BiLSTM بنیاد رکھا ہوا ٹاگنگ komponent بنا کر پارچر کے لئے اپنی طور پر پیش بینی کی POS ٹاگ پیدا کرتا ہے۔ بنچم مارک انگلیسی پن ٹریب بنک پر ہماری مدل 94.51% اور 92.87% پر طاقتور UAS اور LAS اسکورٹ حاصل کرتا ہے، جو BIST گراف بنیاد پارٹر کے لئے 1.5+% مطلوب تغییرات پیدا کرتا ہے، اور 97.97% میں ایک ایٹ پوس ٹیگ مطلوب تغییرات حاصل کرتا ہے۔ اور اس کے علاوہ، 61 'بزرگ' Universal Dependencies Treebanks کے بارے میں آزمائش کا نتیجہ پارس کرنا دکھاتا ہے کہ ہمارا نمڈل ڈیس لین UDPipe (استراکا اور استراکووا، 2017) کو 0.8% اوپر متوسط POS ٹاگ گینگ سکوٹ اور 3.6% اوپر متوسط LAS سکوٹ کے ساتھ اضافہ کرتا ہے. اور ہمارے موڈل کے ساتھ، ہم نے بیوڈیسی ایڈیٹ ڈونسٹریم ٹاکس اسکور کو بھی پایا جو بیوڈیسی ایڈیٹ اکٹرک اور نظر تحلیل کاربرد کے لئے ہے. ہمارا کوڈ تمام پیش آموزش کی مدل کے ساتھ موجود ہے: https://github.com/datquocnguyen/jPTDP >", 'uz': "Biz gapirish qismlari (POS) bilan birlashtirish va ishlatish uchun novel tarmoq modeli rivojlanamiz. Name Benchmark Penn treebankda modelmiz boshqa 94.51% va 92.87% bilan strong UAS va LAS scorlariga ega bo'ladi. Biz BIST grafik asosida bo'lgan kompaniyalar uchun 1.5+ yaxshi yaxshi darajaga ega bo'ladi, va 97.97%-da faqat POS yozuvchi davlatga ega bo'ladi. Ko'rsatganda, 61 'katta' universitetsiya davomida qizil matnlarni ajratish natijalari raqamli matnlaridan foydalanishi mumkin, modelmiz asosiy UDPip (Straka and Strakova, 2017) bilan 0.8% uzoq POS teglagich scori va 3.6% yuqori LAS scorini bajaradi. Ko'pchilik, modelimiz bilan, biz biomedical hodisa chiqarish va fikr analyzer dasturlari uchun shaxsiyatlarning holatini topamiz. Bizning kodlash hamma taʼminlovchi modellar bilan birlashtirilgan: < https://github.com/datquocnguyen/jPTDP >", 'vi': "Chúng tôi đề xuất một mô hình mạng lưới thần kinh mới cho việc phân tích kết hợp bài phát âm và độ phụ thuộc. Phiên bản này mở rộng các phân tích dựa vào đồ thị lớn cùng với các phân tích phụ thuộc thuộc (Kiperwasser và Goldberg, 2006) bằng cách nhập một thành phần hiệu gắn liền BiLSTM để tự động sản xuất các thẻ kết vị phân tích. Trên tiêu chuẩn xuất bản English Penn treeback, mẫu của chúng ta có thể đạt được điểm UAS và LAS mạnh tại 94.51=và97.87=, sản xuất xuất xuất đỉnh cao 1.5+ cải tiến tuyệt đối với phân giải do đồ thị BIN, và cũng đạt được độ chính xác hoàn hảo nhất hoàn hảo tại 97.97=. Hơn nữa, kết quả thử nghiệm về cách phân tích 6'lớn'các trường vạn phụ thuộc bản gốc cho thấy rằng mô hình của chúng ta vượt trội con đường cơ bản UDPipe (Straka và Strakova, thẩm 7) với 0.8 cao hơn so với số hiệu Vị POS và 3.6 cao hơn số điểm LAS trung bình. Với mẫu của chúng ta, chúng ta cũng đạt được điểm công việc hiện đại theo dòng cuối cho các ứng dụng về chiết xuất các sự kiện sinh học và phân tích ý kiến. Mật mã của chúng tôi có sẵn cùng với tất cả các mẫu được huấn luyện https://github.com/datquocnguyen/jPTDP Language", 'hr': "Predlažemo nov model neuralne mreže za zajedničku ulogu govora (POS) oznake i analizu ovisnosti. Naš model proširi poznati analizator ovisnosti na grafiku BIST (Kiperwasser i Goldberg, 2016) uključujući komponent oznake na BiLSTM-u kako bi proizveli automatski predviđene oznake POS za analizatora. Na referenciji engleskog Penn treebanca, naš model dobiva jake rezultate UAS-a i LAS-a na 94,51% i 92,87%, što proizvodi apsolutne poboljšanje na temelju analizatora na grafiku BIST-a i dobija tačnost označavanja stanja umjetnosti POS-a na 97,97%. Osim toga, eksperimentalni rezultati analize 61 'velikih' univerzalnih zavisnosti od sirovih tekstova pokazuju da naš model nadmaže početnu UDPipe (Straka i Strakova, 2017) sa 0,8% višim prosječnim rezultatima POS-a i 3,6% višim prosječnim rezultatima LAS-a. Osim toga, s našim modelom, također dobijamo i rezultate rezultata za sniženje biomedicinskih događaja za izvlačenje i analizu mišljenja. Naš kod je dostupan zajedno sa svim predobučenim modelima na: < https://github.com/datquocnguyen/jPTDP >", 'nl': "We stellen een nieuw neuraal netwerkmodel voor joint part-of-speech (POS) tagging en afhankelijkheidsparsing voor. Ons model breidt de bekende BIST grafiekgebaseerde afhankelijkheidsparser (Kiperwasser en Goldberg, 2016) uit met een BiLSTM-gebaseerde tagging component om automatisch voorspelde POS tags voor de parser te produceren. Op de benchmark Engelse Penn boombank behaalt ons model sterke UAS- en LAS-scores bij respectievelijk 94,51% en 92,87%, waardoor 1,5+% absolute verbeteringen aan de BIST-grafiek-gebaseerde parser oplevert en ook een state-of-the-art POS-tagging nauwkeurigheid bij 97,97%. Verder tonen experimentele resultaten op het parsen van 61 'grote' Universal Dependencies boombanken uit ruwe teksten aan dat ons model beter presteert dan de baseline UDPipe (Straka en Strakova, 2017) met 0,8% hogere gemiddelde POS tagging score en 3,6% hogere gemiddelde LAS score. Daarnaast verkrijgen we met ons model ook state-of-the-art downstream taakscores voor biomedische gebeurtenisextractie en opinieanalyse toepassingen. Onze code is samen met alle voorgetrainde modellen beschikbaar op: < https://github.com/datquocnguyen/jPTDP >", 'bg': 'Предлагаме нов модел на невронна мрежа за съвместно маркиране на част от речта (ПОС) и анализ на зависимостта. Нашият модел разширява добре познатия графичен анализатор на зависимост (Кипервасер и Голдбърг, 2016), като включва компонент за етикетиране, базиран на БиЛСТМ, за да произвежда автоматично прогнозирани ПОС тагове за анализатора. На референтната английска тройна банка, нашият модел получава силни резултати съответно от 94.51% и 92.87%, произвеждайки 1.5+% абсолютни подобрения на базата на графика и също така получавайки най-съвременна точност на маркиране на ПОС при 97.97%. Освен това, експерименталните резултати за анализиране на 61 "големи" дървесни ленти от универсални зависимости от сурови текстове показват, че нашият модел превъзхожда базовия с 0,8% по-висок среден резултат за маркиране на ПОС и 3,6% по-висок среден резултат. Освен това с нашия модел получаваме и най-съвременни оценки на задачите надолу по веригата за извличане на биомедицински събития и приложения за анализ на мненията. Нашият код е достъпен заедно с всички предварително обучени модели на: < https://github.com/datquocnguyen/jPTDP >', 'ko': "우리는 어성 표기와 의존 분석에 사용되는 새로운 신경 네트워크 모델을 제시했다.우리의 모델은 유명한 BIST 그림 기반의 의존 관계 해석기(Kiperwasser와 Goldberg, 2016)를 확장하고 BILSTM 기반의 표기 구성 요소를 통합하여 해석기에 자동으로 예측되는 단어 표기를 생성한다.기준 영어 펜트레뱅크에서 우리 모델은 94.51%, 92.87%의 강력한 UAS와 LAS 점수를 받았고 BIST 그림을 바탕으로 한 해석기에 1.5% 이상의 절대적인 개선을 가져왔으며 97.97%의 최첨단 어성 표기 정확도를 얻었다.또한 원시 텍스트에서 61개의'대'통용 의존 트리 라이브러리를 분석한 실험 결과에 따르면 우리의 모델은 기선 UDPipe(Straka와 Strakova, 2017)보다 우수하고 평균 어성 표기 점수는 0.8%, 평균 LAS 점수는 3.6% 높았다.또한 우리 모델을 통해 생물의학 사건 추출과 의견 분석 응용 프로그램의 최신 하위 임무 점수를 얻었다.Dell 코드는 <https://github.com/datquocnguyen/jPTDP>", 'id': "Kami mengusulkan model jaringan saraf baru untuk tagging bagian-dari-pidato (POS) dan penghuraian dependensi. Model kami memperluas penganalis dependensi berdasarkan grafik BIST yang terkenal (Kiperwasser dan Goldberg, 2016) dengan memasukkan komponen tagging berdasarkan BiLSTM untuk menghasilkan tag POS yang diprediksi secara otomatis untuk penganalis. Pada benchmark pohon Penn Inggris, model kami mendapatkan skor UAS dan LAS yang kuat pada 94,51% dan 92,87%, respectively, menghasilkan 1,5+% peningkatan absolut pada pemeriksa berdasarkan grafik BIST, dan juga mendapatkan akurasi tagging POS state-of-the-art pada 97,97%. Selain itu, hasil percobaan dalam menghurai 61 'besar' Universal Dependencies Treebank dari teks mentah menunjukkan bahwa model kami melampaui batas dasar UDPipe (Straka dan Strakova, 2017) dengan nilai POS rata-rata 0,8% lebih tinggi dan nilai LAS rata-rata 3,6% lebih tinggi. Selain itu, dengan model kami, kami juga mendapatkan skor tugas terbaik turun untuk ekstraksi peristiwa biomedis dan aplikasi analisis pendapat. Our code is available together with all pre-trained models at: < https://github.com/datquocnguyen/jPTDP >", 'fa': 'ما پیشنهاد می\u200cکنیم یک مدل شبکه عصبی جدید برای بررسی کردن قسمت سخنرانی (POS) و بستگی مشترک. مدل ما تقسیم بستگی بر اساس گراف BIST معروف می\u200cشود (Kiperwasser and Goldberg, 2016) با تولید یک بخش Tagging Based BiLSTM برای تولید از توسعه نقاشی POS پیش\u200cبینی برای تقسیم\u200cکننده\u200cها را توسعه می\u200cدهد. در برچسب انگلیسی پن تریبان، مدل ما امتیاز UAS و LAS قوی در 94.51 درصد و 92.87 درصد را دریافت می\u200cکند، با توجه به تولید ۱.۵ درصد کامل تولید می\u200cکند برای بازیگر گراف بنیاد BIST، و همچنین با تولید دقیق برچسب POS هنری در 97.97 درصد دریافت می\u200cکند. علاوه بر این، نتیجه آزمایش\u200cهای تحقیق بر پاره\u200cبندی 61 «بزرگ» بستگی جهانی از متن\u200cهای زرد نشان می\u200cدهد که مدل ما از UDPipe (استراکا و استراکوva، 2017) پایه\u200cبندی پایه\u200cبندی (استراکا و استراکوva) با امتیاز متوسط 0.8% بالاتر POS tagging score و امتیاز متوسط LAS ۳.۶ درصد بالاتر علاوه بر این، با مدل ما، نقطه\u200cهای وضعیت هنری را برای اخراج و تحلیل نظر رویدادهای بیولوپزشکی دریافت می\u200cکنیم. کد ما با تمام مدل\u200cهای پیش آموزش آموزش موجود است: https://github.com/datquocnguyen/jPTDP >', 'tr': "Biz sözlerin (POS) gabdaly parçasyny we baglanylyk parslamak üçin täze bir nural şebeke nusgasyny teklip edip görýäris. Biziň modelimiz bilinen BIST grafdaky baglançylyk tärkezilişini (Kiperwasser we Goldberg, 2016) tärkezilişi üçin otomatik önlenen POS tägleri üretmek üçin BiLSTM tabanly tägleme komponenti goşulýar. Iňlis dilinde Penn treebank çykyşynda biziň modelimiz güýçli UAS we LAS sanlaryny 94.51% we 92.87% diýip kabul edýär we BIST grafdaky parçasynda 1.5+% absolut gelişmeleri bar we 97.97% da möhüm taýýarlar. Furthermore, experimental results on parsing 61 'big' Universal Dependencies treebanks from raw texts show that our model outperforms the baseline UDPipe (Straka and Strakova, 2017) with 0.8% higher average POS tagging score and 3.6% higher average LAS score. Munuň üstünde biziň nusgymyz bilen, biziň hem biomedical hadysalary çykarmak we pikir analizi uygulamalary üçin düşürmeli täzeliklerimizi tapylýarys. Biziň kodymyz öňünden eğlenen nusgalar bilen bar: https://github.com/datquocnguyen/jPTDP >", 'da': "Vi foreslår en ny neural netværksmodel til fælles del-of-tale (POS) tagging og afhængighedsparsing. Vores model udvider den velkendte BIST grafbaserede afhængighedsfortolker (Kiperwasser og Goldberg, 2016) ved at indarbejde en BiLSTM-baseret taggkomponent til at producere automatisk forudsigede POS tags til fortolkeren. På benchmark engelske Penn treebank opnår vores model stærke UAS og LAS scores på henholdsvis 94,51% og 92,87%, hvilket giver 1,5 +% absolutte forbedringer af BIST grafbaserede fortolker, og også opnår en state-of-the-art POS tagging nøjagtighed på 97,97%. Desuden viser eksperimentelle resultater på at analysere 61 'store' Universal Dependences-træbanker fra rå tekster, at vores model overgår baseline UDPipe (Straka og Strakova, 2017) med 0,8% højere gennemsnitlig POS tagging score og 3,6% højere gennemsnitlig LAS score. Derudover opnår vi med vores model også state-of-the-art downstream opgaver scores til biomedicinsk hændelsesudvinding og meningsanalyse applikationer. Vores kode er tilgængelig sammen med alle prætrænede modeller på: < https://github.com/datquocnguyen/jPTDP >", 'sw': "We propose a novel neural network model for joint part-of-speech (POS) tagging and dependency parsing.  Mfano wetu unaeneza mchambuzi wa maarufu wa picha inayotegemea na BIST (Kiperwasser na Goldberg, 2016) kwa kuingiza kifaa chenye kibiashara cha BiLSTM ili kutengeneza alama za POS zinazotabiriwa kwa kujitegemea. Katika bendera ya Penn Treebank ya Kiingereza, mwelekeo wetu unapata vipimo vizuri vya UAS na LAS kwa asilimia 94.51 na 92.87, kwa asilimia 92.87, unaotengeneza maboresho ya moja.5+ muhimu kabisa kwa uchambuzi wa picha za BIST, na pia kupata kiwango kinachofanana na POS ya sanaa kwa asilimia 97.97.97. Zaidi ya hayo, matokeo ya majaribio yanayotokana na kuchimba 'ukubwa' ulimwengu kote yanategemea mitandao mbaya yanaonyesha kwamba model yetu inaonyesha msingi wa UDPipe (Straka na Strakova, 2017) yenye kiwango cha wastani cha POS cha 0.8 cha juu na kiwango cha wastani wa wastani wa LAS wa asilimia 3.6. Zaidi ya hayo, kwa mfano wetu, pia tunapata vipimo vya kazi za sanaa za chini ya mitandao kwa ajili ya kutengeneza matumizi ya kitabibu na uchambuzi wa maoni. Kodi letu linapatikana pamoja na mifano yote ya mafunzo ya awali katika: < https://github.com/datquocnguyen/jPTDP >", 'de': "Wir schlagen ein neuartiges neuronales Netzwerkmodell für Joint Part-of-Speech (POS) Tagging und Dependency Parsing vor. Unser Modell erweitert den bekannten grafischen Abhängigkeitsparser BIST (Kiperwasser und Goldberg, 2016) um eine BiLSTM-basierte Tagging-Komponente, um automatisch prognostizierte POS-Tags für den Parser zu erzeugen. Auf der Benchmark English Penn Treebank erzielt unser Modell starke UAS- und LAS-Scores bei 94,51% bzw. 92,87% und erzielt damit 1,5+% absolute Verbesserungen des BIST graph-basierten Parsers sowie eine hochmoderne POS-Tagging-Genauigkeit bei 97,97%. Darüber hinaus zeigen experimentelle Ergebnisse zum Parsen von 61 'großen' Universal Dependencies Baumbänken aus Rohtexten, dass unser Modell die Baseline UDPipe (Straka und Strakova, 2017) mit 0,8% höheren durchschnittlichen POS Tagging Score und 3,6% höheren durchschnittlichen LAS Score übertrifft. Darüber hinaus erhalten wir mit unserem Modell auch aktuelle Downstream Task Scores für biomedizinische Ereignisextraktion und Meinungsanalyseanwendungen. Unser Code ist zusammen mit allen vortrainierten Modellen verfügbar unter: < https://github.com/datquocnguyen/jPTDP >", 'sq': "Ne propozojmë një model të ri të rrjetit nervor për shënimin e pjesës së përbashkët të fjalimit (POS) dhe analizimin e varësisë. Our model extends the well-known BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating a BiLSTM-based tagging component to produce automatically predicted POS tags for the parser.  Në bazën e pemës Angleze Penn, modeli ynë merr rezultate të forta UAS dhe LAS në 94.51% dhe 92.87%, respektivisht, duke prodhuar 1.5+% përmirësime absolute në analizuesin bazuar në grafik BIST dhe gjithashtu duke marrë një saktësi të lartë të etiketave POS në 97.97%. Përveç kësaj, rezultatet eksperimentale në analizimin e 61 'të mëdhave' të bazave të drurit të Varësive Universale nga tekstet e papërpunuara tregojnë se modeli ynë mbivlerëson bazën e UDPipe (Straka dhe Strakova, 2017) me 0.8% më të lartë mesatare të shënimit të POS dhe 3.6% më të lartë mesatare të LAS. In addition, with our model, we also obtain state-of-the-art downstream task scores for biomedical event extraction and opinion analysis applications.  Kodi ynë është i disponueshëm së bashku me të gjitha modelet e paratrajnuar në: < https://github.com/datquocnguyen/jPTDP >", 'am': "የአሁኑን የኔዌብ መረብ ሞዴል ለመጠቀም የንግግር ክፍል (POS) ማተሚያ እና የመታሰል ማዘጋጀት እና ለመጠቀም እናዘጋጅታለን፡፡ ሞዴሌያችን የሚታወቀውን የBIST ቀለም-አካባቢ ተሟጋቾችን (ኪperwasser እና ጎልdberg, 2016) በመጠቀም የቢLSTM መሠረት ማሰናከል ክፈቻን በመጠቀም ለፓርተር የተጠቃሚ የPOS tags ለመፍጠር ይዘረጋል፡፡ የኢንጂልኛ ፕሬን ቴርebank በኩል፣ ሞዴላታችን በ94.51 በመቶ እና 92.87 በመቶ የበረታች UAS እና የLAS ደረጃዎች አግኝተዋል፡፡ 1.5+ የBIST graph-based ትክክለኛ ክፍተቶችን አግኝተዋል፡፡ ከዚህም በላይ፣ የ 61 ትልቅ 'የዩንቨርስቲ ድጋፍ ማጋራት መፈተሚያ ፍጻሜዎች ከጥሩ ጽሑፎች መዝገብ የሚቆጠሩ የድምፅ ምርጫዎች በ0.8 በመቶ የበለጠ የPOS ማተላለፊያ score እና 3.6 በመቶ የበለጠ የLAS ደረጃ score እንዲያሳየው ነው፡፡ በተጨማሪም እና በሞዴላታችን፣ የዳርቻ አካባቢ ጉዳይ የሀብት ሁኔታ እና የባሕርያዊ ጉዳይ እና የአየር አስተያየት ፕሮግራሙን እናገኛለን፡፡ Our code is available together with all pre-trained models at: < https://github.com/datquocnguyen/jPTDP >", 'az': "Biz sözlərin bir parçasının etiketi və bağlılıq ayırması üçün yeni nöral a ğ modeli təklif edirik. Bizim modellərimiz bilinmiş BIST graflı bağlılıq ayırıcısını (Kiperwasser və Goldberg, 2016) ayırıcının automatski tədbir edilmiş POS etiketlərini ürəkləmək üçün BiLSTM tabanlı etiketli komponenti ilə birləşdirir. İngilis Pen treebank'da, modelimiz qüvvətli UAS və LAS scoreları 94.51%-də və 92.87%-də verir, BIST grafındakı parsör üçün 1.5+% mütləq təmizlənir və həmçinin 97.97%-də sanat POS etiketlərinin dəqiqliyini alır. Daha sonra, 61 'böyük' Universal Dependencies treebankları çəkilmiş mətnlərdən ayırmaq üçün təcrübə sonuçları göstərir ki, modellərimizin əsas səhifəsi UDPipe (Straka və Strakova, 2017) ilə 0.8% yüksək orta POS etiketi nöqtəsini və 3.6% yüksək orta LAS nöqtəsini göstərir. Əvvəlcə, modellərimizlə birlikdə biomedical olaraq çıxarılması və fikir analizi uygulamaları üçün daha düşük-düşük işlər nöqtələri də alırıq. Kodumuz öyrənmiş modellərlə birlikdə mövcuddur: https://github.com/datquocnguyen/jPTDP >", 'hy': 'Մենք առաջարկում ենք նոր նյարդային ցանցի մոդել խոսքի ընդհանուր մասի (POS) նշանների և կախվածության վերլուծության համար: Our model extends the well-known BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating a BiLSTM-based tagging component to produce automatically predicted POS tags for the parser.  On the benchmark English Penn treebank, our model obtains strong UAS and LAS scores at 94.51% and 92.87%, respectively, producing 1.5+% absolute improvements to the BIST graph-based parser, and also obtaining a state-of-the-art POS tagging accuracy at 97.97%.  Ավելին, փորձարկվող արդյունքները 61 "մեծ" համաշխարհային կախվածությունների ծառերի հիմքերի վերլուծում ցույց են տալիս, որ մեր մոդելը գերազանցում է հիմնական UDPipe (Ստրակա և Ստրակովա 2017 թվականին) 0.8 տոկոսով ավելի բարձր միջին POS-ի նշանների և 3.6 տոկոսով ավելի բարձր միջին LAS-ի նշա Ավելին, մեր մոդելի օգնությամբ մենք նաև ստանում ենք վերջնական խնդիրների արդյունքներ կենսաբժշկական իրադարձությունների վերացման և կարծիքի վերլուծության ծրագրերի համար: Մեր կոդը հասանելի է միասին բոլոր նախապատրաստված մոդելների հետ՝ https://github.com/datquocnguyen/jPTDP _', 'bn': "আমরা একটি নভেল নিউরেল নেটওয়ার্ক মডেল প্রস্তাব করছি যৌথ ভাষণের অংশ (পোএস) ট্যাগিং এবং নির্ভরশীল পার্জিং এর জন্য। আমাদের মডেল স্বয়ংক্রিয়ভিত্তিক বিএসটি গ্রাফ-ভিত্তিক নির্ভরশীল প্যারেজার (কিপারওয়াসার এবং গোল্ডবার্গ, ২০১৬) একটি বিএলস্টিম ভিত্তিক ট্যাগিং অংশ বেনম্যার্কের ইংরেজি পেন ট্রিবাঙ্কে আমাদের মডেল ৯৪. ৫১% এবং ৯২. ৮৭%-এ শক্তিশালী ইউএসএ এবং ল্যাস স্কোর পায়, যা বিএসটির গ্রাফ ভিত্তিক পরিসংখ্যানের জন্য ১. এছাড়াও, পার্সিং ৬১ 'বড়' বিশ্ববিদ্যালয়ের নির্ভরশীল ট্রিব্যাংকের উপর পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের মডেল বেসেলাইন ইউডিপিপি (স্ট্রাকা এবং স্ট্রাকোভা, ২০১৭) এর মাধ্যমে ০. এছাড়াও, আমাদের মডেলের মাধ্যমে আমরা বায়োমেডিকেল ইভেন্ট বিনিময় এবং মতামত বিশ্লেষণ অ্যাপ্লিকেশনের জন্য প্রতিষ্ঠানের রাষ পূর্ব প্রশিক্ষিত মডেলের সাথে আমাদের কোড পাওয়া যাচ্ছে: < https://github.com/datquocnguyen/jPTDP >", 'af': "Ons voorstel 'n nuwe neuralnetwerk model vir joint part-of-speech (POS) merking en afhanklikheid verwerking. Ons model uitbrei die goed bekend BIST graaf-gebaseerde afhanklikheidspanser (Kiperwasser en Goldberg, 2016) deur 'n BiLSTM-gebaseerde etiket komponent te inkorporeer om outomaties voorskoude POS etikette vir die ontwerker te produseer. Op die benchmarke van Engels Penn treebank, ons model kry sterk UAS en LAS-punte by 94.51% en 92.87%, respectively, die absolute verbeteringe van 1.5+% aan die BIST graf-gebaseerde ontwerker, en ook 'n staat-van-die-kunsten POS-merking presies by 97.97%. Verder, eksperimentele resultate op verwerking van 61 'groot' Universele afhanklikheid treebanks van rooi teks vertoon dat ons model uitvoer die basisline UDPipe (Straka en Strakova, 2017) met 0.8% hoër gemiddelde POS merking aantal en 3.6% hoër gemiddelde LAS aantal. In addition, with our model, we also obtain state-of-the-art downstream task scores for biomedical event extraction and opinion analysis applications. Ons kode is beskikbaar saam met alle voorafgeleerde modele op: < https://github.com/datquocnguyen/jPTDP >", 'ca': 'Proposem un nou model de xarxa neural per etiquetar part-of-speech (POS) i analitzar la dependencia. El nostre model amplia el conegut analitzador de dependencies basat en gràfics BIST (Kiperwasser i Goldberg, 2016) incorporant un component d\'etiqueta basat en BiLSTM per produir etiquetes POS predites automàticament per l\'analitzador. On the benchmark English Penn treebank, our model obtains strong UAS and LAS scores at 94.51% and 92.87%, respectively, producing 1.5+% absolute improvements to the BIST graph-based parser, and also obtaining a state-of-the-art POS tagging accuracy at 97.97%.  A més, els resultats experimentals de l\'analització de 61 bancs d\'arbres "grans" de Dependencies Universals a partir de textos bruts mostren que el nostre model supera l\'UDPipe basal (Straka i Strakova, 2017) amb un 0,8% més puntuació mitjana de POS i un 3,6% més puntuació mitjana de LAS. A més, amb el nostre model, també obtenim puntuacions de tasca més avançades per a aplicacions d\'extracció d\'eventos biomèdics i d\'anàlisi d\'opinió. El nostre codi està disponible juntament amb tots els models pré-entrenats en: < https://github.com/datquocnguyen/jPTDP >', 'et': 'Pakume välja uue närvivõrgu mudeli ühise kõneosa (POS) märgistamiseks ja sõltuvuse parsimiseks. Meie mudel laiendab tuntud BIST graafikapõhist sõltuvuspartserit (Kiperwasser ja Goldberg, 2016), lisades BiLSTM-põhise sildistamiskomponendi parserile automaatselt prognoositavate POS-siltide tootmiseks. Inglise Penn treebank võrdlusalusel saavutab meie mudel tugevad UAS- ja LAS-skoorid vastavalt 94,51% ja 92,87%, andes BIST graafikapõhise parseri absoluutse paranduse 1,5+% ning saavutades ka kaasaegse POS-sildistamise täpsuse 97,97%. Lisaks näitavad eksperimentaalsed tulemused 61 "suure" universaalse sõltuvuse puupunkti parsimise kohta toortekstidest, et meie mudel ületab algtaseme UDPipe (Straka ja Strakova, 2017) 0,8% kõrgema keskmise POS sildistamisskooriga ja 3,6% kõrgema keskmise LAS-skooriga. Lisaks saame oma mudeliga kaasaegseid ülesandepunkte biomeditsiiniliste sündmuste ekstraheerimise ja arvamusanalüüsi rakenduste jaoks. Meie kood on saadaval koos kõigi eeltreenitud mudelitega aadressil: < https://github.com/datquocnguyen/jPTDP >', 'fi': 'Ehdotamme uutta neuroverkkomallia yhteisen puheen osan (POS) tagaukseen ja riippuvuuden jäsentämiseen. Mallimme laajentaa tunnettua BIST-graafiseen riippuvuuden parseria (Kiperwasser ja Goldberg, 2016) sisällyttämällä BiLSTM-pohjaisen tagauskomponentin tuottamaan automaattisesti ennustetut POS-tagit parserille. Englanninkielisessä Penn treebankissa mallimme saa vahvat UAS-pisteet 94,51% ja LAS-pisteet 92,87%, tuottaen 1,5+% absoluuttisia parannuksia BIST-graafiseen jäsentäjään ja saavuttaen huipputason POS-merkintätarkkuuden 97,97%. Kokeelliset tulokset 61:n "suuren" Universal Dependencies -puupenkin jäsentämisestä raakateksteistä osoittavat, että mallimme suoriutuu UDPipen (Straka ja Strakova, 2017) keskiarvolla 0,8% korkeammalla POS-tagging-pisteellä ja 3,6% korkeammalla LAS-pisteellä. Lisäksi mallimme avulla saamme huippuluokan loppupään tehtäväpisteet biolääketieteellisiin tapahtumiin ja mielipide-analyysisovelluksiin. Koodimme on saatavilla yhdessä kaikkien esikoulutettujen mallien kanssa osoitteessa: < https://github.com/datquocnguyen/jPTDP >', 'bs': "Predlažemo nov model neuralne mreže za zajedničku ulogu govora (POS) oznake i analizu ovisnosti. Naš model proširi poznat analizator ovisnosti na grafiku BIST (Kiperwasser i Goldberg, 2016) uključujući komponent označavanja na BiLSTM-u kako bi proizvela automatski predviđene oznake POS za analizatora. Na referenciji engleskog Penn treebanca, naš model dobija jake rezultate UAS-a i LAS-a na 94,51% i 92,87%, što proizvodi apsolutno poboljšanje na temelju analizatora na grafiku BIST-a, a također dobija tačnost označavanja stanja umjetnih POS-a na 97,97%. Nadalje, eksperimentalni rezultati na analizu 61 'velikih' univerzalnih zavisnosti od sirovih tekstova pokazuju da naš model iznosi početnu UDPipe (Straka i Strakova, 2017) sa 0,8% višim prosječnim rezultatima POS-a i 3,6% višim prosječnim rezultatima LAS-a. Osim toga, sa našim modelom, također dobijamo rezultate rezultata za sniženje biomedicinskih događaja za izvlačenje i analizu mišljenja. Naš kod je dostupan zajedno sa svim predobučenim modelima na: < https://github.com/datquocnguyen/jPTDP -Da.", 'cs': "Navrhujeme nový model neuronové sítě pro společné tagování části řeči (POS) a analýzu závislostí. Náš model rozšiřuje známý BIST graf-based dependence parser (Kiperwasser a Goldberg, 2016) o začlenění BiLSTM tagovací komponentu pro automaticky předpovídané POS tagy pro parser. Na benchmarku anglické Penn treebank získává náš model silné hodnocení UAS a LAS na 94,51% a 92,87%, což přináší 1,5+% absolutní zlepšení BIST grafového parseru a také získává nejmodernější POS tagovací přesnost při 97,97%. Dále experimentální výsledky analýzy 61 'velkých' univerzálních závislostí stromů ze surových textů ukazují, že náš model překonává základní UDPipe (Straka a Strakova, 2017) s 0,8% vyšším průměrným POS tagging skóre a 3,6% vyšším průměrným LAS skóre. Díky našemu modelu také získáváme nejmodernější skóre následných úkolů pro aplikace extrakce biomedicínských událostí a analýzy názorů. Náš kód je k dispozici společně se všemi předškolenými modely na adrese: < https://github.com/datquocnguyen/jPTDP >", 'jv': 'We proposal a new Neral network model for joint parts-of-language (po S) tagging and diphensible charging. Kita model teka nggawe barang kelas-kenar BIRT graf-bazi diphendise pater (Kiperwasser and golberg, 2011) nggawe isin conversion nggawe kompon sing bisa BiLTT-bazi tagging kompon to create automatically prelimine tags for the PAS tags Nang bench-bench kanggo ngilanggar nganggo urip Pen, model nambarang nggawe barang-urip SUS lan LAS sing luwih dumadhi, mengko cah-cah sabên, njaluk 1.5+% sing dipolerans nambah sing bisa basa dipolerans BIRT , lak ngelarang langgar-cah sabên-uwong sing bakal terus maring cara-cara nggawe wih kleh dumadhi, wih-asai sawetara wih-asai Laptop" and "Desktop Nambah, nganggep model nambah, kita mulai nggawe kelas state-of-the-arts downtream task punika kanggo ngelarane gambar nggawe barang nggambar events biyoteng lan aplikasi penting. Coverage https://github.com/datquocnguyen/jPTDP >', 'ha': "Munã buɗe wani misali na jerin neural na yanzu wa shirin rabo-faɗi (PoS) tagoging da kuma paring ɗin da ake ƙayyade. Our model extends the well-known BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating a BiLSTM-based tagging component to produce automatically predicted POS tags for the parser.  On an daidaita littafin Ingiriya na Penn Treebank, misalinmu yana sami nau'in UAN da MAS a shekara 94.51% da 92.87%, kuma yana ƙara 1.5+% mai baƙa ƙo ga fassaran BIS, kuma yana sami tsarin-state-of-the-art PS taging at 97.97%. Furan haka, jarrabi masu jarraba matsalar parse 61 'babban' Universal Debtaris Treebanks daga raw text show that modalinmu yana ƙaranci na rubutun UDevelopmentipe (Traaka and Traakva, 2017) da 0.8% da ke ƙaranci tsakanin taging score na PS kuma 3.6% da ke ƙaranci score na LS. Ina ƙaranci, da misalinmu, za'a sami tuna ma'anar-na-sanar-da-kwance wa masu buɗaɗa wa masu zartar da shiryoyin ayukan da aka yi wa aikin bayani da kuma misãlai ga sharĩ'a. Ana samar da kowanmu tare da duk misãlai masu tsari a gaba ɗaya a: https://github.com/datquocnguyen/jPTDP >", 'he': 'אנו מציעים מודל רשת עצבית חדש לתייג חלק משותף של הנאום (POS) ומחקר תלויות. המודל שלנו מגדיל את מעבד התלויות המבוסס על גרף BIST הידוע (Kiperwasser וגולדברג, 2016) על ידי הכילוי רכיב תג מבוסס על BiLSTM כדי לייצר תוויות POS צפויות באופן אוטומטי עבור המעבר. בנק העץ האנגלית של פנים, המודל שלנו מקבל נקודות חזקות UAS ו-LAS ב-94.51% ו-92.87%, בהתאם, יוצר שיפורים מוחלטים של 1.5+% למחקר המבוסס בגרף BIST, וגם מקבל מדויקת תווית POS מוקדמת ב-97.97%. חוץ מזה, תוצאות ניסויים על בדיקת 61 "גדולות" בינלאומיות עצים מסמכים גרועים מראים שהמודל שלנו עולה על UDPipe בסיסי (Straka and Strakova, 2017) עם 0.8% ציון מוצע גבוה יותר POS מצוות ו-3.6% ציון מוצע גבוה יותר LAS. בנוסף, עם המודל שלנו, אנחנו גם מקבלים תוצאות משימות חדשות למטה למטה עבור היציאה אירועים ביולורפואיים ואישומי ניתוח דעה. הקוד שלנו זמין יחד עם כל דוגמנים מאומנים מראש ב: < https://github.com/datquocnguyen/jPTDP >', 'sk': "Predlagamo nov model nevronskega omrežja za označevanje skupnega dela govora (POS) in razčlenitev odvisnosti. Naš model razširja znani razčlenjevalnik odvisnosti BIST (Kiperwasser in Goldberg, 2016) z vključitvijo komponente označevanja, ki temelji na BiLSTM, ki proizvaja samodejno predvidene oznake POS za razčlenjevalnik. Na referenčni angleški Penn treebank naš model doseže močne rezultate UAS in LAS pri 94,51% oziroma 92,87%, kar zagotavlja 1,5+% absolutne izboljšave razčlenjevalnika BIST, ki temelji na grafu, in tudi vrhunsko natančnost označevanja POS pri 97,97%. Poleg tega eksperimentalni rezultati razčlenitve 61 'velikih' drevesnih zbirk Univerzalne odvisnosti iz surovih besedil kažejo, da naš model presega osnovno UDPipe (Straka in Strakova, 2017) z 0,8% višjim povprečnim rezultatom označevanja POS in 3,6% višjim povprečnim LAS rezultatom. Poleg tega z našim modelom pridobimo tudi najsodobnejše rezultate opravil za pridobivanje biomedicinskih dogodkov in aplikacije za analizo mnenja. Naša koda je na voljo skupaj z vsemi predhodno usposobljenimi modeli na: < https://github.com/datquocnguyen/jPTDP >", 'bo': "ང་ཚོས་དྲ་བརྗོད་དང་མཐུན་འབྲེལ་བའི་རྣམ་པ་ཞིག་གི་གླེང་སྒྲོམ་གྱི་ཆ་ཤས་གཅིག་གམ། Our model extends the well-known BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating a BiLSTM-based tagging component to produce automatically predicted POS tags for the parser. On the benchmark English Penn treebank, our model obtains strong UAS and LAS scores at 94.51% and 92.87%, respectively, producing 1.5+% absolute improvements to the BIST graph-based parser, and also obtaining a state-of-the-art POS tagging accuracy at 97.97%. I also obtained a state-of-the-art POS tagging accuracy at 97.97%. Furthermore, experimental results on parsing 61 'big' Universal Dependencies treebanks from raw texts show that our model outperforms the baseline UDPipe (Straka and Strakova, 2017) with 0.8% higher average POS tagging score and 3.6% higher average LAS score. འོན་ཀྱང་། ང་ཚོའི་སྔོན་གྲངས་སྔོན་གྲངས་ཀྱི་དཔེ་དབྱིབས་དང་མཉམ་དུ་སྤྱོད་ཐུབ་པ་: < https://github.com/datquocnguyen/jPTDP >"}
{'en': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'ar': 'IBM Research في CoNLL 2018 المهمة المشتركة حول التحليل متعدد اللغات', 'pt': 'IBM Research na CoNLL 2018 Shared Task on Multilingual Parsing', 'es': 'IBM Research en la CoNll 2018 Shared Task sobre análisis multilingüe', 'fr': "IBM Research à la tâche partagée ConLL 2018 sur l'analyse syntaxique multilingue", 'zh': 'IBM 研究院在 CoNLL 2018 多言解析共其事', 'ja': '多言語構文解析に関するCoNLL 2018シェアード・タスクでのIBMの研究', 'hi': 'CONLL 2018 में आईबीएम रिसर्च ने बहुभाषी पार्सिंग पर साझा कार्य', 'ru': 'Исследования IBM в CoNLL 2018 Shared Task on Multilingual Parsing', 'ga': 'Taighde IBM ag Tasc Comhroinnte CoNLL 2018 ar Pharsáil Ilteangach', 'ka': 'IBM პასუხი CoNLL 2018-ში მრავალენგური პასუხის შესახებ', 'el': 'Έρευνα της IBM στο CoNLL 2018 Κοινή Εργασία για την Πολυγλωσσική Ανάλυση', 'hu': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'it': 'IBM Research al CoNLL 2018 Shared Task on Multilingual Parsing', 'lt': 'IBM moksliniai tyrimai CoNLL 2018 m. bendrame daugiakalbio analizavimo uždavinyje', 'mk': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'kk': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'ms': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'ml': 'കോണ്\u200dഎല്\u200d 2018 ലെ ഐബിഎം പരിശീലനം പല ഭാഷ പാര്\u200dസിങ്ങില്\u200d പങ്കെടുത്ത പണിയാണ്', 'mt': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'mn': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'no': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'ro': 'IBM Research în cadrul CoNLL 2018 sarcina comună privind interpretarea multilingvă', 'sr': 'IBM istraživanja na CoNLL 2018. delnom zadatku o multijezičkom razmatranju', 'pl': 'Badania IBM w CoNLL 2018 Wspólne zadanie dotyczące analizy wielojęzycznej', 'si': 'IBM Research at the CoNLL 2018 shared Job on Multilanguage Parsing', 'so': 'IBM Research at the CoNLL 2018 Shared Task on parsing badan', 'ur': 'CoNLL 2018 میں IBM تحقیقات کا مشترک ٹاکس Multilingual Parsing پر', 'sv': 'IBM Research vid CoNLL 2018 delad uppgift om flerspråkig tolkning', 'ta': 'கோன்எல் 2018 ல் ஐபிஎம் ஆராய்ச்சி பல மொழி பாசிங்கில் பகிர்ந்த பணி', 'uz': 'Comment', 'vi': 'Nghiên cứu của IBM ở CoNll 208 đã chia sẻ Nhiệm vụ phân tích đa ngôn ngữ', 'nl': 'IBM Research bij het CoNLL 2018 Gedeelde taak over meertalige parsing', 'hr': 'IBM istraživanja na CoNLL 2018. dijelom zadatku o multijezičkom razmatranju', 'de': 'IBM Research am CoNLL 2018 Shared Task on Multilingual Parsing', 'bg': 'Изследване на споделена задача за многоезично анализиране', 'da': 'IBM Research på CoNLL 2018 delt opgave om flersproget tolkning', 'id': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'ko': 'IBM의 2018년 CoNLL 콘퍼런스 다국어 해석 공유 연구', 'fa': 'تحقیقات IBM در کارهای مشترک در مورد تحلیل زیادی زبان در CoNLL 2018', 'sw': 'Utafiti wa IBM kwenye CoNLL 2018 ulishiriki kazi ya Uchaguzi wa lugha nyingi', 'tr': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'sq': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'hy': 'IBM-ի հետազոտությունները 2018 թվականի CONSL-ի բազմալեզու վերլուծության ընթացքում', 'af': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'am': 'በCoNLL 2018 የተሰራጨው ስራ በMultilingual Parsing ላይ', 'bn': 'কনএল ২০১৮ সালের আইবিএম গবেষণা মাল্টিভাষায় পার্জিং এর কাজ শেয়ার করা হয়েছে।', 'ca': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'az': 'IBM araştırması CoNLL 2018 çoxlu dil analizi barəsində paylaşın işi', 'et': 'IBM Research at CoNLL 2018 Shared Task on Multilingual Parsing', 'cs': 'IBM Research na CoNLL 2018 Sdílený úkol pro vícejazyčné analýzy', 'fi': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'bs': 'IBM istraživanja na CoNLL 2018. dijeljenom zadatku o multijezičkom razmatranju', 'jv': 'IBM Search at the CoNLL 2008 shared task on Multilanguage Parasing', 'sk': 'IBM raziskave na skupni nalogi CoNLL 2018 o večjezičnem razpravljanju', 'ha': 'KCharselect unicode block name', 'he': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing', 'bo': 'IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing'}
{'en': 'This paper presents the IBM Research AI submission to the CoNLL 2018 Shared Task on Parsing Universal Dependencies. Our system implements a new joint transition-based parser, based on the Stack-LSTM framework and the Arc-Standard algorithm, that handles ', 'ar': 'تقدم هذه الورقة تقديم IBM Research AI إلى المهمة المشتركة CoNLL 2018 حول تحليل التبعيات العالمية. ينفذ نظامنا محللًا جديدًا مشتركًا قائمًا على الانتقال ، استنادًا إلى إطار عمل Stack-LSTM وخوارزمية Arc-Standard ، التي تتعامل مع الترميز ، وعلامات جزء من الكلام ، والعلامات المورفولوجية ، وتحليل التبعية في نموذج واحد. من خلال الاستفادة من مجموعة من النمذجة المستندة إلى الشخصية للكلمات والتكوين المتكرر للهياكل اللغوية المبنية جزئيًا ، قمنا بتأهيل المركز الثالث عشر بشكل عام والسابع في الموارد المنخفضة. نقدم أيضًا بنية عصبية جديدة لتجزئة الجملة بناءً على Stack-LSTMs والتي كانت رابع أفضل بشكل عام.', 'fr': "Cet article présente la soumission d'IBM Research AI à la tâche partagée ConLL 2018 sur l'analyse des dépendances universelles. Notre système implémente un nouvel analyseur conjoint basé sur la transition, basé sur le framework Stack-LSTM et l'algorithme Arc-Standard, qui gère la tokenisation, le balisage partiel, le marquage morphologique et l'analyse des dépendances dans un seul modèle. En tirant parti d'une combinaison de modélisation des mots basée sur les caractères et de composition récursive de structures linguistiques partiellement construites, nous nous sommes classés 13e au classement général et 7ème en ressources faibles. Nous présentons également une nouvelle architecture neuronale de segmentation de phrases basée sur Stack-LSTMS, qui est la 4e meilleure au classement général.", 'es': 'Este artículo presenta la presentación de IBM Research AI a la tarea compartida de CoNll 2018 sobre análisis de dependencias universales. Nuestro sistema implementa un nuevo analizador conjunto basado en transiciones, basado en el marco Stack-LSTM y el algoritmo Arc-Standard, que maneja la tokenización, el etiquetado de parte del discurso, el etiquetado morfológico y el análisis de dependencias en un solo modelo. Al aprovechar una combinación de modelado de palabras basado en caracteres y composición recursiva de estructuras lingüísticas parcialmente construidas, calificamos 13° en general y 7° en recursos bajos. También presentamos una nueva arquitectura neuronal de segmentación de oraciones basada en Stack-LSTMS que fue la cuarta mejor en general.', 'pt': 'Este artigo apresenta o envio do IBM Research AI para a tarefa compartilhada CoNLL 2018 na análise de dependências universais. Nosso sistema implementa um novo analisador baseado em transição conjunta, baseado na estrutura Stack-LSTM e no algoritmo Arc-Standard, que lida com tokenização, marcação de parte da fala, marcação morfológica e análise de dependência em um único modelo. Ao alavancar uma combinação de modelagem de palavras baseada em caracteres e composição recursiva de estruturas linguísticas parcialmente construídas, classificamos 13º geral e 7º em baixo recurso. Apresentamos também uma nova arquitetura neural de segmentação de sentenças baseada em Stack-LSTMs que foi a 4ª melhor no geral.', 'ja': 'この論文は、普遍的依存関係の解析に関するCoNLL 2018共有タスクへのIBM Research AI提出を紹介しています。当社のシステムは、Stack - LSTMフレームワークとArc - Standardアルゴリズムに基づいた新しいジョイント遷移ベースの構文解析器を実装しており、1つのモデルでトークン化、音声の一部タグ付け、形態学的タグ付け、依存性解析を処理します。単語の文字ベースのモデリングと部分的に構築された言語構造の再帰的構成の組み合わせを活用することにより、全体で13位、低リソースで7位に認定した。また、全体で4番目に優れたStack - LSTMに基づいた新しい文章セグメンテーションニューラルアーキテクチャも提示しています。', 'zh': '本文言 IBM 研究院 AI CoNLL 2018 解析通用共事者。 吾统成一新之解析器,当解析器于 Stack-LSTM 框架、 Arc-Standard 算法,可于单形之中处标记、词性标记、形表、依赖解析。 因字符之单词建模,结言语之递归,总排名第13位,资源量排名第7位。 又立Stack-LSTM新型句分神经架构,当架构第四。', 'hi': 'यह पेपर IBM Research AI सबमिशन को CoNLL 2018 Shared Task on Parsing Universal Dependencies पर प्रस्तुत करता है। हमारी प्रणाली स्टैक-एलएसटीएम फ्रेमवर्क और आर्क-स्टैंडर्ड एल्गोरिथ्म के आधार पर एक नया संयुक्त संक्रमण-आधारित पार्सर लागू करती है, जो एक ही मॉडल में टोकनाइजेशन, पार्ट-ऑफ-स्पीच टैगिंग, रूपात्मक टैगिंग और निर्भरता पार्सिंग को संभालती है। शब्दों के चरित्र-आधारित मॉडलिंग और आंशिक रूप से निर्मित भाषाई संरचनाओं की पुनरावर्ती संरचना के संयोजन का लाभ उठाकर हमने कम संसाधन में कुल मिलाकर 13 वें और 7 वें स्थान पर अर्हता प्राप्त की। हम स्टैक-एलएसटीएम के आधार पर एक नया वाक्य विभाजन तंत्रिका वास्तुकला भी प्रस्तुत करते हैं जो कुल मिलाकर 4 वां सबसे अच्छा था।', 'ru': 'В этой статье представлена подача ИИ IBM Research к общей задаче CoNLL 2018 по анализу универсальных зависимостей. Наша система реализует новый совместный парсер на основе перехода, основанный на фреймворке Stack-LSTM и алгоритме Arc-Standard, который обрабатывает токенизацию, частичную тегирование речи, морфологическую тегирование и синтаксический анализ зависимостей в одной модели. Используя комбинацию символьного моделирования слов и рекурсивного состава частично построенных лингвистических структур, мы квалифицировали 13-е место в общем и 7-е по низкому ресурсу. Мы также представляем новую нейронную архитектуру сегментации предложений, основанную на стековых LSTM, которая в целом заняла 4-е место.', 'ga': 'Cuireann an páipéar seo aighneacht IBM Research AI i láthair do Thasc Roinnte CoNLL 2018 maidir le Spleáchais Uilíocha a Pharsáil. Cuireann ár gcóras parsálaí nua tras-bhunaithe comhpháirteach i bhfeidhm, bunaithe ar chreat Stack-LSTM agus ar an algartam Arc-Standard, a láimhseálann tokenization, clibeáil pháirteach cainte, clibeáil moirfeolaíoch agus parsáil spleáchais in aon mhúnla amháin. Trí mheascán de shamhaltú carachtar-bhunaithe focal a ghiaráil agus comhdhéanamh athfhillteach ar struchtúir teanga a tógadh go páirteach cháilíomar sa 13ú háit ar an iomlán agus sa 7ú háit maidir le hacmhainn íseal. Cuirimid i láthair chomh maith ailtireacht néarach deighilte abairtí bunaithe ar Stack-LSTManna a bhí ar an 4ú háit is fearr san iomlán.', 'hu': 'Ez a tanulmány bemutatja az IBM Research AI benyújtását a CoNLL 2018 Shared Task on Parsing univerzális függőségek értelmezésére. Rendszerünk a Stack-LSTM keretrendszeren és az Arc-Standard algoritmuson alapuló új közös átmeneti alapú elemzőt hajt végre, amely egyetlen modellben kezeli a tokenizációt, a beszédrész címkézést, a morfológiai címkézést és a függőség elemzését. A karakter alapú szavak modellezésének és a részben épített nyelvi struktúrák rekurzív kompozíciójának kombinációjával összesen 13. és 7. minősítést végeztünk alacsony erőforrásban. Bemutatunk egy új mondatszegmentációs neurális architektúrát Stack-LSTMs alapján, amely összességében a negyedik legjobb volt.', 'ka': 'ამ დოკუმენტი IBM სწავლობა AI-ის გასამუშაობას CoNLL 2018 სხვადასხვა რაოდენობაში სამუშაო დავამუშაობას. ჩვენი სისტემა ახალი გადაწყვეტილი გადაწყვეტილი გადაწყვეტილი გადაწყვეტილი პანელეზერი, Stack-LSTM ფრამეტზე და Arc-Standard ალგორიტიმზე, რომელიც ერთი მოდელში ტოკენიზაცია, სიტყვების ნაწილის ნაწილის შესახებ. სიტყვების და რეკურსიური კომპოზიციის კომბიზიციის კომბიზიციას, რომელიც ნაწილად შექმნა ლენგურისტიკური სტრუქტურების კომბიზიციაში, ჩვენ კომბიზი ჩვენ ასევე ახალი სიმბოლოების სექმენტაციის ნეირალური აქტიქტიკურაციას, რომელიც სექმენტი LSTMs იყო 4-ი უკეთესი ყველაზე.', 'el': 'Η παρούσα εργασία παρουσιάζει την υποβολή της στην κοινή εργασία για την ανάλυση καθολικών εξαρτήσεων. Το σύστημά μας υλοποιεί ένα νέο κοινό αναλυτή βασισμένο στη μετάβαση, βασισμένο στο πλαίσιο και τον αλγόριθμο που διαχειρίζεται την επισήμανση, την επισήμανση μέρους ομιλίας, τη μορφολογική επισήμανση και την ανάλυση εξαρτήσεων σε ένα μόνο μοντέλο. Με τη χρήση ενός συνδυασμού μοντελοποίησης λέξεων βάσει χαρακτήρων και αναδρομικής σύνθεσης μερικώς δομημένων γλωσσικών δομών, κατατάξαμε την 13η συνολικά και την 7η σε χαμηλούς πόρους. Παρουσιάζουμε επίσης μια νέα νευρική αρχιτεκτονική κατακερματισμού προτάσεων βασισμένη σε Stack-LSTMs που ήταν η 4η καλύτερη συνολικά.', 'it': "Questo articolo presenta la presentazione di IBM Research AI al CoNLL 2018 Shared Task on Parsing Universal Dependences. Il nostro sistema implementa un nuovo parser basato sulla transizione congiunta, basato sul framework Stack-LSTM e sull'algoritmo Arc-Standard, che gestisce tokenizzazione, tag part-of-speech, tag morfologico e analisi delle dipendenze in un unico modello. Sfruttando una combinazione di modellazione basata sui caratteri delle parole e composizione ricorsiva di strutture linguistiche parzialmente costruite, ci siamo qualificati 13 ° in generale e 7 ° in bassa risorsa. Presentiamo anche una nuova architettura neurale di segmentazione delle frasi basata su Stack-LSTMs che è stata la quarta migliore nel complesso.", 'mk': 'Овој документ го претставува поднесувањето на ИБМ Research AI на Соделената задача на CoNLL 2018 за анализирање на универзалните зависности. Нашиот систем имплементира нов заеднички анализатор базиран на транзиција, базиран на Stack-LSTM рамката и арк-стандардниот алгоритм, кој се справува со токенизација, дел од говорот означување, морфолошки означување и анализација на зависност во еден модел. Со искористување на комбинација на карактерско моделирање на зборови и рекурсивна композиција на делумно изградени јазични структури, ние ја квалификувавме 13-тата целокупно и 7-тата во ниски ресурси. Ние, исто така, претставуваме нова реченица сегментација на нервната архитектура базирана на Stack-LSTMs, која беше четвртата најдобра вкупно.', 'lt': 'Šiame dokumente pateikiama IBM mokslinių tyrimų AI paraiška CoNLL 2018 m. bendram universaliųjų priklausomybių vertinimo uždaviniui. Mūsų sistema įdiegia naują bendrą pereinamojo laikotarpio analizatorių, pagrįstą Stack-LSTM sistema ir Arc-Standard algoritmu, kuris tvarko tokenizaciją, kalbos dalies žymėjimą, morfologinį žymėjimą ir priklausomybės analizavimą vienu modeliu. Naudojami žodžių modeliavimo pagal charakteristikas ir iš dalies sukurtų kalbinių struktūrų rekurencinės sudėties derinį, iš viso kvalifikavome 13-ąjį ir 7-ąjį mažai išteklių. Mes taip pat pristatome naują sakinių segmentacijos neurologinę architektūrą, pagrįstą Stack-LSTM, kuri buvo ketvirtoji geriausia bendrai.', 'kk': 'Бұл қағаз IBM зерттеу AI-нің CoNLL 2018 ортақ тапсырмасын универсалдық тәуелдіктерді талдау үшін ортақ тапсырманы көрсетеді. Біздің жүйеміз Stack-LSTM фрейміне негізделген жаңа бөлек ауыстыру негізделген талдаушы және Arc-Стандартты алгоритмді орындайды. Бұл токенизациялау, сөздің бөлігін тегжелеу, морфологиялық тегжелеу мен тәуелдік тал Таңбалар негізінде сөздер мен қайталанатын лингвистикалық құрылымдарының біріктірілген модельдерді қолдану арқылы, біз 13- ші жалпы және 7- ші ресурста төмен көмектесдік. Біз сондай-ақ 4- ші ең жақсы жұмыс болған Stack- LSTMs негізінде жаңа сөз сегментациясы невралдық архитектурасын таңдадық.', 'ml': 'ഈ പത്രത്തില്\u200d പാര്\u200dസിങ്ങ് യൂണിവര്\u200dണല്\u200d ആശ്രയിക്കുന്നതിനെപ്പറ്റിയുള്ള പാര്\u200dസിങ്ങ് യൂണിവര്\u200dണല്\u200d ആന്\u200dഡന്\u200dസികളില്\u200d ഇബിഎ Our system implements a new joint transition-based parser, based on the Stack-LSTM framework and the Arc-Standard algorithm, that handles tokenization, part-of-speech tagging, morphological tagging and dependency parsing in one single model.  വാക്കുകളുടെ അടിസ്ഥാനത്തിലുള്ള ഒരു കൂട്ടിക്കൂട്ടം വാക്കുകളുടെയും പിന്നീട് രീതിയിലുള്ള ഘടകം സ്റ്റാക്ക്-എൽസ്റ്റിഎസ്റ്റിസ്സിനെ അടിസ്ഥാനമായി അടിസ്ഥാനമായി ഒരു പുതിയ വാക്കിന്റെ വേര്\u200dപ്പിന്റെ പുതിയ പ്ര', 'ms': 'Kertas ini memperkenalkan IBM Research AI submission kepada CoNLL 2018 Shared Task on Parsing Universal Dependencies. Sistem kami melaksanakan penghurai berasaskan transisi kongsi baru, berdasarkan kerangka Stack-LSTM dan algoritma Arc-Standard, yang mengendalikan tokenisasi, tag sebahagian-ucapan, tag morfologi dan hurai dependensi dalam satu model. Dengan menggunakan kombinasi pemodelan perkataan berdasarkan aksara dan komposisi rekursif struktur bahasa sebahagian yang dibina kami memenuhi syarat keseluruhan ke-13 dan ke-7 dalam sumber rendah. Kami juga memperkenalkan arkitektur saraf segmen kalimat baru berdasarkan Stack-LSTMs yang merupakan keseluruhan keempat yang terbaik.', 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni tal-IBM Research AI lill-CoNLL 2018 Shared Task on Parsing Universal Dependencies. Is-sistema tagħna timplimenta analizzatur konġunt ġdid ibbażat fuq it-tranżizzjoni, ibbażat fuq il-qafas Stack-LSTM u l-algoritmu Arc-Standard, li jimmaniġġja t-tokenizzazzjoni, it-tikkettar ta’ parti mid-diskors, it-tikkettar morfoloġiku u l-analizzazzjoni tad-dipendenza f’mudell wieħed. Bl-ingranaġġ ta’ kombinazzjoni ta’ mudell ibbażat fuq il-karattru tal-kliem u kompożizzjoni rikorrenti ta’ strutturi lingwistiċi parzjalment mibnija, ikkwalifikajna t-13-il ġeneralment u s-7 f’riżorsi baxxi. We also present a new sentence segmentation neural architecture based on Stack-LSTMs that was the 4th best overall.', 'no': 'Denne papiret viser IBM-forskningsAI-tillegget til CoNLL 2018-delt oppgåve om tolking av universelle avhengighet. Sistemet vårt implementerer ein ny kopla overgangsbasert tolkar, basert på Stack-LSTM-rammeverket og Arc-Standard-algoritmen, som handterar tokenisering, del-av-talemerking, morfologisk merking og avhengighetstolking i eitt enkelt modell. Ved å leverara eit kombinasjon av teiknbasert modellering av ord og rekursivt samansering av delvis bygde lingviske strukturar, vi kvalifiserte 13. overalt og 7. i låg ressurs. Vi presenterer også eit nytt setningsssegmentasjon av neuralarkitektur basert på Stack-LSTMs som var den 4. beste overalt.', 'pl': 'W artykule przedstawiono zgłoszenie IBM Research AI do CoNLL 2018 Shared Task on Parsing Universal Dependences. Nasz system wdraża nowy wspólny parser oparty na przejściach oparty na frameworku Stack-LSTM i algorytmie Arc-Standard, który obsługuje tokenizację, tagowanie części mowy, tagowanie morfologiczne i parsowanie zależności w jednym modelu. Wykorzystując kombinację modelowania słów opartego na znakach i rekursywnego składu częściowo zbudowanych struktur językowych, zakwalifikowaliśmy ogólnie 13-tą i 7-tą w niskich zasobach. Przedstawiamy również nową architekturę neuronową segmentacji zdań opartą na Stack-LSTMs, która była czwartą najlepszą w ogóle.', 'mn': 'Энэ цаас IBM судалгааны AI-г CoNLL 2018 оны Дэлхийн хамаарал хамааралтай талаар хуваалцах ажил дээр илтгэдэг. Бидний систем Stack-LSTM хэлбэрээр, Arc-Стандарт алгоритмын үндсэн шинэ шилжүүлэлт дээр суурилсан хуваарч хийдэг. Энэ нь тодорхойлолт, ярианы нэг хэсэг, морфологик тегжинг, хамааралтай хуваарч нэг загварын нэг хэлбэрээр ажилладаг. Бид 13-р нийтлэг, 7-р нийтлэг бүтээгдэхүүнд 13-р нийтлэг болон 7-р нийтлэг бүтээгдэхүүнийг ашиглаж байна. Мөн бид 4-р хамгийн сайн зүйл байсан Stack-LSTMs дээр багтаж байгаа шинэ өгүүлбэрийн сэтгэл зүйн архитектурыг тайлбарлаж байна.', 'ro': 'Această lucrare prezintă prezentarea IBM Research AI la CoNLL 2018 Shared Task on Parsing Universal Dependents. Sistemul nostru implementează un nou parser bazat pe tranziție comună, bazat pe cadrul Stack-LSTM și algoritmul Arc-Standard, care gestionează tokenizarea, etichetarea parțială de vorbire, etichetarea morfologică și analizarea dependențelor într-un singur model. Prin utilizarea unei combinații de modelare bazată pe caractere a cuvintelor și compoziție recursivă a structurilor lingvistice parțial construite, am calificat al 13-lea general și al 7-lea în resurse reduse. De asemenea, prezentăm o nouă arhitectură neurală de segmentare a frazelor bazată pe Stack-LSTMs care a fost a patra cea mai bună în general.', 'sr': 'Ovaj papir predstavlja podnošenje IBM istraživanja AI podnošenje zajedničkom zadatku CoNLL 2018 o razmatranju univerzalnih zavisnosti. Naš sistem implementira novi zajednički prelazni analizator, zasnovan na okviru Stack-LSTM i Arc-Standard algoritma, koji se bavi tokenizacijom, dijelom govornog etiketiranja, morfološkom etiketiranjem i analizacijom zavisnosti u jednom modelu. Uspoređujući kombinaciju modeliranog na karakteru reči i rekursivnog kompozicija djelomično izgrađenih jezičkih struktura, kvalifikovali smo 13. ukupno i 7. u niskom resursu. Predstavljamo i novu segmentaciju rečenice neuralnu arhitekturu na osnovu Stack-LSTMs-a koja je bila četvrti najbolji ukupno.', 'sv': 'Denna uppsats presenterar IBM Research AI-inlämningen till CoNLL 2018 Shared Task on Parsing Universal Dependences. Vårt system implementerar en ny gemensam övergångsbaserad parser, baserad på Stack-LSTM-ramverket och Arc-Standard-algoritmen, som hanterar tokenisering, delmärkning, morfologisk taggning och beroendetolkning i en enda modell. Genom att utnyttja en kombination av karaktärsbaserad modellering av ord och rekursiv sammansättning av delvis byggda språkliga strukturer kvalificerade vi oss 13:e totalt och 7:e i låg resurs. Vi presenterar också en ny meningssegmentering neural arkitektur baserad på Stack-LSTMs som var den fjärde bästa totalt.', 'si': 'මේ පත්තරේ IBM පරීක්ෂණා AI පිළිගන්න පුළුවන් වෙනවා CoNLL 2018 සමාගත වැඩසටහන් විශේෂ විශේෂ විශේෂ විශේ අපේ පද්ධතිය අළුත් සංවිධානයක් ස්ටැක් LSTM පද්ධතිය සහ ආර්ක් ස්ටැන්ඩ් ඇල්ගෝරිතම් පද්ධතියෙන් අළුත් සංවිධානයක් පරීක්ෂා කරනවා, කොටස් බො වචනය සහ ප්\u200dරතික්\u200dරියාත්මක සංවිධානය සඳහා භාෂාත්මක සංවිධානයක් සම්බන්ධ කරලා තියෙන්නේ අපි 13වෙනි සාමාන්\u200dය සහ 7 අපි අළුත් වාක්ය විශේෂයක් ස්ටැක්-LSTMs වලින් අධාරිත විශේෂයක් පෙන්වන්නේ. ඒක තමයි 4වෙනි හොඳම සාමා', 'so': 'Kanu warqaddan waxaa lagu soo dhiibaa IBM baaritaanka AI oo loo soo dhiibay CoNLL 2018 Shaqada loo sharciyey ku saabsan baaritaanka jaamacadda. Systemkanagu wuxuu sameeyaa baaritaan cusub oo ku saleysan Stack-LSTM iyo Arc-Standard algoritm, kaas oo qabanqaabinaya calaamad, qayb ka mid ah hadal tagging, morphological tagging iyo ku xiran baaritaanka isku model. Sida lagu soo diro muuqasho xaraf ah oo ku qoran hadal iyo dib u dhigid dhismaha qayb ahaan loo dhisay dhismaha luuqadaha, waxaan ku lifaaqnay koox 13aad oo dhan iyo 7aad oo ku qoran resource hoose. Sidoo kale waxaynu soo bandhignaynaa dhismo neuro ah oo lagu saleynayo Stack-LSTMs oo ahaa qofka 4aad oo ugu wada fiican.', 'ur': 'This paper presents the IBM Research AI submission to the CoNLL 2018 Shared Task on Parsing Universal Dependencies. ہماری سیسٹم نے ایک نئی جوڑی تغییر پر بنیاد رکھی ہے، Stack-LSTM فرمود اور Arc-Standard الگوریتم پر بنیاد رکھی ہے، جو ٹوکنیزی کرتا ہے، بات ٹاگنگ کا حصہ، مورپولوژیک ٹاگنگ اور اعتمادی پارسینگ کا ایک مدل میں ہے. ہم نے کلمات اور دوبارہ ساختہ زبان کی ساختاریوں کی ترکیب کے ذریعہ ایک شخصت بنیاد کی موڈلینگ کی ترکیب کے ذریعہ سے 13 کلمات اور 7 کلمات کے ذریعہ کم منصفات میں قابل تعمیر کی۔ ہم نے بھی ایک نئی جماعت سیگنٹ نیورل معماری بنائی ہے جو Stack-LSTMs پر بنیاد ہے جو چوتھا سب سے بہتر تھا.', 'ta': 'இந்த தாள் IBM ஆராய்ச்சி AI கூட்டுகிறது CoNLL 2018 பகிர்ந்த பணியை பாசிங் உலக சார்புகள் பற்றி பகிர்ந்த பணி எங்கள் அமைப்பு அடிப்படையில் அடிப்படையிலான ஒரு புதிய இணைப்பு மாற்றும் பளஞ்சியை செயல்படுத்துகிறது, அடிப்படையில் அடிப்படையில் மற்றும் ஆர- நிலையான ஆல்பரிட்டம், அது கு குறைந்த மூலத்தில் 13வது மொத்தம் மற்றும் 7வது குறைந்த மூலத்தில் கொண்டு எழுத்து அடிப்படையான மாதிரி உருவாக்குதல் மற்றும் திரும்ப அமைப்ப நாம் ஒரு புதிய வாக்கியத்தை பிரித்தல் புதிய நெருக்கமான கட்டுப்பாட்டு அடிப்படையில் கொண்டு வருகிறோம் Stack-LSTMs என்ற', 'uz': 'Bu qogʻoz IBM ta\'qish AI\'ni CoNLL 2018\'ga bogʻliq vazifani universal qoʻllanmalar bilan bogʻliq vazifani koʻrsatadi. Bizning tizimimiz, Stack-LSTM freymi va Arc-Standard algoritga asosida yangi aloqa tarjima qiladi. Bu bir modelda soʻzning qismlarini boshqaradi, morfologik tagg\'ining qismlarini boshqaradi va bir modelda parsing ishlatadi. By leveraging a combination of character-based modeling of words and recursive composition of partially built linguistic structures we qualified 13th overall and 7th in low resource.  Biz yana birinchi so\'zni ajratish uchun "Stack-LSTMs" asosida yaratilgan yangi narsalarning neyrolik arxituvchisi.', 'vi': 'Tờ giấy này trình bày đơn của IBM Research Al để đệ trình cho CLB CodLL 208 "Chia sẻ" về phân tích vật sở hữu chung. Hệ thống của chúng tôi thực hiện một bộ phân tích liên kết kết dựa trên bộ chế độ Stacks-LSTM và thuật toán Arc-Standard, xử lý việc hiệu ứng, định vị phần ngôn ngữ, kích thích và độ phụ thuộc phân tích theo một kiểu. Bằng cách sử dụng sự kết hợp từ điển của các từ ngữ và cấu trúc ngôn ngữ được xây dựng lại từ một phần được cấu tạo ra chúng tôi xếp hạng 13th trong phương pháp thấp. Chúng tôi cũng giới thiệu một kiến trúc dây thần kinh phân loại mới dựa trên Stacks-LSTM, là thứ tư tốt nhất.', 'bg': 'Настоящата статия представя представянето на ИИ за научни изследвания към Споделената задача за анализиране на универсалните зависимости на CoNLL 2018. Нашата система внедрява нов анализатор, базиран на преход, базиран на рамката и алгоритъма който обработва токенизация, маркиране на част от речта, морфологично маркиране и анализ на зависимости в един единствен модел. Използвайки комбинация от символно-базирано моделиране на думи и рекурсивна композиция на частично изградени лингвистични структури, ние квалифицирахме 13-то общо и 7-то по нисък ресурс. Представяме и нова нервна архитектура за сегментиране на изречения, базирана на стак-ЛСТМ, която е 4-та най-добра като цяло.', 'da': 'Denne artikel præsenterer IBM Research AI-indsendelsen til CoNLL 2018 Shared Task on Parsing Universal Dependences. Vores system implementerer en ny fælles overgangsbaseret parser, baseret på Stack-LSTM framework og Arc-Standard algoritmen, der håndterer tokenisering, del-of-tale tagging, morfologisk tagging og afhængighedsparsing i én enkelt model. Ved at udnytte en kombination af karakterbaseret modellering af ord og rekursiv sammensætning af delvist byggede sproglige strukturer kvalificerede vi os 13. samlet og 7. i lav ressource. Vi præsenterer også en ny sætningssegmentering neural arkitektur baseret på Stack-LSTMs, der var den 4. bedste samlet.', 'nl': 'Dit artikel presenteert de IBM Research AI inzending aan de CoNLL 2018 Shared Task on Parsing Universal Dependencies. Ons systeem implementeert een nieuwe gezamenlijke transitie-gebaseerde parser, gebaseerd op het Stack-LSTM framework en het Arc-Standard algoritme, die tokenization, part-of-speech tagging, morfologische tagging en afhankelijkheidsparsing in één model verwerkt. Door gebruik te maken van een combinatie van karaktergebaseerde modellering van woorden en recursieve samenstelling van gedeeltelijk gebouwde linguïstische structuren kwalificeerden we 13e over het algemeen en 7e in low resource. We presenteren ook een nieuwe zinnensegmentatie neurale architectuur gebaseerd op Stack-LSTMs die de 4e beste in het algemeen was.', 'de': 'Dieses Papier stellt die IBM Research AI Einreichung an die CoNLL 2018 Shared Task on Parsing Universal Dependencies vor. Unser System implementiert einen neuen Joint Transition-basierten Parser, der auf dem Stack-LSTM Framework und dem Arc-Standard Algorithmus basiert und Tokenisierung, Sprachteiltagging, morphologische Tagging und Abhängigkeitsparsing in einem einzigen Modell verarbeitet. Durch die Nutzung einer Kombination aus charakterbasierter Modellierung von Wörtern und rekursiver Komposition von teilweise aufgebauten linguistischen Strukturen qualifizierten wir insgesamt 13th und 7th in low resource. Wir präsentieren auch eine neue Satzsegmentierungs-neuronale Architektur basierend auf Stack-LSTMs, die insgesamt viertbeste war.', 'ko': '본고는 IBM Research AI가 CoNLL 2018에 제출하여 유니버설 의존항 공유 임무를 분석한 상황을 소개한다.우리 시스템은 Stack LSTM 프레임워크와 Arc 표준 알고리즘을 바탕으로 새로운 연합 변환을 바탕으로 하는 해상도를 실현했다. 이 해상도는 하나의 모델에서 표기화, 어성 표기, 형태 표기와 의존성 분석을 처리한다.문자 기반의 단어 모델링과 부분적으로 구축된 언어 구조의 귀속 조합을 이용하여 우리는 저자원 분야에서 13위와 7위의 자격을 얻었다.스택 LSTMs를 기반으로 한 새로운 문장 분할 신경 네트워크 구조도 제시했는데 이 구조는 전체 4위에 올랐다.', 'id': 'Kertas ini mempersembahkan IBM Research AI pengiriman ke CoNLL 2018 Shared Task on Parsing Universal Dependencies. Sistem kami mengimplementasikan parser baru berdasarkan transisi, berdasarkan struktur Stack-LSTM dan algoritma Arc-Standard, yang menangani tokenisasi, bagian-dari-pidato tagging, tag morfologi dan penghuraian dependensi dalam satu model. Dengan menggunakan kombinasi dari model karakter berdasarkan kata dan komposisi rekursif dari struktur bahasa yang dibangun sebagian kami memenuhi syarat keseluruhan ke-13 dan ke-7 dalam sumber daya rendah. Kami juga mempersembahkan segmen kalimat baru arsitektur saraf berdasarkan Stack-LSTMs yang merupakan keseluruhan keempat yang terbaik.', 'hr': 'Ovaj papir predstavlja podnošenje IBM istraživačkog AI-a u CoNLL 2018 zajedničkom zadatku o razmatranju univerzalnih zavisnosti. Naš sustav provodi novi zajednički razmatrač na temelju prijenosa na temelju okvira Stack-LSTM i Arc-Standard algoritma, koji se bavi tokenizacijom, dijelom govornog etiketiranja, morfološkom etiketiranja i analizacijom ovisnosti u jednom modelu. Uzimajući kombinaciju modeliranog na karakteru riječi i rekursivnog sastojaka djelomično izgrađenih jezičkih struktura, kvalificirali smo 13. ukupno i 7. u niskom resursu. Također predstavljamo novu segmentaciju rečenica neuralnu arhitekturu na temelju Stack-LSTMs-a koja je bila četvrti najbolji ukupno.', 'fa': 'این کاغذ تحقیقات AI IBM را به کار مشترک CoNLL 2018 در مورد تحلیل بستگی جهانی نشان می دهد. سیستم ما یک بازیگر جدید بر اساس چهارچوب Stack-LSTM و الگوریتم استاندارد آرک را اجرای می\u200cکند که با توکینز، قسمتی از نقاشی سخنرانی، نقاشی مورفولوژیک و بازیگری بستگی در یک مدل است. با توجه به ترکیب یک ترکیب از مدل\u200cسازی بر اساس شخصیت کلمات و ترکیب دوباره از ساختمان\u200cهای زبان\u200cشناسی که بخشی ساخته شده\u200cایم، در کل ۱۳ و ۷م منابع پایین را درآوردیم. ما همچنین یک معماری عصبی جدید از جمله جدید را بر اساس استک-LSTMs نشان می دهیم که چهارمین بهترین عمومی بود.', 'sw': 'Gazeti hili linaonyesha utafiti wa IBM utafiti wa AI uliotolewa kwa CoNLL 2018 Kushirikisha kazi ya Kuchapisha Kutegemea Uimbaji ulimwengu kote. Mfumo wetu unatekeleza mchambuzi mpya wa mpito wa pamoja, kwa msingi wa mfumo wa Stack-LSTM na utaratibu wa KiArc-Standard, unaohusisha ushambulizi, sehemu ya wimbo wa hotuba, wimbo wa kifolojia na kutegemea kuimba kwa mtindo mmoja. Kwa kutumia muunganiko wa muungano wa maneno na ujenzi wa sekunde wa miundombinu ya lugha tuliyojipatia ujumla wa 13 na 7 katika rasilimali chini. Pia tunaonyesha muundo mpya wa ujenzi wa kisasa wa kifungu cha hukumu kwa msingi wa Stack-LSTMs ambao ulikuwa ni mkuu wa nne.', 'tr': 'Bu kagyz IBM Araştyrma AI CoNLL 2018-nji Halkara Baýramlyklary Parlamak üçin beýleki Görevi üýtgedýär. Bizim sistemimiz Stack-LSTM çerçevesinde we Arc-Standardlı algoritminin tabanly bir birleşik geçişi tabanly bir täze çözümlerini implement edir. Bu tokenizasyonu, sözlerin bir bölümini tägleme, morfolojik tägleme we baglançylyk çözümlemesini bir tek modelde çözýär. Karakter tabanly sözler we rekursiv dil strukturalarynyň birleşigini we biz iň az resurslarda 13-nji we 7-nji derejesini ukyp etdik. Biz hem Täze sözlem segmentasiýasynda Stack-LSTMs üçin 4-nji iň gowy tarapyndan daşary bir neural arhitektegi görkeýäris.', 'af': "Hierdie papier stel die IBM Research AI-onderskrywing aan die CoNLL 2018 deelde taak op verwerking van Universele afhanklikhede. Ons stelsel implementeer 'n nuwe joint transition-based ontwerker, gebaseer op die Stack-LSTM raamwerk en die Arc-Standaard algoritme, wat handteer tokenisasie, deel-van-spreek etiketing, morfologiese etiketing en afhanklikheid verwerking in een enkele model. Deur 'n kombinasie van karaktergebaseerde modellering van woorde en rekursief opstelling van gedeeltelik gebou lingwisiese strukture, het ons 13-de heeltemal en 7-de in lae hulpbron gekvalifiseer. Ons het ook 'n nuwe setningsegmentasie neurale arkitektuur voorgestel wat op Stack-LSTMs gebaseer is wat die 4de beste totaal was.", 'am': 'ይህ ገጽ የIBM ምርመራ AI ለኮንLL 2018 በፓርቲ የዓለማዊ ግንኙነት ላይ የተሰራጨውን ስራ ያቀርባል፡፡ የስርዓታችን አዲስ የፍሬት-LSTM ፍሬም እና የአርካቲ-Standard algorithም በተመሳሳይ፣ የንግግር ማተሚያ ክፍል፣ ሞርፎሎጂ ማተላለፊያ እና በአንድ ሞዴል ማኅበረሰብ በመጠቀም የሚችል አዲስ የፍትወት ተተሳታፊ ማተር ያስተካክላል፡፡ በአካባቢው የቋንቋዊ ቋንቋዎች መሠረት እና በተመሳሳይ የቃላት ምሳሌ እና የክፍለ ሥርዓት አካባቢ በመስጠት በ13ኛ በሙሉ እና 7ኛ ታናሽ ክፍል አዋቂ ነው፡፡ አዲስ የቁጥጥር አካባቢ የናቡር አካባቢ መሠረት እናቀርባታለን፤ ይህም የአራተኛው ክፍል ጥሩ ነው፡፡', 'hy': "Այս հոդվածը ներկայացնում է IBM Research AI-ի ներկայացումը 2018 թվականի ԿՈՆԼ-ի Համաշխարհային Հանկախությունների վերլուծության ընդհանուր խնդիրը: Մեր համակարգը իրականացնում է մի նոր միավոր վերաբերյալ հիմնված վերաբերյալ, որը հիմնված է Stack-LSMT-ի շրջանակի և Արք-Ստանդարտ ալգորիթմի վրա, որը վերահսկում է թոկենիզացիան, խոսքի մասը, մորֆոլոգիական թղթերը և կախվածության վերաբերյալ մեկ մոդելի մեջ: Օգտագործելով բառերի բնորոշ մոդելավորման և մասամբ կառուցված լեզվաբանական կառուցվածքների համակցությունը' մենք համարվում էինք 13-րդին և 7-րդին ցածր ռեսուրսներով: Մենք նաև ներկայացնում ենք նոր նախադասությունների սեգմետրացիայի նյարդային ճարտարապետություն, որը հիմնված է Stack-LStms-ի վրա, որը 4-րդ լավագույն համաշխարհում էր:", 'sq': 'Ky dokument paraqet paraqitjen e IBM Research AI në CoNLL 2018 Task Shared on Parsing Universal Dependencies. Sistemi ynë zbaton një analizues të ri të përbashkët bazuar në tranzicion, bazuar në kuadrin Stack-LSTM dhe algoritmin Arc-Standard, që trajton tokenizimin, shënimin pjesë-të-fjalimit, shënimin morfologjik dhe analizimin e varësisë në një model të vetëm. Duke përdorur një kombinim të modelimit të fjalëve bazuar në karakter dhe përbërjes rekursive të strukturave gjuhësore të ndërtuara pjesërisht, kualifikuam të 13-tën në përgjithësi dhe të 7-tën në burime të ulëta. Ne prezantojmë gjithashtu një arkitekturë të re të segmentimit të fjalëve neuronale bazuar në Stack-LSTMs që ishte e katërta më e mirë në përgjithësi.', 'az': "Bu kağıt IBM araştırma AI'nin CoNLL 2018 Üniversal bağlılıqları Parsing üçün paylaşılmış işi ilə birləşdirir. Sistemimiz Stack-LSTM çerçivesi və Arc-Standardlı algoritmi ilə birləşdirilmiş bir keçişçilik tərzini təşkil edən yeni bir keçişçilik tərzini təşkil edir. Sözlər və dil qurulduqların parçacıq in şa edilmiş quruluşların birləşdirilməsinə görə 13. ünvanı və 7. ünvanı düşük çoxluğa qaytardıq. Biz də dördüncü ən yaxşısı Stack-LSTMs-lərə dayanan yeni cümləlik segmentasyonu nöral arhitektürünü göstəririk.", 'ca': "Aquest paper presenta la presentació d'IBM Research AI a la CoNLL 2018 Shared Task on Parsing Universal Dependencies. El nostre sistema implementa un nou analitzador conjunt basat en la transició, basat en el marc Stack-LSTM i l'algoritme Arc-Standard, que gestiona la tecenització, l'etiquetage de part-of-speech, l'etiquetage morfològic i l'analització de dependencies en un únic model. Utilitzant una combinació de modelació de paraules basada en caràcters i composició recursiva d'estructures lingüístices parcialment construïdes, vam qualificar el 13è en general i el 7è en baix recursos. També presentem una nova arquitectura neuronal de segmentació de frases basada en Stack-LSTMs que va ser la quarta millor en general.", 'bs': 'Ovaj papir predstavlja podnošenje IBM istraživačkog AI-a u CoNLL 2018 zajedničkom zadatku o razmatranju univerzalnih zavisnosti. Naš sistem provodi novi zajednički analizator na temelju prijenosa, zasnovan na okviru Stack-LSTM i Arc-Standard algoritma, koji se bavi tokenizacijom, dijelom govornog etiketiranja, morfološkom etiketiranjem i analizacijom ovisnosti u jednom modelu. Uzimajući kombinaciju modeliranog na karakteru riječi i rekursivnog sastanka djelomično izgrađenih jezičkih struktura, kvalifikovali smo 13. ukupno i 7. u niskom resursu. Također predstavljamo novu segmentaciju rečenice neuralnu arhitekturu na osnovu Stack-LSTMs-a koja je bila četvrti najbolji ukupno.', 'cs': 'Tento článek představuje předložení IBM Research AI do sdíleného úkolu CoNLL 2018 o analýze univerzálních závislostí. Náš systém implementuje nový společný parser založený na přechodu založený na frameworku Stack-LSTM a algoritmu Arc-Standard, který zpracovává tokenizaci, tagování části řeči, morfologické tagování a analýzu závislostí v jednom modelu. Využitím kombinace znakového modelování slov a rekurzivního složení částečně postavených jazykových struktur jsme kvalifikovali celkově třináctý a sedmý v nízkých zdrojích. Představujeme také novou neuronovou architekturu segmentace vět založenou na Stack-LSTMs, která byla celkově čtvrtá nejlepší.', 'bn': 'এই পত্রিকাটি পার্জিং বিশ্ববিদ্যালয়ের নির্ভরিত কাজের জন্য আইবিএম গবেষণা AI প্রদান করেছে। আমাদের সিস্টেম স্ট্যাক-এলসিএমএর ফ্রেম এবং আর্ক-স্ট্যান্ডার্ড অ্যালগরিদমের ভিত্তিতে একটি নতুন যোগাযোগ-ভিত্তিক প্রতিযোগিতা ব্যবস্থা করে, যা একটি মডেলে পার্জ বিভিন্ন ভিত্তিক ক্যারেক্টারের মডেল এবং পুনঃসংগঠনের মাধ্যমে অংশ নির্মিত ভাষাগত কাঠামোর মাধ্যমে আমরা নিম্ন সম্পদে ১৩ তম সাধারণ এবং ৭ তম আমরা স্ট্যাক-এলস্টিএমএস এর ভিত্তিতে একটি নতুন শাস্তি বিভক্তি নিউরাল কাঠামোর সাথে উপস্থাপন করেছি যা ছিল ৪তম সেরা সার্ব', 'et': 'Käesolevas artiklis tutvustatakse IBM Research AI esitlust CoNLL 2018. aasta jagatud ülesandele universaalsete sõltuvuste parsimise kohta. Meie süsteem rakendab Stack-LSTM raamistikul ja Arc-Standard algoritmil põhinevat ühisüleminekul põhinevat parserit, mis käsitleb tokeniseerimist, kõneosa sildistamist, morfoloogilist sildistamist ja sõltuvuse parsimist ühes mudelis. Kasutades sõnade märgipõhist modelleerimist ja osaliselt ehitatud keelestruktuuride rekursiivset kompositsiooni, kvalifitseerisime 13. üldiselt ja 7. madala ressursiga. Samuti tutvustame uut lausesegmentatsiooni neuroarhitektuuri, mis põhineb Stack-LSTMdel, mis oli üldiselt 4. parim.', 'fi': 'Tässä artikkelissa esitellään IBM:n tutkimuksen tekoälyn julkaisu CoNLL 2018 Shared Task on Parsing Universal Dependences -ohjelmaan. Järjestelmämme toteuttaa uuden, Stack-LSTM-viitekehykseen ja Arc-Standard-algoritmiin perustuvan yhteissiirtymäpohjaisen jäsentäjän, joka käsittelee tokenisaatiota, puheen osaa merkitsemistä, morfologista merkitsemistä ja riippuvuuden jäsentämistä yhdessä mallissa. Hyödyntämällä merkkipohjaista sanamallinnusta ja osittain rakennettujen kielellisten rakenteiden rekursiivista koostumusta kvalifioimme 13. ja 7. heikossa resurssissa. Esittelemme myös Stack-LSTMs:iin perustuvan lausesegmentoinnin neuroarkkitehtuurin, joka oli neljänneksi paras.', 'ha': 'Wannan karatun na bãyar da IBM Research AI ɗin da aka bai wa the CoNLL 2018 Shared job on Paring Universal depend. Tsarinmu na zartar da wani tsari na daban a haɗi da shi, a kan asalin firam na Stack-LSSM da algoritm na Tsarin-Tsarin, wanda ke yi aiki da alama, rabon tagogi ga magana, tagogi na mutfologi da kuma yana dõgara ga parse cikin shekara guda. Ina iya samar da wani komi mai bincike wa misalin na rubutu da kurekursive composition of partly-gina linguistic tsarori, mun ƙayyade 13 na jumla da 7 cikin wuri mai ƙasƙanci. Kayya, Munã halatar da wani matsayin neura na salon da aka haɗa shi na rubutun maganar.', 'he': 'העיתון הזה מציג את ההצגה של IBM Research AI למשימה משותפת CoNLL 2018 על בדיקת תלויות Universal. המערכת שלנו מפעילה חוקר משותף חדש מבוסס על המסגרת של Stack-LSTM והאלגוריתם Arc-Standard, שמטפל בטקניזציה, תגים חלק מהנאום, תגים מורפולוגיים ומחקר תלויות במודל אחד. על ידי השימוש בשילוב של מודל מבוסס על אופים של מילים ומרכיב חוזר של מבנים שפתיים בנויים חלקית, הכישרנו את ה-13 באופן כללי ו-7 במשאבים נמוכים. אנחנו גם מציגים ארכיטקטורה עצבית חדשה במחלקת משפטים המבוססת על סטאק-LSTMs שהיתה הרביעית הכי טובה באופן כללי.', 'sk': 'V tem članku je predstavljena predložitev IBM Research AI za skupno nalogo CoNLL 2018 o razvrščanju univerzalnih odvisnosti. Naš sistem uvaja nov razčlenjevalnik, ki temelji na okviru Stack-LSTM in algoritmu Arc-Standard, ki obravnava žetonizacijo, označevanje dela govora, morfološko označevanje in razčlenjevanje odvisnosti v enem samem modelu. Z uporabo kombinacije karakterskega modeliranja besed in rekurzivne kompozicije delno zgrajenih jezikovnih struktur smo se uvrstili na 13. skupno in 7. v nizkih virih. Predstavljamo tudi novo živčno arhitekturo segmentacije stavkov, ki temelji na Stack-LSTMs, ki je bila četrta najboljša v celoti.', 'jv': 'Gambar iki bakal ngewehi nggawe IBM istrangis AI kanggo kowe CoNLL 2013 Gejaratan task nang Parasing Universal dependancies. Sistem dhéwé ngewehku nggawe sistem sing bagian nggawe politenessoffpolite"), and when there is a change ("assertive Awak dhéwé éntuk karo akeh sing katêpakan uwis seneng dadi, Arketektur Neral sing basa saben Stack-KST M kuwi wis nganggo katêh saben apik dhéwé.', 'bo': 'ཤོག་བྱང་འདིས་IBM་འཚོལ་ཞིབ་སྐྱོང་ཆེད་པ AI་ལ་CoNLL 2018་ཡི་ནང་དུ་ཆ་རྐྱེན་སྤྲོད་ཀྱི་བྱ་རིམ་དང་། Our system implements a new joint transition-based parser, based on the Stack-LSTM framework and the Arc-Standard algorithm, that handles tokenization, part-of-speech tagging, morphological tagging and dependency parsing in one single model. ང་ཚོས་རང་ཉིད་ཀྱི་སྐད་རིགས་ཀྱི་ཁྱད་ཆོས་དང་བསྐྱར་རིམ་ཅིག་གི་མཉམ་འབྲེལ་གྱི་ཁྱད་ཆོས་ལ་བསྡད་པའི་སྒྲིག་ཆ་སྒྲིག ང་ཚོས་Stack-LSTMs འི་ནང་དུ་ཚིག་གི་སྒྲ་ཚིགས་ཀྱི་དཔུད་རིམ་གནས་སྟངས་གསརཔ་ཞིག་ལ་སྟོན་པ་དེ་བཞི་ཆ་ཤོས་ཡོད།'}
{'en': '82 Treebanks, 34 Models : Universal Dependency Parsing with Multi-Treebank Models', 'ar': '82 Treebanks ، 34 نموذجًا: تحليل التبعية العالمية باستخدام نماذج Multi-Treebank', 'pt': '82 Treebanks, 34 Modelos: Análise de Dependência Universal com Modelos Multi-Treebank', 'es': '82 bancos de árboles, 34 modelos: análisis de dependencias universal con modelos de bancos de árboles múltiples', 'fr': "82 banques d'arbres, 34 modèles\xa0: analyse de dépendance universelle avec des modèles multi-banques d'arbres", 'ja': '82ツリーバンク、34モデル：マルチツリーバンクモデルによるユニバーサル依存性解析', 'ru': '82 Treebanks, 34 Модели: Универсальный парсинг зависимостей с моделями Multi-Treebank', 'zh': '82 树库,34 用多树库解析', 'hi': '82 Treebanks, 34 मॉडल: यूनिवर्सल निर्भरता बहु Treebank मॉडल के साथ पार्सिंग', 'ga': '82 Bruach Crann, 34 Múnla: Spleáchas Uilíoch Parsáil le Múnlaí Il-Bhainc Crann', 'ka': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'el': '82 Δέντρα, 34 Μοντέλα: Οικουμενική ανάλυση εξάρτησης με μοντέλα πολλαπλών δέντρων', 'hu': '82 Fák, 34 Modell: univerzális függőség értelmezés több fák modellekkel', 'it': '82 Alberi, 34 Modelli: Analisi Universale della Dipendenza con Modelli Multi-Alberi', 'lt': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'mk': '82 дрвени банки, 34 модели: универзално анализирање на зависноста со модели од повеќе дрвени банки', 'kk': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'ms': '82 Banek Pohon, 34 Model: Penghuraian Dependensi Universal dengan Model Banek Berberbilang', 'ml': '82 ട്രീബാങ്കുകള്\u200d, 34 മോഡലുകള്\u200d: പൊതുവിലെ ആശ്രമമായ പാര്\u200dസിങ്ങ് പല- ട്രീബാങ്ക് മോഡലുകളോടൊപ്പം', 'mt': '82 Banek tas-siġar, 34 Mudell: Analiżi tad-Dipendenza Universali b’Mudelli ta’ Banek Multi-Siġar', 'mn': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'no': '82 Treebanks, 34 Modeller: Universal Dependency Parsing with Multi-Treebank Models', 'pl': '82 Drzewa banki, 34 Modele: Uniwersalne parowanie zależności z modelami wielu drzew', 'ro': '82 Bănci de copac, 34 Modele: Analizare universală a dependenței cu modele Multi-Bănci de copac', 'sr': '82 Treebanks, 34 Modeli: Universal Dependency Parsing with Multi-Treebank Models', 'si': '82 TreeBank, 34 Models: Universal Dependency Parsing with Multi-TreeBank Models', 'sv': '82 Trädbankar, 34 Modeller: Universell beroendetolkning med Multi-Treebank Modeller', 'so': '82 Treebanks, 34 Models: Universal Dependence Parsing with Multi-Treebank Models', 'ta': '82 Treebanks, 34 மாதிரிகள்: பொதுவான சார்ந்த சார்ந்த பாடல் பல- Treebank மாதிரிகளுடன்', 'ur': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'uz': 'Name', 'vi': '82 Treebanks, 34 Models: Universal Depdependnce Parsing with Mul-Trees Models', 'bg': '82 Дървесни ленти, 34 Модела: Универсално анализиране на зависимостта с многодървесни ленти', 'hr': '82 Treebanks, 34 Modeli: Univerzalna zavisnost za analizu s multi-Treebank modelima', 'nl': '82 Treebanks, 34 Modellen: Universele Afhankelijkheidsparsing met Multi-Treebank Modellen', 'da': '82 Træbanker, 34 modeller: Universal Afhængighed Parsing med Multi-Treebank modeller', 'fa': '82 درخت بانک، 34 مدل: تولید بستگی جهانی با مدل\u200cهای چند درخت بانک', 'de': '82 Treebanks, 34 Modelle: Universal Dependency Parsing mit Multi-Treebank Modellen', 'ko': '82개의 트리 라이브러리, 34개의 모델: 다중 트리 라이브러리 모델의 일반적인 의존 해석', 'sw': '82 Treebanks, Model 34: Uhuru wa Kimataifa na Modeli nyingi za Treebank', 'tr': '82 Agaç Banky, 34 Modeller: Universal Dependency Parsing with Multi-Treebank Models', 'af': '82 Boomsbanke, 34 Modelle: Universele afhanklikheid verwerking met Multi-Treebank Modelle', 'hy': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'id': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'am': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi Treebank Models', 'sq': '82 banka pemësh, 34 modele: analiza e varësisë universale me modele shumëpemësh', 'az': '82 Ağaç Bankları, 34 Modellər: Universal Dependency Parsing with Multi-Treebank Models', 'bn': '৮২ ট্রিব্যাংক, ৩৪ মডেল: বিশ্ববিদ্যালয়ের নির্ভরিত পার্সিং মোডেল দিয়ে', 'et': '82 Puupunkti, 34 mudelit: universaalne sõltuvuse parsimine mitme puuga mudelitega', 'bs': '82 Treebanks, 34 Modeli: Universal Dependency Parsing with Multi-Treebank Models', 'fi': '82 puupalkkia, 34 mallia: Universal Dependency Parsing with Multi-Treebank Models', 'cs': '82 Treebanks, 34 Modely: Univerzální analýza závislosti s modely Multi-Treebank', 'ca': '82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models', 'ha': '82 Treebanks, 34 Models: Universal Deputy Parse with Moduls of Treebank', 'jv': 'Mulai', 'he': '82 בנקים עץ, 34 דוגמנים: בדיקת תלויות אוניברסלית עם דוגמנים של בנקים רבים', 'sk': '82 drevesnih plošč, 34 modelov: univerzalno razvrščanje odvisnosti z modeli več drevesnih plošč', 'bo': 'སྡོང་བོའི་དབྱིབས་གཞུང་ཚང་ལ་རྒྱ་ནག་མི་དབྱིབས་༤༣：སྤྱི་ཚོགས་ཁང་གི་དབྱིབས་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'We present the Uppsala system for the CoNLL 2018 Shared Task on universal dependency parsing. Our system is a pipeline consisting of three components : the first performs joint word and sentence segmentation ; the second predicts ', 'ar': 'نقدم نظام أوبسالا للمهمة المشتركة CoNLL 2018 بشأن تحليل التبعية العالمية. نظامنا عبارة عن خط أنابيب يتكون من ثلاثة مكونات: الأول يؤدي تجزئة الكلمات والجمل المشتركة ؛ يتنبأ الثاني بعلامات جزء من الكلام والسمات المورفولوجية ؛ والثالث يتنبأ بالأشجار التبعية من الكلمات والعلامات. بدلاً من تدريب نموذج تحليل فردي لكل ضفة شجرة ، قمنا بتدريب نماذج مع العديد من البنوك الشجرية للغة واحدة أو للغات وثيقة الصلة ، مما قلل بشكل كبير من عدد النماذج. في التشغيل التجريبي الرسمي ، حصلنا على المركز السابع من بين 27 فريقًا لمقاييس LAS و MLAS. حصل نظامنا على أفضل الدرجات بشكل عام لتجزئة الكلمات ، وعلامات نقاط البيع العامة ، والميزات المورفولوجية.', 'es': 'Presentamos el sistema de Uppsala para la tarea compartida de CoNll 2018 sobre el análisis universal de dependencias. Nuestro sistema es una canalización que consta de tres componentes: el primero realiza una segmentación conjunta de palabras y oraciones; el segundo predice las etiquetas de parte del discurso y las características morfológicas; el tercero predice los árboles de dependencias a partir de palabras y etiquetas. En lugar de entrenar un solo modelo de análisis para cada banco de árboles, entrenamos modelos con varios bancos de árboles para un idioma o idiomas estrechamente relacionados, lo que redujo considerablemente el número de modelos. En la prueba oficial, clasificamos el séptimo lugar de 27 equipos según las métricas de LAS y MLAS. Nuestro sistema obtuvo las mejores puntuaciones en general en segmentación de palabras, etiquetado de PDV universal y características morfológicas.', 'fr': "Nous présentons le système Uppsala pour la tâche partagée ConLL 2018 sur l'analyse de dépendance universelle. Notre système est un pipeline composé de trois composants\xa0: le premier effectue une segmentation conjointe des mots et des phrases\xa0; le second prévoit les balises de parties du discours et les caractéristiques morphologiques\xa0; le troisième prédit les arbres de dépendance à partir de mots et de balises. Au lieu de former un modèle d'analyse unique pour chaque banque d'arbres, nous avons formé des modèles avec plusieurs banques d'arbres pour une langue ou des langues étroitement apparentées, réduisant ainsi considérablement le nombre de modèles. Lors du test officiel, nous nous sommes classés 7ème sur 27 équipes pour les métriques LAS et MLAS. Notre système a obtenu les meilleurs scores dans l'ensemble pour la segmentation des mots, le marquage POS universel et les caractéristiques morphologiques.", 'pt': 'Apresentamos o sistema Uppsala para a tarefa compartilhada CoNLL 2018 na análise de dependência universal. Nosso sistema é um pipeline composto por três componentes: o primeiro realiza a segmentação conjunta de palavras e frases; a segunda prevê marcas de fala e características morfológicas; o terceiro prevê árvores de dependência de palavras e tags. Em vez de treinar um único modelo de análise para cada treebank, treinamos modelos com vários treebanks para uma linguagem ou linguagens intimamente relacionadas, reduzindo bastante o número de modelos. No teste oficial, ficamos em 7º lugar entre 27 equipes nas métricas LAS e MLAS. Nosso sistema obteve as melhores pontuações gerais para segmentação de palavras, marcação POS universal e características morfológicas.', 'ja': '普遍的な依存関係解析に関するCoNLL 2018共有タスクのためのUppsalaシステムを提示します。我々のシステムは、３つのコンポーネントからなるパイプラインである。第１のコンポーネントは、合同の単語と文のセグメンテーションを実行する。第２のコンポーネントは、音声の一部のタグと形態学的特徴を予測する。第３のコンポーネントは、単語とタグから依存木を予測する。ツリーバンクごとに単一の解析モデルをトレーニングするのではなく、1つの言語または密接に関連する言語のために複数のツリーバンクを持つモデルをトレーニングし、モデルの数を大幅に削減しました。公式テストでは、LASおよびMLAメトリックの27チーム中7位にランクインしました。当社のシステムは、単語セグメンテーション、ユニバーサルPOSタグ付け、および形態学的特徴について全体的に最高のスコアを取得しました。', 'hi': 'हम यूनिवर्सल निर्भरता पार्सिंग पर CoNLL 2018 साझा कार्य के लिए उप्साला प्रणाली प्रस्तुत करते हैं। हमारी प्रणाली एक पाइपलाइन है जिसमें तीन घटक शामिल हैं: पहला संयुक्त शब्द और वाक्य विभाजन करता है; दूसरा भाग-के-भाषण टैग और रूपात्मक विशेषताओं की भविष्यवाणी करता है; तीसरा शब्दों और टैग से निर्भरता पेड़ों की भविष्यवाणी करता है। प्रत्येक ट्रीबैंक के लिए एक एकल पार्सिंग मॉडल को प्रशिक्षित करने के बजाय, हमने एक भाषा या निकटता से संबंधित भाषाओं के लिए कई ट्रीबैंक के साथ मॉडल को प्रशिक्षित किया, जिससे मॉडल की संख्या बहुत कम हो गई। आधिकारिक परीक्षण रन पर, हमने एलएएस और एमएलएएस मीट्रिक के लिए 27 टीमों में से 7 वें स्थान पर रखा। हमारे सिस्टम ने शब्द विभाजन, सार्वभौमिक पीओएस टैगिंग और रूपात्मक सुविधाओं के लिए समग्र रूप से सर्वश्रेष्ठ स्कोर प्राप्त किया।', 'zh': '言 CoNLL 2018 共事者乌普萨拉统,事涉通解析。 一统三组件管道:一组件合单词句分; 次二占词性标形特征; 第三从单词及标签占依树。 吾不为树库解析,为一言而多树库,以大大减少其数。 官方试中, LAS MLAS 指标 27 团队中排名第 7 位。 余之系统于分词、通用 POS 标形之总体为最佳。', 'ru': 'Мы представляем систему Uppsala для совместной задачи CoNLL 2018 по универсальному парсингу зависимостей. Наша система представляет собой конвейер, состоящий из трех компонентов: первый выполняет совместную сегментацию слов и предложений; второй предсказывает теги части речи и морфологические особенности; третий предсказывает деревья зависимостей от слов и тегов. Вместо того, чтобы обучать одну модель синтаксического анализа для каждого берега деревьев, мы обучали модели с несколькими берегами деревьев для одного языка или тесно связанных языков, значительно сокращая количество моделей. На официальном тестовом запуске мы заняли 7-е место из 27 команд по показателям LAS и MLAS. Наша система получила лучшие оценки по сегментации слов, универсальной POS-метке и морфологическим признакам.', 'ga': 'Cuirimid i láthair an chórais Uppsala do Thasc Comhroinnte CoNLL 2018 ar pharsáil spleáchais uilíoch. Is píblíne é ár gcóras comhdhéanta de thrí chomhpháirt: déanann an chéad cheann deighilt focal agus abairtí i gcomhpháirt; déanann an dara ceann clibeanna cuid cainte agus gnéithe moirfeolaíocha a thuar; déanann an tríú tuar crainn spleáchais ó fhocail agus ó chlibeanna. In ionad múnla parsála aonair a oiliúint do gach crann, chuireamar oiliúint ar mhúnlaí le bainc iolracha d’aon teanga amháin nó do theangacha a bhfuil dlúthbhaint acu leo, rud a laghdaigh go mór líon na múnlaí. Ar an rith tástála oifigiúil, rinneamar an 7ú háit as 27 foireann do mhéadracht LAS agus MLAS. Fuair ár gcóras na scóir is fearr san iomlán maidir le deighilt focal, clibeáil uilíoch POS, agus gnéithe moirfeolaíocha.', 'ka': 'ჩვენ შევაჩვენეთ სისტემა Uppsala-ს CoNLL 2018-ის საზოგადოებული დავალებისთვის უნივერსალური დამხმარებულობის პარასტის შესახებ. ჩვენი სისტემა არის სამი კომპონენტებისგან შექმნილი პირველი სიტყვა და სიტყვა სექმენტირება. მეორე წარმოდგენა სიტყვების ნაწილი და მორფოლოგიური ფუნქციები; მესამე წარმოდგინდება სიტყვებით და ჭდებით განსაკუთრებულება. ყოველ საბეჭდოს ერთი პარაზიციის მოდელს შემდეგ, ჩვენ მრავალ საბეჭდოების მოდელები ერთი ენაზე ან მხოლოდ დაკავშირებული ენაზე, მნიშვნელოვანი მოდელების რაოდენობას შემცირებით ჲტთუთალური ტესტის გავაკეთებაში, ჩვენ 27 ჯგუფი დავწერეთ LAS და MLAS მეტრიკისთვის. ჩვენი სისტემა მიიღეთ ყველაზე საუკეთესო წერტილები სიტყვების სექმენტაციისთვის, საუკეთესო POS-მაგრამებისთვის და მოპოროლოგიური ფ', 'hu': 'Bemutatjuk a CoNLL 2018 Shared Task Uppsala rendszerét az univerzális függőség elemzésére. Rendszerünk három komponensből álló csővezeték: az első közös szó- és mondatszegmentációt végez; a második előrejelzi a beszédrész-címkéket és morfológiai jellemzőket; A harmadik megjósolja a függőség fáit szavakból és címkékből. Ahelyett, hogy egyetlen elemzési modellt képzettünk volna minden egyes fapadra, több fapadra képzett modelleket képzettünk egy nyelvre vagy szorosan rokon nyelvre, jelentősen csökkentve a modellek számát. A hivatalos tesztfutáson a 27 csapat közül a 7. helyen álltunk a LAS és MLAS mutatók szerint. Rendszerünk a szószegmentáció, az univerzális POS címkézés és a morfológiai jellemzők tekintetében a legjobb pontszámot kapta.', 'it': "Presentiamo il sistema Uppsala per il CoNLL 2018 Shared Task sull'analisi universale delle dipendenze. Il nostro sistema è una pipeline composta da tre componenti: il primo esegue la segmentazione congiunta di parole e frasi; la seconda prevede tag di parte-of-speech e caratteristiche morfologiche; Il terzo prevede alberi di dipendenza da parole e tag. Invece di formare un singolo modello di analisi per ogni albero, abbiamo addestrato modelli con più alberi per una lingua o lingue strettamente correlate, riducendo notevolmente il numero di modelli. Nella prova ufficiale, ci siamo classificati 7 ° su 27 squadre per le metriche LAS e MLAS. Il nostro sistema ha ottenuto i migliori punteggi complessivi per segmentazione delle parole, tag POS universale e caratteristiche morfologiche.", 'kk': 'Біз CoNLL 2018 жылы ортақ тапсырманы универсалдық тәуелдік талдау үшін Uppsala жүйесін таңдаймыз. Біздің жүйеміз үш компоненттің біріншіден біріктірілген сөз мен сөз сегментациясын орындайды. екіншісі сөйлеу тегтерінің бөлігін және морфологиялық мүмкіндіктерін алдын алады; үшінші сөздер мен тегтерден тәуелсіздік ағаштарды көрсетеді. Әрбір құрылғының бір талдау үлгісін оқыту орнына бір тіл не жақын тілдер үшін бірнеше құрылғының үлгілерін оқыту үшін бірнеше құрылғының үлгілерін өзгертіп, үлгілер санын көп аза Оригиялық сынақтар орындалғанда, LAS және MLAS метрикасының 7-ші тобында орындалдық. Біздің жүйеміз сөздерді сегментациялау, универсалды POS тегтері және морфологиялық мүмкіндіктері үшін ең жақсы нәтижелерді алды.', 'el': 'Παρουσιάζουμε το σύστημα Uppsala για την κοινή εργασία σχετικά με την ανάλυση καθολικής εξάρτησης. Το σύστημά μας είναι ένας αγωγός που αποτελείται από τρία συστατικά: το πρώτο εκτελεί κοινή κατανομή λέξεων και προτάσεων. το δεύτερο προβλέπει ετικέτες τμήματος ομιλίας και μορφολογικά χαρακτηριστικά· το τρίτο προβλέπει δέντρα εξάρτησης από λέξεις και ετικέτες. Αντί να εκπαιδεύσουμε ένα μόνο μοντέλο ανάλυσης για κάθε τράπεζα δέντρων, εκπαιδεύσαμε μοντέλα με πολλαπλές τράπεζες δέντρων για μια γλώσσα ή στενά συνδεδεμένες γλώσσες, μειώνοντας σημαντικά τον αριθμό των μοντέλων. Στην επίσημη δοκιμαστική διαδρομή, κατατάξαμε 7η από τις 27 ομάδες για τις μετρήσεις LAS και MLAS. Το σύστημά μας απέκτησε τις καλύτερες βαθμολογίες συνολικά για την κατάτμηση λέξεων, την καθολική σήμανση και τα μορφολογικά χαρακτηριστικά.', 'lt': 'Mes pristatome Uppsala sistemą, skirtą 2018 m. CoNLL bendram uždaviniui dėl universalios priklausomybės analizės. Mūsų sistema yra vamzdynas, sudarytas iš trijų komponentų: pirmasis atlieka jungtinį žodžio ir sakinio segmentavimą; antroje numatytos kalbos dalys ir morfologinės savybės; trečiasis numato priklausomybę nuo žodžių ir ženklų nuo medžių. Užuot mokę vieną analizavimo model į kiekvienam medžio langeliui, mes mokėme modelius su daugeliu medžio langelių viena kalba arba glaudžiai susijusiomis kalbomis, labai sumažindami modelių skaičių. Oficialių bandymų metu mes klasifikuojame 7-ąją iš 27 komandų LAS ir MLAS metriniams rodikliams. Mūsų sistema iš viso gavo geriausius rezultatus žodžių segmentacijai, universaliam POS ženklinimui ir morfologinėms savybėms.', 'ms': 'Kami memperkenalkan sistem Uppsala untuk Tugas Berkongsi CoNLL 2018 pada penghuraian dependensi universal. Sistem kita adalah saluran paip yang terdiri dari tiga komponen: yang pertama melakukan segmen perkataan dan kalimat bersama; yang kedua meramalkan sebahagian dari tag-ucapan dan ciri-ciri morfologi; yang ketiga meramalkan pokok dependensi dari kata-kata dan tag. Instead of training a single parsing model for each treebank, we trained models with multiple treebanks for one language or closely related languages, greatly reducing the number of models.  Dalam ujian rasmi, kami menaiki 7 dari 27 pasukan untuk metrik LAS dan MLAS. Sistem kami mendapat skor terbaik secara keseluruhan untuk segmen perkataan, tag POS universal, dan ciri-ciri morfologik.', 'mk': 'Го претставуваме системот на Упсала за заедничката задача CoNLL 2018 за универзално анализирање на зависноста. Нашиот систем е гасовод кој се состои од три компоненти: првиот изведува заедничка сегментација на зборови и реченици; вториот предвидува дел од говорот и морфолошки карактеристики; третата предвидува дрвја на зависност од зборови и ознаки. Наместо да обучуваме еден модел за анализирање за секоја дрвена лента, обучувавме модели со повеќе дрвени ленти за еден јазик или блиски поврзани јазици, значително намалувајќи го бројот на модели. На официјалниот тест, ние се рангиравме на 7 од 27 тимови за метриката на ЛАС и МЛАС. Нашиот систем ги доби најдобрите резултати вкупно за зборовите сегментација, универзалното POS означување и морфолошки карактеристики.', 'mt': 'Aħna nippreżentaw is-sistema Uppsala għall-Kompitu Konġunt CoNLL 2018 dwar l-analiżi tad-dipendenza universali. Is-sistema tagħna hija pipeline li tikkonsisti minn tliet komponenti: l-ewwel tagħmel segmentazzjoni konġunta ta’ kliem u sentenza; it-tieni tipprevedi tikketti ta’ parti mid-diskors u karatteristiċi morfoloġiċi; it-tielet jipprevedi s-siġar tad-dipendenza mill-kliem u t-tikketti. Instead of training a single parsing model for each treebank, we trained models with multiple treebanks for one language or closely related languages, greatly reducing the number of models.  On the official test run, we ranked 7th of 27 teams for the LAS and MLAS metrics.  Is-sistema tagħna kisbet l-aħjar punteġġi globali għas-segmentazzjoni tal-kliem, it-tikkettar universali tal-POS, u l-karatteristiċi morfoloġiċi.', 'ml': 'ഞങ്ങള്\u200d കോണ്\u200dഎല്\u200d 2018 ല്\u200d ഉപ്പ്സാലാ സിസ്റ്റത്തെ കാണിച്ചുകൊണ്ടിരിക്കുന്നു. പ്രപഞ്ചാരത്തിലെ ആശ്രയിച്ച പാ നമ്മുടെ സിസ്റ്റത്തിന്റെ മൂന്നു ഭാഗങ്ങളില്\u200d ഉള്ള ഒരു പൈപ്പെലിന്\u200d ആണ്: ആദ്യം യോജിപ്പിക്കുന്ന വാക്കും വാക് രണ്ടാമത്തെ സംസാരിക്കുന്നതിന്റെ ഭാഗവും മോര്\u200dഫോളജിക്കല്\u200d ഗുണഗണങ്ങളും പ്രവചിക്കുന്നു; മൂന്നാമത്തെ വാക്കുകളില്\u200d നിന്നും ടാഗുകളില്\u200d നിന്നും ആശ്രയിക്കുന്ന വൃക്ഷങ്ങള്\u200d പ്രവചിക ഓരോ ട്രീബാങ്കിനും ഒരു പാര്\u200dസിംഗ് മോഡല്\u200d പരിശീലിപ്പിക്കാന്\u200d പകരം, ഒരു ഭാഷയ്ക്കോ അടുത്തുള്ള ഭാഷകള്\u200dക്കോ പല ട്രീബാങ്കുകളുമായി മോഡലു ഓഫീസിലെ പരീക്ഷണത്തില്\u200d ഞങ്ങള്\u200d 27 ടീമില്\u200d 7 ടീമിനെ റെഞ്ച് ചെയ്തു. നമ്മുടെ സിസ്റ്റത്തില്\u200d വാക്കുകളുടെ വിഭാഗത്തിന്റെ ഏറ്റവും മികച്ച സ്കോര്\u200d കിട്ടിയിരിക്കുന്നു, പ്രപഞ്ച പോസ്', 'mn': 'Бид 2018 оны CoNLL-ийн нийтлэл хамааралтай ажлын Uppsala системийг дэвшүүлж байна. Бидний систем бол гурван компонентын хоолойн шугам юм. Эхлээд хамтдаа үг, өгүүлбэр хэмжээг хийдэг. хоёр дахь нь ярианы нэг хэсэг болон морфологичдын хувьд таамагладаг. Гуравдагч нь үг, тэмдэгүүдийн хамааралтай модыг таамагладаг. Магаз бүрийн нэг хуваалцах загварын оронд бид нэг хэл эсвэл ойролцоогоор холбоотой хэл дээр олон моделуудыг суралцаж, загваруудын тоо их багасгаж байна. Шинжлэх ухааны туршилтын дараа бид LAS болон MLAS метрийн 27 багийн7-р баг байгуулсан. Бидний систем үг загварын хамгийн сайн оноо, универсал POS маркинг, мөн морфологикийн тоо баримтуудыг авсан.', 'no': 'Vi presenterer opppsala- systemet for CoNLL 2018 delt oppgåve på universell tolking av avhengighet. Sistemet vårt er ein røyrlinje som inneheld tre komponentar: den første utfører kopla ord og setningsssegmentasjon; den andre foregår ein del av taletaggar og morfologiske funksjonar; den tredje forventar avhengighetstrær frå ord og merkelappar. I staden for å lære eit enkelt tolkingsmodul for kvar treebank, trengte vi modeller med fleire treebanklar for eitt språk eller nærare relaterte språk, og det reduserer mykje talet på modeller. På den offisielle testkøyren rangerte vi 7. av 27 grupper for LAS- og MLAS- metrikane. Sistemet vårt fikk dei beste poeng overalt for ordsegmentering, universelle POS-merking og morfologiske funksjonar.', 'pl': 'Przedstawiamy system Uppsala dla CoNLL 2018 Shared Task na temat uniwersalnego parsowania zależności. Nasz system to rurociąg składający się z trzech składników: pierwszy wykonuje wspólną segmentację słów i zdań; drugi przewiduje znaczniki części mowy i cechy morfologiczne; Trzecia przewiduje drzewa zależności od słów i tagów. Zamiast szkolić pojedynczy model parsowania dla każdego banku drzew, trenowaliśmy modele z wieloma bankami drzew dla jednego języka lub blisko pokrewnych języków, znacznie zmniejszając liczbę modeli. Podczas oficjalnego biegu testowego zajęliśmy siódmą z 27 drużyn pod względem wskaźników LAS i MLAS. Nasz system uzyskał najlepsze wyniki w kategoriach segmentacji słów, uniwersalnego tagowania POS oraz cech morfologicznych.', 'ro': 'Prezentăm sistemul Uppsala pentru CoNLL 2018 Shared Task privind analizarea dependenței universale. Sistemul nostru este o conductă formată din trei componente: prima efectuează segmentarea comună a cuvântului și propozițiilor; al doilea prezice etichetele parțiale de vorbire și caracteristicile morfologice; Al treilea prezice copaci dependenți de cuvinte și etichete. În loc să instruim un singur model de analiză pentru fiecare braţ, am instruit modele cu mai multe braţe pentru o singură limbă sau limbi strâns legate, reducând considerabil numărul de modele. La testul oficial, ne-am clasat pe locul 7 din 27 de echipe pentru valorile LAS și MLAS. Sistemul nostru a obținut cele mai bune scoruri generale pentru segmentarea cuvintelor, etichetarea POS universală și caracteristicile morfologice.', 'sr': 'Predstavljamo Uppsala sistem za zajednički zadatak CoNLL 2018 na univerzalnom analizu zavisnosti. Naš sistem je cijevi koji se sastoji od tri komponenta: prvi izvodi zajedničku reč i segmentaciju rečenica; Drugi predviđa dio govornih znakova i morfološke karakteristike; treæe predviða drveæe zavisnosti od reèi i etiketa. Umjesto treninga jednog model a analize za svaki treeban, trenirali smo modele sa višestrukim treebancima za jednog jezika ili bliskog povezanog jezika, veoma smanjujući broj modela. Na službenom testu smo postavili 7. od 27 timova za metriku LAS i MLAS. Naš sistem je dobio najbolje rezultate ukupno za segmentaciju reči, univerzalne oznake POS-a i morfološke funkcije.', 'si': 'අපි CoNLL 2018 සාමාන්\u200dය විශේෂ විශේෂ විශේෂ විශේෂ කරනවා කාර්යය සඳහා Uppseala පද්ධතිය පෙන්වන්න. අපේ පද්ධතිය පායිප්ලින් එකක්, අංකයක් තුනක් තියෙනවා: පළමු වචන සහ වාක්ය අංකයක් කරනවා; දෙවෙනි ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා කොටස් කොටස් කිරීමේ ටැග් සහ මෝර්ෆෝලෝජික විශ තුන්වෙනි වචන සහ ටැග් වලින් විශේෂතාවක් විශ්වාස කරනවා. හැම ත්\u200dරීබැන්ක් වෙනුවෙන් එක්ක විශ්ලේෂණ නිර්මාණයක් වෙනුවෙන් ප්\u200dරීක්ෂණා කරන්න, අපි හැම ත්\u200dරීබැන්ක් වෙනුවෙන් විශ්ලේෂ ප්\u200dරධානික පරීක්ෂණාවේ පරීක්ෂණාවට, අපි LAS සහ MLAS මෙට්\u200dරික්ස් වලට කණ්ඩායම් 27 ක් 7වෙනි ස්ථානය ක අපේ පද්ධතියට වචන විශේෂණය, ජාතික POS ටැග් එක සහ විශේෂ විශේෂතාවක් ලැබුනා.', 'so': 'Waxaannu soo bandhignaynaa nidaamka Uppsala ee CoNLL 2018 shaqo ku saabsan baarlamaanka ku xiran caalamiga. Our system is a pipeline consisting of three components: the first performs joint word and sentence segmentation;  the second predicts part-of-speech tags and morphological features;  saddexaad wuxuu wax ka sheegaa geedaha ku xiran ee hadalka iyo alaabta. Isku tababarinta tusaale baarlamaha hal mar ah, waxaynu tababarinnay tusaalooyin badan oo af keliya ama luqad ku dhow ku yaal oo ku qoran qoraal badan, si weyn ayaannu u yaraynay tirada modello. Baaritaanka rasmiga ah ee baaritaanka rasmiga ah, waxaynu ka samaysannay koox 7aad oo ka mid ah maamulka LAS iyo MLAS. Systemkanagu wuxuu helay qiimaha ugu fiican ee la xiriira hadalka, goobaha caalamiga ah ee POS iyo waxyaabaha morphologiga ah.', 'sv': 'Vi presenterar Uppsala-systemet för CoNLL 2018 Shared Task om universell beroendetolkning. Vårt system är en pipeline bestående av tre komponenter: den första utför gemensam ord och mening segmentering; Den andra förutspår delar av tal taggar och morfologiska egenskaper. Den tredje förutspår beroendeträd från ord och taggar. Istället för att träna en enda tolkningsmodell för varje trädbank tränade vi modeller med flera trädbanker för ett språk eller nära besläktade språk, vilket avsevärt minskade antalet modeller. På den officiella testkörningen rankade vi 7:e av 27 lag för LAS- och MLAS-mätningarna. Vårt system fick de bästa poängen totalt för ordsegmentering, universell POS-märkning och morfologiska egenskaper.', 'ur': 'ہم نے CoNLL 2018 کے لئے عمومی اعتماد پارسینگ کے بارے میں شریک ٹاکس کے لئے Uppsala سیستم کو پیش کیا ہے. ہمارا سیسٹم تین قسمتوں میں سے ایک پیپ لین ہے: پہلی کلمات اور کلمات سقمیٹ کرتی ہے۔ دوسری بات کی قسمت ٹاگ اور مورفولوژیکوں کی پیش بینی کرتی ہے۔ تیسری باتوں اور ٹاگ سے اعتباری درختوں کی پیش بینی کرتی ہے۔ ہر ٹریب بانک کے لئے ایک پارسینگ موڈل کی تعلیم کے بدلے ہم نے ایک زبان یا نزدیک مرتبہ زبانوں کے لئے بہت سی ٹریب بانک کے مطابق موڈل کی تعلیم دی تھی، اور موڈل کی تعداد بہت کم کر رہی تھی۔ رسمی آزمائش پر، ہم LAS اور MLAS متریک کے لئے 27 ٹیموں میں 7م رقم رکھتے تھے. ہماری سیستم نے کلمات سکوٹ کے لئے سب سے بہترین سکوٹ حاصل کئے ہیں، یونولیٹ POS ٹاگ، اور مورفولوجی وینٹر کے لئے۔', 'ta': 'நாங்கள் கோன்எல் 2018 பங்கிடப்பட்ட பணியை உலக சார்ந்த சார்பு பாடல் மீது பங்கிடப்பட்டுள்ள உப்பிசாலா அமைப்பை க நம் அமைப்பு மூன்று பொருள்களில் உள்ள ஒரு பைப்லைன் ஆகும்: முதல் இணைய வார்த்தையும் வாக்கின் பிரிவு இரண்டாவது பேச்சு குறிகளின் பகுதி மற்றும் குறிப்புகளின் குறிப்பை முன்வாக்குகிறது; the third predicts dependency trees from words and tags.  ஒவ்வொரு ட்ரீபாங்குக்கும் ஒரே பாடல் மாதிரியை பயிற்சி செய்வதற்கு பதிலாக, ஒரு மொழியில் அல்லது அருகில் தொடர்ந்த மொழிகளுக்கு பல முனைகள நாங்கள் ஏலஸ் மற்றும் MLAS மெட்ரிக்களுக்கான 27 குழுக்களில் 7வது இயக்கப்பட்டது. வார்த்தை பிரித்தல், பொதுவான POS குறிப்பு, மற்றும் குறிப்புகளுக்கு எங்கள் அமைப்பு சிறந்த மதிப்புகள் பெற்றது.', 'uz': "Biz 2018 CoNLL'ning Uppsala tizimini umumiy tashkilotga qo'shilgan vazifani birlashtiramiz. Bizning tizimimiz uch komponentlardan bir pipeline: birinchi birinchi birinchi birinchi birinchi bir so'z va so'zni birlashtirishni bajaradi; ikkinchi marta so'zlarning qismlarini va morfologik xususiyatlarini ko'rsatadi; uchinchi marta so'zlar va taglar bilan ishlatadigan daraxtlarga ishlatiladi. Biz har bir treebank uchun bir parsing modelini o'rganishni oʻrniga bir tillar yoki yaxshi bog'langan bir necha treebacha modellarni o'rganishga o'rganamiz, modellarning soni juda ko'p ko'plab chiqaradi. Rasm sinov ishga tushganda, biz LAS va MLAS metriklari uchun 27 guruhdan 7 guruhni boshladik. Bizning tizimimiz soʻzni birlashtirish uchun eng yaxshi scorlar topildi, universal POS tagning va morfologik xususiyatlariga.", 'vi': 'Chúng tôi xin giới thiệu hệ thống Uppsala với ban tổ chức Colt Thậm chí thẩm quyền chia sẻ nhiệm vụ phân tích độ phụ thuộc phổ biến. Hệ thống của chúng tôi là một đường ống gồm ba thành phần: phần đầu tiên tiến hành phân đoạn chữ và câu: Người thứ hai dự đoán các thẻ bài phát biểu và các tính chất lịch. Thứ ba dự đoán các cây phụ thuộc từ và mác. Thay vì đào tạo một mô hình phân tách đơn cho mỗi lần trên ba, chúng tôi đã đào tạo các mô hình đa dạng cho một ngôn ngữ hoặc ngôn ngữ liên quan, giảm đáng kể số mô hình. Trong cuộc thử nghiệm chính thức, chúng tôi xếp hạng bảy đội tàu gần tàu LAS và MLAS metrics. Hệ thống của chúng tôi đạt được điểm số tốt nhất tổng thể cho việc phân đoạn từ, vị trí hoàn toàn của trường và các tính chất.', 'bg': 'Представяме системата Упсала за споделената задача за анализ на универсалната зависимост. Нашата система е тръбопровод, състоящ се от три компонента: първият извършва съвместна сегментация на думи и изречения; втората прогнозира маркери за част от речта и морфологични характеристики; Третият прогнозира зависимостта дървета от думи и тагове. Вместо да тренираме по един модел за анализ за всяка дървесна лента, ние тренирахме модели с множество дървесни ленти за един език или тясно свързани езици, което значително намали броя на моделите. На официалния тест бяхме на 7-о място от 27 отбора по показателите. Нашата система получи най-добрите резултати като цяло за сегментация на думи, универсално маркиране на ПОС и морфологични характеристики.', 'nl': 'We presenteren het Uppsala systeem voor de CoNLL 2018 Shared Task over universele afhankelijkheidsparsing. Ons systeem bestaat uit drie componenten: de eerste voert gezamenlijke woord- en zinssegmentatie uit; de tweede voorspelt deeltaal-tags en morfologische kenmerken; De derde voorspelt afhankelijkheidsbomen van woorden en tags. In plaats van een enkel parsing model voor elke boombank te trainen, trainden we modellen met meerdere boombanken voor één taal of nauw verwante talen, waardoor het aantal modellen sterk verminderd werd. Op de officiële testrun stonden we 7e van 27 teams voor de LAS- en MLAS-statistieken. Ons systeem behaalde de beste scores voor woordsegmentatie, universele POS tagging en morfologische kenmerken.', 'hr': 'Predstavljamo Uppsala sistem za zajednički zadatak CoNLL 2018 na univerzalnom analizu ovisnosti. Naš sustav je cijevi koji se sastoji od tri komponenta: prvi izvodi zajedničku riječ i segmentaciju rečenica; Drugi predviđa dio govornih znakova i morfološke karakteristike; treće predviđa drveće zavisnosti od riječi i znakova. Umjesto treniranja jednog model a analize za svaki treeban, obučili smo modele sa višestrukim treebancima za jednog jezika ili bliskog povezanog jezika, veoma smanjujući broj modela. Na službenom testu smo postavili 7. od 27 timova za LAS i MLAS metriku. Naš sustav je dobio najbolje rezultate ukupno za segmentaciju riječi, univerzalne oznake POS-a i morfološke funkcije.', 'da': 'Vi præsenterer Uppsala-systemet til CoNLL 2018 Shared Task om universel afhængighedsanalyse. Vores system er en rørledning bestående af tre komponenter: Den første udfører fælles ord og sætning segmentering; Den anden forudsiger dele af tale mærker og morfologiske træk Den tredje forudsiger afhængighedstræer fra ord og tags. I stedet for at træne en enkelt analysemodel for hver træbank, trænede vi modeller med flere træbanker til ét sprog eller tæt beslægtede sprog, hvilket reducerede antallet af modeller betydeligt. På den officielle testkørsel rangerede vi 7. ud af 27 hold for LAS og MLAS målinger. Vores system opnåede de bedste resultater generelt for ordsegmentering, universel POS tagging og morfologiske funktioner.', 'de': 'Wir stellen das Uppsala-System für den CoNLL 2018 Shared Task zum universellen Parsen von Abhängigkeiten vor. Unser System ist eine Pipeline, die aus drei Komponenten besteht: Die erste führt eine gemeinsame Wort- und Satzsegmentierung durch; Die zweite prognostiziert Teile-of-Speech-Tags und morphologische Merkmale; Der dritte sagt Abhängigkeitsbäume von Wörtern und Tags voraus. Anstatt für jede Baumbank ein einzelnes Parsing-Modell zu trainieren, trainierten wir Modelle mit mehreren Baumbanken für eine Sprache oder nahe verwandte Sprachen, wodurch die Anzahl der Modelle stark reduziert wurde. Im offiziellen Testlauf belegten wir den siebten Platz der 27-Teams für die LAS- und MLAS-Metriken. Unser System erzielte insgesamt die besten Bewertungen für Wortsegmentierung, universelle POS-Tagging und morphologische Merkmale.', 'ko': 'Google은 CoNLL 2018 일반 종속 해결 공유 작업을 위한 Uppsala 시스템을 제공합니다.우리의 시스템은 세 부분으로 구성된 파이프라인이다. 첫 번째 부분은 단어와 문장의 결합 구분을 집행한다.두 번째 부분은 어성 표기와 형태 특징을 예측한다.세 번째는 단어와 표기에 따라 예측 의존 트리다.우리는 모든 트리 라이브러리에 하나의 해석 모델을 훈련시키지 않고 하나의 언어나 밀접한 관계를 가진 언어를 위해 여러 개의 트리 라이브러리 모델을 훈련시켜 모델의 수량을 크게 줄였다.공식 테스트에서는 LAS와 MLAS의 27개 팀 중 7위에 올랐다.우리의 시스템은 분사, 통용어성 표기와 형태학적 특징에서 가장 좋은 전체 점수를 얻었다.', 'sw': 'Tunaonyesha mfumo wa Uppsala wa CoNLL 2018 ulishirikisha kazi ya kutegemea uchimbaji wa ulimwengu. Our system is a pipeline consisting of three components: the first performs joint word and sentence segmentation;  the second predicts part-of-speech tags and morphological features;  matatu yanatabiri miti ya kutegemea kutoka maneno na alama. Badala ya kufundisha muundo mmoja wa wimbo kwa kila benki ya mitatu, tulifundisha mifano yenye vifaa vingi vya mitatu kwa lugha moja au kwa karibu, kwa kiasi kikubwa kupunguza idadi ya mifano. Katika jaribio rasmi, tulipanda timu 7 ya 27 kwa ajili ya mbinu za LAS na MLAS. Mfumo wetu ulipata vipimo vizuri zaidi kwa ajili ya kujitenga maneno, wimbo wa POS ulimwengu wa kawaida, na vipengele vya kifolojia.', 'tr': 'Biz CoNLL 2018-nji ýylyň ýerleşýän zady üçin Uppsala sistemini uniwersal baglanylyk parslamasynda görkezip otyrdyk. Biziň sistemimiz üç komponenten bar pipeline: ilkinji gezek we sözlem segmentasyny bejerýär; Ikinji tarapy çykyş tägleriniň bir parçasyny we morfolojik özelliklerini çaklaýar; Üçünji sany söz we täglerden bağlyklyk agaçlaryny çaklaýar. Her sany çubuk üçin ýeke bir analyz nusgasyny eğlemek ýerine, bir dil ýa-da ýakyn derejeler üçin örän sany düşürmek üçin örän nusgasyny ukypdyk. Resmi testiň üstünde biz LAS we MLAS metrikleri üçin 27 topardan 7-nji topar düzüldik. Bizim sistemimiz kelime segmentasyon, universel POS taglaması ve morfolojik özellikleri için en iyi noktalar aldı.', 'af': "Ons stel die Uppsala stelsel voor die CoNLL 2018 deelde taak op universele afhanklikheid verwerking. Ons stelsel is 'n pipelyn wat bestaan van drie komponente: die eerste uitvoer joint woord en sentence segmentasie; die tweede voorskou deel van spraak etikette en morfologiese funksies; en die derde voorskou afhanklikheidbome van woorde en etikette. In plaas van onderwerp van 'n enkele onderwerp model vir elke treebank, het ons onderwerp modele met veelvuldige treebanks vir een taal of naby verwante tale, met groot verduur van die aantal modele. Op die offisiele toets hardloop, het ons 7de van 27 teams gerankeer vir die LAS en MLAS metries. Ons stelsel het die beste punte geneem totaal vir woord segmentasie, universele POS merking en morfologiese funksies.", 'am': 'የኮንLL 2018 የኦፕሳላን ስርዓት በዓለምአቀፍ በተደገመ ማኅበር ላይ ያሳየናል፡፡ Our system is a pipeline consisting of three components: the first performs joint word and sentence segmentation;  ሁለተኛው የንግግር መክፈቻ እና የሞፎሎጂ ምርጫዎች ሦስተኛው የቃልና የቦታ ዛፎች የታመነ ይናገራል፡፡ አንድ የቲርባክ ዘርጊያ model በማስተማር ፋንታ፣ በአንድ ቋንቋ ወይም በአቅራቢያ የተቃራረበ ቋንቋዎች ላይ ብዙ ድምፅዎችን አስተማርተናል፡፡ ባለሥልጣን ፈተና በሮጠ ጊዜ የ27 ቡድን ሰባተኛ ለLAS እና MLAS ሜትሪክ ደረስን፡፡ Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.', 'fa': 'ما سیستم Uppsala را برای کارهای مشترک CoNLL ۲۰۱۸ در پارش بستگی جهانی پیشنهاد می کنیم. سیستم ما یک لوله است که از سه عنصر بستگی دارد: اولین بار کلمه مشترک و قطعه جمله را انجام می دهد. دومین برچسب\u200cهای سخنرانی و ویژه\u200cهای مورفیک را پیش\u200cبینی می\u200cکند. سوم درختان بستگی را از کلمات و نقاشی پیش بینی می\u200cکند. به جای آموزش یک مدل جدا کردن واحد برای هر چوب درخت، ما مدل های متعدد درخت آموزش دادیم برای یک زبان یا به نزدیک مرتبط به زبان، و بسیار تعداد مدل را کاهش می دهیم. در مسیر آزمایش رسمی، ما هفتم از 27 تیم برای متریک LAS و MLAS رقم دادیم. سیستم ما بهترین امتیاز برای جدایی کلمات، نقاشی POS جهانی و ویژه های مورفولوژیک را دریافت کرد.', 'sq': 'We present the Uppsala system for the CoNLL 2018 Shared Task on universal dependency parsing.  Sistemi ynë është një tubacion që përbëhet nga tre komponente: i pari kryen segmentimin e fjalëve dhe fjalëve të përbashkëta; e dyta parashikon etiketa pjesë të fjalimit dhe karakteristika morfologjike; e treta parashikon pemët e varësisë nga fjalët dhe etiketat. Në vend të trajnimit të një modeli të vetëm analizimi për çdo bazë pemësh, ne trajnuam modele me baza pemësh të shumta për një gjuhë apo gjuhë të lidhura afër, duke reduktuar shumë numrin e modeleve. Në provën zyrtare, renditëm të shtatën nga 27 ekipe për metrikat e LAS dhe MLAS. Sistemi ynë mori rezultatet më të mira përgjithësisht për segmentimin e fjalëve, etiketën universale të POS dhe karakteristikat morfologjike.', 'bn': 'আমরা বিশ্ববিদ্যালয়ের নির্ভরশীল পার্গিং নিয়ে আপপ্সালা সিস্টেম উপস্থাপন করছি। আমাদের সিস্টেম একটি পাইপেলাইন যার মধ্যে তিন কম্পোনেন্ট রয়েছে: প্রথমটি যৌথ শব্দ এবং শাস্তি বিভক্ত করে; দ্বিতীয় ভাষণের অংশ এবং মরোফোলজিক্যাল বৈশিষ্ট্যাবলীর বৈশিষ্ট্য; তৃতীয় ভবিষ্যদ্বাণী করে শব্দ এবং ট্যাগ থেকে নির্ভর বৃক্ষ। প্রত্যেক ট্রিব্যাংকের জন্য একটি পার্সিং মডেল প্রশিক্ষণের বদলে আমরা এক ভাষা বা কাছাকাছি সম্পর্কিত ভাষার জন্য বেশ কিছু ত্রীব্যাংক প্রশিক্ অফিসিয়াল পরীক্ষায়, আমরা ২৭ টি দলের ৭তম টিম ল্যান্স এবং এমলাস মেট্রিকের জন্য রেন্ড করেছি। Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.', 'hy': 'Մենք ներկայացնում ենք ԿոՆԼԼ 2018-ի համաշխարհային կախվածության վերլուծության համակարգը: Մեր համակարգը խողովակաշար է, որը կազմված է երեք բաղադրիչներից. առաջինը կատարում է միավոր բառեր և նախադասություններ: երկրորդը կանխատեսում է խոսքի մասերը և մորֆոլոգիական հատկությունները, երրորդը կանխատեսում է բառերից և նշաններից կախված ծառերը: Փոխարենը յուրաքանչյուր ծառի աճի համար մեկ վերլուծության մոդել սովորեցնելու փոխարեն, մենք մի լեզու կամ միմյանց հետ կապված լեզուների բազմաթիվ ծառերի աճով սովորեցրեցինք, մեծ նվազեցնելով մոդելների թիվը: Օրինակական փորձարկումների ժամանակ մենք դասակարգեցինք 27 թիմերից 7-րդը LAS-ի և MLAS-ի մետրիկայի համար: Մեր համակարգը ստացավ ընդհանուր լավագույն գնահատականները բառերի սեգրեգացիայի, համաշխարհային POS-ի նշանների և մորֆոլոգիական հատկությունների համար:', 'id': 'Kami mempersembahkan sistem Uppsala untuk CoNLL 2018 Shared Task on universal dependency parsing. Our system is a pipeline consisting of three components: the first performs joint word and sentence segmentation;  the second predicts part-of-speech tags and morphological features;  the third predicts dependency trees from words and tags.  Daripada melatih model penghuraian tunggal untuk setiap batang pohon, kami melatih model dengan banyak batang pohon untuk satu bahasa atau bahasa yang berhubungan dekat, dengan besar mengurangi jumlah model. On the official test run, we ranked 7th of 27 teams for the LAS and MLAS metrics.  Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.', 'cs': 'Představujeme Uppsala systém pro CoNLL 2018 Shared Task na univerzální analýzu závislostí. Náš systém je potrubí sestávající ze tří složek: první provádí společnou segmentaci slova a věty; druhá předpovídá značky části řeči a morfologické rysy; Třetí předpovídá stromy závislostí ze slov a značek. Místo tréninku jediného parsovacího modelu pro každou stromovou břeh jsme trénovali modely s více stromovými břehy pro jeden jazyk nebo úzce příbuzné jazyky, což výrazně snižuje počet modelů. Na oficiálním testovacím běhu jsme zařadili sedmé z 27 týmů pro metriky LAS a MLAS. Náš systém získal celkově nejlepší skóre pro segmentaci slov, univerzální POS tagování a morfologické vlastnosti.', 'bs': 'Predstavljamo Uppsala sistem za zajednički zadatak CoNLL 2018 na univerzalnom analizu ovisnosti. Naš sistem je cijevi koji se sastoji od tri komponenta: prvi izvodi zajedničku riječ i segmentaciju rečenica; Drugi predviđa dio govornih znakova i morfološke karakteristike; treće predviđa drveće zavisnosti od riječi i etiketa. Umjesto treninga jednog model a analize za svaki treeban, trenirali smo modele sa višestrukim treebancima za jednog jezika ili bliskog povezanog jezika, veoma smanjujući broj modela. Na službenom testu smo postavili 7. od 27 tima za LAS i MLAS metriku. Naš sistem je dobio najbolje rezultate ukupno za segmentaciju riječi, univerzalne oznake POS-a i morfološke funkcije.', 'az': 'Biz CoNLL 2018-ci ilə üniversal bağlılıq ayırılması barəsində paylaşılmış iş iş üçün Uppsala sistemini göstəririk. Bizim sistemimiz üç komponentlərdən olan bir bor çizgidir: ilk sözlər və cümlələr segmentasiyasını gerçəkləşdirir; ikinci söz etiketlərinin bir parçasını və morfolojik özelliklərini təmin edir; üçüncü təvəkküllük ağaclarını sözlərdən və etiketlərdən təmin edir. Hər çubuq üçün təkrarlama modeli təhsil etmək yerinə, bir dil və yaxınlaşdırılmış dillər üçün çoxlu çubuq modelləri təhsil etdik, modellərin sayını çox azaldırırdıq. Resmi sınaqda, LAS və MLAS metrikləri üçün 27 dəstədən 7 dəstədik. Sistemimiz söz segmentasyonu, universal POS etiketi və morfolojik özellikləri üçün ən yaxşı nöqtələri qəbul etdi.', 'fi': 'Esittelemme CoNLL 2018 Shared Task -ohjelman Uppsala-järjestelmän yleisriippuvuuden jäsentämisestä. Järjestelmämme koostuu kolmesta osasta: ensimmäinen suorittaa yhteisen sanan ja lauseen segmentoinnin; toisessa ennustetaan puheen osan tunnisteita ja morfologisia piirteitä; Kolmas ennustaa riippuvuuspuita sanoista ja tunnisteista. Sen sijaan, että treenaisimme yhden jäsennysmallin jokaiselle puupenkille, koulutimme malleja, joissa oli useita puupenkkejä yhdelle kielelle tai läheisille kielille, mikä vähensi mallien määrää huomattavasti. Virallisessa testiajossa sijoittuimme 27 joukkueesta seitsemänneksi LAS- ja MLAS-mittareiden osalta. Järjestelmämme sai parhaat pisteet sanasegmentoinnista, yleisestä POS-tagauksesta ja morfologisista ominaisuuksista.', 'et': 'Esitleme Uppsala süsteemi CoNLL 2018 Shared Task jaoks universaalse sõltuvuse parsimise kohta. Meie süsteem koosneb kolmest komponendist: esimene teostab ühise sõna- ja lausesegmenteerimise; teine prognoosib kõneosa märgistust ja morfoloogilisi tunnuseid; Kolmas ennustab sõltuvuspuude sõnadest ja siltidest. Selle asemel, et koolitada üks parsimismudel iga puupanga jaoks, koolitasime mudeleid, millel on mitu puupanka ühe keele või lähedaselt seotud keele jaoks, vähendades oluliselt mudelite arvu. Ametlikul katsesõidul saime LAS- ja MLAS-i meeskonnast seitsmenda koha 27-st meeskonnast. Meie süsteem sai parimad hinded sõna segmenteerimise, universaalse POS-märgistuse ja morfoloogiliste omaduste osas.', 'ca': 'Presentam el sistema Uppsala per la CoNLL 2018 Shared Task on universal dependency analysis. El nostre sistema és un conductor compost de tres components: el primer fa segmentació de paraules i frases conjuntes; the second predicts part-of-speech tags and morphological features;  the third predicts dependency trees from words and tags.  Instead of training a single parsing model for each treebank, we trained models with multiple treebanks for one language or closely related languages, greatly reducing the number of models.  En la prova oficial, vam classificar el 7 de cada 27 equips per a les mètriques LAS i MLAS. Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.', 'ha': "Tuna halatar da Shirin Upppala na CoNLL 2018 Shared Taimar da aka yi tasgaro a kan parse na universal dependanci. Tsarinmu yana da wani pipilin wanda ke haɗa cikin ƙanshi uku: na farkon yana tafiyar da kalmar da haɗe; ko kuma yana da rabon kalma; QXml na ukunsa yana iya gabatar da itãce masu inganci daga kalmõmi da tags. Babu kula da misãlin parsigi guda wa kowanne Treebank, mun sanar da misãlai masu motsi masu yawa wa lugha guda ko kuwa masu haɗi da lingui guda, kuma mun ƙari ƙidãyar motel. A kan jarrabi rasmi, muka sami karatun 7 na jama'a 27 na LoS da ML. Tsarinmu ya samu mafiya kyakkyawan score wa sauri, tagogi na farko da shiryoyin mutane.", 'sk': 'Predstavljamo sistem Uppsala za CoNLL 2018 Shared Task o univerzalnem razčlenitvi odvisnosti. Naš sistem je cevovod, sestavljen iz treh komponent: prvi izvaja skupno segmentacijo besed in stavkov; druga napoveduje oznake dela govora in morfološke značilnosti; Tretja napoveduje drevesa odvisnosti iz besed in oznak. Namesto usposabljanja enega samega modela razčlenjanja za vsako drevesno ploščo smo usposabljali modele z več drevesnimi ploščami za en jezik ali tesno sorodne jezike, kar je močno zmanjšalo število modelov. Na uradnem testu smo se uvrstili na 7. mesto med 27 ekipami za meritve LAS in MLAS. Naš sistem je dobil najboljše rezultate za segmentacijo besed, univerzalno označevanje POS in morfološke značilnosti.', 'jv': 'Awak dhéwé nggawe sistem uppseala kanggo CoNLL 2008 Kemerdekaan task kanggo ngerasai universel diperénsesi urip. Sistem-sistem sing dibenakake tanggal sing sampeyan telu kompon: sampeyan siji sing dibenakake kelas lan soko sampeyan; kapa Display boxes politenessoffpolite"), and when there is a change ("assertive Tanggal terjamahan ing model sing sampeyan kanggo saben nggawe barang, kita model terjamahan karo sistem sing tinimpen kanggo saben nggawe layang sampeyan uga luwih apik dhéwé, ngelarang langgar sampeyan model. Nang resmi hukum sing ditambah, kita disenyong 7-7 sing sampeyan alam kanggo LAS karo MLas Metika. Monday', 'he': 'אנחנו מציגים את מערכת Uppsala עבור משימה משותפת CoNLL 2018 על בדיקת תלויות אוניברסלית. המערכת שלנו היא צינור מורכב משלושה רכיבים: הראשון מבצע סגמנציה משותפת של מילים ומשפטים; השנייה חוששת תוויות חלק מהנאום והתכונות מורפולוגיות; השלישי חושף עצי תלויות ממילים ותגים. במקום לאמן דוגמנית בדיקת אחת לכל גבעת עץ, אימנו דוגמנים עם גבעות עץ מרובות לשפה אחת או שפות קשורות קרובות, להפחית במידה רבה את מספר הדוגמנים. במהלך הבדיקה הרשמי, הגענו לשבע מ-27 קבוצות למטריקות לאס"א ו-MLAS. המערכת שלנו השיגה את התוצאות הטובות ביותר באופן כללי עבור סגמנציה מילים, תג POS אוניברסלי, ותחומים מורפולוגיים.', 'bo': 'ང་ཚོས་CoNLL 2018 རྒྱལ་སྤྱིའི་རྟེན་འབྲེལ་བཤད་ཀྱི་ལས་འགུལ་གྱི་ཡར་རྒྱས་གཞུང་ལ་སྟོན་པ། ང་ཚོའི་མ་ལག་ནི་ཆ་ཤས་གསུམ་ཀྱི་རྒྱུད་དུང་ཞིག་ཡིན་པས། དང་པོ་མའི་ཐ་སྙད་འདི་ཚིག་དང་ཚིག་རྟགས་སྦྲེལ་མཐུ སྒྲུང་བརྗོད་ཀྱི་ཆ་ཤས་གཉིས་པ་དེ་ལ་ཞིབ་བྱེད་པའི་རྣམ་པ་དང་དབྱེ་བ་དག་ཚོད་རྟོགས། ཐ་སྙད་དང་ཤོག་བྱང་ཐོག་གི་རྟེན་འབྲེལ་གྱི་རྩོད་པ་གསུམ་དང་མཐོང་ཐུབ་པ་རེད། དབྱིབས་ཡུལ་རེ་རེར་སོ་སོའི་མིག་ལམ་ལུགས་གཅིག་གི་དབྱེ་སྟངས་མིན་གྱི་ཚབ་ལ། ང་ཚོས་སྐད་ཡིག གཞུང་འབྲེལ་གྱི་བརྟག་ཞིབ་འཁོར་སྐྱོད་ཀྱི་ལྟ་བུའི་ནང་དུ་ང་ཚོའི་LAS དང་ MLAS སྒྲིག་འཛིན་གྱི་ཚད་ལྡན་གྱི་༧པ་ཆ་ཕྲན Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.'}
{'en': 'Tree-Stack LSTM in Transition Based Dependency Parsing', 'ar': 'Tree-Stack LSTM في تحليل التبعية القائم على الانتقال', 'pt': 'Tree-Stack LSTM na Análise de Dependência Baseada em Transição', 'fr': "LSTM Tree-Stack dans l'analyse des dépendances basée sur les transitions", 'es': 'LSTM de pila de árboles en el análisis de dependencias basado en transición', 'zh': '盖转换之赖解析中之树堆栈 LSTM', 'ja': 'トランジションベースの依存関係解析におけるツリースタックLSTM', 'ru': 'Древовидный стек LSTM при анализе зависимостей на основе перехода', 'hi': 'ट्री-स्टैक LSTM संक्रमण आधारित निर्भरता पार्सिंग में', 'ga': 'LSTM Crann-Chruach i bParsáil Spleáchais Idirthréimhsebhunaithe', 'ka': 'ტრანზიციაციის განსაზღვრებულობის განსაზღვრება LSTM', 'el': 'LSTM δέντρου σε ανάλυση εξάρτησης με βάση τη μετάβαση', 'hu': 'Tree-Stack LSTM átmeneti alapú függőség-értelmezésben', 'it': 'LSTM Tree-Stack in Transition Based Dependency Parsing', 'lt': 'LSTM pagal medžių pakopą pereinamojo laikotarpio priklausomybės analizėje', 'kk': 'Қайталау негізіндегі тәуелдік талдау', 'mk': 'LSTM на степенот на дрво во анализирање на зависности базирано на транзиција', 'ms': 'LSTM Tree-Stack dalam Penghuraian Dependency Berasas Transition', 'ml': 'Transition Based on Dependency Parsing', 'mn': 'Түүнчлэлт үндсэн хамааралын талаар мод-Стак LSTM', 'mt': 'Tree-Stack LSTM in Transition Based Dependency Parsing', 'no': 'Trestakk LSTM i tolking av avhengighet', 'ro': 'LSTM în analizarea dependenței bazate pe tranziție', 'pl': 'Tree-Stack LSTM w przejściowym parowaniu zależności', 'sr': 'Drvo-staklo LSTM u analizu zavisnosti', 'si': 'ට්\u200dරි- ස්ටෑක් LSTM පරිස්ථානය අධාරිත විශ්වාස කරන්න', 'sv': 'Trästapel LSTM i övergångsbaserad beroendetolkning', 'so': 'Baaritaanka ku saleysan baaritaanka ku xiran', 'ta': 'மாற்றுதலில் சார்ந்த சார்ந்த பாசிங்கு அடிப்படையில் மரத்தின் அடிப்படை LSTM', 'ur': 'ٹرانسیٹن بنیاد ڈیفاندنستی پارسینگ میں تری-سٹک LSTM', 'uz': 'Name', 'vi': 'Kiểu méo mó:', 'bg': 'LSTM на дърветата в анализ на зависимостта въз основа на прехода', 'nl': 'Tree-Stack LSTM in overgangsgebaseerde afhankelijkheidsparsing', 'hr': 'Drvo-staklo LSTM u razmatranju zavisnosti', 'da': 'Træstak LSTM i overgangsbaseret afhængighedsfortolkning', 'de': 'Tree-Stack LSTM in Transition Based Dependency Parsing', 'ko': '변환 종속 해결 기반 트리 스택 LSTM', 'id': 'LSTM Tree-Stack dalam Parsing Dependensi Berdasarkan Transisi', 'tr': 'Kejime Başlyklar Taýýarlamasynda Tree-Stak LSTM', 'fa': 'LSTM درخت- سطح درخت در تحلیل بستگی بر اساس تغییر', 'sw': 'Mlima-Stack LSTM katika Mpito Kutegemea', 'af': 'Boom- Stack LSTM in Transisie Basiese Afhanklikheidverwerking', 'sq': 'LSTM në analizimin e varësive të bazuar në tranzicion', 'am': 'ምርጫዎች', 'az': 'Aƒüac-Stack LSTM T…ôrzind…ô baƒülƒ±lƒ±q analizi', 'bn': 'ট্রীস- স্ট্যাক এলসিএম- এ পরিবর্তনের উপর নির্ভরিত পার্সিং', 'hy': 'Փայռ-կույտ LSMT-ն անցումի հիմնված կախվածության վերլուծում', 'cs': 'LSTM stromových stohů v analýze závislostí založeném na přechodu', 'bs': 'Drvo-staklo LSTM u razmatranju zavisnosti', 'ca': "LSTM de pila d'arbres en l'analització de dependencies basada en transició", 'et': 'Tree-Stack LSTM üleminekupõhises sõltuvuse parsimises', 'fi': 'Tree-Stack LSTM siirtymään perustuvassa riippuvuuden analysoinnissa', 'sk': 'LSTM Tree-Stack v prehodnem razčlenjevanju odvisnosti na podlagi prehoda', 'ha': 'KCharselect unicode block name', 'jv': 'Stack', 'he': 'LSTM מעלה עץ במחקר תלויות מבוסס על העברה', 'bo': 'Transition་ལ་གཞི་བརྟེན་པའི་རྟེན་འབྲེལ་བཤད་ནང་སྡོང་བོའི་སྡོང་བ LSTM'}
{'en': 'We introduce tree-stack LSTM to model state of a transition based parser with ', 'ar': 'نقدم LSTM المكدس الشجري لنموذج حالة المحلل اللغوي القائم على الانتقال مع الشبكات العصبية المتكررة. لا تستخدم Tree-stack LSTM أي ميزات تستند إلى شجرة التحليل أو مصنوعة يدويًا ، ولكنها تؤدي أداءً أفضل من النماذج التي تحتوي على هذه الميزات. نقوم أيضًا بتطوير مجموعة جديدة من حفلات الزفاف من الميزات الخام لتحسين الأداء. هناك 4 مكونات رئيسية لهذا النموذج: المكدس σ-LSTM و β-LSTM المخزن المؤقت و LSTM للإجراءات و Tree-RNN. تستخدم جميع LSTMs متجهات ميزة كثيفة مستمرة (حفلات الزفاف) كمدخل. تقوم Tree-RNN بتحديث حفلات الزفاف هذه بناءً على التحولات. نظهر أن نموذجنا يعمل على تحسين الأداء باستخدام لغات منخفضة الموارد مقارنة بسابقاتها. نشارك في المهمة المشتركة لـ CoNLL 2018 UD كفريق "KParse" واحتلت المرتبة 16 في LAS والمرتبة 15 في مقاييس BLAS و BLEX ، من 27 مشاركًا قاموا بتحليل 82 مجموعة اختبار من 57 لغة.', 'es': 'Presentamos LSTM de pila de árboles para modelar el estado de un analizador basado en transiciones con redes neuronales recurrentes. Tree-stack LSTM no utiliza ninguna función basada en árbol de análisis o hecha a mano, pero funciona mejor que los modelos con estas funciones. También desarrollamos un nuevo conjunto de incrustaciones a partir de funciones sin procesar para mejorar el rendimiento. Hay 4 componentes principales de este modelo: σ-LSTM de stack, β-LSTM de buffer, LSTM de acciones y Tree-RNN. Todos los LSTM utilizan vectores de características densos continuos (incrustaciones) como entrada. Tree-RNN actualiza estas incrustaciones en función de las transiciones. Demostramos que nuestro modelo mejora el rendimiento con lenguajes de bajos recursos en comparación con sus predecesores. Participamos en la tarea compartida UD de CoNll 2018 como el equipo «KParse» y ocupamos el puesto 16 en LAS, el 15 en las métricas de BLAS y BLEX, de 27 participantes analizando 82 conjuntos de pruebas de 57 idiomas.', 'pt': 'Introduzimos o LSTM de pilha de árvore para modelar o estado de um analisador baseado em transição com redes neurais recorrentes. O LSTM de pilha de árvore não usa nenhum recurso baseado em árvore de análise ou feito à mão, mas tem um desempenho melhor do que os modelos com esses recursos. Também desenvolvemos um novo conjunto de incorporações a partir de recursos brutos para aprimorar o desempenho. Existem 4 componentes principais deste modelo: σ-LSTM da pilha, β-LSTM do buffer, LSTM das ações e árvore-RNN. Todos os LSTMs usam vetores de recursos densos contínuos (embeddings) como entrada. Tree-RNN atualiza essas incorporações com base nas transições. Mostramos que nosso modelo melhora o desempenho com linguagens de poucos recursos em comparação com seus antecessores. Participamos do CoNLL 2018 UD Shared Task como a equipe “KParse” e ocupamos o 16º lugar no LAS, 15º nas métricas BLAS e BLEX, com 27 participantes analisando 82 conjuntos de teste de 57 idiomas.', 'fr': "Nous introduisons le LSTM tree-stack pour modéliser l'état d'un analyseur basé sur la transition avec des réseaux de neurones récurrents. Tree-Stack LSTM n'utilise aucune fonctionnalité basée sur un arbre d'analyse ou fabriquée à la main, mais fonctionne mieux que les modèles dotés de ces fonctionnalités. Nous développons également de nouveaux ensembles d'intégrations à partir de fonctionnalités brutes pour améliorer les performances. Ce modèle comporte 4 composants principaux\xa0: σ-LSTM de la pile, β-LSTM du tampon, LSTM des actions et Arbre-RNN. Tous les LSTM utilisent des vecteurs d'entités denses continus (embeddings) en entrée. Tree-RNN met à jour ces intégrations en fonction des transitions. Nous montrons que notre modèle améliore les performances avec des langages à faibles ressources par rapport à ses prédécesseurs. Nous participons à ConLL 2018 UD Shared Task en tant qu'équipe «\xa0KParse\xa0» et nous nous sommes classés 16e dans LAS, 15e pour les métriques BLAS et BLEX, avec 27 participants analysant 82 ensembles de tests dans 57 langues.", 'ja': 'ツリースタックLSTMを導入し、遷移ベースの構文解析器の状態を再帰ニューラルネットワークでモデル化する。ツリースタックLSTMは、構文解析ツリーベースまたは手作業で作成された機能を使用しませんが、これらの機能を持つモデルよりも優れたパフォーマンスを発揮します。また、パフォーマンスを向上させるために、RAW機能から新しい組み込みセットを開発しています。このモデルには、スタックのσ - LSTM、バッファのβ - LSTM、アクションのLSTM、ツリー- RNNの4つの主要なコンポーネントがあります。すべてのLSTMは、入力として連続した高密度フィーチャーベクトル（埋め込み）を使用します。ツリー- RNNは、トランジションに基づいてこれらの埋め込みを更新します。当社のモデルは、以前のモデルと比較して、リソースの少ない言語でパフォーマンスを向上させることを示しています。CoNLL 2018 UD Shared Taskに「KParse」チームとして参加し、57の言語から82のテストセットを解析した27人の参加者のうち、LASで16位、BLASとBLEXの指標で15位にランクインしました。', 'hi': 'हम आवर्तक तंत्रिका नेटवर्क के साथ एक संक्रमण आधारित पार्सर के मॉडल राज्य के लिए ट्री-स्टैक एलएसटीएम पेश करते हैं। ट्री-स्टैक एलएसटीएम किसी भी पार्स ट्री आधारित या हाथ से तैयार की गई सुविधाओं का उपयोग नहीं करता है, फिर भी इन सुविधाओं के साथ मॉडल की तुलना में बेहतर प्रदर्शन करता है। हम प्रदर्शन को बढ़ाने के लिए कच्चे सुविधाओं से एम्बेडिंग का नया सेट भी विकसित करते हैं। इस मॉडल के 4 मुख्य घटक हैं: स्टैक का σ-एलएसटीएम, बफर का β-एलएसटीएम, एक्शन \'एलएसटीएम और ट्री-आरएनएन। सभी LSTMs एक इनपुट के रूप में निरंतर घने सुविधा वैक्टर (embeddings) का उपयोग करें। ट्री-RNN संक्रमण के आधार पर इन embeddings अद्यतन करता है। हम दिखाते हैं कि हमारा मॉडल अपने पूर्ववर्तियों की तुलना में कम संसाधन भाषाओं के साथ प्रदर्शन में सुधार करता है। हम CoNLL 2018 UD Shared Task में "KParse" टीम के रूप में भाग लेते हैं और LAS में 16 वें स्थान पर, BLAS और BLEX मैट्रिक्स में 15 वें स्थान पर हैं, 27 प्रतिभागियों के 57 भाषाओं से 82 परीक्षण सेट पार्स करते हैं।', 'zh': '引入树栈 LSTM 以拟递归神经网络之解析器。 栈 LSTM 不用解析树手工,而性优于此。 我们还从原始特征中开发了一朋新的嵌入,以崇性能。 凡此 4 大要组件:堆栈之 σ-LSTM、缓冲区之 β-LSTM、操作之 LSTM 、树-RNN。 凡 LSTM 皆以连密特征向量(嵌)为输。 Tree-RNN 以转换更新。 吾明与前身,低资源言增性能。 臣等以"KParse"团队与CoNLL 2018 UD共事,排名第16位于LAS中,排名第15位于BLAS、BLEX指标,27名参与者解析自57种语者82试集。', 'ru': 'Введем древовидный стек LSTM для моделирования состояния парсера на основе перехода с рекуррентными нейронными сетями. Tree-stack LSTM не использует функции, основанные на дереве синтаксического анализа или созданные вручную, но работает лучше, чем модели с этими функциями. Мы также разрабатываем новый набор вложений из RAW-функций для повышения производительности. Существует 4 основных компонента этой модели: σ-LSTM стека, β-LSTM буфера, LSTM действий и tree-RNN. Все LSTM используют непрерывные векторы плотных признаков (вложения) в качестве входных данных. Tree-RNN обновляет эти вложения на основе переходов. Мы показываем, что наша модель улучшает производительность с низкими языками ресурсов по сравнению с ее предшественниками. Мы участвуем в CoNLL 2018 UD Shared Task в качестве команды «KParse» и занимаем 16-е место в LAS, 15-е в BLAS и BLEX метриках, из 27 участников синтаксического анализа 82 тестовых наборов с 57 языков.', 'ga': 'Tugaimid LSTM cruach-chrann isteach mar mhúnla de staid parsálaí atá bunaithe ar thrasdul le líonraí néaracha athfhillteacha. Ní úsáideann LSTM cruach-chrann aon ghnéithe crann-bhunaithe nó lámhcheirde ar bith, ach is fearr a fheidhmíonn sé ná samhlacha leis na gnéithe seo. Déanaimid forbairt freisin ar shraith nua leabaithe ó ghnéithe amh chun an fheidhmíocht a fheabhsú. Tá 4 phríomhchuid den tsamhail seo: cruacha σ-LSTM, β-LSTM maoláin, LSTM gníomhartha agus crann-RNN. Úsáideann gach LSTM veicteoirí gné dlúth leanúnach (leabaithe) mar ionchur. Déanann Tree-RNN na leabaithe seo a nuashonrú bunaithe ar aistrithe. Léirímid go bhfeabhsaíonn ár múnla feidhmíocht le teangacha íseal-acmhainne i gcomparáid lena réamhtheachtaithe. Glacaimid páirt i dTasc Comhroinnte UD CoNLL 2018 mar fhoireann “KParse” agus táimid sa 16ú háit i méadracht LAS, 15ú i méadracht BLAS agus BLEX, as 27 rannpháirtí ag parsáil 82 tacar tástála ó 57 teanga.', 'el': "Εισάγουμε το δέντρο-στοίβα LSTM για να μοντελοποιήσουμε την κατάσταση ενός αναλυτή με βάση τη μετάβαση με επαναλαμβανόμενα νευρωνικά δίκτυα. Το σύστημα δεν χρησιμοποιεί χαρακτηριστικά ανάλυσης δέντρου ή χειροποίητα χαρακτηριστικά, αλλά αποδίδει καλύτερα από τα μοντέλα με αυτά τα χαρακτηριστικά. Αναπτύσσουμε επίσης νέο σύνολο ενσωμάτωσης από ακατέργαστα χαρακτηριστικά για να ενισχύσουμε την απόδοση. Υπάρχουν τέσσερα κύρια συστατικά αυτού του μοντέλου: στοίβα -LSTM, buffer -LSTM, δράσεις' LSTM και δέντρο-RNN. Όλα τα LSTMs χρησιμοποιούν συνεχείς πυκνές διανυσματικές λειτουργίες (ενσωματώσεις) ως είσοδο. Το δέντρο-ενημερώνει αυτές τις ενσωματώσεις με βάση τις μεταβάσεις. Δείχνουμε ότι το μοντέλο μας βελτιώνει την απόδοση με γλώσσες χαμηλής περιεκτικότητας σε σύγκριση με τους προκατόχους του. Συμμετέχουμε στην κοινή εργασία του ως ομάδα και κατατάσσουμε 16η στην κατηγορία LAS, 15η στις μετρήσεις BLAS και BLEX, των 27 συμμετεχόντων που αναλύουν 82 σετ δοκιμών από 57 γλώσσες.", 'hu': 'Bevezetjük a fa-stack LSTM-t egy visszatérő neurális hálózatokkal rendelkező átmeneti alapú elemző állapotának modellezésére. A Tree-stack LSTM nem használ semmilyen elemzési fa alapú vagy kézzel készített funkciót, mégis jobban teljesít, mint az ilyen funkciókkal rendelkező modellek. A teljesítmény javítása érdekében új beágyazásokat is fejlesztünk a nyers funkciókból. Ennek a modellnek 4 fő összetevője van: stack -LSTM, buffer -LSTM, action\' LSTM és tree-RNN. Minden LSTM bemenetként folyamatos sűrű funkcióvektorokat (beágyazásokat) használ. A Tree-RNN az átmenetek alapján frissíti ezeket a beágyazásokat. Megmutatjuk, hogy modellünk alacsony erőforrású nyelvekkel javítja a teljesítményt az elődeihez képest. A CoNLL 2018 UD Shared Task-ban "KParse" csapatként veszünk részt, a 16. helyen a LAS-ban, a 15. helyen a BLAS és BLEX mutatókban, 27 résztvevőből 57 nyelvről 82 tesztkészletet elemezve.', 'kk': "Қайталанған невралды желілерден басталған ауыстыру күйінің үлгісіне LSTM батырмасын келтіреміз. Бұтақ- стекті LSTM бір талдау ағашының негізінде не қолмен құрылған мүмкіндіктерін пайдалануға болмайды, бірақ бұл мүмкіндіктерді моделдерден артық істейді. Біз сондай-ақ жаңа қасиеттерден жаңа ендіру жиілігін құрамыз. Бұл үлгінің 4 негізгі компоненті бар: stack's - LSTM, buffer's - LSTM, actions' LSTM and tree- RNN. Барлық LSTMs жұмыс қасиеттерді (ендіру) ендіру ретінде қолданылады. Бұтақ- RNN бұл ендірулерді ауыстыру негізінде жаңарту. Біз үлгіміз өзінің алдыңғыларымен салыстырып, ресурс тілдерімізді жақсарту үшін жасайды. Біз CoNLL 2018 UD ортақ тапсырмасына 'KParse' командасы ретінде қатынасыз және LAS 16- інде, 15- інде BLAS және BLEX метрикаларында, 27 қатысушылар 57 тілден 82 сынақтарды талдап тұрған.", 'it': "Introducemo LSTM ad albero-stack per modellare lo stato di un parser basato sulla transizione con reti neurali ricorrenti. Tree-stack LSTM non utilizza funzionalità basate su albero di analisi o artigianali, ma funziona meglio dei modelli con queste caratteristiche. Sviluppiamo anche un nuovo set di incorporazioni da funzionalità raw per migliorare le prestazioni. Ci sono 4 componenti principali di questo modello: stack's -LSTM, buffer's -LSTM, actions' LSTM e tree-RNN. Tutti gli LSTMs utilizzano vettori di funzionalità dense continue (embeddings) come input. Tree-RNN aggiorna queste incorporazioni in base alle transizioni. Mostriamo che il nostro modello migliora le prestazioni con linguaggi a basso contenuto di risorse rispetto ai suoi predecessori. Partecipiamo a CoNLL 2018 UD Shared Task come team 'KParse' e ci classifichiamo 16° nella LAS, 15° nella metrica BLAS e BLEX, di 27 partecipanti analizzando 82 test set da 57 lingue.", 'lt': 'Įdiegiame medžių pilį LSTM modeliuojant pereinamojo laikotarpio pagrindu pagrįstą analizatorių būklę su pasikartojančiais nerviniais tinklais. LSTM iš medžio pilvo nenaudoja jokių apdorojimo medžio ar rankiniu būdu grindžiamų savybių, tačiau veikia geriau nei modeliai su šiais savybėmis. Taip pat kuriame naują žaliavinių savybių įdėjimų rinkinį, kad pagerintume veiklos rezultatus. Yra keturi pagrindiniai šio modelio komponentai: stack − LSTM, buffer − LSTM, action − LSTM ir tree- RNN. All LSTMs use continuous dense feature vectors (embeddings) as an input.  Medžio RNN atnaujina šiuos įrašus remiantis perėjimu. Mes rodome, kad mūsų modelis gerina rezultatus mažomis išteklių kalbomis, palyginti su ankstesniais. Mes dalyvaujame CoNLL 2018 UD Shared Task kaip "KParse" komanda ir 16-ojoje klasifikuojame LAS, 15-ojoje BLAS ir BLEX metrijoje, iš 27 dalyvių, analizuojančių 82 bandymų rinkinius iš 57 kalbų.', 'mk': 'We introduce tree-stack LSTM to model state of a transition based parser with recurrent neural networks.  ЛСТМ со стоп дрвја не користи никакви оперативни или рачно направени карактеристики, но изведува подобро од моделите со овие карактеристики. Ние, исто така, развиваме нов сет на вградувања од сурови карактеристики за подобрување на резултатите. Постојат 4 главни компоненти на овој модел: сток − LSTM, буфер − LSTM, акции − LSTM и tree- RNN. Сите LSTM користат континуирани вектори со густи функции (вградени) како влог. Tree-RNN updates these embeddings based on transitions.  Ние покажуваме дека нашиот модел ја подобрува перформансата со ниски јазици на ресурси во споредба со неговите претходници. Ние учествуваме во CoNLL 2018 UD Shared Task како тим „KParse“ и се рангиравме на 16-тото место во LAS, 15-тото место во BLAS и BLEX метрика, од 27 учесници кои анализираа 82 тестови од 57 јазици.', 'ka': "ჩვენ დავიყენებთ ხე-სტაკი LSTM მოდელში გადაწყენებული გადაწყენებული პანუარული ქსელების მოდელზე. LSTM ხე- სტაკი არ გამოყენებს არსებობი პარასის ხე ან ხელის შექმნილი ფუნქციები, მაგრამ ეს ფუნქციებისთვის მოდელზე უკეთესი გამოყენება. ჩვენ ასევე განვითარებთ ახალი სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვ ამ მოდელის 4 მნიშვნელი კომპონენტები არიან: სტაკის -LSTM, ბუფერის -LSTM, მოქმედების LSTM და ხე-RNN. ყველა LSTMs გამოყენება მუშაობელი გექტიური გექტირები (დაყენება) როგორც ჩასმა. Tree-RNN განახლება ამ ინბიდრებების გარეშე გარეშე. ჩვენ აჩვენებთ, რომ ჩვენი მოდელი უფრო მეტი რესურსის ენათებით, რომლებიც უფრო მეტი წინასწინასწინასწინასწინასწინასწინასწინასწინ ჩვენ CoNLL 2018 UD გაყოფილი საქმე როგორც 'KParse' ჯგუფი და LAS-ში, 15-ში BLAS და BLEX მეტრიკში გაყოფილი, 27 მოთავსწავლებელი, 57 წლიდან 82 ტესტის ნაწილის ნაწილის ნაწილი.", 'ml': "നിലനില്\u200dക്കുന്ന നെയൂറല്\u200d നെറ്റുറല്\u200d നെറ്റോവര്\u200dക്കുകള്\u200d ഉപയോഗിച്ച് ട്രീ-സ്റ്റാക്ക് എംഎസ്റ്റിം മാതൃകയ ട്രീ- സ്റ്റാക്ക് LSTM പാര്\u200dസ് മരത്തെ അടിസ്ഥാനമാക്കിയോ കൈകൈകാര്യം ചെയ്യുന്ന വിശേഷങ്ങളോ ഉപയോഗിക്കുന്നില്ല, പക്ഷെ  പ്രവര്\u200dത്തനത്തിന് മുന്\u200dകൂട്ടുവാന്\u200d വേണ്ടി നമ്മള്\u200d പുതിയ കൂട്ടത്തില്\u200d നിന്നും പുതിയ കൂട്ടുകങ്ങള്\u200d ഉണ് ഈ മോഡലിന്റെ നാല് പ്രധാനപൂര്\u200dണ്ണഭാഗങ്ങള്\u200d ഉണ്ട്: സ്റ്റാക്കിന്റെ - LSTM, ബഫറിന്റെ - LSTM, പ്രവര്\u200dത്തനങ്ങള്\u200d 'LSTM എന്\u200d All LSTMs use continuous dense feature vectors (embeddings) as an input.  ട്രാന്\u200dസിപ്ഷനുകള്\u200d അടിസ്ഥാനമായി അടിസ്ഥാനപ്പെടുത്തിയ ഈ വൃക്ഷത്തെ RNN പുതുക്കുന്നു. ഞങ്ങള്\u200d കാണിക്കുന്നത് നമ്മുടെ മോഡല്\u200d കുറഞ്ഞ വിഭവഭാഷകളുമായി പ്രകടനം മുന്\u200dകൂട്ടുന്നതാണെന്നാണ്. കെപാര്\u200dസ് ടീമായിട്ടാണ് ഞങ്ങള്\u200d കോണ്\u200dഎല്\u200d 2018ല്\u200d പങ്കെടുത്ത കാര്യങ്ങളില്\u200d പങ്കുചേര്\u200dക്കുന്നത്. ലാസില്\u200d 16th, ബിലാസിലും ബിലെക്സിലും 15 മെറ്റിക്സിലും ഞങ്ങള്\u200d പ", 'mt': "Aħna nintroduċu l-LSTM tas-siġar għall-mudell tal-istat ta’ analizzatur ibbażat fuq tranżizzjoni b’netwerks newrali rikorrenti. L-LSTM tal-pil tas-siġar ma juża l-ebda karatteristika bbażata fuq is-siġar tal-analizzazzjoni jew maħduma bl-idejn, iżda tagħmel aħjar minn mudelli b’dawn il-karatteristiċi. Aħna niżviluppaw ukoll sett ġdid ta' inkorporazzjonijiet minn karatteristiċi mhux ipproċessati biex itejbu l-prestazzjoni. Hemm 4 komponenti ewlenin ta’ dan il-mudell: stack’s -LSTM, buffer’s -LSTM, actions’ LSTM u tree-RNN. L-LSTMs kollha jużaw vetturi b’karatteristiċi densi kontinwi (inkorporazzjonijiet) bħala input. L-RNN tas-siġar jaġġorna dawn l-inkorporazzjonijiet ibbażati fuq tranżizzjonijiet. Aħna nuru li l-mudell tagħna jtejjeb il-prestazzjoni b’lingwi b’riżorsi baxxi meta mqabbel mal-preċedenti tiegħu. Aħna qed jipparteċipaw f'CoNLL 2018 UD Shared Task bħala t-tim ta' 'KParse' u kklassifikajna s-16-il fil-LAS, il-15-il fil-metriċi BLAS u BLEX, ta' 27 parteċipant li janalizzaw 82 sett ta' testijiet minn 57 lingwa.", 'ms': "Kami perkenalkan LSTM tumpukan pepohon ke keadaan model penghurai berasaskan transisi dengan rangkaian saraf berulang. LSTM tumpukan-pokok tidak menggunakan sebarang ciri-ciri asas pokok hurai atau buatan-tangan, tetapi berjalan lebih baik daripada model dengan ciri-ciri ini. We also develop new set of embeddings from raw features to enhance the performance.  Terdapat 4 komponen utama bagi model ini: stack ' -LSTM', penimbal ' -LSTM, tindakan' LSTM dan tree-RNN. Semua LSTM menggunakan vektor fitur padat terus menerus (penyembedding) sebagai input. Name Kami menunjukkan bahawa model kami meningkatkan prestasi dengan bahasa sumber rendah dibandingkan dengan terdahulu. Kami berpartisipasi dalam CoNLL 2018 UD Shared Task sebagai pasukan 'KParse' dan berturut-turut ke-16 dalam LAS, ke-15 dalam BLAS dan BLEX metrik, dari 27 peserta menghurai 82 set ujian dari 57 bahasa.", 'no': 'Vi introduserer tråstack LSTM til modelltilstanden til ein oversikningsbasert tolkar med gjentakelige neuralnettverk. Trestack LSTM brukar ikkje nokon tolkettre basert eller håndkopla funksjonar, men utfører likevel bedre enn modeller med desse funksjonane. Vi utviklar også nye innbyggingssett frå råeigenskapar for å forbetra utviklinga. Det finst 4 hovudkomponentar av denne modellen: Stakken - LSTM, bufferen - LSTM, handlingar LSTM og tre- RNN. Alle LSTMs brukar kontinuerlege tette funksjonsvektorar (innebygdar) som ein inndata. Tre- RNN oppdaterer desse innbyggingane basert på overgangar. Vi viser at modellen vårt forbetrar utviklinga med låg ressursspråk sammenlignet med dei førehandsarane. Vi deltar i CoNLL 2018 UD-delt oppgåve som gruppa « KParse » og rankerte 16. i LAS, 15. i BLAS og BLEX-metrika, av 27 deltakarar som tolkar 82 testsett frå 57 språk.', 'mn': "Бид мод-стек LSTM-г дахин сэтгэл мэдрэлийн сүлжээний загварын загвар дээр танилцуулдаг. Мод-стек LSTM нь ямар ч хуваалцааны мод, гар бүтээгдэхүүнээс илүүг ашиглахгүй. Гэхдээ эдгээр тодорхойлолтуудыг загвараас илүү сайн хийдэг. Мөн бид үүнийг илүү сайжруулахын тулд шинэ хэмжээсүүдийг хөгжүүлдэг. Энэ загварын 4 гол компонент байдаг: stack's -LSTM, buffer's -LSTM, actions' LSTM and tree-RNN. Бүх LSTMs нь үргэлжилсэн жингийн товчтой векторуудыг (интербингүүд) оруулах гэж ашигладаг. Мод-РНХ шилжилт дээр үндсэн эдгээр орнуудыг шинэчлүүлдэг. Бидний загвар нь өмнөх хүмүүстэй харьцуулахад бага боловсролын хэл дээр ажиллагааг сайжруулдаг. Бид 2018 оны CoNLL UD хуваалтын ажиллагаанд 'KParse' баг болсон бөгөөд LAS-ын 16-нд, BLAS-ын 15-нд, BLEX-ын метрикийн 15-нд оролцсон бөгөөд 27 оролцогчдын 57 хэлний 82 тестийн хуваалтыг хуваалцаж байсан.", 'pl': "Wprowadzamy stos drzew LSTM do modelowania stanu parsera opartego na przejściu z powtarzającymi się sieciami neuronowymi. LSTM nie używa żadnych funkcji opartych na drzewie parsowaniu ani ręcznie wykonywanych, ale działa lepiej niż modele z tymi funkcjami. Opracowujemy również nowy zestaw osadzeń z surowych funkcji, aby zwiększyć wydajność. Istnieją cztery główne składniki tego modelu: stos -LSTM, bufor -LSTM, actions' LSTM i drzewo-RNN. Wszystkie LSTMy używają ciągłych gęstych wektorów cech (osadzeń) jako wejścia. Drzewo-RNN aktualizuje te osadzenia w oparciu o przejścia. Pokazujemy, że nasz model poprawia wydajność przy użyciu języków niskich zasobów w porównaniu z poprzednikami. Uczestniczymy w CoNLL 2018 UD Shared Task jako zespół KParse i zajęliśmy się szesnastym miejscem w LAS, 15-tym w metrykach BLAS i BLEX, 27-tym uczestników parsujących 82 zestawy testów z 57 języków.", 'ro': "Introducem LSTM arbore-stack pentru a modela starea unui parser bazat pe tranziție cu rețele neurale recurente. Tree-stack LSTM nu folosește caracteristici bazate pe arbori de parse sau lucrate manual, dar performează mai bine decât modelele cu aceste caracteristici. De asemenea, dezvoltăm un nou set de încorporări din caracteristici brute pentru a îmbunătăți performanța. Există 4 componente principale ale acestui model: stack's -LSTM, buffer's -LSTM, actions' LSTM și tree-RNN. Toate LSTMs folosesc vectori de caracteristici dense continue (încorporări) ca intrare. Tree-RNN actualizează aceste încorporări pe baza tranzițiilor. Aratăm că modelul nostru îmbunătățește performanța cu limbaje cu resurse reduse în comparație cu predecesorii săi. Participăm la CoNLL 2018 UD Shared Task ca echipă 'KParse' și ocupăm locul 16 în LAS, al 15-lea în clasamentul BLAS și BLEX metrics, cu 27 de participanți analizând 82 seturi de teste din 57 de limbi.", 'so': "Waxaynu soo bandhignaynaa geed-stack LSTM si aan u sameyno xaalada soo wareegista oo lagu soo bandhigi karo shabakado neurada ah oo soo socda. Tree-stack LSTM ma isticmaalo geed baarlamadu ku saleysan ama tayooyin ay gacanta ku shaqeeyaan, laakiin wuxuu sameynaa tusaalooyin ka wanaagsan qaabilsan. Sidoo kale waxaynu horumarinaa koob cusub oo ka mid ah tababaro xunxun si aan u korinno tababarka. There are 4 main components of this model: stack's  -LSTM, buffer's  -LSTM, actions' LSTM and tree-RNN.  Dhammaan LSTMs waxay u isticmaalaan vectors deegaan (embeddings) sida input. Geedka-RNN ayaa cusboonaysiiya embeddingadan ku saleysan baaritaanka. Waxaynu muujinnaa in muusikadeenna horumarinta muuqashada iyo afafka hoose ee noocyada nololeed ee la barbarto kuwii hore. Waxaannu ka qeybqaadannaa CoNLL 2018 UD Shaqada loo sharciyey kooxda 'KParse' waxaana ka qeybqaadanay 16aad oo LAS, 15aad oo BLAS iyo BLEX metrics, 27 ka mid ah kuwa ka shaqeeya jardiinada 82 jirrabaadka oo ka qoraya 57 luuqadood.", 'sv': 'Vi introducerar tree-stack LSTM för att modellera tillstånd för en övergångsbaserad parser med återkommande neurala nätverk. Tree-stack LSTM använder inga parse tree-baserade eller handgjorda funktioner, men presterar bättre än modeller med dessa funktioner. Vi utvecklar också nya inbäddningar från råa funktioner för att förbättra prestandan. Det finns fyra huvudkomponenter i denna modell: stackens -LSTM, buffertens -LSTM, handlingens LSTM och tree-RNN. Alla LSTMs använder kontinuerliga täta funktionsvektorer (inbäddningar) som indata. Tree-RNN uppdaterar dessa inbäddningar baserat på övergångar. Vi visar att vår modell förbättrar prestandan med språk med låg resurs jämfört med sina föregångare. Vi deltar i CoNLL 2018 UD Shared Task som KParse-teamet och rankas 16:e i LAS, 15:e i BLAS- och BLEX-mätningar, med 27 deltagare som analyserar 82 testuppsättningar från 57 språk.', 'ta': "We introduce tree-stack LSTM to model state of a transition based parser with recurrent neural networks.  Tree- stack LSTM எந்த பகுதி மரத்தை அடிப்படையில் அல்லது கையில் கையாளும் பண்புகளை பயன்படுத்தாது, ஆனால் இந்த பண்புகளை விட மாதிரிகளை சிறந் நாம் செயல்பாட்டை மேம்படுத்துவதற்காக புதிய குணங்களை உருவாக்குகிறோம். இந்த மாதிரியின் 4 முக்கிய பகுதிகள் உள்ளன: stack's -LSTM, buffer's -LSTM, actions' LSTM மற்றும் tree- RNN. எல்லா LSTMs தொடர்ந்து உள்ளீடு மரம்- RNN மாற்றங்களை அடிப்படையாக இந்த உள்ளடக்கங்களை புதுப்பிக்கிறது. முன்னோர்களுடன் ஒப்பிடும் குறைந்த மூலத்தின் மொழிகளுடன் எங்கள் மாதிரி செயல்பாட்டை மேம்படுத்துகிறது  நாங்கள் கோன்எல் 2018ல் கேபார்ஸ் குழுவில் பங்கிடப்பட்ட பணியில் பங்கிடுகிறோம் மற்றும் ஏஸில் 16வது, பிலாஸ் மற்றும் பிலெக்ஸ் மெட்ரிக்களில் 15வது, 57 மொழி", 'si': "අපි ට්\u200dරි-ස්ටැක් LSTM වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක විශේෂකයෙන් ප්\u200dරතික්\u200dරියාත්මක විශේෂකයෙන් ප්\u200dර ට්\u200dරි- ස්ටැක් LSTM විශේෂණ ගස් අධාරිත නැහැ නැහැ නැහැ නැහැ නැහැ නැහැ අත් කරුණු විශේෂතාවක් නැහැ, ඒ අපි අළුත් සම්පූර්ණයක් සම්පූර්ණය කරනවා ක්\u200dරියාත්මක වැඩ කරන්න. මේ මොඩල් එකේ ප්\u200dරධාන කොටස් 4ක් තියෙනවා: ස්ටෑක්ගේ - LSTM, බාෆර්ගේ - LSTM, ක්\u200dරියාවන්ගේ LSTM සහ tree- RNN. සියළු LSTMs පාවිච්චි කරන්න පුළුවන් වෙක්ටර්ස් වෙක්ටර්ස් වලින්. Tree- RNN මේ ඇම්බෙන්ඩින්ග් අවස්ථාවන් කරන්න පුළුවන්. අපි පෙන්වන්නේ අපේ මොඩේල් එක්ක ප්\u200dරශ්නයක් අඩුම භාෂාවත් අඩුම භාෂාවත් වැඩ කරනවා කියලා ප්\u200d අපි CoNLL 2018 UD කොටස් එක්ක 'KParse' කණ්ඩායම විදියට සම්බන්ධ වෙලා තියෙන්නේ, LAS එක්ක 16වෙනි ප්\u200dරධාන විදියට, BLAS සහ BLex මෙට්\u200dරික්ස් එක්ක 15වෙනි සම්", 'sr': 'Predstavljamo LSTM stablu drveta na model stanja prelaznog analizatora sa rekonstruiranim neuralnim mrežama. LSTM ne koristi nikakve analiziranje drveta na osnovu ili na rukama, ali čini bolje od modela sa ovim karakteristikama. Takoðe razvijamo novi set integracija iz sirovih karakteristika kako bi poboljšali performancu. Postoje 4 glavne komponente ovog modela - LSTM, buferova - LSTM, akcija LSTM i drvo-RNN. Svi LSTMs koriste stalne gustne funkcije vektore (ugrađenje) kao ulaz. Drvo-RNN objavljuje ove integracije na osnovu prijenosa. Pokazujemo da naš model poboljšava izvodnju sa niskim jezicima resursa u usporedbi sa svojim prethodnicima. Učestvovali smo u CoNLL 2018 UD zajednièkom zadatku kao tim "KParse" i zvali 16. u LAS-u, 15. u BLAS-u i BLEX-u metriku, od 27 učesnika koji parsaju 82 testova iz 57 jezika.', 'ur': 'ہم نے درخت استک LSTM کو دوبارہ نئورل نیٹورک کے ساتھ ایک ٹرنسیٹ کے بنیاد پارچر کی موڈل کے لئے پیش آئیں۔ Tree-stack LSTM نے کسی پارس درخت کو نہ استعمال کرتا ہے جو بنیاد ہے یا ہاتھ-کرفٹ کے فرصت ہیں، مگر یہ فرصت کے ساتھ مدل سے بہتر عمل کرتا ہے. ہم نے بھی نئی مہربانی کا مجموعہ پیدا کیا ہے کہ عملکرد کو اضافہ کرنے کے لئے۔ اس موڈل کی 4 اصلی قسمتیں ہیں: استک کی -LSTM، بافر کی -LSTM، عمل کی LSTM اور درخت-RNN. All LSTMs use continuous dense feature vectors (embedding) as an input. درخت RNN ان ایمبڈینگ کو تغییرات پر بنیاد رکھتا ہے۔ ہم نشان دیتے ہیں کہ ہماری مدل کم سرمایہ کی زبانوں کے ساتھ عمل کو بہتر کر دیتا ہے۔ ہم CONLL 2018 UD Shared Task میں شامل ہوتے ہیں "KParse" تیم کے طور پر اور LAS میں 16م رقم رکھتے ہیں، BLAS اور BLEX متریک میں 15م رقم رکھتے ہیں، 27 مشرکین میں سے 57 زبانوں سے 82 تست سٹ پارس کرتے ہیں.', 'vi': 'Chúng tôi giới thiệu LSTM cây chồng để mô hình của một nhà phân tách chuyển đổi với các mạng thần kinh liên tục. Tree- stack LSD không dùng các tính năng căn cứ cây cha hay tay tạo, nhưng thực hiện tốt hơn các mẫu với các tính năng này. Chúng tôi cũng phát triển những sự nhúng mới từ các tính năng thô để nâng cao khả năng. Có bốn thành phần chính của mô hình này: chồng\'s LSTM, đệm-LSTM, Actions\'LSTM and tree-RNN. Tất cả các cử tri (LSTM) dùng liên tục đóng đặc trưng (thêm) làm nhập. Cây-RNN cập nhật những sự nối này dựa trên sự chuyển đổi. Chúng tôi cho rằng một cách tốt đẹp bằng ngôn ngữ với đàn nguyên của nó so với những gã trước. Chúng tôi tham gia CLB này thuộc dạng "KPass" và xếp hạng năm đầu ở LAS, 15m trong âm RLAS và LEX metrics, của chấp nhận sự phân tích 82 từ 57 languages.', 'uz': "@ info: whatsthis Name Biz tashkilotni oshirish uchun yangi tashkilotlarni yaratishmiz. There are 4 main components of this model: stack's  -LSTM, buffer's  -LSTM, actions' LSTM and tree-RNN.  @ info: whatsthis Name Biz modelimizni oldingizdan birinchi narsalar bilan bir necha manbalar bilan bajarishimizni ko'rsatamiz. 2018 yilda, KParse guruhi bo'lgan vazifalarga murojaat qilamiz va 57 tillardan 82 sinov satrlarni birlashtirish uchun LAS, BLAS va BLEX metriklarida 16 chi qismini boshlamiz.", 'bg': 'Въвеждаме дърво-стек LSTM за моделиране на състояние на преходен базиран анализатор с повтарящи се невронни мрежи. Не използва никакви функции, базирани на дърва или ръчно изработени, но се представя по-добре от моделите с тези функции. Също така разработваме нов набор от вграждания от сурови функции, за да подобрим производителността. Има 4 основни компонента на този модел: стак-ЛСТМ, буфер-ЛСТМ, действия ЛСТМ и дърво-RNN. Всички ЛСТМ използват непрекъснати вектори на плътни функции (вграждания) като вход. Дърво-актуализира тези вграждания въз основа на преходи. Показваме, че нашият модел подобрява производителността с езици с ниски ресурси в сравнение с предшествениците си. Участваме в Споделената задача като екип и се класирахме на 16-то място в класацията на МЛАС, 15-то по показатели от 27 участници, анализиращи 82 теста от 57 езика.', 'hr': "Predstavljamo stablu LSTM na model stanja prelaznog analizatora s rekonstruiranim neuralnim mrežama. LSTM ne koristi nikakve analiziranje drveta na temelju ili na rukama, ali čini bolje od modela s ovim karakteristikama. Također razvijamo novi set integracija iz sirovih karakteristika kako bi poboljšali učinkovitost. Postoje 4 glavne komponente ovog modela: stakla - LSTM, buferova - LSTM, akcija LSTM i drvo-RNN. Svi LSTMs koriste stalne gustne funkcije vektore (ugrađenje) kao ulaz. Drvo-RNN aktualizira ove ugrađenje na temelju prijenosa. Pokazujemo da naš model poboljšava učinkovitost s niskim jezicima resursa u usporedbi s prethodnicima. Učestvovali smo u CoNLL 2018 UD zajedničkom zadatku kao ekipu 'KParse' i učestvovali su 16. u LAS-u, 15. u BLAS-u i BLEX-u metriku, od 27 učesnika koji parsaju 82 testova iz 57 jezika.", 'da': "Vi introducerer træstak LSTM til modellering af tilstanden af en overgangsbaseret parser med tilbagevendende neurale netværk. Tree-stack LSTM bruger ikke nogen parse træ baserede eller håndlavede funktioner, men yder bedre end modeller med disse funktioner. Vi udvikler også nye sæt af indlejringer fra rå funktioner for at forbedre ydeevnen. Der er 4 hovedkomponenter i denne model: stakkens -LSTM, bufferens -LSTM, handlingernes LSTM og træ-RNN. Alle LSTMs bruger kontinuerlige tætte funktionsvektorer (indlejringer) som input. Tree-RNN opdaterer disse indlejringer baseret på overgange. Vi viser, at vores model forbedrer ydeevnen med sprog med lave ressourcer sammenlignet med sine forgængere. Vi deltager i CoNLL 2018 UD Shared Task som 'KParse'-holdet og rangerer 16. i LAS, 15. i BLAS og BLEX metrics, hvor 27 deltagere analyserer 82 testsæt fra 57 sprog.", 'nl': "We introduceren tree-stack LSTM om de status van een transitie gebaseerde parser met terugkerende neurale netwerken te modelleren. Tree-stack LSTM maakt geen gebruik van parse tree gebaseerde of handgemaakte functies, maar presteert beter dan modellen met deze functies. We ontwikkelen ook nieuwe set embeddings van ruwe functies om de prestaties te verbeteren. Er zijn vier hoofdcomponenten van dit model: stack's -LSTM, buffer's -LSTM, actions' LSTM en tree-RNN. Alle LSTMs gebruiken continue dichte kenmerkvectoren (embeddings) als input. Tree-RNN werkt deze insluitingen bij op basis van overgangen. We laten zien dat ons model de prestaties verbetert met talen met weinig resources in vergelijking met zijn voorgangers. We nemen deel aan CoNLL 2018 UD Shared Task als het 'KParse' team en zijn 16e gerangschikt in LAS, 15e in BLAS en BLEX metrics, van 27 deelnemers die 82 testsets uit 57 talen parsen.", 'de': "Wir führen Tree-Stack LSTM ein, um den Zustand eines transitionsbasierten Parsers mit wiederkehrenden neuronalen Netzen zu modellieren. Tree-Stack LSTM verwendet keine Parse-Tree-basierten oder handgefertigten Funktionen, schneidet jedoch besser ab als Modelle mit diesen Funktionen. Wir entwickeln auch neue Einbettungen aus Rohfunktionen, um die Leistung zu verbessern. Es gibt vier Hauptkomponenten dieses Modells: stack's -LSTM, buffer's -LSTM, actions' LSTM und tree-RNN. Alle LSTMs verwenden kontinuierliche dichte Feature Vektoren (Einbettungen) als Eingang. Tree-RNN aktualisiert diese Einbettungen basierend auf Übergängen. Wir zeigen, dass unser Modell die Leistung mit ressourcenarmen Sprachen im Vergleich zu seinen Vorgängern verbessert. Wir nehmen als KParse-Team an CoNLL 2018 UD Shared Task teil und belegten den 16ten Platz in LAS, 15ten in BLAS- und BLEX-Metriken, von 27-Teilnehmern, die 82-Testsets aus 57-Sprachen parsen.", 'id': "Kami memperkenalkan LSTM tumpukan pohon ke kondisi model dari parser berdasarkan transisi dengan jaringan saraf rekuren. LSTM tumpukan pohon tidak menggunakan apa-apa parse pohon berdasarkan atau karakteristik buatan tangan, namun berhasil lebih baik dari model dengan karakteristik-karakteristik ini. Kami juga mengembangkan set baru embedding dari fitur mentah untuk meningkatkan prestasi. Ada 4 komponen utama dari model ini: stack -LSTM, buffer -LSTM, action 'LSTM dan tree-RNN. Semua LSTM menggunakan vektor fitur padat terus menerus (embeddings) sebagai input. Tree-RNN memperbaharui penerbangan ini berdasarkan transisi. Kami menunjukkan bahwa model kami meningkatkan prestasi dengan bahasa sumber daya rendah dibandingkan dengan sebelumnya. Kami berpartisipasi di CoNLL 2018 UD Shared Task sebagai tim 'KParse' dan tertinggi ke-16 di LAS, ke-15 di BLAS dan BLEX metrik, dari 27 peserta menghindari 82 set tes dari 57 bahasa.", 'ko': "트리 스택 LSTM을 도입하여 변환 기반 파서의 상태를 반복 신경 네트워크로 모델링합니다.트리 스택 LSTM은 분석 트리를 기반으로 하거나 수동으로 만드는 기능은 사용하지 않지만 이러한 기능이 있는 모델보다 성능이 우수합니다.우리는 성능을 향상시키기 위해 원시적인 특징에 따라 새로운 삽입을 개발했다.이 모델에는 스택의 - LSTM, 버퍼의 - LSTM, 조작의 LSTM 및 트리 RNN 등 네 가지 주요 어셈블리가 있습니다.모든 LSTM은 연속 밀집 피쳐 벡터(내장)를 입력으로 사용합니다.트리 RNN은 변환을 기반으로 이러한 포함을 업데이트합니다.우리는 이전 모델에 비해 우리 모델이 저자원 언어를 사용할 때 성능을 향상시켰다는 것을 보여준다.코넬 2018 UD 공유 임무에는'KParse'팀으로 참여해 LAS 16위, BLAS·BLEX 메트릭 15위 등 총 27명의 참가자가 57개 언어의 82개 테스트집을 분석했다.", 'fa': 'ما LSTM را به موقعیت مدل انتقال با شبکه\u200cهای عصبی دوباره معرفی می\u200cکنیم. LSTM درخت استفاده از هیچ درختی که بر اساس درخت تقسیم یا ویژگی\u200cهای دستی ساخته شده استفاده نمی\u200cکند، ولی هنوز بهتر از مدل\u200cها با این ویژگی انجام می\u200cدهد. ما همچنین مجموعه جدیدی از شرکت\u200cهایی از ویژه\u200cهای خالی برای افزایش عملکرد توسعه می\u200cکنیم. چهار بخش اصلی از این مدل وجود دارد: LSTM - LSTM ، بوفر ، LSTM ، عمل LSTM و درخت- RNN. همۀ LSTMs از ویکتورهای ویکتورهای متفاوت دائمی (دائمی) به عنوان ورودی استفاده می\u200cکنند. درخت RNN این وسیله\u200cها را بر اساس تغییرات تبدیل می\u200cکند. ما نشان می دهیم که مدل ما با زبانهای منابع کم در مقایسه با پیشینیان آن بهتر است. ما به عنوان تیم KParse در CoNLL 2018 شرکت می\u200cکنیم و ۱۶م در LAS، ۱۵م در BLAS و BLEX متریک، از ۲۷ شرکت کنندگان که مجموعه آزمایش 82 را از ۷۷ زبان تقسیم می\u200cکنند.', 'sq': "Ne paraqesim LSTM-kope pemësh në modelin e gjendjes së një analizuesi të bazuar në tranzicion me rrjete neurale të përsëritura. LSTM-stack druri nuk përdor asnjë elementë bazuar në pemë analizimi apo të ndërtuar me dorë, por performon më mirë se modelet me këto elemente. Ne gjithashtu zhvillojmë një grup të ri të përfshirjeve nga karakteristikat e papërpunuara për të përmirësuar performancën. Ka 4 komponente kryesore të këtij modeli: stack's -LSTM, buffer's -LSTM, actions' LSTM and tree-RNN. Të gjithë LSTMs përdorin vektorë të vazhdueshëm të dendura (të përfshira) si një hyrje. Tree-RNN updates these embeddings based on transitions.  Ne tregojmë se modeli ynë përmirëson performancën me gjuhë të ulëta burimesh krahasuar me paraardhësit e tij. Ne marrim pjesë në CoNLL 2018 UD Shared Task si ekip 'KParse' dhe u renditëm i 16-ti në LAS, i 15-ti në BLAS dhe BLEX metrika, nga 27 pjesëmarrës që analizuan 82 set testimi nga 57 gjuhë.", 'sw': "Tunawasilisha LSTM kwa ajili ya kutengeneza hali ya mabadiliko yenye msingi wa mpito kwa mitandao ya kisasa yanayoendelea. LSTM anatumia mti usio na mti wa bunge au vipengele vya mikono, lakini hufanya vizuri kuliko mifano yenye tabia hizi. Tunaweza pia kutengeneza mfumo mpya wa mapambano kutoka kwenye vipengele vibaya ili kuongeza utendaji. Kuna vipengele nne muhimu vya mtindo huu: stack's -LSTM, buffer's -LSTM, actions' LSTM na mti-RNN. Wasomi wote wa LSTMs hutumia vectors that continues to dense features (embedded) as an input. Mti-RNN anatupya habari hizi zinazotokana na misitu. We show that our model improves performance with low resource languages compared with its predecessors.  Tumeshiriki katika kampuni ya CoNLL 2018 UD ilishiriki kazi kama timu ya 'KParse' na kuanzia rangi ya 16 nchini LAS, mitindo 15 ya BLAS na BLEX, miongoni mwa washiriki 27 wakiimba vituo 82 vya majaribio kutoka lugha 57.", 'af': "Ons introduseer boom- stack LSTM na model staat van 'n transisie gebaseerde parser met herhaalde neuralnetwerke. Boom- stack LSTM gebruik nie enige verwerking boom gebaseer of hand- crafted funksies nie, maar doen nog beter as modele met hierdie funksies. Ons ontwikkel ook nuwe stel inbêding van reë funksies om die prestasie te verbeter. Daar is 4 hoofkomponente van hierdie model: stack se - LSTM, buffer s se - LSTM, aksies' LSTM en boom- RNN. Alle LSTMs gebruik voortdurende dens funksie vektore (inbêding) as 'n invoer. Boom- RNN opdateer hierdie inbêdings gebaseer op oordragte. Ons wys dat ons model met lae hulpbron tale vergelyk word met sy voorkomste. Ons deel in CoNLL 2018 UD Gedeelde Opdrag as die 'KParse' span en rangeer 16de in Las, 15de in BLAS en BLEX metries, van 27 deelnimmers ontlees 82 toets stel van 57 tale.", 'tr': "Biz agaç staci LSTM'i tekrarly näral a ýtlary bilen geçişik taýýarlançylaryň durumyna görkezip Agat staci LSTM hiç hili tansçylyk agaçyny ullamýar. Şu tansçylyklar bilen nusgalardan has gowurak işleýär. Biz hem çyz özelliklerinden täze köpürler geliştirip performansy bejermek üçin. Bu nusganyň 4 sany esasy bölekleri bar: stacklaryň -LSTM, bufferlaryň -LSTM, emelleriň LSTM we agaç-RNN. Ehli LSTM sürekli giç wajyplary bir giriş şeklinde ullan %s-iň üýtgewleri üstine daýanýar. Biziň nusgymyzyň öňki adamlary bilen görä düşük ressurs dilleri bilen täsirleýändigini görkezýäris. Biz CoNLL 2018 UD toparyna 'KParse' toparyna 'LAS'da 16-nji döwürildik we BLAS we BLEX metriklerinde 15-nji döwürildik, 57 dilinden 82 synat düzümlerini paýlaşýarlar.", 'am': "የዛፍ-stack ዛፍ-stack We also develop new set of embeddings from raw features to enhance the performance.  የዚህ ሞዴል 4 የዋነኛው ክፍሎች አሉ: Stack's -LSTM, buffer's -LSTM, action's LSTM and tree-RNN. የLST ምርጫዎች የዛፍ-RNN በመጠቀም ላይ እነዚህን አካባቢዎች ያሻራል። ምሳሌያችን ከቀደሙት ሰዎች ጋር እንደተካፈለ ከታናሽ የኩነቶች ቋንቋዎች ጋር የሚያሳድገውን እናሳያቸዋለን፡፡ በ 2018 ኮንLL እና ዲ ስራዎችን ከ57 ቋንቋዎች 82 ተፈተና መስመር ማዘጋጀት የሚችሉትን 27 ተጋሪዎች በLAS፣ 15ኛው በBLAS እና በቢሌX ሜትሪክ ላይ ተጋርተናል፡፡", 'hy': 'We introduce tree-stack LSTM to model state of a transition based parser with recurrent neural networks.  Tree-stack LSTM does not use any parse tree based or hand-crafted features, yet performs better than models with these features.  We also develop new set of embeddings from raw features to enhance the performance.  Այս մոդելի չորս հիմնական բաղադրիչներ կան. կույտը -LSMT է, կույտը -LSMT, գործողությունները\' LSMT և ծառի-ARN: Բոլոր LSMT-ները շարունակական խտության հատկությունների վեկտորներ են օգտագործում որպես ներմուծք: Փայրի ՌՆԹ-ը վերականգնում է այս ներդրումները, հիմնված տեղափոխությունների վրա: Մենք ցույց ենք տալիս, որ մեր մոդելը բարելավում է արդյունքը ցածր ռեսուրսների լեզուներով, համեմատած նախորդների հետ: Մենք մասնակցում ենք 2018 թվականի CONAL-ի UD-ի կիսված առաջադրանքին որպես "ԿՊարզ" թիմ և 16-րդ դասակարգված ենք ԼԱՍ-ում, 15-րդ\' ԲԼԱՍ-ում և Բլեքս-ում, 27 մասնակիցներից, ովքեր վերլուծում են 82 փորձարկումներ 57 լեզուներից:', 'bn': "পুনরায় নিউরেল নেটওয়ার্কের মাধ্যমে আমরা গাছ-স্ট্যাক এলএসএমকে পরিচয় করিয়ে দিচ্ছি। Tree-stack LSTM does not use any parse tree based or hand-crafted features, yet performs better than models with these features.  এছাড়াও আমরা নতুন কিছু বিভিন্ন বিভিন্ন প্রতিষ্ঠান তৈরি করি প্রদর্শনের ক্ষেত্রে প্রদর্শন করার জন্য। এই মডেলের চার প্রধান অংশ রয়েছে: স্ট্যাকের -এলস্টিএম, বাফারের -LSTM, কাজ এলসিএম এবং গাছ-RNN। সকল LSTMs ব্যবহার করে অব্যহত গভীর বৈশিষ্ট্যাবলী ভেক্টর (ইনপুট) হিসেবে ব্যবহার করে। ট্রি-RNN ট্রান্সপ্রান্সিডেন্ট ভিত্তিক এই প্রতিযোগিতাগুলো আপডেট করেছে। আমরা দেখাচ্ছি যে আমাদের মডেল তাদের পূর্ববর্তীদের সাথে তুলনা করে নিম্ন রিসোর্স ভাষার সাথে নিম্ন ভাষা আমরা কনএল ২০১৮ সালে অংশগ্রহণ করি কেপার্স টিম হিসেবে 'কেপার্স' টাকা হিসেবে এবং ৫৭ ভাষায় ২৭ জন অংশগ্রহণকারীদের মধ্যে বিলেক্স এবং বিলেক্স মেট্রিকে ১৬", 'ca': "Introduïm LSTM de pila d'arbres a un estat model d'un analitzador basat en transició amb xarxes neurals recurrents. LSTM de pila d'arbres no utilitza cap característica basada en arbres d'analització o artificial, però funciona millor que models amb aquestes característices. També desenvolupem un nou conjunt d'integracions a partir de característiques brutes per millorar el rendiment. Hi ha 4 components principals d'aquest model: LSTM de pila, LSTM de buffer, LSTM d'accions i RNN d'arbre. Tots els LSTMs utilitzen vectors de característiques denses continus com a entrada. Tree-RNN updates these embeddings based on transitions.  Mostrem que el nostre model millora el rendiment amb llengües de baix recursos en comparació amb els seus predecessors. Participem en CoNLL 2018 UD Shared Task com l'equip de KParse i vam classificar-nos en 16è a LAS, 15è a BLAS i BLEX, de 27 participants analitzant 82 conjunts de proves de 57 llengües.", 'cs': "Představujeme strom-stack LSTM pro modelování stavu přechodového parseru s rekurentními neuronovými sítěmi. LSTM Tree-Stack nepoužívá žádné funkce založené na parsování stromu nebo ručně vytvořené, ale funguje lépe než modely s těmito funkcemi. Rovněž vyvíjíme novou sadu vložení ze surových funkcí pro zlepšení výkonu. Existují čtyři hlavní komponenty tohoto modelu: stack's -LSTM, buffer's -LSTM, actions' LSTM a tree-RNN. Všechny LSTMy používají jako vstup kontinuální husté funkční vektory (embeddings). Tree-RNN aktualizuje tato vložení na základě přechodů. Ukazujeme, že náš model zlepšuje výkon při jazycích s nízkými zdroji ve srovnání s předchůdci. Účastníme se CoNLL 2018 UD Shared Task jako tým KParse a místo šestnáctého v LAS, patnáctého v metrikách BLAS a BLEX 27 účastníků analyzujících 82 testovací sady z 57 jazyků.", 'bs': "Predstavljamo LSTM stablu drveta na modelu stanja prelaznog analizatora baziranog na transiciji sa rekonstruiranim neuralnim mrežama. LSTM ne koristi nikakve analiziranje drveta na temelju ili na rukama, ali čini bolje od modela s ovim karakteristikama. Također razvijemo novi set integracija iz sirovih karakteristika kako bi poboljšali performancu. Postoje 4 glavne komponente ovog modela: stakla -LSTM, buferova -LSTM, akcija LSTM i drvo-RNN. Svi LSTMs koriste stalne gustne funkcije vektore (ugrađenje) kao input. Drvo-RNN aktualizira ove integracije na temelju prelaza. Mi pokazujemo da naš model poboljšava izvođenje sa niskim jezicima resursa u usporedbi sa svojim prethodnicima. Učestvovali smo u CoNLL 2018 UD zajedničkom zadatku kao tim 'KParse' i učestvovali su 16. u LAS-u, 15. u metrici BLAS i BLEX-a, od 27 učesnika koji analiziraju 82 testova iz 57 jezika.", 'fi': "Esittelemme puupinon LSTM:n siirtymäpohjaisen parserin tilan mallintamiseen toistuvilla hermoverkoilla. Tree-stack LSTM ei käytä jäsennyspuupohjaisia tai käsin tehtyjä ominaisuuksia, mutta toimii kuitenkin paremmin kuin mallit, joissa on näitä ominaisuuksia. Kehitämme myös uusia upotuksia raakaominaisuuksista suorituskyvyn parantamiseksi. Mallissa on neljä pääkomponenttia: pinon -LSTM, puskurin -LSTM, actions' LSTM ja puu-RNN. Kaikki LSTMs käyttävät syötteenä jatkuvia tiheitä ominaisuuksia (upotuksia). Tree-RNN päivittää nämä upotukset siirtymän perusteella. Osoitamme, että mallimme parantaa suorituskykyä matalan resurssin kielillä verrattuna edeltäjiinsä. Osallistumme CoNLL 2018 UD Shared Taskiin KParse-tiiminä ja sijoittuimme LAS:ssa 16. sijalle, BLAS- ja BLEX-mittareissa 15. sijalle. 27 osallistujasta analysoi 82 testisarjaa 57 kieleltä.", 'et': "Tutvustame puuvirnast LSTM-i, et modelleerida üleminekupõhise parseri olekut korduvate närvivõrkudega. Puustack LSTM ei kasuta parsimispuudel põhinevaid või käsitsi valmistatud funktsioone, kuid toimib paremini kui nende funktsioonidega mudelid. Töötame välja ka uue komplekti manustamisi toorfunktsioonidest, et parandada jõudlust. Selles mudelis on neli peamist komponenti: stack's -LSTM, puhver's -LSTM, actions' LSTM ja puu-RNN. Kõik LSTMd kasutavad sisendina pidevaid tihedaid funktsioonivektoreid (manustamisi). Puu- RNN värskendab neid manustamisi üleminekute põhjal. Näitame, et meie mudel parandab jõudlust madala ressursiga keeltega võrreldes eelkäijatega. Osaleme CoNLL 2018 UD Shared Task'is KParse'i meeskonnana ning saime LAS-is 16. koha, BLAS- ja BLEX-mõõdikutes 15. koha, kus 27 osalejast parsisid 82 testikomplekti 57 keelest.", 'az': "Biz a ğac-stack LSTM'i yenidən nöral ağları ilə dəyişiklik məlumatının modeli şəkildə təşkil edirik. Ağaç-stack LSTM heç bir pars ağacını istifadə etməz, yaxud əl yaratdığı özellikləri istifadə etməz, amma bu özelliklər ilə modellərdən daha yaxşı işlər edir. Biz də həmçinin həmçinin həmçinin fəaliyyətlərindən yeni inşallar toplamışıq. Bu modelinin 4 ana komponenti var: stack's -LSTM, buffer's -LSTM, actions' LSTM and tree-RNN. Tüm LSTMs sürəkli yox xüsusiyyət vektörlərini giriş olaraq istifadə edir. Ağac-RNN bu inşalları dəyişdirir, dəyişikliklərə dayanan. Biz modellərimizin əvvəlkilərlə qarşılaşdığı düşük ressurs dilləri ilə performansımızı yaxşılaşdırır. Biz CoNLL 2018 UD paylaşılmış işə 'KParse' ekibi olaraq həmçin in LAS 15-ci ilə, BLAS və BLEX metriklərində 15-ci ilə, 57 dilindən 82 test setini ayırır.", 'ha': "Tuna ƙara wa-stack LSM don mu motsa halin mai shige da aka baka wani shirin transitional da aka sake marar da zanen tsarin neural. Tree-stack LstuM bai yi amfani da wani itãce na parse ko wasu tayari na hannayen-hannayen, kuma yana amfani da mafiya alhẽri daga misãlai da wannan zafi. Kayya, Munã ƙara sami masu samura na samura daga taskõki mai raɗawa dõmin ya ƙãre aikin. Aka ƙunsa da fire masu babban ayuka daga wannan motel: stack's -LTRM, buffet's -LTRM, aikin LSSM da itãce-RNN. @ info: whatsthis KCharselect unicode block name Tuna nũna cewa misalinmu yana improve performance da harshen masu rauni na resource sami da waɗanda suka gaba. Tuna raba cikin CoNLL 2018 UD Shared Taimar As the 'KParse' team and ranked 16th in L.S. the 15th in BLES and BLEX metrics, daga 27 mãsu shirin karatun 82 samãri daga 57 languages.", 'he': 'אנחנו מציגים LSTM עץ-ערימה למודל מצב של מעבד מבוסס מעבר עם רשתות עצביות חוזרות. LSTM עץ-ערימה לא משתמש בשום תכונות מבוססות על עץ מעבדה או יצירת ידיים, אך מבצע טוב יותר ממודלים עם תכונות אלה. אנחנו גם מפתחים קבוצה חדשה של תוכניות ממיוחדים חומרים כדי לשפר את ההופעה. There are 4 main components of this model: stack\'s  -LSTM, buffer\'s  -LSTM, actions\' LSTM and tree-RNN.  כל LSTMs משתמשים בוקטורים צפופים ממשיכים ככניסה. עץ-RNN מעדכן את התכניות האלה בהתבסס על העברות. אנחנו מראים שהמודל שלנו משפר ביצועים עם שפות משאבים נמוכות בהשוואה לקדמוניו. אנחנו משתתפים במשימה משותפת של CoNLL 2018 UD כצוות "KParse" והדרגנו ב-16 בלאס, ב-15 בלאס ומטריקה בלאקס, של 27 משתתפים המחקרים 82 קבוצות מבחן מ-57 שפות.', 'sk': "Za modeliranje stanja prehodnega razčlenjevalnika s ponavljajočimi se nevronskimi omrežji uvajamo drevesno-stack LSTM. Drevesni sklad LSTM ne uporablja nobenih funkcij razčlenitve drevesa ali ročno izdelanih funkcij, vendar je boljši od modelov s temi funkcijami. Razvijamo tudi nov nabor vdelav iz surovih funkcij za izboljšanje zmogljivosti. Obstajajo 4 glavne komponente tega modela: stack's -LSTM, buffer's -LSTM, actions' LSTM in dreve-RNN. Vsi LSTMs uporabljajo neprekinjene goste vektorje funkcij (vdelave) kot vhod. Tree-RNN posodablja te vdelave na podlagi prehodov. Pokazali smo, da naš model izboljšuje učinkovitost z jeziki z nizkimi viri v primerjavi s svojimi predhodniki. Sodelujemo v skupni nalogi CoNLL 2018 UD Shared Task kot ekipa KParse in se uvrščamo na 16. mesto v LAS, 15. v BLAS in BLEX metrikah, od 27 udeležencev pa je razčlenilo 82 testnih sklopov iz 57 jezikov.", 'bo': "ང་ཚོས་བརྗེད་མཁན་གྱི་དབྱིབས་ཤིག་སྡེབ་LSTM་ལ་ཚུལ་མཐུན་བཟོ་བའི་གནས་སྟངས་ལ་སྟོན་པ སྡོང་བོའི་དབྱིབས་ཁང་གི་LSTM་ཡིས་མིན་སྤྱོད་པས་རྩིས་བ་གཞི་ཡིན་པ་ཡང་ན་ལག་ཆོས་ཡིན་པའི་ཁྱད་ཆོས་སྤྱོད་མེད། དེ་ནའ ང་ཚོས་ཀྱང་རང་ཉིད་ཀྱིས་གཟུགས་རིས་ལ་སྒྲིག་འཛུགས་གསར་བ་ཞིག་གི་ཡར་རྒྱས་སྐྱོར་ཡོད། འདི་རྣམ་གྲངས་འདིའི་རྩ་བའི་ཆ་ཤས་༤་ཡོད་པ：stack's -LSTM, buffer's -LSTM, actions' LSTM དང་སྡོང་རིམ་-RNN All LSTMs use continuous dense feature vectors (embeddings) as an input. སྐྱེལ་སྤྱོད་གཞི་བརྟེན་ཏུ་སྡོང་བོའི་དབྱིབས་RNN་ནང་དུ་བཅུག་པ ང་ཚོས་མིག་གཟུགས་རིས་འདི་མ་ཟད་ཅིག་གི་སྔོན་པ་དང་མཉམ་དུ་རྒྱུ་དངོས་ཐོན་ཁུངས་ལ་ཉུང་བའི་སྐད་ We participate in CoNLL 2018 UD Shared Task as the 'KParse' team and ranked 16th in LAS, 15th in BLAS and BLEX metrics, of 27 participants parsing 82 test sets from 57 languages.", 'jv': 'string" in "context_BAR_stringLink Jaring-stak KST Awak dhéwé éntuk sistem sing dibutuhke aturan anyar tentang kanggo nggawe barang nggawe Sampeyan sing wis ngawe 4 kompon sing model iki: stabk\'s -LTT M, buffer\'s -LTT M, aksi\' LTT M lan pung -R All Validity Awak dhéwé ngerasakno ngono model sing nyebutaké nggawe barang langgar oleh dumadhi karo sing kudu nggawe barang kelas nang sira gerarané. Awak dhéwé nggawe barêng cara CoNLL Kamung, ning mulai \'KParase\' karo nganggo cara-cara sing 16 sampek ning LAS, tunika-keng liyane PART karo PART karo PART (sing wis nambah sabanjuré) sing sampek tanggal alam soko papat (sing titik sabanjuré) sing sampek awak dhéwé'}
{'en': 'SEx BiST : A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations', 'ar': 'SEx BiST: محلل متعدد المصادر قابل للتدريب مع تمثيلات معجمية سياقية عميقة', 'pt': 'SEx BiST: um analisador multi-fonte treinável com representações lexicais profundamente contextualizadas', 'fr': 'SeX BiST\xa0: un analyseur multisource pouvant être entraîné avec des représentations lexicales contextualisées profondes', 'es': 'SeX BiST: un analizador capacitable de múltiples fuentes con representaciones léxicas profundamente contextualizadas', 'ja': 'SEx BiST:深いコンテキスト化された語彙表現を備えたマルチソースのトレーニング可能なパーサー', 'zh': 'BiST 曰:上下文词汇多源训解析器', 'hi': 'SEx BiST: गहरी Contextualized लेक्सिकल प्रतिनिधित्व के साथ एक बहु स्रोत Trainable पार्सर', 'ru': 'SEx BiST: Многоисточникный Обучаемый Разборчик с Глубоко Контекстуализированными Лексическими Представлениями', 'ga': 'Gnéas BiST: Parsálaí Ilfhoinse Inaistrithe le Léirithe Foclaíochta Doimhneacha Comhthéacsúla', 'ka': 'SEx BiST: მრავალური წიგნის გასწავლებელი პანელიზატორი, რომელიც ძალიან კონტექსტუალური ლექსიკური გამოსახულებებით', 'hu': 'SEx BiST: Többforrású edzhető elemző mély kontextualizált lexikai ábrázolásokkal', 'it': 'SEx BiST: un parser multi-sorgente tracciabile con rappresentazioni lessicali contestualizzate profonde', 'lt': 'SEx BiST: daugialypis mokomas analizatorius su giliai kontekstualizuotais leksiniais atstovais', 'mk': 'SEx BiST: Мултиизворен трениран анализатор со длабоко контекстуални лексикални претставувања', 'el': 'Ένας εκπαιδευόμενος αναλυτής πολλαπλών πηγών με βαθιές περιεκτικές Lexical Representations', 'kk': 'SEx BiST: Көптеген көздерді оқыту мүмкіндігі теңіздеген теңізші', 'mn': 'SEx BiST: Олон эх үүсвэрийн суралцах боломжтой судлаач, гүн гүнзгий сэтгэл хөдлөлт', 'ml': 'സെക്സ് ബിസ്റ്റ്: ആഴത്തില്\u200d കൂടിച്ചേര്\u200dത്തിരിക്കുന്ന ലെക്സിക്കല്\u200d പ്രതിനിധികളോടൊപ്പം ഒരു അധിക സ്രോതസ്സ്', 'ms': 'SEx BiST: Penjana Latihan Berberapa Sumber dengan Perwakilan Lexik Berkonteks Dalam Dalam', 'mt': 'SEx BiST: Parser Taħriġ Multi-Sorsi b’Rappreżentazzjonijiet Lessiċi Kontekstwalizzati Profondi', 'no': 'SEx BiST: Eit fleirkjeldelærbar tolkar med dyp kontekstualiserte leksiske representasjonar', 'pl': 'SEx BiST: Multi-Source treningowy parser z głębokimi kontekstualnymi reprezentacjami leksykalnymi', 'ro': 'SEx BiST: Un Parser Trainabil Multi-Source cu reprezentari Lexicale Contextualizate profunde', 'sr': 'SEx BiST: Multi-Source Trainable Parser sa dubokim kontekstualiziranim leksičkim predstavljanjima', 'si': 'SEx BiST: ගොඩක් ප්\u200dරධාන ප්\u200dරධානය කරන්න පුළුවන් ප්\u200dරධානයක් සමග ග ගොඩක් ප්\u200dරධානයක් ලෙක්සිකාල ප්\u200dරධාන', 'ta': 'SEx பிஸ்ட்: ஆழமாக சூழலாக்கப்பட்ட லெக்சிகிய பிரதிநிபந்தனைகளுடன் ஒரு பல மூலம் பயிற்சியமுடியாத பகுதி', 'so': 'SEx BiST: A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations', 'sv': 'SEx BiST: En flerspråkig tolkning med djupa kontextualiserade Lexical representationer', 'ur': 'SEx BiST: ایک بہت سی-سرورز تطالب پارس جو عمیق کنٹکسٹیولیز لکسیکیسی روشنی کے ساتھ ہے', 'uz': 'SEx BiST: QPrintPreviewDialog', 'vi': 'SEx BiST: A multisource huấn luyện giả. với bộ truyền hình mạch chứa đựng kỹ thuật.', 'hr': 'SEx BiST: Multi-Source Trainable Parser sa dubokim kontekstualiziranim leksičkim predstavljanjem', 'bg': 'Секс БиСТ: Многоизточников тренировъчен анализ с дълбоки контекстуализирани лексикални представяния', 'da': 'SEx BiST: En multi-kilde træningsbar parser med dybe kontekstualiserede Lexical repræsentationer', 'de': 'SEx BiST: Ein Multi-Source Trainable Parser mit Deep Contextualized Lexical Representations', 'ko': 'SEx-Bist: 심층 어경화 어휘 표현을 가진 다원적 트레이닝 해석기', 'nl': 'SEx BiST: Een multi-source trainable parser met diepe contextualiseerde Lexical Representaties', 'fa': 'SEx BiST: یک پزشک متعدد منبع آموزشی قابل آموزش با نمایش\u200cهای جذابی عمیق متوسط', 'tr': 'SEx BiST: Derin Kontekstualized Lexical Temsiller ile Çoklu Kaynak Eğitimli Parser', 'sq': 'SEx BiST: Një analizues i trajnuar me burime të shumta me përfaqësime të thella të kontekstuara leksikale', 'id': 'SEx BiST: A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations', 'af': "SEx BiST: ' n Multi- Source Trainable Parser met Deep Contextualized Lexical Representations", 'sw': 'SEx BiST: Mbunge wa vyanzo vingi vinavyowezekana na Representative wa Kilexico', 'bn': 'সেক্স বিস্ট: লেক্সিক্সিকাল প্রতিনিধির সাথে একটি বহুসূত্র ট্রেনিয়াল পার্সার', 'az': 'SEx BiST: Deep Contextualized Lexical Representations', 'am': 'SEx BiST: A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations', 'cs': 'SEx BiST: Vícezdrojový trénovatelný parser s hlubokými kontextualizovanými Lexickými reprezentacemi', 'et': 'SEx BiST: mitmealliline treenitav parser sügavate kontekstualiseeritud leksiliste esitustega', 'fi': 'SEx BiST: Multi-Source Trainable Parser with Deep Contextualized Lexical Representations', 'hy': 'SEx', 'bs': 'SEx BiST: Multi-Source Trainable Parser sa dubokim kontekstualiziranim leksičkim predstavljanjem', 'ca': 'SEx BiST: Un analitzador capacitable de múltiples fonts amb representacions lècsiques profundament contextualitzades', 'he': 'SEx BiST: מפרסן מאומן ממקורים רבים עם מייצגים לקסיים עמוקים', 'jv': 'SEx BiRT: Una Multi-Source', 'sk': 'SEx BiST: Trainable Parser z več virov z globokimi kontekstualiziranimi leksičnimi predstavitvami', 'ha': 'KCharselect unicode block name', 'bo': 'SEx BiST: A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations'}
{'en': 'We describe the SEx BiST parser (Semantically EXtended Bi-LSTM parser) developed at Lattice for the CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies). The main characteristic of our work is the encoding of three different modes of contextual information for ', 'ar': 'نحن نصف محلل SEx BiST (محلل Bi-LSTM الموسع بشكل دلالي) الذي تم تطويره في Lattice للمهمة المشتركة CoNLL 2018 (التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية). السمة الرئيسية لعملنا هي ترميز ثلاثة أنماط مختلفة من المعلومات السياقية للتحليل: (1) تمثيلات ميزة Treebank ، (2) تمثيلات الكلمات متعددة اللغات ، (3) تمثيلات ELMo التي تم الحصول عليها من خلال التعلم غير الخاضع للإشراف من الموارد الخارجية. كان أداء المحلل اللغوي جيدًا في التقييم الرسمي الشامل (73.02 LAS - 4/26 فريقًا ، و 78.72 UAS - 2/26) ؛ بشكل ملحوظ ، حققنا أفضل درجات UAS على جميع الهيئات الإنجليزية من خلال تطبيق تمثيلات الميزات الثلاثة المقترحة. أخيرًا ، تم تصنيفنا أيضًا في المرتبة الأولى في مهمة استخراج الحدث الاختيارية ، وهي جزء من حملة تقييم المحلل اللغوي الخارجي لعام 2018.', 'pt': 'Descrevemos o analisador SEx BiST (semantically EXtended Bi-LSTM parser) desenvolvido na Lattice para a Tarefa Compartilhada CoNLL 2018 (Multilingual Parsing from Raw Text to Universal Dependencies). A principal característica do nosso trabalho é a codificação de três modos diferentes de informação contextual para análise sintática: (i) representações de características do Treebank, (ii) representações de palavras multilíngues, (iii) representações ELMo obtidas através de aprendizagem não supervisionada de recursos externos. Nosso analisador teve bom desempenho na avaliação oficial de ponta a ponta (73,02 LAS – 4º/26 equipes e 78,72 UAS – 2º/26); notavelmente, alcançamos as melhores pontuações de UAS em todos os corpora ingleses aplicando as três representações de características sugeridas. Por fim, também ficamos em 1º lugar na tarefa opcional de extração de eventos, parte da campanha 2018 Extrinsic Parser Evaluation.', 'es': 'Describimos el analizador SeX BiST (analizador Bi-LSTM semánticamente extendido) desarrollado en Lattice para la tarea compartida de CoNll 2018 (análisis multilingüe de texto sin procesar a dependencias universales). La característica principal de nuestro trabajo es la codificación de tres modos diferentes de información contextual para el análisis: (i) representaciones de entidades de Treebank, (ii) representaciones de palabras multilingües, (iii) representaciones de eLMO obtenidas a través del aprendizaje no supervisado de recursos externos. Nuestro analizador tuvo un buen desempeño en la evaluación oficial de extremo a extremo (73.02 LAS — 4°/26 equipos y 78.72 UAS — 2°/26); notablemente, logramos los mejores puntajes de UAS en todos los corpus ingleses aplicando las tres representaciones de características sugeridas. Por último, también obtuvimos el primer puesto en la tarea opcional de extracción de eventos, que forma parte de la campaña Evaluación de analizadores extrínsecos de 2018.', 'ja': 'ここでは、CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies)のためにLatticeで開発されたSEx BiST構文解析器(Semantically EXtended Bi - LSTM構文解析器)について説明します。私たちの研究の主な特徴は、構文解析のための3つの異なるコンテキスト情報モードをエンコードすることです。（ i ）ツリーバンクの機能表現、（ ii ）多言語の単語表現、（ iii ）外部リソースからの無監督学習を通じて得られたELMo表現。当社のパーサーは、公式のエンドツーエンド評価（ 73.02 LAS – 4位/26チーム、78.72 UAS – 2位/26チーム）で良好なパフォーマンスを発揮しました。顕著なことに、提案された3つの機能表現を適用することにより、すべての英語コーパで最高のUASスコアを達成しました。最後に、2018年のExtrinsic Parser Evaluationキャンペーンの一部であるオプションのイベント抽出タスクでも1位になりました。', 'zh': '述莱迪思为 CoNLL 2018 共事(始于文本至于多言解析)发 BiST 解析器(语义广其 Bi - LSTM 解析器)。 吾事之大体,编码三式者上下文信以解析:(i)树库特征,(ii)多言单词,(iii)资无监学之ELMo。 解析器在官端到端评(73.02 LAS – 第4/26组78.72 UAS – 2nd/26); 值得注意者,因三言之征,得至英语语料库之UAS。 最后,可选事第一,此 2018 年外解析器估动之一也。', 'fr': "Nous décrivons l'analyseur SeX BiST (analyseur bi-LSTM sémantically eXtended) développé par Lattice pour la tâche partagée ConLL 2018 (analyse multilingue du texte brut aux dépendances universelles). La principale caractéristique de notre travail est l'encodage de trois modes différents d'informations contextuelles pour l'analyse\xa0: (i) les représentations de caractéristiques Treebank, (ii) les représentations de mots multilingues, (iii) les représentations ElMo obtenues via un apprentissage non supervisé à partir de ressources externes. Notre analyseur a bien performé lors de l'évaluation officielle de bout en bout (73,02 LAS — 4e/26 équipes, et 78,72 UAS — 2ème/26)\xa0; remarquablement, nous avons obtenu les meilleurs scores UAS sur tous les corpus anglais en appliquant les trois représentations de caractéristiques suggérées. Enfin, nous avons également été classés au premier rang de la tâche facultative d'extraction d'événements, dans le cadre de la campagne d'évaluation de l'analyseur extrinsèque 2018.", 'hi': 'हम CoNLL 2018 साझा कार्य (यूनिवर्सल निर्भरताओं के लिए कच्चे पाठ से बहुभाषी पार्सिंग) के लिए जाली में विकसित SEx BiST पार्सर (Semantically EXtended Bi-LSTM पार्सर) का वर्णन करते हैं। हमारे काम की मुख्य विशेषता पार्सिंग के लिए प्रासंगिक जानकारी के तीन अलग-अलग तरीकों का एन्कोडिंग है: (i) ट्रीबैंक फीचर प्रतिनिधित्व, (ii) बहुभाषी शब्द प्रतिनिधित्व, (iii) बाहरी संसाधनों से असुरक्षित सीखने के माध्यम से प्राप्त ELMo प्रतिनिधित्व। हमारे पार्सर ने आधिकारिक एंड-टू-एंड मूल्यांकन (73.02 एलएएस - 4 / 26 टीमों, और 78.72 यूएएस - 2 nd / 26) में अच्छा प्रदर्शन किया; उल्लेखनीय रूप से, हमने तीन सुझाए गए फीचर अभ्यावेदनों को लागू करके सभी अंग्रेजी कॉर्पोरेट पर सर्वश्रेष्ठ यूएएस स्कोर हासिल किया। अंत में, हमें वैकल्पिक घटना निष्कर्षण कार्य में भी 1 स्थान दिया गया था, जो 2018 बाह्य पार्सर मूल्यांकन अभियान का हिस्सा था।', 'ru': 'Мы описываем парсер SEx BiST (Semantically Extended Bi-LSTM parser), разработанный в Lattice для общей задачи CoNLL 2018 (многоязычный парсинг от необработанного текста к универсальным зависимостям). Основной характеристикой нашей работы является кодирование трех различных режимов контекстной информации для синтаксического анализа: (i) представления функций Treebank, (ii) многоязычные представления слов, (iii) представления ELMo, полученные посредством неконтролируемого обучения из внешних ресурсов. Наш парсер показал хорошие результаты в официальной сквозной оценке (73,02 LAS – 4-я/26-я команды и 78,72 UAS – 2-я/26); примечательно, что мы достигли лучших результатов БАС во всех английских корпорациях, применив три предложенные характеристики. Наконец, мы также заняли 1-е место в необязательной задаче по извлечению событий в рамках кампании оценки внешнего анализа 2018 года.', 'ga': "Déanaimid cur síos ar pharsálaí Sex BiST (parsálaí Bi-LSTM Leathnaithe Semantach) a forbraíodh ag Lattice le haghaidh Tasc Comhroinnte CoNLL 2018 (Parsáil Ilteangach ó Théacs Raw go dtí Spleáchais Uilíocha). Is é príomhthréith ár gcuid oibre ná trí mhodhanna éagsúla faisnéise comhthéacsúla a ionchódú le haghaidh parsála: (i) Léiriúcháin gnéithe Treebank, (ii) Léiriúcháin focal ilteangacha, (iii) Léiriúcháin ELMo a fhaightear trí fhoghlaim gan mhaoirseacht ó acmhainní seachtracha. D'fheidhmigh ár parsálaí go maith sa mheastóireacht oifigiúil ceann go ceann (73.02 LAS - 4ú / 26 foirne, agus 78.72 UAS - 2nd/26); thar a bheith tábhachtach, bhaineamar amach na scóir UAS is fearr ar chorpora Shasana ar fad trí na trí ghné-léiriú molta a chur i bhfeidhm. Ar deireadh, bhí muid rangaithe freisin 1st ag an tasc eastóscadh imeacht roghnach, mar chuid d'fheachtas Meastóireachta Parsálaí Eitreach 2018.", 'hu': 'Leírjuk a SEx BiST elemzőt (Semantically EXtended Bi-LSTM elemzőt), amelyet a Lattice-nél fejlesztett ki a CoNLL 2018 Shared Task (többnyelvű elemzés a nyers szövegtől az univerzális függőségekig). Munkánk fő jellemzője a kontextuális információk három különböző elemzési módjának kódolása: (i) Fábank jellemzői, (ii) Többnyelvű szóreprezentációk, (iii) felügyelet nélküli tanulással kapott ELMo reprezentációk. Elemzőnk jól teljesített a hivatalos end-to-end értékelésben (73.02 LAS – 4/26 csapat, 78.72 UAS – 2/26); Figyelemre méltó, hogy a három javasolt feature reprezentáció alkalmazásával értük el a legjobb UAS pontszámokat minden angol korpuson. Végezetül a 2018-as Extrinsic Parser Evaluation kampány részét képező opcionális eseménykivonási feladaton is első helyezést értünk el.', 'el': 'Περιγράφουμε τον επεξεργαστή SEx BiST (Σημασιολογικά επεκταμένος δι-LSTM αναλυτής) που αναπτύχθηκε στο πλέγμα για την κοινή εργασία του CoNLL 2018 (Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις). Το κύριο χαρακτηριστικό της εργασίας μας είναι η κωδικοποίηση τριών διαφορετικών τρόπων περιεκτικών πληροφοριών για την ανάλυση: (i) αναπαραστάσεις χαρακτηριστικών δέντρων, (ii) πολυγλωσσικές αναπαραστάσεις λέξεων, (iii) αναπαραστάσεις ELMo που λαμβάνονται μέσω μη επιτηρημένης μάθησης από εξωτερικούς πόρους. Ο αναλυτής μας πέτυχε καλά στην επίσημη αξιολόγηση (73.02 ΛΑ – 4η/26 ομάδες και 78.72 UAS – 2η/26); Αξιοσημείωτα, πετύχαμε τις καλύτερες βαθμολογίες UAS σε όλα τα αγγλικά σώματα εφαρμόζοντας τις τρεις προτεινόμενες αναπαραστάσεις χαρακτηριστικών. Τέλος, κατατάξαμε επίσης πρώτοι στην προαιρετική εργασία εξαγωγής γεγονότων, μέρος της καμπάνιας αξιολόγησης εξωτερικών αναλύσεων 2018.', 'ka': 'ჩვენ SEx BiST პარასტორი (Semantically EXtended Bi-LSTM პარასტორი) განვითარებულია CoNLL 2018 საზოგადო დავალებისთვის Lattice-ში (მრავალენგური პარასტი წაშლა ტექსტიდან სამუშაო განსაზომილებებისათვის). ჩვენი სამუშაო სამუშაო პროცენტი არის სამი განსხვავებული კონტექსტური ინფორმაციის კონტექსტური რეჟიუმენტის კონტექსტური კონტექსტურის კონტექსტურაცია: ჩვენი პანსერტი უფრო კარგი გავაკეთეთ უფრო საკუთარი დასრულებაში (73.02 LAS – 4/26 ჯგუფი და 78.72 UAS – 2/26); ჩვენ ყველა ინგლისური კოპორაზე უკეთესი UAS მონაცემები მივიღეთ სამი მონაცემების გამოყენებით. საბოლოოდ, ჩვენ შეგვიძლია პირველი მოვლენების გამოყენება, რომელიც 2018 წლის ექსტრინსიკური ოჯახის გამოყენება.', 'it': "Descriviamo il parser SEx BiST (parser Semantically EXtended Bi-LSTM) sviluppato a Lattice per il CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependences). La caratteristica principale del nostro lavoro è la codifica di tre diverse modalità di informazione contestuale per l'analisi: (i) rappresentazioni di caratteristiche di Treebank, (ii) rappresentazioni di parole multilingue, (iii) rappresentazioni ELMo ottenute tramite apprendimento non supervisionato da risorse esterne. Il nostro parser si è comportato bene nella valutazione end-to-end ufficiale (73.02 LAS – 4/26 team, e 78.72 UAS – 2/26); Abbiamo ottenuto i migliori punteggi UAS su tutti i corpora inglesi applicando le tre rappresentazioni di funzionalità suggerite. Infine, siamo stati anche al primo posto nel compito opzionale di estrazione dell'evento, parte della campagna 2018 Extrinsic Parser Evaluation.", 'kk': 'Біз SEx BiST талдаушысын (Semantically EXtended Bi- LSTM талдаушысы) CoNLL 2018 ортақ тапсырмасының Lattice- де жасалған тапсырманы (Қара мәтіннен бірнеше тілдік талдау және Universal Dependencies) анықтадық. Жұмысының негізгі қасиеттері - талдау үш әртүрлі мәліметтің кодтамасы: i) Бұтақ банк мүмкіндіктері, ii) Көптеген сөздерді түсіндіру, (iii) ELMo мәліметтері сыртқы ресурстардан үйрену арқылы алған. Біздің талдаушымыз оқиға соңғы соңғы оқиға жақсы орындалды (73.02 LAS – 4th/26 команда және 78.72 UAS – 2/26); Біз ағылшын корпорасының барлық ең жақсы UAS нәтижелерін жеткіздік. Бұл үш нәтижелерді қолдану үшін. Соңында, біз сондай-ақ 2018 жылдың экстринзикалық аудитор оқиғасының бағалау кампаниясының бірінші ретінде болдық.', 'mk': 'Го опишуваме анализаторот SEx BiST (семантично проширен анализатор Bi-LSTM) развиен на Lattice за заедничката задача CoNLL 2018 (Мултијазично анализирање од суров текст до универзални зависности). The main characteristic of our work is the encoding of three different modes of contextual information for parsing: (i) Treebank feature representations, (ii) Multilingual word representations, (iii) ELMo representations obtained via unsupervised learning from external resources.  Нашиот анализатор успеа добро во официјалната оценка од крај до крај (73,02 ЛАС – тимови од 4/26 и 78,72 УАС – 2/26); извонредно, ги постигнавме најдобрите оценки на УАС на сите англиски корпора со апликација на трите предложени претставувања на карактеристиката. Конечно, ние исто така бевме рангирани на првата на опционалната задача за извлекување настани, дел од кампањата за евалуација на екстринсичните партнери во 2018 година.', 'lt': 'Mes apibūdiname SEx BiST analizatorių (Semantiškai išplėstas dviejų LSTM analizatorius), sukurtą Lattice bendrai užduočiai CoNLL 2018 (daugiakalbis analizavimas nuo žaliavinio teksto iki universaliųjų priklausomybių). Pagrindinė mūsų darbo savybė yra trijų skirtingų rūši ų kontekstinės informacijos, skirtos analizei, kodavimas: i) medžio banko savybių atstovavimas, ii) daugiakalbis žodžių atstovavimas, iii) ELMo atstovavimas, gaunamas nepastebimu mokymusi iš išorės išteklių. Mūsų analizatorius gerai atliko oficialų vertinimą nuo pabaigos (73,02 LAS – 4-oji iš 26 komandos ir 78,72 UAS – 2-oji iš 26 komandos); nepaprastai, pasiekėme geriausius UAS rezultatus visoje anglų korporoje taikant tris siūlomus požymius. Galiausiai mes taip pat buvome pirmasis neprivalomo renginio išgavimo uždavinys, kuris buvo 2018 m. ekstrinio analizatoriaus vertinimo kampanijos dalis.', 'ms': 'Kami menggambarkan penghurai SEx BiST (penghurai Bi-LSTM Semantically Extended) dikembangkan di Lattice untuk Tugas Berkongsi CoNLL 2018 (Penghuraian Berbahasa Dari Teks Raw ke Dependenci Universal). Karakteristik utama kerja kita ialah pengekodan tiga mod berbeza maklumat kontekstual untuk menghurai: (i) perwakilan ciri-ciri Treebank, (ii) perwakilan perkataan berbilang bahasa, (iii) perwakilan ELMo yang diperoleh melalui pembelajaran tanpa diawasi dari sumber luar. Penganalis kami berjaya dengan baik dalam penilaian rasmi akhir-akhir (73.02 LAS – pasukan ke-4/26, dan 78.72 UAS – ke-2/26); remarkably, we achieved the best UAS scores on all the English corpora by applying the three suggested feature representations.  Akhirnya, kami juga dipilih pertama dalam tugas ekstraksi peristiwa pilihan, sebahagian dari kampanye Evaluasi Parser Extrinsic 2018.', 'mn': 'Бид SEx BiST хуваарч (Semantically EXtended Bi-LSTM parser) нь 2018 CoNLL-ын CoNLL хуваарилагдсан ажлын Lattice-д хөгжсөн ажлыг тайлбарлаж байна. Бидний ажлын гол чанар нь хуваалцах үед 3 өөр орчин үеийн мэдээллийн кодлог: i) Модны банкны шинжлэх ухаан, ii) Олон хэл үеийн илэрхийлэл, iii) ЭЛМО-ын илэрхийлэл нь гадаад нөөцийн боловсролын суралцах аргаар авсан юм. Манай ажиллагчид үндсэн төгсгөлийн дүгнэлт сайн хийсэн (73.02 LAS – 4/26 баг, 78.72 UAS – 2/26); Гайхалтай нь бид Англи Корпора дахь хамгийн сайн АНУ-ын оноо хүртэл гурван хувилбаруудыг ашиглаж байна. Эцэст нь, бид 2018 оны Экстринзик Эзэмшигчдийн Эзэмшигчдийн Эзэмшигчийн Эзэмшигчийн Эзэмшигчийн Эзэмшигчийн Эзэмшигчийн Эзэмшигчдийн 1', 'mt': 'Aħna niddeskrivu l-analizzatur SEx BiST (analizzatur Bi-LSTM estiż b’mod Semantiku) żviluppat f’Lattice għall-Kompitu Kondiviż CoNLL 2018 (Analiżi Multilingwi minn Test Prim għal Dipendenzi Universali). Il-karatteristika ewlenija tax-xogħol tagħna hija l-kodifikazzjoni ta’ tliet modi different i ta’ informazzjoni kuntestwali għall-analiżi: (i) rappreżentazzjonijiet tal-karatteristiċi tal-bank tas-siġar, (ii) rappreżentazzjonijiet multilingwi tal-kliem, (iii) rappreżentazzjonijiet tal-ELMo miksuba permezz ta’ tagħlim mhux sorveljat minn riżorsi esterni. Il-parser tagħna wettaq tajjeb fl-evalwazzjoni uffiċjali minn tarf sa tarf (73.02 LAS – ir-raba’ tim/26, u 78.72 UAS – it-tieni/26); notevolment, laħaqna l-aħjar punteġġi tal-UAS fuq il-korpra Ingliża kollha billi applikajna t-tliet rappreżentazzjonijiet tal-karatteristiċi ssuġġeriti. Fl-aħħar nett, inqajmu l-ewwel post fil-kompitu fakultattiv tal-estrazzjoni tal-avvenimenti, parti mill-kampanja tal-Evalwazzjoni Extrinsika tal-Parser tal-2018.', 'no': 'Vi beskriver SEx BiST- tolkaren (Semantisk EXtended Bi- LSTM- tolkaren) utvikla i Lattice for den delte oppgåva CoNLL 2018 (fleirspråk tolking frå Raw Text til universele avhengighet). Den viktigste karakteristikaren av arbeidet vårt er koding av tre ulike modus av kontekstinformasjon for tolking: i) Trebankfunksjonsrepresentasjonar, (ii) fleirspråk ordrepresentasjonar, (iii) ELMo-representasjonar som er fått gjennom ulike læring frå eksterne ressursar. Tolkaren vårt utførte godt i den offisielle ende-til-sluttevalueringa (73.02 LAS – 4/26 grupper, og 78.72 UAS – 2/26); Det er merkelig at vi har oppnådd dei beste UAS-poeng på alle engelske korporane ved å bruka dei tre tilgjengelege funksjonsrepresentasjonane. I slutten vart vi også rankert første på den valgfriske hendingsknappen, delt av kampanjonen «Extrinsic Parser Evaluation campaign» 2018.', 'pl': 'Opisujemy parser SEx BiST (Semantycznie EXtended Bi-LSTM parser) opracowany w Lattice dla wspólnego zadania CoNLL 2018 (Wielojęzyczne Parsowanie z tekstu surowego do zależności uniwersalnych). Główną cechą naszej pracy jest kodowanie trzech różnych sposobów analizy informacji kontekstowych: (i) reprezentacji cech drzewa, (ii) reprezentacji wielojęzycznych słów, (iii) reprezentacji ELMo uzyskiwanych poprzez nienadzorowaną naukę z zasobów zewnętrznych. Nasz parser sprawdził się dobrze w oficjalnej ocenie end-to-end (73.02 LAS – 4th/26 zespoły, 78.72 UAS – 2nd/26); Co ciekawe, osiągnęliśmy najlepsze wyniki UAS we wszystkich angielskich korporach poprzez zastosowanie trzech sugerowanych reprezentacji funkcji. Wreszcie zostaliśmy również pierwszymi miejscami w opcjonalnym zadaniu ekstrakcji zdarzeń, części kampanii Ocena Parser Extrinsic 2018.', 'ro': 'Descriem parserul SEx BiST (parser Bi-LSTM Semantically EXtended) dezvoltat la Lattice pentru CoNLL 2018 Shared Task (Parsing multilingv de la text brut la dependențe universale). Principala caracteristică a lucrării noastre este codificarea a trei moduri diferite de analiză a informațiilor contextuale: (i) reprezentări ale caracteristicilor Treebank, (ii) reprezentări multilingve de cuvinte, (iii) reprezentări ELMo obținute prin învățare nesupravegheată din resurse externe. Analizorul nostru s-a descurcat bine în evaluarea oficială end-to-end (73.02 LAS – echipe 4/26 și 78.72 UAS – 2/26); În mod remarcabil, am obținut cele mai bune scoruri UAS pe toate corporele engleze aplicând cele trei reprezentări sugerate de caracteristici. În cele din urmă, am fost clasați pe locul 1 la sarcina opțională de extragere a evenimentului, parte a campaniei de Evaluare Extrinsică Parser 2018.', 'ml': 'സെക്സ് ബിസ്റ്റ് പരാജയപ്രകാരം (സെക്സ് ബിഎസ്റ്റി- എക്സ്റ്റി- എക്സ്റ്റമില്\u200d എക്സ്റ്റന്\u200dഡ് ബി- എല്\u200dസ്റ്റി) ലാറ്റിസില്\u200d നിര്\u200dമ്മിക്കപ്പെട്ട ട ടാസ നമ്മുടെ ജോലിയുടെ പ്രധാനപ്രകൃതി പാര്\u200dസിങ്ങിന്റെ മൂന്നു വ്യത്യസ്ത വിവരങ്ങളുടെ കോഡിങ്ങ് ആണ്: (i) ട്രീബാങ്കിന്റെ പ്രതിനിധികള്\u200d, (ii) പല ഭാഷ വാക്കുകളുടെ പ്രതിനി ഞങ്ങളുടെ പരാജയപ്രകാരം ഓഫീസല്\u200d അവസാന പരിഗണനത്തില്\u200d നന്നായി പ്രവര്\u200dത്തിച്ചു (73. 02 LAS - 4th/26 ടീം, 78. 72 UAS - 2nd/26); അത്ഭുതകരമായി, എല്ലാ ഇംഗ്ലീഷ് കോര്\u200dപ്പോറിയിലും ഏറ്റവും നല്ല യുഎസ് സ്കോര്\u200dട്ടുകള്\u200d ഞങ്ങള്\u200d നേടിയെടുത്തു. മൂന്നു പ്രോദ അവസാനം, ഞങ്ങള്\u200d തിരഞ്ഞെടുക്കുന്നതിന്റെ ആദ്യത്തെ പ്രവര്\u200dത്തനത്തിലാണ്, 2018 എക്സ്റ്റ്രിന്\u200dസിക് പാര്\u200dസറിന്റെ പ്രതിയോഗി', 'sr': 'Opišemo SEx BiST analizator (Semantički EXtended Bi-LSTM analizator) razvijen na Lattice za zajednički zadatak CoNLL 2018 (Multilingual Parsing from Raw Text to Universal Dependencies). Glavna karakteristika našeg rada je kodiranje tri različite režima kontekstualne informacije za analizu: i) predstavljanja Treebank karakteristike, ii) predstavljanja višejezičkih reèi, iii) predstavljanja ELMo dobijena putem neodređenog učenja iz vanjskih resursa. Naš analitičar je dobro proveo u službenoj procjeni kraja do kraja (73.02 LAS – 4.26 timova i 78.72 UAS – 2.26); iznenađujuće, postigli smo najbolji rezultat UAS na svim engleskim korporama primjenom tri predložene predstave. Konačno, bili smo i prvi na opcionalnom izvlačenju zadatka događaja, deo kampanje za ocjenu Extrinsičkog roditelja 2018.', 'si': 'අපි SEx BiST විශේෂකය (සෙමාන්ටිකිලියම් ප්\u200dරශ්ණ බී- LSTM විශේෂකය) කොන්ටික් 2018 කොන්ටික් විශේෂකය සඳහා විශේෂ කරලා තියෙන්නේ (රාව් පාළ අපේ වැඩේ ප්\u200dරධාන විශේෂතාවය තමයි පරීක්ෂණය සඳහා වෙනස් ප්\u200dරතිකෘති තුනක් තියෙන සංකේතනය (i) වර්ගබැංක් විශේෂතාවක්, (i) වර්ගභාෂාවක් වචන අපේ පරීක්ෂකයා හොඳටම සාධාරණික අවසානයෙන් අවසානයෙන් අවසානය කරනවා (73.02 LAS – 4th/26 කණ්ඩායම, 78.72 UAS – 2th/26) අපි ඉංග්\u200dරීස් කොර්පෝරා වලට හොඳම UAS ස්කෝර් ලබාගත්තා, ප්\u200dරශ්නයක් තුනක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ අන්තිමේදි, අපිට තියෙන්නේ අන්තිමේදී අවස්ථාවක් නිර්මාණය වෙනුවෙන් පළවෙනි කාර්යාවක් තියෙනවා.', 'so': 'Waxaannu qornaa SEx BiST Parser (Semantically EXtended Bi-LSTM ParParParser) oo u soo baxay at Lattice for the CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependences). Xirfaha ugu muhiimka ah ee shaqadeenna waa kooban saddex noocyo oo kala duduwan ee baarlamaanka: (i) macluumaad kala duduwan ee baarlamaanka ee Treebank, (ii) noocyada hadalka luuqadaha badan, (iii) noocyada ELMo ee laga helay waxbarashada dibadda ah. Baaritaankeenna si fiican ayuu u sameeyay qiimeynta rasmiga ugu dambaysta ah (73.02 LAS – 4th/26 koox iyo 78.72 UAS – 2nd/26); wax la yaabo leh, waxaynu dhamaan kooxda UAS ee ugu wanaagsan ee shirkadda Ingiriiska oo dhan ku soo bandhignay codsiga saddexda qof oo la soo jeeday. Ugu dambaysta waxaa kaloo nala qoray xafiiska la soo saaray oo ah qeyb ka mid ah campaignkii qiimeynta baararka ee 2018.', 'sv': 'Vi beskriver SEx BiST parser (Semantically EXtended Bi-LSTM parser) som utvecklats på Lattice för CoNLL 2018 Shared Task (Flerspråkig tolkning från råtext till universella beroende). Det viktigaste kännetecknet för vårt arbete är kodning av tre olika sätt av kontextuell information för tolkning: (i) Treebank funktionsrepresentationer, (ii) Flerspråkiga ordrepresentationer, (iii) ELMo-representationer erhållna via oövervakat lärande från externa resurser. Vår parser presterade bra i den officiella end-to-end utvärderingen (73.02 LAS – 4:e/26 lag, och 78.72 UAS – 2:a/26); anmärkningsvärt nog uppnådde vi de bästa UAS-poängen på alla engelska korpora genom att tillämpa de tre föreslagna funktionsrepresentationerna. Slutligen blev vi också rankade 1:a i den valfria händelseutvinningsuppgiften, en del av 2018 Extrinsic Parser Evaluation kampanjen.', 'ur': 'ہم نے SEx BiST پارچر (Semantically EXtended Bi-LSTM پارچر) کو CoNLL 2018 شریک ٹاکس کے لئے لاٹیکس میں تقویت کی۔ ہمارے کام کی اصلی خصوصیت یہ ہے کہ پارسینٹ کے لئے تین مختلف متوسط معلومات کا اکنوڈ کرنا ہے: (i) درخت بانک فرصت معلومات, (ii) Multilingual word representations, (iii) ELMo representations obtained by unsupervised learning from external resources. ہمارے پارچر نے رسمی انتظام میں بہتر عمل کیا (73.02 LAS – 4th/26 تیم اور 78.72 UAS – 2nd/26) ہم نے تمام انگلیسی کورپورا پر سب سے بہترین UAS اسکور پہنچ گئے، یہاں تک کہ تین معلوم فرضیوں کو لازم کریں۔ آخر میں، ہم نے بھی انتخاب کرنے کے کام میں پہلی مرتبہ میں رقم کیا گیا تھا، 2018 کی اضطراب پارس ارزیابی کمپین کی حصہ۔', 'ta': 'நாம் SEx பிஸ்ட் பகுதியை விவரிக்கிறோம் (பொதுவாக EXtended Bi-LSTM பரிசோதனை) கோன்எல் 2018 பகிர்ந்த பணிக்கான லாட்டிஸில் உருவாக்கப்பட்டது (Raw Text from Raw Text to Universal சார்புகளுக எங்கள் வேலையின் முதன்மையான தன்மையான மூன்று வித்தியாசமான தகவல் குறிமுறையாகும்: (i) வெளி வளங்களிலிருந்து பாதுகாக்கப்படாத கற்றல் மூலம் கொடுக்கப்பட்டுள்ளது. Our parser performed well in the official end-to-end evaluation (73.02 LAS – 4th/26 teams, and 78.72 UAS – 2nd/26);  மூன்று பரிந்துரைக்கப்பட்ட குணங்களை பயன்படுத்தி அனைத்து ஆங்கில நிறுவனத்திலும் சிறந்த UAS மதிப்புகளை நாங்கள் அடைந் இறுதியில், நாங்கள் விருப்பப்பட்ட விருப்பத்தேர்வு வெளியேற்றும் பணியில் முதல் நிறுவப்பட்டுள்ளோம், 2018 விரிவாக்க', 'vi': 'Chúng tôi mô tả phân tích cơ chế SEx BiST (cha phân tách Bi-LSTM kỳ kỳ cục) được phát triển tại Latetic for the CoNLL bây bây bây giờ chia sẻ Nhiệm vụ (đa ngôn ngữ phân tích từ văn bản thô tới các phụ thuộc chung). Đi ều đặc trưng nhất trong công việc của chúng ta là mã hóa ba phương pháp liên quan khác nhau để phân tích: i) Các bộ trình bày về các từ đa ngôn ngữ, H) các bộ trình diễn văn ElMo lấy từ nguồn tài nguyên bên ngoài không giám sát. Vị cha xứ của chúng ta đã hoàn thành tốt trong phần đánh giá cuối chính thức Thật đáng chú ý, chúng ta đã đạt được điểm cao nhất của Hạ sĩ Anh bằng cách áp dụng ba biểu tượng đặc trưng. Cuối cùng, chúng tôi cũng được xếp hạng thứ nhất trong nhiệm vụ khai thác sự kiện tùy chọn, một phần của chiến dịch thai nghén toà toà toà toà thẩm mĩ.', 'uz': "@ info: status Bizning vazifasimizning asosiy xil xususiyatlari - parsing uchun uchta xil turli maʼlumot kodlash: (i) Treebank xususiyatlarini (ii) Multi-tillar qismlarini (iii) Tashqi rasmlardan saqlab olilmagan ELMo representations. Bizning ajratishimiz ofisi oxirigi qiymatda yaxshi bajardi (73.02 LAS - 4/26 guruhi va 78.72 UAS - 2 chi/26)). Biz hamma ingliz kompaniya uchun eng yaxshi UAS scorlarini qo'llab berdik. Oxirgi, biz 2018 tashkilotni ajratish vazifasidagi birinchi tashkilotga kiritdik.", 'bg': 'Описваме анализатора разработен в мрежата за споделената задача CoNLL 2018 (многоезично анализиране от суров текст до универсални зависимости). Основната характеристика на нашата работа е кодирането на три различни начина на контекстуална информация за анализиране: (i) представяне на характеристиките на дървесната банка, (ii) многоезични думи, (iii) представяне на ЕЛМО, получено чрез ненадзорно обучение от външни ресурси. Нашият анализатор се представи добре в официалната оценка от край до край (73.02 ЛАС - 4/26 отбора, а 78.72 УАС - 2/26); Забележително е, че постигнахме най-добрите резултати на всички английски корпуси, като приложихме трите предложения представяне на функциите. Накрая, ние също бяхме класирани на първо място в незадължителната задача за извличане на събития, част от кампанията за оценка на екстринзичните анализи 2018 г.', 'hr': 'Opisujemo SEx BiST analizator (Semantički EXtended Bi-LSTM analizator) razvijen na Lattice za zajednički zadatak CoNLL 2018 (Multilingual Parsing from Raw Text to Universal Dependencies). Glavna karakteristika našeg rada je kodiranje tri različite načina kontekstualnih informacija za analizu: i) predstavljanja Treebank karakteristike, ii) predstavljanja višejezičkih riječi, iii) predstavljanja ELMo dobijena putem neodređenog učenja iz vanjskih resursa. Naš analitičar je dobro proveo u službenoj procjeni kraja do kraja (73.02 LAS - 4/26 timova i 78.72 UAS - 2/26); iznenađujuće, postigli smo najbolji rezultati UAS na svim engleskim korporama primjenom tri predložene predstave. Konačno, bili smo i prvi na opcionalnom zadatku izvlačenja događaja, dio kampanje Extrinsic Parser Evaluation 2018.', 'nl': 'We beschrijven de SEx BiST parser (Semantically EXtended Bi-LSTM parser) ontwikkeld bij Lattice voor de CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies). Het belangrijkste kenmerk van ons werk is de codering van drie verschillende modi van contextuele informatie voor het parsen: (i) Treebank feature representaties, (ii) Meertalige woordrepresentaties, (iii) ELMo representaties verkregen via onbeheerd leren van externe bronnen. Onze parser presteerde goed in de officiële end-to-end evaluatie (73.02 LAS,4th/26 teams, en 78.72 UAS,2nd/26); Opvallend genoeg bereikten we de beste UAS scores op alle Engelse corpora door de drie voorgestelde feature representaties toe te passen. Tot slot werden we ook 1e gerangschikt bij de optionele event extractie taak, onderdeel van de 2018 Extrinsic Parser Evaluation campagne.', 'de': 'Wir beschreiben den SEx BiST Parser (Semantically EXtended Bi-LSTM parser), der bei Lattice für den CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies) entwickelt wurde. Das Hauptmerkmal unserer Arbeit ist die Codierung von drei verschiedenen Modi von Kontextinformationen für das Parsen: (i) Treebank Feature Repräsentationen, (ii) Mehrsprachige Wortrepräsentationen, (iii) ELMo Repräsentationen, die durch unbeaufsichtigtes Lernen aus externen Ressourcen gewonnen werden. Unser Parser hat sich in der offiziellen End-to-End-Bewertung gut entwickelt (73.02 LAS, 4th/26 Teams und 78.72 UAS, 2nd/26); Bemerkenswerterweise erreichten wir die besten UAS-Scores auf allen englischen Korpora, indem wir die drei vorgeschlagenen Feature-Darstellungen anwendeten. Schließlich wurden wir auch bei der optionalen Event-Extraktionsaufgabe, die Teil der Kampagne 2018 Extrinsic Parser Evaluation ist, als Erster belegt.', 'da': 'Vi beskriver SEx BiST parser (Semantically EXtended Bi-LSTM parser) udviklet på Lattice til CoNLL 2018 Shared Task (Flersproget Parsing fra rå tekst til universelle afhængigheder). Det vigtigste kendetegn ved vores arbejde er kodning af tre forskellige former for kontekstuel information til tolkning: (i) Træbank funktion repræsentationer, (ii) Flersprogede ord repræsentationer, (iii) ELMo repræsentationer opnået via uautoriseret læring fra eksterne ressourcer. Vores fortolker klarede sig godt i den officielle end-to-end evaluering (73.02 LAS - 4th/26 teams, og 78.72 UAS - 2nd/26); bemærkelsesværdigt nok opnåede vi de bedste UAS scoringer på alle de engelske korpora ved at anvende de tre foreslåede feature repræsentationer. Endelig blev vi også rangeret 1. på den valgfrie event ekstraktionsopgave, som er en del af 2018 Extrinsic Parser Evaluation kampagnen.', 'fa': 'ما توصیف می\u200cکنیم که تقسیم SEx BiST (تقسیم\u200cکننده\u200cی BI-LSTM) در Lattice برای کار مشترک CoNLL 2018 توسعه داده شده است. ویژگی اصلی کار ما این است که رمزبندی از سه نوع اطلاعات متفاوتی برای پردازی: i) نمایش\u200cهای ویژگی درخت بانک, (ii) نمایش\u200cهای کلمه\u200cهای متعدد زبان, (iii) نمایش\u200cهای ELMo از طریق یادگیری غیرقابل استفاده از منابع خارجی یافت شده است. پارچر ما در ارزیابی رسمی پایان و پایان (73.02 LAS - 4/26 تیم و 78.72 UAS - 2/26) خوب انجام داده است. به طور معرکه، ما بهترین امتیاز UAS را در تمام شرکت انگلیسی به دست آوردیم با کاربردی از سه نمایش\u200cهای ویژه\u200cهای پیشنهاد. بالاخره، ما همچنین در وظیفه اخراج تصمیم گزینه\u200cای، بخشی از کمپین ارزیابی پدر عمومی Extrinsic Parser ۲۰۱۸ رقابت یافته\u200cایم.', 'id': 'Kami menggambarkan pengenalisan SEx BiST (pengenalisan Bi-LSTM Semantically Extended) yang dikembangkan di Lattice untuk Tugas Berkongsi CoNLL 2018. Karakteristik utama dari pekerjaan kami adalah pengekodan tiga modus informasi kontekstual yang berbeda untuk menghurai: (i) representation karakteristik Treebank, (ii) representation kata berbilang, (iii) representation ELMo yang diperoleh melalui belajar tidak diawasi dari sumber daya luar. Parser kami berhasil dengan baik dalam evaluasi resmi akhir-akhir (73.02 LAS - tim ke-4/26, dan 78.72 UAS - 2/26); luar biasa, kami mencapai skor UAS terbaik pada semua korpra Inggris dengan menggunakan tiga representation karakteristik yang disarankan. Akhirnya, kami juga tertinggi pertama di tugas ekstraksi acara pilihan, bagian dari kampanye Evaluasi Extrinsic Parser 2018.', 'ko': 'Google은 Lattice가 CoNLL 2018 공유 작업(원본 텍스트에서 일반 의존 항목까지의 다중 언어 해석)을 위해 개발한 SEx Bist 해석기(의미 확장 Bi LSTM 해석기)를 설명합니다.우리가 일하는 주요 특징은 세 가지 서로 다른 모델의 상하문 정보를 인코딩하여 해석하는 것이다. (i) 트리 라이브러리 특징 표시, (ii) 다국어 단어 표시, (iii)는 무감독 학습을 통해 외부 자원에서 얻은 ELMo 표시이다.우리의 해석기는 정부측의 단말기부터 단말기까지의 평가에서 양호한 모습을 보였다(73.02 LAS-제4/26팀, 78.72 UAS-제2/26팀).주의해야 할 것은 세 가지 제안의 특징을 응용함으로써 우리는 모든 영어 어료 라이브러리에서 가장 좋은 UAS 점수를 얻었다는 것이다.마지막으로 우리는 선택할 수 있는 이벤트 추출 임무 중 1위를 차지했는데 이것은 2018년 외부 해석기 평가 활동의 일부분이다.', 'sw': 'Tunaelezea mchambuzi wa SEx BiST (mchambuzi wa kimapenzi EXtended Bi-LSTM) uliotengenezwa katika Lattice kwa ajili ya kazi ya CoNLL 2018 (Uchapishaji wa lugha nyingine kutoka Mabarua ya Raw hadi Uvumilio wa Kimataifa). Uhusika mkuu wa kazi yetu ni kuongezeka kwa namna tatu tofauti za taarifa za kisasa kwa ajili ya parsing: (i) maonesho ya Treebank, (ii) wawakilishi wa maneno ya lugha mbalimbali, (iii) wawakilishi wa ELMo uliopatikana kwa kupitia elimu isiyo sahihi kutoka rasilimali za nje. Wanachambuzi wetu walifanya kazi vizuri katika tathmini rasmi ya mwisho (LAS - timu 4/26 na 78.72 UAS - 2 na 26); Inashangaza, tulifanikiwa vipimo vizuri vya UAS katika kampuni zote za Kiingereza kwa kutumia maoni matatu yanayopendekezwa. Finally, we were also ranked 1st at the optional event extraction task, part of the 2018 Extrinsic Parser Evaluation campaign.', 'tr': 'SEx BiST täzeleçisini (Semantik EXtended Bi-LSTM täzeleçisi) CoNLL 2018 bölüm zady üçin Lattikde geliştirildi. Çalışymyzyň esasy karakterleri, parslamak üçin üç dürli mod çykyş maglumatynyň kodlemesidir: (i) agaç özellikleri, (ii) köp dilli söz temsilleri, (iii) ELMo taýşaryk çeşmelerinden dowam edilmedik öwrenmeleri ýüzerinden berilýär. Bizim çözümlerimiz resmi son-a-soňrak deňlemede gowy gazandy (73.02 LAS - 4th/26 topar we 78.72 UAS - 2nd/26); ýüz Mükemmel bolsa, üç teklip eden çykyşlary ulanyp iňlisçe korporatyň iň gowy depelerine ýetdik. Soňunda, 2018-nji ýyldaky Extrinsik Parser Taýýarlama kampanyasynyň birinji derejesinde diýilip atlandyryldyk.', 'sq': 'Ne e përshkruajmë analizuesin SEx BiST (analizuesin Semantikisht të zgjeruar Bi-LSTM) të zhvilluar në Lattice për detyrën e përbashkët CoNLL 2018. Karakteristika kryesore e punës sonë është kodimi i tre modaliteteve të ndryshme të informacionit kontekstual për analizimin: (i) përfaqësimet e karakteristikave të bankës së pemës, (ii) përfaqësimet e fjalëve shumëgjuhëse, (iii) përfaqësimet e ELMo të përfunduara nëpërmjet mësimit të pazgjidhur nga burimet e jashtme. Analizatori ynë bëri mirë në vlerësimin zyrtar nga fundi në fund (73.02 LAS - ekipe të 4/26 dhe 78.72 UAS - 2/26); në mënyrë të mrekullueshme, arritëm rezultatet më të mira të UAS në të gjithë korporatën angleze duke aplikuar tre përfaqësimet e propozuara të funksionimit. Më në fund, ne ishim të renditur gjithashtu të parë në detyrën opsionale të nxjerrjes së veprimtarisë, pjesë e fushatës së vlerësimit Extrinsik Parser 2018.', 'af': 'Ons beskryf die SEx BiST-ontwerker (Semantiese uitgetrek Bi-LSTM ontwerker) ontwikkel by Lattice vir die CoNLL 2018 Gedeelde Opdrag Die hoofde karakteristiek van ons werk is die kodering van drie verskillende modus van contextual inligting vir verwerking: i) Boom bank funksie voorstellings, (ii) Multilingual woord voorstellings, (iii) ELMo voorstellings wat deur onverondersteunde leer van eksterne hulpbronne ontvang word. Ons ontvanger het goed uitgevoer in die offisiele end-to-end evaluering (73.02 LAS - 4de/26 teams en 78.72 UAS - 2de/26); waarskynlik, ons het die beste UAS-rekening op al die Engelske korpora bereik deur die drie voorgestelde funksie voorstellings te doen. Eindelik is ons ook 1st rangeer by die opsionele gebeurtenis uittrekking taak, deel van die 2018 Extrinsic Parser Evaluering Kampanja.', 'am': 'የSEx ቢST ተፈላጊ (Semantically EXtended Bi-LSTM ParParser) በተለየነው Lattice for the CoNLL 2018 የተለየ ስራ (Multilingual Parsing from Raw Text to Universal Dependations) እናሳውቃለን፡፡ የሥራችንን ዋነኛ አካባቢ የሦስት መልዕክት ለማኅበረሰብ መልዕክት ማቀናቀል ነው:(i) የTreebank ምርጫዎች መልዕክቶች፣ (ii) የብዙ ቋንቋዎች ቃላት መልዕክቶች (iii) ውጭ ሀብት በማይጠበቅ ትምህርት የተገኘ የኤልሞ መልዕክቶች ነው፡፡ የሥርዓት መጨረሻ ውጤት ውስጥ ተሳካሚ ተቃውሞ ነበር (73.02 LAS - 4th/26 ቡድን እና 78.72 UAS - 2nd/26)፤ በብርቱ፣ የኢንግሊዝኛ ኮርፖርት ሁሉ የበለጠውን የኦዚ ደረጃዎች አግኝተናል፡፡ በመጨረሻውም በ2018 የውጭ የፓርስ አካለ ማስታወቂያ ዘመቻ ውስጥ ለመጀመሪያ የተለየን አካባቢ ስራ ተደረገን፡፡', 'az': "Biz SEx BiST parçacısını (Semantically EXtended Bi-LSTM parser) CoNLL 2018 paylaşılan işi üçün Lattice'də təşkil etdik. İşimizin ən böyük xüsusiyyəti, ayırmaq üçün üç cür müxtəlif məlumatın kodlaması: i) Ağaç bankası xüsusiyyətləri, ii) çoxlu dil sözlərin təşkiləri, iii) ELMo təşkiləri daşınmış qadınlardan öyrənmək vasitəsilə alındı. Bizim parçacımız resmi sonun-sonun değerlendirməsində yaxşı işlədi (73.02 LAS - 4th/26 team, 78.72 UAS - 2/26); Əlbəttə, biz bütün İngilizə korporasında ən yaxşı UAS nöqtələrini təmin edib üç nöqtələri təşkil etdik. Sonunda, biz də 2018-ci Extrinsic Parser Evaluation kampanyasının birinci dərəcə verildik.", 'bs': 'Opišemo SEx BiST analizator (Semantički EXtended Bi-LSTM analizator) razvijen na Lattice za zajednički zadatak CoNLL 2018 (Multilingual Parsing from Raw Text to Universal Dependencies). Glavna karakteristika našeg rada je kodiranje tri različite načina kontekstualnih informacija za analizu: i) predstavljanja Treebank karakteristike, (ii) višejezičke predstavljanja riječi, (iii) predstavljanja ELMo dobijena putem neodređenog učenja iz vanjskih resursa. Naš analitičar je dobro proveo u službenoj procjeni kraja do kraja (73.02 LAS - 4/26 timova i 78.72 UAS - 2/26); Iznenađujuće, postigli smo najbolji rezultat UAS na svim engleskim korporama primjenom tri predložene predstave. Konačno, bili smo i prvi na opcionalnom zadatku izvlačenja događaja, dio kampanje Extrinsic Parser Evaluation 2018.', 'bn': 'আমরা সেক্স বিস্ট বিস্ট ব্যাক্তির বর্ণনা করছি (সেক্স বিএলস্টিএম বিএলস্টিএম বিশ্লেষক) কোন কনএল ২০১৮ শেয়ার করা কাজের জন্য ল্যাটিসে উন্নয়ন করেছে (রো টেক্সট আমাদের কাজের প্রধান বৈশিষ্ট্য হচ্ছে পার্সিং এর জন্য তিনটি বিভিন্ন ধরনের বিভিন্ন তথ্যের এনকোডিং: (i) ট্রেবাঙ্কের বৈশিষ্ট্য প্রতিনিধিত্ব, (ii) বহুভাষাভাষী শব্ আনুষ্ঠানিক শেষ পর্যন্ত মূল্যের মাধ্যমে আমাদের বিশ্লেষক ভালো করেছে (৭৩. ০২ ল্যাস - ৪/২৬ দল এবং ৭৮. 72 ইউএস - ২য়/২৬)। বিস্ময়কর যে, আমরা সব ইংরেজি কর্পোরায় সেরা ইউএসস স্কোর অর্জন করেছি এই তিনটি প্রস্তাবিত বৈশিষ্ট্যের প্রতিনিধিদের প্রয়োগ অবশেষে ২০১৮ সালের এক্সট্রিন্সিক পার্সার প্রতিযোগিতা প্রচারণার অংশে আমরা অনুষ্ঠানের বেছে নিয়ে যাওয়ার জন্য প্রথম কাজে র', 'ca': "Descrivem l'analitzador SEx BiST (Semantly Extended Bi-LSTM parser) desenvolupat a Lattice per la tasca compartida CoNLL 2018 (Multilingual Parsing from Raw Text to Universal Dependencies). La característica principal de la nostra feina és la codificació de tres mods diferents d'informació contextual per analitzar: (i) representacions de característiques de banc d'arbres, (ii) representacions multilingües de paraules, (iii) representacions d'ELMo obtingudes mitjançant aprenentatge no supervisat amb recursos externs. El nostre analitzador va funcionar bé en l'evaluació oficial de final a final (73,02 equips LAS - 4th/26, i 78,72 UAS - 2nd/26); notevolment, vam aconseguir les millors puntuacions de la UAS en tots els corpores anglesos aplicant les tres representacions suggerides. Finally, we were also ranked 1st at the optional event extraction task, part of the 2018 Extrinsic Parser Evaluation campaign.", 'et': 'Me kirjeldame SEx BiST parserit (Semantically EXtended Bi-LSTM parser), mis on välja töötatud Võrgus CoNLL 2018 ühise ülesande jaoks (mitmekeelne parsimine toortekstist universaalsete sõltuvusteni). Meie töö põhiomaduseks on kolme erineva kontekstilise informatsiooni vormi kodeerimine parsimiseks: (i) puupanga funktsioonide esitused, (ii) mitmekeelsed sõnade esitused, (iii) ELMo esitused, mis saadakse järelevalveta õppe kaudu välisressurssidest. Meie parser sai ametlikus lõpp-lõpuni hindamises hästi hakkama (73,02 LAS - 4/26 meeskond ja 78,72 UAS - 2/26); märkimisväärselt saavutasime parimad UAS skoorid kõigis inglise korpustes, rakendades kolme soovitatud funktsiooni esitusi. Lõpuks saime ka esimese koha valikulisel ürituse ekstrinsiivse hindamise ülesandel, mis oli osa 2018. aasta ekstrinsiivse parseri hindamise kampaaniast.', 'cs': 'Popisujeme SEx BiST parser (Sémanticky EXtended Bi-LSTM parser) vyvinutý v Lattice pro sdílený úkol CoNLL 2018 (Multilingual Parsing from Raw Text to Universal Dependences). Hlavní charakteristikou naší práce je kódování tří různých režimů kontextových informací pro analýzu: (i) reprezentace stromové banky, (ii) reprezentace vícejazyčných slov, (iii) reprezentace ELMo získané bez dozoru učením z externích zdrojů. Náš parser si vedl dobře v oficiálním end-to-end hodnocení (73.02 LAS,4th/26 týmy a 78.72 UAS na 2nd/26); Pozoruhodně jsme dosáhli nejlepších hodnot UAS na všech anglických korpusech použitím tří navrhovaných reprezentací funkcí. A konečně jsme byli také první v volitelném úkolu extrakce událostí, který byl součástí kampaně 2018 Extrinsic Parser Evaluation.', 'fi': 'Kuvaamme SEx BiST -parserin (Semantically EXtended Bi-LSTM -parserin), joka on kehitetty Latticessa CoNLL 2018 Shared Task -tehtävään (monikielinen parsing raakatekstistä universaaleihin riippuvuuksiin). Työn pääpiirteenä on kolmen erilaisen kontekstuaalisen informaation koodaus jäsentämiseen: (i) Puupankki-ominaisuusesitykset, (ii) Monikieliset sanaesitykset, (iii) ELMo-esitykset, jotka saadaan valvomattomalla oppimisella ulkoisista resursseista. Analysoijamme suoriutui hyvin virallisessa end-to-end-arvioinnissa (73,02 LAS - 4/26 joukkuetta, ja 78,72 AMK - 2/26); Huomattavaa on, että saavutimme parhaat AMK-pisteet kaikissa englanninkielisissä korpusissa soveltamalla kolmea ehdotettua ominaisuusesitystä. Lopulta saimme myös ensimmäisen sijan valinnaisessa tapahtumanpoistotehtävässä, joka oli osa vuoden 2018 Extrinsic Parser Evaluation -kampanjaa.', 'hy': 'We describe the SEx BiST parser (Semantically EXtended Bi-LSTM parser) developed at Lattice for the CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies).  Մեր աշխատանքի հիմնական առանձնահատկությունն է վերլուծության կոնտեքստալ ինֆորմացիայի երեք տարբեր միջոցների կոդավորումը: i) ծառի հիմքի առանձնահատկությունների ներկայացումները, i) բառերի բառերի բազմալեզու ներկայացումները, III) ELMo ներկայացումները, որոնք ստացվում են արտաքի Our parser performed well in the official end-to-end evaluation (73.02 LAS - 4th/26 teams, and 78.72 UAS - 2nd/26);  remarkably, we achieved the best UAS scores on all the English corpora by applying the three suggested feature representations.  Finally, we were also ranked 1st at the optional event extraction task, part of the 2018 Extrinsic Parser Evaluation campaign.', 'ha': "@ info Maɓallin aikin mu yana kodi da wasu irin mutane uku daban-daban information wa parse: (i) tsaroyi na Treebank, (ii) masu fassarar magana masu yawa, (ii) masu motsi da aka kama da ELMo daga bayan da ba'a tsare shi ba daga ressursn bakin. Anazartar da mu aikata mai kyau a cikin rabin ƙarshen dawwama (73.01 LoS - 4th/26 team, da 78.42 USA - 2nd/26), Ina karanta, mun sami mafiya kyakkyawan fassarar UAN a kan duk Companiya na Ingiriya da mu applied wasu mataimaka uku wanda aka yi niyyar. Ga ƙarshe, an ranar mu da na farko a cikin aikin da aka zãɓe shi, wani abu na Kamcampin da aka Shirar Sura'awa na 2018.", 'sk': 'Opisujemo razčlenjevalnik SEx BiST (Semantically EXtended Bi-LSTM parser), razvit v mreži za skupno nalogo CoNLL 2018 (večjezično razčlenjevanje od surovega besedila do univerzalnih odvisnosti). Glavna značilnost našega dela je kodiranje treh različnih načinov kontekstualnih informacij za razčlenjevanje: (i) predstavitve značilnosti drevesne banke, (ii) večjezične predstavitve besed, (iii) predstavitve ELMo, pridobljene preko nenadzorovanega učenja iz zunanjih virov. Naš parser se je dobro izkazal v uradni oceni od konca do konca (73,02 LAS - 4/26 ekip, 78,72 UAS - 2/26); Izjemno je, da smo dosegli najboljše rezultate UAS v vseh angleških korpusih z uporabo treh predlaganih predstavitev funkcij. Nazadnje smo bili uvrščeni na prvo mesto tudi na izbirni nalogi ekstrinzičnega razporejanja dogodkov, ki je del kampanje za oceno ekstrinzičnega razporejanja 2018.', 'jv': 'We rambarang SEx BiRT Ngubah PASSAR (semanti-cally ex-SLT PASSAR) nggawe Lattike nggo CoNLL 2013 shared task (Multilanguage Parasing from Roo Text to Universal dependncies). Attribute Ngubah ceras sing dumaten hukum sing dumaten ning cual-ne-tuku cara-cara (75.02 LAS - 4th/24 ekip, lan 75.75 UES - 2th/24). maneh, awak dhéwé wis ngerasakno sing luwih dumadhi CUS sak ngono perusahaan Inggris nggawe nyimpen karo telu supayasané suratan. Lha wigatining, awak dhéwé uga cara-cara sing wis rak tanggal 1 nganggo caak nggawe winih kanggo gabung, akèh ning kampanya "ex-trincic parentser measurement".', 'he': 'אנו מתארים את המחקר SEx BiST (המחקר Bi-LSTM מורחב באופן סמנטי) שפותח ב Lattice עבור המשימה המשותפת CoNLL 2018 (המחקר רב-שפתי מתוך טקסט ראש לתלויות universal). הסימן העיקרי של העבודה שלנו הוא הקוד של שלושה דרכים שונות של מידע קונטוקטואלי עבור העבודה: (i) מייצגות תכונות בעץ, (ii) מייצגות מילים רבות שפות, (iii) מייצגות ELMo שנקבלו באמצעות לימוד ללא השגחה משאבים חיצוניים. Our parser performed well in the official end-to-end evaluation (73.02 LAS - 4th/26 teams, and 78.72 UAS - 2nd/26);  באופן יוצא דופן, השגנו את הציונים הטובים ביותר של UAS על כל הקופורה האנגלית על ידי שימוש בשלושת מייצגי התאים המוצעים. סוף סוף, היינו גם מועמדים ראשונים במשימת החלץ האופציונלית של האירועים, חלק מהקמפיין הערכת הפרסים האסטרניסקי 2018.', 'bo': 'We describe the SEx BiST parser (Semantically EXtended Bi-LSTM parser) developed at Lattice for the CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies). The main characteristic of our work is the encoding of three different modes of contextual information for parsing: (i) Treebank feature representations, (ii) Multilingual word representations, (iii) ELMo representations obtained via unsupervised learning from external resources. ང་ཚོའི་དབྱེ་སྟངས་གཞུང་ཕྱོགས་མཇུག་གི་གནད་སྡུད་མིན་པར་ལྡན་གྱི་ནང་དུ་སྒྲུབ་པ་ཡིན། remarkably, we achieved the best UAS scores on all the English corpora by applying the three suggested feature representations. མཐའ་མཇུག་དུ། ང་ཚོ་ཡང་གདམ་ཁ་འབེབས་ཀྱི་བྱ་འགུལ་གྱི་ནང་ལས་ཆོག་པོ་༡་པ་ཞིག་བསྡུར་ཡོད།'}
{'en': 'Towards JointUD : ', 'pt': 'Rumo ao JointUD: marcação e lematização de parte do discurso usando redes neurais recorrentes', 'es': 'Hacia JointUD: lematización y etiquetado de partes del habla mediante redes neuronales recurrentes', 'zh': '迈向关节UD:用递归神经网络词性标词形还原', 'ja': 'JointUDに向けて：再発性ニューラルネットワークを使用した発話部分タグ付けとリンパ節形成', 'hi': 'संयुक्त राज्य की ओर: आवर्तक तंत्रिका नेटवर्क का उपयोग करके पार्ट-ऑफ-स्पीच टैगिंग और लेमेटाइजेशन', 'fr': "Vers JointUD\xa0: marquage et lemmatisation des parties du discours à l'aide de réseaux neuronaux récurrents", 'ru': 'На пути к JointUD: Тегирование части речи и лематизация с использованием рекуррентных нейронных сетей', 'ar': 'نحو JointUD: تمييز جزء من الكلام و Lemmatization باستخدام الشبكات العصبية المتكررة', 'ga': 'I dTreo JointUD: Clibeáil Pháirteach agus Leamatú ag baint úsáide as Líonraí Néaracha Athfhillteacha', 'ka': 'JointUD: სიტყვების ნაწილი მაგრამ და ლემატიზაციის გამოყენება', 'el': 'Προς το κοινό: Σηματοποίηση μέρους ομιλίας και λεμματοποίηση με χρήση επαναλαμβανόμενων νευρωνικών δικτύων', 'kk': 'JointUD- қайталанатын нейралық желілерді қолданып сөйлеу тегтерінің бөлігі мен лематизация', 'hu': 'Towards JointUD: Part-of-speech Tagging és Lemmatizálás ismétlődő ideghálózatokkal', 'it': 'Verso JointUD: Part-of-speech Tagging e Lemmatizzazione utilizzando reti neurali ricorrenti', 'ml': 'മുകളിലേക്ക് ജോയിന്റുUD: പിന്നീട് നെയുറല്\u200d നെറ്റുവര്\u200dക്കുകള്\u200d ഉപയോഗിച്ചു് ഭാഗം', 'ms': 'Ke arah Sambungan: Bahagian-dari-ucapan Tagging dan Lemmatisasi menggunakan Rangkaian Neural Berulang', 'lt': 'JointUD link: kalbos dalis ženklinimas ir lemmatizacija naudojant pakartotinius nervinius tinklus', 'mk': 'КАЈ ЈОНТУД: Дел од говорот за означување и лематизација со користење на рекурентните неврални мрежи', 'mt': 'Lejn JointUD: Tagging u Lemmatizzazzjoni ta’ Parti mid-Diskors bl-użu ta’ Netwerks Newrali Rikorrenti', 'no': 'Til JointUD: Delt av talemerking og lemmatisering ved å bruka gjentaande neuralnettverk', 'pl': 'W kierunku JointUD: Tagowanie części mowy i lemmatyzacja przy użyciu powtarzających się sieci neuronowych', 'ro': 'Către JointUD: Part-of-speech Tagging și Lemmatizare folosind Rețele Neurale Recurente', 'sr': 'Do zajedničkog UD: deo oznake govora i limatizacija koristeći ponovne neurone mreže', 'si': 'සම්බන්ධ UD වලට: කොටස් කිරීමේ ටැග් සහ ලෙම්මාටිස් කරන්න', 'sv': 'Mot JointUD: Part-of-speech Tagging och lemmatisering med återkommande neurala nätverk', 'ta': 'UD: பகுதி பேச்சு ஒட்டுதல் மற்றும் எழுத்துருவுகள் மறுநிகழ்ந்த நெயுரல் வலைப்பின்னல்களை பயன்படுத்தி', 'mn': 'JointUD руу: хэлэлцээний нэг хэсэг Tagging болон Lemmatization', 'so': 'Towards JointUD: Part of speech Tagging and Lemmatization using Recurrent Neural Network', 'ur': 'JointUD کی طرف: دوبارہ نئورل نیٹورک کے مطابق بات ٹاگ اور لیمیٹیز کا حصہ', 'uz': 'UD: Part of speech Tagging and Lemmatization using Recurrence Neural Networks', 'vi': 'Về hướng JointUD: Phần của ngôn ngữ Đánh dấu và Lemmatition nhờ liên tiếp các mạng thần kinh', 'da': 'Mod JointUD: Part-of-tale Tagging og lemmatisering ved hjælp af tilbagevendende neurale netværk', 'nl': 'Naar JointUD: Part-of-speech Tagging en Lemmatisatie met behulp van Recurrent Neural Networks', 'bg': 'Към съединение: Част от речта маркиране и лематизация чрез повтарящи се неврални мрежи', 'hr': 'Prema JointUD: dijelom oznake govora i limatizacija korištenjem ponovnih neuronskih mreža', 'de': 'Towards JointUD: Part-of-Speech-Tagging und Lemmatisierung mittels wiederkehrender neuronaler Netzwerke', 'id': 'Menuju JointUD: Tagging dan Lemmatisasi bagian dari pidato menggunakan Rangkaian Neural Berikutnya', 'ko': 'JointUD로 가기: 귀속 신경 네트워크의 어성 표시와 레몬화 사용', 'fa': 'به سمت UD JointUD: قسمتی از نقاشی سخنرانی و تنظیم با استفاده از شبکه\u200cهای عصبی دوباره', 'af': 'Gaan na JointUD: Deel van- spraak etiket en Lemmatiseering gebruik Herhaalde Neurale Netwerke', 'sw': 'UD: Part of speech Tagging and Lemmaration using Recent Neural Network', 'sq': 'Për të bashkuar me UD: Tagging dhe Lemmatizim pjesë e fjalës duke përdorur rrjetet neurale të përsëritura', 'tr': "JointUD'a doğru", 'am': 'UD: Part-of-speech Tagging and Lemmatization using Recent Neural Network', 'hy': 'Դադար', 'bn': 'পুনরাবৃত্তিক নিউরাল নেটওয়ার্ক ব্যবহার করে ভাষণের অংশ ট্যাগিং এবং লেমাটিশেশন', 'az': 'JointUD tərəfində: Dərgahlı Nöral Ağlarını istifadə edən sözlərin bir parçası etiketlənməsi və Lemmatizatlığı', 'bs': 'Prema JointUD: deo oznake govora i limatizacija koristeći ponovne neurone mreže', 'ca': 'En direcció a la Unió: Etiquetar i lemmatitzar part de la xerrada fent servir xarxes neurals recurrents', 'cs': 'Směrem k JointUD: Tagování části řeči a lemmatizace pomocí recidivních neuronových sítí', 'et': 'JointUD suunas: kõneosa märgistamine ja lemmatiseerimine korduvate neurovõrkude abil', 'fi': 'Kohti JointUD: Osa puheesta merkitseminen ja lemmatisointi toistuvilla hermoverkoilla', 'jv': 'ProgressBarUpdates', 'he': 'Towards JointUD: Part-of-speech Tagging and Lemmatization using Recurrent Neural Networks', 'sk': 'K skupnemu UD: označevanje in lemmatizacija dela govora z uporabo ponavljajočih se živčnih omrežij', 'ha': 'UD: part of language Taging and Lemmatization by Recurrence Neural Networks', 'bo': 'Towards JointUD: Part-of-speech Tagging and Lemmatization using Recurrent Neural Networks'}
{'en': 'This paper describes our submission to CoNLL UD Shared Task 2018. We have extended an LSTM-based neural network designed for sequence tagging to additionally generate character-level sequences. The network was jointly trained to produce ', 'ar': 'تصف هذه الورقة تقديمنا إلى CoNLL UD Shared Task 2018. لقد قمنا بتوسيع شبكة عصبية قائمة على LSTM مصممة لوضع علامات التسلسل لإنشاء تسلسلات على مستوى الأحرف بالإضافة إلى ذلك. تم تدريب الشبكة بشكل مشترك لإنتاج lemmas وعلامات جزء من الكلام والسمات المورفولوجية. تم التعامل مع تجزئة الجملة ، والترميز ، وتحليل التبعية بواسطة خط الأساس UDPipe 1.2. توضح النتائج جدوى البنية متعددة المهام المقترحة ، على الرغم من أن أدائها لا يزال بعيدًا عن أحدث التقنيات.', 'ja': '本稿では、CoNLL UD Shared Task 2018への提出について説明します。我々は、文字レベルの配列を追加的に生成するために、配列タグ付けのために設計されたＬＳＴＭベースのニューラルネットワークを拡張した。このネットワークは、レマ、発話部分タグ、および形態学的特徴を作成するために共同トレーニングされました。文章のセグメンテーション、トークン化、および依存関係の解析は、UDPipe 1.2ベースラインによって処理されました。その結果は、提案されたマルチタスクアーキテクチャの実現可能性を示していますが、そのパフォーマンスはまだ最先端のものとは程遠いままです。', 'zh': '本文介于CoNLL UD Shared Task 2018。 广一基于LSTM之神经网络,当神经网络专为序表而设之,以额外生成字符级序之。 其网络合习,以生引理,词性标形。 句分标赖解析 UDPipe 1.2 基线处之。 卒明其所言多任务架构可行性,虽性能犹远非先进之术。', 'pt': 'Este artigo descreve nossa submissão ao CoNLL UD Shared Task 2018. Estendemos uma rede neural baseada em LSTM projetada para marcação de sequências para gerar adicionalmente sequências em nível de caractere. A rede foi treinada em conjunto para produzir lemas, tags parciais de fala e características morfológicas. A segmentação de sentença, tokenização e análise de dependência foram tratadas pela linha de base do UDPipe 1.2. Os resultados demonstram a viabilidade da arquitetura multitarefa proposta, embora seu desempenho ainda permaneça longe do estado da arte.', 'hi': 'यह पेपर CoNLL UD Shared Task 2018 के लिए हमारे सबमिशन का वर्णन करता है। हमने एक एलएसटीएम-आधारित तंत्रिका नेटवर्क का विस्तार किया है जो अतिरिक्त रूप से चरित्र-स्तर के अनुक्रमों को उत्पन्न करने के लिए अनुक्रम टैगिंग के लिए डिज़ाइन किया गया है। नेटवर्क को संयुक्त रूप से लेमा, पार्ट-ऑफ-स्पीच टैग और रूपात्मक विशेषताओं का उत्पादन करने के लिए प्रशिक्षित किया गया था। वाक्य विभाजन, टोकनीकरण और निर्भरता पार्सिंग UDPipe 1.2 बेसलाइन द्वारा नियंत्रित किए गए थे। परिणाम प्रस्तावित मल्टीटास्क आर्किटेक्चर की व्यवहार्यता को प्रदर्शित करते हैं, हालांकि इसका प्रदर्शन अभी भी अत्याधुनिक से बहुत दूर है।', 'es': 'Este documento describe nuestro envío a CoNll UD Shared Task 2018. Hemos ampliado una red neuronal basada en LSTM diseñada para el etiquetado de secuencias para generar adicionalmente secuencias a nivel de caracteres. La red recibió capacitación conjunta para producir lemas, etiquetas de parte del discurso y características morfológicas. La segmentación de oraciones, la tokenización y el análisis de dependencias fueron manejados por la línea de base UDPipe 1.2. Los resultados demuestran la viabilidad de la arquitectura multitarea propuesta, aunque su rendimiento sigue estando lejos del estado de la técnica.', 'fr': "Cet article décrit notre soumission à ConLL UD Shared Task 2018. Nous avons étendu un réseau de neurones basé sur LSTM conçu pour le marquage de séquences afin de générer en plus des séquences au niveau des caractères. Le réseau a été formé conjointement pour produire des lemmes, des étiquettes de parties du discours et des caractéristiques morphologiques. La segmentation des phrases, la segmentation en jetons et l'analyse des dépendances ont été gérées par UDPipe 1.2 baseline. Les résultats démontrent la viabilité de l'architecture multitâche proposée, même si ses performances sont encore loin d'être à la pointe de la technologie.", 'ru': 'В этой статье описывается наше представление CoNLL UD Shared Task 2018. Мы расширили нейронную сеть на основе LSTM, предназначенную для маркировки последовательностей, чтобы дополнительно генерировать последовательности на уровне символов. Сеть была совместно обучена изготовлению лемм, тегов части речи и морфологических особенностей. Сегментация предложений, токенизация и синтаксический анализ зависимостей обрабатывались базовой линией UDPipe 1.2. Результаты демонстрируют жизнеспособность предлагаемой многозадачной архитектуры, хотя ее производительность по-прежнему далека от современного уровня.', 'ga': 'Déanann an páipéar seo cur síos ar ár n-aighneacht chuig Tasc Comhroinnte CoNLL UD 2018. Tá síneadh curtha againn le líonra néareolaíoch bunaithe ar LSTM atá deartha le haghaidh clibeáil seichimh chun seichimh ar leibhéal carachtar a ghiniúint freisin. Rinneadh an líonra a chomhoiliúint chun leamaí, clibeanna cuid cainte agus gnéithe moirfeolaíocha a tháirgeadh. Dhéileáil bunlíne UDPipe 1.2 le deighilt pianbhreithe, comharthaíocht agus parsáil spleáchais. Léiríonn na torthaí inmharthanacht na hailtireachta iltascanna atá beartaithe, cé go bhfuil a fheidhmíocht fós i bhfad ó bheith den scoth.', 'el': 'Αυτή η εργασία περιγράφει την υποβολή μας στην κοινή εργασία 2018. Επεκτείναμε ένα νευρωνικό δίκτυο βασισμένο στην LSTM σχεδιασμένο για τη σήμανση ακολουθιών για να παράγουμε επιπλέον ακολουθίες σε επίπεδο χαρακτήρων. Το δίκτυο εκπαιδεύτηκε από κοινού για την παραγωγή λεμμάτων, ετικετών τμημάτων ομιλίας και μορφολογικών χαρακτηριστικών. Η τμηματοποίηση προτάσεων, η επισήμανση και η ανάλυση εξαρτήσεων διαχειρίστηκαν από τη γραμμή βάσης του UDPipe 1.2. Τα αποτελέσματα καταδεικνύουν τη βιωσιμότητα της προτεινόμενης αρχιτεκτονικής πολλαπλών εργασιών, αν και η απόδοσή της εξακολουθεί να απέχει πολύ από την σύγχρονη τεχνολογία.', 'hu': 'Ez a tanulmány bemutatja a CoNLL UD Shared Task 2018-ra való benyújtásunkat. Kiterjesztettünk egy LSTM alapú neurális hálózatot, amelyet szekvencia-címkézésre terveztünk, hogy további karakterszintű szekvenciákat generáljunk. A hálózatot közösen képezték ki lemmák, beszédrészes címkék és morfológiai jellemzők előállítására. A mondatszegmentációt, tokenizációt és függőség elemzését az UDPipe 1.2 alapszintje kezelte. Az eredmények bizonyítják a javasolt többfeladatos architektúra életképességét, bár teljesítménye még mindig messze van a korszerűségtől.', 'it': "Questo articolo descrive la nostra presentazione a CoNLL UD Shared Task 2018. Abbiamo esteso una rete neurale basata su LSTM progettata per il tag di sequenza per generare sequenze a livello di carattere. La rete è stata formata congiuntamente per produrre lemmi, tag part-of-speech e caratteristiche morfologiche. Segmentazione delle frasi, tokenizzazione e analisi delle dipendenze sono state gestite da UDPipe 1.2 baseline. I risultati dimostrano la fattibilità dell'architettura multitask proposta, anche se le sue prestazioni rimangono tutt'altro che all'avanguardia.", 'kk': 'Бұл қағаз 2018 CoNLL UD ортақ тапсырмасына жіберімізді анықтайды. Біз LSTM негіздеген нейрондық желі, таңбаның деңгейі реттеулерін жасау үшін реттеулерді жасау үшін құрылған. Желі лимма, сөйлеу тегтерінің бөлігі мен морфологиялық мүмкіндіктерін жасау үшін біріктірілген. UDPipe 1. 2 негізгі жолдан сөз сегментациясы, токенизация және тәуелдік талдау арқылы өзгертілді. Нәтижелер ұсынылған көп тапсырманың архитектурасының тәжірибесін көрсетеді, бірақ оның әрекеті әлі оның орындау күйінен тыс қалды.', 'ms': 'Kertas ini menggambarkan penghantaran kita ke Tugas Berkongsi CoNLL UD 2018. Kami telah melambangkan rangkaian saraf berasaskan LSTM yang direka untuk tag jujukan untuk menghasilkan jujukan aras-aksara secara tambahan. Rangkaian telah dilatih bersama-sama untuk menghasilkan lemma, sebahagian-tag-ucapan dan ciri-ciri morfologik. Segmen perkataan, tokenization dan penghuraian dependensi telah dikendalikan oleh dasar UDPipe 1.2. Hasilnya menunjukkan kemampuan arkitektur multitugas yang diusulkan, walaupun prestasinya masih jauh dari state-of-the-art.', 'ka': 'ამ დოკუმენტი ჩვენი მომხმარება CoNLL UD-ის გაყოფილი საქმე 2018. ჩვენ LSTM-დაბავშირებული ნეიროლური ქსელის გადაქმნა, რომელიც დამატებით სიმბოლოების შედეგების გადაქმნა. ქსელი იყო ერთადერთად შესწავლობულია ლემების, სიტყვების ნაწილი და მორპოლოგიური ფუნქციების შემქმნა. UDPipe 1.2 ფესმენტის გამოყენებულია სიტყვების სექმენტირება, ტოკენიზაცია და დამხოლოების პანუზაცია. წარმოდგენები გამოჩვენებენ მრავალრამეტური არქტიქტურის ცხოვრება, მაგრამ მისი წარმოდგენება უფრო დიდ იქნება ხელსაწარმოდგენებისგან.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ കോണ്\u200dഎല്\u200d യുഡി പങ്കെടുത്ത പണിയിലേക്ക് കൊടുക്കുന്നത് വിവരിക്കുന്നു. സെക്കന്\u200dസ് ടാഗിങ്ങിന് വേണ്ടി നിര്\u200dമ്മിക്കപ്പെട്ട ഒരു LSTM-അടിസ്ഥാനത്തുള്ള നെയൂറല്\u200d നെറുല്\u200d നെറുല്\u200d നെറുല്\u200d നെറ്റോ ലെമ്മാസ്, സംസാരിക്കുന്നതിന്റെ ഭാഗവും മോര്\u200dഫോളിക്കല്\u200d ഗുണഗണങ്ങളും ഉല്\u200dപാദിപ്പിക്കാനുള്ള നെറ്റര്\u200dനെറ് ശിക്ഷ വേര്\u200dപെര്\u200dമെന്\u200dഷന്\u200d, സ്ഥിരതയും ആശ്രയിക്കുന്നതും യുഡിപിപ്പി 1. 2 ബെസ്ലൈന്\u200d കൈകാര്യം ചെയ്തു. The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.', 'lt': 'Šiame dokumente apibūdinamas mūsų pranešimas CoNLL UD bendros užduoties 2018 m. Mes išplėtėme LSTM pagrįstą nervinį tinklą, suprojektuotą sekos žymėjimui, kad papildomai būtų sukurtos simbolių lygio sekos. Tinklas buvo bendrai apmokytas gaminti citrinų, kalbos dalių ženklų ir morfologinių savybių. Sentencijų segmentaciją, tokenizaciją ir priklausomybės analizavimą tvarkė UDPipe 1,2 pradinė analizė. The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.', 'mn': 'Энэ цаас бидний CoNLL UD-ын 2018 оны хуваалтын ажлыг тайлбарладаг. Бид LSTM-ээр суурилсан мэдрэлийн сүлжээг нэмэлтэй хэмжээний дарааллыг бүтээх зорилготой. Холбооны сүлжээнд лимм, ярианы нэг хэсэг болон морфологик чанарыг бүтээх боломжтой болсон. UDPipe 1.2 суурь шугам дээр өгүүлбэл хэвлэл, тодорхойлолт болон хамааралтай хуваалцах нь зориулагдсан. Үүний үр дүнд олон ажлын архитектурын амьдралыг харуулж байна. Гэхдээ үүний үйл ажиллагаа урлагийн байгууллагаас хол байдаг.', 'no': 'Denne papiret beskriver vårt oppføring til CoNLL UD-delt oppgåve 2018. Vi har utvida eit LSTM-basert neuralnettverk designert for sekvensmerking for å laga tillegg teiknkombinasjonar. Nettverket vart kopla trent til å produsera limmar, del av taletaggar og morfologiske funksjonar. UDPipe 1.2 baseline handlerte uttrykk, tokenisering og tolking av avhengighet. Resultatet viser det første fleiroppgåve-arkitekturen, selv om utviklinga sitt fortsatt er langt frå kunsttilstanden.', 'mk': 'Овој весник го опишува нашето поднесување на CoNLL UD Shared Task 2018. We have extended an LSTM-based neural network designed for sequence tagging to additionally generate character-level sequences.  Мрежата беше заеднички обучена да произведува лимаси, делови од говорот и морфолошки карактеристики. Сегментацијата на речениците, токенизацијата и анализирањето на зависноста беа управувани со UDPipe 1.2 основна вредност. Резултатите ја покажуваат животноста на предложената мултизадачна архитектура, иако нејзината перформанса сé уште е далеку од најновата.', 'pl': 'Niniejszy artykuł opisuje naszą zgłoszenie do CoNLL UD Shared Task 2018. Rozszerzyliśmy sieć neuronową opartą na LSTM przeznaczoną do tagowania sekwencji, aby dodatkowo generować sekwencje na poziomie znaków. Sieć została wspólnie przeszkolona do produkcji lemmas, tagów częściowych i cech morfologicznych. Segmentacja zdań, tokenizacja i parsowanie zależności były obsługiwane przez bazę bazową UDPipe 1.2. Wyniki pokazują możliwość realizacji proponowanej architektury wielozadaniowej, chociaż jej wydajność jest daleka od najnowocześniejszej technologii.', 'ro': 'Această lucrare descrie trimiterea noastră la CoNLL UD Shared Task 2018. Am extins o rețea neuronală bazată pe LSTM concepută pentru etichetarea secvențelor pentru a genera în plus secvențe la nivel de caractere. Rețeaua a fost instruită în comun pentru a produce lemme, etichete part-of-speech și caracteristici morfologice. Segmentarea sentințelor, tokenizarea și analizarea dependențelor au fost gestionate de UDPipe 1.2 baseline. Rezultatele demonstrează viabilitatea arhitecturii multitask propuse, deși performanțele sale rămân departe de a fi de ultimă generație.', 'sr': 'Ovaj papir opisuje naše podnošenje CoNLL UD zajedničkom zadatku 2018. Proširili smo na LSTM baziranu neuralnu mrežu dizajniranu za označavanje sekvencije da dodatno stvorimo sekvence nivoa karaktera. Mreža je zajedno obučena da proizvodi limme, deo govornih znakova i morfološke karakteristike. Segmentacija, tokenizacija i analiza zavisnosti rešila je UDPipe 1.2 početna linija. Rezultati pokazuju životinju predložene multizadatačne arhitekture, iako je njegova izvedba još uvijek daleko od države umjetnosti.', 'si': 'මේ පැත්තේ අපේ පිළිගන්නේ කොන්ල් UD කොටස් 2018 වලට කැමතියි. අපි LSTM අධාරිත න්\u200dයූරල් ජාලයෙක් විස්තර කරලා තියෙන්නේ පරික්ෂණ පරික්ෂණය සඳහා පරික්ෂණ පරික්ෂණය සඳ ජාලය සම්බන්ධ විදියට ලෙම්මාස්, කතාවේ කොටස් ටැග් හා මෝර්ෆෝලෝජික විශේෂතාවක් නිර්මා UDPipe 1.2 බේස්ලායින් වචන සැකසුම්, ටොකෙනිස් සහ අවශ්\u200dය විශ්ලේෂණය පරීක්ෂණය කරලා තියෙනවා. ප්\u200dරතිචාරය පෙන්වන්න පුළුවන් වැඩි වැඩි වැඩි වැඩි වැඩක් ස්ථාපනයේ ජීවත්වය පෙන්වන්න, ඒකේ වැඩේ තාම', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjoni tagħna lil CoNLL UD Shared Task 2018. Estendijna netwerk newrali bbażat fuq LSTM iddisinjat għat-tikkettar tas-sekwenzi biex jiġġenera wkoll sekwenzi fil-livell tal-karattri. In-netwerk kien imħarreġ b’mod konġunt biex jipproduċi limmi, tikketti ta’ parti mid-diskors u karatteristiċi morfoloġiċi. Is-segmentazzjoni tas-sentenzi, it-tokenizzazzjoni u l-analiżi tad-dipendenza ġew immaniġġjati minn UDPipe 1.2 linja bażi. Ir-riżultati juru l-vijabbiltà tal-arkitettura multikompitu proposta, għalkemm il-prestazzjoni tagħha għadha 'l bogħod mill-aħħar.", 'so': 'Warqadan waxaa ku qoran warqaddayada loo soo dhiibay CoNLL UD oo lagu sharciyey shaqo 2018. Waxaan fidinnay shabakad neurada ah oo LSTM ku saleysan, taasoo loo qoray hab-tagging si ay u kordhiso xaraf-darajada. The network was jointly trained to produce lemmas, part-of-speech tags and morphological features.  Xiliga maxkamadda, bandhigga xubnaha iyo baaritaanka ku xiran waxaa lagu maamulaa saldhigga UDPipe 1.2. Abaalkeedu waxay muujiyaan suurtagalka dhismaha la soo jeeday wax badan, in kastoo ay sameyntoodu weli ka fog tahay dowladda farshaxanka.', 'ur': 'یہ کاغذ کاغذ کائنال UD شریک ٹاکس 2018 کے لئے ہماری اطاعت کرتا ہے. ہم نے ایک LSTM بنیاد نیورل نیٹ ورک کو اضافہ کرنے کے لئے طراحی کیا ہے تاگ کے لئے علامت سطح سطح کے پیدا کرنے کے لئے۔ نیٹورک ایک ساتھ لیمز، بولنے کے ٹاگ اور مورفولوژیکوں کے پیدا کرنے کے لئے آموزش کی گئی تھی. UDPipe 1.2 بنسٹلین کے ذریعہ ویڈیس سپٹیٹ، ٹوکنیزی اور اعتمادی پارسینگ کے ذریعہ تحت نظر کیا گیا۔ نتیجے پیشنهاد کی ملتی ٹاکس معماری کے قابلیت کو دکھاتے ہیں، اگرچہ اس کی عملی ابھی هنر کی حالت سے دور رہتی ہے.', 'ta': 'இந்த காகிதத்தில் கோNLL UD பகிர்ந்த பணிக்கு எங்கள் submissionை குறிப்பிடுகிறது. நாங்கள் ஒரு LSTM-அடிப்படையிலான நெருக்கல் வலைப்பின்னலை விரிவாக்கியுள்ளோம். தொடர் குறிப்புகளை கூடுதலாக எழுத்து- நில Name வாக்குறுக்குப் பிரிவு, குறிப்பிடுதல் மற்றும் சார்பு பாடல் UDPipe 1. 2 அடிப்படைக்கோடு கையாளிக்கப்பட்டது. முடிவுகள் பரிந்துரைக்கப்பட்ட பல்கல் கேள்வி கட்டுப்பாட்டின் விருப்பத்தை காட்டுகிறது, ஆனாலும் அதன் செயல்பாடு இன்னும் த', 'sv': 'Denna uppsats beskriver vårt bidrag till CoNLL UD Shared Task 2018. Vi har utökat ett LSTM-baserat neuralt nätverk som utformats för sekvensmärkning för att dessutom generera sekvenser på karaktärsnivå. Nätverket utbildades gemensamt för att producera lemmer, deltal taggar och morfologiska egenskaper. Sentensegmentering, tokenisering och beroendetolkning hanterades av UDPipe 1.2 baseline. Resultaten visar att den föreslagna flerfunktionsarkitekturen är genomförbar, även om dess prestanda fortfarande är långt ifrån toppmodern.', 'uz': "Bu qogʻoz CONLL UD bilan bog'liq vazifani tahrirlash mumkin. Biz qoʻshimcha harf- darajasini yaratish uchun tarmoqni yaratdik. Name Name Natijalar quyidagi multitask maktablarining imkoniyatlarini ko'rsatadi, ammo ularning bajarishi davlatdan uzoq.", 'vi': 'Tờ giấy này mô tả sự chịu trách nhiệm chia sẻ của chúng ta cho CoNLL UD A8. Chúng tôi đã mở rộng một mạng lưới thần kinh dựa trên LSD được thiết kế để hiệu ứng chuỗi để thêm tạo ra các dãy mực ký tự. Mạng lưới được huấn luyện cùng nhau để sản xuất lemmmas, một phần của ngôn ngữ và các yếu tố lịch sự. Bộ phân loại cảm xúc, hiệu ứng và phân tách phụ thuộc đã được xử lý bởi UDPipe 1.2 cơ bản. Kết quả chứng minh khả năng của kiến trúc đa nhiệm đã được đề nghị, mặc dù trình độ của nó vẫn còn xa lắm.', 'bg': 'Тази статия описва нашето представяне на Споделена задача 2018. Разширихме базирана на LSTM невронна мрежа проектирана за маркиране на последователности, за да генерираме допълнително последователности на ниво символи. Мрежата беше съвместно обучена да произвежда леми, част от речта етикети и морфологични характеристики. Сегментацията на изреченията, токенизацията и анализирането на зависимостта бяха обработени от базовата линия на UDPipe 1.2. Резултатите показват жизнеспособността на предложената многозадача архитектура, въпреки че изпълнението й все още е далеч от най-съвременните.', 'nl': "Dit document beschrijft onze inzending aan CoNLL UD Shared Task 2018. We hebben een LSTM-gebaseerd neuraal netwerk uitgebreid dat ontworpen is voor sequence tagging om extra sequenties op karakterniveau te genereren. Het netwerk werd gezamenlijk getraind om lemma's, part-of-speech tags en morfologische kenmerken te produceren. Zinnsegmentatie, tokenizatie en afhankelijkheidsparsing werden afgehandeld door UDPipe 1.2 baseline. De resultaten tonen de haalbaarheid van de voorgestelde multitask architectuur aan, hoewel de prestaties nog ver van de stand van de techniek blijven.", 'hr': 'Ovaj papir opisuje naše podnošenje CoNLL UD zajedničkom zadatku 2018. Proširili smo na LSTM baziranu neuralnu mrežu dizajniranu za označavanje sekvencije kako bi dodatno stvorili sekvence nivoa karaktera. Mreža je zajedno obučena kako bi proizvela limme, dijelogovorne etikete i morfološke funkcije. Segmentacija, tokenizacija i analiza ovisnosti rešila su UDPipe 1.2 početna linija. Rezultati pokazuju živototvornost predložene multizadatačne arhitekture, iako je njegova učinka još uvijek daleko od države umjetnosti.', 'da': 'Dette dokument beskriver vores indsendelse til CoNLL UD Shared Task 2018. Vi har udvidet et LSTM-baseret neuralt netværk designet til sekvensmærkning til yderligere at generere sekvenser på karakterniveau. Netværket blev i fællesskab uddannet til at producere lemmaer, del-of-speech tags og morfologiske træk. Sætningssegmentering, tokenisering og afhængighedsanalyse blev håndteret af UDPipe 1.2 baseline. Resultaterne viser levedygtigheden af den foreslåede multitask-arkitektur, selv om dens ydeevne stadig er langt fra state-of-the-art.', 'de': 'Dieses Papier beschreibt unsere Einreichung an CoNLL UD Shared Task 2018. Wir haben ein LSTM-basiertes neuronales Netzwerk für Sequenz-Tagging erweitert, um zusätzlich Zeichensequenzen zu generieren. Das Netzwerk wurde gemeinsam in der Herstellung von Lemmen, Sprachteiltags und morphologischen Merkmalen geschult. Satzsegmentierung, Tokenisierung und Abhängigkeitsparsing wurden von UDPipe 1.2 Baseline abgewickelt. Die Ergebnisse belegen die Tragfähigkeit der vorgeschlagenen Multitask-Architektur, obwohl ihre Leistung noch weit vom Stand der Technik entfernt ist.', 'id': 'This paper describes our submission to CoNLL UD Shared Task 2018.  Kami telah memperluas jaringan saraf berdasarkan LSTM yang dirancang untuk penandaian urutan untuk tambahan menghasilkan urutan karakter-level. The network was jointly trained to produce lemmas, part-of-speech tags and morphological features.  Segmen hukuman, tokenization dan penghuraian dependensi ditangani oleh UDPipe 1.2 dasar. Hasilnya menunjukkan kemampuan arsitektur multitask yang diusulkan, meskipun prestasinya masih jauh dari state-of-the-art.', 'tr': "Bu käze biziň CoNLL UD'yň 2018-nji ýyldaky paýlaşdyrylşymyzy tassyýar. Biz LSTM tabanly näral aýry ekledik, karakter derejesini yzarlamak üçin taýýarlanan tägler üçin saýlanan. Aýry limmalar, sözlerin bölegi we morfolojik özelliklerini üretmek üçin birleşik eğitildi. UDPipe 1.2 baseline tarapyndan çykylýar Netijiler teklip eden çoklu işgär arhitekteginiň ýaşaýyşlygyny görkezýär, ýöne onuň etkinlik şol ýagdaýyň durumyndan daşda durup ýok.", 'ko': '이 문서에서는 CoNLL UD 공유 작업 2018에 제출된 파일을 설명합니다.시퀀스 태그를 사용하여 문자급 시퀀스를 추가로 생성하는 LSTM 기반 신경 네트워크를 확장했습니다.이 네트워크는 인용, 어성 라벨, 형태학적 특징을 형성하기 위해 연합 훈련을 받는다.문장 분할, 표기화 및 의존성 분석은 UDPipe 1.2 베이스라인에서 처리됩니다.그 결과 제시된 다중 임무 체계 구조의 타당성을 증명했다. 비록 그 성능은 여전히 가장 선진적인 수준에 이르지 못했지만.', 'af': "Hierdie papier beskryf ons onderskrywing na CoNLL UD Gedeelde Taak 2018. Ons het 'n LSTM-gebaseerde neuralnetwerk ontwerp vir sekwensiemerking om byvoeg karaktervlak sekwensies te genereer. Die netwerk was saamstig opgelei om lemmas, deel van spraak etikette en morfologiese funksies te produseer. Soektog segmentasie, tokenisasie en afhanklikheidverwerking is gehandel deur UDPipe 1. 2 basislien. Die resultate bevestig die lewendigheid van die voorgestelde multitaak-arkitektuur, alhoewel sy prestasie nog ver van die staat van die kuns bly.", 'sq': 'Ky dokument përshkruan paraqitjen tonë në CoNLL UD Task Shared 2018. Kemi zgjeruar një rrjet nervor bazuar në LSTM të dizajnuar për shënimin e sekuencës në gjenerimin shtesë të sekuencave të nivelit të karakterit. Rrjeti u trajnua së bashku për të prodhuar limma, pjesë të etiketave të fjalimit dhe karakteristika morfologjike. Segmentimi i dënimeve, tokenizimi dhe analizimi i varësisë u trajtuan nga UDPipe 1.2 bazë. Rezultatet demonstrojnë jetueshmërinë e arkitekturës së propozuar të shumëdetyrave, megjithëse performanca e saj mbetet ende larg nga më e larta.', 'am': 'ይህም ገጽ ለኮንLL UD ስራ 2018 የተሰራጨውን መልዕክታችንን ይናገራል፡፡ የ LSTM-based የኔural መረብ አሰፋንለታል፡፡ መረብ በኩል ተማርቷል፡፡ የሥርዓት ክፍል፣ ማስታወቂያ እና የመደገፊያ ፓርቲ በUDPipe 1.2 baseline የተደረገ ነው፡፡ The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.', 'hy': 'Այս հոդվածը նկարագրում է մեր ներկայացումը ԿՈՆԼ UD 2018 թվականին ընդհանուր հանձնարարությանը: Մենք ընդլայնել ենք LSMT-ով հիմնված նյարդային ցանցը, որը ստեղծվել է հաջորդականության նշանների նշանների համար, որպեսզի նաև ստեղծենք բնավորական մակարդակի հաջորդականություններ: Համակարգը միասին ուսուցանված էր լեմմա, խոսքի մասերի և մորֆոլոգիական հատկությունների արտադրելու համար: Դարտահայտությունների սեգմետրացիան, տոկինիզացիան և կախվածությունների վերլուծումը վերահսկվում էին UDPipe 1.2 հիմքի միջոցով: Արդյունքները ցույց են տալիս առաջարկված բազմախնդիրների ճարտարապետության կենսունակությունը, չնայած, որ դրա արտադրողությունը դեռևս հեռու է նորաձևից:', 'az': 'Bu kağıt 2018-ci CoNLL UD paylaşılmış iş işimizi təsdiqləyir. Biz LSTM tabanlı nöral şəbəkəsini artıq karakter səviyyəsini yaratmaq üçün dizayn edilmişik. Ağ limmas, sözlərin bir parçasını və morfolojik özelliklərini ürəkləmək üçün birlikdə təhsil edildi. Sözlük segmentasyonu, tokenizaciju və bağlılıq ayırılması UDPipe 1.2 səhifəsi ilə idarə edildi. Sonuçlar təbliğ edilmiş çoxlu iş arhitektarının yaşamlığını göstərir. Halbuki onun performansı hələ də art ıqlıq eyaletindən uzaq durur.', 'bn': 'এই পত্রিকাটি আমাদের কএনএল উডি শেয়ার করা কাজ ২০১৮-এর প্রতি প্রতিষ্ঠান বর্ণনা করেছে। আমরা এলস্টিএম ভিত্তিক নিউরেল নেটওয়ার্ক বিস্তৃত করেছি যার জন্য সেকেন্স ট্যাগিং নির্মাণ করা হয়েছে যাতে অক্ষর-স্তরের স এই নেটওয়ার্ক একত্রে প্রশিক্ষণ প্রদান করা হয়েছিল ল লেমমাস, ভাষণের অংশ এবং মরোফোলিক্যাল বৈশিষ্ট্য। শাস্তি বিভক্ত, অঙ্গীকার এবং নির্ভরশীল পার্সিং দ্বারা ইউডিপিপি ১. এর ফলাফল প্রস্তাবিত মাল্টিউটিক্যাটিক্যালেক্টারের বিশ্বাসযোগ্য প্রদর্শন করে, যদিও তার প্রতিষ্ঠান এখনো রাষ্ট্র-শিল্প', 'bs': 'Ovaj papir opisuje naše podnošenje CoNLL UD zajedničkom zadatku 2018. Proširili smo na LSTM baziranu neuralnu mrežu dizajniranu za označavanje sekvencije da dodatno proizvedemo sekvence nivoa karaktera. Mreža je zajedno obučena da proizvodi limme, dijelogovorne etikete i morfološke funkcije. Segmentacija kazna, tokenizacija i analizacija ovisnosti vodila je UDPipe 1.2 početna linija. Rezultati pokazuju živototvornost predložene multizadatačne arhitekture, iako je njegova učinka još uvijek daleko od države umjetnosti.', 'sw': 'Gazeti hili linaelezea ujumbe wetu wa chama cha CoNLL UD kilichoshirikishwa na kazi 2018. Tumeeneza mtandao wa neura wa LSTM ulioandaliwa kwa ajili ya viungo vya mfululizo ili kutengeneza mfululizo wa kiwango cha tabia. Mtandao huo ulifundishwa pamoja kwa ajili ya kutengeneza viungo, sehemu ya viungo vya hotuba na vipengele vya kifolojia. Mgawanyo wa hukumu, utambulisho na parge ya kutegemea ulikabiliwa na UDPipe 1.2 msingi. The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.', 'fa': 'این کاغذ تحویل ما به کار مشترک CoNLL UD ۲۰۱۸ را توصیف می\u200cکند. ما یک شبکه عصبی بر اساس LSTM را گسترش دادیم که طراحی شده است برای ترکیب ترکیب برای تولید ترکیب سطح شخصیت. شبکه با همدیگر آموزش داده شده است تا آفرینش لیمز، قسمتی از نقاشی سخنرانی و ویژه های مورفولوژیک را تولید کند. قطعه\u200cبندی، توکین\u200cبندی و تقسیم بستگی از خط پایین UDPipe 1.2 تحت کنترل قرار گرفته است. نتیجه\u200cها ثابت قابلیت معماری پیشنهاد چندین کار را نشان می\u200cدهند، اگرچه عملکرد آن هنوز دور از ایالت هنری است.', 'cs': 'Tento článek popisuje náš předložení CoNLL UD Shared Task 2018. Rozšířili jsme neuronovou síť založenou na LSTM určenou pro značení sekvencí, abychom dodatečně generovali sekvence na úrovni znaků. Síť byla společně vyškolena na výrobu lemmů, značek části řeči a morfologických rysů. Segmentace vět, tokenizace a analýza závislostí byly zpracovány pomocí základního principu UDPipe 1.2. Výsledky ukazují životaschopnost navržené víceúlohové architektury, ačkoli její výkon stále zůstává daleko od nejmodernějšího stavu.', 'fi': 'Tässä artikkelissa kuvataan, miten toimitamme CoNLL UD Shared Task 2018 -ohjelmaan. Olemme laajentaneet LSTM-pohjaista neuroverkkoa, joka on suunniteltu sekvenssimerkkausta varten luodaksemme lisäksi merkkitason sekvensseja. Verkosto koulutettiin yhdessä tuottamaan lemmoja, puheen osatunnisteita ja morfologisia piirteitä. Lausekkeiden segmentointia, tokenisointia ja riippuvuuksien jäsentämistä käsitteli UDPipe 1.2 -perusaikataulu. Tulokset osoittavat ehdotetun monitehtäväarkkitehtuurin elinkelpoisuuden, vaikka sen suorituskyky on vielä kaukana tekniikan tasosta.', 'ca': "Aquest paper descriu la nostra presentació a CoNLL UD Shared Task 2018. Hem extinguit una xarxa neuronal basada en LSTM dissenyada per etiquetar seqüències per generar més seqüències de nivell de caràcter. La xarxa va ser formada conjuntament per produir limoses, etiquetes de parla i característiques morfològiques. La segmentació de sentences, la tomenització i l'analització de la dependencia van ser gestionades per UDPipe 1,2 basal. Els resultats demostren la viabilitat de l'arquitectura multitasca proposada, tot i que el seu rendiment encara està lluny de l'actualitat.", 'et': 'Käesolevas artiklis kirjeldatakse meie esitamist CoNLL UD Shared Task 2018. Oleme laiendanud LSTM-põhist närvivõrku, mis on loodud järjestuste märgistamiseks, et luua täiendavalt märgitasemel järjestusi. Võrgustikku koolitati ühiselt lemmade, kõneosade siltide ja morfoloogiliste tunnuste tootmiseks. Lause segmenteerimist, tokeniseerimist ja sõltuvuse parsimist käsitles UDPipe 1.2 algväärtus. Tulemused näitavad kavandatud mitmeülesandelise arhitektuuri elujõulisust, kuigi selle tulemused jäävad veel kaugele tehnika tasemest.', 'jv': 'Perintah iki rambarang nggawe nyimpen CoNLL UT Habang Tabah Bawih-Bawih (task) Awak dhéwé wis luwih akeh KST-basan seneng alat sing dibenalke nggo sekondi, dadi nambah kanggo nambah layar-layar seneng layar. Jejaring structural navigation Rejaleng wong liyane wis ngerasakno kanggo ngerasakno akeh multitask sing supoyo, sanes ngono nggawe barang durung-durung-karang.', 'ha': 'Wannan takardan na bayyana sallama zuwa CoNLL UD Shared Aiki 2018. Mun shimfiɗa wani jerin neural na LTRM wanda aka ƙayyade wa masu sakan tagogi don a ƙara da ya zata fassarar-daraja. An sanar da shi tare da shirin haɗi dõmin ya zaɓi limma, rabon tagogi na magana da shiryoyin mutfologi. Tsarawa da aka yi zartar da cewa, shirin ayuka da parse mai inganci na rubutu na UDP 1.2 Haƙĩƙa, matsala na nuna abincin matsayin da aka buƙace multitaskin, kuma ingawa bajariyarsa yana da bada mai nĩsa daga state-of-the-art.', 'he': 'העיתון הזה מתאר את ההעברה שלנו למשימה משותפת של CoNLL UD 2018. הרשת העצבית המבוססת על LSTM התוכננה לתג רצף כדי ליצור באופן נוסף רצפי רמת האופים. הרשת היתה מאומנת ביחד כדי ליצור לימוס, חלק מהדיבורים ותחומים מורפולוגיים. סגמנציה של משפטים, טקניזציה ומחקר תלויות טיפלו על ידי UDPipe 1.2 בסיסי. התוצאות מראות את היציאות של הארכיטקטורה המועמדת המוצעת, למרות שהביצועים שלה עדיין רחוקים מהמצב החדש.', 'sk': 'Ta prispevek opisuje našo predložitev CoNLL UD Shared Task 2018. Razširili smo nevronsko omrežje, ki temelji na LSTM, zasnovano za označevanje zaporedja, da dodatno ustvarimo zaporedja na ravni znakov. Mreža je bila skupaj usposobljena za izdelavo lemm, delovnih oznak govora in morfoloških značilnosti. Segmentacijo stavkov, žetonizacijo in razčlenjevanje odvisnosti so obravnavali v osnovni vrsti UDPipe 1.2. Rezultati kažejo uspešnost predlagane večopravilne arhitekture, čeprav njena uspešnost še vedno ni najsodobnejša.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་རྣམ་པ་CoNLL UD ལ་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་2018་ལ་འགྲེལ་བཤད་པ We have extended an LSTM based neural network designed for sequence tagging to additionally generate character-level sequences. དྲ་བ་འདི་ལྟ་བུའི་ནང་དུ་limmas(lemmas)དང་། part-of-speech(tags)དང་། morphological ཆ་འབྲེལ་བ་མང་ཙམ་སྦྱར་བ་བསླབས་བྱས་ཡོད། Sentence segmentation, tokenization and dependency parsing were handled by UDPipe 1.2 baseline. གྲུབ་འབྲས་འདི་དག་གི་སྔོན་སྒྲིག་འཇུག་སྣེ་མང་བོའི་གནས་སྟངས་ལ་འཚོ་བ་སྟོན་པ་ཡིན།'}
{'en': 'CUNI x-ling : Parsing Under-Resourced Languages in CoNLL 2018 UD Shared Task', 'ar': 'CUNI x-ling: تحليل اللغات منخفضة الموارد في المهمة المشتركة CoNLL 2018 UD', 'es': 'CUNI x-ling: Análisis de idiomas con pocos recursos en la tarea compartida de UD de CoNll 2018', 'fr': 'CUNI x-ling\xa0: Analyse des langues sous-ressources dans la tâche partagée UD ConLL 2018', 'pt': 'CUNI x-ling: analisando idiomas com poucos recursos na tarefa compartilhada CoNLL 2018 UD', 'ja': 'CUNI x - ling: CoNLL 2018 UD共有タスクでのリソース不足の言語の解析', 'hi': 'CUNI x-ling: CoNLL 2018 UD साझा कार्य में अंडर-रिसोर्स्ड भाषाओं को पार्स करना', 'zh': 'CUNI x-ling: CoNLL 2018 UD 共事解析资不足之言', 'ru': 'CUNI x-ling: анализ недофинансируемых языков в CoNLL 2018 UD Shared Task', 'ga': 'CUNI x-ling: Teangacha Faoin Acmhainní á bParsáil i dTasc Comhroinnte UD CoNLL 2018', 'ka': 'CUNI x-ling: რესურსის დამატებული ენები CoNLL 2018-ში UD shared Task', 'el': 'CUNI x-ling: Ανάλυση γλωσσών που δεν διαθέτουν πόρους σε κοινή εργασία', 'hu': 'CUNI x-ling: Alacsony erőforrású nyelvek értelmezése a CoNLL 2018 UD megosztott feladatban', 'it': 'CUNI x-ling: Analisi delle lingue poco risorse in CoNLL 2018 UD Shared Task', 'lt': 'CUNI x-ling: Paruošimas nepakankamai išteklių turinčiomis kalbomis CoNLL 2018 UD bendra užduotis', 'mk': 'CUNI x-ling: Анализирање на јазици со недоволни ресурси во CoNLL 2018 UD споделена задача', 'kk': 'CUNI x- ling: CoNLL 2018 бағытталған тілдерді талдау UD ортақ тапсырмасы', 'ms': 'CUNI x-ling: Menghurai Bahasa Bawah Sumber dalam Tugas Berkongsi CoNLL 2018 UD', 'ml': 'സിയുണിഐ എക്സ്- ലിംഗ്: കോണ്\u200dഎല്\u200d 2018 യുഡി പങ്കെടുത്ത ജോലി', 'mn': 'CUNI x-ling: CoNLL 2018-д UD хуваалцаагүй үйл ажиллагаанд бага-сан хэл талбарлах', 'mt': 'CUNI x-ling: Parsing Under-Resourced Languages in CoNLL 2018 UD Shared Task', 'no': 'CUNI x-ling: Tolking underressurserte språk i CoNLL 2018 UD delt oppgåve', 'ro': 'CUNI x-ling: Analizarea limbilor subresursate în sarcina partajată CoNLL 2018 UD', 'pl': 'CUNI x-ling: Parsowanie niedostatecznie zasobów języków w CoNLL 2018 UD Shared Task', 'sr': 'CUNI x-ling: Analiza podresursnih jezika u CoNLL 2018 UD zajedničkom zadatku', 'so': 'CUNI x-ling: Parsing Under-Resourced Languages in CoNLL 2018 UD Shared Task', 'sv': 'CUNI x-ling: Tolkning av underresurser i CoNLL 2018 UD delad uppgift', 'si': 'CUNI x-ling: CoNLL 2018 දී UD කොටස් වැදගත්ත භාෂාවට පරීක්ෂණය', 'ur': 'CUNI x-ling: CoNLL 2018 UD Shared Task میں کم-Resourced Languages Parsing', 'ta': 'CUNI x- ling: கோன்எல் 2018 UD பகிர்ந்த பணி', 'vi': 'Công việc chia sẻ với mục đích:', 'uz': 'Comment', 'nl': 'CUNI x-ling: Parsen van onvoldoende beschikbare talen in CoNLL 2018 UD Shared Task', 'hr': 'CUNI x-ling: Analiza podresursnih jezika u CoNLL 2018 UD zajedničkom zadatku', 'da': 'CUNI x-ling: Fortolkning af underressourcerede sprog i CoNLL 2018 UD delt opgave', 'bg': 'Разглеждане на недостатъчно ресурсни езици в споделена задача', 'id': 'CUNI x-ling: Menghurai Bahasa Dibawah Sumber Dalam CoNLL 2018 UD Bagi Tugas', 'de': 'CUNI x-ling: Parsing under resourced languages in CoNLL 2018 UD Shared Task', 'fa': 'CUNI x-ling: تحلیل زبانهای زیر منبع در کار مشترک UD در CoNLL 2018', 'sw': 'CUNI x-ling: Kucheza lugha za chini ya rasilimali nchini CoNLL 2018 UD ilishiriki kazi', 'tr': "CUNI x-ling: CoNLL 2018'de CoNLL'de Taýýarlan Diller", 'af': 'Kuni x-ling: Onderhulpbron Taal in CoNLL 2018 UD Gedeelde Taak', 'sq': 'CUNI x-ling: Analizimi i gjuhëve të pakufishme në CoNLL 2018 UD Task Shared', 'am': 'CUNI x-ling: Parsing Under-Resourced Languages in CoNLL 2018 UD Shared Task', 'hy': 'Cuhni x-ling. ԿոՆԼL 2018 թվականին UD ընդհանուր խնդիր', 'az': 'CUNI x-ling: CoNLL 2018-də, UD paylaşılmış iş dilləri analiz edilir', 'bn': 'সিউনিI এক্স- লিং: কনএল ২০১৮ সালে অন্তর্ভুক্ত ভাষাগুলো পার্সিং করা হচ্ছে', 'bs': 'CUNI x-ling: Analiza podresursnih jezika u CoNLL 2018 UD zajedničkom zadatku', 'ca': 'CUNI x-ling: Analitzar llengües sense recursos a CoNLL 2018 UD Task Shared', 'cs': 'CUNI x-ling: Parsování nedostatečně zdrojovaných jazyků v CoNLL 2018 UD Shared Task', 'ko': 'CUNI x-ling: CoNLL 2018 UD 공유 작업 중 리소스가 부족한 언어 해석', 'et': 'CUNI x-ling: Alaressurssidega keelte parsimine CoNLL 2018 UD jagatud ülesandes', 'fi': 'CUNI x-ling: Vähävaraisten kielten analysointi CoNLL 2018 UD Shared Task', 'jv': 'CUNI x', 'ha': 'KCharselect unicode block name', 'sk': 'CUNI x-ling: Razčlenitev jezikov s premalo virov v skupni nalogi CoNLL 2018 UD', 'he': 'CUNI x-ling: Parsing Under-Resourced Languages in CoNLL 2018 UD Shared Task', 'bo': 'CUNI x-ling CoNLL 2018 ནང་དུ་མཐུན་སྤྱོད་པའི་སྐད་ཡིག་གཙང་བཤད་པ'}
{'en': 'This is a system description paper for the CUNI x-ling submission to the CoNLL 2018 UD Shared Task. We focused on parsing under-resourced languages, with no or little training data available. We employed a wide range of approaches, including simple word-based treebank translation, combination of delexicalized parsers, and exploitation of available morphological dictionaries, with a dedicated setup tailored to each of the languages. In the official evaluation, our submission was identified as the clear winner of the Low-resource languages category.', 'ar': 'هذه ورقة وصف نظام لتقديم CUNI x-ling إلى المهمة المشتركة لـ CoNLL 2018 UD. ركزنا على تحليل اللغات منخفضة الموارد ، مع عدم توفر بيانات تدريبية أو القليل منها. لقد استخدمنا مجموعة واسعة من الأساليب ، بما في ذلك ترجمة بنك الشجرة البسيط القائم على الكلمات ، ومجموعة من المحللات اللغوية ، واستغلال القواميس الصرفية المتاحة ، مع إعداد مخصص مصمم خصيصًا لكل لغة من اللغات. في التقييم الرسمي ، تم تحديد تقديمنا على أنه الفائز الواضح بفئة اللغات منخفضة الموارد.', 'fr': "Ceci est un document de description du système pour la soumission CUNI x-ling à la tâche partagée ConLL 2018 UD. Nous nous sommes concentrés sur l'analyse des langues sous-ressources, avec peu ou pas de données de formation disponibles. Nous avons utilisé un large éventail d'approches, y compris la traduction simple de banques d'arbres basée sur des mots, la combinaison d'analyseurs délexicalisés et l'exploitation des dictionnaires morphologiques disponibles, avec une configuration dédiée adaptée à chacune des langues. Lors de l'évaluation officielle, notre soumission a été clairement identifiée comme la gagnante de la catégorie des langues à faibles ressources.", 'es': 'Este es un documento de descripción del sistema para la presentación de x-ling de CUNI a la Tarea Compartida UD de CoNll 2018. Nos centramos en analizar idiomas con pocos recursos, sin datos de entrenamiento disponibles o con pocos datos de capacitación disponibles. Empleamos una amplia gama de enfoques, incluida la traducción simple de bancos de árboles basada en palabras, la combinación de analizadores delicados y la explotación de diccionarios morfológicos disponibles, con una configuración específica adaptada a cada uno de los idiomas. En la evaluación oficial, nuestro envío fue identificado como el claro ganador de la categoría de idiomas de bajos recursos.', 'pt': 'Este é um documento de descrição do sistema para o envio CUNI x-ling para a Tarefa Compartilhada CoNLL 2018 UD. Nós nos concentramos em analisar linguagens com poucos recursos, sem ou com poucos dados de treinamento disponíveis. Empregamos uma ampla gama de abordagens, incluindo tradução simples de banco de palavras baseada em palavras, combinação de analisadores deslexicalizados e exploração de dicionários morfológicos disponíveis, com uma configuração dedicada adaptada a cada um dos idiomas. Na avaliação oficial, nossa submissão foi identificada como a vencedora clara da categoria Idiomas de poucos recursos.', 'ja': 'これは、CoNLL 2018 UD Shared TaskへのCuNi x -lingサブミッションのシステム記述論文です。私たちは、利用可能なトレーニングデータがほとんどない、またはほとんどない、リソース不足の言語の解析に焦点を当てました。私たちは、単純な単語ベースのツリーバンク翻訳、非フレキシカル化された構文解析器の組み合わせ、利用可能な形態辞書の活用など、幅広いアプローチを採用し、それぞれの言語に合わせた専用のセットアップを採用しました。公式評価では、当社の提出物が低資源言語カテゴリの明確な受賞者として特定されました。', 'zh': '此一系统描述文,用于 CoNLL 2018 UD 共享提交 CUNI x-ling。 专解析资源贫乏语,无或少训练可用。 博采之法,略于单词之树库译,合exicalized解析器之组,因可用之形词典,及为每言量身制者专用之。 官方评估,定为低资言语之明赢家。', 'hi': 'यह CoNLL 2018 UD साझा कार्य करने के लिए CUNI x-ling सबमिशन के लिए एक सिस्टम विवरण कागज है। हमने अंडर-रिसोर्स्ड भाषाओं को पार्स करने पर ध्यान केंद्रित किया, जिसमें कोई या बहुत कम प्रशिक्षण डेटा उपलब्ध नहीं है। हमने सरल शब्द-आधारित ट्रीबैंक अनुवाद, delexicalized पार्सर के संयोजन, और उपलब्ध रूपात्मक शब्दकोशों के शोषण सहित दृष्टिकोणों की एक विस्तृत श्रृंखला को नियोजित किया, जिसमें प्रत्येक भाषा के अनुरूप एक समर्पित सेटअप शामिल है। आधिकारिक मूल्यांकन में, हमारे सबमिशन को कम संसाधन भाषाओं की श्रेणी के स्पष्ट विजेता के रूप में पहचाना गया था।', 'ru': 'Это документ с описанием системы для представления CUNI x-ling в CoNLL 2018 UD Shared Task. Мы сосредоточились на анализе языков, не обеспеченных достаточными ресурсами, с отсутствием или малым объемом данных об обучении. Мы использовали широкий спектр подходов, включая простой перевод деревьев на основе слов, комбинацию делексикализованных парсеров и использование доступных морфологических словарей с специальной настройкой, адаптированной к каждому из языков. В официальной оценке наша заявка была определена как явный победитель в категории «Языки с ограниченными ресурсами».', 'ga': 'Is páipéar tuairisce córais é seo le haghaidh aighneacht x-ling CUNI chuig Tasc Comhroinnte 2018 UD CoNLL. Dhíríomar ar pharsáil teangacha gann-acmhainní, gan aon sonraí oiliúna ar fáil, nó beagán sonraí oiliúna. D’úsáideamar raon leathan de chur chuige, lena n-áirítear aistriú crann crann focal-bhunaithe simplí, teaglaim de pharsálaithe díleicseála, agus saothrú na bhfoclóirí moirfeolaíocha a bhí ar fáil, le socrú tiomnaithe a bhí in oiriúint do gach ceann de na teangacha. Sa mheastóireacht oifigiúil, aithníodh ár n-aighneacht mar bhuaiteoir soiléir sa chatagóir teangacha Íseal-acmhainne.', 'hu': 'Ez egy rendszerleíró tanulmány a CUNI x-ling benyújtásához a CoNLL 2018 UD megosztott feladathoz. Az alacsony erőforrásokkal rendelkező nyelvek elemzésére összpontosítottunk, ahol nincsenek vagy kevés képzési adatok. A megközelítések széles skáláját alkalmaztuk, beleértve az egyszerű szóalapú fabank fordítást, a delexikalizált elemzők kombinációját és a rendelkezésre álló morfológiai szótárak kiaknázását, az egyes nyelvekhez igazított speciális beállításokkal. A hivatalos értékelés során a pályázatunkat az Alacsony forrású nyelvek kategóriájának egyértelmű győzteseként határozták meg.', 'el': 'Αυτό είναι ένα έγγραφο περιγραφής συστήματος για την υποβολή CUNI x-ling στην κοινή εργασία CoNLL 2018 UD. Εστιάσαμε στην ανάλυση γλωσσών που δεν διαθέτουν πόρους, χωρίς να υπάρχουν ή λίγα διαθέσιμα δεδομένα κατάρτισης. Χρησιμοποιήσαμε ένα ευρύ φάσμα προσεγγίσεων, συμπεριλαμβανομένης της απλής λέξης-βασισμένης στη μετάφραση δέντρων, του συνδυασμού απεξαρτημένων αναλύσεων και της αξιοποίησης των διαθέσιμων μορφολογικών λεξικών, με μια ειδική ρύθμιση προσαρμοσμένη σε κάθε μία από τις γλώσσες. Στην επίσημη αξιολόγηση, η υποβολή μας αναγνωρίστηκε ως ο σαφής νικητής της κατηγορίας γλωσσών χαμηλής περιεκτικότητας.', 'kk': 'Бұл CUNI x- ling тапсырмасын CoNLL 2018 UD ортақ тапсырмасына жүйелік сипаттамасы қағазы. Біз ресурсты тілдерді талдау үшін көңіл көмектесдік. Қолданбаған немесе кішкентай оқыту деректері жоқ. Біз әрбір тілдерге өзгертілген морфологиялық сөздерді қолдану үшін көпшілік жағдайлардың аудармасын жұмыс істедік. Төмен ресурс тілдерінің санатын таңдау үшін оқытуымыз керек болды.', 'ka': 'ეს არის სისტემის გამოსახულება CUNI x-ling მისამართლად CoNLL 2018 UD shared Task. ჩვენ დავუყენებდით რესურსურსი ენების პანუსაციას, რომლებიც არაფერი ან ცოტა მონაცემების მონაცემები არაა. ჩვენ დავამუშავეთ უფრო პარამეტრები, რომელიც სიტყვების სახელსაწყოფილი სიტყვების გაგრძელება, დელექსიკალიზებული პარამეტრების კომბიზაცია და მოსახლეობის მოპოროლოგიური სიტყვების გამოყენება,  ჩვენი წარმოდგენება განსაზღვრებულია, როგორც ჩვენი წარმოდგენება ჩემი წარმოდგენება კატეგორია ბალ რესურსის ენების წარმოდგენებელი.', 'it': "Questo è un documento di descrizione del sistema per l'invio di CUNI x-ling al CoNLL 2018 UD Shared Task. Ci siamo concentrati sull'analisi delle lingue con scarse risorse, senza dati di formazione disponibili o scarsi. Abbiamo utilizzato una vasta gamma di approcci, tra cui la semplice traduzione di treebank basata su parole, la combinazione di parser delessicalizzati e lo sfruttamento dei dizionari morfologici disponibili, con un setup dedicato su misura per ciascuna delle lingue. Nella valutazione ufficiale, il nostro contributo è stato identificato come il chiaro vincitore della categoria Lingue a basso contenuto di risorse.", 'lt': 'Tai sistemos aprašymo dokumentas, skirtas CUNI x-ling pateikimui CoNLL 2018 UD bendrai užduočiai. We focused on parsing under-resourced languages, with no or little training data available.  We employed a wide range of approaches, including simple word-based treebank translation, combination of delexicalized parsers, and exploitation of available morphological dictionaries, with a dedicated setup tailored to each of the languages.  Oficialiame vertinime mūsų pasiūlymas buvo nustatytas kaip aiškus žemų išteklių kalbų kategorijos laimėtojas.', 'ml': 'കോണ്\u200dഎല്\u200d 2018 യുഡി പങ്കെടുത്ത പണിയിലേക്ക് സിയുണി എക്സ്-ലിംഗിന്റെ വിശദീകരണ പേപ്പറാണിത്. വിഭവങ്ങളിലുള്ള ഭാഷകളില്\u200d പാര്\u200dസിങ്ങ് ചെയ്യുന്നതിനെക്കുറിച്ച് ഞങ്ങള്\u200d ശ്രദ്ധിച്ചിരിക്കുന് ഞങ്ങള്\u200d ഒരു വിശാലമായ വഴികള്\u200d ഉപയോഗിച്ചു, എളുപ്പമായ വാക്ക് അടിസ്ഥാനമായ ട്രീബാങ്കിന്\u200dറെ പരിഭാഷകള്\u200d, ഡെനിക്സിക്സിക്കല്\u200d പാര്\u200dസരുകളുടെ കൂട്ടത്തില്\u200d, ലഭ്യമായ മൊര ഓഫീസല്\u200d വിലാസങ്ങളില്\u200d, നമ്മുടെ സന്ദേശം കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകളുടെ വിഭാഗവിഭാഗത്തിലെ വ്യക്തമായ വിജയിയായി', 'mk': 'Ова е документ за опис на системот за пренесување на CUNI x-ling во CoNLL 2018 UD Shared Task. Се фокусиравме на анализирање на јазиците со недоволни ресурси, без достапни или мали податоци за обука. Употребивме голем број пристапи, вклучувајќи едноставен превод на дрвја базиран на зборови, комбинација на делексикализирани анализатори, и експлоатација на достапните морфолошки речници, со посветена поставка прилагодена на секој од јазиците. Во официјалната оценка, нашето поднесување беше идентификувано како јасен победник на категоријата на јазици со ниски ресурси.', 'ms': 'Ini adalah kertas keterangan sistem untuk penghantaran x-ling CUNI kepada Tugas Berkongsi UD CoNLL 2018. Kami fokus pada hurai bahasa-bahasa bawah-sumber, tanpa atau sedikit data latihan tersedia. Kami menggunakan jangkauan yang luas pendekatan, termasuk terjemahan pangkalan pokok berdasarkan perkataan sederhana, kombinasi penghurai-hurai deleksikal, dan penggunaan kamus morfologik yang tersedia, dengan seting dedikasi yang disesuaikan untuk setiap bahasa. Dalam penilaian rasmi, penghantaran kami dikenali sebagai pemenang jelas kategori bahasa-sumber rendah.', 'mt': 'Dan huwa dokument ta’ deskrizzjoni tas-sistema għas-sottomissjoni ta’ x-ling tal-CUNI lill-Kompitu Konġunt tal-UD CoNLL 2018. Aħna ffukajna fuq l-analiżi tal-lingwi b’riżorsi baxxi, bl-ebda dejta jew ftit dejta ta’ taħriġ disponibbli. Aħna impjegajna firxa wiesgħa ta’ approċċi, inklużi traduzzjoni sempliċi bbażata fuq il-kliem tas-siġar, kombinazzjoni ta’ analizzaturi delessikalizzati, u sfruttament ta’ dikjararji morfoloġiċi disponibbli, b’struttura ddedikata mfassla għal kull waħda mil-lingwi. Fl-evalwazzjoni uffiċjali, is-sottomissjoni tagħna ġiet identifikata bħala r-rebbieħa ċara tal-kategorija tal-lingwi b’riżorsi baxxi.', 'mn': 'Энэ бол CUNI Х-лингийн CoNLL 2018-н UD хуваалтын ажлын хуваалцааны системийн тодорхойлолтын цаас юм. Бид бага болон бага сургалтын мэдээллийг ашиглахгүй хэлний талаар анхаарлаа төвлөрсөн. Бид олон олон арга зам ашиглаж, мөн энгийн үг дээр суурилсан зам хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн холбоотой, мөн ашиглах морфологик сөрөгчийн хөгжлийн хэрэглээ, хэ Эрийн оюутнуудын шалгалтын тулд бидний давтамжлалт нь бага боловсролын хэлний хэлний тодорхой ялагч гэж тодорхойлдог.', 'no': 'Dette er eit systemskildring papir for CUNI x-ling-tilføring til CoNLL 2018 UD-delt oppgåve. Vi fokuserte på tolking av underressurserte språk, med ingen eller lite treningsdata tilgjengelege. Vi arbeida eit stor rekke tilnærmingar, inkludert enkelt ordbasert treebank-omsetjing, kombinasjon av deleksisaserte tolkarar, og ekspluatering av tilgjengelege morfologiske ordbokar, med ein spesifisert oppsett tilpassa kvar av språka. I den offisielle evalueringa ble vårt oppføring identifisert som den klare vinner i kategorien for lavressursspråk.', 'pl': 'Jest to dokument opisu systemu dla zgłoszenia CUNI x-ling do CoNLL 2018 UD Shared Task. Skupiliśmy się na analizie niedostatecznie zasobów języków, z brakiem lub małą ilością dostępnych danych szkoleniowych. Zastosowaliśmy szeroki zakres podejść, w tym proste tłumaczenie bazy drzew oparte na słowach, połączenie deleksykalizowanych parserów oraz eksploatację dostępnych słowników morfologicznych, z dedykowaną konfiguracją dostosowaną do każdego z języków. W oficjalnej ocenie nasz wniosek został zidentyfikowany jako wyraźny zwycięzca kategorii języków niskich zasobów.', 'ro': 'Acesta este un document de descriere a sistemului pentru depunerea CUNI x-ling la CoNLL 2018 UD Shared Task. Ne-am concentrat pe analizarea limbilor cu resurse insuficiente, fără date de instruire disponibile sau puține. Am folosit o gamă largă de abordări, inclusiv traducerea simplă bazată pe cuvinte, combinația de parsere delexicalizate și exploatarea dicționarelor morfologice disponibile, cu o configurație dedicată adaptată fiecărei limbi. În evaluarea oficială, depunerea noastră a fost identificată drept câștigătorul clar al categoriei de limbi cu resurse reduse.', 'sr': 'Ovo je papir za opis sistema za podnošenje CUNI x-ling na zadatak CoNLL 2018. Fokusirali smo se na analizu jezika pod resursima, bez dostupnih ili manjih podataka o obuci. Zaposlili smo širok niz pristupa, uključujući jednostavan prevod na rečima, kombinaciju deleksikaliziranih parsera, i ekspluataciju dostupnih morfoloških rečenika, sa posvećenim setom koji je pripremljen svakom od jezika. U službenoj procjeni, naša predstava je identifikovana kao jasni pobednik kategorije jezika niskih resursa.', 'si': 'මේක CUNI x-ling එකේ CoNLL 2018 UD කොටස් එක්ක වැදගත්ත වැඩකට පද්ධති විස්තර කාරණයක්. අපි ප්\u200dරශ්නයක් නැති භාෂාවක් පරීක්ෂණය කරනවා, පොඩි ප්\u200dරශ්නයක් නැති තොරතුරු නැති කියලා. අපි විශාල විශාල ප්\u200dරවේශනයක් කළා, සරල වචනය අධාරිත වචනය සම්පූර්ණ වචනය සම්පූර්ණ වචනය සම්පූර්ණ වචනය සම්පූර්ණ වචනය සම්පූර අධාරික විශ්ලේෂණයේ අපේ පිළිබඳින්න පුළුවන් භාෂාවන්ගේ පැහැදිලි ජයග්\u200dරාහකයා කියලා තියෙනව', 'so': 'Kanu waa warqad ku qoran qoraalka nidaamka ee CUNI x-ling oo u soo diraya shaqo la sharciyey CoNLL 2018 UD. Waxaynu ku kalsoonaannay baaritaanka luuqadaha hoos-nololeed, oo aan helin macluumaad waxbarasho yar ama wax yar. Waxaannu shaqeynay qaabab badan oo badan, kuwaas oo ah turjumid fudud oo ku qoran qoraal-qori ah, kooxa baarlamayaasha deleksikal ah, iyo isticmaalka luqadaha qofka oo dhan ku qoran. Markaas qiimeynta rasmiga ah waxaa loo xaqiijiyey soo diritaankayada sida guul u muuqda luqada hoose-resourceyaasha.', 'sv': 'Detta är en systembeskrivning för CUNI x-ling-inlämningen till CoNLL 2018 UD Shared Task. Vi fokuserade på att tolka underresurserade språk, med ingen eller lite utbildningsdata tillgänglig. Vi använde ett brett spektrum av tillvägagångssätt, inklusive enkel ordbaserad treebank översättning, kombination av delexikaliserade parsers och utnyttjande av tillgängliga morfologiska ordböcker, med en dedikerad inställning anpassad till vart och ett av språken. I den officiella utvärderingen identifierades vårt bidrag som den tydliga vinnaren av kategorin Lågresursspråk.', 'ta': 'இது CUNI x- லிங் கோன்எல் 2018 UD பகிர்ந்த பணிக்கான முறைமை விவரிப்பு தாள். நாங்கள் மூலத்திற்கு கீழே பாடல் மொழிகளை கவனம் செலுத்துகிறோம், இல்லை அல்லது சிறிய பயிற்சி தகவல் இல்லை. நாங்கள் நிறைய முறைமைகளை பயன்படுத்தினோம், எளிதான வார்த்தையில் மொழிமாற்றி, பிரிந்திசைப்படுத்தப்பட்ட பார்சர்கள், மற்றும் கிடைக்கக்கூடிய மொழிக்கான Official evaluation, our submission was identified as the clear winner of the Low-resource language category.', 'ur': 'یہ CUNI x-ling مہمانی کے لئے ایک سیسٹم کا سفارش کاغذ ہے CoNLL 2018 UD Shared Task کے لئے. ہم نے کم رسسورٹ زبانوں کو پارس کرنے پر تمرکز کیا تھا، کوئی یا تھوڑی آموزش دیٹا موجود نہیں ہے۔ ہم نے بہت سی طریقے کے مطابق استعمال کیا تھا، یہاں تک کہ کلمات کی بنیادی تریب بانک کی ترجمہ، ڈیلکسکسیکسیکسیکسیزی پارس کی ترجمہ، اور موجود موفورلوجی لکھنے والی لکھنے والی لکھنے والی مطابق، ہر زبان کے لئے ایک خاص سٹاپ کے رسمی ارزیابی میں، ہماری اطلاعات کم رسورس زبان کاٹی کی واضح جیت کے طور پر پہچان کی گئی تھی.', 'uz': "Name Biz murabbiy tilida bir ta\xa0ľminlovchi ma\xa0ľlumot yo\xa0Ľq, yoki kichkina ta\xa0ľminlovchi ma\xa0ľlumot yo\xa0Ľq. Biz oddiy so'zlar uchun treebank tarjima qilish, deleksikatsiya parserlarni birlashtirish, mavjud morfologik lug\xa0Ľatlarini ishlatish va har bir tillarda qo'llangan qo'llanmalarni ishlatdik. Hujjatni tasavvur qilishda, bizning jo\xa0Ľnatishimiz qanchalik rasm turlarining ko'proq muvaffaqiyatli deb aniqlangan.", 'vi': 'Đây là một tờ mô tả hệ thống cho đơn trình phụ thuộc vào hoạt động kép đôi CoNLL 208 UD chia. Chúng tôi tập trung vào phân tích ngôn ngữ thiếu nguồn, không có hay ít dữ liệu đào tạo. Chúng tôi đã sử dụng một loạt các phương pháp rộng rãi, bao gồm dịch ba chiều đơn giản, kết hợp các phân tích tâm thần học, và khai thác các từ điển hình sẵn sàng, với một thiết lập đặc biệt được chỉnh sửa cho mỗi ngôn ngữ. Trong cuộc đánh giá chính thức, bài phát biểu của chúng tôi được xác định là người thắng cuộc rõ ràng của hạng ngôn ngữ hạn.', 'bg': 'Това е документ за описание на системата за представяне на КУНИ x-линг към споделената задача на КоНЛ 2018 UD. Фокусирахме се върху анализирането на недостиг на ресурси езици, без налични или малко данни за обучение. Използвахме широк спектър от подходи, включително прост превод на думи, комбинация от делексикализирани анализатори и използване на налични морфологични речници, със специална настройка, съобразена с всеки един от езиците. В официалната оценка нашето предложение беше определено като явен победител в категорията Езици с нисък ресурс.', 'nl': 'Dit is een systeembeschrijvingspapier voor de CUNI x-ling indiening aan de CoNLL 2018 UD Shared Task. We concentreerden ons op het parsen van talen met weinig of weinig trainingsgegevens. We gebruikten een breed scala aan benaderingen, waaronder eenvoudige woordgebaseerde boombankvertaling, combinatie van gedexexicaliseerde parsers en exploitatie van beschikbare morfologische woordenboeken, met een speciale opstelling op maat van elke taal. In de officiële evaluatie werd onze inzending geïdentificeerd als de duidelijke winnaar van de categorie Low-resource talen.', 'da': 'Dette er en systembeskrivelse af CUNI x-ling-indsendelsen til CoNLL 2018 UD Shared Task. Vi fokuserede på at analysere underressourcer sprog, uden nogen eller få træningsdata tilgængelige. Vi anvendte en bred vifte af tilgange, herunder simpel ordbaseret treebank oversættelse, kombination af delekskaliserede parsere og udnyttelse af tilgængelige morfologiske ordbøger, med en dedikeret opsætning skræddersyet til hvert af sprogene. I den officielle evaluering blev vores indsendelse identificeret som den klare vinder af kategorien lav ressource sprog.', 'hr': 'Ovo je papir za opis sustava za podnošenje CUNI x-ling u CoNLL 2018 UD zajednički zadatak. Fokusirali smo se na analizu jezika pod resursima, bez dostupnih ili manjih podataka o obuci. Zaposlili smo širok niz pristupa, uključujući jednostavan prevod na riječima baziran treebank, kombinaciju deleksikaliziranih parsera i iskorištavanje dostupnih morfoloških dictionara, s posvećenim setom prilagođenim svakom od jezika. U službenoj procjeni, naša predstava je identifikovana kao jasni pobjednik kategorije jezika niskih resursa.', 'de': 'Dies ist ein Systembeschreibungspapier für die CUNI x-ling Einreichung an die CoNLL 2018 UD Shared Task. Wir konzentrierten uns auf das Parsen von unzureichend ausgestatteten Sprachen, wobei keine oder nur wenige Trainingsdaten verfügbar waren. Wir verwendeten eine breite Palette von Ansätzen, einschließlich einfacher wortbasierter Baumbankübersetzung, Kombination von delexikalisierten Parsern und Nutzung verfügbarer morphologischer Wörterbücher, mit einem dedizierten Setup, das auf jede der Sprachen zugeschnitten ist. In der offiziellen Bewertung wurde unsere Einreichung als klarer Gewinner der Kategorie Niedrige Ressourcen Sprachen identifiziert.', 'fa': 'این یک کاغذ توصیف سیستم برای تسلیم CUNI x-ling به کار مشترک CoNLL 2018 است. ما روی بررسی زبانهای زیر منبع تمرکز کردیم، بدون داده های آموزش یا کمی موجود نیستند. ما یک مجموعه از طریق\u200cهای گسترده استخدام کردیم، شامل ترجمه\u200cهای ترجمه\u200cای ساده بر اساس کلمه\u200cها، ترجمه\u200cای از بازرسان\u200cهای حذف\u200cکننده\u200cای، و استفاده از لغوی\u200cهای مورفولوژیکی موجود، با یک تنظیم ویژه\u200cای که برای هر زبان آماده شده است. در ارزیابی رسمی، تحویل ما به عنوان برنده آشکار زبان\u200cهای زیر منبع شناسایی شد.', 'id': 'Ini adalah kertas deskripsi sistem untuk pengiriman CUNI x-ling ke CoNLL 2018 UD Shared Task. Kami fokus pada menghurai bahasa-bahasa bawah sumber daya, tanpa atau sedikit data pelatihan tersedia. Kami menggunakan jangkauan luas pendekatan, termasuk terjemahan batang pohon berdasarkan kata sederhana, kombinasi parser-parser deleksi, dan eksploitasi kamus morfologi yang tersedia, dengan seting dedikasi yang disesuaikan untuk setiap bahasa. Dalam evaluasi resmi, pengiriman kami diidentifikasi sebagai pemenang jelas dari kategori bahasa sumber daya rendah.', 'ko': '이는 CoNLL 2018 UD 공유 임무에 제출된 CUNI x-ling 시스템 설명서입니다.우리는 자원이 부족한 언어를 분석하는 데 전념하고, 쓸만한 훈련 데이터가 없거나 거의 없다.우리는 간단한 단어 기반의 트리 라이브러리 번역, 탈사화 해석기의 조합, 사용 가능한 형태 사전을 활용하여 각 언어에 대한 전문적인 설정을 제공하는 광범위한 방법을 채택했다.공식 평가에서 우리가 제출한 자료는 저자원 언어 유형의 뚜렷한 승자로 확정되었다.', 'sw': 'Hii ni karatasi ya maelezo ya mfumo kwa kutuma ujumbe wa CUNI x-ling kwa ajili ya CoNLL 2018 UD Kushirikishwa. Tulijikita kwenye kuimba lugha zenye rasilimali, bila taarifa ndogo ya mafunzo. Tulitumia mbinu mbalimbali, ikiwa ni pamoja na tafsiri rahisi ya mitebank yenye maneno, pamoja na bunge la mbunge waliotengenezwa, na matumizi ya lugha za kisemolojia zinazopatikana, yenye seti maalum iliyochukuliwa kwa kila lugha. Katika tathmini rasmi, ujumbe wetu ulitambuliwa kama mshindi wa wazi wa lugha za chini za rasilimali.', 'tr': 'Bu CUNI x-ling göndermesi üçin sistem waspy CoNLL 2018 UD Paýlaşy Gözme üçin. Biz golaý dilleriň aşagynda ýa-da kiçi bilim maglumaty bar diýip üns berdik. Biz birnäçe golaý golaýlary ýüze çykardyk, hem basit sözleriň daýanýan treebank terjimeleri we deleksikalizýän çykyşçylaryň birleşmesi we meňzeş morfolojik sözleriň ulanmagyny we dilleriň her biri üçin beýleki düzümlenmesi bilen ulandyk. Resmi çözümlerde, biziň teslim edişimiz düşük resurslar dili kategoriýasynyň düşük ýeňiji diýip kabul edildi.', 'am': 'ይህ CUNI x-ling ለCONLL 2018 UD የተሰራጨው ስራ የሚያደርግ የስርዓት መግለጫ ገጽ ነው፡፡ በሀብት ቋንቋዎች ላይ ማጋራት እና ምንም ወይም ትንሽ ትምህርት ማድረግ ሳይኖር ተማርከናል፡፡ በቋንቋዎች ሁሉ ላይ በተለየ የተመሳሳይ የቴርቢባን ትርጉም፣ የሜልስክሲካዊ ፓርራርስ ማቀናቀል እና የሞፎሎጂ መዝገብ እና የተገኘውን አካባቢዎች እና የቋንቋዎች በተለየ ቁጥጥር እና በተለየን ጥያቄ እና በተለየን ጥያቄ አካሄድን አቀረብን። In the official evaluation, our submission was identified as the clear winner of the Low-resource languages category.', 'sq': 'Ky është një dokument përshkrimi i sistemit për paraqitjen e CUNI x-ling në CoNLL 2018 UD Task Shared. Ne u përqëndruam në analizimin e gjuhëve të dobëta me burime, pa asnjë apo pak të dhëna trajnimi në dispozicion. Ne përdorëm një gamë të gjerë metodash, duke përfshirë përkthimin e thjeshtë të bazuar në fjalë, kombinimin e analizuesve të deleksializuar dhe shfrytëzimin e fjalorëve morfologjikë të disponueshëm, me një strukturë të përkushtuar të përshtatshme për secilën nga gjuhët. Në vlerësimin zyrtar, paraqitja jonë u identifikua si fituesi i qartë i kategorisë gjuhësh me burime të ulta.', 'af': "Hierdie is 'n stelsel beskrywing papier vir die CUNI x- ling onderskrywing na die CoNLL 2018 UD Gedeelde Opdrag. Ons het gefokus op verwerking van onder-hulpbronne tale, met geen of klein onderring data beskikbaar. Ons het 'n wyde reek van toegang gebruik, insluitend eenvoudige woord-gebaseerde treebank vertaling, kombinasie van deleksikaliseerde verwerkers, en uitbreiding van beskikbaar morfologiese woordeboekvorms, met 'n bespesifiseerde opstelling wat vir elkeen van die tale aangestel is. In die offisiele evaluasie is ons onderwerp geïdentifiseer as die duidelike wen van die Laag-hulpbron tale kategorie.", 'hy': 'This is a system description paper for the CUNI x-ling submission to the CoNLL 2018 UD Shared Task.  Մենք կենտրոնացրեցինք թերռեսուրսների լեզուների վերլուծության վրա, առանց կամ քիչ ուսուցման տվյալների: Մենք օգտագործեցինք բազմաթիվ մոտեցումներ, ներառյալ պարզ բառերով հիմնված ծառի թարգմանումը, դելեքսիկալիզացված վերլուծումների համակցությունը և հասանելի մորֆոլոգիական բառարանների օգտագործումը, որտեղ նվիրված կառուցվածք կազմված էր յուրաքանչյուր լեզվի Օրիտական գնահատման ժամանակ մեր ներկայացումը հայտնաբերվել է որպես ցածր ռեսուրսների լեզուների կատեգորիայի պարզ հաղթանակը:', 'bn': 'এটি সিউনিI x-লিং কোন কনএল ২০১৮ উডি শেয়ার করা কাজের জন্য সিস্টেমের বর্ণনা কাগজ। আমরা অনেক সম্পদের ভাষায় পার্সিং করার দিকে মনোযোগ দিয়েছি, কোন প্রশিক্ষণ বা ছোট ট ট্রেনিং ডাটা নেই। আমরা ব্যাপক প্রযুক্তি ব্যবহার করেছি, যার মধ্যে রয়েছে সাধারণ শব্দ ভিত্তিক ত্রিবাঙ্ক অনুবাদ, প্রতিনিধিত্বিত করা পার্সারের সংযোগ এবং প্রত্যেক ভাষার জন্য বিশ আনুষ্ঠানিক মূল্যের মাধ্যমে আমাদের প্রতিষ্ঠান নিম্নলিখিত ভাষার বিভাগের পরিষ্কার বিজয়ী হিসেবে চিহ্নিত', 'az': 'Bu CUNI x-ling göndərməsi üçün sistem tanımlama kağıdı CoNLL 2018 UD paylaşdırılmış işə. Biz çox qüvvətli dilləri analizəyə təhsil etdik, heç bir təhsil veri yoxdur. Biz hər dil üçün müəyyən edilmiş bir quruluş ilə çoxlu tərəflər istifadə etdik. Resmi değerlendirmədə, bizim təklifimiz aşağı ressurs dillərin kategoriyasının açıq-aydın qələbəsi olaraq tanındı.', 'ca': "Aquest és un paper de descripció del sistema per la presentació de CUNI en línia x a la CoNLL 2018 UD Shared Task. Ens vam centrar en analitzar llengües amb menys recursos, sense informació disponible o poca. Vam utilitzar una gran varietat d'enfocaments, incloent traducció simple basada en paraules, combinació d'analitzadors desxitalitzats i explotació de diccionaris morfològics disponibles, amb una configuració específica adaptada a cada una de les llengües. In the official evaluation, our submission was identified as the clear winner of the Low-resource languages category.", 'cs': 'Toto je dokument s popisem systému pro předložení CUNI x-ling do sdílené úlohy CoNLL 2018 UD. Zaměřili jsme se na analýzu nedostatečně vybavených jazyků, přičemž nebyly k dispozici žádné nebo málo údajů o tréninku. Použili jsme širokou škálu přístupů, včetně jednoduchého slovního překladu stromové banky, kombinace delexikalizovaných parserů a využití dostupných morfologických slovníků, se specializovaným nastavením přizpůsobeným každému z jazyků. V oficiálním hodnocení byl náš příspěvek identifikován jako jasný vítěz kategorie Nízké zdroje jazyků.', 'et': 'See on süsteemi kirjeldus CUNI x-ling esitamiseks CoNLL 2018 UD Shared Task. Me keskendusime alaressurssidega keelte parsimisele, kusjuures koolitusandmeid puuduvad või vähe. Me kasutasime mitmesuguseid lähenemisviise, sealhulgas lihtsat sõnapõhist puupanga tõlkimist, deleksikaliseeritud parserite kombinatsiooni ja olemasolevate morfoloogiliste sõnaraamatute kasutamist koos spetsiaalse seadistusega, mis on kohandatud iga keele jaoks. Ametliku hindamise käigus määrati meie esitus kindlaks kui madala ressursiga keelte kategooria selge võitja.', 'fi': 'Tämä on järjestelmäkuvaus CUNI x-ling -julkaisusta CoNLL 2018 UD Shared Task -ohjelmaan. Keskityimme käsittelemään aliresurssoituja kieliä, jolloin koulutustietoja ei ollut saatavilla tai niitä oli vähän. Käytimme laajaa valikoimaa lähestymistapoja, kuten yksinkertaisia sanapohjaisia treebank-käännöksiä, deleksikalisoitujen parserien yhdistelmiä ja saatavilla olevien morfologisten sanakirjojen hyödyntämistä, ja niille on räätälöity erityinen kokoonpano kullekin kielelle. Virallisessa arvioinnissa ehdotuksemme todettiin selvästi voittajaksi Vähävaraiset kielet -kategoriassa.', 'bs': 'Ovo je papir za opis sustava za podnošenje CUNI x-ling u CoNLL 2018 UD zajednički zadatak. Fokusirali smo se na analizu jezika pod resursima, bez dostupnih ili manjih podataka o obuci. Zaposlili smo širok niz pristupa, uključujući jednostavan prevod na riječima, kombinaciju deleksikaliziranih parsera, i ekspluataciju dostupnih morfoloških dictionara, sa posvećenim uspostavljanjem prilagođenim svakom od jezika. U službenoj procjeni, naša predstava je identifikovana kao jasni pobjednik kategorije jezika niskih resursa.', 'jv': "Iki iku sistem Keterangan karo CUNI X Awak dhéwé nglanggar aturan dipunangé kapan-kapan langgar, lan ora ono data sing wis mulasai Awak dhéwé éntuk akeh akeh akeh sampeyan luwih, lan akeh basa gambar n' tarjamahan sing basa gambar, kumpulan karo perusahaan nggunakakno, lan ijol-ijolan diktualisar modorolêk sing wis ana, lan akeh iso nggawe gerakan sampeyan luwih dumadhi sak barêng langa. Nang resmi offisisi sing dipunangé, nggunaké awak dhéwé iso nggawe barang kelas sing perusahaan ning langa banter.", 'he': 'זהו נייר תיאור מערכת עבור ההעברה של CUNI x-ling למשימה המשותפת של CoNLL 2018 UD. התמקדנו באבחן שפות מתחת למקורים, ללא או מעט נתונים אימונים זמינים. שימשנו מגוון רחב של גישות, כולל תרגום פשוט מבוסס על מילים על עץ, שילוב של מעבדות דלקסיקוליזציות, והניצול של מילונים מורפולוגיים זמינים, עם ערכת מוקדשת מתאימה לכל שפה. בהערכה הרשמית, ההצגה שלנו זוהה כמנצח ברור של הקטגוריה של שפות משאבים נמוכות.', 'sk': 'To je opisni dokument sistema za predložitev CUNI x-ling v skupno nalogo UD CoNLL 2018. Osredotočili smo se na razčlenitev jezikov s premalo virov, pri čemer ni na voljo nobenih ali malo podatkov o usposabljanju. Uporabili smo širok spekter pristopov, vključno s preprostim prevajanjem treebank na besedi, kombinacijo deleksikaliziranih razčlenjevalnikov in izkoriščanjem razpoložljivih morfoloških slovarjev, z namensko nastavitvijo, prilagojeno vsakemu od jezikov. V uradni oceni je bila naša prijava opredeljena kot jasna zmagovalka kategorije jezikov z nizkimi viri.', 'ha': "Wannan wata takardar siffarwa na'urar kwamfyuta wa CUNI x-lin da aka aika da shi zuwa the CoNLL 2018 UD wanda aka yi shirin aiki. Mun fokus a kan yin parse da harshen wanda ke ƙarƙasan da aka ci, bã da data mai amfani ko kaɗan ba. We employed a wide range of approaches, including simple word-based treebank translation, combination of delexicalized parsers, and exploitation of available morphological dictionaries, with a dedicated setup tailored to each of the languages.  Daga ƙidãya rasmi, an gane musuluncinmu kamar mai rinjãya na harshen Low-resource.", 'bo': 'འདི་CUNI x-ling CoNLL 2018 UD མཉམ་སྤྱོད་པའི་བྱ་འགུལ་ལ་མ་ལག་གི་འགྲེལ་བཤད་ཀྱི་ཤོག་བུ་རེད། ང་ཚོས་སྤྱོད་མཁན་གཙང་འབོར་བའི་སྐད་ཡིག་ཆ་ལ་རང་ཉིད་ཀྱི་མིའི་ནང་དུ་དམིགས་བསལ་བྱས་པ་ཡིན། We employed a wide range of approaches, including simple word-based treebank translation, combination of delexicalized parsers, and exploitation of available morphological dictionaries, with a dedicated setup tailored to each of the languages. གཞུང་འབྲེལ་གྱི་དཔྱད་འགན'}
{'en': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica : Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'ar': 'التحليل الشامل للصور النحوية ومساهمة المعجم: تحليل تقديم مختبر ONLP إلى المهمة المشتركة لـ CoNLL 2018', 'pt': 'Análise Morfo-Sintática Universal e a Contribuição da Lexica: Analisando o Envio do Laboratório ONLP para a Tarefa Compartilhada CoNLL 2018', 'es': 'Análisis morfosintáctico universal y la contribución de Lexica: análisis de la presentación del laboratorio de ONLP a la tarea compartida de CoNll 2018', 'fr': "L'analyse morpho-syntaxique universelle et la contribution de Lexica\xa0: Analyse de la soumission du laboratoire ONLP à la tâche partagée ConLL 2018", 'ja': 'Universal Morpho - Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'zh': '通形句法解析 Lexica 之献:析 ONLP 实验室以达 CoNLL 2018 共其事', 'hi': 'यूनिवर्सल मॉर्फो-सिंटैक्टिक पार्सिंग और लेक्सिका का योगदान: CONLL 2018 साझा कार्य के लिए ONLP लैब सबमिशन का विश्लेषण करना', 'ru': 'Универсальный морфо-синтаксический анализ и вклад Lexica: анализ представления лаборатории ONLP к общей задаче CoNLL 2018', 'ga': 'Parsáil Uilíoch Morpho-Syntactic agus Ranníocaíocht Lexica: Anailís a dhéanamh ar Aighneacht Saotharlainne ONLP chuig Tasc Comhroinnte CoNLL 2018', 'ka': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'it': 'Analisi Morfo-Sintattica Universale e Contributo di Lexica: Analizzare il Contributo del Laboratorio ONLP al Compito Condiviso CoNLL 2018', 'el': 'Οικουμενική Μορφο-Συντακτική Ανάλυση και η συμβολή της Λεξικής: Ανάλυση της Υποβολής του εργαστηρίου στο Κοινή Εργασία', 'hu': 'Univerzális morfo-szintaktikus értelmezés és a Lexica hozzájárulása: Az ONLP Lab beküldésének elemzése a CoNLL 2018 megosztott feladathoz', 'lt': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'kk': 'Universal Morpho- Syntactic Analysis and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'mk': 'Универзално морфосинтактичко анализирање и придонесот на Лексика: анализирање на поднесувањето на лабораторијата на ОНЛП на заедничката задача CoNLL 2018', 'ml': 'ലെക്സിക്കിയയുടെ പാര്\u200dസിങ്ങും ലോക്സിക്കിയുടെ വിഭാഗം: കോണ്\u200dഎല്\u200d 2018 പങ്കെടുത്ത പണിയിലേക്കുള്ള ONLP ലാബ് സബ്മിഷന്\u200d അന്വേഷ', 'mt': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'no': 'Universal Morpho-Syntactic Analysing and the Contribution of Lexica: Analysing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'mn': 'Universal Morpho-Syntactic Analysis and the Contribution of Lexica: ONLP Lab Submission to the CoNLL 2018 Shared Task', 'ms': 'Penghuraian Universal Morpho-Syntactic and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'pl': 'Uniwersalne analizowanie morfo-syntaktyczne i wkład Lexiki: Analiza zgłoszeń ONLP Lab do CoNLL 2018 Wspólne Zadanie', 'ro': 'Analiza transmiterii laboratorului ONLP la sarcina partajată CoNLL 2018', 'sr': 'Univerzalna morfosintaktička analiza i doprinos leksije: analiziranje podataka laboratorija ONLP-a na zajednički zadatak CoNLL 2018.', 'si': 'Universal Morpho-Synectic Parsing and the Contibution of Lexica: The ONLP Lab SubMisssion to the CoNLL 2018 shared Job', 'sv': 'Universell morfosyntaktisk tolkning och Lexicas bidrag: Analysera inlämningen av ONLP Lab till CoNLL 2018 delad uppgift', 'ta': 'பொதுவான மோர்போ- ஒத்திசைவு பாடல் மற்றும் லெக்சிக்காவின் பொருள்: ONLP Lab Submission to the CONLL 2018 Shared Task', 'so': 'Jaamacadda Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'ur': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'uz': 'Umumiy Morpho- Syntactic parsing va Leksika tarkibi: Analyzing the ONLP Lab Submission to the CONLL 2018 Sharpening Vazifani', 'vi': 'Universal Morpho-Synachal Parsing and the contribution of Lexica: Analyding the UNL Lab subjection to the CoNLL bây bây giờ chia sẻ Task', 'bg': 'Универсално морфо-синтактично анализиране и приносът на Лексика: анализ на представянето на ОНЛП лабораторията в споделената задача', 'da': 'Universal Morpho-Syntaktic Parsing og bidraget fra Lexica: Analyse af ONLP Lab indsendelse til CoNLL 2018 delt opgave', 'nl': 'Universele Morpho-Syntactische Parsing en de bijdrage van Lexica: Analyseren van de ONLP Lab inzending aan het CoNLL 2018 Gedeelde Taak', 'hr': 'Univerzalno razmatranje morfosintaktičke analize i doprinos lijeksije: Analiziranje podataka laboratorija ONLP-a na zajednički zadatak CoNLL 2018.', 'ko': '통용 문법 분석 실험실 2018 문법 분석에 기여', 'id': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'fa': 'تحلیل عمومی مورفو-سنتاکتیک و مشترک لکسیکا: تحلیل تحلیل آزمایشگاه ONLP به کار مشترک CoNLL 2018', 'de': 'Universal Morpho-Syntaktic Parsing und der Beitrag von Lexica: Analyse der ONLP Lab Einreichung an das CoNLL 2018 Shared Task', 'tr': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'sw': 'Uchapishaji wa Morpho-Syntactic Universal Morpho and Contribution of Lexica: Anachambua Ujumbe wa Lab ya ONLP kwa CoNLL 2018', 'af': 'Universele Morpho-Syntaktiese Toepassing en die Deelde Opdrag van Lexica: Analiseer die ONLP Lab Submission na die CoNLL 2018 Gedeelde Opdrag', 'sq': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'hy': 'Համաշխարհային մորֆո-սինտակտիկ վերլուծությունը և Լեքսիկայի ներդրումը. ՕնԼՊ լաբորատորիայի հանձնարարությունների վերլուծումը ԿոՆԼԼ 2018 թվականին կիսված առաջադրանքին', 'bn': 'বিশ্ববিদ্যালয় মোর্ফো-সিন্ট্যাক্টিক পার্সিং এবং লেক্সিকার বিভাগ: কনএল ২০১৮ শেয়ার কর্মসূচিতে ওনএলপি লেব ব বিশ্লেষণ করছে', 'bs': 'Univerzalna morfosintaktička analiza i doprinos Leksike: Analiziranje podataka laboratorija ONLP-a na zajednički zadatak CoNLL 2018.', 'cs': 'Univerzální morfosyntaktické analýzy a přínos Lexiky: Analýza příspěvku ONLP laboratoře do CoNLL 2018 Sdílená úloha', 'et': 'Universaalne morfosüntaktiline parsimine ja Lexica panus: ONLP labori esitamise analüüs CoNLL 2018 jagatud ülesandele', 'am': 'ዓለምአዊ ሞርፎ-Syntactic ማዘጋጀት እና የሎክሲካ ምርጫዎች: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'az': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'ca': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analysing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'fi': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'sk': 'Univerzalno morfo-sintaktično razporejanje in prispevek Lexice: analiza prispevka ONLP laboratorija k skupni nalogi CoNLL 2018', 'he': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task', 'jv': 'Universal', 'ha': 'KCharselect unicode block name', 'bo': 'Universal Morpho-Syntactic Parsing and the Contribution of Lexica: Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task'}
{'en': 'We present the contribution of the ONLP lab at the Open University of Israel to the UD shared task on multilingual parsing from raw text to Universal Dependencies. Our contribution is based on a transition-based parser called ‘yap   yet another parser’, which includes a standalone morphological model, a standalone dependency model, and a joint morphosyntactic model. In the ', 'fr': "Nous présentons la contribution du laboratoire ONLP de l'Open University of Israel à la tâche partagée de l'UD sur l'analyse multilingue du texte brut aux dépendances universelles. Notre contribution est basée sur un analyseur basé sur la transition appelé «\xa0yap — yet another parser\xa0», qui inclut un modèle morphologique autonome, un modèle de dépendance autonome et un modèle morphosyntaxique conjoint. Dans cette tâche, nous avons utilisé l'analyseur de dépendance autonome de yap pour analyser les entrées désambiguguées morphologiquement par UDPipe, et obtenu le score officiel de 58,35 LAS. Dans notre enquête de suivi, nous utilisons yap pour montrer comment l'incorporation de ressources morphologiques et lexicales peut améliorer les performances de l'analyse des dépendances brutes de bout en bout dans le cas d'un langage morphologiquement riche et peu de ressources, l'hébreu moderne. Nos résultats sur l'hébreu soulignent l'importance de Conll-UL, une norme compatible UD pour accéder aux ressources lexicales externes, afin d'améliorer l'analyse UD de bout en bout, en particulier pour les langues riches en morphologie et à faibles ressources. Nous encourageons donc la communauté à créer, convertir ou rendre disponible davantage de lexiques de ce type dans les tâches futures.", 'ar': 'نقدم مساهمة مختبر ONLP في الجامعة المفتوحة في إسرائيل إلى مهمة UD المشتركة بشأن التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. تستند مساهمتنا إلى محلل قائم على الانتقال يسمى "ياب - محلل آخر" ، والذي يتضمن نموذجًا مورفولوجيًا مستقلًا ، ونموذج اعتماد مستقل ، ونموذج مورفوسينتيكتيك مشترك. في المهمة ، استخدمنا محلل التبعية المستقل لـ yap لتحليل المدخلات التي تم توضيحها شكليًا بواسطة UDPipe ، وحصلنا على الدرجة الرسمية 58.35 LAS. في تحقيق المتابعة الخاص بنا ، نستخدم ياب لإظهار كيف أن دمج الموارد المورفولوجية والمعجمية قد يحسن أداء تحليل التبعيات من البداية إلى النهاية في حالة لغة غنية شكليًا وقليلة الموارد ، اللغة العبرية الحديثة . تؤكد نتائجنا حول اللغة العبرية على أهمية CoNLL-UL ، وهو معيار متوافق مع UD للوصول إلى الموارد المعجمية الخارجية ، لتعزيز تحليل UD الشامل ، ولا سيما للغات الغنية شكليًا وقليلة الموارد. وبالتالي نشجع المجتمع على إنشاء أو تحويل أو إتاحة المزيد من هذه المعجم في المهام المستقبلية.', 'pt': "Apresentamos a contribuição do laboratório ONLP da Open University of Israel para a tarefa compartilhada da UD sobre análise multilíngue de texto bruto para dependências universais. Nossa contribuição é baseada em um analisador baseado em transição chamado `yap – ainda outro analisador', que inclui um modelo morfológico autônomo, um modelo de dependência autônomo e um modelo morfossintático conjunto. Na tarefa usamos o analisador de dependência autônomo do yap para analisar a entrada morfologicamente desambiguada pelo UDPipe, e obtivemos a pontuação oficial de 58,35 LAS. Em nossa investigação de acompanhamento, usamos o yap para mostrar como a incorporação de recursos morfológicos e lexicais pode melhorar o desempenho da análise de dependências brutas de ponta a ponta no caso de uma linguagem morfologicamente rica e de poucos recursos, o hebraico moderno . Nossos resultados em hebraico ressaltam a importância do CoNLL-UL, um padrão compatível com UD para acessar recursos lexicais externos, para aprimorar a análise UD de ponta a ponta, em particular para linguagens morfologicamente ricas e com poucos recursos. Assim, incentivamos a comunidade a criar, converter ou disponibilizar mais léxicos desse tipo em tarefas futuras.", 'es': "Presentamos la contribución del laboratorio ONLP de la Universidad Abierta de Israel a la tarea compartida de la UD sobre el análisis multilingüe del texto sin procesar a las dependencias universales. Nuestra contribución se basa en un analizador basado en la transición llamado `yap — yet another parser', que incluye un modelo morfológico independiente, un modelo de dependencia independiente y un modelo morfosintáctico conjunto. En la tarea utilizamos el analizador de dependencias independiente de yap para analizar la entrada desambiguada morfológicamente por UDPipe, y obtuvimos la puntuación oficial de 58.35 LAS. En nuestra investigación de seguimiento, utilizamos yap para mostrar cómo la incorporación de recursos morfológicos y léxicos puede mejorar el rendimiento del análisis de extremo a extremo desde el principio hasta las dependencias en el caso de un lenguaje rico en morfología y pocos recursos, el hebreo moderno. Nuestros resultados en hebreo subrayan la importancia de Conll-UL, un estándar compatible con UD para acceder a recursos léxicos externos, para mejorar el análisis de UD de extremo a extremo, en particular para lenguajes ricos morfológicamente y de bajos recursos. Por lo tanto, alentamos a la comunidad a crear, convertir o poner a disposición más léxica de este tipo en tareas futuras.", 'zh': '我们介绍了以色列开大学ONLP实验室对UD从原始文本到通用靠关系的多言语解析方面的共同任务献。 吾所献者,yap - 一解析器之解析器也;独立者,一形也;独立者,一形句法。 吾以yap独恃解析器来解析由UDPipe消歧义输形,而得58.35 LAS官方分数。 考之后世,以yap示富而乏言希伯来语,形态学与词汇合,原始赖解析。 吾于希伯来语而强CoNLL-UL之要,CoNLL-UL与UD兼容之准,以访问外部词汇资源,以强端到端UD解析,尤于形容丰低资源之言。 是以劝社区创业将来,转给多词典。', 'ja': '私たちは、イスラエルのオープン大学のONLPラボが、RAWテキストからUniversal Dependenciesへの多言語構文解析に関するUD共有タスクに貢献していることを提示します。 私たちの貢献は、遷移ベースの「yap –さらに別の構文解析器」という構文解析器に基づいています。これには、スタンドアロンの形態モデル、スタンドアロンの依存関係モデル、およびジョイントの形態構文モデルが含まれます。 このタスクでは、YAPのスタンドアロン依存構文解析器を使用して、UDPipeによって形態学的に曖昧さを解消された入力を解析し、58.35 LASの公式スコアを取得しました。 フォローアップ調査では、YAPを使用して、形態的リソースと語彙的リソースの組み込みが、形態的に豊富でリソースの少ない言語である現代ヘブライ語の場合、エンドツーエンドの生から依存関係解析のパフォーマンスをどのように向上させるかを示します。 ヘブライ語に関する私たちの結果は、特に形態的に豊富でリソースの少ない言語では、エンドツーエンドのUD構文解析を強化するために、外部の語彙リソースにアクセスするためのUD互換性のある標準であるCoNLL - ULの重要性を強調しています。 したがって、コミュニティは、将来のタスクでこのような辞書を作成、変換、またはより多く利用できるようにすることを奨励します。', 'hi': "हम इसराइल के ओपन विश्वविद्यालय में ONLP प्रयोगशाला के योगदान को यूडी के लिए यूनिवर्सल निर्भरताओं के लिए कच्चे पाठ से बहुभाषी पार्सिंग पर साझा कार्य करने के लिए प्रस्तुत करते हैं। हमारा योगदान एक संक्रमण-आधारित पार्सर पर आधारित है जिसे 'याप - अभी तक एक और पार्सर' कहा जाता है, जिसमें एक स्टैंडअलोन रूपात्मक मॉडल, एक स्टैंडअलोन निर्भरता मॉडल और एक संयुक्त मॉर्फोसिंटैक्टिक मॉडल शामिल है। कार्य में हमने यूडीपाइप द्वारा रूपात्मक रूप से विघटित इनपुट को पार्स करने के लिए याप के स्टैंडअलोन निर्भरता पार्सर का उपयोग किया, और 58.35 एलएएस का आधिकारिक स्कोर प्राप्त किया। हमारी अनुवर्ती जांच में हम यह दिखाने के लिए yap का उपयोग करते हैं कि कैसे रूपात्मक और लेक्सिकल संसाधनों का समावेश एक रूपात्मक रूप से समृद्ध और कम संसाधन भाषा, आधुनिक हिब्रू के मामले में पार्सिंग के अंत-से-अंत कच्चे-से-निर्भरताओं के प्रदर्शन में सुधार कर सकता है। हिब्रू पर हमारे परिणाम CoNLL-UL के महत्व को रेखांकित करते हैं, जो बाहरी लेक्सिकल संसाधनों तक पहुंचने के लिए एक UD-संगत मानक है, विशेष रूप से रूपात्मक रूप से समृद्ध और कम-संसाधन भाषाओं के लिए, विशेष रूप से अंत-से-अंत UD पार्सिंग को बढ़ाने के लिए। इस प्रकार हम समुदाय को भविष्य के कार्यों में इस तरह के अधिक लेक्सिका बनाने, परिवर्तित करने या उपलब्ध कराने के लिए प्रोत्साहित करते हैं।", 'ru': 'Мы представляем вклад лаборатории ONLP в Открытом университете Израиля в совместную задачу UD по многоязычному синтаксическому анализу от необработанного текста до универсальных зависимостей. Наш вклад основан на синтаксическом анализаторе перехода под названием «yap – another parser», который включает в себя отдельную морфологическую модель, отдельную модель зависимости и совместную морфосинтаксическую модель. В задании мы использовали отдельный парсер зависимостей yap для морфологического разбора входных данных, дезамбигированных UDPipe, и получили официальный балл 58.35 LAS. В нашем последующем исследовании мы используем YAP, чтобы показать, как включение морфологических и лексических ресурсов может улучшить производительность сквозного синтаксического анализа в случае морфологически богатого и малоресурсного языка, современного иврита. Наши результаты на иврите подчеркивают важность CoNLL-UL, UD-совместимого стандарта для доступа к внешним лексическим ресурсам, для улучшения сквозного синтаксического анализа UD, в частности, для морфологически богатых и низкоресурсных языков. Таким образом, мы призываем сообщество создать, преобразовать или сделать доступной более такую лексику в будущих задачах.', 'ga': "Cuirimid i láthair an méid a chuireann saotharlann ONLP ag Ollscoil Oscailte Iosrael le tasc roinnte UD ar pharsáil ilteangach ó bhuntéacs go Spleáchais Uilíocha. Tá ár gcion bunaithe ar pharsálaí tras-bhunaithe ar a dtugtar `yap – parsálaí eile fós', a chuimsíonn múnla moirfeolaíoch neamhspleách, samhail spleáchais aonair, agus comhshamhail morphosyntactic. Sa tasc d'úsáideamar parsálaí spleáchais neamhspleách yap chun ionchur a pharsáil a bhí dí-athbhríoch ag UDPipe, agus fuaireamar an scór oifigiúil de 58.35 LAS. Inár n-imscrúdú leantach bainimid úsáid as yap chun a thaispeáint conas a d’fhéadfadh ionchorprú acmhainní moirfeolaíocha agus foclóireachta feabhas a chur ar fheidhmíocht na parsála amh-go-deireadh ó cheann go ceann i gcás teanga atá saibhir go moirfeolaíoch agus a bhfuil acmhainní ísle aici, an Nua-Eabhrais. . Leagann ár dtorthaí ar an Eabhrais béim ar a thábhachtaí atá CoNLL-UL, caighdeán atá oiriúnach do UD chun rochtain a fháil ar acmhainní foclóireachta seachtracha, chun feabhas a chur ar pharsáil UD ó cheann ceann go ceann, go háirithe do theangacha moirfeolaíocha saibhir agus íseal-acmhainní. Spreagaimid mar sin an pobal chun tuilleadh foclóireachta dá leithéid a chruthú, a thiontú nó a chur ar fáil i dtascanna amach anseo.", 'el': "Παρουσιάζουμε τη συμβολή του εργαστηρίου του Ανοικτού Πανεπιστημίου του Ισραήλ στην κοινή εργασία της για την πολύγλωσση ανάλυση από ακατέργαστο κείμενο σε Οικουμενικές Εξαρτήσεις. Η συνεισφορά μας βασίζεται σε έναν αναλυτή που βασίζεται στη μετάβαση που ονομάζεται 'yap' ακόμα ένας αναλυτής', ο οποίος περιλαμβάνει ένα αυτόνομο μορφολογικό μοντέλο, ένα αυτόνομο μοντέλο εξάρτησης και ένα κοινό μορφοσυντακτικό μοντέλο. Στην εργασία χρησιμοποιήσαμε τον αυτόνομο αναλυτή εξάρτησης του yap για να αναλύσουμε την εισαγωγή μορφολογικά αποσαφηνισμένη από το UDPipe, και πήραμε την επίσημη βαθμολογία 58.35 LAS. Στη συνέχεια, χρησιμοποιούμε το yap για να δείξουμε πώς η ενσωμάτωση μορφολογικών και λεξικών πόρων μπορεί να βελτιώσει την απόδοση της ανάλυσης ακατέργαστων εξαρτήσεων από το τέλος στην περίπτωση μιας μορφολογικά πλούσιας και χαμηλής περιεκτικότητας γλώσσας, της Σύγχρονης Εβραϊκής. Τα αποτελέσματά μας στα εβραϊκά υπογραμμίζουν τη σημασία του ενός προτύπου συμβατού με UD για την πρόσβαση σε εξωτερικούς λεξικούς πόρους, για την ενίσχυση της ολοκληρωμένης ανάλυσης UD, ιδίως για μορφολογικά πλούσιες και χαμηλής περιεκτικότητας γλώσσες. Έτσι ενθαρρύνουμε την κοινότητα να δημιουργήσει, να μετατρέψει ή να διαθέσει περισσότερα τέτοια λεξικά σε μελλοντικές εργασίες.", 'hu': "Bemutatjuk az Izraeli Nyílt Egyetem ONLP laboratóriumának hozzájárulását az UD megosztott feladatához, amely a nyers szövegtől az univerzális függőségekig való többnyelvű elemzéssel foglalkozik. Közreműködésünk egy átmeneti alapú elemzőn alapul, melynek neve `yap - egy újabb elemző', mely magában foglal egy önálló morfológiai modellt, egy önálló függőségi modellt és egy közös morfoszintatikus modellt. A feladat során a yap önálló függőségi elemzőjét használtuk az UDPipe által egyértelműsített bemenetek morfológiailag egyértelműsített értékelésére, és megszereztük a hivatalos pontszámot 58,35 LAS. Nyomon követési vizsgálatunkban a yap segítségével megmutatjuk, hogy a morfológiai és lexikai erőforrások beépítése hogyan javíthatja az end-to-end nyers függőségek elemzésének teljesítményét morfológiailag gazdag és alacsony erőforrású nyelv, a modern héber esetében. A héberről szóló eredményeink hangsúlyozzák a CoNLL-UL, egy UD-kompatibilis szabvány fontosságát a külső lexikai erőforrásokhoz való hozzáférésre, a végpontok közötti UD elemzés javítására, különösen morfológiailag gazdag és alacsony erőforrású nyelvek esetében. Ezért arra ösztönözzük a közösséget, hogy hozzon létre, konvertáljon vagy tegyen elérhetővé ilyen lexikát a jövőbeli feladatokban.", 'ka': "ჩვენ განვითავსებთ ONLP ლაბოლობის გახსნა იზრავლელის სუნივერსიტში UD-ის გაყოფილი რაქაღაზე მრავალენგური პარასტიდან სუნივერსიტური განსაზღვრებისთვის. ჩვენი დამატება გადაწყვეტილი პანსტრინციის დაბაზია `yap - მაგრამ სხვა პანსტრისტორი', რომელიც აქვს სხვა მოპოროლოგიური მოდელი, სხვა დამატებული მოდელი და სხვა მოპოროსინტატიური მოდელი. დავალებში ჩვენ გამოიყენეთ yap-ის განმავლობათად დავამხოლობულობის პანსერერერი, რომელიც UDPipe-ის გამოყენებული მოპოროლოგიურად განმავლებულია, და მივიღეთ 58.35 LAS-ის официальный წერტილი. ჩვენი შემდეგი განსხვავებაში ჩვენ გამოყენებთ yap, როგორ მორპოლოგიური და ლექსიკალური რესურსების შექმნარება შეიძლება უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო მეტი და უფრო ჩვენი წარმოდგენები ჰებური შესახებ CoNLL-UL-ის მნიშვნელობა, UD-სკომპორტირებული სტანდარტი, გარეშე ლექსიკალური რესურსების მისაღებისთვის, სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვად ამიტომ ჩვენ საზოგადოებას მოვიწყებთ, გადაქმნა, ან უფრო მეტი ლექსიკას მომავალეთ საქმედებში.", 'it': "Presentiamo il contributo del laboratorio ONLP presso l'Open University of Israel al compito condiviso dell'UD sull'analisi multilingue dal testo grezzo alle dipendenze universali. Il nostro contributo si basa su un parser basato sulla transizione chiamato `yap - ancora un altro parser', che include un modello morfologico standalone, un modello di dipendenza standalone e un modello morfosintattico congiunto. Nel compito abbiamo usato il parser di dipendenza standalone di yap per analizzare l'input morfologicamente disambiguato da UDPipe, e abbiamo ottenuto il punteggio ufficiale di 58,35 LAS. Nella nostra indagine di follow up usiamo yap per mostrare come l'incorporazione di risorse morfologiche e lessicali possa migliorare le prestazioni dell'analisi end-to-end raw-to-dependences nel caso di un linguaggio morfologicamente ricco e a basso contenuto di risorse, l'ebraico moderno. I nostri risultati sull'ebraico sottolineano l'importanza di CoNLL-UL, uno standard UD compatibile per l'accesso a risorse lessicali esterne, per migliorare l'analisi UD end-to-end, in particolare per linguaggi morfologicamente ricchi e a basso contenuto di risorse. Incoraggiamo quindi la comunità a creare, convertire o rendere disponibile più lessica in attività future.", 'kk': 'Біз Израиль Ашық университетінде ONLP лабораториясының көптілік мәтіннен Universal Dependencies үшін бірнеше тілдерді талдау үшін UD жұмыс істейтін тапсырмасына қатынас береміз. Біздің көмегіміз "yap - бірақ басқа талдаушы" деп аталатын ауыстыру негізінде негізделген, бұл бір-бірінші морфологиялық модель, бір-бірінші тәуелдік үлгісі мен бірінші морфосинтактика Тапсырмада, UDPipe арқылы енгізу морфологиялық түрде бұл параметрлерді талдау үшін yap тәуелсіздік параметрлерін қолдандық, олар 58,35 LAS официалдық нөмірін алдық. Біздің келесі зерттеулерімізде, морфологиялық және лексикалық ресурстарды қалай ендіру үшін, морфологиялық баяны және төмен ресурстар тілінің морфологиялық тілі, Қазіргі Иврит тілінде талдау тәуелдіктерінің істемін Біздің Иврит нәтижелеріміз CoNLL-UL, сыртқы лексикалық ресурстарына қатынау үшін UD-мен үйлесімді стандартты, UD талдау үшін end-to-end талдау үшін, осымен қатар морфологиялық баяны және төмен ресурстар тілдері үшін. Біз қоғамды болашақ тапсырмаларда бұл лексиканы құру, аудару немесе қолдануға көмектесеміз.', 'lt': 'Mes pristatome ONLP laboratorijos atvirojo Izraelio universiteto indėlį į bendrą UD užduotį daugiakalbio analizavimo iš žaliavinio teksto į Universal Dependencies. Mūsų indėlis grindžiamas pereinamojo laikotarpio analizatoriumi, vadinamu "yap - dar vienas analizatorius", kuris apima atskirą morfologinį model į, atskirą priklausomybės modelį ir jungtinį morfosintaktinį modelį. Atlikdami užduotį mes naudojome yap savarankišką priklausomybės analizatorių analizuoti įvestį morfologiškai išskaičiuotą UDPipe, ir gavome oficialų 58,35 LAS rezultatą. In our follow up investigation we use yap to show how the incorporation of morphological and lexical resources may improve the performance of end-to-end raw-to-dependencies parsing in the case of a morphologically-rich and low-resource language, Modern Hebrew.  Mūsų rezultatai dėl hebrajų pabrėžia CoNLL-UL svarbą – UD suderinamą standartą, skirtą prieigai prie išorinių leksinių išteklių, didinti galutinį UD analizavimą, visų pirma morfologiškai turtingoms ir mažai išteklių turinčioms kalboms. Taigi skatiname bendruomenę kurti, konvertuoti ar suteikti daugiau tokios leksikos galimybių ateityje.', 'ms': "Kami memperkenalkan kontribusi makmal ONLP di Universiti terbuka Israel untuk tugas berkongsi UD mengenai penghuraian berbilang bahasa dari teks mentah ke Dependensi Universal. Kontribusi kami berdasarkan penghurai berdasarkan transisi yang dipanggil `yap - lagi penghurai lain', yang termasuk model morfologi tunggal, model dependensi tunggal, dan model morfosintaksi kongsi. Dalam tugas kami menggunakan penghurai dependensi sendiri yap untuk hurai input morfologik disambiguated oleh UDPipe, dan mendapat skor rasmi 58.35 LAS. Dalam penyelidikan berikut kami kami menggunakan yap untuk menunjukkan bagaimana penyambungan sumber morfologik dan leksikal boleh meningkatkan prestasi penghuraian dari hujung-hujung raw-to-dependencies dalam kes bahasa yang kaya morfologik dan rendah-sumber, Hebrew Modern. Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages.  Oleh itu, kami mendorong masyarakat untuk mencipta, mengubah, atau membuat lebih banyak lexika seperti ini dalam tugas masa depan.", 'ml': "തുറന്ന യിസ്രായേല്\u200d യൂണിവേഴ്സിറ്റിയിലെ ഒണ്\u200dഎല്\u200dപി ലാബിലെ പങ്ക് ഞങ്ങള്\u200d യുഡി പങ്കെടുത്ത ജോലിയിലേക്ക് കൊടുക്കുന്നു. മോശം  നമ്മുടെ പങ്ക് അടിസ്ഥാനത്തുള്ള 'യാപ്പ്- എന്നിട്ടും മറ്റൊരു പരാജയപ്രകാരം' എന്ന പേരില്\u200d അടിസ്ഥാനമാണ്. അതില്\u200d ഒരു സ്ഥിരമായ മോര്\u200dഫോളിക്കല്\u200d മോഡല്\u200d, ഒരു സ്ഥ യാപ്പിന്\u200dറെ സ്റ്റാന്\u200dറിയേറ്റി ആശ്രയിക്കുന്നതിന്\u200dറെ ജോലിയില്\u200d യുഡിപിപ്പിയില്\u200d നിന്നുള്ള ഇന്\u200dപുട്ട് മോര്\u200dഫോളോഗിക്കല്\u200d പാര്\u200dസ് ച നമ്മുടെ പിന്തുടര്\u200dന്ന അന്വേഷണത്തില്\u200d മോര്\u200dഫോളജിക്കും ലെക്സിക്കല്\u200d വിഭവങ്ങളുടെയും ഉള്\u200dപ്പെടുത്തുന്നത് എങ്ങനെയാണെന്ന് കാണിക്കാന്\u200d ഞങ്ങള്\u200d യാപ്പ് ഉപയോഗിക്കുന്നത് മോര്\u200dഫ പുറത്തുള്ള ലെക്സിക്കല്\u200d വിഭവങ്ങള്\u200d സമ്പാദിക്കുന്നതിനുള്ള യുഡി പാര്\u200dസിങ്ങിനുള്ള പ്രധാനപ്പെട്ട കോണ്\u200dഎല്\u200d- യുഎലിന്റെ പ്രാധാന്യം ഹെബ്രൂയില്\u200d ഞങ്ങളുടെ ഫലങ്ങള്\u200d ക അതുകൊണ്ട് നമ്മള്\u200d സമുദായത്തെ ആശ്വാസിപ്പിക്കുന്നു, സൃഷ്ടിക്കുന്നത്, മാറ്റുന്നതോ അല്ലെങ്കില്\u200d ഭാവി", 'mt': "Aħna nippreżentaw il-kontribut tal-laboratorju ONLP fl-Università Miftuħa tal-Iżrael għall-kompitu kondiviż tal-UD dwar l-analiżijiet multilingwi minn test mhux ipproċessat għal Dipendenzi Universali. Il-kontribuzzjoni tagħna hija bbażata fuq parser ibbażat fuq it-tranżizzjoni msejjaħ “yap – parser ieħor”, li jinkludi mudell morfoloġiku indipendenti, mudell ta’ dipendenza indipendenti, u mudell morfosintattiku konġunt. In the task we used yap`s standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS.  In our follow up investigation we use yap to show how the incorporation of morphological and lexical resources may improve the performance of end-to-end raw-to-dependencies parsing in the case of a morphologically-rich and low-resource language, Modern Hebrew.  Ir-riżultati tagħna dwar l-Ebrej jenfasizzaw l-importanza tal-CoNLL-UL, standard kompatibbli mal-UD għall-a ċċess għar-riżorsi lexiċi esterni, għat-titjib tal-analiżi tal-UD minn tarf sa tarf, b’mod partikolari għal lingwi morfoloġikament rikki u b’riżorsi baxxi. Għalhekk in ħeġġu lill-komunità biex to ħloq, tikkonverti, jew tagħmel disponibbli aktar tali lessika f'kompiti futuri.", 'mk': 'Ние го претставуваме придонесот на лабораторијата на ОНЛП на Отворениот универзитет во Израел за заедничката задача на УД за мултијазичко анализирање од суров текст до универзалните зависности. Нашиот придонес е базиран на анализатор базиран на транзиција наречен „ yap - уште еден анализатор “, кој вклучува и самостојен модел на морфологија, самостојен модел на зависност и заеднички морфосинтактички модел. Во задачата го употребивме самостојниот анализатор на зависност на yap за анализирање на влезот морфолошки дебабигуиран од UDPipe, и добивме официјален резултат од 58,35 LAS. Во нашата следна истрага користиме јап за да покажеме како вклопувањето на морфолошките и лексичките ресурси може да ја подобри резултатот на анализирањето на суровите зависности од крај до крај во случај на морфолошки богат и нискоресурсен јазик, Модерниот Евреин. Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages.  Така ја охрабруваме заедницата да создаде, претвори или да направи достапна повеќе таква лексика во идните задачи.', 'mn': 'Бид Израилийн нээлттэй Их Сургуулийн ONLP лабораторийн тусламжтайгаа UD-д олон хэл хэлний хуваалцааны тусламжтайгаас Universal Dependencies руу хуваалцах ажлыг илтгэнэ. Бидний зориулалт нь "yap" гэдэг шилжилт дээр суурилсан хуваагч дээр суурилсан. Энэ нь ганц морфологик загвар, ганцаараа хамааралтай загвар, нийлбэр морфосинтактик загвар юм. Энэ ажил дээр бид UDPipe-аас өөрчлөгдсөн морфологикийн хувьд yap-ын ганцаараа хамааралтай байдлыг ашиглаж, 58.35 ЛАС-ын үндсэн тоо авсан. Дараагийн судалгаанд бид морфологик болон лексикийн эх үүсвэрүүдийг хэрхэн хуваалцах боломжтой вэ гэдгийг харуулахын тулд yap хэрхэн ашигладаг. Одоогийн Хеврийн морфологик баян болон бага баялаг хэлний хуваалцааны үр дүнг хэрхэн сайжруулж боло Бидний Хибри улсын үр дүнд CoNLL-UL-ын чухал, UD-тэй хамааралтай стандарт нь гадаад лексикийн боловсролыг ашиглах боломжтой, UD-ын хуваалцлагын төгсгөлд, ялангуяа морфологийн баян болон бага боловсролын хэлний тухай илүү их чуха Иймээс бид нийгэмд ирээдүйн ажил дээр ийм лексикийг бүтээх, шилжүүлэх, эсвэл ашиглах боломжтой болгодог.', 'no': 'Vi presenterer bidrag av ONLP-laboratoriet på Opna Universiteten av Israel til UD-delt oppgåve om fleirspråk tolking frå råteksten til universelle avhengighet. Bidraget vårt er basert på ein overgangsbasert tolkar kalla «yap – enno ein annan tolkar», som inneheld ein samstundes morfologisk modell, ein samstundes avhengighetsmodell og ein samstundes morfosyntaktisk modell. I oppgåva brukte vi yap s samstundes avhengighetsanalyser for å tolka inndata morfologisk utsatt av UDPipe, og henta den offisielle poeng av 58,35 LAS. I følgjande undersøkelsen bruker vi yap for å vise korleis inkorporasjonen av morfologiske og leksiske ressursar kan forbetra utføringen av end-to-end råavhengighet som tolkar i tilfelle til ein morfologisk rikk og låg ressursspråk, modern Hebraisk. Resultatet våre på hebresisk understrekar viktigheten til CoNLL-UL, eit UD-kompatibel standard for å få tilgang til eksterne leksiske ressursar, for å forbetra tolking av UD-end-to-end, spesielt for morfologisk rike og låg ressursspråk. Vi oppfordrer samfunnet derfor å laga, konvertera eller gjera tilgjengeleg meir slike lexica i framtidige oppgåver.', 'pl': "Przedstawiamy wkład laboratorium ONLP na Otwartym Uniwersytecie Izraela w wspólne zadanie UD dotyczące wielojęzycznego parsowania tekstu surowego do uniwersalnych zależności. Nasz wkład opiera się na parserze opartym na przejściach zwanym `yap˝yet another parser', który obejmuje samodzielny model morfologiczny, samodzielny model zależności i wspólny model morfologiczny. W zadaniu użyliśmy samodzielnego parsera zależności yap do analizy wejść morfologicznie rozproszonych przez UDPipe i uzyskaliśmy oficjalny wynik 58.35 LAS. W naszym następnym badaniu używamy yap, aby pokazać, w jaki sposób włączenie zasobów morfologicznych i leksykalnych może poprawić wydajność kompleksowego parsowania raw-to-zależności w przypadku języka bogatego morfologicznie i nisko zasobów, współczesnego hebrajskiego. Nasze wyniki dotyczące hebrajskiego podkreślają znaczenie CoNLL-UL, standardu zgodnego z UD dla dostępu do zewnętrznych zasobów leksykalnych, dla ulepszania kompleksowego parsowania UD, w szczególności dla języków bogatych morfologicznie i niskich zasobów. Zachęcamy zatem społeczność do tworzenia, konwersji lub udostępniania więcej takich leksyk w przyszłych zadaniach.", 'ro': "Vă prezentăm contribuția laboratorului ONLP de la Open University of Israel la sarcina comună UD privind analizarea multilingvă de la text brut la Dependențe Universale. Contribuția noastră se bazează pe un parser bazat pe tranziție numit `yap - încă un parser', care include un model morfologic independent, un model de dependență independent și un model morfosintactic comun. În această sarcină am folosit parserul de dependență standalone yap pentru a analiza intrarea dezambiguizată morfologic de UDPipe și am obținut scorul oficial de 58,35 LAS. În investigația noastră de urmărire folosim yap pentru a arăta cum încorporarea resurselor morfologice și lexicale poate îmbunătăți performanța analizării end-to-end raw-to-dependențe în cazul unui limbaj bogat din punct de vedere morfologic și cu resurse reduse, ebraica modernă. Rezultatele noastre despre ebraică subliniază importanța CoNLL-UL, un standard compatibil UD pentru accesarea resurselor lexicale externe, pentru îmbunătățirea analizării UD end-to-end, în special pentru limbile bogate din punct de vedere morfologic și cu resurse reduse. Astfel, încurajăm comunitatea să creeze, converti sau să pună la dispoziție mai multe astfel de lexice în sarcinile viitoare.", 'sr': "Predstavljamo doprinos laboratorije ONLP-a na Otvorenom Univerzitetu Izraela na zajednički zadatak UD-a o multijezičkom analizu sa sirovog teksta do univerzalnih zavisnosti. Naš doprinos je baziran na prelaznom analizatoru koji se zove 'yap - još jedan analizator', koji uključuje samostalni morfološki model, model zavisnosti samostalnosti i zajednički morfosintaktički model. U zadatku smo koristili samostalni analizač zavisnosti yapa da bi analizirali ulaz morfološki dezambiguovan od UDPipe, i dobili zvanični rezultat 58,35 LAS-a. U našoj istrazi za praćenje koristimo jaje da pokažemo kako bi uključivanje morfoloških i leksičkih resursa moglo poboljšati učinkovitost razmatranja kraja do kraja nezavisnosti u slučaju morfološki bogatog i niskog jezika, modernog hebrejskog jezika. Naši rezultati na hebrejskoj podaci su važnost CoNLL-UL-a, UD-kompatibilnog standarda za pristup vanjskim leksičkim resursima, za poboljšanje analize UD-a do kraja, posebno za morfološki bogate i niske resurse. Zato ohrabrujemo zajednicu da stvori, pretvori ili dostavi takvu leksiju u budućim zadacima.", 'si': "අපි ඉස්රායේල් විශ්වාසික විද්\u200dයාපිත්තාවේ ONLP ලැබෝර්ගේ සම්බන්ධය පෙන්වන්න පුළුවන් විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dය අපේ භාවිතාව අධාරිත වෙනුවෙන් ස්ථානය වෙනුවෙන් ප්\u200dරවේශනයක් අධාරිත වෙනුවෙන් `යාප් - තවත් වෙනුවෙන් ප්\u200dරවේශකයක්', ස්ථානය මේ වැඩේ අපි පාවිච්චි කරලා යාප්ගේ ස්ටෑන්ඩන් විශේෂතාවක් පරිශ්චා කරලා UDPipe වලින් ඇතුළු මාර්ෆෝලෝජික විශේෂ අපේ පරීක්ෂණ පරීක්ෂණයේදී අපි ප්\u200dරයෝජනය කරනවා පෙන්වන්න පුළුවන් විදිහට ප්\u200dරයෝජනය කරනවා කොහොමද මොර්ෆෝලෝගික සහ ලෙක්සිකාලික සම්බන්ධ භ අපේ ප්\u200dරතිචාරය හිබ්\u200dරෝවියේ අධ්\u200dයස්ථානය CoNLL-UP, UD-සම්බන්ධ ප්\u200dරතිචාරයක් ප්\u200dරවේශනය කරන්න, අන්තිම ප්\u200dරතිචාරයක් අධ්\u200dයස්ථානය කරන්න, අ අපි අනාගතයෙන් සමාජයෙන්ට ප්\u200dරශ්නයක් කරන්න, වෙනස් කරන්න, නැත්නම් අනාගතයේ වැඩි ලෙක්සිකාව ප්\u200dරවේශ", 'so': "Dhaqaalaha labka ONLP ee jaamacadda furan ee Israa'iil ayaannu u soo bandhignaynaa shaqada UD oo ku saabsan baaritaanka luuqadaha kala duduwan ee laga soo diro macluumaad khaas ah ilaa masruufka caalamiga ah. Midhahayagu waxay ku saleysan tahay baaritaanka lagu magacaabay `yap- xitaa mid kale oo la yidhaahdo Parser', kaas oo ku jira model taagan oo morphological ah, model kali ah oo ku xiran, iyo model wadajir ah morphosyntactic. In the task we used yap`s standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS.  Baaritaanka soo socoshada waxaynu u isticmaalnaa baaritaanka si aan u muujinno in lagu soo galo asalka morphological iyo leksikalka ay u hormari karto sameynta dhamaadka ee baaritaanka qoyska ee ugu dambeeya, marka lagu jiro luqada morphologically-rich iyo hoos-resource, Cibraaniyeed hore. Abaalkayaga Cibraaniyadu waxay ku qoran yihiin muhiimka CoNLL-UL, taas oo ah standard u eg in la kordhiyo hantida dibadda ee leksikada, si loo kordhiyo jardiinada dhammaadka ugu dambeeya ee UD, khusuusan afka morphologically-rich iyo hoose resource. Sidaa darteed waxaynu bulshada ku dhiirranaynaa in ay sameeyaan, soo beddelaan ama ay sameyno shaqooyin la mid ah oo kale oo lexica ah oo ku soo socda.", 'sv': "Vi presenterar bidraget från ONLP-labbet vid Open University of Israel till UD:s gemensamma uppgift om flerspråkig tolkning från råtext till Universal Dependences. Vårt bidrag är baserat på en övergångsbaserad parser kallad `yap - ännu en parser', som inkluderar en fristående morfologisk modell, en fristående beroendemodell och en gemensam morfosyntaktisk modell. I uppgiften använde vi yaps fristående beroendetolkare för att tolka indata morfologiskt ogiltigförklarad av UDPipe, och fick den officiella poängen 58,35 LAS. I vår uppföljningsundersökning använder vi yap för att visa hur inkorporering av morfologiska och lexikala resurser kan förbättra prestandan för end-to-end raw-to-beroendetolkning vid ett morfologiskt rikt och resurssnålt språk, Modern Hebrew. Våra resultat på hebreiska understryker vikten av CoNLL-UL, en UD-kompatibel standard för åtkomst till externa lexikala resurser, för att förbättra end-to-end UD-tolkning, särskilt för morfologiskt rika och lågresursspråk. Vi uppmuntrar därför samhället att skapa, konvertera eller tillgängliggöra fler sådana lexika i framtida uppgifter.", 'ur': "ہم بنی اسرائیل کے اوپن یونیورسٹ یونیورسٹی میں ONLP آزمائش کا حصہ پیش کریں گے۔ ہمارا حصہ ایک تغییر بنیادی پارچر پر بنیاد ہے جو 'yap - لیکن دوسرا پارچر' ہے، جس میں ایک استاندارے مورفیل موڈل شامل ہے، ایک استاندارے اعتمادی موڈل، اور ایک جوڑے مورپوسٹک موڈل ہے. اس کام میں ہم نے یوپ کی استاندارڈینسیٹ پارٹر کا استعمال کیا ہے کہ UDPipe کے ذریعے اینپیٹ مورفولوژیک طریقے سے ناکام ہوا اور 58.35 لاس کی رسمی اسکور پارٹ دی۔ ہمارے پیچھے چلنے کی تحقیق میں ہم یوپ کو استعمال کرتے ہیں تاکہ دکھائیں کہ morfological and lexical resources کی تعمیر کس طرح ہوسکتی ہے کہ آخر-to-end raw-to-dependencies کا پارس کرنا ایک morfologically-rich اور کم-resource زبان کے مطابق، مدرن یہودی زبان کے مطابق ہے. ہبری کے نتائج کے ذریعے CoNLL-UL کی تعریف ہے، ایک UD-compatible استاندارد کے لئے بیرونی لکسیکل رسسور کے لئے، آخر-to-end UD پارسینگ کی مزید کرنے کے لئے، مخصوصاً morfologically rich اور low-resource languages کے لئے۔ اسی طرح ہم جماعت کو اس طرح سفارش دیتے ہیں کہ آگے کے کاموں میں ایسی لکسیکی پیدا کریں، تبدیل کریں، یا زیادہ موجود کریں۔", 'ta': "நாம் திறந்த ஐஸ்ரியேல் கல்லூரியில் ONLP லேபின் பங்கை வழங்குகிறோம் பல மொழிக்காட்சியில் பங்கீட்டு பணிக்கு வழங்குகிறோம்  'yap - இன்னும் மற்றொரு பரிசுத்தம்' என்று பெயரிடப்பட்ட மாதிரியில், தனிப்பட்ட சார்பு மாதிரி மற்றும் ஒரு இணைய மாதிரி மாதிரியில் உள்ளது. நாங்கள் யாபின் நிலையான சார்பு சார்பு பரிசோதனையை பயன்படுத்தி உள்ளீட்டை மாற்றியமைக்கப்பட்டதை பார்க்க பயன்படுத்தி, மற்றும் நாங்கள் UDPip ஆ எங்கள் பின்பற்றும் விசாரணையில் நாம் வரைபடத்தை பயன்படுத்துகிறோம் என்பதை காண்பிக்க முடியும் மற்றும் லெக்சிக்சியல் வளங்களை எப்படி உள்ளடக்கும் என்பதை காட்டுகிறோம் என்பதை நாம்  எங்கள் முடிவுகள் ஹீப்ரியில் கோன்எல்- UL முக்கியத்தை குறிப்பிடுகிறது, வெளி லெக்சியல் மூலங்களை அணுகுவதற்கு UD- பொருத்தமான நிலை இவ்வாறாக நாம் சமூகத்தை எதிர்கால வேலைகளில் உருவாக்க, மாற்ற, அல்லது அதிகமான லெக்சியா உருவாக்குவதற்கு ஆர்", 'uz': "Biz Oynash Universitetdagi ONLP laboratoriyasining qisqa matnni Universal Dependenciyatlariga ko'pchilik tillardan bir xil parsing vazifasini yuboramiz. Our contribution is based on a transition-based parser called `yap - yet another parser', which includes a standalone morphological model, a standalone dependency model, and a joint morphosyntactic model.  UDPip tomonidan o'zgartirish uchun yap'ning andoza ishlatilgan vazifani ishlatdik va 58.35 LAS'ning rasmi scorini olib keldik. Biz qo'shish davomida, morfologik va leksikal Resilitlarni qanday qo'yishni ko'rsatishimiz mumkin. Morfologik hovrik va kamaytirli manbalar tili, Moden yevropacha yevropacha o'zgarishni o'zgartirish mumkin. Yubraanistonning natijalarimiz, tashqi leksikal Resilitlarini oshirish uchun UD (UD) muhim imkoniyatini ko'rsatadi, balki morfologik ichki va kichkina resource tillariga o'zgartirish uchun UD ta'minlovchi darajasi. Шундай қилиб, биз jamiyatlarni kelajakdagi vazifalarni яратиш, ўзгартириш ёки яна кўпроқ leksikani ishlab chiqarishni amalga oshirimiz mumkin.", 'vi': 'Chúng tôi xin giới thiệu sự đóng góp của phòng thí nghiệm từng giọt tại đại học Open of Israel cho các nhiệm vụ đã chia sẻ của UD về chế độ đọc rộng từ văn bản nguyên bản đến các môi trường chung. Sự đóng góp của chúng tôi dựa trên một nhà phân tích chuyển hóa được gọi là "yap" nhưng là một nhà phân mục khác, gồm một mô hình morphology Đứng riêng, một mô hình phụ thuộc riêng, và một mô hình morphine chung. Trong nhiệm vụ chúng tôi đã dùng phân tích độ phụ thuộc của yap để phân tích nội dung theo kiểu cách bị UDPipe, và nhận được s ố lượng chính thức của 58.35 LAS. Trong cuộc điều tra tiếp theo, chúng tôi sử dụng yap để cho thấy làm thế nào việc khai thác các nguồn gốc từ ngữ và từ vựng có thể cải thiện hiệu quả của các môi trường sống bất kể, khai thác từ ngữ, ngôn ngữ cổ đại Do Thái. Kết quả của chúng ta trên tiếng Do Thái nhấn mạnh tầm quan trọng của Colt L, một tiêu chuẩn UD-phù hợp cho việc truy cập tài nguyên ngôn ngữ văn học bên ngoài, để tăng cường phân tích UD từ tận cùng, đặc biệt cho ngôn ngữ có độ to lớn và ít nguồn. Chúng tôi khuyến khích cộng đồng tạo, cải tạo, hoặc phát triển văn bản này trong các nhiệm vụ tương lai.', 'bg': 'Представяме приноса на лабораторията в Отворения университет в Израел към споделената задача на СД за многоезично анализиране от суров текст до универсални зависимости. Нашият принос се основава на преходен анализатор, наречен още един анализатор, който включва самостоятелен морфологичен модел, самостоятелен модел на зависимост и съвместен морфосинтактичен модел. В задачата използвахме самостоятелен анализатор на зависимост на яп, за да анализираме входните данни морфологично разграничени от UDPipe и получихме официален резултат от 58.35. В нашето последващо проучване ние използваме яп, за да покажем как включването на морфологични и лексикални ресурси може да подобри ефективността на анализ от край до край сурови до зависимости в случай на морфологично богат и нискоресурсен език, съвременния иврит. Резултатите ни за иврит подчертават значението на съвместим стандарт за достъп до външни лексикални ресурси, за подобряване на анализа от край до край, особено за морфологично богати и нискоресурсни езици. По този начин насърчаваме общността да създава, конвертира или предоставя повече такива лексики в бъдещи задачи.', 'da': "Vi præsenterer bidraget fra ONLP laboratoriet på Open University of Israel til UD's delte opgave om flersproget parsing fra rå tekst til universelle afhængigheder. Vores bidrag er baseret på en overgangsbaseret fortolker kaldet `yap - endnu en fortolker', som omfatter en selvstændig morfologisk model, en selvstændig afhængighedsmodel og en fælles morfosyntaktisk model. I opgaven brugte vi yap`s standalone afhængighedsfortolker til at fortolke input morfologisk forstået af UDPipe, og opnåede den officielle score på 58,35 LAS. I vores opfølgende undersøgelse bruger vi yap til at vise, hvordan inkorporering af morfologiske og leksikologiske ressourcer kan forbedre ydeevnen af end-to-end rå-til-afhængigheder parsing i tilfælde af et morfologisk rig og lav ressource sprog, Modern Hebraisk. Vores resultater på hebraisk understreger vigtigheden af CoNLL-UL, en UD-kompatibel standard til adgang til eksterne leksikologiske ressourcer, for at forbedre end-to-end UD parsing, især for morfologisk rige og lav ressource sprog. Vi opfordrer derfor fællesskabet til at oprette, konvertere eller gøre mere sådan leksika tilgængelig i fremtidige opgaver.", 'de': "Wir stellen den Beitrag des ONLP-Labors an der Open University of Israel zur gemeinsamen UD-Aufgabe zum mehrsprachigen Parsen von Rohtext zu Universal Dependencies vor. Unser Beitrag basiert auf einem Übergangs-basierten Parser namens `yap bis yet another parser', der ein eigenständiges morphologisches Modell, ein eigenständiges Abhängigkeitsmodell und ein gemeinsames morphosyntaktisches Modell enthält. In der Aufgabe verwendeten wir yap`s Standalone Dependency Parser, um Eingaben morphologisch durch UDPipe zu analysieren und erhielten die offizielle Punktzahl von 58.35 LAS. In unserer Folgeuntersuchung zeigen wir anhand von yap, wie die Einbeziehung von morphologischen und lexikalischen Ressourcen die Leistung von End-to-End Raw-Abhängigkeiten Parsing im Fall einer morphologisch reichen und ressourcenarmen Sprache, Modernes Hebräisch, verbessern kann. Unsere Ergebnisse auf Hebräisch unterstreichen die Bedeutung von CoNLL-UL, einem UD-kompatiblen Standard für den Zugriff auf externe lexikalische Ressourcen, für die Verbesserung der End-to-End UD-Parsing, insbesondere für morphologisch reiche und ressourcenarme Sprachen. Wir ermutigen daher die Community, in zukünftigen Aufgaben mehr solcher Lexika zu erstellen, zu konvertieren oder zur Verfügung zu stellen.", 'nl': "We presenteren de bijdrage van het ONLP lab aan de Open Universiteit van Israël aan de UD gedeelde taak over meertalig parsen van ruwe tekst naar universele afhankelijkheden. Onze bijdrage is gebaseerd op een transitie-based parser genaamd `yap by yet another parser', die een standalone morfologisch model, een standalone afhankelijkheidsmodel en een joint morfologisch model omvat. In de taak gebruikten we yap`s standalone dependency parser om input morfologisch te parsen die door UDPipe werd verduidelijkt, en kregen we de officiële score van 58.35 LAS. In ons vervolgonderzoek gebruiken we yap om aan te tonen hoe de integratie van morfologische en lexicale bronnen de prestaties van end-to-end raw-dependencies parsing kan verbeteren in het geval van een morfologisch rijke en low-resource taal, Modern Hebreeuws. Onze resultaten op Hebreeuws onderstrepen het belang van CoNLL-UL, een UD-compatibele standaard voor toegang tot externe lexicale bronnen, voor het verbeteren van end-to-end UD parsing, in het bijzonder voor morfologisch rijke en low-resource talen. We moedigen de gemeenschap dus aan om meer dergelijke lexica te maken, te converteren of beschikbaar te stellen in toekomstige taken.", 'fa': 'ما مشارکت آزمایشگاه ONLP در دانشگاه باز اسرائیل را به کار UD مشترک می\u200cکنیم که از متن خاصی به بستگی جهانی از متن خاصی به بررسی کردن زبان\u200cهای زیادی مشترک می\u200cشود. دسترسي ما بر اساس پالاس\u200cکننده\u200cي تغيير\u200cسازي به نام «yap - هنوز پالاس\u200cکننده\u200cي ديگري» است که شامل یک مدل مورفولوژيکي تنها است، مدل بستگي تنها و مدل مرفوزوسينکتيک مشترک است. در وظیفه ما از طریق وابستگی وابستگی یوپ استفاده کردیم تا در مورد ورودی مورفولوژیکی که توسط UDPipe ناتوان شده است تحلیل کنیم و امتیاز رسمی 58.35 LAS را دریافت کردیم. در تحقیقات دنبال ما از یاب استفاده می کنیم تا نشان دهیم که چگونه شامل تشکیل منابع مورفولوژیکی و زبان زبان زبان مدرن، ابریه\u200cی مدرن، عملکرد بستگی\u200cهای بی\u200cپایان به پایان برسیم. نتیجه\u200cهای ما در ابریشم مهمترین CoNLL-UL، استاندارد با UD برای رسیدن به منابع زبان\u200cهای خارجی، برای افزایش تجزیه\u200cهای UD به پایان آخر و پایان، مخصوصا برای زبان\u200cهای پولدار و کم منابع مورفولوژی را نشان می\u200cدهد. ما همین\u200cطور اجتماعی را تشویق می\u200cکنیم که در وظیفه\u200cهای آینده چنین لکسی بیشتری را ایجاد کنند، تبدیل کنند یا در دسترسی دهند.', 'ko': "이스라엘 개방대학 ONLP 실험실이 UD 공유 임무에 기여한 바를 소개했는데 이 임무는 원시 텍스트부터 통용적으로 의존하는 다중 언어 해석에 이르기까지 다양하다.우리의 공헌은'yap-또 하나의 해석기'라는 전환을 바탕으로 하는 해석기를 바탕으로 한다. 이것은 독립된 형태 모델, 독립된 의존 모델과 결합된 형태 문법 모델을 포함한다.이 작업에서 우리는 yap의 독립 의존 해석기를 사용하여 UDPipe가 형태학적으로 잘못된 의미를 제거하는 입력을 해석하고 58.35 LAS의 공식 점수를 얻었다.우리의 후속 조사에서 우리는yap을 사용하여 형태가 풍부하고 자원이 부족한 언어인 현대 히브리어를 결합한 상황에서 형태와 어휘자원을 결합시켜 원시적 의존항 해석의 성능을 어떻게 향상시키는지 보여준다.우리는 히브리어에 대한 연구 결과에 대해 CoNLL UL의 중요성을 강조했다. 이것은 UD 호환의 표준으로 외부 어휘 자원을 방문하고 끝에서 끝까지의 UD 해석을 강화하는데 특히 형태가 풍부하고 자원이 적은 언어에 사용된다.따라서 우리는 지역 사회가 미래의 임무에서 이러한 어휘를 창설하고 전환하거나 더 많이 제공하도록 장려한다.", 'sw': "Tunaweza kutoa michango ya labda ya ONLP katika Chuo Kikuu cha wazi cha Israeli katika kazi ya UDD inayosambazwa kwenye wimbo wa lugha mbalimbali kutoka ujumbe mfupi wa maandishi na kutegemea matumizi ya ulimwengu. Mchango wetu umejikita na mchanganyiko wa mpito unaoitwa 'yap - lakini mchanganyiko mwingine', ambao unajumuisha muundo wa kisiasa pekee, modeli ya kutegemea mwenyewe, na mtindo wa pamoja wa morphosyntactic. Katika juhudi tulizotumia kujitegemea ya yap kwa ajili ya kuvuruga inzani uliofanywa na UDPipe, na kupata score rasmi ya LAS 58.35. Katika uchunguzi wetu wa ufuatiliaji tunatumia safari ili kuonyesha jinsi ya kuungizwa na rasilimali za kimaadilojia na za kilexico inavyoweza kuongeza ufanisi wa kutegemea mwishoni wa kusitisha matumaini ya uchunguzi katika kesi ya lugha ya kimorphologically rich and low resource, Kibraania wa sasa. Matokeo yetu kuhusu Kibraania yanaonyesha umuhimu wa CoNLL-UL, kiwango kinachofanana na UD cha upatikanaji wa rasilimali za nje za lexico, kwa kuongeza wimbo wa UD wa mwisho wa mwisho, hususani kwa lugha zenye utajiri na rasilimali duni za kisiasa. We thus encourage the community to create, convert, or make available more such lexica in future tasks.", 'id': "Kami mempersembahkan kontribusi dari laboratorium ONLP di Universitas terbuka Israel untuk tugas UD berbagi tentang penghuraian berbagai bahasa dari teks mentah ke Dependensi Universal. Kontribusi kami berdasarkan parser berdasarkan transisi yang disebut `yap - lagi parser lain', yang termasuk model morfologi standar, model dependensi standar, dan model morfosintaksi kongsi. Dalam tugas kami menggunakan penyelesaian dependensi yap sendiri untuk menghindari input morfologis disambiguated oleh UDPipe, dan mendapatkan skor resmi 58,35 LAS. Dalam penyelidikan berikutnya kami menggunakan yap untuk menunjukkan bagaimana inkorporasi sumber daya morfologi dan leksik bisa meningkatkan prestasi dari akhir-akhir raw-to-dependencies penghuraian dalam kasus bahasa yang kaya morfologi dan rendah-sumber daya, Hebrew Modern. Hasil kita di Hebrew menyatakan penting CoNLL-UL, standar kompatibel UD untuk mengakses sumber daya leksik eksternal, untuk meningkatkan penghuraian UD akhir-akhir, terutama untuk bahasa morfologis kaya dan sumber daya rendah. We thus encourage the community to create, convert, or make available more such lexica in future tasks.", 'af': "Ons stel die bydrang van die ONLP laboratorie op die Open Universiteit van Israel aan die UD deel taak op veelvuldige verwerking van rooi teks tot universele afhanklikhede. Ons bydraai is gebaseer op 'n transition-based ontwerker wat genoem word 'yap - nog 'n ander ontwerker', wat insluit 'n standalone morfologiese model, 'n standalone afhanklikheid model en 'n joint morphosyntaktike model. In die taak gebruik ons yap se standalone afhanklikheidspanser om invoer morfologies te ontlees deur UDPipe, en die offisiele telling van 58.35 LAS te kry. In ons volgende ondersoek gebruik ons yap om te wys hoe die inkorporering van morfologiese en leksiese hulpbronne kan die prestasie van end-to-end raw-to-dependencies verhoog in die geval van 'n morfologiese-ryk en lae-hulpbronne taal, Moderne Hebreeus. Ons resultate op Hebreeus onderstrek die belangrikheid van CoNLL-UL, 'n UD-kompatibel standaard vir toegang tot eksterne leksiese hulpbronne, vir verbetering van end-to-end UD verwerking, in particular for morphologically rich and low-resource languages. Ons moet daarom die gemeenskap aanbevestig om meer sodanige lexika in toekomstige opdragte te skep, omskakel of beskikbaar te maak.", 'am': "በክፈት እስራኤል ዩንቨርስቲ ላይ የONLP laboratory አካሄዱን ከጥሩ ጽሑፍ ጀምሮ እስከ ዓለማዊ ደጋፊዎች ድረስ የዩዲ ቋንቋ ማኅበረሰብ ላይ የተካፈለውን ስራ እናቀርባለን፡፡ አካሄዳችን ``yap- ነገር ግን ሌላ ተማሪ› በሚባል የክፍለ መተላለፊያ ማተር ላይ ነው፡፡ የያp'ን ብቻውን ተማሪ በተጠቃሚ ስራ ውስጥ በUDPip በሞፎሎጂ የተለየን ጥያቄን ለመግለጽ እና የ58.35 LAS ጥያቄ አግኝተናል፡፡ የሞሮፎሎጂ እና የሌክሲካዊ ሀብት መግባት እንዴት እንደሚያሳየው የፍጻሜ-ወደታደጋጊዎች መዘርጋት በሚያሳድገው እና በሞሮፎሎጂ ባለጠጋ እና ዋነኛ ዕቃ ቋንቋ፣ የአሁኑን ዕብራዊ ቋንቋ፣ የፍጻሜ ዕድሜ ማድረግ ይችላል፡፡ በዕብራይስጥ ላይ ፍሬዎቻችን የውጭ የሊክሲካዊ ሀብትን ለማግኘት የሆኑት የኮንLL-UL ግንኙነት የሆኑት የሆኑት የሆኑት የውጭው የሊክሲ ሀብት አካባቢ ነው፡፡ እንደዚሁም ማኅበረሰቢያን በመጨረሻው እንደዚህ ያሉትን ሌክሲያን ሥራ እንዲፈጥሩ፣ እንዲመለሱ ወይም እንዲጨምሩ እናበረታታለን፡፡", 'hy': 'Մենք ներկայացնում ենք Իսրայելի Բաց համալսարանի ՕՆԼՊ լաբորատորիայի ներդրումը ԱՄՆ-ի հանրային առաջադրանքին բազմալեզու վերլուծության մասին, որը տեղի է ունենում ոչ թղթից տեքստից Universal Depndenties-ի: Մեր ներդրումը հիմնված է «yap»-ի վերաբերյալ վերաբերյալ հիմնված վերաբերյալ վերաբերյալ, որը ներառում է առանձին մորֆոլոգիական մոդել, առանձին կախվածության մոդել և միավոր մորֆոսինտակտիկ մոդել: Մենք օգտագործեցինք yap-ի առանձին կախվածության վերլուծումը, որպեսզի վերլուծենք UDPipe-ի կողմից բացատրված մուտքը և ստացանք 58.35 LAS-ի պաշտոնական գնահատականը: In our follow up investigation we use yap to show how the incorporation of morphological and lexical resources may improve the performance of end-to-end raw-to-dependencies parsing in the case of a morphologically-rich and low-resource language, Modern Hebrew.  Հեբրայի վերաբերյալ մեր արդյունքները ենթադրում են ԿոՆԼ-ԱԼ-ի կարևորությունը՝ UD-ի համատեղելի ստանդարտ արտաքին լեքսիկական ռեսուրսների հասանելիության համար, վերջ-վերջ UD-ի վերլուծության բարելավման համար, հատկապես մորֆոլոգիապես հարուստ և ցածր ռե Այսպիսով, մենք խրախուսում ենք համայնքը ստեղծել, փոխակերպել կամ ավելի շատ այդպիսի լեքսիկա հասանելի դարձնել ապագա խնդիրներում:', 'tr': 'Biz Izraýlyň Aç Uniwersitetinde ONLP laboratuýasynyň UDa birnäçe dilli analyz edilen çyzgy metinden Halkara Baýramlyklara dahyl edip görkezip otyrdyk. Bizim teklifimiz "yap - hala başka bir ayıracak" adında geçişim tabanlı bir ayıracağına dayanıyor. Bu da tek bir morfolojik modeli, tek bir bağlılık modeli ve birleşmiş bir morfosyntaktik modeli dahil edir. Bizim görevimizde yap yalnız bağlılığı tanımlayıcıs ını UDPipe tarafından gizli morfolojik şeklinde çözümlenmek için kullandık ve resmi noktaları 58.35 LAS aldık. Biziň yzygymyz barlamagymyzda morfolojik we leksiýaly çeşmeleriň üýtgetmeginiň nähili morfolojik bagly we ýok-resurslardan habaryň täsirini gowy edip biljekdigini görkezmek üçin yap ulanýarys. Ýähüdçemiz netijelerimiz CoNLL-UL, daşarydaky leksiýa çeşmelerine gollanmak üçin UD-uň wajyplygyny belirtdi. Şonuň üçin jemgyýetiň gelejekde şeýle bir dilini döretmegini, üýtgetmegini ýa-da ýene bir hereket edip bilmesini töwekgelýäris.', 'sq': "We present the contribution of the ONLP lab at the Open University of Israel to the UD shared task on multilingual parsing from raw text to Universal Dependencies.  Our contribution is based on a transition-based parser called `yap - yet another parser', which includes a standalone morphological model, a standalone dependency model, and a joint morphosyntactic model.  In the task we used yap`s standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS.  Në hetimin tonë të vazhdueshëm ne përdorim yap për të treguar se si përfshirja e burimeve morfologjike dhe lexike mund të përmirësojë performancën e analizimit të të parëve nga fundi në fund në rastin e një gjuhe morfologjike të pasur dhe me burime të ulëta, Hebrej modern. Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages.  Kështu inkurajojmë komunitetin të krijojë, të konvertojë apo të bëjë në dispozicion më shumë leksikë të tillë në detyrat e ardhshme.", 'bs': "Predstavljamo doprinos laboratorije ONLP-a na Otvorenom Univerzitetu Izraela na zajednički zadatak UD-a o multijezičkom analizu sa sirovog teksta do univerzalnih ovisnosti. Naš doprinos je baziran na prelaznom analizatoru koji se zove 'yap - još jedan analizator', koji uključuje samostalni morfološki model, model zavisnosti samostalnosti i zajednički morfosintaktički model. U zadatku smo koristili samostalni analizač zavisnosti yapa kako bi analizirali ulaz morfološki dezambiguiran od UDPipe i dobili zvanični rezultat 58,35 LAS-a. U našoj istrazi za praćenje koristimo yap da pokažemo kako bi uključivanje morfoloških i leksičkih resursa moglo poboljšati učinkovitost analize zavisnosti kraja do kraja u slučaju morfološki bogatog i niskog jezika, modernog hebrejskog jezika. Naši rezultati na hebrejskom podsjećaju važnost CoNLL-UL-a, UD-kompatibilnog standarda za pristup vanjskim leksičkim resursima, za poboljšanje analize UD-a do kraja, posebno za morfološki bogate i niske resurse jezike. Stoga ohrabrujemo zajednicu da stvori, preobrati ili dostavi takvu leksiju u budućim zadacima.", 'ca': 'Presentam la contribució del laboratori ONLP de la Universitat Oberta d\'Israel a la UD compartida tasca sobre l\'analització multilingüe des de text brut a Dependencies Universals. La nostra contribució es basa en un analitzador basat en la transició anomenat "yap - un altre analitzador", que inclou un model morfològic independent, un model de dependencia independent i un model morfosinàctic conjunt. In the task we used yap`s standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS.  En la nostra investigació de seguiment utilitzem yap per demostrar com l\'incorporació de recursos morfològics i lècsics pot millorar el rendiment de l\'analització de funcions brutes fins a finals en el cas d\'un llenguatge morfològicament ric i de baix recursos, l\'hebreu moderne. Els nostres resultats en hebreu subrayen l\'importància de CoNLL-UL, un estàndard compatible amb l\'UD per accedir a recursos lexicals externs, per millorar l\'analització final a final de l\'UD, en particular per llengües morfològicament rics i de baix recursos. Així que animam la comunitat a crear, convertir o fer disponible més llexica en tasques futures.', 'bn': "আমরা ওপেন বিশ্ববিদ্যালয়ের ওপেন বিশ্ববিদ্যালয়ের ওনএলপি ল্যাবের অবদান প্রদান করেছি ভূল টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ আমাদের অবদানের ভিত্তিতে 'ইয়াপ- এরপরেও অন্য একটি প্যারাজার' নামের ভিত্তিতে রয়েছে, যার মধ্যে একটি স্থানীয় মোরফোলিক্যাল মডেল, একটি স্থানীয় নির্ভর মড ইউডিপিপিপি দ্বারা ইনপুট নির্ভর করার জন্য আমরা ইয়াপের স্থানীয় নির্ভরশীল ব্যবহার করেছিলাম এবং ৫৮. আমাদের অনুসরণের তদন্তে আমরা কিভাবে মৃত্যুবিজ্ঞান এবং লেক্সিক্যাল সম্পদের মধ্যে যোগাযোগ করার জন্য ইয়াপ ব্যবহার করি তা দেখাতে পারি যে কিভাবে শেষ পর্যন্ত নির্ভর করা শুরু করা যায়,  Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages.  এভাবেই আমরা সম্প্রদায়কে উৎসাহ দিচ্ছি ভবিষ্যতের কাজে এই ধরনের লেক্সিকা তৈরি করতে, পরিবর্তন করতে, অথবা আরো বেশী কিছু", 'et': "Esitleme Iisraeli Avatud Ülikooli ONLP labori panust UD ühisesse ülesandesse mitmekeelse parsimise kohta toortekstist universaalsete sõltuvusteni. Meie panus põhineb üleminekupõhisel parseril nimega `yap - veel üks parser', mis sisaldab iseseisvat morfoloogilist mudelit, iseseisvat sõltuvusmudelit ja ühist morfosüntaktilist mudelit. Ülesandes kasutasime UDPipe'iga morfoloogiliselt eristatud sisendi parsimiseks yap'i iseseisvat sõltuvuspartserit ja saime ametliku skoori 58,35 LAS. Oma järeluuringus kasutame yap'i näitamaks, kuidas morfoloogiliste ja leksikaalsete ressursside kaasamine võib parandada lõpust lõpuni toorsõltuvuste parsimise tulemuslikkust morfoloogiliselt rikka ja vähese ressursiga keele, kaasaegse heebrea keele puhul. Meie heebrea keele tulemused rõhutavad CoNLL-UL-i tähtsust, mis on UD-ga ühilduv standard välistele leksikaalsetele ressurssidele juurdepääsuks, UD-de parsimise parandamiseks, eelkõige morfoloogiliselt rikkalike ja vähese ressursiga keelte puhul. Seega julgustame kogukonda luua, teisendada või teha kättesaadavaks rohkem sellist leksikat tulevastes ülesannetes.", 'fi': "Esittelemme Israelin avoimen yliopiston ONLP-laboratorion panoksen UD:n yhteiseen tehtävään monikielisestä jäsentämisestä raakatekstistä universaaleihin riippuvuuksiin. Työmme perustuu siirtymäpohjaiseen parseriin nimeltä `yap - yet another parser', joka sisältää erillisen morfologisen mallin, erillisen riippuvuusmallin ja yhteisen morfosyntaktisen mallin. Tehtävässä käytimme yapin itsenäistä riippuvuuden parseria analysoimaan UDPipen morfologisesti erottelemaa syötettä ja saimme virallisen pistemäärän 58,35 LAS. Jatkotutkimuksessamme käytämme yappia osoittaaksemme, miten morfologisten ja leksikaalisten resurssien yhdistäminen voi parantaa end-to-end-raw-dependency-jäsentelyn suorituskykyä morfologisesti rikkaan ja vähäresurssisen kielen, modernin heprean tapauksessa. Tuloksemme hepreasta korostavat CoNLL-UL:n merkitystä, joka on UD-yhteensopiva standardi ulkoisten leksikaalisten resurssien käyttämisessä, UD-jäsentämisen parantamisessa, erityisesti morfologisesti rikkailla ja vähäresurssisilla kielillä. Kannustamme siten yhteisöä luomaan, muuntamaan tai asettamaan saataville enemmän tällaista sanastoa tulevissa tehtävissä.", 'cs': "Představujeme příspěvek ONLP laboratoře Open University of Izrael ke sdílenému úkolu UD na vícejazyčné parsování ze surového textu do univerzálních závislostí. Náš příspěvek je založen na parseru založeném na přechodu nazvaném `yap' yet another parser', který zahrnuje samostatný morfologický model, samostatný model závislosti a joint morphosyntaktický model. V úkolu jsme použili yapův samostatný závislostní parser k analýze vstupu morfologicky rozděleného UDPipe a získali oficiální skóre 58.35 LAS. V našem následném šetření používáme yap k ukázání, jak začlenění morfologických a lexikálních zdrojů může zlepšit výkon end-to-end parsování raw-to-dependencies v případě morfologicky bohatého a nízko zdrojového jazyka, moderní hebrejštiny. Naše výsledky v hebrejštině zdůrazňují význam CoNLL-UL, standardu kompatibilního s UD pro přístup k externím lexikálním zdrojům, pro zlepšení end-to-end UD parsing, zejména pro morfologicky bohaté jazyky s nízkými zdroji. Proto podporujeme komunitu, aby vytvářela, konvertovala nebo zpřístupnila další takovou lexiku v budoucích úkolech.", 'az': 'Biz İsrail Üniversitesi Açıq Üniversitesində ONLP laboratuvarının çoxlu dil ayırılmasından Universal Dependenciyə qədər öyrənməsi haqqında UD paylaşdığı işi göstəririk. Bizim səbəbimiz "yap - başqa bir parçacıq" adlı keçmiş parçacıya dayanılır. Bu, tək bir morfolojik modeli, tək bir bağımlılıq modeli və birlikdə morfosintaktik modeli içərir. Bu işdə, UDPipe tarafından giriş morfolojik dəyişməsini analiz etmək üçün yap ının yalnız təvəkküllük analizi istifadə etdik və resmi dəyişməsini 58.35 LAS aldıq. Bizim araşdırmalarımızda yap istifadə edirik ki, morfolojik zəngin və düşük ressurs dilinin, Modern Hebrew dilinin, morpholojik, zəngin və düşük ressurs dilinin, son-to-end-end-to-dependency dilinin təhsil edilməsinin necə olduğunu göstərsin. İbraniyyətimizin sonuçlarımız CoNLL-UL, dış leksik kaynaqlarına istifadə etmək üçün UD-kompatibil standartdır, end-to-end UD analizi artırmaq üçün, özlərinə də morfolojik zəngin və düşük ressurs dillərinə istifadə etmək üçün. Beləliklə, ümmətinə gələcək işlərdə böyük lexika yaratmaq, dönüştürmək və ya daha çox faydalanmaq üçün təşkil edirik.', 'hr': "Predstavljamo doprinos laboratorije ONLP-a na Otvorenom Univerzitetu Izraela na zajednički zadatak UD-a o multijezičkom analizu od sirovog teksta do univerzalnih ovisnosti. Naš doprinos je baziran na prethodnom analizatoru koji se zove 'yap - još jedan analizator', koji uključuje samostalni morfološki model, model zavisnosti samostalnosti i zajednički morfosintaktički model. U zadatku smo iskoristili samostalni analizač zavisnosti yapa kako bi analizirali ulaz morfološki disambiguiran od UDPipe i dobili službeni rezultat 58,35 LAS-a. U našoj slijedećoj istrazi koristimo yap da pokažemo kako bi uključivanje morfoloških i leksičkih resursa moglo poboljšati učinkovitost analize zavisnosti kraja do kraja u slučaju morfološki bogatog i niskog jezika, modernog hebrejskog jezika. Naši rezultati na hebrejskom podsjećaju važnost CoNLL-UL-a, UD-kompatibilnog standarda za pristup vanjskim leksičkim resursima, za poboljšanje analize UD-a do kraja, posebno za morfološki bogate i niske resurse jezike. Stoga poticamo zajednicu da stvori, preobrati ili dostavi takvu leksiju u budućim zadatkima.", 'he': "אנחנו מציגים את התרומה של מעבדת ONLP באוניברסיטת ישראל הפתוחה למשימה המשותפת של ארצות הברית על בדיקת רבות שפות מהטקסט גרוע לתלויות יוניברסליות. Our contribution is based on a transition-based parser called `yap - yet another parser', which includes a standalone morphological model, a standalone dependency model, and a joint morphosyntactic model.  במשימה השתמשנו במחקר ההתמודדות הבודד של יאפ כדי לאבד את הכניסה המורפולוגית שנפרדה על ידי UDPipe, ולקבל את הציון הרשמי של 58.35 LAS. בחקירה הבאה שלנו אנו משתמשים באפ כדי להראות כיצד הכילוי של משאבים מורפולוגיים ולקסיקליים יכול לשפר את ההפעלה של מערכת התמכויות ראשונות לסוף במקרה של שפה מורפולוגית עשירה ומורפולוגית נמוכה משאבים, היברית המודרנית. התוצאות שלנו על היברית מזכירות את חשיבותו של CoNLL-UL, סטנדרט מתאים UD לגישה למשאבים לקסיים חיצוניים, לשיפור בדיקת UD סוף-סוף, במיוחד לשפות עשירות מורפולוגית וממשאבים נמוכים. כך אנו מעודדים את הקהילה ליצור, להפוך או להפעיל לקסיקה כזאת זמינה יותר במשימות עתידות.", 'sk': "Predstavljamo prispevek laboratorija ONLP na Odprti univerzi v Izraelu k skupni nalogi UD na področju večjezičnega razčlenjanja od surovega besedila do univerzalnih odvisnosti. Naš prispevek temelji na prehodnem razčlenjevalniku, imenovanem `yap - še en razčlenjevalnik', ki vključuje samostojni morfološki model, samostojni model odvisnosti in skupni morfosintaktični model. V nalogi smo uporabili yap-ov samostojni razčlenjevalnik odvisnosti za razčlenjevanje vhodnih vhodov morfološko razločenih z UDPipe in pridobili uradno oceno 58,35 LAS. V naši nadaljnji raziskavi uporabljamo yap, da pokažemo, kako lahko vključitev morfoloških in leksikalnih virov izboljša učinkovitost razčlenitve neodvisnosti od konca do konca v primeru morfološko bogatega jezika z nizkimi viri, sodobnega hebrejščine. Naši rezultati o hebrejščini poudarjajo pomen CoNLL-UL, standarda, ki je združljiv z UD-jem, za dostop do zunanjih leksikalnih virov, za izboljšanje razčlenitve UD-jezikov od konca do konca, zlasti za morfološko bogate jezike in jezike z nizkimi viri. Tako spodbujamo skupnost k ustvarjanju, pretvorbi ali dajanju na voljo več takih leksikov v prihodnjih nalogah.", 'ha': "Tuna halatar da rabon lab na OLP a Jami'ar Open University of Isrã'ĩla zuwa the UD na raba aikin da ake yi wa parse multilingu daga raw text to Universal dependanci. Bayanmu da zai ɗauki a kan wani parser mai bassi da aka kallo `yap- da wani Parser', wanda ke ƙunsa da wata motel mai maras da ɗabi'a, da wani misali wanda ke daidaita, da wani matabbaci wanda ke tsaya, da kuma wata motel mai marafosyntact. In aiki da muka yi amfani da yap`s tsaye-kaɗan parse to parse inputs morfologically disbarred by UD, kuma muka sami nau'in rubutun 58.35 LES. Daga ƙaraminmu, za mu yi amfani da mazaɓa ko ko da za'a nuna yadda za'a shigar da abincin morfologi da leksisi ko zai fi ƙara aikin marubuci na ƙari-zuwa-baka-daidaici, idan na cikin harshen marufukiya na morfologically-matajiri da wuri-resource, Yahudin Kizaman. Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages.  Kamar haka ne Muke kwaɗaitar da jamii, su halitta, su mayar, kõ kuwa su sami wasu aikin nan a ƙarshe.", 'bo': "We present the contribution of the ONLP lab at the Open University of Israel to the UD shared task on multilingual parsing from raw text to Universal Dependencies. Our contribution is based on a transition-based parser called `yap - yet another parser', which includes a standalone morphological model, a standalone dependency model, and a joint morphosyntactic model. In the task we used yap's standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS. In our follow-up investigation we use yap to show how the incorporation of morphological and lexical resources may improve the performance of end-to-end raw-to-dependencies parsing in the case of a morphologically-rich and low-resource language, Modern Hebrew. Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages. འུ་ཚོས་མི་ཚོགས་སྡེར་ལ་རང་སྤྱི་ཚོགས་ལ་རང་སྤྱི་ཚོགས་ཀྱི་ལས་འགུལ་གྱི་ནང་དུ་གསར་བསྐྲུན་, བསྒྱུར་ན་དང་ཡང་ན་འདྲ་བར", 'jv': "Awakdhéwé nggawe nyumbang tanggal LP Lab ning Open Universite di Isirael nang nggawe Universite di sistem (Open Universite) kanggo nyelarakno urip bantuan ingkang urip bantuan teks nggo Universite Awak dhéwé iné kabèh basa karo transform-basa pater sing nganggo 'Yap - gak nggawe oleh' seneng sampek modèl, ngon sampek akeh-akeh model, sampek sampek model, lan akeh dumateng modèl. In the task we used Nang istrangé awakdhéwé nggawe ngubah dhéwé iso nggambar aturan sing bisa nguasai perusahaan modorolêk lan kelêksi kuwi nggawe geranggap tarjamahan karo hal-end-to-end Awak dhéwé éntuk cara-cara sing nggawe coNLL-Ul, saben udèh-kompatible kanggo ngakses supar leksikalo penyusok, kanggo nglanggar aturan end-to-end Awak dhéwé nggawe komunitas kanggo nggawe, njuk, njuk njaluk, ngono iso nggawe lewat cara sing luwih kanggo nggawe gerakan."}
{'en': 'ELMoLex : Connecting ELMo and Lexicon Features for Dependency Parsing', 'ar': 'ELMoLex: توصيل ميزات ELMo والمعجم لتحليل التبعية', 'pt': 'ELMoLex: Conectando recursos ELMo e Lexicon para análise de dependência', 'fr': "ElMolex\xa0: Connexion des fonctionnalités ElMo et Lexicon pour l'analyse des dépendances", 'es': 'ElMolex: Conexión de las funciones de eLMO y Lexicon para el análisis de dependencias', 'ja': 'ELMoLex ：依存関係解析のためのELMo機能とLexicon機能の接続', 'zh': 'ELMoLex曰:接 ELMo 词典以恃解析', 'hi': 'ELMoLex: निर्भरता पार्सिंग के लिए ELMo और शब्दकोश सुविधाओं को कनेक्ट करना', 'ru': 'ELMoLex: Подключение функций ELMo и Lexicon для анализа зависимостей', 'ga': 'ELMoLex: Gnéithe ELMo agus Foclóir a nascadh le haghaidh Parsáil Spleáchais', 'ka': 'ELMoLex: ELMo და Lexicon ფუტურების დაკავშირება განსაზღვრებულობისთვის', 'kk': 'ELMoLex: Тәуелсіздік талдау үшін ELMo және Lexicon қасиеттерін қосылу', 'lt': 'ELMoLex: ELMo ir Lexicon ryšys priklausomybės analizei', 'el': 'Σύνδεση των χαρακτηριστικών του και του λεξικού για ανάλυση εξάρτησης', 'hu': 'ELMoLex: ELMo és Lexicon funkciók csatlakoztatása a függőség értelmezéséhez', 'it': "ELMoLex: Collegamento delle funzionalità ELMo e Lexicon per l'analisi delle dipendenze", 'ml': 'ELMoLex: ആശ്രയിച്ച പാര്\u200dസിങ്ങിനുള്ള ELMo- യെയും ലെക്സിക്സണ്\u200d വിശേഷതകളെയും ബന്ധപ്പെടുത്തുന്നു', 'mt': 'ELMoLex: Nikkollegaw il-Karatteristiċi tal-ELMo u tal-Lexicon għall-Analiżi tad-Dipendenza', 'mn': 'ELMoLex: ELMo болон Lexicon Features for Dependency Parsing холбоотой', 'no': 'ELMoLex: Koplar til ELMo- og Lexicon- funksjonar for avhengighetstolking', 'mk': 'ELMoLex: Поврзување на ELMo и Lexicon функции за анализирање зависности', 'ms': 'ELMoLex: Connecting ELMo and Lexicon Features for Dependency Parsing', 'ro': 'ELMoLex: Conectarea funcțiilor ELMo și Lexicon pentru analizarea dependenței', 'sr': 'ELMoLex: povezivanje ELMo i leksičkih karakteristika za analizu zavisnosti', 'si': 'ELMoLex: ELMo සහ Lexicon විශේෂතාවක් සම්බන්ධ විශේෂණය සඳහා සම්බන්ධ කරනවා', 'so': 'ELMoLex: Connecting ELMo and Lexicon Features for Dependency Parsing', 'sv': 'ELMoLex: Ansluta ELMo- och Lexiconfunktioner för beroendetolkning', 'pl': 'ELMoLex: Łączenie funkcji ELMo i Lexikonu dla parowania zależności', 'ur': 'ELMoLex: ELMo اور Lexicon Features for Dependency Parsing Connecting', 'ta': 'ELMoLex: சார்ந்த பாடலுக்கான ELMo மற்றும் Lexicon பண்புகளை இணைக்கிறது', 'vi': 'Máy phát triển cung cấp năng lượng', 'uz': 'ELMoLex: ELMo va Lekson parametrlari', 'bg': 'Свързване на функциите на ЕЛМО и Лексикона за анализ на зависимостта', 'nl': 'ELMoLex: Verbinding van ELMo- en Lexiconfuncties voor afhankelijkheidsparsing', 'hr': 'ELMoLex: Povezivanje ELMo i leksičkih karakteristika za razmatranje zavisnosti', 'da': 'ELMoLex: Tilslutning af ELMo- og Lexiconfunktioner til afhængighedsfortolkning', 'de': 'ELMoLex: Verbindung von ELMo- und Lexikon-Funktionen für Dependency Parsing', 'id': 'ELMoLex: Menyambung Karakteristik ELMo dan Lexicon untuk Penganalisan Dependensi', 'ko': 'ELMoLex: 종속성 해결을 위해 ELMo 및 사전 기능 연결', 'fa': 'ELMoLex: ارتباط ویژه های ELMo و Lexicon برای تحلیل بستگی', 'sw': 'ELMoLex: Kuunganisha ELMo na Tazo za Lexico kwa Kutegemea Uhuru', 'tr': 'ELMoLex: Bağlamlık Taýramlygy üçin ELMo we Lexicon Özellikleri Bağlantýa', 'af': 'ELMoLex: Konnekteer ELMo en Lexicon-eienskappe vir afhanklikheid verwerking', 'sq': 'ELMoLex: Lidhja e funksioneve ELMo dhe Lexicon për analizimin e varësive', 'am': 'ELMoLex:', 'bn': 'ELMoLex: নির্ভর পার্সিং এর জন্য ELMo এবং লেক্সিকোন বৈশিষ্ট্য সংযোগ সংযোগ করা হচ্ছে', 'hy': 'ԷլՄոլեքս. Ախխտավորության վերլուծության ELMo և Լեքսիկոնի առանձնահատկություններ կապելը', 'ca': 'ELMoLex: Conectar ELMo i Lexicon Features for Dependence Parsing', 'cs': 'ELMoLex: Propojení funkcí ELMo a Lexikonu pro analýzu závislostí', 'bs': 'ELMoLex: povezivanje ELMo i leksičkih karakteristika za analizu zavisnosti', 'et': 'ELMoLex: ELMo ja Lexiconi funktsioonide ühendamine sõltuvuse parsimiseks', 'fi': 'ELMoLex: ELMo- ja Lexicon-ominaisuuksien yhdistäminen riippuvuuden analysointia varten', 'az': 'ELMoLex: bağlılıq analizi üçün ELMo və Lexicon özelliklərini bağlayır', 'jv': 'el', 'sk': 'ELMoLex: Povezovanje funkcij ELMo in Lexicon za razčlenitev odvisnosti', 'he': 'ELMoLex: חיבור תכונות ELMo ולקסיקון עבור בדיקת תלויות', 'ha': 'KCharselect unicode block name', 'bo': 'ELMoLex: མཐུད་པ ELMo་དང་Lexicon རྒྱུ་ཆོས་ལ་རྟེན་འབྲེལ་བ་ཡིན་པ'}
{'en': 'In this paper, we present the details of the neural dependency parser and the neural tagger submitted by our team ‘ParisNLP’ to the CoNLL 2018 Shared Task on parsing from raw text to Universal Dependencies. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively : we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations ; we utilize disambiguated, embedded, morphosyntactic features from lexicons (Sagot, 2018), which complements the existing feature set. Henceforth, we call our ', 'ar': 'في هذه الورقة ، نقدم تفاصيل محلل التبعية العصبية والعلامة العصبية التي أرسلها فريقنا "ParisNLP" إلى المهمة المشتركة لـ CoNLL 2018 حول التحليل من النص الخام إلى التبعيات العالمية. نحن نزيد من محلل Biaffine (BiAF) العميق (Dozat and Manning ، 2016) بميزات جديدة لأداء تنافسي: نحن نستخدم نسخة غير محدودة من ميزات ELMo (Peters et al. ، 2018) التي توفر تمثيلات للكلمات تعتمد على السياق ؛ نحن نستخدم ميزات غير غامضة ومضمنة وصرفية من المعاجم (Sagot ، 2018) ، والتي تكمل مجموعة الميزات الحالية. من الآن فصاعدًا ، نطلق على نظامنا اسم "ELMoLex". بالإضافة إلى دمج عمليات دمج الأحرف ، تستفيد ELMoLex من متجهات الكلمات المدربة مسبقًا ، و ELMo والميزات الصرفية (كلما كان ذلك متاحًا) للتعامل بشكل صحيح مع الكلمات النادرة أو غير المعروفة السائدة في اللغات ذات التشكل المعقد. احتلت ELMoLex المرتبة 11 من خلال مقياس نقاط المرفق المسمى (70.64٪) ، مقياس LAS المدرك لعلم التشكل (55.74٪) والمرتبة 9 من خلال مقياس التبعية Bilexical (60.70٪).', 'pt': "Neste artigo, apresentamos os detalhes do analisador de dependência neural e do tagger neural enviado por nossa equipe `ParisNLP' à tarefa compartilhada CoNLL 2018 na análise de texto bruto para dependências universais. Aumentamos o analisador profundo Biaffine (BiAF) (Dozat e Manning, 2016) com novos recursos para um desempenho competitivo: utilizamos uma versão indomain dos recursos ELMo (Peters et al., 2018) que fornecem representações de palavras dependentes do contexto; utilizamos recursos desambiguados, incorporados e morfossintáticos de léxicos (Sagot, 2018), que complementam o conjunto de recursos existente. Daqui em diante, chamamos nosso sistema de 'ELMoLex'. Além de incorporar a incorporação de caracteres, o ELMoLex se beneficia de vetores de palavras pré-treinados, ELMo e recursos morfossintáticos (sempre que disponíveis) para lidar corretamente com palavras raras ou desconhecidas que são predominantes em idiomas com morfologia complexa. O ELMoLex ficou em 11º na métrica Labeled Attachment Score (70,64%), métrica LAS com reconhecimento de morfologia (55,74%) e em 9º na métrica de dependência Bilexical (60,70%).", 'fr': "Dans cet article, nous présentons les détails de l'analyseur de dépendances neuronales et du tagger neuronal soumis par notre équipe «\xa0ParisNLP\xa0» à la tâche partagée ConLL 2018 sur l'analyse du texte brut vers les dépendances universelles. Nous augmentons l'analyseur biaffine profond (BiAF) (Dozat et Manning, 2016) avec de nouvelles fonctionnalités pour une performance compétitive\xa0: nous utilisons une version indomain des fonctionnalités ElMo (Peters et al., 2018) qui fournissent des représentations de mots dépendantes du contexte\xa0; nous utilisons des fonctionnalités morphosyntaxiques désambiguïsées, intégrées et issues de lexiques (Sagot, 2018), qui complète l'ensemble de fonctionnalités existantes. Désormais, nous appelons notre système «\xa0ElMolex\xa0». En plus d'intégrer des caractères, ElMolex bénéficie de vecteurs de mots pré-entraînés, d'ElMo et de fonctionnalités morphosyntaxiques (le cas échéant) pour gérer correctement les mots rares ou inconnus qui prévalent dans les langues à morphologie complexe. ElMolex s'est classé 11e selon la métrique Labeled Attachment Score (70,64\xa0%), la métrique LAS tenant compte de la morphologie (55,74\xa0%) et la 9e selon la métrique de dépendance bilexique (60,70\xa0%).", 'es': 'En este artículo, presentamos los detalles del analizador de dependencias neuronales y el etiquetador neuronal presentados por nuestro equipo «PariSNLP» a la tarea compartida de CoNll 2018 sobre el análisis del texto sin procesar a las dependencias universales. Aumentamos el analizador profundo de Biaffine (BiAF) (Dozat y Manning, 2016) con funciones novedosas para un rendimiento competitivo: utilizamos una versión en el dominio de las funciones de eLMO (Peters et al., 2018) que proporcionan representaciones de palabras dependientes del contexto; utilizamos características morfosintácticas desambiguadas, incrustadas y de léxicos (Sagot, 2018), que complementa el conjunto de funciones existente. De ahora en adelante, llamaremos a nuestro sistema «ElMolex». Además de incorporar incrustaciones de caracteres, ElMolex se beneficia de vectores de palabras previamente entrenados, ELMO y características morfosintácticas (siempre que estén disponibles) para manejar correctamente palabras raras o desconocidas que prevalecen en idiomas con morfología compleja. ElMolex ocupó el puesto 11 por la métrica de puntuación de apego etiquetado (70,64%), la métrica LAS sensible a la morfología (55,74%) y el noveno por la métrica de dependencia biléxica (60,70%).', 'ja': '本稿では、チーム`ParisNLP`がCoNLL 2018 Shared Taskに提出した、RAWテキストからUniversal Dependenciesへの解析に関するニューラル依存性解析器とニューラルタガーの詳細を紹介する。 DEEP Biaffine (BiAF)パーサー(Dozat and Manning, 2016)を、競争的に実行するための新規の機能で拡張します。文脈依存的な単語表現を提供するELMo機能のインドメインバージョン(Peters et al., 2018)を利用します。既存の機能セットを補完する、辞書からの曖昧さを解消し、埋め込まれた、形態素構文機能を利用します(Sagot, 2018 )。 これ以降、私たちはシステムを「ELMoLex」と呼びます。 文字埋め込みに加えて、ELMoLexは、複雑な形態を持つ言語で普及している希少または未知の単語を正しく扱うために、事前にトレーニングされた単語ベクトル、ELMo、およびモルフォシンタクティック機能（利用可能な場合はいつでも）の恩恵を受けます。 ELMoLexは、ラベル付き添付スコアメトリック（ 70.64 ％ ）、形態学的に認識されるLASメトリック（ 55.74 ％ ）によって11位にランクインし、Bilexical dependency metric （ 60.70 ％ ）によって9位にランクインしました。', 'hi': "इस पेपर में, हम तंत्रिका निर्भरता पार्सर और हमारी टीम 'पेरिसएनएलपी' द्वारा प्रस्तुत तंत्रिका टैगर का विवरण प्रस्तुत करते हैं, जो कच्चे पाठ से यूनिवर्सल निर्भरताओं तक पार्सिंग पर CoNLL 2018 साझा कार्य है। हम प्रतिस्पर्धी प्रदर्शन करने के लिए उपन्यास सुविधाओं के साथ गहरे Biaffine (BiAF) पार्सर (Dozat और Manning, 2016) को बढ़ाते हैं: हम ELMo सुविधाओं (पीटर्स एट अल। हम शब्दकोशों (Sagot, 2018) से disambiguated, एम्बेडेड, morphosyntactic सुविधाओं का उपयोग करते हैं, जो मौजूदा सुविधा सेट को पूरक करता है। इसके बाद से, हम अपने सिस्टम को 'ELMoLex' कहते हैं। चरित्र एम्बेडिंग को शामिल करने के अलावा, ELMoLex पूर्व-प्रशिक्षित शब्द वैक्टर, ELMo और morphosyntactic सुविधाओं (जब भी उपलब्ध हो) से लाभ दुर्लभ या अज्ञात शब्दों को सही ढंग से संभालने के लिए जो जटिल आकृति विज्ञान वाली भाषाओं में प्रचलित हैं। ELMoLex लेबल अनुलग्नक स्कोर मीट्रिक (70.64%), आकृति विज्ञान-जागरूक LAS मीट्रिक (55.74%) द्वारा 11 वें स्थान पर है और बिलेक्सिकल निर्भरता मीट्रिक (60.70%) द्वारा 9 वें स्थान पर है।", 'ru': 'В этой статье мы представляем детали анализатора нейронных зависимостей и нейронного тегера, представленные нашей командой «ParisNLP» совместной задаче CoNLL 2018 по анализу от необработанного текста до универсальных зависимостей. Мы дополняем глубокий парсер Biaffine (BiAF) (Dozat and Manning, 2016) новыми функциями для обеспечения конкурентоспособности: мы используем индоменную версию функций ELMo (Peters et al., 2018), которые предоставляют контекстно-зависимые представления слов; мы используем дезамбигированные, встроенные, морфосинтаксические признаки из лексиконов (Sagot, 2018), которые дополняют существующий набор признаков. Отныне мы называем нашу систему «ELMoLex». В дополнение к внедрению символов, ELMoLex пользуется предварительно обученными векторами слов, ELMo и морфосинтаксическими признаками (при наличии) для правильной обработки редких или неизвестных слов, которые распространены в языках со сложной морфологией. ELMoLex занимал 11-е место по метрике меченого вложения (70,64%), метрике LAS, основанной на морфологии (55,74%), и 9-е место по метрике билексической зависимости (60,70%).', 'zh': '本文者,言吾团队"ParisNLP"与CoNLL 2018共事者神经依赖性解析器与神经标器之详细信息,事涉于始解析通用。 吾以新益深Biaffine(BiAF)解析器(DozatManning,2016)以有竞争力:吾以ELMoindomain版(Peters等,2018),上下文关单词也。 吾因词典之消歧义,嵌入式形句法(Sagot,2018),此见特徵集之补也。 自是以后,号为"ELMoLex"。 除合字符嵌外,ELMoLex益训练之词向量,ELMo形句法特徵(但可用),以正杂形之语行稀未知单词。 ELMoLex在标记附件分数指标(70.64%),形态学感知LAS指标(55.74%)中排名第11位,在Bilexical依赖性指标(60.70%)中排名第9位。', 'ga': "Sa pháipéar seo, cuirimid i láthair sonraí an pharsálaí spleáchais néaraigh agus an clibeálaí néaraigh a chuir ár bhfoireann `ParisNLP' isteach chuig Tasc Comhroinnte CoNLL 2018 ar pharsáil ó théacs amh go Spleáchais Uilíocha. Méadaimid an parsálaí domhain Biaffine (BiAF) (Dozat and Manning, 2016) le gnéithe núíosacha chun feidhmiú go hiomaíoch: bainimid úsáid as leagan indomain de ghnéithe ELMo (Peters et al., 2018) a sholáthraíonn léiriúcháin focal a bhraitheann ar an gcomhthéacs; bainimid úsáid as gnéithe dídhébhríoch, leabaithe, morphosyntactic ó fhoclóirí (Sagot, 2018), a chomhlánaíonn an tacar gnéithe atá ann cheana féin. As seo amach, tugaimid 'ELMoLex' ar ár gcóras. Chomh maith le neadú carachtair a ionchorprú, baineann ELMoLex leas as veicteoirí focal réamhoilte, gnéithe ELMo agus morphosyntactic (nuair a bhíonn siad ar fáil) chun focail neamhchoitianta nó anaithnide atá forleithne i dteangacha le moirfeolaíocht chasta a láimhseáil i gceart. Rangaíodh ELMoLex sa 11ú háit de réir méadrach Scór Ceangaltán Lipéadaithe (70.64%), méadrach LAS atá feasach ar mhoirfeolaíocht (55.74%) agus rangaithe sa 9ú háit de réir méadrach spleáchais Bhileacsúil (60.70%).", 'ka': 'ამ დომენტში ჩვენ ჩვენ ჩვენი ჯგუფი `ParisNLP\' მხოლოდ გაყოფილი საქმე CoNLL 2018-ში გაყოფილი საქმე ტექსტიდან უნივერსი განსაცემებებისთვის გადაწყენება და ნეიროლური ტექსტის განსაცემების განმავლება ჩვენ კონპექტიურად გავაკეთებთ ძალიან დიაგფინის (BiAF) პასუტერი (Dozat და Manning, 2016) რომელიც პრომენტიური ფუნქციებით, რომელიც კონპექტიურად გავაკეთებთ: ჩვენ გამოყენებთ ELMo ფუნქციების საშუალო ვერსი ჩვენ გამოიყენებთ განსხვავებული, დავყენებული, მოპორფსინტაქტიური ფუნქციები (Sagot, 2018), რომელიც კომპლენტირებულ ფუნქციების შესახებ. შემდეგ ჩვენი სისტემა "ELMoLex". ELMoLex გამოიყენება საკუთარი სიტყვის გვექტორიდან, ELMo და მოპროსინტაქტიური ფუნქციებიდან (როდესაც ხელსახულია) სწორად გამოყენებლად წარმოდგენებული ან უცნობი სიტყვის, რომლებიც კომპლექსი მოპ ELMoLex 11 წერტილი მარტიკით (70.64%), მოპოლოგიური LAS მეტრიკით (55.74%) და 9 წერტილი ბილექსიკალური დადარჩენების მეტრიკით (60.70%).', 'el': 'Σε αυτή την εργασία, παρουσιάζουμε τις λεπτομέρειες του αναλύτη νευρωνικής εξάρτησης και του νευρικού δείκτη που υποβλήθηκαν από την ομάδα μας στην κοινή εργασία για την ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Ενσωματώνουμε τον βαθύ αναλυτή με καινοτόμα χαρακτηριστικά για ανταγωνιστική απόδοση: χρησιμοποιούμε μια ινδομανική έκδοση των χαρακτηριστικών που παρέχουν αναπαραστάσεις λέξεων ανάλογα με το περιβάλλον. Χρησιμοποιούμε αποσαφηνισμένα, ενσωματωμένα, μορφοσυντακτικά χαρακτηριστικά από λεξικά (το οποίο συμπληρώνει το υπάρχον σύνολο χαρακτηριστικών. Στο εξής, ονομάζουμε το σύστημά μας "ELMOLex". Εκτός από την ενσωμάτωση χαρακτήρων, το επωφελείται από προ-εκπαιδευμένα διανύσματα λέξεων, και μορφοσυντακτικά χαρακτηριστικά (όποτε είναι διαθέσιμα) για να χειριστεί σωστά σπάνιες ή άγνωστες λέξεις που επικρατούν σε γλώσσες με σύνθετη μορφολογία. Το ELMoLex κατατάχθηκε 11η με βάση τη μετρική βαθμολογία επισυνάπτοντος (70.64%) και 9η με βάση τη μετρική διεξική εξάρτηση (60.70%).', 'hu': "Ebben a tanulmányban bemutatjuk az idegi függőség elemző és a neurális címkéző részleteit, amelyet csapatunk `ParisNLP' küldött be a CoNLL 2018 Shared Task részére a nyers szövegről az univerzális függőségekre. A mély Biaffine (BiAF) elemzőt (Dozat és Manning, 2016) új funkciókkal bővítjük versenyképes teljesítéshez: az ELMo funkciók indomain verzióját (Peters et al., 2018), amelyek kontextusfüggő szóreprezentációkat biztosítanak; A lexikonok (Sagot, 2018) egyértelmű, beágyazott morfoszintatikus funkcióit használjuk, amelyek kiegészítik a meglévő funkciókészletet. Ezentúl a rendszerünket ELMoLexnek hívjuk. A karakterek beágyazása mellett az ELMoLex előre képzett szóvektorokból, ELMo-ból és morfoszintatikus tulajdonságokból áll (amennyiben rendelkezésre állnak), hogy helyesen kezelje a ritka vagy ismeretlen szavakat, amelyek komplex morfológiájú nyelveken elterjednek. Az ELMoLex a 11. helyen helyezett a Címkézett Csatlakozási Pontszám metrika (70,64%), a Morfológia-tudatos LAS metrika (55,74%) és a 9. helyen a Bilexikus függőség metrika alapján (60,70%).", 'lt': 'Šiame dokumente pristatome išsamią informaciją apie neurologinio priklausomybės analizatorių ir mūsų komandos „ParisNLP“ pateiktą neurologinį žymenį CoNLL 2018 m. bendrai užduotims analizuoti iš žaliavinio teksto į universaliąsias priklausomybes. Mes padidiname gilią Biaffine (BiAF) analizatorių (Dozat ir Manning, 2016 m.) naujomis savybėmis, kad galėtume konkuruoti: naudojame vidinę ELMo savybių versiją (Peters et al., 2018 m.), kuri teikia nuo konteksto priklausomus žodžių vaizdus; mes naudojame nedambiguotas, įterptas, morfosintaktines lexikonų savybes (Sagot, 2018), kurios papildo esamą savybių rinkinį. Nuo šiol vadiname savo sistemą ELMoLex. In addition to incorporating character embeddings, ELMoLex benefits from pre-trained word vectors, ELMo and morphosyntactic features (whenever available) to correctly handle rare or unknown words which are prevalent in languages with complex morphology.  ELMoLex buvo 11-asis pagal pažymėto pridėjimo rodiklio metrinį rodiklį (70,64 %), morfologiškai žinomą LAS metrinį rodiklį (55,74 %) ir 9-asis pagal bilieksinį priklausomybės metrinį rodiklį (60,70 %).', 'it': 'In questo articolo, presentiamo i dettagli del parser di dipendenza neurale e del tagger neurale presentato dal nostro team `ParisNLP\' al CoNLL 2018 Shared Task sull\'analisi dal testo grezzo alle dipendenze universali. Aumentiamo il parser profondo Biaffine (BiAF) (Dozat e Manning, 2016) con nuove funzionalità per eseguire in modo competitivo: utilizziamo una versione indomain delle funzionalità ELMo (Peters et al., 2018) che forniscono rappresentazioni di parole contestuali; Utilizziamo funzionalità morfosintattiche disambiguate, incorporate, dai lessici (Sagot, 2018), che completano il set di funzionalità esistente. D\'ora in poi, chiamiamo il nostro sistema "ELMoLex". Oltre a incorporare incorporazioni di caratteri, ELMoLex beneficia di vettori di parole pre-addestrati, ELMo e caratteristiche morfosintattiche (quando disponibili) per gestire correttamente parole rare o sconosciute che sono prevalenti in linguaggi con morfologia complessa. ELMoLex si è classificato 11esimo per metrica Labeled Attachment Score (70,64%), metrica LAS sensibile alla morfologia (55,74%) e nono per metrica di dipendenza Bilessica (60,70%).', 'kk': 'Бұл қағазда біз невралдық тәуелсіздік талдаушысын және біздің командамыздың "ParisNLP" CoNLL 2018 ортақ тапсырмасына келтірілген невралдық тегжерлерін келтіреміз. Біз биафин (BiAF) талдаушысын (Dozat және Manning, 2016) конкурентті істеу үшін романдық мүмкіндіктермен көтереміз: біз ELMo мүмкіндіктерінің ішкі негізгі нұсқасын (Peters et al., 2018) қолданып, контексті тәуелді сөздерді таңдау ү Біз Лексикон (Sagot, 2018) қасиеттерін қолдануға арналған, ендірілген, морфосинтактикалық қасиеттерді қолданамыз. Содан соң біз жүйемізді "ELMoLex" деп атаймыз. Таңбаларды ендіру үшін ELMoLex сөздер векторларынан, ELMo және морфосинтактикалық мүмкіндіктерінен (кезде болса), комплекс морфология тілдерінде көтерілген немесе беймәлім сөздерді дұрыс шектеу үшін қолданылады. ELMoLex 11- інде белгіленген тіркемелерді метрикалық (70, 64%), морфологиялық LAS метрикалық (55, 74%) деп, 9- інде белгіленген тіркемелерді метрикалық (60, 70%) деп реттеді.', 'ms': "Dalam kertas ini, kami memperkenalkan perincian penghurai dependensi saraf dan tag saraf yang dihantar oleh pasukan kami `ParisNLP' kepada Tugas Berkongsi CoNLL 2018 mengenai hurai dari teks mentah ke Dependensi Universal. Kami menambah parser Biaffine (BiAF) dalam (Dozat and Manning, 2016) dengan ciri-ciri baru untuk dilakukan secara kompetitif: kami menggunakan versi indomain ciri-ciri ELMo (Peters et al., 2018) yang menyediakan perwakilan perkataan tergantung konteks; kita menggunakan ciri-ciri morfosintaktik yang tidak disambiguated, embedded dari leksikon (Sagot, 2018), yang menyempurnakan set ciri-ciri yang ada. Mulai sekarang, kita panggil sistem kita 'ELMoLex'. In addition to incorporating character embeddings, ELMoLex benefits from pre-trained word vectors, ELMo and morphosyntactic features (whenever available) to correctly handle rare or unknown words which are prevalent in languages with complex morphology.  ELMoLex ditangkap ke-11 mengikut Skor Lampiran Label metrik (70.64%), metrik LAS yang sedar-morfologi (55.74%) dan ditangkap ke-9 mengikut metrik dependensi bileksik (60.70%).", 'mt': 'F’dan id-dokument, nippreżentaw id-dettalji tal-analizzatur tad-dipendenza newrali u t-tagger newrali ppreżentat mit-tim tagħna “ParisNLP” lill-CoNLL 2018 Task Konġunt dwar l-analizzazzjoni minn test mhux ipproċessat għal Dipendenzi Universali. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively: we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations;  nużaw karatteristiċi diżambigwati, inkorporati u morfosintattiċi minn lexicons (Sagot, 2018), li jikkomplementaw is-sett ta’ karatteristiċi eżistenti. Minn issa ’l quddiem, aħna nsejħu s-sistema tagħna “ELMoLex”. Minbarra li jinkorpora inkorporazzjonijiet ta’ karattri, ELMoLex jibbenefika minn vetturi tal-kliem imħarrġa minn qabel, ELMo u karatteristiċi morfosintattiċi (kull meta disponibbli) biex jimmaniġġja b’mod korrett kliem rari jew mhux magħruf li huma prevalenti f’lingwi b’morfoloġija kumplessa. ELMoLex ikklassifika l-11-il skont il-punteġġ metriku tal-Attakkament Tikkettat (70.64%), metriku tal-LAS konxju mill-morfoloġija (55.74%) u kklassifikat id-9 skont il-metriku tad-dipendenza bilessika (60.70%).', 'mk': 'Во овој весник, ги претставуваме деталите за анализаторот на нервната зависност и нервниот тагер поднесен од нашиот тим „ ParisNLP “ на Соделената задача CoNLL 2018 за анализирање од суров текст до универзални зависности. Го зголемуваме длабокиот анализатор на Биафин (БиАФ) (Dozat and Manning, 2016) со нови карактеристики за конкурентно изведување: користиме индомејна верзија на карактеристиките на ЕЛМО (Peters et al., 2018), која обезбедува контекстни зависни зборови претставувања; користиме деамбигирани, вградени, морфосинтактички карактеристики од лексиконите (Sagot, 2018), кои го комплиментираат постојниот набор карактеристики. Од сега, го нарекуваме нашиот систем ЕЛМОЛЕКС. Покрај вклучувањето на вклучувањата на карактери, ЕЛМОЛЕКС има корист од предобучени вектори на зборови, ЕЛМО и морфосинтактички карактеристики (кога и да се достапни) за правилно да се справи со ретки или непознати зборови кои се превземаат на јазици со комплексна морфологи ЕЛМОЛЕКС се рангираше на 11-тото место според метричкиот резултат на означениот приклучок (70,64 %), метричкиот резултат на ЛАС со свесност за морфологија (55,74 %) и се рангираше на 9-тото место според метричкиот резултат на билексичната завис', 'ml': "ഈ പത്രത്തില്\u200d നമ്മള്\u200d ന്യൂറല്\u200d ആശ്രയിക്കുന്നതിന്\u200dറെ വിശദീകരണങ്ങളും നമ്മുടെ 'പാരിസ്നെല്\u200dപി' ടീമില്\u200d നിന്ന് 'പാരിസ് എന്\u200dഎല്\u200dപി' നല്\u200dകിയ ന്യൂറല്\u200d ടാഗ്ഗരും കോണ്\u200dഎല ഞങ്ങള്\u200d ആഴത്തെ ബിയാഫിന്\u200dറെ (ബിയാഫിന്\u200d) പരാജയപ്പെടുത്തുന്നു (ഡോസാത്തും മാനിംഗ് 2016) പ്രവർത്തിപ്പെടുത്താനുള്ള പ്രവർത്തകങ്ങളുമായി പ്രവര്\u200dത്തിപ്പിക്കുന്ന പുത്രന ലെക്സിക്കങ്ങളില്\u200d നിന്നും മോര്\u200dഫോസിനിറ്റിക്കുന്ന വിഭാഗങ്ങള്\u200d ഞങ്ങള്\u200d ഉപയോഗിക്കുന്നു, നിലവിലുള്ള വിശേഷസജ്ജീകരണങ്ങള്\u200d പ ഇപ്പോള്\u200d നമ്മുടെ സിസ്റ്റത്തിനെ 'എല്\u200dമോളെക്സ്' എന്ന് വിളിക്കുന്നു. അകത്തേക്ക് ചേര്\u200dക്കുന്ന അക്ഷരരൂപം കൂടാതെ, മുമ്പ് പരിശീലന വാക്ക് വെക്റ്റര്\u200d, ELMo, മോര്\u200dഫോസിനിറ്റിക്ക് വിശേഷങ്ങള്\u200d (എപ്പോഴെങ്കിലും ലഭ്യമായിരിക്കുമ്പോള്\u200d എഎല്\u200dമോളെക്സ് ലേബെല്ലെക്സ് ലാബെല്\u200dഡ് അറ്റാച്മെന്\u200dറ് സ്കോര്\u200d മെറ്റിക്ക് (70. 64%), മോര്\u200dഫോളോളജി അറിയുന്ന ലാസ് മെട്രിക്ക് (55. 74%) കൊണ്ട് ബിലിക്കല്\u200d ആശ്", 'mn': 'Энэ цаасан дээр бид мэдрэлийн хамааралтай хуваалцагч болон бидний багийнх "ParisNLP" CoNLL 2018-н хуваалцагч ажлын тухай мэдрэлийн хамааралтай хуваалцагч болон "Universal Dependencies" руу хуваалцах талаар ярьж байна. Бид биафин (BiAF) хуваарилагч (Dozat and Manning, 2016) руу шинэ өрсөлдөөнтэй ажиллах зохиолуудыг нэмэгдүүлнэ: бид ELMo хувьцааны дотор үндсэн хувилбарыг ашиглаж байна (Peters et al., 2018) гэдэг нь контекст хамааралтай үг илэрхийлэл өгдөг. бид Лексикон (Sagot, 2018) дээр холбогдсон, хөгжигдсэн, морфосинтактикийн төлөвлөгөөг ашигладаг. Дараа нь бид өөрсдийн системийг "ELMoLex" гэж нэрлэдэг. Хараагуудыг нэгтгэхэд, ELMoLex нь илүү сургалтын үг векторуудын, ELMo болон морфосинтактикийн чадваруудын тусламжтайгаар (хэрэглэх үед) ховор эсвэл мэдэхгүй үгсийг зөв засах боломжтой болгодог. ELMoLex 11-р ангид Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэг', 'no': 'I denne papiret viser vi detaljane om den neurale avhengighetsanalyseren og den neurale merkelappen som er sendt av gruppa « ParisNLP » til CoNLL 2018 delt oppgåva om tolking frå råteksten til universele avhengighet. Vi aukar dyppa Biaffine-analyseren (Dozat og Manning, 2016) med romanske funksjonar for å utføra konkurrentleg: vi bruker ein innehovudversjon av ELMo-funksjonar (Peters et al., 2018) som gir kontekstavhengige ord-representasjonar. brukar vi disambiguate, innebygde, morfosyntaktiske funksjonar frå lexicons (Sagot, 2018), som complementerer den eksisterande funksjonen. I dag kallar vi systemet vårt «ELMoLex». I tillegg til inkorprering av teiknkombinasjonar, vil ELMoLex bruka frå føretrainerte ordvektorar, ELMo og morphosyntaktiske funksjonar (når det er tilgjengeleg) for å retta handtera sjeldre eller ukjende ord som er utbredt i språk med komplekse morfologi. ELMoLex rangerte 11 av merkelige vedleggskområde metrisk (70,64%), MAS-metrisk (55,74%) og rangerte 9 av Bileksisk avhengighetsmetrisk (60,70%).', 'pl': 'W niniejszym artykule przedstawiamy szczegóły parsera zależności neuronowej i tagera neuronowego przesłanego przez nasz zespół `ParisNLP\' do wspólnego zadania CoNLL 2018 dotyczącego parsowania tekstu surowego do uniwersalnych zależności. Rozszerzamy głęboki parser biafiny (BiAF) (Dozat i Manning, 2016) o nowe funkcje, aby działać konkurencyjnie: wykorzystujemy indomanową wersję funkcji ELMo (Peters et al., 2018), które zapewniają zależne od kontekstu reprezentacje słów; Wykorzystujemy jednoznaczne, osadzone, morfosyntaktyczne cechy leksykonów (Sagot, 2018), które uzupełniają istniejący zestaw funkcji. Odtąd nasz system nazywamy "ELMoLex". Oprócz włączenia osadzeń znaków, ELMoLex korzysta z wstępnie przeszkolonych wektorów słów, ELMo i funkcji morfosyntaktycznych (jeśli są dostępne), aby prawidłowo obsługiwać rzadkie lub nieznane słowa, które są powszechne w językach o złożonej morfologii. ELMoLex znalazł się jedenastą miejscowością według wskaźników etykietowanych załączników (70.64%) i dziewiątą klasyfikację według wskaźników zależności dwueksycznej (60.70%).', 'ro': 'În această lucrare, prezentăm detaliile parserului de dependență neurală și etichetului neural trimis de echipa noastră `ParisNLP\' la CoNLL 2018 Shared Task privind analizarea de la text brut la Dependențe Universale. Îmbunătățim parserul profund Biaffine (BiAF) (Dozat și Manning, 2016) cu caracteristici noi pentru a performa competitiv: utilizăm o versiune indomain a caracteristicilor ELMo (Peters et al., 2018) care oferă reprezentări de cuvinte dependente de context; Utilizăm caracteristici dezambiguizate, încorporate, morfosintactice din lexicoane (Sagot, 2018), care completează setul de caracteristici existent. De acum înainte, noi numim sistemul nostru "ELMoLex". În plus față de încorporarea caracterelor, ELMoLex beneficiază de vectori de cuvinte pre-instruiți, ELMo și caracteristici morfosintactice (ori de câte ori sunt disponibile) pentru a gestiona corect cuvintele rare sau necunoscute care sunt predominante în limbi cu morfologie complexă. ELMoLex s-a clasat pe locul 11 după metrica Scorului de atașament etichetat (70,64%), metrica LAS conștientă de morfologie (55,74%) și pe locul 9 după metrica dependenței bilixice (60,70%).', 'sr': 'U ovom papiru predstavljamo detalje analizatora neuralne zavisnosti i neuralne oznake koje je naš tim `ParisNLP\' podnio CoNLL 2018. zajedničkom zadatku o analizanju sa sirovog teksta na univerzalne zavisnosti. Povećavamo duboki analizator Biaffine (BiAF) (Dozat i Manning, 2016) sa novim karakteristikama za konkurentno izvršavanje: koristimo unutrašnju verziju karakteristika ELMo (Peters et al., 2018) koja pruža predstave riječi ovisnog o kontekstu; Koristimo dezambiguovane, ugrađene, morfosintaktične karakteristike iz leksikona (Sagot, 2018), koja dodaje postojeću setu karakteristika. Od sada zovemo naš sistem "ELMoLex". Uz uključenje integracije karaktera, ELMoLex koristi od predobučenih vektora riječi, ELMo i morfosintaktičkih karakteristika (kad god je dostupan) kako bi ispravno poduzela rijetke ili nepoznate reči koje su prevalente na jezicima sa kompleksnom morfologijom. ELMoLex je rankirao 11. po metričkoj rezultatnoj tački priključenih priključenja (70,64%), metričkom LAS (55,74%) na morfologiji i 9. po metričkoj rezultatiji Bileksikalne zavisnosti (60,70%).', 'so': "Qoraalkan waxan ku qornaa macluumaadka ku saabsan baaritaanka neurada ah Pariser iyo neural tagger submitted by team `ParisNLP' to the CoNLL 2018, waxan sharaxnay shaqo ku saabsan baaritaanka ka raw text to Universal dependencies. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively: we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations;  waxaynu isticmaalaynaa waxyaabaha la burburiyay, oo la koobay, oo la isticmaalayo lexico (Sagot, 2018), kaas oo dhamaystiraya xeerarka joogta. Hada dabadeedna nidaamkan waxaan ugu yeedhaa ELMoLex. Inta dheer oo ku qoran xarafka, ELMoLex waxyaabaha laga heli karaa waddooyinka hadalka horay loo tababaray, ELMo iyo farsamada (marka la jiraaba) si saxda ah u maamula hadalka qaaliga ah ama aan la aqoon, kuwaas oo ku qoran luuqadaha ku qoran morphology oo complex ah. ELMoLex waxay ka baxday 11aad oo ay Labeled Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) oo ay ka kireysatay 9aad oo ah metric Bilexical dependency (60.70%).", 'sv': "I den här uppsatsen presenterar vi detaljerna om den neurala beroendetolkaren och den neurala taggaren som vårt team `ParisNLP' skickat till CoNLL 2018 Shared Task om tolkning från råtext till Universal Beroenden. Vi utökar den djupa Biaffine (BiAF) parsern (Dozat och Manning, 2016) med nya funktioner för att prestera konkurrenskraftigt: vi använder en indomain version av ELMo funktioner (Peters et al., 2018) som ger kontextberoende ordrepresentationer; Vi använder oss av otvetydiga, inbäddade, morfosyntaktiska funktioner från lexikon (Sagot, 2018), som kompletterar den befintliga funktionsuppsättningen. Hädanefter kallar vi vårt system ELMoLex. Förutom att införliva tecken inbäddningar, ELMoLex drar nytta av pre-utbildade ordvektorer, ELMo och morfosyntaktiska funktioner (när tillgängliga) för att korrekt hantera sällsynta eller okända ord som är vanliga i språk med komplex morfologi. ELMoLex rankades 11:e efter Märkt Attachment Score-metrik (70,64%), Morfologimedveten LAS-metrik (55,74%) och 9:e efter Bilexiskt beroendemetrik (60,70%).", 'ta': "இந்த காக்கியத்தில், நாம் புதிய சார்பு சார்பு பரிசோதனையின் விவரங்களை காட்டுகிறோம் மற்றும் எங்கள் குழு 'பாரிஸ்NLP' கோன்எல் 2018 குழு 'பாரிஸ் எல்பி' க்கு  நாம் ஆழமான பையாபின் (பையாஃபின்) பரிசோதனை (Dozat மற்றும் Manning, 2016) புதிய பண்புகளுடன் சேர்க்கிறோம்: நாம் ஒரு indomain பதிப்பை பயன்படுத்துகிறோம் சூழ்நிலை சார்ந்த சொல்லை பிரதிநிதி லெக்சிகோன்களில் இருந்து மாற்றியமைக்கப்பட்ட, சுருக்கப்பட்ட, மாற்றியமைக்கப்பட்ட, மாற்றியமைப்புகளை பயன்படுத்துகிறோம். இது இர இப்போது, நாம் 'ELMoLex' என்று எங்கள் கணினியை அழைக்கிறோம். சிகிச்சை அல்லது தெரியாத வார்த்தை வெக்டார்களிலிருந்து ELMoLex பயன்படுத்தும் முன் பயிற்சி செய்யப்பட்ட வார்த்தை வெக்டர்கள், ELMo மற்றும் morphosyntactic தன்மைகள் (எப்போதும்  ELMoLex விளக்கச்சீட்டு இணைப்பு புள்ளி மெட்ரிக் (70. 64%), Morphology- aware LAS மெட்ரிக் (55. 74%) மற்றும் 9வது பிலைமெக்ஸிக் சார்பு மெட்ரிக் (60. 70%).", 'si': "මේ පත්තරේ අපි පෙන්වන්නේ න්\u200dයුරල් විශේෂතා විශේෂතාවක් සහ අපේ කණ්ඩායම `Paris NLP' වල පෙන්වන්න පුළුවන් න්\u200dයුරල් ටැගර් වලින් පෙන්වන්නේ න්\u200d අපි ගොඩක් බියාෆින් (BiAF) පරීක්ෂකය (Dozat and Manling, 2016) සමඟ සංවේදනය සමඟ ප්\u200dරශ්නයක් කරන්න: අපි ELMo විශේෂකයේ ඉන්ධිමත් සංවේදනය (Peters et al., 2018) සම්බන්ධ ව අපි ප්\u200dරයෝජනය කරන්නේ නැති විශේෂතාවක්, සම්බන්ධතාවක්, මොර්ෆෝසින්ටැක්ටික් විශේෂතාවක් ලෙක්සිකන්ස් වලි ඊට පස්සේ, අපි අපේ පද්ධතිය 'ELMoLex' කියනවා. In plus to inkorporating character Embdings, ELMoLex is avail from pre-Trained word Vectors, ELMo and Morphoosyntactic Featuries (Whenever Avail) to correctly manage rarr or unknown Words that are overlent in the language with comprehensed Morphoology. ELMoLex ලැබෙල්ඩ් ඇතුළුම් ස්කෝර් මෙට්\u200dරික් වලින් 11වෙනි රැජින් කරලා තියෙන්නේ (70.64%), මොර්ෆෝලෝජිකාව-අනතුරු LAS මෙට්\u200dරික් (55.74%) වල", 'ur': 'اس کاغذ میں، ہم نے نورول اعتمادی پارچر اور نورول ٹاگر کے معاملات کی تفصیل کو CoNLL 2018 میں شریک ٹاکس کے ذریعہ تقسیم کرنے کے لئے پیش کیا ہے۔ ہم دوزٹ اور منینگ کی عمیق بیفائین (BiAF) پارچر (Dozat and Manning, 2016) کو رابطہ طریقے سے کام کرنے کے لئے نومین خصوصے کے ساتھ اضافہ کرتے ہیں: ہم ELMo فرضیوں کی ایک داخل اصلی نسخہ استعمال کرتے ہیں (Peters et al., 2018) جو کائنات وابستہ کلمات کی نشانیوں کو پیش ہم لکسینس (Sagot, 2018) سے مخلوقات، مضبوط، مضبوط، مورف سینٹاکیٹ ویٹیوں کو استعمال کرتے ہیں، جو موجود ویٹیوں کے سٹے کو اضافہ کرتی ہے۔ اس کے بعد ہم نے اپنے سیستم "ELMoLex" کو بلایا۔ المولکس پہلے تدریس کی لفظ ویکتروں، المو اور مورپوسینٹک ویکتروں سے فائدہ اٹھائے جاتے ہیں (جب بھی موجود ہوتے ہیں) کہ عاجزی یا ناشناس لفظ کو درست سمجھنے کے لئے سمجھتے ہیں جو زبانوں میں پیچیدہ مورپولوژی کے ساتھ پھیلاتے ہیں۔ ELMoLex 11th ranked by Labeled Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) and ranked 9th by Bilexical dependency metric (60.70%).', 'uz': "Bu qogʻozda, biz neyrol ishlatuvchi qismlarini va guruhmizning `ParisNLP' ga koʻchirilgan neyrol tagger' ga CoNLL 2018 yildan CoNLL' ga bogʻliq matnning to ʻgʻri muammolariga bogʻlash uchun vazifani birlashtiramiz. Biz murojaat qilish uchun yuqori Biaffine parametrlarini (Dozat va Manning 2016) qoidaga qoʻshishimiz. Biz muvaffaqiyatli qoʻllanmiz, bu soʻzni tashkilotga ishlatadigan ELMo imkoniyatlaridan foydalanamiz. biz leksikanining (Sagot, 2018) murakkab qilingan, murfosyntik xususiyatlaridan foydalanamiz. Bu mavjud xususiyatlarni murakkab qiladi. Henceforth, we call our system `ELMoLex'.  @ info: whatsthis Name", 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu chi tiết của phân tích thần kinh phụ thuộc và loại gen thần kinh được gửi bởi nhóm "PariszNLP" với CLB Chia sẻ CodLL 208 về phân tích từ văn bản thô đến các quan hệ chung. Chúng tôi tăng cường khả năng sử dụng nội dung dung bạch thủ (BiAF) phân tích (Dozat and Manning, 2006) với các yếu tố mới để tiến hành cạnh tranh. Chúng tôi sử dụng một phiên bản bất chính của các nhân tố ElMo (Peters et al., 208) cung cấp các biểu tượng từ ngữ cảnh dựa vào ngữ cảnh; Chúng tôi sử dụng các tính năng biến dạng, nhúng, morphine từ ngôn ngữ (hiền triết, thẩm tê). Từ giờ, chúng tôi gọi hệ thống là "ElMoLex". Bên cạnh việc nhập thêm các sự nhúng khắc nhân cách, ElMolex hưởng lợi từ những cỗ máy có từ được huấn luyện trước, ElMo và morphology (bất cứ khi nào có thể) để xử lý chính xác những từ hiếm hay không rõ ràng phổ biến theo ngôn ngữ có độ morphology phức tạp. Mô-Lex phân loại 11th by Nhãn đính kèm Score mét (70.649).', 'bg': 'В тази статия представяме подробности за анализатора на невралната зависимост и невралния тагер, представени от нашия екип на споделената задача за анализ от суров текст до универсални зависимости. Подобряваме дълбокия анализатор Биафин (БиАФ) (Дозат и Манинг, 2016) с нови функции, за да изпълняваме конкурентно: използваме индомейна версия на функциите на ЕЛМО (Питърс и др., 2018), които осигуряват зависими от контекста думи представяния; използваме недвусмислени, вградени, морфосинтактични черти от лексиконите (Сагот, 2018), които допълват съществуващия набор от функции. Отсега нататък наричаме нашата система "ELMoLex". В допълнение към вграждането на знаци, ELMoLex се възползва от предварително обучени текстови вектори, ELMo и морфосинтактични характеристики (когато има такива), за да обработва правилно редки или неизвестни думи, които са преобладаващи в езици със сложна морфология. ELMoLex се класира на 11-о място по показател за оценка на прикрепването (70,64%), отчитащ морфологията (55,74%) и на 9-о място по показател за двустранна зависимост (60,70%).', 'hr': "U ovom papiru predstavljamo detalje analizatora neuralne zavisnosti i neuralne oznake koje je naš tim `ParisNLP' podnio podijeljenom zadatku CoNLL 2018 o analizanju sa sirovog teksta na univerzalne zavisnosti. Povećavamo duboki analizator Biaffine (BiAF) (Dozat i Manning, 2016) s novim karakteristikama za konkurentno izvršavanje: koristimo unutrašnju verziju karakteristika ELMo (Peters et al., 2018) koja pruža predstave riječi ovisnih o kontekstu; Koristimo disambiguacije, ugrađene, morfosintaktične karakteristike leksikona (Sagot, 2018), koja dopunjava postojeći set karakteristika. Od sada zovemo naš sistem ELMoLex. Osim uključujući integraciju karaktera, ELMoLex koristi od predobučenih vektorija riječi, ELMo i morfosintaktičkih karakteristika (kad god je dostupan) kako bi ispravno rijetke ili nepoznate riječi koje su prevalente na jezicima sa složenom morfologijom. ELMoLex je određen 11. redom metričkim (70,64%), LAS metričkim (55,74%) s obzirom na morfologiju i 9. redom od biliexičke zavisnosti metričke (60,70%).", 'da': "I denne artikel præsenterer vi detaljerne om den neurale afhængighedsfortolker og den neurale tagger indsendt af vores team `ParisNLP' til CoNLL 2018 Shared Task om parsing fra rå tekst til universelle afhængigheder. Vi udvider den dybe Biaffine (BiAF) parser (Dozat og Manning, 2016) med nye funktioner til at udføre konkurrencedygtigt: Vi bruger en indomain version af ELMo funktioner (Peters et al., 2018), som giver kontekst-afhængige ord repræsentationer; Vi anvender entydige, indlejrede, morfosyntaktiske funktioner fra leksikoner (Sagot, 2018), som supplerer det eksisterende funktionssæt. Fremover kalder vi vores system ELMoLex. Ud over at inkorporere tegn indlejringer, ELMoLex drager fordel af forududdannede ordvektorer, ELMo og morfosyntaktiske funktioner (når tilgængelige) til korrekt at håndtere sjældne eller ukendte ord, der er udbredt i sprog med kompleks morfologi. ELMoLex rangerede 11th efter Labeled Attachment Score metric (70,64%), Morphology-award LAS metric (55,74%) og rangerede 9th efter Bileksisk afhængighed metric (60,70%).", 'nl': "In dit artikel presenteren we de details van de neurale afhankelijkheidsparser en de neurale tagger die door ons team 'ParisNLP' zijn ingediend bij de CoNLL 2018 Shared Task over het parsen van ruwe tekst naar universele afhankelijkheden. We breiden de diepe Biaffine (BiAF) parser (Dozat en Manning, 2016) uit met nieuwe functies om competitief te presteren: we gebruiken een indomain versie van ELMo features (Peters et al., 2018) die contextafhankelijke woordrepresentaties bieden; We maken gebruik van ondubbelzinnige, ingesloten, morfosyntactische kenmerken uit lexicons (Sagot, 2018), die de bestaande functieset aanvullen. Voortaan noemen we ons systeem 'ELMoLex'. Naast het integreren van tekens, profiteert ELMoLex van vooraf getrainde woordvectoren, ELMo en morfosyntactische functies (indien beschikbaar) om zeldzame of onbekende woorden correct te behandelen die voorkomen in talen met complexe morfologie. ELMoLex werd 11e gerangschikt op basis van Labeled Attachment Score metric (70.64%) Morfologische LAS metric (55.74%) en 9e gerangschikt op basis van Bilexische afhankelijkheidsmetric (60.70%).", 'de': 'In diesem Beitrag stellen wir die Details des neuronalen Abhängigkeitsparsers und des neuronalen Taggers vor, die von unserem Team ParisNLP an die CoNLL 2018 Shared Task zum Parsen von Rohtext zu Universellen Abhängigkeiten übermittelt wurden. Wir erweitern den tiefen Biaffine (BiAF) Parser (Dozat und Manning, 2016) um neue Funktionen, um wettbewerbsfähig zu sein: Wir verwenden eine Indomain-Version von ELMo Features (Peters et al., 2018), die kontextabhängige Wortdarstellungen bieten; Wir verwenden disambiguated, embedded, morphosyntaktic features aus Lexikonen (Sagot, 2018), die das bestehende Feature Set ergänzen. Von nun an nennen wir unser System "ELMoLex". Neben der Einbettung von Zeichen profitiert ELMoLex von vortrainierten Wortvektoren, ELMo und morphosyntaktischen Funktionen (sofern verfügbar), um seltene oder unbekannte Wörter korrekt zu behandeln, die in Sprachen mit komplexer Morphologie vorherrschen. ELMoLex rangierte elf nach Labeled Attachment Score Metrik (70.64%) Morphologie-bewusste LAS Metrik (55.74%) und neunte nach Bilexische Abhängigkeitsmetrik (60.70%).', 'id': "Dalam kertas ini, kami memperkenalkan rincian dari parser ketergantungan saraf dan tag saraf yang dikirim oleh tim kami `ParisNLP' ke CoNLL 2018 Shared Task on parsing from raw text to Universal Dependencies. Kami menambah parser Biaffine (BiAF) dalam (Dozat and Manning, 2016) dengan ciri-ciri baru untuk berkompetitif: kami menggunakan versi indomain dari ciri-ciri ELMo (Peters et al., 2018) yang menyediakan representation kata tergantung konteks; kita menggunakan karakteristik morfosintaktik yang disambiguasi, terkandung dari leksikon (Sagot, 2018), yang menyempurnakan set karakteristik yang ada. Henceforth, we call our system `ELMoLex'.  Selain memasukkan bentuk karakter, ELMoLex berguna dari vektor kata yang terlatih sebelumnya, ELMo dan fitur morfosintaksi (kapan saja tersedia) untuk menangani dengan benar kata langka atau tidak dikenal yang prevalent dalam bahasa dengan morfologi kompleks. ELMoLex berturut-turut ke-11 oleh Labeled Attachment Score metric (70,64%), Morphology-aware LAS metric (55,74%) dan berturut-turut ke-9 oleh Bilexical dependency metric (60,70%).", 'fa': 'در این کاغذ، جزئیات وابستگی عصبی و نقاشی عصبی که توسط تیم ما «ParisNLP» به کار مشترک CoNLL ۲۰۱۸ در مورد بررسی از متن خاکستری به وابستگی جهانی ارائه می\u200cدهیم. ما بازیگر عمیق Biaffine (BiAF) را (Dozat and Manning, 2016) با ویژه\u200cهای رمانی برای اجرای مسابقه افزایش می\u200cدهیم: ما یک نسخهٔ اصلی از ویژه\u200cهای ELMo (Peters et al., 2018) را استفاده می\u200cکنیم که نشانه\u200cهای کلمه بستگی به محیط می\u200cدهد. ما از ویژگی\u200cهای ناآزمایش\u200cشده، داخل شده، مورفوسینتیک از لکسیون (Sagot, 2018) استفاده می\u200cکنیم که مجموعه\u200cی ویژگی\u200cهای موجود را اضافه می\u200cکند. بعد از آن، سیستم ما را «ELMoLex» می\u200cگوییم. در اضافه به شامل تنظیم شخصیت، ELMoLex از ویکتورهای کلمه پیش آموزش شده، ELMo و ویکتورهای مورفوسینتیک (هر وقت موجود موجود) سود می\u200cدهد تا به درستی بررسی کردن کلمات نادر یا ناشناخته\u200cاند که در زبان\u200cها با مورفولوژی پیچیده\u200cاند. ELMoLex با مقدار متریک (70.64%), متریک LAS متریک (55.74%) در مورد مورفولوژی آگاهی و درجات ۹م با متریک بستگی بیلکسیکی (60.70%) درجات یافت.', 'sw': "Katika karatasi hii, tunaweka maelezo ya kituo kinachotegemea ubongo na bendera ya neura iliyotolewa na timu yetu ya ‘ParisNLP’ kwenye CoNLL 2018 ilishirikisha kazi ya kuchimba kuanzia maandishi mabaya kwenda Uingereza. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively: we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations;  tunatumia vipengele vilivyo vibaya, vilivyofungwa na viungo vya kisiasa kutoka lexico (Sagot, 2018), ambavyo vinatumia vipengele vilivyopo. Hivi sasa, tunaita mfumo wetu 'ELMoLex'. Zaidi ya kuweka tabia, ELMoLex inafaidia kutoka kwa vectors wa neno lililofunzwa kabla, ELMo na vipengele vya vifo vya kisiasa (wakati wowote unapatikana) ili kukabiliana sahihi maneno nadra au yasiyofahamika ambayo yanafanana na lugha yenye morphology complex. ELMoLex ilikuwa na kiwango cha 11 na kiwango cha kiwango cha Uchaguzi cha Labeled (70.64%), kiwango cha LAS kinachofahamika kwa Kimorphology (55.74%) na kilikuwa cha 9 na kiwango cha utoaji wa kutegemea kwa Bilexia (60.70%).", 'ko': '본고에서 우리는 우리 팀의\'ParisNLP\'가 CoNLL 2018 공유 임무에 제출한 신경 의존성 해석기와 신경 표기기의 상세한 정보를 소개했는데 이 임무는 원시 텍스트부터 일반적인 의존성에 대한 해석을 포함한다.우리는 새로운 기능으로 deep Biafine(Biaf) 해석기(Dozat와 Manning, 2016)를 강화하여 경쟁력을 가지게 했다. 우리는 ELMo 기능(Peters 등, 2018)의 인도교 버전을 사용했고 이 버전은 상하문과 관련된 단어 표시를 제공했다.사전에서 잘못된 뜻을 없애고 삽입한 형태문법특징(Sagot, 2018)을 활용했는데 이는 기존 특징집을 보완한 것이다.이제부터는 시스템을 "ELMolex"라고 부릅니다.ELMoLex는 문자 삽입을 포함하는 것 외에 복잡한 형태 언어에 보편적으로 존재하는 보기 드물거나 알 수 없는 단어를 정확하게 처리하는 데 도움을 준다.엘모렉스는 레이블 애틋한 득점 지표(70.64%), 형태 감지 LAS 지표(55.74%), 양성의존 지표(60.70%)에서 각각 11위와 9위를 차지했다.', 'tr': 'Bu kagyzda, biz neural baglançylyk tägleriň we neural tägleriň \'ParisNLP\' toparymyzyň CoNLL 2018-nji ýyldaky paýlaşylyk üçin Waýlaşylyk üçin paýlaşdyrylýar. Biz derin Biaffine (BiAF) törenlerini (Dozat and Manning, 2016) rekabet etmek için roman özellikleri ile arttırıyoruz: ELMo özelliklerinin iç üste bağlı bir versiyonunu kullanırız (Peters et al., 2018) yani kontekste bağlı kelime temsillerini temsil edenler; bu şekilde düzenlenen kelime temsilleri sağlayan lexikonlardan döwürilen, integraly, morfositik özellikleri ulanýarys (Sagot, 2018), bu häzirki özellikleri doldurur. Şonuň üçin sistemimizi "ELMoLex" diýip atlandyrýarys. Karakter ködlemelerini dahil etmek üçin ELMoLex öňünden eğlenen söz vektörlerinden, ELMo we morphosyntaktik özelliklerinden (her zaman mejbur bolsa) nadir ýa-da bilinmegen sözleri kompleks morfologiýa bilen üstünleşir. ELMoLex Labeled Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) we Bilexical dependency metric (60.70%) tarapyndan 9nji derejli.', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք նյարդային կախվածության վերլուծության մանրամասները և նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդային նյարդայի Մենք ավելացնում ենք Բիաֆինի (Բիաֆինգ) խորը վերլուծողը (Դոզատ և Մաննինգ, 2016) նոր հատկանիշներով մրցակցության համար: Մենք օգտագործում ենք ELMo հատկանիշների ներքին տարբերակը (Պիտերն և այլն., 2018 թվականը), որը ապահովում է կոնտեքստից կախված մենք օգտագործում ենք բացատրված, ներառված, մորֆոսինտակտիկ առանձնահատկություններ լեքսիկոններից (Sagot, 2018), որոնք համալրացնում են գոյություն ունեցող առանձնահատկությունները: Հիմա մենք մեր համակարգը կոչում ենք «ELMoLex», Ավելին բնավորական ներդրումների ներառման համար, ELMoLex-ը օգտակար է նախապատրաստված բառերի վեկտորներից, ELMo-ից և մորֆոսինտակտիկ առանձնահատկություններից (երբ հնարավոր է) հազվադեպ կամ անհայտ բառերից ճիշտ վարվել, որոնք գոյություն ունեն բարդ մոր ԷԼՄոլեքսը 11-րդ դասակարգում էր նշված կապվածքի գնահատականի (70.64), «Մորֆոլոգիա գիտականի» ԼԱՍ-ի մետրականի (55.74), «Բիլեքսիկական կապվածքի մետրականի» 9-րդ դասակարգում էր:', 'af': "In hierdie papier, ons voorsien die details van die neurale afhanklikheidspanser en die neurale etiket wat deur ons span `ParisNLP' aan die CoNLL 2018 Gedeelde taak aangaande verwerking van rooi teks na universele afhanklikhede. Ons vergroot die diep Biaffine (BiAF) ontwerker (Dozat en Manning, 2016) met novele funksies om kompetitive te uitvoer: ons gebruik 'n binneste weergawe van ELMo funksies (Peters et al., 2018) wat voorsien konteksafhanklike woord voorstellings; Ons gebruik ontsammingde, inbêde, morfosyntaktike funksies van leksikone (Sagot, 2018), wat die bestaande funksiestel complementeer. Daarom noem ons stelsel 'ELMoLex'. In addition to incorporating character embedding, ELMoLex benefits from pre- trained word vectors, ELMo and morphosyntactic features (whenever available) to correct handle rare or unknown words which are prevalent in languages with complex morphology. ELMoLex het 11de rangeer deur merkelike aanhegstelling metriek (70.64%), Morphology-aware LAS metric (55.74%) en 9de rangeer deur Bilexical dependency metric (60.70%).", 'sq': 'Në këtë gazetë, ne paraqesim detajet e analizuesit të varësisë nervore dhe etiketit nervor të dërguar nga ekipi ynë `ParisNLP\' në Detyrën e Përbashkët të CoNLL 2018 mbi analizimin nga teksti i papërpunuar në Varësitë Universale. Ne shtojmë analizuesin e thellë të Biaffine (BiAF) (Dozat dhe Manning, 2016) me karakteristika të reja për të kryer konkuruese: ne përdorim një version të brendshëm të karakteristikave të ELMo (Peters et al., 2018) që ofrojnë përfaqësime fjalësh të varura nga konteksti; ne përdorim karakteristika të çambiguara, të përfshira, morfosintaktike nga lexikonet (Sagot, 2018), që komplementon komplementin e karakteristikave ekzistuese. Që tani e tutje, ne e quajmë sistemin tonë "ELMoLex". Përveç përfshirjes së përfshirjes së karaktereve, ELMoLex përfiton nga vektorët e paratrajnuar të fjalëve, ELMo dhe karakteristikat morfosintaktike (kur të jetë në dispozicion) për të trajtuar korrekt fjalë të rralla apo të panjohura që mbizotërojnë në gjuhë me morfologji komplekse. ELMoLex ranked 11th by Labeled Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) and ranked 9th by Bilexical dependency metric (60.70%).', 'az': 'Bu kağızda, biz nürol bağımlılıq ayırıcısının detaylarını və nürol etiketçisinin `ParisNLP\' ekibimizin CoNLL 2018 paylaşılmış görevi Üniversal bağımlıqlarına ayırılması haqqında təmizləndirdik. Biz düzgün Biaffine (BiAF) parçacısını (Dozat and Manning, 2016), müəllif olaraq işləmək üçün yeni özelliklərlə artırdıq: biz ELMo özelliklərinin (Peters et al., 2018) daxilində bağlı sözlərin ifadəsi ilə istifadə edirik. Biz lexikonların (Sagot, 2018-ci Sagot) müəyyən edilmiş, inkişaf edilmiş, morphosyntaktik özelliklərini istifadə edirik. Bundan sonra sistemimizi "ELMoLex" deyirik. Karakter in şallarını birləşdirmək üçün ELMoLex əvvəlcə təhsil edilmiş söz vektörlərindən, ELMo və morfosyntaktik xüsusiyyətlərindən faydalanır (hər dəfə mövcuddur), kompleks morfoloji ilə çox nadir və bilinməz sözlərdən düzgün işləmək üçün istifadə edir. ELMoLex 11-ci dərəcə etiketli Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) və Bilexical dependency metric (60.70%) ilə 9-ci dərəcə verildi.', 'am': 'በዚህ ፕሮግራም፣ የደዌብ ተሟጋቾችን እና የቡድን ‘ፓርሲን NLP’ ወደ ኮንጆል 2018 ወደ ኮንጆል 2018 የስራውን ማጋራት ከንጹሕ ጽሑፍ ወደ ዓለማዊ ድጋፍ ማጋራት እናቀርባለን፡፡ የጥልቅ ቢያፊን (ቢAF) ተፈላጊዎችን (ዶዛt እና ማኒንግ 2016) በማስተካከል ለመፈለግ አዋራጆችን እናበረታለን፤ የጽሑፍ ቃላት የተታመነ ቃላትን የሚቆጠሩ የELMo ፊደላትን እናስጠጋለን፡ ከሌክሲኮን (ሳጎት፣ 2018) የተለየ፣ የሞሮፎስSyntactic ምርጫዎችን እናጠቃለን፡፡ ከዚህም በኋላ ስብሰባችንን ‹‹ELMoLex› እንጠራለን › ELMoLex ከቀድሞ ተማሪ ቃላት vector፣ ELMo እና ሞሮፎSyntactic ፊደሎች (ማንኛውም ቢገኝ) ጥሩ ወይም ያልታወቀ ቃላት በቋንቋዎች በተጨማሪው ሞሮፎሎጂ ለመቀበል ይጠቅማል፡፡ ELMoLex በLabeled Attachment Score meterric (70.64%), ሞሮፎሎጂ-ታዋቂው LAS metric (55.74%) እና 9ኛ በቢልቢክ የታመነ ሚትሪክ (60.70%).', 'bn': "এই কাগজটিতে আমরা নিউরেল নির্ভরশীল বিস্তারিত বিস্তারিত বিবরণ উপস্থাপন করি এবং আমাদের দল 'প্যারিসএনএলপি' দ্বারা আমাদের দল 'প্যারিসএনএলপি' প্রদান করেছে কনএল ২০১ আমরা গভীর বিয়াফিন (বিএএফ) প্যারাজাট (ডোজাত এবং ম্যানিং, ২০১৬) এর সাথে প্রতিযোগিতায় প্রদর্শনের বৈশিষ্ট্যাবলীর সাথে যোগাযোগ করি: আমরা ইএলমো সংস্করণ ব্যবহার করি (পিটার এন্ডা আমরা লেক্সিকোনের (সাগেট, ২০১৮) থেকে অস্থির বৈশিষ্ট্যাবলী ব্যবহার করি, যা বিভিন্ন বৈশিষ্ট্যের সেট সম্পূর্ণ করে। এখন, আমরা আমাদের সিস্টেম 'এল মোলেক্স' বলি। এলমোলেক্স পূর্ববর্তী প্রশিক্ষিত শব্দ ভেক্টর, ELMo এবং মরোফোসিক্যাটিক বৈশিষ্ট্যাবলীর (যতদিন পাওয়া যায়) সঠিকভাবে বা অজানা শব্দ নিয়ন্ত্রণ করার জন্য সুবিধা প্রদ এলমোলেক্স লেবেলেড সংযুক্ত স্কোর মেট্রিক (৭০. 64%), মরোফোলজি পরিচিত ল্যাস মেট্রিক (৫৫. ৭৪%) এবং বিলেক্সিক্যাল নির্ভরশীল মেট্রিক (৬০.", 'ca': "En aquest article, presentem els detalls de l'analitzador de dependencia neuronal i l'etiquetador neuronal enviat pel nostre equip ParisNLP a la CoNLL 2018 Shared Task sobre l'analització de text brut a Universal Dependencies. augmentem el perfeccionador Biaffine (BiAF) (Dozat i Manning, 2016) amb noves característiques per a actuar competitivament: utilitzem una versió indomain de característiques ELMo (Peters et al., 2018) que proporcionen representacions de paraules relacionades amb el context; utilitzem característiques desambigües, incorporades i morfosintàctiques dels lexicòns (Sagot, 2018), que complementen el conjunt de característiques existents. Des de llavors, anomenem el nostre sistema ELMoLex. A més d'incorporar incorporacions de caràcters, ELMoLex beneficia dels vectors de paraules pré-entrenats, ELMo i les característiques morfosíntactiques (sempre disponibles) per manejar correctament paraules rares o desconeguts que prevalen en llengües amb morfologia complexa. ELMoLex es va classificar 11è per puntuació mètrica de l'anexament etiquetat (70,64%), mètrica del LAS conscient de la morfologia (55,74%) i el 9è per puntuació mètrica de la dependencia biliexical (60,70%).", 'bs': "U ovom papiru predstavljamo detalje analizatora neuralne zavisnosti i neuralne oznake koje je naš tim `ParisNLP' podnio CoNLL 2018. zajedničkom zadatku o analizanju sa sirovog teksta na univerzalne zavisnosti. Povećavamo duboki analizator Biaffine (BiAF) (Dozat i Manning, 2016) sa novim karakteristikama za konkurentno izvršavanje: koristimo unutrašnju verziju karakteristika ELMo (Peters et al., 2018) koja pruža predstave riječi ovisnog o kontekstu; Koristimo dezambiguovane, ugrađene, morfosintaktične karakteristike iz leksikona (Sagot, 2018), koje dodaje postojeći set karakteristika. Od sada zovemo naš sistem ELMoLex. Uz uključenje integracije karaktera, ELMoLex koristi od predobučenih vektora riječi, ELMo i morfosintaktičkih karakteristika (kad god je dostupan) kako bi ispravno rijetke ili nepoznate riječi koje su prevalente na jezicima sa kompleksnom morfologijom. ELMoLex je rankirao 11. po metričkoj rezultatnoj mjeri označenih napada (70,64%), metričkom LAS (55,74%) na morfologiji i 9. po metričkoj biliexikalnoj zavisnosti (60,70%).", 'fi': "Tässä artikkelissa esittelemme tiimimme `ParisNLP' toimittaman neuroriippuvuuden parserin ja neurotagkerin yksityiskohdat CoNLL 2018 Shared Task -ohjelmaan raakatekstistä universaaleihin riippuvuuksiin. Lisäämme syvää Biaffine (BiAF) -jäsennystä (Dozat ja Manning, 2016) uusilla ominaisuuksilla kilpailemaan: hyödynnämme indomain-versiota ELMo-ominaisuuksista (Peters et al., 2018), jotka tarjoavat kontekstista riippuvaisia sanaesityksiä; Käytämme sanaston (Sagot, 2018) selkeitä, upotettuja morfosyntaktisia piirteitä, jotka täydentävät olemassa olevaa ominaisuuskokonaisuutta. Tästä lähtien kutsumme järjestelmäämme ELMoLexiksi. Merkkien upottamisen lisäksi ELMoLex hyötyy ennalta koulutetuista sanavektoreista, ELMo:sta ja morfosyntaktisista ominaisuuksista (aina kun saatavilla), jotta harvinaisia tai tuntemattomia sanoja voidaan käsitellä oikein monimutkaisilla kielillä. ELMoLex sijoittui 11. sijalle Labeled Attachment Score -mittarin (70,64%), Morfology-aware LAS -mittarin (55,74%) ja 9. sijalle kaksoisriippuvuusmittarin (60,70%).", 'cs': 'V tomto článku prezentujeme podrobnosti neuronového závislostního parseru a neuronového tageru, který náš tým ParisNLP předložil do sdíleného úkolu CoNLL 2018 na analýzu surového textu do univerzálních závislostí. Rozšiřujeme hluboký biffinský parser (BiAF) o nové funkce pro konkurenční výkon: využíváme indomanní verzi funkcí ELMo (Peters et al., 2018), které poskytují kontextově závislé reprezentace slov; Používáme rozjednoznačné, vložené, morfosyntaktické prvky z lexikonů (Sagot, 2018), které doplňují stávající sadu funkcí. Od teď našemu systému říkáme "ELMoLex". Kromě začlenění vložení znaků, ELMoLex těží z předškolených slovních vektorů, ELMo a morfosyntaktických funkcí (kdykoli jsou k dispozici), aby správně zpracoval vzácná nebo neznámá slova, která jsou převládající v jazycích se složitou morfologií. ELMoLex se zařadil jedenáctý podle metriky Labeled Attachment Score (70.64%) Morfologicky orientované LAS metriky (55.74%) a devátý podle metriky bilixické závislosti (60.70%).', 'et': "Käesolevas töös esitame meie meeskonna `ParisNLP' poolt CoNLL 2018. aasta jagatud ülesandele parsimiseks toortekstist universaalsetele sõltuvustele esitatud närvisõltuvuse parsimise ja närvimärgistuse detailid. Täiendame sügavat Biaffine (BiAF) parserit (Dozat ja Manning, 2016) uudsete funktsioonidega konkurentsivõimeliseks toimimiseks: kasutame ELMo funktsioonide indomainversiooni (Peters jt., 2018), mis pakuvad kontekstist sõnasõltuvaid esitusi; Kasutame olemasolevat funktsioonikomplekti täiendavaid selgitatud, manustatud morfosüntaktilisi tunnuseid leksikonidest (Sagot, 2018). Nüüdsest nimetame oma süsteemi ELMoLexiks. Lisaks märkide manustamisele kasutab ELMoLex eelnevalt väljaõpetatud sõnavaktorid, ELMo ja morfosüntaktilised omadused (kui need on olemas), et õigesti käsitleda haruldasi või tundmatuid sõnu, mis esinevad keerulise morfoloogiaga keeltes. ELMoLex asus 11. kohal märgistatud manustamiskoori mõõdiku järgi (70,64%), morfoloogiateadliku LAS-i mõõdiku järgi (55,74%) ja 9. kohal kaksiksõltuvusmõõdiku järgi (60,70%).", 'jv': 'In this paper, we present the details of the Neral Care PASSARE and the Neral tagger forwarded by this group \'Parais NLP\' to the CoNLL 2013 shared tasks on PASSing from row text to Universal dependncies. Click here to see the full text in the edit box and click here to see the full text in the edit box. We artment the deep BiAfine (BiAf) browser we use disabled mbiguted, embedembeded, shapeosYnstruct parameters from Lexcon Yo wis malah, kita Ngawe sistememu "el-MoLex". In Addition to inkporting character embedding, elMoLex benets from before-cared word vectors, elMo and shapeosytacal settings ETMoLex ranged 11th by Labeled AttacAttacAttacAttacAttached Point Metric (75.64 %), Marphologi-awake LAS Metric (75.75 %) and ranged 9 th by Bilexit diphensible Metric (60.75 %).', 'ha': "Daga wannan takardan, Munã halatar da cikakken takardar tsari na neural and the neural tagger wanda aka bai wa team `ParisNLP' zuwa the CoNLL 2018 Shared aiki on paring from raw text to Universal deposities. Mu ƙara girgije na Biaffine (Dozat and Manning, 2016) Paramer (Dozat and Manning, 2016) da wasu masu novelar da za'a yi tafiyar da competitive: Munã amfani da an Indomiin version of ELMo (Peters et al., 2018) wanda ke samar da mazaunin-dependant magana; za mu yi amfani da bambancin, da aka shigar da, mutfosyntactic daga lex (Sagota, 2018), wanda ke cika da kowancin da ke da. Kayyan nan, munã kiran system 'ELMoLex'. Babu da ɗabi'ar da aka shigar da cikin rubutun, ELMoLex na amfani da shiryoyin ayuka na zaman mai amfani da, ELMo da masu amfani da shiryoyin ayuka na farko, da ELMo da morfosyntactic (idan yana iya amfani da) dõmin su yi amfani da sauri ko da maganar da ba'a sani ba, waɗanda ke daidai da harshe da murafa masu haɗuwa da morfologi. KCharselect unicode block name", 'sk': 'V tem prispevku predstavljamo podrobnosti razčlenjevalnika nevralne odvisnosti in nevralnega označevalca, ki ga je naša ekipa `ParisNLP\' predložila skupni nalogi CoNLL 2018 o razčlenjevanju iz surovega besedila v univerzalne odvisnosti. Za konkurenčno delovanje smo dopolnili globoki biaffinski razčlenjevalnik (Dozat in Manning, 2016) z novimi funkcijami: uporabljamo indomainno različico funkcij ELMo (Peters et al., 2018), ki zagotavljajo od konteksta odvisne predstavitve besed; Uporabljamo razločene, vgrajene, morfosintaktične značilnosti iz leksikonov (Sagot, 2018), ki dopolnjujejo obstoječi nabor funkcij. Odslej imenujemo naš sistem "ELMoLex". Poleg vključevanja znakov ima ELMoLex prednost predhodno usposobljenih besednih vektorjev, ELMo in morfosintaktičnih značilnosti (kadar je na voljo), da pravilno ravna z redkimi ali neznanimi besedami, ki so prevladujoče v jezikih s kompleksno morfologijo. ELMoLex se je uvrstil na 11. mesto po merilu ocene označene priključke (70,64%), meritvi LAS z zavedanjem morfologije (55,74%) in 9. mesto po merilu bilateralne odvisnosti (60,70%).', 'he': 'בעיתון הזה, אנו מציגים את הפרטים של מעבד התלויות העצביות והתג העצבי שנשלח על ידי צוות שלנו "ParisNLP" למשימה משותפת CoNLL 2018 אנו מגדילים את הפרסום העמוק של ביאפין (BiAF) (Dozat and Manning, 2016) עם תכונות חדשות כדי להופיע בתחרות: אנו משתמשים בגרסה אינדומיין של תכונות ELMo (Peters et al., 2018) שמספקים מייצגים מילים תלויים בקונקסט; אנו משתמשים בתחומים מורפוסינטקטיים בלתי משובחים, מוכנים ומורפוסינטקטיים מלקסיקונים (Sagot, 2018), שמחליפים את קבוצת התחומים הקיומים. מעתה והלאה, אנחנו קוראים למערכת שלנו "ELMoLex". בנוסף לכילוי תוכניות אופיים, ELMoLex מועיל בוקטורים מילים מאומנים מראש, ELMo ואפיקסים מורפוסינטקטיים (בכל פעם זמינים) כדי לטפל בצורה נכונה במילים נדירות או לא ידועות ששולטות בשפות עם מורפולוגיה מורכבת. ELMoLex מצוות 11th by Labelled Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) and ranked 9th by Bilexical dependency metric (60.70%).', 'bo': "In this paper, we present the details of the neural dependency parser and the neural tagger submitted by our team `ParisNLP' to the CoNLL 2018 Shared Task on parsing from raw text to Universal Dependencies. The following information is available: We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively: we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations;  we utilize disambiguated, embedded, morphosyntactic features from lexicons (Sagot, 2018), which complements the existing feature set. དེ་ལས་བརྟེན། ང་ཚོས་མ་ལག་ལུགས་‘ELMoLex’་ཞེས་འབོད་ཀྱི་ཡོད། In addition to incorporating character embeddings, ELMoLex benefits from pre-trained word vectors, ELMo and morphosyntactic features (whenever available) to correctly handle rare or unknown words which are prevalent in languages with complex morphology. ELMoLex ranked 11th by Labeled Attachment Score metric (70.64%), Morphology-aware LAS metric (55.74%) and ranked 9th by Bilexical dependency metric (60.70%)."}
