{'en': 'Corrected CBOW Performs as well as Skip-gram', 'ar': 'تصحيح CBOW يؤدي وكذلك تخطي الجرام', 'fr': 'Performances CBOW corrigées ainsi que Skip-gram', 'es': 'CBOW corregido funciona así como Skip-gram', 'pt': 'Corrigido CBOW Executa bem como Skip-gram', 'ja': '修正されたCBOWパフォーマンスとスキップグラム', 'hi': 'सही CBOW प्रदर्शन के रूप में के रूप में अच्छी तरह से छोड़ें-ग्राम', 'zh': '校正CBOW行及跳过克', 'ru': 'Скорректированный CBOW выполняет, а также скип-грамму', 'ga': 'Feidhmíonn CBOW ceartaithe chomh maith le Skip-gram', 'ka': 'კონფიგურაცია', 'hu': 'Javított CBOW teljesít, valamint Skip-gram', 'el': 'Διορθώθηκε ΒΒΟ αποδίδει καθώς και Skip-gram', 'it': 'Corretto CBOW Esegue così come Skip-gram', 'kk': 'CBOW түзетілген жұмыс істеу және Skip- грамма', 'mk': 'Коригирани извршувања на CBOW како и Skip- gram', 'lt': 'Corrected CBOW Performs as well as Skip-gram', 'ms': 'Corrected CBOW Performs as well as Skip-gram', 'mn': 'CBOW зөвхөн Skip-грамм', 'no': 'Korrigerte CBOW utfører og hopp over', 'ml': 'CBOW പാര്\u200dഫോര്\u200dമ്മുകളും സ്കിപ്- ഗ്രാമും ശരിയാക്കിയിരിക്കുന്നു', 'mt': 'Corrected CBOW Performs as well as Skip-gram', 'sr': 'Upravljena CBOW Performacija kao i Skip-gram', 'pl': 'Poprawione CBOW działa jak również Pomiń-gram', 'ro': 'Corectat CBOW efectuează, precum și Skip-gram', 'si': 'සුදුසු CBOW සහ Skip-gram සහ', 'so': 'Corrected CBOW Performs as well as Skip-gram', 'sv': 'Korrigerad CBOW utför såväl som Skip-gram', 'ur': 'سی بی بی وئ کامل کرتا ہے اور اسکیپ گرم کرتا ہے', 'ta': 'சரிசெய்யப்பட்ட CBOW வடிவங்கள் மற்றும் தவிர- கிராம்', 'vi': 'KCharselect unicode block name', 'uz': 'Name', 'bg': 'Коригиран CBOW изпълнява както и пропуска грама', 'nl': 'Corrigeerde CBOW presteert evenals Skip-gram', 'hr': 'Ispravljeni CBOW Performacija kao i Skip-gram', 'da': 'Korrigeret CBOW udfører såvel som Skip-gram', 'de': 'Korrigierte CBOW Leistung sowie Skip-Gramm', 'id': 'Memperbaiki Performasi CBOW serta Skip-gram', 'fa': 'عملکرد CBOW و Skip-gram درست شده', 'sw': 'Tamko zilizosahihishwa CBOW pamoja na Skip-gram', 'tr': 'CBOW düzeldi we atla', 'am': 'Corrected CBOW Performs as well as Skip-gram', 'sq': 'Performon CBOW të korrigjuar si dhe Skip-gram', 'af': 'Korrekteer CBOW Performaat ook as Skip- gram', 'hy': 'Կարգավորված համակարգչային կազմակերպությունները, ինչպես նաև', 'bn': 'CBOW পার্ফর্ম এবং সাথে স্কিপ- গ্রাম সংশোধন করা হয়েছে', 'az': 'T톛sdiq CBOW v톛 Skip-gram', 'bs': 'Ispravljena CBOW Performacija kao i Skip-gram', 'ko': '수정된 CBOW는 점프 그램만큼 성능이 좋아요.', 'ca': 'Performances corregides del CBOW, així com Skip-gram', 'cs': 'Opravený CBOW funguje stejně jako Skip-gram', 'fi': 'Korjattu CBOW Suorittaa sekä Ohita gramma', 'et': 'Korrigeeritud CBOW toimib nii hästi kui ka vahele jätta gramm', 'jv': 'Diworongi tambah Jejaring', 'sk': 'Popravljen CBOW deluje tako kot preskoči gram', 'he': 'ביצועים CBOW תוקנים כמו גם Skip-gram', 'ha': 'KCharselect unicode block name', 'bo': 'corrected CBOW Performs as well as Skip-gram'}
{'en': 'Mikolov et al. (2013a) observed that continuous bag-of-words (CBOW) word embeddings tend to underperform Skip-gram (SG) embeddings, and this finding has been reported in subsequent works. We find that these observations are driven not by fundamental differences in their training objectives, but more likely on faulty negative sampling CBOW implementations in popular libraries such as the official implementation, word2vec.c, and Gensim. We show that after correcting a bug in the CBOW gradient update, one can learn CBOW word embeddings that are fully competitive with SG on various intrinsic and extrinsic tasks, while being many times faster to train.', 'ar': 'ميكولوف وآخرون. (2013 أ) لاحظ أن حفلات الزفاف المستمرة في كيس من الكلمات (CBOW) تميل إلى التقليل من أداء حفلات الزفاف Skip-gram (SG) ، وقد تم الإبلاغ عن هذه النتيجة في الأعمال اللاحقة. وجدنا أن هذه الملاحظات مدفوعة ليس بالاختلافات الأساسية في أهداف التدريب الخاصة بهم ، ولكن على الأرجح بسبب العينات السلبية الخاطئة تطبيقات CBOW في المكتبات الشعبية مثل التنفيذ الرسمي ، word2vec.c ، و Gensim. نوضح أنه بعد تصحيح خطأ في تحديث التدرج CBOW ، يمكن للمرء أن يتعلم حفلات الزفاف في CBOW التي تتنافس تمامًا مع SG في العديد من المهام الداخلية والخارجية ، بينما تكون أسرع عدة مرات في التدريب.', 'fr': "Mikolov et al. (2013a) ont observé que les incorporations continues de mots en sac de mots (CBOW) ont tendance à sous-performer les intégrations Skip-gram (SG), et cette découverte a été rapportée dans des travaux ultérieurs. Nous constatons que ces observations ne sont pas motivées par des différences fondamentales dans leurs objectifs de formation, mais plus probablement par des implémentations CBOW d'échantillonnage négatif erronées dans des bibliothèques populaires telles que l'implémentation officielle, word2vec.c et Gensim. Nous montrons qu'après avoir corrigé un bug dans la mise à jour du dégradé CBOW, on peut apprendre des intégrations de mots CBOW qui sont totalement compétitives avec SG sur diverses tâches intrinsèques et extrinsèques, tout en étant beaucoup plus rapides à entraîner.", 'pt': 'Mikolov et ai. (2013a) observaram que os embeddings contínuos de palavras do tipo bag-of-words (CBOW) tendem a ter um desempenho inferior aos embeddings Skip-gram (SG), e esse achado foi relatado em trabalhos subsequentes. Descobrimos que essas observações são motivadas não por diferenças fundamentais em seus objetivos de treinamento, mas mais provavelmente em implementações CBOW de amostragem negativa defeituosa em bibliotecas populares, como a implementação oficial, word2vec.c e Gensim. Mostramos que após corrigir um bug na atualização do gradiente CBOW, pode-se aprender incorporações de palavras CBOW que são totalmente competitivas com SG em várias tarefas intrínsecas e extrínsecas, sendo muitas vezes mais rápidas para treinar.', 'es': 'Mikolov et al. (2013a) observaron que las incrustaciones continuas de palabras en bolsa de palabras (CBOW) tienden a tener un rendimiento inferior a las incrustaciones de Skip-gram (SG), y este hallazgo se ha informado en trabajos posteriores. Encontramos que estas observaciones no se deben a diferencias fundamentales en sus objetivos de entrenamiento, sino más probablemente a implementaciones defectuosas de CBOW de muestreo negativo en bibliotecas populares, como la implementación oficial, word2vec.c y Gensim. Demostramos que después de corregir un error en la actualización de degradado de CBOW, uno puede aprender incrustaciones de palabras CBOW que son totalmente competitivas con SG en varias tareas intrínsecas y extrínsecas, mientras que es mucho más rápido de entrenar.', 'ja': 'Mikolov et al .( 2013 a)は、連続した単語袋（ CBOW ）の埋め込みは、スキップグラム（ SG ）の埋め込みを下回る傾向があることを観察し、この発見はその後の研究で報告されている。これらの観察結果は、トレーニング目標の根本的な違いではなく、公式な実装、word2vec.c、Gensimなどの人気のあるライブラリでの故障したネガティブサンプリングCBOW実装で駆動される可能性が高いことがわかりました。CBOWグラデーションアップデートのバグを修正した後、CBOWワード埋め込みを学ぶことができます。CBOWワード埋め込みは、さまざまな本質的および外因的なタスクでSGと完全に競合しますが、トレーニングの速度は何倍も速くなります。', 'ru': 'Миколов и др. (2013a) отметили, что непрерывные вкладыши слов (CBOW), как правило, не выполняют вкладыши скип-грамм (SG), и об этом выводе сообщалось в последующих работах. Мы обнаружили, что эти наблюдения обусловлены не фундаментальными различиями в целях обучения, а скорее ошибочной реализацией CBOW с отрицательной выборкой в популярных библиотеках, таких как официальная реализация, word2vec.c и Gensim. Мы показываем, что после исправления ошибки в обновлении градиента CBOW можно выучить вложения слов CBOW, которые полностью конкурируют с SG по различным внутренним и внешним задачам, при этом они во много раз быстрее тренируются.', 'zh': 'Mikolov等(2013a)察之,连词袋(CBOW)词嵌,往往不如Skip-gram(SG)嵌,已在后事中报道。 观其所习之本异,或由库藏之误负采样CBOW,如官方得之,word2vec.c Gensim也。 臣等明正CBOW梯度更新之非,人可学CBOW词嵌之,其词嵌内外与SG竞,兼练倍多。', 'hi': 'मिकोलोव एट अल( 2013ए) ने देखा कि निरंतर बैग-ऑफ-वर्ड्स (सीबीओडब्ल्यू) शब्द एम्बेडिंग स्किप-ग्राम (एसजी) एम्बेडिंग को कम करते हैं, और इस खोज को बाद के कार्यों में सूचित किया गया है। हम पाते हैं कि ये टिप्पणियां उनके प्रशिक्षण उद्देश्यों में मौलिक अंतर से प्रेरित नहीं हैं, लेकिन आधिकारिक कार्यान्वयन, word2vec.c और Gensim जैसे लोकप्रिय पुस्तकालयों में दोषपूर्ण नकारात्मक नमूना CBOW कार्यान्वयन पर अधिक संभावना है। हम दिखाते हैं कि CBOW ग्रेडिएंट अपडेट में एक बग को सही करने के बाद, कोई CBOW शब्द एम्बेडिंग सीख सकता है जो विभिन्न आंतरिक और बाह्य कार्यों पर एसजी के साथ पूरी तरह से प्रतिस्पर्धी हैं, जबकि ट्रेन करने के लिए कई गुना तेज हैं।', 'ga': 'Mikolov et al. (2013a) gur gnách go mbíonn leabú focal leanúnach mála de na focail (CBOW) tearcfheidhmíocht le leabaithe Skip-gram (SG), agus tá an toradh seo tuairiscithe i saothair ina dhiaidh sin. Faighimid amach nach bhfuil na tuairimí seo á dtiomáint ag difríochtaí bunúsacha ina gcuspóirí oiliúna, ach is dóichí go bhfuil sampláil dhiúltach lochtach curtha i bhfeidhm ar CBOW i leabharlanna móréilimh mar an cur i bhfeidhm oifigiúil, word2vec.c, agus Gensim. Léirímid, tar éis fabht a cheartú i nuashonrú grádán CBOW, gur féidir le duine leabaithe focal CBOW a fhoghlaim atá go hiomlán iomaíoch le SG ar thascanna intreacha agus eistreacha éagsúla, agus iad a bheith i bhfad níos tapúla chun oiliúint a dhéanamh.', 'ka': 'Mikolov et al. (2013a) აღმოჩნდა, რომ მუშაობელი სიტყვები (CBOW) სიტყვების შემოწყვება უნდა გავაკეთოთ Skip-gram (SG) შემოწყვება, და ეს მოწყვება შემდეგ მუშაობაში იყო. ჩვენ ვფიქრობთ, რომ ეს მონაცემებები არა ფუნდამეტური განსხვავებებით საკუთარი განსხვავებაში, მაგრამ უფრო შეუძლებელია შეცდომა განსხვავებაში CBOW-ის განსხვავებაში პოლიპური ლიბურიაში, როგორ C და Gensim. ჩვენ ჩვენ აჩვენებთ, რომ CBOW გრადიენტის განახლების შეცდომა შემდეგ CBOW სიტყვების ინტერნექტიური და ექსტრინიური დავალების შემდეგ, რომლებიც CBOW სიტყვების ინტერნექტიური და კონპრენექტიური და', 'el': 'Ο Mikolov κ.α. (2013α) παρατήρησε ότι οι συνεχείς ενσωμάτωσης λέξεων τείνουν να μην αποδίδουν στις ενσωμάτωσεις Skip-gram (SG), και αυτό το εύρημα έχει αναφερθεί σε επόμενες εργασίες. Διαπιστώνουμε ότι αυτές οι παρατηρήσεις δεν οδηγούνται από θεμελιώδεις διαφορές στους εκπαιδευτικούς στόχους τους, αλλά πιθανότατα σε ελαττωματικές αρνητικές εφαρμογές δειγματοληψίας σε δημοφιλείς βιβλιοθήκες όπως η επίσημη εφαρμογή, word2vec. Γ, και Τζένσιμ. Δείχνουμε ότι μετά τη διόρθωση ενός σφάλματος στην ενημέρωση διαβάθμισης μπορεί κανείς να μάθει ενσωμάτωση λέξεων που είναι πλήρως ανταγωνιστικές με την σε διάφορες εγγενείς και εξωτερικές εργασίες, ενώ είναι πολλές φορές ταχύτερη στην εκπαίδευση.', 'hu': 'Mikolov és társai (2013a) megállapították, hogy a folyamatos zsák-of-words (CBOW) szóbeágyazások hajlamosak alulteljesíteni a Skip-gram (SG) beágyazásokat, és ezt a megállapítást a későbbi munkákban jelentették. Úgy találjuk, hogy ezeket a megfigyeléseket nem a képzési célkitűzések alapvető különbségei vezérlik, hanem inkább a népszerű könyvtárak hibás negatív mintavételi CBOW implementációi, mint például a hivatalos implementáció, word2vec. c, és Gensim. Megmutatjuk, hogy a CBOW gradient frissítés hibájának kijavítása után megtanulhatjuk a CBOW szóbeágyazásokat, amelyek teljes mértékben versenyképesek a SG-vel különböző belső és külső feladatokban, miközben sokszor gyorsabbak a képzés.', 'it': "Mikolov et al. (2013a) hanno osservato che le incorporazioni continue di parole (CBOW) tendono a sottoperformare le incorporazioni Skip-gram (SG), e questo risultato è stato riportato nei lavori successivi. Scopriamo che queste osservazioni non sono guidate da differenze fondamentali nei loro obiettivi formativi, ma più probabilmente da errori di campionamento negativo delle implementazioni CBOW nelle biblioteche popolari come l'implementazione ufficiale, word2vec. c, and Gensim. Dimostriamo che dopo aver corretto un bug nell'aggiornamento CBOW gradient, si possono imparare le incorporazioni di parole CBOW che sono pienamente competitive con SG su varie attività intrinseche ed estrinseche, pur essendo molte volte più veloci da addestrare.", 'mk': 'Миколов и други (2013а) забележаа дека континуираните вградувања на зборови со торба на зборови (CBOW) имаат тенденција да ги потврдат вградувањата на Skip-gram (SG), а ова откритие е известено во последните дела. Најдовме дека овие набљудувања не се поттикнати од основните разлики во нивните обукни цели, туку најверојатно од погрешното негативно примерување на примероци на CBOW во популарните библиотеки како што е официјалната спроведувачка, word2vec. c, and Gensim.  We show that after correcting a bug in the CBOW gradient update, one can learn CBOW word embeddings that are fully competitive with SG on various intrinsic and extrinsic tasks, while being many times faster to train.', 'kk': 'Mikolov et al. (2013a) сол жалғастырақ сөздерді (CBOW) ендіру үшін Skip-gram (SG) ендіру әдістерін бақылады. Бұл табу келесі жұмыстарда хабарлады. Бұл байқауларды оқыту мақсаттарындағы негізгі айырмашылығы емес, бірақ CBOW мәліметтерінің алғашқы кітапханалардың, мысалы, оқыту мақсаттарындағы, 2vec сөздерінде қайталанған түрлендірушілері c, және Gensim. Біз CBOW градиенттің жаңартуындағы қателерді түзетуден кейін, CBOW сөздерді SG-мен бірнеше интринзикалық және сыртқы тапсырмаларды түзету үшін, бірақ бірнеше рет тез жұмыс істеуге болады.', 'lt': 'Mikolov et al. (2013a) observed that continuous bag-of-words (CBOW) word embeddings tend to underperform Skip-gram (SG) embeddings, and this finding has been reported in subsequent works.  Mes manome, kad šios pastabos grindžiamos ne pagrindiniais jų mokymo tikslų skirtumais, bet labiau tikėtina dėl klaidingų neigiamų mėginių ėmimo CBOW įgyvendinimų populiariose bibliotekose, pavyzdžiui, oficialiai įgyvendinant, žod2vec. c, and Gensim.  Mes parodome, kad ištaisius klaidą CBOW gradient atnaujinime, galima išmokti CBOW žodžių įterpimus, kurie yra visiškai konkurencingi su SG įvairiose vidinėse ir išorinėse užduotyse, tuo pačiu metu, kai mokymas yra daug kartų greitesnis.', 'ms': 'Mikolov et al. (2013a) observed that continuous bag-of-words (CBOW) word embeddings tend to underperform Skip-gram (SG) embeddings, and this finding has been reported in subsequent works.  Kami mendapati bahawa pengamatan-pengamatan ini tidak didorong oleh perbezaan dasar dalam tujuan latihan mereka, tetapi lebih kemungkinan pada penggunaan sampel negatif cacat CBOW dalam perpustakaan populer seperti pelaksanaan rasmi, word2vec. c, dan Gensim. We show that after correcting a bug in the CBOW gradient update, one can learn CBOW word embeddings that are fully competitive with SG on various intrinsic and extrinsic tasks, while being many times faster to train.', 'mt': 'Mikolov et al. (2013a) osservaw li l-inkorporazzjonijiet kontinwi tal-kliem tal-borża (CBOW) għandhom it-tendenza li jwettqu inkorporazzjonijiet ta’ Skip-gram (SG), u din is-sejba ġiet irrappurtata f’xogħlijiet sussegwenti. Issibu li dawn l-osservazzjonijiet mhumiex xprunati minn differenzi fundamentali fl-għanijiet tat-taħriġ tagħhom, iżda aktar probabbli fuq l-implimentazzjoni ta’ kampjunar negattiv difettuż tas-CBOW fil-libreriji popolari bħall-implimentazzjoni uffiċjali, word2vec. c, and Gensim.  We show that after correcting a bug in the CBOW gradient update, one can learn CBOW word embeddings that are fully competitive with SG on various intrinsic and extrinsic tasks, while being many times faster to train.', 'mn': 'Mikolov et al. (2013a) үргэлжлүүлэх үг (CBOW) нэвтрүүлэх нь Skip-gram (SG) нэвтрүүлэхийг багасгадаг гэдгийг анзаарсан ба дараагийн ажилладаг. Бид эдгээр ажиглалтуудыг сургалтын зорилго дээр үндсэн өөрчлөлт биш гэдгийг ойлгож байна. Гэхдээ CBOW-ын алдаа алдаа аргагүй номын сангийн жишээлбэл, ерөнхийлөгчийн үйлдвэрлэлт, үг 2vec гэдгийг ойлгож байна. Ц, Женсим. Бид CBOW градиентийн буруу шинэчлэлийн дараа CBOW үгнээс бүрэн өрсөлдөг байдлыг SG-тэй бүрэн өрсөлдөг бүрэн төвлөрөх болон гадаадын ажил дээр суралцах боломжтой болно.', 'pl': 'Mikolov et al. (2013a) zauważył, że ciągłe osadzenia słów (CBOW) mają tendencję do niskiej wydajności osadzeń Skip-gram (SG), co zostało zgłoszone w kolejnych pracach. Uważamy, że obserwacje te nie są napędzane przez fundamentalne różnice w ich celach szkoleniowych, ale bardziej prawdopodobne na błędnych implementacjach CBOW w popularnych bibliotekach, takich jak oficjalna implementacja word2vec. C, i Gensim. Pokazujemy, że po skorygowaniu błędu w aktualizacji gradientów CBOW można nauczyć się osadzeń słów CBOW, które są w pełni konkurencyjne z SG w różnych zadaniach wewnętrznych i zewnętrznych, a jednocześnie są wielokrotnie szybsze w treningu.', 'ml': 'മികൊളോവ് എം അല്\u200d. (2013a) നിരീക്ഷിച്ചു കൊണ്ടിരിക്കുന്ന ബാഗ് ഓഫ് വാക്കുകള്\u200d (CBOW) വാക്കുകള്\u200d സ്കിപ്പ്- ഗ്രാമിന്\u200dറെ അകത്തുകൊണ്ട് പ്രവര്\u200dത്തിപ്പിക് ഈ പരിശീലനത്തിന്റെ ലക്ഷ്യങ്ങളില്\u200d അടിസ്ഥാനമായ വ്യത്യാസങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നില്ല എന്ന് നമുക്ക് തോന്നുന്നു, പക്ഷെ പ്രധാനപ്പെട്ട ലൈബ്രറികള c, and Gensim. We show that after correcting a bug in the CBOW gradient update, one can learn CBOW word embeddings that are fully competitive with SG on various intrinsic and extrinsic tasks, while being many times faster to train.', 'ro': 'Mikolov et al. (2013a) au observat că încorporările continue de cuvinte (CBOW) tind să subperformeze încorporările Skip-gram (SG), iar această constatare a fost raportată în lucrările ulterioare. Considerăm că aceste observații nu sunt conduse de diferențe fundamentale în obiectivele lor de formare, ci mai probabil de eșantionarea negativă defectă a implementărilor CBOW în bibliotecile populare, cum ar fi implementarea oficială, word2vec. c, și Gensim. Vă arătăm că după corectarea unei erori în actualizarea gradientului CBOW, puteți învăța încorporări de cuvinte CBOW care sunt pe deplin competitive cu SG în diferite sarcini intrinsece și extrinsice, fiind în același timp de multe ori mai rapid de antrenat.', 'no': 'Mikolov et al. (2013a) observerte at kontinuerlege ordinnbygging (CBOW) har tendens å underføra innbygging av Skip-gram (SG), og denne finninga er rapportert i følgjande arbeid. Vi finn at desse observasjonane vert drivt ikkje av grunnleggjande forskjeller i opplæringsmålene sine, men meir sannsynleg på feil negativ samling av CBOW-implementasjonar i populære biblioteker som den offisielle implementasjonen, ord2vec. c, og Gensim. Vi viser at etter korrigering av ein feil i CBOW- oppdateringa kan ein lære CBOW- ordinnbygging som er fullstendig konkurentivt med SG på ulike innrykkende og ekstrinske oppgåver, mens det er mange ganger raskare å trene.', 'sr': 'Mikolov et al. (2013a) primetio je da se kontinualna vreća reèi (CBOW) ugražavanje rijeèi tendencije podizati ugražavanje Skip-grama (SG), a ovo nalaženje je prijavljeno u sljedećim poslovima. Mi smatramo da te primedbe ne vode temeljne razlike u njihovim ciljevima obuke, već vjerojatno u pogrešnim negativnim provedbama CBOW-a u popularnim bibliotekama poput službenog provedbe, rečenog 2vec. c, i Gensim. Pokazujemo da nakon isprave bube u aktualizaciji CBOW Gradienta, jedan može naučiti CBOW reč integracije koje su potpuno konkurentne sa SG-om na različitim unutrašnjim i ekstrinsickim zadatkima, dok su mnogo puta brže trenirati.', 'so': 'Mikolov et al. (2013a) wuxuu arkay in boosaska sii-socda (CBOW) oo eray ku qoran ayaa caadi u ah inay sameeyaan meelaha lagu soo galo Skip-gram (SG), taasina waxaa loo sheegay shaqada dabadeed. Waxaynu ognahay in aragtidaasi aan kala duwanaanayn waxyaabaha aasaasiga ah ee waxyaabaha waxbarashada, laakiin waxaa suurtagal ah in la sameeyo tusaale ahaan xafiiska rasmiga ah ee maktabadaha bulshada, sida xafiiska rasmiga ah, word2vec. c, and Gensim. Waxaynu muujinnaa in markii uu hagaajiyo bug oo ku qoran xarunta CBOW, qof ayaa baran kara hadal ku qoran CBOW oo si buuxda ah u tartanka SG shaqooyin badan oo gudaha iyo dibadda ah, iyadoo ay marar badan u dhaqsaysan yihiin waxbarashada.', 'sv': 'Mikolov m.fl. (2013a) observerade att kontinuerliga bag-of-words (CBOW) ord inbäddningar tenderar att underprestera Skip-gram (SG) inbäddningar, och detta resultat har rapporterats i efterföljande arbeten. Vi finner att dessa observationer inte drivs av grundläggande skillnader i deras utbildningsmål, utan mer sannolikt av felaktig negativ provtagning av CBOW implementering i populära bibliotek såsom den officiella implementeringen, word2vec. c, och Gensim. Vi visar att efter att ha korrigerat ett fel i CBOW gradient update, kan man lära sig CBOW ord inbäddningar som är fullt konkurrenskraftiga med SG på olika inre och yttre uppgifter, samtidigt som det är många gånger snabbare att träna.', 'ta': 'மிகோலோவ் மற்றும் அல் (2013a) கண்டறிந்து கொண்டிருந்தால் தொடர்ந்து சொல்லும் வார்த்தைகள் (CBOW) உள்ளடக்கங்கள் ஸ்கிப்- கிராம் உள்ளடக்கங்களை செயல்படுத்தும்  நாம் கண்டுபிடிக்கிறோம் இந்த பார்வைகள் அவர்கள் பயிற்சி செயல்பாடுகளில் அடிப்படையான வேறுபாடுகளால் இயக்கப்படுகிறது என்பதை கண்டுபிடி c, மற்றும் Gensim. @ info', 'si': 'මයිකෝලෝව් ට් අල්. අපි හොයාගන්නවා මේ පරීක්ෂණාවල් ඔවුන්ගේ ප්\u200dරධානය අරමුණු වෙනස් නෙවෙයි කියලා, ඒත් වඩා ප්\u200dරශ්නයක් නොවැරදි CBOW පරීක්ෂණාවල් ප්\u200dර C, සහ ජෙන්සිම්. අපි පෙන්වන්නේ CBOW ග්\u200dරේඩියේන්ට් අවස්ථානයේ වැරැද්දක් හරියට පස්සේ, කෙනෙක් CBOW වචන අවස්ථානය ඉගෙන ගන්න පුළුවන් කියලා SG එක්ක සම්පූ', 'ur': 'Mikolov et al. (2013a) نے دیکھا کہ سیپ گرم (SG) ایمبڈینگ کے مطابق ہمیشہ کلمات (CBOW) کلمات کی ابڈینگ کی باتیں کمی کر رہی ہیں، اور اس تلاش کو اس کے بعد عمل میں گزارے گئے ہیں. ہم دیکھتے ہیں کہ یہ نظارت ان کی تعلیم موجودات میں بنیادی تفاوت کے ذریعہ نہیں ہیں لیکن زیادہ مشکل ہے کہ CBOW کے مطابق مشترک لیبریوں میں مشترک مطابق غلط نمونہ اضافہ کریں جیسے رسمی عملومات، کلمہ 2vec. اور جنسیم. ہم دکھاتے ہیں کہ CBOW گریڈینٹ اڈڈیٹ میں ایک بوگ درست کرنے کے بعد، ایک CBOW کلمات ایمبڈینگ سیکھ سکتا ہے جو SG کے ساتھ مختلف داخلی اور خارجی کاموں پر کام مطابق ہیں، حالانکہ بہت سے دفعہ تیز تر ہے۔', 'vi': 'Các chi tiết đã được xác nhận là: Sự nhúng từ từ liên tục (CBOW) đã có xu hướng giảm tiến trình cho quá trình ghép màn hình cho màn hình « Màn hình ». Chúng tôi thấy những quan điểm này không phải do những khác biệt cơ bản trong các mục tiêu huấn luyện của chúng, mà do có khả năng là các dụng cụ phản trắc của đài CBS ở các thư viện nổi tiếng như cách thực hiện chính thức, Từ 2Co. C, và Gensim. Chúng tôi cho thấy sau khi sửa lỗi trong lần cập nhật dốc bù của CBS, bạn có thể học được sự nhúng vào từ của CBS, và hoàn to àn có thể cạnh tranh với GS về các công việc nội bộ và phi cơ khác nhau, trong khi nó còn nhanh hơn nhiều lần để huấn luyện.', 'uz': "Name Biz o'ylaymiz, bu taʼminlovchi maqsadlarining asosiy o'zgarishlari bilan boshlanadi, balki shaxsiy maktablarda faqat noto'xshash CBOW dasturlarini, huddi rasm ishga tushirish, dunyo 2vek kabi muammolar kabi notoʻgʻri misollariga ishlatish mumkin. c va Gensim. Name @ info: status", 'bg': 'Миколов и др. (2013а) отбелязват, че непрекъснатите вграждания на думи с торба от думи (КБУ) са склонни да не изпълняват по-добре вгражданията със скок-грам (SG), като тази констатация е докладвана в следващи работи. Установяваме, че тези наблюдения не се дължат на фундаментални различия в целите на обучението им, а по-вероятно на грешни негативни извадкови имплементации в популярните библиотеки като официалното изпълнение, word2vec. c, и Gensim. Показваме, че след коригиране на грешка в актуализацията на градиента човек може да научи вграждания на думи, които са напълно конкурентни с SG по различни вътрешни и външни задачи, като същевременно е много пъти по-бърз за обучение.', 'da': 'Mikolov et al. (2013a) bemærkede, at kontinuerlige sæk-of-words (CBOW) ord indlejringer har tendens til at underyde Skip-gram (SG) indlejringer, og dette fund er blevet rapporteret i efterfølgende værker. Vi finder, at disse observationer ikke er drevet af grundlæggende forskelle i deres uddannelsesmål, men mere sandsynligt af fejlagtige negative prøveudtagninger CBOW implementeringer i populære biblioteker såsom den officielle implementering, word2vec. c, og Gensim. Vi viser, at efter at have rettet en fejl i CBOW gradient opdateringen, kan man lære CBOW ord embeddings, der er fuldt konkurrencedygtige med SG på forskellige iboende og ekstrensiske opgaver, samtidig med at det er mange gange hurtigere at træne.', 'nl': 'Mikolov et al. (2013a) constateerde dat continue bag-of-words (CBOW) woord embeddings meestal onderpresteren Skip-gram (SG) embeddings, en deze bevinding is in latere werken gerapporteerd. We vinden dat deze waarnemingen niet worden gedreven door fundamentele verschillen in hun trainingsdoelstellingen, maar eerder door foutieve negatieve sampling CBOW implementaties in populaire bibliotheken zoals de officiële implementatie, word2vec. C, en Gensim. We laten zien dat na het corrigeren van een bug in de CBOW gradiënt update, men CBOW woord embeddings kan leren die volledig concurreren met SG op verschillende intrinsieke en extrinsieke taken, terwijl het vele malen sneller te trainen is.', 'hr': 'Mikolov et al. (2013a) primijetio je da se kontinualno ugrađivanje riječi u torbi riječi (CBOW) čini podrškom ugrađivanja Skip-grama (SG), a to otkriće prijavljeno je u sljedećim poslovima. Mi smatramo da te promatranja ne vode temeljne razlike u njihovim ciljevima obuke, već vjerojatno u pogrešnim negativnim provedbama CBOW-a u popularnim bibliotekama poput službenog provedbe, rečenog 2vec. c, i Gensim. Pokazujemo da nakon isprave bube u aktualizaciji CBOW gradient a, jedan može naučiti integraciju CBOW riječi koje su potpuno konkurentne s SG-om na različitim unutrašnjim i ekstrinsickim zadatkima, dok su mnogo puta brže trenirati.', 'de': 'Mikolov et al. (2013a) beobachteten, dass Continuous Bag-of-Words (CBOW) Worteinbettungen tendenziell schlechter als Skip-Gram (SG) Einbettungen sind, was in späteren Arbeiten berichtet wurde. Wir stellen fest, dass diese Beobachtungen nicht von fundamentalen Unterschieden in ihren Trainingszielen angetrieben werden, sondern eher von fehlerhaften negativen Sampling-CBOW-Implementierungen in populären Bibliotheken wie der offiziellen Implementierung word2vec. C und Gensim. Wir zeigen, dass man nach der Korrektur eines Fehlers im CBOW-Gradienten-Update CBOW-Worteinbettungen lernen kann, die bei verschiedenen intrinsischen und extrinsischen Aufgaben voll mit SG konkurrieren und gleichzeitig um ein Vielfaches schneller trainieren können.', 'id': 'Mikolov et al. (2013a) observed that continuous bag-of-words (CBOW) word embeddings tend to underperform Skip-gram (SG) embeddings, and this finding has been reported in subsequent works.  Kami menemukan bahwa pengamatan-pengamatan ini tidak didorong oleh perbedaan dasar dalam tujuan pelatihan mereka, tetapi lebih mungkin pada pemilihan sampel negatif cacat implementasi CBOW di perpustakaan populer seperti implementasi resmi, word2vec. c, dan Gensim. Kami menunjukkan bahwa setelah memperbaiki pepijat dalam pembaruan gradien CBOW, seseorang dapat belajar pembaruan kata CBOW yang sepenuhnya kompetitif dengan SG dalam berbagai tugas intrinsik dan ekstrinsik, sementara banyak kali lebih cepat untuk berlatih.', 'sw': 'Mikolov et al. (2013a) alibaini kuwa maneno ya kuendelea (CBOW) yanajumuisha mabango ya Skip-gram (SG), na utafiti huu umeripotiwa katika kazi za baadae. Tunafikiri kwamba maoni haya hayaendeshwa na tofauti za msingi katika malengo yao ya mafunzo, lakini inawezekana zaidi kuhusu utekelezaji hasi wa mifano ya CBOW katika maktaba maarufu kama vile utekelezaji rasmi, word2vec. c, na Gensim. Tunaonyesha kwamba baada ya kurekebisha mabadiliko katika kipindi cha habari cha CBOW, mtu anaweza kujifunza maneno ya CBOW yanayojitahidi sana na SG katika kazi mbalimbali za ndani na za nje, wakati ambapo ni mara nyingi sana haraka kufundisha mafunzo.', 'tr': 'Mikolov et al. (2013a) daşary sözleriň baglanmasynyň (CBOW) sözleriň integratlaryny Skip-gram (SG) integratlaryny aşdyrmagyny gözleýär we bu tapylmagyň sonrak işlerde bildirildi. Biz bu gözlemleri olaryň eğitim maksadynda esasy üýtgeşiklerden däldir, ýöne resmi implementasiýa, sözleriň 2vek ýaly meýilleşdirýän kitaphanalarda köpüräk täsir örän täsirlerde däldir. Gensim! CBOW gradient ýäniň güncelleşiginde bir bähleri düzeltdikden soň bir adam CBOW söz integrasyny SG bilen doly daşky we çykyş işlerinde döredip biler öwrenip biler, bir näçe gezek ýigrenç we çalt öwrenip biler.', 'fa': 'Mikolov et al. (2013a) مشاهده کرد که ابتدایی کلمه\u200cهای ادامه\u200cدار (CBOW) کلمه\u200cهای ابتدایی\u200cهای Skip-gram (SG) را کمتر انجام می\u200cدهند و این پیدا در کارهای بعدی گزارش داده شده است. ما پیدا می\u200cکنیم که این مشاهده\u200cها توسط تفاوتهای بنیادی در هدف آموزش آنها نیستند، بلکه احتمالاً بیشتر در عملکرد نمونه\u200cهای منفی CBOW در کتابخانه\u200cهای مشهور مثل عملکرد رسمی، کلمه ۲vek راهنمایی می\u200cشوند. C و Gensim. ما نشان می دهیم که بعد از اصلاح یک کثافت در اخبار گزارش ابتدایی CBOW، یکی می تواند ابتدایی کلمات CBOW را یاد بگیرد که کاملا با SG در کار های مختلف داخلی و خارجی مسابقه دارند، در حالی که بسیار سریع تر برای آموزش باشند.', 'sq': 'Mikolov et al. (2013a) vunë në dukje se përfshirjet e fjalëve të vazhdueshme të çantës së fjalëve (CBOW) kanë tendencë të mungojnë përfshirjet e Skip-gram (SG), dhe ky gjetje është raportuar në punët më pas. Ne zbulojmë se këto vëzhgime nuk janë të nxitura nga dallimet thelbësore në objektivat e tyre të trainimit, por më shumë gjasa në zbatimin e gabuar të CBOW-së në bibliotekat popullore të tilla si zbatimi zyrtar, word2vec. c, dhe Gensim. Ne tregojmë se pasi të korrigjojmë një gabim në përditësimin e gradientit CBOW, mund të mësohemi përfshirje të fjalëve CBOW që janë plotësisht konkurruese me SG në detyra të ndryshme të brendshme dhe të jashtme, ndërsa janë shumë herë më të shpejtë për të stërvitur.', 'am': 'ሚኮሎov እና አል (2013a) የሚቆጠሩ የቃላት አካባቢ (CBOW) ቃላት አካባቢዎች የስክፕ-ግራም (SG) መልዕክቶችን ለማድረግ ይጠቅማሉ፡፡ ይህቺ አስተያየት በተማሪዎች አቃውሞ በተለየ አይደለም፣ ነገር ግን በተሳሳተ የCBOW ፕሮግራሞች፣ ባለሥልጣን አካባቢ፣ word2vec፣ በሚያስተካክሉ በመዝገብ ገበቦች ውስጥ የክስ ምሳሌ በሚያሳስል ክፋት ነው ብለን እናገኛለን፡፡ c እና Gensim የCBOW ቀዳሚ ቅድሚያ ውስጥ ስሕተቱን በማስተካከል እናሳየዋለን፤ ከዚህም በኋላ ከSG ጋር የተዋጋውን የCBOW ቃላት የውጤት እና ውጭ አድራጊ ስራዎችን በተለየ ቁጥጥር መማር ይችላል፡፡', 'af': "Mikolov et al. (2013a) het aanbevestig dat voortdurende sak van woorde (CBOW) woord inbêdings tendeer om Skip-gram (SG) inbêdings te ondersteun, en hierdie vinding is verkondig in volgende werke. Ons vind dat hierdie opmerkinge nie deur fundamentele verskil in hul oefening-doels gedryf word nie, maar meer waarskynlik op foute negatiewe opmerking van CBOW-implementasies in populêre biblioteke soos die offisiele implementasie, woord 2vec. c, en Gensim. Ons wys dat na korrigeer van 'n fout in die CBOW Gradiënt opdateer, kan een leer CBOW woord inbêding wat heeltemal gemeenskap is met SG op verskeie intrinsiese en extrinsic taak, terwyl baie maal vinniger is om te trein.", 'hy': 'Միկոլով և այլն. (2013a) նկատեցին, որ անընդհատ բառերի պայուսակի ներդրումները հակված են թերևակերպ արտադրել Սկիպ-գրամ (ՍԳ) ներդրումները, և այս հայտնաբերությունը հայտարարվել է հետագա աշխատանքներում: Մենք հայտնաբերում ենք, որ այս հետազոտությունները հիմնական տարբերությունների պատճառով չեն իրենց ուսումնասիրության նպատակներում, այլ ավելի հավանական են սխալ բացասական նմուշներ ընդունելու համար, որոնք հանրային գրադարաններում են, ինչպիսիք են օրինակ պաշտոնական իրականացումը, Word2ve և Ջենսիմ: Մենք ցույց ենք տալիս, որ սխալ ուղղելուց հետո, երբ կարելի է հասկանալ, որ կարելի է հասկանալ այն բառերը, որոնք լիովին մրցակցում են ՍԳ-ի հետ տարբեր ներքին և արտաքին առաջադրանքներում, մինչդեռ շատ անգամ ավելի արագ են վարժվում:', 'az': 'Mikolov et al. (2013a) həmişəlik sözlərin (CBOW) daxilində olan sözlərin içərisində Skip-gram (SG) in şallarını aşağılaşdırmaq məqsədilə göründü və bu tapışma sonrakı işlərdə bildirildi. Biz bu baxışları onların təhsil məqsədilərində əsl fərqli olmayan deyildir, lakin daha çox fərqli olaraq CBOW nümunələrini məşğul kitabları kimi məşğul təhsil etmək, sözləri 2vec kimi məşğul olaraq qeyri-fərqli məqsədilə təşkil edilir. c, Gensim. Biz göstəririk ki CBOW gradient in xətasını düzəltdikdən sonra, CBOW sözlərini SG ilə müxtəlif iç və extrinsic işlərdə mübahisə edən SG sözləri öyrənə bilər, çünki təhsil etmək üçün çox dəfə daha hızlı olaraq.', 'ko': 'Mikolov 등(2013a)이 관찰한 바에 따르면 연속 단어 패키지(CBOW) 단어 삽입은 문법(SG) 삽입을 건너뛰는 것보다 못하다는 발견이 후속 작업에서 보도되었다.우리는 이러한 관찰 결과가 그들의 교육 목표의 근본적인 차이에 의해 구동된 것이 아니라 유행 라이브러리(예를 들어 공식적으로 word2vec를 실현하는 것)에서 잘못된 샘플링 CBOW에 의해 구동된 것일 수도 있다는 것을 발견했다.c. 그리고 겐쿰.우리는 CBOW 계단식 업데이트의 오류를 바로잡은 후에 CBOW 단어의 삽입을 배울 수 있고 각종 내재적, 외적 임무에서 SG와 완전히 경쟁할 수 있으며 훈련 속도가 여러 배 빠르다는 것을 보여준다.', 'ca': "Mikolov et al. (2013a) van observar que l'incorporació continua de paraules en sacs de paraules (CBOW) tendeix a desfer les incorporacions Skip-gram (SG), i aquest descobriment s'ha reportat en treballs posteriors. Trobem que aquestes observacions no estan motivades per diferències fonamentals en els seus objectius de formació, sinó més probablement per implementacions negatives de mostres defectuoses en biblioteques populars com la implementació oficial, word2vec. c, i Gensim. We show that after correcting a bug in the CBOW gradient update, one can learn CBOW word embeddings that are fully competitive with SG on various intrinsic and extrinsic tasks, while being many times faster to train.", 'bn': 'মিকোলোভ এবং আল (২০১৩) লক্ষ্য করেছেন যে অবাধ্য ব্যাগ-অফ-ওয়ার্ড (সিবিওডি) শব্দের প্রতিবেদনে স্কিপ-গ্রাম (এসজি) প্রতিবেদন প্রদর্শন করা হয় এবং পরবর্তী কাজে এই খুঁ আমরা দেখতে পাচ্ছি যে এই পর্যবেক্ষণ তাদের প্রশিক্ষণের উদ্দেশ্যে মৌলিক পার্থক্য নেই, কিন্তু জনপ্রিয় লাইব্রেরীতে জনপ্রিয় লাইব্রেরীতে যেমন সরকারি বাস c, এবং জেন্সিম। আমরা দেখাচ্ছি যে সিবিউড গ্রেডিয়েন্ড আপডেটে একটি বাগ সংশোধনের পরে কেউ শিখতে পারে সিবিউড শব্দের বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন', 'bs': 'Mikolov et al. (2013a) je primijetio da stalno ugrađenje riječi o torbi riječi (CBOW) tendencije podizati ugrađenje Skip-grama (SG), a ovo nalaženje je prijavljeno u sljedećim poslovima. Mi smatramo da te primedbe ne vode temeljne razlike u njihovim ciljevima obuke, već vjerojatno u pogrešnim negativnim provedbama CBOW-a u popularnim bibliotekama poput službenog provedbe, rečenog 2vec. c, i Gensim. Pokazujemo da nakon isprave bube u aktualizaciji CBOW Gradienta, jedan može naučiti CBOW riječi ugrađenje koje su potpuno konkurentne sa SG-om na različitim unutrašnjim i ekstrinsickim zadatkima, dok su mnogo puta brže trenirati.', 'et': 'Mikolov jt. (2013a) märkisid, et pidevad sõnakoti (CBOW) sõnade manustamised kipuvad olema vähem tulemuslikud kui Skip-gramm (SG) manustamised, ja sellest leiust on teatatud hilisemates töödes. Leiame, et need tähelepanekud ei ole tingitud mitte nende koolituse eesmärkide põhimõttelistest erinevustest, vaid tõenäolisemalt puudulikest negatiivsetest proovivõtetest CBOW rakendustest populaarsetes raamatukogudes, nagu ametlik rakendamine, word2vec. c, ja Gensim. Näitame, et pärast vea parandamist CBOW gradienti värskenduses on võimalik õppida CBOW sõna manustamist, mis on SG-ga täielikult konkurentsivõimelised erinevates sisemistes ja välistes ülesannetes, olles samas palju kordi kiirem treenida.', 'cs': 'Mikolov et al. (2013a) poznamenal, že spojité vložení slov (CBOW) mají tendenci nedostatečně výkonné vložení Skip-gram (SG), což bylo popsáno v následujících pracích. Zjišťujeme, že tato pozorování nejsou poháněna zásadními rozdíly v jejich cílech výcviku, ale spíše na chybných negativních vzorkových implementacích CBOW v populárních knihovnách, jako je oficiální implementace Word2vec. C a Gensim. Ukazujeme, že po opravě chyby v aktualizaci CBOW gradientu se člověk může naučit vkládání slov CBOW, které jsou plně konkurenční se SG na různých intrinsických a extrinsických úkolech, přičemž je mnohokrát rychlejší trénovat.', 'fi': 'Mikolov et al. (2013a) havaitsivat, että jatkuvat sanapussin upotukset (CBOW) sanan upotukset yleensä eivät täytä Skip-gram (SG) -upotuksia, ja tämä havainto on raportoitu myöhemmissä tutkimuksissa. Havaintojen taustalla eivät ole perustavanlaatuiset erot koulutustavoitteissa, vaan todennäköisemmin puutteelliset negatiiviset näytteenottomenetelmät populaarikirjastoissa, kuten virallinen toteutus word2vec. c, ja Gensim. Osoitamme, että korjattuamme vian CBOW gradienttipäivityksessä voidaan oppia CBOW-sanaupotuksia, jotka ovat täysin kilpailevia SG:n kanssa erilaisissa sisäisissä ja ulkoisissa tehtävissä, samalla kun niitä on monta kertaa nopeampi kouluttaa.', 'jv': 'mikolv et al. (2013 3 a) Ngawe barang-barang sing ditambah pakan-pakan (IBOw) gambar sing tenong iso nggawe Skip-gram (sG) embedding Awak dhéwé éntuk éntuk-éntuk sing rumpéné karo perusahaan sing dipulangan barang nggawe winih dhéwé, ngèwèké supaya bantêpakan karo perusahaan Where Where is the error message? b, karo Gensi. Awak dhéwé éntuk nggawe diumbang nggawe kesempatan karo perusahaan kelas nang nggawe barang, sampeyan iso nggambar kelas telas nggambar obah-obahan sing dipun-obahan karo GG sampek sing sampeyan karo winih lan akeh dumadhi, sampek uga sak kapan langgar sampeyan tambah.', 'sk': 'Mikolov et al. (2013a) so ugotovili, da neprekinjena vgradnja besed vrečke besed (CBOW) ponavadi manj uspešna vgradnja preskočenih gramov (SG), o čemer so poročali v nadaljnjih delih. Ugotavljamo, da teh opažanj ne vodijo temeljne razlike v njihovih ciljih usposabljanja, temveč verjetneje zaradi napačnih negativnih vzorčenj CBOW implementacij v popularnih knjižnicah, kot je uradna implementacija word2vec. c, in Gensim. Pokazali smo, da se lahko po popravku napake v posodobitvi gradienta CBOW naučimo vgradnje besed CBOW, ki so popolnoma konkurenčne s SG pri različnih notranjih in zunanjih nalogah, hkrati pa je velikokrat hitreje trenirati.', 'ha': "Mikovo et al. (2013) ya gane cewa an na sakan-zane-zane (CBOW) maganar da ake shigar da su ana ƙara da shi a bayan aikin bayan. Tun gane cewa ba a tafiyar da waɗannan saurãre ba da rabo masu binti a cikin goayyakinsu, kuma amma mafi yiwuwa a kan misalin misãlai na haske da misãlai na CBOW a cikin littattafai masu popular kamar misalin rasmi, word2webc. KCharselect unicode block name Mu nuna cewa, a lokacin da za'a daidaita buga cikin mai tsaro na CBOW, za'a iya fahimta maganar CBOW da za'a iya cikakken yin jihãdi da SG kan taskõkin masu cikin na'ura da bakwai, da kuma a sami'a da yawa masu kasi da za'a sani.", 'bo': 'Mikolov et al. (2013a) ནང་དུ་འཕྲོ་མཐུད་གྱི་bag-of-words (CBOW)ཡིག་གེ་སྦྲེལ་མཐུད་ནི་Skip-gram (SG)སྦྲེལ་མཐུད་དང་མཐུད་འདི་ལས་ཀ་སྒྲུབ་ཀྱི་ནང་ཐོག་ཏུ་བྱུང་བ་རེད། ང་ཚོས་མཐོང་སྣང་འདི་དག་གི་ཁྱད་པར་གཞི་རྩལ་བའི་ཁྱད་པར་མི་འདྲ་བ་ཡིན་པས། C དང་Gensim ཡིན། ང་ཚོས་CBOW མཐའ་འཁོར་གྱི་སྒོ་སྒྲིག་ནང་གི་བྱུང་བའི་རྗེས་སུ།', 'he': "Mikolov et al. (2013a) observed that continuous bag-of-words (CBOW) word embeddings tend to underperform Skip-gram (SG) embeddings, and this finding has been reported in subsequent works.  We find that these observations are driven not by fundamental differences in their training objectives, but more likely on faulty negative sampling CBOW implementations in popular libraries such as the official implementation, word2vec. c, וג'נסים. אנחנו מראים שאחרי לתקן באג בתעדכון המדרגות של CBOW, אפשר ללמוד מילים של CBOW שמתחרות לחלוטין עם SG על משימות פנימיות וחיצוניות שונות, בזמן שהיא הרבה פעמים מהירה יותר לאימון."}
{'en': 'BERT Can not Align Characters', 'pt': 'BERT Não Consegue Alinhar Caracteres', 'ar': 'لا يمكن لـ BERT محاذاة الأحرف', 'es': 'BERT no puede alinear los personajes', 'fr': 'BERT ne peut pas aligner les caractères', 'ja': 'BERTは文字を揃えることができません', 'ru': 'BERT не может выровнять символы', 'zh': 'BERT 无以对齐字符', 'hi': 'BERT वर्णों को संरेखित नहीं कर सकता', 'ga': 'Ní féidir le BERT Carachtair a Ailíniú', 'el': 'Δεν είναι δυνατή η ευθυγράμμιση χαρακτήρων BERT', 'hu': 'A BERT nem tudja igazítani a karaktereket', 'it': 'BERT impossibile allineare i caratteri', 'ka': 'BERT შეუძლებელია სიმბოლოების შენახვა', 'kk': 'BERT таңбаларды туралау мүмкін емес', 'lt': 'BERT negali suderinti simbolių', 'mk': 'BERT не може да ги израмни знаците', 'ms': 'BERT Tidak dapat Jajarkan Aksara', 'ml': 'BERT അക്ഷരങ്ങള്\u200d സജ്ജീകരിക്കുവാന്\u200d സാധ്യമല്ല', 'mt': 'BERT Cannot Align Characters', 'pl': 'BERT nie może wyrównać znaków', 'no': 'BERT Kan ikkje justera teikn', 'mn': 'BERT тэмдэгтийг тэмдэглэж чадахгүй', 'ro': 'BERT nu poate alinia caracterele', 'so': 'QIBaseResult', 'si': 'BERT අක්ෂර සම්බන්ධ කරන්න බෑ', 'sr': 'BERT NE MOŽE POPRAVITI karaktere', 'sv': 'BERT kan inte justera tecken', 'ur': 'BERT karakters Align نہیں کر سکتا', 'ta': 'BERT Cannot Align Characters', 'uz': 'Belgilarni tekislab boĘ»lmadi', 'vi': 'kí tự cân bằng', 'bg': 'BERT не може да подравни знаците', 'hr': 'BERT ne može ispraviti znakove', 'da': 'BERT kan ikke justere tegn', 'nl': 'BERT kan tekens niet uitlijnen', 'ko': '버트는 문자를 정렬할 수 없습니다', 'id': 'BERT Tidak dapat Jajarkan Karakter', 'sw': 'QUnicodeControlCharacterMenu', 'tr': 'Karakterler', 'af': 'BERT Kan nie Oplyn Karakters', 'sq': 'BERT nuk mund të rregullojë karakteret', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'BER Չի կարողանում հավասարեցնել նշանները', 'de': 'BERT kann Zeichen nicht ausrichten', 'az': 'BERT Karakterl톛ri Q톛rcl톛y톛 bilmir', 'fa': 'BERT نمی\u200cتوان تنظیم شخصیت\u200cها', 'cs': 'BERT nelze zarovnat znaky', 'et': 'BERT ei saa märke joondada', 'fi': 'BERT ei pysty tasaamaan merkkejä', 'bn': 'বেরেট অক্ষরের সাথে একত্রিত করা যাচ্ছে না', 'bs': 'BERT ne može ispraviti znakove', 'ca': 'BERT no pot alliniar els carauters', 'jv': 'BERT Gak Iso Rusak', 'ha': 'QIBaseResult', 'sk': 'BERT ni moč poravnati znakov', 'he': 'BERT לא יכול להסביר אותיות', 'bo': 'BERT ཡི་གེའི་ཡིག་འབྲུ་གྲལ་སྒྲིག་མི་ཐུབ་པ'}
{'en': 'In previous work, it has been shown that BERT can adequately align cross-lingual sentences on the word level. Here we investigate whether BERT can also operate as a char-level aligner. The languages examined are English, Fake English, German and Greek. We show that the closer two languages are, the better BERT can align them on the character level. BERT indeed works well in English to Fake English alignment, but this does not generalize to natural languages to the same extent. Nevertheless, the proximity of two languages does seem to be a factor. English is more related to German than to Greek and this is reflected in how well BERT aligns them ; English to German is better than English to Greek. We examine multiple setups and show that the similarity matrices for natural languages show weaker relations the further apart two languages are.', 'ar': 'في العمل السابق ، تم إثبات أن BERT يمكنه محاذاة الجمل عبر اللغات بشكل مناسب على مستوى الكلمة. نحن هنا نتحرى ما إذا كان BERT يمكن أن يعمل أيضًا كمصفف على مستوى الحرف. اللغات التي تم فحصها هي الإنجليزية والإنجليزية المزيفة والألمانية واليونانية. نوضح أنه كلما اقتربت لغتان ، كان بإمكان BERT محاذاتهما بشكل أفضل على مستوى الحرف. يعمل BERT بالفعل بشكل جيد في اللغة الإنجليزية لمحاذاة اللغة الإنجليزية المزيفة ، لكن هذا لا يعمم على اللغات الطبيعية بنفس القدر. ومع ذلك ، يبدو أن التقارب بين لغتين عامل. ترتبط اللغة الإنجليزية بالألمانية أكثر من ارتباطها باليونانية وهذا ينعكس في مدى توافق BERT معهم ؛ الإنجليزية إلى الألمانية أفضل من الإنجليزية إلى اليونانية. نحن نفحص إعدادات متعددة ونبين أن مصفوفات التشابه للغات الطبيعية تظهر علاقات أضعف كلما تباعد اللغتان عن بعضهما البعض.', 'pt': 'Em trabalhos anteriores, foi demonstrado que o BERT pode alinhar adequadamente frases multilíngues no nível da palavra. Aqui investigamos se o BERT também pode operar como um alinhador de nível de carvão. Os idiomas examinados são inglês, inglês falso, alemão e grego. Mostramos que quanto mais próximos dois idiomas estiverem, melhor o BERT poderá alinhá-los no nível do caractere. O BERT de fato funciona bem no alinhamento de inglês para inglês falso, mas isso não se generaliza para idiomas naturais na mesma medida. No entanto, a proximidade de duas línguas parece ser um fator. O inglês está mais relacionado ao alemão do que ao grego e isso se reflete em quão bem o BERT os alinha; Inglês para alemão é melhor do que inglês para grego. Examinamos várias configurações e mostramos que as matrizes de similaridade para linguagens naturais mostram relações mais fracas quanto mais distantes duas linguagens estão.', 'ja': 'これまでの研究では、BERTは単語レベルでクロスリンガル文を適切に整列させることができることが示されています。ここでは、BERTがチャージレベルアライナとしても動作できるかどうかを調査します。調べた言語は英語、偽英語、ドイツ語、ギリシャ語である。2つの言語が近ければ近いほど、BERTはキャラクターレベルでそれらを整列させることができることを示しています。BERTは確かに英語ではうまく機能していますが、偽の英語との整合性を保っています。しかし、これが同じ程度に自然言語に一般化するわけではありません。とはいえ、2つの言語が近接していることも要因のようには思えない。英語はギリシャ語よりもドイツ語に関連しており、これはバートがドイツ語とドイツ語をどれだけ揃えているかに反映されています。英語とドイツ語は英語とギリシャ語よりも優れています。複数の設定を検討し、自然言語の類似性行列は、2つの言語がさらに離れているほど弱い関係を示すことを示します。', 'fr': "Dans des travaux antérieurs, il a été démontré que le BERT peut aligner de manière adéquate les phrases multilingues au niveau des mots. Nous examinons ici si le BERT peut également fonctionner comme un aligneur de niveau charbon. Les langues examinées sont l'anglais, le faux anglais, l'allemand et le grec. Nous montrons que plus les deux langues sont proches, mieux BERT peut les aligner au niveau des caractères. BERT fonctionne bien en anglais pour Fake English Alignment, mais cela ne se généralise pas aux langues naturelles dans la même mesure. Néanmoins, la proximité de deux langues semble jouer un rôle. L'anglais est plus proche de l'allemand que du grec, ce qui se reflète dans la façon dont BERT les aligne\xa0; l'anglais vers l'allemand est meilleur que l'anglais vers le grec. Nous examinons plusieurs configurations et montrons que les matrices de similarité pour les langues naturelles montrent des relations plus faibles à mesure que les deux langues sont éloignées l'une de l'autre.", 'es': 'En trabajos anteriores, se ha demostrado que BERT puede alinear adecuadamente las oraciones en varios idiomas a nivel de palabra. Aquí investigamos si BERT también puede funcionar como un alineador de nivel de caracteres. Los idiomas examinados son inglés, inglés falso, alemán y griego. Mostramos que cuanto más cerca estén dos idiomas, mejor será que BERT los alinee en el nivel de los caracteres. De hecho, BERT funciona bien en la alineación del inglés al inglés falso, pero esto no se generaliza a las lenguas naturales en la misma medida. Sin embargo, la proximidad de dos idiomas parece ser un factor. El inglés está más relacionado con el alemán que con el griego y esto se refleja en lo bien que BERT los alinea; el inglés con el alemán es mejor que el inglés con el griego. Examinamos múltiples configuraciones y mostramos que las matrices de similitud para los lenguajes naturales muestran relaciones más débiles cuanto más alejados están los dos idiomas.', 'zh': '前此之事,已验BERT可以尽对齐跨言于单词级。 以此论BERT,亦可以为char齐器行乎? 省言英语,假英语,德语希腊语。 二语愈近,BERT字符愈齐。 BERT诚善于英语英语对齐效,然未尝推之于自然语言也。 然二语近似实一因。 英语之于德语,大于希腊语,其于BERT对齐也。 英语至德语愈于英语希腊语。 检数设,并明自然语言相似性矩阵示两语相去越弱远。', 'ru': 'В предыдущей работе было показано, что БЕРТ может адекватно выравнивать кросслингвальные предложения на уровне слов. Здесь мы исследуем, может ли БЕРТ также работать в качестве выравнивателя на уровне символов. Изучаемые языки: английский, фальшивый английский, немецкий и греческий. Мы показываем, что чем ближе два языка, тем лучше БЕРТ может выровнять их на уровне символов. БЕРТ действительно хорошо работает на английском языке, чтобы подделать английское выравнивание, но это не обобщает естественные языки в той же степени. Тем не менее близость двух языков, как представляется, является одним из факторов. Английский язык больше связан с немецким, чем с греческим, и это отражается в том, насколько хорошо БЕРТ выравнивает их; английский язык с немецким лучше, чем английский с греческим. Мы рассмотрим несколько установок и покажем, что матрицы сходства для естественных языков показывают более слабые отношения, чем дальше два языка.', 'hi': 'पिछले काम में, यह दिखाया गया है कि BERT शब्द स्तर पर क्रॉस-लिंगुअल वाक्यों को पर्याप्त रूप से संरेखित कर सकता है। यहां हम जांच करते हैं कि क्या BERT भी एक चार-स्तरीय संरेखक के रूप में काम कर सकता है। जिन भाषाओं की जांच की गई है, वे अंग्रेजी, नकली अंग्रेजी, जर्मन और ग्रीक हैं। हम दिखाते हैं कि दो भाषाएं जितनी करीब हैं, उतना ही बेहतर बर्ट उन्हें चरित्र स्तर पर संरेखित कर सकता है। BERT वास्तव में नकली अंग्रेजी संरेखण के लिए अंग्रेजी में अच्छी तरह से काम करता है, लेकिन यह उसी हद तक प्राकृतिक भाषाओं के लिए सामान्यीकृत नहीं करता है। फिर भी, दो भाषाओं की निकटता एक कारक प्रतीत होती है। अंग्रेजी ग्रीक की तुलना में जर्मन से अधिक संबंधित है और यह इस बात से परिलक्षित होता है कि BERT उन्हें कितनी अच्छी तरह संरेखित करता है; अंग्रेजी से जर्मन ग्रीक के लिए अंग्रेजी से बेहतर है। हम कई सेटअप की जांच करते हैं और दिखाते हैं कि प्राकृतिक भाषाओं के लिए समानता मैट्रिक्स कमजोर संबंधों को दो भाषाओं के अलावा आगे दिखाते हैं।', 'ga': 'I saothar roimhe seo, tá sé léirithe gur féidir le CRET abairtí tras-teangacha a ailíniú go sásúil ar leibhéal na bhfocal. Déanaimid fiosrú anseo an féidir le CRET feidhmiú mar ailínithe ar leibhéal na ruaille freisin. Is iad na teangacha a scrúdaíodh ná Béarla, Béarla Bréige, Gearmáinis agus Gréigis. Léirímid, dá gaire an dá theanga, is amhlaidh is fearr is féidir le CRET iad a ailíniú ar leibhéal na gcarachtar. Is deimhin go n-oibríonn BERT go maith ó thaobh an Bhéarla le hailíniú Bréige Béarla, ach ní dhéanann sé seo ginearálú go teangacha nádúrtha chomh mór céanna. Mar sin féin, is fachtóir é cóngaracht an dá theanga. Tá baint níos mó ag an mBéarla leis an nGearmáinis ná leis an nGréigis agus léirítear é seo sa chaoi a n-ailínigheann BET iad; Is fearr Béarla go Gearmáinis ná Béarla go Gréigis. Scrúdaímid socruithe iolracha agus léirímid go léiríonn na maitrísí cosúlachta do theangacha nádúrtha caidreamh níos laige dá theanga eile óna chéile.', 'hu': 'Korábbi munkákban bebizonyították, hogy a BERT megfelelően igazítja a nyelvek közötti mondatokat a szó szintjén. Itt azt vizsgáljuk, hogy a BERT képes-e karszintű igazítóként is működni. A vizsgált nyelvek angol, hamis angol, német és görög. Megmutatjuk, hogy minél közelebb van a két nyelv, annál jobban tudja a BERT összehangolni őket a karakter szintjén. A BERT valóban jól működik angolról hamis angolra, de ez nem általánosítja ugyanolyan mértékben a természetes nyelveket. Mindazonáltal a két nyelv közelsége tényezőnek tűnik. Az angol nyelv inkább a némethez kapcsolódik, mint a göröghez, és ez tükröződik abban, hogy a BERT milyen jól összehangolja őket; Az angolról németre jobb, mint az angolról görögre. Többféle beállításokat vizsgálunk, és megmutatjuk, hogy a természetes nyelvek hasonlósági mátrixoi gyengébb kapcsolatokat mutatnak, minél távolabb van két nyelv.', 'el': 'Σε προηγούμενες εργασίες, έχει αποδειχθεί ότι ο BERT μπορεί να ευθυγραμμίσει επαρκώς τις γλωσσικές προτάσεις σε επίπεδο λέξεων. Εδώ ερευνούμε αν το BERT μπορεί επίσης να λειτουργήσει ως ευθυγράμμιση επιπέδου χαρακτήρων. Οι γλώσσες που εξετάζονται είναι Αγγλικά, Ψεύτικα Αγγλικά, Γερμανικά και Ελληνικά. Δείχνουμε ότι όσο πιο κοντά είναι οι δύο γλώσσες, τόσο καλύτερα μπορεί να τις ευθυγραμμίσει στο επίπεδο χαρακτήρων. Το BERT πράγματι λειτουργεί καλά στα αγγλικά για να πλαστογραφήσει την αγγλική ευθυγράμμιση, αλλά αυτό δεν γενικεύει τις φυσικές γλώσσες στον ίδιο βαθμό. Ωστόσο, η εγγύτητα δύο γλωσσών φαίνεται να αποτελεί παράγοντα. Τα αγγλικά σχετίζονται περισσότερο με τα γερμανικά παρά με τα ελληνικά και αυτό αντικατοπτρίζεται στο πόσο καλά τα ευθυγραμμίζει ο BERT. Τα Αγγλικά στα Γερμανικά είναι καλύτερα από τα Αγγλικά στα Ελληνικά. Εξετάζουμε πολλαπλές συνθέσεις και δείχνουμε ότι οι πίνακες ομοιότητας για τις φυσικές γλώσσες δείχνουν ασθενέστερες σχέσεις όσο πιο μακριά είναι οι δύο γλώσσες.', 'ka': 'წინა სამუშაოში მოჩვენებულია, რომ BERT შეუძლია მსგავსი სიტყვების სიტყვების დონეზე გადასრულება. აქ ჩვენ შევხედავთ თუ ბერტი შეუძლია ასევე გავაკეთოთ როგორც სიმბოლობის სწორედ. პასუხულებული ენები არის ანგლისური, ტალქტური ანგლისური, გერმანური და დრეკური. ჩვენ ჩვენ აჩვენებთ, რომ ორი წლის უფრო დაბრუნდება, რომ BERT უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო BERT ნამდვილად ინგლისურად მუშაობს ანგლისურად, მაგრამ ეს არ უნდა იგივე განმავლობაში ჩვენებული ენებისთვის. მაგრამ, ორი ენების დამატება იქნება ფაქტორია. ანგლისური გერმანური უფრო დაკავშირებულია, ვიდრე გერმანური და ეს აღწერებულია რომლებიც BERT მათ უფრო კარგი დაკავშირებულია; ინგლისური გერმანეთისთვის უკეთესია ანგლისური გერმანეთისთვის. ჩვენ გავაკეთებთ რამდენიმე კონფიგურაციები და ჩვენ აჩვენებთ, რომ სახელსახური ენებისთვის მარტირები უფრო ცოტა შესახებ, რამდენიმე გაყოფილი ორი ენები', 'lt': 'Ankstesniame darbe įrodyta, kad BERT gali tinkamai suderinti tarpkalbinius sakinius su žodžių lygiu. Čia mes tiriame, ar BERT taip pat gali veikti kaip simbolių lygio derintuvas. Nagrinėtos anglų, suklastotų anglų, vokiečių ir graikų kalbos. Mes rodome, kad kuo artimesnės dvi kalbos, tuo geresnis BERT gali jas suderinti su simboliais. BERT iš tiesų gerai veikia anglų kalba, kad suklastotų anglų derinimą, tačiau tai ne taip pat paplitusi gamtinėms kalboms. Vis dėlto atrodo, kad dviejų kalbų artimumas yra veiksnys. anglų kalba labiau susijusi su vokiečių kalba nei su graikų kalba ir tai atspindi tai, kaip gerai BERT jas suderina; anglų kalba vokiečių kalba yra geresnė nei anglų kalba graikų kalba. Mes išnagrinėjame įvairias struktūras ir rodome, kad panašumo matricos natūralioms kalboms rodo silpnesnius santykius, tuo labiau atskiriamos dvi kalbos.', 'it': "In precedenti lavori, è stato dimostrato che BERT è in grado di allineare adeguatamente frasi cross-lingual a livello di parola. Qui esaminiamo se BERT può funzionare anche come allineatore a livello char. Le lingue esaminate sono l'inglese, l'inglese falso, il tedesco e il greco. Mostriamo che più le due lingue sono vicine, più BERT può allinearle al livello dei caratteri. BERT funziona davvero bene in inglese a finto allineamento inglese, ma questo non si generalizza alle lingue naturali nella stessa misura. Tuttavia, la vicinanza di due lingue sembra essere un fattore determinante. L'inglese è più legato al tedesco che al greco e questo si riflette nel modo in cui BERT li allinea; Da inglese a tedesco è meglio che da inglese a greco. Esaminiamo configurazioni multiple e mostriamo che le matrici di somiglianza per i linguaggi naturali mostrano relazioni più deboli quanto più distanti sono le due lingue.", 'kk': 'Алдыңғы жұмыс ішінде, BERT сөздің деңгейінде тілді сөздерді дұрыс түрлендіруге болады деп көрсетілді. Мұнда біз BERT символдық деңгейінде жұмыс істеуге болады. Тексерілген тілдер - ағылшын, жалғыз ағылшын, неміс және грек. Біз екі тіл жақын болса, BERT оны таңбаның деңгейіне жақсы түрлендіре алады деп көрсетедік. BERT ағылшын тілінде ағылшын тіліне жақсы жұмыс істейді, бірақ бұл табиғи тілдеріне бірдей жақсы жұмыс істемейді. Әйтпесе, екі тілдің жақын жақын факторы сияқты. Ағылшын тілінде неміс тілінде грек тілінен қанша сәйкес болады. Бұл BERT оларды қанша жақсы түрлендіру үшін көрсетіледі. Ағылшын тіліне неміс тіліне ағылшын тілінен жақсы. Біз бірнеше параметрлерді тексеріп, табиғи тілдерінің тең матрицаларының қатынастарының бірнеше қатынастарын көрсетеді.', 'mk': 'Во претходната работа се покажа дека БЕРТ може соодветно да ги поправи прекујазичните реченици на нивото на зборот. Here we investigate whether BERT can also operate as a char-level aligner.  Јазиците кои се испитани се англиски, лажни англиски, германски и грчки. Ние покажуваме дека колку поблиску се двата јазици, толку подобро BERT може да ги поправи на ниво на карактеристика. Берт навистина работи добро на англиски за лажно англиско прилагодување, но ова не се генерализира на природни јазици во ист степен. Сепак, близината на двата јазици се чини дека е фактор. Англискиот јазик е поврзан со германскиот отколку со грчкиот јазик и ова се одразува во тоа колку добро ги прилагодува БЕРТ; Англиски на германски е подобар од англиски на грчки. Ги испитуваме многуте поставувања и покажуваме дека матриците на сличност за природните јазици покажуваат послаби односи колку повеќе се разделени двата јазици.', 'ml': 'മുമ്പുള്ള ജോലിയില്\u200d BERT വാക്കുകള്\u200d വാക്കിന്റെ നിലയില്\u200d മതിയായി സജ്ജീകരിക്കാന്\u200d സാധിക്കുന്നു. ഇവിടെ നമ്മള്\u200d അന്വേഷിക്കുന്നത് ബെര്\u200dട്ടി ഒരു ചാര്\u200dലേയര്\u200d ആകെ പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d കഴിയുമോ എന്ന്. പരിശോധിക്കപ്പെട്ട ഭാഷ ഇംഗ്ലീഷ്, ഫെയ്ക് ഇംഗ്ലീഷ്, ജര്\u200dമ്മന്\u200d, ഗ്രീക്ക്. നമ്മള്\u200d കാണിക്കുന്നത് രണ്ടു ഭാഷകളുടെ അടുത്താണെന്നാണ്, കൂടുതല്\u200d ഭാഷകങ്ങള്\u200d ബെര്\u200dട്ട് അതിനെ അക്ഷരസഞ്ചയില ബെര്\u200dട്ടി തീര്\u200dച്ചയായും ഇംഗ്ലീഷിലേക്ക് ഫെയ്ക് ഇംഗ്ലീഷിലേക്ക് നന്നായി പ്രവര്\u200dത്തിക്കുന്നു. പക്ഷെ ഇത് സ്വ എന്നാലും രണ്ടു ഭാഷകളുടെ അടുത്ത് ഒരു കാരണമാണെന്ന് തോന്നുന്നു. ഗ്രീക്കിലേക്കാള്\u200d ജര്\u200dമ്മനിലേക്കാള്\u200d ഇംഗ്ലീഷിലേക്ക് കൂടുതല്\u200d ബന്ധമുള്ളതാണ് ഇത് ബെര്\u200dട്ടി എത്ര നന്നായ ഇംഗ്ലീഷിലേക്ക് ജര്\u200dമനിലേക്ക് ഇംഗ്ലീഷിലേക്ക് ഗ്രീക്കിലേക്കാള്\u200d നല്ലതാണ്. സ്വാഭാഷ ഭാഷകള്\u200dക്കുള്ള ഒരേപോലുള്ള മാറ്റിക്രിസ്റ്റികള്\u200d കാണിക്കുന്നു. രണ്ടു ഭാഷകള്\u200d വേര്\u200dതിരിച്ചു കൂടുതല്\u200d ദ', 'ms': 'Dalam kerja terdahulu, telah dipaparkan bahawa BERT boleh menyesuaikan kalimat salib-bahasa dengan sesuai pada aras perkataan. Di sini kita menyelidiki sama ada BERT juga boleh beroperasi sebagai penyesuaian aras-aksara. Bahasa yang diperiksa adalah bahasa Inggeris, Bahasa Inggeris palsu, Jerman dan Yunani. Kita tunjukkan bahawa semakin dekat dua bahasa, semakin baik BERT boleh menyesuaikan mereka pada tahap aksara. BERT benar-benar berfungsi dengan baik dalam bahasa Inggeris untuk menyesuaikan bahasa Inggeris palsu, tetapi ini tidak menyebarkan kepada bahasa semulajadi ke arah yang sama. Namun, kedekatan dua bahasa nampaknya adalah faktor. English is more related to German than to Greek and this is reflected in how well BERT aligns them;  Bahasa Inggeris kepada Jerman lebih baik daripada Bahasa Inggeris kepada Yunani. Kami memeriksa setup berbilang dan menunjukkan bahawa matriks persamaan untuk bahasa alam menunjukkan hubungan yang lemah semakin jauh dua bahasa.', 'no': 'I førre arbeid har det vist at BERT kan tilpassa krysspråk setningar på ordnivået. Her kan vi undersøkja om BERT også kan arbeide som ei teiknvolving. Språk som er undersøkt er engelsk, falske engelsk, tysk og gresk. Vi viser at dei nærmere to språka er, jo bedre BERT kan justera dei på teiknivået. BERT fungerer faktisk godt i engelsk for å falske engelsk innretting, men dette generelliserer ikkje til naturspråk samme grad. Men tilnærminga til to språk ser likevel ut til å vera ein faktor. Engelsk er meir relatert til tysk enn til gresk, og dette er reflektert i kor godt BERT innrettar dei. Engelsk til tysk er bedre enn engelsk til gresk. Vi undersøker fleire innstillingar og viser at tilsvarende matrisene for naturspråk viser forskjellige forholdar, dei fleire skilde to språk er.', 'mt': 'F’ħidma preċedenti, intwera li l-BERT jista’ jallinja b’mod adegwat is-sentenzi translingwi fuq il-livell tal-kelma. Hawnhekk ninvestigaw jekk il-BERT jistax jopera wkoll bħala allinjatur fil-livell tal-karattri. Il-lingwi eżaminati huma l-Ingliż, l-Ingliż Falz, il-Ġermaniż u l-Grieg. Aħna nuru li aktar ma jkunu eqreb iż-żewġ lingwi, aktar il-BERT jista’ jallinjahom fuq il-livell tal-karattri. BERT indeed works well in English to Fake English alignment, but this does not generalize to natural languages to the same extent.  Madankollu, il-viċinanza ta’ żewġ lingwi tidher li hija fattur. L-Ingliż huwa aktar relatat mal-Ġermaniż milli mal-Grieg u dan huwa rifless f’kemm il-BERT jallinjahom tajjeb; English to German is better than English to Greek.  Aħna jeżaminaw diversi strutturi u nuru li l-matriċi ta’ similarità għal-lingwi naturali juru relazzjonijiet aktar dgħajfa aktar ma jkunux differenti żewġ lingwi.', 'pl': 'W poprzednich pracach wykazano, że BERT potrafi odpowiednio dopasować zdania wielojęzyczne na poziomie słowa. W tym miejscu badamy, czy BERT może również działać jako aligner na poziomie znaków. Badane języki to angielski, fałszywy angielski, niemiecki i grecki. Pokazujemy, że im bliżej są dwa języki, tym lepiej BERT może wyrównać je na poziomie znaków. BERT rzeczywiście działa dobrze w języku angielskim do fałszywego języka angielskiego, ale nie uogólnia to języków naturalnych w tym samym stopniu. Niemniej jednak bliskość dwóch języków wydaje się być czynnikiem. Angielski jest bardziej spokrewniony z niemieckim niż z greckim, co znajduje odzwierciedlenie w tym, jak dobrze BERT je dopasowuje; Angielski na niemiecki jest lepszy niż angielski na grecki. Badamy wiele konfiguracji i pokazujemy, że macierze podobieństwa dla języków naturalnych wykazują słabsze relacje, im dalej są dwa języki.', 'ro': 'În lucrările anterioare, s-a demonstrat că BERT poate alinia în mod adecvat propozițiile translingvistice la nivelul cuvântului. Aici investigăm dacă BERT poate funcționa și ca alinier la nivel de caracter. Limbile examinate sunt engleza, engleza falsă, germana și greaca. Arătăm că cu cât sunt mai apropiate două limbi, cu atât BERT le poate alinia mai bine la nivelul caracterului. BERT funcționează într-adevăr bine în limba engleză la aliniere falsă, dar acest lucru nu generalizează la limbile naturale în aceeași măsură. Cu toate acestea, apropierea a două limbi pare a fi un factor. Engleza este mai mult legată de germană decât de greacă și acest lucru se reflectă în modul în care BERT le aliniază; Engleză în germană este mai bine decât engleză în greacă. Examinăm mai multe setări și arătăm că matricele de similitudine pentru limbile naturale prezintă relații mai slabe cu cât sunt mai departe două limbi.', 'sr': 'U prethodnom poslu, pokazalo je da BERT može odgovarajući poravnati krstojezičke rečenice na nivou reči. Ovde istražujemo da li BERT može i da funkcioniše kao poravnač nivoa karaktera. Ispitivani jezici su engleski, lažni engleski, nemački i grčki. Pokazujemo da su bliže dve jezike, što bolje BERT može da ih poravna na nivou karaktera. BERT zaista dobro radi na engleskom jeziku da laži englesko poravnanje, ali to se ne generalizuje na prirodne jezike u istoj mjeri. Ipak, blizina dva jezika izgleda da je faktor. Engleski su više povezani s nemačkim nego sa grčkim, a to se odražava kako ih BERT dobro poravna; Engleski na njemački je bolji od engleskog na grčkog. Provjeravamo više setova i pokazujemo da su matrice sličnosti prirodnim jezicima slabije odnose koje su dalje razdvojene dve jezike.', 'so': 'Shaqo hore waxaa la muujiyey in BERT si ku filan looga simi karo erayga heerka luqada ah. Halkan waxaynu baaraynaa in BERT uu sidoo kale u shaqeyn karo sameynta xarafta. Luqadaha la imtixaamo waa Ingiriis, Ingiriis fake, Jarmal iyo Gariig. Waxan tusnaynaa in labada luqadood ee ugu dhow ay yihiin, BERT ayaa si fiican u sawiri kara heerka aqoonta. Sida runta ah BERT wuxuu si wanaagsan ugu shaqeeyaa afka ingiriisiga, laakiin taas si isku mid ah uma sameeyo luuqadaha asalka ah. Si kastaba ha ahaatee, u dhowaanshada laba luqadood waxay u muuqataa inay ahaato xaal. Ingiriis waxay ku xiran tahay Jarmalka ka tirsan tahay Gariigga, taasna waxaa looga fiirsan yahay sida aad BERT ugu siman tahay; Ingiriis ilaa Jarmal way ka wanaagsan tahay Ingiriis ilaa Gariig. We examine multiple setups and show that the similarity matrices for natural languages show weaker relations the further apart two languages are.', 'si': 'මුලින් වැඩේදී, BERT වචන ස්තූතියෙන් ක්\u200dරිස් භාෂාවක් වචන වචන සැකසුම් කරන්න පුළුවන් කියලා පෙන්වන්න මෙතන අපි පරීක්ෂණය කරන්නේ BERT එක්ක අක්ෂර ප්\u200dරමාණයක් විදිහට වැඩ කරන්න පුළුවන් කියලා. පරීක්ෂණය කරපු භාෂාවල් ඉංග්\u200dරීසිය, බොරු ඉංග්\u200dරීසිය, ජර්මන් සහ ග්\u200dරීසිය. අපි පෙන්වන්නේ වඩා ලඟින් භාෂාවක් දෙකක් තියෙනවා කියලා, BERT වඩා හොඳයි ඔවුන්ව අක්ෂර ස්ථානයේ ස BERT ඇත්තටම ඇත්තටම ඉංග්\u200dරීසියේ හොඳ වැඩ කරනවා ඉංග්\u200dරීසිය සංවිධානය කරනවා, ඒත් මේක සාමාන්\u200dය භාෂාව ඒත් වගේම, භාෂාව දෙන්නෙක් ගොඩක් ප්\u200dරමාණයක් වගේ. ඉංග්\u200dරීසිය ග්\u200dරීක් වලට වඩා ජර්මන් වලට වඩා සම්බන්ධ වෙනවා ඒ වගේම BERT ඔවුන්ට කොච්චර හොඳ සංව ඉංග්\u200dරීසියෙන් ජර්මන් වලට ඉංග්\u200dරීසියෙන් ග්\u200dරීක් වලට වඩා හොඳයි. අපි ගොඩක් සැකසුම් පරීක්ෂා කරනවා ඒ වගේම පෙන්වන්නේ ස්වභාවික භාෂාවට සම්බන්ධතා මැට්\u200dරිස් වලින් වඩා ද', 'sv': 'I tidigare arbete har det visat sig att BERT på lämpligt sätt kan anpassa korspråkiga meningar på ordnivå. Här undersöker vi om BERT också kan fungera som en char-level aligner. De undersökta språken är engelska, falska engelska, tyska och grekiska. Vi visar att ju närmare två språk är, desto bättre kan BERT anpassa dem på teckenivå. BERT fungerar verkligen bra på engelska till falska engelska justeringar, men detta generaliserar inte till naturliga språk i samma utsträckning. Närheten till två språk tycks dock vara en faktor. Engelska är mer relaterad till tyska än till grekiska och detta återspeglas i hur väl BERT anpassar dem. Engelska till tyska är bättre än engelska till grekiska. Vi undersöker flera uppställningar och visar att likhetmatriserna för naturliga språk visar svagare relationer ju längre isär två språk är.', 'ta': 'முந்தைய வேலையில், BERT வார்த்தை மட்டத்தில் போதுமான மொழிகளை ஒழுங்குபடுத்த முடியும் என்பது தெரியும். இங்கே BERT ஒரு எழுத்து மட்டத்தில் செயல்படுத்த முடியுமா என்பதை நாம் சோதிக்க வேண்டும். பரிசோதிக்கப்பட்ட மொழிகள் ஆங்கிலம், போலி ஆங்கிலம், ஜெர்மன் மற்றும் கிரீக்கு நெருங்கிய இரண்டு மொழிகள் என்பதை நாம் காட்டுகிறோம், பெர்ட் அதை எழுத்து நிலையில் ஒழுங்குபடுத்த முடிய பெர்ட் நிச்சயமாக ஆங்கிலத்தில் போலி ஆங்கிலத்திற்கு நன்றாக செயல்படுகிறது, ஆனால் இது இயல்பான மொழிகளுக்கு ஒரே அளவில் ப ஆனாலும், இரண்டு மொழிகளின் நெருக்கம் ஒரு காரணி தெரிகிறது. ஆங்கிலத்தில் ஜெர்மனிக்குக் கிரீக்குக்கு விட அதிகமாக தொடர்பு உள்ளது இது பிரிக்கப்படுகிறது BERT அவை எவ்வளவு நன் ஜெர்மனுக்கு ஆங்கிலம் என்பது ஆங்கிலத்தை கிரீக்கிலத்தை விட சிறந்தது. நாம் பல அமைப்புகளைச் சோதிக்கிறோம் மற்றும் இயற்கையான மொழிகளுக்கு சமமான மாட்ரிக்களை காண்பிக்கிறோம் என்று காட', 'mn': 'Өмнөх ажлын хувьд БЕРТ хэл хэлний өгүүлбэрийг хэлний түвшинд адилхан зохицуулж чадна гэдгийг харуулсан. Энд бид БЕРТ мөн чанарын түвшинд зохицуулагч гэж ажиллаж болох эсэхийг судалж байна. Шалгуулсан хэл бол Англи, худлаа Англи, Герман, Грек. Бид хоёр илүү ойрхон хэл гэдгийг харуулж байна, тэдгээрийг илүү сайн БЕРТ харилцааны түвшинд зохицуулж чадна. БЕРТ Англи хэлний хэлний хувьд Англи хэлний хувьд сайн ажилладаг, гэхдээ энэ нь байгалийн хэлний хувьд ижил хэмжээнд нийтлэгддэггүй. Гэвч хоёр хэлний ойролцоо нь хүчин зүйл мэт харагдаж байна. Англи хэл Германтай Гректэй илүү холбоотой. БЕРТ тэднийг хэрхэн сайн холбоотой вэ? Англи хэл Германт Англи хэл грект илүү сайн. Бид олон төрлийн байгууллагуудыг шалгаж байгалийн хэлний тэнцүү байдлын матриц нь хоёр хэлний хоорондоо илүү бага харилцаа харуулдаг гэдгийг харуулж байна.', 'ur': 'پہلے کے کام میں دکھایا گیا ہے کہ BERT کلام سطح پر کلاس زبان کے مطابق قابل تعمیر کر سکتا ہے۔ یہاں ہم تحقیق کریں کہ کیا BERT ایک چار سطح الیزار کے طور پر عمل کرسکتا ہے۔ تحقیق کی زبانیں انگلیسی، انگلیسی، جرمانی اور یونانی ہیں. ہم دکھاتے ہیں کہ دو زبانیں زیادہ قریب ہیں، بہترین BERT ان کو شخصیٹ سطح پر ٹھیک کر سکتا ہے۔ BERT یقیناً انگلیسی میں اچھا کام کرتا ہے انگلیسی الٹ مہلت کے لئے، لیکن یہ طبیعی زبانوں کو ایک ہی اندازہ تک نہیں پہنچاتا۔ لیکن دو زبانوں کے نزدیک ایک فاکتور بن رہا ہے۔ انگلیسی انگلیسی یونانی سے زیادہ جرمنی کے ساتھ رابطہ ہے اور یہ بتائی جاتی ہے کہ BERT ان کے ساتھ کس طرح اچھا ٹھیک ٹھیک کرتا ہے۔ انگلیسی سے جرمانی سے انگلیسی سے بہتر ہے یونانی سے۔ ہم بہت سی تنظیمات کی تحقیق کرتے ہیں اور دکھاتے ہیں کہ طبیعی زبانوں کے مثال مثالیں کمزور رابطہ دکھاتے ہیں اور دوسری زبانیں کمزور ہیں۔', 'uz': "Oldingi ishda BERT so'zlarni so'zning har bir tillar darajada tekislash mumkin. Bu yerda biz BERT char- darajasi tenglari sifatida ishlab chiqara oladi. Tanlangan tillar ingliz tili, fake ingliz tili, Olmon va Greek tili. Ko'pchilik ikkita tilni ko'rsatishimiz mumkin, BERT ularning yaxshi darajadagi harfga tekislash mumkin. BERT haqida ingliz tilida faqqat ingliz tilida eng yuqoriga ishlaydi, lekin bu tabiiy tillarda bir xil tilda yaratishmaydi. Nevertheless, the proximity of two languages does seem to be a factor.  Inglizcha ingliz tilidan yunonchadan ko'proq yunonchaga bog'liq va bu ularning BERT qanday yaxshi ko'plab keladi. Inglizcha tiliga ingliz tilidan Inglizchadan yunonchadan yaxshi. Biz bir necha ta'plamlarni ko'rib o'rganamiz va tabiiy tillar uchun huddi matrikalarni ko'rsatamiz va ikki tillarning ikki tillari ko'proq qo'shimcha munosabatlarni ko'rsatamiz.", 'vi': 'Trong công việc trước đây, đã được cho thấy rằng BERT có thể thẳng xếp các câu chữ xuyên ngôn ngữ thích hợp với từ cấp này. Ở đây chúng tôi điều tra xem BERT có thể hoạt động cùng với bia đốt cháy. Các ngôn ngữ được kiểm tra là Anh, Anh quốc Giả, Đức và Hy Lạp. Chúng tôi cho thấy hai ngôn ngữ gần nhau hơn, loại BERT càng có thể xếp chúng theo cấp độ nhân vật. Thực ra BERT thật sự hoạt động tốt trong tiếng Anh giả tạo. Nhưng điều này không thể nói chung về ngôn ngữ tự nhiên. Tuy nhiên, gần hai ngôn ngữ có vẻ là một yếu tố. Tiếng Anh có liên quan đến Đức hơn là tiếng Hy Lạp, và điều đó phản ánh bằng cách nào BERT mang họ vào. Tiếng Anh với tiếng Đức tốt hơn tiếng Anh với tiếng Hy Lạp. Chúng tôi xem xét nhiều cài đặt và cho thấy các sản phẩm giống nhau trong ngôn ngữ tự nhiên cho thấy các mối quan hệ yếu hơn.', 'hr': 'U prethodnom poslu pokazalo je da BERT može odgovarajući poravnati krstojezičke rečenice na razini riječi. Ovdje istražujemo da li BERT također može funkcionirati kao poravnač nivoa karaktera. Ispitivani jezici su engleski, lažni engleski, njemački i grčki. Pokazujemo da su bliže dvije jezike, bolje ih BERT može poravnati na razini karaktera. BERT zaista dobro radi na engleskom jeziku da laži englesko poravnanje, ali to se ne generalizuje na prirodne jezike u istoj mjeri. Ipak, blizina dva jezika čini se da je faktor. Engleski su više povezani s njemačkim nego s grčkim, a to se odražava kako ih BERT dobro poravna; Engleski na njemački je bolji nego engleski na grčki. Istražujemo više setova i pokazujemo da su matrice sličnosti prirodnim jezicima slabije odnose koje su dalje razdvojeni dva jezika.', 'bg': 'В предишни работи беше показано, че BERT може адекватно да подравнява междуезичните изречения на ниво думата. Тук ние разследваме дали BERT може да работи и като подравняване на нивото на въглерод. Разгледаните езици са английски, фалшив английски, немски и гръцки. Показваме, че колкото по-близки са двата езика, толкова по-добре може да ги подравни на ниво символи. BERT наистина работи добре на английски език за фалшиво английско подравняване, но това не обобщава естествените езици в същата степен. Въпреки това близостта на два езика изглежда фактор. Английският е по-скоро свързан с немски, отколкото с гръцки и това се отразява в това колко добре BERT ги подравнява; Английски на немски е по-добре от английски на гръцки. Разглеждаме множество настройки и показваме, че матриците за сходство при естествените езици показват по-слаби взаимоотношения, колкото по-отдалечени са два езика.', 'id': 'Dalam pekerjaan sebelumnya, telah menunjukkan bahwa BERT dapat menyesuaikan kalimat saling bahasa dengan cukup pada tingkat kata. Di sini kita menyelidiki apakah BERT juga bisa beroperasi sebagai penyesuaian tingkat karakter. Bahasa yang diperiksa adalah bahasa Inggris, Bahasa Inggris palsu, Jerman dan Yunani. Kita menunjukkan bahwa semakin dekat dua bahasa, semakin baik BERT dapat menyesuaikan mereka pada tingkat karakter. BERT benar-benar bekerja dengan baik dalam bahasa Inggris untuk menyesuaikan bahasa Inggris palsu, tetapi ini tidak menyebar ke bahasa alami dengan tingkat yang sama. Namun, kedekatan dua bahasa tampaknya faktor. Bahasa Inggris lebih berhubungan dengan Jerman daripada Yunani dan ini terrefleksi dalam betapa baik BERT menyesuaikan mereka; Inggris ke Jerman lebih baik dari Inggris ke Yunani. Kami memeriksa beberapa setup dan menunjukkan bahwa matris persamaan untuk bahasa alami menunjukkan hubungan yang lebih lemah semakin jauh dua bahasa.', 'de': 'In früheren Arbeiten konnte gezeigt werden, dass BERT mehrsprachige Sätze auf Wortebene adäquat ausrichten kann. Hier untersuchen wir, ob BERT auch als Char-Level Aligner funktionieren kann. Die untersuchten Sprachen sind Englisch, Fake English, Deutsch und Griechisch. Wir zeigen, dass je näher zwei Sprachen sind, desto besser BERT sie auf Zeichenebene ausrichten kann. BERT funktioniert zwar gut in Englisch zu Fake English Alignment, aber dies verallgemeinert sich nicht in gleichem Maße auf natürliche Sprachen. Dennoch scheint die Nähe zweier Sprachen ein Faktor zu sein. Englisch ist mehr mit Deutsch als mit Griechisch verwandt, und dies spiegelt sich darin wider, wie gut BERT sie ausrichtet; Englisch zu Deutsch ist besser als Englisch zu Griechisch. Wir untersuchen mehrere Setups und zeigen, dass die Ähnlichkeitsmatrizen für natürliche Sprachen schwächere Beziehungen aufweisen, je weiter zwei Sprachen voneinander entfernt sind.', 'da': 'I tidligere arbejde har det vist sig, at BERT tilstrækkeligt kan justere tværsprogede sætninger på ordniveau. Her undersøger vi, om BERT også kan fungere som en char-level aligner. De undersøgte sprog er engelsk, falsk engelsk, tysk og græsk. Vi viser, at jo tættere to sprog er, jo bedre kan BERT justere dem på tegneniveau. BERT fungerer faktisk godt på engelsk til falsk engelsk justering, men dette generaliserer ikke til naturlige sprog i samme omfang. Ikke desto mindre synes nærheden af to sprog at være en faktor. Engelsk er mere relateret til tysk end til græsk, og dette afspejles i, hvor godt BERT tilpasser dem. Engelsk til tysk er bedre end engelsk til græsk. Vi undersøger flere opsætninger og viser, at lighedsmatricerne for natursprog viser svagere relationer jo længere adskilt to sprog er.', 'nl': 'In eerder werk is aangetoond dat BERT taaloverschrijdende zinnen op woordniveau adequaat kan uitlijnen. Hier onderzoeken we of BERT ook als char-level aligner kan werken. De onderzochte talen zijn Engels, Nep Engels, Duits en Grieks. We laten zien dat hoe dichter de twee talen zijn, hoe beter BERT ze op karakterniveau kan uitlijnen. BERT werkt inderdaad goed in het Engels naar Fake English alignment, maar dit generaliseert niet in dezelfde mate naar natuurlijke talen. Toch lijkt de nabijheid van twee talen een factor te zijn. Engels is meer verwant aan Duits dan aan Grieks en dit komt tot uiting in hoe goed BERT ze op elkaar afstemt; Engels naar Duits is beter dan Engels naar Grieks. We onderzoeken meerdere opstellingen en tonen aan dat de vergelijkingsmatrices voor natuurlijke talen zwakkere relaties vertonen naarmate twee talen verder uit elkaar liggen.', 'ko': '이전 작업에서 BERT가 단어 차원에서 크로스 언어 문장을 충분히 맞출 수 있음을 증명하였다.여기서, 우리는 버트가 문자급 대조기로도 쓸 수 있는지 조사한다.검사된 언어는 영어, 가짜 영어, 독일어, 그리스어가 있다.우리는 두 언어가 가까울수록 BERT는 문자 레벨에서 그것들을 정렬할 수 있다는 것을 보여 준다.BERT는 영어에서 확실히 영어의 정렬 방식을 잘 모방했지만 같은 정도에 자연어로 보급되지는 않았다.그러나 두 언어의 접근은 확실히 하나의 요소인 것 같다.영어와 독일어의 관계는 그리스어와의 관계보다 더욱 밀접하다는 점은 버트가 어떻게 그것들을 잘 연결시키는지에 반영된다.영어가 독일어에 대한 것이 영어가 그리스어에 대한 것보다 낫다.우리는 여러 가지 설정을 검사했고 자연 언어의 유사성 행렬이 비교적 약한 관계를 보였으며 두 언어 사이의 거리가 멀어질수록', 'fa': 'در کار قبلی، نشان داده شده که BERT می تواند به طور مناسب جمله\u200cهای متوسط زبان را بر سطح کلمه تنظیم کند. ما در اینجا تحقیق می کنیم که آیا BERT می تواند همچنین به عنوان یک تنظیم سطح علامت عمل کند. زبانها تحقیق شده انگلیسی، انگلیسی، آلمانی و یونانی هستند. ما نشان می دهیم که دو زبان نزدیکتر اینه که BERT بهتر می تواند آنها را در سطح شخصیت تنظیم کند. BERT واقعاً در انگلیسی برای تبدیل کردن انگلیسی خوب کار می کند، اما این به زبانهای طبیعی به همان اندازه عادی نمی کند. با این حال، نزدیک دو زبان به نظر می رسد یک faktor باشد. انگلیسی بیشتر به آلمانی نسبت به یونانی ارتباط دارد و این توضیح می\u200cشود که BERT چقدر خوب به آنها ارتباط می\u200cدهد. انگلیسی به آلمان بهتر از انگلیسی به یونانی است. ما چند تنظیم را تحقیق می\u200cکنیم و نشان می\u200cدهیم که ماتریس شباهت برای زبانهای طبیعی رابطه\u200cهای ضعیف\u200cتری را نشان می\u200cدهیم که دو زبان بیشتر جدا می\u200cشوند.', 'sw': 'Katika kazi zilizopita, imeonyesha kwamba BERT anaweza kuunganisha vigezo vya lugha vya kutosha kwenye ngazi ya neno. Hapa tunachunguza kama BERT anaweza kufanya kazi kama aliyetengenezea ngazi ya tabia. Lugha zinazochunguzwa ni Kiingereza, Kiingereza Hati, Kijerumani na Kigiriki. We show that the closer two languages are, the better BERT can align them on the character level.  BERT kwa hakika inafanya kazi vizuri katika lugha ya Kiingereza kwa ajili ya kuingia Uingereza, lakini hii haiwezi kuzalisha lugha za asili kwa kiwango hicho. Hata hivyo, ukaribu wa lugha mbili unaonekana kuwa sababu. Kiingereza kinahusiana na Ujerumani zaidi ya Kigiriki na hii inaonyesha kwa jinsi BERT inavyofanana; Kiingereza kwa Kijerumani ni bora kuliko Kiingereza hadi Kigiriki. Tunajaribu matatizo mengi na kuonyesha kuwa viungo vinavyofanana kwa lugha asili vinaonyesha uhusiano dhaifu zaidi wa lugha mbili tofauti zaidi.', 'tr': "Öňki işde, BERT sözleriň sözleriň derejesinde adaty çykyp biljekdigini görkezildi. Bu ýerde BERT'iň karakter derejesi çyzgyrjakda işleýändigini barlaýarys. Barlanýan diller iňlisçe, iňlisçe ýalan, nemes we iňlisçe. Biz iki diliň ýakyn bolandygyny görkeýäris, BERT-iň gowy görkezilişi karakter derejesinde çyzyp biler. BERT Iňlisçe adatça iňlisçe söňlemek üçin gowy işleýär, ýöne bu tebigy dillere bir şekilde täze söňlemeýär. Yöne iki diliň golaýynyň bir faktör bolup görünýär. Iňlisçe Almança Ýunanyň derejesinden has baglanýar we bu BERT olary nähili gowy gabdalýar; Iňlisçe bilen Almança iňlisçe iňlisçe iňlisçe iňlisçe has gowydyr. Biz birnäçe düzümleri barlaýarys we tebigy diller üçin meňzeşlik matrisleriniň iki dilden daşyrak baglaşyklaryny görkez.", 'sq': "Në punën e mëparshme, është treguar se BERT mund të përshtatet në mënyrë të përshtatshme fjalët ndërgjuhësore në nivelin e fjalëve. Këtu ne hetojmë nëse BERT mund të funksionojë gjithashtu si një rregullues i nivelit të karakterit. Gjuhat e shqyrtuara janë anglisht, anglisht të rreme, gjermanisht dhe grek. Ne tregojmë se sa më afër janë dy gjuhët, aq më mirë BERT mund t'i rregullojë ato në nivelin e karakterit. BERT me të vërtetë punon mirë në anglisht për të falsifikuar rregullimin anglez, por kjo nuk gjeneralizohet në gjuhët natyrore në të njëjtën shkallë. Megjithatë, afërsia e dy gjuhëve duket se është një faktor. Angleza është më e lidhur me gjermaninë se me greqin dhe kjo pasqyrohet në se sa mirë BERT i përshtatet ato; Anglisht në gjerman është më mirë se anglisht në grek. Ne shqyrtojmë struktura të shumta dhe tregojmë se matricat e ngjashmërisë për gjuhët natyrore tregojnë marrëdhënie më të dobëta sa më larg janë dy gjuhët.", 'hy': 'Անցյալ աշխատանքի ընթացքում ցույց է տվել, որ BER-ը կարող է բառերի մակարդակի հետ համապատասխանաբար հարմարեցնել լեզվային նախադասությունները: Here we investigate whether BERT can also operate as a char-level aligner.  Անգլերեն, կեղծ անգլերեն, գերմաներեն և հուներեն են: Մենք ցույց ենք տալիս, որ որքան ավելի մոտ են երկու լեզուները, այնքան ավելի լավ է BERT-ը կարող դրանք հարմարեցնել հերոսների մակարդակի վրա: ԲԵՌԹ-ը իսկապես լավ է աշխատում անգլերենում կեղծ անգլերեն հարմարեցման համար, բայց սա նույն չափով չի ընդհանրացվում բնական լեզուների համար: Այնուամենայնիվ, երկու լեզուների մոտիկությունը կարծես գործոն է: Անգլերենը ավելի շատ կապված է գերմանացիների հետ, քան հունացիների հետ, և սա արտացոլում է, թե ինչքան լավ է BER-ը հարմարեցնում դրանք: Անգլերեն գերմաներեն ավելի լավ է, քան անգլերեն՝ հուներեն: Մենք ուսումնասիրում ենք բազմաթիվ կառուցվածքներ և ցույց ենք տալիս, որ բնական լեզուների նմանությունները ցույց են տալիս ավելի թույլ հարաբերությունները, այնքան ավելի հեռու են երկու լեզուները:', 'af': "In die vorige werk, is dit vertoon dat BERT kan adequate kruistale setnings op die woord vlak aligneer. Hier ons ondersoek of BERT ook kan werk as 'n karaktervlak lyn. Die taal wat ondersoek is Engels, Fake Engels, Duits en Grieks. Ons wys dat die nader twee tale is, die beter BERT kan hulle aligneer op die karaktervlak. BERT werk regtig goed in Engels na Fake Engels alignment, maar hierdie doen nie generaliseer na natuurlike tale na dieselfde uitbreiding nie. Maar die proximity van twee tale lyk tog as 'n faktor. Engels is meer verwanter met Duits as met Grieks en dit is reflekteer in hoe goed BERT hulle align; Engels tot Duits is beter as Engels tot Grieks. Ons ondersoek veelvuldige opstelling en wys dat die gelykenis matrikse vir natuurlike tale swakker verhouding vertoon die verdere skiedende twee tale is.", 'am': 'ከቀድሞው ስራ BERT የቋንቋ ቃላትን በንግግር ደረጃዎች ላይ በኩል ሊተካክሉ ይችላል፡፡ ይሄን BERT በካራር-ደረጃ ምዕራብ እንዲሠራ እንፈልጋለን፡፡ የተመረጡት ቋንቋዎች እንግሊዘኛ፣ የፋይል እንግሊዘኛ፣ ጀርመን እና ግሪክ ናቸው፡፡ በሁለት ቋንቋዎች የሚቃረቡ መሆኑን እናሳያቸዋለን፣ የBERT ጥሩ በሥርዓት ደረጃዎች ላይ ማሳየት ይችላል፡፡ BERT በንግግሊዝኛ ለሳቅ እንግሊዘኛ ተቃውሞ በመልካም ይሠራል፤ ግን ይህ ለፍጥረቱ ቋንቋዎች በአንድ ልክ አይገልጽም፡፡ ነገር ግን የሁለት ቋንቋዎች መቃረቢያ እውነተኛ ነው ይመስላል፡፡ እንግሊዘኛ ከግሪክኛ ይልቅ ከጀርመን ጋር ተገናኝነት ነው፤ ይህም BERT እንዴት ያደላድፋቸዋል፡ English to German is better than English to Greek.  ብዙ ጥያቄዎችን እንፈትናለን እናሳያቸዋለን፣ ለፍጥረት ቋንቋዎች የተመሳሳይ ማተሚያዎች የሁለት ቋንቋዎች በጣም ደካሞች ግንኙነት እንዲያሳዩ እናስታውቃለን፡፡', 'bn': 'পূর্ববর্তী কাজের মধ্যে দেখা যাচ্ছে যে বিআরটি শব্দের স্তরে যথেষ্ট ভাষার বাক্য স্থাপন করতে পারে। Here we investigate whether BERT can also operate as a char-level aligner.  পরীক্ষা করা ভাষা ইংরেজি, ভুয়া ইংরেজি, জার্মান এবং গ্রীক। আমরা দেখাচ্ছি যে দুই ভাষার কাছাকাছি দুই ভাষা হচ্ছে, ভালো ভাষায় বিবেরেট তাদের অক্ষরের স্তরে সাজাতে প বেরেটি অবশ্যই ইংরেজি ভাষায় ভালো কাজ করে ফেক ইংরেজি সার্বভাষায় কাজ করে, কিন্তু এটা প্রাকৃতিক ভাষায় একই পর্যায়ে সা তবে দুই ভাষার কাছাকাছি মনে হচ্ছে একটা কারণ। ইংরেজি জার্মানের সাথে গ্রীকের চেয়েও বেশি সম্পর্ক এবং এটা প্রতিফলিত করা হচ্ছে বিবের্ট তাদের সাথে কত ভালোভাব জার্মানে ইংরেজী থেকে গ্রীক থেকে ভালো। আমরা বেশ কয়েকটি বিপর্যয় পরীক্ষা করি এবং দেখাচ্ছি যে প্রাকৃতিক ভাষার সমতুল্য ম্যাট্রিকেট দেখাচ্ছে যে দুটি ভাষার', 'bs': 'U prethodnom poslu, pokazalo je da BERT može odgovarajući poravnati krstojezičke rečenice na nivou riječi. Ovdje istražujemo da li BERT također može da radi kao poravnač nivoa karaktera. Ispitivani jezici su engleski, lažni engleski, nemački i grčki. Pokazujemo da su bliže dvije jezike, bolje ih BERT može poravnati na nivou karaktera. BERT zaista dobro radi na engleskom jeziku da laži englesko poravnanje, ali to se ne generalizuje na prirodne jezike u istoj mjeri. Ipak, blizina dva jezika čini se da je faktor. Engleski su više povezani s njemačkim nego s grčkim, a to se odražava kako ih BERT dobro poravna; Engleski na njemački je bolji nego engleski na grčki. Istražujemo više setova i pokazujemo da su matrice sličnosti prirodnim jezicima slabije odnose koje su dalje razdvojeni dvije jezike.', 'ca': "En treball anterior, s'ha demostrat que BERT pot alinejar adequadament les frases translingües al nivell de paraules. Aquí investigam si BERT també pot funcionar com a allinjador de nivell de caracteres. Les llengües examinades són anglès, anglès fals, alemany i grec. Mostrem que com més s'apropen dues llengües, millor els BERT poden alinejar a nivell de caràcter. BERT realment funciona bé en anglès per a falsificar l'alliniament anglès, però això no s'generalitza a les llengües naturals fins al mateix punt. No obstant això, la proximitat de dues llengües sembla ser un factor. L'anglès està més relacionat amb l'alemanya que amb el grec i això es reflexiona en com de bé els allinia BERT; L'anglès a l'alemany és millor que l'anglès a l'grec. Examinem múltiples configuracions i demostrem que les matrius de similitud per a les llengües naturals mostren relacions més dèbils com més distants són dues llengües.", 'cs': 'V předchozí práci bylo prokázáno, že BERT dokáže adekvátně sladit věty mezi jazyky na úrovni slova. Zde zkoumáme, zda BERT může fungovat také jako zarovnávač na úrovni znaků. Zkoušené jazyky jsou angličtina, falešná angličtina, němčina a řečtina. Ukazujeme, že čím blíže jsou dva jazyky, tím lépe je BERT dokáže zarovnat na úrovni znaků. BERT skutečně funguje dobře v angličtině na falešnou angličtinu zarovnání, ale to se nezobecňuje na přirozené jazyky ve stejné míře. Přesto se zdá, že blízkost dvou jazyků je faktorem. Angličtina je spíše příbuzná němčině než řečtině a to se odráží v tom, jak dobře je BERT zarovnává; Z angličtiny do němčiny je lepší než z angličtiny do řečtiny. Prozkoumáme několik nastavení a ukážeme, že podobnostní matice pro přírodní jazyky vykazují slabší vztahy, čím dále jsou dva jazyky od sebe vzdálenější.', 'et': 'Varasemates töödes on näidatud, et BERT suudab piisavalt keeleüleseid lauseid sõna tasandil ühtlustada. Siin uurime, kas BERT võib töötada ka söögitasemel joonlahendina. Kontrollitavad keeled on inglise, võltsingli, saksa ja kreeka keel. Näitame, et mida lähemal kaks keelt on, seda paremini suudab BERT neid märkide tasandil joondada. BERT töötab tõepoolest hästi inglise keeles valeinglise joondamiseks, kuid see ei üldista looduslikke keeli samas ulatuses. Siiski tundub kahe keele lähedus olevat tegur. Inglise keel on rohkem seotud saksa keelega kui kreeka keelega ning see kajastub selles, kui hästi BERT neid ühtlustab; Inglise kuni saksa on parem kui inglise kuni kreeka. Uurime mitmeid seadistusi ja näitame, et looduskeelte sarnasuse maatriksid näitavad nõrgemaid suhteid, mida kaugemal kaks keelt on.', 'fi': 'Aiemmissa tutkimuksissa on osoitettu, että BERT pystyy sovittamaan monikieliset lauseet riittävästi yhteen sanatasolla. Tässä selvitämme, voiko BERT toimia myös hiilitasauslaitteena. Tutkittavat kielet ovat englanti, väärennetty englanti, saksa ja kreikka. Osoitamme, että mitä lähempänä kaksi kieltä ovat, sitä paremmin BERT voi kohdistaa ne merkkitasolla. BERT toimii hyvin englanniksi Fake English -linjaukseen, mutta tämä ei yleisty luonnollisiin kieliin samassa määrin. Kahden kielen läheisyys vaikuttaa kuitenkin olevan tekijä. Englanti liittyy enemmän saksaan kuin kreikkaan, ja tämä näkyy siinä, miten hyvin BERT linjaa ne. Englanti saksaksi on parempi kuin Englanti kreikaksi. Tutkimme useita kokoonpanoja ja osoitamme, että luonnollisten kielten samankaltaisuusmatriisit osoittavat heikompia suhteita, mitä kauemmas toisistaan kaksi kieltä ovat.', 'az': "Əvvəlki işdə, BERT sözlərin səviyyəsində çoxlu dil cümlələrini müəyyən edə biləcəyini göstərildi. Beləliklə, BERT'nin cür seviyyəti tərəfindən istifadə edə biləcəyini təşkil edirik. İzahat edilən dillər İngilizdir, yalan İngilizdir, Alman və Yunanlardır. İki dilin daha yaxın olduğunu göstəririk ki, BERT onları karakter seviyesində düzəltə bilər. BERT İngilizce dilində çox yaxşı işlər edir İngilizce tərəfindən uyğunlaşdırmaq üçün, amma bu təbiətli dillərə eyni qədər təbiətli deyildir. Ancaq iki dilin yaxınlığı bir faktor kimi görünür. İngilizce dilimlə Yunanlıqdan daha çox əlaqədir və bu, BERT onları necə yaxşı tərəfləndirir. İngilizce dilində Almanca dilindən daha yaxşıdır. Biz çoxlu quruluşları incidirik və təbiətli dillərə bənzər matrikləri daha zəif ilişkiler göstərir.", 'jv': 'Nang barêng-barêng langkung rawuh, akeh wis rambarang nang saben BERT iso nggawe barang langgar banter nggambar barang. Punika kita panggunawa ing BERT iso nggawe ngupakan cara-stringke Sugeng-luwih sing kelas Inggris, marang Inggris, alaman karo Grik. Awak dhéwé ngomong nik banjuré durung sampeyan, BERT iso nggawe lan sampeyan cara sing luwih apik. BERT ugo ngerti apa ora marang Inggris kanggo alih nggawe Inggris, mangkat iki ora gegangalahan kanggo alih dumadhi sing apik. Nanging, mbok saiki, nggambar obah-obahan luwih saben karo ingkang. Inggris mengko karo alaman sing luwih dumadhi karo Grik lan iki sak olahan luwih apik sing BERT nggawe lan alam iki; Inggris karo alaman sing luwih karo Inggris kanggo kuwi Grik. Awak dhéwé éntukno akeh sampeyan karo akeh lan ngomong nik kabèh saben tanggal sing gak bener kanggo langgar sapa-bener iki.', 'sk': 'V prejšnjem delu je bilo dokazano, da lahko BERT ustrezno uskladi večjezične stavke na ravni besed. Tukaj raziskujemo, ali BERT lahko deluje tudi kot poravnalnik na ravni ogljika. Preučeni jeziki so angleščina, ponarejena angleščina, nemščina in grščina. Pokazujemo, da čim sta bližja dva jezika, bolje ju BERT lahko uskladi na ravni znakov. BERT dejansko dobro deluje v angleščini za lažno angleško usklajevanje, vendar to ne posplošuje na naravne jezike v enaki meri. Kljub temu se zdi, da je bližina dveh jezikov dejavnik. Angleščina je bolj povezana z nemščino kot z grščino, kar se odraža v tem, kako dobro jih BERT usklajuje; Angleščina v nemščino je boljša kot angleščina v grščino. Preučujemo več nastavitev in pokažemo, da matrike podobnosti za naravne jezike kažejo šibkejše odnose, čim bolj sta razdaljena dva jezika.', 'ha': 'An nuna shi cikin aikin da ya gabãta, BERT zai iya daidaita tsarin maganar-harsunan da ke cikin tsari. Bu nan, Munã tambaya ko BERT zai iya yi amfani da shi kamar mai salon-daraja. The languages examined are English, Fake English, German and Greek.  Muna nũna cewa mafi ƙaranci lugha biyu ne, mafi kyaun BERT zai iya daidaita su kan daraja. @ info: whatsthis A lokacin da, kamfatawa na harshen biyu na kasa wani matsayi. Ingiriya yana da mafi yawan abu zuwa Jamanci ko zuwa Garanci, kuma an yi wannan ana iya ƙayyade a kan yadda BERT ke daidaita su; @ item Spelling dictionary Kana jarraba wasu tsaro masu yawa kuma Muke nũna cewa misalin matrikai masu daidaita wa lugha masu natsuwa sun nuna masu rauni da danganta guda biyu.', 'bo': 'སྔོན་གྱི་ལས་ཀ་ནང་དུ། BERT་ཡིས་སྐད་ཡིག་གཟུགས་པའི་ཚིག་རྐད་ཀྱི་སྐོར་དང་མཐུན་སྒྲིག་འགོད་ཐུབ་པ་ཡིན་པས། Here we investigate whether BERT can also operate as a char-level aligner. སྐད་རིགས་འདི་ཞིབ་དཔྱད་ཡོད་པའི་སྐད་ཡིག་གཟུགས་དང་། ཨིན་ཇིའི་མིན་དང་། སྐད་ཡིག་གཟུགས། ང་ཚོས་སྐད་ཡིག BERT ། དངོས་ཡིག་འཕྲིན་ཡིག་གི་སྒྲིག་འགོད་ལ་རང་ཉིད་ཀྱི་སྐད་ཡིག ཡིན་ནའང་། སྐད་རིགས་གཉིས་ཀྱི་གཟུགས་འགྱུར་བའི་ཆ་རྐྱེན་ཞིག་ཡིན་པ་རེད། དབྱིན་ཡིག་དང་སྐད་ཡིག་དང་འབྲེལ་བའི་ཇར་མན་མིན་དང་ཅི་ཞིག་ཡིན་རྒྱུ་དང་། དབྱིན་ཡིག་ལས་སྐད་ཡིག་དང་དར་མིག་ལ་ཧ་ཅང་ཡིན། ང་ཚོས་གཞུང་ཚབ་མང་པོ་ཞིག་དཔྱད་བྱས་ནས་མཐུན་རྟགས་ཀྱི་སྐད་རིགས་ལ་མཐུན་པ་མཚུངས་ན། སྐད་རིགས་གཉིས་ཀྱི་དབར་གཅིག་', 'he': 'בעבודה הקודמת, הוכח כי BERT יכול לארגן מספיק משפטים בין שפתיים ברמה המילים. כאן אנחנו חוקרים אם BERT יכול גם לפעול כמאיין רמה סמויות. השפות הנבחנות הן אנגלית, אנגלית מזויפת, גרמנית ויונית. אנחנו מראים שככל שתי שפות קרובות יותר, כך BERT עדיף יכול ליישר אותם ברמה של האופים. BERT indeed works well in English to Fake English alignment, but this does not generalize to natural languages to the same extent.  למרות זאת, הקרבות של שתי שפות באמת נראית גורם. אנגלית קשורה יותר לגרמנית מאשר ליונית וזה משקף בכמה טוב BERT מציין אותם; אנגלית לגרמנית טובה יותר מאנגלית ליונית. We examine multiple setups and show that the similarity matrices for natural languages show weaker relations the further apart two languages are.'}
{'en': 'Two Heads are Better than One? Verification of Ensemble Effect in Neural Machine Translation', 'ar': 'اثنين من رؤساء هي أفضل من واحدة؟ التحقق من تأثير المجموعة في الترجمة الآلية العصبية', 'pt': 'Duas cabeças são melhores que uma? Verificação do efeito do conjunto na tradução automática neural', 'fr': "Deux têtes valent mieux qu'une\xa0? Vérification de l'effet d'ensemble dans la traduction automatique neuronale", 'es': '¿Dos cabezas son mejores que una? Verificación del efecto conjunto en la traducción automática neuronal', 'ja': '2つの頭は1つよりも優れていますか？神経機械翻訳におけるアンサンブル効果の検証', 'hi': 'एक से भले दो? तंत्रिका मशीन अनुवाद में पहनावा प्रभाव का सत्यापन', 'zh': '两个头比一个好么? 神经机器翻译中集成效应之验', 'ru': 'Две головы лучше, чем одна? Верификация эффекта ансамбля в нейронном машинном переводе', 'ga': 'An fearr dhá cheann na gceann? Fíorú Éifeacht Ensemble san Aistriú Meaisín Néarthach', 'hu': 'Két fej jobb, mint egy? Az együttes hatásának ellenőrzése a neurális gépi fordításban', 'el': 'Δύο κεφάλια είναι καλύτερα από ένα; Επαλήθευση της επίδρασης του συνόλου στη νευρωνική μηχανική μετάφραση', 'lt': 'Dvi galvos geresnės už vieną? Verification of Ensemble Effect in Neural Machine Translation', 'kk': 'Екі басы бірден жақсы ба? Нейрондық машинаның аудармасындағы шифрлау эффектін тексеру', 'ka': 'ეგვ დლაგთ ჟა ოჲ-ეჲბპთ ჲრ ვენა? Name', 'ms': 'Dua kepala lebih baik dari satu? Name', 'mk': 'Two Heads are Better than One?  Верификација на енсемблен ефект во превод на неврална машина', 'ml': 'രണ്ട് തല ഒന്നിനെക്കാള്\u200d നല്ലതാണോ? നെയുറല്\u200d മെഷീനിലെ സജ്ജീകരണത്തിന്റെ സാക്ഷ്യം', 'mt': 'Żewġ Kapijiet huma Aħjar minn Wieħed? Verifika tal-Effett Uniku fit-Traduzzjoni tal-Magna Newrali', 'it': "Due teste sono meglio di una? Verifica dell'effetto Ensemble nella traduzione automatica neurale", 'ro': 'Două capete sunt mai bune decât unul? Verificarea efectului ansamblului în traducerea automată neurală', 'pl': 'Dwie głowy są lepsze niż jedna? Weryfikacja efektu zespołu w neuronowym tłumaczeniu maszynowym', 'si': 'ඔළුව දෙකක් එකට වඩා හොඳින්ද? Name', 'so': 'Laba madax ayaa ka wanaagsan mid? Verification of Ensemable Effect in Neural machine Translation', 'no': 'To hovud er bedre enn éin? Verifisering av effekten som skal brukast i neuralmaskineoversettelsa', 'mn': 'Хоёр толгой нь нэгээс илүү сайн уу? Сэтгэл машины хөрөнгө дамжуулах эффектийн шалгалт', 'sv': 'Två huvuden är bättre än ett? Verifiering av ensembleeffekt vid neural maskinöversättning', 'ur': 'دو سر ایک سے بہتر ہیں؟ Neural Machine Translation', 'ta': 'இரண்டு தலைப்புகள் ஒன்றை விட சிறந்தது? Name', 'sr': 'Dva glava su bolja od jednog? Verifikacija učinka u neurološkom prevodu mašine', 'uz': 'Two Heads are Better than One?  Tafsilotlar roʻyxati', 'vi': 'Hai đầu còn tốt hơn một? Kiểm tra tác dụng an thần của cây tạo thần kinh', 'bg': 'Две глави са по-добри от една? Проверка на ефекта на ансамбъла в невралния машинен превод', 'da': 'To hoveder er bedre end et? Verificering af Ensemble Effect i Neural Machine Translation', 'hr': 'Dva glava su bolja od jednog? Verifikacija učinka proširenja u prevodu neuroloških strojeva', 'nl': 'Twee hoofden zijn beter dan één? Verificatie van Ensemble Effect in Neural Machine Translation', 'id': 'Dua kepala lebih baik dari satu? Verifikasi Efek Ensemble dalam Translation Mesin Neural', 'de': 'Zwei Köpfe sind besser als einer? Überprüfung des Ensembleeffekts in der neuronalen maschinellen Übersetzung', 'fa': 'دو سر بهتر از يک هستن؟ Verification of Ensemble Effect in Neural Machine Translation', 'tr': 'Iki baş Birden gowymy? Nural Makina Terjimesinde Ewez Etkiniň barlanmasynyň', 'af': 'Twee koppe is beter as een? Bevestiging van Ensemble Effek in Nural Masjien Vertaling', 'ko': '둘이 한 사람보다 낫다고요?신경 기계 번역 중 집적 효과 검증', 'sw': 'Viongo viwili ni bora kuliko moja? Tafsiri ya Mashine ya Kifaransa', 'hy': 'Երկու գլխարկն ավելի լավ է, քան մեկը: Նյարդային մեքենայի թարգմանման ընդհանուր ազդեցության ստուգելը', 'sq': 'Dy koka janë më të mira se një? Verifikimi i efektit të përbashkët në përkthimin e makinës nervore', 'am': 'ሁለት አናት ከአንዱ ይሻላሉን? መግለጫ', 'bn': 'দুই হেড একের চেয়ে ভালো? নিউরাল মেশিন অনুবাদের মধ্যে সার্ফিকেশন', 'az': 'ńįki baŇü Birind…ôn daha yaxŇüńĪdńĪr? N√∂ral Makin √áevirm…ôsind…ôki Ensemble Efektl…ôrin D…ôst…ôliyi', 'bs': 'Dva glava su bolja od jednog? Verifikacija učinka proširenja u neurološkom prevodu strojeva', 'ca': "Dos Caps són millors que un? Verifica d'efecte conjunt en la traducció de màquines neuronales", 'fi': 'Kaksi päätä on parempi kuin yksi? Ensemble-vaikutuksen verifiointi neurokonekäännöksessä', 'cs': 'Dvě hlavy jsou lepší než jedna? Ověření efektu souboru v neuronovém strojovém překladu', 'et': 'Kaks pead on paremad kui üks? Ensemble efekti kontrollimine neuroaalses masintõlkes', 'jv': 'Isi-iki luwih luwih apik sing sembaye Sing ? checkbox', 'he': 'שני ראשים טובים יותר מאחד? Verification of Ensemble Effect in Neural Machine Translation', 'bo': 'མགོ་ཡིག་གཉིས་གཅིག་ལས་སྐྱོ་བ་ཡིན་ནམ། Neural Machine Translation ནང་ལ་ཕན་ཚུན་བརྗོད་ནུས་ཡོད་པའི་ནུས་ཚོད་ཀྱི་ཞིབ་དཔྱད་བྱེད་པ', 'ha': 'Two Heads are Better than One?  @ action', 'sk': 'Dve glavi sta boljši kot ena? Preverjanje učinka ansambla v nevralnem strojnem prevajanju'}
{'en': 'In the field of natural language processing, ensembles are broadly known to be effective in improving performance. This paper analyzes how ensemble of neural machine translation (NMT) models affect performance improvement by designing various experimental setups (i.e., intra-, inter-ensemble, and non-convergence ensemble). To an in-depth examination, we analyze each ensemble method with respect to several aspects such as different attention models and vocab strategies. Experimental results show that ensembling is not always resulting in performance increases and give noteworthy negative findings.', 'es': 'En el campo del procesamiento del lenguaje natural, se sabe que los conjuntos son efectivos para mejorar el rendimiento. Este artículo analiza cómo el conjunto de modelos de traducción automática neuronal (NMT) afecta la mejora del rendimiento mediante el diseño de varias configuraciones experimentales (es decir, conjuntos intra, interconjuntos y no convergentes). Para un examen en profundidad, analizamos cada método de conjunto con respecto a varios aspectos, como diferentes modelos de atención y estrategias de vocabulario. Los resultados experimentales muestran que el ensamblaje no siempre resulta en un aumento del rendimiento y dan resultados negativos notables.', 'fr': "Dans le domaine du traitement du langage naturel, les ensembles sont largement reconnus pour leur efficacité dans l'amélioration des performances. Cet article analyse comment un ensemble de modèles de traduction automatique neuronale (NMT) affecte l'amélioration des performances en concevant diverses configurations expérimentales (c.-à-d. ensembles intra-, inter-ensembles et sans convergence). Pour un examen approfondi, nous analysons chaque méthode d'ensemble en fonction de plusieurs aspects tels que différents modèles d'attention et stratégies de vocabulaire. Les résultats expérimentaux montrent que l'assemblage n'entraîne pas toujours une augmentation des performances et donne des résultats négatifs notables.", 'ar': 'في مجال معالجة اللغة الطبيعية ، من المعروف على نطاق واسع أن الفرق الموسيقية فعالة في تحسين الأداء. تحلل هذه الورقة كيف تؤثر مجموعة نماذج الترجمة الآلية العصبية (NMT) على تحسين الأداء من خلال تصميم إعدادات تجريبية مختلفة (على سبيل المثال ، مجموعة داخل ، بين المجموعات ، وغير متقاربة). لإجراء فحص متعمق ، نقوم بتحليل كل طريقة مجموعة فيما يتعلق بالعديد من الجوانب مثل نماذج الانتباه المختلفة واستراتيجيات المفردات. تظهر النتائج التجريبية أن التجميع لا يؤدي دائمًا إلى زيادة الأداء وإعطاء نتائج سلبية جديرة بالملاحظة.', 'pt': 'No campo do processamento de linguagem natural, os conjuntos são amplamente conhecidos por serem eficazes na melhoria do desempenho. Este artigo analisa como o conjunto de modelos de tradução automática neural (NMT) afeta a melhoria do desempenho projetando várias configurações experimentais (ou seja, conjunto intra, interconvergência e não-convergência). Para um exame aprofundado, analisamos cada método de ensemble em relação a vários aspectos, como diferentes modelos de atenção e estratégias de vocabulário. Os resultados experimentais mostram que o ensembling nem sempre resulta em aumentos de desempenho e fornecem resultados negativos notáveis.', 'zh': '在自然语言理域,人普遍认为融合,可以有益。 本文设诸实验(内集成间非敛合)以析神经机器翻译(NMT)形之合,何以易性? 深入之验,论融合之数,各如其词汇。 实验结果表明,融合非常致性,并与值得注意负面见。', 'ja': '自然言語処理の分野では、アンサンブルは、パフォーマンスの向上に効果的であることが広く知られている。神経機械翻訳（ NMT ）モデルのアンサンブルが、様々な実験的セットアップ（すなわち、イントラアンサンブル、インターアンサンブル、およびノンコンバージェンスアンサンブル）を設計することによって、パフォーマンス向上にどのように影響するかを分析した。詳細に検討するために、さまざまな注目モデルやボキャブ戦略などのいくつかの側面に関して、各アンサンブルメソッドを分析します。実験結果は、アンサンブルが必ずしもパフォーマンスの向上をもたらすとは限らず、注目すべき否定的な所見をもたらすことを示している。', 'hi': 'प्राकृतिक भाषा प्रसंस्करण के क्षेत्र में, ensembles मोटे तौर पर प्रदर्शन में सुधार में प्रभावी होने के लिए जाना जाता है। यह पेपर विश्लेषण करता है कि तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल का पहनावा विभिन्न प्रयोगात्मक सेटअप (यानी, इंट्रा-, इंटर-एनसेंबल और गैर-अभिसरण पहनावा) को डिजाइन करके प्रदर्शन सुधार को कैसे प्रभावित करता है। एक गहन परीक्षा के लिए, हम विभिन्न ध्यान मॉडल और vocab रणनीतियों जैसे कई पहलुओं के संबंध में प्रत्येक पहनावा विधि का विश्लेषण करते हैं। प्रयोगात्मक परिणामों से पता चलता है कि ensembling हमेशा प्रदर्शन में वृद्धि और उल्लेखनीय नकारात्मक निष्कर्ष देने में परिणाम नहीं है.', 'ru': 'В области обработки естественного языка общеизвестно, что ансамбли эффективны в улучшении производительности. В этой статье анализируется, как ансамбль моделей нейронного машинного перевода (НМП) влияет на улучшение производительности, разрабатывая различные экспериментальные установки (т.е. внутри-, межкомпонентный и неконвергенционный ансамбль). Для углубленного изучения мы анализируем каждый ансамблевый метод в отношении нескольких аспектов, таких как различные модели внимания и стратегии Vocab. Экспериментальные результаты показывают, что ансамблирование не всегда приводит к повышению производительности и дает заслуживающие внимания отрицательные результаты.', 'ga': 'I réimse na próiseála teanga nádúrtha, is eol go ginearálta go bhfuil ensembles éifeachtach chun feidhmíocht a fheabhsú. Déanann an páipéar seo anailís ar an gcaoi a mbíonn tionchar ag samhlacha ensemble de néaraistriúchán meaisín (NMT) ar fheabhsú feidhmíochta trí shocruithe turgnamhacha éagsúla a dhearadh (i.e., ensemble laistigh, idir-ensemble, agus neamh-chóineasaithe). Le scrúdú domhain a dhéanamh, déanaimid anailís ar gach modh ensemble maidir le gnéithe éagsúla ar nós múnlaí airde difriúla agus straitéisí foclóra. Léiríonn torthaí turgnamhacha nach mbíonn méaduithe feidhmíochta i gcónaí mar thoradh ar chomhshamhlú agus tugann sé torthaí diúltacha suntasacha.', 'hu': 'A természetes nyelvfeldolgozás területén az együttesek széles körben ismertek, hogy hatékonyan javítják a teljesítményt. Ez a tanulmány azt vizsgálja, hogy a neurális gépi fordítás (NMT) modellek együttese hogyan befolyásolja a teljesítmény javítását különböző kísérleti beállítások (azaz intra-, inter-ensemble és non-konvergencia együttesek) tervezésével. Mélyreható vizsgálatra minden együttes módszert elemezünk több szempontból, mint például a különböző figyelemmodellek és szókincsstratégiák. Kísérleti eredmények azt mutatják, hogy az összeállítás nem mindig eredményez teljesítménynövekedést, és figyelemre méltó negatív eredményeket ad.', 'ka': 'თავისუფალური ენერგიის პროცესის პანელში, სენემბელი უფრო უფრო ეფექტიურია პროცექტის უფრო მეტადებაში. ამ დოკუმენტის ანალიზაცია, როგორ ნეიროლური მანქანის გაგრძელება (NMT) მოდელების შესახებ გამოსახულება გამოსახულებას, განსხვავებული ექსპერიმენტიური შეგრძელებების განაზღვრებით (მაგალითად, ინტე ჩვენ ყველაფერი სურათების შესახებ განსხვავებული მოდელები და საუკეთესი სტრატეგიაზე ანალიზებთ. ექსპერიმენტიური წარმოდგენება ჩვენებს, რომ ანსტემბულება არ ყოველთვის გამოიყენება პროცემენტის გაზრდილებაში და მივიღებთ უფრო უფრო უ', 'el': 'Στον τομέα της επεξεργασίας φυσικής γλώσσας, τα σύνολα είναι ευρέως γνωστά ότι είναι αποτελεσματικά στη βελτίωση της απόδοσης. Η παρούσα εργασία αναλύει τον τρόπο με τον οποίο το σύνολο μοντέλων νευρωνικής μηχανικής μετάφρασης (NMT) επηρεάζει τη βελτίωση της απόδοσης σχεδιάζοντας διάφορες πειραματικές ρυθμίσεις (δηλαδή, σύνολο εντός, μεταξύ συνόλου και μη σύγκλισης). Σε μια διεξοδική εξέταση, αναλύουμε κάθε μέθοδο συνόλου σε σχέση με διάφορες πτυχές, όπως διαφορετικά μοντέλα προσοχής και στρατηγικές λεξιλογίου. Τα πειραματικά αποτελέσματα δείχνουν ότι η σύνθεση δεν οδηγεί πάντα σε αυξήσεις απόδοσης και δίνουν αξιοσημείωτα αρνητικά ευρήματα.', 'lt': 'In the field of natural language processing, ensembles are broadly known to be effective in improving performance.  This paper analyzes how ensemble of neural machine translation (NMT) models affect performance improvement by designing various experimental setups (i.e., intra-, inter-ensemble, and non-convergence ensemble).  To an in-depth examination, we analyze each ensemble method with respect to several aspects such as different attention models and vocab strategies.  Eksperimentiniai rezultatai rodo, kad susivienijimas ne visada lemia veiklos rezultatų padidėjimą ir rodo pastebimus neigiamus rezultatus.', 'ms': 'Dalam medan pemprosesan bahasa alami, ensembles secara luas diketahui sebagai berkesan dalam meningkatkan prestasi. Kertas ini menganalisis bagaimana kumpulan model terjemahan mesin saraf (NMT) mempengaruhi peningkatan prestasi dengan merancang pelbagai tetapan percubaan (iaitu, kumpulan intra-, inter- ensemble, dan bukan-konvergence). Untuk pemeriksaan mendalam, kami menganalisis setiap kaedah ensemble terhadap beberapa aspek seperti model perhatian yang berbeza dan strategi vokal. Experimental results show that ensembling is not always resulting in performance increases and give noteworthy negative findings.', 'it': "Nel campo dell'elaborazione del linguaggio naturale, gli ensemble sono ampiamente noti per essere efficaci nel migliorare le prestazioni. Questo articolo analizza come l'insieme di modelli di traduzione automatica neurale (NMT) influiscono sul miglioramento delle prestazioni progettando varie configurazioni sperimentali (ad esempio, insimble intra-, inter-ensemble e non-convergenza). Ad un esame approfondito, analizziamo ogni metodo ensemble rispetto a diversi aspetti come diversi modelli di attenzione e strategie vocaboliche. I risultati sperimentali mostrano che l'assemblaggio non sempre comporta aumenti delle prestazioni e danno risultati negativi notevoli.", 'kk': 'Табиғи тілдерді өңдеу өрісінде енсембрлер әсер ету үшін көпшілікті болып табылады. Бұл қағаз невралдық компьютердің аудармаларының (NMT) моделдерінің қалай жақсарту үлгілерін анықтайды, әртүрлі тәжірибелі параметрлерді құру арқылы (т. е. интера -, интерансemble, және конвергенс емес енсемблі) жақ Түндікті тексеру үшін, біз әрбір әрбір әдістерді бірнеше аспектерге қатынау үлгілері мен сөздер стратегиясы секілді бірнеше аспектерді анализирақ. Эксперименталдық нәтижелері дегенді көрсетеді, олар әрқашанда әрқашанда істеу үшін көтерілмейді және қарапайым тапсырмаларды көрсетеді.', 'mk': 'Во областа на природното обработување јазик, ансемблите се познати како ефикасни во подобрувањето на резултатите. Оваа хартија анализира како ансемблот на невропски машински превод (НМТ) влијае на подобрувањето на резултатите со дизајнирање на различни експериментални поставувања (т.е., интра-, интерансембл и неконвергенциски ансембл). За длабоко испитување, го анализираме секој ансембл метод во однос на неколку аспекти како што се различни модели на внимание и стратегии на гласот. Експерименталните резултати покажуваат дека собирањето не секогаш резултира со зголемување на резултатите и дава значителни негативни откритија.', 'no': 'I feltet for naturspråkshandtering er det vanlege å vera effektivt for å forbetra utviklingar. Denne papiret analyserer korleis ensemblen av neuralmaskinsomsetjingsmodular (NMT) påvirkar forbetringa av utviklingar ved å designa ulike eksperimentale oppsett (t.d. intra-, inter-ensemble og ikkje-konvergens ensemble). For ein undersøking av dybde, analyserer vi kvar ensemble metode med respekt til fleire aspektar, som ulike oppmerksmodeller og ordstrategiar. Eksperimentale resultat viser at ensembering ikkje alltid fører til å auka utviklingar og gi noteworthy negativ oppdagingar.', 'ml': 'സ്വാഭാവികമായ ഭാഷയുടെ പ്രക്രിയശ്ചിത്രത്തില്\u200d, പ്രവര്\u200dത്തനങ്ങള്\u200d മുന്\u200dകൂട്ടുന്നതില്\u200d പ്രവർത്തികമാക്കുന്നത ഈ പത്രത്തില്\u200d ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷകളുടെ (NMT) മോഡലുകള്\u200d എങ്ങനെയാണ് പ്രവര്\u200dത്തനത്തിന്റെ മെച്ചപ്പെള്\u200d മെച്ചപ്പെടുത്തുന്നതെന്ന് അന്വേഷിക്കുന്നത് എന്ന്  ആഴത്തില്\u200d പരീക്ഷിക്കുന്നതിന് വ്യത്യസ്തമായ ശ്രദ്ധ മോഡലുകളും വോട്ടാക്ക് പ്രായോഗ്രിയുമുള്ള പല കാര്യങ്ങളെക്കുറിച്ചും  പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് എപ്പോഴും പ്രവര്\u200dത്തനങ്ങള്\u200d കൂടുതല്\u200d വര്\u200dദ്ധിപ്പിക്കുന്നില്ല എന', 'mt': 'Fil-qasam tal-ipproċessar tal-lingwi naturali, l-ensembles huma ġeneralment magħrufa li huma effettivi fit-titjib tal-prestazzjoni. This paper analyzes how ensemble of neural machine translation (NMT) models affect performance improvement by designing various experimental setups (i.e., intra-, inter-ensemble, and non-convergence ensemble).  Għal eżami fil-fond, nagħmlu analiżi ta’ kull metodu ta’ ensemble fir-rigward ta’ diversi aspetti bħal mudelli differenti ta’ attenzjoni u strateġiji vokabbli. Ir-riżultati esperimentali juru li l-ġabra mhux dejjem tirriżulta f’żidiet fil-prestazzjoni u tagħti sejbiet negattivi notevoli.', 'ro': 'În domeniul procesării limbajului natural, ansamblurile sunt cunoscute ca fiind eficiente în îmbunătățirea performanței. Această lucrare analizează modul în care ansamblul modelelor neuronale de traducere automată (NMT) afectează îmbunătățirea performanței prin proiectarea diferitelor setări experimentale (adică ansamblul intra-, inter-ansamblu și non-convergență). La o examinare aprofundată, analizăm fiecare metodă de ansamblu în raport cu mai multe aspecte, cum ar fi diferite modele de atenție și strategii vocabulare. Rezultatele experimentale arată că ansamblul nu duce întotdeauna la creșterea performanței și oferă constatări negative remarcabile.', 'mn': 'Байгалийн хэл үйлдвэрлэлийн талбар дээр ажиллагааг сайжруулахад эффективнэй байдаг. Энэ цаас нь мэдрэлийн машины хөгжлийн загварын хэрхэн нөлөөлдөгийг шинжилдэг нь олон туршилтын байгууллагуудыг зохион байгуулж (т.е. интро-, интерэнзембл, мөн конвергенс биш эмзэг). Гүн гүнзгий шалгалтын тулд бид бүгдийг анхаарлын загвар болон үгийн стратеги зэрэг олон асуудлуудын тухай шинжилгээ хийдэг. Үүний туршилтын үр дүнг нь үргэлж үйл ажиллагааны нэмэгдүүлэлт болон үнэ цэнэтэй сөрөг ололтууд өгч чадахгүй гэдгийг харуулдаг.', 'sr': 'U oblasti obrade prirodnog jezika, ensemble se široko poznaju da su efikasne u poboljšanju izvršnosti. Ovaj papir analizira kako obezbeđenje modela neuronskog prevoda (NMT) utječe na poboljšanje učinka dizajniranjem različitih eksperimentalnih setova (tj. intra-, međuensemble i ne konvergencije ensemble). Za duboko ispitivanje, analiziramo svaku metodu koja se uključuje u pogledu nekoliko aspekta poput različitih modela pažnje i zvaničnih strategija. Eksperimentalni rezultati pokazuju da ensembliranje ne uvijek uzrokuje povećanje učinka i pružanje značajnih negativnih nalaza.', 'si': 'ස්වාභාවික භාෂාව ප්\u200dරක්\u200dරියාසයේ ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් හොයාගන්න පුළුවන් කියලා  මේ පත්තු විශ්ලේෂණය කරනවා කොහොමද ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විදිහට පරීක්ෂණය කරනවා (ඉතින්, intra-, inter-ensEmble, සහ non-konvergenece ensEmb අපි හැම ප්\u200dරමාණයක්ම විශ්ලේෂණය කරනවා වගේම වෙනස් අවධානයක් වගේම අවධානයක් වගේම අවධානයක් වගේම වෙනස් ප්\u200dරමාණ පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ සැමවෙලාවම ප්\u200dරතිචාරයක් විශාලනය කරන්නේ නැහැ කියලා,', 'so': 'In the field of natural language processing, ensembles are broadly known to be effective in improving performance.  Kanu wuxuu sawiraa sida qoraalka tarjumaadda neurada (NMT) u saameyn ku yeelashada horumarinta muuqashada (tusaale ahaan marka loo qoro qalabka baaritaanka kala duduwan (intra-, inter-ensemble, and non-convert ensemble). Baaritaanka moolka dheer baaritaanka, waxaynu ku baaraynaa qaab kasta oo ka mid ah qaab kala duduwan tusaale ahaan tusaale ahaan qaababka caafimaadka iyo qoraalka afka. Imtixaanka waxaa ka muuqda in booqashada looma sameyn karo mar walba kordhiska tababarka iyo sidoo kale uu helo helitaanka liita ah.', 'ur': 'طبیعی زبان پردازش کی کھیتی میں، انڈیسمبل کو عملکرد کے ساتھ اثر سے پہچان لیا جاتا ہے. This paper analyzes how ensemble of neural machine translation (NMT) models affect performance improvement by designing various experimental setups (i.e. intra-, inter-ensemble, and non-convergence ensemble). ایک عمیق تحقیقات کے لئے ہم ہر طریقے کا تحقیق کریں گے جس طرح مختلف توجه نمونڈل اور آواز استراتژی کے بارے میں۔ Experimental results show that ensembling is not always resulting in performance increases and give noteworthy negative findings.', 'pl': 'W dziedzinie przetwarzania języka naturalnego zespoły są powszechnie znane jako skuteczne w poprawie wydajności. Niniejszy artykuł analizuje, w jaki sposób zespół modeli neuronowego tłumaczenia maszynowego (NMT) wpływa na poprawę wydajności poprzez projektowanie różnych konfiguracji eksperymentalnych (tj. zespołu wewnątrz-, między zespołem i niekonwergencją). Do dogłębnego badania analizujemy każdą metodę zespołu pod kątem kilku aspektów, takich jak różne modele uwagi i strategie słownicze. Wyniki eksperymentalne pokazują, że zestawienie nie zawsze prowadzi do wzrostu wydajności i daje godne uwagi negatywne ustalenia.', 'sv': 'Inom området naturlig språkbehandling är ensembler allmänt kända för att vara effektiva för att förbättra prestanda. Denna uppsats analyserar hur ensemble av neurala maskinöversättningsmodeller (NMT) påverkar prestandaförbättring genom att utforma olika experimentella setups (dvs. intra-, inter-ensemble och non-konvergensensensensembel). Till en fördjupad undersökning analyserar vi varje ensemblemetod med hänsyn till flera aspekter såsom olika uppmärksamhetsmodeller och vokabstrategier. Experimentella resultat visar att ensemblering inte alltid leder till prestandaökningar och ger anmärkningsvärda negativa resultat.', 'ta': 'இயற்கையான மொழி செயல்பாட்டின் புலத்தில், முன்னேற்றத்தை மேம்படுத்துவதற்கு முன்னேற்றும் பொருள்கள் விர இந்த தாள் எவ்வாறு புதிய கணினி மொழிபெயர்ப்புகள் (NMT) மாதிரிகள் செயல்பாட்டின் மேம்படுத்தலை வடிவமைப்பதற்காக பாதிக்கும் (அதாவது, உள்ளமைப்பு, இடைவெளியில் உள்ள மா ஆழமான பரிசோதனை சோதனையின் முடிவுகள் எப்போதும் செயல்பாடு அதிகரிக்க முடியாது மற்றும் குறிப்பிட்ட எதிர்மம் காட்டும்.', 'uz': "Natijalik tilni boshqarish maydonida, odamlarni bajarishni bajarishga juda foydalanishi mumkin. Bu qogʻoz neyron tarjima (NMT) modellari qanday nazar tarjima qilishini aniqlaydi va har xil tajriba moslamalarni yaratish orqali bajarish imkoniyatini bajaradi (masalan, intra-, inter-ensemble va ikkinchi tarjima qilish imkoniyatini yaratish mumkin). Ko'pchilikni tekshirish uchun, biz har bir foydalanuvchi usulni o'rganimiz, har xil qismlar modellari va vosita strategiyasi bilan bir necha qismlarga o'anadi. Name", 'vi': 'Trong lĩnh vực xử lý ngôn ngữ tự nhiên, dàn hợp đồng được biết đến có hiệu quả trong việc cải thiện hiệu quả. Bài này phân tích cách kết hợp các mô hình dịch chuyển máy thần kinh (NMB) ảnh hưởng tới việc cải thiện lợi nhuận bằng cách thiết kế các cài đặt thử nghiệm khác nhau (như là kết hợp nội bộ, liên kết, và kết hợp nhau). Để kiểm tra kỹ lưỡng, chúng tôi phân tích các phương pháp kết hợp với nhiều khía cạnh như các mô hình chú ý khác nhau và các phương pháp hợp giọng. Kết quả thí nghiệm cho thấy kết hợp không phải lúc nào cũng dẫn tới hiệu suất tăng và đem lại kết quả tiêu cực đáng chú ý.', 'bg': 'В областта на обработката на естествения език ансамблите са широко известни като ефективни за подобряване на производителността. В настоящата статия се анализира как ансамбъл от модели на невронен машинен превод (НМТ) влияе върху подобряването на производителността чрез проектиране на различни експериментални настройки (т.е. интра-, междуансамбъл и неконвергенция ансамбъл). За задълбочен преглед анализираме всеки ансамбъл метод по отношение на няколко аспекта като различни модели на внимание и стратегии за речник. Експерименталните резултати показват, че ансамблирането не винаги води до повишаване на производителността и дава забележителни отрицателни открития.', 'nl': 'Op het gebied van natuurlijke taalverwerking staat algemeen bekend dat ensembles effectief zijn in het verbeteren van prestaties. Dit artikel analyseert hoe ensemble of neural machine translation (NMT) modellen prestatieverbetering beïnvloeden door verschillende experimentele opstellingen te ontwerpen (d.w.z. intra-, inter-ensemble en non-convergentie ensemble). Voor een diepgaand onderzoek analyseren we elke ensemblemethode met betrekking tot verschillende aspecten, zoals verschillende aandachtsmodellen en vocabstrategieën. Experimentele resultaten tonen aan dat ensembling niet altijd resulteert in prestatieverbeteringen en geven opmerkelijke negatieve bevindingen.', 'de': 'Im Bereich der Verarbeitung natürlicher Sprache sind Ensembles allgemein dafür bekannt, ihre Leistung zu verbessern. In diesem Beitrag wird untersucht, wie sich Ensemble neuronaler maschineller Translation (NMT)-Modelle auf die Leistungsverbesserung auswirken, indem verschiedene experimentelle Setups entworfen werden (d.h. Intra-, Inter-Ensemble- und Nicht-Konvergenz-Ensemble). Zu einer eingehenden Untersuchung analysieren wir jede Ensemblemethode in Bezug auf verschiedene Aspekte wie Aufmerksamkeitsmodelle und Vokabelstrategien. Experimentelle Ergebnisse zeigen, dass Ensemblebildung nicht immer zu Leistungssteigerungen führt und zu bemerkenswerten negativen Ergebnissen führt.', 'ko': '자연 언어 처리 분야에서 사람들은 집적이 성능을 효과적으로 향상시킬 수 있다고 보편적으로 생각한다.본고는 서로 다른 실험 장치(즉 내부 집적, 내부 집적과 비수렴 집적)를 설계하여 신경기계번역(NMT) 모델 집적이 성능 개선에 미친 영향을 분석했다.깊이 있게 연구하기 위해 우리는 서로 다른 주의 모델과 발성 전략 등 몇 가지 측면에서 각 집적 방법을 분석했다.실험 결과 엔셀링이 성능을 늘 높일 수 있는 것은 아니며 주의할 만한 부정적인 결과를 내놓았다.', 'hr': 'U području prirodnog obradivanja jezika, ensemble su široko poznati učinkoviti u poboljšanju učinkovitosti. Ovaj papir analizira kako ensemble modela neuronskog prevoda (NMT) utječe na poboljšanje učinka dizajniranjem različitih eksperimentalnih setova (tj. intra-, međuensemble i ne konvergencije ensemble). Za duboko ispitivanje, analiziramo svaku metodu koja se uključuje u pogledu nekoliko aspekta poput različitih modela pažnje i glasnih strategija. Eksperimentalni rezultati pokazuju da ensembliranje ne uvijek uzrokuje povećanje učinka i pružanje značajnih negativnih nalaza.', 'da': 'Inden for naturlig sprogbehandling er ensembler bredt kendt for at være effektive til at forbedre ydeevnen. Denne artikel analyserer, hvordan ensemble af neurale maskinoversættelsesmodeller (NMT) påvirker performance forbedring ved at designe forskellige eksperimentelle opsætninger (dvs. intra-, inter-ensemble og non-konvergens ensemble). Til en dybdegående undersøgelse analyserer vi hver ensemble metode med hensyn til flere aspekter såsom forskellige opmærksomhedsmodeller og vokabstrategier. Eksperimentelle resultater viser, at sammensætning ikke altid resulterer i ydelsesforøgelser og giver bemærkelsesværdige negative resultater.', 'fa': 'در زمینه پرداخت زبان طبیعی، نشانه\u200cها به طور کلی معلوم می\u200cشوند که در improving performance است. این کاغذ تحلیل می\u200cکند که چگونه نمونه\u200cهای ترجمه\u200cهای ماشین عصبی (NMT) با طراحی تنظیم\u200cهای آزمایشی مختلف تحلیل می\u200cکند. برای یک امتحان عمیق، ما هر روش تغییر\u200cگیری را با نسبت به چند نقطه\u200cای مثل مدل\u200cهای متفاوت توجه و استراتژی\u200cهای صوتی تحلیل می\u200cکنیم. نتیجه\u200cهای تجربه نشان می\u200cدهد که تحریک همیشه به افزایش عملکرد نتیجه نمی\u200cیابد و نتیجه\u200cهای منفی ارزش می\u200cدهد.', 'id': 'Dalam bidang proses bahasa alami, ensembles secara umum dikenal sebagai efektif dalam meningkatkan prestasi. Kertas ini menganalisis bagaimana ensemble dari model terjemahan mesin saraf (NMT) mempengaruhi peningkatan prestasi dengan merancang berbagai setup eksperimental (i.e., ensemble intra-, inter-ensemble, dan non-convergence). To an in-depth examination, we analyze each ensemble method with respect to several aspects such as different attention models and vocab strategies.  Experimental results show that ensembling is not always resulting in performance increases and give noteworthy negative findings.', 'sw': 'Katika eneo la utaratibu wa lugha asili, vifaa vinajulikana kuwa na ufanisi katika kuboresha utendaji. Kanisa hili linachambua jinsi utafsiri wa mashine ya neural i (NMT) unavyoathiri maboresho ya utendaji kwa kutengeneza vituo mbalimbali vya majaribio (yaani, intra-, vifaa vya ndani, na vifaa vinavyobadilika). Kwa uchunguzi wa kina, tunachambua kila njia ya utambuzi kwa kuhusiana na mambo kadhaa kama vile mifano tofauti ya maoni na mikakati ya sauti. Matokeo ya majaribio yanaonyesha kuwa upepo huo hausababisha kuongezeka kwa utendaji na kutoa matokeo mabaya.', 'tr': 'Dogaty dil işleýän sahypalarda, eserler täzeliklerini geliştirmek üçin täsirli bolup bilýärler. Bu kagyz näyral maşynyň terjimesiniň (NMT) nusgalarynyň nähili tanyşlaryny tanyşdyrylyp tanyşdyrylygyny çykarýar (myseläm, intra-, inter-ensemble we netije-konvergence ensemble) düzenleyerek tanyşdyrylygyny çykarýar. Derňlikli bir synagda, her biri üns nusgasyna we sesli stratejiýana sereden ähli aspektlere görä çözýäris. Testeniýaly netijeler görkezýär, taýýarlamak hemişe performansyň azalmagyna netijesi ýok bolmaýar we deň-deňli negatif tapylyklary berer.', 'sq': 'Në fushën e përpunimit natyror të gjuhës, ensemblet janë të njohur gjerësisht se janë efektive në përmirësimin e performancës. Ky dokument analizon se si kompleti i modeleve të përkthimit të makinave nervore (NMT) ndikon në përmirësimin e performancës duke dizajnuar struktura të ndryshme eksperimentale (pra, kompleti brenda, ndër-kompleti dhe jo-konvergencë). Për një ekzamin të thellë, ne analizojmë çdo metodë ensemble lidhur me disa aspekte të tilla si modelet e ndryshme të vëmendjes dhe strategjitë e zërit. Rezultatet eksperimentale tregojnë se mbledhja nuk rezulton gjithmonë në rritje të performancës dhe jep gjetje të rëndësishme negative.', 'af': "In die veld van natuurlike taal-verwerking, is ensemble breed bekend om effektief te wees in die verbetering van prestasie. Hierdie papier analyseer hoe ensemble van neural e masjien vertaling (NMT) modele beïnvloor effektiviteit verbetering deur verskeie eksperimentale opstelling te ontwerp (bv. intra-, inter-ensemble en non-convergence ensemble). Na 'n in-diepte eksaminasie analiseer ons elke ensembleem metode met respek na verskeie aspekte soos verskillende aandag modele en woomste strategies. Eksperimentale resultate wys dat inkombring nie altyd resultaat in prestasie vermeerder en gee notaverdige negatiewe vindings nie.", 'am': 'በፍጥረተ ቋንቋ ማቀናቀል እርሻ፣ የድምፅ አካባቢዎች በጥቅም ለማድረግ የሚታወቁ ናቸው፡፡ ይህ ፕሮግራም የነዌብ መሣሪያን ትርጉም (NMT) ሞዴላዎች በተለያዩ የፈተና ጥናት ማቀናቀል እንዴት እንደሚያስጨምር ያሳያል፡፡ ወደ ጥልቅ ምርመራ፣ የሁሉንም ዓይነቶች በተለያዩ የጥያቄ ምሳሌዎች እና የድምፅ ስርዓት በተለያዩ ጉዳዮች ላይ እናስተምር፡፡ ፈተና ውጤቶች ሁልጊዜ የድምፅ ውጤት ማድረግ እንዳይደረግ እና የተጠቃሚ የnegative ፍለጎቶችን እንዲሰጥ ያሳያል፡፡', 'hy': 'Բնական լեզուների վերլուծության ոլորտում, համակարգերը լայնորեն հայտնի են որպես արդյունավետ բարելավելու համար: Այս հոդվածը վերլուծում է, թե ինչպես նյարդային մեքենայի թարգմանման (NMT) մոդելների համակարգը ազդում է արդյունավետության բարելավման վրա, ստեղծելով տարբեր փորձարկվող կառուցվածքներ (այսինքն, ինտերննզեմբերի, ինտերննզեմբ Մենք խորապես ուսումնասիրելու համար վերլուծում ենք յուրաքանչյուր համակարգչային մեթոդը հաշվի առնելով մի քանի ասպեկտներ, ինչպիսիք են ուշադրության տարբեր մոդելները և ձայնային ռազմավարությունները: Փորձարկվող արդյունքները ցույց են տալիս, որ համախմբումը միշտ չի հանգեցնում արդյունքների աճի և նշանակալի բացասական արդյունքներ է տալիս:', 'az': 'Təbiətli dil işləməsi sahəsində, ensembli işləmələri yaxşılaşdırmaq üçün çox etkilidir. Bu kağıt nöral maşın çevirilməsinin (NMT) modellerinin müxtəlif təcrübə qurğularını tasarlayaraq müxtəlif təcrübə qurğularını necə təsir edir? Derin bir sınamaya görə, hər birimizi müxtəlif ünsiyyət modelləri və səs stratejiləri kimi müxtəlif aspektlər haqqında analiz edirik. Müsəlman sonuçları göstərir ki, ensembling həmişə performans artırılmasına və qiymətli negatif tapışmalarına nəticə edilməyən deyildir.', 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ার ক্ষেত্রে ব্যাপকভাবে বিস্তারিত ভাষার প্রক্রিয়া উন্নয়নে কার্যকর হতে পারে। এই পত্রিকাটি বিশ্লেষণ করেছে কিভাবে নিউরুল মেশিন অনুবাদ (এনএমটি) মডেলগুলো বিভিন্ন পরীক্ষা বিভিন্ন পরীক্ষার বৈশিষ্ট্য নির্ধারণের মাধ্যমে প্রভাবিত করে গভীর পরীক্ষার জন্য আমরা প্রত্যেকটি বিশ্লেষণ করি বিভিন্ন বিষয়ের প্রতি বিশ্লেষণ মডেল এবং ভোটাক্স কৌশল। পরীক্ষার ফলাফল দেখা যাচ্ছে যে বিস্ফোরণের ফলে কার্যকর বৃদ্ধি পাচ্ছে না এবং নেতিবাচক ফলাফল প্রদান করা হচ্ছে।', 'bs': 'U oblasti obrade prirodnog jezika, ensemble se široko poznaju da su učinkovito u poboljšanju učinkovitosti. Ovaj papir analizira kako ensemble modela neuronskog prevoda (NMT) utječe na poboljšanje učinka dizajniranjem različitih eksperimentalnih setova (tj. intra-, interensemble i ne konvergencije ensemble). Za duboko ispitivanje, analiziramo svaku metodu obezbeđenog u pogledu nekoliko aspekta poput različitih modela pažnje i glasnih strategija. Eksperimentalni rezultati pokazuju da ensembliranje ne uvijek uzrokuje povećanje učinka i daje značajne negativne nalaze.', 'cs': 'V oblasti zpracování přirozeného jazyka jsou soubory obecně známé jako efektivní při zlepšování výkonu. Tento článek analyzuje, jak soubor NMT modelů ovlivňuje zlepšení výkonu navrhováním různých experimentálních nastavení (tj. intra-, inter-ensemble a non-konvergenční soubor). K hloubkovému zkoumání analyzujeme jednotlivé souborové metody s ohledem na několik aspektů, jako jsou různé modely pozornosti a strategie slovníku. Experimentální výsledky ukazují, že soubor ne vždy vede ke zvýšení výkonu a poskytuje pozoruhodné negativní nálezy.', 'et': 'Loodusliku keele töötlemise valdkonnas on ansamblid üldiselt teadaolevalt tõhusad jõudluse parandamisel. Käesolevas töös analüüsitakse, kuidas neuronal masintõlke (NMT) mudelite ansambel mõjutab jõudluse parandamist, kujundades erinevaid eksperimentaalseid seadistusi (st intra-, ansambli- ja mittekonverentsiooni ansambel). Põhjalikuks uurimiseks analüüsime iga ansambli meetodit mitmete aspektide, näiteks erinevate tähelepanu mudelite ja sõnavara strateegiate osas. Eksperimentaalsed tulemused näitavad, et ansambleerimine ei too alati kaasa jõudluse suurenemist ja annab märkimisväärseid negatiivseid tulemusi.', 'fi': 'Luonnonkielen käsittelyn alalla yhtyeet tunnetaan yleisesti tehokkaina suorituskyvyn parantamisessa. Tässä työssä analysoidaan, miten neuron konekäännösmallit (NMT) vaikuttavat suorituskyvyn parantamiseen suunnittelemalla erilaisia kokeellisia kokoonpanoja (esim. intra-, interensemble- ja non-convergence ensemble). Analysoimme jokaisen ensemble-menetelmän syvälliseen tarkasteluun useita näkökulmia, kuten erilaisia huomiomalleja ja sanastostrategioita. Kokeelliset tulokset osoittavat, että kokoonpano ei aina lisää suorituskykyä ja antaa merkittäviä negatiivisia havaintoja.', 'ca': "En el camp del processament natural del llenguatge, es coneix que els conjunts són eficaços en millorar el rendiment. Aquest paper analitza com el conjunt de models de traducció neural de màquines (NMT) afecta a la millora del rendiment dissenyant diverses configuracions experimentals (és a dir, conjunt intra-, inter-ensemble i no convergència). En un examen profund, analitzem cada mètode d'ensemble en relació a diversos aspectes com els diferents models d'atenció i estratègies vocals. Els resultats experimentals mostren que la reunió no sempre provoca augments de rendiment i dona descobriments negatius notables.", 'sk': 'Na področju obdelave naravnega jezika so ansambli široko znani kot učinkoviti pri izboljšanju učinkovitosti. V prispevku je analizirano, kako ansambel modelov nevronskega strojnega prevajanja (NMT) vpliva na izboljšanje zmogljivosti z oblikovanjem različnih eksperimentalnih nastavitev (tj. intra-, interansambel in nekonvergenčni ansambel). V poglobljenem pregledu analiziramo vsako metodo ansambla glede na več vidikov, kot so različni modeli pozornosti in strategije besednika. Eksperimentalni rezultati kažejo, da ansambling ne povzroči vedno povečanja zmogljivosti in daje pomembne negativne ugotovitve.', 'jv': "Taning Awakdhéwé iki dadi piye kalagayet penting nggambar model penting nggambar alam nyebutur Nyong-nggambar nyong-nambarang Menu item to Open 'Search for Open Files' dialog", 'he': 'בשטח עיבוד שפת טבעית, אנסמבלים ידועים באופן רחב להיות יעילים בשיפור ביצועים. הנייר הזה מנתח איך סמל התרגום של מכונות עצביות (NMT) משפיע על שיפור ביצועים על ידי עיצוב מסדרות ניסויים שונות (כלומר, סמל אינטרנסבול, אינטרנסבול ואינטרנסבול). לבדיקה עמוקה, אנו מנתחים כל שיטת אנסמבל בנוגע לכמה היבטים כמו דוגמני תשומת לב שונים ואסטרטגיות קול. התוצאות הניסוייות מראות שהאסיפציה לא תמיד תוצאה בזימות ביצועים ולתת מציאות שליליות משמעותיות.', 'ha': 'A cikin field da ake zartar da harshen na asili, an sanar da fanel masu amfani da wajen kyautatawa. Wannan takardan na yi anayyani ga yadda misalin masu fassarar kwamfyutan neural (NMT) na yi amfani da gyara ga gyaranta na aikin aiki, ko kuma ana ƙayyade tsari masu fitina daban-dabam (misali, intra-, guda-ensemble, da wata ensemble na-dabar). To, zuwa ga jarrabi guda, mu yi anayya ga kowane metode da ke cikin shirin ayuka, kamar misãlai masu zane-zane da zane-zane-zane. Matarin jarrabai ke nũna cewa, emballa bã zai iya ƙara ajiya ba daidai kuma ya bãyar da matsalan negative.', 'bo': 'སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་ལས་སྦྱོར་བའི་གྲངས་ཀ་དེ་ཤེས་ཡོད་ཚད་ལྡན་ཡར་རྒྱས་འགྲོ་བ་དང་། This paper analyzes how ensemble of neural machine translation (NMT) models affect performance improvement by designing various experimental setups (i.e. intra-, inter-ensemble, and non-convergence ensemble). To an in-depth examination, we analyze each ensemble method with respect to several aspects such as different attention models and vocab strategies. ལག་ལེན་འཐབ་པའི་གྲུབ་འབྲས་མཐོང་ནི་རྟག་པར་མཐོང་སྣང་མེད་རྟག་པར་མཐུན་རྐྱེན་ཚད་མངོན་གསལ་བ་ཞིག'}
{'en': 'Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph', 'ar': 'مقارنة بين عمليات التطابق الإقليدية والزائدية في الرسم البياني التشعبي لأسماء WordNet', 'es': 'Comparación de incrustaciones euclidianas e hiperbólicas en el gráfico de hipernemia de sustantivos de WordNet', 'fr': "Comparaison des incorporations euclidiennes et hyperboliques sur le graphe d'hypernymie des noms WordNet", 'pt': 'Comparando incorporações euclidianas e hiperbólicas no gráfico de hipernímia de substantivos do WordNet', 'hi': 'WordNet संज्ञाएँ हाइपरनीमी ग्राफ़ पर यूक्लिडियन और हाइपरबोलिक एम्बेडिंग की तुलना करना', 'zh': '较 WordNet 名词 Hypernymy Graph 上欧数里得与双曲嵌', 'ja': 'WordNet名詞ハイパーニミーグラフ上のユークリッド埋め込みと双曲線埋め込みの比較', 'ru': 'Сравнение евклидовых и гиперболических вложений на гипернимическом графике существительных WordNet', 'ga': 'Comparáid a dhéanamh idir Leabaithe Eoiclídeacha agus Hipirbolacha ar Ghraf Hipirimide Ainmfhocail WordNet', 'el': 'Σύγκριση Ευκλείδειων και Υπερβολικών Ενσωματώσεων στο Γράφημα Υπερνυμίας', 'hu': 'Az euklideai és hiperbolikus beágyazások összehasonlítása a WordNet főnevekben Hypernymia grafikon', 'it': 'Confronto tra incorporazioni euclidee e iperboliche nel grafico dei sostantivi WordNet', 'lt': 'Euklidinės ir hiperbolinės įrangos palyginimas WordNet vardų hipernimijos grafike', 'kk': 'WordNet тізімдерінің гипернимнің графикасында Еклидеян және гиперболық ендірулерді салыстыру', 'ms': 'Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph', 'ml': 'വാര്\u200dഡ്നെറ്റ് നോണ്ട് ഹൈപ്പര്\u200dനിമി ഗ്രാഫിലെ എക്കുളിഡിനും ഹൈപ്പര്\u200dബോളിക് എംബഡിങ്ങുകളും തുല്യമാക്കുക', 'mt': 'It-tqabbil tal-Embeddings Euclidean u Hyperbolic fuq il-Graff tal-Ipernimija tal-WordNet Nouns', 'mk': 'Споредување на евклидиски и хиперболички вградувања на графот со WordNet именици', 'ka': 'Name', 'mn': 'WordNet Nouns Hypernymy Graph', 'pl': 'Porównanie osadzeń euklidowych i hiperbolicznych na wykresie rzeczowników WordNet', 'sr': 'U usporedbi Euklideana i hiperboličkih integracija na WordNet Nouns Hypernymy Graph', 'ro': 'Compararea încorporărilor euclidiene și hiperbolice în graficul substantivelor WordNet', 'si': 'Name', 'sv': 'Jämför euklidiska och hyperboliska inbäddningar på WordNet substantiv Hypernymy Graph', 'so': 'Isbarbardhigta Euclidian iyo Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph', 'ta': 'Name', 'ur': 'WordNet Nouns Hypernymy Graph', 'no': 'Samanliknar Euclidean- og hyperbolsk innbygging på WordNet- nøkkelgrafen Hypernymy', 'uz': 'Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph', 'vi': 'So sánh môi trường Euclide và Hyperolic trên the WordNet Noins Hypernymy Graph.', 'nl': 'Vergelijking van euclidische en hyperbolische insluitingen op de WordNet zelfstandige naamwoorden Hypernymiegrafiek', 'hr': 'Uspoređujući Euclidean i hiperboličke integracije na WordNet Nouns Hypernymy Graph', 'bg': 'Сравняване на евклидските и хиперболичните вграждания в графиката на хипернимията', 'da': 'Sammenligning af euklidiske og hyperboliske indlejringer på WordNet-navneord Hypernymy Graph', 'de': 'Vergleich von euklidischen und hyperbolischen Einbettungen im WordNet Substantive Hypernymie Graph', 'id': 'Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph', 'ko': 'WordNet 명사 초의도에서 유클리드 삽입과 쌍곡 삽입의 비교', 'sw': 'Kulinganisha Mazungumzo ya Euclidia na Mazungumzo ya Ki-Hypernymy kwenye Graph ya WordNet Nouns Hypernymy', 'tr': 'WordNet Taşları Hiperşim Grafiğinde Euklidean ve Hiperbolik İblemeleri Karşılaştırılýar', 'af': 'Vergelyking Euclidean en Hyperboliese Inbêdings op die WordNet Noun Hypernymy Graaf', 'fa': 'در مقایسه ابتدایی\u200cهای یوکلیدین و هیپر\u200cبولیک روی گراف ابتدایی\u200cهای WordNet Nouns Hypernymy', 'am': 'የዩክሊዲያን እና የhypperbolic Embedding on WordNet Nouns Hypernymy Graph', 'sq': 'Duke krahasuar përfshirjet euklideane dhe hiperbolike në grafikun e hipernimisë së emrave WordNet', 'hy': 'Եուկլիդիայի և հիպերբոլիկ ներգրավումների համեմատությունը WordNet անունների հիպերնիմիայի գրաֆում', 'az': 'WordNet AdlarńĪ Hypernimi Grafi √ľzerind…ô Euclidean v…ô Hiperbolik ńįfad…ôl…ôri', 'bn': 'ওয়ার্ডনেট নোনাস হাইপার্নিমি গ্রাফে ইউক্লিডিয়ান এবং হাইপার্বোলিক দূর্ঘটনার তুলনায়', 'cs': 'Porovnání euklidových a hyperbolických vložení na WordNet Podstatná jména Hypernymie Graf', 'bs': 'Uspoređujući Euklidean i hiperboličke integracije na WordNet Nouns Hypernymy Graph', 'ca': "Comparar l'incorporació euclídica i hiperbòlica al gràfic d'hipernimia dels noms WordNet", 'et': 'Eukliidi ja hüperboolsete põimimiste võrdlemine WordNeti substantiivne hüpernüümiagraafik', 'fi': 'Eukleidisten ja hyperbolisten upotusten vertailu WordNet Substantiivinen Hypernyymikaavio', 'jv': 'Ngubah YuClida karo akeh basa Hyperbudhakan lan Gambar Anyar aku Word net Njuk Hypernymi Graph', 'ha': 'KCharselect unicode block name', 'sk': 'Primerjava evklidskih in hiperboličnih vdelav v WordNetovem samostalniku Hypernimy Graph', 'bo': 'Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph', 'he': 'השוואה של התכניות יוקלדיות והיפרבוליות על גרף היפרנימיה של השמות WordNet'}
{'en': 'Nickel and Kiela (2017) present a new method for embedding tree nodes in the Poincare ball, and suggest that these hyperbolic embeddings are far more effective than Euclidean embeddings at embedding nodes in large, hierarchically structured graphs like the WordNet nouns hypernymy tree. This is especially true in low dimensions (Nickel and Kiela, 2017, Table 1). In this work, we seek to reproduce their experiments on embedding and reconstructing the WordNet nouns hypernymy graph. Counter to what they report, we find that Euclidean embeddings are able to represent this tree at least as well as Poincare embeddings, when allowed at least 50 dimensions. We note that this does not diminish the significance of their work given the impressive performance of hyperbolic embeddings in very low-dimensional settings. However, given the wide influence of their work, our aim here is to present an updated and more accurate comparison between the Euclidean and hyperbolic embeddings.', 'ar': 'يقدم Nickel and Kiela (2017) طريقة جديدة لتضمين العقد الشجرية في كرة Poincare ، ويقترحان أن هذه الزخارف الزائدية أكثر فاعلية بكثير من عمليات التضمين الإقليدية في تضمين العقد في رسوم بيانية كبيرة منظمة بشكل هرمي مثل شجرة hypernymy لأسماء WordNet. هذا صحيح بشكل خاص في الأبعاد المنخفضة (Nickel and Kiela ، 2017 ، الجدول 1). في هذا العمل ، نسعى إلى إعادة إنتاج تجاربهم على تضمين وإعادة بناء الرسم البياني المفرط لأسماء WordNet. على عكس ما أفادوا به ، وجدنا أن حفلات الزفاف الإقليدية قادرة على تمثيل هذه الشجرة على الأقل بالإضافة إلى حفلات الزفاف في Poincare ، عندما يُسمح بـ 50 بعدًا على الأقل. نلاحظ أن هذا لا يقلل من أهمية عملهم نظرًا للأداء المثير للإعجاب لحفلات الزفاف الزائدية في إعدادات منخفضة الأبعاد للغاية. ومع ذلك ، نظرًا للتأثير الواسع لعملهم ، فإن هدفنا هنا هو تقديم مقارنة محدثة وأكثر دقة بين حفلات الزفاف الإقليدية والزائدية.', 'es': 'Nickel y Kiela (2017) presentan un nuevo método para incrustar nodos de árbol en la bola de Poincare, y sugieren que estas incrustaciones hiperbólicas son mucho más efectivas que las incrustaciones euclidianas en la incrustación de nodos en gráficos grandes y estructurados jerárquicamente, como el árbol hipernimo de los sustantivos de WordNet. Esto es especialmente cierto en dimensiones bajas (Nickel y Kiela, 2017, Tabla 1). En este trabajo, buscamos reproducir sus experimentos sobre la incrustación y reconstrucción del gráfico de hipernemia de sustantivos de WordNet. Contrario a lo que informan, encontramos que las incrustaciones euclidianas pueden representar este árbol al menos tan bien como las incrustaciones de Poincare, cuando se permiten al menos 50 dimensiones. Observamos que esto no disminuye la importancia de su trabajo dado el impresionante rendimiento de las incrustaciones hiperbólicas en entornos de muy baja dimensión. Sin embargo, dada la amplia influencia de su trabajo, nuestro objetivo aquí es presentar una comparación actualizada y más precisa entre las incrustaciones euclidiana e hiperbólica.', 'pt': 'Nickel e Kiela (2017) apresentam um novo método para incorporar nós de árvore na bola de Poincaré e sugerem que essas incorporações hiperbólicas são muito mais eficazes do que as incorporações euclidianas na incorporação de nós em grafos grandes e hierarquicamente estruturados, como a árvore de hipernímia de substantivos WordNet. Isso é especialmente verdadeiro em dimensões baixas (Níquel e Kiela, 2017, Tabela 1). Neste trabalho, procuramos reproduzir seus experimentos de incorporação e reconstrução do grafo de hipernímia de substantivos WordNet. Ao contrário do que eles relatam, descobrimos que os embeddings euclidianos são capazes de representar essa árvore pelo menos tão bem quanto os embeddings de Poincaré, quando permitidos pelo menos 50 dimensões. Observamos que isso não diminui a importância de seu trabalho, dado o desempenho impressionante de incorporações hiperbólicas em configurações de dimensões muito baixas. No entanto, dada a ampla influência de seu trabalho, nosso objetivo aqui é apresentar uma comparação atualizada e mais precisa entre os embeddings euclidianos e hiperbólicos.', 'fr': "Nickel et Kiela (2017) présentent une nouvelle méthode pour intégrer des nœuds d'arbre dans la boule de Poincare, et suggèrent que ces intégrations hyperboliques sont bien plus efficaces que les intégrations euclidiennes pour intégrer des nœuds dans de grands graphiques structurés hiérarchiquement comme l'arbre d'hypernymie des noms WordNet. Cela est particulièrement vrai pour les petites dimensions (Nickel et Kiela, 2017, Tableau 1). Dans ce travail, nous cherchons à reproduire leurs expériences sur l'intégration et la reconstruction du graphe d'hypernymie des noms WordNet. Contrairement à ce qu'ils rapportent, nous constatons que les incrassements euclidiens sont capables de représenter cet arbre au moins aussi bien que les incorporer Poincaré, lorsqu'ils sont autorisés à au moins 50 dimensions. Nous notons que cela ne diminue en rien l'importance de leur travail compte tenu des performances impressionnantes des intégrations hyperboliques dans des environnements de très faible dimension. Cependant, compte tenu de l'influence considérable de leurs travaux, notre objectif est de présenter une comparaison actualisée et plus précise entre les intégrations euclidiennes et hyperboliques.", 'ja': 'NickelとKiela （ 2017 ）は、ポインケアボールにツリーノードを埋め込むための新しい方法を提示し、これらの双曲線埋め込みは、WordNet名詞ハイパーニミーツリーのような大きな階層構造のグラフにノードを埋め込むときのユークリッド埋め込みよりもはるかに効果的であることを示唆している。特に低次元ではそうである（ Nickel and Kiela, 2017, Table 1 ）。この研究では、WordNet名詞ハイパーニミーグラフの埋め込みと再構築の実験を再現しようとしています。彼らの報告に反して、ユークリッド埋め込みは、少なくとも50次元で許容される場合、少なくともポインケア埋め込みと同様にこの木を表すことができることがわかりました。これは、非常に低次元の環境での双曲線埋め込みの印象的なパフォーマンスを考えると、彼らの作品の重要性を低下させるものではないことに注意してください。しかし、彼らの研究の広範な影響を考慮すると、ここでの私たちの目的は、ユークリッド埋め込みと双曲線埋め込みの間の最新でより正確な比較を提示することです。', 'zh': 'Nickel与Kiela(2017)言新法于Poincare球中节点,明双曲嵌比欧数里得嵌于大结构图节点(如WordNet名词hymonymy树)中益效。 在下尺寸中尤如此(Nickel and Kiela,2017,表1)。 此图重见嵌WordNet名词超名图之实验。 与其所告相反,见欧数里得嵌至少,及庞加莱嵌之,许至少50维度时。 鉴双曲嵌非常低之深,未降其要也。 然鉴其广化,在此数里,与双曲嵌间更相较也。', 'hi': 'निकल और किला (2017) पोइनकेयर बॉल में ट्री नोड्स को एम्बेड करने के लिए एक नई विधि पेश करते हैं, और सुझाव देते हैं कि ये हाइपरबोलिक एम्बेडिंग वर्डनेट संज्ञा हाइपरनिमी ट्री जैसे बड़े, पदानुक्रमित रूप से संरचित ग्राफ में एम्बेडिंग नोड्स में यूक्लिडियन एम्बेडिंग की तुलना में कहीं अधिक प्रभावी हैं। यह विशेष रूप से कम आयामों में सच है (निकल और किला, 2017, तालिका 1)। इस काम में, हम WordNet संज्ञाओं hypernymy ग्राफ को एम्बेड करने और पुनर्निर्माण करने पर उनके प्रयोगों को पुन: पेश करना चाहते हैं। वे जो रिपोर्ट करते हैं, उसके विपरीत, हम पाते हैं कि यूक्लिडियन एम्बेडिंग इस पेड़ को कम से कम प्रतिनिधित्व करने में सक्षम हैं और साथ ही साथ पोइनकेयर एम्बेडिंग, जब कम से कम 50 आयामों की अनुमति दी जाती है। हम ध्यान दें कि यह बहुत कम आयामी सेटिंग्स में हाइपरबोलिक एम्बेडिंग के प्रभावशाली प्रदर्शन को देखते हुए उनके काम के महत्व को कम नहीं करता है। हालांकि, उनके काम के व्यापक प्रभाव को देखते हुए, हमारा उद्देश्य यहां यूक्लिडियन और हाइपरबोलिक एम्बेडिंग के बीच एक अद्यतन और अधिक सटीक तुलना प्रस्तुत करना है।', 'ru': 'Никель и Киела (2017) представляют новый метод встраивания узлов деревьев в шарик Пуанкаре и предполагают, что эти гиперболические вложения гораздо более эффективны, чем евклидовые вкладыши в узлах встраивания в больших иерархически структурированных графах, таких как гипернимическое дерево существительных WordNet. Это особенно верно в низких размерах (Nickel and Kiela, 2017, таблица 1). В этой работе мы стремимся воспроизвести их эксперименты по встраиванию и реконструкции гипернимического графа существительных WordNet. Вопреки тому, что они сообщают, мы находим, что евклидовы вложения способны представлять это дерево, по крайней мере, так же, как вложения Пуанкаре, если разрешено, по крайней мере, 50 измерений. Мы отмечаем, что это не умаляет значимости их работы, учитывая впечатляющую производительность гиперболических вложений в очень низкоразмерных условиях. Однако, учитывая большое влияние их работы, наша цель здесь состоит в том, чтобы представить обновленный и более точное сравнение между евклидовым и гиперболическим вложениями.', 'ga': 'Cuireann Nickel and Kiela (2017) modh nua i láthair chun nóid chrainn a leabú sa liathróid Poincare, agus molann siad go bhfuil na leabaithe hipearbóileacha seo i bhfad níos éifeachtaí ná leabú Eoiclídeach ag neadú nóid i ngraif mhóra struchtúracha ordlathacha cosúil leis an gcrann hipearbóileach ainmfhocail WordNet. Tá sé seo fíor go háirithe i toisí ísle (Nickel agus Kiela, 2017, Tábla 1). Sa saothar seo, déanaimid iarracht a gcuid trialacha a atáirgeadh ar leabú agus athchruthú an ghraf hipearainmneacha d’ainmfhocail WordNet. I gcoinne a dtuairiscíonn siad, feicimid go bhfuil leabaithe Eoiclídeach in ann an crann seo ar a laghad a léiriú chomh maith le leabaithe Poincare, nuair a cheadaítear ar a laghad 50 toise. Tugaimid faoi deara nach laghdaítear tábhacht a gcuid oibre mar gheall ar fheidhmíocht iontach na leabaithe hipearbóileacha i suíomhanna an-ísealtoiseacha. Ach mar gheall ar thionchar leathan a gcuid oibre, is é an aidhm atá againn anseo ná comparáid nuashonraithe agus níos cruinne a chur i láthair idir na leabaithe Eoiclídeacha agus hipearbóileacha.', 'el': 'Το νικέλιο και η Κίλα (2017) παρουσιάζουν μια νέα μέθοδο για την ενσωμάτωση κόμβων δέντρου στη σφαίρα και υποδηλώνουν ότι αυτές οι υπερβολικές ενσωμάτωσης είναι πολύ πιο αποτελεσματικές από τις ευκλείδειες ενσωμάτωση κόμβων σε μεγάλα, ιεραρχικά δομημένα γραφήματα όπως το δέντρο υπερνύμων ουσιαστικών. Αυτό ισχύει ιδιαίτερα σε χαμηλές διαστάσεις (Νικέλιο και Κίλα, 2017, Πίνακας 1). Σε αυτή την εργασία, επιδιώκουμε να αναπαράγουμε τα πειράματά τους για την ενσωμάτωση και την ανακατασκευή του γραφήματος υπερνύμων ουσιαστικών. Σε αντίθεση με ό,τι αναφέρουν, διαπιστώνουμε ότι οι ευκλείδειες ενσωματώσεις είναι σε θέση να αντιπροσωπεύουν αυτό το δέντρο τουλάχιστον όπως και οι ενσωματώσεις, όταν επιτρέπονται τουλάχιστον 50 διαστάσεις. Σημειώνουμε ότι αυτό δεν μειώνει τη σημασία του έργου τους δεδομένης της εντυπωσιακής απόδοσης των υπερβολικών ενσωματώσεων σε πολύ χαμηλών διαστάσεων ρυθμίσεις. Ωστόσο, δεδομένης της μεγάλης επιρροής του έργου τους, στόχος μας εδώ είναι να παρουσιάσουμε μια ενημερωμένη και πιο ακριβή σύγκριση μεταξύ των ευκλείδειων και των υπερβολικών ενσωμάτωσης.', 'hu': 'A nikkel és Kiela (2017) egy új módszert mutatnak be a poincare golyóba való beágyazására, és azt sugallják, hogy ezek a hiperbolikus beágyazások sokkal hatékonyabbak, mint az euklideai beágyazások nagy, hierarchikusan strukturált grafikonokba, mint a WordNet főnevek hipernymia fa. Ez különösen igaz az alacsony méretekben (Nikkel és Kiela, 2017, 1. táblázat). Ebben a munkában arra törekszünk, hogy reprodukáljuk kísérleteiket a WordNet főnevek hipernímiájának beágyazására és rekonstruálására. Ellentétben azzal, amit jelentenek, azt találjuk, hogy az euklideai beágyazások képesek ezt a fát legalább úgy reprezentálni, mint a Poincare beágyazásokat, ha engedélyezett legalább 50 dimenzió. Megjegyezzük, hogy ez nem csökkenti munkájuk jelentőségét, tekintettel a hiperbolikus beágyazások lenyűgöző teljesítményére nagyon alacsony dimenziós környezetben. Munkájuk nagy hatására tekintettel azonban célunk, hogy az euklideai és hiperbolikus beágyazások közötti korszerűbb és pontosabb összehasonlítást mutassunk be.', 'ka': 'ნთკვლი და კივლა (2017) ახალი მეტი პონკერის ბოლში შავის კუნძებების დაყენებას და აჩვენება, რომ ეს ჰიპერბოლური კუნძებები უფრო ეფექტიურია, ვიდრე ძალიან ეფექტიურია უფრო ეფექტიურია, როგორც WordNet სახელის ჰიპერნიმის ხე ეს სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა (Nickel and Kiela, 2017, Table 1). ამ სამუშაოში, ჩვენ მინდა გამოვიყენოთ მათი ექსპერიმენტები, რომელიც WordNet სამუშაო ჰიპერნიმე გრაფიკაში დავყენებთ და განაკეთება. ჩვენ ვიღებთ, რომ ძკლიდიანი ინბედინგიები შეუძლიათ ამ ხელის გამოსახულებას, მაგრამ Poincare ინბედინგიების გამოსახულებას, როდესაც უფრო დამატებული 50 განზომილებები. ჩვენ დავხედავთ, რომ ეს მათი სამუშაო მნიშვნელობას არ გამოკლებს, რომლებიც ჰიპერბოლიკური ინბედინგიზების შესაძლებლობად მცირე განზომილებული შესაძლებლობაში. მაგრამ, მათი სამუშაო სამუშაო შესახებ, ჩვენი მიზეზი აქ არის ახალი და უფრო მარტივი შესახებ ეუკლიდიანი და ჰიპერბოლური შესახებ.', 'it': "Nickel e Kiela (2017) presentano un nuovo metodo per incorporare nodi di albero nella sfera Poincare, e suggeriscono che questi incorporamenti iperbolici sono molto più efficaci degli incorporamenti euclidi nell'incorporare nodi in grandi grafici strutturati gerarchicamente come l'albero ipernimico dei sostantivi WordNet. Questo è particolarmente vero nelle dimensioni basse (Nichel e Kiela, 2017, Tabella 1). In questo lavoro, cerchiamo di riprodurre i loro esperimenti sull'incorporazione e la ricostruzione del grafico ipernimico dei sostantivi WordNet. Contrariamente a quanto riportano, troviamo che le incorporazioni euclidee sono in grado di rappresentare questo albero almeno così come quelle Poincare, quando consentite almeno 50 dimensioni. Notiamo che questo non diminuisce il significato del loro lavoro data l'impressionante performance di incorporamenti iperbolici in impostazioni molto basse dimensionali. Tuttavia, data l'ampia influenza del loro lavoro, il nostro obiettivo qui è quello di presentare un confronto aggiornato e più accurato tra le incorporazioni euclidee e iperboliche.", 'kk': 'Никел және Киела (2017) Poincare бағасында ағаш түрлерін ендіру әдісін таңдап, бұл гиперболық ендіруді Еклидеяның ендіру түрлеріне үлкен, иерархиялық құрылған графиктерді WordNet атауы сияқты гипернимнің ағашындағы үлкен, үлкен, иерархиялық құрылған гра Бұл өзгеше төмен өлшемдерде (Никел және Киела, 2017, 1. кесте). Бұл жұмыс ішінде, WordNet атауларының гипернимнің графикасын ендіру және қайта құру үшін өз тәжірибелерін қайта құру керек. Олардың хабарламаларына қарсы, біз Еклидеяның ендіру бұл ағаш мен Poincare ендіру үшін кемінде 50 өлшемдерге рұқсат етілген кезде болады. Біз олардың жұмысының маңыздылығын өте төмен өлшемді параметрлерде гиперболық ендірудің әсер ететін әсер етімдерін азайтпайды. Бірақ, олардың жұмысының көпшілігін көрсету мақсатымыз - Еклидеяның мен гиперболық ендірудің арасындағы жаңарту мен дұрыс салыстыру.', 'lt': 'Nikelis ir Kiela (2017 m.) yra naujas medinių mazgų įterpimo į Poincare rutulį metodas ir rodo, kad šie hiperboliniai įterpimai yra daug veiksmingesni nei Euklidiniai įterpimai įterpiant mazgus į didelius, hierarchiškai struktūruotus grafikus, pvz., WordNet pavadinimų hipernimijos medį. Tai ypač pasakytina apie mažus matmenis (Nikelis ir Kiela, 2017 m., 1 lentelė). Šiame darbe mes siekiame atkurti jų eksperimentus įterpiant ir atkuriant WordNet vardų hipernimijos grafiką. Priešingai negu jie praneša, mes matome, kad Euklidų įdėjiniai gali atstovauti bent jau šiam medžiui, taip pat Poincare įdėjiniams, kai leidžiama bent 50 matmenų. Mes pastebime, kad tai nesumažina jų darbo reikšmės, atsižvelgiant į įspūdingą hiperbolinių įdėjimų veiksmingumą labai mažo matmens aplinkybėse. Tačiau atsižvelgiant į didelę jų darbo įtaką, mūsų tikslas yra pateikti atnaujintą ir tikslesnį Euklidinės ir hiperbolinės medžiagos palyginimą.', 'mk': 'Никел и Кила (2017) претставуваат нови методи за внесување на дрвените јазли во топката Поинкар, и предлагаат дека овие хиперболични внесувања се многу поефикасни од евклидските внесувања во внесувањето на јазли во големи, хиерархички структурирани графики како што е дрвото со имената WordNet. Ова е особено точно во ниските димензии (Никел и Кила, 2017, маса 1). Во оваа работа, ние се обидуваме да ги репродуктираме нивните експерименти за вградување и реконструкција на WordNet имената хипернимиски граф. Во спротивност на она што го известуваат, откривме дека евклидските вградувања можат да го претставуваат ова дрво барем како и вградувањата на Поинкар, кога се дозволени барем 50 димензии. Ние забележуваме дека ова не го намалува значењето на нивната работа со оглед на импресивната резултат на хиперболичките вградувања во многу ниски димензионални услови. Сепак, со оглед на широкото влијание на нивната работа, нашата цел овде е да претставиме оновремена и попрецизна споредба помеѓу евклидиските и хиперболичките вградувања.', 'mt': 'Nikil u Kiela (2017) jippreżentaw metodu ġdid għall-inkorporazzjoni ta’ nodi tas-siġar fil-ballun Poincare, u jissuġġerixxu li dawn l-inkorporazzjonijiet iperboliċi huma ħafna aktar effettivi mill-inkorporazzjonijiet Euclideani fl-inkorporazzjoni ta’ nodi f’graffi kbar, ġerarkikament strutturati bħall-WordNet nomes hypernymy tree. Dan huwa speċjalment minnu f’dimensjonijiet baxxi (Nikil u Kiela, 2017, Tabella 1). F’dan ix-xogħol, qed nippruvaw nipproduċu l-esperimenti tagħhom dwar l-inkorporazzjoni u r-rikostruzzjoni tal-graff tal-ipernimija tal-WordNet. Għall-kuntrarju ta’ dak li jirrappurtaw, isibu li l-inkorporazzjonijiet Euclideani jistgħu jirrappreżentaw din is-siġra mill-inqas kif ukoll l-inkorporazzjonijiet Poincare, meta permessi mill-inqas 50 dimensjoni. Ninnutaw li dan ma jnaqqas is-sinifikat tax-xogħol tagħhom minħabba l-prestazzjoni impressjonanti ta’ inkorporazzjonijiet iperboliċi f’ambjenti b’dimensjoni baxxa ħafna. Madankollu, minħabba l-influwenza wiesgħa tax-xogħol tagħhom, l-għan tagħna hawnhekk huwa li nippreżentaw paragun aġġornat u aktar preċiż bejn l-inkorporazzjonijiet Euclideani u iperboliċi.', 'ml': 'നിക്കേലും കിയേല (2017) പോയിന്\u200dക്കാള്\u200d ബോളില്\u200d ഉള്\u200dപ്പെടുത്തുന്ന മരത്തിന്\u200dറെ നോഡുകള്\u200dക്ക് ഒരു പുതിയ രീതിയില്\u200d കൊണ്ടുവരുന്നു. ഈ ഹൈപ്പര്\u200dബോളിക്ക് മുന്നോട്ടുള്ള പ്രവേശനങ്ങള്\u200d വലിയ, ഹൈരാര ഇത് പ്രത്യേകിച്ച് കുറച്ചു ഭാഗങ്ങളില്\u200d സത്യമാണ് (നിക്കേലും കിയേല, 2017, ടേബിള്\u200d 1). ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d അവരുടെ പരീക്ഷണങ്ങള്\u200d പുനരുത്ഥാപിക്കാന്\u200d ശ്രമിക്കുന്നു. വാര്\u200dഡ്നെറ്റ് നെറ്റിന്റെ ഹൈപ്പെര അവര്\u200d റിപ്പോര്\u200dട്ട് ചെയ്യുന്നതിനെക്കുറിച്ച് നമുക്ക് കണ്ടെത്താം, ഈ മരത്തിന്റെ പ്രതിനിധികള്\u200dക്കും ഈ മരത്തിന്റെ പ്രതിനിധികള്\u200dക്കും കഴി ഇത് അവരുടെ പ്രവര്\u200dത്തനത്തിന്റെ പ്രാധാന്യം കുറവിലാക്കുന്നില്ലെന്ന് ഞങ്ങള്\u200d കാണുന്നുണ്ട്. വളരെ കുറഞ്ഞ മാന്യമായ സജ്ജീകരണങ്ങളി എന്നാലും, അവരുടെ പ്രവര്\u200dത്തനത്തിന്\u200dറെ വിശാലമായ പ്രഭാവം കൊണ്ട്, നമ്മുടെ ലക്ഷ്യം ഇവിടെ ഉണ്ടാക്കുന്നത് യൂക്ലിഡിയന്\u200dറെയും ഹൈപ്പര്\u200dബോളിക്', 'mn': 'Никел болон Киела (2017) Poincare бөмбөг дээр модны цогцуудыг орлуулахын тулд шинэ арга зам өгнө. Энэхүү гиперболын цогцууд нь Еклидийн цогцуудыг том, hierarchically бүтээгдэхүүнтэй график болон WordNet гэх мэт гиперним модноос илүү үр дүнтэй гэдгийг сануулдаг. Энэ нь ялангуяа бага хэмжээсүүд дээр үнэн. Энэ ажил дээр бид WordNet нэртэй гиперним график гэх мэт туршилтуудыг дахин бүтээхийг хүсч байна. Тэдний хэлж байгаа зүйлсийн эсрэг бид Еуклидийн модыг хамгийн багахан 50 хэмжээсүүд болох үед Poincare-г илэрхийлж чадна гэдгийг олж мэднэ. Бид үүнийг хамгийн бага хэмжээст хэмжээсүүд дээр гиперболын хөрөнгө оруулалтын үр дүнг багасгахгүй гэдгийг анзаарч байна. Гэхдээ тэдний ажлын шинэ нөлөө үзүүлэхэд бидний зорилго нь Еклидийн болон гиперболын хоорондын харьцуулалтыг нэмэгдүүлэх, илүү тодорхой харьцуулах юм.', 'no': 'Nickel og Kiela (2017) viser ein ny metode for innbygging av tre-noder i Poincare-ballen, og foreslår at desse hyperbolske innbygginga er mykje mer effektive enn Euclidean-innbygging ved innbygging av noder i store, hierarkisk strukturerte grafikk som WordNet-namnet hypernymtre. Dette er spesielt sann i låge dimensjonar (Nickel and Kiela, 2017, tabell 1). I denne arbeida søker vi å gjenoppretta eksperimentene sine på å innebygge og gjenoppretta WordNet-namnet hypernymgrafikk. Kontroller kva dei rapporterer, finn vi at Euclidean-innbyggingar kan representera denne treen minst og Poincare-innbyggingar, når det er tillatt minst 50 dimensjonar. Vi merker på at dette ikkje minner betydninga av arbeidet sine gjeven uttrykking av hyperbolske innbygging i svært låg dimensjonal innstillingar. Dette er imidlertid å oppdatere og meir nøyaktig sammenligning mellom Euklidean og hyperbolske innbygging.', 'pl': 'Nikiel i Kiela (2017) prezentują nową metodę osadzania węzłów drzew w kuli Poincare i sugerują, że te hiperboliczne osadzenia są o wiele bardziej skuteczne niż euklidejskie przy osadzaniu węzłów w dużych, hierarchicznie ustrukturyzowanych wykresach, takich jak drzewo hipernimii rzeczowników WordNet. Dotyczy to szczególnie niskich wymiarów (nikiel i Kiela, 2017, tabela 1). W niniejszej pracy staramy się odtworzyć ich eksperymenty dotyczące osadzania i rekonstrukcji wykresu hipernimii rzeczowników WordNet. W przeciwieństwie do tego, co zgłaszają, stwierdzimy, że osadzenia euklidejskie są w stanie reprezentować to drzewo co najmniej tak dobrze, jak osadzenia Poincare, jeśli dozwolone są co najmniej 50-wymiary. Zauważamy, że nie zmniejsza to znaczenia ich pracy biorąc pod uwagę imponujące wykonanie osadzeń hiperbolicznych w bardzo niskich warunkach wymiarowych. Jednak biorąc pod uwagę szeroki wpływ ich pracy, naszym celem jest przedstawienie aktualnego i dokładniejszego porównania osadzeń euklidejskich i hiperbolicznych.', 'ro': 'Nickel și Kiela (2017) prezintă o nouă metodă de încorporare a nodurilor copaci în bila Poincare și sugerează că aceste încorporări hiperbolice sunt mult mai eficiente decât încorporările euclidiene la încorporarea nodurilor în grafice mari, structurate ierarhic, cum ar fi arborele hipernimic al substantivelor WordNet. Acest lucru este valabil în special în dimensiuni mici (Nickel și Kiela, 2017, Tabelul 1). În această lucrare, încercăm să reproducem experimentele lor privind încorporarea și reconstruirea graficului hipernimic al substantivelor WordNet. Contrar celor raportate, constatăm că încorporările euclidiene sunt capabile să reprezinte acest copac cel puțin la fel de bine ca încorporările Poincare, atunci când sunt permise cel puțin 50 de dimensiuni. Observăm că acest lucru nu diminuează semnificația muncii lor având în vedere performanța impresionantă a încorporărilor hiperbolice în setări foarte mici dimensiuni. Cu toate acestea, având în vedere influența vastă a activității lor, scopul nostru aici este de a prezenta o comparație actualizată și mai precisă între încorporările euclidiene și hiperbolice.', 'sr': 'Nikel i Kiela (2017) predstavljaju novu metodu za uključenje čvorova drveta u loptu Poincare i sugeriraju da su te hiperboličke uključenje mnogo efikasnije od uključenja Euklideana na ugrađenja čvorova u velikim, hijerarhički strukturovanim grafikama kao što je WordNet imenuje hipernimno drvo. Ovo je posebno tačno u niskim dimenzijama (Nikel i Kiela, 2017, tablica 1). U ovom poslu tražimo da reproduktujemo njihove eksperimente na ugradnji i rekonstrukciji grafa WordNeta imena hipernimu. Prema onome što prijavljuju, našli smo da su Euklideanski ugradnji u stanju da predstave ovo drvo najmanje kao i ugradnje Poincare, kad je dozvoljeno najmanje 50 dimenzija. Primećujemo da to ne smanjuje značajnost njihovog rada s obzirom na impresivnu funkciju hiperboličkih ugrađenja u vrlo niskom dimenzionalnom postavku. Međutim, s obzirom na širok uticaj njihovog rada, naš cilj je da predstavimo aktualizirane i tačnije usporedbe između Euklideana i hiperboličkih ugrađenja.', 'si': 'නිකෙල් සහ කිලා (2017) පොයින්කාර් බෝල් වල අළුත් විධානයක් පෙන්වන්න, ඒ වගේම මේ හායිපර්බෝලික සංවිධානය යුක්ලිඩියාන් සංවිධානයක් ලොකු නොඩ් වලින් සංවිධ මේක විශේෂ විශේෂයෙන්ම අඩුම විශේෂයෙන් ඇත්ත (නිකෙල් සහ කිලා, 2017, ටේස් 1). මේ වැඩේ අපි ඔවුන්ගේ පරීක්ෂණ ප්\u200dරතික්\u200dරියාවට පරිස්සම් කරන්න හා WordNet නාමය හායිපර්නාමි ග්\u200dරාෆ් එක පුන්වර්තන ඔවුන් වාර්තා කරපු දේවල් ගැන, අපිට හොයාගන්න පුළුවන් යුක්ලිඩියාන් ඇම්බෙන්ඩින් එක්ක මේ ගස් අඩුම තරම් පොයින්කාර් ඇම් අපි බලන්නේ මේක ඔවුන්ගේ වැඩේ වැදගත්ත වැදගත්තේ නැහැ කියලා හායිපර්බෝලික් සංවිධානය ගොඩක් අඩු අභිමාණ ස ඒත්, ඔවුන්ගේ වැඩේ විශාල ප්\u200dරශ්නයක් තියෙන්නේ, අපේ අරමුණ තමයි යුක්ලිඩියාන් සහ හායිපර්බෝලික් සංවිධානය අතර', 'so': 'Nickel iyo Kiela (2017) waxay soo bandhigaan qaab cusub oo ku habboon geed nodes ee Poincare Ball, waxaana ka jeedinayaa in meelahan hierbolka ah ay ka faa’iido badan yihiin meelaha uu ku hoggaamiyo Yuuclid oo aad u qoran karo, sida geedka hore ee WordNet oo kale. Taasi si gaar ah waa mid ku run daboolka hoose (Nickel iyo Kiela, 2017, Tabell 1). Markaas waxan waxaynu doonnaa in aan dib u soo celino jirrabadooda ku saabsan koritaanka iyo cusboonaysiinta xarafka nuurka ah ee WordNet. Xisaabta waxay wargeliyaan, waxaan ka helaynaa in meelaha ay Yuuclid ku soo daabacaan ay u representi karaan ugu yaraan geedkan iyo sidoo kale Poincare, marka loo ogolaado ugu yaraan 50 dimensions. Waxaynu ogaanaynaa in taasu uusan ka dhimin muhiimka shaqadooda, sababtoo ah dhaqdhaqaalaha aad u yar ee daboolka daboolka ah. Si kastaba ha ahaatee, saameyn badan ee shuqulkooda, waxaynu ku talo galaynaa halkan in la keeno barbaro cusub oo si saxda ah oo u sahlan isbardhiga dadka Euclidka iyo meelaha dhaqdhaqaaqa ah dhexdooda.', 'sv': 'Nickel och Kiela (2017) presenterar en ny metod för att bädda in trädnoder i Poincare bollen, och föreslår att dessa hyperboliska inbäddningar är mycket effektivare än euklidiska inbäddningar för att bädda in noder i stora hierarkiskt strukturerade grafer som WordNet substantiv hypernymyträd. Detta gäller särskilt i låga dimensioner (Nickel och Kiela, 2017, tabell 1). I detta arbete försöker vi reproducera deras experiment på att bädda in och rekonstruera WordNet substantiv hypernymy graf. Mot bakgrund av vad de rapporterar, finner vi att euklidiska inbäddningar kan representera detta träd minst lika väl som Poincare inbäddningar, när det tillåts minst 50 dimensioner. Vi noterar att detta inte minskar betydelsen av deras arbete med tanke på den imponerande prestandan av hyperboliska inbäddningar i mycket låga dimensioner. Men med tanke på det stora inflytandet av deras arbete är vårt mål här att presentera en uppdaterad och mer exakt jämförelse mellan euklidisk och hyperbolisk inbäddning.', 'ta': 'Name இது குறைந்த பரிமாணத்தில் உண்மை (நிக்கெல் மற்றும் கியேலா, 2017, அட்டவணை 1). இந்த வேலையில், நாம் அவர்களுடைய சோதனைகளை மீண்டும் முயற்சி செய்து வார்த்தை நெட்டின் முன்னிருப்பு வரைபடத்தை மீண்டும அவர்கள் என்ன அறிக்கை செய்கிறார்கள் என்று எண்ணுகிறோம், நாங்கள் கண்டுபிடிக்க முடியும் யுக்லிடியன் உள்ளீடுகள் இந்த மரத்தை குறைந்தது மற்ற மிகவும் குறைந்த பரிமாற்றமான அமைப்புகளில் அதிகப்பெரிய செயல்பாடுகளை குறைக்கவில்லை என்பதை நாம் கவனிக்கிறோம். ஆயினும், அவர்கள் வேலையின் பாக்கியம் கொடுத்தால், எங்கள் இலக்கு இங்கே ஒரு புதுப்பிக்கப்பட்ட மற்றும் மேலும் சரியான ஒப்பிடுதலை கொடுக்க', 'ur': 'نیکل اور کیلا (2017) Poincare Ball میں درخت نوڈ ڈینڈ کے لئے نئی طریقہ پیش کرتے ہیں، اور یہ پیش کرتا ہے کہ یہ ہیربولیک ایمبڈینڈ یوکلیڈین سے زیادہ مفید ہیں جو بڑے، ہیروکریٹی طریقہ سے ساختہ گراف ہیں جیسے WordNet نام ہیرنیمی درخت۔ یہ مخصوصا کم اندازے میں سچا ہے (نیکل اور کیلا، 2017، ٹیبل 1)۔ ہم اس کام میں ان کی آزمائش دوبارہ کرنا چاہتے ہیں WordNet کو ہیرنیمی گراف بنانے اور دوبارہ ساخت کرنے کے لئے۔ جو کچھ وہ راپور کرتے ہیں، ہم دیکھتے ہیں کہ Euclidean embeddings اس درخت کو کم کم اور Poincare embeddings دکھا سکتے ہیں، جب کم 50 dimensions اجازت دی جاتی ہے. ہم نے یاد رکھا ہے کہ یہ ان کے کاموں کی تعریف کم نہیں کر رہا ہے حالانکہ ہیربولیک ایمبڈینگ کی تعریف بہت کم اندازے کے اندازے میں ہے اگرچہ، ان کے کاموں کی وسیع تأثیر کے باعث، ہمارا مقصد یہاں ہے کہ یوکلیڈین اور ہیربولیک انبولینگ کے درمیان ایک آدٹر اور دقیق مقایسہ پیش کرنا ہے.', 'ms': 'Nickel dan Kiela (2017) menghasilkan kaedah baru untuk memasukkan nod pokok ke dalam bola Poincare, dan menyarankan bahawa penyambungan hiperbolik ini jauh lebih efektif daripada penyambungan Euclidean pada penyambungan nod dalam graf besar, secara hierarkis struktur seperti pokok hipernimi nama WordNet. Ini terutama benar dalam dimensi rendah (Nickel dan Kiela, 2017, Jadual 1). Dalam kerja ini, kita cuba untuk mereproduksi eksperimen mereka pada penyembedding dan membangun semula graf hipernimi nama WordNet. Berlawan dengan apa yang mereka laporkan, kami mendapati bahawa pembenaman Euclidean boleh mewakili pokok ini sekurang-kurangnya serta pembenaman Poincare, apabila dibenarkan sekurang-kurangnya 50 dimensi. Kami memperhatikan bahawa ini tidak mengurangi kepentingan kerja mereka kerana prestasi yang mengesankan penyampaian hiperbolik dalam tetapan dimensi yang sangat rendah. However, given the wide influence of their work, our aim here is to present an updated and more accurate comparison between the Euclidean and hyperbolic embeddings.', 'uz': "Name Bu juda qisqa shakllar (Nikel va Kiela, 2017, tab 1) da haqiqida. Bu ishda biz ularning tajribalarini qayta yuklashni istayapmiz va WordNet nuqta hypernemiy grafikni qayta yuklashni istaysizki. Ko'rib chiqishni tasavvur qiling, biz Euklidiya emblemlari bu дарахтni ko'rib tashkilotga ega bo'ladi, va Poincincincha qanchalik 50 dimension imkoniyatlariga ega bo'ladi. Biz shunday ishlarining muhimligini kamaytirish mumkin, biz juda kichkina o'smirlik moslamalarda hyperbolik chegarasining muhimligini kamaytirish mumkin. Lekin ularning vazifasini katta ishga ega bo'lganda, biz bu yerda Euklida va hyperbolik kuchlari орасида yangilangan va yaxshi qisqatlarni o'rganish uchun.", 'vi': 'Nickel và Kiela (Des7) có một phương pháp mới để nhúng các nút cây vào dạ dày Poincare, và cho rằng những sự nhúng ép siêu ma này có hiệu quả hơn nhiều so với sự nhúng vào các nút Euclide tại các biểu đồ cấu trúc phân rộng lớn, theo cấu trúc thứ tự như WordNet danh từ cây siêu năng. Đây là đặc biệt trong các kích thước thấp (Nickel và Kiela, thậm chí là Aw7, Bàn 1). Trong công trình này, chúng tôi cố gắng mô phỏng thí nghiệm của họ về việc tác dụng và tái tạo các danh từ WordNet siêu âm. Chống lại những gì họ báo cáo, chúng tôi thấy sự nhúng chàm có thể đại diện cho cây này ít nhất cũng như sự nhúng chàm, khi được cho phép ít nhất là 50 chiều. Chúng tôi lưu ý rằng điều này không làm giảm tầm quan trọng của công việc của họ dựa vào khả năng gây ấn tượng của việc phù hợp với các thiết lập cấp thấp. Tuy nhiên, dựa trên tầm ảnh hưởng lớn của công việc của họ, mục tiêu của chúng ta ở đây là trình bày một so sánh cập nhật và chính xác hơn giữa sự tác nhân Euclide và hypogolic.', 'bg': 'Никел и Кийла (2017) представят нов метод за вграждане на дървесни възли в топката Поанкар и предполагат, че тези хиперболични вграждания са далеч по-ефективни от евклидските вграждания при вграждане на възли в големи, йерархично структурирани графики като хипернимното дърво на съществителните. Това важи особено за ниски размери (Никел и Кийла, 2017, Таблица 1). В тази работа се стремим да възпроизведем техните експерименти за вграждане и реконструкция на хипернимичната графика на съществителните в WordNet. Противно на това, което съобщават, откриваме, че евклидските вграждания са в състояние да представят това дърво поне както и вгражданията на Поанкар, когато са разрешени поне 50 измерения. Отбелязваме, че това не намалява значението на тяхната работа предвид впечатляващото представяне на хиперболични вграждания в много нискоизмерни условия. Въпреки това, предвид широкото влияние на тяхната работа, нашата цел тук е да представим актуализирано и по-точно сравнение между евклидското и хиперболичното вграждане.', 'nl': 'Nikkel en Kiela (2017) presenteren een nieuwe methode voor het insluiten van boomknooppunten in de Poincare bal, en suggereren dat deze hyperbolische insluitingen veel effectiever zijn dan euclidische insluitingen bij het insluiten van knooppunten in grote, hiërarchisch gestructureerde grafieken zoals de WordNet naamwoorden hyperniemieboom. Dit geldt vooral voor lage afmetingen (nikkel en Kiela, 2017, tabel 1). In dit werk proberen we hun experimenten over het inbedden en reconstrueren van de WordNet naamwoorden hyperniemiegrafiek te reproduceren. In tegenstelling tot wat ze rapporteren, vinden we dat euclidische insluitingen in staat zijn om deze boom minstens zo goed te vertegenwoordigen als Poincare insluitingen, wanneer toegestaan minstens 50 dimensies. We merken op dat dit de betekenis van hun werk niet vermindert, gezien de indrukwekkende prestaties van hyperbolische embeddings in zeer laagdimensionale omgevingen. Echter, gezien de grote invloed van hun werk, is ons doel hier een geactualiseerde en nauwkeurigere vergelijking te presenteren tussen de euclidische en hyperbolische inbeddingen.', 'da': 'Nikkel og Kiela (2017) præsenterer en ny metode til indlejring af træknuder i Poincare-kuglen, og antyder, at disse hyperboliske indlejringer er langt mere effektive end euklidiske indlejringer til indlejring af knuder i store, hierarkisk strukturerede grafer som WordNet substantiver hypernymy-træet. Dette gælder især i lave dimensioner (nikkel og Kiela, 2017, tabel 1). I dette arbejde søger vi at gengive deres eksperimenter med indlejring og rekonstruktion af WordNet substantiv hypernymy graf. I modsætning til hvad de rapporterer, finder vi, at euklidiske indlejringer er i stand til at repræsentere dette træ mindst lige så godt som Poincare indlejringer, når det er tilladt mindst 50 dimensioner. Vi bemærker, at dette ikke mindsker betydningen af deres arbejde i betragtning af den imponerende ydeevne af hyperboliske indlejringer i meget lavdimensionelle indstillinger. Men i betragtning af den store indflydelse af deres arbejde, vores mål her er at præsentere en opdateret og mere præcis sammenligning mellem euklidisk og hyperbolsk indlejring.', 'de': 'Nickel und Kiela (2017) stellen eine neue Methode zur Einbettung von Baumknoten in die Poincare-Kugel vor und legen nahe, dass diese hyperbolischen Einbettungen weitaus effektiver sind als euklidische Einbettungen bei Einbettungsknoten in große, hierarchisch strukturierte Graphen wie den WordNet-Substantiven-Hypernymibaum. Dies gilt besonders für niedrige Abmessungen (Nickel und Kiela, 2017, Tabelle 1). In dieser Arbeit versuchen wir, ihre Experimente zur Einbettung und Rekonstruktion des WordNet-Nomen-Hypernymigraphen zu reproduzieren. Im Gegensatz zu dem, was sie berichten, finden wir, dass euklidische Einbettungen in der Lage sind, diesen Baum mindestens genauso gut zu repräsentieren wie Poincare Einbettungen, wenn mindestens 50 Dimensionen erlaubt sind. Wir stellen fest, dass dies die Bedeutung ihrer Arbeit angesichts der beeindruckenden Leistung hyperbolischer Einbettungen in sehr niederdimensionalen Umgebungen nicht mindert. Angesichts des großen Einflusses ihrer Arbeit ist es jedoch unser Ziel, einen aktualisierten und genaueren Vergleich zwischen den euklidischen und hyperbolischen Einbettungen zu präsentieren.', 'hr': 'Nikel i Kiela (2017) predstavljaju novu metodu za uključenje čvorova drveta u Poincare loptu i sugeriraju da su te hiperboličke uključenje mnogo učinkovitije od Euclideanskih uključenja u velike, hijerarhički strukturirane grafike poput WordNet imena hipernimsko drvo. To je posebno istina u niskim dimenzijama (Nickel i Kiela, 2017, tablica 1). U ovom poslu tražimo reprodukciju njihovih eksperimenata na ugrađenju i rekonstrukciji grafa WordNeta imena hipernimu. Prema onome što prijavljuju, nalazimo se da su Euclidean ugrađenje u stanju predstavljati ovo drvo najmanje kao i Poincare ugrađenje, kad je dozvoljeno najmanje 50 dimenzija. To ne smanjuje značajnost njihovog rada s obzirom na impresivnu učinku hiperboličkih ugrađenja u vrlo niskom dimenzionalnom postavku. Međutim, s obzirom na širok utjecaj njihovog rada, naš cilj je da predstavimo aktualiziranu i precizniju usporedbu između Euklideana i hiperboličkih ugrađenja.', 'ko': 'Nickel과 Kiela(2017)는 방글라데시 볼에 나무 노드를 삽입하는 새로운 방법을 제시했고WordNet 명사 초명 트리와 같은 대형 차원 구조도에 노드를 삽입할 때 이런 쌍곡 삽입은 오클리드보다 훨씬 효과적이라고 지적했다.저차원 상황에서 특히 그렇다(Nickel and Kiela, 2017년, 표1).이 작업에서, 우리는WordNet 명사 초의도를 삽입하고 재구성하는 실험을 시도했다.그들의 보고서와 반대로, 우리는 적어도 50차원을 허용할 때, 유클리드의 삽입은 이 나무를 나타낼 수 있으며, 적어도 방글라데시의 삽입과 같다는 것을 발견했다.우리는 극저차원 환경에 쌍곡이 박혀 있는 인상적인 성능을 감안하면 그들의 업무의 중요성을 약화시키지 않았다는 것을 알아차렸다.그러나 그들의 업무의 광범위한 영향을 감안하여 우리의 목표는 유클리드 삽입과 쌍곡 삽입 사이를 갱신하고 더욱 정확하게 비교하는 것이다.', 'fa': 'نیکل و کیلا (۲۰۱۷) یک روش جدید برای وارد کردن گرافهای درخت در توپ پوینکار نشان می\u200cدهند و پیشنهاد می\u200cدهند که این وارد کردن هیپر\u200cبولیک بیشتر از وارد کردن گرافهای یوکلیدان در گرافهای بزرگ و زیر نظامی ساخته شده مانند درخت WordNet هیپرنیمی نامیده می\u200cشود. این مخصوصا در اندازه\u200cهای پایین حقیقت است (نیکل و کیلا، 2017، میز ۱). در این کار، ما تلاش می\u200cکنیم آزمایش\u200cهایشان را در مورد پیدا کردن و دوباره ساختن گراف هوپر نیمی نام WordNet بازسازی کنیم. بر خلاف آنچه گزارش می\u200cدهند، ما پیدا می\u200cکنیم که انبوه\u200cهای یوکلیدین می\u200cتوانند حداقل این درخت و همچنین انبوه\u200cهای Poincare را نشان دهند، وقتی حداقل ۵۰ بعدی اجازه می\u200cدهند. ما توجه می کنیم که این تعریف کارشان را کم نمی کند با توجه به فعالیت تحت تاثیر قرار دهنده\u200cای از انجمن هایربولیک در تنظیمات بسیار کم بعدی. با این حال، با وجود تأثیر عملشان، هدف ما اینجاست که یک مقایسه جدید و دقیق تری بین یوکلیدان و حامله های هیپر بولیک را پیشنهاد کنیم.', 'sw': 'Nickel na Kiela (2017) wanaweka mbinu mpya ya kutengeneza viwanja vya mti katika mpira wa Poincare, na anapendekeza kuwa matumizi haya ya ukame yanakuwa na ufanisi zaidi ya viwanja vya Euclid katika viwanja vikubwa vya upepo, vilivyoundwa picha kama vile mti wa WordNet unaotumia sura. Hii ni kweli kwa upande wa chini (Nickel na Kiela, 2017, Tabell 1). Katika kazi hii, tunajaribu kurudisha majaribio yao kuhusu kuingiza na kujenga tena picha ya upya ya WordNet. Hebu kile wanachoripoti, tunagundua kuwa mabango ya watu wa Euclid wanaweza kuwakilisha mti huu angalau kama vile ilivyoingizwa na Poincare, ambapo huruhusu angalau kwa vipengele 50. Tunajua kwamba hii haipunguzi umuhimu wa kazi zao kwa sababu ya utendaji wa matumizi ya vifaa vya umeme katika mazingira ya chini sana. Hata hivyo, kwa kuwa na ushawishi mkubwa wa kazi zao, lengo letu hapa ni kuleta ulinganisha habari mpya na sahihi kati ya viwanja vya Euclid na vifaa vya ukame.', 'id': 'Nickel dan Kiela (2017) mempersembahkan metode baru untuk memasukkan node pohon di bola Poincare, dan menyarankan bahwa penyembahan hiperbolik ini jauh lebih efektif daripada penyembahan Euclidean pada penyembahan node di grafik besar, secara hierarkis strukturasi seperti pohon hipernimi nama WordNet. Ini terutama benar dalam dimensi rendah (Nickel dan Kiela, 2017, Tabel 1). Dalam pekerjaan ini, kami berusaha untuk mereproduksi eksperimen mereka tentang memasukkan dan merekonstruksi grafik hipernimi nama WordNet. Berlawan dengan apa yang mereka laporkan, kami menemukan bahwa penerbangan Euclidean dapat mewakili pohon ini setidaknya juga penerbangan Poincare, ketika diizinkan setidaknya 50 dimensi. We note that this does not diminish the significance of their work given the impressive performance of hyperbolic embeddings in very low-dimensional settings.  Namun, mengingat pengaruh yang luas dari pekerjaan mereka, tujuan kami di sini adalah untuk mempersembahkan perbandingan yang terbaru dan lebih akurat antara Euclidean dan penyebab hiperbolik.', 'tr': 'Nikel we Kiela (2017) Poincar topunda agaç düğümlerini integral etmek üçin täze bir täze yöntemi görkez we bu hiperbolik düzümleriniň uly, iýerarhiýa guralýan grafikleriň WordNet ýaly hipernimi agajynda ýeterlik taýýarlandygyny maslahat berýär. Bu elbette düşük ölçülerde dogry (Nikel we Kiela, 2017, täblisa1). Bu işde, WordNet adını hipernimi grafiğinde tekrar döretmek ve tekrar düzenlemek üzere deneylerini tekrar etmek istiyoruz. Eýklideki baglaýyşlaryň hasaplanyna seredeniňe görä, bu agajyň iň azyndan 50 ölçü mümkin bolup biler. Biz bu olaryň işiniň etkileşimli noktalarynda hiperbolik integrlerin etkileşimli täsirini azaltmaz. Ýöne, bu ýerde biziň maksadymyz Euklidek we hiperbolik baglaşyklaryň arasynda düzgün bir şekilde çykarmakdyr.', 'am': 'ኒክሌል እና ኪላ (2017) በፖንቢካር አበባ ውስጥ የዛፍ ኖዶች አዲስ ማሰናከል አቅራቢያ መንገድን አቀረቡ፤ እነዚህም አፍሪባዊ አካባቢዎች የኢዩክሊድ አካባቢዎች በተለይ፣ በአፍሪካዊ፣ እንደWordNet አፍሬናዊ ዛፍ በሚያቋርጡ አካባቢዎች ላይ የተሻሉ ናቸው፡፡ ይህም በተለየ ትንሽ ሽፋን ውስጥ እውነተኛ ነው (ኒክkel እና ኪela, 2017, ገበታ 1) በዚህ ሥራ የቃላትን አፍሪካዊ ግልጾችን ለመግለጽ እና መግለጽ ይፈልጋለን፡፡ የኢዩክሊድ አካባቢዎች የዚህን ዛፍ ማሳየት እንዲችሉ እና ፖንቲካ በተፈቀደ ጊዜ ምናልባት 50 እውቀት እንዲችሉ እናገኛለን፡፡ ይህ የሥራቸውን ማስታወቂያ የሚያጎድል እንደሆነ እናስታውቃለን፡፡ ነገር ግን የሥራቸውን ስፋት አብልጦ በመጠየቅ፣ የዚህ ስልጣን በኤውሎጂ እና በኤፍሬቦሊክ ክፍሎች መካከል አሻራጅ እና በጣም እርግጠኛ ትክክል ማሳየት ነው፡፡', 'af': "Nikkel en Kiela (2017) voorstel 'n nuwe metode vir inbêring van boom nodes in die punk bal, en voorstel dat hierdie hiperboliese inbêdings veel meer effektief is as Euclidean inbêdings by inbêring nodes in groot, hierarkies struktureerde graaf soos die WordNet noum hypernymy boom. Hierdie is veral waar in lae dimensies (Nickel en Kiela, 2017, Tabel 1). In hierdie werk soek ons om hul eksperimente op die inbêring en herkonstruksiering van die WordNet naam hipernimi graf te herstel. Telling tot wat hulle raporteer, vind ons dat Euclidean inbêding kan voorstel hierdie boom ten minste as ook Poincare inbêding, wanneer toegelaat is ten minste 50 dimensies. Ons nota dat hierdie nie die betekening van hul werk verklein nie gegee het dat die inpresieële prestasie van hiperboliese inbêdings in baie lae-dimensie instellings gegee het nie. Maar, gegee die wyde influens van hul werk, is ons doel hier om 'n opdateerde en meer presies vergelyking tussen die Euklidean en hiperboliese inbêdings te voorsien.", 'az': 'Nickel və Kiela (2017) Poincare topunda a ğac düyünü in şa etmək üçün yeni bir yolu göstərər və bu hiperbolik inşalları, WordNet kimi böyük, hiyerarhiqli inşallarda olan düyünü yerləşdirmək üçün Euclidean inşallarından daha etkilidir. Bu özellikle düşük ölçülərdə doğrudur (Nickel and Kiela, 2017, Table 1). Bu işlərdə, WordNet adını hipernimi grafı inşa etmək və yenidən inşa etmək üçün onların təcrübələrini yenidən inşa etmək istəyirik. Onların bildirdiklərinə qarşı, Euclidean inşalları bu ağacın ən azından və Poincare inşallarını göstərə biləcəyini görürük ki, bu ağacı ən az 50 ölçüdə imkansız olur. Bu onların çalışmalarının çox düşük ölçülük ayarlarında hiperbolik inbinglərin etkileyici performansını əskiltməz. Ancaq, onların işinin geniş təsirlərinə görə, bizim amacımız Euclidean və hiperbolik inbinglərin arasında yenilənmiş və daha doğru bir müqayisədə göstərməkdir.', 'cs': 'Nikl a Kiela (2017) představují novou metodu vkládání uzlů stromů do Poincare koule a naznačují, že tyto hyperbolické vložení jsou mnohem efektivnější než euklidové vložení při vložení uzlů do velkých hierarchicky strukturovaných grafů, jako je například hypernymický strom WordNet. To platí zejména v nízkých rozměrech (nikl a Kiela, 2017, tabulka 1). V této práci se snažíme reprodukovat jejich experimenty na vkládání a rekonstrukci hypernymického grafu WordNet podstatných jmen. Na rozdíl od toho, co hlásí, zjišťujeme, že euklidové vložení jsou schopny reprezentovat tento strom alespoň stejně jako Poincare vložení, pokud je povoleno alespoň 50 dimenzí. Poznamenáváme, že to nesnižuje význam jejich práce vzhledem k impozantnímu výkonu hyperbolických vložení ve velmi nízko-dimenzionálních prostředích. Avšak vzhledem k širokému vlivu jejich práce je naším cílem představit aktualizované a přesnější srovnání mezi euklidovými a hyperbolickými vloženími.', 'bs': 'Nikel i Kiela (2017) predstavljaju novu metodu za uključenje čvorova drveta u Poincare loptu i sugeriraju da su te hiperboličke uključenje mnogo učinkovitije od ugrađenja Euklideana na ugrađenja čvorova u velikim, hijerarhički strukturovanim graficama poput WordNet naziva hipernimsko drvo. To je posebno istina u niskim dimenzijama (Nickel i Kiela, 2017, tablica 1). U ovom poslu tražimo da reproduktujemo njihov eksperiment na ugrađenju i rekonstrukciji grafa WordNeta imena hipernimno. Protiv onoga što prijavljuju, našli smo da su Euclidean ugrađenja u stanju predstavljati ovo drvo najmanje kao i ugrađenje Poincare, kad je dozvoljeno najmanje 50 dimenzija. To ne smanjuje značajnost njihovog rada s obzirom na impresivnu učinku hiperboličkih ugrađenja u vrlo niskom dimenzionalnom postavku. Međutim, s obzirom na širok uticaj njihovog rada, naš cilj je da predstavimo aktualiziranu i precizniju usporedbu između Euklideana i hiperboličkih ugrađenja.', 'et': 'Nickel ja Kiela (2017) tutvustavad uut meetodit puusõlmede paigaldamiseks Poincare palli ja viitavad, et need hüperboolsed manustamised on palju efektiivsemad kui euklide manustamised suurtes hierarhiliselt struktureeritud graafikutes, nagu WordNeti nimisõnad hüpernüümipuu. See kehtib eriti madalate mõõtmete puhul (Nikkel ja Kiela, 2017, tabel 1). Selles töös püüame reprodutseerida nende eksperimente WordNeti nimisõnade hüpernüümiagraafiku manustamisel ja rekonstrueerimisel. Vastupidiselt sellele, mida nad teatavad, leiame, et Euklidean manustamised on võimelised esindama seda puud vähemalt sama kui Poincare manustamised, kui lubatud vähemalt 50 dimensiooni. Me märgime, et see ei vähenda nende töö tähtsust, arvestades hüperboolsete manustamiste muljetavaldavat jõudlust väga madalamõõtmelistes tingimustes. Kuid arvestades laia mõju nende töö, meie eesmärk siin on esitada ajakohastatud ja täpsem võrdlus Euklidean ja hüperboolsed embeddings.', 'sq': 'Nikel dhe Kiela (2017) paraqesin një metodë të re për përfshirjen e nyjeve të pemëve në topin Poincare, dhe sugjerojnë se këto përfshirje hiperbolike janë shumë më efektive se përfshirjet euklideane në përfshirjen e nyjeve në grafikë të mëdha, të strukturuar hierarkikisht si druri hipernimi i emrave WordNet. Kjo është veçanërisht e vërtetë në dimensione të ulta (Nikel dhe Kiela, 2017, Tabela 1). Në këtë punë, ne kërkojmë të riprodhojmë eksperimentet e tyre mbi përfshirjen dhe rindërtimin e emrave WordNet grafik hipernimi. Counter to what they report, we find that Euclidean embeddings are able to represent this tree at least as well as Poincare embeddings, when allowed at least 50 dimensions.  We note that this does not diminish the significance of their work given the impressive performance of hyperbolic embeddings in very low-dimensional settings.  Megjithatë, duke marrë parasysh ndikimin e gjerë të punës së tyre, qëllimi ynë këtu është të paraqesim një krahasim të përditësuar dhe më të saktë midis përfshirjeve euklide dhe hiperbolike.', 'bn': 'নিকেল এবং কিয়েলা (২০১৭) পোইনিকার বোলে গাছের নোডগুলোকে প্রবেশ করার একটি নতুন পদ্ধতি উপস্থাপন করেছেন এবং পরামর্শ দিচ্ছেন যে এই হাইপার্বোলিক বিষয়গুলো ইউক্লিডিয়ান প্রবেশ করার চেয়ে বেশী কার্য এটা বিশেষ করে নীচের মানে সত্যি (নিকেল এবং কিয়েলা, ২০১৭, টেবিল ১)। এই কাজে আমরা তাদের পরীক্ষা পুনরুদ্ধার করতে চাই ওয়ার্ড নেটের হাইপারেনিমি গ্রাফ তৈরি করার জন্য। তারা যা রিপোর্ট করেছে তা নিয়ে গণনা করেছে, আমরা দেখতে পাচ্ছি যে ইউক্লিডিয়ার প্রবেশাধিকারীরা অন্তত এই গাছের প্রতিনিধিত্ব করতে পারে এবং পো আমরা লক্ষ্য করেছি যে এটা তাদের কাজের গুরুত্বপূর্ণ কমে যাচ্ছে না যেহেতু হাইপারবোলিক বিভিন্ন সংস্থাগুলোর আকর্ষণীয় প্রদর্শনের তবে তাদের কাজের ব্যাপারে প্রভাব প্রদান করে আমাদের লক্ষ্য হচ্ছে ইউক্লিডিয়ান এবং হাইপার্বোলিক বিভিন্ন সংস্থার মধ্যে একটি আপডেট এবং আরো', 'hy': 'Նիկլելը և Կիելան (2017) ներկայացնում են Փոունկերի գնդակի ծառի հանգույցների ներգրավման նոր մեթոդ և առաջարկում են, որ այս հիպերբոլիկ ներգրավումները շատ ավելի արդյունավետ են, քան Եուկլիդիայի ներգրավումները մեծ, հիերարխիկապես կառուցված գրաֆիկներում, ինչպիսիք են WordNet անունների հիպերնիմիայի ծառ Սա հատկապես ճիշտ է ցածր չափերում (Նիկել և Կիելա, 2017 թվականը, 1. աղյուսակը): Այս աշխատանքում մենք փորձում ենք վերարտադրել իրենց փորձերը WordNet անունների հիպերնիմիայի գրաֆիկի ներառման և վերակառուցման վրա: Հակառակ նրանց զեկույցներին, մենք հայտնաբերում ենք, որ էուկլիդիայի ներդրումները կարող են ներկայացնել այս ծառը առնվազն, ինչպես նաև պոունկցիայի ներդրումները, երբ թույլ է տալիս առնվազն 50 չափով: We note that this does not diminish the significance of their work given the impressive performance of hyperbolic embeddings in very low-dimensional settings.  However, given the wide influence of their work, our aim here is to present an updated and more accurate comparison between the Euclidean and hyperbolic embeddings.', 'fi': 'Nickel ja Kiela (2017) esittelevät uuden menetelmän puusolmujen upottamiseksi Poincare-palloon ja ehdottavat, että nämä hyperboliset upotukset ovat paljon tehokkaampia kuin euklidialaiset upotukset isojen hierarkisesti jäsenneltyjen graafien, kuten WordNet-substantiivien hypernyymipuun, solmujen upottamisessa. Tämä pätee erityisesti pieniin mitoihin (Nikkeli ja Kiela, 2017, taulukko 1). Tässä työssä pyrimme toistamaan heidän kokeilujaan WordNet substantiivien hypernyymikäyrän upottamisesta ja rekonstruoinnista. Toisin kuin mitä he raportoivat, huomaamme, että Euklidean upotukset pystyvät edustamaan tätä puuta ainakin samoin kuin Poincare upotukset, kun sallitaan vähintään 50 ulottuvuutta. Huomautamme, että tämä ei vähennä heidän työnsä merkitystä, kun otetaan huomioon hyperbolisten upotusten vaikuttava suorituskyky hyvin pieniulotteisissa olosuhteissa. Kuitenkin ottaen huomioon laaja vaikutus heidän työnsä, meidän tavoitteena tässä on esittää päivitetty ja tarkempi vertailu Euklidean ja hyperbolic upotukset.', 'ca': "Nickel i Kiela (2017) presenten un nou mètode d'incorporació de nodos d'arbre a la bola Poincare, i suggereixen que aquestes incorporacions hiperbòliques són molt més eficaces que les incorporacions euclídeas a incorporar nodos en grans gràfics jeràrquicament estructurats com l'arbre hipernimògic dels noms WordNet. Això és especialment cert en baixes dimensions (Nikel i Kiela, 2017, taula 1). En aquest treball busquem reproduir els seus experiments en incorporar i reconstruir el gràfic d'hipernim dels noms WordNet. Contrariament al que diuen, trobem que les incorporacions euclídiques són capaços de representar aquest arbre almenys com també les incorporacions Poincare, quan es permeten almenys 50 dimensions. Notem que això no diminui la significació de la seva feina, dada l'impressionant rendiment d'incorporacions hiperbòliques en ambients de baixa dimensió. However, given the wide influence of their work, our aim here is to present an updated and more accurate comparison between the Euclidean and hyperbolic embeddings.", 'jv': 'FindOK Iki ki ngomong tenan kanggo dimensi ambang (NIKEL lan Kila, 2011, Tabel 1). Nang barêng-barêng iki, kita bukên nggawe perintaksi barêng-barêng lan nggawe barang nggawe lan wiintakno nggawe word net barang ipernimiy graf. Counter to their report, we find that YuClide embedding is able to represent this trumpet at the bottom of the pageStock label, navigation Awakdhéwé, digambut kuwi nggawe barang akeh penggunaké karo ngono nggawe barang langgar barang langgar-akeh banjur. Nanging, ono nggawe kahan wong liyane karo hal-wong liyane, dadi awak dhéwé iki dadi sing nyenggawe lan ijol-ijolan sing dikarepaké karo épaké awak dhéwé karo épaké sing bakal terus tambah karo épaké sing nyenggawe karo épaké.', 'he': 'ניקל וקיילה (2017) מציגים שיטה חדשה להכניס קשרי עצים בכדור פוינקר, ולהציע שהקשרים היפרבוליים האלה הרבה יותר יעילים מהקשרים יוקלדיים להכניס קשרים בגרפים גדולים ומבנים היירארכית כמו עץ היפרנימיה בשמות WordNet. זה נכון במיוחד במימדים נמוכים (ניקל וקיילה, 2017, שולחן 1). בעבודה הזו, אנו מנסים לשחזר את הניסויים שלהם על הכניסה ולבניית מחדש את גרף ההיפרנימיה של השמות WordNet. בניגוד למה שהם מדווחים, אנו מוצאים שהתוכניות יוקלדיות יכולות לייצג את העץ הזה לפחות כמו תוכניות Poincare, כאשר מותר לפחות 50 מימדים. אנו מבחינים שזה לא מפחיד את משמעותו של העבודה שלהם בהתחשב ביצועים מרשים של תוכניות היפרבוליות במסגרות נמוכות מאוד. בכל אופן, בהתחשב בהשפעה רחבה של עבודתם, המטרה שלנו כאן היא להציג שיווך מעודכן יותר מדויק בין האיוקלידאים וההיפרבוליים.', 'ha': "Nickel da Killa (2017) na zo da wata hanyoyi na embedded itãce nodes in the Poinare ball, kuma yana shawarar da waɗannan hierbonic embedding a ne mafi mai amfani da mafi yawanci daga Euclodi da ke shiga nodes cikin babban, hierirchically-founded grafiks kamar the wordNet na nufi. This is especially true in low dimensions (Nickel and Kiela, 2017, Table 1).  Daga wannan aikin, Munã nufin mu dubuɗe jarrabayensu a cikin shirin da kuma za'a sami karatun na surori-surori. Ana lissafa zuwa abin da suke bãyar da lãbãri, za mu gane cewa bajaran Euclodi na iya iya iya lissafa wannan itãciyar da damu da Poincan, idan an yarda da daidai hanyoyin 50. Tuna ganin cẽwa, wannan bã zai rage muhimmin aikinsu da aka sami mai kyãwon saukarwa da ke cikin tsari masu ƙaranci. Kayya, ko da yã yi amfani ga aikinsu, kanmu na so ne a nan, ka sami wani na'ura da taƙaitacce a tsakanin Euclodi da hiperboni.", 'sk': 'Nikkel in Kiela (2017) predstavljata novo metodo za vgradnjo drevesnih vozlišč v Poincarjevo kroglo in predlagata, da so te hiperbolične vdelave veliko učinkovitejše od evklidskih vdelav pri vgradnji vozlišč v velike, hierarhično strukturirane grafe, kot je hipernimsko drevo WordNet samostalnikov. To še posebej velja za nizke dimenzije (Nikelj in Kiela, 2017, Tabela 1). V tem delu želimo reproducirati njihove poskuse na vdelavi in rekonstrukciji hipernimskega grafa WordNet samostalnikov. V nasprotju s tem, kar poročajo, ugotavljamo, da evklidske vdelave lahko predstavljajo to drevo vsaj tako kot Poincarjeve vdelave, če je dovoljeno vsaj 50 dimenzij. Ugotavljamo, da to ne zmanjšuje pomena njihovega dela glede na impresivno zmogljivost hiperboličnih vdelav v zelo nizkodimenzionalnih okoljih. Glede na širok vpliv njihovega dela pa je naš cilj predstaviti posodobljeno in natančnejšo primerjavo evklidskih in hiperboličnih vdelav.', 'bo': 'Nickel and Kiela (2017) present a new method for embedding tree nodes in the Poincare ball, and suggest that these hyperbolic embeddings are far more effective than Euclidean embeddings at embedding nodes in large, hierarchically structured graphs like the WordNet nouns hypernymy tree. འདི་ལྟ་བུའི་ཆེ་ཆུང་ལ་ཉུང་བའི་ནང་དུ་ཁྱད་པར་བདེན་པོ་རེད། ང་ཚོས་ཀྱི་ལས་འགན་འདི་ལྟར་ཁོང་ཚོའི་བརྟག་ཞིག་གསར་བསྐྲུན་འབད་བྱེད་ཀྱི་ཡོད། Counter to what they report, we find that Euclidean embeddings are able to represent this tree at least as well as Poincare embeddings, when allowed at least 50 dimensions. འུ་ཅག་གིས་འདིས་ཁོང་ཚོའི་ལས་འགན་གྱི་གསལ་བཤད་ཀྱི་རྐྱེན་ཚད་ཉུང་བའི་སྒྲིག་སྟངས་ལ་ཡི་གྲངས་སུ་མཐུན་རྐྱེན་ཚད་ཉུང་བའི་ཡི ཡིན་ནའང་། འདིའི་དམིགས་ཡུལ་ནི་ཁོང་ཚོའི་ལས་ཀ་ཡུལ་ཆེན་པོ་ཞིག་གིས་Euclidean དང་hyperbolic embeddings་གཉིས་ཀྱི་མཐུན་སྒྲིག་འབད་བ་ཡིན་པས།'}
{'en': 'The Highs and Lows of Simple Lexical Domain Adaptation Approaches for Neural Machine Translation', 'ar': 'الارتفاعات والانخفاضات في مناهج التكيف المعجمي البسيط للمجال للترجمة الآلية العصبية', 'fr': "Les hauts et les bas des approches simples d'adaptation du domaine lexical pour la traduction automatique neuronale", 'es': 'Los altibajos de los enfoques simples de adaptación de dominios léxicos para la traducción automática neuronal', 'pt': 'Os altos e baixos das abordagens de adaptação de domínio lexical simples para tradução automática neural', 'ja': '神経機械翻訳のための単純な言語ドメイン適応アプローチの高低', 'zh': '神经机器翻译之简词汇域应法之高潮低谷', 'ru': 'Высокие и низкие значения простых подходов к адаптации лексических доменов для нейронного машинного перевода', 'hi': 'तंत्रिका मशीन अनुवाद के लिए सरल लेक्सिकल डोमेन अनुकूलन दृष्टिकोण के Highs और Lows', 'ga': 'Buaicphointí agus Míbhuntáistí na gCur Chuige Simplí um Oiriúnú Fearainn Foclóra don Aistriúchán Meaisín Néarach', 'hu': 'Az egyszerű lexikai tartomány adaptációs megközelítések magasságai és csökkenései a neurális gépi fordításhoz', 'it': 'Gli alti e i bassi dei semplici approcci di adattamento del dominio lessico per la traduzione automatica neurale', 'kk': 'Невралды машинаны аудару үшін қарапайым лексикалық домен адаптациясының жоғары және төмен', 'ka': 'Name', 'el': 'Τα ύψη και τα χαμηλά των απλών προσεγγίσεων προσαρμογής Lexical Domain για τη νευρωνική μηχανική μετάφραση', 'lt': 'Neuralinių mašinų vertimo metodai, taikomi aukščiausiems ir mažesniems paprastų leksinių domenų pritaikymo metodams', 'mk': 'Највисоките и ниските од едноставните пристапи за адаптација на лексикалниот домен за преведување на невралните машини', 'ms': 'Pendekatan Penyesuaian Domain Leksikal Sederhana Tinggi dan Rendah untuk Terjemahan Mesin Neural', 'ml': 'ലളിതമായ ലെക്സിക്കല്\u200d ഡോമെന്\u200d അഡാപ്റ്റേഷന്\u200d നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിനുള്ള ഉയര്\u200dച്ചയും കുറവുകള', 'mt': 'L-approċċi għoljin u baxxi ta’ adattament sempliċi għad-dominju lexiku għat-traduzzjoni tal-makkinarju newrali', 'mn': 'Цөмийн машин хөгжүүлэхийн тулд хамгийн өндөр болон бага хэмжээний лексикийн холбоотой адаптацийн тулд', 'ro': 'Cele mai înalte și scăzute abordări ale adaptării simple a domeniului lexical pentru traducerea automată neurală', 'pl': 'Najwyższe i upadki prostych podejść do adaptacji domen leksykalnych dla neuronowego tłumaczenia maszynowego', 'no': 'Høgd og låg av enkle leksiske domeneadaptasjonsbehandlingar for neuralmaskinsomsetjing', 'so': 'Highs and Lows of Simple Lexical Domain Adaptation Approaches for Translation of Neural machine', 'si': 'Name', 'sv': 'De högsta och lägsta metoderna för enkel Lexical Domain anpassning för neural maskinöversättning', 'sr': 'Visoki i niski prosti leksički pristup adaptaciji domena za neurološki prevod mašine', 'ta': 'Name', 'ur': 'نئورل ماشین ترجمہ کے لئے ساده لکسکسیکل ڈومین اڈپٹیٹ کے مطابق اچھے اور کم', 'uz': 'Name', 'vi': 'The Highs and Lows of Simple Lexical Domain Adaptation approaches for Neural Machine Translation', 'bg': 'Върховете и ниските нива на простите подходи за адаптиране на лексикалните домейни за неврален машинен превод', 'da': 'De højeste og laveste muligheder for enkle tilpasningsmetoder til Lexical Domain til Neural Machine Translation', 'hr': 'Visoki i niski pristup jednostavnim leksičkim domenama prilagodbe za neurološki prevod strojeva', 'nl': 'De hoogten en diepten van eenvoudige benaderingen van Lexical Domain Adaptation voor Neural Machine Translation', 'de': 'Die Höhen und Tiefen einfacher Lexikal Domain Adaptation Ansätze für neuronale maschinelle Übersetzung', 'ko': '신경 기계 번역 중 단순 어휘역 적응 방법의 장단점', 'fa': 'ارتفاع و پایین ترجمه ماشین عصبی', 'sw': 'Mazungumzo na kupungua kwa ajili ya Tafsiri ya Mashine ya Kifaransa', 'tr': 'Neural Makina Çevirmek üçin Beýik we Açyk Basit Leksik Saýlaw Aklaplar', 'sq': 'Përqafimet më të larta dhe më të ulta të adaptimit të domenit të thjeshtë leksikal për përkthimin e makinës nervore', 'am': 'ቀላል ሊስክሲካል ዶሜን አዳaptation ለኔural machine ትርጉም', 'id': 'The Highs and Lows of Simple Lexical Domain Adaptation Approaches for Neural Machine Translation', 'af': 'Name', 'az': 'Nöral Makina Çevirməsi üçün ən yüksək və düşük Basit Lexical Domain Adjustasyon Yaxınlıqları', 'hy': 'Նյարդային մեքենայի թարգմանման համար պարզ լեքսիկական բնագավառի ադապտացիայի բարձր և ցածր մոտեցումները', 'bn': 'সাধারণ লেক্সিক্যাল ডোমেইন পরিচালনার উচ্চতা এবং কম নিউরাল মেশিন অনুবাদের জন্য', 'bs': 'Visoki i niski jednostavni pristup adaptaciji domena za neurološki prevod strojeva', 'ca': "Els enfocaments més alts i baixos d'adaptació simple del domini lècsic per a la traducció de màquines neurals", 'cs': 'Výšky a úpadky jednoduchých přístupů k adaptaci Lexikální domény pro neuronový strojový překlad', 'fi': 'Yksinkertaisten Lexical Domain Adaptation Approaches for Neural Machine Translation', 'et': 'Lihtsate leksaalsete domeenide kohandamise lähenemisviiside kõrgemad ja madalad tasemed neuroaalse masintõlke jaoks', 'ha': 'KCharselect unicode block name', 'he': 'הגבוהה והנמוכה של גישות ההתאמה למשטרה לקסיקה פשוטות לתרגום מכונות נוירות', 'jv': 'politenessoffpolite"), and when there is a change ("assertive', 'sk': 'Najvišje in nizke vrednosti enostavnih pristopov za prilagajanje leksičnih domen za strojno prevajanje nevronov', 'bo': 'སྤྱིར་བཏང་ནུས་མེད་ལག་གི་སྤྱི་ཚོགས་ཀྱི་ཆེ་མཐོང་དང་ཉུང་བའི་ཁྲོད་ཚད།'}
{'en': 'Machine translation systems are vulnerable to domain mismatch, especially in a low-resource scenario. Out-of-domain translations are often of poor quality and prone to hallucinations, due to exposure bias and the decoder acting as a language model. We adopt two approaches to alleviate this problem : lexical shortlisting restricted by IBM statistical alignments, and hypothesis reranking based on similarity. The methods are computationally cheap and show success on low-resource out-of-domain test sets. However, the methods lose advantage when there is sufficient data or too great domain mismatch. This is due to both the IBM model losing its advantage over the implicitly learned neural alignment, and issues with subword segmentation of unseen words.', 'fr': "Les systèmes de traduction automatique sont vulnérables aux incohérences de domaines, en particulier dans un scénario à faibles ressources. Les traductions hors domaine sont souvent de mauvaise qualité et sujettes à des hallucinations, en raison du biais d'exposition et du décodeur agissant comme un modèle linguistique. Nous adoptons deux approches pour pallier ce problème\xa0: la présélection lexicale limitée par les alignements statistiques IBM et le reclassement des hypothèses basé sur la similitude. Les méthodes sont peu coûteuses en termes de calcul et réussissent sur des ensembles de tests hors domaine à faibles ressources. Cependant, les méthodes perdent leur avantage lorsqu'il y a suffisamment de données ou qu'il y a trop de discordance de domaines. Cela est dû à la fois au fait que le modèle IBM perd son avantage par rapport à l'alignement neuronal implicitement appris et à des problèmes de segmentation de sous-mots de mots invisibles.", 'pt': 'Os sistemas de tradução automática são vulneráveis à incompatibilidade de domínio, especialmente em um cenário de poucos recursos. Traduções fora do domínio geralmente são de baixa qualidade e propensas a alucinações, devido ao viés de exposição e ao decodificador atuando como modelo de linguagem. Adotamos duas abordagens para aliviar esse problema: listagem léxica restrita por alinhamentos estatísticos da IBM e reclassificação de hipóteses com base na similaridade. Os métodos são computacionalmente baratos e mostram sucesso em conjuntos de teste fora do domínio de poucos recursos. No entanto, os métodos perdem vantagem quando há dados suficientes ou incompatibilidade de domínio muito grande. Isso se deve ao fato de o modelo IBM perder sua vantagem sobre o alinhamento neural aprendido implicitamente e a problemas com a segmentação de subpalavras de palavras não vistas.', 'ar': 'أنظمة الترجمة الآلية عرضة لعدم تطابق المجال ، خاصة في سيناريو الموارد المنخفضة. غالبًا ما تكون الترجمات خارج المجال ذات جودة رديئة وعرضة للهلوسة ، بسبب تحيز التعرض وعمل وحدة فك التشفير كنموذج لغوي. نعتمد نهجين للتخفيف من هذه المشكلة: القائمة المختصرة المعجمية المقيدة بمحاذاة إحصائية لشركة IBM ، وإعادة تصنيف الفرضيات على أساس التشابه. الأساليب رخيصة من الناحية الحسابية وتظهر النجاح في مجموعات الاختبار خارج المجال منخفضة الموارد. ومع ذلك ، تفقد الأساليب ميزة عند وجود بيانات كافية أو عدم تطابق كبير جدًا في المجال. هذا يرجع إلى أن كلا من نموذج IBM يفقد ميزته على المحاذاة العصبية المكتسبة ضمنيًا ، والمشكلات المتعلقة بتجزئة الكلمات الفرعية للكلمات غير المرئية.', 'es': 'Los sistemas de traducción automática son vulnerables a la falta de coincidencia de dominios, especialmente en un escenario de bajos recursos. Las traducciones fuera del dominio suelen ser de mala calidad y propensas a alucinaciones, debido al sesgo de exposición y al descodificador que actúa como modelo de lenguaje. Adoptamos dos enfoques para aliviar este problema: la preselección léxica restringida por las alineaciones estadísticas de IBM y la reorganización de hipótesis basada en la similitud. Los métodos son computacionalmente baratos y muestran éxito en conjuntos de pruebas fuera del dominio de pocos recursos. Sin embargo, los métodos pierden ventaja cuando hay suficientes datos o hay una falta de coincidencia de dominio demasiado grande. Esto se debe tanto a que el modelo de IBM pierde su ventaja sobre la alineación neuronal aprendida implícitamente como a problemas con la segmentación de subpalabras de palabras no vistas.', 'zh': '机器翻译统易受域不匹,尤在资源匮乏。 域外译常质差,且以暴露偏差解码器充言模形而易生幻觉。 臣等以二术缓之:IBM 计齐限者词法候选列表,及相似性之假设复序。 其法甚贱,且试于低资源域外集上示成功。 然当存足之数或太大不敌之时,其法将失其宜。 此IBM失隐式学之神经齐之势,不见之单词也。', 'ja': '機械翻訳システムは、特にリソースの少ないシナリオでは、ドメインの不一致に対して脆弱です。ドメイン外翻訳は、露出バイアスとデコーダーが言語モデルとして機能するため、品質が低く、幻覚を起こしやすいことが多い。この問題を緩和するために、IBMの統計的アライメントによって制限された語彙の候補リスト化と、類似性に基づいた仮説の再ランク化という2つのアプローチを採用しています。これらの方法は、計算的に安価であり、低リソースのドメイン外テストセットで成功を示します。しかし、十分なデータがないか、ドメインの不一致が大きすぎると、メソッドは優位性を失います。これは、暗黙的に学習されたニューラルアライメントよりも、IBMモデルの優位性が失われていることと、見えない単語のサブワードセグメンテーションの問題の両方に起因しています。', 'hi': 'मशीन अनुवाद सिस्टम डोमेन बेमेल के लिए कमजोर हैं, विशेष रूप से कम-संसाधन परिदृश्य में। आउट-ऑफ-डोमेन अनुवाद अक्सर खराब गुणवत्ता के होते हैं और एक्सपोजर पूर्वाग्रह और एक भाषा मॉडल के रूप में कार्य करने वाले डिकोडर के कारण मतिभ्रम के लिए प्रवण होते हैं। हम इस समस्या को कम करने के लिए दो दृष्टिकोण अपनाते हैं: आईबीएम सांख्यिकीय संरेखण द्वारा प्रतिबंधित लेक्सिकल शॉर्टलिस्टिंग, और समानता के आधार पर परिकल्पना को फिर से तैयार करना। विधियाँ कम्प्यूटेशनल रूप से सस्ती हैं और कम-संसाधन आउट-ऑफ-डोमेन परीक्षण सेट पर सफलता दिखाती हैं। हालांकि, पर्याप्त डेटा या बहुत महान डोमेन बेमेल है, जब विधियों लाभ खो देते हैं। यह आईबीएम मॉडल दोनों के कारण है जो स्पष्ट रूप से सीखे गए तंत्रिका संरेखण पर अपना लाभ खो रहा है, और अनदेखी शब्दों के उप-शब्द विभाजन के साथ मुद्दों को खो रहा है।', 'ru': 'Системы машинного перевода уязвимы к несоответствию доменов, особенно в сценарии с низким объемом ресурсов. Внедоменные переводы часто имеют низкое качество и склонны к галлюцинациям из-за смещения экспозиции и декодера, выступающего в качестве языковой модели. Мы принимаем два подхода для облегчения этой проблемы: лексический шорт-лист, ограниченный статистическими выравниваниями IBM, и перегруппировка гипотез на основе сходства. Методы являются вычислительно дешевыми и показывают успех на малоресурсных внедоменных тестовых наборах. Тем не менее, методы теряют преимущество при наличии достаточного количества данных или слишком большого несоответствия доменов. Это связано как с тем, что модель IBM теряет свое преимущество над неявно изученным нейронным выравниванием, так и с проблемами сегментации подсловов невидимых слов.', 'ga': 'Tá córais aistriúcháin mheaisín i mbaol neamhréire fearainn, go háirithe i gcás acmhainní ísle. Is minic go mbíonn droch-chaighdeán ag baint le haistriúcháin as an bhfearann agus go mbíonn siabhránachtaí iontu, mar gheall ar laofacht nochta agus an díchódóir ag feidhmiú mar mhúnla teanga. Glacaimid dhá chur chuige chun an fhadhb seo a mhaolú: gearrliostú foclóireachta srianta ag ailíniú staidrimh IBM, agus hipitéis a athrangú bunaithe ar chosúlacht. Tá na modhanna saor ó thaobh ríomhaireacht de agus léiríonn siad rath ar thacair tástála lasmuigh den fhearann a bhfuil acmhainní ísle acu. Mar sin féin, cailleann na modhanna buntáiste nuair a bhíonn dóthain sonraí ann nó nuair a bhíonn an iomarca neamhréire fearainn ann. Is é is cúis leis seo ná gur chaill samhail IBM a buntáiste ar an ailíniú néareolaíoch atá foghlamtha go hintuigthe, agus go bhfuil fadhbanna le deighilt fofhocail d’fhocail nach bhfacthas riamh cheana.', 'el': 'Τα συστήματα μηχανικής μετάφρασης είναι ευάλωτα σε αναντιστοιχία τομέων, ειδικά σε ένα σενάριο χαμηλής περιεκτικότητας σε πόρους. Οι μεταφράσεις εκτός πεδίου είναι συχνά κακής ποιότητας και επιρρεπείς σε παραισθήσεις, λόγω προκατάλειψης έκθεσης και του αποκωδικοποιητή που λειτουργεί ως γλωσσικό μοντέλο. Υιοθετούμε δύο προσεγγίσεις για την ανακούφιση αυτού του προβλήματος: τη λεξική λίστα που περιορίζεται από τις στατιστικές ευθυγραμμίσεις της IBM και την επανακατάταξη υποθέσεων με βάση την ομοιότητα. Οι μέθοδοι είναι υπολογιστικά φτηνές και δείχνουν επιτυχία σε σύνολα δοκιμών χαμηλού πόρου εκτός πεδίου. Ωστόσο, οι μέθοδοι χάνουν το πλεονέκτημα όταν υπάρχουν επαρκή δεδομένα ή υπερβολικά μεγάλη έλλειψη αντιστοιχίας τομέα. Αυτό οφείλεται τόσο στο ότι το μοντέλο χάνει το πλεονεκτήμα του έναντι της έμμεσης εκμάθησης νευρωνικής ευθυγράμμισης, όσο και στα προβλήματα με την τμηματοποίηση υπολέξεων αόρατων λέξεων.', 'hu': 'A gépi fordítási rendszerek sérülékenyek a tartomány eltérésének, különösen alacsony erőforrással rendelkező forgatókönyv esetén. A területen kívüli fordítások gyakran rossz minőségűek és hajlamosak hallucinációkra, mivel az expozíció elfogult és a dekóder nyelvi modellként működik. A probléma enyhítésére két megközelítést alkalmazunk: az IBM statisztikai igazításai által korlátozott lexikai rövidlistázás és a hasonlóságon alapuló hipotézisek átrendezése. A módszerek számítási szempontból olcsóak és sikeresek az alacsony erőforrású, domain kívüli tesztkészletek esetében. A módszerek azonban elveszítik az előnyt, ha elegendő adat vagy túl nagy a domain eltérés. Ez annak köszönhető, hogy az IBM modell elvesztette előnyét a hallgatólagosan megtanult neurális igazítással szemben, valamint a láthatatlan szavak alszó szegmentálásával kapcsolatos problémák.', 'ka': 'მაქსინური გაგრძელების სისტემები დიომინის არსებობისთვის უფრო დაახლობელია, განსაკუთრებით ცოტა რესურსის სინარიოში. დიომინის გარეშე განსხვავებული განსხვავებები ხშირად ცოტა კალუტინაციების და ჰალუცინაციების გარეშე, რომლებიც განსხვავებული წინასწორება და განსხვავებელი იქნება ენის მოდელზე ჩვენ ორი პრობლემას გავაკეთებთ, რომ ამ პრობლემას გახსნა: ელექსიკალური კოტატიკური სია IBM-ის სტატისტიკური დაწყვეტილებით, და ჰიპოტეზის გახსნა სხვადასხვობით. პროცემები კომპუტაციალურად მარტივია და გამოჩვენება სექსია დემომინის გარეშე ტესტის შესაძლებლობაში. მაგრამ, მეტივები გამოცდილობს, როდესაც მონაცემები ან ძალიან დიდი დიომინის არსებობა. ეს იქნება IBM მოდელის გამოსახულება, რომელიც გადასრულებული ნეიროლური დასრულება, და პრობლემები, რომელიც არაჩვენებული სიტყვების სუბველსიტყვების დასრულება.', 'lt': 'Mašin ų vertimo sistemos yra pažeidžiamos dėl srities neatitikimo, ypač mažai išteklių turinčiame scenarijuje. Išorės vertimai dažnai yra prastos kokybės ir gali turėti haliucinacijas dėl sąlyčio su ekspozicija ir kaip kalbos modelis veikiančio dekoderio. Siekdami sušvelninti šią problem ą, imame du metodus: tekstinį trumpą sąrašą riboja IBM statistiniai koregavimai ir hipotezės pakartotinį koregavimą panašumo pagrindu. The methods are computationally cheap and show success on low-resource out-of-domain test sets.  Tačiau metodai praranda pranašumą, jei yra pakankamai duomenų arba per didelis srities neatitikimas. Tai atsiranda dėl to, kad IBM model is praranda pranašumą dėl netiesiogiai išmokto neurologinio susiejimo ir dėl problemų, susijusių su nematomų žodžių subžodžių segmentacija.', 'kk': 'Машина аудару жүйелері доменге сәйкес келмейді, осылай қатар, төмен ресурстар сценариясында. Доменге тыс аудармалардың көбінде сапалы болып, тіл үлгісі ретінде әрекеттер жасалғандар және декодерлердің көбінде халуцинацияларына тұрады. Бұл мәселеді көшірмелеу үшін екі арқылы қолданып тұрмыз: IBM статистикалық түрлендіруден шектелген лексикалық қысқартылық тізімі және ұқсас тәртібіне негізделген гипотеза қайта түрл Бұл әдістер компьютерлік үлкен және доменге тыс ресурстар сынақтарында сәтті көрсетіледі. Бірақ әдістер жеткілікті деректер немесе толық үлкен доменге сәйкес келмегенде артықшылық жоқ. Бұл IBM үлгісінің екеуінде білім берілген невралдық түрлендіріміне артықшылығын жоғалуының себебі мен белгілмеген сөздердің ішкі сөздерді сегментациясының мәселелері', 'mk': 'Машинските преведувачки системи се ранливи на недоразбирање на домените, особено во сценарио со ниски ресурси. Преведувањата надвор од домен честопати се од лош квалитет и навикнати на халуцинации, поради предрасудата на изложеноста и декодерот кој дејствува како јазички модел. Ние усвојуваме два пристапи за олеснување на овој проблем: лексикалното кратко листување ограничено од статистичките израмки на ИБМ, и хипотезното повторно врзување базирано на сличност. Методите се пресметувачки ефтини и покажуваат успех на тестовите со ниски ресурси надвор од доменот. Сепак, методите губат предност кога постојат доволни податоци или премногу големи недоразбирања на домените. Ова е поради тоа што моделот на ИБМ ја изгуби својата предност во однос на имплицитно наученото нервно прилагодување, како и проблемите со сегментацијата на подзборови на невидливи зборови.', 'ms': 'Sistem terjemahan mesin rentan terhadap ketidakpadanan domain, terutama dalam skenario sumber rendah. Terjemahan diluar domain sering berkualiti dan cenderung kepada halusinasi, disebabkan bias eksposisi dan dekoder bertindak sebagai model bahasa. Kami mengadopsi dua pendekatan untuk mengurangi masalah ini: senarai pendek leksikal yang diharamkan oleh aliran statistik IBM, dan hipotesis mengikat semula berdasarkan persamaan. Kaedah ini secara kira-kira murah dan menunjukkan kejayaan pada set ujian luar domain sumber rendah. Namun, kaedah kehilangan keuntungan apabila ada data yang cukup atau tidak sepadan domain terlalu besar. Ini disebabkan kedua-dua model IBM kehilangan keuntungannya atas penyesuaian saraf yang dipelajari secara implicit, dan isu dengan segmen subkata kata perkataan yang tidak terlihat.', 'it': "I sistemi di traduzione automatica sono vulnerabili a disallineamenti di dominio, soprattutto in uno scenario a basso consumo di risorse. Le traduzioni fuori dominio sono spesso di scarsa qualità e soggette ad allucinazioni, a causa di distorsioni dell'esposizione e del decoder che funge da modello linguistico. Adottiamo due approcci per alleviare questo problema: shortlist lessicale limitato da allineamenti statistici IBM e ricanking delle ipotesi basate sulla somiglianza. I metodi sono computazionalmente economici e mostrano successo su set di test fuori dominio a basso contenuto di risorse. Tuttavia, i metodi perdono vantaggio quando ci sono dati sufficienti o disallineamento del dominio troppo grande. Ciò è dovuto sia al fatto che il modello IBM perde il suo vantaggio rispetto all'allineamento neurale implicitamente appreso, sia ai problemi con la segmentazione delle sottoparole delle parole invisibili.", 'ml': 'മെഷീന്\u200d പരിഭാഷയുടെ സിസ്റ്റത്തില്\u200d ഡോമെന്\u200d തെറ്റിപ്പോകാന്\u200d സാധ്യതയുണ്ട്, പ്രത്യേകിച്ച് കുറഞ്ഞ വിഭവങ്ങളു ഡൊമെയിനില്\u200d നിന്നും പുറത്തുപോകാത്ത വിഭാഷകങ്ങള്\u200d പലപ്പോഴും ദരിദ്രതയുള്ള വിവാദങ്ങളാണ്. ഭാഷ മോഡലായി പ്രവര്\u200dത്തിക്കുന്നതി ഈ പ്രശ്നത്തെ ലളിപ്പിക്കാന്\u200d നമ്മള്\u200d രണ്ടു വഴികള്\u200d എടുത്തുകൊണ്ടിരിക്കുന്നു: ഐബിഎം സ്റ്റാസ്റ്റിക്കല്\u200d സങ്കല്\u200dപ്പിക്കുന്നത ഈ രീതികള്\u200d കണക്കിലൂടെ എളുപ്പമാണ്. കുറഞ്ഞ വിഭവങ്ങള്\u200d ഡൊമൈന്\u200d ടെസ്റ്റ് സെറ്റുകളില്\u200d വിജയം കാണിക്കുന്നു. എന്നാലും മതിയായ ഡേറ്റായോ വലിയ ഡൊമെയിന്\u200d പൊരുതുമ്പോഴോ രീതികള്\u200d നഷ്ടപ്പെടുന്നു. ഇത് രണ്ടുപേര്\u200dക്കും ഐബിഎം മോഡല്\u200d നഷ്ടപ്പെടുന്നതിനാല്\u200d പ്രധാനപ്പെട്ട ന്യൂറല്\u200d ചേര്\u200dന്നതിനെക്കുറിച്ച് അതിന്റെ ഉപകാരം നഷ', 'mn': 'Машин хөрөнгө оруулах системүүд холбоотой тоглоомоос эмзэг, ялангуяа бага нөөцийн хувилбарт байдаг. Ингээд хэл загвараар ажиллаж буй хүмүүсийн хувьд бага чадвартай байдаг. Ингээд хэл загвараар ажиллаж буй хүмүүсийн хувьд бага байдаг. Бид энэ асуудлыг багасгахын тулд хоёр арга зам ашиглаж байна: IBM-ын статистикийн тэгшитгэлээр хязгаарлагдсан лексикийн богино жагсаалт, мөн адилхан байдлын үндсэн гипотез дахин багасгаж байна. Эдгээр арга нь тооцоололтой хямд бөгөөд бага нөөцийн туршилтын бага зэрэг амжилтыг харуулдаг. Гэвч методууд хангалттай өгөгдлийн эсвэл хэтэрхий том зохион байдалтай байхад ашигтай байдаг. Энэ нь IBM загварын хоёр давуу талаар сурсан мэдрэлийн давхаргыг алдаж, харагдахгүй үгнүүдийн давхаргын асуудлуудын шалтгаан юм.', 'mt': 'Is-sistemi tat-traduzzjoni tal-magni huma vulnerabbli għad-diskrepanza fid-dominju, speċjalment f’xenarju b’riżorsi baxxi. It-traduzzjonijiet barra d-dominju ta’ spiss huma ta’ kwalità ħa żina u suxxettibbli għal alluċinazzjonijiet, minħabba preġudizzju għall-espożizzjoni u d-dekoder li jaġixxi bħala mudell lingwistiku. We adopt two approaches to alleviate this problem: lexical shortlisting restricted by IBM statistical alignments, and hypothesis reranking based on similarity.  Il-metodi huma komputazzjonalment irħas u juru suċċess f’settijiet ta’ testijiet barra d-dominju b’riżorsi baxxi. Madankollu, il-metodi jitilfu l-vantaġġ meta jkun hemm biżżejjed dejta jew diskrepanza kbira wisq fid-dominju. Dan huwa dovut kemm għall-mudell IBM li jitlef il-vantaġġ tiegħu fuq l-allinjament newrali impliċitament imgħallem, kif ukoll għal kwistjonijiet b’segmentazzjoni ta’ sottokliem ta’ kliem mhux viżibbli.', 'ro': 'Sistemele de traducere automată sunt vulnerabile la neconcordanța domeniului, în special într-un scenariu cu resurse reduse. Traducerile din afara domeniului sunt adesea de slabă calitate și predispuse la halucinații, din cauza prejudecății expunerii și a decodorului care acționează ca model lingvistic. Adoptăm două abordări pentru a atenua această problemă: shortlisting lexical restricționat de alinierea statistică IBM și recanking ipoteze bazate pe similaritate. Metodele sunt ieftine din punct de vedere computațional și arată succes pe seturi de teste cu resurse reduse în afara domeniului. Cu toate acestea, metodele pierd avantajul atunci când există suficiente date sau o neconcordanță prea mare a domeniului. Acest lucru se datorează atât modelului IBM pierzându-și avantajul față de alinierea neurală implicit învățată, cât și problemelor cu segmentarea subcuvintelor a cuvintelor nevăzute.', 'pl': 'Systemy tłumaczenia maszynowego są podatne na niedopasowanie domen, zwłaszcza w scenariuszu niskiego zasobu. Tłumaczenia poza domeną są często złej jakości i podatne na halucynacje, ze względu na tendencje ekspozycji i dekoder działający jako model językowy. Przyjmujemy dwa podejścia, aby złagodzić ten problem: krótką listę leksykalną ograniczoną przez dostosowania statystyczne IBM oraz zmianę rankingu hipotez opartą na podobieństwie. Metody te są tanie obliczeniowo i wykazują sukces na niskich zasobach zestawach testowych poza domeną. Jednak metody tracą przewagę, gdy istnieje wystarczająca ilość danych lub zbyt duża niedopasowanie domeny. Wynika to zarówno z utraty przewagi modelu IBM nad domyślnie uczonym wyrównaniem neuronowym, jak i problemów z segmentacją podsłów niewidzialnych słów.', 'sr': 'Sistemi prevoda mašine su ranjivi na nepovladanje domena, posebno u scenariju niskog resursa. Prevodi van domena često su loše kvalitete i spremni halucinacijama, zbog izloženja predrasude i dekodera koji djeluju kao jezički model. Prihvaćamo dva pristupa da ublažimo ovaj problem: leksičko skraćenje ograničeno statističkim poravnanjem IBM-a i preokretanje hipoteze na temelju sličnosti. Metode su računalno jeftine i pokazuju uspjeh na nizim resursima izvan domena. Međutim, metode gube prednost kada postoje dovoljno podataka ili previše velike domene nesklade. To je zbog oba modela IBM-a koji gubi prednost nad implicitno naučenim neuralnim poravnanjem, i problema sa podriječjom segmentacijom nevidljivih reči.', 'sv': 'Maskin철vers채ttningssystem 채r s책rbara f철r dom채nmissmatchning, s채rskilt i ett scenario med l책ga resurser. 횜vers채ttningar utanf철r dom채nen 채r ofta av d책lig kvalitet och ben채gna att hallucinationer, p책 grund av exponeringsf철rm책ga och avkodaren fungerar som spr책kmodell. Vi antar tv책 tillv채gag책ngss채tt f철r att lindra detta problem: lexikal shortlist begr채nsad av IBM statistiska justeringar, och hypoteser omr채kning baserad p책 likhet. Metoderna 채r ber채kningsm채ssigt billiga och visar framg책ng p책 l책gresurstester utanf철r dom채nen. Metoderna f철rlorar dock f철rdel n채r det finns tillr채ckligt med data eller f철r stor dom채nmissmatchning. Detta beror b책de p책 att IBM-modellen f철rlorar sin f철rdel j채mf철rt med den implicit l채rda neurala anpassningen, och problem med underordssegmentering av osynliga ord.', 'no': 'Maskineoversettelsystemet er sårbar til domenet ikkje samsvar, spesielt i ein låg ressursscenario. Omsetjingar uten domenet er ofte av dårlige kvalitet og påverka halusinasjonar på grunn av eksponering av forsiktighet og dekoderen som språk-modell. Vi adopterer to tilnærmingar for å redusera dette problemet: leksisk kortliste begrenset av IBM-statistiske innstillingar, og hipotesisk gjenoppretting basert på liknande tilnærmingar. Metodane er kalkulasjonell jeftige og viser suksess på låg- ressurs- testsett. Men metodane mistar fordel når det er nok data eller for stor domenet ikkje passar. Dette er grunn av både IBM-modellen som mistar fordel over det implisitt lærte neuraljusteringa, og problemar med underordsegmenteringa av ukjende ord.', 'ta': 'இயந்திர மொழிபெயர்ப்பு அமைப்புகள் களம் பொருத்தமில்லை, குறைந்த மூலத்தின் காட்சியில் பொருத்தக்கூடியது. டோமைன் வெளியே மொழிபெயர்ப்புகள் பெரும்பாலாகவே ஏழை தரம் மற்றும் பாதிப்புகள் தெரியும், பியாஸ் மற்றும் குறியீடு மொழி ம இந்த பிரச்சனையை எளிதாக்க இரண்டு வழிகளை நாம் எடுத்துக் கொள்கிறோம்: IBM புள்ளிவிவரமான சுருக்கல் வரிசைப்படுத்தல் தடுக்கப்பட்டது, மற முறைகள் கணக்கில் மிகவும் எளிமையாக இருக்கும் மற்றும் குறைந்த மூலத்திற்கு வெற்றியைக் காட்டுகின்றன. ஆனால் போதுமான தகவல் இருக்கும் அல்லது மிகவும் பெரிய களம் பொருத்தமாக இருக்கும்போது முறைகள் பயன்பாடுகளை  இது தான் IBM மாதிரி இருவருக்கும் தெரியாத புதிய நெறி ஒழுங்குபடுத்தும் மேல் அதில் தன் முன்னுரிமை இழக்கும், மறைவார்த்த வார', 'si': 'පද්ධතිය පද්ධතිය අවශ්\u200dය වෙන්න බැරි වෙන්න පුළුවන්, විශේෂයෙන්ම ප්\u200dරතිපද්ධතියක් අඩුම ප්\u200dර පැහැදිලි ඩොමේන් වලින් භාෂාවක් වලින් ක්\u200dරියාත්මක විශ්වාස කරනවා හැලුසිනස් වලින් පිළිබඳින්න, භාෂාව අපි මේ ප්\u200dරශ්නය අඩංගුවට අඩංගුවක් දෙකක් භාවිත කරනවා: ලෙක්සිකල් කොටස් ලිස්ටික් අඩංගුවක් IBM ස්ථාතික සංවිධාන පරීක්ෂණය පරීක්ෂණය විශේෂයෙන් පරීක්ෂණය වෙනුවෙන් පරීක්ෂණය පෙන්වන්න. නමුත්, විදියට ප්\u200dරයෝජනය නැති වෙන්නේ ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය නැති වෙන්නේ දත්ත නැති වෙලා මේක IBM මොඩල් දෙන්නම නිසා විශ්වාසයෙන් ප්\u200dරයෝජනය නැති වෙන්නේ නිර්භාවිත විසින් ඉගෙන ගත්ත නිර්භාවිත විසින', 'so': "Isticmaha turjumidda maskinentu waxay u dhaawacaan in ay domain u baahan yihiin, khusuusan waxay ku jiraan muuqashada hoose-resource. Turjumaadda aan degmada ahayn inta badan waa mid baahan oo aad u baahan tahay islamarkaasna waxay u baahan yihiin inay is-daahiriyaan, sababtuna waa inay u muuqato qalabka luqada. Waxaynu qaadannaa laba habboon si aan u fududayno dhibaatadan: baaritaanka leksikal ee ku xadgudbay tartanka IBM, iyo sidoo kale kaleemeysashada hypothesis. Isticmaalayaashu waa qiimo jaban yihiin, waxayna muujiyaan liibaano ku saabsan tijaabada hoose-resource-ka-baxa-domain-ka. Si kastaba ha ahaatee qaababka way lumiyaan faa'iido, marka ay jirto macluumaad ku filan ama ay ku filan yihiin deegaan aad u weyn. Taas waxaa sabab u ah labada model ee IBM oo lumin faa'iidadeeda ku saabsan isbedelka neurada, iyo dhibaato ku saabsan qeybinta hadalka qarsoon.", 'ur': 'ماشین ترجمہ سیسٹم ڈومین کے مطابق غیر مطابق ہے، مخصوصاً کم رسورس سناریو میں۔ بیرون ڈومین کی تعبیر اکثر کمزور کیفیت کے ساتھ ہیں اور ہلوسینیوں کے ساتھ آواز دینے کے سبب اور ڈوکور زبان مدل کے طور پر عمل کرتے ہیں. ہم نے اس مسئلہ کو کمزور کرنے کے لئے دو طریقے قبول کرتے ہیں: IBM ایستٹیسٹیٹیٹیٹیٹیٹیٹیٹیٹیٹیٹیٹیٹ کے ذریعہ محدود ہونے والی لکسیکل شرٹ لیست، اور ایسی طریقے پر بنیاد ہونے والی فرضی یہ طریقے کامپیوتر کے طور پر آسان ہیں اور کم رسسور کے آواز ڈومین تست سٹوں پر موفقیت دکھائی جاتی ہیں. However, the methods lose advantage when there is sufficient data or too great domain mismatch. یہ IBM موڈل کی وجہ سے ہے کہ اس کا فائدہ چھوڑ رہا ہے اس کے ذریعہ ذریعہ سے سیکھا ہوا نئورل الیٹینیٹینیٹ پر اور غیب کی کلمات کے زیر کلمات الیٹینیٹ کے ساتھ مسائل ہیں.', 'uz': "Name Domen tomonidan tashqi tarjimalar ko'p o'rtacha o'xshash sifatida o'xshash mumkin. Bu bizni ko'rsatish sababi va o'zgarishni tillar modeli sifatida bajarishi mumkin. Bu muammolarni kamaytirish uchun ikkita usulni olib tashlash mumkin: IBM statistika tarkibini yigʻilgan leksikal qisqartmalari va huddi bir xil asosida yetarli hypotesiya. Uslublar qiymati cheksiz va domen sinov moslamalaridan kamaytirish muvaffaqiyatlarini koʻrsatish. Lekin, ma'lumot yoʻq yoki juda katta domen moslama boʻlganda usullar foydalanadi. Bu ikkita IBM modeli o'rganilgan neyralik tartibi bilan foydalanishi mumkin, va bu gapiradigan so'zlarning tub soʻzni ajratish mumkin.", 'vi': 'Hệ thống dịch cỗ máy rất dễ bị sụp đổ, đặc biệt là trong một viễn cảnh ít tài nguyên. Bản dịch ngoại ô thường thiếu chất lượng và có khuynh hướng ảo giác, do khuynh hướng phơi nhiễm và việc giải mã là mô hình ngôn ngữ. Chúng tôi sử dụng hai phương pháp để giải quyết vấn đề này: danh sách chữ viết bị hạn chế bởi hệ thống thống thống thống thống IBM, và giả thuyết lặp lại dựa trên điểm tương đồng. Các phương pháp là tính rẻ và cho thấy thành công trên các bộ thử ra khỏi miền thấp. Tuy nhiên, các phương pháp mất lợi thế khi có đủ dữ liệu hoặc không phù hợp miền quá lớn. Do cả mô hình IBM mất đi lợi thế do hệ thống thần kinh theo dự đoán và vấn đề phân biệt chữ ngầm của những từ không nhìn thấy.', 'bg': 'Системите за машинен превод са уязвими от несъответствие на домейните, особено при сценарий с ниски ресурси. Преводите извън домейна често са с лошо качество и са склонни към халюцинации, поради отклонения на експозицията и декодера, действащ като езиков модел. Ние възприемаме два подхода за облекчаване на този проблем: лексикален списък, ограничен от статистически подравнявания и хипотеза за пренареждане въз основа на сходство. Методите са изчислително евтини и показват успех при нискоресурсни тестови комплекти извън домейна. Методите обаче губят предимство, когато има достатъчно данни или твърде голямо несъответствие на домейна. Това се дължи както на това, че моделът губи предимството си пред имплицитно наученото невронно подравняване, така и на проблеми със сегментацията на поддуми на невидими думи.', 'nl': 'Machinevertaalsystemen zijn kwetsbaar voor domeinmismatch, vooral in een scenario met weinig middelen. Vertalingen buiten het domein zijn vaak van slechte kwaliteit en vatbaar voor hallucinaties, als gevolg van blootstellingsbias en de decoder die fungeert als taalmodel. We hanteren twee benaderingen om dit probleem te verlichten: lexicale shortlisting beperkt door IBM statistische uitlijningen, en hypothese herschikking gebaseerd op overeenkomsten. De methoden zijn rekenkundig goedkoop en laten succes zien op low-resource out-of-domain testsets. De methoden verliezen echter voordeel wanneer er voldoende data of te grote domeinmismatch is. Dit komt doordat zowel het IBM model zijn voordeel verliest ten opzichte van de impliciet aangeleerde neurale uitlijning, als problemen met subwoordsegmentatie van onzichtbare woorden.', 'hr': 'Sistemi prevođenja strojnih sustava su ranjivi na nedostatak domena, posebno u scenariju niskog resursa. Prevodi van domena često su loše kvalitete i skloni halucinacijama, zbog izloženosti predrasude i dekodera koji djeluju kao jezički model. Prihvaćamo dva pristupa za ublažavanje ovog problema: leksičko skraćenje ograničeno statističkim poravnanjem IBM-a i preokretanje hipoteze na temelju sličnosti. Metode su računalno jeftine i pokazuju uspjeh na nizim resursima izvan domena. Međutim, metode gube prednost kada postoje dovoljno podataka ili previše velike domene nesklade. To je zbog oba IBM modela koji gubi prednost nad implicitno naučenim neuralnim poravnanjem i pitanja s podriječjom segmentacijom nevidljivih riječi.', 'de': 'Maschinelle Übersetzungssysteme sind anfällig für Domain-Mismatchs, insbesondere in einem Szenario mit geringen Ressourcen. Außerdomänenübersetzungen sind oft von schlechter Qualität und anfällig für Halluzinationen, da der Decoder als Sprachmodell fungiert. Wir verwenden zwei Ansätze, um dieses Problem zu lindern: lexikalische Shortlist, die durch statistische Alignments von IBM eingeschränkt wird, und Hypothesen-Reranking basierend auf Ähnlichkeit. Die Methoden sind rechnerisch günstig und zeigen Erfolg auf ressourcenarmen Out-of-Domain Testsets. Allerdings verlieren die Methoden bei ausreichenden Daten oder zu großer Domain-Mismatch ihren Vorteil. Dies liegt sowohl daran, dass das IBM-Modell seinen Vorteil gegenüber der implizit erlernten neuronalen Ausrichtung verliert, als auch an Problemen mit der Subword-Segmentierung unsichtbarer Wörter.', 'ko': '기계 번역 시스템은 특히 자원이 부족한 상황에서 일치하지 않는 영향을 받기 쉽다.노출 편차와 디코더가 언어 모델을 충당하기 때문에 역외 번역은 보통 질이 낮고 환각을 일으키기 쉽다.우리는 이 문제를 완화하기 위해 두 가지 방법을 사용했다. IBM 통계에 의해 제한된 어휘를 선별하고, 유사성을 바탕으로 가설을 다시 정렬하는 것이다.이런 방법은 계산 원가가 낮아서 낮은 자원의 역외 테스트 집합에서 성공을 거두었다.그러나 충분한 데이터가 있거나 너무 큰 영역이 일치하지 않을 때 이런 방법은 우위를 잃게 된다.이는 IBM 모델이 은식 학습신경에 비해 일치하는 장점과 은닉어의 자어 분할 문제를 잃었기 때문이다.', 'id': 'Sistem terjemahan mesin rentan terhadap ketidakcocokan domain, terutama dalam skenario sumber daya rendah. Terjemahan luar domain sering berkualitas yang buruk dan cenderung untuk halusinasi, karena bias eksposisi dan dekoder bertindak sebagai model bahasa. We adopt two approaches to alleviate this problem: lexical shortlisting restricted by IBM statistical alignments, and hypothesis reranking based on similarity.  Metodenya secara komputasional murah dan menunjukkan sukses pada set tes rendah sumber daya luar domain. Namun, metode kehilangan keuntungan ketika ada data yang cukup atau tidak cocok domain terlalu besar. Ini karena kedua model IBM kehilangan keuntungannya atas penyesuaian saraf yang secara implicit belajar, dan masalah dengan segmen subkata kata kata yang tidak terlihat.', 'da': 'Maskinoversættelsessystemer er sårbare over for domæneforskel, især i et scenario med lav ressource. Oversættelser uden for domænet er ofte af dårlig kvalitet og tilbøjelige til hallucinationer på grund af eksponering bias og dekoderen fungerer som sprogmodel. Vi anvender to tilgange til at afhjælpe dette problem: leksikal shortlist begrænset af IBM statistiske justeringer og hypoteser omlægning baseret på lighed. Metoderne er beregningsmæssigt billige og viser succes på lav ressource out-of-domæne testsæt. Metoderne mister dog fordelen, når der er tilstrækkelige data eller for stor domænemæssig mismatch. Dette skyldes både IBM-modellen mister sin fordel i forhold til den implicit lærte neurale justering, og problemer med underordssegmmentering af usynlige ord.', 'sw': 'Mfumo wa kutafsiri mashine unaathirika na kukosa mafanikio ya ndani, hususani katika hali ya rasilimali duni. Utafsiri wa nje ya ndani mara nyingi ni wa kiwango duni na unaonekana kuwa na utakatifu, kwa sababu ya kuonyesha upendeleo na kupunguza vigezo vinavyofanya kama mtindo wa lugha. Tunachukua hatua mbili ili kupunguza tatizo hili: upungufu wa uchunguzi wa ukosefu wa kimapenzi uliowekwa na upunguaji wa takwimu wa IBM, na nadharia zinazoendelea kwa usawa. mbinu hizo ni rahisi kwa hisabati na zinaonyesha mafanikio kwenye seti za rasilimali duni nje ya majaribio ya ndani. Hata hivyo, mbinu hizo zinapoteza faida pale ambapo kuna taarifa za kutosha au zile kubwa za ndani zinazofanikiwa. Hii ni kwa sababu ya mbili ya IBM kupoteza faida yake kwa sababu ya kujifunza kwa ufanisi wa uraia, na masuala yanayohusiana na sehemu ya maneno ya siri.', 'fa': 'سیستم\u200cهای ترجمه ماشین آسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآسیب\u200cآ ترجمه\u200cهای خارج از دومین اغلب از کیفیت فقیر است و به خاطر نشان دادن طبیعی و دکوردر که به عنوان مدل زبان عمل می\u200cکند، به عنوان حولیسی است. ما دو دستور برای کمبود کردن این مشکل را قبول می کنیم: فهرست کوتاه\u200cهای زبانی که توسط تطبیق آماری IBM محدود شده است، و فرضیه\u200cهای دوباره بر اساس شبیه است. روش\u200cها به صورت محاسبه ارزونی هستند و موفقیت را در مجموعه\u200cهای آزمایش\u200cهای خارج از دومین نشان می\u200cدهند. ولی روش\u200cها وقتی داده\u200cهای کافی یا دامین بسیار بزرگ متفاوتی وجود دارد، فایده\u200cای از دست می\u200cدهند. این به دلیل هر دو مدل IBM از دست دادن سودهایی خود بر روی تعیین عصبی که به طور غیر قابل تعلیم یاد گرفته است، و مشکلات با بخش زیر کلمه کلمه غیر قابل تعریف است.', 'tr': 'Otomatik terjime sistemleri domenaň eşleşmesine ýakyn ýagdaýa hasaplanýar, ýöne iň az resurslar senaryýasynda. Domenyň daşky terjimeleri köplenç erbet kalitesinden we halucinasyonlara takyklaýarlar, dil nusgasyna görä terjime edip otyrýarlar. Bu soruyu azaltmak için iki yaklaşım kabul ediyoruz: IBM istatistik çözümleri tarafından sınırlı olan leksik kısayollama ve benzeri tabanlı tahmin ediyoruz. Bu yöntemler kalamlaryň arasynda arzan we üstünlik etmäni domain testi düzümlerinde görkez. Ýöne, metodlar ýeterli maglumat ýa-da örän uly domena eşleşmeýän wagtlary ýitirýärler. Bu IBM modeliniň iň bellenen öwrenmeli näral çykyşynyň üstünde özüni ýitirmeginiň sebäbi we garaşylmadyklaryň asty sözleriň segmentasy bilen meseleleri.', 'am': 'የመኪን ትርጉም ስርዓቶች ለዶሜን መሳሰል አይችሉም፣ በተለይም በዝቅተኛ resource scenario ነው፡፡ ከዶሜን ወጥቶ የመረጃ ትርጓሜዎች ብዙ ጊዜ ድሀ ብዛት እና በቋንቋ ምሳሌ በመግለጥ እና የድምፅ አካባቢ እና የድምፅ መልዕክት በመቆጣጠር ነው፡፡ ይህንን ጉዳይ ለማቅረብ ሁለት ደረጃዎችን እንይዛለን፤ IBM በstatistic ግንኙነት የተከለከለ የሌክሲካዊ አነስተኛ እና በተለያዩ ላይ የተመሳሳይ ተቃውሞ አፍሪካዊ ጉዳይ ነው፡፡ ዘዴዎች በተቆጠሩ ቀላል እና የጎዳና ክፍተት ውጭ ከዶሜን ፈተና ማሳየት ነው፡፡ ምንም እንኳን የጠቅላላ ዳታ ወይም የዶሜን አካባቢ ሲኖር የሥርዓት ጥቅም ይጠፋል፡፡ ይህ በሁለቱ IBM ምሳሌ የሆኑት የናቡር ክፍል ላይ ጥቅሙን በመጠቀም ነው፣ እናም የተሰወረውን የውይይት ቃላት በማስተካከል ጉዳይ ነው፡፡', 'hy': 'Machine translation systems are vulnerable to domain mismatch, especially in a low-resource scenario.  Առանց տիեզերքի թարգմանությունները հաճախ վատ որակի են և հակված են հալյուցինացիաներին, արտահայտության կողմնականության պատճառով և դեկոդերը, որը գործում է որպես լեզվի մոդել: We adopt two approaches to alleviate this problem: lexical shortlisting restricted by IBM statistical alignments, and hypothesis reranking based on similarity.  Մեթոդները հաշվարկներով էժան են և ցույց են տալիս հաջողություն ցածր ռեսուրսների արտաքին թեստերի համակարգերի վրա: Այնուամենայնիվ, մեթոդները կորցնում են առավելությունը, երբ բավարար տվյալներ կան կամ չափազանց մեծ տիեզերքի անհամապատասխանություններ: Սա պատճառով է, որ IBM-ի մոդելը կորցնում է իր առավելությունը անխուսափելի սովորված նյարդային հարմարեցման դեպքում, ինչպես նաև անտեսանելի բառերի ենթաբառի սեգմետրացիայի խնդիրները:', 'az': 'Makinat çeviri sistemləri domeinin uyğunlaşmasına zəiflik edir, özlərinə də zəif ressurs senaryosunda. Dömrünün dışında tərcümələri çox zəif kaliteli və halucinallara yaxınlaşdırılır, dil modeli olaraq tərzlərini göstərmək və dekoderi göstərmək üçün. Biz bu problemi yüngülləşdirmək üçün iki tərzim qəbul edirik: IBM statistik tərzimlərindən sınırlanan leksik qısa listesi və bənzərinə dayanan hipotezi yenidən tərzim edirik. Bu metodlar hesaplama ucuz və düşük-ressurs sınama setlərində başarılı göstərir. Ancaq metodlar yeterli verilər və ya çox böyük domena uyğunluğu olduğu zaman istifadə edirlər. Bu IBM modelinin imkansız öyrəndiyi nöral tərəflənməsi və görmədikləri sözlərin altı sözlərin segmentasiyonu ilə problemlərinə görədir.', 'af': "Masjien vertaling stelsels is onvulnerable na domein nie ooreenstem nie, veral in 'n lae-hulpbron scenario. Uit-domein vertalings is dikwels van arme kwaliteit en voorskrif tot halucinasies, vanweë die eksponering bias en die dekoder wat gedoen word as 'n taal model. Ons aanvaar twee toegange om hierdie probleem te alleviaat: leksiese kortplys beperk deur IBM statistiese lyn, en hipotees herank gebaseer op gelykenis. Die metodes is rekenaarsaal chip en wys sukses op lae- hulpbron uit- van- domein toets stelle. Maar die metodes verloor voordeel wanneer daar genoeg data of te groot domein nie ooreenstem nie. Hierdie is vanweë beide die IBM-model wat sy voordeel verloor oor die implisiteit leer neurale lyn, en probleem met subwoord segmentasie van ongesiende woorde.", 'bs': 'Sistemi prevođenja mašine su ranjivi na nedostatak domena, posebno u scenariju niskog resursa. Prevodi izvan domena često su loše kvalitete i skloni se halucinacijama, zbog izloženja predrasude i dekodera koji djeluje kao jezički model. Prihvaćamo dva pristupa za ublažavanje ovog problema: leksičko skraćenje ograničeno statističkim poravnanjem IBM-a i preokretanje hipoteze na temelju sličnosti. Metode su računalno jeftine i pokazuju uspjeh na nizim resursima izvan domena. Međutim, metode gube prednost kada postoje dovoljno podataka ili previše velike domene nesklade. To je zbog oba modela IBM-a koji gubi prednost nad implicitno naučenim neuralnim poravnanjem i pitanja s podriječjim segmentacijom nevidljivih riječi.', 'sq': 'Sistemet e përkthimit të makinave janë të prekshëm ndaj mospërputhjes së domenit, veçanërisht në një skenar me burime të ulëta. Përkthimet jashtë domenisë janë shpesh të cilësisë së keqe dhe të afërta ndaj halucinacioneve, për shkak të paragjykimit dhe dekodimit që vepron si një model gjuhësh. Ne miratojmë dy qasje për të lehtësuar këtë problem: listimi lexik i kufizuar nga renditjet statistikore të IBM-së dhe hipoteza e rikthyer bazuar në ngjashmëri. Metodat janë llogaritësisht të lira dhe tregojnë sukses në grupe testesh jashtë domenisë me burime të ulta. Megjithatë, metodat humbin avantazhin kur ka të dhëna të mjaftueshme apo mospërputhje shumë të madhe në domeni. Kjo është për shkak se si modeli IBM humb përparësinë e tij ndaj rregullimit nervor të mësuar implicitisht dhe çështjeve me segmentimin e nënfjalëve të fjalëve të padukshme.', 'ca': "Els sistemes de traducció màquina són vulnerables a la incompatibilitat de dominis, especialment en un escenari de baix recursos. Les traduccions fora de domini sovint són de mala qualitat i propenses a alucinacions, degut a la tendència a l'exposició i el decodificador actuant com a model de llenguatge. Adopem dos enfocaments per aliviar aquest problema: l'esborrament lècsic restringit pels alliniaments estadístics IBM, i l'hipòtesi de recalculació basada en la similitud. Els mètodes són calculativament barats i mostran èxit en conjunts de proves fora de domini amb baix recursos. Però els mètodes perden l'avantatge quan hi ha suficients dades o massa gran incompatibilitat de dominis. Això és degut a que el model IBM perd el seu avantatge sobre l'alliniament neural implícitament aprenent, i problemes amb la segmentació de subparaules de paraules invisibles.", 'fi': 'Konekäännösjärjestelmät ovat alttiita toimialueiden yhteensopimattomuudelle, varsinkin kun resurssit ovat vähäisiä. Ulkopuoliset käännökset ovat usein huonolaatuisia ja alttiita hallusinaatioille altistumisen vääristymisen ja kielimallina toimivan dekooderin vuoksi. Tämän ongelman lievittämiseksi käytämme kahta lähestymistapaa: IBM:n tilastollisten linjausten rajoittamaa sanastoa ja samankaltaisuuteen perustuvaa hypoteesien uudelleenjärjestelyä. Menetelmät ovat laskennallisesti halpoja ja osoittavat menestystä vähävaraisissa toimialueen ulkopuolisissa testisarjoissa. Menetelmät menettävät kuitenkin etunsa, kun tietoja on riittävästi tai verkkotunnuksen epäsuhta on liian suuri. Tämä johtuu sekä siitä, että IBM-malli menettää etunsa implisiittisesti opittuun hermolinjaukseen nähden, että ongelmista, jotka liittyvät näkymättömien sanojen alasanasegmentointiin.', 'bn': 'মেশিন অনুবাদ সিস্টেম ডোমেইনের ভুল মিলের জন্য ক্ষতিগ্রস্ত, বিশেষ করে কম সম্পদের দৃশ্যে। ডোমেইনের বাইরে অনুবাদ প্রায়শই দরিদ্র মানের ব্যাপার এবং পবিত্রতার জন্য প্রমাণিত হয়, যারা বিয়া এবং ভাষার মডেল হিসেবে কাজ করে। এই সমস্যাটি কমিয়ে দেওয়ার জন্য আমরা দুটি পদক্ষেপ গ্রহণ করেছি: আইবিএম পরিসংখ্যানের পরিসংখ্যান সীমাবদ্ধ এবং একই সাথে ভিত্তিক হিসেবে হিসে এই পদ্ধতিগুলো গণনাত্রিকভাবে সস্তা এবং ডোমেইন পরীক্ষা বাইরে নিম্ন সম্পর্কে সফল প্রদর্শন করে। তবে যথেষ্ট তথ্য অথবা অনেক বড় ডোমেইনের মিল্যাসের সময় এই পদ্ধতিগুলো সুবিধা হারায়। This is due to both the IBM model losing its advantage over the implicitly learned neural alignment, and issues with subword segmentation of unseen words.', 'et': 'Masintõlkesüsteemid on tundlikud domeenide mittevastavuse suhtes, eriti vähese ressursiga stsenaariumi korral. Domeenivälised tõlked on sageli halva kvaliteediga ja altid hallutsinatsioonidele, kuna kokkupuute kallutamine ja dekooder toimib keelemudelina. Selle probleemi leevendamiseks võtame kasutusele kaks lähenemisviisi: IBM statistiliste joondustega piiratud leksikaalne lühinimekiri ja sarnasusel põhinev hüpoteesi ümberjaotamine. Meetodid on arvutuslikult odavad ja näitavad edu madala ressursiga väljaspool domeeni katsekomplektide puhul. Kuid meetodid kaotavad eelise, kui on piisavalt andmeid või domeeni liiga suur ebakõla. See on tingitud nii IBM mudeli eelise kaotamisest kaudselt õppitud närvijoonduse ees kui ka probleemidest nähtamatute sõnade alamsõna segmenteerimisega.', 'cs': 'Systémy strojového překladu jsou náchylné k nesouladu domén, zejména v případě scénáře s nízkými zdroji. Překlady mimo doménu jsou často špatné kvality a náchylné k halucinacím, protože dekodér funguje jako jazykový model. Pro zmírnění tohoto problému přijímáme dva přístupy: lexikální shortlist omezený statistickým zarovnáním IBM a přerozdělování hypotéz založené na podobnosti. Metody jsou výpočetně levné a ukazují úspěch na nízkých zdrojových mimo doménu testovacích sadách. Metody však ztrácejí výhodu, pokud existuje dostatek dat nebo příliš velká nesoulad domény. Je to způsobeno jak tím, že IBM model ztrácí svou výhodu nad implicitně naučeným neuronovým zarovnáním, tak i problémy s podslovní segmentací neviditelných slov.', 'sk': 'Sistemi strojnega prevajanja so občutljivi na neskladje domen, zlasti v scenariju z nizkimi viri. Prevodi zunaj domene so pogosto slabe kakovosti in nagnjeni k halucinacijam zaradi pristranskosti izpostavljenosti in dekoderja, ki deluje kot jezikovni model. Za lajšanje tega problema uporabljamo dva pristopa: leksikalni uvrstitev, ki ga omejujejo IBM statistične poravnave, in hipotezo, ki temelji na podobnosti. Metode so računalniško poceni in kažejo uspeh pri nizkih virov zunaj domene testnih nizov. Vendar pa metode izgubijo prednost, ko je dovolj podatkov ali preveliko neskladje domen. To je posledica tako IBM-ovega modela, ki izgublja svojo prednost pred implicitno učeno nevronsko poravnavo, kot tudi težav s segmentacijo podbesed nevidnih besed.', 'ha': "Machine translation systems are vulnerable to domain mismatch, especially in a low-resource scenario.  @ info: whatsthis Tuna zãɓi hanyoyin biyu dõmin ka sauƙaƙara wannan mataimaki: shortlisting na mai ƙayyade na IBM statistical, da sami-hanyoyi mai saukarwa a kan daidaita. @ info: whatsthis A lokacin da, metoden za'a ɓace amfani idan an ƙunsa da data ko kuma don don sauri daidai mai girma. Wannan yana kasa duk misalin IBM da ya ɓace amfani da shi a kan juyi na tsarin neural da aka sani, kuma yana da masu hushi da rabon maganar da ba'a sani ba.", 'he': 'מערכות התרגום מכונות פגיעות לחוסר התאמה בתחום, במיוחד בתרחיש עם משאבים נמוכים. התרגשות מחוץ לתחום הן לעתים קרובות של איכות גרועה ונושאות להזיות, בגלל ההנחות לחשוף והמפענח מתנהג כמודל שפה. אנו מאמצים שני גישות כדי להקל על הבעיה הזאת: רשימת קצרות לקסית מוגבלת על ידי התאמות סטטיסטיות IBM, וההיפותזיה מחדש הקשר מבוססת על דומות. השיטות זולות מבחינה מחשבית והופעות הצלחה במערכות מבחן מחוץ לתחום משאבים נמוכים. However, the methods lose advantage when there is sufficient data or too great domain mismatch.  זה בגלל שני המודל IBM מאבד את יתרונו מעל התאמה העצבית המולמדת באופן מילוי, ובעיות עם סגמנטציה של מילים בלתי נראות.', 'jv': 'Majin terjamahan sistemi are weakness to domain mismatch, Espero in a lowly-source scenaro. Out-of-domain terjamahan pirsak-pirsak nguasai kapan lan sakjane kanggo halusikap, kaya paketen bias karo dekojer sing nganggep sistem lang. Awakdhéwé nggunaké durung hasar nggawe barang nggawe boten iki: leksik shortlisting limited by IBM Statistatical alignments, lan ipotes reranking basa gambar kelas usul. The Methods are komputationly modep and show success on small-source out-of-domain test set. Name Iki lak iki dadi model IBM kuwi nggoleki perusahaan anyar nggawe nguasai paten', 'bo': 'རྩིས་འཁོར་འཁོར་གྱི་ཡིག་སྒྲུབ་ནུས་མེད་པར་ཉམས་ཆོག Out-of-domain translations are often of poor quality and prone to hallucinations, due to exposure bias and the decoder acting as a language model. We adopt two approaches to alleviate this problem: lexical shortlisting restricted by IBM statistical alignments, and hypothesis reranking based on similarity. The methods are computationally cheap and show success on low-resource out-of-domain test sets. ཡིན་ནའང་། ཐབས་ལམ་དེ་བསམ་བློ་གཏོང་ཐབས་ལམ་ཞིག་ཡོད་པའི་ཆ་འཕྲིན་ཡིག་ཆ་ཡང་ན་ཁྱད་ཆེ་བའི་གྲངས This is due to the IBM model losing its advantage over the implicitly learned neural alignment, and problems with subword segmentation of unseen words.'}
{'en': 'Backtranslation in Neural Morphological Inflection', 'ar': 'الترجمة العكسية في الانعكاس الصرفي العصبي', 'fr': "Rétrotranslation dans l'inflexion morphologique neurale", 'pt': 'Retrotradução em Inflexão Morfológica Neural', 'es': 'Retrotraducción en la inflexión morfológica neuronal', 'ja': '神経形態学的変形における逆変換', 'ru': 'Обратная трансляция при нейроморфологическом перегибе', 'zh': '神经形拐点中者反', 'hi': 'तंत्रिका रूपात्मक मोड़ में बैकट्रांसलेशन', 'ga': 'aisaistriúchán i Infhilleadh Néar-mhirfeolaíoch', 'ka': 'Name', 'el': 'Αντιμετάφραση σε Νευρική Μορφολογική Ανατροπή', 'hu': 'Visszafordítás Neural Morphological Inflection', 'it': 'Backtranslation in Neural Morphological Inflession', 'mk': 'Назадtranslation in Neural Morphological Inflection', 'kk': 'Нейралық морфологикалық инфлекциясында қайта аудару', 'lt': 'Backtranslation in Neural Morphological Inflection', 'ml': 'translation in Neural Morphological Inflection', 'mn': 'Backtranslation in Neural Morphological Inflection', 'mt': 'Backtranslation in Neural Morphological Inflection', 'no': 'Tilbakeomsetjing i nøyralt morfologisk infleksjon', 'pl': 'Backtranslacja w neuronowym zaburzeniu morfologicznym', 'ro': 'Traducere inversă în inflexia morfologică neurală', 'sr': 'Povratni prevod u neurološkoj morfološkoj inflekciji', 'si': 'Name', 'so': 'translation in Neural Morphological Inflection', 'sv': 'Backöversättning i neural morfologisk inflektion', 'ms': 'translation in Neural Morphological Inflection', 'ta': 'translation in Neural Morphological Inflection', 'ur': 'Neural Morphological Inflection in Backtranslation', 'uz': 'translation in Neural Morphological Inflection', 'vi': 'Hậu đoạn trong tiếp cận', 'bg': 'Обратен превод в неврално морфологично влияние', 'hr': 'Povratni prevod u neurološkoj morfološkoj inflekciji', 'nl': 'Backtranslation in neurale morfologische inflectie', 'da': 'Backtranslation in Neural Morphological Inflection', 'de': 'Rückübersetzung bei neuronaler morphologischer Inflktion', 'fa': 'ترجمه عقب در تغییرات مورفولوژیک عصبی', 'ko': '신경 형태 굴절 중의 반역', 'sw': 'translation in Neural Morphological Inflection', 'id': 'Backtranslation in Neural Morphological Inflection', 'tr': 'Terjime', 'af': 'Terugvertaling in Neural Morphological Infleksie', 'sq': 'Backtranslation in Neural Morphological Inflection', 'am': 'translation in Neural Morphological Inflection', 'az': 'Nöral Morfolojik Infleksiyanın geri dönüşü', 'hy': 'Translate in', 'bs': 'Povratni prevod u neurološkoj morfološkoj inflekciji', 'bn': 'translations in Neural Morphological Inflection', 'cs': 'Zpětný překlad v neuronové morfologické inflaci', 'et': 'Tagasitõlge neuromorfoloogilises mõjus', 'ca': "Traducció posterior a l'Inflexió Morfològica Neural", 'fi': 'Taaksetranslaatio neuromorfologisessa influenssassa', 'jv': 'translation in Neral Marphologic Information', 'ha': 'translation in Neural morfological Infletion', 'sk': 'Nazaj prevajanje pri živčni morfološki inflekciji', 'he': 'Backtranslation in Neural Morphological Inflection', 'bo': 'Backtranslation in Neural Morphological Inflection'}
{'en': 'Backtranslation is a common technique for leveraging unlabeled data in low-resource scenarios in machine translation. The method is directly applicable to morphological inflection generation if unlabeled word forms are available. This paper evaluates the potential of backtranslation for morphological inflection using data from six languages with labeled data drawn from the SIGMORPHON shared task resource and unlabeled data from different sources. Our core finding is that backtranslation can offer modest improvements in low-resource scenarios, but only if the unlabeled data is very clean and has been filtered by the same annotation standards as the labeled data.', 'ar': 'الترجمة العكسية هي تقنية شائعة للاستفادة من البيانات غير المسماة في سيناريوهات الموارد المنخفضة في الترجمة الآلية. الطريقة قابلة للتطبيق مباشرة على توليد الانعكاس الصرفي إذا كانت أشكال الكلمات غير المسماة متوفرة. تقيم هذه الورقة إمكانات الترجمة العكسية للانعطاف الصرفي باستخدام بيانات من ست لغات مع بيانات مصنفة مأخوذة من مورد المهام المشتركة SIGMORPHON والبيانات غير المسماة من مصادر مختلفة. النتيجة الأساسية التي توصلنا إليها هي أن الترجمة العكسية يمكن أن تقدم تحسينات متواضعة في سيناريوهات الموارد المنخفضة ، ولكن فقط إذا كانت البيانات غير المسماة نظيفة للغاية وتمت تصفيتها وفقًا لمعايير التعليقات التوضيحية نفسها مثل البيانات المصنفة.', 'fr': "La rétrotraduction est une technique courante qui permet d'exploiter des données non étiquetées dans des scénarios à faibles ressources en traduction automatique. La méthode est directement applicable à la génération d'inflexions morphologiques si des formes de mots non étiquetées sont disponibles. Cet article évalue le potentiel de la rétrotranslation pour l'inflexion morphologique à l'aide de données provenant de six langues avec des données étiquetées tirées de la ressource de tâche partagée SIGMORPHON et des données non étiquetées provenant de différentes sources. Notre principale conclusion est que la rétrotraduction peut apporter des améliorations modestes dans les scénarios à faibles ressources, mais uniquement si les données non étiquetées sont très propres et ont été filtrées selon les mêmes normes d'annotation que les données étiquetées.", 'es': 'La retrotraducción es una técnica común para aprovechar los datos sin etiqueta en escenarios de bajos recursos en la traducción automática. El método es directamente aplicable a la generación de inflexiones morfológicas si hay formas de palabras sin etiqueta disponibles. Este artículo evalúa el potencial de la retrotraducción para la inflexión morfológica utilizando datos de seis idiomas con datos etiquetados extraídos del recurso de tareas compartidas de SIGMORPHON y datos no etiquetados de diferentes fuentes. Nuestra conclusión principal es que la retrotraducción puede ofrecer mejoras modestas en situaciones de bajos recursos, pero solo si los datos sin etiqueta están muy limpios y se han filtrado con los mismos estándares de anotación que los datos etiquetados.', 'pt': 'A tradução reversa é uma técnica comum para aproveitar dados não rotulados em cenários de poucos recursos na tradução automática. O método é diretamente aplicável à geração de flexão morfológica se formas de palavras não rotuladas estiverem disponíveis. Este artigo avalia o potencial da retrotradução para flexão morfológica usando dados de seis idiomas com dados rotulados extraídos do recurso de tarefa compartilhada SIGMORPHON e dados não rotulados de diferentes fontes. Nossa descoberta principal é que a retrotradução pode oferecer melhorias modestas em cenários de poucos recursos, mas somente se os dados não rotulados forem muito limpos e tiverem sido filtrados pelos mesmos padrões de anotação dos dados rotulados.', 'hi': 'बैकट्रांसलेशन मशीन अनुवाद में कम संसाधन परिदृश्यों में बिना लेबल वाले डेटा का लाभ उठाने के लिए एक सामान्य तकनीक है। विधि सीधे रूपात्मक मोड़ पीढ़ी के लिए लागू होती है यदि बिना लेबल वाले शब्द रूप उपलब्ध हैं। यह पेपर SIGMORPHON साझा कार्य संसाधन और विभिन्न स्रोतों से अनलेबल किए गए डेटा से तैयार किए गए लेबल किए गए डेटा के साथ छह भाषाओं से डेटा का उपयोग करके रूपात्मक मोड़ के लिए बैकट्रांसलेशन की क्षमता का मूल्यांकन करता है। हमारी मुख्य खोज यह है कि बैकट्रांसलेशन कम-संसाधन परिदृश्यों में मामूली सुधार की पेशकश कर सकता है, लेकिन केवल तभी जब अनलेबल डेटा बहुत साफ है और लेबल किए गए डेटा के समान एनोटेशन मानकों द्वारा फ़िल्टर किया गया है।', 'ja': 'バックトランスレーションは、機械翻訳における低リソースシナリオでラベル付けされていないデータを活用するための一般的な手法です。この方法は、標識されていない単語形態が利用可能である場合、形態学的屈折生成に直接適用可能である。本論文では、SIGMORPHON共有タスクリソースから抽出したラベル付きデータと、異なるソースからのラベルなしデータを用いて、6言語からのデータを用いて、形態学的変形のための逆翻訳の可能性を評価した。私たちの主な調査結果は、バックトランスレーションが低資源シナリオでわずかな改善を提供できることですが、ラベル付けされていないデータが非常にきれいであり、ラベル付けされたデータと同じアノテーション基準でフィルタリングされている場合に限られます。', 'zh': '反向译者,机器翻译之卑资方案也。 若可用未标之单词,则径适形词形变化矣。 本文用六言之数,SIGMORPHON共事资源之标数,与未来之未标数,评形拐点之反译。 我们的核心发现,反向译者可以在资源缺乏的事情中供给适度的改进,但前提是未标记的数据很清净,并且已经按照与标记数据相同的注准。', 'ru': 'Обратный перевод - это распространенный метод использования немаркированных данных в сценариях с низкими ресурсами в машинном переводе. Метод непосредственно применим для генерации морфологических перегибов, если имеются немеченые формы слов. В этой статье оценивается потенциал обратной трансляции для морфологического перегиба с использованием данных с шести языков с мечеными данными, полученными из ресурса совместной задачи SIGMORPHON, и немаркированными данными из различных источников. Наш основной вывод заключается в том, что обратный перевод может предложить скромные улучшения в сценариях с низкими ресурсами, но только в том случае, если немаркированные данные очень чистые и были отфильтрованы по тем же стандартам аннотаций, что и помеченные данные.', 'ga': 'Teicníc choiteann is ea aisaistriúchán chun sonraí neamhlipéadaithe a ghiaráil i gcásanna íseal-acmhainne in aistriúchán meaisín. Tá an modh infheidhme go díreach maidir le hinfhilleadh moirfeolaíocha a ghiniúint má tá foirmeacha focal gan lipéad ar fáil. Déanann an páipéar seo measúnú ar an bpoitéinseal a bhaineann le haisaistriúchán do infhilleadh moirfeolaíoch ag baint úsáide as sonraí ó shé theanga le sonraí lipéadaithe ó thasc comhroinnte SIGMORPHON agus sonraí neamhlipéadaithe ó fhoinsí éagsúla. Is é an príomhthoradh atá againn ná gur féidir le haisaistriúchán feabhsuithe measartha a thairiscint i gcásanna íseal-acmhainne, ach amháin má tá na sonraí neamhlipéadaithe an-ghlan agus go bhfuil siad scagtha de réir na gcaighdeán anótála céanna agus atá na sonraí lipéadaithe.', 'el': 'Η αναδρομική μετάφραση είναι μια κοινή τεχνική για τη χρησιμοποίηση δεδομένων χωρίς ετικέτα σε σενάρια χαμηλού πόρου στη μηχανική μετάφραση. Η μέθοδος εφαρμόζεται άμεσα στην παραγωγή μορφολογικών καμπυλών εάν υπάρχουν διαθέσιμες μορφές λέξεων χωρίς επισήμανση. Η παρούσα εργασία αξιολογεί το δυναμικό της αντίστροφης μετάφρασης για μορφολογική καμπύλη χρησιμοποιώντας δεδομένα από έξι γλώσσες με επισήμαντα δεδομένα που προέρχονται από τον πόρο κοινής εργασίας και μη επισήμαντα δεδομένα από διαφορετικές πηγές. Το βασικό μας συμπέρασμα είναι ότι η αναδρομική μετάφραση μπορεί να προσφέρει μέτρια βελτιώσεις σε σενάρια χαμηλού κόστους πόρων, αλλά μόνο εάν τα δεδομένα χωρίς ετικέτα είναι πολύ καθαρά και έχουν φιλτραριστεί με τα ίδια πρότυπα σχολιασμού με τα δεδομένα που έχουν επισημανθεί.', 'ka': 'Backtranslation არის საერთო ტექნოგია, რომელიც მაქსინური გაგრძელებაში არაფერილი მონაცემების შესახებ. პროგრამა მოპოროლოგიური ინფლექციის შემდეგ დააყენებელია, თუ არა წერტილი სიტყვის ფორმები ხელმისაწარმოდგენია. ამ დოკუმენტი მოპოროლოგიური ინფლექციის შესახებ მონაცემების შესახებ მონაცემების შესახებ შვიდი ენაზე, რომლებიც სიმბოლოგიური მონაცემების შესახებ SIGMORPHON გაყოფილი დავა ჩვენი მნიშვნელოვანი აღმოჩენა, რომ backtranslation შეუძლია მინდომი რესურსის სინარიოში უფრო მეტი შესაძლებლობა, მაგრამ მხოლოდ თუ არაფერი მონაცემები მნიშვნელოვანია და იგივე მონაცემების სტ', 'lt': 'Grįžtamasis vertimas yra bendras metodas, kuriuo naudojant mašin in į vertimą naudojami nepažymėti duomenys, naudojami mažai išteklių turinčiais scenarijais. Šis metodas tiesiogiai taikomas morfologiniam įkišimui, jei yra pažymėtų žodžių formų. Šiame dokumente vertinamas galimas grįžtamasis vertimas morfologiniam įvedimui, naudojant šešių kalbų duomenis su pažymėtais duomenimis, paimtais iš SIGMORPHON bendro užduočių išteklio ir be žymėtų duomenų iš skirtingų šaltinių. Mūsų pagrindinė išvada yra ta, kad atgalinis vertimas gali nedideliu mastu pagerinti mažai išteklių turinčius scenarijus, tačiau tik jei nepažymėti duomenys yra labai švari ir buvo filtruoti pagal tuos pačius anotacijos standartus kaip ir pažymėti duomenys.', 'it': "Backtranslation è una tecnica comune per sfruttare dati non etichettati in scenari a basso contenuto di risorse nella traduzione automatica. Il metodo è direttamente applicabile alla generazione di flessioni morfologiche se sono disponibili forme di parole non etichettate. Questo articolo valuta il potenziale della backtranslation per l'inflessione morfologica utilizzando dati provenienti da sei lingue con dati etichettati tratti dalla risorsa task condivisa SIGGMORPHON e dati non etichettati provenienti da fonti diverse. Il nostro principale risultato è che la backtranslation può offrire modesti miglioramenti in scenari a basso consumo di risorse, ma solo se i dati non etichettati sono molto puliti e sono stati filtrati dagli stessi standard di annotazione dei dati etichettati.", 'kk': 'Аудару - машина аудармасындағы төмен ресурстар сценариясында жалпы деректерді қолдану үшін жалпы техникалық. Бұл әдіс морфологиялық инфлекцияны құру үшін тікелей қолданылады, егер сөз пішіндері бар болса. Бұл қағаз, SIGMORPHON ортақ тапсырманың ресурсынан жазылған деректермен алты тілден алты тілден морфологиялық инфлекциялық аудармасының мүмкіндігін бағалайды. Басқа көзгертілмеген деректері мен Біздің негізгі табуымыз - backtranslation деген ресурстар сценариясында төменгі жақсартылығын түсіндіре алады, бірақ тек ескертілмеген деректері өте таза болса және мәліметті белгілеген деректерге сүзгіледі.', 'hu': 'A Backtranslation egy gyakori technika a címke nélküli adatok felhasználására alacsony erőforrás-igényű forgatókönyvekben a gépi fordításban. A módszer közvetlenül alkalmazható a morfológiai hajlékonyság generálására, ha rendelkezésre állnak címke nélküli szóformák. Ez a tanulmány hat nyelvű adatok felhasználásával értékeli a visszafordítás morfológiai inflexió lehetőségét a SIGGMORPHON megosztott feladat erőforrásból származó címkézett adatokkal és különböző forrásokból származó címke nélküli adatokkal. Alapvető megállapításunk az, hogy a visszafordítás mérsékelt fejlesztéseket kínál az alacsony erőforrásokkal foglalkozó forgatókönyvekben, de csak akkor, ha a címke nélküli adatok nagyon tiszták és ugyanazok a jegyzetelési szabványok szerint szűrték, mint a címkézett adatok.', 'mk': 'Backtranslation е обична техника за користење на неозначени податоци во сценарија со ниски ресурси во машински превод. Методот е директно применлив за генерацијата на морфолошки инфекции ако се достапни неозначени форми на зборови. Овој документ го оценува потенцијалот на враќање на морфолошкиот превод со користење на податоци од шест јазици со означени податоци извадени од SIGMORPHON споделениот ресурс на задачи и неозначени податоци од различни извори. Нашиот основен заклучок е дека грб-преводот може да нуди скромни подобрувања во сценаријата со ниски ресурси, но само ако неозначените податоци се многу чисти и се филтрирани со истите стандарди на анотација како и означените податоци.', 'ms': 'Backtranslation is a common technique for leveraging unlabeled data in low-resource scenarios in machine translation. Kaedah ini secara langsung berlaku pada generasi penyebaran morfologik jika bentuk perkataan tidak ditabel tersedia. Kertas ini meneliti potensi terjemahan belakang untuk penyebaran morfologik menggunakan data dari enam bahasa dengan data yang ditabel dilukis dari sumber tugas berkongsi SIGMORPHON dan data tidak ditabel dari sumber berbeza. Penemuan utama kami adalah bahawa terjemahan belakang boleh menawarkan peningkatan sederhana dalam skenario sumber rendah, tetapi hanya jika data tidak berlebihan sangat bersih dan telah ditapis oleh piawai anotasi yang sama dengan data yang ditabel.', 'mn': 'Backtranslation is a common technique for leveraging unlabeled data in low-resource scenarios in machine translation. Хэрвээ тэмдэглэгдэхгүй үг хэлбэрүүд байвал морфологик нөлөөлөлийн үеэр шууд хэрэглэгддэг. This paper evaluates the potential of backtranslation for morphological inflection using data from six languages with labeled data drawn from the SIGMORPHON shared task resource and unlabeled data from different sources. Our core finding is that backtranslation can offer modest improvements in low-resource scenarios, but only if the unlabeled data is very clean and has been filtered by the same annotation standards as the labeled data.', 'mt': 'It-traduzzjoni fl-isfond hija teknika komuni għall-ingranaġġ ta’ dejta mhux immarkata f’xenarji b’riżorsi baxxi fit-traduzzjoni bil-magna. Il-metodu huwa direttament applikabbli għall-ġenerazzjoni ta’ inflezzjoni morfoloġika jekk ikunu disponibbli forom ta’ kliem mingħajr tikketta. Dan id-dokument jevalwa l-potenzjal ta’ backtranslation għal inflezzjoni morfoloġika bl-użu ta’ dejta minn sitt lingwi b’dejta ttikkettata miġbura mir-riżorsa ta’ kompitu kondiviża SIGMORPHON u dejta mhux ittikkettata minn sorsi differenti. Is-sejba ewlenija tagħna hija li t-traduzzjoni lura tista’ toffri titjib modest fix-xenarji b’riżorsi baxxi, iżda biss jekk id-dejta mhux ittikkettata tkun nadifa ħafna u tkun ġiet iffiltrata bl-istess standards ta’ annotazzjoni bħad-dejta ttikkettata.', 'ml': 'translation is a common technique for levering unlabeled data in low- resource scenarios in machine translation. വാക്കുകളുടെ ഫോമുകള്\u200d ലഭ്യമല്ലെങ്കില്\u200d നേരിട്ട് മോര്\u200dഫോളിക്കല്\u200d ഫോര്\u200dമാര്\u200dമാറ്റുന്നതിനായി പ്രയോഗിക്ക ഈ പത്രത്തില്\u200d ആറു ഭാഷകളില്\u200d നിന്നും ചിട്ടപ്പെട്ട ഡേറ്റാ ഉപയോഗിച്ച് മോര്\u200dഫോളജിക്കുന്നതിനുള്ള ബാക്ക്\u200cട്രിന്\u200dഷന്\u200d സാധ്യതയുടെ സാധ്യതയും വ്യത്യ നമ്മുടെ കൂട്ടത്തിലുള്ള കണ്ടെത്തുന്നത് ബാക്ക്\u200cട്രിന്\u200dസിന്\u200dറെ മെച്ചപ്പെട്ട മെച്ചപ്പെടുത്താന്\u200d സാധിക്കുന്നതാണെന്നാണ്. പക്ഷെ അടയാളപ്', 'ro': 'Backtranslation este o tehnică comună pentru utilizarea datelor fără etichete în scenarii cu resurse reduse în traducerea automată. Metoda este direct aplicabilă generarii inflexiunii morfologice dacă sunt disponibile forme de cuvinte fără etichete. Această lucrare evaluează potențialul traducerii înapoi pentru inflexiunea morfologică utilizând date din șase limbi cu date etichetate extrase din resursa de activitate comună SIGGMRPHON și date necontabilizate din diferite surse. Rezultatul nostru principal este că backtranslation poate oferi îmbunătățiri modeste în scenariile cu resurse reduse, dar numai dacă datele fără etichete sunt foarte curate și au fost filtrate după aceleași standarde de adnotare ca datele etichetate.', 'pl': 'Backtranslation jest powszechną techniką wykorzystywania danych nieoznakowanych w scenariuszach niskich zasobów w tłumaczeniu maszynowym. Metoda ta jest bezpośrednio stosowana do generowania zmian morfologicznych, jeśli dostępne są nieoznakowane formy słów. W artykule dokonano oceny potencjału backtranslacji dla zmiany morfologicznej przy użyciu danych z sześciu języków z oznakowanymi danymi pochodzącymi ze wspólnego zasobu zadań SIGMORPHON oraz danych nieoznakowanych z różnych źródeł. Nasze główne ustalenie polega na tym, że backtranslation może zapewnić skromne ulepszenia w scenariuszach niskich zasobów, ale tylko wtedy, gdy dane nieoznakowane są bardzo czyste i zostały przefiltrowane według tych samych standardów adnotacji, co dane etykietowane.', 'no': 'Tilbakeomsetjing er ein vanleg teknikk for å levera ulike data i låg ressursscenarioar i maskinsomsetjinga. Metoden er direkte tilgjengeleg for formasjon av morfologiske infleksjon dersom det er tilgjengeleg ikkje merkelige ordformar. Denne papiret evaluerer potensialen for tilbakeomsetjing til morfologiske infleksjon ved å bruka data frå seks språk med merkelige data teikne frå delt oppgåveressursen SIGMORPHON og ikkje merkelige data frå ulike kilder. Dette finn kjerneomsetjinga vår er at tilbakeomsetjinga kan tilbys minste forbedringar i låg ressursscenario, men berre dersom dei ulike dataene er svært reine og har blitt filtrert av same notasjonsstandardar som dei merkelige data.', 'sr': 'Backtranslation je zajednička tehnika za upotrebu nepobeleženih podataka u scenarijima niskog resursa u prevodu mašine. Metod je direktno primjenjivan na generaciju morfološke inflekcije ako su dostupni oblici neopisivanih reči. Ovaj papir procjenjuje potencijal backtranslation za morfološku inflekciju koristeći podatke sa šest jezika sa označenim podacima izvedenim iz zajedničkog zadatkovnog resursa SIGMORPHON-a i neizbiljnih podataka iz različitih izvora. Naše osnovno otkriće je da backtranslation može ponuditi skromne poboljšanje u scenarijima niskih resursa, ali samo ako su podaci bez imena veoma čisti i filtrirani istim standardima annotacije kao što su podaci označeni.', 'sv': 'Backtranslation är en vanlig teknik för att utnyttja omärkta data i scenarier med låga resurser i maskinöversättning. Metoden är direkt tillämplig på morfologisk böjning generering om det finns obemärkta ordformer. Denna uppsats utvärderar potentialen med backtranslation för morfologisk böjning med hjälp av data från sex språk med märkta data hämtade från SIGGMORPHON delade aktivitetsresurs och omärkta data från olika källor. Vår huvudsakliga slutsats är att backtranslation kan erbjuda blygsamma förbättringar i scenarier med låga resurser, men bara om de omärkta data är mycket rena och har filtrerats enligt samma kommentarstandarder som de märkta data.', 'so': 'Backtranslation is a common technique for delivering unlabeled data in low-resource scenarios in machine translation. Midabka waxaa si toos ah loo isticmaalaa muuqashada muraajiyada, haddii ay heystaan noocyada hadalka aan la aqoon lahayn. Warqadan ayaa qiimeynaya suurtagalka tarjumaadda dib-tarjiilka oo la isticmaalayo macluumaadka lix luqadood oo labeled data laga soo qoray SIGMORPHON qaybsan resource shaqo iyo macluumaad aan la labeled oo laga soo diro sourceo kala duduwan. Helitaankeena koonfureed waa in turjumista dib u dhigi karo horumarinta hoose-resourceedka, laakiin haddii macluumaadka aan la aqoonin ay aad u daahirsanaayeen oo lagu filteriyay si lamid ah calaamadaha la xiriiray oo kale.', 'ta': 'translation is a common technique for levering unlabeled data in low- resource scenarios in machine translation. குறிப்பிடாத வார்த்தை வடிவங்கள் கிடைக்கும் போது நேரடியாக மாற்றத்திற்கு பயன்படுத்தப்படும். இந்த paper evaluates the potential of backtranslation for morphological inflection using data from six languages with labeled data drawn from the SIGMORPHON shared task resource and unlabeled data from different sources. எங்கள் மூல கண்டுபிடிப்பு என்னவென்றால் பின்மொழிப்பெயர்ப்பு குறைந்த மூலத்தின் காட்சியில் முன்னேற்றங்களை கொடுக்க முடியும், ஆனால் குறிப', 'si': 'Backtranslation is a generic tech for assistive readers in low-source scenarios in the machine translation. මේ විධානය ප්\u200dරතික්\u200dරමාණය ප්\u200dරවේශනය සඳහා ප්\u200dරතික්\u200dරමාණය සඳහා ප්\u200dරතික්\u200dරමාණය කරන්න පුළුවන්. Name අපේ ප්\u200dරධානය හොයාගන්නේ පසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුපසුම් වෙන්න පුළුවන්, ඒත් පස', 'ur': 'Backtranslation is a common technique for leveraging unlabeled data in low-resource scenarios in machine translation. یہ طریقہ مستقیماً مورفولوژیکی اثرات کی نسل پر لازم ہے اگر غیر لکھی لکھی لکھی فرموں موجود ہیں۔ This paper evaluates the potential of backtranslation for morphological inflection using six languages with labeled data drawn from the SIGMORPHON shared task resource and unlabeled data from different sources. ہماری اصلی پیدا کرنا یہ ہے کہ پک ترجمہ کم منبع سناریوں میں بہت کم ترجمہ کرسکتا ہے، لیکن صرف اگر نامزد نہ ہوئی ڈاٹا بہت پاک ہے اور اس کے ساتھ بھی نامزد استانداریوں کے ذریعہ فیلٹر کیا گیا ہے جیسے لیبل کیا گیا ڈاٹا۔', 'uz': 'translation is a common technique for levering unlabeled data in low- resource scenarios in machine translation. Name This paper evaluates the potential of backtranslation for morphological inflection using data from six languages with labeled data drawn from the SIGMORPHON shared task resource and unlabeled data from different sources.  @ info', 'vi': 'Dịch phụ là một kỹ thuật phổ biến để vận dụng dữ liệu chưa tải (động) trong các viễn cảnh hạ nguồn trong dịch cỗ máy. Phương pháp này được áp dụng trực tiếp với việc sản sinh biến từ ngữ theo chiều chuẩn nếu có dạng từ không được dán. Tờ này phân tích khả năng dịch ngược về biến đổi lịch sử sử sử sử dụng dữ liệu từ sáu ngôn ngữ với dữ liệu được dán nhãn được lấy từ tài nguyên tác vụ đã chia sẻ SIMPAF và dữ liệu chưa tải từ các nguồn khác nhau. Điểm mấu chốt của chúng tôi là bản dịch phụ có thể cho thấy cải tiến khiêm tốn trong các tình huống với nguồn ít, nhưng chỉ khi dữ liệu chưa được sửa lỗi rất sạch và đã được lọc bằng các tiêu chuẩn ghi chú như các dữ liệu đã ghi rõ.', 'nl': "Backtranslation is een veelvoorkomende techniek voor het gebruik van niet-gelabelde gegevens in scenario's met weinig resources in machinevertaling. De methode is direct toepasbaar op morfologische buigingsgeneratie als er niet-gelabelde woordvormen beschikbaar zijn. Dit artikel evalueert het potentieel van backtranslation voor morfologische inflectie met behulp van gegevens uit zes talen met gelabelde gegevens afkomstig van de gedeelde taak van SIGMORPHON en niet-gelabelde gegevens uit verschillende bronnen. Onze kernbevinding is dat backtranslation bescheiden verbeteringen kan bieden in scenario's met weinig resources, maar alleen als de niet-gelabelde gegevens zeer schoon zijn en zijn gefilterd volgens dezelfde annotatienormen als de gelabelde gegevens.", 'da': 'Backtranslation er en almindelig teknik til at udnytte ikke-mærkede data i scenarier med lav ressource i maskinoversættelse. Metoden er direkte anvendelig til morfologisk bøjning generering, hvis der findes ikke mærkede ordformer. Denne artikel evaluerer potentialet for backtranslation for morfologisk bøjning ved hjælp af data fra seks sprog med mærkede data trukket fra SIGGMORPHON delte opgaveressource og ikke-mærkede data fra forskellige kilder. Vores centrale konklusion er, at backtranslation kan tilbyde beskedne forbedringer i scenarier med lav ressource, men kun hvis de ikke-mærkede data er meget rene og er blevet filtreret efter de samme annotationsstandarder som de mærkede data.', 'de': 'Backtranslation ist eine gängige Technik, um nicht beschriftete Daten in ressourcenarmen Szenarien in der maschinellen Übersetzung zu nutzen. Die Methode ist direkt anwendbar auf morphologische Beugungserzeugung, wenn nicht beschriftete Wortformen verfügbar sind. In diesem Beitrag wird das Potenzial der Rückübersetzung für morphologische Flexion anhand von Daten aus sechs Sprachen mit markierten Daten aus der gemeinsamen Aufgabenressource SIGMORPHON und nicht gekennzeichneten Daten aus verschiedenen Quellen evaluiert. Unsere zentrale Erkenntnis ist, dass Backtranslation bescheidene Verbesserungen in ressourcenarmen Szenarien bieten kann, aber nur, wenn die nicht beschrifteten Daten sehr sauber sind und nach denselben Anmerkungsstandards gefiltert wurden wie die beschrifteten Daten.', 'bg': 'Обратният превод е често срещана техника за използване на немаркирани данни в сценарии с ниски ресурси в машинния превод. Методът е пряко приложим при генериране на морфологични наклонения, ако са налице незабелязани думи. В настоящата статия се оценява потенциалът на обратния превод за морфологична инфлекция, като се използват данни от шест езика с етикетирани данни, извлечени от споделения ресурс на задачите и неетикетирани данни от различни източници. Основната ни констатация е, че обратният превод може да предложи скромни подобрения в сценарии с ниски ресурси, но само ако неетикетираните данни са много чисти и са филтрирани по същите стандарти за анотация като етикетираните данни.', 'hr': 'Backtranslation je zajednička tehnika za primjenu neopisivanih podataka u scenarijima niskih resursa u prevodu stroja. Metod je direktno primjenjivan na generaciju morfološke inflekcije ako su dostupni neopiseni oblici riječi. Ovaj papir procjenjuje potencijal povratnog prevoda za morfološku inflekciju koristeći podatke iz šest jezika s označenim podacima izvedenim iz zajedničkog zadatkovnog resursa SIGMORPHON-a i neizbiljnih podataka iz različitih izvora. Naše osnovno otkriće je da backtranslation može ponuditi skromne poboljšanje u scenarijima niskih resursa, ali samo ako su podaci bez imena vrlo čisti i filtrirani istim standardima annotacije kao i podacima označenim.', 'ko': '반역은 기계 번역에서 저자원 장면에서 표기되지 않은 데이터를 이용하는 상용 기술이다.만약 표기되지 않은 어형이 있다면, 이 방법은 형태 변화의 생성에 직접 적용된다.본고는 6개 언어의 데이터, SIGMORPHON 공유 작업 자원에서 나온 표기 데이터와 서로 다른 출처에서 온 표기되지 않은 데이터를 사용하여 형태 변화 반역의 잠재력을 평가했다.우리의 핵심 발견은 낮은 자원 상황에서 반역은 적당한 개선을 제공할 수 있으나, 전제는 표시되지 않은 데이터가 매우 깨끗하고, 표시된 데이터와 같은 주석 기준에 따라 필터링되었다는 것이다.', 'tr': "Iň terjime edilmek maşynyň terjime edilmesinde ýazman maglumatlary iň az resursy senaryýasynda süýtgetmek üçin bir orta teknikdir. Eger başarmaýan söz biçimleri bar, morfoloýulyk etmäniň döwletlerine direkt uygulanabilir. Bu käze SIGMORPHON'yň beýleki täzeliklerden we beýleki çeşmelerden soňra ýazylan veriler ullanýan alty dillerden ullanýan arka terjime etjeginiň mümkinçiligini çykýar. Biziň esasy tapylşymyz, arka terjime edilen iň az resurs senaryýasynda örän düýsek gelişmeler teklip edip bilýär, ýöne diňe ýazşyrmadyk maglumatlar örän arassa bolsa we etilgeli maglumatlar bilen filteredildi.", 'sw': 'translation is a common technique for delivering data unmarked in low resource scenarios in translation of machine. Utawala unatumika moja kwa moja kwa kizazi cha ushawishi wa kimaadili kama aina isiyoeleweka zinapatikana. Makala hii inaonyesha uwezekano wa kutafsiri kwa ajili ya ushawishi wa kimaadili kwa kutumia taarifa kutoka lugha sita zenye taarifa zinazoonyesha kutoka SIGMORPHON zinazoshirikisha rasilimali za kazi na taarifa zisizoeleweka kutoka vyanzo tofauti. Ugunduzi wetu wa msingi ni kwamba tafsiri ya upinzani inaweza kutoa maendeleo mazuri katika hali ya chini ya rasilimali, lakini ni kama taarifa zisizoeleweka ni safi sana na imechapishwa na viwango sawa vya taarifa hizo.', 'fa': 'تغییر پشتیبانی یک تکنیک مشترک برای استفاده از داده های غیرقابل استفاده در سیناریو های منبع کم در ترجمه ماشین است. این روش مستقیماً برای نسل تأثیرات مورفولوژیکی مواجه می\u200cشود اگر فرم\u200cهای کلمه نامزدی در دسترس باشند. این کاغذ پتانسیل ترجمه پشتیبانی برای تأثیر مورفولوژیکی را با استفاده از داده های از شش زبان با داده\u200cهای برچسب\u200cشده از منابع کار مشترک SIGMORPHON و داده\u200cهای بدون استفاده از منابع مختلف ارزیابی می\u200cکند. پیدا کردن اصلی ما این است که ترجمه پشتیبانی می تواند کمترین بهترین پیشنهاد در سناریو های کمترین منبع را پیشنهاد دهد، اما فقط اگر داده های نامزدی بسیار پاک باشد و با استانداردهای نامزدی مثل داده های نامزدی فیلتر شده باشد.', 'af': "Terugvertaling is 'n gemeenskaplike tekniks vir die uitbreiding van ongeabelde data in lae- hulpbron scenarios in masjien vertaling. Die metode is direk toewenbaar vir morfologiese inflekking generasie as ongeabelde woord vorms beskikbaar is. Hierdie papier evalueer die potensieal van agtergrondvertaling vir morfologiese infleksie met gebruik van data van ses tale met etiketeerde data geteken van die Sigmorfon gedeelde taak hulpbron en onbekende data van verskillende bronne. Ons kern soek is dat terugvertaling kan modeste verbeteringe in lae- hulpbronne scenarios aanbied, maar slegs as die ongeabelde data baie rein is en is filtered deur dieselfde annotasie standaarde as die gemerkte data.", 'id': 'Backtranslation adalah teknik umum untuk menggunakan data yang tidak disebut dalam skenario sumber daya rendah dalam terjemahan mesin. The method is directly applicable to morphological inflection generation if unlabeled word forms are available.  Kertas ini mengevaluasi potensi terjemahan belakang untuk infleksi morfologi menggunakan data dari enam bahasa dengan data yang dicetak dari sumber tugas berbagi SIGMORPHON dan data yang tidak dicetak dari sumber berbeda. Penemuan utama kami adalah bahwa backtranslation dapat menawarkan peningkatan sederhana dalam skenario sumber daya rendah, tetapi hanya jika data yang tidak diberi tanda sangat bersih dan telah ditulis oleh standar anotasi yang sama dengan data yang diberi tanda.', 'am': 'translation is a common technique for levering unlabeled data in low-resource scenarios in machine translation. መልዕክት ይህ ፕሮግራም የደብዳቤውን ትርጉም ማድረግ የሞሮፎሎጂ ማቀናቀል ከስድስት ቋንቋዎች ዳታ በተለየ SIGMORPHON የስራ ክፍተት እና ከልዩ ምንጮች የተለየ መረጃዎች በተለየ ጥያቄ ይታያል፡፡ አካላዊ ግንኙነታችን የደብዳቤ ትርጓሜ በዝቅተኛ resource scenario ውስጥ ትክክል ማድረግ እንዲችል ነው፤ ነገር ግን ያልታወቀው ዳታ እጅግ ንጹሕ ቢሆን እና እንደተጻፈ በአካባቢው ዳታዎች የተጠቃሚ ክፍል ቢሆን ብቻ ነው፡፡', 'hy': 'Բարթարգմանությունը ընդհանուր տեխնիկան է, որպեսզի մեքենայի թարգմանության մեջ օգտագործենք աննշան տվյալներ ցածր ռեսուրսների սցենարներում: Այս մեթոդը անմիջապես կիրառվում է մորֆոլոգիական ազդեցության սերունդների հետ, եթե բառերի առանց նշանների ձևերը հասանելի են: Այս աշխատանքը գնահատում է մորֆոլոգիական արտադրման պոտենցիալը օգտագործելով վեց լեզուներից ստացված տվյալներ, որոնք նշանված են SIGOrPHon-ի ընդհանուր աշխատանքային ռեսուրսից և տարբեր աղբյուրներից բացահայտված տվյալներ: Մեր հիմնական հայտնաբերությունն այն է, որ ետնաթարգմանությունը կարող է նվազեցնել ցածր ռեսուրսների սցենարները, բայց միայն եթե անվազեցված տվյալները շատ մաքուր են և ֆիլտրված են նույն նոտացիայի ստանդարտներով, ինչպիսիք են պիտակուցված տվյա', 'bn': '@ info: whatsthis এই পদ্ধতি সরাসরি মোরফোলগিক্যাল প্রভাবিত প্রজন্মের জন্য প্রয়োজনীয়, যদি অলাইন শব্দের ফর্ম পাওয়া যায়। এই পত্রিকাটি শেয়ার কর্ম সম্পদ এবং বিভিন্ন সূত্র থেকে নির্বাচিত তথ্যের মাধ্যমে ছয় ভাষা থেকে ডাটা ব্যবহার করে মোরফোলজিক্যাল প্রভাবের জন্য ব্যাক-অন আমাদের মূল অনুসন্ধান হচ্ছে যে ব্যাক-অনুবাদ নিম্নলিখিত রিসোর্স পরিস্থিতিতে কম উন্নতি প্রদান করতে পারে, কিন্তু যদি অলাইনের তথ্য খুব পরিষ্কার এবং লেবে', 'bs': 'Backtranslation je zajednička tehnika za primjenu nepobećanih podataka u scenarijima niskih resursa u prevodu mašine. Metod je direktno primjenjivan na generaciju morfološke inflekcije ako su dostupne neopisne formulare riječi. Ovaj papir procjenjuje potencijal backtranslation za morfološku inflekciju koristeći podatke iz šest jezika sa označenim podacima izvedenim iz zajedničkog zadatkovnog resursa SIGMORPHON-a i neizbiljnih podataka iz različitih izvora. Naše osnovno otkriće je da backtranslation može ponuditi skromne poboljšanje u scenarijima niskih resursa, ali samo ako su podaci bez imena vrlo čisti i filtrirani istim standardima annotacije kao i podaci označene.', 'az': 'Backtranslation mašin tercüməsindəki düşük ressurs senaryoları içində istifadə edilməmiş məlumatları istifadə etmək üçün ortaq bir teknikdir. Əgər yazılmadığı söz formları faydalanırsa, bu metod morfolojik infleksiyon nəsilinə doğrudan uyğun olar. Bu kağıt, SIGMORPHON paylaşdırılmış işlər çoxluğundan və müxtəlif kaynaqlardan yazılmış məlumatları istifadə edilən altı dildən verilən Morfolojik infleksyonun geri çevirilməsinin potensialını değerləşdirir. Bizim ilk öyrənməyimiz belədir ki, backtranslation düşük ressurs scenariolarında ucuz düzəltmələri təbliğ edə bilər, amma yalnız təklif edilməmiş məlumatlar çox təmizdir və etiketli məlumatlar kimi istifadə edilmiş istifadə standartları ilə filtrlənir.', 'cs': 'Zpětný překlad je běžná technika pro využití neznačených dat v nízkých scénářích s nízkými zdroji v strojovém překladu. Metoda je přímo použitelná pro tvorbu morfologických kloubů, pokud jsou k dispozici neoznačené slovní formy. Tento článek hodnotí potenciál zpětného překladu pro morfologickou inflekci pomocí dat ze šesti jazyků s označenými daty čerpanými ze sdíleného zdroje úloh SIGMORPHON a neoznačených dat z různých zdrojů. Naším hlavním zjištěním je, že zpětný překlad může nabídnout mírné zlepšení ve scénářích s nízkými zdroji, ale pouze pokud jsou data bez označení velmi čistá a byla filtrována stejnými anotacemi jako data s označením.', 'et': 'Tagasitõlkimine on tavaline meetod märgistamata andmete kasutamiseks masintõlke vähese ressursiga stsenaariumides. Meetodit kohaldatakse otseselt morfoloogilise painde tekitamisel, kui märgistamata sõnavormid on olemas. Käesolevas töös hinnatakse tagasitõlke potentsiaali morfoloogilise paindlikkuse jaoks, kasutades andmeid kuuest keelest, millel on märgistatud andmed SIGMORPHONi jagatud ülesannete ressursist ja märgistamata andmed erinevatest allikatest. Meie põhiline järeldus on, et tagasitõlkimine võib pakkuda mõõdukaid parandusi vähese ressursiga stsenaariumides, kuid ainult siis, kui märgistamata andmed on väga puhtad ja on filtreeritud samade märgistusstandarditega nagu märgistatud andmed.', 'sq': 'Backtranslation is a common technique for leveraging unlabeled data in low-resource scenarios in machine translation. The method is directly applicable to morphological inflection generation if unlabeled word forms are available.  Ky dokument vlerëson potencialin e përkthimit mbrapsht për përdorimin morfologjik duke përdorur të dhëna nga gjashtë gjuhë me të dhëna të etiketuara të nxjerra nga burimi i përbashkët i detyrave SIGMORPHON dhe të dhëna pa etiketë nga burime të ndryshme. Our core finding is that backtranslation can offer modest improvements in low-resource scenarios, but only if the unlabeled data is very clean and has been filtered by the same annotation standards as the labeled data.', 'fi': 'Backtranslation on yleinen tekniikka, jolla voidaan hyödyntää merkitsemätöntä dataa konekäännöksen vähäresurssisissa skenaarioissa. Menetelmää voidaan soveltaa suoraan morfologisten taipumusten tuottamiseen, jos saatavilla on merkitsemättömiä sanamuotoja. Tässä artikkelissa arvioidaan takaisinkääntämisen mahdollisuuksia morfologiseen taipumukseen käyttäen kuuden kielen dataa, joissa on merkitty tieto, joka on peräisin SIGMORPHON-jaetusta tehtäväresurssista ja merkitsemätöntä tietoa eri lähteistä. Keskeinen havaintomme on, että backtranslation voi tarjota vaatimattomia parannuksia vähäresurssisissa skenaarioissa, mutta vain jos merkitsemätön data on erittäin puhdasta ja on suodatettu samoilla merkintästandardeilla kuin merkitty data.', 'ca': "La retrotraducció és una tècnica comú per aprofitar dades no etiquetades en escenaris de baix recursos en la traducció màquina. El mètode s'aplica directament a la generació d'inflexió morfològica si hi ha formes de paraules no etiquetades. Aquest paper evalua el potencial de la traducció inversa per inflexió morfològica utilitzant dades de sis llengües amb dades etiquetades dibuixades del recurso compartit de tasques SIGMORPHON i dades no etiquetades de diferents fonts. La nostra conclusió principal és que la traducció inversa pot oferir modestes millores en escenaris de baix recursos, però només si les dades no etiquetades són molt netes i han estat filtrats pels mateixos estàndards d'anotació que les dades etiquetades.", 'sk': 'Nazaj prevajanje je pogosta tehnika za izkoriščanje neoznačenih podatkov v scenarijih z nizkimi viri v strojnem prevajanju. Metoda se neposredno uporablja za generiranje morfoloških infleksij, če so na voljo neoznačene besedne oblike. V prispevku je ocenjen potencial nazaj prevajanja za morfološko inflekcijo s podatki iz šestih jezikov z označenimi podatki iz skupnega vira opravil SIGMORPHON in neoznačenimi podatki iz različnih virov. Naša glavna ugotovitev je, da lahko nazaj prevod ponudi skromne izboljšave v scenarijih z nizkimi viri, vendar le, če so neoznačeni podatki zelo čisti in so bili filtrirani po enakih standardih opombe kot označeni podatki.', 'he': 'התרגום האחורי הוא טכניקה משותפת לנצל נתונים ללא סימנים בתרחיש משאבים נמוכים בתרגום מכונות. השיטה מתאימה ישירות לדור השפעה מורפולוגית אם נוצרי מילים ללא סימנים זמינים. העבודה הזו מעריכה את הפוטנציאל של התרגום האחורי לשימוש מורפולוגי באמצעות נתונים מששת שפות עם נתונים מסוימים ממשקל המשימה המשותף SIGMORPHON ומידע לא מסוים ממקורים שונים. המצאה העיקרית שלנו היא שהתרגום האחורי יכול להציע שיפורים צנועים בתרחיש משאבים נמוכים, אך רק אם המידע הלא רשום הוא נקי מאוד והוא היה מסנן על ידי אותם סטנדרטים הערות כמו המידע המתווים.', 'ha': "translation is a ordinary tech for sharing unlable data in lower- resource zonaries in Macine translation. @ info: whatsthis Wannan takardar ta ƙaddara the awon translation of back for morfological haƙin mai amfani da data from 6 languages with labled data drew from the SiGMORPHO share resource and unelable data from several sources. Ana gane kwamfyutan bayani, zan iya iya samar da baƙaƙƙe masu rauni cikin fassarar-resource, kuma amma idan data na da ba'a rubutu da shi ba zai zama mai tsari kuma aka filterar da su da kiman alama kamar da aka rubuta.", 'bo': 'Backtranslation is a common technique for leveraging unlabeled data in low-resource scenarios in the machine translation. གལ་སྲིད་བྱས་མེད་པའི་ཐ་སྙད་ཅིག་འདི་གཟུགས་འགྱུར་བ་དང་འཕགས་རིས་ཀྱི་ཁྱད་པར་སྤྱོད་ཐུབ་པ། This paper evaluates the potential of backtranslation for morphological inflection using data from six languages with labeled data drawn from the SIGMORPHON shared task resource and unlabeled data from different sources. Our core finding is that backtranslation can offer modest improvements in low-resource scenarios, but only if the unlabeled data is very clean and has been filtered by the same annotation standards as the labeled data.', 'jv': 'Backtranslation iku teknik sing berarti kanggo nggawe data yang dipunanggap karo sekènari apakno kanggo ditambang maneh. Metopo dadi bisa aplikasi kanggo ngeralakno nyong nggunakake Name Kita punika ingkang punika dipun-punika nik backtranslation iso dianggap ngomong gak bener neng sistem sing gak bener maces, nango iso dipun dadi sing gak bener dhéwé lan warni iki dipun dianggap sing berarti ujak maneh sing berarti podho sing wis etiket berarti.'}
{'en': 'Challenging the Semi-Supervised VAE Framework for Text Classification', 'pt': 'Desafiando a estrutura VAE semi-supervisionada para classificação de texto', 'fr': 'Défier le cadre VAE semi-supervisé pour la classification de texte', 'es': 'Desafiando el marco VAE semisupervisado para la clasificación de textos', 'ar': 'تحدي إطار عمل VAE شبه الخاضع للإشراف لتصنيف النص', 'zh': '挑战文本分者半督 VAE 框架', 'ja': 'テキスト分類のための半監修VAEフレームワークへの挑戦', 'hi': 'पाठ वर्गीकरण के लिए अर्ध पर्यवेक्षित VAE फ्रेमवर्क को चुनौती देना', 'ru': 'Оспаривание полунадзорной структуры VAE для классификации текста', 'ga': 'Dúshlán a thabhairt don Chreat VAE Leath-mhaoirsithe um Aicmiú Téacs', 'ka': 'ტექსტის კლასიფიკაციისთვის პრომენტი დანახვა VAE პარამეტრები', 'hu': 'A szövegosztályozás félig felügyelt VAE keretrendszerének kihívása', 'el': 'Αντιμετώπιση του ημιεποπτευόμενου πλαισίου VAE για την ταξινόμηση κειμένου', 'it': 'Sfidare il quadro VAE semisupervisionato per la classificazione dei testi', 'lt': 'Iššūkis pusiau prižiūrimos TPE teksto klasifikavimo sistemos uždavinys', 'ms': 'Mencabar Semi-Supervised VAE Framework for Text Classification', 'mk': 'Предизвик на полунадгледуваната ВЕЕ рамка за класификација на текст', 'kk': 'Мәтін классификациясының жарты бақылау VAE фреймдерін өзгерту', 'ml': 'പദാവലി ക്ലാസിഷനിക്കുവേണ്ടി സെമി- സുപ്രദര്\u200dശിപ്പിക്കപ്പെട്ട VAE ഫ്രെമ്മെക്കോര്\u200dക്ക് ചെല', 'mn': 'Текст классификацийн төлөвлөгөөний төлөвлөгөөс хагас найдаж,', 'no': 'Name', 'mt': 'L-isfida tal-Qafas tal-VAE Semissorveljat għall-Klassifikazzjoni tat-Test', 'ro': 'Provocarea cadrului VAE semisupravegheat pentru clasificarea textelor', 'pl': 'Stawianie czołowego nadzoru ramowego VAE dla klasyfikacji tekstów', 'sr': 'Izazovanje polu nadzornog VAE okvira za klasifikaciju teksta', 'sv': 'Att utmana den halvövervakade ramen för VAE för textklassificering', 'so': 'Challenging the Semi-Supered VAE Framework for Text Classification', 'si': 'පරීක්ෂා විද්\u200dයාපනය සඳහා පාළු විද්\u200dයාපනය විද්\u200dයාපනය', 'ta': 'Name', 'ur': 'ٹیکسٹ کلاسیفٹ کے لئے نصف-Supervised VAE Framework چلنگ', 'uz': 'Comment', 'vi': 'Thách thức bộ phận hóa đơn bán nón', 'da': 'Udfordring af rammebestemmelserne for halvtilsynet VAE for tekstklassificering', 'bg': 'Предизвикателство на полунадзорната рамка за класификация на текста на VAE', 'hr': 'Izazovanje polu nadzornog okvira VAE za klasifikaciju teksta', 'ko': '텍스트 분류에 도전하는 반감시VAE 프레임워크', 'de': 'Herausforderung des semi-supervised VAE Framework for Text Classification', 'fa': 'چالش ساختمانۀ پایین مراقبت VAE برای کلاس\u200cسازی متن', 'sw': 'Kupigania Mfumo wa VAE wa Kuhusu Makala', 'af': 'Name', 'nl': 'Uitdaging van het semi-supervised VAE Framework voor tekstclassificatie', 'sq': 'Duke sfiduar kuadrin e gjysmë-mbikqyrur VAE për klasifikimin e tekstit', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'id': 'Mencabar Semi-Supervised VAE Framework untuk Klasifikasi Teks', 'az': 'Metin Klasifikasyonu üçün yarı-gözləyirli VAE Framework', 'bn': 'টেক্সট ক্লাসিকেশনের জন্য সেমি- সাপার্ভিস ভিএই ফ্রেমার্ক চ্যালেঞ্জ করা হচ্ছে', 'bs': 'Izazovanje polu nadzornog okvira VAE za klasifikaciju teksta', 'tr': 'Semi-gözetli VAE Framework for Text Classification', 'ca': "Desafiant el marc semisupervisat d'EEV per la classificació del text", 'hy': 'Տեքստի դասակարգման կես-վերահսկվող ՎԱԵ համակարգի մարտահրավերը', 'et': 'Pooljärelevalve alla kuuluva VAE raamistiku vaidlustamine teksti klassifitseerimiseks', 'fi': 'Tekstiluokitusta koskevan puolivalvotun VAE-kehyksen haastaminen', 'cs': 'Výzva polovičně kontrolovaného rámce VAE pro klasifikaci textů', 'jv': 'Cagling', 'sk': 'Izpodbijanje polnadzorovanega okvira VAE za klasifikacijo besedila', 'bo': 'རྒྱ་ཡིག་གི་དབྱེ་སྟངས་ལ་དུས་མཐུན་བཟོས་ཚར་བ(VAE)', 'ha': 'KCharselect unicode block name', 'he': 'מאתגר את המסגר של VAE חצי-מושגים לסימן טקסט'}
{'en': 'Semi-Supervised Variational Autoencoders (SSVAEs) are widely used models for data efficient learning. In this paper, we question the adequacy of the standard design of sequence SSVAEs for the task of text classification as we exhibit two sources of overcomplexity for which we provide simplifications. These simplifications to SSVAEs preserve their theoretical soundness while providing a number of practical advantages in the semi-supervised setup where the result of training is a text classifier. These simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unobserved latent variable from its probabilistic model. These changes relieve users from choosing a prior for their latent variables, make the model smaller and faster, and allow for a better flow of information into the latent variables. We compare the simplified versions to standard SSVAEs on 4 text classification tasks. On top of the above-mentioned simplification, experiments show a speed-up of 26 %, while keeping equivalent classification scores. The code to reproduce our experiments is public.', 'ar': 'تعد أجهزة التشفير التلقائي المتغيرة شبه الخاضعة للإشراف (SSVAEs) نماذج مستخدمة على نطاق واسع للتعلم الفعال للبيانات. في هذه الورقة ، نشكك في مدى ملاءمة التصميم القياسي لتسلسل SSVAEs لمهمة تصنيف النص حيث نعرض مصدرين من التعقيد المفرط نقدم لهما التبسيط. تحافظ هذه التبسيطات على SSVAEs على سلامتها النظرية مع توفير عدد من المزايا العملية في الإعداد شبه الخاضع للإشراف حيث تكون نتيجة التدريب عبارة عن مصنف نصي. هذه التبسيط هي إزالة (1) اختلاف Kullback-Liebler من هدفه و (2) المتغير الكامن غير المرصود بالكامل من نموذجه الاحتمالي. تعفي هذه التغييرات المستخدمين من اختيار المتغيرات الكامنة مسبقًا ، وتجعل النموذج أصغر وأسرع ، وتسمح بتدفق أفضل للمعلومات إلى المتغيرات الكامنة. قارنا الإصدارات المبسطة بمعايير SSVAEs في 4 مهام لتصنيف النص. علاوة على التبسيط المذكور أعلاه ، تظهر التجارب تسريعًا بنسبة 26٪ ، مع الحفاظ على درجات تصنيف مكافئة. الشفرة لإعادة إنتاج تجاربنا علنية.', 'fr': "Les auto-encodeurs variationnels semi-supervisés (SSVAE) sont des modèles largement utilisés pour un apprentissage efficace des données. Dans cet article, nous remettons en question l'adéquation de la conception standard des SSVAE de séquence pour la tâche de classification de texte, car nous présentons deux sources de complexité excessive pour lesquelles nous fournissons des simplifications. Ces simplifications apportées aux SSVAE préservent leur solidité théorique tout en offrant un certain nombre d'avantages pratiques dans la configuration semi-supervisée où le résultat de la formation est un classificateur de texte. Ces simplifications consistent à supprimer (i) la divergence de Kullback-Liebler de son objectif et (ii) la variable latente totalement non observée de son modèle probabiliste. Ces modifications évitent aux utilisateurs de choisir un paramètre antérieur pour leurs variables latentes, rendent le modèle plus petit et plus rapide, et permettent un meilleur flux d'informations dans les variables latentes. Nous comparons les versions simplifiées aux SSVAE standard pour 4 tâches de classification de texte. En plus de la simplification mentionnée ci-dessus, les expériences montrent une accélération de 26\xa0%, tout en conservant des scores de classification équivalents. Le code pour reproduire nos expériences est public.", 'es': 'Los autocodificadores variacionales semisupervisados (SSVAE) son modelos ampliamente utilizados para el aprendizaje eficiente de los datos. En este artículo, cuestionamos la idoneidad del diseño estándar de los SSVAE de secuencia para la tarea de clasificación de textos, ya que exhibimos dos fuentes de complejidad excesiva para las que proporcionamos simplificaciones. Estas simplificaciones de los SSVAE preservan su solidez teórica al tiempo que proporcionan una serie de ventajas prácticas en la configuración semisupervisada donde el resultado de la capacitación es un clasificador de texto. Estas simplificaciones son la eliminación de (i) la divergencia de Kullback-Liebler de su objetivo y (ii) la variable latente totalmente inobservada de su modelo probabilístico. Estos cambios alivian a los usuarios de elegir un valor previo para sus variables latentes, hacen que el modelo sea más pequeño y rápido y permiten un mejor flujo de información en las variables latentes. Comparamos las versiones simplificadas con los SSVAE estándar en 4 tareas de clasificación de texto. Además de la simplificación mencionada anteriormente, los experimentos muestran una aceleración del 26%, manteniendo puntuaciones de clasificación equivalentes. El código para reproducir nuestros experimentos es público.', 'pt': 'Autoencoders Variacionais Semi-Supervisionados (SSVAEs) são modelos amplamente utilizados para aprendizado eficiente de dados. Neste artigo, questionamos a adequação do design padrão de SSVAEs de sequência para a tarefa de classificação de texto, pois exibimos duas fontes de supercomplexidade para as quais fornecemos simplificações. Essas simplificações para SSVAEs preservam sua solidez teórica ao mesmo tempo em que proporcionam uma série de vantagens práticas na configuração semissupervisionada onde o resultado do treinamento é um classificador de texto. Essas simplificações são a remoção (i) da divergência de Kullback-Liebler de seu objetivo e (ii) da variável latente totalmente não observada de seu modelo probabilístico. Essas mudanças aliviam os usuários de escolher um prior para suas variáveis latentes, tornam o modelo menor e mais rápido e permitem um melhor fluxo de informações para as variáveis latentes. Comparamos as versões simplificadas com SSVAEs padrão em 4 tarefas de classificação de texto. Além da simplificação mencionada acima, os experimentos mostram uma aceleração de 26%, mantendo pontuações de classificação equivalentes. O código para reproduzir nossos experimentos é público.', 'ja': '半監視型バリエーションオートエンコーダー（ SSVAE ）は、データ効率の良い学習のために広く使用されているモデルです。 本論文では、テキスト分類のタスクのための配列SSVAEの標準設計の妥当性について疑問を呈している。これは、単純化を提供する2つの過剰複雑性のソースを示すためである。 ＳＳＶＡＥに対するこれらの簡略化は、訓練の結果がテキスト分類子である半監督セットアップにおいて、いくつかの実用的な利点を提供しながら、それらの理論的健全性を維持する。 これらの単純化は、(i)クルバック-リーブラー発散をその目的から除去し、(ii)完全に観測されていない潜在的変数をその確率モデルから除去することである。 これらの変更により、ユーザーは潜伏変数の事前設定を選択することがなくなり、モデルがより小さく速くなり、潜伏変数への情報の流れが改善されます。 4つのテキスト分類タスクで、簡易版を標準のSSVAEと比較します。 上記の単純化実験に加えて、同等の分類スコアを維持しながら、26%のスピードアップを示している。 私たちの実験を再現するコードは公開されています。', 'hi': 'अर्ध-पर्यवेक्षित परिवर्तनीय ऑटोएनकोडर (एसएसवीएई) डेटा कुशल सीखने के लिए व्यापक रूप से उपयोग किए जाने वाले मॉडल हैं। इस पेपर में, हम पाठ वर्गीकरण के कार्य के लिए अनुक्रम एसएसवीएई के मानक डिजाइन की पर्याप्तता पर सवाल उठाते हैं क्योंकि हम अतिसंवाद के दो स्रोतों को प्रदर्शित करते हैं जिसके लिए हम सरलीकरण प्रदान करते हैं। एसएसवीएई के लिए ये सरलीकरण अर्ध-पर्यवेक्षित सेटअप में कई व्यावहारिक लाभ प्रदान करते हुए अपनी सैद्धांतिक सुदृढ़ता को संरक्षित करते हैं जहां प्रशिक्षण का परिणाम एक पाठ क्लासिफायर है। ये सरलीकरण (i) अपने उद्देश्य से कुलबैक-लिबलर विचलन को हटाना और (ii) इसके संभाव्य मॉडल से पूरी तरह से अनदेखा अव्यक्त चर है। ये परिवर्तन उपयोगकर्ताओं को अपने अव्यक्त चर के लिए एक पूर्व चुनने से राहत देते हैं, मॉडल को छोटा और तेज़ बनाते हैं, और अव्यक्त चर में जानकारी के बेहतर प्रवाह की अनुमति देते हैं। हम 4 पाठ वर्गीकरण कार्यों पर मानक SSVAEs के लिए सरलीकृत संस्करणों की तुलना करते हैं। उपर्युक्त सरलीकरण के शीर्ष पर, प्रयोग 26% की गति दिखाते हैं, जबकि समकक्ष वर्गीकरण स्कोर रखते हैं। हमारे प्रयोगों को पुन: पेश करने के लिए कोड सार्वजनिक है।', 'zh': '半监变分自编码器(SSVAE)者,所以数高效学之广用也。 质疑序SSVAE,设计于充分性,盖展其两端,供其简化也。 SSVAE简存其理合理性,而给实势于半监,训练者,文本类器也。 此简化者,(i)Kullback-Liebler偏离其所向(ii)从其概率形中全未察者潜除于变量。 使用户无所潜于变量择先验,使模形更小,愈疾,许其信入变量。 简本与 4 文本分类 SSVAE 较之。 自此之外,实验示速26%,而守等效之分。 重见吾实验代码明矣。', 'ru': 'Полуконтролируемые вариационные автокодировщики (SSVAE) являются широко используемыми моделями для эффективного обучения данным. В данной работе мы ставим под сомнение адекватность стандартной конструкции последовательности SSVAE для задачи классификации текста, так как мы демонстрируем два источника чрезмерной сложности, для которых мы предоставляем упрощения. Эти упрощения к SSVAE сохраняют свою теоретическую обоснованность, предоставляя ряд практических преимуществ в полунадзорной настройке, где результатом обучения является текстовый классификатор. Эти упрощения являются удалением (i) расхождения Куллбека-Либлера от его цели и (ii) полностью ненаблюдаемой скрытой переменной из его вероятностной модели. Эти изменения освобождают пользователей от выбора априора для своих скрытых переменных, делают модель меньше и быстрее и позволяют улучшить поток информации в скрытые переменные. Мы сравниваем упрощенные версии со стандартными SSVAE по 4 задачам классификации текста. Вдобавок к вышеупомянутому упрощению, эксперименты показывают ускорение на 26%, сохраняя эквивалентные баллы классификации. Код для воспроизведения наших экспериментов является общедоступным.', 'ga': 'Is samhlacha a úsáidtear go forleathan iad Uath-ionchódóirí Athrógacha Leathmhaoirsithe (SSVAEanna) le haghaidh foghlama tíosach ar shonraí. Sa pháipéar seo, cuirimid ceist faoi leorgacht an dearaidh chaighdeánaigh de sheichimh SSVAEanna don tasc a bhaineann le haicmiú téacs mar go léirímid dhá fhoinse ró-castachta a gcuirimid simplithe ar fáil dóibh. Caomhnaíonn na simplithe seo ar SSVAEanna a bhfóntacht theoiriciúil agus cuireann siad roinnt buntáistí praiticiúla ar fáil sa socrú leath-mhaoirseachta nuair is aicmitheoir téacs é toradh na hoiliúna. Is éard atá i gceist leis na simplithe seo ná (i) an éagsúlacht Kullback-Liebler a bhaint óna chuspóir agus (ii) an athróg fholaigh nach bhfuil breathnaithe go hiomlán óna samhail dóchúlachta. Tugann na hathruithe seo faoiseamh d’úsáideoirí ó réamhfhocal a roghnú dá n-athróga folaigh, déanann siad an tsamhail níos lú agus níos tapúla, agus ceadaíonn siad sreabhadh níos fearr faisnéise isteach sna hathróga folaigh. Déanaimid comparáid idir na leaganacha simplithe agus SSVAEanna caighdeánacha ar 4 thasc aicmithe téacs. Anuas ar an simpliú thuasluaite, taispeánann turgnaimh luas suas de 26%, agus scóir aicmithe coibhéiseacha á gcoimeád acu. Tá an cód chun ár dturgnaimh a atáirgeadh poiblí.', 'ka': 'ნახევარჯერი გარეთიციონალური ავტოკოდერები (SSVAEs) იყენება დიდი მოდელების გამოყენება მონაცემებისთვის ეფექტიური სწავლებისთვის. ამ დომენტში, ჩვენ ვაკითხვით სტანდარტული სერექსიფიკაციის სტანდარტული სერექსიფიკაციის დამუშაობას, როგორც ჩვენ გამოჩვენებთ ორი ძალიან კომპლექსიკოლექსიტების მსგავსი ეს განხორცილებები SSVAEs-ის ტეორეტიკური სიგრძნობის შეუძლებელია, როდესაც პრაქტიკური გამოსახულებების რამდენიმე პროგრამიკური გამოსახულებების გასახულებლად, სადაც განახლების შედეგი ტექსტი ეს გამოყენება არის i) Kullback-Liebler განსხვავება მისი მიზეზიდან და ii) მისი შესაბამისი მოდელიდან ყველაფერად დაახლოებილი ლატენტიური განსხვავება. ეს ცვლილებები მომხმარებელების გამოყენებას წინასწორედ მონიშნეთ ცვლილებისთვის, მოდელის გაზრუნეთ და უფრო სიჩქარე, და უფრო უკეთესი ინფორმაციის გარცვლილებისთვის ჩვენ განვითარებული ვერსიები სტანდარტული SSVAEs-თან 4 ტექსტის კლასიფიკაციის დავალებისთვის შედგენებთ. გამოსახულებული განსხვავებაზე, ექსპერიმენტები 26%-ის სიჩქარე ჩვენებს, როცა ექსგალენტი კლასიფიკაციის მონაცემები იყოს. ჩვენი ექსპერიმენტები გარეშექმნის კოდი არის ადამიანი.', 'hu': 'A félig felügyelt variációs autokódolók (SSVAE) széles körben használt modellek az adathatékony tanuláshoz. Jelen tanulmányban megkérdőjelezzük, hogy a szövegosztályozás feladatához megfelelő-e az SSVAE-k szabványos kialakítása, mivel a túlkomplexitás két forrását mutatjuk be, amelyekhez egyszerűsítéseket biztosítunk. Ezek az egyszerűsítések az SSVAE-k számára megőrzik elméleti megalapozottságukat, miközben számos gyakorlati előnyt biztosítanak a félig felügyelt rendszerben, ahol a képzés eredménye szövegosztályozó. Ezek az egyszerűsítések a Kullback-Liebler célkitűzésétől való eltérésének eltávolítása, valamint a valószínűsíthető modelljétől való teljes mértékben megfigyelhetetlen látens változó eltávolítása. Ezek a változások megkönnyítik a felhasználókat a látens változók előzetes kiválasztásától, kisebbé és gyorsabbá teszik a modellt, és lehetővé teszik a látens változók jobb információáramlását. Az egyszerűsített változatokat a standard SSVAE-khez hasonlítjuk össze 4 szövegosztályozási feladat során. A fent említett egyszerűsítés mellett a kísérletek 26%-os gyorsulást mutatnak, miközben azonos osztályozási pontszámokat tartanak fenn. A kísérleteink reprodukálására szolgáló kód nyilvános.', 'el': 'Οι ημι-εποπτευόμενοι αυτόματοι κωδικοποιητές παραλλαγών (είναι ευρέως χρησιμοποιούμενα μοντέλα για αποδοτική μάθηση δεδομένων. Στην παρούσα εργασία, αμφισβητούμε την επάρκεια του τυποποιημένου σχεδιασμού των ακολουθιών για το έργο της ταξινόμησης κειμένων καθώς επιδεικνύουμε δύο πηγές υπερπολυπλοκότητας για τις οποίες παρέχουμε απλοποιήσεις. Αυτές οι απλοποιήσεις στα SSVAE διατηρούν τη θεωρητική τους αξιοπιστία ενώ παρέχουν ορισμένα πρακτικά πλεονεκτήματα στην ημι-εποπτική εγκατάσταση όπου το αποτέλεσμα της εκπαίδευσης είναι ένας ταξινομητής κειμένου. Αυτές οι απλοποιήσεις είναι η κατάργηση (i) της απόκλισης Kullback-Liebler από τον στόχο της και (ii) της πλήρως μη παρατηρούμενης λανθάνουσας μεταβλητής από το πιθανό μοντέλο της. Αυτές οι αλλαγές ανακουφίζουν τους χρήστες από την επιλογή ενός προηγούμενου για τις λανθάνουσες μεταβλητές τους, κάνουν το μοντέλο μικρότερο και ταχύτερο και επιτρέπουν μια καλύτερη ροή πληροφοριών στις λανθάνουσες μεταβλητές. Συγκρίνουμε τις απλοποιημένες εκδόσεις με τις τυποποιημένες σε εργασίες ταξινόμησης τεσσάρων κειμένων. Εκτός από την προαναφερθείσα απλοποίηση, τα πειράματα δείχνουν επιτάχυνση 26%, διατηρώντας ισοδύναμες βαθμολογίες ταξινόμησης. Ο κώδικας αναπαραγωγής των πειραμάτων μας είναι δημόσιος.', 'it': "Gli autocodificatori a variazione semisupervisionata (SSVAE) sono modelli ampiamente utilizzati per l'apprendimento efficiente dei dati. In questo articolo, mettiamo in discussione l'adeguatezza del design standard degli SSVAE di sequenza per il compito di classificazione del testo in quanto mostriamo due fonti di sovracomplessità per le quali forniamo semplificazioni. Queste semplificazioni per gli SSVAE preservano la loro solidità teorica fornendo al contempo una serie di vantaggi pratici nella configurazione semi-supervisionata, dove il risultato della formazione è un classificatore di testo. Queste semplificazioni consistono nell'eliminazione (i) della divergenza Kullback-Liebler dal suo obiettivo e (ii) della variabile latente completamente inosservata dal suo modello probabilistico. Queste modifiche sollevano gli utenti dalla scelta di un precedente per le loro variabili latenti, rendono il modello più piccolo e veloce e consentono un migliore flusso di informazioni nelle variabili latenti. Confrontiamo le versioni semplificate con le SSVAE standard su 4 attività di classificazione del testo. Oltre alla semplificazione di cui sopra, gli esperimenti mostrano una velocità del 26%, pur mantenendo punteggi di classificazione equivalenti. Il codice per riprodurre i nostri esperimenti è pubblico.", 'kk': 'Жарты бақылау Автоматтық Автоматтық Кодерлер (SSVAEs) деректерді эффективті оқыту үшін үлгі қолданылады. Бұл қағазда, біз SSVAE стандартты түрлендіру тапсырмасының стандартты түрлендірімізді сұрақтаймыз. Бұл жағдайда біз қарапайым түрлендіріміздің екі түрлендірілігін көрсетеді. Бұл SSVAE үшін теоретикалық дыбыстығын сақтау кезінде бірнеше практикалық артықшылықтарды жарты бақылау баптауында қалай оқыту нәтижесі мәтін классификациясы болады. Бұл қарапайымдылықтар: i) Kullback- Liebler мақсаттығынан келтіріліп, ii) оның мүмкіндікті үлгісінен толық қаралмаған latent айнымалылығын өшіру. Бұл өзгерістер келесі айнымалыларды таңдау үшін пайдаланушыларды өзінің алдындағы айнымалыларды таңдауға көмектеседі, үлгісін кішірейтін және тез қылуға мүмкіндік береді, және Біз қарапайым нұсқаларды 4 мәтін салыстыру тапсырмаларында стандартты SSVAE- ге салыстырық. Жоғардағы қарапайымдылығының жоғарында, тәжірибелер 26% жылдамдығын көрсетеді. Бірақ тең классификациялық нөмірлерін сақтау үшін. Біздің тәжірибемдерімізді қайта жасау кодымыз көпшілік.', 'lt': 'Puspriežiūrėti kintamųjų savikodai (SSVAE) yra plačiai naudojami veiksmingo duomenų mokymosi modeliai. Šiame dokumente mes abejojame, ar standartinis SSVAE sekos projektas atitinka teksto klasifikavimo užduotį, nes rodome du pernelyg sudėtingumo šaltinius, kuriems teikiame supaprastinimus. Šie supaprastinimai SSVAE išlaiko jų teorinį patikimumą ir suteikia tam tikrų praktinių pranašumų pusiau prižiūrimoje struktūroje, kurioje mokymo rezultatas yra teksto klasifikatorius. Šie supaprastinimai yra i) Kullback-Liebler skirtumas nuo jo tikslo pašalinimas ir ii) visiškai nepastebimas latentinis kintamasis nuo jo probabilistinio modelio. Šie pokyčiai palengvina naudotojus pasirinkti ankstesnį jų latentiniams kintamiesiems, daro model į mažesnis ir greitesnis ir leidžia geresniam informacijos srautui į latentinius kintamuosius. Palyginame supaprastintas versijas su standartinėmis SSVAE 4 teksto klasifikavimo užduotimis. Be pirmiau minėto supaprastinimo, eksperimentai rodo 26 proc. greitį ir išlaiko lygiaverčius klasifikavimo rezultatus. Kodas mūsų eksperimentams atkurti yra viešas.', 'ms': 'Autopengekod Perubahan Semi-Dijaga (SSVAE) adalah model yang digunakan secara luas untuk pembelajaran efisien data. Dalam kertas ini, kita mempertanyakan keperluan desain piawai SSVAE urutan untuk tugas kelasukan teks kerana kita menunjukkan dua sumber keterlaluan yang kita sediakan. These simplifications to SSVAEs preserve their theoretical soundness while providing a number of practical advantages in the semi-supervised setup where the result of training is a text classifier.  Permudahan ini adalah pembuangan (i) perbezaan Kullback-Liebler dari objektifnya dan (ii) pembolehubah tersembunyi yang tidak dilihat sepenuhnya dari model kemungkinannya. Perubahan ini melepaskan pengguna daripada memilih sebelumnya untuk pembolehubah tersembunyi mereka, membuat model lebih kecil dan lebih cepat, dan membolehkan aliran maklumat yang lebih baik ke dalam pembolehubah tersembunyi. Kami membandingkan versi mudah dengan SSVAE piawai pada 4 tugas kelasukan teks. Di atas kemudahan yang disebut di atas, eksperimen menunjukkan kelajuan 26%, sementara menjaga skor klasifikasi yang sama. Kod untuk mereproduksi eksperimen kita adalah awam.', 'mk': 'Semi-Supervised Variational Autoencoders (SSVAEs) are widely used models for data efficient learning.  Во овој документ, се сомневаме во соодветноста на стандардниот дизајн на секвенциските SSVAE за задачата на класификацијата на текстот додека изложуваме два извори на прекумерна комплексност за кои обезбедуваме поедноставувања. Овие поедноставувања за SSVAE ја зачуваат нивната теоретска здравост додека обезбедуваат голем број практични предности во полунадгледуваното поставување каде резултатот на обуката е текст класификатор. These simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unobserved latent variable from its probabilistic model.  Овие промени ги олеснуваат корисниците од изборот на претходните за нивните лантни променливи, го направат моделот помал и побрз и овозможуваат подобар тек на информации во лантните променливи. Ги споредуваме поедноставените верзии со стандардните SSVAE на 4 задачи за класификација на текст. Покрај наведеното едноставување, експериментите покажуваат забрзување од 26 отсто, при што се одржуваат еквивалентни оценки за класификација. Кодот за репродукција на нашите експерименти е јавен.', 'mn': 'Хэдхэн Хэрэглэгдсэн Variational Autoencoders (SSVAEs) нь өгөгдлийн бүтээмжтэй суралцах үйлдвэрлэлийн загваруудыг ихэвчлэн ашигладаг. Энэ цаасан дээр бид SSVAE-ын стандарт дарааллын загварын адилхан байдлыг асууж байна. Бид текст хуваалтын ажил дээр хоёр хэмжээний цогцолтын эх үүсвэрийг харуулж байна. Эдгээр хялбарчлалууд нь теоретикийн чимээгүй байдлыг хадгалаж байдаг. Харин хагас дасгал хөгжлийн үр дүнг нь текст хэлбэрээр хэлбэрээр хэдэн практикийн давуу ашиг өгдөг. Эдгээр хялбарчлалууд бол i) Kullback-Liebler-ын зорилготой өөрчлөлтийг устгах ба ii) магадлалын загвараас бүрэн харагдаагүй соронзон хувьсагч. Эдгээр өөрчлөлт нь өмнө нь өөрчлөлтийг сонгохын тулд хэрэглэгчдийг илүү хурдан багасгаж, загварыг багасгаж, хурдан илүү сайхан мэдээллийн урсгалыг хадгалах боломжтой болгодог. Бид энгийн хувилбаруудыг стандарт SSVAEs-тай харьцуулж байна 4 текст хуваалтын ажил. Үүний дээр хэлсэн хялбарчлал дээр туршилтууд 26% хурдтай хурдтай харуулж байна. Тэнцүү хэлбэрийн тоонуудыг хадгалж байна. Бидний туршилтыг үржүүлэх код бол нийтлэг.', 'no': 'Halvoversikte variasjonale autokodar (SSVAEs) er breidde brukte modeller for data effektivt læring. I denne papiret spør vi om adekvitet til standardsdesign av sekvens SSVAEs for oppgåva til tekstklassifikasjon som vi viser to kjelder av overkompleksitet som vi gjev enklaringar for. Desse forenklingane til SSVAE beholder teoretiske lydstyrken deres mens det gjer mange praktiske fordel i den halvoversikte oppsettet der resultatet av opplæring er ein tekstklassifiserer. Desse forenklingane er å fjerna i) forskjellen av Kullback-Liebler frå objektet sin, og ii) den fullstendig utsvarte latentvariabelen frå sannsynlige modellen sin. Desse endringane leverer brukarar frå å å velja eit førre for dei latere variabelene sine, gjera modellen mindre og raskare, og tillat å ha bedre informasjonsflytting inn i latere variabelene. Vi sammenliknar dei enklare versjonane med standard SSVAE på 4 tekstklassifikasjonsprogrammet. På øvre av den oppgjevne forenklinga viser eksperimentane ein raskaren på 26 %, mens det held ekvivalente klassifikasjonspoeng. Koden som skal gjenoppretta eksperimentet våre er offentlig.', 'ml': 'സെമി- സുപ്രദര്\u200dശിപ്പിക്കപ്പെട്ട വേറിയനേഷന്\u200d സ്റ്റോക്കോഡെര്\u200dഡുകള്\u200d (SSVAEs) ഡാറ്റായുള്ള പഠിക്കുവാന്\u200d വേണ് ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d എസ്വിഎസിന്\u200dറെ സാധാരണ ഡിസൈന്\u200dസിന്\u200dറെ മതിയെന്ന് ചോദ്യം ചെയ്യുന്നു. ടെക്സ്റ്റ് ക്ലാസ്ഫിക്ഷന്\u200dറെ ജോലിയില്\u200d ഞങ്ങള്\u200d രണ്ട് സ് എസ്സ്\u200cവിഎസിലേക്കുള്ള എളുപ്പമുള്ള ഈ സൌകര്യങ്ങള്\u200d അവരുടെ തിയറ്ററിക്കല്\u200d ശബ്ദത്തെ സൂക്ഷിക്കുക. പരിശീലനത്തിന്റെ ഫലം ഒരു ടെക്സ്ക്ലാസ് ഈ എളുപ്പമാണ് കുള്\u200dബാക്ക്-ലിബ്ലെര്\u200d വ്യത്യാസങ്ങള്\u200d അതിന്റെ ലക്ഷ്യത്തില്\u200d നിന്നും നീക്കം ചെയ്യുന്നത്. അതിന്റെ സാധ്യതകള്\u200d മാതൃകയില്\u200d നിന ഈ മാറ്റങ്ങള്\u200d അവയുടെ അവസാന മാറ്റങ്ങള്\u200dക്കുള്ള മുമ്പ് ഒരു മാറ്റങ്ങള്\u200d തെരഞ്ഞെടുക്കുന്നതില്\u200d നിന്ന് ഉപയോക്താക്കളെ ഉപയോക്താക്കള്\u200dക 4 ടെക്സ്റ്റ് ടെക്സ്റ്റ് ക്ലാസ്ഫിക്ഷന്\u200d ജോലികളില്\u200d സാധാരണ എസ്വിഎസിനോട് നമ്മള്\u200d എളുപ്പമുള്ള പതിപ്പ മുകളിലുള്ള എളുപ്പത്തിന്റെ മുകളില്\u200d, പരീക്ഷണങ്ങള്\u200d 26% വേഗത്തിലേക്ക് കാണിക്കുന്നു, സമാനമായ ക്ലാസ്ഫിക്ഷന്\u200d സ്കോര്\u200d  നമ്മുടെ പരീക്ഷണങ്ങള്\u200d പുനര്\u200dമ്മിപ്പിക്കാനുള്ള കോഡ് പൊതുവാണ്.', 'ro': 'Autoencoderele semisupravegheate (SSVAE) sunt modele utilizate pe scară largă pentru învățarea eficientă a datelor. În această lucrare, punem la îndoială caracterul adecvat al designului standard al SSVAE-urilor secvențiale pentru sarcina clasificării textului, deoarece prezentăm două surse de supracomplexitate pentru care oferim simplificări. Aceste simplificări pentru întreprinderile SSVAE își păstrează soliditatea teoretică, oferind în același timp o serie de avantaje practice în configurația semi-supravegheată, unde rezultatul formării este un clasificator de text. Aceste simplificări sunt eliminarea (i) divergenței Kullback-Liebler față de obiectivul său și (ii) variabilei latente complet neobservate față de modelul său probabilistic. Aceste modificări scutesc utilizatorii de la alegerea unui anterior pentru variabilele latente, fac modelul mai mic și mai rapid și permit un flux mai bun de informații în variabilele latente. Comparăm versiunile simplificate cu SSVAE standard pe 4 sarcini de clasificare a textului. Pe lângă simplificarea menționată mai sus, experimentele arată o viteză de 26%, menținând în același timp scoruri de clasificare echivalente. Codul pentru reproducerea experimentelor noastre este public.', 'pl': 'Semi-Supervised Variational Autoencoders (SSVAE) to szeroko stosowane modele do efektywnego uczenia się danych. W niniejszym artykule kwestionujemy adekwatność standardowego projektu sekwencyjnych SSVAE do zadania klasyfikacji tekstu, ponieważ wykazujemy dwa źródła nadmiernej skomplikowaności, dla których zapewniamy uproszczenia. Uproszczenia te dla SSVAE zachowują swoją solidność teoretyczną, zapewniając jednocześnie szereg praktycznych zalet w konfiguracji pół-nadzorowanej, gdzie efektem szkolenia jest klasyfikator tekstowy. Uproszczenia te polegają na usunięciu (i) rozbieżności Kullbacka-Lieblera od jego celu oraz (ii) w pełni nieobserwowanej utajonej zmiennej z modelu prawdopodobieństwa. Zmiany te zwalniają użytkowników od wyboru uprzedniego dla ich zmiennych utajonych, sprawiają, że model jest mniejszy i szybszy, a także pozwalają na lepszy przepływ informacji do zmiennych utajonych. Porównujemy wersje uproszczone do standardowych SSVAE na czterech zadaniach klasyfikacji tekstu. Oprócz wyżej wymienionego uproszczenia eksperymenty wykazują przyspieszenie 26%, przy zachowaniu równoważnych wyników klasyfikacji. Kod do reprodukcji naszych eksperymentów jest publiczny.', 'sr': 'Polu nadzornih varijacijskih autokodera (SSVAE) široko se koriste modeli za učinkovito učenje podataka. U ovom papiru ispitujemo adekvatnost standardnog dizajna SSVAE-a za zadatak klasifikacije teksta kao što pokazujemo dva izvora prekompleksnosti za koje pružamo pojednostavljenje. Ova pojednostavljanja SSVAE-ima sačuvaju svoju teorijsku zvuk dok pružaju broj praktičnih prednosti u polu-nadzornom setu gde je rezultat obuke klasifikator teksta. Ove pojednostavljenje su uklanjanje i) razlike Kullback-Lieblera iz objektiva i ii) potpuno neočuvane latentne varijable iz njegovog verovatnog modela. Ove promjene olakšavaju korisnike od odabiranja ranije za njihove latentne varijante, čine model manjim i bržim i omogućavaju bolji tok informacija u latentne varijante. Uspoređujemo pojednostavljene verzije sa standardnim SSVAE na četiri klasifikacijskih zadataka teksta. Na vrhu navedenog pojednostavljanja, eksperimenti pokazuju brzinu od 26%, dok drže ekvivalentne klasifikacijske rezultate. Kod za reprodukciju naših eksperimenata je javno.', 'si': 'Half- supervised variant autocode (SSVAE) are vast use Models for data Effective learnt. මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා SSVAE පත්තර වින්යාසයේ ප්\u200dරමාණිත වින්යාසයේ සාමාන්\u200dය වින්යාසයේ සාමාන්\u200dය වින්යාසය සඳහා පැත්ත SSVAE සඳහා මේ සාමාන්\u200dය විශ්වාසය ඔවුන්ගේ සාධාර්ථික ශබ්දයක් සුරක්ෂා කරනවා වගේම ප්\u200dරයෝජන විශ්වාසය සම්පුර්ණ පරික්ෂා  මේ සාමාන්\u200dයය තමයි කුල්බැක්-ලිබ්ලර් වෙනස් වෙනුවෙන් ඉලක්කයෙන් ඉවරයෙන් ඉවරයෙන් ඉවරයෙන් ඉවරයෙන් ඉවරයෙන් ඉවරයි මේ වෙනස් වෙනුවෙන් ප්\u200dරයෝජකයෝ ඔවුන්ගේ ලේටින් වෙනස් වෙනුවෙන් ප්\u200dරයෝජකයෝ තෝරාගන්න පුළුවන් වෙනුවෙන් ප්\u200dරයෝ අපි සාමාන්\u200dය සංවිධානය සඳහා ස්ථානය SSVAE සඳහා පාළු විශේෂණ කාර්ය 4ක් විතරයි. උඩින් කියපු සාමාන්\u200dය විශ්වාසයේ උඩ, පරීක්ෂණාවල් 26% වේගයක් පෙන්වන්න පුළුවන්, සමාන්\u200dය විශ්වාසය විශ අපේ පරීක්ෂණ ප්\u200dරතිපරීක්ෂණයක් සාමාජිකයි.', 'so': "Semi-Supervised Variational Autoencoders (SSVAEs) are widely used models for data efficient learning.  Qoraalkan waxaynu ka weydiinaa si ku filan qoraalka caadiga ah ee SSVAEs-ka xilliga shaqada fasaxa qoraalka, markaynu aragno laba nooc oo ka mid ah dhibaatada, taas oo aynu fududayno. Isfududaadka SSVAEs ayaa ilaaliya codkooda theoretical ah, marka lagu siinayo faa'iido caafimaad ah oo ku saabsan qoraalka la ilaaliyey semi-ilaaliyey, meesha dhamaadka waxbarashadu ay tahay qoraal fasax. Isku fudud waa in la qaado (i) Kullback-Liebler kala duwanaanayo goalkiisa iyo (ii) isbedelka ugu dambeeya ee aan la arkin sameyntiisa suurtagalka ah. Isticmaalayaashu waxay caawinaysaa in ay ka doorato horay is-beddelkoodii ugu dambeeyey, ka dhigto tusaaleyda wax yar oo dhaqdhaqaaqi, wuxuuna u ogolaan karaa in macluumaad la beddelo isbedelka ugu dambeeya. Waxaannu isbarbardhignaa warqadaha sahlan ee SSVAEs oo ku saabsan 4 shaqooyinka fasaxa qoraalka. Isku fududaanshaha kor lagu qoray, imtixaanka waxaa lagu muujiyaa dhaqdhaqaaqa 26 boqolkiiba, marka lagu haysto iskuul isku mid ah. Qorada lagu soo celiyo imtixaankeena waa dadweynaha.", 'sv': 'Semi-Supervised Variational Autoencoders (SSVAEs) är ofta använda modeller för dataeffektiv inlärning. I denna uppsats ifrågasätter vi lämpligheten av standardutformningen av sekvens SSVAE för uppgiften att klassificera text eftersom vi uppvisar två källor till överkomplexitet som vi tillhandahåller förenklingar för. Dessa förenklingar för SSVAE bevarar sin teoretiska sundhet samtidigt som de ger ett antal praktiska fördelar i den halvövervakade uppsättningen där resultatet av utbildningen är en textklassificerare. Dessa förenklingar innebär att i) Kullback-Liebler avviker från sitt mål och ii) den helt obemärkta latenta variabeln från dess sannolikhetsmodell avlägsnas. Dessa förändringar befriar användare från att välja en tidigare för sina latenta variabler, gör modellen mindre och snabbare och möjliggör ett bättre flöde av information till de latenta variablerna. Vi jämför de förenklade versionerna med standard SSVAE på 4 textklassificeringsuppgifter. Utöver ovannämnda förenkling visar experimenten på en hastighet på 26%, samtidigt som motsvarande klassificeringspoäng bibehålls. Koden för att reproducera våra experiment är offentlig.', 'ur': 'نصف-Supervised Variational Autoencoders ہم اس کاغذ میں سوال کرتے ہیں کہ SSVAEs کے استاندارڈ ڈیزاینٹ کے مطابق تفصیل کلاسیفوں کے کام کے لئے استاندارڈ ڈیزاینٹ ڈیزاینٹ کے مطابق ہے جبکہ ہم ان کے لئے بہت پیچیدگی کے دو سوسوں کو دکھاتے ہیں جن کے لئے ہم سا یہ سادھائی SSVAEs کے لئے ان کی نظریاتی صوت کی حفاظت کرتی ہیں جب کہ ان کی تعلیم کا نتیجہ ایک ٹیکسٹ کلاسیر ہے ان کے نیچے نظریات میں بہت سادھائی فائدہ دے رہی ہے. یہ سادھاتے ہیں کہ (i) Kullback-Liebler کے اختلاف کو اس کے مقصد سے ہٹانے والی ہے اور (ii) اس کے احتمالی مدل سے پوری غیر نظاری لاٹینٹ بدل ہے۔ یہ تغییرات کارساز کو ان کے لٹینٹ بدیریوں کے لئے پہلے سے انتخاب کرنے سے آسان کر دیتے ہیں، مدل کو چھوٹا اور سریع کر دیتے ہیں، اور لاٹینٹ بدیریوں میں بہتر سی معلومات کا بہانا اجازت دیتے ہیں. ہم سادھے سادھے نسخے چرے ٹیکسٹ کلاسپیٹ کے کاموں پر استاندارڈ SSVAEs کے مقایسہ کرتے ہیں۔ اوپر سے ذکر کی سادگی کے اوپر، آزمائش 26% کی سرعت کی آگے دکھاتے ہیں، اور برابر کلاسیفوں کا اسکور رکھتے ہیں. ہمارے آزمائش کو دوبارہ پیدا کرنے کے لئے کوڈ ظاہر ہے۔', 'ta': 'பாதி- பரிசோதிக்கப்பட்ட மாறிகள் தானியங்கி குறியீடுகள் (SSVAEs) தகவல் தேவையற்றத்திற்கான மாதிரிகள் பயன்படுத்தப்பட்டுள இந்த காகிதத்தில், நாம் எஸ்விஎஸ் வரிசையின் இயல்பான வடிவமைப்பின் சரியான தேவையை கேட்கிறோம் உரை வகைப்படுத்தலின் செயல்பாட்டிற்கு நாம் இரண்டு மூல SSVAEs க்கு இந்த எளிதாக்கங்கள் அவர்களுடைய திசீரியல் ஒலியைப் பாதுகாக்கும் போது பாதுகாப்பில் பயிற்சியின் முடிவு ஒரு உரை வகைப்பாளர் என்பத இந்த எளிதாக்கங்கள் (i) கூல்பாக்-லிப்பர் வேறுபாடு அதன் இலக்கத்திலிருந்து நீக்கப்பட்டது மற்றும் (ii) அதன் சாத்தியமான மாதிரியிலிருந்து ம இந்த மாற்றங்கள் தங்கள் சமீபத்தில் மாறிகளுக்கு முன்னால் தேர்ந்தெடுக்க முன்னால் பயனர்களை தேர்ந்தெடுக்க உதவும், மாதிரியை சிறிதாகவ நாம் 4 உரை வகைப்படுத்தல் பணிகளில் எளிதாக்கப்பட்ட பதிப்புகளை ஒப்பிடுகிறோம். மேலே குறிப்பிட்ட சுலபமாக்கத்தின் மேல், சோதனைகள் 26% வேகத்தின் மேல் காட்டுகிறது, சமமான வகுப்பு மதிப்புகளை வைத்திர எங்கள் சோதனைகளை புதுப்பிக்க குறியீடு பொதுவானது.', 'mt': 'L-Awtokodifikaturi Varjazzjonali Semi-Sorveljati (SSVAEs) huma mudelli użati b’mod wiesa’ għal tagħlim effiċjenti fid-dejta. F’dan id-dokument, niddubitaw l-adegwatezza tad-disinn standard tas-sekwenza SSVAEs għall-kompitu tal-klassifikazzjoni tat-test peress li naraw żewġ sorsi ta’ kumplessità żejda li għalihom nipprovdu simplifikazzjonijiet. Dawn is-simplifikazzjonijiet għall-SSVAEs jippreservaw is-sodezza teoretika tagħhom filwaqt li jipprovdu għadd ta’ vantaġġi prattiċi fl-istruttura semisuperviża fejn ir-riżultat tat-taħriġ huwa klassifikatur tat-test. These simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unobserved latent variable from its probabilistic model.  These changes relieve users from choosing a prior for their latent variables, make the model smaller and faster, and allow for a better flow of information into the latent variables.  We compare the simplified versions to standard SSVAEs on 4 text classification tasks.  Minbarra s-simplifikazzjoni msemmija hawn fuq, l-esperimenti juru veloċità ta’ 26%, filwaqt li jżommu punteġġi ta’ klassifikazzjoni ekwivalenti. Il-kodiċi għar-riproduzzjoni tal-esperimenti tagħna huwa pubbliku.', 'vi': 'Kỹ thuật hóa biến đổi (SSVAEs) được phổ biến các mẫu dùng cho việc học hành hiệu quả dữ liệu. Trong tờ giấy này, chúng tôi đặt câu hỏi về sự phù hợp của thiết kế tiêu chuẩn của các công trình SSVAEs cho nhiệm vụ phân loại văn bản vì chúng tôi có hai nguồn chứa tính phức tạp mà chúng tôi cung cấp đơn giản. Những sự đơn giản này giúp SSVAE giữ vững lý thuyết của mình trong khi cung cấp một số lợi ích thực tế trong việc thiết lập bán giám sát nơi kết quả đào tạo là một người phân loại văn bản. Những sự đơn giản này là loại bỏ (i) sự khác biệt giữa Kullback-Liebler và (II) biến biến cố tiềm ẩn hoàn toàn chưa được phục tùng từ mô hình hiển nhiên của nó. Những thay đổi này giúp người dùng dễ dàng chọn một phiên bản trước cho các biến số tiềm năng tiềm ẩn, làm cho mô hình nhỏ hơn và nhanh hơn, và cho phép cung cấp thông tin tốt hơn vào các biến số tiềm ẩn. Chúng tôi so sánh các phiên bản đơn giản với SSVAEs tiêu chuẩn trong bốn nhiệm vụ phân loại văn bản. Bên cạnh việc đơn giản trước đây, thí nghiệm cho thấy tốc độ cao hơn 26=, trong khi còn giữ tỉ số phân hạng tương đương. Quy tắc mô phỏng thí nghiệm của chúng tôi công khai.', 'uz': "@ info: whatsthis Bu hujjatda, biz matn classifikasining vazifasi uchun SSVAEs стандарт dizayning yetarlicha haqida savol qilamiz. Biz buni soddalashtirish uchun ikkita manbani ko'rsatamiz. Ushbu SSVAEs uchun oddiylik o'zining teoretikal tovushlarini saqlab qoladi va semi- supervisor qilingan moslamalarda bir necha foydalanuvchilarni qoʻllash mumkin. Bu oddiyliklarni (I) Kullback-Liebler'ning obʼektini olib tashlash va (i i) taʼminlovchi soniyada ko'rinmagan narsa o'zgarishdir. Ushbu oʻzgarishlar keyingi oʻzgarishlarni tanlash uchun oldin foydalanuvchilardan foydalanadi, modelni kichik va tezroq qiladi va keyingi oʻzgarishlarda yaxshi maʼlumotni olib tashlash imkoniyatini beradi. Biz soddalashtirilgan versiyalarni 4 matn classification vazifalarda Andoza SSVAEsga kamaytamiz. Yuqori taʼminlovchi soʻzda, taʼminlovlar 26%'ning tezligini koʻrsatiladi, va bir teng darajalashtirish imkoniyatini davom etishda. Bizning tajribalarimizni qayta chiqarish qoidamiz public.", 'hr': 'Polu nadzornih varijacijskih autokodera (SSVAE) široko se koriste modeli za učinkovito učenje podataka. U ovom papiru ispitujemo adekvatnost standardnog dizajna SSVAE-a za zadatak klasifikacije teksta kao što pokazujemo dva izvora prekompleksnosti za koje pružamo pojednostavljenje. Ova pojednostavljanja SSVAE-ima čuvaju svoju teorijsku zvuk dok pružaju broj praktičnih prednosti u polu-nadzornom postavku gdje je rezultat obuke klasifikator teksta. Ova pojednostavljanja su uklanjanje i) razlike Kullback-Lieblera iz cilja i ii) potpuno neočuvane latentne varijable iz njegovog vjerojatnog modela. Te promjene olakšavaju korisnike od odabiranja ranije za njihove latentne promjene, čine model manjim i bržim i omogućavaju bolji tok informacija u latentne promjene. Upoređujemo pojednostavljene verzije sa standardnim SSVAE-ima na četiri zadatke klasifikacije teksta. Na vrhu navedenog pojednostavljanja, eksperimenti pokazuju brzinu od 26%, dok drže ekvivalentne rezultate klasifikacije. Kod reprodukcije naših eksperimenata je javno.', 'da': "Semi-Supervised Variational Autoencoders (SSVAE'er) er almindeligt anvendte modeller til dataeffektiv læring. I denne artikel sætter vi spørgsmålstegn ved, om standarddesignet af sekvens SSVAE'er er tilstrækkeligt til opgaven med tekstklassifikation, da vi udviser to kilder til overkompleksitet, som vi giver forenklinger for. Disse forenklinger til SSVAE bevarer deres teoretiske soliditet og giver samtidig en række praktiske fordele i den halvovervågede opsætning, hvor resultatet af uddannelsen er en tekstklassifikation. Disse forenklinger er fjernelsen af (i) Kullback-Liebler-afvigelsen fra dens mål og (ii) den helt uobserverede latente variabel fra dens sandsynlighedsmodel. Disse ændringer afhjælper brugerne fra at vælge en forudgående for deres latente variabler, gør modellen mindre og hurtigere og giver mulighed for en bedre strøm af information til de latente variabler. Vi sammenligner de forenklede versioner med standard SSVAE'er på 4 tekstklassifikationsopgaver. Ud over ovennævnte forenkling viser eksperimenter en hastighed på 26%, samtidig med at de holder tilsvarende klassificeringsscorer. Koden til at gengive vores eksperimenter er offentlig.", 'nl': "Semi-Supervised Variational Autoencoders (SSVAE's) zijn veel gebruikte modellen voor data efficiënt leren. In dit artikel vragen we de geschiktheid van het standaardontwerp van sequentie SSVAE's voor de taak van tekstclassificatie af, aangezien we twee bronnen van overcomplexiteit vertonen waarvoor we vereenvoudigingen bieden. Deze vereenvoudigingen voor SSVAE's behouden hun theoretische deugdelijkheid en bieden een aantal praktische voordelen in de semi-begeleide opstelling, waarbij het resultaat van de opleiding een tekstclassificator is. Deze vereenvoudigingen zijn het verwijderen van (i) de Kullback-Liebler-divergentie van zijn doel en (ii) de volledig onopgemerkt latente variabele uit zijn probabilistisch model. Deze wijzigingen ontzorgen gebruikers van het kiezen van een voorafgaand voor hun latente variabelen, maken het model kleiner en sneller, en zorgen voor een betere stroom van informatie in de latente variabelen. We vergelijken de vereenvoudigde versies met standaard SSVAE's op 4-tekstclassificatietaken. Naast bovengenoemde vereenvoudiging tonen experimenten een versnelling van 26%, terwijl gelijkwaardige classificatiescores behouden blijven. De code om onze experimenten te reproduceren is openbaar.", 'de': 'Semi-Supervised Variational Autoencoder (SSVAEs) sind weit verbreitete Modelle für dateneffizientes Lernen. In diesem Beitrag stellen wir die Angemessenheit des Standarddesigns von Sequenz-SSVAEs für die Aufgabe der Textklassifizierung in Frage, da wir zwei Quellen von Überkomplexität aufzeigen, für die wir Vereinfachungen bereitstellen. Diese Vereinfachungen für SSVAEs bewahren ihre theoretische Solidität und bieten gleichzeitig eine Reihe praktischer Vorteile in der halbüberwachten Einrichtung, bei der das Ergebnis der Ausbildung ein Textklassifikator ist. Diese Vereinfachungen sind die Entfernung (i) der Kullback-Liebler-Divergenz von ihrem Ziel und (ii) der völlig unbeobachteten latenten Variablen aus ihrem probabilistischen Modell. Diese Änderungen entlasten Benutzer von der Auswahl eines Priors für ihre latenten Variablen, machen das Modell kleiner und schneller und ermöglichen einen besseren Informationsfluss in die latenten Variablen. Wir vergleichen die vereinfachten Versionen mit Standard-SSVAEs für 4-Textklassifizierungsaufgaben. Zusätzlich zu der oben genannten Vereinfachung zeigen Experimente eine Beschleunigung von 26% bei gleichwertiger Klassifikation. Der Code zur Reproduktion unserer Experimente ist öffentlich.', 'ko': '반감시 변분 자동 인코더(SSVAE)는 데이터 고효율 학습에서 광범위하게 사용되는 모델이다.본고에서 우리는 서열 SSVAE의 표준 디자인이 텍스트 분류 임무에 대한 충분성에 대해 의문을 제기했다. 왜냐하면 우리는 두 가지 지나치게 복잡한 출처를 보여주었기 때문에 이를 간소화했다.이러한 SSVAE의 간소화는 그들의 이론적 합리성을 보존하는 동시에 훈련 결과는 텍스트 분류기의 반감독 설정에 많은 실제적인 장점을 제공했다.이러한 간소화는 (i) 목표에서 Kullback-Liebler 산도를 제거하고 (ii) 확률모델에서 완전히 관측되지 않은 잠재적인 변수를 제거하는 것을 포함한다.이러한 변화는 사용자로 하여금 잠재적 변수에 대한 선험을 더 이상 선택하지 않게 하고 모델을 더욱 작고 빠르게 하며 더 좋은 정보 흐름이 잠재적 변수에 들어가도록 허용한다.4개의 텍스트 분류 작업에서 표준 SSVAE와 단순화 버전을 비교했습니다.상술한 간소화를 토대로 실험은 동등한 분류 점수를 유지하는 상황에서 속도가 26퍼센트 높아졌다는 것을 나타냈다.우리가 실험한 코드를 복제한 것은 공개된 것이다.', 'sw': 'Kodi za kujibadilisha kwa ajili ya kujifunza kwa ufanisi wa taarifa (SSVAEs) zinatumiwa vizuri sana. Katika karatasi hii, tunahoji usawa wa ubunifu wa kawaida wa mfululizo wa SSVAEs kwa ajili ya kazi ya kutangaza maandishi wakati tunaonyesha vyanzo viwili vya utata ambavyo tunatoa urahisi. Simulizi hizi kwa SSVAEs zinalinda sauti zao za nadharia wakati wakitoa manufaa kadhaa za kiufundi katika seti inayofuatiliwa na sekondari ambapo matokeo ya mafunzo ni mwandishi wa maandishi. These simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unobserved latent variable from its probabilistic model.  Mabadiliko haya yanawasaidia watumiaji kuamua kuchagua awali kwa mabadiliko yao ya hivi karibuni, kufanya mtindo mdogo na haraka, na kuruhusu usafirishaji wa taarifa katika mabadiliko ya hivi karibuni. Tunawalinganisha toleo rahisi na SSVAEs kwa ajili ya kazi 4 za usambazaji wa maandishi. Katika upande wa urahisi unaotajwa hapo juu, majaribio yanaonyesha kuongezeka kwa kasi ya asilimia 26, wakati wakiweka vipimo sawa vya usambazaji. Sheria ya kutengeneza majaribio yetu ni wazi.', 'tr': "Half-Supervised Çeşitli Otomatik Ködlemeler (SSVAEs) maglumat efekt öwrenmek üçin ullanylar. Bu kagyzda, biz SSVAE'yň standart tasarlamasynyň ýeterligini soraýýarys. Şu şekilde tekst klasifikasyýasynyň üçin beýleki karmaşıklygyň iki çeşmesini görkez. Bu süňlelikler SSVAEň teoriýaly ses goraýarlaryny, ýarym-gözleýän düzümlerde birnäçe praktik avantajlary saýlaýarlar. Şu ýerde okuwçylygyň netijesi metin klasifikatçy bolan ýerde. Bu basitleşdirimler (i) Kullback-Liebler netijesinden çykarmadyr we (ii) mümkinçilik nusgasyndan tamamlanmadyk tertibinden çykarmadyr. Bu üýtgewler geçmiş üýtgewleri üçin öňünden birini saýlamak üçin azaltýar, modelini kiçiräk we çalt saýlamak üçin we geçmiş üýtgewlere gowy bir informasiň akışyny saýlamak üçin kömekleýärler. Besitlendirlen wersiýalary 4 metin klasifikasynda standart SSVAE bilen karşılaştyrýarys Yukarıdaki esasy basitleme üstünde, deneyler 26%-den ýokary hızlandyrylýar we eşit klasifikasyon notlaryny tutarlar. Deneylerimizi täzeden edip bilmek ködleri umumy.", 'bg': 'Полунадзорните вариационни автокодери (са широко използвани модели за ефективно обучение на данни. В настоящата статия поставяме под въпрос адекватността на стандартния дизайн на последователността за задачата за класификация на текста, тъй като показваме два източника на свръхсложност, за които предоставяме опростявания. Тези опростявания на SSVAE запазват теоретичната им стабилност, като същевременно осигуряват редица практически предимства в полунадзорната настройка, в която резултатът от обучението е текстов класификатор. Тези опростявания са премахването на i) отклонението на Кулбек-Либлър от неговата цел и ii) напълно незаблюдаваната латентна променлива от неговия вероятностен модел. Тези промени освобождават потребителите от избора на предшественик за техните латентни променливи, правят модела по-малък и по-бърз и позволяват по-добър поток на информация към латентните променливи. Сравняваме опростените версии със стандартните по 4 задачи за класификация на текста. Освен горепосоченото опростяване експериментите показват ускорение от 26%, като същевременно запазват еквивалентни класификационни оценки. Кодът за възпроизвеждане на експериментите ни е публичен.', 'af': "Semi- ondersoekte Veranderlike Autoencoders (SSVAEs) word heeltemal gebruik modele vir data effektief leer. In hierdie papier vra ons die adekuasie van die standaard ontwerp van sekwensies SSVAE vir die taak van teks klassifikasie as ons uitbied twee bronne van oorvloedigheid waarvan ons eenvoudigings verskaf. Hierdie eenvoudiginge na SSVAE bewaar hul teorieese klankheid terwyl 'n aantal praktiese voordeel verskaf in die semi-ondersoekte opstelling waar die resultaat van onderwerking 'n teks klassifiseerder is. Hierdie eenvoudiginge is die verwydering van (i) die Kullback- Liebler afwyking van sy objekte en (ii) die volledig ongebevestig latent veranderlike van sy waarskynlik model. Hierdie veranderinge verlos gebruikers van die kies van 'n vooraf vir hul latente veranderlikes, maak die model kleiner en vinniger, en laat toe vir 'n beter vloei van inligting in die latente veranderlikes. Ons vergelyk die eenvoudige weergawe met standaard SSVAE op 4 teks klassifikasie taak. Op die bo-mentioneerde eenvoudiging vertoon eksperimente 'n spoed-op van 26%, terwyl gelykivalente klassifikasie telling hou. Die kode om ons eksperimente te herhaal is publiek.", 'id': 'Autokoder Variasi Semi-Supervised (SSVAEs) adalah model yang sangat digunakan untuk belajar efisien data. Dalam kertas ini, kami mempertanyakan keperluan desain standar dari urutan SSVAE untuk tugas klasifikasi teks saat kami menunjukkan dua sumber keterlaluan yang kami menyediakan sederhana. Persederhanaan ini untuk SSVAE mempertahankan kedengaran teori mereka sambil menyediakan beberapa keuntungan praktis dalam setup semi-supervised dimana hasil pelatihan adalah klasifikasi teks. Persederhanaan ini adalah penghapusan (i) divergensi Kullback-Liebler dari tujuannya dan (ii) variabel latent yang tidak diperhatikan sepenuhnya dari model probabilistiknya. Perubahan ini melepaskan pengguna dari memilih sebelumnya untuk variabel latent mereka, membuat model lebih kecil dan lebih cepat, dan memungkinkan aliran informasi yang lebih baik ke dalam variabel latent. Kami membandingkan versi sederhana dengan SSVAE standar pada 4 tugas klasifikasi teks. Di atas penyimplifikasi yang disebutkan di atas, eksperimen menunjukkan kecepatan 26%, sementara menjaga skor klasifikasi yang sama. Kode untuk mereproduksi eksperimen kita adalah publik.', 'am': 'ምርጫዎች በዚህ ፕሮግራም፣ ለጽሑፍ ክፍተቶችን ለማሳየት እናስጠይቃለን፡፡ ይህች የSSVAEs ቀላልነት የጽሑፍ ፍጻሜ የተለያየ የጽሑፍ ክፍል በተደረገ በsemi-supervised ጥቅምቶችን በመጠበቅ ድምፅ እንዲጠብቁ ነው፡፡ እነዚህ ቀላልዎች (i) የኮልቡክ-ሊebler ትለዩነት ከአቃውሞ እና (ii) ከስልጣኑ ሙሉ ያልታወቀው መለወጫ ነው፡፡ እነዚህም ለውጦች ተጠቃሚዎችን ለመምረጡ የቀድሞው ለውጦቹን ከመምረጡ ያቀናልላሉ፣ ምሳሌውን ትንሽ እና ፈጥኖ ያደርጋሉ፡፡ አዲስ የጽሑፍ መግለጫ ስራዎችን ለመቀላቀል እናስተያየዋለን፡፡ በአሁኑ ላይ በሚታወቀው ቀላል ላይ፣ ፈተናዎች የ26 በመቶ ፈጥኖ ያሳያል፡፡ ፈተናዎቻችንን ለመመልስ የኮድ ግልፅ ነው፡፡', 'sq': 'Autokoduesit Variacional Semi-Supervised (SSVAEs) janë modele të përdorura gjerësisht për mësim të efektshëm të të dhënave. Në këtë letër, ne vëmë në dyshim përshtatjen e dizajnit standard të sekuencës SSVAE për detyrën e klasifikimit të tekstit ndërsa ne ekspozojmë dy burime të mbikompleksitetit për të cilat ne ofrojmë simplifikime. Këto thjeshtimet për SSVAE ruajnë soliditën e tyre teorike duke ofruar një numër avantazhe praktike në strukturën gjysmë-mbikqyrure ku rezultati i trajnimit është një klasifikues teksti. These simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unobserved latent variable from its probabilistic model.  Këto ndryshime lehtësojnë përdoruesit nga zgjedhja e një paraprake për ndryshuesit e tyre latent, e bëjnë modelin më të vogël dhe më të shpejtë dhe lejojnë një rrjedhje më të mirë informacioni në ndryshuesit latent. Ne krahasojmë versionet e thjeshta me SSVAE standarde në 4 detyra klasifikuese teksti. Përveç thjeshtimit të përmendur më lart, eksperimentet tregojnë një përshpejtim prej 26%, duke mbajtur rezultate ekvivalente klasifikimi. Kodi për të riprodhuar eksperimentet tona është publik.', 'hy': 'Կամ-վերահսկված տարբերակային ավտոկոդավորները (SSVE) լայնորեն օգտագործված մոդելներ են տվյալների արդյունավետ սովորելու համար: Այս թղթի մեջ մենք քննարկում ենք SSVE հաջորդականության ստանդարտ դիզայնի հարմարությունը տեքստի դասակարգման խնդրի համար, քանի որ ցույց ենք տալիս չափազանց բարդ աղբյուրներ, որոնց համար մենք պարզաբանում ենք: SSVE-ի այս պարզաբանությունները պահպանում են իրենց տեսական ճշմարտությունը, միաժամանակ տալիս են մի շարք պրակտիկ առավելություններ կիսակառավարվող կառուցվածքի մեջ, որտեղ վարժեքի արդյունքը տեքստի դասակարգիչ է: Այս պարզաբանությունները i) Կուլբակ-Լիբլերի տարբերությունը հեռացվում են դրա նպատակից և 2) ամբողջովին անտեսված թաքնված փոփոխական իր հավանական մոդելուց: Այս փոփոխությունները թույլ են տալիս օգտագործողներին նախկին ընտրել իրենց թաքնված փոփոխականների համար, փոքրացնել և արագ դարձնել մոդելը և հնարավորություն տալ ավելի լավ տեղեկատվության հոսք թաքնված փոփոխականների մեջ: Մենք համեմատում ենք պարզ տարբերակները ստանդարտ SSVE-ների հետ 4 տեքստի դասակարգման խնդիրներում: Առաջին կոչվող պարզաբանությունից բացի, փորձերը ցույց են տալիս 26 տոկոսով արագացում, մինչդեռ հավասար դասակարգման գնահատականներ են պահում: Մեր փորձերի վերարտադրման կոդը հանրային է:', 'bn': 'ডাটা কার্যকর শিক্ষার জন্য ব্যাপক মডেল ব্যবহার করা হয়েছে। এই কাগজটিতে আমরা প্রশ্ন করি টেক্সট গ্রাফিকেশনের কাজের জন্য স্ট্যান্ডারেন্ড ডিজাইনের যথেষ্ট পরিমাণ প্রশ্নের যেহেতু আমরা দুটি জটিল উৎস প্রদর্শন করছি  এসভিএসএ-এর সুস্পষ্টভাবে এই সুবিধা তাদের ততিত্বিক শব্দ সংরক্ষণ করার সময় সেমি পর্যবেক্ষণ করা বেশ কয়েকটি ব্যাক্তিগত সুবিধা প্রদান করে যেখানে প এই সুস্পষ্ট বিষয়গুলো হচ্ছে (i) কুল্লব্যাক-লিব্লারক এর উদ্দেশ্য থেকে পার্থক্য সরিয়ে নেয়া এবং (ii) সম্ভবত তার সম্ভাব্য মডেল থেকে সম্পূর্ণ এই পরিবর্তনগুলো ব্যবহারকারীদের সাম্প্রতিক পরিবর্তনের জন্য একটি পূর্বেই বেছে নিতে সুবিধা দেয়, মডেল ছোট আর দ্রুত বানান এবং সাম্প্রতিক ভিন ৪ টি টেক্সট ক্লাস্ফিকেশন কাজে আমরা স্বাভাবিক সংস্করণের সাথে সাধারণ সংস্করণের তুলনা করি। উপরের উল্লেখিত স্বচ্ছতার উপরে, পরীক্ষার মধ্যে ২৬ শতাংশের গতি বেড়ে যাওয়া পরীক্ষা দেখা যাচ্ছে এবং সমতার স্কোর রাখছে। আমাদের পরীক্ষাগুলো পুনরুদ্ধার করার কোড পাবলিক।', 'bs': 'Pola nadzornih varijacijskih autokodera (SSVAE) široko se koriste modeli za učinkovito učenje podataka. U ovom papiru ispitujemo adekvatnost standardnog dizajna sekvence SSVAE za zadatak klasifikacije teksta kao što pokazujemo dva izvora prekompleksnosti za koje pružamo pojednostavljenje. Ova pojednostavljanja SSVAE-u sačuvaju svoju teorijsku zvuk dok pružaju broj praktičnih prednosti u polu-nadzornoj ustanovi gdje je rezultat obuke klasifikator teksta. Ova pojednostavljanja su uklanjanje i) razlike Kullback-Lieblera iz objekta i ii) potpuno neočuvane latentne varijable iz njegovog vjerojatnog modela. Ove promjene olakšavaju korisnike od odabiranja ranije za njihove latentne promjene, čine model manjim i bržim i omogućavaju bolji tok informacija u latentne promjene. Uspoređujemo pojednostavljene verzije sa standardnim SSVAE na četiri funkcije klasifikacije teksta. Na vrhu navedenog pojednostavljanja, eksperimenti pokazuju brzinu od 26%, dok drže ekvivalentne rezultate klasifikacije. Kod za reprodukciju naših eksperimenata je javno.', 'az': 'Yarı-gözləyirli Variasyon Autoencoder (SSVAEs) məlumatlar faydalı öyrənmək üçün çox geniş modellər istifadə edilir. Bu kağızda, SVV-lərin standart dizaynının uyğunluğunu soruşuruq, mətn klasifikasiyasının görevi üçün iki çox kompleks mənbəsini göstəririk ki, buna görə basitləşdirəcəyik. SSVAE üçün bu basitləşdirilənlər teoriki səslərini qoruyub saxlayarlar, halı-gözləyirləndirilən təhsil nəticəsinin mətn klasifikatıdır. Bu basitləşdirmələr Kullback-Liebler müəyyən etdiyi məqsədildən i) çıxarılmasıdır və ii) mümkün olaraqlıq modelindən tamamlanmamış latent dəyişiklik. Bu dəyişiklik istifadəçiləri latent dəyişiklikləri üçün daha əvvəl seçməkdən, modeli daha kiçik və daha hızlı edər və latent dəyişikliklərinə daha yaxşı məlumat akışını sağlayarlar. Biz basitləşdirilmiş versiyonları 4 metin klasifikasyonu işlərdə standart SSVAE ilə qarşılaşdırırıq. Yuxarıda deyilən basitlaşdırma üstündə, təminatlar 26%-in hızlandırmasını göstərər, eyni klasifikasiya nöqtələrini saxlayarkən. Bizim təcrübələrimizi yenidən yaratmaq üçün koddur.', 'ca': "Els autocodificadors de variació semisupervisats (SSVAEs) són models generalment utilitzats per aprendre eficients en dades. En aquest paper, ens qüestionem la adequació del disseny estándar de seqüències SSVAE per a la tasca de classificació de textos mentre mostram dues fonts de sobreplexitat per a les quals proporcionem simplificacions. Aquestes simplificacions per a SSVAEs conserven la seva soliditat teòrica mentre proporcionen alguns avantatges pràctics en la configuració semisupervisada on el resultat de l'entrenament és un classificador de text. Aquestes simplificacions són l'eliminació de (i) la divergència Kullback-Liebler del seu objectiu i (ii) la variable latent completament no observada del seu model probabilista. Aquests canvis lliuen als usuaris d'escollir un anterior per a les seves variables latents, fan el model més petit i més ràpid i permeten un millor flux d'informació a les variables latents. Comparem les versions simplificades amb les SSVAE standard en quatre tasques de classificació de text. A més de la simplificació mencionada, els experiments mostran una velocitat del 26%, mantenint puntuacions de classificació equivalents. El codi per reproduir els nostres experiments és públic.", 'et': 'Pooljärelevalvega varieeruvad automaatkodeerijad (SSVAE) on laialdaselt kasutatavad mudelid andmetõhusaks õppimiseks. Käesolevas töös me küsime, kas standard disain jada SSVAE ülesandeks klassifitseerida teksti, kuna me ilmneb kaks allikat liigse komplektsuse, mille me pakume lihtsustusi. Kõnealused SSVAE lihtsustamised säilitavad nende teoreetilise usaldusväärsuse, pakkudes samas mitmeid praktilisi eeliseid pooljärelevalve korral, kus koolituse tulemus on teksti klassifitseerija. Need lihtsustused hõlmavad i) Kullback-Liebleri erinevuse eemaldamist selle eesmärgist ja ii) täielikult tähelepanuta latentse muutuja eemaldamist tõenäosusmudelist. Need muudatused vabastavad kasutajad oma latentsete muutujate eelneva valimisest, muudavad mudeli väiksemaks ja kiiremaks ning võimaldavad paremat infovoogu latentsetesse muutujatesse. Võrdleme lihtsustatud versioone standardsete SSVAE-dega neljas tekstiklassifitseerimisülesandes. Lisaks eespool nimetatud lihtsustamisele näitavad katsed 26% kiirendust, säilitades samaväärsed klassifitseerimisskoorid. Kood meie eksperimentide reprodutseerimiseks on avalik.', 'cs': 'Semi-Supervised Variational Autoencodery (SSVAE) jsou široce používané modely pro efektivní učení dat. V tomto článku se zabýváme adekvátností standardního návrhu sekvenčních SSVAE pro úlohu klasifikace textu, protože vykazujeme dva zdroje nadsložitosti, pro které poskytujeme zjednodušení. Tato zjednodušení SSVAE zachovávají svou teoretickou soliditu a zároveň poskytují řadu praktických výhod v polovičně dohledovaném nastavení, kde výsledkem školení je klasifikátor textu. Tato zjednodušení spočívá v odstranění (i) Kullback-Lieblerovy divergence od jejího cíle a (ii) plně nepozorované latentní proměnné z jejího pravděpodobnostního modelu. Tyto změny uvolňují uživatele od výběru předem pro své latentní proměnné, činí model menší a rychlejší a umožňují lepší tok informací do latentních proměnných. Porovnáváme zjednodušené verze se standardními SSVAE na čtyřech úlohách klasifikace textu. Kromě výše zmíněného zjednodušení, experimenty ukazují rychlost 26%, při zachování ekvivalentních klasifikačních skórí. Kód pro reprodukci našich experimentů je veřejný.', 'fi': 'Semi-Supervised Variational Autocooderit (SSVAE) ovat laajalti käytettyjä malleja datatehokkaaseen oppimiseen. Tässä artikkelissa kyseenalaistamme sekvenssin SSVAE:ien standardisuunnittelun riittävyyden tekstin luokitteluun, koska meillä on kaksi ylikompleksisuuden lähdettä, joille tarjoamme yksinkertaistuksia. Nämä SSVAE-järjestelmien yksinkertaistamiset säilyttävät niiden teoreettisen luotettavuuden ja tarjoavat useita käytännön etuja puolivalvotussa kokoonpanossa, jossa koulutuksen tulos on tekstiluokitus. Yksinkertaistuksina on i) Kullback-Liebler-poikkeaman poistaminen sen tavoitteesta ja ii) täysin havaitsemattoman piilevän muuttujan poistaminen sen todennäköisyysmallista. Nämä muutokset vapauttavat käyttäjiä valitsemasta aikaisempaa piileville muuttujilleen, tekevät mallista pienemmän ja nopeamman ja mahdollistavat paremman tiedonkulun piileville muuttujille. Vertailemme yksinkertaistettuja versioita vakiomuotoisiin SSVAE-järjestelmiin neljässä tekstiluokittelutehtävässä. Edellä mainitun yksinkertaistamisen lisäksi kokeet nopeutuivat 26 prosenttia samalla kun luokituspisteet säilyivät vastaavina. Koodi kokeiden toistamiseen on julkinen.', 'fa': 'استفاده از مدل\u200cها برای یادگیری موثرت داده\u200cها استفاده می\u200cشوند. در این کاغذ، ما از طراحی استاندارد سفارش می\u200cکنیم که SSVAEs برای وظیفه\u200cی گروه\u200cشناسی متن، دو منبع پیچیدگی زیادی را نشان می\u200cدهیم که برای آن ساده\u200cسازی\u200cها پیشنهاد می\u200cدهیم. این ساده\u200cسازی برای SSVAEs صدای نظریه\u200cشان را حفظ می\u200cکند در حالی که تعداد سودهایی عملی را در سازمان نیمه تحت نظر قرار می\u200cدهد که نتیجه تمرین یک راهنمایی متن است. این ساده\u200cسازی\u200cها (i) تفاوت Kullback-Liebler از هدف و (ii) تفاوت latent کامل غیر نظارت شده از مدل احتمالات آن است. این تغییرات کاربران را از انتخاب پیشینه\u200cای برای تغییرات latent خود آزاد می\u200cکند، مدل را کوچکتر و سریعتر می\u200cکند، و اجازه می\u200cدهد یک جریان بهتر اطلاعات به تغییرات latent. ما نسخه\u200cهای ساده\u200cشده را با SSVAEs استاندارد بر روی کارهای مختصات متن مقایسه می\u200cکنیم. در بالای ساده\u200cسازی از بالا، آزمایش\u200cها سرعت ۲۶ درصد را نشان می\u200cدهند، در حالی که نمونه\u200cهای مختلف\u200cسازی همسان نگه می\u200cدارند. کد برای تولید آزمایشات ما عمومی است.', 'he': 'מודלים משתמשים במידה רחבה ללימוד יעיל של נתונים. In this paper, we question the adequacy of the standard design of sequence SSVAEs for the task of text classification as we exhibit two sources of overcomplexity for which we provide simplifications.  הפשטות האלה ל SSVAEs שומרות את היטב התיאורי שלהם בזמן שסיפקו מספר יתרונות מעשיות במערכת חצי-מפקחת היכן שהתוצאה של האימונים היא מסגרת טקסט. הפשטות הללו הן ההסירה של (i) ההבדל קולבאק-לייבלר מהמטרה שלה (ii) המשתנה הלוטנה ללא צפייה מלאה מהמודל הפרוביליסטי שלה. השינויים האלה משחררים משתמשים מבחירה קודמת לשתנים הלאוטים שלהם, הופכים את המודל קטן ומהיר יותר, ואפשרים לזרם מידע טוב יותר לתוך המשתנים הלאוטים. אנחנו משוותים את הגרסאות הפשוטות ל SSVAE סטנדרטיים על 4 משימות מסווג טקסט. בנוסף להפשטה הזכירה, ניסויים מראים מהירות של 26%, בעוד שומרים על נקודות מסווגות שוויות. הקוד להחזיר את הניסויים שלנו הוא ציבורי.', 'ha': "KCharselect unicode block name Ga wannan takarda, Munã tambaya ma'aunin tsarin wanda aka ƙayyade SSV AEs na matsayin da aka yi wa aikin classified matsayi ko da Muke nuna manyan nau'i biyu na rufe kwamfyuta da za'a ba da sauƙi. @ info: whatsthis These sanitikken su ne tafiyar da (i) Kullback-Liebler rarrabẽwa daga abursa kuma (ii) mai cikakken variant na nan da ba'a gane shi ba daga motel mai yiwuwa. These changes relieve users from choosing a prior for their latent variables, make the model smaller and faster, and allow for a better flow of information into the latent variables.  Tuna daidaita versiyar da aka sauƙaƙa da SSV AEs na daidaita a kan aikin mai fassarar matsayi 4. Ga saman da aka faɗa ɗabi'a, jarrabai ke nuna wata kashi-tally-up ga 26%, da kuma yana tsara nau'in sifilafi daidai. Kokunan da za'a mayar da jarrabayenmu ne bayyane.", 'sk': 'Semi-nadzorovani variacijski samokodirniki (SSVAE) so pogosto uporabljeni modeli za učinkovito učenje s podatki. V prispevku postavljamo vprašanje o ustreznosti standardnega oblikovanja zaporedja SSVAE za nalogo klasifikacije besedila, saj kažemo dva vira pretirane kompleksnosti, za katera zagotavljamo poenostavitve. Te poenostavitve SSVAE ohranjajo njihovo teoretično trdnost, hkrati pa zagotavljajo številne praktične prednosti v polnadzorovani postavitvi, kjer je rezultat usposabljanja klasifikacija besedila. Te poenostavitve so odstranitev (i) razlike Kullback-Liebler od njenega cilja in (ii) popolnoma neopažene latentne spremenljivke iz njenega verjetnostnega modela. Te spremembe uporabnikom olajšajo izbiro prej za svoje latentne spremenljivke, naredijo model manjši in hitrejši ter omogočajo boljši pretok informacij v latentne spremenljivke. Pri 4 opravilih klasifikacije besedila primerjamo poenostavljene različice s standardnimi SSVAE-ji. Poleg zgoraj omenjene poenostavitve so poskusi pokazali 26-odstotno pospešitev, pri čemer so ohranili enakovredne ocene klasifikacije. Koda za reprodukcijo naših poskusov je javna.', 'jv': "Variation In this paper, we question the adalah of the Standard design of the SSVS[1] for the task of text CLASS[2] Simplikasun iki nggo SSVU kang dipunangé perusahaan theoretik dhéwé, ingkang dipunangé perusahaan langgar sampek kang dipunangé dipunangé dipunangé katêpakan karo dipunangé terakhir. Simulate change Where's the text Yuta nesaturan purong Ngubungke nggawe perintah sing paling awak dhéwé.", 'bo': 'ལྕགས་རིགས་ལྟ་བུའི་སྣ་ཚོགས་འགྱུར་ཅན་གྱི་རང་འགུལ་གྱི་རྩིས་འཁོར་བ་དག་གི་གྲངས་སྤྱོད་པའི་མིག་དཔེ་གཞུང་སྟོན་པ འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ཡིག་གེ་དབྱེ་སྟངས་ཀྱི་ཚད་རྩིས་འཁོར་གྱི་བཟོ་རྣམ་མཐུན་པ་དེ་གསལ་བཤད་དགོས་པ་ལྟར། ང་ཚོས་ཚོར་ཆ SSVAEལ་ལས་འཕགས་རིས་འདི་དག་གི་དྲན་རིམ་གྱི་སྟབས་བདེ་རིམ་ཡོད་ཚད་རྟོགས་པ་དང་ཕྱེད་བསྡོམས་པའི་སྒྲིག་འཛུགས་ནང་གི་གོ་སྐབས་འཕགས་རིམ་གྱི་ཐབས་ལམ་ This simplifications are the removal of (i) the Kullback-Liebler divergence from its objective and (ii) the fully unabserved latent variable from its probabilistic model. These changes relieve users from choosing a prior for their latent variables, make the model smaller and faster, and allow for a better flow of information into the latent variables. We compare the simplified versions to standard SSVAEs on 4 text classification tasks. ཐོག་ལས་བརྗོད་ཟིན་བྱས་པའི་སྔོན་སྒྲིག་ཕྱོགས་གྱི་ཐོག་ཏུ། བརྟག་དཔྱད་ཀྱིས་མགྱོགས་ཚད་ཉེ་བར་མཐུན་ཡོད། ང་ཚོའི་བརྟག་ཞིག་བསྐྱར་བཟོ་བྱེད་པའི་ཨང་རྟགས་མ་མང་པོ་རེད།'}
{'en': 'Active Learning for Argument Strength Estimation', 'ar': 'التعلم النشط لتقدير قوة الحجة', 'fr': "Apprentissage actif pour l'estimation de la force", 'es': 'Aprendizaje activo para estimar la fuerza argumental', 'pt': 'Aprendizado Ativo para Estimativa de Força de Argumento', 'ja': '引数強度推定のアクティブラーニング', 'zh': '以参数度者自学', 'hi': 'तर्क शक्ति अनुमान के लिए सक्रिय सीखना', 'ru': 'Активное обучение для оценки силы аргументации', 'ga': 'Foghlaim Ghníomhach don Argóint Meastachán Neart', 'el': 'Ενεργή μάθηση για την εκτίμηση της δύναμης επιχειρημάτων', 'hu': 'Aktív tanulás az érvek erősségének becsléséhez', 'ka': 'არგემენტის ძალიან განსაზღვრება', 'kk': 'Аргументтің күш оқу үшін белсенді оқу', 'it': "Apprendimento attivo per la stima della forza dell'argomento", 'lt': 'Veiklus mokymasis argumentų stiprumo vertinimui', 'mk': 'Активно учење за проценка на силата на аргументот', 'ml': 'Active Learning for Argument Strength Estimation', 'ms': 'Pelajaran Aktif untuk Estimasi Kekuatan Argumen', 'mt': 'Tagħlim Attiv għal Stima tas-Saħħa tal-Argument', 'mn': 'Аргументийн хүчтэй тооцооллын актив суралцах', 'pl': 'Aktywne uczenie się dla oszacowania siły argumentów', 'ro': 'Învățare activă pentru estimarea forței argumentelor', 'sr': 'Aktivno učenje za procjenu snage argumenta', 'no': 'Aktiv læring for sterkte estimating av argument', 'si': 'සක්\u200dරිය ඉගෙනගන්න', 'so': 'Waxbarashada Active Learning for Argument Strength Estimation', 'sv': 'Aktivt lärande för bedömning av argumentstyrka', 'ta': 'ஆரம்ப வலிமை கணக்கீட்டிற்கான செயல்படுத்தல்', 'ur': 'Argument Strength Estimation for Active Learning', 'vi': 'Học hành cho Đối số Độ mạnh', 'uz': 'Name', 'hr': 'Aktivno učenje za procjenu snage argumenta', 'da': 'Aktiv læring til vurdering af argumentstyrke', 'id': 'Pelajaran Aktif untuk Penghargaan Kekuatan Argumen', 'bg': 'Активно обучение за оценка на силата на аргументите', 'nl': 'Actief leren voor de schatting van argumentsterkte', 'ko': '논원 강도 추정의 주동 학습', 'sw': 'Kiongozi cha harakati cha Kushinikiza Uhisabu', 'tr': 'Argument Güç Hesablamak üçin janlaş öwrenme', 'fa': 'یادگیری فعال برای ارزیابی قوت ارزیابی', 'de': 'Aktives Lernen zur Schätzung der Argumentstärke', 'am': 'Active Learning for Argument Strength Estimation', 'af': 'Aktiewe leer vir Argument Sterkte Estimasie', 'sq': 'Mësimi aktiv për vlerësimin e forcës së argumentit', 'bn': 'আর্গামেন্ট শক্তি গণনার জন্য সক্রিয় শিক্ষা শিক্ষা', 'hy': 'Ակտիվ սովորելը բանավեճի ուժի գնահատման համար', 'ca': 'Active Learning for Argument Strength Estimation', 'bs': 'Aktivno učenje za procjenu snage argumenta', 'cs': 'Aktivní učení pro odhad síly argumentů', 'az': 'Argument Q칲vv톛tli N칬mr톛si 칲칞칲n Fayl 칐yr톛nm톛', 'et': 'Aktiivne õpe argumentide tugevuse hindamiseks', 'fi': 'Aktiivinen oppiminen argumentin vahvuuden arviointiin', 'jv': 'Attribute', 'ha': 'KCharselect unicode block name', 'sk': 'Aktivno učenje za oceno moči argumentov', 'he': 'לימוד פעיל עבור הערכת כוח הטיעון', 'bo': 'སྒྲུབ་རྟགས་ཀྱི་སྟོབས་ཤུགས་ཚད་ལ་སྤྱོད་སྦྱོར་བ'}
{'en': 'High-quality arguments are an essential part of decision-making. Automatically predicting the quality of an argument is a complex task that recently got much attention in argument mining. However, the annotation effort for this task is exceptionally high. Therefore, we test uncertainty-based active learning (AL) methods on two popular argument-strength data sets to estimate whether sample-efficient learning can be enabled. Our extensive empirical evaluation shows that uncertainty-based acquisition functions can not surpass the accuracy reached with the random acquisition on these data sets.', 'ar': 'تعتبر الحجج عالية الجودة جزءًا أساسيًا من عملية صنع القرار. إن التنبؤ تلقائيًا بجودة الحجة هو مهمة معقدة حظيت مؤخرًا باهتمام كبير في التنقيب عن الجدل. ومع ذلك ، فإن جهد التعليقات التوضيحية لهذه المهمة مرتفع بشكل استثنائي. لذلك ، نقوم باختبار طرق التعلم النشط القائمة على عدم اليقين على مجموعتين شائعتين من بيانات قوة الحجة لتقدير ما إذا كان يمكن تمكين التعلم الفعال في العينة. يُظهر تقييمنا التجريبي الشامل أن وظائف الاستحواذ القائمة على عدم اليقين لا يمكنها تجاوز الدقة التي تم الوصول إليها من خلال الاستحواذ العشوائي على مجموعات البيانات هذه.', 'fr': "Des arguments de qualité constituent un élément essentiel de la prise de décision. Prédire automatiquement la qualité d'un argument est une tâche complexe qui a récemment fait l'objet d'une grande attention lors de l'exploration d'arguments. Toutefois, l'effort d'annotation pour cette tâche est exceptionnellement élevé. Par conséquent, nous testons des méthodes d'apprentissage actif (AL) basées sur l'incertitude sur deux ensembles de données populaires sur la force des arguments afin d'estimer si l'apprentissage efficace sur l'échantillon peut être activé. Notre évaluation empirique approfondie montre que les fonctions d'acquisition basées sur l'incertitude ne peuvent pas dépasser la précision atteinte avec l'acquisition aléatoire sur ces ensembles de données.", 'pt': 'Argumentos de alta qualidade são uma parte essencial da tomada de decisão. Prever automaticamente a qualidade de um argumento é uma tarefa complexa que recentemente recebeu muita atenção na mineração de argumentos. No entanto, o esforço de anotação para esta tarefa é excepcionalmente alto. Portanto, testamos métodos de aprendizado ativo (AL) baseado em incerteza em dois conjuntos de dados de força de argumento populares para estimar se o aprendizado com eficiência de amostra pode ser ativado. Nossa extensa avaliação empírica mostra que as funções de aquisição baseadas em incerteza não podem superar a precisão alcançada com a aquisição aleatória nesses conjuntos de dados.', 'es': 'Los argumentos de alta calidad son parte esencial de la toma de decisiones. Predecir automáticamente la calidad de un argumento es una tarea compleja que recientemente ha recibido mucha atención en la minería de argumentos. Sin embargo, el esfuerzo de anotación para esta tarea es excepcionalmente alto. Por lo tanto, probamos los métodos de aprendizaje activo (AL) basados en la incertidumbre en dos conjuntos de datos populares de solidez de argumentos para estimar si se puede habilitar el aprendizaje eficiente de la muestra. Nuestra amplia evaluación empírica muestra que las funciones de adquisición basadas en la incertidumbre no pueden superar la precisión alcanzada con la adquisición aleatoria de estos conjuntos de datos.', 'ja': '質の高い議論は意思決定に不可欠な部分です。引数の品質を自動的に予測することは、最近引数マイニングで注目されている複雑なタスクです。しかしながら、このタスクの注釈の労力は非常に高い。したがって、不確実性ベースのアクティブラーニング（ AL ）方法を2つの人気のある引数強度データセットでテストして、サンプル効率の高い学習が有効になるかどうかを推定します。私たちの広範な実証的評価は、不確実性に基づく取得関数が、これらのデータセット上のランダム取得で到達した精度を上回ることはできないことを示しています。', 'ru': 'Высококачественные аргументы являются неотъемлемой частью процесса принятия решений. Автоматическое прогнозирование качества аргумента - это сложная задача, которая в последнее время привлекает большое внимание в области интеллектуального анализа аргументов. Тем не менее, усилия по аннотации для этой задачи исключительно высоки. Поэтому мы тестируем методы активного обучения (AL) на основе неопределенности на двух популярных наборах данных аргумент-сила, чтобы оценить, можно ли включить выборочно-эффективное обучение. Наша обширная эмпирическая оценка показывает, что функции сбора данных на основе неопределенности не могут превосходить точность, достигаемую при случайном сборе данных на этих наборах данных.', 'hi': 'उच्च गुणवत्ता वाले तर्क निर्णय लेने का एक अनिवार्य हिस्सा हैं। स्वचालित रूप से एक तर्क की गुणवत्ता की भविष्यवाणी करना एक जटिल कार्य है जिसे हाल ही में तर्क खनन में बहुत ध्यान दिया गया है। हालांकि, इस कार्य के लिए एनोटेशन प्रयास असाधारण रूप से उच्च है। इसलिए, हम दो लोकप्रिय तर्क-शक्ति डेटा सेट पर अनिश्चितता-आधारित सक्रिय सीखने (एएल) विधियों का परीक्षण करते हैं ताकि यह अनुमान लगाया जा सके कि नमूना-कुशल सीखने को सक्षम किया जा सकता है या नहीं। हमारे व्यापक अनुभवजन्य मूल्यांकन से पता चलता है कि अनिश्चितता-आधारित अधिग्रहण कार्य इन डेटा सेटों पर यादृच्छिक अधिग्रहण के साथ पहुंची सटीकता को पार नहीं कर सकते हैं।', 'zh': '高质量之论,决策之要组成部分。 自料论点质是一项复杂的事务,近在论点发掘中很多关注。 然此注甚高。 是以两行之参数,度数集上试于不确定性之自学(AL)法,以度可用样本高效学否。 臣等博实质明,基于不确定性采函数无以过此集上随机采致之精度。', 'ga': 'Is cuid riachtanach den chinnteoireacht iad argóintí ardchaighdeáin. Is tasc casta é cáilíocht argóinte a thuar go huathoibríoch ar tugadh go leor airde air le déanaí i mianadóireacht argóintí. Mar sin féin, tá an iarracht nótaí don tasc seo thar a bheith ard. Dá bhrí sin, déanaimid tástáil ar mhodhanna foghlama gníomhaí atá bunaithe ar éiginnteacht (AL) ar dhá thacar sonraí a bhfuil neart argóinte acu chun a mheas an féidir foghlaim atá tíosach ar shamplaí a chumasú. Léiríonn ár meastóireacht eimpíreach fhairsing nach féidir le feidhmeanna fála atá bunaithe ar éiginnteacht an cruinneas a baineadh amach leis an bhfáil randamach ar na tacair sonraí seo a shárú.', 'el': 'Τα επιχειρήματα υψηλής ποιότητας αποτελούν ουσιαστικό μέρος της λήψης αποφάσεων. Η αυτόματη πρόβλεψη της ποιότητας ενός επιχειρήματος είναι μια πολύπλοκη εργασία που πρόσφατα έλαβε μεγάλη προσοχή στην εξόρυξη επιχειρημάτων. Ωστόσο, η προσπάθεια σχολιασμού για αυτό το έργο είναι εξαιρετικά υψηλή. Ως εκ τούτου, δοκιμάζουμε μεθόδους ενεργού μάθησης βασισμένης στην αβεβαιότητα σε δύο δημοφιλή σύνολα δεδομένων δύναμης επιχειρημάτων για να εκτιμήσουμε αν μπορεί να ενεργοποιηθεί η αποτελεσματική μάθηση δειγμάτων. Η εκτενής εμπειρική μας αξιολόγηση δείχνει ότι οι λειτουργίες απόκτησης βάσει αβεβαιότητας δεν μπορούν να υπερβούν την ακρίβεια που επιτυγχάνεται με την τυχαία απόκτηση σε αυτά τα σύνολα δεδομένων.', 'hu': 'A kiváló minőségű érvek a döntéshozatal alapvető részét képezik. Az argumentumok minőségének automatikus előrejelzése komplex feladat, amely nemrégiben nagy figyelmet kapott az argumentumbányászatban. Ennek ellenére a feladatnak a jegyzetelési erőfeszítése rendkívül magas. Ezért a bizonytalanságon alapuló aktív tanulási (AL) módszereket két népszerű argumentum-erősség adatkészleten teszteljük annak megállapítására, hogy a mintahatékony tanulás engedélyezhető-e. Kiterjedt empirikus értékelésünk azt mutatja, hogy a bizonytalanságon alapuló beszerzési funkciók nem haladhatják meg az ezen adatkészletek véletlenszerű beszerzésével elért pontosságot.', 'ka': 'უფრო კანგალიტიური არგუმენტები უფრო მნიშვნელოვანი გადაწყვეტილების ნაწილი. ავტომატურად აპორმენტის კალიონტის წინასწარმოდგენა კომპლექსი რაოდენობა, რომელიც ახლა აპორმენტის წინასწარმოდგენა. მაგრამ, ამ დავალებისთვის ამოცანების ძალიან ძალიან დიდი. ამიტომ, ჩვენ შევცვალობთ არჩეულობის აკტივი სწავლების (AL) მეტოვებზე ორი პოლიპური არგუმენტის ძალადობის მონაცემების შესახებ, რომელიც შეიძლება გავამწონოთ თუ ჩვენი უფრო დიდი ემპერიკალური განსაზღვრება აჩვენებს, რომ უცნობიერებული მიღება ფუნქციები არ შეუძლიათ გადავადგინოთ მართლა, რომელიც მიღებულია ამ მონაცემების სე', 'kk': 'Жоғары сапатты аргументтер - шешімдеу үшін негізгі бөлігі. Аргументтің сапасын автоматты түрде таңдау - жаңа уақытта аргументтің бағыттауында көп қызық тапсырмасы. Бірақ бұл тапсырманың жаңарту әрекеті өте жоғары. Сондықтан, біз белсенді үйрену (AL) әдістерін тексереміз екі мәліметтік аргумент- күштік деректер бағдарламасы үшін мәліметтің оқыту мүмкіндігін бағалау үшін. Біздің кеңейтілген импирикалық оқиғамыз бұл деректер жиындарындағы кездейсоқ қабылдау функцияларына негізделген тәуелсіздік қабылдау функцияларына арналмайды.', 'it': "Argomenti di alta qualità sono una parte essenziale del processo decisionale. Prevedere automaticamente la qualità di un argomento è un compito complesso che recentemente ha ricevuto molta attenzione nel mining degli argomenti. Tuttavia, lo sforzo di annotazione per questo compito è eccezionalmente elevato. Pertanto, testiamo metodi di apprendimento attivo basato sull'incertezza (AL) su due insiemi di dati popolari per valutare se l'apprendimento efficiente del campione può essere abilitato. La nostra ampia valutazione empirica mostra che le funzioni di acquisizione basate sull'incertezza non possono superare l'accuratezza raggiunta con l'acquisizione casuale su questi set di dati.", 'lt': 'Aukštos kokybės argumentai yra esminė sprendimų priėmimo dalis. Automatinis argumento kokybės prognozavimas yra sudėtinga užduotis, kuri neseniai daug dėmesio skyrė argument ų gavybai. Tačiau pastangos užrašyti šią užduotį yra išskirtinai didelės. Todėl bandome neapibrėžtumu pagrįstus aktyvaus mokymosi (angl. uncertainty-based active learning (AL) metodus naudojant du populiarius argument ų stiprumo duomenų rinkinius, kad įvertintume, ar galima įdiegti mėginių naudojimo efektyvų mokymąsi. Išsamus empirinis vertinimas rodo, kad netikrumo pagrindu pagrįstos įsigijimo funkcijos negali viršyti tikslumo, pasiekto atsitiktiniu šių duomenų rinkinių įsigijimu.', 'mk': 'Високиквалитетните аргументи се суштински дел од донесувањето одлуки. Автоматски предвидување на квалитетот на аргументот е комплексна задача која неодамна доби многу внимание во рудањето аргументи. Сепак, напорите за анотација за оваа задача се исклучително високи. Затоа, ги тестираме методите на активно учење (АЛ) базирано на несигурноста на два популарни групи податоци за сила на аргументите за да процениме дали може да се овозможи учење ефикасно на примероци. Our extensive empirical evaluation shows that uncertainty-based acquisition functions can not surpass the accuracy reached with the random acquisition on these data sets.', 'ml': 'ഉയര്\u200dന്ന വിവരങ്ങള്\u200d തീരുമാനിക്കുന്നതിന്റെ പ്രധാന ഭാഗമാണ്. ഒരു ആര്\u200dഗ്യുമെന്റെ സ്വാഭാവികമായി പ്രവചിക്കുന്നത് ഒരു ചികിത്രമായ ജോലിയാണ്. അതിന്റെ അടുത്തുതന്നെ വാദ്യ എന്നാലും, ഈ ജോലിയുടെ പ്രശ്നം വ്യക്തമായി ഉയര്\u200dന്നിരിക്കുന്നു. അതുകൊണ്ട്, നമ്മള്\u200d പരീക്ഷിക്കുന്നത് പരിശോധിക്കുന്നത് രണ്ട് പ്രധാനപ്പെട്ട ആര്\u200dഗ്യുമെന്\u200dറ് ശക്തിയുള്ള വിവരങ്ങളുടെ സെറ്റുകളില നമ്മുടെ വിശാലമായ എക്മീരിക്കല്\u200d വിലാസങ്ങള്\u200d കാണിക്കുന്നുവെങ്കില്\u200d ഈ ഡേറ്റാ സജ്ജീകരണങ്ങളില്\u200d എത്തുന്നതിന്റെ കൃത്യമായ വി', 'mn': 'Өндөр чанартай аргументууд бол шийдвэр гаргах үндсэн хэсэг юм. Аргументийн сайн чанарыг автоматаар таамаглах нь аргументын хөрөнгө оруулахад маш их анхаарлын ажил юм. Гэхдээ энэ ажил дээрх анхаарлаа хандуулах чадвар маш өндөр. Тиймээс, бид алдартай аргумент-хүчтэй өгөгдлийн хоёр аргумент дээр тодорхойлж чадахгүй эсэхийг тооцоолж чадна. Бидний өргөн эзэмшигийн үнэлгээ нь тодорхойгүй байдлын худалдааны функцүүд эдгээр өгөгдлийн санамсаргүй худалдааны тодорхойлолтой тодорхойлж чадахгүй гэдгийг харуулж байна.', 'ms': 'Argumen kualiti tinggi adalah bahagian penting dalam pembuat keputusan. Automatik meramalkan kualiti argumen adalah tugas kompleks yang baru-baru ini mendapat banyak perhatian dalam perlombongan argumen. Namun, usaha anotasi untuk tugas ini sangat tinggi. Oleh itu, kami menguji kaedah pembelajaran aktif berdasarkan ketidakpastian (AL) pada dua set data kekuatan argumen populer untuk menghargai sama ada pembelajaran efisien sampel boleh dibenarkan. Evaluasi empirik luas kami menunjukkan bahawa fungsi penemuan berdasarkan ketidakpastian tidak boleh melebihi ketepatan yang dicapai dengan penemuan rawak pada set data ini.', 'mt': 'Argumenti ta’ kwalità għolja huma parti essenzjali mit-teħid tad-deċiżjonijiet. Il-previżjoni awtomatika tal-kwalità ta’ argument hija kompitu kumpless li reċentement irċeviet ħafna attenzjoni fil-minjieri tal-argumenti. However, the annotation effort for this task is exceptionally high.  Għalhekk, nistestjaw il-metodi tat-tagħlim attiv ibbażat fuq l-inċertezza (AL) fuq żewġ settijiet ta’ dejta popolari dwar is-saħħa tal-argument biex nistmaw jekk it-tagħlim effiċjenti fil-kampjuni jistax ikun possibbli. L-evalwazzjoni empirika estensiva tagħna turi li l-funzjonijiet ta’ akkwist ibbażati fuq l-inċertezza ma jistgħux jaqbżu l-preċiżjoni milħuqa bl-akkwist aleatorju fuq dawn is-settijiet ta’ dejta.', 'pl': 'Wysokiej jakości argumenty są istotną częścią podejmowania decyzji. Automatyczne przewidywanie jakości argumentu jest złożonym zadaniem, które ostatnio zyskało dużą uwagę w eksploracji argumentów. Jednak nakład adnotacyjny dla tego zadania jest wyjątkowo wysoki. W związku z tym testujemy metody aktywnego uczenia się oparte na niepewności (AL) na dwóch popularnych zbiorach danych dotyczących siły argumentów, aby oszacować, czy można włączyć naukę efektywną próbkę. Nasza szeroka ocena empiryczna pokazuje, że funkcje pozyskiwania oparte na niepewności nie mogą przekroczyć dokładności osiągniętej przy losowym pozyskiwaniu na tych zbiorach danych.', 'no': 'Høgkvalitetssargumenter er ein viktig del av avgjøring av beslutningar. Automatisk forhåndsvising av kvaliteten til eit argument er ein kompleks oppgåve som nyleg fikk mykje oppmerksomhet i argument-mining. Dette er imidlertid uttrykket for annotasjonen for denne oppgåva ekstra høg. Det er derfor vi tester ulike aktive læringsmetodar (AL) på to populære argumentstyrkedata for å vurdere om prøveeffektiv læring kan slå på. Vårt utvida empirisk evaluering viser at uavhengige opptak-funksjonar kan ikkje overføre nøyaktigheten som er nådd med tilfeldig opptak på desse datasettene.', 'ro': 'Argumentele de înaltă calitate reprezintă o parte esențială a luării deciziilor. Prezicerea automată a calității unui argument este o sarcină complexă care a primit recent multă atenție în mineritul argumentelor. Cu toate acestea, efortul de adnotare pentru această sarcină este excepțional de mare. Prin urmare, testăm metodele de învățare activă bazată pe incertitudine (AL) pe două seturi de date populare pentru a estima dacă învățarea eficientă prin eșantioane poate fi activată. Evaluarea noastră empirică extinsă arată că funcțiile de achiziție bazate pe incertitudine nu pot depăși acuratețea atinsă cu achiziția aleatorie a acestor seturi de date.', 'sr': 'Visokokvalitetni argumenti su ključni deo donošenja odluka. Automatski predviđanje kvalitete argument a je kompleksan zadatak koji je nedavno dobio mnogo pažnje u rudarstvu argumenta. Međutim, napor za annotaciju ovog zadatka je izuzetno visok. Stoga, testiramo metode aktivnog učenja (AL) na temelju nejasnosti na dva popularna seta podataka o snazi argumentacija kako bi procenili može li omogućiti učenje uzorka efikasnog učenja. Naša široka empirička procjena pokazuje da funkcije na osnovu prikupljanja na osnovu nesigurnosti ne mogu preći tačnost koja je postignuta slučajnim prikupljanjem na ovim podacima.', 'sv': 'Högkvalitativa argument är en viktig del av beslutsfattandet. Att automatiskt förutsäga kvaliteten på ett argument är en komplex uppgift som nyligen fick mycket uppmärksamhet i argumentmining. Annotationsinsatsen för denna uppgift är dock exceptionellt stor. Därför testar vi osäkerhetsbaserade aktiva inlärningsmetoder (AL) på två populära argumentstyrkedata för att uppskatta om proveffektivt lärande kan aktiveras. Vår omfattande empiriska utvärdering visar att osäkerhetsbaserade förvärvsfunktioner inte kan överträffa den noggrannhet som uppnåtts med slumpmässiga förvärv på dessa datauppsättningar.', 'si': 'උත්සත් ප්\u200dරශ්ණතාවය ප්\u200dරශ්ණත්වයක් තීරණය කරන්න අවශ්\u200dය කොටසක්. ස්වයංක්\u200dරියාවිතයෙන් ප්\u200dරශ්නයක් ස්වයංක්\u200dරියාවිතයෙන් ප්\u200dරශ්නයක් තියෙන්නේ සංක්\u200dරිය වැ නමුත්, මේ වැඩක් වෙනුවෙන් ප්\u200dරශ්නයක් විශේෂයෙන් ඉහළයි. ඉතින්, අපි අනිශ්චිතත්වයක් අධාරිත්වය සක්\u200dරිය ඉගෙනීම (AL) විධානයක් පරීක්ෂා කරනවා ප්\u200dරජාතිකාරිය සඳහා ප්\u200dරත අපේ විශාල සාමාන්\u200dය විශ්ලේෂණය පෙන්වන්නේ අනිශ්වාසිත විශ්ලේෂණය සඳහා මේ තොරතුරු සෙට් එක්ක සාමාන්\u200dය විශ්ලේෂණය ස', 'so': "Qiimaha takhasuska sare waa qayb muhiim ah go’aanka. Sida dhaqso ah ka hor dhigidda qiimaha doodu waa shaqo adag oo ugu dhowaad aad aad u fiirsatay qoraalka arrimaha. Si kastaba ha ahaatee hawlgabka la xiriiro waa mid si gaar ah. Sidaa darteed waxaynu ku imtixaannaa qaababka waxbarashada waxqabadka ah oo ku qoran labada kooban ee macluumaadka arrimaha bulshada, si aan u qiimeyno in waxbarashada faa’iido leh ay awoodi karto. Qiimeynta faa'iidada aad u dheer waxay muuqataa in qabashada aqoonta la'aanta aysan ka hor marin karin saxda la heli karo koritaanka kooxdaas.", 'ta': 'உயர்தரமான தருமதிப்புகள் முடிவு செய்ய முக்கியமான பகுதியாகும். ஒரு தருமதிப்பின் தரம் தானாகவே முன்வாக்குவது ஒரு சிக்கலான செயல் ஆனால், இந்த பணிக்கான அறிவிப்பு முயற்சி வித்தியாசமாக உயர்ந்தது. ஆகையால், நாம் சோதிக்க வேண்டும் இரண்டு பிரபலமான தருமதிப்பு-சக்தி தரவு அமைப்புகளில் தெரியாத செயல்பாடு கற்றல் செயல்படுத்த முடியுமா  நம்முடைய விரிவான உச்சரிப்பு காண்பிக்கப்படுகிறது நம்பிக்கை அடிப்படையான பெறுதல் செயல்பாடுகள் இந்த தரவு அமைப்புகளில் குறிப்ப', 'ur': 'اچھی کیفیت کے ارائے فیصلہ کرنے کے ایک ضروری حصہ ہیں. آروم کی کیفیت کی آگاہ کرنا ایک پیچیدہ کام ہے جو اچھے سے بہت سی توجه حاصل کیا گیا ہے۔ لیکن اس کام کے لئے اظہار کی کوشش بہت بلند ہے۔ لہٰذا، ہم نے ان دو مشرکین آرکیم-قوت ڈیٹ سٹوں پر غیر یقین کی بنیاد پر فعال یادہانی (AL) طریقے کی آزمائش کی تاکید کی کہ نمونہ-فعال یادہانی قابل ہو سکتی ہے. ہماری گھیری عمومی ارزیابی دکھاتی ہے کہ غیر قطعی بنیاد رکھنے والی غیر قطعی فعالیتیں ان ڈیٹ سٹوں پر پہنچ جانے والی صحیح کے ساتھ غیر قطعی غیر قابل ہے', 'uz': "Buyuk qiymati argumentlari xabar qilish muhim qismi. @ info: whatsthis Lekin, bu vazifa uchun taʼminlovchi harakat oddiy juda yuqori. Shunday qilib, biz ko'pchilik asosiy aktiv o'rganish (AL) usullarini o'rganish mumkin, masalan o'rganishni foydalanishiga imkoniyat qilamiz. Bizning kengaytirilgan muvaffaqiyatlarimizni ko'rsatadi, bu maʼlumotlar sonlarida tasdiqlash muvaffaqiyatlarni aniqlab boʻlmaydi.", 'vi': 'Tài liệu chất lượng cao là yếu tố quyết định. Tự động dự đoán chất lượng của một cuộc tranh luận là một nhiệm vụ phức tạp mà gần đây đã được chú ý nhiều trong việc khai thác tranh luận. Tuy nhiên, ghi chú dành cho nhiệm vụ này cực kỳ cao. Do đó, chúng tôi thử các phương pháp nghiên cứu hoạt động dựa trên sự mơ hồ (Al) dựa trên hai nhóm dữ liệu dựa trên các cuộc tranh luận để ước lượng liệu hiệu quả mẫu có khả năng học hay không. Sự nghiên cứu đầy đủ của chúng tôi cho thấy các chức năng mua sắm dựa trên sự rủi ro không thể vượt qua độ chính xác đạt được với việc mua ngẫu nhiên trên các bộ dữ liệu này.', 'hr': 'Vjerojatno kvalitetni argumenti su ključni dio donošenja odluka. Automatski predviđanje kvalitete argument a je kompleksan zadatak koji je nedavno dobio mnogo pažnje u rudarstvu argumenta. Međutim, napor za annotaciju ovog zadatka je izuzetno visok. Stoga testiramo metode aktivnog učenja (AL) na temelju nejasnosti na dva popularna seta podataka o snazi argument-a kako bi procijenili može li se omogućiti učenje učinkovitosti uzorka. Naša široka empirička procjena pokazuje da funkcije na osnovu prikupljanja na temelju nesigurnosti ne mogu preći točnost dostignuta slučajnim prikupljanjem na ovim podacima.', 'da': 'Argumenter af høj kvalitet er en væsentlig del af beslutningstagningen. Automatisk forudsigelse af kvaliteten af et argument er en kompleks opgave, der for nylig fik meget opmærksomhed i argument mining. Anmærkningsindsatsen for denne opgave er dog usædvanlig stor. Derfor tester vi usikkerhedsbaserede aktive læringsmetoder (AL) på to populære argumentstyrkedatasæt for at vurdere, om prøveeffektiv læring kan aktiveres. Vores omfattende empiriske evaluering viser, at usikkerhedsbaserede anskaffelsesfunktioner ikke kan overgå den nøjagtighed, der opnås med tilfældig anskaffelse af disse datasæt.', 'bg': 'Висококачествените аргументи са съществена част от вземането на решения. Автоматичното предсказване на качеството на аргумент е сложна задача, която наскоро привлече много внимание в добива на аргументи. Въпреки това усилията за анотация за тази задача са изключително високи. Ето защо тестваме методи за активно учене, базирани на неопределеност (АЛ), върху два популярни набора от данни за силата на аргументите, за да преценим дали може да се даде възможност за ефективно учене на извадката. Нашата обширна емпирична оценка показва, че функциите за придобиване, базирани на неопределеност, не могат да надминат точността, постигната при случайното придобиване на тези набори от данни.', 'ko': '고품질의 논거는 정책 결정의 중요한 구성 부분이다.논점의 질을 자동으로 예측하는 것은 복잡한 임무로 최근 몇 년 동안 논점 발굴에서 광범위한 관심을 받았다.그러나 이 임무의 주석 작업량은 매우 높다.따라서 우리는 두 가지 유행하는 매개 변수 강도 데이터 집합에서 불확실성에 기반한 능동 학습(AL) 방법을 테스트하여 샘플의 효과적인 학습을 사용할 수 있는지를 평가한다.우리의 광범위한 경험 평가에 따르면 불확실성을 바탕으로 하는 채집 함수는 무작위 채집이 달성한 정밀도를 초과할 수 없다.', 'nl': 'Hoogwaardige argumenten zijn een essentieel onderdeel van de besluitvorming. Het automatisch voorspellen van de kwaliteit van een argument is een complexe taak die onlangs veel aandacht kreeg in argument mining. De annotatie-inspanning voor deze taak is echter uitzonderlijk hoog. Daarom testen we op onzekerheid gebaseerde actieve leermethoden (AL) op twee populaire gegevenssets met argumentsterkte om te schatten of steekproefefficiënt leren mogelijk is. Onze uitgebreide empirische evaluatie toont aan dat onzekerheidsgebaseerde acquisitiefuncties de nauwkeurigheid die bereikt wordt met de willekeurige acquisitie op deze datasets niet kunnen overtreffen.', 'id': 'Argumen kualitas tinggi adalah bagian penting dalam pembuat keputusan. Otomatis memprediksi kualitas argumen adalah tugas kompleks yang baru-baru ini mendapat banyak perhatian dalam pertambangan argumen. Namun, usaha anotasi untuk tugas ini sangat tinggi. Oleh karena itu, kami menguji metode pembelajaran aktif berdasarkan ketidakpastian (AL) pada dua set data kekuatan argumen populer untuk memperkirakan apakah pembelajaran efisien sampel dapat diaktifkan. Evaluasi empirik ekstensif kami menunjukkan bahwa fungsi akvizi berdasarkan ketidakpastian tidak dapat melebihi akurasi yang dicapai dengan akvizi acak pada set data ini.', 'fa': 'ارائه\u200cهای کیفیت بالا بخشی از تصمیم گرفتن ضروری هستند. خودکار پیش\u200cبینی کیفیت یک حجت یک کار پیچیده است که اخیراً توجه زیادی در ذخیره کردن حجت داشته است. ولی تلاش اظهار این کار بسیار بالاست. بنابراین، ما روش\u200cهای یادگیری فعالی (AL) بر بنیاد غیر مطمئنی را آزمایش می\u200cکنیم بر دو مجموعه\u200cهای داده\u200cهای قوت arguments-قوت محبوب برای تخمین کردن که آیا یادگیری\u200cهای مثبت نمونه\u200cای تواند فعال ارزیابی عمومی ما نشان می دهد که عملکرد گرفتن غیر مستقیم نمی توانند دقیقاتی که با گرفتن تصادفی در این مجموعه داده ها رسیده شده را تغییر دهند.', 'sw': 'Majadiliano ya juu ni sehemu muhimu ya uamuzi. Kutabiri mwenyewe kiwango cha mjadala ni kazi tata ambayo hivi karibuni ilijikuta makini sana katika uchimbaji wa mijadala. Hata hivyo, jitihada za kutangaza kwa kazi hii ni kubwa zaidi. Kwa hiyo, tunajaribu njia za kujifunza kwa usio na uhakika (AL) za takwimu mbili maarufu za hoja zinazohitimisha kama elimu yenye ufanisi unaweza uwezekano. Utafiti wetu wa kipekee unaonyesha kuwa kazi za kupatikana kwa usio na uhakika hauwezi kupitisha ukweli uliofanywa na upatikanaji wa taarifa hizi.', 'tr': 'Yüksek kalitede argümanlar karar bermegiň esasy bölegi. Argumentyň kalitesini otomatik çaklamak üçin gaty bir täblikdir. Soňra argüment taýýarlamakda köp üns berilýär. Yöne şu işiň üçin duýdurma çalygy ýok. Şol sebäpli, biz ynamlykdan daşary aktiw öwrenmek (AL) yöntemlerini iki popüler argum güýçli maglumat düzümleriniň örän-täsirli öwrenmek mümkin edip biljegini takyklaýarys. Biziň golaý empirik deňleşmerimiz bu maglumat düzümlerinde gatnaşykly gazanýan fonksiyonlaryň dogrylygyny üstünde tutup bilmeýändigini görkez.', 'de': 'Qualitativ hochwertige Argumente sind ein wesentlicher Bestandteil der Entscheidungsfindung. Die automatische Vorhersage der Qualität eines Arguments ist eine komplexe Aufgabe, die kürzlich im Argument Mining viel Aufmerksamkeit erregte. Der Annotationsaufwand für diese Aufgabe ist jedoch außergewöhnlich hoch. Daher testen wir unsicherheitsbasierte aktive Lernmethoden (AL) an zwei gängigen Argumentstärke-Datensätzen, um abzuschätzen, ob sample-efficient learning aktiviert werden kann. Unsere umfangreiche empirische Auswertung zeigt, dass unsicherheitsbasierte Erfassungsfunktionen die Genauigkeit der Zufallserfassung auf diesen Datensätzen nicht überschreiten können.', 'sq': 'Argumentet e cilësisë së lartë janë një pjesë thelbësore të vendimit. Parashikimi automatik i cilësisë së një argument është një detyrë komplekse që kohët e fundit mori shumë vëmendje në minierën e argumenteve. Megjithatë, përpjekja e anotacionit për këtë detyrë është jashtëzakonisht e lartë. Therefore, we test uncertainty-based active learning (AL) methods on two popular argument-strength data sets to estimate whether sample-efficient learning can be enabled.  Vlerësimi ynë i gjerë empirik tregon se funksionet e blerjes bazuar në pasiguri nuk mund të kapërcejnë saktësinë e arritur me blerjen e rastësishme në këto grupe të dhënash.', 'am': 'ከፍተኛ ውጤት ክርክሮች የውሳኔ ውሳኔ ናቸው፡፡ የአውራጅ ግንኙነት ውጤትን በመቀበል በአሁኑ ጊዜ ብዙ ትኩረትን በመቀበል የደረሰበት ትክክለኛ ስራ ነው፡፡ ምንም እንኳን ለዚህ ስራ የሚደረገው አካባቢ ትልቅ ነው፡፡ ስለዚህም የምናስፈልገውን የፀሐይ ትምህርት (AL) ሥርዓት በሁለት የሆኑት የአውራሲ-የኃይል ዳታዎችን በመጠቀም ምሳሌ-ፍቃድ ትምህርት መቻለኛ እንዲችል እንደሆነ እናስታውቃለን፡፡ የስፋት ማነሳያ ግንኙነታችን በማይታወቅ በአካባቢው የሥርዓት ግንኙነታችን በዚህ የዳታ ሰርቨሮች ላይ በተደረገው እርግጠኛ ማግኘት አይችልም፡፡', 'az': 'Yüksek kaliteli argumentlər karar verməyin əsas bir parçasıdır. Argumentin keyfiyyətini avtomatik olaraq təxminə etmək müxtəlif bir işdir ki, az öncə Argument qurmasında çox dikkat alırdı. Ancaq bu işin məcburiyyətinin məcburiyyəti çox yüksəkdir. Buna görə də, nümunə-effektiv öyrənmə qabiliyyəti qabiliyyəti qabiliyyəti ilə müəyyən etmək üçün iki məşhur argument-qüvvət verilən dəyişiklik qurunun istifadə etdik. Bizim genişliyimiz empirik değerlendirmələrimiz belə göstərir ki, bu məlumatlar qurduğu istisna qəbul etmə fəaliyyətlərinin istisnadır.', 'hy': 'Բավական որակի բանավեճերը որոշումների կայացման կարևոր մասն են: Ավելի բարդ խնդիր է, որը վերջերս շատ ուշադրություն դարձրեց բանավեճերի հանքահանման մեջ: Այնուամենայնիվ, այս խնդրի նկարագրման ջանքը բացառությամբ բարձր է: Այսպիսով, մենք փորձում ենք անորոշությամբ հիմնված ակտիվ ուսումնասիրության (ԱԲ) մեթոդները երկու հայտնի բանավեճի ուժի տվյալների համակարգերի վրա, որպեսզի հաշվարկենք, արդյոք նմուշներ արդյունավետ ուսում Մեր էքսպենսիվ էմպրիկական գնահատումը ցույց է տալիս, որ անորոշությամբ հիմնված գնումների ֆունկցիաները չեն կարող գերազանցել ճշգրտությունը, որը հասել է այս տվյալների համակարգերի պատահական գնումների հետ:', 'af': "Hoog-kwaliteit argumente is 'n nuwe deel van besluit-making. Outomaties voorskou die kwaliteit van 'n argument is 'n kompleks taak wat onlangs baie aandag het in argument mining. Maar, die annotasie versoek vir hierdie taak is uitsonderlik hoog. Daarom, ons probeer onbevestigheid-gebaseerde aktiewe leer (AL) metodes op twee populêre argument-sterkte data stelle om te estimereer of voorbeeld-effektief leer geaktiveer kan word. Ons uitbreidige empiriese evaluering vertoon dat onbevestigheid-gebaseerde akseptasie funksies kan nie oorvloei die presisie wat bereik is met die willekeurige akseptasie op hierdie data stel.", 'ca': "Els arguments d'alta qualitat són una part essencial de la toma de decisions. Predir automàticament la qualitat d'un argument és una tasca complex a que fa poc va rebre molta atenció en la mineria d'arguments. Però l'esforç d'anotació d'aquesta tasca és excepcionalment alt. Per tant, testem mètodes d'aprenentatge actiu basat en incertituds (AL) en dos conjunts populars de dades d'argument-strength per estimar si es pot activar aprenentatge eficient en mostra. Our extensive empirical evaluation shows that uncertainty-based acquisition functions can not surpass the accuracy reached with the random acquisition on these data sets.", 'cs': 'Vysoce kvalitní argumenty jsou nezbytnou součástí rozhodování. Automatické předpovídání kvality argumentu je složitý úkol, který v poslední době získal velkou pozornost při dolování argumentů. Avšak úsilí o anotaci pro tento úkol je mimořádně vysoké. Proto testujeme metody aktivního učení založené na nejistotě na dvou populárních datových sadách argumentů, abychom odhadli, zda lze povolit efektivní učení vzorků. Naše rozsáhlé empirické hodnocení ukazuje, že akviziční funkce založené na nejistotě nemohou překonat přesnost dosaženou náhodným získáváním na těchto datových sadách.', 'bn': 'উচ্চমানের যুক্তি সিদ্ধান্ত নির্ধারণের একটি গুরুত্বপূর্ণ অংশ। স্বয়ংক্রিয়ভাবে একটি যুক্তির মানের ভবিষ্যদ্বাণী হচ্ছে একটি জটিল কাজ যা সম্প্রতি যুক্তি মিনিটে বেশী মনোযো তবে এই কাজের প্রচেষ্টা ব্যতিক্রমে বেশী উচ্চ। তাই আমরা দুই জনপ্রিয় যুক্তি-শক্তিশালী তথ্যের উপর নিশ্চিতভিত্তিক সক্রিয় শিক্ষা শিক্ষার পদ্ধতি পরীক্ষা করছি যাতে আমরা ধারণা করি নমুনা আমাদের বিস্তৃত ক্ষমতার মূল্য দেখাচ্ছে যে নিশ্চিতভিত্তিক অনুসন্ধানের ক্ষেত্রে এই তথ্য সংক্রান্ত তথ্য পাওয়ার ক্ষেত্রে', 'et': 'Kvaliteetsed argumendid on otsuste tegemise oluline osa. Argumenti kvaliteedi automaatne prognoosimine on keeruline ülesanne, mis sai hiljuti argumentide kaevandamisel palju tähelepanu. Selle ülesande märgistamise jõupingutused on siiski erakordselt suured. Seetõttu testime ebakindlusel põhinevat aktiivse õppe (AL) meetodeid kahe populaarse argumentide tugevuse andmekogumi põhjal, et hinnata, kas valimitõhusat õppimist on võimalik lubada. Meie ulatuslik empiiriline hindamine näitab, et määramatusel põhinevad omandamise funktsioonid ei saa ületada nende andmekogumite juhusliku omandamise täpsust.', 'bs': 'Argumenti visoke kvalitete su ključni dio donošenja odluka. Automatski predviđanje kvalitete argument a je kompleksan zadatak koji je nedavno dobio mnogo pažnje u rudarstvu argumenta. Međutim, napor za annotaciju ovog zadatka je izuzetno visok. Stoga testiramo metode aktivnog učenja (AL) na temelju nesigurnosti na dva popularna seta podataka snage argumentacija kako bi procijenili može li se omogućiti učenje učinkovitosti uzorka. Naša široka empirička procjena pokazuje da funkcije na osnovu prikupljanja na osnovu nesigurnosti ne mogu preći tačnost ostvarena slučajnim prikupljanjem na ovim podacima.', 'fi': 'Laadukkaat perustelut ovat olennainen osa päätöksentekoa. Argumentin laadun automaattinen ennustaminen on monimutkainen tehtävä, joka on viime aikoina saanut paljon huomiota argumenttien louhintaan. Tähän tehtävään liittyvät huomautukset ovat kuitenkin poikkeuksellisen suuria. Tämän vuoksi testaamme epävarmuuteen perustuvaa aktiivista oppimista kahdella suositulla argumenttivahvuusaineistolla arvioidaksemme, voidaanko otokseen perustuva oppiminen mahdollistaa. Laaja empiirinen arviointimme osoittaa, että epävarmuuteen perustuvat hankintatoiminnot eivät voi ylittää satunnaishankinnalla saavutettua tarkkuutta.', 'jv': 'Delokan sawar luwih-kaliwat sing dibenakno ning kebijakan dockable-action politenessoffpolite"), and when there is a change ("assertive Nanging, kéné ujian seneng pisan-pakan mulai akses nggambar (AL) gambar ditambah populer Awak dhéwé éntuk empirhik sing ngomong nik akeh perusahaan-perusahaan karo pakem gak dhéwé, kuwi mau kuwi kesempatan kanggo ngerasah', 'sk': 'Visokokakovostni argumenti so bistveni del odločanja. Samodejno napovedovanje kakovosti argumenta je kompleksno opravilo, ki je v zadnjem času pridobilo veliko pozornosti pri rudarjenju argumentov. Vendar pa je prizadevanje za opombe za to nalogo izjemno visoko. Zato preizkusimo metode aktivnega učenja na podlagi negotovosti na dveh priljubljenih naborih podatkov o moči argumentov, da ocenimo, ali je mogoče učenje z učinkovitim vzorcem omogočiti. Naša obsežna empirična ocena kaže, da funkcije pridobivanja, ki temeljijo na negotovosti, ne morejo preseči natančnosti, dosežene z naključnim pridobivanjem na teh naborih podatkov.', 'ha': "Argumen da sifawa ya fi girma yana da muhimu rabo ga yin hukunci. @ info: whatsthis A lokacin da, aikin zartar da wannan aikin na sarki. Saboda haka, Munã jarraba hanyõyi masu tsari da aka sani a bakin da ba'a sani ba (AI) a kan data masu jama'a biyu na argument-ƙarfi, dõmin ka ƙaddara ko an iya iya iya karatar da karatun masu amfani da kwamfyuta. Our extensive empirical evaluation shows that uncertainty-based acquisition functions can not surpass the accuracy reached with the random acquisition on these data sets.", 'he': 'הטיעונים באיכות גבוהה הם חלק חיוני של קיבלת החלטות. חיזוי אוטומטי של איכות טיעון הוא משימה מורכבת שקיבלה לאחרונה תשומת לב רבה במכריית טיעונים. עם זאת, מאמץ הערות למשימה הזאת גבוה באופן יוצא דופן. לכן, אנחנו בודקים שיטות לימוד פעיל מבוססת על אי-בטוחות (AL) על שני קבוצות נתונים פופולריים של כוח טיעון כדי להעריך אם לימוד יעיל בדגימה יכול להיות אפשרי. הערכה האמפרית המורחבת שלנו מראה שמפעילות רכישה מבוססת בלתי בטוחות לא יכולות להתגבר על הדיוקת שנהגעה עם הרישוי האקראי על קבוצות הנתונים האלה.', 'bo': 'High-quality arguments are an essential part of decision-making. Automatically predicting the quality of an argument is a complex task that recently got much attention in argument mining. ཡིན་ནའང་། བྱ་འགུལ་འདིའི་དོན་ལ་གསལ་བཤད་ཀྱི་སྒུལ་ཤུགས་ནི་ཁྱད་དུ་འཕགས་པ་ཞིག་རེད། Therefore, we test uncertainty-based active learning (AL) methods on two popular argument-strength data sets to estimate whether sample-efficient learning can be enabled. ང་ཚོའི་འཛམ་གླིང་གི་empirical evaluation་ནི་གསལ་བཤད་ཀྱི་ལས་འཚོལ་བ་གཞི་རྟེན་ནས་ཉར་ཞིབ་ཀྱི་རྩིས་འབྲེལ་འདི་ཚོའི་གནས་སྟངས་འདི་ཚོར'}
