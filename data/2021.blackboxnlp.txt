{'en': 'Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings', 'ar': 'هل المعرفة الخارجية تساعد في تفسير استدلال اللغة الطبيعية؟ التقييم التلقائي مقابل التقييمات البشرية', 'pt': 'O conhecimento externo ajuda a inferência de linguagem natural explicável? Avaliação automática versus classificações humanas', 'es': '¿El conocimiento externo ayuda a la inferencia explicable del lenguaje natural? Evaluación automática frente a calificaciones humanas', 'fr': "Les connaissances externes contribuent-elles à l'inférence explicable du langage naturel\xa0? Évaluation automatique par rapport aux évaluations humaines", 'ja': '外部知識は説明可能な自然言語推論に役立ちますか？自動評価と人間評価', 'hi': 'क्या बाहरी ज्ञान प्राकृतिक भाषा अनुमान को समझाने में मदद करता है? स्वचालित मूल्यांकन बनाम मानव रेटिंग', 'zh': '外知有助于可解者自然语言理乎? 自料与人工评级', 'ru': 'Помогают ли внешние знания сделать вывод о естественном языке? Автоматическая оценка в сравнении с человеческими оценками', 'ga': 'An Cuidíonn Eolas Seachtrach Tátail Inmhínithe Teanga Nádúrtha? Meastóireacht Uathoibríoch vs. Rátálacha Daonna', 'ka': 'გარეშე ცნობიერების დახმარება გამოსახულებელი თავისუფლიო ენაზე? ადამიანის რეტინგის ავტომატური განსაზღვრება', 'hu': 'Segít a külső tudás megmagyarázni a természetes nyelvi fertőzést? Automatikus értékelés vs. humán minősítések', 'el': 'Βοηθά η εξωτερική γνώση στην εξήγηση της φυσικής γλώσσας; Αυτόματη αξιολόγηση έναντι των ανθρώπινων βαθμολογιών', 'it': "La conoscenza esterna aiuta a spiegare l'inferenza del linguaggio naturale? Valutazione automatica contro valutazioni umane", 'kk': 'Сыртқы білім көмегімен түсініктіретін табиғи тілдер қатынасы бар ма? Адам бағалауына қарсы автоматты түрде оқу', 'lt': 'Ar išorinės žinios padeda paaiškinti gamtinės kalbos trūkumą? Automatinis vertinimas, palyginti su žmogaus vertinimais', 'mk': 'Дали надворешното знаење помага да се објасни природната инференција на јазикот? Automatic Evaluation vs. Human Ratings', 'ms': 'Adakah Pengetahuan Luar Bantu Dijelaskan Bahasa Bahasa Alami? Evaluasi Automatik vs. Nilai Manusia', 'mn': 'Байгалийн мэдлэг нь тайлбарлах байгалийн хэл хамааралтай туслах уу? Хүн төрөлхтний тооны эсрэг автоматтын үнэлгээ', 'ml': 'പുറത്തുള്ള അറിവ് സ്വാഭാവികമായ ഭാഷ വിശദീകരിക്കാന്\u200d സഹായിക്കുന്നുണ്ടോ? മനുഷ്യരുടെ റേറ്റിങ്ങുകള്\u200d', 'mt': 'L-Għarfien Estern jgħin fl-Inferenza tal-Lingwi Naturali Spjegabbli? Evalwazzjoni Awtomatika vs. Klassifikazzjonijiet tal-Bniedem', 'no': 'Er eksterne kunnskap hjelp for utforskar naturspråk? Automatisk evaluering mot menneske verdiar', 'sr': 'Da li vanjska znanja pomaže da objasni prirodni jezik? Automatic Evaluation vs. Human Ratings', 'pl': 'Czy wiedza zewnętrzna pomaga wyjaśnić wniosek języka naturalnego? Automatyczna ocena w porównaniu z oceną ludzką', 'ro': 'Cunoștințele externe ajută la explicarea inferenței limbajului natural? Evaluare automată comparativ cu evaluările umane', 'si': 'පුරුද්ගලික දැනගන්න උදව් කරන්න පුරුද්ගලික භාෂාව ප්\u200dරශ්නය කරන්න පුළුවන්ද? ස්වයංක්\u200dරියාත්මක විශ්වාස කරන්න', 'sv': 'Hjälper extern kunskap till att förklara naturliga språkinfektioner? Automatisk utvärdering jämfört med mänskliga värderingar', 'so': 'Ma cawinaada aqoonta dibadda ah oo la caddeyn karo afka asalka ah? Qedemeynta bilowga', 'ta': 'வெளி அறிவு இயல்பான மொழி புதுப்பிக்க உதவுகிறதா? தானியங்கி மதிப்பீடு', 'ur': 'کیا خارجی علم کی تعریف قابل توسطی زبان کی نسبت مدد کرتی ہے؟ اٹوٹوکیٹ ارتفاع انسانی راٹینگ', 'uz': 'Tashqi maò¥lumot Natalik tilni aniqlashni istaysizmi? Avto- toò£gò£rilash', 'vi': 'Hỗ trợ hiểu biết đối diện Giải thích ngôn ngữ tự nhiên? Đánh giá tự động tương ứng con người', 'bg': 'Външното знание помага ли за обяснимото природно езиково заключение? Автоматична оценка спрямо човешките рейтинги', 'nl': 'Helpt Externe Kennis Verklaarbare Natuurlijke Taal Inferentie? Automatische evaluatie versus menselijke ratings', 'hr': 'Da li vanjska znanja pomaže objašnjivim prirodnim jezikom? Automatska procjena protiv ljudskih ocjena', 'da': 'Hjælper ekstern viden med at forklare naturlige sproginfektioner? Automatisk evaluering i forhold til menneskelige vurderinger', 'id': 'Apakah Pengetahuan Luar membantu Penjelasan Bahasa Alami Inferensi? Evaluasi Otomatis vs. Rating Manusia', 'de': 'Hilft externes Wissen bei erklärbaren Schlussfolgerungen natürlicher Sprache? Automatische Bewertung vs. Human Ratings', 'ko': '외부 지식은 자연 언어의 추리를 해석하는 데 도움이 됩니까?자동 평가와 인공 평가', 'fa': 'آیا دانش خارجی کمک می کند تفاوت زبان طبیعی توضیح داده شود؟ ارزیابی خودکار با ارزیابی انسان', 'sw': 'Je, maarifa ya nje inasaidia kuingilia lugha ya asili? Uchunguzi wa kujitegemea dhidi ya mabomu ya binadamu', 'tr': 'Daşarydaky Bilim Tebiýaly Dili Aňlamakda Kömek edip bilýärmi? Otomatik Taýýarlama', 'af': 'Het eksterne kennis hulp verduidelik Natuurlike Taal Inferensie? Outomatiese evaluering teen menslike waardelings', 'sq': 'A ndihmon njohuria e jashtme të shpjegohet për gjuhën natyrore? Vlerësim automatik kundër vlerësimeve njerëzore', 'am': "የውጭ እውቀት የባሕላዊ ቋንቋ መግለጫ ይችላልን? ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'az': 'External Knowledge Yard캼m edir M톛xluqat Dili Inference? 캻nsan qiym톛tl톛ri', 'hy': 'Does External Knowledge Help Explainable Natural Language Inference?  Comment', 'bn': 'বাইরের জ্ঞান কি স্বাভাবিক ভাষা ব্যাখ্যা করতে সাহায্য করে? স্বয়ংক্রিয়ভাবে মানুষের রেটিং', 'bs': 'Da li vanjska znanja pomaže objašnjavajući prirodni jezik? Automatska procjena protiv ljudskih ocjena', 'ca': 'El coneixement extern ajuda a explicar la llengua natural? Evaluació automàtica contra valoracions humanes', 'cs': 'Pomáhají externí znalosti vysvětlitelnému závěru přirozeného jazyka? Automatické hodnocení vs. lidské hodnocení', 'et': 'Kas välised teadmised aitavad selgitada loodusliku keele järeldust? Automaatne hindamine vs inimhinnangud', 'fi': 'Auttaako ulkoinen tietämys selittäviä luonnollisen kielen päätelmiä? Automaattinen arviointi verrattuna ihmisten luokituksiin', 'jv': 'Opo kowe paling Panjenengan langkung popolahan apik ? drawable-action', 'he': 'האם הידע החיצוני עוזר להסביר שפת טבעית חולה? Automatic Evaluation vs. Human Ratings', 'ha': "Shin, Aiki na Bayan Cilmi na Bayan Aiki na Bayan Taurar da za'a bayyana Infez da Lugha na Natural? @ action", 'sk': 'Ali zunanje znanje pomaga pojasniti sklepanje naravnega jezika? Avtomatsko ocenjevanje v primerjavi z oceno ljudi', 'bo': 'ཕྱི་རིང་གི་ཤེས་པའི་རོགས་རམ་བསླབ་བཏུབ་པའི་རང་བཞིན་སྐད་ཀྱི་ཆ་གཤིས་ཡིན་ནམ། རང་འགུལ་གྱིས་མིའི་རིམ་པ'}
{'en': 'Natural language inference (NLI) requires models to learn and apply commonsense knowledge. These reasoning abilities are particularly important for explainable NLI systems that generate a natural language explanation in addition to their label prediction. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date. It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor grammar correctness.', 'ar': 'يتطلب الاستدلال اللغوي الطبيعي (NLI) نماذج للتعلم وتطبيق المعرفة المنطقية. تعتبر قدرات التفكير هذه مهمة بشكل خاص لأنظمة NLI القابلة للتفسير والتي تولد تفسيرًا للغة الطبيعية بالإضافة إلى تنبؤ التسمية الخاصة بهم. لقد ثبت أن تكامل المعرفة الخارجية يحسن أنظمة NLI ، وهنا نتحرى ما إذا كان بإمكانه أيضًا تحسين قدرات التفسير الخاصة بها. لهذا ، نحن نبحث في مصادر مختلفة للمعرفة الخارجية ونقيم أداء نماذجنا على بيانات المجال وكذلك على مجموعات بيانات النقل الخاصة المصممة لتقييم قدرات التفكير الدقيقة. نجد أن مصادر المعرفة المختلفة لها تأثير مختلف على قدرات التفكير ، على سبيل المثال ، المعرفة الضمنية المخزنة في نماذج اللغة يمكن أن تعيق التفكير في الأرقام والنفي. أخيرًا ، نجري أكبر دراسة تعهيد جماعي قابلة للتفسير وأكثرها دقة حتى الآن. ويكشف أنه حتى الاختلافات الكبيرة في درجات الأداء التلقائية لا تنعكس في التصنيفات البشرية للتسمية والتفسير والمنطق ولا صحة القواعد.', 'fr': "L'inférence en langage naturel (NLI) nécessite des modèles pour apprendre et appliquer des connaissances de bon sens. Ces capacités de raisonnement sont particulièrement importantes pour les systèmes NLI explicables qui génèrent une explication en langage naturel en plus de leur prédiction d'étiquette. Il a été démontré que l'intégration de connaissances externes améliore les systèmes NLI. Nous examinons ici si elle peut également améliorer leurs capacités d'explication. Pour cela, nous étudions différentes sources de connaissances externes et évaluons les performances de nos modèles sur des données internes au domaine ainsi que sur des ensembles de données de transfert spéciaux conçus pour évaluer des capacités de raisonnement précis. Nous constatons que différentes sources de connaissances ont un effet différent sur les capacités de raisonnement. Par exemple, les connaissances implicites stockées dans les modèles linguistiques peuvent entraver le raisonnement sur les nombres et les négations. Enfin, nous menons l'étude de crowdsourcing NLI explicable la plus importante et la plus fine à ce jour. Il révèle que même de grandes différences dans les scores de performance automatiques ne se reflètent pas dans les évaluations humaines de l'étiquette, de l'explication, du bon sens ou de la correction grammaticale.", 'es': 'La inferencia de lenguaje natural (NLI) requiere modelos para aprender y aplicar el conocimiento de sentido común. Estas habilidades de razonamiento son particularmente importantes para los sistemas de NLI explicables que generan una explicación en lenguaje natural además de la predicción de su etiqueta. Se ha demostrado que la integración del conocimiento externo mejora los sistemas de NLI, aquí investigamos si también puede mejorar sus capacidades de explicación. Para ello, investigamos diferentes fuentes de conocimiento externo y evaluamos el rendimiento de nuestros modelos en datos de dominio, así como en conjuntos de datos de transferencia especiales que están diseñados para evaluar capacidades de razonamiento minuciosas. Encontramos que las diferentes fuentes de conocimiento tienen un efecto diferente en las habilidades de razonamiento, por ejemplo, el conocimiento implícito almacenado en los modelos de lenguaje puede dificultar el razonamiento sobre números y negaciones. Finalmente, llevamos a cabo el mayor y más detallado estudio de crowdsourcing explicable de NLI hasta la fecha. Revela que incluso las grandes diferencias en las puntuaciones automáticas de rendimiento no se reflejan en las calificaciones humanas de etiqueta, explicación, sentido común ni corrección gramatical.', 'pt': 'A inferência de linguagem natural (NLI) requer modelos para aprender e aplicar o conhecimento do senso comum. Essas habilidades de raciocínio são particularmente importantes para sistemas NLI explicáveis que geram uma explicação em linguagem natural além de sua previsão de rótulo. A integração do conhecimento externo mostrou melhorar os sistemas NLI, aqui investigamos se também pode melhorar suas capacidades de explicação. Para isso, investigamos diferentes fontes de conhecimento externo e avaliamos o desempenho de nossos modelos em dados no domínio, bem como em conjuntos de dados de transferência especiais projetados para avaliar recursos de raciocínio refinado. Descobrimos que diferentes fontes de conhecimento têm um efeito diferente nas habilidades de raciocínio, por exemplo, o conhecimento implícito armazenado em modelos de linguagem pode dificultar o raciocínio sobre números e negações. Por fim, realizamos o maior e mais detalhado estudo de crowdsourcing NLI explicável até o momento. Ele revela que mesmo grandes diferenças nas pontuações de desempenho automático não refletem nas classificações humanas de rótulo, explicação, senso comum ou correção gramatical.', 'ja': '自然言語推論（ NLI ）では、モデルが常識的な知識を学び、適用する必要がある。 これらの推論能力は、ラベル予測に加えて自然言語の説明を生成する説明可能なNLIシステムにとって特に重要です。 外部知識の統合はNLIシステムを改善することが示されており、ここではそれらの説明能力を向上させることができるかどうかを調査します。 このため、外部知識のさまざまなソースを調査し、ドメイン内データおよび細かい推論能力を評価するように設計された特別な転送データセットでのモデルのパフォーマンスを評価します。 異なる知識源は、例えば、言語モデルに保存された暗黙の知識が、数値や否定に関する推論を妨げる可能性があるなど、推論能力に異なる影響を及ぼすことがわかっている。 最後に、これまでで最大かつ最も細かく説明可能なNLIクラウドソーシング研究を行います。 自動パフォーマンススコアの大きな違いでさえ、ラベル、説明、常識、文法の正しさの人間的評価に反映されないことが明らかになりました。', 'zh': '自然语言推理(NLI)求模形学用常识。 其于可解者NLI统尤要,非生成之外,犹生自然语言解。 外知之整合,已验可以改善NLI统,于此论其可以益其说。 故论外知之本,而论域内之数,及指评细粒度理能之殊传输数据集上。 臣等见异端,有异于推理,如言语模形隐性则碍数否之理。 最后迄今为止规模最大,最细粒度者可解NLI众包究。 明虽性能分数差异,不能见于人,说,常识语法正确性之评级也。', 'hi': 'प्राकृतिक भाषा अनुमान (एनएलआई) को सामान्य ज्ञान ज्ञान को सीखने और लागू करने के लिए मॉडल की आवश्यकता होती है। ये तर्क क्षमताएं विशेष रूप से स्पष्ट एनएलआई प्रणालियों के लिए महत्वपूर्ण हैं जो उनके लेबल की भविष्यवाणी के अलावा एक प्राकृतिक भाषा स्पष्टीकरण उत्पन्न करती हैं। बाहरी ज्ञान के एकीकरण को एनएलआई प्रणालियों में सुधार करने के लिए दिखाया गया है, यहां हम जांच करते हैं कि क्या यह उनकी स्पष्टीकरण क्षमताओं में भी सुधार कर सकता है। इसके लिए, हम बाहरी ज्ञान के विभिन्न स्रोतों की जांच करते हैं और इन-डोमेन डेटा के साथ-साथ विशेष हस्तांतरण डेटासेट पर हमारे मॉडल के प्रदर्शन का मूल्यांकन करते हैं जो ठीक-ठाक तर्क क्षमताओं का आकलन करने के लिए डिज़ाइन किए गए हैं। हम पाते हैं कि ज्ञान के विभिन्न स्रोतों का तर्क क्षमताओं पर एक अलग प्रभाव पड़ता है, उदाहरण के लिए, भाषा मॉडल में संग्रहीत अंतर्निहित ज्ञान संख्याओं और नकारों पर तर्क में बाधा डाल सकता है। अंत में, हम आज तक के सबसे बड़े और सबसे ठीक-ठाक स्पष्ट एनएलआई क्राउडसोर्सिंग अध्ययन का संचालन करते हैं। यह पता चलता है कि स्वचालित प्रदर्शन स्कोर में भी बड़े अंतर न तो लेबल, स्पष्टीकरण, कॉमनसेंस और न ही व्याकरण शुद्धता की मानव रेटिंग में प्रतिबिंबित होते हैं।', 'ru': 'Вывод о естественном языке (NLI) требует, чтобы модели изучали и применяли знания здравого смысла. Эти способности рассуждения особенно важны для объяснимых систем NLI, которые генерируют объяснение естественного языка в дополнение к их предсказанию метки. Интеграция внешних знаний, как было показано, улучшает системы NLI, здесь мы исследуем, может ли она также улучшить их возможности объяснения. Для этого мы исследуем различные источники внешних знаний и оцениваем эффективность наших моделей на основе внутридоменных данных, а также на основе специальных наборов данных о переносе, которые предназначены для оценки возможностей мелкозернистого мышления. Мы обнаружили, что разные источники знаний по-разному влияют на способности к рассуждению, например, скрытые знания, хранящиеся в языковых моделях, могут препятствовать рассуждению о цифрах и отрицаниях. Наконец, мы проводим крупнейшее и наиболее мелкомасштабное объяснимое на сегодняшний день исследование краудсорсинга NLI. Это показывает, что даже большие различия в автоматических оценках производительности не отражаются ни на человеческих оценках этикетки, объяснения, здравого смысла, ни на правильности грамматики.', 'ga': 'Teastaíonn samhlacha ó thátal nádúrtha teanga (NLI) chun eolas ciallmhar a fhoghlaim agus a chur i bhfeidhm. Tá na cumais réasúnaíochta seo thar a bheith tábhachtach do chórais NLI inmhínithe a ghineann míniúchán teanga nádúrtha i dteannta lena dtuar lipéid. Léiríodh go bhfeabhsaítear córais LNÉ trí chomhtháthú an eolais sheachtraigh, agus anseo fiosraimid an féidir leis a gcumas míniúcháin a fheabhsú freisin. Chuige sin, déanaimid imscrúdú ar fhoinsí éagsúla eolais sheachtraigh agus déanaimid meastóireacht ar fheidhmíocht ár samhlacha ar shonraí in-fhearainn agus ar thacair sonraí aistrithe speisialta atá deartha chun cumais réasúnaíochta mhínínithe a mheas. Faighimid amach go mbíonn tionchar difriúil ag foinsí éagsúla eolais ar chumais réasúnaíochta, mar shampla, is féidir le heolas intuigthe atá stóráilte i múnlaí teanga bac a chur ar réasúnaíocht ar uimhreacha agus ar dhiúltaí. Ar deireadh, déanaimid an staidéar sluafhoinsithe de chuid LNÉ is mó agus is míne inmhínithe go dtí seo. Léiríonn sé nach léiríonn fiú difríochtaí móra sna scóir feidhmíochta uathoibríocha sna rátálacha daonna maidir le lipéad, míniú, tuiscint choitianta ná cruinneas gramadaí.', 'hu': 'A természetes nyelvi következtetés (NLI) modelleket igényel a közértelmes ismeretek tanulásához és alkalmazásához. Ezek az érvelési képességek különösen fontosak a megmagyarázható NLI rendszerek esetében, amelyek természetes nyelvi magyarázatot generálnak a címke előrejelzése mellett. A külső tudás integrációja bizonyítottan javítja az NLI rendszereket, itt azt vizsgáljuk, hogy képes-e javítani a magyarázat képességeit is. Ennek érdekében a külső ismeretek különböző forrásait vizsgáljuk, és értékeljük modelleink teljesítményét a tartományon belüli adatokon, valamint speciális átviteli adatkészleteken, amelyek a finomszemcsés érvelési képességek felmérésére szolgálnak. Megállapítjuk, hogy a különböző tudásforrások eltérő hatással vannak az érvelési képességekre, például a nyelvi modellekben tárolt implicit tudás akadályozhatja a számok és tagadások érvelését. Végül végezzük el az eddigi legnagyobb és legfinomabb magyarázható NLI crowdsourcing tanulmányt. Feltárja, hogy még az automatikus teljesítmény pontszámok közötti nagy különbségek sem tükröznek az emberi értékelésekben a címke, magyarázat, közérzet vagy nyelvtani helyesség.', 'el': 'Το συμπέρασμα φυσικής γλώσσας απαιτεί μοντέλα για να μάθουν και να εφαρμόσουν γνώση κοινής λογικής. Αυτές οι ικανότητες συλλογισμού είναι ιδιαίτερα σημαντικές για τα εξηγητά συστήματα που παράγουν μια φυσική εξήγηση γλώσσας εκτός από την πρόβλεψη ετικετών τους. Η ενσωμάτωση εξωτερικών γνώσεων έχει αποδειχθεί ότι βελτιώνει τα συστήματα Εδώ ερευνούμε αν μπορεί επίσης να βελτιώσει τις δυνατότητες εξήγησης τους. Για το σκοπό αυτό, διερευνούμε διαφορετικές πηγές εξωτερικής γνώσης και αξιολογούμε την απόδοση των μοντέλων μας σε δεδομένα εντός του τομέα καθώς και σε ειδικά σύνολα δεδομένων μεταφοράς που έχουν σχεδιαστεί για την αξιολόγηση των δυνατοτήτων λεπτού συλλογισμού. Διαπιστώνουμε ότι διαφορετικές πηγές γνώσης έχουν διαφορετική επίδραση στις ικανότητες συλλογισμού, για παράδειγμα, η σιωπηρή γνώση που αποθηκεύεται σε γλωσσικά μοντέλα μπορεί να εμποδίσει τη συλλογιστική αριθμών και αρνήσεων. Τέλος, διεξάγουμε τη μεγαλύτερη και πιο λεπτόκοκκη επεξηγητή μελέτη μέχρι σήμερα. Αποκαλύπτει ότι ακόμη και μεγάλες διαφορές στις αυτόματες βαθμολογίες απόδοσης δεν αντικατοπτρίζονται στις ανθρώπινες αξιολογήσεις της ετικέτας, της επεξήγησης, της κοινής λογικής ή της γραμματικής ορθότητας.', 'ka': 'ნაირადი ენის ინფრენცია (NLI) უნდა მოდელების შესწავლება და გამოყენება საერთო სიცოცხლე. ეს პარამენტიური შესაძლებლობა განსაზღვრებელი NLI სისტემებისთვის მნიშვნელოვანია, რომელიც თავის ლაბეტის წარმოდგენის დამატებით ნახვა ენის გახსნა. გარეშე ცნობილების ინტერგურაცია გამოჩვენებულია, რომ NLI სისტემების უფრო მეტირებად, აქ ჩვენ ვაკეთებთ თუ ეს შეუძლია ასევე უფრო მეტირება შესაძლებლობა. ამისთვის, ჩვენ განსხვავებული გარეშე ცნობილების განსხვავებული გამოყენება და ჩვენი მოდელების გამოყენება დემომინის მონაცემებზე და სპეციალური გარეშე მონაცემების შესახებ, რომლებიც განაზღვრებულია ჩვენ ვიფიქრობთ, რომ განსხვავებული მეცნიერების გამოსახულების განსხვავებული ეფექტი არსებობს რაოდენობის შესაძლებლობაზე, მაგალითად, ენის მოდელში მუშაობული მეცნიერების შესაძლებელია რაო საბოლოოდ, ჩვენ გავაკეთებთ უფრო დიდი და უკეთესი განახსენებელი NLI მუშაობის სწავლა. ეს აღმოჩნდება, რომ კიდევ დიდი განსხვავებები ავტომატური განსხვავებაში არ განსხვავებენ ადამიანის რეტენტირებში, განსხვავებაში, საშუალოდ განსხვავებაში არ განსხვავებენ,', 'it': "L'inferenza del linguaggio naturale (NLI) richiede modelli per imparare e applicare conoscenze di senso comune. Queste capacità di ragionamento sono particolarmente importanti per i sistemi NLI spiegabili che generano una spiegazione del linguaggio naturale in aggiunta alla loro previsione dell'etichetta. L'integrazione delle conoscenze esterne ha dimostrato di migliorare i sistemi NLI, qui si studia se può anche migliorare le loro capacità di spiegazione. Per questo, esaminiamo diverse fonti di conoscenza esterna e valutiamo le prestazioni dei nostri modelli su dati in-domain e su set di dati speciali di trasferimento progettati per valutare capacità di ragionamento a grana fine. Troviamo che diverse fonti di conoscenza hanno un effetto diverso sulle capacità di ragionamento, ad esempio, le conoscenze implicite memorizzate nei modelli linguistici possono ostacolare il ragionamento su numeri e negazioni. Infine, conduciamo lo studio di crowdsourcing NLI più ampio e spiegabile fino ad oggi. Essa rivela che anche le grandi differenze nei punteggi delle prestazioni automatiche non riflettono nelle valutazioni umane di etichetta, spiegazione, senso comune o correttezza grammaticale.", 'lt': 'Natural language inference (NLI) requires models to learn and apply commonsense knowledge.  Šie pagrįstieji gebėjimai ypač svarbūs aiškioms NLI sistemoms, kurios, be etiketės prognozės, sukuria natūralų kalbos paaiškinimą. Įrodyta, kad išorės žinių integracija pagerina NLI sistemas, čia mes tiriame, ar ji taip pat gali pagerinti jų paaiškinimo gebėjimus. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities.  Nustatome, kad skirtingi žinių šaltiniai turi skirtingą poveikį pagrįstiesiems gebėjimams, pavyzdžiui, netiesioginės kalbų modeliuose saugomos žinios gali trukdyti pagrįsti skaičių ir neigiamus gebėjimus. Galiausiai iki šiol atliekame didžiausią ir geriausiai paaiškinamą NLI visuomenės išteklių tyrimą. Iš jo matyti, kad net dideli automatinių veikimo rezultatų skirtumai neatspindi nei žmogaus etiketės, paaiškinimo, bendro pobūdžio, nei gramatinio tikslumo vertinimų.', 'kk': 'Табиғлық тіл инференциясы (NLI) үлгілерін үйрену және көпшілік мәліметтерді қолдану үшін керек. Бұл сезімдік мүмкіндіктері өзінің белгілерін таңдау үшін түсініктіретін NLI жүйелері үшін өте маңызды. Сыртқы білімдердің интеграциясы NLI жүйелерін жақсарту үшін көрсетілді. Бұл жерде біз оның түсіндіру мүмкіндіктерін де жақсартуға болады. Бұл үшін біз сыртқы білім көзін зерттеп, домен деректерінің үлгілеріміздің және арнайы аудару деректер жиындарын оқу үшін құрылған. Мысалы, тіл үлгілерінде сақталған мәліметтердің түрлі мәліметтерінің басқа нәтижелері сандар мен негативтер үшін тұратын мәліметтердің әртүрлі нәтижелері бар. Соңында, біз NLI көпшілік көпшіліктерінің ең үлкен және ең жақсы түсінікті зерттеуді жасадық. Бұл автоматты істеу нәтижесінің үлкен түрлері адамдардың белгілері, түсініктемелері, көпшілікті және грамматикалық дұрыстығын көрсетпейді.', 'mk': 'Природната инференција на јазикот (NLI) бара модели за учење и примена на заедничко знаење. Овие размислувачки способности се особено важни за објаснливите системи на НЛИ кои генерираат природно објаснување на јазикот покрај нивните предвидувања на етикетата. Интеграцијата на надворешното знаење покажа дека ќе ги подобри системите на НЛИ, тука истражуваме дали тоа може, исто така, да ги подобри нивните објаснувачки способности. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities.  Најдовме дека различните извори на знаење имаат различен ефект на размислувачките способности, на пример, имплицитното знаење складирано во јазичките модели може да го попречи размислувањето на броевите и негативите. Конечно, досега ја спроведуваме најголемата и најубавата објаснлива студија на НЛИ за пулсорсирање. Истата открива дека дури и големите разлики во автоматските резултати не одразуваат ниту во човечките рејтинзи на етикетата, објаснувањето, заедничката ниту граматичната коректност.', 'ms': 'Keputusan bahasa semulajadi (NLI) memerlukan model untuk belajar dan melaksanakan pengetahuan umum. These reasoning abilities are particularly important for explainable NLI systems that generate a natural language explanation in addition to their label prediction.  Penyempurnaan pengetahuan luaran telah menunjukkan untuk meningkatkan sistem NLI, di sini kita menyelidiki sama ada ia juga boleh meningkatkan kemampuan penjelasan mereka. Untuk ini, kami menyelidiki sumber-sumber pengetahuan luaran yang berbeza dan mengevaluasi prestasi model kami pada data dalam domain serta pada set data pemindahan khas yang direka untuk mengevaluasi kemampuan pemakaian yang sempurna. Kami mendapati bahawa sumber pengetahuan berbeza mempunyai kesan yang berbeza pada kemampuan reasoning, misalnya, pengetahuan implicit yang disimpan dalam model bahasa boleh menghalang reasoning pada nombor dan negatif. Akhirnya, kami melakukan penelitian crowdsourcing NLI yang paling besar dan paling baik yang boleh dijelaskan sehingga kini. Ia mengungkapkan bahawa walaupun perbezaan besar dalam skor prestasi automatik tidak mencerminkan dalam nilai manusia label, penjelasan, umum atau kebijaksanaan grammar.', 'ml': 'സ്വാഭാവികമായ ഭാഷ അപരിഹാരം ആവശ്യപ്പെടുന്നു. കമോണ്\u200dസണ്\u200dസെന്\u200dസ് അറിവ് പഠിക്കുകയും പ്രയോഗിക്കുകയും ചെയ്യാ ഈ കാരണങ്ങളുടെ കഴിവുകള്\u200d വ്യക്തമാക്കാന്\u200d കഴിയുന്ന NLI സിസ്റ്റമുകള്\u200dക്ക് പ്രധാനപ്പെട്ടതാണ്. അവയുടെ ലേബിള്\u200d പ്രവചനങ്ങള്\u200dക് പുറത്തുള്ള അറിവുകളുടെ കൂട്ടത്തില്\u200d NLI സിസ്റ്റം മെച്ചപ്പെടുത്തുന്നതിനായി കാണിച്ചിരിക്കുന്നു. ഇവിടെ നമ്മള്\u200d അന് ഇതിനുവേണ്ടി ഞങ്ങള്\u200d പുറത്തുള്ള അറിവുകളുടെ വ്യത്യസ്ത സ്രോതസ്സുകള്\u200d അന്വേഷിക്കുകയും, നമ്മുടെ മോഡലുകളുടെ പ്രഭാവം ഡോമെയിന്\u200d ഡേറ്റാകളുടെ പ്രഭാവം വി വ്യത്യസ്ത അറിവുകളുടെ സ്രോതസ്സുകള്\u200dക്ക് വ്യത്യസ്ത പ്രഭാവം ഉണ്ടെന്ന് ഞങ്ങള്\u200d കണ്ടെത്തുന്നു. ഉദാഹരണത്തിനായി ഭാഷ മോഡലില്\u200d സൂക്ഷ അവസാനം, നമ്മള്\u200d ഏറ്റവും വലിയ കിട്ടിയിട്ടുള്ള ഏറ്റവും സുന്ദരിയായിട്ടുള്ള ഏറ്റവും നല്ല കാര്യങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന സ്വയം പ്രവര്\u200dത്തിപ്പിക്കുന്ന സ്കോര്\u200dസില്\u200d വലിയ വ്യത്യാസങ്ങള്\u200d പോലും മനുഷ്യരുടെ ലേബ്ലെറ്റിന്\u200dറെയും വിശദീകരണങ്ങള്\u200d, കമോണ്\u200dസണ', 'mt': 'L-inferenza lingwistika naturali (NLI) teħtieġ mudelli biex jitgħallmu u japplikaw għarfien komuni. Dawn l-abbiltajiet ta’ raġunament huma partikolarment importanti għal sistemi NLI li jistgħu jiġu spjegati li jiġġeneraw spjegazzjoni tal-lingwa naturali minbarra t-tbassir tat-tikketta tagħhom. Intwera li l-integrazzjoni tal-għarfien estern ittejjeb is-sistemi NLI, hawnhekk ninvestigaw jekk tistax ittejjeb ukoll il-kapaċitajiet ta’ spjegazzjoni tagħhom. Għal dan, ninvestigaw sorsi differenti ta’ għarfien estern u ninvestigaw il-prestazzjoni tal-mudelli tagħna fuq id-dejta fid-dominju kif ukoll fuq settijiet ta’ dejta speċjali ta’ trasferiment li huma mfassla biex jivvalutaw il-kapaċitajiet ta’ raġunament imfassla fin. Issibu li sorsi differenti ta’ għarfien għandhom effett differenti fuq il-ħiliet ta’ raġunament, pereżempju, għarfien impliċitu maħżun fil-mudelli lingwistiċi jista’ jfixkel ir-raġunament fuq in-numri u n-negazzjonijiet. Fl-aħħar nett, sal-lum qed nagħmlu l-akbar u l-aktar studju spjegabbli tal-crowdsourcing NLI. Jiżvela li anki differenzi kbar fil-punteġġi awtomatiċi tal-prestazzjoni la jirriflettu fil-klassifikazzjonijiet umani tat-tikketta, l-ispjegazzjoni, il-kunsens komuni u lanqas il-korrettezza grammarja.', 'mn': 'Байгалийн хэл халдвар (NLI) нь ерөнхий мэдрэмжтэй мэдлэг сурах, ашиглах загваруудыг шаарддаг. Эдгээр ойлголтын чадварууд нь ихэвчлэн хамгийн чухал NLI системүүдэд байгалийн хэл тодорхойлолт бий болгодог. Гадаан мэдлэгийн нэгтгэл нь NLI системийг сайжруулахын тулд харагдсан. Энд бид түүний тайлбарлалтын чадварыг сайжруулж чадах эсэхийг судалж байна. Үүний тулд бид гадаад мэдлэгийн өөр өөр эх үүсвэрүүдийг судалж, дотоод өгөгдлийн загварын үйл ажиллагааг үнэлэх боломжтой. Мөн өөр өөр шилжүүлэлтийн өгөгдлийн сангуудыг үнэлэх зорилготой. Бид өөр өөр мэдлэгийн эх үүсвэрүүд нь ойлголтын чадвар дээр өөр нөлөөтэй, жишээ нь хэл загваруудад хадгалагдсан үндсэн мэдлэг нь тоо болон сөрөг талаар бодохыг зогсоож чадна. Эцэст нь бид НЛИ-ын олон нийтийн хүмүүсийн асуудлын судалгааг хүртэл хамгийн том, хамгийн сайхан тарианы судалгаа хийсэн. Энэ нь автоматик үйлдвэрлэлийн оноо дээр маш их ялгаа ч хүн төрөлхтний загвар, тодорхойлолт, ерөнхий ойлголт, грамматик зөв байдлыг харуулж чадахгүй.', 'no': 'Naturspråk-infeksjon (NLI) krev modeller for å læra og bruka vanleg kunnskap. Desse grunnleggjande kapasitetene er spesielt viktige for forklarbare NLI-systemer som lagar eit naturleg språk-forklaring i tillegg til merkelappen sin forhåndsvising. Integreringen av eksterne kunnskap er vist for å forbetra NLI-systemet. Her er vi undersøk om det også kan forbetra utklaringskapasiteten sine. For dette, vi undersøker ulike kjelde for eksterne kunnskap og evaluerer utviklinga av våre modeller på interne domenedata, og på spesielle overføringsdata som er utforma for å vurdere fin-kornerte redensingskapasiteten. Vi finn at forskjellige kjelde av kunnskap har ein annan effekt på rasjonskobilitetar, for eksempel, implisitt kunnskap lagra i språk-modeller kan hindra rasjon på tall og negasjon. Etter slutt, vi gjer den største og mest fyrste forklarbare NLI crowdsourcing studien til dag. Det viser at sjølv store forskjeller i automatiske funksjonspoeng ikkje reflekterer i menneskelige retningar av etikett, forklaring, fellesskap eller gramatisk rettighet.', 'pl': 'Inferencja języka naturalnego (NLI) wymaga modeli do nauki i stosowania wiedzy zdrowego rozsądku. Te zdolności rozumowania są szczególnie ważne dla wyjaśnionych systemów NLI, które generują wyjaśnienie języka naturalnego oprócz przewidywania etykiety. Wykazano, że integracja wiedzy zewnętrznej poprawia systemy NLI, tutaj badamy, czy może ona również poprawić ich możliwości wyjaśniania. W tym celu badamy różne źródła wiedzy zewnętrznej i oceniamy wydajność naszych modeli na danych wewnątrz domeny, jak również na specjalnych zbiorach danych transferowych, które mają na celu ocenę możliwości precyzyjnego rozumowania. Odkrywamy, że różne źródła wiedzy mają różny wpływ na zdolności rozumowania, na przykład wiedza domniemana przechowywana w modelach językowych może utrudniać rozumowanie liczb i negacji. Wreszcie prowadzimy do tej pory największe i najbardziej precyzyjne badanie crowdsourcingu NLI. Ujawnia ona, że nawet duże różnice w automatycznych wynikach wydajności nie odzwierciedlają ludzkiej oceny etykiety, wyjaśnienia, zdrowego rozsądku czy poprawności gramatycznej.', 'sr': 'Prirodna jezička infekcija (NLI) zahteva modele za naučenje i primjenu znanja zajedničkog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sisteme koje stvaraju prirodno objašnjenje jezika u dodatnom predviđanju etiketa. Integracija vanjskih znanja je pokazala kako bi poboljšala NLI sisteme, ovde istražujemo da li može i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskog znanja i procjenjujemo učinkovitost naših modela na podacima u domenu, kao i na specijalne sete podataka koji su dizajnirani za procjenu kvalitetnih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različit uticaj na razumne sposobnosti, na primer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razumljivanje na brojeve i negacije. Konačno, provedem najveću i najbolje objašnjavajuću studiju NLI za crowdsourcing do sada. To otkriva da čak i velike razlike u automatskim rezultatima uspeha ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, čestitosti niti gramatičke ispravnosti.', 'ro': 'Inferența limbajului natural (NLI) necesită modele pentru a învăța și aplica cunoștințele de bun simț. Aceste abilități de raționament sunt deosebit de importante pentru sistemele NLI explicabile care generează o explicație de limbaj natural în plus față de predicția etichetei lor. Integrarea cunoștințelor externe a demonstrat că îmbunătățește sistemele NLI, aici investigăm dacă poate îmbunătăți și capacitățile lor de explicare. În acest scop, investigăm diferite surse de cunoștințe externe și evaluăm performanța modelelor noastre pe date în domeniu, precum și pe seturi de date speciale de transfer, concepute pentru a evalua capacitățile de raționament fină. Considerăm că diferitele surse de cunoaștere au un efect diferit asupra abilităților de raționament, de exemplu, cunoștințele implicite stocate în modele lingvistice pot împiedica raționamentul asupra numerelor și negațiilor. În cele din urmă, efectuăm cel mai mare și cel mai fin studiu de crowdsourcing explicabil NLI până în prezent. Aceasta dezvăluie că chiar și diferențele mari în scorurile automate de performanță nu reflectă în evaluările umane de etichetă, explicație, sens comun sau corectitudine gramaticală.', 'si': 'ස්වභාවික භාෂාව ප්\u200dරමාණය (NLI) අවශ්\u200dය වෙනවා සාමාන්\u200dය භාෂාවික දැනගන්න සහ අවශ්\u200dය වෙන් මේ හේතුවක් ප්\u200dරශ්නයක් විශේෂයෙන් වැදගත් NLI පද්ධතියක් විස්තර කරන්න පුළුවන් විදිහට වැදගත් වෙනවා ඔවුන් පුරුද්ගලික දන්නවගේ සම්බන්ධයක් පෙන්වන්න පුළුවන් NLI පද්ධතිය වැඩ කරන්න, මෙතන අපි පරීක්ෂණය කරන්න පුළුවන් ක මේක සඳහා අපි ප්\u200dරතිශේෂ විවිධ දැනයේ වෙනස් ප්\u200dරතිශ්නයක් පරීක්ෂා කරනවා සහ අපේ මොඩේල්ස් ගැන ප්\u200dරතිශේෂ දත්ත සඳහා විශේෂ සං අපිට හොයාගන්න පුළුවන් වෙනස් දැනගන්න ප්\u200dරශ්නයක් තියෙනවා කියලා, උදාහරණයෙන්, භාෂා මොඩල් වල සංකේතයෙන් තියෙන අ අන්තිමේදි, අපි ලොකුම සහ හොඳම ප්\u200dරශ්නයක් කරනවා නිලි ජාතික විස්තර කරන්න පුළුවන් ප්\u200dරශ්නයක් තියෙන ඒක ප්\u200dරකාශ කරන්නේ ස්වයංක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක වෙනස් වගේම මිනිස්සුන්ගේ රේටින්ස් වලින් ප්\u200dරතිකා', 'so': 'Cudurka afka asalka ah (NLI) wuxuu u baahan yahay qaabab barashada iyo codsashada aqoonta shirkadda. Aqooyinkan sababta ah si gaar ah waa muhiim u ah nidaamka NLI ee aan la caddeyn karin, taas oo soo saara fasirada afka dabiicadda ah, iyadoo aan laguu sii sheegin calaamada. La-qabsashada aqoonta dibadda waxaa lagu muujiyey in la kordhiyo nidaamka NLI, halkan waxaynu baaraynaa inay kordhin karto awoodooda turjumista. Taas darteed waxaynu baaraynaa noocyo kala duduwan aqoonta dibadda ah iyo waxaynu qiimeynaynaa sameynta sameynta modellka macluumaadka gudaha iyo sawirada macluumaadka gaarka ah oo loo qoray si aan u qiimeyno awoodaha garashada. Waxaynu aragnaa in noocyada aqoonta kala duduwan ay saameyn u leeyihiin waxyaabo kala duduwan, tusaale ahaan aqoonta ku saabsan noocyada luuqada lagu kaydiyey waxay ka hor mari karaan arrimaha ku saabsan lambarada iyo waxyaabaha la naco. Ugu dambaysta, waxaynu sameynaa waxbarashada kooxaha dadka NLI ee ugu waaweyn ee ugu fiican. Waxay muuqataa in xittaa kala duwanaanshaha badan oo ay iskuulaadka farsamada iskuulka ah ku jiraan kuma fikiraan qiyaastii dadka, fasax, faqan ama hagaajinta qofka.', 'ur': 'طبیعی زبان ایفارنس (NLI) کی مدل کی ضرورت ہے کہ معمولی علم کی تعلیم اور استعمال کریں۔ یہ منطقی قابلیت ان کے لیبل پیش بینی کے علاوہ ایک طبیعی زبان کی توضیح پیدا کرتی ہیں۔ بیرونی علم کی تعلیم NLI سیستموں کو بہتر کرنے کے لئے دکھائی گئی ہے، یہاں ہم تحقیق کرتے ہیں کہ یہ ان کی توضیح کے قابلیت بھی بہتر کر سکتا ہے. اس کے لئے ہم باہر علم کے مختلف سراسروں کی تحقیق کرتے ہیں اور ہمارے مدلکوں کے عملکرد کو دامین میں ڈیٹے پر مطالعہ کرتے ہیں اور ویسی ترنسیٹ ڈیٹ سٹ پر بھی مطالعہ کئے جاتے ہیں جو مطالعہ اندازے کے قابلیت کی آزمائش کے لئے طراحی ک ہمیں معلوم ہے کہ علم کے مختلف سرمالوں کے باعث منطقی قابلیت پر مختلف اثر ہے، مثال، زبان مدلکوں میں ذخیره ہوئی معلومات کی تعداد اور منطقی کے باعث منطقی کرسکتی ہے. آخر میں ہم نے سب سے بڑے اور بہترین دانے کا مفصل کر لیا ہے۔ یہ ظاہر کرتا ہے کہ اٹوٹیٹ کروٹ سکونٹوں میں بھی بہت بڑی اختلاف بھی نہیں کرتی لیبل، توضیح، معمولی اور گرامی اصلاح میں.', 'sv': 'Naturligt språk inferens (NLI) kräver modeller för att lära sig och tillämpa allmännyttig kunskap. Dessa resonemang förmågor är särskilt viktiga för förklaringsbara NLI-system som genererar en naturlig språkförklaring utöver deras etikettprediktion. Integrationen av extern kunskap har visat sig förbättra NLI-system, här undersöker vi om det också kan förbättra deras förklaringsförmåga. För detta undersöker vi olika källor till extern kunskap och utvärderar prestandan hos våra modeller på domändata samt på speciella överföringsdatauppsättningar som är utformade för att bedöma finkorniga resonemang. Vi finner att olika kunskapskällor har en annan effekt på resonemang förmågor, till exempel implicit kunskap lagrad i språkmodeller kan hindra resonemang om siffror och negationer. Slutligen genomför vi den största och mest finkorniga förklaringsbara NLI crowdsourcingsstudien hittills. Det avslöjar att även stora skillnader i automatiska prestationspoäng varken återspeglar mänskliga bedömningar av etikett, förklaring, allmänst eller grammatik korrekthet.', 'ta': 'இயல்பான மொழி குறைவு (NLI) தொழில்நுட்ப அறிவை கற்று பயன்படுத்த மாதிரிகள் தேவைப்படுகிறது. இந்த காரணங்கள் விளக்கமுடியாத NLI அமைப்புகளுக்கு குறிப்பாக முக்கியமானது. அது ஒரு இயல்பான மொழி விளக்கம் உருவாக்குகிறது  வெளி அறிவின் ஒன்றிணைப்பு NLI முறைமைகளை மேம்படுத்துவதற்கு காண்பிக்கப்பட்டுள்ளது, இது அவர்களுடைய விளக்கங்களின் இயல்புகளை  இதுக்கு, நாம் வெளி அறிவின் மூலங்களை ஆராய்ச்சி மற்றும் எங்கள் மாதிரிகளின் செயல்பாட்டை கண்டறிக்கிறோம் மற்றும் சிறப்பு மாற்றும் தகவல் அமைப்புகளில மொழி மாதிரிகளில் சேமிக்கப்பட்ட அறிவு மூலம் எண்கள் மற்றும் எதிர்மங்கள் பற்றி குறித்துக் கொள்ள வேறு விளைவுகள் இருக்கும் என்பதை நா இறுதியில், நாங்கள் பெரிய மற்றும் மிகவும் நல்ல பிரச்சனையான NLI மக்கள் மூல வளைவு பட்டியலை நடத்துகிறோம். அது தானியங்கி செய்யும் புள்ளிகளில் பெரிய வேறுபாடுகளுக்கு கூட தெளிவுபடுத்துகிறது விளக்கத்தின் விளக்கங்கள், விளக்கம', 'uz': "Natalik til infeksiyati (NLI) modellarni o'rganish va qoʻllash uchun kerak. Bu sabablar qobiliyatlari ularning yorliq oldini oldinga oddiy tilning forklarini yaratadigan NLI tizimlariga muhim. Tashqi ta'limning birlashtirish NLI tizimlarini yaxshi ko'rsatadi. Bu yerda biz ularning fikrlarining imkoniyatlarini bajarishi mumkin deb o'rganamiz. Bu uchun, biz tashqi ta'limning boshqa manbalarini qidirib, domen maʼlumotidagi modellarimizning natijasini qiymatimiz, va xavfsiz tarkib maʼlumotlar tarkibida o'zgartirish qoidalarini qidirish uchun qo'llanmalar mumkin. Biz o'ylaymiz, boshqa ta'lim manbaslari haqida ma'lumotga ega bo'ladi. Masalan, tildagi modellarda saqlangan ilmo'zi sonlar va negativ haqida g'oyalarni o'zgartiradi. Endi biz hozirda eng katta va eng yaxshi ajoyib bo'lgan NLI jamoatlarni o'rganamiz. U avtomatik foydalanuvchi darajadagi katta ўзгаришларни ko'rsatadi, odamning qismlarini, faqat fasirlash, murakkab va grammatik toʻgʻri haqida o'ylamaydi.", 'vi': 'Kết quả ngôn ngữ tự nhiên (NLI) đòi hỏi các mẫu học hỏi và áp dụng các kiến thức thông thường. Những khả năng lập luận này rất quan trọng với hệ thống NIL có thể giải thích ngôn ngữ tự nhiên, cùng với dự đoán nhãn hiệu của chúng. Sự hợp nhất của kiến thức bên ngoài đã được cho thấy nhằm cải thiện hệ thống NIL, tại đây chúng tôi đang tìm hiểu liệu nó có thể cải thiện khả năng giải thích của chúng. Chúng tôi nghiên cứu các nguồn kiến thức bên ngoài khác nhau và đánh giá khả năng làm việc của các mẫu trên dữ liệu nội bộ, cũng như các tập tin giao dịch đặc biệt được thiết kế để đánh giá các khả năng lập luận ổn định. Chúng tôi thấy những nguồn kiến thức khác nhau có ảnh hưởng khác nhau đến khả năng lập luận, ví dụ, kiến thức ngầm được cất giữ trong mô hình ngôn ngữ có thể gây trở ngại việc lập luận về con số và âm bản. Cuối cùng, chúng tôi tiến hành nghiên cứu tài nguyên cao nhất và được giải thích cao nhất. Nó tiết lộ rằng thậm chí sự khác nhau lớn trong tỉ số hiệu suất tự động cũng không phản ánh các đánh giá của nhân loại về nhãn hiệu, cách giải thích, lẽ thường hay sửa ngữ pháp.', 'bg': 'Природните езикови изводи (НЛИ) изискват модели за учене и прилагане на разумни знания. Тези способности за разсъждаване са особено важни за обясними системи, които генерират естествено езиково обяснение в допълнение към прогнозирането на етикета. Доказано е, че интегрирането на външни знания подобрява системите на НЛИ, тук изследваме дали може да подобри и техните обяснителни възможности. За тази цел ние изследваме различни източници на външни знания и оценяваме ефективността на нашите модели върху вътрешни данни, както и върху специални набори от данни за трансфер, които са предназначени да оценят фините възможности за разсъждаване. Откриваме, че различните източници на знания имат различен ефект върху способностите за разсъждаване, например имплицитното знание, съхранявано в езиковите модели, може да възпрепятства разсъждаването на числа и отрицания. И накрая, ние провеждаме най-голямото и най-фино обяснимо проучване на НЛИ crowdsourcing досега. Тя разкрива, че дори големите разлики в автоматичните резултати не отразяват нито в оценките на етикета, обяснението, благоразумието, нито граматическата коректност.', 'nl': 'Natural language inference (NLI) vereist modellen om gezond verstand te leren en toe te passen. Deze redeneringsvaardigheden zijn vooral belangrijk voor uitlegbare NLI-systemen die naast hun labelvoorspelling ook een natuurlijke taalverklaring genereren. De integratie van externe kennis is aangetoond om NLI-systemen te verbeteren, hier onderzoeken we of het ook hun verklaringsmogelijkheden kan verbeteren. Hiervoor onderzoeken we verschillende bronnen van externe kennis en evalueren we de prestaties van onze modellen op in-domain data en op speciale transfer datasets die zijn ontworpen om fijngranige redeneermogelijkheden te beoordelen. We vinden dat verschillende bronnen van kennis een ander effect hebben op redeneringsvermogen, bijvoorbeeld impliciete kennis opgeslagen in taalmodellen kan redeneren over getallen en ontkenningen belemmeren. Tot slot voeren we de grootste en meest fijngranige uitlegbare NLI crowdsourcing studie uit tot nu toe. Het toont aan dat zelfs grote verschillen in automatische prestatiescores geen weerspiegeling zijn in menselijke beoordelingen van label, uitleg, gezond verstand of grammatica correctheid.', 'de': 'Natural Language Inference (NLI) erfordert Modelle, um gesundes Wissen zu lernen und anzuwenden. Diese Argumentationsfﾃ､higkeiten sind besonders wichtig fﾃｼr erklﾃ､rbare NLI-Systeme, die zusﾃ､tzlich zu ihrer Label-Vorhersage eine natﾃｼrliche Spracherklﾃ､rung generieren. Die Integration von externem Wissen hat gezeigt, dass NLI-Systeme verbessert werden, hier untersuchen wir, ob es auch deren Erklﾃ､rungsfﾃ､higkeit verbessern kann. Dazu untersuchen wir verschiedene Quellen externer Erkenntnisse und bewerten die Performance unserer Modelle sowohl auf In-Domain-Daten als auch auf speziellen Transferdatensﾃ､tzen, die zur Beurteilung feingranularer Denkfﾃ､higkeiten konzipiert sind. Wir stellen fest, dass unterschiedliche Wissensquellen unterschiedliche Auswirkungen auf die Denkfﾃ､higkeit haben. Beispielsweise kann implizites Wissen, das in Sprachmodellen gespeichert ist, das Argumentieren von Zahlen und Negationen behindern. Schlieﾃ殕ich fﾃｼhren wir die bisher grﾃｶﾃ殳e und feinkﾃｶrnigste erklﾃ､rbare NLI Crowdsourcing-Studie durch. Es zeigt sich, dass sich selbst groﾃ歹 Unterschiede in den automatischen Leistungswerten weder in der menschlichen Bewertung von Label, Erklﾃ､rung, gesundem Menschenverstand noch grammatikalischer Korrektheit widerspiegeln.', 'da': 'Naturligt sprog inference (NLI) kræver modeller til at lære og anvende almindelig viden. Disse ræsonnement evner er særligt vigtige for forklarelige NLI-systemer, der genererer en naturlig sprogforklaring ud over deres etiket forudsigelse. Integrationen af ekstern viden har vist sig at forbedre NLI systemer, her undersøger vi, om det også kan forbedre deres forklaringsmuligheder. Til dette undersøger vi forskellige kilder til ekstern viden og evaluerer ydeevnen af vores modeller på domænedata såvel som på særlige overførselsdatasæt, der er designet til at vurdere finkornede ræsonnementsfunktioner. Vi finder ud af, at forskellige kilder til viden har en anden effekt på ræsonnement evner, for eksempel kan implicit viden lagret i sprogmodeller hindre ræsonnement om tal og negationer. Endelig gennemfører vi den største og mest finkornede forklarelige NLI crowdsourcing undersøgelse hidtil. Det afslører, at selv store forskelle i automatiske resultater hverken afspejler i menneskelige vurderinger af etiket, forklaring, almindelighed eller grammatik korrekthed.', 'hr': 'Prirodna infekcija jezika (NLI) zahtijeva modele za naučenje i primjenu znanja običnog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sustave koji stvaraju prirodno objašnjenje jezika u dodatnoj predviđanju etiketa. Integracija vanjskih znanja pokazala je kako bi poboljšala NLI sustave, ovdje istražujemo može li i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskih znanja i procjenjujemo učinkovitost naših modela na podacima u domenu, kao i na specijalne prijenosne podatke koje su dizajnirane za procjenu potpunih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različit učinak na razumne sposobnosti, na primjer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razumjevanje brojeva i negacija. Konačno ćemo provesti najveću i najbolje objašnjavajuću studiju NLI crowdsourcing do sada. Otkriva se da čak i velike razlike u automatskim rezultatima učinka ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, češće smisla niti ispravnosti gramatike.', 'fa': 'آلودگی زبان طبیعی (NLI) نیاز به مدل\u200cهای یادگیری و استفاده از دانش معمولی است. این توانایی منطقی برای سیستم های NLI قابل توضیح و توضیح زبان طبیعی در addition to their label prediction مهم است. جمع علم خارجی نشون داده شده تا سیستم\u200cهای NLI را بهتر کند، اینجا تحقیق کنیم که آیا می\u200cتواند توانایی توضیح\u200cشان را بهتر کند. برای این، ما منبع های مختلف دانش خارجی را تحقیق می کنیم و عملکرد مدل های ما را در اطلاعات دامنی\u200cهای خاص و در مجموعه\u200cهای انتقال داده\u200cهای خاصی که طراحی شده\u200cاند برای ارزیابی توانایی\u200cهای منطقی\u200cکننده\u200cهای پاکیزه\u200cی دانه\u200cهای خارجی ارزی ما متوجه شدیم که منابع مختلف علم تأثیر متفاوتی بر توانایی منطقی دارند، برای مثال، دانش معمولی که در مدلهای زبانی ذخیره شده است، می تواند منطقی در شماره و منطقی را متوقف کند. بالاخره، ما بزرگترین و بهترین دانه\u200cهای توضیح قابل توضیح عمومی NLI را تا حالا انجام می\u200cدهیم. این نشان می دهد که حتی تفاوت های بزرگ در امتیاز عملکرد خودکار در امتیاز های نقاشی، توضیح، معمولی و درستی نقاشی انسان تفکیر نمی کنند.', 'id': 'Keputusan bahasa alam (NLI) membutuhkan model untuk belajar dan menerapkan pengetahuan umum. Kemampuan alasan ini sangat penting untuk sistem NLI yang dapat dijelaskan yang menghasilkan penjelasan bahasa alami selain prediksi label mereka. Integrasi pengetahuan luar telah menunjukkan untuk meningkatkan sistem NLI, di sini kita menyelidiki apakah itu juga dapat meningkatkan kemampuan penjelasan mereka. Untuk ini, kami menyelidiki sumber-sumber pengetahuan luar yang berbeda dan mengevaluasi prestasi model kami pada data dalam domain serta pada set data transfer khusus yang direncanakan untuk mengevaluasi kemampuan pemikiran yang baik. Kami menemukan bahwa sumber pengetahuan yang berbeda memiliki efek yang berbeda pada kemampuan reasoning, misalnya, pengetahuan implicit yang disimpan dalam model bahasa dapat menghalangi reasoning pada angka dan negati. Akhirnya, kami melakukan penelitian crowdsourcing NLI yang paling besar dan paling bagus yang bisa dijelaskan sampai saat ini. Hal ini mengungkapkan bahkan perbedaan besar dalam skor prestasi otomatis tidak merefleksikan dalam nilai manusia label, penjelasan, umum atau persis grammar.', 'sw': 'Upunguzo wa lugha ya asili (NLI) unahitaji mifano ya kujifunza na kutumia maarifa ya umma. Tamko hizi zinazoelezea ni muhimu kwa mfumo wa NLI unaotengeneza maelezo ya lugha asili zaidi ya utabiri wao wa alama. Ushirikiano wa maarifa ya nje umeonyesha kuboresha mifumo ya NLI, hapa tunachunguza kama inaweza pia kuboresha uwezo wa maelezo yao. Kwa hili, tunachunguza vyanzo tofauti vya ufahamu wa nje na kutathmini ufanisi wa mifano yetu kwenye data za ndani pamoja na kwenye seti maalum za usafirishaji ambazo zinalengwa kutathmini uwezo wa kufikiriwa vizuri. Tunapata kwamba vyanzo tofauti vya maarifa vina athari tofauti juu ya uwezo wa kuzingatia, kwa mfano, maarifa yaliyohifadhiwa katika mifano ya lugha yanaweza kuzuia mawazo kuhusu idadi na hasi. Mwisho, tunafanya utafiti mkubwa zaidi na wenye ufafanuzi mkubwa zaidi wa vyama vya habari vya NLI mpaka sasa. Inaonyesha kwamba hata tofauti kubwa katika vipimo vya utendaji vya kujitegemea hazitafakari katika viwango vya kibinadamu vya alama, maelezo, makubaliano wala sahihi.', 'ko': '자연 언어 추리(NLI)는 상식 지식을 모형 학습하고 응용해야 한다.이러한 추리력은 해석 가능한 NLI 시스템에 특히 중요하다. 이런 시스템은 라벨 예측 외에 자연 언어 해석도 생성한다.외부 지식의 통합이 NLI 시스템을 개선할 수 있다는 것이 증명되었는데, 여기서 우리는 그것이 그들의 해석 능력을 향상시킬 수 있는지를 연구한다.이를 위해 우리는 외부 지식의 서로 다른 출처를 조사하고 우리의 모델이 역내 데이터와 세립도 추리 능력을 평가하는 특수 전송 데이터 집합의 성능을 평가했다.우리는 서로 다른 지식의 출처가 추리 능력에 서로 다른 영향을 미친다는 것을 발견했다. 예를 들어 언어 모델에 저장된 숨은 지식은 숫자와 부정에 대한 추리를 방해할 수 있다.마지막으로 우리는 지금까지 규모가 가장 크고 입도가 가장 가는 NLI 클러스터 연구를 진행했다.연구에 따르면 자동 성적의 큰 차이도 라벨, 해석, 상식과 문법의 정확성에 대한 인류의 평점에 반영되지 않는다.', 'tr': 'Tebiýal dil azalyşyk (NLI) duýdury bilgi öwrenmek we uygulamak üçin nusgalary gerek. Bu razylyk başaryşlary etiket öňünden boşluşyk bilen tebigy dili düşündirjek NLI sistemalary üçin has möhüm. Daşarydaky bilim üýtgetmegi NLI sistemalaryny geliştirmek üçin görkezildi. Şu ýerde biz munuň olaryň düşündirişi başarylygyny geliştirmegi mümkin edýändigini soradyk. Bu üçin biz daşarydaky bilim sistemleriniň farklı çeşmelerini inceleýäris we domençe maglumatlarymyzda modellerimiziň eserini deňleýäris we gowy gabat etmek üçin tasarlanýan aýratyn transfers veri setirlerini deňleýäris Bilim sistemleriniň farklı kaynaklarynyň düşünüp ukyplaryna üýtgeşik bar, meselâ, dil modellerinde gaýd edilen bilim sistemleri rakamlar we bölümlerde düşünüpden çykaryp biler. Soňunda biz iň uly we iň gowy görnümli NLI köpüşiklik isleýän ylgamy ýerine ýetirdik. Muny otomatik netijesinde hatda näçe üýtgeşmeler etiket, düşündirim, jemgyýetçilik we gramatik dogrylygynda täsirleýändirler.', 'sq': 'Përfundimi natyror i gjuhës (NLI) kërkon modele për të mësuar dhe aplikuar njohuri të përbashkët. Këto aftësi arsyetimi janë veçanërisht të rëndësishme për sistemet e shpjeguara të NLI që gjenerojnë një shpjegim natyror gjuhës përveç parashikimit të etiketës së tyre. Integrimi i njohurive të jashtme është treguar për të përmirësuar sistemet NLI, këtu ne hetojmë nëse mund të përmirësojë gjithashtu aftësitë e tyre të shpjegimit. Për këtë, ne hetojmë burime të ndryshme të njohurive të jashtme dhe vlerësojmë performancën e modeleve tona në të dhënat në domeni si dhe në grupe të dhënash të posaçme transferimi që janë dizajnuar për të vlerësuar aftësitë e arsyetimit të hollësishëm. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations.  Më në fund, ne kryejmë studimin më të madh dhe më të hollë të shpjeguar të NLI crowdsourcing deri tani. Ajo zbulon se edhe dallime të mëdha në rezultatet e performancës automatike nuk pasqyrojnë as në vlerësimet njerëzore të etiketës, shpjegimit, të zakonshme as korrektësisë gramatike.', 'af': "Natuurlike taal inferensie (NLI) benodig modele om gemeenskaplike kennis te leer en toewend. Hierdie redelike moontlikhede is besonderlik belangrik vir verduidelike NLI stelsels wat 'n natuurlike taal uitduidelik genereer in addition to their label prediction. Die integrasie van eksterne kennis is vertoon om NLI stelsels te verbeter, hier ondersoek ons of dit ook hulle uitduidelingskapasiteite kan verbeter. Vir hierdie, ons ondersoek verskillende bronne van eksterne kennis en evalueer die effektiviteit van ons modele op in-domein data as ook op spesiale oordrag datastelle wat ontwerp word om fin-kornerede redekening kapasiteite te asseer. Ons vind dat verskillende bronne van kennis 'n ander effek het op redekende kapasiteite, byvoorbeeld, inplisite kennis wat in taal modele gestoor is, kan hinder redensie op getalle en negasies. Eindelik, ons doen die grootste en mees fyn-korne verduidelik NLI skakering studie tot nou. Dit openbaar dat selfs groot verskil in outomatiese prestasie punte geen reflekteer in menslike reetings van etiket, uitduidelikheid, gewoonlik of grammatiese regverdigheid.", 'hy': 'Բնական լեզվի եզրակացությունը պահանջում է մոդելներ սովորելու և կիրառելու համար ընդհանուր գիտելիքներ: Այս մտածողական հնարավորությունները հատկապես կարևոր են ՀՆԱ-ի բացատրելի համակարգերի համար, որոնք ստեղծում են բնական լեզվի բացատրություն, բացի իրենց պիտակների կանխատեսումից: Պարզվել է, որ արտաքին գիտելիքների ինտեգրացիան բարելավում է ՆԼԻ համակարգերը, այստեղ մենք ուսումնասիրում ենք, արդյոք այն կարող է նաև բարելավել իրենց բացատրական ունակությունները: Այս դեպքում մենք ուսումնասիրում ենք արտաքին գիտելիքների տարբեր աղբյուրներ և գնահատում ենք մեր մոդելների արտադրողականությունը բնագավառի տվյալների, ինչպես նաև հատուկ տեղափոխման տվյալների համակարգերի վրա, որոնք նախագծված են նրբագեղ մտածողականության հ Մենք հայտնաբերում ենք, որ տարբեր գիտելիքների աղբյուրները տարբեր ազդեցություններ ունեն մտածողական ունակությունների վրա, օրինակ, լեզվի մոդելներում պահպանված ենթարկված գիտելիքները կարող են խոչընդոտել մտածողությունը թվերի և բացասական Վերջապես, մենք կատարում ենք մինչ այժմ ամենամեծ և ամենագեղեցիկ բացատրելի ՆԼԻ-ի ժողովրդավարման ուսումնասիրությունը: It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor grammar correctness.', 'bs': 'Prirodna infekcija jezika (NLI) zahtijeva modele za naučenje i primjenu znanja zajedničkog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sisteme koje stvaraju prirodno objašnjenje jezika u dodatnom predviđanju etiketa. Integracija vanjskih znanja pokazala je kako bi poboljšala NLI sisteme, ovdje istražujemo da li može i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskih znanja i procjenjujemo učinkovitost naših modela o podacima u domenu, kao i o specijalnim prijenosnim podacima koje su dizajnirane za procjenu kvalitetnih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različite utjecaje na razumne sposobnosti, na primjer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razgovor na brojeve i negacije. Konačno ćemo provesti najveću i najbolje objašnjavajuću studiju NLI za crowdsourcing do sada. Ono otkriva da čak i velike razlike u rezultatima automatskih učinka ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, češće smisla niti gramatske ispravnosti.', 'am': 'Natural language inference (NLI) requires models to learn and apply commonsense knowledge.  እነዚህ የሚያስተባብሉ ስልጣናት ይልቅ ለማይታወቅ የNLI ስርዓቶች ፍጥረታዊ ቋንቋን ለመፍጠር የሚችሉ ናቸው፡፡ የውጭ እውቀት ማጠናቀል NLI ስርዓቶች ማሻሻል ታይቷል፡፡ በዚህ ደግሞ መፍረጃቸውን ማሻሻል ይችላልን፡፡ ለዚህ ምክንያት የውጭ እውቀት መልዕክቶችን እናሳውቃለን እና የዶሜን ዳታዎችን እና የተመሳሳይ አእምሮዎችን ማረጋገጥ በተለየ የተለየ የዳታ መስኮት ላይ እናስተውላለን፡፡ የልዩ የእውቀት ምንጮች ለልዩ አካባቢዎች በቋንቋ ምሳሌዎች የተደብቀው እውቀት የቁጥር እና ውቀትን የሚከለክል ነው ብለን እናገኛለን፡፡ በመጨረሻም፣ ከሁሉ የበለጠ እና የበለጠ የNLI የድብፅ ጉዳይ ትምህርት እናደርጋለን፡፡ በራሱ አካባቢ ትልቅ ልውጤቶች ቢሆን በአካባቢው ስርዓት፣ ትርጓሜ፣ ትርጓሜ እና ትክክለኛ ትክክል በሚገልጽ አይመለከትም፡፡', 'az': 'Təbiətli dil infeksiyonu (NLI) öyrənmək və müxtəlif bilikləri istifadə etmək üçün modellər lazımdır. Bu müzakirə qabiliyyətlər özlərinin etiketlərinin öngörünüşünü artıran təbiətli dil a çıqlaması yaradan NLI sistemlərinə münasibdir. Dərzində bilgi integrasiyası NLI sistemlərini yaxşılaşdırmaq üçün göstərildi. Burada onların açıqlama kapasitələrini də yaxşılaşdırmaq mümkündür. Buna görə, biz dış bilgisinin müxtəlif mənbələrini incidirik və modellərimizin əməllərini domain verilənlərin və müxtəlif təkrar verilənlərin qurğularını müəyyən etmək üçün tasarlanmışdır. Biz bilirik ki, müxtəlif bilimin mənbələrinin razılıq qabiliyyətlərinə, məsələn dil modellerində qoyulan imkanlı bilgi sayılar və negasyonlar barəsində müzakirə edə bilər. Sonunda biz NLI crowdsourcing təhsil edilən ən ən böyük və ən gözəl taxıl təhsil etdik. Bu göstərir ki, otomatik performans nöqtələrində hətta böyük fərqli etiketlərin, açıq-aydınlıqların, yayınlıqların və gramatik düzgünlüklərində olmaz.', 'bn': 'স্বাভাবিক ভাষার আক্রান্ত (NLI) কমন্সেন্সের জ্ঞান শিক্ষা ও প্রয়োগ করার জন্য মডেল প্রয়োজন। এনলিআই সিস্টেমের জন্য এই কারণের ক্ষমতা বিশেষ গুরুত্বপূর্ণ যা তাদের লেবেলের ভবিষ্যতের ছাড়াও প্রাকৃতিক ভাষার ব্য এনলিআই সিস্টেম উন্নত করার জন্য বাইরের জ্ঞানের একত্রিত করা হয়েছে, এখানে আমরা তদন্ত করছি এটা তাদের ব্যাখ্যা ক্ষমতা উন্নত কিনা। এর জন্য আমরা বাইরের জ্ঞানের বিভিন্ন সূত্র তদন্ত করি এবং ডোমেইনের তথ্যে আমাদের মডেলের প্রভাবের বিষয়টি মূল্য করি এবং সাথে বিশেষ পরিবহনের তথ্যের বিষয়ে যা ভ আমরা খুঁজে পাচ্ছি যে বিভিন্ন জ্ঞানের উৎস বিভিন্ন ক্ষমতার প্রভাব রয়েছে, যেমন, ভাষার মডেলে সংরক্ষিত জ্ঞানের বিষয়টি সংরক্ষিত করা  অবশেষে, আমরা এখন পর্যন্ত সবচেয়ে বৃহত্তম এবং সবচেয়ে ভালোভাবে কাজ করি এনলি জনসোর্সিং গবেষণা। এটি প্রকাশ করে যে স্বয়ংক্রিয়ভাবে প্রদর্শনের স্কোরে বিশাল পার্থক্য তারা লেবেল, ব্যাখ্যা, কমান্সেন্স এবং গ্রামের সঠিক ম', 'ca': "La inferència de llenguatges naturals (NLI) requereix models per aprendre i aplicar coneixements comuns. Aquestes habilitats de raonament són particularment importants per a sistemes explicables de l'INN que generen una explicació natural de llenguatge a més de la seva predicció d'etiqueta. La integració del coneixement extern ha demostrat millorar els sistemes de l'INN, aquí investigam si també pot millorar les seves capacitats d'explicació. Per això, investigam diferents fonts de coneixement extern i evaluem el rendiment dels nostres models en dades internes i en conjunts de dades especials de transfer ència dissenyats per avaluar capacitats de raonament fins. Trobem que diferents fonts de coneixement tenen un efecte diferent en les habilitats de raonament, per exemple, el coneixement implícit emmagatzemat en models lingüístics pot impedir el raonament en números i negatius. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date.  revela que fins i tot les grans diferències en les puntuacions automàtiques de rendiment no reflecteixen ni en les puntuacions humanes d'etiqueta, explicació, comú ni correcció gramàtica.", 'et': 'Looduskeele järeldus (NLI) nõuab mudeleid, et õppida ja rakendada üldse mõistlikke teadmisi. Need arutlusvõimed on eriti olulised seletatavate NLI süsteemide puhul, mis loovad lisaks oma märgise prognoosile looduskeelse selgituse. Välisteadmiste integreerimine on näidanud NLI süsteemide parandamist, siin uurime, kas see võib parandada ka nende selgitusvõimet. Selleks uurime erinevaid välisteadmiste allikaid ja hindame oma mudelite jõudlust nii domeenisiseste andmete kui ka spetsiaalsete edastamisandmekogumite puhul, mis on mõeldud hindama peenete arutlusvõimeid. Leiame, et erinevatel teadmisteallikatel on erinev mõju mõtlemisvõimele, näiteks keelemudelites salvestatud kaudsed teadmised võivad takistada arvude ja negatsioonide arutlemist. Lõpuks viime läbi seni suurima ja kõige peenema selgitatava NLI ühishankimise uuringu. See näitab, et isegi suured erinevused automaatsete tulemuste skoorides ei kajasta inimeste hinnanguid sildi, selgituse, mõistuse ega grammatika õigsuse kohta.', 'cs': 'Inference přirozeného jazyka (NLI) vyžaduje modely k učení se a aplikaci znalostí zdravého rozumu. Tyto schopnosti uvažování jsou obzvláště důležité pro vysvětlitelné NLI systémy, které vedle predikce etiket generují vysvětlení přirozeného jazyka. Bylo prokázáno, že integrace externích znalostí zlepšuje NLI systémy, zde zkoumáme, zda může také zlepšit jejich vysvětlovací schopnosti. Za tímto účelem zkoumáme různé zdroje externích znalostí a vyhodnocujeme výkonnost našich modelů na doménových datech i na speciálních datových sadách přenosu, které jsou navrženy k posouzení jemně zraněných možností uvažování. Zjišťujeme, že různé zdroje znalostí mají různý vliv na schopnosti uvažování, například implicitní znalosti uložené v jazykových modelech mohou bránit uvažování o číslech a negacích. Nakonec provádíme největší a nejjemnější vysvětlitelnou NLI crowdsourcingovou studii dosud. Odhaluje, že ani velké rozdíly v automatickém skórování výkonu se neodrážejí v lidském hodnocení označení, vysvětlení, zdravého rozumu ani gramatické správnosti.', 'fi': 'Luonnonkielen päättely (NLI) edellyttää malleja, joilla voidaan oppia ja soveltaa järjetöntä tietoa. Nämä päättelytaidot ovat erityisen tärkeitä selitettävissä oleville NLI-järjestelmille, jotka tuottavat etikettiennusteen lisäksi luonnollisen kielen selityksen. Ulkoisen tiedon integroinnin on osoitettu parantavan NLI-järjestelmiä, tässä selvitämme, voiko se myös parantaa niiden selityskykyä. Tätä varten tutkimme erilaisia ulkoisen tiedon lähteitä ja arvioimme malliemme suorituskykyä sekä sisäisissä tiedoissa että erityisissä siirtotietoaineistoissa, jotka on suunniteltu arvioimaan hienojakoisia päättelykykyjä. Havaitsemme, että eri tietolähteillä on erilainen vaikutus päättelykykyyn, esimerkiksi kielimalleihin tallennettu implisiittinen tieto voi haitata lukujen ja kiistojen päättelyä. Lopuksi toteutamme tähän mennessä suurimman ja hienorakeisen selitettävän NLI-joukkohankintatutkimuksen. Se paljastaa, että jopa suuret erot automaattisissa suorituspisteissä eivät heijastu ihmisten luokituksia etiketistä, selityksestä, järkevyydestä tai kieliopin oikeellisuudesta.', 'jv': 'Nari kesalahan kelas (NLI) butakon model kanggo sampek karo aplikasi kesalahan ingkang dipun. Awarti punika dipunanggé kuwi nggawe barang akeh luwih apik kanggo ngerasakno NLI iki dadi kapan tanggal sing dirambut kanggo ngerasakno tambah kanggo ngerasakno ning etiket. Entekan wong liyane ing rak segala sing nyerampun kanggo nggawe sistem NLI, kene awak dhéwé ujian sisaan kaya ngono iso nggawe akeh perusahaan kapasituran kanggo mbanjurakno. Saiki iki, we istrage diwurune buktuan samihan kelas barang nggawe barang nggawe model karo data-domain lan karo perusahaan dataset sing dibenaanye nggawe kanggo assess Awak dhéwé éntuk sistem sing dipun ajeng-sistem dadi kapan kuwi tindang yen manut karo nggawe barang, bisa ngono kuwi tindang kuwi tindang kejahatan Nyong-ngopo, kita praksi sing paling awak dhéwé anu nggawe gerakan oleh dumadhi NLI sing susahe nggawe ujak. Punika-punika sing ngerasakno akeh luwih akeh gak bener', 'he': 'תוצאת שפת טבעית (NLI) דורשת דוגמנים ללמוד ולהשתמש בידע משותף. היכולות ההיגיון הללו חשובות במיוחד למערכות NLI מסבירות שמוצרות הסבר טבעי לשפה בנוסף לחזות התווית שלהם. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities.  For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities.  אנו מוצאים שלמקורות שונים של ידע יש השפעה שונה על יכולות ההיגיון, לדוגמא, ידע מרושע שמחסן בדוגמנים לשפה יכול לעצור ההיגיון על מספרים ושלילות. סוף סוף, אנו מבצעים את המחקר הגדול ביותר והמוסבר ביותר במקורי קהל NLI עד היום. הוא מגלה שאפילו הבדלים גדולים בתוצאות ביצועים אוטומטיים לא משקפים בכישורים אנושיים של תווית, הסבר, משמעותי או תקנות גרמטיקה.', 'sk': 'Sklepanje naravnega jezika (NLI) zahteva modele za učenje in uporabo splošnega smisla znanja. Te sposobnosti razmišljanja so še posebej pomembne za pojasnljive sisteme NLI, ki poleg napovedi oznake ustvarjajo razlago naravnega jezika. Pokazalo se je, da integracija zunanjega znanja izboljšuje sisteme NLI, tukaj pa raziskujemo, ali lahko izboljša tudi njihove razlage. V ta namen raziskujemo različne vire zunanjega znanja in ocenjujemo učinkovitost naših modelov na domenskih podatkih in na posebnih naborih prenosov podatkov, ki so zasnovani za ocenjevanje drobnozrnatih sposobnosti razmišljanja. Ugotavljamo, da različni viri znanja različno vplivajo na sposobnosti razmišljanja, npr. implicitno znanje, shranjeno v jezikovnih modelih, lahko ovira razmišljanje o številih in zanikah. Na koncu izvajamo največjo in najbolj natančno razložljivo študijo množičnega nabora NLI doslej. Razkriva, da tudi velike razlike v avtomatskih ocenah uspešnosti ne odražajo niti v ocenah oznake, razlage, splošnega smisla niti slovnične pravilnosti.', 'ha': '@ info: whatsthis Ga wannan abinci masu inganci ne mafiya muhimu ga system-NLI waɗanda bã da an bayyana shi ba, ta ƙãga fassarar harshen kawaici da kuma ba da gabanin littafan su ba. An nuna integratewa da ilmi na baka don ya ƙara tsarin NLI, a nan, Munã tambaya ko za ta ƙara da abincin fassararsu. Daga wannan, Munã tambayi sourcen sanyin baka da kuma munã ƙaddara game da aikin misãlai masu cikin-danne da kuma kan data masu shige da aka ƙaddara don a ƙaddara abincin da aka naƙasa. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations.  Haƙĩƙa, Munã tafiyar da mafi girma da mafi kyaun karatun na NLI da ake bayyana wa maɓallin sourcer zuwa yanzu. Yana bayyana cewa, kõ dã sãɓa masu girma cikin score na-performance farat ɗaya ba su yi tunãni ba a cikin rabo-rayin mutum, fassarar, farin ciki, kuma kuma kuma daman shiryarwa.', 'bo': 'སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་ཕལ་ཆེ་བ(NLI)ལ་མིག་གཟུགས་རིས་དཔེ་གཏོང་དང་མཉམ་དུ་མཐུན རྟོགས་བསམ་ནུས་པ་འདི་དག་གི་ཁྱད་པར་གལ་ཆེན་ཡིན་པའི་NLI་རིགས ཕྱི་ལ་གྱི་ཤེས་ཡོད་ཚད་ཀྱི་ཆ་ཁ་ཤས་གཅིག་སྟོན་ཡོད་པས་NLI་རིམ་པ་ལ་ཡར་རྒྱས་གཏོང་ན། དེ་ནས་ང་ཚོའི་ནང་དུ་འོས་ཡོད For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. ང་ཚོར་ཤེས་པའི་ཐོག་ཁུངས་མི་འདྲ་བ་ལ་རྟོགས་བསམ་བློ་གཏོང་ནུས་པའི་དབང་རྩལ་དང་། དཔེར་ན། སྐད་ཡིག མཐའ་མར་དུ་འུ་ཅག་གིས་གནད་དོན་ཕལ་ཆེ་ཤོས་དང་ཆེ་བའི་ལྕགས་རིས་མང་ཤོས་ཀྱི་ཉེན་བརྗོད་བྱེད་ཀྱི་ཡོད། It reveals that even large differences in automatic performance scores do not reflect in human ratings of label, explanation, commonsense nor grammar correctness.'}
{'en': 'On the Limits of Minimal Pairs in Contrastive Evaluation', 'ar': 'على حدود الحد الأدنى للأزواج في التقييم المتباين', 'zh': '论对比评价中最小对的界限', 'fr': "Sur la limite de la paire minimale dans l'évaluation comparative", 'hi': 'कंट्रास्टिव मूल्यान में न्यूनतम जोड़े की सीमाएँ', 'pt': 'Sobre os limites de pares mínimos na avaliação contrastiva', 'ru': 'граница наименьшей пары в сравнительной оценке', 'es': 'Sobre el límite del Par mínimo en la evaluación comparativa', 'ga': 'Ar theorainneacha na bPáire Íosla i meastóireacht Chothromúil', 'ja': '対照評価における最小対の限界', 'hu': 'A minimális párok korlátairól a kontrasztív értékelésben', 'el': 'Για τα όρια των ελάχιστων ζευγαριών στην Αντιστατική Αξιολόγηση', 'ka': 'მთნთმალნთრვ ოაპთ გ კჲნრპაჟრთგნარა ვგალსაუთწ', 'kk': 'Контрастық оқу үшін төменгі жоғарының шектері', 'lt': 'Dėl minimalių poros ribų kontrastiniame vertinime', 'it': 'Sui limiti delle coppie minime nella valutazione contrastante', 'mk': 'На границите на минималните парови во контрастивната евалуација', 'ml': 'പരിശോധനത്തിന്റെ പരിധികളില്\u200d', 'ms': 'Pada Had Pasangan Minimal dalam Evaluasi Kontras', 'mt': 'Dwar il-Limiti tal-Pawġi Minimi fl-Evalwazzjoni Kontrastiva', 'mn': 'Харамсалтай үнэлгээнд хамгийн бага хэлбэрийн хязгаар', 'pl': 'O granicach par minimalnych w ocenie kontrastywnej', 'no': 'På grensene på minimale parer i kontrastiv evaluering', 'ro': 'Cu privire la limitele perechilor minime în evaluarea contrastivă', 'sr': 'Na granicama minimalnih pare u kontrastivnoj evaluaciji', 'si': 'ප්\u200dරතිශ්න විශ්වාසයෙන් ප්\u200dරතිශේෂයේ ප්\u200dරමාණයක් සීමාවට', 'sv': 'Om gränserna för minimala par i kontrastiv utvärdering', 'so': 'On the Limits of Minimal Pairs in Contrastive Evaluation', 'ta': 'தொடர்புடைய மதிப்பீட்டில் குறைந்தபட்ச பணம் வரம்புகளில்', 'ur': 'مقابلہ مقابلہ میں کمترین جوڑوں کی حدیں پر', 'uz': 'Kontraktiv tasdiqlashda minimal paytlar chegaralarida', 'vi': 'Giới hạn của các khoản trả ít... trong phần đánh giá phản động', 'bg': 'За границите на минималните двойки при контрастивна оценка', 'hr': 'O granicama minimalnih plati u kontrastivnoj procjeni', 'nl': 'Over de grenzen van minimale paren in contrastieve evaluatie', 'de': 'Über die Grenzen minimaler Paare in kontrastiver Bewertung', 'ko': '논 대비 평가 중 가장 작은 쌍의 경계', 'da': 'Om grænserne for minimale par i kontrastiv evaluering', 'id': 'Pada Batas Pasangan Minimal dalam Evaluasi Kontras', 'fa': 'در محدودیت کمینه جفت در ارزیابی کنترستی', 'af': 'Op die Grense van Minimale Pare in Kontrasteev Evaluering', 'am': 'አውቶማቲክ', 'tr': 'Iň kiçi/beýik gabdalyk hökmünde', 'az': 'Kontrast değerlendirməkdə minimal ömrünün sınırları', 'bn': 'কন্ট্রেসিটিভ মূল্যায়নের সীমানা', 'bs': 'O granicama minimalnih pare u kontrastivnoj procjeni', 'ca': "En els límits dels parells mínimos en l'Evaluació Contrastiva", 'cs': 'O limitech minimálních párů v kontrastivním hodnocení', 'sw': 'Katika mipaka ya mishahara madogo katika Uthibitisho', 'et': 'Minimaalsete paaride piiride kohta kontrastiivses hindamises', 'fi': 'Kontrastisen arvioinnin minimiparien rajoista', 'sq': 'On the Limits of Minimal Pairs in Contrastive Evaluation', 'hy': 'On the Limits of Minimal Pairs in Contrastive Evaluation', 'ha': '@ action', 'he': 'על הגבולות של זוגות מינימיות בהערכה נגדית', 'jv': 'Ngucap limiting the minimal PASS in contraststive', 'sk': 'O mejah minimalnih parov pri kontrastivnem vrednotenju', 'bo': 'ཚད་རྩིས་བ་ཐང་མེད་པའི་ཆུང་བའི་ཚད་ལྟར་'}
{'en': 'Minimal sentence pairs are frequently used to analyze the behavior of language models. It is often assumed that model behavior on contrastive pairs is predictive of model behavior at large. We argue that two conditions are necessary for this assumption to hold : First, a tested hypothesis should be well-motivated, since experiments show that contrastive evaluation can lead to false positives. Secondly, test data should be chosen such as to minimize distributional discrepancy between evaluation time and deployment time. For a good approximation of deployment-time decoding, we recommend that minimal pairs are created based on machine-generated text, as opposed to human-written references. We present a contrastive evaluation suite for EnglishGerman MT that implements this recommendation.', 'ar': 'غالبًا ما يتم استخدام أزواج الجمل الدنيا لتحليل سلوك نماذج اللغة. غالبًا ما يُفترض أن سلوك النموذج على الأزواج المتباينة هو تنبؤ بسلوك النموذج بشكل عام. ونجادل بأن هناك شرطين ضروريين للحفاظ على هذا الافتراض: أولاً ، يجب أن تكون الفرضية المختبرة ذات دوافع جيدة ، لأن التجارب تظهر أن التقييم المتباين يمكن أن يؤدي إلى إيجابيات خاطئة. ثانياً ، ينبغي اختيار بيانات الاختبار بحيث تقلل إلى أدنى حد من التباين في التوزيع بين وقت التقييم ووقت النشر. للتقريب الجيد لفك تشفير وقت النشر ، نوصي بإنشاء الحد الأدنى من الأزواج بناءً على نص تم إنشاؤه آليًا ، بدلاً من المراجع المكتوبة من قبل الإنسان. نحن نقدم مجموعة تقييم متناقضة لـ MT الإنجليزية الألمانية التي تنفذ هذه التوصية.', 'zh': '最小句子对常用于分析语言模型的行为。通常认为，对比对上的模型行为可以预测模型行为。我们认为，这一假设成立需要两个条件：第一，经过检验的假设应该有很好的动机，因为实验表明，对比评估可能导致误报。其次，测试数据的选择应尽量减少评估时间和部署时间之间的分布差异。为了更好地近似部署时解码，我们建议基于机器生成的文本创建最小对，而不是人工编写的引用。我们提出了一个实现这一建议的英德机器翻译对比评估套件。', 'hi': 'भाषा मॉडल के व्यवहार को विश्लेषण करने के लिए न्यूनतम वाक्य जोड़े बहुत से उपयोग में लिए जाते हैं. बहुत बार मानता है कि कंट्रास्टिव जोड़े पर मॉडल व्यवहार बड़ा होता है मॉडल व्यवहार के प्रतिदृश्य ह हम लगते हैं कि दो परिस्थितियाँ इस अभिवादन के लिए आवश्यक हैं: पहले, एक परीक्षा किया गया हिपोटेसिस अच्छी प्रारंभित होना चाहिए, क्योंकि प् दूसरी तरह, परीक्षण डाटा चुना जाना चाहिए जैसे कि वितरित समय और वितरित समय के बीच विभाजन समय के बीच कम करने के लिए. एक अच्छा निर्माण समय डिकोडिंग के लिए, हम सिफारिस करते हैं कि न्यूनतम जोड़े मशीन उत्पन्न पाठ पर आधारित बनाए जाएँ हम अंग्रेजी-जर्मनी एम टी के लिए एक कंट्रास्टिव मूल्यूशन सूट प्रस्तुत करते हैं जो इस सूचना का प्रयोग करता ह', 'fr': "Les paires de phrases minimales sont souvent utilisées pour analyser le comportement des modèles linguistiques. On croit généralement que le comportement du modèle peut être prédit en comparant le comportement du modèle au - dessus. À notre avis, deux conditions sont nécessaires pour que cette hypothèse soit fondée: premièrement, l'hypothèse éprouvée devrait être bien motivée, car les expériences montrent que l'évaluation comparative peut donner lieu à des inexactitudes. Deuxièmement, le choix des données d'essai devrait réduire au minimum les différences de répartition entre le temps d'évaluation et le temps de déploiement. Pour une meilleure approximation du décodage au moment du déploiement, nous recommandons de créer des paires minimales basées sur du texte généré par machine plutôt que des références écrites manuellement. Nous proposons une suite d'évaluation comparative de la traduction automatique anglaise - allemande pour mettre en oeuvre cette proposition.", 'ga': 'Minimal sentence pairs are frequently used to analyze the behavior of language models.  Is minic a mheastar go bhfuil iompar samhail ar pháirteanna contrártha réamh- mheasta ar iompar samhail i gcoitinne. Argumentaímid gur gá dhá choinníoll chun an glacadh seo a shealbhú: Ar an gcéad dul síos, ba cheart go mbeadh an t-ipotéis a thástáiltear mothúithe go maith, toisc go léiríonn taithí go bhféadfaidh meastóireacht chonraitheach dearfach folamh a thabhairt. Secondly, test data should be chosen such as to minimize distributional discrepancy between evaluation time and deployment time.  For a good approximation of deployment-time decoding, we recommend that minimal pairs are created based on machine-generated text, as opposed to human-written references.  We present a contrastive evaluation suite for English-German MT that implements this recommendation.', 'ja': '最小文対は言語モデルの挙動を解析するのにしばしば用いられる。対照対におけるモデルの振舞いは，モデルの振舞いを予測することが多い。我々は、この仮定のために2つの条件が保持されるのに必要であると主張します：最初に、実験は対照的な評価が偽陽性につながることができることを示すので、テストされた仮説はよく動機づけられなければなりません。第2に、試験データは、評価時間と展開時間の間の分配の不一致を最小にするように選ばれなければなりません。展開時間デコードの良い近似のために、私たちは、最小限のペアが機械で書かれたテキストに基づいてつくられることを勧めます。この勧告を実装する英語ドイツ語mtの対照評価スイートを提示した。', 'pt': 'Pares mínimos de frases são frequentemente usados para analisar o comportamento de modelos de linguagem. Muitas vezes assume-se que o comportamento do modelo em pares contrastivos é preditivo do comportamento do modelo em geral. Argumentamos que duas condições são necessárias para que essa suposição se mantenha: Primeiro, uma hipótese testada deve ser bem motivada, uma vez que experimentos mostram que a avaliação contrastiva pode levar a falsos positivos. Em segundo lugar, os dados de teste devem ser escolhidos de modo a minimizar a discrepância distributiva entre o tempo de avaliação e o tempo de implantação. Para uma boa aproximação da decodificação em tempo de implantação, recomendamos que pares mínimos sejam criados com base em texto gerado por máquina, ao contrário de referências escritas por humanos. Apresentamos uma suíte de avaliação contrastiva para MT inglês-alemão que implementa essa recomendação.', 'ru': 'минимальное предложение для поведения, обычно используемого при анализе языковой модели. обычно считается, что сопоставление поведения модели на верхнем уровне может предсказать поведение модели. Мы считаем, что для того, чтобы это предположение было утверждено, необходимы два условия: во - первых, проверенные предположения должны быть мотивированы вескими мотивами, поскольку эксперименты показывают, что Сопоставительная оценка может привести к неправильной оценке. Во - вторых, отбор данных для тестирования должен свести к минимуму различия в распределении времени между оценкой и развертыванием. для того чтобы лучше приблизиться к декодированию при развертывании, мы предлагаем создать минимальную пару на основе машинного текста, а не искусственно подготовленные ссылки. мы представили пакет для оценки контрастности переводов англо - германского компьютера для выполнения этого предложения.', 'es': 'Los pares de oraciones mínimas se utilizan a menudo para analizar el comportamiento de los modelos lingüísticos. Se cree generalmente que el comportamiento del modelo se puede predecir comparando el comportamiento del modelo en pares. Creemos que esta hipótesis requiere dos condiciones: En primer lugar, la hipótesis probada debe tener una buena motivación, ya que los experimentos demuestran que la evaluación comparativa puede dar lugar a falsos positivos. En segundo lugar, la selección de los datos de ensayo debe reducir al mínimo la diferencia de distribución entre el tiempo de evaluación y el tiempo de despliegue. Para aproximar mejor la decodificación en tiempo de despliegue, recomendamos crear pares mínimos basados en texto generado por máquina en lugar de referencias escritas manualmente. Proponemos un conjunto de evaluación comparativa de la traducción automática anglo - alemana para implementar esta propuesta.', 'hu': 'Minimális mondatpárokat gyakran használnak a nyelvi modellek viselkedésének elemzésére. Gyakran feltételezik, hogy a kontrasztív párok modellviselkedése általában prediktív a modellviselkedés. Azt állítjuk, hogy két feltétel szükséges ahhoz, hogy ez a feltételezés fenntartható legyen: Először is, egy tesztelt hipotézisnek jól motiváltnia kell, mivel a kísérletek azt mutatják, hogy a kontrasztos értékelés hamis pozitív eredményekhez vezethet. Másodszor a vizsgálati adatokat úgy kell kiválasztani, hogy minimalizálják az értékelési idő és a telepítési idő közötti elosztási eltérést. A telepítési idő dekódolásának megfelelő közelítése érdekében javasoljuk, hogy minimális párokat hozzanak létre gép által generált szöveg alapján, szemben az ember által írt hivatkozásokkal. Ezt az ajánlást végrehajtó kontrasztos értékelő csomagot mutatunk be az angol–német MT számára.', 'el': 'Τα ελάχιστα ζεύγη προτάσεων χρησιμοποιούνται συχνά για την ανάλυση της συμπεριφοράς των γλωσσικών μοντέλων. Συχνά θεωρείται ότι η συμπεριφορά του μοντέλου σε αντίθετα ζεύγη είναι πρόβλεψη της συμπεριφοράς του μοντέλου στο σύνολό του. Υποστηρίζουμε ότι δύο προϋποθέσεις είναι απαραίτητες για να διατηρηθεί αυτή η υπόθεση: Πρώτον, μια δοκιμασμένη υπόθεση πρέπει να έχει καλά κίνητρα, δεδομένου ότι τα πειράματα δείχνουν ότι η αντιπαραβολή αξιολόγησης μπορεί να οδηγήσει σε λανθασμένα θετικά αποτελέσματα. Δεύτερον, τα δεδομένα δοκιμής θα πρέπει να επιλέγονται έτσι ώστε να ελαχιστοποιούνται οι διαφορές κατανομής μεταξύ του χρόνου αξιολόγησης και του χρόνου ανάπτυξης. Για μια καλή προσέγγιση της αποκωδικοποίησης χρόνου ανάπτυξης, συνιστούμε να δημιουργούνται ελάχιστα ζεύγη με βάση κείμενο που παράγεται από μηχανή, σε αντίθεση με αναφορές γραμμένες από άνθρωπο. Παρουσιάζουμε μια αντιδιαστατική σουίτα αξιολόγησης για Αγγλικά-Γερμανικά ΜΤ που εφαρμόζει αυτή τη σύσταση.', 'ka': 'სიტყვების მოდელების მოქმედების ანალიზაციისთვის მინიმალური წესების ორივე ხშირად გამოყენება. ჩვეულად იყოს, რომ მოდელური ქცევა კონტრასტური ზოგებისთვის მოდელური ქცევის განსაზღვრებელია. ჩვენ გვაქვს, რომ ორი შესახებ უნდა იყოს ამ შესახებისთვის: პირველი, ტესტირებული ჰიპოტეზა უნდა იყოს კარგი მოტივირებული, რადგან ექსპერიმენტები გამოჩვენებენ, რომ კონტრასტიური მეორე, ტესტის მონაცემები უნდა იყენება, როგორც განსაზღვრული დროს და განსაზღვრული დროს შორის განსაზღვრული განსხვავება. ჩვენ მინდომენტი ზოგები შექმნა მაქინის შექმნილი ტექსტის გარეშე, როგორც ადამიანის წერტილი რეფენციების გარეშე. ჩვენ აჩვენებთ კონტრასტიგური განსაზღვრების კონტრასტიგური სამუშაო ანგლისურ-გერმანური MT-ს, რომელიც ამომუშაობს ეს მოწ', 'it': "Le coppie di frasi minime sono spesso utilizzate per analizzare il comportamento dei modelli linguistici. Spesso si presume che il comportamento del modello su coppie contrastanti sia predittivo del comportamento del modello in generale. Sosteniamo che due condizioni sono necessarie perché questa ipotesi rimanga: in primo luogo, un'ipotesi testata dovrebbe essere ben motivata, poiché gli esperimenti dimostrano che la valutazione contrastante può portare a falsi positivi. In secondo luogo, i dati di prova dovrebbero essere scelti in modo da ridurre al minimo la discrepanza distributiva tra il tempo di valutazione e il tempo di implementazione. Per una buona approssimazione della decodifica in tempo di distribuzione, si consiglia di creare coppie minime basate sul testo generato dalla macchina, al contrario dei riferimenti scritti dall'uomo. Presentiamo una suite di valutazione contrastante per MT inglese-tedesco che implementa questa raccomandazione.", 'lt': 'Minimal ūs sakiniai dažnai naudojami kalbų modelių elgesiui analizuoti. Dažnai daroma prielaida, kad modelio elgesys kontrastinėse porose nuspėja modelio elgesį apskritai. Mes teigiame, kad šioms prielaidoms laikytis reikia dviejų sąlygų: pirma, išbandyta hipotezė turėtų būti gerai motyvuota, nes eksperimentai rodo, kad kontrastinis vertinimas gali sukelti klaidingą teigiamumą. Antra, turėtų būti pasirinkti bandymų duomenys, kad būtų kuo labiau sumažintas vertinimo laiko ir naudojimo laiko paskirstymo skirtumas. Norėdami gerai suderinti eksploatavimo ir laiko dekodizavimą, rekomenduojame sukurti minimalias poras remiantis mašinų sukurtu tekstu, o ne žmogaus rašytinėmis nuorodomis. Mes pateikiame kontrastinį anglų ir vokiečių MT vertinimo rinkinį, kuris įgyvendina šią rekomendaciją.', 'mk': 'Минималните парови на реченици често се користат за анализа на однесувањето на јазичките модели. Често се претпоставува дека моделното однесување на контрастивните парови претставува предвидување на моделното однесување на целина. Ние тврдиме дека два услови се неопходни за оваа претпоставка да се одржи: Прво, тестираната хипотеза треба да биде добро мотивирана, бидејќи експериментите покажуваат дека контрастивната оценка може да доведе до лажни позитивни резултати. Secondly, test data should be chosen such as to minimize distributional discrepancy between evaluation time and deployment time.  За добра приближување на декодирањето на времето на распоредување, препорачуваме да се создадат минимални парови врз основа на машински генериран текст, наместо човековите референции. Презентираме контрастивна оценка за англиско-германско МТ која ја имплементира оваа препорака.', 'kk': 'Тіл үлгілерінің тәртібін талдау үшін төменгі сөйлем екеуі көбінде қолданылады. Көбінде контрастық екептердің үлгі әрекеттері үлгі қасиеттердің үлгісін көрсетеді. Біз бұл тапсырма үшін екі шарт керек деп айтып тұрамыз: біріншіден, тексерілген гипотеза жақсы мотивациялану керек, себебі тәжірибелер контрастық оқиға жарамсыз оқиғаларға болады. Екіншіден, сынақ деректерін таңдау керек, мысалы, үлестіру уақыты мен орындау уақытының арасындағы бөліктердің айырмашылығын төмендету үшін. Адам жазылған сілтемелеріне қарсы, машина жасалған мәтіннің негізінде төменгі екептерді жасау үшін жақсы уақытты декодтамыз. Бұл рекомендацияны істейтін ағылшын-неміс MT үшін контрастырлық бағалау бағдарламасын таңдаймыз.', 'ms': 'Pasangan kalimat minimum sering digunakan untuk menganalisis perilaku model bahasa. Ia sering dianggap bahawa perilaku model pada pasangan bertentangan adalah ramalan perilaku model pada umumnya. We argue that two conditions are necessary for this assumption to hold: First, a tested hypothesis should be well-motivated, since experiments show that contrastive evaluation can lead to false positives.  Kedua, data ujian sepatutnya dipilih untuk mengurangi ketidaksamaan distribusi antara masa penilaian dan masa penggunaan. Untuk pendekatan penyahkodan masa-penggunaan yang baik, kami cadangkan pasangan minimal dicipta berdasarkan teks yang dijana oleh mesin, selain dari rujukan yang ditulis oleh manusia. Kami memperkenalkan suite penilaian bertentangan untuk MT Inggeris-Jerman yang melaksanakan rekomendasi ini.', 'mt': 'Pari ta’ sentenzi minimi ta’ spiss jintużaw biex janalizzaw l-imġiba tal-mudelli lingwistiċi. Ħafna drabi wieħed jassumi li l-imġiba mudell fuq pari kontrastivi tipprevedi l-imġiba mudell inġenerali. Aħna jargumentaw li żewġ kundizzjonijiet huma meħtieġa biex din is-suppożizzjoni tinżamm: L-ewwel, ipoteżi ttestjata għandha tkun motivata sewwa, peress li l-esperimenti juru li l-evalwazzjoni kontrastiva tista’ twassal għal pożittivi foloz. It-tieni nett, id-dejta tat-test għandha tintgħażel sabiex titnaqqas id-diskrepanza distributtiva bejn il-ħin tal-evalwazzjoni u l-ħin tal-iskjerament. Għal approssimazzjoni tajba tad-dekodifikazzjoni tal-ħin tal-użu, nirrakkomandaw li jinħolqu pari minimi bbażati fuq test iġġenerat mill-magna, minflok referenzi miktuba mill-bniedem. Aħna nippreżentaw sett ta’ evalwazzjoni kuntrastiva għall-MT Ingliż-Ġermaniż li jimplimenta din ir-rakkomandazzjoni.', 'ml': 'ഭാഷ മോഡലുകളുടെ സ്വഭാവം അന്യോന്യം ചെയ്യാന്\u200d ഏറ്റവും ചെറുതായ വാക്ക് ഇണകള്\u200d ഉപയോഗിക്കുന്നു. എതിര്\u200dപ്പിലുള്ള ഇണകളുടെ മാതൃകയുടെ പ്രവര്\u200dത്തനത്തെപ്പറ്റി പലപ്പോഴും വിചാരിക്കുന്നു We argue that two conditions are necessary for this assumption to hold: First, a tested hypothesis should be well-motivated, since experiments show that contrastive evaluation can lead to false positives.  രണ്ടാമതായി, പരീക്ഷ വിവരങ്ങള്\u200d തെരഞ്ഞെടുക്കേണ്ടതുണ്ട്, വിവിതരണ സമയത്തിനും വിലാസക്കേതിനും ഇടയിലുള്ള വ്യത്യാസം കു മെഷീന്\u200d ഉണ്ടാക്കുന്ന വാചകത്തിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d ചെറുതായി ജോണി സൃഷ്ടിക്കുന്നത് മനുഷ്യന്\u200d എഴുതിയ വിവരങ്ങള്\u200dക്ക് വിരോധമാണെ ഞങ്ങള്\u200d ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d എംടിയുടെ വിലാസപൂര്\u200dണ്ണമായ ഒരു വിലാസപ്രകാരം സ്യൂട്ട് കൊണ്ടുവരുന്നു.', 'mn': 'Хэдий бага өгүүлбэр хоёр нь хэл загварын үйл явдлыг шинжилэхэд ихэвчлэн хэрэглэгддэг. Ихэнхдээ эсрэг хоёр дээрх загварын үйл ажиллагаа маш их загварын талаар таамагладаг. Бид хоёр нөхцөл байдал хэрэгтэй гэдгийг хэлж байна: Эхлээд, шалгалтын hypothesis сайн урам зориулан байх ёстой, учир нь туршилтууд эсрэг үнэлгээ буруу эерэг байдалд хүргэж чадна. Хоёрт, шалгалтын өгөгдлийг шалгалтын цаг болон ажиллах цаг хоорондын хуваарилалтын ялгааг багасгах хэрэгтэй. Хүмүүсийн бичигдсэн санаануудын эсрэг машин үүсгэсэн текст дээр бага зэрэг цөөн хоёр бий болгохыг бид зөвшөөрдөг. Бид Англи-Германы MT-ийн эсрэг дүгнэлтийн загварыг тайлбарладаг.', 'no': 'Minste setningar vert ofte brukte for å analysera oppførsel av språk- modeller. Det vert ofte anta at modellåtferd på kontrastiske par er foregåande av modellåtferd i stor stor. Vi argumenterer at to vilkår er nødvendig for denne assumpsjonen å holde: Først bør ein testa hypotese vera godt motivert, sidan eksperimenter viser at kontrastevaluering kan føre til falske positivar. Sekundert bør test data veljast slik som å minimera distribusjonsforskjellighet mellom evalueringstid og utviklingstid. For ein god tilnærming av dekoding for utviklingstid, anbefaler vi at minimale par vert laga basert på maskinelaga tekst i motsetjing til menneskelige skrivne referanser. Vi presenterer eit kontrastevalueringssuite for engelsk-tysk MT som implementerer denne anbefalinga.', 'pl': 'Minimalne pary zdań są często używane do analizy zachowania modeli językowych. Często przyjmuje się, że zachowanie modelu w parach kontrastywnych jest predykcyjne zachowania modelu w ogóle. Uważamy, że do utrzymania tego założenia konieczne są dwa warunki: Po pierwsze, testowana hipoteza powinna być dobrze zmotywowana, ponieważ eksperymenty pokazują, że ocena kontrastywna może prowadzić do fałszywych pozytywnych sytuacji. Po drugie, należy dobrać dane testowe w taki sposób, aby zminimalizować rozbieżność dystrybucyjną między czasem oceny a czasem wdrożenia. Dla dobrego przybliżenia dekodowania w czasie wdrożenia zalecamy tworzenie minimalnych par na podstawie tekstu generowanego maszynowo, w przeciwieństwie do odniesień napisanych przez człowieka. Przedstawiamy kontrastywny pakiet oceny dla angielsko-niemieckich MT, który wdraża to zalecenie.', 'si': 'භාෂා මෝඩල් වර්තනය විශ්ලේෂණය කරන්න ප්\u200dරමාණය කරන්න පුළුවන් විතරයි. ඒක සාමාන්\u200dය විශ්වාසයෙන් හිතන්නේ ප්\u200dරතික්\u200dරියාත්මක දේවල් වලට ප්\u200dරතික්\u200dරියාත්මක වෙනුවෙන් ම අපි ප්\u200dරශ්නයක් කරනවා මේ විශ්නාවට අවශ්\u200dය දෙකක් තියෙනවා කියලා: මුලින්, පරීක්ෂණය කරලා තියෙන්න පුළුවන්, පරීක්ෂණය කරලා තිය දෙවනියෙන්, පරීක්ෂණා දත්ත තෝරාගන්න ඕනේ වගේම විශේෂණ වෙලාව සහ විශේෂණ වෙලාවක් අතර පරීක්ෂණා වි අපි ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් හොඳ සම්බන්ධ වෙනුවෙන්, අපි ප්\u200dරශ්නයක් වෙනුවෙන් පණිවිඩයෙන් පණිව අපි ඉංග්\u200dරීසිය-ජර්මන් MT වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක විශේෂ සුට් එකක් පෙන්වන්නේ මේ සැලසු', 'so': 'Minimal sentence pairs are frequently used to analyze the behavior of language models.  Inta badan waxaa loo malaynayaa in dabeecada noocyada kala duwan ee labo kala duwan waa mid aad u sii sheegaya dabeecada model. Waxaynu ka sheekaynaynaa in labada sharci ah loo baahan yahay in loo haysto malaha: marka hore waxaa haboon in la hagaajiyo tijaabada la tijaabiyo, sababtoo ah jirrabaadu waxay muuqan karaan in qiimeynta ka geesta ah ay ka leedahay waxyaabo been ah. Second waxaa la doortaa macluumaadka imtixaanka, tusaale ahaan ugu yaraan qiimeynta iyo waqtiga shaqada. Sida aad ugu dhow tahay kaartaynta waqtiga shaqada, waxaan ku talinaynaa in labada noocyada ugu yaraan lagu sameeyo qoraal lagu saleeyo machine-generay, si ka gees ah looga jeedo qoraalka dadka. Waxaannu soo bandhignaa hab qiimeynta ka gees ah ee afka Ingiriiska-Jarmalka MT oo soo dejiya taladan.', 'sr': 'Minimalni parovi rečenice često se koriste za analizu ponašanja jezičkih modela. Često se pretpostavlja da je modelo ponašanje na kontrastivnim parovima predvidljivo modelo ponašanje u velikoj meri. Tvrdimo da su dva uvjeta neophodna za ovu pretpostavku: Prvo, ispitivana hipoteza treba biti dobro motivisana, jer eksperimenti pokazuju da kontrastivna procjena može dovesti do lažnih pozitiva. Drugo, potrebno je izabrati test podatke kao što bi se minimizirala distribucija neslaganja između vrijeme procjene i vremena rasporeda. Za dobar približavanje dekodiranja vremena za raspoređenje, preporučujemo da se minimalni parovi stvore na temelju teksta od strojeva, suprotno ljudskim pisanim referencijama. Predstavljamo kontrastivni apartman za procjenu engleskog i njemačkog MT-a koji implementira ovu preporuku.', 'sv': 'Minimala meningspar används ofta för att analysera beteendet hos språkmodeller. Det antas ofta att modellbeteende på kontrastiva par är prediktiv för modellbeteende i stort. Vi hävdar att två villkor är nödvändiga för att detta antagande ska hålla: För det första bör en testad hypotes vara välmotiverad, eftersom experiment visar att kontrastiv utvärdering kan leda till falska positiva effekter. För det andra bör testdata väljas så att fördelningen mellan utvärderingstid och driftstid minimeras. För en bra approximation av avkodning av driftsättningstid rekommenderar vi att minimala par skapas baserat på maskingenererad text, i motsats till mänskliga referenser. Vi presenterar en kontrastiv utvärderingssvit för engelsk-tysk MT som implementerar denna rekommendation.', 'ta': 'குறைந்தபட்ச வாக்கு ஜோடி மொழி மாதிரியின் நடைமுறையை ஆய்வு செய்ய பயன்படுத்தப்படுகிறது. மாதிரியான ஜோடிகளின் மாதிரி நடத்தையை பெரிய மாதிரி நடத்தையின் முன்வாக்குகிறது. நாம் இந்த எண்ணிக்கைக்கு இரண்டு நிபந்தனைகள் தேவைப்படுகிறது என்று விவாதம் செய்கிறோம்: முதலில், ஒரு சோதனைப்படுத்தப்பட்ட hypothesis நன்றாக உச்சரிக இரண்டாவது, மதிப்பு நேரம் மற்றும் வெளியீட்டு நேரத்திற்கும் இடையே பங்கீட்டு வேறுபாட்டை குறைந்து கொள்ள சோதனை தர வெளியீட்டு நேர குறியீட்டின் சுற்றியமான ஜோடி உருவாக்கப்படும் இயந்திரம் உரையை அடிப்படையில், மனித எழுத்தப்பட்ட குறிப்புகளை எதிர்த இந்த பரிந்துரையை நிறைவேற்றும் ஆங்கிலம்- ஜெர்மன் MT ஒரு முறையான மதிப்புரையை நாம் கொண்டுள்ளோம்.', 'ur': 'زبان نمڈلوں کے رفتار کا تحلیل کرنے کے لئے بہت ہی کم کلام جوڑے استعمال کئے جاتے ہیں. اکثر سمجھا جاتا ہے کہ مقابلہ جوڑوں پر موڈل کا رفتار بڑا ہے. ہم argue that two conditions are necessary for this assumption to hold: first, a test hypothesis should be well motivated, since experiments show that contrastive evaluation can lead to false positives. دوسرا، ٹیسٹ ڈیٹا انتخاب کرنا چاہیے جیسے کہ تقسیم زمان اور تقسیم زمان کے درمیان تقسیم اختلاف کو کم کرنا چاہیے. ہم اس بات کی توفیق دیتے ہیں کہ کمترین جوڑوں کو ماشین کے پیدا کئے ہوئے متن پر بنیاد بنایا جاتا ہے، انسان کی نسبت لکھی ہوئی نسبت۔ ہم انگلیسی-جرمن MT کے لئے ایک مقابلہ مقابلہ ارزیابی سوئٹ پیش کرتے ہیں جو اس سفارش کا عملہ کرتا ہے.', 'ro': 'Perechile minime de propoziții sunt frecvent utilizate pentru a analiza comportamentul modelelor lingvistice. Se presupune adesea că comportamentul modelului pe perechile contrastante este predictiv al comportamentului modelului în general. Susținem că sunt necesare două condiții pentru ca această ipoteză să se mențină: În primul rând, o ipoteză testată ar trebui să fie bine motivată, deoarece experimentele arată că evaluarea contrastantă poate duce la fals pozitive. În al doilea rând, ar trebui alese datele de testare astfel încât să minimizeze discrepanța distribuțională dintre timpul de evaluare și timpul de implementare. Pentru o bună aproximare a decodării timpului de implementare, recomandăm crearea de perechi minime bazate pe text generat de mașină, spre deosebire de referințele scrise de om. Vă prezentăm o suită de evaluare contrastantă pentru MT engleză-germană care implementează această recomandare.', 'uz': "Tilning xususiyatlarini aniqlash uchun eng kichik so'zlar qoʻllaniladi. Ko'pincha o'ylashadi, contrast-ikkita qo'llarda model xuddi katta model xususiyatlarini predictor qiladi. Biz aytganmiz, bu fikrlarni boshqarish uchun ikki holat kerak: Birinchida, tizim hypothesis yaxshi harakat qilishi kerak, chunki taʼminlovchi qiymatlar yolg'on joylashishi mumkin. Secondly, test data should be chosen such as to minimize distributional discrepancy between evaluation time and deployment time.  Ishlab chiqarish vaqtni kodlash uchun, biz oddiy qo'llanmalar yaratilgan matn asosida yaratilmoqchimiz, inson yozib qo'llangan parametrlarning asosida. Biz bir so'zlarni ishga tushirish uchun ingliz-Olmon MT'ning qiymatni boshqaruvchimiz.", 'vi': 'Các cặp câu ít thường được dùng để phân tích hành vi của các mô hình ngôn ngữ. Thường thì giả định hành vi mô hình trên các cặp khác nhau là dự đoán hành vi mô hình rộng. Chúng tôi cho rằng hai điều kiện là cần thiết cho giả định này. Thứ nhất, một giả thuyết được thử nghiệm phải được thúc đẩy đầy đủ, vì các thí nghiệm cho thấy đánh giá phản đối có thể dẫn đến điều không tốt. Thứ hai, phải chọn dữ liệu thử để hạn chế sự khác biệt phân chia giữa thời gian đánh giá và thời gian triển khai. Để có một mức độ thích hợp cho việc giải mã thời gian triển khai, chúng tôi đề nghị tạo ra các cặp nhỏ nhất dựa trên văn bản máy tạo ra, thay vì những chỉ dẫn chữ con người. Chúng tôi giới thiệu một phòng đánh giá tương đối cho kênh Anh-Đức để thực hiện đề nghị này.', 'hr': 'Minimalni parovi rečenica često se koriste za analizu ponašanja jezičkih modela. Često se pretpostavlja da je modelo ponašanje na kontrastivnim parovima predviđalo model ponašanje u velikoj mjeri. Tvrdimo da su dvije uvjete potrebne za ovu pretpostavku: Prvo, ispitivana hipoteza treba biti dobro motivirana, jer eksperimenti pokazuju da kontrastivna procjena može dovesti do lažnih pozitiva. Drugo, potrebno je izabrati test podatke kao što bi se smanjila raspodjelna neslaganja između vrijeme procjene i vremena rasporeda. Za dobar približavanje dekodiranja vremena rasporedanja, preporučujemo da se minimalni parovi stvore na temelju teksta proizvođenog strojeva, suprotno ljudskim pisanim referencijama. Predstavljamo kontrastivni apartman za procjenu engleskog i njemačkog MT-a koji provedi ovu preporuku.', 'nl': 'Minimale zinsparen worden vaak gebruikt om het gedrag van taalmodellen te analyseren. Vaak wordt aangenomen dat modelgedrag op contrastieve paren voorspellend is voor modelgedrag in het algemeen. We stellen dat twee voorwaarden nodig zijn om deze veronderstelling te handhaven: Ten eerste, een geteste hypothese moet goed gemotiveerd zijn, omdat experimenten aantonen dat contrastieve evaluatie kan leiden tot valse positieven. Ten tweede moeten testgegevens zodanig worden gekozen dat distributieverschillen tussen evaluatietijd en implementatietijd tot een minimum worden beperkt. Voor een goede benadering van deployment-time decodering raden we aan om minimale paren te maken op basis van door de machine gegenereerde tekst, in tegenstelling tot door mensen geschreven verwijzingen. We presenteren een contrastieve evaluatiesuite voor Engels-Duits MT die deze aanbeveling implementeert.', 'da': 'Minimale sætningspar bruges ofte til at analysere sprogmodellernes adfærd. Det antages ofte, at model adfærd på kontrastive par er forudsigende for model adfærd generelt. Vi hævder, at to betingelser er nødvendige for at denne antagelse kan holde: For det første bør en testet hypotese være velmotiveret, da eksperimenter viser, at kontrastevaluering kan føre til falske positive. For det andet bør testdata vælges således, at fordelingsforskellen mellem evalueringstid og implementeringstid minimeres. For en god tilnærmelse af afkodning af implementeringstid anbefaler vi, at der oprettes minimale par baseret på maskingenereret tekst i modsætning til menneskeskrevne referencer. Vi præsenterer en kontrastiv evalueringspakke for engelsk-tysk MT, der implementerer denne anbefaling.', 'ko': '최소 문장은 언어 모델을 분석하는 데 자주 쓰이는 행위에 대한 것이다.사람들은 일반적으로 대조적인 모델 행위가 모델의 전체적인 행위를 예측할 수 있다고 생각한다.우리는 이 가설의 성립은 두 가지 조건이 필요하다고 생각한다. 첫째, 검증된 가설은 좋은 동기가 있어야 한다. 왜냐하면 실험에 의하면 비교 평가가 오보를 초래할 수 있기 때문이다.그 다음으로 테스트 데이터의 선택은 평가 시간과 배치 시간 간의 분포 차이를 최대한 줄여야 한다.배치 시간 디코딩과 더욱 가깝게 하기 위해서, 우리는 기계가 생성한 텍스트를 기반으로 인공적으로 작성한 인용이 아닌 최소 쌍을 만드는 것을 권장합니다.우리는 영어-독어 기계 번역을 위해 비교 평가 세트를 제공하여 이 건의를 실현하였다.', 'bg': 'Минималните двойки изречения често се използват за анализ на поведението на езиковите модели. Често се приема, че моделното поведение при контрастни двойки предсказва моделното поведение като цяло. Ние твърдим, че две условия са необходими за това предположение: Първо, тестваната хипотеза трябва да бъде добре мотивирана, тъй като експериментите показват, че контрастната оценка може да доведе до фалшиво положителни. На второ място, данните от изпитванията трябва да бъдат избрани така, че да се сведе до минимум разпределителната разлика между времето за оценка и времето за внедряване. За добро приближаване на декодирането във времето на внедряване препоръчваме създаването на минимални двойки въз основа на машинно генериран текст, за разлика от препратки, написани от човека. Представяме контрастивен пакет за оценка на англо-немски МТ, който изпълнява тази препоръка.', 'sw': 'Wanaume wa hukumu ndogo mara nyingi hutumiwa kuchambua tabia za mitindo ya lugha. Mara nyingi inadhaniwa kwamba tabia za model zinazohusu wanandoa tofauti ni kutabiri tabia za model kwa kiasi kikubwa. Tunajaribu kuwa hali mbili ni muhimu kwa dhana hii ya kutekeleza: Kwanza, nadharia iliyojaribiwa inapaswa kusababishwa vizuri, kwa sababu majaribio yanaonyesha kwamba tathmini mbadala unaweza kusababisha nafasi za uongo. Pili, takwimu za kujaribu zinapaswa kuchaguliwa kama vile kupunguza utofauti wa usambazaji kati ya muda wa uchunguzi na wakati wa usafiri. Kwa ajili ya kupunguzwa kwa muda mzuri wa kuajiri, tunapendekeza kuwa wanandoa wachache wanatengenezwa kwa kutumia maandishi yaliyotengenezwa kwa mashine, tofauti na maoni yanayoandikwa kwa binadamu. Tunatoa kituo cha uchunguzi kinachopingana kwa MT wa Kiingereza na Kijerumani kinachotumia pendekezo hili.', 'de': 'Häufig werden minimale Satzpaare verwendet, um das Verhalten von Sprachmodellen zu analysieren. Häufig wird angenommen, dass das Modellverhalten auf kontrastiven Paaren das Modellverhalten insgesamt vorhersagt. Wir argumentieren, dass zwei Bedingungen notwendig sind, um diese Annahme zu halten: Erstens sollte eine getestete Hypothese gut motiviert sein, da Experimente zeigen, dass kontrastive Bewertung zu falschen Positiven führen kann. Zweitens sollten Testdaten so gewählt werden, dass Verteilungsdifferenzen zwischen Evaluierungszeit und Bereitstellungszeit minimiert werden. Für eine gute Näherung der Deployment-Time-Decodierung empfehlen wir, dass minimale Paare auf der Grundlage von maschinell generiertem Text erstellt werden, im Gegensatz zu von Menschen geschriebenen Referenzen. Wir stellen eine kontrastive Evaluation Suite für Deutsch-Englisch MT vor, die diese Empfehlung umsetzt.', 'tr': 'Iň kiçi sözler çift sanly dil nusgalarynyň davranmasyny çözmek üçin ullanylýar. Köplenç garşy nusgalan çiftlerde örän nusgala uly bir hereket edip bilýär. Biz bu tahmin için iki şartlar gerekli olduğunu iddia ediyoruz: ilk olarak, testi tahmin edilmesi iyi motive edilmelidir, çünkü deneyler, tersli değerlendirme yanlış pozitiflere yol a çabilir. Ikinji gezek, çykyş wagty we ýerine ýetirme zamany aralygynda paýlaşylygy azaltmak üçin synanyň maglumaty saýlamalydyr. Araşdyrmak üçin gowy wagt kodlemesi üçin, ynsan ýazylan suratlara garşy döredilen metin üçin iň kiçi çift döredilmelidigini maslahat berýäris. Biz iňlisçe-nemes MT üçin bu maslahatyny ýerine ýetiren nusgasy takyklaýarys.', 'fa': 'جفت\u200cهای کمینه جمله اغلب برای تحلیل رفتار مدل\u200cهای زبان استفاده می\u200cشوند. اغلب فرض می\u200cشود که رفتار مدل روی جفت\u200cهای متفاوت پیش\u200cبینی از رفتار مدل بزرگ است. ما بحث می\u200cکنیم که دو شرایط برای این فرضیه نیاز دارند: اول، یک فرضیه آزمایش باید به خوبی انگیزه شود، زیرا آزمایشات نشان می\u200cدهند که ارزیابی متفاوتی می\u200cتواند به مثبت غلط رخ دهد. دوم، اطلاعات آزمایش باید چنین انتخاب شود که تفاوت تقسیم بین زمان ارزیابی و زمان تغییر. برای تقریباً نزدیک شدن دکوندن زمان فعالیت، ما پیشنهاد می\u200cکنیم که جفت کمینه بر اساس متن تولید شده\u200cی ماشین، در مقابل ارتباط\u200cهای نوشته شده\u200cی انسان آفرینش شود. ما یک سوئت ارزیابی متفاوتی برای MT انگلیسی و آلمانی را پیشنهاد می کنیم که این پیشنهاد را انجام می دهد.', 'sq': 'Minimal sentence pairs are frequently used to analyze the behavior of language models.  It is often assumed that model behavior on contrastive pairs is predictive of model behavior at large.  Ne argumentojmë se dy kushte janë të nevojshme për të mbajtur këtë supozim: së pari, një hipotezë e testuar duhet të jetë e motivuar mirë, pasi eksperimentet tregojnë se vlerësimi kontrastiv mund të shpjerë në pozitiva të rreme. Secondly, test data should be chosen such as to minimize distributional discrepancy between evaluation time and deployment time.  Për një përafërsim të mirë të dekodimit të kohës së vendosjes, ne rekomandojmë që çiftet minimale të krijohen bazuar në tekstin e gjeneruar nga makina, në vend të referencave të shkruara nga njerëzit. Ne paraqesim një suite të vlerësimit kontrastiv për MT anglo-gjerman që zbaton këtë rekomandim.', 'hy': 'Նվայնական նախադասությունների զույգերը հաճախ օգտագործվում են լեզվի մոդելների վարքագիծը վերլուծելու համար: Հաճախ ենթադրվում է, որ հակադրական զույգերի մոդելային վարքագիծը կանխատեսում է մոդելային վարքագիծը: Մենք պնդում ենք, որ այս ենթադրության համար երկու պայմաններ անհրաժեշտ են. առաջինը, փորձարկված հիպոթեզը պետք է լավ մոտիվացված լինի, քանի որ փորձարկումները ցույց են տալիս, որ հակադրական գնահատումը կարող է հանգեցնել սխալ դրական: Երկրորդ, պետք է ընտրենք փորձարկումների տվյալները, որպեսզի նվազեցնենք գնահատման ժամանակի և օգտագործման ժամանակի տարբերությունը: Օգտագործման-ժամանակի կոդավորման լավ մոտեցումների համար մենք խորհուրդ ենք տալիս, որ միմինալ զույգեր ստեղծվեն մեքենայի ստեղծված տեքստի վրա, ի հակառակ մարդկային գրված հղումների: Մենք ներկայացնում ենք անգլերեն-գերմանացի MT-ի հակադրական գնահատման համակարգ, որը կիրառում է այս խորհուրդը:', 'az': 'Ənimətli cümlələr dil modellərin davranışlarını analizə etmək üçün çox sık vaxt istifadə edilir. Tərəfəli çiftlərdə model davranışı böyük modellərin davranışlarını təmin edir. Biz mübahisə edirik ki, bu zənnə saxlamaq üçün iki şartlıq lazımdır: ilk dəfə testlənmiş hipotezi yaxşı motivasiya çəkilməlidir, çünki eksperimentlərin müqayisədə müqayisədə değerlənməsi yanlış positiblərə yol göstərə bilər. İkincisi, müəyyən vaxtı ilə istifadə vaxtı arasındakı fərqliyi azaltmaq üçün test verilən məlumatları seçilməlidir. Yaxınlıq vaxtı kodlamasının yaxınlaşması üçün, insan yazılmış referanslarına qarşı, maşın yaratdığı mətn üzərində minimal çift yaradılmasını tavsiye edirik. Biz İngilizce-Alman MT üçün müxtəlif değerlendirmə suitini göstəririk ki, bu tədbirləri gerçəkləşdirər.', 'bn': 'ভাষার মডেলের আচরণ বিশ্লেষণ করার জন্য প্রায়শই নিম্নলিখিত বাক্যের জোড়া ব্যবহার করা হয়। এটি প্রায়শই ধারণা করা হয় যে বিরোধী জোড়ার প্রতি মডেল আচরণ বিশাল মডেল আচরণের ভবিষ্যৎ। আমরা যুক্তি দিচ্ছি যে এই ধারণার জন্য দুটি পরিস্থিতি প্রয়োজন: প্রথমে একটি পরীক্ষা হিপিসেবে ভালোভাবে উদ্দেশ্য করা উচিত, কারণ পরীক্ষা দেখাচ্ছ দ্বিতীয়, পরীক্ষার তথ্য নির্বাচন করা উচিত যেমন মূল্যের সময় এবং অবতীর্ণ সময়ের মধ্যে বিতরণের বৈষম্য কমিয়ে দেয়ার জন্য। মানুষের লেখার বিরুদ্ধে মেশিন উৎপাদন করা টেক্সট ভিত্তিক ভিত্তিতে কম জোড়া তৈরি করা হয়েছে। আমরা ইংরেজি-জার্মান এমটির জন্য একটি বিরোধী মূল্য স্যুট উপস্থাপন করছি যা এই পরামর্শ প্রয়োগ করে।', 'bs': 'Minimalni parovi rečenice često se koriste za analizu ponašanja jezičkih modela. Često se pretpostavlja da je modelo ponašanje na kontrastivnim parovima predvidljivo modelo ponašanje u velikoj mjeri. Tvrdimo da su dva uvjeta potrebna za ovu pretpostavku: Prvo, ispitivana hipoteza treba biti dobro motivisana, jer eksperimenti pokazuju da kontrastivna procjena može dovesti do lažnih pozitiva. Drugo, potrebno je izabrati test podatke kao što bi se smanjila raspodjelna neslaganja između vrijeme procjene i vremena rasporeda. Za dobar približavanje dekodiranja vremena rasporedanja, preporučujemo da se minimalni parovi stvore na temelju teksta proizvođenog strojeva, suprotno ljudskim pisanim referencijama. Predstavljamo kontrastivni apartman za procjenu engleskog-nemačkog MT-a koji implementira ovu preporuku.', 'id': 'Minimal sentence pairs are frequently used to analyze the behavior of language models.  It is often assumed that model behavior on contrastive pairs is predictive of model behavior at large.  Kami menyangka bahwa dua syarat diperlukan untuk asumsi ini memegang: Pertama, hipotesis yang diuji harus diaktifkan dengan baik, karena eksperimen menunjukkan bahwa evaluasi kontras dapat menyebabkan positif palsu. Kedua, data ujian harus dipilih seperti untuk mengurangi diskrepansi distribusi antara waktu evaluasi dan waktu pengiriman. Untuk pendekatan yang baik dari dekoding deployment-time, kami merekomendasikan bahwa pasangan minimal diciptakan berdasarkan teks yang dibuat oleh mesin, dibandingkan dengan referensi yang ditulis oleh manusia. Kami mempersembahkan suite evaluasi kontras untuk MT Inggris-Jerman yang menerapkan rekomendasi ini.', 'cs': 'Minimální páry vět se často používají k analýze chování jazykových modelů. Často se předpokládá, že chování modelu u kontrastních párů je prediktivní pro chování modelu obecně. Tvrdíme, že pro tento předpoklad jsou nezbytné dvě podmínky: Za prvé, testovaná hypotéza by měla být dobře motivovaná, protože experimenty ukazují, že kontrastní hodnocení může vést k falešným pozitivním hodnocením. Za druhé, testovací data by měla být zvolena tak, aby minimalizovala distribuční nesrovnalost mezi dobou vyhodnocení a dobou nasazení. Pro dobrou aproximaci dekódování v době nasazení doporučujeme vytvořit minimální páry na základě strojově generovaného textu, na rozdíl od odkazů psaných člověkem. Představujeme kontrastní hodnotící sadu pro anglicko-německé MT, která toto doporučení implementuje.', 'af': "Minimale sê paar word dikwels gebruik om die gedrag van taal modelle te analiseer. Dit is dikwels aangeneem dat model gedrag op kontrastiewe paar is voorskoubaar van model gedrag op groot. Ons argumenteer dat twee voorwaardes nodig is vir hierdie aanvaardig om te hou: eerste moet 'n toets hipotees goed motiveer word, omdat eksperimente wys dat kontrastiewe evaluering kan lei na valse positiewe. Tweede, toets data moet gekies word soos om verspreidingstyd en verspreidingstyd te minimiseer. Vir 'n goeie nabyting van verwydering-tyd-dekodering, beveel ons dat minimale paar geskep word gebaseer op masjien genereerde teks, teen mens-skryfde verwysings. Ons stel 'n kontrastiewe evalueringssuite vir Engels-Duits MT wat hierdie rekening implementeer.", 'am': 'የቋንቋ ምሳሌዎችን ለማስተዋል የሚጠቀሙ የዝናብ ቃላት ሁለት እጥፍ ይጠቀማሉ፡፡ ብዙ ጊዜም በተቃዋሚ ሁኔታ ላይ የሞዴል ሁኔታ የሞዴል ሁኔታ ትልቅ ነው የሚል ይመስላል፡፡ ለዚህ አካባቢ ሁለት አካላት እንዲያቆሙ ያስፈልጋል ብለን እንከራከራለን፤ በመጀመሪያ የተፈተናው hypothesis መልካም እንዲሆን ይገባዋል፡፡ በሁለተኛውም ጊዜ እና በመስጠት ጊዜ መካከል የአካባቢውን ግንኙነት እንዲጎድል የመፈተኛ ዳታ ሊመረጥ ይገባዋል፡፡ ለሰው ጽሑፍ በተቃወመ የመሳሰል ጽሑፍ በመሠረት ላይ የተመሳሳይ እናስታውቃለን፡፡ ይህንን ምክንያት የሚያደርገውን እንግሊዘኛ-ጀርመን MT የሚቃወም የኢንጂልኛ-ጀርመን ጉዳይ እናቀርባለን፡፡', 'fi': 'Kielimallien käyttäytymisen analysointiin käytetään usein minimaalisia lausepareja. Usein oletetaan, että mallikäyttäytyminen kontrastipareilla ennustaa mallikäyttäytymistä yleisesti. Väitämme, että kaksi ehtoa ovat välttämättömiä tämän olettamuksen ylläpitämiseksi: Ensinnäkin testatun hypoteesin tulisi olla hyvin motivoitunut, koska kokeet osoittavat, että kontrastiivinen arviointi voi johtaa vääriin positiivisiin tuloksiin. Toiseksi testitiedot olisi valittava siten, että arviointiajan ja käyttöönottoajan välinen jakaumaero minimoidaan. Käyttöönottoajan dekoodauksen hyvän lähentämisen varmistamiseksi suosittelemme, että minimaaliset parit luodaan koneellisesti luodun tekstin perusteella, toisin kuin ihmiskirjoitetut viittaukset. Esittelemme englannin-saksan MT:lle kontrastiivisen arviointipaketin, joka toteuttaa tämän suosituksen.', 'et': 'Keelemudelite käitumise analüüsimiseks kasutatakse sageli minimaalseid lausepaare. Sageli eeldatakse, et mudeli käitumine kontrastsetel paaridel ennustab mudeli käitumist üldiselt. Väitame, et selle eelduse säilitamiseks on vaja kahte tingimust: esiteks peaks testitud hüpotees olema hästi motiveeritud, kuna eksperimendid näitavad, et kontrastiivne hindamine võib viia valepositiivseteni. Teiseks tuleks valida katseandmed nii, et hindamisaja ja kasutuselevõtu aja jaotuserinevus oleks minimaalne. Juurutamisaja dekodeerimise heaks ühtlustamiseks soovitame luua minimaalsed paarid masinagenereeritud tekstil, mitte inimkirjutatud viidetel. Esitame kontrastse hindamise komplekti inglise-saksa MT jaoks, mis rakendab seda soovitust.', 'ca': "Minimal sentence pairs are frequently used to analyze the behavior of language models.  Sovint es suposa que el comportament model en parelles contrastes és preditiu del comportament model en general. Afirmem que són necessàries dues condicions per mantenir aquesta suposició: primer, una hipòtesi testada hauria de ser ben motivada, ja que els experiments demostren que l'evaluació contrastiva pot portar a falsos positives. En segon lloc, s'ha de triar les dades de prova per tal de minimitzar la discrepancia distribucional entre el temps d'evaluació i el temps d'implantació. For a good approximation of deployment-time decoding, we recommend that minimal pairs are created based on machine-generated text, as opposed to human-written references.  Presentam una suite d'evaluació contrastantper a MT anglo-alemanya que implementa aquesta recomanació.", 'ha': "An yi amfani da nau'in maganar da aka ƙayyade ko da yawa a yi amfani da yin anayyar abun ayuka na harshe. It is often assumed that model behavior on contrastive pairs is predictive of model behavior at large.  Tuna faɗa cewa an buƙata mazaɓa biyu ne ga wannan zato da za'a yi damƙara: A farko, za'a iya tafiyar da wani hanyari da aka jarraba shi da alhẽri, dõmin jarrabai za'a nũna cewa muhimmin da ke iya ƙara ƙarya. Kijan da haka, za'a zãɓi data na jarraba kamar ƙara tsakanin lokaci da lokaci da ake saka. Ko da kyakkyawan kodi na lokaci, Munã shawarar da in an halitta nau'i biyu a kan karatun matsayin da aka ƙididdige shi, kafin da musamman mutane da aka rubuta. Tuna halatar da wata tufa mai ƙidãya wa MT na Ingiriya-Jarman da ke cika wannan shauri.", 'sk': 'Minimalni pari stavkov se pogosto uporabljajo za analizo vedenja jezikovnih modelov. Pogosto se domneva, da je obnašanje modela na kontrastnih parih napoved vedenja modela na splošno. Trdimo, da sta za to predpostavko potrebna dva pogoja: Prvič, testirana hipoteza mora biti dobro motivirana, saj eksperimenti kažejo, da kontrastna ocena lahko vodi do lažnih pozitivnih rezultatov. Drugič, izbrati je treba preskusne podatke, da se zmanjša distribucijska razlika med časom ocenjevanja in časom uvajanja. Za dobro približevanje dekodiranja v času uvajanja priporočamo ustvarjanje minimalnih parov na podlagi strojno ustvarjenega besedila, v nasprotju s človeškimi sklici. Predstavljamo kontrastno vrednotenje za angleško-nemško MT, ki izvaja to priporočilo.', 'jv': 'echoH e l l o space w o r l d periodHelloworldHello world drawable-action Awak dhéwé ngerti, akeh durung sing dibutuhke butuh gak nggawe sapané iki: First, a testied ipotes kudu beraksi luwih-luwih apik, sedhaya ke diperénksi maneh na kejahatan karo pak sing bisa basa sing oleh operasi layar Sayensi Ngawe Perintah Panjenengan langkung wigatining pangan-wigatahan pangan Awak dhéwé éntuk karo sistem sing kontribusi kanggo MT Inggris-German sing nyebutne kuwi nggawe sapa tarjamahan iki.', 'bo': 'ཆུང་ཆུང་བའི་ཚིག་རིགས་གཉིས་ཀྱིས་སྐད་རིགས་མིག་དཔེ་དབྱེ་ཞིབ་བྱེད་ན་ལག་ལེན་འཐབ་ཡོད། རྒྱུན་ལྡན་དང་མཐོ་བོ་དང་མིན་པའི་རྣམ་པ་གི་སྣང་ཚུལ་གྱི་མཐུན་རྐྱེན་ཚད་ཆེ་བའི་སྔོན་ཚུལ་རེད། འུ་ཅག་གིས་མཐོང་ཚིག་གཉིས་ཀྱིས་རྟོགས་པར་དགོས་མཁན་གནང་བ་ཡིན་མིན་འདུག གཉིས་པ། བརྟག ལྟ་བུའི་ཉེར་སྤྱོད་པའི་དུས་ཚོད་མཚམས་གཅིག་ཁར་བྱ་རིམ་ལ། འུ་ཅག་གིས་ཆུང་བའི་གཉིས་ཆུང་ཉུང་བའི་རྣམ་གྲངས་རྩོམ་འབྲི་བ་དང་མི་ ང་ཚོས་དབྱིན་ཡིག་དང་སྐད་ཡིག་ཆ་གསལ་ལྡན་གྱི་རྩོམ་འབྲེལ་གྱི་ཐབས་ཤེས་གཅིག་སྟོན་བྱེད་ཀྱི་ཡོད།', 'he': 'זוגות משפטים מינימליים משתמשים לעתים קרובות כדי לנתח את התנהגות של דוגמני שפה. לעתים קרובות ניתן להניח שההתנהגות של דוגמנים על זוגות בניגוד היא צפויה של התנהגות של דוגמנים בכלל. אנחנו מתווכחים ששני תנאים נחוצים כדי שההנחה הזו תחזיק: ראשית, היפותזיה מבוססת צריכה להיות מוטיבציה היטב, מכיוון שניסויים מראים שהעריכה בניגוד יכולה להוביל לחיובי שווא. שנית, נתונים מבחנים צריכים להיבחר כגון להפחית את ההחלטה ההפצה בין זמן ההערכה לבין זמן ההפעלה. עבור התקרבות טובה של פיקוד זמן ההפעלה, אנו ממליצים שיוצרו זוגות מינימליות מבוססות על טקסט שנוצר מהמכונה, בניגוד לתייחסות כתבות אנושיות. אנחנו מציגים סוויטה עריכה נגדית לאנגלית-גרמנית MT שמפעילה את המלצה הזו.'}
{'en': 'What Models Know About Their Attackers : Deriving Attacker Information From Latent Representations', 'es': 'Lo que los modelos saben sobre sus atacantes: derivar información de los atacantes de representaciones latentes', 'ar': 'ما تعرفه النماذج عن مهاجميها: استخلاص معلومات المهاجم من التمثيلات الكامنة', 'fr': 'Ce que les modèles savent de leurs attaquants\xa0: dériver des informations sur les attaquants à partir de représentations latentes', 'pt': 'O que os modelos sabem sobre seus invasores: derivando informações de invasores de representações latentes', 'ja': 'モデルが攻撃者について知っていること：潜在的な表現から攻撃者情報を導き出す', 'ru': 'Что модели знают о своих злоумышленниках: получение информации о злоумышленнике из скрытых представлений', 'zh': '模则攻击者知,取攻击者于潜', 'hi': 'मॉडल अपने हमलावरों के बारे में क्या जानते हैं: अव्यक्त प्रतिनिधित्व से हमलावर जानकारी प्राप्त करना', 'ga': 'A Bhfuil Samhlacha ar Eolas Faoin Lucht Ionsaithe acu: Eolas a Bhaint as Ionsaitheoirí Folaigh', 'el': 'Τι ξέρουν τα μοντέλα για τους επιτιθέμενους τους: Παράγοντας πληροφορίες επιτιθέμενων από λανθάνουσες αντιπροσωπείες', 'ka': 'რომელიც მოდელები იცოდნენ მათი დაკავშირების შესახებ: დაკავშირების ინფორმაცია შემდეგ გამოსახულებიდან', 'hu': 'Mit tudnak a modellek a támadóikról: a támadók információinak kiszárítása a későbbi reprezentációkból', 'kk': 'Өздерінің тіркелгендері туралы қандай үлгілер біледі: тіркелгендер мәліметін кейінгі таңбашалардан алу', 'lt': 'Ką modeliai žino apie jų puolėjus: informacijos apie puolėjus gavimas iš vėlesnių atstovybių', 'mk': 'What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations', 'ms': 'Apa yang Model tahu tentang penyerang mereka: Menerima Maklumat Penyerang Dari Perwakilan Kemudian', 'ml': 'അവയുടെ ആക്രമിക്കുന്നവരെക്കുറിച്ച് മോഡലുകള്\u200d', 'it': 'Cosa sanno i modelli sui loro attaccanti: Derivano informazioni sugli attaccanti dalle rappresentazioni latenti', 'pl': 'Co modele wiedzą o atakujących: pobieranie informacji o atakujących z ostatnich reprezentacji', 'ro': 'Ce știu modelele despre atacatorii lor: Derularea informațiilor atacatorilor din reprezentările laterale', 'mn': 'Загварууд тэдний халдваруудын тухай юу мэддэг вэ? Дараагийн үзүүлэлтийн халдваруудын мэдээлэл', 'no': 'Kva modeller kjenner om vedlegga sine: Hentar vedleggsinformasjon frå siste representasjonar', 'so': 'What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations', 'sv': 'Vad modeller vet om sina angripare: härleder angriparinformation från latenta representationer', 'ta': 'மோடம்', 'sr': 'Ono što Modeli znaju o njihovim napadačama: dobivanje informacija o napadačama iz poslednjih predstavljanja', 'mt': 'X’inhuma l-mudelli li jafu dwar l-Attakkaturi tagħhom: Id-Derivazzjoni ta’ Informazzjoni dwar l-Attakkatur minn Rappreżentazzjonijiet Aktar tard', 'ur': 'Models know what Models About Their Attacks: Getting Attacker Information From Latest Representations', 'si': 'මොඩේල් දන්නේ ඔවුන්ගේ ප්\u200dරදේශකය ගැන: අන්තිම ප්\u200dරදේශකයෙන් පිළිබඳින් පිළිබඳින් ප්\u200dරදේශ', 'vi': 'Những mẫu biết về các tổ chức tấn công: phát tán thông tin tấn công từ các đài phát triển gần', 'uz': 'Name', 'bg': 'Какво знаят моделите за нападателите си: извличане на информация за нападателите от латентни представителства', 'hr': 'Što Modeli znaju o njihovim napadačama: dobivanje informacija o napadačama iz posljednjih predstavljanja', 'nl': 'Wat modellen weten over hun aanvallers: aanvallerinformatie afleiden van latente vertegenwoordigingen', 'da': 'Hvad modeller ved om deres angribere: Aflede angriberinformation fra latente repræsentationer', 'id': 'Apa yang Model Tahu tentang Penyerang Mereka: Menerima Informasi Penyerang Dari Perwakilan Terkini', 'de': 'Was Modelle über ihre Angreifer wissen: Ableitung von Angreiferinformationen aus latenten Repräsentanzen', 'ko': '모형이 공격자에 대한 이해: 잠재적 표시에서 공격자 정보 얻기', 'fa': 'مدل\u200cها درباره\u200cی حمله\u200cهایشان می\u200cدانند: اطلاعات حمله\u200cکننده\u200cها از نمایش\u200cهای اخیر', 'sw': 'Kitu ambacho Model wanajua kuhusu washambuliaji wao: Taarifa zinazotokana na mwakilishi wa hivi karibuni', 'tr': 'Salgalary barada nusgala bilýän Modeller: Deriving Attacker Information From Later Representations', 'af': 'Watter Modelle ken oor hul aanhegsels: Ontvang aanhegsel inligting van Latent Voorstellings', 'am': 'ማወቅ ሞዴል ስለ ተሳታፊዎቹ የሚያውቅ ምንድር ነው: የሚያስጨንቃቂው መረጃ ከኋለኛው መልዕክቶች', 'az': 'Modell톛r onlar캼n istifad톛l톛ri haqq캼nda n톛 bilirl톛r: 쿮laq톛 m톛lumat캼 Son G칬st칲y칲nd톛n g톛lir', 'hy': 'What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations', 'bn': 'মোডেলরা তাদের আক্রমণকারীদের সম্পর্কে কি জানে: সাম্প্রতিক প্রতিক্রিয়া থেকে আক্রমণকারীর তথ্য প্র', 'bs': 'Koji modeli znaju o napadačama njihovim: dobivanje informacija o napadačama iz poslednjih predstavljanja', 'ca': 'El que els models saben sobre els seus atacants: Derivant informació sobre els atacants des de les últimes representacions', 'cs': 'Co modelové vědí o svých útočnících: Odvození informací o útočnících z latentních zastoupení', 'et': 'Mida modellid teavad oma ründajate kohta: ründajate info tuletamine hiljutistest esindustest', 'fi': 'Mitä mallit tietävät hyökkääjistään: Hyökkääjien tietojen saaminen latent-edustuksista', 'sq': 'What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations', 'sk': 'Kaj modeli vedo o svojih napadalcih: pridobivanje informacij o napadalcih iz zadnjih predstavitev', 'he': 'What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations', 'jv': 'Perintah sing model ngerti Perkara Kemerdekaan Panjenengan: dering Attacker Informasi Suggestih Kemerdekaan', 'ha': '@ action', 'bo': 'What Models Know About Their Attacks: Deriving Attacker Information From Later Representations'}
{'en': 'Adversarial attacks curated against NLP models are increasingly becoming practical threats. Although various methods have been developed to detect adversarial attacks, securing learning-based NLP systems in practice would require more than identifying and evading perturbed instances. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts. Specifically, given a piece of adversarial text, we hope to accomplish tasks such as localizing perturbed tokens, identifying the attacker’s access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm. Our contributions are as follows : we formalize the task of classifying attacker attributes, and create a benchmark on various target models from sentiment classification and abuse detection domains. We show that signals from BERT models and target models can be used to train classifiers that reveal the properties of the attacking algorithms. We demonstrate that adversarial attacks leave interpretable traces in both feature spaces of pre-trained language models and target models, making AACTA a promising direction towards more trustworthy NLP systems.', 'pt': 'Os ataques adversários com curadoria de modelos de PNL estão se tornando cada vez mais ameaças práticas. Embora vários métodos tenham sido desenvolvidos para detectar ataques adversários, proteger sistemas de PNL baseados em aprendizado na prática exigiria mais do que identificar e evitar instâncias perturbadas. Para resolver esses problemas, propomos um novo conjunto de tarefas de identificação de adversários, a Classificação de Atributos do Atacante via Análise Textual (AACTA), que tenta obter informações mais detalhadas sobre os atacantes a partir de textos adversários. Especificamente, dado um pedaço de texto adversário, esperamos realizar tarefas como localizar tokens perturbados, identificar o nível de acesso do invasor ao modelo de destino, determinar o mecanismo de evasão imposto e especificar o tipo de perturbação empregado pelo algoritmo de ataque. Nossas contribuições são as seguintes: formalizamos a tarefa de classificar os atributos do invasor e criamos um benchmark em vários modelos de destino dos domínios de classificação de sentimentos e detecção de abuso. Mostramos que sinais de modelos BERT e modelos alvo podem ser usados para treinar classificadores que revelam as propriedades dos algoritmos de ataque. Demonstramos que os ataques adversários deixam rastros interpretáveis em ambos os espaços de recursos de modelos de linguagem pré-treinados e modelos de destino, tornando o AACTA uma direção promissora para sistemas de PNL mais confiáveis.', 'ar': 'أصبحت الهجمات العدائية الموجهة ضد نماذج البرمجة اللغوية العصبية بشكل متزايد تهديدات عملية. على الرغم من تطوير طرق مختلفة لاكتشاف الهجمات العدائية ، فإن تأمين أنظمة معالجة اللغات الطبيعية القائمة على التعلم يتطلب في الممارسة العملية أكثر من تحديد الحالات المضطربة وتجنبها. لمعالجة هذه المشكلات ، نقترح مجموعة جديدة من مهام تحديد الخصوم ، تصنيف سمات المهاجم عبر التحليل النصي (AACTA) ، والتي تحاول الحصول على معلومات أكثر تفصيلاً حول المهاجمين من النصوص العدائية. على وجه التحديد ، بالنظر إلى جزء من النص العدائي ، نأمل في إنجاز مهام مثل توطين الرموز المضطربة ، وتحديد مستوى وصول المهاجم إلى النموذج المستهدف ، وتحديد آلية التهرب المفروضة ، وتحديد نوع الاضطراب الذي تستخدمه خوارزمية الهجوم. مساهماتنا هي كما يلي: نقوم بإضفاء الطابع الرسمي على مهمة تصنيف سمات المهاجم ، وإنشاء معيار على نماذج مستهدفة مختلفة من تصنيف المشاعر ومجالات اكتشاف إساءة الاستخدام. نوضح أنه يمكن استخدام الإشارات من نماذج BERT والنماذج المستهدفة لتدريب المصنفات التي تكشف عن خصائص الخوارزميات المهاجمة. نبرهن على أن الهجمات العدائية تترك آثارًا قابلة للتفسير في فضاءات الميزات لنماذج اللغة المدربة مسبقًا والنماذج المستهدفة ، مما يجعل AACTA اتجاهًا واعدًا نحو أنظمة معالجة اللغات الطبيعية الأكثر جدارة بالثقة.', 'fr': "Les attaques antagonistes organisées contre les modèles de PNL deviennent de plus en plus des menaces pratiques. Bien que diverses méthodes aient été développées pour détecter les attaques contradictoires, la sécurisation des systèmes de PNL basés sur l'apprentissage nécessiterait davantage que l'identification et l'évitement des instances perturbées. Pour résoudre ces problèmes, nous proposons un nouvel ensemble de tâches d'identification des adversaires, Attacker Attribute Classification via Textual Analysis (AACTA), qui tente d'obtenir des informations plus détaillées sur les attaquants à partir de textes contradictoires. Plus précisément, compte tenu d'un texte contradictoire, nous espérons accomplir des tâches telles que la localisation des jetons perturbés, l'identification du niveau d'accès de l'attaquant au modèle cible, la détermination du mécanisme d'évasion imposé et la spécification du type de perturbation utilisé par l'algorithme d'attaque. Nos contributions sont les suivantes\xa0: nous formalisons la tâche de classification des attributs des attaquants et créons une référence sur divers modèles cibles à partir de la classification des sentiments et des domaines de détection des abus. Nous montrons que les signaux des modèles BERT et des modèles de cibles peuvent être utilisés pour entraîner des classificateurs révélant les propriétés des algorithmes d'attaque. Nous démontrons que les attaques contradictoires laissent des traces interprétables à la fois dans les espaces de fonctionnalités des modèles linguistiques pré-entraînés et des modèles cibles, faisant de l'AACTA une direction prometteuse vers des systèmes de PNL plus fiables.", 'es': 'Los ataques adversarios seleccionados contra los modelos de PNL se están convirtiendo cada vez más en amenazas prácticas. Aunque se han desarrollado varios métodos para detectar ataques adversarios, asegurar los sistemas de PNL basados en el aprendizaje en la práctica requeriría más que identificar y evadir casos perturbados. Para abordar estos problemas, proponemos un nuevo conjunto de tareas de identificación de adversarios, Clasificación de atributos de atacantes mediante análisis textual (AACTA), que intenta obtener información más detallada sobre los atacantes a partir de textos contradictorios. Específicamente, dado un fragmento de texto contradictorio, esperamos realizar tareas como localizar los tokens perturbados, identificar el nivel de acceso del atacante al modelo objetivo, determinar el mecanismo de evasión impuesto y especificar el tipo de perturbación empleado por el algoritmo de ataque. Nuestras contribuciones son las siguientes: formalizamos la tarea de clasificar los atributos de los atacantes y creamos un punto de referencia en varios modelos de objetivos desde la clasificación de opiniones y los dominios de detección de abuso. Demostramos que las señales de los modelos BERT y los modelos objetivo se pueden utilizar para entrenar clasificadores que revelan las propiedades de los algoritmos de ataque. Demostramos que los ataques contradictorios dejan huellas interpretables tanto en los espacios de características de los modelos lingüísticos previamente entrenados como en los modelos objetivo, lo que convierte a AACTA en una dirección prometedora hacia sistemas de PNL más confiables.', 'ja': 'NLPモデルに対して策定された対抗攻撃は、ますます実用的な脅威となっています。 対抗攻撃を検出するための様々な方法が開発されているが、実際に学習ベースのNLPシステムを確保するには、撹乱されたインスタンスを特定し、回避する以上のことが必要である。 これらの問題に対処するために、新しい一連の対戦相手識別タスク、テキスト分析による攻撃者属性分類（ AACTA ）を提案します。これは、対戦相手のテキストから攻撃者に関するより詳細な情報を取得しようとするものです。 具体的には、対抗テキストを考慮して、摂動トークンのローカライズ、ターゲットモデルへの攻撃者のアクセスレベルの特定、課された回避メカニズムの決定、攻撃アルゴリズムで使用される摂動タイプの指定などのタスクを達成することを望みます。 私たちの貢献は次のとおりです。攻撃者の属性を分類するタスクを形式化し、センチメント分類と悪用検知ドメインからさまざまなターゲットモデルのベンチマークを作成します。 BERTモデルとターゲットモデルからの信号を使用して、攻撃アルゴリズムの特性を明らかにする分類子をトレーニングできることを示しています。 我々は、対抗攻撃が事前に訓練された言語モデルとターゲットモデルの両方の特徴空間に解釈可能な痕跡を残し、AACTAをより信頼できるNLPシステムに向かう有望な方向にすることを実証します。', 'hi': 'एनएलपी मॉडल के खिलाफ क्यूरेट किए गए प्रतिकूल हमले तेजी से व्यावहारिक खतरे बन रहे हैं। यद्यपि प्रतिकूल हमलों का पता लगाने के लिए विभिन्न तरीकों को विकसित किया गया है, व्यवहार में सीखने-आधारित एनएलपी प्रणालियों को सुरक्षित करने के लिए परेशान उदाहरणों की पहचान करने और बचने की तुलना में अधिक की आवश्यकता होगी। इन समस्याओं को हल करने के लिए, हम विरोधी पहचान कार्यों का एक नया सेट प्रस्तावित करते हैं, हमलावर विशेषता वर्गीकरण पाठ विश्लेषण (AACTA) के माध्यम से, जो प्रतिकूल ग्रंथों से हमलावरों के बारे में अधिक विस्तृत जानकारी प्राप्त करने का प्रयास करता है। विशेष रूप से, प्रतिकूल पाठ के एक टुकड़े को देखते हुए, हम परेशान टोकन का स्थानीयकरण, लक्ष्य मॉडल के लिए हमलावर के पहुंच स्तर की पहचान करने, लगाए गए अपवंचन तंत्र का निर्धारण करने और हमला करने वाले एल्गोरिथ्म द्वारा नियोजित क्षोभ प्रकार को निर्दिष्ट करने जैसे कार्यों को पूरा करने की उम्मीद करते हैं। हमारे योगदान निम्नानुसार हैं: हम हमलावर विशेषताओं को वर्गीकृत करने के कार्य को औपचारिक रूप देते हैं, और भावना वर्गीकरण और दुरुपयोग का पता लगाने वाले डोमेन से विभिन्न लक्ष्य मॉडल पर एक बेंचमार्क बनाते हैं। हम दिखाते हैं कि BERT मॉडल और लक्ष्य मॉडल से संकेतों का उपयोग क्लासिफायरों को प्रशिक्षित करने के लिए किया जा सकता है जो हमलावर एल्गोरिदम के गुणों को प्रकट करते हैं। हम प्रदर्शित करते हैं कि प्रतिकूल हमले पूर्व-प्रशिक्षित भाषा मॉडल और लक्ष्य मॉडल के दोनों फीचर स्पेस में व्याख्यायोग्य निशान छोड़ देते हैं, जिससे AACTA अधिक भरोसेमंद एनएलपी सिस्टम की ओर एक आशाजनक दिशा बन जाती है।', 'ru': 'Сопернические атаки, направленные против моделей NLP, становятся все более практическими угрозами. Хотя для обнаружения враждебных атак были разработаны различные методы, для обеспечения безопасности систем NLP, основанных на обучении, на практике потребуется нечто большее, чем выявление и уклонение от возмущенных случаев. Для решения этих проблем мы предлагаем новый набор задач идентификации злоумышленников - Attacker Attribute Classification via Textual Analysis (AACTA), который пытается получить более подробную информацию о злоумышленниках из текстов злоумышленников. В частности, учитывая фрагмент сопернического текста, мы надеемся выполнить такие задачи, как локализация возмущенных токенов, определение уровня доступа злоумышленника к целевой модели, определение механизма уклонения и определение типа возмущения, используемого атакующим алгоритмом. Наш вклад заключается в следующем: мы формализуем задачу классификации атрибутов злоумышленника и создаем эталон на различных целевых моделях из классификаций настроений и доменов обнаружения злоупотреблений. Показано, что сигналы от моделей BERT и целевых моделей могут быть использованы для обучения классификаторов, которые раскрывают свойства атакующих алгоритмов. Мы демонстрируем, что сопернические атаки оставляют интерпретируемые следы как в функциональных пространствах предварительно обученных языковых моделей, так и в целевых моделях, что делает AACTA перспективным направлением к более надежным системам NLP.', 'zh': 'NLP之对抗性攻,日益为实。 虽已开百术以检对抗性攻,在实践中保基于学者NLP非徒知规避扰之实也。 凡此诸事,举新敌之任,析(AACTA)攻击者类,试取攻击者于对抗性文之攻击者详细信息。 具体来说,给定一段对抗性文本,愿成诸如定位扰令牌,识攻击者访级,定规避机及指攻算法扰动之类。 我贡如下:我正定攻击者属性分类,并于情类滥用检测域中为诸模样创立基准测试。 所以然者,BERT之信,可以练攻算法之器也。 吾证明对抗性攻于豫教之言,空中有可释之迹,使AACTA为可信者NLP系之所欲。', 'ga': 'Tá méadú ag teacht ar bhagairtí praiticiúla ar ionsaithe sáraíochta a dhéantar ar mhúnlaí NLP. Cé gur forbraíodh modhanna éagsúla chun ionsaithe sáraíochta a bhrath, bheadh níos mó ag teastáil chun córais NLP atá bunaithe ar fhoghlaim a dhaingniú i gcleachtas ná cásanna suaite a aithint agus a sheachaint. Chun dul i ngleic leis na saincheisteanna seo, molaimid sraith nua de thascanna aitheantais naimhdeach, Aicmiú Tréithe Ionsaithe trí Anailís Téacsúil (AACTA), a dhéanann iarracht faisnéis níos mionsonraithe a fháil faoi na hionsaitheoirí ó théacsanna sáraíochta. Go sonrach, i bhfianaise píosa sáraíochta, tá súil againn tascanna a chur i gcrích mar chomharthaí suaite a logánú, leibhéal rochtana an ionsaitheora ar an tsamhail sprice a shainaithint, an mheicníocht imghabhála a fhorchuirtear a chinneadh, agus an cineál suaite a úsáideann an algartam ionsaithe a shonrú. Is iad seo a leanas ár rannchuidithe: déanaimid an tasc maidir le tréithe ionsaitheora a rangú ar bhonn foirmiúil, agus cruthaímid tagarmharc ar sprioc-mhúnlaí éagsúla ó na fearainn a bhaineann le haicmiú meon agus braite mí-úsáide. Léirímid gur féidir comharthaí ó mhúnlaí CRET agus samhlacha sprice a úsáid chun oiliúint a chur ar aicmitheoirí a nochtann airíonna na n-algartam ionsaitheach. Léirímid go bhfágann ionsaithe sáraíochta rianta inmhínithe sa dá ghné-spás de mhúnlaí teanga réamhoilte agus de mhúnlaí sprice, rud a fhágann go bhfuil AACTA ina threo geallta i dtreo córais NLP níos iontaofa.', 'el': 'Οι εχθρικές επιθέσεις εναντίον μοντέλων γίνονται όλο και περισσότερο πρακτικές απειλές. Παρά το γεγονός ότι έχουν αναπτυχθεί διάφορες μέθοδοι για την ανίχνευση εχθρικών επιθέσεων, η εξασφάλιση συστημάτων που βασίζονται στη μάθηση στην πράξη θα απαιτούσε περισσότερα από τον εντοπισμό και την αποφυγή διαταραγμένων περιπτώσεων. Για να αντιμετωπιστούν αυτά τα ζητήματα, προτείνουμε ένα νέο σύνολο εργασιών αναγνώρισης αντιπάλου, την ταξινόμηση χαρακτηριστικών επιτιθέμενου μέσω κειμενικής ανάλυσης (η οποία επιχειρεί να λάβει πιο λεπτομερείς πληροφορίες σχετικά με τους επιτιθέμενους από αντικρουόμενα κείμενα. Συγκεκριμένα, δεδομένης ενός αντικρουόμενου κειμένου, ελπίζουμε να επιτύχουμε εργασίες όπως ο εντοπισμός διαταραγμένων Tokens, ο εντοπισμός του επιπέδου πρόσβασης του επιτιθέμενου στο μοντέλο στόχου, ο προσδιορισμός του μηχανισμού αποφυγής που επιβάλλεται και ο προσδιορισμός του τύπου διαταραχής που χρησιμοποιείται από τον αλγόριθμο επίθεσης. Οι συνεισφορές μας είναι οι εξής: επισημοποιούμε το καθήκον της ταξινόμησης χαρακτηριστικών επιτιθέμενων και δημιουργούμε ένα σημείο αναφοράς σε διάφορα μοντέλα στόχων από την ταξινόμηση συναισθημάτων και τους τομείς ανίχνευσης κατάχρησης. Δείχνουμε ότι τα σήματα από μοντέλα και μοντέλα στόχων μπορούν να χρησιμοποιηθούν για την εκπαίδευση ταξινομητών που αποκαλύπτουν τις ιδιότητες των επιτιθέμενων αλγόριθμων. Αποδεικνύουμε ότι οι αντίπαλες επιθέσεις αφήνουν ερμηνευτά ίχνη τόσο στους χώρους χαρακτηριστικών των προ-εκπαιδευμένων γλωσσικών μοντέλων όσο και στα μοντέλα στόχων, καθιστώντας την μια ελπιδοφόρα κατεύθυνση προς πιο αξιόπιστα συστήματα NLP.', 'hu': 'Az NLP modellekkel szembeni ellenkező ellentámadások egyre inkább gyakorlati fenyegetéssé válnak. Bár különböző módszereket fejlesztettek ki az ellenséges támadások észlelésére, a tanulásalapú NLP rendszerek gyakorlati biztosítása többre lenne szükség, mint a zavaros esetek azonosítására és elkerülésére. Ezeknek a problémáknak a megoldása érdekében egy új ellenfélazonosító feladatokat javasolunk, a Támadó Attribute Classification by Textual Analysis (AACTA), amelyek megpróbálnak részletesebb információkat szerezni a támadókról ellenfél szövegekből. Konkrétan egy ellenséges szöveg alapján reméljük, hogy olyan feladatokat tudunk végrehajtani, mint a zavaros tokenek lokalizálása, a támadó hozzáférési szintjének azonosítása a célmodellhez, a kikerülési mechanizmus meghatározása, valamint a támadó algoritmus által alkalmazott zavarok típusának meghatározása. Hozzájárulásaink a következők: formalizáljuk a támadó attribútumok osztályozásának feladatát, és összehasonlítást hozunk létre különböző célmodellekre az érzelmek osztályozásából és a visszaélések észleléséről szóló tartományokból. Megmutatjuk, hogy a BERT modellekből és célmodellekből származó jelek felhasználhatók a támadó algoritmusok tulajdonságait feltáró osztályozók képzésére. Bemutatjuk, hogy az ellenséges támadások értelmezhető nyomokat hagynak az előre képzett nyelvi modellek és a célmodellek jellemzői területén, így az AACTA ígéretes irányt jelent a megbízhatóbb NLP rendszerek felé.', 'it': "Gli attacchi avversi curati contro i modelli NLP stanno diventando sempre più minacce pratiche. Sebbene siano stati sviluppati vari metodi per rilevare gli attacchi avversi, la sicurezza dei sistemi NLP basati sull'apprendimento nella pratica richiederebbe molto di più che identificare ed evitare le istanze perturbate. Per risolvere questi problemi, proponiamo una nuova serie di compiti di identificazione degli avversari, Classificazione degli attributi degli attaccanti tramite analisi testuale (AACTA), che tenta di ottenere informazioni più dettagliate sugli attaccanti dai testi avversari. Nello specifico, dato un pezzo di testo avversario, speriamo di realizzare compiti come la localizzazione dei token perturbati, l'identificazione del livello di accesso dell'attaccante al modello target, la determinazione del meccanismo di evasione imposto e la specifica del tipo di perturbazione utilizzato dall'algoritmo attaccante. I nostri contributi sono i seguenti: formalizziamo il compito di classificare gli attributi degli attaccanti e creiamo un benchmark su vari modelli target a partire dai domini di classificazione dei sentiment e rilevamento degli abusi. Mostriamo che i segnali provenienti da modelli BERT e modelli target possono essere utilizzati per formare classificatori che rivelano le proprietà degli algoritmi di attacco. Dimostriamo che gli attacchi avversi lasciano tracce interpretabili in entrambi gli spazi di modelli linguistici pre-addestrati e modelli target, rendendo AACTA una direzione promettente verso sistemi NLP più affidabili.", 'ka': 'NLP მოდელების განმავლობაში კონპერაციალური ატაკები უფრო მეტი ხდება პრაქტიკური დარჩენები. თუმცა განსხვავებული მეტოვები განვითარებულია განსაზღვრებისთვის განსაზღვრებისთვის, განსხვავებული NLP სისტემების განსაზღვრება პრაქტიკში უფრო მეტი იქნება, ვიდრე განსაზღვრება ამ პრობლემების შესახებ, ჩვენ ახალი ნაცემები ინდენტიფიკაციის რაოდენობების შესახებ, ატრიბუტის კლასიფიკაცია ტექსტულ ანალიზაციის გამოყენებაში, რომელიც უფრო დარწმუნდება ინფორმაციის მიღება გან განსაკუთრებულად, განსაკუთრებული ტექსტის ნაწილი, ჩვენ გვემედით დავაკეთოთ საქმედები, როგორც პერტურბულებული ტექსტულების ლოკალიზაცია, დაატარებელის მისაღების მისაღების დონე მოდელზე, განსაკუთრებული ექსტურაციის მექანსის განსაკუთრებული და გან ჩვენი დამატება იგივეა: ჩვენ კლასიფიკაცია ატრიბუტების ატრიბუტების კლასიფიკაცია და განსხვავებული მიზემის მოდელების სენტიმენტების კლასიფიკაციის და გამოცდილების კომენტების კლასიფიკაციის და გამ ჩვენ ჩვენ აჩვენებთ, რომ BERT მოდელების სიგნალები და მისაღების მოდელების გამოყენება შეიძლება გამოყენება კლასიფიკაციერების განახლებისთვის, რომლებიც აღმოჩენის ალგორიტე ჩვენ ევმონსტრებით, რომ განაცემებული ატაკიცებები განაცემებელი მონაცემებების ორივე განაცემებული ენების მოდელების და მიზემის მოდელების შორის გადასვლა, რომლებიც AACTA უფრო მეტად და', 'mk': 'Adversarial attacks curated against NLP models are increasingly becoming practical threats.  И покрај тоа што се развиени различни методи за детектирање на непријателски напади, обезбедувањето на NLP системите базирани на учење во практиката би барало повеќе од идентификување и избегнување на нервозни случаи. За да ги решиме овие прашања, предлагаме нов набор на противници идентификациски задачи, класификација на атрибутите на напаѓачот преку текстуална анализа (ААКТА), кои се обидуваат да добијат подетални информации за напаѓачите од противниците тексти. Специфично, со оглед на еден дел од противниот текст, се надеваме дека ќе извршиме задачи како што е локализацијата на нервираните симболи, идентификацијата на нивото на пристап на напаѓачот до моделот на метата, одредувањето на воведениот механизам на избегнување и спецификацијата на типот на пертурбирање употребен од алгор Нашите придонеси се како што следи: ја формализираме задачата за класификување на атрибутите на напаѓачите, и создаваме benchmark за различни метни модели од класификацијата на чувствата и домените за детекција на злоупотреба. Ние покажуваме дека сигналите од BERT моделите и метните модели може да се користат за обука на класификатори кои ги откриваат сопственостите на напаѓачките алгоритми. Демонстрираме дека противните напади оставаат интерпретабилни траги во двете области на предобучени јазички модели и метни модели, што ја прави ААКТА ветувачка насока кон подоверливи НЛП системи.', 'ms': 'Serangan musuh yang disembuhkan terhadap model NLP semakin menjadi ancaman praktik. Walaupun berbeza kaedah telah dikembangkan untuk mengesan serangan musuh, keselamatan sistem NLP berdasarkan pelajaran dalam praktek akan memerlukan lebih daripada pengenalan dan menghindari kes yang terganggu. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts.  Secara khusus, diberikan teks musuh, kami berharap untuk menyelesaikan tugas seperti mengelokalisasi token terganggu, mengenalpasti aras akses penyerang ke model sasaran, menentukan mekanisme penghindaran yang ditetapkan, dan menentukan jenis gangguan yang digunakan oleh algoritma penyerang. Our contributions are as follows: we formalize the task of classifying attacker attributes, and create a benchmark on various target models from sentiment classification and abuse detection domains.  Kami menunjukkan bahawa isyarat dari model BERT dan model sasaran boleh digunakan untuk melatih pengeklasifikasi yang mengungkap ciri-ciri algoritma menyerang. Kami menunjukkan bahawa serangan musuh meninggalkan jejak yang boleh diterangkan dalam kedua-dua ruang ciri-ciri model bahasa dan model sasaran yang dilatih-dilatih, menjadikan AACTA arah yang menjanjikan kepada sistem NLP yang lebih dipercayai.', 'lt': "Nepageidaujami išpuoliai prieš NLP modelius vis labiau tampa praktinėmis grėsmėmis. Nors buvo sukurti įvairūs prieštaringų išpuolių nustatymo metodai, siekiant praktiškai užtikrinti mokymosi pagrindu grindžiamas NLP sistemas reikėtų daugiau nei nustatyti ir išvengti sutrikdytų atvejų. Siekiant išspręsti šiuos klausimus, siūlome naują priešiškų identifikavimo užduočių rinkinį, Atakėjo požymių klasifikavimą per tekstinę analizę (AACTA), kuris bando gauti išsamesnę informaciją apie atakėjus iš priešiškų tekstų. Specifically, given a piece of adversarial text, we hope to accomplish tasks such as localizing perturbed tokens, identifying the attacker's access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm.  Mūsų indėlis yra toks: formalizuojame užduotį klasifikuoti užpuolėjo požymius ir sukuriame lyginamąjį tašką įvairiems tiksliniams modeliams iš jausmų klasifikavimo ir piktnaudžiavimo nustatymo sričių. Mes rodome, kad signalai iš BERT modelių ir tikslinių modelių gali būti naudojami klasifikatoriams, kurie atskleidžia atakos algoritmų savybes, treniruoti. Mes įrodome, kad priešingi išpuoliai palieka aiškinamuosius pėdsakus abiejose iš anksto parengtų kalbų modelių ir tikslinių modelių srityse, todėl AACTA yra pažadėjanti kryptis siekiant patikimesnių NLP sistemų.", 'ml': 'NLP മോഡലുകള്\u200dക്കെതിരായി മുമ്പുള്ള ആക്രമണങ്ങള്\u200d പ്രാകൃതിക ഭീഷണിയാകുന്നു. എതിരാളികളായ ആക്രമണങ്ങള്\u200d കണ്ടുപിടിക്കാന്\u200d വ്യത്യസ്ത രീതികള്\u200d സൃഷ്ടിച്ചിരിക്കുന്നുവെങ്കിലും, പഠിക്കുന്നതിന്റെ അടിസ്ഥാനമായ NLP സ ഈ പ്രശ്നങ്ങളെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു പുതിയ പ്രതിരോധത്തിന്റെ തിരിച്ചറിയാനുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രായശ്ചിത്തം ചെയ്യുന്നു. ടെക്സ് പ്രത്യേകിച്ച്, വിരോധമായ വാചകത്തിന്റെ ഒരു ഭാഗം കൊടുത്താല്\u200d, പെര്\u200dട്ടറ്റര്\u200dബെഡ് ചിഹ്നങ്ങള്\u200d പൂര്\u200dത്തിയാക്കുവാന്\u200d ഞങ്ങള്\u200d പ്രതീക്ഷിക്കുന്നു ഞങ്ങളുടെ ഭാഗ്യങ്ങള്\u200d ഇതില്\u200d നിന്നുള്ളതാണ്: ഞങ്ങള്\u200d ആക്രമണത്തിന്റെ ഗുണഗണങ്ങളെ വിശിഷ്ടമാക്കുന്നു ബെര്\u200dട്ടി മോഡലില്\u200d നിന്നും ലക്ഷ്യ മോഡലുകളില്\u200d നിന്നും സിഗ്നലുകള്\u200d കാണിച്ചുകൊടുക്കുന്നത് ആക്രമിക്കുന്ന ആല്\u200dഗോരിത്മുകളു നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് എതിരാളികളായ ആക്രമണങ്ങള്\u200d മുമ്പ് പഠിപ്പിക്കപ്പെട്ട ഭാഷ മോഡലുകളുടെ രണ്ട് സ്ഥലങ്ങളിലും വ്യക്തമാക്കുന്നതാണ്.', 'kk': 'NLP үлгілеріне қарсы белсендірілген белсендірушілер практикалық қорқыныштар болып жатқан. Тәртүрлі әдістер қарсы қалдыруды анықтау үшін жасалған, білім негізделген NLP жүйелерін қамтамасыз ету жүйелері әрекетінде анықтау және қалдыру үшін көбірек болады. Бұл мәселелерді шешу үшін біз жаңа қарсы идентификациялау тапсырмаларын, мәтіндік анализ (AACTA) арқылы аттрибут классификациясын, қарсы мәтіндер туралы жаңа тегжейлі мәліметті алу үшін ұсындық. Ескерілікті, қарсы мәтін бөлігін келтіріп, жергілікті таңбаларды жергіліктіру, атқарушының қатынау деңгейін мақсатты үлгіге қатынау деңгейін анықтау, орнатылған қалдыру механизмін анықтау және атқару алгоритма арқылы қолданылатын пертурбациялау Біздің қатынасыз осылай: біз атрибуттарды классификациялау тапсырмасын оқып, әртүрлі мақсатты үлгілерді сезімдердің классификациясынан және қорқынышты анықтау домендерінен түрлі мақсатты моделдерді Біз BERT үлгілерінен және мақсатты үлгілерден сигналдар алгоритмдердің қасиеттерін көрсетуге қолданылады. Біз қарсы жағдайларды көрсету үшін алдын- оқылған тіл үлгілері мен мақсатты үлгілерінің екеуі бойынша аударылатын іздеулерді қалдырып, AACTA- ға сенімді NLP жүйелерінің көмектесетін жағынан', 'mn': 'NLP загварын эсрэг дэмжигдсэн эсрэг дэмжигчийн дайралтууд үргэлж практикийн аюултай болж байна. Хэдийгээр олон арга зам зохион байгуулсан нь эсрэг атлаасыг олох, суралцах сургалтын НLP системийг дасгал хөдөлгөөнд зориулсан тохиолдолуудыг тодорхойлж, алдагдах нь илүү шаардлагатай. Эдгээр асуудлуудыг олохын тулд бид эсрэг тодорхойлолтын даалгаврын даалгаврын даалгаврын ажиллагааг, Textual Analysis (AACTA) аргаар Attacker Attribute Classification гэх мэт шинэ хэмжээний санал дэвшүүлдэг. Энэ нь эсрэг жагсаалтын текстүүдийн тухай ил Ялангуяа, эсрэг текст гэсэн үг бий болгоход бид зогсоогдсон тодорхойлолтуудыг олох, атлаачдын зорилго загварын хүртэлх түвшинд тодорхойлж, зорилго загварын үйлдвэрлэлийн механизмийг тодорхойлж, эсрэг алгоритмын ажиллагаанд ажилладаг перturbation төрлийг тодорхойлж чадна. Бидний нөлөөлөл нь дайрагч атрибутыг хичээлдэг, мэдрэмжтэй дүрслэлээс, зөрчилдөөнийг олон зорилготой загваруудыг бий болгож байна. Бид БЕРТ загвараас, зорилготой загваруудын сигналуудыг халдварлах алгоритмын шинж чанарыг илэрхийлж чадна гэдгийг харуулж байна. АACTA-г илүү итгэлтэй NLP системээс илүү итгэлтэй зам болгодог гэдгийг бид харуулж байна.', 'ro': 'Atacurile adverse curatate împotriva modelelor PNL devin din ce în ce mai mult amenințări practice. Deși au fost dezvoltate diferite metode pentru detectarea atacurilor adversare, asigurarea în practică a sistemelor PNL bazate pe învățare ar necesita mai mult decât identificarea și evitarea instanțelor perturbate. Pentru a rezolva aceste probleme, propunem un nou set de sarcini de identificare a adversarilor, Clasificarea atributelor de atac prin Analiză Textală (AACTA), care încearcă să obțină informații mai detaliate despre atacatori din texte adversare. Mai exact, având în vedere o bucată de text adversar, sperăm să realizăm sarcini precum localizarea jetoanelor perturbate, identificarea nivelului de acces al atacatorului la modelul țintă, determinarea mecanismului de evaziune impus și specificarea tipului de perturbare utilizat de algoritmul de atac. Contribuțiile noastre sunt următoarele: formalizăm sarcina de clasificare a atributelor atacatorilor și creăm un punct de referință pentru diferite modele țintă din domeniile de clasificare a sentimentelor și detectare a abuzurilor. Arătăm că semnalele de la modelele BERT și modelele țintă pot fi folosite pentru a instrui clasificatori care dezvăluie proprietățile algoritmilor de atac. Demonstrăm că atacurile adversare lasă urme interpretabile atât în spațiile caracteristice ale modelelor lingvistice pre-instruite, cât și modelelor țintă, făcând din AACTA o direcție promițătoare către sisteme NLP mai fiabile.', 'mt': "Adversarial attacks curated against NLP models are increasingly becoming practical threats.  Għalkemm ġew żviluppati diversi metodi biex jinstabu attakki avversarji, l-iżgurar ta’ sistemi NLP ibbażati fuq it-tagħlim fil-prattika jeħtieġ aktar milli l-identifikazzjoni u l-evażjoni ta’ każijiet imfixkla. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts.  B'mod speċifiku, minħabba test avversarju, nittamaw li twettaq kompiti bħall-lokalizzazzjoni ta' tokens imfixkla, l-identifikazzjoni tal-livell ta' a ċċess tal-attakkatur għall-mudell fil-mira, id-determinazzjoni tal-mekkaniżmu ta' evażjoni impost, u l-ispeċifikazzjoni tat-tip ta' perturbazzjoni użat mill-algoritmu tal-attakk. Il-kontribuzzjonijiet tagħna huma kif ġej: nifformalizzaw il-kompitu li nikklassifikaw l-attributi tal-attakki, u noħolqu punt ta’ riferiment fuq diversi mudelli fil-mira mill-klassifikazzjoni tas-sentimenti u d-dominji tal-identifikazzjoni tal-abbuż. We show that signals from BERT models and target models can be used to train classifiers that reveal the properties of the attacking algorithms.  We demonstrate that adversarial attacks leave interpretable traces in both feature spaces of pre-trained language models and target models, making AACTA a promising direction towards more trustworthy NLP systems.", 'pl': 'Ataki przeciwne kuratorskie wobec modeli NLP coraz częściej stają się praktycznymi zagrożeniami. Chociaż opracowano różne metody wykrywania ataków przeciwników, zabezpieczenie systemów NLP opartych na uczeniu się w praktyce wymagałoby więcej niż identyfikowanie i unikanie zakłóconych przypadków. Aby rozwiązać te problemy, proponujemy nowy zestaw zadań identyfikacji przeciwników, klasyfikację atrybutów atakujących za pomocą analizy tekstowej (AACTA), która próbuje uzyskać bardziej szczegółowe informacje o atakujących z tekstów przeciwników. W szczególności, biorąc pod uwagę fragment tekstu przeciwnego, mamy nadzieję wykonać zadania takie jak lokalizacja zakłóconych tokenów, identyfikacja poziomu dostępu atakującego do modelu docelowego, określenie narzuconego mechanizmu uchylania się oraz określenie typu zakłóceń stosowanego przez algorytm atakujący. Nasze wkłady są następujące: formalizujemy zadanie klasyfikacji atrybutów atakujących i tworzymy benchmark dla różnych modeli docelowych od klasyfikacji sentymentów i domen wykrywania nadużyć. Pokazujemy, że sygnały z modeli BERT i modeli docelowych mogą być wykorzystywane do treningu klasyfikatorów ujawniających właściwości algorytmów atakujących. Pokazujemy, że ataki przeciwne pozostawiają interpretowalne ślady zarówno w przestrzeni funkcjonalnych modeli językowych, jak i modeli docelowych, co czyni AACTA obiecującym kierunkiem w kierunku bardziej zaufanych systemów NLP.', 'no': 'Adversarial attacks curated against NLP models are increasingly becoming practical threats. Selv om forskjellige metoder er utvikla for å oppdaga adversariske attackar, vil læringsbaserte NLP-systemer i praksis kreve meir enn å identifisera og unngå avtrykk av avtrykk instansar. For å handtera desse problemene, foreslår vi ein ny set av mottakardidentifikasjonar, Attacker Attribute Classification via Tekstanalyse (AACTA), som prøver å få meir detaljert informasjon om atakarane frå negativ tekst. Spesielt, gitt ein del av negativ tekst, håper vi å fullføre oppgåver som lokalisering av perturberte teikn, identifisering av tilgang til målmodellen til attackeren, bestemmering av evasjonsmekanismen som er sett inn, og spesifisering av perturbasjonstypen som vert brukt av atalgoritmen. Vedlegginga våre er slik: me formaliserer oppgåva for å klassifisera attacker-attributtar, og lager ein benchmarke på ulike målmodeller frå sentimentklassifikasjon og oppdagingsdomene for bruk. Vi viser at signalar frå BERT-modeller og målmodeller kan brukast for å trene klassifikatorar som viser eigenskapane til brukalgoritmen. Vi demonstrerer at adversariske ataka forlate tolkbare spor i både funksjonar mellomrom av først trengte språk-modeller og målmodeller, og gjør AACTA ein promising retning mot meir tiltrudige NLP-systemer.', 'si': 'NLP නිර්මාණය විරුද්ධ විරුද්ධ විරුද්ධ විරුද්ධ විරුද්ධ විරුද්ධ විරුද්ධ විරුද්ධ වෙ විවිධ විදියට විශේෂ විදියට විස්තර කරලා තියෙන්නේ විරෝධ ප්\u200dරහාරයක් හොයාගන්න, ඉගෙන ගන්න අධික NLP පද්ධතිය සුරක මේ ප්\u200dරශ්නයක් ලැබීමට, අපි ප්\u200dරශ්නයක් අලුත් විරෝධ පරීක්ෂණ වැඩක් සම්බන්ධ කරනවා, Attacker Attribte Classication (AACTA) විශ්ලේෂණයෙන්, ඒක ප්\u200dරශ්නයක් වි විශේෂයෙන්, විරෝධ පාළුවේ කොටසක් දෙන්න, අපි හිතන්නේ ප්\u200dරමාණය කරනවා වැඩක් වගේ ස්ථානික විශ්වාස කරනවා වගේ, ප්\u200dරමාණකයාගේ ප්\u200dරවේශනය ස්ථානය කරනවා ඉලක්ෂිත මද අපේ සම්බන්ධයක් පස්සේ වෙනුවෙන්: අපි ප්\u200dරශ්නයක් විශ්වාස කරනවා ප්\u200dරශ්නයක් විශ්වාස කරනවා, සහ විවිදිහට ලක්ෂණ මොඩේල් වලින් ව අපි පෙන්වන්නේ BERT මොඩල් වලින් සහ ඉලක්ෂා මොඩල් වලින් සංඥාවල් ප්\u200dරයෝජනය කරන්න පුළුවන් විදිහට පරික්ෂා කරන්න අපි පෙන්වන්නේ විරෝධ විරෝධ විරෝධ විරෝධ විරෝධ වෙන්න පුළුවන් පරික්ෂාවක් දෙන්න පුළුවන් පරික්ෂාවක් තියෙන්නේ', 'sr': 'Adversarijski napadi koji su okrenuti protiv NLP modela postaju sve veće praktične prijetnje. Iako su razvijene različite metode za otkrivanje neprijateljskih napada, osiguranje sustava NLP na praksi na učenju potrebno bi više od identifikacije i izbjegavanja nevoljnih slučajeva. Za rješavanje tih problema predlažemo novi set neprijateljskih zadataka za identifikaciju, klasifikaciju atributa napadača preko tekstualne analize (AACTA), koji pokušava da dobije detaljnije informacije o napadačama iz neprijateljskih tekstova. Posebno, s obzirom na dio negativnog teksta, nadamo se da ćemo postići zadatak poput lokalizacije perturbiranih znakova, identificiranje nivoa pristupa napadača ciljnom modelu, utvrđivanje mehanizma za evaziju uvedenog i specificiranje vrsta perturbacije zaposlenog algoritmom napada. Naši doprinosi su sljedeći: formaliziramo zadatak klasifikacije atributa napadača i stvaramo kritiku o različitim ciljnim modelima iz klasifikacije sentimenta i detektivnih domena zlostavljanja. Pokazujemo da se signale iz BERT modela i ciljnih modela mogu koristiti za obuku klasifikatora koji otkrivaju vlasništvo napadajućih algoritma. Pokazujemo da neprijateljski napadi ostavljaju interpretabilne tragove u obje oblasti predobučenih jezičkih modela i ciljnih modela, čineći AACTA obećavajućim smjerom prema vjernijim NLP sistemima.', 'so': "Dagaalooyin hore oo ka gees ah samooyinka NLP waxey sii badnaan u noqdaan cabsi caadiga ah. In kastoo ay horumariyeen qaabooyin kala duduwan si ay u ogaato weerar cadaawayaasha ah, in lagu xaqiijiyo nidaamka waxbarashada ee lagu saleeyay ay ay u baahan yihiin in ka badan aqoonsashada iyo ka baxsada dhacdooyinka la xiriiray. Si aan arrimahan ula macaamiloono, waxaan u soo jeedinnaa saf cusub oo ka mid ah shaqooyin aqoonsiga cadaawayaasha, Shaqaalaha cadowga ah ee ku qoran Textual Analysis (AACTA), kaas oo isku dayaya in aad ka hesho macluumaad dheeraad ah oo ku saabsan waxqabayaasha ka soo jeeda qoraalka cadaawayaasha ah. Specifically, given a piece of adversarial text, we hope to accomplish tasks such as localizing perturbed tokens, identifying the attacker's access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm.  Sharciyadayadu waa sida soo socda: waxaynu sameynaa shaqada si aan u fasaxno shirkadaha dadka weerarka ka dhaca, waxaana sameynaynaa mid ku qoran tusaalooyin kala duduwan oo ku saabsan qaabilaada iyo meelaha loo baahdo isticmaalka. Waxaynu tusnaynaa in sawirada ka soo baxa modelalka BERT iyo modelalka waxqabadka waxaa loo isticmaali karaa in lagu baro fasaxyada ay muujiyaan hantida qoraalka weerarka. Waxaynu muujinnaa in Dagaallada cadaawayaasha ah ay ka tagaan calaamado turjuman labada meelood oo gaar ah oo ay ku leeyihiin tusaalaha afka hore lagu baray iyo modellada hagitaanka, waxaana AACTA ka dhiganaynaa hago ballan ah xagga nidaamka NLP oo aamin ah.", 'ur': 'NLP موڈلوں کے مقابلہ میں سرکشی حملہ اضافہ ہوتے ہیں اور اضافہ ہوتے ہیں کہ اضافہ اضافہ ہوتے ہیں۔ اگرچہ مختلف طریقے پیش کیے گئے ہیں کہ مخالف حملہ کو پہچان سکیں، سیکھنے کی بنیادی NLP سیستموں کو قائم کرنے کے لئے بہت زیادہ ضرورت ہے کہ مشکلات کو پہچان سکیں اور پریشان کریں۔ ان مسائلوں کے بارے میں ہم نے ایک نئی مخالف شناسایی کے کاموں کے ساتھ ایک مجموعہ پیش کرتا ہے، متن تحلیل (AACTA) سے Attacker Attribute Classification (Attacker Attribute Classification) کے ذریعہ، جو مخالف متن سے حملہ کرنے والوں کے بارے میں زیادہ مفصل معلومات حاصل کرنے کی کوشش کر خاص طور پر، مخالف ٹیکس کے ایک ٹکڑے کے ذریعہ سے، ہم امید رکھتے ہیں کہ ایسے کاموں کو پورا کریں جیسے ٹکڑے ٹیکنوں کو لوکائل کرنا، حملہ کرنے والے کے دسترس سطح کو مولڈ کے لئے پہچان کریں، مضبوط مکانیسم کا فیصلہ کریں، اور حملہ الگوریتم کے ذریعہ استعمال کیا گیا پرتربیٹ ٹیکس کا مث ہمارے حصے اسی طرح ہیں: ہم حملہ کے اثرات کا کلاس کریں اور مختلف موقعہ مدلکوں پر بینچم کریں، احساس کلاسیفوں اور اذیت کے ڈمین سے۔ ہم دکھاتے ہیں کہ BERT موڈل اور موڈل موڈل سے سیگنالیں کلاسپیر کو ٹرین کرنے کے لئے استعمال کر سکتے ہیں جو حملہ الگوریتم کے خصوصے ظاہر کرتے ہیں۔ ہم نشان دیتے ہیں کہ مقابلہ حملہ ان دونوں فرصت کی جگہ سے پہلے آموزش کی زبان مدلکوں اور موجود مدلکوں میں تفصیل قابل تعبیر کی جگہ چھوڑ دیتا ہے، اور AACTA کو زیادہ اعتماد رکھنے والی NLP سیستموں کی طرف وعدہ دینے والی سم', 'sv': 'Adversariattacker mot NLP-modeller blir alltmer praktiska hot. Även om olika metoder har utvecklats för att upptäcka motstridiga attacker, skulle det krävas mer än att identifiera och undvika störda fall att säkra inlärningsbaserade NLP-system i praktiken. För att åtgärda dessa problem föreslår vi en ny uppsättning uppgifter för identifiering av motståndare, Attacker Attribute Classification via Textual Analysis (AACTA), som försöker få mer detaljerad information om angriparna från motstridiga texter. Specifikt, med tanke på en bit av kontradiktorisk text, hoppas vi kunna utföra uppgifter som att lokalisera störda tokens, identifiera angriparens åtkomstnivå till målmodellen, fastställa den kringgående mekanism som införts och specificera den störningstyp som används av angripande algoritm. Våra bidrag är följande: Vi formaliserar uppgiften att klassificera angripare attribut och skapar ett riktmärke för olika målmodeller från sentiment klassificering och missbruksdetektering domäner. Vi visar att signaler från BERT-modeller och målmodeller kan användas för att träna klassificerare som avslöjar egenskaperna hos angripande algoritmer. Vi visar att fientliga attacker lämnar tolkningsbara spår i både funktionsutrymmen av pre-utbildade språkmodeller och målmodeller, vilket gör AACTA till en lovande riktning mot mer tillförlitliga NLP-system.', 'ta': 'NLP மாதிரிகளுக்கு எதிராக தடுக்கப்பட்ட முன்னாடிகள் செயல்படுத்தும் அச்சுறுத்தலாக இருக்கின்றன. எதிரிகளை கண்டுபிடிக்க பல முறைகள் உருவாக்கப்பட்டுள்ளது எனினும், பயிற்சியில் கற்றல் அடிப்படையான NLP முறைமைகளை பாதுகாப்பானாலும் குறிப் இந்த பிரச்சனைகளை நிர்வகிக்க, நாம் புதிய எதிரி அடையாள செயல்களை பரிந்துரைக்கிறோம், அடிக்கூடிய குணங்கள் உரை ஆராய்ச்சி( AACTA) மூலம், இது எதிர்மறை உரைகளில் இர குறிப்பிட்டு, எதிர்பார்க்கும் உரையின் துண்டு கொடுத்தால், நாங்கள் செயல்களை முடிக்க வேண்டும் என்று நம்புகிறோம், சுற்றுக்குறிப்பிட்ட குறியீடுகளை உள்ளமைக்க, சேர்க் எங்கள் செயல்கள் பின்வருகிறது: நாங்கள் விஷயங்களை வகைப்படுத்தும் பண்பை வடிவமைக்க, மற்றும் உணர்வு வகைப்படுத்தல் மற்றும் abuse கண்டுபிடிப்பு மூலங BERT மாதிரி மற்றும் இலக்கு மாதிரிகளிலிருந்து குறிக்குறிகளை காட்டுகிறோம் என்று காட்டுகிறோம் பிரிட்டி மாதிரிகளின நாம் எதிரிகள் தாக்குதல்கள் முன் பயிற்சி மொழி மாதிரிகள் மற்றும் இலக்கு மாதிரிகளின் இரண்டு குணங்களின் இடைவெளியிலும் விளக்கக்கூடிய தெரியும', 'uz': "Name Although various methods have been developed to detect adversarial attacks, securing learning-based NLP systems in practice would require more than identifying and evading perturbed instances.  Bu muammolarni boshqarish uchun, biz murojaat identifikatlarning yangi tashkilotlarini, Textal Analysis orqali Attribute Classification (AACTA) bilan foydalanishimizni istaysizmi. Agar tashkilotlar textlardan hamma haqida ko'proq maʼlumot olishni istaysizmi. Ko'rsatiladigan matnning bir qismlari bilan biz vazifalarni amalga oshirishingiz mumkin, vaqt modelini aniqlashni istasangiz, saqlash mechanisini aniqlash va harakat qilingan algoritm tomonidan ishlatilgan turini aniqlash. Biz qanday paytlarimiz esa: Biz BERT modellaridan signallarni ko'rsatishmiz mumkin, shamol algoritlarning xossalarini ko'rsatish mumkin. Biz taʼminlovchi tildan oldin foydalanilgan modellar va target modellarning joyida tarjima qilish imkoniyatlarini ko'rsatishimiz mumkin. AACTA yaxshi ishonch qiladigan NLP tizimga ishonch hosil qiladi.", 'vi': 'Những cuộc tấn công trái ngược với mẫu N.L. ngày càng trở nên nguy hiểm thực tế. Mặc dù đã được phát triển nhiều phương pháp để phát hiện các cuộc tấn công đối nghịch, nhưng để đảm bảo các hệ thống ngôn ngữ ngLP trong thực tế đòi hỏi nhiều hơn là xác định và tránh khỏi các trường hợp phiền phức. Để giải quyết các vấn đề này, chúng tôi đề nghị một loạt các nhiệm vụ nhận dạng đối thủ mới, tấn công hoá các kí hiệu phụ thông qua các phân tích Văn bản (AACTA). Cụ thể, dựa trên một đoạn văn bản đối nghịch, chúng tôi hy vọng có thể thực hiện các nhiệm vụ như phát hiện vật lưu động, xác định cấp độ truy cập của kẻ tấn công vào mô hình mục tiêu, xác định cơ chế trốn tránh được áp dụng, và xác định loại bất động do thuật to án tấn công dùng. Những đóng góp của chúng tôi là như sau đây: chúng tôi chính thức hoá nhiệm vụ phân loại các thuộc tính của tấn công, và tạo ra một điểm tiêu chuẩn trên các mẫu khác nhau từ các khu vực phân tích cảm xúc và lạm dụng. Chúng tôi cho thấy tín hiệu từ các mô hình BERT và các mô hình đích có thể được dùng để đào tạo các phân loại tiết lộ tính chất của các thuật to án tấn công. Chúng tôi đã chứng minh các cuộc tấn công đối nghịch để lại dấu vết dễ hiểu ở cả hai khu vực có các mô hình ngôn ngữ được huấn luyện trước và các mô hình tiêu chuẩn, biến AACTA thành một hướng hứa hẹn dẫn tới hệ thống lập NLP đáng tin hơn.', 'bg': 'Рекламните атаки срещу моделите на НЛП все повече се превръщат в практически заплахи. Въпреки че са разработени различни методи за откриване на противоречиви атаки, осигуряването на базирани на учене системи за НЛП на практика би изисквало повече от идентифициране и избягване на смущени случаи. За да се справим с тези проблеми, предлагаме нов набор от задачи за идентифициране на противника, Класификация на атрибутите на атакуващия чрез текстов анализ (ААКТА), който се опитва да получи по-подробна информация за нападателите от съпернически текстове. По-конкретно, като се има предвид част от конкуренционен текст, се надяваме да изпълним задачи като локализиране на смущени токени, идентифициране на нивото на достъп на нападателя до целевия модел, определяне на наложения механизъм за избягване и определяне на типа смущения, използван от атакуващия алгоритъм. Нашите приноси са както следва: формализираме задачата за класифициране на атрибутите на нападателя и създаваме референтна база за различни целеви модели от класификация на сентименти и домейни за откриване на злоупотреби. Показваме, че сигналите от модели и целеви модели могат да бъдат използвани за обучение на класификатори, които разкриват свойствата на атакуващите алгоритми. Ние демонстрираме, че съперническите атаки оставят интерпретирани следи както в функционалните пространства на предварително обучените езикови модели, така и в целевите модели, което прави ААКТА обещаваща посока към по-надеждни системи за НЛП.', 'da': 'Adversariangreb kurateret mod NLP-modeller bliver i stigende grad praktiske trusler. Selvom der er udviklet forskellige metoder til at opdage modstridende angreb, ville sikring af læringsbaserede NLP-systemer i praksis kræve mere end at identificere og undgå forstyrrede tilfælde. For at løse disse problemer foreslår vi et nyt sæt af fjenderidentifikationsopgaver, Attacker Attribute Classification via Textual Analysis (AACTA), der forsøger at få mere detaljerede oplysninger om angriberne fra modstandstekster. Specifikt, givet et stykke modstridende tekst, håber vi at udføre opgaver som lokalisering af forstyrrede tokens, identificering af angriberens adgangsniveau til målmodellen, bestemmelse af undvigelsesmekanismen pålagt og angivelse af den forstyrrelsestype, der anvendes af angribende algoritme. Vores bidrag er som følger: Vi formaliserer opgaven med at klassificere angriber attributter og skaber en benchmark på forskellige målmodeller fra sentiment klassificering og misbrug detektion domæner. Vi viser, at signaler fra BERT modeller og målmodeller kan bruges til at træne klassificere, der afslører egenskaberne af de angribende algoritmer. Vi demonstrerer, at modstridende angreb efterlader fortolkelige spor i både funktionsrum af prætrænede sprogmodeller og målmodeller, hvilket gør AACTA til en lovende retning mod mere pålidelige NLP-systemer.', 'nl': 'Tegenstrijdige aanvallen op NLP-modellen worden steeds meer praktische bedreigingen. Hoewel er verschillende methoden zijn ontwikkeld om tegenstrijdige aanvallen op te sporen, zou het veiligstellen van leergebaseerde NLP-systemen in de praktijk meer vereisen dan het identificeren en ontwijken van gestoorde instanties. Om deze problemen aan te pakken, stellen we een nieuwe reeks taken voor om tegenstanders te identificeren, Attacker Attribute Classification via Textual Analysis (AACTA), die probeert om meer gedetailleerde informatie over de aanvallers te verkrijgen uit tegenstrijdige teksten. Met name hopen we, gezien een stuk tegenstrijdige tekst, taken uit te voeren zoals het lokaliseren van verstoorde tokens, het identificeren van het toegangsniveau van de aanvaller tot het doelmodel, het bepalen van het opgelegde ontwijkingsmechanisme en het specificeren van het verstoorde type gebruikt door het aanvallende algoritme. Onze bijdragen zijn als volgt: we formaliseren de taak van het classificeren van aanvallerattributen en maken een benchmark op verschillende doelmodellen van sentiment classificatie en misbruikdetectie domeinen. We laten zien dat signalen van BERT modellen en doelmodellen kunnen worden gebruikt om classificatoren te trainen die de eigenschappen van de aanvallende algoritmen onthullen. We tonen aan dat tegenstrijdige aanvallen interpreteerbare sporen achterlaten in zowel kenmerkruimten van voorgetrainde taalmodellen als doelmodellen, waardoor AACTA een veelbelovende richting is naar betrouwbaardere NLP-systemen.', 'hr': 'Preporučni napadi koji su okrenuti protiv modela NLP postaju praktične prijetnje. Iako su razvijene različite metode za otkrivanje neprijateljskih napada, osiguranje sustava NLP-a na učenju u praksi zahtijevalo bi više od identifikacije i izbjegavanja uznemirenih slučajeva. Za rješavanje tih pitanja predlažemo novi set neprijateljskih zadataka za identifikaciju, klasifikaciju atributa napadača preko tekstualne analize (AACTA), koji pokušava dobiti detaljnije informacije o napadačama iz neprijateljskih tekstova. Posebno, s obzirom na dio neprijateljskog teksta, nadamo se da ćemo postići zadatke poput lokalizacije perturbiranih znakova, identificiranje razine pristupa napadača ciljnom modelu, utvrđivanje mehanizma uvođenog izbjegavanja i specificiranje vrsta perturbacije zaposlenog algoritmom napada. Naši doprinosi su sljedeći: formaliziramo zadatak klasifikacije atributa napadača i stvaramo kritiku o različitim ciljnim modelima iz domena klasifikacije osjećaja i otkrivanja zlostavljanja. Pokazujemo da se signali iz BERT modela i ciljnih modela mogu koristiti za treniranje klasifikatora koji otkrivaju vlasništvo napadajućih algoritma. Pokazujemo da neprijateljski napadi ostavljaju interpretabilne tragove u obje karakteristične prostore predobučenih jezičkih modela i ciljnih modela, čineći AACTA obećavajućim smjerom prema vjernijim NLP sustavima.', 'de': 'Gegensätzliche Angriffe gegen NLP-Modelle werden zunehmend zu praktischen Bedrohungen. Obwohl verschiedene Methoden entwickelt wurden, um gegnerische Angriffe zu erkennen, würde die Sicherung lernbasierter NLP-Systeme in der Praxis mehr erfordern, als gestörte Instanzen zu identifizieren und zu umgehen. Um diese Probleme zu beheben, schlagen wir eine neue Reihe von Aufgaben zur Identifizierung von Gegnern vor, die Angreifer Attribute Classification via Textual Analysis (AACTA), die versucht, detailliertere Informationen über die Angreifer aus gegnerischen Texten zu erhalten. Insbesondere hoffen wir, mit einem Stück gegnerischem Text Aufgaben wie die Lokalisierung gestörter Token, die Identifizierung des Zugriffsniveaus des Angreifers auf das Zielmodell, die Bestimmung des erzwungenen Ausweichmechanismus und die Angabe des Störungstyps des Angriffsalgorithmus zu erfüllen. Unsere Beiträge sind wie folgt: Wir formalisieren die Aufgabe der Klassifizierung von Angreifer-Attributen und erstellen einen Benchmark für verschiedene Zielmodelle aus Sentiment-Klassifizierung und Missbrauchserkennung Domänen. Wir zeigen, dass Signale aus BERT-Modellen und Zielmodellen genutzt werden können, um Klassifikatoren zu trainieren, die die Eigenschaften der Angriffsalgorithmen aufzeigen. Wir zeigen, dass feindliche Angriffe sowohl in Funktionsräumen von vortrainierten Sprachmodellen als auch in Zielmodellen interpretierbare Spuren hinterlassen, was AACTA zu einer vielversprechenden Richtung hin zu vertrauenswürdigeren NLP-Systemen macht.', 'fa': 'حمله های مخالفی که در مقابل مدل های NLP مشغول شده، بیشتر تهدید های عملی می شوند. اگرچه روش\u200cهای مختلف برای شناسایی حمله\u200cهای دشمنی توسعه شده\u200cاند، امنیت سیستم\u200cهای NLP بر اساس یادگیری در تمرین بیشتر از شناسایی و فرار از مواقع\u200cهای مشکل نیاز دارد. برای حل این مسائل، ما یک مجموعه جدید از مسائل شناسایی دشمنی را پیشنهاد می\u200cکنیم، گروه\u200cشناسایی ویژه\u200cهای متن (AACTA) که سعی می\u200cکند اطلاعات بیشتری در مورد حمله\u200cکنندگان از متن\u200cهای دشمنی بگیرد. به طور خاص، با توجه به یک قطعه از متن مخالف، امیدواریم کارهایی را انجام دهیم که مثل محلی کردن نشانه\u200cهای ناراحت شده، دسترسی سطح حمله\u200cکننده به مدل هدف شناسایی می\u200cکنیم، تعیین کردن مکانیسم تخلیه شده و مشخص کردن نوع ناراحتی که توسط الگوریتم حمله می\u200cکند. دسترسي ما اينطوري هستند: ما وظيفه\u200cي تحليل کردن آبروهات حمله\u200cکننده\u200cها را رسمي\u200cسازيم، و يه نقشه بر مدل\u200cهاي مختلف هدف\u200cهايي از محل\u200cهاي شناسايي احساسات و تجاوز استفاده مي\u200cکنيم. ما نشان می دهیم که سیگنال های مدل BERT و مدل هدف می توانند برای آموزش راهنمایی که ویژه های الگوریتم حمله را نشان می دهند استفاده می شوند. ما نشان می دهیم که حمله های دشمنی در هر دو فضایی از مدل های پیش آموزش زبان و مدل های هدف را ترک می کنند، و AACTA را یک مسیر قول دهنده به سوی سیستم های NLP قابل اعتماد بیشتری قرار می دهد.', 'id': "Serangan musuh yang diselesaikan terhadap model NLP semakin menjadi ancaman praktis. Meskipun berbagai metode telah dikembangkan untuk mendeteksi serangan musuh, mengamankan sistem NLP berbasis belajar dalam praktek akan membutuhkan lebih dari mengidentifikasi dan menghindari kasus yang mengganggu. Untuk mengatasi masalah ini, kami mengusulkan set baru tugas identifikasi musuh, Klasifikasi Attribut Serangan melalui Analisi Tekstil (AACTA), yang mencoba untuk mendapatkan informasi terperinci tentang penyerang dari teks musuh. Specifically, given a piece of adversarial text, we hope to accomplish tasks such as localizing perturbed tokens, identifying the attacker's access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm.  Kontribusi kami adalah seperti ini: kami formalisasi tugas untuk mengklasifikasi atribut penyerang, dan menciptakan benchmark pada berbagai model sasaran dari klasifikasi sentimen dan domain deteksi penyalahgunaan. We show that signals from BERT models and target models can be used to train classifiers that reveal the properties of the attacking algorithms.  Kami menunjukkan bahwa serangan musuh meninggalkan jejak yang dapat diterjemahkan di kedua ruang karakteristik model bahasa dan model sasaran terlatih, membuat AACTA arah yang berjanji menuju sistem NLP yang lebih dipercaya.", 'sw': 'Mashambulizi ya awali yanayozuiwa dhidi ya mifano ya NLP yanaongezeka kuwa vitisho vya kihalisi. Ingawa mbinu mbalimbali zimeandaliwa kutambua mashambulizi yanayopinga, kuhakikisha mfumo wa kujifunza wenye msingi wa NLP unahitaji zaidi ya kutambua na kuepuka matukio yanayohusika. Ili kuzungumzia masuala haya, tunapendekeza shughuli mpya za kutambua upinzani, Mpango wa Shambulizi kupitia Uchambuzi wa Kiteknolojia (AACTA), ambazo zinajaribu kupata taarifa zaidi kuhusu washambuliaji kutoka kwenye maandishi yanayopinga. Kwa hakika, kwa kutumia makala ya maandishi yanayopingana, tunatumaini kutekeleza kazi kama vile kuweka alama zilizotengwa, kutambua kiwango cha upatikanaji wa shambulio hilo kwa muundo wa lengo, kuamua mfumo wa kuhama uliwekwa, na kutambua aina ya ubaguzi uliotumiwa na algorithi ya mashambulizi. Mchango wetu ni kama ifuatavyo: tunatengeneza jukumu la kutangaza sifa za mashambulizi, na kutengeneza bendera kwenye mitindo mbalimbali ya malengo kutoka kwenye maeneo ya kutambua hisia na unyanyasaji. We show that signals from BERT models and target models can be used to train classifiers that reveal the properties of the attacking algorithms.  Tunaonyesha kwamba mashambulizi yanayopinga yanaacha ufuatiliaji wa tafsiri katika maeneo yote ya mifano ya lugha na mifano ya malengo ya awali, na kuifanya AACTA kuwa mwelekeo wa kuahidini kuelekea mfumo wa NLP wenye kuaminika zaidi.', 'sq': 'Sulmet kundërshtare të kuruara kundër modeleve NLP po bëhen gjithnjë e më tepër kërcënime praktike. Megjithëse janë zhvilluar metoda të ndryshme për të zbuluar sulme kundërshtare, sigurimi i sistemeve NLP bazuar në mësim në praktikë do të kërkojë më shumë se identifikimi dhe shmangimi i rasteve të shqetësuara. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts.  Veçanërisht, duke dhënë një pjesë teksti kundërshtar, shpresojmë të kryejmë detyra të tilla si lokalizimi i tokenave të shqetësuara, identifikimi i nivelit të hyrjes s ë sulmuesit në modelin objektiv, përcaktimi i mekanizmit të evazionit të imponuar dhe përcaktimi i tipit të shqetësimit të përdorur nga algoritmi sulmues. Kontributet tona janë si pason: ne formalizojmë detyrën e klasifikimit të atributeve të sulmuesit dhe krijojmë një pikë referimi mbi modele të ndryshme objektive nga klasifikimi i ndjenjave dhe domenet e zbulimit të abuzimit. Ne tregojmë se sinjalet nga modelet BERT dhe modelet objektiv mund të përdoren për të trajnuar klasifikuesit që zbulojnë pronësitë e algoritmeve sulmuese. We demonstrate that adversarial attacks leave interpretable traces in both feature spaces of pre-trained language models and target models, making AACTA a promising direction towards more trustworthy NLP systems.', 'tr': 'NLP modellerine garşy nusgalar praktik tehditlere üýtgeýär. NLP sistemalary praktikada öwrenmek we çykarmak üçin birnäçe döwletler guruldy. Bu meseleleri çözmek üçin, biz rakip kimliklendirme görevlerini, Tekst Analizi (AACTA) yönünde salgıcılar hakkında daha detay bilgi almak isleýäriz. Adatça, täsirli metin bölegi berildi, üstünçisiniň golaý düzedilerine ulaşan işleri ýerine ýetirmek üçin umyt edýäris we golaý algoritmy tarapyndan işledilen perturbasyn hilini takyklaýarys. Biziň täsirlerimiz şol şekilde: agresçy atributlary klasifikasy we duýgularyň klasifikasy we hasaplamak alanlarynyň farklı maksady nusgalaryna düzenleýäris. BERT modellerinden we maksadat modellerinden sygnallaryň salmagyň algoritmalarynyň häsiýetlerini görkezmek üçin ulanylýandygyny görkezýäris. Biz çykyş salyplaryň her iki özellik üçin öň-okuwçy dil nusgalarynyň we maksady nusgalarynyň terjime edilebilir işaretlerden çykyp barýandygyny görkeýäris. AACTA-nyň NLP sistemalarynyň has ynamly yönünde söz berýän ýoly.', 'af': "Adversariële atake wat teen NLP-modelles opgevoer word, word vergroot praktiese bedroefde. Alhoewel verskillende metodes is ontwikkeld om teenstandaarlike atake te ontdek, sal die seker van lêersgebaseerde NLP stelsels in praksie meer as die identifiseer en verdwyn van perturbeerde voorbeelde. Om hierdie probleme te raak, voorstel ons 'n nuwe stel van teëstandige identifikasie-taak, Attacker Attribute Klassifikasie deur Tekstuele Analisie (AACTA), wat probeer om meer gedetale inligting te kry oor die atakers van teëstandige teks. Spesifieke, gegee 'n stuk teëstanderde teks, hoop ons om taak te voldoen soos plaaslike perturbeerde tekens, die toegang vlak van die ataker se toegang tot die doel model te identifiseer, die geïnstalleerde evasione-mekanisme te bepaal en die perturbasie-tipe wat deur die atalgoritme gebruik word. Ons bydraaiïngs is soos volgende: ons formaliseer die taak van die klassifisering van atakers-eienskappe en skep 'n benchmark op verskeie doel modele van sentiment klassifisering en miskiedenis-domene. Ons wys dat signale van BERT modele en doel modele gebruik kan word om klassifiseerders te trein wat die eienskappe van die atake algoritme vertoon word. Ons wys dat teenstandaarde atake verlaat uitleggbare spore in beide funksie spasies van voor-opgelei taal modele en doel modele, maak AACTA 'n beloftelike rigting tot meer vertroubare NLP stelsels.", 'hy': 'ՆԼՊ մոդելների դեմ դառնում են ավելի ու ավելի գործնական սպառնալիքներ: Չնայած տարբեր մեթոդներ են զարգացել հակառակ հարձակումների հայտնաբերելու համար, սովորելով հիմնված ՆԼՊ համակարգերի ապահովման գործընթացքում ավելի շատ կպահանջի, քան անհանգստացված դեպքերի հայտնաբերման և խուսափման: Այս խնդիրներին լուծելու համար մենք առաջարկում ենք հակառակորդ հայտնաբերման խնդիրների նոր շարք, Ահարձակի առանձնահատկությունների դասակարգման տեքստային վերլուծության միջոցով (AACT), որոնք փորձում են ավելի մանրամասն տեղեկատվություն ստանալ հարձակիչների մասին հակառակորդ տեքստների Մասնավորապես, հակառակ տեքստի մի մասի առնելով, մենք հույս ունենք կատարել այնպիսի խնդիրներ, ինչպիսիք են, օրինակ, խեղճված նշանները տեղադրելը, հարձակողի հասանելիության մակարդակը նշանակելը նպատակի մոդելի վրա, որոշումը, թե ինչպես է ներդրված խուսափման մեխանիզմը, և նշանակ Մեր ներդրումները հետևյալն են. մենք ձևափոխում ենք հարձակողի առանձնահատկությունների դասակարգումը և ստեղծում ենք համեմատային նպատակ տարբեր նպատակային մոդելների վրա զգացմունքների դասակարգումը և չարաշահումների հայտնաբերման Մենք ցույց ենք տալիս, որ BER մոդելների և նպատակային մոդելների ազդանշանները կարող են օգտագործվել դասակարգերի վարժեցնելու համար, որոնք բացահայտում են հարձակվող ալգորիթմների հատկությունները: Մենք ցույց ենք տալիս, որ հակառակորդ հարձակումները թողնում են մեկնաբանելի հետքեր նախկինում պատրաստված լեզվի մոդելների և նպատակային մոդելների երկու հատկավոր տարածքներում, դարձնելով AACT-ը խոստացող ուղղություն ավելի վստահելի ՆԼՊ համակարգերի', 'az': "NLP modellərinə qarşı müharibə saldıqları müharibə saldıqları təhdidlərə daha da artırar. Müxtəlif metodlar düşmənçilik saldıqlarını keşfetmək üçün tədbir edilmiş olsa da, öyrənmək sistemlərinə tətbiq edilən NLP sistemlərini təhsil etmək üçün daha çox çətin olar. Bu məsələlərdən çəkinmək üçün yeni düşmənçilik təsdiqləməsi üçün, Textual Analysis (AACTA) vasitəsilə Attacker Attribute Classification təsdiqlənməsini təklif edirik ki, düşmənçilər barəsində daha detalı məlumat almaq istəyirlər. Özellikle, düşmənçilik mətnlərin bir parça s ını təsdiqlədiyimiz kimi məlumatları yerinə yetirmək üçün ümid edirik, düşmənçinin mətn modelinin istifadə etməsini təsdiqlədiyimiz məlumatları təsdiqlədiyimiz və saldırma algoritmi vasitəsilə istifadə edilmiş perturbasyon türünü təsdiqlədiyimizi təsdiqləyirik. Bizim səbəblərimiz beləcə: saldırıcı qüdrətlərini dəyişdirmək və hisslərin klasifikasiyasından və istisna etmək domenalarından müxtəlif məqsədil modellərində bir benchmark yaratmaq işidik. Biz BERT modellərin və məqsəd modellərin sinyallərini saldırma algoritminin özelliklərini göstərən klassifikləri təhsil etmək üçün istifadə edə bilərik. Biz göstəririk ki, düşmənçilik saldıqları hər ikisinin əvvəl təhsil edilmiş dil modellərin və məqsəd modellərin istifadə edilə biləcəyi tərzlərin hər ikisinin istifadə edilməsi üçün AACTA'ya daha güvenilir NLP sistemlərinin tərəfində vəd verici yolu göstərir.", 'am': 'Adversarial attacks curated against NLP models are increasingly becoming practical threats.  ምንም እንኳን በተቃዋሚ ጉዳት ለማግኘት የልዩ ሥርዓቶች ተዘጋጅተዋል፣ የግንኙነት የNLP ስርዓት ማግኘት እና የተለየ ሁኔታዎችን ከመታወቅ ይልቅ ያስፈልጋል፡፡ እነዚህን ጉዳዮች ለመጠየቅ አዲስ የአካባቢ ማወቂያ ስራዎችን እናሳልጋለን፣ በቴክስቲትሁል Analysis (AACTA) እና በተቃዋሚ ጽሑፎች ላይ የተጋጠሙትን የግልጽ መረጃ ለማግኘት ይፈልጋል፡፡ በተለይም፣ በተቃዋሚ ጽሑፍ ክፍል በተሰጠ፣ እንደተጨማሪው ምልክቶች ማግኘት እናስፈልጋለን፡፡ አካሄዳችን እንደ ተጨማሪው ነው፤ የጋዜጠኞች ምርጫዎችን ለማሳመር እናደርጋለን፤ በተለያዩ አካባቢ ዓይነቶች ላይ በተለያዩ አካባቢ እና ከስሜት መግለጫ እና የአስጨናቂዎች ግንኙነቶች እና ማጠቃለያን እናደርጋለን፡፡ እናሳያቸዋለን የBERT ዓይነቶች እና አካባቢ ሞዴላዎችን የሚያሳዩ የአልጎሪትምን ምርጫዎች እንዲገልጹ ይችላል፡፡ ተቃዋሚዎች ላይ ጉዳዮች አስቀድሞ ተማሪ የቋንቋ ምሳሌዎች እና መደበቂያ ሞዴላዎችን በተለዩ ስፍራዎች ውስጥ የሚተረጉትን ነገር እናሳያቸዋለን፡፡', 'ko': 'NLP 모델에 대해 계획된 대항적인 공격이 날로 실제 위협이 되고 있다.대항적 공격을 감지하기 위한 다양한 방법이 개발됐지만, 학습에 기반한 NLP 시스템을 실천적으로 보호하는 데 필요한 것은 단순히 방해를 식별하고 피하는 실례만이 아니다.이러한 문제점을 해결하기 위해 우리는 새로운 적 식별 임무, 즉 텍스트 분석을 통해 공격자 속성 분류(AACTA)를 제시했다. 이 임무는 적의 텍스트에서 공격자에 대한 더 자세한 정보를 얻으려고 한다.구체적으로 말하면 적대 텍스트를 정하고 우리는 다음과 같은 임무를 완성하고자 한다. 방해를 받는 영패를 포지셔닝하고 공격자가 목표 모델에 대한 접근 단계를 식별하며 가하는 회피 메커니즘을 확정하고 공격 알고리즘이 사용하는 방해 유형을 지정한다.우리의 공헌은 다음과 같다. 우리는 공격자 속성 분류의 임무를 형식화하고 감정 분류와 검측 영역의 각종 목표 모델에 기준을 만들 것이다.버트 모델과 목표 모델에서 온 신호는 분류기를 훈련시켜 공격 알고리즘의 특성을 드러낼 수 있음을 보여준다.우리는 대항적인 공격이 사전에 훈련된 언어 모델과 목표 모델의 특징 공간에 해석 가능한 흔적을 남기고 AACTA를 더욱 신뢰할 수 있는 NLP 시스템의 희망적인 방향으로 만들었다는 것을 증명했다.', 'bn': 'এনএলপি মডেলের বিরুদ্ধে প্রাক্তন আক্রমণ বাড়ছে আরো বাড়ছে বৈশিষ্ট্যিক হুমকি হচ্ছে। যদিও বিভিন্ন ধরনের পদ্ধতি উন্নয়ন করা হয়েছে বিরোধী আক্রমণ সনাক্ত করার জন্য, কিন্তু শিক্ষা ভিত্তিক এনএলপি সিস্টেমের ব্যবস্থা নিশ্চিত করার To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts.  বিশেষ করে, বিরোধী টেক্সটের একটি অংশ দিয়ে আমরা আশা করি কাজ সম্পাদন করতে পারি, যেমন পার্টার্টবেড চিহ্ন স্থানীয় স্থানান্তর করা, হামলাকারীর প্রবেশাধিকার মোডেলের স্তর পরিচিহিত করতে পারে,  আমাদের অংশগ্রহণ নীচে নিচের ভাবে: আমরা আক্রমণকারীদের বৈশিষ্ট্যাবলী বিভিন্ন লক্ষ্য মডেলে বিভিন্ন লক্ষ্যবস্তুতে বেনম্যার্ক তৈরি করি এব আমরা দেখাচ্ছি যে বেরেটি মডেল এবং টার্গেট মডেল থেকে সিগন্যাল ব্যবহার করা যায় যারা আক্রমণের অ্যালগরিদমের বৈশিষ্ট্য প্রদর্শন আমরা দেখাচ্ছি যে বিরোধী আক্রমণ পূর্ব প্রশিক্ষিত ভাষা মডেল এবং লক্ষ্য মডেলের দুটির বৈশিষ্ট্যের স্থানে ব্যাখ্যায়তা রেখে যাচ্ছে, যার ফলে এ', 'bs': 'Preporučni napadi koji su okrenuti protiv modela NLP postaju praktične prijetnje. Iako su razvijene različite metode za otkrivanje neprijateljskih napada, osiguranje sustava NLP na praksi na učenju zahtijevalo bi više od identifikacije i izbjegavanja nevoljnih slučajeva. Za rješavanje tih pitanja predlažemo novi set neprijateljskih zadataka za identifikaciju, klasifikaciju atributa napadača preko tekstualne analize (AACTA), koji pokušava dobiti detaljnije informacije o napadačama iz neprijateljskih tekstova. Posebno, s obzirom na dio negativnog teksta, nadamo se da ćemo postići zadatke poput lokalizacije perturbiranih znakova, identificiranje nivoa pristupa napadača ciljnom modelu, utvrđivanje mehanizma uvođenog izbjegavanja i određivanje vrsta perturbacije zaposlenog algoritmom napada. Naši doprinosi su sljedeći: formaliziramo zadatak klasifikacije atributa napadača i stvaramo kritiku o različitim ciljnim modelima iz klasifikacije osjećaja i detektivnih domena zlostavljanja. Pokazujemo da se signali iz BERT modela i ciljnih modela mogu koristiti za trening klasifikatora koji otkrivaju vlasništvo napadajućih algoritma. Pokazujemo da neprijateljski napadi ostavljaju interpretabilne tragove u obje karakteristične prostore predobučenih jezičkih modela i ciljnih modela, čineći AACTA obećavajućim smjerom prema vjernijim NLP sistemima.', 'cs': 'Nepřátelské útoky proti modelům NLP se stávají stále více praktickými hrozbami. Ačkoli byly vyvinuty různé metody detekce protivníků, zabezpečení NLP systémů založených na učení by v praxi vyžadovalo více než identifikaci a vyhýbání se narušeným instancím. Pro řešení těchto problémů navrhujeme novou sadu úkolů identifikace protivníků, klasifikaci atributů útočníka prostřednictvím textové analýzy (AACTA), která se snaží získat podrobnější informace o útočnících z textových textů. Konkrétně doufáme, že s přihlédnutím k protiprávnímu textu dokážeme splnit úkoly, jako je lokalizace narušených tokenů, identifikace úrovně přístupu útočníka k cílovému modelu, určení uloženého únikového mechanismu a specifikace typu narušení používaného útočným algoritmem. Naše příspěvky jsou následující: formalizujeme úkol klasifikace atributů útočníků a vytváříme benchmark na různých cílových modelech od klasifikace sentimentů a domén detekce zneužití. Ukazujeme, že signály z BERT modelů a cílových modelů lze použít k tréninku klasifikátorů, které odhalují vlastnosti útočných algoritmů. Dokazujeme, že nepřátelské útoky zanechávají interpretovatelné stopy v obou funkčních prostorech předem trénovaných jazykových modelů i cílových modelů, což z AACTA dělá slibný směr k důvěryhodnějším NLP systémům.', 'et': 'NLP mudelite vastu kureeritud vastased rünnakud muutuvad üha enam praktilisteks ohtudeks. Kuigi vastaste rünnakute avastamiseks on välja töötatud mitmeid meetodeid, nõuaks õppepõhiste uue õppeprogrammi süsteemide kindlustamine praktikas enamat kui häirete tuvastamine ja vältimine. Nende probleemide lahendamiseks pakume välja uued vastaste tuvastamise ülesanded, ründajate atribuutide klassifitseerimine tekstianalüüsi kaudu (AACTA), mis püüavad saada ründajate kohta üksikasjalikumat teavet vastastekstidest. Täpsemalt, arvestades konkurentsiteksti, loodame täita selliseid ülesandeid nagu häirunud tokenite lokaliseerimine, ründaja juurdepääsu tase sihtmudelile, määrata kindlaks kehtestatud kõrvalehoidumismehhanism ja määrata ära häirete tüüp, mida ründav algoritm kasutab. Meie panus on järgmine: me vormistame ründaja atribuutide klassifitseerimise ülesande ning loome võrdlusaluse erinevatele sihtmudelitele sentimentide klassifitseerimise ja kuritarvituste tuvastamise domeenidest. Näitame, et BERT-mudelite ja sihtmudelite signaale saab kasutada ründavate algoritmide omadusi paljastavate klassifitseerijate koolitamiseks. Näitame, et vastased rünnakud jätavad tõlgendatavaid jälgi nii eelõpetatud keelemudelite kui sihtmudelite funktsiooniruumides, muutes AACTA paljulubavaks suunaks usaldusväärsemate NLP süsteemide suunas.', 'fi': 'NLP-malleihin kuratoiduista vastahy철kk채yksist채 on tulossa yh채 enemm채n k채yt채nn철n uhkia. Vaikka vastustajahy철kk채ysten havaitsemiseen on kehitetty erilaisia menetelmi채, oppimispohjaisten NLP-j채rjestelmien turvaaminen k채yt채nn철ss채 vaatisi muutakin kuin h채iri철iden tunnistamista ja v채ltt채mist채. N채iden ongelmien ratkaisemiseksi ehdotamme uutta vastustajien tunnistusteht채v채채, Attack Attribute Classification via Textual Analysis (AACTA), jolla pyrit채채n saamaan tarkempaa tietoa hy철kk채채jist채 vastustajien teksteist채. Tarkemmin sanottuna, kun otetaan huomioon kontradiktorinen teksti, toivomme voivamme suorittaa teht채vi채, kuten lokalisoida h채irityt poletit, tunnistaa hy철kk채채j채n p채채sytason kohdemalliin, m채채ritt채채 m채채r채tyn v채ist철mekanismin ja m채채ritt채채 hy철kk채채v채n algoritmin k채ytt채m채n h채iri철tyypin. Osallistumme seuraavasti: virallistamme hy철kk채채jien attribuuttien luokitteluteht채v채n ja luomme vertailuarvon erilaisille kohdemalleille tunteiden luokittelusta ja v채채rink채yt철sten tunnistuksesta. Osoitamme, ett채 BERT- ja kohdemallien signaaleja voidaan k채ytt채채 hy철kk채채vien algoritmien ominaisuuksia paljastavien luokittelijoiden kouluttamiseen. Osoitamme, ett채 vastakkainasetteluhy철kk채ykset j채tt채v채t tulkittavissa olevia j채lki채 sek채 ennalta koulutettujen kielimallien ominaisuustiloihin ett채 kohdemalleihin, mik채 tekee AACTA:sta lupaavan suunnan kohti luotettavampia NLP-j채rjestelmi채.', 'ca': "Adversarial attacks curated against NLP models are increasingly becoming practical threats.  Malgrat que s'han desenvolupat diversos mètodes per detectar atacs adversaris, assegurar sistemes NLP basats en l'aprenentatge en la pràctica requeriria més que identificar i evitar casos perturbats. Per abordar aquests problemes, proposem un nou conjunt de tasques d'identificació adversaria, Classificació d'atributs d'atacant a través de l'anàlisi textual (AACTA), que intenti obtenir informació més detallada sobre els atacants a partir de textos adversaris. Concretament, dada una peça de text adversari, esperem aconseguir tasques com localitzar fitxes perturbades, identificar el nivell d'accés del atacant al model d'objectiu, determinar el mecanisme d'evasió imposat, i especificar el tipus de perturbació utilitzat pel algoritme d'ataque. Les nostres contribucions són les següents: formalitzem la tasca de classificar atributs d'atacants i creem un punt de referència en diversos models d'objectiu de la classificació de sentiments i dominis de detecció d'abusos. Ens mostren que els senyals dels models BERT i els models d'objectiu poden ser utilitzats per formar classificadors que revelen les propietats dels algoritmes atacants. Demonstrem que els atacs adversaris deixan rastres interpretables en ambdós espais de característiques de models de llenguatge pré-entrenats i models d'objectiu, fent que AACTA sigui una direcció prometedora cap a sistemes NLP més fiables.", 'sk': 'Neželeni napadi zoper modele NLP postajajo vse bolj praktične grožnje. Čeprav so bile razvite različne metode za odkrivanje nasprotnih napadov, bi za zagotavljanje učnih sistemov NLP v praksi potrebovalo več kot samo prepoznavanje in izogibanje motnjam primerov. Za reševanje teh vprašanj predlagamo nov nabor nalog identifikacije nasprotnikov, klasifikacija atributov napadalcev prek besedilne analize (AACTA), ki poskuša pridobiti podrobnejše informacije o napadalcih iz nasprotnih besedil. Natančneje upamo, da bomo ob upoštevanju nasprotnega besedila opravili naloge, kot so lokalizacija motenih žetonov, identifikacija stopnje dostopa napadalca do ciljnega modela, določitev naloženega mehanizma za izogibanje in določitev vrste motenj, ki jo uporablja napadalni algoritm. Naši prispevki so naslednji: formaliziramo nalogo razvrščanja atributov napadalcev in ustvarimo referenčno merilo različnih ciljnih modelov iz klasifikacije sentimentov in domen za zaznavanje zlorab. Pokazali smo, da se signali BERT modelov in ciljnih modelov lahko uporabljajo za usposabljanje klasifikatorjev, ki razkrivajo lastnosti napadalnih algoritmov. Pokazali smo, da kontradiktorski napadi puščajo razložljive sledi tako v funkcijskih prostorih predhodno usposobljenih jezikovnih modelov kot ciljnih modelov, zaradi česar je AACTA obetavna smer k bolj zaupanja vrednim sistemom NLP.', 'jv': 'Ajol-uwong Advertary Sing sampeyan sistem sing wis dipoleh nggawe kanggo kebonangan ataka yang pakan karo, kuwi wis nguasai sistem NLP sing basa kang praksi kuwi wis dipatenno karo kejahatan lan ujaran ujaran. Ngawe nggunakake perlakon iki, kita ngubah akeh sing nggawe tasks sing gak dhéwé, Attacker Attribute CURRENTCURRENT, WHINDOWSCURRENT, WHANDOWSCURRENT CURRENTCURRENT Attribute Awak dhéwé éntuk sistem sing sampeyan karo model BERT lan model sing berarti iso nguasai nggawe barang alat sing nyimpen karo perusahaan Algorithm. Awak dhéwé éntuk perbudhakan karo atak opoterasi iki bakal terus-terusahaan anyar iki bakal terus-terusahaan anyar model karo nggawe barang sistem sing bisa luwih apik, lan sampek model sing apik dhéwé, lan akeh AAST kuwi nggawe barang langkung sampek kang NLP sistem', 'he': 'התקפות נגד דוגמני NLP הופכות יותר ויותר איומים מעשיים. למרות ששיטות שונות התפתחו כדי לגלות התקפים יריביים, להבטיח מערכות NLP מבוססות על למידה בעבודה תדרש יותר מאשר לזהות ותחמק מקרים מפריעים. כדי להתמודד עם הנושאים האלה, אנו מציעים קבוצה חדשה של משימות זיהוי יריבים, קליфікаציה של תוקפים תוקפים באמצעות ניתוח טקסטולי (AACTA), שמנסה להשיג מידע מפורט יותר על תוקפים מטקסטים יריבים. במיוחד, בהתחשב בפיסה של טקסט יריבי, אנו מקווים להשלים משימות כמו לאתר סימנים מופרעים, לזהות רמת גישה של המתקף למודל המטרה התרומות שלנו הן כאלה: אנו פורשמים את המשימה של קלאסיפור תכונות תוקפים, ויוצרים רמז על מודלים מטרה שונים מסיפור רגשות ומשטחי זיהוי התעללות. אנו מראים שאותם אותים ממודלים BERT ומודלים המטרה יכולים להשתמש כדי לאמן קלאסיפורים שמגלים את תכונות האלגוריתמים התקיפים. אנחנו מוכיחים שהתקיפות יריביות משאירות עקבות אפשריות לפרשנות בשני חללים של דוגמנים לשפה מאומנים מראש ומודלים מטרה, הופכים את AACTA כיוון מבטיח לכיוון מערכות NLP יותר אמינות.', 'ha': "Adversarial attacks curated against NLP models are increasingly becoming practical threats.  Kuma kõ da an buɗe wasu hanyõyi dõmin a gane attacki masu motsi, kuma a tsare masu tsari da aka ƙayyade wa NLP a cikin aikin da za'a ƙayyade wasu shiryoyin ayuka da aka sani, sai ya ƙayyade mafi yawa daga gane da za'a samar da wasu shiryoyin ayuka da aka ƙaddara. Yana buɗar da wasu masu husũma, ko da za mu buɗe wani matsayin shaidar da ke motsi, Attack Attitute Classification through Analyze Textal (AAAATA), wanda ke jarraba ka sami wani bayani na bayani na canza za za'a sami bayani ga waɗanda aka yi attacka daga littãfin na motsi. Ka ƙayyade, da wani yanki na matsayin da ke motsa, tuna fatan mu cika aikin kamar lokal alamomi na perturbata, ka gane daraja ga wanda ya yi attacka zuwa motel na goani, kuma ka ƙayyade mekaninsa da aka samar da shi, kuma ka ƙayyade nau'in perturbation da ke amfani da algoritm mai attacka. Kayyakanmu na kama da: za mu danne aikin mai fassara halin mai attacka, kuma mu sami wani bango a kan misãlai masu yiwuwa daban-daban daga dangane sauri da misĩfar. Tuna nũna cewa misalin ayuka daga misãlai na BERT da misãlai masu amfani da za'a yi amfani da su bi'ar da tsari waɗanda ke nuna properties wa algoritori masu shawara. Tuna nũna cewa attacki masu motsi da ke barin su fassara masu fassara cikin duk filayen da ke cikin misãlai na zaman-tsari da kuma misãlai masu jiyya, kuma ya sanya AAAATA wata shiri mai yi wa'adi zuwa na ƙari masu amintarwa na NLP.", 'bo': "NLP དཔེ་དབྱིབས་བཅས་ཀྱི་སྐྱོན་བརྗོད་གྱི་གནོད་འགྲུལ་བ་ནི་ལག་ལེན་གྱི་གནོད་འགྱུར་བར་གཏོང་གི་ཡོད། Although various methods have been developed to detect adversarial attacks, securing learning-based NLP systems in practice would require more than identifying and evading perturbed instances. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts. Specifically, given a piece of adversarial text, we hope to accomplish tasks such a s localizing perturbed tokens, identifying the attacker's access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm. ང་ཚོའི་གོ་ཐུམ་གྲངས་འདི་ལྟ་བུ་བཞིན་ཡོད། ང་ཚོས་བློ་གཏོང་གི་བྱ་རིམ་ཇི་ལྟར་བཟོ་བྱེད་ཀྱི་ཡོད་པ་དང་། འུ་ཅག་གིས་BERT མིག་དཔེ་དབྱིབས་དང་དམིགས་ཡུལ་གྱི་མིག་དཔེ་དབྱིབས་འགྱུར་བ་སྤྱོད་ཐུབ་པའི་མིག་རྟགས་ལ་སྤྱོད་ཀྱི་ཡོད་པ་ཤར་བ We demonstrate that adversarial attacks leave interpretable traces in both feature spaces of pre-trained language models and target models, making AACTA a promising direction towards more trustworthy NLP systems."}
{'en': 'ProSPer : Probing Human and Neural Network Language Model Understanding of Spatial Perspective', 'ar': 'ProSPer: فحص نموذج لغة الشبكة البشرية والعصبية للمنظور المكاني', 'pt': 'ProSPer: Probing Human and Neural Network Language Model Compreensão da Perspectiva Espacial', 'fr': 'ProSer\xa0: Exploration de la compréhension des modèles de langage de réseaux humains et neuronaux en perspective', 'es': 'ProSper: Sondeo de modelos de lenguaje de redes neuronales y humanas para comprender la perspectiva espacial', 'zh': 'ProSPer:索人神经网络言,透视也', 'ja': 'ProSPer:人間とニューラルネットワーク言語モデルの探索空間的視点の理解', 'hi': 'ProSPer: मानव और तंत्रिका नेटवर्क भाषा मॉडल स्थानिक परिप्रेक्ष्य की समझ की जांच', 'ru': 'ProSPer: Зондируя Понимание Пространственной Перспективы Языковой Модели Человека и Нейронной Сети', 'ga': 'ProSPer: Iniúchadh ar an Líonra Daonna agus Néarach Múnla Teanga Tuiscint ar Dearcadh Spásúlachta', 'ka': 'ProSPer: ადამიანის და ნეიროლური ქსელის მოდელის განსხვავება', 'hu': 'ProSPer: Az emberi és idegi hálózati nyelvi modell vizsgálata a térbeli perspektíva megértése', 'el': 'Δοκιμή γλωσσικού μοντέλου ανθρώπινου και νευρωνικού δικτύου Κατανόηση της χωρικής προοπτικής', 'it': 'ProSPer: Analisi del modello linguistico di rete umana e neurale Comprensione della prospettiva spaziale', 'mk': 'ProSPer: Истражување на човековиот и неуралниот јазик модел Разбирање на просторната перспектива', 'kk': 'ПроSPer: Адам және нейралық желі тілдерін тексеру', 'ms': 'ProSPer: Menguji Model Bahasa Rangkaian Manusia dan Neural Memahami Perspektif Ruang', 'mt': 'ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective', 'ml': 'പ്രോസ്പെര്\u200d: മനുഷ്യനും നെയുറല്\u200d നെറ്റര്\u200d നെറ്റ്വര്\u200dക്കും പ്രോബിങ്ങ് ചെയ്യുന്ന ഭാഷ മോഡില്\u200d സ്പെയില്\u200d പ', 'mn': 'ProSPer: Хүн болон сэтгэл зүйн сүлжээний хэл загварын ойлголт', 'no': 'ProSPer: Testing Human and Neural Network Language Model Understanding of Spatial Perspective', 'pl': 'ProSPer: Badanie modelu językowego ludzkiej i neuronowej sieci Zrozumienie perspektywy przestrzennej', 'ro': 'ProSPer: Proiectarea modelului lingvistic al rețelei umane și neurale Înțelegerea perspectivei spațiale', 'sr': 'ProSPer: Proveravanje modela razumevanja svemirske perspektive ljudskih i neuronskih jezika', 'si': 'ProSPer: මිනිස්සු සහ න්\u200dයූරාල ජාල භාෂාව මොඩල් තේරුම් ගන්න ස්පේසියාල් ප්\u200dරසිදේශය', 'lt': 'ProSPer: Žmogaus ir nervinių tinklų kalbos modelio tyrimas erdvės perspektyvos supratimu', 'so': 'ProSPer: Probining human and Neural Network Model Understanding of Spatial Perspective', 'sv': 'ProSPer: ProSPer: Projektering av mänskligt och neuralt nätverk språkmodell Förståelse av rumsligt perspektiv', 'ta': 'பிராஸ்பெர்: வெற்று முன்னோட்டத்தின் மொழி மாதிரி புரியும்', 'ur': 'پروسپیر: انسان اور نیورال نیٹ ورک کی زبان موڈل سمجھنے کی', 'uz': 'ProSPer: Name', 'vi': 'Phát triển: Định dạng ngôn ngữ con người và thần kinh', 'bg': 'ПроСПър: Проучване на човешки и неврални мрежови езикови модели Разбиране на пространствената перспектива', 'da': 'ProSPer: Probing Human and Neural Network Language Model Forståelse af rumligt perspektiv', 'hr': 'ProSPer: Provjeravanje modela razumijevanja svemirske perspektive ljudskih i neuronskih jezika', 'nl': 'ProSPer: Het bestuderen van het menselijk en neurale netwerktaalmodel Inzicht in het ruimtelijke perspectief', 'id': 'ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective', 'ko': 'ProSPer: 인간과 신경 네트워크 언어 모델이 공간 투시에 대한 이해를 탐색하다', 'fa': 'ProSPer: امتحان مدل زبان\u200cهای انسان و شبکه عصبی درک از perspektiv فضایی', 'de': 'ProSPer: Untersuchung menschlicher und neuronaler Netzwerksprachmodelle Verständnis räumlicher Perspektiven', 'af': 'ProSPer: Probeer Human and Neural Network Language Model Understanding of Spatial Perspective', 'sw': 'ProSPer: Kujaribu Mtandao wa Lugha ya Kibinadamu na Neural Understanding of Spain', 'tr': 'Hassasiyet: İnsan ve näral Network Dilini denemek Modeli Spatial Perspektive Düşüncesi', 'sq': 'ProSPer: Provimi i modelit të gjuhës njerëzore dhe të rrjetit nervor të kuptimit të perspektivës hapësirore', 'am': 'ProSPer: የሰው እና የኔural መረብ ቋንቋ', 'hy': 'ProSP: Մարդկային և նյարդային ցանցի լեզվի մոդելը', 'bs': 'ProSPer: Provjeravanje modela razumijevanja svemirske perspektive ljudskih i neuronskih jezika', 'bn': 'প্রোসপার: স্প্যানেটিয়াল পছন্দের বুঝতে পারে মানুষ এবং নেউরাল নেটওয়ার্ক মোডেল', 'et': 'ProSPer: Inimese ja närvivõrgu keele mudeli mõistmine ruumilise perspektiivi kohta', 'cs': 'ProSPer: sondování jazykového modelu lidské a neuronové sítě Porozumění prostorové perspektivě', 'ca': 'ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective', 'fi': 'ProSPer: Ihmisen ja hermoverkon kielimallin kartoitus Spatial Perspective', 'az': 'ProSPer: İnsan və Nöral Ağ Dili Modeli Uzay Perspektivlərinin anlama', 'ha': 'KCharselect unicode block name', 'sk': 'ProSPer: Razumevanje modela jezikovnega modela človeškega in živčnega omrežja za razumevanje prostorske perspektive', 'he': 'ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective', 'bo': 'ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective', 'jv': 'perspective-clone-mode'}
{'en': 'Understanding perspectival language is important for applications like dialogue systems and human-robot interaction. We propose a probe task that explores how well language models understand spatial perspective. We present a dataset for evaluating perspective inference in English, ProSPer, and use it to explore how humans and Transformer-based language models infer perspective. Although the best bidirectional model performs similarly to humans, they display different strengths : humans outperform neural networks in conversational contexts, while RoBERTa excels at written genres.', 'fr': "La compréhension du langage de perspective est importante pour des applications telles que les systèmes de dialogue et l'interaction homme-robot. Nous proposons une tâche d'exploration qui explore la façon dont les modèles linguistiques comprennent la perspective spatiale. Nous présentons un ensemble de données pour évaluer l'inférence de perspective en anglais, ProSer, et nous l'utilisons pour explorer comment les humains et les modèles de langage basés sur Transformer déduisent la perspective. Bien que le meilleur modèle bidirectionnel fonctionne de la même manière que les humains, ils présentent des forces différentes\xa0: les humains surpassent les réseaux de neurones dans les contextes conversationnels, tandis que Roberta excelle dans les genres écrits.", 'ar': 'يعد فهم لغة المنظور أمرًا مهمًا لتطبيقات مثل أنظمة الحوار والتفاعل بين الإنسان والروبوت. نقترح مهمة التحقيق التي تستكشف مدى فهم النماذج اللغوية للمنظور المكاني. نقدم مجموعة بيانات لتقييم الاستدلال المنظوري في اللغة الإنجليزية ، ProSPer ، ونستخدمها لاستكشاف كيف يستنتج البشر ونماذج اللغة المستندة إلى Transformer المنظور. على الرغم من أن أفضل نموذج ثنائي الاتجاه يعمل بشكل مشابه للبشر ، إلا أنه يظهر نقاط قوة مختلفة: يتفوق البشر على الشبكات العصبية في سياقات المحادثة ، بينما تتفوق RoBERTa في الأنواع المكتوبة.', 'es': 'Entender el lenguaje perspectivo es importante para aplicaciones como los sistemas de diálogo y la interacción humano-robot. Proponemos una tarea de sondeo que explora qué tan bien entienden los modelos lingüísticos la perspectiva espacial. Presentamos un conjunto de datos para evaluar la inferencia de perspectiva en inglés, ProSper, y lo utilizamos para explorar cómo los humanos y los modelos lingüísticos basados en Transformer deducen la perspectiva. Aunque el mejor modelo bidireccional funciona de manera similar a los humanos, muestran diferentes puntos fuertes: los humanos superan a las redes neuronales en contextos conversacionales, mientras que Roberta sobresale en los géneros escritos.', 'pt': 'Compreender a linguagem perspectiva é importante para aplicações como sistemas de diálogo e interação humano-robô. Propomos uma tarefa de sondagem que explora quão bem os modelos de linguagem entendem a perspectiva espacial. Apresentamos um conjunto de dados para avaliar a inferência de perspectiva em inglês, ProSPer, e o usamos para explorar como humanos e modelos de linguagem baseados em Transformer inferem perspectiva. Embora o melhor modelo bidirecional tenha um desempenho semelhante ao dos humanos, eles apresentam pontos fortes diferentes: os humanos superam as redes neurais em contextos de conversação, enquanto o RoBERTa se destaca em gêneros escritos.', 'zh': '通透视言语之于言也,人机交互之于言也。 一探其务,探其空透视。 设一以质英语ProSPer视角理之数集,而用之以求人伦基于Transformer言,何以推视角。 虽至双向与人相似,而见异势:人善于言,而RoBERTa善于神经网络。', 'ja': '視点言語を理解することは、対話システムや人間とロボットの相互作用などのアプリケーションにとって重要です。言語モデルが空間的視点をどの程度理解しているかを探るプローブタスクを提案します。私たちは、英語で視点推論を評価するためのデータセット、ProSPerを提示し、それを使用して、人間とトランスフォーマーベースの言語モデルがどのように視点推論するかを探求します。最高の双方向モデルは人間と同様に機能しますが、異なる強みを示しています。人間は会話の文脈でニューラルネットワークを上回り、RoBERTaは書かれたジャンルに優れています。', 'hi': 'Perspectival भाषा को समझना संवाद प्रणालियों और मानव-रोबोट इंटरैक्शन जैसे अनुप्रयोगों के लिए महत्वपूर्ण है। हम एक जांच कार्य का प्रस्ताव करते हैं जो यह पता लगाता है कि भाषा मॉडल स्थानिक परिप्रेक्ष्य को कितनी अच्छी तरह समझते हैं। हम अंग्रेजी, ProSPer में परिप्रेक्ष्य अनुमान का मूल्यांकन करने के लिए एक डेटासेट प्रस्तुत करते हैं, और इसका उपयोग यह पता लगाने के लिए करते हैं कि मनुष्य और ट्रांसफॉर्मर-आधारित भाषा मॉडल परिप्रेक्ष्य का अनुमान कैसे लगाते हैं। यद्यपि सबसे अच्छा द्विदिश मॉडल मनुष्यों के समान प्रदर्शन करता है, वे विभिन्न शक्तियों को प्रदर्शित करते हैं: मनुष्य संवादी संदर्भों में तंत्रिका नेटवर्क से आगे निकलते हैं, जबकि रोबर्टा लिखित शैलियों में उत्कृष्टता प्राप्त करता है।', 'ru': 'Понимание перспективного языка важно для таких приложений, как диалоговые системы и взаимодействие человек-робот. Мы предлагаем пробную задачу, которая исследует, насколько хорошо языковые модели понимают пространственную перспективу. Мы представляем набор данных для оценки перспективного вывода на английском языке, ProSPer, и используем его для изучения того, как люди и языковые модели на основе Transformer делают вывод о перспективе. Хотя лучшая двунаправленная модель работает аналогично людям, она демонстрирует разные сильные стороны: люди превосходят нейронные сети в разговорных контекстах, в то время как RoBERTa превосходит письменные жанры.', 'ga': 'Tá sé tábhachtach tuiscint a fháil ar theanga peirspictíochta le haghaidh feidhmeanna cosúil le córais dialóige agus idirghníomhú daonna-robot. Molaimid tasc probe a fhiosraíonn cé chomh maith agus a thuigeann samhlacha teanga peirspictíocht spásúil. Cuirimid tacar sonraí i láthair chun an tátal peirspictíochta a mheas i mBéarla, ProSPer, agus úsáidimid é chun iniúchadh a dhéanamh ar an gcaoi a dtagann daoine agus samhlacha teanga atá bunaithe ar an gClaochladán i bhfeidhm ar pheirspictíocht. Cé go bhfeidhmíonn an tsamhail déthreoch is fearr ar an gcaoi chéanna le daoine, léiríonn siad láidreachtaí éagsúla: sáraíonn daoine líonraí néaracha i gcomhthéacsanna comhrá, agus cuireann RoBERTa barr feabhais ar sheánraí scríofa.', 'el': 'Η κατανόηση της οπτικής γλώσσας είναι σημαντική για εφαρμογές όπως συστήματα διαλόγου και αλληλεπίδραση ανθρώπου-ρομπότ. Προτείνουμε μια ερευνητική εργασία που διερευνά πόσο καλά τα γλωσσικά μοντέλα κατανοούν την χωρική προοπτική. Παρουσιάζουμε ένα σύνολο δεδομένων για την αξιολόγηση των συμπερασμάτων προοπτικής στα αγγλικά, και το χρησιμοποιούμε για να διερευνήσουμε πώς οι άνθρωποι και τα γλωσσικά μοντέλα βασισμένα στον μετασχηματιστή συμπεραίνουν την προοπτική. Αν και το καλύτερο αμφίδρομο μοντέλο αποδίδει παρόμοια με τους ανθρώπους, εμφανίζουν διαφορετικές δυνάμεις: οι άνθρωποι ξεπερνούν τα νευρωνικά δίκτυα σε πλαίσια συνομιλίας, ενώ το RoBERTa υπερέχει στα γραπτά είδη.', 'ka': 'პერპექტივალური ენაზე გასანიშვნელოვანია პროგრამებისთვის, როგორც დიალოგის სისტემი და ადამიანის-პრობოტის ინტერაქცია. ჩვენ მინდა პრობეტის რაოდენობა, რომელიც განსხვავებს რამდენი მსგავსი ენის მოდელები განსხვავებენ სივრცელი პერსპექტიკური. ჩვენ ინგლისური, პროსპერის განსაზღვრებისთვის მონაცემების კონფიკურაციის შესახებ გამოყენებთ და ამას გამოყენებთ, როგორ ადამიანები და ტრანფორმეტრის განსაზღვრებული ენ მაგრამ ყველაზე საუკეთესო მედირექციო მოდელი ადამიანებისთვის იგივე გავაკეთებს, ისინი განსხვავებული ძალიანების ჩვენება: ადამიანები უფრო ძალიან ნეიროლური ქსელები გავაკეთებენ კონტაქ', 'it': "Comprendere il linguaggio prospettico è importante per applicazioni come i sistemi di dialogo e l'interazione uomo-robot. Proponiamo un compito di sonda che esplora come bene i modelli linguistici capiscono la prospettiva spaziale. Presentiamo un set di dati per valutare l'inferenza prospettica in inglese, ProSPer, e lo utilizziamo per esplorare come gli esseri umani e i modelli linguistici basati su Transformer deducono la prospettiva. Anche se il migliore modello bidirezionale funziona in modo simile agli esseri umani, mostra diversi punti di forza: gli esseri umani superano le reti neurali in contesti conversazionali, mentre RoBERTa eccelle nei generi scritti.", 'lt': 'Svarbu suprasti perspektyvinę kalbą tokioms programoms kaip dialogo sistemos ir žmogaus ir robot ų sąveika. Siūlome atlikti tyrimą, kuriame nagrinėjama, kaip kalbos modeliai gerai supranta erdvinę perspektyvą. Mes pateikiame duomenų rinkinį, skirtą įvertinti perspektyvų išvadas anglų kalba, ProSPer, ir naudojame jį, kad ištirtume, kaip žmonės ir transformatoriais pagrįsti kalbų modeliai daro išvadą perspektyvai. Nors geriausias dvikryptis modelis veikia panašiai kaip ir žmonės, jis turi skirtingų stiprumų: žmonės viršija nervinius tinklus konversacijos kontekste, o RoBERTa yra geriausias rašytinių genrų.', 'kk': 'Қарапайым тілді түсіну диалог жүйелері және адамдар- роботтардың қатынасы үшін маңызды. Біз тіл үлгілерін қанша жергілікті түсінікті түсіндіретін проб тапсырмасын ұсынамыз. Біз ағылшын, ProSPer тіліндегі перспективті бағалау үшін деректер жиынын таңдап, адамдар мен түрлендіруші тіл үлгілерін қалай бағалау үшін қолданамыз. Ең жақсы бидиеркционалдық модель адамдарға ұқсас істейді дегенде, олар әртүрлі күштерді көрсетеді: адамдар сұлбашалық контекстерде невралдық желілерді жұмыс істейді, және RoBERTa жазылған жанрларда', 'mk': 'Разбирањето на перспективниот јазик е важно за апликациите како дијалошките системи и интеракцијата човек-робот. Предложуваме истражувачка задача која истражува како јазичките модели добро ја разбираат просторната перспектива. Презентираме податоци за проценка на перспективната конференција на англиски, проSPer, и ги користиме за истражување како луѓето и трансформските јазички модели инферираат перспектива. Иако најдобриот дворечен модел функционира слично на луѓето, тие покажуваат различни сили: луѓето ги надминуваат невровните мрежи во контекстни контексти, додека RoBERTa е одличен на напишаните генери.', 'hu': 'A perspektív nyelv megértése fontos az olyan alkalmazásokban, mint például a párbeszédrendszerek és az ember-robot interakció. Javasolunk egy szonda feladatot, amely feltárja, hogy a nyelvi modellek milyen jól értik a térbeli perspektívát. Bemutatunk egy adatkészletet a perspektíva következtetésének értékeléséhez angol nyelven, ProSPer nyelven, és feltárjuk, hogy az emberek és a Transformer alapú nyelvi modellek hogyan következtetnek perspektívát. Bár a legjobb kétirányú modell az emberekhez hasonlóan teljesít, különböző erősségeket mutat: az emberek túllépnek az idegi hálózatokkal a beszélgetési kontextusokban, míg a RoBERTa kitűnik az írott műfajokban.', 'ms': 'Memahami bahasa perspektif adalah penting untuk aplikasi seperti sistem dialog dan interaksi manusia-robot. Kami cadangkan tugas sonda yang mengeksplorasi bagaimana model bahasa faham perspektif ruang. We present a dataset for evaluating perspective inference in English, ProSPer, and use it to explore how humans and Transformer-based language models infer perspective.  Walaupun model bidireksi terbaik berfungsi sama dengan manusia, mereka memaparkan kekuatan yang berbeza: manusia melampaui rangkaian saraf dalam konteks perbualan, sementara RoBERTa mengajar pada genre tertulis.', 'mt': "Il-fehim tal-lingwa perspettiva huwa importanti għal applikazzjonijiet bħal sistemi ta’ djalogu u interazzjoni bejn il-bniedem u r-robot. Aħna nipproponu xogħol ta' sonda li jesplora kif il-mudelli lingwistiċi jifhmu sew il-perspettiva ġeografika. Aħna nippreżentaw sett ta’ dejta għall-evalwazzjoni tal-inferenza tal-perspettiva bl-Ingliż, ProSPer, u nużaha biex nesploraw kif il-bnedmin u l-mudelli lingwistiċi bbażati fuq it-Transformer jininferu l-perspettiva. Għalkemm l-aħjar mudell bidirezzjonali jwettaq b’mod simili għall-bnedmin, dawn juru qawwiet differenti: il-bnedmin iwettqu netwerks newrali f’kuntesti ta’ konverżjoni, filwaqt li RoBERTa jeċċella f’ġeneri miktuba.", 'ml': 'ഡയലോഗ് സിസ്റ്റം പോലുള്ള പ്രയോഗങ്ങള്\u200dക്കും മനുഷ്യര്\u200d റോബോട്ട് ഇടപെടുത്തുന്നതിനും പ്രധാനപ്പെട്ടതാണ്  We propose a probe task that explores how well language models understand spatial perspective.  ഇംഗ്ലീഷ്, പ്രോസ്പെരില്\u200d നിരീക്ഷണത്തെ പരിഗണിക്കാന്\u200d വേണ്ടി നമ്മള്\u200d ഒരു ഡാറ്റാസേറ്റ് കൊണ്ടുവരുന്നു. മനുഷ്യരും ട്രാന്\u200dസ്ഫോര്\u200d മനുഷ്യരെപ്പോലെയാണ് ഏറ്റവും മികച്ച മോഡല്\u200d പ്രവര്\u200dത്തിക്കുന്നതെങ്കിലും അവര്\u200d വ്യത്യസ്ത ശക്തികള്\u200d പ്രദര്\u200dശിപ്പിക്കുന്നു; മനുഷ്യര്\u200d സംസാരിക്കുന്ന', 'mn': 'Хэрэглэгч хэл ойлгох нь диалог систем болон хүн-робот харилцаа шиг хэрэглэгчдийн тулд чухал. Бид хэл загваруудыг хэр сайн ойлгож байгааг судалж буй судалгааны даалгаварыг сануулдаг. Бид англи, проSPer гэх мэт харцгааны халдварыг үнэлэх өгөгдлийн санг тайлбарлаж, хүмүүс болон Трансформ суурилсан хэл загварууд хэрхэн нөлөөлж байгааг судлахын тулд ашиглаж байна. Хамгийн шилдэг загвар нь хүмүүстэй адилхан үйлдэл хийдэг ч, тэд өөр хүчтэй байдлыг харуулдаг: хүмүүс ярианы нөхцөлд мэдрэлийн сүлжээг илүү ашигладаг. Роберта бичигдсэн жанр дээр илүү их байдаг.', 'pl': 'Zrozumienie języka perspektywicznego jest ważne dla aplikacji takich jak systemy dialogu i interakcja człowieka-robota. Proponujemy zadanie sondy, które bada, jak dobrze modele językowe rozumieją perspektywę przestrzenną. Przedstawiamy zestaw danych do oceny wniosków perspektywy w języku angielskim, ProSPer, i wykorzystujemy go do zbadania, w jaki sposób ludzie i modele językowe oparte na Transformerze wnioskują perspektywę. Chociaż najlepszy model dwukierunkowy działa podobnie jak człowiek, wykazują różne mocne strony: ludzie przewyższają sieci neuronowe w kontekście konwersacji, podczas gdy RoBERTa wyróżnia się w gatunkach pisanych.', 'no': 'Forståking av perspektivspråk er viktig for programmer som dialogsystemer og menneskelrobotsamarbeid. Vi foreslår eit probe-oppgåve som utforskar kor godt språk-modeller forstår mellomromperspektiv. Vi presenterer eit datasett for å evaluera perspektivinfeksjon på engelsk, proSPer og bruka det for å utforske korleis menneske og transformeringsspråk-modeller understrekar perspektiv. Selv om den beste bidireksjonale modellen utfører slik som mennesker, viser dei ulike strengdar: mennesker utfører neuralnettverk i samtale kontekstar, mens RoBERTa overstyrer på skrivne gener.', 'ro': 'Înțelegerea limbajului perspectiv este importantă pentru aplicații precum sistemele de dialog și interacțiunea om-robot. Propunem o sarcină de sondă care explorează modul în care modelele lingvistice înțeleg bine perspectiva spațială. Prezentăm un set de date pentru evaluarea inferenței perspectivei în limba engleză, ProSPer, și îl folosim pentru a explora modul în care oamenii și modelele lingvistice bazate pe Transformer deduc perspectiva. Deși cel mai bun model bidirecțional funcționează în mod similar cu oamenii, aceștia prezintă diferite puncte forte: oamenii depășesc rețelele neuronale în contexte conversaționale, în timp ce RoBERTa excelează la genurile scrise.', 'sr': 'Razumevanje perspektivnog jezika je važno za aplikacije poput dijalogskih sustava i interakcije ljudskih robota. Predlažemo zadatak sonde koji istražuje kako dobro jezički modeli razumeju prostornu perspektivu. Predstavljamo setu podataka za procjenu infekcije perspektive na engleskom, ProSPer, i koristimo ga da istražimo kako ljudi i jezički modeli na transformaciji inferiraju perspektivu. Iako najbolji bidirektivni model izvodi slično ljudima, pokazuju različite snage: ljudi izvršavaju neuralne mreže u razgovornim kontekstima, dok RoBERTa nadmaže napisanim genrima.', 'si': 'ප්\u200dරශ්න භාෂාව තේරුම් ගන්න පුළුවන් සංවාද පද්ධතිය වගේම සංවාද පද්ධතිය සහ මිනිස්සු රො අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරනවා ඒ වගේම භාෂා මොඩල් හොඳින් තේරුම් ගන්නේ කො අපි ඉංග්\u200dරීසි, ප්\u200dරොස්පර් වල දත්ත සූදානයක් පෙන්වන්නේ ඉංග්\u200dරීසිය, ප්\u200dරොස්පර් වල, ඒක පාවිච්චි කරන්න මිනිස් මිනිස්සුන්ට වෙනස් ශක්තියක් පෙන්වන්න පුළුවන් හොඳම විද්\u200dයාවක් නිර්මාණය විද්\u200dයාවක් වෙනුවෙන් පෙන්වන්න පුළුවන් වුනා: මින', 'so': 'Waxgarashada afka aragtida waxaa muhiim u ah codsiyada, sida nidaamka dialogka iyo iskaashatada robotiga dadka. Waxaynu soo jeedaynaa shaqo imtixaanka ah oo baaraandegaya noocyada luuqada si fiican u garanaya aragtida spatiada. Waxaynu soo bandhignaa sawirida aragtida cudurka Ingiriiska, ProSPer, waxaynu isticmaalaynaa si aan u baarayno qaababka aragtida dadka iyo asalka afka soo wareegayba. In kastoo ay sameynta noocyada ugu wanaagsan u sameeyaan sida dadka oo kale, waxay muujiyaan xoogo kala duduwan: dadku waxay ka samaystaan shabakooyin neurada ah oo ku qoran xilliyada hadalka, xittaa RoBERta ayaa ka sarreeya qoran jinsiyada.', 'sv': 'Att förstå perspektivspråk är viktigt för applikationer som dialogsystem och människa-robot interaktion. Vi föreslår en sonduppgift som undersöker hur väl språkmodeller förstår rumsligt perspektiv. Vi presenterar en datauppsättning för att utvärdera perspektivinferens på engelska, ProSPer, och använder den för att utforska hur människor och Transformer-baserade språkmodeller infererar perspektiv. Även om den bästa tvåriktade modellen presterar på samma sätt som människor, uppvisar de olika styrkor: människor presterar bättre än neurala nätverk i konversationssammanhang, medan RoBERTa utmärker sig på skrivna genrer.', 'ta': 'புரிந்து கொள்ளும் மொழி புரிந்து கொள்ளும் உரையாடல் அமைப்புகள் போன்ற பயன்பாடுகளுக்கு முக்கியமானது மற மொழி மாதிரிகள் எவ்வளவு நன்றாக புரிந்து கொள்கிறார்கள் என்பதை தெரிந்து கொள்ளும் ஒரு பரிசோதனை செய்யு நாம் ஆங்கிலத்தில், ப்ரோஸ்பெர்லில் பார்வையுள்ள பாதிப்பை மதிப்பதற்கு ஒரு தகவல் அமைப்பை கொண்டு வருகிறோம், மற்றும் மனிதர்கள் மற்றும Although the best bidirectional model performs similarly to humans, they display different strengths: humans outperform neural networks in conversational contexts, while RoBERTa excels at written genres.', 'ur': 'پرسپٹیول کی زبان سمجھنے کے لئے ایسے کاربریاں کے لئے اہم ہے جیسے ڈیلوگ سیستم اور انسان-روبوٹ کی تعامل. ہم ایک اسپورٹ کا کام پیشنهاد کرتے ہیں جو اسپورٹ کرتا ہے کہ زبان مدل کس طرح اچھی طرح سمجھتے ہیں۔ ہم انگلیسی، پروسپر میں ایک ڈیٹ سٹ کے ذریعے نظر اندازے کے لئے انگلیسی، پروسٹ، اور اس کا استعمال کریں کہ انسان اور ترفنسٹر کی بوسیدہ زبان موڈل کس طرح کمتر نظر اندازے رکھتے ہیں. اگرچہ سب سے بہترین نمونہ آدمیوں کے ساتھ برابر عمل کرتا ہے، وہ مختلف طاقتوں کو دکھاتے ہیں: انسانوں نے نئورل نیٹورک کو بحث کے متقابل متقابل میں اضافہ کر لیا ہے، اور روبرٹا لکھی جنر میں اضافہ کرتا ہے۔', 'uz': "Ko'rinadigan tilni tushunish uchun muloqat tizimi va inson robot interfeys uchun muhim. Biz tilning modellari spatial ko'rinishini qanchalik yaxshi o'rganadi. Biz ingliz, ProSPer tilida ko'rinadigan ko'rinishni qidirish uchun maʼlumotlar tarkibini hosil qilamiz va uni insonlar va Transformer tilning modellari ko'rinishini qanday ko'rinishini o'rganish uchun foydalanamiz. Agar eng yaxshi ishlab chiqarish modeli odamlarga o'xshash bajarayotganda, ular har xil ko'plamlarni ko'rsatadi: insonlar talab qilish vaqtlarida neyron tarmoqlarini bajaradi, va RoBERTA yozib qoʻllangan genlarida ko'paytadi.", 'vi': 'Biết rõ ngôn ngữ riêng rất quan trọng cho ứng dụng như hệ thống đối thoại và giao tiếp người-robot. Chúng tôi đề xuất một nhiệm vụ thăm dò để tìm hiểu cách ngôn ngữ hiểu được viễn cảnh không gian. Chúng tôi giới thiệu một tập tin để đánh giá nhận biết về viễn cảnh ở Anh, ProSPer, và sử dụng nó để tìm hiểu cách người và các mô- đun biến hình thiên hướng. Mặc dù mô hình trực tiếp tốt nhất có khả năng tương tự với con người, nhưng chúng hiển thị các điểm mạnh khác nhau: con người thực hiện các mạng thần kinh trong đối thoại, trong khi RozerTa vượt trội các thể loại viết.', 'bg': 'Разбирането на перспективния език е важно за приложения като диалогови системи и взаимодействие човек-робот. Предлагаме задача, която изследва колко добре езиковите модели разбират пространствената перспектива. Представяме набор от данни за оценка на перспективните изводи на английски език и го използваме, за да изследваме как хората и базираните на трансформаторите езикови модели извеждат перспективата. Въпреки че най-добрият двупосочен модел работи подобно на хората, те показват различни силни страни: хората превъзхождат невронните мрежи в разговорни контексти, докато РоBERTa се отличава в писаните жанрове.', 'da': 'Forståelse af perspektivsprog er vigtigt for applikationer som dialogsystemer og menneske-robot interaktion. Vi foreslår en sondeopgave, der undersøger, hvor godt sprogmodeller forstår rumligt perspektiv. Vi præsenterer et datasæt til evaluering af perspektiv inference på engelsk, ProSPer, og bruger det til at undersøge, hvordan mennesker og Transformer-baserede sprogmodeller udleder perspektiv. Selvom den bedste bidirektionelle model præsterer på samme måde som mennesker, viser de forskellige styrker: mennesker overgår neurale netværk i samtalekomplekser, mens RoBERTa udmærker sig til skriftlige genrer.', 'hr': 'Razumijevanje perspektivnog jezika je važno za aplikacije poput dijalogskih sustava i interakcije ljudskih robota. Predlažemo zadatak sonde koji istražuje kako dobro jezički modeli razumiju prostornu perspektivu. Predstavljamo komplet podataka za procjenu infekcije perspektive na engleskom, ProSPer i koristimo ga kako bi istražili kako ljudi i jezički modeli na transformeru inferiraju perspektivu. Iako najbolji bidirektivni model izvodi slično ljudima, pokazuju različite snage: ljudi izvršavaju neuralne mreže u razgovornim kontekstima, dok RoBERTa nadmaže napisanim genrima.', 'nl': 'Het begrijpen van perspectieve taal is belangrijk voor toepassingen zoals dialoogsystemen en mens-robot interactie. We stellen een proeftaak voor die onderzoekt hoe goed taalmodellen ruimtelijk perspectief begrijpen. We presenteren een dataset voor het evalueren van perspectieve inferentie in het Engels, ProSPer, en gebruiken deze om te onderzoeken hoe mensen en op Transformer gebaseerde taalmodellen perspectief afleiden. Hoewel het beste bidirectionele model hetzelfde presteert als mensen, vertonen ze verschillende sterke punten: mensen presteren beter dan neurale netwerken in gesprekscontexten, terwijl RoBERTa uitblinkt in geschreven genres.', 'ko': '투시 언어를 이해하는 것은 대화 시스템과 인간과 기계의 상호작용 등 응용에 매우 중요하다.우리는 언어 모델이 공간적 시각에 대한 이해 정도를 탐색하는 임무를 제시했다.우리는 영어 프로스퍼의 투시 추리를 평가하는 데 사용되는 데이터 집합을 제공하고, 이를 이용하여 인간과 Transformer를 바탕으로 하는 언어 모델이 투시를 어떻게 추정하는지 탐색한다.비록 가장 좋은 쌍방향 모델의 표현은 인류와 비슷하지만 그들은 서로 다른 장점을 나타낸다. 인류는 대화 환경에서 신경 네트워크보다 표현이 우수하고 로버타는 서면 문체에서 뛰어나다.', 'de': 'Das Verständnis perspektivischer Sprache ist wichtig für Anwendungen wie Dialogsysteme und Mensch-Roboter-Interaktion. Wir schlagen eine Sonde-Aufgabe vor, die untersucht, wie gut Sprachmodelle räumliche Perspektiven verstehen. Wir präsentieren einen Datensatz zur Bewertung perspektivischer Inferenz in englischer Sprache, ProSPer, und verwenden ihn, um zu untersuchen, wie Menschen und Transformer-basierte Sprachmodelle Perspektiven ableiten. Obwohl das beste bidirektionale Modell ähnlich funktioniert wie Menschen, zeigen sie unterschiedliche Stärken: Menschen übertreffen neuronale Netzwerke in Konversationskontexten, während RoBERTa in geschriebenen Genres hervorragend ist.', 'id': 'Memahami bahasa perspektif penting untuk aplikasi seperti sistem dialog dan interaksi manusia-robot. Kami mengusulkan tugas sonda yang menjelajahi bagaimana model bahasa mengerti perspektif ruang. Kami mempersembahkan set data untuk mengevaluasi kesimpulan perspektif dalam bahasa Inggris, ProSPer, dan menggunakannya untuk mengeksplorasi bagaimana manusia dan model bahasa berdasarkan Transformer menyimpulkan perspektif. Although the best bidirectional model performs similarly to humans, they display different strengths: humans outperform neural networks in conversational contexts, while RoBERTa excels at written genres.', 'tr': 'Görnüş dilini düşünmek ählisiniň dýalogy sistemalary we adam-robot teşhisi üçin wajypdyr. Biz dil nusgalarynyň uzay perspektiva nähili gowy düşünýändigini gözlemegi teklip edip otyrys. Biz perspektiva hasaplamak üçin anglisiň, ProSPer dilinde hasaplamak üçin bir dataseti görkeýäris we muny adamlaryň we terjime edilen dil nusgalarynyň düşük perspektivini gözlemek üçin ullanýarys. En iyi bidirektif modeli insana benzer bir şekilde gösterir olsa da, farklı güçleri gösterirler: insanlar tartışma kontekstlerinde nöral ağları çıkarırlar, RoBERTa yazılı jenerallerde harika gelir.', 'af': "Verstaan perspektiewe taal is belangrik vir toepassings soos dialoog stelsels en menslike-robot interaksie. Ons voorstel 'n probe taak wat ondersoek hoe goed taal modele verstaan spasielle perspektief. Ons stel 'n datastel voor die evaluering van perspektief inferensie in Engels, ProSPer en gebruik dit om te ondersoek hoe mense en Transformer-gebaseerde taal modele infer perspektief is. Alhoewel die beste bidireksjonale model gelyk aan mense uitvoer, vertoon hulle verskillende sterkte: mense uitvoer neuralnetwerke in gesprekslykse kontekste, terwyl RoBERTa uitvoer by skryfe genre.", 'fa': 'فهمیدن زبان perspectival برای کاربردهای مثل سیستم\u200cهای گفتگو و تعامل روبات انسان مهم است. ما یک کار تحقیق پیشنهاد می\u200cکنیم که مدل زبان چقدر خوب به نظر فضایی درک می\u200cکند. ما یک مجموعه اطلاعات برای ارزیابی آلودگی دیدگاه در انگلیسی، پرواسپر را پیشنهاد می\u200cکنیم و از آن استفاده می\u200cکنیم تا بفهمیم چگونه مدل\u200cهای زبان\u200cهای انسان و تغییر\u200cپذیر را آلودگی می\u200cکنند. اگرچه بهترین مدل دوره\u200cای شبیه به انسانها انجام می\u200cدهد، آنها نیروهای مختلف را نمایش می\u200cدهند: انسانها شبکه\u200cهای عصبی را در موقعیت\u200cهای گفتگو بیشتر انجام می\u200cدهند، در حالی که روبرتا در جنس نوشته\u200cها بیشتر است.', 'sw': 'Kuelewa lugha ya mtazamo ni muhimu kwa matumizi kama mifumo ya mazungumzo na mahusiano ya roboti ya binadamu. Tunazipendekeza jukumu la mtihani linalogundua namna mifano bora ya lugha inavyoelewa mtazamo wa angani. Tunaweza kuweka seti ya taarifa kwa ajili ya kutathmini maambukizi yanayotokana na mtazamo wa lugha ya Kiingereza, ProSPer, na tunatumia ili kutambua jinsi mifano ya lugha za binadamu na lugha za kizamani hazina mtazamo. Although the best bidirectional model performs similarly to humans, they display different strengths: humans outperform neural networks in conversational contexts, while RoBERTa excels at written genres.', 'hy': 'Պարտեկտիվ լեզու հասկանալը կարևոր է այնպիսի ծրագրերի համար, ինչպիսիք են երկխոսային համակարգերը և մարդկային-ռոբոտի փոխազդեցությունը: Մենք առաջարկում ենք ուսումնասիրել, թե ինչպես են լեզվի մոդելները լավ հասկանում տարածական տեսանկյունին: Մենք ներկայացնում ենք տվյալների համակարգ, որպեսզի գնահատենք տեսանկյունից հետևյալները անգլերենում, ProSP-ում, և օգտագործում ենք այն ուսումնասիրելու համար, թե ինչպես են մարդիկ և տրանֆերմերների լեզվի մոդելները հետևում տեսանկյու Չնայած, որ լավագույն երկուղղային մոդելը գործում է նմանապես մարդկանց հետ, նրանք տարբեր ուժեղություններ են ցույց տալիս. մարդիկ արտադրում են նյարդային ցանցեր խոսակցական կոնտեքստներում, մինչդեռ Ռոբերթան արտադրում է գրված գեներում:', 'az': 'İnsan-robot istifadəsi kimi proqramlar üçün münasibdir. Biz təklif edirik ki, dil modellərinin uzaq perspektivlərini necə yaxşı anladığını keşfetir. İngilizce, ProSPer dilində perspektiv infeksiyonu değerləşdirmək üçün verilən qurğunu göstəririk və insanların və Transformer dilində olan modellərin necə a şağı perspektivlərini keşfetmek üçün istifadə edirik. Ən gözəl nümunə modeli insanlara bənzər işlər görürsə də, onlar müxtəlif qüvvətləri göstərirlər: insanlar söhbət müxtəliflərində nöral şəklilərdən üstün gəlirlər, RoBERTa yazılmış genirlərdə üstün gəlirlər.', 'bn': 'ডায়ালগ সিস্টেম এবং মানুষ-রোবট ইন্টারেকশনের মতো অ্যাপ্লিকেশনের জন্য দৃষ্টিভঙ্গিকার ভাষা বুঝতে গুর আমরা একটি প্রস্তাব করছি যা বিশেষ করে ভাষার মডেল কতটা ভালো ভাষার দৃষ্টিভঙ্গি বুঝতে পারে। আমরা ইংরেজি, প্রসপের ভাষায় দৃষ্টিভঙ্গির আক্রান্ত বিষয়টি মূল্যায়নের জন্য একটি ডাটাসেট উপস্থাপন করি এবং এটি ব্যবহার করি মানুষ এবং ট্রান্ যদিও সবচেয়ে ভালো মডেল মানুষের সাথে একই রকম করে, তারা বিভিন্ন শক্তি প্রদর্শন করে: কথোপকথনে মানুষ নিউরেল নেটওয়ার্ক প্রকাশ করে, আর রোবেরেটা লিখিত জিনিস', 'sq': 'Përkuptimi i gjuhës perspektive është i rëndësishëm për aplikimet si sistemi dialogu dhe ndërveprimi njerëzor-robot. Ne propozojmë një detyrë sonde që eksploron se sa mirë modelet gjuhësore kuptojnë perspektivën hapësirore. Ne paraqesim një set të dhënash për vlerësimin e përfundimit të perspektivës në anglisht, ProSPer, dhe e përdorim atë për të eksploruar se si njerëzit dhe modelet e gjuhës me bazë në Transformer inferojnë perspektivën. Megjithëse modeli më i mirë dy-drejtues funksionon në mënyrë të ngjashme me njerëzit, ata shfaqin fuqi të ndryshme: njerëzit ekzekutojnë rrjetet nervore në kontekste bisedimesh, ndërsa RoBERTa ekzekuton në gjenerë të shkruara.', 'bs': 'Razumijevanje perspektivnog jezika je važno za aplikacije poput dijalogskih sustava i interakcije ljudskih robota. Predlažemo zadatak sonde koji istražuje kako dobro jezički modeli razumiju prostornu perspektivu. Predstavljamo komplet podataka za procjenu infekcije perspektive na engleskom, ProSPer i koristimo ga kako bi istražili kako ljudi i jezički modeli na transformaciji inferiraju perspektivu. Iako najbolji bidirektivni model izvodi slično ljudima, pokazuju različite snage: ljudi izvršavaju neuralne mreže u razgovornim kontekstima, dok RoBERTa nadmaže napisanim genrima.', 'am': 'የመስመር ቋንቋ እና የሰው-ሮቦት ተግባር እንደሚመስል ፕሮግራሞች ያስፈልጋል፡፡ የቋንቋዎች ምሳሌዎች ምን ያህል የስፋዊ ምሳሌ የሚያስተውሉ እንደምናስፈልገው የሞከራ ስራ እናሳውቃለን፡፡ እንግሊዝኛ፣ ፕሮስፓር እና የፊደል ቋንቋ ምሳሌዎች እንዴት እንደሚያሳዩ እና የመረጃ ምሳሌዎችን ለማሳየት የዳታ ሳጥን እናደርጋለን፡፡ የተሻለ አካባቢ ምሳሌ በሰዎች ላይ ቢሆን ግን የተለየ ኃይልን ያሳያል፤ ሰዎች በአካባቢው ግንኙነት ውስጥ የደዌብ መረብ ያሳያል፣ ሮብERTA በተጻፈ የሥርዓት ግንኙነት ላይ ይሻላል፡፡', 'ca': "Understanding perspectival language is important for applications like dialogue systems and human-robot interaction.  Proposem una tasca de sonda que explori com els models lingüístics entenen la perspectiva espacial. Presentam un conjunt de dades per avaluar la infer ència de perspectiva en anglès, ProSPer, i l'utilitzem per explorar com els humans i els models de llenguatge basats en Transformer infereixen la perspectiva. Malgrat que el millor model bidireccional actua de manera similar als humans, mostra diferents fortituds: els humans superen les xarxes neurals en contextes de conversació, mentre que RoBERTa excel·lent en gèneres escrits.", 'et': 'Perspektiivkeele mõistmine on oluline sellistes rakendustes nagu dialoogisüsteemid ja inimese-roboti suhtlus. Pakume välja prooviülesande, mis uurib, kui hästi keelemudelid mõistavad ruumilist perspektiivi. Esitame ingliskeelse perspektiivi järelduste hindamise andmekogumi ProSPer ning uurime, kuidas inimesed ja Transformer-põhised keelemudelid perspektiivi järeldavad. Kuigi parim kahesuunaline mudel toimib samamoodi kui inimesed, näitavad nad erinevaid tugevusi: inimesed ületavad vestluskontekstis närvivõrgustikke, samas kui RoBERTa paistab silma kirjutatud žanrites.', 'fi': 'Perspektiivisen kielen ymmärtäminen on tärkeää esimerkiksi dialogijärjestelmissä ja ihmisen ja robotin vuorovaikutuksessa. Ehdotamme tutkimustehtävää, jossa selvitetään, miten hyvin kielimallit ymmärtävät avaruutta. Esitämme englanninkielisen näkökulman arviointiaineiston ProSPer, ja sen avulla selvitämme, miten ihmiset ja Transformer-pohjaiset kielimallit päättelevät näkökulmaa. Vaikka paras kaksisuuntainen malli toimii samalla tavalla kuin ihminen, niillä on erilaisia vahvuuksia: ihmiset suoriutuvat neuroverkoista keskusteluyhteyksissä, kun taas RoBERTa on erinomainen kirjoitusgenreissä.', 'cs': 'Porozumění perspektivnímu jazyku je důležité pro aplikace, jako jsou dialogové systémy a interakce člověk-robot. Navrhujeme sondový úkol, který zkoumá, jak dobře jazykové modely chápou prostorovou perspektivu. Představujeme datovou sadu pro hodnocení perspektivních inferencí v angličtině, ProSPer, a používáme ji k prozkoumání, jak lidé a jazykové modely založené na Transformeru odvozují perspektivu. Ačkoli nejlepší obousměrný model funguje podobně jako člověk, vykazují různé silné stránky: lidé překonávají neuronové sítě v konverzačních kontextech, zatímco RoBERTa vyniká v psaných žánrech.', 'sk': 'Razumevanje perspektivnega jezika je pomembno za aplikacije, kot so dialogni sistemi in interakcija med človekom in robotom. Predlagamo nalogo, ki raziskuje, kako dobro jezikovni modeli razumejo prostorsko perspektivo. Predstavljamo nabor podatkov za ocenjevanje perspektivne sklepe v angleščini, ProSPer, in ga uporabljamo za raziskovanje, kako ljudje in transformatorski jezikovni modeli sklepajo perspektivo. Čeprav najboljši dvosmerni model deluje podobno kot ljudje, kažejo različne prednosti: ljudje v pogovornih kontekstih presegajo nevronske mreže, RoBERTa pa odlikuje v pisanih žanrih.', 'he': 'להבין שפה פרספקטיבית חשובה לתוכניות כמו מערכות דיאלוג ואינטראקציה אנושית-רובוטית. אנו מציעים משימה חוקרת שמחקרת איך מודלים שפות מבינים היטב פרספקטיבה חללית. אנו מציגים קבוצת נתונים להערכה המצאה הפרספקטיבית באנגלית, פרוספר, ולהשתמש בה כדי לחקור איך בני אדם ודוגמני שפה מבוססים על טרנספורטר מונחים פרספקטיבה. למרות שהמודל הדיוני הטוב ביותר מתבצע באופן דומה לבני אדם, הם מציגים כוחות שונים: בני אדם מתגברים על רשתות עצביות בתוך קשרי שיחה, בזמן שרוברטה מתפקדת על גנרס כתוב.', 'bo': 'ཉེར་སྤྱོད་ཀྱི་ལྟ་རྟོག་པའི་སྐད་ཡིག་ནི་རྟོགས་འདོན་པ་ལས་ཉེར་སྤྱོད་ཆས་མིན་ན་དང་མིན་འདུག ང་ཚོས་སྐད་ཡིག་ཆ་དཔེ་གཞུང་གིས་མཐོང་ནུས་མེད་པར་ལྟ་བུ་ཞིག་དང་། ང་ཚོས་དབྱིན་ཡིག་ཆ་དང་། ལས་ཀྱང་གསལ་བཅས་ཀྱི་མཐོང་བའི་མཐོང་སྣང་ཚུལ་ལྟ་བུ་འཇུག་སྟེ། གཟུགས་རིས་བཀོད་པའི་མ་དབྱིབས་གང་འདྲ་ཞིག་ཡིན་ནའང་མི་འདྲ་བ་དང་འདྲ་བ་མངོན་ཡོད།', 'ha': "An fahimta harshen wanda ke kallo na muhimu wa shiryoyin ayuka kamar na'urar zauren akwatin bayanin zauren akwatin bayani da shirin mutum-bot. We propose a probe task that explores how well language models understand spatial perspective.  Tuna halatar da wani danne dõmin ka yi amfani da misãlai masu ƙaranci cikin Ingiriya, ProSPer, kuma don ka yi amfani da shi dõmin ka gane yadda mutane da misalin harshen wanda ke rubutu da wanda ke cikin shi. Ingawa da mafi kyaun motsi na ƙaranci ke aiki kamar mutane, sai su nuna ƙarfi dabam-daban: mutane ke ƙarfafa mitandan neural cikin mazaɓa masu husũma, kuma da RoBERTa ta ƙarfafa a rubũtan genre.", 'jv': 'Awakdhéwé ngerasakno perspekntal luwih akeh nggo aplikasi kaya sistem dialog lan ijol-ijol sing nyelarane ning daerahé apat-apat. Monday Awak dhéwé éntuk dataset kanggo nggawe perspekpekpektur nggambar apa kanggo inggiles, ProSpar, lan usukake kuwi nggawe ngubah manipulan manut lan transformer Mangko, model sing dibenadekaan sing luwih apik lan akeh sampeyan sampeyan karo wong liyane, iki dadi nggawe ngupakan seneng ngregani uwong: wong liyane wis mbutuhak netwisan nyerane karo kontribusi tarjamahan, sampeyan RonBERT kuwi wis mbutuhak ujaran genr-ujaran.'}
{'en': 'Transferring Knowledge from Vision to Language : How to Achieve it and how to Measure it?', 'pt': 'Transferindo o conhecimento da visão para a linguagem: como alcançá-lo e como medi-lo?', 'ar': 'نقل المعرفة من رؤية إلى لغة: كيف نحققها وكيف نقيسها؟', 'fr': 'Transférer les connaissances de la vision au langage\xa0: comment les atteindre et comment les mesurer\xa0?', 'es': 'Transferencia del conocimiento de la visión al lenguaje: ¿cómo lograrlo y cómo medirlo?', 'ja': 'ビジョンから言語への知識の転移：それを達成する方法とそれを測定する方法？', 'ru': 'Передача знаний от видения к языку: как достичь этого и как измерить его?', 'hi': 'दृष्टि से भाषा में ज्ञान को स्थानांतरित करना: इसे कैसे प्राप्त करें और इसे कैसे मापें?', 'zh': '移从愿景语言,何以致之?', 'ga': 'Ag Aistriú Eolais ó Fhís go Teanga: Conas É a Bhaint Amach agus Conas É a Thomhas?', 'ka': 'ცნობილის შესახებისგან ენაში გადატვირცელება: როგორ მივიღოთ და როგორ მივიღოთ?', 'hu': 'Tud찼s 찼tad찼sa a l찼t찼sr처l a nyelvre: Hogyan 챕rj체k el 챕s hogyan m챕rj체k meg?', 'el': 'Μεταφορά Γνώσης από το Όραμα στη Γλώσσα: Πώς να την επιτύχετε και πώς να την μετρήσετε;', 'it': 'Trasferire la conoscenza dalla visione alla lingua: come raggiungerla e come misurarla?', 'kk': 'Мәліметті көрініс тіліне аудару: оны қалай жеткізу және қалай өлшеу?', 'lt': 'Žinių perdavimas iš vizijos į kalbą: kaip ją pasiekti ir kaip ją išmatuoti?', 'mk': 'Пренесување на знаење од визија на јазик: Како да го постигнеме и како да го мериме?', 'ml': 'കണ്ണില്\u200d നിന്നും ഭാഷയിലേക്കും അറിവ് മാറ്റുന്നു: എങ്ങനെയാണ് അതിനെ എടുക്കുക, എങ്ങനെയാണ് അളക്കുക?', 'ms': 'Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?', 'mn': 'Мэдлэгийг үзэхээс хэл руу шилжүүлж байна: яаж олох, хэрхэн хэмжих вэ?', 'no': 'Overfører kunnskap frå vising til språk: Korleis å henta det og korleis å måla det?', 'pl': 'Transfer wiedzy z wizji do języka: jak ją osiągnąć i jak ją mierzyć?', 'ro': 'Transferul cunoștințelor de la viziune la limbă: Cum să le atingeți și cum să le măsurați?', 'sr': 'Prebacivanje znanja iz vizije na jezik: kako da ga nabavimo i kako da ga izmjerimo?', 'so': 'Aqoonta la soo wareejiyo muujinta ilaa luuqada: Sidee baad u heshaa iyo sida loo qiyaasaa?', 'si': 'දර්ශනයෙන් භාෂාවට දැනගන්න: කොහොමද ඒක අල්ලගන්න හා කොහොමද ඒක අල්ලගන්න?', 'sv': 'Överföra kunskap från vision till språk: Hur man uppnår den och hur man mäter den?', 'ta': 'பார்வையிலிருந்து மொழிக்கு அறிவிப்பு மாற்றப்படுகிறது: அதை எவ்வாறு பெறுவது மற்றும் எவ்வாறு அளவிடுவது?', 'ur': 'علم کو آنکھوں سے زبان کی طرف لے جاتا ہے کہ اسے کس طرح پہنچا سکتا ہے اور کس طرح اندازہ لینے والا ہے', 'mt': 'It-Trasferiment tal-Għarfien mill-Viżjoni għal-Lingwa: Kif jinkiseb u kif għandu jitkejjel?', 'uz': 'Ko\xa0Ľrinish tiliga ta\xa0ľrif olinmoqda: Uni qanday olib tashlash va qanday o\xa0Ľlchamini o\xa0Ľzgartirish mumkin?', 'vi': 'Truyền bá tri thức từ Tầm nhìn sang Ngôn ngữ: Cách đạt được nó và cách đo nó?', 'bg': 'Прехвърляне на знания от визия на език: Как да го постигнем и как да го измерим?', 'da': 'Overførsel af viden fra vision til sprog: Hvordan opnår man det, og hvordan man måler det?', 'de': 'Wissen von Vision in Sprache übertragen: Wie erreicht man es und wie misst man es?', 'id': 'Memindahkan pengetahuan dari Vision ke Bahasa: Bagaimana untuk mencapainya dan bagaimana untuk mengukur?', 'ko': '지식을 시각에서 언어로 옮기기: 어떻게 실현하고 평가합니까?', 'hr': 'Prebacivanje znanja iz vizije na jezik: kako da ga ostvarimo i kako da ga izmjerimo?', 'nl': 'Kennis overbrengen van visie naar taal: Hoe bereik je het en hoe meet je het?', 'sw': 'Kuhamishia maarifa kutoka Vision hadi Lugha: Inawezaje kupata ujuzi na jinsi gani kulipima?', 'tr': 'Bilgi G철rn체힊den dile ta첵첵arlamak: ony n채dip 첵erine 첵etirmeli we n채dip 철l챌체meli?', 'af': 'Ontwinder kennis van Besigtiging na Taal: Hoe om dit te kry en hoe om dit te maak?', 'am': 'እውቀትን ከራእይ ወደ ቋንቋ ይለወጥ፤ እንዴት ያግኘዋል እንዴት ይለካል?', 'fa': 'دانش را از دید به زبان انتقال می\u200cدهد: چگونه آن را می\u200cرسانیم و چگونه آن را می\u200cاندازیم؟', 'az': 'G칬zl톛rin elmi dilin톛 g칬nd톛rilir: onu nec톛 tap캼b nec톛 칬l칞칲rm톛k?', 'bn': 'ভিশন থেকে ভাষা পর্যন্ত জ্ঞান পরিবর্তন করা হচ্ছে: এটা কিভাবে আচিয়ে আনতে পারে এবং কিভাবে এটা পরিমাপ করতে পারে?', 'bs': 'Prebacivanje znanja iz vizije na jezik: kako da ga ostvarimo i kako da ga izmjerimo?', 'sq': 'Transferimi i njohurive nga vizioni në gjuhë: Si ta arrijmë dhe si ta masojmë?', 'ca': 'Transferir coneixements de la Visió a la llengua: Com aconseguir-lo i com mesurar-lo?', 'hy': 'Տեսանքից լեզվի գիտելիքների փոխանցումը. ինչպես հասնել դրան և ինչպես չափել այն:', 'fi': 'Tiedon siirtäminen visiosta kieleen: Kuinka saavuttaa se ja miten mitata se?', 'cs': 'Přenos znalostí z vize do jazyka: Jak je dosáhnout a jak je měřit?', 'et': 'Teadmiste ülekandmine visioonist keelele: kuidas seda saavutada ja kuidas seda mõõta?', 'jv': 'Ngubah Kemerdekaan Karo Kemerdekaan kanggo Language: piye ngetoke nggawe layar lan kemerdekaan kuwi ?', 'he': 'Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?', 'ha': 'Sauya ilmi daga gannai zuwa harshe: Yãya zai iya sãma shi kuma ana ƙaddara shi?', 'sk': 'Prenos znanja iz vizije v jezik: kako ga doseči in kako ga meriti?', 'bo': 'མཐོང་སྣང་ལས་སྐད་ཡིག་ལ་གནས་སྐྱོད་པ། ཇི་ལྟར་ཡར་རྒྱས་ལ་འཛུགས་དང་ཇི་ལྟར་ཚད་འཛིན་དགོས་སམ།'}
{'en': 'Large language models are known to suffer from the hallucination problem in that they are prone to output statements that are false or inconsistent, indicating a lack of knowledge. A proposed solution to this is to provide the model with additional data modalities that complements the knowledge obtained through text. We investigate the use of visual data to complement the knowledge of large language models by proposing a method for evaluating visual knowledge transfer to text for uni- or multimodal language models. The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions. Additionally, we introduce a model architecture that involves a visual imagination step and evaluate it with our proposed method. We find that our method can successfully be used to measure visual knowledge transfer capabilities in models and that our novel model architecture shows promising results for leveraging multimodal knowledge in a unimodal setting.', 'pt': 'Grandes modelos de linguagem são conhecidos por sofrerem do problema da alucinação, pois são propensos a produzir declarações falsas ou inconsistentes, indicando falta de conhecimento. Uma solução proposta para isso é fornecer ao modelo modalidades de dados adicionais que complementem o conhecimento obtido por meio de texto. Investigamos o uso de dados visuais para complementar o conhecimento de grandes modelos de linguagem, propondo um método para avaliar a transferência de conhecimento visual para texto para modelos de linguagem uni ou multimodais. O método é baseado em duas etapas, 1) uma nova tarefa de consulta de conhecimento de cores de memória, ou seja, cores típicas de objetos bem conhecidos, e 2) filtragem de dados de treinamento do modelo para separar claramente as contribuições de conhecimento. Além disso, apresentamos uma arquitetura de modelo que envolve uma etapa de imaginação visual e a avaliamos com nosso método proposto. Descobrimos que nosso método pode ser usado com sucesso para medir as capacidades de transferência de conhecimento visual em modelos e que nossa nova arquitetura de modelo mostra resultados promissores para alavancar o conhecimento multimodal em um ambiente unimodal.', 'fr': "Les grands modèles linguistiques sont connus pour souffrir du problème d'hallucination en ce sens qu'ils sont enclins à produire des déclarations fausses ou incohérentes, indiquant un manque de connaissances. Une solution proposée consiste à fournir au modèle des modalités de données supplémentaires qui complètent les connaissances obtenues par le biais du texte. Nous étudions l'utilisation de données visuelles pour compléter la connaissance de grands modèles linguistiques en proposant une méthode d'évaluation du transfert de connaissances visuelles en texte pour des modèles linguistiques unimodaux ou multimodaux. Le procédé est basé sur deux étapes, 1) une nouvelle tâche demandant la connaissance des couleurs de la mémoire, c'est-à-dire des couleurs typiques d'objets connus, et 2) le filtrage des données d'apprentissage du modèle afin de séparer clairement les contributions de connaissances. De plus, nous introduisons une architecture de modèle qui implique une étape d'imagination visuelle et l'évaluons avec la méthode que nous proposons. Nous constatons que notre méthode peut être utilisée avec succès pour mesurer les capacités de transfert de connaissances visuelles dans des modèles et que notre nouvelle architecture de modèle montre des résultats prometteurs pour tirer parti des connaissances multimodales dans un environnement unimodal.", 'ar': 'من المعروف أن النماذج اللغوية الكبيرة تعاني من مشكلة الهلوسة من حيث أنها عرضة لتصريحات ناتجة خاطئة أو غير متسقة ، مما يشير إلى نقص المعرفة. الحل المقترح لهذا هو تزويد النموذج بطرائق بيانات إضافية تكمل المعرفة التي تم الحصول عليها من خلال النص. نحن نحقق في استخدام البيانات المرئية لاستكمال معرفة نماذج اللغة الكبيرة من خلال اقتراح طريقة لتقييم نقل المعرفة المرئية إلى نص لنماذج لغة أحادية أو متعددة الوسائط. تعتمد الطريقة على خطوتين ، 1) مهمة جديدة للاستعلام عن معرفة ألوان الذاكرة ، أي الألوان النموذجية للكائنات المعروفة ، و 2) تصفية بيانات التدريب النموذجية لفصل مساهمات المعرفة بوضوح. بالإضافة إلى ذلك ، نقدم بنية نموذجية تتضمن خطوة تخيل بصري ونقوم بتقييمها باستخدام طريقتنا المقترحة. وجدنا أنه يمكن استخدام طريقتنا بنجاح لقياس قدرات نقل المعرفة المرئية في النماذج وأن بنية النموذج الجديدة لدينا تظهر نتائج واعدة للاستفادة من المعرفة متعددة الوسائط في بيئة أحادية الوسائط.', 'es': 'Se sabe que los modelos lingüísticos grandes sufren el problema de las alucinaciones, ya que son propensos a emitir declaraciones falsas o inconsistentes, lo que indica una falta de conocimiento. Una solución propuesta para esto es proporcionar al modelo modalidades de datos adicionales que complementen el conocimiento obtenido a través del texto. Investigamos el uso de datos visuales para complementar el conocimiento de modelos lingüísticos grandes proponiendo un método para evaluar la transferencia de conocimiento visual al texto para modelos lingüísticos unimodales o multimodales. El método se basa en dos etapas, 1) una tarea novedosa que consulta el conocimiento de los colores de la memoria, es decir, los colores típicos de objetos conocidos, y 2) el filtrado de los datos de entrenamiento del modelo para separar claramente las contribuciones de conocimiento. Además, introducimos una arquitectura modelo que implica un paso de imaginación visual y la evaluamos con nuestro método propuesto. Descubrimos que nuestro método se puede utilizar con éxito para medir las capacidades de transferencia de conocimiento visual en los modelos y que nuestra nueva arquitectura de modelos muestra resultados prometedores para aprovechar el conocimiento multimodal en un entorno unimodal.', 'ja': '大言語モデルは、知識の欠如を示す誤ったまたは一貫性のない文を出力する傾向があるという点で、幻覚の問題に苦しむことが知られている。 これに対する提案された解決策は、テキストを通じて得られた知識を補完する追加のデータモデルをモデルに提供することである。 単式または多式言語モデルのテキストへの視覚的知識の転移を評価する方法を提案することにより、大規模言語モデルの知識を補完するための視覚的データの使用を調査します。 この方法は、２つのステップに基づいており、１ ）メモリカラー、すなわち周知のオブジェクトの典型的な色の知識を照会する新規のタスク、及び２ ）知識貢献を明確に分離するためのモデルトレーニングデータのフィルタリングである。 さらに、視覚的な想像ステップを伴うモデルアーキテクチャを紹介し、提案された方法で評価します。 私たちの方法は、モデルにおける視覚的知識伝達能力を測定するためにうまく使用することができ、私たちの新規のモデルアーキテクチャは、単式の環境でマルチモーダル知識を活用するための有望な結果を示していることがわかります。', 'zh': '众所周知,大言幻觉,以其易失与不同者,明无知也。 其解决方案为模形额外数式,以补文本之知。 论单模多模态言语移文本,论用视数以补大言。 其法基于两步驿,1)一新颖之任,询其所识,即已知所在之典色,及2)过漉模练数以明离之。 此外引入一目想像步架构,并用吾法质之。 吾见吾道之可以成功而度其视也,而吾新型架构以多模态见其所欲也。', 'hi': 'बड़े भाषा मॉडल मतिभ्रम की समस्या से पीड़ित होने के लिए जाने जाते हैं कि वे आउटपुट बयानों के लिए प्रवण होते हैं जो झूठे या असंगत होते हैं, जो ज्ञान की कमी का संकेत देते हैं। इसका एक प्रस्तावित समाधान मॉडल को अतिरिक्त डेटा तौर-तरीकों के साथ प्रदान करना है जो पाठ के माध्यम से प्राप्त ज्ञान को पूरक करता है। हम यूनि- या मल्टीमॉडल भाषा मॉडल के लिए पाठ में दृश्य ज्ञान हस्तांतरण का मूल्यांकन करने के लिए एक विधि का प्रस्ताव करके बड़े भाषा मॉडल के ज्ञान को पूरक करने के लिए दृश्य डेटा के उपयोग की जांच करते हैं। विधि दो चरणों पर आधारित है, 1) स्मृति रंगों के ज्ञान के लिए एक उपन्यास कार्य क्वेरी, यानी प्रसिद्ध वस्तुओं के विशिष्ट रंग, और 2) ज्ञान योगदान को स्पष्ट रूप से अलग करने के लिए मॉडल प्रशिक्षण डेटा का फ़िल्टरिंग। इसके अतिरिक्त, हम एक मॉडल आर्किटेक्चर पेश करते हैं जिसमें एक दृश्य कल्पना चरण शामिल है और हमारी प्रस्तावित विधि के साथ इसका मूल्यांकन करता है। हम पाते हैं कि हमारी विधि का उपयोग मॉडल में दृश्य ज्ञान हस्तांतरण क्षमताओं को मापने के लिए सफलतापूर्वक किया जा सकता है और यह कि हमारा उपन्यास मॉडल आर्किटेक्चर एक यूनिमोडल सेटिंग में मल्टीमॉडल ज्ञान का लाभ उठाने के लिए आशाजनक परिणाम दिखाता है।', 'ru': 'Крупные языковые модели, как известно, страдают от проблемы галлюцинаций, поскольку они склонны к выходным утверждениям, которые являются ложными или противоречивыми, что указывает на недостаток знаний. Предлагаемое решение заключается в том, чтобы обеспечить модель дополнительными формами данных, которые дополняют знания, полученные с помощью текста. Мы исследуем использование визуальных данных в дополнение к знаниям крупных языковых моделей, предлагая метод оценки передачи визуальных знаний в текст для уни- или мультимодальных языковых моделей. Метод основан на двух этапах: 1) новый запрос на знание цветов памяти, то есть типичных цветов известных объектов, и 2) фильтрация данных обучения модели для четкого разделения вкладов знаний. Кроме того, мы вводим модельную архитектуру, которая включает в себя этап визуального воображения, и оцениваем ее с помощью предложенного нами метода. Мы находим, что наш метод может быть успешно использован для измерения возможностей передачи визуальных знаний в моделях и что наша новая архитектура модели показывает многообещающие результаты для использования мультимодальных знаний в условиях одного вида транспорта.', 'ga': 'Is eol go bhfuil fadhb na bréagchráifeachta ag fulaingt ó mhúnlaí móra teanga sa mhéid is go mbíonn siad seans maith go ráitis aschuir atá bréagach nó neamh-chomhsheasmhach, rud a léiríonn easpa eolais. Réiteach molta air seo is ea módúlachtaí sonraí breise a chur ar fáil don tsamhail a chomhlánaíonn an t-eolas a fhaightear trí théacs. Déanaimid imscrúdú ar úsáid sonraí amhairc chun cur leis an eolas ar mhúnlaí móra teanga trí mhodh a mholadh chun aistriú eolais amhairc go téacs a mheas do mhúnlaí teanga uni- nó ilmhódacha. Tá an modh bunaithe ar dhá chéim, 1) tasc nua ag fiosrú eolas ar dhathanna na cuimhne, i.e. dathanna tipiciúla rudaí a bhfuil aithne mhaith orthu, agus 2) scagadh sonraí oiliúna samhlacha chun rannchuidithe eolais a dheighilt go soiléir. Ina theannta sin, tugaimid isteach ailtireacht mhúnla a bhfuil céim samhlaíochta amhairc i gceist leis agus déanaimid é a mheas lenár modh molta. Faighimid amach gur féidir ár modh a úsáid go rathúil chun cumais aistrithe eolais amhairc i múnlaí a thomhas agus go léiríonn ár n-ailtireacht samhlacha nua torthaí geallta maidir le giaráil eolas ilmhódach i suíomh aonmhódúil.', 'el': 'Τα μεγάλα γλωσσικά μοντέλα είναι γνωστό ότι υποφέρουν από το πρόβλημα παραισθήσεων, καθώς είναι επιρρεπείς σε δηλώσεις εξόδου που είναι λανθασμένες ή ασυνεπή, υποδεικνύοντας έλλειψη γνώσης. Μια προτεινόμενη λύση σε αυτό είναι η παροχή στο μοντέλο με πρόσθετες λεπτομέρειες δεδομένων που συμπληρώνουν τις γνώσεις που αποκτώνται μέσω κειμένου. Ερευνούμε τη χρήση οπτικών δεδομένων για τη συμπλήρωση της γνώσης μεγάλων γλωσσικών μοντέλων προτείνοντας μια μέθοδο αξιολόγησης της οπτικής μεταφοράς γνώσης στο κείμενο για μονο- ή πολυμορφικά γλωσσικά μοντέλα. Η μέθοδος βασίζεται σε δύο βήματα, 1) μια νέα εργασία διερεύνησης γνώσεων χρωμάτων μνήμης, δηλαδή τυπικών χρωμάτων γνωστών αντικειμένων, και 2) φιλτράρισμα δεδομένων κατάρτισης μοντέλου για να διαχωρίσει σαφώς τις συνεισφορές γνώσης. Επιπλέον, εισάγουμε μια πρότυπη αρχιτεκτονική που περιλαμβάνει ένα βήμα οπτικής φαντασίας και την αξιολογούμε με την προτεινόμενη μέθοδο. Διαπιστώνουμε ότι η μέθοδος μας μπορεί να χρησιμοποιηθεί με επιτυχία για τη μέτρηση των δυνατοτήτων οπτικής μεταφοράς γνώσης σε μοντέλα και ότι η νέα αρχιτεκτονική μοντέλων μας παρουσιάζει πολλά υποσχόμενα αποτελέσματα για την αξιοποίηση της πολυμορφικής γνώσης σε ένα ενιαίο περιβάλλον.', 'hu': 'A nagy nyelvi modellek ismertek, hogy szenvednek a hallucinációs problémáktól, mivel hajlamosak a hamis vagy következetlen kimeneti állításokra, amelyek a tudás hiányára utalnak. Ennek javasolt megoldása az, hogy a modell további adatmódokat biztosítson, amelyek kiegészítik a szövegben szerzett ismereteket. Vizuális adatok felhasználását vizsgáljuk a nagy nyelvi modellek ismeretének kiegészítésére, egy- vagy multimodális nyelvi modellek vizuális tudásátvitelének értékelésére. A módszer két lépésen alapul: 1) egy új feladat lekérdezése a memória színeinek ismeretére, azaz a jól ismert objektumok tipikus színeire, és 2) modellképzési adatok szűrésére, hogy világosan elkülönítsék a tudáshoz való hozzájárulást. Ezenkívül bemutatunk egy olyan modell architektúrát, amely magában foglalja a vizuális képzelet lépését, és értékeljük azt javasolt módszerünkkel. Úgy találjuk, hogy módszerünk sikeresen használható a vizuális tudásátadási képességek modellekben történő mérésére, és új modellarchitektúránk ígéretes eredményeket mutat a multimodális tudás unimodális környezetben történő kihasználására.', 'ka': 'დიდი ენის მოდელები უცნობიან, რომ ჰალუცინაციის პრობლემადან დაკავშირებულია, რომ ისინი წარმოიდგინენ გამოყენება, რომლებიც არაფერი ან არაფერი, რომლებიც უცნობის არაფ ეს საზოგადომის გარეშე არის მოდელს დამატებული მონაცემების მოდულებით, რომლებიც ტექსტით მიღებული ცნობილების დამატებს. ჩვენ ვიყავით ვიზუალური მონაცემების გამოყენება, რომელიც დიდი ენის მოდელების ცოცხლების შემდეგ გავაკეთებთ, ვიზუალური ცოცხოვრების გადასვლება ტექსტის ერთ- ან მულტიმოდელური ენ პროგრამა ორი ნაწილის დაბაზიან, 1) პრომენტი დავალება, რომელიც მეხსიერების ფერების მეცნიერების შესახებ, მაგალითად უცნობიერი ფერების ტიპიკური ფერები, და 2) მოდელს განაკეთებული მონაცემების მო დამატებით, ჩვენ მოდელური არქტიქტურის შესახებ, რომელიც ვიზუალური გამოსახულების კონფიგურაციის კონფიგურაცია და გავამუშავებთ ჩვენი მიზეზეზე ჩვენ აღმოჩნეთ, რომ ჩვენი მეთოდი შეიძლება იყენება, რომ ვიზუალური ცნობილის გადატანსტირების შესაძლებლობად მოდელში და რომ ჩვენი პრომენური მოდელური აქტიქტიქტირება ჩვენი მომედილური მოდელ', 'it': "I modelli linguistici di grandi dimensioni sono noti per soffrire del problema delle allucinazioni in quanto sono inclini a dichiarazioni di output che sono false o incoerenti, indicando una mancanza di conoscenza. Una soluzione proposta è quella di fornire al modello ulteriori modalità di dati che completino le conoscenze acquisite attraverso il testo. Investighiamo l'uso di dati visivi per integrare la conoscenza di modelli linguistici di grandi dimensioni proponendo un metodo per valutare il trasferimento visivo di conoscenza al testo per modelli linguistici unimodali o multimodali. Il metodo si basa su due passaggi, 1) un nuovo task questing per la conoscenza dei colori della memoria, cioè dei colori tipici di oggetti noti, e 2) il filtraggio dei dati di formazione del modello per separare chiaramente i contributi di conoscenza. Inoltre, introduciamo un modello di architettura che prevede un passo di immaginazione visiva e la valutiamo con il nostro metodo proposto. Scopriamo che il nostro metodo può essere utilizzato con successo per misurare le capacità di trasferimento visivo delle conoscenze nei modelli e che la nostra nuova architettura modello mostra risultati promettenti per sfruttare la conoscenza multimodale in un ambiente unimodale.", 'kk': 'Ең үлкен тіл үлгілері біледі, олар білім жоқ дегенді көрсету үшін халлюзинациялық мәселелерінен қатысты немесе тәуелсіз сөйлемелерді шығаруға көмектеседі. Бұл үшін мәтін арқылы алған мәліметті қосымша мәліметті қосымша деректер әдістерін үлгілеу үшін ұсынылған шешім. Біз үлкен тіл үлгілерінің білімін қолдану үшін визуалдық деректерді қолдануды зерттеп, бірнеше не көп- модалдық тіл үлгілерінің мәтініне аудару әдісін бағалау үшін әдісін ұсыны Бұл әдіс екі қадам негізінде, 1) жады түстерін білеу үшін жаңа тапсырма, мысалы, білетін нысандардың әдетті түстері және 2) мәліметтерді бөліктеу үшін модель оқыту деректерін сүзгілеу. Қосымша, біз көрінетін архитектура үлгісін келтіріп, оны қолданылатын әдімімізмен оқу үлгісін таңдаймыз. Біз өзіміздің әдімімізді модельдерде көрінетін білім беру мүмкіндіктерін өлшейту үшін сәтті қолданылады және романдық үлгі архитектурамыз бірнеше мәліметті білім беру үшін бірнеше мәлі', 'lt': 'Žinoma, kad didelės kalbos modeliai kenčia nuo haliucinacijos problemos, nes jie linkę gauti klaidingus ar nenuoseklius išrašus, rodančius žinių trūkumą. Siūlomas šio sprendimo sprendimas – suteikti modeliui papildomas duomenų formas, papildančias tekstu gautas žinias. We investigate the use of visual data to complement the knowledge of large language models by proposing a method for evaluating visual knowledge transfer to text for uni- or multimodal language models.  The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions.  Be to, įvedame modelio architektūrą, apimančią vizualinę vaizduotę ir vertiname ją pasiūlytu metodu. Mes manome, kad mūsų metodas gali būti sėkmingai naudojamas vizualių žinių perdavimo pajėgumų modeliuose matavimui ir kad mūsų naujasis modelio architektūra rodo pažadėtinus rezultatus, kaip suvienodinti daugiarūšio transporto žinias vienmodalinėje aplinkoje.', 'ms': 'Model bahasa besar diketahui menderita dari masalah halusinasi kerana mereka cenderung untuk output pernyataan yang palsu atau tidak konsisten, menunjukkan kekurangan pengetahuan. Solusi direncanakan untuk ini adalah untuk menyediakan model dengan modaliti data tambahan yang menyempurnakan pengetahuan yang diperoleh melalui teks. Kami menyelidiki penggunaan data visual untuk menambahkan pengetahuan model bahasa besar dengan melamar kaedah untuk menilai pemindahan pengetahuan visual ke teks untuk model bahasa uni- atau multimodal. Kaedah ini berdasarkan dua langkah, 1) tugas baru yang bertanya untuk pengetahuan warna memori, iaitu warna biasa objek yang diketahui, dan 2) penapisan data latihan model untuk kontribusi pengetahuan yang jelas terpisah. Additionally, we introduce a model architecture that involves a visual imagination step and evaluate it with our proposed method.  We find that our method can successfully be used to measure visual knowledge transfer capabilities in models and that our novel model architecture shows promising results for leveraging multimodal knowledge in a unimodal setting.', 'mk': 'Големите јазички модели се познати дека страдаат од халуцинациониот проблем бидејќи тие се навикнати на издадени изјави кои се лажни или несогласни, што покажува недостаток на знаење. Предложено решение за ова е да му се обезбедат на моделот дополнителни модели на податоци кои го комплиментираат знаењето добиено преку текст. Го истражуваме употребата на визуелни податоци за комплиментирање на знаењето на големите јазички модели со предложување на метод за проценка на трансфер на визуелно знаење на текст за уни- или мултимодилни јазички модели. The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions.  Покрај тоа, воведуваме модел на архитектура кој вклучува чекор на визуелна фантазија и го оценуваме со нашиот предложен метод. Најдовме дека нашиот метод може успешно да се употреби за мерење на способностите за трансфер на визуелно знаење во моделите и дека нашата нова архитектура на моделот покажува ветувачки резултати за влијание на мултимодилното знаење во унимодално место.', 'ml': 'മഹത്തായ ഭാഷ മോഡലുകള്\u200dക്ക് വേദന അനുഭവിക്കാന്\u200d അറിയുന്നുണ്ട്. അതിനാല്\u200d അവയൊക്കെയും വ്യാജമാണോ അസാധ്യതയോ അല്ലെങ്കില്\u200d അസാധ്യതയോ  ഇതിനു വേണ്ടി ഒരു പ്രായശ്ചിത്തമായ പരിഹാരം മോഡലിന്റെ കൂടുതല്\u200d ഡേറ്റാ രീതികള്\u200d കൊടുക്കുക എന്നതാണ് വാചകത്തി കാഴ്ച മാതൃകങ്ങളുടെ അറിവ് പൂര്\u200dത്തിയാക്കുന്നതിനാല്\u200d കാഴ്ചയുള്ള ഡേറ്റാ ഉപയോഗിക്കുന്നത് നാം അന്വേഷിക്കുന്നു. യൂണി- അല്ലെങ്കില്\u200d  ഈ രീതിയില്\u200d രണ്ടു പടികളില്\u200d അടിസ്ഥാനമാണ്, 1) മെമ്മറി നിറങ്ങളുടെ അറിവിനുള്ള ഒരു നോവല്\u200d ജോലിയുടെ അടിസ്ഥാനത്താണ്, ഉദാഹരണമായി അറിയപ്പെട്ട വസ്തുക്കളുടെ സാധ കൂടാതെ, നമ്മള്\u200d ഒരു മോഡല്\u200d ആര്\u200dക്ടിക്കറ്റിക്കേറ്റര്\u200d പരിചയപ്പെടുത്തുന്നു. അത് കാഴ്ചകളുടെ ചിത്രം ചേര്\u200dന്ന് നമ്മുടെ പ്രോ നമ്മുടെ രീതിയില്\u200d വിജയകരമായി ഉപയോഗിക്കാന്\u200d നമ്മുടെ രീതിയില്\u200d പരിജ്ഞാനത്തിന്റെ സാധ്യതകള്\u200d മാതൃകങ്ങളില്\u200d അളക്കാന്\u200d ഉപയോഗിക്കുന്നു. നമ്മുടെ ന', 'pl': 'Duże modele językowe są znane z powodu problemu halucynacji, ponieważ są podatne na wyjście stwierdzeń, które są fałszywe lub niespójne, wskazując na brak wiedzy. Proponowanym rozwiązaniem tego problemu jest dostarczenie modelowi dodatkowych metod danych uzupełniających wiedzę uzyskaną za pomocą tekstu. Badamy wykorzystanie danych wizualnych w celu uzupełnienia wiedzy o dużych modelach językowych, proponując metodę oceny wizualnego transferu wiedzy do tekstu dla modeli językowych uni- lub multimodalnych. Metoda opiera się na dwóch etapach: 1) nowatorskim zadaniu zapytania o znajomość kolorów pamięci, czyli typowych kolorów znanych obiektów oraz 2) filtrowaniu danych szkoleniowych modelu w celu wyraźnego oddzielenia wkładu wiedzy. Dodatkowo wprowadzamy modelową architekturę, która obejmuje krok wizualnej wyobraźni i oceniamy ją za pomocą proponowanej metody. Stwierdzamy, że nasza metoda może być z powodzeniem wykorzystana do pomiaru możliwości wizualnego transferu wiedzy w modelach, a nasza nowa architektura modelu pokazuje obiecujące rezultaty w wykorzystaniu wiedzy multimodalnej w otoczeniu unimodalnym.', 'mt': 'Mudelli lingwistiċi kbar huma magħrufa li jsofru mill-problem a tal-alluċinazzjoni peress li huma suxxettibbli għal dikjarazzjonijiet ta’ output li huma foloz jew inkonsistenti, li jindikaw nuqqas ta’ għarfien. A proposed solution to this is to provide the model with additional data modalities that complements the knowledge obtained through text.  Aħna ninvestigaw l-użu ta’ dejta viżwali biex nikkumplimentaw l-għarfien ta’ mudelli lingwistiċi kbar billi nipproponu metodu għall-evalwazzjoni tat-trasferiment ta’ għarfien viżwali għat-test għal mudelli lingwistiċi unimodali jew multimodali. Il-metodu huwa bbażat fuq żewġ stadji, 1) inkjesta ġdida għall-għarfien tal-kuluri tal-memorja, jiġifieri kuluri tipiċi ta’ oġġetti magħrufa sew, u 2) filtrazzjoni tad-dejta tat-taħriġ mudell biex jiġu separati b’mod ċar il-kontribuzzjonijiet tal-għarfien. Barra minn hekk, a ħna nintroduċu arkitettura mudell li tinvolvi pass viżwali ta’ immaġinazzjoni u tevalwawha bil-metodu propost tagħna. Aħna nsibu li l-metodu tagħna jista’ jintuża b’suċċess biex jitkejlu l-kapaċitajiet tat-trasferiment tal-għarfien viżiv fil-mudelli u li l-arkitettura tal-mudell il-ġdid tagħna turi riżultati promettenti għall-ingranaġġ tal-għarfien multimodali f’ambjent unimodali.', 'mn': 'Томоохон хэл загварууд нь мэдлэгийг алдахгүй гэдгийг харуулж, худлаа эсвэл буруу гэсэн үг гаргах боломжтой асуудлын асуудалд зовлон байдаг. Үүний тухай санал өгсөн шийдэл бол хэлбэрээр авсан мэдлэгийг нэмэгдүүлэх нэмэлт өгөгдлийн арга замыг хангах юм. Бид том хэл загварын мэдлэгийг нэмэгдүүлэхийн тулд визуал өгөгдлийн хэрэглээ судалгаагаар нэг эсвэл олон загварын хэл загварын текст руу шилжүүлэх арга зааж өгдөг. Энэ арга нь хоёр алхам дээр суурилсан, 1) санамжийн өнгүүдийн мэдлэг, яг энгийн мэддэг объектүүдийн өнгүүдийн тухай судалгаа, 2) мэдлэгийг тодорхой ялгах боломжтой загварын дасгал өгөгдлийн шинжилгээ. Мөн бид харааны төсөөлөлтийн алхам болох загварын архитектурыг танилцуулж, үүнийг бидний санал дэвшүүлсэн архитектураар үнэлэх болно. Бид өөрсдийн арга загвар загварын шилжүүлэх чадварыг амжилттай хэмжээнд ашиглаж болно. Бидний шинэ загварын архитектур нь олон загварын мэдлэгийг нэг загварын хэмжээнд ашиглаж болно.', 'ro': 'Modelele lingvistice mari sunt cunoscute pentru a suferi de problema halucinațiilor prin faptul că sunt predispuse la afirmații false sau inconsecvente, indicând o lipsă de cunoștințe. O soluție propusă în acest sens este furnizarea modelului cu modalități suplimentare de date care completează cunoștințele obținute prin text. Investigăm utilizarea datelor vizuale pentru a completa cunoștințele modelelor lingvistice mari, propunând o metodă de evaluare a transferului vizual de cunoștințe către text pentru modele lingvistice unimodale sau multimodale. Metoda se bazează pe doi pași, 1) o nouă interogare de sarcini pentru cunoașterea culorilor memoriei, adică culorile tipice ale obiectelor bine cunoscute, și 2) filtrarea datelor de formare a modelului pentru a separa clar contribuțiile de cunoaștere. În plus, introducem o arhitectură model care implică un pas de imaginație vizuală și o evaluăm cu metoda propusă. Considerăm că metoda noastră poate fi folosită cu succes pentru a măsura capacitățile de transfer vizual de cunoștințe în modele și că arhitectura modelului nostru nou arată rezultate promițătoare pentru valorificarea cunoștințelor multimodale într-un cadru unimodal.', 'so': "Tilmaamaha luuqadda waaweyn waxaa loo yaqaan in ay dhibaatada quduuska ah ka xanuunsadaan, sababtoo ah waxaa loo caddeeyaa in ay soo bixiyaan hadallo been ah ama aan la mid ahayn, taasoo ku qoran baahida aqoonta. A proposed solution to this is to provide the model with additional data modalities that complements the knowledge obtained through text.  Waxaynu baaraynaa isticmaalka macluumaadka aragga si aan u dhamaystiro aqoonta muuqashada luuqada waaweyn, taas oo aan u soo jeedinno qaab ku qiimeynaya beddelinta aqoonta aragnimada ee qoraalka u beddelista tusaalaha luuqada uni- ama muuqashada kala duduwan. Midabka waxaa ku saleysan labo tallaabo, 1) shaqo la xiriira aqoonta midibyada xusuusta, tusaale ahaan midabyada qaababka ah oo la yaqaan alaabta xusuusta, iyo 2) baaritaanka macluumaadka waxbarashada modellka si caddaan loogu caddeeyo micnihiisa aqoonta kala duduwan. Sidoo kale waxaynu soo bandhignaa dhismo tusaale ah oo ku saabsan tallaabo arag la'aan ah, waxaana ku qiimeynaynaa qaababkayaga la soo jeeday. Waxaynu ogaanaynaa in qaababkayaga loo isticmaali karo si uu u qiyaaso awoodaha aqoonta la wareejiyo tusaalayaasha, iyo in dhismaha qaababkayaga sawirku uu muujiyo resultooyin ballan u leh in loo soo diro aqoonta kala duduwan si loo beddelo.", 'sv': 'Stora språkmodeller är kända för att drabbas av hallucinationsproblemet eftersom de är benägna att utmatningspåståenden som är falska eller inkonsekventa, vilket indikerar brist på kunskap. En föreslagen lösning på detta är att ge modellen ytterligare dataformer som kompletterar den kunskap som erhållits genom text. Vi undersöker användningen av visuella data för att komplettera kunskapen om stora språkmodeller genom att föreslå en metod för att utvärdera visuell kunskapsöverföring till text för uni- eller multimodala språkmodeller. Metoden bygger på två steg, 1) en ny uppgiftsfråga för kunskap om minnesfärger, dvs typiska färger på välkända objekt, och 2) filtrering av modellträningsdata för att tydligt skilja kunskapsbidrag. Dessutom introducerar vi en modellarkitektur som innebär ett visuellt fantasisteg och utvärderar den med vår föreslagna metod. Vi finner att vår metod framgångsrikt kan användas för att mäta visuell kunskapsöverföring i modeller och att vår nya modellarkitektur visar lovande resultat för att utnyttja multimodal kunskap i en unimodal miljö.', 'ta': 'Large language models are known to suffer from the hallucination problem in that they are prone to output statements that are false or inconsistent, indicating a lack of knowledge.  ஒரு பரிந்துரையிடப்பட்ட தீர்வு உரையால் கிடைக்கப்பட்ட அறிவை முழுமையாக நிறைவேற்றும் கூடுதல் தரவு வகைகளுடன் ம நாம் பெரிய மொழி மாதிரிகளின் அறிவை நிறைவேற்றுவதற்கு பார்வையான தகவல் பயன்படுத்துவதை தேர்வு செய்கிறோம். பார்வை அறிவு மாற்றுதலை யூனி இந்த முறைமை இரண்டு படிகளில் அடிப்படையாக இருக்கிறது, 1) நினைவு வண்ணங்களின் அறிவின் புதிய செயல் கேட்கிறது, அதாவது, நன்றி அறியப்பட்ட பொருட்களின் வழக்கமான வண்ண கூடுதலாக, நாம் ஒரு மாதிரி உருவாக்கத்தை அறிவிக்கிறோம். அது ஒரு பார்வையான கற்பனை படியை சேர்க்கிறது மற்றும் நம் பரிந்துரைய ம நமது முறைமை வெற்றிகரமாக பயன்படுத்தப்படும் பார்வை அறிவு மாற்றல் மாதிரிகளில் அளக்க முடியும் மற்றும் எங்கள் புதிய மாதிரி உருவாக்கம் ஒரு ஒற்றைமைய', 'no': 'Stor språk-modeller er kjent til å kjøre frå hallusinasjonssproblemet i at dei er nøyaktig til å utføra uttrykk som er falske eller inkonsistent, som viser ein mangling av kunnskap. Eit foreslått løysing for dette er å gje modellen med fleire datamodusar som fullfør kunnskapen som er kjent gjennom tekst. Vi undersøker bruken av visuelle data for å komplementa kunnskap av stor språk- modeller ved å foreslå ein metode for å evaluera visuelle kunnskap- overføring til tekst for uni- eller multimodal språk- modeller. Metoden er basert på to steg, 1) eit nytt oppgåve som spør om kunnskap av minnefargar, t.d. typiske fargar av godt kjende objekt, og 2) filtrering av modelløvingsdata for å tydelig skildra kunnskap. I tillegg introduserer vi eit modell-arkitektur som involverer eit visuell fantaseringssteg og evaluerer det med vår foreslått metode. Vi finn at metoden vårt kan vellykkeleg brukast til å måle kapasiteten for visual kunnskap overføring i modeller og at vårt romanmodell-arkitektur viser promiserende resultat for å levera multimodal kunnskap i ein unimodal innstilling.', 'sr': 'Veliki jezički modeli su poznati da pati od halucinacijskog problem a u tome što su spremni izveštavati izjave koje su lažne ili nepristojne, ukazujući na nedostatak znanja. Predloženo rešenje za to je pružanje modela dodatnim modalitetima podataka koji dodaje znanje koje su dobile tekstom. Istražujemo korištenje vizuelnih podataka za dodatak znanja velikih jezičkih modela predlažeći metodu za procjenu vizuelnog transfer a znanja na tekst za jednomodalne ili multimodalne jezičke modele. Metod se temelji na dva koraka, 1) novi zadatak koji se pita za znanje boja pamćenja, tj. tipične boje poznatih predmeta, i 2) filtriranje modelnih podataka za jasno odvojenje doprinosa znanja. Osim toga, predstavljamo model arhitekture koji uključuje korak vizuelne mašte i procenjuje ga našim predloženim metodom. Naša metoda se uspješno može koristiti za mjerenje sposobnosti prijenosa vizuelnih znanja u modelima i da naša nova modela arhitektura pokazuje obećavajuće rezultate za utjecanje multimodalnih znanja u jednomodalnom stanju.', 'si': 'ලොකු භාෂා මොඩල් දන්නවා හැලුසිනස් ප්\u200dරශ්නයෙන් සිද්ධ වෙන්න ප්\u200dරශ්නයක් තියෙනවා ඒ වගේම ඔවුන් බොරු නැති නැති නැති  මේකට ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ මොඩේල් එක්ක තවත් දත්ත ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් තියෙන් අපි දර්ශන දත්ත භාවිතාව පරීක්ෂා කරනවා ලොකු භාෂා මොඩේල්ස් ගැන දන්නවක් සම්පූර්ණ කරලා ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරන්න ප්\u200d මාර්ගය දෙකක් පැත්තෙන් අධාරිත වෙනවා, 1) මතක වර්ණ වලට ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් සාමාන්\u200dය වර්ණ වර්ණ වර්ණ වර්ණ වර්ණ වර තවත්, අපි ප්\u200dරමාණයක් සිද්ධා කරනවා ඒ වගේම ප්\u200dරමාණයක් සම්බන්ධ කරනවා අපේ ප්\u200dරමාණ විධානය සමඟ ඒක අගය කරන්න අපිට හොයාගන්න පුළුවන් අපේ විධානය සමහරවිට ප්\u200dරයෝජනය වෙන්න පුළුවන් විදියට ප්\u200dරයෝජනය වෙන්න පුළුවන් විදියට මොඩේල් වලින්', 'ur': 'بڑی زبان مدلکوں کو معلوم ہوتا ہے کہ ان کی تعلیم کے مشکل سے دردناک ہو جاتی ہیں اس میں کہ وہ جھوٹی یا غلط باتیں نکالتے ہیں اور علم کی کمزوری کی نشان دیتے ہیں. اس کے لئے ایک پیشنهاد حل یہ ہے کہ مدل کو اضافہ ڈیٹا موڈلیٹ کے ساتھ دینا ہے جو متن کے ذریعے ملے ہوئے علم کو اضافہ کرتی ہے. ہم دیکھنے والی ڈیٹا کے استعمال کی تحقیق کرتے ہیں کہ بڑی زبان مدلکوں کے علم کو اضافہ کرنے کے لئے ایک طریقہ پیش کریں کہ visual knowledge transfer to text for uni- or multimodal language models. یہ طریقہ دو قدم پر بنیاد ہے، 1) ایک نئی تابع ہے جو مہمانی رنگ کے علم کے لئے سوال کرتا ہے، یعنی معلوم طریقے سے معلوم ہونے والی چیزوں کے رنگ، اور 2) موڈل کی تطابق ڈیٹا کا فیلتر کرتا ہے، واضح طور پر علم کے حصے کے لئے۔ اور اضافہ، ہم ایک مدل معماری معماری پیش کریں گے جس کے ذریعہ ایک تصور کی قدم شامل ہوتی ہے اور اسے ہمارے مقرر کردہ طریقے سے evaluate کرتے ہیں. ہمیں معلوم ہے کہ ہمارا طریقہ موفق طور پر قابل طور پر استعمال کیا جاتا ہے کہ نمادل میں visual knowledge transfer capabilities اندازے کے لئے اور یہ کہ ہماری رمانی نمادل معماری معماری ایک متعدد علم کے مطابق وعدہ کے نتیجے دکھاتی ہیں۔', 'uz': "Bu katta til modellari haqiqatdan foydalanishi mumkin, chunki ular haqiqat maʼlumot emas deb tushunishini anglatadi. Name Biz juda katta tillar modellarini qidirish uchun ko'rinish maʼlumotlarning foydalanishini aniqlamiz va uni- yoki multimodal tilning modellariga qiymatlashni o'ylab ko'rinish muvaffaqiyatlarini o'ylash usulini o'ylaymiz. Name Ko'pchilik, biz o'ylab tasavvur qiladigan model arxituvchisini ko'rinamiz va bu tasavvur qiladigan usuli bilan qiymatmiz. Biz o'ylaymiz, bizning usuli muvaffaqiyatli foydalanishimiz mumkin modellarda ko'rinish imkoniyatlarini o'zgartirish mumkin va novel modeli arxituvchisi unimodal moslamada multimodal bilimni qo'shish uchun yetarli natijalarini koʻrsatish mumkin.", 'vi': 'Những mô hình ngôn ngữ lớn được biết là phải chịu đựng chứng ảo giác bởi vì chúng có xu hướng xuất phát những biểu đồ sai hoặc mâu thuẫn, chỉ ra thiếu kiến thức. Một giải pháp cho việc này là cung cấp cho mô hình thêm phương thức dữ liệu bổ sung cho kiến thức thu được qua văn bản. Chúng tôi điều tra việc sử dụng dữ liệu hình ảnh để bổ sung kiến thức về các mô hình ngôn ngữ lớn bằng cách đề xuất một phương pháp đánh giá khả năng truyền tri thức trực tiếp đến các mô hình ngôn ngữ uni- hay đa phương. Phương pháp dựa trên hai bước, 1) một nhiệm vụ mới tìm kiếm kiến thức về màu trí nhớ, tức là màu tiêu biểu của vật nổi tiếng, và 2) bộ lọc dữ liệu đào tạo mô hình để chia rõ ràng các tài khoản kiến thức. Thêm nữa, chúng tôi giới thiệu một kiến trúc mẫu có liên quan tới một bước tưởng tượng thị giác và đánh giá nó bằng phương pháp đã đề nghị. Chúng tôi thấy phương pháp có thể dùng thành công để đo khả năng giao tiếp kiến thức trực tiếp trong các mô hình, và kiến trúc mẫu mới của chúng tôi cho thấy kết quả hứa hẹn để vận dụng kiến thức đa phương trong một môi trường trường không đổi.', 'bg': 'Големите езикови модели са известни, че страдат от проблема с халюцинациите, тъй като те са склонни към изходни твърдения, които са фалшиви или непоследователни, което показва липса на знания. Предложено решение за това е да се осигурят на модела допълнителни условия за данни, които допълват знанията, получени чрез текст. Проучваме използването на визуални данни за допълване на познанията по големи езикови модели, като предлагаме метод за оценка на трансфера на визуални знания към текст за уни- или мултимодални езикови модели. Методът се основава на две стъпки, 1) нова задача за търсене на знания за цветовете на паметта, т.е. типичните цветове на добре познати обекти, и 2) филтриране на данните за обучение на модела за ясно разделяне на приноса на знанията. Освен това въвеждаме моделна архитектура, която включва стъпка на визуалното въображение и я оценяваме с предлагания от нас метод. Откриваме, че нашият метод може успешно да бъде използван за измерване на способностите за визуален трансфер на знания в модели и че новата ни архитектура на моделите показва обещаващи резултати за използване на мултимодални знания в унимодална обстановка.', 'da': 'Store sprogmodeller er kendt for at lide af hallucinationsproblemet, da de er tilbøjelige til output udsagn, der er falske eller inkonsekvente, hvilket indikerer mangel på viden. En foreslået løsning på dette er at give modellen yderligere datamodaliteter, der supplerer den viden, der opnås gennem tekst. Vi undersøger brugen af visuelle data til at supplere kendskabet til store sprogmodeller ved at foreslå en metode til vurdering af visuel vidensoverførsel til tekst til uni- eller multimodale sprogmodeller. Metoden er baseret på to trin, 1) en ny opgave forespørgsel om kendskab til hukommelsesfarver, dvs. typiske farver på kendte objekter, og 2) filtrering af model træningsdata for klart at adskille vidensbidrag. Derudover introducerer vi en model arkitektur, der indebærer en visuel fantasi trin og evaluerer den med vores foreslåede metode. Vi oplever, at vores metode med succes kan bruges til at måle visuelle vidensoverførselsevner i modeller, og at vores nye modelarkitektur viser lovende resultater for at udnytte multimodal viden i en unimodal ramme.', 'nl': 'Van grote taalmodellen is bekend dat ze last hebben van het hallucinatieprobleem omdat ze gevoelig zijn voor uitvoerverklaringen die onjuist of inconsistent zijn, wat wijst op een gebrek aan kennis. Een voorgestelde oplossing hiervoor is om het model te voorzien van aanvullende gegevensmodaliteiten die de door tekst verkregen kennis aanvullen. We onderzoeken het gebruik van visuele data om de kennis van grote taalmodellen aan te vullen door een methode voor het evalueren van visuele kennisoverdracht naar tekst voor uni- of multimodale taalmodellen. De methode is gebaseerd op twee stappen, 1) een nieuwe taak die vraagt naar kennis van geheugenkleuren, d.w.z. typische kleuren van bekende objecten, en 2) filteren van modeltrainingsgegevens om kennisbijdragen duidelijk te scheiden. Daarnaast introduceren we een modelarchitectuur die een visuele verbeeldingsstap omvat en evalueren deze met onze voorgestelde methode. We merken dat onze methode succesvol kan worden gebruikt om visuele kennisoverdracht capaciteiten in modellen te meten en dat onze nieuwe modelarchitectuur veelbelovende resultaten toont voor het benutten van multimodale kennis in een unimodale omgeving.', 'id': 'Model bahasa besar dikenal menderita dari masalah halusinasi karena mereka cenderung untuk pernyataan output yang palsu atau tidak konsisten, menunjukkan kekurangan pengetahuan. Sebuah solusi yang diusulkan untuk hal ini adalah untuk menyediakan model dengan modalitas data tambahan yang menyempurnakan pengetahuan yang diperoleh melalui teks. Kami menyelidiki penggunaan data visual untuk menambahkan pengetahuan tentang model bahasa besar dengan mengusulkan metode untuk mengevaluasi transfer pengetahuan visual ke teks untuk model bahasa uni- atau multimodal. Metode ini berdasarkan dua langkah, 1) tugas baru yang menanyai pengetahuan tentang warna memori, i.e. warna tipis dari objek yang dikenal, dan 2) penapisan data pelatihan model untuk dengan jelas memisahkan kontribusi pengetahuan. Selain itu, kami memperkenalkan sebuah arsitektur model yang melibatkan langkah imajinasi visual dan mengevaluasinya dengan metode kami yang diusulkan. Kami menemukan bahwa metode kami dapat berhasil digunakan untuk mengukur kemampuan pemindahan pengetahuan visual dalam model dan bahwa arsitektur model baru kami menunjukkan hasil yang berjanji untuk menggunakan pengetahuan multimodal dalam setting unimodal.', 'hr': 'Veliki jezički modeli su poznati da pati od halucinacijskog problem a jer su spremni izvući izjave koje su lažne ili nepristojne, ukazujući na nedostatak znanja. Predloženo rješenje za to je pružanje modela dodatnim podacima koji dopunjava znanja dobijene tekstom. Istražujemo korištenje vizuelnih podataka kako bi dodali znanje velikih jezičkih modela predložili metodu za procjenu prijenosa vizuelnih znanja tekstu za jednomodalne ili multimodalne jezičke modele. Metod se temelji na dva koraka, 1) novi zadatak koji se pita za znanje boja sjećanja, tj. tipične boje poznatih predmeta, i 2) filtriranje podataka o obuci model a kako bi jasno odvojili doprinos znanja. Osim toga, predstavljamo modelu arhitekture koja uključuje korak vizuelne mašte i procjenjuje ga našim predloženim metodom. Naša metoda se uspješno može koristiti za mjerenje sposobnosti prijenosa vizuelnih znanja u modelima i da naša nova modela arhitektura pokazuje obećavajuće rezultate za utjecanje multimodalnih znanja u jednomodalnom stanju.', 'de': 'Große Sprachmodelle leiden bekanntlich unter dem Halluzinationsproblem, da sie anfällig für falsche oder inkonsistente Aussagen sind, was auf fehlende Kenntnisse hindeutet. Eine vorgeschlagene Lösung hierfür besteht darin, dem Modell zusätzliche Datenmodalitäten zur Verfügung zu stellen, die das durch Text gewonnene Wissen ergänzen. Wir untersuchen die Verwendung visueller Daten zur Ergänzung des Wissens großer Sprachmodelle, indem wir eine Methode vorschlagen, um visuellen Wissenstransfer in Text für uni- oder multimodale Sprachmodelle zu bewerten. Die Methode basiert auf zwei Schritten, 1) einer neuartigen Taskabfrage nach Kenntnissen von Speicherfarben, d.h. typischen Farben bekannter Objekte, und 2) Filtern von Modelltrainingsdaten zur eindeutigen Trennung von Wissensbeiträgen. Zusätzlich führen wir eine Modellarchitektur ein, die einen visuellen Vorstellungsschritt beinhaltet und bewerten diese mit unserer vorgeschlagenen Methode. Wir stellen fest, dass unsere Methode erfolgreich eingesetzt werden kann, um visuelle Wissenstransferfähigkeiten in Modellen zu messen und dass unsere neuartige Modellarchitektur vielversprechende Ergebnisse zeigt, um multimodales Wissen in einem unimodalen Umfeld zu nutzen.', 'ko': '모두가 알다시피 대형 언어 모델에는 환각 문제가 존재한다. 왜냐하면 그들은 잘못되거나 일치하지 않는 문장을 출력하기 쉬워 지식이 부족하다는 것을 나타낸다.이에 대한 해결 방안은 텍스트를 통해 얻은 지식을 보충하기 위해 모델에 추가 데이터 모델을 제공하는 것이다.우리는 시각 데이터의 사용을 연구하여 대형 언어 모델의 지식을 보충하고 단모드나 다중모드 언어 모델의 시각 지식을 텍스트로 옮기는 방법을 평가했다.이 방법은 두 가지 절차를 바탕으로 1) 새로운 임무로 기억 색깔에 대한 지식, 즉 이미 알고 있는 대상의 전형적인 색깔, 그리고 2) 필터 모델 훈련 데이터를 조회하여 지식 공헌을 명확하게 구분한다.그 밖에 우리는 시각적 상상 절차와 관련된 모델 체계 구조를 소개하고 우리가 제시한 방법으로 이를 평가했다.우리는 우리의 방법이 모델의 시각적 지식 이동 능력을 측정하는 데 성공할 수 있고 우리의 새로운 모델 구조는 단봉 환경에서 다봉 지식을 이용하는 데 희망적인 결과를 나타냈다.', 'sw': 'Mradi mkubwa wa lugha unajulikana wanakabiliwa na matatizo yanayotokana na matatizo ya kutafuta utambulisho kwa sababu wanaonesha ukosefu wa ufahamu. suluhisho lililopendekezwa kwa hili ni kutoa mfano kwa njia nyingine za data zinazochanganya maarifa yaliyopatikana kupitia ujumbe wa maandishi. Tunafanya uchunguzi wa matumizi ya taarifa za kuona ili kuumiza ufahamu wa mifano makubwa ya lugha kwa kupendekeza njia ya kutathmini uhamishaji wa maarifa ya kuona kwa ajili ya mifano ya lugha ya uni- au nyingine. Mfumo huu unategemea hatua mbili, 1) jukumu la riwaya linalouliza kuelewa rangi za kumbukumbu, yaani rangi za kawaida za vitu vinavyofahamika vizuri, na 2) kuchuja taarifa za mafunzo ya model i kwa ajili ya michango ya ufahamu tofauti. Zaidi ya hayo, tunaonyesha ujenzi wa muundo ambao unahusisha hatua ya kufikiria na kutathmini kwa njia yetu inayopendekezwa. Tunapata kwamba mbinu yetu inaweza kutumika kwa mafanikio kupima uwezo wa usafiri wa ufahamu wa kuona katika mifano na kwamba ujenzi wetu wa muundo wa riwaya unaonyesha matokeo yanayoahidi kutumia maarifa ya watu wengi katika mazingira ya upekee.', 'tr': 'Uly dil nusgalary halucinasiýanyň problemasyndan çykyp barýandyklarynda bilim ýok bolmagyny görkezýär. Bunun üçin bir çözüm nusgasyna metin bilen alan bilgileri dolduran eklendirmek üçin modüli saýlamakdır. Biz uly dil nusgalarynyň bilgilerini tamamlamak üçin görsel maglumatlaryň ullanyşyny barlaýarys. Bir nusga görsel bilgi nusgasyny bir ýagdaý täze etmek üçin bir täze täze maslahat berýäris. Metin iki adım diýipdir, 1) yada renklerini sorap täze bir täze, ýaly tanyş zadyň düzgün renkleri, we 2) bilim gabdalyklaryny tapawutlamak üçin örän nusgasy bar. Munuň üstüne görsel güýjük adımy dahil eden bir nusga arhitekturuny tanyşdyrýarys we muny teklip eden yöntemimiz bilen çykýarys. Biziň yönümimiz nusgalarda görsel bilim aktarma ukyplaryny ölçürmek üçin ulanylyp bilýäris we bu nusgamyz nusgasymyz bir nusgasynda multimodal bilim etmäge söz berýän netijesini görkez.', 'sq': 'Modelet e mëdha gjuhësh janë të njohura të vuajnë nga problemi i halucinacioneve në atë që ata janë të aftë për të dalë deklarata që janë të rreme apo jo konsistente, duke treguar një mungesë njohurie. Një zgjidhje e propozuar për këtë është të sigurojë modelin me modalitete shtesë të të dhënave që komplementojnë njohuritë e fituara nëpërmjet tekstit. Ne hetojmë përdorimin e të dhënave vizuale për të komplementuar njohurinë e modeleve të mëdha gjuhësh duke propozuar një metodë për vlerësimin e transferimit të njohurive vizuale në tekst për modele gjuhësh unimodale apo multimodale. The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions.  Përveç kësaj, ne paraqesim një arkitekturë modeli që përfshin një hap imagjinatë vizuale dhe e vlerësojmë me metodën tonë të propozuar. Ne zbulojmë se metoda jonë mund të përdoret me sukses për të matur aftësitë e transferimit vizual të njohurive në modele dhe se arkitektura jonë e re e modelit tregon rezultate premtuese për përdorimin e njohurive multimodale në një ambient unimodal.', 'hy': "Մեծ լեզվի մոդելները հայտնի է, որ տառապում են հալյուցինացիաների խնդիրից, որովհետև նրանք հակված են սխալ կամ անհամապատասխանատու արտադրման հայտարարություններին, որոնք ցույց են տալիս գիտելիքի բացակայությունը: Սրա համար առաջարկված լուծումն այն է, որ մոդելը տալիս է ավելացված տվյալների մեթոդներ, որոնք համալրացնում են տեքստի միջոցով ստացված գիտելիքները: We investigate the use of visual data to complement the knowledge of large language models by proposing a method for evaluating visual knowledge transfer to text for uni- or multimodal language models.  Մեթոդը հիմնված է երկու քայլերի վրա: 1) հիշողության գույների գիտելիքի նոր խնդիր, այսինքն' լավ հայտնի առարկաների տիպիկ գույներ, և 2) մոդելների ուսումնասիրության տվյալների ֆիլտրում, որպեսզի պարզ առանձին գիտելիքների ներդրումը: Ավելին, մենք ներկայացնում ենք մի ճարտարապետական մոդել, որը ներառում է տեսողական երևակայության քայլ և գնահատում այն մեր առաջարկված մեթոդով: Մենք հայտնաբերում ենք, որ մեր մեթոդը հաջողությամբ կարող է օգտագործվել տեսողական գիտելիքների փոխանցման հնարավորությունների չափման համար մոդելներում և որ մեր նոր մոդելի ճարտարապետությունը ցույց է տալիս խոստացնող արդյունքներ, որոնք կարող են օգտագործել բազմամոդալ գիտ", 'fa': 'مدل\u200cهای بزرگ زبان شناخته می\u200cشوند که از مشکل هالوسیژن رنج می\u200cبرند، در حالی که آنها به گزارش\u200cهای دروغ یا غیرقابل توجه می\u200cکنند و نشان می\u200cدهند که کمبود دانش است. یک راه حل پیشنهاد برای این است که مدل را با روش داده اضافه\u200cای که از طریق متن دریافت شده دانش را اضافه می\u200cکند. ما استفاده از داده\u200cهای دیده\u200cای را تحقیق می\u200cکنیم تا علم مدل\u200cهای زبان بزرگ را با پیشنهاد یک روش برای ارزیابی انتقال دانش\u200cهای دیده\u200cای به متن برای مدل\u200cهای زبان\u200cهای متحد یا متحد\u200cمتحد تحقیق کنیم. این روش بر روی دو مرحله، ۱) یک وظیفه جدید که در مورد دانش رنگ حافظه سوال می\u200cکند، یعنی رنگ\u200cهای معمولی از موجودات شناخته شده، و ۲) فیلتر داده\u200cهای آموزش مدل برای مشخص رضایت علمی جدا می\u200cشود. به اضافه، ما یک معماری مدل را معرفی می کنیم که درگیر یک قدم تصور دیده و با روش پیشنهاد ما ارزش می دهد. ما پیدا می\u200cکنیم که روش ما می\u200cتواند به موفقیت برای اندازه\u200cگیری توانایی انتقال علم دیده در مدل\u200cها استفاده شود و این معماری مدل رمانی ما نتیجه\u200cهای قول\u200cدهنده برای تأثیر دانش\u200cهای متوسطی در یک تنظیم متوسطی نشان می\u200cدهد.', 'af': "Groot taal modelles is bekend om te lyk van die hallusinasie probleem in dat hulle voordeel is na uitvoer uittekeninge wat valse of onvoldoende is, wat 'n ontbreek van kennis aanwys. 'n voorgestelde oplossing vir hierdie is om die model te verskaf met addisionele data modaliteite wat die kennis wat deur teks ontvang is, complementeer. Ons ondersoek die gebruik van visuele data om die kennis van groot taal modelles te komplementeer deur 'n metode te voorstel om visuele kennis oordrag na teks te evalueer vir uni- of multimodale taal modelles. Die metode is gebaseer op twee stappe, 1) â\x80\x99n nuwe taak wat vra vir kennis van geheue kleure, bv. tipiese kleure van goed bekende voorwerpe, en 2) filtering van model onderwerp data om duidelik kennis bydraai te skei. In addition, we introduce a model architecture that involves a visual imagination step and evaluate it with our proposed method. Ons vind dat ons metode suksesvol gebruik kan word om visuele kennis oordrag kapasiteite in modele te maak en dat ons novele model-arkitektuur beloftende resultate vertoon vir die verwysing van multimodale kennis in 'n unimodaal opstelling.", 'az': 'Büyük dil modelləri halucinasiya problemindən əziyyət çəkməyə məcbur edilir ki, onlar haqsız və müəyyən olunmuş ifadələr çıxarılırlar və elm yoxdur. Bunun üçün təbliğ edilmiş çözüm modeli məktub olaraq alınan bilgiləri tamamlayan ekstra məlumat modülləri ilə təmin etməkdir. Biz böyük dil modellerinin bilgisini tamamlamaq üçün görsel məlumatların istifadəsini təhsil edirik, uni - ya da multimodal dil modellerinin məlumatlarına görsel bilgi transferisini təhsil edirik. Bu metod iki adım, 1) yaddaşların rənglərini bildirmək üçün yeni bir i şdir, məsələn tanınmış objektlərin tipik rəngləri, və 2) bilgi məlumatlarını ayırmaq üçün model i təhsil məlumatlarını filtrləyir. Daha da, biz bir modeli arhitektura tanıyırıq ki, göylü hayal gücünün adımı içərisində olsun və onu bizim təbliğ etdiyimiz metodlar ilə değerləşdiririk. Bizim metodumuzun modellərdə görsel elm transfer qabiliyyətini ölçürmək üçün müvəffəqiyyətimizi və yeni modellərimizin çoxlu modal bilgiləri təmizləmək üçün və ’ d verən sonuçlarını göstəririk.', 'bn': 'বিশাল ভাষার মডেলটিকে পবিত্র সমস্যা থেকে কষ্ট দেয়া হয়েছে যেহেতু তারা মিথ্যা বা অসন্তষ্ট বিবৃতি প্রমাণ করেছে, যা জ্ঞানের অভাব এই সমাধানের জন্য প্রস্তাবিত একটি সমাধান হচ্ছে যে মডেলের সাথে অতিরিক্ত তথ্য মোডামোডেল দিতে পারে যা টেক্সটের আমরা দৃশ্যমান তথ্য ব্যবহার করে বিশাল ভাষার মডেলের জ্ঞান সম্পূর্ণ করার জন্য একটি পদ্ধতি প্রস্তাব করে ইউনি- অথবা বহুটিমোডাল ভাষার মডেলের জন্য প The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions.  এছাড়াও, আমরা একটি মডেল কাঠামো পরিচয় করিয়ে দেখি যা দৃশ্যমান কল্পনার ধাপের মধ্যে রয়েছে এবং আমাদের প্রস্তাবিত পদ্ধতির মাধ্যমে এটি মূ আমরা খুঁজে পাচ্ছি যে আমাদের পদ্ধতি সফলভাবে ব্যবহার করতে পারে মডেলে দৃশ্যমান জ্ঞান পরিবর্তনের ক্ষমতা পরিমাপ করতে এবং আমাদের উপন্যাস মডেল কাঠামো প্রতিশ্র', 'am': 'ታላቁ ቋንቋዎች ምሳሌዎች ከቅድስናዊ መከራ መቀበል የሚታወቁ ናቸው፤ የእውቀት ጉዳይ የሐሰት ወይም የማይቃወም ንግግር እንዲያወጡ ነው፡፡ ለዚህ ጉዳይ ማስፈለግ ሞዴላውን በጽሑፍ የተገኘውን እውቀት የሚጨምር የዳታ ድርጅቶች ማድረግ ነው፡፡ የራእይ ዳታዎችን ለመጠቀም የታላቁ ቋንቋዎች ሞዴላዎችን ለማድረግ እናምርመራለን፡፡ ዓይነት በሁለት ደረጃዎች ላይ ነው፣ 1) የአሁኑን አድራሻ ለማስታወስ ቀለም የሚጠይቅ ነው፤ ምሳሌ የተታወቀ አካላት፣ እና 2) የሞዴል ትምህርት ዳራዎችን ለልዩ እውቀት አካሄድ እንዲያስተካክሉ የመስመር ቀለም ነው፡፡ በተጨማሪም፣ የራእይ አሳብ አካሄድ የሚያስፈልገውን ምሳሌ አካውንት እናሳውቀዋለን በተዘጋጀውም ልማድ እናስተውለውዋለን፡፡ የዓይነት እውቀትን ለመለወጥ እና የዘላለም ዓይነታችን መሠረት የሞዴል መሠረት ፍሬታዎችን በተስፋ የሚያሳየው የብልሃት እውቀትን በመስጠት የሚቻል እንደሆነ እናገኘዋለን፡፡', 'bs': 'Veliki jezički modeli su poznati da pate od halucinacijskog problem a u tome što su spremni izložiti izjave koje su lažne ili nepristojne, ukazujući na nedostatak znanja. Predloženo rješenje za to je pružanje modela dodatnim podacima koji dopunjava znanje koje su dobile tekstom. Istražujemo korištenje vizuelnih podataka za dodatak znanja velikih jezičkih modela predlažeći metodu za procjenu prijenosa vizuelnih znanja tekstu za jednomodalne ili multimodalne jezičke modele. Metod se temelji na dva koraka, 1) novi zadatak koji se pita za znanje boja sjećanja, tj. tipične boje poznatih predmeta, i 2) filtriranje modelnih podataka za jasno odvojenje doprinosa znanja. Osim toga, predstavljamo model arhitekture koji uključuje korak vizuelne mašte i procjenjuje ga našim predloženim metodom. Naša metoda se uspješno može koristiti za mjerenje sposobnosti prijenosa vizuelnih znanja u modelima i da naša nova modela arhitektura pokazuje obećavajuće rezultate za utjecanje multimodalnih znanja u jednomodalnom stanju.', 'ca': "Es coneix que els grans models lingüístics pateixen el problem a de la alucinació en que són propensos a produir declaracions falses o inconsistents, indicant una falta de coneixement. Una solució proposada a això és proporcionar al model modalitats adicionals de dades que complementen el coneixement obtenit a través del text. Investiguem l'ús de dades visuals per complementar el coneixement de grans models de llenguatge proposant un mètode per avaluar la transfer ència de coneixements visuals al text per a models de llenguatge unimodals o multimodals. El mètode es basa en dues etapes: 1) una nova tasca que busca coneixement de colors de la memòria, és a dir, colors típics d'objectes coneguts, i 2) filtrar dades de formació model per separar clarament les contribucions del coneixement. A més, introduïm un model d'arquitectura que implica un pas de imaginació visual i l'evaluem amb el nostre mètode proposat. Trobem que el nostre mètode pot ser utilitzat amb èxit per mesurar les capacitats de transfer ència visual de coneixements en models i que la nostra nova arquitectura model mostra resultats prometedors per aprofitar el coneixement multimodal en un entorn unimodal.", 'fi': 'Suurten kielimallien tiedetään kärsivän hallusinaatioongelmasta, koska ne ovat alttiita väärille tai epäjohdonmukaisille lausuntoille, jotka viittaavat tiedon puutteeseen. Ehdotettu ratkaisu tähän on tarjota mallille lisätietoja, jotka täydentävät tekstillä saatua tietoa. Tutkimme visuaalisen datan käyttöä suurten kielimallien tietämyksen täydentämiseksi ehdottamalla menetelmä visuaalisen tiedon siirtämisen arvioimiseksi tekstiin uni- tai multimodaalisissa kielimalleissa. Menetelmä perustuu kahteen vaiheeseen, 1) uuteen tehtävään, jossa haetaan tietoa muistiväreistä eli tunnettujen kohteiden tyypillisistä väreistä, ja 2) mallinnuskoulutustietojen suodattamiseen, jotta tietoosuudet erotetaan selkeästi toisistaan. Lisäksi esittelemme malliarkkitehtuurin, johon liittyy visuaalinen mielikuvitus ja arvioimme sitä ehdotetulla menetelmällä. Havaitsemme, että menetelmällämme voidaan menestyksekkäästi mitata visuaalista tiedonsiirtokykyä malleissa ja että uusi malliarkkitehtuurimme näyttää lupaavia tuloksia multimodaalisen tiedon hyödyntämisessä unimodaalisessa ympäristössä.', 'cs': 'Je známo, že velké jazykové modely trpí problémem halucinací v tom, že jsou náchylné k výstupním výkazům, které jsou nepravdivé nebo nekonzistentní, což naznačuje nedostatek znalostí. Navrženým řešením je poskytnout modelu další datové modality, které doplňují znalosti získané textem. Zkoumáme využití vizuálních dat k doplnění znalostí velkých jazykových modelů navržením metody hodnocení vizuálního přenosu znalostí do textu pro uni- nebo multimodální jazykové modely. Metoda je založena na dvou krocích, 1) novém úlohovém dotazu na znalost paměťových barev, tj. typických barev známých objektů, a 2) filtrování dat modelového tréninku pro jasné oddělení znalostních příspěvků. Navíc představujeme modelovou architekturu, která zahrnuje krok vizuální fantazie a hodnotíme ji naší navrhovanou metodou. Zjišťujeme, že naše metoda může být úspěšně použita k měření vizuálních schopností přenosu znalostí v modelech a že naše nová modelová architektura ukazuje slibné výsledky pro využití multimodálních znalostí v unimodálním prostředí.', 'et': 'Suured keelemudelid kannatavad teadaolevalt hallutsinatsiooniprobleemi all, sest nad on kalduvad esitama valesid või ebaühtlaseid avaldusi, mis viitavad teadmiste puudumisele. Kavandatav lahendus sellele on pakkuda mudelile täiendavaid andmeid, mis täiendavad tekstiga saadud teadmisi. Uurime visuaalsete andmete kasutamist suurte keelemudelite teadmiste täiendamiseks, pakkudes välja meetodi visuaalsete teadmiste tekstile ülekandmiseks ühe- või mitmeliigiliste keelemudelite jaoks. Meetod põhineb kahel etapil: 1) uuenduslik ülesanne mäluvärvide, st tuntud objektide tüüpiliste värvide pärimiseks ja 2) mudeli koolituse andmete filtreerimiseks, et selgelt eristada teadmisi. Lisaks tutvustame mudeli arhitektuuri, mis sisaldab visuaalset kujutlusvõimet ja hindame seda meie kavandatud meetodiga. Leiame, et meie meetodit saab edukalt kasutada visuaalsete teadmiste edastamise võimekuse mõõtmiseks mudelites ja et meie uudne mudelite arhitektuur näitab paljutõotavaid tulemusi multimodaalsete teadmiste kasutamiseks unimodaalses keskkonnas.', 'jv': 'structural navigation Una supoyo perusahaan kanggo iki dadi nggawe model karo modalité tambah data sing supoyo awak dhéwé nggawe barang text. Awak dhéwé nyonggunian nggambar data Visual kanggo nambah ngerasai model sing luwih bantuan ing nguasai sistem kanggo nggawe ngerasai kesempatan anyar nggo teks kanggo model uni- karo multimodal. Awakdone Mungkin aksi, kita nyengguna architecture model sing nyengkuyung nggawe aturan anyar kang angkang nggawe Awak dhéwé éntuk sistem punika dipunangé kanggo ngelarang kapasituran anyar neng modèl kuwi nggawe barang nggawe barang nggawe sistem model sing bisa pasang awak dhéwé operasi sing dipunangé awak dhéwé multimodal sing nyebutaké awak dhéwé ning béramu sistem unimodal.', 'he': 'מודלים שפות גדולות ידועים לסבול מבעית ההזיות כי הם נוטים להצהרות יציאה ששוויות או לא תואמות, שמצביעים על חוסר ידע. פתרון מוצע לזה הוא לספק למודל מודליות נתונים נוספות שמחליפות את הידע שנקבל דרך טקסט. אנו חוקרים את השימוש של נתונים ויזואליים כדי להוסיף את הידע של דוגמני שפת גדולים על ידי הצעה שיטה להערכה העברת ידע ויזואלי לטקסט עבור דוגמני שפת אוני או multimodal. The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions.  Additionally, we introduce a model architecture that involves a visual imagination step and evaluate it with our proposed method.  אנו מוצאים שהשיטה שלנו יכולה להשתמש בהצלחה כדי למדוד יכולות העברת ידע ויזואלית בדוגמנים ושארכיטקטורת הדוגמנית החדשה שלנו מראה תוצאות מבטיחות להשתמש במידע רב-מודלי במסגרת חד-מודלית.', 'ha': "Ana gane misãlai masu girma cikin harshen salon da za'a cũtar da matabbata ta Hallucinaci, kwani a sami su zuwa magana masu gabatar da ƙarya ko da ba'a ƙunsa da ba'a sani ba. Wata sulfin da aka buƙata zuwa wannan yana azurta shi da shirin ayuka masu ƙaranci da zane-zanen da aka samu da shi daga matsayi. Tuna ƙidãya amfani da data na gane zuwa ya cika kunyar misãlai masu cikin harshen girma da za'a buƙata wani hanyo dõmin an evaluate transfer da zane-gane zuwa matsayin wa misãlai na uni- ko multi-multi. Salon da shirin ayuka ta ƙayyade a kan aikin aiki biyu, 1) mai tambaya wa zane-zane na kumbura, misali launin abun da aka sani, da kuma (2) filteri wa tsarin shiryoyin ayuka da za'a bayyana zane-zane-zane-zane-zane. Additionally, we introduce a model architecture that involves a visual imagination step and evaluate it with our proposed method.  Tuna gane cewa metodenmu za'a iya amfani da mafanici ga iya cika abincin transfer ga gane cikin misalin, kuma a kan muhallin misalin ayuka na yanzu yana nuna matsalar masu yi wa'adi da ake yi wa'adi da su gajiya ma'anar multi-multi a cikin tsarin da ba'a koma ba.", 'sk': 'Veliki jezikovni modeli trpijo zaradi problemov halucinacij, saj so nagnjeni k izhodnim izjavam, ki so lažne ali neskladne, kar kaže na pomanjkanje znanja. Predlagana rešitev za to je zagotoviti modelu dodatne podatkovne načine, ki dopolnjujejo znanje, pridobljeno z besedilom. Raziskujemo uporabo vizualnih podatkov za dopolnitev znanja velikih jezikovnih modelov s predlogom metode ocenjevanja prenosa vizualnega znanja v besedilo za unimodalne ali multimodalne jezikovne modele. Metoda temelji na dveh korakih, 1) novem poizvedovanju o barvah pomnilnika, tj. tipičnih barvah znanih predmetov, in 2) filtriranju podatkov o usposabljanju modela za jasno ločevanje prispevkov znanja. Poleg tega predstavljamo model arhitekture, ki vključuje korak vizualne domišljije in jo ocenimo z našo predlagano metodo. Ugotavljamo, da lahko našo metodo uspešno uporabimo za merjenje sposobnosti prenosa vizualnega znanja v modelih in da naša nova arhitektura modela kaže obetavne rezultate za izkoriščanje multimodalnega znanja v unimodalnem okolju.', 'bo': 'སྐད་ཡིག་གཟུགས་རིས་ཆེན་པོ་ཞིག་ནི་དམིགས་བསལ་བའི་དཀའ་ངལ་ཅིག་ལས་གནོད་པ་ཞིག་ཡོད། འདིས་འཆར་བཀོད་པའི་ཐབས་ཤེས་དེ་ཡི་གེའི་ཐོག་ལས་རྙེད་པའི་གནས་ཚུལ་གསལ་བཤད་ཀྱི་ཐབས་ལམ་ཁ་ཤས་བྱེད་རྒྱུ་རེད། ང་ཚོས་མཐོང་བའི་ཆ་འཕྲིན་ཡིག་གཟུགས་རིས་ལ་ཆ་རྣམས་མཐོང་བའི་སྐད་རིགས་ཀྱི་མ་དཔེ་རིགས་ལ་མཐོང་ནུས་ཀྱི་གནས་ཚུལ་འདྲ་བ་ཞིག་ཏུ་འཇུག་བྱེད The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions. ད་དུང་། ང་ཚོས་མཐོང་བའི་བརྙན་རིས་སྒྲིག ང་ཚོའི་ལམ་ལུགས་འདི་ལྟར་མཐོང་ནུས་མེད་པའི་དབྱིབས་སྐྱེལ་འདྲེན་གྱི་ཆ་རྐྱེན་ཚད་གཅིག་མཐུན་བཟོ་བྱེད་པར་སྤྱོད་ཐུབ་པ་ཡིན་པས།'}
{'en': 'A howling success or a working sea? Testing what BERT knows about metaphors', 'ar': 'نجاح عويل أم بحر عمل؟ اختبار ما يعرفه بيرت عن الاستعارات', 'fr': 'Un succès fulgurant ou une mer qui fonctionne\xa0? Tester ce que le BERT sait des métaphores', 'es': '¿Un éxito rotundo o un mar de trabajo? Probar lo que BERT sabe sobre las metáforas', 'pt': 'Um sucesso uivante ou um mar de trabalho? Testando o que o BERT sabe sobre metáforas', 'ja': 'ハウリングの成功？それとも働く海？バートがメタファーについて知っていることをテストする', 'hi': 'एक howling सफलता या एक काम कर रहे समुद्र? परीक्षण क्या BERT रूपकों के बारे में जानता है', 'zh': '是咆哮之成功与工夫? 试BERT知隐喻', 'ru': 'Воющий успех или работающее море? Тестирование того, что БЕРТ знает о метафорах', 'ga': 'Rath caoineadh nó farraige oibre? Ag tástáil a bhfuil ar eolas ag BERT faoi mheafair', 'el': 'Μια επιτυχία που ουρλιάζει ή μια θάλασσα που λειτουργεί; Δοκιμάζει τι ξέρει ο BERT για μεταφορές', 'hu': 'Üvöltő siker vagy működő tenger? Teszteljük, mit tud a BERT a metaforákról', 'it': 'Un successo urlante o un mare funzionante? Testare ciò che BERT sa sulle metafore', 'lt': 'Šūkimo sėkmė ar darbo jūra? Bandymas, ką BERT žino apie metaforas', 'kk': 'Жұмыс сәттігі немесе жұмыс деңгейі? BERT метафорлар туралы білетінін тексеру', 'mk': 'Успех или море? Тестирање на она што BERT знае за метафорите', 'ms': 'A howling success or a working sea?  Menuji apa yang BERT tahu tentang metafora', 'mt': 'Is-suċċess tat-tixrid jew baħar li jaħdem? L-ittestjar ta’ dak li l-BERT jaf dwar il-metafori', 'ka': 'სამუშაო წარმატება, ან სამუშაო mora? BERT იცოდის მეტაფორების შესახებ', 'mn': 'Улаан амжилт эсвэл ажиллах далай уу? BERT-ийн метафоруудын талаар юу мэддэгийг шалгаж,', 'pl': 'Wyjący sukces czy działające morze? Testowanie tego, co BERT wie o metaforach', 'no': 'Name Testar kva BERT veit om metaforar', 'ro': 'Un succes urlător sau o mare de lucru? Testarea a ceea ce știe BERT despre metafore', 'sr': 'Uspeo ili radno more? Testirajući ono što BERT zna o metaforama', 'si': 'වැඩ කරපු සාර්ථකයක් නැත්නම් වැඩ කරපු මුහුද? BERT දන්නේ මෙටාෆර් ගැන', 'ml': 'A howling success or a working sea?  ബെര്\u200dട്ടി എന്താണെന്ന് പരീക്ഷിക്കുന്നു', 'ta': 'ஒரு வெற்றி அல்லது ஒரு வேலை கடல்? Testing what BERT knows about metaphors', 'sv': 'En hylande framgång eller ett fungerande hav? Testa vad BERT vet om metaforer', 'ur': 'جو چمکتا ہوا کامیابی ہے یا سمندر؟ BERT کے معاملات کے بارے میں کیا جانتا ہے', 'so': 'Badda shaqada? Imtixaanka waxa BERT ku yaqaan', 'uz': 'A howling success or a working sea?  Name', 'vi': 'Một thành công hay một biển làm việc? Kiểm tra những gì sót lại về ẩn dụ', 'bg': 'Виещ успех или работещо море? Тестване на това, което BERT знае за метафорите', 'da': 'En hylende succes eller et arbejdende hav? Test af, hvad BERT ved om metaforer', 'nl': 'Een huilend succes of een werkende zee? Testen wat BERT weet over metaforen', 'hr': 'Plakanje ili radno more? Testirajući što BERT zna o metaforama', 'de': 'Ein heulender Erfolg oder ein funktionierendes Meer? Testen, was BERT über Metaphern weiß', 'id': 'Sukses berteriak atau laut yang bekerja? Menguji apa yang BERT tahu tentang metafora', 'ko': '포효의 성공인가, 일하는 바다인가?버트의 은유에 대한 이해를 시험하다', 'fa': 'موفقیت چشمگیر یا دریا کار؟ آزمایش برت در مورد مثالهای', 'tr': 'Gyglanýan başarnygy ýa-da işleýän deňiz? BERT metaforlar barada näme bilýändigini barlamak', 'af': "'n Hool sukses of 'n werkssee? Toets wat BERT weet oor metafore", 'sw': 'mafanikio ya kusikitisha au bahari inayofanya kazi? Kujaribu kile BERT anachojua kuhusu mifano', 'sq': 'Një sukses ulëritës apo deti që punon? Testimi i asaj që BERT di për metaforat', 'az': 'Böyüyən uğursuzluq və ya çalışan dənizdir? BERT metaforlar haqqında nə bildiyini sınamaq', 'am': 'የልቅሶ ማግኘት ወይም የሥራ ባሕር? Testing what BERT knows about metaphors', 'bn': 'কাঁদছে সাফল্য নাকি কাজের সমুদ্র? বার্ট কি জানে তা পরীক্ষা করা হচ্ছে', 'hy': 'Հաջողություն լալիս կամ աշխատում է ծովը: Տեստել, թե ինչ գիտի ԲԵՌթը փոխաբերությունների մասին', 'ca': 'Un èxit cridant o un mar treballant? Probar el que BERT sap de les metàfores', 'bs': 'Uspješan ili radni mor? Testirajući ono što BERT zna o metaforama', 'et': 'Ulguv edu või töötav meri? Testimine, mida BERT metafooridest teab', 'cs': 'Víjící úspěch nebo pracující moře? Testování toho, co BERT ví o metaforách', 'fi': 'Ulvova menestys vai toimiva meri? Testataan, mitä BERT tietää metaforista', 'jv': 'Ho oh, ngene uwis mangan minggu ? Ngetes piye BERT lak ngerti metaphor', 'he': 'הצלחה זועקת או ים עובד? Testing what BERT knows about metaphors', 'sk': 'Zavijajoč uspeh ali delujoče morje? Preizkušanje, kaj BERT ve o metaforah', 'ha': 'Wani babban rabo mai rauni ko wani tẽku mai aiki? jarraba abin da BERT na sani a kan misfo', 'bo': 'རླད་དམ་པ་ཞིག་ན། ལས་ཀ་འཐབ་རྩོད་པ་ཞིག་ཡིན་ནམ། BERT ཡི་གནས་ཚུལ་གྱི་སྐོར་གྱི་བརྟག་ཞིབ་ཚད་ལྟ་བྱེད་པ'}
{'en': 'Metaphor is a widespread linguistic and cognitive phenomenon that is ruled by mechanisms which have received attention in the literature. Transformer Language Models such as BERT have brought improvements in metaphor-related tasks. However, they have been used only in application contexts, while their knowledge of the phenomenon has not been analyzed. To test what BERT knows about metaphors, we challenge it on a new dataset that we designed to test various aspects of this phenomenon such as variations in linguistic structure, variations in conventionality, the boundaries of the plausibility of a metaphor and the interpretations that we attribute to metaphoric expressions. Results bring out some tendencies that suggest that the model can reproduce some human intuitions about metaphors.', 'fr': "La métaphore est un phénomène linguistique et cognitif répandu qui est régi par des mécanismes qui ont retenu l'attention dans la littérature. Les modèles de langage de transformation tels que BERT ont apporté des améliorations dans les tâches liées aux métaphores. Cependant, ils n'ont été utilisés que dans des contextes d'application, alors que leur connaissance du phénomène n'a pas été analysée. Pour tester ce que le BERT sait des métaphores, nous le remettons en question dans un nouvel ensemble de données que nous avons conçu pour tester divers aspects de ce phénomène, tels que les variations de structure linguistique, les variations de conventionnalité, les limites de la plausibilité d'une métaphore et les interprétations que nous attribuons à la métaphore expressions. Les résultats font ressortir certaines tendances qui suggèrent que le modèle peut reproduire certaines intuitions humaines au sujet des métaphores.", 'pt': 'A metáfora é um fenômeno linguístico e cognitivo amplamente difundido, regido por mecanismos que têm recebido atenção na literatura. Modelos de linguagem transformadora como o BERT trouxeram melhorias em tarefas relacionadas a metáforas. No entanto, eles têm sido usados apenas em contextos de aplicação, enquanto seu conhecimento sobre o fenômeno não foi analisado. Para testar o que o BERT sabe sobre metáforas, nós o desafiamos em um novo conjunto de dados que projetamos para testar vários aspectos desse fenômeno, como variações na estrutura linguística, variações na convencionalidade, os limites da plausibilidade de uma metáfora e as interpretações que atribuímos às expressões metafóricas. Os resultados trazem algumas tendências que sugerem que o modelo pode reproduzir algumas intuições humanas sobre metáforas.', 'es': 'La metáfora es un fenómeno lingüístico y cognitivo generalizado que se rige por mecanismos que han recibido atención en la literatura. Los modelos de lenguaje transformador, como BERT, han traído mejoras en las tareas relacionadas con la metáfora. Sin embargo, solo se han utilizado en contextos de aplicación, mientras que su conocimiento del fenómeno no ha sido analizado. Para probar lo que el BERT sabe sobre las metáforas, lo desafiamos en un nuevo conjunto de datos que diseñamos para probar varios aspectos de este fenómeno, como las variaciones en la estructura lingüística, las variaciones en la convencionalidad, los límites de la plausibilidad de una metáfora y las interpretaciones que atribuimos a la metafórica. expresiones. Los resultados muestran algunas tendencias que sugieren que el modelo puede reproducir algunas intuiciones humanas sobre las metáforas.', 'ar': 'الاستعارة هي ظاهرة لغوية ومعرفية منتشرة تحكمها آليات حظيت باهتمام الأدبيات. جلبت نماذج لغة المحولات مثل BERT تحسينات في المهام المتعلقة بالاستعارة. ومع ذلك ، فقد تم استخدامها فقط في سياقات التطبيق ، بينما لم يتم تحليل معرفتهم بالظاهرة. لاختبار ما تعرفه BERT عن الاستعارات ، نتحدىها في مجموعة بيانات جديدة صممناها لاختبار جوانب مختلفة من هذه الظاهرة مثل الاختلافات في البنية اللغوية ، والاختلافات في الاصطلاحية ، وحدود معقولية الاستعارة والتفسيرات التي ننسبها للتعبيرات المجازية. تظهر النتائج بعض الميول التي تشير إلى أن النموذج يمكن أن يعيد إنتاج بعض الحدس البشري حول الاستعارات.', 'ja': 'メタファーは、文献で注目されているメカニズムによって支配されている、広範囲にわたる言語的および認知的現象です。BERTのようなトランスフォーマー言語モデルは、メタファー関連のタスクに改善をもたらしました。しかし、それらは応用的な文脈でのみ使用されており、その現象に関する知識は分析されていない。BERTがメタファーについて知っていることをテストするために、言語構造のばらつき、従来性のばらつき、メタファーの妥当性の境界、メタファーの表現に帰着する解釈など、この現象のさまざまな側面をテストするために設計された新しいデータセットに挑戦します。結果は、モデルがメタファーに関するいくつかの人間の直観を再現できることを示唆するいくつかの傾向を示しています。', 'zh': '隐喻者,普遍存在之言知,文献之机制也。 变形金刚言语模样(如BERT)隐喻相关。 然其用于应用程序上下文,而其知未析也。 试BERT隐喻之知,挑战于一新之数集上,设此数集来试之,如言语之变,传统性之变,隐喻合理性之界,及吾归因于隐喻之说。 势者,隐喻之直觉也。', 'hi': 'रूपक एक व्यापक भाषाई और संज्ञानात्मक घटना है जो तंत्र द्वारा शासित है जिसने साहित्य में ध्यान आकर्षित किया है। ट्रांसफॉर्मर भाषा मॉडल जैसे BERT ने रूपक से संबंधित कार्यों में सुधार लाया है। हालांकि, उनका उपयोग केवल अनुप्रयोग संदर्भों में किया गया है, जबकि घटना के बारे में उनके ज्ञान का विश्लेषण नहीं किया गया है। यह परीक्षण करने के लिए कि BERT रूपकों के बारे में क्या जानता है, हम इसे एक नए डेटासेट पर चुनौती देते हैं जिसे हमने इस घटना के विभिन्न पहलुओं का परीक्षण करने के लिए डिज़ाइन किया है जैसे कि भाषाई संरचना में भिन्नता, पारंपरिकता में भिन्नताएं, एक रूपक की तर्कसंगतता की सीमाएं और व्याख्याएं जो हम रूपक अभिव्यक्तियों के लिए विशेषता देते हैं। परिणाम कुछ प्रवृत्तियों को बाहर लाते हैं जो सुझाव देते हैं कि मॉडल रूपकों के बारे में कुछ मानव अंतर्ज्ञान को पुन: पेश कर सकता है।', 'ru': 'Метафора - это широко распространенное лингвистическое и когнитивное явление, которое управляется механизмами, получившими внимание в литературе. Языковые модели трансформаторов, такие как BERT, улучшили задачи, связанные с метафорами. Однако они использовались только в прикладных контекстах, в то время как их знание феномена не анализировалось. Чтобы проверить, что БЕРТ знает о метафорах, мы оспариваем это на новом наборе данных, который мы разработали, чтобы проверить различные аспекты этого явления, такие как вариации в лингвистической структуре, вариации в условности, границы правдоподобия метафоры и интерпретации, которые мы приписываем метафорическим выражениям. Результаты выявляют некоторые тенденции, которые предполагают, что модель может воспроизводить некоторые человеческие интуиции о метафорах.', 'ga': 'Feiniméan forleathan teangeolaíoch agus cognaíocha é meafar a rialaítear ag meicníochtaí a bhfuil aird tugtha orthu sa litríocht. Tá feabhas tagtha ar thascanna a bhaineann le meafar i Múnlaí Teanga Trasfhoirmeora ar nós BERT. Mar sin féin, níor úsáideadh iad ach i gcomhthéacsanna feidhmchláir, cé nach bhfuil anailís déanta ar a n-eolas ar an bhfeiniméan. Chun an méid atá ar eolas ag BET faoi mheafair a thástáil, tugaimid dúshlán dó ar thacar sonraí nua a dhearamar chun gnéithe éagsúla den fheiniméan seo a thástáil, mar shampla éagsúlachtaí sa struchtúr teanga, éagsúlachtaí sa choinbhleacht, teorainneacha sochreidteachta meafar agus na léirmhínithe a luaimid. a nathanna meafarach. Tugann torthaí roinnt treochtaí amach a thugann le tuiscint gur féidir leis an tsamhail roinnt intuition daonna faoi mheafair a atáirgeadh.', 'el': 'Η μεταφορά είναι ένα διαδεδομένο γλωσσικό και γνωστικό φαινόμενο που διέπεται από μηχανισμούς που έχουν λάβει προσοχή στη βιβλιογραφία. Τα μοντέλα γλώσσας μετασχηματιστών όπως το BERT έχουν φέρει βελτιώσεις σε εργασίες που σχετίζονται με μεταφορές. Ωστόσο, έχουν χρησιμοποιηθεί μόνο σε πλαίσια εφαρμογής, ενώ η γνώση τους για το φαινόμενο δεν έχει αναλυθεί. Για να δοκιμάσουμε τι γνωρίζει ο BERT για μεταφορές, το αμφισβητούμε σε ένα νέο σύνολο δεδομένων που σχεδιάσαμε για να δοκιμάσουμε διάφορες πτυχές αυτού του φαινομένου, όπως οι παραλλαγές της γλωσσικής δομής, οι παραλλαγές της συμβατικότητας, τα όρια της αξιοπιστίας μιας μεταφοράς και οι ερμηνείες που αποδίδουμε στις μεταφορικές εκφράσεις. Τα αποτελέσματα αναδεικνύουν κάποιες τάσεις που υποδηλώνουν ότι το μοντέλο μπορεί να αναπαράγει κάποιες ανθρώπινες διαισθήσεις σχετικά με μεταφορές.', 'hu': 'A metafora egy széles körben elterjedt nyelvi és kognitív jelenség, amelyet a szakirodalomban figyelmet kapó mechanizmusok irányítanak. Az olyan transzformátor nyelvi modellek, mint a BERT, fejlesztették a metaforákkal kapcsolatos feladatokat. Ezeket azonban csak alkalmazási kontextusokban használták, míg a jelenségről való ismeretüket nem elemezték. Ahhoz, hogy teszteljük, mit tud a BERT a metaforákról, egy új adatkészleten keresztül kihívjuk azt, amelyet a jelenség különböző aspektusainak tesztelésére terveztünk, mint például a nyelvi struktúra változásai, a hagyományosság változásai, a metafora valószínűségének határai és a metaforikus kifejezéseknek tulajdonított értelmezések. Az eredmények olyan tendenciákat mutatnak ki, amelyek arra utalnak, hogy a modell képes reprodukálni néhány emberi intuíciót a metaforákról.', 'it': 'La metafora è un fenomeno linguistico e cognitivo diffuso che è governato da meccanismi che hanno ricevuto attenzione in letteratura. Modelli linguistici dei trasformatori come BERT hanno apportato miglioramenti nei compiti legati alle metafore. Tuttavia, sono stati utilizzati solo in contesti applicativi, mentre la loro conoscenza del fenomeno non è stata analizzata. Per testare ciò che BERT sa delle metafore, lo sfidiamo su un nuovo dataset che abbiamo progettato per testare vari aspetti di questo fenomeno come le variazioni nella struttura linguistica, le variazioni nella convenzionalità, i confini della plausibilità di una metafora e le interpretazioni che attribuiamo alle espressioni metaforiche. I risultati evidenziano alcune tendenze che suggeriscono che il modello può riprodurre alcune intuizioni umane sulle metafore.', 'kk': 'Метафора - лингвистикалық және конитивтік панелі, әдебиеттік механизмлерден басқарылады. BERT секілді тіл түрлендіруші үлгілері, метафорлық тапсырмаларды жақсарту үшін келді. Бірақ олар тек қолданбалардың контекстерінде қолданылады, бірақ олардың пайдалануын білмейді. BERT метафорларды тексеру үшін біз оны жаңа деректер қорында өзгертеміз. Бұл феномендің әртүрлі аспекттерін тексеру үшін, тілдік құрылымының айнымалылығы, әдеттегі айнымалылығы, метафордың шектері мен метафориялық өрнектерге атрибуттарыбыз. Нәтижелер кейбір тенденцияларды таңдайды. Бұл үлгі метафорлар туралы адамдардың тәжірибесін қайта жасай алады.', 'mk': 'Метафората е широк јазички и когнитивен феномен кој се управува со механизмите кои добија внимание во литературата. Моделите на трансформирање јазик како што е BERT донесоа подобрувања во задачите поврзани со метафорите. Сепак, тие се користат само во контекстот на апликациите, додека нивното знаење за феноменот не е анализирано. За да го тестираме тоа што БЕРТ знае за метафорите, го предизвикуваме на нов податок кој го дизајниравме за тестирање на различни аспекти на овој феномен како што се варијациите во јазичката структура, варијациите во конвенционалноста, границите на веројатноста на метафората и интерпретациите кои ги припишуваме на метафорските изрази. Резултатите покажуваат некои тенденции кои покажуваат дека моделот може да репродуцира некои човечки интуиции за метафорите.', 'ms': 'Metafora adalah fenomena bahasa dan kognitif yang disediakan oleh mekanisme yang telah menerima perhatian dalam literatur. Model Bahasa Transformer seperti BERT telah membawa peningkatan dalam tugas berkaitan metafora. Namun, mereka hanya digunakan dalam konteks aplikasi, sedangkan pengetahuan mereka tentang fenomena belum diuji. Untuk menguji apa yang BERT tahu tentang metafora, kita cabar pada set data baru yang kita direka untuk menguji berbagai aspek fenomena ini seperti variasi dalam struktur bahasa, variasi dalam konvensionalitas, sempadan kemungkinan metafora dan interpretasi yang kita atribut kepada ungkapan metafora. Hasil membawa beberapa kecenderungan yang menunjukkan bahawa model boleh mereproduksi beberapa intuisi manusia mengenai metafora.', 'lt': 'Metafora yra plačiai paplitęs kalbinis ir pažintinis reiškinys, kurį valdo mechanizmai, kuriems literatūroje buvo skirtas dėmesys. Perkeitimo kalbos modeliai, pavyzdžiui, BERT, pagerino su metaforomis susijusias užduotis. Tačiau jos buvo naudojamos tik taikymo aplinkybėse, nors jų žinios apie šį reiškinį nebuvo analizuojamos. Norėdami išbandyti tai, ką BERT žino apie metaforas, mes ginčijame ją nauju duomenų rinkiniu, kuriame bandome įvairius šio reiškinio aspektus, pvz., kalbos struktūros pokyčius, įprastumo pokyčius, metaforos patikimumo ribas ir aiškinimus, kuriuos priskiriame metaforinėms išraiškoms. Rezultatai rodo tam tikras tendencijas, rodančias, kad modelis gali atkurti kai kurias žmogaus intuicijas apie metaforas.', 'mn': 'Метафор бол уран зохиолд анхаарал авсан механизмууд дамжуулагдсан хэлний болон мэдлэгтэй явдал юм. BERT шиг хэл загварууд метафор холбоотой ажлыг сайжруулсан. Гэхдээ тэд зөвхөн хэрэгжүүлэх нөхцөлд хэрэглэгдсэн. Тэдний үйл явдлын мэдлэг шинжилгээгүй. BERT-ийн метафоруудын талаар юу мэдэхийг шалгахын тулд бид үүнийг шинэ өгөгдлийн суурь дээр шалгаж, хэлний бүтээгдэхүүний өөрчлөлтийг шалгахын тулд зориулсан шинэ өгөгдлийн суурь дээр шалгаж, хэлний бүтээгдэхүүний өөрчлөлтийг, нийгмийн өөрчлөлтийг, метафорын итгэл үнэлэх хи Үүний үр дүнд загвар нь метафорын тухай зарим хүн төрөлхтний тухай ойлголтыг дахин нэмэгдүүлж чадна.', 'ka': 'მეტაფორი არის უფრო გაფართებული ლენგურისტიკური და კონგენტიგური ფენომენი, რომელიც მართებულია მაქსინტებით, რომელიც ლიტებერიოში მიღებულია გონისტი ტრანფორმაციური ენის მოდელები, როგორც BERT, მეტაფორის შესახებ მომუშაობების შექმნა. მაგრამ ისინი პროგრამების კონტექსტში მხოლოდ გამოყენებულია, მაგრამ ისინი ფენომენის ცოცხლება არ ანალიზებულია. BERT იცოდეთ რას მეტაფორების შესახებ, ჩვენ ამას ახალი მონაცემების კონფიგურაციის შესახებ გამოცდილობა, რომელიც ამ ფენომენის განსხვავებების განსხვავებას, როგორც ენგონისტიკური სტრუქტურაციის განსხვავებების განსხვავებების განსხვავებების გან წარმოდგენები განვითარებს რამდენიმე ტენდენციები, რომლებიც აჩვენებენ, რომ მოდელის შესაძლებელია მოცემული ადამიანის ინტეუციების შესახებ მეტაფორების', 'mt': 'Il-metafora hija fenomenu lingwistiku u konjittiv mifrux li huwa rregolat minn mekkaniżmi li rċevew attenzjoni fil-letteratura. Mudelli tal-Lingwi Transformaturi bħall-BERT wasslu għal titjib fil-kompiti relatati mal-metafora. Madankollu, dawn intużaw biss f’kuntesti ta’ applikazzjoni, filwaqt li l-għarfien tagħhom dwar il-fenomenu ma ġiex analizzat. Biex jiġi ttestjat dak li l-BERT jaf dwar il-metafori, a ħna ninsfidawha fuq sett ta’ dejta ġdid li ddisinjna biex jittestjaw diversi aspetti ta’ dan il-fenomenu bħall-varjazzjonijiet fl-istruttura lingwistika, il-varjazzjonijiet fil-konvenzjonalità, il-limiti tal-plawżibbiltà ta’ metafori u l-interpretazzjonijiet li attribwijna lill-espressjonijiet metaforiċi. Ir-riżultati joħolqu xi tendenzi li jissuġġerixxu li l-mudell jista’ jirriproduċi xi intwizzjonijiet umani dwar il-metafori.', 'pl': 'Metafora jest powszechnym zjawiskiem językowym i poznawczym, którym rządzą mechanizmy, które zyskały uwagę w literaturze. Modele językowe transformatorów, takie jak BERT, przyniosły ulepszenia zadań związanych z metaforą. Są one jednak wykorzystywane tylko w kontekście aplikacji, a ich wiedza na temat tego zjawiska nie została przeanalizowana. Aby sprawdzić, co BERT wie o metaforach, wyzwalamy to na nowym zbiorze danych, który zaprojektowaliśmy, aby sprawdzić różne aspekty tego zjawiska, takie jak zmiany struktury językowej, zmiany konwencjonalności, granice wiarygodności metafory i interpretacje, które przypisujemy metaforycznym wyrażeniom. Wyniki wykazują pewne tendencje sugerujące, że model może odtworzyć pewne ludzkie intuicje dotyczące metafor.', 'ro': 'Metafora este un fenomen lingvistic și cognitiv răspândit care este condus de mecanisme care au primit atenție în literatură. Modelele de limbaj transformator precum BERT au adus îmbunătățiri în sarcinile legate de metafore. Cu toate acestea, acestea au fost utilizate numai în contexte de aplicare, în timp ce cunoștințele lor despre fenomen nu au fost analizate. Pentru a testa ce știe BERT despre metafore, îl provocăm pe un nou set de date pe care l-am conceput pentru a testa diferite aspecte ale acestui fenomen, cum ar fi variațiile structurii lingvistice, variațiile convenționalității, limitele plauzibilității unei metafore și interpretările pe care le atribuim expresiilor metaforice. Rezultatele scot în evidență unele tendințe care sugerează că modelul poate reproduce unele intuiții umane despre metafore.', 'no': 'Metaforet er eit breidde lingvisk og kognitivt fenomen som styrer av mekanismar som har fått oppmerksomhet i litteratur. Transformeringsspråk- modeller som BERT har fått forbedringar i metaforrelaterte oppgåver. Dei har imidlertid berre brukt i programkontekstane, mens dei kjenner om fenomenen er ikkje analysert. For å test a kva BERT kjenner om metaforar, utfordrer vi det på ein ny dataset som vi designerte for å testa ulike aspektar av denne fenomenen, som variasjonar i lingviske strukturen, variasjonar i konvensjonalitet, grensene på uttrykket av ein metaforr og tolkingar som vi attributtar til metaforiske uttrykk. Resultatet gjev ut nokre tendenser som tyder på at modellen kan gjenoppretta nokre menneske intuitjonar om metaforar.', 'sr': 'Metafora je širok širok jezički i kognitivni fenomen koji vlada mehanizami koji su primili pažnju u literaturi. Modeli transformera jezika kao što su BERT doneli su poboljšanje u metaforskim zadacima. Međutim, oni su korišteni samo u kontekstima prijave, dok njihovo znanje o fenomenu nije analizirano. Da bismo testirali ono što BERT zna o metaforama, izazivali smo ga na novom setu podataka koji smo dizajnirali da testiramo različite aspekte ovog fenomena kao što su varijacije jezičke strukture, varijacije konvencionalnosti, granice uvjerljivosti metafore i interpretacije koje pripisujemo metaforskim izrazima. Rezultati donose neke tendencije koje sugeriraju da model može da reprodukuje neke ljudske intuicije o metaforama.', 'sv': 'Metafori är ett utbrett språkligt och kognitivt fenomen som styrs av mekanismer som fått uppmärksamhet i litteraturen. Transformer Språkmodeller som BERT har medfört förbättringar i metaforrelaterade uppgifter. De har dock endast använts i applikationssammanhang, medan deras kunskap om fenomenet inte har analyserats. För att testa vad BERT vet om metaforer utmanar vi det på ett nytt dataset som vi utformat för att testa olika aspekter av detta fenomen såsom variationer i språklig struktur, variationer i konventionell karaktär, gränserna för en metafors sannolikhet och tolkningar som vi tillskriver metaforiska uttryck. Resultaten lyfter fram vissa tendenser som tyder på att modellen kan reproducera vissa mänskliga intuitioner om metaforer.', 'si': 'මෙටාෆෝර් තමයි විශාල භාෂාත්මක සහ පරීක්ෂණාත්මක ප්\u200dරදේශයක්. මෙටාෆෝර් තත්වයේ අවධානය ලැබුණු  BERT වගේ භාෂාව ප්\u200dරවර්තනයක් විදිහට සම්බන්ධ වැඩේ වැඩි කරලා තියෙනවා. නමුත්, ඔවුන් විශ්ලේෂණය කරලා තියෙන්නේ නැති විදිහට. BERT දන්නේ මෙටාෆෝර්ස් ගැන, අපි ඒක අළුත් දත්ත සෙට්ටුවට පරීක්ෂා කරනවා අපි මේ විදියට විවිධ ප්\u200dරතිකාරයක් පරීක්ෂා කරනවා වගේ භාෂාවික සංස්ථානය, විවිධානය, මෙ ප්\u200dරතිචාර විදියට ප්\u200dරතිචාර වෙන්න පුළුවන් විදියට මිනිස්සු ප්\u200dරතිචාර විදියට පුළුවන් කියලා.', 'ml': 'മെറ്റാഫോര്\u200d ഒരു വിശാലമായ ഭാഷയിലുള്ള ഭാഷകശാസ്ത്രതയാണ്. സാഹിത്രത്തില്\u200d ശ്രദ്ധ കൈക്കൊണ്ടിരിക്കുന്ന മെക്കാനിസ്സുകള BERT പോലുള്ള ഭാഷ മോഡലുകള്\u200d മെട്ടിഫോര്\u200d ബന്ധപ്പെട്ട ജോലികളില്\u200d മെച്ചപ്പെടുത്തിയിരിക്കുന്നു. എങ്കിലും അവയെ പ്രയോഗത്തിന്റെ പദ്ധതികളില്\u200d മാത്രമേ ഉപയോഗിച്ചിരിക്കുന്നുള്ളൂ, അവയുടെ അറിവ് വിശദീകരിച്ചിട ബെര്\u200dട്ടി എന്താണെന്ന് പരിശോധിക്കാന്\u200d വേണ്ടി നമ്മള്\u200d അതിനെ വിലാസപ്പെടുത്തുന്ന ഒരു പുതിയ ഡാറ്റാസസെറ്റില്\u200d പരിശോധിക്കുന്നു. ഭാഷകൂട്ടത്തിലെ വ്യത്യാസങ്ങള്\u200d പരീക്ഷിക്കാന്\u200d വേണ Results bring out some tendencies that suggest that the model can reproduce some human intuitions about metaphors.', 'so': 'Metaphoru waa wax luuqadda oo ballaadhan oo ku saabsan, kaas oo xukumaya mekaniisyada ay warqadda ku dhegaysatay. Modelooyinka afka tarafka sida BERT waxay keeneen hagaajinta shaqaalaha la xiriira metaalka. Si kastaba ha ahaatee waxaa lagu isticmaalay arimaha codsiga oo keliya, oo aqoontooda waxyaabaha lagu ogaanayo lama analysin. Si aan u imtixaano waxa BERT ku yaqaan, waxaynu ku dhibaateynaa sawir cusub oo aynu ku qornay in aan imtixaano dhinacyada kala duduwan ee fikradan sida kala duwan ee muuqashada luuqadda, kala duwanaanshaha qaabilaadda, xuduudaha garashada iyo turjumaadka aan ku qorno sawir kala duwan. Laabtoodu waxay soo saaraan dabeecado ka muuqata in modelku uu soo celin karo fikrada biniaadamka.', 'ur': 'مٹیفور ایک گھیری زبان شناختی اور معلوم پھیر ہے جو مکانیزوں کے ذریعے حکومت کیا جاتا ہے جو کتاب میں توجہ حاصل کئے گئے ہیں۔ ٹرانسفور زبان موڈل جیسے BERT نے مٹافور رابطہ دار کاموں میں بہترین توسعہ لایا ہے. لیکن ان کو صرف درخواست معاملات میں استعمال کیا گیا ہے اور ان کے معاملات کا علم تحقیق نہیں کیا گیا ہے BERT کی آزمائش کے لئے مٹافور کے بارے میں کیا جانتا ہے، ہم اسے ایک نئی ڈاٹ سٹ پر چلنے لگتے ہیں جو ہم نے اس فناوری کے مختلف منحصروں کی آزمائش کے لئے طراحی کی ہے جیسے زبان کی ساختاری میں تغییرات، معلومات کی تغییرات، ایک مٹافور کی آزمائش کی محدودیت اور تفسیر کی تعبیر کی جگہ ہم نے نتیجے بعض تنظیمات کو ظاہر کرتے ہیں جو موڈل کو معلوم کرتا ہے کہ مٹافور کے بارے میں انسان کی نظریں دوبارہ پیدا کر سکتی ہیں۔', 'ta': 'மெட்டாபோர் ஒரு விரிவான மொழி மற்றும் குறிப்பிட்ட மொழிகள் என்பது ஒரு விரிவான மொழிகள் மற்றும் குறிப்பிட்ட முறையாகும் அத Transformer Language Models such as BERT have brought improvements in metaphor-related tasks.  ஆனால், அவர்கள் பயன்பாட்டு முறைமைகளில் மட்டும் பயன்படுத்தப்பட்டுள்ளது, ஆனால் அவர்களுடைய அறிவு விளக்கப்படவில்லை. BERT metaphor பற்றி என்ன தெரியும் என்பதை சோதிக்க, நாம் இதை ஒரு புதிய தகவல் அமைப்பில் சவால் செய்ய வேண்டும். இந்த நிகழ்வின் வித்தியாசமான மாறுபாடுகளை சோதிக்க முடியவில்லை போன்ற மொழிக்கல் கட முடிவுகள் சில செயல்பாடுகளை வெளியிடுகின்றன. மாதிரி முறைமையில் உலோகங்கள் பற்றி சில மனித சில உணர்வுகளை மீட்ட', 'uz': "Metaphor - katta tillik va kognitiv narsalar, o'z mekanisme o'zimga taqdim qilgan. Name Lekin ular faqat dastur xizmatlarida ishlatiladi, ammo ularning xususiyatlarini aniqlab qolmadi. BERT metaforlar haqida nima bilan bilganni tekshirish uchun biz uni yangi maʼlumot tarkibida qanday qilamiz. Bu holatning turlarini o'rganish uchun qanday tarjima qilamiz. Natijalar bir necha xususiyatlarni chiqaradi. Usul metaphor haqida bir necha inson hisoblarini qayta oladi.", 'vi': 'Phép ẩn là một hiện tượng ngôn ngữ và nhận thức phổ biến được điều khiển bởi các cơ quan được chú ý trong văn học. Chế độ biến hình ngôn ngữ biến hình như BERT đã mang đến sự cải tiến trong các công việc ẩn dụ. Tuy nhiên, chúng chỉ được sử dụng trong ngữ cảnh ứng dụng, trong khi kiến thức về hiện tượng này chưa được phân tích. Để kiểm tra những gì sót lại về ẩn dụ, chúng ta thách thức nó trên một tập tin mới được thiết kế để thử nghiệm các khía cạnh khác nhau của hiện tượng này, như biến đổi cấu trúc ngôn ngữ, sự biến đổi trong giao tiếp, ranh giới của sự hợp lý của ẩn dụ và cách diễn tả mà chúng ta gán cho biểu tượng ẩn dụ. Kết quả cho thấy một số xu hướng cho thấy mô hình có thể mô phỏng một số linh cảm của con người về ẩn dụ.', 'nl': 'Metafoor is een wijdverbreid linguïstisch en cognitief fenomeen dat wordt beheerst door mechanismen die in de literatuur aandacht hebben gekregen. Transformer Language Modellen zoals BERT hebben verbeteringen gebracht in metaforgerelateerde taken. Ze zijn echter alleen gebruikt in toepassingscontexten, terwijl hun kennis van het fenomeen niet is geanalyseerd. Om te testen wat BERT weet over metaforen, dagen we het uit op een nieuwe dataset die we hebben ontworpen om verschillende aspecten van dit fenomeen te testen, zoals variaties in taalstructuur, variaties in conventionaliteit, de grenzen van de plausibiliteit van een metafoor en de interpretaties die we toeschrijven aan metaforische expressies. De resultaten brengen enkele tendensen naar voren die suggereren dat het model sommige menselijke intuïties over metaforen kan reproduceren.', 'da': 'Metafor er et udbredt sprogligt og kognitivt fænomen, der styres af mekanismer, der har fået opmærksomhed i litteraturen. Transformer Sprogmodeller som BERT har bragt forbedringer i metaforrelaterede opgaver. De er dog kun blevet brugt i applikationssammenhænge, mens deres viden om fænomenet ikke er blevet analyseret. For at afprøve, hvad BERT ved om metaforer, udfordrer vi det på et nyt datasæt, som vi har designet til at teste forskellige aspekter af dette fænomen såsom variationer i sproglig struktur, variationer i konventionel karakter, grænserne for en metafors sandsynlighed og de fortolkninger, vi tillægger metaforiske udtryk. Resultaterne fremhæver nogle tendenser, der tyder på, at modellen kan gengive nogle menneskelige intuitioner om metaforer.', 'bg': 'Метафората е широко разпространено езиково и когнитивно явление, което се управлява от механизми, които са получили внимание в литературата. Трансформаторните езикови модели като BERT донесоха подобрения в задачите, свързани с метафорите. Те обаче са използвани само в контекст на приложение, докато познанията им за явлението не са анализирани. За да тестваме това, което BERT знае за метафорите, ние го предизвикваме на нов набор от данни, който ние разработихме, за да тестваме различни аспекти на това явление като вариации в лингвистичната структура, вариации в конвенционалността, границите на правдоподобността на една метафора и интерпретациите, които приписваме на метафоричните изрази. Резултатите показват някои тенденции, които предполагат, че моделът може да възпроизведе някои човешки интуиции за метафорите.', 'de': 'Metapher ist ein weit verbreitetes linguistisches und kognitives Phänomen, das von Mechanismen beherrscht wird, die in der Literatur Beachtung finden. Transformer Language Modelle wie BERT haben Verbesserungen bei metaphorischen Aufgaben gebracht. Sie wurden jedoch nur in Anwendungskontexten eingesetzt, während ihr Wissen über das Phänomen nicht analysiert wurde. Um zu testen, was BERT über Metaphern weiß, fordern wir es an einem neuen Datensatz heraus, den wir entworfen haben, um verschiedene Aspekte dieses Phänomens zu testen, wie Variationen in der sprachlichen Struktur, Variationen in der Konventionalität, die Grenzen der Plausibilität einer Metapher und die Interpretationen, die wir metaphorischen Ausdrücken zuschreiben. Die Ergebnisse zeigen einige Tendenzen, die darauf hindeuten, dass das Modell einige menschliche Intuitionen über Metaphern reproduzieren kann.', 'hr': 'Metafora je širok širok jezički i kognitivni fenomen koji se vlada mehanizami koji su primili pozornost u literaturi. Modeli transformera jezika poput BERT donosili su poboljšanje u metaforskim zadacima. Međutim, oni su korišteni samo u kontekstima primjene, dok njihovo znanje o fenomenu nije analizirano. Da bismo testirali ono što BERT zna o metaforama, izazvali smo ga na novom setu podataka koji smo dizajnirali da testiramo različite aspekte ovog fenomena kao što su varijacije jezičke strukture, varijacije konvencionalnosti, granice uvjerljivosti metafore i interpretacije koje pripisujemo metaforskim izrazima. Rezultati donose neke tendencije koje sugeriraju da model može promijeniti neke ljudske intuicije o metaforama.', 'id': 'Metafora adalah fenomena bahasa dan kognitif yang disebarkan oleh mekanisme yang telah menerima perhatian dalam literatur. Model Bahasa Transformer seperti BERT telah membawa perkembangan dalam tugas berhubungan metafora. Namun, mereka hanya digunakan dalam konteks aplikasi, sementara pengetahuan mereka tentang fenomena belum dianalisis. Untuk menguji apa yang BERT tahu tentang metafora, kami menantangnya pada set data baru yang kami rancang untuk menguji berbagai aspek fenomena ini seperti variasi dalam struktur bahasa, variasi dalam konvensionalitas, batas plausibilitas metafora dan interpretasi yang kami atribut kepada ekspresi metafora. Hasil membawa beberapa tendensi yang menunjukkan bahwa model dapat mereproduksi beberapa intuisi manusia tentang metafora.', 'fa': 'Metaphor is a widespread linguistic and cognitive phenomenon that is ruled by mechanisms that have received attention in the literature. مدل تغییر دهنده زبانی مانند BERT بهترین کارهای مربوط به متعفر آورده است. با این حال، آنها فقط در شرایط درخواست استفاده می\u200cشوند، در حالی که دانش آنها در این شرایط تحلیل نشده است. برای امتحان کردن چیزی که BERT در مورد مثال می داند، ما آن را روی یک مجموعه داده جدید چالش می کنیم که طراحی کرده ایم برای امتحان کردن نقطه\u200cهای مختلف از این پدیده\u200cها مانند تغییرات در ساختار زبان\u200cشناسی، تغییرات در معمولی، مرزهای مثال\u200cشناسی و تعبیر\u200cهایی که ما به مثال\u200cشناسی تغییر نتیجه\u200cها برخی از نقطه\u200cهای پیشنهاد می\u200cدهند که این مدل می\u200cتواند برخی از بحث انسان را در مورد مثالها بازسازی کند.', 'sw': 'Metaphoro ni jambo ambalo linatawala na mfumo ambao umekumbushwa na fasihi. Modeli za Lugha za Tafsiri kama vile BERT imeleta maendeleo katika kazi zinazohusiana na mitazamo. Hata hivyo, imetumiwa katika miradi ya matumizi tu, wakati maarifa yao ya mambo hayajachambua. Ili kujaribu kile BERT anachojua kuhusu mifano, tunachangamoto kwenye seti mpya ya taarifa ambazo tuliunda ili kujaribu vipengele mbalimbali vya hali hii kama vile mabadiliko katika muundo wa lugha, mabadiliko katika utangazaji, mipaka ya uwezekano wa wimbi na tafsiri tunazohusu hisia za mitazamo. Results bring out some tendencies that suggest that the model can reproduce some human intuitions about metaphors.', 'sq': 'Metafora është një fenomen i përhapur gjuhësor dhe kognitiv që drejtohet nga mekanizmat që kanë marrë vëmendje në letërsi. Modelet e gjuhës Transformer të tilla si BERT kanë sjellë përmirësime në detyrat lidhur me metaforën. Megjithatë, ato janë përdorur vetëm në kontekstet e aplikimit, ndërsa njohuria e tyre për fenomenin nuk është analizuar. Për të testuar atë që BERT di për metaforat, ne e sfidojmë atë në një set të ri të dhënash që ne kemi projektuar për të testuar aspekte të ndryshme të këtij fenomeni si variacionet në strukturën gjuhësore, variacionet në konvencionalitetin, kufijtë e besueshmërisë së një metafore dhe interpretimet që i atribuojmë shprehjeve metaforike. Rezultatet nxjerrin disa tendenca që sugjerojnë se modeli mund të riprodhojë disa intuicione njerëzore rreth metaforave.', 'tr': 'Metaforiýa (metaforiýa) edebiýatda üns berilen mekanizmalar tarapyndan döwletleýän bir lingwistiki we bilgili fenomendir. BERT ýaly dil nusgalary metaforyla ilgili täzeliklerde gelişmeler getirdi. Ýöne olar diňe uygulamalar durumynda ulanylýarlar, olaryň parça bilmesi bardyr. BERT metaforlary barada näme bilýäni barlamak üçin, muny täze bir datasetde çykyp çykýarys. Bu fenomenyň dürli aspektlerini, lingwistiki strukturyň üýtgeşmeleri ýaly, konferensiýanyň üýtgeşmeleriniň, metaforyň ynamlylygynyň çärelerini we metaforiýa tanyşdyrýan terjimeleri barlamak üçin tassykladyk. Netijeler, modeliniň metaforlar hakynda biraz ynsan duýgularyny täzeden edip biljekdigini teklip eden käbir täsirler çykar.', 'am': 'ማተፊኮር የቋንቋ ቋንቋ እና አዋቂ ስሜት ነው፤ በሐሳብሪካ የተጠቃቀው ባለምኮች መንግስታት ይገዛል፡፡ የፊደል ቋንቋ ሞዴል እንደ BERT በሥርዓት ላይ የተጠቃሚ አድራሻ አመጣዋል፡፡ ነገር ግን የግንኙነቱን ማወቅ ሳይዘምሩ በተጠቃሚ ጽሑፎች ውስጥ ብቻ ተጠቀሙ፡፡ BERT ስለ ምሳሌዎች የሚያውቀውን ምን እንደምናውቅ ለመፈትነው፣ የዚህን አዲስ ዳታ setን ለልዩ ልዩ ውጤቶች እንደቋንቋዊ አካባቢ፣ ልዩ ልዩነት፣ የልዩ ልዩ ልዩነት፣ የልዩ ልዩ ልዩነት፣ የብጤፎር ዳርቻ እና የመተላለፊያ ውይይት እና በምናደርገው ትርጓሜዎችን ለመፈትናት እናዋጋታለን፡፡ ፍጥረቶቹ ምሳሌው የህዝብ አሳብ ማሳየት የሚችል አንዳንዶችን ጥያቄ ያወጣሉ፡፡', 'af': "Metafore is 'n breedspreedde lingwisiese en kognitiewe fenomen wat deur mekanisme geregeer word wat aandag in die leeteratur ontvang het. Transformer Taal Modelle soos BERT het verbeteringe in metaforverwante taak gebring. Maar hulle is alleen gebruik in aansoek konteks, terwyl hulle kennis van die fenomen nie analyseer is nie. Om te toets wat BERT weet van metafore, ons uitdruk dit op 'n nuwe datastel wat ons ontwerp het om verskeie aspekte van hierdie fenomen te toets soos veranderinge in lingwisiese struktuur, veranderinge in konvensionaliteit, die grense van die veroorsaaklikheid van 'n metafore en die uitleggings wat ons attributeer na metaforiese uitdrukkings. Resultate bring out some tendencies that suggest that the model can reproduce some human intuitions about metaphors.", 'ko': '은유는 광범위하게 존재하는 언어와 인지 현상으로 각종 메커니즘의 제약을 받고 문헌에서 주목을 받는다.BERT와 같은 Transformer 언어 모델은 은유와 관련된 작업에 개선을 가져왔다.그러나 이들은 응용 환경에서만 사용되고 이 현상에 대한 지식은 아직 분석되지 않았다.버트의 은유에 대한 이해를 시험하기 위해 우리는 새로운 데이터 집합에 도전했다. 우리는 이 데이터 집합을 설계하여 이런 현상의 각 방면, 예를 들어 언어 구조의 변화, 전통적인 변화, 은유의 합리성 경계와 우리가 은유 표현에 의한 해석을 테스트했다.그 결과 이 모델은 은유에 대한 인류의 직감을 재현할 수 있다.', 'az': 'Metaforlar s…ôhif…ôl…ôrind…ô dikkati alńĪnan mehanizmil…ôr t…ôr…ôfind…ôn yayńĪlan dil v…ô kognitiv fenomendir. BERT kimi dil modell…ôri metaforla bańülńĪ iŇül…ôrd…ô yaxŇüńĪlńĪqlar g…ôtirmiŇüdir. Lakin onlar yalnńĪz uyńüunlaŇüdńĪrma m√ľxt…ôlifl…ôrind…ô istifad…ô edilmiŇül…ôr, lakin onlarńĪn par√ßasńĪnńĪn bilgi analiz…ô edilm…ômiŇüdir. BERT metaforlar haqqńĪnda n…ô bildiyini sńĪnamaq √ľ√ß√ľn, bunu yeni bir veri qutusunda t…ôŇükil edirik ki, bu fenomenin m√ľxt…ôlif aspektl…ôrini sńĪnamaq √ľ√ß√ľn t…ôŇükil etdik, kimi dil qutusunda d…ôyiŇüiklikl…ôr, m√ľxt…ôlif d…ôyiŇüiklikl…ôr, metaforńĪn inanńĪlmaz sńĪnńĪrlarńĪ v…ô metaforik ifad…ôl…ôrin…ô t…ôŇükil edirik. Sonu√ßlar, modelin metaforlar haqqńĪnda b…ôzi insan d√ľŇü√ľnc…ôl…ôrini yenil…ôŇüdir…ô bil…ôc…ôyini g√∂st…ôrir.', 'bn': 'মেটাফোর হচ্ছে ব্যাপক ভাষায় ভাষা এবং সাহিত্যে মনোযোগ প্রদান করা মেকানিজেদের দ্বারা শাসন করেছে। ট্রান্সফার্নার্নার্স ভাষার মডেল, যেমন বার্টির সাথে সম্পর্কিত কাজের উন্নতি তৈরি করেছে। তবে এগুলো শুধুমাত্র অ্যাপ্লিকেশন প্রকল্পে ব্যবহার করা হয়েছে, যদিও তাদের জ্ঞান বিশ্লেষণ করা হয় নি। ভাষার কাঠামোর বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন বিভিন্ন প্রতিক্রিয়া পরীক্ষা করার জন্য আমরা এটি চ্যালেঞ্জ করতে চ্যালেঞ্জ করি যেমন ভাষায় ভিন্ন ভিন্ন ভিন্ন ভ ফলাফল কিছু প্রচণ্ড প্রকাশ করেছে যা পরামর্শ করেছে যে মডেল মানুষের কিছু ধারণা পুনরুদ্ধার করতে পারে।', 'cs': 'Metafora je rozšířený jazykový a kognitivní jev, který je ovládán mechanismy, kterým se v literatuře věnovala pozornost. Transformátorové jazykové modely, jako je BERT, přinesly zlepšení v metaforických úkolech. Byly však používány pouze v aplikačních kontextech, zatímco jejich znalosti o fenoménu nebyly analyzovány. Abychom otestovali, co BERT ví o metaforách, vyzýváme to na novém datovém souboru, který jsme navrhli k testování různých aspektů tohoto jevu, jako jsou variace jazykové struktury, variace konvenčnosti, hranice věrohodnosti metafory a interpretace, které přisuzujeme metaforickým výrazům. Výsledky ukazují některé tendence, které naznačují, že model dokáže reprodukovat některé lidské intuice o metaforách.', 'bs': 'Metafora je širok širok jezički i kognitivni fenomen koji vlada mehanizami koji su primili pažnju u literaturi. Modeli transformera jezika poput BERT donosili su poboljšanje u metaforskim zadacima. Međutim, oni su korišteni samo u kontekstima prijave, dok njihovo znanje o fenomenu nije analizirano. Da bismo testirali ono što BERT zna o metaforama, izazivali smo ga na novom setu podataka koji smo dizajnirali da testiramo različite aspekte ovog fenomena kao što su varijacije jezičke strukture, varijacije konvencionalnosti, granice uvjerljivosti metafore i interpretacije koje pripisujemo metaforskim izrazima. Rezultati donose neke tendencije koje sugeriraju da model može reproducirati neke ljudske intuicije o metaforama.', 'hy': 'Մետաֆորը տարածված լեզվաբանական և ճանաչողական ֆենոմեն է, որը ղեկավարվում է մեխանիզմներով, որոնք գրականության մեջ ուշադրություն են ստացել: Տանֆորմացիոն լեզվի մոդելները, ինչպիսիք են BER-ը, բարելավել են փոխաբերության հետ կապված խնդիրները: Այնուամենայնիվ, դրանք օգտագործվել են միայն ծրագրային կոնտեքստում, մինչդեռ ֆենոմենի մասին իրենց գիտելիքները չեն վերլուծվել: Փորձարկելու համար, թե ինչ գիտի ԲԵՌթը փոխաբերությունների մասին, մենք մարտահրավերում ենք այն նոր տվյալների համակարգի վրա, որը մենք ստեղծել ենք փորձարկելու այս ֆենոմենի տարբեր ասպեկտները, ինչպիսիք են լեզվաբանական կառուցվածքի տարբերությունները, ավանդական տարբերությունները, փոխաբերության հավանականության սահմանները և թարգմանությունները, որոնք մենք պատ Արդյունքները ցույց են տալիս որոշ հակվածություններ, որոնք ցույց են տալիս, որ մոդելը կարող է վերարտադրել որոշ մարդկային ինտուիցիաներ փոխաբերությունների մասին:', 'et': 'Metafoor on levinud keeleline ja kognitiivne nähtus, mida reguleerivad kirjanduses tähelepanu pälvinud mehhanismid. Transformerite keelemudelid, nagu BERT, on parandanud metafooridega seotud ülesandeid. Neid on siiski kasutatud ainult rakenduskontekstis, samas kui nende teadmisi nähtusest ei ole analüüsitud. Et testida seda, mida BERT metafooridest teab, esitame selle väljakutse uuele andmekogumile, mille oleme loonud selle nähtuse erinevate aspektide testimiseks, nagu keelestruktuuri variatsioonid, tavapärasuse variatsioonid, metafoori usutavuse piirid ja metafoorsetele väljenditele omistatud tõlgendused. Tulemused toovad esile mõned tendentsid, mis näitavad, et mudel võib reprodutseerida mõningaid inimlikke intuitsioone metafooride kohta.', 'fi': 'Metafori on laajalle levinnyt kielellinen ja kognitiivinen ilmiö, jota ohjaavat kirjallisuudessa huomiota saaneet mekanismit. Transformer Language Models, kuten BERT, on tuonut parannuksia metaforiin liittyviin tehtäviin. Niitä on kuitenkin käytetty vain sovelluskohteissa, mutta niiden tietämystä ilmiöstä ei ole analysoitu. Testataksemme sitä, mitä BERT tietää metaforista, haastamme sen uuteen aineistoon, jonka suunnittelimme testaamaan ilmiön eri puolia, kuten kielellisen rakenteen vaihtelua, muunnelmia tavanomaisuudesta, metaforan uskottavuuden rajoja ja tulkintoja, joita annamme metaforisille ilmaisuille. Tulokset tuovat esiin joitakin taipumuksia, jotka viittaavat siihen, että malli voi toistaa joitakin ihmisen intuitioita metaforista.', 'ca': "La metàfora és un fenomen lingüístic i cognitiu generalitzat que està governat per mecanismes que han rebut atenció a la literatura. Models de llenguatge transformador com BERT han portat millors en tasques relacionades amb les metàfores. No obstant això, només s'han utilitzat en contextes d'aplicació, mentre que el seu coneixement del fenomen no s'ha analitzat. Per provar el que BERT sap de les metàfores, el desafiam en un nou conjunt de dades dissenyat per provar diversos aspectes d'aquest fenomen com variacions en l'estructura lingüística, variacions en la convencionalitat, límits de la plausibilitat d'una metàfora i les interpretacions que atribuïm a les expressions metàfores. Els resultats produeixen algunes tendències que suggereixen que el model pot reproducir algunes intuïcions humanes sobre metàfores.", 'ha': "Metafor is an widespread linguistic and kognitive abu that rules by mekanis waɗand a suka motsa muhimmin littafin. @ action: button Hata haka, ba su yi amfani da su ba fãce da mazaɓa, alhãli kuwa saninsu ba ya yi analyza. To, dõmin ka jarraba abin da BERT yake sani game da misfofo, za'a kange shi a kan wani takis na new wanda muka designe shi dõmin ka jarraba masu cikin masu husũma na wannan abu kamar variants cikin tsarin linguistic, variants a cikin masu husũma, grensa da za'a yi musamman da fassarar da za'a bayyana shi ga misãlai. Mataimakin na fitar da wasu irin ta'ura da ke shagala cewa, misalin za ya iya mayar da wasu na'anin mutum a kan misfofo.", 'sk': 'Metafora je razširjen jezikovni in kognitivni pojav, ki ga vladajo mehanizmi, ki so bili v literaturi pozorni. Modeli transformatorjev jezikov, kot je BERT, so prinesli izboljšave v metaforskih nalogah. Vendar pa so se uporabljali le v aplikacijskih kontekstih, njihovo poznavanje pojava pa ni bilo analizirano. Da bi preizkusili, kaj BERT ve o metaforah, ga izzivamo na novem naboru podatkov, ki smo ga oblikovali za preizkušanje različnih vidikov tega pojava, kot so variacije jezikovne strukture, variacije konvencionalnosti, meje verodostojnosti metafore in interpretacije, ki jih pripisujemo metaforičnim izrazom. Rezultati izpostavljajo nekatere tendence, ki kažejo, da lahko model reproducira nekatere človeške intuicije o metaforah.', 'jv': 'metaphor iku padha akeh kelangan langgambar lan kowé éntuk sing nguasai karo mekanistik sing dino ning teratura. Laptop" and "Desktop Nanging, duwé wis dipoleh nèng pengguna-kowarni iki dadi ono Mbok ujian sing BERT ngerti barang metaphor, kita ngubah dhéwé urip kaya dataset sing dibenakake nggawe ujian karo perkara sing kalalah banjur Pametuné awak dhéwé éntuk kesempalahan sing luwih nggawe modèl iso nguasai perbudhakan karo metaforan.', 'bo': 'འདྲ་སྐུལ་ནི་སྐད་རིགས་དང་ཤེས་པའི་སྒེར་གྱི་རྣམ་པ་ཞིག་རེད། BERT ཡི་དཔེར་ན། འགྱུར་བརྒྱུད་པའི་སྐད་ཡིག་མ་དབྱིབས་གནས་ཚུལ་མཐུན་གྱི་བྱ་འགུལ་ལ་ཡར་རྒྱས་གཏོང་བྱུང་། ཡིན་ནའང་། ཁོང་ཚོས་ཉེར་སྤྱོད་ཀྱི་གནས་ཚུལ་ཁོ་ན་ལག་ལེན་འཐབ་བྱས་མེད་པའི་སྐབས་དེ་ཉེར་སྤྱོད་ཀྱི་ཆ་རྐྱེན་ཞ BERT ་གི་གནས་ཚུལ་སྐོར་གྱི་བརྟག་ཞིབ་ལ་ང་ཚོས་རང་ཉིད་ཀྱི་ཆ་འཕྲིན་གྱི་ནང་དུ་ཡོད་པའི་ཆ་འཕྲིན་གསརཔ་ཞིག་ལ་དཀའ་ངལ་ཞིབ་བྱེད་རྒྱུ་དང་། དབྱིབས་འབྲས་བ་ནི་མིག་ལམ་ལ་ཁྱད་པར་མཐུན་རྐྱེན་ཡོང་།', 'he': 'מטאפורה היא תופעה שפתית וקוניטיבית ששולטת על ידי מנגנונים שקיבלו תשומת לב בספרות. Transformer Language Models such as BERT have brought improvements in metaphor-related tasks.  However, they have been used only in application contexts, while their knowledge of the phenomenon has not been analyzed.  To test what BERT knows about metaphors, we challenge it on a new dataset that we designed to test various aspects of this phenomenon such as variations in linguistic structure, variations in conventionality, the boundaries of the plausibility of a metaphor and the interpretations that we attribute to metaphoric expressions.  Results bring out some tendencies that suggest that the model can reproduce some human intuitions about metaphors.'}
{'en': 'How Length Prediction Influence the Performance of Non-Autoregressive Translation?', 'pt': 'Como a previsão de comprimento influencia o desempenho da tradução não autorregressiva?', 'fr': 'Comment la prédiction de longueur influence les performances de la traduction non autorégressive\xa0?', 'ar': 'كيف يؤثر توقع الطول على أداء الترجمة غير الانحدارية؟', 'es': '¿Cómo influyen las predicciones de longitud en el rendimiento de la traducción no autorregresiva?', 'ja': '長さ予測は、非自動回帰的翻訳のパフォーマンスにどのように影響しますか？', 'hi': 'गैर-स्वत: प्रतिगामी अनुवाद के प्रदर्शन को कैसे प्रभावित करता है?', 'zh': '长占如何非自归译性?', 'ru': 'Как прогнозирование длины влияет на производительность неавторегрессивного перевода?', 'ga': 'Cén tionchar a bhíonn ag Réamhthuar Faid ar Fheidhmíocht Aistriúcháin Neamh-Uath-chéimnitheach?', 'ka': 'როგორ სიგრძელი წინაწყვეტის შესაძლებლობა არ ავტორეგრესიური წინაწყვეტის შესაძლებლობა?', 'hu': 'Hogyan befolyásolja a hosszúság előrejelzése a nem automatikus fordítás teljesítményét?', 'el': 'Πώς επηρεάζει η πρόβλεψη μήκους την απόδοση της μη αυτοανακριτικής μετάφρασης;', 'it': 'In che modo la previsione della lunghezza influenza le prestazioni della traduzione non autoregressiva?', 'kk': 'Автогрегрессивні емес аудармасының істеу қанша ұзындығы?', 'mk': 'How Length Prediction Influence the Performance of Non-Autoregressive Translation?', 'ms': 'Macam mana jangkaan panjang mempengaruhi Performance of Non-Autoregressive Translation?', 'ml': 'സ്വയമില്ലാത്ത വിവരങ്ങളുടെ പ്രവര്\u200dത്തനത്തിന്റെ പ്രവർത്തികമാണെങ്ങനെയാണ് നീളമുള്ളത്?', 'mn': 'Хэдэн урт хугацааны анхаарлын нөлөө нь автоматжруулах бус орнуудын үйлдэл хэрхэн нөлөөлдөг вэ?', 'mt': 'Kif it-Tbassir tat-Tul jinfluwenza l-Prestazzjoni tat-Traduzzjoni Mhux Awtoregressiva?', 'no': 'Kor langt forhåndsvising influenser utføringa av ikkje-autoregressivt omsetjing?', 'lt': 'Kaip ilgio prognozė turi įtakos neautoregresinio vertimo rezultatams?', 'pl': 'Jak prognoza długości wpływa na wydajność tłumaczenia nieautoresywnego?', 'ro': 'Cum influențează predicția de lungime performanța traducerii non-autoregresive?', 'si': 'කොච්චර ලොකු ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ස්වයංක්\u200dරියාත්මක නොප්\u200dරශ්නයක් පරිවර්තනය කරන්නේ?', 'so': 'Sidee Length Prediction influence the Performance of Non-Autoregressive Translation?', 'sv': 'Hur längdförutsägelse påverkar prestandan av icke-autoregressiv översättning?', 'sr': 'Koliko dugačka predviđanja utječe na provedbu neporegresivnog prevoda?', 'ta': 'எவ்வாறு நீளமான விருப்பத்தேர்வு தானியங்கி மொழிபெயர்ப்பின் செயல்பாடு?', 'ur': 'کس طرح طویل پیشنهاد غیر اٹوگریسٹی ترجمہ کی عملکرد اثر کرتا ہے؟', 'uz': '@ info: whatsthis', 'vi': 'Sự hạn chế tác động của sự trình diễn của dịch không tự động?', 'bg': 'Как прогнозирането на дължината влияе върху ефективността на неавторегресивния превод?', 'da': 'Hvordan forudsigelse af længde påvirker ydeevnen af ikke-autoregressiv oversættelse?', 'nl': 'Hoe beïnvloedt lengteprognitie de prestaties van niet-autoregressieve vertaling?', 'hr': 'Koliko dugačka predviđanja utječe na učinku nepotoregresivnog prevoda?', 'de': 'Wie beeinflusst Längenprädiktion die Leistung von nicht autoregressiven Übersetzungen?', 'ko': '길이 예측은 어떻게 비자귀환 번역의 성능에 영향을 줍니까?', 'id': 'How Length Prediction Influence the Performance of Non-Autoregressive Translation?', 'fa': 'چقدر تأثیر پیش\u200cبینی طولانی عملکرد ترجمه\u200cهای غیر خودکار اثر می\u200cدهد؟', 'tr': 'Otomatik gaýşartmaýan terjime etkiniň nähili Uzun Wasp Etkinlik?', 'am': 'እንዴት ረጅም ፕሮግራምশন influence the Performance of Non-Autoregressive Translation?', 'sq': 'How Length Prediction Influence the Performance of Non-Autoregressive Translation?', 'sw': 'Utafiti wa Utawala wa Utawala wa Utawala wa Udhibiti wa kujitegemea ni vipi?', 'af': 'Hoe Lengte Voorskou Ieffens die Performasie van Non- Autoregressive Vertaling?', 'hy': 'Ինչպե՞ս է երկարության կանխատեսումը ազդում ոչ-ինքնառեգրեսիվ թարգմանման գործողություններին:', 'bn': 'স্বয়ংক্রিয়ভাবে অনুবাদের প্রযুক্তি কিভাবে দীর্ঘ?', 'ca': 'Com la predicció de llargada influeix en el rendiment de la traducció no autoregressiva?', 'az': 'Otomatik-regressiv terc칲m톛nin 톛m톛ll톛rinin n톛 q톛d톛r Uzuncu T톛rc칲m톛 Etdi?', 'et': 'Kuidas mõjutab pikkuse prognoos mitteautoregressiivse tõlke jõudlust?', 'bs': 'Koliko duga predviđanja utječe na učinku neporegresivnog prevoda?', 'cs': 'Jak délková predikce ovlivňuje výkon neautoregresivního překladu?', 'fi': 'Miten pituuden ennustaminen vaikuttaa ei-autoregressiivisen käännöksen suorituskykyyn?', 'ha': '@ info: whatsthis', 'jv': 'politenessoffpolite"), and when there is a change ("assertive', 'sk': 'Kako napoved dolžine vpliva na uspešnost neavtoregresivnega prevajanja?', 'he': 'How Length Prediction Influence the Performance of Non-Autoregressive Translation?', 'bo': 'རང་འགུལ་གྱིས་མེད་རུང་བའི་སྐད་བརྗོད་ཀྱི་གདོང་ཚད་གང་འདྲ་ཡིན།'}
{'en': 'Length prediction is a special task in a series of NAT models where target length has to be determined before generation. However, the performance of length prediction and its influence on translation quality has seldom been discussed. In this paper, we present comprehensive analyses on length prediction task of NAT, aiming to find the factors that influence performance, as well as how it associates with translation quality. We mainly perform experiments based on Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), a representative NAT model, and evaluate it on two language pairs, En-De and En-Ro. We draw two conclusions : 1) The performance of length prediction is mainly influenced by properties of language pairs such as alignment pattern, word order or intrinsic length ratio, and is also affected by the usage of knowledge distilled data. 2) There is a positive correlation between the performance of the length prediction and the BLEU score.', 'ar': 'التنبؤ بالطول هو مهمة خاصة في سلسلة من نماذج NAT حيث يجب تحديد الطول المستهدف قبل التوليد. ومع ذلك ، نادرًا ما تمت مناقشة أداء توقع الطول وتأثيره على جودة الترجمة. في هذه الورقة ، نقدم تحليلات شاملة حول مهمة التنبؤ بطول NAT ، بهدف العثور على العوامل التي تؤثر على الأداء ، وكذلك كيفية ارتباطه بجودة الترجمة. نقوم بشكل أساسي بإجراء تجارب على أساس نموذج اللغة المقنعة الشرطية (CMLM) (غازفينينجاد وآخرون ، 2019) ، وهو نموذج تمثيلي لـ NAT ، ونقوم بتقييمه على أزواج لغتين ، En-De و En-Ro. نستخلص استنتاجين: 1) يتأثر أداء التنبؤ بالطول بشكل أساسي بخصائص الأزواج اللغوية مثل نمط المحاذاة أو ترتيب الكلمات أو نسبة الطول الجوهري ، كما يتأثر أيضًا باستخدام البيانات المقطرة للمعرفة. 2) توجد علاقة ارتباط موجبة بين أداء توقع الطول ودرجة BLEU.', 'fr': "La prédiction de longueur est une tâche spéciale dans une série de modèles NAT où la longueur cible doit être déterminée avant la génération. Cependant, la performance de la prédiction de longueur et son influence sur la qualité de la traduction ont rarement été discutées. Dans cet article, nous présentons des analyses complètes sur la tâche de prédiction de longueur de NAT, dans le but de trouver les facteurs qui influencent les performances, ainsi que la façon dont elles s'associent à la qualité de la traduction. Nous réalisons principalement des expériences basées sur le modèle de langage masqué conditionnel (CMLM) (Ghazvininejad et al., 2019), un modèle NAT représentatif, et l'évaluons sur deux paires de langues, En-De et En-Ro. Nous tirons deux conclusions\xa0: 1) La performance de la prédiction de longueur est principalement influencée par les propriétés des paires de langues, telles que le modèle d'alignement, l'ordre des mots ou le rapport de longueur intrinsèque, et est également affectée par l'utilisation de données distillées de connaissances. 2) Il existe une corrélation positive entre les performances de la la prédiction de la longueur et le score BLEU.", 'pt': 'A previsão de comprimento é uma tarefa especial em uma série de modelos NAT em que o comprimento do alvo deve ser determinado antes da geração. No entanto, o desempenho da previsão de comprimento e sua influência na qualidade da tradução raramente tem sido discutido. Neste artigo, apresentamos análises abrangentes sobre a tarefa de previsão de comprimento do NAT, com o objetivo de encontrar os fatores que influenciam o desempenho, bem como como ele se associa à qualidade da tradução. Realizamos principalmente experimentos baseados no Modelo de Linguagem Mascarada Condicional (CMLM) (Ghazvininejad et al., 2019), um modelo NAT representativo, e o avaliamos em dois pares de idiomas, En-De e En-Ro. Tiramos duas conclusões: 1) O desempenho da previsão de comprimento é influenciado principalmente por propriedades de pares de idiomas, como padrão de alinhamento, ordem das palavras ou proporção de comprimento intrínseco, e também é afetado pelo uso de dados destilados de conhecimento. 2) Existe uma correlação positiva entre o desempenho da previsão de comprimento e o escore BLEU.', 'es': 'La predicción de longitud es una tarea especial en una serie de modelos NAT en los que la longitud objetivo debe determinarse antes de la generación. Sin embargo, rara vez se ha discutido el rendimiento de la predicción de longitud y su influencia en la calidad de la traducción. En este artículo, presentamos análisis exhaustivos sobre la tarea de predicción de longitud de NAT, con el objetivo de encontrar los factores que influyen en el rendimiento, así como la forma en que se asocia con la calidad de la traducción. Realizamos principalmente experimentos basados en el Modelo de Lenguaje Enmascarado Condicional (CMLM) (Ghazvininejad et al., 2019), un modelo NAT representativo, y lo evaluamos en dos pares de idiomas, En-De y En-Ro. Sacamos dos conclusiones: 1) El rendimiento de la predicción de longitud está influenciado principalmente por las propiedades de los pares de idiomas, como el patrón de alineación, el orden de las palabras o la relación de longitud intrínseca, y también se ve afectado por el uso de datos destilados de conocimiento. 2) Existe una correlación positiva entre el rendimiento de la predicción de longitud y puntuación BLEU.', 'zh': '长占一系 NAT 模中一特殊任务,其趋长必于生成之前定。 然长占性能及译质所染,罕有讨论。 本文NAT度周析,指求性能之素,与译质相关。 大抵掩码言(CMLM)(Ghazvininejad等,2019)一代表性之NAT实验,两言而质En-DeEn-Ro。 吾得两论:1)长短之性,受齐模式、词序、内比言语属性,亦受知识提炼数据之用。 2)长短之性,与BLEU分数相关。', 'ru': 'Прогнозирование длины является специальной задачей в серии моделей NAT, где целевая длина должна быть определена до генерации. Тем не менее, производительность прогнозирования длины и ее влияние на качество перевода обсуждались редко. В этой статье мы представляем комплексный анализ задачи прогнозирования длины NAT, направленный на поиск факторов, которые влияют на производительность, а также на то, как она ассоциируется с качеством перевода. Мы в основном проводим эксперименты на основе модели условного маскированного языка (CMLM) (Ghazvininejad et al., 2019), репрезентативной модели NAT, и оцениваем ее на двух языковых парах, En-De и En-Ro. Мы делаем два вывода: 1) На производительность прогнозирования длины в основном влияют свойства языковых пар, такие как шаблон выравнивания, порядок слов или внутреннее соотношение длин, а также на использование данных, дистиллированных знаниями. 2) Существует положительная корреляция между производительностью прогнозирования длины и баллом BLEU.', 'ja': '長さ予測は、生成前に目標長を決定する必要がある一連のNATモデルの特別なタスクです。しかし、長さ予測の性能と翻訳品質への影響はほとんど議論されていない。本稿では， NATの長さ予測タスクに関する包括的な分析を提示し，パフォーマンスに影響を与える要因とそれが翻訳品質とどのように関連しているかを見出すことを目的とする．主に代表的なNATモデルであるConditional Masked Language Model (CMLM )( Ghazvininejad et al., 2019)に基づいた実験を行い、En - DeとEn - Roの2つの言語ペアで評価する。我々は、1)長さ予測のパフォーマンスは、主にアラインメントパターン、語順、固有長比などの言語ペアの特性に影響され、知識蒸留データの使用にも影響を受ける。2)長さ予測のパフォーマンスとBLEUスコアとの間には正の相関がある。', 'hi': 'लंबाई की भविष्यवाणी NAT मॉडल की एक श्रृंखला में एक विशेष कार्य है जहां लक्ष्य की लंबाई पीढ़ी से पहले निर्धारित की जानी है। हालांकि, लंबाई की भविष्यवाणी के प्रदर्शन और अनुवाद की गुणवत्ता पर इसके प्रभाव पर शायद ही कभी चर्चा की गई है। इस पेपर में, हम NAT की लंबाई भविष्यवाणी कार्य पर व्यापक विश्लेषण प्रस्तुत करते हैं, जिसका उद्देश्य उन कारकों को ढूंढना है जो प्रदर्शन को प्रभावित करते हैं, साथ ही साथ यह अनुवाद की गुणवत्ता के साथ कैसे जुड़ता है। हम मुख्य रूप से सशर्त नकाबपोश भाषा मॉडल (सीएमएलएम) (Ghazvininejad et al., 2019), एक प्रतिनिधि NAT मॉडल पर आधारित प्रयोग करते हैं, और दो भाषा जोड़े, एन-डे और एन-रो पर इसका मूल्यांकन करते हैं। हम दो निष्कर्ष निकालते हैं: 1) लंबाई की भविष्यवाणी का प्रदर्शन मुख्य रूप से भाषा जोड़े के गुणों जैसे संरेखण पैटर्न, शब्द क्रम या आंतरिक लंबाई अनुपात से प्रभावित होता है, और ज्ञान आसुत डेटा के उपयोग से भी प्रभावित होता है। 2) लंबाई की भविष्यवाणी और BLEU स्कोर के प्रदर्शन के बीच एक सकारात्मक सहसंबंध है।', 'ga': 'Is tasc speisialta é réamh-mheas an fhaid i sraith de shamhlacha TAN, áit nach mór an spriocfhad a chinneadh roimh ghiniúint. Mar sin féin, is annamh a pléadh feidhmíocht thuar faid agus a thionchar ar cháilíocht an aistriúcháin. Sa pháipéar seo, cuirimid i láthair anailísí cuimsitheacha ar thasc thuar faid TAN, dírithe ar na fachtóirí a théann i bhfeidhm ar fheidhmíocht a fháil, chomh maith leis an gcaoi a bhfuil baint aige le cáilíocht an aistriúcháin. Déanaimid turgnaimh den chuid is mó bunaithe ar Mhúnla Teanga Mascaithe Coinníollach (CMLM) (Ghazvininejad et al., 2019), samhail ionadaíoch NAT, agus déanaimid é a mheas ar dhá phéire teanga, En-De agus En-Ro. Bainimid dhá chonclúid: 1) Tá tionchar ag airíonna péirí teanga go príomha ar fheidhmíocht réamh-mheastacháin faid, mar shampla patrún ailínithe, ord focal nó cóimheas fad intreach, agus bíonn tionchar aige freisin ar úsáid sonraí driogtha eolais. 2) Tá comhghaol dearfach idir feidhmíocht an tuar faid agus an scór BLEU.', 'el': 'Η πρόβλεψη μήκους είναι μια ειδική εργασία σε μια σειρά μοντέλων όπου το μήκος στόχου πρέπει να καθοριστεί πριν από τη δημιουργία. Ωστόσο, σπάνια συζητήθηκε η απόδοση της πρόβλεψης μήκους και η επιρροή της στην ποιότητα της μετάφρασης. Στην παρούσα εργασία, παρουσιάζουμε ολοκληρωμένες αναλύσεις σχετικά με το έργο πρόβλεψης μήκους της ΝΑΤ, με στόχο να εντοπίσουμε τους παράγοντες που επηρεάζουν την απόδοση, καθώς και τον τρόπο που συνδέεται με την ποιότητα της μετάφρασης. Πραγματοποιούμε κυρίως πειράματα βασισμένα σε ένα αντιπροσωπευτικό μοντέλο και το αξιολογούμε σε δύο γλωσσικά ζεύγη, Εν-Ντε και Εν-Ρο. Βγάζουμε δύο συμπεράσματα: 1) Η απόδοση της πρόβλεψης μήκους επηρεάζεται κυρίως από τις ιδιότητες των γλωσσικών ζευγαριών όπως το μοτίβο ευθυγράμμισης, η σειρά λέξεων ή η εγγενής αναλογία μήκους, και επηρεάζεται επίσης από τη χρήση των αποσταγμένων δεδομένων γνώσης. 2) Υπάρχει θετική συσχέτιση μεταξύ της απόδοσης της πρόβλεψης μήκους και της βαθμολογίας BLEU.', 'hu': 'A hosszúság előrejelzése speciális feladat egy olyan NAT modellek sorozatában, ahol a célhosszt a generáció előtt meg kell határozni. A hosszúság-előrejelzés teljesítményét és annak a fordítási minőségre gyakorolt hatását azonban ritkán vitatták meg. Ebben a tanulmányban átfogó elemzéseket mutatunk be a NAT hosszúság előrejelzésének feladatairól, azzal a céllal, hogy megtaláljuk a teljesítményt befolyásoló tényezőket, valamint hogyan kapcsolódik a fordítási minőséghez. Elsősorban a feltételes maszkos nyelvi modell (CMLM) (Ghazvininejad et al., 2019) alapján végzünk kísérleteket, és két nyelvpáron értékeljük, az En-De és az En-Ro. Két következtetést vonunk le: 1) A hosszúság előrejelzésének teljesítményét elsősorban a nyelvpárok tulajdonságai befolyásolják, mint például az igazítási minta, a szósorrend vagy a belső hosszúság arány, és befolyásolják a tudás desztillált adatok használata is. 2) Pozitív korreláció áll fenn a hossz előrejelzés teljesítménye és a BLEU pontszám között.', 'ka': 'სიგრძე წარმოდგენა არის სპეციალური დავალება NAT მოდელების სერიოში, სადაც მისაწყისი სიგრძე უნდა განსაზღვრულია წარმოდგენისთვის. მაგრამ, განსაზღვრების და მისი გრძნობის კოლექტურის გამოყენება მარტივია განსაზღვრებულია. ამ დოკუნში ჩვენ გავაჩვენოთ ყველაფერი ანალიზები NAT-ის სიგრძე წინასწორებული საქაღალდე, რომლებიც აღმოჩვენებენ ფაქტორები, რომლებიც გამოიყენებენ გამოყენება და როგორ ჩვენ მხოლოდ ექსპერიმენტები გავაკეთებთ კონდიციონალური მასკრებული ენის მოდელზე (CMLM) (Ghazvininejad et al., 2019), რესპერიმენტი NAT მოდელზე და გავამუშავებთ ორი ენის ზოგებით, En-De და En-Ro. ჩვენ ვაკეთებთ ორი გადაწყვეტი: 1) სიგრძე წარმოდგენების გამოსახულება უფრო მეტად იქნება ენის ზოგების განსახულებებით, როგორც წარმოდგენება, სიტყვების წარმოდგენება ან ინტერენსური სიგრძე გან 2) არსებობს პოტიფიკაციური კორელექცია სიგრძე წარმოდგენების და BLEU წარმოდგენების შორის.', 'it': "La previsione della lunghezza è un compito speciale in una serie di modelli NAT in cui la lunghezza obiettivo deve essere determinata prima della generazione. Tuttavia, le prestazioni della previsione della lunghezza e la sua influenza sulla qualità della traduzione sono state raramente discusse. In questo articolo, presentiamo analisi complete sul compito di previsione della lunghezza di NAT, con l'obiettivo di trovare i fattori che influenzano le prestazioni, così come come esso si associa alla qualità della traduzione. Eseguiamo principalmente esperimenti basati sul Modello Conditional Masked Language (CMLM) (Ghazvininejad et al., 2019), un modello NAT rappresentativo, e lo valutiamo su due coppie linguistiche, En-De e En-Ro. Trattiamo due conclusioni: 1) Le prestazioni della previsione della lunghezza sono influenzate principalmente dalle proprietà delle coppie linguistiche come il modello di allineamento, l'ordine delle parole o il rapporto intrinseco della lunghezza, ed è influenzata anche dall'uso dei dati distillati dalla conoscenza. 2) C'è una correlazione positiva tra le prestazioni della previsione di lunghezza e il punteggio BLEU.", 'kk': 'Ұзындық таңдау - NAT моделдерінің бірнеше тапсырманы құру алдында таңдау керек болады. Бірақ ұзындық таңдау және оның аудармалардың сапасына әсер ету әсер етілмейді. Бұл қағазда, NAT тапсырмасының ұзындығын алдын- алау тапсырмасының толық анализацияларын таңдаймыз. Бұл тапсырмасына әсер ету факторларын табу үшін және аудармалардың сапасы қалай Біз негізінде шарт қалқалаған тіл үлгісіне негізделген эксперименттерді (CMLM) (Ghazvininejad et al., 2019), негізгі NAT үлгісін жасап, екі тіл екі, En-De және En-Ro үлгісінде оқу үшін жасаймыз. Біз екі нәтижесін таңдаймыз: 1) Ұзындығының таңдау әдістері көбінде тіл екі қасиеттерінің, мысалы, түрлендіру үлгісі, сөздер реті не ішкі ұзындығының қасиеттері, сондай-ақ білім көбірек дерект 2) Ұзындық таңдау және BLEU нәтижесі арасындағы оң салыстыру бар.', 'lt': 'Ilgio prognozė yra ypatinga užduotis keliuose NAT modeliuose, kuriuose tikslinis ilgis turi būti nustatytas prieš sukūrimą. Tačiau retai aptarta ilgumo prognozės veiksmingumas ir jos įtaka vertimo kokybei. Šiame dokumente pateikiame išsamią NAT ilgumo prognozavimo užduoties analizę, kuria siekiama rasti veiksnius, darančius įtaką veiklos rezultatams, ir kaip ji siejama su vertimo kokybe. We mainly perform experiments based on Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), a representative NAT model, and evaluate it on two language pairs, En-De and En-Ro.  Ištraukiame dvi išvadas: 1) ilgio prognozės veiksmingumą daugiausia lemia kalbų poros savybės, pavyzdžiui, suderinimo modelis, žodžių tvarka arba vidinis ilgio santykis, ir tai daro įtaką ir distiliuotų žinių naudojimas. 2) Yra teigiama ilgumo prognozės ir BLEU rezultatų koreliacija.', 'mk': 'Предвидувањето на должината е специјална задача во серија модели на НАТ каде што должината на целта мора да се одреди пред генерацијата. Сепак, ретко се дискутира за извршувањето на предвидувањето на должината и нејзиното влијание врз квалитетот на преводот. Во овој документ, претставуваме комплетни анализи за задачата за предвидување на должината на НАТ, со цел да ги најдеме факторите кои влијаат на резултатите, како и како се поврзува со квалитетот на превод. Главно спроведуваме експерименти базирани на Кондиционалниот маскиран јазик модел (CMLM) (Ghazvininejad et al., 2019), претставник на НАТ модел, и го проценуваме на два јазички пара, En-De и En-Ro. Повлекуваме две заклучоци: 1) Извршувањето на предвидувањето на должината е влијано главно врз сопственостите на јазичките парови како што се образецот на израмнување, редот на зборовите или внатрешниот однос на должина, и е влијано и врз употребата на дистилирани податоци 2) Постои позитивна корелација помеѓу резултатот на предвидувањето на должината и оценката БЛЕУ.', 'ms': 'Ramalan panjang adalah tugas istimewa dalam siri model NAT dimana panjang sasaran perlu ditentukan sebelum generasi. Namun, prestasi ramalan panjang dan pengaruhnya pada kualiti terjemahan jarang dibahas. Dalam kertas ini, kami mempersembahkan analisis komprensif tentang tugas ramalan panjang NAT, bertujuan untuk mencari faktor yang mempengaruhi prestasi, serta bagaimana ia berkaitan dengan kualiti terjemahan. Kami terutama melakukan eksperimen berdasarkan Model Bahasa Bertopeng Conditional (CMLM) (Ghazvininejad et al., 2019), model mewakili NAT, dan menilainya pada dua pasangan bahasa, En-De dan En-Ro. Kita lukiskan dua kesimpulan: 1) Performasi prediksi panjang terutamanya dipengaruhi oleh ciri-ciri pasangan bahasa seperti corak penyesuaian, urutan perkataan atau nisbah panjang dalaman, dan juga dipengaruhi oleh penggunaan pengetahuan data yang dipotong. 2) Terdapat korelasi positif antara prestasi ramalan panjang dan skor BLEU.', 'ml': 'നാടി മോഡലുകളില്\u200d നീളം പ്രവചനം ഒരു പ്രത്യേക ജോലിയാണ്. മുന്\u200dതലമുറയില്\u200d ലക്ഷ്യം തീരുമാനിക്കേണ്ടതുണ്ട്. എന്നാലും നീണ്ട പ്രവചനവും അതിന്റെ പ്രഭാവം പരിഭാഷപ്പെടുത്തുന്നതിന്റെ ഗുണത്തിന്റെ പ്രഭാവം വളരെ കുറച ഈ പത്രത്തില്\u200d, നാട്ടിന്റെ നീളം പ്രവചനങ്ങളുടെ ജോലിയെക്കുറിച്ച് നമ്മള്\u200d പൂര്\u200dണ്ണമായ അന്വേഷണങ്ങള്\u200d കൊണ്ടുവരുന്നു. പ്രഭാവനത്തിന്റെ  നമ്മള്\u200d പ്രധാനപ്പെട്ട പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. നാട്ടിന്റെ പ്രതിനിധിയായ ഒരു പ്രതിനിധിയായ നാറ്റി മോഡല്\u200d (സിഎംഎം) അടിസ്ഥാനത്ത് നിര ഞങ്ങള്\u200d രണ്ടു അവസാനം വരയ്ക്കുന്നു: 1) നീളം പ്രവചനങ്ങളുടെ പ്രധാനപ്പെടുത്തുന്നത് ഭാഷ ഇണകളുടെ ഗുണഗണങ്ങളാല്\u200d പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു. ചേര്\u200dന്ന 2) നീളം പ്രവചനം പ്രവചിപ്പിക്കുന്നതിനും ബില്യൂ സ്കോര്\u200d', 'mt': 'It-tbassir tat-tul huwa kompitu speċjali f’serje ta’ mudelli NAT fejn it-tul fil-mira jrid jiġi ddeterminat qabel il-ġenerazzjoni. Madankollu, il-prestazzjoni tat-tbassir tat-tul u l-influwenza tiegħu fuq il-kwalità tat-traduzzjoni rarament ġew diskussi. In this paper, we present comprehensive analyses on length prediction task of NAT, aiming to find the factors that influence performance, as well as how it associates with translation quality.  Il-biċċa l-kbira tagħna twettaq esperimenti bbażati fuq Mudell Kundizzjonali tal-Lingwa Maskjata (CMLM) (Ghazvininejad et al., 2019), mudell rappreżentattiv tan-NAT, u tevalwawha fuq żewġ pari lingwistiċi, En-De u En-Ro. Aħna niġbdu żewġ konklużjonijiet: 1) Il-prestazzjoni tat-tbassir tat-tul hija influwenzata prinċipalment minn proprjetajiet ta’ pari lingwistiċi bħalma huma mudell ta’ allinjament, ordni tal-kliem jew proporzjon intrinsiku tat-tul, u hija affettwata wkoll mill-użu ta’ dejta distillata tal-għarfien. 2) There is a positive correlation between the performance of the length prediction and the BLEU score.', 'mn': 'Урт таамаглах нь NAT загварын цуврал дээр зорилготой урттай ажиллагаа юм. Гэхдээ урт хугацааны үр дүнг болон түүний хөрөнгө оруулах чадварын нөлөө нь бага зэрэг хэлэлцдэг. Энэ цаасан дээр бид НАТ-ын урт хугацааны даалгаварын талаар бүрэн шинжилгээ үзүүлдэг. Үүний үр дүнд нөлөөлж буй хүчин зүйлсийг олох зорилготой. Бид ихэвчлэн шалтгаан хэл загвар (CMLM) (Ghazvininejad et al., 2019), NAT загварын төлөөлөгч, үүнийг хоёр хэл хоёр, En-De, En-Ro дээр үнэлдэг. Бид хоёр шалтгаан зурж байна: 1) Уртын таамаглалын үр дүнг ихэвчлэн хэл хоёрын шинжлэх ухаан, үгийн дараа эсвэл дотоод урт харьцаа шинжлэх ухааны хэрэглээнд нөлөөлдөг. 2) Уртын таамаглалт болон BLEU оноо хоорондох эерэг холбоотой.', 'no': 'Lengdforhåndsvising er ein spesiell oppgåve i ei serie av NAT-modeller der mållengde må bestemme før oppretting. Men utviklinga av forhåndsvising av lengd og påvirkinga på omsetjingskvalitet er ofte diskutert. I denne papiret presenterer vi komplette analyser om løgdforhåndsvising av NAT-oppgåva, med mål å finna faktorene som påvirkar utviklinga, og korleis den tilhøyrer omsetjingskvalitet. Vi utfører hovudsakelig eksperimenter basert på vanleg maskert språk-modell (CMLM) (Ghazvininejad et al., 2019), eit reprezentativt NAT-modell, og evaluerer det på to språk-par, En-De og En-Ro. Vi tegnar to konklusjonar: 1) Utviklinga av lengden er hovudsakelig påvirka av eigenskapar av språkparar som mønster for justering, ordordordordning eller innenfor lengdsforholdet, og blir også påvirka av bruken av kunnskap distilerte data. 2) Det er eit positivt korrelasjon mellom utføringen av lengden og BLEU-poeng.', 'pl': 'Przewidywanie długości jest specjalnym zadaniem w serii modeli NAT, w których długość docelowa musi być ustalona przed wygenerowaniem. Jednak rzadko omawiano wykonanie predykcji długości i jej wpływ na jakość tłumaczenia. W artykule przedstawiono kompleksowe analizy dotyczące zadań prognozowania długości NAT, mające na celu znalezienie czynników wpływających na wydajność, jak również związanych z jakością tłumaczenia. Przeprowadzamy głównie eksperymenty oparte na warunkowym modelu języka maskowanego (CMLM) (Ghazvininejad et al., 2019), reprezentatywnym modelu NAT, i oceniamy go na dwóch parach językowych, En-De i En-Ro. Wyciągamy dwa wnioski: 1) Na wydajność przewidywania długości wpływają głównie właściwości par językowych, takie jak wzór wyrównania, kolejność słów czy współczynnik długości wewnętrznej, a także wykorzystanie danych destylowanych z wiedzy. 2) Istnieje pozytywna korelacja między wydajnością przewidywania długości a wynikiem BLEU.', 'ro': 'Prevederea lungimii este o sarcină specială într-o serie de modele NAT în care lungimea țintă trebuie determinată înainte de generare. Cu toate acestea, performanța predicției lungimii și influența acesteia asupra calității traducerii au fost rareori discutate. În această lucrare, prezentăm analize cuprinzătoare privind sarcina de predicție a lungimii NAT, cu scopul de a găsi factorii care influențează performanța, precum și modul în care aceasta se asociază cu calitatea traducerii. Realizăm în principal experimente bazate pe Modelul Condițional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), un model NAT reprezentativ, și îl evaluăm pe două perechi de limbi, En-De și En-Ro. Tragem două concluzii: 1) Performanța predicției lungimii este influențată în principal de proprietățile perechilor de limbi, cum ar fi modelul de aliniere, ordinea cuvintelor sau raportul intrinsec de lungime, și este, de asemenea, afectată de utilizarea datelor distilate de cunoștințe. 2) Există o corelație pozitivă între performanța predicției lungimii și scorul BLEU.', 'sr': 'Dužin a predviđanja je poseban zadatak u nizu modela NAT-a gde treba da se odredi dužina cilja pre generacije. Međutim, učinkovitost predviđanja dužine i njegovog utjecaja na kvalitet prevoda rijetko se raspravlja. U ovom papiru predstavljamo sveobuhvatne analize o zadatku predviđanja dužine NAT-a, u cilju naći faktore koji utiču na učinkovitost, kao i kako se povezuje sa kvalitetom prevođenja. Uglavnom izvodimo eksperimente na osnovu uslovnog maskiranog jezika model a (CMLM) (Ghazvininejad et al., 2019), predstavnika NAT modela i procjenjujemo ga na dva jezika paira, En-De i En-Ro. Napravili smo dva zaključka: 1) Izvrsnost predviđanja dužine uglavnom utječe na vlasništvo jezičkih parova kao što su uzorak poravnanja, redak reči ili odnos dužine unutrašnje, a takođe utječe na upotrebu znanja destiliranih podataka. 2) Postoji pozitivna korelacija između provedbe predviđanja dužine i rezultata BLEU-a.', 'so': 'Aqoonta dhererku waa shaqo gaar ah oo ku yaala tusaalooyin NAT ah oo ku qoran dhererka goalku waa in la go’aamiyo ka hor qarniga. Si kastaba ha ahaatee waxaa si yar looga baaraandegay ogeysiinta dhererka ah iyo saamaynta ku saabsan qiimaha turjumidda. Qoraalkan waxaynu keenaynaa baaritaanka aasaasiga ah oo ku saabsan shaqada sii sheegidda ee NAT, kaas oo ku talo leh in la helo waxyaabaha saameyn ku yeelata performance iyo sidoo kale sida ay u xidhiidhayso qiimaha turjumaadda. Inta badan waxaynu sameynaa imtixaamo ku saleysan qaababka caadiga ah ee luuqada Masked (CMLM) (Ghazvininejad et al., 2019), kaas oo ka representative NAT model, waxaana qiimeynaynaa laba noocyo oo af ah, En-De iyo En-Ro. Waxaynu soo wareejinnaa laba dhamaadood: 1) dhamaadka sii-dhigista waxyaabaha luuqada ah waxaa ugu badan saameyn ku leh noocyada isbedelka, tusaale ahaan qaabka hadalka ama taranka dhererka gudaha ah, waxaa saameyn ku leh isticmaalka aqoonta macluumaadka kala duduwan. 2) Waxaa jira xiriir positive ah oo ku dhexeeya dhamaadka sii-sheegidda dhererka iyo scorta BLEU.', 'si': 'විශේෂ විශේෂ විශේෂ කාර්යයක් NAT මොඩල් සිරිසියක් තියෙන්නේ ඉලක්ෂාව ලොක්කාව පරීක්ෂණය කලින නමුත්, විශ්වාස ක්\u200dරියාත්මක විශ්වාස කරලා තියෙන්නේ නැහැ. මේ පත්තරේ අපි NAT ගේ විශේෂ විශ්ලේෂණය සඳහා ප්\u200dරශ්ණ විශ්ලේෂණය කරනවා, අදහස් කරනවා විශේෂ ක්\u200dරියාත්මක හොයාගන්න, ඒ ව අපි ප්\u200dරධානයෙන් පරීක්ෂණයක් කරන්නේ ස්ථානික භාෂා මොඩේල් එක්ක (CMLM) (GhazivinineJat et al., 2019), ප්\u200dරධාන NAT මොඩේල් එකක්, ඒ වගේම භාෂා දෙකක්, en-de සහ en- අපි අවස්ථාව දෙකක් ගන්නවා: 1) ලොකු අවස්ථාවේ ප්\u200dරභාව ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විතරයි භාෂා ජාති ජාති වලින් ප්\u200dරශ්නයක් වගේ, වචන අව 2) ඉන්නවා ලොකු ප්\u200dරශ්නයක් සහ BLUE ප්\u200dරශ්නයක් අතර සම්බන්ධයක් තියෙනවා.', 'sv': 'Längdförutsägelse är en särskild uppgift i en serie NAT-modeller där mållängden måste bestämmas före generering. Men prestandan av längdprognoser och dess påverkan på översättningskvaliteten har sällan diskuterats. I den här uppsatsen presenterar vi omfattande analyser av längdprediktionsuppgiften för NAT, med syfte att hitta de faktorer som påverkar prestanda, samt hur det associeras med översättningskvalitet. Vi utför huvudsakligen experiment baserade på Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), en representativ NAT modell, och utvärderar den på två språkpar, En-De och En-Ro. Vi drar två slutsatser: 1) Längdprognosens prestanda påverkas huvudsakligen av egenskaper hos språkpar såsom justeringsmönster, ordordning eller inneboende längdförhållande, och påverkas också av användningen av kunskapsdestillerad data. 2) Det finns ett positivt samband mellan längdprognosen och BLEU-poängen.', 'ur': 'Length prediction is a special task in a series of NAT models where target length must be determined before generation. لیکن، طویل پیش بینی اور اس کا تأثیر ترجمہ کیفیت پر بہت کم مشورہ کیا گیا ہے۔ اس کاغذ میں ہم نے NAT کی طویل پیش بینی کے کام کے بارے میں بہت سی تحلیل پیش کیے ہیں، جو فکتوروں کو دیکھنا چاہتے ہیں جو عملکرد کے تاثیر دیتے ہیں، اور اس کی ترجمہ کیفیت کے ساتھ کس طرح تعلق رکھتے ہیں۔ ہم عمدہ طور پر مستقیم زبان موڈل (CMLM) (Ghazvininejad et al., 2019) پر آزمائش کررہے ہیں، ایک نماینٹر NAT موڈل، اور اسے دو زبان جوڑوں پر ارزش کررہے ہیں، ان-De اور ان-رو. ہم دو نتیجے کریں: 1) طویل پیش بینی کی عملکرد کی عملکرد زیادہ زبان جوڑوں کی ویژگی کے ذریعے اثر دی جاتی ہے جیسے سیدھی پیٹرنگ پٹرنگ، کلمات اورمن یا داخلی طویل نسبت، اور علم کے استعمال سے بھی اثر دی جاتی ہے۔ 2) طول پیش بینی اور BLEU اسکور کے درمیان مثبت تعلق ہے.', 'ta': 'நீளம் முன்பு உருவாக்குவதற்கு முன் இலக்கு நீளம் தீர்மானிக்கப்பட வேண்டிய ஒரு சிறப்பு செயல் ஆயினும், நீளம் மொழிபெயர்ப்பு தரம் மற்றும் அதன் விளைவுகள் குறைவாகவே விவாதம் செய்யப்பட்டுள்ளது. இந்த காகிதத்தில், நாம் நீண்ட முன்வாக்கி பணியின் மீது முழு ஆய்வுகளை கொண்டு வருகிறோம், மொழிபெயர்ப்பு தரமுடன் எவ்வாறு பாதிக்கு நாம் முக்கியமாக சாதாரண மொழி மாதிரி மாதிரி அடிப்படையில் சோதனைகளை செய்கிறோம் (காஜ்வினிஜாட் மற்றும் ஒரு பிரதிநிதிய NAT மாதிரியாக, மற்றும் அதை இரண்டு மொ நாம் இரண்டு முடிவுகளை வரைகிறோம்: 2) நீளம் முன்னோட்டத்தை மற்றும் பிலூயு மதிப்பெண்ணின் செயல்பாட்டிற்கும் இடையே ஒரு நேர்மை இணைப்பு உள்ளது.', 'uz': "@ info: whatsthis Lekin, uzun oldinga bajarish va tarjima sifatida ishlatish natijasi haqida juda kam javob berilmadi. Bu qogʻozdagi biz NAT'ning uzun oldini oldingan vazifani o'rganamiz. Ularning amalni o'zgartirish va tarjima sifatida qanday bog'langan narsalarni topish mumkin. Biz oddiy taʼminlovchi NAT modeli (Ghazvininejad et al., 2019) ga ega bo'lgan tizim modeliga (CMLM) (Ghazvininejad et al., Ghazvininejad, al., 2019) asosida imtiyozlarni bajaramiz va bu ikki tilni to'plab, En-De va En-Ro bilan qiymatmiz. Biz ikkita murojaat bilan chiqaramiz: 1) uzunlik bajarishi natijasi asosiy tilning xossalariga tenglashtirish shakllari, soʻzning tartibi yoki ichki uzunligi darajada ishlatiladi, va bu faqat ajratilgan maʼlumot yordamida qoʻllaniladi. 2) Koʻrinishi va BLEU scorini bajarish uchun yaxshi bogʻliq mavjud.", 'vi': 'Dự đoán về độ dài là một nhiệm vụ đặc biệt trong một loạt các mẫu bên nguyên (đời nguyên (đời nguyên) để xác định độ dài đích trước thời thế hệ. Tuy nhiên, quá trình dự đoán độ dài và ảnh hưởng của nó lên chất lượng dịch chưa được thảo luận. Trong tờ giấy này, chúng tôi đưa ra các phân tích to àn diện về nhiệm vụ dự đoán độ dài của NIT, nhằm tìm ra các yếu tố tác động đến hiệu suất, cũng như cách nó liên kết với chất lượng dịch chuyển. Chúng tôi thường tiến hành thí nghiệm dựa trên mô hình ngôn ngữ Masced (chung chung chung LM) (Ghanti nejad et al., 99), a representative ANT model, và đánh giá nó dựa vào hai cặp ngôn ngữ, En-De và En-Ro. Chúng tôi rút ra hai kết luận: 1) Sự hiệu quả của dự đoán độ dài bị ảnh hưởng bởi tính chất của các cặp ngôn ngữ như mô hình phối hợp, trật tự hay tỷ lệ độ dài nội bộ, và cũng bị ảnh hưởng bởi cách sử dụng các dữ liệu được chưng cất. 2) Có một mối tương quan tích cực giữa hiệu quả của dự đoán dài và số lượng bắn nguyên khí.', 'bg': 'Прогнозирането на дължината е специална задача в серия от модели, при които целевата дължина трябва да бъде определена преди генерирането. Въпреки това, изпълнението на прогнозирането на дължината и влиянието му върху качеството на превода рядко е обсъждано. В настоящата статия представяме изчерпателни анализи на задачата за прогнозиране на дължината на НАТ, с цел да открием факторите, които влияят на изпълнението, както и как тя се свързва с качеството на превода. Извършваме експерименти, базирани основно на Модел на Условен Маскиран Език (Ghazvininejad et al., 2019), представителен НАТ модел, и го оценяваме върху две езикови двойки, En-De и En-Ro. Направихме две изводи: 1) Изпълнението на прогнозирането на дължината се влияе основно от свойствата на езиковите двойки като модел на подравняване, ред на думите или вътрешно съотношение на дължината, а също така се влияе от използването на дестилирани знания данни. 2) Има положителна корелация между изпълнението на прогнозата за дължината и резултата.', 'nl': 'Lengte voorspelling is een speciale taak in een reeks NAT modellen waarbij de streeflengte moet worden bepaald alvorens te worden gegenereerd. De prestaties van lengteprognitie en de invloed ervan op de vertaalkwaliteit zijn echter zelden besproken. In dit artikel presenteren we uitgebreide analyses over de lengteprognitietaak van NAT, met als doel de factoren te vinden die de prestaties beïnvloeden en hoe het samenhangt met vertaalkwaliteit. We voeren voornamelijk experimenten uit op basis van Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), een representatief NAT model, en evalueren dit op twee taalparen, En-De en-Ro. We trekken twee conclusies: 1) De prestaties van lengteprognitie worden voornamelijk beïnvloed door eigenschappen van taalparen zoals uitlijningspatroon, woordvolgorde of intrinsieke lengteverhouding, en wordt ook beïnvloed door het gebruik van kennis gedistilleerde gegevens. 2) Er is een positieve correlatie tussen de prestaties van de lengteverhouding en de BLEU score.', 'da': 'Længde forudsigelse er en særlig opgave i en række NAT modeller, hvor mållængden skal bestemmes før generering. Der er dog sjældent blevet diskuteret resultaterne af længdeforudsigelsen og dens indflydelse på oversættelseskvaliteten. I denne artikel præsenterer vi omfattende analyser af længdepregningsopgaver for NAT med det formål at finde de faktorer, der påvirker ydeevnen, samt hvordan det knytter sig til oversættelseskvaliteten. Vi udfører hovedsageligt eksperimenter baseret på Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), en repræsentativ NAT model, og evaluerer den på to sprogpar, En-De og En-Ro. Vi drager to konklusioner: 1) Præstationen af længde forudsigelse er primært påvirket af egenskaber af sprogpar såsom justeringsmønster, ordrækkefølge eller iboende længdeforhold, og er også påvirket af brugen af viden destilleret data. 2) Der er en positiv sammenhæng mellem resultaterne af længde forudsigelsen og BLEU scoren.', 'hr': 'Predviđanje dužine je poseban zadatak u nizu modela NAT-a gdje treba odrediti dužina cilja prije generacije. Međutim, učinkovitost predviđanja dužine i utjecaja na kvalitet prevoda rijetko se raspravlja. U ovom papiru predstavljamo sveobuhvatne analize o zadatku predviđanja dužine NAT-a, u cilju pronaći faktore koji utječu na učinkovitost, kao i kako se povezuje s kvalitetom prevoda. Uglavnom izvodimo eksperimente na temelju uslovnog maskiranog jezičkog model a (CMLM) (Ghazvininejad et al., 2019), predstavnika NAT modela i procjenjujemo ga na dva jezička parova, En-De i En-Ro. Napravili smo dva zaključka: 1) Učinnost predviđanja dužine uglavnom utječe na vlasništvo jezičkih parova poput uzoraka poravnanja, reda riječi ili odnosa dužine unutrašnje, te utječe na uporabu znanja destiliranih podataka. 2) Postoji pozitivna korelacija između provedbe predviđanja dužine i rezultata BLEU-a.', 'de': 'Längenprädiktion ist eine besondere Aufgabe in einer Reihe von NAT-Modellen, bei denen die Ziellänge vor der Generierung bestimmt werden muss. Die Leistung der Längenprädiktion und ihr Einfluss auf die Übersetzungsqualität wurden jedoch selten diskutiert. In diesem Beitrag stellen wir umfassende Analysen zur Längenprädiktionsaufgabe von NAT vor, mit dem Ziel herauszufinden, welche Faktoren die Leistung beeinflussen und wie sie mit der Übersetzungsqualität assoziiert wird. Wir führen hauptsächlich Experimente basierend auf dem Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), einem repräsentativen NAT-Modell, durch und evaluieren es an zwei Sprachpaaren, En-De und En-Ro. Wir ziehen zwei Schlussfolgerungen: 1) Die Leistung der Längenprädiktion wird hauptsächlich durch Eigenschaften von Sprachpaaren wie Ausrichtungsmuster, Wortreihenfolge oder intrinsisches Längenverhältnis beeinflusst und auch durch die Verwendung von Wissensdestillierten Daten beeinflusst. 2) Es besteht eine positive Korrelation zwischen der Leistung der Längenprädiktion und dem BLEU-Score.', 'id': 'Prediksi panjang adalah tugas khusus dalam seri model NAT dimana panjang sasaran harus ditentukan sebelum generasi. Namun, prestasi prediksi panjang dan pengaruhnya pada kualitas terjemahan jarang didiskusikan. Dalam kertas ini, kami mempersembahkan analisis komprensif tentang tugas prediksi panjang NAT, bertujuan untuk menemukan faktor yang mempengaruhi prestasi, serta bagaimana ia berhubungan dengan kualitas terjemahan. Kami terutama melakukan eksperimen berdasarkan Model Bahasa Bertopeng Kondisional (CMLM) (Ghazvininejad et al., 2019), model yang mewakili NAT, dan mengevaluasinya pada dua pasangan bahasa, En-De dan En-Ro. Kami menarik dua kesimpulan: 1) Prestasi prediksi panjang terutama dipengaruhi oleh properti pasangan bahasa seperti pola penyesuaian, urutan kata atau proporsi panjang intrinsik, dan juga dipengaruhi oleh penggunaan pengetahuan data yang didistil. 2) Ada korelasi positif antara prestasi prediksi panjang dan skor BLEU.', 'sw': 'Utabiri wa muda mrefu ni kazi maalum katika mfululizo wa mitindo ya NAT ambapo lengo lazima utekelezwe kabla ya kizazi. Hata hivyo, utendaji wa utabiri wa muda mrefu na ushawishi wake wa ubora wa tafsiri umejadiliwa mara chache. Katika karatasi hii, tunatoa uchambuzi wa kina kuhusu jukumu la utabiri la ndefu la NAT, lengo la kutafuta sababu zinazoathiri utendaji, na jinsi inavyohusiana na ubora wa tafsiri. Kwa ujumla tunafanya majaribio kwa kutumia Mradi wa Lugha zilizotengenezwa na mazingira (CMLM) (Ghazvininejad et al., 2019), Mradi wa NAT, na kutathmini kwa namna mbili za lugha, En-De na En-Ro. Tunajaribu hitimisho mbili: 1) Utabiri wa muda mrefu unaathirika zaidi na utafiti wa wataalamu wa lugha kama vile mtindo wa kujitengeneza, amri ya maneno au kiwango cha urefu wa ndani, na pia umeathirika na matumizi ya ujuzi wa taarifa zilizotenganishwa. 2) Kuna uhusiano chanya kati ya utabiri wa muda mrefu na score ya BLEU.', 'ko': '길이 예측은 생성되기 전에 대상 길이를 결정해야 하는 일련의 NAT 모델 중 하나입니다.그러나 길이 예측의 성능과 번역 품질에 대한 영향에 대해서는 논의가 드물다.본고에서 우리는 NAT의 길이 예측 임무를 종합적으로 분석했는데 성능에 영향을 주는 요소와 번역의 질과의 관계를 찾아내는 데 목적을 둔다.우리는 주로 대표적인NAT모델인 조건엄폐언어모델(CMLM)(Ghazvininejad et al., 2019)을 토대로 실험을 진행하고 두 언어로 En-De와 En-Ro에 대해 평가한다.우리는 두 가지 결론을 얻었다. 1) 길이 예측의 성능은 주로 언어가 대조하는 정렬 모델, 어순 또는 고유의 길이비 등 속성의 영향을 받고 지식 추출 데이터의 사용 상황의 영향을 받는다.2) 길이 예측은 BLEU 점수와 상관관계가 있다.', 'fa': 'پیش\u200cبینی طولانی یک کار خاص در مجموعه مدل NAT است که طول هدف قبل از نسل تعیین می\u200cشود. ولی عملکرد پیش\u200cبینی طولانی و تاثیرش بر کیفیت ترجمه کمی درباره\u200cی آن صحبت می\u200cشود. در این کاغذ، ما تحلیل کامل در مورد کار پیش بینی طولانی NAT را پیشنهاد می\u200cکنیم، که هدف می\u200cگیریم به پیدا کردن faktورهایی که تأثیر عملکرد را تأثیر می\u200cدهند، و چگونه با کیفیت ترجمه ارتباط دارد. ما در اصل آزمایش\u200cهایی را بر اساس مدل زبان\u200cهای مسکونی (CMLM) (Ghazvininejad et al., 2019) انجام می\u200cدهیم، یک مدل نماینده NAT، و آن را بر دو جفت زبان، En-De و En-Ro ارزش می\u200cدهیم. ما دو نتیجه را کشیدیم: ۱) عملکرد پیش\u200cبینی طولانی در اصل با ویژه\u200cهای جفت زبانی مانند نمونه\u200cهای تطبیق، سفارش کلمات یا نسبت طولانی داخلی تأثیر می\u200cدهد، و همچنین با استفاده از داده\u200cهای متفرق دانش تأثیر می\u200cدهد. 2) یک ارتباط مثبت بین عملکرد پیش بینی طول و امتیاز BLEU وجود دارد.', 'tr': 'Uzunlyk önümlemesi NAT nusgalarynyň bir sanynda maksady uzlykyny generation öň karar etmelidir. Ýagna görä, uzalyk öňünden geçirmegiň we terjime kwaliteti barada täsiri ýakynlaşyp görünýär. Bu kagyzda, NAT-yň uzalyk öňünden geçirmek täsirini we netijesini täsirleýän faktorlary tapmak üçin we terjime kwaliteti bilen nähili baglanýandygyny maslahat berýäris. Biz şartly Maskeli Dil Modeline (CMLM) (Ghazvininejad et al., 2019), NAT nusgasyny çykar we muny iki dil çiftinde çykar. Biz iki çözüm çykarypdyk: 1) Uzluk öňünden geçirmek üçin adatça dil çiftiň häsiýetleri, söz düzümleri ýa-da daşky uzaklyk düzümleri bilen täsirleýär we bu şekilde tanyş edilen bilgilerin ullanyşyna täsirleýär. 2) Uzluk öňünden geçirmegiň we BLES notynyň netijesi arasynda pozitif bir ýagdaýy bar.', 'af': "Lengte voorskou is 'n spesiale taak in' n reeks van NAT modele waar doel lengte moet voor generasie bepaal word. Maar die prestasie van lengte voorskou en sy influens op vertaling kwaliteit is selfs bespreek. In hierdie papier, ons voorstel kompleksies analiserings oor lengte voorskou taak van NAT, die doel om die faktore te vind wat effektief effektief, en hoe dit verbind met vertaling kwaliteit. Ons uitvoer hoofsaaklik eksperimente gebaseer op die voorwaardes maskerde taal model (CMLM) (Ghazvininejad et al., 2019), â\x80\x99n reprezentante NAT model en evalueer dit op twee taal paar, En-De en En-Ro. Ons trek twee konklusies: 1) Die prestasie van lengte voorskou is heeltemal influens deur eienskappe van taal paar soos gelyking patroon, woord volgorde of binneste lengte verhouding, en is ook influens deur die gebruik van kennis verskillende data. 2) Daar is 'n positiewe korrelasie tussen die effektuur van die lengte voorskou en die BLEU-punt.", 'am': 'የረጅም ትንቢት ትልቅ ስራ ከትውልድ በፊት መቆጣጠር በሚገባበት በNAT ዓይነቶች ውስጥ የተለየ ሥርዓት ነው፡፡ ነገር ግን የርዝመት ትንቢት እና የትርጓሜ ጥሩ ላይ ጥቅም በማድረግ ላይ ግንኙነት በጥቂት ነገር ተጫውቷል፡፡ በዚህ ካላት፣ የNAT የረጅም ትንቢት ትርጉም እና ትርጓሜ ጥሩ እንዴት እንደሚያጋራው ውጤቶችን ለማግኘት እናደርጋለን፡፡ አብዛኛውም በሁኔታ የቋንቋ ቋንቋ ሞዴል (CMLM) (ጋazvininejad et al., 2019), የNAT ሞዴል እና በሁለት ቋንቋዎች ሁለት ዓይነቶች፣ ዓይን-ዲ እና En-Ro በተመሳሳይ እናደርጋለን፡፡ 1) የረጅም ውይይት የቋንቋ አካላት እንደምትለይ ምሳሌ፣ ቃላት ትርጉም ወይም ውስጥ ጥቅም፣ እና የተለየ የዳታ እውቀት በማጠቀም ይታሰራል፡፡ 2) የረጅም ትንቢት እና የቢሊዩን ደረጃ መካከል ግንኙነት አለ፡፡', 'hy': 'Երկարության կանխատեսումը հատուկ խնդիր է NAT-ի մոդելների մի շարքում, որտեղ նպատակի երկարությունը պետք է որոշվի նախքան սերունդը: Այնուամենայնիվ, երկարության կանխատեսման արդյունքները և դրա ազդեցությունը թարգմանման որակի վրա հազվադեպ են քննարկվել: Այս թղթի մեջ մենք ներկայացնում ենք ընդհանուր վերլուծություններ NAT-ի երկարության կանխատեսման խնդրի մասին, որոնք նպատակով են գտնել գործոնները, որոնք ազդում են արդյունքին, ինչպես նաև այն, թե ինչպես են դրանք կապված թարգմանման որակի հետ: Մենք հիմնականում կատարում ենք փորձարկումներ, որոնք հիմնված են պայմանավոր մաշկի լեզվի մոդելի վրա (ՔՄԼՄ) (Գազվինինեջադ և այլն., 2019 թ), NAT-ի ներկայացուցիչ մոդելի վրա, և գնահատում ենք այն երկու լեզվի զույգերի վրա, Էն-Դեի We draw two conclusions: 1) The performance of length prediction is mainly influenced by properties of language pairs such as alignment pattern, word order or intrinsic length ratio, and is also affected by the usage of knowledge distilled data.  2) There is a positive correlation between the performance of the length prediction and the BLEU score.', 'sq': 'Parashikimi i gjatësisë është një detyrë e veçantë në një seri modelesh NAT ku gjatësia objektiv duhet të përcaktohet përpara gjeneratës. Megjithatë, performanca e parashikimit të gjatësisë dhe ndikimi i saj në cilësinë e përkthimit janë diskutuar rrallë. Në këtë letër, ne paraqesim analiza tërësore mbi detyrën e parashikimit të gjatësisë të NAT, duke synuar të gjejmë faktorët që ndikojnë në performancë si dhe se si lidhet me cilësinë e përkthimit. Ne kryesisht kryejmë eksperimente bazuar në Modelin e Gjuhave me Maskë të Kushtueshme (CMLM) (Ghazvininejad et al., 2019), një model përfaqësues NAT dhe e vlerësojmë në dy çifte gjuhësh, En-De dhe En-Ro. Ne tërheqim dy përfundime: 1) Performanca e parashikimit të gjatësisë ndikohet kryesisht nga pronësitë e çifteve gjuhësh të tilla si modeli i përshtatjes, rendi i fjalëve apo raporti i gjatësisë së brendshme dhe ndikohet gjithashtu nga përdorimi i të dhënave të distilluara të njohurive. 2) Ka një korrelacion pozitiv midis performancës së parashikimit të gjatësisë dhe rezultatit BLEU.', 'az': "Uzun t…ôdbir n…ôsild…ôn …ôvv…ôl m√ľ…ôyy…ôn edilm…ôsi lazńĪm olan NAT modell…ôrinin bir serisind…ô x√ľsusi bir iŇüdir. Lakin uzunluńüun t…ôdbir v…ô t…ôdbir qiym…ôtin…ô t…ôsir edilm…ôsi az da m√ľbahis…ô edilmiŇüdir. Bu kańüńĪzda, NAT'nin uzunluńüu t…ôdbir t√∂r…ôtm…ôsi haqqńĪnda b√ľt√ľn analizi g√∂st…ôrdik, t…ôdbir etdiyi faktorlarńĪ tapmaq m…ôqs…ôdil…ô, h…ôm√ßinin terc√ľm…ô keyfiyy…ôti il…ô nec…ô bańülanmaq m…ôqs…ôdil…ô. Biz sad…ôc…ô olaraq Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), NAT modeli t…ôŇükil edirik v…ô onu iki dil √ßift, En-De v…ô En-Ro il…ô t…ôŇükil edirik. Biz iki n…ôz…ôr √ß…ôkirik: 1) Uzun t…ôdbir g√∂st…ôricisinin performansńĪ, h…ôm√ßinin dil √ßiftl…ôrinin √∂zellikl…ôrin…ô, s√∂z sńĪralasńĪ v…ô ya daxili uzunluńüu proporsiyasńĪ kimi t…ôsirl…ôndirilir v…ô h…ôm√ßinin bilikl…ôrin t…ôsirl…ôndirilmiŇü m…ôlumatlarńĪn istifad…ôsind…ô d…ô t…ôsirl…ôndirilir. 2) Uzun t…ôdbir v…ô BLEU n√∂qt…ôsi arasńĪnda pozitif bir bańülantńĪ var.", 'bn': 'দীর্ঘ ভবিষ্যৎবাণী ন্যাটি মডেলে একটি বিশেষ কাজ যেখানে প্রজন্মের আগে লক্ষ্যের দীর্ঘ নির্ধারণ করা উচিত। However, the performance of length prediction and its influence on translation quality has seldom been discussed.  In this paper, we present comprehensive analyses on length prediction task of NAT, aiming to find the factors that influence performance, as well as how it associates with translation quality.  প্রতিনিধি নাটি মডেলের প্রতিনিধি গাজ্ভিনিজাদ এল, ২০১৯ এর উপর ভিত্তিতে আমরা পরীক্ষা করি এবং দুই ভাষার জোড়া, এন-ডি এবং এন-Ro এর মূল্যায়ন করি। আমরা দুটি উপসংহার আঁকছি: ১) দীর্ঘ ভবিষ্যদ্বাণী প্রভাব প্রভাবিত হচ্ছে ভাষার জোড়ার বৈশিষ্ট্য, যেমন একত্রিত প্রতিনিধি, শব্দের আদেশ অথবা অভ্যন্তরীণ দীর্ঘদি ২) দীর্ঘ ভবিষ্যদ্বাণী এবং বিলু স্কোরের প্রদর্শনের মধ্যে ইতিবাচক সম্পর্ক রয়েছে।', 'cs': 'Předpověď délky je speciálním úkolem v řadě NAT modelů, kde je třeba určit cílovou délku před generací. Nicméně výkonnost predikce délky a její vliv na kvalitu překladu byl diskutován jen zřídka. V tomto článku předkládáme komplexní analýzy úlohy predikce délky NAT s cílem zjistit faktory, které ovlivňují výkon a jak se spojuje s kvalitou překladu. Především provádíme experimenty založené na podmíněném maskovaném jazykovém modelu (CMLM) (Ghazvininejad et al., 2019), reprezentativním NAT modelu, a hodnotíme jej na dvou jazykových párech, En-De a En-Ro. Vyvoláváme dva závěry: 1) Výkon predikce délky je ovlivněn především vlastnostmi jazykových párů, jako jsou zarovnávací vzor, pořadí slov nebo intrinský délkový poměr, a je ovlivněn také využitím znalostně destilovaných dat. 2) Existuje pozitivní korelace mezi výkonností predikce délky a skóre BLEU.', 'et': 'Pikkuse prognoosimine on eriline ülesanne NAT mudelite seerias, kus sihtpikkus tuleb kindlaks määrata enne tootmist. Kuid pikkuse ennustamise tulemuslikkust ja selle mõju tõlkekvaliteedile on harva arutatud. Käesolevas töös esitame põhjalikke analüüse NAT pikkuse prognoosimise ülesande kohta, eesmärgiga leida tegurid, mis mõjutavad jõudlust ja kuidas see seostub tõlkekvaliteediga. Peamiselt teostame eksperimente, mis põhinevad esinduslikul NAT mudelil (Conditional Masked Language Model, CMLM) (Ghazvininejad et al., 2019), ning hindame seda kahel keelepaaril, En-De ja En-Ro. Teeme kaks järeldust: 1) Pikkuse ennustamise tulemust mõjutavad peamiselt keelepaaride omadused nagu joondusmustr, sõnade järjestus või sisemine pikkuse suhe ning seda mõjutab ka teadmiste destilleeritud andmete kasutamine. 2) Pikkuse prognoosi tulemuslikkuse ja BLEU skoori vahel on positiivne korrelatsioon.', 'ca': "La predicció de la llargada és una tasca especial en una sèrie de models NAT on la llargada d'objectiu ha de ser determinada abans de generar. No obstant això, rarament s'ha discutit el rendiment de la predicció de la llargada i la seva influència en la qualitat de la traducció. In this paper, we present comprehensive analyses on length prediction task of NAT, aiming to find the factors that influence performance, as well as how it associates with translation quality.  Principalment fem experiments basats en el Model Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), un model representatiu del NAT, i l'evaluem en dos parells de llenguatges, En-De i En-Ro. Després treiem dues conclusions: 1) El rendiment de la predicció de la longitud està influenciat principalment per propietats de parells de llenguatges com el patró d'allinjament, l'ordre de paraules o la relació intrínseca de longitud, i també està afectat per l'ús de dades destilades del coneixement. 2) Hi ha una correlació positiva entre el rendiment de la predicció de la longitud i la puntuació BLEU.", 'fi': 'Pituusennuste on erityistehtävä NAT-mallisarjassa, jossa tavoitepituus on määritettävä ennen tuotantoa. Pituusennustuksen suorituskyvystä ja sen vaikutuksesta käännöksen laatuun on kuitenkin harvoin keskusteltu. Tässä työssä esitellään kattavat analyysit NAT:n pituuden ennustamistehtävästä, joiden tavoitteena on löytää suorituskykyyn vaikuttavat tekijät sekä miten se liittyy käännöksen laatuun. Teemme pääasiassa kokeita, jotka perustuvat edustavaan NAT-malliin (Conditional Masked Language Model, CMLM) (Ghazvininejad et al., 2019), ja arvioimme sitä kahdella kieliparilla, En-De ja En-Ro. Teemme kaksi johtopäätöstä: 1) Pituusennusteen suorituskykyyn vaikuttavat pääasiassa kieliparien ominaisuudet, kuten linjauskuvio, sanajärjestys tai luontainen pituussuhde, ja siihen vaikuttaa myös tiedon tislatun datan käyttö. 2) Pituusennusteen suorituskyvyn ja BLEU-pisteen välillä on positiivinen korrelaatio.', 'bs': 'Predviđanje dužine je poseban zadatak u nizu modela NAT-a gdje se mora odrediti dužina cilja prije generacije. Međutim, učinkovitost predviđanja dužine i njegovog utjecaja na kvalitet prevoda rijetko se raspravlja. U ovom papiru predstavljamo sveobuhvatne analize o zadatku predviđanja dužine NAT-a u cilju pronaći faktore koji utiču na učinkovitost, kao i kako se povezuje sa kvalitetom prevoda. Uglavnom izvodimo eksperimente na temelju uslovnog maskiranog jezika model a (CMLM) (Ghazvininejad et al., 2019), predstavnika NAT modela, i procjenjujemo ga na dva jezika paira, En-De i En-Ro. Napravili smo dva zaključaka: 1) Učinnost predviđanja dužine uglavnom utječe na vlasništvo jezičkih parova poput uzoraka, reda riječi ili odnosa dužine unutrašnje, te je utjecala i na uporabu znanja destiliranih podataka. 2) Postoji pozitivna korelacija između provedbe predviđanja dužine i rezultata BLEU-a.', 'jv': 'Duration politenessoffpolite"), and when there is a change ("assertive Nang pepul iki, kita mulai perusahaan akeh nyong nggawe geraksi luwih pawaran karo nggawe geraksi karo nggawe barang nggawe barang nggawe geraksi karo nggawe geraksi karo kaliwat itlanjut. Awak dhéwé éntuk dhéwé éntukno-éntukno sing basa tanggal Pasang Masked Language model (SMLM)(Ganaswin injad et al, 2011), nambah repréntasi NT model, lan jewèké nggawe masalah iki, en-de lan en-ro. 1) Cendelah 2) Kayané perusahaan resmi sing nggawe gerarané tarjamahan karo perusahaan nggambar nggawe', 'ha': "Furofin tsawo yana da wani aikin mai ƙayyade cikin wasu misãlai na NAT wanda za'a ƙayyade tsawo wa taga a gaba ga kizafi. A lokacin da aka yi wa rabon kunyar zaman gabanin da fassararsa a kan sifar fassarar. Daga wannan takardan, Munã zo da fassarar amfani da aikin bayani na tsawo na NAT, don a so zuwa a gane factori waɗanda ke yin amfani da fassarar, da kuma yadda ya yi haɗa da tsarin fassarar. Kana tafiyar jarrabãwa mainli a kan NaT-motsi biyu, A-du da en-Ro. Tuna fiɗe fassarar biyu: 1) Tafiyar da zaman shawarar da ke yi amfani da amfani da zane-danne da aka rarraba shi. 2) Kuna da wata mazauni mai kyau a tsakanin cikakken hisãbin tsawo da scorn BLEU.", 'sk': 'Napovedovanje dolžine je posebna naloga v seriji modelov NAT, kjer je treba ciljno dolžino določiti pred generacijo. Vendar pa o uspešnosti napovedovanja dolžine in njenem vplivu na kakovost prevoda redko razpravljamo. V prispevku predstavljamo celovite analize naloge napovedovanja dolžine NAT s ciljem ugotoviti dejavnike, ki vplivajo na uspešnost in kako se ta povezuje s kakovostjo prevoda. V glavnem izvajamo eksperimente, ki temeljijo na pogojnem maskiranem jezikovnem modelu (CMLM) (Ghazvininejad et al., 2019), reprezentativnem NAT modelu, in ga ocenjujemo na dveh jezikovnih parih, En-De in En-Ro. Na uspešnost napovedovanja dolžine vplivajo predvsem lastnosti jezikovnih parov, kot so vzorec poravnave, vrstni red besed ali notranje razmerje dolžine, vpliva pa tudi uporaba znanja destiliranih podatkov. 2) Obstaja pozitivna korelacija med uspešnostjo napovedi dolžine in rezultatom BLEU.', 'he': 'חיזוי אורך הוא משימה מיוחדת בסדרה של דוגמנים NAT שבו אורך המטרה צריך לקבוע לפני הדור. עם זאת, ביצועים של צפוי ארוך ושפעותו על איכות התרגום נדרשו לעיתים נדירות. בעיתון הזה, אנו מציגים ניתוחים מורכבים על משימת צפייה ארוכה של NAT, המטרה למצוא את הגורמים שמשפיעים על ביצועים, כמו גם איך זה מתחבר לאיכות התרגום. We mainly perform experiments based on Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), a representative NAT model, and evaluate it on two language pairs, En-De and En-Ro.  אנחנו מציירים שתי מסקנות: 1) ביצועים של צפוי אורך משפיעים בעיקר על ידי תכונות של זוגות שפות כמו דפוס התאמה, סדר מילים או יחסי אורך פנימי, וגם משפיעים על ידי השימוש של נתונים מיושבים. 2) יש קשר חיובי בין ביצועים של ציון האורך לבין נקודת BLEU.', 'bo': 'རིང་ཚད་མ་ཚད་ནི་NAT དཔེ་དབྱེ་རིགས་ཚོའི་ནང་དུ་དམིགས་བསལ་ཀྱི་བྱ་འགུལ་ཞིག་རེད། ཡིན་ནའང་། ཆེ་མཐོང་རིང་དང་ཁོང་ཚོའི་དབྱིབས་སྤྲོད་ཀྱི་རྒྱས་ཐག་འདི་ཡང་བསླབ་ཀྱང་མཐོང་མེད། འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་དུ་NAT ཡི་གྲངས་རིང་གི་རྒྱལ་ཁབ་ཀྱི་ལས་འཚོལ་བའི་དབྱེ་ཞིབ་ཡོད་པ་དང་། སྤྱད་ཡོད་ནི་གནས་ཚུལ་དཔག་འབྱེད་ཀྱི་ ང་ཚོས་Conditional Masked Language Model (CMLM)(Ghazvininejad et al., 2019) ལྟ་བུའི་བརྟག་འཛིན་པའི་སྐད་ཡིག་གཟུགས་བརྟན་དཔྱད་ཞིབ་བྱས་ནས་སྐད་རིགས་གཟུགས་གཉིས་ནང་ཞིབ་དཔྱད་བྱས་ན།  ང་ཚོས་རྗེས་འབྲས་གཉིས་དབྱེ་བ་བཟོ 1) གྲངས་རིང་གི་སྔོན་ཚུལ་གྱི་ངོ་བོའི་རྒྱུ་དངོས་དབྱེ་བ་དང་། ཆ་འཕྲིན་གྲངས་ཀ་དང་མཐའ་དབྱེ་བ་མཚུངས་པར་ངོ་བོའི་ཡི 2) མཐུན་རྐྱེན་ཚད་དང་རིམ་པ་གཉིས་ཀྱི་མཐུན་སྒྲིག་འདུག'}
{'en': 'On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning', 'pt': 'Sobre a especificidade do idioma do BERT multilíngue e o impacto do ajuste fino', 'es': 'Sobre la especificidad lingüística del BERT multilingüe y el impacto del ajuste', 'fr': "À propos de la spécificité linguistique du BERT multilingue et de l'impact du réglage fin", 'ar': 'حول خصوصية لغة BERT متعدد اللغات وتأثير الضبط الدقيق', 'ja': '多言語BERTの言語特異性と微調整の影響について', 'zh': '论多言BERT语特异性微调', 'hi': 'बहुभाषी BERT की भाषा-विशिष्टता और फाइन-ट्यूनिंग के प्रभाव पर', 'ru': 'О языковой специфике многоязычного BERT и влиянии тонкой настройки', 'ga': 'Ar Shainiúlacht Teanga BERT Ilteangach agus Tionchar an Mhínithe', 'ka': 'მრავალენგური BERT და სწორი კონფიგურაციის შესახებ', 'hu': 'A többnyelvű BERT nyelvi sajátosságairól és a finomhangolás hatásáról', 'el': 'Σχετικά με τη γλωσσική ιδιαιτερότητα του πολυγλωσσικού BERT και τον αντίκτυπο της τελειοποίησης', 'it': "Sulla specificità linguistica del BERT multilingue e sull'impatto della messa a punto", 'kk': 'Бірнеше тілді BERT және жақсы баптау нәтижесінде', 'mk': 'За јазичното специфичност на Мултијазичниот БЕРТ и влијанието на финетирањето', 'lt': 'Dėl daugiakalbės BERT kalbos specifiškumo ir patobulinimo poveikio', 'ml': 'On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning', 'ms': 'Pada spesifik bahasa BERT berbilang bahasa dan kesan penyesuaian', 'mn': 'БЕРТ хэлний хэлний тодорхойлолт болон сайн зохиолын нөлөө', 'mt': 'Dwar l-ispeċifiċità lingwistika tal-BERT Multilingwi u l-Impatt tal-Irfinar', 'no': 'På språk- spesifikasjonen av fleirspråk BERT og effekten av finnstillingar', 'ro': 'Cu privire la specificitatea lingvistică a BERT multilingv și impactul reglării fine', 'pl': 'O językowo-specyficzności wielojęzycznego BERT i wpływie dostosowania', 'sr': 'U vezi specifičnosti jezika višejezičkog BERT-a i utjecaja dobrog tuniranja', 'so': 'Qofka luqada ah ee BERT iyo saameynta hagitaanka', 'si': 'ගොඩක් භාෂාවික BERT සහ හුදු සංවිධානයේ භාෂාව-විශේෂතාව සඳහා', 'ta': 'பல மொழி பெர்டின் மொழியின் குறிப்பிட்ட மொழியில் மற்றும் நல்ல தூண்டுதலின் விளைவு', 'ur': 'Multilingual BERT اور Fine-tuning کا اثر', 'sv': 'Om språkspecificiteten hos flerspråkig BERT och effekterna av finjustering', 'uz': "Bir necha tillar BERT tilida va yaxshi tug'ilgan amallar haqida", 'vi': 'Về đặc trưng ngôn ngữ của hỗn hợp Berlin và tác động của việc tinh chỉnh...', 'nl': 'Over de taalspecificiteit van meertalig BERT en de impact van fine-tuning', 'da': 'Om sprogspecifikken ved flersproget BERT og virkningen af finjustering', 'bg': 'За езиковата специфика на многоезичния BERT и въздействието на фината настройка', 'id': 'Pada spesifik bahasa dari BERT Berbahasa Berbahasa dan Impak Penyesuaian', 'de': 'Zur Sprachspezifität von mehrsprachigem BERT und den Einfluss von Feinabstimmungen', 'hr': 'U vezi specifičnosti jezika višejezičkog BERT-a i utjecaja dobrog pjesma', 'tr': 'Çoklu diller BERT we Fine-tuning etkisi barada', 'ko': '다국어 언어의 언어 특이성과 미조의 영향을 논하다', 'af': 'Op die Taal-Spesifiekheid van Multilingual BERT en die Impact van Fine-tuning', 'sw': 'Katika lugha yenye utaalamu wa lugha mbalimbali BERT na madhara ya mafunzo mazuri', 'fa': 'بر اساس تعریف زبان بیشتر زبان BERT و اثر تنظیم نیکو', 'am': 'የቋንቋ-ቋንቋ-አካባቢ BERT እና የፊደል ጥያቄ', 'az': 'Multilingual BERT və Fine-tuning Impact on the Language-specificity of the Multilingual BERT and the Impact of Fine-tuning', 'sq': 'Për specificitetin gjuhësor të BERT shumëgjuhës dhe ndikimin e rregullimit të mirë', 'bs': 'U vezi specifičnosti jezika višejezičkog BERT-a i utjecaja dobrog pjesma', 'cs': 'O jazykové specificitě vícejazyčného BERT a vlivu jemného ladění', 'hy': 'Բազլեզու BER-ի լեզվի առանձնահատուկ հատկությունը և բարելավման ազդեցությունը', 'ca': "En l'especificitat lingüística del BERT multilingüe i l'impacte de l'ajustament", 'fi': 'Monikielisen BERT:n kielispesifisyydestä ja hienosäätöjen vaikutuksesta', 'et': 'Mitmekeelse BERT keelespetsiifilisuse ja peenhäälestuse mõju kohta', 'bn': 'মাল্টিভাষার ভাষার বেরেট এবং ভাষার প্রভাব', 'ha': 'KCharselect unicode block name', 'sk': 'O jezikovni specifičnosti večjezičnega BERT in vplivu finega uravnavanja', 'he': 'On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning', 'bo': 'སྐད་ཡིག་དམིགས་འཛུགས་ཀྱི་སྣ་ཚོགས་ཀྱི་BERT་དང་བྱ་ཚིག་གི་གནོད་འགྱུར་བ་དང་', 'jv': 'Nang langgambar-kanggo langgambar luwih saben BERT lan nggo langgambar barang Fine'}
{'en': 'Recent work has shown evidence that the knowledge acquired by multilingual BERT (mBERT) has two components : a language-specific and a language-neutral one. This paper analyses the relationship between them, in the context of fine-tuning on two tasks   POS tagging and natural language inference   which require the model to bring to bear different degrees of language-specific knowledge. Visualisations reveal that mBERT loses the ability to cluster representations by language after fine-tuning, a result that is supported by evidence from language identification experiments. However, further experiments on ‘unlearning’ language-specific representations using gradient reversal and iterative adversarial learning are shown not to add further improvement to the language-independent component over and above the effect of fine-tuning. The results presented here suggest that the process of fine-tuning causes a reorganisation of the model’s limited representational capacity, enhancing language-independent representations at the expense of language-specific ones.', 'ar': 'أظهر العمل الأخير دليلًا على أن المعرفة المكتسبة بواسطة BERT متعدد اللغات (mBERT) تتكون من عنصرين: مكون خاص بلغة محددة ومكون محايد للغة. تحلل هذه الورقة العلاقة بينهما ، في سياق الضبط الدقيق لمهمتين - علامات نقاط البيع واستدلال اللغة الطبيعية - والتي تتطلب أن يحمل النموذج درجات مختلفة من المعرفة الخاصة باللغة. تكشف التصورات أن mBERT تفقد القدرة على تجميع التمثيلات حسب اللغة بعد الضبط الدقيق ، وهي نتيجة مدعومة بأدلة من تجارب تحديد اللغة. ومع ذلك ، فإن التجارب الإضافية على التمثيلات اللغوية الخاصة بـ "إلغاء تعلم" باستخدام انعكاس التدرج والتعلم العدائي التكراري لا تضيف مزيدًا من التحسين إلى المكون المستقل عن اللغة بالإضافة إلى تأثير الضبط الدقيق. تشير النتائج المقدمة هنا إلى أن عملية الضبط الدقيق تؤدي إلى إعادة تنظيم القدرة التمثيلية المحدودة للنموذج ، وتعزيز التمثيلات المستقلة عن اللغة على حساب التمثيلات اللغوية المحددة.', 'pt': "Trabalhos recentes mostraram evidências de que o conhecimento adquirido pelo BERT multilíngue (mBERT) tem dois componentes: um específico ao idioma e um neutro ao idioma. Este artigo analisa a relação entre eles, no contexto do ajuste fino em duas tarefas – marcação POS e inferência de linguagem natural – que exigem que o modelo traga diferentes graus de conhecimento específico da linguagem. As visualizações revelam que o mBERT perde a capacidade de agrupar representações por idioma após o ajuste fino, resultado que é apoiado por evidências de experimentos de identificação de idioma. No entanto, outros experimentos em representações específicas de linguagem de 'desaprender' usando reversão de gradiente e aprendizado adversário iterativo não são mostrados para adicionar mais melhorias ao componente independente de linguagem além do efeito de ajuste fino. Os resultados aqui apresentados sugerem que o processo de ajuste fino provoca uma reorganização da limitada capacidade representacional do modelo, valorizando as representações independentes da linguagem em detrimento das específicas da linguagem.", 'es': 'Un trabajo reciente ha demostrado que el conocimiento adquirido por el BERT multilingüe (mBERT) tiene dos componentes: uno específico del idioma y otro neutral del idioma. Este artículo analiza la relación entre ellos, en el contexto del ajuste de dos tareas, el etiquetado de PDV y la inferencia del lenguaje natural, que requieren que el modelo aporte diferentes grados de conocimiento específico del idioma. Las visualizaciones revelan que MBert pierde la capacidad de agrupar las representaciones por idioma después de ajustarlas, un resultado que está respaldado por la evidencia de los experimentos de identificación del lenguaje. Sin embargo, se ha demostrado que otros experimentos sobre el «desaprendizaje» de representaciones específicas del idioma mediante la inversión de gradientes y el aprendizaje contradictorio iterativo no añaden mejoras adicionales al componente independiente del idioma más allá del efecto del ajuste fino. Los resultados presentados aquí sugieren que el proceso de ajuste fino provoca una reorganización de la capacidad representativa limitada del modelo, mejorando las representaciones independientes del idioma a expensas de las específicas del idioma.', 'fr': "Des travaux récents ont démontré que les connaissances acquises par le BERT multilingue (mBERT) ont deux composantes\xa0: une composante spécifique à la langue et une composante indépendante de la langue. Cet article analyse la relation entre eux, dans le contexte de l'affinement de deux tâches — le marquage POS et l'inférence du langage naturel — qui nécessitent que le modèle apporte différents degrés de connaissances spécifiques à la langue. Les visualisations révèlent que mBerT perd la capacité de regrouper les représentations par langue après un réglage précis, un résultat qui est corroboré par des preuves issues d'expériences d'identification de la langue. Toutefois, d'autres expériences sur le «\xa0désapprentissage\xa0» des représentations spécifiques à une langue utilisant l'inversion de gradient et l'apprentissage contradictoire itératif n'apportent pas d'amélioration supplémentaire à la composante indépendante de la langue au-delà de l'effet de réglage fin. Les résultats présentés ici suggèrent que le processus de réglage fin entraîne une réorganisation de la capacité de représentation limitée du modèle, améliorant les représentations indépendantes de la langue au détriment des représentations spécifiques à la langue.", 'zh': '近事明,多言BERT(mBERT)得二组成部分:特定言中性语。 本文析其之际,于两任(POS标自然语言推理)微调之背景,二者任其言语特定知。 可视化见,mBERT失言聚类能,得言实验证。 然用梯度反迭代抗学忘言特定示实验明,非微效之外,不关言语之组件也。 此言之的结果表明,微调之重组,牺牲特定言,以重言也。', 'hi': "हाल के काम ने सबूत दिखाया है कि बहुभाषी BERT (mBERT) द्वारा प्राप्त ज्ञान के दो घटक हैं: एक भाषा-विशिष्ट और एक भाषा-तटस्थ एक। यह पेपर उनके बीच के संबंधों का विश्लेषण करता है, दो कार्यों पर ठीक-ट्यूनिंग के संदर्भ में - पीओएस टैगिंग और प्राकृतिक भाषा अनुमान - जिसके लिए मॉडल को भाषा-विशिष्ट ज्ञान की विभिन्न डिग्री को सहन करने की आवश्यकता होती है। विज़ुअलाइज़ेशन से पता चलता है कि mBERT ठीक-ट्यूनिंग के बाद भाषा द्वारा प्रतिनिधित्व को क्लस्टर करने की क्षमता खो देता है, एक परिणाम जो भाषा पहचान प्रयोगों से साक्ष्य द्वारा समर्थित है। हालांकि, ग्रेडिएंट रिवर्सल और पुनरावर्ती प्रतिकूल सीखने का उपयोग करके 'अनलर्निंग' भाषा-विशिष्ट अभ्यावेदनों पर आगे के प्रयोगों को ठीक-ट्यूनिंग के प्रभाव के ऊपर और ऊपर भाषा-स्वतंत्र घटक में और सुधार नहीं जोड़ने के लिए दिखाया गया है। यहां प्रस्तुत परिणाम बताते हैं कि फाइन-ट्यूनिंग की प्रक्रिया मॉडल की सीमित प्रतिनिधित्व क्षमता के पुनर्गठन का कारण बनती है, जो भाषा-विशिष्ट लोगों की कीमत पर भाषा-स्वतंत्र प्रतिनिधित्व को बढ़ाती है।", 'ru': 'Недавняя работа показала доказательство того, что знания, полученные многоязычным BERT (mBERT), имеют два компонента: языково-специфичный и языково-нейтральный. В настоящем документе анализируется взаимосвязь между ними в контексте доработки двух задач – маркировки POS и вывода естественного языка, – которые требуют, чтобы модель использовала различные степени знания языка. Визуализация показывает, что mBERT теряет способность группировать представления по языку после тонкой настройки, результат, который подтверждается доказательствами из экспериментов по идентификации языка. Тем не менее, дальнейшие эксперименты по «отучиванию» языковых представлений с использованием градиентной реверсии и итеративного состязательного обучения, как показано, не добавляют дальнейшего улучшения к независимому от языка компоненту помимо эффекта тонкой настройки. Представленные здесь результаты свидетельствуют о том, что процесс доработки приводит к реорганизации ограниченной репрезентативной способности модели, усиливая языково-независимые представления за счет языковых.', 'ja': '最近の研究では、多言語BERT （ mBERT ）によって獲得された知識には、言語固有のものと言語中立のものの2つの要素があることが示されています。 この論文では、POSタグ付けと自然言語推論の2つのタスクの微調整の文脈で、言語固有の知識の異なる程度をモデルが持ち込む必要があるため、それらの間の関係を分析する。 視覚化は、mBERTが微調整後に言語別の表現をクラスター化する能力を失うことを明らかにし、この結果は言語識別実験の証拠によって裏付けられている。 しかしながら、勾配逆転および反復的対立学習を使用した言語固有の表現の「学習を解除する」さらなる実験は、微調整の効果を超えて言語に依存しないコンポーネントにさらなる改善を追加しないことが示されている。 ここで提示された結果は、微調整のプロセスがモデルの限定された表現能力の再編成を引き起こし、言語固有の表現を犠牲にして言語に依存しない表現を強化することを示唆している。', 'ga': "Tá fianaise léirithe ag obair le déanaí go bhfuil dhá chomhpháirt san eolas a fhaigheann BERT (mBERT) ilteangach: ceann a bhaineann go sonrach le teanga agus ceann atá neodrach ó thaobh teanga de. Déanann an páipéar seo anailís ar an ngaol atá eatarthu, i gcomhthéacs mionchoigeartú a dhéanamh ar dhá thasc – clibeáil POS agus tátal nádúrtha teanga – a éilíonn an tsamhail céimeanna éagsúla eolais a bhaineann go sonrach le teanga a úsáid. Léiríonn léirshamhlú go gcaillfidh MBERT an cumas léiriúcháin a chnuasach de réir teanga tar éis mionchoigeartaithe, toradh a fhaigheann tacaíocht ó fhianaise ó thurgnaimh aitheantais teanga. Mar sin féin, taispeántar nach gcuireann turgnaimh bhreise ar léirithe teanga-shonracha `gan fhoghlaim' ag baint úsáide as aisiompú grádáin agus foghlaim sháraíochta atriallach le tuilleadh feabhsuithe ar an gcomhpháirt teanga neamhspleách de bhreis ar éifeacht an mhionchoigeartaithe. Tugann na torthaí a chuirtear i láthair anseo le fios go bhfuil próiseas an mhionchoigeartaithe ina chúis le hatheagrú ar chumas teoranta ionadaíochta an mhúnla, ag cur le léirithe teanga-neamhspleách ar chostas na cinn a bhaineann go sonrach le teanga.", 'hu': 'A közelmúltbeli munkák bizonyítékot mutattak arra, hogy a többnyelvű BERT (mBERT) által megszerzett ismeretek két összetevőből állnak: egy nyelvspecifikus és egy nyelvsemleges. Ez a tanulmány a köztük lévő kapcsolatot elemzi, két feladat finomhangolásával összefüggésben, a POS címkézéssel és a természetes nyelvi következtetéssel kapcsolatban, amelyek megkövetelik, hogy a modell különböző fokú nyelvspecifikus ismereteket hozzon létre. A vizualizációk azt mutatják, hogy az mBERT a finomhangolás után elveszíti a nyelvi reprezentációk csoportosításának képességét, amit a nyelvazonosítási kísérletek bizonyítékai alátámasztanak. A nyelvspecifikus ábrázolások "elsajátítására" irányuló további kísérletek azonban kimutatták, hogy a gradiens fordításával és az iteratív ellentétes tanulással nem adnak további javítást a nyelvfüggetlen összetevőhöz a finomhangolás hatásán túl. Az itt bemutatott eredmények arra utalnak, hogy a finomhangolás folyamata a modell korlátozott reprezentációs kapacitásának átszervezését eredményezi, a nyelv-független reprezentációk növelését a nyelvspecifikus reprezentációk rovására.', 'el': 'Πρόσφατες εργασίες έδειξαν ότι η γνώση που αποκτάται από το πολύγλωσσο BERT (mBERT) αποτελείται από δύο συνιστώσες: μια ειδική γλώσσα και μια ουδέτερη γλώσσα. Η παρούσα εργασία αναλύει τη σχέση μεταξύ τους, στο πλαίσιο της λεπτομέρειας σε δύο εργασίες που απαιτούν το μοντέλο να φέρει διαφορετικούς βαθμούς γλωσσικής γνώσης. Οι απεικονίσεις αποκαλύπτουν ότι το mBERT χάνει την ικανότητα να ομαδοποιεί αναπαραστάσεις ανά γλώσσα μετά από την τελειοποίηση, αποτέλεσμα που υποστηρίζεται από στοιχεία από πειράματα αναγνώρισης γλωσσών. Ωστόσο, περαιτέρω πειράματα σχετικά με την "ξεμάθηση" γλωσσικών αναπαραστάσεων με τη χρήση αντιστροφής διαβάθμισης και επαναλαμβανόμενης αντικρουστικής μάθησης αποδεικνύονται ότι δεν προσθέτουν περαιτέρω βελτίωση στο γλωσσικό ανεξάρτητο στοιχείο πέρα από το αποτέλεσμα του λεπτού συντονισμού. Τα αποτελέσματα που παρουσιάζονται εδώ υποδηλώνουν ότι η διαδικασία της τελειοποίησης προκαλεί αναδιοργάνωση της περιορισμένης αντιπροσωπευτικής ικανότητας του μοντέλου, ενισχύοντας τις γλωσσικές ανεξάρτητες αναπαραστάσεις σε βάρος των γλωσσικών.', 'ka': "მიმდინარე სამუშაო სამუშაო მუშაო ბერტი (mBERT) იყო ორი კომპონენტები: ენის სპექტიფიკური და ენის ნეირრალური ერთი. ეს დოკუმენტი ანალიზებს მათ შორის შესახებ, ორი დავალების კონტექსტში - POS ჭდეს და ნაირადი ენის ინფრენცია - რომლებიც მოდელის შესახებ განსხვავებული ენის სპექტიფიკური ცოდლების განსხვავება ვიზუალიზაციები აღმოჩნენ, რომ mBERT დასრულებს სიტყვების გამოსახულებების შესაძლებლობა, რომელიც ენის იდენტიფიკაციის ექსპერიმენტების გამოსახულებელია. მაგრამ, დამატებული ექსპერიმენტები, რომლებიც `არაკითხვა' ენის განსაკუთრებულ რესპერიმენტებების გამოყენებაში, რომლებიც გამოიყენება გრადიენტური და ინტერატიური განსაკუთრებულ განსაკუთრებულ ამ შემდეგ გამოჩვენებული წარმოდგენების შესახებ, რომ კონფიგურაციის პროცესი მოდელის განსაზღვრებულ რედანგიზაციაციის შესაძლებლობა, მუშაობა ენის განსაზღვრებულ რედანგიზაციების განსაზღვრება", 'it': "Recenti lavori hanno dimostrato che le conoscenze acquisite dal BERT multilingue (mBERT) hanno due componenti: una specifica lingua e una neutrale dal punto di vista linguistico. Questo lavoro analizza il rapporto tra di loro, nel contesto di una messa a punto su due compiti - POS tagging e natural language inference - che richiedono che il modello porti a sopportare diversi gradi di conoscenza specifica del linguaggio. Le visualizzazioni rivelano che mBERT perde la capacità di raggruppare rappresentazioni per linguaggio dopo la messa a punto, un risultato che è supportato da prove provenienti da esperimenti di identificazione linguistica. Tuttavia, ulteriori esperimenti su rappresentazioni specifiche del linguaggio `disimparare' utilizzando l'inversione del gradiente e l'apprendimento avversario iterativo non aggiungono ulteriori miglioramenti alla componente indipendente dalla lingua oltre l'effetto della messa a punto. I risultati qui presentati suggeriscono che il processo di fine-tuning provoca una riorganizzazione della limitata capacità rappresentativa del modello, migliorando le rappresentazioni indipendenti dal linguaggio a scapito di quelle linguistiche specifiche.", 'lt': 'Neseniai atliktas darbas parodė, kad daugiakalbės BERT (mBERT) įgytos žinios turi dvi sudedamąsias dalis: kalbai skirtas ir kalbai neutralus. Šiame dokumente analizuojami tarpusavio santykiai, atsižvelgiant į dviejų užduočių - POS ženklinimo ir natūralios kalbos išvados - tikslinimą, pagal kurį modelis turi turėti skirtingų kalbos žinių laipsnių. Iš vizualizacijų matyti, kad mBERT praranda gebėjimą klastuoti atstovavimus pagal kalbą po tobulinimo, o tai patvirtina kalbos identifikavimo eksperimentų įrodymai. Tačiau įrodoma, kad tolesni eksperimentai, atliekami su konkrečiomis kalbomis susijusiomis reprezentacijomis, naudojant laipsnišką grįžtamąjį ir pakartotinį priešingą mokymąsi, papildomai nepagerina kalbos nepriklausomo komponento, o ne koregavimo poveikis. Iš čia pateiktų rezultatų matyti, kad patobulinimo procesas lemia riboto modelio atstovavimo pajėgumo reorganizavimą, didinant kalbų nepriklausomus atstovavimus konkrečiai kalbai skirtų atstovavimų s ąskaita.', 'ml': "അടുത്ത പ്രവര്\u200dത്തിക്കുന്നതില്\u200d പല ഭാഷ ബെര്\u200dട്ടി (mBERT) സമ്പാദിച്ച അറിവുകള്\u200d രണ്ടു ഭാഷ കൂട്ടങ്ങള്\u200d ഉണ്ടെന്ന് തെളിവുകള്\u200d കാണിച്ചിരി ഈ പത്രത്തില്\u200d അവയ്ക്കിടയിലുള്ള ബന്ധത്തെ പരിശോധിക്കുന്നു, രണ്ടു ജോലികളില്\u200d സുന്ദരിതമായിരിക്കുന്നു. പോസ് ടാഗിങ്ങും സ്വാഭാവികമായ ഭാഷയിലെ അ കാഴ്ചകള്\u200d വെളിപ്പെടുത്തിയിരിക്കുന്നു, ഭാഷയുടെ തിരിച്ചറിയാനുള്ള പരീക്ഷണങ്ങളില്\u200d നിന്ന് തെളിയിക്കുന്നതിനുശേഷം എ എന്നാലും ഗ്രേഡിയന്റ് റിസ്സലും വിരോധമായ വിദ്യാഭ്യാസത്തിനും ഉപയോഗിച്ച് 'അജ്ഞാനമില്ലാത്ത ഭാഷ' പ്രതിനിധികളുടെ കൂടുതല്\u200d പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നില ഇവിടെ കൊണ്ടുവരുന്ന ഫലങ്ങള്\u200d പരിഗണിക്കുന്ന പ്രക്രിയയെ മോഡലിന്റെ പരിധിയിലുള്ള പ്രതിനിധിയുടെ സ്വതന്ത്രമായ പ്രതിനിധികളുടെ സംഘടിപ്പിന് ഒരു", 'mt': 'Xogħol reċenti wera evidenza li l-għarfien miksub minn BERT multilingwi (mBERT) għandu żewġ komponenti: wieħed speċifiku għal-lingwa u wieħed newtrali għal-lingwa. Dan id-dokument janalizza r-relazzjoni bejniethom, fil-kuntest ta’ rfinar fuq żewġ kompiti - it-tikkettar tal-POS u l-inferenza tal-lingwa naturali - li jeħtieġu li l-mudell ikollu gradi differenti ta’ għarfien speċifiku għall-lingwa. Visualisations reveal that mBERT loses the ability to cluster representations by language after fine-tuning, a result that is supported by evidence from language identification experiments.  Madankollu, aktar esperimenti fuq rappreżentazzjonijiet speċifiċi għall-lingwa “mingħajr qligħ” bl-użu ta’ gradjent riversiv u tagħlim avversarju iterattiv jintwerew li ma jżidux aktar titjib lill-komponent indipendenti mil-lingwa minbarra l-effett ta’ rfinar. Ir-riżultati ppreżentati hawnhekk jissuġġerixxu li l-proċess ta’ rfinar jikkawża riorganizzazzjoni tal-kapaċità rappreżentattiva limitata tal-mudell, li ttejjeb ir-rappreżentazzjonijiet indipendenti mil-lingwa bi spejjeż ta’ dawk speċifiċi mil-lingwa.', 'mn': 'Саяхан ажил нь олон хэлний BERT (mBERT) хүмүүсийн мэдлэг хоёр компоненттэй гэдгийг харуулж байна: хэл тодорхойлолтой, хэл тогтвортой. Энэ цаас хоорондын харилцааны талаар нь хоёр даалгавар дээр тодорхойлсон байдлаар POS-ийн тэмдэглэл болон байгалийн хэл халдварыг шинжилдэг. Энэ загвар нь хэл тодорхойлсон мэдлэг дээр өөр хэлбэрийн түвшинд авч ирэх ша МБЕРТ хэл дээр илэрхийлэх боломжтой гэдгийг харуулж байна. Үүний үр дүнг хэлний идентификацийн туршилтаас дэмжигддэг. Гэхдээ хэл боловсруулагдахгүй хэлний төлөвлөгөөний шинжлэх ухааныг ашиглан градиентын эргүүлэлт болон эргүүлэлттэй эсрэг сургалтыг ашиглан илүү сайжруулах нь хэл боловсруулагдсан компонент дээр илүү сайжруулах боломжгүй харагдаж Энд үзүүлсэн үр дүнүүд нь загварын тодорхойлолтын үйл явц нь загварын хязгаарлагдсан загварын чадварыг дахин зохион байгуулах боломжтой болгодог.', 'kk': 'Жуырдағы жұмыс бірнеше тілді BERT (mBERT) бағдарламасының екі компоненті бар екенін көрсетеді: тілді ерекше және тілді нейтралды. Бұл қағаз олардың арасындағы қатынасын анализ, екі тапсырмаларды - POS тегтері және табиғи тілдерінің қатынасын - түрлі тілдердің білімдерінің түрлі градустарын өзгерту үшін үлгісін талдайды. Визуализациялары мBERT тілден кейін кластердің түсіндіру мүмкіндігін жоғалтып, тілді идентификациялау тәжірибесінен қолданылатын мәліметтердің нәтижесін көрсетеді. Бірақ «оқылмау» тілінің арнаулы мәліметтері градиенттің қарсы және қайтаратық қарсы оқыту көмегімен бірнеше тәжірибелері тілінен тәуелсіз компонентіне жақсы жақсарту үшін жұмыс істемейді. Мұнда келтірілген нәтижелер үлгісін баптау процесі үлгісінің шектелген мәліметті қайта органдауға болады, тілден тәуелсіз мәліметтерді тілдердің мәліметіне көтеру үшін.', 'ms': "Kerja baru-baru ini menunjukkan bukti bahawa pengetahuan yang diperoleh oleh BERT berbilang bahasa (mBERT) mempunyai dua komponen: bahasa-spesifik dan bahasa-neutral. Kertas ini menganalisis hubungan antara mereka, dalam konteks penyesuaian dua tugas - penanda POS dan kesimpulan bahasa alami - yang memerlukan model untuk membawa tahap yang berbeza pengetahuan bahasa-khusus. Visualisasi menunjukkan bahawa mBERT kehilangan kemampuan untuk kumpulkan perwakilan oleh bahasa selepas penyesuaian, hasil yang disokong oleh bukti dari eksperimen pengenalan bahasa. Namun, percubaan lanjut pada persembahan `tidak mendapatkan' bahasa-spesifik menggunakan pembalikan gradien dan pembelajaran lawan berulang-ulang dipaparkan tidak untuk menambah penambahan lanjut ke komponen bebas-bahasa di atas kesan penyesuaian. The results presented here suggest that the process of fine-tuning causes a reorganisation of the model's limited representational capacity, enhancing language-independent representations at the expense of language-specific ones.", 'mk': 'Неодамнешната работа покажа докази дека знаењето освоено од мултијазичниот БЕРТ (МБЕРТ) има два компоненти: јазик-специфичен и јазик-неутрален. Овој весник го анализира односот помеѓу нив, во контекст на финетизирање на две задачи - означување на POS и природна инференција на јазик - кои бараат моделот да носи различни степени на јазик-специфично знаење. Visualisations reveal that mBERT loses the ability to cluster representations by language after fine-tuning, a result that is supported by evidence from language identification experiments.  Сепак, се покажува дека понатамошните експерименти на специфичните претставувања за јазик со користење на градиентно свртување и итеративно непријателско учење не додаваат понатамошно подобрување на јазикот независниот компонент над ефектот на финетирање. Резултатите презентирани тука укажуваат на тоа дека процесот на финетизирање предизвикува реорганизација на ограничениот репрезентациски капацитет на моделот, зголемувајќи ги независните претставувања на јазикот на трошок на јазикот специфичните.', 'pl': 'Ostatnie prace wykazały, że wiedza nabyta przez wielojęzyczny BERT (mBERT) składa się z dwóch składników: specyficznego języka i neutralnego języka. Niniejszy artykuł analizuje związek między nimi w kontekście dostosowania dwóch zadań: tagowania POS i wnioskowania języka naturalnego, które wymagają, aby model uwzględnił różny stopień wiedzy specyficznej dla języka. Wizualizacje ujawniają, że mBERT traci zdolność do klastrowania reprezentacji według języka po dostrojeniu, co jest poparte dowodami z eksperymentów identyfikacji języka. Wykazano jednak, że dalsze eksperymenty dotyczące "oduczania" reprezentacji specyficznych dla języka przy użyciu odwracania gradientów i iteracyjnego uczenia się przeciwnego nie dodają dalszej poprawy komponentu niezależnego od języka poza efektem dostrajania. Przedstawione tutaj wyniki sugerują, że proces dostrajania powoduje reorganizację ograniczonej zdolności reprezentacyjnej modelu, zwiększając niezależne od języka reprezentacje kosztem tych specyficznych języków.', 'ro': 'Lucrările recente au demonstrat că cunoștințele dobândite de BERT multilingv (mBERT) au două componente: una specifică limbii și una neutră din punct de vedere lingvistic. Lucrarea analizează relaţia dintre acestea, în contextul perfecţionării a două sarcini - etichetarea POS şi inferenţa limbajului natural - care impun modelului să aducă diferite grade de cunoştinţe specifice limbajului. Vizualizările arată că mBERT pierde capacitatea de a grupa reprezentări după limbaj după ajustare fină, rezultat care este susținut de dovezi din experimentele de identificare a limbajului. Cu toate acestea, s-a demonstrat că experimentele suplimentare privind reprezentările specifice limbajului "dezînvățarea" utilizând inversarea gradientului și învățarea adversară iterativă nu adăugă îmbunătățiri suplimentare componentei independente de limbă în afara efectului reglării fine. Rezultatele prezentate aici sugerează că procesul de reglare fină determină o reorganizare a capacității reprezentative limitate a modelului, sporind reprezentările independente de limbă în detrimentul celor specifice limbii.', 'sr': 'Poslednji rad pokazuje dokaze da znanje koje je dobio multijezički BERT (mBERT) ima dve komponente: jezik specifični i jezik neutralni. Ovaj papir analizira odnos između njih, u kontekstu finalnog prilagođenja dva zadatka - označavanja POS-a i prirodne jezičke infekcije - koji zahteva model da donese različite stepenice znanja za jezik. Visualizacije otkrivaju da mBERT izgubi sposobnost skupljanja predstavljanja jezikom nakon finalnog prilagodbe, rezultat koji se podržava dokazima iz eksperimenata identifikacije jezika. Međutim, pokazuju se da daljnji eksperimenti na predstavljanju jezika određenih za neodređenje koristeći obrnuto i iterativno neprijateljsko učenje ne dodaju daljnje poboljšanje na jezički nezavisni komponent iznad i iznad efekta napravljenja. Rezultati predstavljeni ovdje ukazuju na to da proces finaliziranja uzrokuje reorganizaciju ograničenih predstavljajućih kapaciteta model a, povećanje nezavisnih predstavljanja jezika na troškove specifičnih jezika.', 'no': 'Nyleg har arbeidet vist bevis at kunnskapen henta av fleirspråk BERT (mBERT) har to komponentar: språk spesifisert og språk- neutralt. Denne papiret analyserer forholdet mellom dei, i konteksten av finnstilling på to oppgåver – POS- merking og naturspråk- infeksjon – som krev modellen for å få forskjellige grader av språk- spesifikke kunnskap. Visualiseringar viser at mBERT mistar kapasiteten til å klostera representasjonar etter språk etter finnstilling, eit resultat som er støtta av beviser frå språk identifiseringseksperimenter. Dette er imidlertid vist fleire eksperimenter på språk-spesifikke representasjonar med omvendt og gjentaktiv negativlæring for fargeovergangar ikkje å leggja til fleire forbetringar i språk-uavhengige komponenten over og over effekten av finnstilling. Resultatet som er presentert her foreslår at prosessen av finnstillingar fører til å reorganisera modellen sin begrenset representasjonskkapasitet, forbetra språk-uavhengige representasjonar på utkostnaden av språk-spesifiserte.', 'si': 'අලුත් වැඩේ පෙන්වන්න පුළුවන් සාක්ෂියක් තියෙනවා කියලා බොහොම භාෂාවක් BERT (mBERT) වලින් ගත්ත දන්නවට අවශ්\u200dය දෙක මේ පැත්තේ ඔවුන්ගේ අතර සම්බන්ධය විශ්ලේෂණය කරනවා, වෙනස් භාෂාවක් විශේෂ දන්නවට අනුවෙන් ප්\u200dරතිකාරයෙන් ප්\u200dරතිකාරයෙන් සම් වර්ශනය පෙන්වන්න පුළුවන් විදිහට mBERT විශ්වාස කරනවා කියලා භාෂාව පෙන්වන්න පුළුවන් නැති විදිහට පස්සේ භාෂාව ප නමුත්, ග්\u200dරේඩියන්ට වෙනස් සහ ප්\u200dරතික්\u200dරියාත්මක විශේෂ භාෂාවයේ තවත් පරීක්ෂණය ප්\u200dරතික්\u200dරියාත්මක විශේෂ කරනවා භාෂාව ස්වයංත්\u200d මෙතන පෙන්වන්න ප්\u200dරතිචාරයක් ප්\u200dරශ්නයක් තියෙනවා කියලා හොඳ සංවිධානයේ ප්\u200dරතිචාරයක් නිර්මාණය කරනවා මොඩේල්ගේ සීමාන්\u200dය ප්\u200dරත', 'so': "Shaqoda la soo dhowaaday waxay caddaysay caddeynta aqoonta lagu soo qaatay BERT (mBERT) waxay leedahay laba qeybood: af cayiman iyo af af-nøytral. This paper analyses the relationship between them, in the context of fine-tuning on two tasks - POS tagging and natural language inference - which require the model to bring to bear different degrees of language-specific knowledge.  Waxaa muuqata muuqashada in mBERT uu lumiyo awoodda uu ku kordhiyo aqoonta luuqada si fiican loo qoro kadib, taas darteed waxaa lagu kaalmeeyaa tusaale ahaan imtixaanka aqoonsiga luqada. Si kastaba ha ahaatee imtixaan dheeraad ah oo ku saabsan noocyada afka `aan aqoonin' oo lagu isticmaalo barashada rasmiga ah iyo waxbarashada rasmiga ah ee si aan loogu kordhin kordhin qeybta xornimada ah ee luqada oo ka sii kordhisan saamaynta wanaagga. Fashihiisa halkan lagu soo jeedo waxay ka muuqataa in baaritaanka hagitaanku uu dib u ururiyo awoodda noocyada ku xadgudbay, wuxuuna kordhin karaa wakiilada iskaa’aanta luuqada, kharashka ugu baxa afka cayiman.", 'sv': 'Nyligen genomförda arbeten har visat att den kunskap som förvärvats av flerspråkig BERT (mBERT) består av två komponenter: en språkspecifik och en språkneutral. Denna uppsats analyserar relationen mellan dem, i samband med finjustering av två uppgifter - POS-märkning och naturlig språkinferens - som kräver att modellen bär olika grader av språkspecifik kunskap. Visualiseringar visar att mBERT förlorar förmågan att klustra representationer efter språk efter finjustering, ett resultat som stöds av bevis från språkidentifiering experiment. Ytterligare experiment med att "lösa upp" språkspecifika representationer med hjälp av gradientomvändning och iterativt kontradiktoriskt lärande har dock visat sig inte tillföra ytterligare förbättringar till den språkoberoende komponenten utöver effekten av finjustering. Resultaten som presenteras här tyder på att finjusteringsprocessen leder till en omorganisering av modellens begränsade representationskapacitet, vilket ökar språkoberoende representationer på bekostnad av språkspecifika representationer.', 'ur': "اچھا کام دکھایا گیا ہے کہ بہت سی زبان BERT (mBERT) کے ذریعہ سے ملے ہوئے علم کے دو قسم ہیں: ایک زبان خاص ہے اور ایک زبان نائرٹی ہے۔ یہ کاغذ ان کے درمیان رابطہ کا تحقیق کرتا ہے، دو کاموں کے بارے میں اچھی تنظیم کرنا - POS ٹاگ اور طبیعی زبان کی تنظیم کرنا - جو مدل کی ضرورت ہے کہ ان کے درمیان مختلف دانش کے درجے لے آئیں۔ Visualisations reveal that mBERT loses the ability to cluster representations by language after fine-tuning, a result that is supported by evidence from language identification experiments. However, further experiments on 'unlearning' language-specific representations using gradient reversal and iterative adversarial learning are shown not to add further improvement to the language-independent component over and above the fine-tuning effect. یہاں پیش کیے ہوئے نتیجے اس سے پیش کیے جاتے ہیں کہ پاکیزہ تنظیم کی پروسس موڈل کی محدودہ نمایشگری قابلیت کی تغییر تنظیم کرتی ہے، زبان کے غیر مستقل نمایشگروں کو زبان کے مطابق زیادہ زیادہ بڑھاتی ہے.", 'ta': "சமீபத்தில் வேலை தெரியும் பல மொழி BERT (mBERT) பெறும் அறிவு இரண்டு பொருள்கள் உள்ளது: மொழி- குறிப்பிட்ட மொழி மற்றும் மொழி- நுட்பம்  இந்த தாள் இவ்விரண்டிற்கும் இடையேயுள்ள தொடர்பை ஆய்வு செய்கிறது, இரண்டு பணிகளின் மேல் நன்றாக ஒட்டும் போஸ் குறிப்பிடுதல் மற்றும் இயற்கையான ம பார்வைகள் தெரியும் MBERT மொழியின் குறிப்பிட்ட பின்னர் மொழியின் குறிப்பிடுக்கும் தோல்வியை இழக்கும், மொழி அடையாளம்  ஆனால் 'அறியாத' மொழி- குறிப்பிட்ட குறிப்பிட்ட குறிப்பிட்ட பரிசோதனைகள் கூடுதல் காட்டப்பட்டுள்ளது சரியான மாற்றம் மற்றும் உருவாக்கும் எதிர்மறை கல்விய முடிவுகள் இங்கு கொடுக்கப்பட்டுள்ளது சரியான பயிற்சியின் செயல்பாடு மாதிரியின் வரம்பு பங்கீட்டு சார்ந்த தன்மையை மீண்டும் ஒரு நிறுவனத்தை", 'uz': 'Yaqinda ishni ko\'pchilik tillar BERT (mBERT) tomonidan aniqlangan maʼlumot ikki komponent koʻrsatilgan hujjatlarni koʻrsatilgan: tillar uchun махсус va tillar uchun katta. Bu qogʻoz ularning orasidagi munosabatlarni aniqlaydi, ikkita vazifalar bilan yaxshi bir necha bogʻ\'liq holatda - POS teglash va tabiiy tilni ajratish kerak - bu modelni har xil darajada foydalanish kerak. Ko\'rinishi mumkin mBERT yaxshi suhbatdan keyin tilning tashkilotlarini birlashtirish qobiliyatini yoʻqoladi. Bu natijasi tilning identification imtiyozlaridan foydalanadi. Lekin "ilmogan" tillar uchun foydalanuvchi bo\'lgan foydalanuvchi darajadagi taʼminlovlar bilan gradient reversal va tashkilotlar o\'rganishni foydalanish uchun qoʻshimcha o\'zgarishni ko\'rsatish mumkin. Bu yerda koʻrsatilgan natijalar esa, yaxshi tug\'ilgan jarayonlar modelning chegara representatoriy qobiliyatiga qayta tashkilotga ega beradi, va tilning xossalarini qo\'shish uchun tillar bilan foydalanishini oshirish mumkin.', 'vi': "Những nghiên cứu gần đây đã chứng tỏ kiến kiến kiến thức được sở hữu bởi vang trắng, vũ trụ, vũ trụ, vũ trụ, vũ trụ, vũ trụ, vũ trụ, vũ trụ, vũ trụ. Tờ giấy này phân tích mối quan hệ giữa họ, trong trường hợp nghiên cứu cẩn thận hai việc định vị và ngụ ý ngôn ngữ tự nhiên, buộc phải mang theo trình độ hiểu biết ngôn ngữ khác nhau. Hình ảnh tiết lộ mBERT mất khả năng phân hủy các biểu tượng bằng ngôn ngữ sau khi đặt độ chín, kết quả được chứng cứ từ các thí nghiệm nhận diện ngôn ngữ. Tuy nhiên, thí nghiệm thêm về các biểu tượng'không thu nhập'ngôn ngữ cụ thể bằng cách đảo ngược dốc và lặp lại học cách đối nghịch không thể cải thiện thêm thành phần ngôn ngữ-độc lập hơn và vượt qua hiệu quả của độ nghiên cứu. Những kết quả được đưa ra ở đây cho thấy rằng quá trình độ cẩn thận đã làm thay đổi khả năng đại diện hạn chế của mô phỏng của mô-đun, tăng cường các biểu hiện ngôn ngữ-độc lập hơn.", 'bg': 'Последните изследвания показаха доказателства, че знанията, придобити от многоезичния BERT (mBERT), имат два компонента: специфичен за езика и неутрален за езика. Настоящата статия анализира връзката между тях в контекста на фината настройка на две задачи - маркиране на ПОС и извод на естествен език - които изискват моделът да понесе различни степени на езиково-специфични знания. Визуализациите разкриват, че след фина настройка губи способността да групира представяния по език, резултат, който се подкрепя от доказателства от експерименти за идентификация на езика. Въпреки това, по-нататъшните експерименти за "необучение" специфични за езика изображения, използващи градиентно обръщане и итеративно съперничество, показват, че не добавят по-нататъшно подобрение на независимия от езика компонент освен ефекта от фината настройка. Представените тук резултати предполагат, че процесът на фино настройване води до реорганизация на ограничения представителен капацитет на модела, засилвайки независимите от езика представи за сметка на специфичните за езика.', 'hr': 'Skorašnji rad pokazuje dokaze da znanje koje je dobio višejezički BERT (mBERT) ima dvije komponente: jezički specifični i jezički neutralni. Ovaj papir analizira odnos između njih u kontekstu finalnog prilagođenja dva zadatka - označavanja POS-a i infekcije prirodnog jezika - koji zahtijevaju modelu da donese različite stupnje znanja za jezik. Visualizacije otkrivaju da mBERT gubi sposobnost skupljanja predstavljanja jezikom nakon ispravne prilagodbe, rezultat koji se podržava dokazima iz eksperimenata identifikacije jezika. Međutim, pokazuju se da daljnji eksperimenti na predstavljanja specifičnih jezika „neočitavanja“ koristeći obrnuto i iterativno neprijateljsko učenje, ne dodaju daljnje poboljšanje na jezički nezavisni komponent iznad i iznad učinka isprave. Rezultati predstavljeni ovdje sugeriraju da proces finaliziranja uzrokuje reorganizaciju ograničenih predstavljačkih kapaciteta model a, poboljšanje nezavisnih predstavljanja jezika na troškove specifičnih jezika.', 'da': 'Det seneste arbejde har vist, at den viden, der erhverves af flersproget BERT (mBERT), består af to komponenter: en sprogspecifik og en sprogneutral. Denne artikel analyserer forholdet mellem dem i forbindelse med finjustering af to opgaver - POS tagging og natural language inference - som kræver, at modellen bærer forskellige grader af sprogspecifik viden. Visualiseringer afslører, at mBERT mister evnen til at klynge repræsentationer efter sprog efter finjustering, et resultat, der understøttes af beviser fra sprogidentifikation eksperimenter. Yderligere eksperimenter med "unlearn" sprogspecifikke repræsentationer ved hjælp af gradient reversering og iterativ adversiel læring vises imidlertid ikke at tilføje yderligere forbedringer til den sproguafhængige komponent ud over effekten af finjustering. Resultaterne tyder på, at finjusteringsprocessen medfører en omorganisering af modellens begrænsede repræsentationsevne og styrker sproguafhængige repræsentationer på bekostning af sprogspecifikke repræsentanter.', 'nl': "Recent onderzoek heeft aangetoond dat de door meertalig BERT (mBERT) verworven kennis uit twee componenten bestaat: een taalspecifieke en een taalneutrale. Dit artikel analyseert de relatie tussen hen, in de context van fine-tuning op twee taken pompos tagging en natuurlijke taal inference, waarbij het model verschillende graden van taalspecifieke kennis moet overbrengen. Visualisaties tonen aan dat mBERT de mogelijkheid verliest om representaties per taal te clusteren na finetuning, een resultaat dat wordt ondersteund door bewijs van taalidentificatieexperimenten. Echter, verdere experimenten met het 'verlernen' van taalspecifieke representaties met gradiëntenomkering en iteratief tegenstrijdig leren tonen geen verdere verbetering toe te voegen aan de taal-onafhankelijke component boven het effect van fine-tuning. De hier gepresenteerde resultaten suggereren dat het proces van finetuning een reorganisatie van de beperkte representatiecapaciteit van het model veroorzaakt, waardoor taalonafhankelijke representaties worden verbeterd ten koste van taalspecifieke representaties.", 'fa': 'کارهای اخیرا نشان داده است که علمی که توسط BERT multilingual (mBERT) دریافت شده دو بخش دارد: یک بخش خاص زبان و یک بخش ناتوان زبان است. این کاغذ رابطه بین آنها را تحلیل می\u200cکند، در موقعیت تنظیم کردن قطعی بر دو کار - نقاشی POS و تنظیم زبان طبیعی - که نیاز به مدل دارد تا درجه\u200cهای دانش مختلف زبان را تحمل کند. تصورات نشان می\u200cدهند که mBERT توانایی برای نمایش\u200cدهندگان کلاستری از زبان پس از تنظیم کردن، نتیجه\u200cای که توسط مدارک از آزمایشات شناسایی زبان پشتیبانی می\u200cشود، از دست می\u200cدهد. با این حال، آزمایش\u200cهای دیگر روی نمایش\u200cهای مخصوص زبان «غیر دریافت» با استفاده از یادگیری\u200cهای تغییر و تکرار مخالف، نشان داده می\u200cشود که به عنوان نمایش\u200cهای غیر مستقل زبان بیشتر و بیشتر از تاثیر تغییر\u200cسازی\u200cهای پا نتیجه\u200cهایی که در اینجا ارائه داده می\u200cشوند پیشنهاد می\u200cدهند که فرایند تنظیم\u200cکننده\u200cای باعث تغییر\u200cسازی توانایی محدودیت نمایش\u200cکننده\u200cی مدل است، افزایش نمایش\u200cهای مستقل به زبان بر هزینه\u200cهای متفاوت زبان است.', 'id': "Pekerjaan baru-baru ini menunjukkan bukti bahwa pengetahuan yang diperoleh oleh BERT berbeda bahasa (mBERT) memiliki dua komponen: bahasa-spesifik dan bahasa-neutral. Kertas ini menganalisis hubungan antara mereka, dalam konteks penyesuaian pada dua tugas - penanda POS dan kesimpulan bahasa alami - yang membutuhkan model untuk membawa tahap yang berbeda pengetahuan spesifik bahasa. Visualisasi menunjukkan bahwa mBERT kehilangan kemampuan untuk mengumpulkan representation oleh bahasa setelah penyesuaian, hasil yang didukung oleh bukti dari eksperimen identifikasi bahasa. However, further experiments on `unlearning' language-specific representations using gradient reversal and iterative adversarial learning are shown not to add further improvement to the language-independent component over and above the effect of fine-tuning.  Hasilnya di sini menunjukkan bahwa proses penyesuaian menyebabkan reorganisasi kapasitas representatif terbatas model, meningkatkan representation independen bahasa pada biaya bahasa-spesifik.", 'de': 'Jüngste Arbeiten haben gezeigt, dass das durch mehrsprachiges BERT (mBERT) erworbene Wissen aus zwei Komponenten besteht: einer sprachspezifischen und einer sprachneutralen. Der vorliegende Beitrag analysiert die Beziehung zwischen ihnen im Kontext der Feinabstimmung auf zwei Aufgaben wie POS Tagging und Natural Language Inference, bei denen das Modell unterschiedliche Grade an sprachspezifischem Wissen einbringen muss. Visualisierungen zeigen, dass mBERT nach der Feinabstimmung die Fähigkeit verliert, Repräsentationen nach Sprache zu gruppieren, was durch Beweise aus Sprachidentifikationsexperimenten belegt wird. Weitere Experimente zum "Verlernen" sprachspezifischer Repräsentationen durch Gradientenumsetzung und iteratives adversariales Lernen bringen jedoch keine weitere Verbesserung der sprachunabhängigen Komponente über den Effekt der Feinabstimmung hinaus. Die hier vorgestellten Ergebnisse deuten darauf hin, dass der Prozess der Feinabstimmung zu einer Reorganisation der begrenzten Repräsentationsfähigkeit des Modells führt und sprachunabhängige Repräsentationen auf Kosten sprachspezifischer Repräsentationen verbessert.', 'sw': "Kazi ya hivi karibuni imeonyesha ushahidi kuwa maarifa yaliyopata kutoka kwa lugha mbalimbali ya BERT (mBERT) ina vifaa viwili: lugha maalum na lugha moja kwa moja. This paper analyses the relationship between them, in the context of fine-tuning on two tasks - POS tagging and natural language inference - which require the model to bring to bear different degrees of language-specific knowledge.  Matokeo yanaonyesha kwamba mBERT imepoteza uwezo wa kuwadhibiti kwa lugha baada ya kutangaza vizuri, matokeo yanayoungwa mkono na ushahidi kutoka kwenye majaribio ya utambulisho wa lugha. Hata hivyo, majaribio mengine juu ya uwakilishi wa lugha 'wasiojua' kwa kutumia elimu ya mabadiliko na upinzani yanaonyesha kutokuongeza maendeleo zaidi katika sehemu ya lugha huru zaidi na zaidi ya athari ya kuboresha vizuri. Matokeo yaliyotolewa hapa yanapendekeza kwamba mchakato wa ufundi mzuri unasababisha kuunganisha upya uwezo mdogo wa uwakilishi wa modeli, kuongeza uwakilishi huru wa lugha kwa gharama za lugha maalum.", 'ko': "최근의 연구에 따르면 다언어 학습자(mBERT)가 얻은 지식은 두 가지 구성 부분이 있는데 그것이 바로 언어의 특정함과 언어의 중립성이다.본고는 어성 표기와 자연 언어 추리라는 두 가지 임무를 미세하게 조정하는 배경에서 그들 간의 관계를 분석했다. 이 두 가지 임무는 모델이 서로 다른 정도의 언어 특정 지식을 담도록 요구한다.가시화에 따르면 미세한 조정을 거친 후 mBERT는 언어에 따라 표징을 분류하는 능력을 잃었고 이 결과는 언어식별 실험 증거의 지지를 받았다.그러나 사다리꼴 반전과 교체 대항식 학습을 이용하여 진행된'망각'언어의 특정한 표징에 대한 진일보한 실험은 미세한 조정 효과 외에 언어의 독립 성분을 더욱 개선할 수 없다는 것을 나타냈다.본고가 제시한 결과에 의하면 미세한 조정 과정은 모델의 유한한 표징 능력을 재편성시키고 특정 언어의 표징을 희생하는 대가로 언어에 독립된 표징을 강화할 수 있다.", 'sq': "Recent work has shown evidence that the knowledge acquired by multilingual BERT (mBERT) has two components: a language-specific and a language-neutral one.  Ky dokument analizon marrëdhëniet midis tyre, në kontekstin e rregullimit të dy detyrave - etiketat POS dhe inferencën natyrore të gjuhës - që kërkojnë që modeli të sjellë grada të ndryshme të njohurive specifike gjuhës. Visualizimet tregojnë se mBERT humb aftësinë për të grupuar përfaqësimet nga gjuha pas rregullimit të hollësisë, një rezultat që mbështetet nga prova nga eksperimentet e identifikimit të gjuhës. Megjithatë, eksperimentet e mëtejshme mbi përfaqësimet specifike për gjuhën `pa fitim' duke përdorur kthesën gradiente dhe mësimin e përsëritur kundërshtar tregohen se nuk shtojnë përmirësim të mëtejshëm në komponentin e pavarur nga gjuha mbi efektin e rregullimit të hollësisë. Rezultatet e paraqitura këtu sugjerojnë se procesi i rregullimit shkakton një riorganizim të kapacitetit përfaqësues të kufizuar të modelit, duke përmirësuar përfaqësimet e pavarura nga gjuha në dëm të ato specifike gjuhësh.", 'am': 'የአሁኑ ሥራ በብዛት ቋንቋ BERT (mBERT) የተገኘው እውቀት ሁለት ክፍሎች እንዳላቸው ማስረጃ አሳየ፤ ቋንቋ-የተለየ እና ቋንቋ-nøytral አንዱ ነው። ይህ ገጽ በመካከላቸው ግንኙነትን ያሳያል፣ በሁለቱ ስራዎች ላይ ጥሩ ማቀናቀል፣ የፖএস ማተሚያ እና የፍጥረታዊ ቋንቋ ድምፅ ማውቀትን እና ሞዴል ልዩ ደረጃዎች ልዩ ቋንቋ-የተለየ እውቀትን ለመሸከም ያስፈልጋል፡፡ በቋንቋ ግንኙነት የመረጃ መክፈት የተረዳ መሆኑን ምBERT በቋንቋ አካባቢዎችን በመግለጥ መቻል እንዲያጠፋል፡፡ ነገር ግን የቋንቋ-ቋንቋ-አካባቢ መልዕክቶችን በመጠቀም እና በተቃዋሚው ትምህርት በተጨማሪነት ትምህርት ላይ ለቋንቋው-ነፃ ክፍል ላይ እና በጥሩ ማቀናቀፍ ላይ እንዲጨምሩ አይታየቁም፡፡ ወደዚህ የተደረገው ፍሬዎች የደኅንነት ማቀናቀል ፕሮጀክት በቋንቋ-በተለይም ቋንቋ-ፍቃድ በሚያሳድጉ ክፍተት የሞዴል ግንኙነት ግንኙነት አካባቢ እና የቋንቋ-ነፃነት መልዕክቶችን አበጅቷል፡፡', 'az': "Son işlər çoxlu dil BERT (mBERT) tarafından alınan bilgilərin iki komponenti olduğuna dair kanıtlar göstərdi: dil müəyyən və dil nötrəli bir dəlildir. Bu kağıt onların arasındakı ilişkisini analiz edir, iki işin müəyyən edilməsi haqqında - POS etiketi və təbiətli dil infeksiyonu - bu modeli dillərin müxtəlif dərəcələrinin elmi almasını istəyir. Görüntüləri göstərir ki, mBERT dil təşkil etdikdən sonra, dil təşkil təşkillərindən dəstəkləndirilən dəlillərdən dəstəkləndirilən bir nəticə olaraq, dil təşkil etdikdən sonra cluster təşkil etmək bacarılığını itirər. Lakin, səviyyənin geri dönüşünü və iterativ düşmənçilik öyrənməsini istifadə edən 'oxumaq' dilində müəyyən edilən təcrübələr barəsindəki başqa təcrübələr, dildən bağımsız komponentin üstündə və üstündə düzgün təcrübəsini artırmayacağını göstərilmişdir. Burada göstərilən sonuçlar təbliğ edir ki, modelinin s ınırlı göstəricisi qabiliyyətinin reorganizasyonu yaradır, dillərin müəyyən edilənlərin xərclənməsinə görə bağımsız tərzlərini artırar.", 'bn': 'সাম্প্রতিক কাজ প্রমাণ করেছে যে বহুভাষায় বিরেট (mBERT) অর্জন করা জ্ঞানের দ্বারা দুটি অংশ রয়েছে: একটি ভাষার নির্দিষ্ট এবং একটি ভাষার ন এই পত্রিকাটি তাদের মধ্যে সম্পর্ক বিশ্লেষণ করে, দুই কাজের উপর ভালোভাবে সুন্দর সংশ্লিষ্ট করার প্রাকৃতিক ভাষায় পোস ট্যাগিং এবং প্রাকৃতিক ভাষার দেখা যাচ্ছে যে এমবের্ট ভাষার প্রতিনিধিদের ভাষায় প্রতিনিধিত্বের ক্ষমতা হারিয়ে ফেলেছে ভাষার পরে ভাষার প্রতিনিধিত্বে তবে ‘অজ্ঞাত’ ভাষার নির্দিষ্ট প্রতিনিধিত্ব নিয়ে আরো পরীক্ষা দেখা যাচ্ছে গ্রেডিয়েন্ড বিরোধী শিক্ষা এবং ভাষার স্বাধীন সংক্রান্ত প্রভাবের উপরে আরো উন এখানে উপস্থিত ফলাফল প্রস্তাব করা হয়েছে যে ভাষার স্বাধীন প্রতিনিধিত্বের কারণে মডেলের সীমিত প্রতিনিধিত্বের ক্ষমতা পুনরায় সংগঠিত করা হয়েছে, ভাষার', 'af': "Onlangse werk het getoon getuienis dat die kennis wat deur multilinglike BERT (mBERT) aangeneem is, twee komponente het:  'n taal spesifieke en 'n taal-neutrale een. Hierdie papier analyseer die verhouding tussen hulle, in die konteks van fyn-tuning op twee taak - POS-merking en natuurlike taal-inferensie - wat die model nodig om verskillende grade van taal-spesifieke kennis te dra. Visualiserings vertoon dat mBERT die moontlikheid verloor om cluster voorstellings deur taal na fyn-tuning, 'n resultaat wat ondersteun word deur bevestige van taal-identifikasie eksperimente. Maar verdere eksperimente op 'onverwerking' taal-spesifieke voorstellings gebruik Gradiënt omgekeerde en iteratiewe teenstandaariale leer vertoon word nie om verdere verbetering te voeg by die taal-onafhanklike komponent oor en bo die effek van fyn-tuning nie. Die resultate wat hier voorgeskryf is, beveel dat die proses van fyn-tuning veroorsaak 'n reorganisasie van die model se beperkte representasionale kapasiteit, verbetering van taal-onafhanklike voorstellings op die koste van taal-spesifieke.", 'bs': "Skorašnji rad pokazuje dokaze da znanje koje je dobio multijezički BERT (mBERT) ima dvije komponente: jezički specifičan i jezički neutralan. Ovaj papir analizira odnos između njih u kontekstu finalnog prilagođenja dva zadatka - označavanja POS-a i infekcija prirodnog jezika - koji zahtijevaju modela da donese različite stepenice znanja za jezik. Visualizacije otkrivaju da mBERT gubi sposobnost skupljanja predstavljanja jezikom nakon ispravnog prilagođenja, rezultat koji se podržava dokazima iz eksperimenata identifikacije jezika. Međutim, pokazuju se da daljnji eksperimenti na predstavljanju jezika određenih za 'neočitanje' koristeći obrnuto i iterativno neprijateljsko učenje, ne dodaju daljnje poboljšanje na jezički nezavisni komponent iznad i iznad učinka fine-tuning. Rezultati predstavljeni ovdje sugeriraju da proces finaliziranja uzrokuje reorganizaciju ograničenih predstavljačkih kapaciteta model a, poboljšanje nezavisnih predstavljanja jezika na troškove specifičnih jezika.", 'cs': 'Nedávné práce ukázaly, že znalosti získané vícejazyčným BERT (mBERT) obsahují dvě složky: jazykovou a jazykovou neutrální. Tento článek analyzuje vztah mezi nimi v kontextu jemného ladění na dvou úlohách: POS tagging a přirozený jazyk inference, které vyžadují, aby model přinášel různé stupně jazykově specifických znalostí. Vizualizace ukazují, že mBERT ztrácí schopnost klastrovat reprezentace podle jazyka po jemném ladění, což je podpořeno důkazy z experimentů s identifikací jazyka. Bylo však ukázáno, že další experimenty na "vyučování" jazykově specifických reprezentací pomocí gradientového reverzu a iterativního adversariálního učení nepřidávají další zlepšení jazykově nezávislé komponenty nad efekt jemného ladění. Zde prezentované výsledky naznačují, že proces jemného ladění způsobuje reorganizaci omezené reprezentační schopnosti modelu a zvyšuje jazykově nezávislé reprezentace na úkor jazykově specifických reprezentací.', 'et': 'Hiljutised tööd on näidanud, et mitmekeelse BERTi (mBERT) omandatud teadmistel on kaks komponenti: keeleline ja keeleline neutraalne. Käesolevas töös analüüsitakse nendevahelisi seoseid kahe ülesande – POS märgistamise ja looduskeele järelduse kontekstis, mis nõuavad mudelilt erinevate keelespetsiifiliste teadmiste rakendamist. Visualiseerimine näitab, et mBERT kaotab pärast peenhäälestamist võime keele järgi esindusi klammerdada, mida toetavad tõendid keele identifitseerimise eksperimentidest. Siiski on näidatud, et täiendavad katsed keelespetsiifiliste representatsioonide "õppimata jätmisega", kasutades gradientide pöördumist ja iteratiivset vastandlikku õppimist, ei paranda keelest sõltumatut komponenti lisaks peenhäälestuse mõjule. Siin esitatud tulemused näitavad, et peenhäälestusprotsess põhjustab mudeli piiratud esindusvõime ümberkorraldamist, tugevdades keelest sõltumatuid esindusi keelespetsiifiliste esinduste arvelt.', 'fi': 'Viimeaikaiset tutkimukset ovat osoittaneet, että monikielisen BERT:n (mBERT) saamassa tietämyksessä on kaksi osatekijää: kielikohtainen ja kielineutraali. Tässä artikkelissa analysoidaan niiden välistä suhdetta kahden tehtävän hienosäätön yhteydessä - POS-taggingin ja luonnollisen kielen päättelyn - yhteydessä, jotka edellyttävät mallia tuomaan käyttöön erilaisia kielispesifisiä tietoja. Visualisaatiot paljastavat, että mBERT menettää kyvyn klusteroida esityksiä kielen mukaan hienosäädön jälkeen, mikä on tulosta, jota tukevat kielitunnistuskokeista saadut todisteet. Lisäkokeet kielispesifisistä representaatioista, joissa käytetään gradientin kääntöä ja iteratiivista vastakkainasettelua, eivät kuitenkaan osoita parantavan kielestä riippumatonta komponenttia hienosäädön vaikutuksen lisäksi. Tässä esitetyt tulokset viittaavat siihen, että hienosäätöprosessi aiheuttaa mallin rajallisen edustuskyvyn uudelleenorganisoinnin, mikä parantaa kieliriippumattomia edustustoja kielikohtaisten esitysten kustannuksella.', 'tr': "Ýakyndaky işiň birnäçe dilli BERT (mBERT) tarapyndan alan bilim(bilim) iki komponenti bar: dil takykly we neutral bir dildir. Bu kagyz olaryň arasyndaky baglaýyşyny iki işiň üstünde düzeltmek üçin çözülýär - POS etiketlemesi we tebigy dilleriň azalyşygyny - bu nusga dilleriň beýleki derejesini çözmek üçin gerekli. Görnömler görkezilişinden soň mBERT dilden soň cluster suratlarynyň ukypyny ýitirýändigini görkeýär. Bu netijede dil tanyşdyrma deneylerinden tarapyndan arkalanýar. Ýöne, `okamadyk' dilinden takyk suratlary ýüzünde görä tertiblenen we iteraty teňkil öwrenmek üçin ýene-de dili boýunça komponentä gowurak goşmak üçin görkezilmez. Bu ýerde görkezilen netijeler ýakynlama prosesiniň nusgasyna daşary edilen meýdança ukyplaryny täzeden düzenlemegini maslahat berýär.", 'ca': 'La feina recent ha demostrat que el coneixement adquirit per BERT multilingüe (mBERT) té dos components: una llengua específica i una llengua neutral. This paper analyses the relationship between them, in the context of fine-tuning on two tasks - POS tagging and natural language inference - which require the model to bring to bear different degrees of language-specific knowledge.  Les visualitzacions revelen que mBERT perd l\'habilitat de agrupar representacions per llenguatge després d\'ajustar-se, un resultat que està sostenit per proves d\'experiments d\'identificació de llenguatge. No obstant això, s\'ha demostrat que més experiments en representacions específices de llenguatge "sense guanyar" utilitzant l\'aprenentatge adversari invertit gradient i iteratiu no afegeixen més millor al component independent del llenguatge més enllà de l\'efecte de l\'ajustament. The results presented here suggest that the process of fine-tuning causes a reorganisation of the model\'s limited representational capacity, enhancing language-independent representations at the expense of language-specific ones.', 'hy': "Recent work has shown evidence that the knowledge acquired by multilingual BERT (mBERT) has two components: a language-specific and a language-neutral one.  Այս աշխատանքը վերլուծում է նրանց միջև եղած հարաբերությունները երկու խնդիրների՝ POS-ի նշանների և բնական լեզվի հետևանքների համատեքստում, որոնք պահանջում են, որ մոդելը կրի լեզվի մասնավոր գիտելիքների տարբեր մակարդակներ: Վիզուալիզացիաները բացահայտում են, որ mBER-ը կորցնում է լեզվի ընդհանուր ներկայացումների կազմակերպման ունակությունը բարձրացման հետո, արդյունքը, որը հիմնված է լեզվի հայտնաբերման փորձարկումների ապացույցներով: Այնուամենայնիվ, պարզվում է, որ լեզվի կոնկրետ ներկայացումների առավելագույն փորձարկումները, որոնք օգտագործում են դասավոր հակադարձ և կրկնվող հակառակորդ ուսումնասիրություն, չեն ավելացնում լեզվի անկախ բաղադրամի զարգացումը բարելավման արդյունք The results presented here suggest that the process of fine-tuning causes a reorganisation of the model's limited representational capacity, enhancing language-independent representations at the expense of language-specific ones.", 'ha': "A yanzu aikin da aka nuna bayan nuna cewa sanin da aka gano na BERT (mBERT) na da ƙanshi biyu: wata harshe-ƙayyade da wata lugha-na'ura. Wannan littafi yanã anayyar da mazaunin tsakaninsu, cikin muhimman mai kyau-tunkuɗe wa aikin biyu - yin tagon na PS da wata sabon harshe na natura - wanda na buƙata misalin ya kamata a sami da zane-zane daban-daban. Kunna-zane sun bayyana cẽwa mBERT yana tapar da abincin ya samu masu tsari da harshen bayan tuning, saboda da za'a ƙarfafa da shaida daga jarrabar shaidar lugha. A lokacin da, za'a nuna wasu jarrabo na masu tsari na `na sani' cikin harshen da aka yi amfani da shiryarwa mai motsi da kuma masu motsi da littafin da kuma ba za'a ƙara wani ƙari wa gyãra zuwa ƙananan-da-bane-harshen kodi da kuma kan mai amfani da tunkuɗawa. The results presented here suggest that the process of fine-tuning causes a reorganisation of the model's limited representational capacity, enhancing language-independent representations at the expense of language-specific ones.", 'sk': "Nedavno delo je pokazalo, da znanje, pridobljeno z večjezičnim BERT (mBERT), vsebuje dve komponenti: jezikovno specifično in jezikovno nevtralno. V prispevku analiziramo razmerje med njima v kontekstu finega uravnavanja dveh nalog - označevanja POS in sklepanja naravnega jezika -, ki zahtevata, da model uporabi različne stopnje znanja, specifičnega za jezik. Vizualizacije kažejo, da mBERT po finem nastavitvi izgubi sposobnost združevanja predstavitev po jeziku, kar je rezultat, ki ga podpirajo dokazi iz poskusov identifikacije jezika. Vendar pa so dokazali, da nadaljnji eksperimenti o `neučenju' jezikovno specifičnih reprezentacijah z uporabo preobračanja gradientov in iterativnega kontrastnega učenja ne dodajajo nadaljnjih izboljšav jezikovno neodvisne komponente poleg učinka finega nastavitve. Predstavljeni rezultati kažejo, da proces finega uravnavanja povzroča reorganizacijo omejene reprezentativne zmogljivosti modela, kar krepi jezikovno neodvisne reprezentacije na račun jezikovno specifičnih reprezentacij.", 'he': 'Recent work has shown evidence that the knowledge acquired by multilingual BERT (mBERT) has two components: a language-specific and a language-neutral one.  הנייר הזה מנתח את מערכת היחסים ביניהם, בתוך הקשר של התרגיל על שתי משימות - תווית POS ומסקנה שפה טבעית - שדורשת את המודל כדי להביא דרגות שונות של ידע ספציפי לשפה. ויזואליזציות מראות כי mBERT מאבד את היכולת לקבוע מייצגים על ידי שפה לאחר התאים, תוצאה שמתמכה על ידי ראיות מניסוי זיהוי שפה. בכל אופן, ניסויים נוספים על מייצגים ספציפיים לשפה "לא מרוויחים" בשימוש ההפך המדריך והלימוד הריבי האיטרטיבי התוצאות הנמצאות כאן מצביעות שהתהליך של התאימון גורם לאורגנון מחדש של היכולת המגובלת של המודל, משפר את היציגות עצמאות לשפה על חשבון אלה ספציפיים לשפה.', 'jv': 'Ibanjuré wong liya nggarapakan winih kanggo ngerasakno karo akeh sabanjuré karo BERT (mBERT) sing sampeyan duwé: nggo langa-nesaturan lan langa-nesaturan sampeyan. Perintah sing dipoleh akeh resmi gar dhéwé, ning sakjane sampek duluran kanggo langgar sampek bino - BOS tagging lan ngêngé kesempatan kanggo langgar - sing nyatakake model kanggo ngelakon modèl kanggo ngerasakno akeh langgar. Visual politenessoffpolite"), and when there is a change ("assertive Ngomongé awak dhéwé nglanggar sapa-sapa bener tentang nggawe nguasai perusahaan winih sing bakal terus nggawe nguasai kapaan ingkang dipunangé, njaluké awak dhéwé kuwi tindak dipunangé awak dhéwé.', 'bo': 'འཕྲལ་གསོག་ལས་ཀྱི་སྒྲ་ཚིགས་མང་ཙམ་ལ་བྱུང་བའི་ཤེས་ཡིག་ཆ་ནི་BERT (mBERT)ནང་དུ་ཆ་ཤས་གཉིས་ཡོད་པ་ལྟ་བུ་ཡིན། སྐད་ཡིག་དམིགས་བ ཤོག་བྱང་འདིས་ཁོང་ཚོའི་བར་དུ་འབྲེལ་བ་ཞིབ་བྱེད་པ་ལས་བྱ་རིམ་གཉིས་ཀྱི་ནང་དུ་གཏོང་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད། མཐོང་སྣང་མངོན་འཆར་བྱེད་ན། mBERT་ནི་སྐད་ཡིག ཡིན་ནའང་། གྲུབ་འབྲས་འདིར་སྟོན་ཡོད་པའི་སྐྱེས་བ་དག་གི་ལས་སྦྱོར་གཙང་ཆུང་ལ་རྐྱེན་ཚད་གཞི་སྒྲིག་ཀྱི་རྩ་འབྲེལ་བ་དང་། སྐད་ཡིག་གནས་ཚུལ་གསལ་བཤད་ཀྱི་རྩ་བ'}
{'en': 'Variation and generality in encoding of syntactic anomaly information in sentence embeddings', 'ar': 'الاختلاف والتعميم في ترميز معلومات الشذوذ النحوي في حفلات الزفاف بالجملة', 'es': 'Variación y generalidad en la codificación de la información de anomalías sintácticas en la incrustación de oraciones', 'fr': "Variation et généralité dans le codage des informations d'anomalies syntaxiques dans les incorporations de phrases", 'pt': 'Variação e generalidade na codificação de informações de anomalias sintáticas em embeddings de sentenças', 'zh': '句嵌中句法异常信息编码变化普遍性', 'ja': '文の埋め込みにおける構文異常情報の符号化のバリエーションと一般性', 'ru': 'Изменение и обобщение в кодировании информации синтаксической аномалии во вложениях предложений', 'hi': 'वाक्य एम्बेडिंग में वाक्यात्मक विसंगति जानकारी के एन्कोडिंग में भिन्नता और व्यापकता', 'ga': 'Éagsúlacht agus ginearáltacht in ionchódú faisnéise aimhrialtacht chomhréire i neadú abairtí', 'ka': 'სინტაქტიური ანომალიის ინფორმაციის კოდირებაში გარეშე და გენერალურობა', 'el': 'Μεταβολή και γενικότητα στην κωδικοποίηση των πληροφοριών συντακτικής ανωμαλίας σε ενσωμάτωση προτάσεων', 'it': 'Variazione e generalità nella codifica delle informazioni sulle anomalie sintattiche nelle incorporazioni di frasi', 'hu': 'A szintaktikus anomália információk kódolásának variációja és általánossága mondatbágyazásokban', 'lt': 'Sintaksinės anomalijos informacijos kodavimo variantas ir bendrumas įterpiant sakinius', 'mk': 'Варијација и генералност во кодирањето на информациите за синтактичка аномалија во вклучувањата на речениците', 'ms': 'Variasi dan keseluruhan dalam pengekodan maklumat anomali sintaktik dalam penyelesaian kalimat', 'kk': 'Синтактикалық аномалиялық мәліметтің кодтамасы мен жалпы түрлендіру', 'mn': 'Хэрэглэгчдийн шинжлэх ухааны кодлогын өөрчлөлт болон ерөнхийлөгч', 'ml': 'വാക്കുകള്\u200d അകത്തേക്കുള്ള വിവരങ്ങളില്\u200d സിനിട്ടാക്റ്റിക്ക് അന്യായമായ വിവരങ്ങള്\u200d കോഡിങ്ങില്\u200d മാറ്റങ', 'mt': 'Varjazzjoni u ġeneralità fl-ikkodifikar ta’ informazzjoni ta’ anomalija sintattika fl-inkorporazzjonijiet tas-sentenzi', 'ro': 'Variația și generalitatea în codificarea informațiilor de anomalie sintactică în încorporarea frazelor', 'no': 'Variasjon og generelt i koding av syntaksisk anomalisk informasjon i setningar', 'pl': 'Zmiany i ogÃ³lnoÅ›Ä‡ kodowania informacji o anomaliach skÅ‚adni w osadzeniach zdaÅ„', 'si': 'වාක්ය සම්පූර්ණතාවය සහ සාමාන්\u200dය සංකේතික අනමාන්\u200dය තොරතුරු සංකේතනය', 'sr': 'Varijacija i generalnost u kodiranju sintaktičkih anomalijskih informacija u rečenicama', 'so': 'Isbedelin iyo general ka kooban macluumaadka caasinimada ee xafiiska', 'sv': 'Variation och generalitet i kodning av syntaktisk avvikelseinformation i meningsinbäddningar', 'ta': 'வாக்கியத்தில் உள்ளிடப்பட்டுள்ள குறியீட்டின் மாறி மற்றும் பொதுவாக்கம்', 'ur': 'ویرایش اور عمومی سینٹکسیٹ نامالی معلومات کے اکنوڈینگ میں تغییر', 'vi': 'Sự biến đổi và tổng hợp trong việc mã hóa thông tin dị thường cấu tạo từ điển', 'uz': 'Name', 'nl': 'Variatie en algemeenheid in codering van syntactische anomalie informatie in zinsinsluitingen', 'bg': 'Вариация и обобщение в кодирането на синтактична аномалия информация в вграждането на изречения', 'da': 'Variation og generalitet i kodning af syntaktiske anomaliinformationer i sætningsindlejringer', 'hr': 'Varijacija i generalnost u kodiranju sintaktičkih anomalijskih informacija u ugrađenju rečenica', 'id': 'Variasi dan umumnya dalam pengekodan informasi anomali sintaktik dalam penyampaian kalimat', 'de': 'Variation und Allgemeingültigkeit bei der Kodierung syntaktischer Anomalieninformationen in Satzbedingungen', 'ko': '문장 삽입 중 문법 이상 정보 인코딩의 변이와 공통성', 'fa': 'تغییرات و عمومی در رمزبندی اطلاعات نامالی سنتاکتیک در جمله\u200cهای جمله', 'sw': 'Mabadiliko na umuhimu katika kuongezea taarifa za uongofu wa ushirikiano katika hukumu', 'tr': 'Sentaktik anomali maglumatyň kodlemesinde üýtgeşim we umumy', 'sq': 'Variimi dhe gjeneraliteti në kodimin e informacionit të anomalisë sintaktike në përfshirjet e fjalëve', 'af': 'Verandering en generaliteit in enkodering van sintaktieke anomalies inligting in sentence inbettings', 'am': 'ክፍል', 'hy': 'Սինտակտիկ անոմալիայի տեղեկատվության կոդավորման տարբերությունը և ընդհանուրությունը նախադասությունների ներդրման մեջ', 'bn': 'বাক্যের বিভিন্ন সংক্রান্ত সংক্রান্ত সংক্রান্ত তথ্য এনকোড করার পরিবর্তন এবং সাধারণ', 'az': 'Sintaktik anomali m…ôlumatƒ±nƒ±n kodlamasƒ±nda d…ôyi≈üiklik v…ô generallƒ±q', 'ca': "Variació i generalitat en codificar la informació sinàctica d'anomalies en incorporacions de frases", 'et': 'Süntaktilise anomaalia teabe kodeerimise variatsioon ja üldine kodeerimine lausete manustamisel', 'bs': 'Varijacija i generalnost u kodiranju sintaktičkih anomalijskih informacija u ugrađenju rečenica', 'cs': 'Variace a obecnost v kódování syntaktických anomálií v vložení vět', 'fi': 'Lausekkeen upotuksessa olevien syntaktisten anomaliatietojen koodauksen vaihtelu ja yleisyys', 'jv': 'AllProgressBar', 'ha': '@ action', 'sk': 'Variacija in splošnost pri kodiranju sintaktičnih anomalij informacij v vdelavah stavkov', 'he': 'Variation and generality in encoding of syntactic anomaly information in sentence embeddings', 'bo': 'ཚིག་སྒྲ་ནང་དུ་དབྱེ་བ་དང་མུང་བའི་གསལ་བཤད་ཀྱི་སྔོན་སྒྲིག་འགོད་དང་སྤྱིར་བཏང་བ'}
{'en': 'While sentence anomalies have been applied periodically for testing in NLP, we have yet to establish a picture of the precise status of anomaly information in representations from NLP models. In this paper we aim to fill two primary gaps, focusing on the domain of syntactic anomalies. First, we explore fine-grained differences in anomaly encoding by designing probing tasks that vary the hierarchical level at which anomalies occur in a sentence. Second, we test not only models’ ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types. Results suggest that all models encode some information supporting anomaly detection, but detection performance varies between anomalies, and only representations from more re- cent transformer models show signs of generalized knowledge of anomalies. Follow-up analyses support the notion that these models pick up on a legitimate, general notion of sentence oddity, while coarser-grained word position information is likely also a contributor to the observed anomaly detection.', 'ar': 'بينما تم تطبيق تشوهات الجمل بشكل دوري للاختبار في البرمجة اللغوية العصبية (NLP) ، إلا أننا لم نقم بعد بتكوين صورة للحالة الدقيقة لمعلومات الشذوذ في التمثيلات من نماذج البرمجة اللغوية العصبية. نهدف في هذه الورقة إلى سد فجوتين أساسيتين ، مع التركيز على مجال الانحرافات النحوية. أولاً ، نستكشف الفروق الدقيقة في ترميز الحالات الشاذة من خلال تصميم مهام التحقيق التي تغير المستوى الهرمي الذي تحدث فيه الحالات الشاذة في الجملة. ثانيًا ، لا نختبر فقط قدرة النماذج على اكتشاف شذوذ معين ، ولكن أيضًا نختبر عمومية إشارة الشذوذ المكتشفة ، من خلال فحص النقل بين أنواع الشذوذ المتميزة. تشير النتائج إلى أن جميع النماذج تشفر بعض المعلومات التي تدعم اكتشاف الشذوذ ، لكن أداء الاكتشاف يختلف بين الحالات الشاذة ، وفقط التمثيلات المأخوذة من نماذج المحولات الأكثر حداثة هي التي تظهر علامات على المعرفة المعممة بالحالات الشاذة. تدعم تحليلات المتابعة الفكرة القائلة بأن هذه النماذج تلتقط فكرة عامة شرعية عن غرابة الجملة ، بينما من المحتمل أن تكون معلومات موضع الكلمات ذات الحبيبات الخشنة أيضًا مساهمًا في اكتشاف الشذوذ الملحوظ.', 'fr': "Alors que les anomalies de phrases ont été appliquées périodiquement pour les tests en PNL, nous n'avons pas encore établi une image précise de l'état précis des informations sur les anomalies dans les représentations des modèles de PNL. Dans cet article, nous visons à combler deux lacunes principales, en nous concentrant sur le domaine des anomalies syntaxiques. Tout d'abord, nous explorons les différences fines dans le codage des anomalies en concevant des tâches de sondage qui font varier le niveau hiérarchique auquel les anomalies se produisent dans une phrase. Ensuite, nous testons non seulement la capacité des modèles à détecter une anomalie donnée, mais également la généralité du signal d'anomalie détecté, en examinant le transfert entre des types d'anomalies distincts. Les résultats suggèrent que tous les modèles codent certaines informations appuyant la détection des anomalies, mais les performances de détection varient d'une anomalie à l'autre, et seules les représentations de modèles de transformateurs plus récents montrent des signes de connaissance généralisée des anomalies. Les analyses de suivi appuient l'idée que ces modèles reprennent une notion légitime et générale de bizarrerie de phrase, tandis que des informations plus grossières sur la position des mots contribuent probablement également à la détection des anomalies observées.", 'es': 'Si bien las anomalías de las oraciones se han aplicado periódicamente para las pruebas en PNL, todavía tenemos que establecer una imagen del estado preciso de la información de anomalías en las representaciones de los modelos de PNL. En este artículo pretendemos llenar dos vacíos principales, centrándonos en el dominio de las anomalías sintácticas. Primero, exploramos las diferencias detalladas en la codificación de anomalías mediante el diseño de tareas de sondeo que varían el nivel jerárquico en el que se producen anomalías en una oración. En segundo lugar, probamos no solo la capacidad de los modelos para detectar una anomalía determinada, sino también la generalidad de la señal de anomalía detectada, mediante el examen de la transferencia entre distintos tipos de anomalías. Los resultados sugieren que todos los modelos codifican cierta información que respalda la detección de anomalías, pero el rendimiento de la detección varía entre las anomalías, y solo las representaciones de modelos de transformadores más recientes muestran signos de conocimiento generalizado de las anomalías. Los análisis de seguimiento apoyan la noción de que estos modelos recogen una noción legítima y general de rareza de la oración, mientras que la información de posición de palabras más gruesa probablemente también contribuya a la detección de anomalías observadas.', 'pt': 'Embora anomalias de sentença tenham sido aplicadas periodicamente para testes em PNL, ainda temos que estabelecer uma imagem do status preciso das informações de anomalia em representações de modelos de PNL. Neste artigo pretendemos preencher duas lacunas primárias, focando no domínio das anomalias sintáticas. Primeiro, exploramos diferenças refinadas na codificação de anomalias projetando tarefas de sondagem que variam o nível hierárquico em que as anomalias ocorrem em uma sentença. Em segundo lugar, testamos não apenas a capacidade dos modelos de detectar uma determinada anomalia, mas também a generalidade do sinal de anomalia detectada, examinando a transferência entre tipos distintos de anomalias. Os resultados sugerem que todos os modelos codificam algumas informações que suportam a detecção de anomalias, mas o desempenho da detecção varia entre as anomalias, e apenas representações de modelos de transformadores mais recentes mostram sinais de conhecimento generalizado de anomalias. Análises de acompanhamento suportam a noção de que esses modelos pegam uma noção legítima e geral de estranheza de sentença, enquanto informações de posição de palavra de granulação mais grosseira provavelmente também contribuem para a detecção de anomalia observada.', 'ja': '文の異常は、NLPでの試験のために定期的に適用されているが、NLPモデルからの表現における異常情報の正確な状態の画像を確立するまでには至っていない。 この論文では、構文異常の領域に焦点を当てて、2つの主要なギャップを埋めることを目指しています。 まず、文章内で異常が発生する階層レベルを変化させるプロービングタスクを設計することにより、異常符号化における微細な差異を探る。 第二に、モデルが特定の異常を検出する能力だけでなく、検出された異常信号の一般性を、異なる異常タイプ間の転送を調べることによってテストします。 結果は、すべてのモデルが異常検出をサポートするいくつかの情報をエンコードしていることを示唆していますが、検出性能は異常間で異なり、より多くの変圧器モデルからの表現のみが異常の一般的な知識の兆候を示しています。 フォローアップ分析は、これらのモデルが文の奇妙さの正当な一般的な概念を拾うという概念を支持している一方で、粗い粒度の単語の位置情報は、観察された異常検出の貢献者でもある可能性が高い。', 'hi': 'जबकि एनएलपी में परीक्षण के लिए वाक्य विसंगतियों को समय-समय पर लागू किया गया है, हमने अभी तक एनएलपी मॉडल से अभ्यावेदन में विसंगति जानकारी की सटीक स्थिति की तस्वीर स्थापित नहीं की है। इस पेपर में हम दो प्राथमिक अंतराल को भरने का लक्ष्य रखते हैं, वाक्यात्मक विसंगतियों के डोमेन पर ध्यान केंद्रित करते हैं। सबसे पहले, हम जांच कार्यों को डिजाइन करके विसंगति एन्कोडिंग में ठीक-ठाक अंतर का पता लगाते हैं जो पदानुक्रमित स्तर पर भिन्न होते हैं जिस पर एक वाक्य में विसंगतियां होती हैं। दूसरा, हम न केवल किसी दिए गए विसंगति का पता लगाने के लिए मॉडल की क्षमता का परीक्षण करते हैं, बल्कि अलग-अलग विसंगति प्रकारों के बीच हस्तांतरण की जांच करके पता लगाए गए विसंगति संकेत की व्यापकता का भी परीक्षण करते हैं। परिणाम बताते हैं कि सभी मॉडल विसंगति का पता लगाने का समर्थन करने वाली कुछ जानकारी को एन्कोड करते हैं, लेकिन पता लगाने का प्रदर्शन विसंगतियों के बीच भिन्न होता है, और केवल अधिक पुन: प्रतिशत ट्रांसफार्मर मॉडल से प्रतिनिधित्व विसंगतियों के सामान्यीकृत ज्ञान के संकेत दिखाते हैं। अनुवर्ती विश्लेषण इस धारणा का समर्थन करते हैं कि ये मॉडल वाक्य विषमता की एक वैध, सामान्य धारणा पर उठाते हैं, जबकि मोटे-दाने वाले शब्द की स्थिति की जानकारी भी देखी गई विसंगति का पता लगाने के लिए एक योगदानकर्ता है।', 'zh': '虽句异常已试于NLP,而未立NLP形中信息之精图片。 在本文中,填补两主空白,重点关注句法异域。 先探事以探异编码细粒度异,则变句之层次结构级矣。 其次,我们不惟测试模样检测给定异常的能力,还因检点异常的转移来测测到异常的信号的普遍性。 结果表明诸模皆编码异信,然检性因异而异,唯多自多 re-cent 变压器示出对遍知之迹。 续此一说,即拾句奇数之法,大概而粗粒度单词位信,亦或观其检测之一端也。', 'ru': 'Хотя аномалии предложений периодически применялись для тестирования в NLP, нам еще предстоит создать картину точного статуса информации об аномалиях в представлениях от моделей NLP. В этой статье мы стремимся заполнить два первичных пробела, сосредоточив внимание на области синтаксических аномалий. Во-первых, мы исследуем мелкозернистые различия в кодировании аномалий, разрабатывая задачи зондирования, которые варьируют иерархический уровень, на котором возникают аномалии в предложении. Во-вторых, мы проверяем не только способность моделей обнаруживать данную аномалию, но и общность обнаруженного сигнала аномалии, изучая передачу между различными типами аномалий. Результаты показывают, что все модели кодируют некоторую информацию, поддерживающую обнаружение аномалий, но производительность обнаружения варьируется в зависимости от аномалий, и только представления от более рецензируемых моделей трансформаторов показывают признаки обобщенного знания аномалий. Последующие анализы поддерживают представление о том, что эти модели воспринимают законное, общее понятие странности предложения, в то время как более грубая информация о положении слов, вероятно, также способствует обнаружению наблюдаемых аномалий.', 'ga': 'Cé gur cuireadh aimhrialtachtaí pianbhreithe i bhfeidhm go tréimhsiúil le haghaidh tástála in NLP, níl pictiúr faighte againn go fóill de stádas beacht na faisnéise aimhrialtacht i léiriúcháin ó mhúnlaí NLP. Sa pháipéar seo tá sé mar aidhm againn dhá phríomhbhearna a líonadh, ag díriú ar réimse na n-aimhrialtachtaí comhréire. Ar dtús, déanaimid iniúchadh ar dhifríochtaí míne in ionchódú aimhrialtacht trí thascanna fiosrúcháin a dhearadh a athraíonn an leibhéal ordlathach ag a dtarlaíonn aimhrialtachtaí in abairt. Ar an dara dul síos, déanaimid tástáil ní hamháin ar chumas na múnlaí aimhrialtacht ar leith a bhrath, ach freisin ar ghinearáltacht chomhartha na haimhrialtachta braite, trí scrúdú a dhéanamh ar aistriú idir cineálacha aimhrialtachta ar leith. Tugann na torthaí le tuiscint go n-ionchódaíonn na samhlacha go léir roinnt faisnéise a thacaíonn le haimhrialtachtaí a bhrath, ach athraíonn feidhmíocht braite idir aimhrialtachtaí, agus ní léiríonn ach léirithe ó mhúnlaí claochladán níos déanaí comharthaí eolais ghinearálaithe ar aimhrialtachtaí. Tacaíonn anailísí leantacha leis an nóisean go mbaineann na samhlacha seo le coincheap dlisteanach ginearálta na habairte aisteacha, agus is dócha go gcuirfidh faisnéis ar shuíomh na bhfocal níos garbh leis an mbrath aimhrialtacht a breathnaíodh.', 'ka': 'თუმცა ანომალიები პერიოდულად გამოყენებულია NLP-ში ტესტისთვის, ჩვენ არ უნდა დავიყენოთ ანომალიური ინფორმაციის წესი სტატისტატისტატისტატისტატისტაციებში. ამ დომენტში ჩვენ მივიღებთ ორი პირველ განსხვავებას, რომელიც სინტაქტიკური ანომალიების დიომინზე დავყენებთ. პირველად, ჩვენ განსხვავებთ ანომალიური კოდირებაში განსხვავებული განსხვავებები, რომელიც განსხვავებულია იერაქტიკური დონე, რომელიც ანომალიები ხდება სიტყვაში. მეორე, ჩვენ არა მხოლოდ მოდელების შესაძლებლობა განახლებელი ანომალიის განახლება, მაგრამ განახლებელი ანომალიის სიგნალის გენერალურობა, განახლებელი ანომალიის ტიპების განსხვავებით შევცვალო წარმოდგენები იტყვებენ, რომ ყველა მოდელები ცოტა ინფორმაციას, რომელიც ანომალიური განახლებაზე მხოლოდ განახლება ანომალიების შორის განსხვავებულია, და მხოლოდ უფრო მეტი რესენტის ტრანფორმაციის მო შემდეგ ანალიზები დაეხმარებენ წარმოდგენისთვის, რომ ეს მოდელები წარმოდგენენა წარმოდგენისთვის, ყველაფერი წარმოდგენისთვის განსხვავებული სიტყვის სიტყვის პოციაციის ინფორმაცია, როგორც შემდეგ შე', 'hu': 'Miközben időszakosan alkalmazták a mondatok anomáliáit NLP-ben történő tesztelésre, még nem állapítottunk meg képet az anomáliák pontos állapotáról NLP modellekben. Jelen tanulmányban két elsődleges hiányt kívánunk kitölteni, fókuszálva a szintaktikus anomáliák területére. Először is feltárjuk a finomszemcsés különbségeket az anomália kódolásában olyan mérési feladatok kidolgozásával, amelyek változtatják a hierarchikus szintet, ahol az anomáliák jelentkeznek egy mondatban. Másodszor, nem csak a modellek azon képességét vizsgáljuk, hogy észleljük egy adott anomáliát, hanem az észlelt anomália jel általánosságát is, különböző anomália típusok közötti transzfert vizsgálva. Az eredmények azt sugallják, hogy minden modell kódol bizonyos információkat, amelyek támogatják az anomáliák felismerését, de a detektálási teljesítmény eltérő az anomáliák között, és csak az újabb transzformátormodellek reprezentációi mutatják az anomáliák általános ismeretének jeleit. A nyomon követési elemzések alátámasztják azt az elképzelést, hogy ezek a modellek a mondatok furcsaságának legitim, általános fogalmát veszik fel, míg a durva szemű szópozíciós információk valószínűleg hozzájárulnak a megfigyelt anomália felismeréséhez.', 'el': 'Ενώ οι ανωμαλίες των προτάσεων έχουν εφαρμοστεί περιοδικά για δοκιμές στο ΝΛΠ, δεν έχουμε ακόμη δημιουργήσει μια εικόνα της ακριβούς κατάστασης των πληροφοριών ανωμαλίας σε αναπαραστάσεις από μοντέλα ΝΛΠ. Στην παρούσα εργασία επιδιώκουμε να καλύψουμε δύο βασικά κενά, εστιάζοντας στο πεδίο των συντακτικών ανωμαλιών. Πρώτον, διερευνούμε λεπτόκοκκες διαφορές στην κωδικοποίηση ανωμαλιών σχεδιάζοντας εργασίες ανίχνευσης που ποικίλουν το ιεραρχικό επίπεδο στο οποίο εμφανίζονται ανωμαλίες σε μια πρόταση. Δεύτερον, εξετάζουμε όχι μόνο την ικανότητα των μοντέλων να ανιχνεύουν μια δεδομένη ανωμαλία, αλλά και τη γενικότητα του ανιχνευμένου σήματος ανωμαλίας, εξετάζοντας τη μεταφορά μεταξύ διαφορετικών τύπων ανωμαλίας. Τα αποτελέσματα δείχνουν ότι όλα τα μοντέλα κωδικοποιούν ορισμένες πληροφορίες που υποστηρίζουν την ανίχνευση ανωμαλιών, αλλά η απόδοση ανίχνευσης ποικίλει μεταξύ ανωμαλιών, και μόνο οι αναπαραστάσεις από περισσότερα μοντέλα μετασχηματιστών δείχνουν σημάδια γενικευμένης γνώσης των ανωμαλιών. Οι αναλύσεις παρακολούθησης υποστηρίζουν την ιδέα ότι αυτά τα μοντέλα υιοθετούν μια νόμιμη, γενική έννοια της παράξενης πρότασης, ενώ οι πιο χονδροειδείς πληροφορίες θέσης λέξεων πιθανώς συμβάλλουν επίσης στην παρατήρηση ανωμαλίας.', 'kk': 'Сөздердің аномалиялары NLP үлгілерінде тексеру үшін кезеңдегі уақытта қолданылды, біз әлі NLP үлгілерінде аномалиялық мәліметтердің дұрыс күйін құру керек. Бұл қағазда біз синтактикалық аномалиялардың доменіне көздеген екі негізгі бос орындарды толтыруға мақсатымыз. Біріншіден, біз аномалиялық кодтамасының айырмашылығын зерттеп, аномалиялық деңгейінде өзгертілген иерархиялық тапсырмаларды дизайнерлеп іздейміз. Екіншіден, біз тек келтірілген аномалиясын анықтау үлгілерінің мүмкіндігін тексереміз, сондай-ақ анықталған аномалиялық сигналының жалпы түрлері арасындағы аударуын тексереміз. Нәтижелер барлық үлгілер anomaliялық анықтау үшін бірнеше мәліметті кодтау деп ойлайды, бірақ анықтау әрекеттері аномалиялардың арасында айырылады, және тек қанша реттік түрлендіру үлгілерінен тек аномалиялық біл Қолдану анализациялары бұл үлгілер дұрыс, жалпы мәліметті таңдау үшін жалпы, жалпы мәліметті таңдау үшін қолданылады. Бұл үлгілер мәліметті таңдау аномалиясының көмегіші болуы мүмкі', 'mk': 'Иако аномалиите на речениците се применети периодично за тестирање во НЛП, сé уште не мораме да воспоставиме слика на прецизниот статус на информациите за аномалии во претставувањата од моделите на НЛП. Во оваа хартија имаме за цел да ги пополниме двете примарни празнини, фокусирајќи се на доменот на синтактичките аномалии. Прво, ги истражуваме фините разлики во кодирањето на аномалијата со дизајнирање на истражувачки задачи кои го разликуваат хиерархичното ниво на кое се случуваат аномалии во реченица. Второ, ја тестираме не само способноста на моделите да детектираат одредена аномалија, туку и генералноста на детектираниот сигнал на аномалија, со испитување на трансферот помеѓу различни типови на аномалија. Results suggest that all models encode some information supporting anomaly detection, but detection performance varies between anomalies, and only representations from more re- cent transformer models show signs of generalized knowledge of anomalies.  Анализите за следење го поддржуваат мислењето дека овие модели го прифаќаат легитимното, генерално мислење за чудност на речениците, додека информациите за позицијата на зборовите со поголема грубост најверојатно и придонесуваат за набљудуваната аномалија.', 'it': "Mentre le anomalie di frase sono state applicate periodicamente per i test in NLP, dobbiamo ancora stabilire un quadro dello stato preciso delle informazioni di anomalia nelle rappresentazioni da modelli NLP. In questo articolo puntiamo a colmare due lacune primarie, concentrandoci sul dominio delle anomalie sintattiche. In primo luogo, esploriamo differenze a grana fine nella codifica anomalia progettando attività di sonding che variano il livello gerarchico a cui si verificano anomalie in una frase. In secondo luogo, testiamo non solo la capacità dei modelli di rilevare una determinata anomalia, ma anche la generalità del segnale di anomalia rilevato, esaminando il trasferimento tra diversi tipi di anomalia. I risultati suggeriscono che tutti i modelli codificano alcune informazioni che supportano il rilevamento di anomalie, ma le prestazioni di rilevamento variano tra le anomalie e solo le rappresentazioni di modelli di trasformatori più recenti mostrano segni di conoscenza generalizzata delle anomalie. Le analisi di follow-up sostengono l'idea che questi modelli riprendano una nozione legittima e generale di stranezza della frase, mentre le informazioni sulla posizione delle parole più grossolane sono probabilmente anche un contributo al rilevamento di anomalie osservate.", 'lt': 'Nors NLP bandymams periodiškai taikomos bausmės anomalijos, dar neturime nustatyti tikslios informacijos apie anomalijas būklės nuotraukos iš NLP modelių. Šiame dokumente siekiame užpildyti dvi pagrindines spragas, daugiausia dėmesio skiriant sintaktinių anomalijų sričiai. First, we explore fine-grained differences in anomaly encoding by designing probing tasks that vary the hierarchical level at which anomalies occur in a sentence.  Antra, bandome ne tik modelių gebėjimą aptikti tam tikrą anomaliją, bet ir aptikto anomalijos signalo bendrumą, tikrindami skirtingų anomalijų tipų perdavimą. Results suggest that all models encode some information supporting anomaly detection, but detection performance varies between anomalies, and only representations from more re- cent transformer models show signs of generalized knowledge of anomalies.  Tolesnės analizės patvirtina sąvoką, kad šie modeliai įgyja teisėtą ir bendrą sąvoką apie bausmės keistumą, o informacija apie žodžių padėtį, kuria greičiausiai yra didesnė, taip pat prisideda prie pastebimų anomalijų nustatymo.', 'ms': "Sementara anomali kalimat telah dilaksanakan secara peribadi untuk ujian dalam NLP, kita belum menetapkan gambar status tepat maklumat anomali dalam perwakilan dari model NLP. Dalam kertas ini kami bertujuan untuk mengisi dua ruang utama, fokus pada domain anomali sintaktik. First, we explore fine-grained differences in anomaly encoding by designing probing tasks that vary the hierarchical level at which anomalies occur in a sentence.  Second, we test not only models' ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types.  Results suggest that all models encode some information supporting anomaly detection, but detection performance varies between anomalies, and only representations from more re- cent transformer models show signs of generalized knowledge of anomalies.  Analisis berikut menyokong gagasan bahawa model-model ini mengambil pada gagasan yang sah, umum tentang keanehan kalimat, sementara maklumat kedudukan perkataan terbuka-lebar mungkin juga kontributor untuk pengesan anomali yang dilihat.", 'mt': 'While sentence anomalies have been applied periodically for testing in NLP, we have yet to establish a picture of the precise status of anomaly information in representations from NLP models.  In this paper we aim to fill two primary gaps, focusing on the domain of syntactic anomalies.  First, we explore fine-grained differences in anomaly encoding by designing probing tasks that vary the hierarchical level at which anomalies occur in a sentence.  It-tieni nett, a ħna nistestjaw mhux biss il-ħila tal-mudelli li jinstabu anomalija partikolari, iżda wkoll il-ġeneralità tas-sinjal tal-anomalija li nstab, billi jeżaminaw it-trasferiment bejn tipi distinti ta’ anomalija. Ir-riżultati jissuġġerixxu li l-mudelli kollha jikkodifikaw xi informazzjoni li tappoġġja l-individwazzjoni tal-anomaliji, iżda l-prestazzjoni tal-individwazzjoni tvarja bejn l-anomaliji, u rappreżentazzjonijiet biss minn mudelli ta’ trasformatur aktar riċenti juru sinjali ta’ għarfien ġeneralizzat tal-anomaliji. Analiżijiet ta’ segwitu jappoġġjaw il-kunċett li dawn il-mudelli jieħdu kunċett leġittimu u ġenerali ta’ awtonomija tas-sentenza, filwaqt li informazzjoni dwar il-pożizzjoni tal-kelma b’għeneb ikbar x’aktarx li tikkontribwixxi wkoll għall-identifikazzjoni tal-anomalija osservata.', 'ml': "NLP-ല്\u200d പരീക്ഷിക്കാന്\u200d വേണ്ടി വാക്കുകള്\u200d നിയമപരമായി പ്രയോഗിക്കപ്പെട്ടിരിക്കുമ്പോള്\u200d, NLP മോഡലില്\u200d നിന്നും പ്രതിനിധികളില്\u200d നിന്ന ഈ പത്രത്തില്\u200d നമ്മള്\u200d രണ്ടു പ്രധാനപ്പെട്ട ഭ്രാന്തുകള്\u200d നിറയ്ക്കാന്\u200d ഉദ്ദേശിക്കുന്നു. സിന്\u200dടാക്ടിക് അനാമ ആദ്യം, നമ്മള്\u200d വ്യത്യാസങ്ങള്\u200d പരിശോധിക്കുന്നത് വ്യത്യാസങ്ങള്\u200d നിരീക്ഷിക്കുന്നതിനാല്\u200d മുഴുവന്\u200d വ്യത്യാസങ്ങള്\u200d പരിശോധിക്കുന്നു. അതി Second, we test not only models' ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types.  അതിന്റെ ഫലങ്ങള്\u200dക്കുള്ള എല്ലാ മോഡലുകളും അനര്\u200dത്ഥ കണ്ടെത്താന്\u200d പിന്തുണയ്ക്കുന്ന ചില വിവരങ്ങള്\u200d കോഡിപ്പിക്കുന്നു, പക്ഷെ കണ്ടെത്താനുള്ള പ്രകടനം അനാ പിന്തുടരുന്ന വിശദീകരണങ്ങള്\u200d ഈ മോഡലുകള്\u200d നിയമപരമായ, വാക്കിന്റെ സാധാരണ ആശയത്തിന്റെ പേരില്\u200d എടുക്കുന്നതിനെ പിന്തുണയ്ക്കുന്നു. കോഴ്സര്\u200d ഗ്ര", 'mn': 'NLP-д туршилтын тулд өгүүлбэрийн буруу шинжлэх ухааныг цаг хугацаанд хэрэглэгдсэн ч NLP-ын загвараас илэрхийлэх үед тодорхой мэдээллийн тухай зураг бий болгохгүй байна. Энэ цаасан дээр бид хоёр анхны зай дүүргэхийг зориулж, синтактик аномалийг төвлөрүүлэхийг зориулж байна. Эхлээд бид хэлбэрээр өөрчлөгдөж буй судалгааны даалгаваруудыг зохион байгуулах архитекийн түвшинд өөрчлөгдсөн ялгааг судалж байна. Хоёрт, бид зөвхөн загварын байдлыг олж мэдэх чадвар биш, гэхдээ нээлттэй аномалийн сигналын ерөнхийлөгч байдлыг шалгаж, ялгаатай аномалийн төрлийн шилжүүлэх чадварыг шалгаж байна. Үүний үр дүнд бүх загварууд хэд хэд хэдэн мэдээллийг нээлттэй байдлаар дүгнэж байгааг сануулдаг. Гэхдээ нээлттэй үйл ажиллагааны үйл ажиллагаа нөлөөлдөг байдлын хоорондоо өөрчлөгддөг. Зөвхөн өөрчлөгч загваруудын хувь Дараагийн шинжилгээ нь эдгээр загваруудын хууль, ерөнхий хэлбэрийн сонирхолтой ойлголтыг дэмжиж байна. Гэхдээ хэлбэртэй үгийн байр суурь мэдээлэл нь мөн харагдаж буй анхаарлын шинжилгээнд нөлөөлөгч байх боломжтой.', 'pl': 'Chociaż anomalie zdań były stosowane okresowo do testowania w NLP, musimy jeszcze ustalić obraz dokładnego statusu informacji o anomaliach w reprezentacjach z modeli NLP. Celem niniejszego artykułu jest wypełnienie dwóch podstawowych luk, skupiających się na domenie anomalii składni. Po pierwsze, badamy drobne różnice w kodowaniu anomalii, projektując zadania sondujące, które różnią się poziomem hierarchicznym, na którym występują anomalie w zdaniu. Po drugie, testujemy nie tylko zdolność modeli do wykrycia danej anomalii, ale także ogólność wykrytego sygnału anomalii, badając transfer między różnymi typami anomalii. Wyniki sugerują, że wszystkie modele kodują pewne informacje wspierające wykrywanie anomalii, ale wydajność wykrywania różni się w zależności od anomalii, a tylko reprezentacje z bardziej efektywnych modeli transformatorów wykazują oznaki ogólnej wiedzy o anomaliach. Analizy następcze wspierają przekonanie, że modele te odbierają uzasadnione, ogólne pojęcie dziwności zdań, podczas gdy gruboziarniste informacje o pozycji słów prawdopodobnie również przyczyniają się do obserwowanej anomalii.', 'no': 'Mens setningane er periodisk brukte for testing i NLP, må vi enno laga eit bilete med nøyaktig status av anomaliske informasjon i representasjonar frå NLP-modeller. I denne papiret må vi fylle to primære mellomrom med fokusering på domenet av syntaksiske anomalier. Først utforskar vi forskjeller i anomalisk koding ved å designera proberingsoppgåver som varierer hierarkisk nivå som anomalier skjer i eit setning. Andre, tester vi ikkje berre modellen til å finna ein gitt anomalisk, men også generelitet av den oppdagte anomaliske signalen ved å undersøke overføring mellom ulike anomaliske typar. Resultater tyder på at alle modeller kodar nokre informasjon som støttar anomaliske oppdaging, men oppdaging varierer mellom anomalier, og berre representasjonar frå meir rekent- transformeringsmodeller viser teikn på generelle kunnskap av anomalier. Følgjande analyser støttar oppmerkinga på at desse modelane hentar opp ein legitimt, generell oppmerking av setningsverdi, mens informasjon om ordposisjon som er trekkjande, er sannsynlegvis også ein bidragar til den observerte anomaliske oppdaginga.', 'ro': 'În timp ce anomaliile frazelor au fost aplicate periodic pentru testarea în PNL, nu am stabilit încă o imagine a stării exacte a informațiilor despre anomalii în reprezentările din modelele PNL. În această lucrare ne propunem să umplem două goluri principale, concentrându-ne pe domeniul anomaliilor sintactice. În primul rând, explorăm diferențele fine în codificarea anomaliilor prin proiectarea sarcinilor de sondare care variază nivelul ierarhic la care apar anomaliile într-o propoziție. În al doilea rând, testăm nu numai capacitatea modelelor de a detecta o anumită anomalie, ci și generalitatea semnalului de anomalie detectat, prin examinarea transferului între diferite tipuri de anomalii. Rezultatele sugerează că toate modelele codează unele informații care susțin detectarea anomaliilor, dar performanța detectării variază între anomalii, și numai reprezentările de la modele de transformatoare mai recinte prezintă semne de cunoaștere generalizată a anomaliilor. Analizele ulterioare susțin noțiunea că aceste modele preiau o noțiune legitimă și generală de ciudățenie a propozițiilor, în timp ce informațiile mai grosiere privind poziția cuvintelor contribuie probabil și la detectarea anomaliilor observate.', 'sr': 'Iako su anomalije rečenice primjenjene periodično za testiranje u NLP-u, još uvek nismo uspostavili sliku preciznog status a anomalijskih informacija u predstavljanjima iz modela NLP-a. U ovom papiru imamo cilj da napunimo dve primarne praznine, fokusirajući se na domenu sintaktičkih anomalija. Prvo, istražujemo dobre razlike u anomalijskom kodiranju, dizajnirajući istraživanje zadataka koji se razlikuju hijerarhički nivo na kojem se anomalija događa u rečenici. Drugo, testiramo ne samo sposobnost modela da otkrijemo određenu anomaliju, već i generalnost otkrivenog anomalijskog signal a, pregledajući transfer između različitih anomalijskih tipova. Rezultati ukazuju na to da svi modeli kodiraju neke informacije koje podržavaju anomaliju, ali izvršnost otkrića se razlikuje između anomalija, a samo predstavljanja iz više modela prezentacije pokazuju znakove generaliziranog znanja anomalija. Analiziranja praćenja podržavaju pojam da se ovi modeli prikupljaju legitimnom, općem pojmom neobičnosti rečenica, dok informacije o poziciji rečenica koje su prezrele, vjerojatno su takođe doprinosile observenoj anomaliji.', 'si': 'වාක්ය අනමාර්\u200dයය NLP වලට පරීක්ෂණා කරන්න පරීක්ෂණා වෙනුවෙන් පරීක්ෂණා කරලා තියෙනවා නමුත් අපිට තාමත් NLP මොඩේල් වලින් අනමා මේ පත්තරේ අපි අල්ලගන්නවා ප්\u200dරධාන අවධානය දෙකක් පුරවන්න, සංකේතික අවධානයක් විදිහට බලන්න. මුලින්ම, අපි අනාමාලික සංකේතනයේ වෙනස් විදියට පරීක්ෂා කරනවා විදියට පරීක්ෂා වැඩක් වෙනස් කරනවා කියලා විශේෂ ස්ථාන දෙවනිය, අපි පරීක්ෂා කරන්නේ මොඩේල් එක්ක ප්\u200dරමාණයක් විතරක් නෙවෙයි, ඒත් පරීක්ෂා කරලා තියෙන අනමාන්\u200dය සංඥාවයේ සාමාන්\u200dය සං ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරත පස්සෙන් විශ්ලේෂණය සාමාන්\u200dය විශ්ලේෂණය සහයෙන්නේ මේ මොඩේල් සාමාන්\u200dය විශ්ලේෂණයක්, වචනයක් සාමාන්\u200dය විශ්ලේෂණයක්, කෝර්සර් ග්\u200dරේන', 'sv': 'Även om meningsbestämmelser har tillämpats periodvis för testning i NLP, har vi ännu inte etablerat en bild av den exakta statusen för anomaliinformation i representationer från NLP modeller. I denna uppsats syftar vi till att fylla två primära luckor med fokus på domänen syntaktiska avvikelser. Först utforskar vi finkorniga skillnader i avvikelsekodning genom att utforma probningsuppgifter som varierar den hierarkiska nivå på vilken avvikelser uppstår i en mening. För det andra testar vi inte bara modellernas förmåga att upptäcka en given avvikelse, utan också generaliteten hos den upptäckta avvikelsesignalen, genom att undersöka överföring mellan olika avvikelsetyper. Resultaten tyder på att alla modeller kodar viss information som stöder avvikelsedetektering, men detektionsprestanda varierar mellan avvikelser, och endast representationer från mer återkommande transformatormodeller visar tecken på generaliserad kunskap om avvikelser. Uppföljningsanalyser stöder uppfattningen att dessa modeller tar upp en legitim, allmän uppfattning om meningsuddighet, medan grovkornig ordpositionsinformation sannolikt också bidrar till upptäckten av avvikelser.', 'so': "While sentence anomalies have been applied periodically for testing in NLP, we have yet to establish a picture of the precise status of anomaly information in representations from NLP models.  Qoraalkan waxaan ku talo galaynaa in aan buuxino laba burbur oo asalka ah, oo aan ku kalsoonaynaa meesha ay leedahay isbedelka. Marka ugu horeysa, waxaynu baaraynaa kala duwanaanshaha la'aanta ah oo aan ku qorno shaqooyin la tijaabiyo oo kala duwan darajada hierarchiga, kuwaas oo ay ku dhacdo qofka caafimaadka ah. Second, waxaynu imtixaamaynaa awoodka modelalka oo keliya oo aan aqoonsan karno mid caadi ah, laakiin waxaa kaloo imtixaamaya dhamaanka calaamada caadiga ah, baaritaanka wareejinta u dhexeeya noocyo kala duduwan oo caafimaad ah. Midhaha dhamaantoodu waxay ka muuqataa in tusaalaha oo dhammu ay kooban yihiin macluumaad ka mid ah oo taageeraya aqoonta caafimaadka, laakiin dhaqdhaqaaqa aqoontu waxay kala duwan tahay mid kaleemeysan, waxayna ka muuqataa noocyada bedbeddelka oo keliya muuqashada aqoonta caadiga ah. Baaritaanka soo socoshada ayaa kaalmeeya fikradaas in modelladan ay ku soo qaadaan fikrada saxda ah oo guud ah, marka macluumaadka booska qofka koonfureed ee qofka qofka qofka qofka ku qoran yahay wuxuu ka mid noqon karaa macluumaad ku saabsan baaritaanka caadiga ah.", 'ta': 'NLP மாதிரிகளில் உள்ள சோதனைக்கான வாக்கியம் குறிப்பாக பயன்படுத்தப்பட்டுள்ளது In this paper we aim to fill two primary gaps, focusing on the domain of syntactic anomalies.  முதலில், நாம் வித்தியாசமான குறியீட்டில் நன்றாக்கப்பட்ட வேறுபாடுகளை கண்டுபிடி இரண்டாவது, நாம் ஒரு கொடுக்கப்பட்ட அசாதாரத்தை கண்டுபிடிக்க முடியும் மாதிரிகளின் சக்தியை மட்டும் சோதிக்கிறோம், ஆனால் கண்டுபிடிக்கப்பட்ட முடிவு பின்வரும் ஆராய்ச்சிகள் இந்த மாதிரிகள் சரியான, பொதுவான சொல்லை ஒற்றைப்படையான கருத்தின் மீது எடுக்கும் கருத்தினை ஆதரிக்கும், போது தெரியும', 'ur': 'اگرچہ مطلب غیر معلومات NLP میں آزمائش کے لئے مقررہ طور پر لازم کیا گیا ہے، ہمیں یہاں تک NLP موڈلوں کے معلومات میں غیر معلومات کی تصویر بنانے کی ضرورت ہے. ہم نے اس کاغذ میں دو پہلی فاصلہ بھر جانے کا ارادہ کیا ہے، سینٹکتیک نامالیاں کے ڈومین پر تمرکز کیا جاتا ہے۔ پہلے، ہم غیر معمولی اکنوڈینگ میں بہترین دانے کے اختلاف کو دیکھتے ہیں، جو ایک جماعت میں غیر معمولی اتفاق پھیر رہے ہیں اسے پرڈینگ کے ذریعہ طراحی کرتے ہیں۔ دوسرا، ہم صرف مدل کے قابلیت کی آزمائش نہیں کریں گے کہ ایک معلوم غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر نتیجے ان سے پیش کرتے ہیں کہ تمام نمڈلوں کو غیر قابل شناسایی کی مدد کی کوئی معلومات کے ساتھ کوڈ کرتا ہے، لیکن شناسایی کی عملکرد غیر قابل شناسایی کے درمیان تغییر کرتی ہے، اور صرف اس سے زیادہ ریسنٹ تغییر نمڈلور نمڈلوں سے نشانیاں اچھی تحقیقات کی تحقیقات اس نظریہ کی مدد کرتی ہے کہ یہ مدلے ایک قانونی، عمومی نظریہ جمع کرتی ہیں، حالانکہ کورسر-grained لفظ موقعیت معلومات بھی اظہار کی غیر معلومات کے ذریعہ ایک مددگار ہے.', 'uz': "Name Bu qogʻozda biz ikkita asosiy gap to ʻldirishni istaymiz, sintaktik anomaliyalarining domeniga foydalanamiz. Birinchi so'zda, biz aniqlik kodlash usulini aniqlashni o'rganamiz va hierarchik darajadagi vazifalarni o'zgartirish mumkin. Ikkinchi so'zda, biz nafaqat modellarni aniqlash imkoniyatini o'rganish mumkin, balki aniqlangan anomaly signalning umumiy yetarligini o'rganish uchun boshqa oddiy turlar orasidan uzoqlarni tekshirish mumkin. @ info Koʻpaytirish taʼminlovchilari, bu modellar oddiy, oddiy gaplarni qo'yib keladigan fikrlarni qoʻllash imkoniyatini qoʻllash mumkin. Koʻrsatilgan soʻzning joyi maʼlumoti qoʻllanmagan oddiy va ko'paytirilgan aniqlash uchun foydalanuvchiga ega bo'lishi mumkin.", 'vi': 'Tuy rằng các triệu chứng dị thường được áp dụng thường xuyên cho việc kiểm tra tại Njala, nhưng chúng ta vẫn chưa xác định được tình trạng dị thường chính xác của thông tin dị tật trong các biểu hiện từ mẫu Njala. Trong tờ giấy này chúng tôi hướng tới lấp đầy hai khoảng trống chính, tập trung vào lĩnh vực của dị vật cấu hình. Trước tiên, chúng ta khám phá các khác nhau mức độ thường trong các quy trình dị thường bằng cách thiết kế các nhiệm vụ thăm dò thay đổi cấp thứ tự nơi dị thường xuất hiện trong một câu. Thứ hai, chúng tôi kiểm tra không chỉ khả năng của các mẫu để phát hiện một sự bất thường cụ thể, mà còn tính tổng quát của tín hiệu dị thường phát hiện, bằng cách kiểm tra sự chuyển giao giữa các loại dị thường khác nhau. Kết quả cho thấy tất cả các mô hình đều mã hóa một số thông tin hỗ trợ phát hiện dị tật, nhưng khả năng phát hiện khác nhau, và chỉ các biểu hiện từ các mô hình biến đổi tăng giá trị cho thấy dấu hiệu của kiến thức phổ biến dị thường. Các phân tích theo dõi ủng hộ khái niệm rằng những mô hình này thu thập một khái niệm chính đáng về sự kỳ lạ của câu, trong khi thông tin về vị trí từ phức tạp hơn cũng có thể góp phần vào việc phát hiện dị tật.', 'bg': 'Докато аномалиите на изреченията се прилагат периодично за тестване в НЛП, все още не сме установили картина на точното състояние на аномалията информация в представянето на модели на НЛП. В настоящата статия се стремим да запълним две основни пропуски, фокусирайки се върху областта на синтактичните аномалии. Първо, изследваме фините разлики в кодирането на аномалии чрез проектиране на задачи за сондиране, които варират йерархичното ниво, на което аномалиите се появяват в изречение. Второ, тестваме не само способността на моделите да откриват дадена аномалия, но и генералността на открития сигнал за аномалия, като изследваме трансфера между различни типове аномалии. Резултатите показват, че всички модели кодират известна информация, подкрепяща откриването на аномалии, но ефективността на откриването варира между аномалиите и само представянето на по-повторни трансформаторни модели показва признаци на обобщено познаване на аномалиите. Последващите анализи подкрепят идеята, че тези модели възприемат легитимно общо понятие за странност на изречението, докато по-грубозърнестата информация за позицията на думата вероятно също допринася за откриването на наблюдаваните аномалии.', 'hr': 'Iako su analizije rečenice primjenjene periodično za testiranje u NLP-u, još uvijek moramo utvrditi sliku preciznog status a anomalijskih informacija u predstavljanjima iz modela NLP-a. U ovom papiru ciljamo napuniti dvije primarne praznine, fokusirajući se na domenu sintaktičkih anomalija. Prvo, istražujemo razlike u anomalijskom kodiranju, dizajnirajući istraživačke zadatke koje se razlikuju hijerarhička razina na kojoj se anomalije događaju u rečenici. Drugo, testiramo ne samo sposobnost modela otkrivanja određene anomalije, već i generalnost otkrivenog anomalijskog signal a, ispitivajući prijenos između različitih tipova anomalije. Rezultati ukazuju na to da svi modeli kodiraju neke informacije koje podržavaju anomaliju, ali učinkovitost otkrivanja razlikuje između anomalija, a samo predstavljanja iz više modela prezentacije pokazuju znakove generaliziranog znanja anomalija. Analiziranja nakon praćenja podržavaju pojam da se ovi modeli prikupljaju legitimnom, općem pojavu čudnosti kazne, dok su informacije o poziciji riječi koje su prezrele, vjerojatno, također doprinosile observenoj anomaliji.', 'da': 'Mens sætningsafvigelser regelmæssigt er blevet anvendt til test i NLP, har vi endnu ikke etableret et billede af den præcise status af anomaliinformation i repræsentationer fra NLP modeller. I denne artikel har vi til formål at udfylde to primære huller med fokus på domænet syntaktiske anomalier. Først undersøger vi finkornede forskelle i anomali kodning ved at designe sondeopgaver, der varierer det hierarkiske niveau, hvor anomalier opstår i en sætning. For det andet tester vi ikke kun modellernes evne til at detektere en given anomali, men også generaliteten af det detekterede anomali signal ved at undersøge overførsel mellem forskellige anomali typer. Resultaterne tyder på, at alle modeller indkoder nogle oplysninger, der understøtter anomali detektion, men detektion ydeevne varierer mellem anomalier, og kun repræsentationer fra mere re- cent transformer modeller viser tegn på generel viden om anomalier. Opfølgningsanalyser understøtter forestillingen om, at disse modeller opfanger en legitim, generel begreb om sætningsmærkelighed, mens grovkornede ordpositionsoplysninger sandsynligvis også bidrager til den observerede anomali detektion.', 'nl': 'Hoewel zinsanomalieën periodiek zijn toegepast voor testen in NLP, moeten we nog een beeld krijgen van de precieze status van anomaliegegevens in representaties uit NLP-modellen. In dit artikel willen we twee primaire lacunes opvullen, waarbij we ons richten op het domein van syntactische anomalieën. Eerst onderzoeken we fijnkorrelige verschillen in anomalie-codering door het ontwerpen van sonde-taken die het hiërarchische niveau variëren waarop anomalieën in een zin voorkomen. Ten tweede testen we niet alleen het vermogen van modellen om een bepaalde anomalie te detecteren, maar ook de algemeenheid van het gedetecteerde anomaliesignaal, door overdracht tussen verschillende anomalietypen te onderzoeken. De resultaten suggereren dat alle modellen enige informatie coderen die anomaliedetectie ondersteunt, maar de detectieprestaties variëren per anomalie, en alleen representaties van meer resonante transformatormodellen tonen tekenen van algemene kennis van anomalieën. Follow-up analyses ondersteunen het idee dat deze modellen een legitieme, algemene notie van zinsvreemdelijkheid oppikken, terwijl grovere woordpositieinformatie waarschijnlijk ook bijdraagt aan de waargenomen anomalie detectie.', 'de': 'Während Satzanomalien regelmäßig für Tests in NLP angewendet wurden, müssen wir noch ein Bild über den genauen Status von Anomalieninformationen in Darstellungen aus NLP-Modellen erstellen. In diesem Beitrag wollen wir zwei primäre Lücken schließen, wobei wir uns auf die Domäne syntaktischer Anomalien konzentrieren. Zunächst untersuchen wir feinkörnige Unterschiede in der Anomalienkodierung, indem wir Probenaufgaben entwerfen, die die hierarchische Ebene variieren, auf der Anomalien in einem Satz auftreten. Zweitens testen wir nicht nur die Fähigkeit von Modellen, eine bestimmte Anomalie zu erkennen, sondern auch die Allgemeinheit des detektierten Anomaliesignals, indem wir den Transfer zwischen verschiedenen Anomalietypen untersuchen. Die Ergebnisse deuten darauf hin, dass alle Modelle einige Informationen kodieren, die die Erkennung von Anomalien unterstützen, aber die Erkennungsleistung variiert zwischen Anomalien, und nur Repräsentationen von rücksichtsvolleren Transformatormodellen zeigen Anzeichen einer allgemeinen Kenntnis von Anomalien. Folgeanalysen unterstützen die Annahme, dass diese Modelle eine legitime, allgemeine Vorstellung von Satzkuriosität aufgreifen, während grobkörnige Wortpositioneninformationen wahrscheinlich auch einen Beitrag zur beobachteten Anomalieerkennung leisten.', 'id': "Sementara anomali kalimat telah diaplikasikan secara peribadi untuk tes di NLP, kita belum menetapkan gambar dari status tepat informasi anomali dalam representation dari model NLP. Dalam kertas ini kami bertujuan untuk mengisi dua ruang utama, fokus pada domain anomali sintaksi. Pertama, kita mengeksplorasi perbedaan-perbedaan yang baik dalam pengekodan anomali dengan merancang tugas penyelidikan yang berbeda tingkat hierarkis di mana anomali terjadi dalam kalimat. Second, we test not only models' ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types.  Hasil menunjukkan bahwa semua model mengkode beberapa informasi yang mendukung deteksi anomali, tetapi prestasi deteksi berbeda antara anomali, dan hanya rappresentasi dari model transformer yang lebih resen menunjukkan tanda-tanda pengetahuan umum anomali. Analisis berikutnya mendukung gagasan bahwa model-model ini mengambil pada gagasan yang sah, umum tentang keanehan kalimat, sementara informasi posisi kata yang lebih kasar mungkin juga kontributor untuk deteksi anomali yang diawasi.", 'sw': 'Wakati hukumu hiyo imetumiwa mara kwa mara kwa ajili ya jaribio la NLP, bado hatujaweza kuweka picha ya hali sahihi ya taarifa za uongofu katika uwakilishi wa mifano ya NLP. Katika gazeti hili tunalenga kuzijaza gaidi mbili za msingi, tunalenga kwenye maeneo ya ubaguzi wa pamoja. Kwanza, tunachunguza tofauti zilizotengenezwa vizuri katika kodi la kawaida kwa kutengeneza kazi zinazotofautiana na kiwango kikubwa ambacho ubaguzi unatokea katika hukumu. Pili, tunajaribu siyo tu uwezo wa mifano tu wa kutambua hali ya kawaida, bali pia uzalishaji wa alama zilizogunduliwa, kwa kuchunguza uhamiaji kati ya aina tofauti za kawaida. Matokeo yanapendekeza kuwa mifano yote inajumuisha baadhi ya taarifa zinazounga mkono uchunguzi wa kimaadili, lakini utendaji wa uchunguzi unatofautiana na ubaguzi, na wawakilishaji pekee kutoka kwa miundo mbinu ya mabadiliko ya asilimia nyingine zinaonyesha ishara za maarifa yaliyotengenezwa kwa vitendo vya ubaguzi. Uchambuzi wa ufuatiliaji unaunga mkono dhana ya kwamba mifano hizi zinachukua dhana ya halali, ya jumla ya hali ya kawaida ya hukumu, wakati taarifa za upande wa maneno ya kurekebisha inawezekana pia ni mchangiaji wa kutambuliwa bila utambulisho.', 'ko': '문장 이상은 정기적으로 NLP 테스트에 사용되지만, NLP 모델이 표시하는 이상 정보의 정확한 상태도를 구축하지 않았습니다.본고에서 우리의 목표는 두 가지 주요 공백을 메우는 것이고 중점은 문법이 이상한 분야이다.우선, 우리는 디자인 탐지 임무를 통해 이상 인코딩의 세립도 차이를 탐색하고 탐지 임무는 문장에 이상한 차원 구조를 바꿀 수 있다.그 다음에 서로 다른 이상 유형 간의 전송을 검사함으로써 우리는 모델이 이상을 검출하는 능력을 테스트했을 뿐만 아니라 검출된 이상 신호의 통용성을 테스트했다.그 결과 모든 모델이 이상 검출을 지원하는 정보를 인코딩했지만 검출 성능은 서로 다른 이상 사이에서 달라졌고 변압기 모델을 업데이트하는 표시에서만 이상에 대한 광범위한 지식의 흔적을 보였다.후속 분석은 이러한 관점을 지지한다. 즉, 이러한 모델은 합리적이고 보편적인 문장 이상성 개념을 채택했고 굵은 입자의 단어 위치 정보도 관찰된 이상 검측의 한 요소가 될 수 있다.', 'tr': "NLP'de synaglamak üçin sözlem anomaliýasynyň periyodik ýagdaýda uygulandyrylýar, we heniz NLP modellerinden deňil malümatyň durumynyň dogry bir suratyny düzenlemegimiz gerek. Bu kağıtda sintaktik anomalilerin domenya odaklanmak için iki ana boşluk doldurmak amaçlarımız. Ilkinji gezek, anomaliýa ködlemelerde iýerarhiýalyň derejesini üýtgeden çözgütlerde üýtgeden çözgütlerni tasarlap, iýerarhiýalyň düzedilerini gözleýäris. Ikinjisi, diňe berilen anomaliýany tanamak başaryşlaryny däl, ýöne tanyş edilen anomaliýa sinyalynyň umumy beýleki taryşlaryň arasynda geçirmek üçin synanyşýarys. Netijenler hemme modeller anomaliýa tanyşma destekleýän bazı bilgileri kodlaýar diýip tanyş eserleri anomaliýalar arasynda deňleýär, we diňe kene-cent tanyş modellerinden tanyş etmek üçin döredilen anomaliýalaryň bilgi işaretlerini görkezýär. Diňleşik analyzlary bu nusgalaryň täze bir ýagdaý, umumy sözleýän wajyplygyny gollaýandygy düşünmesi üçin gollaýarlar. Diňleşik sözleýän ýeri maglumatyň we gözlenen daşyplygyna kömekleyici bolup biler.", 'sq': 'Ndërsa anomalitë e dënimeve janë aplikuar periodikisht për testimin në NLP, ne ende duhet të vendosim një fotografi të statusit të saktë të informacionit të anomalisë në përfaqësimet nga modelet NLP. Në këtë letër ne synojmë të mbushim dy boshllëqet kryesore, duke u përqëndruar në domenin e anomalive sintaktike. Së pari, ne eksplorojmë dallime të holla në kodimin e anomalisë duke projektuar detyra sondazhi që ndryshojnë nivelin hierarkik në të cilin ndodhin anomalitë në një fjalim. Së dyti, ne testojmë jo vetëm aftësinë e modeleve për të zbuluar një anomali të caktuar, por gjithashtu gjeneralitetin e sinjalit të zbuluar anomali, duke ekzaminuar transferimin midis tipeve të ndryshëm anomali. Rezultatet sugjerojnë se të gjitha modelet kodojnë disa informacione që mbështesin zbulimin e anomalive, por rezultatet e zbulimit ndryshojnë midis anomalive dhe vetëm përfaqësimet nga modelet më të përqindshëm të transformuesve tregojnë shenja të njohjes së gjeneralizuar të anomalive. Analizat e pasimit mbështesin konceptin se këto modele marrin një koncept të ligjshëm, të përgjithshëm të çuditshëm të dënimit, ndërsa informacioni mbi pozicionin e fjalëve më të mëdha është me gjasa gjithashtu një kontribues në zbulimin e anomalisë të vëzhguar.', 'af': "Alhoewel die setnings anomalies is periodieke aangepas vir toets in NLP, het ons nog 'n prent van die presies status van anomalie inligting in voorstellings van NLP modele te stel. In hierdie papier doen ons doel om twee primêre spasies te vul, fokus op die domein van sintaktieke anomalies. Eerste, ons ondersoek fine-grained verskille in anomalie enkodering deur te ontwerp probeering opdragte wat die hierarkies vlak verander waar anomalies in 'n seting voorkom. Tweede, ons toets nie alleen model se moontlikheid om 'n gegewe anomalie te ontdek nie, maar ook die generelheid van die ontdekte anomaliese sein, deur te ondersoek oordrag tussen verskillende anomalie tipes. @ info Volgende analiserings ondersteun die nodiging dat hierdie modele op 'n regverdige, algemene nodiging van setinge odditeit opneem, terwyl coarser-grained woord posisie inligting waarskynlik is ook 'n bydraer aan die aansigte anomaliese opdekking.", 'am': 'የግንኙነት አካባቢነት በNLP ውስጥ ለመፈተን በጊዜው በተደረገ ጊዜ፣ ከNLP ዓይነቶች በተለየ የአፍላጎት መረጃዎች የግንኙነት መረጃን ማስታወቂያውን እናስቀምጥ ዘንድ ገና አግኝተናል፡፡ በዚህ ፕሮግራም ሁለት የፊደል ጥያቄዎችን ለመሞላ እናስፈልጋለን፡፡ በመጀመሪያው፣ በተለየ ሐይራርክ ደረጃውን በተለየ ውጤት የሚነካውን ስራዎችን በመግለጽ እናሳውቃለን፡፡ ሁለተኛ፣ በተለየ በተለያዩ አካባቢ ዓይነቶች መካከል መዘዋወርን በመመርመርመር የፍላጎት ጥያቄ ብቻ አይደለም፡፡ ፍጥረቶች ሁሉም ሞዴሎችን በአካባቢ ግንኙነት ላይ የሚደግፉ መረጃዎችን እንዲቀድሙ ያሳያል፤ ነገር ግን የግንኙነት ፍጥረት በአናማቢነት መካከል ይለያያል፤ እናም በክፍለ መልዕክት የሚለውጥ ምሳሌዎች ብቻ የበዛ ሰንት ተለወጠው ምሳሌዎች የአንደናግሎችን እውቀት እንዲያሳዩ ነው፡፡ የመከተል ምርጫዎች እነዚህ ምሳሌዎች የተፈቀደ፣ የውይይት አካባቢ የቃላት ስህተት ብዛት እንዲያሳድጉት የሚደብቁትን አሳብ ይደግጋሉ፡፡', 'hy': "Մինչդեռ նախադասությունների անոմալիաները պարբերաբար կիրառվում են ՆԼՊ-ի փորձարկումների համար, մենք դեռևս պետք է հաստատենք ՆԼՊ-ի մոդելների ներկայացումներում անոմալիայի ճշգրիտ կարգավիճակի պատկերը: Այս թղթի մեջ մենք նպատակում ենք լցնել երկու հիմնական բացառություններ, կենտրոնացնելով սինտակտիկ անոմալիաների ոլորտում: Առաջինը, մենք ուսումնասիրում ենք անոմալիայի կոդավորման նրբազան տարբերությունները' ստեղծելով ուսումնասիրելու առաջադրանքներ, որոնք տարբերվում են հիերարխիկ մակարդակին, որտեղ անոմալիաները տեղի են ունենում նախադասության մեջ: Second, we test not only models' ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types.  Արդյունքները ցույց են տալիս, որ բոլոր մոդելները կոդավորում են որոշ տեղեկություններ, որոնք աջակցում են անոմալիաների հայտնաբերման, բայց հայտնաբերման արդյունքները տարբերվում են անոմալիաների միջև, և միայն ավելի համեմատական վերափոխման մոդելների ներկայացումները ցույց են տալիս անոմա Հետևական վերլուծությունները աջակցում են այն գաղափարին, որ այս մոդելները ընդունում են նախադասության տարօրինակության օրինակ, ընդհանուր գաղափար, մինչդեռ ավելի խիստ պատկերված բառերի դիրքի տեղեկատվությունը հավանաբար նաև ներդրում է հետազոտված անոմալիայի հայտնաբերման", 'bn': 'এনএলপিতে পরীক্ষা করার জন্য কোনো নিয়মিত কারাদণ্ড প্রয়োগ করা হয়েছে, তবে এনএলপি মডেল থেকে প্রতিনিধিত্বের প্রতিনিধিত্বের সঠিক তথ্যের একট এই কাগজটিতে আমরা দুটি প্রধান বিভ্রান্তি পূর্ণ করতে চাই, সিন্ট্যাক্টিক অ্যানোমালির দোমেইনের দিকে মনোযো প্রথমত, আমরা অন্যান্য এনকোডিং এ ভালোভাবে ভিন্ন ভিন্ন ভিন্ন ভিন্ন পার্থক্য খুঁজে বের করি যা হিয়েরারাক্কিল স্তরের বিভিন্ন ভিন্ দ্বিতীয়, আমরা শুধুমাত্র মডেলের ক্ষমতার পরীক্ষা করি না যে একটি নির্দিষ্ট অস্বাভাবিক সিগন্যাল সনাক্ত করতে পারে, কিন্তু একই সাথে আবিষ্কার করা  ফলাফল পরামর্শ প্রদান করা হয়েছে যে সকল মডেলের কিছু তথ্য এনকোড করে আন্যান্যালিয়া সনাক্ত করার সমর্থন করে, কিন্তু আবিষ্কার করা প্রক্রিয়া অন্যান্যায়ভাবে বিভিন্ন অনুসরণ বিশ্লেষণ সমর্থন করে যে এই মডেলগুলো বৈধ, সাধারণ ভাবে বাক্যের অদ্ভুত ধারণা নিয়ে গেছে, যদিও কোর্সার-গ্রেড করা শব্দের অবস্থানের তথ্য দেখা যায়', 'az': 'NLP-də imtahana çəkmək üçün cümlələrin anomaliyaları periyodikcə istifadə edildiyi halda, NLP modellerindən göstərilən anomalik məlumatının dəqiqli durumunu təyin etməmiz lazımdır. Bu kağızda iki ilk boşluq doldurmaq istəyirik, sintaktik anomalilərin domeinə odaklanmaq. İlk dəfə, anomaliya kodlaması barəsindəki gözəl dəyişiklik fərqli fərqli işləri hiyerarşik səviyyəsində anomaliya gəldiyi təqdirdə təşkil edirik. İkincisi, biz yalnızca modellərin anomalisini tanıtmaq bacarılığını sınayırıq, ancaq tanınmış anomali sinyallərin genellərini də, ayrı anomali növlərin arasındakı transferini sınamaq üçün. Sonuçlar, bütün modellərin anomaliya keşfini dəstəkləyən bəzi məlumatları kodlamasını təsdiqləyir, amma keşf performansı anomaliya arasında fərqlənir və yalnız yeni-cent transformer modellərin təsdiqlənmələri anomaliyaların genel bilgisinin əlamətlərini göstərir. İzləmə analizi bu modellərin haqqı, cümlənin təəccüblüyünün genel fikrində tutduğu fikrini dəstəkləyir, lakin cümlənin təəccüblənmiş söz pozisyonu məlumatı də gözlənilmiş anomaliya tanımasına köməkçi ola bilər.', 'fa': 'در حالی که نامولی\u200cهای جمله به طور مدتی برای آزمایش در NLP کاربرد شده\u200cاند، هنوز مجبوریم تصویر موقعیت دقیق اطلاعات نامولی را در نمایش\u200cهایی از مدل NLP ایجاد کنیم. در این کاغذ ما هدف داریم که دو فاصله اصلی را پر کنیم، با تمرکز روی حوزه\u200cهای نامالی\u200cهای سنتاکتیک. اول، ما تفاوت\u200cهایی از دانه\u200cهای زیبا در رمزبندی غیر عادی با طراحی کار\u200cهای تحقیق که سطح دایره\u200cآفریقی را تغییر می\u200cدهند که در یک جمله غیر عادلانه اتفاق می\u200cافتد تحقیق می\u200cکنیم. دوم، ما نمی توانیم فقط توانایی مدل\u200cها را امتحان کنیم که یک نامالی به دست آورده باشد، بلکه همچنین ژنرال سیگنال نامالی شناخته شده، با تحقیق انتقال بین نوع نامالی متفاوت. نتیجه\u200cها پیشنهاد می\u200cدهند که تمام مدل\u200cها بعضی اطلاعات را که پشتیبانی از شناسایی غیرعادی می\u200cکنند، رمزگذاری می\u200cکنند، ولی عملکرد شناسایی بین غیرعادی متفاوت می\u200cشود، و تنها نمایش\u200cهایی از مدل\u200cهای تغییر\u200cدهنده\u200cی دوباره سنت نشا تحلیل\u200cهای دنبال کردن به نظر می\u200cرسد که این مدل\u200cها به یک نظر قانونی، نظر عمومی از عجیب جمله برمی\u200cدارند، در حالی که اطلاعات موقعیت\u200cهای کلمه\u200cهای کورکرز احتمالاً همچنین یک حامله\u200cکننده\u200cای برای شناسایی غیرقانونی مشاهده می\u200cشود.', 'bs': 'Iako su analizije rečenice primjenjene periodično za testiranje u NLP-u, još uvijek moramo utvrditi sliku preciznog status a anomalijskih informacija u predstavljanjima iz modela NLP-a. U ovom papiru ciljamo napuniti dvije primarne praznine, fokusirajući se na domenu sintaktičkih anomalija. Prvo, istražujemo dobre razlike u anomalijskom kodiranju, dizajnirajući istraživanje zadataka koji se razlikuju hijerarhički nivo na kojem se anomalija događa u rečenici. Drugo, testiramo ne samo sposobnost modela da otkrijemo određenu anomaliju, već i generalnost otkrivenog anomalijskog signal a, pregledavajući transfer između različitih anomalijskih tipova. Rezultati ukazuju na to da svi modeli kodiraju neke informacije koje podržavaju anomaliju, ali učinkovitost detektiva se razlikuje između anomalija, a samo predstavljanja iz više modela prezentacije pokazuju znakove generaliziranog znanja anomalija. Analiziranja praćenja podržavaju pojam da se ovi modeli prikupljaju legitimnom, općem pojmom neobičnosti kazne, dok su informacije o poziciji riječi koje su prezrele, vjerojatno, također doprinosile observenoj anomaliji.', 'ca': "Mentre que les anomalies de frases s'han aplicat periódicament per a la prova en NLP, encara no hem establit una imatge de l'estatus exacte de la informació d'anomalies en representacions de models NLP. En aquest paper intentem llençar dos forats primàries, centrant-nos en el domini de les anomalies sinàctiques. En primer lloc, explorem diferències fines en la codificació de l'anomalia dissenyant tasques de sondagem que varien el nivell jeràrquic en què ocorren anomalies en una frase. Segon, examinem no només l'habilitat dels models de detectar una determinada anomalia, sinó també la generalitat del senyal d'anomalia detectat, examinant la transfer ència entre tipus distints d'anomalies. Els resultats suggereixen que tots els models codifiquen alguna informació que suporta la detecció d'anomalies, però el rendiment de la detecció varia entre anomalies, i només les representacions de models transformadors més recents mostren senyals de coneixement generalitzat d'anomalies. Les anàlisis de seguiment donen suport a la noció que aquests models recorren a una noció legítima i general d'estranyetat de frases, mentre que la informació sobre posició de paraules més grossa és probablement també un contributor a la detecció observada d'anomalies.", 'cs': 'Zatímco anomálie vět byly pravidelně aplikovány pro testování v NLP, dosud jsme neměli zjistit obraz o přesném stavu informací o anomáliích v reprezentacích z NLP modelů. Cílem tohoto článku je vyplnit dvě primární mezery se zaměřením na oblast syntaktických anomálií. Nejprve zkoumáme jemné rozdíly v kódování anomálií navržením sondovacích úloh, které se liší hierarchickou úroveň, na které se anomálie vyskytují ve větě. Za druhé testujeme nejen schopnost modelů detekovat danou anomálii, ale také obecnost detekovaného anomálie signálu zkoumáním přenosu mezi různými typy anomálií. Výsledky naznačují, že všechny modely kódují některé informace podporující detekci anomálií, ale detekční výkon se liší mezi anomáliemi a pouze reprezentace z více rentních transformátorových modelů ukazují známky obecné znalosti anomálií. Následné analýzy podporují představu, že tyto modely vycházejí z legitimního, obecného pojetí zvláštnosti vět, zatímco hrubozrnnější informace o pozici slova pravděpodobně přispívají také k detekci pozorovaných anomálií.', 'et': 'Kuigi NLP-s testimiseks on perioodiliselt rakendatud lauseanomaaliaid, ei ole me veel loonud pilti anomaaliateabe täpsest staatusest NLP mudelite esitustes. Käesolevas töös püüame täita kaks esmast lünka, keskendudes süntaktiliste anomaaliate valdkonnale. Esiteks uurime anomaaliate kodeerimise peenete erinevusi, kujundades prooviülesandeid, mis varieerivad hierarhilist taset, millel anomaaliad lauses esinevad. Teiseks testime mitte ainult mudelite võimet tuvastada antud anomaalia, vaid ka tuvastatud anomaalia signaali üldist taset, uurides ülekannet erinevate anomaaliatüüpide vahel. Tulemused näitavad, et kõik mudelid kodeerivad anomaaliate tuvastamist toetavat teavet, kuid tuvastamise jõudlus varieerub anomaaliate vahel ja ainult taastuvate transformaatormudelite esitused näitavad üldist teadmist anomaaliatest. Järelmeetmete analüüsid toetavad mõistet, et need mudelid võtavad kasutusele õiguspärase ja üldise lause kummalisuse mõiste, samas kui jämedamat sõna asukoha teave aitab tõenäoliselt kaasa täheldatud anomaalia tuvastamisele.', 'fi': 'Vaikka lausepoikkeamia on sovellettu ajoittain NLP:n testaukseen, ei ole vielä saatu kuvaa poikkeamatietojen tarkasta tilasta NLP:n mallien esityksissä. Tässä artikkelissa pyrimme täyttämään kaksi ensisijaista aukkoa, keskittyen syntaktisten poikkeamien alueeseen. Ensin tutkimme anomaliakoodauksen hienojakoisia eroja suunnittelemalla luotaustehtäviä, jotka vaihtelevat lauseen hierarkkista tasoa, jolla poikkeamat esiintyvät. Toiseksi testaamme paitsi mallien kykyä havaita tietty anomalia, myös havaitun anomaliasignaalin yleisyyttä tutkimalla eri anomaliatyyppien välistä siirtoa. Tulokset viittaavat siihen, että kaikki mallit koodaavat jonkin verran poikkeavuuksien havaitsemista tukevaa informaatiota, mutta havaitsemisen suorituskyky vaihtelee poikkeamien välillä, ja vain toistuvien muuntajamallien esitykset osoittavat merkkejä yleistyneestä poikkeavuuksien tuntemuksesta. Jatkoanalyysit tukevat käsitystä siitä, että nämä mallit ottavat huomioon laillisen, yleisen käsityksen lauseen outoudesta, kun taas karkeammat sanan sijaintitiedot todennäköisesti vaikuttavat myös havaittujen poikkeamien havaitsemiseen.', 'jv': 'Sampeyan ing In this paper we goal to fill 2 primary gaps, centered on the domain of concactive anamalies. Click and find out the "macro" button. Awak dhéwé, kita sampeyan akeh barêng-barêng nggawe barang-barêng nggawe ngubah winih kanggo nggawe winih dhéwé, nggawe ngubah cara-barêng langgar sampeyan karo pak sing paling maneh dumadhi. Siji-siji, kita ujian kuwi nggawe model kanggo saboh anamali sing dadi, dadi ngono generic itolakno kang sampeyan Anamali buddy ProgressBarUpdates', 'ha': "Waka da an applied nau'in zartar azãba daidai a lokacin da aka jarraba shi cikin NLP, ba mu kasa sami wani zane wa halin da inganci na tsari cikin masu motsi na NaLP. Daga wannan takardan, Munã nufin mu cika gaura biyu masu ƙaranci, kuma tuna makõmi ga dukkan surori masu taratiki. Kayyan, ko da za mu iya ƙidãya masu farin tarawa a cikin kode mai kyau ko da za'a ƙayyade aikin da za'a rarraba daraja na hierrchical da wasu abubuwan za'a fito a cikin azãba. Piki, za'a jarraba, ba za'a iya iya gane abincin misãlai kawai da za'a iya ƙidãya wata sura, kuma amma da yawan alamar da aka gane shi na dabar-dabar, kuma a jarraba transfer tsakanin nau'i-nau'in dabam'a. Matamako na gaya cewa duk misãlai sun kode wasu information, sunã ƙarani da gane ɗin surar, kuma amma gyaranin ƙogi yana sãɓã a tsakanin abubuwan, kuma yana da madaidaita kawai daga misãlai masu motsi da za'a shige sauri-sauri, suna nũna ayuka na sanar da ɗayan abubuwan. Ana ƙari-bin Ana ƙari ga zaɓe wannan misãlai da za'a sami wani fiko na halarce, mai jama'a ga haske da ɗabi'a, kuma a lokacin da aka danna cewa ma'anar maganar na kure, yana yiwuwa yana da wani mataimaki ga gane surar da aka tsare.", 'he': 'בזמן שאנומליות משפטים הופעו באופן קבוע לבדיקות ב-NLP, אנחנו עדיין צריכים לקבוע תמונה של המצב המדויק של מידע האנומלי ביציגות ממודלים NLP. בעיתון הזה אנחנו מתכוונים למלא שני פערים ראשיים, מתמקדים בתחום של anomalies סינטקטיות. ראשית, אנו חוקרים הבדלים עצומים בקוד של anomaly על ידי עיצוב משימות חקירה ששונות את רמה היררכית שבה anomalies מתרחשות במשפט. שנית, אנחנו בודקים לא רק את היכולת של דוגמנים לזהות anomaly מסוימת, אלא גם את הגנרליות של אות anomaly הזהה, על ידי לבדוק העברה בין סוגי anomaly בודדים. Results suggest that all models encode some information supporting anomaly detection, but detection performance varies between anomalies, and only representations from more re- cent transformer models show signs of generalized knowledge of anomalies.  Follow-up analyses support the notion that these models pick up on a legitimate, general notion of sentence oddity, while coarser-grained word position information is likely also a contributor to the observed anomaly detection.', 'bo': "While sentence anomalies have been applied periodically for testing in NLP, we have yet to establish a picture of the precise status of anomaly information in representations from NLP models. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་གི་ལྟ་བུའི་བར་སྟོང་གཉིས་མཇུག་འདོགས་བྱེད་ཀྱི་ཡོད། དང་པོ་ནས་འུ་ཚོས་བྱ་ཚིག Second, we test not only models' ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types. གྲུབ་འབྲས་བ་དག་གི་མིག་གཟུགས་རྣམ་གྲངས་ཀ་ལས་ཆ་འཕྲིན་གསལ་བཤད་ལ་རྒྱབ་སྐྱོར་བྱེད་ཀྱི་ཡོད་པ་དང་། རྟོགས་བཤད་ནི་གནས་ཚུལ་ཉེན་རྒྱུས་ཀྱི་རྣམ་པ་ལ་ཕར Follow-up analyses support the notion that these models pick up a legitimate, general notion of sentence oddity, while coarser-grained word position information is likely also a contributor to the observed anomaly detection.", 'sk': 'Čeprav so se anomalije stavkov redno uporabljale za testiranje v NLP, še nismo določili slike natančnega stanja informacij o anomalijah v reprezentacijah iz modelov NLP. V prispevku želimo zapolniti dve primarni vrzeli, s poudarkom na področju sintaktičnih anomalij. Najprej raziščemo drobnozrnate razlike v kodiranju anomalij z oblikovanjem opravil preiskovanja, ki spreminjajo hierarhično raven, na kateri se anomalije pojavijo v stavku. Drugič, testiramo ne le sposobnost modelov, da zaznajo dano anomalijo, temveč tudi splošnost zaznanega signala anomalije, s preučevanjem prenosa med različnimi vrstami anomalij. Rezultati kažejo, da vsi modeli kodirajo nekatere informacije, ki podpirajo odkrivanje anomalij, vendar se učinkovitost odkrivanja razlikuje med anomalijami, in samo reprezentacije iz bolj reprezentativnih transformatorskih modelov kažejo znake splošnega poznavanja anomalij. Nadaljnje analize podpirajo idejo, da ti modeli zaznavajo legitimen, splošni pojem nenavadnosti stavkov, medtem ko grobše informacije o položaju besede verjetno prispevajo tudi k odkrivanju opaženih anomalij.'}
{'en': 'Enhancing Interpretable Clauses Semantically using Pretrained Word Representation', 'ar': 'تعزيز الجمل القابلة للتفسير معنويًا باستخدام تمثيل الكلمات المحدد مسبقًا', 'pt': 'Aprimorando Cláusulas Interpretáveis Semanticamente Usando Representação de Palavras Pré-treinadas', 'es': 'Mejora semántica de las cláusulas interpretables mediante la representación de palabras preentrenada', 'fr': "Amélioration sémantique des clauses interprétables à l'aide d'une représentation de mots préentraînée", 'ru': 'Расширение интерпретируемых предложений семантически с использованием предварительно обученного представления слов', 'hi': 'Interpretable Clauses को बढ़ाना शब्दार्थ रूप से Pretrained Word Representation का उपयोग करके', 'ja': '事前に訓練された単語表現を使用して解釈可能な句を意味的に強化する', 'zh': '以豫练者单词示强于语义也', 'ga': 'Clásail Inmhínithe a Fheabhsú go Semantach ag úsáid Léiriú Focal Réamhthraenáilte', 'hu': 'Az értelmezhető záradékok javítása Szemantikus módon az előkészített szóreprezentáció használatával', 'el': 'Ενίσχυση ερμηνευτών ρήσεων Σημαντικά χρησιμοποιώντας την προκαθορισμένη αναπαράσταση λέξεων', 'ka': 'სიტყვების გამოყენება', 'it': 'Miglioramento delle clausole interpretabili Utilizzando semanticamente la rappresentazione di parole pretensionate', 'lt': 'Gerinti aiškinamąsias sąlygas Semantiškai naudojant išankstinį žodžių atstovavimą', 'kk': 'Түсіндірілген сөзді таңдау көмегімен біртінші түрлі клауларды көтеру', 'mk': 'Зголемување на интерпретабилните клаузии семантично користејќи претренирана репрезентација на зборови', 'ms': 'Meningkatkan Clause Terinterpretable Semantically using Pretrained Word Representation', 'ml': 'പഠിപ്പിക്കപ്പെട്ട വാക്ക് പ്രതിനിധിയോടെ ഉപയോഗിച്ച് വ്യാപാര്\u200dത്ഥ്യമായി പരിഭാഷപ്പെടുത്ത', 'mt': 'Titjib tal-Klawżoli Interpretabbli bl-użu Semantiku tar-Rappreżentanza tal-Kliem Mħarrġa minn Qabel', 'mn': 'Тодорхойлж боломжтой класуудыг шинэчлэх', 'pl': 'Poprawa interpretowalnych klauzul semantycznie za pomocą pretrenowanej reprezentacji słowa', 'no': 'Forstørr omsettbare klassar semantisk ved å bruka omsetjing av tekst', 'ro': 'Îmbunătățirea clauzelor interpretabile Utilizarea semantică a reprezentării cuvintelor pretinse', 'sr': 'Повећавање пременими класове семантично използвајући прекрасне речи', 'so': 'Horumarinta fasalaha turjumista ah si sinnaan ah ugu isticmaalaya hadalka u soo celinta', 'si': 'ප්\u200dරීට්\u200dරේන්ඩ් වචන ප්\u200dරතිස්ථානය භාවිත කරන්න පුළුවන් විශාලනය කරන්න', 'sv': 'Förbättra tolkningsbara klausuler Semanticly using Pretrained Word Representation', 'ur': 'پرٹرینڈ ویڈ ریسپرینٹیشن کے مطابق استعمال کرنے کے قابل تفسیر قابل کلاس', 'ta': 'முன்னேற்றப்பட்ட வார்த்தை பிரதிநிதிப்பு', 'uz': 'Name', 'vi': 'Tăng cường trình bày bí mật thành truyền từ', 'nl': 'Semantisch interpreteerbare clausules verbeteren met behulp van vooraf getrainde woordweergave', 'bg': 'Подобряване на тълкуваемите клаузи семантично, използвайки предварително изразено слово', 'da': 'Forbedring af fortolkningsable klausuler Semantisk ved hjælp af forudgående ordrepræsentation', 'id': 'Meningkatkan Klausik Terinterpretasi Semantik menggunakan Perwakilan Kata Terlatih', 'de': 'Semantische Verbesserung interpretierbarer Klauseln durch vortrainierte Wortdarstellung', 'ko': '예훈련어 표현법을 사용하여 종문의 의미를 해석할 수 있도록 강화하다', 'hr': 'Povećavanje razumljivih klauzula Semantički upotrebljavajući predstavu predstavljenih riječi', 'fa': 'افزایش کلاس\u200cهای قابل تفصیل با استفاده از نمایش کلمه\u200cهای پیشرین', 'sw': 'Kuboresha Makala ya Tafsiri kwa kutumia Tayari ya Tayarishwa', 'af': 'Verbeter Interpretable Klasse Semantiese deur te gebruik Pretrained Word Representation', 'am': 'Interpretable Clauses Semantically using Pretrained Word Representation', 'hy': 'Enhancing Interpretable Clauses Semantically using Pretrained Word Representation', 'tr': 'Pretrained Word representation', 'bn': 'প্রশিক্ষিত শব্দ প্রতিনিধি ব্যবহার করে অনুবাদ করা ক্লাস সেম্যান্ডিকভাবে বৃদ্ধি করা হচ্ছে', 'bs': 'Povećavanje razumljivih klauzula Semantički upotrebljavajući predstavu predstavljenih riječi', 'cs': 'Zlepšení interpretovatelných klauzulí sémanticky pomocí předtrénované reprezentace slov', 'et': 'Tõlgendatavate klauslite parandamine semantiliselt eeltreenitud sõna esindamise abil', 'ca': 'millorar les clàusules interpretables Semàticament fent servir la representació de paraules pretrained', 'fi': 'Tulkittavien lausekkeiden parantaminen semanttisesti käyttämällä ennalta suunniteltua sanaesitystä', 'sq': 'Përmirësimi i dispozitave të interpretueshme duke përdorur në mënyrë Semantike përfaqësimin e fjalëve të paramësuara', 'az': 'S…ôf…ôrl…ônmiŇü Kelimi S…ôf…ôrl…ôndirm…ôsini Semantik olaraq ∆Źlav…ô Et', 'jv': 'Ngubah Yukono Keterangan', 'sk': 'Izboljšanje razložljivih klavzul semantično z uporabo predvajanja besed', 'ha': '@ action', 'bo': 'རྒྱ་མཚོར་སྟངས་ཅན་གྱི་སྔོན་སྒྲིག་ཚོགས་མཚོན་རྟགས་སྤྱོད་བཞིན་པའི་དབྱེ་རིགས་སྔོན་སྒྲིག་བཞིན་པ', 'he': 'Enhancing Interpretable Clauses Semantically using Pretrained Word Representation'}
{'en': 'Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based on propositional logic, which has demonstrated competitive performance in many Natural Language Processing (NLP) tasks, including sentiment analysis, text classification, and Word Sense Disambiguation. To obtain human-level interpretability, legacy TM employs Boolean input features such as bag-of-words (BOW). However, the BOW representation makes it difficult to use any pre-trained information, for instance, word2vec and GloVe word representations. This restriction has constrained the performance of TM compared to deep neural networks (DNNs) in NLP. To reduce the performance gap, in this paper, we propose a novel way of using pre-trained word representations for TM. The approach significantly enhances the performance and interpretability of TM. We achieve this by extracting semantically related words from pre-trained word representations as input features to the TM. Our experiments show that the accuracy of the proposed approach is significantly higher than the previous BOW-based TM, reaching the level of DNN-based models.', 'ar': 'Tsetlin Machine (TM) هي خوارزمية للتعرف على الأنماط يمكن تفسيرها بناءً على المنطق الافتراضي ، والتي أظهرت أداءً تنافسيًا في العديد من مهام معالجة اللغة الطبيعية (NLP) ، بما في ذلك تحليل المشاعر وتصنيف النص وتوضيح معنى الكلمات. للحصول على إمكانية تفسير على مستوى الإنسان ، تستخدم ذاكرة الترجمة القديمة ميزات إدخال منطقية مثل حقيبة الكلمات (BOW). ومع ذلك ، فإن تمثيل BOW يجعل من الصعب استخدام أي معلومات مُدربة مسبقًا ، على سبيل المثال ، تمثيلات word2vec و GloVe. أدى هذا التقييد إلى تقييد أداء TM مقارنة بالشبكات العصبية العميقة (DNNs) في البرمجة اللغوية العصبية. لتقليل فجوة الأداء ، في هذه الورقة ، نقترح طريقة جديدة لاستخدام تمثيلات الكلمات المدربة مسبقًا لـ TM. النهج يعزز بشكل كبير أداء وقابلية تفسير TM. نحقق ذلك من خلال استخراج الكلمات ذات الصلة لغويًا من تمثيلات الكلمات المدربة مسبقًا كميزات إدخال إلى TM. تُظهر تجاربنا أن دقة النهج المقترح أعلى بكثير من دقة TM القائمة على BOW السابقة ، حيث وصلت إلى مستوى النماذج المستندة إلى DNN.', 'fr': "Tsetlin Machine (TM) est un algorithme de reconnaissance de formes interprétable basé sur la logique propositionnelle, qui a démontré des performances concurrentielles dans de nombreuses tâches de traitement du langage naturel (NLP), y compris l'analyse des sentiments, la classification de texte et la désambiguïsation Word Sense. Pour obtenir une interprétabilité au niveau humain, Legacy TM utilise des fonctionnalités d'entrée booléennes telles que le sac de mots (BOW). Cependant, la représentation BOW rend difficile l'utilisation d'informations préentraînées, par exemple les représentations de mots word2vec et Glove. Cette restriction a limité les performances de la MT par rapport aux réseaux de neurones profonds (DNN) dans la PNL. Pour réduire l'écart de performance, nous proposons dans cet article une nouvelle façon d'utiliser des représentations de mots préentraînées pour la MT. L'approche améliore considérablement les performances et l'interprétabilité de la MT. Nous y parvenons en extrayant des mots sémantiquement apparentés à partir de représentations de mots pré-entraînées en tant qu'entités d'entrée dans la MT. Nos expériences montrent que la précision de l'approche proposée est nettement supérieure à celle de la MT basée sur BoW précédente, atteignant le niveau des modèles basés sur DNN.", 'pt': 'Tsetlin Machine (TM) é um algoritmo de reconhecimento de padrões interpretável baseado em lógica proposicional, que demonstrou desempenho competitivo em muitas tarefas de Processamento de Linguagem Natural (NLP), incluindo análise de sentimento, classificação de texto e Desambiguação de Sentido de Palavras. Para obter interpretabilidade em nível humano, a TM legada emprega recursos de entrada booleanos, como bag-of-words (BOW). No entanto, a representação BOW dificulta o uso de qualquer informação pré-treinada, por exemplo, representações de palavras word2vec e GloVe. Essa restrição restringiu o desempenho da TM em comparação com as redes neurais profundas (DNNs) em NLP. Para reduzir a lacuna de desempenho, neste artigo, propomos uma nova maneira de usar representações de palavras pré-treinadas para TM. A abordagem melhora significativamente o desempenho e a interpretabilidade da TM. Conseguimos isso extraindo palavras semanticamente relacionadas de representações de palavras pré-treinadas como recursos de entrada para a TM. Nossos experimentos mostram que a precisão da abordagem proposta é significativamente maior do que a TM anterior baseada em BOW, atingindo o nível dos modelos baseados em DNN.', 'es': 'Tsetlin Machine (TM) es un algoritmo de reconocimiento de patrones interpretable basado en la lógica proposicional, que ha demostrado un rendimiento competitivo en muchas tareas de procesamiento del lenguaje natural (NLP), incluidos el análisis de sentimientos, la clasificación de textos y la desambiguación del sentido de las palabras. Para obtener una interpretabilidad a nivel humano, la TM heredada emplea funciones de entrada booleanas como bolsa de palabras (BOW). Sin embargo, la representación BOW dificulta el uso de cualquier información previamente entrenada, por ejemplo, las representaciones de palabras word2vec y GLOe. Esta restricción ha limitado el rendimiento de la MT en comparación con las redes neuronales profundas (DNN) en la PNL. Para reducir la brecha de rendimiento, en este artículo proponemos una forma novedosa de utilizar representaciones de palabras previamente entrenadas para la MT. El enfoque mejora significativamente el rendimiento y la interpretabilidad de la MT. Lo logramos extrayendo palabras relacionadas semánticamente de representaciones de palabras previamente entrenadas como características de entrada a la memoria de traducción. Nuestros experimentos muestran que la precisión del enfoque propuesto es significativamente mayor que la del TM anterior basado en BOW, alcanzando el nivel de los modelos basados en DNN.', 'ja': 'Tsetlin Machine （ TM ）は、命題論理に基づいた解釈可能なパターン認識アルゴリズムであり、センチメント分析、テキスト分類、ワードセンスの曖昧さ解消など、多くの自然言語処理（ NLP ）タスクで競争力のあるパフォーマンスを実証しています。 人間レベルの解釈可能性を得るために、レガシーTMは、バッグ・オブ・ワード（ BOW ）などのブール入力機能を採用しています。 しかしながら、弓の表現は、任意の事前に訓練された情報、例えば、word 2 vecおよびGloVe単語表現を使用することを困難にする。 この制限は、ＮＬＰにおける深層ニューラルネットワーク（ ＤＮＮ ）と比較して、ＴＭの性能を制約している。 パフォーマンスギャップを減らすために、本稿では、事前にトレーニングされた単語表現をTMに使用する新しい方法を提案する。 このアプローチは、TMのパフォーマンスと解釈性を大幅に向上させます。 私たちは、事前にトレーニングされた単語表現からTMへの入力機能として意味的に関連する単語を抽出することによってこれを達成します。 我々の実験は、提案されたアプローチの精度が以前のBOWベースのTMよりも著しく高く、DNNベースのモデルのレベルに達することを示している。', 'ru': 'Tsetlin Machine (TM) - это интерпретируемый алгоритм распознавания образов, основанный на пропозиционной логике, который продемонстрировал конкурентоспособную производительность во многих задачах обработки естественного языка (NLP), включая анализ настроений, классификацию текста и расчленение смысла слова. Для получения интерпретируемости на человеческом уровне, Legacy TM использует булевы входные функции, такие как Bag-of-Words (BOW). Тем не менее, НОСОВОЕ представление затрудняет использование любой предварительно обученной информации, например, словесных представлений word2vec и GloVe. Это ограничение ограничило производительность TM по сравнению с глубокими нейронными сетями (DNN) в NLP. Чтобы уменьшить разрыв в производительности, в этой статье мы предлагаем новый способ использования предварительно обученных представлений слов для TM. Данный подход значительно повышает производительность и интерпретируемость ТМ. Мы достигаем этого, извлекая семантически связанные слова из предварительно обученных представлений слов в качестве входных признаков для TM. Наши эксперименты показывают, что точность предлагаемого подхода значительно выше, чем предыдущая ТМ на основе BOW, достигая уровня моделей на основе DNN.', 'zh': 'Tsetlin Machine(TM)者,盖命题逻辑可解模式识别算法,于诸自然语言处之(NLP)务见竞性,情析文字感消歧义。 所以得人伦之可解释性, TM 用布尔输功能,如词袋 (BOW)。 然BOW示难用,如word2vecGloVe单词。 比于NLP之深神经网络(DNN),限TM之性也。 为缩小性能相去,本文立TM预训练词新法。 其法著于 TM 性可解释性。 以预练之单词言义相关者单词为TM输特徵以成之。 臣等实验明,精明于前BOWTM,至于DNN之水平。', 'hi': 'Tsetlin Machine (TM) प्रस्तावात्मक तर्क पर आधारित एक व्याख्यायोग्य पैटर्न मान्यता एल्गोरिथ्म है, जिसने कई प्राकृतिक भाषा प्रसंस्करण (NLP) कार्यों में प्रतिस्पर्धी प्रदर्शन का प्रदर्शन किया है, जिसमें भावना विश्लेषण, पाठ वर्गीकरण और वर्ड सेंस बहुविकल्पित शामिल हैं। मानव-स्तरीय interpretability प्राप्त करने के लिए, विरासत TM बूलियन इनपुट सुविधाओं जैसे बैग-ऑफ-वर्ड्स (BOW) को नियोजित करता है। हालांकि, BOW प्रतिनिधित्व किसी भी पूर्व-प्रशिक्षित जानकारी का उपयोग करना मुश्किल बनाता है, उदाहरण के लिए, word2vec और GloVe शब्द प्रतिनिधित्व। इस प्रतिबंध ने एनएलपी में गहरे तंत्रिका नेटवर्क (डीएनएन) की तुलना में टीएम के प्रदर्शन को बाधित किया है। प्रदर्शन अंतर को कम करने के लिए, इस पेपर में, हम टीएम के लिए पूर्व-प्रशिक्षित शब्द प्रतिनिधित्व का उपयोग करने का एक उपन्यास तरीका प्रस्तावित करते हैं। दृष्टिकोण टीएम के प्रदर्शन और व्याख्याक्षमता को काफी बढ़ाता है। हम टीएम के लिए इनपुट सुविधाओं के रूप में पूर्व-प्रशिक्षित शब्द प्रतिनिधित्व से शब्दार्थ से संबंधित शब्दों को निकालकर इसे प्राप्त करते हैं। हमारे प्रयोगों से पता चलता है कि प्रस्तावित दृष्टिकोण की सटीकता पिछले बीओ-आधारित टीएम की तुलना में काफी अधिक है, जो डीएनएन-आधारित मॉडल के स्तर तक पहुंचती है।', 'ga': 'Is algartam aitheantais patrún inmhínithe é Tsetlin Machine (TM) atá bunaithe ar an loighic tairisceana, a bhfuil feidhmíocht iomaíoch léirithe aige i go leor tascanna Próiseála Teanga Nádúrtha (NLP), lena n-áirítear anailís meon, aicmiú téacs, agus Disathbhríocht Word Sense. Chun inléirmhíniú ar leibhéal an duine a fháil, úsáideann oidhreacht TM gnéithe ionchuir Boole mar mála focal (BOW). Mar sin féin, déanann an léiriú BOW sé deacair aon fhaisnéis réamh-oilte a úsáid, mar shampla, léiriúcháin focal word2vec agus GloVe. Chuir an srian seo srian ar fheidhmíocht TM i gcomparáid le líonraí néaracha doimhne (DNNanna) in NLP. Chun an bhearna feidhmíochta a laghdú, molaimid sa pháipéar seo bealach nua chun léirithe focal réamhoilte a úsáid le haghaidh TM. Cuireann an cur chuige seo go mór le feidhmíocht agus inléirmhíniú TM. Bainimid é seo amach trí fhocail atá gaolmhar le séimeantach a bhaint as léiriúcháin focal réamhoilte mar ghnéithe ionchuir don TM. Léiríonn ár dturgnaimh go bhfuil cruinneas an chur chuige atá beartaithe i bhfad níos airde ná an TM BOW-bhunaithe roimhe seo, ag teacht ar leibhéal na samhlacha atá bunaithe ar DNN.', 'ka': 'Name რომ ადამიანის განსხვავებელობა მიიღებთ, TM იყენებს ბულიანური შეტყობინება, როგორც სიტყვების ფანტი (BOW). მაგრამ, BOW-ს გამოსახულება უფრო რთულია გამოიყენოთ ყველა წინ განაკეთებული ინფორმაცია, მაგალითად, სიტყვა 2vec და Glove სიტყვას გამოსახულება. ეს დაზრუქმება TM-ის გამოსახულებას NLP-ში შედგომარებული ნეიროლური ქსელებისთვის (DNN). რომელიც გამოყენებული სიტყვების გამოყენება TM-ის პრომენტის გამოყენება. პროგრამა მნიშვნელოვანად გაუქმედება TM-ის პროგრამეტს და ინტერპუქცია. ჩვენ ამას მივიღეთ სენმანტიკურად დაკავშირებული სიტყვების გამოყენებით, როგორც TM-ს დაკავშირებული სიტყვების გამოყენება. ჩვენი ექსპერიმენტები გამოჩვენება, რომ პირველი პროგრამის წარმოდგენისთვის წარმოდგენისთვის უფრო მეტია, ვიდრე პირველი BOW-დაბათი TM-დან, რომელიც DNN-დაბათი', 'hu': 'A Tsetlin Machine (TM) egy értelmezhető mintafelismerő algoritmus, amely számos természetes nyelvfeldolgozási (NLP) feladatban bizonyított versenyképes teljesítményt, beleértve az érzelmek elemzését, a szövegosztályozást és a Word Sense Disambiguation feladatokat. Az emberi szintű értelmezhetőség elérése érdekében a hagyományos TM boolean bemeneti funkciókat alkalmaz, mint például a szavak zsákja (BOW). A BOW ábrázolás azonban megnehezíti az előre képzett információk használatát, például a word2vec és a GloVe szóreprezentációkat. Ez a korlátozás korlátozta a TM teljesítményét a mély neurális hálózatokhoz (DNN) képest az NLP-ben. A teljesítmény hiányának csökkentése érdekében ebben a tanulmányban egy új módszert javasolunk a TM előzetesen képzett szóreprezentációjának használatára. A megközelítés jelentősen javítja a TM teljesítményét és értelmezhetőségét. Ezt úgy érjük el, hogy szemantikailag kapcsolódó szavakat kivonunk az előkészített szóreprezentációkból, mint bemeneti funkciókat a TM-be. Kísérleteink azt mutatják, hogy a javasolt megközelítés pontossága jelentősen magasabb, mint a korábbi BOW alapú TM, elérve a DNN alapú modellek szintjét.', 'el': 'Η μηχανή είναι ένας ερμηνευτικός αλγόριθμος αναγνώρισης μοτίβων βασισμένος στη λογική προτάσεων, ο οποίος έχει αποδείξει ανταγωνιστική απόδοση σε πολλές εργασίες επεξεργασίας φυσικής γλώσσας, συμπεριλαμβανομένης της ανάλυσης συναισθημάτων, της ταξινόμησης κειμένου και της αποσαφήνισης της αίσθησης λέξεων. Για να επιτευχθεί ερμηνευσιμότητα σε ανθρώπινο επίπεδο, το παλαιό σύστημα χρησιμοποιεί Boolean χαρακτηριστικά εισαγωγής, όπως το σάκο λέξεων (BOW). Ωστόσο, η αναπαράσταση του BOW καθιστά δύσκολη τη χρήση οποιωνδήποτε προ-εκπαιδευμένων πληροφοριών, για παράδειγμα, των αναπαραστάσεων λέξεων word2vec και GloVe. Αυτός ο περιορισμός έχει περιορίσει την απόδοση του TM σε σύγκριση με τα βαθιά νευρωνικά δίκτυα (DNN) στο NLP. Για να μειωθεί το χάσμα απόδοσης, σε αυτή την εργασία, προτείνουμε έναν νέο τρόπο χρήσης προ-εκπαιδευμένων αναπαραστάσεων λέξεων για την TM. Η προσέγγιση ενισχύει σημαντικά την απόδοση και την ερμηνεία του ΤΜ. Αυτό το επιτυγχάνουμε εξάγοντας σημασιολογικά σχετιζόμενες λέξεις από προ-εκπαιδευμένες αναπαραστάσεις λέξεων ως χαρακτηριστικά εισόδου στο TM. Τα πειράματά μας δείχνουν ότι η ακρίβεια της προτεινόμενης προσέγγισης είναι σημαντικά υψηλότερη από την προηγούμενη με βάση το ΔΝ, φτάνοντας στο επίπεδο των μοντέλων που βασίζονται στο ΔΝ.', 'it': "Tsetlin Machine (TM) è un algoritmo di riconoscimento dei pattern interpretabile basato sulla logica proposizionale, che ha dimostrato prestazioni competitive in molte attività di elaborazione del linguaggio naturale (NLP), tra cui l'analisi del sentiment, la classificazione del testo e la disambiguazione del senso della parola. Per ottenere l'interpretabilità a livello umano, legacy TM utilizza funzionalità di input booleano come bag-of-words (BOW). Tuttavia, la rappresentazione BOW rende difficile utilizzare qualsiasi informazione pre-addestrata, ad esempio, le rappresentazioni di parole word2vec e GloVe. Questa restrizione ha limitato le prestazioni della TM rispetto alle reti neurali profonde (DNN) nella PNL. Per ridurre il gap prestazionale, in questo articolo, proponiamo un nuovo modo di utilizzare rappresentazioni di parole pre-addestrate per TM. L'approccio migliora significativamente le prestazioni e l'interpretabilità della TM. Otteniamo questo risultato estraendo parole semanticamente correlate da rappresentazioni di parole pre-addestrate come caratteristiche di input alla TM. I nostri esperimenti dimostrano che l'accuratezza dell'approccio proposto è significativamente superiore alla precedente TM basata su BOW, raggiungendo il livello dei modelli basati su DNN.", 'lt': 'Tsetlin Machine (TM) yra aiškinamasis modelių pripažinimo algoritmas, pagrįstas siūloma logika, kuris parodė konkurencinį veiksmingumą daugelyje gamtinių kalbų apdorojimo (NLP) užduočių, įskaitant jausmų analizę, teksto klasifikaciją ir žodžių jausmų nedviprasmiškumą. Kad būtų galima aiškinti žmogaus lygiu, tradicinis TM naudoja Boolean įvesties savybes, pvz., žodžių maišelį (BOW). Tačiau dėl BOW atstovavimo sunku naudoti bet kokią iš anksto parengtą informaciją, pavyzdžiui, žodžių 2vec ir GloVe žodžių atstovavimus. Šis apribojimas apribojo TM veiksmingumą, palyginti su giliais nerviniais tinklais (DNN) NLP. To reduce the performance gap, in this paper, we propose a novel way of using pre-trained word representations for TM.  Metodas gerokai padidina TM veiksmingumą ir aiškinamumą. Mes tai siekiame ištraukdami semantiškai susijusius žodžius iš iš iš anksto apmokytų žodžių atstovavimų kaip įėjimo į TM savybes. Mūsų eksperimentai rodo, kad siūlomo metodo tikslumas yra gerokai didesnis nei ankstesnis BOW pagrįstas TM, pasiekęs DNN pagrįstų modelių lygį.', 'kk': 'Tsetlin Machine (TM) бұл келесі логика негізінде орналасатын үлгі анықтау алгоритмі. Бұл көптеген Түзіндік тіл процессері (NLP) тапсырмалардың көптеген әрекеттерін көрсетеді, мәтін классификациясы және Word Sense Disambiguation тапсырмаларды қоса,  Адам деңгейінің түсініктемесін жеткізу үшін, TM жұмыс істеу үшін, мәтін сөздер (BOW) сызығындағы Boolean келтіру мүмкіндіктерін қолданады. Бірақ BOW- тың таңбашасы келген алдын- оқылған мәліметті қолдану қиын болады, мысалы, сөздер2vec және Glove- тің сөздерін көрсету үшін. Бұл шектеу NLP- де TM жылдамдығын қалыпты невралдық желілерімен (DNN) салыстырып тұрған. Бұл қағаздың орындалығын азайту үшін, біз TM үшін алдын- оқылған сөздердің түсініктемелерін қолданатын романдық жолын таңдаймыз. Бұл тәсілі ТМ жұмысын және түсініктемесін өзгертеді. Біз бұны TM-нің келтіру мүмкіндіктері ретінде семантикалық сөздерді алдын- оқылған сөздерден шығару арқылы жеткіземіз. Біздің тәжірибеміз келтірілген тәжірибенің дұрыстығы алдыңғы BOW негізінде тәжірибе тәжірибесінен артық, DNN негізінде тәжірибесінің деңгейіне жеткізеді.', 'ms': 'Mesin Tsetlin (TM) adalah algoritma pengenalan corak yang boleh ditafsirkan berdasarkan logik tawaran, yang telah menunjukkan prestasi kompetitif dalam ramai tugas Proses Bahasa Alami (NLP), termasuk analisis sentimen, klasifikasi teks, dan Pemindahan Sensa Perkataan. Untuk mendapatkan pengenalan aras manusia, warisan TM menggunakan ciri-ciri input Boolean seperti beg-of-words (BOW). Namun, perwakilan BOW membuat ia sukar untuk menggunakan mana-mana maklumat terlatih, misalnya, perwakilan kata word2vec dan GloVe. Hadangan ini telah mengurangi prestasi TM dibandingkan dengan rangkaian saraf dalam (DNN) dalam NLP. Untuk mengurangi ruang prestasi, dalam kertas ini, kami cadangkan cara baru untuk menggunakan persembahan perkataan terlatih-terlatih untuk TM. pendekatan meningkatkan prestasi dan interpretabiliti TM secara signifikan. We achieve this by extracting semantically related words from pre-trained word representations as input features to the TM.  Eksperimen kami menunjukkan bahawa ketepatan pendekatan yang direncanakan jauh lebih tinggi daripada TM berdasarkan BOW sebelumnya, mencapai aras model berdasarkan DNN.', 'mk': 'Цетлин машина (TM) е алгоритм за претпоставување на шаблони базиран на предложна логика, кој покажа конкурентна резултат во многу задачи за процес на природен јазик (NLP), вклучително и анализа на чувствата, класификација на текстот и раздвојување на зборовите чувства. За да се добие интерпретабилност на човечко ниво, наследството TM користи булеански внесувачки карактеристики како што се вреќата на зборови (BOW). Сепак, претставувањето на BOW го прави тешко користењето на било какви предобучени информации, на пример word2vec и GloVe зборови претставувања. This restriction has constrained the performance of TM compared to deep neural networks (DNNs) in NLP.  За да ја намалиме празнината во изведувањето, во овој весник предложуваме нов начин за користење предобучени репрезентации на зборови за ТМ. Пристапот значително ја подобрува резултатот и интерпретабилноста на ТМ. Ние го постигнуваме ова со извлекување семантично поврзани зборови од предобучени репрезентации на зборови како влезни карактеристики на ТМ. Нашите експерименти покажуваат дека точноста на предложениот пристап е значително повисока од претходниот ТМ базиран на БОВ, достигнувајќи го нивото на модели базирани на ДНН.', 'ml': 'സെറ്റ്ലിന്\u200d യന്ത്രം (ടിഎം) പ്രാന്തികമായ ലോഗിക്ക് അടിസ്ഥാനമായി തിരിച്ചറിയാനുള്ള ഒരു മാതൃകയാണു് തിരിച്ചറിയാനുള്ള ആല്\u200dഗോരിതം എന്നതാണു്. അത് സ്വാഭാവിക ഭാഷ പ്രവര്\u200dത് മനുഷ്യരുടെ നില വ്യാഖ്യാനം ലഭ്യമാക്കാന്\u200d ടിഎം ബൂലിയന്\u200d ഇന്\u200dപുട്ടിന്\u200dറെ വിശേഷതകള്\u200d ബാഗ്- ഓഫ് വാക്കുകള്\u200d പോലെ ഉപയോഗി എങ്കിലും ബോവ് പ്രതിനിധിയില്\u200d പഠിപ്പിക്കപ്പെട്ട വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നത് പ്രയാസകരമാണ്. ഉദാഹരണത്തിനായി വാര്\u200dഡ്2വിക് ഈ പരിധിയില്\u200d NLP-ല്\u200d ആഴമുള്ള ന്യൂറല്\u200d ശൃംഖലകളുടെ (DNNs) കൂടുതല്\u200d ടിഎം പ്രവര്\u200dത്തനത്തെ തടഞ്ഞിരിക്കുന്നു. ഈ പത്രത്തില്\u200d പ്രകടന വ്യത്യാസം കുറയ്ക്കാന്\u200d, ടിഎമിന് മുന്\u200dപ് പരിശീലന വാക്കുകളുടെ പ്രതിനിധികള്\u200d ഉപയോഗിക്കുന്ന നോവല ടിഎമിന്റെ പ്രദര്\u200dശനവും വ്യാഖ്യാനവും വളര്\u200dത്തുന്നു. മുമ്പ് പഠിപ്പിക്കപ്പെട്ട വാക്കുകളില്\u200d നിന്നും സെമാന്റിക്കല്\u200d ബന്ധപ്പെട്ട വാക്കുകള്\u200d ടിഎമിലേക്ക് പുറത്തെട നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു പ്രൊദ്ദേശിക്കപ്പെട്ട പ്രോഗത്തിന്\u200dറെ അടിസ്ഥാനത്തെക്കാള്\u200d മുന്\u200dപ് BOW', 'mn': 'Tsetlin Machine (TM) гэдэг бол санал нийтийн логикийн үндсэн дүрслэл ойлгох алгоритм юм. Энэ нь Байгалийн хэл Процессорын (NLP) олон даалгаврын даалгаврын даалгаврын үйл ажиллагаанд өрсөлдөг үйл ажиллагааг харуулсан. Хүн төвшин түвшинд илэрхийлж чадах боломжтой байдлыг олгохын тулд, TM нь буулийн өгөгдлийн шинж чанарыг (BOW) ашигладаг. Гэвч BOW-ын илтгэл нь ямар ч урд сургалтын мэдээллийг ашиглах хэцүү болгодог. Жишээ нь, үг 2vec болон Glove үг илтгэлийг ашиглах нь хэцүү. Энэ хязгаар нь TM-ын үйл ажиллагааг NLP-ын гүн гүнзгий мэдрэлийн сүлжээнтэй харьцуулахад хязгаарлагддаг. Энэ цаасан дээр үйл ажиллагааны ялгааг багасгахын тулд бид TM-д сургалтын өмнө сургалтын үг илтгэлээ ашиглах шинэ арга зам өгдөг. Энэ арга барилга нь ТМ-ийн үйл ажиллагаа болон түүхийн чадварыг нэмэгдүүлнэ. Бид үүнийг өмнө сургалтын үг илтгэлээс холбоотой үгсийг TM-д оруулах боломжтой болгон гаргаж чадна. Бидний туршилтууд санал өгсөн арга загварын тодорхойлолт нь өмнөх BOW-д суурилсан TM-ээс илүү өндөр байдаг гэдгийг харуулж байна.', 'no': 'Tsetlin-maskin (TM) er ein tolkbare mønsterkjengsalgoritme basert på foreslåande logikk, som har demonstrert konkurentivt utvikling i mange naturspråk-handsamar (NLP) oppgåver, inkludert sentimentanalyse, tekstklassifikasjon og word-senteringsutvikling. For å få tolkingsfeilighet på menneskelivået brukar TM Boolske inndata-funksjonar som bag-of-words (BOW). Men BOW-representasjonen gjer det vanskeleg å bruka alle føretrainerte informasjonar, for eksempel ordrepresentasjonar med 2vec og Glove. Denne avgrensinga har begrenset utviklinga av TM samanlikna med dype neuralnettverk (DNN) i NLP. For å redusera utgangspunktet, i denne papiret foreslår vi ein novel måte å bruka føretrainerte ordrepresentasjonar for TM. Tilnærminga styrer betydelig utviklinga og interpreteringa av TM. Vi oppnår dette ved å pakka ut semantisk relaterte ord frå føretrainerte ordrepresentasjonar som innskriftsfunksjonar til TM. Eksperimentane våre viser at nøyaktigheten av den foreslåde tilnærming er betydelig høgare enn den førre BOW-baserte TM, som når nivået på DNN-baserte modeller.', 'pl': 'Tsetlin Machine (TM) to interpretowalny algorytm rozpoznawania wzorców oparty na logice propozycji, który wykazał konkurencyjną wydajność w wielu zadaniach przetwarzania języka naturalnego (NLP), w tym analizy sentymentów, klasyfikacji tekstu i dyambiguacji zmysłu Word Sense. Aby uzyskać interpretację na poziomie człowieka, starszy TM wykorzystuje funkcje wejściowe Boolean, takie jak worek słów (BOW). Jednak reprezentacja BOW utrudnia użycie wstępnie przeszkolonych informacji, na przykład reprezentacji słów Word2vec i GloVe. Ograniczenie to ograniczyło wydajność TM w porównaniu z głębokimi sieciami neuronowymi (DNN) w NLP. Aby zmniejszyć lukę w wydajności, w niniejszym artykule proponujemy nowy sposób wykorzystania wstępnie przeszkolonych reprezentacji słów dla TM. Podejście to znacząco zwiększa wydajność i interpretowalność TM. Osiągamy to poprzez ekstrakcję semantycznie powiązanych słów z wstępnie przeszkolonych reprezentacji słów jako funkcji wejściowych do TM. Nasze eksperymenty pokazują, że dokładność proponowanego podejścia jest znacznie wyższa niż poprzednie TM oparte na BOW, osiągając poziom modeli opartych na DNN.', 'ro': 'Tsetlin Machine (TM) este un algoritm de recunoaștere a modelelor interpretabil bazat pe logica propozițională, care a demonstrat performanțe competitive în multe sarcini de procesare a limbajului natural (NLP), inclusiv analiza sentimentului, clasificarea textului și dezambiguizarea simțului cuvântului. Pentru a obține interpretabilitatea la nivel uman, TM legacy utilizează caracteristici de intrare booleană, cum ar fi bag-of-words (BOW). Cu toate acestea, reprezentarea BOW face dificilă utilizarea oricărei informații pre-instruite, de exemplu, reprezentări word2vec și GloVe cuvinte. Această restricție a constrâns performanța TM în comparație cu rețelele neuronale profunde (DNN) în PNL. Pentru a reduce decalajul de performanță, în această lucrare, propunem o modalitate nouă de utilizare a reprezentărilor de cuvinte pre-instruite pentru TM. Abordarea îmbunătățește semnificativ performanța și interpretabilitatea TM. Realizăm acest lucru prin extragerea cuvintelor legate semantic din reprezentările de cuvinte pre-instruite ca caracteristici de intrare în TM. Experimentele noastre arată că acuratețea abordării propuse este semnificativ mai mare decât TM bazată pe BOW anterior, atingând nivelul modelelor bazate pe DNN.', 'sr': 'Tsetlin Machine (TM) je algoritam prepoznavanja obrazaca koji se temelji na predloženoj logici, koji je pokazao konkurentnu funkciju u mnogim zadacima prirodnog procesa jezika (NLP), uključujući analizu sentimenta, klasifikaciju teksta i Disambiguaciju osjećaja riječi. Da bi dobila interpretabilnost na ljudskom nivou, nasljednost TM koristi Booleanske karakteristike kao što su vrećice reči (BOW). Međutim, predstavljanje BOW-a teško je iskoristiti bilo kakve predobučene informacije, na primer, rečenice 2vec i Glove riječi. Ova ograničenja ograničava učinku TM u usporedbi sa dubokim nervnim mrežama (DNN) u NLP-u. Da bismo smanjili prazninu izvedbe, u ovom papiru predlažemo novi način da koristimo predobučene reči predstave za TM. Pristup značajno povećava učinkovitost i interpretabilnost TM. To postižemo izvlačenjem semantički povezanih reèi iz predobučenih reèi kao ulazne karakteristike TM-a. Naši eksperimenti pokazuju da je preciznost predloženog pristupa značajno veća od prethodnog TM-a na BOW-u, koji postiže nivo modela na DNN-u.', 'so': 'Mashinka Tsetlin (TM) waa qoraalka aqoonsashada qaababka lagu turjumo oo ku saleysan qoraalka la soo jeedo, kaas oo muujiyay shaqooyin ku saabsan qabashada afka asalka ah (NLP) oo badan, kuwaas oo ah baaritaanka maandooriyaha, kalajarida qoraalka, iyo kalajarida Sense. Si uu u helo turjubaan heerka dadka, dhaxalka TM wuxuu u shaqeeyaa boolean input, sida bag-of-words (BOW). Si kastaba ha ahaatee wakiilka BOW waxay adag tahay in ay isticmaalaan macluumaad la xiriira horay loo tababaray, tusaale ahaan hadal 2vec iyo GloVe. Qasabkaasi waxay ku qasbay sameynta TM oo la barbardhigay shabakado aad u weyn oo neurada (DNNs) ee NLP. To reduce the performance gap, in this paper, we propose a novel way of using pre-trained word representations for TM.  Dhaqdhaqaaqa ayaa si weyn u kordhiya sameynta iyo turjubaanka TM. Waxan waxan ayaannu ku gaadhnaa markaan ka soo bixino hadal la xidhiidha ah oo ka mid ah macluumaadka hadalka horay loo tababaray sida xariijiyada TM. Imtixaankayada waxay muuqataa in saxda qaababka la soo jeeday ay aad uga sarraysaa TM-kii hore ee BOW-based, oo gaadha heerka modellada DNN-ka-based.', 'si': 'Tsetlin maquin (TM) is a transversal pattern atzout algolorithm based on the preaching Logic, that has showned a Competitive Perfection in a lot of Native language processing (NLP) Jobs, incl. Sentment testing, text classification, and Word Sense Desmbguation. මිනිස්සු ස්තූතිය අභිවාදයක් ලැබෙන්න, legality TM බූලියන් ඇතුළත් අභිවාදයක් භාවිත කරනවා වගේ බෑග් වචන ( නමුත්, BOW ප්\u200dරතිනිධානය ඒක අමාරුයි, ප්\u200dරධානය කරන්න පුළුවන් තොරතුරු භාවිත කරන්න, උදාහරණයෙන්, වචන 2Vec සහ Glove Name මේ පත්තරේ ප්\u200dරශ්නයක් අඩුවෙන්න, අපි TM වෙනුවෙන් ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරන්න පුළුවන් විදිහක් ප්\u200dරයෝජනය ප්\u200dරවේශනය විශේෂයෙන් ප්\u200dරවේශනය සහ ප්\u200dරවේශනය වැඩි කරනවා. අපි මේක පුළුවන් වෙන්නේ පුරුද්ගලික වාර්තාවෙන් පුරුද්ගලික වාර්තාවෙන් පුරුද්ගලික වාර්තාවෙන් පුළ අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට ප්\u200dරතිචාරණයේ ප්\u200dරතිචාරයක් ප්\u200dරතිචාර විදිහට වඩා විශේෂයෙන් වඩා වඩා උඩ', 'sv': 'Tsetlin Machine (TM) ﾃ､r en tolkningsbar mﾃｶnsterigenkﾃ､nningsalgoritm baserad pﾃ･ propositionslogik, som har visat konkurrenskraftig prestanda i mﾃ･nga Natural Language Processing (NLP) uppgifter, inklusive sentimental analys, textklassificering och Word Sense Disambiguation. Fﾃｶr att uppnﾃ･ tolkning pﾃ･ mﾃ､nsklig nivﾃ･ anvﾃ､nder legacy TM booleska inmatningsfunktioner som bag-of-words (BOW). BOW-representationen gﾃｶr det dock svﾃ･rt att anvﾃ､nda nﾃ･gon fﾃｶrklﾃ､dd information, till exempel word2vec och GloVe-ordrepresentationer. Denna begrﾃ､nsning har begrﾃ､nsat prestandan av TM jﾃ､mfﾃｶrt med djupa neurala nﾃ､tverk (DNN) i NLP. Fﾃｶr att minska prestandakravet fﾃｶreslﾃ･r vi i denna uppsats ett nytt sﾃ､tt att anvﾃ､nda fﾃｶrklﾃ､dda ordrepresentationer fﾃｶr TM. Metoden fﾃｶrbﾃ､ttrar prestandan och tolkningen av TM avsevﾃ､rt. Vi uppnﾃ･r detta genom att extrahera semantiskt relaterade ord frﾃ･n fﾃｶrutbildade ordrepresentationer som inmatningsfunktioner till TM. Vﾃ･ra experiment visar att noggrannheten i den fﾃｶreslagna metoden ﾃ､r betydligt hﾃｶgre ﾃ､n den tidigare BOW-baserade TM och nﾃ･r nivﾃ･n fﾃｶr DNN-baserade modeller.', 'ta': 'தெச்டிலின் இயந்திரம் (TM) ஒரு முன்னிருப்பு துறைப்புரிமை அடிப்படையில் தெரியும் முறையான அடிப்படையாகும், இது பல இயல்பான மொழி செயல்பாடுகளில் competitive performance (NLP) காட்டியுள்ளது, உண மனித நிலையின் மொழிபெயர்ப்புகளை பெறுவதற்கு, வார்த்தை TM பூலியன் உள்ளீட்டு குணங்களை பாக்- வார்த்தைகள் போன்ற வார் எனினும், புவி குறிப்பிடுதல் எந்த முன் பயிற்சி தகவலையும் பயன்படுத்த கடினமாக்கும், உதாரணமாக, word2vec மற்றும் கிலோவே வார்த்தை  Name இந்த காகிதத்தில் செயல்பாட்டு வேறுபாட்டை குறைக்க, நாம் முன் பயிற்சி பயிற்சி சொல்லு பிரதிநிதிகளை பயன்படுத்த ஒர இந்த செயல்பாடு TM யின் செயல்முறையையும் விளக்கமையையும் அதிகப்படுத்துகிறது. முன் பயிற்சிக்கப்பட்ட வார்த்தை குறிப்பிடுதலில் இருந்து பாதிப்பு தொடர்புடைய வார்த்தைகளை TM க்கு உள்ளீடு கு நம்முடைய சோதனைகள் தெரியும் முன்னோக்கப்பட்ட செயல்பாட்டின் சரிவு முன்பு BOW-அடிப்படையிலுள்ள TM ஐ விட மிக அதிகமாக இருக்கிறது', 'ur': 'Tsetlin Machine (TM) ایک تفصیل قابل شناسایی الگوریتم ہے جو پیشنهادی لاجیک پر بنیاد ہے، جس نے بہت سی طبیعی زبان پرسس (NLP) کے کاموں میں مسابقه قابل عمل دکھائی ہے، جیسے sentiment analysis, text classification, اور Word Sense Disambiguation. انسان کے سطح کی تعبیر حاصل کرنے کے لئے، میراث ٹی م بولین اینٹ ویٹیوں کا استعمال کرتا ہے جیسے باگ-of-words (BOW). However, the BOW representation makes it difficult to use any pre-trained information, for example, word2vec and Glove word representations. یہ محدودیت نے NLP میں سیاہ نیورل نیٹورک (DNN) کے مقابلے میں TM کے عمل کو محدود کر دیا ہے. اس کاغذ میں فعالیت فاصلہ کم کرنے کے لئے ہم TM کے لئے پیش آموزش کی کلمات کی تعلیمات کے مطابق ایک نو طریقہ پیش کریں گے۔ اس طریقہ سے TM کی عملکرد اور تعبیر کا اثر بڑھاتا ہے۔ ہم اسے پہلے تدریس کی کلمات کے ذریعے ٹی م کے اپنا انپ ویٹر کے طور پر استعمال کرتے ہیں۔ ہماری آزمائش دکھاتی ہے کہ پیشنهاد کی تقریبا کی دقیق اگلی BOW-based TM سے زیادہ بلند ہے، جو DNN-based موڈل کے سطح تک پہنچتی ہے.', 'mt': 'Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based on propositional logic, which has demonstrated competitive performance in many Natural Language Processing (NLP) tasks, including sentiment analysis, text classification, and Word Sense Disambiguation.  Biex tinkiseb interpretabbiltà fil-livell tal-bniedem, il-wirt TM juża karatteristiċi Boolean input bħal bag-of-words (BOW). Madankollu, ir-rappreżentanza tal-BOW tagħmilha diffiċli li tintuża kwalunkwe informazzjoni mħarrġa minn qabel, pereżempju, ir-rappreżentazzjonijiet tal-kliem word2vec u GloVe. Din ir-restrizzjoni llimitat il-prestazzjoni tat-TM meta mqabbla man-netwerks newrali profondi (DNNs) fil-NLP. To reduce the performance gap, in this paper, we propose a novel way of using pre-trained word representations for TM.  L-approċċ itejjeb b’mod sinifikanti l-prestazzjoni u l-interpretabbiltà tat-TM. Aħna nilħqu dan billi neħħew kliem relatat semantikament minn rappreżentazzjonijiet tal-kliem imħarrġa minn qabel bħala karatteristiċi ta’ input għat-TM. L-esperimenti tagħna juru li l-preċiżjoni tal-approċċ propost hija ogħla b’mod sinifikanti minn TM ibbażat fuq BOW preċedenti, li jilħaq il-livell ta’ mudelli bbażati fuq DNN.', 'uz': "Name To obtain human-level interpretability, legacy TM employs Boolean input features such as bag-of-words (BOW).  Lekin BOW-ni taʼminlovchi oldin maʼlumotni ishlatish juda qiyin edi. Masalan, Word2vec va GloVe so'zlarini tashqari mumkin. Name Bu qogʻozdagi jarayon gapni kamaytirish uchun, biz TM uchun oldin o'rganilgan so'zlar tashkilotlarini foydalanish uchun novel yordamni tahrirlash. Bu usulning TM'ning natijasini va tarjima qilishini juda ham oshadi. Biz buni o'rganishdan oldin o'rganilgan so'zlarni TM'ga kiritish xususiyatlaridan foydalanishimiz mumkin. Bizning imtiyozlarimizni ko'rsatadi, oldingi BOW asosidagi TM asosidagi imkoniyatining aniqligidan juda katta, DNN asosiy modellariga imkoniyatli keladi.", 'vi': 'Trình Tsetlin Machine (TM) là một thuật toán nhận dạng mẫu được dịch dựa trên logic xung động, đã chứng minh khả năng cạnh tranh trong nhiều công việc Phân tích ngôn ngữ tự nhiên, bao gồm phân tích cảm xúc, mã hóa văn bản, và từ nhạy cảm thất bại. Để có thể hiểu được tính người, TM đã dùng tính năng nhập từ Boov như túi chữ (BOW). Tuy nhiên, sự đại diện của BOW làm khó sử dụng bất kỳ thông tin được huấn luyện trước, ví dụ diễn tả từ Word2vec và GloVee. Các hạn chế này đã giới hạn hiệu suất của TM so với mạng thần kinh sâu (DNS) trong chọc dò tủy sống. Để giảm hiệu suất, trong bài báo này, chúng tôi đề xuất một cách mới để sử dụng các biểu tượng từ được rèn luyện trước cho TM. Cách tiếp cận nâng cao khả năng ảnh hưởng và giải thích của TM. Chúng ta đạt được điều này bằng cách khai thác các từ ngữ văn theo ngữ nghĩa từ các tác động từ từ từ được đào tạo trước trang TM. Những thí nghiệm của chúng tôi cho thấy độ chính xác của phương pháp được đề xuất cao hơn nhiều so với trang TM dựa trên BOW trước đây, đạt đến mức độ của mô- đun DNS.', 'bg': 'Машината Цетлин (ТМ) е интерпретируем алгоритъм за разпознаване на модели, базиран на proposiционна логика, който демонстрира конкурентни резултати в много задачи по обработка на естествения език (НЛП), включително анализ на сентимента, класификация на текста и дисамбигуация на чувството на думите. За да се получи интерпретативност на човешко ниво, използва булийски входни функции като торба с думи (BOW). Въпреки това, представянето на BOW затруднява използването на всяка предварително обучена информация, например Word2vec и GloVe слово представяне. Това ограничение ограничава ефективността на ТМ в сравнение с дълбоките невронни мрежи (ДНН) в НЛП. За да намалим разликата в ефективността, в тази статия предлагаме нов начин за използване на предварително обучени думи за ТМ. Подходът значително подобрява производителността и интерпретацията на ТМ. Ние постигаме това чрез извличане на семантично свързани думи от предварително обучени думи като входни функции към ТМ. Нашите експерименти показват, че точността на предложения подход е значително по-висока от предишния базиран ТМ, достигайки нивото на базираните модели.', 'nl': "Tsetlin Machine (TM) is een interpreteerbaar patroonherkenningsalgoritme gebaseerd op propositielogica, dat concurrerende prestaties heeft aangetoond in veel Natural Language Processing (NLP) taken, waaronder sentimentanalyse, tekstclassificatie en Word Sense Disambiguation. Om interpreteerbaarheid op menselijk niveau te verkrijgen, maakt legacy TM gebruik van Booleaanse invoerfuncties zoals bag-of-words (BOW). De BOW representatie maakt het echter moeilijk om vooraf getrainde informatie te gebruiken, bijvoorbeeld word2vec en GloVe woordrepresentaties. Deze beperking heeft de prestaties van TM beperkt in vergelijking met diepe neurale netwerken (DNN's) in NLP. Om de prestatiekloof te verkleinen, stellen we in dit artikel een nieuwe manier voor om vooraf getrainde woordrepresentaties voor TM te gebruiken. De aanpak verbetert de prestaties en interpreteerbaarheid van TM aanzienlijk. Dit bereiken we door semantisch gerelateerde woorden uit vooraf getrainde woordrepresentaties te extraheren als invoerfuncties voor de TM. Onze experimenten tonen aan dat de nauwkeurigheid van de voorgestelde aanpak significant hoger is dan de vorige BOW-gebaseerde TM, waardoor het niveau van DNN-gebaseerde modellen bereikt wordt.", 'de': 'Tsetlin Machine (TM) ist ein interpretierbarer Mustererkennungsalgorithmus, der auf der Propositionslogik basiert und in vielen Aufgaben der Natural Language Processing (NLP) wettbewerbsfähig ist, einschließlich Stimmungsanalyse, Textklassifizierung und Word Sense Disambiguation. Um Interpretierbarkeit auf menschlicher Ebene zu erhalten, verwendet Legacy TM boolesche Eingabefunktionen wie Bag-of-Words (BOW). Die BOW-Darstellung macht es jedoch schwierig, vortrainierte Informationen wie Word2vec und GloVe-Wortdarstellungen zu verwenden. Diese Einschränkung hat die Leistung von TM im Vergleich zu Deep Neuronal Networks (DNNs) in NLP eingeschränkt. Um die Leistungslücke zu verringern, schlagen wir in diesem Beitrag eine neuartige Methode vor, vortrainierte Wortrepräsentationen für TM zu verwenden. Der Ansatz verbessert die Leistung und Interpretierbarkeit von TM erheblich. Dies erreichen wir, indem wir semantisch verwandte Wörter aus vortrainierten Wortdarstellungen als Eingabemerkmale für das TM extrahieren. Unsere Experimente zeigen, dass die Genauigkeit des vorgeschlagenen Ansatzes signifikant höher ist als das vorherige BOW-basierte TM und das Niveau DNN-basierter Modelle erreicht.', 'da': "Tsetlin Machine (TM) er en fortolkbar mønstergenkendelsesalgoritme baseret på propositional logik, som har demonstreret konkurrencedygtig ydeevne i mange Natural Language Processing (NLP) opgaver, herunder sentimental analyse, tekstklassifikation og Word Sense Disambiguation. For at opnå fortolkning på menneskeligt niveau anvender legacy TM booleske input funktioner såsom bag-of-words (BOW). BOW-repræsentationen gør det imidlertid vanskeligt at bruge forududdannede oplysninger, f.eks. word2vec og GloVe-ordrepræsentationer. Denne begrænsning har begrænset TM's ydeevne sammenlignet med dybe neurale netværk (DNN'er) i NLP. For at reducere præstationskløften foreslår vi i denne artikel en ny måde at bruge præ-trænede ordrepræsentationer for TM på. Tilgangen forbedrer TM's ydeevne og fortolkningsevne betydeligt. Vi opnår dette ved at udtrække semantisk relaterede ord fra præ-trænede ordrepræsentationer som input funktioner til TM. Vores eksperimenter viser, at nøjagtigheden af den foreslåede tilgang er betydeligt højere end den tidligere BOW-baserede TM og når niveauet for DNN-baserede modeller.", 'hr': 'Tsetlin mašina (TM) je algoritam prepoznavanja obrazaca koji se temelji na predloženoj logici, koji je pokazao konkurentnu učinku u mnogim zadacima prirodnog procesa jezika (NLP), uključujući analizu osjećanja, klasifikaciju teksta i Disambiguaciju osjećaja riječi. Kako bi dobila interpretabilnost na ljudskoj razini, nasljednost TM koristi Booleanske uloge poput torbe riječi (BOW). Međutim, predstavljanje BOW-a teško je iskoristiti bilo kakve predobučene informacije, na primjer, riječi 2vec i Glove. Ova ograničenja ograničava učinku TM u usporedbi s dubokim nervnim mrežama (DNN) u NLP-u. Da bi smanjili prazninu učinka, u ovom papiru predlažemo novi način koristiti predobučene riječi predstave za TM. Pristup značajno povećava učinkovitost i interpretabilnost TM-a. To postignemo izvlačenjem semantički povezanih riječi iz predobučenih riječi kao ulazne karakteristike TM-a. Naši eksperimenti pokazuju da je preciznost predloženog pristupa značajno veća od prethodnog TM-a na BOW-u, koji postigne nivo modela na DNN-u.', 'ko': 'Tsetlin 기계(TM)는 명제 논리를 바탕으로 하는 해석 가능한 패턴 식별 알고리즘으로 많은 자연 언어 처리(NLP) 임무에서 감정 분석, 텍스트 분류와 의미 변조를 포함하여 경쟁력 있는 성능을 나타냈다.인간 수준의 해석 가능성을 얻기 위해legacyTM는 단어 패키지(BOW)와 같은 부울 입력 기능을 채택했다.그러나 궁형 표현법은 워드2vec와GloVe 워드 표현 등 사전에 훈련된 정보를 사용하기 어렵다.NLP의 DNN(Dealth New Network)에 비해 이런 제한은 TM의 성능을 제한한다.성능 격차를 줄이기 위해 본고에서 우리는 미리 훈련된 단어 표현법을 사용하여TM를 나타내는 새로운 방법을 제시했다.이 방법은 TM의 성능과 해석성을 현저히 향상시켰다.우리는 미리 훈련된 단어 표시에서 의미와 관련된 단어를 추출하여TM의 입력 특징으로 삼아 이 점을 실현한다.실험에 의하면 이 방법의 정밀도는 이전에 BOW 기반의TM보다 현저히 높고 DNN 모델 기반의 수준에 이르렀다.', 'id': 'Tsetlin Machine (TM) adalah algoritma pengenalan pola yang dapat diterjemahkan berdasarkan logika proposisi, yang telah menunjukkan prestasi kompetitif dalam banyak tugas Proses Bahasa Alami (NLP), termasuk analisis sentimen, klasifikasi teks, dan Pengambiguasi Sense Word. Untuk mendapatkan interpretasi tingkat manusia, warisan TM menggunakan fitur input Boolean seperti tas-of-words (BOW). Namun, perwakilan BOW membuat sulit menggunakan informasi praselatih, misalnya, perwakilan kata word2vec dan GloVe. Restriksi ini telah mengurangi prestasi TM dibandingkan dengan jaringan saraf dalam (DNN) di NLP. Untuk mengurangi ruang prestasi, di kertas ini, kami mengusulkan cara baru untuk menggunakan represensi kata pre-terlatih untuk TM. pendekatan meningkatkan prestasi dan interpretabilitas TM secara signifikan. Kami mencapai ini dengan mengekstrak kata-kata yang berhubungan semantis dari represensi kata-kata yang terlatih sebelumnya sebagai fitur input ke TM. Eksperimen kami menunjukkan bahwa akurasi pendekatan yang diusulkan jauh lebih tinggi dari TM berdasarkan BOW sebelumnya, mencapai tingkat model berdasarkan DNN.', 'tr': "Tsetlin Maşyny Adamyň derejesi terjime edip bolmak üçin, legacy TM baglançy sözleri (BOW) ýaly gollançy karakterlerni ulanýar. Bu şekilde, BOW temsili eğitimli bir bilgi kullanmak zorlaştırır. Örneğin, Word2vec ve Glove kelime temsilleri. Bu çykyş NLP'de TM'in etkinleşigini döwletlere görä çykardy. Çaltylyk gapysyny azaltmak üçin bu gazetde, TM üçin öňünden okuwçylan söz temsillerini ulanmanyň täze bir nusgasyny teklip edýäris. Bu ýagdaý TM'iň tanyşylygyny we çykyşylygyny örän köpräk üýtgedýär. Bunu TM'ye giriş özellikleri olarak sematik olarak ilgili kelimeleri öňünden alınmış kelimelerden çıkararak elde ediyoruz. Biziň deneylerimiz teklip eden ýagdaýyň dogrudygyny öňki BOW-dan daýanýan TM-den has ýokarydygyny görkeýärler. DNN-dan daýanýan nusgalaryň derejesine ýetýärler.", 'fa': 'ماشین Tsetlin (TM) یک الگوریتم شناسایی الگوریتم قابل تفسیر بر اساس منطقی پیشنهاد است که عملکرد رقابتی در بسیاری از کار\u200cهای پردازش زبان طبیعی (NLP) را نشان داده است، شامل تحلیل احساسات، کلاس\u200cگذاری متن و ناپدید کردن کلمه حس کلمه. برای دریافت تعبیر قابلیت سطح انسان، TM از ویژه\u200cهای ورودی بولی مثل کیف کلمات (BOW) استفاده می\u200cکند. با این حال، نمایش BOW برای استفاده از هر اطلاعاتی پیش آموزش، برای مثال، نمایش کلمه 2vec و Glove سخت می\u200cکند. این محدودیت عملکرد TM را در مقایسه با شبکه های عصبی عمیق (DNN) در NLP محدود کرده است. برای کاهش فاصله عملکرد، در این کاغذ، ما یک روش جدید برای استفاده از نمایش\u200cهای کلمه پیش آموزش برای TM پیشنهاد می\u200cکنیم. این دستور عملکرد و تعبیر قابلیت TM را بسیار زیادی بیشتر می کند. ما این را با استخراج کلمات مربوط به semantically ارتباط از پیش آموزش کلمات به عنوان ویژه\u200cهای ورودی به TM می\u200cرسانیم. آزمایشات ما نشان می دهند که دقیق دستور پیشنهاد بسیار بالاتر از TM بر اساس BOW قبلی است که به سطح مدل بنیاد DNN رسیده است.', 'sw': 'Mashine ya Tsetlin (TM) ni algorithi ya kutambua namna inayoelezea kutokana na mantiki ya pendekezo, ambayo imeonyesha ufanisi wa ushindani katika michakato mengi ya lugha ya asili (NLP), ikiwa ni pamoja na uchambuzi wa hisia, usambazaji wa maandishi, na Ukosefu wa Sensi. To obtain human-level interpretability, legacy TM employs Boolean input features such as bag-of-words (BOW).  Hata hivyo, uwakilishi wa BOW unafanya vigumu kutumia taarifa zote zilizofunzwa kabla, kwa mfano, uwakilishi wa maneno ya Word2vec na GloVe. Uzuizi huu umezuia utendaji wa TM ukilinganishwa na mitandao ya kisasa (DNNs) nchini NLP. Ili kupunguza gaidi ya utendaji, katika karatasi hii, tunapendekeza njia ya riwaya ya kutumia uwakilishi wa maneno ya awali kwa ajili ya TM. Hatua hii inaongeza ufanisi na ufafanuzi wa TM. Tunaweza kufikia hili kwa kuondoa maneno yanayohusiana na kimwili kutoka uwakilishi wa maneno ya awali yaliyofunzwa kama kitendo cha TM. Majaribio yetu yanaonyesha kwamba uhakika wa mbinu hizo zinazopendekezwa ni kubwa zaidi ya TM iliyopita yenye asili ya BOW, kwa kufikia kiwango cha mifano yenye asili ya DNN.', 'af': "Tsetlin Masjien (TM) is 'n uitleggbare patroon herkening algoritme gebaseer op voorstellings logiek, wat het gemeenskaplike prestasie in baie Natuurlike Taal Prosessering (NLP) taak demonstrasie, insluitend sentimentanalisie, teks klassifikasie en WoordSense Ontbreking. Om mens-vlak uitleggingskap te kry, gebruik die geloodskap TM Booleaanse invoer funksies soos sak van woorde (BOW). Maar die BOW-voorstelling maak dit moeilik om enige voorstelling inligting te gebruik, byvoorbeeld, woorde 2vec en Glove woord voorstellings. Hierdie beperking het beheinde die prestasie van TM vergelyk met diep neuralnetwerke (DNN) in NLP. Om die prestasie afstand te verminder, in hierdie papier, voorstel ons 'n nuwe manier om voorafgeleerde woord voorstellings vir TM te gebruik. Die toegang verbeter betekenlik die prestasie en uitleggbare verduidelikheid van TM. Ons het dit bereik deur die uitpak van semantiese verwante woorde van vooraf gevorderde woord voorstellings as invoer funksies na die TM. Ons eksperimente wys dat die presies van die voorgestelde toegang is betekenlik hoër as die vorige BOW-gebaseerde TM, wat die vlak van DNN-gebaseerde modele bereik het.", 'az': "Tsetlin Makinesi (TM) təklif lojik üzərində dayanan örnek tanımlama algoritmi, bir çox təbiətli Dil İşlemi (NLP) işlərində münafiqli performansı göstərir, həmçin in sentiment analizi, metin klasifikasyonu və Word Sense Disambiguasyonu da dahil edilir. İnsan səviyyəsini təfsil etmək üçün, TM vəzifəsi, sözlərin torpağını (BOW) kimi Boolean giriş xüsusiyyətlərini istifadə edir. Ancaq, BOW göstəricisi hər hansı bir əvvəl təhsil edilmiş məlumatı istifadə etmək çətin edər, məsələn, sözləri 2vec və Glove sözlərini göstərir. Bu qurbanlıq NLP'də TM əməllərini NLP'də dərin nöral ağları ilə qarşılaşdırdı. Bu kağızda performans boşluğunu azaltmaq üçün TM üçün əvvəlcə təhsil edilmiş söz təsirlərini istifadə etmək üçün yeni bir yol təklif edirik. Yaxınlıq TM performansını və yorumluluğunu çox artırar. Bunu TM'nin giriş özellikləri olaraq semantik olaraq əlaqə edilən sözləri təhsil edilmiş sözlərdən əlaqə edərik. Bizim təcrübələrimiz təcrübə etdiyimiz təcrübənin doğruluğu əvvəlki BOW-dən yüksək TM-dən daha yüksəkdir, DNN-dən qurulmuş modellərin seviyyəsinə ulaşır.", 'am': 'የተስቴሊን መኪና (TM) በተለመደው ፕሮጀክት ሎጂክ ላይ የተመሳሳይ የመስመር ማድረግ ነው፡፡ ይህም በብዙ ትምህርት ማተሚያ፣ የጽሑፍ መግለጫ እና የንግግር ስሜት ድፍረት እና የስሜት አፍላጎት ነው፡፡ የሰው ደረጃን ትርጉም ለማግኘት ውርስ TM እንደ bag-of-words (BOW) የBoolean input features. ነገር ግን የBOW መልዕክት አስቀድሞ የተጠቃሚ መረጃዎችን ለመቀበል አቃውሞ ይችላል፤ ለምሳሌ የword2vec እና የGloVe ቃላት ተሟጋቾች፡፡ ይህ ግለጽ በNLP ውስጥ ጥልቅ የneyዌብ መረብ (DNNs) የተደረገውን የTM ስርዓት አግኝቷል፡፡ የድምፅ ግንኙነት ለማጎድል፣ በዚህ ገጽ፣ ለTM የተጠቃሚ የንግግር መልዕክቶችን ለመቀበል የመረጃ መንገድ እናሳውቃለን፡፡ የመግቢያው ስርዓት የTM ስርዓት እና ትርጓሜን በሙሉ ይጨምራል፡፡ ይህንን ተግባር እናደርጋለን፡፡ ፈተናዎቻችን የቀድሞው የBOW-based TM-ን ቁጥጥር ከፍተኛ እንዲሆን ያሳየናል፤ የDNN-ተመሳሳይ ዓይነቶች ደረጃ እንዲደርስ ነው፡፡', 'sq': 'Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based on propositional logic, which has demonstrated competitive performance in many Natural Language Processing (NLP) tasks, including sentiment analysis, text classification, and Word Sense Disambiguation.  Për të marrë interpretueshmërinë në nivelin njerëzor, trashëgimia TM përdorë karakteristika të hyrjes Booleane të tilla si çanta e fjalëve (BOW). Megjithatë, përfaqësimi BOW e bën të vështirë përdorimin e çdo informacioni të paratrajnuar, për shembull, përfaqësime fjalë2vec dhe GloVe. Ky kufizim ka kufizuar performancën e TM krahasuar me rrjetet e thella nervore (DNN) në NLP. Për të reduktuar dallimin në performancë, në këtë letër, ne propozojmë një mënyrë të re për të përdorur përfaqësime fjalësh të paratrajnuara për TM. Përqasja përmirëson ndjeshëm performancën dhe interpretueshmërinë e TM. Ne e arrijmë këtë duke nxjerrë fjalët semantike të lidhura nga përfaqësimet e paratrajnuara të fjalëve si elemente të hyrjes në TM. Eksperimentet tona tregojnë se saktësia e qasjes së propozuar është ndjeshëm më e lartë se TM e mëparshme bazuar në BOW, duke arritur nivelin e modeleve bazuar në DNN.', 'hy': 'Չետլինի մեքենան (ԹՄ) մեկնաբանելի կաղապարի ճանաչության ալգորիթմ է, որը հիմնված է պոզիցիոնալ տրամաբանության վրա, որը ցույց է տալիս մրցակցության արդյունքը շատ բնական լեզվի վերաբերյալ գործողություններում, ներառյալ զգացմունքների վերլուծությունը, տեքստի դասակարգումը Մարդկային մակարդակի թարգմանելիության համար ժառանգությունը ԹՄ-ն օգտագործում է բուլեական ներմուծքային առանձնահատկություններ, ինչպիսիք են բառերի պայուսակ (BOW). However, the BOW representation makes it difficult to use any pre-trained information, for instance, word2vec and GloVe word representations.  Այս սահմանափակումը սահմանափակել է ԹՄ-ի արտադրողականությունը, համեմատած ՆԼՊ-ի խորը նյարդային ցանցերի (ԴՆՆ) հետ: Այս թղթի մեջ արտադրողականության տարբերությունը նվազեցնելու համար մենք առաջարկում ենք օգտագործել նախապատրաստված բառերի ներկայացումներ ԹՄ-ի համար: Մոտեցումը նշանակալիորեն բարելավում է ԹՄ-ի արտադրողականությունը և մեկնաբանելիությունը: Մենք դա հասնում ենք սեմանտիկապես կապված բառերից հանելով նախապատրաստված բառերի ներկայացումներից որպես տեղեկատվական հատկություններ ԹՄ-ի: Մեր փորձարկումները ցույց են տալիս, որ առաջարկված մոտեցումների ճշգրիտությունը շատ ավելի բարձր է քան նախորդ BOW-ով հիմնված ՄԹ-ը, հասնելով ԴՆԹ-ով հիմնված մոդելների մակարդակին:', 'bs': 'Tsetlin Machine (TM) je algoritam prepoznavanja obrazaca koji se temelji na predloženoj logici, koji je pokazao konkurentnu funkciju u mnogim zadacima prirodnog procesa jezika (NLP), uključujući analizu osjećanja, klasifikaciju teksta i Disambiguaciju osjećaja riječi. Kako bi dobila interpretabilnost na ljudskom nivou, nasljednost TM koristi Booleanske uloge poput torbe riječi (BOW). Međutim, predstavljanje BOW-a teško je iskoristiti bilo kakve predobučene informacije, na primjer, riječi 2vec i Glove. Ova ograničenja ograničila je učinku TM u usporedbi sa dubokim nervnim mrežama (DNN) u NLP-u. Da bi smanjili prazninu izvedbe, u ovom papiru predlažemo novi način da koristimo predobučene riječi predstave za TM. Pristup značajno povećava učinkovitost i interpretabilnost TM. To postignemo izvlačenjem semantički povezanih riječi iz predobučenih riječi kao ulazne karakteristike TM-a. Naši eksperimenti pokazuju da je preciznost predloženog pristupa značajno veća od prethodnog TM-a na BOW-u, ostvarila nivo modela na DNN-u.', 'ca': "Tsetlin Machine (TM) és un algoritme de reconeixement de patrons interpretable basat en la lògica proposicional, que ha demostrat el rendiment competitiu en moltes tasques de processament de llenguatges naturals (NLP), incloent l'an àlisi de sentiments, la classificació de textos i la desambiguació del sentit de paraules. Per aconseguir l'interpretabilitat a nivell humà, el llegat TM utilitza característiques booleanes com la bolsa de paraules (BOW). Però la representació BOW dificulta l'ús de qualsevol informació pré-entrenada, per exemple, de paraules word2vec i GloVe. Aquesta restricció ha restringit el rendiment de la TM comparat amb les xarxes neuronales profundes (DNN) en NLP. Per reduir la diferència de rendiment, en aquest article, proposem una nova manera d'utilitzar representacions de paraules pre-entrenades per a TM. L'enfocament millora significativament el rendiment i l'interpretabilitat de la TM. Això ho aconsegueixem extraint paraules semànticament relacionades de representacions de paraules pré-entrenades com característiques d'entrada al TM. Els nostres experiments demostren que la precisió de l'enfocament proposat és significativament més alta que la TM basada en BOW anterior, arribant al nivell de models basats en DNN.", 'bn': 'টেটলিন মেশিন (টিএম) প্রস্তাবিত লোগিকের ভিত্তিতে একটি ব্যাখ্যাত প্যানেট স্বীকৃতি স্বীকার করার জন্য একটি স্বাক্ষরিত প্রস্তাবিক প্রক্রিয়া, যা অনেক স্বাভাবিক ভাষার প্রক To obtain human-level interpretability, legacy TM employs Boolean input features such as bag-of-words (BOW).  তবে বিউড প্রতিনিধিত্ব পূর্ব প্রশিক্ষণের কোন তথ্য ব্যবহার করা কঠিন করে, যেমন ওয়ার্ড ২ভেক এবং গ্লোভের শব্দের প্রতিনিধিত্ব করা ক এনএলপির গভীর নিউরেল নেটওয়ার্ক (ডিএনএন) এর তুলনায় এই নিষেধাজ্ঞা টিএমএর প্রদর্শনের বাধা দিয়েছে। এই কাগজটিতে প্রদর্শনীর প্রতিনিধিত্ব কমানোর জন্য আমরা টিএম-এর পূর্ব প্রশিক্ষিত শব্দের প্রতিনিধিত্ব ব ব্যবহার করার একটি উপন এই প্রযুক্তিটি টিএমএর প্রদর্শন এবং ব্যাখ্যা বৃদ্ধি করে। পূর্ব প্রশিক্ষিত শব্দের প্রতিনিধিত্বের প্রতিনিধিত্ব থেকে আমরা এটা অর্জন করি টিএমের প্রতি আপুট বৈশিষ্ট্য হিসেবে। আমাদের পরীক্ষা দেখাচ্ছে যে প্রস্তাবিত পদ্ধতির সঠিকভাবে পূর্ববর্তী বিওউড ভিত্তিক টিএমএর চেয়ে বেশী উচ্চতা, ডিএনএন-ভিত্তি', 'fi': 'Tsetlin Machine (TM) on teoreettiseen logiikkaan perustuva tulkittava kuviontunnistusalgoritmi, joka on osoittanut kilpailukykyä monissa luonnollisen kielen prosessointitehtävissä, kuten tunteiden analysoinnissa, tekstiluokituksessa ja Word Sense Disambiguation. Ihmistason tulkittavuuden saavuttamiseksi legacy TM käyttää boolealaisia syöttöominaisuuksia, kuten sanapussia (BOW). BOW-esitys vaikeuttaa kuitenkin ennalta koulutettujen tietojen käyttöä, esimerkiksi word2vec- ja GloVe-sanaesitysten käyttöä. Tämä rajoitus on rajoittanut TM:n suorituskykyä verrattuna syvähermoverkkoihin (DNN) NLP:ssä. Tässä artikkelissa ehdotamme uudenlaista tapaa käyttää esikoulutettuja sanaesityksiä TM:lle. Lähestymistapa parantaa merkittävästi TM:n suorituskykyä ja tulkittavuutta. Saavutamme tämän poimimalla semanttisesti toisiinsa liittyviä sanoja esikoulutetuista sanaesityksistä TM:n syöttöominaisuuksiksi. Kokeet osoittavat, että ehdotetun menetelmän tarkkuus on huomattavasti korkeampi kuin aiemman BOW-pohjaisen menetelmän, saavuttaen DNN-pohjaisten mallien tason.', 'cs': 'Tsetlin Machine (TM) je interpretovatelný algoritmus rozpoznávání vzorů založený na výrokové logice, který prokázal konkurenční výkon v mnoha úlohách zpracování přirozeného jazyka (NLP), včetně analýzy sentimentu, klasifikace textu a disambiguace smyslu slova. Pro získání interpretovatelnosti na lidské úrovni používá starší TM booleovské vstupní funkce, jako je sáček slov (BOW). Zastoupení BOW však ztěžuje použití jakýchkoli předškolených informací, například slovních reprezentací Word2vec a GloVe. Toto omezení omezilo výkon TM ve srovnání s hlubokými neuronovými sítěmi (DNN) v NLP. Abychom zmenšili výkonnostní mezeru, v tomto článku navrhujeme nový způsob použití předškolených slovních reprezentací pro TM. Tento přístup výrazně zvyšuje výkon a interpretovatelnost TM. Toho dosahujeme extrakcí sémanticky souvisejících slov z předškolených reprezentací slov jako vstupních funkcí do TM. Naše experimenty ukazují, že přesnost navrhovaného přístupu je výrazně vyšší než předchozí BOW-založený TM a dosahuje úrovně DNN-založených modelů.', 'et': 'Tsetlini masin (TM) on tõlgendatav mustrituvastuse algoritm, mis põhineb propositsioonilisel loogikal, mis on näidanud konkurentsivõimet paljudes looduskeele töötlemise (NLP) ülesannetes, sealhulgas sentimentaalüüs, teksti klassifitseerimine ja Word Sense Disambiguation. Inimtasandil tõlgendatavuse saavutamiseks kasutab legacy TM booleani sisendfunktsioone, nagu sõnakott (BOW). Kuid BOW esitus raskendab eelnevalt koolitatud teabe kasutamist, näiteks Word2vec ja GloVe sõnade esitamist. See piirang on piiranud TM jõudlust võrreldes sügavate närvivõrkudega NLP-s. Selleks, et vähendada jõudluse lõhet, pakume käesolevas töös välja uuenduslik viis kasutada eelnevalt väljaõpetatud sõnaesitusi TM jaoks. See lähenemisviis suurendab märkimisväärselt katsemenetluse jõudlust ja tõlgendatavust. Selle saavutame semantiliselt seotud sõnade ekstraheerimisega eelnevalt väljaõpetatud sõnaesitustest TM sisendfunktsioonidena. Meie katsed näitavad, et kavandatud lähenemisviisi täpsus on oluliselt kõrgem kui eelmine BOW-põhine TM, jõudes DNN-põhiste mudelite tasemele.', 'jv': 'System text-tool-action politenessoffpolite"), and when there is a change ("assertivepoliteness Ngubah iki wis ditambah kanggo nggawe TiM dumateng kang di alam Jejarang (DNNs) ning NLP Mbok beraksi geraraning gap sanes, nang alih iki, kita supoyo kuwi nyumbang kanggo ngewehi gambar kelas telu nggawe aturan awak dhéwé. Rasané sing ngerasai nggambar akeh pisan karo akeh dumadhi kanggo ngerasar TIM. We success Awakdhéwé éntuk dhéwé ngerasakno ngono dakasai nggawe akses dituruti nggawe akses dituruti, sing sumulakno karo BOX-diagonalan, sampek model sing bisa DNN-diagonalan.', 'ha': "Shirin Tsetlin (TM) wani algoritm ne mai fassarawa na gane algoritm a kan shirin ayuka da aka bukatar da shi, wanda ya nuna mai fassara cikin aikin aiki mãsu yawa na Jalalar Lugari na Natural (NLP), idan an yi anayyar, fassarar matsayi, da fassarar littãfi, da kuma kallo na ƙyacẽwar magana. To get an fassarar-zane ga mutum, gãdo TM yana amfani da shiryoyin inputs na Boolean kamar bags-of-words (BOW). A lokacin da ake wakilisha BOW ya kamata yin amfani da duk information na gaba-tunne, misali, maganar word2ve da GoV. Wannan ƙunci ya ƙunsa da aikin TM sami da zanen neural na'ura (DNNs) cikin NLP. Dõmin ya ƙara gaura na fassarar aiki, cikin wannan takarda, za mu buƙata wani hanya na yi amfani da shiryoyin maganar ta zaman-danne da TM. Mataimakin na ƙara fassarar da fassarar TM mai girma. Mu sami wannan da ke sami da kuma ka sami magana masu husũma na semantically daga masu tsari da aka yi wa zaman-lõkaci kamar da aka shiga cikin tsarin zuwa TM. Kayan jarrabõnmu sun nũna cewa tsarin hanyarin da aka faɗa shi yana mai girma bisa abin da ya zaman a BOW-based TM, yana kai ga daraja da misãlai da aka ƙayyade DNN.", 'sk': 'Tsetlin Machine (TM) je razložljiv algoritem za prepoznavanje vzorcev, ki temelji na proposicijski logiki, ki je pokazal konkurenčno učinkovitost pri številnih nalogah obdelave naravnega jezika (NLP), vključno z analizo sentimenta, klasifikacijo besedila in razjasnitvijo besedila. Za pridobitev razlagalnosti na človeški ravni, legacy TM uporablja booleanske vhodne funkcije, kot je vreča besed (BOW). Vendar pa predstavitev BOW otežuje uporabo kakršnih koli predhodno usposobljenih informacij, na primer predstavitev besed Word2vec in GloVe. Ta omejitev je omejila učinkovitost TM v primerjavi z globokimi nevronskimi omrežji (DNN) v NLP. Da bi zmanjšali vrzel v učinkovitosti, v tem prispevku predlagamo nov način uporabe predhodno usposobljenih besednih predstavitev za TM. Ta pristop bistveno izboljša učinkovitost in razložljivost TM. To dosežemo z ekstrakcijo semantično sorodnih besed iz predhodno usposobljenih besednih predstavitev kot vhodnih funkcij v TM. Naši eksperimenti kažejo, da je natančnost predlaganega pristopa bistveno višja od prejšnje metode na osnovi BOW, kar dosega raven modelov na osnovi DNN.', 'bo': 'Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based on propositional logic, which has demonstrated competitive performance in many Natural Language Processing (NLP) tasks, including sentiment analysis, text classification, and Word Sense Disambiguation. To obtain human-level interpretability, legacy TM employs Boolean input features such as bag-of-words (BOW). ཡིན་ནའང་། BOW་གསལ་བཤད་ཀྱིས་སྔོན་གྲངས་བསྒྲིག་པའི་གནས་ཚུལ་གང་ཡང་བེད་སྤྱོད་ན་དཀའ་ངལ་ཏུ་གཏོང་། NLP ནང་གི་སྒུལ་མཐུད་དྲ་ཚུ་(DNNs) དང་མཐུན་ཡོད་པའི་སྒྲིག་འགོད་འདིས་TM་ལ་ཚད་འཛིན་ཡོད། དེ་ལྟར་ཤོག་བྱང་འདིའི་ནང་གི་སྐྱེས་ཚད་དམའ་རུ་གཏོང་བའི་ཐབས་ལམ་དེ་ང་ཚོས་TM ལ་སྔོན་གྲངས་བསྒྲིག་པའི་ཐ་སྙད་ཚུལ་ གཟུགས་སྐོར་ན་དེ་ནི་སྒྲུབ་འབྲི་བ་དང་འགྲེལ་བཤད་པ་མང་ཙམ་ཏུ་གཏོང་། We achieve this by extracting semantically related words from pre-trained word representations as input features to the TM. ང་ཚོའི་བརྟག་ཞིག་གིས་དམིགས་འཛུགས་ཀྱི་ཐབས་ལམ་གྱི་བདེ་འཇལ་ཚད་དེ་བྱ་བ་ཡིན་པས། BOW་གཞི་བརྟེན་པའི་TM་ལས་གཟུགས་རིས་མཐོང་བ་ཡིན་', 'he': 'Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based on propositional logic, which has demonstrated competitive performance in many Natural Language Processing (NLP) tasks, including sentiment analysis, text classification, and Word Sense Disambiguation.  כדי להשיג אפשרות לפרשנות ברמה אנושית, המורשת TM משתמשת בתוכניות בוליאניות כמו שקית מילים (BOW). עם זאת, מייצג BOW מקשה להשתמש בכל מידע מאומן מראש, למשל מייצג מילים word2vec וגלוב. ההגבלה הזו הוגבלה את ההפעלה של TM בהשוואה לרשתות עצביות עמוקות (DNN) ב NLP. כדי להפחית את הפער ביצועי, בעיתון הזה, אנחנו מציעים דרך חדשה להשתמש ביצועי מילים מאומנים מראש עבור TM. The approach significantly enhances the performance and interpretability of TM.  We achieve this by extracting semantically related words from pre-trained word representations as input features to the TM.  Our experiments show that the accuracy of the proposed approach is significantly higher than the previous BOW-based TM, reaching the level of DNN-based models.'}
{'en': 'An in-depth look at Euclidean disk embeddings for structure preserving parsing', 'ar': 'نظرة متعمقة على حفلات الزفاف على القرص الإقليدي من أجل الحفاظ على الهيكل', 'pt': 'Uma visão detalhada das incorporações de disco euclidianas para análise de preservação de estrutura', 'fr': "Un examen approfondi des intégrations de disques euclidiens pour l'analyse préservant la structure", 'es': 'Una mirada en profundidad a las incrustaciones de discos euclidianos para el análisis de conservación de estructuras', 'zh': '深知结构存解析欧数里得圆嵌', 'ja': '構文解析を保存するためのユークリッドディスクの埋め込みの詳細を見る', 'hi': 'संरचना संरक्षण पार्सिंग के लिए यूक्लिडियन डिस्क एम्बेडिंग पर गहराई से नज़र डालें', 'ru': 'Глубокий взгляд на вложения в евклидовы диски для сохранения структуры синтаксического анализа', 'ga': 'Súil dhomhain ar leabaithe diosca Eoiclídeach chun parsáil struchtúir a chaomhnú', 'ka': 'Name', 'el': 'Μια σε βάθος ματιά στις ενσωματώσεις ευκλείδειων δίσκων για ανάλυση διατήρησης δομής', 'hu': 'Részletes áttekintés az euklideai lemezbeágyazásokra a struktúra megőrzéséhez', 'it': 'Uno sguardo approfondito alle incorporazioni del disco euclideo per preservare la struttura parsing', 'kk': 'Name', 'ms': 'Name', 'mk': 'Главен поглед на вградувањата на евклидскиот диск за зачувување на структурата на анализирањето', 'ml': 'Name', 'mt': 'Ħarsa fil-fond lejn l-inkorporazzjonijiet tad-diski Euclidean għall-ipproċessar tal-preżervazzjoni tal-istruttura', 'no': 'Name', 'mn': 'Эуклидийн дискийн хэвлэлүүдийг гүн гүнзгий харвал', 'lt': 'Išsamus apžvalgas į Euklidinio disko įrangą, skirtą struktūros išsaugojimui paruošti', 'pl': 'Głębokie spojrzenie na osadzenia dysków euklidejskich w celu zachowania struktury parsowania', 'ro': 'O privire aprofundată a încorporărilor discurilor euclidiene pentru păstrarea structurii analizării', 'si': 'Name', 'so': 'Muuqashada mool-dheer ka eega Disk Euclid oo ku yaala dhismaha dhismaha la ilaaliyo baarlamaanka', 'sv': 'En djupgående titt på euklidiskinbäddningar för strukturbevarande parsning', 'ta': 'Name', 'ur': 'Name', 'sr': 'U dubini pogledaj Euklideanske integracije diska za strukturu koja čuva parsanje', 'uz': 'Name', 'vi': 'Tìm hiểu sâu về sự nhúng vào đĩa Euclide cho cấu trúc bảo tồn tiết kiệm phân tích', 'bg': 'Задълбочен поглед върху вгражданията на Евклидски дискове за запазване на структурата', 'nl': 'Een diepgaande blik op Euclidische schijf embeddings voor structuur behoud parsing', 'hr': 'U dubini pogledaj Euclidean diskovne integracije za strukturu očuvanje analize', 'da': 'Et dybdegående kig på euklidiske indlejringer til struktur bevarelse af parsing', 'de': 'Ein detaillierter Blick auf Euklidische Disk Einbettungen für strukturerhaltendes Parsen', 'id': 'Sebuah pandangan dalam-dalam pada kandungan disk Euclidean untuk menyimpan struktur pemeriksaan penghuraian', 'fa': 'Name', 'ko': '구조 유지 분석에 사용되는 유클리드 디스크 삽입을 깊이 연구하다', 'sw': 'Tazama ya kina kinachoingia kwenye диск ya Euclid kwa ajili ya muundo wa kuhifadhi wimbo', 'tr': 'Euklidean diski gaýşartmak üçin derinlik bir gözleme', 'af': 'Name', 'sq': 'An in-depth look at Euclidean disk embeddings for structure preserving parsing', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'Yuclidean disk in şallarına quruluş gözləyir', 'bn': 'Name', 'bs': 'U dubini pogledaj Euklideanske integracije diska za strukturu očuvanje analize', 'cs': 'Podrobný pohled na euklidovské vložení disku pro analýzu zachování struktury', 'ca': "Una ullada de profunditat a l'incorporació de discos euclídics per a preservar l'analització de l'estructura", 'hy': 'Եուկլիդիայի դիսկի ներդրումներին խորը նայելը վերլուծություն պահպանելու կառուցվածքի համար', 'et': 'Põhjalik ülevaade Eukliidi ketta manustamisest struktuuri parsimise säilitamiseks', 'fi': 'Syvällinen katsaus euklidien levyupotuksiin rakenteen säilyttämiseksi', 'jv': 'Name', 'sk': 'Poglobljen pogled na vgradnje evklidskih diskov za ohranjanje strukture', 'ha': 'Wani mai shimfiɗa-depth zuwa filin Disk na Euclodi wanda ake fitarwa wa tsari da parse', 'he': 'An in-depth look at Euclidean disk embeddings for structure preserving parsing', 'bo': 'An in-depth look at Euclidean disk embedding for structure preserving parsing'}
{'en': 'Preserving the structural properties of trees or graphs when embedding them into a metric space allows for a high degree of interpretability, and has been shown beneficial for downstream tasks (e.g., hypernym detection, natural language inference, multimodal retrieval). However, whereas the majority of prior work looks at using structure-preserving embeddings when encoding a structure given as input, e.g., WordNet (Fellbaum, 1998), there is little exploration on how to use such embeddings when predicting one. We address this gap for two structure generation tasks, namely dependency and semantic parsing. We test the applicability of disk embeddings (Suzuki et al., 2019) that has been proposed for embedding Directed Acyclic Graphs (DAGs) but has not been tested on tasks that generate such structures. Our experimental results show that for both tasks the original disk embedding formulation leads to much worse performance when compared to non-structure-preserving baselines. We propose enhancements to this formulation and show that they almost close the performance gap for dependency parsing. However, the gap still remains notable for semantic parsing due to the complexity of meaning representation graphs, suggesting a challenge for generating interpretable semantic parse representations.', 'ar': 'يسمح الحفاظ على الخصائص الهيكلية للأشجار أو الرسوم البيانية عند تضمينها في مساحة مترية بدرجة عالية من القابلية للتفسير ، وقد ثبت أنه مفيد للمهام النهائية (على سبيل المثال ، اكتشاف hypernym ، واستنتاج اللغة الطبيعية ، واسترجاع الوسائط المتعددة). ومع ذلك ، في حين أن غالبية الأعمال السابقة تبحث في استخدام الزخارف التي تحافظ على البنية عند ترميز بنية معينة كمدخلات ، على سبيل المثال ، WordNet (Fellbaum ، 1998) ، هناك القليل من الاستكشاف حول كيفية استخدام مثل هذه الزخارف عند التنبؤ بواحد. نعالج هذه الفجوة في مهمتين لتوليد البنية ، وهما التبعية والتحليل الدلالي. نحن نختبر قابلية تطبيق عمليات دمج الأقراص (Suzuki et al. ، 2019) التي تم اقتراحها لتضمين الرسوم البيانية غير الدورية الموجهة (DAGs) ولكن لم يتم اختبارها في المهام التي تولد مثل هذه الهياكل. تظهر نتائجنا التجريبية أنه في كلتا المهمتين ، تؤدي صياغة دمج القرص الأصلي إلى أداء أسوأ بكثير عند مقارنتها بخطوط الأساس غير المحافظة على البنية. نقترح تحسينات على هذه الصيغة ونوضح أنها تقترب تقريبًا من فجوة الأداء لتحليل التبعية. ومع ذلك ، لا تزال الفجوة ملحوظة للتحليل الدلالي بسبب تعقيد الرسوم البيانية لتمثيل المعنى ، مما يشير إلى تحدي إنشاء تمثيلات التحليل الدلالي القابلة للتفسير.', 'es': 'Preservar las propiedades estructurales de los árboles o gráficos cuando se incrustan en un espacio métrico permite un alto grado de interpretabilidad, y se ha demostrado que es beneficioso para las tareas posteriores (por ejemplo, detección de hipernimos, inferencia de lenguaje natural, recuperación multimodal). Sin embargo, mientras que la mayoría de los trabajos anteriores se enfocan en el uso de incrustaciones que preservan la estructura al codificar una estructura dada como entrada, por ejemplo, WordNet (Fellbaum, 1998), hay poca exploración sobre cómo usar tales incrustaciones al predecir una. Abordamos esta brecha para dos tareas de generación de estructuras, a saber, la dependencia y el análisis semántico. Probamos la aplicabilidad de las incrustaciones de discos (Suzuki et al., 2019) que se han propuesto para la incrustación de gráficos acíclicos dirigidos (DAG), pero no se han probado en tareas que generan tales estructuras. Nuestros resultados experimentales muestran que, para ambas tareas, la formulación original de incrustación de discos conduce a un rendimiento mucho peor en comparación con las líneas de base que no preservan la estructura. Proponemos mejoras a esta formulación y demostramos que casi cierran la brecha de rendimiento para el análisis de dependencias. Sin embargo, la brecha sigue siendo notable para el análisis semántico debido a la complejidad de los gráficos de representación de significado, lo que sugiere un desafío para generar representaciones de análisis semántico interpretables.', 'fr': "La préservation des propriétés structurelles des arbres ou des graphiques lors de leur intégration dans un espace métrique permet un haut degré d'interprétabilité, et s'est révélée bénéfique pour les tâches en aval (par exemple, détection d'hypernym, inférence en langage naturel, extraction multimodale). Cependant, alors que la majorité des travaux antérieurs portent sur l'utilisation d'intégrations préservant la structure lors du codage d'une structure donnée en entrée, par exemple WordNet (Fellbaum, 1998), il y a peu d'exploration sur la façon d'utiliser de telles intégrations pour en prédire une. Nous comblons cette lacune pour deux tâches de génération de structure, à savoir l'analyse de dépendance et l'analyse sémantique. Nous testons l'applicabilité de l'intégration de disques (Suzuki et al., 2019) qui a été proposée pour intégrer des graphes acycliques dirigés (DAG) mais qui n'a pas été testée sur des tâches qui génèrent de telles structures. Nos résultats expérimentaux montrent que pour les deux tâches, la formulation originale d'intégration de disque entraîne une bien moindre performance par rapport aux configurations de base ne préservant pas la structure. Nous proposons des améliorations à cette formulation et montrons qu'elles comblent presque l'écart de performance pour l'analyse des dépendances. Cependant, l'écart reste notable pour l'analyse sémantique en raison de la complexité des graphes de représentation de signification, ce qui suggère un défi pour générer des représentations d'analyse sémantique interprétables.", 'pt': 'Preservar as propriedades estruturais de árvores ou gráficos ao incorporá-los em um espaço métrico permite um alto grau de interpretabilidade e tem se mostrado benéfico para tarefas posteriores (por exemplo, detecção de hiperônimos, inferência de linguagem natural, recuperação multimodal). No entanto, enquanto a maioria dos trabalhos anteriores analisa o uso de embeddings de preservação de estrutura ao codificar uma estrutura dada como entrada, por exemplo, WordNet (Fellbaum, 1998), há pouca exploração sobre como usar tais embeddings ao prever um. Abordamos essa lacuna para duas tarefas de geração de estrutura, a saber, dependência e análise semântica. Testamos a aplicabilidade de embeddings de disco (Suzuki et al., 2019) que foram propostos para incorporar Directed Acyclic Graphs (DAGs), mas não foram testados em tarefas que geram tais estruturas. Nossos resultados experimentais mostram que, para ambas as tarefas, a formulação original de incorporação de disco leva a um desempenho muito pior quando comparado a linhas de base que não preservam a estrutura. Propomos melhorias para esta formulação e mostramos que elas quase fecham a lacuna de desempenho para análise de dependência. No entanto, a lacuna ainda permanece notável para análise semântica devido à complexidade dos grafos de representação de significado, sugerindo um desafio para gerar representações de análise semântica interpretáveis.', 'hi': 'पेड़ों या रेखांकन के संरचनात्मक गुणों को संरक्षित करते समय उन्हें मीट्रिक स्थान में एम्बेड करते समय उच्च स्तर की व्याख्याक्षमता की अनुमति देता है, और डाउनस्ट्रीम कार्यों के लिए फायदेमंद दिखाया गया है (उदाहरण के लिए, हाइपरनिम डिटेक्शन, प्राकृतिक भाषा अनुमान, मल्टीमॉडल पुनर्प्राप्ति)। हालांकि, जबकि पूर्व काम का बहुमत इनपुट के रूप में दी गई संरचना को एन्कोडिंग करते समय संरचना-संरक्षण एम्बेडिंग का उपयोग करने पर दिखता है, उदाहरण के लिए, वर्डनेट (फेलबॉम, 1998), एक की भविष्यवाणी करते समय इस तरह के एम्बेडिंग का उपयोग करने के तरीके पर बहुत कम अन्वेषण है। हम दो संरचना पीढ़ी के कार्यों के लिए इस अंतर को संबोधित करते हैं, अर्थात् निर्भरता और शब्दार्थ पार्सिंग। हम डिस्क एम्बेडिंग (सुजुकी एट अल. 2019) की प्रयोज्यता का परीक्षण करते हैं, जिसे निर्देशित एसाइक्लिक ग्राफ (डीएजी) एम्बेड करने के लिए प्रस्तावित किया गया है, लेकिन ऐसी संरचनाओं को उत्पन्न करने वाले कार्यों पर परीक्षण नहीं किया गया है। हमारे प्रयोगात्मक परिणामों से पता चलता है कि दोनों कार्यों के लिए मूल डिस्क एम्बेडिंग फॉर्मूलेशन गैर-संरचना-संरक्षण बेसलाइन की तुलना में बहुत खराब प्रदर्शन की ओर जाता है। हम इस सूत्रीकरण के लिए संवर्द्धन का प्रस्ताव करते हैं और दिखाते हैं कि वे निर्भरता पार्सिंग के लिए प्रदर्शन अंतर को लगभग बंद कर देते हैं। हालांकि, अंतर अभी भी अर्थ प्रतिनिधित्व रेखांकन की जटिलता के कारण शब्दार्थ पार्सिंग के लिए उल्लेखनीय बना हुआ है, जो व्याख्यायोग्य शब्दार्थ पार्स प्रतिनिधित्व उत्पन्न करने के लिए एक चुनौती का सुझाव देता है।', 'ru': 'Сохранение структурных свойств деревьев или графиков при их встраивании в метрическое пространство обеспечивает высокую степень интерпретируемости, и было показано, что они полезны для задач ниже по потоку (например, обнаружение гипернима, вывод на естественном языке, мультимодальное извлечение). Однако, в то время как в большинстве предыдущих работ рассматривается использование вложений, сохраняющих структуру, при кодировании структуры, заданной в качестве входных данных, например, WordNet (Fellbaum, 1998), существует мало исследований о том, как использовать такие вложения при прогнозировании. Мы решим этот пробел для двух задач генерации структуры, а именно зависимостей и семантического синтаксического анализа. Мы проверяем применимость дисковых вложений (Suzuki et al., 2019), которые были предложены для встраивания направленных ациклических графиков (DAG), но не были проверены на задачах, которые генерируют такие структуры. Наши экспериментальные результаты показывают, что для обеих задач оригинальная формула встраивания диска приводит к гораздо худшей производительности по сравнению с базовыми линиями, не сохраняющими структуру. Мы предлагаем усовершенствования этой формулировки и показываем, что они почти устраняют разрыв в производительности для анализа зависимостей. Тем не менее, разрыв все еще остается заметным для семантического синтаксического анализа из-за сложности графиков представления смысла, что предполагает проблему для создания интерпретируемых семантических представлений синтаксического анализа.', 'zh': '将树图嵌度量空间,存其结构可以成高可解释性,且已证下流(例,超名检测,自然语言推理,多模态检)有益。 然虽多著于编码为输给定者用结构留嵌,如WordNet(Fellbaum1998),然于测嵌几无探索。 二者相去,依赖性与语义解析也。 余试磁盘嵌适用性(Suzuki et al.,2019),当磁盘嵌已议嵌有向无环图(DAG),而未试于结构也。 臣等实验结果表明,于此二务,比于非构基线,原始磁盘嵌公式致性更差。 臣等议公式强之,且明其几缩恃解析之性相去也。 然义表图复杂性,语义解析差犹著,明生可解之语义解析存也。', 'ja': 'ツリーまたはグラフをメトリック空間に埋め込むときにそれらの構造的特性を保持することは、高い解釈可能性を可能にし、ダウンストリームタスク（例えば、ハイパーニーム検出、自然言語推論、マルチモーダル検索）に有益であることが示されている。 しかしながら、先行研究の大部分は、入力として与えられた構造をエンコードするときに構造保存型埋め込みを使用することを検討しているが、例えばWordNet (Fellbaum, 1998)では、そのような埋め込みを予測するときにどのように使用するかについての探求はほとんど行われていない。 2つの構造生成タスク、すなわち依存関係とセマンティック構文解析のためにこのギャップに対処します。 Directed Acyclic Graph （ DAG ）の埋め込みが提案されているが、そのような構造を生成するタスクではテストされていないディスク埋め込み（ Suzuki et al., 2019 ）の適用性をテストします。 私たちの実験結果は、両方のタスクについて、元のディスク埋め込み製剤は、非構造保存ベースラインと比較して、はるかに悪いパフォーマンスにつながることを示しています。 この定式化の強化を提案し、依存関係解析のパフォーマンスギャップをほぼ埋めることを示しています。 しかしながら、意味表現グラフの複雑さのためにセマンティック構文解析ではギャップが依然として顕著であり、解釈可能なセマンティック構文解析表現を生成するための課題を示唆している。', 'ga': 'Trí airíonna struchtúracha crann nó graif a chaomhnú agus iad á neadú isteach i spás méadrach is féidir ardleibhéal inléirmhínithe a bheith ann, agus tá sé léirithe go bhfuil sé tairbheach do thascanna iartheachtacha (m.sh. braite hipearnaim, tátal teanga nádúrtha, aisghabháil ilmhódach). Mar sin féin, cé go bhféachtar i bhformhór na réamhoibre ar leabaithe caomhnaithe struchtúir a úsáid agus struchtúr a thugtar mar ionchur á ionchódú, m.sh., WordNet (Fellbaum, 1998), is beag iniúchadh a dhéantar ar conas leabaithe den sórt sin a úsáid agus ceann á thuar. Tugaimid aghaidh ar an mbearna seo maidir le dhá thasc giniúna struchtúir, eadhon spleáchas agus parsáil shéimeantach. Déanaimid tástáil ar infheidhmeacht leabaithe diosca (Suzuki et al., 2019) atá molta chun Graif Aicmileach faoi Threoir (DAGanna) a leabú ach nach ndearnadh tástáil orthu ar thascanna a ghineann struchtúir dá leithéid. Léiríonn ár dtorthaí turgnamhacha go n-eascraíonn feidhmíocht i bhfad níos measa as foirmiú leabaithe diosca bunaidh don dá thasc i gcomparáid le bunlínte neamh-struchtúir. Molaimid feabhsuithe ar an bhfoirmliú seo agus léirímid go ndúnann siad beagnach an bhearna feidhmíochta maidir le parsáil spleáchais. Mar sin féin, tá an bhearna fós suntasach maidir le parsáil shéimeantach mar gheall ar chastacht na ngraif ionadaíochta brí, rud a thugann le tuiscint go bhfuil dúshlán ann maidir le léiriú parse shéimeantach inmhínithe a ghiniúint.', 'hu': 'A fák vagy grafikonok szerkezeti tulajdonságainak megőrzése metrikus térbe való beágyazásakor nagyfokú értelmezhetőséget tesz lehetővé, és hasznosnak bizonyult a downstream feladatok (pl. hiperním felismerés, természetes nyelvi következtetés, multimodális visszakeresés) számára. Ugyanakkor, míg a korábbi munkák nagy része a struktúra-megőrző beágyazások használatát vizsgálja bemenetként megadott struktúra kódolásakor, pl. WordNet (Fellbaum, 1998), kevés kutatás van arra, hogy hogyan lehet használni ezeket a beágyazásokat, amikor előrejelzik. Ezt a hiányt két struktúra generálási feladat, nevezetesen a függőség és a szemantikai elemzés szempontjából kezeljük. Vizsgáljuk a Directed Aciklic Graphs (DAG) beágyazására javasolt lemezbeágyazások (Suzuki et al., 2019) alkalmazhatóságát, de nem tesztelték olyan feladatokon, amelyek ilyen struktúrákat generálnak. Kísérleti eredményeink azt mutatják, hogy mindkét feladat esetében az eredeti lemezbeágyazó készítmény sokkal rosszabb teljesítményt eredményez, mint a nem szerkezetmegőrző alapvonalak. Javasoljuk ezt a megfogalmazást, és megmutatjuk, hogy majdnem csökkentik a függőség elemzéséhez szükséges teljesítmény hiányt. Ugyanakkor a szemantikai elemzés szempontjából továbbra is figyelemre méltó a jelentésképviseleti grafikonok összetettsége miatt, ami kihívást jelent az értelmezhető szemantikai elemzési reprezentációk létrehozására.', 'el': 'Η διατήρηση των δομικών ιδιοτήτων των δέντρων ή των γραφημάτων κατά την ενσωμάτωσή τους σε έναν μετρικό χώρο επιτρέπει υψηλό βαθμό ερμηνείας και έχει αποδειχθεί ευεργετική για μεταγενέστερες εργασίες (π.χ. ανίχνευση υπερνύμων, συμπέρασμα φυσικής γλώσσας, πολυμορφική ανάκτηση). Ωστόσο, ενώ η πλειοψηφία των προηγούμενων εργασιών εξετάζει τη χρήση ενσωμάτωσης διατήρησης δομής κατά την κωδικοποίηση μιας δομής που δίνεται ως εισαγωγή, π.χ., υπάρχει μικρή διερεύνηση για το πώς να χρησιμοποιήσετε τέτοιες ενσωμάτωσης κατά την πρόβλεψη μιας. Αντιμετωπίζουμε αυτό το κενό για δύο εργασίες δημιουργίας δομών, δηλαδή την εξάρτηση και τη σημασιολογική ανάλυση. Δοκιμάζουμε τη δυνατότητα ενσωμάτωσης δίσκων (κ.α., 2019) που έχει προταθεί για ενσωμάτωση κατευθυνόμενων ακυκλικών γραφικών (αλλά δεν έχει δοκιμαστεί σε εργασίες που δημιουργούν τέτοιες δομές. Τα πειραματικά μας αποτελέσματα δείχνουν ότι και για τις δύο εργασίες η αρχική σύνθεση ενσωμάτωσης δίσκων οδηγεί σε πολύ χειρότερη απόδοση σε σύγκριση με τις μη-δομικές γραμμές βάσης. Προτείνουμε βελτιώσεις σε αυτή τη σύνθεση και δείχνουν ότι σχεδόν κλείνουν το χάσμα απόδοσης για την ανάλυση εξάρτησης. Ωστόσο, το χάσμα παραμένει αξιοσημείωτο για τη σημασιολογική ανάλυση λόγω της πολυπλοκότητας των γραφημάτων αναπαράστασης εννοιών, υποδηλώνοντας μια πρόκληση για τη δημιουργία ερμηνευτών σημασιολογικών αναπαραστάσεων.', 'ka': 'სტრუქტური განსაზღვრებების სტრუქტური განსაზღვრება, როდესაც მათ მეტრიკური სივრცეში დააყენებულია, უფრო მეტრიკური სივრცეში შესაძლებელია გამოყენება და ჩვენ გამოყენებულია ქვეშტრიკური დავალებებისთვის ( მაგრამ, თუმცა წინა სამუშაო სამუშაო სამუშაო მუშაო იყენებს სტრუქტურის დაკონფიგურაციის გამოყენება, როდესაც სტრუქტურაციის კონფიგურაცია, მაგალითად WordNet (Fellbaum, 1998), არსებობს პატ ჩვენ ამ განსხვავებას ორი სტრუქტურაციის დავალებისთვის გადაწყენებთ, როგორც დასახელოვნება და სმენტიკი პარასტი. ჩვენ შევცვალოთ დისკის ინბედინგიზების (Suzuki et al., 2019) პროგრამები, რომელიც მოგვეყენებულია დირექციკული აციკლიკური გრაფიების (DAGs) დაყენებისთვის, მაგრამ არ შევცვალობულია ამ სტრუქტურ ჩვენი ექსპერიმენტიური წარმოდგენები აჩვენებს, რომ ორივე დავალებისთვის ორივე დავალებისთვის ორიგინალური დისკის ინბექტირებული ფორმულაცია უფრო ცოტა გამოსახ ჩვენ ამ ფორმულაციისთვის უფრო მეტივად დავიწყებთ და გამოჩვენებთ, რომ ისინი უფრო დახურებენ პროცენტის განსხვავება განსხვავებულობისთვის. მაგრამ განსხვავება უკვე იქნება სიმენტიკური განსხვავებისთვის, რადგან განსხვავებული განსხვავება განსხვავებული გრაფიკების კომპლექტირებით, რომელიც განსხვავებული სიმენტიკური განსხვავებ', 'it': "Conservare le proprietà strutturali di alberi o grafici quando li incorporano in uno spazio metrico consente un alto grado di interpretabilità ed è stato dimostrato utile per le attività a valle (ad esempio, rilevamento di ipernimi, inferenza del linguaggio naturale, recupero multimodale). Tuttavia, mentre la maggior parte dei lavori precedenti esamina l'utilizzo di incorporazioni che preservano la struttura durante la codifica di una struttura data come input, ad esempio WordNet (Fellbaum, 1998), c'è poca esplorazione su come utilizzare tali incorporazioni quando si prevede uno. Affrontiamo questo divario per due attività di generazione di strutture, vale a dire dipendenza e analisi semantica. Verifichiamo l'applicabilità dei dischi embedding (Suzuki et al., 2019) che sono stati proposti per incorporare Directed Aciclic Graphs (DAG) ma non sono stati testati su attività che generano tali strutture. I nostri risultati sperimentali mostrano che per entrambe le attività la formulazione originale di incorporazione del disco porta a prestazioni molto peggiori rispetto alle linee di base che non preservano la struttura. Proponiamo miglioramenti a questa formulazione e mostriamo che quasi colmano il gap di performance per l'analisi delle dipendenze. Tuttavia, il gap rimane notevole per l'analisi semantica a causa della complessità dei grafici di rappresentazione del significato, suggerendo una sfida per generare rappresentazioni di analisi semantica interpretabili.", 'kk': 'Метрикалық орынға ендіргенде ағаш не графиктердің структуралық қасиеттерін сақтау мүмкіндігі жоғары түрлендіру мүмкіндігін көмектеседі және төменгі тапсырмалар үшін пайдалы болады (мысалы, гипернимді анықтау, табиғи тілді қалдыру Бірақ, алдыңғы жұмыс көпшілігі келтірілген құрылғының кодтамасын қолдану үшін құрылғы сақтау ендіруді қолданады, мысалы WordNet (Fellbaum, 1998), бұл ендіруді қалай қолдану үшін тым зерттеу жоқ. Екі құрылғы құрылған тапсырмалар үшін осы бос аралығын, мысалы, тәуелдік және semantic талдау. Біз дискі интеграцияларының (Suzuki et al., 2019) қолдануын тексердік. Бірақ бұл құрылғыларды құратын тапсырмаларды құру үшін тапсырмаларды құру үшін тапсырмаларды қолдануға болады. Тәжірибелік нәтижелеріміз екі тапсырмалар үшін бастапқы дискінде ендіру формулациясы құрылмаған негізгі сызықтарды салыстырып, көп жамандығын көрсетеді. Бұл формулацияны жақсарту және тәуелсіздік талдау үшін жұмыс істеу керектігін көрсетуге болады. Бірақ, семантикалық талдау үшін бұл аралығы мәліметтің түсініктеме графикалық түсініктерінің тәуелдігі симпатикалық талдау үшін әлі өзгертілмейді. Бұл мәліметтің түсіні', 'lt': 'Struktūrinių medžių ar grafikų savybių išsaugojimas įterpiant juos į metrinę erdvę leidžia užtikrinti aukštą aiškinamumo lygį ir įrodyta, kad tai naudinga tolesnėms užduotims (pvz., hipernimo nustatymas, gamtinė kalbos išvada, daugiarūšio naudojimo atkūrimas). However, whereas the majority of prior work looks at using structure-preserving embeddings when encoding a structure given as input, e.g., WordNet (Fellbaum, 1998), there is little exploration on how to use such embeddings when predicting one.  We address this gap for two structure generation tasks, namely dependency and semantic parsing.  We test the applicability of disk embeddings (Suzuki et al., 2019) that has been proposed for embedding Directed Acyclic Graphs (DAGs) but has not been tested on tasks that generate such structures.  Mūsų eksperimentiniai rezultatai rodo, kad abiejų užduočių atveju pradinė disko įterpimo formuluotė sukuria daug blogesnius rezultatus, palyginti su ne struktūros išsaugojimo bazinėmis linijomis. Siūlome patobulinti šią formuluotę ir parodysime, kad jos beveik mažina priklausomybės analizės rezultatų spragą. Vis dėlto semantinio analizavimo spraga vis dar pastebima dėl reikšmės reprezentacinių grafikų sudėtingumo, o tai rodo iššūkį sukurti aiškinamas semantinio analizavimo reprezentacijas.', 'mk': 'Зачувањето на структурните сопствености на дрвјата или графиците при вградувањето на дрвјата во метричкиот простор овозможува висок степен на интерпретабилност и се покажа дека е корисно за понатамошните задачи (на пример, детекција на хипернимите, природна инференција на јазикот, мултимедално преземање). However, whereas the majority of prior work looks at using structure-preserving embeddings when encoding a structure given as input, e.g., WordNet (Fellbaum, 1998), there is little exploration on how to use such embeddings when predicting one.  Ние ја решаваме оваа празнина за две задачи на генерација на структури, имено зависноста и семантичното анализирање. Ние ја тестираме апликабилноста на внатрешноста на дискот (Suzuki и други, 2019) која е предложена за внатрешност на директни акциклички графи (DAGs), но не е тестирана на задачи кои генерираат такви структури. Нашите експериментални резултати покажуваат дека за двете задачи оригиналната формулација за вградување на диск води до многу полоши резултати во споредба со неструктурните основни линии. Предложуваме подобрување на оваа формулација и покажуваме дека тие речиси ја затвораат празнината во изведувањето на зависноста. Сепак, празнината сé уште е значајна за семантичното анализирање поради комплексноста на значењето на графиците за претставување, што предлага предизвик за генерирање интерпретабилни семантични анализирања.', 'ml': 'വൃക്ഷങ്ങളുടെയോ ഗ്രാഫ്റ്റുകളുടെയോ അടിസ്ഥാനത്തിന്റെയോ ഗ്രാഫ്റ്റുകള്\u200d സൂക്ഷിച്ചുകൊണ്ടിരിക്കുന്നു. അവയെ മെറ്റിക്ക് സ്പെയിസ്റ്റിലേക്ക് ചേര്\u200dക്കുമ്പോള എന്നാലും മുമ്പുള്ള ജോലിയില്\u200d മിക്കവേറെ പണിയിടത്തില്\u200d കൂടുതല്\u200d അടിസ്ഥാന സൂക്ഷിക്കുന്നത് ഉപയോഗിക്കുന്നത് കാണുന്നുണ്ടായിരുന്നു. ഇന്\u200dപുട്ട് പോലുള്ള ഒരു കോണ്\u200dഡ രണ്ടു തലമുറയുടെ ജോലികള്\u200dക്ക് വേണ്ടി നമ്മള്\u200d ഈ വേര്\u200dതിരിച്ചുകൊടുക്കുന്നു. ആശ്രയിക്കുന്നതും സെമാന് ഞങ്ങള്\u200d ഡിസ്കിന്റെ അകത്തേക്ക് നിര്\u200dദ്ദേശിച്ചിരിക്കുന്ന അക്സിക്ലിക് ഗ്രാഫ്സുകളുടെ പ്രയോഗത്തിനായി പരീക്ഷിക്കുന്നു നമ്മുടെ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ രണ്ട് ജോലികള്\u200dക്കും ആദ്യമായ ഡിസ്കിന്റെ ഫോര്\u200dമൂലേഷന്\u200d ഉള്\u200dപ്പെട ഈ രൂപപ്രകൃതിയിലേക്ക് മെച്ചപ്പെടുത്തുവാന്\u200d ഞങ്ങള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു. ആശ്രയിക്കുന്ന പാര്\u200dജിങ്ങിന്  However, the gap still remains notable for semantic parsing due to the complexity of meaning representation graphs, suggesting a challenge for generating interpretable semantic parse representations.', 'mn': 'Метрик орон зайд мод эсвэл графикийн бүтэц байгууллагуудыг хамгаалах нь өндөр хэмжээний түвшинд ойлгох боломжтой болгодог бөгөөд доорх үйл ажиллагаанд ашигтай ажиллагааг харуулсан (жишээ нь гиперним нээлт, байгалийн хэл халдвар, олон модуль хамгаа Гэхдээ өмнөх ажлын ихэнх нь нэгийг тодорхойлох үед бүтэц кодлох боломжтой байгууллагуудыг ашиглаж байдаг. Жишээ нь WordNet (Fellbaum, 1998), нэгийг тодорхойлох үед ийм хөрөнгө оруулалтыг хэрхэн ашиглах талаар бага зэрэг судалгаа бий. Бид эдгээр зай хоёр бүтээгдэхүүний бүтээгдэхүүний даалгаврыг удирдаж байна. Энэ бол хамааралтай байдал, semantic хуваалцаа. Бид Диск интеграцийн хэрэглээ (Suzuki et al., 2019) шалгаж үзэх боломжтой. Гэхдээ эдгээр бүтэц үүсгэдэг ажил дээр шалгагдсан. Бидний туршилтын үр дүнд нь хоёр даалгаварын хувьд жинхэнэ дискийн томъёо нь бүтцийг хадгалахгүй суурь шулуунуудыг харьцуулахад илүү муу үйлдэл хийдэг. Бид энэ томъёоны сайжруулалт болон хамааралтай хуваалцааны үйл ажиллагааны ялгааг ойролцохыг санал болгож байна. Гэвч энэ зай нь зэрэг тодорхойлолтын графикийн цогц цогцолтой учраас хэмжээний хуваалцлын тулд ихэвчлэн тодорхойлолтын төлөвлөгөө үүсгэх зорилго юм.', 'mt': "Il-preservazzjoni tal-proprjetajiet strutturali tas-siġar jew tal-graffi meta jiġu inkorporati fi spazju metriku tippermetti grad g ħoli ta’ interpretabbiltà, u ntwera li hija ta’ benefiċċju għal kompiti downstream (e ż. detezzjoni ta’ iperinimi, inferenza fil-lingwa naturali, irkupru multimodali). Madankollu, filwaqt li l-maġġoranza tax-xogħol preċedenti jħares lejn l-użu ta’ inkorporazzjonijiet li jippreservaw l-istruttura meta tiġi kkodifikata struttura mogħtija bħala input, pereżempju WordNet (Fellbaum, 1998), ftit li xejn hemm esplorazzjoni dwar kif jintużaw tali inkorporazzjonijiet meta wieħed jipprevedi waħda. Aħna nindirizzaw din id-distakk għal żewġ kompiti ta’ ġenerazzjoni ta’ strutturi, jiġifieri d-dipendenza u l-analiżi semantika. Aħna nistestjaw l-applikabbiltà tal-inkorporazzjoni tad-diski (Suzuki et al., 2019) li ġiet proposta għall-inkorporazzjoni tal-Graffi Aċikliċi Diretti (DAGs) iżda ma ġietx ittestjata fuq kompiti li jiġġeneraw tali strutturi. Ir-riżultati sperimentali tagħna juru li għaż-żewġ kompiti l-formulazzjoni oriġinali tal-inkorporazzjoni tad-diska twassal għal prestazzjoni ħafna agħar meta mqabbla mal-linji bażi li ma jippreservawx l-istruttura. Aħna nipproponu titjib f'din il-formulazzjoni u nuru li kważi jagħlqu d-distakk fil-prestazzjoni għall-analiżi tad-dipendenza. Madankollu, id-distakk għadu notevoli għall-analiżi semantika minħabba l-kumplessità tal-grafiċi ta’ rappreżentazzjoni tat-tifsira, li jissuġġerixxi sfida għall-ġenerazzjoni ta’ rappreżentazzjonijiet interpretabbli tal-analiżi semantika.", 'ms': 'Menjaga ciri-ciri struktur pokok atau graf apabila memasukkannya ke ruang metrik membolehkan darjah tinggi pengenalan, dan telah dipaparkan berguna untuk tugas turun (cth. pengesan hipernim, kesimpulan bahasa alam, pemulihan multimodal). Namun, walaupun kebanyakan kerja sebelumnya melihat menggunakan penyemahan struktur bila mengekodkan struktur yang diberi sebagai input, cth., WordNet (Fellbaum, 1998), terdapat sedikit pengeksplorasi bagaimana menggunakan penyemahan struktur semasa meramalkan satu. Kami mengatasi ruang ini untuk dua tugas generasi struktur, iaitu dependensi dan penghuraian semantik. Kami menguji kemampuan penyampaian cakera (Suzuki et al., 2019) yang telah diusulkan untuk penyampaian Graf Akisiklik Arah (DAG) tetapi tidak diuji pada tugas yang menghasilkan struktur-struktur tersebut. Our experimental results show that for both tasks the original disk embedding formulation leads to much worse performance when compared to non-structure-preserving baselines.  Kami cadangkan peningkatan kepada formulasi ini dan menunjukkan bahawa mereka hampir menutup ruang prestasi untuk penghuraian dependensi. Namun, jarak masih tertentu untuk penghuraian semantik disebabkan kompleksiti graf perwakilan makna, mencadangkan cabaran untuk menghasilkan perwakilan huraian semantik yang boleh diterangkan.', 'pl': 'Zachowanie właściwości strukturalnych drzew lub wykresów podczas osadzania ich w przestrzeni metrycznej pozwala na wysoki stopień interpretowalności i okazało się korzystne dla dalszych zadań (np. wykrywanie hipernimów, wnioskowanie języka naturalnego, odzyskiwanie multimodalne). Jednakże, podczas gdy większość wcześniejszych prac zajmuje się zastosowaniem osadzeń zachowujących strukturę przy kodowaniu struktury podanej jako wejścia, np. WordNet (Fellbaum, 1998), jest niewiele badań nad tym, jak wykorzystać takie osadzenia podczas przewidywania. Rozwiązujemy tę lukę dla dwóch zadań generowania struktury, a mianowicie zależności i parsowania semantycznego. Testujemy zastosowanie osadzeń dyskowych (Suzuki et al., 2019), które zostały zaproponowane do osadzania wykresów bezpośrednich (DAG), ale nie zostały przetestowane na zadaniach generujących takie struktury. Nasze wyniki eksperymentalne pokazują, że dla obu zadań oryginalna formuła osadzania dysku prowadzi do znacznie gorszej wydajności w porównaniu z niezachowującymi struktury liniami bazowymi. Proponujemy ulepszenia tej formuły i pokazujemy, że prawie zmniejszają lukę wydajności w analizie zależności. Jednak luka ta nadal pozostaje zauważalna dla parsowania semantycznego ze względu na złożoność wykresów reprezentacji znaczenia, sugerując wyzwanie dla generowania interpretowalnych reprezentacji parsowania semantycznego.', 'no': 'Lagrar strukturelle eigenskapane til trår eller graf når dei innebygger i ein metrisk plass, kan det ha vist høg grader for tolkingar, og er vist nyttig for nedstrekingar (f.eks. hypernymoppdaging, naturspråk infeksjon, multimodal henting). Mens dei fleste førre arbeida ser på å bruka strukturelagra innbygging når koding av ein struktur oppgjeven som innbygging, f.eks. WordNet (Fellbaum, 1998), er det lite utforsking om korleis denne innbygginga skal brukast når det foregår ein. Vi adresserer denne mellomroma for to strukturoppgåver, dvs. avhengighet og semantisk tolking. Vi tester tilgjengeligheten til innbygging av diskar (Suzuki et al., 2019) som er foreslått for innbygging av direkte aksikliske graf (DAG) men er ikkje testa på oppgåver som lagar slike strukturar. Eksperimentale resultat våre viser at for begge oppgåver det opprinnelige formasjonen som innebygger disken fører til mykje verre utvikling når det sammenlignet med baselinjer som ikkje er lagra struktur. Vi foreslår forbedringar til denne formelen og viser at dei nesten lukkar utgangspunktet for tolking av avhengighet. Avstanden er imidlertid fortsatt notatlig for semantisk tolking på grunn av kompleksiteten av teikningsgrafikk, som fører til å laga tolkbare semantiske tolkingssrepresentasjonar.', 'ro': 'Păstrarea proprietăților structurale ale copacilor sau graficilor atunci când încorporează aceștia într-un spațiu metric permite un grad ridicat de interpretare și a fost demonstrată benefică pentru activitățile din aval (de exemplu, detectarea hipernimului, inferența limbajului natural, recuperarea multimodală). Cu toate acestea, în timp ce majoritatea lucrărilor anterioare vizează utilizarea încorporărilor care păstrează structura atunci când codează o structură dată ca intrare, de exemplu WordNet (Fellbaum, 1998), există puține explorări asupra modului în care se utilizează astfel de încorporări atunci când se previne una. Abordăm acest decalaj pentru două sarcini de generare a structurii, și anume dependența și analiza semantică. Testăm aplicabilitatea încorporărilor discurilor (Suzuki et al., 2019) care au fost propuse pentru încorporarea graficilor aciclice directe (DAG), dar care nu au fost testate pe sarcini care generează astfel de structuri. Rezultatele noastre experimentale arată că pentru ambele sarcini formula inițială de încorporare a discurilor duce la performanțe mult mai slabe în comparație cu liniile de bază care nu păstrează structura. Propunem îmbunătățiri la această formulă și arătăm că acestea aproape elimină decalajul de performanță pentru analizarea dependenței. Cu toate acestea, decalajul rămâne încă notabil pentru analizarea semantică datorită complexității graficelor de reprezentare a semnificației, sugerând o provocare pentru generarea reprezentărilor de parsare semantică interpretabile.', 'sv': 'Att bevara de strukturella egenskaperna hos träd eller grafer när de bäddas in i ett metriskt utrymme möjliggör en hög grad av tolkning, och har visat sig vara fördelaktigt för efterföljande uppgifter (t.ex. hypernymdetektering, naturlig språkinferens, multimodal hämtning). Men medan majoriteten av tidigare arbeten tittar på att använda strukturbevarande inbäddningar vid kodning av en struktur som ges som indata, t.ex. WordNet (Fellbaum, 1998), finns det lite utforskning av hur man använder sådana inbäddningar när man förutspår en. Vi tar itu med detta gap för två strukturgenereringsuppgifter, nämligen beroende och semantisk tolkning. Vi testar lämpligheten av diskinbäddningar (Suzuki et al., 2019) som föreslagits för inbäddning av Directed Acyclic Graphs (DAG) men som inte testats på uppgifter som genererar sådana strukturer. Våra experimentella resultat visar att den ursprungliga diskinbäddningsformeln för båda uppgifterna leder till mycket sämre prestanda jämfört med icke-strukturbevarande baslinjer. Vi föreslår förbättringar av denna formulering och visar att de nästan minskar prestandakravet för beroendetolkning. Skillnaden kvarstår dock fortfarande anmärkningsvärd för semantisk tolkning på grund av komplexiteten i meningsrepresentationsgrafer, vilket tyder på en utmaning för att generera tolkningsbara semantiska tolkningsrepresentationer.', 'sr': 'Čuvanje strukturnih vlasništva drveta ili grafika kada ih ugrađuje u metrički prostor omogućava visokoj stepeni interpretabilnosti i pokazuje se korisno za sledeće zadatke (npr. hipernimu detekciju, prirodnu infekciju jezika, multimodalnu povratku). Međutim, iako većina prethodnog rada gleda na korištenje integracija koje očuvaju strukturu kada kodiraju strukturu koju daju kao ulaz, npr. WordNet (Fellbaum, 1998), ne postoji malo istraživanja o tome kako koristiti takve integracije kada predviđaju jednu. Obraèunamo taj praznik za dva zadataka za generaciju strukture, a to je zavisnost i semantičko razmatranje. Testiramo primjenu integracija diska (Suzuki et al., 2019) koji je predložen za uključenje direktnih azikličkih grafa (DAG) ali nisu testirani na zadatke koje stvaraju takve strukture. Naši eksperimentalni rezultati pokazuju da za obe zadatke originalna formulacija uključujući disk dovede do mnogo gore izvedbe u usporedbu sa neočuvajućim osnovnim linijama. Predlažemo poboljšanje ovoj formulaciji i pokažemo da su skoro zatvorili prazninu izvedbe za analizu zavisnosti. Međutim, praznina još uvek ostaje poznata za semantičko analiziranje zbog kompleksnosti grafika predstavljanja značenja, predlažeći izazov za stvaranje interpretabilnih semantičkih predstavljanja.', 'si': 'Name නමුත්, මුලින් වැඩේ ගොඩක් බලාපොරොත්තු වැඩේ පරීක්ෂණය සම්බන්ධයක් පාවිච්චි කරන්න පුළුවන් විදිහට බලාපොරොත්තු විදිහට ඇතුළු විදිහට සංකේත අපි මේ අවස්ථාවක් විස්තර දෙකක් නිර්මාණය කරනවා, මේ අවස්ථාවක් සහ සෙමැන්ටික් විස්තර කරන්න. අපි පරීක්ෂණය කරන්නේ ඩිස්ක් ඇම්බෙඩින්ග්ස් ග්\u200dරාෆ්ස් එක්ක (Suzi et al., 2019) ප්\u200dරශ්නයක් තියෙන්නේ, ඒත් ඒ වගේ ස්ථාපනයක් නිර්මාණය කරනවා කාර් අපේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ මූලික ඩිස්ක් එක්ක ඇතුළත් පරීක්ෂණය සඳහා ප්\u200dරතිචාරයක් නොස අපි මේ සංවිධානයට වැඩි වැඩි වැඩි කරන්න පුළුවන් වෙනවා ඒ වගේම ඔවුන් පෙන්වන්නේ ඔවුන් විශ්වාස විශ නමුත්, සෙමාන්ටික් විශ්ලේෂණය විශ්ලේෂණය විශ්ලේෂණය සඳහා තියෙන්නේ විශ්ලේෂණය විශ්ලේෂණය ග්\u200dරාෆ් වලින් සංකේෂණය', 'so': 'Horumarinta xuquuqda dhismaha dhirta ama xarumaha marka lagu wado meel metric ah ayaa faa’iido dheer u heli kara turjubaan, waxaana lagu muujiyey faa’iido u leh shaqaalaha hooseeya (tusaale ahaan detection hypernym, cudurka afka asalka ah, dib u soo celinta badan). Si kastaba ha ahaatee, inta badan shaqada ka horeeyay waxay fiiriyaan isticmaalka dhismaha ilaalinta, marka uu koobnayo dhismo la siiyo sida input, tusaale ahaan WordNet (Fellbaum, 1998), waxaa laga helaa wax yar baaritaan sida loo isticmaalayo marka uu wax ka sii sheego. Waxaannu kala sheekeynaa labada hawl oo dhismaha ah, taas oo ah ku xirnaanta iyo baarlamaanka semantika. Waxaynu imtixaamaynaa codsiga diimaha (Suzuki et al., 2019) oo loo talo galay in lagu sameynayo Directed Acyclic Graphs (DAGs), laakiin lama imtixaamin shuqullada sameeya dhismaha caynkaas ah. Imtixaankayada waxaa muuqda in labada shaqooyin ee asalka ah lagu sameynayo qoraalka diimaha ee asalka ah waxay ku socotaa shaqo aad u xun marka la barbarbardhigo saldhigyada aan dhismaha ilaalinayn. Waxaannu soo jeedaynaa horumarinta horumarinta, waxaana tusnaynaa in ay dhamaadaan goobta sameynta ee baarlamaanka ku xiran. Si kastaba ha ahaatee fursadu weli way sii maahmi tahay baarlamaanka semantika sababtoo ah dhibaatooyin ay leedahay tusaale ahaan in ay soo saaro wakiilada baarlamaanka semantika ah.', 'ta': 'மரங்கள் அல்லது வரைபடங்களின் கட்டுப்பாட்டு பண்புகளை சேமிக்கும் போது அவற்றை மெட்ரிக் வெளியீட்டில் சேர்க்கும் போது அதிக தரம் விளக்கம் அனுமதிக்கும், மற்றும் கீழ் நீர் பணி ஆனால், முன்னாலும் பெரும்பாலான வேலையில் உள்ளீடு போன்ற ஒரு அமைப்பு குறிமுறையாக்கப்படும் போது அமைப்புகளை பயன்படுத்துவது பார்க்கிறது, உதாரணமாக வார்ட்நெட் (பெல்பாம இரண்டு உருவாக்கும் பணிகளுக்கான இந்த இடைவெளியை நாம் விளக்குகிறோம், அதாவது சார்ந்த சார்பு மற்றும் அரைப் நாங்கள் சோதிக்கப்பட்டுள்ள வட்டு உள்ளடக்கங்களின் பயன்பாடு (சுசுகி et al., 2019) ஆனால் இது உருவாக்கும் அடிப்படைகளை உருவாக்கும் பணிகளில் சோதிக்கப்படவில்லை. Our experimental results show that for both tasks the original disk embedding formulation leads to much worse performance when compared to non-structure-preserving baselines.  இந்த வடிவமைப்பிற்கு மேம்படுத்தலை நாம் பரிந்துரைக்கிறோம் மற்றும் அவர்கள் சார்ந்த பாடலுக்கு சார்ந்த பாடல் செ எனினும், அர்த்தமான குறிப்பிடும் வரைபடங்களின் சிக்கல் காரணத்தால் இந்த இடைவெளி இன்னும் குறிப்பிடப்பட்டு இருக்கிறது, பொருளாக முடியும', 'ur': 'درختوں یا گراف کے ساختہ خصوصے کی حفاظت کرتے ہیں جب ان کو متریک جگہ میں داخل کریں تو ان کی تعبیر کے بلند درجے کے لئے اجازت دیتے ہیں اور نیچے درجے کے کاموں کے لئے فائدہ دکھائی جاتی ہے (جیسے hypernym detection, natural language inference, multimodal retrieval). اگرچہ پہلے کے کاموں کی اکثریت ساختاری نگہبانی ایمبڈینگ کے استعمال کی طرف دیکھتی ہے جب ایک ساختاری کو ایمبڈینگ کے طور پر دی جاتی ہے، جیسے WordNet (Fellbaum, 1998), ایک کی پیش بینی کے وقت ایسی ایمبڈینگ کیسے استعمال کرنا بہت کم تحقیق ہے. ہم اس فاصلہ کو دو ساختاری نسل کے کاموں کے لئے سمجھتے ہیں، یعنی اعتمادی اور سیمنٹی پارسینگ. ہم نے ڈیسک ایمبڈینگ (Suzuki et al., 2019) کی کاربری کی آزمائش کی ہے جو دہرائی اکسیکلیک گراف (DAGs) کے لئے پیشنهاد کی گئی ہے لیکن اس طرح کی ساختاریوں کو پیدا کرنے کے لئے آزمائش نہیں کی گئی ہے۔ ہمارے آزمائش نتیجے دکھاتے ہیں کہ دونوں کاموں کے لئے اصلی ڈیسک ڈیسک ڈیسک ڈیسک ڈیسک ڈیسک ڈیسک ڈیسک ڈیسٹ ڈیسٹ ڈیسٹ ڈیسٹ ڈیسٹ ڈیسٹ ڈیس ہم اس فرمول کے لئے اضافہ کرنے کی پیشنهاد کرتے ہیں اور دکھاتے ہیں کہ وہ تقریباً اعتباری پارسینگ کے لئے عمل فاصلہ کو بند کر رہے ہیں۔ However, the gap still notable for semantic parsing because of the complexity of meaning representation graphs, suggesting a challenge for generating interpretable semantic parse representations.', 'uz': "Name Shunday qilib, ko'pchilik ishlash tugmalarini saqlash imkoniyatini ishlatishda ko'rib turadi. Masalan, WordNet (1998, Fellbaum) kabi birinchi narsalarni ishlatishda qanday foydalanishni kamaytirish mumkin. Biz bu gapni ikkita tizim yaratish vazifalari uchun boshqaramiz, buni ishlatuvchi va semantik parsing. Biz bu kompyuterni boshqarish uchun boshqaruvchi Acyklic Graphs (DAGs) qoʻllaniladigan disk ichiga (Suzuki et al., 2019) dasturlarni tekshirishni tekshirib boʻlmaydi, lekin bunday tuzuvlar yaratish vazifalarda tekshirilmaydi. Bizning tajriba natijalarimizni ko'rsatish mumkin, ikkita tashkilotlar uchun asl disk formatlashning asl qismlarini saqlash asosiy satrlarni kamaytirish bilan ko'proq amalni bajaradi. Biz bu shaklga oshirishni tasavvur qilamiz va ularning tashkilotni tashkilotga qo'llashga ishlatish imkoniyatini ko'rsatamiz. Шундай қилиб, парламент аъзоларини кўриб чиқишидан иборат бўлган қизиқлик ҳосил бўлиб турибди. Бу тушунчалик парламент аъзоларини таркиб қилиш учун қизиқлик кўрсатилади.", 'vi': 'Bảo tồn các tính chất cấu trúc của cây hay đồ thị khi g ắn chúng vào một không gian đo lường cho phép có một mức độ dễ hiểu, và đã được cho thấy thuận lợi cho các công việc xuôi dòng (v.d. phát hiện siêu âm, ám ảnh ngôn ngữ tự nhiên, truy tìm đa phương). Tuy nhiên, khi hầu hết các công việc trước đây xem xét việc nhúng vào bảo tồn cấu trúc khi mã hóa một cấu trúc được cho là nhập, ví dụ, WordNet (Fellbaum, 198), ít có tìm hiểu được cách sử dụng sự nhúng chàm khi dự đoán. Chúng ta giải quyết vấn đề này cho hai công việc tạo ra cấu trúc, là phụ thuộc và phân tích theo ngữ nghĩa. Chúng tôi kiểm tra phương pháp có thể hiện nổi (Suzuki et al., 2009) được bảo tới việc tổn bộ trịc rành pháp địa hước (DAG) nhưng chưa được thực phép kiểm tra những thành thức cung cấp này. Các kết quả thử nghiệm cho thấy rằng trong cả hai công việc thì công thức nhúng đĩa nguyên bản sẽ hiệu quả tệ hơn nhiều so với các bản nền bảo tồn không cấu trúc. Chúng tôi đề nghị cải tiến công trình này và cho thấy họ gần như thu hẹp khoảng cách khả năng để phân tích độ phụ thuộc. Tuy nhiên, khoảng cách vẫn còn đáng chú ý với phân tích theo ngữ nghĩa do sự phức tạp của các đồ thị đại diện, gợi ý một thách thức để tạo ra các biểu tượng phân biệt mọi khái niệm.', 'nl': "Het behouden van de structurele eigenschappen van bomen of grafieken bij het inbedden in een metrische ruimte zorgt voor een hoge mate van interpreteerbaarheid, en is nuttig gebleken voor downstreamtaken (bijv. hyperniemdetectie, natuurlijke taal inferentie, multimodaal ophalen). Echter, terwijl het merendeel van eerdere werk kijkt naar het gebruik van structurenbeschermende embeddings bij het coderen van een structuur die als input wordt gegeven, bijvoorbeeld WordNet (Fellbaum, 1998), is er weinig onderzoek naar hoe dergelijke embeddings te gebruiken bij het voorspellen ervan. We verhelpen deze kloof voor twee structuurgeneratietaken, namelijk afhankelijkheid en semantische parsing. We testen de toepasbaarheid van schijf embeddings (Suzuki et al., 2019) die is voorgesteld voor het embedden van Directed Acyclic Graphs (DAG's), maar niet is getest op taken die dergelijke structuren genereren. Onze experimentele resultaten tonen aan dat voor beide taken de originele schijfinsluitingsformulering leidt tot veel slechtere prestaties in vergelijking met niet-structuur-behoud baselines. We stellen verbeteringen voor aan deze formulering en laten zien dat ze de prestatiekloof voor afhankelijkheidsparsing bijna dichten. De kloof blijft echter nog steeds opmerkelijk voor semantische parsing vanwege de complexiteit van betekenisrepresentatiegrafieken, wat een uitdaging suggereert voor het genereren van interpreteerbare semantische parse representaties.", 'da': 'Bevarelse af træers eller grafers strukturelle egenskaber, når de indlejres i et metrisk rum, giver mulighed for en høj grad af fortolkning, og det er vist sig gavnligt for downstream opgaver (f.eks. hypernymdetektion, naturlig sproginferens, multimodal hentning). Mens størstedelen af tidligere arbejder ser på at bruge strukturbevarende indlejringer ved kodning af en struktur givet som input, f.eks. WordNet (Fellbaum, 1998), er der kun lidt undersøgelse af, hvordan man bruger sådanne indlejringer, når man forudsiger en. Vi løser dette hul for to strukturgenereringsopgaver, nemlig afhængighed og semantisk fortolkning. Vi tester anvendeligheden af diskindlejringer (Suzuki et al., 2019), der er blevet foreslået til indlejring af Directed Acyclic Graphs (DAG), men ikke er blevet testet på opgaver, der genererer sådanne strukturer. Vores eksperimentelle resultater viser, at for begge opgaver fører den oprindelige diskindlejring formulering til meget dårligere ydeevne sammenlignet med ikke-strukturbevarende basislinjer. Vi foreslår forbedringer af denne formulering og viser, at de næsten lukker præstationskløften for afhængighed parsing. Men kløften er stadig bemærkelsesværdig for semantisk parsing på grund af kompleksiteten af meningsrepræsentationsgrafer, hvilket tyder på en udfordring for at generere fortolkende semantiske parse repræsentationer.', 'bg': 'Запазването на структурните свойства на дърветата или графиките при вграждането им в метрично пространство позволява висока степен на интерпретация и е доказано полезно за задачи надолу по веригата (напр. откриване на хиперними, изводи на естествен език, мултимодално извличане). Въпреки това, докато по-голямата част от предишните работи разглеждат използването на вграждания за запазване на структурата при кодиране на структура, дадена като вход, например WordNet (Fellbaum, 1998), има малко проучване как да се използват такива вграждания при предсказване на такава. Ние решаваме тази празнина за две задачи за генериране на структури, а именно зависимост и семантичен анализ. Тестваме приложимостта на дискови вграждания (Сузуки и др., 2019), които са предложени за вграждане на директни ациклични графики (ДАГ), но не са тествани върху задачи, генериращи такива структури. Нашите експериментални резултати показват, че и за двете задачи оригиналната формулировка за вграждане на диска води до много по-лоша производителност в сравнение с базовите линии, които не запазват структурата. Предлагаме подобрения на тази формулировка и показваме, че те почти затварят разликата в ефективността за анализ на зависимостта. Въпреки това, празнината все още остава забележима за семантичното анализиране поради сложността на графиките за представяне на смисъла, което предполага предизвикателство за генериране на интерпретирани семантични представи за анализ.', 'hr': 'Čuvanje strukturnih vlasništva drveća ili grafika kada ih ugrađuje u metrički prostor omogućava visokoj stepeni interpretabilnosti i pokazuje se korisno za ležanje zadataka (npr. hipernim otkrivanjem, prirodnom jezičkom infekcijom, multimodalnom povratku). Međutim, dok većina prethodnog rada gleda korištenje ugrađenja strukture-očuvanja kada kodiranje strukture podataka kao ulaz, npr. WordNet (Fellbaum, 1998), ne postoji malo istraživanja kako koristiti takve ugrađenje kada predviđaju jednu. Ovaj praznik se obraćamo za dva zadatka generacije strukture, a to je zavisnost i semantičko razmatranje. Testiramo primjenu uključenja diskova (Suzuki et al., 2019) koja je predložena za uključenje direktnih azikličkih grafa (DAG) ali nije testirana na zadatke koje proizvode takve strukture. Naši eksperimentalni rezultati pokazuju da za obje zadatke originalna formulacija uključujući disk vodi do mnogo gore učinkovitosti u usporedbi s početnim linijama koji ne očuvaju strukturu. Predlažemo poboljšanje ovoj formulaciji i pokažemo da skoro zatvaraju prazninu učinka za analizu ovisnosti. Međutim, praznina još uvijek je zabilježena za semantičko analiziranje zbog kompleksnosti grafika predstavljanja značenja, što predlaže izazov za stvaranje interpretabilnih semantičkih predstavljanja.', 'de': 'Die Erhaltung der strukturellen Eigenschaften von Bäumen oder Graphen bei der Einbettung in einen metrischen Raum ermöglicht ein hohes Maß an Interpretierbarkeit und hat sich für nachgelagerte Aufgaben (z.B. Hypernymdetektion, natürliche Sprachinferenz, multimodales Retrieval) als vorteilhaft erwiesen. Während die meisten früheren Arbeiten sich jedoch mit strukturerhaltenden Einbettungen befassen, wenn eine Struktur als Eingabe kodiert wird, z.B. WordNet (Fellbaum, 1998), gibt es wenig Forschung darüber, wie solche Einbettungen bei der Vorhersage verwendet werden können. Wir schließen diese Lücke für zwei Strukturgenerierungsaufgaben, nämlich Abhängigkeit und semantisches Parsen. Wir testen die Anwendbarkeit von Disk Embeddings (Suzuki et al., 2019), die für die Einbettung von Directed Acyclic Graphs (DAGs) vorgeschlagen wurde, aber nicht auf Aufgaben getestet wurde, die solche Strukturen erzeugen. Unsere experimentellen Ergebnisse zeigen, dass die ursprüngliche Platteneinbettungsformulierung für beide Aufgaben im Vergleich zu nicht strukturerhaltenden Baselines zu einer wesentlich schlechteren Leistung führt. Wir schlagen Verbesserungen dieser Formulierung vor und zeigen, dass sie fast die Leistungslücke für Dependency Parsing schließen. Allerdings bleibt die Lücke für semantisches Parsen aufgrund der Komplexität von Bedeutungsdarstellungsdiagrammen nach wie vor bemerkenswert, was eine Herausforderung für die Generierung interpretierbarer semantischer Parse-Darstellungen nahelegt.', 'ko': '트리나 그림을 도량 공간에 삽입할 때 그들의 구조 속성을 보존하면 높은 해석성을 실현할 수 있고 하류 작업(예를 들어 초어 검출, 자연 언어 추리, 다중모드 검색)에 유리하다는 것이 증명되었다.그러나 이전의 대부분의 작업은 인코딩을 입력의 구조로 할 때 보존 구조의 삽입, 예를 들어WordNet(Fellbaum, 1998)을 사용하는 데 착안했지만 구조를 예측할 때 이런 삽입을 어떻게 사용하는지 탐색하는 사람은 드물다.우리는 두 가지 구조 생성 임무, 즉 의존과 의미 해석에 대해 이 격차를 해결했다.디스크 삽입(Suzuki et al., 2019)의 적용성을 테스트했습니다. 이 삽입은 다이어그램(DAG)을 삽입하는 데 사용하도록 제안되었으나 이러한 구조를 생성하는 작업에서 테스트되지 않았습니다.우리의 실험 결과에 따르면 이 두 가지 임무에 대해 원시 디스크 삽입 공식은 비구조 보존 기선에 비해 성능이 훨씬 떨어진다고 한다.우리는 이 공식에 대해 강화를 제안하며, 의존항 해석의 성능 차이를 거의 보완했다.그러나 의미 표시도의 복잡성 때문에 의미 분석에 현저한 차이가 존재한다. 이것은 해석 가능한 의미 분석을 생성하는 것이 도전이라는 것을 나타낸다.', 'id': 'Preserving the structural properties of trees or graphs when embedding them into a metric space allows for a high degree of interpretability, and has been shown beneficial for downstream tasks (e.g., hypernym detection, natural language inference, multimodal retrieval).  Namun, sementara kebanyakan pekerjaan sebelumnya melihat menggunakan penyimpanan struktur ketika mengekodikan struktur yang diberikan sebagai input, misalnya WordNet (Fellbaum, 1998), ada sedikit eksplorasi bagaimana menggunakan penyimpanan tersebut ketika memprediksikan salah satu. We address this gap for two structure generation tasks, namely dependency and semantic parsing.  Kami menguji aplikabilitas penyembedding disk (Suzuki et al., 2019) yang telah diusulkan untuk penyembedding Direct Acyclic Graphs (DAG) tetapi belum diuji pada tugas yang menghasilkan struktur-struktur tersebut. Hasil percobaan kami menunjukkan bahwa untuk kedua tugas formulasi penyembedding disk asli menyebabkan prestasi jauh lebih buruk ketika dibandingkan dengan garis dasar yang tidak memelihara struktur. We propose enhancements to this formulation and show that they almost close the performance gap for dependency parsing.  Namun, ruang tersebut masih terkenal untuk penghuraian semantis karena kompleksitas grafik reprezentasi artinya, yang menunjukkan tantangan untuk menghasilkan reprezentasi penghuraian semantis yang dapat diterjemahkan.', 'fa': 'حفاظت خصوصیت ساختاری درختان یا گرافیکان هنگامی که آنها را در فضای متریک وارد می\u200cشوند، اجازه می\u200cدهد که درجه بالا تفسیر قابلیت باشد، و برای کارهای پایین پایین (مثلاً شناسایی hypernym، آلودگی زبان طبیعی، بازیابی متوسطی) منافع باشد. ولی در حالی که اکثر کارهای پیشینیان به استفاده از ابتدایی های محافظت ساختاری نگاه می\u200cکند وقتی ساختاری که به عنوان ورودی داده می\u200cشود، مثال WordNet (Fellbaum, 1998) در حال پیش\u200cبینی از این ابتدایی کمی در مورد استفاده از این ابتدایی وجود دارد. ما این فاصله را برای دو وظیفه نسل ساختاری، به عنوان بستگی و تجزیه\u200cهای سنتی درباره\u200cی آن حل می\u200cکنیم. ما کاربردی دیسک ابتدایی (Suzuki et al., 2019) را آزمایش می\u200cکنیم که برای ابتدایی گراف\u200cهای اکسیکلیک مستقیم (DAGs) پیشنهاد شده است، ولی بر کار\u200cهایی که این ساختارها تولید می\u200cکنند آزمایش نشده است. نتیجه آزمایشی ما نشان می دهد که برای هر دو کار فرمول اصلی دیسک وارد کردن، در مقایسه با خطوط پایین\u200cهای غیر ساختار به کار می\u200cرسد. ما پیشنهاد می\u200cکنیم برای این فرمول افزایش\u200cها و نشان می\u200cدهیم که تقریباً فاصله\u200cهای فعالیت برای تقسیم بستگی را بستند. با این حال، فاصله هنوز برای تجزیه\u200cهای semantic به دلیل پیچیدگی گرافیک نمایش معنی مشخص می\u200cشود، پیشنهاد یک چالش برای تولید نمایش\u200cهای تجزیه\u200cهای semantic interpretable.', 'sw': 'Kuhudumia vifaa vya miundombinu vya miti au picha pale ambapo kuingiza kwenye nafasi ya metri inaruhusu kiwango kikubwa cha tafsiri, na imeonyeshwa kuwa na faida kwa kazi za mito ya chini (kama vile kutambua hali ya juu, maambukizi ya lugha ya asili, upatikanaji wa lugha nyingi). Hata hivyo, wakati wengi wa kazi zilizopita wanaangalia kutumia vifaa vya kutengeneza miundombinu ambapo kutangaza muundo uliotolewa kama vile input, kwa mfano, WordNet (Fellbaum, 1998), hakuna uchunguzi kidogo wa namna ya kutumia mazingira kama haya wakati wa kutabiri moja. Tunaongelea hatua hii kwa ajili ya kazi mbili za vizazi vya ujenzi, yaani kutegemea na wimbo wa kimapenzi. Tunajaribu matumizi ya matumizi ya mabadiliko ya disk (Suzuki et al., 2019) ambayo yamependekezwa kwa ajili ya kuunda maarufu ya Acyklic (DAGs) lakini haijajaribiwa katika kazi zinazotengeneza miundombinu kama hiyo. Matokeo yetu ya majaribio yanaonyesha kwamba kwa kazi zote hizo mbili za kazi zisizo rasmi katika ujenzi huo unapelekea utendaji mbaya zaidi ukilinganishwa na misingi isiyohifadhi miundombinu. Tunazipendekeza kuongezeka kwa utaratibu huu na kuonyesha kuwa karibu wanafunga nafasi ya utendaji kwa ajili ya parge ya kutegemea. Hata hivyo, pengo hilo bado linaendelea kuwa maarufu kwa ajili ya parge ya kimapenzi kwa sababu ya utata wa ramani za kuwakilisha, linalopendekeza changamoto ya kutengeneza wakilishi wabunge wa semantic.', 'tr': 'Agaç ýa-da grafikleriň strukturlarynyň hasaplaryny metriň seleňe girdirmek üçin ýokary derejesi bir terjime edip biljek bolýar we a şaky g örenler üçin peýdaly görkezilýär (mysal. hipernim deteksiýasy, tebigy diller alyp barýar, multimodal alyp gitmek üçin has gowy görkezilýär). Ýöne öňki işiň köp bölegi girişi diýip beren strukturyň kodlemesini ullanynda, myselýet WordNet (Fellbaum, 1998), beýleki guramlary täze hili ullanylýandyr. Biz bu gapysyny iki düýşürme täblisasynyň üçin çykarýarys, diýmek üçin bağlyklyk we semantik ayırmak üçin çykarýarys. Biz diskiň girişimleri (Suzuki et al., 2019) diýip kabul edilen, Direkt Aksilik Graflary (DAG) dahil şeýle döretjek zadlaryň barlanmasynda maslahat edilmedik. Biziň experimental netijelerimiz hem zadymyz üçin özüniň diskiň daşary taýýarlanmagy üçin daşary çykyş edip, struktur taýýarlanmagy boýunçylyklary bilen daşyrýar. Bu formüle gelişmeleri teklif edip, bağımlılık ayırma için sonuç boşluğunu neredeyse kapatıklarını gösteriyoruz. Fakat bu uzaklar semantik ayırma grafiklerinin karmaşıklığına sebep hala özellikli durumda kalır. Bu semantik ayırma çözümlerini oluşturmak için bir çözüm gösteriyor.', 'sq': 'Duke ruajtur pronësitë strukturore të pemëve apo grafikëve kur i përfshijnë në një hapësirë metrike lejon një shkallë të lartë interpretueshmërie dhe u tregua e dobishme për detyrat poshtë (për shembull zbulimi i hipernimeve, përfundimi natyror i gjuhës, marrja multimodale). Megjithatë, ndërsa shumica e punës së mëparshme vështron përdorimin e përfshirjeve të ruajtura të strukturës kur kodon një strukturë të dhënë si input, për shembull WordNet (Fellbaum, 1998), ka pak eksplorim se si të përdoren përfshirjet e tilla kur parashikohen një. Ne e trajtojmë këtë mungesë për dy detyra të gjenerimit të strukturës, veçanërisht varësinë dhe analizimin semantik. Ne testojmë aplikabilitetin e përfshirjes së diskut (Suzuki et al., 2019) që është propozuar për përfshirjen e grafive të drejtpërdrejta aksiklike (DAGs) por nuk është testuar në detyra që gjenerojnë struktura të tilla. Rezultatet tona eksperimentale tregojnë se për të dy detyrat formulimi origjinal i përfshirjes së diskut shpie në performancë shumë më të keqe kur krahasohet me linjat bazë jo të ruajtura nga struktura. Ne propozojmë përmirësime në këtë formulim dhe tregojmë se ato pothuajse mbyllin dallimin e performancës për analizimin e varësisë. Megjithatë, mungesa mbetet ende e shquar për analizimin semantik për shkak të kompleksitetit të grafikave përfaqësimi të kuptimit, duke sugjeruar një sfidë për krijimin e përfaqësimeve të interpretueshme të analizimit semantik.', 'af': "Waarskuwing van die strukturele eienskappe van bome of graaf wanneer hulle in 'n metriese spasie ingesluit word, laat toe vir 'n hoë grad van vertalingskap, en is gebruiklik getoon vir onderstreem opdragte (bv. hypernym opdekking, natuurlike taal inprop, multimodaal ontvanging). Maar, terwyl die meeste van voorheede werk kyk na gebruik van struktuur-beveilige inbêdings wanneer 'n enkodering van 'n struktuur gegee as invoer, bv. WordNet (Fellbaum, 1998), is daar klein uitsoek oor hoe om sodanige inbêdings te gebruik wanneer een voorskou word. Ons adres hierdie afstand vir twee strukturegenerasie taak, naamlik afhanklikheid en semantiese verwerking. Ons toets die toepassing van skyf inbêdings (Suzuki et al., 2019) wat is voorgestel vir inbêding van direkte aksikliske grafte (DAG) maar is nie getest op opdragte wat sodanige strukture genereer word nie. Ons eksperimentele resultate vertoon dat vir beide taak die oorspronklike skyf inbetering formulasie lei na baie verdere prestasie wanneer vergelyk word met nie-struktuur-behoort basisline. Ons voorstel verbeteringe aan hierdie formulasie en wys dat hulle amper die prestasie afstand toemaak vir afhanklikheid verwerking. Maar die afstand bly nog notaabel vir semantiese verwerking vanweë die kompleksiteit van betekenis voorstelling grafieke, voorstel 'n uitdrukking vir die genereer van uittelbare semantiese verwerking voorstellings.", 'am': 'የዛፎች ወይም የግራፎች ግንኙነትን በመጠቀም ጊዜ ወደ ማተሚያ ቦታ መግለጫ እንዲፈቅድ እና ለታችኛው ፈሳሽ ስርዓት የሚጠቅሙ (ምሳሌ hypernym ማግኘት፣ የፍጥረት ቋንቋ ውጤት፣ ብዙ ደጋፍ ማድረግ እንዲፈቅድ) ታይቷል፡፡ ምንም እንኳን፣ ከአሁን በፊት ሥራ ብዙዎቹም የሥርዓት አካባቢዎችን በመቀበል የመቀናቀል ቁጥጥር ሲቆጥሩ፣ ለምሳሌ፣ የWordNet (የፊልቡaum 1998)፣ እንደዚህ ያሉ አካባቢዎች እንዴት እንዲጠቀም ጥቂት ምርመራ አለበት፡፡ ለሁለት ትውልድ ትውልድ ስራዎችን እናስቀራለን፡፡ የዲስክ ውጤቶች (ሱዙኪ et al., 2019) በተመሳሳይ የአክስኪክ መዝገብ (DAGs) ነገር ግን እንደዚህ ያሉትን ሥርዓቶች በሚወስዱት ስርዓቶች ላይ አልተፈተናም፡፡ ፈተና ፍሬዎቻችን ለሁለቱ ስራ የመጀመሪያው ዲስክ የተሰኘው መልዕክት ከሥርዓት ሳይጠበቅ መሠረት መሠረት ጋር የሚያሳየው ክፋት ነው፡፡ ይህንን አካባቢ አካባቢ እናሳውቃለን፡፡ ነገር ግን የሚተረጉትን የsemantic ፓርላማ መልዕክቶች ለመፍጠር የሚችል ግንኙነት በማድረግ ግንኙነት ነው፡፡', 'hy': 'Փայրերի կամ գրաֆիկների կառուցվածքային հատկությունները պահպանելով դրանք մետրական տարածության մեջ հնարավորություն է տալիս մեկնաբանելու բարձր աստիճան, և ցույց է տալիս, որ դրանք օգտակար են հետագա խնդիրների համար (օրինակ հիպերնիմների հայտնաբերումը, բնական լեզվի հետևանքները, բա Այնուամենայնիվ, մինչդեռ նախորդ աշխատանքի մեծամասնությունը նայում է կառուցվածքներ պահպանող ներդրումների օգտագործման վրա, օրինակ WordNet-ը (Ֆելբայում, 1998), չկա փոքր ուսումնասիրություն, թե ինչպես օգտագործել այդ ներդրումները նախատեսելիս: Մենք լուծում ենք այս տարբերությունը երկու կառուցվածքային առաջադրանքների համար, հատկապես կախվածության և սեմանտիկ վերլուծության համար: Մենք ստուգում ենք դիսկի ներդրումների կիրառելիությունը (SusouKi և այլն., 2019), որը առաջարկվել է ուղղակի հաճախային գրաֆիկների (DAG) ներդրման համար, բայց չի ստուգել նման կառուցվածքներ ստեղծող խնդիրների վրա: Մեր փորձարկման արդյունքները ցույց են տալիս, որ երկու խնդիրների համար սկզբնական դիսկի ներդրման ձևավորումը շատ ավելի վատ արդյունք է հանգեցնում, երբ համեմատած է ոչ կառուցվածքի պահպանող հիմնական գծերին: Մենք առաջարկում ենք բարելավել այս բանաձևը և ցույց ենք տալիս, որ դրանք գրեթե փակում են կախվածության վերլուծության արդյունավետության տարբերությունը: Այնուամենայնիվ, բացառությունը դեռևս նշանակալի է սեմանտիկ վերլուծության համար նշանակալի ներկայացման գրաֆիկների բարդության պատճառով, որը առաջարկում է մարտահրավեր սեմանտիկ վերլուծություններ ստեղծելու համար:', 'bn': 'বৃক্ষ অথবা গ্রাফের কাঠামোর বৈশিষ্ট্য সংরক্ষণ করা যখন তাদেরকে মেট্রিক স্পেসে প্রবেশ করার অনুমতি দেয় এবং নীচের কাজের জন্য সুবিধা প্রদর্শন করা হয়েছে (উদাহরণ হাইপারেনিম আবিষ্কার,  তবে যদিও পূর্বের বেশীরভাগ কাজের দিকে তাকিয়ে থাকে কাঠামো সংরক্ষণের ব্যবহারের দিকে, যেমন ইনপুটের মতো একটি কাঠামো এনকোড করা হচ্ছে, যেমন ওয়ার্ডনেট (ফেল্লবাম, ১৯৯৮), কিভাবে এই আমরা দুই কাঠামোর প্রজন্মের কাজের জন্য এই বিভ্রান্তির কথা বলি, যার মধ্যে নির্ভরশীল এবং সেমেন্টিক পার্গিং। আমরা ডিস্কের বিভিন্ন প্রযুক্তির প্রয়োগ পরীক্ষা করছি (সুজুকি এন্টাল ২০১৯) যা পরীক্ষা করা হয়েছে পরিচালিত একাইক্লিক গ্রাফ (ডিএজি) কিন্তু এই ধরনের কাঠামো  আমাদের পরীক্ষার ফলাফল দেখা যাচ্ছে যে দুটো কাজের জন্য মূল ডিস্ক আটকে রাখার মাধ্যমে বিভিন্ন কাঠামো সংরক্ষণের বেসারলাইনের তুলনা আমরা এই বিন্যাসের উন্নতি প্রস্তাব করছি এবং দেখাচ্ছি যে তারা নির্ভরশীল পার্সিং এর জন্য প্রায় কার্যক্রমের প্রায় বন্ধ কর তবে মানে প্রতিনিধিত্বের গ্রাফের জটিলতার কারণে সেমেন্টিক পার্সিং এর বিভ্রান্তির ক্ষেত্রে এই বিভ্রান্তিতে এখনো বুঝতে পারে না, যা', 'az': 'Ağacların və graflərin strukturlu xüsusiyyətlərini metrik alanına qovuşdurduğu zaman yüksək dərəcə yorumluluğa müvəffəq edər və a şağı-aşağı işlər üçün faydalı g östərildi (məsələn, hipernim tanıması, doğal dil infeksiyonu, çoxlu modal alınması üçün). Ancaq əvvəlki işlərin çoxu, giriş kimi verilən struktur kodlaması üçün struktur-konserv inbinglərini istifadə etməyə baxırlar, məsələn WordNet (Fellbaum, 1998), bu inbinglərin necə istifadə edilməsini təmin edir. Biz bu boşluğu iki strukturlu nəsil işləri üçün çəkirik, həmçinin bağımlılıq və semantik ayırmaq üçün. Biz disk inbinglərinin (Suzuki et al., 2019) uyğunluğunu sınağa çəkirik, amma böyük yapılar yaratmaq üçün təbliğ edilmiş aciklik graflərin (DAG) inbingəsi üçün təklif edilmişdir. Bizim təcrübəmiz sonuçlarımız göstərir ki, hər ikisi iş üçün orijinal diski içərisində formülasyon daxil olmayan səhifələr ilə müqayisədə daha pis performans yaradır. Biz bu formülünü daha yaxşılaşdırmağı təklif edirik və onların bağımlılıq ayırması üçün performans boşluğunu az qala kapatırlarını göstəririk. Halbuki, bu boşluq hələ də semantik analizi anlama grafiklərinin qarışıqlığı üzündən mövcuddur, yoxsulluq verə bilən semantik analizi tərzlərini təşkil etmək üçün çətinlikləri təşkil edir.', 'bs': 'Čuvanje strukturnih vlasništva drveća ili grafika kada ih ugrađuje u metrički prostor omogućava visokoj stepeni interpretabilnosti i pokazuje se korisno za sledeće zadatke (npr. otkrivanje hipernima, infekcija prirodnog jezika, multimodalno povlačenje). Međutim, iako većina prethodnog rada gleda na korištenje ugrađenih strukturalnih ugrađenja kada kodira strukturu koju daje kao ulaz, npr. WordNet (Fellbaum, 1998), ne postoji malo istraživanja o tome kako koristiti takve ugrađenje kada predviđaju jednu. Ovaj praznik se obraćamo za dva zadatka generacije strukture, a to je zavisnost i semantička analiza. Testiramo primjenu integracija diska (Suzuki et al., 2019) koji je predložen za uključenje direktnih acikličkih grafa (DAG) ali nisu testirani na zadatke koje stvaraju takve strukture. Naši eksperimentalni rezultati pokazuju da za obje zadatke originalna formulacija uključujući disk vodi do mnogo gore funkcije u usporedbi s neočuvajućim osnovnim linijama. Predlažemo poboljšanje ovoj formulaciji i pokažemo da skoro zatvaraju prazninu učinka za analizu ovisnosti. Međutim, praznina još uvijek je zabilježena za semantičko analiziranje zbog kompleksnosti grafika predstavljanja značenja, što predlaže izazov za stvaranje interpretabilnih semantičkih predstavljanja.', 'cs': 'Zachování strukturálních vlastností stromů nebo grafů při jejich vložení do metrického prostoru umožňuje vysoký stupeň interpretovatelnosti a bylo prokázáno, že je výhodné pro následné úlohy (např. detekce hypernymů, inference přirozeného jazyka, multimodální vyhledávání). Nicméně, zatímco většina předchozí práce se zabývá použitím vložení zachovávajících strukturu při kódování struktury uvedené jako vstup, např. WordNet (Fellbaum, 1998), existuje málo zkoumání toho, jak takové vložení použít při predikci. Tuto mezeru řešíme u dvou úloh generování struktury, konkrétně závislosti a sémantického parsování. Testujeme použitelnost vložení disků (Suzuki et al., 2019), které bylo navrženo pro vložení řízených akyklických grafů (DAG), ale nebylo testováno na úlohách, které generují takové struktury. Naše experimentální výsledky ukazují, že u obou úkolů původní formulace vložení disku vede k mnohem horšímu výkonu ve srovnání s nezachovávajícími struktury základními liniemi. Navrhujeme vylepšení této formulace a ukazujeme, že téměř uzavřou mezeru výkonu pro analýzu závislostí. Mezera však stále zůstává pozoruhodná pro sémantickou parsování vzhledem ke složitosti grafů reprezentace významů, což naznačuje výzvu pro generování interpretovatelných sémantických parsovacích reprezentací.', 'et': 'Puude või graafikute struktuuriomaduste säilitamine nende meetrilisesse ruumi manustamisel võimaldab suurt tõlgendatavust ning on osutunud kasulikuks järgnevate ülesannete puhul (nt hüpernüümide tuvastamine, looduskeele järeldus, multimodaalne otsimine). Kuigi enamikus varasematest töödest käsitletakse struktuuri säilitamist säilitavate manustamiste kasutamist sisendina antud struktuuri kodeerimisel, nt WordNet (Fellbaum, 1998), on vähe uuritud, kuidas neid manustamisi prognoosides kasutada. Me lahendame selle lünga kahe struktuuri loomise ülesande, nimelt sõltuvuse ja semantilise parsimise puhul. Testime ketta manustamise (Suzuki et al., 2019) rakendatavust, mida on kavandatud suunatud atsükliliste graafikute manustamiseks, kuid mida ei ole testitud selliseid struktuure tekitavate ülesannetega. Meie eksperimentaalsed tulemused näitavad, et mõlema ülesande puhul põhjustab originaalne ketta manustamise koostis palju halvemat jõudlust võrreldes struktuuri mittesäästvate lähtejoontega. Me teeme ettepaneku selle sõnastuse täiustamiseks ja näitame, et need peaaegu kaotavad sõltuvuse parsimise tulemuslikkuse lõhe. Siiski jääb lõhe semantilise parsimise puhul märkimisväärseks tähendusgraafikute keerukuse tõttu, mis viitab väljakutsele tõlgendatavate semantiliste parsimise representatsioonide genereerimisel.', 'fi': 'Puiden tai graafien rakenteellisten ominaisuuksien säilyttäminen upottaessa niitä metriseen tilaan mahdollistaa suuren tulkinnan, ja sen on osoitettu olevan hyödyllistä loppupään tehtävissä (esim. hypernyymien tunnistus, luonnollisen kielen päättely, multimodaalinen haku). Vaikka suurin osa aiemmista töistä tarkastelee rakennetta säilyttävien upotusten käyttöä syötteenä annetun rakenteen koodauksessa, esim. WordNet (Fellbaum, 1998), tällaisten upotusten käyttöä ennustettaessa ei ole juurikaan tutkittu. Korjaamme tätä aukkoa kahden rakenteen luontitehtävän eli riippuvuuden ja semanttisen jäsentämisen osalta. Testaamme levyupotusten soveltuvuutta (Suzuki et al., 2019), joita on ehdotettu Directed Aciclic Graphs (DAG) upottamiseen, mutta joita ei ole testattu tehtäviä, jotka tuottavat tällaisia rakenteita. Kokeelliset tulokset osoittavat, että molemmissa tehtävissä alkuperäinen levyupotusformulaatio johtaa paljon huonompaan suorituskykyyn verrattuna ei-rakennetta säilyttäviin peruslinjoihin. Ehdotamme parannuksia tähän formulaatioon ja osoitamme, että ne lähes sulkevat riippuvuuksien jäsentämisen suorituskykykuilun. Ero on kuitenkin edelleen merkittävä semanttisessa jäsentämisessä merkityksen esittämisen graafien monimutkaisuuden vuoksi, mikä viittaa haasteeseen luoda tulkittavia semanttisia jäsennysesityksiä.', 'ca': "Preserving the structural properties of trees or graphs when embedding them into a metric space allows for a high degree of interpretability, and has been shown beneficial for downstream tasks (e.g., hypernym detection, natural language inference, multimodal retrieval).  Tot i així, mentre que la majoria del treball anterior mira a utilitzar incorporacions que conserven l'estructura quan codifiquen una estructura dada com entrada, per exemple WordNet (Fellbaum, 1998), no hi ha gaire exploració sobre com utilitzar aquestes incorporacions quan en prediu una. Ens ocupem d'aquesta diferència per a dues tasques de generació d'estructures, a saber, la dependència i l'analització semàntica. We test the applicability of disk embeddings (Suzuki et al., 2019) that has been proposed for embedding Directed Acyclic Graphs (DAGs) but has not been tested on tasks that generate such structures.  Els nostres resultats experimentals mostren que, per ambdues tasques, la formulació d'incorporació original del discu provoca un rendiment molt pitjor en comparació amb línies de base no conservadores d'estructura. Proposem millors a aquesta formulació i demostrem que gairebé tanquen la diferència de rendiment per l'analització de la dependencia. No obstant això, la diferència encara és notable per l'analització semàntica degut a la complexitat dels gràfics de representació del sentit, suggerint un repte per generar representacions semàntiques interpretables.", 'sk': 'Ohranjanje strukturnih lastnosti dreves ali grafov pri njihovi vgradnji v metrični prostor omogoča visoko stopnjo razlagalnosti in se je izkazalo za koristno pri nadaljnjih nalogah (npr. zaznavanje hipernimov, sklepanje naravnega jezika, multimodalno iskanje). Čeprav večina predhodnih del obravnava uporabo vgradnj za ohranjanje strukture pri kodiranju strukture, dane kot vhod, npr. WordNet (Fellbaum, 1998), je malo raziskovanja, kako uporabiti takšne vgradnje pri napovedovanju. To vrzel obravnavamo pri dveh nalogah ustvarjanja strukture, in sicer pri odvisnosti in semantičnem razčlenjevanju. Preizkušamo uporabnost vdelav diskov (Suzuki et al., 2019), ki je bila predlagana za vdelavo usmerjenih acikličnih grafov (DAG), vendar ni bila testirana na nalogah, ki ustvarjajo takšne strukture. Naši eksperimentalni rezultati kažejo, da pri obeh nalogah originalna formulacija vdelave diskov vodi do veliko slabše zmogljivosti v primerjavi z osnovnimi črtami, ki ne ohranjajo strukture. Predlagamo izboljšave te formulacije in pokažemo, da skoraj zapolnijo vrzel v učinkovitosti razčlenitve odvisnosti. Vendar je vrzel še vedno opazna pri semantičnem razčlenjevanju zaradi kompleksnosti grafikonov predstavitve pomena, kar kaže na izziv za ustvarjanje razlagaljivih semantičnih razčlenjevalnih reprezentacij.', 'ha': "An tsare tsarin halin itãce ko grafi idan an shigar da su a cikin wani fili na metric, kuma an nuna yana da amfani ga fassarar fassarar kwamfyuta (misali, ganin Hyperym, wata wa'anar harshe na natsuwa, mai amfani da multi-sauri). However, whereas the majority of prior work looks at using structure-preserving embeddings when encoding a structure given as input, e.g., WordNet (Fellbaum, 1998), there is little exploration on how to use such embeddings when predicting one.  Munã jãyayya wannan gap wa aikin matsayin kiyaye biyu, kamar depositi da parparing na semantic. Tuna jarraba shirin ayuka na sakan da aka shigar (Suzuki et al., 2019) wanda aka buƙata dõmin an embedded Directed Acyclic Grafs (DAGs) kuma ba a jarraba shi ba a kan aikin wanda ke iya ƙara wannan rubutu. MatarayinMu na nuna cewa, dõmin aikin duk aikin da aka shigar da tsarin Disk na farko, yana ƙara wa aikin mafi sharri idan an sammenliki da tsari-layin ba-tsare. Tuna goyya da mafiya ƙari zuwa wannan ƙayyade, kuma Muke nũna cewa za'a rufe gaura na aikin da za'a yi baka ga parse. Haƙĩƙa, gaura na bada yana da nota wa parse na semantic, saboda da adadi na fassarar grafyuta masu fassara, yana gayar da wata tsãwa ga ta ƙãga parse masu fassarawa na semantic.", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé nggawe gap iki nggo kelompok nggawe structural navigation Awakdhéwé éntuk aplikasinung akeh nggambar Disket sing berarti (Susuki et al, 2011) kang dipolehasno nggawe barang Akyclik Graffs (DEGs) sing berarti ora bisa ditambah nggawe mungkin sing bisa nggawe sisarane oleh dumadhi dibutuhé. Laptop" and "Desktop Anyone Tulung, nggih gap paling beraksi kanggo semanti nggawe kelangan kelangan kelangan kelangan kelangan kelangan kelangan kelangan kelangan kelangan kelangan', 'bo': 'Preserving the structural properties of trees or graphs when embedding them into a metric space allows for a high degree of interpretability, and has been shown beneficial for downstream tasks (e.g., hypernym detection, natural language inference, multimodal retrieval). However, whereas the majority of previous work looks at using structure-preserving embeddings when encoding a structure given as input, e.g., WordNet (Fellbaum, 1998), there is little exploration on how to use such embeddings when predicting one. Examples: ང་ཚོས་དབྱིབས་བཟོ་བྱ་རིམ་གཉིས་ཀྱི་བར་སྟོང་འདི་ལ་བསླབས་བྱེད་ཀྱི་ཡོད་མིན་དེ། མིན་པར་རྟེན་དང་བློ་གཏོ ང་ཚོས་གསོག་སྡེར་ནང་འཇུག་སྣོད་ཀྱི་འཇུག་སྤྱོད་ལ་བརྟག་ཞིབ་བྱས་པ་ཡིན་པས། ང་ཚོའི་བརྩོན་འཁྲུལ་གྱི་གྲུབ་འབྲས་བ་གཉིས་ཀྱིས་སྔོན་སྒྲིག་གཞི་རྩིས་གཞི་ཚོགས་སྒྲིག་འགོད་པའི་ལས་འགན་སྐྱོན་ཤིག་ཡོད་པ ང་ཚོས་རྩོམ་འབྲེལ་འདི་ལ་ཡར་རྒྱས་གཏོང་བ་དང་། དེ་དག་གི་རྟེན་འབྲེལ་མིག་དཔྱད་ཀྱི་ལས་འགན་སྟོན་གྱི་བར་སྟོན་ཤུ འོན་ཀྱང་། བར་སྟོང་དེ་དུས་ངེས་པར་ལེན་སྔོན་གྱི་དབྱེ་སྟངས་ནང་དུ་དམིགས་གསལ་རྐྱང་ཡོད།', 'he': 'לשמור על תכונות המבנה של עצים או גרפים כשהם נכנסים למרחב מטרי מאפשרים למידה גבוהה של אפשרות לפרשנות, והופיע שימושי למשימות מתחתיות (לדוגמא זיהוי היפרנימי, תוצאת שפה טבעית, השיגור multimodal). בכל אופן, בעוד רוב העבודה הקודמת מסתכלת על השימוש בתכניות שמשמרת מבנה כשקודמת מבנה שנתנה כתוצאה, למשל WordNet (Fellbaum, 1998), יש מעט חקירה על איך להשתמש בתכניות כאלה כאשר לחזות אחת. אנו מתמודדים עם הפער הזה לשני משימות דורת מבנה, כלומר תלויה ואבחנה סמנטית. אנו בודקים את אפשרות ההשתקפות של דיסקים (Suzuki et al., 2019) שהצעה להכניס גרפים אוציקליים ישירים (DAGs) אבל לא נבחנה על משימות שיוצרות מבנים כאלה. התוצאות הניסיוניים שלנו מראות שבשביל שני המשימות התכנית המקורית של דיסק מובילה להופעה הרבה יותר גרועה בהשוואה לקווי הבסיס שלא שומרים על מבנה. אנו מציעים שיפורים לתצורה הזו ולהראות שהם כמעט סוגרים את הפער ביצועי עבור בדיקת תלויות. However, the gap still remains notable for semantic parsing due to the complexity of meaning representation graphs, suggesting a challenge for generating interpretable semantic parse representations.'}
{'en': 'Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference', 'pt': 'Avaliando a capacidade de generalização de modelos de linguagem pré-treinados por meio de inferência de linguagem natural antagônica japonesa', 'fr': "Évaluation de la capacité de généralisation de modèles linguistiques pré-entraînés par l'inférence contradictoire du langage naturel japonais", 'ar': 'تقييم قدرة التعميم لنماذج اللغة المدربة مسبقًا من خلال الاستدلال اللغوي الطبيعي العدائي الياباني', 'es': 'Evaluación de la capacidad de generalización de modelos lingüísticos preentrenados mediante la inferencia de lenguaje natural contradictorio japonés', 'zh': '因日语对抗性自然语言推理评估预练言语模样泛化能', 'ja': '事前にトレーニングされた言語モデルの一般化能力を日本語の対位法的自然言語推論を通じて評価する', 'hi': 'जापानी प्रतिकूल प्राकृतिक भाषा अनुमान के माध्यम से पूर्व-प्रशिक्षित भाषा मॉडल की सामान्यीकरण क्षमता का आकलन करना', 'ru': 'Оценка обобщающей способности предварительно подготовленных языковых моделей с помощью японского состязательного вывода о естественном языке', 'ga': 'Cumas Ginearálaithe Múnlaí Teanga Réamhoilte a Mheas trí Thástáil Teanga Nádúrtha Sháraíochta na Seapáine', 'it': "Valutazione della capacità di generalizzazione dei modelli linguistici pre-addestrati attraverso l'inferenza avversaria giapponese del linguaggio naturale", 'hu': 'Az előképzett nyelvi modellek generalizációs képességének értékelése japán negatív természetes nyelvi inferencián keresztül', 'ka': 'წაპონიური კონპერსალიური თავისუფალური ენერგიის შესაძლებლობა წავლის მოდელების განსაზღვრება', 'el': 'Αξιολόγηση της ικανότητας γενικοποίησης των προ-εκπαιδευμένων γλωσσικών μοντέλων μέσω της ιαπωνικής αντίθεσης φυσικής γλώσσας', 'lt': 'Išankstinio mokymo kalbų modelių generalizacijos pajėgumų vertinimas naudojant Japonijos prieštaringą gamtos kalbų konferenciją', 'mk': 'Оценувањето на генерализацискиот капацитет на предобучените јазички модели преку јапонската непријатна природна инференција на јазик', 'ml': 'Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference', 'ms': 'Mengesan Kekuatan Penjanaan Model Bahasa Latihan-Latihan melalui Inferensi Bahasa Alam Adversarial Jepun', 'mt': 'Valutazzjoni tal-Kapaċità ta’ Ġeneralizzazzjoni ta’ Mudelli tal-Lingwi mħarrġa minn qabel permezz tal-Inferenza tal-Lingwi Naturali Adversarjali Ġappuniża', 'mn': 'Өмнөх сургалтын хэл загваруудын ерөнхийлөгч чадварыг Японы Конверсарийн Байгалийн Холбооны Төвшөөрөл', 'ro': 'Evaluarea capacității de generalizare a modelelor lingvistice pre-instruite prin inferența limbajului natural adversar japonez', 'kk': 'Алдыңғы оқылған тіл моделдерінің генерализациялау мүмкіндігін жапон конверсариялық натурал тілдерінің қасиеттері арқылы оқу', 'sr': 'Procjenjivanje kapaciteta generalizacije predobučenih jezičkih modela kroz japanski savezni prirodni jezik', 'pl': 'Ocena zdolności uogólniających wstępnie przeszkolonych modeli językowych poprzez japońskie wnioski języka naturalnego', 'no': 'Å vurdere Generaliseringskapasiteten for før- trengte språk- modeller gjennom Japanske rekursarialt naturleg språk', 'si': 'ජාපාන් වලින් සාමාන්\u200dය භාෂාව ප්\u200dරධාන භාෂාව ප්\u200dරධානය සක්ෂමතාව අවශ්\u200dය කරන්න', 'so': 'Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Luqad Inference', 'ur': 'جاپانیایی اڈورساریل طبیعی زبان انفارنس کے ذریعے پیش آموزش کی زبان موڈلوں کی جرائنالیزی قابلیت کی آزمائش کی', 'ta': 'ஜப்பானிய மொழி மாற்று மூலம் மூலம் மூலம் மூலம் மூலம் பொதுவாக்கும் தேவை', 'sv': 'Bedömning av generaliseringskapaciteten hos förberedda språkmodeller genom japanska negativa naturliga språkinferens', 'uz': 'Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference', 'vi': 'Đánh giá sức mạnh giải thích của các mô- đun ngôn ngữ đã được đào tạo qua Liên Minh ngôn ngữ tự do Nhật Bản', 'bg': 'Оценка на генерализационния капацитет на предварително обучените езикови модели чрез японски противоречиви природни езикови изводи', 'nl': 'Het beoordelen van de generalisatiecapaciteit van voorgetrainde taalmodellen door middel van Japanse tegenstrijdige natuurlijke taal Inferentie', 'da': 'Vurdering af generaliseringskapaciteten af prætrænede sprogmodeller gennem japansk adversarial naturlig sproginferens', 'hr': 'Procjenjivanje kapaciteta generalizacije predobučenih jezičkih modela kroz japanski poremećajni prirodni jezik', 'de': 'Bewertung der Generalisierungskapazit瓣t von vortrainierten Sprachmodellen durch japanische Adversarial Natural Language Inference', 'id': 'Mengevaluasi Kemampuan Generalisasi Model Bahasa Terlatih Melalui Inferensi Bahasa Alam Adversarial Jepang', 'ko': '일본어 대항성 자연언어 추리를 통해 예훈련 언어 모델의 범화 능력을 평가하다', 'sw': 'Kushuhudia Umoja wa Utamaduni wa Models of Pre-trained Lugha kupitia Ulinzani wa Kijapani wa Kiasili', 'tr': 'Öňki bilinmeden dil nusgalarynyň döredijilik ukyplaryny Japonça Adversarial Tebiýal Dili Görnüşdirmeleri', 'af': 'Assesseer die Generalisasie Kapaciteit van vooraf-opgelei taal Modelle deur Japaanse Adversariale Natuurlike Taal Inferensie', 'fa': 'ارزیابی توانایی ژنرالیزی مدل های پیش آموزش زبان با تفاوت زبان طبیعی ژاپنی', 'sq': 'Duke vlerësuar aftësinë e gjeneralizimit të modeleve të gjuhës së paratrajnuar nëpërmjet Inferencës së gjuhës natyrore kundërshtare japoneze', 'am': 'በጃፓንኛ አዳራዊ የፍጥረት ቋንቋ ምሳሌ መግለጫ', 'hy': 'Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference', 'bn': 'জাপানিজ প্রাকৃতিক ভাষার প্রতিষ্ঠানের মোডেলের সাধারণ ক্ষমতা বিশেষ করে জেনারেলিশনের ক্ষমতা', 'ca': 'Evaluar la capacitat de generalització dels models de llenguatge pré-entrenats a través de la Inferència de llenguatge natural adversari japonès', 'az': 'Yaponca Adversarial Natural Language Inference vasit…ôsil…ô …ôvv…ôlc…ô t…ôhsil edilmiŇü Dil Modell…ôrin Generalization Capacity Assessment', 'cs': 'Posouzení generalizační kapacity předškolených jazykových modelů prostřednictvím japonského nepřátelského přirozeného jazyka inference', 'bs': 'Procjenjivanje kapaciteta generalizacije predobučenih jezičkih modela kroz japansku poremećajnu prirodnu jeziku', 'fi': 'Esikoulutettujen kielimallien yleistymiskyvyn arviointi japanilaisen adversariaalisen luonnollisen kielen päättelyn avulla', 'et': 'Eelkoolitud keelemudelite üldise võimekuse hindamine Jaapani kõrvalsaaduste loodusliku keele järelduse kaudu', 'jv': 'Language', 'he': 'הערכה של היכולת הגנרליזציה של דוגמני שפת מאומנים מראש באמצעות השפה הטבעית היפנית התנגדות', 'sk': 'Ocena generalizacijske zmogljivosti predhodno usposobljenih jezikovnih modelov s pomočjo japonske adversarne naravne jezikovne sklepe', 'ha': 'KCharselect unicode block name', 'bo': 'སྔོན་གྲངས་བསྐུལ་གྱི་སྐད་རིགས་ཀྱི་སྤྱིར་བཏང་བའི་ཆ་མཐོང་ཚད་ལྟར་ཞིབ་བྱེད་ན། ཇུས་ཡིན་Adversarial Natural Language Inference'}
{'en': 'Despite the success of multilingual pre-trained language models, it remains unclear to what extent these models have human-like generalization capacity across languages. The aim of this study is to investigate the out-of-distribution generalization of pre-trained language models through Natural Language Inference (NLI) in Japanese, the typological properties of which are different from those of English. We introduce a synthetically generated Japanese NLI dataset, called the Japanese Adversarial NLI (JaNLI) dataset, which is inspired by the English HANS dataset and is designed to require understanding of Japanese linguistic phenomena and illuminate the vulnerabilities of models. Through a series of experiments to evaluate the generalization performance of both Japanese and multilingual BERT models, we demonstrate that there is much room to improve current models trained on Japanese NLI tasks. Furthermore, a comparison of human performance and model performance on the different types of garden-path sentences in the JaNLI dataset shows that structural phenomena that ease interpretation of garden-path sentences for human readers do not help models in the same way, highlighting a difference between human readers and the models.', 'ar': 'على الرغم من نجاح نماذج اللغة متعددة اللغات المدربة مسبقًا ، لا يزال من غير الواضح إلى أي مدى تتمتع هذه النماذج بقدرة تعميم شبيهة بالإنسان عبر اللغات. الهدف من هذه الدراسة هو التحقيق في التعميم خارج التوزيع لنماذج اللغة المدربة مسبقًا من خلال الاستدلال اللغوي الطبيعي (NLI) باللغة اليابانية ، والتي تختلف خصائصها النمطية عن تلك الموجودة في اللغة الإنجليزية. نقدم مجموعة بيانات NLI يابانية تم إنشاؤها صناعياً ، تسمى مجموعة بيانات Adversarial NLI اليابانية (JaNLI) ، وهي مستوحاة من مجموعة بيانات HANS الإنجليزية ، وهي مصممة لتتطلب فهم الظواهر اللغوية اليابانية وإلقاء الضوء على نقاط ضعف النماذج. من خلال سلسلة من التجارب لتقييم أداء التعميم لكل من نماذج BERT اليابانية ومتعددة اللغات ، نوضح أن هناك مجالًا كبيرًا لتحسين النماذج الحالية المدربة على مهام NLI اليابانية. علاوة على ذلك ، تُظهر مقارنة الأداء البشري وأداء النموذج على الأنواع المختلفة من جمل مسار الحديقة في مجموعة بيانات JaNLI أن الظواهر الهيكلية التي تسهل تفسير جمل مسار الحديقة للقراء البشريين لا تساعد النماذج بنفس الطريقة ، مما يبرز الاختلاف بين القراء والنماذج.', 'pt': 'Apesar do sucesso dos modelos de linguagem pré-treinados multilíngues, ainda não está claro até que ponto esses modelos têm capacidade de generalização semelhante à humana entre os idiomas. O objetivo deste estudo é investigar a generalização fora da distribuição de modelos de linguagem pré-treinados por meio de Inferência de Linguagem Natural (NLI) em japonês, cujas propriedades tipológicas são diferentes das do inglês. Apresentamos um conjunto de dados NLI japonês gerado sinteticamente, chamado de conjunto de dados Japanese Adversarial NLI (JaNLI), que é inspirado no conjunto de dados inglês HANS e é projetado para exigir a compreensão dos fenômenos linguísticos japoneses e iluminar as vulnerabilidades dos modelos. Por meio de uma série de experimentos para avaliar o desempenho de generalização de modelos BERT japoneses e multilíngues, demonstramos que há muito espaço para melhorar os modelos atuais treinados em tarefas NLI japonesas. Além disso, uma comparação entre o desempenho humano e o desempenho do modelo nos diferentes tipos de frases de caminho de jardim no conjunto de dados JaNLI mostra que fenômenos estruturais que facilitam a interpretação de frases de caminho de jardim para leitores humanos não ajudam os modelos da mesma maneira, destacando uma diferença entre os leitores humanos e os modelos.', 'fr': "Malgré le succès des modèles linguistiques multilingues préformés, on ne sait toujours pas dans quelle mesure ces modèles ont une capacité de généralisation similaire à celle de l'humain dans toutes les langues. Le but de cette étude est d'étudier la généralisation hors distribution de modèles linguistiques pré-entraînés par l'inférence du langage naturel (NLI) en japonais, dont les propriétés typologiques sont différentes de celles de l'anglais. Nous introduisons un jeu de données NLI japonais généré synthétiquement, appelé jeu de données NLI (Japanese Adversarial NLI), qui s'inspire du jeu de données HANS anglais et est conçu pour exiger la compréhension des phénomènes linguistiques japonais et mettre en lumière les vulnérabilités des modèles. Grâce à une série d'expériences visant à évaluer les performances de généralisation des modèles BERT japonais et multilingues, nous démontrons qu'il existe une grande marge d'amélioration des modèles actuels formés sur des tâches NLI japonaises. En outre, une comparaison des performances humaines et des performances des modèles sur les différents types de phrases de chemin de jardin dans l'ensemble de données JanLi montre que les phénomènes structurels qui facilitent l'interprétation des phrases de chemin de jardin pour les lecteurs humains n'aident pas les modèles de la même manière, mettant en évidence une différence entre les humains les lecteurs et les modèles.", 'es': 'A pesar del éxito de los modelos lingüísticos multilingües preentrenados, no está claro hasta qué punto estos modelos tienen una capacidad de generalización similar a la humana en todos los idiomas. El objetivo de este estudio es investigar la generalización fuera de distribución de modelos de lenguaje preentrenados a través de la Inferencia de Lenguaje Natural (NLI) en japonés, cuyas propiedades tipológicas son diferentes de las del inglés. Presentamos un conjunto de datos NLI japonés generado sintéticamente, denominado conjunto de datos NLI adversarial japonés (JanLI), que se inspira en el conjunto de datos HANS en inglés y está diseñado para requerir la comprensión de los fenómenos lingüísticos japoneses e iluminar las vulnerabilidades de los modelos. A través de una serie de experimentos para evaluar el rendimiento de generalización de los modelos BERT japoneses y multilingües, demostramos que hay mucho margen para mejorar los modelos actuales capacitados en tareas de NLI en japonés. Además, una comparación del rendimiento humano y el rendimiento del modelo en los diferentes tipos de oraciones de camino de jardín en el conjunto de datos de JanLi muestra que los fenómenos estructurales que facilitan la interpretación de oraciones de camino de jardín para lectores humanos no ayudan a los modelos de la misma manera, destacando una diferencia entre humanos lectores y modelos.', 'ru': 'Несмотря на успех многоязычных заранее подготовленных языковых моделей, остается неясным, в какой степени эти модели обладают человекоподобной способностью к обобщению между языками. Целью данного исследования является исследование внераспределительного обобщения предварительно обученных языковых моделей с помощью естественного языкового вывода (NLI) на японском языке, типологические свойства которого отличаются от свойств английского языка. Мы вводим синтетически сгенерированный японский набор данных NLI, называемый японским набором данных состязательного NLI (JaNLI), который вдохновлен английским набором данных HANS и предназначен для того, чтобы требовать понимания японских языковых явлений и освещать уязвимости моделей. С помощью серии экспериментов по оценке общих характеристик японских и многоязычных моделей BERT, мы демонстрируем, что есть много возможностей для улучшения текущих моделей, обученных японским задачам NLI. Кроме того, сравнение показателей деятельности человека и эффективности модели для различных типов предложений садового пути в наборе данных JaNLI показывает, что структурные явления, которые облегчают интерпретацию предложений садового пути для читателей, не помогают моделям одинаково, подчеркивая различие между читателями и моделями.', 'ja': '事前に訓練された多言語言語モデルの成功にもかかわらず、これらのモデルが言語全体で人間のような一般化能力をどの程度持っているかはまだ不明である。 本研究の目的は、日本語の自然言語推論（ NLI ）を通じて、事前に訓練された言語モデルの分布外一般化を調査することであり、その類型的性質は英語とは異なる。 英語のHANSデータセットにインスパイアされ、日本語の言語現象の理解を必要とし、モデルの脆弱性を明らかにするように設計された、日本語のAdversarial NLI （ JaNLI ）データセットと呼ばれる合成生成された日本語NLIデータセットを紹介します。 日本語と多言語の両方のBERTモデルの一般化パフォーマンスを評価する一連の実験を通じて、日本語のNLIタスクで訓練された現在のモデルを改善する余地があることを実証します。 さらに、ＪａＮＬＩデータセットの異なる種類のガーデンパス文の人間のパフォーマンスとモデルのパフォーマンスの比較は、人間の読者のためのガーデンパス文の解釈を容易にする構造現象が、同じ方法でモデルを助けないことを示し、人間の読者とモデルとの間の違いを強調する。', 'zh': '虽多言训语成功,未详其多大程度有跨语之类泛化能也。 本治以日语自然语言推理(NLI)治先训之言形布外泛化,其类型学性与英语异。 引入一合成日语NLI数集,名曰日语对抗性NLI(JaNLI)数集,其数自英语HANS数集,指求解日语语言象而明模形之脆弱性。 列实验以质日语与多言BERT其泛化性,吾验日语NLI之所习,犹有大改也。 JaNLI数聚会,比诸园径句句,为人读者简园径句说之象对模型无同助,异乎人读者与模形之异。', 'hi': 'बहुभाषी पूर्व-प्रशिक्षित भाषा मॉडल की सफलता के बावजूद, यह स्पष्ट नहीं है कि इन मॉडलों में भाषाओं में मानव जैसी सामान्यीकरण क्षमता किस हद तक है। इस अध्ययन का उद्देश्य जापानी में प्राकृतिक भाषा अनुमान (एनएलआई) के माध्यम से पूर्व-प्रशिक्षित भाषा मॉडल के आउट-ऑफ-डिस्ट्रीब्यूशन सामान्यीकरण की जांच करना है, जिनमें से टाइपोलॉजिकल गुण अंग्रेजी के उन लोगों से अलग हैं। हम एक सिंथेटिक रूप से उत्पन्न जापानी एनएलआई डेटासेट पेश करते हैं, जिसे जापानी एडवर्सरियल एनएलआई (जेएनएनएलआई) डेटासेट कहा जाता है, जो अंग्रेजी हंस डेटासेट से प्रेरित है और जापानी भाषाई घटनाओं की समझ की आवश्यकता के लिए डिज़ाइन किया गया है और मॉडल की कमजोरियों को रोशन करता है। जापानी और बहुभाषी BERT मॉडल दोनों के सामान्यीकरण प्रदर्शन का मूल्यांकन करने के लिए प्रयोगों की एक श्रृंखला के माध्यम से, हम प्रदर्शित करते हैं कि जापानी एनएलआई कार्यों पर प्रशिक्षित वर्तमान मॉडल को बेहतर बनाने के लिए बहुत जगह है। इसके अलावा, JaNLI डेटासेट में विभिन्न प्रकार के उद्यान-पथ वाक्यों पर मानव प्रदर्शन और मॉडल प्रदर्शन की तुलना से पता चलता है कि संरचनात्मक घटनाएं जो मानव पाठकों के लिए बगीचे-पथ वाक्यों की व्याख्या को आसान बनाती हैं, मॉडल को उसी तरह से मदद नहीं करती हैं, मानव पाठकों और मॉडलों के बीच अंतर को उजागर करती हैं।', 'ga': 'In ainneoin gur éirigh go maith le múnlaí teanga ilteangacha réamhoilte, ní léir cé chomh mór agus atá acmhainn ginearálaithe ar nós an duine trasna teangacha ag na samhlacha seo. Tá sé mar aidhm ag an staidéar seo ginearálú eis-dáileadh na múnlaí teanga réamh-oilte a fhiosrú trí Tátail Teanga Nádúrtha (NLI) sa tSeapáinis, a bhfuil a n-airíonna tíopeolaíochta difriúil le hairíonna an Bhéarla. Tugaimid isteach tacar sonraí NLI Seapánach a ghintear go sintéiseach, ar a dtugtar tacar sonraí Japanese Adversarial NLI (JaNLI), atá spreagtha ag tacar sonraí HANS Béarla agus atá deartha chun tuiscint a éileamh ar fheiniméin theangeolaíocha na Seapáine agus leochaileachtaí na múnlaí a léiriú. Trí shraith turgnaimh chun feidhmíocht ginearálaithe na múnlaí BERT Seapáine agus ilteangacha araon a mheas, léirímid go bhfuil go leor spáis ann feabhas a chur ar mhúnlaí reatha atá oilte ar thascanna LNÉ na Seapáine. Ina theannta sin, léiríonn comparáid idir feidhmíocht an duine agus feidhmíocht mhúnla ar na cineálacha éagsúla abairtí cosáin gairdín i dtacar sonraí JaNLI nach gcuidíonn feiniméin struchtúracha a éascaíonn léirmhíniú abairtí cosán gairdín do léitheoirí daonna le samhlacha ar an mbealach céanna, rud a léiríonn difríocht. idir léitheoirí daonna agus na múnlaí.', 'hu': 'A többnyelvű, előre képzett nyelvi modellek sikere ellenére továbbra sem világos, hogy ezek a modellek milyen mértékben rendelkeznek emberi-szerű általánosítási kapacitással a nyelvek között. A tanulmány célja, hogy megvizsgálja az előre képzett nyelvi modellek eloszláson kívüli általánosítását a Natural Language Inference (NLI) japán nyelven, amelyek tipológiai tulajdonságai eltérnek az angol nyelvtől. Bemutatunk egy szintetikusan generált japán NLI adatkészletet, a Japán Adversarial NLI (JaNLI) nevű adatkészletet, amelyet az angol HANS adatkészlet ihletett, és úgy terveztünk, hogy megkövetelje a japán nyelvi jelenségek megértését és felvilágítsa a modellek sebezhetőségeit. A japán és többnyelvű BERT modellek általánosítási teljesítményének értékelésére szolgáló kísérletsorozat révén bebizonyítjuk, hogy sok hely van a japán NLI feladatokra képzett aktuális modellek fejlesztésére. Továbbá a JaNLI adatkészletben található különböző típusú kerti-út mondatok emberi teljesítményének és modellteljesítményének összehasonlítása azt mutatja, hogy a kerti-út mondatok értelmezését megkönnyítő strukturális jelenségek az emberi olvasók számára nem hasonló módon segítenek a modelleken, kiemelve az emberi olvasók és a modellek közötti különbséget.', 'ka': 'მრავალენგიური წარმატების წარმატებით უფრო მხოლოდ წარმატებული ენახის მოდელების შემდეგ, ეს უცნობიერია თუ რამდენი ეს მოდელების განმავლობაში ადამიანის გენერალიზაციის ამ სწავლის მიზეზი არის იგივე, რომ წაპონეთიური ენერგიის განსხვავებული მადელების განსხვავებული განსხვავებული განსხვავება, რომლის ტიპოლოგიური განსხვავება ანგლისური მოდელების განსხვავება. ჩვენ სინტეტიკურად დავიყენებთ წაპონიური NLI მონაცემების სექტი, რომელიც წაპონიური კონპერაციალური NLI (JaNLI) მონაცემების სექტი, რომელიც ინგლისური HANS მონაცემების სექტიდან ინგლისური HANS მონაცემების შე ექსპერიმენტების სერიონის გამოყენებით, რომლებიც იგივე იაპონიანი და მრავალენგური BERT მოდელეების გენერალიზაციის გამოყენებას, ჩვენ მოვიდენობთ, რომ არსებობს ბევრი ადგილი, რომელიც წ დამატებით, ადამიანის გამოსახულება და მოდელური გამოსახულება განსხვავებული სახულების სახულების განსხვავებული სახულების გამოსახულება JaNLI მონაცემების მონაცემების სტრუქტური ფენომენების განსხვავება, რომელიც ადამიანის კითხველებისთვის სახულების გამო', 'kk': 'Бірнеше тілді алдын- ала оқылған тіл үлгілерінің сәттілігіне қарамастан, бұл үлгілердің адамдардың жалпы жалпы жалпы тілдерінің қанша көмегімен байқалмайды. Бұл зерттеулердің мақсаты жапон тілдерінің табиғи тілдерінің (NLI) қасиеттерінің типтологиялық қасиеттері ағылшын тілдерінен бірнеше түрлендіру. Біз жапон конверсариялық NLI (JaNLI) деректер жиынына синтетикалық құрылған жапон NLI деректер жиынын таңдадық. Бұл ағылшын HANS деректер жиының түсініктемесін талап ету үшін жапон лингвистикалық панелдерін түсініп, моделдердің уязықтығын жары Жапон және көптілік BERT моделдерінің жалпы түрлендіру үшін бірнеше тәжірибелер арқылы жапон және көптілік үлгілерінің жалпы түрлендіру мүмкіндігін бағалау үшін біз жапон NLI тап Қосымша, JaNLI деректер қорларындағы бағат жолының әртүрлі түрлерінде адамдардың істеу және үлгіліктерін салыстыру үшін адамдардың оқушыларының бағат жолының толықтыруын көмектесетін құрастырмалы пайдаланулары адамдардың оқушылары мен үлгілердің айырмашыл', 'mk': 'И покрај успехот на мултијазичните предобучени јазички модели, останува нејасно во колку овие модели имаат човечки капацитет за генерализација низ јазиците. Целта на оваа студија е да се истражи генерализацијата надвор од дистрибуција на предобучените јазички модели преку природната јазична инференција (НЛИ) на јапонски, чии типологички имотности се различни од оние на англиски. Ние воведуваме синтетички генериран јапонски набор на податоци на НЛИ, наречен јапонски набор на податоци на НЛИ (JaNLI), кој е инспириран од англискиот набор на податоци на ХАНС и е дизајниран за да бара разбирање на јапонските јазички феномени и осветлување на ранливостите на моделите. Со серија експерименти за проценка на генерализацијата на јапонските и мултијазичните модели на БЕРТ, демонстрираме дека има многу место за подобрување на сегашните модели обучени за јапонските НЛИ задачи. Покрај тоа, споредбата на човечката перформанса и моделната перформанса на различните типови на реченици од градината во податоците на JaNLI покажува дека структурните феномени кои ја олеснуваат интерпретацијата на речениците од градината за човечките читатели не помагаат на моделите на истиот начин, истакнувајќи ја разликата помеѓу човечките читат', 'el': 'Παρά την επιτυχία των πολύγλωσσων προ-εκπαιδευμένων γλωσσικών μοντέλων, παραμένει ασαφές σε ποιο βαθμό αυτά τα μοντέλα έχουν ανθρώπινη ικανότητα γενικοποίησης μεταξύ των γλωσσών. Στόχος της παρούσας μελέτης είναι η διερεύνηση της γενικοποίησης των προ-εκπαιδευμένων γλωσσικών μοντέλων μέσω της Συμπερασματικής Φυσικής Γλώσσας στα Ιαπωνικά, οι τυπολογικές ιδιότητες των οποίων διαφέρουν από αυτές των Αγγλικών. Παρουσιάζουμε ένα συνθετικά παραγόμενο ιαπωνικό σύνολο δεδομένων το οποίο είναι εμπνευσμένο από το αγγλικό σύνολο δεδομένων και έχει σχεδιαστεί για να απαιτεί κατανόηση των ιαπωνικών γλωσσικών φαινομένων και να φωτίζει τις τρωτότητες των μοντέλων. Μέσα από μια σειρά πειραμάτων για την αξιολόγηση της απόδοσης γενικοποίησης τόσο των ιαπωνικών όσο και των πολυγλωσσικών μοντέλων καταδεικνύουμε ότι υπάρχει πολύς χώρος για τη βελτίωση των σημερινών μοντέλων που εκπαιδεύονται σε ιαπωνικές εργασίες. Επιπλέον, μια σύγκριση της ανθρώπινης απόδοσης και της απόδοσης του μοντέλου στους διαφορετικούς τύπους προτάσεων για τον κήπο-μονοπάτι στο σύνολο δεδομένων δείχνει ότι δομικά φαινόμενα που διευκολύνουν την ερμηνεία των προτάσεων για τους ανθρώπινους αναγνώστες δεν βοηθούν τα μοντέλα με τον ίδιο τρόπο, επισημαίνοντας τη διαφορά μεταξύ των ανθρώπινων αναγνωστών και των μοντέλων.', 'lt': 'Nepaisant daugiakalbių išankstinio mokymo kalbų modelių sėkmės, vis dar neaišku, kokiu mastu šie modeliai turi žmogaus panašių bendrųjų kalbų gebėjimų. Šio tyrimo tikslas – ištirti iš anksto parengtų kalbų modelių neperdirbtiną generalizaciją naudojant gamtinės kalbos inferenciją (NLI) japonų kalba, kurių tipologinės savybės skiriasi nuo anglų kalbos. Įdiegiame sintetiškai sukurtą Japonijos NLI duomenų rinkinį, vadinamą Japonijos prieštaringo NLI (JaNLI) duomenų rinkinį, kurį įkvėpia anglų HANS duomenų rinkinys ir kuriame reikalaujama suprasti Japonijos kalbinius reiškinius ir apšviesti modelių pažeidžiamumus. Atliekant keletą eksperimentų, skirtų įvertinti Japonijos ir daugiakalbių BERT modelių generalizacijos rezultatus, parodome, kad yra daug vietos tobulinti dabartinius modelius, parengtus Japonijos NLI užduotyse. Be to, JaNLI duomenų rinkinyje palyginus žmogaus veiklos rezultatus ir įvairių rūšių sodo kelio sakinių model į matyti, kad struktūriniai reiškiniai, palengvinantys žmonių skaitytojų sodo kelio sakinių aiškinimą, taip pat nepadeda modeliams, pabrėžiant žmogaus skaitytojų ir modelių skirtumą.', 'it': "Nonostante il successo dei modelli linguistici pre-formati multilingue, non è chiaro in che misura questi modelli abbiano una capacità di generalizzazione umana tra le lingue. Lo scopo di questo studio è quello di indagare la generalizzazione fuori-distribuzione di modelli linguistici pre-formati attraverso Natural Language Inference (NLI) in giapponese, le cui proprietà tipologiche sono diverse da quelle dell'inglese. Introducemo un dataset giapponese NLI generato sinteticamente, chiamato Japanese Adversarial NLI (JaNLI), che si ispira al dataset inglese HANS ed è progettato per richiedere la comprensione dei fenomeni linguistici giapponesi e illuminare le vulnerabilità dei modelli. Attraverso una serie di esperimenti per valutare le prestazioni di generalizzazione di entrambi i modelli BERT giapponesi e multilingue, dimostriamo che c'è molto spazio per migliorare i modelli attuali formati sui compiti NLI giapponesi. Inoltre, un confronto tra performance umane e performance del modello sui diversi tipi di frasi di percorso giardino nel dataset JaNLI mostra che i fenomeni strutturali che facilitano l'interpretazione delle frasi di percorso giardino per i lettori umani non aiutano i modelli allo stesso modo, evidenziando una differenza tra lettori umani e modelli.", 'ml': 'Despite the success of multilingual pre-trained language models, it remains unclear to what extent these models have human-like generalization capacity across languages.  ഈ പഠനത്തിന്റെ ലക്ഷ്യം ജാപ്പാനീസിലെ സ്വാഭാഷയുടെ (NLI) മുമ്പ് പരിശീലന ഭാഷ മോഡലുകളുടെ പുറത്തുനിന്നുള്ള വിതരണ മാതൃകങ്ങള്\u200d പരിശോധിക്കുന്നതിനാണ്.  ജപ്പാനീസ് അഡ്വാരരിയല്\u200d NLI (ജാന്\u200dലി) എന്ന ഡാറ്റാസെറ്റ് എന്ന പേരുള്ള ജാപ്പാന്\u200d നിര്\u200dമ്മിക്കുന്ന ഒരു സിനിസ്റ്റീക്കില്\u200d നാം പരിചയപ്പെടുത്തുന്നു. അത് ഇംഗ്ലീഷ് ഹാന്\u200dസ് ഡാറ് ജപ്പാനീസിലേക്കും പല ഭാഷയിലേക്കുമുള്ള ബെര്\u200dട്ടി മോഡലുകളുടെയും പ്രഭാഷണത്തെ പരീക്ഷിക്കാന്\u200d ഒരുപാട് പരീക്ഷണങ്ങളിലൂടെ ഞങ്ങള്\u200d കാണിക്കുന്നു, ജാപ്പ അതിനുശേഷം, ജാന്\u200dലിയിലെ വ്യത്യസ്ത തരത്തിലെ തോട്ടത്തിലുള്ള വാക്കുകളില്\u200d മനുഷ്യരുടെ പ്രവര്\u200dത്തനവും മോഡല്\u200d പ്രവര്\u200dത്തനവും ഒരു താല്\u200dക്കീത് കാണിക്കുന്നു. മനുഷ്യര്\u200d വായിക്കുന്നവര്\u200dക്ക', 'ms': 'Despite the success of multilingual pre-trained language models, it remains unclear to what extent these models have human-like generalization capacity across languages.  Tujuan penelitian ini adalah untuk menyelidiki generalisasi luar distribusi model bahasa yang dilatih sebelum melatih melalui Natural Language Inference (NLI) dalam bahasa Jepun, sifat tipologi yang berbeza dari sifat bahasa Inggeris. Kami memperkenalkan set data NLI Jepun yang dijana secara sintetik, yang dipanggil set data NLI (JaNLI) Jepun Adversarial, yang diinspirasi oleh set data HANS Inggeris dan direka untuk memerlukan pemahaman fenomena bahasa Jepun dan menyalakan kelemahan model. Melalui sejumlah eksperimen untuk menilai prestasi generalisasi model BERT Jepun dan berbilang bahasa, kami menunjukkan bahawa terdapat banyak ruang untuk meningkatkan model semasa dilatih dalam tugas NLI Jepun. Lagipun, perbandingan prestasi manusia dan prestasi model pada jenis-jenis kalimat laluan kebun yang berbeza dalam set data JaNLI menunjukkan bahawa fenomena struktur yang memudahkan interpretasi kalimat laluan kebun bagi pembaca manusia tidak membantu model dengan cara yang sama, menandakan perbezaan antara pembaca manusia dan model.', 'mt': 'Despite the success of multilingual pre-trained language models, it remains unclear to what extent these models have human-like generalization capacity across languages.  L-għan ta’ dan l-istudju huwa li jinvestiga l-ġeneralizzazzjoni barra mid-distribuzzjoni ta’ mudelli lingwistiċi mħarrġa minn qabel permezz ta’ Inferenza tal-Lingwa Naturali (NLI) bil-Ġappuniż, li l-karatteristiċi tipoloġiċi tagħhom huma differenti minn dawk tal-Ingliż. Aħna nintroduċu sett tad-dejta Ġappuniż tal-NLI ġġenerat b’mod sintetiku, imsejjaħ sett tad-dejta Ġappuniż tal-Adversarji tal-NLI (JaNLI), li huwa ispirat mis-sett tad-dejta Ingliż HANS u huwa ddisinjat biex jeħtieġ fehim tal-fenomeni lingwistiċi Ġappuniżi u jdawwal il-vulnerabbiltajiet tal-mudelli. Permezz ta’ serje ta’ esperimenti biex tiġi evalwata l-prestazzjoni tal-ġeneralizzazzjoni kemm tal-mudelli BERT Ġappuniżi kif ukoll multilingwi, nagħmlu xhieda li hemm ħafna spazju biex jittejbu l-mudelli attwali mħarrġa dwar il-kompiti NLI Ġappuniżi. Furthermore, a comparison of human performance and model performance on the different types of garden-path sentences in the JaNLI dataset shows that structural phenomena that ease interpretation of garden-path sentences for human readers do not help models in the same way, highlighting a difference between human readers and the models.', 'no': 'Til tross fullføringa av fleirspråksmodeller for først treng språk, er det ikkje klart til kor mykje desse modelane har menneskelig generelliseringskapasitet over språk. Målet for denne studien er å undersøke generelliseringen av utfordelingsmodeller av først trengte språk gjennom naturspråk (NLI) i japansk, typologiske eigenskapane som er ulike frå engelske. Vi introduserer ein sintetisk generert japansk NLI-dataset, kalla den japanske Adversarial NLI-dataset (JaNLI), som er inspirert av den engelske HANS-dataset og er designert for å kreve forståelse av japanske lingviske fenomen og lyse sårbarheten av modeller. Gjennom ein rekke eksperimenter for å evaluera generelliseringsfunksjonen av både japanske og fleirspråk BERT-modeller, viser vi at det finst mye rom for å forbetra gjeldande modeller som trengte på japanske NLI-oppgåver. I tillegg viser eit sammenligning av menneskelige utviklingar og modelleutviklingar på dei ulike typane gardenstige setningane i JaNLI-datasettet at strukturfenomen som lett tolking av gardenstige setningar for menneskelige lesarar ikkje hjelper modeller på samme måte, og markerer ein forskjell mellom menneskelige lesarar og modelane.', 'pl': 'Pomimo sukcesu wielojęzycznych modeli językowych wstępnie przeszkolonych, pozostaje niejasne, w jakim stopniu modele te mają zdolność do uogólniania w różnych językach. Celem niniejszego opracowania jest zbadanie pozadystrybucyjnego uogólnienia wstępnie przeszkolonych modeli językowych poprzez Natural Language Inference (NLI) w języku japońskim, których właściwości typologiczne różnią się od właściwości angielskiego. Wprowadzamy syntetycznie generowany japoński zestaw danych NLI, zwany JaNLI (JaNLI), który jest inspirowany angielskim zbiorem danych HANS i ma na celu wymaganie zrozumienia japońskich zjawisk językowych i oświetlenie luk modeli. Poprzez serię eksperymentów mających na celu ocenę wydajności uogólnienia zarówno japońskich, jak i wielojęzycznych modeli BERT, pokazujemy, że istnieje dużo miejsca na ulepszenie obecnych modeli trenowanych w japońskich zadaniach NLI. Ponadto porównanie wydajności człowieka i wydajności modelu na różnych typach zdań ogrodowych w zbiorze danych JaNLI pokazuje, że zjawiska strukturalne ułatwiające interpretację zdań ogrodowych dla czytelników nie pomagają modelom w ten sam sposób, podkreślając różnicę między ludzkimi czytelnikami a modelami.', 'sr': 'Uprkos uspjehu multijezičkih pre-obučenih jezičkih modela, ostaje nepoznato u kolikoj mjeri ovi modeli imaju kapacitet generalizacije poput ljudi na jezika. Cilj ovog istraživanja je istražiti generalizaciju izvan distribucije predobučenih jezičkih modela kroz prirodnu jezičku Inferenciju (NLI) na japanskom jeziku, njihova tipološka vlasništva su drugačija od onih engleskog jezika. Upoznajemo sintetički generiranu japansku NLI podatku, nazvanu Japanski savezni NLI (JaNLI), koji je inspirisan Engleskim HANS podacima i dizajniran da bi trebalo da razumemo japanske jezičke fenomene i da objasnimo ranjivost modela. Kroz niz eksperimenata za procjenu generalizacije i japanskih i multijezičkih BERT modela, pokazujemo da postoji mnogo prostora za poboljšanje trenutnih modela obučenih na japanski NLI zadatak. Osim toga, usporedba ljudskih predstava i model a o različitim vrtovima rečenica na vrtu-putu u JaNLI podacima pokazuje da strukturni fenomeni koji olakšaju interpretaciju rečenica na vrtu-putu za ljudske čitače ne pomažu modelima na isti način, naglašavajući razliku između ljudskih čitača i modela.', 'mn': 'Олон хэл сургалтын өмнө сургалтын хэл загварын амжилтыг хүртэл эдгээр загварууд хэл дээр хүн төрөлхтний төстэй ерөнхийлөгчийн чадвар ямар хэмжээнд байдгийг ойлгохгүй байна. Энэ судалгааны зорилго нь англи хэл загваруудын өмнө суралцагдсан хэл загваруудыг Япон хэлний Байгалийн Холбооны (NLI) хэлбэрээр судалгаа хийх юм. Бид Япон Конверсариал NLI (JaNLI) өгөгдлийн сан гэдэг Япон NLI өгөгдлийн санг сануулдаг. Энэ нь Англи ХаNS өгөгдлийн сангийн урам зориулагдсан ба Япон хэлний үзэгдлийг ойлгохын тулд зориулагдсан. Япон болон олон хэлний BERT загварын ерөнхийлөгчийн үйл ажиллагааг үнэлэх олон туршилтаар бид Японы NLI ажиллагаанд сургалтын моделуудыг сайжруулах маш олон орон байдгийг харуулж байна. Мөн хүн төрөлхтний үйл ажиллагааны болон загварын үйл ажиллагааны харьцуулалт нь JaNLI өгөгдлийн сангийн олон төрлийн салбарын өргөмжийг хүмүүсийн уншигчид салбарын өргөмжийг хялбарчлах бүтэц үйл ажиллагааны үйл ажиллагааны тухай харьцуулах нь хүний уншигчид болон загварын ялгааг ил', 'sv': 'Trots framgångarna med flerspråkiga förklädda språkmodeller är det fortfarande oklart i vilken utsträckning dessa modeller har mänsklig generaliseringskapacitet över språk. Syftet med denna studie är att undersöka generaliseringen av förutbildade språkmodeller genom Natural Language Inference (NLI) på japanska, vars typologiska egenskaper skiljer sig från engelska. Vi introducerar en syntetiskt genererad japansk NLI-datauppsättning, kallad Japanese Adversarial NLI (JaNLI), som är inspirerad av den engelska HANS-datauppsättningen och är utformad för att kräva förståelse för japanska språkliga fenomen och belysa sårbarheterna hos modeller. Genom en serie experiment för att utvärdera generaliseringen av både japanska och flerspråkiga BERT-modeller visar vi att det finns mycket utrymme att förbättra nuvarande modeller utbildade på japanska NLI-uppgifter. Vidare visar en jämförelse av mänsklig prestanda och modellprestanda på de olika typerna av trädgårdssökord i JaNLI datauppsättningen att strukturella fenomen som underlättar tolkningen av trädgårdssökord för mänskliga läsare inte hjälper modeller på samma sätt, vilket belyser en skillnad mellan mänskliga läsare och modeller.', 'so': 'Inkastoo ay guulaysteen samooyinka afka kala duwan oo luuqadaha la tababaray, ma garan karto sida qaababkan noocyadan ay u leeyihiin awood u dhalashada sida dadka oo kale luqadaha oo dhan. Ujeedada waxbarashadu waa in lagu baaraandegayo tusaalaha afka hore oo lagu tababariyey ee afka asalka ah (NLI) oo jabaneeska ah, noocyada qaabilsan oo ay ka duwan yihiin kuwa ingiriisiga ah. Waxaynu soo bandhignaa sawirada NALI ee Japanese Adversarial NLI (JaNLI) oo la yidhaahdo, kaas oo laguugu soo dhiibay taariikhda afka Ingiriiska HANS, waxaana loo qoray in loo baahan yahay garashada muuqashada afka japaniya iyo in loo iftiimiyo waxyaabaha u halista modellada. Imtixaano kala duduwan oo lagu qiimeeyo sameynta dhalashada modelalka BERT ee Japoniya iyo kuwa luuqadaha kala duduwan, waxaynu muujinnaa inay leedahay qolo badan oo hagaajiya modelalka hada lagu baray shaqada NLI ee Japanese. Furthermore, tusaale ahaan sameynta sameynta dadweynaha iyo tusaale ahaan xukunka kala duduwan ee hagitaanka ee JaNLI-dataset waxay tustaa fikrada dhismaha ah oo fudud turjumaadda hagitaanka ee dadka akhriya uma caawiyo tusaale u eg, wuxuuna ku caddeeyaa kala duwan u dhexeeya akhriska dadka iyo modelalka.', 'ro': 'În ciuda succesului modelelor lingvistice pre-instruite multilingve, rămâne neclar în ce măsură aceste modele au capacitatea de generalizare umană în toate limbile. Scopul acestui studiu este de a investiga generalizarea în afara distribuției modelelor lingvistice pre-instruite prin Inferența Limbii Naturale (NLI) în japoneză, ale căror proprietăți tipologice sunt diferite de cele ale limbii engleze. Introducem un set de date NLI japonez generat sintetic, numit set de date NLI japonez Adversarial (JaNLI), care este inspirat din setul de date HANS englez și este conceput pentru a necesita înțelegerea fenomenelor lingvistice japoneze și a ilumina vulnerabilitățile modelelor. Printr-o serie de experimente pentru evaluarea performanței de generalizare atât a modelelor japoneze, cât și a modelelor multilingve BERT, demonstrăm că există mult spațiu pentru îmbunătățirea modelelor curente instruite pe sarcini NLI japoneze. Mai mult decât atât, o comparație între performanța umană și performanța modelului pe diferitele tipuri de propoziții de cale de grădină din setul de date JaNLI arată că fenomenele structurale care ușurează interpretarea propozițiilor de cale de grădină pentru cititorii umani nu ajută modelele în același mod, evidențiind o diferență între cititorii umani și modele.', 'si': 'ගොඩක් භාෂාවක් ප්\u200dරීක්ෂණා කරපු භාෂාවක් මොඩේල් විශ්වාස කරලා තියෙනවා නමුත්, මේ මොඩේල් වල මිනිස්සු වගේ සාමා මේ පරීක්ෂණයේ ලක්ෂණය තමයි ජාපානියේ ප්\u200dරාභික භාෂාව ප්\u200dරශ්නය (NLI) වලින් ප්\u200dරාභික භාෂාව ප්\u200dරශ්නය (ප්\u200dරාභික භාෂාවික) වල අපි සම්පූර්ණයෙන් ජාපානිස් NLI දත්ත සෙට් එකක් ප්\u200dරදේශ කරනවා, ජාපානිස් සම්පූර්ණය NLI (JaNLI) දත්ත සෙට් කියලා, ඒක ඉංග්\u200dරීසි HANS දත්ත සෙට් එකෙන් ප්\u200dරේෂණ ජාපානි සහ ගොඩක් භාෂාවක් BERT මෝඩල් වලින් සාමාන්\u200dය විශ්වාස කරන්න ප්\u200dරයෝජනයක් වලින් ප්\u200dරයෝජනය කරනවා කියලා අපි පෙන්වන්නේ ජාප තවත්, මිනිස්සු වැඩසටහන් සහ මනුස්සු වැඩසටහන් සටහන් කරනවා ජන්ලි දත්ත සටහනේ වෙනස් වර්ඩිය-පාත වර්ඩියේ වර්ඩියේ වර්ඩියේ ප්\u200dරකාරයක් පෙන්වනවා කියලා, මිනිස් කියවන්', 'ta': 'பல மொழி மொழி மாதிரிகளின் வெற்றியடைந்த பின்னரும், இந்த மாதிரிகளின் மனித போன்ற பொதுவான உருவாக்கத்திற்கு முன் பயிற்சி முன இந்த ஆராய்ச்சியின் இலக்கு என்பது ஜப்பானியில் இயல்பான மொழியின் மூலம் பாதுகாப்பு (NLI) மூலம் மூலம் பயிற்சிய மொழி மாதிரியின் வெளியே வெளியேற்றப் ஜாப்பானிய அரசியல் NLI (ஜான்லி) தகவல் அமைப்பை நாம் ஒரு கூட்டிணைப்பாக உருவாக்கிய ஜப்பானிய NLI தகவல் அமைப்பை குறிப்பிடுகிறோம். இது ஆங்கிலத்தில் HANS தரவுத்தளத்தால் தெரிவிக்கப ஜப்பானிய மற்றும் பல மொழி பிரெட் மாதிரிகளின் பொதுவான செயல்பாட்டை மதிப்பீடு செய்ய ஒரு சில பரிசோதனைகள் மூலம் நாம் காண்பிக்கிறோம் ஜப்பானிய NLI பணி அதற்கும், ஜான்லி தரவுத்தளத்தில் மாதிரி செயல்பாடு மற்றும் மாதிரி செயல்பாட்டின் ஒப்பிடுப்பாடு ஜான்லியின் வாக்கியங்களில் உள்ள வேறு வகைகளின் மாதிரியை காட்டுகிறது அமைப்பு', 'ur': 'بہت سی زبان کی پیش آموزش کی زبان موڈل کے کامیابی کے بغیر، یہ بات کس طرح معلوم رہتی ہے کہ ان موڈلوں میں انسان کی طرح عمومی سازی کی قابلیت زبانوں میں ہے. اس مطالعہ کا مطالعہ یہ ہے کہ پہلے تدریس کی زبان مدلکوں کی بغیر تقسیم کی عمومی تحقیق کرنا جاپانی زبان کے مطالعہ سے، جن کی تایپولوژیکوں کا اختیار انگلیسی کے مطالعہ سے مختلف ہے. ہم ایک جپانیایی NLI ڈاٹ سٹ کو معرفی کرتے ہیں جن کا نام جاپانیایی اڈارسٹ NLI (JaNLI) ڈاٹ سٹ ہے جو انگلیسی HANS ڈاٹ سٹ کے ذریعے الهام کیا جاتا ہے اور جاپانیایی زبان پڑھنے کی ضرورت کی ہے اور مدلوں کی نہایت اضطراری کو روشن کرتا ہے۔ ایک سری آزمائش کے ذریعے جپانیایی اور بہت سی زبانی BERT موڈل کی عمومی فعالیت کا ارزش کرنے کے لئے ہم نشان دیتے ہیں کہ جاپانیایی NLI کے کاموں پر آموزش کی موڈل بہت سی جگہ ہے۔ اور اس کے علاوہ، انسان کے کامیابی اور موڈل کے کامیابی کا مقایسہ جNLI ڈیٹسٹ میں مختلف بہشت پاؤں کا فیصلہ دکھاتا ہے کہ ساختاری اتفاقات جو انسان کے پڑھنے والوں کے لئے باغ پاؤں کا تفسیر آسان کرتا ہے ان کے مطابق موڈلوں کی مدد نہیں کرتی، انسان کے پڑھنے والوں اور موڈلوں کے درمیان تفاوت کی', 'uz': "Despite the success of multilingual pre-trained language models, it remains unclear to what extent these models have human-like generalization capacity across languages.  Bu o'qituvchi maqsadi Japoniya tilidagi tabiiy til influence (NLI) orqali taʼminlovchi tildan oldin taʼminlovchi modellarni o'rganish natijasida o'rganish natijasida o'zgarishga ega bo'ladi. Bu tashkilotlar ingliz tilidagi turolog xossalaridan o'xshash. Biz Yaponcha NLI (JaNLI) haqida yaratilgan maʼlumotlar tarkibini ishlab chiqaramiz. Bu Inglizcha HANS maʼlumotlari tarkibini ishlatadi. Bu tilni o'rganish uchun japon tillarini tasavvur qilish kerak va modellarning vulniyatlarini ko'rsatish kerak. Japoniya va bir necha tilda BERT modellarining generaliz natijaligini qidirish uchun bir necha eksperimentelar orqali biz Joriy NLI vazifalarda o'rganish modellarini bajarish uchun juda ko'p xona bor. Ko'rsatganda, JaNLI maʼlumotlar tarkibidagi boshqa yo'l yo'l turlaridagi inson bajarish va model bajarishga misollar ko'rsatish mumkin. Bu holatda oddiy narsalarning o'quvchilarini saqlash mumkin, oddiy o'quvchilar va modellarning orasidagi bir usuli modelga yordam bermaydi.", 'vi': 'Mặc dù các mô hình ngôn ngữ đa dạng đã được đào tạo nhiều thành công, nhưng vẫn chưa rõ các mô hình này có khả năng tổng hợp con người xuyên qua các ngôn ngữ. Mục đích của nghiên cứu này là nghiên cứu loại ra khỏi phân phối các mô hình ngôn ngữ được đào tạo thông qua Liên Minh ngôn ngữ tự nhiên (NLI) ở Nhật Bản, các đặc tính khác với ngôn ngữ Anh. Chúng tôi giới thiệu một tập tin dữ liệu dòng họ Nhật Bản được tạo ra tổng hợp, được gọi là the Japanese Wersarial NLl (JaNLl) dataset, which is based by the English HABS dataset và được thiết kế để yêu cầu kiến thức về sự kiện ngôn ngữ Nhật và light the vulnerable of models. Qua một loạt các thí nghiệm để đánh giá khả năng tổng hợp của các mô hình BERT Nhật và nhiều trường khác nhau, chúng tôi chứng minh rằng có nhiều chỗ để cải thiện những mô hình hiện tại được rèn luyện trong các công việc KHÔNG Nhật Bản. Hơn nữa, so sánh khả năng của con người và khả năng mô hình với các loại câu thơ đường vườn khác nhau trong bộ dữ liệu JaNli cho thấy những hiện tượng cấu trúc dễ hiểu về các câu chữ vẽ đường vườn của con người không giúp mô hình theo cùng một cách, nhấn mạnh sự khác biệt giữa người đọc và các mô hình.', 'bg': 'Въпреки успеха на многоезичните предварително обучени езикови модели, остава неясно до каква степен тези модели имат човешки способност за обобщаване в различните езици. Целта на настоящото изследване е да се проучи генерализацията извън разпространението на предварително обучени езикови модели чрез естествени езикови изводи (НЛИ) на японски език, чиито типологични свойства са различни от тези на английски език. Въвеждаме синтетично генериран японски набор от данни, наречен японски рекламен набор от данни, който е вдъхновен от английския набор от данни и е предназначен да изисква разбиране на японските езикови явления и да осветява уязвимостта на моделите. Чрез серия от експерименти за оценка на генерализацията на японски и многоезични модели демонстрираме, че има много място за подобряване на настоящите модели, обучени по японски задачи. Освен това, сравнението на човешкото представяне и представянето на модела върху различните видове изречения по градински път в набора от данни показва, че структурните явления, които улесняват интерпретацията на изреченията по градински път за човешките читатели, не помагат на моделите по същия начин, подчертавайки разликата между човешките читатели и моделите.', 'da': 'På trods af succesen med flersprogede præuddannede sprogmodeller er det stadig uklart, i hvilket omfang disse modeller har menneskelig-lignende generaliseringskapacitet på tværs af sprog. Formålet med denne undersøgelse er at undersøge out-of-distribution generalisering af præuddannede sprogmodeller gennem Natural Language Inference (NLI) på japansk, hvis typologiske egenskaber er forskellige fra engelsk. Vi introducerer et syntetisk genereret japansk NLI datasæt, kaldet Japansk Adversarial NLI (JaNLI), som er inspireret af det engelske HANS datasæt og er designet til at kræve forståelse af japanske sproglige fænomener og belyse sårbarhederne i modeller. Gennem en række eksperimenter for at evaluere generaliseringen af både japanske og flersprogede BERT modeller, viser vi, at der er meget plads til at forbedre nuværende modeller trænet i japanske NLI-opgaver. Desuden viser en sammenligning af menneskelig præstation og model præstation på de forskellige typer havevejssætninger i JaNLI datasættet, at strukturelle fænomener, der letter fortolkningen af havevejssætninger for menneskelige læsere, ikke hjælper modeller på samme måde, hvilket fremhæver en forskel mellem menneskelige læsere og modeller.', 'hr': 'Unatoč uspjehu multijezičkih predobučenih jezičkih modela, ostaje nepoznato u kolikoj mjeri ovi modeli imaju kapacitet generalizacije ljudskih sličnih na jezicima. Cilj ovog ispitivanja je istražiti generalizaciju izvan distribucije predobučenih jezičkih modela kroz prirodnu jezičku Inferenciju (NLI) na japanskom jeziku, čije su tipološke vlasništvo različite od onih na engleskom jeziku. Upoznajemo sintetički proizvedenu japansku NLI podatku podataka, zvanu Japanski savezni NLI (JaNLI), koja je inspirisana Engleskim HANS podacima i dizajnirana kako bi zahtijevala razumijevanje japanskih jezičkih fenomena i osvijetlila ranjivost modela. Kroz niz eksperimenata za procjenu generalizacije učinka japanskih i multijezičkih BERT modela, pokazujemo da postoji mnogo mjesta za poboljšanje trenutnih modela obučenih na japanskim NLI zadatkima. Osim toga, usporedba ljudskih učinka i model a o različitim vrstama kazni za vrt-put u JaNLI podacima pokazuje da strukturni fenomeni koji olakšaju interpretaciju kazni za vrt-put za ljudske čitače ne pomažu modelima na isti način, naglašavajući razliku između ljudskih čitača i modela.', 'nl': 'Ondanks het succes van meertalige voorgetrainde taalmodellen, blijft het onduidelijk in hoeverre deze modellen menselijk generaliseringsvermogen hebben over talen. Het doel van deze studie is de out-of-distribution generalisatie van voorgetrainde taalmodellen te onderzoeken via Natural Language Inference (NLI) in het Japans, waarvan de typologische eigenschappen verschillen van die van het Engels. We introduceren een synthetisch gegenereerde Japanse NLI dataset, genaamd de Japanse Adversarial NLI (JaNLI) dataset, die is geïnspireerd op de Engelse HANS dataset en is ontworpen om begrip van Japanse linguïstische fenomenen te vereisen en de kwetsbaarheden van modellen te verlichten. Door middel van een reeks experimenten om de generalisatieprestaties van zowel Japanse als meertalige BERT modellen te evalueren, tonen we aan dat er veel ruimte is om huidige modellen die zijn getraind op Japanse NLI taken te verbeteren. Bovendien toont een vergelijking van menselijke prestaties en modelprestaties op de verschillende typen tuinpaden zinnen in de JaNLI dataset aan dat structurele fenomenen die de interpretatie van tuinpaden zinnen voor menselijke lezers vergemakkelijken, modellen niet op dezelfde manier helpen, wat een verschil tussen menselijke lezers en de modellen benadrukt.', 'de': 'Trotz des Erfolgs mehrsprachiger vortrainierter Sprachmodelle bleibt unklar, inwieweit diese Modelle sprachübergreifend menschenähnliche Verallgemeinerungskapazitäten aufweisen. Ziel dieser Arbeit ist es, die Out-of-Distribution Generalisierung von vortrainierten Sprachmodellen mittels Natural Language Inference (NLI) im Japanischen zu untersuchen, deren typologische Eigenschaften sich von denen des Englischen unterscheiden. Wir stellen einen synthetisch generierten japanischen NLI-Datensatz vor, den sogenannten Japanese Adversarial NLI (JaNLI), der vom englischen HANS-Datensatz inspiriert ist und entwickelt wurde, um Verständnis japanischer linguistischer Phänomene zu erfordern und die Schwachstellen von Modellen zu beleuchten. Durch eine Reihe von Experimenten zur Bewertung der Generalisierungsleistung von japanischen und mehrsprachigen BERT-Modellen zeigen wir, dass es viel Raum gibt, aktuelle Modelle zu verbessern, die für japanische NLI-Aufgaben trainiert werden. Darüber hinaus zeigt ein Vergleich der menschlichen Leistung und der Modellleistung auf den verschiedenen Arten von Gartenpfadsätzen im JaNLI-Datensatz, dass strukturelle Phänomene, die die Interpretation von Gartenpfadsätzen für menschliche Leser erleichtern, Modellen nicht in gleicher Weise helfen, was einen Unterschied zwischen menschlichen Lesern und den Modellen hervorhebt.', 'id': 'Meskipun sukses dari model bahasa multibahasa yang sudah dilatih, masih belum jelas seberapa banyak model ini memiliki kapasitas generalisasi seperti manusia melalui bahasa. Tujuan penelitian ini adalah menyelidiki generalisasi luar distribusi dari model bahasa yang dilatih-dilatih melalui Natural Language Inference (NLI) dalam bahasa Jepang, sifat tipologi yang berbeda dari bahasa Inggris. Kami memperkenalkan dataset NLI Jepang yang dibuat secara sintetis, disebut dataset NLI Adversarial Jepang (JaNLI), yang diinspirasi oleh dataset HANS Inggris dan direncanakan untuk memerlukan pemahaman fenomena bahasa Jepang dan menerangi kelemahan model. Through a series of experiments to evaluate the generalization performance of both Japanese and multilingual BERT models, we demonstrate that there is much room to improve current models trained on Japanese NLI tasks.  Selain itu, perbandingan prestasi manusia dan prestasi model pada jenis yang berbeda kalimat jalur kebun di dataset JaNLI menunjukkan bahwa fenomena struktur yang memudahkan interpretasi kalimat jalur kebun bagi pembaca manusia tidak membantu model dengan cara yang sama, menandai perbedaan antara pembaca manusia dan model.', 'ko': '비록 다언어가 미리 훈련한 언어 모델이 성공을 거두었지만 이러한 모델이 어느 정도에 언어를 뛰어넘는 유인범화 능력을 가지고 있는지는 아직 분명하지 않다.본 연구의 목적은 일본어에서 자연언어추리(NLI)를 통해 미리 훈련된 언어 모델의 분포가 일반화되고 그 유형학적 특성이 영어와 다르다는 것을 연구하는 것이다.우리는 일본어 대항성 NLI(JanLI) 데이터 집합이라고 종합적으로 생성된 일본어 NLI 데이터 집합을 소개했다. 이 데이터 집합은 영어HANS 데이터 집합의 계발을 받아 일본어 언어 현상을 이해하고 모델의 빈틈을 설명하기 위한 것이다.일련의 실험을 통해 일본어와 다국어 버트 모델의 범위화 성능을 평가함으로써 우리는 일본어 NLI 임무에서 훈련된 기존 모델에 큰 개선 공간이 있음을 증명했다.또한 JanLI 데이터가 서로 다른 유형의 정원 경로 문장에 집중된 인류 표현과 모델 표현을 비교한 결과 인류 독자가 정원 경로 문장을 쉽게 해석할 수 있는 구조 현상이 모델에 대한 도움이 같지 않고 인류 독자와 모델 간의 차이를 두드러지게 했다.', 'fa': 'با وجود موفقیت مدل های پیش آموزش زبان\u200cهای زیادی از زبان\u200cها، به چه اندازه این مدل\u200cها توانایی ژنرال\u200cسازی مانند انسان در زبان\u200cها وجود دارد، بی\u200cخبر است. هدف این مطالعه این است که از طریق تفاوت زبان طبیعی (NLI) در ژاپنی تحقیق کنیم، ویژگی\u200cهای نوع شناسی که از انگلیسی\u200cها متفاوت است. ما یک مجموعه داده های ژاپنی NLI ساخته شده\u200cای را معرفی می\u200cکنیم، به نام مجموعه داده\u200cهای ژاپنی NLI (JaNLI) که توسط مجموعه داده\u200cهای انگلیسی HANS الهام داده می\u200cشود و طراحی می\u200cشود تا بفهمید پدیده\u200cهای زبان ژاپنی و آسیبی\u200cهای مدل را روشن کند. از طریق یک سری آزمایشات برای ارزیابی عمومی از مدل های ژاپنی و متعدد زبان BERT، نشان می دهیم که جای زیادی وجود دارد تا مدل های فعلی را بر وظیفه های NLI ژاپنی تحصیل داده شود. علاوه بر این، مقایسه\u200cای از عملکرد انسان و عملکرد مدل بر نوع\u200cهای مجموعه\u200cهای باغ\u200cمسیر مختلف در مجموعه\u200cهای داده\u200cهای جاNLI نشان می\u200cدهد که نمایش\u200cهای ساختاری که تعبیر مجموعه\u200cهای باغ\u200cمسیر برای خوانندگان انسان را آسان می\u200cسازد، مدل\u200cها به همان طریق کمک نمی\u200cکنند، و تفاوتی بی', 'sw': 'Pamoja na mafanikio ya mifano ya lugha zilizofunzwa kwa lugha mbalimbali, bado haijaeleweka wazi kwa kiasi gani mifano hii ina uwezo wa uzalishaji wa kibinadamu katika lugha mbalimbali. Lengo la utafiti huu ni kuchunguza uzalishaji wa modeli za lugha zilizo na mafunzo ya zamani kupitia Udhibiti wa lugha ya asili (NLI) nchini Japani, hoja za kawaida ambazo zinatofautiana na wale wa Kiingereza. Tunawasilisha seti ya taarifa za NLI za Kijapani, inayoitwa Japani Adversarial NLI (JaNLI), ambayo inahamasishwa na seti ya data ya Kiingereza HANS na imelengwa kuelewa hali ya lugha ya Kijapani na kuonyesha hatari ya mifano. Kupitia mfululizo wa majaribio ya kutathmini utendaji wa uzalishaji wa miundo mbili za Kijapani na lugha mbalimbali za BERT, tunaonyesha kuwa kuna nafasi mengi ya kuboresha mifano ya sasa yanayofundishwa katika kazi za NLI za Japani. Zaidi ya hayo, kulinganisha utendaji wa binadamu na utendaji wa mifano katika a in a mbalimbali ya hukumu za barabara katika seti ya data ya JaNLI inaonyesha kwamba hali ya ujenzi ambayo inasahihi tafsiri ya hukumu za njia ya bustani kwa wasomaji binadamu hausaidia mifano kwa namna hiyo, ikionyesha tofauti kati ya wasomaji binadamu na mifano.', 'af': "Onthou die sukses van multitaalse voor-opgelei taal modele, bly dit onbekende tot wat die uitbreiding van hierdie modele menslike generellisering kapasiteit oor tale het. Die doel van hierdie studie is om die uitverspreiding generellisering van voor-opgelei taal modele deur Natuurlike Taal Inferensie (NLI) in Japanse te ondersoek, die tipologiese eienskappe waarvan verskillend is van die Engels. Ons introduseer 'n sintetiese genereerde japanse NLI dataset, genoem die japanse Adversarial NLI (JaNLI) dataset, wat inspireer word deur die Engelse HANS dataset en is ontwerp om verstanding van japanse lingwisiese fenomene te nodig en die vulnerabiliteite van modele te verlig. Deur 'n reeks eksperimente om die generellisering effektuur van japanse en multilinguele BERT-modele te evalueer, wys ons dat daar baie kamer is om huidige modele te verbeter wat op japanse NLI-opdragte onderrig is. Daarom vertoon 'n vergelyking van menslike prestasie en model prestasie op die verskillende tipes tuin-pad setinge in die JaNLI datastel dat strukturele fenomene wat die uitlegging van tuin-pad setinge vir menslike lesers maklik maak nie hulp modele op dieselfde manier nie, verligting van 'n verskil tussen menslike lesers en die modele.", 'tr': 'Birnäçe dil öňünden bilim sistemasy nusgalarynyň üstünligine rağmen bu nusgalaryň adam ýaly jeneral dillerde nähili ukyplary bar? Bu araşdyrmanyň maksady, Iňlislerden beýleki dil nusgalarynyň (NLI) ýagdaýynda tapawutlyk daýratyndan beýleki düzümlerni barlamakdyr. Biz Japonça Adversarial NLI (JaNLI Ýaponiýa we köp dilli BERT nusgalarynyň döredilişini deňlemek üçin birnäçe deneyler ýüzerinde häzirki nusgalaryň Ýaponiýa NLI täbliklerinde täzeleştirilýän nusgalaryň köp bolmagyny görkeýäris. Mundan soňra, adamlaryň tanyşylygynyň we nusgalarynyň farklı şeklinde JaNLI veri setirinde çykyş-ýol sözleriň örneklerini adamlaryň okuwçylary üçin bagy-ýol sözleriniň terjimesini a ňsat eden däldigini görkezýär.', 'sq': 'Megjithë suksesin e modeleve shumëgjuhësore të gjuhës së stërvitur para, mbetet e paqartë në çfarë mase këto modele kanë kapacitet të gjeneralizimit të ngjashëm me njerëzit nëpër gjuhë. The aim of this study is to investigate the out-of-distribution generalization of pre-trained language models through Natural Language Inference (NLI) in Japanese, the typological properties of which are different from those of English.  Ne prezantojmë një set të dhënash të gjeneruar sintetikisht japonez NLI, të quajtur grupi i dhënash japonez kundërshtar NLI (JaNLI), i cili frymëzohet nga grupi i dhënash angleze HANS dhe është dizajnuar për të kërkuar kuptimin e fenomeneve gjuhësore japoneze dhe për të ndriçuar dobësitë e modeleve. Nëpërmjet një serie eksperimentesh për të vlerësuar paraqitjen e gjeneralizimit të si modeleve japoneze ashtu edhe të BERT-it shumëgjuhës, ne demonstrojmë se ka shumë vend për të përmirësuar modelet aktuale të trajnuar në detyrat japoneze NLI. Përveç kësaj, një krahasim i paraqitjes njerëzore dhe paraqitjes së modelit në llojet e ndryshme të fjalëve në rrugën e kopshtit në dataset JaNLI tregon se fenomenet strukturore që lehtësojnë interpretimin e fjalëve në rrugën e kopshtit për lexuesit njerëzor nuk ndihmojnë modelet në të njëjtën mënyrë, duke theksuar një dallim midis lexuesve njerëzor dhe modeleve.', 'am': 'በብዙ ቋንቋዎች በፊት ተማሪ የቋንቋ ምሳሌዎች ድል ምንም እንኳ የደረሰ ቢሆንም፣ እነዚህ ምሳሌዎች በምን ዓይነት የሰው ብጤ አቀማመጥ ኃይል በቋንቋዎች ውስጥ እንዴት እንደሆኑ አይገልጽም፡፡ የዚህ ትምህርት ጉዳዩ የባሕላዊ ቋንቋ ምሳሌዎች በጃፓንኛ የዘርፍ ቋንቋ መግለጫ (NLI) የተለየ የባሕላዊ ምርጫዎች ከኢንግሊዘኛ የተለየ ነው፡፡ የጃፓን አዳራሲ NLI (JaNLI) ዳታተር የተባለውን የጃፓንን የጃፓንን አዳራሲ (የያNLI) ዳታተር ማቀናቀል እና በንግግሊዝኛ HANS ዳታተር የተገኘውን እና የጃፓንን ቋንቋዊ አካባቢ ስህተት ማስተዋል እና የሞዴሎችን ደካማ ያበራል፡፡ በጃፓንኛ እና በብዙ ቋንቋዎች የBERT ሞዴላዎችን ለማስተዋል በተለያዩ ፈተናዎች ውስጥ በጃፓን NLI ስራ ላይ የተጠቃሚውን የዓይነቶች ማሻሻል ብዙ ስፍራዎች እንዳለ እናሳየዋለን፡፡ በተጨማሪም፣ የጃንሊ ዳታተር ውስጥ በተለዩ ዓይነት የሰው አካባቢ እና ሞዴል ድምፅ በሚያሳየው አካባቢ አካባቢዎች እና በሰው አካባቢዎች መካከል የተለየ የአትክል መንገድ ፍርድ መተርጓሜን የሚያቃልል የአትክልት መንገድ ፍርድ መተርጓሜ በሚያቃጥሉ ምሳሌዎችን በአንድ ዓይነት አይረዳቸውም፣ በሰው አካባቢዎች እና በሞዴሎቹ መካከል የተለዩትን ት', 'az': 'M√ľxt…ôlif dil …ôvv…ôl t…ôhsil edilmiŇü dil modell…ôrinin baŇüarńĪsńĪna rańümen, bu modell…ôrin insanlara b…ônz…ôr generalizasiya kapasit…ôsi dill…ôrd…ô n…ô q…ôd…ôr olduńüunu bilmir. Bu araŇüdńĪrmanńĪn m…ôqs…ôdi, …ôvv…ôlc…ô t…ôhsil edilmiŇü dil modellerinin (NLI) t…ôhsil edilm…ôsini Japonca t…ôhsil dill…ôrinin (NLI) vasit…ôsil…ô m√ľxt…ôlif dańüńĪtńĪlmasńĪdńĪr, √ß√ľnki bunlarńĪn typolojik √∂zellikl…ôri ingiliz dill…ôrind…ôn f…ôrqli olarlar. Biz sintetik olaraq Japon NLI veri quruluńüunu t…ôŇükil edirik, Japon Adversarial NLI (JaNLI) veri quruluńüunu, ńįngiliz HANS veri quruluńüu il…ô t…ôŇükil edir v…ô Japon dilind…ô olanlarńĪ anlamaq v…ô modell…ôrin z…ôiflikl…ôrini aydńĪnlaŇüdńĪrmaq √ľ√ß√ľn t…ôŇükil edilir. Yaponca v…ô √ßoxlu dil BERT modellerinin generalizasyon performansńĪnńĪ deńüerl…ôŇüdirm…ôk √ľ√ß√ľn bir s√ľr√ľ t…ôcr√ľb…ô vasit…ôsil…ô, Japon NLI iŇül…ôrind…ô t…ôhsil edil…ôn modell…ôrin √ßox yer olduńüunu g√∂st…ôrdik. Daha sonra, JaNLI veril…ônl…ôrind…ô insanlarńĪn performanslarńĪnńĪn v…ô modell…ôrin m√ľxt…ôlif c√ľml…ôl…ôrinin qarŇüńĪlaŇüdńĪrmasńĪ g√∂st…ôrir ki, insanlarńĪn oxuyanlarńĪ √ľ√ß√ľn bańü yolunu asanlaŇüdńĪran c√ľml…ôl…ôrin istifad…ôsi d…ô modell…ôr…ô bir fayda verm…ôz, insanlarńĪn oxuyanlarńĪ v…ô modell…ôrin arasńĪndakńĪ f…ôrqliyi iŇüńĪqlandńĪrmaq ist…ôyir.', 'bs': 'Uprkos uspjehu multijezičkih pre-obučenih jezičkih modela, ostaje nepoznato u kolikoj mjeri ovi modeli imaju kapacitet generalizacije poput ljudskih ljudi na jezicima. Cilj ovog ispitivanja je istražiti generalizaciju izvan distribucije predobučenih jezičkih modela kroz prirodnu jezičku Inferenciju (NLI) na japanskom jeziku, čije su tipološke vlasništvo različite od onih na engleskom jeziku. Upoznajemo sintetički proizvedenu japansku NLI podatku podataka, zvanu Japanski savezni NLI (JaNLI), koja je inspirisana Engleskim HANS podacima i dizajnirana kako bi trebalo da razumijemo japanske lingvističke fenomene i da objasnimo ranjivost modela. Kroz niz eksperimenata za procjenu generalizacije učinka japanskih i multijezičkih BERT modela, pokazujemo da postoji mnogo prostora za poboljšanje trenutnih modela obučenih na japanskim NLI zadacima. Osim toga, usporedba ljudskog učinka i model a o različitim vrtovima kazni na vrtu-putu u JaNLI podacima pokazuje da strukturni fenomeni koji olakšaju interpretaciju kazni na vrt-putu za ljudske čitače ne pomažu modelima na isti način, naglašavajući razliku između ljudskih čitača i modela.', 'hy': 'Չնայած բազմալեզու նախապատրաստված լեզվի մոդելների հաջողությանը, դեռևս անհասկանալի է, թե ինչքանով են այս մոդելները մարդկային նման ընդհանուր ընդունակություններ լեզուների միջև: Այս ուսումնասիրության նպատակն է ուսումնասիրել նախապատրաստված լեզվի մոդելների տարածումից դուրս ընդհանուր տարածումը ճապոներեն բնական լեզվի ինֆերանսի միջոցով, որոնց տիպոլոգիական հատկությունները տարբերվում են անգլերենի հատկություններից: Մենք ներկայացնում ենք մի սինթետիկ ստեղծված ճապոնական ՆԼԻ տվյալների համակարգ, որը կոչվում է ճապոնական ՆԼԻ (ՋԱՆԼԻ) տվյալների համակարգ, որը ոգեշնչվում է անգլերենի HANS ի տվյալների համակարգով և նախագծված է պահանջելու ճապոնական լեզվաբանական ֆենոմենների հասկանալը և մոդելների Մենք մի շարք փորձարկումների միջոցով գնահատելու ճապոնացի և բազլեզու BER մոդելների ընդհանուր արտադրողականությունը ցույց ենք տալիս, որ շատ տեղ կա զարգացնելու ներկայիս մոդելները, որոնք պատրաստված են ճապոնացի ՆԼԻ խնդիրների վրա: Ավելին, մարդկային արտադրողականության և մոդելների արտադրողականության համեմատությունը ՅանԼԻ տվյալների համակարգում պարզվում է, որ կառուցվածքային երևույթները, որոնք հեշտացնում են մարդկային կարդացողների արտադրողականության արտադրողականությունը, նույն կերպ չեն օգնում մոդելներին, նշելով մարդկային կարդացողների', 'cs': 'Navzdory úspěchu vícejazyčných předškolených jazykových modelů zůstává nejasné, do jaké míry mají tyto modely lidskou generalizační schopnost napříč jazyky. Cílem této studie je zkoumat mimo distribuci předškolených jazykových modelů pomocí Natural Language Inference (NLI) v japonštině, jejichž typologické vlastnosti se liší od vlastností angličtiny. Představujeme synteticky generovanou japonskou sadu NLI (JaNLI), která je inspirována anglickou datasadou HANS a je navržena tak, aby vyžadovala porozumění japonským jazykovým jevům a osvětlila zranitelnost modelů. Prostřednictvím série experimentů pro hodnocení zobecnění výkonnosti japonských i vícejazyčných modelů BERT ukazujeme, že existuje velký prostor pro zlepšení současných modelů trénovaných na japonských úlohách NLI. Dále srovnání lidského výkonu a výkonu modelu na různých typech vět zahradní cesty v datové sadě JaNLI ukazuje, že strukturální jevy, které usnadňují interpretaci vět pro lidské čtenáře, nepomáhají modelům stejným způsobem, což zdůrazňuje rozdíl mezi lidskými čtenáři a modely.', 'bn': 'বহুভাষায় প্রশিক্ষিত ভাষা মডেলের সাফল্য সত্ত্বেও, এই মডেলগুলো কিভাবে মানুষের মত জেনারেলিজেশনের ক্ষমতা আছে সারা ভাষায় কিভ এই গবেষণার উদ্দেশ্য হচ্ছে পূর্বপূর্ব প্রশিক্ষিত ভাষা মডেলের জেনারেলিং বিতরণের বাইরে বিতরণের বিষয়টি গবেষণা করা হচ্ছে জাপানী ভাষায় প্রাকৃতিক ভাষা ই জাপানি এডভারেরিয়াল এনলি (জাএনলি) ডাটাসেট নামে একটি সিন্টিভিক্রিয়াল তৈরি করা জাপানী এনলির ডাটাসেটের পরিচালনা করা হয়েছে, যা ইংরেজী হাএনএস ডাটাসেট দ্বারা অনুপ্রাণিত হয়েছে এবং  জাপানী এবং বহুভাষী বার্টি মডেলের সাধারণ প্রদর্শনের মাধ্যমে বেশ কিছু পরীক্ষার মাধ্যমে আমরা প্রমাণিত করেছি যে জাপানী এনলি কাজে প্রশিক্ষিত বর্তমান মডেলে এছাড়াও জাএনলির ডাটাসেটের বিভিন্ন ধরনের বাগান-পাথের শাস্তির উপর মানুষের প্রদর্শন এবং মডেল প্রদর্শনের তুলনায় একটি তুলনা দেখা যাচ্ছে যে কাঠামোর বাগান-পাঠকদের ব্যাখ্যা সহজে বাগা', 'et': 'Vaatamata mitmekeelsete eelkoolitud keelemudelite edule on endiselt ebaselge, mil määral on nende mudelite inimlik üldistamisvõime keeltes. Käesoleva uuringu eesmärk on uurida eelõpetatud keelemudelite levikust väljapoole üldistamist jaapani keeles Natural Language Inference (NLI), mille tüpoloogilised omadused erinevad inglise keele omadustest. Tutvustame sünteetiliselt genereeritud Jaapani NLI andmekogumit, mida nimetatakse Jaapani Adversarial NLI (JaNLI), mis on inspireeritud inglise HANS andmekogumist ja mille eesmärk on nõuda Jaapani keeleliste nähtuste mõistmist ja valgustada mudelite haavatavust. Mitmete eksperimentide abil, mille eesmärk on hinnata nii Jaapani kui ka mitmekeelsete BERT mudelite üldistamisjõudlust, näitame, et Jaapani NLI ülesannete täiustamiseks on palju ruumi. Lisaks näitab JaNLI andmekogumi erinevat tüüpi aiateelausete võrdlus inimese ja mudeli jõudluse võrdlus, et struktuurinähtused, mis hõlbustavad aiateelausete tõlgendamist inimlugejate jaoks, ei aita mudeleid samamoodi, rõhutades erinevust inimlugejate ja mudelite vahel.', 'ca': "Malgrat l'èxit dels models multilingües de llengües pré-entrenats, encara no és clar en quin punt aquests models tenen la capacitat de generalització humana a través de les llengües. L'objectiu d'aquest estudi és investigar la generalització fora de distribució de models de llenguatge pré-entrenats a través de l'Inferència de Llingua Natural (NLI) en japonès, les propietats tipològices de les quals són diferents d'aquelles de l'anglès. Introduïm un conjunt de dades NLI japonès sintèticament generat, anomenat el conjunt de dades NLI adversari japonès (JaNLI), inspirat pel conjunt de dades HANS anglès i dissenyat per requerer entendre els fenomens lingüístics japonès i iluminar les vulnerabilitats dels models. A través d'una sèrie d'experiments per avaluar el rendiment de generalització dels models BERT japonesos i multilingües, demostram que hi ha molt espai per millorar els models actuals entrenats en tasques japoneses NLI. A més, una comparació entre el rendiment humà i el model de rendiment dels diferents tipus de frases de camí al jardí del conjunt de dades JaNLI mostra que fenomens estructurals que faciliten l'interpretació de les frases de camí al jardí per als lectors humans no ajuden els models de la mateixa manera, destacant una diferència entre els lectors humans i els models.", 'fi': 'Monikielisten esikoulutettujen kielimallien menestyksestä huolimatta on edelleen epäselvää, missä määrin näillä malleilla on inhimillinen yleistyskyky eri kielillä. Tämän tutkimuksen tavoitteena on tutkia japanin kielen luonnollisten kielten inferenssien (Natural Language Inference, NLI) yleistymistä, jonka typologiset ominaisuudet poikkeavat englannin kielistä. Esittelemme synteettisesti tuotetun japanilaisen NLI-aineiston nimeltä Japanese Adversarial NLI (JaNLI), joka on saanut inspiraationsa englanninkielisestä HANS-aineistosta ja joka on suunniteltu vaatimaan japanilaisten kieliilmiöiden ymmärtämistä ja valaisemaan mallien haavoittuvuuksia. Kokeilla, joilla arvioidaan sekä japanilaisten että monikielisten BERT-mallien yleistymistä, osoitetaan, että japanilaisiin NLI-tehtäviin koulutettujen nykyisten mallien parantamiseen on paljon tilaa. Lisäksi JaNLI-aineiston erityyppisten puutarhapolkulauseiden vertailu ihmisen suorituskykyyn ja mallin suorituskykyyn osoittaa, että puutarhapolkulauseiden tulkintaa helpottavat rakenteelliset ilmiöt eivät auta malleja samalla tavalla, mikä korostaa ihmisen lukijoiden ja mallien välistä eroa.', 'he': 'למרות הצלחתו של דוגמני שפת מורכבות מראש לשפות רבות, עדיין לא ברור עד כמה הדוגמנים האלה יש יכולת הגנרליזציה דומה לאדם בכל שפות. המטרה של המחקר הזה היא לחקור את הגנרליזציה מחוץ לפיתוח של דוגמני שפה מאומנים מראש באמצעות השפה הטבעית (NLI) ביפנית, שהתכונות הטיפולוגיות שלהן שונות מאלה של אנגלית. אנחנו מציגים קבוצת מידע NLI היפנית שנוצרה באופן סינטטי, שנקראת קבוצת מידע NLI היפנית התנגדות (JaNLI), אשר מעוררת השראה על ידי קבוצת מידע HANS האנגלית ומועצבת כדי לדרוש הבנה של התופעות שפתיות יפניות ולאור את פגיעות הדוגמנים. Through a series of experiments to evaluate the generalization performance of both Japanese and multilingual BERT models, we demonstrate that there is much room to improve current models trained on Japanese NLI tasks.  חוץ מזה, השוואה של ביצועים אנושיים והביצועים של מודל על סוגים שונים של משפטי גן-מסלול במערכת הנתונים של JaNLI מראה כי תופעות מבנה שמקלות בפרשנות של משפטי גן-מסלול לקוראים אנושיים לא עוזרים מודלים באותה דרך, להדגיש הבדל בין קוראים אנושיים לבין המודלים.', 'jv': 'Ngayon iku, ndelok sistem sing alih luwih dumadhi sing sampeyan ingkang luwih-luwih dumadhi, kuwi mau ngerasai kapaan ingkang sampeyan ingkang sampeyan. Rayongno kuwi panggunakake punika ingkang nggunakake kapan-kanggo ngilangno Generalizasi kanggo model sing luwih cara-cara ngregani anu sakjane (NLI) lan japoniya, rak akeh nyong oleh lanjut karo ingkang. Awak dhéwé nyenggunaké dataset sing paling kelangan seneng pisan NLI japong, sing kelangan dataset Japong Advertary NLI Ato sampeyan akeh sing perbudhakan kanggo nggawe akeh Generalizasi nggawe model japones lan akeh langgar BERT, kéné bisa ngono kuwi tindakan sing wis ana dadi nggawe model sing bisa nggawe nguasai model sing bisa nggawe sak sebelah Japongan NLI. politenessoffpolite"), and when there is a change ("assertive"', 'sk': 'Kljub uspehu večjezičnih predhodno usposobljenih jezikovnih modelov ostaja nejasno, v kolikšni meri imajo ti modeli človeku podobno sposobnost posploševanja v jezikih. Cilj raziskave je raziskati generalizacijo predhodno usposobljenih jezikovnih modelov prek sklepanja naravnega jezika (NLI) v japonščini, katerih tipološke lastnosti se razlikujejo od angleščine. Predstavljamo sintetično generiran japonski nabor podatkov NLI, imenovan japonski adversarialni nabor podatkov NLI (JaNLI), ki je navdihnjen iz angleškega nabora podatkov HANS in je zasnovan tako, da zahteva razumevanje japonskih jezikovnih pojavov in osvetli ranljivosti modelov. Z vrsto eksperimentov za oceno splošne učinkovitosti japonskih in večjezičnih BERT modelov dokazujemo, da je veliko prostora za izboljšanje sedanjih modelov, usposobljenih za japonske naloge NLI. Poleg tega primerjava delovanja človeka in delovanja modela na različnih vrstah stavkov vrtne poti v naboru podatkov JaNLI kaže, da strukturni pojavi, ki olajšajo interpretacijo stavkov vrtne poti za človeka bralca, modelom ne pomagajo na enak način, kar poudarja razliko med človeškimi bralci in modeli.', 'bo': 'སྐད་རིགས་ལ་བསྔོན་གྲངས་སྒྲིག་འགོད་མིན་པའི་ཆ་འཕྲིན་ཡིག་གཟུགས་རིས་ལྷག་མིན་ནའང་། མིག་རྣམས་འདི་དག་གི་ཚད་ལ་ཆེ་བས་ཞིབ་དཔ དམིགས་ཡུལ་འདིའི་དམིགས་ཡུལ་ནི་སྔོན་གྱི་སྔོན་གྱི་སྐད་རིགས་གཟུགས་འགྱུར་བའི་གྲངས་རིགས་ལ་བསྟུན་ནས་གནད་ཅིག ང་ཚོས་རང་ཉིད་ཀྱི་སྐྱེས་སྐར་ཡིག་ཆ་གསར་འཛུགས་པའི་ཉེ་ཧོང་གི་NLI གནད་སྡུད་ཅིག་གསལ་ཆགས་བྱས་པ་ཞིག་ལ་བཤད་ཀྱི་ཡོད། དབྱིན་ཡིག་ཆའི་HANS གནད་སྡུད་གཞི་རྟེན་འདི་གསལ་མ སྐད་ཡིག་གི་བརྟག་ཞིག་བྱས་པར་སྤྱིར་བཏང་བ་ཡིན་པའི་སྐད་ཡིག་ཆ་གཅིག་ལས་ཇུས་ཡིན་གྱི་མིག་རྩལ་གྲངས་སྒྲིག ད་དུང་། JaNLI གནད་སྡུད་ནང་གི་མིང་ཚོའི་གོ་སྐབས་དང་རྣམ་པ་གྱི་མཇལ་ཚོགས་སྡུར་སྐྱེས་པའི་ཚིག་རྣམ་པ་ཚོར་སྤྱོད་མཁན་གྱི་བཟོ་རྣམ་དང་མིང་ཚོའི་ནང་དུ་བཟོ་བཅོས་ནི་structural phenomena་འདྲ་མཁན་ག', 'ha': "Babu da cin nasara wa misalin misalin harshe masu cikin multiziman da aka yi wa zaman-tun, ba ta kasancẽwa ga inda duk misalin waɗannan suna da abincin mai kama da mutum a cikin lugha. Haƙĩƙa na kasar wannan lõkaci ne dõmin a tambaya masu buɗe-out-rabo mai samun misãlai na zaman-wahalar da aka yi amfani da shi a cikin harshen Kiasal (NLI) cikin japaneni, wasu properties na daban daga Ingiriya. Tuna introduce wani danna na'urar NLI na Jabaniya da aka samu da shi, wanda aka sanar da data na Japanen Adversarial NLI (JaNLI), wanda aka yi wahayi da shi na danne na Ingiriya hasNS kuma aka designe shi dõmin a buƙata fahimta ga abubuwa na harshen japane da kuma a haske masu zartar da misãlai. Through a series of experiments to evaluate the generalization performance of both Japanese and multilingual BERT models, we demonstrate that there is much room to improve current models trained on Japanese NLI tasks.  Furan wannan, misalin mafarin mutane da tsarin mutane a cikin wasu nau'i-nau'i-hagu cikin dataset na JaNLI, yana nũna wa abu na rubutu da sauƙin fassarar-ayukan hagu ga ma'abũcin karãtun mutane, bã ya amfani da misalin misãlai daidai, kuma ya bayyana wani sãɓãni a tsakanin karatun mutane da misãlai."}
{'en': 'Investigating Negation in Pre-trained Vision-and-language Models', 'fr': 'Étude de la négation dans des modèles de vision et de langage pré-entraînés', 'ar': 'التحقيق في النفي في نماذج الرؤية واللغة المدربة مسبقًا', 'es': 'Investigación de la negación en modelos de visión y lenguaje preentrenados', 'pt': 'Investigando a negação em modelos de visão e linguagem pré-treinados', 'zh': '治预习视语模中否', 'ja': '事前に訓練されたビジョンと言語モデルにおける否定の調査', 'hi': 'पूर्व-प्रशिक्षित दृष्टि और भाषा मॉडल में नकारात्मकता की जांच करना', 'ru': 'Исследование отрицания в предварительно обученных моделях зрения и языка', 'ga': 'Ag Imscrúdú Diúltaithe i Múnlaí Físe agus Teanga Réamh-oilte', 'ka': 'პროგრამეტრებული ხედის და ენათის მოდელში ინსტექტირება', 'hu': 'Negáció vizsgálata előre képzett látás- és nyelvi modellekben', 'el': 'Διερεύνηση της Αρνείας σε Προεκπαιδευμένα Μοντέλα Όρασης και Γλώσσας', 'it': 'Investigare la negazione in modelli pre-formati di visione e linguaggio', 'kk': 'Алдыңғы көрініс мен тіл үлгілерінде зерттеу', 'lt': 'Investigating Negation in Pre-trained Vision-and-language Models', 'mk': 'Истражување на негативностите во предобучените модели на визија и јазик', 'mt': 'Negazzjoni ta’ Investigazzjoni f’Mudelli ta’ Viżjoni u lingwa mħarrġa minn qabel', 'ms': 'Menyelidiki Negasi dalam Model Pemandangan-dan-bahasa Latihan-Terdahulu', 'ml': 'പഠിപ്പിക്കപ്പെട്ട വിഷയത്തിലും ഭാഷ മോഡലുകളിലുമുള്ള നെഗേഷന്\u200d അന്വേഷിക്കുന്നു', 'ro': 'Investigarea negării în modele de viziune și limbaj pre-instruite', 'no': 'InvestigasjonsNegasjon i føretrengte visingsog språk- modeller', 'mn': 'Өмнөх сургалтын үзэл болон хэл загваруудыг судалгаа хийх', 'sr': 'Istraživanje pregovora u predobučenim modelima vizije i jezika', 'so': 'Baaritaanka dalbashada qaababka horumarinta iyo afka', 'pl': 'Badanie negatywności w przeszkolonych modelach wzroku i języka', 'si': 'මුලින් ප්\u200dරීක්ෂණිත දර්ශනය සහ භාෂාව මඩේල් වල පරීක්ෂණය කරනවා', 'ta': 'முன் பயிற்சி காட்சி மற்றும் மொழி மாதிரியில் உள்ள தொடர்புகள் ஆராய்ச்சிக்கப்படுகிறது', 'sv': 'Undersöka Negation i Pre-utbildade Vision-och-språkmodeller', 'ur': 'پیش تعلیم کی تصویر اور زبان موڈل میں ناگہانی تحقیق کرنا', 'uz': 'Taò¥rifi boò£lgan koò£rinish va tillar modellarida qidirilmoqda', 'vi': 'Điều tra qua thao tác trong chế độ nhìn và ngôn ngữ', 'da': 'Undersøgelse af Negation i forududdannede Vision- og sprogmodeller', 'bg': 'Изследване на отрицанието в предварително обучени модели на зрение и език', 'nl': 'Onderzoek naar negatie in voorgetrainde visie- en taalmodellen', 'hr': 'Istraživanje pregovora u predobučenim modelima vizije i jezika', 'id': 'Investigating Negation in Pre-trained Vision-and-language Models', 'de': 'Untersuchung von Negation in vortrainierten Seh- und Sprachmodellen', 'ko': '미리 훈련된 시각과 언어 모델에서 부정을 조사하다', 'sw': 'Kuchunguza Ushirikiano katika Modeli za Maonyesho na lugha zilizojifunza', 'tr': 'Öňki Görnöş we Diller nusgasynda Ýaşmak', 'af': 'Inligting Negasie in vooraf- opgelei Besigtig en taal Modelle', 'am': 'ምርጫዎች', 'hy': 'Նախապատրաստված տեսողության և լեզվի մոդելների հետազոտությունը', 'sq': 'Hetimi i negativës në modelet e vizionit dhe gjuhës paratrajnuar', 'az': '쎖渠瓉饨獩氠敤楬浩얟⁇쎶狃볅鼠盉餠䑩氠䵯摥汬즙物湤즙⁓즙晬즙琊', 'bs': 'Istraživanje pregovora u predobučenim modelima vizije i jezika', 'bn': 'প্রশিক্ষিত ভিশন- এবং ভাষার মোডেলে নেগেশন অনুসন্ধান করা হচ্ছে', 'fa': 'تحقیق مکالمات در مدل دید و زبان پیش آموزش', 'ca': 'Investigar la negatió en models de visió i llenguatge pré-entrenats', 'cs': 'Vyšetřování negativních modelů předškoleného vidění a jazyka', 'fi': 'Negaation tutkiminen ennalta koulutetuissa näkö- ja kielimalleissa', 'et': 'Negatiivsuse uurimine eelkoolitud nägemis- ja keelemudelites', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': '@ action', 'sk': 'Raziskovanje negativnosti v vnaprej usposobljenih modelih vida in jezika', 'bo': 'སྔོན་གྱི་མཐོང་སྣང་དང་སྐད་རིགས་ཀྱི་མ་དབྱིབས་ནང་ལ་བཙལ་བཤེར་བྱེད་པ', 'he': 'חוקר שלילה במודלים חזון ושפה מאומנים מראש'}
{'en': 'Pre-trained vision-and-language models have achieved impressive results on a variety of tasks, including ones that require complex reasoning beyond object recognition. However, little is known about how they achieve these results or what their limitations are. In this paper, we focus on a particular linguistic capability, namely the understanding of negation. We borrow techniques from the analysis of language models to investigate the ability of pre-trained vision-and-language models to handle negation. We find that these models severely underperform in the presence of negation.', 'fr': "Les modèles de vision et de langage pré-entraînés ont obtenu des résultats impressionnants pour une variété de tâches, y compris celles qui nécessitent un raisonnement complexe au-delà de la reconnaissance d'objets. Cependant, on sait peu de choses sur la façon dont ils obtiennent ces résultats ni sur leurs limites. Dans cet article, nous nous concentrons sur une capacité linguistique particulière, à savoir la compréhension de la négation. Nous empruntons des techniques issues de l'analyse de modèles linguistiques pour étudier la capacité des modèles de vision et de langage pré-entraînés à gérer la négation. Nous constatons que ces modèles sont très peu performants en présence de négation.", 'pt': 'Modelos de visão e linguagem pré-treinados alcançaram resultados impressionantes em uma variedade de tarefas, incluindo aquelas que exigem raciocínio complexo além do reconhecimento de objetos. No entanto, pouco se sabe sobre como eles alcançam esses resultados ou quais são suas limitações. Neste artigo, nos concentramos em uma capacidade linguística particular, a saber, a compreensão da negação. Tomamos emprestado técnicas da análise de modelos de linguagem para investigar a capacidade de modelos de visão e linguagem pré-treinados para lidar com a negação. Descobrimos que esses modelos têm um desempenho severamente inferior na presença de negação.', 'ar': 'لقد حققت نماذج الرؤية واللغة المدربة مسبقًا نتائج رائعة في مجموعة متنوعة من المهام ، بما في ذلك المهام التي تتطلب تفكيرًا معقدًا يتجاوز التعرف على الأشياء. ومع ذلك ، لا يُعرف الكثير عن كيفية تحقيق هذه النتائج أو ما هي حدودها. في هذه الورقة ، نركز على قدرة لغوية معينة ، ألا وهي فهم النفي. نستعير تقنيات من تحليل نماذج اللغة لاستقصاء قدرة نماذج الرؤية واللغة المدربة مسبقًا على التعامل مع النفي. نجد أن أداء هذه النماذج ضعيف بشدة في وجود النفي.', 'es': 'Los modelos de visión y lenguaje previamente entrenados han logrado resultados impresionantes en una variedad de tareas, incluidas aquellas que requieren un razonamiento complejo más allá del reconocimiento de objetos. Sin embargo, se sabe poco sobre cómo logran estos resultados o cuáles son sus limitaciones. En este artículo, nos centramos en una capacidad lingüística particular, a saber, la comprensión de la negación. Tomamos prestadas técnicas del análisis de modelos de lenguaje para investigar la capacidad de los modelos de visión y lenguaje previamente entrenados para manejar la negación. Encontramos que estos modelos tienen un rendimiento muy inferior en presencia de la negación.', 'ja': '事前に訓練されたビジョンと言語のモデルは、オブジェクト認識を超えた複雑な推論を必要とするものを含む、さまざまなタスクで印象的な結果を達成しました。しかしながら、それらがどのようにこれらの結果を達成するか、またはそれらの制限が何であるかについてはほとんど知られていない。本稿では、特定の言語能力、すなわち否定の理解に焦点を当てる。言語モデルの分析から技術を借用して、事前に訓練されたビジョンと言語モデルが否定を処理する能力を調査します。これらのモデルは、否定の存在下では非常にパフォーマンスが低いことがわかります。', 'hi': 'पूर्व-प्रशिक्षित दृष्टि-और-भाषा मॉडल ने विभिन्न प्रकार के कार्यों पर प्रभावशाली परिणाम प्राप्त किए हैं, जिनमें वे भी शामिल हैं जिन्हें ऑब्जेक्ट मान्यता से परे जटिल तर्क की आवश्यकता होती है। हालांकि, इस बारे में बहुत कम जानकारी है कि वे इन परिणामों को कैसे प्राप्त करते हैं या उनकी सीमाएं क्या हैं। इस पत्र में, हम एक विशेष भाषाई क्षमता पर ध्यान केंद्रित करते हैं, अर्थात् नकार की समझ। हम भाषा मॉडल के विश्लेषण से तकनीकों को उधार लेते हैं ताकि पूर्व-प्रशिक्षित दृष्टि-और-भाषा मॉडल की क्षमता की जांच की जा सके ताकि नकार को संभाला जा सके। हम पाते हैं कि ये मॉडल नकारात्मकता की उपस्थिति में गंभीर रूप से अंडरपरफॉर्म करते हैं।', 'zh': '预教愿景语,取象深远,兼越杂理。 然其所以然者何局限性,人知之甚少。 本文中,注一特定语力,即非解也。 吾鉴言模之术,以究豫教之愿景,与言模形之能否。 吾见其所非,其形甚不佳。', 'ru': 'Предварительно обученные модели зрения и языка достигли впечатляющих результатов по целому ряду задач, включая те, которые требуют сложных рассуждений, выходящих за рамки распознавания объектов. Однако мало что известно о том, как они достигают этих результатов или каковы их ограничения. В этой статье мы фокусируемся на конкретной языковой способности, а именно на понимании отрицания. Мы заимствуем методы из анализа языковых моделей, чтобы исследовать способность предварительно обученных моделей зрения и языка справляться с отрицанием. Мы находим, что эти модели сильно неэффективны при наличии отрицания.', 'ga': 'Tá torthaí iontacha bainte amach ag samhlacha fís-agus teanga réamh-oilte ar thascanna éagsúla, lena n-áirítear cinn a éilíonn réasúnú casta seachas aithint oibiachta. Mar sin féin, is beag atá ar eolas faoi conas a bhaineann siad amach na torthaí seo nó cad iad na teorainneacha atá leo. Sa pháipéar seo, dírímid ar chumas teanga ar leith, is é sin tuiscint ar an diúltú. Faighimid teicníochtaí ón anailís ar mhúnlaí teanga chun iniúchadh a dhéanamh ar chumas múnlaí réamhoilte fís-agus-teanga chun déileáil le faillí. Faighimid amach go bhfuil tearcfheidhmíocht ag na samhlacha seo go mór i láthair na ndiúltuithe.', 'ka': 'პროგრამეტად განსწავლა ვიდეო და ენაზე მოდელები მიიღეთ განსხვავებული მოდელების შესახებ, რომლებიც უნდა კომპლექსი განსხვავების გარეშე. მაგრამ მალკჲ უცნობილია თუ როგორ ისინი გავაკეთებენ ეს შედეგი ან როგორ არის მათი შედეგი. ამ დოკუნტში, ჩვენ განსაკუთრებული ლენდომისტიკური შესაძლებლობაზე გავაკეთებთ, ანუ ნეგრაციის შესაძლებლობაზე. ჩვენ ენების მოდელების ანალიზაციის ტექნეკების შესაძლებლობად დავიწყებთ წინასწარმოვიდგინეთ ვიდეო და ენების მოდელების შესაძლებლობა დავიწყებთ. ჩვენ აღმოჩნეთ, რომ ეს მოდელები ძალიან უკეთესი გავაკეთებენ ნეგციაციის სახელში.', 'hu': 'Az előre képzett látás-és nyelvi modellek lenyűgöző eredményeket értek el a különböző feladatokban, beleértve azokat is, amelyek komplex érvelést igényelnek a tárgyfelismerésen túl. Keveset tudunk azonban arról, hogyan érhetik el ezeket az eredményeket, vagy mik a korlátaik. Ebben a tanulmányban egy bizonyos nyelvi képességre összpontosítunk, nevezetesen a tagadás megértésére. A nyelvi modellek elemzéséből technikákat veszünk kölcsön annak vizsgálatára, hogy az előre képzett látás- és nyelvmodellek képesek-e a negatív kezelésre. Úgy találjuk, hogy ezek a modellek súlyosan alulteljesítenek tagadás jelenlétében.', 'el': 'Τα προ-εκπαιδευμένα μοντέλα όρασης και γλώσσας έχουν επιτύχει εντυπωσιακά αποτελέσματα σε μια ποικιλία εργασιών, συμπεριλαμβανομένων εκείνων που απαιτούν πολύπλοκη συλλογιστική πέρα από την αναγνώριση αντικειμένων. Ωστόσο, ελάχιστα είναι γνωστά για το πώς επιτυγχάνουν αυτά τα αποτελέσματα ή ποιοι είναι οι περιορισμοί τους. Στην παρούσα εργασία εστιάζουμε σε μια ιδιαίτερη γλωσσική ικανότητα, δηλαδή στην κατανόηση της άρνησης. Δανείζομαι τεχνικές από την ανάλυση γλωσσικών μοντέλων για να διερευνήσουμε την ικανότητα των προ-εκπαιδευμένων προτύπων όρασης και γλώσσας να χειριστούν την άρνηση. Βρίσκουμε ότι αυτά τα μοντέλα παρουσιάζουν πολύ χαμηλές επιδόσεις με την παρουσία της άρνησης.', 'it': "Modelli di visione e linguaggio pre-addestrati hanno ottenuto risultati impressionanti su una varietà di compiti, compresi quelli che richiedono ragionamenti complessi oltre il riconoscimento degli oggetti. Tuttavia, poco si sa su come raggiungono questi risultati o quali sono i loro limiti. In questo articolo, ci concentriamo su una particolare capacità linguistica, vale a dire la comprensione della negazione. Prendiamo in prestito tecniche dall'analisi dei modelli linguistici per indagare la capacità di modelli di visione e linguaggio pre-addestrati di gestire la negazione. Troviamo che questi modelli gravemente sottoperformano in presenza di negazione.", 'mk': 'Pre-trained vision-and-language models have achieved impressive results on a variety of tasks, including ones that require complex reasoning beyond object recognition.  Сепак, малку е познато за тоа како тие ги постигнуваат овие резултати или какви се нивните ограничувања. Во овој весник, се фокусираме на одредена јазичка способност, имено разбирањето на негативноста. Ние позајмуваме техники од анализата на јазичките модели за да ја истражуваме способноста на предобучени визиски и јазички модели да се справат со негативноста. Најдовме дека овие модели сериозно недостасуваат во присуство на негативност.', 'ms': 'Model penglihatan dan bahasa terlatih telah mencapai keputusan yang mengesankan dalam berbagai tugas, termasuk tugas yang memerlukan alasan kompleks diluar pengenalan objek. Bagaimanapun, sedikit yang diketahui tentang bagaimana mereka mencapai keputusan ini atau apa batasan mereka. Dalam kertas ini, kita fokus pada kemampuan bahasa tertentu, iaitu pemahaman negatif. Kami meminjam teknik dari analisis model bahasa untuk menyelidiki kemampuan model penglihatan dan bahasa terlatih untuk menangani negatif. Kami mendapati bahawa model-model ini sangat rendah dalam kehadiran negatif.', 'kk': 'Алдыңғы көрініс мен тіл үлгілері көптеген тапсырмалардың әртүрлі нәтижелерін жеткіздік, сондай-ақ нысандарды анықтауға арналған комплекс себептерді талап етеді. Бірақ олар осы нәтижелерді қалай жеткізетін немесе шектеулері қандай болатынын білмейді. Бұл қағазда, біз лингвистикалық мүмкіндіктеріне назар береміз, мысалы - негативті түсініміз. Біз тіл үлгілерін анализдеу үшін алдын- оқылған көрініс және тіл үлгілерінің қасиетін зерттеу үшін техникаларды ұстаймыз. Біз бұл үлгілер негативдік болып тұрғанда өте жақсы істейді.', 'lt': 'Iš anksto apmokyti vizijos ir kalbos modeliai sukėlė įspūdingų rezultatų įvairiose užduotyse, įskaitant užduotis, kurioms reikalingas sudėtingas pagrindimas be objektų pripažinimo. However, little is known about how they achieve these results or what their limitations are.  In this paper, we focus on a particular linguistic capability, namely the understanding of negation.  Iš kalbų modelių analizės pasiskoliname metodais, kad ištirtume iš anksto parengtų vizijos ir kalbos modelių gebėjimą valdyti neigiamą padėtį. Nustatome, kad šie modeliai labai nepakankamai veiksmingi atsisakant.', 'mt': 'Mudelli ta’ viżjoni u lingwa mħarrġa minn qabel kisbu riżultati impressjonanti fuq varjetà ta’ kompiti, inklużi dawk li jeħtieġu raġunament kumpless lil hinn mir-rikonoxximent tal-oġġett. Madankollu, ftit huwa magħruf dwar kif jiksbu dawn ir-riżultati jew x’inhuma l-limitazzjonijiet tagħhom. F’dan id-dokument, niffokaw fuq kapaċità lingwistika partikolari, jiġifieri l-fehim tan-negazzjoni. Nisellfu tekniki mill-analiżi tal-mudelli lingwistiċi biex ninvestigaw il-kapaċità ta’ mudelli ta’ viżjoni u lingwa mħarrġa minn qabel li jimmaniġġjaw in-negazzjoni. Issibu li dawn il-mudelli ma jwettqux biżżejjed prestazzjoni fil-preżenza ta’ negazzjoni.', 'mn': 'Өмнө сургалтын үзэл болон хэл загварууд олон даалгавар дээр гайхалтай үр дүнг гаргасан. Объектын хүлээн зөвхөн комплекс ойлголт хэрэгтэй. Гэхдээ эдгээр үр дүнг хэрхэн, хязгаарлалтыг хэрхэн хүртэхийг бага мэддэг. Энэ цаасан дээр бид хэлний чадварын тухай анхаарлаа анхаарлаа төвлөрүүлдэг. Яг л сөрөг зүйлсийг ойлгох. Бид хэл загварын шинжилгээс техникуудыг аль болон хэл загварын аль болон сургалтын үзэл загварын чадварыг судалж өгсөн. Бид эдгээр загварууд сөрөг байдалд маш бага байдаг.', 'ml': 'പഠിപ്പിക്കപ്പെട്ട കാഴ്ചകളും ഭാഷ മോഡലുകളും വ്യത്യസ്തമായ ജോലികളുടെ ഫലങ്ങള്\u200d കണ്ടെത്തിയിരിക്കുന്നു. ഉപയോഗങ്ങള്\u200dക്ക് മുന്\u200dപ്  However, little is known about how they achieve these results or what their limitations are.  ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു പ്രത്യേക ഭാഷക്കാരന്റെ കഴിവിനെക്കുറിച്ച് ശ്രദ്ധിക്കുന്നു. നേരിയയുടെ മനസ്സില ഭാഷ മോഡലുകളുടെ അന്വേഷണത്തില്\u200d നിന്നും നമ്മള്\u200d ടെക്കിനിക്ക് വാങ്ങുന്ന സാങ്കേതികവിദ്യകള്\u200d നേരിട്ടുനോക്കാനുള്ള നമുക്ക് കണ്ടെത്തുന്നത് ഈ മോഡലുകള്\u200d നെഗറിയേഷന്\u200dറെ സാന്നിധ്യത്തില്\u200d കൂടുതല്\u200d പ്രവര്\u200dത്തിക്കു', 'pl': 'Wstępnie przeszkolone modele wizji i języka osiągnęły imponujące rezultaty w wielu zadaniach, w tym takich, które wymagają złożonego rozumowania poza rozpoznawaniem obiektów. Niewiele wiadomo jednak o tym, w jaki sposób osiągają te rezultaty lub jakie są ich ograniczenia. W artykule skupiamy się na szczególnej zdolności językowej, a mianowicie na zrozumieniu negacji. Pożyczamy techniki z analizy modeli językowych, aby zbadać zdolność wcześniej przeszkolonych modeli wizji i języka do radzenia sobie z negacją. Stwierdzimy, że modele te poważnie słabo sprawdzają się w obecności negacji.', 'no': 'Førehandsvis vising- og språk-modeller har oppnådd uttrykkelige resultat på mange oppgåver, inkludert dei som krev komplekse grunnlag enn objektkjenning. Men litt er kjent om korleis dei oppnår disse resultatene eller kva grensene dei er. I denne papiret fokuserer vi på ein spesielt språkstisk kapasitet, som er forståelse av negasjon. Vi låner teknikke frå analysen av språk-modeller for å undersøke evnen på føretrainerte visingsog språk-modeller for å handtera negasjon. Vi finn at desse modelane er vanskeleg underutført i tilstand av negasjon.', 'ro': 'Modelele pre-instruite de viziune și limbaj au obținut rezultate impresionante într-o varietate de sarcini, inclusiv cele care necesită raționamente complexe dincolo de recunoașterea obiectelor. Cu toate acestea, se știe puține despre modul în care obțin aceste rezultate sau care sunt limitele lor. În această lucrare, ne concentrăm pe o anumită capacitate lingvistică, și anume înțelegerea negației. Împrumutăm tehnici din analiza modelelor lingvistice pentru a investiga capacitatea modelelor de viziune și limbaj pre-instruite de a gestiona negarea. Considerăm că aceste modele sunt grav subperformante în prezența negării.', 'sv': 'Förtränade vision- och språkmodeller har uppnått imponerande resultat på en mängd olika uppgifter, inklusive sådana som kräver komplexa resonemang bortom objektigenkänning. Det är dock lite känt om hur de uppnår dessa resultat eller vad deras begränsningar är. I denna uppsats fokuserar vi på en särskild språklig förmåga, nämligen förståelsen av negation. Vi lånar tekniker från analysen av språkmodeller för att undersöka förmågan hos förintränade vision- och språkmodeller att hantera negation. Vi finner att dessa modeller kraftigt underpresterar i närvaro av negation.', 'so': 'Tusaalada muuqashada iyo afka hore waxaa laga helay matooyin wanaagsan oo ku saabsan shaqooyin kala duduwan, kuwaas oo ah kuwa u baahan sabab adag oo aan la aqoonsan wax kasta. Si kastaba ha ahaatee wax yar waxaa la yaqaan sida ay u soo gaadhaan resultiyadan ama xuduudaha ay yihiin. In this paper, we focus on a particular linguistic capability, namely the understanding of negation.  Waxaannu wax ka amaahannaa qalabka baaritaanka modelalka luuqada si aan u baarayno awoodda muuqashada iyo tusaalaha afka hore oo lagu barto inay u baaraandegaan wax diidi ah. Waxaynu ogaanaynaa in modelladan si adag u shaqeeyaan marka ay jiraan waxyaabo.', 'ta': 'முன்பயிற்சி காட்சி மற்றும் மொழி மாதிரி மாதிரிகள் பல பணிகளின் முடிவுகளை பெருக்கினார்கள், பொருள் அடையாளத்திற்கு மேல் சிக ஆனால், இந்த முடிவுகளை எப்படி அடையும் என்பதைப் பற்றி சிறிது தெரியும் அல்லது அவர்களுடைய எல்லைகள் என்ன. இந்த காகிதத்தில், நாம் ஒரு குறிப்பிட்ட மொழிமாற்றலை கவனம் செலுத்துகிறோம், எதிர்மறை புரிந்து கொள்வது. நாம் மொழி மாதிரிகளின் ஆராய்ச்சியிலிருந்து தொழில்நுட்பத்தை கடன்றுக்கொள்கிறோம் முன் பயிற்சி காட்சி மற்றும நாம் இந்த மாதிரிகள் எதிர்பார்ப்பின் முன்னால் கடுமையாக செயல்படுத்துகிறது என்பதை கண்டுபிடி', 'sr': 'Pre-obučeni modeli vizije i jezika postigli su impresivne rezultate na raznim zadacima, uključujući one koji zahtevaju kompleksno razmišljanje izvan priznanja objekata. Međutim, malo je poznato kako postignu te rezultate ili šta su njihove ograničenje. U ovom papiru, fokusiramo se na posebnu jezičku sposobnost, a to je razumijevanje negacije. Pozajmićemo tehnike iz analize jezičkih modela da istražimo sposobnost predobučenih modela vizije i jezika kako bi se bavili negacijom. Pronašli smo da su ovi modeli teško podrške u prisustvu negacije.', 'si': 'ප්\u200dරධාන ප්\u200dරේක්ෂණිත දිහා භාෂා මොඩේල්ස් වලින් විවිධ වැඩක් ගැන ප්\u200dරශ්නයක් ලැබුණා, ඒ වගේම ප්\u200dරශ්නයක් අ ඒත් පොඩ්ඩක් දැනගන්නේ එයාලා මේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර මේ පත්තරේ අපි විශේෂ භාෂාවික ශක්තියක් ගැන අවධානය කරනවා, ඒ වගේම අවධානය කරනවා. අපි භාෂා මෝඩේල් විශ්ලේෂණයෙන් ප්\u200dරශ්නයක් ගන්න පුළුවන් ප්\u200dරශ්නයක් ලැබෙන්න පුළුවන් ප්\u200dරශ්නයක් පු අපිට හොයාගන්න පුළුවන් මේ මොඩේල්ස් ගොඩක් බොරු වෙනවා කියලා.', 'ur': 'پہلے کی تعلیم کی تصویر اور زبان کی مدلکوں نے مختلف کاموں پر اثر انگیز نتیجے پہنچ گئے ہیں، ان میں سے جن کی تعلیم تعلیم کی ضرورت ہے object وں کی شناخت کے بعد. لیکن بہت ہی کم جانتا ہے کہ یہ کس طرح ان کے نتائج پہنچ سکتے ہیں یا ان کی حدود کیا ہے اس کاغذ میں ہم ایک مخصوص زبان کی قابلیت پر تمرکز کرتے ہیں، یعنی منفی کا سمجھنا۔ ہم زبان نمڈلوں کی تحلیل سے تکنیک لیتے ہیں تاکہ پہلے تحلیل کی تصویر اور زبان نمڈلوں کے قابل تحقیق کریں کہ منفی طریقے کے لئے منفی کریں. ہم دیکھتے ہیں کہ یہ نمونے ناپسند کے حضور زیادہ کم کر رہے ہیں.', 'uz': "Taʼminlovchi ko'rinish va tilning modellari bir necha vazifalar uchun juda yaxshi natijalarni topadi. Agar narsalar obʼekt aniqlash uchun murakkab sabablar kerak. Lekin, bu natijalarni qanday amalning chegaralarini qanday amalga oshirishni bilmaydi. Bu qogʻozda, biz bir hususiy tillar qobiliyatiga qarasamiz, nega tushunish imkoniyatini. We borrow techniques from the analysis of language models to investigate the ability of pre-trained vision-and-language models to handle negation.  Biz bu modellar yomonlik hayotida juda katta ishlaydi.", 'vi': 'Những mô hình ảnh và ngôn ngữ đã được đào tạo trước đã đạt được kết quả ấn tượng về nhiều nhiệm vụ, bao gồm những nhiệm vụ cần lập luận phức tạp vượt qua nhận dạng đối tượng. Tuy nhiên, ít biết về cách họ đạt được kết quả hay giới hạn của họ. Trong tờ giấy này, chúng ta tập trung vào một khả năng ngôn ngữ đặc biệt, là sự hiểu biết âm bản. Chúng tôi mượn kỹ thuật từ phân tích các mô hình ngôn ngữ để nghiên cứu khả năng của các mô hình ảnh và ngôn ngữ được huấn luyện để xử lý sự cấm đoán. Chúng tôi thấy các mô hình này quá tệ khi có sự từ chối.', 'hr': 'Preobučeni modeli vizije i jezika postigli su impresivni rezultati na raznim zadacima, uključujući one koji zahtijevaju kompleksno razmišljanje izvan priznanja objekata. Međutim, malo je poznato kako postignu te rezultate ili što su njihove ograničenje. U ovom papiru, fokusiramo se na posebnu jezičku sposobnost, a to je razumijevanje negacije. Pozajmićemo tehnike iz analize jezičkih modela kako bi istražili sposobnost predobučenih modela vizije i jezika kako bi se riješili negacija. Mi smatramo da su ovi modeli teško podizani u prisustvu negacije.', 'bg': 'Предварително обучените модели на зрение и език са постигнали впечатляващи резултати по различни задачи, включително такива, които изискват сложни разсъждения отвъд разпознаването на обектите. Въпреки това, малко се знае за това как те постигат тези резултати или какви са техните ограничения. В тази статия се фокусираме върху конкретна езикова способност, а именно разбирането на отрицанието. Вземаме назаем техники от анализа на езикови модели, за да изследваме способността на предварително обучените модели на зрение и език да се справят с отрицанието. Намираме, че тези модели сериозно не се представят в присъствието на отрицание.', 'nl': 'Vooropgeleide visie- en taalmodellen hebben indrukwekkende resultaten behaald bij een verscheidenheid aan taken, waaronder taken die complexe redenering vereisen die verder gaat dan objectherkenning. Er is echter weinig bekend over hoe ze deze resultaten bereiken of wat hun beperkingen zijn. In dit artikel richten we ons op een bepaalde taalvaardigheid, namelijk het begrip van negatie. We lenen technieken uit de analyse van taalmodellen om het vermogen van vooraf getrainde visie- en taalmodellen om met negatie om te gaan te onderzoeken. We vinden dat deze modellen ernstig onderpresteren in aanwezigheid van negatie.', 'da': 'Forududdannede vision- og sprogmodeller har opnået imponerende resultater på en række forskellige opgaver, herunder dem, der kræver kompleks ræsonnement ud over objektgenkendelse. Der ved dog ikke meget om, hvordan de opnår disse resultater, eller hvad deres begrænsninger er. I denne artikel fokuserer vi på en særlig sproglig evne, nemlig forståelsen af negation. Vi låner teknikker fra analyse af sprogmodeller til at undersøge evnen af prætrænede vision- og sprogmodeller til at håndtere negation. Vi finder, at disse modeller alvorligt underpræsterer i tilstedeværelse af negation.', 'fa': 'مدل\u200cهای دید و زبان پیش آموزش داده شده\u200cاند، نتیجه\u200cهای تاثیر\u200cپذیر روی کارهای مختلف را به دست آورده\u200cاند، شامل کسانی که نیاز به دلیل پیچیده\u200cای فراتر از شناسایی جسم\u200cها دارند. ولی در مورد اینکه چگونه این نتیجه\u200cها را می\u200cرسانند، یا حدود\u200cهایشان، کمی می\u200cدانند. در این کاغذ، ما روی یک توانایی زبان\u200cشناسی خاص تمرکز می\u200cکنیم، یعنی درک ناپذیری. ما تکنیک\u200cها را از تحلیل مدل\u200cهای زبان قرض می\u200cدهیم تا توانایی مدل\u200cهای دید و زبان پیش آموزش را تحقیق کنند تا از نابودی کند. ما پیدا می\u200cکنیم که این مدل\u200cها در موقعیت منکری بسیار کم انجام می\u200cدهند.', 'id': 'Pre-trained vision-and-language models have achieved impressive results on a variety of tasks, including ones that require complex reasoning beyond object recognition.  Namun, sedikit yang diketahui tentang bagaimana mereka mencapai hasil ini atau apa batasan mereka. Dalam kertas ini, kita fokus pada kemampuan bahasa tertentu, yaitu pemahaman negatif. Kami meminjam teknik dari analisis model bahasa untuk menyelidiki kemampuan model penglihatan dan bahasa yang terlatih untuk menangani negatif. Kami menemukan bahwa model-model ini sangat rendah dalam kehadiran negatif.', 'tr': 'Öňki okuwçy görnüş-we dil nusgalary birnäçe zada etkileýän netijelere ýetdi, hatda zadyň tanyşyndan soňra karmaşık sebäplere gerek. Ýöne bu netijeleri nähili ýetip biljeklerini ýa-da mugatlarynyň nähili bolandygyny barada biraz bilýär. Bu kagyzda, biz lingwistiki ukyplaryň üstine üns berýäris, diýmek ýalňyşlygyny düşünmek. Biz dil nusgalaryndan öňünden ukyp biljek nusgalaryň negatyny çözmek üçin teknikleri alýarys. Bu nusgalar negatiýa ýagdaýda çykyp ýok bolýar.', 'de': 'Vortrainierte Vision- und Sprachmodelle haben beeindruckende Ergebnisse bei einer Vielzahl von Aufgaben erzielt, einschließlich solcher, die komplexes Denken jenseits der Objekterkennung erfordern. Allerdings ist wenig darüber bekannt, wie sie diese Ergebnisse erzielen oder was ihre Grenzen sind. In diesem Beitrag konzentrieren wir uns auf eine besondere sprachliche Fähigkeit, nämlich das Verständnis von Negation. Wir nutzen Techniken aus der Analyse von Sprachmodellen, um die Fähigkeit von vortrainierten Vision- und Sprachmodellen zu untersuchen, mit Negation umzugehen. Wir stellen fest, dass diese Modelle in Gegenwart von Negation stark schlechter abschneiden.', 'af': "Vorige opgelei visie-en-taal-modelles het inpresieële resultate op 'n verskillende opdragte bereik, insluitend die wat kompleks redening vereis buite voorwerp van voorwerp herken. Maar, klein is bekend oor hoe hulle hierdie resultate bereik of wat hulle beperking is. In hierdie papier, ons fokus op 'n spesifieke lingwisiese kapasiteit, bedoel die verstanding van negasie. Ons luit teknike van die analiseer van taal modele om die moontlikheid van voorafgevorderde visie-en-taal modele te ondersoek om negasie te hanteer. Ons vind dat hierdie modele swaar onderhou in die voorsiening van negasie.", 'sq': 'Modelet e paratrajnuara të vizionit dhe gjuhës kanë arritur rezultate mbresëlënëse në një varietet detyrash, duke përfshirë ato që kërkojnë arsyetim kompleks përtej njohjes së objekteve. Megjithatë, pak është e njohur se si arrijnë këto rezultate apo cilat janë kufizimet e tyre. Në këtë letër, ne përqëndrohemi në një aftësi të veçantë gjuhësore, veçanërisht në kuptimin e negativit. Ne marrim hua teknika nga analiza e modeleve gjuhësore për të hetuar aftësinë e modeleve paratrajnuar të vizionit dhe gjuhës për të trajtuar negativën. We find that these models severely underperform in the presence of negation.', 'am': 'የቀድሞው የራእይን እና ቋንቋ-ቋንቋ ምሳሌዎች በተለያዩ ስራዎች ላይ ያማረ ፍሬዎችን አግኝተዋል፡፡ However, little is known about how they achieve these results or what their limitations are.  በዚህ ፕሮግራም፣ የቋንቋዊ ኃይል፣ የሽፋን ማስተዋል እናቆማለን፡፡ የቋንቋ ዓይነቶች ማስረጃ እና የቋንቋ-ቋንቋ ዓይነቶችን መቆጣጠር ችሎታዎችን ለመመርመርመር እናስማርናለን፡፡ እነዚህም ምሳሌዎች በጥፋት ፊት በጭንቀት እንደተሳካ እናገኛለን፡፡', 'hy': 'Նախապատրաստված տեսողության և լեզվի մոդելները բազմաթիվ խնդիրների վրա տպավորիչ արդյունքներ են ստացել, ներառյալ այն խնդիրները, որոնք պահանջում են բարդ մտածողություններ առանց օբյեկտների ճանաչման: Այնուամենայնիվ, քիչ է հայտնի այն մասին, թե ինչպես են նրանք հասնում այս արդյունքներին կամ ինչ են իրենց սահմանափակումները: Այս թղթի մեջ մենք կենտրոնանում ենք որոշակի լեզվաբանական հնարավորության վրա, հատկապես մերժման հասկանալու վրա: Մենք փոխառում ենք լեզվի մոդելների վերլուծության մեթոդներ, որպեսզի ուսումնասիրենք նախապատրաստված տեսողության և լեզվի մոդելների կարողությունը բացասական վարվել: Մենք հայտնաբերում ենք, որ այս մոդելները լուրջ թերահաջողություն ունեն բացասական դեպքում:', 'az': 'Əvvəlcə təhsil edilmiş görünüş və dil modelləri növbənöv işlərdə etkileyici sonuçları başa düşdü, həmçinin objektləri tanımadan çox kompleks dəyişiklik lazımdır. Ancaq bu sonuçların necə başa düşdüyünü və nəticələrinin necə olduğunu az bilər. Bu kağızda, müəyyən bir dil qabiliyyətinə odaklanırıq, yani negasyonun anlaması. Biz dil modellərin analizindən təhsil edirik ki, əvvəlcə təhsil edilmiş görünüş və dil modellərinin təhsil edilməsi üçün təhsil edilmiş modellərin yetkinliğini incitmək üçün. Biz bu modellərin negatif olmasında çox çətin əməllərini tapırıq.', 'sw': 'Mfano wa maono na lugha zilizojifunza vimepata matokeo mazuri ya kazi mbalimbali, ikiwa ni pamoja na wale wanaohitaji sababu tatizo zaidi ya kutambua vitu. Hata hivyo, bado hawajui jinsi wanavyofikia matokeo haya au mipaka yao ni vipi. Katika karatasi hii, tunajikita na uwezo maalum wa lugha, yaani uelewa wa hasi. Tunapataji mbinu kutoka katika uchambuzi wa mifano ya lugha ili kuchunguza uwezo wa mifano ya maono na lugha ya zamani ya kukabiliana na hasi. Tunapata kwamba mifano hii inafanya vizuri katika presence of hasi.', 'ko': '미리 훈련된 시각과 언어 모델은 각종 임무에서 인상적인 결과를 얻었다. 복잡한 추리가 있어야만 목표 식별을 완성할 수 있는 임무를 포함한다.그러나 사람들이 그 결과를 어떻게 실현했는지, 그리고 그 한계성에 대해 아는 것은 드물다.본고에서 우리는 부정에 대한 이해라는 특수한 언어 능력에 주목한다.우리는 언어 모델 분석의 기술을 빌려 미리 훈련된 시각과 언어 모델이 부정을 처리하는 능력을 연구한다.우리는 이 모델들이 부정적인 상황에서 심각하게 좋지 않다는 것을 발견했다.', 'bn': 'প্রশিক্ষিত ভিশন ও ভাষার মডেল বিভিন্ন কাজের উপর আকর্ষণীয় ফলাফল অর্জন করেছে, যাদের মধ্যে রয়েছে যাদের বস্তুকে স্বীকৃতির বাইরে জটিল কারণ তবে তারা এই ফলাফল কিভাবে অর্জন করে অথবা তাদের সীমাবদ্ধতা কীভাবে। এই কাগজটিতে আমরা একটি বিশেষ ভাষাগত ক্ষমতার উপর মনোযোগ দিচ্ছি, যার মধ্যে নেতিবেশনের বোঝা। আমরা ভাষার মডেলের বিশ্লেষণ থেকে কৌশল ধার দিয়েছি পূর্ব প্রশিক্ষিত ভাষা এবং ভাষার মডেলের নেতিবিরতি সামলাতে পারার ক্ আমরা খুঁজে পাচ্ছি যে এই মডেলগুলো নেতিবেশনের উপস্থিতিতে গুরুত্বপূর্ণ ভাবে চালাচ্ছে।', 'cs': 'Předškolené modely vidění a jazyka dosáhly působivých výsledků při řadě úkolů, včetně těch, které vyžadují komplexní uvažování mimo rozpoznávání objektů. Nicméně o tom, jak dosahují těchto výsledků nebo jaká jsou jejich omezení, je známo málo. V tomto článku se zaměřujeme na konkrétní jazykovou schopnost, konkrétně porozumění negaci. Z analýzy jazykových modelů si vypůjčujeme techniky, abychom zkoumali schopnost předškolených vizuálních a jazykových modelů zvládnout negaci. Zjišťujeme, že tyto modely výrazně nedosahují výkonu v přítomnosti negace.', 'ca': "Els models de visió i llenguatge pré-entrenats han aconseguit resultats impressionants en una varietat de tasques, incloent aquelles que requereixen raonament complexe més enllà del reconeixement d'objectes. However, little is known about how they achieve these results or what their limitations are.  En aquest paper ens centrem en una capacitat lingüística concreta, a saber, la comprensió de la negatió. Prenem tècniques a partir de l'anàlisi de models de llenguatge per investigar l'habilitat dels models de visió i llenguatge pré-entrenats de gestionar la negatió. Trobem que aquests models són gravement insuficients en presencia de negatió.", 'bs': 'Preobučeni modeli vizije i jezika postigli su impresivni rezultati na raznim zadacima, uključujući one koji zahtijevaju kompleksno razmišljanje izvan priznanja objekata. Međutim, malo je poznato kako postignu te rezultate ili kakve su njihove ograničenje. U ovom papiru, fokusiramo se na posebnu jezičku sposobnost, a to je razumijevanje negacije. Pozajmićemo tehnike iz analize jezičkih modela da istražimo sposobnost predobučenih modela vizije i jezika kako bi se bavili negacijom. Mi smatramo da su ovi modeli teško podnijeli u prisustvu negacije.', 'fi': 'Esikoulutetut näkö- ja kielimallit ovat saavuttaneet vaikuttavia tuloksia erilaisissa tehtävissä, myös niissä, joissa vaaditaan monimutkaista päättelyä objektitunnistuksen ulkopuolella. Kuitenkin vähän tiedetään siitä, miten ne saavuttavat nämä tulokset tai mitkä niiden rajoitukset ovat. Tässä artikkelissa keskitymme tiettyyn kielelliseen kykyyn, nimittäin kieltämisen ymmärtämiseen. Lainaamme kielimallien analyysistä tekniikoita tutkiaksemme esikoulutettujen näkemys- ja kielimallien kykyä käsitellä kieltämistä. Huomaamme, että nämä mallit ovat erittäin heikosti suoriutuneita kiellon läsnä ollessa.', 'et': 'Eelkoolitud nägemis- ja keelemudelid on saavutanud muljetavaldavaid tulemusi mitmesuguste ülesannete puhul, sealhulgas nende puhul, mis nõuavad objekti tuvastamisest väljaspool keerukat arutlust. Kuid vähe on teada, kuidas nad saavutavad need tulemused või millised on nende piirangud. Käesolevas dokumendis keskendume konkreetsele keelelisele võimekusele, nimelt eitamise mõistmisele. Laename keelemudelite analüüsist tehnikaid, et uurida eelkoolitud nägemis- ja keelemudelite võimet käsitleda negatsiooni. Leiame, et need mudelid on negatsiooni juuresolekul väga halvad.', 'sk': 'Predhodno usposobljeni modeli vizije in jezika so dosegli impresivne rezultate pri različnih nalogah, vključno s tistimi, ki zahtevajo kompleksno razmišljanje, ki presega prepoznavanje objektov. Vendar pa je malo znano o tem, kako dosežejo te rezultate ali kakšne so njihove omejitve. V prispevku se osredotočamo na posebno jezikovno sposobnost, namreč na razumevanje zanikanja. Izposojamo si tehnike iz analize jezikovnih modelov za raziskovanje sposobnosti vnaprej usposobljenih modelov vizije in jezika za obvladovanje zanikanja. Ugotovili smo, da ti modeli v prisotnosti zanikanja zelo slabo delujejo.', 'ha': "Modalin gani da harshen zaman aka sami matsayin mai kyau a kan wani aikin dabam-dabam, kamar waɗanda ke buƙata sabon da ke da wata sabon da ba'a gane abun. A'a, bã da abu kaɗan ba a san yadda suke sãmun waɗannan matsararsu ko abin da suke ƙaranci. In a cikin wannan takarda, munã fahimta masu cikin abincin da aka ƙayyade harshen, misalin fahimtar haske. Tuna ɗauki misãlai daga anayyar misãlai na harshe dõmin mu yi ƙidãya awon misalin-na-da-harshen zaman-wanda za'a yi amfani da haske. Muna gane cewa waɗannan misãlai sunã aiki mai girma a gaba ga haske.", 'jv': 'Awak-Awak Masking Nanging, sithik liwat ditambah barang babagan piye perangkat dhéwé dadi iki dadi, opo sing perusahaan uwong. Nanging mapang iki, awake dhéwé dipundukne ning kapasituran ingkang sing apik, nambah kang ngerasakno. Awak dhéwé nglanggar teknik karo halénsul model sing luwih nggambar nggambar kapan modèl ro-terenyang karo nggambar barang. Awak dhéwé ngerti, model iki dadi nggawe barang-barang.', 'bo': 'སྔོན་གྲངས་འཛིན་གྱི་མཐོང་སྣང་དང་སྐད་ཡིག ཡིན་ནའང་། ཁོང་ཚོས་ཇི་ལྟར་འབྲས་བྱ་རྐྱེན་དང་ཁོང་ཚོའི་ཚད་གཞི་གང་ཡིན ཤོག་བྱང་འདིའི་ནང་གི་སྐད་རིགས་ལ་ཆ་ཁྱད་པར་བློ་གཏོང་ནུས་པ་ཞིག་དང་། མིང་དུ་ཤོག་བྱང་ཉེས་ཀྱི་རྟོ We borrow techniques from the analysis of language models to investigate the ability of pre-trained vision-and-language models to handle negation. ང་ཚོས་མིག་གཟུགས་རིས་འདི་དག་གི་གཟུགས་རིས་མེད་དུ་རྩ་བ་ཁག་པོ་ཡོད་པས་', 'he': 'מודלים חזון ושפה מאומנים מראש השיגו תוצאות מרשים על מגוון משימות, כולל משימות שדורשות הגיון מורכב מעבר לזהות אובייקטים. עם זאת, מעט ידוע על איך הם מגיעים לתוצאות אלה או מה הגבלות שלהם. In this paper, we focus on a particular linguistic capability, namely the understanding of negation.  אנחנו משאילים טכניקות מהניתוח של דוגמני שפה כדי לחקור את היכולת של דוגמני חזון ושפה מאומנים מראש להתמודד עם שלילה. אנו מוצאים שהדוגמנים האלה מתעלמים מאוד בנוכחות שלילה.'}
{'en': 'Learning Mathematical Properties of Integers', 'pt': 'Aprendendo Propriedades Matemáticas de Inteiros', 'ar': 'تعلم الخصائص الرياضية للأعداد الصحيحة', 'es': 'Aprendizaje de las propiedades matemáticas de los enteros', 'ja': '整数の数学的性質の学習', 'fr': 'Apprentissage des propriétés mathématiques des nombres entiers', 'ru': 'Изучение математических свойств целых чисел', 'hi': 'पूर्णांक के गणितीय गुण सीखना', 'zh': '数学属性', 'ga': 'Foghlaim Airíonna Matamaitice na Slánuimhreacha', 'hu': 'Az egészek matematikai tulajdonságainak tanulása', 'ka': 'მთელი რიცხვის მათემატიკური განსაზღვრება', 'lt': 'Mokymasis matematinėmis visaverčių savybėmis', 'el': 'Μάθηση μαθηματικών ιδιοτήτων ακέραιων', 'kk': 'Бүтін сандардың математикалық қасиеттерін үйрену', 'it': 'Imparare le proprietà matematiche degli interi', 'mk': 'Учење математички сопствености на целите', 'ms': 'Mempelajari Ciri Matematik Integer', 'ml': 'ഗണിത ഗുണഗണങ്ങള്\u200d പഠിക്കുന്നു', 'mt': 'Learning Mathematical Properties of Integers', 'no': 'Læring matematiske eigenskapar for heiltal', 'pl': 'Uczenie się właściwości matematycznych liczb całkowitych', 'sr': 'Naučenje matematičkih vlasništva celog broja', 'ro': 'Învățarea proprietăților matematice ale întregilor', 'mn': 'Тооны математикийн хувьцаа сурах', 'so': 'Barista tayada xisaabta', 'sv': 'Lära sig matematiska egenskaper hos heltal', 'ta': 'முழுமையாளர்களின் கணித பண்புகளை கற்றுக்கொள்கிறது', 'si': 'ගාණිතික විශේෂතාව ඉගෙනගන්න', 'ur': 'پورے اعداد کے ریاضی خصوصیت سکھائی جاتی ہے', 'uz': 'Name', 'vi': 'Học tài sản toán học của thiết kế', 'da': 'Indlæring af heltes matematiske egenskaber', 'de': 'Lernen mathematischer Eigenschaften von Ganzzahlen', 'bg': 'Учене на математически свойства на цели числа', 'nl': 'Wiskundige eigenschappen van getallen leren', 'hr': 'Naučenje matematičkih vlasništva cijelog broja', 'id': 'Mempelajari Properti Matematika Integer', 'fa': 'یاد گرفتن ویژگی ریاضی کلی', 'af': 'Leer Wiskundige Eienskappe van Heelgetalle', 'ko': '정수의 수학적 성질을 배우다', 'sw': 'Kujifunza Taybeti za Kihisabati', 'sq': 'Mësimi i pronave matematike të të gjithë', 'tr': 'Kalamyň matematik häsiýetlerini öwrenmek', 'az': 'He칞 Say캼lar캼n Matematik 칐yr톛nm톛si', 'bn': 'গণতান্ত্রিক বৈশিষ্ট্যাবলীর বৈশিষ্ট্যাবলী', 'am': 'ምርጫዎች', 'bs': 'Naučenje matematičkih vlasništva cijelog broja', 'ca': 'Learning Mathematical Properties of Integers', 'hy': 'Ամբողջ թվերի մաթեմատիկական հատկություններ սովորելը', 'fi': 'Kokonaisten lukujen matemaattisten ominaisuuksien oppiminen', 'cs': 'Učení matematických vlastností celých čísel', 'et': 'Täisarvutite matemaatiliste omaduste õppimine', 'sk': 'Učenje matematičnih lastnosti celih črk', 'he': 'ללמוד תכונות מתמטיות של שלמים', 'ha': 'KCharselect unicode block name', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'ཚང་མས་འདིའི་གྲངས་རིག་གི་རྒྱུ་ཆ་ལ་སློབ་བཞིན་པ།'}
{'en': 'Embedding words in high-dimensional vector spaces has proven valuable in many natural language applications. In this work, we investigate whether similarly-trained embeddings of integers can capture concepts that are useful for mathematical applications. We probe the integer embeddings for mathematical knowledge, apply them to a set of numerical reasoning tasks, and show that by learning the representations from mathematical sequence data, we can substantially improve over number embeddings learned from English text corpora.', 'ar': 'أثبت تضمين الكلمات في فضاءات متجهية عالية الأبعاد قيمة في العديد من تطبيقات اللغة الطبيعية. في هذا العمل ، نتحرى ما إذا كانت عمليات دمج الأعداد الصحيحة المدربة بشكل مشابه يمكنها التقاط مفاهيم مفيدة للتطبيقات الرياضية. نحن نتحرى عن الزخارف الصحيحة للمعرفة الرياضية ، ونطبقها على مجموعة من مهام التفكير العددي ، ونوضح أنه من خلال تعلم التمثيلات من بيانات التسلسل الرياضي ، يمكننا بشكل كبير تحسين عدد حفلات الزفاف التي تعلمناها من النص الإنجليزي.', 'es': 'La incrustación de palabras en espacios vectoriales de alta dimensión ha demostrado ser valiosa en muchas aplicaciones de lenguaje natural. En este trabajo, investigamos si las incrustaciones de números enteros entrenadas de manera similar pueden capturar conceptos que son útiles para aplicaciones matemáticas. Investigamos las incrustaciones de enteros para el conocimiento matemático, las aplicamos a un conjunto de tareas de razonamiento numérico y demostramos que al aprender las representaciones de datos de secuencias matemáticas, podemos mejorar sustancialmente las incrustaciones de números aprendidas de los cuerpos de texto en inglés.', 'fr': "L'intégration de mots dans des espaces vectoriels de grande dimension s'est révélée utile dans de nombreuses applications de langage naturel. Dans ce travail, nous étudions si des intégrations d'entiers formés de manière similaire peuvent capturer des concepts utiles pour des applications mathématiques. Nous étudions les intégrations d'entiers pour des connaissances mathématiques, les appliquons à un ensemble de tâches de raisonnement numérique et montrons qu'en apprenant les représentations à partir de données de séquences mathématiques, nous pouvons considérablement améliorer les intégrations de nombres apprises à partir de corpus de textes anglais.", 'pt': 'A incorporação de palavras em espaços vetoriais de alta dimensão provou ser valiosa em muitas aplicações de linguagem natural. Neste trabalho, investigamos se embeddings de inteiros treinados de forma semelhante podem capturar conceitos que são úteis para aplicações matemáticas. Nós sondamos as incorporações de números inteiros para conhecimento matemático, as aplicamos a um conjunto de tarefas de raciocínio numérico e mostramos que, aprendendo as representações de dados de sequência matemática, podemos melhorar substancialmente as incorporações de números aprendidas com corpora de texto em inglês.', 'ja': '高次元ベクトル空間に単語を埋め込むことは、多くの自然言語アプリケーションで価値があることが証明されています。この研究では、同様に訓練された整数の埋め込みが、数学的応用に有用な概念を取り込むことができるかどうかを調査します。数学的知識のために整数埋め込みを探索し、それらを一連の数値推論タスクに適用し、数学的シーケンスデータから表現を学習することで、英語のテキストコーパスから学んだ数値埋め込みよりも実質的に改善できることを示します。', 'zh': '嵌高维向量空中单词诸自然语言已验有直。 于此,我们研究了这样训练的整数可以对数学应用的大概。 探数学知识之全数嵌入,宜用于一组数推理,并明从数学序数中学习,可大改善从英语文本语料库中学得之数嵌之。', 'hi': 'उच्च आयामी वेक्टर रिक्त स्थान में शब्दों को एम्बेड करना कई प्राकृतिक भाषा अनुप्रयोगों में मूल्यवान साबित हुआ है। इस काम में, हम जांच करते हैं कि क्या पूर्णांकों के समान रूप से प्रशिक्षित एम्बेडिंग उन अवधारणाओं को कैप्चर कर सकते हैं जो गणितीय अनुप्रयोगों के लिए उपयोगी हैं। हम गणितीय ज्ञान के लिए पूर्णांक एम्बेडिंग की जांच करते हैं, उन्हें संख्यात्मक तर्क कार्यों के एक सेट पर लागू करते हैं, और दिखाते हैं कि गणितीय अनुक्रम डेटा से प्रतिनिधित्व सीखकर, हम अंग्रेजी पाठ निगम से सीखे गए संख्या एम्बेडिंग पर काफी सुधार कर सकते हैं।', 'ru': 'Встраивание слов в высокоразмерные векторные пространства оказалось ценным во многих приложениях на естественном языке. В этой работе мы исследуем, могут ли аналогично обученные вложения целых чисел захватывать концепции, которые полезны для математических приложений. Мы исследуем целочисленные вложения для математических знаний, применяем их к набору задач численного рассуждения и показываем, что, изучая представления из данных математической последовательности, мы можем существенно улучшить числовые вложения, изученные из английских текстовых корпусов.', 'ga': 'Bhí sé thar a bheith luachmhar focail a leabú i spásanna veicteora ardtoiseacha i go leor feidhmeanna teanga nádúrtha. San obair seo, déanaimid imscrúdú an féidir le leabú slánuimhreacha atá oilte ar an gcaoi chéanna coincheapa a ghlacadh atá úsáideach d’fheidhmeanna matamaitice. Scrúdaímid na leabuithe slánuimhreacha don eolas matamaitice, cuirimid i bhfeidhm iad ar thascanna réasúnaíochta uimhriúla, agus taispeánann muid gur féidir linn feabhas suntasach a chur ar an leabú uimhreach a foghlaimíodh ó chorpora téacs Béarla trí na huiríll a fhoghlaim ó shonraí seicheamh matamaitice.', 'hu': 'A szavak nagy dimenziójú vektorterekbe való beágyazása sok természetes nyelvi alkalmazásban értékesnek bizonyult. Ebben a munkában azt vizsgáljuk, hogy az egész számok hasonlóan képzett beágyazásai képesek-e olyan fogalmakat rögzíteni, amelyek hasznosak a matematikai alkalmazásokhoz. Az egész számok beágyazását matematikai ismeretekre vizsgáljuk, alkalmazzuk azokat numerikus érvelési feladatokra, és megmutatjuk, hogy a reprezentációk matematikai szekvenciaadatokból történő tanulásával jelentősen javulhatunk az angol szövegkorpusokból tanult számok beágyazásával szemben.', 'el': 'Η ενσωμάτωση λέξεων σε υψηλής διάστασης διανυσματικούς χώρους έχει αποδειχθεί πολύτιμη σε πολλές εφαρμογές φυσικής γλώσσας. Σε αυτή την εργασία, διερευνούμε αν οι παρόμοια εκπαιδευμένες ενσωματώσεις ακέραιων αριθμών μπορούν να συλλάβουν έννοιες που είναι χρήσιμες για μαθηματικές εφαρμογές. Εξετάζουμε τις ενσωματώσεις ακέραιων αριθμών για μαθηματική γνώση, τις εφαρμόζουμε σε ένα σύνολο εργασιών αριθμητικής συλλογιστικής, και δείχνουμε ότι μαθαίνοντας τις αναπαραστάσεις από δεδομένα μαθηματικής ακολουθίας, μπορούμε να βελτιώσουμε σημαντικά έναντι των ενσωματώσεων αριθμών που μαθαίνουμε από αγγλικά σώματα κειμένου.', 'it': 'Incorporare parole in spazi vettoriali ad alta dimensione si è dimostrato utile in molte applicazioni di linguaggio naturale. In questo lavoro, esaminiamo se incorporazioni di numeri interi con formazione simile possono catturare concetti utili per applicazioni matematiche. Analizziamo le incorporazioni di numeri interi alla ricerca di conoscenze matematiche, le applichiamo ad una serie di compiti di ragionamento numerico e mostriamo che imparando le rappresentazioni dai dati di sequenza matematica, possiamo migliorare notevolmente rispetto alle incorporazioni di numeri apprese dai corpora di testo inglese.', 'lt': 'Įtraukti žodžius į didelės dimensijos vektorių erdves buvo vertinga daugelyje gamtinių kalbų taikomųjų programų. Šiame darbe tiriame, ar panašiai apmokyti sveikų skaičių įdėjimai gali apimti sąvokas, kurios yra naudingos matematinėms programoms. Mes ištiriame visą skaičių įdėjimus matematikos žinioms, taikome juos tam tikroms skaitmeninio pagrįstumo užduotims, ir parodome, kad mokydami reprezentacijas iš matematikos sekos duomenų, mes galime gerokai pagerinti daugiau nei skaičių įdėjimus, išmoktus iš anglų teksto korporas.', 'ka': 'Name ამ სამუშაოში, ჩვენ განსხვავებთ თუ არა განსხვავებული სამუშაო რიცხვების კონფექტები, რომლებიც მათემატიკური პროგრამებისთვის გამოყენებელია. ჩვენ მათემატიკური ცნობილებისთვის უფრო მნიშვნელოვანი ინტერნეტიკური პარამეტრებისთვის გავაკეთებთ, და ჩვენ გამოჩვენებთ, რომ მათემატიკური წერტილების მონაცემებისთვის გავისწავლით, ჩვენ შეგვიძლია გავაკ', 'ms': 'Membentuk perkataan dalam ruang vektor dimensi tinggi telah terbukti bernilai dalam banyak aplikasi bahasa alam. Dalam kerja ini, kita menyelidiki sama ada penyambungan integer yang dilatih sama boleh menangkap konsep yang berguna untuk aplikasi matematik. We probe the integer embeddings for mathematical knowledge, apply them to a set of numerical reasoning tasks, and show that by learning the representations from mathematical sequence data, we can substantially improve over number embeddings learned from English text corpora.', 'ml': 'കൂടുതല്\u200d മാന്യമായ വെക്ടര്\u200d സ്പെയിലുകളില്\u200d ഉള്\u200dപെടുത്തുന്ന വാക്കുകള്\u200d പലതും സ്വാഭാവികമായ ഭാഷ പ്രയോഗങ്ങളില In this work, we investigate whether similarly-trained embeddings of integers can capture concepts that are useful for mathematical applications.  ഗണിത ജ്ഞാനത്തിന്റെ മുഴുവന്\u200d പ്രവേശിപ്പിക്കുന്നത് നമ്മള്\u200d തെളിവാക്കുന്നു. അത് ഒരു സംഖ്യകങ്ങളുടെ ജോലികളില്\u200d പ്രയോഗിക്കുക. ഗണിതിക്കല്\u200d വിവരങ്ങളില്\u200d നിന്നുള്ള പ്', 'mk': 'Вклучувањето на зборови во високодимензионалните векторни простори се покажа вредно во многу природни јазички апликации. Во оваа работа, истражуваме дали слично обучени вложувања на цели броеви можат да фатат концепти кои се корисни за математичките апликации. Ги истражуваме целосните внатрешни броеви за математичко знаење, ги применуваме на неколку броеви задачи за размислување, и покажуваме дека со научување на претставувањата од математичките податоци за секвенца, можеме значително да ги подобриме преку броевите внатрешни научени од англискиот текст корпора.', 'mt': 'L-inkorporazzjoni ta’ kliem fi spazji ta’ vetturi b’dimensjoni għolja wriet li hija ta’ valur f’ħafna applikazzjonijiet lingwistiċi naturali. F’dan ix-xogħol, ninvestigaw jekk inkorporazzjonijiet imħarrġa b’mod simili ta’ numri sħaħ jistgħux jaqbdu kunċetti li huma utli għall-applikazzjonijiet matematiċi. Aħna nistudjaw l-inkorporazzjonijiet tal-għadd sħiħ għall-għarfien matematiku, napplikawhom għal sett ta’ kompiti ta’ raġunament numeriku, u nuru li billi nitgħallmu r-rappreżentazzjonijiet mid-dejta tas-sekwenza matematika, nistgħu ntejbu sostanzjalment fuq l-inkorporazzjonijiet tal-għadd imgħallmu minn korpra tat-test Ingliż.', 'mn': 'Өндөр хэмжээст вектор орон зайд үгсийг оруулах нь олон байгалийн хэл хэрэглээнд үнэ цэнэтэй байдаг. Энэ ажлын хувьд бид математикийн хэрэглээнд хэрэглэгддэг ойлголтыг тодорхойлох эсэхийг судалж байна. Бид математикийн мэдлэгтэй бүхэл тоонуудыг судалж, тоон утгын даалгавар дээр ашиглаж, математикийн дарааллын өгөгдлийн зураг суралцаж, Англи хэлний текст корпорас сурсан тоонуудыг ихэвчлэн сайжруулж чадна.', 'no': 'Name I denne arbeida undersøker vi om tilsvarande innbygging av heiltal kan ta opp konseptar som er nyttig for matematiske program. Vi prøver heiltal innbygging for matematiske kunnskap, bruker dei til eit sett av numeriske rasjonsbehandlingar, og viser at ved å lære representasjonane frå matematiske sekvensdata, kan vi forbetra over tallinnbygging lært frå engelsk tekstkorpora.', 'pl': 'Wkładanie słów w wysokowymiarowych przestrzeniach wektorowych okazało się cenne w wielu aplikacjach językowych naturalnych. W niniejszej pracy badamy, czy podobnie przeszkolone osadzenia liczb całkowitych mogą uchwycić koncepcje przydatne w zastosowaniach matematycznych. Badamy osadzenia liczb całkowitych pod kątem wiedzy matematycznej, stosujemy je do zestawu zadań rozumowania numerycznego i pokazujemy, że ucząc się reprezentacji z matematycznych danych sekwencji, możemy znacznie poprawić nad osadzeniami liczb nauczonymi z angielskich korpusów tekstowych.', 'sr': 'Uklapanje reèi u visokim vektorskim prostorijama pokazalo je vrijednost u mnogim prirodnim jezičkim aplikacijama. U ovom poslu istražujemo da li slièno obučeni integraciji mogu uhvatiti koncept koji su korisni za matematičke aplikacije. Provjeravamo integralne integracije za matematičko znanje, primjenjujemo ih na skup brojnih razumnih zadataka, i pokažemo da, naučići predstave iz matematičkih podataka o sekvenciji, možemo značajno poboljšati iznad brojnih uključenih brojeva iz engleskog teksta korporacije.', 'so': 'Hadal ku soo deganaanshada goobaha wadooyinka sare waxaa lagu caddeeyey mid qiimo ah codsiyada afka kala duduwan. Shaqadaas waxaynu baaraynaa in wadamada la tababaray ay qabsan karaan fikrada ay faa’iido u leeyihiin codsiga xisaabta. Waxaynu sameynaa kooxaha aqoonta xisaabta, waxaynu ku codsanaynaa shaqooyin badan oo sabab ah, waxaana tusaynaa in marka lagu barto noocyada kooxaha xisaabta, waxaynu si weyn ugu hormarin karnaa koritaanka lambarka laga barto shirkadda qoraalka Ingiriiska.', 'ro': 'Încorporarea cuvintelor în spații vectoriale de înaltă dimensiune s-a dovedit valoroasă în multe aplicații lingvistice naturale. În această lucrare, investigăm dacă încorporările de numere întregi instruite similar pot capta concepte care sunt utile pentru aplicații matematice. Sondăm încorporările numerelor întregi pentru cunoștințe matematice, le aplicăm la un set de sarcini de raționament numeric și arătăm că prin învățarea reprezentărilor din datele secvențelor matematice, putem îmbunătăți substanțial față de încorporările numerelor învățate din corpurile text engleze.', 'sv': 'Att bädda in ord i högdimensionella vektorutrymmen har visat sig vara värdefullt i många naturliga språkapplikationer. I detta arbete undersöker vi om liknande tränade inbäddningar av heltal kan fånga begrepp som är användbara för matematiska tillämpningar. Vi undersöker heltalsinbäddningarna för matematisk kunskap, tillämpar dem på en uppsättning numeriska resonemangsuppgifter, och visar att genom att lära oss representationerna från matematiska sekvensdata, kan vi avsevärt förbättra över antal inbäddningar som lärts från engelska textkorpor.', 'si': 'Name මේ වැඩේ අපි පරීක්ෂණය කරනවා මුළු සංචාරකයේ සාමාන්\u200dය ප්\u200dරශ්නයක් තියෙන්න පුළුවන් තියෙන්නේ නැද්ද කියලා. අපි ගාණිතික දන්නවට පූර්ණ අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක', 'ta': 'உயர்நிலையான வெக்டார் இடைவெளிகளில் உள்ளிடும் வார்த்தைகள் பல இயல்பான மொழி பயன்பாடுகளில் மதிப்பிடப்பட்டது. இந்த வேலையில், ஒருங்கிணைக்கப்பட்ட பயிற்சியான உட்பொதிகளை பிடிக்க முடியுமா என்று நாம் சோதிக்கிறோம். கணித பயன்பாடுகளுக கணித அறிவின் முழுமையான பொருள்களை நாம் கணித்துப் பொருளாக்குகிறோம், அவற்றை செயல்படுத்துகிறோம் பல எண் காரணங்கள் செயல்களுக்கு, கணித வரிசை தகவலிலிருந்து பிரதிநிதிகளை கற', 'ur': 'Name ہم اس کام میں تحقیق کرتے ہیں کہ کیا ایک طرح تدریس کی تمام تعلیم کے مطابق مطابق مطابق مطابق مطابق ریاضیات کے لئے فائدہ اٹھائے جاتے ہیں۔ ہم ریاضیات علم کے لئے تمام تعداد انڈینگ کو امتحان کرتے ہیں، ان کو ایک مجموعہ مفصل کرنے کے کام پر لازم کرتے ہیں، اور دکھاتے ہیں کہ ریاضیات کے کنارے ڈیٹے سے نمائش سکھاتے ہیں، ہم انگلیسی ٹیکس کورپور سے سکھائے ہوئے نقش انڈینگ پر زیادہ بہتر کر سک', 'kk': 'Өлшемі жоғары вектор бос орындарында сөздерді ендіру көптеген табиғи тіл қолданбаларында мәні көрсетілді. Бұл жұмыс ішінде біз математикалық қолданбалар үшін пайдалы концепцияларды сәйкес оқылған бүтін топтардың ендірілген ендірілгенін зерттейміз. Біз математикалық білім үшін бүтін сан ендіруді тексереміз, оларды санды түсіндіру тапсырмаларына қолданып, математикалық реттеу деректерінің түсіндіруді оқып, ағылшын мәтін корпорасынан үйренілген сандар ендірімінен көп жақсы', 'uz': "Name Bu ishda, biz bir xil o'rganilgan birinchi birinchi birinchi narsalarni o'rganib, matematika dasturlariga foydalanadigan g'oyalarni qabul qila olamiz. Biz matematika taʼminotiga birinchi narsalarni tasavvur qilamiz, ularni bir necha sabablar vazifalarga qo'llab beramiz va matematika tarkibini o'rganish orqali biz ingliz matn kompaniyasidan o'rganishni o'rganishda ko'rsatdik.", 'vi': 'Nhúng chữ vào các không gian vector lớn đã được thành giá trị trong nhiều ứng dụng ngôn ngữ tự nhiên. Trong công trình này, chúng tôi điều tra liệu những sự nhúng vào vào những số nguyên có thể thu thập các khái niệm hữu dụng cho các ứng dụng toán học. Chúng tôi thăm dò sự nhúng vào to àn bộ các kiến thức toán học, áp dụng chúng vào các công việc lập trình số, và cho thấy bằng cách học các biểu hiện từ các dữ liệu dãy toán học, chúng tôi có thể cải thiện đáng kể về sự nhúng số học từ cơ thể văn bản Anh.', 'bg': 'Вградването на думи във високомерни векторни пространства се оказа ценно в много приложения на естествения език. В тази работа изследваме дали подобно обучените вграждания на цели числа могат да улавят концепции, които са полезни за математически приложения. Проучваме вгражданията на цели числа за математически знания, прилагаме ги към набор от задачи по числено разсъждаване и показваме, че чрез изучаване на представянето от данни от математически последователности, можем значително да подобрим вгражданията на числа, научени от английски текстови корпуси.', 'da': 'Indlejring af ord i højdimensionelle vektorrum har vist sig værdifuld i mange naturlige sprogapplikationer. I dette arbejde undersøger vi, om lignende trænede integreringer af heltal kan fange begreber, der er nyttige til matematiske applikationer. Vi undersøger heltalsindlejringer for matematisk viden, anvender dem til et sæt numeriske ræsonnement opgaver, og viser, at ved at lære repræsentationerne fra matematiske sekvensdata, kan vi betydeligt forbedre over tal indlejringer lært fra engelske tekstkorpora.', 'nl': 'Het inbedden van woorden in hoogdimensionale vectorruimten is waardevol gebleken in veel toepassingen in natuurlijke talen. In dit werk onderzoeken we of soortgelijk getrainde inbeddingen van integers concepten kunnen vastleggen die nuttig zijn voor wiskundige toepassingen. We onderzoeken de integer embeddings voor wiskundige kennis, passen ze toe op een reeks numerieke redeneringstaken, en laten zien dat door het leren van de representaties van wiskundige sequentiegegevens, we substantieel kunnen verbeteren ten opzichte van getalembeddingen geleerd uit Engelse tekstcorpora.', 'hr': 'Uklapanje riječi u visokodimenzionalnim vektorskim prostorima pokazalo je vrijednost u mnogim prirodnim jezičkim aplikacijama. U ovom poslu istražujemo da li slično obučeni integraciji mogu uhvatiti koncept koji su korisni za matematičke primjene. Provjeravamo integralne integracije za matematičko znanje, primjenjujemo ih na skup brojnih razumnih zadataka, i pokažemo da učeći predstave iz podataka matematičke sekvence, možemo značajno poboljšati iznad brojnih integracija učenih iz engleskog tekstnog tijela.', 'de': 'Die Einbettung von Wörtern in hochdimensionale Vektorräume hat sich in vielen natürlichen Sprachanwendungen bewährt. In dieser Arbeit untersuchen wir, ob ähnlich trainierte Einbettungen von Ganzzahlen Konzepte erfassen können, die für mathematische Anwendungen nützlich sind. Wir untersuchen die integer Einbettungen auf mathematisches Wissen, wenden sie auf eine Reihe numerischer Argumentationsaufgaben an und zeigen, dass wir durch das Erlernen der Repräsentationen aus mathematischen Sequenzdaten die Einbettungen von Zahlen, die aus englischen Textkorpora gelernt wurden, wesentlich verbessern können.', 'ko': '고차원 벡터 공간에 단어를 삽입하는 것은 많은 자연 언어 응용에서 가치가 있다는 것이 증명되었다.이 작업에서 우리는 유사한 훈련을 거친 정수 삽입이 수학 응용에 유용한 개념을 포착할 수 있는지를 연구했다.우리는 수학 지식의 정수 삽입을 연구하고 이를 한 그룹의 디지털 추리 임무에 응용한 결과 수학 서열 데이터의 표시를 학습함으로써 영어 텍스트 자료 라이브러리에서 배운 숫자 삽입을 현저하게 개선할 수 있음을 나타냈다.', 'sw': 'maneno yanayoingia katika maeneo ya ukubwa ya vector imethibitisha thamani katika matumizi mengi ya lugha za asili. Katika kazi hii, tunachunguza kama maendeleo ya jumuiya yanayoweza kupata dhana ambazo zinafaa kwa matumizi ya hisabati. Tunawajaribu maendeleo ya ujuzi wa hisabati, tumia kazi kadhaa zinazoelezea, na kuonyesha kwamba kwa kujifunza maoni ya taarifa za hisabati, tunaweza kuboresha kwa kiasi kikubwa zaidi ya jumbe zilizojifunza kutoka kwenye kampuni ya ujumbe wa Kiingereza.', 'tr': 'Beýik-ölçekli vektör seleňlerinde sözler girişdirilýär Bu işde, biz matematiksel uygulamalar üçin ulanyp bilýän düşünjeleri meňzeş-şekilde eğlenen integralaryň düzümlerini çykaryp bilýändigini soruşýarys. Biz matematik bilgileri üçin bütin sanlary barlaýarys, olary sayyp düşünüp gören zadlaryň bir toparyna uygulaýarys we muny matematik sequence verilerinden üýtgewleri öwrenip bileris, iňlisiň tekst korporatyndan öwrenen sanlaryň üstünde gowurap bileris.', 'af': "Name In hierdie werk, ons ondersoek of gelyk-onderwerpende inbêding van hele getalle kan aanvang konsepte wat nuttig is vir matematiese toepassings. Ons probeer die hele getal inbêdings vir matematiese kennis, toewend hulle na 'n stel getal redekende taak, en wys dat deur die voorstellings van matematiese volgorde data te leer, ons kan substantieel verbeter oor getal inbêdings wat geleer word van Engels teks korpora.", 'fa': 'جمع کردن کلمات در فضای vektor بالا در بسیاری از کاربردهای زبان طبیعی ثابت کرده است. در این کار، ما تحقیق می\u200cکنیم که آیا انجمن\u200cسازی\u200cهای کامل به همان\u200cگونه آموزش داده شده\u200cاند می\u200cتوانند مفهوم\u200cهای مفید برای کاربردهای ریاضی را بگیرند. ما تأثیر عمومی را برای دانش ریاضی امتحان می کنیم، آنها را به یک مجموعه از کارهای منطقی شماره انجام می دهیم، و نشان می دهیم که با یاد گرفتن نمایش\u200cهای داده\u200cهای ریاضی، ما می\u200cتوانیم زیادی بیشتر از جمله\u200cهای تعدادی از شرکت متن انگلیسی یاد گرفته باشیم.', 'hy': 'Բառերի ներգրավումը բարձր չափերի վեկտորների տարածքներում պարզվեց արժեքավոր շատ բնական լեզվի ծրագրերում: Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք, արդյոք նույնպես վարժեցված ամբողջ թվերի ներդրումները կարող են ընդունել գաղափարներ, որոնք օգտակար են մաթեմատիկական ծրագրերի համար: Մենք ուսումնասիրում ենք մաթեմատիկական գիտելիքների ամբողջ բաղադրությունը, կիրառում ենք դրանք թվային մտածողության խնդիրների համար և ցույց ենք տալիս, որ մաթեմատիկական հաջորդականության տվյալների ներկայացումները սովորելով, մենք կարող ենք նշանակալի բարելավել անգլերեն տեքստի կոպորատից սովորված թվա', 'am': 'በአፍሪካዊ ቋንቋ ፕሮግራሞች ውስጥ ያሉ ቃላትን በመጠቀም አቀማመጥ፡፡ በዚህ ስራ፣ በተመሳሳይ የተጠቃሚ የኢንተርኔት አካባቢዎች ለmathematical ፕሮግራሞች የሚጠቅሙትን አእምሮዎች ማግኘት ይችላልን፡፡ የmathematical እውቀት አካባቢዎችን እናሳውቃለን፣ ለብዙ አካባቢ አካሄድ ስራዎችን እናስቀምጣቸዋለን፤ ከmathematical sequence data በመማር እናሳውቃለን፡፡', 'az': 'Yüksek ölçülü vektor boşluqlarında sözləri içərilən təbiətli dil proqramlarında qiymətli göstərildi. Bu işdə, biz matematiksel uyğulamalar üçün faydalı olduğu fikirləri hesablayırıq. Biz matematiksel bilgi üçün bütün sayı inşallarını sınayırıq, onları sayı dəyişiklik işlərə uygulayıq, və göstəririk ki, matematiksel seçmə məlumatlarından təsirlərini öyrənərək, İngiliz məlumatlarından öyrənmiş sayı inşallarından daha çox yaxşılaşabilirik.', 'id': 'Membentuk kata-kata dalam ruang vektor dimensi tinggi telah terbukti berharga dalam banyak aplikasi bahasa alam. Dalam pekerjaan ini, kami menyelidiki apakah penerbangan integer yang terlatih sama dapat menangkap konsep yang berguna untuk aplikasi matematika. Kami memeriksa integer embedding untuk pengetahuan matematika, menerapkannya untuk set tugas pemikiran numerik, dan menunjukkan bahwa dengan mempelajari represensi dari data urutan matematika, kita dapat meningkatkan secara konsideratif lebih dari number embedding belajar dari korpora teks Inggris.', 'bn': 'বেশ কয়েকটি প্রাকৃতিক ভাষার অ্যাপ্লিকেশনে বিভিন্ন ভেক্টরের স্থানে বিভিন্ন শব্দ প্রমাণ করেছে। এই কাজে আমরা অনুসন্ধান করি যে একই ধরনের প্রশিক্ষিত প্রশিক্ষিত ইউনিটের বিভিন্ন প্রতিযোগিতায় যে ধারণা গ্রহণ করতে পারে গণতান্তিক অ্ আমরা গণতান্ত্রিক জ্ঞানের প্রতিষ্ঠান পরীক্ষা করি, সেগুলোকে সংখ্যাত সংখ্যাগরিক কাজে প্রয়োগ করি, এবং দেখাচ্ছি যে গণতান্ত্রিক সেকেন্ডার থেকে প্রতিনিধিত্ব শিখতে প', 'bs': 'Uklapanje riječi u visokodimenzionalnim vektorskim prostorijama pokazalo je vrijednost u mnogim prirodnim aplikacijama jezika. U ovom poslu istražujemo da li slično obučeni integraciji mogu uhvatiti koncept koji su korisni za matematičke aplikacije. Provjeravamo integralne integracije za matematičko znanje, primjenjujemo ih na skup brojnih razumnih zadataka, i pokažemo da učeći predstave iz podataka matematičke sekvence, možemo značajno poboljšati brojne integracije naučene iz engleskog teksta korporacije.', 'sq': 'Embedding words in high-dimensional vector spaces has proven valuable in many natural language applications.  Në këtë punë, ne hetojmë nëse përfshirjet e trajnuara në mënyrë të ngjashme të numrave të tëra mund të kapin koncepte që janë të dobishme për aplikimet matematike. Ne vëzhgojmë përfshirjet e tëra të njohurive matematike, i aplikojmë a to në një sërë detyrash të arsyetimit numëror, dhe tregojmë se duke mësuar përfaqësimet nga të dhënat e sekuencës matematike, ne mund të përmirësojmë thelbësisht përmes përfshirjeve të numrave të mësuara nga korpra teksti angleze.', 'fi': 'Sanan upottaminen suuriulotteisiin vektoriavaruuksiin on osoittautunut arvokkaaksi monissa luonnonkielisovelluksissa. Tässä työssä tutkitaan, voidaanko vastaavalla tavalla koulutetut kokonaislukujen upotukset tallentaa matemaattisissa sovelluksissa hyödyllisiä käsitteitä. Tutkimme kokonaislukuupotuksia matemaattista tietoa varten, sovellamme niitä joukko numeerisia päättelytehtäviä, ja osoitamme, että oppimalla representaatioita matemaattisista sekvenssiteistä, voimme merkittävästi parantaa yli lukuupotuksia, jotka on opittu englanninkielisistä tekstikorpusista.', 'ca': "L'integració de paraules en espais vectoris d'alta dimensió s'ha demostrat útil en moltes aplicacions de llenguatge natural. In this work, we investigate whether similarly-trained embeddings of integers can capture concepts that are useful for mathematical applications.  Investiguem els incorporacions integers per al coneixement matemàtic, les aplicam a un conjunt de tasques de raonament numèric, i demostram que aprenent les representacions a partir de dades de seqüència matemàtica, podem millorar substancialment amb els incorporacions de nombres aprenguts a partir de corpora de text anglesa.", 'cs': 'Vložení slov do vysoce rozměrných vektorových prostorů se osvědčilo v mnoha aplikacích přirozeného jazyka. V této práci zkoumáme, zda podobně trénované vložení celých čísel dokáže zachytit koncepty, které jsou užitečné pro matematické aplikace. Zkoumáme celočíselné vložení pro matematické znalosti, aplikujeme je na sadu úloh numerického uvažování a ukážeme, že učením reprezentací z matematických sekvenčních dat můžeme podstatně zlepšit oproti vložení čísel naučeným z anglických textových korpusů.', 'et': 'Sõnade manustamine kõrgemõõtmelistesse vektoriruumidesse on osutunud väärtuslikuks paljudes looduskeeltes rakendustes. Selles töös uurime, kas sarnaselt koolitatud täisarvude manustamine võib hõlmata kontseptsioone, mis on kasulikud matemaatiliste rakenduste jaoks. Me uurime täisarvude manustamist matemaatiliste teadmiste jaoks, rakendame neid arvuliste arutlusülesannete kogumile ja näitame, et õppides esitusi matemaatilise jada andmetest, saame oluliselt parandada üle arvu manustamine õppinud inglise tekstikorpused.', 'jv': 'politenessoffpolite"), and when there is a change ("assertive Nang barêng-barêng iki, kéné ujês mengko baléng lan gambaran gambaran karo akeh lan barang-rambarang nggawe barang nggambar barang nggawe barang nggambar tarjamahan kanggo aplikasi matamatik. Awak dhéwé éntuk sistem sing gawe nggawe alam kuwi nggawe matatem, iso nggawe yen manut karo nggawe dolanan sing beraksi yang cukup, lan bukane kuwi nggawe representasi tarjamahan karo data Dinasal sing bakal terus marito, kéné iso nggawe barang langgar sampeyan Dinasal terus kesempatan langgar sampeyan inggilis', 'he': 'ההכניסה של מילים בחלל ווקטורים במימדים גבוהים הוכיחה חשובה בהרבה שימושים טבעיים. בעבודה הזו, אנו חוקרים אם תוספות שלמות מאומנות באופן דומה יכולות לתפוס מושג שימושי ליישומים מתמטיים. אנו חוקרים את המספרים שלמים לידע מתמטי, משתמשים בהם על קבוצה של משימות הגיון מספריות, ולהראות כי על ידי ללמוד את הייצגות ממידע רצף מתמטי, אנחנו יכולים לשפר באופן משמעותי מעל המספרים של המספרים ללמודים מהטקסט גופרה אנגלית.', 'sk': 'Vgradnja besed v visokodimenzionalne vektorske prostore se je izkazala za dragoceno v številnih aplikacijah naravnega jezika. V tem delu raziskujemo, ali podobno usposobljene vdelave celih števil lahko zajamejo koncepte, ki so koristni za matematične aplikacije. Preiskujemo vgradnje celih števil za matematično znanje, jih uporabljamo za nabor nalog numeričnega razmišljanja in pokažemo, da lahko z učenjem reprezentacij iz matematičnih zaporednih podatkov bistveno izboljšamo nad vgradnjo števil iz angleških besedilnih korpusov.', 'ha': '@ info: whatsthis Daga wannan aikin, Munã jarraba ko da aka sanar da shirin cikin shirin integrity masu kamid ko kuma za su iya kãma zato masu da amfani ga shiryoyin hisabati. Tuna sami masu shiga masu iya cikin ilin matabiki, kuma ke amfani da su zuwa wasu aikin masu hankali masu yawa, kuma ke nuna cewa, idan an sanar da masu motsi daga dangiyar matabiki, za mu iya ƙara koda tallin da aka sanar daga makampuni na littafin Ingiriya.', 'bo': 'ཆ་རྐྱེན་ཚད་མཐོ་བར་སྟོང་ནང་ཡི་ཡིག་ཚུལ་ནང་དུ་བཅུག་པ་ལྟར་ནུས་པ་ངོས་འཛིན་ཡོད་པ འོན་ཀྱང་། ང་ཚོས་གྲངས་རིག་གི་ཉེར་སྤྱོད་ལ་སྤྱོད་པའི་ཆོས་ཉིད་དེ་གྲངས་རིག་གི་ནང་དུ་མཐོང་སྒྲིག་ཡོད་མིན་ཡང་ན། We probe the integer embeddings for mathematical knowledge, apply them to a set of numerical reasoning tasks, and show that by learning the representations from mathematical sequence data, we can substantially improve over number embeddings learned from English text corpora.'}
{'en': 'An Investigation of Language Model Interpretability via Sentence Editing', 'ar': 'تحقيق في تفسير نموذج اللغة عن طريق تحرير الجملة', 'pt': 'Uma investigação da interpretabilidade do modelo de linguagem por meio da edição de frases', 'es': 'Una investigación de la interpretabilidad de los modelos lingüísticos mediante la edición', 'fr': "Une étude de l'interprétabilité des modèles linguistiques via l'édition de phrases", 'ru': 'Исследование интерпретируемости языковой модели посредством редактирования предложений', 'ja': '文章編集による言語モデルの解釈可能性の調査', 'hi': 'वाक्य संपादन के माध्यम से भाषा मॉडल Interpretability की एक जांच', 'zh': '因句编次可解释性', 'ga': 'Imscrúdú ar Léirmhíniú na Múnla Teanga trí Eagarthóireacht Pianbhreithe', 'hu': 'A nyelvi modell értelmezhetőségének vizsgálata mondatszerkesztéssel', 'el': 'Διερεύνηση της ερμηνείας του γλωσσικού μοντέλου μέσω επεξεργασίας φράσεων', 'ka': 'სიტყვების რედაქტირების გამოყენებაName', 'it': "Un'indagine sull'interpretabilità del modello linguistico tramite la modifica delle frasi", 'kk': 'Сөзді өңдеу арқылы тіл моделінің интерпретациялығын зерттеу', 'mk': 'Истрага за интерпретабилност на јазичкиот модел преку уредување на реченици', 'lt': 'Kalbos modelio aiškinamumo tyrimas redaguojant sakinius', 'ms': 'Name', 'ml': 'ഭാഷ മോഡല്\u200d വിവരങ്ങള്\u200d എഡിറ്റര്\u200d ചെയ്യുന്നതിലൂടെ ഒരു അന്വേഷണം', 'mt': 'Investigazzjoni tal-Interpretabilità tal-Mudell tal-Lingwi permezz tal-Edizzjoni tas-Sentenzi', 'mn': 'Холбоо загварын утгын шинжилгээ', 'pl': 'Badanie interpretowalności modelu językowego poprzez edycję zdań', 'no': 'Name', 'ro': 'O investigare a interpretabilității modelului lingvistic prin editarea sentințelor', 'sr': 'Istraživanje preglednosti jezičkog modela putem redakcije kazne', 'sv': 'En undersökning av språkmodelltolkning via meningsredigering', 'so': 'Tilmaamaha turjumista nooca luuqada ee ku qoran dhibaatada', 'si': 'Name', 'ta': 'வாக்குறுதி தொகுப்பு வழியாக மொழி மாதிரி மொழியின் மாற்று மொழியின் பொருள் ஆய்வு', 'ur': 'Name', 'uz': 'Name', 'vi': 'Một cuộc điều tra về ngôn ngữ học thông qua Sensence Editing', 'hr': 'Istraživanje razmišljanja o jezičkim modelima putem redakcije kazne', 'da': 'En undersøgelse af sprogmodellens fortolkningsevne via sætningsredigering', 'de': 'Eine Untersuchung der Interpretierbarkeit von Sprachmodellen mittels Satzbearbeitung', 'id': 'Sebuah penyelidikan Interpretabilitas Model Bahasa melalui Penyunting Perkataan', 'bg': 'Изследване на интерпретацията на езиковия модел чрез редактиране на изречения', 'ko': '문장 편집에 기초한 언어 모델 해석성 연구', 'fa': 'Name', 'nl': 'Een onderzoek naar interpreteerbaarheid van taalmodellen via zinsbewerking', 'tr': 'Çaltylyk Editlemesi Aralygy Görkezilişi', 'af': 'Name', 'sq': 'Një hetim i interpretueshmërisë së modelit gjuhësor nëpërmjet editimit të fjalëve', 'hy': 'Լեզվի մոդելի թարգմանելիության հետազոտությունը դատողությունների խմբագրման միջոցով', 'am': 'የቋንቋ ሞዴል መግለጫ', 'az': 'Sözü Düzenlemesi vasitəsilə Dil Modelinin İşleşməsi', 'sw': 'Utafiti wa Utafsiri wa Modeli wa Lugha kupitia Mhariri wa Hukumu', 'bs': 'Istraživanje razmjernosti jezičkog modela putem redakcije kazne', 'cs': 'Vyšetřování interpretovatelnosti jazykového modelu pomocí editace vět', 'et': 'Keelemudeli tõlgendatavuse uurimine lausete redigeerimise kaudu', 'fi': 'Kielimallin tulkinnan tutkimus lausemuokkauksen avulla', 'bn': 'শাস্তি সম্পাদনার মাধ্যমে ভাষার মডেল অনুবাদের তদন্ত', 'ca': "Una investigació de l'interpretabilitat del model de llenguatge a través de l'edició de sentences", 'ha': '@ action', 'he': 'חקירה של התפרצות מודל שפה באמצעות עורך גזרות', 'sk': 'Preiskava tolmačljivosti jezikovnega modela z urejanjem stavkov', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'སྐད་ཡིག་Model Interpretability་ཀྱི་དཔེ་དབྱིབས་ཞིབ་བཟོ་བཅོས་དང་བསྟུན་ནས་དབྱེ་རིགས'}
{'en': 'Pre-trained language models (PLMs) like BERT are being used for almost all language-related tasks, but interpreting their behavior still remains a significant challenge and many important questions remain largely unanswered. In this work, we re-purpose a sentence editing dataset, where faithful high-quality human rationales can be automatically extracted and compared with extracted model rationales, as a new testbed for interpretability. This enables us to conduct a systematic investigation on an array of questions regarding PLMs’ interpretability, including the role of pre-training procedure, comparison of rationale extraction methods, and different layers in the PLM. The investigation generates new insights, for example, contrary to the common understanding, we find that attention weights correlate well with human rationales and work better than gradient-based saliency in extracting model rationales. Both the dataset and code will be released to facilitate future interpretability research.', 'es': 'Los modelos lingüísticos preentrenados (PLM), como BERT, se utilizan para casi todas las tareas relacionadas con el lenguaje, pero la interpretación de su comportamiento sigue siendo un desafío importante y muchas preguntas importantes permanecen en gran medida sin respuesta. En este trabajo, reutilizamos un conjunto de datos de edición de oraciones, donde los fundamentos humanos fieles de alta calidad se pueden extraer automáticamente y comparar con los fundamentos extraídos del modelo, como un nuevo banco de pruebas para la interpretabilidad. Esto nos permite llevar a cabo una investigación sistemática sobre una serie de cuestiones relacionadas con la interpretabilidad de los PLM, incluida la función del procedimiento de preentrenamiento, la comparación de los métodos de extracción de fundamentos y las diferentes capas del PLM. La investigación genera nuevos conocimientos, por ejemplo, contrariamente al entendimiento común, encontramos que los pesos de atención se correlacionan bien con los fundamentos humanos y funcionan mejor que la prominencia basada en gradientes para extraer los fundamentos del modelo. Tanto el conjunto de datos como el código se publicarán para facilitar la investigación de interpretabilidad futura.', 'fr': "Les modèles linguistiques préformés (PLM) tels que BERT sont utilisés pour presque toutes les tâches liées à la langue, mais l'interprétation de leur comportement reste un défi de taille et de nombreuses questions importantes restent en grande partie sans réponse. Dans ce travail, nous réutilisons un jeu de données d'édition de phrases, dans lequel des justifications humaines fidèles de haute qualité peuvent être automatiquement extraites et comparées aux justifications de modèles extraites, en tant que nouveau banc d'essai pour l'interprétabilité. Cela nous permet de mener une enquête systématique sur un éventail de questions concernant l'interprétabilité des PLM, y compris le rôle de la procédure de pré-formation, la comparaison des méthodes d'extraction des justifications et les différentes couches du PLM. L'enquête génère de nouvelles informations. Par exemple, contrairement à ce que l'on croit généralement, nous constatons que les pondérations de l'attention sont bien corrélées aux justifications humaines et fonctionnent mieux que la prépondérance basée sur le gradient dans l'extraction des justifications du modèle. L'ensemble de données et le code seront publiés afin de faciliter les futures recherches sur l'interprétabilité.", 'pt': 'Modelos de linguagem pré-treinados (PLMs) como o BERT estão sendo usados para quase todas as tarefas relacionadas à linguagem, mas interpretar seu comportamento ainda continua sendo um desafio significativo e muitas questões importantes permanecem em grande parte sem resposta. Neste trabalho, redefinimos um conjunto de dados de edição de sentenças, onde os raciocínios humanos fiéis de alta qualidade podem ser extraídos automaticamente e comparados com os raciocínios do modelo extraídos, como um novo banco de testes para interpretabilidade. Isso nos permite realizar uma investigação sistemática sobre uma série de questões relacionadas à interpretabilidade dos PLMs, incluindo o papel do procedimento de pré-treinamento, comparação de métodos de extração de lógica e diferentes camadas no PLM. A investigação gera novos insights, por exemplo, ao contrário do entendimento comum, descobrimos que os pesos de atenção se correlacionam bem com as razões humanas e funcionam melhor do que a saliência baseada em gradiente na extração de razões do modelo. Tanto o conjunto de dados quanto o código serão divulgados para facilitar futuras pesquisas de interpretabilidade.', 'ar': 'يتم استخدام نماذج اللغة المدربة مسبقًا (PLMs) مثل BERT في جميع المهام المتعلقة باللغة تقريبًا ، لكن تفسير سلوكهم لا يزال يمثل تحديًا كبيرًا والعديد من الأسئلة المهمة تظل بلا إجابة إلى حد كبير. في هذا العمل ، نعيد الغرض من مجموعة بيانات تحرير الجملة ، حيث يمكن استخلاص المبررات البشرية المؤمنة عالية الجودة تلقائيًا ومقارنتها مع المبررات النموذجية المستخرجة ، كقاعدة اختبار جديدة لقابلية التفسير. يتيح لنا ذلك إجراء تحقيق منهجي حول مجموعة من الأسئلة المتعلقة بقابلية تفسير PLM ، بما في ذلك دور إجراء ما قبل التدريب ، ومقارنة طرق الاستخراج المنطقي ، والطبقات المختلفة في PLM. يولد التحقيق رؤى جديدة ، على سبيل المثال ، على عكس الفهم الشائع ، نجد أن أوزان الانتباه ترتبط جيدًا بالمنطق البشري وتعمل بشكل أفضل من البراعة القائمة على التدرج في استخراج مبررات النموذج. سيتم إصدار كل من مجموعة البيانات والرمز لتسهيل أبحاث التفسير المستقبلية.', 'ja': 'BERTのような事前にトレーニングされた言語モデル（ PLM ）は、ほぼすべての言語関連のタスクに使用されていますが、それらの行動を解釈することは依然として大きな課題であり、多くの重要な質問はほとんど答えられません。 この研究では、解釈可能性の新しいテストベースとして、忠実な高品質の人間の根拠を自動的に抽出し、抽出されたモデルの根拠と比較できる文章編集データセットを再利用します。 これにより、事前トレーニング手順の役割、根拠抽出方法の比較、およびPLMのさまざまなレイヤーを含む、PLMの解釈可能性に関する一連の質問を体系的に調査することができます。 この調査は、例えば、共通の理解に反して、注意の重みが人間の理論的根拠と良好に相関し、モデルの理論的根拠を抽出する際の勾配ベースの顕著性よりも優れていることを示します。 データセットとコードは、将来の解釈可能性研究を容易にするためにリリースされます。', 'zh': '如BERT之预训言语模样(PLM)几于凡语,而说之行犹大挑战,其要犹未解也。 于此之中,重用一句编辑数集,其可自取忠实者高质量人类基本原理,与提取基本原理较之,以为可解释性新试平台。 此可以系统调查PLM可解释性之一系,预培训程序之用,基本原理取法之较,与PLM之不同者也。 求新意者,反普解也,见权重与人基本原理相关,而取形于梯度者显著性。 数集代码将发,以趣来者可解释性。', 'hi': 'BERT जैसे पूर्व-प्रशिक्षित भाषा मॉडल (पीएलएम) का उपयोग लगभग सभी भाषा-संबंधित कार्यों के लिए किया जा रहा है, लेकिन उनके व्यवहार की व्याख्या करना अभी भी एक महत्वपूर्ण चुनौती बनी हुई है और कई महत्वपूर्ण प्रश्न काफी हद तक अनुत्तरित हैं। इस काम में, हम एक वाक्य संपादन डेटासेट को फिर से उद्देश्य देते हैं, जहां वफादार उच्च गुणवत्ता वाले मानव तर्कों को स्वचालित रूप से निकाला जा सकता है और निकाले गए मॉडल तर्कों के साथ तुलना की जा सकती है, व्याख्यात्मकता के लिए एक नए टेस्टबेड के रूप में। यह हमें पीएलएम की व्याख्याक्षमता के बारे में सवालों की एक सरणी पर एक व्यवस्थित जांच करने में सक्षम बनाता है, जिसमें पूर्व-प्रशिक्षण प्रक्रिया की भूमिका, तर्क निष्कर्षण विधियों की तुलना और पीएलएम में विभिन्न परतें शामिल हैं। जांच नई अंतर्दृष्टि उत्पन्न करती है, उदाहरण के लिए, आम समझ के विपरीत, हम पाते हैं कि ध्यान वजन मानव तर्कों के साथ अच्छी तरह से सहसंबंधित है और मॉडल तर्कों को निकालने में ग्रेडिएंट-आधारित सेलींसी की तुलना में बेहतर काम करता है। डेटासेट और कोड दोनों को भविष्य की व्याख्याता अनुसंधान की सुविधा के लिए जारी किया जाएगा।', 'ru': 'Предварительно обученные языковые модели (PLM), такие как BERT, используются почти для всех языковых задач, но интерпретация их поведения по-прежнему остается серьезной проблемой, и многие важные вопросы остаются в основном без ответа. В этой работе мы перепрофилируем набор данных для редактирования предложений, где верные высококачественные человеческие обоснования могут быть автоматически извлечены и сравнены с извлеченными модельными обоснованиями, в качестве нового испытательного стенда для интерпретируемости. Это позволяет проводить систематическое исследование по целому ряду вопросов, касающихся интерпретируемости PLMS, включая роль процедуры предварительного обучения, сравнение обоснованных методов извлечения и различных слоев в PLM. Исследование генерирует новые идеи, например, вопреки общему пониманию, мы находим, что веса внимания хорошо коррелируют с человеческими обоснованиями и работают лучше, чем соленость на основе градиента при извлечении обоснований модели. Как набор данных, так и код будут выпущены для облегчения будущих исследований по интерпретируемости.', 'ga': 'Tá múnlaí teanga réamhoilte (PLManna) cosúil le BERT á n-úsáid le haghaidh beagnach gach tasc a bhaineann le teanga, ach is dúshlán suntasach fós é a n-iompraíocht a léirmhíniú agus cuid mhór ceisteanna tábhachtacha fós gan freagairt. Sa saothar seo, déanaimid athchuspóireacht ar thacar sonraí eagarthóireachta abairtí, inar féidir réasúnaíocht dhaonna ardcháilíochta dílis a bhaint go huathoibríoch agus a chur i gcomparáid le réasúnaíocht na samhla asbhainte, mar leaba tástála nua le haghaidh inléirmhínithe. Cuireann sé seo ar ár gcumas imscrúdú córasach a dhéanamh ar raon ceisteanna maidir le léirmhíniú PLManna, lena n-áirítear ról an nós imeachta réamh-oiliúna, comparáid idir modhanna eastósctha réasúnaíochta, agus sraitheanna éagsúla sa PLM. Gineann an t-imscrúdú léargais nua, mar shampla, contrártha leis an gcomhthuiscint, feicimid go bhfuil comhghaol maith idir meáchain aird agus réasúnaíocht daonna agus go n-oibríonn siad níos fearr ná an tsábháilteacht atá bunaithe ar ghrádán maidir le réasúnaíocht mhúnla a bhaint amach. Eiseofar an tacar sonraí agus an cód araon chun taighde inléirmhínithe a éascú amach anseo.', 'ka': 'მხოლოდ ყველა ენის შესახებ მოდელებისთვის გამოყენება, როგორც BERT, მაგრამ მათი ქცევის შესახებ მნიშვნელოვანი გამოყენება და ბევრი მნიშვნელოვანი კითხვები უნდა გადასწორება. ამ სამუშაოში ჩვენ განვითარებით მონაცემების რედაქტირება, სადაც მჯგუფი საშუალო ადამიანის რაციონალები შეიძლება ავტომატურად ექსტრაქტირება და შედგენა ექსტრაქტირებული მოდელ ეს გვეძლია გავაკეთოთ სისტემატიკური პარაციონალური ექსტრექციის მეტი და განსხვავებული სიახლეების შესახებ პროცემის პროცემის შესახებ. პასუხი იქნება ახალი შესახებ, მაგალითად, საერთო შესახებ, ჩვენ აღმოჩნეთ, რომ აღმოჩნდება, რომ აღმოჩნდება ადამიანის რაციონალთან და მუშაობა უფრო უფრო კარგად, ვიდრე გრადიენტის დაბა ორივე მონაცემები და კოდის შესაძლებლობად მომავალე ინტერუქტურაციის შესაძლებლობად გახსნა.', 'el': 'Προεκπαιδευμένα γλωσσικά μοντέλα (όπως το BERT) χρησιμοποιούνται για σχεδόν όλες τις γλωσσικές εργασίες, αλλά η ερμηνεία της συμπεριφοράς τους εξακολουθεί να αποτελεί σημαντική πρόκληση και πολλά σημαντικά ερωτήματα παραμένουν σε μεγάλο βαθμό αναπάντητα. Σε αυτή την εργασία, επαναχρησιμοποιούμε ένα σύνολο δεδομένων επεξεργασίας προτάσεων, όπου πιστοί υψηλής ποιότητας ανθρώπινοι λόγοι μπορούν να εξαχθούν αυτόματα και να συγκριθούν με τους εξαγόμενους συλλογισμούς μοντέλων, ως ένα νέο δοκιμαστικό πεδίο ερμηνείας. Αυτό μας δίνει τη δυνατότητα να διεξάγουμε συστηματική έρευνα σε μια σειρά ερωτήσεων σχετικά με την ερμηνεία των ΠΜΣ, συμπεριλαμβανομένου του ρόλου της διαδικασίας προεκπαίδευσης, της σύγκρισης μεθόδων εξαγωγής λογικών και των διαφορετικών στρωμάτων της ΠΜΣ. Η έρευνα παράγει νέες ιδέες, για παράδειγμα, αντίθετα με την κοινή κατανόηση, διαπιστώνουμε ότι τα βάρη προσοχής συσχετίζονται καλά με τις ανθρώπινες αιτιολογίες και λειτουργούν καλύτερα από την ευδαιμονία που βασίζεται στη διαβάθμιση στην εξαγωγή των λογικών μοντέλων. Τόσο το σύνολο δεδομένων όσο και ο κώδικας θα κυκλοφορήσουν για να διευκολύνουν τη μελλοντική έρευνα ερμηνείας.', 'hu': 'Az előképzett nyelvi modelleket (PLM-eket) mint a BERT szinte minden nyelvi feladathoz használják, viselkedésük értelmezése azonban továbbra is jelentős kihívást jelent, és számos fontos kérdés nagyrészt megválaszolatlan marad. Ebben a munkában egy mondatszerkesztő adatkészletet újra célozunk, ahol a hűséges, kiváló minőségű emberi értelmezések automatikusan kivonhatók és összehasonlíthatók a kivont modell értelmezhetőségének új tesztágyaként. Ez lehetővé teszi számunkra, hogy szisztematikus vizsgálatot végezzünk a PLM értelmezhetőségével kapcsolatos számos kérdésben, beleértve a képzés előtti eljárás szerepét, a logikus kitermelési módszerek összehasonlítását és a PLM különböző rétegeit. A vizsgálat új betekintéseket hoz létre, például a közös megértéssel ellentétben úgy találjuk, hogy a figyelem súlya jól korrelál az emberi ésszerűséggel, és jobban működik, mint a gradiens alapú kiemelkedő modellek kivonásában. A jövőbeli értelmezhetőségi kutatás megkönnyítése érdekében mind az adatkészlet, mind a kód kiadásra kerül.', 'it': "Modelli linguistici pre-formati (PLM) come BERT vengono utilizzati per quasi tutte le attività linguistiche, ma interpretare il loro comportamento rimane ancora una sfida significativa e molte domande importanti rimangono in gran parte senza risposta. In questo lavoro, ri-scopo un set di dati di editing di frasi, dove fedeli logiche umane di alta qualità possono essere automaticamente estratte e confrontate con logiche di modello estratte, come un nuovo banco di prova per l'interpretabilità. Questo ci permette di condurre un'indagine sistematica su una serie di questioni relative all'interpretabilità dei PLM, tra cui il ruolo della procedura di pre-formazione, il confronto dei metodi di estrazione razionale e i diversi strati del PLM. L'indagine genera nuove intuizioni, ad esempio, contrariamente alla comune comprensione, troviamo che i pesi dell'attenzione sono ben correlati con le logiche umane e funzionano meglio della salienza basata sul gradiente nell'estrarre le logiche dei modelli. Sia il set di dati che il codice saranno rilasciati per facilitare la futura ricerca sull'interpretabilità.", 'mk': 'Преобучените јазички модели (ПЛМ) како Берт се користат за речиси сите задачи поврзани со јазикот, но интерпретацијата на нивното однесување сé уште останува значителен предизвик и многу важни прашања остануваат во голема мера неодговорени. Во оваа работа, ние повторно употребуваме набор на податоци за уредување на реченици, каде верните висококвалитетни човечки рационали можат автоматски да бидат извадени и споредени со извадени моделни рационали, како нов тест за интерпретабилност. Ова ни овозможува да спроведеме систематска истрага во врска со голем број прашања во врска со интерпретабилноста на ПЛМ, вклучувајќи ја и улогата на процедурата на предобука, споредба на рационалните методи на екстракција и различни слоеви во ПЛМ. Истрагата генерира нови информации, на пример, спротивно на заедничкото разбирање, откриваме дека теговите на вниманието добро се корелираат со човечките рационали и работат подобро од градиентната солидност во извлекувањето на моделните рационали. И наборот на податоци и кодот ќе бидат објавени за олеснување на идното истражување за интерпретабилност.', 'lt': 'Iš anksto parengti kalbos modeliai (PLM), pavyzdžiui, BERT, naudojami beveik visoms su kalba susijusioms užduotims, tačiau jų elgesio aiškinimas tebėra didelis iššūkis ir daugelis svarbių klausimų tebėra iš esmės neatsakytas. Šiame darbe mes persvarstome sakinių redakcijos duomenų rinkinį, kuriame patikimi aukštos kokybės žmogaus racionalai gali būti automatiškai išgaunami ir palyginami su išgautais modelių racionalais, kaip naują išbandytą vertimo žodžiu pagrindą. Tai suteikia mums galimybę sistemingai tirti daugelį klausimų, susijusių su PLM aiškinimu, įskaitant pasirengimo mokymui procedūros vaidmenį, racionalių gavybos metodų palyginimą ir skirtingus PLM sluoksnius. Tyrimas sukuria naujų įžvalgų, pavyzdžiui, priešingai bendram supratimui, mes manome, kad dėmesio svoris gerai koreliuoja su žmogaus racionalais ir veikia geriau nei gradientais pagrįstas druska išgaunant racionalų modelius. Duomenų rinkinys ir kodas bus paskelbti siekiant palengvinti būsimus aiškinamumo tyrimus.', 'kk': 'BERT секілді алдын- ала оқылған тіл үлгілері барлық тілдермен байланысты тапсырмалар үшін қолданылады, бірақ олардың тәртібін толтыру әлі үлкен мәселелер болып тұрады, бірақ көп маңызды сұрақтар Бұл жұмыс ішінде, біз деректер жиынын өңдеу үшін мәліметті қайта мақсаттамыз. Бұл жерде сенім жоғары сапатты адамдардың мақсаттары автоматты түрде тарқатылады және тарқатылатын үлгілер рацион Бұл бізге PLMs толықтығы туралы жүйелік сұрақтарды жұмыс істеуге мүмкіндік береді, алдын- оқыту процедурының рөлі, рационалдық тарқату әдістерін салыстыру және PLM қабаттарының түрлі қабаттар Сіздеу жаңа түсініктерді жасайды, мысалы, жалпы түсініктерге қарсы, біз тәртіпсіздік түсініктердің адамдардың рационализациялары мен градиенттің негізінде тәртіпсіздігінен жақсы жұмыс істейді. Деректер және код екеуі болашақ аудармаларды зерттеу үшін шығарылады.', 'ms': 'Model bahasa terlatih-awal (PLMs) seperti BERT digunakan untuk hampir semua tugas berkaitan dengan bahasa, tetapi menerangkan perilaku mereka masih satu cabaran yang signifikan dan banyak soalan penting tetap kebanyakan tidak dijawab. Dalam kerja ini, kita gunakan semula set data penyuntingan kalimat kalimat yang setia manusia boleh secara automatik diekstrak dan dibandingkan dengan kalimat model yang diekstrak, sebagai tempat ujian baru untuk boleh diterjemahkan. Ini membolehkan kita melakukan penyelidikan sistemik pada sejumlah soalan mengenai interpretabiliti PLMs, termasuk peran prosedur pralatihan, perbandingan kaedah ekstraksi rasional, dan lapisan yang berbeza dalam PLM. Penyelidikan menghasilkan pandangan baru, contohnya, bertentangan dengan pemahaman umum, kita mendapati bahawa berat perhatian berkorelaci dengan rasional manusia dan bekerja lebih baik daripada salinsi berdasarkan gradien dalam mengekstrak rasional model. Kedua-dua set data dan kod akan dilepaskan untuk memudahkan kajian interpretabiliti masa depan.', 'ml': 'മുമ്പ് പരിശീലന ഭാഷ മോഡലുകള്\u200d (പിഎല്\u200dഎസ്) ബെര്\u200dട്ടിയെപ്പോലെ ഉപയോഗിക്കപ്പെടുന്ന എല്ലാ ഭാഷകളോടും ബന്ധപ്പെട്ട ജോലികള്\u200dക്കും ഉപയോഗിക്കുന്നു. പക്ഷ ഈ പ്രവര്\u200dത്തനത്തില്\u200d വാക്ക് ചിട്ടപ്പെടുത്തുന്നതിന്റെ വാക്കുകള്\u200d വീണ്ടും ഉദ്ദേശിക്കുന്നു. വിശ്വസ്തനായ മനുഷ്യരുടെ വിശ്വാസികള്\u200d സ്വയം പുറത്ത പിഎല്\u200dഎംഎസിന്റെ വ്യാഖ്യാനത്തെപ്പറ്റിയുള്ള ഒരു കൂട്ടം ചോദ്യങ്ങളില്\u200d നമുക്ക് സിസ്റ്റമിക്ക് അന്വേഷണം നടത്താന്\u200d സാധിക്കുന്നു. പിഎല്\u200dഎമിലെ വ്യത് അതിന്\u200dറെ അന്വേഷണം പുതിയ കണ്ണുകള്\u200d ഉണ്ടാക്കുന്നു. ഉദാഹരണത്തിന് ഉദാഹരണത്തിനായി, സാധാരണ ബുദ്ധിമുട്ടിന് വിരോധമാണ്, മനുഷ്യരുടെ വിവേകതകളുമായി ശ് ഭാവിയ്ക്കുള്ള വ്യാഖ്യാനം പരിശോധിപ്പിക്കാന്\u200d ഉപയോഗിക്കാന്\u200d ഡാറ്റാസറ്റും കോഡും വിടുന്', 'mt': 'Mudelli lingwistiċi mħarrġa minn qabel (PLMs) bħall-BERT qed jintużaw għal kważi l-kompiti kollha relatati mal-lingwa, iżda l-interpretazzjoni tal-imġiba tagħhom għadha sfida sinifikanti u ħafna mistoqsijiet importanti għadhom fil-biċċa l-kbira mingħajr tweġiba. F’din il-ħidma, a ħna qed nimmiraw mill-ġdid sett ta’ dejta tal-edizzjoni tas-sentenzi, fejn raġunijiet umani ta’ kwalità għolja fedeli jistgħu jiġu awtomatikament estratti u mqabbla ma’ raġunijiet tal-mudell estratti, bħala test ġdid għall-interpretabilità. Dan jippermettilna twettaq investigazzjoni sistematika dwar firxa ta’ mistoqsijiet dwar l-interpretabbiltà tal-PLMs, inkluż ir-rwol tal-proċedura ta’ qabel it-taħriġ, it-tqabbil ta’ metodi ta’ estrazzjoni raġonevoli, u saffi differenti fil-PLM. L-investigazzjoni tiġġenera fehmiet ġodda, pereżempju, għall-kuntrarju tal-fehim komuni, isibu li l-piżijiet tal-attenzjoni jikkorrelataw tajjeb mar-raġunijiet umani u jaħdmu aħjar mis-salinzja bbażata fuq il-gradjenti fl-estrazzjoni tar-raġunijiet tal-mudell. Kemm is-sett tad-dejta kif ukoll il-kodiċi se jiġu rilaxxati biex jiffaċilitaw ir-riċerka futura dwar l-interpretabbiltà.', 'no': 'Førehandsvis språk-modeller (PLMs) som BERT vert brukt for nesten alle språk-relaterte oppgåver, men tolking av oppgåva sin fortsatt er ein betydelig utfordring, og mange viktige spørsmål er stort ikkje svart. I denne arbeida kan vi gjenoppretta eit setning som redigerer datasett, der sannsynleg høgkvalitetsforsjonar kan automatisk pakkast ut og samanliknast med utpakka modeller, som ein ny testen for tolkingsbehandling. Dette kan gjere oss systematisk undersøking om eit rekkje spørsmål om PLMs interpreteringsverktøy, inkludert rolen på føreøvingsprosedyren, sammenligning av racionale utpakkingsmetoder og ulike lag i PLM. Forsøket generer nye innsyningar, for eksempel, i motsetning til felles forståelse, finn vi at oppmerksvektene korrelaterte godt med menneske rasjonar og arbeider bedre enn fargeovergangsbasert saliensjon i utpakking av modeller. Begge datasettet og koden vert lagt ut for å gjera framtidige uttolkingsforskning.', 'pl': 'Wstępnie przeszkolone modele językowe (PLM), takie jak BERT, są stosowane do prawie wszystkich zadań związanych z językiem, ale interpretacja ich zachowań nadal pozostaje istotnym wyzwaniem, a wiele ważnych pytań pozostaje w dużej mierze bez odpowiedzi. W niniejszej pracy przeznaczyliśmy zbiór danych edycji zdań, w którym wierne wysokiej jakości uzasadnienia ludzkie mogą być automatycznie wyodrębnione i porównywane z wyodrębnionymi uzasadnieniami modelu, jako nowy zestaw testowania interpretacji. Dzięki temu możemy prowadzić systematyczne badanie szeregu pytań dotyczących interpretowalności PLM, w tym roli procedury przedszkoleniowej, porównania metod ekstrakcji racjonalnej oraz różnych warstw w PLM. Badanie generuje nowe spostrzeżenia, na przykład wbrew powszechnemu zrozumieniu, stwierdza się, że wagi uwagi dobrze korelują z ludzkimi racjonalnościami i działają lepiej niż wyraźność oparta na gradientach w wydobyciu racjonalnych modeli. Zarówno zbiór danych, jak i kod zostaną udostępnione w celu ułatwienia przyszłych badań nad interpretacją.', 'ro': 'Modelele lingvistice pre-instruite (PLM) precum BERT sunt utilizate pentru aproape toate sarcinile legate de limbă, dar interpretarea comportamentului lor rămâne încă o provocare semnificativă și multe întrebări importante rămân în mare parte fără răspuns. În această lucrare, refolosim un set de date de editare a propozițiilor, în care rațiunile umane fidele de înaltă calitate pot fi extrase automat și comparate cu rațiunile modelului extras, ca un nou pat de testare pentru interpretabilitate. Acest lucru ne permite să efectuăm o investigație sistematică asupra unei serii de întrebări privind interpretabilitatea PLM-urilor, inclusiv rolul procedurii de pre-formare, compararea metodelor de extragere rațională și diferite straturi din PLM. Investigația generează noi perspective, de exemplu, contrar înțelegerii comune, constatăm că ponderile atenției corelează bine cu rațiunile umane și funcționează mai bine decât saliența bazată pe gradient în extragerea rațiunilor modelului. Atât setul de date, cât și codul vor fi lansate pentru a facilita cercetarea viitoare privind interpretabilitatea.', 'si': 'BERT වගේ ප්\u200dරධානය කළ භාෂා මොඩේල්ස් වගේ භාෂාව සම්බන්ධ වැඩකට භාවිතා කරනවා, ඒත් ඔවුන්ගේ භාවිතාව අභාවිත කරන්න තවමත් වැදගත මේ වැඩේදී, අපි ආයෙත් අරමුණු වාක්ෂාවක් නිර්මාණය කරනවා දත්ත සෙට්, කොහේද විශ්වාසිත විශ්වාසිත මිනිස්සුන්ගේ ප්\u200dරතිකාරය ස මේකෙන් අපිට ප්\u200dරශ්නයක් කරන්න පුළුවන් ප්\u200dරශ්නයක් ගැන, ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ගැන, ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ගැන, ප්\u200dරශ්නයක් ප්\u200d පරීක්ෂණයෙන් අළුත් අදහසක් නිර්මාණය කරනවා, උදාහරණයෙන්, සාමාන්\u200dය තේරුම් එක්ක, අපි හොයාගන්නවා අවධානයක් මිනිස්සුන්ගේ ප්\u200dරතිකාරය දත්ත සැට් සහ කෝඩ් දෙන්නම ප්\u200dරතික්\u200dරියා වෙන්නේ අනාගතයේ අභිවිධානය පරීක්ෂණය සහාය කරන්න', 'sr': 'Pre-obučeni jezički modeli poput BERT koriste se za skoro sve zadatke vezane za jezik, ali interpretacija njihovog ponašanja i dalje ostaje značajan izazov i mnogi važni pitanja u velikoj mjeri ostaju bez odgovora. U ovom poslu, ponovo namjeravamo re čenicu za redikciju podataka, gde verne visoke kvalitetne ljudske racionale mogu biti automatski izvučene i u usporedbi sa izvlačenim modelima racionalnih razloga, kao novo testovanje za interpretabilnost. To nam omogućava da obavimo sistematsku istragu o nizu pitanja o interpretabilnosti PLMs-a, uključujući ulogu procedure pre obuke, usporedbu racionalnih metoda ekstrakcije i različitih slojeva PLM-a. Istraga stvara nove uvide, na primer, suprotno zajedničkom razumijevanju, smatramo da težina pažnje dobro povezuje sa ljudskim racionalima i radi bolje od salicije na osnovu gradienta u izvlačenju modelnih racionala. Oba grupa podataka i koda će biti objavljena kako bi olakšali buduće istraživanje interpretabilnosti.', 'so': "Tusaalada afka hore oo la tababaray (PLMs) sida BERT waxaa loo isticmaali karaa in dhowr shaqooyin la xiriira luuqada oo dhan, laakiin turjumidda tababarkooda weli wuxuu sii jiraa dhibaato muhiim ah iyo su'aalo badan oo muhiim ah oo aan la jawaabin. Markaas waxan, waxaynu ku qoraynaa qoraal macluumaad, kaas oo lagu soo saari karo rasmiga shakhsiga ah oo aaminka ah, oo lagu barbaran karo rasmiga qaababka soo saaray, sida loo tijaabiyey turjumidda cusub. Taasi waxay inagu sameyn kartaa baaritaan nidaamka ah oo ku saabsan turjumaadda PLMs (PLMs) qaarkood, kuwaas oo ka mid ah qaybta koorasyada waxbarashada horta, isbarbardhigida qaababka soo bixinta rasmi ah iyo qaybaha kala duduwan ee PLM. Baaritaanku wuxuu sameeyaa arago cusub, tusaale ahaan ka duwan waxgarashada caadiga ah, waxaynu aragnaa in dhegtu ay si wanaagsan u leedahay rasmiga biniaadamka, shaqeyntana way ka wanaagsan tahay qiimeynta dabeecada. Lacagta macluumaadka iyo codsiga waxaa la bixinayaa si uu u fududeeyo baaritaanka turjumidda mustaqbalka ah.", 'sv': 'Förutbildade språkmodeller (PLM) som BERT används för nästan alla språkrelaterade uppgifter, men tolkningen av deras beteende är fortfarande en stor utmaning och många viktiga frågor förblir i stort sett obesvarade. I detta arbete omarbetar vi ett meningsredigeringsdataset, där trogna högkvalitativa mänskliga rationaler automatiskt kan extraheras och jämföras med extraherade modellrationaler, som en ny testbädd för tolkning. Detta gör det möjligt för oss att genomföra en systematisk undersökning av en rad frågor som rör PLM:s tolkning, inklusive rollen för förberedelseförfarandet, jämförelse av rationella extraktionsmetoder och olika skikt i PLM. Undersökningen genererar nya insikter, till exempel, i motsats till den gemensamma förståelsen, finner vi att uppmärksamhetsvikt korrelerar väl med mänskliga rationaler och fungerar bättre än gradientbaserad saliens i utvinningen av modellrationaler. Både datauppsättningen och koden kommer att släppas för att underlätta framtida tolkningsforskning.', 'ta': 'முன்பயிற்சிக்கப்பட்ட மொழி மாதிரிகள் (PLMs) பிரெட்டி போன்ற அனைத்து மொழி தொடர்புடைய பணிகளுக்கும் பயன்படுத்தப்படுகிறது, ஆனால் அவற்றின் நடத்தையை ம இந்த வேலையில், நாம் மீண்டும் ஒரு வாக்கு தரவு தொகுப்பு அமைப்பை திருத்த வேண்டும். இது பிஎல்எம்எஸ் மொழிபெயர்ப்பு பற்றிய பல கேள்விகள் மீது ஒரு அமைப்பான விசாரணையை செயல்படுத்த முடியும், முன் பயிற்சி செயல்பாடு ஆய்வு புதிய குறிப்புகளை உருவாக்குகிறது, உதாரணமாக, பொது புரிய புரியும் எதிர்த்து, நாம் கவனத்தை மனித குறிப்புகளுடன் நன்றாக இணைக்கிறது மற்றும் ச தகவல் அமைப்புகளும் குறியீடுகளும் இரண்டும் வெளியேற்றப்படும் எதிர்கால விளக்கமான ஆராய்ச்சியை', 'mn': 'BERT шиг сургалтын өмнө сургалтын хэл загварууд бараг бүх хэл холбоотой ажил дээр хэрэглэгддэг. Гэхдээ тэдний үйл ажиллагааг илэрхийлэх нь чухал сорилт байдаг. Олон чухал асуултууд ихэвчлэн хариултгүй байдаг. Энэ ажлын тулд бид өгөгдлийн загварыг дахин зориулсан өгөгдлийн загварыг дахин зориулсан. Энд итгэлтэй өндөр чанартай хүн төрөлхтний ойлголт автоматаар автоматаар гаргаж, гаргасан загварын ойлголтыг харьцуулж болно Энэ нь бидэнд ПЛМ-ын илэрхийлэл боломжтой асуултын тухай систематик судалгааг хийх боломжтой болгодог. Судалгаанд шинэ ойлголт бий болгодог. Жишээлбэл, ерөнхий ойлголтын эсрэг, анхаарлын жин нь хүн төрөлхтний ойлголтыг сайн харьцуулж, градиент суурь загварын рационалийг гаргахаас илүү сайн ажилладаг. Дахиад өгөгдлийн сан болон кодын хоёр нь ирээдүйн ойлголтын судалгааг нэмэгдүүлэх боломжтой болно.', 'ur': 'BERT کی طرح پہلے تدریس کی زبان مدل (PLMs) تقریباً تمام زبان کے متعلقّق کاموں کے لئے استعمال کئے جاتے ہیں، لیکن ان کے رفتار کی تعبیر ابھی ایک بڑی مشکل ہے اور بہت سی اہم سوالات بالکل بغیر جواب دیتے ہیں. اس کام میں ہم ایک فیصلہ دوبارہ سمجھ سکتے ہیں جو ڈیٹ سٹ سمجھ رہے ہیں، جہاں ایمان والی بلند کیفیت انسان کی منطقی اٹھائے جاتے ہیں اور اٹھائے جاتے ہیں مدل کے منطقیوں کے مقابلہ میں، ایک نئی تفسیر کے طور پر۔ یہ ہمیں PLMs کی تفسیر قابلیت کے بارے میں ایک سیستمائی تحقیق کرنے کی اجازت دیتا ہے، اس میں پہلے تحقیق کے رول کے ذریعہ، منطقی اخراج طریقوں کے مقایسے اور PLM میں مختلف لہروں کے بارے میں۔ تحقیقات نے نئی نظریں پیدا کی ہیں، مثال، مشترک سمجھ کے مقابلہ میں، ہم دیکھتے ہیں کہ توجه کا وزن انسان کے منطقیوں سے بہت اچھا مرتبہ ہے اور اس سے بہتر کام کرتا ہے کہ نمڈل کے منطقیوں کو اٹھانے کے لئے گرادی بنیاد سے زیادہ اچھا مرتبہ ہے. دونوں ڈاٹ سٹ اور کوڈ آزاد کیے جائیں گے تاکہ مستقبل تفسیر کا تحقیق آسان کرے۔', 'uz': "Birinchi taʼminlovchi tillar modellari (PLMs) BERT kabi hamma tillar bilan bog'langan vazifalar uchun ishlatiladi, lekin ularning xuddi tarjima qilishi hamma muhim qiymati va ko'p muhim savollar juda javob bermaydi. Bu ishda biz bir so'z maʼlumot tarkibini tahrirlash uchun bir so'zni qaytadan foydalanamiz. Bu yerda muammolar yuqori shaxsiy inson rationalarini avtomatik olib tashlash mumkin va kichkina model rationalari bilan kamaytirish mumkin. Bu bizga PLMs' tarjima haqida bir necha savollarni tizim qilish imkoniyatini beradi, bir ta'lim vazifasi bajarayonligi, qisqarish usullarini kamaytirish va PLM'da har xil qatlamlar. Qidirish yangi ko'rini tushunadi, masalan umumiy tushunchaga qaragan, biz o'ylaymiz, huddi inson rationalari bilan yaxshi bog'liq bo'ladi va gradient-asosiy modelni chiqarish imkoniyatlaridan yaxshi ishlayapti. Keyingi birinchi tarjima qilishga foydalanuvchi uchun maʼlumot set va kodi yoʻq.", 'vi': 'Những mô hình ngôn ngữ được rèn luyện trước (PLM) như BERT đang được sử dụng cho hầu hết các công việc liên quan đến ngôn ngữ, nhưng dịch chuyển hành vi của họ vẫn là một thử thách lớn và nhiều câu hỏi quan trọng vẫn còn chưa được giải đáp. Trong công việc này, chúng ta cần ghép lại một bộ dữ liệu sửa bản án, nơi lý trí con người trung thành chất lượng chất lượng cao có thể tự động được lấy ra và so sánh với các nguyên lý kiểu được chiết xuất, như một mẫu thử mới để giải thích. Điều này cho phép chúng ta tiến hành một cuộc điều tra có hệ thống về một loạt câu hỏi liên quan đến tính cách của Đảng, bao gồm vai trò của thủ tục huấn luyện trước, so sánh phương pháp khai thác lý, và các lớp khác nhau trong PLM. Cuộc điều tra tạo ra những ý tưởng mới, ví dụ, trái với sự hiểu biết chung, chúng tôi thấy sự chú ý của nó phù hợp tốt với các lý trí và hoạt động tốt hơn những lời nói có độ thuận lợi trong việc khai thác các mô hình lý trí. Cả bộ dữ liệu và mã sẽ được phát hành để dễ dàng tìm hiểu thấu đáo tương lai.', 'hr': 'Preobučeni jezički modeli poput BERT koriste se za skoro sve zadatke vezane za jezik, ali tumačenje njihovog ponašanja još uvijek ostaje značajan izazov i mnoga važnih pitanja u velikoj mjeri ostaju bez odgovora. U ovom poslu, ponovno namjeravamo re čenicu za redakciju podataka, gdje vjerne visokokvalitetne ljudske racionale mogu biti automatski izvučene i u usporedbi s izvučenim modelima racionalnih razloga, kao novo testovanje za interpretabilnost. To nam omogućava provoditi sistematsku istragu o nizu pitanja o interpretabilnosti PLMs-a, uključujući ulogu postupaka predobučenja, usporedbu racionalnih metoda izvlačenja i različitih slojeva u PLM-u. Istraga stvara nove uvide, na primjer, suprotno zajedničkom razumijevanju, smatramo da težina pažnje dobro povezuje sa ljudskim racionalima i radi bolje od salicije na gradient-based u izvlačenju modelnih racionala. Obojica će se podaci i kodeks osloboditi kako bi olakšali buduće istraživanje interpretabilnosti.', 'nl': "Vooropgeleide taalmodellen (PLM's) zoals BERT worden gebruikt voor bijna alle taalgerelateerde taken, maar het interpreteren van hun gedrag blijft een belangrijke uitdaging en veel belangrijke vragen blijven grotendeels onbeantwoord. In dit werk hergebruiken we een dataset voor zinsbewerking, waarbij trouwe, hoogwaardige menselijke rationalen automatisch kunnen worden geëxtraheerd en vergeleken met geëxtraheerde modellrationalen, als een nieuw testbed voor interpreteerbaarheid. Dit stelt ons in staat een systematisch onderzoek uit te voeren naar een reeks vragen over de interpreteerbaarheid van PLM's, waaronder de rol van pre-training procedure, vergelijking van rationale extractiemethoden en verschillende lagen in de PLM. Het onderzoek genereert nieuwe inzichten, bijvoorbeeld, in tegenstelling tot het algemeen begrip, vinden we dat aandachtsgewichten goed correleren met menselijke rationales en beter werken dan gradiënt gebaseerde saliciëntie bij het extraheren van modelregionalen. Zowel de dataset als de code zullen worden vrijgegeven om toekomstig interpreteerbaarheidsonderzoek te vergemakkelijken.", 'da': "Forududdannede sprogmodeller (PLM'er) som BERT bruges til næsten alle sprogrelaterede opgaver, men fortolkningen af deres adfærd er stadig en stor udfordring, og mange vigtige spørgsmål er stort set ubesvarede. I dette arbejde genbruger vi et sætningsredigeringsdatasæt, hvor tro menneskelige rationaler af høj kvalitet automatisk kan udtrækkes og sammenlignes med ekstraherede modelrationaler, som et nyt testbed for fortolkning. Dette gør det muligt for os at gennemføre en systematisk undersøgelse af en række spørgsmål vedrørende PLM'ernes fortolkningsevne, herunder rollen som forberedelsesprocedure, sammenligning af rationelle ekstraktionsmetoder og forskellige lag i PLM. Undersøgelsen skaber nye indsigter, for eksempel, i modsætning til den fælles forståelse, finder vi, at opmærksomhedsvægte korrelerer godt med menneskelige rationaler og fungerer bedre end gradient-baseret fremhævelse i at udtrække model rationaler. Både datasættet og koden vil blive frigivet for at lette fremtidig fortolkningsforskning.", 'bg': 'Предварително обучени езикови модели (ПЛМ) като BERT се използват за почти всички задачи, свързани с езика, но тълкуването на поведението им все още остава значително предизвикателство и много важни въпроси остават до голяма степен без отговор. В тази работа преработваме набор от данни за редактиране на изречения, където верните висококачествени човешки обосновки могат автоматично да бъдат извлечени и сравнени с извлечените мотиви на модела, като нов тест за интерпретация. Това ни позволява да проведем систематично разследване на редица въпроси, свързани с тълкуваемостта на ПЛМ, включително ролята на процедурата преди обучението, сравняването на методите за извличане на обосновка и различните слоеве в ПЛМ. Разследването генерира нови прозрения, например, противно на общото разбиране, ние откриваме, че тежестите на вниманието корелират добре с човешките обосновки и работят по-добре от градиентната видимост при извличането на обосновките на модела. Както наборът от данни, така и кодът ще бъдат публикувани, за да се улеснят бъдещите изследвания за тълкуваемост.', 'ko': '버트와 같은 예비훈련언어모델(PLM)은 거의 모든 언어와 관련된 임무에 사용되지만, 그들의 행동을 설명하는 것은 여전히 중대한 도전이며, 많은 중요한 문제들은 기본적으로 여전히 답이 없다.이 작업에서 우리는 문장 편집 데이터 집합을 새로운 해석 가능한 테스트 플랫폼으로 삼아 이 데이터 집합은 충실한 고품질 인간 추리를 자동으로 추출하고 추출한 모델 추리와 비교할 수 있다.이로써 우리는 PLM의 해석성에 관한 일련의 문제를 체계적으로 조사할 수 있다. 이는 교육 전 프로그램의 역할, 기본 원리 추출 방법의 비교와 PLM의 서로 다른 측면을 포함한다.이 연구는 새로운 견해를 얻었다. 예를 들어 보편적인 이해와 반대로 우리는 주의권이 인류의 기본 원리와 매우 좋은 관련성을 가지며 추출 모델의 기본 원리에 있어 사다리를 바탕으로 하는 현저성보다 더욱 효과적임을 발견했다.데이터 집합과 코드가 발표되어 미래의 해석 가능한 연구를 추진할 것이다.', 'de': 'Vortrainierte Sprachmodelle (PLMs) wie BERT werden für fast alle sprachbezogenen Aufgaben eingesetzt, aber die Interpretation ihres Verhaltens bleibt nach wie vor eine große Herausforderung und viele wichtige Fragen bleiben weitgehend unbeantwortet. In dieser Arbeit verwenden wir einen Satz Editing Datensatz, in dem originalgetreue, qualitativ hochwertige menschliche Rationalien automatisch extrahiert und mit extrahierten Modellrationen verglichen werden können, als neues Testfeld für Interpretierbarkeit. Dies ermöglicht uns eine systematische Untersuchung einer Reihe von Fragen zur Interpretierbarkeit von PLMs, einschließlich der Rolle des Vortrainingsverfahrens, des Vergleichs von rationalen Extraktionsmethoden und verschiedener Schichten im PLM. Die Untersuchung generiert neue Erkenntnisse, zum Beispiel, entgegen dem üblichen Verständnis, dass Aufmerksamkeitsgewichte gut mit menschlichen Rationalen korrelieren und besser funktionieren als gradientenbasierte Salienz bei der Extraktion von Modellrationen. Sowohl der Datensatz als auch der Code werden veröffentlicht, um zukünftige Interpretationsforschung zu erleichtern.', 'sw': 'Mradi wa lugha zilizofunzwa kabla (PLMs) kama BERT unatumiwa kwa ajili ya kazi zote zinazohusiana na lugha, lakini kutafsiri tabia zao bado bado bado ni changamoto kubwa na maswali mengi muhimu bado hayajajibiwa. Katika kazi hii, tunalenga tena hukumu ya kuhariri seti ya taarifa, ambapo rasilimali za juu za binadamu zilizoamini zinaweza kutengenezwa na kulinganisha na rasilimali za mifano iliyochapishwa, kama ilivyojaribiwa mpya kwa ajili ya tafsiri. Hii inatuwezesha kutekeleza uchunguzi wa mfumo wa maswali mengi kuhusu tafsiri ya PLMs, ikiwa ni pamoja na jukumu la mchakato wa mafunzo ya kabla, ukilinganisha na njia za utekelezaji rasmi, na vipande tofauti katika PLM. Uchunguzi unaleta mitazamo mpya, kwa mfano, kinyume na uelewa wa kawaida, tunagundua kuwa makini yanaunganisha vizuri na rasilimali za binadamu na kufanya kazi nzuri zaidi ya bei yenye msingi wa rangi katika kuchagua misimamo. Viwili vyote vya taarifa na sheria zitatolewa ili kusaidia tafiti za kutafsiri mustakabali.', 'id': 'Pre-trained language models (PLMs) like BERT are being used for almost all language-related tasks, but interpreting their behavior still remains a significant challenge and many important questions remain largely unanswered.  Dalam pekerjaan ini, kami mengubah tujuan sebuah set data penyuntingan kalimat kalimat, di mana rasional manusia yang setia kualitas tinggi dapat secara otomatis diekstraksi dan dibandingkan dengan rasional model ekstrakt, sebagai tempat ujian baru untuk interpretasi. Ini memungkinkan kita melakukan penyelidikan sistematis pada sejumlah pertanyaan mengenai interpretabilitas PLM, termasuk peran prosedur prapelatihan, perbandingan metode ekstraksi rasional, dan lapisan yang berbeda di PLM. Penyelidikan menghasilkan pandangan baru, misalnya, bertentangan dengan pemahaman umum, kami menemukan bahwa berat perhatian berkorelasi dengan baik dengan rasional manusia dan bekerja lebih baik daripada salinsi berdasarkan gradien dalam ekstraksi rasional model. Kedua set data dan kode akan dilepaskan untuk memudahkan penelitian interpretabilitas masa depan.', 'af': "Vorige opgelei taal modele (PLMs) soos BERT word gebruik word vir amper alle taal verwante taak, maar die uitteling van hulle gedrag bly nog 'n betekende uitdrukking en baie belangrike vrae bly groot ongeantwoord. In hierdie werk, ons herdoen 'n seting redigeerder datastel, waar getroude hoë-kwaliteit menslike rationales kan outomaties uitpak en vergelyk word met uitpak model rationales, as 'n nuwe toetspel vir uittelbare. Dit laat ons toe om 'n sistematiese ondersoek te doen op 'n aantal vrae aangaande PLMs se uitleggbare verklaring, insluitend die rol van voor-ondersoek prosedure, vergelyking van racionale uittrekking metodes en verskillende laag in die PLM. Die ondersoek genereer nuwe ondersoek, byvoorbeeld, teen die gemeenskaplike verstanding, ons vind dat aanmerking gewigte goed korreleer met menslike rationales en werk beter as gradient-gebaseerde salienskap in uittrek van model rationales. Beweel die datastel en kode sal verlos word om toekomstige uitleggingsverklaring te maak.", 'fa': 'مدل\u200cهای پیش آموزش زبانی (PLMs) مانند BERT برای تقریباً تمام کار\u200cهای زبانی استفاده می\u200cشوند، ولی تعبیر رفتارشان هنوز یک چالش بزرگی باقی ماند و بسیاری از سوالات مهم\u200cها به طور بزرگ بی\u200cپاسخ می\u200cمانند. در این کار، ما مجدد ویرایش مجدد داده\u200cها را دوباره هدف می\u200cدهیم، جایی که منطقه\u200cهای انسان با کیفیت اعتماد قابل اعتماد می\u200cتوانند به طور خودکار خارج شوند و در مقایسه با منطقه\u200cهای مدل خارج شده، به عنوان یک تست جدید برای تعبیر قابل این به ما اجازه می دهد که یک تحقیقات سیستمی در یک مجموعه سوال در مورد تعبیر قابلیت PLMs انجام دهیم، شامل نقش روش پیش آموزش، مقایسه از روش\u200cهای استخراج منطقی و لایه\u200cهای مختلف در PLM. این تحقیقات، برای مثال، در مقابل درک مشترک، مشاهده جدید را تولید می\u200cکند، ما می\u200cبینیم که وزن توجه با منطقه\u200cهای انسان به خوبی مرتبط می\u200cشود و بهتر کار می\u200cکند از استفاده از استفاده از منطقه\u200cهای مدل بر اساس استفاده می\u200cکند. هر دو مجموعه داده ها و کد برای آسانی تحقیقات قابلیت تعبیر آینده آزاد می شوند.', 'sq': "Modelet e paratrajnuara të gjuhës (PLM) si BERT po përdoren për pothuajse të gjitha detyrat lidhur me gjuhën, por interpretimi i sjelljes së tyre mbetet ende një sfidë e rëndësishme dhe shumë pyetje të rëndësishme mbeten kryesisht të papërgjidhura. Në këtë punë, ne përsërisim qëllimin e një grupi të dhënash të redaksionit të fjalëve, ku racionet njerëzore të cilësisë së lartë besimtarë mund të nxirren automatikisht dhe të krahasohen me racionet e modelit të nxjerrë, si një vend i ri i testuar për interpretueshmërinë. This enables us to conduct a systematic investigation on an array of questions regarding PLMs' interpretability, including the role of pre-training procedure, comparison of rationale extraction methods, and different layers in the PLM.  Hetimi gjeneron kuptime të reja, për shembull, në kundërshtim me kuptimin e përbashkët, ne gjejmë se peshat e vëmendjes korrelojnë mirë me racionet njerëzore dhe punojnë më mirë se sallësia bazuar në gradiente në nxjerrjen e racioneve të modelit. Si kompleti i të dhënave dhe kodi do të lëshohen për të lehtësuar kërkimin e interpretueshëm të ardhshëm.", 'tr': "BERT ýaly öňki bilim sistemasynda bilim nusgalary (PLMs) diýen ýaly dilleriň ähli meseleleri üçin ullanılýar, ýöne olaryň davranışlaryny täze bir kynçylyk ýok we köp wajyp soraglary ýok. Bu işde, biz esaslary düzenlemek üçin ynamly ýokarylyk sebäbi adamlaryň derejesi otomatik bilen a çylyp biler we daňlanan nusgalar bilen deňleşdirilip biler. Bu bizi PLMsiň terjimeleri barada sistematik soraglary çykaryp bilen mümkin edýär, öňünden öňünden eğitim prosedasynyň roli bilen, dogry çekme yöntemleriniň karşılaştyrylygyny we PLM'yň farklı katlary bilen üýtgetmegimizi mümkin edýär. Soragy örän täze düşünjeleri döredir, umumy düşünjegiň garşynyň tersine, üns çekişiniň nähili adamlaryň dogrylyklary bilen gowy ýagdaýlaýar we gradiýa daýanýan çykyşlyklary çykarmakdan has gowy işleýäris. Veri set we köd ikisi gelejek terjime edilişi barlamak üçin çykılacak.", 'bn': 'প্রাক্তন প্রশিক্ষিত ভাষার মডেল (পিএলএমএস) প্রায় সকল ভাষার সংশ্লিষ্ট কাজের জন্য ব্যবহার করা হচ্ছে, কিন্তু তাদের আচরণের ব্যাখ্যা এখনো বিশাল চ্যা এই কাজে আমরা পুনরায় একটি বাক্য সম্পাদনার উদ্দেশ্য চাই, যেখানে বিশ্বাসী উচ্চমান মানুষের মানুষের যৌক্তিকতা স্বয়ংক্রিয়ভাবে বের করে নিতে পারে  এটি আমাদেরকে পিএলএমএসের ব্যাখ্যাতির বিভিন্ন প্রশ্নের ব্যাপারে সিস্টেমিক তদন্তের ব্যবস্থা করার সুযোগ প্রদান করা যায়, যার মধ্যে প্রশিক্ষণ পূর্ব প্রক্ তদন্তের জন্য নতুন দৃষ্টিভঙ্গি তৈরি করে, যেমন সাধারণ বুদ্ধির বিপরীতে, আমরা দেখতে পাচ্ছি যে মনোযোগ মানুষের যৌক্তিকতার সাথে ভালোভাবে সম্পর্কিত এবং গ্ ভবিষ্যতের ব্যাখ্যাত গবেষণার সুবিধা প্রদান করার জন্য ডাটাসেট এবং কোড উভয়কে মুক্তি দেয়া হবে।', 'az': "BERT kimi əvvəl təhsil edilmiş dil modelləri neredeyse bütün dillərlə bağlı işlər üçün istifadə edilir, amma onların davranışlarını təfsil etmək hələ də möhkəm bir çətinlikdir və çox möhkəm sual çox cavab vermədir. Bu işdə, biz bir cümləyi düzenleyici verilən qutusu yenidən məqsədilə təşkil edirik. İnsanların mövcud yüksək kaliteli nəticələri öz-özündən çıxarılabilir və təşkil edilmiş modellərlə müqayisədə yeni təşkil edilə bilər. Bu bizim PLMs'in yorumluluğu haqqında sistematik bir soruşma işlətməyimizi fərqləndirir, əvvəlcə təhsil işlətməsinin rolünün, racional çıxarma metodlarının və PLM'nin farklı səviyyələrinin karşılaşdırmasına mümkün olur. Bu araşdırma, məsələn, ortaq anlama qarşısında yeni anlayışlar yaradır, biz insanların razılıqları ilə yaxşı bağlı olduğunu görürük və modeli razılıqları çıxartmaqdan daha yaxşı çalışır. Verilər və kodu hər ikisi də gələcək təfsirləşib araştırmalarını asanlaşdırmaq üçün yayınlanacaq.", 'bs': 'Preobučeni jezički modeli poput BERT koriste se za skoro sve zadatke vezane za jezik, ali interpretacija njihovog ponašanja još uvijek ostaje značajan izazov i mnogi važni pitanja u velikoj mjeri ostaju bez odgovora. U ovom poslu, ponovno namjeravamo re čenicu za editiranje podataka, gdje vjerni visoki kvalitetni ljudski racionali mogu biti automatski izvučeni i uspoređeni s izvlačenim modelima, kao novi testovan za interpretabilnost. To nam omogućava da provodimo sistematsku istragu o gomili pitanja o interpretabilnosti PLMs-a, uključujući ulogu procedure predobučenja, usporedbu racionalnih metoda izvlačenja i različitih slojeva u PLM-u. Istraga stvara nove uvide, na primjer, suprotno zajedničkom razumijevanju, smatramo da težina pažnje dobro povezuje sa ljudskim racionalima i radi bolje od salicije na gradient-based u izvlačenju modelnih racionala. Oba grupa podataka i kodeksa će se osloboditi kako bi olakšali buduće istraživanje interpretabilnosti.', 'am': 'በፊት ተማርቷል የቋንቋ ምሳሌዎች (PLMs) እንደBERT ለቋንቋ-related ስራ ሁሉ ይጠቀማሉ፤ ነገር ግን ትርጓሜአቸው እንኳ ትልቅ ጥያቄ ይኖራል ብዙዎቹም ጠያቂዎች ገና የማይመልሱ ናቸው፡፡ በዚህ ሥራ፣ አዲስ ትርጓሜ ለመተረጉም አዲስ ተፈተና እንደሆነ የታመነ የራሱ የሰው አካላት በራስነት እንዲወስዱ እና በተለየው ሞዴል አካላት እናስተካከል፡፡ ይህም በPLMs ትርጉም ላይ በተለያዩ የጥያቄ ምርመራ፣ ከዚህ በፊት ትምህርት ፕሮጀክት ትክክል፣ በአስተናጋሪነት ውጤት እና በPLM ላይ የተለየ ደረጃዎች እና በተለየ ደረጃዎች እና በተለየ ጥያቄዎችን ለማስተካከል ይችላል፡፡ ምርመራው አዲስ ማስተዋል እንዲያሳየው አዲስ ማስታወቂያዎች፣ ትኩረት ከሰው አካባቢ ጋር መልካም እንዲታሰል እና በሥርዓት መሠረት ላይ የሚሻል እናደርጋለን፡፡ የዳታ ሰርቨሮች እና ኮድ ለኋለኛይቱ ትርጉም ትርጓሜን ለማግኘት ይቻላል፡፡', 'ca': "Models de llenguatge pré-entrenats (PLM) com BERT s'utilitzen per gairebé totes les tasques relacionades amb el llenguatge, però interpretar el seu comportament encara és un repte significatiu i moltes preguntes importants encara no són respostes. En aquesta feina, hem de redigir un conjunt de dades d'edició de frases, on es poden extrair automàticament fidels racionals humans d'alta qualitat i comparar-se amb els racionals de models extraits, com un nou test d'interpretabilitat. Això ens permet fer una investigació sistemàtica sobre una sèrie de preguntes relacionades amb l'interpretabilitat dels PLM, incloent el paper del procediment de pré-entrenament, la comparació de mètodes d'extracció racional i diferents capes del PLM. L'investigació genera noves intuïcions, per exemple, contrariament a la comprensió comú, trobem que el pes de l'atenció correlaciona bé amb les racions humanes i treballa millor que la saliència basada en gradients en l'extracció de racions models. Tant el conjunt de dades com el codiserà publicat per facilitar la recerca futura d'interpretabilitat.", 'cs': 'Předškolené jazykové modely (PLM) jako BERT se používají téměř pro všechny jazykové úkoly, ale interpretace jejich chování stále zůstává významnou výzvou a mnoho důležitých otázek zůstává do značné míry nezodpovězených. V této práci přepracováváme datovou sadu editace vět, kde lze automaticky extrahovat věrné vysoce kvalitní lidské racionály a porovnat s extrahovanými modelovými racionály, jako nové testovací místo interpretovatelnosti. To nám umožňuje provádět systematické šetření řady otázek týkajících se interpretovatelnosti PLM, včetně role postupu předškolení, srovnání metod odůvodnění extrakce a různých vrstev PLM. Výzkum generuje nové poznatky, například na rozdíl od běžného chápání zjišťujeme, že váhy pozornosti korelují dobře s lidskými zdůvodněními a fungují lépe než gradientová slabost při extrakci modelových racionálů. Datová sada i kód budou zveřejněny pro usnadnění budoucího výzkumu interpretovatelnosti.', 'hy': 'ԲԵՌՏ-ի նման նախապատրաստված լեզվի մոդելները օգտագործվում են գրեթե բոլոր լեզվով կապված խնդիրների համար, սակայն իրենց վարքագծի մեկնաբանությունը դեռևս նշանակալի մարտահրավեր է, և շատ կարևոր հարցեր հիմնականում չեն պատասխանում: Այս աշխատանքի ընթացքում մենք վերականգնում ենք նախադասությունների խմբագրման տվյալների համակարգը, որտեղ հավատարիմ բարձր որակի մարդկային ռացիոնալները կարող են ինքնաբերաբար վերցնել և համեմատել վերացված մոդելի ռացիոնալների հետ, որպես նոր փորձարկումների միջոց մեկնա Սա մեզ հնարավորություն է տալիս կատարել սիստեմատիկ հետազոտություն PLM-ի մեկնաբանելիության հարցերի մի շարք վերաբերյալ, ներառյալ նախապատրաստման գործընթացի դերը, ռացիոնալ վերացման մեթոդների համեմատությունը և PLM-ի տարբեր շերտերը: The investigation generates new insights, for example, contrary to the common understanding, we find that attention weights correlate well with human rationales and work better than gradient-based saliency in extracting model rationales.  Երկու տվյալների համակարգը և կոդը կհրապարակվեն ապագա մեկնաբանելիության հետազոտությունների հեշտացնելու համար:', 'et': 'Eelkoolitud keelemudeleid, nagu BERT, kasutatakse peaaegu kõigis keelega seotud ülesannetes, kuid nende käitumise tõlgendamine on endiselt oluline väljakutse ja paljud olulised küsimused jäävad suures osas vastuseta. Selles töös kavandame ümber lausete redigeerimise andmekogumi, kus on võimalik automaatselt ekstraheerida ustavaid kvaliteetseid inimpõhjendusi ja võrrelda ekstraheeritud mudelirõhjendustega, uue tõlgendatavuse testialusena. See võimaldab meil läbi viia süstemaatilise uurimise mitmete küsimuste kohta, mis puudutavad PLMide tõlgendatavust, sealhulgas koolituseelse protseduuri rolli, põhjenduste ekstraheerimise meetodite võrdlemist ja PLMi erinevaid kihte. Uurimine tekitab uusi teadmisi, näiteks vastupidiselt üldisele arusaamale leiame, et tähelepanu kaalud korreleeruvad hästi inimese loogilistele põhjendustele ja toimivad paremini kui gradientil põhinev silmapaistvus mudeli loogiliste põhjenduste väljatöötamisel. Nii andmekogum kui ka kood avaldatakse tulevaste tõlgendatavuse uuringute hõlbustamiseks.', 'fi': 'BERT:n kaltaisia esikoulutettuja kielimalleja käytetään lähes kaikissa kieliin liittyvissä tehtävissä, mutta niiden käyttäytymisen tulkinta on edelleen merkittävä haaste ja monet tärkeät kysymykset jäävät pitkälti vastaamatta. Tässä työssä uudelleenmuotoillaan lauseidenmuokkausaineisto, jossa luotettavat ja laadukkaat inhimilliset perustelut voidaan automaattisesti poimia ja verrata uutettuihin malliperusteisiin, uudeksi tulkittavuuden testialustaksi. Tämä mahdollistaa systemaattisen tutkimuksen useista PLM:ien tulkittavuuteen liittyvistä kysymyksistä, kuten esikoulutuksen roolista, perustelujen poimimismenetelmien vertailusta ja PLM:n eri tasoista. Tutkimuksessa syntyy uusia oivalluksia, esimerkiksi yleisen ymmärryksen vastaisesti huomaamme, että huomiopainot korreloivat hyvin ihmisen logiikan kanssa ja toimivat paremmin kuin gradienttipohjainen salienti mallin logiikan poimimisessa. Sekä aineisto että koodi julkaistaan tulevan tulkittavuustutkimuksen helpottamiseksi.', 'sk': 'Vnaprej usposobljeni jezikovni modeli (PLM), kot je BERT, se uporabljajo za skoraj vsa jezikovna naloga, povezana z jezikom, vendar je tolmačenje njihovega vedenja še vedno pomemben izziv in številna pomembna vprašanja ostajajo večinoma neodgovorjena. V tem delu smo ponovno namenili nabor podatkov za urejanje stavkov, kjer je mogoče zveste visokokakovostne človeške utemeljitve samodejno izvleči in primerjati z izvlečenimi modelnimi utemeljitvami, kot novo preskusno podlago za interpretabilnost. To nam omogoča sistematično preiskavo številnih vprašanj glede razlagalnosti PLM, vključno z vlogo postopka predusposabljanja, primerjavo metod ekstrakcije utemeljitev in različnimi plastmi PLM. Raziskava ustvari nove vpoglede, na primer, v nasprotju s splošnim razumevanjem ugotavljamo, da uteži pozornosti dobro povezujejo s človeškimi racionalizacijami in delujejo bolje kot na osnovi gradienta pri izvlečevanju racional modela. Zbirka podatkov in koda bosta objavljena za olajšanje prihodnjih raziskav razlagalnosti.', 'ha': "Ana yi amfani da misãlai na harshen zaman shawara (PLM) kamar BERT don a yi amfani da shi zuwa ga duk aiki masu husũma da harshe, kuma amma fassarar aikin su yana da bada wata taraja mai girma kuma masu tambayi masu muhimma na bada ba'a karɓa ba. Daga wannan aikin, za mu yi amfani da wani salon zarar da tsarin mutane na tsari, a inda mutane masu yin ĩmãni masu iya cire rasasanci da sifanci farat ɗaya kuma a sami da masu tsari da misalin da aka samu, kamar wata sabo na sabo wa fassarar. Wannan yana amfani da mu, yin ƙidãya a kan wasu maswali masu husu da fassarar PLM, kamar rolin a cikin aikin zaman shawara, da misalin hanyor zartarwa masu inganci da kuma abun dabam-dabam cikin PLM. The investigation generates new insights, for example, contrary to the common understanding, we find that attention weights correlate well with human rationales and work better than gradient-based saliency in extracting model rationales.  Za saka kodi da kodi duk su zama masu amfani da fassarar fassararsa a gaba ɗaya.", 'he': 'דוגמני שפה מאומנים מראש (PLMs) כמו BERT משתמשים כמעט לכל משימות קשורות לשפה, אך הפרשנות התנהגותם עדיין אתגר משמעותי והרבה שאלות חשובות נשארות בעיקר בלתי ענויות. בעבודה הזו, אנו משתמשים מחדש בסט מידע עורך משפטים, שבו הגיוני האנושי נאמני באיכות גבוהה יכול להיות אוטומטית מווצא ומשוווה עם הגיוני מודל מווצא, כמקום מבחן חדש לפרשנות. זה מאפשר לנו לבצע חקירה מערכתית על סדרה של שאלות בנוגע לפרשנות של PLMs, כולל תפקיד הליך התאמה לפני, השוואה של שיטות חיפוש הגיוניים, ושכבות שונות ב PLM. החקירה יוצרת תובנות חדשות, לדוגמא, בניגוד להבנה המשותפת, אנו מוצאים שמשקלי תשומת לב מתאימים היטב לרציונליות אנושיות ועובדים טוב יותר ממחלקה מבוססת תדרגות בהוציאה של דוגמאות רציונליות. גם קבוצת הנתונים וגם הקוד ישחררו כדי להקל מחקר אפשרות הפרשנות בעתיד.', 'bo': "BERT དང་སྔོན་གྱི་སྔོན་གྱི་སྐད་ཡིག་གཟུགས་འགྲོ་བ་ཀྱི་དཔེ་དབྱིབས་བྱ་རིམ་ལ་ལག་ལེན་འཐབ་ཡོད་པ། འོན་ཀྱང་། ང་ཚོས་ཚོར་ཞིབ་འཇུག་སྟངས་འདིའི་ནང་གི་བྱ་ཚིག་ལྟ་བུ This enables us to conduct a systematic investigation on an array of questions regarding PLMs' interpretability, including the role of pre-training procedure, comparison of rationale extraction methods, and different layers in the PLM. The investigation generates new insights, for example, contrary to the common understanding, we find that attention weights correlate well with human rationales and work better than gradient-based saliency in extracting model rationales. གནད་སྡུད་ཆ་འཕྲིན་དང་kod་གཉིས་ཀྱིས་མ་འོངས་པར་སླེབས་རུང་བའི་དབྱེ་རིགས་ལ་སླེབས་བཅུག་པ", 'jv': '(PLM) Sampeyan kang dipoleh-perusahaan anyar luwih model (PLM) lagi BERT dumadhi kapan saben gak nggalakno arep nggawe Language-Relative tasks, nguasai itoleh operasi kapan dhéwé isih lanjut cara-diangguna sing dumadhi kapan akeh jutaan susahé sing apik dan akeh sing ng Nang barêng-barêng iki, kéné iso ngubah perusahaan seneng pisan dataset, wong-wong sing nyimpen uwong-kalitas barang-uwong sing isa otomatik dhéwé wae nyong ngerasakno karo rationale model sing apik dhéwé, nganggep kuwi sitik dhéwé nggawe tarjamakno Nyong iso nggawe sistem barêng-barêng nggawe sistem sing arep nggawe gerarané karo perusahaan PLM, gambar nggawe barang sistem sing nyerangké karo perusahaan anyar nggawe tarjamahan, nggerarangké karo perusahaan langkung sampek, lan nggawe barang-langkung sampek karo PLM. Gebudhake perbudhakan suggerujak nggawa Anyadir, sing ngomong nik nggambar perbudhakan anyar Sampeyan dataset lan kode kang dipuluhake kanggo sakjane perusahaan resmi'}
{'en': 'Controlled tasks for model analysis : Retrieving discrete information from sequences', 'fr': "Tâches contrôlées pour l'analyse de modèles\xa0: récupération d'informations discrètes à partir de séquences", 'ar': 'المهام الخاضعة للرقابة لتحليل النموذج: استرداد المعلومات المنفصلة من التسلسلات', 'es': 'Tareas controladas para el análisis de modelos: recuperación de información discreta de las secuencias', 'pt': 'Tarefas controladas para análise de modelo: Recuperando informações discretas de sequências', 'hi': 'मॉडल विश्लेषण के लिए नियंत्रित कार्य: अनुक्रमों से असतत जानकारी प्राप्त करना', 'zh': '模范之受控,检索离散', 'ja': 'モデル分析のための制御されたタスク：シーケンスから離散情報を取得する', 'ru': 'Управляемые задачи для анализа модели: извлечение дискретной информации из последовательностей', 'ga': 'Tascanna rialaithe le haghaidh anailíse samhlacha: Faisnéis scoite a aisghabháil ó sheichimh', 'ka': 'მოდელის ანალიზაციისთვის კონტროლირებული მოქმედება: დისკრეტული ინფორმაცია კონტროლისგან მიღება', 'hu': 'Vezérelt feladatok modellelemzéshez: diszkrét információk lekérése a szekvenciákból', 'el': 'Ελεγχόμενες εργασίες για ανάλυση μοντέλων: Ανάκτηση διακριτών πληροφοριών από ακολουθίες', 'it': "Attività controllate per l'analisi dei modelli: recupero di informazioni discrete dalle sequenze", 'mk': 'Controlled tasks for model analysis: Retrieving discrete information from sequences', 'kk': 'Үлгі анализ үшін басқару тапсырмалары: дискретті мәліметті реттен алу', 'ms': 'Tugas terkawal untuk analisis model: Menerima maklumat diskret dari jujukan', 'ml': 'നിയന്ത്രിക്കപ്പെട്ട ജോലികള്\u200d', 'mt': 'Kompiti kkontrollati għall-analiżi tal-mudell: Inkisbu informazzjoni diskreta mis-sekwenzi', 'mn': 'Загварын шинжилгээний даалгаврыг удирдлага: дарааллаас ялгаатай мэдээллийг авах', 'no': 'Kontrollerte oppgåver for modelleanalyse: Hentar diskrete informasjon frå sekvensar', 'pl': 'Kontrolowane zadania do analizy modelu: Pobieranie dyskretnych informacji z sekwencji', 'ro': 'Sarcini controlate pentru analiza modelului: Preluarea de informații discrete din secvențe', 'sr': 'Kontrolirani zadatak za analizu modela: Uzimanje diskretnih informacija iz sekvencija', 'lt': 'Kontroliuojamos modelio analizės užduotys: atskiros informacijos gavimas iš sekų', 'si': 'නිර්මාණය විශ්ලේෂණය සඳහා පාලනය කරපු වැඩක්: ක්\u200dරමයෙන් විශේෂ තොරතුරු ලැබෙනවා', 'so': 'Shaqooyinka la ilaaliyey baaritaanka modelalka: Ka soo celinta macluumaadka kala duwan', 'sv': 'Kontrollerade uppgifter för modellanalys: Hämta diskret information från sekvenser', 'ta': 'மாதிரி ஆய்வுக்கான கட்டுப்படுத்தப்பட்ட பணிகள்:', 'ur': 'نمڈل تحلیل کے لئے کنٹرول کئے ہوئے کام: سطح سے مختلف معلومات لیا جاتا ہے', 'uz': 'Name', 'vi': 'Nhiệm vụ kiểm soát cho phân tích mẫu: thu thập thông tin riêng từ chuỗi', 'bg': 'Контролирани задачи за анализ на моделите: извличане на дискретна информация от последователности', 'hr': 'Kontrolirani zadatak za analizu modela: Uzimanje diskretnih informacija iz sekvencija', 'nl': 'Gecontroleerde taken voor modelanalyse: Afhalen van discrete informatie uit sequenties', 'da': 'Kontrollerede opgaver til modelanalyse: Hentning af diskrete oplysninger fra sekvenser', 'ko': '모델 분석의 제어 작업: 시퀀스에서 이산 정보 검색', 'fa': 'وظیفه\u200cهای کنترل برای تحلیل مدل: گیر دادن اطلاعات جدا از دستورات', 'id': 'Tugas terkendali untuk analisis model: Menerima informasi diskret dari urutan', 'af': 'Kontroleerde taak vir model analiseer: Ontvang diskrete inligting vanaf volgorde', 'de': 'Kontrollierte Aufgaben für die Modellanalyse: Abrufen diskreter Informationen aus Sequenzen', 'sq': 'Detyrat e kontrolluara për analizën e modelit: marrja e informacionit diskret nga sekuencat', 'am': 'ምርጫዎች', 'sw': 'Kazi zinazodhibitiwa kwa uchambuzi wa model: Retrieving information discrete from sequence', 'tr': 'Model analyzasy üçin kontrol edilen zadlar: disket maglumaty sequencerden alýar', 'bs': 'Kontrolirani zadatak za analizu modela: Uzimanje diskretnih informacija iz sekvencija', 'az': 'Model analizi üçün kontrol edilmiş işlər: Seçənlərdən diskrete məlumatlar alınır', 'bn': 'মডেল বিশ্লেষণের জন্য নিয়ন্ত্রণিত কাজ: সেকেন্ড থেকে বিভিন্ন তথ্য পুনরুদ্ধার করা হচ্ছে', 'ca': "Tasques controlades per a l'anàlisi del model: Obtenir informació discreta de seqüències", 'hy': 'Մոդելի վերլուծության վերահսկվող խնդիրները. հաջորդականություններից խիստ տեղեկատվություն ստանալը', 'cs': 'Řízené úlohy pro analýzu modelu: Získání diskrétních informací z sekvencí', 'et': 'Mudelianalüüsi kontrollitavad ülesanded: järjestustest eraldi teabe hankimine', 'fi': 'Kontrolloidut tehtävät mallinalyysiä varten: Yksittäisten tietojen hakeminen sekvensseistä', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': 'Get information tsawo daga sequences', 'he': 'משימות שולטות עבור ניתוח מודל: להשיג מידע דיסקרטי מהרצפים', 'sk': 'Nadzorovana opravila za analizo modela: Pridobivanje diskretnih informacij iz zaporedij', 'bo': 'Controlled tasks for model analysis: Retrieving discrete information from sequences'}
{'en': 'In recent years, the NLP community has shown increasing interest in analysing how deep learning models work. Given that large models trained on complex tasks are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of language. We propose a new set of such controlled tasks to explore a crucial aspect of natural language processing that has not received enough attention : the need to retrieve discrete information from sequences. We also study model behavior on the tasks with simple instantiations of Transformers and LSTMs. Our results highlight the beneficial role of decoder attention and its sometimes unexpected interaction with other components. Moreover, we show that, for most of the tasks, these simple models still show significant difficulties. We hope that the community will take up the analysis possibilities that our tasks afford, and that a clearer understanding of model behavior on the tasks will lead to better and more transparent models.', 'ar': 'في السنوات الأخيرة ، أظهر مجتمع البرمجة اللغوية العصبية اهتمامًا متزايدًا بتحليل كيفية عمل نماذج التعلم العميق. نظرًا لصعوبة فحص النماذج الكبيرة المدربة على المهام المعقدة ، فقد ركز بعض هذا العمل على المهام الخاضعة للرقابة التي تحاكي جوانب معينة من اللغة. نقترح مجموعة جديدة من مثل هذه المهام الخاضعة للرقابة لاستكشاف جانب مهم من معالجة اللغة الطبيعية التي لم تحظ بالاهتمام الكافي: الحاجة إلى استرداد المعلومات المنفصلة من التسلسلات. ندرس أيضًا سلوك النموذج في المهام باستخدام عمليات إنشاء بسيطة من المحولات و LSTMs. تسلط نتائجنا الضوء على الدور المفيد لانتباه وحدة فك التشفير وتفاعلها غير المتوقع أحيانًا مع المكونات الأخرى. علاوة على ذلك ، نظهر أنه بالنسبة لمعظم المهام ، لا تزال هذه النماذج البسيطة تظهر صعوبات كبيرة. نأمل أن يتبنى المجتمع إمكانيات التحليل التي توفرها مهامنا ، وأن يؤدي الفهم الأوضح لسلوك النموذج في المهام إلى نماذج أفضل وأكثر شفافية.', 'fr': "Ces dernières années, la communauté de la PNL a montré un intérêt croissant pour l'analyse du fonctionnement des modèles de deep learning. Étant donné que les grands modèles formés à des tâches complexes sont difficiles à inspecter, certains de ces travaux se sont concentrés sur des tâches contrôlées qui imitent des aspects spécifiques du langage. Nous proposons un nouvel ensemble de tâches contrôlées afin d'explorer un aspect crucial du traitement du langage naturel qui n'a pas reçu suffisamment d'attention\xa0: la nécessité de récupérer des informations discrètes à partir de séquences. Nous étudions également le comportement des modèles sur les tâches avec de simples instanciations de Transformers et de LSTM. Nos résultats mettent en évidence le rôle bénéfique de l'attention du décodeur et de son interaction parfois inattendue avec d'autres composants. De plus, nous montrons que, pour la plupart des tâches, ces modèles simples présentent encore des difficultés importantes. Nous espérons que la communauté saisira les possibilités d'analyse que nous offrent nos tâches, et qu'une meilleure compréhension du comportement des modèles sur les tâches conduira à des modèles meilleurs et plus transparents.", 'pt': 'Nos últimos anos, a comunidade de PNL tem demonstrado crescente interesse em analisar como funcionam os modelos de aprendizado profundo. Dado que grandes modelos treinados em tarefas complexas são difíceis de inspecionar, alguns desses trabalhos se concentraram em tarefas controladas que emulam aspectos específicos da linguagem. Propomos um novo conjunto de tais tarefas controladas para explorar um aspecto crucial do processamento de linguagem natural que não recebeu atenção suficiente: a necessidade de recuperar informações discretas de sequências. Também estudamos o comportamento do modelo nas tarefas com instanciações simples de Transformadores e LSTMs. Nossos resultados destacam o papel benéfico da atenção do decodificador e sua interação às vezes inesperada com outros componentes. Além disso, mostramos que, para a maioria das tarefas, esses modelos simples ainda apresentam dificuldades significativas. Esperamos que a comunidade aproveite as possibilidades de análise que nossas tarefas oferecem e que uma compreensão mais clara do comportamento do modelo nas tarefas leve a modelos melhores e mais transparentes.', 'es': 'En los últimos años, la comunidad de PNL ha mostrado un interés creciente en analizar cómo funcionan los modelos de aprendizaje profundo. Dado que los modelos grandes entrenados en tareas complejas son difíciles de inspeccionar, parte de este trabajo se ha centrado en tareas controladas que emulan aspectos específicos del lenguaje. Proponemos un nuevo conjunto de tareas controladas para explorar un aspecto crucial del procesamiento del lenguaje natural que no ha recibido suficiente atención: la necesidad de recuperar información discreta de las secuencias. También estudiamos el comportamiento del modelo en las tareas con instancias simples de Transformers y LSTM. Nuestros resultados destacan el papel beneficioso de la atención del decodificador y su interacción, a veces inesperada, con otros componentes. Además, demostramos que, para la mayoría de las tareas, estos modelos simples todavía presentan dificultades significativas. Esperamos que la comunidad acepte las posibilidades de análisis que ofrecen nuestras tareas y que una comprensión más clara del comportamiento de los modelos en las tareas conduzca a modelos mejores y más transparentes.', 'hi': 'हाल के वर्षों में, एनएलपी समुदाय ने विश्लेषण करने में बढ़ती रुचि दिखाई है कि गहरे सीखने के मॉडल कैसे काम करते हैं। यह देखते हुए कि जटिल कार्यों पर प्रशिक्षित बड़े मॉडल का निरीक्षण करना मुश्किल है, इस काम में से कुछ ने नियंत्रित कार्यों पर ध्यान केंद्रित किया है जो भाषा के विशिष्ट पहलुओं का अनुकरण करते हैं। हम प्राकृतिक भाषा प्रसंस्करण के एक महत्वपूर्ण पहलू का पता लगाने के लिए इस तरह के नियंत्रित कार्यों के एक नए सेट का प्रस्ताव करते हैं, जिसे पर्याप्त ध्यान नहीं मिला है: अनुक्रमों से असतत जानकारी प्राप्त करने की आवश्यकता। हम ट्रांसफॉर्मर और एलएसटीएम के सरल instantiations के साथ कार्यों पर मॉडल व्यवहार का भी अध्ययन करते हैं। हमारे परिणाम विकोडक ध्यान की लाभकारी भूमिका और अन्य घटकों के साथ इसकी कभी-कभी अप्रत्याशित बातचीत को उजागर करते हैं। इसके अलावा, हम दिखाते हैं कि, अधिकांश कार्यों के लिए, ये सरल मॉडल अभी भी महत्वपूर्ण कठिनाइयों को दिखाते हैं। हम आशा करते हैं कि समुदाय विश्लेषण की संभावनाओं को उठाएगा जो हमारे कार्यों को वहन करते हैं, और कार्यों पर मॉडल व्यवहार की स्पष्ट समझ बेहतर और अधिक पारदर्शी मॉडल का कारण बनेगी।', 'zh': '近年以来,NLP社区深于剖析模范之事,其理益大。 鉴大体之难检,集于言特定之受控务。 臣等条上此类受控务,以探自然语言处之未得其一要,须从序中检索离散信息。 因变压器与LSTM简实化来究其行事。 吾实见码器注意之益,及其时与他组件之意外交也。 此外明于多务,其形犹大难也。 愿社区受事析能,而益明知所行之善,明知之矣。', 'ru': 'В последние годы сообщество NLP проявляет все больший интерес к анализу того, как работают модели глубокого обучения. Учитывая, что крупные модели, обученные сложным задачам, трудно проверить, часть этой работы сосредоточена на контролируемых задачах, которые имитируют конкретные аспекты языка. Мы предлагаем новый набор таких контролируемых задач для изучения критического аспекта обработки естественного языка, которому не уделяется достаточного внимания: необходимости извлечения дискретной информации из последовательностей. Мы также изучаем поведение модели на задачах с помощью простых экземпляров Трансформаторов и LSTM. Наши результаты подчеркивают полезную роль внимания декодера и его иногда неожиданное взаимодействие с другими компонентами. Более того, мы показываем, что для большинства задач эти простые модели все еще демонстрируют значительные трудности. Мы надеемся, что сообщество воспользуется возможностями анализа, которые предоставляют наши задачи, и что более четкое понимание поведения модели на задачах приведет к лучшим и более прозрачным моделям.', 'ja': '近年、NLPコミュニティは、ディープラーニングモデルがどのように機能するかを分析することにますます関心を示している。 複雑なタスクで訓練された大規模なモデルは検査が困難であるため、この研究の一部は、言語の特定の側面をエミュレートする管理されたタスクに焦点を当てています。 私たちは、十分な注意を払われていない自然言語処理の重要な側面を探求するために、そのような制御されたタスクの新しいセットを提案します。すなわち、シーケンスから離散的な情報を取得する必要性です。 また、トランスフォーマーとLSTMの単純なインスタンス化を使用して、タスクのモデル挙動を研究します。 私たちの結果は、デコーダー注意の有益な役割と、他のコンポーネントとの予期せぬ相互作用を強調しています。 さらに、私たちは、ほとんどのタスクで、これらの単純なモデルは依然として大きな困難を示していることを示しています。 コミュニティが私たちのタスクがもたらす分析の可能性を取り上げ、タスクのモデル行動をより明確に理解することで、より良い、より透明性の高いモデルが生まれることを願っています。', 'ga': 'Le blianta beaga anuas, léirigh an pobal NLP suim mhéadaithe in anailís a dhéanamh ar conas a oibríonn samhlacha foghlama domhain. Ós rud é gur deacair iniúchadh a dhéanamh ar mhúnlaí móra atá oilte ar thascanna casta, díríodh cuid den obair seo ar thascanna rialaithe a dhéanann aithris ar ghnéithe ar leith den teanga. Molaimid sraith nua de thascanna rialaithe den sórt sin chun gné ríthábhachtach de phróiseáil teanga nádúrtha a iniúchadh nach bhfuil dóthain airde tugtha uirthi: an gá atá le faisnéis scoite a aisghabháil ó sheichimh. Déanaimid staidéar freisin ar iompraíocht eiseamláireach ar na tascanna le modhnuithe simplí Trasfhoirmeoirí agus LSTManna. Aibhsíonn ár dtorthaí an ról tairbheach a bhaineann le haird an díchódóra agus an idirghníomhaíocht a bhíonn aige uaireanta gan choinne le comhpháirteanna eile. Thairis sin, léirímid, don chuid is mó de na tascanna, go léiríonn na samhlacha simplí seo deacrachtaí suntasacha fós. Tá súil againn go nglacfaidh an pobal leis na féidearthachtaí anailíse atá ar fáil dár gcuid tascanna, agus go dtiocfaidh múnlaí níos fearr agus níos trédhearcaí de bharr tuiscint níos soiléire ar iompar eiseamláireach ar na tascanna.', 'ka': 'შემდეგ წლის განმავლობაში NLP საზოგადოება აჩვენეთ უფრო მეტი ინტერესტის ანალიზაციაში თუ რამდენი დიდი მოდელები მუშაობს. რადგან კომპლექსიკური საქმედების შესაბამისი დიდი მოდელები ძალიან რთულია დაინტექტირება, ამ საქმედების ზოგიერთი კონტროლური საქმედებზე დაყენება, რომლებიც ენის განსაკუთრე ჩვენ ამისთვის კონტროლური დავალების ახალი სექტი, რომელიც არ მივიღეთ მნიშვნელოვანი ენის პროცესის გასაკეთებელი აპექტი, რომელიც არ მივიღეთ მნიშვნელოვანი ინფორმაცია: სის ჩვენ ასევე მოდელური ქცევის შესახებ დავასწავლობთ ტრანფორმეტრების და LSTMs-ის მარტივი ინტენციაციებით. ჩვენი წარმოდგენები გააღწევენ ბენექტიური პროლემა, რომელიც აღწევენ სხვა კომპონტენტებით, და რომელიც განახოვრებული ინტერფექცია. დამატებით, ჩვენ ჩვენ აჩვენებთ, რომ, უფრო მეტი დავალებებისთვის, ეს მარტივი მოდელები უკვე მნიშვნელოვანი რთული ჩვენებს. ჩვენ გვემედით, რომ საზოგადოებო შესაძლებლობების ანალიზაციის შესაძლებლობა, რომელიც ჩვენი დავაკეთება, და რომ მოდელური ქცევის უფრო უფრო წარმოიცნობა მოდელური მოდელზე იქნება უ', 'el': 'Τα τελευταία χρόνια, η κοινότητα έχει δείξει αυξανόμενο ενδιαφέρον για την ανάλυση του τρόπου λειτουργίας των μοντέλων βαθιάς μάθησης. Δεδομένου ότι τα μεγάλα μοντέλα εκπαιδευμένα σε πολύπλοκες εργασίες είναι δύσκολο να επιθεωρηθούν, ορισμένα από αυτά τα έργα έχουν επικεντρωθεί σε ελεγχόμενες εργασίες που μιμούνται συγκεκριμένες πτυχές της γλώσσας. Προτείνουμε ένα νέο σύνολο τέτοιων ελεγχόμενων εργασιών για να διερευνήσουμε μια κρίσιμη πτυχή της επεξεργασίας φυσικής γλώσσας που δεν έχει λάβει αρκετή προσοχή: την ανάγκη ανάκτησης διακριτών πληροφοριών από ακολουθίες. Μελετάμε επίσης τη συμπεριφορά μοντέλων στις εργασίες με απλές στιγμιότητες μετασχηματιστών και LSTMs. Τα αποτελέσματά μας αναδεικνύουν τον ευεργετικό ρόλο της προσοχής αποκωδικοποιητή και τις μερικές φορές απρόσμενες αλληλεπιδράσεις του με άλλα συστατικά. Επιπλέον, αποδεικνύουμε ότι, για τα περισσότερα από τα καθήκοντα, αυτά τα απλά μοντέλα εξακολουθούν να παρουσιάζουν σημαντικές δυσκολίες. Ελπίζουμε ότι η κοινότητα θα εκμεταλλευτεί τις δυνατότητες ανάλυσης που παρέχουν τα καθήκοντά μας, και ότι μια σαφέστερη κατανόηση της συμπεριφοράς του μοντέλου στις εργασίες θα οδηγήσει σε καλύτερα και πιο διαφανή μοντέλα.', 'hu': 'Az elmúlt években az NLP közösség egyre nagyobb érdeklődést mutatott a mélytanulási modellek működésének elemzése iránt. Tekintettel arra, hogy a komplex feladatokra képzett nagyméretű modelleket nehéz ellenőrizni, ennek a munkának egy része olyan ellenőrzött feladatokra összpontosított, amelyek a nyelv speciális aspektusait emulálják. Az ilyen ellenőrzött feladatok új halmazát javasoljuk, hogy feltárjuk a természetes nyelvfeldolgozás egyik kulcsfontosságú aspektusát, amely nem kapott elegendő figyelmet: a szekvenciákból diszkrét információk visszanyerésének szükségességét. Tanulmányozzuk továbbá a transzformátorok és LSTMs egyszerű instanciálásával végzett feladatok modellviselkedését. Eredményeink kiemelik a dekóder figyelem jótékony szerepét és annak néha váratlan interakcióját más komponensekkel. Ezenkívül megmutatjuk, hogy a legtöbb feladat esetében ezek az egyszerű modellek továbbra is jelentős nehézségeket mutatnak. Reméljük, hogy a közösség kihasználja a feladataink által biztosított elemzési lehetőségeket, és hogy a modellviselkedés tisztább megértése jobb és átláthatóbb modellekhez vezet.', 'it': "Negli ultimi anni, la comunità PNL ha mostrato un crescente interesse nell'analizzare come funzionano i modelli di deep learning. Dato che i grandi modelli formati su compiti complessi sono difficili da ispezionare, alcuni di questi lavori si sono concentrati su compiti controllati che emulano aspetti specifici del linguaggio. Proponiamo una nuova serie di compiti così controllati per esplorare un aspetto cruciale dell'elaborazione del linguaggio naturale che non ha ricevuto abbastanza attenzione: la necessità di recuperare informazioni discrete dalle sequenze. Studiamo anche il comportamento modello sui compiti con semplici istanziazioni di Transformers e LSTMs. I nostri risultati evidenziano il ruolo benefico dell'attenzione del decoder e la sua interazione talvolta inaspettata con altri componenti. Inoltre, mostriamo che, per la maggior parte dei compiti, questi semplici modelli presentano ancora notevoli difficoltà. Speriamo che la comunità sfrutti le possibilità di analisi che i nostri compiti offrono e che una comprensione più chiara del comportamento modello sui compiti porti a modelli migliori e più trasparenti.", 'kk': 'Соңғы жылдарда NLP компаниясы қанша ділік оқыту үлгілерін анализдеу үшін көп қызықты көрсетті. Комплекс тапсырмалардың үлкен үлгі моделдері тексеру қиын болса, бұл жұмысының кейбірі тілдің ерекше аспектерін бақылайтын тапсырмаларына назар аударды. Біз бұл бақылаған тапсырмалардың жаңа бөлігін жеткілікті тіл процессерінің маңызды бөлігін зерттеу үшін ұсынамыз: тәртібінен дискретті мәліметті алу керек. Сонымен қатар, Трансформация және LSTMs тапсырмалардың қарапайым институцияларының үлгі әрекеттерін зерттейміз. Біздің нәтижелеріміз декодердің маңызды рөлін және кейбірде оның күтпеген басқа компоненттермен байланыстыруға болады. Көпшілігінің көпшілігінде бұл қарапайым үлгілер әлі маңызды мәселелерді көрсетеді. Біз қоғамдық тапсырмаларымыздың керек анализ мүмкіндіктерін алып тастайды деп үміттенеміз, және тапсырмалардың үлгі әрекеттерінің түсініктері жақсы және мөлдірлікті моделдеріне кө', 'lt': 'Pastaraisiais metais NLP bendruomenė vis labiau suinteresuota analizuoti, kaip veikia gilaus mokymosi modeliai. Atsižvelgiant į tai, kad sunku patikrinti didelius modelius, parengtus sudėtingomis užduotimis, kai kurie iš šių darbų buvo sutelkti į kontroliuojamas užduotis, kurios imituoja konkrečius kalbos aspektus. We propose a new set of such controlled tasks to explore a crucial aspect of natural language processing that has not received enough attention: the need to retrieve discrete information from sequences.  Mes taip pat tiriame modelio elgesį užduočių atžvilgiu su paprastomis Transformers ir LSTM instancijomis. Mūsų rezultatai rodo naudingą dekoderių dėmesio vaidmenį ir kartais netikėtą sąveiką su kitais komponentais. Moreover, we show that, for most of the tasks, these simple models still show significant difficulties.  Tikimės, kad bendruomenė pasinaudos analizės galimybėmis, kurias mums suteikia mūsų užduotys, ir kad aiškesnis modelio elgesio su užduotimis supratimas leis sukurti geresnius ir skaidresnius modelius.', 'mk': 'In recent years, the NLP community has shown increasing interest in analysing how deep learning models work.  Со оглед на тоа што големите модели обучени за комплексни задачи се тешки да се проверат, некои од овие работи се фокусираа на контролирани задачи кои емулираат специфични аспекти на јазикот. Предложуваме нов набор такви контролирани задачи за истражување на клучен аспект на природното обработување јазик кој не доби доволно внимание: потребата да се добијат дискретни информации од секвенциите. Ние исто така студираме моделно однесување на задачите со едноставни инстанции на Трансформери и ЛСТМ. Нашите резултати ја истакнуваат корисната улога на вниманието на декодерот и нејзината понекогаш неочекувана интеракција со другите компоненти. Покрај тоа, покажуваме дека, за повеќето од задачите, овие едноставни модели сé уште покажуваат значителни тешкотии. Се надеваме дека заедницата ќе ги искористи можностите за анализа кои нашите задачи ги дозволуваат, и дека појасно разбирање на моделното однесување на задачите ќе доведе до подобри и потранспарентни модели.', 'ms': 'Dalam tahun-tahun terakhir, komuniti NLP telah menunjukkan kepentingan semakin meningkat dalam menganalisis bagaimana model belajar mendalam berfungsi. Oleh kerana model besar dilatih pada tugas kompleks adalah sukar untuk diperiksa, sebahagian dari kerja ini telah fokus pada tugas kawal yang meniru aspek khusus bahasa. Kami cadangkan set baru tugas kawal seperti ini untuk mengeksplorasi aspek penting pemprosesan bahasa alam yang tidak menerima perhatian yang cukup: perlukan untuk mendapatkan maklumat yang diambil dari urutan. Kami juga mempelajari perilaku model pada tugas dengan kejadian sederhana Transformers dan LSTMs. Hasil kami menyatakan peran berguna perhatian penyahkod dan kadang-kadang interaksi yang tidak dijangka dengan komponen lain. Selain itu, kami menunjukkan bahawa, untuk kebanyakan tugas, model sederhana ini masih menunjukkan kesulitan yang signifikan. Kami berharap komuniti akan mengambil kemungkinan analisis yang tugas kita mampu, dan bahawa pemahaman lebih jelas perilaku model pada tugas akan membawa kepada model yang lebih baik dan lebih transparan.', 'ml': 'കഴിഞ്ഞ വര്\u200dഷങ്ങളില്\u200d, NLP സമൂഹത്തിന്റെ ആഴത്തില്\u200d പഠിക്കുന്ന മോഡലുകള്\u200d എങ്ങനെ പ്രവര്\u200dത്തിക്കുന്നു സങ്കീര്\u200dണ്ണമായ ജോലികളില്\u200d പഠിപ്പിക്കപ്പെട്ട വലിയ മോഡലുകള്\u200d പരിശോധിക്കാന്\u200d ബുദ്ധിമുട്ടാണെന്ന് കാണിച്ചിട്ടുണ്ടെങ്കി ഇത്തരം നിയന്ത്രിക്കപ്പെട്ട ജോലികളുടെ കൂട്ടത്തില്\u200d നാം പുതിയൊരു സജ്ജീകരിക്കുന്നു. സ്വാഭാവിക ഭാഷ പ്രക്രിയയുടെ പ്രധാനപ്പെട്ട ഭ ട്രാന്\u200dസ്ഫോര്\u200dമാരുടെയും എളുപ്പമുള്ള ട്രാന്\u200dസ്ഫോര്\u200dമാരുടെയും എസ്റ്റിഎസ്എസിസിന്\u200dറെയും പ്രവര്\u200dത്തനങ നമ്മുടെ ഫലങ്ങള്\u200d ഡെക്കോഡെര്\u200d ശ്രദ്ധിക്കുന്നതിന്റെ പ്രയോജനകരമായ ഭൂമിയെയും ചിലപ്പോള്\u200d പ്രതീക്ഷിക്കാത്ത വിഭാ പിന്നെ ഞങ്ങളത് കാണിക്കുന്നു, പ്രവര്\u200dത്തനങ്ങളില്\u200d മിക്കവാറും, ഈ സാധാരണ മോഡലുകള്\u200d ഇപ്പോഴും വലിയ പ്രയാസമുണ്ട്. നമ്മുടെ ജോലികള്\u200dക്ക് കഴിവുള്ള അന്വേഷണങ്ങള്\u200d നമ്മുടെ സമൂഹത്തിന് എടുക്കുമെന്ന് നമ്മുടെ പ്രതീക്ഷിക്കുന്നു. ജോലികളില്\u200d മാതൃകയുടെ പ്രവര്\u200d', 'mt': 'In recent years, the NLP community has shown increasing interest in analysing how deep learning models work.  Minħabba li mudelli kbar imħarrġa fuq kompiti kumplessi huma diffiċli biex jiġu spezzjonati, xi wħud minn dan ix-xogħol iffoka fuq kompiti kkontrollati li jimulaw aspetti speċifiċi tal-lingwa. Aħna nipproponu sett ġdid ta’ kompiti kkontrollati bħal dawn biex jesploraw aspett kruċjali tal-ipproċessar tal-lingwi naturali li ma rċeviex biżżejjed attenzjoni: il-ħtieġa li tinkiseb informazzjoni diskreta mis-sekwenzi. Aħna nistudjaw ukoll imġiba mudell dwar il-kompiti b’istanzjazzjonijiet sempliċi ta’ Transformers u LSTMs. Our results highlight the beneficial role of decoder attention and its sometimes unexpected interaction with other components.  Barra minn hekk, nuru li, għall-biċċa l-kbira tal-kompiti, dawn il-mudelli sempliċi għadhom juru diffikultajiet sinifikanti. We hope that the community will take up the analysis possibilities that our tasks afford, and that a clearer understanding of model behavior on the tasks will lead to better and more transparent models.', 'mn': 'Сүүлийн жилийн дотор НLP-ын нийгэм суралцах загварууд хэр гүн гүнзгий ажилладаг талаар шинжилгээнд их сонирхолтой болж байна. Комплексийн ажил дээр сургалтын том загваруудыг шалгахад хэцүү байдаг учир зарим нь энэ ажил хэлний тодорхой асуудлыг шалгаж буй хяналттай ажил дээр төвлөрсөн. Бид тийм шинэ удирдлагатай задалгаануудыг санал болгож, хангалттай анхаарлаа авч чадахгүй байгалийн хэл үйлдвэрлэлийн чухал асуудлыг судлах хэрэгтэй. Бид мөн Трансформ болон ЛСТMs-ийн энгийн ажил дээр загварын загварын үйл ажиллагааг судалдаг. Бидний үр дүнд анхаарлыг сайжруулахын тулд хэрэгтэй нөлөө болон заримдаа бусад хэсэгтэй харилцааны тухай тайлбарладаг. Мөн бид ихэнх ажлын хувьд эдгээр энгийн загварууд маш их хэцүү байгааг харуулж байна. Бид нийгэм бидний ажлын төлөвлөгөөний шинжилгээний боломжуудыг авах боломжтой гэж найдаж байна. Тэдгээр ажлын загварын загварын илүү тодорхой ойлголт нь илүү, илүү тодорхой загвар руу хүргэж чадна.', 'no': 'I siste år har NLP-samfunnet vist økt interesse på å analysera kor dype læringsmodeller fungerer. Dette er vanskeleg å kontrollere store modeller på komplekse oppgåver. Noen av dette arbeidet har fokusert på kontrollerte oppgåver som emulerer spesifikke aspektar på språk. Vi foreslår eit nytt sett av slike kontrollerte oppgåver for å utforska eit viktig aspekt av naturspråkshandtering som ikkje har fått nok oppmerksomhet: må henta diskrete informasjon frå sekvensar. Vi studerer også modellåtferd på oppgåvene med enkle instansasjonar av transformerer og LSTMs. Resultatet våre markerer den nyttige rolla for dekoder oppmerksomheten og det noen ganger uventa interaksjon med andre komponentar. I tillegg viser vi at for dei fleste av oppgåva viser desse enkle modelane fortsatt signifikante vanskeleghetar. Vi håper at samfunnet vil ta opp muligheten for analyse som oppgåver våre tillate, og at ein klarere forståelse av modellen på oppgåva vil føre til bedre og meir gjennomsiktige modeller.', 'pl': 'W ostatnich latach społeczność NLP wykazała coraz większe zainteresowanie analizą funkcjonowania modeli głębokiego uczenia. Biorąc pod uwagę fakt, że duże modele przeszkolone na złożonych zadaniach są trudne do sprawdzenia, niektóre z tych prac koncentrowały się na kontrolowanych zadaniach, które emulują konkretne aspekty języka. Proponujemy nowy zestaw takich kontrolowanych zadań, aby zbadać kluczowy aspekt przetwarzania języka naturalnego, który nie poświęcił wystarczającej uwagi: potrzebę pobierania dyskretnych informacji z sekwencji. Badamy również zachowanie modeli na zadaniach z prostymi instancjami Transformerów i LSTMów. Nasze wyniki podkreślają korzystną rolę uwagi dekodera i jego niekiedy nieoczekiwaną interakcję z innymi komponentami. Ponadto pokazujemy, że w przypadku większości zadań te proste modele nadal wykazują znaczne trudności. Mamy nadzieję, że społeczność skorzysta z możliwości analizy, które dają nam nasze zadania, a lepsze zrozumienie zachowań modeli w zadaniach doprowadzi do lepszych i bardziej przejrzystych modeli.', 'ro': 'În ultimii ani, comunitatea PNL a arătat interes tot mai mare în analiza modului în care funcționează modelele de învățare profundă. Având în vedere că modelele mari instruite pe sarcini complexe sunt dificil de inspectat, unele dintre aceste lucrări s-au concentrat pe sarcini controlate care emulează aspecte specifice ale limbajului. Propunem un nou set de astfel de sarcini controlate pentru a explora un aspect crucial al procesării limbajului natural care nu a primit suficientă atenție: necesitatea de a recupera informații discrete din secvențe. De asemenea, studiem comportamentul modelului asupra sarcinilor cu instanțări simple de Transformers și LSTMs. Rezultatele noastre evidențiază rolul benefic al atenției decodorului și interacțiunea sa uneori neașteptată cu alte componente. Mai mult decât atât, arătăm că, pentru majoritatea sarcinilor, aceste modele simple prezintă încă dificultăți semnificative. Sperăm că comunitatea va profita de posibilitățile de analiză pe care le oferă sarcinile noastre și că o înțelegere mai clară a comportamentului model pe sarcini va duce la modele mai bune și mai transparente.', 'sr': 'Za poslednje godine, zajednica NLP pokazala je povećanje interesa za analizu koliko duboko funkcioniše modeli učenja. S obzirom na to da su veliki modeli obučeni na kompleksnom zadatku teško provjeriti, neki od ovog rada se fokusirali na kontrolirane zadatke koje emuliraju specifične aspekte jezika. Predlažemo novi set takvih kontroliranih zadataka da istražimo ključni aspekt prirodnog obradivanja jezika koji nije dobio dovoljno pažnje: potrebu da dobijemo diskretne informacije iz sekvencija. Istražujemo i modelo ponašanje na zadatkima sa jednostavnim instancijama transformera i LSTMs. Naši rezultati naglašavaju korisnu ulogu pažnje dekodera i njegove ponekad neočekivane interakcije sa drugim komponentima. Osim toga, pokazujemo da za većinu zadataka ovi jednostavni modeli još uvek pokazuju značajne probleme. Nadamo se da će zajednica uzeti mogućnosti analize koje su nam zadaci priuštili i da će jasnije razumijevanje model a ponašanja na zadacima dovesti do boljih i transparentnih modela.', 'sv': 'De senaste åren har NLP-samhället visat ett ökande intresse för att analysera hur djupinlärningsmodeller fungerar. Med tanke på att stora modeller utbildade på komplexa uppgifter är svåra att inspektera, har en del av detta arbete fokuserat på kontrollerade uppgifter som efterliknar specifika aspekter av språket. Vi föreslår en ny uppsättning av sådana kontrollerade uppgifter för att utforska en avgörande aspekt av naturlig språkbehandling som inte har fått tillräckligt med uppmärksamhet: behovet av att hämta diskret information från sekvenser. Vi studerar även modellbeteende på uppgifterna med enkla instantieringar av Transformers och LSTMs. Våra resultat belyser avkodarens positiva roll och dess ibland oväntade interaktion med andra komponenter. Dessutom visar vi att dessa enkla modeller fortfarande uppvisar betydande svårigheter för de flesta av uppgifterna. Vi hoppas att samhället tar tillvara de analysmöjligheter som våra uppgifter ger oss, och att en tydligare förståelse för modellbeteende på uppgifterna leder till bättre och mer transparenta modeller.', 'si': 'අන්තිම අවුරුදු වලින්, NLP සමාජය පෙන්වන්නේ කොච්චර ගොඩක් ඉගෙනගන්න ප්\u200dරශ්නයක් විශ්ලේෂණය ක පරීක්ෂණය කරන්න අමාරුයි විශේෂ වැඩේ ප්\u200dරධානය කරලා තියෙන්නේ, මේ වැඩේ සමහර දෙයක් භාෂාවේ විශේෂ ප්\u200dරතිකාරයක් පර අපි අළුත් සැකසුම් සම්බන්ධ වැඩක් ප්\u200dරශ්න කරනවා ස්වභාවික භාෂාව ප්\u200dරශ්නයක් ගැන ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්න, ඒ වගේම අපි අධ්\u200dයානය කරන්නේ මොඩොල් වැඩක් අධ්\u200dයානය කරන්නේ වැඩක් එක්ක සාමාන්\u200dය වැඩක් සහ LSTMs වලින්. අපේ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරයෝජනය අවධානය සහ සමහර වෙලාවෙන් අනතුරු අවධානය සමඟ ප්\u200dරයෝජනය ප්\u200dරත ඒවගේම, අපි පෙන්වන්නේ, ගොඩක් වැඩක් වෙනුවෙන්, මේ සාමාන්\u200dය මොඩල් තාමත් වැඩිය අමාරුවක් පෙන්වන්න අපි බලාපොරොත්තු කරනවා අපේ විශ්ලේෂණ අවස්ථාවක් අරගෙන යනවා කියලා, අපේ වැඩක් අරගෙන ඉන්න පුළුවන් විශ්ලේෂණ අවස්ථාවක්', 'so': 'Sannadihii ugu danbeeyey, bulshada NLP waxay muuqatay korsocod xiiso ku saabsan qaababka waxbarashada ee mool dheer ka shaqeeya. Sida darteed samooyin waaweyn oo lagu tababariyey shaqooyinka adag waa adag tahay in laga baaraandegayo, qaar ka mid ah shaqadaas ayaa ku kalsoonaaday shaqaalaha la maamulay, kuwaas oo qabanqaabiya qayb gaar ah oo luuqada ku saabsan. Waxaan soo jeedaynaa shuqullo cusub oo la maamulay si aan u baarayno dhinac muhiim ah oo ka baaraandegista baaritaanka luqada dabiicadda ah oo aan u helin daryeel ku filan: baahida u baahan in laga helo macluumaad kala duwan. Sidoo kale waxaynu sidoo kale ka baranaa dabeecada sameynta shaqaalaha si fudud ah oo lagu sameeyo turjumayaasha iyo LSTMs. Abaalkayaga ayaa iftiimiya qaybta faa’iidada ah ee dareemada kharashka iyo marmarka qaarkood oo aan filanayn la xiriira qeybaha kale. Sidoo kale waxaynu muujinnaa in, shuqullada badan, modelladan fudud weli waxay muuqataa dhibaatooyin badan. Waxaan rajaynaynaa in bulshada ay sameynaysaa suurtagalka baaritaanka shaqaalahayaga ay awoodaan, iyo in garashada dabeecada muuqashada ee shuqullada lagu sameeyo uu ku hoggaamiyo qaabab aad u fiican oo muuqda ah.', 'ta': 'சமீபத்திய ஆண்டுகளில், NLP சமூகத்தில் எவ்வாறு ஆழமான கற்றல் மாதிரிகள் செயல்படுகிறது என்பதை அறிவிக்கும் ஆர்வம் அதி Given that large models trained on complex tasks are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of language.  நாம் புதிய கட்டுப்படுத்தப்பட்ட பணிகளை தேர்ந்தெடுக்க இயல்பான மொழி செயல்பாட்டின் முக்கியமான பகுதி மாற்றுபவர்கள் மற்றும் LSTMs. எளிதான நிகழ்வுகளுடன் பணிகளின் மாதிரி நடத்தைகளை நாம் கற்றுக்கொள்கிறோம். நம்முடைய முடிவுகள் மற்றும் மற்ற பொருளுடன் எதிர்பாராத இடைவெளிப்பாடு மற்றும் குறியீட்டு கவனத்தின் பயனுள்ள பங் மேலும், நாம் பெரும்பாலான செயல்களுக்கு, இந்த எளிய மாதிரிகள் இன்னும் முக்கியமான பிரச்சனைகளை காண்பிக நாங்கள் நம்முடைய செயல்கள் சொந்தமானது என்று ஒரு சமுதாயத்தை ஆராய்வு எடுத்துக் கொள்ள வேண்டும் என்று நம்புகிறோம். பணிகளில் ஒரு தெளிவான மாத', 'ur': 'اگلے سالوں میں، NLP کمونٹی نے کس طرح عمیق سیکھنے کی مدلکوں کا کام کرتا ہے تحقیق کرنے کے لئے اضافہ کیا ہے۔ اس وجہ سے کہ پیچیدہ کاموں پر آموزش کی بڑی نمونڈلیاں مشکل ہیں، اس کام میں سے کچھ ایسے کاموں پر کنٹرول کی کوشش کی ہے جو زبان کی مخصوص اندازوں کو اثبات کرتے ہیں. ہم ایسے کنٹرول کئے ہوئے کاموں کے نو سٹے کو پیشنهاد کرتے ہیں کہ طبیعی زبان پردازی کے ایک اہم حصہ کا تحقیق کریں جو کافی توجه نہیں ملی: سٹریل سے مختلف معلومات حاصل کرنے کی ضرورت ہے۔ ہم نے بھی ماڈل رفتاری کا تحقیق کرلیا ہے تاسکیوں پر ساده ترنسفور اور LSTMs کے ساتھ ہمارے نتیجے دھوکا دینے کے مفید رغم اور اس کی بعض وقت غیر انتظار کی تعامل دوسرے رغتوں کے ساتھ تسبیح کرتے ہیں۔ اور ہم دکھاتے ہیں کہ اکثر کاموں کے لئے یہ سادھے موڈل ابھی بڑے مشکلات دکھاتے ہیں۔ ہم امید رکھتے ہیں کہ کمونٹی ان تحلیل امکانات کو اٹھائے گی جنہیں ہمارے کاموں کو پہنچا سکتی ہیں اور یہ کہ ان کاموں پر موڈل رفتار کا زیادہ واضح سمجھنا بہتر اور زیادہ روشن موڈل کو پہنچا سکتی ہے.', 'uz': "In recent years, the NLP community has shown increasing interest in analysing how deep learning models work.  Bu ishlarda murakkab vazifalar o'rganilgan katta modellar taʼminlovchi bo'lganligini tekshirish qiyin edi. Bu bir necha ishlarda tillarning specific aspektlarini yaratish uchun boshqaruvchi vazifalarni foydalanadi. Biz bunday boshqaruv vazifalarni o'rganish uchun asl tilning jarayonlarining muhim aspektlarini qidirish uchun yangi boshqa vazifalarni talab qilamiz. Qaytadan tez maʼlumotni olish kerak. Biz vazifalar bilan oddiy tashkilotlar va LSTMs bilan ishlarda model xuddi o'rganamiz. Bizning natijalarimiz foydalanuvchi xususiyatlarini va ba'zida kutilmagan narsa boshqa komponentlar bilan ishlash kerak. Ko'pchilik vazifalar uchun bu oddiy modellar ham juda muhim muammolar ko'rsatadi. Bu jamiyat vazifalamizning vazifalari qo'llanmagan narsalarni aniqlash imkoniyatlarini o'rganamiz va vazifalarga model xususiyatlarini yaxshi va ko'proq shaxsiy modellarga aytib beradi.", 'vi': 'Trong những năm gần đây, cộng đồng New York đã chú ý hơn nhiều trong việc phân tích cách sử dụng các mô hình học sâu. Vì rất khó kiểm tra các mô hình lớn được huấn luyện về các công việc phức tạp, một số công việc này đã tập trung vào các công việc kiểm soát, noi theo các khía cạnh cụ thể của ngôn ngữ. Chúng tôi đề xuất một loạt các nhiệm vụ được kiểm soát mới để khám phá một khía cạnh quan trọng trong việc xử lý ngôn ngữ tự nhiên chưa được chú ý đủ: nhu cầu thu hồi những thông tin mật từ các chuỗi. Chúng tôi cũng nghiên cứu hành vi mô hình về các công việc với các biến hình transformer và LSTM đơn giản. Kết quả của chúng tôi nhấn mạnh vai trò tích cực của sự chú ý giải mã và đôi khi là tác động bất ngờ với các thành phần khác. Chúng tôi cho thấy, trong hầu hết các nhiệm vụ, những mô hình đơn giản này vẫn có những khó khăn lớn. Chúng tôi hy vọng rằng cộng đồng sẽ nắm bắt các khả năng phân tích mà nhiệm vụ của chúng tôi cho phép, và một nhận thức rõ ràng về hành vi mô hình về các nhiệm vụ sẽ dẫn đến những mô hình tốt hơn và trong suốt.', 'bg': 'През последните години общността на НЛП показа нарастващ интерес към анализирането на начина, по който работят моделите на дълбоко обучение. Като се има предвид, че големите модели, обучени по сложни задачи, са трудни за проверка, част от тази работа е фокусирана върху контролирани задачи, които имитират специфични аспекти на езика. Предлагаме нов набор от такива контролирани задачи, за да се изследва решаващ аспект на обработката на естествения език, който не е получил достатъчно внимание: необходимостта от извличане на дискретна информация от последователности. Изследваме и моделното поведение на задачите с прости инстанции на трансформатори и ЛТМ. Нашите резултати подчертават благоприятната роля на вниманието на декодера и понякога неочакваното му взаимодействие с други компоненти. Освен това показваме, че за повечето от задачите тези прости модели все още показват значителни трудности. Надяваме се, че общността ще се възползва от възможностите за анализ, които нашите задачи позволяват, и че по-ясно разбиране на моделното поведение по задачите ще доведе до по-добри и по-прозрачни модели.', 'da': 'I de seneste år har NLP-fællesskabet vist stigende interesse for at analysere, hvordan deep learning modeller fungerer. I betragtning af at store modeller, der er trænet i komplekse opgaver, er vanskelige at inspicere, har nogle af dette arbejde fokuseret på kontrollerede opgaver, der efterligner specifikke aspekter af sproget. Vi foreslår et nyt sæt af sådanne kontrollerede opgaver for at udforske et afgørende aspekt af naturlig sprogbehandling, som ikke har fået tilstrækkelig opmærksomhed: behovet for at hente diskrete oplysninger fra sekvenser. Vi studerer også modeludfærd på opgaverne med enkle instantieringer af Transformers og LSTMs. Vores resultater fremhæver den gavnlige rolle af dekoder opmærksomhed og dens undertiden uventede interaktion med andre komponenter. Desuden viser vi, at disse enkle modeller for de fleste opgaver stadig viser betydelige vanskeligheder. Vi håber, at samfundet vil udnytte de analysemuligheder, som vores opgaver giver, og at en klarere forståelse af modeladfærd på opgaverne vil føre til bedre og mere gennemsigtige modeller.', 'hr': 'Za poslednje godine, zajednica NLP pokazala je veći interes za analiziranje koliko dubokih modela učenja rade. S obzirom na to da je teško provjeriti velike modele obučene na složene zadatke, neki od ovog rada usredotočili su se na kontrolirane zadatke koje emuliraju specifične aspekte jezika. Predlažemo novu skupu takvih kontroliranih zadataka kako bi istražili ključni aspekt prirodnog obradivanja jezika koji nije dobio dovoljno pažnje: potrebu za otkupljanje diskretnih informacija iz sekvencija. Istražujemo i modelo ponašanje na zadatkima s jednostavnim instancijama transformera i LSTMs. Naši rezultati naglašavaju korisnu ulogu pozornosti dekodera i njegove ponekad neočekivane interakcije s drugim komponentima. Osim toga, pokazujemo da za većinu zadataka ovi jednostavni modeli još uvijek pokazuju značajne probleme. Nadamo se da će zajednica uzeti mogućnosti analize koje su nam zadaci priuštili i da će jasnije razumijevanje model a ponašanja na zadacima dovesti do boljih i transparentnih modela.', 'nl': 'De afgelopen jaren heeft de NLP gemeenschap steeds meer interesse getoond om te analyseren hoe deep learning modellen werken. Aangezien grote modellen getraind op complexe taken moeilijk te inspecteren zijn, is een deel van dit werk gericht op gecontroleerde taken die specifieke aspecten van taal emuleren. We stellen een nieuwe set van dergelijke gecontroleerde taken voor om een cruciaal aspect van natuurlijke taalverwerking te onderzoeken dat onvoldoende aandacht heeft gekregen: de noodzaak om discrete informatie uit sequenties te halen. We bestuderen ook modelgedrag op de taken met eenvoudige instanties van Transformers en LSTMs. Onze resultaten benadrukken de gunstige rol van decoderaandacht en de soms onverwachte interactie met andere componenten. Bovendien laten we zien dat deze eenvoudige modellen voor de meeste taken nog steeds aanzienlijke moeilijkheden vertonen. We hopen dat de community de analysemogelijkheden die onze taken bieden, zal aangrijpen en dat een duidelijker begrip van modelgedrag op de taken zal leiden tot betere en transparantere modellen.', 'de': 'In den letzten Jahren hat die NLP-Community zunehmendes Interesse an der Analyse der Funktionsweise von Deep Learning-Modellen gezeigt. Da große Modelle, die für komplexe Aufgaben trainiert werden, schwer zu überprüfen sind, konzentriert sich ein Teil dieser Arbeit auf kontrollierte Aufgaben, die bestimmte Aspekte der Sprache emulieren. Wir schlagen einen neuen Satz solcher kontrollierten Aufgaben vor, um einen entscheidenden Aspekt der Verarbeitung natürlicher Sprache zu erforschen, der nicht genügend Aufmerksamkeit erhalten hat: die Notwendigkeit, diskrete Informationen aus Sequenzen abzurufen. Wir untersuchen auch das Modellverhalten der Aufgaben mit einfachen Instanziierungen von Transformern und LSTMs. Unsere Ergebnisse unterstreichen die positive Rolle der Decoderaufmerksamkeit und ihre manchmal unerwartete Interaktion mit anderen Komponenten. Darüber hinaus zeigen wir, dass diese einfachen Modelle für die meisten Aufgaben immer noch erhebliche Schwierigkeiten aufweisen. Wir hoffen, dass die Community die Analysemöglichkeiten aufgreift, die unsere Aufgaben bieten, und dass ein klareres Verständnis des Modellverhaltens der Aufgaben zu besseren und transparenteren Modellen führt.', 'id': 'Selama bertahun-tahun terakhir, komunitas NLP telah menunjukkan semakin tertarik untuk menganalisis bagaimana model belajar dalam bekerja. Given that large models trained on complex tasks are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of language.  Kami mengusulkan set baru dari tugas terkendali seperti ini untuk mengeksplorasi aspek penting dari proses bahasa alam yang belum menerima perhatian yang cukup: kebutuhan untuk mendapatkan informasi diskret dari urutan. Kami juga mempelajari perilaku model pada tugas dengan instansi sederhana Transformers dan LSTMs. Hasil kami menunjukkan peran yang berguna dari perhatian dekoder dan kadang-kadang interaksi yang tidak terduga dengan komponen lain. Moreover, we show that, for most of the tasks, these simple models still show significant difficulties.  Kami berharap bahwa masyarakat akan mengambil kemungkinan analisis yang diberikan tugas kita, dan bahwa pemahaman lebih jelas tentang perilaku model pada tugas akan membawa ke model yang lebih baik dan lebih transparan.', 'fa': 'در سال های اخیر، جامعه NLP، علاقه\u200cای بیشتر در تحلیل کردن مدل\u200cهای یادگیری چقدر عمیق کار می\u200cکند، نشان داده است. با وجود اینکه مدل های بزرگی که روی کار های پیچیده آموزش داده شده\u200cاند برای تحقیق سخت است، بعضی از این کار روی کار کنترل کنترل تمرکز کرده\u200cاند که نسخه\u200cهای ویژه زبان را تحقیق می\u200cکنند. ما یک مجموعه جدید از این وظیفه کنترل را پیشنهاد می\u200cکنیم تا یک نقطه مهمی از پردازش زبان طبیعی را تحقیق کنیم که به اندازه کافی توجه نداشته باشد: نیازی برای گرفتن اطلاعات مختلف از طریقه\u200cها. ما همچنین رفتار مدل را در مورد وظیفه های ساده تغییر دهندگان و LSTMs مطالعه می کنیم. نتیجه\u200cهای ما نقش منافع توجه دکوردر و بعضی وقتها تعامل غیرمنتظره\u200cای با جزئیات دیگر را مشخص می\u200cکنند. و به علاوه، ما نشان می دهیم که، برای بیشتر کارها، این مدل ساده هنوز مشکلات بزرگی را نشان می دهند. امیدواریم که جامعه احتمالات تحلیل را که وظیفه\u200cهای ما به آن می\u200cرساند برگیرد، و درک روشن\u200cتر از رفتار مدل روی وظیفه\u200cها به مدل\u200cهای بهتر و شفافیت\u200cتری می\u200cرسد.', 'af': "In onlangse jaar het die NLP-gemeenskap vergroot belang gewys om te analiseer hoe diep leer modele werk. As die groot modele wat op komplekse opdragte onderwerp is, is moeilik om te inspekteer, sommige van hierdie werk het gefokus op kontroleerde opdragte wat spesifieke aspekte van taal emuleer. Ons voorstel 'n nuwe stel van sodanige kontroleerde taak om 'n gekruisige aspekt van natuurlike taal-prosessering te uitprobeer wat nie genoeg aandag ontvang het nie: die nodig om diskrete inligting van sekwensies te ontvang. Ons studeer ook model gedrag op die opdragte met eenvoudige instansies van Transformers en LSTMs. Ons resultate verlig die beneficiele rol van dekoder aandag en sy soms onverwagte interaksie met ander komponente. Maar ons wys dat, vir die meeste van die taak, hierdie eenvoudige modele steeds betekende moeilikhede vertoon. Ons hoop dat die gemeenskap die analiseerde moontlikhede sal neem wat ons opdragte verskaf, en dat 'n duideliker verstanding van model gedrag op die opdragte sal lei na beter en meer deursigtige modele.", 'ko': '최근 몇 년 동안 NLP 커뮤니티는 딥러닝 모델을 분석하는 작업 방식에 대해 갈수록 흥미를 느끼고 있다.복잡한 임무에서 훈련된 대형 모델은 검사하기 어렵다는 것을 감안하여 이 업무의 일부 중점은 언어의 특정한 방면의 통제 임무를 모의하는 것이다.우리는 자연 언어 처리에서 아직 충분히 중시되지 않은 관건적인 부분인 서열에서 분리된 정보를 검색하는 수요를 탐색하기 위해 새로운 통제 임무를 제시했다.Transformers와 LSTM의 간단한 실례화 임무의 모델 행위도 연구했다.우리의 결과는 디코더의 주의력의 유익한 작용과 때때로 다른 구성 요소와의 의외의 상호작용을 강조했다.그 밖에 우리는 대부분의 임무에 대해 이런 간단한 모델들은 여전히 매우 큰 어려움을 나타낸다고 밝혔다.우리는 지역사회가 우리의 임무가 제공할 수 있는 분석 가능성을 받아들일 수 있고 임무의 모델 행위에 대해 더욱 명확한 이해를 가지고 더욱 좋고 투명한 모델을 만들 수 있기를 바란다.', 'am': 'ባለፈው ዓመታት፣ የNLP ማኅበረሰብ እንዴት ጥልቅ ትምህርት ምሳሌዎች እንደሚሠራ ማስተምር የሚጨምረው ማሳየት ማድረግ ያሳየዋል፡፡ በተጨማሪው ስራ ላይ የተማሩ ታላላቆቹ ሞዴላዎች ሊመርምሩ ባይችላል፣ አንዳንዶቹ የቋንቋዎችን በተለያዩ ጉዳይ ላይ የሚቆጥሩትን ስራዎችን ያስተካክላሉ፡፡ እንደዚህ ያሉ ሥርዓቶች የባሕላዊ ቋንቋ ማቀናቀል የጠቃሚ ጉዳይ ለመፈለግ አዲስ ጉዳይ እናስባለን፤ ከሥርዓት የተለየ መረጃ ማግኘት ያስፈልጋል፡፡ እና በሥርዓት ላይ የሚደረገውን የሞዴል ሁኔታ እና የዘለላዊ ነፃነት እና LSTMs. ፍሬዎቻችን የጥቅም ትኩረት እና አንዳንዶቹ ጊዜ ከሌሎች አካባቢዎች ጋር ያልተስፋ ግንኙነት የሚያሳየው ጥያቄ ነው፡፡ ደግሞም ለስራ ብዙዎቹ እነዚህ ቀላል ምሳሌዎች ገና ብዙ ችግር ያሳያል፡፡ ማኅበረሰብ ስራቶቻችንን የሚያስፈልገውን ማስታወቂያውን እንዲያሳድግ ተስፋ እናደርጋለን፤ በሥርዓት ላይ የሚደረገውን የሞዴል ልማወቅ የሚሻለውን እና አብልጦ የሚገልጥ ሞዴላዎችን እንዲያገኛል፡፡', 'sw': 'Katika miaka ya hivi karibuni, jumuiya ya NLP imeonyesha kuongezeka kwa maslahi ya kuchambua namna mifano ya kujifunza ya kina inavyofanya kazi. Kutokana na kuwa mifano makubwa ya kufundishwa katika kazi za tatizo ni vigumu kuchunguza, baadhi ya kazi hii imejikita kwenye kazi zinazodhibitiwa zinazoelezea mambo maalum ya lugha. Tunazipendekeza mfululizo mpya wa kazi hizi zinazodhibitiwa kutafuta upande muhimu wa upasuaji wa lugha asilia ambao haujapokea hisia za kutosha: haja ya kupata taarifa tofauti kutoka kwa mfululizo. Kadhalika tunasoma tabia za muundo katika kazi zenye vifumo rahisi vya WaTransformers na LSTMs. Matokeo yetu yanaonyesha jukumu la faida la kusikiliza na wakati mwingine la mahusiano yasiyotarajiwa na vifaa vingine. Zaidi, tunaonyesha kwamba, kwa majukumu mengi, mifano hii nyepesi bado inaonyesha vigumu vikubwa. Tunatumaini kwamba jamii itachukua uchambuzi uwezekano wa kazi zetu zinazoweza, na kwamba uelewa mzuri wa tabia za muundo katika kazi hiyo utapelekea mifano bora na uwazi zaidi.', 'tr': 'Soňky ýyllar içinde NLP jemgyýeti nähili derin öwrenmek nusgalarynyň işleýändigini çözümleşdirmek üçin gyzyklanýar. Karmaşık işlerde bilinmeli uly nusgalar barlamak kyn üçin, bu işiň käbirlerini diliň spesifik aspektlerini örän üns berýän zadlara üns berdi. Biz täze kontrol eden zadlaryň täze bir toparyny tebigy dil işlemeginiň nähili üns berilmeýän aspektini keşfetmek üçin teklip berýäris: diskret maglumaty sıralardan almak gerek. Biz hem Transformerçiler we LSTMsler bilen bu zadlarda örän nusgalary öwrenýärik. Biziň netijelerimiz dekoderlemek üçin ýeterlik täsirini ýagtylaýar we käwagt başga zatlary bilen garaşylmadyk täsirini ýagtylaýar. Mundan soňra biz bu basit nusgalaryň köpüsi kynçylyklary görkezýäris. Toplumyň biziň zadymyzyň berýän çözümleri çykaryp biljek mümkinçiliklerini alap biljekdigini umyt edýäris we bu zadyň nusgalarynyň düzümlerini gowy we daşyrylyk nusgalaryna ýüze çykaryp biljekdigini umyt edýäris.', 'sq': 'Në vitet e fundit, komuniteti i NLP ka treguar interes në rritje në analizën e mënyrës se si funksionojnë modelet e mësimit të thellë. Given that large models trained on complex tasks are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of language.  Ne propozojmë një sërë të re detyrash të tilla të kontrolluara për të eksploruar një aspekt vendimtar të procesimit natyror të gjuhës që nuk ka marrë vëmendje të mjaftueshme: nevojën për të marrë informacion diskret nga sekuencat. We also study model behavior on the tasks with simple instantiations of Transformers and LSTMs.  Rezultatet tona theksojnë rolin e dobishëm të vëmendjes së dekoderit dhe ndërveprimin e tij ndonjëherë të papritur me komponente të tjera. Përveç kësaj, ne tregojmë se, për shumicën e detyrave, këto modele të thjeshta ende tregojnë vështirësi të rëndësishme. We hope that the community will take up the analysis possibilities that our tasks afford, and that a clearer understanding of model behavior on the tasks will lead to better and more transparent models.', 'hy': 'In recent years, the NLP community has shown increasing interest in analysing how deep learning models work.  Քանի որ բարդ առաջադրանքների վրա սովորեցված մեծ մոդելները դժվար են վերահսկել, այս աշխատանքից որոշները կենտրոնացել են վերահսկվող առաջադրանքների վրա, որոնք արտացոլում են լեզվի հատուկ ասպեկտները: Մենք առաջարկում ենք այդպիսի վերահսկվող խնդիրների նոր համակարգ, որպեսզի ուսումնասիրենք բնական լեզվի վերլուծության կարևոր ասպեկտը, որը բավարար ուշադրություն չի ստացել. անհրաժեշտությունը հաջորդականություններից խիստ Մենք նաև ուսումնասիրում ենք վերաբերյալ վերաբերյալ ձևերի մոդելների վարքագիծը Transforme-ների և LSMT-ների պարզ պահերով: Մեր արդյունքները ներկայացնում են կոդերի ուշադրության օգտակար դերը և երբեմն անսպասելի փոխազդեցությունը այլ բաղադրիչների հետ: Moreover, we show that, for most of the tasks, these simple models still show significant difficulties.  Մենք հույս ունենք, որ համայնքը կօգտագործի վերլուծության հնարավորությունները, որոնք մեր առաջադրանքները իրենց թույլ են տալիս, և որ ավելի պարզ հասկանալը առաջադրանքների վրա կատարվող մոդելների վարքագիծը կհանգեցնի ավելի լավ և թափանցիկ մոդե', 'az': 'Son illərdə NLP toplumunun öyrənmə modellərinin nə qədər çalışdığını analizə etmək üçün artırmağını göstərdi. Müxtəlif işlərdə təhsil edilən böyük modellerin təhsil edilməsi çətin olduğuna görə, bu işlərdən bazıları dilin müxtəlif aspektlərini təhsil edən kontrol işlərə odaqlanırlar. Biz bu növbənöv müdafiə edilmiş işləri təbiətli dil işləməsinin çox möhkəm bir aspektini keşfetmək üçün yeni təklif edirik ki, bu təbiətli işlər yetişdirməyən təbiətli dil işləməsinin çoxluğunu təsdiqləyir: müxtəlif məlumatları seçmə Biz də Transformers və LSTMs işlərində modeli davranışları təhsil edirik. Sonuçlarımız dekoder məlumatının faydalı rolünü və bəzən gözləməmiş başqa komponentlərlə birlikdə istifadə edir. Daha çox işlər üçün bu basit modellər hələ də çox çətin göstərir. Biz ümid edirik ki, toplumun bizim işimizin qazandığı analiz mümkünlüklərini alır, və işlərdə modellərin davranışlarını daha aydın anlayış daha yaxşı və daha transparent modellərə yol verər.', 'bn': 'সাম্প্রতিক বছরগুলোতে এনএলপি সম্প্রদায় গভীর শিক্ষা মডেল কাজ করে বিশ্লেষণের আগ্রহ বাড়ছে। যেহেতু কমপ্লেক্স কাজে প্রশিক্ষিত বড় মডেল পরীক্ষা করা কঠিন, কিছু কাজ নিয়ন্ত্রণ করা কাজের উপর মনোযোগ দিয়েছে যা ভাষার নির্দিষ্ট প প্রাকৃতিক ভাষা প্রক্রিয়ার গুরুত্বপূর্ণ প্রতিক্রিয়া খুঁজে বের করার জন্য আমরা এই ধরনের নিয়ন্ত্রিত কাজের একটি নতুন সেট প্রস্তাব করেছি: প্ আমরা ট্রান্সফর্মার এবং এলস্টিএমএস এর সাধারণ অবস্থায় কাজের উপর মডেল আচরণ গবেষণা করি। আমাদের ফলাফল ডিকোডের মনোযোগের কার্যকর ভূমিকা উল্লেখ করে এবং মাঝে মাঝে মাঝে মাঝে অন্যান্য উপাদানের সাথে অপ্রত্য এছাড়াও, আমরা দেখাচ্ছি যে এই কাজের বেশীরভাগ, এই সাধারণ মডেলগুলো এখনো বিশাল কষ্ট দেখাচ্ছে। আমরা আশা করি যে সম্প্রদায় বিশ্লেষণের সম্ভাবনা তুলে ধরবে যে আমাদের কাজের সম্ভাবনা আছে, আর এই কাজে মডেল আচরণের ক্ষেত্রে পরিষ্কার বুঝতে পারবে যে মডে', 'cs': 'V posledních letech komunita NLP projevila rostoucí zájem o analýzu fungování modelů hlubokého učení. Vzhledem k tomu, že velké modely trénované pro složité úkoly jsou obtížně kontrolovatelné, některá z této práce se zaměřila na řízené úlohy, které emulují specifické aspekty jazyka. Navrhujeme nový soubor takových kontrolovaných úkolů, abychom prozkoumali klíčový aspekt zpracování přirozeného jazyka, kterému nebyla dostatečná pozornost: potřebu získávat diskrétní informace z sekvencí. Dále studujeme chování modelů na úlohách s jednoduchými instanciemi transformátorů a LSTMů. Naše výsledky zdůrazňují příznivou roli pozornosti dekodéru a jeho někdy neočekávanou interakci s dalšími komponenty. Navíc ukazujeme, že u většiny úkolů tyto jednoduché modely stále vykazují značné obtíže. Doufáme, že komunita využije možností analýzy, které naše úkoly poskytují, a že jasnější porozumění chování modelů na úkolech povede k lepším a transparentnějším modelům.', 'ca': "En els últims anys, la comunitat del NLP ha demostrat un interès creixent en analitzar com funcionen els models d'aprenentatge profund. Given that large models trained on complex tasks are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of language.  Proposem un nou conjunt d'aquestes tasques controlades per explorar un aspecte crucial del processament natural del llenguatge que no ha rebut prou atenció: la necessitat d'obtenir informació discreta de seqüències. També estudiem el comportament model en les tasques amb simples instancies de Transformers i LSTMs. Els nostres resultats destaquen el paper beneficiós de l'atenció del decodificador i la seva interacció de vegades inesperada amb altres components. A més, demostram que, per la majoria de les tasques, aquests models simples encara tenen dificultats significatives. Esperem que la comunitat aprofiti les possibilitats d'anàlisi que es permeten les nostres tasques, i que una comprensió més clara del comportament model en les tasques condueixi a models millors i més transparents.", 'et': 'Viimastel aastatel on uue õppeprogrammi kogukond näidanud kasvavat huvi sügavõppe mudelite toimimise analüüsimise vastu. Arvestades, et keerukate ülesannete täitmiseks koolitatud suuri mudeleid on raske kontrollida, on osa sellest tööst keskendunud kontrollitud ülesannetele, mis jäljendavad keele konkreetseid aspekte. Me pakume välja uue kontrollitud ülesannete komplekti, et uurida looduskeele töötlemise olulist aspekti, millele ei ole piisavalt tähelepanu pööratud: vajadust saada diskreetset infot järjestustest. Samuti uurime mudelikäitumist Transformerite ja LSTMde lihtsate instanciatsioonidega ülesannetel. Meie tulemused rõhutavad dekooderi tähelepanu kasulikku rolli ja selle mõnikord ootamatut koostoimet teiste komponentidega. Lisaks näitame, et enamiku ülesannete puhul esinevad need lihtsad mudelid endiselt märkimisväärseid raskusi. Loodame, et kogukond kasutab analüüsivõimalusi, mida meie ülesanded pakuvad, ning et selgem arusaam mudelikäitumisest ülesannete puhul viib paremate ja läbipaistvamate mudeliteni.', 'bs': 'Za poslednje godine, zajednica NLP pokazala je veći interes za analizu koliko duboko funkcioniše modeli učenja. S obzirom na to da su veliki modeli obučeni na kompleksnom zadatku teško provjeriti, neki od ovog rada se fokusirali na kontrolirane zadatke koje emuliraju specifične aspekte jezika. Predlažemo novu skupu takvih kontroliranih zadataka da istražimo ključni aspekt prirodnog obradivanja jezika koji nije dobio dovoljno pažnje: potrebu da dobijemo diskretne informacije iz sekvencija. Također proučavamo model ponašanja na zadatkima sa jednostavnim instancijama transformera i LSTMs. Naši rezultati naglašavaju korisnu ulogu pažnje dekodera i njegove ponekad neočekivane interakcije sa drugim komponentima. Osim toga, pokazujemo da za većinu zadataka ovi jednostavni modeli još uvijek pokazuju značajne probleme. Nadamo se da će zajednica uzeti mogućnosti analize koje su nam zadaci priuštili i da će jasnije razumijevanje model a ponašanja na zadacima dovesti do boljih i transparentnih modela.', 'fi': 'Viime vuosina NLP-yhteisö on osoittanut kasvavaa kiinnostusta analysoida, miten syväoppimisen mallit toimivat. Koska monimutkaisiin tehtäviin koulutettuja suuria malleja on vaikea tarkastaa, osa työstä on keskittynyt kontrolloituihin tehtäviin, jotka jäljittelevät kielen erityispiirteitä. Ehdotamme uusia kontrolloituja tehtäviä tutkimaan luonnollisten kielten käsittelyn keskeistä näkökohtaa, johon ei ole kiinnitetty riittävästi huomiota: tarvetta hakea erillisiä tietoja sekvensseistä. Tutkimme myös mallikäyttäytymistä tehtävissä muuntajien ja LSTMien yksinkertaisilla instantiaatioilla. Tuloksemme korostavat dekooderin huomion hyödyllistä roolia ja sen joskus odottamatonta vuorovaikutusta muiden komponenttien kanssa. Lisäksi osoitamme, että useimmissa tehtävissä nämä yksinkertaiset mallit osoittavat edelleen merkittäviä vaikeuksia. Toivomme, että yhteisö hyödyntää tehtävämme tarjoamat analyysimahdollisuudet ja että selkeämpi ymmärrys mallikäyttäytymisestä johtaa parempiin ja läpinäkyvämpiin malleihin.', 'sk': 'V zadnjih letih je skupnost NLP pokazala vse večje zanimanje za analizo delovanja modelov globokega učenja. Glede na to, da je velike modele, usposobljene za kompleksne naloge, težko pregledati, se je nekaj tega dela osredotočilo na nadzorovane naloge, ki posnemajo posebne vidike jezika. Predlagamo nov sklop takšnih nadzorovanih nalog za raziskovanje ključnega vidika obdelave naravnega jezika, ki ni prejel dovolj pozornosti: potrebe po pridobivanju diskretnih informacij iz zaporedij. Preučujemo tudi vedenje modela pri opravilih s preprostimi instanciacijami transformatorjev in LSTMs. Naši rezultati poudarjajo koristno vlogo pozornosti dekoderja in njegovo včasih nepričakovano interakcijo z drugimi komponentami. Poleg tega pokažemo, da pri večini nalog ti preprosti modeli še vedno kažejo velike težave. Upamo, da bo skupnost izkoristila možnosti analize, ki jih naše naloge omogočajo, in da bo jasnejše razumevanje vedenja modela pri nalogah vodilo do boljših in preglednejših modelov.', 'jv': 'Banyak segala sing dumadhi, komunitas NLP lak ngelakon seneng tah njaluk luwih apik sing apik nguasai model sing paling nggambar. Ingat kalaman lagi model sing ditambah akeh lan akeh akeh operasi sing nggawe ngubah bisa nguasal, supoyo ning karo negoro iki dadi supoyo akeh nguasal kang dadi sing apik tur angel. Awak dhéwé nggunakake sistem sing gawe ngubah akeh dikontrol kanggo ngelangno sak cara-cara sing perusahaan ingkang pribadirne soko ora ono mulasaé: kudu nggawe informasi sing berarti secana Awak dhéwé uga ngerasakno dadi nggawe modèl karo ngono ngerasahan surat Transformer karo LA Rejalekan dhéwé nglanggar kelompok nggawe barang nggawe Nambah, awak dhéwé ngerti ngomong, kanggo akeh operasi iki sak model sing isih beraksi kudu susahé. Awak dhéwé hal komunitas kuwi nggawe akeh perusahaan kanggo awak dhéwé dadi kanggo awak dhéwé, lan ngono kuwi tindakan layakno sing luwih apik dhéwé modèl kanggo awak dhéwé sing bakal ngelarang model sing luwih apik lan tambah bantuan.', 'ha': "A cikin shekara na farko, Jamii'in NLP ya nuna yana ƙara sha'anin sha'anin anarra misãlai masu ƙari da za'a aiki. Gida cewa, misãlai babba wanda aka sanar da su a kan aikin masu husũma sun zama mai ƙunci a kan jarraba su, wani daga wannan aikin yã fokusa kan aikin da aka lissafa, wanda ke ƙayyade masu ƙayyade masu cikin harshe. Tuna goyyar da wani sabo na aikin waɗannan da aka lissafa dõmin su nẽmi wani muhimu na aikin aiki na lugha wanda ba ya motsa zura ba: ana buƙata domin ka sami takardar da takarda. Kayya, tuna karatun misalin mutane a kan aikin da ke samu masu sauri na Transformers da LSM. MatamayinMu na nuna rolin mai amfani na aikin rakoda da kuma a yinin da ba'a ƙayyade wani aikin da ke samu'a da waɗansu composhi na daban. Kayya, Munã nũna, kuma, don mafiya yawan aikin waɗannan misãlai masu sauƙi sai ke nũna matabbata mai girma. Munã kwaɗayin cẽwa jamii zai sami fassara masu yiwuwa da aikinanmu suke iya amfani da, kuma wani fahimci na idãnun misãlai a kan aikin zai ƙara mafiya alhẽri da mafi bayyani.", 'he': 'בשנים האחרונות, קהילת NLP הראה מעניין גדול בניתוח איך מודלים למידה עמוקה עובדים. Given that large models trained on complex tasks are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of language.  We propose a new set of such controlled tasks to explore a crucial aspect of natural language processing that has not received enough attention: the need to retrieve discrete information from sequences.  אנחנו גם לומדים התנהגות מודל על המשימות עם רגעים פשוטים של Transformers ו LSTMs. Our results highlight the beneficial role of decoder attention and its sometimes unexpected interaction with other components.  חוץ מזה, אנחנו מראים, לרוב המשימות, הדוגמנים הפשוטים האלה עדיין מראים קשים משמעותיים. אנו מקווים שהקהילה תיקח את אפשרויות הניתוח שהמשימות שלנו מרשות לעצמנו, ושהבנה ברורה יותר של התנהגות מודל על המשימות תוביל למודלים טובים יותר ויותר שקופים.', 'bo': 'Son zamanlarda NLP ཚོགས་སྤྱི་ཚོགས་ཀྱི་མཐོ་ཁང་གིས་ཇི་ལྟར་སློབ་པའི་མིག་དཔེ་དབྱེ་ཞིབ་འབད་ནི་ལྟར་དཀའ་གཏོང་ཡོད། ཆེས་རྙིང་གི་ལས་འགུལ་ལ་སྒྲིག་འཛིན་བྱས་པའི་མིག་དཔེ་གཟུགས་རིས་འདི་ལྟ་ཞིབ་འཇུག་བྱེད་དགོས་པ་ལ་ལས་ཀྱང་གཞན་ལས་ཀྱང་སྒོ་འབྱེད ང་ཚོས་རང་རིའི་སྐད་རིགས་ཀྱི་ལས་སྦྱོར་བའི་ཆེད་དུ་འཚོལ་ཞིབ་བྱས་པའི་སྒྲིག་འགོད་འདི་གསར་པ་ཞིག་སྤྲོད་ཀྱི་ཡོད། ང་ཚོས་ཀྱང་གསར་བསྐྲུན་བྱེད་པའི་སྔོན་པ་དང་གླེང་མོལ་གྱི་རྗེས་སུ་མིག་དཔྱད་བྱས་ན་ ང་ཚོའི་མཐོང་སྐྱེས་འབྲས་ནི་ཕན་ཚུན་བསྡན་པའི་ལྟ་སྟངས་དང་མཚམས་རེ་རེད་མེད་པའི་སྐྱེས་འབྲེལ་བ་གཞན་དང་ འོན་ཀྱང་། ང་ཚོས་བྱ་འགུལ་མང་ཆེ་བ་ལྟར་ན་སྟབས་བདེ་བའི་མིག་དཔེ་འདི་ཚོ་ཡང་དཀའ་ངལ་ཆེ་བ་མངོན་པ་ཡིན་ན་ ང་ཚོའི་ཚོགས་སྡེ་འདིས་ང་ཚོའི་བྱ་འགུལ་དག་གི་ཆོས་ཉིད་ཅིག་ཡོད་པའི་ཆོས་ཉིད་དེ་ལེན་རྒྱུ་ཞིག་དང་། ལས་འགུལ་གྱི་མིག་དཔེ་རིགས་གཤིས་'}
{'en': 'Do Language Models Know the Way to Rome?', 'es': '¿Los modelos lingüísticos conocen el camino a Roma?', 'pt': 'Os modelos de linguagem conhecem o caminho para Roma?', 'ar': 'هل تعلم النماذج اللغوية الطريق إلى روما؟', 'fr': 'Les modèles linguistiques connaissent-ils le chemin de Rome\xa0?', 'ja': '言語モデルはローマへの道を知っていますか？', 'zh': '言语知罗马之道乎?', 'hi': 'क्या भाषा मॉडल रोम का रास्ता जानते हैं?', 'ru': 'Знают ли языковые модели путь в Рим?', 'ga': 'An bhfuil Eolas ag Múnlaí Teanga ar an Bealach chun na Róimhe?', 'ka': 'ენვჟკთ მჲევლთ ჱნაწრ ლთ ოყრ ჱა პთმ?', 'el': 'Γνωρίζουν τα μοντέλα γλώσσας τον δρόμο για τη Ρώμη;', 'hu': 'A nyelvi modellek ismerik az utat Rómába?', 'it': 'I modelli linguistici conoscono la strada per Roma?', 'kk': 'Тіл үлгілері Рим жолын біледі ме?', 'mk': 'Дали јазичките модели го знаат патот кон Рим?', 'lt': 'Ar kalbos modeliai žino kelią į Romą?', 'ms': 'Adakah Model Bahasa tahu jalan ke Roma?', 'ml': 'ഭാഷ മോഡലുകള്\u200dക്ക് റോമിലേക്ക് വഴി അറിയാമോ?', 'mt': 'Il-mudelli lingwistiċi jafu t-triq lejn Ruma?', 'mn': 'Холны загварууд Ромын замыг мэддэг үү?', 'no': 'Kjenner språk-modeller veien til Roma?', 'pl': 'Czy modele językowe znają drogę do Rzymu?', 'ro': 'Modelele lingvistice cunosc calea spre Roma?', 'sr': 'Da li jezički modeli znaju put do Rima?', 'si': 'රෝම් වලට යන පාර දන්නවද?', 'sv': 'Vet språkmodeller vägen till Rom?', 'so': 'Modelooyinka luuqada ma taqaan jidka Rooma?', 'ta': 'மொழி மாதிரிகள் ரோமுக்கு வழி தெரியுமா?', 'ur': 'کیا زبان مدل روم کی راہ جانتے ہیں؟', 'uz': 'Til modellari Romga yoĘ»lni bilmadi?', 'vi': 'Bạn có biết đường tới Rome không?', 'bg': 'Знаят ли езиковите модели пътя към Рим?', 'da': 'Kender sprogmodeller vejen til Rom?', 'hr': 'Da li jezički modeli znaju put do Rima?', 'id': 'Apakah Model Bahasa tahu jalan ke Roma?', 'fa': 'آیا مدل زبانی راهی به روم می دانند؟', 'nl': 'Weten taalmodellen de weg naar Rome?', 'de': 'Kennen Sprachmodelle den Weg nach Rom?', 'ko': '언어 모델은 로마로 가는 길을 아십니까?', 'sw': 'Mradi wa lugha wanajua njia ya Roma?', 'af': 'Do Language Models Know the Way to Rome?', 'tr': 'Dil nusgalary Roma dalanyny bilýärmi?', 'am': 'Do Language Models Know the Way to Rome?', 'sq': 'A e dinë modelet gjuhësore rrugën për në Romë?', 'hy': 'Գիտե՞ն լեզվի մոդելները Ռոմի ճանապարհը:', 'az': 'Dil Modell톛ri Roma yolunu bilir mi?', 'bs': 'Da li jezički modeli znaju put do Rima?', 'bn': 'ভাষার মডেলরা কি রোমের পথ জানে?', 'ca': 'Els models de llenguatgeconeixen el camí a Roma?', 'et': 'Kas keelemudelid teavad teed Rooma?', 'fi': 'Tietävätkö kielimallit tien Roomaan?', 'cs': 'Znají jazykové modely cestu do Říma?', 'jv': 'Opo model anyir banget ngerti Kasang lunga Ram?', 'ha': '@ action: button', 'sk': 'Ali jezikovni modeli poznajo pot do Rima?', 'bo': 'སྐད་ཡིག་མ་དབྱིབས་དཔེ་དབྱིབས་གྱི་ཁྲོད་ལམ་ལ་རྟོགས་པ་ཡིན་ནམ།', 'he': 'האם מודלים לשפה יודעים את הדרך לרומא?'}
{'en': 'The global geometry of language models is important for a range of applications, but language model probes tend to evaluate rather local relations, for which ground truths are easily obtained. In this paper we exploit the fact that in geography, ground truths are available beyond local relations. In a series of experiments, we evaluate the extent to which language model representations of city and country names are isomorphic to real-world geography, e.g., if you tell a language model where Paris and Berlin are, does it know the way to Rome? We find that language models generally encode limited geographic information, but with larger models performing the best, suggesting that geographic knowledge can be induced from higher-order co-occurrence statistics.can be induced from higher-order co-occurrence statistics.', 'fr': "La géométrie globale des modèles de langage est importante pour de nombreuses applications, mais les sondes de modèles de langage ont tendance à évaluer des relations plutôt locales, pour lesquelles des vérités de terrain sont facilement obtenues. Dans cet article, nous exploitons le fait qu'en géographie, les vérités de terrain sont disponibles au-delà des relations locales. Dans une série d'expériences, nous évaluons dans quelle mesure les représentations de modèles linguistiques des noms de villes et de pays sont isomorphes par rapport à la géographie du monde réel. Par exemple, si vous indiquez à un modèle linguistique où se trouvent Paris et Berlin, connaît-il le chemin vers Rome\xa0? Nous constatons que les modèles linguistiques codent généralement des informations géographiques limitées, mais que les modèles plus grands fonctionnent le mieux, ce qui suggère que la connaissance géographique peut être induite à partir de statistiques de cooccurrence d'ordre supérieur.", 'pt': 'A geometria global dos modelos de linguagem é importante para uma variedade de aplicações, mas as sondagens de modelos de linguagem tendem a avaliar relações bastante locais, para as quais as verdades básicas são facilmente obtidas. Neste artigo, exploramos o fato de que, na geografia, as verdades básicas estão disponíveis além das relações locais. Em uma série de experimentos, avaliamos até que ponto as representações do modelo de linguagem de nomes de cidades e países são isomórficas à geografia do mundo real, por exemplo, se você disser a um modelo de linguagem onde estão Paris e Berlim, ele sabe o caminho para Roma? Descobrimos que os modelos de linguagem geralmente codificam informações geográficas limitadas, mas com modelos maiores com melhor desempenho, sugerindo que o conhecimento geográfico pode ser induzido a partir de estatísticas de co-ocorrência de ordem superior.', 'ar': 'تعد الهندسة العالمية لنماذج اللغة مهمة لمجموعة من التطبيقات ، لكن تحقيقات نموذج اللغة تميل إلى تقييم العلاقات المحلية إلى حد ما ، والتي يمكن الحصول على الحقائق الأساسية بسهولة. في هذه الورقة ، نستغل حقيقة أن الحقائق الأرضية متوفرة خارج العلاقات المحلية في الجغرافيا. في سلسلة من التجارب ، نقوم بتقييم مدى تشابه تمثيلات نماذج اللغة لأسماء المدن والبلد في جغرافيا العالم الحقيقي ، على سبيل المثال ، إذا أخبرت نموذجًا للغة عن مكان باريس وبرلين ، فهل يعرف الطريق إلى روما؟ نجد أن نماذج اللغة تشفر عمومًا معلومات جغرافية محدودة ، ولكن مع النماذج الأكبر تقدم أفضل أداء ، مما يشير إلى أنه يمكن استحداث المعرفة الجغرافية من إحصائيات التكرار ذات الترتيب الأعلى.', 'es': 'La geometría global de los modelos lingüísticos es importante para una variedad de aplicaciones, pero las sondas de modelos lingüísticos tienden a evaluar relaciones más bien locales, para las cuales se obtienen fácilmente verdades fundamentales. En este artículo explotamos el hecho de que en geografía, las verdades básicas están disponibles más allá de las relaciones locales. En una serie de experimentos, evaluamos hasta qué punto las representaciones de modelos lingüísticos de nombres de ciudades y países son isomórficas con la geografía del mundo real, por ejemplo, si le dices a un modelo lingüístico dónde están París y Berlín, ¿conoce el camino a Roma? Encontramos que los modelos lingüísticos generalmente codifican información geográfica limitada, pero con modelos más grandes que funcionan mejor, lo que sugiere que el conocimiento geográfico puede ser inducido a partir de estadísticas de coocurrencia de orden superior.', 'ja': '言語モデルのグローバルジオメトリは、さまざまなアプリケーションにとって重要であるが、言語モデルプローブは、地上真理が容易に得られるローカル関係よりもむしろ評価する傾向がある。この論文では、地理学において、地上の真理は地域関係を超えて利用可能であるという事実を利用している。一連の実験では、私たちは都市名と国名の言語モデル表現が現実世界の地理に同形である程度を評価します。例えば、パリとベルリンがどこにあるかを言えば、ローマへの道はわかりますか？言語モデルは一般的に限られた地理的情報を符号化するが、より大きなモデルは最高のパフォーマンスを発揮することから、より高次の共起統計から地理的知識を誘導できることが示唆されている。', 'zh': '言语模样之全局几何于一系应用甚重,而言模探针向于评估相当,故易得其实。 在本文中,我们用了这一个事实,即在地理学中,地方真理可以在地方关系之外。 列实验之中,论城邑国名语形于多大程度,与世同构地理,若告以巴黎柏林所在,知罗马之道乎? 此言模常编码于有限之地理信息,而大者为上,此地理知识可从高阶共现计中出也。', 'ru': 'Глобальная геометрия языковых моделей важна для целого ряда областей применения, но зонды языковых моделей, как правило, оценивают довольно локальные отношения, для которых легче получить истины. В этой статье мы используем тот факт, что в географии истины доступны за пределами местных отношений. В серии экспериментов мы оцениваем, в какой степени представления языковой модели названий городов и стран изоморфны реальной географии, например, если вы расскажете языковой модели, где находятся Париж и Берлин, знает ли он путь в Рим? Мы обнаружили, что языковые модели, как правило, кодируют ограниченную географическую информацию, но с более крупными моделями, работающими наилучшим образом, что позволяет предположить, что географические знания могут быть получены из статистики совместного возникновения более высокого порядка.', 'hi': 'भाषा मॉडल की वैश्विक ज्यामिति अनुप्रयोगों की एक श्रृंखला के लिए महत्वपूर्ण है, लेकिन भाषा मॉडल जांच स्थानीय संबंधों का मूल्यांकन करती है, जिसके लिए जमीनी सत्य आसानी से प्राप्त किए जाते हैं। इस पत्र में हम इस तथ्य का फायदा उठाते हैं कि भूगोल में, जमीनी सत्य स्थानीय संबंधों से परे उपलब्ध हैं। प्रयोगों की एक श्रृंखला में, हम इस हद तक मूल्यांकन करते हैं कि शहर और देश के नामों के भाषा मॉडल प्रतिनिधित्व वास्तविक दुनिया के भूगोल के लिए आइसोमोर्फिक हैं, उदाहरण के लिए, यदि आप एक भाषा मॉडल बताते हैं जहां पेरिस और बर्लिन हैं, तो क्या यह रोम का रास्ता जानता है? हम पाते हैं कि भाषा मॉडल आम तौर पर सीमित भौगोलिक जानकारी को एन्कोड करते हैं, लेकिन बड़े मॉडल के साथ सबसे अच्छा प्रदर्शन करते हैं, यह सुझाव देते हुए कि भौगोलिक ज्ञान को उच्च-क्रम के सह-घटना आंकड़ों से प्रेरित किया जा सकता है।', 'ga': 'Tá céimseata dhomhanda na múnlaí teanga tábhachtach do raon feidhmeanna, ach is gnách go ndéanann taiscéalaithe samhlacha teanga measúnú a dhéanamh ar chaidreamh sách áitiúil, agus is furasta na bunfhírinní a fháil ina leith. Sa pháipéar seo déanaimid leas as an bhfíric go bhfuil fáil ar fhírinní talún sa tíreolaíocht lasmuigh de chaidreamh áitiúil. I sraith turgnaimh, déanaimid measúnú ar a mhéid atá léirithe samhlacha teanga d’ainmneacha cathracha agus tíortha isomorphic le tíreolaíocht an fhíorshaoil, m.sh., má insíonn tú do mhúnla teanga cá bhfuil Páras agus Beirlín, an bhfuil a fhios aige an bealach go dtí an Róimh? Feictear dúinn go n-iondaíonn samhlacha teanga faisnéis gheografach teoranta go ginearálta, ach go bhfuil múnlaí níos mó ag feidhmiú mar is fearr, rud a thugann le tuiscint gur féidir eolas geografach a tharlú ó staitisticí comh-tharlú d’ord níos airde.', 'hu': 'A nyelvi modellek globális geometriája számos alkalmazás számára fontos, de a nyelvi modellszondák inkább helyi kapcsolatokat értékelnek, amelyekhez az alapvető igazságok könnyen megszerezhetők. Ebben a tanulmányban kihasználjuk azt a tényt, hogy a földrajzi igazságok a helyi kapcsolatokon túl is elérhetőek. Egy kísérletsorozat során felmérjük, hogy a városok és országok nyelvi modellreprezentációi milyen mértékben izomorfák a valós világ földrajzához, például ha elmondod egy nyelvi modellt, hol van Párizs és Berlin, tudja-e az utat Rómába? Úgy találjuk, hogy a nyelvi modellek általában korlátozott földrajzi információkat kódolnak, de a nagyobb modellek a legjobban teljesítenek, ami arra utal, hogy a földrajzi ismeretek a magasabb rendű együttes-előfordulási statisztikákból indukálhatók.', 'el': 'Η παγκόσμια γεωμετρία των γλωσσικών μοντέλων είναι σημαντική για μια σειρά εφαρμογών, αλλά οι ανιχνευτές γλωσσικών μοντέλων τείνουν να αξιολογούν μάλλον τοπικές σχέσεις, για τις οποίες οι βασικές αλήθειες μπορούν εύκολα να ληφθούν. Στην παρούσα εργασία αξιοποιούμε το γεγονός ότι στη γεωγραφία, οι επίγειες αλήθειες είναι διαθέσιμες πέρα από τις τοπικές σχέσεις. Σε μια σειρά πειραμάτων, αξιολογούμε τον βαθμό στον οποίο οι γλωσσικές αναπαραστάσεις των ονομάτων πόλεων και χωρών είναι ισομορφικές με την πραγματική γεωγραφία, π.χ. αν πεις σε ένα γλωσσικό μοντέλο πού βρίσκονται το Παρίσι και το Βερολίνο, ξέρει το δρόμο για τη Ρώμη; Διαπιστώνουμε ότι τα γλωσσικά μοντέλα κωδικοποιούν γενικά περιορισμένες γεωγραφικές πληροφορίες, αλλά με μεγαλύτερα μοντέλα να αποδίδουν καλύτερα, υποδηλώνοντας ότι η γεωγραφική γνώση μπορεί να προκληθεί από τις στατιστικές συνεμφάνισης υψηλότερης τάξης.', 'ka': 'ენის მოდელების გლობალური ჯეომეტრია არის მნიშვნელოვანი პროგრამებისთვის, მაგრამ ენის მოდელური მოდელური პრობეტები უფრო მხოლოდ ლოკალური შესახებ გაუმუშავებენ, რომელი ამ დოგომაში ჩვენ ვკოლექრობთ ფაქტი, რომ გეგოგოგოგიაში, მხოლოდ სინამდვილეები აქვს ლოკალური შესახებების გარეშე. ექსპერიმენტის სერიომენტებში, ჩვენ ვამუშაობთ რამდენიმე ენის მოდელის გამოსახულებების სიტყვების და ქვეყნების სახელების თიომოპორფიკაცია რეალური მსოფლიო გეგოგოგიაზე, მაგალითად, თუ თქვენ ამოხსენთ ჩვენ აღმოჩნეთ, რომ ენის მოდელები სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა გეგ', 'it': 'La geometria globale dei modelli linguistici è importante per una serie di applicazioni, ma le sonde dei modelli linguistici tendono a valutare relazioni piuttosto locali, per le quali le verità fondamentali sono facilmente ottenibili. In questo articolo sfruttiamo il fatto che in geografia, le verità di base sono disponibili al di là delle relazioni locali. In una serie di esperimenti, valutiamo in che misura le rappresentazioni dei modelli linguistici dei nomi di città e paesi sono isomorfe alla geografia del mondo reale, ad esempio, se si racconta un modello linguistico dove si trovano Parigi e Berlino, conosce la strada per Roma? Troviamo che i modelli linguistici generalmente codificano informazioni geografiche limitate, ma con modelli più grandi che funzionano meglio, suggerendo che la conoscenza geografica può essere indotta da statistiche di co-occorrenza di ordine superiore.', 'lt': 'Kalbos modelių pasaulinė geometrija yra svarbi įvairioms taikomosioms sritims, tačiau kalbos modelių sondai dažniausiai vertina vietos santykius, dėl kurių lengvai gaunama antžeminė tiesa. Šiame dokumente išnaudojame faktą, kad geografinėje vietovėje nėra vietos santykių. Keliuose eksperimentuose vertiname, kokiu mastu kalbos modelio nuorodos į miesto ir šalies pavadinimus yra izomorfinės tikrojo pasaulio geografijai, pvz., jei pasakysite kalbos modeliui, kur yra Paryžius ir Berlynas, ar jis žino kelią į Romą? Mes manome, kad kalbų modeliai paprastai koduoja ribotą geografinę informaciją, tačiau su didesniais geriausiai veikiančiais modeliais, kurie rodo, kad geografinės žinios gali būti pagrįstos aukštesnės tvarkos bendro pobūdžio statistika.', 'mk': 'Глобалната геометрија на јазичките модели е важна за голем број апликации, но јазичките модели тенденцираат да ги проценат прилично локалните односи, за кои лесно се добиваат земјските вистини. Во овој документ го искористуваме фактот дека во географијата, земјските вистини се достапни надвор од локалните односи. Во серија експерименти, го проценуваме степенот во кој јазички модел претставувањата на имињата на градот и земјите се изоморфични со реалната географија, на пример, ако кажете јазички модел каде се Париз и Берлин, дали знае патот кон Рим? Најдовме дека јазичките модели генерално кодираат ограничени географски информации, но со поголеми модели кои го изведуваат најдоброто, што укажува на тоа дека географското знаење може да биде индукцирано од статистика на појава на повисок ред.', 'kk': 'Тіл үлгілерінің жүйелік геометриясы бірнеше қолданбалардың аумағына маңызды, бірақ тіл үлгілері жергілікті қатынастарды бағалайды, олардың жергілікті шындықтарын оңай алады. Бұл қағазда біз географияда жергілікті қатынастардан артық жергілікті шындықтар бар. Бірнеше тәжірибелерде біз қала мен елдердің атауларының қай тіл үлгілерін көрсету үлгісін есептеп береміз. Мысалы, егер Париж мен Берлин тіл үлгісін айтқанда, ол Ромға қалай жолын біледі бе? Тіл үлгілері кәдімгі шектелген географиялық мәліметтерді кодтамыз, бірақ үлкен үлгілер ең жақсы жасайтын, географиялық мәліметтерді жоғары реттегі біріктіру статистикасынан баста', 'ms': 'Geometri global model bahasa adalah penting untuk julat aplikasi, tetapi sond model bahasa cenderung untuk menilai hubungan tempatan, yang mana kebenaran tanah mudah dicapai. Dalam kertas ini kita mengeksploitasi fakta bahawa dalam geografi, kebenaran tanah tersedia diluar hubungan tempatan. Dalam sejumlah eksperimen, kita menilai jangkauan mana perwakilan model bahasa nama bandar dan negara adalah isomorfik kepada geografi dunia sebenar, misalnya, jika and a memberitahu model bahasa di mana Paris dan Berlin berada, adakah ia tahu cara ke Roma? Kami mendapati bahawa model bahasa secara umum mengekodkan maklumat geografik terbatas, tetapi dengan model yang lebih besar melaksanakan yang terbaik, menyarankan bahawa pengetahuan geografik boleh disebabkan dari statistik sambungan tertib-tinggi.', 'ml': 'ഭാഷ മോഡലുകളുടെ ഗ്ലോബല്\u200d ജിയോമിത്രി ഒരു പ്രയോഗങ്ങള്\u200dക്ക് വേണ്ടി പ്രധാനപ്പെട്ടതാണ്. പക്ഷെ ഭാഷ മോഡല്\u200d പരിശോധനങ്ങള്\u200d ലോക്കല്\u200d ബന്ധങ്ങളെക ഈ പത്രത്തില്\u200d നമ്മള്\u200d വിവരിക്കുന്നത് ഭൂഗ്രാഫിയില്\u200d ഭൂമിയിലെ സത്യം പ്രാദേശിക ബന്ധങ്ങള്\u200dക്ക് മുകളില്\u200d ല ഒരുപാട് പരീക്ഷണങ്ങളില്\u200d, പട്ടണത്തിന്റെയും രാജ്യത്തിന്റെയും പേരുകളുടെയും ഭാഷ മോഡലിന്റെയും പ്രതിനിധികള്\u200d ഏത് ഭാഷയിലാണെന്ന് നമുക്ക് വിചാരിക്കാന്\u200d കഴിയുന്നു. യഥ ഭാഷ മോഡലുകള്\u200d സാധാരണ പരിധിയില്ലാത്ത ജോഗ്രാഫിക വിവരങ്ങളുടെ കോഡിങ്ങിനെ കണ്ടെത്തുന്നു. പക്ഷെ ഏറ്റവും നല്ല മോഡലുകള്\u200d പ്രവര്\u200dത്തിക്കുന്നതില്\u200d വല', 'mt': 'Il-ġeometrija globali tal-mudelli lingwistiċi hija importanti għal firxa ta’ applikazzjonijiet, iżda s-sondi tal-mudelli lingwistiċi għandhom it-tendenza li jevalwaw relazzjonijiet pjuttost lokali, li għalihom jinkisbu l-veritajiet tal-art faċilment. F’dan id-dokument nisfruttaw il-fatt li fil-ġeografija, il-veritajiet tal-art huma disponibbli lil hinn mir-relazzjonijiet lokali. F’sensiela ta’ esperimenti, jivvalutaw sa liema punt ir-rappreżentazzjonijiet tal-mudell lingwistiku tal-ismijiet tal-bliet u tal-pajjiżi huma iżomorfiċi g ħal ġeografija tad-dinja reali, pereżempju, jekk tgħid mudell lingwistiku fejn jinsabu Pariġi u Berlin, taf it-triq lejn Ruma? Issibu li l-mudelli lingwistiċi ġeneralment jikkodifikaw informazzjoni ġeografika limitata, iżda b’mudelli akbar li jwettqu l-aħjar, li jissuġġerixxu li l-għarfien ġeografiku jista’ jiġi indott minn statistika ta’ kookkorrenza ta’ ordni ogħla.', 'no': 'Den globale geometrien for språk-modeller er viktig for eit rekkje av program, men språk-modeller har tendens til å evaluera stadig lokale forhold, for dei grunnsannene er enkelt henta. I denne papiret bruker vi faktum at i geografikk er bakgrunnsannheten tilgjengeleg enn lokale forhold. I ein rekke eksperimenter evaluerer vi kor mykje språk-modeller representasjonar av byer og landnamn er isomorfiske til verdens geografikk, f.eks. viss du forteller e it språk-modell der Paris og Berlin er, vet det korleis det g år til Rome? Vi finn at språk-modeller generelt koder begrensede geografiske informasjon, men med større modeller som utfører best, tyder på at geografiske kunnskap kan induserast frå høgare rekkefølgje-statistikk.', 'pl': 'Globalna geometria modeli językowych jest ważna dla wielu zastosowań, ale sondy modeli językowych mają tendencję do oceny raczej lokalnych relacji, dla których podstawowe prawdy są łatwo uzyskane. W artykule wykorzystujemy fakt, że w geografii prawdy podstawowe są dostępne poza relacjami lokalnymi. W serii eksperymentów oceniamy, w jakim stopniu modele językowe reprezentacji nazw miast i krajów są izomorficzne dla geografii świata rzeczywistego, np. jeśli powiemy modelowi językowemu, gdzie znajdują się Paryż i Berlin, czy zna on drogę do Rzymu? Stwierdzono, że modele językowe zazwyczaj kodują ograniczone informacje geograficzne, ale przy większych modelach działają najlepiej, sugerując, że wiedzę geograficzną można wywołać ze statystyk współwystępowania wyższego rzędu.', 'mn': 'Дэлхийн хэл загварын геометри нь олон янз бүрийн хэрэглэгчдийн хувьд чухал. Гэхдээ хэл загварын шалгалтууд орон нутгийн харилцааныг үнэлдэг байдаг. Энэ цаасан дээр бид газрын зураг дээр газрын үнэнийг орон нутгийн харилцааны гадна нэмэгдэж байгааг ашигладаг. Бид хэдэн олон туршилтуудад хот болон улсын нэрлүүдийн хэл загварын дүрслэлүүдийг бодит ертөнцийн газрын зурагт илэрхийлдэг хэл загварыг хэлж чадвал, жишээ нь Париж болон Берлин хаана байгааг хэлсэн бол Ромын замыг мэдэх үү? Бид хэл загварууд ихэвчлэн хязгаарлагдсан газрын мэдээллийг хязгаарлагддаг. Гэхдээ том загварууд хамгийн сайн үйлдвэрлэгддэг, газрын мэдлэг өндөр дараагийн хамтран үйлдвэрлэх статистикээс нөлөөлж чадна', 'ro': 'Geometria globală a modelelor lingvistice este importantă pentru o serie de aplicații, dar sondele modelelor lingvistice tind să evalueze relațiile locale, pentru care adevărurile fundamentale sunt ușor obținute. În această lucrare exploatăm faptul că în geografie, adevărurile fundamentale sunt disponibile dincolo de relațiile locale. Într-o serie de experimente, evaluăm măsura în care modelele lingvistice reprezentări ale numelor orașelor și țărilor sunt izomorfe geografiei lumii reale, de exemplu, dacă spui un model lingvistic unde se află Paris și Berlin, știe acesta drumul spre Roma? Considerăm că modelele lingvistice codează în general informații geografice limitate, dar cu modele mai mari care performează cel mai bine, sugerând că cunoștințele geografice pot fi induse din statisticile de coerență de ordin superior.', 'sr': 'Globalna geometrija jezičkih model a je važna za niz aplikacija, ali sonde jezičkih modela obično procjenjuju prilično lokalne odnose, za koje su temeljne istine lako dobijene. U ovom papiru iskorištavamo činjenicu da su u geografiji zemaljske istine dostupne izvan lokalnih odnosa. U nizu eksperimenata procjenjujemo koliko je jezički model predstavljanja grada i zemaljskih imena izomorfična na geografiju stvarnog svijeta, na primer, ako kažete jezički model gde su Pariz i Berlin, zna li put do Rima? Nalazimo da jezički modeli obično kodiraju ograničene geografske informacije, ali sa većim modelima koji najbolje izvršavaju, ukazujući na to da geografsko znanje može biti indukovano iz statistike povećane saradnje.', 'so': 'Jaomeetiyada caalamiga ah ee noocyada luuqada waxaa muhiim u ah codsiyada kala duduwan, laakiin sameynta qaababka luuqadu waa inay qiimeeyaan xiriirka deegaanka, taas oo runta lagu helaa si fudud. Warqadan waxaynu ka baaraannaa in xaqiiqada dhulku ay ka helaan xiriirka deegaanka. Imtixaano kala duduwan ayaannu qiimeynaynaa qiyaastii noocyada noocyada luuqada e e magaalada iyo magaca waddanka ay yihiin isomorfi oo ay u leeyihiin geoografiga caalamka ah, tusaale ahaan haddii aad u sheegtid qaababka luuqada ee ay joogaan Paris iyo Berlin, ma garanayaa jidka Rome? Waxaynu helnaa noocyada luuqadda sida caadiga ah macluumaadka geographicka ee sahlan, laakiin tusaalaha waaweyn oo sameynaya waxa ugu wanaagsan, waxaan ka jeedinayaa in aqoonta jiografiga laga soo bandhigi karo takhasuska soo socoshada sare.', 'sv': 'Språkmodellens globala geometri är viktig för en rad tillämpningar, men språkmodellsonder tenderar att utvärdera ganska lokala relationer, för vilka grundsanningar lätt kan erhållas. I denna uppsats utnyttjar vi det faktum att det inom geografi finns grundläggande sanningar utöver lokala relationer. I en serie experiment utvärderar vi i vilken utsträckning språkmodellrepresentationer av stad- och landsnamn är isomorfa till verklig geografi, t.ex. om du berättar en språkmodell var Paris och Berlin är, vet den vägen till Rom? Vi finner att språkmodeller generellt kodar begränsad geografisk information, men med större modeller som presterar bäst, vilket tyder på att geografisk kunskap kan induceras från högre ordning samförekomststatistik.', 'ta': 'The global geometry of language models is important for a range of applications, but language model probes tend to evaluate rather local relations, for which ground truths are easily obtained.  இந்த காகிதத்தில் நாம் புவியியலில், நிலத்தில் உண்மைகள் உள்ளூர உறவுகளுக்கு மேல் கிடைக்கும். சில சோதனைகளில், நகரம் மற்றும் நாடு பெயர்களின் மொழி மாதிரி பாரிஸ் மற்றும் பெர்லின் எங்கே இருக்கிறது என்று ஒரு மொழி மாதிரி மாதிரி பாரிஸ் மற்றும் பெர்லின் எங்கே இர நாம் அந்த மொழி மாதிரிகளை பொதுவாக வரையறை வரையறை புவியியல் தகவல்களை கண்டுபிடிக்கிறோம், ஆனால் சிறந்த மாதிரிகள் செய்யும் பெரிய முறைகளில், புவி', 'si': 'භාෂා මොඩේල්ස් ගැන සාමාන්\u200dය භාවිත්\u200dයාත්මක විශේෂයෙන් විශේෂයි, ඒත් භාෂා මොඩේල්ස් ප්\u200dරෝඩේල්ස් ස්ථානික සම් මේ පත්තරේ අපි ප්\u200dරයෝජනය කරනවා භූතිකාරයේ ස්ථානික සම්බන්ධතාවට වඩා ප්\u200dරයෝජනය කරන්නේ. අපි පරීක්ෂණාවක් වලින්, නගරය සහ රටේ නම් වලින් ප්\u200dරතිනිධානයේ භාෂාවක් වලින් ප්\u200dරතිනිධානයක් විශේෂය කරනවා කියලා, උදාහරණයෙන්, ඔයා පැරිසි  අපිට හොයාගන්න පුළුවන් කියලා භාෂාව මොඩල් සාමාන්\u200dයයෙන්ම සීමාවික භාෂ්\u200dය තොරතුරු සංකේතය කරනවා, ඒත් වැඩි මොඩල් හොඳම', 'ur': 'زبان مدلکوں کی глобальнی جئومتری ایک طریقہ کے لئے اہم ہے، لیکن زبان مدلکوں کی مطابق محلی رابطہ کا ارزش کرنا چاہتے ہیں، جن کے لئے زمین حقیقت آسانی حاصل کی جاتی ہے. اس کاغذ میں ہم اس حقیقت کو استعمال کرتے ہیں کہ جغرافی میں زمین حقیقتیں محلی رابطہ سے زیادہ موجود ہیں۔ ایک سری آزمائش میں ہم کس طرح شہر اور ملک کے نام کی زبان نمونہ کی تصدیق کرتے ہیں، جیسے کہ اگر آپ ایک زبان نمونہ بتائیں کہ پاریس اور برلین کہاں ہیں، کیا یہ روم کی راہ جانتا ہے؟ ہم دیکھتے ہیں کہ زبان موڈل معلوم ہوتے ہیں کہ محدود جغرافیک معلومات کے ساتھ، لیکن بہترین موڈل کے ذریعہ سے بہترین عمل کرتی ہیں، یہ معلوم کرتا ہے کہ جغرافیک معلومات بالاتر اوقات کے اتفاق آمار سے اضافہ کر سکتی ہے۔', 'uz': "Til modellarining dunyo geometri bir necha dastur uchun muhim, lekin til modeli modellari lokal aloqalarni qiymatga ega bo'ladi. Bu uchun soniya haqiqatlarni oson qiladi. Bu takarda biz geografi haqida o'ylaymiz, ground haqida lokal aloqalaridan ham mavjud. Bir necha tajribalarda biz shaxsiy va davlat nomlarining qiymatlarini qiymatimiz, masalan, agar Paris va Berlin qayerda bo'lgan tillar modelini o'zgartirishingiz mumkin, bu Roma qanday yoʻlni bilasizmi? Biz bu tilning modellari umumiy cheksiz geographik maʼlumotini kodlash mumkin, lekin eng yaxshi modellarni bajarish bilan juda ko'proq modellar bilan, geographik ilmiyotini eng yuqori taʼminotdan foydalanishi mumkin.", 'vi': 'Sự hình dạng to àn cầu của các mô hình ngôn ngữ là quan trọng trong một loạt các ứng dụng, nhưng các vấn đề ngôn ngữ thường đánh giá các mối quan hệ địa phương, nơi mà sự thật được lấy dễ dàng. Trong tờ giấy này, chúng tôi khai thác sự thật nằm ngoài địa lý. Trong một loạt các thí nghiệm, chúng tôi đánh giá mức độ các mô hình ngôn ngữ của các biểu tượng thành phố và quốc gia có giống nhau với địa lý ở thế giới thực, ví dụ như, nếu bạn kể một mô hình ngôn ngữ nơi Paris và Berlin có ở đó, nó có biết đường đến Rome không? Chúng tôi thấy các mô hình ngôn ngữ thường mã hóa thông tin địa lý giới hạn, nhưng với các mô hình lớn thực hiện tốt nhất, gợi ý rằng hiểu biết địa lý có thể được tạo ra từ các thống kê khớp với nhau.', 'hr': 'Globalna geometrija jezičkih model a je važna za niz aplikacija, ali sonde jezičkih modela obično procjenjuju prilično lokalne odnose, za koje su temeljne istine lako dobijene. U ovom papiru iskorištavamo činjenicu da su u geografiji zemaljske istine dostupne izvan lokalnih odnosa. U nizu eksperimenata procjenjujemo koliko je jezički model predstavljanja grada i zemaljskih imena izomorfična na geografiju stvarnog svijeta, na primjer, ako kažete jezički model gdje su Pariz i Berlin, zna li put do Rima? Nalazimo da jezički modeli obično kodiraju ograničene geografske informacije, ali s većim modelima koji najbolje izvršavaju, ukazujući na to da se geografske znanje može inducirati iz statistike povećane saradnje.', 'da': 'Den globale geometri af sprogmodeller er vigtig for en række applikationer, men sprogmodelssonder har tendens til at evaluere temmelig lokale relationer, hvor grundsandheder let kan opnås. I denne artikel udnytter vi det faktum, at der i geografien findes grundlæggende sandheder ud over lokale relationer. I en række eksperimenter vurderer vi, i hvilket omfang sprogmodelrepresentationer af by- og landenavne er isomorfe for den virkelige verdens geografi, f.eks. hvis du fortæller en sprogmodel, hvor Paris og Berlin er, kender den så vejen til Rom? Vi finder ud af, at sprogmodeller generelt indkoder begrænset geografisk information, men med større modeller, der fungerer bedst, tyder på, at geografisk viden kan fremkaldes fra højere ordens samhørighedsstatistik.', 'bg': 'Глобалната геометрия на езиковите модели е важна за редица приложения, но сондите за езикови модели са склонни да оценяват по-скоро локалните отношения, за които основните истини са лесно получени. В тази статия използваме факта, че в географията основните истини са достъпни отвъд местните отношения. В поредица от експерименти оценяваме степента, до която езиковите модели представяния на имената на градове и държави са изоморфни на географията на реалния свят, например, ако кажете езиков модел къде са Париж и Берлин, знае ли той пътя към Рим? Установяваме, че езиковите модели обикновено кодират ограничена географска информация, но с по-големи модели, които се представят най-добре, което предполага, че географското знание може да бъде индуцирано от статистика за съвместни събития от по-висок ред.', 'nl': 'De globale geometrie van taalmodellen is belangrijk voor een scala aan toepassingen, maar taalmodellen hebben de neiging om eerder lokale relaties te evalueren, waarvoor grondwaarheden gemakkelijk te verkrijgen zijn. In dit artikel benutten we het feit dat in de geografie grondwaarheden beschikbaar zijn buiten lokale relaties. In een reeks experimenten evalueren we in hoeverre taalmodellen representaties van stad- en landnamen isomorf zijn aan de echte aardrijkskunde, bijvoorbeeld, als je een taalmodel vertelt waar Parijs en Berlijn zijn, weet het dan de weg naar Rome? We vinden dat taalmodellen over het algemeen beperkte geografische informatie coderen, maar met grotere modellen die het beste presteren, wat suggereert dat geografische kennis kan worden geïnduceerd uit hogere orde co-incident statistieken.', 'de': 'Die globale Geometrie von Sprachmodellen ist für eine Reihe von Anwendungen wichtig, aber Sprachmodellsonden neigen dazu, eher lokale Beziehungen zu bewerten, für die Grundwahrheiten leicht gewonnen werden können. In diesem Beitrag nutzen wir die Tatsache aus, dass in der Geographie grundlegende Wahrheiten jenseits lokaler Beziehungen verfügbar sind. In einer Reihe von Experimenten untersuchen wir, inwieweit Sprachmodelldarstellungen von Stadt- und Ländernamen isomorph zur realen Geographie sind, z.B. wenn man einem Sprachmodell sagt, wo Paris und Berlin sind, kennt es den Weg nach Rom? Wir finden, dass Sprachmodelle im Allgemeinen begrenzte geographische Informationen kodieren, aber mit größeren Modellen, die am besten funktionieren, deutet darauf hin, dass geographisches Wissen aus höheren Co-Vorkommen Statistiken induziert werden kann.', 'id': 'Geometri global dari model bahasa penting untuk jangkauan aplikasi, tetapi probe model bahasa cenderung untuk mengevaluasi hubungan lokal, untuk yang kebenaran tanah mudah diperoleh. Dalam kertas ini kita mengeksploitasi fakta bahwa dalam geografi, kebenaran tanah tersedia diluar hubungan lokal. Dalam sejumlah eksperimen, kita mengevaluasi seberapa besar representation model bahasa dari nama kota dan negara adalah isomorfik untuk geografi dunia nyata, misalnya, jika Anda memberitahu model bahasa di mana Paris dan Berlin, apakah itu tahu jalan ke Roma? Kami menemukan bahwa model bahasa secara umum mengkode informasi geografik terbatas, tetapi dengan model yang lebih besar melakukan yang terbaik, menyarankan bahwa pengetahuan geografik dapat didorong dari statistik korespondensi tertib tinggi.', 'ko': '언어 모델의 전역 기하학은 일련의 응용에 매우 중요하지만 언어 모델 탐색은 국부 관계를 평가하는 경향이 있기 때문에 이러한 관계의 기본적인 사실은 쉽게 얻을 수 있다.본고에서 우리는 지리학에서 국부적인 관계를 제외하고 기본적인 사실을 얻을 수 있다는 사실을 이용했다.일련의 실험에서 우리는 도시와 국가 명칭의 언어 모델이 현실 세계의 지리와 어느 정도 일치하는지 평가했다. 예를 들어 파리와 베를린이 어디에 있는지 알려주면 로마로 가는 길을 알 수 있을까?우리는 언어 모델이 통상적으로 유한한 지리 정보를 인코딩하지만 비교적 큰 모델이 가장 잘 나타난다는 것을 발견했다. 이것은 지리 지식이 높은 단계의 공현 통계에서 귀납될 수 있음을 나타낸다.', 'tr': 'Dil nusgalarynyň küresel geometriýasy birnäçe uygulamalar üçin wajypdyr, ýöne dil nusgalary ýerli baglaýyşlaryň ýerinde baýramçylygyny a ňsatlyk bilen çykýar. Bu kagyzda geografiýada ýerli baglaşyklaryň öňünde hakykatlar bar. Birnäçe deneylerde, şehir we ýurtyň adlarynyň nähili dil nusgasyny çykaryp barýandygyny çykarýarys, meselä, eger siz Pariz we Berlin dil nusgasyny a ýtsaňyz, Roma ýolu bilermi? Dil nusgalary umumy diýip çarpan geografik maglumatlary ködleýäris ýöne uly nusgalar bilen gowy eden, geografik bilim ýokary derejesinden täsir edilebilir.', 'fa': 'ژومتریک جهانی مدل زبان برای یک مجموعه کاربرد مهم است، ولی پرونده های مدل زبان به ارزیابی نسبت به ارزیابی رابطه\u200cهای محلی است، که حقیقت زمینی به آسانی دریافت می\u200cشود. در این کاغذ ما از حقیقت استفاده می کنیم که در جغرافیا حقیقت زمینی فراتر از رابطه های محلی وجود دارد. در یک سری آزمایشات، ما ارزیابی می کنیم که چقدر نمونه های مدل زبانی از نام شهر و کشور به جغرافیا دنیای واقعی ایزومورفیک هستند، مثال اگر به یک مدل زبانی بگویید که پاریس و برلین کجاست، آیا راهی به روم می داند؟ ما این مدل زبان را معمولاً اطلاعات جغرافی محدود می\u200cکنیم، ولی با مدل\u200cهای بزرگتر که بهترین عمل می\u200cکنند، پیشنهاد می\u200cدهیم که دانش جغرافی می\u200cتواند از آمار اتفاق افراد بالاتر تحریک شود.', 'sq': 'The global geometry of language models is important for a range of applications, but language model probes tend to evaluate rather local relations, for which ground truths are easily obtained.  Në këtë letër ne shfrytëzojmë faktin se në gjeografi, të vërtetat tokësore janë në dispozicion përtej marrëdhënieve lokale. Në një seri eksperimentesh, ne vlerësojmë shkallën deri sa përfaqësimet e model it gjuhësor të emrave të qytetit dhe vendeve janë izomorfike ndaj gjeografisë së botës reale, për shembull, nëse ju tregoni një model gjuhësor ku janë Paris dhe Berlin, a e di rrugën për në Romë? Ne zbulojmë se modelet gjuhësore zakonisht kodojnë informacion gjeografik të kufizuar, por me modele më të mëdha që bëjnë më të mirën, duke sugjeruar se njohuria gjeografike mund të induktohet nga statistikat e bashkëndodhjes me rend më të lartë.', 'sw': 'Geomea ya mitindo ya lugha duniani ni muhimu kwa matumizi mengi, lakini vipindi vya lugha vinaendelea kutathmini mahusiano ya wenyeji, ambapo ukweli wa msingi unapatikana kirahisi. Katika karatasi hii tunatumia ukweli kwamba katika geographia, ukweli wa ardhi unapatikana zaidi ya mahusiano ya wenyeji. Katika mfululizo wa majaribio, tunapitia kiwango gani maonesho ya mifano ya lugha ya mji na majina ya nchi ni ya upande wa kujitenga kwa geographia halisi duniani, kwa mfano, kama utaambia mtindo wa lugha wapi Paris na Berlin, je unajua njia ya kwenda Rome? We find that language models generally encode limited geographic information, but with larger models performing the best, suggesting that geographic knowledge can be induced from higher-order co-occurrence statistics.', 'af': "Die globale geometrie van taal modele is belangrik vir 'n reek van toepassings, maar taal model probes tendeer na evalueer eerder plaaslike verwantings, waarvoor grondwaardes maklik verkry word. In hierdie papier gebruik ons die feit dat in geografie grondwaardes beskikbaar is buite plaaslike verhouding. In 'n reeks eksperimente evalueer ons die uitbreiding waar taal model voorstellings van stad en landnaams isomorfiek is tot reël-wêreld geografie, bv. as jy 'n taal model vertel waar Parys en Berlin is, weet dit die pad na Rome? Ons vind dat taal modeller generelyk geografiese inligting enkodeer, maar met grootste modeller wat die beste uitvoer, voorstel dat geografiese kennis kan ingestel word van hoër volgorde kooperasiestatistiek.", 'am': 'የቋንቋ ዓይነቶች ዓለምአቀፍ ሞኮትሪ ለብዙ ፕሮግራሞች ያስፈልጋል፤ ነገር ግን የቋንቋ ሞዴል ሞክራዎች ከቅርብ ግንኙነት ይልቅ ያስተካክላሉ፤ ስለዚህም መሬት እውነቱን ቀላል ያገኙበታል፡፡ በዚህ ገጾች ውስጥ የጂዮግራፊ ውሸት ከቅርብ ግንኙነት በላይ የተገኘ ነው፡፡ በተለያዩ ፈተናዎች ውስጥ የከተማይቱና የአገሪቱ ስሞች የቋንቋ ምሳሌ የኢንተርኔት ግንኙነት የቅርብ ዓለም geography ምን እንደሆነ እናውቃለን፡፡ የቋንቋዎች ምሳሌዎች በተለየ የጂዮግራፍ መረጃዎችን እናገኛለን፣ ነገር ግን የበለጠ ዓይነቶች ማድረግ፣ የጂዮግራፍ እውቀት ከፍተኛ ቁጥጥር መሆኑን ማግኘት ይችላል፡፡', 'bn': 'ভাষার মডেলের গুরুত্বপূর্ণ ভূমিতি, কিন্তু ভাষার মডেল প্রযোজ্যেরা স্থানীয় সম্পর্কের পরিবর্তে স্থানীয় সম্পর্কের মূল্য মূল্যায়ন এই পত্রিকায় আমরা এই বাস্তবতা ব্যবহার করি যে ভূগ্রাফিতে স্থানীয় সম্পর্কের বাইরে ভূমির সত্য পাওয়া যাচ্ছে। In a series of experiments, we evaluate the extent to which language model representations of city and country names are isomorphic to real-world geography, e.g., if you tell a language model where Paris and Berlin are, does it know the way to Rome?  আমরা ভাষার মডেল সাধারণত ভৌগলিক তথ্য সীমিত, কিন্তু বৃহত্তম মডেলের সাথে ভূমিকা প্রদর্শন করার পরামর্শ দিয়েছে যে ভূমিকার জ্ঞানের উচ্চ পরিসংখ্য', 'hy': 'Լեզվային մոդելների գլոբալ երկրաչափությունը կարևոր է մի շարք ծրագրերի համար, բայց լեզվային մոդելների ուսումնասիրությունները հակված են գնահատել բավականին տեղական հարաբերությունները, որոնց համար հեշտությամբ ստացվում են հողի ճշմարտությունները Այս թղթի մեջ մենք օգտագործում ենք այն փաստը, որ երկրաբանության մեջ երկրային ճշմարտությունները հասանելի են տեղական հարաբերություններից դուրս: Մենք մի շարք փորձարկումների ընթացքում գնահատում ենք, թե որքանով են քաղաքի և երկրի անունների լեզվային մոդելները իսոմորֆիկ իրական աշխարհի երկրաբանության, օրինակ, եթե դուք պատմեք լեզվային մոդելը, որտեղ Փարիզին և Բերլինը գտնվում են, արդյոք այն ճանապարհ է հասնում Մենք հայտնաբերում ենք, որ լեզվի մոդելները ընդհանուր առմամբ կոդավորում են սահմանափակ երկրագրական տեղեկատվություն, բայց ավելի մեծ մոդելների հետ, որոնք լավագույնն են աշխատում, առաջարկում են, որ երկրագրական գիտելիքը կարող է առաջացվել ավելի բարձր կարգով համա', 'bs': 'Globalna geometrija jezičkih model a je važna za niz aplikacija, ali sonde jezičkih modela obično procjenjuju prilično lokalne odnose, za koje su temeljne istine lako dobijene. U ovom papiru iskorištavamo činjenicu da su na geografiji zemaljske istine dostupne izvan lokalnih odnosa. U nizu eksperimenata procjenjujemo koliko je jezički model predstavljanja grada i zemaljskih imena izomorfična na geografiju stvarnog svijeta, na primjer, ako kažete jezički model gdje su Pariz i Berlin, zna li put do Rima? Nalazimo da jezički modeli obično kodiraju ograničene geografske informacije, ali sa većim modelima koji najbolje izvode, sugerirajući da geografsko znanje može biti indukovano iz statistike o povećanju saradnje.', 'ca': "La geometria mundial dels models de llenguatge és important per a una gamma d'aplicacions, però les sondes del model de llenguatge tendeixen a evaluar les relacions més o menys locals, per les quals es obtienen fàcilment veritats fonamentals. En aquest paper explotam el fet que en la geografia, les veritats terrestres són disponibles més enllà de les relacions locals. En una sèrie d'experiments, evaluem l'importància en què les representacions del model lingüístic dels noms de ciutat i país són isomòrfiques a la geografia del món real, per exemple, si dius a un model lingüístic on està París i Berlín, sabe el camí a Roma? Trobem que els models de llenguatge codifiquen generalment informació geogràfica limitada, però amb models més grans que desempenyen el millor, suggerint que el coneixement geogràfic pot ser induït a partir d'estadístiques de coincidència d'ordre superior.", 'cs': 'Globální geometrie jazykových modelů je důležitá pro řadu aplikací, ale sondy jazykových modelů mají tendenci hodnotit spíše lokální vztahy, pro které lze snadno získat základní pravdy. V tomto článku využíváme skutečnosti, že v geografii jsou základní pravdy dostupné mimo lokální vztahy. V sérii experimentů hodnotíme, do jaké míry jsou jazykové modelové reprezentace měst a zemí izomorfní k reálné geografii, např. pokud řeknete jazykovému modelu, kde jsou Paříž a Berlín, zná cestu do Říma? Zjišťujeme, že jazykové modely obecně kódují omezené geografické informace, ale s většími modely fungují nejlépe, což naznačuje, že geografické znalosti lze vyvolat ze statistik současného výskytu vyššího řádu.', 'fi': 'Kielimallien globaali geometria on tärkeä monille sovelluksille, mutta kielimallien luotaimilla on tapana arvioida melko paikallisia suhteita, joille pohjatotuudet ovat helposti saatavissa. Tässä artikkelissa hyödynnämme sitä tosiasiaa, että maantieteessä pohjatotuudet ovat saatavilla paikallisten suhteiden ulkopuolella. Tutkimussarjassa arvioimme, missä määrin kaupunkien ja maiden nimien kielimallit ovat isomorfisia todellisen maailman maantieteelle, esimerkiksi jos kerrot kielimallin missä Pariisi ja Berliini ovat, tietääkö se tien Roomaan? Havaitsemme, että kielimallit yleensä koodaavat rajallista maantieteellistä tietoa, mutta suuremmat mallit toimivat parhaiten, mikä viittaa siihen, että maantieteellinen tieto voidaan indusoida korkeamman järjestyksen rinnakkaisesiintymistilastoista.', 'et': 'Keelemudelite globaalne geomeetria on oluline mitmesuguste rakenduste jaoks, kuid keelemudeli sondid kipuvad hindama pigem kohalikke suhteid, mille jaoks on alustõde kergesti kättesaadav. Käesolevas dokumendis kasutame ära asjaolu, et geograafias on alustõed kättesaadavad väljaspool kohalikke suhteid. Eksperimentide seerias hindame, mil määral on linna- ja riiginimede keelemudelite kujutised isomorfsed reaalmaailma geograafiale, näiteks kui räägite keelemudelile, kus on Pariis ja Berliin, kas see teab teed Rooma? Leiame, et keelemudelid kodeerivad üldiselt piiratud geograafilist informatsiooni, kuid suuremate mudelitega on parim tulemus, mis viitab sellele, et geograafiliseid teadmisi saab indutseerida kõrgema järjekorra koosesinemisstatistikast.', 'az': 'Dil modellərin küresel geometri çoxlu uyğulamalar üçün mövcuddur, amma dil modelləri çoxlu yerli ilişkilerin değerlendirməyə məcbur edirlər, bunun üçün yer doğruları asanlıqla alınır. Bu kağızda biz geografiyada yerli əlaqələrdən daha çox istifadə edirik. Bir neçə təcrübələrdə, şəhər və ülk adlarının növ dil modellərinin g östərilmələrinin həqiqi dünya geografiyasına izomorfiq olduğu qədər değerləşdiririk, məsələn, əgər Paris və Berlin dil modellərinin haradadığını anlarsanız, Roma yolunu bilirmi? Biz dil modelləri genellikle sınırlı ģeogrāfiski məlumatları kodlayır, amma ən yaxşı işlədən böyük modellərlə birlikdə ģeogrāfiski bilgi yüksək sıralar birlikdə gələn statistikdən təşkil edilə bilər.', 'jv': 'jeogram global nang model sing luwih akeh lanjut kanggo gambar aplikasi, nguasai model sing nggawe gerakan kanggo kuwi nggawe barang lokal sing, kanggo awak dhéwé true. Nang paper iki kita sumelang ngomong nek jeogras, kaleh pakan iki bakal terus ing manut ning laranan ingkang lokal. Nang liya sing perbudhakan banget, awak dhéwé nggunakake kapan modèl nggawe geratan siji lan nganggo langa kuwi nggologèhku nggawe geratan ning dunya iki, t.d. bisa awak dhéwé ngerasakno model sing paling nggawe nêmêr, kuwi wis ngerasakno ning parangan sing bakal têmêr dumadhi nêmêr,  Awak dhéwé nglanggar model sing larang urip kuwi nggawe informasi jeografi, nguasai model sing luwih apik dhéwé, supoyo supoyo kuwi kesempatan jeografi sing bisa ngelarang sakjane sak ono ngéwé ujaran ciptaaken langkung sampek.', 'ha': "Dukkan geometiri na misalin harshe na da muhimu wa wasu shiryoyin ayuka, kuma amma misalin ayuka na harshe, za'a yi amfani da idan an ƙaddara wa danganta masu lokaci, don a iya amfani da gaskiyar bakin. Ga wannan takardan da Muke amfani da gaskiya a cikin geography, za'a iya saman gaskiya daga mazaunin lokal. Daga cikin majarin jarrabai, munã iya ƙayyade inda duk misalin misalin harshen na birnin da sunayen ƙasane su ne solimorfi zuwa geografi masu gaskiya a cikin duniya, misali, idan ka faɗa wani misalin harshe na Paris da Berlin, za'a san hanya zuwa Rome? Tuna gane misalin harshen kode data na geographic da aka ƙayyade, kuma amma da misãlai masu ƙaranci da ke aikata mafi kyãwo, Munã shawarar da cewa za'a iya ƙara kunyar geographic daga statistics na koma da sauri.", 'sk': 'Globalna geometrija jezikovnih modelov je pomembna za različne aplikacije, vendar pa sonde jezikovnih modelov ponavadi ocenjujejo precej lokalne odnose, za katere je mogoče zlahka pridobiti osnovne resnice. V tem članku izkoriščamo dejstvo, da so v geografiji temeljne resnice na voljo zunaj lokalnih odnosov. V vrsti eksperimentov ocenjujemo, v kolikšni meri so predstavitve jezikovnih modelov imena mest in držav izomorfne glede na zemljepisno geografijo realnega sveta, npr. če povemo jezikovnemu modelu, kje sta Pariz in Berlin, ali pozna pot do Rima? Ugotavljamo, da jezikovni modeli običajno kodirajo omejene geografske informacije, vendar z večjimi modeli, ki delujejo najbolje, kar kaže, da je geografsko znanje mogoče inducirati iz statistike sočasnih pojavov višjega reda.', 'bo': 'The global geometry of language models is important for a range of applications, but language model probes tend to evaluate rather local relations, for which ground truths are easily obtained. ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་མཐོ་རིམ་དང་། རྨང་གཞུང་གི་དངོས་གནས་ཚུལ་དག་གནས་སྟངས་དང་ཁྱད་པར་ཡོད། གྲོང་ཁྱེར་དང་རྒྱལ་ཁབ་ཀྱི་མིང་ཚོའི་སྐད་ཡིག་གཟུགས་འགྱུར་བ་ཅིན་གྱི་དབྱིབས་དཔེ་བས། ང་ཚོས་སྐད་ཡིག་ཆ་དཔེ་དབྱིབས་ཡིག་ཆ་ནི་རྣམས་ལས་ཉུང་བའི་དབྱིབས་འགྲེལ་བཤད་ཀྱི་རྣམ་པ་ཡིན་ནའང་། དཔེ་དབྱིབས་དཔེ་གཏོང་མཁན་དག་ཚད་མང་ཤ', 'he': 'הגאומטריה הגלובלית של דוגמני שפת חשובה לטווח של שימושים, אך חוקי דוגמני שפת נוטים להעריך מערכות יחסים מקומיות למדי, שבגלל הן אמונות קרקעיות קלות להשיג. In this paper we exploit the fact that in geography, ground truths are available beyond local relations.  In a series of experiments, we evaluate the extent to which language model representations of city and country names are isomorphic to real-world geography, e.g., if you tell a language model where Paris and Berlin are, does it know the way to Rome?  אנו מוצאים שדוגמני שפה בדרך כלל קודים מידע גאוגרפי מוגבל, אך עם דוגמנים גדולים יותר שמופעים את הטוב ביותר, המציע שידע גאוגרפי יכול להיות מעורר מסטטיסטיקה של התרחשות משותפת סדר גבוה יותר.'}
